Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0013315579227696406,"Causal knowledge about the relationships among decision variables and a reward
variable in a bandit setting can accelerate the learning of an optimal decision.
Current works often assume the causal graph is known, which may not always
be available a priori. Motivated by this challenge, we focus on the causal bandit
problem in scenarios where the underlying causal graph is unknown and may
include latent confounders. While intervention on the parents of the reward node
is optimal in the absence of latent confounders, this is not necessarily the case in
general. Instead, one must consider a set of possibly optimal arms/interventions,
each being a special subset of the ancestors of the reward node, making causal
discovery beyond the parents of the reward node essential. For regret minimization,
we identify that discovering the full causal structure is unnecessary; however, no
existing work provides the necessary and sufficient components of the causal graph.
We formally characterize the set of necessary and sufficient latent confounders
one needs to detect or learn to ensure that all possibly optimal arms are identified
correctly. We also propose a randomized algorithm for learning the causal graph
with a limited number of samples, providing a sample complexity guarantee for
any desired confidence level. In the causal bandit setup, we propose a two-stage
approach. In the first stage, we learn the induced subgraph on ancestors of the
reward, along with a necessary and sufficient subset of latent confounders, to
construct the set of possibly optimal arms. We show that for our proposed algorithm,
the number of intervention samples required to learn the set of possibly optimal
arms scales polynomially with respect to the number of nodes. The second phase
involves the application of a standard bandit algorithm, such as the UCB algorithm.
We also establish a regret bound for our two-phase approach, which is sublinear in
the number of rounds."
INTRODUCTION,0.002663115845539281,"1
Introduction"
INTRODUCTION,0.0039946737683089215,"Causal bandits have been a topic of interest since their inception and have been studied in various
contexts [1]. The authors assumed precise knowledge of the causal graph and the impact of in-
terventions or actions on the parents of the reward node. Subsequently, there has been a flurry of
research on causal bandits [2, 3, 4]. The primary limitation of the majority of existing works on causal
bandits is their assumption of full knowledge of the causal graph, which is often impractical for many"
INTRODUCTION,0.005326231691078562,"real-world applications [1, 5, 6]. Recently, efforts have been made to overcome this limitation. In [7],
the authors propose a sample efficient algorithm for cases where the causal graph can be represented
as a directed tree or a causal forest and later extend the algorithm to encompass a broader class of
general chordal graphs. However, the proposed algorithm is only applicable to scenarios where the
Markov equivalence class (MEC) of the causal graph is known and does not have confounders. In
[8], the authors propose a causal bandit algorithm that does not require any prior knowledge of the
causal structure and leverages separating sets. However, their theoretical result holds only when a
true separating set is known. The paper by Konobeev et al. [9] also deals with causal bandits with an
unknown graph and proposes a two-phase approach. The first phase uses a randomized parent search
algorithm to learn the parents of the reward node, and the second phase employs UCB to identify
the optimal intervention over the parents of the reward node. However, similar to [7], they assume
causal sufficiency, i.e., no latent confounders are present. In another related paper, [10], the authors
initially emphasize the challenge of dealing with exponentially many arms when addressing causal
bandits with an unknown graph. To tackle this issue, the authors assume that the reward is a noisy
additive function of its parents. This assumption enables them to reframe the problem as an additive
combinatorial linear bandit problem."
INTRODUCTION,0.006657789613848202,"We also focus on the causal bandit setup where the causal graph is unknown, but we allow the
presence of latent confounders and make no parametric assumptions. The optimal intervention in
this case is not limited to parents of the reward node; instead, we have a candidate set of optimal
interventions, called possibly optimal minimum intervention sets (POMISs), each being a special
subset of the ancestors of the reward node [5]. Thus, learning only the parents of the reward, similar
to [9], is insufficient. This implies that causal discovery beyond parents of the reward is imperative.
However, for regret minimization, discovering the full causal structure is not necessary. Instead, we
characterize the set of necessary and sufficient latent confounders one needs to detect/learn to ensure
all the possibly optimal arms are learned correctly."
INTRODUCTION,0.007989347536617843,"Causal discovery is a well-studied problem and can be applied to our setup [11, 12, 13]. However,
the majority of the existing causal discovery algorithms rely on the availability of an infinite amount
of interventional data [14, 15, 16]. Some prior work shows that discovery is possible with limited
interventional data, with theoretical guarantees when the underlying causal graph is a tree and
contains no latent confounders [17]. Also, the paper [18] proposes a sample-efficient active learning
algorithm for causal graphs without latent confounders, given that the MEC for the underlying causal
graph is known. Bayesian causal discovery can also be a valuable tool when interventional data is
limited. However, it faces challenges when tasked with computing posterior probabilities across
the combinatorial space of directed acyclic graphs (DAGs) without specific parametric assumptions
[19, 20, 21]. All in all, the sample-efficient learning of causal graphs with latent confounders, without
any parametric or graphical assumptions, with theoretical guarantees, remains an open problem."
INTRODUCTION,0.009320905459387484,"We propose a randomized algorithm for sample-efficient learning of causal graphs with confounders.
We analyze the algorithm and bound the maximum number of interventional samples required to
learn the causal graph with all the confounders with a given confidence level. For the causal bandit
setup, we propose a two-stage approach where the first step learns a subgraph of the underlying causal
graph to construct a set of POMISs, and the second phase learns the optimal arm among the POMISs.
We show that the requirement of learning only a subgraph leads to significant savings in terms of
interventional samples and consequently, regret. The main contributions of our work are as follows:"
INTRODUCTION,0.010652463382157125,"• We characterize the necessary and sufficient set of latent confounders in the induced subgraph
on ancestors of the reward node that we need to learn/detect in order to identify all the
POMISs for a causal bandit setup when the underlying causal graph is unknown."
INTRODUCTION,0.011984021304926764,"• We propose a randomized algorithm for sample-efficient learning of causal graphs with
confounders, providing theoretical guarantee on the number of interventional samples
required to learn the graph with a given confidence level."
INTRODUCTION,0.013315579227696404,"• We propose a two-phase algorithm for causal bandits with unknown causal graphs containing
confounders. The first phase involves learning the induced subgraph on reward’s ancestors
along with a subset of latent confounders to identify all the POMISs. The next phase involves
a standard bandit algorithm, e.g., upper confidence bound (UCB) algorithm. Our theoretical
analysis establishes an upper bound on the cumulative regret of the overall algorithm."
PRELIMINARIES AND PROBLEM SETUP,0.014647137150466045,"2
Preliminaries and Problem Setup"
PRELIMINARIES AND PROBLEM SETUP,0.015978695073235686,"We start with an overview of the causal bandit problem and other relevant background needed on
causal models. Structural causal model (SCM) is a tuple M = ⟨V, U, F, P(U)⟩where V =
{Vi}n
i=1 ∪{Y } is the set of observed variables, U is the set of independent exogenous variables, F is
the set of deterministic structural equations and P(U) is the distribution for exogenous variables [22].
The equations fi map the parents (Pa(Vi)) and a subset of exogenous variables Ui ⊆U, to the value
of variable Vi, i.e., Vi = fi(Pa(Vi), Ui). We consider the causal bandit setup where all the observed
variables Vi ∈V are discrete with the domain Ω(Vi) = [K] := {1, 2, 3, . . . , K}, and the reward Y
is binary, i.e., Ω(Y ) = {0, 1}. We can associate a DAG G = (V, E) with every SCM, where the
vertices V correspond to the observed variables and edges E consist of directed edges Vi →Vj when
Vi ∈Pa(Vj) and bi-directed edges between Vi and Vj (Vi ←→Vj) when they share some common
unobserved variable, also called latent confounder. We restrict ourselves to semi-Markovian causal
models in which every unobserved variable has no parents and has exactly two children, both of
which are observed [10]. An intervention on a set of variables W ⊆V, denoted by do(W), induces
a post-interventional DAG (GW) with incoming edges to vertices W removed . We can broadly
classify interventions into deterministic interventions, where variables are set to a fixed realization
denoted by do(W = w), and stochastic interventions, where instead of a fixed realization we have
W ∼P(.), where P is a probability measure over the domain Ω(W). We denote the sub-model
induced under hard intervention by MW=w and the one induced under stochastic intervention by
MW. In the context of causal bandits, an arm or action corresponds to hard intervention on a subset
of variables other than the reward. The goal of the agent is to identify the intervention that maximizes
the expected reward. The performance of an agent is measured in terms of cumulative regret RT ."
PRELIMINARIES AND PROBLEM SETUP,0.017310252996005325,"RT := T max
W⊆V
max
w∈[K]|W| E[Y |do(W = w)] − T
X"
PRELIMINARIES AND PROBLEM SETUP,0.018641810918774968,"t=1
E[Y |do(Wt = wt)],
(1)"
PRELIMINARIES AND PROBLEM SETUP,0.019973368841544607,"where do(Wt = wt) represents the intervention selected by the agent in round t. We use the notation
∆do(w) to define the sub-optimality gap of the corresponding arm do(W = w). We denote the
descendants, ancestors and children of a vertex Vi by De(Vi), An(Vi) and Ch(Vi) respectively. We
use the notation Bi(Vi, G) to denote the set of vertices having bidirected edges to Vi except the reward
node Y . We refer to the induced graph between observed variables as the observable graph. The
transitive closure of a graph, denoted by Gtc, encodes the ancestral relationship in G. That is, the
directed edge Vi →Vj is included in Gtc only when Vi ∈An(Vj). The transitive reduction, denoted
by Tr(G) = (V, Er), is a graph with the minimum number of edges such that the transitive closure
is the same as G. The connected component (c-component) of the DAG G, containing vertex Vi, is
denoted by CC(Vi), which is the maximal set of all vertices in G that have a path to Vi, consisting only
of bi-directed edges [23]. For a subset of vertices W ⊆V, we define CC(W) := S"
PRELIMINARIES AND PROBLEM SETUP,0.02130492676431425,"Wi∈W CC(Wi).
In a DAG, a subset of nodes W d-separates two nodes Vi and Vj when it effectively blocks all
paths between them, denoted as Vi ⊥⊥d Vj|W. Blocking is a graphical criterion associated with
d-separation [22]. A probability distribution is said to be faithful to a graph if and only if every
conditional independence (CI) statement can be inferred from d-separation statements in the graph.
Faithfulness is a commonly used assumption in the existing work on causal discovery [14, 24]. We
assume that the following form of the interventional faithfulness assumption holds in our setup.
Assumption 2.1. Consider a set of nodes W ⊆V and the stochastic intervention do(W, U) on W
and any set U ⊆V\W. The conditional independence (CI) statement (X ⊥⊥Y | Z)MW,U holds in
the induced model if and only if there is a corresponding d-separation statement in post-interventional
graph (X ⊥⊥d Y | Z)GW,U, where X, Y, and Z are disjoint subsets of V \ W. The CI statements in
the induced model are with respect to the post-interventional joint probability distribution."
POSSIBLY OPTIMAL ARMS IN CAUSAL BANDITS WITH UNKNOWN CAUSAL GRAPH,0.022636484687083888,"3
Possibly Optimal Arms in Causal Bandits with Unknown Causal Graph"
POSSIBLY OPTIMAL ARMS IN CAUSAL BANDITS WITH UNKNOWN CAUSAL GRAPH,0.023968042609853527,"The optimal intervention in a causal bandit setup is not restricted to the parent set of the reward
node when the reward node Y is confounded with any node in its ancestors An(Y ) [5]. For instance,
consider SCM X1 = U1 and X2 = X1 ⊕U2 and reward Y = X2 ⊕U2, where U1 ∼Ber(0.5) and
U2 ∼Ber(0.5). Note that X2 and reward Y are confounded in this SCM. The optimal intervention
in this case is do(X1 = 1) since E[Y |do(X1 = 1)] = 1. The intervention on the parent of the reward
(Pa(Y ) = X2) is suboptimal because E[Y |do(X2 = 0)] = E[Y |do(X2 = 1)] = 0.5. The example Y V1
V2 V3 (a) G Y V1
V2 V3"
POSSIBLY OPTIMAL ARMS IN CAUSAL BANDITS WITH UNKNOWN CAUSAL GRAPH,0.02529960053262317,"(b) G1 Y V1
V2 V3"
POSSIBLY OPTIMAL ARMS IN CAUSAL BANDITS WITH UNKNOWN CAUSAL GRAPH,0.02663115845539281,"(c) G2 Y V1
V2 V3"
POSSIBLY OPTIMAL ARMS IN CAUSAL BANDITS WITH UNKNOWN CAUSAL GRAPH,0.02796271637816245,(d) G3
POSSIBLY OPTIMAL ARMS IN CAUSAL BANDITS WITH UNKNOWN CAUSAL GRAPH,0.02929427430093209,Figure 1: True Causal Graph G with four other graphs each with one missing bi-directed edge.
POSSIBLY OPTIMAL ARMS IN CAUSAL BANDITS WITH UNKNOWN CAUSAL GRAPH,0.03062583222370173,"shows that it is possible to construct SCMs where optimal intervention is on ancestors of the reward
node instead of parents when reward node is confounded with one of its ancestors. The authors in [5]
propose a graphical criterion to enumerate the set of all possibly optimal arms, which they refer to as
POMISs. We revisit some definitions and results from their work.
Definition 3.1. (Unobserved Confounder (UC)-Territory[5]) Consider a causal graph G(V, E)
with a reward node Y and let H be G[An(Y )]. A set of variables T ⊆V (H) containing Y is called
an UC-territory on G with respect to Y if DeH(T) = T and CCH(T) = T."
POSSIBLY OPTIMAL ARMS IN CAUSAL BANDITS WITH UNKNOWN CAUSAL GRAPH,0.03195739014647137,"A UC-territory is minimal if none of its subsets are UC-territories. A minimal UC-territory denoted
by MUCT(G, Y ), can be constructed by extending a set of variables, starting from the reward {Y },
alternatively updating the set with the c-component and descendants of the set until there is no change.
Definition 3.2. (Interventional Border)[5] Let T be a minimal UC-territory on G with respect to Y .
Then, X = Pa(T) \ T is called an interventional border for G w.r.t. Y denoted by IB(G, Y )."
POSSIBLY OPTIMAL ARMS IN CAUSAL BANDITS WITH UNKNOWN CAUSAL GRAPH,0.033288948069241014,"Lemma 3.1. [5] For causal graph G with reward Y , IB(GW, Y )is a POMIS, for any W ⊆V \ {Y }."
POSSIBLY OPTIMAL ARMS IN CAUSAL BANDITS WITH UNKNOWN CAUSAL GRAPH,0.03462050599201065,"Although the graphical characterization in Lemma 3.1 provides a means to enumerate the complete
set of POMISs, it comes with exponential time complexity. The authors also propose an efficient
algorithm for enumerating all POMISs in [5]. However, this requires knowing the true causal
graph, and without it, one has to consider interventions on all possible subsets of nodes, which are
exponentially many. One naive approach to tackle the problem is to learn the full causal graph with all
confounders to list all POMISs. However, a question arises: Do we need to learn/detect all possible
confounders since the goal is to find POMISs and not the full graph?"
POSSIBLY OPTIMAL ARMS IN CAUSAL BANDITS WITH UNKNOWN CAUSAL GRAPH,0.03595206391478029,"Before answering the above question, we start with an example considering the causal graphs in Figure
1. Using Lemma 3.1, the set of POMISs for the true graph G is IG = {ϕ, {V1}, {V2}, {V3}, {V1, V2}}.
However, for G1 which has the bidirected edge V2 ↔Y missing, the set of POMISs is IG1 =
{ϕ, {V2}, {V1, V2}}. Also for G2 which has the bidirected edge V1 ↔V2 missing, the set of POMISs
is IG2 = {ϕ, {V1}, {V2}, {V1, V2}}. In both cases, we miss at least one POMIS, and since it is
possible to construct an SCM compatible with the true causal graph G where any arm in POMIS
is optimal, if this arm is not learned, we can suffer linear regret [5]. Although the graph G3 has
the bidirected edge V1 ↔V3 missing, it still has the same set of POMISs as the true graph, i.e.,
IG3 = {ϕ, {V1}, {V2}, {V3}, {V1, V2}}. This example shows that only a subset of latent confounders
affect the POMISs learned from the graph. We formally prove that it is necessary and sufficient to
learn/detect all latent variables between the reward and its ancestors because missing any one of them
will cause us to miss at least one of POMISs leading to linear regret for some bandit instances.
Lemma 3.2. It is necessary to learn/detect the latent confounders between reward node Y and any
node X ∈An(Y ) in causal graph G to learn all the POMISs correctly and hence avoid linear regret.
Theorem 3.1. Consider a causal graph G(V, E) and another causal graph G′ such that they have
the same vertex set and directed edges but differ in bidirected edges, with the bidirected edges in G′
being a subset of the bidirected edges in G. The graphs will yield different collections of POMISs if
and only if there exists some Z ∈An(Y ) such that either (a) or (b) is true:"
POSSIBLY OPTIMAL ARMS IN CAUSAL BANDITS WITH UNKNOWN CAUSAL GRAPH,0.037283621837549935,(a) There is a bi-directed edge between Z and Y in G but not in G′ .
POSSIBLY OPTIMAL ARMS IN CAUSAL BANDITS WITH UNKNOWN CAUSAL GRAPH,0.03861517976031957,"(b) Neither of the graphs G′ and G have a bidirected edge between Z and Y , and there exists a
bidirected edge in G between some X ∈MUCT(G′"
POSSIBLY OPTIMAL ARMS IN CAUSAL BANDITS WITH UNKNOWN CAUSAL GRAPH,0.03994673768308921,"Pa(Z),Bi(Z,G′) , Y ) and Z but not in G′."
POSSIBLY OPTIMAL ARMS IN CAUSAL BANDITS WITH UNKNOWN CAUSAL GRAPH,0.041278295605858856,"We extend Lemma 3.2 to provide necessary and sufficient conditions in Theorem 3.1 characterizing
all the latent variables that need to be learned, ensuring that the POMISs learned from a sparser causal"
POSSIBLY OPTIMAL ARMS IN CAUSAL BANDITS WITH UNKNOWN CAUSAL GRAPH,0.0426098535286285,"graph match all those in the true causal graph. Suppose we have access to the induced observable
subgraph G′ on ancestors of the reward node. We can start by testing for latent confounders between
Y and any node in An(Y ). Then, we need to test for latent confounders between any pair Z ∈An(Y )
such that Z and Y don’t have a bi-directed edge between them, and X ∈MUCT(G′"
POSSIBLY OPTIMAL ARMS IN CAUSAL BANDITS WITH UNKNOWN CAUSAL GRAPH,0.043941411451398134,"Pa(Z),Bi(Z,G′) , Y )
until there are no new pairs to test. Theorem 3.1 can be useful because depending on the underlying
causal graph, it saves us the number of latent confounders we need to test. For instance, consider a
causal graph that has the reward Y with n different parent nodes, i.e., Pa(Y ) = {V1, V2, . . . , Vn},
with no edges between the parents. In cases where every parent of Y is confounded with Y , or when
none of them is confounded with Y , we only need to test for |An(Y )| latent variables, as implied by
Theorem 3.1. However, in the worst-case scenario, we would need to test
 |An(Y )|+1
2

latent variables
when the true graph only has the confounders V1 ←→Y and Vi ←→Vi+1 for all i = 1, .., n −1. The
exact number of latents we need to test can range from |An(Y )| to
 |An(Y )|+1
2

depending on the true
graph. One issue still remains: we need a sample-efficient algorithm to learn the induced observable
graph over An(Y ) and to test the presence of confounders, which is addressed in upcoming sections."
FINITE SAMPLE CAUSAL DISCOVERY ALGORITHM,0.045272969374167776,"4
Finite Sample Causal Discovery Algorithm"
FINITE SAMPLE CAUSAL DISCOVERY ALGORITHM,0.04660452729693742,"In this section, we propose a sample-efficient algorithm to learn causal graphs with latent confounders.
We propose a two-phase approach. In the first phase, the algorithm learns the observable graph
structure, i.e., the induced graph between observed variables. In the second phase, it detects the
latent confounders. In the next section, we use the proposed discovery algorithm to construct the
algorithm for causal bandits with an unknown graph. We begin by proposing two Lemmas to learn
the ancestrality relations and latent confounders using interventions."
FINITE SAMPLE CAUSAL DISCOVERY ALGORITHM,0.047936085219707054,"Lemma 4.1. Consider a causal graph G(V, E) and W ⊆V. Furthermore, let X, T ∈V \ W be
any two variables. Under the faithfulness Assumption 2.1 (X ∈An(T))GW if and only if for any
w ∈[K]|W|, we have P(t|do(w)) ̸= P(t|do(w), do(x)) for some x, t ∈[K]."
FINITE SAMPLE CAUSAL DISCOVERY ALGORITHM,0.0492676431424767,"Lemma 4.2. Consider two variables Xi and Xj such that Xj /∈An(Xi) and a set of variables
(Pa(Xi) ∪Pa(Xj) \ {Xi}) ⊆W and Xi, Xj /∈W. Under the faithfulness Assumption 2.1 there
is latent confounder between Xi and Xj if and only if for any w ∈[K]|W|, we have P(xj |
do(xi), do(W = w)) ̸= P(xj | xi, do(W = w)) for some realization xi, xj ∈[K]."
FINITE SAMPLE CAUSAL DISCOVERY ALGORITHM,0.05059920106524634,"These Lemmas are modified versions of Lemma 1 in [14] and Interventional Do-see test in [14],
respectively. The difference between Lemma 4.1 and Lemma 1 in [14] is that we have an inequality
test that can be used in the sample-efficient discovery instead of a statistical independence test. The
Interventional Do-see test in [14] is valid for adjacent nodes only; however, our Lemma 4.2 can be
used to test presence of latent confounder between any pair of nodes. This is because the condition in
Lemma 4.2, Xj /∈An(Xi), can always be satisfied for any pair by flipping the order when one node
is an ancestor of the other. In order to provide theoretical guarantees on sampling complexity, the
inequality conditions are not enough; we need to assume certain gaps similar to [7, 9, 17]."
FINITE SAMPLE CAUSAL DISCOVERY ALGORITHM,0.05193075898801598,"Assumption 4.1. Consider a causal graph G(V, E) and W ⊆V. Furthermore, let X, T ∈V \ W
be any two variables. Then, we have (X ∈An(T))GW if and only if for any w ∈[K]|W|, we have
|P(t|do(w)) −P(t|do(w), do(x))| > ϵ for some x, t ∈[K], where ϵ > 0 is some constant."
FINITE SAMPLE CAUSAL DISCOVERY ALGORITHM,0.05326231691078562,"Assumption 4.2. Consider two variables Xi and Xj such that Xj /∈An(Xi) and a set of variables
(Pa(Xi)∪Pa(Xj)\{Xi}) ⊆W and Xi, Xj /∈W. There is a latent confounder or a bidirected edge
between Xi and Xj if and only if for any w ∈[K]|W|, we have
P(xj | do(xi), do(W = w))−P(xj |
xi, do(W = w))
 > γ
for some realization xi, xj ∈[K] and some constant γ > 0."
LEARNING THE OBSERVABLE GRAPH,0.05459387483355526,"4.1
Learning the Observable Graph"
LEARNING THE OBSERVABLE GRAPH,0.0559254327563249,"We propose Algorithm 1 to learn the transitive closure under any arbitrary intervention do(W),
denoted by Gtc"
LEARNING THE OBSERVABLE GRAPH,0.05725699067909454,"W. We use the Assumption 4.1 to bound the number of samples for ancestrality tests.
We start with an empty graph and add edges by running ancestrality tests for all pairs of nodes in
V\W, resulting in the transitive closure Gtc"
LEARNING THE OBSERVABLE GRAPH,0.05858854860186418,"W. We recall that the transitive reduction Tr(G) = (V, Er)
of a DAG G = (V, E) is unique, with Er ⊆E, and it can be computed in polynomial time [25]. Also,
note that Tr(G) = Tr(Gtc). We propose a randomized Algorithm 2 similar to the one proposed in"
LEARNING THE OBSERVABLE GRAPH,0.05992010652463382,"Algorithm 1: Learn the Transitive Closure of the Causal Graph under any intervention, i.e., Gtc W"
LEARNING THE OBSERVABLE GRAPH,0.06125166444740346,"1 Function LearnTransitiveClosure(V, W, δ1, δ2):"
LEARNING THE OBSERVABLE GRAPH,0.06258322237017311,"2
E = ∅, Fix some w ∈[K]|W| and A = max( 8"
LEARNING THE OBSERVABLE GRAPH,0.06391478029294274,"ϵ2 ,
8
γ2 ) log 2nK2"
LEARNING THE OBSERVABLE GRAPH,0.06524633821571238,"δ1
and B =
8
ϵ2 log 2nK2"
LEARNING THE OBSERVABLE GRAPH,0.06657789613848203,"δ2
3
Get B samples from do(W = w)"
LEARNING THE OBSERVABLE GRAPH,0.06790945406125166,"4
Get A samples from every do(Xi = xi, W = w) ∀Xi ∈V \ W and ∀xi ∈[K]"
LEARNING THE OBSERVABLE GRAPH,0.0692410119840213,"5
for every pair Xi, Xj ∈V \ W do"
LEARNING THE OBSERVABLE GRAPH,0.07057256990679095,"6
Use the Interventional Data to Test if (Xi ∈An(Xj))GW"
LEARNING THE OBSERVABLE GRAPH,0.07190412782956059,"7
if ∃xi, xj ∈[K] s.t. | bP(xj|do(w)) −bP(xj|do(w), do(xi))| > ϵ"
THEN,0.07323568575233022,2 then
THEN,0.07456724367509987,"8
E ←−E ∪(Xi, Xj)"
THEN,0.0758988015978695,"9
return The graph’s transitive closure (V, E) and All Interventional data"
END FUNCTION,0.07723035952063914,10 End Function
END FUNCTION,0.07856191744340879,Algorithm 2: Learn the Observable Graph
END FUNCTION,0.07989347536617843,"1 Function LearnObservableGraph(V, α, dmax, δ1, δ2):"
END FUNCTION,0.08122503328894808,"2
E = ∅& IData = ∅"
END FUNCTION,0.08255659121171771,"3
for i = 1 : 8α dmax log(n) do"
END FUNCTION,0.08388814913448735,"4
W = ∅"
END FUNCTION,0.085219707057257,"5
for Vi ∈V do"
END FUNCTION,0.08655126498002663,"6
W ←−W ∪Vi with probability 1 −
1
2dmax"
GTC,0.08788282290279627,"7
Gtc"
GTC,0.08921438082556592,"W, DataW = LearnTransitiveClosure(V, W, δ1, δ2)"
GTC,0.09054593874833555,"8
Compute the transitive reduction Tr(Gtc"
GTC,0.09187749667110519,W) & add any missing edges from Tr(Gtc
GTC,0.09320905459387484,W) to E
GTC,0.09454061251664447,"9
IData = IData ∪DataW (Keep Saving Interventional Data)"
GTC,0.09587217043941411,"10
return The observable graph structure (V, E) and interventional data samples in IData"
END FUNCTION,0.09720372836218376,11 End Function
END FUNCTION,0.0985352862849534,"[14] that repeatedly uses Algorithm 1 to learn the observable graph structure. The motivation behind
the randomized Algorithm 2 is Lemma 5 from [14], which states that for any edge (Xi, Xj), consider
a set of variables W such that {Wi : π(Wi) > π(Xi) & Wi ∈Pa(Xj)} ⊆W where π is any total
order that is consistent with the partial order implied by the DAG, i.e., π(X) < π(Y ) iff X ∈An(Y ).
In this case, the edge (Xi, Xj) will be present in the graph Tr(GW). Algorithm 2 randomly selects
W, computes the transitive reduction of the post-interventional graphs, and finally accumulates all
edges found in the transitive reduction across iterations. Algorithm 2 takes a parameter dmax, which
must be greater than or equal to the highest graph degree for our theoretical guarantees to hold."
END FUNCTION,0.09986684420772303,Lemma 4.3. Suppose that the Assumption 4.1 holds and we have access to max( 8
END FUNCTION,0.10119840213049268,"ϵ2 , 8"
END FUNCTION,0.10252996005326231,γ2 ) log 2K2
END FUNCTION,0.10386151797603196,"δ1
samples from do(Xi = xi, W = w) ∀xi ∈[K] and 8"
END FUNCTION,0.1051930758988016,ϵ2 log 2K2
END FUNCTION,0.10652463382157124,"δ2 samples from do(W = w) for a fixed
w ∈[K]|W| and W ⊆V. Then, with probability at least 1 −δ1 −δ2, we have (Xi ∈An(Xj))GW if
and only if ∃xi, xj ∈[K] s.t.
 bP(xj | do(w)) −bP(xj | do(w), do(xi))
 > ϵ 2."
END FUNCTION,0.10785619174434088,"Lemma 4.3 provides the sample complexity for running ancestrality tests. Algorithm 1 selects a
realization w ∈[K]|W|, takes B samples from the intervention do(W = w), and A samples from
every do(Xi = xi, W = w) for all Xi ∈V \ W and xi ∈[K] interventions. Thus, in the worst
case, Algorithm 1 requires KAn+B samples to learn the true transitive closure with high probability.
We formally prove this result in the Lemma 4.4.
Lemma 4.4. Algorithm 1 learns the true transitive closure under any intervention, i.e., Gtc"
END FUNCTION,0.10918774966711052,"W, with
probability at least 1 −nδ1 −δ2 with a maximum KAn + B interventional samples. If we set
δ1 =
δ
2n and δ2 = δ"
END FUNCTION,0.11051930758988016,"2, then Algorithm 1 learns true transitive closure with probability at least 1 −δ."
END FUNCTION,0.1118508655126498,"Algorithm 2 repeatedly invokes Algorithm 1 to learn Tr(GW) for randomly sampled W. Through
this iterative process, it accumulates edges across iterations, ultimately constructing the observable
graph structure. To establish the sampling complexity guarantee for Algorithm 2, we leverage the
result from Lemma 4.4. The Theorem 4.1 gives the sampling complexity for learning the true
observable graph with high probability."
END FUNCTION,0.11318242343541944,"Theorem 4.1. Algorithm 2 learns the true observable graph with probability at least 1−
1"
END FUNCTION,0.11451398135818908,"n
α
2dmax −2 −"
END FUNCTION,0.11584553928095873,"8αdmax log(n)(nδ1 + δ2) with 8αdmax log n(KAn + B) interventional samples. If we set α =
2dmax log ( 2"
END FUNCTION,0.11717709720372836,"δ +2)
log n
, δ1 =
δ
32αdmaxn log n and δ2 =
δ
32αdmax log n, then Algorithm 2 learns the true"
END FUNCTION,0.118508655126498,"observable graph with probability at least of 1 −δ. (We have A = max

8
ϵ2 , 8"
END FUNCTION,0.11984021304926765,"γ2

log 2nK2 δ1
&"
END FUNCTION,0.12117177097203728,"B =
8
ϵ2 log 2nK2"
END FUNCTION,0.12250332889480692,"δ2
as in line 2 of Algorithm 1.)"
LEARNING THE LATENT CONFOUNDERS,0.12383488681757657,"4.2
Learning the Latent Confounders"
LEARNING THE LATENT CONFOUNDERS,0.12516644474034622,"Assumption 4.2 can be used to test for latents between any pair of observed variables. Note that while
using Algorithm 2, we save and return all the interventional data samples. These samples can be reused
to detect latent confounders in the next phase. For any variables Xi and Xj such that Xj /∈An(Xi),
we need access to interventional samples do(W = w) such that (Pa(Xi) ∪Pa(Xj) \ {Xi}) ⊆W
and Xi & Xj /∈W. In the supplementary material, we demonstrate that randomly selecting
the target set W in Algorithm 2 ensures that we have access to all such datasets for all pairs of
observed variables with high probability. In addition to simple causal effects we need to estimate
the conditional causal effect of the form P(xj|xi, do(W = w)). To bound the number of samples
required to ensure accurate estimation of the conditional causal effects, we rely on Assumption 4.3.
Note that Assumption 4.3 does not restrict the applicability of our algorithm; it simply assumes that
under an intervention do(W = w), either the probability of observing a realization Xi = xi is zero
or is lower-bounded by some constant η > 0. The role of this assumption is to bound the number of
interventional samples required for accurate estimation of the conditional causal effects."
LEARNING THE LATENT CONFOUNDERS,0.12649800266311584,"Assumption 4.3. For any variable Xi ∈V and any intervention do(W = w) where W ⊆V and
w ∈[K]|W|, we assume that either P(xi|do(W = w)) = 0 or P(xi|do(W = w)) ≥η > 0."
LEARNING THE LATENT CONFOUNDERS,0.1278295605858855,Algorithm 3: Learn the Causal Graph along-with the Latent Confounders
LEARNING THE LATENT CONFOUNDERS,0.12916111850865514,"1 Function LearnCausalGraph(α, dmax, δ1, δ2, δ3, δ4):"
LEARNING THE LATENT CONFOUNDERS,0.13049267643142476,"2
G, IData = LearnObservableGraph(α, dmax, δ1, δ2)"
LEARNING THE LATENT CONFOUNDERS,0.1318242343541944,"3
C =
16
ηγ2 log( 2n2K2"
LEARNING THE LATENT CONFOUNDERS,0.13315579227696406,"δ3
) +
1
2η2 log( 2n2K2"
LEARNING THE LATENT CONFOUNDERS,0.13448735019973368,"δ4
), B =
8
ϵ2 log 2nK2"
LEARNING THE LATENT CONFOUNDERS,0.13581890812250333,"δ2
4
for every pair Xi, Xj ∈V do"
LEARNING THE LATENT CONFOUNDERS,0.13715046604527298,"5
If Xj ∈An(Xi), swap them."
LEARNING THE LATENT CONFOUNDERS,0.1384820239680426,"6
Find interventional data sets do(W = w) and do(Xi = xi, W = w) from IData s.t.
(Pa(Xi) ∪Pa(Xj) \ {Xi}) ⊆W and Xi & Xj /∈W"
LEARNING THE LATENT CONFOUNDERS,0.13981358189081225,"7
Get max(0, C −B) new samples for do(W = w)"
LEARNING THE LATENT CONFOUNDERS,0.1411451398135819,"8
if ∃xi, xj ∈[K] s.t. | bP(xj|do(xi), do(w)) −bP(xj|xi, do(w))| > γ"
THEN,0.14247669773635152,2 then
THEN,0.14380825565912117,"9
Add bi-directed edge Xi ←→Xj to graph G"
RETURN THE CAUSAL GRAPH WITH LATENT CONFOUNDERS G,0.14513981358189082,"10
return The Causal Graph with Latent Confounders G"
END FUNCTION,0.14647137150466044,11 End Function
END FUNCTION,0.1478029294274301,"Lemma 4.5. Consider two nodes Xi and Xj s.t. Xj /∈An(Xi) and suppose that Assumptions
2.1 4.2 hold and we have access to max( 8"
END FUNCTION,0.14913448735019974,"ϵ2 , 8"
END FUNCTION,0.15046604527296936,γ2 ) log 2K2
END FUNCTION,0.151797603195739,"δ1
samples from do(Xi = xi, W = w)"
END FUNCTION,0.15312916111850866,"∀xi ∈[K] and
16
ηγ2 log( 2K2"
END FUNCTION,0.15446071904127828,"δ3 ) +
1
2η2 log( 2K2"
END FUNCTION,0.15579227696404793,δ4 ) samples from do(W = w) for a fixed w ∈[K]|W|
END FUNCTION,0.15712383488681758,"and W ⊆V such that (Pa(Xi) ∪Pa(Xj) \ {Xi}) ⊆W and Xi & Xj /∈W. Then, with
probability at least 1 −δ1 −δ3 −δ4, we have a latent confounder between Xi and Xj iff ∃xi, xj ∈
[K] s.t.
 bP(xj|do(xi), do(w)) −bP(xj|xi, do(w))
 > γ 2 ."
END FUNCTION,0.1584553928095872,"Lemma 4.5 establishes the sample complexity for detecting the presence of latent confounders for
any pair of nodes in the causal graph. Using results from Theorem 4.1 and Lemma 4.5, we bound
the number of interventions required by the proposed Algorithm 3 to learn the causal graph along
with the latent confounders. Theorem 4.2 provides the sample complexity guarantee for Algorithm 3
to learn the true causal graph, including all latent confounders, with a given confidence level. An
important feature of the sampling complexity result in Theorem 4.2 is that the number of intervention
samples needed to learn the causal graph scales polynomially with the number of nodes n."
END FUNCTION,0.15978695073235685,"Theorem 4.2. Algorithm 3 learns the true causal graph with latents with probability at least
1 −
2"
END FUNCTION,0.1611185086551265,"n
α
2dmax −2 −8αdmax log(n)(nδ1 + (δ2 + δ3 + δ4)) with a maximum of 8αdmax log n(KAn +"
END FUNCTION,0.16245006657789615,"max(B, C)) interventional samples. If we set α = 2dmax log ( 4"
END FUNCTION,0.16378162450066577,"δ +2)
log n
, δ1 =
δ
64αdmaxn log n and δ2 =
δ3 = δ4 =
δ
64αdmax log n, then Algorithm 3 learns the true causal graph with probability at least
1 −δ.
(A and B are given by line 2 of Algorithm 1 and C is given by line 3 of Algorithm 3.)"
END FUNCTION,0.16511318242343542,"Suppose the constant gaps ϵ and γ in Assumptions 4.1 and 4.2 are close; then, we have C > 1"
END FUNCTION,0.16644474034620507,"ηA ≥
1
ηB. The value of the constant 0 < η < 1 is usually small in practical scenarios, so the quantity C is
much greater than both B or A. This implies that the number of samples required to test the presence
of latent variables is greater than that required to learn ancestral relations. This is because we need to
accurately estimate conditional causal effects to detect latent variables, which requires a large number
of samples compared to simple causal effects. Theorem 3.1 is useful here because it shows that we
do not need to test for confounders between all pairs of nodes among ancestors of the reward node to
learn the POMIS set."
ALGORITHM FOR CAUSAL BANDITS WITH UNKNOWN GRAPH STRUCTURE,0.1677762982689747,"5
Algorithm for Causal Bandits with Unknown Graph Structure"
ALGORITHM FOR CAUSAL BANDITS WITH UNKNOWN GRAPH STRUCTURE,0.16910785619174434,"Algorithm 4 is the sketch of our algorithm for causal bandits with unknown graph structure. The
detailed algorithm with all steps explained is given in the supplementary material (Algorithm 6).
Algorithm 4 first learns the transitive closure of the graph Gtc to find ancestors of the reward node
Y . This is because POMISs are only subsets of An(Y ). The next step is to learn the observed graph
structure among the reward Y and nodes in An(Y ). Instead of detecting the presence of confounders
between all pairs of nodes in An(Y ) as in Algorithm 3, we focus on identifying the necessary and
sufficient ones, as characterized by Theorem 3.1. This approach is more sample-efficient since it
tests for fewer latent confounders. The exact saving in terms of samples depends on the underlying
causal graph and is hard to characterize in general. The last step of Algorithm 4 is to run a simple
bandit algorithm, e.g., UCB algorithm [26], to identify the optimal arm from the POMISs. Given that
Assumptions 4.1, 4.2, and 4.3 hold, and the reward is binary (Y ∈{0, 1}), using the results from
Lemma 4.4 and Theorem 4.2, we provide a worst-case regret bound for Algorithm 4 in Theorem 5.1."
ALGORITHM FOR CAUSAL BANDITS WITH UNKNOWN GRAPH STRUCTURE,0.170439414114514,Algorithm 4: Sketch of Algorithm for causal bandits with unknown graph structure
ALGORITHM FOR CAUSAL BANDITS WITH UNKNOWN GRAPH STRUCTURE,0.17177097203728361,"1 Calculate α, δ1, δ2, δ3, δ4 as in Theorem 5.1"
ALGORITHM FOR CAUSAL BANDITS WITH UNKNOWN GRAPH STRUCTURE,0.17310252996005326,"2 Gtc = LearnTransitiveClosure(W = ϕ,
δ
2n, δ n)"
ALGORITHM FOR CAUSAL BANDITS WITH UNKNOWN GRAPH STRUCTURE,0.1744340878828229,"3 G, IData = LearnObservableGraph(An(Y )Gtc, α, dmax, δ1, δ2)"
ALGORITHM FOR CAUSAL BANDITS WITH UNKNOWN GRAPH STRUCTURE,0.17576564580559254,4 # Learn the bi-directed edges between reward Y and all nodes Xi ∈An(Y ) and update G.
ALGORITHM FOR CAUSAL BANDITS WITH UNKNOWN GRAPH STRUCTURE,0.17709720372836218,5 for every Xi ∈An(Y )Gtc do
ALGORITHM FOR CAUSAL BANDITS WITH UNKNOWN GRAPH STRUCTURE,0.17842876165113183,"6
G = DetectLatentConfounder(G, Xi, Xj, δ2, δ3, δ4, IData) (Algorithm 5)"
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.17976031957390146,7 while There is a new pair that is tested do
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.1810918774966711,"8
Find a new pair (Z, X) s.t. Z ∈An(Y ) such that Z and Y don’t have a bi-directed edge between them
in G and X ∈MUCT(GPa(Z),Bi(Z,G), Y ) and test for the latent and update G."
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.18242343541944075,"9
G = DetectLatentConfounder(G, Z, X, δ2, δ3, δ4, IData)"
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.18375499334221038,10 Learn the set of POMISs IG from the graph G (Using Algorithm 1 from [5]).
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.18508655126498003,11 Run UCB algorithm over the arm set A = {Ω(I) | ∀I ∈IG}.
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.18641810918774968,"Theorem 5.1. Algorithm 4 learns the true set of POMISs with probability at least 1 −2δ. Under the
event that it learns POMISs correctly, the cumulative regret is bounded as follows:"
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.1877496671105193,"RT ≤Kn max
 8"
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.18908122503328895,"ϵ2 , 8 γ2"
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.1904127829560586,"
log 4n2K2"
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.19174434087882822,"δ
+
8
ϵ2 log 4nK2 δ
+"
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.19307589880159787,8αdmax
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.19440745672436752,"
KA
An(Y )
 + max(B, C)

log
 An(Y )

+
X"
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.19573901464713714,"s∈{Ω(I)|∀I∈IG}
∆do(s)"
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.1970705725699068,"
1 + log T"
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.19840213049267644,"∆2
do(s) 
,"
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.19973368841544606,"where A and B are given by line 2 of Algorithm 1, and C is given by line 3 of Algorithm 3 by setting
α = 2dmax log ( 4 δ +2)"
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.2010652463382157,"log
An(Y )

, δ1 =
δ"
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.20239680426098536,"64αdmax
An(Y )
 log
An(Y )
 and δ2 = δ3 = δ4 =
δ"
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.20372836218375498,"64αdmax log
An(Y )
."
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.20505992010652463,"The first three terms in the regret bound correspond to the interventional samples required to learn
the ancestors of the reward node, and then the set of POMISs (IG). The last term corresponds to the
regret incurred by running the UCB algorithm over the POMIS set. The number of interventional
samples used to learn the true set of POMISs, with high probability, has polynomial scaling with
respect to the number of nodes n in the graph. However, the total number of arms in the POMIS
set, in the worst case, can exhibit exponential scaling with respect to the number of ancestors of
the reward node |An(Y )|. The advantage of sample-efficient discovery is that it helps us reduce the
action space before applying the UCB algorithm. If the graph is not densely confounded, the total
number of arms in the POMIS set would be small, and running causal discovery before the bandit
algorithm is advantageous. Without discovery, one would always have to run the UCB or a standard
MAB solver with exponentially many arms. For instance, if the causal graph has n nodes, there will
be Pn
i=1
 n
i

Ki = (K + 1)n different possible arms/interventions."
EXPERIMENTS,0.20639147802929428,"6
Experiments"
EXPERIMENTS,0.20772303595206393,"Theorem 5.1 establishes the worst-case upper bound for cumulative regret when we need to test latent
confounders between all pairs of nodes within An(Y ). However, Algorithm 4 selectively examines
only a subset of latent confounders sufficient to infer the true POMIS set, as outlined in Theorem
3.1. Although the advantage is hard to quantify in general, we demonstrate it using simulations on
randomly generated graphs. We sample a random ordering σ among the vertices. Then, for each nth
node, we determine its in-degree as Xn = max(1, Bin(n −1, ρ)), followed by selecting its parents
through uniform sampling from the preceding nodes in the ordering. Finally, we chordalize the graph
using the elimination algorithm [27], employing an elimination ordering that is the reverse of σ.
Additionally, we introduce a confounder between every pair of nodes with a probability of ρL. For
all the simulations, we randomly sample 50 causal graphs with different values of densities ρ and
ρL and assume that all variables are binary for simplicity, i.e., K = 2. We set the value of δ to 0.99,
and the gaps γ = ϵ = 0.01 and η = 0.05. We plot interventional samples used to learn the induced
observable graph on An(Y ) with and without latent confounders, as well as the samples required to
learn the POMIS set by Algorithm 4. The width of confidence interval is set to 2 standard deviations."
EXPERIMENTS,0.20905459387483355,"Figure 2: Simulations to demonstrate the advantage of Algorithm 4 over full graph discovery
(Learning all possible latents)"
EXPERIMENTS,0.2103861517976032,"The simulation results in Figure 2 demonstrate that Algorithm 4 requires fewer samples than learning
the induced graph on An(Y ), which includes all confounders. However, as ρL increases for a fixed
ρ, this advantage diminishes, as illustrated in Figure 2. The trend remains consistent as the density
parameters ρ and ρL are varied from 0.2, 0.4, and 0.6. The plots in Figure 3 compare the exponentially"
EXPERIMENTS,0.21171770972037285,"growing arms in causal bandits with intervention samples used by our algorithm to learn the reduced
action set in the form of POMISs. This demonstrates the major advantage of our algorithm, which,
instead of exploring an exponentially large action set as in naive UCB algorithms, uses interventions
to reduce the action space to the POMIS set before applying the UCB algorithm. Additionally, the
number of intervention samples required in the first phase of identifying the true POMIS set grows
polynomially with respect to the number of nodes in the graph. However, the number of arms in the
POMIS set can still exhibit exponential scaling with respect to the number of ancestors of the reward
node in the worst case."
EXPERIMENTS,0.21304926764314247,"(a) ρ = 0.4, ρL = 0.2
(b) ρ = 0.4, ρL = 0.4
(c) ρ = 0.4, ρL = 0.6"
EXPERIMENTS,0.21438082556591212,Figure 3: Simulations to demonstrate advantage of discovery for causal bandits.
EXPERIMENTS,0.21571238348868177,"(a) Nodes n = 10
(b) Nodes n = 15
(c) Nodes n = 20"
EXPERIMENTS,0.2170439414114514,Figure 4: Cumulative regret for Algorithm 4 versus learning all possible latents (ρ = ρL = 0.3).
EXPERIMENTS,0.21837549933422104,"We also run the UCB algorithm on the learned POMIS set and plot the cumulative regret in Figure 4.
Since the number of time steps T is on the order of 108, it is not feasible to store and plot cumulative
regret for every time step over multiple randomly sampled graphs; therefore, we downsample the
cumulative regret to show the overall trend. The downsampling, along with the large scale of the
y-axis, makes the regret in the discovery phase appear linear with a fixed slope, although it is piece-
wise linear if we zoom in. Also, the UCB phase converges very fast compared to the discovery phase
because the number of POMISs for randomly sampled graphs is small. We plot the results for graphs
with 10, 15, and 20 nodes, and in all cases, we can see the advantage of partial discovery compared to
full discovery, since Algorithm 4 finds the POMIS set with fewer samples. The code to reproduce
our experimental results is available at https://github.com/CausalML-Lab/CausalBandits_
with_UnknownGraph."
CONCLUSION,0.2197070572569907,"7
Conclusion"
CONCLUSION,0.2210386151797603,"We show that partial discovery is sufficient to achieve sublinear regret for causal bandits with an
unknown causal graph containing latent confounders. Without relying on causal discovery, one must
consider interventions on all possible subsets of nodes, which is infeasible. Therefore, we propose a
two-phase approach: the first phase learns the induced subgraph of the ancestors of the reward node,
along with a subset of confounders, to construct a set of possibly optimal arms. We demonstrate that
the number of interventional samples in the first phase required to identify the POMIS set scales
polynomially with respect to the number of nodes in the causal graph. In the next phase, we apply
the Upper Confidence Bound (UCB) algorithm to the reduced action space to find the optimal arm."
ACKNOWLEDGMENT,0.22237017310252996,"8
Acknowledgment"
ACKNOWLEDGMENT,0.2237017310252996,"Murat Kocaoglu acknowledges the support of NSF CAREER 2239375, IIS 2348717, Amazon
Research Award and Adobe Research."
REFERENCES,0.22503328894806923,References
REFERENCES,0.22636484687083888,"[1] Finnian Lattimore, Tor Lattimore, and Mark D Reid. Causal bandits: Learning good interven-
tions via causal inference. Advances in Neural Information Processing Systems, 29, 2016."
REFERENCES,0.22769640479360853,"[2] Rajat Sen, Karthikeyan Shanmugam, Alexandros G Dimakis, and Sanjay Shakkottai. Identifying
best interventions through online importance sampling. In International Conference on Machine
Learning, pages 3057–3066. PMLR, 2017."
REFERENCES,0.22902796271637815,"[3] Yangyi Lu, Amirhossein Meisami, Ambuj Tewari, and William Yan. Regret analysis of bandit
problems with causal background knowledge. In Conference on Uncertainty in Artificial
Intelligence, pages 141–150. PMLR, 2020."
REFERENCES,0.2303595206391478,"[4] Vineet Nair, Vishakha Patil, and Gaurav Sinha. Budgeted and non-budgeted causal bandits. In
International Conference on Artificial Intelligence and Statistics, pages 2017–2025. PMLR,
2021."
REFERENCES,0.23169107856191745,"[5] Sanghack Lee and Elias Bareinboim. Structural causal bandits: Where to intervene? Advances
in neural information processing systems, 31, 2018."
REFERENCES,0.23302263648468707,"[6] Lai Wei, Muhammad Qasim Elahi, Mahsa Ghasemi, and Murat Kocaoglu. Approximate
allocation matching for structural causal bandits with unobserved confounders. Advances in
Neural Information Processing Systems, 36, 2024."
REFERENCES,0.23435419440745672,"[7] Yangyi Lu, Amirhossein Meisami, and Ambuj Tewari. Causal bandits with unknown graph
structure. Advances in Neural Information Processing Systems, 34:24817–24828, 2021."
REFERENCES,0.23568575233022637,"[8] Arnoud De Kroon, Joris Mooij, and Danielle Belgrave. Causal bandits without prior knowledge
using separating sets. In Conference on Causal Learning and Reasoning, pages 407–427.
PMLR, 2022."
REFERENCES,0.237017310252996,"[9] Mikhail Konobeev, Jalal Etesami, and Negar Kiyavash. Causal bandits without graph learning.
arXiv preprint arXiv:2301.11401, 2023."
REFERENCES,0.23834886817576564,"[10] Alan Malek, Virginia Aglietti, and Silvia Chiappa. Additive causal bandits with unknown graph.
arXiv preprint arXiv:2306.07858, 2023."
REFERENCES,0.2396804260985353,"[11] Jonas Peters, Dominik Janzing, and Bernhard Schölkopf. Elements of causal inference: founda-
tions and learning algorithms. The MIT Press, 2017."
REFERENCES,0.24101198402130491,"[12] Xinpeng Shen, Sisi Ma, Prashanthi Vemuri, and Gyorgy Simon. Challenges and opportunities
with causal discovery algorithms: application to alzheimer’s pathophysiology. Scientific reports,
10(1):2975, 2020."
REFERENCES,0.24234354194407456,"[13] Alessio Zanga, Elif Ozkirimli, and Fabio Stella. A survey on causal discovery: Theory and
practice. International Journal of Approximate Reasoning, 151:101–129, 2022."
REFERENCES,0.2436750998668442,"[14] Murat Kocaoglu, Karthikeyan Shanmugam, and Elias Bareinboim. Experimental design for
learning causal graphs with latent variables. Advances in Neural Information Processing
Systems, 30, 2017."
REFERENCES,0.24500665778961384,"[15] Kun Zhang, Biwei Huang, Jiji Zhang, Clark Glymour, and Bernhard Schölkopf. Causal discov-
ery from nonstationary/heterogeneous data: Skeleton estimation and orientation determination.
In IJCAI: Proceedings of the Conference, volume 2017, page 1347. NIH Public Access, 2017."
REFERENCES,0.24633821571238348,"[16] Karthikeyan Shanmugam, Murat Kocaoglu, Alexandros G Dimakis, and Sriram Vishwanath.
Learning causal graphs with small interventions. Advances in Neural Information Processing
Systems, 28, 2015."
REFERENCES,0.24766977363515313,"[17] Kristjan Greenewald, Dmitriy Katz, Karthikeyan Shanmugam, Sara Magliacane, Murat Ko-
caoglu, Enric Boix Adsera, and Guy Bresler. Sample efficient active learning of causal trees.
Advances in Neural Information Processing Systems, 32, 2019."
REFERENCES,0.24900133155792276,"[18] Muhammad Qasim Elahi, Lai Wei, Murat Kocaoglu, and Mahsa Ghasemi. Adaptive online
experimental design for causal discovery, 2024."
REFERENCES,0.25033288948069243,"[19] David Heckerman, Christopher Meek, and Gregory Cooper. A bayesian approach to causal
discovery. Technical report, Technical report msr-tr-97-05, Microsoft Research, 1997."
REFERENCES,0.25166444740346205,"[20] Yashas Annadani, Nick Pawlowski, Joel Jennings, Stefan Bauer, Cheng Zhang, and Wenbo
Gong. Bayesdag: Gradient-based posterior sampling for causal discovery. arXiv preprint
arXiv:2307.13917, 2023."
REFERENCES,0.2529960053262317,"[21] Christian Toth, Lars Lorch, Christian Knoll, Andreas Krause, Franz Pernkopf, Robert Peharz,
and Julius Von Kügelgen. Active bayesian causal inference. Advances in Neural Information
Processing Systems, 35:16261–16275, 2022."
REFERENCES,0.25432756324900135,"[22] Judea Pearl. Causality. Cambridge university press, 2009."
REFERENCES,0.255659121171771,"[23] Jin Tian and Judea Pearl. A general identification condition for causal effects. In Aaai/iaai,
pages 567–573, 2002."
REFERENCES,0.2569906790945406,"[24] Alain Hauser and Peter Bühlmann. Two optimal strategies for active learning of causal models
from interventional data. International Journal of Approximate Reasoning, 55(4):926–939,
2014."
REFERENCES,0.2583222370173103,"[25] Alfred V. Aho, Michael R Garey, and Jeffrey D. Ullman. The transitive reduction of a directed
graph. SIAM Journal on Computing, 1(2):131–137, 1972."
REFERENCES,0.2596537949400799,"[26] Tor Lattimore and Csaba Szepesvári. Bandit algorithms. Cambridge University Press, 2020."
REFERENCES,0.2609853528628495,"[27] Daphne Koller and Nir Friedman. Probabilistic graphical models: principles and techniques.
MIT press, 2009."
REFERENCES,0.2623169107856192,"A
Supplemental Material"
REFERENCES,0.2636484687083888,"A.1
Review of d-separation:"
REFERENCES,0.26498002663115844,"Consider three disjoint sets of nodes X, Y, and Z in the causal graph G = (V, E). The sets of nodes
X and Y are d-separated given Z, denoted by (X ⊥⊥d Y|Z)G, if and only if there exists no path,
directed or undirected, between any node in set X and any node in set Y such that for every collider
on the path, either the collider itself or one of its descendants is included in the set Z, and no other
non-collider nodes on the path are included in the set Z. (A collider on a path is a node with both
arrows converging, e.g., B is a collider on the path ABC in A →B ←C)."
REFERENCES,0.2663115845539281,"A.2
Pearl’s Rules of do-Calculus ([22]):"
REFERENCES,0.26764314247669774,"Let G represent the causal DAG, and let P denote the probability distribution induced by the
corresponding causal model. For any disjoint subsets of variables X, Y, Z, and W, the following rules
apply:"
REFERENCES,0.26897470039946736,Rule 1: (Insertion/deletion of observations):
REFERENCES,0.27030625832223704,"P(y|do(x), z, w) = P(y|do(x), w)
if
(Y ⊥⊥d Z|X, W)GX.
(2)"
REFERENCES,0.27163781624500666,Rule 2: (Action/observation exchange):
REFERENCES,0.2729693741677763,"P(y|do(x), do(z), w) = P(y|do(x), z, w)
if
(Y ⊥⊥d Z|X, W)GXZ.
(3)"
REFERENCES,0.27430093209054596,Rule 3: (Insertion/deletion of actions):
REFERENCES,0.2756324900133156,"P(y|do(x), do(z), w) = P(y|do(x), w)
if
(Y ⊥⊥d Z|X, W)GX,Z(W),
(4)"
REFERENCES,0.2769640479360852,where Z(W) is the set of nodes in Z that are not ancestors of any of the nodes in W in the graph GX.
REFERENCES,0.2782956058588549,"A.3
Function to Detect Presence of Latent Confounder:"
REFERENCES,0.2796271637816245,Algorithm 5: Function to Detect Presence of Latent Confounder
REFERENCES,0.2809587217043941,"1 Function DetectLatentConfounder(G, Xi, Xj, δ2, δ3, δ4, IData):"
REFERENCES,0.2822902796271638,"2
C =
16
ηγ2 log( 2n2K2"
REFERENCES,0.2836218375499334,"δ3
) +
1
2η2 log( 2n2K2"
REFERENCES,0.28495339547270304,"δ4
), B =
8
ϵ2 log 2nK2"
REFERENCES,0.2862849533954727,"δ2
3
if Xj ∈An(Xi) swap them."
REFERENCES,0.28761651131824234,"4
Find interventional data sets do(W = w) and do(Xi = xi, W = w) from IData s.t.
(Pa(Xi) ∪Pa(Xj) \ {Xi}) ⊆W and Xi & Xj /∈W"
REFERENCES,0.28894806924101196,"5
Get max(0, B −C) new samples for do(W = w)"
REFERENCES,0.29027962716378164,"6
if ∃xi, xj ∈[K] s.t. | bP(xj|do(xi), do(w)) −bP(xj|xi, do(w))| > γ"
THEN,0.29161118508655126,2 then
THEN,0.2929427430093209,"7
Add bi-dirceted edge Xi ←→Xj to graph G"
RETURN UPDATED CAUSAL GRAPH G,0.29427430093209056,"8
return Updated Causal Graph G"
END FUNCTION,0.2956058588548602,9 End Function
END FUNCTION,0.2969374167776298,"A.4
Proof of Lemma 3.2:"
END FUNCTION,0.2982689747003995,"Lemma. 3.2: It is necessary to learn/detect the latent confounders between reward node Y and any
node X ∈An(Y ) in causal graph G to learn all the POMISs correctly and hence avoid linear regret."
END FUNCTION,0.2996005326231691,"Before proceeding to the proof, we recall an important result from [5]: For a causal graph G with
reward variable Y , IB(GW, Y ) is a POMIS for any W ⊆V \ Y ."
END FUNCTION,0.3009320905459387,"Proof: Consider a causal graph G(V, E) with a node X ∈An(Y ) such that there exists a latent
confounder between X and the reward Y . Suppose we do not detect the presence of the confounder
and have access to another causal graph G′ with everything the same as G except that there is no
confounder between X and Y . We show that there exists one such POMIS that we cannot learn
from G′, which actually exists in the true causal graph G. To prove this, consider a set of nodes"
END FUNCTION,0.3022636484687084,"W = Pa(X) ∪Ch(Pa(X)) ∪CC(X) \ {X, Y }. For the graph G′, note that X /∈MUCT(G′"
END FUNCTION,0.303595206391478,"W, Y ),
and also there ∄Z ∈Ch(Pa(X)) \ {X} s.t. Z ∈MUCT(G′"
END FUNCTION,0.30492676431424764,"W, Y ). This implies that ∄Z ∈Pa(X)
s.t. Z ∈IB(G′"
END FUNCTION,0.3062583222370173,"W, Y ). However, for the true graph G, we have a different IB(GW, Y ) for the same
definition of W because it contains the bi-directed edge between X and Y , which implies that
X ∈MUCT(GW, Y ), and as a result, Pa(X) ⊆IB(GW, Y ). Also, in the case Pa(X) = ∅, we have
a different POMIS. On this side, note that X /∈MUCT(G′"
END FUNCTION,0.30758988015978694,"W, Y ), which implies that along the causal
path from X to Y , there must be one node Z such that Z ∈MUCT(G′"
END FUNCTION,0.30892143808255657,"W, Y ), which implies either
X or one of its descendants on the path from X to Y is in IB(G′"
END FUNCTION,0.31025299600532624,"W, Y ), which is not the case for G
since X ∈MUCT(GW, Y ). Thus, we have different interventional boundary or POMIS for the two
causal graphs G and G′ given the above choice of W, even if X has no parents."
END FUNCTION,0.31158455392809586,"The next step is to show that the particular POMIS IB(GW, Y ) cannot be learned from the DAG G′,
i.e., IB(GW, Y ) ̸= IB(G′"
END FUNCTION,0.3129161118508655,"W′, Y ) for any W′ ⊆V. We need to show this because of the graphical
characterization of POMISs in Lemma 3.1. Using the definition of W, note that Pa(X) ⊆IB(GW, Y )
and for all Z ∈Ch(Pa(X))\{X}, there exists either Z ∈IB(GW, Y ) or De(Z)\{Y } ∈IB(GW, Y ).
Also, if there are such nodes in CC(X) \ {X, Y } which do not have a path to X comprised of
directed edges only, call such set of nodes T. If T ̸= ϕ, then for all t ∈T, we have either
t ∈IB(GW, Y ) or De(t) \ {Y } ∈IB(GW, Y ). Also, note that ∄Z ∈De(X) ∪{X} such that
Z ∈IB(GW, Y ). Now consider DAG G′ with the bi-directed edge between X and Y missing.
Assume by contradiction ∃W′ ⊆V such that IB(GW, Y ) = IB(G′"
END FUNCTION,0.31424766977363516,"W′, Y ). This, however, using
the aforementioned characterization of IB(GW, Y ) implies that ∄Z ∈Ch(Pa(X)) \ {X} such that
Z ∈MUCT(G′"
END FUNCTION,0.3155792276964048,"W′, Y ) and also ∄t ∈T such that t ∈MUCT(G′"
END FUNCTION,0.3169107856191744,"W′, Y ) using the aforementioned
definition of T. However, note that we need Pa(X) ⊆IB(G′"
END FUNCTION,0.3182423435419441,"W′, Y ), which under the given choice
of W is only possible when X ∈MUCT(G′"
END FUNCTION,0.3195739014647137,"W′, Y ), which would require is a bi-directed edge
between X and Y in the DAG G′, which is a contradiction. Also, for the case when Pa(X) = ϕ,
we have a contradiction because we require the following to be true: ∄Z ∈De(X) ∪{X} such that
Z ∈IB(G′"
END FUNCTION,0.3209054593874834,"W′, Y ). For the given choice of W, it implies that there is a bi-directed edge between X
and Y in the DAG G′, which is again a contradiction. Thus, by contradiction, we show that ∄W′ ⊆V
such that G′, i.e., IB(GW, Y ) ̸= IB(G′"
END FUNCTION,0.322237017310253,"W′, Y ). This implies that we will miss at least one POMIS if
we do not learn or detect latent confounders between the reward node Y and any node X ∈An(Y ),
and may incur linear regret. This completes the proof of Lemma 3.2."
END FUNCTION,0.3235685752330226,"A.5
Proof of Theorem 3.1:"
END FUNCTION,0.3249001331557923,"Before proving Theorem 3.1, we state and prove another Lemma. We then extend this Lemma to
prove Theorem 3.1.
Lemma A.1. Consider a causal graph G(V, E) and another graph G′ such that they have the same
vertex set and directed edges but differ in bidirected edges, with the bidirected edges in G′ being a
subset of the bidirected edges in G. The graphs will yield different collections of POMISs if there
exists some Z ∈An(Y ) such that either (a) or (b) is true:"
END FUNCTION,0.3262316910785619,(a) There is a bi-directed edge between Z and Y in G but not in G′ .
END FUNCTION,0.32756324900133155,"(b) Neither of the graphs G′ and G have a bidirected edge between Z and Y , and there exists a
bidirected edge in G between some X ∈MUCT(G′"
END FUNCTION,0.3288948069241012,"Pa(Z),Bi(Z,G′) , Y ) and Z but not in G′."
END FUNCTION,0.33022636484687085,"Proof: The first half of Lemma A.1, i.e., ""The graphs will yield different collections of POMISs
if there exists some Z ∈An(Y ) such that there is a bi-directed edge between Z and Y in G but
not in G′,"" is the same as Lemma 3.2, and the same proof applies here. The reason is that in graph
G′, we miss a latent variable between reward and one of its ancestors, which was actually present
in the true graph G. We only need to proof the second half of Lemma A.1 i.e. graphs will yield
different collections of POMISs if there exists some Z ∈An(Y ) such that (b) is true. Consider
a causal graph G(V, E) and another DAG G′ such that they have the same vertex set and directed
edges, but differ in bi-directed edges. Consider a causal graph G(V, E) and another DAG G′ such
that they have the same vertex set and directed edges, but differ in bi-directed edges. We show
that if neither of the graphs G′ and G have a bidirected edge between Z and Y , and there exists a
bidirected edge in G between some X ∈MUCT(G′"
END FUNCTION,0.33155792276964047,"Pa(Z),Bi(Z,G′) , Y ) and Z, then there exists one"
END FUNCTION,0.33288948069241014,"such POMIS that we cannot learn from G′, which actually exists in the true causal graph G. To
prove this, consider a set of nodes W = Pa(Z) ∪Ch(Pa(Z) \ An(X)) ∪Bi(Z, G′) \ {X, Z, Y }. For"
END FUNCTION,0.33422103861517977,"the graph G′, note that Z /∈MUCT(G′"
END FUNCTION,0.3355525965379494,"W, Y ), and also there ∄N ∈Ch(Pa(Z) \ An(X)) \ {Z} s.t.
N ∈MUCT(G′"
END FUNCTION,0.33688415446071907,"W, Y ). This implies that ∄N ∈Pa(Z) \ An(X) s.t. N ∈IB(G′"
END FUNCTION,0.3382157123834887,"W, Y ). However,
for the true graph G, we have a different IB(GW, Y ) for the same definition of W because it contains
the bi-directed edge between X and Z, which implies that Z ∈MUCT(GW, Y ), and as a result,
Pa(Z) \ An(X) ⊆IB(GW, Y ). Also, in the case Pa(Z) \ An(X) = ∅, we have different a POMIS.
On this side, note that Z /∈MUCT(G′"
END FUNCTION,0.3395472703062583,"W, Y ), which implies that along the causal path from Z
to Y , there must be one node N such that N ∈MUCT(G′"
END FUNCTION,0.340878828229028,"W, Y ), which implies either Z or one
of its descendants on the path from Z to Y is in IB(G′"
END FUNCTION,0.3422103861517976,"W, Y ), which is not the case for G since
Z ∈MUCT(GW, Y ). Thus, we have different interventional boundary or POMIS for the two causal
graphs G and G′ given the above choice of W."
END FUNCTION,0.34354194407456723,"The next step is to show that the particular POMIS IB(GW, Y ) cannot be learned from the DAG G′,
i.e., IB(GW, Y ) ̸= IB(G′"
END FUNCTION,0.3448735019973369,"W′, Y ) for any W′ ⊆V. We need to show this because of the graphical
characterization of POMISs in Lemma 3.1. Using the definition of W, note that Pa(Z) \ An(X) ⊆
IB(GW, Y ) and for all N ∈Ch(Pa(Z) \ An(X)) \ {Z}, there exists either N ∈IB(GW, Y ) or
De(N)\{Y } ∈IB(GW, Y ). Also, if there are such nodes in Bi(Z, G′)\{X, Z, Y } which do not have
a path to Z comprising of directed edges only, call such set of nodes T. If T ̸= ϕ, then for all t ∈T,
we have either t ∈IB(GW, Y ) or De(t)\{Y } ∈IB(GW, Y ). Also, note that ∄N ∈De(Z)∪{Z} such
that N ∈IB(GW′, Y ). Now consider the DAG G′ with the bi-directed edge between Z and Y missing.
Assume by contradiction ∃W′ ⊆V such that IB(GW, Y ) = IB(G′"
END FUNCTION,0.34620505992010653,"W′, Y ). This, however, using the
aforementioned characterization of IB(GW, Y ) implies that ∄N ∈Ch(Pa(Z) \ An(X)) \ {Z} such
that N ∈MUCT(G′"
END FUNCTION,0.34753661784287615,"W′, Y ) and also ∄t ∈T such that t ∈MUCT(G′"
END FUNCTION,0.3488681757656458,"W′, Y ) for the aforementioned
definition of T. However, note that we need Pa(Z) \ An(X) ⊆IB(G′"
END FUNCTION,0.35019973368841545,"W′, Y ), which under the given
choice of W is only possible when Z ∈MUCT(G′"
END FUNCTION,0.35153129161118507,"W′, Y ), which would require a bi-directed edge
between Z and X in the DAG G′, which is a contradiction. Also, for the case when Pa(Z) = ϕ, we
have a contradiction because we require the following to be true: ∄N ∈De(Z) ∪{Z} such that
N ∈IB(G′"
END FUNCTION,0.35286284953395475,"W′, Y ). For the given choice of W, it implies that there is a bi-directed edge between Z
and X in the DAG G′, which is again a contradiction. Thus, by contradiction, we show that ∄W′ ⊆V
such that G′, i.e., IB(GW, Y ) ̸= IB(G′"
END FUNCTION,0.35419440745672437,"W′, Y ). This implies that we miss atleast one POMIS when
either of statements (a) and (b) hold. This completes the proof of Lemma A.1."
END FUNCTION,0.355525965379494,We now proceed to the formal proof for Theorem 3.1:
END FUNCTION,0.35685752330226367,"Theorem. 3.1: Consider a causal graph G(V, E) and another DAG G′ such that they have the same
vertex set and directed edges but differ in bidirected edges, with the bidirected edges in G′ being a
subset of the bidirected edges in G. The graphs will yield different collections of POMISs if and only
if there exists some Z ∈An(Y ) such that either (a) or (b) is true:"
END FUNCTION,0.3581890812250333,(a) There is a bi-directed edge between Z and Y in G but not in G′ .
END FUNCTION,0.3595206391478029,"(b) Neither of the graphs G′ and G have a bidirected edge between Z and Y , and there exists a
bidirected edge in G between some X ∈MUCT(G′"
END FUNCTION,0.3608521970705726,"Pa(Z),Bi(Z,G′) , Y ) and Z but not in G′."
END FUNCTION,0.3621837549933422,"Proof: One direction for Theorem 3.1 is proved already in Lemma A.1. We only to need to prove the
other direction which is that two causal graphs G and G′ such that they have the same vertex set and
directed edges, but differ in bi-directed edges will yield same collections POMISs when neither of
statements (a) and (b) is true. Note when neither of (a) or (b) is true the graphs G and G′ might still
have a different set of bi-directed edges. We will have two possible scenarios here. Suppose G has a
bi-directed edge between some Z ∈An(Y ) and some X ∈An(Y ), such that there is a bi-directed
edge between pair of vertices (Z, Y ) and (X, Y ) in both the graphs and the bi-directed edge between
X and Z is absent in G′. Further, assume neither of statements (a) and (b) hold. In this case, despite
the absence of a bi-directed edge between X and Z in G′, the graphs will yield the same set of
POMISs. This is because Z /∈MUCT(GW, Y ) for some set of nodes W only when Z ∈W, and the
same is the case for G because they share a bi-directed edge between Z and Y . By symmetry, we have
the argument hold for X as well. So, the presence or absence of bi-directed edges between X and Z
does not change the set of POMISs learned from the graph when both X and Z are confounded with
reward Y already. Thus, we can delete all such bi-directed edges one by one from G while the set of
POMISs learned from each of the intermediate causal graphs stays the same. Consider the second
scenario, where G has bi-directed edges between a node Z ∈An(Y ), such that there is no bi-directed"
END FUNCTION,0.36351531291611183,"edge between Z and Y in both graphs (G and G′) and a node X that has the following characteristics:
X ∈MUCT(G′"
END FUNCTION,0.3648468708388815,"W, Y ) for some set W ⊆V but X /∈MUCT(G′"
END FUNCTION,0.36617842876165113,"Pa(Z),Bi(Z,G′) , Y ). However, the"
END FUNCTION,0.36750998668442075,"bi-directed edge between X and Z is absent in G′. Further, assume neither of statements (a) and (b)
hold. The condition X ∈MUCT(G′"
END FUNCTION,0.36884154460719043,"W, Y ) but X /∈MUCT(G′"
END FUNCTION,0.37017310252996005,"Pa(Z),Bi(Z,G′) , Y ) implies that either"
END FUNCTION,0.3715046604527297,∃N ∈Pa(Z) such that N ∈MUCT(G′
END FUNCTION,0.37283621837549935,"W, Y ) or ∃N ∈Bi(Z, G′) such that N ∈MUCT(G′"
END FUNCTION,0.374167776298269,"W, Y ).
Since bi-directed edges in G′ are a subset of bi-directed edges in G, we have: Either ∃N ∈Pa(Z)
such that N ∈MUCT(GW, Y ) or ∃N ∈Bi(Z, G) such that N ∈MUCT(GW, Y ). Note that
any MUCT is closed under the De(.) and CC(.) operations, i.e., for any MUCT, say T, we have
De(T) = T and CC(T) = T. if ∃N ∈Pa(Z) such that N ∈MUCT(GW, Y ) or ∃N ∈Bi(Z, G)
such that N ∈MUCT(GW, Y ), we already have Z ∈MUCT(GW, Y ) using the definition of
MUCT. The bi-directed edge between X and Z will play a role only when ∄N ∈Pa(Z) such
that N ∈MUCT(GW, Y ) and ∄N ∈Bi(Z, G) such that N ∈MUCT(GW, Y ) for any choice
of W. Recall that the given condition X ∈MUCT(G′"
END FUNCTION,0.3754993342210386,"W, Y ) but X /∈MUCT(G′"
END FUNCTION,0.37683089214380827,"Pa(Z),Bi(Z,G′), Y )"
END FUNCTION,0.3781624500665779,"already implies that either ∃N ∈Pa(Z) such that N ∈MUCT(GW, Y ) or ∃N ∈Bi(Z, G) such that
N ∈MUCT(GW, Y ). Thus absence or presence of bi-directed edge between X and Z will have no
effect on POMISs learned from graph G in this scenario as well. Combining both of the scenarios
when neither of the conditions of (a) and (b) hold, all other bi-directed edges from G, which are
absent in G′, can be removed one by one from G while keeping the POMISs learned from both the
intermediate graphs the same. Since G and G′ only differ in bi-directed edges, with bi-directed edges
in G′ being a subset of those in G, eventually both graphs will become identical, which proves the
statement: Two graphs G and G′ will have the same POMISs if neither of the statements (a) or (b)
hold true. This completes the proof of the Theorem 3.1."
END FUNCTION,0.3794940079893475,"A.6
Proof of Lemma 4.1:"
END FUNCTION,0.3808255659121172,"Consider a causal graph G(V, E) and W ⊆V. Furthermore, let X, T ∈V \ W be any two variables.
Fix some realization w ∈[K]|W|. Under post interventional faithfulness Assumption 2.1 we want to
prove: (X ∈An(T))GW ⇐⇒P(t|do(w)) ̸= P(t|do(w), do(x)) for some x, t ∈[K]."
END FUNCTION,0.3821571238348868,"Forward Direction ( =⇒): (X ∈An(T))GW
=⇒P(t|do(w)) ̸= P(t|do(w), do(x)) for some
x, t ∈[K]. By contradiction, assume P(t|do(w)) = P(t|do(w), do(x)), ∀x, t ∈[K]. This implies
that P(t|do(w), do(x)) = P(t|do(w)) = some function of only t and w. This implies that for
the sub-model MW,X the following CI statements holds: (T ⊥⊥X)MW,X. However, note that if
(X ∈An(T))GW, then we still have (X ∈An(T))GW,X. This implies there is a directed path from X
to T in the post-interventional graph GW,X. Therefore, we have: (T ̸⊥⊥d X)GW,X. Note that under
the post interventional faithfulness Assumption 2.1, the CI statement (T ⊥⊥X)MW,X can hold only
if the d-separation statement holds (T ⊥⊥d X)GW,X, which is clearly a contradiction. This completes
the proof for the forward direction."
END FUNCTION,0.38348868175765644,"Reverse Direction ( ⇐= ): (X ∈An(T))GW
⇐=
P(t|do(w)) ̸= P(t|do(w), do(x)) for
some x, t ∈[K]. We prove the contrapositive statement instead, i.e., (X /∈An(T))GW
=⇒
P(t|do(w)) = P(t|do(w), do(x)), ∀x, t ∈[K]. Note that (X /∈An(T))GW clearly implies that
(X /∈An(T))GW,X which implies that (T ⊥⊥d X)GW,X. Thus, using Rule 3 of Pearl’s do calculus,
we have: P(t|do(w), do(x)) = P(t|do(w)), ∀x, t ∈[K]. This completes the proof of the reverse
direction."
END FUNCTION,0.3848202396804261,"A.7
Proof of Lemma 4.2:"
END FUNCTION,0.38615179760319573,"Consider two variables Xi and Xj such that Xj /∈An(Xi) and a set of variables (Pa(Xi)∪Pa(Xj)\
{Xi}) ⊆W and Xi & Xj /∈W. Fix some realization w ∈[K]|W|. Under the post-interventional
faithfulness Assumption 2.1 we want to show that: There is latent confounder between Xi and Xj
⇐⇒P(xj | do(xi), do(W = w)) ̸= P(xj | xi, do(W = w)) for some realization xi, xj ∈[K]."
END FUNCTION,0.38748335552596536,"Forward Direction ( =⇒): There is latent confounder between Xi and Xj such that Xj /∈An(Xi)
=⇒P(xj | do(xi), do(W = w)) ̸= P(xj | xi, do(W = w)) for some realization xi, xj ∈[K]. By
contradiction assume P(xj | do(xi), do(W = w)) = P(xj | xi, do(W = w)) ∀xi, xj ∈[K]. Recall"
END FUNCTION,0.38881491344873503,"that: Xj = fj(Pa(Xj), Uj). Since there is latent confounder between Xi and Xj call it Lij. Also
note that Lij ∈Uj. Define U′
j := Uj \ {Li,j}"
END FUNCTION,0.39014647137150466,"P(xj | do(xi), do(W)) = P(xj | do(xi), do(pa(Xi)), do(pa(Xj) \ {xi})))
(5)"
END FUNCTION,0.3914780292942743,"where the interventions do(Pa(Xi)) and do(Pa(Xj))) are consistent with do(xi) and do(W = w).
The equation 5 holds by the application of Pearl’s do-calculus Rule 3 because, by definition of the set
W, we have (Pa(Xi) ∪Pa(Xj) \ {Xi}) ⊆W and Xi, Xj /∈W. All the extra intervention targets
can simply be deleted, and we are left with intervention on Xi, Pa(Xi), and Pa(Xj)."
END FUNCTION,0.39280958721704395,"P(xj | do(xi), do(W)) =
X"
END FUNCTION,0.3941411451398136,"u′
j, li,j
P(xj | do(xi), do(pa(Xi)), do(pa(Xj) \ {xi}), U′
j = u′
j, Lij = lij)"
END FUNCTION,0.3954727030625832,"× P(U′
j = u′
j, Lij = lij)
(6)"
END FUNCTION,0.3968042609853529,"We have another application of Pearl’s do-calculus Rule 3 because interventions on observed variables
don’t affect unobserved variables, as there are no causal/directed paths from observed to unobserved
variables. Also we have:"
END FUNCTION,0.3981358189081225,"P(xj | xi, do(W)) = P(xj | xi, do(pa(Xi)), do(pa(Xj) \ {xi})))
(7)"
END FUNCTION,0.3994673768308921,"The equation 7 holds by the application of Pearl’s do-calculus Rule 3 because, by definition of the set
W, we have (Pa(Xi) ∪Pa(Xj) \ {Xi}) ⊆W and Xi, Xj /∈W. All the extra intervention targets
can simply be deleted, and we are left with conditioning on Xi = xi and interventions on Pa(Xi)
and Pa(Xj)."
END FUNCTION,0.4007989347536618,"P(xj | xi, do(W)) =
X"
END FUNCTION,0.4021304926764314,"u′
j, li,j
P(xj | xi, do(pa(Xi)), do(pa(Xj) \ {xi}), U′
j = u′
j, Lij = lij)"
END FUNCTION,0.40346205059920104,"× P(U′
j = u′
j, Lij = lij|xi, do(pa(Xi)), do(pa(Xj) \ {xi}))
(8)"
END FUNCTION,0.4047936085219707,"Using Pearl’s do-calculus Rule 2, we can replace the conditioning Xi = xi with the intervention
do(xi) in P(xj | xi, do(pa(Xi)), do(pa(Xj) \ {xi}), U′j = u′j, Lij = lij) because Xj /∈An(Xi)
and Pa(Xi) are already intervened on. Also, the latent confounder Lij is conditioned on, so there is
no open backdoor path from Xi to Xj. Thus, we have:"
END FUNCTION,0.40612516644474034,"P(xj | xi, do(W)) =
X"
END FUNCTION,0.40745672436750996,"u′
j, li,j
P(xj | do(xi), do(pa(Xi)), do(pa(Xj) \ {xi}), U′
j = u′
j, Lij = lij)"
END FUNCTION,0.40878828229027964,"× P(U′
j = u′
j, Lij = lij|xi, do(pa(Xi)), do(pa(Xj) \ {xi}))
(9)"
END FUNCTION,0.41011984021304926,"From the Equations 6 and 9 and assumption P(xj | do(xi), do(W = w)) = P(xj | xi, do(W = w))
∀xi, xj ∈[K] we have:
X"
END FUNCTION,0.41145139813581894,"u′
j, li,j
P(xj | do(xi), do(pa(Xi)), do(pa(Xj) \ {xi}), U′
j = u′
j, Lij = lij)"
END FUNCTION,0.41278295605858856,"×

P(U′
j = u′
j, Lij = lij|xi, do(pa(Xi)), do(pa(Xj) \ {xi})) −P(U′
j = u′
j, Lij = lij)

= 0 (10)"
END FUNCTION,0.4141145139813582,"Since probabilities are non-negative, whenever P(xj
|
do(xi), do(pa(Xi)), do(pa(Xj) \
{xi}), U′j = u′j, Lij = lij) > 0, we must have:"
END FUNCTION,0.41544607190412786,"P(U′
j = u′
j, Lij = lij|xi, do(pa(Xi)), do(pa(Xj) \ {xi})) = P(U′
j = u′
j, Lij = lij).
(11)"
END FUNCTION,0.4167776298268975,"However, since we know that Lij is a confounder between Xi and Xj, we have an edge Lij →Xi
in the causal graph, which implies that under any intervention do(Z) such that Xi /∈Z, we must
have (Lij ̸⊥⊥Xi)MZ by interventional faithfulness Assumption 2.1. This implies that there exists a
realization x∗
i and l∗
ij such that:"
END FUNCTION,0.4181091877496671,"P(U′
j = u′
j, Lij = l∗
ij|x∗
i , do(pa(Xi)), do(pa(Xj) \ {xi})) ̸= P(U′
j = u′
j, Lij = l∗
ij)
(12)"
END FUNCTION,0.4194407456724368,"Now, using the combination do(W = w) and a special choice of realizations x∗
i and l∗
ij, we must have
at least one special realization x∗
j such that: P(x∗
j | do(x∗
i ), do(Pa(Xi)), do(Pa(Xj) \ {xi}), U′j =
u′j, Lij = l∗
ij) > 0. Combining this with Equations 12 and 10, we conclude for some x∗
i , x∗
j ∈[K],
we have P(x∗
j | do(x∗
i ), do(W = w)) ̸= P(x∗
j | x∗
i , do(W = w)). Thus this leads to contradiction.
Thus if there is a latent confounder between Xi and Xj =⇒P(xj | do(xi), do(W = w)) ̸= P(xj |
xi, do(W = w)) for some realization xi, xj ∈[K]. This completes the proof of the forward direction."
END FUNCTION,0.4207723035952064,"Reverse Direction ( ⇐= ): For a pair of variables Xi and Xj such that Xj /∈An(Xi), if P(xj |
do(xi), do(W = w)) ̸= P(xj | xi, do(W = w)) for some realizations xi, xj ∈[K], then there is a
latent confounder between Xi and Xj. We prove the contrapositive statement instead, i.e., if there is no
latent confounder between Xi and Xj, then P(xj | do(xi), do(W = w)) = P(xj | xi, do(W = w)),
∀xi, xj ∈[K]. Note that by construction, we have: (Pa(Xi) ∪Pa(Xj) \ {Xi}) ⊆W. For such
choice of set W and the fact that Xj /∈An(Xi) and there is no latent confounder between Xi and Xj,
we have (Xj ⊥⊥Xi)GXiW. Thus, from Pearl’s do-calculus Rule 2, we have P(xj | do(xi), do(W ="
END FUNCTION,0.422103861517976,"w)) = P(xj | xi, do(W = w)), ∀xi, xj ∈[K]. This completes the proof of the reverse direction."
END FUNCTION,0.4234354194407457,"A.8
Proof of Lemma 4.3:"
END FUNCTION,0.4247669773635153,Suppose that Assumption 4.1 holds and we have access to max( 8
END FUNCTION,0.42609853528628494,"ϵ2 , 8"
END FUNCTION,0.4274300932090546,γ2 ) log 2K2
END FUNCTION,0.42876165113182424,"δ1
samples from"
END FUNCTION,0.43009320905459386,"do(Xi = xi, W = w) ∀xi ∈[K] and 8"
END FUNCTION,0.43142476697736354,ϵ2 log 2K2
END FUNCTION,0.43275632490013316,δ2 samples from do(W = w) for a fixed w ∈[K]|W|
END FUNCTION,0.4340878828229028,"for some W ⊆V. We want to show that with probability at least 1 −δ1 −δ2, we have the following:"
END FUNCTION,0.43541944074567246,"(Xi ∈An(Xj))GW ⇐⇒∃xi, xj ∈[K] s.t.
 bP(xj|do(w)) −bP(xj|do(w), do(xi))
 > ϵ"
END FUNCTION,0.4367509986684421,2. (13)
END FUNCTION,0.4380825565912117,"Using Hoeffding’s inequality with A samples from intervention do(xi, w),"
END FUNCTION,0.4394141145139814,"bP(xj|do(xi), do(w)) −P(xj|do(xi), do(w))
 ≥ s"
END FUNCTION,0.440745672436751,"1
2A log 2K2"
END FUNCTION,0.4420772303595206,"δ1
w.p. at most δ1"
END FUNCTION,0.4434087882822903,"K2 .
(14)"
END FUNCTION,0.4447403462050599,If we choose A = max( 8
END FUNCTION,0.44607190412782954,"ϵ2 , 8"
END FUNCTION,0.4474034620505992,γ2 ) log 2K2
END FUNCTION,0.44873501997336884,"δ1 , we have:"
END FUNCTION,0.45006657789613846,"bP(xj|do(xi), do(w)) −P(xj|do(xi), do(w))
 ≥ϵ"
END FUNCTION,0.45139813581890814,4 w.p. at most δ1
END FUNCTION,0.45272969374167776,"K2 .
(15)"
END FUNCTION,0.4540612516644474,"Similarly, using Hoeffding’s inequality with B samples from intervention do(w),"
END FUNCTION,0.45539280958721706,"bP(xj|do(w)) −P(xj|do(w))
 ≥ s"
END FUNCTION,0.4567243675099867,"1
2A log 2K2"
END FUNCTION,0.4580559254327563,"δ1
w.p. at most δ2"
END FUNCTION,0.459387483355526,"K2 .
(16)"
END FUNCTION,0.4607190412782956,"If we choose B =
8
ϵ2 log 2K2"
END FUNCTION,0.4620505992010652,"δ2 , we have:"
END FUNCTION,0.4633821571238349,"bP(xj|do(w)) −P(xj|do(w))
 ≥ϵ"
END FUNCTION,0.4647137150466045,4 w.p. at most δ2
END FUNCTION,0.46604527296937415,"K2 .
(17)"
END FUNCTION,0.4673768308921438,"Since the realization w ∈[K]|W| is fixed, while xi and xj are in [K], we have a total of K2 possible
bad events when the estimates are not accurate. Given the choice of samples, A and B, we have:"
END FUNCTION,0.46870838881491345,"bP(xj|do(xi), do(w)) −P(xj|do(xi), do(w))
 ≤ϵ"
END FUNCTION,0.47003994673768307,"4 ∀xi, xj ∈[K] w.p. at least 1 −δ1,
(18)"
END FUNCTION,0.47137150466045274,"bP(xj|do(w)) −P(xj|do(w))
 ≤ϵ"
END FUNCTION,0.47270306258322237,"4 ∀xj ∈[K] w.p. at least 1 −δ2.
(19)"
END FUNCTION,0.474034620505992,"Under the good event, which occurs with a probability of at least 1 −δ1 −δ2, the estimates are
accurate. We now consider the two possible scenarios. Suppose that Xi /∈An(Xj) in GW. In this case"
END FUNCTION,0.47536617842876167,"by Pearl’s do-calculus Rule 3 we have
P(xj|do(xi), do(w)) −P(xj|do(w))
 = 0 , ∀xi, xj ∈[K]."
END FUNCTION,0.4766977363515313,By triangular inequality we have the following:
END FUNCTION,0.4780292942743009,"bP(xj|do(xi), do(w)) −bP(xj|do(w))
 ≤
 bP(xj|do(xi), do(w)) −P(xj|do(xi), do(w))
+
 bP(xj|do(w)) −P(xj|do(w))
 ≤ϵ"
END FUNCTION,0.4793608521970706,"2 ∀xi, xj ∈[K].
(20)"
END FUNCTION,0.4806924101198402,"However, when Xi ∈An(Xj) in GW under Assumption 4.1 we must have some configuration say"
END FUNCTION,0.48202396804260983,"xi, xj ∈[K] for any w ∈[K]|W| such that
P(xj|do(xi), do(w))−P(xj|do(w))
 > ϵ. By triangular"
END FUNCTION,0.4833555259653795,"inequality when Xi ∈An(Xj) in GW, ∃xi, xj ∈[K] such that"
END FUNCTION,0.48468708388814913,"bP(xj|do(xi), do(w)) −bP(xj|do(w))
 ≥
P(xj|do(xi), do(w)) −P(xj|do(w))"
END FUNCTION,0.48601864181091875,"−
 bP(xj|do(xi), do(w)) −P(xj|do(xi), do(w))
 −
 bP(xj|do(w)) −P(xj|do(w))
 > ϵ"
END FUNCTION,0.4873501997336884,"2.
(21)"
END FUNCTION,0.48868175765645805,"Thus, using Assumption 4.1 with the given choice of number of samples with probability at least
1 −δ1 −δ2, we have the following result:"
END FUNCTION,0.49001331557922767,"(Xi ∈An(Xj))GW ⇐⇒∃xi, xj ∈[K] s.t.
 bP(xj|do(w)) −bP(xj|do(w), do(xi))
 > ϵ"
END FUNCTION,0.49134487350199735,2. (22)
END FUNCTION,0.49267643142476697,This completes the proof for Lemma 4.3.
END FUNCTION,0.4940079893475366,"A.9
Proof of Lemma 4.4:"
END FUNCTION,0.49533954727030627,"In order to prove that Algorithm 1 learns the true transitive closure under any intervention, i.e., Gtc"
END FUNCTION,0.4966711051930759,"W,
we recall from the proof of Lemma 4.3 that the test for ancestrality works with high probability under
the event that the causal effects of the form P(xj|do(xi), do(w)) and P(xj|do(w)) are estimated
accurately with an error of at most ϵ"
END FUNCTION,0.4980026631158455,"4 for all xi, xj ∈[K] and any fixed w ∈[K]W. Now, since"
END FUNCTION,0.4993342210386152,"Algorithm 1 takes B =
8
ϵ2 log 2nK2"
END FUNCTION,0.5006657789613849,"δ2
samples from do(W = w) and A = max

8
ϵ2 , 8"
END FUNCTION,0.5019973368841545,"γ2

log 2nK2"
END FUNCTION,0.5033288948069241,"δ1
samples from every do(Xi = xi, W = w) for all Xi ∈V \ W and for all xi ∈[K], the total number
of intervention samples collected is clearly at most KAn + B. In order to show that Algorithm 1
learns the true transitive closure under any intervention, i.e., Gtc"
END FUNCTION,0.5046604527296937,"W, with high probability, we must
demonstrate that Algorithm 1 can estimate all causal effects with a maximum error of ϵ"
WITH HIGH,0.5059920106524634,"4 with high
probability, so that all the ancestrality tests work with high probability, as implied by the proof of
Lemma 4.3."
WITH HIGH,0.507323568575233,"Using Hoeffding’s inequality with B =
8
ϵ2 log 2nK2"
WITH HIGH,0.5086551264980027,"δ2
samples from the intervention do(w), we have
for any Xj ∈V \ W:"
WITH HIGH,0.5099866844207723,"bP(xj|do(w)) −P(xj|do(w))
 ≤ϵ"
WITH HIGH,0.511318242343542,4 ∀xj ∈[K] w.p. at least 1 −δ2
WITH HIGH,0.5126498002663116,"n .
(23)"
WITH HIGH,0.5139813581890812,Using the union bound we have the following:
WITH HIGH,0.5153129161118508,"bP(Xj = xj|do(w))−P(Xj = xj|do(w))
 ≤ϵ"
WITH HIGH,0.5166444740346205,"4 ∀xj ∈[K] , ∀Xj ∈V\W w.p. at least 1−δ2. (24)"
WITH HIGH,0.5179760319573902,"Now, consider a fixed pair Xi, Xj ∈V \ W, and using A = max

8
ϵ2 , 8"
WITH HIGH,0.5193075898801598,"γ2

log 2nK2"
WITH HIGH,0.5206391478029294,"δ1
samples from"
WITH HIGH,0.521970705725699,"the intervention do(xi, w) for every xi ∈[K], we have the following using Hoeffding’s inequality:"
WITH HIGH,0.5233022636484687,"bP(xj|do(xi), do(w)) −P(xj|do(xi), do(w))
 ≤min( ϵ 4, γ"
WITH HIGH,0.5246338215712384,"4 ) ∀xi, xj ∈[K] w.p. at least 1 −δ1"
WITH HIGH,0.525965379494008,"n
(25)"
WITH HIGH,0.5272969374167776,Using the union bound we have the following:
WITH HIGH,0.5286284953395473,"bP(xj|do(xi), do(w)) −P(xj|do(xi), do(w))
 ≤min( ϵ 4, γ 4 )"
WITH HIGH,0.5299600532623169,"∀xi, xj ∈[K] , ∀Xj ∈V \ (W ∪{Xi}) w.p. at least 1 −δ1
(26)"
WITH HIGH,0.5312916111850865,Again using the union bound over all intervention targets Xi ∈V we have the following:
WITH HIGH,0.5326231691078562,"bP(xj|do(xi), do(w)) −P(xj|do(xi), do(w))
 ≤min( ϵ 4, γ 4 )"
WITH HIGH,0.5339547270306259,"∀xi, xj ∈[K] , ∀Xi ∈V \ W , ∀Xj ∈V \ (W ∪{Xi}) w.p. at least 1 −nδ1
(27)"
WITH HIGH,0.5352862849533955,"From Equations 24 and 27, using the union bound with probability at least 1 −nδ1 −δ2, all the
causal effects are estimated within an error of ϵ"
WITH HIGH,0.5366178428761651,"4 from the true values, ensuring that all ancestrality
tests work perfectly under this good event. Thus, Algorithm 1 learns the true transitive closure
under any intervention, i.e., Gtc"
WITH HIGH,0.5379494007989347,"W, with KAn + B intervention samples with probability of at least
1 −nδ1 −δ2. Also, if we set δ1 =
δ
2n and δ2 = δ"
WITH HIGH,0.5392809587217043,"2, then Algorithm 1 learns the true transitive closure
under any intervention, i.e., Gtc"
WITH HIGH,0.5406125166444741,"W with a probability of 1 −δ, with KAn + B intervention samples,"
WITH HIGH,0.5419440745672437,"where A = max

8
ϵ2 , 8"
WITH HIGH,0.5432756324900133,"γ2

log 4n2K2"
WITH HIGH,0.5446071904127829,"δ
and B =
8
ϵ2 log 4nK2"
WITH HIGH,0.5459387483355526,"δ
. This completes the proof of Lemma 4.4."
WITH HIGH,0.5472703062583223,"A.10
Proof of Theorem 4.1:"
WITH HIGH,0.5486018641810919,"We start by revising the statement of Lemma 4.3: Algorithm 1 learns the true transitive closure
under any intervention, i.e., Gtc"
WITH HIGH,0.5499334221038615,"W, with KAn + B intervention samples with a probability of at least
1 −nδ1 −δ2. Algorithm 2 randomly samples a target set W and calls Algorithm 1 to learn the active
true transitive closure of the post-interventional graph, i.e., Gtc"
WITH HIGH,0.5512649800266312,"W. For every iteration, Algorithm 2
computes transitive reduction Tr(Gtc"
WITH HIGH,0.5525965379494008,"W) and updates all the edges to construct the observable graph.
To prove the results in Theorem 4.1, we rely on Lemma 5 from [14], which is stated below:"
WITH HIGH,0.5539280958721704,"Lemma A.2. [14] Consider a graph G with observed variables V and an intervention set W ⊆V.
Consider post-interventional observable graph GW and a variable Xj ∈V \ W. Let Xi ∈Pa(Xj)
be such that all the parents of Xj above Xi in partial order are included in the intervention set
W. This implies that {Wi : π(Wi) > π(Xi) & Wi ∈Pa(Xj)} ⊆W . Then, the directed
edge (Xi, Xj) ∈E(Tr(GW)). The properties of transitive reduction yields Tr(GW) = Tr(Gtc"
WITH HIGH,0.5552596537949401,"W).
Consequently, the transitive reduction of Gtc"
WITH HIGH,0.5565912117177098,"W , i.e., Tr(Gtc"
WITH HIGH,0.5579227696404794,"W) = Tr(GW) may be used to learn the
directed edge (Xi, Xj).
(Note: E(G) denotes the edges of the graph G and π is any total order that is consistent with the
partial order implied by the DAG, i.e., π(X) < π(Y ) iff X is an ancestor of Y)."
WITH HIGH,0.559254327563249,"Assume that the number of the direct parents of Xj above Xi is dij where dij ≤dmax. Let Ei(Xj)
be the following event: Xi, Xj /∈W & {Wi : π(Wi) > π(Xi) & Wi ∈Pa(Xj)} ⊆W. The
probability of this event for one run of the outer loop in Algorithm 2 with the assumption that
2dmax >= 2 is given by:"
WITH HIGH,0.5605858854860186,"P[Ei(Xj)] =
1
4d2max
(1 −
1
2dmax
)dij ≥
1
4d2max
(1 −
1
2dmax
)2dmax≥
1
d2max"
WITH HIGH,0.5619174434087882,"1
16.
(28)"
WITH HIGH,0.563249001331558,The last inequality holds for 2dmax >= 2 because (1 −1
WITH HIGH,0.5645805592543276,"x)x ≥0.25, ∀x ≥2. Based on Lemma
A.2, the event Ei(Xj) implies that the directed edge (Xj, Xj) will be present in Tr(Gtc"
WITH HIGH,0.5659121171770972,"W) and
will be learned. The outer loop runs for 8αdmax log(n) iterations and elements of the set W are
independently sampled. The probability of failure, i.e., the event under consideration does not happen
for all runs of the outer loop in Algorithm 2, is bounded as follows:"
WITH HIGH,0.5672436750998668,"P[(Ei(V ))c] ≤(1 −
1
16 d2max
)8αdmax log(n) ≤e−
α
2dmax log(n) =
1
n
α
2dmax .
(29)"
WITH HIGH,0.5685752330226365,"For a graph with a total number of variables n, the total number of such bad events will be
 n
2

since
a graph can have at most
 n
2

edges. Using the union bound, the probability of bad event for any pair
of variables is given by:"
WITH HIGH,0.5699067909454061,"P[Failure] ≤
n
2"
WITH HIGH,0.5712383488681758,"
×
1
n
α
2dmax ≤
1
n
α
2dmax −2 .
(30)"
WITH HIGH,0.5725699067909454,Under the event that Algorithm 1 learns the correct transitive closure Gtc
WITH HIGH,0.5739014647137151,"W for all the 8αdmax log n
randomly sampled intervention sets W ⊆V, the above derivation shows that we will be able to learn
all edges in the true observable graph with a probability of at least 1 −
1"
WITH HIGH,0.5752330226364847,"n
α
2dmax −2 . Now recall the
result from Lemma 4.3 that Algorithm 1 learns the true transitive closure under any intervention, i.e.,
Gtc"
WITH HIGH,0.5765645805592543,"W, with KAn + B intervention samples with a probability of at least 1 −nδ1 −δ2. Combining the
two results above using the union bound, we have the following result:"
WITH HIGH,0.5778961384820239,"Algorithm 2 learns the true observable graph with a probability of at least 1 −
1"
WITH HIGH,0.5792276964047937,"n
α
2dmax −2 −"
WITH HIGH,0.5805592543275633,"8αdmax log(n)(nδ1 + δ2) with a maximum 8αdmax log n(KAn + B) interventional samples. Also,
if we set α = 2dmax log ( 2"
WITH HIGH,0.5818908122503329,"δ +2)
log n
, δ1 =
δ
32αdmaxn log n, and δ2 =
δ
32αdmax log n, then Algorithm 2 learns the"
WITH HIGH,0.5832223701731025,"true observable graph with a probability of at least 1 −δ. Where A = max

8
ϵ2 , 8"
WITH HIGH,0.5845539280958721,"γ2

log 2nK2"
WITH HIGH,0.5858854860186418,"δ1
and"
WITH HIGH,0.5872170439414115,"B =
8
ϵ2 log 2nK2"
WITH HIGH,0.5885486018641811,δ2 . This completes the proof of Theorem 4.1.
WITH HIGH,0.5898801597869507,"A.11
Proof of Lemma 4.5:"
WITH HIGH,0.5912117177097204,"Consider two nodes Xi and Xj s.t. Xj /∈An(Xi) and suppose that Assumptions 4.2 4.3 holds
and we have access to max( 8"
WITH HIGH,0.59254327563249,"ϵ2 , 8"
WITH HIGH,0.5938748335552596,γ2 ) log 2K2
WITH HIGH,0.5952063914780293,"δ1
samples from do(Xi = xi, W = w) ∀xi ∈[K] and"
WITH HIGH,0.596537949400799,"16
ηγ2 log( 2K2"
WITH HIGH,0.5978695073235686,"δ3 ) +
1
2η2 log( 2K2"
WITH HIGH,0.5992010652463382,"δ4 ) from do(W = w) for a fixed w ∈[K]|W| and W ⊆V such that
(Pa(Xi) ∪Pa(Xj) \ {Xi}) ⊆W and Xi & Xj /∈W. We want to show that, with probability at
least 1 −δ1 −δ3 −δ4, we have the following:"
WITH HIGH,0.6005326231691078,There exists a latent confounder between Xi and Xj ⇐⇒
WITH HIGH,0.6018641810918774,"∃xi, xj ∈[K] s.t.
 bP(xj|do(xi), do(w)) −bP(xj|xi, do(w))
 > γ 2 . (31)"
WITH HIGH,0.6031957390146472,"Using Hoeffding’s inequality with A samples from intervention do(xi, w)."
WITH HIGH,0.6045272969374168,"bP(xj|do(xi), do(w)) −P(xj|do(xi), do(w))
 ≥ s"
WITH HIGH,0.6058588548601864,"1
2A log 2K2"
WITH HIGH,0.607190412782956,"δ1
w.p. at most δ1"
WITH HIGH,0.6085219707057257,"K2 .
(32)"
WITH HIGH,0.6098535286284953,If we choose A = max( 8
WITH HIGH,0.611185086551265,"ϵ2 , 8"
WITH HIGH,0.6125166444740346,γ2 ) log 2K2
WITH HIGH,0.6138482023968043,"δ1 , we have:"
WITH HIGH,0.6151797603195739,"bP(xj|do(xi), do(w)) −P(xj|do(xi), do(w))
 ≥γ"
WITH HIGH,0.6165113182423435,4 w.p. at most δ1
WITH HIGH,0.6178428761651131,"K2 .
(33)"
WITH HIGH,0.6191744340878829,Using Hoeffding’s inequality with C samples from intervention do(xi).
WITH HIGH,0.6205059920106525,"bP(xj|xi, do(w)) −P(xj|xi, do(w))
 ≥ s"
WITH HIGH,0.6218375499334221,"1
2Cxi
log 2K2"
WITH HIGH,0.6231691078561917,"δ3
w.p. at most δ3"
WITH HIGH,0.6245006657789614,"K2 .
(34)"
WITH HIGH,0.625832223701731,"Where Cxi is the number of samples where Xi = xi among the C samples for the intervention do(w).
Note the we can’t directly control Cxi and it’s value depends on the true interventions distribution
P(xi, do(w)) along-with the number of samples C. Suppose if we can set Cxi ≥
8
γ2 log 2K2"
WITH HIGH,0.6271637816245007,"δ3 , we
have:"
WITH HIGH,0.6284953395472703,"bP(xj|xi, do(w)) −P(xj|xi, do(w))
 ≥γ"
WITH HIGH,0.62982689747004,4 w.p. at most δ3
WITH HIGH,0.6311584553928096,"K2 .
(35)"
WITH HIGH,0.6324900133155792,"We need to find the number of samples C such that Cxi ≥
8
γ2 log 2K2"
WITH HIGH,0.6338215712383488,"δ3 . Using the Hoeffding’s bound
we have:"
WITH HIGH,0.6351531291611185,"P(Cxi ≥CP(xi|do(w)) −η) ≥1 −2e−2η2/C.
(36)"
WITH HIGH,0.6364846870838882,Let δ4
WITH HIGH,0.6378162450066578,"K2 = 2e−2η2/C, which implies η =
q C"
WITH HIGH,0.6391478029294274,2 log 2K2
WITH HIGH,0.640479360852197,δ4 . Thus we have:
WITH HIGH,0.6418109187749668,"P

Cxi ≥CP(xi|do(w)) − s C"
WITH HIGH,0.6431424766977364,2 log 2K2 δ4
WITH HIGH,0.644474034620506,"
≥1 −δ4"
WITH HIGH,0.6458055925432756,"K2
(37)"
WITH HIGH,0.6471371504660453,Cxi ≥CP(xi|do(w)) − s C
WITH HIGH,0.6484687083888149,2 log 2K2
WITH HIGH,0.6498002663115846,"δ4
w.p. at least 1 −δ4"
WITH HIGH,0.6511318242343542,"K2 .
(38)"
WITH HIGH,0.6524633821571239,"Using Assumption 4.3, we have P(xi|do(w)) = 0 or P(xi|do(w)) ≥η. Note that if P(xi|do(w)) =
0, the event will never happen, and we don’t care about the accuracy of the estimate bP(xj|xi, do(w))
because it is already initialized to zero. Now the equation above can be rewritten as:"
WITH HIGH,0.6537949400798935,Cxi ≥Cη − s C
WITH HIGH,0.6551264980026631,2 log 2K2
WITH HIGH,0.6564580559254327,"δ4
w.p. at least 1 −δ4"
WITH HIGH,0.6577896138482024,"K2 .
(39)"
WITH HIGH,0.6591211717709721,"Since we want Cxi ≥
8
γ2 log 2K2"
WITH HIGH,0.6604527296937417,"δ3 with high probability, we have the following relationship: Cη − s C"
WITH HIGH,0.6617842876165113,"2 log 2K2 δ4
≥8"
WITH HIGH,0.6631158455392809,γ2 log 2K2
WITH HIGH,0.6644474034620506,"δ3
(40)"
WITH HIGH,0.6657789613848203,Solving the equation for number of samples C we get:
WITH HIGH,0.6671105193075899,"C ≥
4η
8 log

2K2 δ3 "
WITH HIGH,0.6684420772303595,"γ2
+ ln

2K2 δ4 
+ r"
WITH HIGH,0.6697736351531292,"8η
8 log

2K2 δ3 "
WITH HIGH,0.6711051930758988,"γ2
ln

2K2 δ4"
WITH HIGH,0.6724367509986684,"
+ ln2 
2K2 δ4 "
WITH HIGH,0.6737683089214381,"4η2
(41)"
WITH HIGH,0.6750998668442078,In order to make the expression simpler we choose the number of samples C as follows:
WITH HIGH,0.6764314247669774,"C =
4η
8 log

2K2 δ3 "
WITH HIGH,0.677762982689747,"γ2
+ ln

2K2 δ4 
+ r"
WITH HIGH,0.6790945406125166,"8η
8 log

2K2 δ3 "
WITH HIGH,0.6804260985352862,"γ2
ln

2K2 δ4"
WITH HIGH,0.681757656458056,"
+ ln2 
2K2 δ4"
WITH HIGH,0.6830892143808256,"
+
 
4η
8 log

2K2 δ3  γ2
2"
WITH HIGH,0.6844207723035952,"4η2
(42)"
WITH HIGH,0.6857523302263648,"C =
4η
8 log

2K2 δ3 "
WITH HIGH,0.6870838881491345,"γ2
+ ln

2K2 δ4 
+"
WITH HIGH,0.6884154460719041,"s
4η
8 log

2K2 δ3 "
WITH HIGH,0.6897470039946738,"γ2
+ ln

2K2 δ4  2"
WITH HIGH,0.6910785619174434,"4η2
(43)"
WITH HIGH,0.6924101198402131,"C =
4η
8 log

2K2 δ3 "
WITH HIGH,0.6937416777629827,"γ2
+ ln

2K2 δ4 "
WITH HIGH,0.6950732356857523,"2η2
(44)"
WITH HIGH,0.6964047936085219,C = 16
WITH HIGH,0.6977363515312917,ηγ2 log(2K2
WITH HIGH,0.6990679094540613,"δ3
) +
1
2η2 log(2K2"
WITH HIGH,0.7003994673768309,"δ4
)
(45)"
WITH HIGH,0.7017310252996005,"Suppose we take C samples for intervention do(w) as given above. Now, from Equations 35, 39, and
40, using the union bound, we have the following:"
WITH HIGH,0.7030625832223701,"bP(xj|xi, do(w)) −P(xj|xi, do(w))
 ≥γ"
WITH HIGH,0.7043941411451398,4 w.p. at most δ3 + δ4
WITH HIGH,0.7057256990679095,"K2
.
(46)"
WITH HIGH,0.7070572569906791,"Since the realization w ∈[K]|W| is fixed, but xi, xj ∈[K], we have a total of K2 possible bad
events when estimates are not good. With the given choice of number of samples A and C, we have:"
WITH HIGH,0.7083888149134487,"bP(xj|do(xi), do(w)) −P(xj|do(xi), do(w))
 ≤γ"
WITH HIGH,0.7097203728362184,"4 ∀xj ∈[K] w.p. at least 1 −δ1.
(47)"
WITH HIGH,0.711051930758988,"bP(xj|xi, do(w)) −P(xj|xi, do(w))
 ≤γ"
WITH HIGH,0.7123834886817576,"4 ∀xi, xj ∈[K] w.p. at least 1 −δ3 −δ4.
(48)"
WITH HIGH,0.7137150466045273,"Under the good event, which has a probability of at least 1 −δ1 −δ3 −δ4, both estimates are
accurate. We now consider the two possible scenarios. Suppose that there is no latent confounder"
WITH HIGH,0.715046604527297,"between Xi and Xj. In this case by Lemma 4.2 we have
P(xj|do(xi), do(w))−P(xj|xi, do(w))
 ="
WITH HIGH,0.7163781624500666,"0 , ∀xixj ∈[K]. By triangular inequality we have the following:"
WITH HIGH,0.7177097203728362,"bP(xj|do(xi), do(w)) −bP(xj|xi, do(w))
 ≤
 bP(xj|do(xi), do(w)) −P(xj|do(xi), do(w))
+
 bP(xj|x,do(w)) −P(xj|xi, do(w))
 ≤γ"
WITH HIGH,0.7190412782956058,"2 ∀xi, xj ∈[K].
(49)"
WITH HIGH,0.7203728362183754,"However, when there is a latent confounder between Xi and Xj, in this case, under Assump-
tion 4.2, we must have some configuration, say xi, xj ∈[K], for any w ∈[K]|W|, such that
P(xj|do(xi), do(w)) −P(xj|xi, do(w))
 > γ. By triangular inequality when there is a latent"
WITH HIGH,0.7217043941411452,"confounder between Xi and Xj,
∃xi, xj ∈[K] such that:"
WITH HIGH,0.7230359520639148,"bP(xj|do(xi), do(w)) −bP(xj|xi, do(w))
 ≥
P(xj|do(xi), do(w)) −P(xj|xi, do(w))"
WITH HIGH,0.7243675099866844,"−
 bP(xj|do(xi), do(w)) −P(xj|do(xi), do(w))
 −
 bP(xj|xi, do(w)) −P(xj|xi, do(w))
 > γ"
WITH HIGH,0.725699067909454,"2
(50)"
WITH HIGH,0.7270306258322237,"Thus, using Assumption 4.2 with the given choice of number of samples with probability at least
1 −δ1 −δ3 −δ4, we have the following result:"
WITH HIGH,0.7283621837549934,There exists a latent confounder between Xi and Xj ⇐⇒
WITH HIGH,0.729693741677763,"∃xi, xj ∈[K] s.t.
 bP(xj|do(xi), do(w)) −bP(xj|xi, do(w))
 > γ 2 . (51)"
WITH HIGH,0.7310252996005326,This completes the proof for Lemma 4.5.
WITH HIGH,0.7323568575233023,"A.12
Proof of Theorem 4.2:"
WITH HIGH,0.7336884154460719,"The Algorithm 3 first calls Algorithm 2 to learn the observable graph structure. We have already
proved in Theorem 4.1 that Algorithm 2 learns the true observable graph with a probability of at least
1−
1"
WITH HIGH,0.7350199733688415,"n
α
2dmax −2 −8αdmax log(n)(nδ1 +δ2) with a maximum of 8αdmax log n(KAn+B) interventional
samples. The next phase in Algorithm 3 is to learn/detect latent confounders between any pair
of variables. For all pairs of nodes Xi and Xj such that Xj /∈An(Xi), we define a set of nodes
Wij ⊆V such that Xi, Xj /∈Si, where Wij = (Pa(Xi) ∪Pa(Xj) \ {Xi}). Also, note that
|Wij| ≤2dmax. Let us define the event Eij = [Wij ⊆W & Xj, Xi /∈W]. The probability of this
event for one run of the outer loop in Algorithm 2 with the assumption that 2dmax ≥2 is given by:"
WITH HIGH,0.7363515312916112,"P[Eij] =
1
4d2max
(1 −
1
2dmax
)|Wij| ≥
1
4d2max
(1 −
1
2dmax
)2dmax≥
1
d2max"
WITH HIGH,0.7376830892143809,"1
16.
(52)"
WITH HIGH,0.7390146471371505,"The last inequality holds for dmax ≥2. Note that we reuse all the interventional data samples from
Algorithm 2 in Algorithm 3. Under Assumption 4.2, if the event Eij happens with a large enough
number of samples, we can detect the presence or absence of latent confounders between Xi and Xj.
The outer loop runs for 8αdmax log(n) iterations, and the elements of the set W are independently
sampled. The probability of failure, i.e., the event under consideration does not happen for all runs of
the outer loop in Algorithm 2, is bounded as follows:"
WITH HIGH,0.7403462050599201,"P[Ec
ij] ≤(1 −
1
16 d2max
)8αdmax log(n) ≤e−
α
2dmax log(n) =
1
n
α
2dmax .
(53)"
WITH HIGH,0.7416777629826897,"For a graph with a total number of variables n, the total number of such bad events will be
 n
2

. Using
the union bound, the probability of bad event for any pair of variables is given by:"
WITH HIGH,0.7430093209054593,"P[Failure] ≤
n
2"
WITH HIGH,0.7443408788282291,"
×
1
n
α
2dmax ≤
1
n
α
2dmax −2 .
(54)"
WITH HIGH,0.7456724367509987,"This implies with a probability of 1 −
1"
WITH HIGH,0.7470039946737683,"n
α
2dmax −2 , we will be able to find an appropriate interventional
dataset to test the presence of latent confounders between any pair of variables using Assumption 4.2"
WITH HIGH,0.748335552596538,"after running Algorithm 2. We still need to make sure we have enough interventional samples to be
able to test the latents. This is because we need to accurately estimate conditional effects to carry out
the test, as in Assumption 4.2. We first consider estimation of the causal effect bP(xj|do(xi), do(w))
for any randomly sampled set W. Now, consider a fixed Xi, Xj ∈V \ W. We have access to"
WITH HIGH,0.7496671105193076,"max

8
ϵ2 , 8"
WITH HIGH,0.7509986684420772,"γ2

log 2nK2"
WITH HIGH,0.7523302263648469,"δ1
samples for every xi ∈[K]. We have already shown that under the good
event, we have the following:
 bP(xj|do(xi), do(w)) −P(xj|do(xi), do(w))
 ≤min( ϵ 4, γ 4 )"
WITH HIGH,0.7536617842876165,"∀xi, xj ∈[K] , ∀Xi ∈V \ W , ∀Xj ∈V \ (W ∪{Xi}) w.p. at least 1 −nδ1
(55)"
WITH HIGH,0.7549933422103862,"Now, we consider estimation of the conditional causal effects, i.e., bP(xj|xi, do(w)). Note the while
running the Algorithm 2 we have access to B =
8
ϵ2 log 2nK2"
WITH HIGH,0.7563249001331558,"δ2
samples form intervention do(w)
and in the step 7 of Algorithm 3 we add more samples to the data set and have access to at least
C =
16
ηγ2 log( 2n2K2"
WITH HIGH,0.7576564580559254,"δ3
) +
1
2η2 log( 2n2K2"
WITH HIGH,0.758988015978695,"δ4
) samples instead. Now, consider a fixed Xi, Xj ∈V \ W.
With access to C samples as given above, following from Equation 48 in the Proof of Lemma 4.5, we
have the following result:"
WITH HIGH,0.7603195739014648,"bP(xj|xi, do(w)) −P(xj|xi, do(w))
 ≤γ"
WITH HIGH,0.7616511318242344,"4 ∀xi, xj ∈[K] w.p. at least 1 −δ3"
WITH HIGH,0.762982689747004,n2 −δ4
WITH HIGH,0.7643142476697736,"n2 .
(56)"
WITH HIGH,0.7656458055925432,"Note that in the above equation, we have δ3"
WITH HIGH,0.7669773635153129,n2 and δ4
WITH HIGH,0.7683089214380826,"n2 instead of δ3 and δ4 as in Equation 48, because
here in the number of samples C, we also have δ3"
WITH HIGH,0.7696404793608522,n2 and δ4
WITH HIGH,0.7709720372836218,"n2 instead of δ3 and δ4 when compared to the
number of samples in Equation 45. Now, using the union bound we have the following:"
WITH HIGH,0.7723035952063915,"bP(xj|xi, do(w)) −P(xj|xi, do(w))
 ≤γ 4"
WITH HIGH,0.7736351531291611,"∀xi, xj ∈[K] , ∀Xj ∈V \ (W ∪{Xi}) w.p. at least 1 −δ3 n −δ4"
WITH HIGH,0.7749667110519307,"n .
(57)"
WITH HIGH,0.7762982689747004,Again using the union bound over all Xi ∈V \ W we have the following:
WITH HIGH,0.7776298268974701,"bP(xj|do(xi), do(w)) −P(xj|do(xi), do(w))
 ≤γ"
WITH HIGH,0.7789613848202397,"4
∀xi, xj ∈[K] , ∀Xi ∈V \ W , ∀Xj ∈V \ (W ∪{Xi}) w.p. at least 1 −δ3 −δ4
(58)"
WITH HIGH,0.7802929427430093,"This implies that under the good event, for every randomly sampled intervention set W ⊆V, the
estimate of the conditional causal effect is accurate within the desired γ"
WITH HIGH,0.7816245006657789,"4 threshold. This would imply
that the test for detection of latent variables is perfect under this good event. We have already shown
that to ensure we have access to sufficient datasets to detect latent variables between any pair of
nodes, the 8αdmax log n randomly sampled target sets in Algorithm 2 are sufficient. Combining these
results with the results from Theorem 4.1, we have the following:"
WITH HIGH,0.7829560585885486,"The Algorithm 3 learns the true causal graph along with all latents with a probability of at least
1−
1"
WITH HIGH,0.7842876165113183,"n
α
2dmax −2 −
1"
WITH HIGH,0.7856191744340879,"n
α
2dmax −2 −8αdmax log(n)(nδ1+δ2)−8αdmax log(n)(δ3+δ4) = 1−
2"
WITH HIGH,0.7869507323568575,"n
α
2dmax −2 −"
WITH HIGH,0.7882822902796272,"8αdmax log(n)(nδ1 + (δ2 + δ3 + δ4)) with a maximum 8αdmax log n(KAn + max(B, C)) inter-
ventional samples. Also If we set α = 2dmax log ( 4"
WITH HIGH,0.7896138482023968,"δ +2)
log n
, δ1 =
δ
64αdmaxn log n and δ2 = δ3 = δ4 ="
WITH HIGH,0.7909454061251664,"δ
64αdmax log n, then Algorithm 2 learns the true causal graph with latents with a probability at least 1−δ."
WITH HIGH,0.7922769640479361,"Note that: A = max

8
ϵ2 , 8"
WITH HIGH,0.7936085219707057,"γ2

log 2nK2"
WITH HIGH,0.7949400798934754,"δ1 , B =
8
ϵ2 log 2nK2"
WITH HIGH,0.796271637816245,"δ2 , C =
16
ηγ2 log( 2K2"
WITH HIGH,0.7976031957390146,δ3 )+ 1
WITH HIGH,0.7989347536617842,2η2 log( 2K2
WITH HIGH,0.800266311584554,"δ4 ). This
completes the proof for Theorem 4.2."
WITH HIGH,0.8015978695073236,Algorithm 6: Full version of Algorithm for causal bandits with unknown graph structure
WITH HIGH,0.8029294274300932,"1 Set the Parameter δ, dmax
2 Calculate α, δ1, δ2, δ3, δ4 as in Theorem 5.1"
WITH HIGH,0.8042609853528628,"3 Gtc = LearnTransitiveClosure(W = ϕ, δ 2n, δ n)"
WITH HIGH,0.8055925432756325,"4 G, IData = LearnObservableGraph(An(Y )Gtc, α, dmax, δ1, δ2)"
WITH HIGH,0.8069241011984021,"5 C =
16
ηγ2 log( 2n2K2"
WITH HIGH,0.8082556591211718,"δ3
) +
1
2η2 log( 2n2K2"
WITH HIGH,0.8095872170439414,"δ4
) , B =
8
ϵ2 log 2nK2"
WITH HIGH,0.810918774966711,"δ2
6 #Learn the bi-directed edges between reward Y and all nodes Xi ∈An(Y ) and update G."
WITH HIGH,0.8122503328894807,7 for every Xi ∈An(Y )Gtc do
WITH HIGH,0.8135818908122503,"8
Set Xj := Y"
WITH HIGH,0.8149134487350199,"9
Find interventional data sets do(W = w) and do(Xi = xi, W = w) from IData s.t.
(Pa(Xi) ∪Pa(Xj) \ {Xi}) ⊆W and Xi & Xj /∈W"
WITH HIGH,0.8162450066577897,"10
Get max(0, B −C) new samples for do(W = w)"
WITH HIGH,0.8175765645805593,"11
if ∃xi, xj ∈[K] s.t. | bP(xj|do(xi), do(w)) −bP(xj|xi, do(w))| > γ"
THEN,0.8189081225033289,2 then
THEN,0.8202396804260985,"12
Add bi-dirceted edge Xi ←→Xj to graph G"
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.8215712383488681,13 while There is a new pair that is tested do
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.8229027962716379,"14
Find a new pair (Z, X) s.t. Z ∈An(Y ) such that Z and Y don’t have a bi-directed edge
between them in G and X ∈MUCT(GPa(Z),Bi(Z,G), Y )"
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.8242343541944075,"15
# Test for the latent between the pair (Z, X) and update G."
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.8255659121171771,"16
Set Xi := Z, Xj := X"
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.8268974700399467,"17
if Xj ∈An(Xi) swap them."
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.8282290279627164,"18
Find interventional data sets do(W = w) and do(Xi = xi, W = w) from IData s.t.
(Pa(Xi) ∪Pa(Xj) \ {Xi}) ⊆W and Xi & Xj /∈W"
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.829560585885486,"19
Get max(0, B −C) new samples for do(W = w)"
WHILE THERE IS A NEW PAIR THAT IS TESTED DO,0.8308921438082557,"20
if ∃xi, xj ∈[K] s.t. | bP(xj|do(xi), do(w)) −bP(xj|xi, do(w))| > γ"
THEN,0.8322237017310253,2 then
THEN,0.833555259653795,"21
Add bi-directed edge Xi ←→Xj to graph G"
THEN,0.8348868175765646,22 Learn the set of POMISs IG from the graph G Using Algorithm 1 in [5].
THEN,0.8362183754993342,23 Run UCB algorithm over the arm set A = {Ω(I) | ∀I ∈IG}.
THEN,0.8375499334221038,"A.13
Full Version of Algorithm 4 and Proof of Theorem 5.1:"
THEN,0.8388814913448736,"Algorithm 4 or its full version (Algorithm 6) starts by learning the transitive closure of the graph,
denoted as Gtc. This is because Gtc can give us An(Y ), and every possible POMIS is a subset of
An(Y ). Thus, we can restrict ourselves to ancestors of the read node. From Lemma 4.4, we can
learn the transitive closure Gtc with a probability of at least 1 −δ with a maximum of KAn + B
interventional samples by setting δ1 =
δ
2n and δ2 = δ"
THEN,0.8402130492676432,"2. Then, Algorithm 1 learns the true transitive"
THEN,0.8415446071904128,"closure with a probability of at least 1 −δ. (We have A = max

8
ϵ2 , 8"
THEN,0.8428761651131824,"γ2

log 2nK2"
THEN,0.844207723035952,"δ1
and B ="
THEN,0.8455392809587217,"8
ϵ2 log 2nK2"
THEN,0.8468708388814914,"δ2
as in line 2 of Algorithm 1). Thus, the total interventional samples for this step turn out"
THEN,0.848202396804261,"to be Kn max

8
ϵ2 , 8"
THEN,0.8495339547270306,"γ2

log 4n2K2 δ
+ 8"
THEN,0.8508655126498003,"ϵ2 log 4nK2 δ
."
THEN,0.8521970705725699,"The next step is to learn the complete observable graph induced on the reward node and its ancestors
and then learn/detect only a subset of latent confounders which are characterized to be necessary and
sufficient to learn the true set of POMISs (Theorem 3.1). Although this step saves us interventional
samples compared to the full discovery Algorithm 3, which learns/detects latents between all pairs of
variables, the exact saving will depend on the structure of the underlying causal graph. For the regret
upper bound, we can use the results from Theorem 4.2 to bound the number of interventional samples
for learning the true POMIS set from the ancestors of the reward node. This implies that given the
true set of ancestors of the reward An(Y ), we can learn the true POMIS set with a probability of"
THEN,0.8535286284953395,at least 1 −δ using 8αdmax
THEN,0.8548601864181092,"
KA
An(Y )
 + B

log
 An(Y )

interventions, where A and B are"
THEN,0.8561917443408789,"given by line 2 of Algorithm 1, and C is given by line 3 of Algorithm 3 by setting α = 2dmax log ( 4 δ +2)"
THEN,0.8575233022636485,"log
An(Y )
 ,"
THEN,0.8588548601864181,"δ1 =
δ"
THEN,0.8601864181091877,"64αdmax
An(Y )
 log
An(Y )
, and δ2 = δ3 = δ4 =
δ"
THEN,0.8615179760319573,"64αdmax log
An(Y )
."
THEN,0.8628495339547271,"The last phase is just running the UCB algorithm over the set of all possibly optimal arms, i.e.,"
THEN,0.8641810918774967,A = {Ω(I) | ∀I ∈IG}. This phase has a regret bound of P
THEN,0.8655126498002663,s∈{Ω(I)|∀I∈IG} ∆do(s)
THEN,0.8668442077230359,"
1 +
log T
∆2
do(s) "
THEN,0.8681757656458056,[26]. Now combining all the results we have the following:
THEN,0.8695073235685752,"Algorithm 4 learns the true set of POMISs IG with probability at least 1 −δ −δ = 1 −2δ, and under
the good event E that it learns POMISs correctly, the cumulative regret is bounded as follows:"
THEN,0.8708388814913449,"Rt ≤Kn max
 8"
THEN,0.8721704394141145,"ϵ2 , 8 γ2"
THEN,0.8735019973368842,"
log 4n2K2 δ
+ 8"
THEN,0.8748335552596538,ϵ2 log 4nK2 δ (59)
THEN,0.8761651131824234,+ 8αdmax
THEN,0.877496671105193,"
KA
An(Y )
 + max(B, C)

log
 An(Y )

+
X"
THEN,0.8788282290279628,"s∈{Ω(I)|∀I∈IG}
∆do(s)"
THEN,0.8801597869507324,"
1 + log T"
THEN,0.881491344873502,"∆2
do(s) 
,"
THEN,0.8828229027962716,"where A and B are given by line 2 of Algorithm 1, and C is given by line 3 of Algorithm 3 by setting
α = 2dmax log ( 4 δ +2)"
THEN,0.8841544607190412,"log
An(Y )

, δ1 =
δ"
THEN,0.8854860186418109,"64αdmax
An(Y )
 log
An(Y )
 and δ2 = δ3 = δ4 =
δ"
THEN,0.8868175765645806,"64αdmax log
An(Y )
. This"
THEN,0.8881491344873502,completes the proof of the Theorem 5.1.
THEN,0.8894806924101198,"A.14
Comparison with SCM-based Approximate Allocation Matching Algorithm from [6]:"
THEN,0.8908122503328895,"Our proposed algorithm, Algorithm 4, consists of two phases. The first phase uses interventional
samples to learn the set of POMISs, and the second phase uses the UCB algorithm to find the
optimal arm among the POMISs. Note that in the second phase, we use the UCB algorithm, which
assumes that arms are independent of one another. However, in the case of causal bandits, the arms
are correlated, and every intervention provides some information about other interventions. The
UCB algorithm cannot exploit this information. However, [6] proposes an algorithm to exploit the
correlations between arms in a causal bandit setting, which accelerates the learning compared to the
simple UCB algorithm. The main limitation is that the algorithm requires access to the true causal
graph. Therefore, it is possible that we can use an alternative approach where instead of POMISs,
we learn the entire causal graph and then use the SCM-based Approximate Allocation Matching
Algorithm from [6] for our problem setup. This approach can also allow us to reuse the intervention
samples from the discovery phase to accelerate the next phase. However, the main drawback of this
approach is that the algorithm proposed in [6] faces issues when it comes to larger, densely connected
causal graphs. We explain the reasoning of our claim by reviewing some concepts from the paper [6]."
THEN,0.8921438082556591,"In order to exploit the correlations between different arms in a causal bandit setting, the authors
in [6] rely on response variable formulation for causal effects, which we discuss very briefly
here.
For any causal graph G, the observed variables V can be uniquely partitioned into c-
components C1, . . . , Cnc(G). Consider a set of response variables M, which we also partition
into M1, . . . , Mnc(G), where each Mj contains response variables corresponding to every observed
variable in the corresponding c-component Cj. Within a c-component, the response variables of all
the observed variables are correlated since they are connected by bidirected edges. However, across
two c-components, the response variables are independent. As a result, P(m) = Qnc(G)
j=1 P(mj).
By concatenating P(mj) for each mj ∈Ω(Mj), one can construct a vector pj ∈∆(|Ω(Mj)|)
where ∆(|Ω(Mj)|) denotes the probability simplex over the discrete domain Ω(Mj). Let the
parent set of a c-component Cj be PaCj :=
 S"
THEN,0.8934753661784287,"i:Vi∈Cj Pai

\ Cj. When taking intervention
do(S = s), the values of Cj ∩S are set to s[Cj], which denotes the values of Cj ∩S that
are consistent with s. Mj picks the mapping functions from Pai to Vi for all Vi ∈Cj. By
marking configurations in BG,s[Cj](Cj, paCj) ⊆Ω(Mj) with 1 and 0, one constructs a vector"
THEN,0.8948069241011984,"bG,s[Cj](Cj, paCj) ∈{0, 1}|Ω(Mj)| such that:"
THEN,0.8961384820239681,Ps(v) =
THEN,0.8974700399467377,"nc(G)
Y"
THEN,0.8988015978695073,"j=1
P
 
Mj ∈BG,s[Cj](Cj, paCj)

="
THEN,0.9001331557922769,"nc(G)
Y"
THEN,0.9014647137150466,"j=1
b⊤
G,s[Cj](Cj, paCj)pj.
(60)"
THEN,0.9027962716378163,"The equation 60 is very useful since it enables us to exploit the correlations between different
interventions in the causal bandit setting. This is because every interventional distribution can be"
THEN,0.9041278295605859,"written as a deterministic linear function of the response variable distribution. Thus, it is possible
that using the response variable decomposition, we can reuse the samples from discovery into the
next phase and accelerate learning of the optimal arm. However, we need to discuss the scalability
of this approach. Note that every variable in the SCM can take values from the set [K], and in
total, there could be K different realizations for Vj for every realization of its parents Pa(Vj).
As a result, there are a total of KK|Pa(Vj )| possible mappings from Pa(Vj) to Vj. Also, note that
within a c-component, the response variables for every observed variable are correlated. This
implies that for every component Cj, the corresponding response variable Mj has the domain
|Ω(Mj)| = Q"
THEN,0.9054593874833555,"Vi∈Cj KK|Pa(Vi)|. Thus, every vector pj will have a total of Q"
THEN,0.9067909454061251,Vi∈Cj KK|Pa(Vi)|
THEN,0.9081225033288948,"components. Although the response variable decomposition is useful for smaller and sparse causal
graphs, the scaling for the length of vectors pj is clearly exponential, making the use of response
variable decomposition infeasible for larger or denser causal graphs. All in all, there are correlations
between different arms in causal bandits, but it is not clear how to exploit them effectively, especially
for larger and denser causal graphs, which is still an open problem."
THEN,0.9094540612516645,"A.15
Experimental Compute Resources and Runtime"
THEN,0.9107856191744341,"We ran our experiments on a server equipped with the AMD Ryzen Threadripper PRO 5995WX
CPU, which has 64 cores and 128 threads, with a base clock speed of 2.7 GHz and a maximum boost
clock speed of 4.5 GHz, along with 128 GB of RAM. The total runtime for the experimental plots in
Figures 2 and 3 is around 2 hours. For the experimental plots in Figure 4, the total runtime is around
2 hours for each subplot since we run the full algorithm for multiple randomly sampled graphs."
THEN,0.9121171770972037,"A.16
Broader Impacts of our Work"
THEN,0.9134487350199734,"This paper presents work with the goal of advancing the field of Machine Learning. Since the causal
bandit framework can be used to model real-life decision-making scenarios, there are some potential
societal consequences of our work. The possibility of biased or incomplete understanding of causal
relationships could lead to misguided decision-making or policy recommendations in real-world
situations. Thus, extra care and consideration of ethical boundaries regarding actions/interventions
are needed while applying our proposed methodology to practical problems."
THEN,0.914780292942743,NeurIPS Paper Checklist
CLAIMS,0.9161118508655126,1. Claims
CLAIMS,0.9174434087882823,"Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?"
CLAIMS,0.918774966711052,Answer: [Yes]
CLAIMS,0.9201065246338216,"Justification: Our abstract and introduction clearly reflect the paper’s contributions, and we
provide a list of main contributions at the end of the introduction as well."
CLAIMS,0.9214380825565912,Guidelines:
CLAIMS,0.9227696404793608,"• The answer NA means that the abstract and introduction do not include the claims
made in the paper.
• The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
• The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
• It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper."
LIMITATIONS,0.9241011984021305,2. Limitations
LIMITATIONS,0.9254327563249002,Question: Does the paper discuss the limitations of the work performed by the authors?
LIMITATIONS,0.9267643142476698,"Answer: [Yes]
Justification: Our paper clearly discusses all the limitations and assumptions in sections 2
and 4."
LIMITATIONS,0.9280958721704394,Guidelines:
LIMITATIONS,0.929427430093209,"• The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate ""Limitations"" section in their paper.
• The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
• The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
• The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
• The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
• If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
• While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations."
THEORY ASSUMPTIONS AND PROOFS,0.9307589880159787,3. Theory Assumptions and Proofs
THEORY ASSUMPTIONS AND PROOFS,0.9320905459387483,"Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?"
THEORY ASSUMPTIONS AND PROOFS,0.933422103861518,"Answer: [Yes]
Justification: All the theorems and lemmas in our paper are properly numbered, and formal
proofs are provided in the supplementary material.
Guidelines:"
THEORY ASSUMPTIONS AND PROOFS,0.9347536617842876,"• The answer NA means that the paper does not include theoretical results.
• All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
• All assumptions should be clearly stated or referenced in the statement of any theorems.
• The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
• Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4. Experimental Result Reproducibility"
THEORY ASSUMPTIONS AND PROOFS,0.9360852197070573,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: We provide detailed explanation of our experiments in section 6 and also
provide the code with instructions to reproduce the results.
Guidelines:"
THEORY ASSUMPTIONS AND PROOFS,0.9374167776298269,"• The answer NA means that the paper does not include experiments.
• If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
• If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
• Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
• While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a) If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b) If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c) If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d) We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5. Open access to data and code"
THEORY ASSUMPTIONS AND PROOFS,0.9387483355525965,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: We have uploaded the code along with the instructions to reproduce the results
in our experiments section.
Guidelines:"
THEORY ASSUMPTIONS AND PROOFS,0.9400798934753661,"• The answer NA means that paper does not include experiments requiring code.
• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
public/guides/CodeSubmissionPolicy) for more details.
• While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
• The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines (https:
//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
• The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
• The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
• At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
• Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6. Experimental Setting/Details"
THEORY ASSUMPTIONS AND PROOFS,0.9414114513981359,"Question: Question: Does the paper specify all the training and test details (e.g., data splits,
hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand
the results?
Answer: [Yes]
Justification: We provide all the details about our experimental setting in section 6.
Guidelines:"
THEORY ASSUMPTIONS AND PROOFS,0.9427430093209055,"• The answer NA means that the paper does not include experiments.
• The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
• The full details can be provided either with the code, in appendix, or as supplemental
material.
7. Experiment Statistical Significance"
THEORY ASSUMPTIONS AND PROOFS,0.9440745672436751,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: We plot the error bars as part of the experimental results in section 6 and also
mention the method used to calculate them.
Guidelines:"
THEORY ASSUMPTIONS AND PROOFS,0.9454061251664447,"• The answer NA means that the paper does not include experiments.
• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
• The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions)."
THEORY ASSUMPTIONS AND PROOFS,0.9467376830892144,"• The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
• It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
• It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
• For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
• If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8. Experiments Compute Resources"
THEORY ASSUMPTIONS AND PROOFS,0.948069241011984,"Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: We provide all the information on computer resources and runtime for our
experiments in section A.15.
Guidelines:"
THEORY ASSUMPTIONS AND PROOFS,0.9494007989347537,"• The answer NA means that the paper does not include experiments.
• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
• The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
• The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9. Code Of Ethics"
THEORY ASSUMPTIONS AND PROOFS,0.9507323568575233,"Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
Answer: [Yes]
Justification: We have looked at the NeurIPS code of ethics, and we believe there are no
potential harms caused by the research or potential future harmful consequences for our
work.
Guidelines:"
THEORY ASSUMPTIONS AND PROOFS,0.952063914780293,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
• If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10. Broader Impacts"
THEORY ASSUMPTIONS AND PROOFS,0.9533954727030626,"Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [Yes]
Justification: We discuss possible broader impacts of our work in section A.16.
Guidelines:"
THEORY ASSUMPTIONS AND PROOFS,0.9547270306258322,"• The answer NA means that there is no societal impact of the work performed.
• If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact."
THEORY ASSUMPTIONS AND PROOFS,0.9560585885486018,"• Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
• The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
• The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
• If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML)."
SAFEGUARDS,0.9573901464713716,11. Safeguards
SAFEGUARDS,0.9587217043941412,"Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?"
SAFEGUARDS,0.9600532623169108,Answer: [NA]
SAFEGUARDS,0.9613848202396804,"Justification: We mainly conduct synthetic experiments in our work, and we don’t see any
risk of misuse of our code."
SAFEGUARDS,0.96271637816245,Guidelines:
SAFEGUARDS,0.9640479360852197,"• The answer NA means that the paper poses no such risks.
• Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
• Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
• We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort."
LICENSES FOR EXISTING ASSETS,0.9653794940079894,12. Licenses for existing assets
LICENSES FOR EXISTING ASSETS,0.966711051930759,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?"
LICENSES FOR EXISTING ASSETS,0.9680426098535286,Answer: [NA]
LICENSES FOR EXISTING ASSETS,0.9693741677762983,"Justification: Our experiments are purely synthetic in nature, and we don’t use any datasets
or models that require licenses."
LICENSES FOR EXISTING ASSETS,0.9707057256990679,Guidelines:
LICENSES FOR EXISTING ASSETS,0.9720372836218375,"• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
• The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
• For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided."
LICENSES FOR EXISTING ASSETS,0.9733688415446072,"• If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
• For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
• If this information is not available online, the authors are encouraged to reach out to
the asset’s creators."
NEW ASSETS,0.9747003994673769,13. New Assets
NEW ASSETS,0.9760319573901465,"Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?"
NEW ASSETS,0.9773635153129161,Answer: [NA]
NEW ASSETS,0.9786950732356857,"Justification: We don’t create new assets in our work, and the main contributions of our
work lie predominantly on the theoretical side."
NEW ASSETS,0.9800266311584553,Guidelines:
NEW ASSETS,0.9813581890812251,"• The answer NA means that the paper does not release new assets.
• Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
• The paper should discuss whether and how consent was obtained from people whose
asset is used.
• At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9826897470039947,14. Crowdsourcing and Research with Human Subjects
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9840213049267643,"Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9853528628495339,Answer: [NA]
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9866844207723036,Justification: Our paper does not involve crowdsourcing or research with human subjects.
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9880159786950732,Guidelines:
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9893475366178429,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9906790945406125,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9920106524633822,"Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9933422103861518,Answer: [NA]
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9946737683089214,"Justification: We don’t require any approval since our work does not involve crowdsourcing
or research with human subjects."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.996005326231691,Guidelines:
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9973368841544608,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9986684420772304,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
• We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
• For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review."
