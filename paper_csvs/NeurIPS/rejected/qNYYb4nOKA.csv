Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0013717421124828531,"Advances in large language models have notably enhanced the efficiency of infor-
1"
ABSTRACT,0.0027434842249657062,"mation extraction from unstructured and semi-structured data sources. As these
2"
ABSTRACT,0.00411522633744856,"technologies become integral to various applications, establishing an objective
3"
ABSTRACT,0.0054869684499314125,"measure for the quality of information extraction becomes imperative. However,
4"
ABSTRACT,0.006858710562414266,"the scarcity of labeled data presents significant challenges to this endeavor. In
5"
ABSTRACT,0.00823045267489712,"this paper, we introduce an automatic framework to assess the quality of the in-
6"
ABSTRACT,0.009602194787379973,"formation extraction/retrieval and its completeness. The framework focuses on
7"
ABSTRACT,0.010973936899862825,"information extraction in the form of entity and its properties. We discuss how to
8"
ABSTRACT,0.012345679012345678,"handle the input/output size limitations of the large language models and analyze
9"
ABSTRACT,0.013717421124828532,"their performance when extracting the information. In particular, we introduce
10"
ABSTRACT,0.015089163237311385,"scores to evaluate the quality of the extraction and provide an extensive discussion
11"
ABSTRACT,0.01646090534979424,"on how to interpret them.
12"
INTRODUCTION,0.01783264746227709,"1
Introduction
13"
INTRODUCTION,0.019204389574759947,"In the domain of natural language processing (NLP), information extraction (IE) stands as a critical
14"
INTRODUCTION,0.0205761316872428,"task, transforming unstructured or semi-structured data into a structured format conducive to indexing,
15"
INTRODUCTION,0.02194787379972565,"exploration, and further analysis. The increasing amount of data across digital platforms underscores
16"
INTRODUCTION,0.023319615912208505,"the urgency for sophisticated IE techniques that can parse through volumes of information with
17"
INTRODUCTION,0.024691358024691357,"precision. An extensive survey about IE is provided by [1], where the authors highlight the complexity
18"
INTRODUCTION,0.02606310013717421,"of processing and analyzing text to derive meaningful information, given the heterogeneity and volume
19"
INTRODUCTION,0.027434842249657063,"of such data.
20"
INTRODUCTION,0.02880658436213992,"Large language models (LLMs) have revolutionized IE by introducing generative methods for
21"
INTRODUCTION,0.03017832647462277,"structuring knowledge from text. LLMs excel across diverse domains without extensive task-specific
22"
INTRODUCTION,0.03155006858710562,"training. A survey by [9] details the progress of LLMs on IE tasks. Here, the authors address specific
23"
INTRODUCTION,0.03292181069958848,"aspects of information extraction, including entity recognition, relation extraction, event detection,
24"
INTRODUCTION,0.03429355281207133,"and universal IE. They review the existing models and their efficiency on a comprehensive collection
25"
INTRODUCTION,0.03566529492455418,"of annotated benchmarks. Nonetheless, the challenge of quantitatively assessing the quality and
26"
INTRODUCTION,0.037037037037037035,"completeness of extracted information persists, particularly in the absence of labeled datasets for
27"
INTRODUCTION,0.038408779149519894,"benchmarking. Before conducting the experiments introduced in this paper, we perform IE on a vast
28"
INTRODUCTION,0.039780521262002745,"corpus of business documents utilizing LLMs. While the extraction process is beyond the scope of
29"
INTRODUCTION,0.0411522633744856,"this paper, some details about the extraction are given in Section 3.
30"
INTRODUCTION,0.04252400548696845,"To measure the quality of extraction, we propose an evaluation framework that relies on artificially
31"
INTRODUCTION,0.0438957475994513,"generated complex information which is infused into the document to test the efficiency of LLMs in
32"
INTRODUCTION,0.04526748971193416,"IE tasks. This paper introduces an iterative extraction process and a novel score, MINEA (Multiple
33"
INTRODUCTION,0.04663923182441701,"Infused Needle Extraction Accuracy), to address the critical need for objective quality assessment
34"
INTRODUCTION,0.04801097393689986,"measures. By inserting artificial information (""needles"") into the data, the proposed method creates
35"
INTRODUCTION,0.04938271604938271,"a synthetic ground truth for evaluation, enabling the measurement of extraction quality in various
36"
INTRODUCTION,0.05075445816186557,"specific domains even without manually labeled data. The empirical analysis demonstrates the
37"
INTRODUCTION,0.05212620027434842,"utility of MINEA for evaluating LLM-based IE in scenarios where ground truth is unavailable. By
38"
INTRODUCTION,0.053497942386831275,"automating the quality assessment of information extraction, the framework could reduce the need
39"
INTRODUCTION,0.05486968449931413,"for manual review by experts, saving time and resources and thus enhance the efficiency and accuracy
40"
INTRODUCTION,0.056241426611796985,"of information extraction from large volumes of unstructured data.
41"
INTRODUCTION,0.05761316872427984,"The paper is organized as follows: Section 2 presents a related work that inspired us when developing
42"
INTRODUCTION,0.05898491083676269,"our IE quality assessment method; Section 3 sketch a way in which structured information is obtained
43"
INTRODUCTION,0.06035665294924554,"using LLMs; Section 4 deals with shortcomings arising when treating long contexts by LLMs; finally
44"
INTRODUCTION,0.06172839506172839,"Section 5 introduces the novel method to access the quality of IE and provide the reader with practical
45"
INTRODUCTION,0.06310013717421124,"tips; Sections 4 and 5 are supplemented by numerical studies. The data used in these studies are an
46"
INTRODUCTION,0.0644718792866941,"internal set of documents related to a business case in the healthcare industry.
47"
RELATED WORK,0.06584362139917696,"2
Related work
48"
RELATED WORK,0.06721536351165981,"A common practice in many specialized IE tasks is that well-trained experts review what was extracted
49"
RELATED WORK,0.06858710562414266,"and provide ground truth as done in [5]. Such an approach is relatively reliable, however, it is manual
50"
RELATED WORK,0.06995884773662552,"and very time-consuming.
51"
RELATED WORK,0.07133058984910837,"In [4] they suggest summary score without reference (SUSWIR), a score to evaluate the quality of
52"
RELATED WORK,0.07270233196159122,"text summaries without the need for human annotations. The SUSWIR score can be used for IE tasks
53"
RELATED WORK,0.07407407407407407,"where the extracted information is viewed as a compression of original data. The score compares
54"
RELATED WORK,0.07544581618655692,"the original text with its summary. From its nature, it is very useful when comparing the outputs
55"
RELATED WORK,0.07681755829903979,"of extraction tasks among themselves, i.e., the best extraction/summary has the highest score value.
56"
RELATED WORK,0.07818930041152264,"On the other hand, its ability to provide an objective absolute evaluation of a single extraction is
57"
RELATED WORK,0.07956104252400549,"disadvantaged because the desirable output is not known.
58"
RELATED WORK,0.08093278463648834,"Recently, an effort to eliminate the requirement for human involvement relies on LLMs. These prove
59"
RELATED WORK,0.0823045267489712,"themselves as highly cost-effective data creators, either by labeling unlabeled data or generating data
60"
RELATED WORK,0.08367626886145405,"given the labels, see [7]. Therefore they may substitute human experts providing the ground truth by
61"
RELATED WORK,0.0850480109739369,"doing their work in an automatic way.
62"
RELATED WORK,0.08641975308641975,"Needle In A Haystack (NIAH)1 evaluation is a tool designed to evaluate the performance of LLMs in
63"
RELATED WORK,0.0877914951989026,"retrieval across different sizes of context. Short targeted information, the ‘needle’, is inserted into a
64"
RELATED WORK,0.08916323731138547,"large, more complex text body, the ‘haystack’. The goal is to test an LLM’s ability to find and make
65"
RELATED WORK,0.09053497942386832,"use of this piece of information.
66"
RELATED WORK,0.09190672153635117,"Our method builds on LLMs acting as data creators, but instead of annotating the complete data, it
67"
RELATED WORK,0.09327846364883402,"only automatizes the process of creating the needle. I.e., given an original text, an LLM generates the
68"
RELATED WORK,0.09465020576131687,"needle. The needle then substitutes the ground truth.
69"
CAPTURING THE STRUCTURE,0.09602194787379972,"3
Capturing the structure
70"
CAPTURING THE STRUCTURE,0.09739368998628258,"The form of needles depends on a form of data, on structure capturing the information and on the
71"
CAPTURING THE STRUCTURE,0.09876543209876543,"task being solved. The needles can be short paragraphs of text, account records, graph nodes as you
72"
CAPTURING THE STRUCTURE,0.10013717421124829,"extract information from continuous text, table, graph, respectively. The structured arrangement of
73"
CAPTURING THE STRUCTURE,0.10150891632373114,"information is beneficial for consecutive processing and analysis. It helps to highlight relationships
74"
CAPTURING THE STRUCTURE,0.102880658436214,"among distinct information pieces. There are countless ways to impose a structure on unstructured
75"
CAPTURING THE STRUCTURE,0.10425240054869685,"data in order to capture the relevant information. To demonstrate our methodology for measuring the
76"
CAPTURING THE STRUCTURE,0.1056241426611797,"quality of information extraction, we specify a particular structure and tailor the needles to it.
77"
SCHEMA,0.10699588477366255,"3.1
Schema
78"
SCHEMA,0.1083676268861454,"To impose a structure on the data, we adopt the idea of schema markup [3] which is used to
79"
SCHEMA,0.10973936899862825,"communicate the content of a web page to the search tool. The schema markup is in the form of
80"
SCHEMA,0.1111111111111111,"structured data and can be viewed as a compression of the essential information. The structure
81"
SCHEMA,0.11248285322359397,"is defined by Schema.org2 vocabulary which is a set of entity types, each associated with a set of
82"
SCHEMA,0.11385459533607682,"properties and hierarchically arranged. Figure 1 shows an example of structured information inspired
83"
SCHEMA,0.11522633744855967,"by Schema.org. It describes three entities of types ‘Insight’, ‘Person’ and ‘Organization’. Each
84"
SCHEMA,0.11659807956104253,"1https://github.com/gkamradt/LLMTest_NeedleInAHaystack
2https://schema.org"
SCHEMA,0.11796982167352538,"type has its own set of properties, e.g., an entity of type ‘Person’ is described by ‘type’, ‘name’,
85"
SCHEMA,0.11934156378600823,"‘birthDate’, ‘worksFor’, and ‘jobTitle’. In other words, each entity is a set of key-value pairs, e.g.,
86"
SCHEMA,0.12071330589849108,"‘name’ is the key and ‘AI Enthusiast’ is the value.
87"
SCHEMA,0.12208504801097393,Figure 1: Toy example: structured information encapsulating three entities using schema.org.
SCHEMA,0.12345679012345678,"Similarly, we extract and compress the relevant information contained in data using an LLM.
88"
SCHEMA,0.12482853223593965,"Schema.org presents a clear basis for the categorization of various entities contained in data. In the
89"
SCHEMA,0.1262002743484225,"rest of the paper, by schema we mean a predetermined set of types, such as {‘Person’, ‘Project’,
90"
SCHEMA,0.12757201646090535,"‘Product’, ‘Legislation’, ‘Event’, ‘OpportunityArea’, ‘Insight’, ‘Substance’, ‘Thing’, ‘BioChemEn-
91"
SCHEMA,0.1289437585733882,"tity’, ‘MedicalCondition’}, together with their properties. The schema is set at the beginning and
92"
SCHEMA,0.13031550068587106,"the information to be extracted depends on it. Therefore the schema has to be tailored to a particular
93"
SCHEMA,0.13168724279835392,"scope of the (proprietary) knowledge and application. If a more complex or uncommon entity needs
94"
SCHEMA,0.13305898491083676,"to be captured, it is natural and very easy to extend the set of core types by more detailed descriptive
95"
SCHEMA,0.13443072702331962,"and custom vocabulary. E.g., ‘Insight’ and ‘OpportunityArea’ are not native Schema.org types, but
96"
SCHEMA,0.13580246913580246,"we will use them in our study. The usage of suitably tailored schema is beneficial for specialized
97"
SCHEMA,0.13717421124828533,"applications since it narrows the information to the relevant core and hence potentially improves the
98"
SCHEMA,0.13854595336076816,"overall performance. On the other hand, the usage of schemata is not restrictive as the scope can be
99"
SCHEMA,0.13991769547325103,"always extended by using a broader set of types.
100"
THE ROLE OF LLMS,0.1412894375857339,"3.2
The role of LLMs
101"
THE ROLE OF LLMS,0.14266117969821673,"LLMs are rather effective in the creation of structured data, cf. [9]. Using dedicated prompts, we get
102"
THE ROLE OF LLMS,0.1440329218106996,"a structured text file describing entities found in the documents and matching types of predefined
103"
THE ROLE OF LLMS,0.14540466392318244,"schema. The predefined schema (types and properties) is given to an LLM within the prompt. The
104"
THE ROLE OF LLMS,0.1467764060356653,"LLM is asked to analyse the document, identify an information relevant to the mentioned types of
105"
THE ROLE OF LLMS,0.14814814814814814,"entities and populate the schema with this information. It is asked to be attentive to nested entities,
106"
THE ROLE OF LLMS,0.149519890260631,"maintain consistency and uniqueness of extracted entities. Indeed, LLM is not prohibited from
107"
THE ROLE OF LLMS,0.15089163237311384,"extracting entities whose types do not appear in the predefined schema. It is worthy to note, that
108"
THE ROLE OF LLMS,0.1522633744855967,"LLMs are known to inherit biases present in their training data. If not carefully managed, these biases
109"
THE ROLE OF LLMS,0.15363511659807957,"could lead to unfair or inaccurate information extraction, impacting decision-making processes.
110"
THE ROLE OF LLMS,0.1550068587105624,"Besides the information extraction task, LLMs can be used to suggest suitable Schema.org types for
111"
THE ROLE OF LLMS,0.15637860082304528,"a particular document. An example together with a prompt is shown in Appendix B1.
112"
LENGTH ASPECTS,0.15775034293552812,"4
Length aspects
113"
LENGTH ASPECTS,0.15912208504801098,"When focusing on the quality of IE performed by an LLM, several limitations that LLM presents
114"
LENGTH ASPECTS,0.16049382716049382,"in terms of the length of data to be extracted from must be considered. Each LLM has a maximal
115"
LENGTH ASPECTS,0.16186556927297668,"content limit it can process, both on the input and the output. The limit on the output is typically
116"
LENGTH ASPECTS,0.16323731138545952,"much more strict. When trying to use the maximal possible input another issue may appear – the
117"
LENGTH ASPECTS,0.1646090534979424,"Lost in the middle phenomenon [8] says that the ability of LLMs to retrieve information from a long
118"
LENGTH ASPECTS,0.16598079561042525,"context declines and that the attention focuses on the beginning and the end of the context while it
119"
LENGTH ASPECTS,0.1673525377229081,"tends to attenuate information in the middle.
120"
LENGTH ASPECTS,0.16872427983539096,"To demonstrate shortcomings arising from these limitations numerically we use gpt-4-1106-preview
121"
LENGTH ASPECTS,0.1700960219478738,"model.3 The model is limited by 4095 tokens on the output and by 128000 tokens on the input
122"
LENGTH ASPECTS,0.17146776406035666,"(context window limit). The following sections present two major LLM limitations we have to
123"
LENGTH ASPECTS,0.1728395061728395,"consider before performing IE, namely length restrictions in Section 4.1 and Lost in the middle
124"
LENGTH ASPECTS,0.17421124828532236,"problem in Section 4.2.
125"
LENGTH RESTRICTIONS,0.1755829903978052,"4.1
Length restrictions
126"
LENGTH RESTRICTIONS,0.17695473251028807,"Long data are difficult to process because of the restrictions posed by the maximum amount of:
127"
LENGTH RESTRICTIONS,0.17832647462277093,"(O) output tokens: The restriction on output tokens means that there is some maximal length of
128"
LENGTH RESTRICTIONS,0.17969821673525377,"data from which most entities can be efficiently extracted. If the length of the text exceeds
129"
LENGTH RESTRICTIONS,0.18106995884773663,"this maximum, there would be no tokens for extra entities.
130"
LENGTH RESTRICTIONS,0.18244170096021947,"(I) input tokens: Maximal size of context window (input) prohibits the extraction of data
131"
LENGTH RESTRICTIONS,0.18381344307270234,"exceeding the specific token limit.
132"
LENGTH RESTRICTIONS,0.18518518518518517,"Another difficulty regarding the output is the tendency of LLMs to generate rather brief responses
133"
LENGTH RESTRICTIONS,0.18655692729766804,"which do not use the allowed maximal number of tokens. This unwillingness of models can be
134"
LENGTH RESTRICTIONS,0.18792866941015088,"circumvented by prompting. Even so, the limited number of output tokens is typically too low and
135"
LENGTH RESTRICTIONS,0.18930041152263374,"prevents effective extraction from long texts.
136"
LENGTH RESTRICTIONS,0.1906721536351166,"With a more sophisticated approach, the restriction (O) becomes irrelevant and only the restriction (I)
137"
LENGTH RESTRICTIONS,0.19204389574759945,"will apply. The issue imposed by (O) is overcome by splitting the source document into smaller pieces
138"
LENGTH RESTRICTIONS,0.1934156378600823,"which are extracted independently. A significant drawback is that the extracted information can be
139"
LENGTH RESTRICTIONS,0.19478737997256515,"easily duplicated – extracted independently from multiple text pieces. Iterating the calls to the LLM
140"
LENGTH RESTRICTIONS,0.19615912208504802,"with instruction to continue with already started extraction, i.e., continuing with the extraction in a
141"
LENGTH RESTRICTIONS,0.19753086419753085,"single thread, helps to extract more information and avoid duplication. As we insist on continuation,
142"
LENGTH RESTRICTIONS,0.19890260631001372,"more and more information is added and the extraction is more thorough, at least to some point – this
143"
LENGTH RESTRICTIONS,0.20027434842249658,"will be addressed in detail in Section 5.1. Further, a lower number of duplicates is found due to the
144"
LENGTH RESTRICTIONS,0.20164609053497942,"extraction history, i.e., all information extracted until present, which is kept within the thread.
145"
LENGTH RESTRICTIONS,0.2030178326474623,"The combination of both improvements – text splitting and iterated calls, has proven itself to perform
146"
LENGTH RESTRICTIONS,0.20438957475994513,"the best. We split the document into distinct text pieces which we extract sequentially. Extraction
147"
LENGTH RESTRICTIONS,0.205761316872428,"from each text piece is carried out by several iterated LLM calls while taking into account the
148"
LENGTH RESTRICTIONS,0.20713305898491083,"extraction history from previously extracted text pieces. Once the sum of the lengths of the text
149"
LENGTH RESTRICTIONS,0.2085048010973937,"pieces and the extraction history exceeds the context window limit, i.e., restriction (I) applies, a new
150"
LENGTH RESTRICTIONS,0.20987654320987653,"independent extraction starts. A single structured output, per document or once (I) is applied, is
151"
LENGTH RESTRICTIONS,0.2112482853223594,"created by appending all entities identified from each text piece.
152"
LOST IN THE MIDDLE,0.21262002743484226,"4.2
Lost in the middle
153"
LOST IN THE MIDDLE,0.2139917695473251,"In the case of long documents, whose extraction consumes almost the whole context window,
154"
LOST IN THE MIDDLE,0.21536351165980797,"LLMs are giving more inconsistent results and we can observe a presence of the Lost in the middle
155"
LOST IN THE MIDDLE,0.2167352537722908,"phenomenon, see [8]. We extract information from several long documents from our business case
156"
LOST IN THE MIDDLE,0.21810699588477367,"which are each split into 15 pieces and its processing consumes almost the whole context window.
157"
LOST IN THE MIDDLE,0.2194787379972565,"We add the sixteenth piece identical to one of the fifteen that are already extracted and measure a
158"
LOST IN THE MIDDLE,0.22085048010973937,"redundancy score, for details see Appendix A. Each column of Table 1 then states the redundancy of
159"
LOST IN THE MIDDLE,0.2222222222222222,"the newly extracted information with the information that was already extracted from the same piece
160"
LOST IN THE MIDDLE,0.22359396433470508,"of the text before. The table presents mean values per four distinct documents. We can notice that
161"
LOST IN THE MIDDLE,0.22496570644718794,3https://platform.openai.com/docs/models/overview
LOST IN THE MIDDLE,0.22633744855967078,"for the parts ’in the middle’ the proportion of redundantly extracted entities (entities with the same
162"
LOST IN THE MIDDLE,0.22770919067215364,"’name’ attribute) is higher than for those at the beginning and the end.
163"
LOST IN THE MIDDLE,0.22908093278463648,"Table 1: Are we lost in the middle? After finishing the extraction of a whole document (consisting of
fifteen pieces), we re-extract the information from each of its pieces. Columns 1-15 then compare
the re-extracted information with the information that was extracted from the same piece of the text
before. The pieces in the middle of the document contain more duplicated entities then those at the
beginning and the end."
LOST IN THE MIDDLE,0.23045267489711935,"part
1
2
3
4
5
6
redundancy (key = ’name’)
0
0
0.2266
0.1150
0.1482
0.3816"
LOST IN THE MIDDLE,0.23182441700960219,"7
8
9
10
11
12
13
14
15
0.3334
0.4643
0.7398
0.5152
0.6672
0.4659
0.3820
0.4473
0.4086"
QUALITY OF EXTRACTION,0.23319615912208505,"5
Quality of extraction
164"
QUALITY OF EXTRACTION,0.2345679012345679,"Once the information is extracted from data into a structured form defined by the chosen schema,
165"
QUALITY OF EXTRACTION,0.23593964334705075,"e.g., Figure 1, the quality of such extraction is important to evaluate. In practice, it is very rare to be
166"
QUALITY OF EXTRACTION,0.23731138545953362,"equipped with ground truth and its human generation requires vast expertise in the scope of data and a
167"
QUALITY OF EXTRACTION,0.23868312757201646,"ridiculous amount of time. Therefore we adopt methods from [4]. They examine semantic similarity,
168"
QUALITY OF EXTRACTION,0.24005486968449932,"relevance, redundancy, and bias and compound these into a single score called SUSWIR, for details
169"
QUALITY OF EXTRACTION,0.24142661179698216,"see Appendix A. The score and its subparts are very useful when comparing distinct extractions
170"
QUALITY OF EXTRACTION,0.24279835390946503,"among themselves, e.g., we can use it to find an optimal number of iterated LLM calls. Unfortunately,
171"
QUALITY OF EXTRACTION,0.24417009602194786,"the score does not represent an absolute way of evaluation. It does not provide a complete insight into
172"
QUALITY OF EXTRACTION,0.24554183813443073,"the task – some information (= entities) can be missing, misclassified or their properties not filled
173"
QUALITY OF EXTRACTION,0.24691358024691357,"in correctly. To come up with a robust and general solution we generalize the NIAH test, which is
174"
QUALITY OF EXTRACTION,0.24828532235939643,"commonly used to measure the ability of LLMs to process long documents, cf. [6].
175"
ITERATED LLM CALLS,0.2496570644718793,"5.1
Iterated LLM calls
176"
ITERATED LLM CALLS,0.25102880658436216,"Since the first LLM extraction is typically not exhaustive, iterating the extraction process helps with
177"
ITERATED LLM CALLS,0.252400548696845,"the completeness of extraction. To improve the quality of extraction, we ask LLM to process the
178"
ITERATED LLM CALLS,0.25377229080932784,"document again and search for other entities which were not extracted yet. A question arises: What is
179"
ITERATED LLM CALLS,0.2551440329218107,"the optimal number of iterations? It is desirable to stop when additional LLM call will return no or
180"
ITERATED LLM CALLS,0.25651577503429357,"only a few new entities. The answer however depends heavily on the text being extracted and on the
181"
ITERATED LLM CALLS,0.2578875171467764,"chosen schema. Below, we present a small comparative study regarding the contribution of iterated
182"
ITERATED LLM CALLS,0.25925925925925924,"extraction to its quality. We interpret the extracted structured data, e.g., Figure 3, as a summary of
183"
ITERATED LLM CALLS,0.2606310013717421,"the original text document. To measure the quality of the summary we adopt the scores from [4] (a
184"
ITERATED LLM CALLS,0.262002743484225,"convex combination of these scores creates the overall SUSWIR metric), namely semantic similarity,
185"
ITERATED LLM CALLS,0.26337448559670784,"relevance, and redundancy avoidance. We use a modified bias avoidance score from [4] and add two
186"
ITERATED LLM CALLS,0.26474622770919065,"new scores, relevance spread, and incompleteness score. See Appendix A for more details.
187"
ITERATED LLM CALLS,0.2661179698216735,"Consider document which length is approximately 12k chars. Table 2 compares the content of the
188"
ITERATED LLM CALLS,0.2674897119341564,"document with extracted information created iteratively by succeeding LLM calls. Each iteration
189"
ITERATED LLM CALLS,0.26886145404663925,"enriches the extracted information, but the benefit decreases. From the third iteration, i.e., after
190"
ITERATED LLM CALLS,0.27023319615912206,"four LLM calls, the majority of scores in Table 2 are either getting worse or stagnating (the arrows
191"
ITERATED LLM CALLS,0.2716049382716049,"following the score name indicate the direction in which the score improves). It is obvious that shorter
192"
ITERATED LLM CALLS,0.2729766803840878,"and longer text will require less or more iterations to extract majority of information without reducing
193"
ITERATED LLM CALLS,0.27434842249657065,"its semantic and factually relevant meaning, respectively. Further, the risk that the LLM will suffer
194"
ITERATED LLM CALLS,0.2757201646090535,"from hallucinations increases as we observe a growth of bias. In the rest of the paper we use three
195"
ITERATED LLM CALLS,0.27709190672153633,"iterations to extract documents of approximate length 12k chars within all extractions (if not stated
196"
ITERATED LLM CALLS,0.2784636488340192,"otherwise).
197"
TEST THE QUALITY,0.27983539094650206,"5.2
Test the quality
198"
TEST THE QUALITY,0.2812071330589849,"This section introduces a robust and versatile score to objectively measure the quality of IE. Assuming
199"
TEST THE QUALITY,0.2825788751714678,"the structure is imposed by some schema, see Section 3.1, we would like to measure the IE quality as
200"
TEST THE QUALITY,0.2839506172839506,"Table 2: Quality of extraction depends on a number of calls to LLM. The first iterated call is the most
beneficial one. From some point (bold) the scores stagnate or even deteriorate. All scores have values
between 0 and 1, the arrows indicate whether lower (↓) or higher (↑) values are desired."
TEST THE QUALITY,0.28532235939643347,"# iterations
0
1
2
3
4
5
semantic similarity ↑
0.5416
0.6316
0.6899
0.7572
0.7540
0.7685
relevance ↑
0.3409
0.4396
0.4449
0.4746
0.4522
0.4445
relevance spread ↓
0.3364
0.2493
0.2350
0.1445
0.1428
0.1368
redundancy avoidance (0.2) ↑
0.7727
0.8670
0.8810
0.9257
0.9251
0.9307
redundancy avoidance (0.1) ↑
0.4697
0.5936
0.6854
0.8002
0.7972
0.8119
redundancy avoidance
0.8182
0.9163
0.9422
0.9650
0.9699
0.9726
(0.5, key=’name’) ↑
bias avoidance ↑
0.5614
0.5515
0.4925
0.4559
0.4447
0.4247
incompleteness ↓
0.
0.5862
0.6735
0.4217
0.5413
0.4615"
TEST THE QUALITY,0.28669410150891633,"a portion of successfully extracted entities, i.e., the accuracy of name entity recognition (NER) task
201"
TEST THE QUALITY,0.2880658436213992,"taking into account even the context captured by entity properties. Unfortunately, such an experiment
202"
TEST THE QUALITY,0.289437585733882,"is unfeasible without labeled data. As a consequence, it is unfeasible in many specialized tasks
203"
TEST THE QUALITY,0.2908093278463649,"because of the absence of suitable labeled data unseen by LLM models. This can be the case with
204"
TEST THE QUALITY,0.29218106995884774,"very recent datasets as well as proprietary datasets. To overcome this issue we use inspiration by
205"
TEST THE QUALITY,0.2935528120713306,"NIAH test to build up an automatic and general procedure to access the quality of IE tasks.
206"
NEEDLES,0.29492455418381347,"5.2.1
Needles
207"
NEEDLES,0.2962962962962963,"A ‘needle’ in our context represents an entity. It is created according to the chosen schema, i.e.,
208"
NEEDLES,0.29766803840877915,"a list of types we want to extract from the document. We use an LLM to generate a short paragraph
209"
NEEDLES,0.299039780521262,"introducing a new original (not appearing in the document) entity, but still relevant to the scope of the
210"
NEEDLES,0.3004115226337449,"document, for an example see Figure 2, and for more details on generation process see Appendix B2.
211"
NEEDLES,0.3017832647462277,"This artificial paragraph, the needle, is then placed into the document body at random (taking into
212"
NEEDLES,0.30315500685871055,"the account natural units within the text as sentences, paragraphs, etc. if applicable). Moreover,
213"
NEEDLES,0.3045267489711934,"the needle is accompanied with several properties, namely we assign to the needle a name, short
214"
NEEDLES,0.3058984910836763,"description and keywords, see Figure 2. This additional properties are assigned to the needle by the
215"
NEEDLES,0.30727023319615915,"LLM.
216"
MULTIPLE INFUSED NEEDLE EXTRACTION ACCURACY,0.30864197530864196,"5.2.2
Multiple infused needle extraction accuracy
217"
MULTIPLE INFUSED NEEDLE EXTRACTION ACCURACY,0.3100137174211248,"To measure the quality of extraction we propose a multiple infused needle extraction accuracy
218"
MULTIPLE INFUSED NEEDLE EXTRACTION ACCURACY,0.3113854595336077,"(MINEA) score. Its computation combines the approach of NIAH evaluation and NER task. We
219"
MULTIPLE INFUSED NEEDLE EXTRACTION ACCURACY,0.31275720164609055,"scatter several needles at random over the text document body (such that the inserted needles fill 10
220"
MULTIPLE INFUSED NEEDLE EXTRACTION ACCURACY,0.31412894375857336,"to 30% of the enriched text) and measure how many of them were successfully extracted. Since we
221"
MULTIPLE INFUSED NEEDLE EXTRACTION ACCURACY,0.31550068587105623,"know what exactly was inserted, we know what should be extracted. Then we can objectively measure
222"
MULTIPLE INFUSED NEEDLE EXTRACTION ACCURACY,0.3168724279835391,"the quality of extraction on these new entities and moreover, we can compare extracted information
223"
MULTIPLE INFUSED NEEDLE EXTRACTION ACCURACY,0.31824417009602196,"from the document with and without needles. Table 3 shows extraction accuracy – MINEA score
224"
MULTIPLE INFUSED NEEDLE EXTRACTION ACCURACY,0.3196159122085048,"– total and per schema type – measured on a vast corpus of business documents with predefined
225"
MULTIPLE INFUSED NEEDLE EXTRACTION ACCURACY,0.32098765432098764,"schema consisting of types ‘BioChemEntity’, ‘Event’, ‘Insight’, ‘Legislation’, ‘MedicalCondition’,
226"
MULTIPLE INFUSED NEEDLE EXTRACTION ACCURACY,0.3223593964334705,"‘OpportunityArea’, ‘Person’, ‘Product’, ‘Project’, ‘Substance’ and ‘Thing’.
227"
IDENTIFICATION OF NEEDLES,0.32373113854595337,"5.2.3
Identification of needles
228"
IDENTIFICATION OF NEEDLES,0.32510288065843623,"Matching the generated needles with extracted entities imposes a challenge and mostly depends
229"
IDENTIFICATION OF NEEDLES,0.32647462277091904,"on the formulation of needles. If the needles are too complex or too vague, the straightforward
230"
IDENTIFICATION OF NEEDLES,0.3278463648834019,"identification changes into a serious problem. For this reason, we equip the needles with additional
231"
IDENTIFICATION OF NEEDLES,0.3292181069958848,"properties which are then used to compare the needles with extracted entities and to decide whether
232"
IDENTIFICATION OF NEEDLES,0.33058984910836764,"the needles were extracted successfully or not.
233"
IDENTIFICATION OF NEEDLES,0.3319615912208505,"We present several alternative ways how to measure whether the extraction of a needle is successful:
234"
IDENTIFICATION OF NEEDLES,0.3333333333333333,"n an entity with a name perfectly matching the needle name is found;
235"
IDENTIFICATION OF NEEDLES,0.3347050754458162,"ns the needle name is found among the extracted information;
236"
IDENTIFICATION OF NEEDLES,0.33607681755829905,"Figure 2: Toy example: two needles, highlighted by blue color, accompanied by additional informa-
tion described by ‘name’, ‘description’, and ‘keywords’."
IDENTIFICATION OF NEEDLES,0.3374485596707819,"Table 3: Quality of extraction – MINEA score – total and per schema type. Entity types are grouped
into five classes - 1. three most frequent schema.org types in the documents; 2. med-bio-chem
entities, somewhat interchangeable types; 3. best distinguishable types; 4. custom (non Schema.org)
types; 5. Schema.org types related to documents, but not stated in the chosen schema. Note: an entity
is assumed to be extracted if it is contained within the extracted information - often its type can be
misclassified (Project-Product-OpportunityArea, Substance-Thing-BioChemEntity) or sometimes it
can be mentioned indirectly (Organization is related to a Person by property ’works for’)."
IDENTIFICATION OF NEEDLES,0.3388203017832647,"class
entity type
extraction accuracy
# entities used for evaluation"
IDENTIFICATION OF NEEDLES,0.3401920438957476,"Person
0.884
69
1
Project
0.702
47
Product
0.750
52"
IDENTIFICATION OF NEEDLES,0.34156378600823045,"Substance
0.822
45
2
Thing
0.739
46
BioChemEntity
0.674
43
MedicalCondition
0.636
44"
LEGISLATION,0.3429355281207133,"3
Legislation
0.942
52
Event
0.915
47"
OPPORTUNITYAREA,0.3443072702331962,"4
OpportunityArea
0.671
73
Insight
0.747
91"
ORGANIZATION,0.345679012345679,"5
Organization
0.907
43
Place
0.767
43"
ORGANIZATION,0.34705075445816186,"overall
0.780
695"
ORGANIZATION,0.3484224965706447,"k an entity with some number of keywords perfectly matching the needle keywords is found,
237"
ORGANIZATION,0.3497942386831276,"the number is determined by the threshold parameter determining the percentage of keywords
238"
ORGANIZATION,0.3511659807956104,"to be matched;
239"
ORGANIZATION,0.35253772290809327,Figure 3: Toy example: extracted information from the data infused by needles from Figure 2.
ORGANIZATION,0.35390946502057613,"llm an entity matching the needle according to LLM is found.
240"
ORGANIZATION,0.355281207133059,"Table 4: Toy example: fulfillment of the conditions. The text enriched by two needles from Figure 2
was extracted into the form shown in Figure 3."
ORGANIZATION,0.35665294924554186,"entity type
condition for needle identification
n
ns
k0.5
k0.6
k0.7
llm"
ORGANIZATION,0.35802469135802467,"Event
0
1
1
0
0
1
Product
0
0
1
1
0
1"
ORGANIZATION,0.35939643347050754,"Note that other conditions can be constructed, e.g., based on the short description instead of keywords,
241"
ORGANIZATION,0.3607681755829904,"etc. Table 4 shows whether the conditions are fulfilled in the example illustrated by Figures 2 and
242"
ORGANIZATION,0.36213991769547327,"3. Namely, the condition n is not satisfied (‘AI Clan Meeting’ ̸= ‘AI Meeting’, ‘Graph Index’ ̸=
243"
ORGANIZATION,0.3635116598079561,"‘GRIX’). Condition ns is satisfied only for needle representing an entity of type ‘Event’ (‘AI Clan
244"
ORGANIZATION,0.36488340192043894,"Meeting’ can be found in the extracted information). There are three keywords out of the six assigned
245"
ORGANIZATION,0.3662551440329218,"to the needle representing the entity of type ‘Event’ which match the keywords of an extracted entity,
246"
ORGANIZATION,0.3676268861454047,"hence k0.5 is, and k0.6, k0.7 are not satisfied (there is an entity within the extracted information
247"
ORGANIZATION,0.36899862825788754,"with 50% of keywords being the same as the keywords of the needle). In the case of the second
248"
ORGANIZATION,0.37037037037037035,"needle, there are four such keywords, therefore k0.5 and k0.6 are satisfied. Finally, both needles are
249"
ORGANIZATION,0.3717421124828532,"identified within the extracted information by an LLM.
250"
ORGANIZATION,0.3731138545953361,"Table 5 shows scores (ratios of successfully extracted entities) based on the above criteria in the case
251"
ORGANIZATION,0.37448559670781895,"of our business documents. The types of inserted needles are ’BioChemEntity’, ’Country’, ’Event’,
252"
ORGANIZATION,0.37585733882030176,"’Insight’, ’Legislation’, ’Person’, ’Product’, ’Project’ and ’Substance’. Matching the needle and
253"
ORGANIZATION,0.3772290809327846,"entity name usually does not perform well if the name is prone to modification (e.g., person name
254"
ORGANIZATION,0.3786008230452675,"with and without title), or if the entity is easy to be misclassified (an entity of type ‘Country’ was
255"
ORGANIZATION,0.37997256515775035,"often extracted as ‘Place’ whose name did not match the country name). Searching for a needle name
256"
ORGANIZATION,0.3813443072702332,"in all extracted information gives very accurate results if the entities are well characterized by their
257"
ORGANIZATION,0.38271604938271603,"name (compare for example types ‘Person’ and ’Legislation’ with type ’Insight’ where the name is
258"
ORGANIZATION,0.3840877914951989,"not a natural attribute). Matching the needle and entity keywords depends on the threshold parameter
259"
ORGANIZATION,0.38545953360768176,"– with a lower proportion of keywords that have to match the score value increases and the reliability
260"
ORGANIZATION,0.3868312757201646,"of the entity identification decreases. An LLM performs well the entity identification and it is an
261"
ORGANIZATION,0.38820301783264743,"important criterion in the case of more creative types such as ‘Insight’. Finally, the MINEA score for
262"
ORGANIZATION,0.3895747599451303,"each type is taken as the maximum of the scores (the values are highlighted).
263"
ORGANIZATION,0.39094650205761317,"Table 5: The decision about the success of needle extraction can be made based on several criteria:
comparing the corresponding needle and entity properties (columns n and k0.5-k0.7 compare name
and keywords, respectively), full-text search (column ns search for the needle name in extracted
information), comparison of needles and entities using LLM (column llm)."
ORGANIZATION,0.39231824417009603,"entity type
condition for needle identification
# entities used
n
ns
k0.5
k0.6
k0.7
llm
for evaluation"
ORGANIZATION,0.3936899862825789,"Person
0.594
0.884
0.652
0.362
0.232
0.826
69
Project
0.170
0.702
0.638
0.234
0.085
0.681
47
Product
0.596
0.712
0.462
0.192
0.135
0.750
52
Country
0
0.765
0.412
0.294
0.059
0.471
17
Legislation
0.635
0.942
0.365
0.269
0.096
0.942
52
Event
0.830
0.851
0.638
0.511
0.149
0.915
47
Insight
0.176
0.187
0.714
0.418
0.088
0.747
91
BioChemEntity
0.116
0.605
0.651
0.581
0.488
0.674
43
Substance
0.289
0.578
0.822
0.644
0.222
0.800
45"
MODEL COMPARISON,0.3950617283950617,"5.2.4
Model comparison
264"
MODEL COMPARISON,0.39643347050754457,"MINEA score can be used to compare the performance of distinct LLMs, see Table 6. A corpus
265"
MODEL COMPARISON,0.39780521262002744,"of documents is infused by needles representing entities whose types match the schema introduced
266"
MODEL COMPARISON,0.3991769547325103,"in Section 5.2.2. Three OpenAI LLMs4 are used to extract a relevant information under the same
267"
MODEL COMPARISON,0.40054869684499317,"setting (the same model parameters such as temperature, the same number of iterations, the same
268"
MODEL COMPARISON,0.401920438957476,"prompting, etc.). Model gpt-3.5-turbo is outperformed by gpt-4-turbo by almost 15% and gpt-4-turbo
269"
MODEL COMPARISON,0.40329218106995884,"is outperformed by gpt-4o model by another 12%. Note that the achieved accuracy is lower than
270"
MODEL COMPARISON,0.4046639231824417,"presented in Table 3, since only one iteration instead of three was performed in order to reduce the
271"
MODEL COMPARISON,0.4060356652949246,"computational time.
272"
MODEL COMPARISON,0.4074074074074074,Table 6: LLMs comparison using MINEA score.
MODEL COMPARISON,0.40877914951989025,"model
gpt-3.5-turbo
gpt-4-turbo
gpt-4o"
MODEL COMPARISON,0.4101508916323731,"MINEA
0.449198
0.593583
0.716578"
MODEL COMPARISON,0.411522633744856,"Conclusions
273"
MODEL COMPARISON,0.41289437585733885,"In this paper, we focused on quality evaluation of information extraction (IE) performed by large
274"
MODEL COMPARISON,0.41426611796982166,"language models (LLMs). First, we delved into the technical limitations of LLMs complicating the
275"
MODEL COMPARISON,0.4156378600823045,"extraction of information from a long context. To extract reasonable information from data it is
276"
MODEL COMPARISON,0.4170096021947874,"needed to take into the account features such as context window limits, iterated extractions, extraction
277"
MODEL COMPARISON,0.41838134430727025,"history recording and Lost in the middle phenomenon. Once the extraction is performed, assessing its
278"
MODEL COMPARISON,0.41975308641975306,"quality is essential. However in many customized tasks, a truly objective method is missing, because
279"
MODEL COMPARISON,0.42112482853223593,"of the lack of labeled data fitting the scope of the application. The versatile method presented in this
280"
MODEL COMPARISON,0.4224965706447188,"paper overcomes the issue by adjustment of the data by insertion of an artificial information, a needle,
281"
MODEL COMPARISON,0.42386831275720166,"into it. The artificial information created to this purpose is application and data-specific, but the
282"
MODEL COMPARISON,0.4252400548696845,"method itself is applicable generally across the field of IE. By controlling the generation process of
283"
MODEL COMPARISON,0.42661179698216734,"the needles, we created a synthetic ground truth that enables us to absolutely measure the extraction
284"
MODEL COMPARISON,0.4279835390946502,"quality even when no labeled data is available. We introduced a MINEA score to measure the quality
285"
MODEL COMPARISON,0.42935528120713307,"of extraction. The key part is a decision rule on whether a needle was successfully extracted or not.
286"
MODEL COMPARISON,0.43072702331961593,"MINEA possibly combines several decision rules into one final score. Our empirical analysis of the
287"
MODEL COMPARISON,0.43209876543209874,"MINEA score on a specialized dataset demonstrated its utility for evaluation of LLM-based IE tasks
288"
MODEL COMPARISON,0.4334705075445816,"when ground truth is unavailable.
289"
MODEL COMPARISON,0.4348422496570645,4https://platform.openai.com/docs/models
REFERENCES,0.43621399176954734,"References
290"
REFERENCES,0.4375857338820302,"[1] Kiran Adnan and Rehan Akbar. Limitations of information extraction methods and techniques for
291"
REFERENCES,0.438957475994513,"heterogeneous unstructured big data. International Journal of Engineering Business Management,
292"
REFERENCES,0.4403292181069959,"11:1847979019890771, 2019.
293"
REFERENCES,0.44170096021947874,"[2] Satanjeev Banerjee and Alon Lavie. METEOR: An automatic metric for MT evaluation with
294"
REFERENCES,0.4430727023319616,"improved correlation with human judgments. In Proceedings of the acl workshop on intrinsic
295"
REFERENCES,0.4444444444444444,"and extrinsic evaluation measures for machine translation and/or summarization, pages 65–72,
296"
REFERENCES,0.4458161865569273,"2005.
297"
REFERENCES,0.44718792866941015,"[3] Matthew Edgar. Schema and structured data markup. In Tech SEO Guide: A Reference Guide for
298"
REFERENCES,0.448559670781893,"Developers and Marketers Involved in Technical SEO, pages 67–78. Springer, 2023.
299"
REFERENCES,0.4499314128943759,"[4] Abdullah Al Foysal and Ronald Böck. Who Needs External References?—Text Summarization
300"
REFERENCES,0.4513031550068587,"Evaluation Using Original Documents. AI, 4(4):970–995, 2023.
301"
REFERENCES,0.45267489711934156,"[5] Neil Jethani, Simon Jones, Nicholas Genes, Vincent J Major, Ian S Jaffe, Anthony B Cardillo,
302"
REFERENCES,0.4540466392318244,"Noah Heilenbach, Nadia Fazal Ali, Luke J Bonanni, Andrew J Clayburn, et al. Evaluating
303"
REFERENCES,0.4554183813443073,"ChatGPT in Information Extraction: A Case Study of Extracting Cognitive Exam Dates and
304"
REFERENCES,0.4567901234567901,"Scores. 2023.
305"
REFERENCES,0.45816186556927296,"[6] Yuri Kuratov, Aydar Bulatov, Petr Anokhin, Dmitry Sorokin, Artyom Sorokin, and Mikhail
306"
REFERENCES,0.45953360768175583,"Burtsev. In Search of Needles in a 11M Haystack: Recurrent Memory Finds What LLMs Miss.
307"
REFERENCES,0.4609053497942387,"arXiv preprint arXiv:2402.10790v2, 2024.
308"
REFERENCES,0.46227709190672156,"[7] Dong-Ho Lee, Jay Pujara, Mohit Sewak, Ryen W White, and Sujay Kumar Jauhar. Making large
309"
REFERENCES,0.46364883401920437,"language models better data creators. arXiv preprint arXiv:2310.20111, 2023.
310"
REFERENCES,0.46502057613168724,"[8] Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni,
311"
REFERENCES,0.4663923182441701,"and Percy Liang. Lost in the middle: How language models use long contexts. arXiv preprint
312"
REFERENCES,0.46776406035665297,"arXiv:2307.03172, 2023.
313"
REFERENCES,0.4691358024691358,"[9] Derong Xu, Wei Chen, Wenjun Peng, Chao Zhang, Tong Xu, Xiangyu Zhao, Xian Wu, Yefeng
314"
REFERENCES,0.47050754458161864,"Zheng, and Enhong Chen. Large language models for generative information extraction: A
315"
REFERENCES,0.4718792866941015,"survey. arXiv preprint arXiv:2312.17617, 2023.
316"
REFERENCES,0.4732510288065844,"Appendix A
317"
REFERENCES,0.47462277091906724,"To measure the quality of the summary we adopt the methods from [4]: semantic similarity combines
318"
REFERENCES,0.47599451303155005,"latent semantic similarity and cosine similarity; relevance is measured using METEOR score, see
319"
REFERENCES,0.4773662551440329,"[2], without chunk penalty; redundancy avoidance compares extracted entities among themselves
320"
REFERENCES,0.4787379972565158,"using a threshold parameter – entities with a higher cosine similarity are assumed to be redundant;
321"
REFERENCES,0.48010973936899864,"redundancy avoidance can be focused on a single particular property of entities (we use ’name’ as
322"
REFERENCES,0.48148148148148145,"this pivotal property).
323"
REFERENCES,0.4828532235939643,"We modify the bias avoidance score from [4] to be J∗(A, B) = |A∩B|"
REFERENCES,0.4842249657064472,"|B| , where A represents the
324"
REFERENCES,0.48559670781893005,"entities in the original text document and we normalize by a number of entities that were extracted,
325"
REFERENCES,0.4869684499314129,"|B|. The score controls how much information in the structured file is not present in the original text,
326"
REFERENCES,0.4883401920438957,"i.e., a potential hallucination of an LLM.
327"
REFERENCES,0.4897119341563786,"We add two new scores: the relevance spread is the standard deviation of relevance over the text
328"
REFERENCES,0.49108367626886146,"pieces to which the document is split and normalized by the mean value, its higher values indicate
329"
REFERENCES,0.4924554183813443,"that the extraction from distinct text pieces is unbalanced; the incompleteness score just measures the
330"
REFERENCES,0.49382716049382713,"proportion of entities with incomplete information (at least one property value missing or unfilled),
331"
REFERENCES,0.49519890260631,"e.g., the entity ‘AI Enthusiast’ in Figure 1 has an unknown ‘birthDate’.
332"
REFERENCES,0.49657064471879286,"Appendix B
333"
REFERENCES,0.49794238683127573,"Except for the IE task, LLMs are used in several subtasks within the paper, namely to determine
334"
REFERENCES,0.4993141289437586,"schema types appearing in the document, to create a suitable needles fitting contextually to the
335"
REFERENCES,0.5006858710562414,"document and to identify whether a needle was extracted or not. In the following, we provide the
336"
REFERENCES,0.5020576131687243,"reader with prompts and examples of these subtasks.
337"
REFERENCES,0.5034293552812071,"B1 Discovering a schema
338"
REFERENCES,0.50480109739369,"Figure 4 shows a prompt to obtain the Schema.org types from the attached text – Wikipedia article
339"
REFERENCES,0.5061728395061729,"about IE.5 An LLM is asked to assign relevance to the types to distinguish the most important ones.
340"
REFERENCES,0.5075445816186557,"Figure 5 shows the entity types that were deduced from the text, together with their relevance and
341"
REFERENCES,0.5089163237311386,"reasoning for why they were chosen. The most relevant types are those directly mentioned – ‘Article’,
342"
REFERENCES,0.5102880658436214,"as the webpage content itself is represented as an article, ‘SoftwareApplication’, and ‘WebSite’ (all
343"
REFERENCES,0.5116598079561042,"with maximal relevance). The least relevant identified types are generic – ‘Thing’, as a parent type of
344"
REFERENCES,0.5130315500685871,"many directly mentioned types, and ‘LearningResource’, as a categorization of the article style.
345"
REFERENCES,0.51440329218107,"Figure 4: Prompt to determine a possible suitable schema from a given text – Wikipedia article about
IE."
REFERENCES,0.5157750342935528,Figure 5: Schema.org types found by an LLM within Wikipedia article about IE.
REFERENCES,0.5171467764060357,5https://en.wikipedia.org/wiki/Information_extraction
REFERENCES,0.5185185185185185,"B2 Creating needles
346"
REFERENCES,0.5198902606310014,"A needle, i.e., a text paragraph fitting thematically to the document, but being new and unique to it, is
347"
REFERENCES,0.5212620027434842,"generated by an LLM using the prompt in Figure 6. The prompt specifies the type of entity that the
348"
REFERENCES,0.522633744855967,"needle should represent. Multiple needles of the same type can be obtained easily within a single
349"
REFERENCES,0.52400548696845,"LLM call.
350"
REFERENCES,0.5253772290809328,"Figure 7 shows ten needles representing the entities of type ‘Person’ generated based on a Wikipedia
351"
REFERENCES,0.5267489711934157,"article about IE. In the next step properties such as a name, description and keywords can be generated
352"
REFERENCES,0.5281207133058985,"by an LLM.
353"
REFERENCES,0.5294924554183813,"Figure 6: Prompt to generate needles. Given a Wikipedia article about IE, the LLM is asked to think
out 10 relevant persons."
REFERENCES,0.5308641975308642,"Figure 7: Needles generated by an LLM and representing ten entities of type ‘Person’. .
354"
REFERENCES,0.532235939643347,"B3 Identifying needles
355"
REFERENCES,0.53360768175583,"The quality of extraction is evaluated based on the proportion of successfully extracted needles. An
356"
REFERENCES,0.5349794238683128,"LLM can be used to decide whether the needle was extracted or not using the prompt presented in
357"
REFERENCES,0.5363511659807956,"Figure 8.
358"
REFERENCES,0.5377229080932785,Figure 8: Prompt to identify whether the needles were extracted or not.
REFERENCES,0.5390946502057613,"NeurIPS Paper Checklist
359"
CLAIMS,0.5404663923182441,"1. Claims
360"
CLAIMS,0.541838134430727,"Question: Do the main claims made in the abstract and introduction accurately reflect the
361"
CLAIMS,0.5432098765432098,"paper’s contributions and scope?
362"
CLAIMS,0.5445816186556928,"Answer: [Yes]
363"
CLAIMS,0.5459533607681756,"Justification: The abstract and introduction clearly state the development of an automatic
364"
CLAIMS,0.5473251028806584,"framework to assess the quality of information extraction (IE), which is the main contribution
365"
CLAIMS,0.5486968449931413,"of the paper. This is supported by the introduction of the MINEA score and the discussion
366"
CLAIMS,0.5500685871056241,"on handling input/output size limitations of large language models (LLMs).
367"
CLAIMS,0.551440329218107,"Guidelines:
368"
CLAIMS,0.5528120713305898,"• The answer NA means that the abstract and introduction do not include the claims
369"
CLAIMS,0.5541838134430727,"made in the paper.
370"
CLAIMS,0.5555555555555556,"• The abstract and/or introduction should clearly state the claims made, including the
371"
CLAIMS,0.5569272976680384,"contributions made in the paper and important assumptions and limitations. A No or
372"
CLAIMS,0.5582990397805213,"NA answer to this question will not be perceived well by the reviewers.
373"
CLAIMS,0.5596707818930041,"• The claims made should match theoretical and experimental results, and reflect how
374"
CLAIMS,0.5610425240054869,"much the results can be expected to generalize to other settings.
375"
CLAIMS,0.5624142661179699,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
376"
CLAIMS,0.5637860082304527,"are not attained by the paper.
377"
LIMITATIONS,0.5651577503429356,"2. Limitations
378"
LIMITATIONS,0.5665294924554184,"Question: Does the paper discuss the limitations of the work performed by the authors?
379"
LIMITATIONS,0.5679012345679012,"Answer: [Yes]
380"
LIMITATIONS,0.5692729766803841,"Justification: The paper discusses the limitations related to the complexity or vagueness of
381"
LIMITATIONS,0.5706447187928669,"the needles, dependence on the chosen schema and criteria for needle identification (Section
382"
LIMITATIONS,0.5720164609053497,"5). Further the paper focuses on limitations of LMMs in IE tasks such as input/output size
383"
LIMITATIONS,0.5733882030178327,"constraints, lost in the middle phenomenon, bias and hallucinations (Section 4).
384"
LIMITATIONS,0.5747599451303155,"Guidelines:
385"
LIMITATIONS,0.5761316872427984,"• The answer NA means that the paper has no limitation while the answer No means that
386"
LIMITATIONS,0.5775034293552812,"the paper has limitations, but those are not discussed in the paper.
387"
LIMITATIONS,0.578875171467764,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
388"
LIMITATIONS,0.5802469135802469,"• The paper should point out any strong assumptions and how robust the results are to
389"
LIMITATIONS,0.5816186556927297,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
390"
LIMITATIONS,0.5829903978052127,"model well-specification, asymptotic approximations only holding locally). The authors
391"
LIMITATIONS,0.5843621399176955,"should reflect on how these assumptions might be violated in practice and what the
392"
LIMITATIONS,0.5857338820301783,"implications would be.
393"
LIMITATIONS,0.5871056241426612,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
394"
LIMITATIONS,0.588477366255144,"only tested on a few datasets or with a few runs. In general, empirical results often
395"
LIMITATIONS,0.5898491083676269,"depend on implicit assumptions, which should be articulated.
396"
LIMITATIONS,0.5912208504801097,"• The authors should reflect on the factors that influence the performance of the approach.
397"
LIMITATIONS,0.5925925925925926,"For example, a facial recognition algorithm may perform poorly when image resolution
398"
LIMITATIONS,0.5939643347050755,"is low or images are taken in low lighting. Or a speech-to-text system might not be
399"
LIMITATIONS,0.5953360768175583,"used reliably to provide closed captions for online lectures because it fails to handle
400"
LIMITATIONS,0.5967078189300411,"technical jargon.
401"
LIMITATIONS,0.598079561042524,"• The authors should discuss the computational efficiency of the proposed algorithms
402"
LIMITATIONS,0.5994513031550068,"and how they scale with dataset size.
403"
LIMITATIONS,0.6008230452674898,"• If applicable, the authors should discuss possible limitations of their approach to
404"
LIMITATIONS,0.6021947873799726,"address problems of privacy and fairness.
405"
LIMITATIONS,0.6035665294924554,"• While the authors might fear that complete honesty about limitations might be used by
406"
LIMITATIONS,0.6049382716049383,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
407"
LIMITATIONS,0.6063100137174211,"limitations that aren’t acknowledged in the paper. The authors should use their best
408"
LIMITATIONS,0.607681755829904,"judgment and recognize that individual actions in favor of transparency play an impor-
409"
LIMITATIONS,0.6090534979423868,"tant role in developing norms that preserve the integrity of the community. Reviewers
410"
LIMITATIONS,0.6104252400548696,"will be specifically instructed to not penalize honesty concerning limitations.
411"
THEORY ASSUMPTIONS AND PROOFS,0.6117969821673526,"3. Theory Assumptions and Proofs
412"
THEORY ASSUMPTIONS AND PROOFS,0.6131687242798354,"Question: For each theoretical result, does the paper provide the full set of assumptions and
413"
THEORY ASSUMPTIONS AND PROOFS,0.6145404663923183,"a complete (and correct) proof?
414"
THEORY ASSUMPTIONS AND PROOFS,0.6159122085048011,"Answer: [NA]
415"
THEORY ASSUMPTIONS AND PROOFS,0.6172839506172839,"Justification: The paper does not include theoretical results that require formal proofs.
416"
THEORY ASSUMPTIONS AND PROOFS,0.6186556927297668,"Guidelines:
417"
THEORY ASSUMPTIONS AND PROOFS,0.6200274348422496,"• The answer NA means that the paper does not include theoretical results.
418"
THEORY ASSUMPTIONS AND PROOFS,0.6213991769547325,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
419"
THEORY ASSUMPTIONS AND PROOFS,0.6227709190672154,"referenced.
420"
THEORY ASSUMPTIONS AND PROOFS,0.6241426611796982,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
421"
THEORY ASSUMPTIONS AND PROOFS,0.6255144032921811,"• The proofs can either appear in the main paper or the supplemental material, but if
422"
THEORY ASSUMPTIONS AND PROOFS,0.6268861454046639,"they appear in the supplemental material, the authors are encouraged to provide a short
423"
THEORY ASSUMPTIONS AND PROOFS,0.6282578875171467,"proof sketch to provide intuition.
424"
THEORY ASSUMPTIONS AND PROOFS,0.6296296296296297,"• Inversely, any informal proof provided in the core of the paper should be complemented
425"
THEORY ASSUMPTIONS AND PROOFS,0.6310013717421125,"by formal proofs provided in appendix or supplemental material.
426"
THEORY ASSUMPTIONS AND PROOFS,0.6323731138545954,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
427"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6337448559670782,"4. Experimental Result Reproducibility
428"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.635116598079561,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
429"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6364883401920439,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
430"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6378600823045267,"of the paper (regardless of whether the code and data are provided or not)?
431"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6392318244170097,"Answer: [Yes]
432"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6406035665294925,"Justification: The paper provides detailed descriptions of the experimental setup, including
433"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6419753086419753,"the use of LLMs for IE and the creation of synthetic ground truth data. This is detailed in
434"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6433470507544582,"Sections 3 and 5.
435"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.644718792866941,"Guidelines:
436"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6460905349794238,"• The answer NA means that the paper does not include experiments.
437"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6474622770919067,"• If the paper includes experiments, a No answer to this question will not be perceived
438"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6488340192043895,"well by the reviewers: Making the paper reproducible is important, regardless of
439"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6502057613168725,"whether the code and data are provided or not.
440"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6515775034293553,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
441"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6529492455418381,"to make their results reproducible or verifiable.
442"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.654320987654321,"• Depending on the contribution, reproducibility can be accomplished in various ways.
443"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6556927297668038,"For example, if the contribution is a novel architecture, describing the architecture fully
444"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6570644718792867,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
445"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6584362139917695,"be necessary to either make it possible for others to replicate the model with the same
446"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6598079561042524,"dataset, or provide access to the model. In general. releasing code and data is often
447"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6611796982167353,"one good way to accomplish this, but reproducibility can also be provided via detailed
448"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6625514403292181,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
449"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.663923182441701,"of a large language model), releasing of a model checkpoint, or other means that are
450"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6652949245541838,"appropriate to the research performed.
451"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6666666666666666,"• While NeurIPS does not require releasing code, the conference does require all submis-
452"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6680384087791496,"sions to provide some reasonable avenue for reproducibility, which may depend on the
453"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6694101508916324,"nature of the contribution. For example
454"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6707818930041153,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
455"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6721536351165981,"to reproduce that algorithm.
456"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6735253772290809,"(b) If the contribution is primarily a new model architecture, the paper should describe
457"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6748971193415638,"the architecture clearly and fully.
458"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6762688614540466,"(c) If the contribution is a new model (e.g., a large language model), then there should
459"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6776406035665294,"either be a way to access this model for reproducing the results or a way to reproduce
460"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6790123456790124,"the model (e.g., with an open-source dataset or instructions for how to construct
461"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6803840877914952,"the dataset).
462"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6817558299039781,"(d) We recognize that reproducibility may be tricky in some cases, in which case
463"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6831275720164609,"authors are welcome to describe the particular way they provide for reproducibility.
464"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6844993141289437,"In the case of closed-source models, it may be that access to the model is limited in
465"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6858710562414266,"some way (e.g., to registered users), but it should be possible for other researchers
466"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6872427983539094,"to have some path to reproducing or verifying the results.
467"
OPEN ACCESS TO DATA AND CODE,0.6886145404663924,"5. Open access to data and code
468"
OPEN ACCESS TO DATA AND CODE,0.6899862825788752,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
469"
OPEN ACCESS TO DATA AND CODE,0.691358024691358,"tions to faithfully reproduce the main experimental results, as described in supplemental
470"
OPEN ACCESS TO DATA AND CODE,0.6927297668038409,"material?
471"
OPEN ACCESS TO DATA AND CODE,0.6941015089163237,"Answer: [No]
472"
OPEN ACCESS TO DATA AND CODE,0.6954732510288066,"Justification: The paper does not provide open access to the data and code due to the
473"
OPEN ACCESS TO DATA AND CODE,0.6968449931412894,"proprietary nature of the business documents used in the experiments. However, it provides
474"
OPEN ACCESS TO DATA AND CODE,0.6982167352537723,"detailed instructions on how to replicate the methodology.
475"
OPEN ACCESS TO DATA AND CODE,0.6995884773662552,"Guidelines:
476"
OPEN ACCESS TO DATA AND CODE,0.700960219478738,"• The answer NA means that paper does not include experiments requiring code.
477"
OPEN ACCESS TO DATA AND CODE,0.7023319615912208,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
478"
OPEN ACCESS TO DATA AND CODE,0.7037037037037037,"public/guides/CodeSubmissionPolicy) for more details.
479"
OPEN ACCESS TO DATA AND CODE,0.7050754458161865,"• While we encourage the release of code and data, we understand that this might not be
480"
OPEN ACCESS TO DATA AND CODE,0.7064471879286695,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
481"
OPEN ACCESS TO DATA AND CODE,0.7078189300411523,"including code, unless this is central to the contribution (e.g., for a new open-source
482"
OPEN ACCESS TO DATA AND CODE,0.7091906721536351,"benchmark).
483"
OPEN ACCESS TO DATA AND CODE,0.710562414266118,"• The instructions should contain the exact command and environment needed to run to
484"
OPEN ACCESS TO DATA AND CODE,0.7119341563786008,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
485"
OPEN ACCESS TO DATA AND CODE,0.7133058984910837,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
486"
OPEN ACCESS TO DATA AND CODE,0.7146776406035665,"• The authors should provide instructions on data access and preparation, including how
487"
OPEN ACCESS TO DATA AND CODE,0.7160493827160493,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
488"
OPEN ACCESS TO DATA AND CODE,0.7174211248285323,"• The authors should provide scripts to reproduce all experimental results for the new
489"
OPEN ACCESS TO DATA AND CODE,0.7187928669410151,"proposed method and baselines. If only a subset of experiments are reproducible, they
490"
OPEN ACCESS TO DATA AND CODE,0.720164609053498,"should state which ones are omitted from the script and why.
491"
OPEN ACCESS TO DATA AND CODE,0.7215363511659808,"• At submission time, to preserve anonymity, the authors should release anonymized
492"
OPEN ACCESS TO DATA AND CODE,0.7229080932784636,"versions (if applicable).
493"
OPEN ACCESS TO DATA AND CODE,0.7242798353909465,"• Providing as much information as possible in supplemental material (appended to the
494"
OPEN ACCESS TO DATA AND CODE,0.7256515775034293,"paper) is recommended, but including URLs to data and code is permitted.
495"
OPEN ACCESS TO DATA AND CODE,0.7270233196159122,"6. Experimental Setting/Details
496"
OPEN ACCESS TO DATA AND CODE,0.7283950617283951,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
497"
OPEN ACCESS TO DATA AND CODE,0.7297668038408779,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
498"
OPEN ACCESS TO DATA AND CODE,0.7311385459533608,"results?
499"
OPEN ACCESS TO DATA AND CODE,0.7325102880658436,"Answer: [Yes]
500"
OPEN ACCESS TO DATA AND CODE,0.7338820301783264,"Justification: The paper specifies the use of LLMs, the schema used for structuring data, and
501"
OPEN ACCESS TO DATA AND CODE,0.7352537722908093,"the process of generating needles for evaluation. These details are provided in Sections 3, 4
502"
OPEN ACCESS TO DATA AND CODE,0.7366255144032922,"and 5.
503"
OPEN ACCESS TO DATA AND CODE,0.7379972565157751,"Guidelines:
504"
OPEN ACCESS TO DATA AND CODE,0.7393689986282579,"• The answer NA means that the paper does not include experiments.
505"
OPEN ACCESS TO DATA AND CODE,0.7407407407407407,"• The experimental setting should be presented in the core of the paper to a level of detail
506"
OPEN ACCESS TO DATA AND CODE,0.7421124828532236,"that is necessary to appreciate the results and make sense of them.
507"
OPEN ACCESS TO DATA AND CODE,0.7434842249657064,"• The full details can be provided either with the code, in appendix, or as supplemental
508"
OPEN ACCESS TO DATA AND CODE,0.7448559670781894,"material.
509"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7462277091906722,"7. Experiment Statistical Significance
510"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.747599451303155,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
511"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7489711934156379,"information about the statistical significance of the experiments?
512"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7503429355281207,"Answer: [No]
513"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7517146776406035,"Justification: The paper does not include experiments that require statistical significance
514"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7530864197530864,"testing or error bars. The experiments in Sections 4 and 5 present mean values of reasonably
515"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7544581618655692,"large samples. The experiments are not repeated, each of them is carried once on a set of
516"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7558299039780522,"distinct documents containing a large amount of entities. In Section 5, a vast set of unique
517"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.757201646090535,"needles (with repeating types) is used to infuse the documents.
518"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7585733882030178,"Guidelines:
519"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7599451303155007,"• The answer NA means that the paper does not include experiments.
520"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7613168724279835,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
521"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7626886145404664,"dence intervals, or statistical significance tests, at least for the experiments that support
522"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7640603566529492,"the main claims of the paper.
523"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7654320987654321,"• The factors of variability that the error bars are capturing should be clearly stated (for
524"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.766803840877915,"example, train/test split, initialization, random drawing of some parameter, or overall
525"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7681755829903978,"run with given experimental conditions).
526"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7695473251028807,"• The method for calculating the error bars should be explained (closed form formula,
527"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7709190672153635,"call to a library function, bootstrap, etc.)
528"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7722908093278463,"• The assumptions made should be given (e.g., Normally distributed errors).
529"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7736625514403292,"• It should be clear whether the error bar is the standard deviation or the standard error
530"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7750342935528121,"of the mean.
531"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7764060356652949,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
532"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7777777777777778,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
533"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7791495198902606,"of Normality of errors is not verified.
534"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7805212620027435,"• For asymmetric distributions, the authors should be careful not to show in tables or
535"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7818930041152263,"figures symmetric error bars that would yield results that are out of range (e.g. negative
536"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7832647462277091,"error rates).
537"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7846364883401921,"• If error bars are reported in tables or plots, The authors should explain in the text how
538"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7860082304526749,"they were calculated and reference the corresponding figures or tables in the text.
539"
EXPERIMENTS COMPUTE RESOURCES,0.7873799725651578,"8. Experiments Compute Resources
540"
EXPERIMENTS COMPUTE RESOURCES,0.7887517146776406,"Question: For each experiment, does the paper provide sufficient information on the com-
541"
EXPERIMENTS COMPUTE RESOURCES,0.7901234567901234,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
542"
EXPERIMENTS COMPUTE RESOURCES,0.7914951989026063,"the experiments?
543"
EXPERIMENTS COMPUTE RESOURCES,0.7928669410150891,"Answer: [No]
544"
EXPERIMENTS COMPUTE RESOURCES,0.7942386831275721,"Justification: The paper does not provide detailed information on the compute resources used
545"
EXPERIMENTS COMPUTE RESOURCES,0.7956104252400549,"for the experiments. The requirements such as time of execution are determined especially
546"
EXPERIMENTS COMPUTE RESOURCES,0.7969821673525377,"by used LLMs.
547"
EXPERIMENTS COMPUTE RESOURCES,0.7983539094650206,"Guidelines:
548"
EXPERIMENTS COMPUTE RESOURCES,0.7997256515775034,"• The answer NA means that the paper does not include experiments.
549"
EXPERIMENTS COMPUTE RESOURCES,0.8010973936899863,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
550"
EXPERIMENTS COMPUTE RESOURCES,0.8024691358024691,"or cloud provider, including relevant memory and storage.
551"
EXPERIMENTS COMPUTE RESOURCES,0.803840877914952,"• The paper should provide the amount of compute required for each of the individual
552"
EXPERIMENTS COMPUTE RESOURCES,0.8052126200274349,"experimental runs as well as estimate the total compute.
553"
EXPERIMENTS COMPUTE RESOURCES,0.8065843621399177,"• The paper should disclose whether the full research project required more compute
554"
EXPERIMENTS COMPUTE RESOURCES,0.8079561042524005,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
555"
EXPERIMENTS COMPUTE RESOURCES,0.8093278463648834,"didn’t make it into the paper).
556"
CODE OF ETHICS,0.8106995884773662,"9. Code Of Ethics
557"
CODE OF ETHICS,0.8120713305898491,"Question: Does the research conducted in the paper conform, in every respect, with the
558"
CODE OF ETHICS,0.813443072702332,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
559"
CODE OF ETHICS,0.8148148148148148,"Answer: [Yes]
560"
CODE OF ETHICS,0.8161865569272977,"Justification: The research adheres to the NeurIPS Code of Ethics, ensuring that the methods
561"
CODE OF ETHICS,0.8175582990397805,"and data used do not violate ethical guidelines. The proprietary data used is handled with
562"
CODE OF ETHICS,0.8189300411522634,"confidentiality and integrity.
563"
CODE OF ETHICS,0.8203017832647462,"Guidelines:
564"
CODE OF ETHICS,0.821673525377229,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
565"
CODE OF ETHICS,0.823045267489712,"• If the authors answer No, they should explain the special circumstances that require a
566"
CODE OF ETHICS,0.8244170096021948,"deviation from the Code of Ethics.
567"
CODE OF ETHICS,0.8257887517146777,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
568"
CODE OF ETHICS,0.8271604938271605,"eration due to laws or regulations in their jurisdiction).
569"
BROADER IMPACTS,0.8285322359396433,"10. Broader Impacts
570"
BROADER IMPACTS,0.8299039780521262,"Question: Does the paper discuss both potential positive societal impacts and negative
571"
BROADER IMPACTS,0.831275720164609,"societal impacts of the work performed?
572"
BROADER IMPACTS,0.8326474622770919,"Answer: [Yes]
573"
BROADER IMPACTS,0.8340192043895748,"Justification: The paper is primarily concerned with the technical methodology, the intro-
574"
BROADER IMPACTS,0.8353909465020576,"duction of the MINEA score, and the empirical analysis of the framework’s performance.
575"
BROADER IMPACTS,0.8367626886145405,"The potential positive impacts are mentioned in Introduction: by automating the quality
576"
BROADER IMPACTS,0.8381344307270233,"assessment of information extraction, the framework could reduce the need for manual
577"
BROADER IMPACTS,0.8395061728395061,"review by experts, saving time and resources and thus enhance the efficiency and accuracy
578"
BROADER IMPACTS,0.840877914951989,"of information extraction from large volumes of unstructured data. The negative aspects of
579"
BROADER IMPACTS,0.8422496570644719,"using LLMs for IE tasks such as inherited bias and potential hallucinations are mentioned
580"
BROADER IMPACTS,0.8436213991769548,"especially in Sections 4.2 (Lost in the middle problem) and 5.1 (bias avoidance score).
581"
BROADER IMPACTS,0.8449931412894376,"Guidelines:
582"
BROADER IMPACTS,0.8463648834019204,"• The answer NA means that there is no societal impact of the work performed.
583"
BROADER IMPACTS,0.8477366255144033,"• If the authors answer NA or No, they should explain why their work has no societal
584"
BROADER IMPACTS,0.8491083676268861,"impact or why the paper does not address societal impact.
585"
BROADER IMPACTS,0.850480109739369,"• Examples of negative societal impacts include potential malicious or unintended uses
586"
BROADER IMPACTS,0.8518518518518519,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
587"
BROADER IMPACTS,0.8532235939643347,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
588"
BROADER IMPACTS,0.8545953360768176,"groups), privacy considerations, and security considerations.
589"
BROADER IMPACTS,0.8559670781893004,"• The conference expects that many papers will be foundational research and not tied
590"
BROADER IMPACTS,0.8573388203017832,"to particular applications, let alone deployments. However, if there is a direct path to
591"
BROADER IMPACTS,0.8587105624142661,"any negative applications, the authors should point it out. For example, it is legitimate
592"
BROADER IMPACTS,0.8600823045267489,"to point out that an improvement in the quality of generative models could be used to
593"
BROADER IMPACTS,0.8614540466392319,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
594"
BROADER IMPACTS,0.8628257887517147,"that a generic algorithm for optimizing neural networks could enable people to train
595"
BROADER IMPACTS,0.8641975308641975,"models that generate Deepfakes faster.
596"
BROADER IMPACTS,0.8655692729766804,"• The authors should consider possible harms that could arise when the technology is
597"
BROADER IMPACTS,0.8669410150891632,"being used as intended and functioning correctly, harms that could arise when the
598"
BROADER IMPACTS,0.8683127572016461,"technology is being used as intended but gives incorrect results, and harms following
599"
BROADER IMPACTS,0.869684499314129,"from (intentional or unintentional) misuse of the technology.
600"
BROADER IMPACTS,0.8710562414266118,"• If there are negative societal impacts, the authors could also discuss possible mitigation
601"
BROADER IMPACTS,0.8724279835390947,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
602"
BROADER IMPACTS,0.8737997256515775,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
603"
BROADER IMPACTS,0.8751714677640604,"feedback over time, improving the efficiency and accessibility of ML).
604"
SAFEGUARDS,0.8765432098765432,"11. Safeguards
605"
SAFEGUARDS,0.877914951989026,"Question: Does the paper describe safeguards that have been put in place for responsible
606"
SAFEGUARDS,0.879286694101509,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
607"
SAFEGUARDS,0.8806584362139918,"image generators, or scraped datasets)?
608"
SAFEGUARDS,0.8820301783264746,"Answer: [NA]
609"
SAFEGUARDS,0.8834019204389575,"Justification: The paper does not release any data or models that pose a high risk for misuse.
610"
SAFEGUARDS,0.8847736625514403,"Guidelines:
611"
SAFEGUARDS,0.8861454046639232,"• The answer NA means that the paper poses no such risks.
612"
SAFEGUARDS,0.887517146776406,"• Released models that have a high risk for misuse or dual-use should be released with
613"
SAFEGUARDS,0.8888888888888888,"necessary safeguards to allow for controlled use of the model, for example by requiring
614"
SAFEGUARDS,0.8902606310013718,"that users adhere to usage guidelines or restrictions to access the model or implementing
615"
SAFEGUARDS,0.8916323731138546,"safety filters.
616"
SAFEGUARDS,0.8930041152263375,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
617"
SAFEGUARDS,0.8943758573388203,"should describe how they avoided releasing unsafe images.
618"
SAFEGUARDS,0.8957475994513031,"• We recognize that providing effective safeguards is challenging, and many papers do
619"
SAFEGUARDS,0.897119341563786,"not require this, but we encourage authors to take this into account and make a best
620"
SAFEGUARDS,0.8984910836762688,"faith effort.
621"
LICENSES FOR EXISTING ASSETS,0.8998628257887518,"12. Licenses for existing assets
622"
LICENSES FOR EXISTING ASSETS,0.9012345679012346,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
623"
LICENSES FOR EXISTING ASSETS,0.9026063100137174,"the paper, properly credited and are the license and terms of use explicitly mentioned and
624"
LICENSES FOR EXISTING ASSETS,0.9039780521262003,"properly respected?
625"
LICENSES FOR EXISTING ASSETS,0.9053497942386831,"Answer: [Yes]
626"
LICENSES FOR EXISTING ASSETS,0.906721536351166,"Justification: All existing models are properly referenced and credit to their creators is given.
627"
LICENSES FOR EXISTING ASSETS,0.9080932784636488,"These are either LLMs or metrics such as SUSWIR and METEOR (Section 5 and Appendix
628"
LICENSES FOR EXISTING ASSETS,0.9094650205761317,"A).
629"
LICENSES FOR EXISTING ASSETS,0.9108367626886146,"Guidelines:
630"
LICENSES FOR EXISTING ASSETS,0.9122085048010974,"• The answer NA means that the paper does not use existing assets.
631"
LICENSES FOR EXISTING ASSETS,0.9135802469135802,"• The authors should cite the original paper that produced the code package or dataset.
632"
LICENSES FOR EXISTING ASSETS,0.9149519890260631,"• The authors should state which version of the asset is used and, if possible, include a
633"
LICENSES FOR EXISTING ASSETS,0.9163237311385459,"URL.
634"
LICENSES FOR EXISTING ASSETS,0.9176954732510288,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
635"
LICENSES FOR EXISTING ASSETS,0.9190672153635117,"• For scraped data from a particular source (e.g., website), the copyright and terms of
636"
LICENSES FOR EXISTING ASSETS,0.9204389574759945,"service of that source should be provided.
637"
LICENSES FOR EXISTING ASSETS,0.9218106995884774,"• If assets are released, the license, copyright information, and terms of use in the
638"
LICENSES FOR EXISTING ASSETS,0.9231824417009602,"package should be provided. For popular datasets, paperswithcode.com/datasets
639"
LICENSES FOR EXISTING ASSETS,0.9245541838134431,"has curated licenses for some datasets. Their licensing guide can help determine the
640"
LICENSES FOR EXISTING ASSETS,0.9259259259259259,"license of a dataset.
641"
LICENSES FOR EXISTING ASSETS,0.9272976680384087,"• For existing datasets that are re-packaged, both the original license and the license of
642"
LICENSES FOR EXISTING ASSETS,0.9286694101508917,"the derived asset (if it has changed) should be provided.
643"
LICENSES FOR EXISTING ASSETS,0.9300411522633745,"• If this information is not available online, the authors are encouraged to reach out to
644"
LICENSES FOR EXISTING ASSETS,0.9314128943758574,"the asset’s creators.
645"
NEW ASSETS,0.9327846364883402,"13. New Assets
646"
NEW ASSETS,0.934156378600823,"Question: Are new assets introduced in the paper well documented and is the documentation
647"
NEW ASSETS,0.9355281207133059,"provided alongside the assets?
648"
NEW ASSETS,0.9368998628257887,"Answer: [NA]
649"
NEW ASSETS,0.9382716049382716,"Justification: The paper does not introduce new assets that require documentation.
650"
NEW ASSETS,0.9396433470507545,"Guidelines:
651"
NEW ASSETS,0.9410150891632373,"• The answer NA means that the paper does not release new assets.
652"
NEW ASSETS,0.9423868312757202,"• Researchers should communicate the details of the dataset/code/model as part of their
653"
NEW ASSETS,0.943758573388203,"submissions via structured templates. This includes details about training, license,
654"
NEW ASSETS,0.9451303155006858,"limitations, etc.
655"
NEW ASSETS,0.9465020576131687,"• The paper should discuss whether and how consent was obtained from people whose
656"
NEW ASSETS,0.9478737997256516,"asset is used.
657"
NEW ASSETS,0.9492455418381345,"• At submission time, remember to anonymize your assets (if applicable). You can either
658"
NEW ASSETS,0.9506172839506173,"create an anonymized URL or include an anonymized zip file.
659"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9519890260631001,"14. Crowdsourcing and Research with Human Subjects
660"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.953360768175583,"Question: For crowdsourcing experiments and research with human subjects, does the paper
661"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9547325102880658,"include the full text of instructions given to participants and screenshots, if applicable, as
662"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9561042524005487,"well as details about compensation (if any)?
663"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9574759945130316,"Answer: [NA]
664"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9588477366255144,"Justification: The paper does not involve crowdsourcing or research with human subjects.
665"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9602194787379973,"Guidelines:
666"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9615912208504801,"• The answer NA means that the paper does not involve crowdsourcing nor research with
667"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9629629629629629,"human subjects.
668"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9643347050754458,"• Including this information in the supplemental material is fine, but if the main contribu-
669"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9657064471879286,"tion of the paper involves human subjects, then as much detail as possible should be
670"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9670781893004116,"included in the main paper.
671"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9684499314128944,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
672"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9698216735253772,"or other labor should be paid at least the minimum wage in the country of the data
673"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9711934156378601,"collector.
674"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9725651577503429,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
675"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9739368998628258,"Subjects
676"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9753086419753086,"Question: Does the paper describe potential risks incurred by study participants, whether
677"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9766803840877915,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
678"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9780521262002744,"approvals (or an equivalent approval/review based on the requirements of your country or
679"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9794238683127572,"institution) were obtained?
680"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9807956104252401,"Answer: [NA]
681"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9821673525377229,"Justification: The paper does not involve research with human subjects that would require
682"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9835390946502057,"IRB approval.
683"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9849108367626886,"Guidelines:
684"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9862825788751715,"• The answer NA means that the paper does not involve crowdsourcing nor research with
685"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9876543209876543,"human subjects.
686"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9890260631001372,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
687"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.99039780521262,"may be required for any human subjects research. If you obtained IRB approval, you
688"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9917695473251029,"should clearly state this in the paper.
689"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9931412894375857,"• We recognize that the procedures for this may vary significantly between institutions
690"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9945130315500685,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
691"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9958847736625515,"guidelines for their institution.
692"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9972565157750343,"• For initial submissions, do not include any information that would break anonymity (if
693"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9986282578875172,"applicable), such as the institution conducting the review.
694"
