Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.002242152466367713,"“Zero-shot” neural architecture search (ZNAS) is key to achieving real-time neural
1"
ABSTRACT,0.004484304932735426,"architecture search. ZNAS comes from “one-shot” neural architecture search but
2"
ABSTRACT,0.006726457399103139,"searches in a weight-agnostic supernet and consequently largely reduce the search
3"
ABSTRACT,0.008968609865470852,"cost. However, the weight parameters are agnostic in the zero-shot NAS and none
4"
ABSTRACT,0.011210762331838564,"of the previous methods try to explain it. We question whether there exists a
5"
ABSTRACT,0.013452914798206279,"way to unify the one-shot and zero-shot experiences for interpreting the agnostic
6"
ABSTRACT,0.01569506726457399,"weight messages. To answer this question, we propose a causal definition for “zero-
7"
ABSTRACT,0.017937219730941704,"shot NAS” and facilitate it with interventional data from “one-shot” knowledge.
8"
ABSTRACT,0.020179372197309416,"The experiments on the standard NAS-bench-201 and CIFAR-10 benchmarks
9"
ABSTRACT,0.02242152466367713,"demonstrate a breakthrough of search cost which requires merely 8 GPU seconds
10"
ABSTRACT,0.02466367713004484,"on CIFAR-10 while maintaining competitive precision.
11"
INTRODUCTION,0.026905829596412557,"1
Introduction
12"
INTRODUCTION,0.02914798206278027,"Neural architecture search has been an interesting topic in the AutoML community [27]. Traditional
13"
INTRODUCTION,0.03139013452914798,"methods search by training the distinct neural architecture iteratively [31] whose training cost is
14"
INTRODUCTION,0.033632286995515695,"huge. One-shot model cleverly use a supernet to merge all the singular neural architectures into
15"
INTRODUCTION,0.03587443946188341,"one and consequently, the waste of search time is largely saved [16]. Further, the gradient-based
16"
INTRODUCTION,0.03811659192825112,"one-shot method [12] is proposed which acquires robust results on NASNet [32]. Though the one-shot
17"
INTRODUCTION,0.04035874439461883,"model largely reduces the search cost, it still suffers from a weight-sharing problem, and especially,
18"
INTRODUCTION,0.042600896860986545,"gradient-based approaches cause degenerate architectures [29]. The work [25] gives theoretical proof
19"
INTRODUCTION,0.04484304932735426,"for this and subtly uses a progressive tuning metric to discretize the one-shot supernet iteratively
20"
INTRODUCTION,0.04708520179372197,"which gets awesome neural architectures. However, it still gets degenerate architectures with different
21"
INTRODUCTION,0.04932735426008968,"training settings.
22"
INTRODUCTION,0.0515695067264574,"The brilliant work [5] from Google Brain gives a hint for searching neural networks without tuning the
23"
INTRODUCTION,0.053811659192825115,"parameters. “To produce architectures that themselves encode solutions, the importance of weights
24"
INTRODUCTION,0.05605381165919283,"must be minimized”. In this manner, a zero-shot neural architecture search (ZNAS) is born. The
25"
INTRODUCTION,0.05829596412556054,"work [10] firsts propose the idea of ZNAS to be “it does not optimize network parameters during
26"
INTRODUCTION,0.06053811659192825,"search ”. From a one-shot perspective, the “zero-shot” is given credit by “one-shot” where single
27"
INTRODUCTION,0.06278026905829596,"neural architectures are supposed to be selected from the weight-agnostic supernet [5]. Considering
28"
INTRODUCTION,0.06502242152466367,"causal weight messages, the “zero-shot” select neural architecture with the minimum impact of
29"
INTRODUCTION,0.06726457399103139,"any weight parameter [5]. Thus a causal definition is supposed to be that the weight messages are
30"
INTRODUCTION,0.06950672645739911,"multi-environmentally distributed. Compared to one-shot NAS, zero-shot NAS gets imperfect weight
31"
INTRODUCTION,0.07174887892376682,"messages due to random initialization and searching without training [10, 2].
32"
INTRODUCTION,0.07399103139013453,"A training-free approach is first proposed by the work [13]. Different from the previous zero-shot
33"
INTRODUCTION,0.07623318385650224,"model [10], the work [13] samples well-trained architectures and get validation accuracy to train the
34"
INTRODUCTION,0.07847533632286996,"statistical proxy before it searches. The work [2] follows the way of the previous work [10] and uses
35"
INTRODUCTION,0.08071748878923767,"the DARTS search space to conduct zero-shot NAS on CIFAR-10 and ImagNet in a training-free
36"
INTRODUCTION,0.08295964125560538,"manner. However, the number of samples directly decides the belief of the final precision. The
37"
INTRODUCTION,0.08520179372197309,"“well-trained” architectures might not be “perfectly-trained” in different training settings.
38"
INTRODUCTION,0.08744394618834081,"Zero-shot NAS learns the representation of neural architectures to get the best one. Consistently
39"
INTRODUCTION,0.08968609865470852,"compared to one-shot NAS methods, zeros-shot NAS methods ignore the weight information. By
40"
INTRODUCTION,0.09192825112107623,"merely measuring the architectural expressivity, they overlooked the impact of weights as a necessary
41"
INTRODUCTION,0.09417040358744394,"assessment element. From a one-shot NAS perspective, architectural information can be represented
42"
INTRODUCTION,0.09641255605381166,"by a list of neuron representations [25]. The message of training weights ω supports the neuron’s
43"
INTRODUCTION,0.09865470852017937,"representation [15, 12, 25]. Because the structural dependencies of shared (mutual) messages across
44"
INTRODUCTION,0.10089686098654709,"neurons are all agnostic [5], in the zero-shot neural architecture search, the neuron’s representation is
45"
INTRODUCTION,0.1031390134529148,"harder to interpret due to the random messages. What is worse, the uniterpretability might result in
46"
INTRODUCTION,0.10538116591928251,"large bias and variances because the imprecise observational data might be misleading. Finally, it
47"
INTRODUCTION,0.10762331838565023,"will lead the search to get degenerate architectures through the process of accumulating errors.
48"
INTRODUCTION,0.10986547085201794,"We first propose to interpret the zero-shot NAS in a causal-representation-learning setting. According
49"
INTRODUCTION,0.11210762331838565,"to the weight-agnostic setting, we formulate the zero-shot NAS as a novel framework for imperfect-
50"
INTRODUCTION,0.11434977578475336,"information NAS. The structural information of zero-shot NAS is interpreted by impact with the
51"
INTRODUCTION,0.11659192825112108,"latent factors. As a consequence, intrinsic high-level interventional data acquired by one-shot NAS
52"
INTRODUCTION,0.11883408071748879,"is properly adopted to refine the imperfectness. Moreover, we reformulate the causality by game
53"
INTRODUCTION,0.1210762331838565,"theory and interpret the imperfect-information NAS as imperfect information game G. Extensive
54"
INTRODUCTION,0.12331838565022421,"experiments on various benchmark datasets including CIFAR-10, NAS-Bench-201, and ImageNet
55"
INTRODUCTION,0.12556053811659193,"have shown the super search efficiency (10000× faster than DARTS) of our methods. In this work,
56"
INTRODUCTION,0.12780269058295965,"our main contributions are as follows:
57"
INTRODUCTION,0.13004484304932734,"• We propose that the causal zero-shot NAS is to learn the neuron’s representation with latent
58"
INTRODUCTION,0.13228699551569506,"factors in observationally imperfect messages.
59"
INTRODUCTION,0.13452914798206278,"• We theoretically demonstrate the validation information of either a neuron or a neuron
60"
INTRODUCTION,0.1367713004484305,"ensemble obeys a Gaussian distribution given a Gaussian input.
61"
INTRODUCTION,0.13901345291479822,"• The proposed method uses high-level interventional data from one-shot NAS to facilitating
62"
INTRODUCTION,0.1412556053811659,"zero-shot NAS to solve the imperfectness.
63"
INTRODUCTION,0.14349775784753363,"• Our method sets the new state-of-the-art in zero-shot NAS of search cost (8 GPU seconds)
64"
INTRODUCTION,0.14573991031390135,"while maintaining comparable test accuracies.
65"
PRELIMINARIES AND RELATED WORK,0.14798206278026907,"2
Preliminaries and Related Work
66"
PRELIMINARIES AND RELATED WORK,0.15022421524663676,"In this section, we talk about the preliminaries and the previous works on one-shot NAS and zero-shot
67"
PRELIMINARIES AND RELATED WORK,0.15246636771300448,"NAS. We talk about the motivation to replace statistical proxy by introducing the basic knowledge on
68"
PRELIMINARIES AND RELATED WORK,0.1547085201793722,"causal interventaional representation learning in causality [20, 1].
69"
ONE-SHOT NAS,0.15695067264573992,"2.1
One-shot NAS
70"
ONE-SHOT NAS,0.1591928251121076,"One-shot NAS methods [12, 16], that unify all the single-path neural architectures into one super-
71"
ONE-SHOT NAS,0.16143497757847533,"network S (supernet), select the single-path neural architecture as the best one by training the weights
72"
ONE-SHOT NAS,0.16367713004484305,"ω in a weight-sharing manner and maximizing the validation accuracy (V) of architecture A as
73"
ONE-SHOT NAS,0.16591928251121077,"follows:
74
MaxA(V(A, ¯ω))
s.t.
¯ω = ω + δAωS
(1)"
ONE-SHOT NAS,0.1681614349775785,"The iterative updating of ω and selection of A makes the one-shot NAS a bi-level optimization
75"
ONE-SHOT NAS,0.17040358744394618,"problem that is NP-hard. Differentiable one-shot model also relies on the observational data from
76"
ONE-SHOT NAS,0.1726457399103139,"unitedly trained validation accuracies of differentiable subnets [12]. Wang et al. [25] propose a
77"
ONE-SHOT NAS,0.17488789237668162,"selection-based approach to modify the output of differentiable one-shot NAS [12] to discretize a
78"
ONE-SHOT NAS,0.17713004484304934,"single-path neural architecture that consists of operations (neurons) with strength. As a consequence,
79"
ONE-SHOT NAS,0.17937219730941703,"the perturbation-based inductive bias is demonstrated to be helpful to solve the degeneration.
80"
STATISTICAL PROXIES IN ZERO-SHOT NAS,0.18161434977578475,"2.2
Statistical proxies in zero-shot NAS
81"
STATISTICAL PROXIES IN ZERO-SHOT NAS,0.18385650224215247,"We compare the various training-free and zero-shot NAS methods according to the usage of statistical
82"
STATISTICAL PROXIES IN ZERO-SHOT NAS,0.1860986547085202,"representation. Some training-free approaches use the statistic of validation accuracy to predict the
83"
STATISTICAL PROXIES IN ZERO-SHOT NAS,0.18834080717488788,"final architecture. NASWOT [13] samples a number (N) of well-trained neural architectures from
84"
STATISTICAL PROXIES IN ZERO-SHOT NAS,0.1905829596412556,"the NAS-Bench-201 dataset to learn the kernel. However, to get these representations, the training
85"
STATISTICAL PROXIES IN ZERO-SHOT NAS,0.19282511210762332,"costs tremendously. The zero-shot methods directly use zero-cost statistical proxies to represent the
86"
STATISTICAL PROXIES IN ZERO-SHOT NAS,0.19506726457399104,"expressivity without weights and validation accuracy. Zen-NAS [10] uses a Gaussian complexity to
87"
STATISTICAL PROXIES IN ZERO-SHOT NAS,0.19730941704035873,"measure the network expressivity and evolve the architectures to maximize the expressivity. Other
88"
STATISTICAL PROXIES IN ZERO-SHOT NAS,0.19955156950672645,"training-free approaches such as TE-NAS [2] and NASI [22] imitate the train of NAS by neural
89"
STATISTICAL PROXIES IN ZERO-SHOT NAS,0.20179372197309417,"tangent kernel (NTK) which largely reduces the waste of train cost. TE-NAS [2] propose to maximize
90"
STATISTICAL PROXIES IN ZERO-SHOT NAS,0.2040358744394619,"the number of linear region of activation patterns [14]. On the opposite, NASI [22] subtly optimize
91"
STATISTICAL PROXIES IN ZERO-SHOT NAS,0.2062780269058296,"the trace of NTK by sampling.
92"
STATISTICAL PROXIES IN ZERO-SHOT NAS,0.2085201793721973,"Here raise the question that to what extent the validation accuracy outperforms the statistical proxy.
93"
STATISTICAL PROXIES IN ZERO-SHOT NAS,0.21076233183856502,"Vice versa, we question if the statistical proxy is in substitute of the validation accuracy. Compared to
94"
STATISTICAL PROXIES IN ZERO-SHOT NAS,0.21300448430493274,"the proxy-based methods with approximations, the validation-based method is more reproducible. The
95"
STATISTICAL PROXIES IN ZERO-SHOT NAS,0.21524663677130046,"validation accuracy is an intrinsic robust and upper-bounded proxy to measure the neural architectures.
96"
STATISTICAL PROXIES IN ZERO-SHOT NAS,0.21748878923766815,"Besides, previous arts of one-shot manner usually use the validation accuracy to be the objective to
97"
STATISTICAL PROXIES IN ZERO-SHOT NAS,0.21973094170403587,"maximize. Despite these benefits, the zero-shot representation is imperfect due to the weight-agnostic
98"
STATISTICAL PROXIES IN ZERO-SHOT NAS,0.2219730941704036,"messages.
99"
CAUSAL REPRESENTATION LEARNING,0.2242152466367713,"2.3
Causal representation learning
100"
CAUSAL REPRESENTATION LEARNING,0.226457399103139,"The study [20] demonstrates that causality is a “subtle concept” which can not be fully described
101"
CAUSAL REPRESENTATION LEARNING,0.22869955156950672,"by Boolean or Probabilistic. It is more about reasoning. Reichenbach demonstrates a common
102"
CAUSAL REPRESENTATION LEARNING,0.23094170403587444,"cause principle to explain the causality by dependencies among variables [18]. Causal representation
103"
CAUSAL REPRESENTATION LEARNING,0.23318385650224216,"learning mainly deals with learning causally for representations. By observational data, we can hardly
104"
CAUSAL REPRESENTATION LEARNING,0.23542600896860988,"learn the real circumstances (environments), especially in complex scenes and high-dimensional data
105"
CAUSAL REPRESENTATION LEARNING,0.23766816143497757,"scenarios. Causal representation learning seeks to extract high-level information (dependencies) from
106"
CAUSAL REPRESENTATION LEARNING,0.2399103139013453,"low-level data. Interventions have taken a prominent role in representation learning literature on
107"
CAUSAL REPRESENTATION LEARNING,0.242152466367713,"causation. The work [1] uses interventional data to facilitate the causal representations to get precise
108"
CAUSAL REPRESENTATION LEARNING,0.24439461883408073,"outcomes. Neural architecture search aims at learning the architectural representations automatically.
109"
CAUSAL REPRESENTATION LEARNING,0.24663677130044842,"The automatism of the previous arts of neural architecture search might not be causal especially in
110"
CAUSAL REPRESENTATION LEARNING,0.24887892376681614,"zero-shot setting.
111"
METHOD,0.25112107623318386,"3
Method
112"
IMPERFECT INFORMATION,0.2533632286995516,"3.1
Imperfect information
113"
IMPERFECT INFORMATION,0.2556053811659193,"Neural architecture search is a task aiming at interpreting the mechanism of architectural knowledge
114"
IMPERFECT INFORMATION,0.257847533632287,"of neural networks given methods of evaluations. Activation patterns, statistical proxies, and naive
115"
IMPERFECT INFORMATION,0.2600896860986547,"validation accuracy are adopted to evaluate the score of a neural network. However, we can hardly
116"
IMPERFECT INFORMATION,0.2623318385650224,"understand any neural network and even hardly explain the weight distribution of any neural network
117"
IMPERFECT INFORMATION,0.2645739910313901,"without assumptions. Observational data are always imperfect due to the infinite environments (search
118"
IMPERFECT INFORMATION,0.26681614349775784,"spaces/training schemes/hardware/etc.) of all possible networks with finite observations and limited
119"
IMPERFECT INFORMATION,0.26905829596412556,"tools. Architecture information is not stand-alone.
120"
IMPERFECT INFORMATION,0.2713004484304933,"In one-shot NAS, demonstrated in Equation 4, given a neural network, we first train the weights ω
121"
IMPERFECT INFORMATION,0.273542600896861,"and the ω combined with architecture A can give a validation accuracy V. After V is given, we then
122"
IMPERFECT INFORMATION,0.2757847533632287,"update the ω to get ¯ω and a novel architecture A until the validation accuracy V is maximum. In
123"
IMPERFECT INFORMATION,0.27802690582959644,"the train, the architecture of a neural network is the key factor that impacts the other two factors ω
124"
IMPERFECT INFORMATION,0.2802690582959641,"and validation accuracy V. The search is actually a reverse way of train to the aspect of the intrinsic
125"
IMPERFECT INFORMATION,0.2825112107623318,"dependency of accuracy V on the weight ω and architecture A. However, we have overlooked a lot of
126"
IMPERFECT INFORMATION,0.28475336322869954,"factors like data distributions, batch sizes, rates of weight decay, and so on and on which we can not
127"
IMPERFECT INFORMATION,0.28699551569506726,"optimize as “one shot”. If the observational data alone can not interpret the phenomenon, it is a must
128"
IMPERFECT INFORMATION,0.289237668161435,"to model the latent factors Z that cause this uninterpretability. Figure 1 illustrates the dependencies
129"
IMPERFECT INFORMATION,0.2914798206278027,"of architecture A, validation accuracy V, and weights ω. The dashed line reveals that Z changes the
130"
IMPERFECT INFORMATION,0.2937219730941704,"dependencies of selected neurons (or searched architectures) on observational data of ω and V [23],
131"
IMPERFECT INFORMATION,0.29596412556053814,"which indeed implies strong causality [20]. In logical condition, the structural relationship between
132"
IMPERFECT INFORMATION,0.2982062780269058,"V and ω can be almost broken1.
133"
IMPERFECT INFORMATION,0.3004484304932735,"1See demonstration in Section 3.3, results in Section 4."
IMPERFECT INFORMATION,0.30269058295964124,"Figure 1: Illustrations of the dependencies of architecture A, validation accuracy V, and weights
ω with latent factor Z on the train (left), one-shot neural architecture search (middle), and causal
zero-shot neural architecture search (right)."
IMPERFECT INFORMATION,0.30493273542600896,"We assume the validation accuracy V of a set of neural architectures {A} obeys a Gaussian distribution.
134"
IMPERFECT INFORMATION,0.3071748878923767,"135
V ∼N(µ, σ2)
(2)"
IMPERFECT INFORMATION,0.3094170403587444,"Due to the random weight information, artificial neural networks (ANN) themselves have architectural
136"
IMPERFECT INFORMATION,0.3116591928251121,"information to deliver the neural networks’ expressivity with large variances [5]. It is demonstrated
137"
IMPERFECT INFORMATION,0.31390134529147984,"that the weight-agnostic neural network still preserves the 92% accuracy-level information for digit
138"
IMPERFECT INFORMATION,0.31614349775784756,"classification by the work [5]. However, the weights are agnostic and consequently the validation
139"
IMPERFECT INFORMATION,0.3183856502242152,"accuracies are imperfect. We assume the true validation accuracy is the difference of the observational
140"
IMPERFECT INFORMATION,0.32062780269058294,"Vobser and latent impact of factor Z demonstrated in Equation 3.
141"
IMPERFECT INFORMATION,0.32286995515695066,"V ∼N(µobser −µZ, σ2
obser −σ2
Z)
(3)"
PROBLEM FORMULATION,0.3251121076233184,"3.2
Problem formulation
142"
PROBLEM FORMULATION,0.3273542600896861,"In Zen-NAS, the adoption of statistical proxy on the feature map is impressive while it is constrained
143"
PROBLEM FORMULATION,0.3295964125560538,"to structural dependencies [10]. We question to what extent, when we search a neural network, the
144"
PROBLEM FORMULATION,0.33183856502242154,"statistical proxies can be replaced with the more robust functions such as validation accuracy causally
145"
PROBLEM FORMULATION,0.33408071748878926,"[20]. In some one-shot [16, 12] and training-free methods [13], the evaluation metrics are usually the
146"
PROBLEM FORMULATION,0.336322869955157,"validation accuracy of the associated neural architectures.
147"
PROBLEM FORMULATION,0.33856502242152464,"Inspired by the previous work [25], we evaluate each neuron to select respectively in substitute.
148"
PROBLEM FORMULATION,0.34080717488789236,"Intuitively, we measure the importance of each neuron by a simple validation accuracy of a singular
149"
PROBLEM FORMULATION,0.3430493273542601,"associate neuron while resting other neurons on the same edge. DARTS+PT [25] the perturbation-
150"
PROBLEM FORMULATION,0.3452914798206278,"based approach mutes the irrelevant neurons to conduct an inference while saving the other paralleled
151"
PROBLEM FORMULATION,0.3475336322869955,"edges. For each paralleled edge (layer) E that contains M neurons N s, we mute the other neurons
152"
PROBLEM FORMULATION,0.34977578475336324,"while only saving the ith neuron N(i). The kth paralleled edge E (k)
i
consequently only contains one
153"
PROBLEM FORMULATION,0.35201793721973096,"neuron (operation): E (k)
i
= {0 × N(1), 0 × N(2), . . . , N(i), . . . , 0 × N(M)}. When saving the other
154"
PROBLEM FORMULATION,0.3542600896860987,"paralleled edges {E(j)}j̸=k, N(i) denotes any single sub-architecture (a neuron) in the supernet S
155"
PROBLEM FORMULATION,0.35650224215246634,"with tuned weights ωS of the supernet. Formally, the one-shot neuron selection for kth paralleled
156"
PROBLEM FORMULATION,0.35874439461883406,"edge is defined as:
157"
PROBLEM FORMULATION,0.3609865470852018,"N ∗= argmax(F({V(N(i), ωS)}))
∀N(i) ∈E (k)
(4)"
PROBLEM FORMULATION,0.3632286995515695,"where validation accuracy V is measured by an intrinsic inductive bias function F such as a rein-
158"
PROBLEM FORMULATION,0.3654708520179372,"forcement learning policy π [31, 32]. V(N(i)) = V({E (1), E (2), . . . , E (k)
i
, . . . , E (N)}) in practise.
159"
PROBLEM FORMULATION,0.36771300448430494,"In zero-shot NAS, the weight information is agnostic, which is impacted by a latent factor Z as
160"
PROBLEM FORMULATION,0.36995515695067266,"shown in Figure 1. [4]. The latent variable obeys a distribution P in dimension Λ:
161"
PROBLEM FORMULATION,0.3721973094170404,"Z ∼PΛ
(5)"
PROBLEM FORMULATION,0.3744394618834081,"When we sample larger enough numbers of impacts, the sample of factor Z obeys a Gaussian
162"
PROBLEM FORMULATION,0.37668161434977576,"distribution by the central limit theorem (CLT). The causal zero-shot neural architecture search
163"
PROBLEM FORMULATION,0.3789237668161435,"(Causal-Znas) that searches in imperfect messages is defined as:
164"
PROBLEM FORMULATION,0.3811659192825112,"N ∗= argmax(F({V(N(i), ω)}|Z))
∀N(i) ∈E (k)
(6)"
PROBLEM FORMULATION,0.3834080717488789,"for i = 1, 2, . . . , M. In this Equation 6, Z means the latent information to impact agnostic-weights
165"
PROBLEM FORMULATION,0.38565022421524664,"(such as a random initialization [5, 10]) and consequently validation accuracies V. Therefore, we get a
166"
PROBLEM FORMULATION,0.38789237668161436,"causal information set of singular neuron representation {V(N(i))|Z} for i = 1, 2, . . . , M. For each
167"
PROBLEM FORMULATION,0.3901345291479821,"paralleled edge (layer) E that contains M neurons N s: E = {N(1), N(2), . . . , N(M)}. We calculate
168"
PROBLEM FORMULATION,0.3923766816143498,"the information of singular neuron Ni on edge E (j) by freezing the other layers (ensembles/edges)
169"
PROBLEM FORMULATION,0.39461883408071746,"{E (k)}k̸=j so that the causal information is only impacted by the current neurons due to the same
170"
PROBLEM FORMULATION,0.3968609865470852,"condition (in the same paralleled edge). Then the causal information set of a paralleled edge E is as:
171"
PROBLEM FORMULATION,0.3991031390134529,"{V(E )|Z} = {N(1)(X|Z), N(2)(X|Z), . . . , N(M)(X|Z)}
(7)"
PROBLEM FORMULATION,0.4013452914798206,"In a Causal-Znas, a prediction function F is able to measure the selected architectures from the
172"
PROBLEM FORMULATION,0.40358744394618834,"un-trained supernet. To avoid the improper introduction of inductive biases, we use an identity
173"
PROBLEM FORMULATION,0.40582959641255606,"function to measure the importance of neurons.
174"
GAUSSIAN INTERVENTION,0.4080717488789238,"3.3
Gaussian intervention
175"
GAUSSIAN INTERVENTION,0.4103139013452915,"Most existing NAS approaches use observational data and make assumptions on the architectural de-
176"
GAUSSIAN INTERVENTION,0.4125560538116592,"pendencies to achieve provable representation identification. However, in our causal zero-shot neural
177"
GAUSSIAN INTERVENTION,0.4147982062780269,"architecture search, there is a wealth of interventional data available. To perfect the observational
178"
GAUSSIAN INTERVENTION,0.4170403587443946,"validation accuracies Vobser in D, we sample Vven from an interventional distribution D(Z) to be in
179"
GAUSSIAN INTERVENTION,0.4192825112107623,"substitute for the ones derived by the observation Vobser. Formally, we have:Vven ∼D(Z). Though
180"
GAUSSIAN INTERVENTION,0.42152466367713004,"pure architectural information is imperfectly obseved, we can use an interventional function I (do
181"
GAUSSIAN INTERVENTION,0.42376681614349776,"intervn [1]) to replenish data from a one-shot perspective:
182"
GAUSSIAN INTERVENTION,0.4260089686098655,"V = ID(Z)
p
Vven [
ID
1−pVobser
(8)"
GAUSSIAN INTERVENTION,0.4282511210762332,"Ming et al. [10] assume the inputs obey Gaussian distribution and get comparable results with
183"
GAUSSIAN INTERVENTION,0.4304932735426009,"one-shot methods [12, 16]. What we use as the input for each neuron is a Gaussian image which also
184"
GAUSSIAN INTERVENTION,0.4327354260089686,"obeys the assumption of Gaussian inputs of Zen-NAS [10].
185"
GAUSSIAN INTERVENTION,0.4349775784753363,"Lemma 1. Given a Gaussian input X ∼N(µ, σ2), the output of a neuron N in the first layer is
186"
GAUSSIAN INTERVENTION,0.437219730941704,"Gaussian.
187"
GAUSSIAN INTERVENTION,0.43946188340807174,"Proof. Assuming each neuron is a distinct convolution denoted as Convi for i = 1, 2, . . . , M, then
188"
GAUSSIAN INTERVENTION,0.44170403587443946,"the output of this edge is:
189 O = M
X"
GAUSSIAN INTERVENTION,0.4439461883408072,"i=1
({Conv(1)(X, W(1)), Conv(2)(X, W(2)), . . . , Conv(M)(X, W(M))})
(9)"
GAUSSIAN INTERVENTION,0.4461883408071749,"where X ∼N(µ, σ2) and W(i) ∼N(µw, σ2
w) for i = 1, 2, . . . , M. Given the i.i.d. inputs
190"
GAUSSIAN INTERVENTION,0.4484304932735426,"and weights, the output score (validation accuracy) of the neural network layer is Gaussian since
191"
GAUSSIAN INTERVENTION,0.45067264573991034,"the Convolution of a Gaussian (random variable) is still a Gaussian (random variable). We have
192"
GAUSSIAN INTERVENTION,0.452914798206278,"Gaussian weights W(i) and Conv(i)(X, W(i)) ∼N(µ(i), σ2
(i)). Then P"
GAUSSIAN INTERVENTION,0.4551569506726457,"i Conv(i)(X, W(i)) ∼
193"
GAUSSIAN INTERVENTION,0.45739910313901344,"N(P µ(i), P σ2
(i)).
194"
GAUSSIAN INTERVENTION,0.45964125560538116,"Lemma 2. Given a Gaussian input X ∼N(µ, σ2), the output of a neuron N in any layer is
195"
GAUSSIAN INTERVENTION,0.4618834080717489,"Gaussian.
196"
GAUSSIAN INTERVENTION,0.4641255605381166,"Proof. Apparently, any weighted summation of random variables that obey two distinct Gaussian is
197"
GAUSSIAN INTERVENTION,0.4663677130044843,"still a Gaussian. In neural networks, the layers are stacked. Based on Lemma 1, in the latter layer,
198"
GAUSSIAN INTERVENTION,0.46860986547085204,"the outputs also obey the Gaussian, whose inputs are the former layer’s outputs. The convolution
199"
GAUSSIAN INTERVENTION,0.47085201793721976,"(neuron) Conv′
(i) of the next layer with output of latter layer O (in Equation 9) has Conv′
(i)(O) ∼
200"
GAUSSIAN INTERVENTION,0.4730941704035874,"N(µ′
(i), σ′
(i)
2).
201"
GAUSSIAN INTERVENTION,0.47533632286995514,"Corollary 2.1. Given a Gaussian input X ∼N(µ, σ2), the output of any neuron ensemble
202"
GAUSSIAN INTERVENTION,0.47757847533632286,"{N(i)}i∈M is Gaussian.
203"
GAUSSIAN INTERVENTION,0.4798206278026906,"Formally, we have O(i) ∼N (i)(µ′, σ′2). e
O = {O(1), O(2), . . . , O(K)} where e
O denotes all the
204"
GAUSSIAN INTERVENTION,0.4820627802690583,"outputs across edges
z
}|
{
E(1), E(2), . . . , E(K). Based on Lemma 1 and Lemma 2, we get the Corollary 2.1
205"
GAUSSIAN INTERVENTION,0.484304932735426,"to select edges (topology preferences).
206"
GAUSSIAN INTERVENTION,0.48654708520179374,"Proof. By Lemma 1, we have any neuron N(i) has a Gaussian output O(i) ∼N(µ(i), σ2
(i)). Any
207"
GAUSSIAN INTERVENTION,0.48878923766816146,ensemble of neurons has an output P
GAUSSIAN INTERVENTION,0.4910313901345291,i O(i). Then we have P
GAUSSIAN INTERVENTION,0.49327354260089684,"i O(i) ∼N(P µ(i), P σ2
(i)).
208"
GAUSSIAN INTERVENTION,0.49551569506726456,"As demonstrated in Equation 8, we propose an intervention function ID to facilitate the imper-
209"
GAUSSIAN INTERVENTION,0.4977578475336323,"fect causal representation of the validation information. We propose that the ideal information is
210"
GAUSSIAN INTERVENTION,0.5,"distributed in the information set by a probability p. The distribution D is N(µ, σ) in the context.
211"
GAUSSIAN INTERVENTION,0.5022421524663677,"Figure 2: Illustration of intervention of observational data. The blue denotes interventional data while
the white denotes observational data."
GAUSSIAN INTERVENTION,0.5044843049327354,"Herein, we question to what extent, the imperfectness can be interventionally refined [1]. We use
212"
GAUSSIAN INTERVENTION,0.5067264573991032,"the parameter p to asymmetrically flipping the random Gaussian IN(µ,σ2)
p
[15] to understand the
213"
GAUSSIAN INTERVENTION,0.5089686098654709,"imperfect information in dimension Λ which is mapped to a vanilla Gaussian (in Equation 5). As
214"
GAUSSIAN INTERVENTION,0.5112107623318386,"shown in Figure 2, it compares the information difference between the observational information set
215"
GAUSSIAN INTERVENTION,0.5134529147982063,"and interventional information set impacted by the parameter p. In different environments, the data
216"
GAUSSIAN INTERVENTION,0.515695067264574,"of interventional data combined with observation obeys a distinct Gaussian, which implies strong
217"
GAUSSIAN INTERVENTION,0.5179372197309418,"coherence and robustness. When p = 1, the causality is perfectly achieved due to breaking the
218"
GAUSSIAN INTERVENTION,0.5201793721973094,"dependency of validation accuracy V on weights ω; otherwise, it is imperfect. The mean and variance
219"
GAUSSIAN INTERVENTION,0.5224215246636771,"coefficients of the additional notion of intervention are derived by sampling validation accuracy of
220"
GAUSSIAN INTERVENTION,0.5246636771300448,"one-shot prior. We propose that setting of p is conditional on the fraction of the mean of latent factor
221"
GAUSSIAN INTERVENTION,0.5269058295964125,"to the difference of the mean of observational data and the mean of interventional data.
222"
GAUSSIAN INTERVENTION,0.5291479820627802,"Proposition 1. When p −→
µZ
µobser−µven , the mean of the intervened data eµ −→µtrue.
223"
GAUSSIAN INTERVENTION,0.531390134529148,"As demonstrated in Proposition 1, a sufficient condition of the mean of intervened data is getting
224"
GAUSSIAN INTERVENTION,0.5336322869955157,"closer to the true mean of the validation accuracy is that the p is closer to 1 and interventional data is
225"
GAUSSIAN INTERVENTION,0.5358744394618834,"closer to the true data.
226"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5381165919282511,"3.4
Causal zero-shot neural architecture search
227"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5403587443946188,"We formulate the zero-shot NAS into ensemble selection and neuron selection. There are K neuron
228"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5426008968609866,"ensembles
z
}|
{
{N(i)}(1)
i∈M, {N(i)}(2)
i∈M, . . . , {N(i)}(K)
i∈M. For each ensemble, there are M neurons
229"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5448430493273543,"(operations). The ensemble selection is the selection of an ensemble {N(i)}(j)
i∈M of neurons among
230"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.547085201793722,"the K ensembles (j ∈K), while neuron selection follows the same formula and selects a neuron N(i)
231"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5493273542600897,"from a neuron ensemble {N(i)}(j)
i∈M.
232"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5515695067264574,Figure 3: The distribution plate of three neurons and a big distribution plate of ensemble of them.
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5538116591928252,"Algorithm 1 Causal zero-shot neuron selection.
Initialize supernet weights ω;
For i = 1, 2, . . . , M:
Calculate validate accuracy Vobser(N(i)(ω))};
do intervn by p;
Maximize the V and select the N ∗."
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5560538116591929,"As is shown in Figure 3, the validation accuracy of both a neuron and a neuron ensemble obey
233"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5582959641255605,"Gaussian distributions respectively. From a macro perspective it is an ensemble selection while from
234"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5605381165919282,"a minor perspective, it is a neuron selection. Thus we talk about both types in the same formula.
235"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5627802690582959,"As demonstrated in Equation 6, the final outcome neurons are derived by maximizing their validation
236"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5650224215246636,"accuracies according to the latent factor. Given the Gaussian intervention in Equation 8, we further
237"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5672645739910314,"modify the formula of the causal neuron selection by doing intervention (without the additional
238"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5695067264573991,"inductive bias [20]):
239"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5717488789237668,"f
N ∗= argmax({eV(N(i))}i∈M)
(10)"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5739910313901345,", where eV is the validation accuracy with intervention.
240"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5762331838565022,"The methodology of neuron selection is given in Algorithm 1. The search process of neuron ensemble
241"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.57847533632287,"follows the same formulation as mentioned in this Section. do intervn represents to do intervention.
242"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5807174887892377,"At first, the weight ω of the supernet is randomly initialized [10]. Second, validation scores V on the
243"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5829596412556054,"validation set are prepared for the calculation of the neurons N which adopts probability p to do the
244"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5852017937219731,"intervention. At last, the maximum of values is compared to select the best neuron (operation). In
245"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5874439461883408,"practice, when the probability p is close to 1, the validation accuracy of observation has less need to
246"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5896860986547086,"compute.
247"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5919282511210763,"Equation 6 reveals a universal formula for causal neural architecture search in the zero-shot settings.
248"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.594170403587444,"The measure function F measures the importance [25] (“responsibility”) of a neuron and Shapley
249"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5964125560538116,"value is proposed to be ideal for the selection of a neuron [7] or ensemble [19].
250"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.5986547085201793,"N ∗= argmax({G(i)({eV})}i∈M)
(11)
We use the game-theoretic inductive bias to extract the valuable information [20, 7]. G represent the
251"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.600896860986547,"Shapely value [21]. Given Corollary 2.1, we know that any the neuron ensemble obeys a Gaussian
252"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.6031390134529148,"distribution. The information set of Shapley value is thus build on top of an ensemble of Gaussian
253"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.6053811659192825,"variables. However, we could not guarantee a Gaussian distribution of the Shapley value [24]. As
254"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.6076233183856502,"a consequence, we use a Gaussian distribution to do intervention on validation accuracy and then
255"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.6098654708520179,"calculate the Shapely value of the intervened validation accuracy. At last, the Shapley value is
256"
CAUSAL ZERO-SHOT NEURAL ARCHITECTURE SEARCH,0.6121076233183856,"maximized whose associated neuron is supposed to be more expressive [7].
257"
WEIGHT-AGNOSTIC WEIGHTS,0.6143497757847534,"3.5
Weight-agnostic weights
258"
WEIGHT-AGNOSTIC WEIGHTS,0.6165919282511211,"In the assumptions of various methods, weights are initialized as Gaussian. However, in our frame-
259"
WEIGHT-AGNOSTIC WEIGHTS,0.6188340807174888,"work, we demonstrate that this strong assumption is not a must. Supernet can be initialized in different
260"
WEIGHT-AGNOSTIC WEIGHTS,0.6210762331838565,"ways: i) with Gaussian [10], ii) Uniform [5], and iii) Constant number [5].
261"
WEIGHT-AGNOSTIC WEIGHTS,0.6233183856502242,"Corollary 2.2. Given a Gaussian input X ∼N(µ, σ2), if the initial weights are Uniform or Constant
262"
WEIGHT-AGNOSTIC WEIGHTS,0.625560538116592,"number C, the output of any neuron ensemble {N(i)}i∈M is not Gaussian.
263"
WEIGHT-AGNOSTIC WEIGHTS,0.6278026905829597,"Proof. Apparently, the convolution of a Gaussian input with constant or uniform weights obeys a
264"
WEIGHT-AGNOSTIC WEIGHTS,0.6300448430493274,"difference of CDF Φ of the Gaussian in the range of constant or uniform.
265"
WEIGHT-AGNOSTIC WEIGHTS,0.6322869955156951,"In the previous work [5], it is proposed that weights are supposed to be initialized by a distribution
266"
WEIGHT-AGNOSTIC WEIGHTS,0.6345291479820628,"but not a constant (C). To be more precise, we propose that the constant value could not represent the
267"
WEIGHT-AGNOSTIC WEIGHTS,0.6367713004484304,"agnostic weights and thus could not reflect the latent information while a uniform distribution can
268"
WEIGHT-AGNOSTIC WEIGHTS,0.6390134529147982,"guarantee the randomness. By training on a “wide range” of uniform weight samples, Gaier et al.
269"
WEIGHT-AGNOSTIC WEIGHTS,0.6412556053811659,"propose that “the best performing values were outside of this training set” [5]. We propose that this
270"
WEIGHT-AGNOSTIC WEIGHTS,0.6434977578475336,"phenomenon is essentially resulted from a distribution shift of the Gaussian validation accuracy which
271"
WEIGHT-AGNOSTIC WEIGHTS,0.6457399103139013,"causes the change of search procedure. To solve the distribution shift, we could use the difference of
272"
WEIGHT-AGNOSTIC WEIGHTS,0.647982062780269,"CDF of Gaussian (Φ) to conduct intervention. Even in a broader view, if the weights distributions are
273"
WEIGHT-AGNOSTIC WEIGHTS,0.6502242152466368,"totally unknown, we can use Bayesian method to approximate a distribution D(Z) in Equation 8.
274"
EXPERIMENTS,0.6524663677130045,"4
Experiments
275"
EXPERIMENTS,0.6547085201793722,"We present the results and all experiment details of our method in this section. A robustness analysis
276"
EXPERIMENTS,0.6569506726457399,"is included to examine the stability of our method, which also explains the time efficiency. Results
277"
EXPERIMENTS,0.6591928251121076,"are given on the benchmark datasets, NAS-Bench-201 and CIFAR-10.
278"
EXPERIMENTAL DETAILS,0.6614349775784754,"4.1
Experimental details
279"
EXPERIMENTAL DETAILS,0.6636771300448431,"We use the search space of DARTS [12] for fair comparisons with the state-of-the-art NAS approaches.
280"
EXPERIMENTAL DETAILS,0.6659192825112108,"During the searching process, we follow adopting the same and hyper-parameters as DARTS [12]
281"
EXPERIMENTAL DETAILS,0.6681614349775785,"to initialize the supernet on the CIFAR-10 and NAS-Bench-201 datasets for a fair comparison with
282"
EXPERIMENTAL DETAILS,0.6704035874439462,"DARTS-variants (one-shot methods). All the training is conducted on a single 2080Ti GPU.
283"
EXPERIMENTAL DETAILS,0.672645739910314,"4.2
Results on CIFAR-10
284"
EXPERIMENTAL DETAILS,0.6748878923766816,Table 1: Comparison with state-of-the-art NAS methods on CIFAR-10.
EXPERIMENTAL DETAILS,0.6771300448430493,"Algorithm
Test Error
Params
Search Cost
Search Strategy
(%)
(M)
(GPU seconds)"
EXPERIMENTAL DETAILS,0.679372197309417,"DenseNet-BC [6]
3.46
25.6
-
manual"
EXPERIMENTAL DETAILS,0.6816143497757847,"NASNet-A + cutout [32]
2.65
3.3
1.73×108
RL
AmoebaNet-A [17]
3.34 ± 0.06
3.2
2.72×108
GA
AmoebaNet-B [17]
2.55 ± 0.05
2.8
2.72×108
GA
PNAS [11]
3.41 ± 0.09
3.2
1.94×107
SMBO"
EXPERIMENTAL DETAILS,0.6838565022421524,"ENAS [16]
2.89
4.6
43200
RL
DARTS(1st) [12]
3.00 ± 0.14
3.3
34560
gradient
DARTS(2nd) [12]
2.76 ± 0.09
3.3
86400
gradient
BayesNAS [30]
2.81 ± 0.04
3.4
17280
gradient
DrNAS [3]
2.54 ± 0.03
4.0
34560
gradient
ISTA-NAS [26]
2.54 ± 0.05
3.3
4320
gradient
DARTS+PT [25]
2.61 ± 0.10
3.0
69120
gradient"
EXPERIMENTAL DETAILS,0.6860986547085202,"TE-NAS [2]
2.63 ± 0.06
3.8
4320
NTK
NASI-FIX [22]
2.79 ± 0.01
3.9
864
NTK
NASI-ADA [22]
2.90 ± 0.01
3.7
864
NTK"
EXPERIMENTAL DETAILS,0.6883408071748879,"Causal-Znas(p = 0.5)
2.89 ± 0.08
2.6
142
causal
Causal-Znas(p = 1)
2.75 ± 0.10
3.2
8
causal
Causal-Znas-G(p = 1)
2.61 ± 0.04
3.1
30
causal"
EXPERIMENTAL DETAILS,0.6905829596412556,"As shown in Table 1, we compare the proposed Causal-Znas and game-version Causal-Znas-G with
285"
EXPERIMENTAL DETAILS,0.6928251121076233,"the state-of-the-art methods. The comparisons are made with respect to the informatics of the model,
286"
EXPERIMENTAL DETAILS,0.695067264573991,"including test accuracy on the test set (Test Error), the number of parameters (Params), the search
287"
EXPERIMENTAL DETAILS,0.6973094170403588,"costs, and the search strategies. As shown, our results set the new state-of-the-art search speed with a
288"
EXPERIMENTAL DETAILS,0.6995515695067265,"competitive test error rate. Compared to DARTS [12], our method is 10000× faster with comparable
289"
EXPERIMENTAL DETAILS,0.7017937219730942,"accuracy (2.75% v.s. 2.76%). Compared to DARTS+PT [25], our model is much simpler without
290"
EXPERIMENTAL DETAILS,0.7040358744394619,"introducing the perturbation-based inductive bias [20] and achieves a similar test error rate (2.61%
291"
EXPERIMENTAL DETAILS,0.7062780269058296,"v.s. 2.61%). DrNAS [3] and ISTA-NAS [26] are not only precise (2.54%) but also theoretically sound
292"
EXPERIMENTAL DETAILS,0.7085201793721974,"approaches. ISTA-NAS [26] is extremely fast in one-shot NAS while ours are more competitive
293"
EXPERIMENTAL DETAILS,0.7107623318385651,"(500× faster) in search efficiency.
294"
EXPERIMENTAL DETAILS,0.7130044843049327,"We compare our method with other zero-shot NAS approaches in Table 1. It demonstrates that the
295"
EXPERIMENTAL DETAILS,0.7152466367713004,"TE-NAS [2] which is the first algorithm that reaches 4 GPU hours search cost is experimentally
296"
EXPERIMENTAL DETAILS,0.7174887892376681,"awesome. TE-NAS uses the neural tangent kernel to approximate the train so it largely reduces
297"
EXPERIMENTAL DETAILS,0.7197309417040358,"the cost of training the neural networks. Compared to TE-NAS, our proposed approach is 500×
298"
EXPERIMENTAL DETAILS,0.7219730941704036,"faster and our game-based result (-G) gets a comparable test error rate (2.61% v.s. 2.63 %) with a
299"
EXPERIMENTAL DETAILS,0.7242152466367713,"smaller number of parameters (3.1M v.s. 3.8M). We also surpass the current state-of-the-art zero-shot
300"
EXPERIMENTAL DETAILS,0.726457399103139,"(training-free) method (NASI) [22] by more than 100× in search efficiency and get fewer errors in
301"
EXPERIMENTAL DETAILS,0.7286995515695067,"both settings (2.75% v.s.2.79%; 2.89% v.s. 2.90%).
302"
EXPERIMENTAL DETAILS,0.7309417040358744,"4.3
Results on NAS-Bench-201
303"
EXPERIMENTAL DETAILS,0.7331838565022422,"NAS-Bench-201 is a pure-architecture-aware dataset where the neural architectures are trained in the
304"
EXPERIMENTAL DETAILS,0.7354260089686099,"same settings, and the info such as performance, parameters, architecture topologies, and operations
305"
EXPERIMENTAL DETAILS,0.7376681614349776,"are available. Compared to NAS-Bench-101 [28], NAS-Bench-201 adopts a different search space
306"
EXPERIMENTAL DETAILS,0.7399103139013453,"and gets results on various datasets such as CIFAR-10, CIFAR-100, and ImageNet16-120.
307"
EXPERIMENTAL DETAILS,0.742152466367713,"As shown in Table 2, it compares our proposed method with the state-of-the-art methods on NAS-
308"
EXPERIMENTAL DETAILS,0.7443946188340808,"Bench-201. Compared to NASWOT(N=10) [13], NASWOT(N=100) and NASWOT(N=1000) are
309"
EXPERIMENTAL DETAILS,0.7466367713004485,"much more accurate due to enlarged sample amounts. However, it also cause 10× and 100× waste of
310"
EXPERIMENTAL DETAILS,0.7488789237668162,"search costs. NASI [22] also enlarges its search cost to get much more precise results with extension
311"
EXPERIMENTAL DETAILS,0.7511210762331838,"of 90s. Our approach gets the same search cost with NASWOT (3s) while being much more precise
312"
EXPERIMENTAL DETAILS,0.7533632286995515,"on CIFAR-10 (90.03% v.s. 89.14%, 93.49% v.s. 92.44), CIFAR-100 (70.18% v.s. 68.50%, 71.18%
313"
EXPERIMENTAL DETAILS,0.7556053811659192,"v.s. 68.62%) and ImageNet 16-120 (43.83% v.s. 41.09%, 44.43% v.s. 41.31). A 9s extension of
314"
EXPERIMENTAL DETAILS,0.757847533632287,"search cost (Ours-G) by neuron games gets even better results than NASWOT and NASI for their
315"
EXPERIMENTAL DETAILS,0.7600896860986547,extreme results.
EXPERIMENTAL DETAILS,0.7623318385650224,Table 2: Comparison with the state-of-the-art methods on NAS-Bench-201.
EXPERIMENTAL DETAILS,0.7645739910313901,"Algorithm
Search Cost
CIFAR-10
CIFAR-100
ImageNet 16-120"
EXPERIMENTAL DETAILS,0.7668161434977578,"GPU seconds
Val (%)
Test (%)
Val (%)
Test (%)
Val (%)
Test (%)"
EXPERIMENTAL DETAILS,0.7690582959641256,"ResNet [8]
-
90.83
93.97
70.42
70.86
44.53
43.63
Optimal
-
91.61
94.37
73.49
73.51
46.77
47.31"
EXPERIMENTAL DETAILS,0.7713004484304933,"RSPS [9]
7587
84.16 ± 1.69
87.66 ± 1.69
45.78 ± 6.33
46.60 ± 6.57
31.09 ± 5.65
30.78 ± 6.12
DARTS(1st) [12]
10890
39.77 ± 0.00
54.30 ± 0.00
15.03 ± 0.00
15.61 ± 0.00
16.43 ± 0.00
16.32 ± 0.00
DARTS(2nd) [12]
29902
39.77 ± 0.00
54.30 ± 0.00
15.03 ± 0.00
15.61 ± 0.00
16.43 ± 0.00
16.32 ± 0.00"
EXPERIMENTAL DETAILS,0.773542600896861,"NASWOT(N=10) [13]
3
89.14 ± 1.14
92.44 ± 1.13
68.50 ± 2.03
68.62 ± 2.04
41.09 ± 3.97
41.31 ± 4.11
NASWOT(N=100) [13]
30
89.55 ± 0.89
92.81 ± 0.99
69.35 ± 1.70
69.48 ± 1.70
42.81 ± 3.05
43.10 ± 3.16
NASWOT(N=1000) [13]
300
89.69 ± 0.73
92.96 ± 0.81
69.86 ± 1.21
69.98 ± 1.22
43.95 ± 2.05
44.44 ± 2.10
NASI(T) [22]
30
-
93.08 ± 0.24
-
69.51 ± 0.59
-
40.87 ± 0.85
NASI(4T) [22]
120
-
93.55 ± 0.10
-
71.20 ± 0.14
-
44.84 ± 1.41"
EXPERIMENTAL DETAILS,0.7757847533632287,"Ours
3
90.03 ± 0.61
93.49 ± 0.71
70.18 ± 1.38
71.18 ± 1.41
43.83 ± 2.10
44.43 ± 2.11
Ours-G
12
90.12 ± 0.52
93.59 ± 0.67
70.54 ± 1.29
71.50 ± 1.31
45.77 ± 1.20
45.73 ± 1.21 316"
RESULTS ON IMAGENET WITH THE DARTS SEARCH SPACE,0.7780269058295964,"4.4
Results on ImageNet with the DARTS search space
317"
RESULTS ON IMAGENET WITH THE DARTS SEARCH SPACE,0.7802690582959642,"As shown in Table 3, we report the searched results on ImageNet. The validation size of the
318"
RESULTS ON IMAGENET WITH THE DARTS SEARCH SPACE,0.7825112107623319,"observation data batch is 1024. On ImageNet, the number of classes is 1000 so a large data batch is
319"
RESULTS ON IMAGENET WITH THE DARTS SEARCH SPACE,0.7847533632286996,"necessary. Compared to NASI [22], and TE-NAS [2], our search costs are faster when p = 1. The
320"
RESULTS ON IMAGENET WITH THE DARTS SEARCH SPACE,0.7869955156950673,"larger batches for evaluation enlarge the search cost for observational data resulting in a slightly
321"
RESULTS ON IMAGENET WITH THE DARTS SEARCH SPACE,0.7892376681614349,"larger search cost when p = 0.5. Ours(p=1) gets a competitive test error rate (25.0%) in the table and
322"
RESULTS ON IMAGENET WITH THE DARTS SEARCH SPACE,0.7914798206278026,NASI-ADA [22] gets similar result (24.8%) but NASI-ADA has a larger search cost (864s v.s. 8s).
RESULTS ON IMAGENET WITH THE DARTS SEARCH SPACE,0.7937219730941704,Table 3: Comparisons with the state-of-the-art on ImageNet.
RESULTS ON IMAGENET WITH THE DARTS SEARCH SPACE,0.7959641255605381,"Algorithm
Search Cost
Test Error
Params
(GPU seconds)
(%)
(M)"
RESULTS ON IMAGENET WITH THE DARTS SEARCH SPACE,0.7982062780269058,"DARTS [12]
8.64×105
26.7
4.7
DARTS+PT [25]
2.94×105
25.5
4.6
DrNAS [3]
3.37×105
24.2
5.2"
RESULTS ON IMAGENET WITH THE DARTS SEARCH SPACE,0.8004484304932735,"TE-NAS [2]
4320
26.2
5.0
TE-NAS [2]
14688
24.5
5.4
NASI-ADA [22]
864
24.8
5.2
NASI-FIX [22]
864
24.3
5.5"
RESULTS ON IMAGENET WITH THE DARTS SEARCH SPACE,0.8026905829596412,"Ours(p=0.5)
1020
25.5
4.9
Ours(p=1)
8
25.0
5.2
Ours-G
31
24.8
5.4 323"
CONCLUSION,0.804932735426009,"5
Conclusion
324"
CONCLUSION,0.8071748878923767,"In this work, we interpret the zero-shot NAS as a causal representation learning and solve it by
325"
CONCLUSION,0.8094170403587444,"interventional data from one-shot NAS. Besides, our work is dedicated to displaying the inheriting
326"
CONCLUSION,0.8116591928251121,"relationship among the latent variables. We demonstrate that the neural architectures can be evaluated
327"
CONCLUSION,0.8139013452914798,"and selected by a Gaussian distribution given Gaussian inputs. Experiments on benchmark datasets
328"
CONCLUSION,0.8161434977578476,"reveal awesome efficiency and competitive accuracy.
329"
REFERENCES,0.8183856502242153,"References
330"
REFERENCES,0.820627802690583,"[1] Kartik Ahuja, Divyat Mahajan, Yixin Wang, and Yoshua Bengio. Interventional causal repre-
331"
REFERENCES,0.8228699551569507,"sentation learning. arXiv preprint arXiv:2209.11924, 2022.
332"
REFERENCES,0.8251121076233184,"[2] Wuyang Chen, Xinyu Gong, and Zhangyang Wang. Neural architecture search on imagenet in
333"
REFERENCES,0.827354260089686,"four gpu hours: A theoretically inspired perspective. arXiv preprint arXiv:2102.11535, 2021.
334"
REFERENCES,0.8295964125560538,"[3] Xiangning Chen, Ruochen Wang, Minhao Cheng, Xiaocheng Tang, and Cho-Jui Hsieh. Drnas:
335"
REFERENCES,0.8318385650224215,"Dirichlet neural architecture search. arXiv preprint arXiv:2006.10355, 2020.
336"
REFERENCES,0.8340807174887892,"[4] Frederick Eberhardt and Richard Scheines. Interventions and causal inference. Philosophy of
337"
REFERENCES,0.8363228699551569,"Science, 74(5):981–995, 2007.
338"
REFERENCES,0.8385650224215246,"[5] Adam Gaier and David Ha. Weight agnostic neural networks. Advances in neural information
339"
REFERENCES,0.8408071748878924,"processing systems, 32, 2019.
340"
REFERENCES,0.8430493273542601,"[6] Huang Gao, Liu Zhuang, LVD Maaten, and Kilian Q Weinberger. Densely connected convolu-
341"
REFERENCES,0.8452914798206278,"tional networks. In CVPR, volume 1, page 3, 2017.
342"
REFERENCES,0.8475336322869955,"[7] Amirata Ghorbani and James Y Zou. Neuron shapley: Discovering the responsible neurons.
343"
REFERENCES,0.8497757847533632,"Advances in Neural Information Processing Systems, 33:5922–5932, 2020.
344"
REFERENCES,0.852017937219731,"[8] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
345"
REFERENCES,0.8542600896860987,"recognition. In 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR
346"
REFERENCES,0.8565022421524664,"2016, Las Vegas, NV, USA, June 27-30, 2016, pages 770–778, 2016.
347"
REFERENCES,0.8587443946188341,"[9] Liam Li and Ameet Talwalkar. Random search and reproducibility for neural architecture search.
348"
REFERENCES,0.8609865470852018,"In Uncertainty in Artificial Intelligence, pages 367–377. PMLR, 2020.
349"
REFERENCES,0.8632286995515696,"[10] Ming Lin, Pichao Wang, Zhenhong Sun, Hesen Chen, Xiuyu Sun, Qi Qian, Hao Li, and Rong
350"
REFERENCES,0.8654708520179372,"Jin. Zen-nas: A zero-shot nas for high-performance image recognition. In 2021 IEEE/CVF
351"
REFERENCES,0.8677130044843049,"International Conference on Computer Vision (ICCV), pages 337–346, 2021.
352"
REFERENCES,0.8699551569506726,"[11] Chenxi Liu, Barret Zoph, Maxim Neumann, Jonathon Shlens, Wei Hua, Li-Jia Li, Li Fei-Fei,
353"
REFERENCES,0.8721973094170403,"Alan Yuille, Jonathan Huang, and Kevin Murphy. Progressive neural architecture search. In
354"
REFERENCES,0.874439461883408,"Proceedings of the European conference on computer vision (ECCV), pages 19–34, 2018.
355"
REFERENCES,0.8766816143497758,"[12] Hanxiao Liu, Karen Simonyan, and Yiming Yang. Darts: Differentiable architecture search.
356"
REFERENCES,0.8789237668161435,"arXiv preprint arXiv:1806.09055, 2018.
357"
REFERENCES,0.8811659192825112,"[13] Joe Mellor, Jack Turner, Amos Storkey, and Elliot J Crowley. Neural architecture search
358"
REFERENCES,0.8834080717488789,"without training. In Proceedings of the International Conference on Machine Learning, pages
359"
REFERENCES,0.8856502242152466,"7588–7598. PMLR, 2021.
360"
REFERENCES,0.8878923766816144,"[14] Guido F Montufar, Razvan Pascanu, Kyunghyun Cho, and Yoshua Bengio. On the number of
361"
REFERENCES,0.8901345291479821,"linear regions of deep neural networks. Advances in neural information processing systems, 27,
362"
REFERENCES,0.8923766816143498,"2014.
363"
REFERENCES,0.8946188340807175,"[15] Yookoon Park, Sangho Lee, Gunhee Kim, and David M. Blei. Unsupervised representation
364"
REFERENCES,0.8968609865470852,"learning via neural activation coding. arXiv preprint arXiv:2112.04014, 2021.
365"
REFERENCES,0.899103139013453,"[16] Hieu Pham, Melody Guan, Barret Zoph, Quoc Le, and Jeff Dean. Efficient neural architecture
366"
REFERENCES,0.9013452914798207,"search via parameters sharing. In International Conference on Machine Learning, pages
367"
REFERENCES,0.9035874439461884,"4095–4104. PMLR, 2018.
368"
REFERENCES,0.905829596412556,"[17] Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc V Le. Regularized evolution for image
369"
REFERENCES,0.9080717488789237,"classifier architecture search. In Proceedings of the aaai conference on artificial intelligence,
370"
REFERENCES,0.9103139013452914,"volume 33, pages 4780–4789, 2019.
371"
REFERENCES,0.9125560538116592,"[18] Hans Reichenbach. The Direction of Time. Dover Publications, 1956.
372"
REFERENCES,0.9147982062780269,"[19] Benedek Rozemberczki and Rik Sarkar. The shapley value of classifiers in ensemble games.
373"
REFERENCES,0.9170403587443946,"arXiv preprint arXiv:2101.02153, 2021.
374"
REFERENCES,0.9192825112107623,"[20] Bernhard Schölkopf, Francesco Locatello, Stefan Bauer, Nan Rosemary Ke, Nal Kalchbrenner,
375"
REFERENCES,0.92152466367713,"Anirudh Goyal, and Yoshua Bengio. Toward causal representation learning. Proceedings of the
376"
REFERENCES,0.9237668161434978,"IEEE, 109(5):612–634, 2021.
377"
REFERENCES,0.9260089686098655,"[21] LS Shapley. Quota solutions op n-person games1. Edited by Emil Artin and Marston Morse,
378"
REFERENCES,0.9282511210762332,"page 343, 1953.
379"
REFERENCES,0.9304932735426009,"[22] Yao Shu, Shaofeng Cai, Zhongxiang Dai, Beng Chin Ooi, and Bryan Kian Hsiang Low.
380"
REFERENCES,0.9327354260089686,"Nasi: Label-and data-agnostic neural architecture search at initialization.
arXiv preprint
381"
REFERENCES,0.9349775784753364,"arXiv:2109.00817, 2021.
382"
REFERENCES,0.9372197309417041,"[23] Jin Tian and Judea Pearl. Causal discovery from changes. arXiv preprint arXiv:1301.2312,
383"
REFERENCES,0.9394618834080718,"2013.
384"
REFERENCES,0.9417040358744395,"[24] Isabella Verdinelli and Larry Wasserman. Feature importance: A closer look at shapley values
385"
REFERENCES,0.9439461883408071,"and loco. arXiv preprint arXiv:2303.05981, 2023.
386"
REFERENCES,0.9461883408071748,"[25] Ruochen Wang, Minhao Cheng, Xiangning Chen, Xiaocheng Tang, and Cho-Jui Hsieh. Re-
387"
REFERENCES,0.9484304932735426,"thinking architecture selection in differ-entiable nas. In International Conference on Learning
388"
REFERENCES,0.9506726457399103,"Representations, 2021.
389"
REFERENCES,0.952914798206278,"[26] Yibo Yang, Hongyang Li, Shan You, Fei Wang, Chen Qian, and Zhouchen Lin.
Ista-
390"
REFERENCES,0.9551569506726457,"nas: Efficient and consistent neural architecture search by sparse coding. arXiv preprint
391"
REFERENCES,0.9573991031390134,"arXiv:2010.06176, 2020.
392"
REFERENCES,0.9596412556053812,"[27] Quanming Yao, Mengshuo Wang, Hugo Jair Escalante, Isabelle Guyon, Yi-Qi Hu, Yu-Feng Li,
393"
REFERENCES,0.9618834080717489,"Wei-Wei Tu, Qiang Yang, and Yang Yu. Taking human out of learning applications: A survey
394"
REFERENCES,0.9641255605381166,"on automated machine learning. CoRR, abs/1810.13306, 2018.
395"
REFERENCES,0.9663677130044843,"[28] Chris Ying, Aaron Klein, Eric Christiansen, Esteban Real, Kevin Murphy, and Frank Hutter.
396"
REFERENCES,0.968609865470852,"Nas-bench-101: Towards reproducible neural architecture search. In International Conference
397"
REFERENCES,0.9708520179372198,"on Machine Learning, pages 7105–7114. PMLR, 2019.
398"
REFERENCES,0.9730941704035875,"[29] Arber Zela, Thomas Elsken, Tonmoy Saikia, Yassine Marrakchi, Thomas Brox, and Frank
399"
REFERENCES,0.9753363228699552,"Hutter. Understanding and robustifying differentiable architecture search. In 8th International
400"
REFERENCES,0.9775784753363229,"Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30,
401"
REFERENCES,0.9798206278026906,"2020, 2020.
402"
REFERENCES,0.9820627802690582,"[30] Hongpeng Zhou, Minghao Yang, Jun Wang, and Wei Pan. Bayesnas: A bayesian approach for
403"
REFERENCES,0.984304932735426,"neural architecture search. In International Conference on Machine Learning, pages 7603–7613.
404"
REFERENCES,0.9865470852017937,"PMLR, 2019.
405"
REFERENCES,0.9887892376681614,"[31] Barret Zoph and Quoc V Le. Neural architecture search with reinforcement learning. arXiv
406"
REFERENCES,0.9910313901345291,"preprint arXiv:1611.01578, 2016.
407"
REFERENCES,0.9932735426008968,"[32] Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V Le.
Learning transferable
408"
REFERENCES,0.9955156950672646,"architectures for scalable image recognition. In Proceedings of the IEEE conference on computer
409"
REFERENCES,0.9977578475336323,"vision and pattern recognition, pages 8697–8710, 2018.
410"
