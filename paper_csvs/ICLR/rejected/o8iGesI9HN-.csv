Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0024875621890547263,"The convolution operation is the most critical component in recent surge of deep
learning research. Conventional 2D convolution needs O(C2K2) parameters to
represent, where C is the channel size and K is the kernel size. The amount of
parameters has become really costly considering that these parameters increased
tremendously recently to meet the needs of demanding applications. Among var-
ious implementations of the convolution, separable convolution has been proven
to be more efﬁcient in reducing the model size. For example, depth separable
convolution reduces the complexity to O(C · (C + K2)) while spatial separable
convolution reduces the complexity to O(C2K). However, these are considered
ad hoc designs which cannot ensure that they can in general achieve optimal sep-
aration. In this research, we propose a novel and principled operator called opti-
mized separable convolution by optimal design for the internal number of groups
and kernel sizes for general separable convolutions can achieve the complexity of
O(C
3
2 K). When the restriction in the number of separated convolutions can be
lifted, an even lower complexity at O(C · log(CK2)) can be achieved. Experi-
mental results demonstrate that the proposed optimized separable convolution is
able to achieve an improved performance in terms of accuracy-#Params trade-offs
over both conventional, depth-wise, and depth/spatial separable convolutions."
INTRODUCTION,0.004975124378109453,"1
INTRODUCTION"
INTRODUCTION,0.007462686567164179,"Tremendous progresses have been made in recent years towards more accurate image analysis tasks,
such as image classiﬁcation, with deep convolutional neural networks (DCNNs) (Krizhevsky et al.,
2012; Srivastava et al., 2015; He et al., 2016; Real et al., 2019; Tan & Le, 2019; Dai et al., 2020).
However, the complexity of state-of-the-art DCNN models has also become increasingly high. This
can signiﬁcantly deter their deployment to real-world applications, such as mobile platforms and
robotics, where the resources and networks are highly constrained (Howard et al., 2017; Dai et al.,
2020)."
INTRODUCTION,0.009950248756218905,"The most resource-consuming building block of a DCNN is the convolutional layer. There have
been many previous works aiming at reducing the amount of parameters in the convolutional layer.
Network pruning (Han et al., 2015) strategies are developed to reduce redundant parameters that are
not sensitive to performances. Quantization and binarization (Gong et al., 2014; Courbariaux et al.,
2016) techniques are introduced to compress the original network by reducing the number of bits re-
quired to represent each parameter. Low-rank factorization methods (Jaderberg et al., 2014; Ioannou
et al., 2015) are designed to approximate the original weights using matrix decomposition. Knowl-
edge distillation (Hinton et al., 2015) is applied to train a compact network with distilled knowledge
from a large ensemble model. However, all these existing methods start from a pre-trained model.
Besides, they mainly focus on network compression and have limited or no improvements in terms
of network acceleration."
INTRODUCTION,0.012437810945273632,"In this research, we study how to design a separable convolution to achieve an optimal implemen-
tation in terms of model size (representational complexity). Enabling convolution to be separable
has been proven to be an efﬁcient way to reduce the representational complexity (Sifre & Mallat,
2014; Howard et al., 2017; Szegedy et al., 2016). Comparing to the network compression related
approaches, a well-designed separable convolution shall be more efﬁcient in both storage and com-
putation and shall not require a pre-trained model to begin with."
INTRODUCTION,0.014925373134328358,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.017412935323383085,"Table 1. A comparison of the number of parameters and computational complexity of the proposed optimized
separable convolution and existing approaches. The proposed optimized separable convolution is much more
efﬁcient in both #Params and FLOPs. In this table, C represents the channel size of convolution, K is the
kernel size, H and W are the output height and width, g is the number of groups. “Vol. RF” represents whether
the corresponding convolution satisﬁes the proposed volumetric receptive ﬁeld condition."
INTRODUCTION,0.01990049751243781,"Conventional
Grouped
Depth-wise
Point-wise
Depth Separable
Spatial Separable
Optimized Separable
Optimized Separable"
INTRODUCTION,0.022388059701492536,"Conv2D
Conv2D
Conv2D
Conv2D
Conv2D
Conv2D
Conv2D (N = 2)
Conv2D (Optimized N)"
INTRODUCTION,0.024875621890547265,"#Params
C2K2
C2K2/g
CK2
C2
C(C + K2)
2C2K
2C
3
2 K
eC log(CK2)"
INTRODUCTION,0.02736318407960199,"FLOPs
C2K2HW
C2K2HW/g
CK2HW
C2HW
CHW (C + K2)
2C2KHW
2C
3
2 KHW
eCHW log(CK2)"
INTRODUCTION,0.029850746268656716,"Vol. RF







"
INTRODUCTION,0.03233830845771144,"Note
-
-
g = C
K = 1
Depth-wise + Point-wise
K2 →2K
-
e = 2.71828..."
INTRODUCTION,0.03482587064676617,Volumetric RF
INTRODUCTION,0.03731343283582089,"Receptive Field
(RF)"
INTRODUCTION,0.03980099502487562,Channel RF (a)
INTRODUCTION,0.04228855721393035,"3x3
3x3
1x1
3x3
1x1"
INTRODUCTION,0.04477611940298507,"Conv2D
Depth Separable
Optimal Separable"
INTRODUCTION,0.0472636815920398,"(b)
Figure 1. Volumetric receptive ﬁeld and the proposed optimized separable convolution. (a) The volumetric
receptive ﬁeld (RF) of a convolution is the Cartesian product of its (spatial) RF and channel RF. (b) Illustrations
of the channel connections for conventional, depth separable, and the proposed optimized separable convolu-
tions. Optimized separable convolution is sparse-connected, whereas it can be efﬁciently implemented using a
channel shufﬂe operation."
INTRODUCTION,0.04975124378109453,"In the DCNN research, the two most well-known separable convolutions are depth separable (Sifre
& Mallat, 2014) and spatial separable (Szegedy et al., 2016) convolutions. Both are able to reduce
the complexity of a convolution. The representational complexity of a conventional 2D convolu-
tion is quadratic with two hyper-parameters: number of channels (C) and kernel size (K), and its
representational complexity is actually O(C2K2). Depth separable convolution is constructed as
a depth-wise convolution followed by a point-wise convolution, where depth-wise convolution is a
group convolution with its number of groups g = C and point-wise convolution is a 1 × 1 convo-
lution. Spatial separable convolution replaces a K × K kernel with a K × 1 and a 1 × K kernel.
Different types of convolutions and their complexities are summarized in Table 1. From this table,
we can see that, for all convolutions, their computational complexities equal to the corresponding
representational complexity times a constant. We can also verify that depth separable convolution
has a complexity of O(C·(C+K2)) and spatial separable convolution has a complexity of O(C2K)."
INTRODUCTION,0.05223880597014925,"Both depth and spatial separable convolutions follow an ad hoc design mode and are non-principled.
They are able to reduce the complexity to some degree but normally cannot achieve an optimal sepa-
ration. A separable convolution in general has three sets of hyperparameters: the internal number of
groups, channel size, and kernel size of each separated convolution. Instead of setting these hyper-
parameters in an ad hoc (manual) fashion, we design a novel and principled (auto) scheme to achieve
an optimal separation. The resulting separable convolution is called optimized separable convolu-
tion in this research. The proposed scheme in general performs better than the other convolution
operator counterparts and it also enriches the separable convolution family."
INTRODUCTION,0.05472636815920398,"To prevent the proposed optimized separable convolution from being degenerated, we assume that
the internal channel size is in an order of O(C) and propose the following volumetric receptive ﬁeld
condition. As illustrated in Fig. 1a, similar to the receptive ﬁeld (RF) of a convolution which is
deﬁned as the region in the input space that a particular CNN’s feature is looking at (or affected by)
(Lindeberg, 2013), we deﬁne the volumetric RF of a convolution to be the volume in the input space
that affects CNN’s output. The volumetric RF condition requires a properly decomposed separable
convolution to maintain the same volumetric RF as the original convolution before decomposition.
Hence, the proposed optimized separable convolution will be equivalent to optimizing the internal
number of groups and kernel sizes to achieve the target objective (measured in #Params) while"
INTRODUCTION,0.05721393034825871,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.05970149253731343,"satisfying the proposed volumetric RF condition. Formally, the objective function is deﬁned by
Equation (2) under the constraints deﬁned by Equations (3)-(6). The solution to this optimization
problem will be elaborated in Section 2."
INTRODUCTION,0.06218905472636816,"We shall show that the proposed optimized separable convolution can be represented with the order
of O(C
3
2 K). This is at least a factor of
√"
INTRODUCTION,0.06467661691542288,"C more efﬁcient than the depth and spatial separable
convolutions. The proposed optimized separable convolution is able to be generalized into an N-
separable case, where the number of separated convolutions N can be optimized further. In such a
generalized case, an even lower complexity at O(C · log(CK2)) may be achieved."
INTRODUCTION,0.06716417910447761,"Extensive experiments have been carried out to demonstrate the effectiveness of the proposed opti-
mized separable convolution over other alternatives, including conventional, depth-wise, depth and
spatial separable convolutions (Fig. 3(c) and Fig. 4(c)). As further illustrated in Fig. 3 and Fig.
4, on the CIFAR10 and CIFAR100 datasets (Krizhevsky et al., 2009), the proposed optimized sep-
arable convolution achieves a better Pareto-frontier1 than both conventional and depth separable
convolutions using the ResNet (He et al., 2016) architecture. To demonstrate that the proposed op-
timized separable convolution generalizes well to other DCNN architectures, we adopt the DARTS
(Liu et al., 2018) architecture by replacing the depth separable convolution with the proposed op-
timized separable convolution. The accuracy is improved from 97.24% to 97.67% with reduced
representational complexity. On the ImageNet dataset (Deng et al., 2009), the proposed optimized
separable convolution also achieves improved performance. For the DARTS architecture, the pro-
posed approach achieves 74.2% top1 accuracy with only 4.5 million parameters. For MobileNet, the
proposed approach achieves 71.1% top1 accuracy with only 3.0 million parameters."
THE PROPOSED APPROACH,0.06965174129353234,"2
THE PROPOSED APPROACH"
CONVOLUTION AND ITS COMPLEXITY,0.07213930348258707,"2.1
CONVOLUTION AND ITS COMPLEXITY"
CONVOLUTION AND ITS COMPLEXITY,0.07462686567164178,"A convolutional layer takes an input tensor Bl−1 of shape (Cl−1, Hl−1, Wl−1) and produces an
output tensor Bl of shape (Cl, Hl, Wl), where C∗, H∗, W∗are input and output channels, feature
heights and widths. The convolutional layer is parameterized with a convolutional kernel of shape
(Cl, Cl−1, KH
l , KW
l ), where K∗
l are the kernel sizes, and the superscript indicates whether it is
aligned with the features in height or width. In this research, we take C∗= O(C), H∗= O(H),
W∗= O(W), and KH|W
∗
= O(K) for complexity analysis. Formally, we have"
CONVOLUTION AND ITS COMPLEXITY,0.07711442786069651,"Bl(cl, hl, wl) =
X cl−1 X kH
l X kW
l"
CONVOLUTION AND ITS COMPLEXITY,0.07960199004975124,"Bl−1(cl−1, hl−1, wl−1) · Fl(cl, cl−1, kH
l , kW
l ),
(1)"
CONVOLUTION AND ITS COMPLEXITY,0.08208955223880597,"where hl = hl−1 + kH
l and wl = wl−1 + kW
l . Hence, the number of parameters for convolution is
ClCl−1KH
l KW
l
and its representational complexity is O(C2K2). The number of FLOPs (multiply-
adds) for convolution is ClHlWl·Cl−1KH
l KW
l
and its computational complexity is O(C2K2HW)."
CONVOLUTION AND ITS COMPLEXITY,0.0845771144278607,"For a group convolution, we have g convolutions with kernels of shape (Cl/g, Cl−1/g, KH
l , KW
l ).
Hence, it has O(C2K2/g) parameters and O(C2K2HW/g) FLOPs, where g is the number of
groups. A depth-wise convolution is equivalent to a group convolution with g = C∗= C. A point-
wise convolution is a 1×1 convolution. A depth separable convolution is composed of a depth-wise
convolution and a point-wise convolution. A spatial separable convolution replaces a K × K kernel
with K × 1 and 1 × K kernels. Different types of convolutions are summarized in Table 1. From
this table, their number of parameters and FLOPs can be easily veriﬁed. It can also be seen that, for
a convolution, its representational complexity is equivalent to its computational complexity for up
to a constant (HW)."
RETHINKING CONVOLUTION AND THE VOLUMETRIC RECEPTIVE FIELD CONDITION,0.08706467661691543,"2.2
RETHINKING CONVOLUTION AND THE VOLUMETRIC RECEPTIVE FIELD CONDITION"
RETHINKING CONVOLUTION AND THE VOLUMETRIC RECEPTIVE FIELD CONDITION,0.08955223880597014,"Separable convolution has been proven to be efﬁcient in reducing the representational demand in
convolution. However, existing approaches including both depth and spatial separable convolutions
follow an ad hoc design and are non-principled. They are able to reduce the complexity to some
extent but will not normally achieve an optimal separation. In this research, we shall design an"
RETHINKING CONVOLUTION AND THE VOLUMETRIC RECEPTIVE FIELD CONDITION,0.09203980099502487,"1In multi-objective optimization, a Pareto-frontier is the set of parameterizations (allocations) that are all
Pareto-optimal. An allocation is Pareto-optimal if there is no alternative allocation where improvement can be
made to one participant’s well-being without sacriﬁcing any other’s. Here, Pareto-frontier represents the curve
of the accuracies we are able to achieve for different #Params (or FLOPs)."
RETHINKING CONVOLUTION AND THE VOLUMETRIC RECEPTIVE FIELD CONDITION,0.0945273631840796,Under review as a conference paper at ICLR 2022
RETHINKING CONVOLUTION AND THE VOLUMETRIC RECEPTIVE FIELD CONDITION,0.09701492537313433,"efﬁcient convolution operator capable of achieving the representational objective by optimal design
of its internal hyper-parameters. The resulting operator is called optimized separable convolution."
RETHINKING CONVOLUTION AND THE VOLUMETRIC RECEPTIVE FIELD CONDITION,0.09950248756218906,"The proposed optimized separable convolution is called principled as it optimizes the representa-
tional complexity under the following volumetric receptive ﬁeld condition. As illustrated in Fig. 1a,
the receptive ﬁeld (RF) of a convolution is deﬁned to be the region in the input space that a particular
CNN’s feature is affected by (Lindeberg, 2013). We deﬁne the channel RF to be the channels that
affect CNN’s output and deﬁne the volumetric RF to be the Cartesian product of the RF and channel
RF of this convolution. The volumetric RF of a convolution actually represents the volume in the
input space that affects CNN’s output. The volumetric RF condition requires that a properly decom-
posed separable convolution at least maintains the same volumetric RF as the original convolution
before decomposition. Hence, the proposed optimized separable convolution will be equivalent to
optimizing its internal parameters while satisfying the volumetric RF condition. Formally, we shall
have the objective function deﬁned by Equation (2) and the volumetric RF constraints deﬁned by
Equations (3)-(6)."
RETHINKING CONVOLUTION AND THE VOLUMETRIC RECEPTIVE FIELD CONDITION,0.10199004975124377,"The volumetric RF of a convolution needs to be maintained for technical, conceptual, and experi-
mental reasons. Technically, if we do not pose any restriction to a separable convolution, optimizing
the representational complexity will resulting in a separable convolution being equivalent to a de-
generated channel scaling operator2. The composition of such operators is not meaningful because
the composition itself is equivalent to a single channel scaling operator. Conceptually, maintain-
ing the volumetric RF encourages the fusion of channel information, which shall contribute to the
good performance of a DCNN. In fact, all modern DCNNs are designed following this rule. With-
out this channel information exchange, the performance of a DCNN shall be signiﬁcantly degraded
(depth-wise vs depth separable convolutions in Section 3). Finally, the necessity of maintaining
the volumetric RF is experimentally veriﬁed. We shall quantize the degree of necessity as overlap
coefﬁcient (γ) in Section 2.3 and elaborate the experimental results in Section 3."
OPTIMIZED SEPARABLE CONVOLUTION,0.1044776119402985,"2.3
OPTIMIZED SEPARABLE CONVOLUTION"
OPTIMIZED SEPARABLE CONVOLUTION,0.10696517412935323,"In this section, for ease of simplicity, we ﬁrst discuss the case of two-separable convolution. Suppose
that the shape of the original convolutional kernel is (Cout, Cin, KH, KW ), where Cin, Cout are
the input and output channels, and (KH, KW ) is the kernel size. Let C1 = Cin, and C3 = Cout.
For the proposed optimized separable convolution, we optimize the representational complexity as
objective while maintaining the original convolution’s volumetric RF. Formally, the representational
demand of the proposed separable convolution is"
OPTIMIZED SEPARABLE CONVOLUTION,0.10945273631840796,"f(g1, g2, C2, KH|W
∗
) = C2C1KH
1 KW
1
g1
+ C3C2KH
2 KW
2
g2
(2)"
OPTIMIZED SEPARABLE CONVOLUTION,0.11194029850746269,"In order to satisfy the volumetric RF condition, the following three conditions need to be satisﬁed:
KH
1 + KH
2 −1 = KH
(Receptive Field Condition)
(3)"
OPTIMIZED SEPARABLE CONVOLUTION,0.11442786069651742,"KW
1
+ KW
2
−1 = KW
(4)"
OPTIMIZED SEPARABLE CONVOLUTION,0.11691542288557213,g1 · g2 ≤C2/γ ⇔C1
OPTIMIZED SEPARABLE CONVOLUTION,0.11940298507462686,"g1
· C2"
OPTIMIZED SEPARABLE CONVOLUTION,0.12189054726368159,"g2
≥γC1
(Channel Condition)
(5)"
OPTIMIZED SEPARABLE CONVOLUTION,0.12437810945273632,"min(Cl, Cl+1) ≥gl
(Group Convolution Condition)
(6)"
OPTIMIZED SEPARABLE CONVOLUTION,0.12686567164179105,The channel condition (5) means the product C1
OPTIMIZED SEPARABLE CONVOLUTION,0.12935323383084577,g1 · C2
OPTIMIZED SEPARABLE CONVOLUTION,0.1318407960199005,"g2 needs to occupy each node in the input channel
C1 = Cin to maintain the volumetric receptive ﬁeld. This is further explained for the channel
condition general case (15) in Section 2.4. In order to study the necessity of the proposed volumetric
RF condition, an overlap coefﬁcient γ is introduced to encourage channel information fusion. It can
be veriﬁed that, if γ ≥1, the channel RF shall be maintained, otherwise, it shall be not. By default,
we set γ = 1 in this research unless the behavior of γ is particularly concerned."
OPTIMIZED SEPARABLE CONVOLUTION,0.13432835820895522,"We have three sets of parameters: the number of groups g1, g2, the internal channel size C2, and the
internal kernel sizes KH|W
∗
. In this research, we assume that the internal channel size C2 is in an
order of O(C) and is preset according to a given policy. Otherwise, g1 = g2 = C2 = 1 will be a
trivial solution. This could lead the separable convolution to be over-simpliﬁed and not applicable"
OPTIMIZED SEPARABLE CONVOLUTION,0.13681592039800994,"2From Table 1, let g = C and K = 1, a convolution will have C parameters and CHW FLOPs. This is in
fact a channel scaling operator."
OPTIMIZED SEPARABLE CONVOLUTION,0.13930348258706468,Under review as a conference paper at ICLR 2022
OPTIMIZED SEPARABLE CONVOLUTION,0.1417910447761194,"in practice. Typical policies of presetting C2 include C2 = min(C1, C3) (normal architecture),
C2 = (C1 + C3)/2 (linear architecture), C2 = max(C1, C3)/4 (bottleneck architecture (He et al.,
2016)), or C2 = 4 min(C1, C3) (inverted residual architecture (Sandler et al., 2018))."
OPTIMIZED SEPARABLE CONVOLUTION,0.14427860696517414,number of groups
OPTIMIZED SEPARABLE CONVOLUTION,0.14676616915422885,"6.0 6.5 7.0 7.5 8.0 8.5 9.0
9.5 10.0"
OPTIMIZED SEPARABLE CONVOLUTION,0.14925373134328357,kernel size 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 2800 3000 3200 3400 3600 FLOPs
OPTIMIZED SEPARABLE CONVOLUTION,0.1517412935323383,"Figure 2.
Given channels C1 = C2 =
C3 = 64, and kernel sizes KH = KW = 5
in Equation (2), by setting f ′(g1) = 0,
f ′(K1) = 0. The solution g1 = 8, K1 = 3
is a saddle point."
OPTIMIZED SEPARABLE CONVOLUTION,0.15422885572139303,"The solution to the proposed optimized separable prob-
lem shall be given in Theorem 1 in Section 2.4. By setting
N = 2 and γ = 1, we shall have g1 = s"
OPTIMIZED SEPARABLE CONVOLUTION,0.15671641791044777,"C1C2KH
1 KW
1
C3KH
2 KW
2
∼
√"
OPTIMIZED SEPARABLE CONVOLUTION,0.15920398009950248,"C, g2 = C2/g1
(7)"
OPTIMIZED SEPARABLE CONVOLUTION,0.16169154228855723,"(KH
1 , KH
2 ) = (KH, 1) or (1, KH)
(8)
(KW
1 , KW
2 ) = (KW , 1) or (1, KW )
(9)
and"
OPTIMIZED SEPARABLE CONVOLUTION,0.16417910447761194,"min f = 2 ·
q"
OPTIMIZED SEPARABLE CONVOLUTION,0.16666666666666666,"C1C2C3KH
1 KW
1 KH
2 KW
2
= O(C
3
2 K).
(10)"
OPTIMIZED SEPARABLE CONVOLUTION,0.1691542288557214,"One interesting fact is that if we set g2
=
C2/g1,
f ′(g1) = 0, and f ′(K1) = 0, assume that kernel sizes
aligned in height and width are equal, one can derive that
g1 is the same as Equation (7) and K1 = K2 =
K+1"
OPTIMIZED SEPARABLE CONVOLUTION,0.17164179104477612,"2 .
Substituting them into Equation (10), one can get f(g1, K1) = O(C
3
2 K2). This results in a higher
complexity than O(C
3
2 K). In fact, the solution to f ′(g1) = 0 and f ′(K1) = 0 is a saddle point,
which is illustrated in Fig. 2."
OPTIMIZED SEPARABLE CONVOLUTION,0.17412935323383086,"2.4
OPTIMIZED SEPARABLE CONVOLUTION (GENERAL CASE)"
OPTIMIZED SEPARABLE CONVOLUTION,0.17661691542288557,"In this section, we shall generalize the proposed optimized separable convolution from N = 2 to an
optimal N. For ease of analysis, we ﬁrst introduce the notation channels per group nl = Cl"
OPTIMIZED SEPARABLE CONVOLUTION,0.1791044776119403,"gl , which
simply means: channels per group × number of groups = the number of channels."
OPTIMIZED SEPARABLE CONVOLUTION,0.18159203980099503,"Theorem 1 (Optimized Separable Convolution: General Case). Suppose that the shape of the orig-
inal convolutional kernel is (Cout, Cin, KH, KW ). Let C1 = Cin, and CN+1 = Cout. The repre-
sentational demand of an N-separable convolution is"
OPTIMIZED SEPARABLE CONVOLUTION,0.18407960199004975,"f({g∗}, {KH|W
∗
}) = N
X l=1"
OPTIMIZED SEPARABLE CONVOLUTION,0.1865671641791045,"Cl+1ClKH
l KW
l
gl
(11) or"
OPTIMIZED SEPARABLE CONVOLUTION,0.1890547263681592,"f({n∗}, {KH|W
∗
}) = N
X"
OPTIMIZED SEPARABLE CONVOLUTION,0.19154228855721392,"l=1
Cl+1nlKH
l KW
l .
(12)"
OPTIMIZED SEPARABLE CONVOLUTION,0.19402985074626866,"Under the proposed volumetric RF condition, we will have:
KH
1 + KH
2 + · · · = KH + (N −1)
(Receptive Field Condition)
(13)"
OPTIMIZED SEPARABLE CONVOLUTION,0.19651741293532338,"KW
1
+ KW
2
+ · · · = KW + (N −1)
(14)"
OPTIMIZED SEPARABLE CONVOLUTION,0.19900497512437812,n1 · · · nN ≥γC1 ⇔g1 · · · gN ≤C2 · · · CN
OPTIMIZED SEPARABLE CONVOLUTION,0.20149253731343283,"γ
(Channel Condition)
(15)"
OPTIMIZED SEPARABLE CONVOLUTION,0.20398009950248755,"nl ≥max(1, Cl+1"
OPTIMIZED SEPARABLE CONVOLUTION,0.2064676616915423,"Cl
) ⇔gl ≤min(Cl, Cl+1).
(Group Convolution Condition)
(16)"
OPTIMIZED SEPARABLE CONVOLUTION,0.208955223880597,"Assume that C∗= O(C) and KH|W
∗
= O(K). The solution to this constrained optimization
problem (the proposed optimized separable convolution problem) is given by nl = Nq"
OPTIMIZED SEPARABLE CONVOLUTION,0.21144278606965175,"γΠN+1
i=1 CiΠN
i=1KH
i ΠN
i=1KW
i
Cl+1KH
l KW
l
∼
N√"
OPTIMIZED SEPARABLE CONVOLUTION,0.21393034825870647,"C
(17)"
OPTIMIZED SEPARABLE CONVOLUTION,0.21641791044776118,"KH
l0 = KH, KH
l
= 1 (l ̸= l0)
(18)"
OPTIMIZED SEPARABLE CONVOLUTION,0.21890547263681592,"KW
l1 = KW , KW
l
= 1 (l ̸= l1)
(19)
and its corresponding representational complexity is
min f({n∗}, {KH|W
∗
}) = O(Nγ
1
N C1+ 1"
OPTIMIZED SEPARABLE CONVOLUTION,0.22139303482587064,"N K
2
N ).
(20)"
OPTIMIZED SEPARABLE CONVOLUTION,0.22388059701492538,Under review as a conference paper at ICLR 2022
OPTIMIZED SEPARABLE CONVOLUTION,0.2263681592039801,"0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
#Params (million) 89 90 91 92 93 94 95"
OPTIMIZED SEPARABLE CONVOLUTION,0.22885572139303484,Top1 (%) r20 r32
OPTIMIZED SEPARABLE CONVOLUTION,0.23134328358208955,"r56
r110"
OPTIMIZED SEPARABLE CONVOLUTION,0.23383084577114427,"r20
r32 r56"
OPTIMIZED SEPARABLE CONVOLUTION,0.236318407960199,"r110
r110"
OPTIMIZED SEPARABLE CONVOLUTION,0.23880597014925373,"r20_m2.72
r32_m2.75"
OPTIMIZED SEPARABLE CONVOLUTION,0.24129353233830847,r56_m2.75
OPTIMIZED SEPARABLE CONVOLUTION,0.24378109452736318,r110_m2.75 r20 r32 r56
OPTIMIZED SEPARABLE CONVOLUTION,0.2462686567164179,"r110
r110"
OPTIMIZED SEPARABLE CONVOLUTION,0.24875621890547264,"r20_m3.625
r32_m3.75
r56_m3.875"
OPTIMIZED SEPARABLE CONVOLUTION,0.2512437810945274,r110_m3.875
OPTIMIZED SEPARABLE CONVOLUTION,0.2537313432835821,"ResNet (baseline)
d-ResNet"
OPTIMIZED SEPARABLE CONVOLUTION,0.2562189054726368,d-ResNet (w/ multiplier)
OPTIMIZED SEPARABLE CONVOLUTION,0.25870646766169153,"o-ResNet
o-ResNet (w/ multiplier) (a)"
OPTIMIZED SEPARABLE CONVOLUTION,0.26119402985074625,"0.00
0.05
0.10
0.15
0.20
0.25
FLOPs (billion) 89 90 91 92 93 94 95"
OPTIMIZED SEPARABLE CONVOLUTION,0.263681592039801,Top1 (%) r20 r32
OPTIMIZED SEPARABLE CONVOLUTION,0.26616915422885573,"r56
r110"
OPTIMIZED SEPARABLE CONVOLUTION,0.26865671641791045,"r20
r32 r56"
OPTIMIZED SEPARABLE CONVOLUTION,0.27114427860696516,"r110
r110"
OPTIMIZED SEPARABLE CONVOLUTION,0.2736318407960199,"r20_m2.72
r32_m2.75"
OPTIMIZED SEPARABLE CONVOLUTION,0.27611940298507465,r56_m2.75
OPTIMIZED SEPARABLE CONVOLUTION,0.27860696517412936,r110_m2.75 r20 r32 r56
OPTIMIZED SEPARABLE CONVOLUTION,0.2810945273631841,"r110
r110"
OPTIMIZED SEPARABLE CONVOLUTION,0.2835820895522388,r20_m3.625
OPTIMIZED SEPARABLE CONVOLUTION,0.2860696517412935,"r32_m3.75
r56_m3.875"
OPTIMIZED SEPARABLE CONVOLUTION,0.2885572139303483,r110_m3.875
OPTIMIZED SEPARABLE CONVOLUTION,0.291044776119403,"ResNet (baseline)
d-ResNet"
OPTIMIZED SEPARABLE CONVOLUTION,0.2935323383084577,d-ResNet (w/ multiplier)
OPTIMIZED SEPARABLE CONVOLUTION,0.2960199004975124,"o-ResNet
o-ResNet (w/ multiplier) (b)"
OPTIMIZED SEPARABLE CONVOLUTION,0.29850746268656714,"ResNet20
ResNet32
ResNet56
ResNet110
88 89 90 91 92 93 94 95 96 97"
OPTIMIZED SEPARABLE CONVOLUTION,0.3009950248756219,"Conventional (baseline)
Depthwise (dw-)"
OPTIMIZED SEPARABLE CONVOLUTION,0.3034825870646766,Depth Separable (d-)
OPTIMIZED SEPARABLE CONVOLUTION,0.30597014925373134,Spatial Separable (s-)
OPTIMIZED SEPARABLE CONVOLUTION,0.30845771144278605,Optimal Separable (o-)
OPTIMIZED SEPARABLE CONVOLUTION,0.31094527363184077,Spatial Optimal Separable (so-)
OPTIMIZED SEPARABLE CONVOLUTION,0.31343283582089554,"(c)
Figure 3. Experimental results on CIFAR10 for the ResNet architecture (best viewed in color). The proposed
optimized separable convolution (o-ResNet) achieves improved (a) accuracy-#Params and (b) accuracy-FLOPs
Pareto-frontiers than both the conventional (ResNet) and depth separable (d-ResNet) convolutions. (c) A com-
parison for performances of different convolution schemes."
OPTIMIZED SEPARABLE CONVOLUTION,0.31592039800995025,"Table 2. Experimental results on CIFAR10 for different overlap coefﬁcients (γ). If γ ≥1, the volumetric RF
is maintained, otherwise it is not. Each row of o-ResNet is channel multiplied. When γ < 1, the performance
hurts due to discourage of channel information fusion."
OPTIMIZED SEPARABLE CONVOLUTION,0.31840796019900497,"Overlap Coef. (γ)
ε (Depthwise)
1/16
1/4
1
4
16
64
+∞(Conventional)"
OPTIMIZED SEPARABLE CONVOLUTION,0.3208955223880597,"Vol. RF







"
OPTIMIZED SEPARABLE CONVOLUTION,0.32338308457711445,"o-ResNet20
90.2
91.45
92.56
93.37
92.84
93.06
92.16
91.25"
OPTIMIZED SEPARABLE CONVOLUTION,0.32587064676616917,"o-ResNet32
89.82
92.31
92.8
93.69
93.65
93.03
93.07
92.49"
OPTIMIZED SEPARABLE CONVOLUTION,0.3283582089552239,"o-ResNet56
89.88
92.71
92.88
93.81
93.8
93.49
92.73
93.03"
OPTIMIZED SEPARABLE CONVOLUTION,0.3308457711442786,"o-ResNet110
90.26
94.04
94.85
94.88
94.83
94.41
93.95
93.39"
OPTIMIZED SEPARABLE CONVOLUTION,0.3333333333333333,"Furthermore, if the number of separated convolutions N can be optimized, we will have
N = log(γCK2)
(21)
and
min f({n∗}, {KH|W
∗
}) = O(C · log(γCK2)).
(22)"
OPTIMIZED SEPARABLE CONVOLUTION,0.3358208955223881,"In Theorem 1, we keep both notations gl and nl. This is because, for the channel condition, it is
intuitive to see n1 · · · nN ≥C1 means that the product of n1 · · · nN needs to occupy each node in
the input channel C1 = Cin. This is equivalent to the less intuitive condition g1 · · · gN ≤C2 · · · CN.
Similarly, for the group convolution condition, gl ≤min(Cl, Cl+1) means the number of groups can
not exceed the input and output channels of this group convolution, while nl ≥max(1, Cl+1"
OPTIMIZED SEPARABLE CONVOLUTION,0.3383084577114428,"Cl ) is less
intuitive. A sketch of proof of Theorem 1 is given in Appendix A."
OPTIMIZED SEPARABLE CONVOLUTION,0.3407960199004975,"Equations (18) and (19) mean that one of the internal kernel sizes should take KH or KW and
the remaining ones take 1. Hence, the proposed optimized separable convolution shall have a spatial
separable conﬁguration: a single kernel takes (KH, KW ) or two kernels take (KH, 1) and (1, KW ).
The implementation details of the proposed optimized separable convolution scheme is described in
Algorithm 1 (Appendix B). Finally, the proposed optimized separable convolution is sparse con-
nected. The hyperparameters of each separated convolution are given by Equations (17)-(19) and
the proposed scheme can be efﬁciently implemented using a channel shufﬂe operation (Fig. 1b)."
EXPERIMENTAL RESULTS,0.34328358208955223,"3
EXPERIMENTAL RESULTS"
EXPERIMENTAL RESULTS,0.34577114427860695,"In this section, we carry out extensive experiments on benchmark datasets to demonstrate the effec-
tiveness of the proposed optimized separable convolution scheme. In the proposed experiments, we
use a preﬁx dw-, d-, s-, o- or so- to indicate that the conventional or depth separable convolutions
in the baseline networks are replaced with depth-wise, depth separable (dsep), spatial separable,
the proposed optimized separable (osep), or the proposed spatial optimized separable convolutions.
In this research, we set the number of separated convolutions N = 2. The details of the training
settings for the proposed experiments are described in Appendix C."
EXPERIMENTAL RESULTS,0.3482587064676617,"3.1
EXPERIMENTAL RESULTS ON CIFAR10"
EXPERIMENTAL RESULTS,0.35074626865671643,"CIFAR10 (Krizhevsky et al., 2009) is a dataset consist of 50,000 training images and 10,000 testing
images. These images are with a resolution of 32 × 32 and are categorized into 10 object classes. In"
EXPERIMENTAL RESULTS,0.35323383084577115,Under review as a conference paper at ICLR 2022
EXPERIMENTAL RESULTS,0.35572139303482586,"the proposed experiments, we use ResNet (He et al., 2016) as baselines and replace the conventional
convolutions in ResNet with dsep and osep convolutions, resulting in d-ResNet and o-ResNet."
EXPERIMENTAL RESULTS,0.3582089552238806,"Table 3. Experimental results on CIFAR10 for DARTS. The pro-
posed optimized separable convolution (o-DARTS) generalizes well
to the DARTS architecture, and achieves improved accuracy with ap-
proximately the same FLOPs and fewer parameters. DARTS uses
depth separable convolution and an optional d- is preﬁxed."
EXPERIMENTAL RESULTS,0.36069651741293535,"Net Arch
#Params
FLOPs
Accuracy
Error Rate"
EXPERIMENTAL RESULTS,0.36318407960199006,"(million)
(billion)
(%)
(%)"
EXPERIMENTAL RESULTS,0.3656716417910448,"(d-)DARTS (Liu et al., 2018)
3.35
0.528
97.24%
2.76%"
EXPERIMENTAL RESULTS,0.3681592039800995,"o-DARTS
3.25
0.572
97.67%
2.33%"
EXPERIMENTAL RESULTS,0.3706467661691542,"P-DARTS (Chen et al., 2019)
3.43
0.532
97.50%
2.50%"
EXPERIMENTAL RESULTS,0.373134328358209,"PC-DARTS (Xu et al., 2019)
3.63
0.557
97.43%
2.57%"
EXPERIMENTAL RESULTS,0.3756218905472637,"GOLD-DARTS (Bi et al., 2020)
3.67
0.546
97.47%
2.53%"
EXPERIMENTAL RESULTS,0.3781094527363184,"The proposed osep scheme can
signiﬁcantly reduce the representa-
tional complexity. In Section 2, we
state that this reduction factor can
be
√"
EXPERIMENTAL RESULTS,0.3805970149253731,"CK in theory3. As illustrated
by the solid lines in Fig. 3(a), the
orange solid curve lies in a region
with signiﬁcantly smaller x-values
than the blue solid curve. This indi-
cates that o-ResNet shall have sig-
niﬁcantly less parameters than the
ResNet baseline. For example, the
110-layered o-ResNet110 has even
fewer parameters (0.180 million vs
0.270 million) than the 20-layered ResNet20, yet with noticeable higher accuracy (92.15% vs
91.25%). This demonstrates that the proposed osep scheme could signiﬁcantly reduce the repre-
sentational complexity for convolutions. For dsep, this reduction factor is
1
1/K2+1/C , which is
bounded by K2. For 3 × 3 kernels, this reduction can be at most 9. Whereas for the proposed osep
scheme, no such bounds exist. The advantage of the proposed osep scheme over dsep is illustrated
in Fig. 3(a) by the orange and green solid curves. From this, we can see the proposed osep scheme
is more efﬁcient with smaller x-values. We further plot accuracy-FLOPs curves in Fig. 3(b) for
reference, where similar conclusions can be drawn."
EXPERIMENTAL RESULTS,0.38308457711442784,"The proposed o-ResNets can have 10x-18x fewer parameters than the ResNet baselines in the pro-
posed experiments. For fair comparisons, we introduce the channel multiplier in order to approxi-
mately match the #Params (or FLOPs)4. We use the sufﬁx “ m<multiplier>” to indicate the
channel multiplier. As illustrated in Fig. 3(a), from which we can see, the proposed osep scheme
is much more efﬁcient than conventional convolutions. The orange curve, including both solid and
dashed parts, achieved a better accuracy-#Params Pareto-frontier than the blue curve. Such repre-
sentation efﬁciency could result in a more regularized network with fewer parameters to prevent
over-ﬁtting and possibly contribute to the ﬁnal performance. In Fig. 3(a), we also present the d-
ResNet curves in dashed green by replacing the conventional convolutions with dsep convolutions.
As can be seen, d-ResNet achieves good accuracy-#Params balances for small networks (e.g. d-
ResNet20 and d-ResNet32), but performs comparable or no better than conventional convolutions
for large ones (e.g. d-ResNet56 and d-ResNet110). In summary, the proposed osep scheme achieves
better accuracy-#Params (and also accuracy-FLOPs as illustrated in Fig. 3(b)) Pareto-frontiers than
both conventional and dsep convolutions."
EXPERIMENTAL RESULTS,0.3855721393034826,"Other Conv2D Types: Besides conventional and depth separable (d-) convolutions, we compare
the proposed osep (o-) scheme against the other convolution types, including depth-wise (dw-) and
spatial separable (s-) convolutions. In the following, we shall omit the sufﬁx of channel multiplier
for simplicity, which shall be clear from the context. From Algorithm 1 (Appendix B), the proposed
osep scheme also has a spatial separable (so-) variant. A comparison of all these convolutions for
the ResNet architecture is illustrated Fig. 3(c). From this ﬁgure, we can conclude that the proposed
osep scheme is more efﬁcient than all other alternatives (the orange bar is highest)."
EXPERIMENTAL RESULTS,0.3880597014925373,"Channel Information Fusion: We discuss more about dw-ResNet in Fig. 3(c). Recall from Table 1
that a depth separable convolution is a depth-wise convolution followed by a pointwise convolution.
dw-ResNet allows no channel information exchange while d-ResNet does. Fig. 3(c) demonstrates
that dw-ResNet performs much worse than d-ResNet. In fact, dw-ResNet is the only one that does
not maintain the volumetric RF and performs worst of all these six convolution schemes. This"
EXPERIMENTAL RESULTS,0.39054726368159204,"3For optimized separable,
√"
EXPERIMENTAL RESULTS,0.39303482587064675,"CK =
C2K2"
EXPERIMENTAL RESULTS,0.39552238805970147,"C3/2K . For depth separable,
1
1/K2+1/C =
C2K2"
EXPERIMENTAL RESULTS,0.39800995024875624,"C(C+K2) < K2.
4We match both #Params and FLOPs here. If this is not allowed, we approximately match for one and make
sure the other not to exceed. In Appendix D, we present experimental results of matching #Params only in Fig.
5 and Fig. 6. The conclusions we reached in this Section is the same."
EXPERIMENTAL RESULTS,0.40049751243781095,Under review as a conference paper at ICLR 2022
EXPERIMENTAL RESULTS,0.40298507462686567,"0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
#Params (million) 62 64 66 68 70 72 74 76"
EXPERIMENTAL RESULTS,0.4054726368159204,Top1 (%) r20 r32 r56 r110 r20 r32 r56
EXPERIMENTAL RESULTS,0.4079601990049751,"r110
r110"
EXPERIMENTAL RESULTS,0.41044776119402987,"r20_m2.72
r32_m2.75
r56_m2.75"
EXPERIMENTAL RESULTS,0.4129353233830846,r110_m2.75 r20 r32 r56
EXPERIMENTAL RESULTS,0.4154228855721393,"r110
r110"
EXPERIMENTAL RESULTS,0.417910447761194,"r20_m3.625
r32_m3.75"
EXPERIMENTAL RESULTS,0.42039800995024873,r56_m3.875
EXPERIMENTAL RESULTS,0.4228855721393035,r110_m3.875
EXPERIMENTAL RESULTS,0.4253731343283582,"ResNet (baseline)
d-ResNet"
EXPERIMENTAL RESULTS,0.42786069651741293,d-ResNet (w/ multiplier)
EXPERIMENTAL RESULTS,0.43034825870646765,"o-ResNet
o-ResNet (w/ multiplier) (a)"
EXPERIMENTAL RESULTS,0.43283582089552236,"0.00
0.05
0.10
0.15
0.20
0.25
FLOPs (billion) 62 64 66 68 70 72 74 76"
EXPERIMENTAL RESULTS,0.43532338308457713,Top1 (%)
EXPERIMENTAL RESULTS,0.43781094527363185,"r20
r32 r56 r110 r20 r32 r56"
EXPERIMENTAL RESULTS,0.44029850746268656,"r110
r110"
EXPERIMENTAL RESULTS,0.4427860696517413,"r20_m2.72
r32_m2.75
r56_m2.75"
EXPERIMENTAL RESULTS,0.44527363184079605,r110_m2.75 r20 r32 r56
EXPERIMENTAL RESULTS,0.44776119402985076,"r110
r110"
EXPERIMENTAL RESULTS,0.4502487562189055,"r20_m3.625
r32_m3.75
r56_m3.875"
EXPERIMENTAL RESULTS,0.4527363184079602,r110_m3.875
EXPERIMENTAL RESULTS,0.4552238805970149,"ResNet (baseline)
d-ResNet"
EXPERIMENTAL RESULTS,0.4577114427860697,d-ResNet (w/ multiplier)
EXPERIMENTAL RESULTS,0.4601990049751244,"o-ResNet
o-ResNet (w/ multiplier) (b)"
EXPERIMENTAL RESULTS,0.4626865671641791,"ResNet20
ResNet32
ResNet56
ResNet110
64 66 68 70 72 74 76 78 80"
EXPERIMENTAL RESULTS,0.4651741293532338,"Conventional (baseline)
Depthwise (dw-)"
EXPERIMENTAL RESULTS,0.46766169154228854,Depth Separable (d-)
EXPERIMENTAL RESULTS,0.4701492537313433,Spatial Separable (s-)
EXPERIMENTAL RESULTS,0.472636815920398,Optimal Separable (o-)
EXPERIMENTAL RESULTS,0.47512437810945274,Spatial Optimal Separable (so-)
EXPERIMENTAL RESULTS,0.47761194029850745,"(c)
Figure 4. Experimental results on CIFAR100 for the ResNet architecture (best viewed in color). The proposed
optimized separable convolution (o-ResNet) achieves improved (a) accuracy-#Params and (b) accuracy-FLOPs
Pareto-frontiers than both the conventional (ResNet) and depth separable (d-ResNet) convolutions. (c) A com-
parison for performances of different convolution schemes."
EXPERIMENTAL RESULTS,0.48009950248756217,"Table 4. Experimental results on CIFAR100 for different overlap coefﬁcients (γ). If γ ≥1, the volumetric RF
is maintained, otherwise it is not. Each row of o-ResNet is channel multiplied. When γ < 1, the performance
hurts due to discourage of channel information fusion."
EXPERIMENTAL RESULTS,0.48258706467661694,"Overlap Coef. (γ)
ε (Depthwise)
1/16
1/4
1
4
16
64
+∞(Conventional)"
EXPERIMENTAL RESULTS,0.48507462686567165,"Vol. RF







"
EXPERIMENTAL RESULTS,0.48756218905472637,"o-ResNet20
65.46
68.24
70.96
71.03
71.12
70.8
70.08
67.38"
EXPERIMENTAL RESULTS,0.4900497512437811,"o-ResNet32
66.42
70.59
71.05
72.75
70.89
71.91
70.76
68.21"
EXPERIMENTAL RESULTS,0.4925373134328358,"o-ResNet56
65.39
69.23
69.87
73.55
72.4
71.98
70.98
69.34"
EXPERIMENTAL RESULTS,0.49502487562189057,"o-ResNet110
65.98
73.30
74.00
75.48
74.74
73.62
73.01
71.68"
EXPERIMENTAL RESULTS,0.4975124378109453,"suggests that channel information fusion could be critical for the good performance of a DCNN, and
hence validates our proposed volumetric receptive ﬁeld condition."
EXPERIMENTAL RESULTS,0.5,"Overlap Coefﬁcient: We carry out an ablation study on the overlap coefﬁcient γ. For γ ≥1, the
volumetric RF is maintained, otherwise, it is not. From Table 2, we can see that, a good-performing
γ takes values 1 ≤γ ≤4 and γ = 1 achieves the best. It is reasonable to conjecture that, for γ < 1,
the volumetric RF is not maintained and the channel information fusion is compromised, leading to
bad performance. For γ > 4, the representation efﬁciency is also slightly lower. We argue that this
is because the channel information has already been fused sufﬁciently. For larger γ, more overlap
introduces more cost yet no additional fusion, hence the efﬁciency has been degraded accordingly.
In Table 2, we also include the results for dw-ResNet and ResNet, as they can be roughly viewed
as the limit cases of γ to be inﬁnitely small (ε) or inﬁnitely large (+∞). The ablation study on the
overlap coefﬁcient in Table 2 clearly demonstrates that we should satisfy the proposed volumetric
RF condition."
EXPERIMENTAL RESULTS,0.5024875621890548,"Generalization to DARTS: To demonstrate that the proposed osep scheme generalizes well to
other DCNN architectures, we adopt the DARTS (V2) (Liu et al., 2018) network as the baseline.
The DARTS evaluation network has 20 cells and 36 initial channels, we increase the initial channels
to 42 to match the FLOPs. By replacing the dsep convolutions in DARTS with the proposed osep
convolutions, as illustrated in Table 3, the resulting o-DARTS improved the accuracy from 97.24%
to 97.67%, but with fewer parameters (3.25 million vs 3.35 million). It is worth noting that it is very
hard to signiﬁcantly improve the DARTS search space. In Table 3, we also include three variants of
DARTS, i.e. P-DARTS (Chen et al., 2019), PC-DARTS (Xu et al., 2019), and GOLD-DARTS (Bi
et al., 2020), with more advanced search strategies for comparison. As can be seen, o-DARTS can
achieve even higher accuracies than these advanced network architectures."
EXPERIMENTAL RESULTS,0.5049751243781094,"3.2
EXPERIMENTAL RESULTS ON CIFAR100"
EXPERIMENTAL RESULTS,0.5074626865671642,"CIFAR100 (Krizhevsky et al., 2009) is a dataset consist of 50,000 training images and 10,000 testing
images. These images are with a resolution of 32×32 and are categorized into 100 object classes. We
carry out similar experiments on CIFAR100 as those on CIFAR10, from which similar conclusions
can be drawn."
EXPERIMENTAL RESULTS,0.5099502487562189,"From Fig. 4(a) and (b), we can conclude that the proposed optimized separable convolution scheme
achieves better accuracy-#Params and accuracy-FLOPs Pareto-frontiers than both conventional and
depth separable convolutions. From Fig. 4(c), we can see that the proposed osep scheme is more"
EXPERIMENTAL RESULTS,0.5124378109452736,Under review as a conference paper at ICLR 2022
EXPERIMENTAL RESULTS,0.5149253731343284,"efﬁcient than the other alternative Conv2D types, including depth-wise, spatial separable, and the
proposed spatial optimized separable convolutions. In Fig. 4(c), dw-ResNet is the only one that
does not maintain the volumetric RF and performs signiﬁcantly worse than the other counterparts.
In Table 4, the experimental results indicate the best overlap coefﬁcient takes value γ = 1. These
latter two observations also demonstrate the validity of the proposed volumetric RF condition."
EXPERIMENTAL RESULTS ON IMAGENET,0.5174129353233831,"3.3
EXPERIMENTAL RESULTS ON IMAGENET"
EXPERIMENTAL RESULTS ON IMAGENET,0.5199004975124378,"Table 5. Experimental results on full ImageNet for the DARTS ar-
chitecture. The proposed o-DARTS achieves 74.2% top1 accuracy
with only 4.5 million parameters and the proposed o-MobileNet
achieves 70.8% top1 accuracy with only 3.0 million parameters."
EXPERIMENTAL RESULTS ON IMAGENET,0.5223880597014925,"Net Arch
#Params
FLOPs
Top1
Top1 Error
(million)
(billion)
(%)
(%)"
EXPERIMENTAL RESULTS ON IMAGENET,0.5248756218905473,"(d-)DARTS (Liu et al., 2018)
4.72
0.530
73.3%
26.7%"
EXPERIMENTAL RESULTS ON IMAGENET,0.527363184079602,"o-DARTS
4.50
0.554
74.2%
25.8%"
EXPERIMENTAL RESULTS ON IMAGENET,0.5298507462686567,"(d-)MobileNet (Howard, 2017)
4.20
0.575
70.6%
29.4%"
EXPERIMENTAL RESULTS ON IMAGENET,0.5323383084577115,"o-MobileNet
3.00
0.564
71.1%
28.9%"
EXPERIMENTAL RESULTS ON IMAGENET,0.5348258706467661,"We evaluate the proposed optimized
separable convolution scheme on the
benchmark ImageNet (Deng et al.,
2009) dataset, which contains 1.28
million training images and 50,000
testing images."
EXPERIMENTAL RESULTS ON IMAGENET,0.5373134328358209,"3.3.1
IMAGENET40"
EXPERIMENTAL RESULTS ON IMAGENET,0.5398009950248757,"Because carrying out experiments di-
rectly on the ImageNet dataset can
be resource- and time-consuming, we
resized all the images into 40 × 40 pixels. Due to space limitations, we present the experimental
results on ImageNet40 in Appendix F and Table 7. We can conclude that the proposed o-ResNet
achieved 4-5% (e.g. 49.97% vs 44.93% for 56-layer and 50.72% vs 46.74% for 110-layer) perfor-
mance gains comparing against the ResNet baselines."
FULL IMAGENET,0.5422885572139303,"3.3.2
FULL IMAGENET"
FULL IMAGENET,0.5447761194029851,"Similar to the experiments on CIFAR10, we replace the dsep convolutions in the DARTS (V2)
network with the proposed osep convolutions to demonstrate that the proposed approach is able to
generalize to other network architectures. The experiment is carried out on the full ImageNet dataset.
The DARTS evaluation network has 14 cells and 48 initial channels, we increase the initial channel
size to 56 to match the original neural net. The resulting network is called o-DARTS. Experimental
results are illustrated in Table 5. It can be seen that, with fewer parameters (4.50 million vs 4.72
million), the proposed o-DARTS network achieved higher accuracies in both top1 (74.2% vs 73.3%)
and top5 (91.9% vs 91.3%) accuracies than the DARTS baseline. Finally, we replace the dsep
convolution in MobileNet (Howard et al., 2017) to the proposed osep convolution. Using only
3.0 million parameters, the proposed o-MobileNet is able to achieve 71.1% top1 accuracy on the
ImageNet dataset. This is a great gain comparing against the original MobileNet with 4.2 million
parameters. We can conclude that the proposed osep is able to achieve better accuracy-FLOPs and
accuracy-#Params balances than dsep convolutions."
CONCLUSIONS,0.5472636815920398,"4
CONCLUSIONS"
CONCLUSIONS,0.5497512437810945,"In this paper, we have presented yet another novel convolution scheme called optimized separable
convolution to improve efﬁciency. Conventional convolution took a costly complexity at O(C2K2).
The proposed optimized separable convolution scheme is able to achieve its complexity at O(C
3
2 K),
which is even lower than that of depth separable convolution at O(C · (C + K2)). Hence, the pro-
posed optimized separable convolution has the full potential to replace the usage of depth separable
convolutions in a DCNN. Examples considered include ResNet, DARTS, and MobileNet architec-
tures. The proposed optimized separable convolution also has a spatial separable conﬁguration. A
generalized N-separable case can achieve better performance at O(C · log(CK2))."
CONCLUSIONS,0.5522388059701493,"We believe the proposed optimized separable convolution also has a potential impact on the AutoML
community. The proposed novel operator is able to increase the neural architecture search space.
In a multi-objective optimization formulation, where both accuracy and #Params (or FLOPs) are
optimized, we expect a more efﬁcient network architecture can be discovered in the future using
the proposed optimized separable convolution operator. In the future, we also expect to carry out
experiments on more neural network architectures, e.g. EfﬁcientNet, etc."
CONCLUSIONS,0.554726368159204,Under review as a conference paper at ICLR 2022
REFERENCES,0.5572139303482587,REFERENCES
REFERENCES,0.5597014925373134,"Kaifeng Bi, Lingxi Xie, Xin Chen, Longhui Wei, and Qi Tian. Gold-nas: Gradual, one-level, differ-
entiable. arXiv preprint arXiv:2007.03331, 2020. 3, 3.1"
REFERENCES,0.5621890547263682,"Xin Chen, Lingxi Xie, Jun Wu, and Qi Tian. Progressive differentiable architecture search: Bridging
the depth gap between search and evaluation. In Proceedings of the IEEE International Confer-
ence on Computer Vision, pp. 1294–1303, 2019. 3, 3.1, C"
REFERENCES,0.5646766169154229,"Matthieu Courbariaux, Itay Hubara, Daniel Soudry, Ran El-Yaniv, and Yoshua Bengio. Binarized
neural networks: Training deep neural networks with weights and activations constrained to+ 1
or-1. arXiv preprint arXiv:1602.02830, 2016. 1, G"
REFERENCES,0.5671641791044776,"Xiaoliang Dai, Alvin Wan, Peizhao Zhang, Bichen Wu, Zijian He, Zhen Wei, Kan Chen, Yuandong
Tian, Matthew Yu, Peter Vajda, et al. Fbnetv3: Joint architecture-recipe search using neural
acquisition function. arXiv preprint arXiv:2006.02049, 2020. 1"
REFERENCES,0.5696517412935324,"Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hi-
erarchical image database. In 2009 IEEE conference on computer vision and pattern recognition,
pp. 248–255. Ieee, 2009. 1, 3.3"
REFERENCES,0.572139303482587,"Yunchao Gong, Liu Liu, Ming Yang, and Lubomir Bourdev. Compressing deep convolutional net-
works using vector quantization. arXiv preprint arXiv:1412.6115, 2014. 1, G"
REFERENCES,0.5746268656716418,"Song Han, Jeff Pool, John Tran, and William J Dally. Learning both weights and connections for
efﬁcient neural networks. arXiv preprint arXiv:1506.02626, 2015. 1, G"
REFERENCES,0.5771144278606966,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.
770–778, 2016. 1, 1, 2.3, 3.1"
REFERENCES,0.5796019900497512,"Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. arXiv
preprint arXiv:1503.02531, 2015. 1, G"
REFERENCES,0.582089552238806,"Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing Tan, Weijun
Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, et al. Searching for mobilenetv3. In Pro-
ceedings of the IEEE International Conference on Computer Vision, pp. 1314–1324, 2019. G"
REFERENCES,0.5845771144278606,"Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand,
Marco Andreetto, and Hartwig Adam. Mobilenets: Efﬁcient convolutional neural networks for
mobile vision applications. arXiv preprint arXiv:1704.04861, 2017. 1, 3.3.2, G"
REFERENCES,0.5870646766169154,"Yani Ioannou, Duncan Robertson, Jamie Shotton, Roberto Cipolla, and Antonio Criminisi. Training
cnns with low-rank ﬁlters for efﬁcient image classiﬁcation. arXiv preprint arXiv:1511.06744,
2015. 1, G"
REFERENCES,0.5895522388059702,"Max Jaderberg, Andrea Vedaldi, and Andrew Zisserman. Speeding up convolutional neural networks
with low rank expansions. arXiv preprint arXiv:1405.3866, 2014. 1, G"
REFERENCES,0.5920398009950248,"Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.
2009. 1, 3.1, 3.2"
REFERENCES,0.5945273631840796,"Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classiﬁcation with deep convo-
lutional neural networks. In Advances in neural information processing systems, pp. 1097–1105,
2012. 1"
REFERENCES,0.5970149253731343,"Tony Lindeberg. A computational theory of visual receptive ﬁelds. Biological cybernetics, 107(6):
589–635, 2013. 1, 2.2"
REFERENCES,0.599502487562189,"Hanxiao Liu, Karen Simonyan, and Yiming Yang. Darts: Differentiable architecture search. arXiv
preprint arXiv:1806.09055, 2018. 1, 3, 3.1, 5, C, G"
REFERENCES,0.6019900497512438,"Ningning Ma, Xiangyu Zhang, Hai-Tao Zheng, and Jian Sun. Shufﬂenet v2: Practical guidelines for
efﬁcient cnn architecture design. In Proceedings of the European conference on computer vision
(ECCV), pp. 116–131, 2018. E"
REFERENCES,0.6044776119402985,Under review as a conference paper at ICLR 2022
REFERENCES,0.6069651741293532,"Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc V Le. Regularized evolution for image
classiﬁer architecture search. In Proceedings of the aaai conference on artiﬁcial intelligence,
volume 33, pp. 4780–4789, 2019. 1"
REFERENCES,0.6094527363184079,"Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. Mo-
bilenetv2: Inverted residuals and linear bottlenecks. In Proceedings of the IEEE conference on
computer vision and pattern recognition, pp. 4510–4520, 2018. 2.3, G"
REFERENCES,0.6119402985074627,"Laurent Sifre and St´ephane Mallat. Rigid-motion scattering for image classiﬁcation. Ph. D. thesis,
2014. 1"
REFERENCES,0.6144278606965174,"Rupesh K Srivastava, Klaus Greff, and J¨urgen Schmidhuber.
Training very deep networks.
In
Advances in neural information processing systems, pp. 2377–2385, 2015. 1"
REFERENCES,0.6169154228855721,"Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Du-
mitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In
Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1–9, 2015.
G"
REFERENCES,0.6194029850746269,"Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Rethink-
ing the inception architecture for computer vision. In Proceedings of the IEEE conference on
computer vision and pattern recognition, pp. 2818–2826, 2016. 1, G"
REFERENCES,0.6218905472636815,"Mingxing Tan and Quoc V Le. Efﬁcientnet: Rethinking model scaling for convolutional neural
networks. arXiv preprint arXiv:1905.11946, 2019. 1, G"
REFERENCES,0.6243781094527363,"Yuhui Xu, Lingxi Xie, Xiaopeng Zhang, Xin Chen, Guo-Jun Qi, Qi Tian, and Hongkai Xiong.
Pc-darts: Partial channel connections for memory-efﬁcient architecture search. In International
Conference on Learning Representations, 2019. 3, 3.1"
REFERENCES,0.6268656716417911,Under review as a conference paper at ICLR 2022
REFERENCES,0.6293532338308457,Algorithm 1 The Algorithm for Optimized Separable Convolution
REFERENCES,0.6318407960199005,"Input: Input channel C1 = Cin, output channel CN+1 = Cout, kernel size (KH, KW ), number of sepa-
rated convolutions N
Optional Input: internal kernel sizes (optional, preset), internal number of groups (optional, masked values),
spatial separable (True or False), overlap coefﬁcient (γ = 1).
Output: internal channel sizes C2, · · · , CN, internal kernel sizes KH|W
1
, · · · , KH|W
N
, internal number of
groups g1, · · · , gN
Calculate internal channel sizes C2, · · · , CN as min(Cin, Cout), max(Cin, Cout)/4, or 4 min(Cin, Cout),
etc. according to a preset policy.
if internal kernel sizes KH|W
1
, · · · , KH|W
N
are not given then
if spatial separable then"
REFERENCES,0.6343283582089553,"Set KH
⌊N/2⌋= KH, KW
⌊N/2+1⌋= KW and all other internal kernel sizes to 1.
else"
REFERENCES,0.6368159203980099,"Set KH|W
⌊N/2⌋= KH|W and all other internal kernel sizes to 1.
end if
end if"
REFERENCES,0.6393034825870647,Calculate internal channels per group nl according to nl = Nq
REFERENCES,0.6417910447761194,"γΠN+1
i=1 CiΠN
i=1KH
i ΠN
i=1KW
i
Cl+1KH
l KW
l
."
REFERENCES,0.6442786069651741,"Let gl = min(⌈Cl/nl⌉, Cl, Cl+1). If Cl/nl < 1 or Cl/nl > min(Cl, Cl+1) for certain l, re-optimize gl
with a masked number of groups by pre-setting gl = 1 for l ∈{l : Cl/nl < 1}, gl = min(Cl, Cl+1) for
l ∈{l : Cl/nl > min(Cl, Cl+1)}.
▷Because nl ∼
N√"
REFERENCES,0.6467661691542289,"C, for large channel sizes, we rarely need to re-optimize.
Return C2, · · · , CN; KH|W
1
, · · · , KH|W
N
; g1, · · · , gN"
REFERENCES,0.6492537313432836,"A
SKETCH OF PROOF FOR THEOREM 1"
REFERENCES,0.6517412935323383,"Sketch of Proof for Theorem 1. For Equation (12), after applying an arithmetic-geometric mean in-
equality, we can get"
REFERENCES,0.654228855721393,"f({n∗},{KH|W
∗
})≥N
N
r"
REFERENCES,0.6567164179104478,"C1C2
2 ···C2
N CN+1KH
1 ···KH
N KW
1
···KW
N
g1···gN
(23) ≥N N√"
REFERENCES,0.6592039800995025,"γC1···CN+1KH
1 ···KH
N KW
1 ···KW
N
(24)
The equality holds if and only if C2n1KH
1 KW
1
= · · · = CN+1nNKH
N KW
N . Let nl = βln1, where"
REFERENCES,0.6616915422885572,"βl =
C2KH
1 KW
1
Cl+1KH
l KW
l . Let β = Πβi, we can solve n1 =
Nq γC1 β
= N√"
REFERENCES,0.664179104477612,"γΠCiΠKH
i ΠKW
i
C2KH
1 KW
1
and nl = Nq"
REFERENCES,0.6666666666666666,"γΠN+1
i=1 CiΠN
i=1KH
i ΠN
i=1KW
i
Cl+1KH
l KW
l
∼
N√"
REFERENCES,0.6691542288557214,"C.
(25)"
REFERENCES,0.6716417910447762,"Note that the inequality (24) holds for arbitrary KH|W
∗
. We need to further optimize KH|W
∗
. Again,
from the arithmetic-geometric mean inequality again, we can get KH
1 · · · KH
N ≤( KH
1 +···+KH
N
N
)N =
( KH+N−1"
REFERENCES,0.6741293532338308,"N
)Nand the equality holds if and only if KH
1
= · · · = KH
N = KH+N−1"
REFERENCES,0.6766169154228856,"N
. However, we
want the inequality reversed, instead of ﬁnding the maximum of this product, we expect to ﬁnd its
minimum. This still gives us a hint, the maximum is achieved when the internal kernel sizes are as
even as possible, so the minimum should be achieved when the internal kernel sizes are as diverse as
possible. In the extreme case, one of the internal kernel sizes should take KHand all the rest takes
1, i.e. Equations (18) and (19). A formal proof of this claim can be derived. Hence, we have
f({n∗}, {KH|W
∗
}) ≥N
Np"
REFERENCES,0.6791044776119403,"γC1 · · · CN+1KHKW
(26)"
REFERENCES,0.681592039800995,"= O(Nγ
1
N C1+ 1"
REFERENCES,0.6840796019900498,"N K
2
N ).
(27)"
REFERENCES,0.6865671641791045,"By setting f ′(N) = 0, we can derive that
N = log(γCK2),
(28)
and
min f({n∗}, {KH|W
∗
}) = eCHW · log(γCK2)
(29)"
REFERENCES,0.6890547263681592,"= O(CHW · log(γCK2)),
(30)
where e = 2.71828... is the natural logarithm constant."
REFERENCES,0.6915422885572139,Under review as a conference paper at ICLR 2022
REFERENCES,0.6940298507462687,"0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
#Params (million) 89 90 91 92 93 94"
REFERENCES,0.6965174129353234,Top1 (%) r20 r32 r56 r110 r20 r32 r56
REFERENCES,0.6990049751243781,"r110
r110"
REFERENCES,0.7014925373134329,"r20_m2.75
r32_m2.80"
REFERENCES,0.7039800995024875,r56_m2.85
REFERENCES,0.7064676616915423,r110_m2.85 r20 r32 r56
REFERENCES,0.7089552238805971,"r110
r110"
REFERENCES,0.7114427860696517,r20_m4.125
REFERENCES,0.7139303482587065,r32_m4.375
REFERENCES,0.7164179104477612,r56_m4.5
REFERENCES,0.7189054726368159,r110_m4.625
REFERENCES,0.7213930348258707,"ResNet (baseline)
d-ResNet"
REFERENCES,0.7238805970149254,d-ResNet (w/ multiplier)
REFERENCES,0.7263681592039801,"o-ResNet
o-ResNet (w/ multiplier) (a)"
REFERENCES,0.7288557213930348,"0.00
0.05
0.10
0.15
0.20
0.25
0.30
FLOPs (billion) 89 90 91 92 93 94"
REFERENCES,0.7313432835820896,Top1 (%) r20 r32
REFERENCES,0.7338308457711443,"r56
r110 r20 r32 r56"
REFERENCES,0.736318407960199,"r110
r110"
REFERENCES,0.7388059701492538,"r20_m2.75
r32_m2.80"
REFERENCES,0.7412935323383084,r56_m2.85
REFERENCES,0.7437810945273632,r110_m2.85 r20 r32 r56
REFERENCES,0.746268656716418,"r110
r110"
REFERENCES,0.7487562189054726,r20_m4.125
REFERENCES,0.7512437810945274,r32_m4.375
REFERENCES,0.753731343283582,r56_m4.5
REFERENCES,0.7562189054726368,r110_m4.625
REFERENCES,0.7587064676616916,"ResNet (baseline)
d-ResNet"
REFERENCES,0.7611940298507462,d-ResNet (w/ multiplier)
REFERENCES,0.763681592039801,"o-ResNet
o-ResNet (w/ multiplier) (b)"
REFERENCES,0.7661691542288557,"ResNet20
ResNet32
ResNet56
ResNet110
88 89 90 91 92 93 94 95 96 97"
REFERENCES,0.7686567164179104,"Conventional (baseline)
Depthwise (dw-)"
REFERENCES,0.7711442786069652,Depth Separable (d-)
REFERENCES,0.7736318407960199,Spatial Separable (s-)
REFERENCES,0.7761194029850746,Optimal Separable (o-)
REFERENCES,0.7786069651741293,Spatial Optimal Separable (so-)
REFERENCES,0.7810945273631841,"(c)
Figure 5. Experimental results on CIFAR10 for the ResNet architecture (best viewed in color, same as Fig.
3 except networks are channel multiplied to match #Params). The proposed optimized separable convolution
(o-ResNet) achieves improved (a) accuracy-#Params and (b) accuracy-FLOPs Pareto-frontiers than both the
conventional (ResNet) and depth separable (d-ResNet) convolutions. (c) A comparison for performances of
different convolution schemes."
REFERENCES,0.7835820895522388,"0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
#Params (million) 62 64 66 68 70 72 74 76"
REFERENCES,0.7860696517412935,Top1 (%)
REFERENCES,0.7885572139303483,"r20
r32 r56 r110 r20 r32 r56"
REFERENCES,0.7910447761194029,"r110
r110"
REFERENCES,0.7935323383084577,r20_m2.75
REFERENCES,0.7960199004975125,r32_m2.80
REFERENCES,0.7985074626865671,r56_m2.85
REFERENCES,0.8009950248756219,r110_m2.85 r20 r32 r56
REFERENCES,0.8034825870646766,"r110
r110"
REFERENCES,0.8059701492537313,r20_m4.125
REFERENCES,0.8084577114427861,"r32_m4.375
r56_m4.5"
REFERENCES,0.8109452736318408,r110_m4.625
REFERENCES,0.8134328358208955,"ResNet (baseline)
d-ResNet"
REFERENCES,0.8159203980099502,d-ResNet (w/ multiplier)
REFERENCES,0.818407960199005,"o-ResNet
o-ResNet (w/ multiplier) (a)"
REFERENCES,0.8208955223880597,"0.00
0.05
0.10
0.15
0.20
0.25
0.30
FLOPs (billion) 62 64 66 68 70 72 74 76"
REFERENCES,0.8233830845771144,Top1 (%)
REFERENCES,0.8258706467661692,"r20
r32 r56 r110 r20 r32 r56"
REFERENCES,0.8283582089552238,"r110
r110"
REFERENCES,0.8308457711442786,r20_m2.75
REFERENCES,0.8333333333333334,r32_m2.80
REFERENCES,0.835820895522388,r56_m2.85
REFERENCES,0.8383084577114428,r110_m2.85 r20 r32 r56
REFERENCES,0.8407960199004975,"r110
r110"
REFERENCES,0.8432835820895522,r20_m4.125
REFERENCES,0.845771144278607,"r32_m4.375
r56_m4.5"
REFERENCES,0.8482587064676617,r110_m4.625
REFERENCES,0.8507462686567164,"ResNet (baseline)
d-ResNet"
REFERENCES,0.8532338308457711,d-ResNet (w/ multiplier)
REFERENCES,0.8557213930348259,"o-ResNet
o-ResNet (w/ multiplier) (b)"
REFERENCES,0.8582089552238806,"ResNet20
ResNet32
ResNet56
ResNet110
64 66 68 70 72 74 76 78 80"
REFERENCES,0.8606965174129353,"Conventional (baseline)
Depthwise (dw-)"
REFERENCES,0.8631840796019901,Depth Separable (d-)
REFERENCES,0.8656716417910447,Spatial Separable (s-)
REFERENCES,0.8681592039800995,Optimal Separable (o-)
REFERENCES,0.8706467661691543,Spatial Optimal Separable (so-)
REFERENCES,0.8731343283582089,"(c)
Figure 6. Experimental results on CIFAR100 for the ResNet architecture (best viewed in color, same as Fig.
4 except networks are channel multiplied to match #Params). The proposed optimized separable convolution
(o-ResNet) achieves improved (a) accuracy-#Params and (b) accuracy-FLOPs Pareto-frontiers than both the
conventional (ResNet) and depth separable (d-ResNet) convolutions. (c) A comparison for performances of
different convolution schemes."
REFERENCES,0.8756218905472637,"B
THE PROPOSED OPTIMIZED SEPARABLE CONVOLUTION ALGORITHM"
REFERENCES,0.8781094527363185,"A detailed implementation of the proposed optimized separable convolution algorithm is illustration
in Algorithm 1."
REFERENCES,0.8805970149253731,"C
TRAINING SETTINGS"
REFERENCES,0.8830845771144279,"Experiments on CIFAR10 and CIFAR100 for the ResNet architecture
The images are padded
with 4 pixels and randomly cropped into 32 × 32 to feed into the network. A random horizontal ﬂip
with a probability of 0.5 is also applied. All the networks are trained with a standard SGD optimizer
for 200 epochs. The initial learning rate is set to 0.1, with a decay of 0.1 at the 100 and 150 epochs.
The batch size is 128. A weight decay of 0.0001 and a momentum of 0.9 are used."
REFERENCES,0.8855721393034826,"Experiments on CIFAR10 for the DARTS architecture
We follow the same training settings in
(Liu et al., 2018): the network is trained with a standard SGD optimizer for 600 epochs with a batch
size of 96. The initial learning rate is set to 0.025 with a cosine learning rate scheduler. A weight
decay of 0.0003 and a momentum of 0.9 are used. Additional enhancements include cutout, path
dropout of probability 0.2, and auxiliary towers with weight 0.4."
REFERENCES,0.8880597014925373,"Experiments on ImageNet40 for the ResNet architecture
Each network is trained with a stan-
dard SGD optimizer for 20 epochs with the initial learning rate set to 0.1, and a decay of 0.1 at the
10 and 15 epochs. The batch size is 256, the weight decay is 0.0001 and the momentum is 0.9."
REFERENCES,0.8905472636815921,"Experiments on full ImageNet for the DARTS architecture
We follow the training settings in
(Chen et al., 2019) for multi-GPU training: the images are random resized crop into 224 × 224"
REFERENCES,0.8930348258706468,Under review as a conference paper at ICLR 2022
REFERENCES,0.8955223880597015,"Table 6. Experimental results on CIFAR10 for the ResNet with inference time on a Windows 10 Intel i5-8250
CPU or Nvidia GeForce RTX 2080 Ti GPU."
REFERENCES,0.8980099502487562,"Net Arch
Channel
#Params
FLOPs
Accuracy
CPU Infer
GPU Infer
Multiplier
(million)
(billion)
(%)
Time (s)
Time (s)"
REFERENCES,0.900497512437811,"ResNet20
-
0.270
0.04055
91.25
0.0310
0.0057"
REFERENCES,0.9029850746268657,"o-ResNet20
3.625
0.221
0.04070
93.37
0.0468
0.0120"
REFERENCES,0.9054726368159204,"d-ResNet20
2.72
0.250
0.0400
92.66
0.0468
0.0060"
REFERENCES,0.9079601990049752,"ResNet32
-
0.464
0.06886
92.49
0.0469
0.0067"
REFERENCES,0.9104477611940298,"o-ResNet32
3.75
0.367
0.06726
93.69
0.0937
0.0185"
REFERENCES,0.9129353233830846,"d-ResNet32
2.75
0.429
0.06565
92.98
0.1154
0.0092"
REFERENCES,0.9154228855721394,"ResNet56
-
0.853
0.12548
93.03
0.0938
0.0101"
REFERENCES,0.917910447761194,"o-ResNet56
3.875
0.682
0.12574
93.81
0.1562
0.0330"
REFERENCES,0.9203980099502488,"d-ResNet56
2.75
0.786
0.11890
92.69
0.1875
0.0181"
REFERENCES,0.9228855721393034,"ResNet110
-
1.728
0.25289
93.39
0.1563
0.0178"
REFERENCES,0.9253731343283582,"o-ResNet110
3.875
1.337
0.24763
94.88
0.3216
0.0671"
REFERENCES,0.927860696517413,"d-ResNet110
2.75
1.590
0.23870
93.40
0.3462
0.0317"
REFERENCES,0.9303482587064676,"patches with a random scale in [0.08, 1.0] and a random aspect ratio in [0.75, 1.33]. Random
horizontal ﬂip and color jitter are also applied. The network is trained from scratch for 250 epochs
with batch size 1024 on 8 GPUs. An SGD optimizer with an initial learning rate of 0.5, a momentum
of 0.9, and a weight decay of 3e-5. The learning rate is decayed linearly after each epoch. Additional
enhancements include label smoothing with weight 0.1 and auxiliary towers with weight 0.4."
REFERENCES,0.9328358208955224,"Experiments on full ImageNet for the MobileNet architecture
The images are random resized
crop into 224 × 224 patches with a random scale in [0.08, 1.0] and a random aspect ratio in [0.75,
1.33]. Random horizontal ﬂip is also applied (no color jitter). The network is trained from scratch
for 200 epochs with batch size 1024 on 8 GPUs. An SGD optimizer with an initial learning rate of
0.064, a momentum of 0.9, and a weight decay of 1e-5. The learning rate is decayed with a rate of
0.973 for every 0.8 epoch."
REFERENCES,0.9353233830845771,"D
EXPERIMENTAL RESULTS FOR MATCHING #PARAMS"
REFERENCES,0.9378109452736318,"In this section, we report experimental results of matching #Params only, instead of matching both
#Params and FLOPs. In Fig. 5 and Fig. 6, we illustrate the experimental results on CIFAR10
and CIFAR100 for the ResNet architecture. As can be seen, the observations in these two ﬁgures
are consistent with those in Fig. 3 and Fig. 4. Hence, the conclusions we reached in Section 3.1
and Section 3.2 are not affected. Please refer to these two sections for a detailed description of the
experimental results."
REFERENCES,0.9402985074626866,"E
INFERENCE TIME FOR THE PROPOSED OPTIMIZED SEPARABLE
CONVOLUTION"
REFERENCES,0.9427860696517413,"In this research, we focus on the representational efﬁciency of the proposed optimized separable
scheme. The representational complexity is measured with the number of parameters (#Params) and
is hardware-independent. For the proposed experiments, we included both #Params and FLOPs. In
this section, we further report the wall-clock inference time of the proposed optimized separable
convolution scheme for reference reasons. It is important to keep in mind that FLOPs measures the
theoretical speed we are able to achieve. The wall-clock time reported in this section is hardware
dependent. Slowness can occur due to an inefﬁcient hardware implementation."
REFERENCES,0.945273631840796,"From Table 6, we can see that, under approximately the same FLOPs, both o-ResNet and d-ResNet
take a longer inference time than conventional ResNet. This is because the current implementation
of grouped convolution in PyTorch is not optimized. From Table 6, we can also conclude that, under
approximately the same FLOPs, o-ResNet is slightly faster than d-ResNet (e.g. o-ResNet32 takes
0.0937s while d-ResNet32 takes 0.1154s) on a CPU and yet the former is about twice slower than
the latter (e.g. o-ResNet32 takes 0.0185s while d-ResNet32 takes 0.0092s) on a GPU. The better
wall-clock timing of the proposed osep scheme over dsep on a CPU may suggest that it also has"
REFERENCES,0.9477611940298507,Under review as a conference paper at ICLR 2022
REFERENCES,0.9502487562189055,"Table 7. Experimental results on ImageNet40 for the ResNet architecture. The proposed optimized separable
convolution (o-ResNet) achieves 4-5% performance gain over the ResNet baseline."
REFERENCES,0.9527363184079602,"Net Arch
Channel
#Params
FLOPs
Accuracy
Error Rate
Multiplier
(million)
(billion)
(%)
(%)"
REFERENCES,0.9552238805970149,"ResNet20
-
4.58
0.162
40.28
59.72"
REFERENCES,0.9577114427860697,"o-ResNet20
5.375
5.13
0.160
44.94
55.06"
REFERENCES,0.9601990049751243,"ResNet32
-
7.68
0.275
42.98
57.02"
REFERENCES,0.9626865671641791,"o-ResNet32
5.75
7.78
0.278
47.88
52.12"
REFERENCES,0.9651741293532339,"ResNet56
-
13.88
0.502
44.93
55.07"
REFERENCES,0.9676616915422885,"o-ResNet56
6.0
12.55
0.497
49.97
50.03"
REFERENCES,0.9701492537313433,"ResNet110
-
27.83
1.012
46.74
53.26"
REFERENCES,0.972636815920398,"o-ResNet110
6.25
23.79
1.027
50.72
49.28"
REFERENCES,0.9751243781094527,"advantages for ARM CPU architectures. Hence, the proposed osep scheme could be more efﬁcient
for mobile applications."
REFERENCES,0.9776119402985075,"There are good reasons for the slowness of the proposed osep on a GPU. In fact, there are two extra
copies of blobs in our current Python implementation of the proposed osep convolution (one for
group convolution if the number of groups does not divide the input or output channels, and the
other one for the channel shufﬂe operation). These two extra copies of blobs can actually be avoided
for an efﬁcient implementation. However, optimizing this code shall require a careful tweak of
the CUDNN library. It is known that on a GPU, the memory access cost can dominate over the
computational cost (Ma et al., 2018). Hence, the slowness of the proposed osep scheme shall occur.
On a CPU, the computational cost dominates over the memory access cost. Hence, the proposed
osep is faster than dsep. In the future, we expect the bottleneck of memory access for a GPU could
be addressed and the wall-clock timing of the proposed osep scheme could be greatly sped up."
REFERENCES,0.9800995024875622,"F
EXPERIMENTAL RESULTS ON IMAGENET40"
REFERENCES,0.9825870646766169,"Because carrying out experiments directly on the ImageNet dataset can be resource- and time-
consuming, we resized all the images into 40 × 40 pixels. A 32 × 32 patch is randomly cropped
and a random horizontal ﬂip with a probability of 0.5 is applied before feeding into the network.
No extra data augmentation strategies are used. The baseline ResNet architecture is a modiﬁed
version of that used on the CIFAR10 dataset, except that the channel sizes are set to be 4× larger,
the features are calculated on scales of [16, 8, 4], and the last fully-connected (FC) layer outputs
1000 categories for classiﬁcation. We make this modiﬁcation because the ImageNet dataset has sig-
niﬁcantly more training samples than the CIFAR10 dataset. Experimental results are illustrated in
Table 7, as can be seen, by substituting conventional convolutions with the proposed optimized sep-
arable convolutions, the resulting o-ResNet achieved 4-5% (e.g. 49.97% vs 44.93% for 56-layer and
50.72% vs 46.74% for 110-layer) performance gains comparing against the ResNet baselines. This
demonstrates that the proposed optimized separable convolution scheme is much more efﬁcient. For
o-ResNet56 and o-ResNet110, they also have fewer parameters which could contribute to a more
regularized model. For o-ResNet20 and o-ResNet32, they have slightly more parameters because
the last FC layer accounts for a great portion of overhead for 1000 classes."
REFERENCES,0.9850746268656716,"G
RELATED WORK"
REFERENCES,0.9875621890547264,"There have been many previous works aiming at reducing the amount of parameters in convolution.
Network pruning (Han et al., 2015) strategies are developed to reduce redundant parameters that are
not sensitive to performances. Quantization and binarization (Gong et al., 2014; Courbariaux et al.,
2016) techniques are introduced to compress the original network by reducing the number of bits re-
quired to represent each parameter. Low-rank factorization methods (Jaderberg et al., 2014; Ioannou
et al., 2015) are designed to approximate the original weights using matrix decomposition. Knowl-
edge distillation (Hinton et al., 2015) is applied to train a compact network with distilled knowledge
from a large ensemble model. However, all these existing methods start from a pre-trained model.
Besides, they mainly focus on network compression and have limited or no improvements in terms
of network acceleration."
REFERENCES,0.9900497512437811,Under review as a conference paper at ICLR 2022
REFERENCES,0.9925373134328358,"Among various implementations of convolution, separable convolution has been proven to be more
efﬁcient in reducing the representational demand. Depth separable convolution is explored exten-
sively in modern DCNNs (Howard et al., 2017; Sandler et al., 2018; Howard et al., 2019; Liu et al.,
2018; Tan & Le, 2019). It reduces the representational cost of a conventional convolution from
O(C2K2) to O(C · (C + K2)). However, the proposed optimized separable convolution is even
more efﬁcient than depth separable convolution. It can be represented at O(C
3
2 K) and has the full
potential to replace the usage of depth separable convolutions. A second advantage of the proposed
optimized separable convolution is that it can be applied to fully connected layers if we view them
as 1 × 1 convolutional layers, whereas depth separable convolution cannot. Further, depth separable
convolution requires the middle channel size to be equal to the input channel size, whereas for the
proposed optimized separable convolution, the middle channel size can be freely set."
REFERENCES,0.9950248756218906,"Spatial separable convolution was originally developed to speed up image processing operations.
For example, a Sobel kernel is a 3 × 3 kernel and can be written as (1, 2, 1)T · (−1, 0, 1). Spatial
separable will require 6 instead of 9 parameters while doing the same operation. Spatial separable
convolution is also adopted in the design of modern DCNNs. For example, in (Szegedy et al., 2016),
the authors introduce spatial separation to the GoogLeNet (Szegedy et al., 2015) architecture. For
the proposed optimized separable convolution, there is also a spatial separable conﬁguration."
REFERENCES,0.9975124378109452,"In the body of literature, separable convolution is also referred as factorized convolution or convolu-
tion decomposition. In this research, the proposed scheme is called optimized separable convolution
following the naming conventions of depth and spatial separable convolutions."
