Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.002631578947368421,"We study the problem of combining neural networks with symbolic reasoning.
Recently introduced frameworks for Probabilistic Neurosymbolic Learning (PNL),
such as DeepProbLog, perform exponential-time exact inference, limiting the
scalability of PNL solutions. We introduce Approximate Neurosymbolic Inference
(A-NESI): a new framework for PNL that uses neural networks for scalable
approximate inference. A-NESI 1) performs approximate inference in polynomial
time without changing the semantics of probabilistic logics; 2) is trained using data
generated by the background knowledge; 3) can generate symbolic explanations
of predictions; and 4) can guarantee the satisfaction of logical constraints at test
time, which is vital in safety-critical applications. Our experiments show that
A-NESI is the ﬁrst end-to-end method to solve three neurosymbolic tasks with
exponential combinatorial scaling. Finally, our experiments show that A-NESI
achieves explainability and safety without a penalty in performance."
INTRODUCTION,0.005263157894736842,"1
Introduction"
INTRODUCTION,0.007894736842105263,"Recent work in neurosymbolic learning combines neural perception with symbolic reasoning [52, 38],
using symbolic knowledge to constrain the neural network [19], to learn perception from weak
supervision signals [36], and to improve data efﬁciency [5, 57]. Many neurosymbolic methods use
a differentiable logic such as fuzzy logics [5, 17] or probabilistic logics [35, 57, 16]. We call the
latter Probabilistic Neurosymbolic Learning (PNL) methods. PNL methods add probabilities over
discrete truth values to maintain all logical equivalences from classical logic, unlike fuzzy logics
[54]. However, performing inference requires solving the weighted model counting (WMC) problem,
which is computationally exponential [13], signiﬁcantly limiting the kind of tasks that PNL can solve."
INTRODUCTION,0.010526315789473684,"We study how to scale PNL to exponentially complex tasks using deep generative modelling [51].
Our method called Approximate Neurosymbolic Inference (A-NESI), introduces two neural networks
that perform approximate inference over the WMC problem. The prediction model predicts the output
of the system, while the explanation model computes which worlds (i.e. which truth assignment
to a set of logical symbols) best explain a prediction. We use a novel training algorithm to ﬁt both
models with data generated using background knowledge: A-NESI samples symbol probabilities
from a prior and uses the symbolic background knowledge to compute likely outputs given these
probabilities. We train both models on these samples. See Figure 1 for an overview."
INTRODUCTION,0.013157894736842105,"A-NESI combines all beneﬁts of neurosymbolic learning with scalability. Our experiments on the
Multi-digit MNISTAdd problem [35] show that, unlike other approaches, A-NESI scales almost"
INTRODUCTION,0.015789473684210527,"p(P)
P
p(w|P)
w
y
c
p(P, w, y) x"
INTRODUCTION,0.018421052631578946,"LtjLtokDRFvKJeKCVXuiQM="">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</latexit>qφ(w, y|x)
f✓
P
w
y"
INTRODUCTION,0.021052631578947368,"Perceive
Predict
Explain (optional)"
INTRODUCTION,0.02368421052631579,"Sample belief
Choose example
Reason
Forward process"
INTRODUCTION,0.02631578947368421,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</latexit>qφp(y|P)
INTRODUCTION,0.02894736842105263,"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</latexit>qφe(w|y, P)"
INTRODUCTION,0.031578947368421054,Inference model
INTRODUCTION,0.034210526315789476,"Figure 1: Overview of A-NESI. The forward process samples a belief P from a prior, then chooses a
world w for that belief. The symbolic function c computes its output y. The inference model uses
the perception model fθ to ﬁnd a belief P, then uses the prediction model qφ to ﬁnd the most likely
output y for that belief. If we also use the optional explanation model, then qψ explains the output."
INTRODUCTION,0.03684210526315789,"linearly in the number of digits and solves MNISTAdd problems with up to 15 digits while maintaining
the predictive performance of exact inference. Furthermore, it can produce explanations of predictions
and guarantee the satisfaction of logical constraints using a novel symbolic pruner."
INTRODUCTION,0.039473684210526314,"The paper is organized as follows. In Section 3, we introduce A-NESI. Section 3.1 presents scalable
neural networks for approximate inference. Section 3.2 outlines a novel training algorithm using data
generated by the background knowledge. Section 3.2.4 extends A-NESI to include an explanation
model. Section 3.3 extends A-NESI to guarantee the satisfaction of logical formulas. In Section 4,
we perform experiments on three Neurosymbolic tasks that require perception and reasoning. Our
experiments on Multi-digit MNISTAdd show that A-NESI learns to predict sums of two numbers
with 15 handwritten digits, up from 4 in competing systems. Similarly, A-NESI can classify Sudoku
puzzles in 9 × 9 grids, up from 4, and ﬁnd the shortest path in 30 × 30 grids, up from 12."
PROBLEM SETUP,0.042105263157894736,"2
Problem setup"
PROBLEM SETUP,0.04473684210526316,"First, we introduce our inference problem. We will use the MNISTAdd task from [35] as a running
example. In this problem, we must learn to recognize the sum of two MNIST digits using only the
sum as a training label. Importantly, we do not provide the labels of the individual MNIST digits."
PROBLEM COMPONENTS,0.04736842105263158,"2.1
Problem components"
PROBLEM COMPONENTS,0.05,We introduce four sets representing the spaces of the variables of interest.
PROBLEM COMPONENTS,0.05263157894736842,"1. X is an input space. In MNISTAdd, this is the pair of MNIST digits x = (
,
).
2. W is a structured space of kW different discrete variables wi, each with their own domain. Its
elements w ∈W = W1 × ... × WkW are worlds or concepts [59] of some x ∈X. For (
,
),
the correct world is w = (5, 8) ∈{0, ..., 9}2.
3. Y is a structured space of kY discrete variables yi. Elements y ∈Y = Y1 × ... × YkY represent
the output of the neurosymbolic system. Given world w = (5, 8), the sum is 13. We decompose
the sum into individual digits, so y = (1, 3) ∈{0, 1} × {0, ..., 9}."
PROBLEM COMPONENTS,0.05526315789473684,"4. P ∈∆|W1| × ... × ∆|WkW |, where each ∆|Wi| is the probability simplex over the options of the
variable wi, is a belief. P assigns probabilities to different worlds with p(w|P) = QkW
i=1 Pi,wi.
That is, P is a parameter for an independent categorical distribution over the kW choices."
PROBLEM COMPONENTS,0.05789473684210526,"We assume access to some symbolic reasoning function c : W →Y that deterministically computes
the (structured) output y for any world w. This function captures our background knowledge of the
problem and we do not impose any constraints on its form. For MNISTAdd, c takes the two digits
(5, 8), sums them, and decomposes the sum by digit to form (1, 3)."
WEIGHTED MODEL COUNTING,0.060526315789473685,"2.2
Weighted Model Counting"
WEIGHTED MODEL COUNTING,0.06315789473684211,"Together, these components form the Weighted Model Counting (WMC) problem [13]:"
WEIGHTED MODEL COUNTING,0.06578947368421052,"p(y|P) = Ep(w|P)[1c(w)=y]
(1)"
WEIGHTED MODEL COUNTING,0.06842105263157895,"The WMC counts the possible worlds w1 for which c produces the output y, and weights each
possible world w with p(w|P). In PNL, we want to train a perception model fθ to compute a belief
P = fθ(x) for an input x ∈X in which the correct world is likely. Note that possible worlds are
not necessarily correct worlds: w = (4, 9) also sums to 13, but is not a symbolic representation of
x = (
,
)."
WEIGHTED MODEL COUNTING,0.07105263157894737,"Given this setup, we are interested in efﬁciently computing the following quantities:"
WEIGHTED MODEL COUNTING,0.07368421052631578,"1. p(y|P = fθ(x)): We want to ﬁnd the most likely outputs for the belief P that the perception
network computes on the input x.
2. ∇Pp(y|P = fθ(x)): We want to train our neural network fθ, which requires computing the
gradient of the WMC problem.
3. p(w|y, P = fθ(x)): We want to ﬁnd likely worlds given a predicted output and a belief about the
perceived digits. The probabilistic logic programming literature calls w∗= arg maxw p(w|y, P)
the most probable explanation (MPE) [50]."
THE PROBLEM WITH EXACT INFERENCE FOR WMC,0.07631578947368421,"2.3
The problem with exact inference for WMC"
THE PROBLEM WITH EXACT INFERENCE FOR WMC,0.07894736842105263,"The three quantities introduced in Section 2.2 require calculating or estimating the WMC problem
of Equation 1. However, the exact computation of the WMC is #P-hard, which is above NP-hard.
Thus, we would need to do a potentially exponential-time computation for each training iteration
and test query. Existing PNL methods use probabilistic circuits (PCs) to speed up this computation
[60, 28, 35, 57]. PCs compile a logical formula into a circuit for which many inference queries are
linear in the size of the circuit. PCs are a good choice when exact inference is required but do not
overcome the inherent exponential complexity of the problem: the compilation step is potentially
exponential in time and memory, and there are no guarantees the size of the circuit is not exponential."
THE PROBLEM WITH EXACT INFERENCE FOR WMC,0.08157894736842106,"The Multi-digit MNISTAdd task is excellent for studying the scaling properties of WMC. We can
increase the complexity of MNISTAdd exponentially by considering not only the sum of two single
digits (called N = 1) but the sum of two numbers with multiple digits. An example of N = 2
would be
+
= 135. There are 64 ways to sum to 135 using two numbers with two digits.
Contrast this to summing two digits: there are only 6 ways to sum to 13. Each increase of N leads
to 10 times more options to consider for exact inference. Our experiments in Section 4 will show
that approximate inference can solve this problem up to N = 15. Solving this using exact inference
would require enumerating around 1015 options for each query."
THE PROBLEM WITH EXACT INFERENCE FOR WMC,0.08421052631578947,"3
A-NESI: Approximate Neurosymbolic Inference"
THE PROBLEM WITH EXACT INFERENCE FOR WMC,0.0868421052631579,"Our goal is to reduce the inference complexity of PNL to allow training neurosymbolic models on
much more complex problems. To this end, in the following subsections, we introduce Approximate
Neurosymbolic Inference (A-NESI). A-NESI approximates the three quantities of interest from
Section 2, namely p(y|P), ∇Pp(y|P) and p(w|y, P), using neural networks. We give an overview
of our method in Figure 1."
INFERENCE MODELS,0.08947368421052632,"3.1
Inference models"
INFERENCE MODELS,0.09210526315789473,"A-NESI uses an inference model qφ,ψ deﬁned as"
INFERENCE MODELS,0.09473684210526316,"qφ,ψ(w, y|P) = qφ(y|P)qψ(w|y, P).
(2)"
INFERENCE MODELS,0.09736842105263158,"We call qφ(y|P) the prediction model and qψ(w|y, P) the explanation model. The prediction model
should approximate the WMC problem of Equation 1, while the explanation model should predict
likely worlds w given outputs y and beliefs P. One way to model qφ,ψ is by considering W and Y
as two sequences and deﬁning an autoregressive generative model over these sequences:"
INFERENCE MODELS,0.1,"qφ(y|P) = kY
Y"
INFERENCE MODELS,0.10263157894736842,"i=1
qφ(yi|y1:i−1, P),
qψ(w|y, P) = kW
Y"
INFERENCE MODELS,0.10526315789473684,"i=1
qψ(wi|y, w1:i−1, P)
(3)"
INFERENCE MODELS,0.10789473684210527,"1Possible worlds are also called ‘models’. We refrain from using this term to prevent confusion with ‘(neural
network) models’."
INFERENCE MODELS,0.11052631578947368,Algorithm 1 Compute inference model loss
INFERENCE MODELS,0.11315789473684211,"ﬁt prior p(P) on P1, ..., Pk
P ∼p(P)
w ∼p(w|P)
y ←c(w)
return φ + α∇φ log qφ(y|P)"
INFERENCE MODELS,0.11578947368421053,Algorithm 2 A-NESI training loop
INFERENCE MODELS,0.11842105263157894,"Input: dataset D, params θ, params φ
beliefs←[]
while not converged do"
INFERENCE MODELS,0.12105263157894737,"(x, y) ∼D
P ←fθ(x)
update beliefs with P
φ ←Algorithm 1(beliefs, φ)
θ ←θ + α∇θ log qφ(y|P)"
INFERENCE MODELS,0.12368421052631579,Figure 2: The training loop of A-NESI.
INFERENCE MODELS,0.12631578947368421,"This factorization makes the inference model highly ﬂexible. We can use simpler models if we know
the dependencies between variables in W and Y . The factorization is computationally linear in
kW + kY , instead of exponential in kW for exact inference. During testing, we use a beam search to
ﬁnd the most likely prediction from qφ,ψ(w, y|P). If the method successfully trained the perception
model, then its entropy is low and a beam search should easily ﬁnd the most likely prediction [37]."
INFERENCE MODELS,0.12894736842105264,"There are no restrictions on the architecture of the inference model qφ. Any neural network with
appropriate inductive biases and parameter sharing to speed up training can be chosen. For instance,
CNNs over grids of variables, graph neural networks [27, 48] for reasoning problems on graphs, or
transformers for sets or sequences [55]."
INFERENCE MODELS,0.13157894736842105,"We use the prediction model to train the perception model fθ given a dataset D of tuples (x, y). Our
novel loss function trains the perception model by backpropagating through the prediction model:
LP erc(D, θ) = −log qφ(y|P = fθ(x)),
x, y ∼D
(4)
The gradients of this loss are biased due to the error in the approximation qφ, but it has no variance
outside of sampling from the training dataset."
TRAINING THE INFERENCE MODEL,0.13421052631578947,"3.2
Training the inference model"
TRAINING THE INFERENCE MODEL,0.1368421052631579,"We deﬁne two variations of our method. The prediction-only variant (Section 3.2.1) uses only the
prediction model qφ(y|P), while the explainable variant (Section 3.2.4) also uses the explanation
model qψ(w|y, P)."
TRAINING THE INFERENCE MODEL,0.1394736842105263,"Efﬁcient training of the inference model relies on two design decisions. The ﬁrst is a descriptive
factorization of the output space Y , which we discuss in Section 3.2.2. The second is using an
informative belief prior p(P), which we discuss in Section 3.2.3."
TRAINING THE INFERENCE MODEL,0.14210526315789473,"We ﬁrst deﬁne the forward process that uses the symbolic function c to generate training data:
p(w, y|P) = p(w|P)p(y|w, P) = p(w|P)1c(w)=y
(5)
We take some example world w and deterministically compute the output of the symbolic function
c(w). Then, we compute whether the output c(w) equals y. Therefore, p(w, y|P) is 0 if c(w) ̸= y
(that is, w is not a possible world of y)."
TRAINING THE INFERENCE MODEL,0.14473684210526316,"The belief prior p(P) allows us to generate beliefs P for the forward process. That is, we generate
training data for the inference model using
p(P, w) = p(P)p(w|P)
where P, w ∼p(P, w),
y = c(w).
(6)"
TRAINING THE INFERENCE MODEL,0.14736842105263157,"The belief prior allows us to train the inference model with synthetic data: The prior and the forward
process deﬁne everything qφ needs to learn. Note that the sampling process P, w ∼p(P, w) is
fast and parallelisable. It involves sampling from a Dirichlet distribution, and then sampling from a
categorical distribution for each dimension of w based on the sampled parameters P."
TRAINING THE PREDICTION-ONLY VARIANT,0.15,"3.2.1
Training the prediction-only variant"
TRAINING THE PREDICTION-ONLY VARIANT,0.15263157894736842,"In the prediction-only variant, we only train the prediction model qφ(y|P). We use the samples
generated by the process in Equation 6. We minimize the expected cross entropy between p(y|P)"
TRAINING THE PREDICTION-ONLY VARIANT,0.15526315789473685,and qφ(y|P) over the prior p(P):
TRAINING THE PREDICTION-ONLY VARIANT,0.15789473684210525,"LP red(φ) = −log qφ(c(w)|P),
P, w ∼p(P, w)
(7)"
TRAINING THE PREDICTION-ONLY VARIANT,0.16052631578947368,"See A for a derivation. In the loss function deﬁned in Equation 7, we estimate the expected cross
entropy using samples from p(P, w). We use the sampled world w to compute the output y = c(w)
and increase its probability under qφ. Importantly, we do not need to use any data to evaluate this
loss function. We give pseudocode for the full training loop in Figure 2."
OUTPUT SPACE FACTORIZATION,0.1631578947368421,"3.2.2
Output space factorization"
OUTPUT SPACE FACTORIZATION,0.16578947368421051,"The factorization of the output space Y introduced in Section 2 is one of the key ideas that allow
efﬁcient learning in A-NESI. We will illustrate this with MNISTAdd. As the number of digits N
increases, the number of possible outputs (i.e., sums) is 2 · 10N −1. Without factorization, we would
need an exponentially large output layer. We solve this by predicting the individual digits of the
output so that we need only N · 10 + 2 outputs similar to [3]. Furthermore, recognizing a single digit
of the sum is easier than recognizing the entire sum: for its rightmost digit, only the rightmost digits
of the input are relevant."
OUTPUT SPACE FACTORIZATION,0.16842105263157894,"Choosing the right factorization is crucial when applying A-NESI. A general approach is to take the
CNF of the symbolic function and predict each clause’s truth value. However, this requires grounding
the formula, which can be exponential. Another option is to predict for what objects a universally
quantiﬁed formula holds, which would be linear in the number of objects."
BELIEF PRIOR DESIGN,0.17105263157894737,"3.2.3
Belief prior design"
BELIEF PRIOR DESIGN,0.1736842105263158,"How should we choose the Ps for which we train qφ,ψ? A naive method would use the perception
model fθ, sample some training data x1, ..., xk ∼D and train the inference model over P1 =
fθ(x1), ..., Pk = fθ(xk). However, this means the inference model is only trained on those P
occurring in the training data. Again, consider the Multi-digit MNISTAdd problem. For N = 15, we
have a training set of 2000 sums, while there are 2 · 1015 −1 possible sums. By simulating many
beliefs, the inference model sees a much richer set of inputs and outputs, allowing it to generalize."
BELIEF PRIOR DESIGN,0.1763157894736842,"A better approach is to ﬁt a Dirichlet prior p(P) on P1, ..., Pk that covers all possible combinations
of numbers. We choose a Dirichlet prior since it is conjugate to the discrete distributions. For details,
see Appendix F. During hyperparameter tuning, we found that the prior needs to be high entropy to
prevent the inference model from ignoring the inputs P. Therefore, we regularize the prior with an
additional term encouraging high-entropy Dirichlet distributions."
TRAINING THE EXPLAINABLE VARIANT,0.17894736842105263,"3.2.4
Training the explainable variant"
TRAINING THE EXPLAINABLE VARIANT,0.18157894736842106,"The explainable variant uses both the prediction model qφ(y|P) and the optional explanation model
qψ(w|y, P). When training the explainable variant, we use the idea that both factorizations of
the joint should have the same probability mass, that is, p(w, y|P) = qφ,ψ(w, y|P). To this end,
we use a novel joint matching loss inspired by the theory of GFlowNets [9, 10], in particular, the
trajectory balance loss introduced by [33] which is related to variational inference [34]. For an
in-depth discussion, see Appendix E. The joint matching loss is essentially a regression of qφ,ψ onto
the true joint p that we compute in closed form:"
TRAINING THE EXPLAINABLE VARIANT,0.18421052631578946,"LExpl(φ, ψ) =

log qφ,ψ(w, c(w)|P)"
TRAINING THE EXPLAINABLE VARIANT,0.1868421052631579,p(w|P)
TRAINING THE EXPLAINABLE VARIANT,0.18947368421052632,"2
,
P, w ∼p(P, w)
(8)"
TRAINING THE EXPLAINABLE VARIANT,0.19210526315789472,"Here we use that p(w, c(w)|P) = p(w|P) since c(w) is deterministic. Like when training the
prediction-only variant, we sample a random belief P and world w and compute the output y. Then
we minimize the loss function to match the joints p and qφ,ψ. We further motivate the use of this loss
in Appendix D. Instead of a classiﬁcation loss like cross-entropy, the joint matching loss ensures qφ,ψ
does not become overly conﬁdent in a single prediction and allows spreading probability mass easier."
SYMBOLIC PRUNER,0.19473684210526315,"3.3
Symbolic pruner"
SYMBOLIC PRUNER,0.19736842105263158,"An attractive option is to use symbolic knowledge to ensure the inference model only generates valid
outputs. We can compute each factor qψ(wi|y, w1:i−1, P) (both for world and output variables)"
SYMBOLIC PRUNER,0.2,"y1
y2
w2
w1
1
0 5
8
3 0"
SYMBOLIC PRUNER,0.2026315789473684,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</latexit>. . . . . . 9 0
SYMBOLIC PRUNER,0.20526315789473684,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</latexit>. . .
SYMBOLIC PRUNER,0.20789473684210527,"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</latexit>3
4 . . . 9 0"
SYMBOLIC PRUNER,0.21052631578947367,F0GCAmcJIJU9iOyjSbmzHmEN3JjszmZk2DgY0RctsKJFDUokdQcde2v7P3pYoOi1x97G3rqP+hL2bIlUbIBJzSf5348NVLitJMKq06/7nk0+/9e3vfPd7n32/YMf/ujHP3n0+U/fKh5LTK4wZ1y+nyFGI3IlakfdCEhTOGHk3ux0Z/N0dkYry6I1eCXIToiCic4qRhq6rqc+1+vDo0D1ys49jN7xN4/C3/7m6/+6efXH74/Iv/QSCOQxJpzJBS154r9E2CpKaYkbQ9jRURCN+igFzHej64SWgkYk0inDqPAZvHzNHcMYcn0qCNVtBA2FJQcHBCyQR1mC7XZSJEIhUR3/jgq1bq7YN3QCOZ8kyznKSlwCSQSCwoXpacJShUIdILq1OtwlnaflzsJTEj8i4sU41NMFnuJEsiMVUmCZeQmZfC5Fm94ZcbfLESCxKpNIklS4uBABApyRwCs6YiOhZJNhu4uLfqTMuYdEwz6zsbI3n7ivgd0Cl1lO3MGUe63DULK9lhOCgzNL19KPcsBZJmTu1pRO4xD0MU+clUpMlUk6VOp2jFMAsxAQzOpNIrhK1QIokDKdACVtx4GKcxbU90n0qyOlV4ycJWkH+k0F1wImwMwltv+ogYSgkS+s0HWqTj0UivUJ3MUM302YzCn7YAV4ZKJfcql4J02QJerKlR9I4h5pusFuR9v1swoT6Av0b1PSZq8TNIwTdrTGQlolOVfUKxjSdLr5Zl71D8hYWeVNw69jpOvejrnpDlDVjK1K4ljyOf+OBNRlBEgJ90CrO6cZ64HfepY9YcigJGnCdex3v6axNP59z3D7vQhB9zytj1Ls8mDpTg+9TBVGITmM9wHT2na40oDg+7v/HaDRpdI9Ldo2KH9E1IvzEkH/JZs/EuCAwa4htCBsZmc0g+6En2c49Gk+29XpuDNmGv9kX6rNULVnxSUIjqiVU2DVszvqs14FqiCPYqs6g2DrOx5gS3XEUIf7ZcfemvKbh/kBxmiRTE58XaNJNYX2XeGpDnCqMGOGzP0Kd9I8Hmw8drLlMONI+uXQV0be7LyzmfOqvuiAL6oghcF8GIzCGe+M+fSuYOK5lI5QHSAIikmqhx9tY2eO1dV6bcF8G0VfFcA31XBWVxAYwu9K6B3FnpfQO8tVBRQUWXBXBZBVcFcFUFHwrgQxV8v0/29/tk/1CRhasDN95VthvCDpRtoMkt1MzN1/9Lk1Os8+mUmLieGUinuXEZ5Ne/7SfVmGW48eTgTc2/iW0B+e6M6wpZx3h+54udl26FuzXtur2L815VCrMdPjgdTWx8Z9Y974+HNYSd28no+K/SR8hUYUabHmj096xlZgq3M6HA5PTm18Sxgej0aDbg1hyxiNx+PzUWZFxFIwUuGKnNjrnbi2lNgKDdze8XkNvrsA7mA4tMyKgpfhZOiNvcyLJohVmHpbLKPB+elFVUjv8j8H42sC6gL6R+MvPFxDWHn9WR8cvEsc8JhlwyqWeHb9PX6g2eDqhTfCk36cAUtL3w30uR06PYtL7zgZTIcDU1iysRFtm1d5OsT2e7deceo7ZyMtkWGhVsl7ObnCZTVk1syupe/j1wewRvP2TDFuksc14rjRDK7zgpvN41rzeJ/5wOYHTfJBjXjQaCao8xI0mw9qzQf7zAubL5rkRY24aDQj6ryIZvOi1rzYZ17bfN0kr2vEdaMZXedFN5vXteb1PvPc5vMmeV4jzhvN8DovNk8rzXP95iX5B4OhOakANWVSEsSnvhgTnDMUuQfe7USJM5ixRFswAjXSOP1j4TC+IRgafheA5+2EfuxY0Z5imjasdrmpwjeLtCNC0cCJUjkOTMphvleNTlZ3Zs5kIlkwDBEi6PVXBoTzSDlGahtmbnEqSUAg36zyJUzsNgZrvDmtJkH5IplwQieAEbd6mJK8nqR0j/L0xl+N040+YF0GIOeZFCmcOjTbnwNItKjvb3mJI4Zq9LpUxwQxJ8hUM8nIj/ksoChmEFIoC/k87prWPiJY5EVrtavVwvIBnouzJcuNmQ48wSvayoNuBH3yYb62qpleOxYF/OU3xEpabDQSEp+n70KRGR2V0ylXl1GIOpDTipgh9jIlfpeq18tMbXMtaLrJLgIWid7ETbS4ymb1+y6e8DkstEo/1hgWjTRdIb6mg+OHRoVd9JWg3naPvN7R8dfu4ZfPW+vPZ62ftX7RetLyWv3Wl63nrcvWVQu3aOsvrb+2/nbw54O/H/zj4J9r6qefbGK+aJU+B/6P8fEwW4=</latexit>. . . 7 9
SYMBOLIC PRUNER,0.2131578947368421,"qφ(y2|y1, P)
qφ(y1|P) P"
SYMBOLIC PRUNER,0.21578947368421053,"q (w1|y, P)"
SYMBOLIC PRUNER,0.21842105263157896,"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</latexit>q (w2|w1, y, P)"
SYMBOLIC PRUNER,0.22105263157894736,"Figure 3: Example rollout sampling an explainable variant on input x = (
,
). For y2, we prune
option 9, as the highest attainable sum is 9 + 9 = 18. For w1, {0, ..., 3} are pruned as there is no
second digit to complete the sum. w2 is deterministic given w1, and prunes all branches but 8."
SYMBOLIC PRUNER,0.2236842105263158,"using a neural network ˆqψ,i and a symbolic pruner sy,w1:i−1 : Wi →{0, 1}:"
SYMBOLIC PRUNER,0.22631578947368422,"qψ(wi = j|y, w1:i−1, P) =
ˆqψ(wi = j|y, w1:i−1, P)sy,w1:i−1(j)
P"
SYMBOLIC PRUNER,0.22894736842105262,"j′∈Wi ˆqψ(wi = j′|y, w1:i−1, P)sy,w1:i−1(j′)
(9)"
SYMBOLIC PRUNER,0.23157894736842105,"The symbolic pruner sets the probability mass of certain choices for the variable wi to zero. Then,
qψ is computed by renormalizing. If we know that by expanding w1:i−1 it will be impossible to
produce a possible world for y, we can set the probability mass under that branch to 0: we will know
that p(w, y) = 0 for all such branches. In Figure 3 we give an example for single-digit MNISTAdd.
Symbolic pruning signiﬁcantly reduces the number of branches our algorithm needs to explore during
training. Moreover, symbolic pruning is critical in settings where veriﬁability and safety play crucial
roles, such as medicine. We discuss the design of symbolic pruners s in Appendix G."
EXPERIMENTS,0.23421052631578948,"4
Experiments"
EXPERIMENTS,0.23684210526315788,"We study three Neurosymbolic reasoning tasks to evaluate the performance and scalability of A-
NeSI: Multi-digit MNISTAdd [37], Visual Sudoku Puzzle Classiﬁcation [4] and Warcraft path
planning. Code is available at https://github.com/HEmile/a-nesi. We used the ADAM
optimizer throughout."
EXPERIMENTS,0.2394736842105263,"A-NESI has two prediction methods. 1) Symbolic prediction uses the symbolic reasoning function
c to compute the output: ˆy = c(arg maxwp(w|P = fθ(x))). 2) Neural prediction predicts with
the prediction network qφ using a beam search: ˆy = arg maxyqφ(y|P = fθ(x)). In our studied
tasks, neural prediction cannot perform better than symbolic prediction. However, we still use the
prediction model to efﬁciently train the perception model in the symbolic prediction setting. We
consider the prediction network adequately trained if it matches the accuracy of symbolic prediction."
MULTI-DIGIT MNISTADD,0.24210526315789474,"4.1
Multi-digit MNISTAdd"
MULTI-DIGIT MNISTADD,0.24473684210526317,"We evaluate A-NESI on the Multi-Digit MNISTAdd task (Section 2). For the perception model, we
use the same CNN as in DeepProbLog [35]. The prediction model has N +1 factors qφ(yi|y1:i−1, P),
while the explanation model has 2N factors qψ(wi|y, w1,i−1, P). We model each factor with a
separate MLP. yi and wi are one-hot encoded digits, except for the ﬁrst output digit y1: it can only be
0 or 1. We used a shared set of hyperparameters for all N. For more details and a description of the
baselines, see Appendix I.1."
MULTI-DIGIT MNISTADD,0.24736842105263157,"Table 1 reports the accuracy of predicting the sum. For all N, A-NESI is close to the reference
accuracy, meaning there is no signiﬁcant drop in the accuracy of the perception model as N increases.
For small N, it is slightly outperformed by DeepStochLog [56], which can not scale to N = 15.
A-NESI also performs slightly better than DeepProbLog, showing approximate inference does not
hurt the accuracy. With neural prediction, we get the same accuracy for low N, but there is a
signiﬁcant drop for N = 15, meaning the prediction network did not perfectly learn the problem.
However, compared to training a neural network without background knowledge (Embed2Sym with"
MULTI-DIGIT MNISTADD,0.25,"N=1
N=2
N=4
N=15
Symbolic prediction
LTN
80.54 ± 23.33
77.54 ± 35.55
T/O
T/O
DeepProbLog
97.20 ± 0.50
95.20 ± 1.70
T/O
T/O
DPLA*
88.90 ± 14.80
83.60 ± 23.70
T/O
T/O
DeepStochLog
97.90 ± 0.10
96.40 ± 0.10
92.70 ± 0.60
T/O
Embed2Sym
97.62 ± 0.29
93.81 ± 1.37
91.65 ± 0.57
60.46 ± 20.36
A-NESI (predict)
97.66 ± 0.21
95.96 ± 0.38
92.56 ± 0.79
75.90 ± 2.21
A-NESI (explain)
97.37 ± 0.32
96.04 ± 0.46
92.11 ± 1.06
76.84 ± 2.82
A-NESI (pruning)
97.57 ± 0.27
95.82 ± 0.33
92.40 ± 0.68
76.46 ± 1.39
A-NESI (no prior)
76.54 ± 27.38
95.67 ± 0.53
44.58 ± 38.34
0.03 ± 0.09
Neural prediction
Embed2Sym
97.34 ± 0.19
84.35 ± 6.16
0.81 ± 0.12
0.00
A-NESI (predict)
97.66 ± 0.21
95.95 ± 0.38
92.48 ± 0.76
54.66 ± 1.87
A-NESI (explain)
97.37 ± 0.32
96.05 ± 0.47
92.14 ± 1.05
61.77 ± 2.37
A-NESI (pruning)
97.57 ± 0.27
95.82 ± 0.33
92.38 ± 0.64
59.88 ± 2.95
A-NESI (no prior)
76.54 ± 27.01
95.28 ± 0.62
40.76 ± 34.29
0.00 ± 0.00
Reference
98.01
96.06
92.27
73.97"
MULTI-DIGIT MNISTADD,0.25263157894736843,"Table 1: Test accuracy of predicting the correct sum on the Multi-digit MNISTAdd task. “T/O”
(timeout) represent computational timeouts. Reference accuracy approximates the accuracy of an
MNIST predictor with 0.99 accuracy using 0.992N. Bold numbers signify the highest average
accuracy for some N within the prediction categories. predict is the prediction-only variant, explain
is the explainable variant, pruning adds symbolic pruning (see Appendix H), and no prior is the
prediction-only variant without the prior p(P)."
MULTI-DIGIT MNISTADD,0.25526315789473686,"2
4
6
8
10
12
14
N 10−3 10−2 10−1 100 101 102"
MULTI-DIGIT MNISTADD,0.2578947368421053,Inference time (s)
MULTI-DIGIT MNISTADD,0.26052631578947366,"DeepProbLog
DSL (grounding)
DPLA*
A-NeSI (explain)"
MULTI-DIGIT MNISTADD,0.2631578947368421,A-NeSI (predict)
MULTI-DIGIT MNISTADD,0.2657894736842105,DSL (inference)
MULTI-DIGIT MNISTADD,0.26842105263157895,"5
10
15
N 0,00 0,02 0,04 0,06 0,08 0,10"
MULTI-DIGIT MNISTADD,0.2710526315789474,"Figure 4: Inference time for a single input x for different nr. of digits. The left plot uses a log scale,
and the right plot a linear scale. DSL stands for DeepStochLog. We use the GM variant of DPLA*."
MULTI-DIGIT MNISTADD,0.2736842105263158,"neural prediction), it is much more accurate already for N = 2. Therefore, A-NESI’s training loop
allows training a prediction network with high accuracy on large-scale problems."
MULTI-DIGIT MNISTADD,0.27631578947368424,"Comparing the different A-NESI variants, we see the prediction-only, explainable and pruned variants
perform quite similarly, with signiﬁcant differences only appearing at N = 15 where the explainable
and pruning variants outperform the predict-only model, especially on neural prediction. However,
when removing the prior p(P), the performance degrades quickly. The prediction model sees much
fewer beliefs P than when sampling from a (high-entropy) prior p(P). A second and more subtle
reason is that at the beginning of training, all the beliefs P = fθ(x) will be uniform because the
perception model is not yet trained. Then, the prediction model learns to ignore the input belief P."
MULTI-DIGIT MNISTADD,0.2789473684210526,"Figure 4 shows the runtime for inference on a single input x. Inference in DeepProbLog (cor-
responding to exact inference) increases with a factor 100 as N increases, and DPLA* (another
approximation) is not far behind. Inference in DeepStochLog, which uses different semantics, is
efﬁcient due to caching but requires a grounding step that is exponential both in time and memory.
We could not ground beyond N = 4 because of memory issues. A-NESI avoids having to perform
grounding altogether: it scales slightly slower than linear. Furthermore, it is much faster in practice
as parallelizing the computation of multiple queries on GPUs is trivial."
MULTI-DIGIT MNISTADD,0.28157894736842104,"N=4
N=9
CNN
51.50 ± 3.34
51.20 ± 2.20
Exact inference
86.70 ± 0.50
T/O
NeuPSL
89.7 ± 2.20
51.50 ± 1.37
A-NESI (symbolic prediction)
89.70 ± 2.08
62.15 ± 2.08
A-NESI (neural prediction)
89.80 ± 2.11
62.25 ± 2.20"
MULTI-DIGIT MNISTADD,0.28421052631578947,"Table 2: Test accuracy of predicting whether a grid of numbers is a Sudoku. For A-NeSI, we used the
prediction-only variant."
MULTI-DIGIT MNISTADD,0.2868421052631579,"4.2
Visual Sudoku Puzzle Classiﬁcation"
MULTI-DIGIT MNISTADD,0.2894736842105263,"In this task, the goal is to recognize whether an N × N grid of MNIST digits is a Sudoku. We
have 100 examples of correct and incorrect grids from [4]. We use the same MNIST classiﬁer as
in the previous section. We treat w as a grid of digits in {1, . . . , N} and designed an easy-to-learn
representation of the label. For sudokus, all pairs of digits wi, wj in a row, column, and block
must differ. For each such pair, a dimension in y is 1 if different and 0 otherwise, and the symbolic
function c computes these interactions from w. The prediction model is a single MLP that takes the
probabilities for the digits Pi and Pj and predicts the probability that those represent different digits.
For additional details, see Appendix I.2."
MULTI-DIGIT MNISTADD,0.29210526315789476,"Table 2 shows the accuracy of classifying Sudoku puzzles. A-NESI is the only method to perform
better than random on 9 × 9 sudokus. Exact inference cannot scale to 9 × 9 sudokus, while we were
able to run A-NESI for 3000 epochs in 38 minutes on a single NVIDIA RTX A4000."
WARCRAFT VISUAL PATH PLANNING,0.29473684210526313,"4.3
Warcraft Visual Path Planning"
WARCRAFT VISUAL PATH PLANNING,0.29736842105263156,"Figure 5: Example
of the Warcraft task."
WARCRAFT VISUAL PATH PLANNING,0.3,"12 × 12
30 × 30
ResNet18 [43]
23.0 ± 0.3
0.0 ± 0.0
SPL [1]
78.2
T/O
I-MLE [41]
97.2 ± 0.5
93.7 ± 0.6
RLOO [29]
43.75 ± 12.35
12.59 ± 16.38
A-NESI
94.57 ± 2.27
17.13 ± 16.32
A-NESI + RLOO
98.96 ± 1.33
67.57 ± 36.76
Table 3: Test accuracy of predicting the lowest-cost path on the Warcraft
Visual Path Planning task. For A-NeSI, we used the prediction-only variant."
WARCRAFT VISUAL PATH PLANNING,0.3026315789473684,"The Warcraft Visual Path Planning task [43] is to predict a shortest path from the top left corner of an
N × N grid to the bottom right, given an image from the Warcraft game (Figure 5). The perception
model has to learn the cost of each tile of the Warcraft image. We use a small CNN that takes the
tile i, j (a 3 × 8 × 8 image) and outputs a distribution over 5 possible costs. The symbolic function
c(w) is Dijkstra’s algorithm and returns a shortest path y, which we encode as a sequence of the 8
(inter)-cardinal directions starting from the top-left corner. We use a ResNet18 [22] as the prediction
model, which we train to predict the next direction given beliefs of the tile costs P and the current
location. We pretrain the prediction model on a ﬁxed prior and train the perception model with a
frozen prediction model. See Appendix I.3 for additional details."
WARCRAFT VISUAL PATH PLANNING,0.30526315789473685,"Table 3 presents the accuracy of predicting a shortest path. A-NESI is competitive on 12 × 12 grids
but struggles on 30×30 grids. We believe this is because the prediction model is not accurate enough,
resulting in gradients with too high bias. Still, A-NESI ﬁnds short paths, is far better than a pure
neural network, and can scale to 30×30 grids, unlike SPL [1], which uses exact inference. Since both
SPL and I-MLE [41] have signiﬁcantly different setups (see Appendix I.3.2), we added experiments
using REINFORCE with the leave-one-out baseline (RLOO, [29]) that we implemented with the
Storchastic PyTorch library [53]. We ﬁnd that RLOO has high variance in its performance. Since
RLOO is unbiased with high variance and A-NESI is biased with no variance, we also tried running
A-NESI and RLOO simultaneously. Interestingly, this is the best-performing method on the 12 × 12
grid, and has competitive performance on 30 × 30 grids, albeit with high variance (6 out 10 runs get
to an accuracy between 93.3% and 98.5%, while the other runs are stuck around 25% accuracy)."
RELATED WORK,0.3078947368421053,"5
Related work"
RELATED WORK,0.3105263157894737,"A-NESI can approximate multiple PNL methods [16]. DeepProbLog [35] performs symbolic
reasoning by representing w as ground facts in a Prolog program. It enumerates all possible proofs of
a query y and weights each proof by p(w|P). NeurASP [58] is a PNL framework closely related to
DeepProbLog, but is based on Answer Set Programming [12]. Some methods consider constrained
structured output prediction [19]. In Appendix B, we discuss extending A-NESI to this setting.
Semantic Loss [57] improves learning with a loss function but does not guarantee that formulas
are satisﬁed at test time. Like A-NESI, Semantic Probabilistic Layers [1] solves this with a layer
that performs constrained prediction. These approaches perform exact inference using probabilistic
circuits (PCs) [60]. Other methods perform approximate inference by only considering the top-k
proofs in PCs [36, 23]. However, ﬁnding those proofs is hard, especially when beliefs have high
entropy, and limiting to top-k signiﬁcantly reduces performance. Other work considers MCMC
approximations [31]. Using neural networks for approximate inference ensures computation time is
constant and independent of the entropy of P or long MCMC chains."
RELATED WORK,0.3131578947368421,"Other neurosymbolic methods use fuzzy logics [5, 17, 15, 18], which are faster than PNL with
exact inference. Although traversing ground formulas is linear time, the grounding is itself often
exponential [37], so the scalability of fuzzy logics often fails to deliver. A-NESI is polynomial in
the number of ground atoms and does not traverse the ground formula. Furthermore, background
knowledge is often not fuzzy [54, 20], and fuzzy semantics does not preserve classical equivalence."
RELATED WORK,0.3157894736842105,"A-NESI performs gradient estimation of the WMC problem. We can extend our method to biased
but zero-variance gradient estimation by learning a distribution over function outputs (see Appendix
C). Many recent works consider continuous relaxations of discrete computation to make them
differentiable [42, 24] but require many tricks to be computationally feasible. Other methods compute
MAP states to compute the gradients [41, 11, 47] but are restricted to integer linear programs. The
score function (or ‘REINFORCE’) gives unbiased yet high-variance gradient estimates [40, 53].
Variance reduction techniques, such as memory augmentation [32] and leave-one-out baselines [29],
exist to reduce this variance."
RELATED WORK,0.31842105263157894,"6
Conclusion, Discussion and Limitations"
RELATED WORK,0.32105263157894737,"We introduced A-NESI, a scalable approximate method for probabilistic neurosymbolic learning.
We demonstrated that A-NESI scales to combinatorially challenging tasks without losing accuracy.
A-NESI can be extended to include explanations and hard constraints without loss of performance."
RELATED WORK,0.3236842105263158,"However, there is no ‘free lunch’: when is A-NESI a good approximation? We discuss three aspects
of learning tasks that could make it difﬁcult to learn a strong and efﬁcient inference model."
RELATED WORK,0.3263157894736842,"• Dependencies of variables. When variables in world w are highly dependent, ﬁnding an
informative prior is hard. We suggest then using a prior that can incorporate dependen-
cies such as a normalizing ﬂow [45, 14] or deep generative models [51] over a Dirichlet
distribution."
RELATED WORK,0.32894736842105265,"• Structure in symbolic reasoning function. We studied reasoning tasks with a relatively
simple structure. Learning the inference model will be more difﬁcult when the symbolic
function c is less structured. Studying the relation between structure and learnability is
interesting future work."
RELATED WORK,0.33157894736842103,"• Problem size. A-NESI did not perfectly train the prediction model in more challenging
problems, which is evident from the divergence in performance between symbolic and
neural prediction for 15 digits in Table 1. We expect its required parameter size and training
time to increase with the problem size."
RELATED WORK,0.33421052631578946,"Promising future avenues are studying if the explanation model produces helpful explanations [50],
extensions to continuous random variables [21] (see Appendix C for an example), and extensions
to unnormalized distributions such as Markov Logic Networks[46], as well as (semi-) automated
A-NESI solutions for neurosymbolic programming languages like DeepProbLog [35]."
RELATED WORK,0.3368421052631579,Acknowledgements
RELATED WORK,0.3394736842105263,"We want to thank Robin Manhaeve, Giusseppe Marra, Thomas Winters, Yaniv Aspis, Robin Smet,
and Anna Kuzina for helpful discussions. For our experiments, we used the DAS-6 compute cluster
[6]. We also thank SURF (www.surf.nl) for its support in using the Lisa Compute Cluster."
REFERENCES,0.34210526315789475,References
REFERENCES,0.3447368421052632,"[1] Kareem Ahmed, Stefano Teso, Kai-Wei Chang, Guy Van den Broeck, and Antonio Vergari.
Semantic probabilistic layers for neuro-symbolic learning. Advances in Neural Information
Processing Systems, 35:29944–29959, 2022."
REFERENCES,0.3473684210526316,"[2] Kareem Ahmed, Eric Wang, Kai-Wei Chang, and Guy Van den Broeck. Neuro-Symbolic
Entropy Regularization. In The 38th Conference on Uncertainty in Artiﬁcial Intelligence, June
2022."
REFERENCES,0.35,"[3] Yaniv Aspis, Krysia Broda, Jorge Lobo, and Alessandra Russo. Embed2Sym - Scalable Neuro-
Symbolic Reasoning via Clustered Embeddings. In Proceedings of the Nineteenth International
Conference on Principles of Knowledge Representation and Reasoning, pages 421–431, Haifa,
Israel, July 2022. International Joint Conferences on Artiﬁcial Intelligence Organization. ISBN
978-1-956792-01-0. doi: 10.24963/kr.2022/44."
REFERENCES,0.3526315789473684,"[4] Eriq Augustine, Connor Pryor, Charles Dickens, Jay Pujara, William Yang Wang, and Lise
Getoor. Visual sudoku puzzle classiﬁcation: A suite of collective neuro-symbolic tasks. In
International Workshop on Neural-Symbolic Learning and Reasoning (NeSy), Windsor, United
Kingdom, 2022."
REFERENCES,0.35526315789473684,"[5] Samy Badreddine, Artur d’Avila Garcez, Luciano Seraﬁni, and Michael Spranger. Logic
Tensor Networks. Artiﬁcial Intelligence, 303:103649, February 2022. ISSN 0004-3702. doi:
10.1016/j.artint.2021.103649."
REFERENCES,0.35789473684210527,"[6] Henri Bal, Dick Epema, Cees de Laat, Rob van Nieuwpoort, John Romein, Frank Seinstra, Cees
Snoek, and Harry Wijshoff. A medium-scale distributed system for computer science research:
Infrastructure for the long term. Computer, 49(5):54–63, 2016."
REFERENCES,0.3605263157894737,"[7] Tomas Balyo, Marijn J. H. Heule, Markus Iser, Matti J¨arvisalo, Martin Suda, Helsinki Institute
for Information Technology, Constraint Reasoning and Optimization research group / Matti
J¨arvisalo, and Department of Computer Science. Proceedings of SAT Competition 2022 : Solver
and Benchmark Descriptions. 2022."
REFERENCES,0.3631578947368421,"[8] Marc G Bellemare, Will Dabney, and R´emi Munos. A distributional perspective on reinforce-
ment learning. In International Conference on Machine Learning, pages 449–458. PMLR,
2017."
REFERENCES,0.36578947368421055,"[9] Emmanuel Bengio, Moksh Jain, Maksym Korablyov, Doina Precup, and Yoshua Bengio. Flow
network based generative models for non-iterative diverse candidate generation. Advances in
Neural Information Processing Systems, 34:27381–27394, 2021."
REFERENCES,0.3684210526315789,"[10] Yoshua Bengio, Salem Lahlou, Tristan Deleu, Edward J. Hu, Mo Tiwari, and Emmanuel Bengio.
GFlowNet Foundations, August 2022."
REFERENCES,0.37105263157894736,"[11] Mathieu Blondel, Quentin Berthet, Marco Cuturi, Roy Frostig, Stephan Hoyer, Felipe Llinares-
L´opez, Fabian Pedregosa, and Jean-Philippe Vert. Efﬁcient and modular implicit differentiation.
Advances in Neural Information Processing Systems, 35:5230–5242, 2022."
REFERENCES,0.3736842105263158,"[12] Gerhard Brewka, Thomas Eiter, and Mirosław Truszczy´nski. Answer set programming at a
glance. Communications of the ACM, 54(12):92–103, 2011."
REFERENCES,0.3763157894736842,"[13] Mark Chavira and Adnan Darwiche. On probabilistic inference by weighted model counting.
Artiﬁcial Intelligence, 172(6):772–799, April 2008. ISSN 0004-3702. doi: 10.1016/j.artint.
2007.11.002."
REFERENCES,0.37894736842105264,"[14] Xi Chen, Diederik P. Kingma, Tim Salimans, Yan Duan, Prafulla Dhariwal, John Schulman,
Ilya Sutskever, and Pieter Abbeel. Variational Lossy Autoencoder. In International Conference
on Learning Representations, July 2022."
REFERENCES,0.3815789473684211,"[15] Alessandro Daniele, Emile van Krieken, Luciano Seraﬁni, and Frank van Harmelen. Reﬁning
neural network predictions using background knowledge. Machine Learning, March 2023.
ISSN 1573-0565. doi: 10.1007/s10994-023-06310-3."
REFERENCES,0.38421052631578945,"[16] Luc De Raedt, Robin Manhaeve, Sebastijan Dumancic, Thomas Demeester, and Angelika
Kimmig. Neuro-symbolic= neural+ logical+ probabilistic. In NeSy’19@ IJCAI, the 14th
International Workshop on Neural-Symbolic Learning and Reasoning, 2019."
REFERENCES,0.3868421052631579,"[17] Michelangelo Diligenti, Marco Gori, and Claudio Sacca. Semantic-based regularization for
learning and inference. Artiﬁcial Intelligence, 244:143–165, 2017."
REFERENCES,0.3894736842105263,"[18] Eleonora Giunchiglia and Thomas Lukasiewicz. Multi-Label Classiﬁcation Neural Networks
with Hard Logical Constraints. J. Artif. Intell. Res., 72:759–818, 2021. doi: 10.1613/jair.1.
12850."
REFERENCES,0.39210526315789473,"[19] Eleonora Giunchiglia, Mihaela Catalina Stoian, and Thomas Lukasiewicz. Deep Learning with
Logical Constraints. In Luc De Raedt, editor, Proceedings of the Thirty-First International
Joint Conference on Artiﬁcial Intelligence, IJCAI 2022, Vienna, Austria, 23-29 July 2022, pages
5478–5485. ijcai.org, 2022. doi: 10.24963/ijcai.2022/767."
REFERENCES,0.39473684210526316,"[20] Mattia Medina Grespan, Ashim Gupta, and Vivek Srikumar. Evaluating Relaxations of Logic
for Neural Networks: A Comprehensive Study. arXiv:2107.13646 [cs], July 2021."
REFERENCES,0.3973684210526316,"[21] Bernd Gutmann, Manfred Jaeger, and Luc De Raedt. Extending ProbLog with Continuous
Distributions. In Paolo Frasconi and Francesca A. Lisi, editors, Inductive Logic Programming,
Lecture Notes in Computer Science, pages 76–91, Berlin, Heidelberg, 2011. Springer. ISBN
978-3-642-21295-6. doi: 10.1007/978-3-642-21295-6 12."
REFERENCES,0.4,"[22] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-
age recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition, pages 770–778, 2016."
REFERENCES,0.4026315789473684,"[23] Jiani Huang, Ziyang Li, Binghong Chen, Karan Samel, Mayur Naik, Le Song, and Xujie Si.
Scallop: From Probabilistic Deductive Databases to Scalable Differentiable Reasoning. In
Advances in Neural Information Processing Systems, May 2021."
REFERENCES,0.4052631578947368,"[24] Eric Jang, Shixiang Gu, and Ben Poole. Categorical reparameterization with gumbel-softmax.
In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April
24-26, 2017, Conference Track Proceedings, 2017."
REFERENCES,0.40789473684210525,"[25] Diederik P. Kingma and Jimmy Ba.
Adam:
A Method for Stochastic Optimization.
arXiv:1412.6980 [cs], January 2017."
REFERENCES,0.4105263157894737,"[26] Diederik P. Kingma and Max Welling. Auto-encoding variational bayes. In 2nd International
Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014,
Conference Track Proceedings, 2014."
REFERENCES,0.4131578947368421,"[27] Thomas N. Kipf and Max Welling. Semi-Supervised Classiﬁcation with Graph Convolutional
Networks, February 2017."
REFERENCES,0.41578947368421054,"[28] Doga Kisa and Guy Van den Broeck. Probabilistic sentential decision diagrams. Proceedings of
the 14th International Conference on Principles of Knowledge Representation and Reasoning
(KR), pages 558–567, 2014."
REFERENCES,0.41842105263157897,"[29] Wouter Kool, Herke van Hoof, and Max Welling. Buy 4 REINFORCE samples, get a baseline
for free! page 14, 2019."
REFERENCES,0.42105263157894735,[30] Yann LeCun and Corinna Cortes. MNIST handwritten digit database. 2010.
REFERENCES,0.4236842105263158,"[31] Zenan Li, Yuan Yao, Taolue Chen, Jingwei Xu, Chun Cao, Xiaoxing Ma, and Jian L\”{u}.
Softened Symbol Grounding for Neuro-symbolic Systems. In The Eleventh International
Conference on Learning Representations, February 2023."
REFERENCES,0.4263157894736842,"[32] Chen Liang, Mohammad Norouzi, Jonathan Berant, Quoc V. Le, and Ni Lao. Memory aug-
mented policy optimization for program synthesis and semantic parsing. In Samy Bengio,
Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicol`o Cesa-Bianchi, and Roman
Garnett, editors, Advances in Neural Information Processing Systems 31: Annual Conference on
Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montr´eal,
Canada, pages 10015–10027, 2018."
REFERENCES,0.42894736842105263,"[33] Nikolay Malkin, Moksh Jain, Emmanuel Bengio, Chen Sun, and Yoshua Bengio. Trajectory
balance: Improved credit assignment in GFlowNets. In NeurIPS, 2022."
REFERENCES,0.43157894736842106,"[34] Nikolay Malkin, Salem Lahlou, Tristan Deleu, Xu Ji, Edward J. Hu, Katie E. Everett, Dinghuai
Zhang, and Yoshua Bengio. GFlowNets and variational inference. In The Eleventh International
Conference on Learning Representations, February 2023."
REFERENCES,0.4342105263157895,"[35] Robin Manhaeve, Sebastijan Dumanˇci´c, Angelika Kimmig, Thomas Demeester, and Luc
De Raedt. DeepProbLog: Neural probabilistic logic programming. In Samy Bengio, Hanna M
Wallach, Hugo Larochelle, Kristen Grauman, Nicol`o Cesa-Bianchi, and Roman Garnett, edi-
tors, Advances in Neural Information Processing Systems 31: Annual Conference on Neural
Information Processing Systems 2018, NeurIPS 2018, 3-8 December 2018, Montr´eal, Canada,
2018."
REFERENCES,0.4368421052631579,"[36] Robin Manhaeve, Sebastijan Dumanˇci´c, Angelika Kimmig, Thomas Demeester, and Luc
De Raedt. Neural probabilistic logic programming in DeepProbLog. Artiﬁcial Intelligence, 298:
103504, 2021. ISSN 0004-3702. doi: 10.1016/j.artint.2021.103504."
REFERENCES,0.4394736842105263,"[37] Robin Manhaeve, Giuseppe Marra, and Luc De Raedt. Approximate inference for neural
probabilistic logic programming. In Proceedings of the 18th International Conference on
Principles of Knowledge Representation and Reasoning, pages 475–486, November 2021. doi:
10.24963/kr.2021/45."
REFERENCES,0.4421052631578947,"[38] Giuseppe Marra, Sebastijan Dumanˇci´c, Robin Manhaeve, and Luc De Raedt. From Statistical
Relational to Neural Symbolic Artiﬁcial Intelligence: A Survey. arXiv:2108.11451 [cs], August
2021."
REFERENCES,0.44473684210526315,"[39] Thomas Minka. Estimating a dirichlet distribution, 2000."
REFERENCES,0.4473684210526316,"[40] Shakir Mohamed, Mihaela Rosca, Michael Figurnov, and Andriy Mnih. Monte carlo gradient
estimation in machine learning. Journal of Machine Learning Research, 21:132:1–132:62,
2020."
REFERENCES,0.45,"[41] Mathias Niepert, Pasquale Minervini, and Luca Franceschi. Implicit MLE: Backpropagating
through discrete exponential family distributions. Advances in Neural Information Processing
Systems, 34:14567–14579, 2021."
REFERENCES,0.45263157894736844,"[42] Felix Petersen. Learning with Differentiable Algorithms, September 2022."
REFERENCES,0.45526315789473687,"[43] Marin Vlastelica Poganˇci´c, Anselm Paulus, Vit Musil, Georg Martius, and Michal Rolinek.
Differentiation of blackbox combinatorial solvers. In International Conference on Learning
Representations, 2020."
REFERENCES,0.45789473684210524,"[44] Connor Pryor, Charles Dickens, Eriq Augustine, Alon Albalak, William Wang, and Lise Getoor.
NeuPSL: Neural Probabilistic Soft Logic, June 2022."
REFERENCES,0.4605263157894737,"[45] Danilo Rezende and Shakir Mohamed. Variational Inference with Normalizing Flows. In
Proceedings of the 32nd International Conference on Machine Learning, pages 1530–1538.
PMLR, June 2015."
REFERENCES,0.4631578947368421,"[46] Matthew Richardson and Pedro Domingos. Markov logic networks. Machine Learning, 62(1):
107–136, February 2006. ISSN 1573-0565. doi: 10.1007/s10994-006-5833-1."
REFERENCES,0.46578947368421053,"[47] Subham Sekhar Sahoo, Anselm Paulus, Marin Vlastelica, V´ıt Musil, Volodymyr Kuleshov, and
Georg Martius. Backpropagation through Combinatorial Algorithms: Identity with Projection
Works. In The Eleventh International Conference on Learning Representations, February 2023."
REFERENCES,0.46842105263157896,"[48] Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne van den Berg, Ivan Titov, and
Max Welling. Modeling relational data with graph convolutional networks. In Aldo Gangemi,
Roberto Navigli, Maria-Esther Vidal, Pascal Hitzler, Rapha¨el Troncy, Laura Hollink, Anna
Tordai, and Mehwish Alam, editors, The Semantic Web, pages 593–607, Cham, 2018. Springer
International Publishing. ISBN 978-3-319-93417-4."
REFERENCES,0.4710526315789474,"[49] John Schulman, Nicolas Heess, Theophane Weber, and Pieter Abbeel. Gradient estimation
using stochastic computation graphs. In Advances in Neural Information Processing Systems,
2015."
REFERENCES,0.47368421052631576,"[50] Dimitar Shterionov, Joris Renkens, Jonas Vlasselaer, Angelika Kimmig, Wannes Meert, and
Gerda Janssens. The Most Probable Explanation for Probabilistic Logic Programs with An-
notated Disjunctions. In Jesse Davis and Jan Ramon, editors, Inductive Logic Programming,
Lecture Notes in Computer Science, pages 139–153, Cham, 2015. Springer International
Publishing. ISBN 978-3-319-23708-4. doi: 10.1007/978-3-319-23708-4 10."
REFERENCES,0.4763157894736842,"[51] Jakub M. Tomczak. Deep Generative Modeling. Springer International Publishing, Cham, 2022.
ISBN 978-3-030-93157-5 978-3-030-93158-2. doi: 10.1007/978-3-030-93158-2."
REFERENCES,0.4789473684210526,"[52] Frank van Harmelen and Annette ten Teije. A Boxology of Design Patterns for Hybrid Learning
and Reasoning Systems. Journal of Web Engineering, 18(1):97–124, 2019. ISSN 1540-9589.
doi: 10.13052/jwe1540-9589.18133."
REFERENCES,0.48157894736842105,"[53] Emile van Krieken, Jakub Tomczak, and Annette Ten Teije. Storchastic: A framework for
general stochastic automatic differentiation. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S.
Liang, and J. Wortman Vaughan, editors, Advances in Neural Information Processing Systems,
volume 34, pages 7574–7587. Curran Associates, Inc., 2021."
REFERENCES,0.4842105263157895,"[54] Emile van Krieken, Erman Acar, and Frank van Harmelen. Analyzing differentiable fuzzy logic
operators. Artiﬁcial Intelligence, 302:103602, 2022. ISSN 0004-3702. doi: 10.1016/j.artint.
2021.103602."
REFERENCES,0.4868421052631579,"[55] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez,
Lukasz Kaiser, and Illia Polosukhin. Attention Is All You Need, December 2017."
REFERENCES,0.48947368421052634,"[56] Thomas Winters, Giuseppe Marra, Robin Manhaeve, and Luc De Raedt. DeepStochLog: Neural
Stochastic Logic Programming. In Proceedings of the First MiniCon Conference, February
2022."
REFERENCES,0.4921052631578947,"[57] Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, and Guy den Broeck. A semantic loss
function for deep learning with symbolic knowledge. In Jennifer Dy and Andreas Krause,
editors, Proceedings of the 35th International Conference on Machine Learning, volume 80,
pages 5502–5511, Stockholmsm¨assan, Stockholm Sweden, 2018. PMLR."
REFERENCES,0.49473684210526314,"[58] Zhun Yang, Adam Ishay, and Joohyung Lee. NeurASP: Embracing neural networks into answer
set programming. In Christian Bessiere, editor, Proceedings of the Twenty-Ninth International
Joint Conference on Artiﬁcial Intelligence, IJCAI-20, pages 1755–1762. International Joint
Conferences on Artiﬁcial Intelligence Organization, July 2020. doi: 10.24963/ijcai.2020/243."
REFERENCES,0.49736842105263157,"[59] Chih-Kuan Yeh, Been Kim, Sercan O. Arik, Chun-Liang Li, Tomas Pﬁster, and Pradeep
Ravikumar. On Completeness-aware Concept-Based Explanations in Deep Neural Networks,
February 2022."
REFERENCES,0.5,"[60] Choi Yoojung, Antonio Vergari, and Guy Van den Broeck. Probabilistic circuits: A unifying
framework for tractable probabilistic models. 2020."
REFERENCES,0.5026315789473684,"A
Derivation of prediction-only variant loss"
REFERENCES,0.5052631578947369,"Ep(P)

−Ep(y|P)[log qφ(y|P)]

(10)"
REFERENCES,0.5078947368421053,"= −Ep(P)

Ep(w,y|P)[log qφ(y|P)]

(11)"
REFERENCES,0.5105263157894737,"= −Ep(P,w) [log qφ(c(w)|P)]
(12)"
REFERENCES,0.5131578947368421,"LP red(φ) = −log qφ(c(w)|P),
P, w ∼p(P, w)
(13)"
REFERENCES,0.5157894736842106,"In line 11, we marginalize out w, and use the fact that y is deterministic given w."
REFERENCES,0.5184210526315789,"B
Constrained structured output prediction"
REFERENCES,0.5210526315789473,"We consider how to implement the constrained structured output prediction task considered in (for
example) [2, 1, 57] in the A-NESI framework. Here, the goal is to learn a mapping of some X to a
structured output space W, where we have some constraint c(w) that returns 1 if the background
knowledge holds, and 0 otherwise. We can model the constraints using Y = {0, 1}; that is, the
‘output’ in our problem setup is whether w satisﬁes the background knowledge c or not. We give an
example of this setting in Figure 6."
REFERENCES,0.5236842105263158,"Then, we design the inference model as follows. 1) qφ(y|P) is tasked with predicting the probability
that randomly sampled outputs w ∼p(w|P) will satisfy the background knowledge. 2) qψ(w|y =
1, P) is an approximate posterior over structured outputs w that satisfy the background knowledge c."
REFERENCES,0.5263157894736842,"This setting changes the interpretation of the set W from unobserved worlds to observed outputs. We
will train our perception module using a “strongly” supervised learning loss where x, w ∼DL:"
REFERENCES,0.5289473684210526,"LP erc(θ) = −log qψ(w|y = 1, P = fθ(x)).
(14)"
REFERENCES,0.531578947368421,"If we also have unlabeled data DU, we can use the prediction model to ensure the perception
model gives high probabilities for worlds that satisfy the background knowledge. This approximates
Semantic Loss [57]: Given x ∼DU,"
REFERENCES,0.5342105263157895,"LSL(θ) = −log qφ(y = 1|P = fθ(x)).
(15)"
REFERENCES,0.5368421052631579,"That is, we have some input x for which we have no labelled output. Then, we increase the probability
that the belief P the perception module fθ predicts for x would sample structured outputs w that
satisfy the background knowledge."
REFERENCES,0.5394736842105263,"Training the inference model in this setting can be challenging if the problem is very constrained.
Then, random samples P, w ∼p(P, w) will usually not satisfy the background knowledge. Since
we are only in the case that y = 1, we can choose to sample from the inference model qφ and exploit
the symbolic pruner to obtain samples that are guaranteed to satisfy the background knowledge.
Therefore, we modify equation 8 to the on-policy joint matching loss"
REFERENCES,0.5421052631578948,"LExpl(P, φ, ψ) = Eqψ(w|y=1,P)"
REFERENCES,0.5447368421052632,"""
log qφ,ψ(w, y = 1|P)"
REFERENCES,0.5473684210526316,p(w|P) 2# (16)
REFERENCES,0.55,"Here, we incur some sampling bias by not sampling structured outputs from the true posterior, but this
bias will reduce as qφ becomes more accurate. We can also choose to combine the on- and off-policy
losses. Another option to make learning easier is using the suggestions of Section 3.2.2: factorize y
to make it more ﬁne-grained."
REFERENCES,0.5526315789473685,"C
A-NESI as a Gradient Estimation method"
REFERENCES,0.5552631578947368,"In this appendix, we discuss using the method A-NESI introduced for general gradient estimation [40].
We ﬁrst deﬁne the gradient estimation problem. Consider some neural network fθ that predicts the
parameters P of a distribution over unobserved variable z ∈Z: p(z|P = fθ(x)). This distribution
corresponds to the distribution over worlds p(w|P) in A-NESI. Additionally, assume we have some
deterministic function g(z) that we want to maximize in expectation. This maximization requires
estimating the gradient
∇θEp(z|P=fθ(x))[g(z)].
(17)"
REFERENCES,0.5578947368421052,"Common methods for estimating this gradient are reparameterization [26], which only applies
to continuous random variables and differentiable r, and the score function [40, 49] which has
notoriously high variance."
REFERENCES,0.5605263157894737,"Instead, our gradient estimation method learns an inference model qφ(r|P) to approximate the
distribution of outcomes r = g(z) for a given P. In A-NESI, this is the prediction network qφ(y|P)
that estimates the WMC problem of Equation 1. Approximating a distribution over outcomes is
similar to the idea of distributional reinforcement learning [8]. Our approach is general: Unlike
reparameterization, we can use inference models in settings with discrete random variables z and
non-differentiable downstream functions g."
REFERENCES,0.5631578947368421,"We derive the training loss for our inference model similar to that in Section 3.2.1. First, we deﬁne
the joint on latents z and outcomes r like the joint process in 6 as p(r, z|P) = p(z|P) · δg(z)(r),
where δg(z)(r) is the dirac-delta distribution that checks if the output of g on z is equal to r. Then
we introduce a prior over distribution parameters p(P), much like the prior over beliefs in A-NESI.
An obvious choice is to use a prior conjugate to p(z|P). We minimize the expected KL-divergence
between p(r|P) and qφ(r|P):"
REFERENCES,0.5657894736842105,"Ep(P)[DKL(p||qφ)]
(18)"
REFERENCES,0.5684210526315789,"=Ep(P)

Ep(r|P)[log qφ(r|P)]

+ C
(19)"
REFERENCES,0.5710526315789474,=Ep(P) Z
REFERENCES,0.5736842105263158,"R
p(r|P) log qφ(r|P)]dr

+ C
(20)"
REFERENCES,0.5763157894736842,"Next, we marginalize over z, dropping the constant: Ep(P) Z Z Z"
REFERENCES,0.5789473684210527,"R
p(r, z|P) log qφ(r|P)]drdz

(21)"
REFERENCES,0.5815789473684211,=Ep(P) Z
REFERENCES,0.5842105263157895,"Z
p(z|P)
Z"
REFERENCES,0.5868421052631579,"R
δg(z)(r) log qφ(r|P)]drdz

(22)"
REFERENCES,0.5894736842105263,=Ep(P) Z
REFERENCES,0.5921052631578947,"Z
p(z|P) log qφ(g(z)|P)]dz

(23)"
REFERENCES,0.5947368421052631,"=Ep(P,z) [log qφ(g(z)|P)]
(24)"
REFERENCES,0.5973684210526315,This gives us a negative-log-likelihood loss function similar to Equation 7.
REFERENCES,0.6,"LInf(φ) = −log qφ(g(z)|P),
P, z ∼p(z, P)
(25)"
REFERENCES,0.6026315789473684,"where we sample from the joint p(z, P) = p(P)p(z|P)."
REFERENCES,0.6052631578947368,We use a trained inference model to get gradient estimates:
REFERENCES,0.6078947368421053,"∇PEp(z|P)[g(z)] ≈∇PEqφ(r|P)[r]
(26)"
REFERENCES,0.6105263157894737,"We use the chain rule to update the parameters θ. This requires a choice of distribution qφ(r|P)
for which computing the mean Eqφ(r|P)[r] is easy. The simplest option is to parameterize qφ with
a univariate normal distribution. We predict the mean and variance using a neural network with
parameters φ. For example, a neural network mφ would compute µ = mφ(P). Then, the mean
parameter is the expectation on the right-hand side of Equation 26. The loss function for fθ with this
parameterization is:
LNN(θ) = −mφ(fθ(x)),
x ∼D
(27)"
REFERENCES,0.6131578947368421,"Interestingly, like A-NESI, this gives zero-variance gradient estimates! Of course, bias comes from
the error in the approximation of qφ."
REFERENCES,0.6157894736842106,"Like A-NESI, we expect the success of this method to rely on the ease of ﬁnding a suitable prior
over P to allow proper training of the inference model. See the discussion in Section 3.2.3. We also
expect that, like in A-NESI, it will be easier to train the inference model if the output r = g(z) is
structured instead of a single scalar. We refer to Section 3.2.2 for this idea. Other challenges might be
stochastic and noisy output measurements of r and non-stationarity of g, for instance, when training
a VAE [26]."
REFERENCES,0.618421052631579,"v6+Tqh1zqth9KB6WFCd0WZBk="">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</latexit>P"
REFERENCES,0.6210526315789474,"="">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</latexit>A y B
A"
REFERENCES,0.6236842105263158,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</latexit>B B 1
REFERENCES,0.6263157894736842,x78+BfB/9eUz/8YBPzeaNwHfzn/4JKwoA=</latexit>(1 −PA)(1 −PB)
REFERENCES,0.6289473684210526,fB/9eUz/8YBPzeaNwHfzn/4JKwoA=</latexit>(1 −PA)(1 −PB)
REFERENCES,0.631578947368421,(1 −PA)PB
REFERENCES,0.6342105263157894,ZxGr/G08X3jvHRwA3e+Fvjn41/Hfz14N8H/zn475r6/nubmC8ahevg5/8DSyrB0w=</latexit>PA(1 −PB)
REFERENCES,0.6368421052631579,M/jR8O/nHw48F/D/63pr7/3ibmi0buOvjpF3rjwak=</latexit>(1 −PA)PB 1
REFERENCES,0.6394736842105263,"3x38dPCvg3+vqR9+sIn5rFH4HPzn/0u4v1M=</latexit>PAPB A, B A, ¬B"
REFERENCES,0.6421052631578947,"¬A, ¬B"
REFERENCES,0.6447368421052632,"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</latexit>¬A, B"
REFERENCES,0.6473684210526316,KHwO/vd/YjC+Gg=</latexit>PA
REFERENCES,0.65,V83ftN41HAavcbTxteN8ZFAzdk4+NHxo/Hnx/8M+Dfx38e019/71NzOeN3OfgP/8HN0rBsg=</latexit>PA + PB −PAPB A _ B
REFERENCES,0.6526315789473685,Satisfying worlds
REFERENCES,0.6552631578947369,Unsatisfying worlds
REFERENCES,0.6578947368421053,"p(w|P)
qφ(y|P) Sa"
REFERENCES,0.6605263157894737,"Figure 6: The tree ﬂow network corresponding to weighted model counting on the formula A ∨B.
Following edges upwards means setting the corresponding binary variable to true (and to false by
following edges downwards). We ﬁrst choose probabilities for the propositions A and B, then choose
whether we want to sample a world that satisﬁes the formula A ∨B. y = 1 is the WMC of A ∨B,
and equals its outgoing ﬂow PA + PB −PAPB. Terminal states (with two circles) represent choices
of the binary variables A and B. These are connected to a ﬁnal sink node, corresponding to the
prior over worlds p(w|P). The total ingoing and outgoing ﬂow to this network is 1, as we deal with
normalized probability distributions p and qφ."
REFERENCES,0.6631578947368421,"D
A-NESI and GFlowNets"
REFERENCES,0.6657894736842105,"A-NeSI is heavily inspired by the theory of GFlowNets [9, 10], and we use this theory to derive our
loss function. In the current section, we discuss these connections and the potential for future research
by taking inspiration from the GFlowNet literature. In this section, we will assume the reader is
familiar with the notation introduced in [10] and refer to this paper for the relevant background."
REFERENCES,0.6684210526315789,"D.1
Tree GFlowNet representation"
REFERENCES,0.6710526315789473,"The main intuition is that we can treat the inference model qφ in Equation 3 as a ‘trivial’ GFlowNet.
We refer to Figure 6 for an intuitive example. It shows what a ﬂow network would look like for
the formula A ∨B. We take the reward function R(w, y) = p(w, y). We represent states s by
s = (P, y1:i, w1:j), that is, the belief P, a list of some dimensions of the output instantiated with a
value and a list of some dimensions of the world assigned to some value. Actions a set some value to
the next output or world variable, i.e., A(s) = Yi+1 or A(s) = Wj+1."
REFERENCES,0.6736842105263158,"Note that this corresponds to a ﬂow network that is a tree everywhere but at the sink since the state
representation conditions on the whole trajectory observed so far. We demonstrate this in Figure 6.
We assume there is some ﬁxed ordering on the different variables in the world, which we generate
the value of one by one. Given this setup, Figure 6 shows that the branch going up from the node y
corresponds to the regular weighted model count (WMC) introduced in Equation 1."
REFERENCES,0.6763157894736842,"The GFlowNet forward distribution PF is qφ as deﬁned in Equation 3. The backward distribution
PB is p(w, y|P) at the sink node, which chooses a terminal node. Then, since we have a tree, this
determines the complete trajectory from the terminal node to the source node. Thus, at all other states,
the backward distribution is deterministic. Since our reward function R(w, y, P) = p(w, y|P) is
normalized, we trivially know the partition function Z(P) = P w
P"
REFERENCES,0.6789473684210526,"y R(w, y|P) = 1."
REFERENCES,0.6815789473684211,"D.2
Lattice GFlowNet representation"
REFERENCES,0.6842105263157895,"Our setup of the generative process assumes we are generating each variable in the world in some
order. This is ﬁne for some problems like MNISTAdd, where we can see the generative process
as ‘reading left to right’. For other problems, such as Sudoku, the order in which we would like to
generate the symbols is less obvious. Would we generate block by block? Row by row? Column by
column? Or is the assumption that it needs to be generated in some ﬁxed order ﬂawed by itself? P
y
1"
REFERENCES,0.6868421052631579,PyN3Xr2ZWN9fdL4beP3jScNp9FrPGt81bhoXDZwQzZ+aPy98Y+Dvx78+BfB/9eUz/8YBPzeaNwHfzn/4JKwoA=</latexit>(1 −PA)(1 −PB)
REFERENCES,0.6894736842105263,ZWN9fdL4beP3jScNp9FrPGt81bhoXDZwQzZ+aPy98Y+Dvx78+BfB/9eUz/8YBPzeaNwHfzn/4JKwoA=</latexit>(1 −PA)(1 −PB)
REFERENCES,0.6921052631578948,(1 −PA)PB
REFERENCES,0.6947368421052632,=</latexit>PA(1 −PB)
REFERENCES,0.6973684210526315,48F/D/63pr7/3ibmi0buOvjpF3rjwak=</latexit>(1 −PA)PB 1
REFERENCES,0.7,7Ipr8MSg8QjtWHBaNMFUlsqKN48ajnlV4Jm423n0OkeHn1jt5/2Vh/Pmr8ofHxpOG0+g1nje+apw3Lhq4cdv4vHPxo8H3x38dPCvg3+vqR9+sIn5rFH4HPzn/0u4v1M=</latexit>PAPB
REFERENCES,0.7026315789473684,Go4bT6DWeNr5tnDcuGrjhNX5q/Nz458GPB/8+M/Bf9fU9/bxHzZKHwO/vd/YjC+Gg=</latexit>PA
REFERENCES,0.7052631578947368,xteN8ZFAzdk4+NHxo/Hnx/8M+Dfx38e019/71NzOeN3OfgP/8HN0rBsg=</latexit>PA + PB −PAPB A _ B
REFERENCES,0.7078947368421052,Satisfying worlds
REFERENCES,0.7105263157894737,Unsatisfying worlds
REFERENCES,0.7131578947368421,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</latexit>p(w|P) {}
REFERENCES,0.7157894736842105,"{}
{A, B} {A} {B}"
REFERENCES,0.718421052631579,3+vqR9+sIn5rFH4HPzn/0u4v1M=</latexit>PAPB 0 Sa
REFERENCES,0.7210526315789474,"="">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</latexit>p(y|P)"
REFERENCES,0.7236842105263158,"Figure 7: The lattice ﬂow network corresponding to weighted model counting on the formula A ∨B.
In this representation, nodes represent sets of included propositions. Terminal states represent sets of
random variables such that A ∨B is true given y = 1, or false otherwise."
REFERENCES,0.7263157894736842,"In this section, we consider a second GFlowNet representation for the inference model that represents
states using sets instead of lists. We again refer to Figure 7 for the resulting ﬂow network of
this representation for A ∨B. We represent states using s = (P, {yi}i∈IY , {wi}i∈IW ), where
IY ⊆{1, ..., kY } and IW ⊆{1, ..., kW } denote the set of variables for which a value is chosen. The
possible actions from some state correspond to A(s) = S"
REFERENCES,0.7289473684210527,"i̸∈IW Wi (and analogous for when y is not
yet completely generated). For each variable in W for which we do not have the value yet, we add its
possible values to the action space."
REFERENCES,0.7315789473684211,"With this representation, the resulting ﬂow network is no longer a tree but a DAG, as the order in
which we generate the different variables is now different for every trajectory. What do we gain
from this? When we are primarily dealing with categorical variables, the two gains are 1) we no
longer need to impose an ordering on the generative process, and 2) it might be easier to implement
parameter sharing in the neural network that predicts the forward distributions, as we only need a
single set encoder that can be reused throughout the generative process."
REFERENCES,0.7342105263157894,"However, the main gain of the set-based approach is when worlds are all (or mostly) binary random
variables. We illustrate this in Figure 7. Assume W = {0, 1}kW . Then we can have the following state
and action representations: s = (P, y, IW ), where IW ⊆{1, ..., kW } and A(s) = {1, ..., kW } \ IW .
The intuition is that IW contains the set of all binary random variables that are set to 1 (i.e., true), and
{1, ..., kW } \ IW is the set of variables set to 0 (i.e., false). The resulting ﬂow network represents
a partial order over the set of all subsets of {1, ..., kW }, which is a lattice, hence the name of this
representation."
REFERENCES,0.7368421052631579,"With this representation, we can signiﬁcantly reduce the size and computation of the ﬂow network
required to express the WMC problem. As an example, compare Figures 6 and 7, which both
represent the WMC of the formula A ∨B. We no longer need two nodes in the branch y = 0 to
represent that we generate A and B to be false, as the initial empty set {} already implies they are.
This will save us two nodes. Similarly, we can immediately stop generating at {A} and {B}, and no
longer need to generate the other variable as false, which also saves a computation step."
REFERENCES,0.7394736842105263,"While this is theoretically appealing, the three main downsides are 1) PB is no longer trivial to
compute; 2) we have to handle the fact that we no longer have a tree, meaning there is no longer a
unique optimal PF and PB; and 3) parallelization becomes much trickier. We leave exploring this
direction in practice for future work."
REFERENCES,0.7421052631578947,"E
Analyzing the Joint Matching Loss"
REFERENCES,0.7447368421052631,"This section discusses the loss function we use to train the joint variant in Equation 8. We recommend
interested readers ﬁrst read Appendix D.1. Throughout this section, we will refer to p := p(w, y|P)
(Equation 5) and q := qφ,ψ(w, y|P) (Equation 2). We again refer to [10] for notational background."
REFERENCES,0.7473684210526316,"E.1
Trajectory Balance"
REFERENCES,0.75,"We derive our loss function from the recently introduced Trajectory Balance loss for GFlowNets,
which is proven to approximate the true Markovian ﬂow when minimized. This means sampling from
the GFlowNet allows sampling in proportion to reward R(sn) = p. The Trajectory Balance loss is
given by"
REFERENCES,0.7526315789473684,"L(τ) =

log F(s0) Qn
t=1 PF (st|st−1)
R(sn) Qn
t=1 PB(st−1|st)"
REFERENCES,0.7552631578947369,"2
,
(28)"
REFERENCES,0.7578947368421053,"where s0 is the source state, in our case P, and sn is some terminal state that represents a full
generation of y and w. In the tree representation of GFlowNets for inference models (see Appendix
D.1), this computation becomes quite simple:"
REFERENCES,0.7605263157894737,"1. F(s0) = 1, as R(sn) = p is normalized;
2. Qn
t=1 PF (st|st−1) = q: The forward distribution corresponds to the inference model
qφ(w, y|P);
3. R(sn) = p, as we deﬁne the reward to be the true joint probability distribution p(w, y|P);
4. Qn
t=1 PB(st−1|st) = 1, since the backward distribution is deterministic in a tree."
REFERENCES,0.7631578947368421,"Therefore, the trajectory balance loss for (tree) inference models is"
REFERENCES,0.7657894736842106,"L(P, y, w) =

log q p"
REFERENCES,0.7684210526315789,"2
= (log q −log p)2 ,
(29)"
REFERENCES,0.7710526315789473,"i.e., the term inside the expectation of the joint matching loss in Equation 8. This loss function is
stable because we can sum the individual probabilities in log-space."
REFERENCES,0.7736842105263158,"A second question might then be how we obtain ‘trajectories’ τ = (P, y, w) to minimize this loss
over. The paper on trajectory balance [33] picks τ on-policy, that is, it samples τ from the forward
distribution (in our case, the inference model qφ,ψ). We discussed when this might be favorable in
our setting in Appendix B (Equation 16). However, the joint matching loss as deﬁned in Equation 8
is off-policy, as we sample from p and not from qφ,ψ."
REFERENCES,0.7763157894736842,"E.2
Relation to common divergences"
REFERENCES,0.7789473684210526,"These questions open quite some design space, as was recently noted when comparing the trajectory
balance loss to divergences commonly used in variational inference [34]. Redeﬁning PF = q and
PB = p, the authors compare the trajectory balance loss with the KL-divergence and the reverse
KL-divergence and prove that"
REFERENCES,0.781578947368421,∇φDKL(q||p) = 1
REFERENCES,0.7842105263157895,"2Eτ∼q[∇φL(τ)].
(30)"
REFERENCES,0.7868421052631579,"That is, the on-policy objective minimizes the reverse KL-divergence between p and q. We do not
quite ﬁnd such a result for the off-policy version we use for the joint matching loss in Equation 8:"
REFERENCES,0.7894736842105263,"∇φDKL(p||q) = −Eτ∼p[∇φ log q]
(31)
Eτ∼p[∇φL(τ)] = −2Eτ∼p[(log p −log q)∇φ log q]
(32)"
REFERENCES,0.7921052631578948,"So why do we choose to minimize the joint matching loss rather than the (forward) KL divergence
directly? This is because, as is clear from the above equations, it takes into account how far the
‘predicted’ log-probability log q currently is from log p. That is, given a sample τ, if log p < log q, the
joint matching loss will actually decrease log q. Instead, the forward KL will increase the probability
for every sample it sees, and whether this particular sample will be too likely under q can only be
derived through sampling many trajectories."
REFERENCES,0.7947368421052632,"Furthermore, we note that the joint matching loss is a ‘pseudo’ f-divergence with f(t) = t log2 t [34].
It is not a true f-divergence since t log2 t is not convex. A related well-known f-divergence is the
Hellinger distance given by"
REFERENCES,0.7973684210526316,H2(p||q) = 1
REFERENCES,0.8,"2Eτ∼p[(√p −√q)2].
(33)"
REFERENCES,0.8026315789473685,"This divergence similarly takes into account the distance between p and q in its derivatives through
squaring. However, it is much less stable than the joint matching loss since both p and q are computed
by taking the product over many small numbers. Computing the square root over this will be much
less numerically stable than taking the logarithm of each individual probability and summing."
REFERENCES,0.8052631578947368,"Finally, we note that we minimize the on-policy joint matching Eq[(log p −log q)2] by taking
derivatives Eq[∇φ,ψ(log p −log q)2]. This is technically not minimizing the joint matching, since it
ignores the gradient coming from sampling from q."
REFERENCES,0.8078947368421052,"F
Dirichlet prior"
REFERENCES,0.8105263157894737,"This section describes how we ﬁt the Dirichlet prior p(P) used to train the inference model. During
training, we keep a dataset of the last 2500 observations of P = fθ(x). We have to drop observations
frequently because θ changes during training, meaning that the empirical distribution over Ps changes
as well."
REFERENCES,0.8131578947368421,"We perform an MLE ﬁt on kW independent Dirichlet priors to get parameters α for each. The
log-likelihood of the Dirichlet distribution cannot be found in closed form [39]. However, since
its log-likelihood is convex, we run ADAM [25] for 50 iterations with a learning rate of 0.01 to
minimize the negative log-likelihood. We refer to [39] for details on computing the log-likelihood
and alternative options. Since the Dirichlet distribution accepts positive parameters, we apply the
softplus function on an unconstrained parameter during training. We initialize all parameters at 0.1."
REFERENCES,0.8157894736842105,"We added L2 regularization on the parameters. This is needed because at the beginning of training,
all observations P = fθ(x) represent uniform beliefs over digits, which will all be nearly equal.
Therefore, ﬁtting the Dirichlet on the data will give increasingly higher parameter values, as high
parameter values represent low-entropy Dirichlet distributions that produce uniform beliefs. When
the Dirichlet is low-entropy, the inference models learn to ignore the input belief P, as it never
changes. The L2 regularization encourages low parameter values, which correspond to high-entropy
Dirichlet distributions."
REFERENCES,0.8184210526315789,"G
Designing symbolic pruners"
REFERENCES,0.8210526315789474,"We next discuss four high-level approaches for designing the optional symbolic pruner, each with
differing tradeoffs in accuracy, engineering time and efﬁciency:"
REFERENCES,0.8236842105263158,"1. Mathematically derive efﬁcient solvers. For simple problems, we could mathematically
derive an exact solver. One example of an efﬁcient symbolic pruner, along with a proof
for exactness, is given for Multi-digit MNISTAdd in Appendix H. This pruner is linear-
time. However, for most problems we expect the pruner to be much more computationally
expensive.
2. Use SAT-solvers. Add the sampled symbols y and w1:i to a CNF-formula, and ask an
SAT-solver if there is an extension wi+1:kW that satisﬁes the CNF-formula. SAT-solvers are
a general approach that will work with every function c, but using them comes at a cost.
The ﬁrst is that we would require grounding the logical representation of the problem.
Furthermore, to do SAT-solving, we have to solve a linear amount of NP-hard problems.
However, competitive SAT solvers can deal with substantial problems due to years of
advances in their design [7], and a linear amount of NP-hard calls is a lower complexity
class than #P hard. Using SAT-solvers will be particularly attractive in problem settings
where safety and veriﬁability are critical.
3. Prune with local constraints. In many structured prediction tasks, we can use local
constraints of the symbolic problem to prune paths that are guaranteed to lead to branches
that can never create possible worlds. However, local constraints do not guarantee that each
non-pruned path contains a possible world, but this does not bias the inference model, as
the neural network will (eventually) learn when an expansion would lead to an unsatisﬁable
state.
One example is the shortest path problem, where we ﬁlter out directions that would lead
outside the N × N grid, or that would create cycles (See Appendix I.3). However, this only
ensures we ﬁnd a path, but does not ensure it is the shortest one."
REFERENCES,0.8263157894736842,"4. Learn the pruner. Finally, we can learn the pruner, that is, we can train a neural network to
learn satisﬁability checking. One possible approach is to reuse the inference model trained
on the belief P that uniformly distributes mass over all worlds.
Learned pruners will be as quick as regular inference models, but are less accurate than
symbolic pruners and will not guarantee that constraints are always satisﬁed during test-time.
We leave experimenting with learning the pruner for future work."
REFERENCES,0.8289473684210527,"H
MNISTAdd Symbolic Pruner"
REFERENCES,0.8315789473684211,"In this section, we describe a symbolic pruner for the Multi-digit MNISTAdd problem, which we
compute in time linear to N. Note that w1:N represents the ﬁrst number and wN+1:2N the second.
We deﬁne n1 = PN
i=1 wi · 10N−i−1 and n2 = PN
i=1 wN+i · 10N−i−1 for the integer representations
of these numbers, and y = PN+1
i=1 yi · 10N−i for the sum label encoded by y. We say that partial
generation w1:k has a completion if there is a wk+1:2N ∈{0, . . . , 9}2N−k such that n1 + n2 = y.
Proposition H.1. For all N ∈N, y ∈{0, 1} × {0, . . . , 9}N and partial generation w1:k−1 ∈
{0, . . . , 9}k with k ∈{1, . . . , 2N}, the following algorithm rejects all wk for which w1:k has no
completions, and accepts all wk for which there are:"
REFERENCES,0.8342105263157895,"• k ≤N: Let lk = Pk+1
i=1 yk · 10k+1−i and pk = Pk
i=1 wk · 10k−i. Let S = 1 if k = N or
if the (k + 1)th to (N + 1)th digit of y are all 9, and S = 0 otherwise. We compute two
boolean conditions for all wk ∈{0, . . . , 9}:"
REFERENCES,0.8368421052631579,"0 ≤lk −pk ≤10k −S
(34)
We reject all wk for which either condition does not hold."
REFERENCES,0.8394736842105263,"• k > N: Let n2 = y −n1.
We reject all wk ∈{0, . . . , 9} different from wk =
⌊
n2
10N−k−1 ⌋mod 10, and reject all wk if n2 < 0 or n2 ≥10N."
REFERENCES,0.8421052631578947,"Proof. For k > N, we note that n2 is ﬁxed given y and n1 through linearity of summation, and we
only consider k ≤N. We deﬁne ak = PN+1
i=k+2 yi · 10N+1−i as the sum of the remaining digits of y.
We note that y = lk · 10N−k + ak."
REFERENCES,0.8447368421052631,"Algorithm rejects wk without completions We ﬁrst show that our algorithm only rejects wk for
which no completion exists. We start with the constraint 0 ≤lk −pk, and show that whenever
this constraint is violated (i.e., pk > lk), w1:k has no completion. Consider the smallest possible
completion of wk+1:N: setting each to 0. Then n1 = pk · 10N−k. First, note that"
REFERENCES,0.8473684210526315,"10N−k > 10N−k −1 ≥ak
Next, add lk · 10N−k to both sides
(lk + 1) · 10N−k > lk · 10N−k + ak = y
By assumption, pk is an integer upper bound of lk and so pk ≥lk + 1. Therefore,
n1 = pk · 10N−k > y"
REFERENCES,0.85,"Since n1 is to be larger than y, n2 has to be negative, which is impossible."
REFERENCES,0.8526315789473684,"Next, we show the necessity of the second constraint. Assume the constraint is unnecessary, that is,
lk > pk + 10k −S. Consider the largest possible completion wk+1:N by setting each to 9. Then"
REFERENCES,0.8552631578947368,n1 = pk · 10N−k + 10N−k −1
REFERENCES,0.8578947368421053,= (pk + 1) · 10N−k −1
REFERENCES,0.8605263157894737,"We take n2 to be the maximum value, that is, n2 = 10N −1. Therefore,
n1 + n2 = 10N −(pk + 1) · 10N−k −2
We show that n1 + n2 < y. Since we again have an integer upper bound, we know lk ≥pk + 10k −
S + 1. Therefore,
y ≥(pk + 1 + 10k −S)10N−k + ak
≥n1 + n2 + 2 −S · 10N−k + ak
There are two cases."
REFERENCES,0.8631578947368421,"• S = 0. Then ak < 10N−k −1, and so"
REFERENCES,0.8657894736842106,y ≥n1 + n2 + 2 + ak > n1 + n2.
REFERENCES,0.868421052631579,"• S = 1. Then ak = 10N−k −1, and so"
REFERENCES,0.8710526315789474,y ≥n1 + n2 + 1 > n1 + n2.
REFERENCES,0.8736842105263158,"Algorithm accepts wk with completions Next, we show that our algorithm only accepts wk with
completions. Assume Equation 34 holds, that is, 0 ≤lk −pk ≤10k −S. We ﬁrst consider all possible
completions of w1:k. Note that pk ·10N−k ≤n1 ≤pk ·10N−k +10N−k −1 and 0 ≤n2 ≤10N −1,
and so
pk · 10N−k ≤n1 + n2 ≤(pk + 1) · 10N−k + 10N −2.
Similarly,
lk · 10N−k ≤y ≤(lk + 1) · 10N−k −1."
REFERENCES,0.8763157894736842,"By assumption, pk ≤lk, so pk · 10N−k ≤lk cot 10N−k. For the upper bound, we again consider
two cases. We use the second condition lk ≤10k + pk −S:"
REFERENCES,0.8789473684210526,"• S = 0. Then (since there are no trailing 9s),"
REFERENCES,0.881578947368421,y ≤(lk + 1) · 10N−k −2
REFERENCES,0.8842105263157894,≤(10k + pk + 1) · 10N−k −1
REFERENCES,0.8868421052631579,= (pk + 1) · 10N−k + 10N −2.
REFERENCES,0.8894736842105263,"• S = 1. Then with trailing 9s,"
REFERENCES,0.8921052631578947,y = (lk + 1) · 10N−k −1
REFERENCES,0.8947368421052632,≤(10k + pk) · 10N−k −1
REFERENCES,0.8973684210526316,= pk · 10N−k + 10N −1
REFERENCES,0.9,"≤(pk + 1) · 10N−k + 10N −2,"
REFERENCES,0.9026315789473685,since 10N−k ≥1.
REFERENCES,0.9052631578947369,"Therefore,
pk · 10N−k ≤y ≤(pk + 1) · 10N−k + 10N −2
and so there is a valid completion."
REFERENCES,0.9078947368421053,"I
Details of the experiments"
REFERENCES,0.9105263157894737,"I.1
Multi-digit MNISTAdd"
REFERENCES,0.9131578947368421,"Like [36, 37], we take the MNIST [30] dataset and use each digit exactly once to create data. We
follow [36] and require more unique digits for increasing N. Therefore, the training dataset will be
of size 60000/2N and the test dataset of size 10000/2N."
REFERENCES,0.9157894736842105,"I.1.1
Hyperparameters"
REFERENCES,0.9184210526315789,"We performed hyperparameter tuning on a held-out validation set by splitting the training data
into 50.000 and 10.000 digits, and forming the training and validation sets from these digits. We
progressively increased N from N = 1, N = 3, N = 4 to N = 8 during tuning to get improved
insights into what hyperparameters are important. The most important parameter, next to learning rate,
is the weight of the L2 regularization on the Dirichlet prior’s parameters which should be very high.
We used ADAM [25] throughout. We ran each experiment 10 times to estimate average accuracy,
where each run computes 100 epochs over the training dataset. We used Nvidia RTX A4000s GPUs
and 24-core AMD EPYC-2 (Rome) 7402P CPUs."
REFERENCES,0.9210526315789473,"Parameter name
Value
Parameter name
Value
Learning rate
0.001
Prior learning rate
0.01
Epochs
100
Amount beliefs prior
2500
Batch size
16
Prior initialization
0.1
# of samples
600
Prior iterations
50
Hidden layers
3
L2 on prior
900.000
Hidden width
800
Table 4: Final hyperparameters for the multi-digit MNISTAdd task."
REFERENCES,0.9236842105263158,"Parameter name
Value
Parameter name
Value
Perception Learning rate
0.00055
Prior learning rate
0.0029
Inference learning rate
0.003
Amount beliefs prior
2500
Batch size
20
Prior initialization
0.02
# of samples
500
Prior iterations
18
Hidden layers
2
L2 on prior
2.500.000
Hidden width
100
Epochs
5000
Pretraining epochs
50
Table 5: Final hyperparameters for the visual Sudoku puzzle classiﬁcation task."
REFERENCES,0.9263157894736842,"We give the ﬁnal hyperparameters in Table 4. We use this same set of hyperparameters for all N.
# of samples refers to the number of samples we used to train the inference model in Algorithm 1.
For simplicity, it is also the beam size for the beam search at test time. The hidden layers and width
refer to MLP that computes each factor of the inference model. There is no parameter sharing. The
perception model is ﬁxed in this task to ensure performance gains are due to neurosymbolic reasoning
(see [35])."
REFERENCES,0.9289473684210526,"I.1.2
Other methods"
REFERENCES,0.9315789473684211,"We compare with multiple neurosymbolic frameworks that previously tackled the MNISTAdd
task. Several of those are probabilistic neurosymbolic methods: DeepProbLog [35], DPLA* [37],
NeurASP [58] and NeuPSL [44]. We also compare with the fuzzy logic-based method LTN [5] and
with Embed2Sym [3] and DeepStochLog [56]. We take results from the corresponding papers, except
for DeepProbLog and NeurASP, which are from [37], and LTN from [44]1. We reran Embed2Sym,
averaging over 10 runs since its paper did not report standard deviations. We do not compare DPLA*
with pre-training because it tackles an easier problem where part of the digits is labeled."
REFERENCES,0.9342105263157895,"Embed2Sym [3] uses three steps to solve Multi-digit MNISTAdd: First, it trains a neural network to
embed each digit and to predict the sum from these embeddings. It then clusters the embeddings and
uses symbolic reasoning to assign clusters to labels. A-NESI has a similar neural network architecture,
but we train the prediction network on an objective that does not require data. Furthermore, we train
A-NESI end-to-end, unlike Embed2Sym. For Embed2Sym, we use symbolic prediction to refer to
Embed2Sym-NS, and neural prediction to refer to Embed2Sym-FN, which also uses a prediction
network but is only trained on the training data given and does not use the prior to sample additional
data"
REFERENCES,0.9368421052631579,"We believe the accuracy improvements compared to DeepProbLog to come from hyperparameter
tuning and longer training times, as A-NESI approximates DeepProbLog’s semantics."
REFERENCES,0.9394736842105263,"I.2
Visual Sudoku Puzzle Classiﬁcation"
REFERENCES,0.9421052631578948,"I.2.1
A-NeSI deﬁnition"
REFERENCES,0.9447368421052632,"First, we will be more precise with the model we use. We see x as a N × N × 784 grid of MNIST
images, and beliefs P as an N × N × N grid of distributions over N options (for example, for a
4 × 4 puzzle, we have to ﬁll in the digits {0, 1, 2, 3}). For each grid index i, j, the world variable
wi,j corresponds to the digit at location (i, j). For correct puzzles, we know that the digits at location"
REFERENCES,0.9473684210526315,"1We take the results of LTN from [44] because [5] averages over the 10 best outcomes of 15 runs and
overestimates its average accuracy."
REFERENCES,0.95,"(i, j) and location (i′, j′) need to be different if i = i′, j = j′ or if (i, j) is in the same block as
(i′, j′). For each pair of locations (i, j), (i′, j′) for which this holds, we have a dimension in y that
indicates if the digits at that grid location are indeed different. The symbolic function c considers
each such pair and returns the corresponding y."
REFERENCES,0.9526315789473684,"For the prediction model, we use a single MLP fθ. That is, for each pair that should be different, we
compute qφ(yk|P) = fφ(Pi,j, Pi′,j′). This introduces the independence assumption that the digits
at location (i, j) and location (i′, j′) being different does not depend on the digits at other locations.
This is, clearly, wrong. However, we found it is sufﬁcient to accurately train the perception model."
REFERENCES,0.9552631578947368,"When training the prediction model, since we sample P from a Dirichlet prior that assumes the
different dimensions of w are independent, the grid of digits w are highly unlikely to represent actual
sudoku’s: There are about 1021 Sudoku’s and 981 possible grids (for 9 × 9 Sudoku’s). However, it is
quite likely to sample two digits that are different, and this is enough to train the prediction model."
REFERENCES,0.9578947368421052,"I.2.2
Hyperparameters and other methods"
REFERENCES,0.9605263157894737,"We used the Visual Sudoku Puzzle Classiﬁcation dataset from [4]. This dataset offers many options:
We used the simple generator strategy with 200 training puzzles (100 correct, 100 incorrect). We
took a corrupt chance of 0.50, and used the dataset with 0 overlap (this means each MNIST digit can
only be used once in the 200 puzzles). There are 11 splits of this dataset, independently generated.
We did hyperparameter tuning on the 11th split of the 9 × 9 dataset. We used the other 10 splits to
evaluate the results, averaging results over runs of each of those."
REFERENCES,0.9631578947368421,"The ﬁnal hyperparameters are reported in Table 5. The 5000 epochs took on average 20 minutes for
the 4 × 4 puzzles, and 38 minutes for the 9 × 9 puzzles on a machine with a single NVIDIA RTX
A4000. The ﬁrst 50 epochs we only trained the prediction model to ensure it provides reasonably
accurate gradients."
REFERENCES,0.9657894736842105,"While [4] used NeuPSL, we had to rerun it to get accuracy results and results on 9 × 9 grids."
REFERENCES,0.968421052631579,"We implemented the exact inference methods using what can best be described as Semantic Loss
[57]. We encoded the rules of Sudoku described at the beginning of this section as a CNF, and used
PySDD (https://github.com/wannesm/PySDD) to compile this to an SDD [28]. This was almost
instant for the 4 × 4 CNF, but we were not able to compile the 9 × 9 CNF within 4 hours, hence
why we report a timeout for exact inference. To implement Semantic Loss, we modiﬁed a PyTorch
implementation available at https://github.com/lucadiliello/semantic-loss-pytorch
to compute in log-space for numerically stable behavior. This modiﬁed version is included in our own
repository. We ran this method for 300 epochs with a learning rate of 0.001. We ran this method for
fewer epochs because it is much slower than A-NeSI even on 4 × 4 puzzles (1 hour and 16 minutes
for those 300 epochs, so about 63 times as slow)."
REFERENCES,0.9710526315789474,"For both A-NESI and exact inference, we train the perception model on correct puzzles by maxi-
mizing the probability that p(y = 1|P). A-NESI does this by maximizing log qφ(y = 1|P), while
Semantic Loss uses PSDDs to exactly compute log p(y = 1|P). For incorrect puzzles, there is not
much to be gained since we cannot assume anything about y. Still, for both methods we added the
loss −log(1 −p(y = 1|P)) for the incorrect puzzles."
REFERENCES,0.9736842105263158,"I.3
Warcraft Visual Path Planning"
REFERENCES,0.9763157894736842,"I.3.1
A-NeSI deﬁnition"
REFERENCES,0.9789473684210527,"We see x as a N × N × 3 × 8 × 8 real tensor: The ﬁrst two dimensions indicate the different grid
cells, the third dimension indicates the RGB color channels, and the last two dimensions indicate
the pixels in each grid cell. The world w is an N × N grid of integers, where each integer indexes
ﬁve different costs for traversing that cell. The ﬁve costs are [0.8, 1.2, 5.3, 7.7, 9.2], and correspond
to the ﬁve possible costs in the Warcraft game. The symbolic function c takes the grid of costs w
and returns the shortest path from the top left corner (1, 1) to the bottom right corner (N, N) using
Dijkstra’s algorithm. We encode the shortest path as a sequence of actions to take in the grid, where
each action is one of the eight (inter-)cardinal directions (down, down-right, right, etc.). The sequence
is padded with the do-not-move action to allow for batching."
REFERENCES,0.9815789473684211,"For the perception model, we use a single small CNN fθ for each of the N × N grid cells. That is,
for each grid cell, we compute Pi,j = fθ(xi,j). The CNN has a single convolutional layer with 6
output dimensions, a 2 × 2 maxpooling layer, a hidden layer of 24 × 84 and a softmax output layer
of 24 × 5, with ReLU activations."
REFERENCES,0.9842105263157894,"The prediction model is a ResNet18 model [22], with an output layer of 8 options. It takes an image
of size 6 × N × N as input. The ﬁrst 5 channels are the probabilities Pi,j, and the last channel
indicates the current position in the grid. The 8 output actions correspond to the 8 (inter-)cardinal
directions. We apply symbolic pruning (Section 3.3) to prevent actions that would lead outside the
grid or return to a previously visited grid cell. We pretrained the prediction model by repeating
Algorithm 1 on a ﬁxed prior using 185.000 iterations (200 samples each) for 12 × 12, and 370.000
iterations (20 samples) for 30 × 30. We used fewer examples per iteration for the larger grid because
Dijkstra’s algorithm became a computational bottleneck. This took 23 hours for 12 × 12 and 44 hours
for 30 × 30. Both used a learning rate of 2.5 · 10−4 and an independent ﬁxed Dirichlet prior with
α = 0.005. Standard deviations over 10 runs are reported over multiple perception model training
runs on the same frozen pretrained prediction model. We trained the perception model for only 1
epoch using a learning rate of 0.0084 and a batch size of 70."
REFERENCES,0.9868421052631579,"I.3.2
Other methods"
REFERENCES,0.9894736842105263,"We compare to SPL [1] and I-MLE [41]. SPL is also a probabilistic neurosymbolic method, and uses
exact inference. Its setup is quite different from ours, however. Instead of using Dijkstra’s algorithm,
it trains a ResNet18 to predict the shortest path end-to-end, and uses symbolic constraints to ensure
the output of the ResNet18 is a valid path. Furthermore, it only considers the 4 cardinal directions
instead of all 8 directions. SPL only reports a single training rule in their paper."
REFERENCES,0.9921052631578947,"I-MLE is more similar to our setup and also uses Dijkstra’s algorithm. It uses the ﬁrst ﬁve layers of
a ResNet18 to predict the cell costs given the input image. One big difference to our setup is that
I-MLE uses continuous costs instead of a choice out of ﬁve discrete costs. This may be easier to
optimize, as it gives the model more freedom to move costs around. I-MLE is reported using the
numbers from the paper, and averages over 5 runs."
REFERENCES,0.9947368421052631,"To be able to compare to another scalable baseline with the same setup, we added REINFORCE using
the leave-one-out baseline (RLOO, [29]), implemented using the PyTorch library Storchastic [53].
It uses the same small CNN to predict a distribution over discrete cell costs, then takes 10 samples,
and feeds those through Dijkstra’s to get the shortest path. Here, we represent the shortest path as an
N × N grid of zeros and ones. The reward function for RLOO is the Hamming loss between the
predicted path and the ground truth path. We use a learning rate of 5 · 10−4 and a batch size of 70.
We train for 10 epoch and report the standard deviation over 10 runs. We note that RLOO gets quite
expensive for 30 × 30 grids, as it needs 10 Dijkstra calls per training sample."
REFERENCES,0.9973684210526316,"Finally, we experimented with running A-NESI and RLOO simultaneously. We ran this for 10 epochs
with a learning rate of 5 · 10−4 and a batch size of 70. We report the standard deviation over 10 runs."
