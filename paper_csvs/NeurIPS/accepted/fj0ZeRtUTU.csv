Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0037735849056603774,"We study the problem of optimizing biological sequences, e.g., proteins, DNA,
and RNA, to maximize a black-box score function that is only evaluated in an
offline dataset.
We propose a novel solution, bootstrapped training of score-
conditioned generator (BOOTGEN) algorithm. Our algorithm repeats a two-stage
process. In the first stage, our algorithm trains the biological sequence generator
with rank-based weights to enhance the accuracy of sequence generation based
on high scores. The subsequent stage involves bootstrapping, which augments the
training dataset with self-generated data labeled by a proxy score function. Our
key idea is to align the score-based generation with a proxy score function, which
distills the knowledge of the proxy score function to the generator. After train-
ing, we aggregate samples from multiple bootstrapped generators and proxies to
produce a diverse design. Extensive experiments show that our method outper-
forms competitive baselines on biological sequential design tasks. We provide
reproducible source code: https://github.com/kaist-silab/bootgen."
INTRODUCTION,0.007547169811320755,"1
Introduction"
INTRODUCTION,0.011320754716981131,"The automatic design of biological sequences, e.g., DNA, RNA, and proteins, with a specific prop-
erty, e.g., high binding affinity, is a vital task within the field of biotechnology [5, 54, 41, 33]. To
solve this problem, researchers have developed algorithms to optimize a biological sequence to max-
imize a score function [40, 9, 10, 2, 29]. Here, the main challenge is the expensive evaluation of the
score function that requires experiments in a laboratory setting or clinical trials."
INTRODUCTION,0.01509433962264151,"To resolve this issue, recent works have investigated offline model-based optimization [32, 21, 44,
52, 12, 45, MBO]. Given an offline dataset of biological sequences paired with scores, offline MBO
algorithms train a proxy for the score function, e.g., a deep neural network (DNN), and maximize
the proxy function without querying the true score function. Therefore, such offline MBO algo-
rithms bypass the expense of iteratively querying the true score function whenever a new solution
is proposed. However, even optimizing such a proxy function is challenging due to the vast search
space over the biological sequences."
INTRODUCTION,0.018867924528301886,"On the one hand, several works [21, 44, 52, 12] considered applying gradient-based maximization
of the proxy function. However, when the proxy function is parameterized using a DNN, these
methods often generate solutions where the true score is low despite the high proxy score. This is
due to the fragility of DNNs against adversarial optimization of inputs [52, 44, 21]. Furthermore,
the gradient-based methods additionally require reformulating biological sequence optimization as
a continuous optimization, e.g., continuous relaxation [21, 44, 12] or mapping discrete designs to a
continuous latent space [52]."
INTRODUCTION,0.022641509433962263,"On the other hand, one may consider training deep generative models to learn a distribution over
high-scoring designs [32, 29]. They learn to generate solutions from scratch, which amortizes opti-
mization over the design space."
INTRODUCTION,0.026415094339622643,"To be specific, Kumar and Levine [32] suggests learning an inverse map from a score to a solu-
tion with a focus on generating high-scoring solutions. Next, Jain et al. [29] proposed training a
generative flow network [7, GFN] as the generative distribution of high-scoring solutions."
INTRODUCTION,0.03018867924528302,"Contribution
In this paper, we propose a bootstrapped training of score-conditioned generator
(BOOTGEN) for the offline design of biological sequences. Our key idea is to enhance the score-
conditioned generator by suggesting a variation of the classical ensemble strategy of bootstrapping
and aggregating. We train multiple generators using bootstrapped datasets from training and com-
bine them with proxy models to create a reliable and diverse sampling solution."
INTRODUCTION,0.033962264150943396,"In the bootstrapped training, we aim to align a score-conditioned generator with a proxy function
by bootstrapping the training dataset of the generator. To be specific, we repeat multiple stages of
(1) training the conditional generator on the training dataset with a focus on high-scoring sequences
and (2) augmenting the training dataset using sequences that are sampled from the generator and la-
beled using the proxy function. Intuitively, our framework improves the score-to-sequence mapping
(generator) to be consistent with the sequence-to-score mapping (proxy function), which is typically
more accurate."
INTRODUCTION,0.03773584905660377,"When training the score-conditioned generator, we assign high rank-based weights [46] to high-
scoring sequences. Sequences that are highly ranked among the training dataset are more frequently
sampled to train the generator. This leads to shifting the training distribution towards an accurate
generation of high-scoring samples. Compared with the value-based weighting scheme previously
proposed by Kumar and Levine [32], the rank-based weighting scheme is more robust to the change
of training dataset from bootstrapping."
INTRODUCTION,0.04150943396226415,"To further boost the performance of our algorithm, we propose two post-processing processes after
the training: filtering and diversity aggregation (DA). The filtering process aims to filter samples
from generators using the proxy function to gather samples with cross-agreement between the proxy
and generator. On the other hand, DA collects sub-samples from multiple generators and combines
them into complete samples. DA enables diverse decision-making with reduced variance in gener-
ating quality, as it collects samples from multiple bootstrapped generators."
INTRODUCTION,0.045283018867924525,"We perform extensive experiments on six offline biological design tasks: green fluorescent protein
design [54, GFP], DNA optimization for expression level on an untranslated region [41, UTR], tran-
scription factor binding [5, TFBind8], and RNA optimization for binding to three types of transcrip-
tion factors [33, RNA-Binding]. Our BOOTGEN demonstrates superior performance, surpassing the
100th percentile score and 50th percentile score of the design-bench baselines [45], a generative
flow network (GFN)-based work [29] and bidirectional learning method (BDI) [12]. Furthermore,
we additionally verify the superior performance of BOOTGEN in various design scenarios, particu-
larly when given a few opportunities to propose solutions."
RELATED WORKS,0.04905660377358491,"2
Related Works"
AUTOMATIC DESIGN OF BIOLOGICAL SEQUENCES,0.052830188679245285,"2.1
Automatic Design of Biological Sequences"
AUTOMATIC DESIGN OF BIOLOGICAL SEQUENCES,0.05660377358490566,"Researchers have investigated machine learning methods to automatically design biological se-
quences, e.g., Bayesian optimization [50, 6, 36, 38, 43], evolutionary methods [3, 8, 18, 4, 40],
model-based reinforcement learning [2], and generative methods [9, 32, 20, 29, 19, 11, 14]. These
methods aim to optimize biological sequence (e.g., protein, RNA, and DNA) for maximizing the
target objective of binding activity and folding, which has crucial application in drug discovery and
health care [29]."
OFFLINE MODEL-BASED OPTIMIZATION,0.06037735849056604,"2.2
Offline Model-based Optimization"
OFFLINE MODEL-BASED OPTIMIZATION,0.06415094339622641,"Offline model-based optimization (MBO) aims to find the design x that maximizes a score function
f(x), using only pre-collected offline data. The most common approach is to use gradient-based
optimization on differentiable proxy models trained on an offline dataset [49, 44, 52, 21, 12]. How-"
OFFLINE MODEL-BASED OPTIMIZATION,0.06792452830188679,"ùëùùúÉ(ùíô|ùë¶‚Ä†)
Generator ùêø
ùêæ"
OFFLINE MODEL-BASED OPTIMIZATION,0.07169811320754717,labelling Top K
OFFLINE MODEL-BASED OPTIMIZATION,0.07547169811320754,Augmented Dataset y
OFFLINE MODEL-BASED OPTIMIZATION,0.07924528301886792,Density
OFFLINE MODEL-BASED OPTIMIZATION,0.0830188679245283,Step B: Bootstrapping
OFFLINE MODEL-BASED OPTIMIZATION,0.08679245283018867,"ùëìùúô(ùíô)
Proxy"
OFFLINE MODEL-BASED OPTIMIZATION,0.09056603773584905,Bootstrapping y
OFFLINE MODEL-BASED OPTIMIZATION,0.09433962264150944,Density
OFFLINE MODEL-BASED OPTIMIZATION,0.09811320754716982,"Reweighting
Training
ùëùùúÉ(ùíô|ùë¶)
Generator y"
OFFLINE MODEL-BASED OPTIMIZATION,0.1018867924528302,Density
OFFLINE MODEL-BASED OPTIMIZATION,0.10566037735849057,"Training 
Dataset"
OFFLINE MODEL-BASED OPTIMIZATION,0.10943396226415095,Reweighted
OFFLINE MODEL-BASED OPTIMIZATION,0.11320754716981132,Dataset
OFFLINE MODEL-BASED OPTIMIZATION,0.1169811320754717,Step A: Rank-based Weighted Training
OFFLINE MODEL-BASED OPTIMIZATION,0.12075471698113208,High Score ùë¶‚Ä†
OFFLINE MODEL-BASED OPTIMIZATION,0.12452830188679245,Figure 2.1: Illustration of the bootstrapped training process for learning score-conditioned generator.
OFFLINE MODEL-BASED OPTIMIZATION,0.12830188679245283,"ever, they can lead to poor scores due to the non-smoothness of the proxy landscape. To address this
issue, Trabucco et al. [44] proposed conservative objective models (COMs), which use adversarial
training to create a smooth proxy. Yu et al. [52] suggests the direct imposition of a Gaussian prior on
the proxy model to create a smooth landscape and model adaptation to perform robust estimation on
the specific set of candidate design space. While these methods are effective for high-dimensional
continuous design tasks, their performance on discrete spaces is often inferior to classical methods,
e.g., gradient ascent [45]."
BOOTSTRAPPING,0.1320754716981132,"2.3
Bootstrapping"
BOOTSTRAPPING,0.13584905660377358,"Bootstrapping means maximizing the utilization of existing resources. In a narrow sense, it refers to
a statistical method where the original dataset is repeatedly sampled to create various datasets [25].
In a broader sense, it also encompasses concepts frequently used in machine learning to improve
machine learning scenarios where the label is expensive, e.g., self-training and semi-supervised
learning [37, 1, 22]. These methods utilize an iterative training scheme to augment the dataset with
self-labeled samples with high confidence."
BOOTSTRAPPING,0.13962264150943396,"The bootstrapping strategy at machine learning showed great success in various domains, e.g., fully-
labeled classification [51], self-supervised learning [17] and offline reinforcement learning [48].
We introduce a novel bootstrapping strategy utilizing score-conditioned generators and apply it to
offline biological sequence design, addressing the challenge of working with a limited amount of
poor-quality offline datasets."
DESIGN BY CONDITIONAL GENERATION,0.14339622641509434,"2.4
Design by Conditional Generation"
DESIGN BY CONDITIONAL GENERATION,0.1471698113207547,"Conditional generation is a promising method with several high-impact applications, e.g., class-
conditional image generation [35], language-to-image generation [39], reinforcement learning [16].
With the success of conditional generation, several studies proposed to use it for design tasks, e.g.,
molecule and biological sequence design."
DESIGN BY CONDITIONAL GENERATION,0.1509433962264151,"Hottung et al. [27] proposed an instance-conditioned variational auto-encoder [31] for routing prob-
lems, which can generate near-optimal routing paths conditioned on routing instances. Igashov
et al. [28] suggested a conditional diffusion model to generate 3D molecules given their fragments.
Specifically, the molecular fragments are injected into the latent space of the diffusion model, and
the diffusion model generates links between fragments to make the 3D molecular compound."
DESIGN BY CONDITIONAL GENERATION,0.15471698113207547,"3
Bootstrapped Training of Score-Conditioned Generator (BOOTGEN)"
DESIGN BY CONDITIONAL GENERATION,0.15849056603773584,"Problem definition
We are interested in optimizing a biological sequence x to maximize a given
score function f(x). We consider an offline setting where, during optimization, we do not have
access to the score function f(x). Instead, we optimize the biological sequences using a static
dataset D = {(xn, yn)}N
n=1 consisting of offline queries yn = f(xn) to the score function. Finally,
we consider evaluating a set of sequences {xm}M
m=1 as an output of offline design algorithms."
DESIGN BY CONDITIONAL GENERATION,0.16226415094339622,"Overview of BOOTGEN
We first provide a high-level description of our bootstrapped training
of score-conditioned generator, coined BOOTGEN. Our key idea is to align the score-conditioned
generation with a proxy model via bootstrapped training (i.e., we train the generator on sequences
labeled using the proxy model) and aggregate the decisions over multiple generators and proxies for
reliable and diverse sampling of solutions."
DESIGN BY CONDITIONAL GENERATION,0.1660377358490566,Algorithm 1 Bootrapped Training of Score-conditioned generators
DESIGN BY CONDITIONAL GENERATION,0.16981132075471697,"1: Input: Offline dataset D = {xn, yn}N
n=1.
2: Update œï to minimize P"
DESIGN BY CONDITIONAL GENERATION,0.17358490566037735,"(x,y)‚ààD(fœï(x) ‚àíy)2.
3: for j = 1, . . . , Ngen do
‚ñ∑Training multiple generaters
4:
Initialize Dtr ‚ÜêD.
5:
for i = 1, . . . , I do
‚ñ∑Rank-based weighted training
6:
Update Œ∏j to maximize P"
DESIGN BY CONDITIONAL GENERATION,0.17735849056603772,"(x,y)‚ààDtr w(y, Dtr) log pŒ∏j(x|y)."
DESIGN BY CONDITIONAL GENERATION,0.1811320754716981,"7:
Sample x‚àó
‚Ñì‚àºpŒ∏j(x|y‚Ä†) for ‚Ñì= 1, . . . , L.
‚ñ∑Bootstrapping
8:
Set y‚àó
‚Ñì‚Üêfœï(x‚àó
‚Ñì) for ‚Ñì= 1, . . . , L.
9:
Set Daug as top-K scoring samples in {x‚àó
‚Ñì, y‚àó
‚Ñì}L
‚Ñì=1.
10:
Set Dtr ‚ÜêDtr ‚à™Daug.
11:
end for
12: end for
13: Output: trained score-conditioned generators pŒ∏1(x|y), ..., pŒ∏Ngen(x|y)."
DESIGN BY CONDITIONAL GENERATION,0.18490566037735848,"Before BOOTGEN training, we pre-train proxy score function fœï(x) ‚âàf(x) only leveraging offline
dataset D. After that, our BOOTGEN first initializes a training dataset Dtr as the offline dataset D
and then repeats the following steps:"
DESIGN BY CONDITIONAL GENERATION,0.18867924528301888,"A. BootGen optimizes the score-conditioned generator pŒ∏(x|y) using the training dataset Dtr.
During training, it assigns rank-based weights to each sequence for the generator to focus
on high-scoring samples."
DESIGN BY CONDITIONAL GENERATION,0.19245283018867926,"B. BOOTGEN bootstraps the training dataset Dtr using samples from the generator pŒ∏(x|y‚Ä†)
conditioned on the desired score y‚Ä†. It uses a proxy fœï(x) of the score function to label the
new samples."
DESIGN BY CONDITIONAL GENERATION,0.19622641509433963,"After BOOTGEN training for multiple score-conditioned generators pŒ∏1(x|y), ..., pŒ∏n(x|y), we ag-
gregate samples from the generators with filtering of proxy score function fœï to generate diverse and
reliable samples. We provide the pseudo-code of the overall procedure in Algorithm 1 for training
and Algorithm 2 for generating solutions from the trained model."
RANK-BASED WEIGHTED TRAINING,0.2,"3.1
Rank-based Weighted Training"
RANK-BASED WEIGHTED TRAINING,0.2037735849056604,"Here, we introduce our framework to train the score-conditioned generator. Our algorithm aims to
train the score-conditioned generator with more focus on generating high-scoring designs. Such a
goal is helpful for bootstrapping and evaluation of our framework, where we query the generator
conditioned on a high score."
RANK-BASED WEIGHTED TRAINING,0.20754716981132076,"Given a training dataset Dtr, our BOOTGEN minimizes the following loss function:"
RANK-BASED WEIGHTED TRAINING,0.21132075471698114,"L(Œ∏) := ‚àí
X"
RANK-BASED WEIGHTED TRAINING,0.21509433962264152,"(x,y)‚ààDtr
w(y, Dtr) log pŒ∏(x|y),
w(y, Dtr) =
(k|Dtr| + rank(y, Dtr))‚àí1
P"
RANK-BASED WEIGHTED TRAINING,0.2188679245283019,"(x,y)‚ààDtr(k|Dtr| + rank(y, Dtr))‚àí1 ."
RANK-BASED WEIGHTED TRAINING,0.22264150943396227,"where w(y, Dtr) is the score-wise rank-based weight [46]. Here, k is a weight-shifting factor, and
rank(y, Dtr) denotes the relative ranking of a score y with respect to the set of scores in the dataset
Dtr. We note that a small weight-shifting factor k assigns high weights to high-scoring samples."
RANK-BASED WEIGHTED TRAINING,0.22641509433962265,"For mini-batch training of the score-conditioned generator, we approximate the loss function L(Œ∏)
via sampling with probability w(y, Dtr) for each sample (x, y)."
RANK-BASED WEIGHTED TRAINING,0.23018867924528302,"We note that Tripp et al. [46] proposed the rank-based weighting scheme for training unconditional
generators to solve online design problems. At a high level, the weighting scheme guides the gener-
ator to focus more on generating high-scoring samples. Compared to weights that are proportional
to scores [32], using the rank-based weights promotes the training to be more robust against out-
liers, e.g., samples with abnormally high weights. To be specific, the weighting factor w(y, D) is
less affected by outliers due to its upper bound that is achieved when rank(y, D) = 1."
RANK-BASED WEIGHTED TRAINING,0.2339622641509434,Algorithm 2 Aggregation Strategy for Sample Generation
RANK-BASED WEIGHTED TRAINING,0.23773584905660378,"1: Input: Trained score-conditioned generators pŒ∏1(x|y), ..., pŒ∏Ngen (x|y), and trained proxy
function fœï(x).
2: Initialize Dsamples ‚Üê‚àÖ.
3: for i = 1, . . . , Ngen do
4:
Sample x‚àó
m ‚àºpŒ∏i(x|y‚Ä†) for m ‚àà[M].
5:
Set y‚àó
m ‚Üêfœï(x‚àó
m) for m ‚àà[M].
6:
Set Dsub-samples as Top-K scoring samples in {x‚àó
m, y‚àó
m}M
m=1.
‚ñ∑Filtering
7:
Set Dsamples ‚ÜêDsamples ‚à™Dsub-samples
‚ñ∑Diversity Aggregation
8: end for
9: Output: Dsamples."
BOOTSTRAPPING,0.24150943396226415,"3.2
Bootstrapping"
BOOTSTRAPPING,0.24528301886792453,"Next, we introduce our bootstrapping strategy to augment a training dataset with high-scoring sam-
ples that are collected from the score-conditioned generator and labeled using a proxy model. Our
key idea is to enlarge the dataset so that the score-conditioned generation is consistent with predic-
tions of the proxy model, in particular for the high-scoring samples. This enables self-training by
utilizing the extrapolation capabilities of the generator and allows the proxy model to transfer its
knowledge to the score-conditioned generation process."
BOOTSTRAPPING,0.2490566037735849,"We first generate a set of samples x‚àó
1, . . . , x‚àó
L from the generator pŒ∏(x|y‚Ä†) conditioned on the desired
score y‚Ä† 1 Then we compute the corresponding labels y‚àó
1, . . . , y‚àó
L using the proxy model, i.e., we set
y‚Ñì= fœï(x‚Ñì) for ‚Ñì= 1, . . . , L. Finally, we augment the training dataset using the set of top-K
samples Daug with respect to the proxy model, i.e., we set Dtr ‚à™Daug as the new training dataset Dtr."
AGGREGATION STRATEGY FOR SAMPLE GENERATION,0.2528301886792453,"3.3
Aggregation Strategy for Sample Generation"
AGGREGATION STRATEGY FOR SAMPLE GENERATION,0.25660377358490566,"Here, we introduce additional post-hoc aggregation strategies that can be used to further boost the
quality of samples from our generator. See Algorithm 2 for a detailed process."
AGGREGATION STRATEGY FOR SAMPLE GENERATION,0.26037735849056604,"Filtering
We follow Kumar and Levine [32] to exploit the knowledge of the proxy function for
filtering high-scoring samples from the generator. To be specific, when evaluating our model, we
sample a set of candidate solutions and select the top samples with respect to the proxy function."
AGGREGATION STRATEGY FOR SAMPLE GENERATION,0.2641509433962264,"Diverse aggregation
To enhance the diversity of candidate samples while maintaining reliable
generating performances with low variance, we gather cross-aggregated samples from multiple
score-conditioned generators. These generators are independently trained using our proposed boot-
strapped training approach. Since each bootstrapped training process introduces high randomness
due to varying training datasets, combining the generative spaces of multiple generators yields a
more diverse space compared to a single generator."
AGGREGATION STRATEGY FOR SAMPLE GENERATION,0.2679245283018868,"Moreover, this process helps reduce the variance in generating quality. By creating ensemble candi-
date samples from multiple generators, we ensure stability and mitigate the risk of potential failure
cases caused by adversarial samples. These samples may receive high scores from the proxy func-
tion but have low actual scores. This approach resembles the classical ensemble strategy known as
‚Äúbagging,‚Äù which aggregates noisy bootstrapped samples from decision trees to reduce variances."
EXPERIMENTS,0.27169811320754716,"4
Experiments"
EXPERIMENTS,0.27547169811320754,"We present experimental results on six representative biological sequence design tasks to verify the
effectiveness of the proposed method. We also conduct ablation studies to verify the effectiveness
of each component in our method. For training, we use a single GPU of NVIDIA A100, where the
training time of one generator is approximately 10 minutes."
EXPERIMENTS,0.2792452830188679,"1Following Chen et al. [12], we assume that we know the maximum score of the task."
EXPERIMENTS,0.2830188679245283,"Table 4.1: Experimental results on 100th percentile scores. The mean and standard deviation are reported for 8
independent solution generations. D(best) indicate the maximum score of the offline dataset. The best-scored
value is marked in bold."
EXPERIMENTS,0.28679245283018867,"Method
RNA-A
RNA-B
RNA-C
TFBind8
GFP
UTR
Avg."
EXPERIMENTS,0.29056603773584905,"D (best)
0.120
0.122
0.125
0.439
0.789
0.593
0.365
REINFORCE [45]
0.462 ¬± 0.080
0.437 ¬± 0.033
0.463 ¬± 0.043
0.936 ¬± 0.041
0.865 ¬± 0.003
0.685 ¬± 0.012
0.643
CMA-ES [24]
0.841 ¬± 0.058
0.822 ¬± 0.046
0.803 ¬± 0.039
0.904 ¬± 0.040
0.055 ¬± 0.003
0.737 ¬± 0.013
0.694
BO-qEI [50]
0.724 ¬± 0.055
0.729 ¬± 0.038
0.707 ¬± 0.034
0.798 ¬± 0.083
0.254 ¬± 0.352
0.684 ¬± 0.000
0.649
CbAS [9]
0.541 ¬± 0.042
0.647 ¬± 0.057
0.644 ¬± 0.071
0.913 ¬± 0.025
0.865 ¬± 0.004
0.692 ¬± 0.008
0.717
Auto. CbAS [20]
0.524 ¬± 0.055
0.562 ¬± 0.031
0.495 ¬± 0.048
0.890 ¬± 0.050
0.865 ¬± 0.003
0.693 ¬± 0.009
0.672
MIN [32]
0.376 ¬± 0.039
0.374 ¬± 0.041
0.404 ¬± 0.047
0.892 ¬± 0.060
0.865 ¬± 0.001
0.691 ¬± 0.011
0.600
Grad [45]
0.821 ¬± 0.048
0.720 ¬± 0.047
0.688 ¬± 0.035
0.965 ¬± 0.030
0.862 ¬± 0.003
0.682 ¬± 0.013
0.792
COMs [44]
0.403 ¬± 0.062
0.393 ¬± 0.076
0.494 ¬± 0.098
0.945 ¬± 0.033
0.861 ¬± 0.009
0.699 ¬± 0.011
0.633
AdaLead [42]
0.691 ¬± 0.059
0.630 ¬± 0.062
0.605 ¬± 0.055
0.962 ¬± 0.024
0.841 ¬± 0.014
0.631 ¬± 0.010
0.727
GFN-AL [29]
0.630 ¬± 0.054
0.677 ¬± 0.079
0.623 ¬± 0.045
0.956 ¬± 0.018
0.059 ¬± 0.006
0.695 ¬± 0.021
0.607
BDI [12]
0.700 ¬± 0.000
0.560 ¬± 0.000
0.632 ¬± 0.000
0.973 ¬± 0.000
0.864 ¬± 0.000
0.667 ¬± 0.000
0.733"
EXPERIMENTS,0.2943396226415094,"BOOTGEN
0.902 ¬± 0.039
0.931 ¬± 0.055
0.831 ¬± 0.044
0.979 ¬± 0.001
0.865 ¬± 0.000
0.865 ¬± 0.000
0.895"
EXPERIMENTS,0.2981132075471698,"Table 4.2: Experimental results on 50th percentile scores. The mean and standard deviation are reported for 8
independent solution generations. D(best) indicate the maximum score of the offline dataset. The best-scored
value is marked in bold."
EXPERIMENTS,0.3018867924528302,"Method
RNA-A
RNA-B
RNA-C
TFBind8
GFP
UTR
Avg."
EXPERIMENTS,0.30566037735849055,"D (best)
0.120
0.122
0.125
0.439
0.789
0.593
0.365
REINFORCE [45]
0.159 ¬± 0.011
0.162 ¬± 0.007
0.177 ¬± 0.011
0.450 ¬± 0.017
0.845 ¬± 0.003
0.575 ¬± 0.018
0.395
CMA-ES [24]
0.558 ¬± 0.012
0.531 ¬± 0.010
0.535 ¬± 0.012
0.526 ¬± 0.017
0.047 ¬± 0.000
0.497 ¬± 0.009
0.449
BO-qEI [50]
0.389 ¬± 0.009
0.397 ¬± 0.015
0.391 ¬± 0.012
0.439 ¬± 0.000
0.246 ¬± 0.341
0.571 ¬± 0.000
0.406
CbAS [9]
0.246 ¬± 0.008
0.267 ¬± 0.021
0.281 ¬± 0.015
0.467 ¬± 0.008
0.852 ¬± 0.004
0.566 ¬± 0.018
0.447
Auto. CbAS [20]
0.241 ¬± 0.022
0.237 ¬± 0.009
0.193 ¬± 0.007
0.413 ¬± 0.012
0.847 ¬± 0.003
0.563 ¬± 0.019
0.420
MIN [32]
0.146 ¬± 0.009
0.143 ¬± 0.007
0.174 ¬± 0.007
0.417 ¬± 0.012
0.830 ¬± 0.011
0.586 ¬± 0.000
0.383
Grad [45]
0.473 ¬± 0.025
0.462 ¬± 0.016
0.393 ¬± 0.017
0.513 ¬± 0.007
0.763 ¬± 0.181
0.611 ¬± 0.000
0.531
COMs [44]
0.172 ¬± 0.026
0.184 ¬± 0.039
0.228 ¬± 0.061
0.512 ¬± 0.051
0.737 ¬± 0.262
0.608 ¬± 0.000
0.407
AdaLead [42]
0.407 ¬± 0.018
0.353 ¬± 0.029
0.326 ¬± 0.019
0.485 ¬± 0.013
0.186 ¬± 0.216
0.592 ¬± 0.002
0.392
GFN-AL [29]
0.312 ¬± 0.013
0.300 ¬± 0.012
0.324 ¬± 0.009
0.538 ¬± 0.045
0.051 ¬± 0.003
0.597 ¬± 0.021
0.354
BDI [12]
0.411 ¬± 0.000
0.308 ¬± 0.000
0.345 ¬± 0.000
0.595 ¬± 0.000
0.837 ¬± 0.010
0.527 ¬± 0.000
0.504"
EXPERIMENTS,0.30943396226415093,"BOOTGEN
0.707 ¬± 0.005
0.717 ¬± 0.006
0.596 ¬± 0.006
0.833 ¬± 0.007
0.853 ¬± 0.017
0.701 ¬± 0.004
0.731"
EXPERIMENTAL SETTING,0.3132075471698113,"4.1
Experimental Setting"
EXPERIMENTAL SETTING,0.3169811320754717,"Tasks. We evaluate an offline design algorithm by (1) training it on an offline dataset and (2) using it
to generate 128 samples for high scores. We measure the 50th percentile and 100th percentile scores
of the generated samples. All the results are measured using eight independent random seeds."
EXPERIMENTAL SETTING,0.32075471698113206,"We consider six biological sequence design tasks: green fluorescent protein (GFP), DNA optimiza-
tion for expression level on untranslated region (UTR), DNA optimization tasks for transcription
factor binding (TFBind8), and three RNA optimization tasks for transcription factor binding (RNA-
Binding-A, RNA-Binding-B, and RNA-Binding-C). The scores of the biological sequences range in
[0, 1]. We report the statistics of the offline datasets used for each task in Table A.1. We also provide
a detailed description of the tasks in Appendix A.1."
EXPERIMENTAL SETTING,0.32452830188679244,"Baselines
We compare our BOOTGEN with the following baselines: gradient ascent with respect
to a proxy score model [45, Grad.], REINFORCE [49], Bayesian optimization quasi-expected-
improvement [50, BO-qEI], covariance matrix adaptation evolution strategy [24, CMA-ES], con-
ditioning by adaptative sampling [9, CbAS], autofocused CbAS [20, Auto. CbAS], model inversion
network [32, MIN], where these are in the official design bench [45]. We compare with additional
baselines of conservative objective models [44, COMs], generative flow network for active learning
[29, GFN-AL] and bidirectional learning [12, BDI]."
EXPERIMENTAL SETTING,0.3283018867924528,"Implementation
We parameterize the conditional distribution pŒ∏(xt|x1:t‚àí1, y) using a 2-layer
long short-term memory [26, LSTM] network with 512 hidden dimensions. The condition y is
injected into the LSTM using a linear projection layer. We parameterize the proxy model using
a multi-layer perceptron (MLP) with 2048 hidden dimensions and a sigmoid activation function.
Our parameterization is consistent across all the tasks. We provide a detailed description of the
hyperparameters in Appendix A. We also note the importance of the desired score y‚Ä† to condition
during bootstrapping and evaluation. In this regard, we set it as the maximum score that is achievable
for the given problem, i.e., we set y‚Ä† = 1. We assume that such a value is known following [12]."
EXPERIMENTAL SETTING,0.3320754716981132,"0
20
40
60
80
100
120
Number of evaluations (K) 0.3 0.4 0.5 0.6 0.7 0.8 0.9 Score"
EXPERIMENTAL SETTING,0.33584905660377357,"BootGen
Grad.
BDI
CbAS
CMA-ES"
EXPERIMENTAL SETTING,0.33962264150943394,(a) RNA-Binding-A
EXPERIMENTAL SETTING,0.3433962264150943,"0
20
40
60
80
100
120
Number of evaluations (K) 0.3 0.4 0.5 0.6 0.7 0.8 0.9 Score"
EXPERIMENTAL SETTING,0.3471698113207547,"BootGen
Grad.
BDI
CbAS
CMA-ES"
EXPERIMENTAL SETTING,0.35094339622641507,(b) RNA-Binding-B
EXPERIMENTAL SETTING,0.35471698113207545,"0
20
40
60
80
100
120
Number of evaluations (K) 0.3 0.4 0.5 0.6 0.7 0.8 0.9 Score"
EXPERIMENTAL SETTING,0.3584905660377358,"BootGen
Grad.
BDI
CbAS
CMA-ES"
EXPERIMENTAL SETTING,0.3622641509433962,(c) RNA-Binding-C
EXPERIMENTAL SETTING,0.3660377358490566,"0
20
40
60
80
100
120
Number of evaluations (K) 0.800 0.825 0.850 0.875 0.900 0.925 0.950 0.975 1.000 Score"
EXPERIMENTAL SETTING,0.36981132075471695,"BootGen
Grad.
BDI
CbAS
CMA-ES"
EXPERIMENTAL SETTING,0.37358490566037733,(d) TFBind8
EXPERIMENTAL SETTING,0.37735849056603776,"0
20
40
60
80
100
120
Number of evaluations (K) 0.856 0.858 0.860 0.862 0.864 Score"
EXPERIMENTAL SETTING,0.38113207547169814,"BootGen
Grad.
BDI
CbAS
CMA-ES"
EXPERIMENTAL SETTING,0.3849056603773585,(e) GFP
EXPERIMENTAL SETTING,0.3886792452830189,"0
20
40
60
80
100
120
Number of evaluations (K) 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 Score"
EXPERIMENTAL SETTING,0.39245283018867927,"BootGen
Grad.
BDI
CbAS
CMA-ES"
EXPERIMENTAL SETTING,0.39622641509433965,(f) UTR
EXPERIMENTAL SETTING,0.4,"Figure 4.1: Evaluation-performance graph to compare with representative offline biological design baselines.
The number of evaluations K ‚àà[1, 128] stands for the number of candidate designs to be evaluated by the
Oracle score function. The average value and standard deviation error bar for 8 independent runs are reported.
Our method outperforms other baselines at every task for almost all K."
PERFORMANCE EVALUATION,0.4037735849056604,"4.2
Performance Evaluation"
PERFORMANCE EVALUATION,0.4075471698113208,"In Table 4.1 and Table 4.2, we report the performance of our BOOTGEN along with other baselines.
One can observe how our BOOTGEN consistently outperforms the considered baselines across all
six tasks. In particular, one can observe how our BOOTGEN achieves large gains in 50th percentile
metrics. This highlights how our algorithm is able to create a reliable set of candidates."
PERFORMANCE EVALUATION,0.41132075471698115,"For TFbind8, which has a relatively small search space (48), having high performances on the 100th
percentile is relatively easy. Indeed, the classical method of CMA-ES and Grad. gave pretty good
performances. However, for the 50th percentile score, a metric for measuring the method‚Äôs reliabil-
ity, BDI outperformed previous baselines by a large margin. Our method outperformed even BDI
and achieved an overwhelming score."
PERFORMANCE EVALUATION,0.41509433962264153,"For higher dimensional tasks of UTR, even the 50th percentile score of BOOTGEN outperforms the
100th percentile score of other baselines by a large margin. We note that our bootstrapping strategies
and aggregation strategy greatly contributed to improving performances on UTR. For additional
tasks of RNA, we achieved the best score for both the 50th percentile and the 100th percentile. This
result verifies that our method is task-expandable."
VARYING THE EVALUATION BUDGET,0.4188679245283019,"4.3
Varying the Evaluation Budget"
VARYING THE EVALUATION BUDGET,0.4226415094339623,"In real-world scenarios, there may be situations where only a few samples can be evaluated due to the
expensive score function. For example, in an extreme scenario, for the clinical trial of a new protein
drug, there may be only one or two chances to be evaluated. As we measure the 50th percentile and
100th percentile score among 128 samples following the design-bench [45] at Tables 4.1 and 4.2, we
also provide a 100th percentile score report at the fewer samples from 1 sample to the 128 samples
to evaluate the model‚Äôs robustness on the low-budget evaluation scenarios."
VARYING THE EVALUATION BUDGET,0.42641509433962266,"To account for this, we also provide a budget-performance graph that compares the performance of
our model to the baselines using different numbers of evaluations. This allows us to observe the
trade-off between performance and the number of samples generated. Note that we select baselines
as the Top 5 methods in terms of average percentile 100 scores reported at Table 4.1."
VARYING THE EVALUATION BUDGET,0.43018867924528303,"Table 4.3: Experimental results on 100th percentile scores (100th Per.), 50th percentile scores (50th Per.),
average score (Avg. Score), diversity, and novelty, among 128 samples of UTR task. The mean and standard
deviation of 8 independent runs for producing 128 samples is reported. The best-scored value is marked in
bold. The lowest standard deviation is marked as the underline. The DA stands for the diverse aggregation
strategy."
VARYING THE EVALUATION BUDGET,0.4339622641509434,"Methods
100th Per.
50th Per.
Avg. Score
Diversity
Novelty"
VARYING THE EVALUATION BUDGET,0.4377358490566038,"MIN [32]
0.691 ¬± 0.011
0.587 ¬± 0.012
0.554 ¬± 0.010
28.53 ¬± 0.095
18.32 ¬± 0.091
CMA-ES [24]
0.746 ¬± 0.018
0.498 ¬± 0.012
0.520 ¬± 0.013
24.69 ¬± 0.150
19.95 ¬± 0.925
Grad. [45]
0.682 ¬± 0.013
0.513 ¬± 0.007
0.521 ¬± 0.006
25.63 ¬± 0.615
16.89 ¬± 0.426
GFN-AL [29]
0.700 ¬± 0.015
0.602 ¬± 0.014
0.580 ¬± 0.014
30.89 ¬± 1.220
20.25 ¬± 2.272"
VARYING THE EVALUATION BUDGET,0.44150943396226416,"BOOTGEN w/o DA.
0.729 ¬± 0.074
0.672 ¬± 0.082
0.652 ¬± 0.081
17.83 ¬± 5.378
20.49 ¬± 1.904
BOOTGEN w/ DA. (ours)
0.858 ¬± 0.003
0.701 ¬± 0.004
0.698 ¬± 0.001
31.57 ¬± 0.073
21.40 ¬± 0.057"
VARYING THE EVALUATION BUDGET,0.44528301886792454,"22
24
26
28
30
32
34
Diversity 0.50 0.55 0.60 0.65 0.70"
VARYING THE EVALUATION BUDGET,0.4490566037735849,Avg. Score
VARYING THE EVALUATION BUDGET,0.4528301886792453,"BootGen
GFN-AL
Grad.
CMA-ES
CbAS
Auto. CbAS
MIN
REINFORCE
BDI"
VARYING THE EVALUATION BUDGET,0.45660377358490567,"16
17
18
19
20
21
22
Novelty 0.50 0.55 0.60 0.65 0.70"
VARYING THE EVALUATION BUDGET,0.46037735849056605,Avg. Score
VARYING THE EVALUATION BUDGET,0.4641509433962264,"BootGen
GFN-AL
Grad.
CMA-ES
CbAS
Auto. CbAS
MIN
REINFORCE
BDI"
VARYING THE EVALUATION BUDGET,0.4679245283018868,"Figure 4.2: Multi-objectivity comparison of diversity and novelty on the average score for the UTR task. Each
datapoint for 8 independent runs is depicted."
VARYING THE EVALUATION BUDGET,0.4716981132075472,"As shown in Fig. 4.1, our method outperforms every baseline for almost every evaluation budget.
For the UTR task, our performance on a single evaluation budget gives a better score than the other
baselines‚Äô scores when they have a budget of 128 evaluations. For RNA tasks, our method with an
approximate budget of 30 achieves superior performance compared to other methods with a budget
of 128. These results show that our method is the most reliable as its performance is most robust
when the evaluation budget is limited."
AVERAGE SCORE WITH DIVERSITY,0.47547169811320755,"4.4
Average Score with Diversity"
AVERAGE SCORE WITH DIVERSITY,0.47924528301886793,"For biological sequence design, measuring the diversity and novelty of the generated sequence is
also crucial [29]. Following the evaluation metric of [29] we compare the performance of models in
terms of diversity and novelty."
AVERAGE SCORE WITH DIVERSITY,0.4830188679245283,"Here is measurement of diversity for sampled design dataset D = {x1, ..., xM} from generator
which is average of Levenshtein distance [23], denoted by d (xi, xj), between arbitrary two biolog-
ical sequences xi, xj from the generated design candidates D:"
AVERAGE SCORE WITH DIVERSITY,0.4867924528301887,"Diversity(D) :=
1
|D|(|D| ‚àí1) X x‚ààD X"
AVERAGE SCORE WITH DIVERSITY,0.49056603773584906,"s‚ààD\{x}
d (x, s) ."
AVERAGE SCORE WITH DIVERSITY,0.49433962264150944,"Next, we measure the minimum distance from the offline dataset Doffline which measures the novelty
of generated design candidates D as:"
AVERAGE SCORE WITH DIVERSITY,0.4981132075471698,"Novelty(D, Doffline) =
1
|D| X"
AVERAGE SCORE WITH DIVERSITY,0.5018867924528302,"x‚ààD
min
s‚ààDoffline d (x, s) ."
AVERAGE SCORE WITH DIVERSITY,0.5056603773584906,"Our method surpasses all baselines, including GFN-AL [29], in the UTR task, as evidenced by
the Pareto frontier depicted in Table 4.3 and Fig. 4.2. Given the highly dimensional nature of the
UTR task and its expansive search space, the discovery of novel and diverse candidates appears
to be directly related to their average score. This implies that extensive exploration of the high-
dimensional space is crucial for improving scores in the UTR task."
AVERAGE SCORE WITH DIVERSITY,0.5094339622641509,"Table 4.4: Ablation study for BOOTGEN. The average score among 128 samples is reported. We make 8
independent runs to produce 128 samples where the mean and the standard deviation are reported. For every
method, an aggregation strategy is applied by default. The best-scored value is marked in bold. The lowest
standard deviation is underlined. The RR stands for rank-based reweighting, the B stands for bootstrapping,
and the F stands for filtering."
AVERAGE SCORE WITH DIVERSITY,0.5132075471698113,"Components
RNA-A
RNA-B
RNA-C
TFbind8
UTR
GFP"
AVERAGE SCORE WITH DIVERSITY,0.5169811320754717,"‚àÖ
0.388 ¬± 0.007
0.350 ¬± 0.008
0.394 ¬± 0.010
0.579 ¬± 0.010
0.549 ¬± 0.009
0.457 ¬± 0.044
{RR}
0.483 ¬± 0.006
0.468 ¬± 0.008
0.441 ¬± 0.010
0.662 ¬± 0.009
0.586 ¬± 0.008
0.281 ¬± 0.031
{RR, B}
0.408 ¬± 0.009
0.379 ¬± 0.009
0.417 ¬± 0.006
0.666 ¬± 0.009
0.689 ¬± 0.003
0.470 ¬± 0.034
{RR, F}
0.576 ¬± 0.005
0.586 ¬± 0.004
0.536 ¬± 0.007
0.833 ¬± 0.004
0.621 ¬± 0.003
0.783 ¬± 0.011
{RR, F, B}
0.607 ¬± 0.009
0.612 ¬± 0.005
0.554 ¬± 0.007
0.840 ¬± 0.004
0.698 ¬± 0.001
0.804 ¬± 0.002"
AVERAGE SCORE WITH DIVERSITY,0.5207547169811321,"It is worth noting that GFN-AL, which is specifically designed to generate diverse, high-quality
samples through an explorative policy, secures a second place for diversity. Although GFN-AL
occasionally exhibits better diversity than our method and achieves a second-place average score,
it consistently delivers poor average scores in the GFP and RNA tasks Table 4.2. This drawback
can be attributed to its high explorative policy, which necessitates focused exploration in narrow
regions. In contrast, BOOTGEN consistently produces reliable scores across all tasks Table 4.2. For
a comprehensive comparison with GFN-AL, please refer to the additional experiments presented in
Appendix C."
AVERAGE SCORE WITH DIVERSITY,0.5245283018867924,"Diverse aggregation strategy
Our diverse aggregation (DA) strategy significantly enhances di-
versity, novelty, and score variance, as demonstrated in Table 4.3. This is especially beneficial for
the UTR task, which necessitates extensive exploration of a vast solution space, posing a substantial
risk to the bootstrapped training process. In this context, certain bootstrapped generators may yield
exceedingly high scores, while others may produce low scores due to random exploration scenarios.
By employing DA, we combine multiple generators to generate candidate samples, thereby greatly
stabilizing the quality of the bootstrapped generator."
ABLATION STUDY,0.5283018867924528,"4.5
Ablation study"
ABLATION STUDY,0.5320754716981132,"The effectiveness of our components, namely rank-based reweighting (RR), bootstrapping (B), and
filtering (F), in improving performance is evident in Table 4.4. Across all tasks, these components
consistently contribute to performance enhancements. The bootstrapping process is particularly
more beneficial for high-dimensional tasks like UTR and GFP. This correlation is intuitive since
high-dimensional tasks require a larger amount of data for effective exploration. The bootstrapped
training dataset augmentation facilitates this search process by leveraging proxy knowledge. Addi-
tionally, the filtering technique proves to be powerful in improving scores. As we observed from the
diverse aggregation and filtering, the ensemble strategy greatly enhances score-conditioned genera-
tors."
FUTURE WORKS,0.5358490566037736,"5
Future Works"
FUTURE WORKS,0.539622641509434,"Enhancing proxy robustness
While our bootstrapping method shows promise for offline bio-
sequential design tasks, it has inherent technical limitations. The assumption that the generator
produces superior data to the training dataset may backfire if the generator samples have poor quality
designs and the proxy used is inaccurate. While the current aggregation strategy effectively manages
this risk, we can address this limitation by utilizing robust learning methods of proxies such as
conservative proxies modeling [44], robust model adaptation techniques [52], parallel mentoring
proxies [13], and importance-aware co-teaching of proxies [53] for further improvement."
FUTURE WORKS,0.5433962264150943,"Enhancing architecture of BOOTGEN
Our approach primarily employs a straightforward archi-
tectural framework, with a primary emphasis on validating its algorithmic structures in the context
of offline biological sequence design. To enhance the practical utility of our method, it will be ad-
vantageous to incorporate established and robust architectural paradigms, exemplified in works such
as [11] and [14], into the framework of our method. One promising avenue for achieving this inte-
gration is the incorporation of pre-trained protein language models (pLMs) [34, 15], akin to those
expounded upon in [14]."
CONCLUSION,0.5471698113207547,"6
Conclusion"
CONCLUSION,0.5509433962264151,"This study introduces a novel approach to stabilize and enhance score-conditioned generators for
offline biological sequence design, incorporating the classical concepts of bootstrapping and ag-
gregation. Our novel method, named BOOTGEN, consistently outperformed all baselines across
six offline biological sequence design tasks, encompassing RNA, DNA, and protein optimization.
Our strategy of bootstrapping and aggregation yielded remarkable improvements in achieving high
scores, generating diverse samples, and minimizing performance variance."
CONCLUSION,0.5547169811320755,Acknowledgements
CONCLUSION,0.5584905660377358,"We thank all the valuable comments and suggestions from anonymous reviewers who helped
us improve and refine our paper.
This work was supported by the Institute of Informa-
tion & communications Technology Planning & Evaluation (IITP) grant funded by the Korean
government(MSIT)(2022-0-01032, Development of Collective Collaboration Intelligence Frame-
work for Internet of Autonomous Things)."
REFERENCES,0.5622641509433962,References
REFERENCES,0.5660377358490566,"[1] M.-R. Amini and P. Gallinari. Semi-supervised logistic regression. In ECAI, volume 2, page 11,
2002."
REFERENCES,0.569811320754717,"[2] C. Angermueller, D. Dohan, D. Belanger, R. Deshpande, K. Murphy, and L. Colwell. Model-
based reinforcement learning for biological sequence design. In International conference on
learning representations, 2019."
REFERENCES,0.5735849056603773,"[3] F. H. Arnold. Design by directed evolution. Accounts of chemical research, 31(3):125‚Äì131,
1998."
REFERENCES,0.5773584905660377,"[4] F. H. Arnold. Directed evolution: bringing new chemistry to life. Angewandte Chemie Inter-
national Edition, 57(16):4143‚Äì4148, 2018."
REFERENCES,0.5811320754716981,"[5] L. A. Barrera, A. Vedenko, J. V. Kurland, J. M. Rogers, S. S. Gisselbrecht, E. J. Rossin,
J. Woodard, L. Mariani, K. H. Kock, S. Inukai, et al. Survey of variation in human transcription
factors reveals prevalent dna binding changes. Science, 351(6280):1450‚Äì1454, 2016."
REFERENCES,0.5849056603773585,"[6] D. Belanger, S. Vora, Z. Mariet, R. Deshpande, D. Dohan, C. Angermueller, K. Murphy,
O. Chapelle, and L. Colwell. Biological sequences design using batched bayesian optimiza-
tion. 2019."
REFERENCES,0.5886792452830188,"[7] E. Bengio, M. Jain, M. Korablyov, D. Precup, and Y. Bengio. Flow network based genera-
tive models for non-iterative diverse candidate generation. Advances in Neural Information
Processing Systems, 34:27381‚Äì27394, 2021."
REFERENCES,0.5924528301886792,"[8] J. D. Bloom and F. H. Arnold. In the light of directed evolution: pathways of adaptive protein
evolution. Proceedings of the National Academy of Sciences, 106(supplement_1):9995‚Äì10000,
2009."
REFERENCES,0.5962264150943396,"[9] D. Brookes, H. Park, and J. Listgarten. Conditioning by adaptive sampling for robust design.
In International conference on machine learning, pages 773‚Äì782. PMLR, 2019."
REFERENCES,0.6,"[10] D. H. Brookes and J. Listgarten.
Design by adaptive sampling.
arXiv preprint
arXiv:1810.03714, 2018."
REFERENCES,0.6037735849056604,"[11] A. Chan, A. Madani, B. Krause, and N. Naik. Deep extrapolation for attribute-enhanced gen-
eration. Advances in Neural Information Processing Systems, 34:14084‚Äì14096, 2021."
REFERENCES,0.6075471698113207,"[12] C. Chen, Y. Zhang, J. Fu, X. Liu, and M. Coates. Bidirectional learning for offline infinite-
width model-based optimization.
In Advances in Neural Information Processing Systems,
2022."
REFERENCES,0.6113207547169811,"[13] C. Chen, C. Beckham, Z. Liu, X. Liu, and C. Pal. Parallel-mentoring for offline model-based
optimization. arXiv preprint arXiv:2309.11592, 2023."
REFERENCES,0.6150943396226415,"[14] C. Chen, Y. Zhang, X. Liu, and M. Coates. Bidirectional learning for offline model-based
biological sequence design. arXiv preprint arXiv:2301.02931, 2023."
REFERENCES,0.6188679245283019,"[15] C. Chen, J. Zhou, F. Wang, X. Liu, and D. Dou.
Structure-aware protein self-supervised
learning. Bioinformatics, 2023."
REFERENCES,0.6226415094339622,"[16] L. Chen, K. Lu, A. Rajeswaran, K. Lee, A. Grover, M. Laskin, P. Abbeel, A. Srinivas, and
I. Mordatch. Decision transformer: Reinforcement learning via sequence modeling. Advances
in neural information processing systems, 34:15084‚Äì15097, 2021."
REFERENCES,0.6264150943396226,"[17] T. Chen, S. Kornblith, K. Swersky, M. Norouzi, and G. E. Hinton. Big self-supervised models
are strong semi-supervised learners. Advances in neural information processing systems, 33:
22243‚Äì22255, 2020."
REFERENCES,0.630188679245283,"[18] P. A. Dalby. Strategy and success for the directed evolution of enzymes. Current opinion in
structural biology, 21(4):473‚Äì480, 2011."
REFERENCES,0.6339622641509434,"[19] C. Ekbote, M. Jain, P. Das, and Y. Bengio. Consistent training via energy-based gflownets for
modeling discrete joint distributions. arXiv preprint arXiv:2211.00568, 2022."
REFERENCES,0.6377358490566037,"[20] C. Fannjiang and J. Listgarten. Autofocused oracles for model-based design. Advances in
Neural Information Processing Systems, 33:12945‚Äì12956, 2020."
REFERENCES,0.6415094339622641,"[21] J. Fu and S. Levine. Offline model-based optimization via normalized maximum likelihood
estimation. arXiv preprint arXiv:2102.07970, 2021."
REFERENCES,0.6452830188679245,"[22] Y. Grandvalet and Y. Bengio. Semi-supervised learning by entropy minimization. Advances in
neural information processing systems, 17, 2004."
REFERENCES,0.6490566037735849,"[23] R. Haldar and D. Mukhopadhyay. Levenshtein distance technique in dictionary lookup meth-
ods: An improved approach. arXiv preprint arXiv:1101.1232, 2011."
REFERENCES,0.6528301886792452,"[24] N. Hansen. The CMA evolution strategy: a comparing review. Towards a new evolutionary
computation, pages 75‚Äì102, 2006."
REFERENCES,0.6566037735849056,"[25] T. Hesterberg. Bootstrap. Wiley Interdisciplinary Reviews: Computational Statistics, 3(6):
497‚Äì526, 2011."
REFERENCES,0.660377358490566,"[26] S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural computation, 9(8):1735‚Äì
1780, 1997."
REFERENCES,0.6641509433962264,"[27] A. Hottung, B. Bhandari, and K. Tierney. Learning a latent search space for routing problems
using variational autoencoders.
In International Conference on Learning Representations,
2020."
REFERENCES,0.6679245283018868,"[28] I. Igashov, H. St√§rk, C. Vignac, V. G. Satorras, P. Frossard, M. Welling, M. Bronstein, and
B. Correia. Equivariant 3d-conditional diffusion models for molecular linker design. arXiv
preprint arXiv:2210.05274, 2022."
REFERENCES,0.6716981132075471,"[29] M. Jain, E. Bengio, A. Hernandez-Garcia, J. Rector-Brooks, B. F. Dossou, C. A. Ekbote, J. Fu,
T. Zhang, M. Kilgour, D. Zhang, et al. Biological sequence design with gflownets. In Interna-
tional Conference on Machine Learning, pages 9786‚Äì9801. PMLR, 2022."
REFERENCES,0.6754716981132075,"[30] D. P. Kingma and J. Ba.
Adam: A method for stochastic optimization.
arXiv preprint
arXiv:1412.6980, 2014."
REFERENCES,0.6792452830188679,"[31] D. P. Kingma and M. Welling.
Auto-encoding variational bayes.
arXiv preprint
arXiv:1312.6114, 2013."
REFERENCES,0.6830188679245283,"[32] A. Kumar and S. Levine. Model inversion networks for model-based optimization. Advances
in Neural Information Processing Systems, 33:5126‚Äì5137, 2020."
REFERENCES,0.6867924528301886,"[33] R. Lorenz, S. H. Bernhart, C. H√∂ner zu Siederdissen, H. Tafer, C. Flamm, P. F. Stadler, and
I. L. Hofacker. Viennarna package 2.0. Algorithms for molecular biology, 6(1):1‚Äì14, 2011."
REFERENCES,0.690566037735849,"[34] A. Madani, B. McCann, N. Naik, N. S. Keskar, N. Anand, R. R. Eguchi, P.-S. Huang,
and R. Socher.
Progen:
Language modeling for protein generation.
arXiv preprint
arXiv:2004.03497, 2020."
REFERENCES,0.6943396226415094,"[35] M. Mirza and S. Osindero.
Conditional generative adversarial nets.
arXiv preprint
arXiv:1411.1784, 2014."
REFERENCES,0.6981132075471698,"[36] H. Moss, D. Leslie, D. Beck, J. Gonzalez, and P. Rayson. Boss: Bayesian optimization over
string spaces. Advances in neural information processing systems, 33:15476‚Äì15486, 2020."
REFERENCES,0.7018867924528301,"[37] K. Nigam and R. Ghani.
Analyzing the effectiveness and applicability of co-training.
In
Proceedings of the ninth international conference on Information and knowledge management,
pages 86‚Äì93, 2000."
REFERENCES,0.7056603773584905,"[38] E. O. Pyzer-Knapp. Bayesian optimization for accelerated drug discovery. IBM Journal of
Research and Development, 62(6):2‚Äì1, 2018."
REFERENCES,0.7094339622641509,"[39] A. Ramesh, P. Dhariwal, A. Nichol, C. Chu, and M. Chen. Hierarchical text-conditional image
generation with clip latents. arXiv preprint arXiv:2204.06125, 2022."
REFERENCES,0.7132075471698113,"[40] Z. Ren, J. Li, F. Ding, Y. Zhou, J. Ma, and J. Peng. Proximal exploration for model-guided
protein sequence design. In K. Chaudhuri, S. Jegelka, L. Song, C. Szepesvari, G. Niu, and
S. Sabato, editors, Proceedings of the 39th International Conference on Machine Learning,
volume 162 of Proceedings of Machine Learning Research, pages 18520‚Äì18536. PMLR, 17‚Äì
23 Jul 2022. URL https://proceedings.mlr.press/v162/ren22a.html."
REFERENCES,0.7169811320754716,"[41] P. J. Sample, B. Wang, D. W. Reid, V. Presnyak, I. J. McFadyen, D. R. Morris, and G. Seelig.
Human 5‚Äô utr design and variant effect prediction from a massively parallel translation assay.
Nature biotechnology, 37(7):803‚Äì809, 2019."
REFERENCES,0.720754716981132,"[42] S. Sinai, R. Wang, A. Whatley, S. Slocum, E. Locane, and E. D. Kelsic.
Adalead: A
simple and robust adaptive greedy search algorithm for sequence design.
arXiv preprint
arXiv:2010.02141, 2020."
REFERENCES,0.7245283018867924,"[43] K. Terayama, M. Sumita, R. Tamura, and K. Tsuda. Black-box optimization for automated
discovery. Accounts of Chemical Research, 54(6):1334‚Äì1346, 2021."
REFERENCES,0.7283018867924528,"[44] B. Trabucco, A. Kumar, X. Geng, and S. Levine. Conservative objective models for effective
offline model-based optimization. In International Conference on Machine Learning, pages
10358‚Äì10368. PMLR, 2021."
REFERENCES,0.7320754716981132,"[45] B. Trabucco, X. Geng, A. Kumar, and S. Levine. Design-bench: Benchmarks for data-driven
offline model-based optimization. arXiv preprint arXiv:2202.08450, 2022."
REFERENCES,0.7358490566037735,"[46] A. Tripp, E. Daxberger, and J. M. Hern√°ndez-Lobato. Sample-efficient optimization in the la-
tent space of deep generative models via weighted retraining. Advances in Neural Information
Processing Systems, 33:11259‚Äì11272, 2020."
REFERENCES,0.7396226415094339,"[47] H. Wang, A. Sakhadeo, A. M. White, J. M. Bell, V. Liu, X. Zhao, P. Liu, T. Kozuno, A. Fyshe,
and M. White. No more pesky hyperparameters: Offline hyperparameter tuning for RL. Trans-
actions on Machine Learning Research, 2022. URL https://openreview.net/forum?id=
AiOUi3440V."
REFERENCES,0.7433962264150943,"[48] K. Wang, H. Zhao, X. Luo, K. Ren, W. Zhang, and D. Li. Bootstrapped transformer for offline
reinforcement learning. arXiv preprint arXiv:2206.08569, 2022."
REFERENCES,0.7471698113207547,"[49] R. J. Williams. Simple statistical gradient-following algorithms for connectionist reinforce-
ment learning. Machine learning, 8(3):229‚Äì256, 1992."
REFERENCES,0.7509433962264151,"[50] J. T. Wilson, R. Moriconi, F. Hutter, and M. P. Deisenroth. The reparameterization trick for
acquisition functions. arXiv preprint arXiv:1712.00424, 2017."
REFERENCES,0.7547169811320755,"[51] Q. Xie, M.-T. Luong, E. Hovy, and Q. V. Le. Self-training with noisy student improves im-
agenet classification. In Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition, pages 10687‚Äì10698, 2020."
REFERENCES,0.7584905660377359,"[52] S. Yu, S. Ahn, L. Song, and J. Shin. Roma: Robust model adaptation for offline model-based
optimization. Advances in Neural Information Processing Systems, 34:4619‚Äì4631, 2021."
REFERENCES,0.7622641509433963,"[53] Y. Yuan, C. Chen, Z. Liu, W. Neiswanger, and X. Liu. Importance-aware co-teaching for
offline model-based optimization. arXiv preprint arXiv:2309.11600, 2023."
REFERENCES,0.7660377358490567,"[54] M. Zimmer. Green fluorescent protein (GFP): applications, structure, and related photophysical
behavior. Chemical reviews, 102(3):759‚Äì782, 2002."
REFERENCES,0.769811320754717,"A
Additional Experimental Settings"
REFERENCES,0.7735849056603774,"Table A.1: Details of the offline datasets. We let |X| and |D| denote the sizes of the search space and the offline
dataset, respectively."
REFERENCES,0.7773584905660378,"Seq. Length
Vocab size
|X|
|D|"
REFERENCES,0.7811320754716982,"GFP
20
237
20237
5,000
UTR
50
4
504
140,000
TFBind8
8
8
48
32,898
RNA-Binding
14
4
414
5,000"
REFERENCES,0.7849056603773585,"A.1
Datasets"
REFERENCES,0.7886792452830189,"‚Ä¢ GFP [41] is a task to optimize a protein sequence of length 237 consisting of one of 20
amino acids, i.e., the search space is 20237. Its objective is to find a protein with high
fluorescence. Following Trabucco et al. [45], we prepare the offline dataset using 5000
samples with 50 to 60 percentile scores in the original data.
‚Ä¢ UTR [41] is a task to optimize a DNA sequence of length 50 consisting of one of four
nucleobases: adenine (A), guanine (G), cytosine (C), thymine (T). Its objective is to max-
imize the expression level of the corresponding 5‚ÄôUTR region. For the construction of the
offline dataset D, following Trabucco et al. [45], we provide samples with scores under the
50th percentile data of 140, 000 examples.
‚Ä¢ TFBind8 [5] is a task that optimizes DNA similar to the UTR. The objective is to find a
length 8 sequence to maximize the binding activity with human transcription factors. For
the offline dataset D, we provide under 50th percentile data of 32,898 examples following
Trabucco et al. [45].
‚Ä¢ RNA-Binding [33] is a task that optimizes RNA, a sequence that contains four vocab words
of nucleobases: adenine (A), uracil (U), cytosine (C), and guanine (G). The objective is to
find a length 14 sequence to maximize the binding activity with the target transcription
factor. We present three target transcriptions of RNA termed RNA-Binding-A (for L14
RNA1), RNA-Binding-B (for L14 RNA2), and RNA-Binding-C (for L14 RNA3). We
provide under 0.12 scored data for the offline dataset D among randomly generated 5,000
sequences using open-source code 2."
REFERENCES,0.7924528301886793,"A.2
Implementation of Baselines"
REFERENCES,0.7962264150943397,This section provides a detailed implementation of baselines of offline biological sequence design.
REFERENCES,0.8,"Baselines from Design Bench [45].
Most baselines are from the offline model-based optimiza-
tion (MBO) benchmark called design-bench [45]. The design bench contains biological sequence
tasks of the GFP, UTR, and TFbind8, where it contains baselines of REINFORCE, CMA-ES [24],
BO-qEI [50], CbAS [9], Auto. Cbas [20], MIN [32], gradient ascent (Grad.), and COMS [44]. We
reproduce them by following the official source code 3. For the RNA tasks, we follow hyperparam-
eters of TFBind8 as the number of vocab are same as 4, and the sequence length is similar where
the TFBind8 has length 8 and RNA tasks have length 14 as our method follows the same."
REFERENCES,0.8037735849056604,"BDI [12]. For BDI, we follow hyperparameter setting at the paper [12] and implementation at the
opensource code 4. For RNA tasks, we follow the hyperparameter for TFBind8 tasks, as our method
follows the same."
REFERENCES,0.8075471698113208,"GFN-AL [29]. For GFN-AL we follow hyperparameters setting at the paper [29] and implementa-
tion on open-source code5. Because they only reported the TFbind8 and the GFP tasks, we use the
hyperparameter of the GFP for the UTR tasks hyperparameter of the TFBind8 for RNA tasks, as our
method follows the same."
REFERENCES,0.8113207547169812,"2https://github.com/samsinai/FLEXS
3https://github.com/brandontrabucco/design-baselines
4https://github.com/GGchen1997/BDI
5https://github.com/MJ10/BioSeq-GFN-AL"
REFERENCES,0.8150943396226416,"A.3
Hyperparameters"
REFERENCES,0.8188679245283019,"Table A.2: Hyperparameters. I denotes the number of bootstrapping iterations after pretraining, I‚Ä≤ denotes
the number of pretaining iterations, M represents the number of samples used in inference, K stands for the
number of filtered samples among M candidates, and Ngen refers to the number of aggregated generators in the
experiments."
REFERENCES,0.8226415094339623,"I
I‚Ä≤
M
K
Ngen
2,500
12,500
1,280
128
8"
REFERENCES,0.8264150943396227,"Training. We give consistency hyperparameters for all tasks except the learning rate. We set the
generator‚Äôs learning rate to 10‚àí5 for short-length tasks (lengths 8 and 14) of TFBind and RNA
tasks and 5 √ó 10‚àí5 for longer-length tasks (lengths 50 and 237) of UTR and GFP. We trained the
generator with 12,500 steps before bootstrapping. Bootstrapping is applied with 2, 500 in additional
steps. The batch size of training is 256. We set the weighting parameter k = 10‚àí2. Note that we
early-stopped the generator iteration of GFP with the 3, 000 step based on monitoring the calibration
model of Appendix B. For bootstrapping, the generator samples 2 candidates every 5 steps. For
Top-K sampling at the bootstrapping, we sample with L = 1, 000 and select the Top 2 samples to
augment the training dataset."
REFERENCES,0.8301886792452831,"Testing. For filtering, we generated M = 1, 280 candidate samples and collected the Top-K samples
where K = 128 based on the proxy score. For diverse aggregation, we collect K = 16 samples
from 8 generators, making a total of 128 samples."
REFERENCES,0.8339622641509434,"Proxy model. For the proxy model, we applied a weight regularization of 10‚àí4, set the learning
rate to 10‚àí4, and used a dropout rate of 0.1. We used early stopping with a tolerance of 5 and
a train/validate ratio of 9:1 following Jain et al. [29]. We used the Adam optimizer [30] for the
training generator, proxy, and calibration model."
REFERENCES,0.8377358490566038,"B
Calibration Model"
TH PERCENTILE,0.8415094339622642,"100th Percentile
50th Percentile
Calibration model"
TH PERCENTILE,0.8452830188679246,"0
2500
5000
7500
10000
12500
15000
Iteration 0.5 0.6 0.7 0.8 0.9 Score 0.4 0.5 0.6 0.7 0.8"
TH PERCENTILE,0.8490566037735849,Calibration score
TH PERCENTILE,0.8528301886792453,(a) TFbind8
TH PERCENTILE,0.8566037735849057,"0
2500
5000
7500
10000
12500
15000
Iteration 0.0 0.2 0.4 0.6 0.8 1.0 Score 0.3 0.4 0.5 0.6 0.7 0.8"
TH PERCENTILE,0.8603773584905661,Calibration score
TH PERCENTILE,0.8641509433962264,(b) GFP
TH PERCENTILE,0.8679245283018868,Figure B.1: Calibration model‚Äôs tendency.
TH PERCENTILE,0.8716981132075472,"Tuning the hyperparameters of offline design algorithms is challenging due to the lack of access to
the true score function. Therefore, existing works have proposed various strategies to circumvent
this issue, e.g., choosing a hyperparameter that is transferrable between different tasks [45] or tuning
the hyperparameter based on training statistics [52]."
TH PERCENTILE,0.8754716981132076,"In this work, we leverage the calibration function. Inspired by Wang et al. [47], we train the cal-
ibration function on the offline dataset to approximate the true score function similar to the proxy
function. Then we use the calibration function to select a score-conditioned model that achieves
higher performance with respect to the calibration function. We also choose the number of training
steps and early stopping points using the same criterion."
TH PERCENTILE,0.879245283018868,"As shown in Fig. B.1, the calibration model accurately predicts early stopping points as the GFP task
is unstable and has a narrow high score region which gives a high chance to be overfitted into the
low-scored region (Table 4.1 shows that score of GFP is highly polarized). By using the calibration
function, we can simply choose an early stopping point for GFP. Note we simply leverage the proxy
model as a calibration model with an exact sample training scheme and hyperparameters."
TH PERCENTILE,0.8830188679245283,"C
Diversity and Novelty Comparison with GFN-AL [29]"
TH PERCENTILE,0.8867924528301887,"Table C.1: Experimental results on 100th percentile scores (100th Per.), 50th percentile scores (50th Per.),
average score (Avg. Score), diversity, and novelty, among 128 samples of low dimensional tasks comparing
with GFN-AL. The mean and standard deviation of 8 independent runs for producing 128 samples is reported.
The best-scored value is marked in bold."
TH PERCENTILE,0.8905660377358491,"Methods
100th Per.
50th Per.
Avg. Score
Diversity
Novelty RNA-A"
TH PERCENTILE,0.8943396226415095,"GFN-AL
0.630 ¬± 0.054
0.312 ¬± 0.013
0.320 ¬± 0.010
8.858 ¬± 0.045
4.269 ¬± 0.130"
TH PERCENTILE,0.8981132075471698,"BOOTGEN
0.898 ¬± 0.039
0.694 ¬± 0.009
0.699 ¬± 0.008
5.694 ¬± 0.008
7.509 ¬± 0.049
BOOTGEN‚Ä†
0.750 ¬± 0.041
0.382 ¬± 0.014
0.399 ¬± 0.008
8.917 ¬± 0.078
4.957 ¬± 0.052 RNA-B"
TH PERCENTILE,0.9018867924528302,"GFN-AL
0.677 ¬± 0.080
0.300 ¬± 0.012
0.311 ¬± 0.011
8.846 ¬± 0.050
4.342 ¬± 0.128"
TH PERCENTILE,0.9056603773584906,"BOOTGEN
0.886 ¬± 0.028
0.689 ¬± 0.007
0.693 ¬± 0.007
5.192 ¬± 0.073
7.981 ¬± 0.036
BOOTGEN‚Ä†
0.686 ¬± 0.052
0.355 ¬± 0.018
0.371 ¬± 0.017
8.929 ¬± 0.121
4.967 ¬± 0.132 RNA-C"
TH PERCENTILE,0.909433962264151,"GFN-AL
0.623 ¬± 0.045
0.324 ¬± 0.010
0.333 ¬± 0.010
8.831 ¬± 0.046
4.151 ¬± 0.088"
TH PERCENTILE,0.9132075471698113,"BOOTGEN
0.837 ¬± 0.045
0.598 ¬± 0.006
0.606 ¬± 0.006
4.451 ¬± 0.071
7.243 ¬± 0.051
BOOTGEN‚Ä†
0.651 ¬± 0.056
0.370 ¬± 0.011
0.376 ¬± 0.013
8.913 ¬± 0.087
4.597 ¬± 0.073"
TH PERCENTILE,0.9169811320754717,TFBind8
TH PERCENTILE,0.9207547169811321,"GFN-AL
0.951 ¬± 0.026
0.537 ¬± 0.055
0.575 ¬± 0.037
5.001 ¬± 0.178
0.778 ¬± 0.143"
TH PERCENTILE,0.9245283018867925,"BOOTGEN
0.977 ¬± 0.004
0.848 ¬± 0.010
0.839 ¬± 0.009
3.118 ¬± 0.045
1.802 ¬± 0.025
BOOTGEN‚Ä†
0.970 ¬± 0.018
0.613 ¬± 0.017
0.627 ¬± 0.014
5.048 ¬± 0.039
0.965 ¬± 0.033"
TH PERCENTILE,0.9283018867924528,"Table C.2: Experimental results on 100th percentile scores (100th Per.), 50th percentile scores (50th Per.),
average score (Avg. Score), diversity, and novelty, among 128 samples of 6 six biological sequential tasks
comparing with GFN-AL. The mean and standard deviation of 8 independent runs for producing 128 samples
is reported. The best-scored value is marked in bold. The ‚ÄòRandom‚Äô stands for uniform random generator."
TH PERCENTILE,0.9320754716981132,"Methods
100th Per.
50th Per.
Avg. Score
Diversity
Novelty GFP"
TH PERCENTILE,0.9358490566037736,"Random
0.053 ¬± 0.000
0.051 ¬± 0.000
0.051 ¬± 0.000
219.840 ¬± 0.207
216.960 ¬± 0.330
GFN-AL
0.057 ¬± 0.001
0.051 ¬± 0.004
0.052 ¬± 0.004
130.113 ¬± 41.202
208.610 ¬± 46.271"
TH PERCENTILE,0.939622641509434,"BOOTGEN
0.865 ¬± 0.000
0.854 ¬± 0.002
0.813 ¬± 0.011
7.969 ¬± 0.460
2.801 ¬± 0.163"
TH PERCENTILE,0.9433962264150944,"Building upon the ¬ß 4.4 findings of the UTR, we present further multi-objective experimental results
for the remaining 5 tasks, comparing them closely with the GFN-AL [29] approach. The GFN-AL
model aims to achieve extensive exploration by prioritizing sample diversity and novelty, leading
to the generation of diverse, high-quality biological sequences. Nevertheless, the diversity measure
occasionally introduces a trade-off between sample scores, particularly when certain tasks exhibit a
narrow score landscape, resulting in only a limited number of samples with high scores."
TH PERCENTILE,0.9471698113207547,"We conducted a detailed analysis to shed light on the relationship between score metrics (average,
100th percentile, 50th percentile) and diversity metrics (diversity and novelty). The results, pre-
sented in Table C.2, demonstrate that our proposed method, BOOTGEN, outperforms GFN-AL in
terms of score performance. However, it is noteworthy that GFN-AL exhibits high diversity, par-
ticularly in the case of GFP. On the contrary, GFN-AL generates extremely low scores for GFP,
almost comparable to those produced by a uniform random generator. This observation indicates
that the GFP task possesses a narrow score landscape, making it relatively easy to generate diverse
yet low-scoring samples."
TH PERCENTILE,0.9509433962264151,"For the TFbind8 and RNA tasks, GFN-AL achieves high diversity but a low novelty. This suggests
that GFN-AL struggles to discover samples beyond the scope of the offline training dataset, resulting
in less novel but diverse samples with low scores. In contrast, BOOTGEN successfully identifies
high-scoring and novel samples. Consequently, in this scenario, we consider high diversity coupled
with low novelty and score to be somewhat meaningless, as such results can also be achieved by a
random generator."
TH PERCENTILE,0.9547169811320755,"To substantiate our claim regarding diversity, we present experimental results of an enhanced di-
versity version of BOOTGEN. In order to achieve increased diversity, BOOTGEN makes certain
sacrifices in terms of score performance. One approach we employ is interpolation with a uniform
random sequence generator. Specifically, we combine our generator with the uniform random gen-"
TH PERCENTILE,0.9584905660377359,"erator to generate random samples in a portion of the sequence (we make 3/4 samples from the
random generator and 1/4 from BOOTGEN). Additionally, we can filter out low-diversity sequences
without requiring score evaluation, thereby generating a more diverse set of samples by referring
code of GFN-AL [29]. To this end, we introduce the diversity-improved version of our method,
denoted as BOOTGEN‚Ä†. It is important to note that BOOTGEN‚Ä† sacrifices score performance, as
diversity and score are inherent trade-offs, and it focuses primarily on diversity to provide a more
direct comparison with GFN-AL by manually adjusting diversity."
TH PERCENTILE,0.9622641509433962,"As shown in Table C.2, BOOTGEN‚Ä† exhibits similar diversity levels in RNA-A, RNA-B, RNA-C,
and TFBind8, while achieving higher score metrics and novelty. We attribute these results to GFN‚Äôs
underfitting issue, as it fails to adequately fit within the high-scoring region of the score landscape,
particularly for the high-dimensional tasks of UTR and GFP."
TH PERCENTILE,0.9660377358490566,"D
Rank-based weighting vs. Value-based weighting"
TH PERCENTILE,0.969811320754717,"0
2000
4000
6000
8000 10000 12000 14000
Iteration 0.65 0.70 0.75 0.80 0.85 Score"
TH PERCENTILE,0.9735849056603774,"NW
VW (T=0.1)"
TH PERCENTILE,0.9773584905660377,VW (T=0.3)
TH PERCENTILE,0.9811320754716981,VW (T=0.7)
TH PERCENTILE,0.9849056603773585,VW (T=1.0)
TH PERCENTILE,0.9886792452830189,RW (ours)
TH PERCENTILE,0.9924528301886792,"Figure D.1: Comparison of rank-based weighting (RW) and value-based weighting (VW) methods. The NW
represents the case where no weighting is applied to the training distribution. In the VW case, we explored
different weighting temperatures, T ‚àà{0.1, 0.3, 0.7, 1.0}. The 50th percentile scores of TFBind8 are reported,
and the results include a bootstrapping procedure applied from iteration 12,500 to 15,000."
TH PERCENTILE,0.9962264150943396,"We verify the contribution of the rank-based weighting (RW) scheme compared to ours with no
weighting (NW) and the existing value-based weighting (VW) proposed by Kumar and Levine [32].
To implement VW, we set the sample-wise weight proportional to exp(|y ‚àíy‚àó|/T), where y‚àóis the
maximum score in the training dataset and T ‚àà{0.1, 0.3, 0.7, 1.0} is a hyperparameter. As shown
in Fig. D.1, the results indicate that RW outperforms both NW and VW. This validates our design
choice for BOOTGEN."
