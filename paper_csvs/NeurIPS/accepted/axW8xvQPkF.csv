Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0013422818791946308,"We study fairness in social influence maximization, whereby one seeks to select
seeds that spread a given information throughout a network, ensuring balanced
outreach among different communities (e.g. demographic groups). In the literature,
fairness is often quantified in terms of the expected outreach within individual
communities. In this paper, we demonstrate that such fairness metrics can be
misleading since they overlook the stochastic nature of information diffusion
processes. When information diffusion occurs in a probabilistic manner, multiple
outreach scenarios can occur. As such, outcomes such as “In 50% of the cases, no
one in group 1 gets the information, while everyone in group 2 does, and in the
other 50%, it is the opposite”, which always results in largely unfair outcomes,
are classified as fair by a variety of fairness metrics in the literature. We tackle
this problem by designing a new fairness metric, mutual fairness, that captures
variability in outreach through optimal transport theory. We propose a new seed-
selection algorithm that optimizes both outreach and mutual fairness, and we show
its efficacy on several real datasets. We find that our algorithm increases fairness
with only a minor decrease (and at times, even an increase) in efficiency."
INTRODUCTION,0.0026845637583892616,"1
Introduction"
INTRODUCTION,0.004026845637583893,"Problem Description.
Social networks play a fundamental role in the spread of information, as in
the context of commercial products endorsement [17], job vacancy advertisements [3], public health
awareness [27], etc. Information, ideas, or new products can either go viral and potentially bring
significant changes in a community or die out quickly. In this context, a fundamental algorithmic prob-
lem arises, known as Social Influence Maximization (SIM) [11, 12]. SIM studies how to strategically
select a pre-specified small proportion of nodes in the social network – the early adopters or seeds –
so that the outreach generated by a diffusion process that starts at these early adopters is maximized.
Consider, for example, a product endorsement campaign: the early adopters are strategically selected
users who receive the product first to promote it to their friends, who in turn may or may not adopt
it. The optimal selection of early adopters is known to be an NP-hard problem [11]. Thus, many
heuristic strategies have been proposed, based on iterative processes such as greedy algorithms or on
network centrality measures. However, all these algorithms purely rely on the graph topology and are
agnostic to users’ demographics, which raises significant fairness concerns, especially in contexts
of health awareness campaigns, education, and job advertisements, where one wants to ensure an"
INTRODUCTION,0.005369127516778523,∗Authors contributed equally.
INTRODUCTION,0.006711409395973154,"equitable spreading of information. Indeed, real-world social networks are populated by different
social groups based on gender, age, race, geography, etc., with different group sizes or connectivity
patterns. Ignoring these aspects and focusing only on the outreach maximization process usually
leads to the early adopters being the most central nodes. Consequently, low-interconnected minorities
are often neglected from the diffusion process, thus causing fundamental inequity in the information
propagation and biases exacerbation [10, 25]."
INTRODUCTION,0.008053691275167786,"Related Work.
The problem of SIM was first introduced in 2003 in Kempe et al. [11], where the
problem of optimally selecting a (limited) set of early adopters was proved to be NP-hard. The study
of SIM under fairness guarantees has a more recent history [5]. Several multiple group-level fairness
metrics have been proposed over the years [6]. They fall under the notions of equity [23, 9, 10],
equality [6], max-min fairness [7, 30], welfare [16], and diversity [25]: all of them quantify the
fair distribution of influence across groups. In particular, Stoica et al. [23] propose a new SIM
algorithm that operates under the constraint that, in expectation, the same percentage of users in
each category is reached. Junaid et al. [9] optimize outreach under fairness and time constraints, by
ensuring that the expected fraction of influenced nodes in each group is the same within a prescribed
time deadline. Farnadi et al. [6] propose a unifying framework that encodes all different definitions
of fairness in the SIM process as constraints in a linear program that optimizes outreach. Several
other works [7, 30] adopt a max-min strategy. Specifically, in Fish et al. [7] fairness is ensured by
maximizing the minimum probability of a group receiving the information through modifications
of the greedy algorithm. Zhu et al. [30] ensure that the outreach contains a pre-specified proportion
of each group in a population. Finally, Tsang et al. [25] optimize outreach under the constraint that
no group should be better off by leaving the influence maximization process with their proportional
allocation of resources done internally. All these definitions involve a marginal expected value of
fairness in groups, without considering the correlations – or other higher-order moments – for the
joint probability distribution of different groups adopting the information (see Farnadi et al. [6] for
an overview). In contrast, our work introduces a novel formalism for taking into account the actual
joint distribution of outreach among groups, thus considering all groups simultaneously, highlighting
limitations of various fairness metrics and developing a new seed selection policy that strategically
extracts and optimizes our proposed notion of fairness. To conclude, our work is inspired by a recent
line of work that draws on optimal transport theory [28] for fairness guarantees [2, 4, 21, 29, 20, 24].
To our knowledge, this is the first work to develop novel metrics and seeding algorithms that leverage
optimal transport for the SIM problem."
INTRODUCTION,0.009395973154362415,"Motivation.
Many models of diffusion processes in the SIM problem are inherently stochastic,
meaning that who gets the information transmitted can vary greatly from one run to another. Consider,
as an example, the case in which 50% of realizations over a diffusion process, no one in group 1
receives the information and everyone in group 2 does, whereas in the other 50% it is the opposite.
This circumstance would be classified as fair in expectation, even though it is commonly not perceived
as “fair”. We show how this phenomenon is common in real-world data and how our proposed
framework can detect such undesired scenarios. This prompts us to study a novel fairness metric."
INTRODUCTION,0.010738255033557046,"Contributions.
Our main contribution is twofold: first, we propose a new fairness metric based
on optimal transport, called mutual fairness, and second, we propose a novel seeding algorithm that
optimizes for both the group-wise total outreach (termed efficiency) and fairness. Our proposed
fairness metric provides stronger fairness guarantees, and it reveals and overcomes known limitations
of various other fairness metrics in the literature. Specifically, we leverage optimal transport theory
to build mutual fairness, a metric that accounts for all groups simultaneously in terms of the distance
between an ideal distribution where all groups receive the information in the same proportion. We
leverage our proposed mutual fairness metric to provide a unifying framework that classifies the most
celebrated information-spreading algorithms both in terms of fairness and efficiency. All algorithms
are tested on a variety of real-world datasets. We show how our approach unveils new insights into the
role of network topology on fairness; in particular, we observe that selecting group-label blind seeds
in networks with moderate levels of homophily induces inequality in information access. In contrast,
very integrated or very segregated networks tend to have quite fair and efficient access to information
across different groups upon greedy seedset selection. We then extend our mutual fairness metric
to also account for efficiency, thus introducing the notion of β-fairness, with β being the tuning
parameter for the fairness-efficiency trade-off. Finally, we design a new seedset selection algorithm
that optimizes over the proposed β-fairness metric and enhances fairness with either a small trade-off"
INTRODUCTION,0.012080536912751677,"or even improved efficiency. This novel approach provides a comprehensive evaluation and design
tool that bridges the gap between fairness and efficiency in SIM problems."
PRELIMINARIES,0.013422818791946308,"2
Preliminaries"
PRELIMINARIES,0.01476510067114094,"Notation. Given m ∈N, we let [m] denote the interval of integers from 1 to m. We denote by G
a network, considered undirected, and by (Ci)i∈[m] the m groups of different sensitive attributes.
In this paper, we consider m = 2 groups, noting that our framework is easily generalizable to more
groups as discussed in Appendix B. We denote by ϕG(S) the influence function of a seedset S over
a network G, through some diffusion process. In other words, ϕG(S) determines the set of nodes
reached by the seedset under a diffusion process. Then, |ϕG(S)| is often referred to as the outreach,
a measure of efficiency for the selection of a seedset S. Under a stochastic diffusion process (e.g.,
independent cascade, linear threshold model, etc.), |ϕG(S)| is a random variable, for which we
are interested in the expected value and distribution. For a particular outreach, we define the final
configuration at the end of a diffusion process as follows."
PRELIMINARIES,0.016107382550335572,"Definition 2.1 (Final configuration) For a network G with two communities (Ci)i∈[2] and a seedset
S, we let xi, i ∈[2], denote the fraction of nodes in each community in the outreach ϕG(S). The final
configuration is the tuple (x1, x2)."
PRELIMINARIES,0.0174496644295302,"In many definitions in the literature, fairness is operationalized by measuring the expected value of
the final configuration, where the expectation is taken over the diffusion process. In particular, the
equity definition introduced by Stoica et al. [23], Junaid et al. [9] checks that the expected value of the
proportions of each group reached in the outreach is the same for all groups. For a formal definition
of equity and other fairness definitions in the literature, see Appendix A. We will show that relying
solely on the expected value leads largely unfair outcomes to be classified as fair."
MUTUAL FAIRNESS VIA OPTIMAL TRANSPORT,0.01879194630872483,"3
Mutual Fairness via Optimal Transport"
MUTUAL FAIRNESS VIA OPTIMAL TRANSPORT,0.020134228187919462,"In contrast to the literature, we propose using the joint outreach probability distribution, instead of its
marginals, to capture simultaneous outreach between the two groups and therefore address questions
like (i) When group 1 receives the information, will group 2 also receive it? (ii) Even if the two
groups have the same marginal outreach probability distributions will the final configuration always
be fair? We argue that capturing these aspects is crucial for understanding and assessing fairness, as
shown in the motivating example below."
MUTUAL FAIRNESS VIA OPTIMAL TRANSPORT,0.021476510067114093,"Notation.
We collect the output of the information-spreading process via a probability distribution
γ ∈P([0, 1] × [0, 1]) over all possible final configurations. Informally, γ(x1, x2) is the probability
that a fraction x1 of group 1 receives the information and a fraction x2 of group 2 receives the
information; e.g., γ(0.3, 0.4) represents the probability that 30% of group 1 and 40% of group
2 receive the information. We can marginalize γ to obtain the outreach probability distributions
associated with each group; i.e., µ1 ∈P([0, 1]) and µ2 ∈P([0, 1]). Informally, we can write
µ1(x1) = P"
MUTUAL FAIRNESS VIA OPTIMAL TRANSPORT,0.022818791946308724,"x2 γ(x1, x2). As in the example above, µi(0.3) is the probability that 30% of group i
receives the information."
MUTUAL FAIRNESS VIA OPTIMAL TRANSPORT,0.024161073825503355,"Motivating Example.
Consider the SIM problem with nodes belonging to two groups, C1 and C2,
each group having the outreach probability distribution µi = 1"
MUTUAL FAIRNESS VIA OPTIMAL TRANSPORT,0.025503355704697986,2δ0 + 1
MUTUAL FAIRNESS VIA OPTIMAL TRANSPORT,0.026845637583892617,"2δ1, i ∈{1, 2}, with δk represent-
ing the delta distribution at k ∈[0, 1]. That is, in 50% of the cases all members in group i receive the
information (i.e., we get xi = 1.0) and in 50% of the cases no one in group i receives the information
(i.e., we get xi = 0.0). It is therefore tempting to say that this setting is fair since µ1 and µ2 coincide
and therefore share the same expected value. We argue that this information does not suffice to claim
fairness. Indeed, consider the two following probability distributions over the final configurations:"
MUTUAL FAIRNESS VIA OPTIMAL TRANSPORT,0.028187919463087248,"γa = 0.5 · δ(0,0) + 0.5 · δ(1,1),
γb = 0.25 · δ(0,0) + 0.25 · δ(1,1) + 0.25 · δ(0,1) + 0.25 · δ(1,0),"
MUTUAL FAIRNESS VIA OPTIMAL TRANSPORT,0.02953020134228188,"with δ(i,j), representing the delta distribution at (i, j) ∈[0, 1]2. Interestingly, both γa and γb are
“compatible” with µ1 and µ2: If we compute their marginals, we obtain µ1 and µ2. However, γa"
MUTUAL FAIRNESS VIA OPTIMAL TRANSPORT,0.03087248322147651,"and γb encode two fundamentally different final configurations. In γa, the percentage of members"
MUTUAL FAIRNESS VIA OPTIMAL TRANSPORT,0.032214765100671144,% outreach group 2
MUTUAL FAIRNESS VIA OPTIMAL TRANSPORT,0.03355704697986577,"% outreach group 1 γb
γa"
MUTUAL FAIRNESS VIA OPTIMAL TRANSPORT,0.0348993288590604,"Figure 1: Illustration of the (γa,γb) example."
MUTUAL FAIRNESS VIA OPTIMAL TRANSPORT,0.036241610738255034,% outreach group 2
MUTUAL FAIRNESS VIA OPTIMAL TRANSPORT,0.03758389261744966,% outreach group 1
MUTUAL FAIRNESS VIA OPTIMAL TRANSPORT,0.038926174496644296,"(x1, x2)"
MUTUAL FAIRNESS VIA OPTIMAL TRANSPORT,0.040268456375838924,"(y1, y2)"
MUTUAL FAIRNESS VIA OPTIMAL TRANSPORT,0.04161073825503356,"z(x1, x2, y1, y2)"
MUTUAL FAIRNESS VIA OPTIMAL TRANSPORT,0.042953020134228186,"Figure 2: The transportation cost measures the
length of the solid segment; shifts along the diag-
onal (dotted) are not considered for fairness and
are only relevant for efficiency."
MUTUAL FAIRNESS VIA OPTIMAL TRANSPORT,0.04429530201342282,"of group 1 who get the information always coincides with the percentage of people of group 2. Con-
versely, in γb, more outcomes are possible; in particular, there is a probability of 0.25 + 0.25 = 0.5
that all members of one group receive the information and no member of the other group receives
it (see Fig. 1). Thus, from a fairness perspective, γa and γb encode very different outcomes. We
therefore argue that a fairness metric should be expressed in terms of joint probability distribution
γ, and not solely based on its marginals µ1 and µ2, as commonly done in the literature [23, 9]."
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.04563758389261745,"3.1
A Fairness Metric Based on Optimal Transport"
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.04697986577181208,"Our motivating example prompts us to reason about fairness in terms of the joint probability measure
γ, instead of its marginal distributions µ1 and µ2. Since γ is a probability distribution (over all
possible final configurations), we can quantify fairness by computing its “distance” from an “ideal”
reference distribution γ∗along the diagonal, capturing the ideal situation in which both groups receive
the information in the same proportion. We do so by using tools from optimal transport."
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.04832214765100671,"Background in optimal transport.
For a given (continuous) transportation cost c : ([0, 1]×[0, 1])×
([0, 1] × [0, 1]) →R≥0, the optimal transport discrepancy between two probability distributions
γa ∈P([0, 1] × [0, 1]) and γb ∈P([0, 1] × [0, 1]) is defined as"
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.049664429530201344,"Wc(γa, γb) =
min
π∈Π(γa,γb) E(x1,x2),(y1,y2)∼π, [c((x1, x2), (y1, y2))],
(1)"
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.05100671140939597,"where Π(γa, γb) is the set of probability distributions over ([0, 1] × [0, 1]) × ([0, 1] × [0, 1]) so that
the first marginal is γa and the second marginal is γb. Intuitively, the optimal transport problem
quantifies the minimum transportation cost to morph γa into γb when transporting a unit of mass from
(x1, x2) to (y1, y2) costs c((x1, x2), (y1, y2)). The optimization variable π is called transportation
plan and π((x1, x2), (y1, y2)) indicates the amount of mass at (x1, x2) displaced to (y1, y2). Thus,
its first marginal has to be γa(x1, x2) (that is, (x1, x2) has to be transported to some (y1, y2)) and its
second marginal must be γb(y1, y2) (that is, the mass at (y1, y2) has to arrive from some (x1, x2)).
If the transportation cost c is chosen to be a p ≥1 power of a distance d, then (Wdp(·, ·))1/p is a
distance on the space of probability distributions. When the probability distributions are discrete (or
the space [0, 1] is discretized), the transportation problem (1) is a finite-dimensional linear program
and can therefore be solved efficiently [15]."
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.052348993288590606,"Our proposed fairness metric.
To operationalize the optimal transport problem (1), we therefore
need to define (i) a transportation cost and (ii) a reference distribution γ∗. To define the transportation
cost, we start with the following two considerations. First, moving mass along the diagonal should
have zero cost, as it does not affect fairness but only efficiency (the proportion of population reached
in respective groups). Second, moving mass orthogonally towards the diagonal should come at a
price, since the difference in group proportion outreach between groups 1 and 2 decreases. We
quantify this price as the Euclidean distance. This is illustrated in Fig. 2, which shows how the joint
distribution captures unfairness, by depicting the percentage outreach in each group on each axis;"
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.053691275167785234,"thus, the diagonal represents a “fair” line, where the probability of reaching a particular outreach
percentage is the same for both groups."
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.05503355704697987,"These two insights suggest decomposing the distance between the initial configuration (x1, x2) (e.g.,
belonging to γa) and (y1, y2) (e.g., belonging to γb) into two components: one capturing efficiency
and the other one being the fairness component (see Fig. 2). Since the aim of our metric is to measure
fairness, we therefore obtain the transportation cost"
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.056375838926174496,"c((x1, x2), (y1, y2)) = ∥z(x1, x2, y1, y2) −(x1, x2)∥= √"
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.05771812080536913,"2
2 |(x2 −x1) −(y2 −y1)|,
(2)"
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.05906040268456376,"where z(x1, x2, y1, y2) is the point indicated in green in Fig. 2 and ∥·∥is the standard Euclidean
norm. Thus, the “fairness distance” between two distributions γa and γb can be readily quantified
by Wc(γa, γb). Since moving mass along the diagonal is free, we quantify the fairness of a given
γ as its “fairness distance"" from the “ideal” distribution γ∗= δ(1,1), which represents the case where
all members of both groups receive the information. We can now formally introduce our proposed
fairness metric."
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.06040268456375839,"Definition 3.1 (Mutual Fairness) Given a network with communities (Ci)i∈[2], a SIM algorithm is
said to be mutually fair if the algorithm propagation is such that it maximizes"
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.06174496644295302,"FAIRNESS(γ) := 1 −
√"
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.06308724832214765,"2Wc(γ, γ∗),"
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.06442953020134229,"where Wc(γ, γ∗) is the optimal transport discrepancy, defined with the transportation cost (2),
between the probability distribution γ and the desired probability distribution γ∗defined as in (1)."
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.06577181208053691,"The mutual fairness from Definition 3.1 can be seen as a normalized expression of Wc(γ, γ∗) to
contain its values in [0, 1]. Indeed, its lowest value is 0 and it is achieved with γ = δ(0,1), for which
is Wc(γ, γ∗) = 1; its largest value is 1 and it is achieved with γ = γ∗, for which Wc(γ∗, γ∗) = 0.
Since γ∗is a delta distribution, we can solve the optimal transport problem (1) in closed form to"
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.06711409395973154,"FAIRNESS(γ) = 1 −
√"
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.06845637583892618,"2Wc(γ, γ∗) = E(x1,x2)∼γ"
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.0697986577181208,"
1 −|x1 −x2|

,"
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.07114093959731543,which reduces to FAIRNESS(γ) = 1 −1
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.07248322147651007,"N
PN
i=1 |x1,i −x2,i| when the distribution γ is empirical
with N samples {(x1,i, x2,i)}i∈[N]. In particular, our fairness metric can also be interpreted in terms
of the average distance between the outreach proportions within the two groups."
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.0738255033557047,"Discussion.
We note that, while we considered two groups in the aforementioned definition, our
methodology readily extends the setting with m groups. We present this extension in Appendix B. Sec-
ond, since moving mass “diagonally” is free, any distribution γ∗supported on the diagonal yields the
same fairness metric. In practice, it is often not the case that all network members receive the informa-
tion, and the best one could hope for is to project γ onto the diagonal; since moving along the diagonal
is free, the fairness cost is the same whether the ideal distribution is that projection or γ∗. Moreover,
it is easy to see that the “fairness distance” is symmetric, namely Wc(γa, γb) = Wc(γb, γa). Finally,
our definition readily extends to any other distance function besides the standard Euclidean metric."
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.07516778523489932,"Back to the motivating example.
Armed with a definition of fairness that captures the nature of a
diffusion process, we now revisit the motivating example in Fig. 1. To start, we evaluate the “fairness
distance” between γa and γb:"
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.07651006711409396,"Wc(γa, γb) = 1 4 · √"
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.07785234899328859,"2
2 + 1 4 · √ 2
2
= √ 2
4 ,"
A FAIRNESS METRIC BASED ON OPTIMAL TRANSPORT,0.07919463087248323,"which amounts to the cost of transporting the points (0, 1) and (1, 0), each with weight 1/4, to
the diagonal. Notably, in contrast to simply computing the expected outreach of each group, our
fairness metric distinguishes the two outcomes. Similarly, we can easily compute the fairness metric:
FAIRNESS(γa) = 1 and FAIRNESS(γb) = 0.5. In particular, γa achieves the highest fairness score.
Indeed, its outcome will always be fair. Instead, FAIRNESS(γb) achieves a lower fairness score,
capturing the fact that in 50% of the cases the outcome is perfectly fair, while in the remaining 50%
it is largely unfair."
MUTUAL FAIRNESS IN PRACTICE,0.08053691275167785,"3.2
Mutual Fairness in Practice"
MUTUAL FAIRNESS IN PRACTICE,0.08187919463087248,"We now investigate the use of our newly defined fairness metric across a variety of real-world datasets:
Add Health (AH), Antelope Valley variants 0 to 23 (AV_{0-23}) [26], APS Physics (APS) [13], Deezer
(DZ) [19], High School Gender (HS) [14], Indian Villages (IV) [1], and Instagram (INS) [22]. Each
dataset contains a social network with a chosen demographic partitioning the population into two
groups (see Appendix C for details). We load the datasets as graphs G(V, E). We then select a seedset
S of size 2-90 (depending on the dataset) using the following heuristics: two group-agnostic seed
selection strategies as our baselines, namely degree centrality (bas_d), and greedy (bas_g), proposed
by Kempe et al. [11]. In addition, we implement two fair seed selection heuristics based on the equity
metric, namely degree-central fair heuristic (hrt_d), and greedy fair heuristic (hrt_g), proposed
by Stoica et al. [23]. To model the information spread, we use the Independent Cascade model (IC)
for the diffusion of information [11] with a probability p ∈[0, 1] for all edges. This process, being
stochastic, is simulated R times in a Monte Carlo sampling process to achieve R final configurations
(Definition 2.1) plotted together as a joint outreach distribution, in Fig. 3. Then we apply our
distribution-aware notion of fairness from Section 3.1, mutual fairness. We keep R = 1, 000
throughout, but explore several values in p, |S| (mentioned per experiment in the figures below) and
exhaustively recorded with other hyperparameters in Appendix D. All details related to computational
resources and development environment are available in Appendix G. The code for all our numerical
experiments is available at https://github.com/nicolaslanzetti/fairness-sim-ot."
MUTUAL FAIRNESS IN PRACTICE,0.08322147651006712,"Are the outcomes fair?
As a first experiment, we study the joint outreach probability distribution
for different datasets. We identify four qualitatively different outcomes, shown in Fig. 3 for a few
of the datasets. Additional experiments with different propagation probability and seed selection
strategies can be found in Appendix D. Fig. 3a is obtained on AH with bas_g selection strategy and
p = 0.5, |S| = 10. We note how the joint outreach distribution is almost concentrated on the top
right of the plane, i.e., the outcome is almost deterministic and highly fair and efficient. In turn, this
trivializes both the expected value in the equity metric and the cost in the mutual fairness metric in
Definition 3.1, which therefore essentially boils down to comparing the almost deterministic outreach
fraction within each group. In these cases, our fairness metric does not provide additional insights.
Such deterministic outcomes are typical of degree or greedy seedset outreach in dense graphs, such as
AH, DZ, INS (refer to Appendix D), with extreme probability of conduction (p ≥0.5 or p →0), and
cross-group interconnectivity (see Table 1 in Appendix C). For moderate p (e.g., 0.1), the outreach
probability distribution is concentrated along the diagonal (Fig. 3b). Thus, both the equity metric and
our fairness measure are maximal. Nonetheless, our fairness metric provides additional insights: not
only does the expected outreach within each group coincide, but also the outreach at every realization
coincides (see the example in Section 3). Thus, our fairness metric provides a stronger certificate of
fairness. As before, the same applies to AH, DZ, INS (see Appendix D). Intuitively, high cross-group
interconnectivity in a dense graph already ensures fairness. Additionally, extreme p values ensure
deterministic outreach (either the information dies out at the seedset, or reaches everyone in the
population). When propagation happens with moderate propagation probabilities, p, outreach appears
as in Fig. 3b. Fig. 3c represents APS for its hrt_g seedset outreach and p = 0.3, |S| = 6. Here, we
observe a highly stochastic outcome, with many realizations for which almost no member of one
group receives the information. Note that the phenomenon observed in Fig. 3c is the same as the
one captured by our motivating example. We argue such an outcome should not be classified as
fair, despite the expected value of the proportions being similar. Finally, Fig. 3d shows the AV_0
dataset with p = 0.3, |S| = 4, and bas_g selection strategy. We observe a more stochastic outreach
compared to Fig. 3b with variance spread along, but not on the diagonal, with a small bias towards
one group. Also in this case, both the equity and mutual fairness metrics characterize this outcome as
fair, but mutual fairness is more informative as it requires outcomes to be fair at each realization."
MUTUAL FAIRNESS IN PRACTICE,0.08456375838926175,"The impact of the conduction probability.
As a second experiment, we investigate the difference
between mutual fairness and equity (difference in the expected value of the proportions), as a
function of the conduction probability p. We consider the IV dataset as a case study and select seeds
using bas_g. We show our results in Fig. 4. Our mutual fairness metric in Definition 3.1 shows a
fundamentally different trend compared to the equity metric from Definition A.3. Importantly, for
p ∈(0, 0.5), both metrics have an opposite trend: equity fairness increases to some extent whereas
our metric suggests a significant fall in fairness in this region. For p ∈(0.5, 0.7), there is a decrease
in equity fairness, while our fairness evaluation remains relatively constant. We notice similar trends 0.8
1 0.8 1"
MUTUAL FAIRNESS IN PRACTICE,0.08590604026845637,% outreach group 1
MUTUAL FAIRNESS IN PRACTICE,0.087248322147651,% outreach group 2
MUTUAL FAIRNESS IN PRACTICE,0.08859060402684564,"AH, p = 0.5
bas_g, |S| = 10 (a)"
MUTUAL FAIRNESS IN PRACTICE,0.08993288590604027,"0
0.2
0.4
0 0.2 0.4"
MUTUAL FAIRNESS IN PRACTICE,0.0912751677852349,% outreach group 1
MUTUAL FAIRNESS IN PRACTICE,0.09261744966442953,% outreach group 2
MUTUAL FAIRNESS IN PRACTICE,0.09395973154362416,"AH, p = 0.1
bas_g, |S| = 20 (b)"
MUTUAL FAIRNESS IN PRACTICE,0.0953020134228188,"0
0.2
0.4
0 0.2 0.4"
MUTUAL FAIRNESS IN PRACTICE,0.09664429530201342,% outreach group 1
MUTUAL FAIRNESS IN PRACTICE,0.09798657718120805,% outreach group 2
MUTUAL FAIRNESS IN PRACTICE,0.09932885906040269,"APS, p = 0.3
hrt_g, |S| = 6 (c)"
MUTUAL FAIRNESS IN PRACTICE,0.10067114093959731,"0
0.2
0.4
0.6
0 0.2 0.4 0.6"
MUTUAL FAIRNESS IN PRACTICE,0.10201342281879194,% outreach group 1
MUTUAL FAIRNESS IN PRACTICE,0.10335570469798658,% outreach group 2
MUTUAL FAIRNESS IN PRACTICE,0.10469798657718121,"AV_0, p = 0.3
bas_g, |S| = 4 (d)"
MUTUAL FAIRNESS IN PRACTICE,0.10604026845637583,"Figure 3: Joint outreach probability distribution for different datasets, different propagation probabili-
ties p, and seedsets cardinalities |S|."
MUTUAL FAIRNESS IN PRACTICE,0.10738255033557047,"0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0.9 0.95 1"
MUTUAL FAIRNESS IN PRACTICE,0.1087248322147651,Conduction Probability
MUTUAL FAIRNESS IN PRACTICE,0.11006711409395974,Mutual fairness
MUTUAL FAIRNESS IN PRACTICE,0.11140939597315436,"IV, bas_g, |S| = 2 0.9 0.95 1"
MUTUAL FAIRNESS IN PRACTICE,0.11275167785234899,Equity (1-diff. in exp. outreach)
MUTUAL FAIRNESS IN PRACTICE,0.11409395973154363,"Figure 4: Mutual fairness (left, red) and equity (right, blue) for the IV dataset as p varies in [0, 1]."
MUTUAL FAIRNESS IN PRACTICE,0.11543624161073826,"for both metrics only for p ∈(0.8, 1.0). The significant difference in the trend of the two metrics
confirms our previous finding that mutual fairness is more informative than the equity metric and that
the equity metric fails to adequately capture changes in fairness, see Sections 3.1 and 3.2. For more
experiments on other datasets, we refer to Appendix D.2."
TRADING OFF FAIRNESS AND EFFICIENCY,0.11677852348993288,"3.3
Trading off Fairness and Efficiency"
TRADING OFF FAIRNESS AND EFFICIENCY,0.11812080536912752,"To construct our fairness metric, we completely discarded the efficiency of the final configuration. For
instance, the “fairness distance” between a configuration whereby no agent receives the information
(i.e., γ = δ(0,0)) and the “ideal” configuration whereby everyone receives the information (i.e., γ∗) is
zero, as both probability distributions lay on the diagonal. As such, the fairness score of γ = δ(0,0) is
1 and therefore maximal. Thus, in practice, one seeks a fairness-efficiency tradeoff."
TRADING OFF FAIRNESS AND EFFICIENCY,0.11946308724832215,"In our setting, we can easily introduce the tradeoff in the transportation cost (2). Specifically, we can
define the transportation cost as a weighted sum of the “diagonal distance” (measuring the difference
in efficiency, dotted segment in Fig. 2) and the “orthogonal distance” (measuring the difference in
fairness, solid segment in Fig. 2). Formally, for a given weight β ≥0, the transportation cost reads
cβ((x1, x2), (y1, y2)) = β∥z(x1, x2, y1, y2) −(x1, x2)∥+ (1 −β)∥z(x1, x2, y1, y2) −(y1, y2)∥ = β √"
TRADING OFF FAIRNESS AND EFFICIENCY,0.12080536912751678,"2
2 |(x2 −x1) −(y2 −y1)| + (1 −β) √"
TRADING OFF FAIRNESS AND EFFICIENCY,0.1221476510067114,"2
2 |(x1 + x2) −(y1 + y2)|. (3)"
TRADING OFF FAIRNESS AND EFFICIENCY,0.12348993288590604,"We refer to Fig. 5 for a heatmap of cβ. In particular, for β = 1, we recover the transportation
cost (2); for β = 0 one optimizes for efficiency, and the β-fairness collapses in the classical influence
maximization problem. We can then proceed as in Section 3.1. The “β-fairness-efficiency distance”
between γa and γb is Wcβ(γa, γb) and the β-fairness metric can be then defined as follows."
TRADING OFF FAIRNESS AND EFFICIENCY,0.12483221476510067,"Definition 3.2 (β-Fairness) Consider a network with groups C1, C2, a SIM algorithm is said to be
β-fair if the algorithm propagation is such that it maximizes"
TRADING OFF FAIRNESS AND EFFICIENCY,0.1261744966442953,β−FAIRNESS(γ) := 1 − √
TRADING OFF FAIRNESS AND EFFICIENCY,0.12751677852348994,"2
max{1, 2 −2β}Wcβ(γ, γ∗),
(4)"
TRADING OFF FAIRNESS AND EFFICIENCY,0.12885906040268458,"0
0.5
1
0 0.5 1"
TRADING OFF FAIRNESS AND EFFICIENCY,0.13020134228187918,% outreach group 1
TRADING OFF FAIRNESS AND EFFICIENCY,0.13154362416107382,% outreach group 2 β = 0
TRADING OFF FAIRNESS AND EFFICIENCY,0.13288590604026845,"0
0.5
1
0 0.5 1"
TRADING OFF FAIRNESS AND EFFICIENCY,0.1342281879194631,% outreach group 1
TRADING OFF FAIRNESS AND EFFICIENCY,0.13557046979865772,% outreach group 2
TRADING OFF FAIRNESS AND EFFICIENCY,0.13691275167785236,β = 0.33
TRADING OFF FAIRNESS AND EFFICIENCY,0.138255033557047,"0
0.5
1
0 0.5 1"
TRADING OFF FAIRNESS AND EFFICIENCY,0.1395973154362416,% outreach group 1
TRADING OFF FAIRNESS AND EFFICIENCY,0.14093959731543623,% outreach group 2
TRADING OFF FAIRNESS AND EFFICIENCY,0.14228187919463087,β = 0.66
TRADING OFF FAIRNESS AND EFFICIENCY,0.1436241610738255,"0
0.5
1
0 0.5 1"
TRADING OFF FAIRNESS AND EFFICIENCY,0.14496644295302014,% outreach group 1
TRADING OFF FAIRNESS AND EFFICIENCY,0.14630872483221477,% outreach group 2 β = 1
TRADING OFF FAIRNESS AND EFFICIENCY,0.1476510067114094,"Figure 5: Cost of transporting a point (x1, x2) to the “ideal” point (1, 1) (i.e., everyone receives the
information) for various values of β (i.e., we plot (x1, x2) 7→cβ((x1, x2), (1, 1))). Yellow denotes a
low transportation cost, whereas dark blue denotes a large cost."
TRADING OFF FAIRNESS AND EFFICIENCY,0.14899328859060404,"with Wcβ(γ, γ∗) defined as in (1) with transportation cost as in (3) and ideal distribution γ∗= δ(1,1)."
TRADING OFF FAIRNESS AND EFFICIENCY,0.15033557046979865,"The terms 1 and
√"
TRADING OFF FAIRNESS AND EFFICIENCY,0.15167785234899328,"2/ max{1, 2 −2β} in (4) ensure that the metric is non-negative and in [0, 1].
Again, the optimal transport problem can be solved in closed form, which yields"
TRADING OFF FAIRNESS AND EFFICIENCY,0.15302013422818792,"β−FAIRNESS(γ) = E(x1,x2)∼γ"
TRADING OFF FAIRNESS AND EFFICIENCY,0.15436241610738255,"
1 −β|x1 −x2| + (1 −β)|x1 + x2 −2|"
TRADING OFF FAIRNESS AND EFFICIENCY,0.15570469798657718,"max{1, 2 −2β} 
."
TRADING OFF FAIRNESS AND EFFICIENCY,0.15704697986577182,"In particular, for β = 1, we recover the mutual fairness FAIRNESS(γ) in Definition 3.1 and for β = 0
we obtain the efficiency metric E(x1,x2)∼γ[1 −|x1+x2−2| 2
]."
IMPROVING FAIRNESS,0.15838926174496645,"4
Improving Fairness"
FAIRNESS-PROMOTING SEED-SELECTION ALGORITHM,0.1597315436241611,"4.1
Fairness-promoting Seed-selection Algorithm"
FAIRNESS-PROMOTING SEED-SELECTION ALGORITHM,0.1610738255033557,"Armed with a novel fairness metric, β−FAIRNESS, we now design an iterative seed-selection
algorithm, which we call Stochastic Seedset Selection Descent (S3D), that strategically selects seeds
taking into account all communities simultaneously. The pseudo-code is summarized in Algorithm 1.
For its motivation and details, refer to Appendix E. For a given initial seedset, our algorithm explores
new seeds and evaluates them on the efficiency-fairness metric β−FAIRNESS as in (4) for a desired
value of the fairness-efficiency tradeoff parameter β (S3D_STEP() in Appendix E), to decide if
the new seedset becomes a candidate for the optimized seedset. These seeds are searched for by
iteratively sampling stochastically reachable nodes, up to a fixed depth, taken as a fraction of the
graph diameter, from the current seedset (SEEDSET_REACH() in Appendix E) while making sure
they contribute to a non-overlapping outreach (Algorithm 1::6-8). To avoid local minima of the
generally non-convex objective, the procedure allows for visiting inferior seedsets on β−FAIRNESS
or even selecting completely random ones on rare occasions (Algorithm 1::12-18) using Metropolis
Sampling [18]. Otherwise, a high β−FAIRNESS encourages opting for the new seedset with high
probability. Finally, we revisit all the seedset candidates collected so far and pick the one with the
largest β−FAIRNESS as the optimal seedset. For a sparse graph G(V, E), with E = O(V ), choosing
|S| seeds, averaging over R realizations to approximate outreach via Monte-Carlo sampling and
exploring k candidates using S3D_STEP suggests a total running time upper bound of O(kR|S||V |)
(see Appendix E for details). In practice, k ∈[500, 1000], R = 1000 for S ∈[2, 100] works well for
all datasets."
REAL-WORLD DATA,0.16241610738255033,"4.2
Real-world Data"
REAL-WORLD DATA,0.16375838926174496,"Are the outcomes more fair?
We test our algorithm across a variety of datasets (Appendix C)
against our baselines (bas_d, bas_g). We initialize the S3D algorithm with the two baseline seedsets
and hence include results from two separately optimized seedsets, S3D_d, S3D_g. Our results are
shown in Fig. 6. Informally, we observe that our seed-selection mechanism “moves” the probability
mass of the joint outreach probability distribution towards the diagonal, which ultimately increases the
fairness of the resulting configuration. At the same time, efficiency either increases as well or suffers
only a small decrease, as we investigate more in detail in our next experiment. Generally, datasets"
REAL-WORLD DATA,0.1651006711409396,"Algorithm 1 Stochastic Seedset Selection Descent
Input: Social Graph G(VG, EG), initial seed set S0, β fairness weight, ϵ-tolerance
Output: Optimal seedset S∗"
REAL-WORLD DATA,0.16644295302013423,"1: S ←{}, S ←S0
▷initial collection of candidates, running seedset
2: for k iterations do
▷configurable k
3:
VS ←nodes reachable from S via cascade, using SEEDSET_REACH routine
4:
S′ ←{}
5:
for |S| iterations do
▷searching nearby states, VS′, to get S′ (Appendix E.3)
6:
S′ ←S′ ∪{v} | v ∼VS
7:
VS′ ←nodes reachable from S′ in a fixed horizon, using SEEDSET_REACH
8:
VS ←VS \ VS′"
REAL-WORLD DATA,0.16778523489932887,"9:
ES ←−BETA_FAIRNESS(S, β)
▷expected potential energy defined on β-fairness
10:
ES′ ←−BETA_FAIRNESS(S′, β)
11:
paccept ←min{1, eES−ES′}
▷S′ acceptance on energy minimization
12:
if x ∼B(paccept) then
▷Metropolis sampling
13:
S+ ←S′
▷get a better seedset
14:
else
15:
if x ∼B(ϵ) then
▷for some small constant ϵ"
REAL-WORLD DATA,0.1691275167785235,"16:
S+ ←{vi}|S|
i=1
|S|
∼VG
▷random seedset
17:
else
18:
S+ ←S
▷retain existing choice
19:
S ←S ∪{S+}
20:
S ←S+
▷for next iteration
21: S∗←S ∈S | BETA_FAIRNESS(S, β) is maximum
▷via S3D_ITERATE
22: return S∗"
REAL-WORLD DATA,0.1704697986577181,"0
0.2
0.4
0.6
0 0.2 0.4 0.6"
REAL-WORLD DATA,0.17181208053691274,% outreach group 1
REAL-WORLD DATA,0.17315436241610738,% outreach group 2
REAL-WORLD DATA,0.174496644295302,"APS, p = 0.3
bas_d, |S| = 6, β = 0.8"
REAL-WORLD DATA,0.17583892617449665,"0
0.2
0.4
0.6
0 0.2 0.4 0.6"
REAL-WORLD DATA,0.17718120805369128,% outreach group 1
REAL-WORLD DATA,0.17852348993288591,% outreach group 2 (a)
REAL-WORLD DATA,0.17986577181208055,"0
0.1
0.2
0 0.1 0.2"
REAL-WORLD DATA,0.18120805369127516,% outreach group 1
REAL-WORLD DATA,0.1825503355704698,% outreach group 2
REAL-WORLD DATA,0.18389261744966443,"IV, p = 0.1
bas_g, |S| = 2, β = 0.8"
REAL-WORLD DATA,0.18523489932885906,"0
0.1
0.2
0 0.1 0.2"
REAL-WORLD DATA,0.1865771812080537,% outreach group 1
REAL-WORLD DATA,0.18791946308724833,% outreach group 2 (b)
REAL-WORLD DATA,0.18926174496644296,"0
0.1
0.2
0 0.1 0.2"
REAL-WORLD DATA,0.1906040268456376,% outreach group 1
REAL-WORLD DATA,0.1919463087248322,% outreach group 2
REAL-WORLD DATA,0.19328859060402684,"HS, p = 0.01
bas_g, |S| = 10, β = 0.5"
REAL-WORLD DATA,0.19463087248322147,"0
0.1
0.2
0 0.1 0.2"
REAL-WORLD DATA,0.1959731543624161,% outreach group 1
REAL-WORLD DATA,0.19731543624161074,"% outreach group 2 (c) 0.8
1 0.8 1"
REAL-WORLD DATA,0.19865771812080538,% outreach group 1
REAL-WORLD DATA,0.2,% outreach group 2
REAL-WORLD DATA,0.20134228187919462,"HS, p = 0.5
bas_d, |S| = 6, β = 0.8 0.8
1 0.8 1"
REAL-WORLD DATA,0.20268456375838925,% outreach group 1
REAL-WORLD DATA,0.2040268456375839,% outreach group 2 (d)
REAL-WORLD DATA,0.20536912751677852,"Figure 6: Demonstrate S3D (red) improvement over its label-blind baseline counter-part initializations
(blue) for several datasets, propagation probabilities p, seed set cardinalities |S| and fairness-efficiency
tradeoffs β. Fig. 6d provides the strongest evidence that, besides improving in fairness, our strategy
can also be more efficient, from 83.1% to 87.9%."
REAL-WORLD DATA,0.20671140939597316,"with high cross-group connections (AH, DZ, INS) yield moderately fair outreach with label-blind
seed selection. Similarly, for datasets with low cross-group connections (APS) a label-blind strategy,
in order to maximize efficiency, selects a diverse population of seeds from which all communities are
reached. Therefore, label-blind algorithms work similarly to S3D. In other moderate cases (AV, HS,
IV), instead, we observe significant improvements of S3D over label-blind strategies."
REAL-WORLD DATA,0.2080536912751678,"Classification of seed-selection algorithms.
In our final experiments, we compare several
algorithms along with ours in terms of efficiency and mutual fairness across various datasets (see
Appendix C). We consider the following algorithms: bas_d, bas_g, their fair heuristic counterparts,
hrt_d, hrt_g, against our S3D_d, S3D_g, initialized via greedy and degree centrality baseline
seeds, respectively. We show our results in Fig. 7. S3D achieves in almost all cases the highest"
REAL-WORLD DATA,0.20939597315436242,"0
0.1
0.2
0.3
0.4 0.8 0.9 1"
REAL-WORLD DATA,0.21073825503355706,Efficiency
REAL-WORLD DATA,0.21208053691275167,Mutual fairness
REAL-WORLD DATA,0.2134228187919463,"APS, p = 0.3
|S| = 6, β = 0.8"
REAL-WORLD DATA,0.21476510067114093,"0.2
0.25
0.3
0.35
0.85 0.9 0.95 1"
REAL-WORLD DATA,0.21610738255033557,Efficiency
REAL-WORLD DATA,0.2174496644295302,Mutual fairness
REAL-WORLD DATA,0.21879194630872484,"AV_0, p = 0.3
|S| = 4, β = 0.8"
REAL-WORLD DATA,0.22013422818791947,"0.06
0.08
0.1
0.9 0.92 0.94 0.96 0.98 1"
REAL-WORLD DATA,0.2214765100671141,Efficiency
REAL-WORLD DATA,0.22281879194630871,Mutual fairness
REAL-WORLD DATA,0.22416107382550335,"HS, p = 0.01
|S| = 10, β = 0.5"
REAL-WORLD DATA,0.22550335570469798,"0.8 0.82 0.84 0.86 0.88 0.9
0.9 0.92 0.94 0.96 0.98 1"
REAL-WORLD DATA,0.22684563758389262,Efficiency
REAL-WORLD DATA,0.22818791946308725,Mutual fairness
REAL-WORLD DATA,0.2295302013422819,"HS, p = 0.5
|S| = 6, β = 0.8"
REAL-WORLD DATA,0.23087248322147652,"Figure 7: S3D trade-off and improvement against other label-aware and label-blind algorithms for
several datasets, propagation probabilities p, seed set cardinalities |S| and fairness-efficiency tradeoffs
β. Filled markers refer to greedy-based algorithms: ■= bas_g,  = S3D_g, and ♦= hrt_g. Empty
markers refer to degree-based algorithms: □= bas_d, # = S3D_d, and ♢= hrt_d. For statistical
bounds, we refer to Appendix F."
REAL-WORLD DATA,0.23221476510067113,"fairness score (y-axis) and generally a slightly lower efficiency score (x-axis), compared to others.
Thus, our seed-selection mechanism leads to fairer outcomes with only a minor decrease in efficiency."
REAL-WORLD DATA,0.23355704697986576,"The impact of the network topology.
To conclude, we discuss the impact of the network topology.
In particular, when the conduction probability is moderate, network topology starts playing a role,
mainly through the number of cross-group edges (CE):"
REAL-WORLD DATA,0.2348993288590604,"CE% is small (∼5%, APS): Such datasets encode group interaction information in the edges them-
selves, that is, an edge likely means nodes belong to the same group. In such cases, baseline
greedy algorithms (bas_g) already perform well as they rely only on edge connectivity. In such
circumstances, S3D does not significantly improve on their selection, both in efficiency and fairness."
REAL-WORLD DATA,0.23624161073825503,"CE% is balanced (40-50%, HS, AH): These datasets reflect that groups interact well across each
other and so any seedset selection largely ends up in a fair outreach. Since bas_g already has proven
near-optimal efficiency guarantees, it is unlikely that S3D performs significantly better than bas_g."
REAL-WORLD DATA,0.23758389261744967,"CE% is moderate (5-30%, AV (datasets 0, 2, 16, 20), IV): These are the non-trivial cases not
covered above. Here bas_g can not reliably leverage the existence of edges into group information.
Hence, S3D usually outperforms the baseline, achieving similar efficiency scores while significantly
improving fairness."
REAL-WORLD DATA,0.2389261744966443,"CE% is high (>50%): The case where nodes interact more across groups than in their group was
never observed. However, as long as the existence of edges does not reliably signal group information,
we expect S3D to perform well based on a similar analysis."
REAL-WORLD DATA,0.24026845637583893,"Moderate outreach in dense graphs (INS, DZ): For graphs where |E| substantially exceeds |V |, the
outreach variance across sample sub-graphs is too low to be captured in the discretized space we
experimented (100×100 units in [0, 1]2), even for moderate p. This leads to single-point concentrated
joint-distribution plots, all of them leading to the same β−FAIRNESS."
CONCLUSIONS AND LIMITATIONS,0.24161073825503357,"5
Conclusions and Limitations"
CONCLUSIONS AND LIMITATIONS,0.24295302013422818,"Conclusions.
We propose a new fairness metric, called mutual fairness, in the context of SIM.
Mutual fairness draws on optimal transport and captures various fairness-related aspects (e.g., when
members of group 1 receive the information will members of group 2 receive it?) that are obscure to
the fairness metrics in the literature. We also leverage our novel fairness metric to design a new seed
selection strategy that tradeoffs fairness and efficiency. Across various real datasets, our algorithm
yields superior fairness with a minor decrease (and in some cases even an increase) in efficiency."
CONCLUSIONS AND LIMITATIONS,0.2442953020134228,"Limitations.
Our proposed algorithm, S3D, is essentially a random combinatorial search in the
graph defining the social network. As such, its performance will generally depend on the quality of
the seedset initialization. Moreover, there is no guaranteed bound on the number of iterations needed
in S3D to achieve a desired level of fairness. Both aspects can be limiting in real-world applications."
CONCLUSIONS AND LIMITATIONS,0.24563758389261744,Acknowledgments and Disclosure of Funding
CONCLUSIONS AND LIMITATIONS,0.24697986577181208,"We thank the reviewers for their constructive suggestions. This work was supported as a part of NCCR
Automation, a National Centre of Competence in Research, funded by the Swiss National Science
Foundation (grant number 51NF40_225155). A.-A. S. acknowledges support from the Tübingen AI
Center."
REFERENCES,0.2483221476510067,References
REFERENCES,0.24966442953020135,"[1] Abhijit Banerjee, Arun G Chandrasekhar, Esther Duflo, and Matthew O Jackson. The diffusion
of microfinance. Science, 341(6144):1236498, 2013."
REFERENCES,0.25100671140939596,"[2] Emily Black, Samuel Yeom, and Matt Fredrikson. Fliptest: fairness testing via optimal transport.
Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (FAT’20),
pages 111–121, 2020."
REFERENCES,0.2523489932885906,"[3] Wei Chen, Wei Lu, and Ning Zhang. Time-critical influence maximization in social net-
works with time-delayed diffusion process. In Proceedings of AAAI Conference of Artificial
Intelligence, 26(1):1–7, 2012."
REFERENCES,0.2536912751677852,"[4] Silvia Chiappa, Ray Jiang, Tom Stepleton, Aldo Pacchiano, Heinrich Jiang, and John Aslanides.
A general approach to fairness with optimal transport. Proceedings of the 2020 Conference on
Fairness, Accountability, and Transparency (FAT’20), pages 3633–3640, 2020."
REFERENCES,0.2550335570469799,"[5] Tang Fangshuang, Qi Liu, Zhu Hengshu, Chen Enhong, and Feida Zhu. Diversified social
influence maximization. 2014 IEEE/ACM International Conference on Advances in Social
Networks Analysis and Mining (ASONAM 2014), pages 455–459, 2014."
REFERENCES,0.2563758389261745,"[6] Golnoosh Farnadi, Behrouz Babaki, and Michel Gendreau. A unifying framework for fairness-
aware influence maximization. International World Wide Web Conference 2020, pages 714–722,
2020."
REFERENCES,0.25771812080536916,"[7] Benjamin Fish, Ashkan Bashardoust, Danah Boyd, Sorelle Friedler, Carlos Scheidegger, and
Suresh Venkatasubramanian. Gaps in information access in social networks? International
World Wide Web Conference 2019, San Francisco, USA, pages 480–490, 2020."
REFERENCES,0.25906040268456376,"[8] Aric Hagberg, Pieter Swart, and Daniel Chult. Exploring network structure, dynamics, and
function using networkx. In Proceedings of the 7th Python in Science Conference, 01 2008."
REFERENCES,0.26040268456375837,"[9] Ali Junaid, Babaei Mahmoudreza, Abhijnan Chakraborty, Baharan Mirzasoleiman, Krishna P.
Gummadi, and Adish Singla. On the fairness of time-critical influence maximization in social
network. IEEE Transaction on knowledge and data engineering, 35(3):480–490, 2023."
REFERENCES,0.26174496644295303,"[10] Fariba Karimi, Mathieu Génois, Claudia Wagner, Philipp Singer, and Markus Strohmaier.
Homophily influences ranking of minorities in social networks. Scientific reports, 8(1):11077,
2018."
REFERENCES,0.26308724832214764,"[11] David Kempe, Jon Kleinberg, and Eva Tardos. Maximizing the spread of influence through a
social network. Proceedings of the 9th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining, pages 137–146, 2003."
REFERENCES,0.2644295302013423,"[12] David Kempe, Jon Kleinberg, and Éva Tardos. Influential nodes in a diffusion model for social
networks. In Automata, Languages and Programming: 32nd International Colloquium, ICALP
2005, Lisbon, Portugal, July 11-15, 2005. Proceedings 32, pages 1127–1138. Springer, 2005."
REFERENCES,0.2657718120805369,"[13] Eun Lee, Fariba Karimi, Claudia Wagner, Hang-Hyun Jo, Markus Strohmaier, and Mirta Galesic.
Homophily and minority-group size explain perception biases in social networks. Nature human
behaviour, 3(10):1078–1087, 2019."
REFERENCES,0.26711409395973157,"[14] Rossana Mastrandrea, Julie Fournet, and Alain Barrat. Contact patterns in a high school:
a comparison between data collected using wearable sensors, contact diaries and friendship
surveys. PloS one, 10(9):e0136497, 2015."
REFERENCES,0.2684563758389262,"[15] Gabriel Peyré, Marco Cuturi, et al. Computational optimal transport: With applications to data
science. Foundations and Trends® in Machine Learning, 11(5-6):355–607, 2019."
REFERENCES,0.2697986577181208,"[16] Aida Rahmattalabi, Shahin Jabbari, Himabindu Lakkaraju, Phebe Vayanos, Max Izenberg, Ryan
Brown, Eric Rice, and Milind Tambe. Fair influence maximization: A welfare optimization
approach. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages
11630–11638, 2021."
REFERENCES,0.27114093959731544,"[17] Matthew Richardson and Pedro Domingos. Mining knowledge-sharing sites for viral marketing.
In Proceedings of 8th International Conference on Knowledge, Discovery and Data Mining,
pages 61–70, 2002."
REFERENCES,0.27248322147651005,"[18] Christian P Robert, George Casella, Christian P Robert, and George Casella. The metropo-
lis—hastings algorithm. Monte Carlo statistical methods, pages 267–320, 2004."
REFERENCES,0.2738255033557047,"[19] Benedek Rozemberczki and Rik Sarkar. Characteristic functions on graphs: Birds of a feather,
from statistical descriptors to parametric models. In Proceedings of the 29th ACM international
conference on information & knowledge management, pages 1325–1334, 2020."
REFERENCES,0.2751677852348993,"[20] Yves Rychener, Bahar Taskesen, and Daniel Kuhn.
Metrizing fairness.
arXiv preprint
arXiv:2205.15049, 2022."
REFERENCES,0.276510067114094,"[21] Nian Si, Karthyek Murthy, Jose Blanchet, and Viet Anh Nguyen. Testing group fairness via
optimal transport projections. Proceedings of the 38th International Conference on Machine
Learning, pages 9649–9659, 2021."
REFERENCES,0.2778523489932886,"[22] Ana-Andreea Stoica, Christopher Riederer, and Augustin Chaintreau. Algorithmic glass ceiling
in social networks: The effects of social recommendations on network diversity. In Proceedings
of the 2018 World Wide Web Conference, pages 923–932, 2018."
REFERENCES,0.2791946308724832,"[23] Ana-Andreea Stoica, Jessy Xinyi Han, and Augustin Chaintreau. Seeding network influence in
biased networks and the benefits of diversity. Proceedings of The Web Conference 2020, pages
2089–2098, 2020."
REFERENCES,0.28053691275167786,"[24] Bahar Taskesen, Jose Blanchet, Daniel Kuhn, and Viet Anh Nguyen. A statistical test for
probabilistic fairness. In Proceedings of the 2021 ACM conference on fairness, accountability,
and transparency, pages 648–665, 2021."
REFERENCES,0.28187919463087246,"[25] Alan Tsang, Bryan Wilder, Eric Rice, Milind Tambe, and Yair Zick. Group-fairness in influence
maximization. Proceedings of the Twenty-Eighth International Joint Conference on Artificial
Intelligence (IJCAI-19), pages 5997–6005, 2018."
REFERENCES,0.2832214765100671,"[26] Alan Tsang, Bryan Wilder, Eric Rice, Milind Tambe, and Yair Zick. Group-fairness in influence
maximization. Proceedings of the Twenty-Eighth International Joint Conference on Artificial
Intelligence (IJCAI-19), pages 5997–6005, 2019."
REFERENCES,0.28456375838926173,"[27] Thomas W. Valente and Patchareeya Pumpuang.
Identifying opinion leaders to promote
behaviour change. Health, Education & Behaviour, 34(6):881–896, 2007."
REFERENCES,0.2859060402684564,"[28] Cédric Villani. Optimal transport: old and new, volume 338. Springer, 2009."
REFERENCES,0.287248322147651,"[29] Meike Zehlike, Alex Loosley, Håkan Jonsson, Emil Wiedemann, and Philipp Hacker. Beyond
incompatibility: Trade-offs between mutually exclusive fairness criteria in machine learning
and law. arXiv preprint arXiv:2212.00469, 2022."
REFERENCES,0.28859060402684567,"[30] Jianming Zhu, Smita Ghosh, and Weili Wu. Group influence maximization problem in social
networks. IEEE Transactions on Computational Social Sciences, 6(6):1156–1164, 2019."
REFERENCES,0.28993288590604027,"A
Existing Fairness Metrics"
REFERENCES,0.2912751677852349,"Definition A.1 (Expected outreach ratio) Given a network with communities C1, . . . , Cm, the SIM
algorithm expected outreach ratio in Ci, ¯xi, is the expected ratio of nodes reached in Ci, namely"
REFERENCES,0.29261744966442954,¯xi := E[|{v reached |v ∈Ci}|]
REFERENCES,0.29395973154362415,"|Ci|
,
∀i ∈{1, . . . , m}."
REFERENCES,0.2953020134228188,"Definition A.2 (Equality [23]) Given the groups C1, . . . , Cm, a configuration is said to be equal, if
the SIM algorithm chooses a seed set S in a way such that the proportion of all communities in the
seed set is the same, namely"
REFERENCES,0.2966442953020134,E[|{v ∈S|v ∈Ci}|]
REFERENCES,0.2979865771812081,"|Ci|
= E[|{v ∈S|v ∈Cj}|]"
REFERENCES,0.2993288590604027,"|Cj|
∀i, j ∈{1, . . . , m}."
REFERENCES,0.3006711409395973,"The notion of equality focuses on the fair allocation of seeds to the groups proportional to the size
of the group within the population. This notion of fairness applies, for example, in the context of
advertising companies that aim at having a fair distribution of resources among groups."
REFERENCES,0.30201342281879195,"Definition A.3 (Equity [23]) Given a network with communities C1, . . . , Cm, a SIM algorithm that
selects a seedset S is said to be equitable if the algorithm propagation reaches all communities in a
balanced way, i.e. ¯xi = ¯xj for all i, j ∈{1, . . . , m}."
REFERENCES,0.30335570469798656,"The notion of equity focuses on the outcome of the diffusion process, e.g. independent cascade, linear
threshold model and it is suitable in contexts in which one aims to reach a diverse population in a
calibrated way."
REFERENCES,0.3046979865771812,"Definition A.4 (Max-min fairness [6]) Given the groups C1, . . . , Cm, the max-min fairness
criterion maximizes the minimum expected outreach ratio among all groups,
namely
max mini∈{1,...,m} ¯xi."
REFERENCES,0.30604026845637583,"The goal of the maxmin fairness is to minimize the gap among different groups in the outreach. The
SIM problem under maxmin constraints has been investigated in [6, 7, 30]."
REFERENCES,0.3073825503355705,"Definition A.5 (Diversity [6]) Given the groups C1, . . . , Cm, let ki =

k · |Ci|"
REFERENCES,0.3087248322147651,"|V |

, where k is the
pre-specified total seed budget. Let ¯x∗
i (Ci) := maxS⊂Ci:|S|=ki ¯xi. A configuration is said to be
diverse if for each i ∈{1, . . . , m} it holds ¯xi ≥¯x∗
i (Ci), where ¯xi refers to the expected outreach
ratio in Ci obtained from the seed set S, with |S| = k."
REFERENCES,0.3100671140939597,"The notion of diversity ensures that each group receives influence at least equal to their internal
spread of influence. The SIM problem under diversity constraints has been investigated in [6, 25]."
REFERENCES,0.31140939597315437,"B
Extension to Multiple Groups"
REFERENCES,0.312751677852349,"In this section, we extend our definitions of mutual fairness and β-fairness to the setting of m groups.
To do so, we first notice that, in the case of m groups, the outreach distribution is a probability
distribution γ on the hypercube [0, 1]m; i.e., γ now lives in P([0, 1]m)."
REFERENCES,0.31409395973154364,"We start with the definition of mutual fairness. We proceed as in Section 3.1 and define mutual fairness
via optimal transport, which, in turn, requires defining a reference distribution and a transportation
cost. The reference distribution is again the “ideal” distribution γ∗= δ(1,...,1) which encodes the
case in which all members of all groups receive the information. As for the transportation cost, it
suffices to generalize the transportation cost (2) to an m dimensional space. Specifically, it can be
defined as the distance between any given point (x1, . . . , xm) ∈[0, 1]m in the hypercube and the
diagonal line. For this, let"
REFERENCES,0.31543624161073824,"z(x1, . . . , xm) =
argmin
z=(y,...,y),y∈[0,1]
∥(x1, . . . , xm) −z∥"
REFERENCES,0.3167785234899329,= x1 + . . . + xm
REFERENCES,0.3181208053691275,"m
(1, . . . , 1)"
REFERENCES,0.3194630872483222,"be the closest point to (x1, . . . , xm) on the diagonal. Then, the transportation cost can be defined as
in (2) and the fairness metric reads"
REFERENCES,0.3208053691275168,"FAIRNESS(γ) = 1 −αE(x1,...,xm)∼γ[∥z(x1, . . . , xm) −(x1, . . . , xm)∥]"
REFERENCES,0.3221476510067114,"= 1 −αE(x1,...,xm)∼γ"
REFERENCES,0.32348993288590605,"
min
z∈[0,1] ∥(x1, . . . , xm) −(z, . . . , z)∥

,"
REFERENCES,0.32483221476510066,"where the constant α > 0 is again chosen so that FAIRNESS(γ) is between 0 and 1. Note that in the
case of two groups, we have z = 1"
REFERENCES,0.3261744966442953,2(x1 + x2) and
REFERENCES,0.3275167785234899,"min
z∈[0,1] ∥(x1, . . . , xm) −(z, . . . , z)∥= √"
REFERENCES,0.3288590604026846,"2
2 |x1 −x2|,"
REFERENCES,0.3302013422818792,which is precisely the mutual fairness of Definition 3.1.
REFERENCES,0.3315436241610738,We now turn our attention to β-fairness. We can proceed analogously and obtain
REFERENCES,0.33288590604026846,"β−FAIRNESS(γ) = 1 −αE(x1,...,xm)∼γ[β∥z(x1, . . . , xm) −(x1, . . . , xm)∥"
REFERENCES,0.33422818791946307,"+ (1 −β)∥z(x1, . . . , xm) −(1, . . . , 1)∥],"
REFERENCES,0.33557046979865773,"where α > 0 is again chosen to normalize the metric. Again, in the case of two groups, we have
z = 1"
REFERENCES,0.33691275167785234,2(x1 + x2) and so
REFERENCES,0.338255033557047,"β−FAIRNESS(γ) = 1 −αE(x1,...,xm)∼γ 
β √"
REFERENCES,0.3395973154362416,"2
2 |x1 −x2| + (1 −β) √"
REFERENCES,0.3409395973154362,"2
2 |x1 + x2 −2|

,"
REFERENCES,0.3422818791946309,which coincides with Definition 3.2.
REFERENCES,0.3436241610738255,"We conclude with two remarks on this extension to m groups. First, as in the case of two groups, there
is no need to numerically solve optimal transport problems, as we provide a closed-form expression
for the optimal transport problems. Second, we highlight that our extension to m groups does not
resort to the so-called multi-marginal optimal transport problem, which might cause exponential
complexity in the dimensionality."
REFERENCES,0.34496644295302015,"C
Description and Properties of Datasets"
REFERENCES,0.34630872483221475,"To associate the notion of fairness developed in Sections 3.1 and 3.3 with the datasets and the
outcomes from experiments in Sections 3.2 and 4.2, we summarize the dataset statistics in Table 1.
Minority % is calculated as the percentage of the minority group nodes in the entire population.
Fraction of Cross Edges evaluates heterophily in the dataset, by calculating the fraction of edges that
connect different groups. A higher value means a more heterophilic network, whereas a lower value
means a more homophilic network."
REFERENCES,0.3476510067114094,"Add Health (AH).
The Add Health dataset consists of a social network of students in schools and
a relation between them is represented by whether they nominated each other in the Add Health
surveys. We select a school at random with 1, 997 students and use race as the sensitive attribute
(white and non-white).2"
REFERENCES,0.348993288590604,"Antelope Valley (AV), [26].
We choose 4 random networks among the 24 available in the Antelope
Valley dataset to compare our fairness-improving algorithm, S3D, against [26], which worked on the
same dataset. We also run our baselines and other fair seed selection heuristics from [23] on these
datasets to get a fair comparison. The two sensitive attribute groups are male and female, self-reported
in the dataset with binary attributes."
REFERENCES,0.3503355704697987,"2The Add Health project is funded by grant P01 HD31921 (Harris) from the Eunice Kennedy Shriver National
Institute of Child Health and Human Development (NICHD), with cooperative funding from 23 other federal
agencies and foundations. Add Health is currently directed by Robert A. Hummer and funded by the National
Institute on Aging cooperative agreements U01 AG071448 (Hummer) and U01AG071450 (Aiello and Hummer)
at the University of North Carolina at Chapel Hill. Add Health was designed by J. Richard Udry, Peter S.
Bearman, and Kathleen Mullan Harris at the University of North Carolina at Chapel Hill."
REFERENCES,0.3516778523489933,"Dataset
# Nodes
# Edges
Avg. Degree
Diameter
Minority %
Frac. Cross Edges"
REFERENCES,0.3530201342281879,"AH
1997
8523
8.54
10
34.6
0.452"
REFERENCES,0.35436241610738256,"AV_0
500
969
3.87
12
49
0.189
AV_2
500
954
3.81
14
49.6
0.183
AV_16
500
949
3.8
13
47.6
0.210
AV_20
500
959
3.84
15
48.4
0.198"
REFERENCES,0.35570469798657717,"APS
1281
3064
4.78
26
31.8
0.056"
REFERENCES,0.35704697986577183,"DZ
18442
46172
5.00
25
44.4
0.476"
REFERENCES,0.35838926174496644,"HS
133
401
6.03
10
40.6
0.394"
REFERENCES,0.3597315436241611,"IV
90
238
5.29
13
26.7
0.265"
REFERENCES,0.3610738255033557,"INS
553628
652830
2.36
16
45.6
0.417
Table 1: Summary statistics of datasets used."
REFERENCES,0.3624161073825503,"APS Physics (APS), [13].
The APS citation network contains 1, 281 nodes, representing papers
written in two main topics: Classical Statistical Mechanics (CSM), constituting 31.8% of the papers,
and Quantum Statistical Mechanics (QSM), accounting for the rest. As Lee et al. [13] analyze,
the dataset has high homophily, meaning that each subfield cites more papers in its own field than
in the other field. For simplicity, we use only the largest connected component in the full dataset
(component stats in 1) between the two groups, for this study."
REFERENCES,0.363758389261745,"Deezer (DZ), [19].
A social network from Europe with 18, 442 nodes, where each node has a
self-reported attributed gender (male or female). Men are the minority (44.3%) and women are the
majority (55.6%). The dataset has moderate homophily."
REFERENCES,0.3651006711409396,"High School (HS), [14].
A high school friendship network collected from Mastrandrea et al. [14],
with 133 nodes in its main connected component represented by students who self-identify as male
or female. The majority are female (60%), and the network is homophilic."
REFERENCES,0.36644295302013424,"Indian Villages (IV), [1].
The dataset contains different demographic attributes for the individual
networks and the household networks collected in 77 Indian villages, from which we select Mother-
tongue (Telugu or Kannada) as the sensitive attribute. We note that most villages contain a majority
mother tongue, either Telugu or Kannada. We pick a random village with 90 individuals for our study."
REFERENCES,0.36778523489932885,"Instagram (INS), [22].
An interaction network from Instagram containing 553, 628 nodes, where
everyone has a labeled gender (45.57% men and 54.43% women). Each edge between two users
represents a ‘like’ or ‘comment’ that one user gave another on a posted photo. The dataset has
moderate homophily."
REFERENCES,0.3691275167785235,"D
Details on the Experiments and Extended Results"
REFERENCES,0.3704697986577181,"We use R = 1000 throughout our experiments.
For the outreach, we discretize the space
[0, 1] × [0, 1] into 100 × 100 equal sized bins.
For S3D (refer to Appendix E), we use
constants, exploit_to_explore = 1.3, non_acceptance_retention_prob = 0.95, and
shallow_horizon = 4."
REFERENCES,0.3718120805369127,"D.1
Outreach Distribution"
REFERENCES,0.3731543624161074,We report additional experiments in Figs. 8 to 11.
REFERENCES,0.374496644295302,"0
0.2
0 0.2"
REFERENCES,0.37583892617449666,% outreach group 1
REFERENCES,0.37718120805369126,% outreach group 2
REFERENCES,0.3785234899328859,"AH, p = 0.1
hrt d, |S| = 20"
REFERENCES,0.37986577181208053,"0
0.2
0 0.2"
REFERENCES,0.3812080536912752,% outreach group 1
REFERENCES,0.3825503355704698,% outreach group 2
REFERENCES,0.3838926174496644,"AH, p = 0.1
hrt g, |S| = 20"
REFERENCES,0.38523489932885907,"0
0.2
0 0.2"
REFERENCES,0.3865771812080537,% outreach group 1
REFERENCES,0.38791946308724834,% outreach group 2
REFERENCES,0.38926174496644295,"AH, p = 0.1
bas d, |S| = 20"
REFERENCES,0.3906040268456376,"0
0.2
0 0.2"
REFERENCES,0.3919463087248322,% outreach group 1
REFERENCES,0.3932885906040268,% outreach group 2
REFERENCES,0.3946308724832215,"AH, p = 0.1
bas g, |S| = 20 0.8
1 0.8 1"
REFERENCES,0.3959731543624161,% outreach group 1
REFERENCES,0.39731543624161075,% outreach group 2
REFERENCES,0.39865771812080536,"AH, p = 0.5
hrt d, |S| = 10 0.8
1 0.8 1"
REFERENCES,0.4,% outreach group 1
REFERENCES,0.40134228187919463,% outreach group 2
REFERENCES,0.40268456375838924,"AH, p = 0.5
hrt g, |S| = 10 0.8
1 0.8 1"
REFERENCES,0.4040268456375839,% outreach group 1
REFERENCES,0.4053691275167785,% outreach group 2
REFERENCES,0.40671140939597317,"AH, p = 0.5
bas d, |S| = 10 0.8
1 0.8 1"
REFERENCES,0.4080536912751678,% outreach group 1
REFERENCES,0.40939597315436244,% outreach group 2
REFERENCES,0.41073825503355704,"AH, p = 0.5
bas g, |S| = 10"
REFERENCES,0.4120805369127517,"0
0.2
0.4
0.6
0 0.2 0.4 0.6"
REFERENCES,0.4134228187919463,% outreach group 1
REFERENCES,0.4147651006711409,% outreach group 2
REFERENCES,0.4161073825503356,"APS, p = 0.3
hrt_d, |S| = 6"
REFERENCES,0.4174496644295302,"0
0.2
0.4
0.6
0 0.2 0.4 0.6"
REFERENCES,0.41879194630872485,% outreach group 1
REFERENCES,0.42013422818791946,% outreach group 2
REFERENCES,0.4214765100671141,"APS, p = 0.3
hrt_g, |S| = 6"
REFERENCES,0.4228187919463087,"0
0.2
0.4
0.6
0 0.2 0.4 0.6"
REFERENCES,0.42416107382550333,% outreach group 1
REFERENCES,0.425503355704698,% outreach group 2
REFERENCES,0.4268456375838926,"APS, p = 0.3
bas_d, |S| = 6"
REFERENCES,0.42818791946308726,"0
0.2
0.4
0.6
0 0.2 0.4 0.6"
REFERENCES,0.42953020134228187,% outreach group 1
REFERENCES,0.43087248322147653,% outreach group 2
REFERENCES,0.43221476510067114,"APS, p = 0.3
bas_g, |S| = 6"
REFERENCES,0.43355704697986575,Figure 8: Outreach distribution.
REFERENCES,0.4348993288590604,"0
0.2
0.4
0.6
0 0.2 0.4 0.6"
REFERENCES,0.436241610738255,% outreach group 1
REFERENCES,0.4375838926174497,% outreach group 2
REFERENCES,0.4389261744966443,"AV_0, p = 0.3
hrt_d, |S| = 4"
REFERENCES,0.44026845637583895,"0
0.2
0.4
0.6
0 0.2 0.4 0.6"
REFERENCES,0.44161073825503355,% outreach group 1
REFERENCES,0.4429530201342282,% outreach group 2
REFERENCES,0.4442953020134228,"AV_0, p = 0.3
hrt_g, |S| = 4"
REFERENCES,0.44563758389261743,"0
0.2
0.4
0.6
0 0.2 0.4 0.6"
REFERENCES,0.4469798657718121,% outreach group 1
REFERENCES,0.4483221476510067,% outreach group 2
REFERENCES,0.44966442953020136,"AV_0, p = 0.3
bas_d, |S| = 4"
REFERENCES,0.45100671140939597,"0
0.2
0.4
0.6
0 0.2 0.4 0.6"
REFERENCES,0.45234899328859063,% outreach group 1
REFERENCES,0.45369127516778524,% outreach group 2
REFERENCES,0.45503355704697984,"AV_0, p = 0.3
bas_g, |S| = 4"
REFERENCES,0.4563758389261745,"0
0.2
0.4
0 0.2 0.4"
REFERENCES,0.4577181208053691,% outreach group 1
REFERENCES,0.4590604026845638,% outreach group 2
REFERENCES,0.4604026845637584,"AV_2, p = 0.2
hrt_d, |S| = 4"
REFERENCES,0.46174496644295304,"0
0.2
0.4
0 0.2 0.4"
REFERENCES,0.46308724832214765,% outreach group 1
REFERENCES,0.46442953020134226,% outreach group 2
REFERENCES,0.4657718120805369,"AV_2, p = 0.2
hrt_g, |S| = 4"
REFERENCES,0.4671140939597315,"0
0.2
0.4
0 0.2 0.4"
REFERENCES,0.4684563758389262,% outreach group 1
REFERENCES,0.4697986577181208,% outreach group 2
REFERENCES,0.47114093959731546,"AV_2, p = 0.2
bas_d, |S| = 4"
REFERENCES,0.47248322147651006,"0
0.2
0.4
0 0.2 0.4"
REFERENCES,0.4738255033557047,% outreach group 1
REFERENCES,0.47516778523489933,% outreach group 2
REFERENCES,0.47651006711409394,"AV_2, p = 0.2
bas_g, |S| = 4"
REFERENCES,0.4778523489932886,"0
0.2
0.4
0 0.2 0.4"
REFERENCES,0.4791946308724832,% outreach group 1
REFERENCES,0.48053691275167787,% outreach group 2
REFERENCES,0.4818791946308725,"AV_2, p = 0.2
hrt_d, |S| = 4"
REFERENCES,0.48322147651006714,"0
0.2
0.4
0 0.2 0.4"
REFERENCES,0.48456375838926175,% outreach group 1
REFERENCES,0.48590604026845635,% outreach group 2
REFERENCES,0.487248322147651,"AV_2, p = 0.2
hrt_g, |S| = 4"
REFERENCES,0.4885906040268456,"0
0.2
0.4
0 0.2 0.4"
REFERENCES,0.4899328859060403,% outreach group 1
REFERENCES,0.4912751677852349,% outreach group 2
REFERENCES,0.49261744966442955,"AV_2, p = 0.2
bas_d, |S| = 4"
REFERENCES,0.49395973154362416,"0
0.2
0.4
0 0.2 0.4"
REFERENCES,0.49530201342281877,% outreach group 1
REFERENCES,0.4966442953020134,% outreach group 2
REFERENCES,0.49798657718120803,"AV_2, p = 0.2
bas_g, |S| = 4"
REFERENCES,0.4993288590604027,"0
0.2
0 0.2"
REFERENCES,0.5006711409395973,% outreach group 1
REFERENCES,0.5020134228187919,% outreach group 2
REFERENCES,0.5033557046979866,"AV_16, p = 0.1
hrt_d, |S| = 10"
REFERENCES,0.5046979865771812,"0
0.2
0 0.2"
REFERENCES,0.5060402684563758,% outreach group 1
REFERENCES,0.5073825503355704,% outreach group 2
REFERENCES,0.508724832214765,"AV_16, p = 0.1
hrt_g, |S| = 10"
REFERENCES,0.5100671140939598,"0
0.2
0 0.2"
REFERENCES,0.5114093959731544,% outreach group 1
REFERENCES,0.512751677852349,% outreach group 2
REFERENCES,0.5140939597315436,"AV_16, p = 0.1
bas_d, |S| = 10"
REFERENCES,0.5154362416107383,"0
0.2
0 0.2"
REFERENCES,0.5167785234899329,% outreach group 1
REFERENCES,0.5181208053691275,% outreach group 2
REFERENCES,0.5194630872483221,"AV_16, p = 0.1
bas_g, |S| = 10"
REFERENCES,0.5208053691275167,"0.4
0.6
0.8
1
0.4 0.6 0.8 1"
REFERENCES,0.5221476510067115,% outreach group 1
REFERENCES,0.5234899328859061,% outreach group 2
REFERENCES,0.5248322147651007,"AV_20, p = 0.5
hrt_d, |S| = 15"
REFERENCES,0.5261744966442953,"0.4
0.6
0.8
1
0.4 0.6 0.8 1"
REFERENCES,0.5275167785234899,% outreach group 1
REFERENCES,0.5288590604026846,% outreach group 2
REFERENCES,0.5302013422818792,"AV_20, p = 0.5
hrt_g, |S| = 15"
REFERENCES,0.5315436241610738,"0.4
0.6
0.8
1
0.4 0.6 0.8 1"
REFERENCES,0.5328859060402684,% outreach group 1
REFERENCES,0.5342281879194631,% outreach group 2
REFERENCES,0.5355704697986577,"AV_20, p = 0.5
bas_d, |S| = 15"
REFERENCES,0.5369127516778524,"0.4
0.6
0.8
1
0.4 0.6 0.8 1"
REFERENCES,0.538255033557047,% outreach group 1
REFERENCES,0.5395973154362416,% outreach group 2
REFERENCES,0.5409395973154363,"AV_20, p = 0.5
bas_g, |S| = 15"
REFERENCES,0.5422818791946309,Figure 9: Outreach distribution.
REFERENCES,0.5436241610738255,"0
0.2
0 0.2"
REFERENCES,0.5449664429530201,% outreach group 1
REFERENCES,0.5463087248322148,% outreach group 2
REFERENCES,0.5476510067114094,"DZ, p = 0.1
hrt d, |S| = 90"
REFERENCES,0.548993288590604,"0
0.2
0 0.2"
REFERENCES,0.5503355704697986,% outreach group 1
REFERENCES,0.5516778523489932,% outreach group 2
REFERENCES,0.553020134228188,"DZ, p = 0.1
hrt g, |S| = 90"
REFERENCES,0.5543624161073826,"0
0.2
0 0.2"
REFERENCES,0.5557046979865772,% outreach group 1
REFERENCES,0.5570469798657718,% outreach group 2
REFERENCES,0.5583892617449664,"DZ, p = 0.1
bas d, |S| = 90"
REFERENCES,0.5597315436241611,"0
0.2
0 0.2"
REFERENCES,0.5610738255033557,% outreach group 1
REFERENCES,0.5624161073825503,% outreach group 2
REFERENCES,0.5637583892617449,"DZ, p = 0.1
bas g, |S| = 90"
REFERENCES,0.5651006711409396,"0
0.2
0 0.2"
REFERENCES,0.5664429530201343,% outreach group 1
REFERENCES,0.5677852348993289,% outreach group 2
REFERENCES,0.5691275167785235,"HS, p = 0.01
hrt d, |S| = 10"
REFERENCES,0.5704697986577181,"0
0.2
0 0.2"
REFERENCES,0.5718120805369128,% outreach group 1
REFERENCES,0.5731543624161074,% outreach group 2
REFERENCES,0.574496644295302,"HS, p = 0.01
hrt g, |S| = 10"
REFERENCES,0.5758389261744966,"0
0.2
0 0.2"
REFERENCES,0.5771812080536913,% outreach group 1
REFERENCES,0.5785234899328859,% outreach group 2
REFERENCES,0.5798657718120805,"HS, p = 0.01
bas d, |S| = 10"
REFERENCES,0.5812080536912752,"0
0.2
0 0.2"
REFERENCES,0.5825503355704698,% outreach group 1
REFERENCES,0.5838926174496645,% outreach group 2
REFERENCES,0.5852348993288591,"HS, p = 0.01
bas g, |S| = 10"
REFERENCES,0.5865771812080537,"0.6
0.8
1
0.6 0.8 1"
REFERENCES,0.5879194630872483,% outreach group 1
REFERENCES,0.5892617449664429,% outreach group 2
REFERENCES,0.5906040268456376,"HS, p = 0.5
hrt d, |S| = 6"
REFERENCES,0.5919463087248322,"0.6
0.8
1
0.6 0.8 1"
REFERENCES,0.5932885906040268,% outreach group 1
REFERENCES,0.5946308724832214,% outreach group 2
REFERENCES,0.5959731543624162,"HS, p = 0.5
hrt g, |S| = 6"
REFERENCES,0.5973154362416108,"0.6
0.8
1
0.6 0.8 1"
REFERENCES,0.5986577181208054,% outreach group 1
REFERENCES,0.6,% outreach group 2
REFERENCES,0.6013422818791946,"HS, p = 0.5
bas d, |S| = 6"
REFERENCES,0.6026845637583893,"0.6
0.8
1
0.6 0.8 1"
REFERENCES,0.6040268456375839,% outreach group 1
REFERENCES,0.6053691275167785,% outreach group 2
REFERENCES,0.6067114093959731,"HS, p = 0.5
bas g, |S| = 6"
REFERENCES,0.6080536912751678,"0
0.2
0.4
0 0.2 0.4"
REFERENCES,0.6093959731543624,% outreach group 1
REFERENCES,0.610738255033557,% outreach group 2
REFERENCES,0.6120805369127517,"HS, p = 0.1
hrt d, |S| = 4"
REFERENCES,0.6134228187919463,"0
0.2
0.4
0 0.2 0.4"
REFERENCES,0.614765100671141,% outreach group 1
REFERENCES,0.6161073825503356,% outreach group 2
REFERENCES,0.6174496644295302,"HS, p = 0.1
hrt g, |S| = 4"
REFERENCES,0.6187919463087248,"0
0.2
0.4
0 0.2 0.4"
REFERENCES,0.6201342281879194,% outreach group 1
REFERENCES,0.6214765100671141,% outreach group 2
REFERENCES,0.6228187919463087,"HS, p = 0.1
bas d, |S| = 4"
REFERENCES,0.6241610738255033,"0
0.2
0.4
0 0.2 0.4"
REFERENCES,0.625503355704698,% outreach group 1
REFERENCES,0.6268456375838927,% outreach group 2
REFERENCES,0.6281879194630873,"HS, p = 0.1
bas g, |S| = 4"
REFERENCES,0.6295302013422819,Figure 10: Outreach distribution.
REFERENCES,0.6308724832214765,"0
0.2
0 0.2"
REFERENCES,0.6322147651006711,% outreach group 1
REFERENCES,0.6335570469798658,% outreach group 2
REFERENCES,0.6348993288590604,"IV, p = 0.1
hrt d, |S| = 2"
REFERENCES,0.636241610738255,"0
0.2
0 0.2"
REFERENCES,0.6375838926174496,% outreach group 1
REFERENCES,0.6389261744966444,% outreach group 2
REFERENCES,0.640268456375839,"IV, p = 0.1
hrt g, |S| = 2"
REFERENCES,0.6416107382550336,"0
0.2
0 0.2"
REFERENCES,0.6429530201342282,% outreach group 1
REFERENCES,0.6442953020134228,% outreach group 2
REFERENCES,0.6456375838926175,"IV, p = 0.1
bas d, |S| = 2"
REFERENCES,0.6469798657718121,"0
0.2
0 0.2"
REFERENCES,0.6483221476510067,% outreach group 1
REFERENCES,0.6496644295302013,% outreach group 2
REFERENCES,0.6510067114093959,"IV, p = 0.1
bas g, |S| = 2"
REFERENCES,0.6523489932885906,"0
0.2
0 0.2"
REFERENCES,0.6536912751677852,% outreach group 1
REFERENCES,0.6550335570469799,% outreach group 2
REFERENCES,0.6563758389261745,"IV, p = 0.1
hrt d, |S| = 2"
REFERENCES,0.6577181208053692,"0
0.2
0 0.2"
REFERENCES,0.6590604026845638,% outreach group 1
REFERENCES,0.6604026845637584,% outreach group 2
REFERENCES,0.661744966442953,"IV, p = 0.1
hrt g, |S| = 2"
REFERENCES,0.6630872483221476,"0
0.2
0 0.2"
REFERENCES,0.6644295302013423,% outreach group 1
REFERENCES,0.6657718120805369,% outreach group 2
REFERENCES,0.6671140939597315,"IV, p = 0.1
bas d, |S| = 2"
REFERENCES,0.6684563758389261,"0
0.2
0 0.2"
REFERENCES,0.6697986577181209,% outreach group 1
REFERENCES,0.6711409395973155,% outreach group 2
REFERENCES,0.6724832214765101,"IV, p = 0.1
bas g, |S| = 2"
REFERENCES,0.6738255033557047,Figure 11: Outreach distribution.
REFERENCES,0.6751677852348993,"D.2
The Impact of the Conduction Probability for Various Dataset"
REFERENCES,0.676510067114094,We report additional experiments in Figs. 12 and 13.
REFERENCES,0.6778523489932886,"0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0.96 0.98 1"
REFERENCES,0.6791946308724832,Conduction Probability
REFERENCES,0.6805369127516778,Mutual fairness
REFERENCES,0.6818791946308724,"AH, bas_g, |S| = 6"
REFERENCES,0.6832214765100671,"0
0.2
0.4
0.6
0.8
1 0.96 0.98 1"
REFERENCES,0.6845637583892618,Equity (1-diff. in exp. outreach)
REFERENCES,0.6859060402684564,"(a) bas_g seeds in AH, |S| = 6"
REFERENCES,0.687248322147651,"0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0.7 0.8 0.9 1"
REFERENCES,0.6885906040268457,Conduction Probability
REFERENCES,0.6899328859060403,Mutual fairness
REFERENCES,0.6912751677852349,"APS, bas_d, |S| = 15"
REFERENCES,0.6926174496644295,"0
0.2
0.4
0.6
0.8
1 0.7 0.8 0.9 1"
REFERENCES,0.6939597315436241,Equity (1-diff. in exp. outreach)
REFERENCES,0.6953020134228188,"(b) bas_d seeds in APS, |S| = 15"
REFERENCES,0.6966442953020134,"0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0.9 0.95 1"
REFERENCES,0.697986577181208,Conduction Probability
REFERENCES,0.6993288590604027,Mutual fairness
REFERENCES,0.7006711409395974,"APS, bas_g, |S| = 15"
REFERENCES,0.702013422818792,"0
0.2
0.4
0.6
0.8
1 0.9 0.95 1"
REFERENCES,0.7033557046979866,Equity (1-diff. in exp. outreach)
REFERENCES,0.7046979865771812,"(c) bas_g seeds in APS, |S| = 15"
REFERENCES,0.7060402684563758,"Figure 12: Part 1: Different definitions of fairness VS conduction probability on an outreach
distribution created by the bas_g or bas_d heuristic."
REFERENCES,0.7073825503355705,"0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0.92 0.94 0.96 0.98 1"
REFERENCES,0.7087248322147651,Conduction Probability
REFERENCES,0.7100671140939597,Mutual fairness
REFERENCES,0.7114093959731543,"AV_0, bas_g, |S| = 20"
REFERENCES,0.7127516778523489,"0
0.2
0.4
0.6
0.8
1 0.97 0.98 0.99 1"
REFERENCES,0.7140939597315437,Equity (1-diff. in exp. outreach)
REFERENCES,0.7154362416107383,"(a) bas_g seeds in AV_0, |S| = 20"
REFERENCES,0.7167785234899329,"0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0.94 0.96 0.98 1"
REFERENCES,0.7181208053691275,Conduction Probability
REFERENCES,0.7194630872483222,Mutual fairness
REFERENCES,0.7208053691275168,"DZ, bas_g, |S| = 50"
REFERENCES,0.7221476510067114,"0
0.2
0.4
0.6
0.8
1 0.94 0.96 0.98 1"
REFERENCES,0.723489932885906,Equity (1-diff. in exp. outreach)
REFERENCES,0.7248322147651006,"(b) bas_g seeds in DZ, |S| = 50"
REFERENCES,0.7261744966442953,"0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1 0.9 0.95 1"
REFERENCES,0.72751677852349,Conduction Probability
REFERENCES,0.7288590604026846,Mutual fairness
REFERENCES,0.7302013422818792,"HS, bas_g, |S| = 6"
REFERENCES,0.7315436241610739,"0
0.2
0.4
0.6
0.8
1 0.9 0.95 1"
REFERENCES,0.7328859060402685,Equity (1-diff. in exp. outreach)
REFERENCES,0.7342281879194631,"(c) bas_g seeds in HS, |S| = 6"
REFERENCES,0.7355704697986577,"0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1 0.9 0.95 1"
REFERENCES,0.7369127516778523,Conduction Probability
REFERENCES,0.738255033557047,Mutual fairness
REFERENCES,0.7395973154362416,"IV, bas_g, |S| = 2"
REFERENCES,0.7409395973154362,"0
0.2
0.4
0.6
0.8
1 0.9 0.95 1"
REFERENCES,0.7422818791946308,Equity (1-diff. in exp. outreach)
REFERENCES,0.7436241610738255,"(d) bas_g seeds in IV, |S| = 2"
REFERENCES,0.7449664429530202,"Figure 13: Part 2: Different definitions of fairness VS conduction probability on an outreach
distribution created by the bas_g heuristic."
REFERENCES,0.7463087248322148,"D.3
Fairness-Efficiency performance of seedset selection algorithms"
REFERENCES,0.7476510067114094,We report more experiments in Fig. 14.
REFERENCES,0.748993288590604,"0.1 0.12 0.14 0.16 0.18 0.2
0.96 0.97 0.98 0.99 1"
REFERENCES,0.7503355704697987,Efficiency
REFERENCES,0.7516778523489933,Fairness
REFERENCES,0.7530201342281879,"AH, p = 0.1
|S| = 10, β = 0.8"
REFERENCES,0.7543624161073825,"0.94
0.94
0.95
0.95
0.96
0.98 0.99 0.99 1 1"
REFERENCES,0.7557046979865771,Efficiency
REFERENCES,0.7570469798657719,Fairness
REFERENCES,0.7583892617449665,"AH, p = 0.5
|S| = 10, β = 0.8"
REFERENCES,0.7597315436241611,"0
0.1
0.2
0.3
0.4 0.8 0.9 1"
REFERENCES,0.7610738255033557,Efficiency
REFERENCES,0.7624161073825504,Fairness
REFERENCES,0.763758389261745,"APS, p = 0.3
|S| = 6, β = 0.5"
REFERENCES,0.7651006711409396,"0.1
0.2
0.3
0.4 0.8 0.9 1"
REFERENCES,0.7664429530201342,Efficiency
REFERENCES,0.7677852348993288,Fairness
REFERENCES,0.7691275167785235,"APS, p = 0.3
|S| = 6, β = 0.8"
REFERENCES,0.7704697986577181,"0.2
0.25
0.3
0.35
0.9 0.92 0.94 0.96 0.98 1"
REFERENCES,0.7718120805369127,Efficiency
REFERENCES,0.7731543624161074,Fairness
REFERENCES,0.774496644295302,"AV_0, p = 0.3
|S| = 4, β = 0.8"
REFERENCES,0.7758389261744967,"0.06
0.08
0.1 0.96 0.98 1"
REFERENCES,0.7771812080536913,Efficiency
REFERENCES,0.7785234899328859,Fairness
REFERENCES,0.7798657718120805,"AV_2, p = 0.2
|S| = 4, β = 0.5"
REFERENCES,0.7812080536912752,"0.06
0.08
0.1 0.96 0.98 1"
REFERENCES,0.7825503355704698,Efficiency
REFERENCES,0.7838926174496644,Fairness
REFERENCES,0.785234899328859,"AV_2, p = 0.2
|S| = 4, β = 0.8"
REFERENCES,0.7865771812080536,"0
0.02 0.04 0.06 0.08 0.1 0.96 0.98 1"
REFERENCES,0.7879194630872484,Efficiency
REFERENCES,0.789261744966443,Fairness
REFERENCES,0.7906040268456376,"AV_16, p = 0.1
|S| = 10, β = 0.8"
REFERENCES,0.7919463087248322,"0.6
0.65
0.7
0.75
0.8
0.9 0.92 0.94 0.96 0.98 1"
REFERENCES,0.7932885906040269,Efficiency
REFERENCES,0.7946308724832215,Fairness
REFERENCES,0.7959731543624161,"AV_20, p = 0.5
|S| = 15, β = 0.8"
REFERENCES,0.7973154362416107,"0.06 0.08 0.1 0.12 0.14
0.99 1"
REFERENCES,0.7986577181208053,Efficiency
REFERENCES,0.8,Fairness
REFERENCES,0.8013422818791947,"DZ, p = 0.1
|S| = 90, β = 0.8"
REFERENCES,0.8026845637583893,"0.06
0.08
0.1
0.9 0.92 0.94 0.96 0.98 1"
REFERENCES,0.8040268456375839,Efficiency
REFERENCES,0.8053691275167785,Fairness
REFERENCES,0.8067114093959732,"HS, p = 0.01
|S| = 10, β = 0.5"
REFERENCES,0.8080536912751678,"0.8 0.82 0.84 0.86 0.88 0.9
0.9 0.92 0.94 0.96 0.98 1"
REFERENCES,0.8093959731543624,Efficiency
REFERENCES,0.810738255033557,Fairness
REFERENCES,0.8120805369127517,"HS, p = 0.5
|S| = 6, β = 0.8"
REFERENCES,0.8134228187919463,"0.06 0.08 0.1 0.12 0.14
0.9 0.92 0.94 0.96 0.98 1"
REFERENCES,0.8147651006711409,Efficiency
REFERENCES,0.8161073825503355,Fairness
REFERENCES,0.8174496644295302,"HS, p = 0.1
|S| = 4, β = 0.8"
REFERENCES,0.8187919463087249,"0
0.02 0.04 0.06 0.08 0.1
0.9 0.92 0.94 0.96 0.98 1"
REFERENCES,0.8201342281879195,Efficiency
REFERENCES,0.8214765100671141,Fairness
REFERENCES,0.8228187919463087,"IV, p = 0.1
|S| = 2, β = 0.5"
REFERENCES,0.8241610738255034,"0
0.02 0.04 0.06 0.08 0.1
0.9 0.92 0.94 0.96 0.98 1"
REFERENCES,0.825503355704698,Efficiency
REFERENCES,0.8268456375838926,Fairness
REFERENCES,0.8281879194630872,"IV, p = 0.1
|S| = 2, β = 0.8"
REFERENCES,0.8295302013422818,0.46 0.48 0.5 0.52 0.54 0.96 0.98 1
REFERENCES,0.8308724832214766,Efficiency
REFERENCES,0.8322147651006712,Fairness
REFERENCES,0.8335570469798658,"INS, p = 0.5
|S| = 28, β = 0.8"
REFERENCES,0.8348993288590604,"Figure 14: S3D trade-off and improvement against other label-aware and label-blind algorithms.
Filled markers refer to greedy-based algorithms: ■= bas_g,  = S3D_g, and ♦= hrt_g. Empty
markers refer to degree-based algorithms: □= bas_d, # = S3D_d, and ♢= hrt_d."
REFERENCES,0.836241610738255,"E
Details on the Algorithm"
REFERENCES,0.8375838926174497,"E.1
Pseudocode"
REFERENCES,0.8389261744966443,"We provide more details on our algorithm, S3D, in two routines, Algorithm 2 and Algorithm 3."
REFERENCES,0.8402684563758389,Algorithm 2 Seed Selection Stochastic Descent (S3D) Step: Pseudo Code
REFERENCES,0.8416107382550335,"1: function SEEDSET_REACH(seedset,G,p,horizon)
▷nodes reached from seedset until
horizon
2:
realizations ←1000
▷for MCMC sampling, configurable
3:
reach ←[]"
REFERENCES,0.8429530201342282,"4:
while realizations do
5:
reach ←reach+ INDEPENDENT_CASCADE(seedset, G, p, horizon)
▷collect
nodes reached
6:
realizations ←realizations −1"
REFERENCES,0.8442953020134228,"7:
return reach
▷repetition of nodes reached"
REFERENCES,0.8456375838926175,"8: function S3D_STEP(seedset, G, p, fair_to_efficacy) ▷each step yields a new seedset
9:
exploit_to_explore ←1.3
▷experimentally chosen, configurable
10:
non_acceptance_retention_prob ←0.95
▷prob. of retaining set
11:
max_horizon ←GET_DIAM(G)
12:
horizon_factor ←max_horizon/4
▷limit runtime
13:
shallow_horizon ←max_horizon/horizon_factor"
REFERENCES,0.8469798657718121,"14:
num_seeds ←len(seedset)
15:
seedset ←DISTINCT(seedset)
16:
seedset ←FIT_TO_SIZE(seedset, num_seeds)
▷fit to size with random nodes
17:
reach ←SEEDSET_REACH(seedset, G, p, max_horizon)
18:
candidate_set ←[SAMPLE(reach, 1)]
▷get first in candidate seedset"
REFERENCES,0.8483221476510067,"19:
while num_seeds do
20:
last_seed ←candidate_set[−1]
▷get latest seed
21:
▷remove shallow reach of last seed from current reach
22:
reach ←reach−SEEDSET_REACH([last_seed], G, p, shallow_horizon)
23:
candidate_set ←candidate_set + [SAMPLE(reach, 1)]
▷extend new seedset
24:
num_seeds ←num_seeds −1"
REFERENCES,0.8496644295302014,"25:
curr_score ←-BETA_FAIRNESS(seedset, fair_to_efficacy)
26:
candidate_score ←-BETA_FAIRNESS(candidate_set, fair_to_efficacy)"
REFERENCES,0.851006711409396,"27:
▷Metropolis Sampling
28:
energy_change ←curr_score −candidate_score
29:
accept_prob ←CLIP(exp(exploit_to_explore ∗energy_change), [0, 1])"
REFERENCES,0.8523489932885906,"30:
nonce_1 ←U(0, 1)
31:
if nonce_1 < accept_prob then
32:
return candidate_set
▷get a better seedset
33:
else
34:
nonce_2 ←U(0, 1)
35:
if nonce_2 < non_acceptance_retention_prob then
36:
return seedset
▷retain existing choice
37:
else
38:
random_set ←SAMPLE(G.nodes, num_seeds)
39:
return random_set
▷completely random selection rarely"
REFERENCES,0.8536912751677852,"E.2
Estimating Runtime"
REFERENCES,0.8550335570469799,"We estimate the running time of Algorithm 2 and 3 combined. For the S3D_STEP, lines 9-13 are
constant operations and comprise dataset properties. Lines 14-15 cost O(|S|). FIT_TO_SIZE can
cost up to O(|S| log |V |) for sampling new |S| nodes. SEEDSET_REACH does repeated BFS, and so
costs O(R(|V | + |E|)). Lines 19-24 cost as follows,"
REFERENCES,0.8563758389261745,"O((|S −1|)(RdDmax
avg
+ R|V | + log R|V |))"
REFERENCES,0.8577181208053691,"where davg is the average degree of the graph, and Dmax is the largest diameter of the graph. The
first term here upper bounds the max computation in BFS for Dmax horizon. Other terms follow"
REFERENCES,0.8590604026845637,Algorithm 3 S3D Iteration: Pseudo Code
REFERENCES,0.8604026845637583,"1: function S3D_ITERATE(seedset, G, p, fair_to_efficacy, num_iters)
2:
least_score_seedset ←seedset
3:
least_score ←-BETA_FAIRNESS(seedset, fair_to_efficacy)"
REFERENCES,0.8617449664429531,"4:
while num_iters do
5:
seedset ←S3D_STEP(seedset, G, p, fair_to_efficacy)
6:
score ←−BETA_FAIRNESS(seedset, fair_to_efficacy)
7:
if score < least_score then
8:
least_seedset ←seedset
9:
num_iters ←num_iters −1"
REFERENCES,0.8630872483221477,"10:
return least_seedset"
REFERENCES,0.8644295302013423,"from the remaining operations in the while loop. Now, lines 25-26 first create an outreach from the
corresponding seedsets, costing O(R(|V | + |E|)) each, and then analytically calculate β-fairness
for all the R final configurations, costing O(R ∗1) each. In the worst case, we might additionally
execute lines 37-39 costing O(|S| log |V |). So, a single S3D_STEP costs"
REFERENCES,0.8657718120805369,"O(2|S| + |S| log |V | + R(|V | + |E|) + (|S −1|)(RdDmax
avg
+ R|V | + log R|V |)"
REFERENCES,0.8671140939597315,"+ 2(R(|V | + |E|) + R) + |S| log |V |)
= O(|S| log |V | + R(|V | + |E|)
+ R|S| + R|S||V | + |S| log |V |)
= O(|S| log |V | + R|S||V |)
= O(R|S||V |)."
REFERENCES,0.8684563758389262,"Here, we used the assumption that davg = O(2E/V ) = O(1) for a sparse graph (E = O(V )). Now
this S3D_STEP is run k times using S3D_ITERATE to find the best seedset in these k runs. Moreover,
we avoid any redundant calculations and memorize β-fairness for any seedset we discover. Hence,
the total runtime is O(kR|S||V |), as claimed."
REFERENCES,0.8697986577181208,"E.3
Motivation and Extension to Generic Combinatorial Optimization"
REFERENCES,0.8711409395973154,"The S3D approach to β-fairness optimization in this setting is independently motivated and in general
can be extended to any combinatorial optimization problem where each choice of initial action at
time t = 0, amongst exponentially many choices of actions, can lead a system to one of exponentially
many states, for which we know the probability distribution of the system achieving one of these
states and an associated, possibly non-convex, expected energy profile resulting from this stochastic
state occupancy of the system at a later time. S3D then boils down to iteratively trying different
initial actions that lead to small changes in the state occupancy distribution that align well with the
ideal occupancy distribution, leading to a gradual reduction of the expected potential energy of the
resulting system using Metropolis Sampling/Simulated Annealing."
REFERENCES,0.87248322147651,"In this study, the initial action at t = 0 is the initial seedset choice S, which leads to a distribution of
states, called the outreach distribution on final configuration (Theorem 2.1), that the system, a Social
Network here, can reach to. Each such distribution corresponds to a bounded expected ""potential
energy"" (keeping the ideally mutually fair distribution as reference) defined on β-fairness– a mutually
fair configuration is defined to be a ""stable"", less ""energetic"" system, and S3D aims to achieve it via
an optimal choice of S, S∗."
REFERENCES,0.8738255033557047,"E.4
Theoretical Guarantees of Convergence in S3D"
REFERENCES,0.8751677852348994,"The S3D algorithm is similar to non-convex optimization methods such as Simulated Annealing.
Such algorithms do not have theoretical guarantees but have a long history of empirical success."
REFERENCES,0.876510067114094,"Let f : P(V ) →[0, 1] be the β-fairness set-evaluation function defined in the power set of the graph
vertex set V . The function can then evaluate any seedset, S ⊆V for its β-fairness. Now for iterative
optimization purposes, S3D defines a sampling process to define neighbors S′ of S, based on similar
outreaches VS′ and VS. Then S3D essentially follows non-convex optimization of f using Simulated"
REFERENCES,0.8778523489932886,"Annealing under Metropolis Sampling at a constant temperature. While Simulated Annealing does
not have strict mathematical guarantees to find the global optimum in finite time, its empirical success
is well understood in non-convex optimization."
REFERENCES,0.8791946308724832,"While Simulated Annealing usually runs for finite iterations defined by an empirically tested tem-
perature schedule, we ran Simulated Annealing under several constant temperatures to estimate the
performance of S3D against baselines and concluded that a number of iterations k ∈[500, 1000] usu-
ally works well in practice. Hence, any decaying temperature schedule that translates total iterations
in this range should work fine."
REFERENCES,0.8805369127516779,"E.5
Illustrative Example"
REFERENCES,0.8818791946308725,"Consider the information spreading over the graph in Fig. 15 as an independent cascade model with
probability p = 0.1, with blue and red nodes belonging to two different groups. A greedy strategy
would choose the seed set as Sg = 3, 5 (enlarged nodes) as shown in Fig. 15a, thus leading to the
highly unfair outreach in Fig. 15b. In contrast, our algorithm S3D promotes the choice SS3D = 1, 4
reflected in 15c, which gives the more fair outreach plotted in Fig. 15d, showing that it improves over
greedy/sophisticated label-blind seed selection strategies."
REFERENCES,0.8832214765100671,"(a) Greedy Choice: Graph
(b) Greedy Choice: Outreach"
REFERENCES,0.8845637583892617,"(c) S3D Choice: Graph
(d) S3D Choice: Outreach"
REFERENCES,0.8859060402684564,"Figure 15: Toy example to show label-aware choice using S3D over a label-blind seedset selection process.
The enlarged nodes are selected seeds. Since the graph is small, the outreach discretization bucket has been
granularized for improved readability."
REFERENCES,0.887248322147651,"F
Error Bars on Fairness and Efficiency Experiments"
REFERENCES,0.8885906040268456,"Referring to Fig. 7, we mention 2σ symmetrical error bars on 100 repetitions for each of the
experiment pipelines, as follows. Since each experiment itself runs on R = 1, 000 realizations, we
take 100R = 105 samples of each random graph encoded social network dataset."
REFERENCES,0.8899328859060402,"-
Eff-Mean
Efficiency-Err-Bar (±2σ)
Fair-Mean
Fairness-Err-Bar (±2σ)"
REFERENCES,0.8912751677852349,"s3d_d
0.24
0.0022
0.94
0.002
hrt_d
0.105
0.005
0.911
0.004
bas_d
0.173
0.0016
0.803
0.003
s3d_g
0.25
0.002
0.945
0.002
hrt_g
0.17
0.0058
0.868
0.006
bas_g
0.318
0.002
0.898
0.003
Table 2: APS."
REFERENCES,0.8926174496644296,"-
Eff-Mean
Efficiency-Err-Bar (±2σ)
Fair-Mean
Fairness-Err-Bar (±2σ)"
REFERENCES,0.8939597315436242,"s3d_d
0.241
0.005
0.95
0.002
hrt_d
0.227
0.005
0.951
0.002
bas_d
0.277
0.004
0.935
0.002
s3d_g
0.241
0.005
0.951
0.002
hrt_g
0.258
0.005
0.945
0.003
bas_g
0.3
0.004
0.926
0.003
Table 3: AV_0."
REFERENCES,0.8953020134228188,"-
Eff-Mean
Efficiency-Err-Bar (±2σ)
Fair-Mean
Fairness-Err-Bar (±2σ)"
REFERENCES,0.8966442953020134,"s3d_d
0.08
0.0004
0.99
0.0008
hrt_d
0.08
0.0004
0.967
0.0007
bas_d
0.08
0.0004
0.91
0.001
s3d_g
0.08
0.0004
0.988
0.0008
hrt_g
0.08
0.0004
0.965
0.0008
bas_g
0.08
0.0004
0.938
0.0009
Table 4: HS, p = 0.01."
REFERENCES,0.897986577181208,"-
Eff-Mean
Efficiency-Err-Bar (±2σ)
Fair-Mean
Fairness-Err-Bar (±2σ)"
REFERENCES,0.8993288590604027,"s3d_d
0.88
0.002
0.96
0.001
hrt_d
0.83
0.002
0.94
0.002
bas_d
0.83
0.002
0.94
0.002
s3d_g
0.87
0.002
0.96
0.002
hrt_g
0.86
0.002
0.935
0.002
bas_g
0.89
0.002
0.94
0.002
Table 5: HS, p = 0.5."
REFERENCES,0.9006711409395973,"G
Declaration of Computational Resources"
REFERENCES,0.9020134228187919,"All experiments were performed on a local PC on a single CPU core 3.5 GHz. Except for datasets DZ,
INS, all datasets were loaded and operated on a local PC with 32 GB of RAM. For the largest datasets
(DZ, INS), we used remote compute clusters with ∼64 GB memory and similar CPU capabilities.
For the code development, we broadly used Python 3.10+, numpy, jupyter, and networkx [8].
Runtime for each non-S3D configured experiment on datasets except DZ, INS, was 10 −15 minutes.
For DZ, INS, this was approximately 1 −2 hours. For S3D optimizations to be satisfactory, we ran
each small dataset (except DZ, INS) for 1.5 hours additionally. For massive datasets DZ, INS, the
cluster took ∼4 days for k = 10 steps. The total set of experiments made, including the failed,
passed or submitted ones, roughly took the same order of resources separately."
REFERENCES,0.9033557046979865,NeurIPS Paper Checklist
CLAIMS,0.9046979865771813,1. Claims
CLAIMS,0.9060402684563759,"Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]"
CLAIMS,0.9073825503355705,"Justification: The paper sheds light on the limitation of most of the fairness metrics used in
the context of Social Influence Maximization. In particular, as mentioned in the Abstract, In
the literature, fairness is often quantified in terms of the expected outreach within individual
communities. In this paper, we demonstrate that such fairness metrics can be misleading
since they overlook the stochastic nature of information diffusion processes. We propose
a new metric that overcomes such limitations and, based on it, we propose a new seed
selection policy that strategically takes into account for mutual information. This is made
explicit in the abstract by saying We tackle this problem by designing a new fairness metric
that captures variability in outreach through optimal transport theory. We propose a new
seed-selection algorithm that optimizes both outreach and our new fairness metric, and
we show its efficacy on several real datasets. All these aspects are also mentioned in the
Contributions paragraph of the Introduction.
Guidelines:"
CLAIMS,0.9087248322147651,"• The answer NA means that the abstract and introduction do not include the claims
made in the paper.
• The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
• The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
• It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2. Limitations"
CLAIMS,0.9100671140939597,"Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: Yes. Limitations are listed in the second paragraph of Section 5 entitled
Limitations.
Guidelines:"
CLAIMS,0.9114093959731544,"• The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate ""Limitations"" section in their paper.
• The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
• The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
• The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
• The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
• If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness."
CLAIMS,0.912751677852349,"• While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations."
THEORY ASSUMPTIONS AND PROOFS,0.9140939597315436,3. Theory Assumptions and Proofs
THEORY ASSUMPTIONS AND PROOFS,0.9154362416107382,"Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?"
THEORY ASSUMPTIONS AND PROOFS,0.9167785234899329,Answer: [Yes]
THEORY ASSUMPTIONS AND PROOFS,0.9181208053691275,"Justification: The construction and validity of our metric are theoretically and didactically
explained in the paper in Section 3.1 and Section 3.3. Also, Appendix E, provides a formal
proof for the complexity of our proposed seed-selection algorithm."
THEORY ASSUMPTIONS AND PROOFS,0.9194630872483222,Guidelines:
THEORY ASSUMPTIONS AND PROOFS,0.9208053691275168,"• The answer NA means that the paper does not include theoretical results.
• All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
• All assumptions should be clearly stated or referenced in the statement of any theorems.
• The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
• Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced."
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9221476510067114,4. Experimental Result Reproducibility
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9234899328859061,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9248322147651007,Answer: [Yes]
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9261744966442953,"Justification: To replicate our experiments, we (i) open-sourced our code, (ii) put a reference
for each of the datasets used (see Section 3.2) (iii) provide a detailed pseudo-code for the
seed-selection algorithm (See Appendix E), and (iv) give clear explanation of the diffusion
process used (independent cascade) and the parameters choices (propagation probability,
size of the seed set, etc., see Section 3.2)."
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9275167785234899,Guidelines:
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9288590604026845,"• The answer NA means that the paper does not include experiments.
• If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
• If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
• Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
• While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9302013422818792,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b) If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c) If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d) We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results."
OPEN ACCESS TO DATA AND CODE,0.9315436241610738,5. Open access to data and code
OPEN ACCESS TO DATA AND CODE,0.9328859060402684,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?"
OPEN ACCESS TO DATA AND CODE,0.934228187919463,Answer: [Yes]
OPEN ACCESS TO DATA AND CODE,0.9355704697986578,"Justification: Our code is publicly available at https://github.com/nicolaslanzetti/
fairness-sim-ot."
OPEN ACCESS TO DATA AND CODE,0.9369127516778524,Guidelines:
OPEN ACCESS TO DATA AND CODE,0.938255033557047,"• The answer NA means that paper does not include experiments requiring code.
• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
public/guides/CodeSubmissionPolicy) for more details.
• While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
• The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines (https:
//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
• The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
• The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
• At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
• Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted."
OPEN ACCESS TO DATA AND CODE,0.9395973154362416,6. Experimental Setting/Details
OPEN ACCESS TO DATA AND CODE,0.9409395973154362,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?"
OPEN ACCESS TO DATA AND CODE,0.9422818791946309,Answer: [Yes]
OPEN ACCESS TO DATA AND CODE,0.9436241610738255,"Justification: Yes, all the hyperparameters involved in the experiments execution are specified
in Section 3.2 and Appendix D."
OPEN ACCESS TO DATA AND CODE,0.9449664429530201,Guidelines:
OPEN ACCESS TO DATA AND CODE,0.9463087248322147,"• The answer NA means that the paper does not include experiments.
• The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
• The full details can be provided either with the code, in appendix, or as supplemental
material."
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9476510067114094,7. Experiment Statistical Significance
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9489932885906041,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9503355704697987,Answer: [Yes]
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9516778523489933,"Justification: Plots requiring statistical significance are the ones in Fig. 7. Plots in Fig. 7 are
associated with statistical bounds reported in Appendix F."
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9530201342281879,Guidelines:
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9543624161073826,"• The answer NA means that the paper does not include experiments.
• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
• The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
• The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
• It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
• It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
• For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
• If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text."
EXPERIMENTS COMPUTE RESOURCES,0.9557046979865772,8. Experiments Compute Resources
EXPERIMENTS COMPUTE RESOURCES,0.9570469798657718,"Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?"
EXPERIMENTS COMPUTE RESOURCES,0.9583892617449664,Answer: [Yes]
EXPERIMENTS COMPUTE RESOURCES,0.959731543624161,Justification: Computational resources are detailed in Appendix G.
EXPERIMENTS COMPUTE RESOURCES,0.9610738255033557,Guidelines:
EXPERIMENTS COMPUTE RESOURCES,0.9624161073825503,"• The answer NA means that the paper does not include experiments.
• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
• The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
• The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper)."
CODE OF ETHICS,0.963758389261745,9. Code Of Ethics
CODE OF ETHICS,0.9651006711409396,"Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?"
CODE OF ETHICS,0.9664429530201343,Answer: [Yes]
CODE OF ETHICS,0.9677852348993289,"Justification: The paper conforms with the NeurIPS code of ethics. All the datasets we
tested our algorithm on preserve anonimity."
CODE OF ETHICS,0.9691275167785235,Guidelines:
CODE OF ETHICS,0.9704697986577181,• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
CODE OF ETHICS,0.9718120805369127,"• If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction)."
BROADER IMPACTS,0.9731543624161074,10. Broader Impacts
BROADER IMPACTS,0.974496644295302,"Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?"
BROADER IMPACTS,0.9758389261744966,Answer: [Yes]
BROADER IMPACTS,0.9771812080536912,"Justification: Yes, this is explicitly done in the Introduction and Abstract when we
explicitly mention the limitation of the current approaches that we propose to overcome.
For example we say: As such, outcomes such as “in 50% of the cases, no one of group A
receives the information and everyone in group B receives it and in other 50%, the opposite
happens”, which always results in largely unfair outcomes, are classified as fair by a variety
of fairness metrics in the literature. We tackle this problem by designing a new fairness
metric that captures variability in outreach through optimal transport theory. We propose a
new seed-selection algorithm that optimizes both outreach and our new fairness metric, and
we show its efficacy on several real datasets."
BROADER IMPACTS,0.978523489932886,Guidelines:
BROADER IMPACTS,0.9798657718120806,"• The answer NA means that there is no societal impact of the work performed.
• If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
• Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
• The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
• The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
• If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML)."
SAFEGUARDS,0.9812080536912752,11. Safeguards
SAFEGUARDS,0.9825503355704698,"Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?"
SAFEGUARDS,0.9838926174496644,Answer: [NA]
SAFEGUARDS,0.9852348993288591,Guidelines:
SAFEGUARDS,0.9865771812080537,"• The answer NA means that the paper poses no such risks.
• Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
• Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images."
SAFEGUARDS,0.9879194630872483,"• We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12. Licenses for existing assets"
SAFEGUARDS,0.9892617449664429,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: Yes, all the sources of existing datasets and algorithms have been cited and
can be found in the References.
Guidelines:"
SAFEGUARDS,0.9906040268456375,"• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
• The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
• For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
• If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
• For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
• If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13. New Assets"
SAFEGUARDS,0.9919463087248322,"Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [Yes]
Justification: We documented the code with instructions in README files and dedicated
comments in the code.
Guidelines:"
SAFEGUARDS,0.9932885906040269,"• The answer NA means that the paper does not release new assets.
• Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
• The paper should discuss whether and how consent was obtained from people whose
asset is used.
• At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14. Crowdsourcing and Research with Human Subjects"
SAFEGUARDS,0.9946308724832215,"Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Guidelines:"
SAFEGUARDS,0.9959731543624161,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper."
SAFEGUARDS,0.9973154362416108,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Guidelines:"
SAFEGUARDS,0.9986577181208054,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
• We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
• For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review."
