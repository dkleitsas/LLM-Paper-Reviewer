Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0025974025974025974,"Recurrent State-space models (RSSMs) are highly expressive models for learning
patterns in time series data and system identification. However, these models as-
sume that the dynamics are fixed and unchanging, which is rarely the case in real-
world scenarios. Many control applications often exhibit tasks with similar but not
identical dynamics which can be modeled as a latent variable. We introduce the
Hidden Parameter Recurrent State Space Models (HiP-RSSMs), a framework that
parametrizes a family of related dynamical systems with a low-dimensional set of
latent factors. We present a simple and effective way of learning and performing
inference over this Gaussian graphical model that avoids approximations like vari-
ational inference. We show that HiP-RSSMs outperforms RSSMs and competing
multi-task models on several challenging robotic benchmarks both on real-world
systems and simulations."
INTRODUCTION,0.005194805194805195,"1
INTRODUCTION"
INTRODUCTION,0.007792207792207792,"System identification, i.e., learning models of dynamical systems from observed data ( Ljung (1998);
Gevers (2005)), is a key ingredient of model-predictive control (Camacho & Alba (2013)) and
model-based reinforcement learning (RL). State space models (Hamilton (1994); Jordan (2004);
Sch¨on et al. (2011)) (SSMs) provide a principled framework for modelling dynamics. Recently
there have been several works that fused SSMs with deep (recurrent) neural networks achieving
superior results in time series modelling (Haarnoja et al., 2016; Karl et al., 2016) and system identi-
fication tasks (Becker et al., 2019; Hafner et al., 2019; Shaj et al., 2020). Learning the dynamics in
an encoded latent space allows us to work with high dimensional observations like images and was
proven to be successful for planning from high dimensional sensory inputs. However, most of these
tasks assume a fixed, unchanging dynamics, which is quite restrictive in real-world scenarios."
INTRODUCTION,0.01038961038961039,"Several control applications involve situations where an agent must learn to solve tasks with similar,
but not identical, dynamics. A robot playing table tennis may encounter several bats with different
weights or lengths, while an agent manipulating a bottle may face bottles with varying amounts of
liquid. An agent driving a car may encounter many different cars, each with unique handling char-
acteristics. Humanoids learning to walk may face different terrains with varying slopes or friction
coefficients. Any real-world dynamical system might change over time due to multiple reasons,
some of which might not be directly observable or understood. For example, in soft robotics small
variations in temperature or changes in friction coefficients of the cable drives of a robot can sig-
nificantly change the dynamics. Similarly, a robot may undergo wear and tear over time which can
change its dynamics. Thus, assuming a global model that is accurate throughout the entire state
space or duration of use is a limiting factor for using such models in real-world applications."
INTRODUCTION,0.012987012987012988,"We found that existing literature on recurrent models fails to model the dynamics accurately in
these situations. Thus, we introduce hidden parameter state-space models (HiP-SSM), which allow
capturing the variation in the dynamics of different instances through a set of hidden task parameters."
INTRODUCTION,0.015584415584415584,Correspondence to Vaisakh Shaj <v.shaj@kit.edu>
INTRODUCTION,0.01818181818181818,Published as a conference paper at ICLR 2022
INTRODUCTION,0.02077922077922078,"We formalize the HiP-SSM and show how to perform inference in this graphical model. Under
Gaussian assumptions, we obtain a probabilistically principled yet scalable approach. We name the
resulting probabilistic recurrent neural network as Hidden Parameter Recurrent State Space Model
(HiP-RSSM). HiP-RSSM achieves state-of-the-art performance for several systems whose dynamics
change over time. Interestingly, we also observe that HiP-RSSM often exceeds traditional RSSMs
in performance for dynamical systems previously assumed to have unchanging global dynamics due
to the identification of unobserved causal effects in the dynamics."
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.023376623376623377,"2
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS"
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.025974025974025976,"State space models are Bayesian probabilistic graphical models (Koller & Friedman, 2009; Jordan,
2004) that are popular for learning patterns and predicting behavior in sequential data and dynamical
systems. Let f(·) be any arbitrary dynamic model, and let h(·) be any arbitrary observation model.
Then, the dynamic systems of a Gaussian state space model can be represented using the following
equations"
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.02857142857142857,"zt = f(zt−1, at) + ut,
ut ∼N(0, Q)
ot = h(zt) + vt,
vt ∼N(0, R)."
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.03116883116883117,"Here zt, at and ot are the latent states, control inputs/actions and observations at time t. The
vectors ut ∼N(0, Q) and vt ∼N(0, R) denote zero-mean Gaussian noise. Further, based on
the assumptions made for f(·) and h(·), we can have different variants of Gaussian state space
models (Ribeiro, 2004; Wan & Van Der Merwe, 2000). In the linear case, inference can be performed
efficiently using Kalman Filters."
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.033766233766233764,"Our goal is to learn a state space model that can model the dynamics of partially observable robotic
systems under scenarios where the dynamics changes over time. Often, the dynamics of real systems
may differ in significant ways from the system our models were trained on. However, it is unrea-
sonable to train a model across all possible conditions an agent may encounter. Instead, we propose
a state space model that learns to account for the causal factors of variation observed across tasks
at training time, and then infer at test time the model that best describe the system. Thus, we intro-
duce a new formulation namely Hidden Parameter State Space Models (HiP-SSMs), a framework
for modeling families of SSMs with different but related dynamics using low-dimensional latent
task embeddings. In this section, we formally define the HiP-SSM family in Section 3.1, propose a
probabilistically principled inference scheme for HiP-SSMs based on the forward algorithm (Jordan,
2004) in Section 3.2, and finally provide training scheme for the setting in Section 3.3."
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.03636363636363636,"2.1
HIDDEN PARAMETER STATE SPACE MODELS (HIP-SSMS)"
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.03896103896103896,"z0
z1
z2"
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.04155844155844156,"w0
w1
w2 l Cl"
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.04415584415584416,"Figure 1: The graphical model
for a particular instance for the
HiP-SSM. The transition dy-
namics between latent states is
a function of the previous la-
tent state, and a specific latent
task parameter l which is in-
ferred from a context set of ob-
served past observations. Ac-
tions are omitted for brevity."
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.046753246753246755,"We denote a set of SSMs with transition dynamics fl that are fully de-
scribed by hidden parameters l and observation model h as a Hidden
Parameter SSM (HiP-SSM). In this definition we assume the observa-
tion model h to be independent of the hidden parameter l as we only
focus on cases where the dynamics changes. HiP-SSMs allows us to
extend SSMs to multi-task settings where dynamics can vary across
tasks. Defining the changes in dynamics by a latent variable unifies
dynamics across tasks as a single global function. In dynamical sys-
tems, for example, parameters can be physical quantities like gravity,
friction of a surface, or the strength of a robot actuator. Their effects
influence the dynamics but not directly observed; and hence l is not
part of the observation space and is treated as latent task parameter
vector."
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.04935064935064935,"Formally, a HiP-SSM is defined by a tuple {Z, A, W, L, f, h}, where
Z, A and W are the sets of hidden states z, actions a, and observa-
tions w respectively. L is the set of all possible latent task parameters
and let p0(l) be the prior over these parameters. Thus, a HiP-RSSM
describes a class of dynamics and a particular instance of that class is
obtained by fixing the parameter vector l ∈L. The dynamics f for
each instance depend on the value of the hidden parameters l."
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.05194805194805195,Published as a conference paper at ICLR 2022 rl
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.05454545454545454,"al
t
ol
t+1
ol
t
z0
z1
z2"
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.05714285714285714,"w0
w1
w2
a0
a1
a2"
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.05974025974025974,"o0
o1
o2 l
N (a) µl σl"
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.06233766233766234,"Context
Update"
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.06493506493506493,"{rl
n, (σl
rn)2}N
n=1"
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.06753246753246753,"Context
Encoder Cl"
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.07012987012987013,HiP-RSSM Cell
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.07272727272727272,"Time
Update
Observation
Update
z−
t , Σ−
t
z+
t , Σ+
t
z−
t+1, Σ−
t+1"
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.07532467532467532,"wt σobs
t
Observation
Encoder ot"
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.07792207792207792,"Decoder
Output ˆot+1 at"
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.08051948051948052,"(b)
Figure 2: (a) The Gaussian graphical model corresponding to a particular instance l ∈L for the HiP-RSSM.
The posterior of the latent task/context variable is inferred via a Bayesian aggregation procedure described
in 2.2.1 based on a set of N interaction histories. The prior over the latent states z−
t
is inferred via task
conditional Kalman time update described in 2.2.2 and the posterior over the latent states z+
t is inferred via
Kalman measurement update described in 2.2.3. Here, the hollow arrows denote deterministic transformation
leading to implicit distributions, using the context and observation encoders. (b) Depicts the schematic Of
HiP-RSSM. The output of the task conditional ‘Time Update’ stage, which forms the prior for the next time
step (z−
t+1, Σ−
t+1) is decoded to get the prediction of the next observation."
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.08311688311688312,"Each instance of a HiP-SSM is an SSM conditioned on l. We also make the additional assumption
that the parameter vector l is fixed for the duration of the task (i.e. a local segment of a trajectory),
and thus the latent task parameter has no dynamics. This assumption considerably simplifies the
procedure for inferring the hidden parametrization and is reasonable since dynamics can be assumed
to be locally-consistent over small trajectories in most applications (Nagabandi et al., 2018a)."
HIDDEN PARAMETER RECURRENT STATE SPACE MODELS,0.08571428571428572,"The definition is inspired from related literature on HiP-MDPs (Doshi-Velez & Konidaris, 2016),
where the only unobserved variable is the latent task variable. One can connect HiP-SSMs with
HiP-MDPs by including rewards to the definition and formalize HiP-POMDPs. However this is left
for future work."
LEARNING AND INFERENCE,0.08831168831168831,"2.2
LEARNING AND INFERENCE"
LEARNING AND INFERENCE,0.09090909090909091,"We perform inference and learning in the HiP-SSM borrowing concepts from both deep learning and
graphical model communities following recent works on recurrent neural network models (Haarnoja
et al., 2016; Becker et al., 2019), where the architecture of the network is informed by the structure
of the probabilistic state estimator. We denote the resulting probabilistic recurrent neural network
architecture as Hidden Parameter Recurrent State Space Model (HiP-RSSM)."
LEARNING AND INFERENCE,0.09350649350649351,"The structure of the Bayesian network shown in Figure 1 allows tractable inference of latent vari-
ables by the forward algorithm (Jordan, 2004; Koller & Friedman, 2009). Since we are dealing
with continuous dynamical systems, we assume a Gaussian multivariate distribution over all vari-
ables (both observed and hidden) for the graph shown in Figure 1. This assumption has several
advantages. Firstly, it makes the inference very similar to the well studied Kalman Filtering ap-
proaches. Secondly, the Gaussian assumptions and conditional in-dependencies allows us to have
a closed form solution to each of these update procedures which are fully differentiable and can be
backpropagated to the deep encoders. The belief update over the hidden variables zt and l happens
in three stages. Similar to Kalman filtering approaches, we have two recursive belief state update
stages, the time update and observation update which calculate the prior and posterior belief over
the latent states respectively. However, we have an additional hierarchical latent variable l which
models the (unobserved) causal factors of variation in dynamics in order to achieve efficient gener-
alization. Hence, we have a third belief update stage to calculate the posterior over the latent task
variable based on the observed context set. Each of these three stages are detailed in the sections
below:"
LEARNING AND INFERENCE,0.09610389610389611,"2.2.1
INFERRING THE LATENT TASK VARIABLE (CONTEXT UPDATE)"
LEARNING AND INFERENCE,0.0987012987012987,"In this stage, we infer the posterior over the Gaussian latent task variable l based on an ob-
served context set Cl.
For any HiP-RSSM instance defined over a target sequence T
="
LEARNING AND INFERENCE,0.1012987012987013,Published as a conference paper at ICLR 2022
LEARNING AND INFERENCE,0.1038961038961039,"(ot, at, ot+1, ..., ot+N, at+N), over which we intend to perform state estimation/prediction, we
maintain a fixed context set Cl. Cl in our HiP-SSM formalism can be obtained as per the algo-
rithm designer’s choice. We choose a Cl consisting a set of tuples Cl = {ol
t−n, al
t−n, ol
t−n+1}N
n=1.
Here each set element is a tuple consisting of the current state/observation, current action and next
state/observation for the previous N time steps."
LEARNING AND INFERENCE,0.10649350649350649,"Inferring a latent task variable l ∈L based on an observed context set Cl = {xl
n}N
n=1 has been
explored previously by different neural process architectures (Gordon et al., 2018; Garnelo et al.,
2018). Neural processes are multi-task latent variable models that rely on deep set functions (Zaheer
et al., 2017) to output a latent representation out of varying number of context points in a permutation
invariant manner. Similar to Volpp et al. (2020) we formulate context data aggregation as a Bayesian
inference problem, where the information contained in Cl is directly aggregated into the statistical
description of l based on a factorized Gaussian observation model of the form p(rl
n|l), where"
LEARNING AND INFERENCE,0.10909090909090909,"rl
n = encr(ol
t−n, al
t−n, ol
t−n+1),
 
σl
n
2 = encσ(ol
t−n, al
t−n, ol
t−n+1)."
LEARNING AND INFERENCE,0.11168831168831168,"Here n is the index of an element from context set Cl. Given a prior p0(l) = N(l|µ0, diag(σ2
0))
we can compute the posterior p(l|Cl) using Bayes rule. The Gaussian assumption allows us to
get a closed form solution for the posterior estimate of the latent task variable, p(l|Cl) based on
Gaussian conditioning. The factorization assumption further simplifies this update rule by avoiding
computationally expensive matrix inversions into a simpler update rule as"
LEARNING AND INFERENCE,0.11428571428571428,"σ2
l ="
LEARNING AND INFERENCE,0.11688311688311688," 
σ2
0
⊖+ N
X n=1"
LEARNING AND INFERENCE,0.11948051948051948," 
σl
n
2⊖
!⊖ ,"
LEARNING AND INFERENCE,0.12207792207792208,"µl = µ0 + σ2
l ⊙ N
X n=1"
LEARNING AND INFERENCE,0.12467532467532468," 
rl
n −µ0
2 ⊘
 
σl
n
2"
LEARNING AND INFERENCE,0.12727272727272726,"where ⊖, ⊙and ⊘denote element-wise inversion, product, and division, respectively. Intuitively
the mean of the latent task variable µl is a weighted sum of the individual latent observations rl
n,
while the variance of the latent task variable σ2
l gives the uncertainty of this task representation."
LEARNING AND INFERENCE,0.12987012987012986,"2.2.2
INFERRING PRIOR LATENT STATES OVER THE NEXT TIME STEP (TIME UPDATE)"
LEARNING AND INFERENCE,0.13246753246753246,The goal of this step is to compute the prior marginal
LEARNING AND INFERENCE,0.13506493506493505,"p(zt|w1:t−1, a1:t, Cl) =
ZZ
p(zt|zt−1, at, l)p(zt−1|w1:t−1, a1:t−1, Cl)p(l|Cl)dzt−1dl.
(1)"
LEARNING AND INFERENCE,0.13766233766233765,"We
assume
a
dynamical
model
of
the
following
form:
p(zt|zt−1, at, l)
=
N (At−1zt−1 + Bat + Cl, Σtrans) and denote the posterior from the previous time-step by
p(zt−1|w1:t−1, a1:t−1, Cl) = N
 
z+
t−1, Σ+
t−1

. Following Shaj et al. (2020) we assume the action
at is known and not subject to noise."
LEARNING AND INFERENCE,0.14025974025974025,"At any time t, the posterior over the belief state zt−1|w1:t−1, a1:t−1, posterior over the latent task
variable l|Cl and the action at are independent of each other since they form a “common-effect”
/ v-structure (Koller et al., 2007) with the unobserved variable zt. With these independencies and
Gaussian assumptions, according to Gaussian Identity 1, it can be shown that calculating the integral
in equation 1 has a closed form solution as follows, p(zt|w1:t−1, a1:t, Cl) = N(z−
t , Σ−
t ), where"
LEARNING AND INFERENCE,0.14285714285714285,"z−
t = At−1zt−1 + Bat + Cl,
(2)"
LEARNING AND INFERENCE,0.14545454545454545,"Σ−
t = At−1Σ+
t−1AT
t−1 + CΣlCT + Σtrans.
(3)"
LEARNING AND INFERENCE,0.14805194805194805,"Gaussian Identity 1. If u ∼N(µu + b, Σu) and v ∼N(µv, Σv) are normally distributed
independent random variables and if the conditional distribution p (y|u, v) = N(Au+b+Bv, Σ),
then marginal p(y) =
R
p(y|u, v)p(u)p(v))dudv = N(Aµu +b+Bµv, AΣuAT +BΣvBT +
Σ)"
LEARNING AND INFERENCE,0.15064935064935064,"We use a locally linear transition model At−1 as in Becker et al. (2019) and a non-linear control
model as in Shaj et al. (2020). The local linearization around the posterior mean, can be interpreted"
LEARNING AND INFERENCE,0.15324675324675324,Published as a conference paper at ICLR 2022
LEARNING AND INFERENCE,0.15584415584415584,"as equivalent to an EKF. For the latent task transformation we can either use a linear, locally-linear
or non-linear transformation. More details regarding the latent task transformation model can be
found in the appendix F.5. Our ablations (Figure 3c) show that a non-linear feedforward neural
network f(.) that outputs mean and variances and interact additively gave the best performance in
practice. f(.) transforms the latent task moments µl and σl directly into the latent space of the state
space model via additive interactions. The corresponding time update equations are given below:"
LEARNING AND INFERENCE,0.15844155844155844,"z−
t = At−1z+
t−1 + b(at) + f(µl),"
LEARNING AND INFERENCE,0.16103896103896104,"Σ−
t = At−1Σ+
t−1AT
t−1 + f(σl) + Σtrans."
LEARNING AND INFERENCE,0.16363636363636364,"2.2.3
INFERRING POSTERIOR LATENT STATES / OBSERVATION UPDATE"
LEARNING AND INFERENCE,0.16623376623376623,"The goal of this step is to compute the posterior belief p(zt|o1:t, a1:t, Cl).
We first
map the observations at each time step ot to a latent space using an observation en-
coder (Haarnoja et al., 2016; Becker et al., 2019) which emits latent features wt along
with an uncertainty in those features via a variance vector σt
obs.
We then compute the pos-
terior belief p(zt|w1:t, a1:t, Cl),
based on p(zt|w1:t−1, a1:t, Cl) obtained from the time
update, the latent observation (wt, σobs
t
) and the observation model H.
This is exactly the
Kalman update step, which has a closed form solution as shown below for a time instant t,"
LEARNING AND INFERENCE,0.16883116883116883,"Kalman Gain:
Qt = Σ−
t HT  
HΣ−
t HT + I · σobs
t
−1 ,"
LEARNING AND INFERENCE,0.17142857142857143,"Posterior Mean:
z+
t = z−
t + Qt
 
wt −Hz−
t

,"
LEARNING AND INFERENCE,0.17402597402597403,"Posterior Covariance:
Σ+
t = (I −QtH) Σ−
t ,
where I denotes the identity matrix. This update is added as a layer in the computation graph
(Haarnoja et al. (2016); Becker et al. (2019)). However, the Kalman update involves computation-
ally expensive matrix inversions of the order of O(L3), where L is the dimension of the latent state
zt. Thus, in order to make the approach scalable we follow the same factorization assumptions as
in Becker et al. (2019). This factorization provides a simple way of reducing the observation update
equation to a set of scalar operations, bringing down the computational complexity from O(L3) to
O(L). More mathematical details on the simplified update equation can be found in appendix F.7."
LEARNING AND INFERENCE,0.17662337662337663,"Discussion
From a computational perspective, this a Gaussian conditioning layer, similar to sec-
tion 2.2.1. Both outputs a posterior distribution over latent variables z, given a prior p(z) and an
observation model p(w|z), using Bayes rule: p(z|w) = p(w|z)p(z)/p(w). This has a closed form
solution because of Gaussian assumptions, which is coded as a layer in the neural network. The
observation model is assumed to have the following structure, P(w|z) = N(Hz, Σobs)."
TRAINING HIP-RSSM FOR EPISODIC ADAPTATION TO CHANGING DYNAMICS,0.17922077922077922,"2.3
TRAINING HIP-RSSM FOR EPISODIC ADAPTATION TO CHANGING DYNAMICS"
TRAINING HIP-RSSM FOR EPISODIC ADAPTATION TO CHANGING DYNAMICS,0.18181818181818182,"The latent task variable l models a distribution over functions Garnelo et al. (2018), rather than a
single function. In our case these functions are latent dynamics functions. In order to train such
a model we use a training procedure that reflects this objective, where we form datasets consisting
of timeseries, each with a different latent transition dynamics. Thus, we collect a set of trajectories
over which the dynamics changes over time. This can be trajectories where a robot picks up objects
of different weights or a robot traversing terrain of different slopes. Now we introduce a multi-task
setting with a rather flexible definition of task, where each temporal segment of a trajectory can be
considered to be a different “task” and the observed context set based on interaction histories from
the past N time steps provides information about the current task setting. This definition allows
us to have potentially infinite number of tasks/local dynamical systems and the distribution over
these tasks/systems is modelled using a hierarchical latent task variable l. The formalism is based
on the assumption that over these local temporal segments, the dynamics is unchanging. This local
consistency in dynamics holds for most real world scenarios (Nagabandi et al., 2018b;a). Yet, our
formalism can model the global changes in dynamics at test time, since we obtain a different instance
of the HiP-RSSM for each temporal segment based on the observed context set. We also provide
a detailed description of the multi-task dataset creation process in the appendix E and a pictorial
illustration in appendix D."
TRAINING HIP-RSSM FOR EPISODIC ADAPTATION TO CHANGING DYNAMICS,0.18441558441558442,"Batch Training. Let T ∈RB×N×D be the batch of local temporal segments with different dynam-
ics which we intend to model with the HiP-RSSM formalism. Given a target batch T, HiP-RSSM"
TRAINING HIP-RSSM FOR EPISODIC ADAPTATION TO CHANGING DYNAMICS,0.18701298701298702,Published as a conference paper at ICLR 2022
TRAINING HIP-RSSM FOR EPISODIC ADAPTATION TO CHANGING DYNAMICS,0.18961038961038962,"can be trained in a supervised fashion similar to popular recurrent architectures like LSTMs or
GRUs. However for each local temporal sequence t ∈T, over which the dynamics is being mod-
elled, we also input a set of the N previous interactions, which forms the context set C ∈RB×N×D
for inferring the latent task as explained in Section 2.2.1. Processing the context set C adds minimal
additional computational/memory constraints as we use a permutation invariant set encoder. The set
encoder allows parallelization in processing the context set as opposed to the recurrent processing
of target set."
TRAINING HIP-RSSM FOR EPISODIC ADAPTATION TO CHANGING DYNAMICS,0.19220779220779222,"The learnable parameters in the computation graph includes the locally linear transition model At,
the non-linear control factor b, the linear/non-linear latent task transformation model C, the transi-
tion noise Σtrans, along with the observation encoder, context encoder and the output decoder."
TRAINING HIP-RSSM FOR EPISODIC ADAPTATION TO CHANGING DYNAMICS,0.19480519480519481,"Loss Function. We optimize the root mean square error (RMSE) between the decoder output and
the ground truth states. As in Shaj et al. (2020) we use the differences to next state as our ground
truth states, as this results in better performance for dynamics learning especially at higher frequen-
cies. In principle, we could train on the Gaussian log-likelihood instead of the RMSE and hence
model the variances. Training on RMSE yields slightly better predictions and allows for a fair com-
parison with deterministic baselines which use the same loss like feed-forward neural networks,
LSTMs and meta-learnng algorithms such as MAML. Thus, we report results with the RMSE loss.
A probabilistic formulation for this loss function is provided in appendix B."
TRAINING HIP-RSSM FOR EPISODIC ADAPTATION TO CHANGING DYNAMICS,0.1974025974025974,"Gradients are computed using (truncated) backpropagation through time (BPTT) (Werbos (1990))
and clipped. We optimize the objective using the Adam (Kingma & Ba (2014)) stochastic gradient
descent optimizer with default parameters."
RELATED WORK,0.2,"3
RELATED WORK"
RELATED WORK,0.2025974025974026,"Deep State Space Models. Classical State-space models (SSMs) are popular due to their tractable
inference and interpretable predictions. However, inference and learning in SSMs with high dimen-
sional and large datasets are often not scalable. Recently, there have been several works on deep
SSMs that offer tractable inference and scalability to high dimensional and large datasets. Haarnoja
et al. (2016); Becker et al. (2019); Shaj et al. (2020) use neural network architectures based on
closed-form solutions of the forward inference algorithm on SSMs and achieve the state of the art
results in state estimation and dynamics prediction tasks. Krishnan et al. (2017); Karl et al. (2016);
Hafner et al. (2019) perform learning and inference on SSMs using variational approximations.
However, most of these recurrent state-space models assume that the dynamics is fixed, which is a
significant drawback since this is rarely the case in real-world applications such as robotics."
RELATED WORK,0.2051948051948052,"Recurrent Switching Dynamical Systems. Linderman et al. (2017); Becker-Ehmck et al. (2019);
Dong et al. (2020) tries to address the problem of changing/multi-modal dynamics by incorporat-
ing additional discrete switching latent variables. However, these discrete states make learning and
inference more involved. Linderman et al. (2017) uses auxiliary variable methods for approximate
inference in a multi-stage training process, while Becker-Ehmck et al. (2019); Dong et al. (2020)
uses variational approximations and relies on additional regularization/annealing to encourage dis-
crete state transitions. On the other hand Fraccaro et al. (2017) uses “soft” switches, which can be
interpreted as a SLDS which interpolate linear regimes continuously rather than using truly discrete
states. We take a rather different, simpler formalism for modelling changing dynamics by view-
ing it as a multi-task learning problem with a continuous hierarchical hidden parameter that model
the distribution over these tasks. Further our experiments in appendix C.1 show that our model
significantly outperfroms the soft switching baseline (Fraccaro et al., 2017)."
RELATED WORK,0.2077922077922078,"Hidden Parameter MDPs. Hidden Parameter Markov Decision Process (HiP-MDP) (Doshi-Velez
& Konidaris, 2016; Killian et al., 2016) address the setting of learning to solve tasks with similar,
but not identical, dynamics. In HiP-MDP formalism, the states are assumed to be fully observed.
However, we formalize the partially observable setting where we are interested in modelling the
dynamics in a latent space under changing scenarios. The formalism is critical for learning from high
dimensional observations and dealing with partial observability and missing data. The formalism can
be easily extended to HiP-POMDPs by including rewards into the graphical model 1, for planning
and control in the latent space (Hafner et al., 2019; Sekar et al., 2020). However this is left as a
future work."
RELATED WORK,0.21038961038961038,Published as a conference paper at ICLR 2022
RELATED WORK,0.21298701298701297,"No Imputation
50% Imputation"
RELATED WORK,0.21558441558441557,"HiP-RSSM
2.30 ± 0.043
2.47 ± 0.012
RKN
3.088 ± 0.046
3.223 ± 0.014
LSTM
3.108 ± 0.041
3.630 ± 0.097
GRU
3.287 ± 0.013
3.621 ± 0.047
FFNN
8.150 ± 0.047
-
NP
5.526 ± 0.030
-
MAML
7.314 ± 0.021
-"
RELATED WORK,0.21818181818181817,"(a) Pneumatic RMSE
 
10−3"
RELATED WORK,0.22077922077922077,"No Imputation
50 % Imputation"
RELATED WORK,0.22337662337662337,"HiP-RSSM
2.833 ± 0.024
2.843 ± 0.024
RKN
3.392 ± 0.062
3.398 ± 0.062
LSTM
3.503 ± 0.006
3.736 ± 0.062
GRU
3.407 ± 0.02
3.642 ± 0.153
FFNN
3.313 ± 0.018
-
NP
2.765 ± 0.004
-
MAML
3.202 ± 0.006
-"
RELATED WORK,0.22597402597402597,"(b) Franka RMSE
 
10−4"
RELATED WORK,0.22857142857142856,"No Imputation
50% Imputation"
RELATED WORK,0.23116883116883116,"HiP-RSSM
2.96 ± 0.212
6.15 ± 0.327
RKN
7.17 ± 0.017
14.66 ± 0.224
LSTM
9.14 ± 0.026
51.21 ± 0.431
GRU
9.216 ± 0.073
53.14 ± 0.242
FFNN
8.72 ± 0.021
-
NP
4.57 ± 0.013
-
MAML
5.04 ± 0.051
-"
RELATED WORK,0.23376623376623376,(c) Mobile Robot RMSE (10−5)
RELATED WORK,0.23636363636363636,"Table 1: Prediction Error in RMSE for (a) pneumatic muscular arm (4.1) and (b) Franka Arm manipulating
varying loads (4.2) for both fully observable and partially observable scenarios."
RELATED WORK,0.23896103896103896,"Meta Learning For Changing Dynamics. There exists a family of approaches that attempt online
model adaptation to changing dynamics scenarios via meta-learning (Nagabandi et al., 2018a;b).
They perform online adaptation on the parameters of the dynamics models through gradient de-
scent (Finn et al., 2017) from interaction histories. Our method fundamentally differs from these
approaches in the sense that we do not perform a gradient descent step at every time step during test
time, which is computationally impractical in modern robotics, where we often deal with high fre-
quency data. We also empirically show that our approach adapts better especially in scenarios with
non-markovian dynamics, a property that is often encountered in real world robots due to stiction,
slip, friction, pneumatic/hydraulic/cable-driven actuators etc. Sæmundsson et al. (2018); Achterhold
& Stueckler (2021) on the other hand learn context conditioned hierarchical dynamics model for
control in a formalism similar to HiP-MDPs. The former meta-learn a context conditioned gaussian
process while the later use a context conditioned determisitic GRU. Our method on the other hand
focuses on a principled probabilistic formulation and inference scheme for context conditioned re-
current state space models, which is critical for learning under partial observabilty/high dimensional
observations and with noisy and missing data."
EXPERIMENTS,0.24155844155844156,"4
EXPERIMENTS"
EXPERIMENTS,0.24415584415584415,"This section evaluates our approach on a diverse set of dynamical systems from the robotics domain
in simulations and real systems. We show that HiP-RSSM outperforms contemporary recurrent
state-space models (RSSMs) and recurrent neural networks (RNNs) by a significant margin under
changing dynamics scenarios. Further, we show that HiP-RSSM outperforms these models even un-
der situations with partial observability/ missing values. We also baseline our HiP-RSSM with con-
temporary multi-task models and improve performance, particularly in modelling non-Markovian
dynamics and under partial observability. Finally, the visualizations of the Gaussian latent task vari-
ables in HiP-RSSM demonstrates that they learn meaningful representations of the causal factors of
variations in dynamics in an unsupervised fashion."
EXPERIMENTS,0.24675324675324675,We consider the following baselines:
EXPERIMENTS,0.24935064935064935,"• RNNs - We compare our method to two widely used recurrent neural network architectures,
LSTMs (Hochreiter & Schmidhuber, 1997) and GRUs (Cho et al., 2014)."
EXPERIMENTS,0.2519480519480519,"• RSSMs - Among several RSSMs from the literature, we chose RKN (Becker et al., 2019)
as these have shown excellent performance for dynamics learning (Shaj et al., 2020) and
relies on exact inference as in our case."
EXPERIMENTS,0.2545454545454545,"• Multi Task Models - We also compare with state of the art multi-task learning models like
Neural Processes (NPs) and MAML (Nagabandi et al., 2018a). Both models receive the
same context information as in HiP-RSSM."
EXPERIMENTS,0.2571428571428571,"In case of recurrent models we replace the HiP-RSSM cell with a properly tuned LSTM, GRU and
RKN Cell respectively, while fixing the encoder and decoder architectures. For the NP baseline
we use the same context encoder and aggregation mechanism as in HiP-RSSM to ensure a fair
comparison. We create partially observable settings by imputing 50% of the observations during
inference. More details regarding the baselines and hyperparameters can be found in the appendix."
EXPERIMENTS,0.2597402597402597,Published as a conference paper at ICLR 2022
EXPERIMENTS,0.2623376623376623,"(a)
(b)"
EXPERIMENTS,0.2649350649350649,"Pneumatic
Mobile
Franka 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 RMSE"
EXPERIMENTS,0.2675324675324675,"Linear
Locally Linear
Non Linear"
EXPERIMENTS,0.2701298701298701,"(c)
Figure 3: (a) and (b) shows the tSNE (Van der Maaten & Hinton, 2008) plots of the latent task embeddings
produced from randomly sampled instances of HiP-RSSM for two different robots. (a) The wheeled robot
discussed in section 4.3 traversing terrains of varying slopes. The color coding indicates the average gradients
of the terrain for each of these instances. These can have either positive or negative values. (b) The Franka
manipulator with loads of varying weights attached to the end-effector. The color coding indicated weights
ranging from 0 to 3 kgs. (c) An ablation on the performance of different task transformation models discussed
in section 2.2.2."
SOFT ROBOT PLAYING TABLE TENNIS,0.2727272727272727,"4.1
SOFT ROBOT PLAYING TABLE TENNIS"
SOFT ROBOT PLAYING TABLE TENNIS,0.2753246753246753,"We first evaluate our model on learning the dynamics of a pneumatically actuated muscular robot.
This four Degree of Freedom (DoF) robotic arm is actuated by Pneumatic Artificial Muscles
(PAMs) (B¨uchler et al., 2016). The data consists of trajectories of hitting movements with vary-
ing speeds while playing table tennis (B¨uchler et al., 2020). This robot’s fast motions with high
accelerations are complicated to model due to hysteresis and hence require recurrent models (Shaj
et al., 2020)."
SOFT ROBOT PLAYING TABLE TENNIS,0.2779220779220779,"We show the prediction accuracy in RMSE in Table 5a. We observe that the HiP-RSSM can out-
perform the previous state of the art predictions obtained by recurrent models. Based on the domain
knowledge, we hypothesise that the latent context variable captures multiple unobserved causal fac-
tors of variation that affect the dynamics in the latent space, which are not modelled in contemporary
recurrent models. These causal factors could be, in particular, the temperature changes or the friction
due to a different path that the Bowden trains take within the robot. Disentangling and interpreting
these causal factors can be exciting and improve generalisation, but it is out of scope for the current
work. Further, we find that the multi-task models like NPs and MAML fail to model these dynamics
accurately compared to all the recurrent baselines because of the non-markovian dynamics resulting
from the high accelerations in this pneumatically actuated robot."
ROBOT MANIPULATION WITH VARYING LOADS,0.2805194805194805,"4.2
ROBOT MANIPULATION WITH VARYING LOADS"
ROBOT MANIPULATION WITH VARYING LOADS,0.2831168831168831,"We collected the data from a 7 DoF Franka Emika Panda manipulator carrying six different loads at
its end-effector. It involved a mix of movements of different velocities from slow to swift motions
covering the entire workspace of the robot. We chose trajectories with four different loads as training
set and evaluated the performance on two unseen weights, which results in a scenario where the
dynamics change over time. Here, the causal factor of variation in dynamics is the weights attached
to the end-effector and assumed to be unobserved."
ROBOT MANIPULATION WITH VARYING LOADS,0.2857142857142857,"We show the prediction errors in RMSE in Table 1c. HiP-RSSMs outperforms all recurrent state-
space models, including RKN and deterministic RNNs, in modelling these dynamics under fully
observable and partially observable conditions. The multi-task baselines of NPs and MAML per-
form equally well under full observability for this task because of the near Markovian dynamics of
Franka Manipulator, which often does not need recurrent models. However, HiP-RSSMs have an
additional advantage in that these are naturally suited for partially observable scenarios and can pre-
dict ahead in a compact latent space, a critical component for recent success in model-based control
and planning (Hafner et al., 2019)."
ROBOT LOCOMOTION IN TERRAINS OF DIFFERENT SLOPES,0.2883116883116883,"4.3
ROBOT LOCOMOTION IN TERRAINS OF DIFFERENT SLOPES"
ROBOT LOCOMOTION IN TERRAINS OF DIFFERENT SLOPES,0.2909090909090909,"Wheeled mobile robots are the most common types of robots being used in exploration of unknown
terrains where they may face uneven and challenging terrain. We set up an environment using a"
ROBOT LOCOMOTION IN TERRAINS OF DIFFERENT SLOPES,0.2935064935064935,Published as a conference paper at ICLR 2022 (a)
ROBOT LOCOMOTION IN TERRAINS OF DIFFERENT SLOPES,0.2961038961038961,"(b)
(c)
Figure 4: (a) Simulated environment of a Wheeled Robot traversing terrains of different slopes. (b) and (c)
shows how the one dimensional UMAP (McInnes et al., 2018) embedding of the inferred latent task variable
(top blue plots) changes at test time when an agent undergoes changes in its dynamics for the franka robot and
mobile robot respectively. An indicator of the Ground Truth (GT) Task (bottom red plots) variables are also
given. In case of the Franka Robot, the groundtruth (GT) tasks denotes the switching of dynamics between 0
kg (free motion) and 2.5 kg loads. In case of the mobile robot the groundtruth (GT) tasks denoted slopes of the
terrain."
ROBOT LOCOMOTION IN TERRAINS OF DIFFERENT SLOPES,0.2987012987012987,"Pybullet simulator (Coumans & Bai, 2016) where a four-wheeled mobile robot traverses an uneven
terrain of varying steepness generated by sinusoidal functions (Sonker & Dutta, 2020) as shown
in 4a. This problem is challenging due to the highly non-linear dynamics involving wheel-terrain
interactions. In addition, the varying steepness levels of the terrain results in a changing dynamics
scenario, which further increases the complexity of the task."
ROBOT LOCOMOTION IN TERRAINS OF DIFFERENT SLOPES,0.3012987012987013,"We show the prediction errors in RMSE in Table 1c. When most recurrent models, including RSSMs
and deterministic RNNs, fail to model these dynamics, HiP-RSSMs are by far the most accurate in
modelling these challenging dynamics in the latent space. Further, the HiP-RSSMs perform much
better than state of the art multi-task models like NPs and MAML."
ROBOT LOCOMOTION IN TERRAINS OF DIFFERENT SLOPES,0.3038961038961039,"We finally visualize the latent task representations using TSNE in Figure 3a. As seen from the plot,
those instances of the HiP-SSMs under similar terrain slopes get clustered together in the latent
task space, indicating that the model correctly identifies the causal effects in the dynamics in an
unsupervised fashion."
"VISUALIZING CHANGING HIDDEN PARAMETERS AT TEST TIME OVER TRAJECTORIES
WITH VARYING DYNAMICS",0.3064935064935065,"4.4
VISUALIZING CHANGING HIDDEN PARAMETERS AT TEST TIME OVER TRAJECTORIES
WITH VARYING DYNAMICS"
"VISUALIZING CHANGING HIDDEN PARAMETERS AT TEST TIME OVER TRAJECTORIES
WITH VARYING DYNAMICS",0.3090909090909091,"We finally perform inference using the trained HiP-RSSM in a multi-task / changing dynamics sce-
nario where the dynamics continuously changes over time. We use the inference procedure described
in appendix D based on a fluid definition for “task” as the local dynamics in a temporal segment.
We plot the global variation in the latent task variable captured by each instance of the HiP-RSSM
over these local temporal segments using the dimensionality reduction technique UMAP (McInnes
et al., 2018). As seen in figures 4b and 4c, the latent task variable captures these causal factors of
variations in an interpretable manner."
CONCLUSION,0.3116883116883117,"5
CONCLUSION"
CONCLUSION,0.3142857142857143,"We proposed HiP-RSSM, a probabilistically principled recurrent neural network architecture for
modelling changing dynamics scenarios. We start by formalizing a new framework, HiP-SSM, to
address the multi-task state-space modelling setting. HiP-SSM assumes a shared latent state and
action space across tasks but additionally assumes latent structure in the dynamics. We exploit the
structure of the resulting Bayesian network to learn a universal dynamics model with latent parame-
ter l via exact inference and backpropagation through time. The resulting recurrent neural network,
namely HiP-RSSM, learns to cluster SSM instances with similar dynamics together in an unsuper-
vised fashion. Our experimental results on various robotic benchmarks show that HiP-RSSMs sig-
nificantly outperform state of the art recurrent neural network architectures on dynamics modelling
tasks. We believe that modelling the dynamics in the latent space which disentangles the state, ac-
tion and task representations can benefit multiple future applications including planning/control in
the latent space and causal factor identification."
CONCLUSION,0.3168831168831169,Published as a conference paper at ICLR 2022
AKNOWLEDGEMENTS,0.3194805194805195,"6
AKNOWLEDGEMENTS"
AKNOWLEDGEMENTS,0.3220779220779221,"We thank Michael Volpp, Onur Celik, Marc Hanheide and the anonymous reviewers for valuable
remarks and discussions which greatly improved this paper. The authors acknowledge support by
the state of Baden-W¨urttemberg through bwHPC and the Lichtenberg high performance computer
of the TU Darmstadt. This work was supported by the EPSRC UK (project NCNR, National Centre
for Nuclear Robotics,EP/R02572X/1)."
REFERENCES,0.3246753246753247,REFERENCES
REFERENCES,0.32727272727272727,"Jan Achterhold and Joerg Stueckler.
Explore the context: Optimal data collection for context-
conditional dynamics models. In International Conference on Artificial Intelligence and Statistics,
pp. 3529–3537. PMLR, 2021."
REFERENCES,0.32987012987012987,"Philipp Becker, Harit Pandya, Gregor Gebhardt, Cheng Zhao, C James Taylor, and Gerhard Neu-
mann. Recurrent kalman networks: Factorized inference in high-dimensional deep feature spaces.
In International Conference on Machine Learning, pp. 544–552. PMLR, 2019."
REFERENCES,0.33246753246753247,"Philip Becker-Ehmck, Jan Peters, and Patrick Van Der Smagt. Switching linear dynamics for vari-
ational bayes filtering. In International Conference on Machine Learning, pp. 553–562. PMLR,
2019."
REFERENCES,0.33506493506493507,"Christopher M Bishop. Pattern recognition. Machine learning, 128(9), 2006."
REFERENCES,0.33766233766233766,"Dieter B¨uchler, Heiko Ott, and Jan Peters. A lightweight robotic arm with pneumatic muscles for
robot learning. In 2016 IEEE International Conference on Robotics and Automation (ICRA), pp.
4086–4092. IEEE, 2016."
REFERENCES,0.34025974025974026,"Dieter B¨uchler, Simon Guist, Roberto Calandra, Vincent Berenz, Bernhard Sch¨olkopf, and Jan
Peters.
Learning to play table tennis from scratch using muscular robots.
arXiv preprint
arXiv:2006.05935, 2020."
REFERENCES,0.34285714285714286,"Eduardo F Camacho and Carlos Bordons Alba.
Model predictive control.
Springer science &
business media, 2013."
REFERENCES,0.34545454545454546,"Kyunghyun Cho, Bart van Merri¨enboer, Dzmitry Bahdanau, and Yoshua Bengio. On the properties
of neural machine translation: Encoder–decoder approaches. In Proceedings of SSST-8, Eighth
Workshop on Syntax, Semantics and Structure in Statistical Translation, pp. 103–111. Association
for Computational Linguistics, October 2014."
REFERENCES,0.34805194805194806,"Erwin Coumans and Yunfei Bai.
Pybullet, a python module for physics simulation for games,
robotics and machine learning. 2016."
REFERENCES,0.35064935064935066,"Zhe Dong, Bryan Seybold, Kevin Murphy, and Hung Bui. Collapsed amortized variational inference
for switching nonlinear dynamical systems. In International Conference on Machine Learning,
pp. 2638–2647. PMLR, 2020."
REFERENCES,0.35324675324675325,"Finale Doshi-Velez and George Konidaris. Hidden parameter markov decision processes: A semi-
parametric regression approach for discovering latent task parametrizations. In IJCAI: proceed-
ings of the conference, volume 2016, pp. 1432. NIH Public Access, 2016."
REFERENCES,0.35584415584415585,"Chelsea Finn, Ian Goodfellow, and Sergey Levine. Unsupervised learning for physical interaction
through video prediction. Advances in neural information processing systems, 29:64–72, 2016."
REFERENCES,0.35844155844155845,"Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation
of deep networks. In International Conference on Machine Learning, pp. 1126–1135. PMLR,
2017."
REFERENCES,0.36103896103896105,"Marco Fraccaro, Simon Kamronn, Ulrich Paquet, and Ole Winther. A disentangled recognition and
nonlinear dynamics model for unsupervised learning. arXiv preprint arXiv:1710.05741, 2017."
REFERENCES,0.36363636363636365,"Marta Garnelo, Jonathan Schwarz, Dan Rosenbaum, Fabio Viola, Danilo J Rezende, SM Eslami,
and Yee Whye Teh. Neural processes. arXiv preprint arXiv:1807.01622, 2018."
REFERENCES,0.36623376623376624,Published as a conference paper at ICLR 2022
REFERENCES,0.36883116883116884,"Michel Gevers. Identification for control: From the early achievements to the revival of experiment
design. European journal of control, 11(4-5):335–352, 2005."
REFERENCES,0.37142857142857144,"Jonathan Gordon, John Bronskill, Matthias Bauer, Sebastian Nowozin, and Richard E Turner. Meta-
learning probabilistic inference for prediction. arXiv preprint arXiv:1805.09921, 2018."
REFERENCES,0.37402597402597404,"Tuomas Haarnoja, Anurag Ajay, Sergey Levine, and Pieter Abbeel. Backprop kf: Learning discrim-
inative deterministic state estimators. In Advances in neural information processing systems, pp.
4376–4384, 2016."
REFERENCES,0.37662337662337664,"Danijar Hafner, Timothy Lillicrap, Ian Fischer, Ruben Villegas, David Ha, Honglak Lee, and James
Davidson. Learning latent dynamics for planning from pixels. In International Conference on
Machine Learning, pp. 2555–2565. PMLR, 2019."
REFERENCES,0.37922077922077924,"James D Hamilton. State-space models. Handbook of econometrics, 4:3039–3080, 1994."
REFERENCES,0.38181818181818183,"Sepp Hochreiter and J¨urgen Schmidhuber.
Long short-term memory.
Neural Comput., 9(8):
1735–1780, November 1997. ISSN 0899-7667."
REFERENCES,0.38441558441558443,"Michael I Jordan. Graphical models. Statistical science, 19(1):140–155, 2004."
REFERENCES,0.38701298701298703,"Maximilian Karl, Maximilian Soelch, Justin Bayer, and Patrick Van der Smagt.
Deep varia-
tional bayes filters: Unsupervised learning of state space models from raw data. arXiv preprint
arXiv:1605.06432, 2016."
REFERENCES,0.38961038961038963,"Taylor Killian, George Konidaris, and Finale Doshi-Velez. Transfer learning across patient varia-
tions with hidden parameter markov decision processes. arXiv preprint arXiv:1612.00475, 2016."
REFERENCES,0.3922077922077922,"Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014."
REFERENCES,0.3948051948051948,"Daphne Koller and Nir Friedman. Probabilistic graphical models: principles and techniques. MIT
press, 2009."
REFERENCES,0.3974025974025974,"Daphne Koller, Nir Friedman, Lise Getoor, and Ben Taskar. Graphical models in a nutshell. Intro-
duction to statistical relational learning, 43, 2007."
REFERENCES,0.4,"Rahul Krishnan, Uri Shalit, and David Sontag. Structured inference networks for nonlinear state
space models.
In Proceedings of the AAAI Conference on Artificial Intelligence, volume 31,
2017."
REFERENCES,0.4025974025974026,"Scott Linderman, Matthew Johnson, Andrew Miller, Ryan Adams, David Blei, and Liam Paninski.
Bayesian learning and inference in recurrent switching linear dynamical systems. In Artificial
Intelligence and Statistics, pp. 914–922. PMLR, 2017."
REFERENCES,0.4051948051948052,"Lennart Ljung. System identification. In Signal analysis and prediction, pp. 163–173. Springer,
1998."
REFERENCES,0.4077922077922078,"Leland McInnes, John Healy, and James Melville. Umap: Uniform manifold approximation and
projection for dimension reduction. arXiv preprint arXiv:1802.03426, 2018."
REFERENCES,0.4103896103896104,"Anusha Nagabandi, Ignasi Clavera, Simin Liu, Ronald S Fearing, Pieter Abbeel, Sergey Levine,
and Chelsea Finn.
Learning to adapt in dynamic, real-world environments through meta-
reinforcement learning. arXiv preprint arXiv:1803.11347, 2018a."
REFERENCES,0.412987012987013,"Anusha Nagabandi, Chelsea Finn, and Sergey Levine. Deep online learning via meta-learning:
Continual adaptation for model-based rl. arXiv preprint arXiv:1812.07671, 2018b."
REFERENCES,0.4155844155844156,"Maria Isabel Ribeiro. Kalman and extended kalman filters: Concept, derivation and properties.
Institute for Systems and Robotics, 43:46, 2004."
REFERENCES,0.41818181818181815,"Steind´or Sæmundsson, Katja Hofmann, and Marc Peter Deisenroth. Meta reinforcement learning
with latent variable gaussian processes. arXiv preprint arXiv:1803.07551, 2018."
REFERENCES,0.42077922077922075,Published as a conference paper at ICLR 2022
REFERENCES,0.42337662337662335,"Thomas B Sch¨on, Adrian Wills, and Brett Ninness. System identification of nonlinear state-space
models. Automatica, 47(1):39–49, 2011."
REFERENCES,0.42597402597402595,"Ramanan Sekar, Oleh Rybkin, Kostas Daniilidis, Pieter Abbeel, Danijar Hafner, and Deepak Pathak.
Planning to explore via self-supervised world models. In International Conference on Machine
Learning, pp. 8583–8592. PMLR, 2020."
REFERENCES,0.42857142857142855,"Vaisakh Shaj, Philipp Becker, Dieter Buchler, Harit Pandya, Niels van Duijkeren, C James Tay-
lor, Marc Hanheide, and Gerhard Neumann. Action-conditional recurrent kalman networks for
forward and inverse dynamics learning. arXiv preprint arXiv:2010.10201, 2020."
REFERENCES,0.43116883116883115,"Rohit Sonker and Ashish Dutta. Adding terrain height to improve model learning for path tracking
on uneven terrain by a four wheel robot. IEEE Robotics and Automation Letters, 6(1):239–246,
2020."
REFERENCES,0.43376623376623374,"Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine
learning research, 9(11), 2008."
REFERENCES,0.43636363636363634,"Michael Volpp, Fabian Fl¨urenbrock, Lukas Grossberger, Christian Daniel, and Gerhard Neumann.
Bayesian context aggregation for neural processes.
In International Conference on Learning
Representations, 2020."
REFERENCES,0.43896103896103894,"Eric A Wan and Rudolph Van Der Merwe. The unscented kalman filter for nonlinear estimation.
In Proceedings of the IEEE 2000 Adaptive Systems for Signal Processing, Communications, and
Control Symposium (Cat. No. 00EX373), pp. 153–158. Ieee, 2000."
REFERENCES,0.44155844155844154,"Paul J Werbos. Backpropagation through time: what it does and how to do it. Proceedings of the
IEEE, 78(10):1550–1560, 1990."
REFERENCES,0.44415584415584414,"Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan Salakhutdinov, and
Alexander Smola. Deep sets. arXiv preprint arXiv:1703.06114, 2017."
REFERENCES,0.44675324675324674,Published as a conference paper at ICLR 2022
REFERENCES,0.44935064935064933,"A
PROOF FOR GAUSSIAN IDENTITY 1"
REFERENCES,0.45194805194805193,"This section provides a proof for Gaussian Identity 1. First we derive an expression for the joint
distribution p(u, v, y).
Gaussian Identity 2. If u ∼N(µu + b, Σu) and v ∼N(µv, Σv) are normally distributed inde-
pendent random variables and if conditional distribution p(y|u, v) = N(Au + b + Bv, Σ), the
joint distribution has an expression as follows:
 u
v
y ! ∼N  "
REFERENCES,0.45454545454545453,"µu
µv
Aµu + b + Bµv ! , "
REFERENCES,0.45714285714285713,"
Σu
0
ΣuA⊤"
REFERENCES,0.4597402597402597,"0
Σv
ΣvB⊤"
REFERENCES,0.4623376623376623,"AΣ⊤
u
BΣ⊤
v
AΣuA⊤+ BΣvB⊤+ Σ    "
REFERENCES,0.4649350649350649,Proof for Identity 2
REFERENCES,0.4675324675324675,Let displacement of a variable u be denoted by ∆u = u −⟨u⟩.
REFERENCES,0.4701298701298701,"Since u and v are independent, covariances

∆u∆v⊤
= 0."
REFERENCES,0.4727272727272727,"We can write y = Au+b+Bv+ϵ, where ϵ ∼N(0, Σ) and b is a constant. Then we have covariance

∆u∆y⊤
=

∆u(A∆u + B∆v + ∆ϵ)⊤
=

∆u∆u⊤
A⊤+

∆u∆v⊤
B⊤+

∆u∆ϵ⊤
.
Since

∆u∆v⊤
=

∆u∆ϵ⊤
= 0 we therefore have

∆u∆y⊤
= ΣuA⊤."
REFERENCES,0.4753246753246753,"The derivations for covariances

∆v∆y⊤
follows similarly and the corresponding covariance has
the expression,

∆v∆y⊤
= ΣvB⊤."
REFERENCES,0.4779220779220779,"Similarly,

∆y∆y⊤
=

(A∆u + B∆v + ∆ϵ)(A∆u + B∆v + ∆ϵ)⊤
= A

∆u∆u⊤
A⊤+
B

∆v∆v⊤
B⊤+

∆ϵ∆ϵ⊤
= AΣuA⊤+ BΣvB⊤+ Σ. The result follows.
Gaussian Identity 3 (Gaussian Marginalization). If
 u
v
y ! ∼N  "
REFERENCES,0.4805194805194805,"µu
µv
µz ! , "
REFERENCES,0.4831168831168831,"
Σuu
Σuv
Σuy
Σ⊤
uv
Σvv
Σvy
Σ⊤
uy
Σ⊤
vy
Σyy    "
REFERENCES,0.4857142857142857,"then marginal over y is given as p(y) =
R"
REFERENCES,0.4883116883116883,"u,v p(y|u, v)p(u)p(v)dudv = N (µy, Σyy)"
REFERENCES,0.4909090909090909,Proof For Identity 3
REFERENCES,0.4935064935064935,"We refer to Bishop (2006) for the derivation, which requires calculation of the Schur complement
as well as completing the square of the Gaussian p.d.f. to integrate out the variable. The given
derivation (Bishop, 2006) for two variable multivariate Gaussians can be extended to 3 variable case
WLOG."
REFERENCES,0.4961038961038961,Proof For Identity 1 is immediate from Identity 2 and Identity 3.
REFERENCES,0.4987012987012987,"B
PROBABILISTIC FORMULATION OF HIP-RSSM TRAINING OBJECTIVE"
REFERENCES,0.5012987012987012,"The training objective for the HiP-RSSM involves maximizing the posterior predictive log-
likelihood given below: T
X t=1 N
X"
REFERENCES,0.5038961038961038,"b=1
log p(ˆob
t+1|Cl, ob
1:t) = T
X t=1 N
X"
REFERENCES,0.5064935064935064,"b=1
log
Z
p(ˆob
t+1|zb
t+1)p(zb
t+1|om
1:t, Cl)dzb
t+1.
(4)"
REFERENCES,0.509090909090909,"Here, for any time t, ˆot+1 are the ground truth observations for the next time step and the latent state
prior p(zb
t+1|om
1:t, Cl) as discussed in the Section 2.2.2, have closed form solutions. We approxi-
mate the objective in Eq.(4) using a deterministic variational approximation, similar to Becker et al.
(2019)."
REFERENCES,0.5116883116883116,"We employ a Gaussian approximation of the posterior predictive log likelihood of the form
p(ˆob
t+1|Cl, ob
1:t)
≈
N(µob
t+1, diag((σob
t+1)2)).
Here µob
t+1
=
decµ(zb
t+1) and σob
t
="
REFERENCES,0.5142857142857142,"decΣ(Σb
t+1)), where decµ() and decΣ() denote the parts of the output decoder that are responsi-
ble for decoding the latent means and latent variances respectively. This decoder can be interpreted"
REFERENCES,0.5168831168831168,Published as a conference paper at ICLR 2022
REFERENCES,0.5194805194805194,"0
500
1000
1500
2000
2500
epochs 0 2 4 6 8 10 12 14 rmse"
REFERENCES,0.522077922077922,"HiP-RSSM
LSTM
RKN
Soft-Switching (a)"
STEP,0.5246753246753246,"1 Step
10 Step
20 Step
30 Step
50 Step
Number Of Steps 20 40 60 80 100"
STEP,0.5272727272727272,RMSE(1e-5)
STEP,0.5298701298701298,"HiP-RSSM
RKN
LSTM
Soft Switching"
STEP,0.5324675324675324,"(b)
Figure 5: Comparison of different algorithms for Wheeled Mobile Robot in terms of (a) moving average
of decoder error in normalized RMSE for the test set, plotted against training epochs (b) multi-step ahead
prediction error in RMSE."
STEP,0.535064935064935,"as a “moment matching network”, computing the moments of ob
t given the moments of zb
t (Volpp
et al., 2020; Becker et al., 2019). This allows to evaluate an approximation to the objective in a
deterministic manner."
STEP,0.5376623376623376,"Alternatively, we could ignore the variances and only focus on the mean predictions by training our
model with a RMSE loss. Training on RMSE yields slightly better predictions and allows for a fair
comparison with deterministic baselines (Feed Forward NN, LSTM, GRU, MAML etc) and hence
we report results with the RMSE loss."
STEP,0.5402597402597402,"C
ADDITIONAL EXPERIMENTS"
STEP,0.5428571428571428,"C.1
COMPARISON TO SOFT SWITCHING BASELINE"
STEP,0.5454545454545454,"We also implement a soft-switching baseline similar to Fraccaro et al. (2017), where a soft mix-
ture of dynamics is implemented in the latent transition dynamics (Kalman time update). Similar to
Fraccaro et al. (2017), we now globally learn K constant transition matrices A(k) and control matri-
ces B(k). An interpolation is done between these using a “dynamics parameter network” (Fraccaro
et al., 2017) αt = αt (w0:t−1). The dynamics parameter network is implemented with a recurrent
neural network with LSTM cells that takes at each time step the mean of the encoded observation
wt as input and recurses dt = LSTM (wt−1, dt−1) and αt = softmax (dt). The output of the
dynamics parameter network is weights that sum to one, PK
k=1 α(k)
t
(w0:t−1) = 1. These weights
choose and interpolate between K different operating modes: At = K
X"
STEP,0.548051948051948,"k=1
α(k)
t
(w0:t−1) A(k),
Bt = K
X"
STEP,0.5506493506493506,"k=1
α(k)
t
(w0:t−1) B(k)"
STEP,0.5532467532467532,"Authors interpret the weighted sum as a soft mixture of K different Linear Gaussian SSMs whose
time-invariant matrices are combined using the time varying weights αt. In practice, each of the K
sets

A(k), B(k)	
models different/changing dynamics, that will dominate when the corresponding
α(k)
t
is high."
STEP,0.5558441558441558,"Figure 5 compares HiP-RSSM with different recurrent architectures including the soft-switching
baseline. As seen in figure 5, HiP-RSSM clearly outperforms the soft-switching baseline both in
terms of convergence speed and also mult-step ahead predictions. More details regarding the multi-
step ahead training procedure can be found in appendix C.3."
STEP,0.5584415584415584,"C.2
ABLATION ON CONTEXT ENCODER"
STEP,0.561038961038961,"In table 2, we report the details of evaluating our bayesian aggregation based context set en-
coder (discussed in 2.2.1) against the a causal / recurrent encoder that takes into account the
temporal structure of the context data. We used a probabilistic recurrent encoder (Becker et al.,"
STEP,0.5636363636363636,Published as a conference paper at ICLR 2022
STEP,0.5662337662337662,"2019), whose mean and variance from the last time step is used to infer the posterior latent task
distribution p(l|Cl) = N(µl, diag(σ2
l )). The dimensions of latent task parameters obtained from
both the set and recurrent encoders are kept the same (60)."
STEP,0.5688311688311688,"Table 2: Comparison between the permutation invariant set en-
coder and recurrent encoder. The performance is measured in
terms of prediction RMSE (10-5) and mean of the training time
per epoch (in seconds) over 5 runs."
STEP,0.5714285714285714,"No Imputation RMSE
50% Imputation RMSE
Training Time Per Epoch"
STEP,0.574025974025974,"Set Encoder
2.96 ± 0.212
6.15 ± 0.327
6.71
Recurrent Encoder
5.10 ± 0.041
10.12 ± 0.112
14.13"
STEP,0.5766233766233766,"The reported experiments are conducted
on data from wheeled mobile robot dis-
cussed in section 4.3. As reported in Ta-
ble 2 the permutation invariant set en-
coder outperforms the recurrent encoder
by a good margin in terms of prediction
accuracy for both fully and partially ob-
servable scenarios. Additionally the set
encoder is far more efficient in terms of
computational time required for training
as seen from the time taken per epoch for each of these cases."
STEP,0.5792207792207792,"C.3
MULTI-STEP AHEAD PREDICTIONS"
STEP,0.5818181818181818,"In figure 5b, we compare the results of multi-step ahead predictions for upto 50 steps of HiP-RSSM
with recurrent baselines like RKN(Becker et al., 2019) and LSTM. Inorder to train the recurrent
models for multi step ahead predictions, we removed three-quarters of the observations from the
temporal sequence and tasked the models with imputing those missing observations, only based on
the knowledge of available actions/control commands, i.e., we train the models to perform action
conditional future predictions to impute missing observations. The imputation employs the model
for multi-step ahead predictions in a convenient way (Shaj et al., 2020). One could instead also go
for a dedicated multi-step loss function as in approaches like Finn et al. (2016)."
STEP,0.5844155844155844,"As seen in figure 5b, HiP-RSSM clearly outperforms contemporary recurrent models for multi-step
ahead prediction tasks since it takes into account additional causal factors of variation (slopes of the
terrain for this robot) in the latent dynamics in an unsupervised manner."
STEP,0.587012987012987,"D
HIP-RSSM DURING TEST TIME / INFERENCE"
STEP,0.5896103896103896,"We perform inference using HiP-RSSM at test time on a trajectory with varying dynamics using
algorithm 1. A pictorial representation of the same is given in the figure 6. We use this inference
scheme to visualize how the latent variable l, that describe different instances of a HiP-RSSM over
different temporal segments, evolve at a global level. The visualizations are reported in figures 4b
and 4c in the main text."
STEP,0.5922077922077922,"Algorithm 1: HiP-RSSM Test Time Inference
Required: Trained HiP-RSSM Model
Required: A time series τ of length K >> N
Divide the time series τ into non-overlapping windows Tl of length N. Let
T = {T1, T2, T3, ., ., .} be the ordered list of all temporal segments, sorted in the ascending
order of time of occurrence.
foreach each time window Tl ∈T do"
STEP,0.5948051948051948,1. maintain a context set Cl consisting of N previous interactions;
STEP,0.5974025974025974,2. infer posterior latent task variable p(l|Cl) using context update stage as in section 2.2.1;
STEP,0.6,"3. using the posterior over latent task variable l|Cl and observations in sequence Tl to
perform sequential Bayesian inference over the state space model using Kalman
observation update (2.2.3) and task conditional Kalman time update; (2.2.2) end"
STEP,0.6025974025974026,Published as a conference paper at ICLR 2022
STEP,0.6051948051948052,"- Context Set
 - Target Time Series"
STEP,0.6077922077922078,Time Series With Changing Dynamics
STEP,0.6103896103896104,"Locally consistent dynamics 
modelled as a HiP-RSSM instance
Figure 6: HiP-RSSM Inference Under Changing Dynamics Scenarios"
STEP,0.612987012987013,"E
MULTI-TASK DATASET CREATION"
STEP,0.6155844155844156,"Algorithm 2: Multi Task Dataset Creation For Training HiP-RSSM
Required:A set S of trajectories of changing dynamics
D ←ϕ
foreach each trajectory τ ∈S do"
STEP,0.6181818181818182,"1. divide the trajectory τ into non-overlapping windows Tl of length N. Let
T = {T1, T2, T3, ., ., .} be the list of all temporal segments/time-series.
foreach each time window Tl ∈T do"
STEP,0.6207792207792208,"(a) maintain a context set Cl consisting of N previous interactions;
(b) update D ←D ∪{Cl, Tl} end"
STEP,0.6233766233766234,"end
Output: Output D consisting of batch of context and target sets."
STEP,0.625974025974026,"F
IMPLEMENTATION DETAILS"
STEP,0.6285714285714286,"F.1
CONTEXT SET ENCODER AND LATENT TASK REPRESENTATION"
STEP,0.6311688311688312,"The HiP-RSSM maps a set of previous interaction histories, {ol
t,n, al
t,n, ol
t+1,n}N
n=1, to a set of
latent features and an estimate of uncertainty in those features, {rl
n, (σl
n)2}N
n=1, using a context
encoder. We use a feed-forward neural network as the encoder in all of our experiements since we
deal with high dimensional vectors as our observations. However, depending upon the nature of
observations, we could use different encoder architectures.
The set of latent features and uncertainties, {rl
n,
 
σl
n
2}N
n=1, are further aggregated in a probabilis-
tically principled manner using bayesian aggregation operator discussed in 2.2.1 to get a gaussian
latent task variable, with a mean (µl) and diagonal covariance (σl). Intuitively the context encoder
learns to weight the contribution from each observation in the context set based on bayesian prinici-
ples and emits a probabilistic representation of the latent task."
STEP,0.6337662337662338,"F.2
OBSERVATION ENCODER AND LATENT STATE REPRESENTATION"
STEP,0.6363636363636364,"HiP-RSSM transforms the observations at each time step ot to a latent space using an encoder
network which emits latent features wt and an estimate of the uncertainty in those features via a
variance vector σobs
t
."
STEP,0.638961038961039,"The probabilistic recurrent module uses a latent state vector zt and corresponding covariance Σt
whose transitions are governed by the update rules in the HiP-RSSM cell. The latent state vector
zt has been designed to contain two conceptual parts, a vector pt for holding information that
can directly be extracted from the observations and a vector mt to store information inferred over
time, e.g., velocities. The former is referred to as the observation or upper part and the latter as the
memory or lower part of the latent state as in Becker et al. (2019). For an ordinary dynamical system
and images as observations the former may correspond to positions while the latter corresponds to
velocities. The corresponding posterior and prior covariance matrices Σ+
t and Σ−
t have a chosen
factorized representation to yield simple Kalman updates, i.e.,"
STEP,0.6415584415584416,Published as a conference paper at ICLR 2022
STEP,0.6441558441558441,"Σt =
Σu
t
Σs
t
Σs
t
Σl
t 
,"
STEP,0.6467532467532467,"where each of Σu
t , Σs
t, Σl
t ∈Rm×m is a diagonal matrix. The vectors σu
t , σl
t and σs
t denote the
vectors containing the diagonal values of those matrices. This structure with Σs
t ensures that the
correlation between the memory and the observation parts are not neglected as opposed to the case
of designing Σt as a diagonal covariance matrix. This representation was exploited to avoid the
expensive and numerically problematic matrix inversions involved in the KF equations as shown
below."
STEP,0.6493506493506493,"F.3
LOCALLY LINEAR TRANSITION MODEL"
STEP,0.6519480519480519,"The state transitions in the time update stage (section 2.2.2) of the HiP-RSSM Cell is governed
by a locally linear transition model as in Becker et al. (2019). To obtain a locally linear transition
model, the HiP-RSSM gloablly learns K constant transition matrices A(k) and interpolate between
them using state dependent coefficients α(k)(z+
t ), i.e., At = PK
k=0 α(k)(z+
t )A(k), where z+
t is
the mean of the posterior distribution at time step t. So we locally linearize At around the posterior
mean, which can be interpreted as equivalent to what an EKF do with a Jacobian. A small neural
network with softmax output is used to learn α(k)."
STEP,0.6545454545454545,"F.4
CONTROL MODEL"
STEP,0.6571428571428571,"To achieve action conditioning within the recurrent cell, we include a control model b(at) in addition
to the locally linear transition model At. b(at) = f(at), where f(.) can be any non-linear function
approximator. We use a multi-layer neural network regressor with ReLU activations (Shaj et al.,
2020)."
STEP,0.6597402597402597,"F.5
LATENT TASK TRANSFORMATION MODEL"
STEP,0.6623376623376623,"To achieve latent task conditioning within the recurrent cell, we include a task transformation model
(c), in addition to the locally linear transition model At and control model b in the time update
stage (section 2.2.2). Though in section 2.2.2, we used the notation for a linear task transformation
matrix, C, to motivate the additive interaction of latent task variables, µl and σl in the latent space,
the task transformation function can be designed in several ways, i.e.:"
STEP,0.6649350649350649,"(i) Linear: c = C, where C is a linear transformation matrix. The corresponding time update
equations are given below:"
STEP,0.6675324675324675,"z−
t = At−1z+
t−1 + b(at) + Cµl,"
STEP,0.6701298701298701,"Σ−
t = At−1Σ+
t−1AT
t−1 + C(I · σl)CT + Σtrans."
STEP,0.6727272727272727,"(ii) Locally-Linear: c = Ct, where Ct = PK
k=0 β(k)(zt)C(k) is a linear combination of k
linear control models C(k). A small neural network with softmax output is used to learn
β(k). The corresponding time update equations are given below:"
STEP,0.6753246753246753,"z−
t = At−1z+
t−1 + b(at) + Ctµl,"
STEP,0.6779220779220779,"Σ−
t = At−1Σ+
t−1AT
t−1 + Ct(I · σl)CT
t + Σtrans."
STEP,0.6805194805194805,"(iii) Non-Linear: c = f, where f(.) can be any non-linear function approximator. We use
a multi-layer neural network regressor with ReLU activations, which transforms the latent
task moments µl and σl directly into the latent space of the state space model via additive
interactions. The corresponding time update equations are given below:"
STEP,0.6831168831168831,"z−
t = At−1z+
t−1 + b(at) + f(µl),"
STEP,0.6857142857142857,"Σ−
t = At−1Σ+
t−1AT
t−1 + f(σl) + Σtrans."
STEP,0.6883116883116883,Published as a conference paper at ICLR 2022
STEP,0.6909090909090909,"In our ablation study (Figure 3c), for the linear and locally linear task transformation models, we
assume that the dimension of the latent context variable l and the latent state space zt are equal. This
allows us to work with square matrices which are more convenient. For the non-linear transformation
we are free to choose the size of the latent context variable. However for a fairer comparison we
keep the dimension of latent task variable to be similar in all three cases. We choose the non-linear
task transformation model in HiP-RSSM architecture as this gave the best performance in practice."
STEP,0.6935064935064935,"F.6
OBSERVATION MODEL"
STEP,0.6961038961038961,"The latent state space Z = Rn of the HiP-RSSM is related to the observation space W by the linear
latent observation model H =
 Im
0m×(n−m)

, i.e., w|z ∼N(Hz, Σobs) with w ∈W and
z ∈Z, where Im denotes the m × m identity matrix and 0m×(n−m) denotes a m × (n −m) matrix
filled with zeros. Typically, m is set to n/2. This corresponds to the assumption that the first half
of the state can be directly observed while the second half is unobserved and contains information
inferred over time (Becker et al. (2019))."
STEP,0.6987012987012987,"F.7
OBSERVATION UPDATE STEP"
STEP,0.7012987012987013,"The observation update discussed in section 2.2.3 involves computing the Kalman gain matrix Qt,
which requires computationally expensive matrix inversions that are difficult to backpropagate, at
least for high dimensional latent state representations. However, the choice of a locally linear tran-
sition model, the factorized covariance Σt, and the special observation model simplify the Kalman
update to scalar operations as shown below. As the network is free to choose its own state rep-
resentation, it finds a representation where such assumptions works well in practice Becker et al.
(2019)."
STEP,0.7038961038961039,"Similar to the state, the Kalman gain matrix Qt is split into an upper Qu
t and a lower part
Ql
t. Both Qu
t and Ql
t are squared matrices. Due to the simple latent observation model H =
 Im
0m×(n−m)

and the factorized covariances, all off-diagonal entries of Qu
t and Ql
t are zero
and one can again work with vectors representing the diagonals, i.e., qu
t and ql
t. Those are obtained
by"
STEP,0.7064935064935065,"qu
t = σu,−
t
⊘
 
σu,−
t
+ σobs
t
"
STEP,0.7090909090909091,"ql
t = σs,−
t
⊘
 
σu,−
t
+ σobs
t

,"
STEP,0.7116883116883117,"where ⊘denotes an elementwise vector division. The update equation for the mean therefore sim-
plifies to"
STEP,0.7142857142857143,"z+
t = z−
t +
 qu
t
ql
t"
STEP,0.7168831168831169,"
⊙

wt −zu,−
t
wt −zu,−
t 
,"
STEP,0.7194805194805195,"where ⊙denotes the elementwise vector product. The update equations for the individual parts of
covariance are given by"
STEP,0.7220779220779221,"σu,+
t
= (1m −qu
t ) ⊙σu,−
t
,"
STEP,0.7246753246753247,"σs,+
t
= (1m −qu
t ) ⊙σs,−
t
,"
STEP,0.7272727272727273,"σl,+
t
= σl,−
t
−ql
t ⊙σs,−
t
,"
STEP,0.7298701298701299,where 1m denotes the m dimensional vector consisting of ones.
STEP,0.7324675324675325,"G
ROBOTS AND DATA"
STEP,0.7350649350649351,"The experiments are performed on data from two different real robots. The details of robots, data
and data preprocessing is explained below:"
STEP,0.7376623376623377,"G.1
MUSCULOSKELETAL ROBOT ARM"
STEP,0.7402597402597403,"Observation and Data Set: For this soft robot we have 4 dimensional observation inputs(joint
angles) and 8 dimensional action inputs(pressures). We collected the data of a four DoF robot"
STEP,0.7428571428571429,Published as a conference paper at ICLR 2022
STEP,0.7454545454545455,"Figure 7: The experiments are performed on data from robots with different actuator dynamics. From left to
right these include: Pneumatically actuated artificial muscles (B¨uchler et al., 2016), electrically actuated Franka
Emika Panda Robotic Arm."
STEP,0.7480519480519481,"actuated by Pneumatic Artificial Muscles (PAMs). The robot arm has eight PAMs in total with
each DoF actuated by an antagonistic pair. The robot arm reaches high joint angle accelerations of
up to 28, 000deg/s2 while avoiding dangerous joint limits thanks to the antagonistic actuation and
limits on the air pressure ranges. The data consists of trajectories collected while training with a
model-free reinforcement learning algorithm to hit balls while playing table tennis. We sampled
the data at 100Hz. The hysteresis associated with the pneumatic actuators used in this robot is
challenging to model and is relevant to the soft robotics in general."
STEP,0.7506493506493507,"Training Procedure: For the fully observable case, we trained HiP-RSSM for one-step ahead pre-
diction using an RMSE loss. For partially observable case, during training, we randomly removed
half of the observations from the sequences and tasked the models with imputing those missing
states, only based on the knowledge of available actions/control commands, i.e., we train the models
to perform action conditional future predictions to impute missing states. The imputation employs
the model for multi-step ahead predictions in a convenient way.
Other recurrent baselines (RKN, LSTM, GRU) are trained in a similar fashion except that, we don’t
maintain a context set of interaction histories during training/inference."
STEP,0.7532467532467533,"G.2
FRANKA EMIKA PANDA ROBOT ARM"
STEP,0.7558441558441559,"Observation and Data Set: We collected the data from a 7 DoF Franka Emika Panda manipulator
during free motion and while manipulating loads with weights 0kg (free motion), 0.5 kg, 1 kg, 1.5
kg, 2 kg and 2.5 kg. Data is sampled at high frequencies (1kHz). The training trajectories were
motions with loads 0kg(free motion), 1kg, 1.5kg, 2.5 kgs, while the testing trajectories contained
motions with loads of 0.5kg and 2 kgs. The observations for the forward model consist of the seven
joint angles in radians, and the corresponding actions were joint Torques in Nm. We divide the data
into sequences of length 600 while training the recurrent models for forward dynamics, with 300
time-steps (corresponding to 300 milli-seconds) used as context set and rest 300 is used for the
recurrent time-series modelling."
STEP,0.7584415584415585,"Training Procedure: For the fully observable case, we trained HiP-RSSM for one-step ahead pre-
diction using an RMSE loss. Similar to the training procedure for partially observable case as in
G.1, during training we randomly removed half of the observations(joint angles) from the sequences
and tasked the models with imputing those missing observations, only based on the knowledge of
available actions/control commands.
Other recurrent baselines (RKN, LSTM, GRU) are trained in a similar fashion except that, we dont
maintain a context set of interaction histories during training/inference."
STEP,0.7610389610389611,"G.3
WHEELED MOBILE ROBOT"
STEP,0.7636363636363637,"Observation and Data Set: We collected 50 random trajectories from a Pybullet simulator a
wheeled mobile robot traversing terrain with sinusoidal slopes. Data is sampled at high frequen-
cies (500Hz). 40 out of the 50 trajectories were used for training and the rest 10 for testing. The
observations consists of parameters which completely describe its location and orientation of the"
STEP,0.7662337662337663,Published as a conference paper at ICLR 2022
STEP,0.7688311688311689,robot. The observation of the robot at any time instance t consists of the following features:.
STEP,0.7714285714285715,"ot = [x, y, z, cos(α), sin(α), cos(β)
sin(β), cos(γ), sin(γ)]"
STEP,0.7740259740259741,"where, x, y, z - denote the global position of the Center of Mass of he robot, α, β, γ−Roll, pitch
and yaw angles of the robot respectively, in the global frame of reference (Sonker & Dutta, 2020).
We divide the data into sequences of length 300 while training the recurrent models for forward
dynamics, with 150 time-steps (corresponding to 300 milli-seconds) used as context set and rest
150 is used for the recurrent time-series modelling."
STEP,0.7766233766233767,"Training Procedure: For the fully observable case, we trained HiP-RSSM for one-step ahead pre-
diction using an RMSE loss. Similar to the training procedure for partially observable case as in
G.1, during training we randomly removed half of the observations from the sequences and tasked
the models with imputing those missing observations, only based on the knowledge of available
actions/control commands.
Other recurrent baselines (RKN, LSTM, GRU) are trained in a similar fashion except that, we dont
maintain a context set of interaction histories during training/inference."
STEP,0.7792207792207793,"H
HYPERPARAMETERS"
STEP,0.7818181818181819,"H.1
PNEUMATIC MUSCULOSKELTAL ROBOT ARM"
STEP,0.7844155844155845,Recurrent Models
STEP,0.787012987012987,"Hyperparameter
HiP-RSSM
RKN
LSTM
GRU
Learning Rate
8e-4
8e-4
1e-3
1e-3
Latent Observation Dimension
15
15
15
15
Latent State Dimension
30
30
75
75
Latent Task Dimension
30
-
-
-"
STEP,0.7896103896103897,Context Encoder (HiP-RSSM): 1 fully connected + linear output (elu + 1)
STEP,0.7922077922077922,"• Fully Connected 1: 240, ReLU"
STEP,0.7948051948051948,"Observation Encoder (HiP-RSSM,RKN,LSTM,GRU): 1 fully connected + linear output (elu + 1)"
STEP,0.7974025974025974,"• Fully Connected 1: 120, ReLU"
STEP,0.8,"Observation Decoder (HiP-RSSM,RKN,LSTM): 1 fully connected + linear output:"
STEP,0.8025974025974026,"• Fully Connected 1: 120, ReLU"
STEP,0.8051948051948052,"Transition Model (HiP-RSSM,RKN): number of basis: 15"
STEP,0.8077922077922078,• α(zt): No hidden layers - softmax output
STEP,0.8103896103896104,"Control Model (HiP-RSSM,RKN): 3 fully connected + linear output"
STEP,0.812987012987013,"• Fully Connected 1: 120, ReLU
• Fully Connected 2: 120, ReLU
• Fully Connected 3: 120, ReLU"
STEP,0.8155844155844156,"Neural Process (NP) Baseline
Latent Task Dimension: 30
Learning Rate: 9e-4
Optimizer Used: Adam Optimizer"
STEP,0.8181818181818182,Context Encoder : 1 fully connected + linear output (elu + 1)
STEP,0.8207792207792208,Published as a conference paper at ICLR 2022
STEP,0.8233766233766234,"• Fully Connected 1: 240, ReLU"
STEP,0.825974025974026,• Linear output: 30
STEP,0.8285714285714286,Decoder 3 fully connected + linear output
STEP,0.8311688311688312,"• Fully Connected 1: 512, ReLU"
STEP,0.8337662337662337,"• Fully Connected 2: 240, ReLU"
STEP,0.8363636363636363,"• Fully Connected 2: 120, ReLU"
STEP,0.8389610389610389,"FFNN Baseline
Learning Rate: 1e-3
Optimizer Used: Adam Optimizer"
STEP,0.8415584415584415,2 fully connected + linear output
STEP,0.8441558441558441,"• Fully Connected 1: 6000, ReLU"
STEP,0.8467532467532467,"• Fully Connected 2: 3000, ReLU"
STEP,0.8493506493506493,"MAML Baseline
Meta Optimizer Learning Rate: 3e-3
Inner Optimizer Learning Rate: 0.4
Number Of Gradient Steps: 1
Optimizer Used: Adam Optimizer (Meta Update) and SGD Optimizer (Inner Update)
Model
Feed Forward Neural Network with 3 fully connected + linear output"
STEP,0.8519480519480519,"• Fully Connected 1: 512, ReLU"
STEP,0.8545454545454545,"• Fully Connected 2: 240, ReLU"
STEP,0.8571428571428571,"• Fully Connected 2: 120, ReLU"
STEP,0.8597402597402597,"H.2
FRANKA ROBOT ARM WITH VARYING LOADS"
STEP,0.8623376623376623,Recurrent Models
STEP,0.8649350649350649,"Hyperparameter
HiP-RSSM
RKN
LSTM
GRU
Learning Rate
1e-3
1e-3
3e-3
3e-3
Latent Observation Dimension
15
15
15
15
Latent State Dimension
30
30
75
75
Latent Task Dimension
30
-
-
-"
STEP,0.8675324675324675,"Encoder (HiP-RSSM,RKN,LSTM,GRU): 1 fully connected + linear output (elu + 1)"
STEP,0.8701298701298701,"• Fully Connected 1: 30, ReLU"
STEP,0.8727272727272727,"Observation Decoder (HiP-RSSM,RKN,LSTM,GRU): 1 fully connected + linear output:"
STEP,0.8753246753246753,"• Fully Connected 1: 30, ReLU"
STEP,0.8779220779220779,"Transition Model (HiP-RSSM,RKN): number of basis: 32"
STEP,0.8805194805194805,• α(zt): No hidden layers - softmax output
STEP,0.8831168831168831,"Control Model (HiP-RSSM, RKN): 1 fully connected + linear output"
STEP,0.8857142857142857,"• Fully Connected 1: 120, ReLU"
STEP,0.8883116883116883,Published as a conference paper at ICLR 2022
STEP,0.8909090909090909,"Neural Process (NP) Baseline
Latent Task Dimension: 30
Learning Rate: 1e-3
Optimizer Used: Adam Optimizer"
STEP,0.8935064935064935,Context Encoder : 1 fully connected + linear output (elu + 1)
STEP,0.8961038961038961,"• Fully Connected 1: 240, ReLU
• Linear output: 30"
STEP,0.8987012987012987,Decoder 3 fully connected + linear output
STEP,0.9012987012987013,"• Fully Connected 1: 512, ReLU
• Fully Connected 2: 240, ReLU
• Fully Connected 2: 120, ReLU"
STEP,0.9038961038961039,"FFNN Baseline
Learning Rate: 1e-3
Optimizer Used: Adam Optimizer"
STEP,0.9064935064935065,2 fully connected + linear output
STEP,0.9090909090909091,"• Fully Connected 1: 6000, ReLU
• Fully Connected 2: 3000, ReLU"
STEP,0.9116883116883117,"MAML Baseline
Meta Optimizer Learning Rate: 3e-4
Inner Optimizer Learning Rate: 0.04
Number Of Gradient Steps: 1
Optimizer Used: Adam Optimizer (Meta Update) and SGD Optimizer (Inner Update)
Model
Feed Forward Neural Network with 3 fully connected + linear output"
STEP,0.9142857142857143,"• Fully Connected 1: 512, ReLU
• Fully Connected 2: 240, ReLU
• Fully Connected 2: 120, ReLU"
STEP,0.9168831168831169,"H.3
WHEELED ROBOT TRAVERSING SLOPES OF DIFFERENT HEIGHT"
STEP,0.9194805194805195,Recurrent Models
STEP,0.922077922077922,"Hyperparameter
HiP-RSSM
RKN
LSTM
GRU
Learning Rate
9e-4
9e-4
1e-2
1e-2
Latent Observation Dimension
30
30
15
15
Latent State Dimension
60
60
75
75
Latent Task Dimension
60
-
-
-"
STEP,0.9246753246753247,"Encoder (HiP-RSSM,RKN,LSTM,GRU): 1 fully connected + linear output (elu + 1)"
STEP,0.9272727272727272,"• Fully Connected 1: 120, ReLU"
STEP,0.9298701298701298,"Observation Decoder (HiP-RSSM,RKN,LSTM,GRU): 1 fully connected + linear output:"
STEP,0.9324675324675324,"• Fully Connected 1: 240, ReLU"
STEP,0.935064935064935,"Transition Model (HiP-RSSM,RKN): number of basis: 15"
STEP,0.9376623376623376,Published as a conference paper at ICLR 2022
STEP,0.9402597402597402,• α(zt): No hidden layers - softmax output
STEP,0.9428571428571428,"Control Model (HiP-RSSM, RKN): 3 fully connected + linear output"
STEP,0.9454545454545454,"• Fully Connected 1: 120, ReLU"
STEP,0.948051948051948,"Neural Process (NP) Baseline
Latent Task Dimension: 30
Learning Rate: 1e-3
Optimizer Used: Adam Optimizer"
STEP,0.9506493506493506,Context Encoder : 1 fully connected + linear output (elu + 1)
STEP,0.9532467532467532,"• Fully Connected 1: 240, ReLU"
STEP,0.9558441558441558,• Linear output: 30
STEP,0.9584415584415584,Decoder 3 fully connected + linear output
STEP,0.961038961038961,"• Fully Connected 1: 512, ReLU"
STEP,0.9636363636363636,"• Fully Connected 2: 240, ReLU"
STEP,0.9662337662337662,"• Fully Connected 2: 120, ReLU"
STEP,0.9688311688311688,"• Fully Connected 2: 60, ReLU"
STEP,0.9714285714285714,"FFNN Baseline
Learning Rate: 2e-3
Optimizer Used: Adam Optimizer"
STEP,0.974025974025974,3 fully connected + linear output
STEP,0.9766233766233766,"• Fully Connected 1: 512, ReLU"
STEP,0.9792207792207792,"• Fully Connected 2: 240, ReLU"
STEP,0.9818181818181818,"• Fully Connected 2: 120, ReLU"
STEP,0.9844155844155844,"• Fully Connected 2: 60, ReLU"
STEP,0.987012987012987,"MAML Baseline
Meta Optimizer Learning Rate: 3e-4
Inner Optimizer Learning Rate: 0.4
Number Of Gradient Steps: 1
Optimizer Used: Adam Optimizer (Meta Update) and SGD Optimizer (Inner Update).
Model
Feed Forward Neural Network with 3 fully connected + linear output"
STEP,0.9896103896103896,"• Fully Connected 1: 512, ReLU"
STEP,0.9922077922077922,"• Fully Connected 2: 240, ReLU"
STEP,0.9948051948051948,"• Fully Connected 2: 120, ReLU"
STEP,0.9974025974025974,"• Fully Connected 3: 60, ReLU"
