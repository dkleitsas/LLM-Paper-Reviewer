Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.002150537634408602,"Recent years have witnessed an explosion in the development of novel prediction-
1"
ABSTRACT,0.004301075268817204,"based attribution methods, which have slowly been supplanting older gradient-
2"
ABSTRACT,0.0064516129032258064,"based methods to explain the decisions of deep neural networks. However, it is still
3"
ABSTRACT,0.008602150537634409,"not clear why prediction-based methods outperform gradient-based ones. Here, we
4"
ABSTRACT,0.010752688172043012,"start with an empirical observation: these two approaches yield attribution maps
5"
ABSTRACT,0.012903225806451613,"with very different power spectra, with gradient-based methods revealing more
6"
ABSTRACT,0.015053763440860216,"high-frequency content than prediction-based methods. This observation raises
7"
ABSTRACT,0.017204301075268817,"multiple questions: What is the source of this high-frequency information, and does
8"
ABSTRACT,0.01935483870967742,"it truly reflect decisions made by the system? Lastly, why would the absence of
9"
ABSTRACT,0.021505376344086023,"high-frequency information in prediction-based methods yield better explainability
10"
ABSTRACT,0.023655913978494623,"scores along multiple metrics? We analyze the gradient of three representative
11"
ABSTRACT,0.025806451612903226,"visual classification models and observe that it contains noisy information emanat-
12"
ABSTRACT,0.02795698924731183,"ing from high-frequencies. Furthermore, our analysis reveals that the operations
13"
ABSTRACT,0.030107526881720432,"used in Convolutional Neural Networks (CNNs) for downsampling appear to be a
14"
ABSTRACT,0.03225806451612903,"significant source of this high-frequency content – suggesting aliasing as a possible
15"
ABSTRACT,0.034408602150537634,"underlying basis. We then apply an optimal low-pass filter for attribution maps and
16"
ABSTRACT,0.03655913978494624,"demonstrate that it improves gradient-based attribution methods. We show that (i)
17"
ABSTRACT,0.03870967741935484,"removing high-frequency noise yields significant improvements in the explainabil-
18"
ABSTRACT,0.04086021505376344,"ity scores obtained with gradient-based methods across multiple models – leading
19"
ABSTRACT,0.043010752688172046,"to (ii) a novel ranking of state-of-the-art methods with gradient-based methods
20"
ABSTRACT,0.04516129032258064,"at the top. We believe that our results will spur renewed interest in simpler and
21"
ABSTRACT,0.047311827956989246,"computationally more efficient gradient-based methods for explainability.
22"
INTRODUCTION,0.04946236559139785,"1
Introduction
23"
INTRODUCTION,0.05161290322580645,"Explaining and interpreting the decision of AI architectures is an important area of research towards
24"
INTRODUCTION,0.053763440860215055,"enabling the development of more interpretable models. Explainability methods (XAI) aim to provide
25"
INTRODUCTION,0.05591397849462366,"insights into the strategies used by models to arrive at their decision. This is expected to lead to the
26"
INTRODUCTION,0.05806451612903226,"development of better models that are more accurate, robust, and better aligned with humans.
27"
INTRODUCTION,0.060215053763440864,"One of the first attribution methods proposed, “Saliency“ [1], consists of back-propagating a model’s
28"
INTRODUCTION,0.06236559139784946,"decision back to an input image to highlight areas that most affected the final decision. The method
29"
INTRODUCTION,0.06451612903225806,"remains relatively simple and computationally efficient, but it is also known to be noisy and to lead to
30"
INTRODUCTION,0.06666666666666667,"attribution maps that are often hard to interpret. Multiple methods have been proposed since to try to
31"
INTRODUCTION,0.06881720430107527,"improve on these limitations. These methods fall broadly into two main classes. (i) Gradient-based
32"
INTRODUCTION,0.07096774193548387,"methods extend Saliency [1] by smoothing the resulting attribution maps [2–8]. However, these
33"
INTRODUCTION,0.07311827956989247,"so-called white-box methods require access to all the model’s components, which is not always
34"
INTRODUCTION,0.07526881720430108,† The authors contributed equally.
INTRODUCTION,0.07741935483870968,"Figure 1: Effect of FORGrad on gradient-based attribution methods. We show that for an
input image (left), the initial explanations from two gradient-based methods are plagued by noise
as indicated by the high power in the high-frequency range of their respective spectra. Filtering the
explanations with FORGrad yields improved explanations (right)."
INTRODUCTION,0.07956989247311828,"possible. Conversely, prediction-based methods, also called black-box methods [3, 9–11], alter the
35"
INTRODUCTION,0.08172043010752689,"input of the model to produce an explanation based on the resulting change in the output. Those
36"
INTRODUCTION,0.08387096774193549,"methods are computationally inefficient and are known to sometimes fail to capture all the diagnostic
37"
INTRODUCTION,0.08602150537634409,"information, but they currently lead to the best fidelity scores across all explainability methods.
38"
INTRODUCTION,0.08817204301075268,"Overall, there are dozens of attribution methods available but relatively little is understood about
39"
INTRODUCTION,0.09032258064516129,"what makes certain methods more accurate than others.
40"
INTRODUCTION,0.09247311827956989,"Here, we start with the observation made across multiple studies [12, 4, 13] that the attribution maps
41"
INTRODUCTION,0.09462365591397849,"derived with Saliency are very noisy. Generally, these maps highlight sparse pixel activations around
42"
INTRODUCTION,0.0967741935483871,"a region of interest, and they are often hard to interpret. Because Saliency is simply the gradient of
43"
INTRODUCTION,0.0989247311827957,"the score function with respect to the input, we suggest that the noise originates from the gradient
44"
INTRODUCTION,0.1010752688172043,"itself: in other words, because the gradient is noisy, the explanation provided by Saliency is also
45"
INTRODUCTION,0.1032258064516129,"noisy. To try to better understand the origin of this noise, we compare the Fourier power spectra of
46"
INTRODUCTION,0.1053763440860215,"gradient-based methods (including Saliency) against prediction-based methods and observe that they
47"
INTRODUCTION,0.10752688172043011,"differ quite markedly. We discern significant differences between the two classes of approaches, with
48"
INTRODUCTION,0.10967741935483871,"gradient-based methods returning higher frequency content and prediction-based methods returning
49"
INTRODUCTION,0.11182795698924732,"lower frequency content. In the remainder of this paper, we will show that:
50"
INTRODUCTION,0.11397849462365592,"• The gradient is indeed noisy, and this noise is especially present in the high-frequencies.
51"
INTRODUCTION,0.11612903225806452,"• We then look for the origin of these high frequencies in vision models. Our findings show
52"
INTRODUCTION,0.11827956989247312,"that downsampling operations (via MaxPooling or strides) are the main sources of high
53"
INTRODUCTION,0.12043010752688173,"frequencies, and training the model does not alleviate the issue.
54"
INTRODUCTION,0.12258064516129032,"• We then propose to repair Saliency – as well as other gradient-based methods – by introduc-
55"
INTRODUCTION,0.12473118279569892,"ing FORGrad (FOurier Reparation of the Gradient). This method consists in estimating the
56"
INTRODUCTION,0.12688172043010754,"optimal amount of high frequencies to remove per model to make gradient-based methods
57"
INTRODUCTION,0.12903225806451613,"surpass the prediction-based family of attribution methods.
58"
RELATED WORK,0.13118279569892474,"2
Related Work
59"
RELATED WORK,0.13333333333333333,"Attribution methods for black-box models
Various methods have been developed to compute
60"
RELATED WORK,0.13548387096774195,"importance scores for individual pixels or groups of pixels. For black-box (prediction-based) attribu-
61"
RELATED WORK,0.13763440860215054,"tion methods, the analytical form and potential internal states of the model are unknown. The first
62"
RELATED WORK,0.13978494623655913,"method, Occlusion [3], masks individual image regions, one at a time, using an occluding mask set to
63"
RELATED WORK,0.14193548387096774,"a baseline value. The corresponding prediction scores are assigned to all pixels within the occluded
64"
RELATED WORK,0.14408602150537633,"region, providing an easily interpretable explanation. However, occlusion fails to account for the
65"
RELATED WORK,0.14623655913978495,"joint (higher-order) interactions between multiple image regions. For instance, occluding two image
66"
RELATED WORK,0.14838709677419354,"regions individually may only have a minimal impact on the model’s prediction, such as removing a
67"
RELATED WORK,0.15053763440860216,"single eye or mouth component from a face. However, occluding these two regions together may lead
68"
RELATED WORK,0.15268817204301074,"to a substantial change in the model’s prediction if these regions interact non-linearly, as expected
69"
RELATED WORK,0.15483870967741936,"in a deep neural network. Sobol [10], along with related methods such as LIME [11] and RISE [9],
70"
RELATED WORK,0.15698924731182795,"address this problem by randomly perturbing multiple regions of the input image simultaneously.
71"
RELATED WORK,0.15913978494623657,"Interestingly, recent studies, including RISE [9] and Sobol [10], have demonstrated that black-box
72"
RELATED WORK,0.16129032258064516,"attribution methods can rival and even surpass the commonly used white-box methods without relying
73"
RELATED WORK,0.16344086021505377,"on internal states.
74"
RELATED WORK,0.16559139784946236,"Attribution methods for white-box models
The gradient-based methods, that we propose to
75"
RELATED WORK,0.16774193548387098,"improve here, were first introduced in [14] and improved in [2–4]. They consist in explaining the
76"
RELATED WORK,0.16989247311827957,"decisions of a model by back-propagating the gradient from the output to the input, indicating which
77"
RELATED WORK,0.17204301075268819,"pixels affect the decision score the most. However, this family of methods is limited because they
78"
RELATED WORK,0.17419354838709677,"focus on the influence of individual pixels in an infinitesimal neighborhood in the input image. For
79"
RELATED WORK,0.17634408602150536,"instance, it has been shown that gradients often vanish when the prediction score to be explained is
80"
RELATED WORK,0.17849462365591398,"near the maximum value [6]. Integrated Gradient [6] and SmoothGrad [5] partially address this issue
81"
RELATED WORK,0.18064516129032257,"by accumulating gradients. Another family of attribution methods relies on the neural network’s
82"
RELATED WORK,0.1827956989247312,"activation, like CAM [7], which computes an attribution score based on a weighted sum of feature
83"
RELATED WORK,0.18494623655913978,"channel activities – right before the classification layer. GradCAM [8] extends CAM via the use of
84"
RELATED WORK,0.1870967741935484,"gradients, re-weighting each feature channel to take into account their importance for the predicted
85"
RELATED WORK,0.18924731182795698,"class. Nevertheless, the choice of the layer has a huge impact on the quality of the explanation. Our
86"
RELATED WORK,0.1913978494623656,"contribution proposes to overcome some of the mentioned issues by removing the noise present in
87"
RELATED WORK,0.1935483870967742,"the gradients in the form of high frequencies.
88"
RELATED WORK,0.1956989247311828,"Fourier analysis of vision models
Very little work has been proposed to analyze vision models
89"
RELATED WORK,0.1978494623655914,"and methods from a Fourier perspective. The closest, [15], used Fourier analysis to investigate the
90"
RELATED WORK,0.2,"impact of DNNs optimization parameters and methods without a specific focus on vision.
91"
RELATED WORK,0.2021505376344086,"Additional work has focused on the analysis and development of adversarial attacks in the Fourier
92"
RELATED WORK,0.20430107526881722,"domain, [16, 17], while others [18–20] have proposed to defend against adversarial attacks by
93"
RELATED WORK,0.2064516129032258,"transforming the input image in the Fourier domain. Jo and Bengio [21] examined whether CNNs
94"
RELATED WORK,0.2086021505376344,"rely on high-level features by using Fourier-filtered images. None of the mentioned studies make a
95"
RELATED WORK,0.210752688172043,"link between explainability and attribution methods with Fourier analysis.
96"
RELATED WORK,0.2129032258064516,"3
Decomposing the gradient: An analysis of frequency content in attribution
97"
RELATED WORK,0.21505376344086022,"methods
98"
RELATED WORK,0.2172043010752688,"Notations
We consider a general supervised learning setting, where a classifier f : X →Y maps
99"
RELATED WORK,0.21935483870967742,"images from an input space X ⊆RW ×H to an output space Y ⊆R. Let (x1, . . . , xN) be a set of
100"
RELATED WORK,0.221505376344086,"images which contains N samples drawn from a probability distribution ∀i ∈{1 · · · n}, xi ∼D.
101"
RELATED WORK,0.22365591397849463,"Moreover, we respectively denote F and F−1 the Discrete Fourier Transform (DFT) on RW ×H and
102"
RELATED WORK,0.22580645161290322,"its inverse. Therefore: ∀x ∈X, F(x) ∈CW ×H and (F−1 ◦F)(x) = x. Additionally, when we
103"
RELATED WORK,0.22795698924731184,"visualize the Fourier spectrum, we always shift the low-frequency components to the center of the
104"
RELATED WORK,0.23010752688172043,"spectrum. We recall that an attribution method is a function φ : X →RW ×H that maps an input of
105"
RELATED WORK,0.23225806451612904,"interest to its corresponding importance scores φ(x). Finally, we denote by φσ(x) the attribution
106"
RELATED WORK,0.23440860215053763,method where high frequencies have been filtered using a cutoff value of σ.
RELATED WORK,0.23655913978494625,"Figure 2: Fourier footprint of attribution methods. We show on the top row the Fourier spectrum of
prediction-based attribution methods and of the gradient-based methods on the bottom row, computed
with a ResNet50. The two families can be distinguished by methods but also by their signature in
the Fourier domain. The former method has magnitudes largely concentrated in the low frequencies,
while the latter is more spread out: it features non-trivial magnitudes almost everywhere, including in
high frequencies.
107"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.23870967741935484,"3.1
Different signatures for different categories of methods
108"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.24086021505376345,"In this work, we analyze the Fourier signature of several attribution methods. To do so, we compute
109"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.24301075268817204,"the feature map φ(x) for most existing attribution methods on representative models of the literature
110"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.24516129032258063,"(ResNet50 in Figure 2). From these importance maps, we extract the corresponding amplitude of the
111"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.24731182795698925,"Fourier spectrum, |(F ◦φ)(x)|. In Figure 2, we show the average power spectra, over 1,000 images,
112"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.24946236559139784,"for an array of methods. Upon visual inspection, it is obvious that certain methods tend to emphasize
113"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.25161290322580643,"higher frequencies in their explanations, while others concentrate on lower frequencies. Interestingly,
114"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.2537634408602151,"these differences can be traced to the class of methods: Black-box methods, which do not rely
115"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.25591397849462366,"on gradients, exhibit frequency footprints dominated by very low frequencies, whereas white-box
116"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.25806451612903225,"methods exhibit footprints that extend into higher frequencies. To quantify our observations, we
117"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.26021505376344084,"employ two metrics to measure the complexity of the attribution maps. The first metric employs
118"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.2623655913978495,"a Laplacian-based operator [22, 23] that evaluates the presence of high frequencies in images by
119"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.2645161290322581,"analyzing their second derivative. The second metric involves measuring the file size of the image
120"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.26666666666666666,"after undergoing lossless compression [24, 25], which we refer to as “High-frequency content“
121"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.26881720430107525,"throughout this study (as it can be seen as a loose approximation of Kolmogorov complexity).
122"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.2709677419354839,"Figure 3: High-frequency power in attribution
methods. High-frequency power present in the
importance maps derived from different attribution
methods. Prediction-based methods produce less
high-frequency content than gradient-based meth-
ods."
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.2731182795698925,"Both metrics validate our visual observations,
123"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.2752688172043011,"as depicted in Figure 3 (see Laplace quantity
124"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.27741935483870966,"in appendix). It is evident that black-box meth-
125"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.27956989247311825,"ods (shown in dark in the figure) exhibit fewer
126"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.2817204301075269,"high frequencies compared to white-box meth-
127"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.2838709677419355,"ods. This observation provides valuable insight
128"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.2860215053763441,"into where these methods extract information
129"
DIFFERENT SIGNATURES FOR DIFFERENT CATEGORIES OF METHODS,0.28817204301075267,"from the model to compute their explanations.
130"
HIGH-FREQUENCIES,0.2903225806451613,"3.2
High-frequencies
131"
HIGH-FREQUENCIES,0.2924731182795699,"are just noise in the gradient
132"
HIGH-FREQUENCIES,0.2946236559139785,"Naturally, gradient-based methods will be sub-
133"
HIGH-FREQUENCIES,0.2967741935483871,"ject to the characteristics of the gradient itself.
134"
HIGH-FREQUENCIES,0.2989247311827957,"Consequently, when the gradient is subject to
135"
HIGH-FREQUENCIES,0.3010752688172043,"noise, the resulting explanation provided by
136"
HIGH-FREQUENCIES,0.3032258064516129,"such methods becomes similarly noisy. In light
137"
HIGH-FREQUENCIES,0.3053763440860215,"of this observation, we propose to demonstrate
138"
HIGH-FREQUENCIES,0.30752688172043013,"that the gradients obtained from three state-of-
139"
HIGH-FREQUENCIES,0.3096774193548387,"the-art models (ResNet50 [26], ViT [27], and
140"
HIGH-FREQUENCIES,0.3118279569892473,"ConvNeXT [28]) do indeed contain noise, pre-
141"
HIGH-FREQUENCIES,0.3139784946236559,"dominantly present in high-frequency compo-
142"
HIGH-FREQUENCIES,0.3161290322580645,"nents. To achieve this, we suggest an approach"
HIGH-FREQUENCIES,0.31827956989247314,"Figure 4: Evidence for noise in the gradient. We plot the residual of the first-order approximation
of the model, that is f(x + ε) ≈f(x) + ε∇xf(x), with the gradient ∇f filtered at different
bandwidths σ. We sample 100 values of ε uniformly on Sd−1 scaled by the radius, for 1,000 images
of the validation set of ImageNet. If high-frequencies contained information necessary for a good
linearization of the model then we would observe a gap between the curves of σ = 224 - where no
filter is applied, vs. the curves where we apply a filter - σ < 224. 143"
HIGH-FREQUENCIES,0.3204301075268817,"that involves selectively removing high-frequency gradient information by employing various fre-
144"
HIGH-FREQUENCIES,0.3225806451612903,"quency cutoffs σ. By computing residuals between f(x + ε) and its first order filtered by σ
145"
HIGH-FREQUENCIES,0.3247311827956989,"decomposition around x that we denote by f(x) + ε∇σ
xf(x), we generate corresponding curves for
146"
HIGH-FREQUENCIES,0.32688172043010755,"different scales of ε, which are presented in Figure 4. As anticipated, our observations reveal that the
147"
HIGH-FREQUENCIES,0.32903225806451614,"curves exhibiting reduced high-frequency content (from σ < 224 to σ = 10) closely align with the
148"
HIGH-FREQUENCIES,0.3311827956989247,"one of the non-filtered gradient (σ = 224). In other words, the gradient remains approximately as
149"
HIGH-FREQUENCIES,0.3333333333333333,"informative, even after removing high-frequency information. This implies that the high-frequency
150"
HIGH-FREQUENCIES,0.33548387096774196,"content primarily contains noisy information within the gradient.
151"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.33763440860215055,"3.3
Investigating the mechanisms introducing noise
152"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.33978494623655914,"Next, we investigated the underlying operations responsible for the introduction of such content
153"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.3419354838709677,"by computing the power of high-frequency content in the gradients at the level of all the layers.
154"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.34408602150537637,"Notably, we observed a consistent trend in CNNs where high-frequency content tends to increase
155"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.34623655913978496,"and jump at each block, indicative of downsampling operation through strided convolutions or
156"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.34838709677419355,"pooling. This observation aligns with the findings of [29, 30], suggesting that downsampling
157"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.35053763440860214,"operations via MaxPooling or strided convolution can introduce noise. To verify this hypothesis,
158"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.35268817204301073,"we substituted these specific operations in two representative CNNs, namely ResNet50 [26] (which
159"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.3548387096774194,"incorporates strided convolutions and MaxPooling) and VGG16 [31] (details in appendix) with
160"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.35698924731182796,"AveragePooling. This replacement ensured the preservation of information continuity in the gradient.
161"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.35913978494623655,"The resulting plots for ResNet50 (VGG) are presented in Figures 5 - bottom curve (see appendix
162"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.36129032258064514,"for VGG), displaying the power of high-frequency content using Kolmogorov image compression
163"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.3634408602150538,"and Laplace-operator (see appendix) at each step. The depicted red shades represent the amount of
164"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.3655913978494624,"high-frequency content in both models. We observe that prior to the initial dimension change, the
165"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.36774193548387096,"quantity of high-frequency content remain comparable, suggesting that operations within a block of
166"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.36989247311827955,"the same dimension does not significantly increase the power of high-frequency content. However,
167"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.3720430107526882,"with the introduction of a downsampling layer, the curves for each model diverge, indicating a
168"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.3741935483870968,"bigger contribution to the introduction of high frequencies by striding or MaxPooling compared to
169"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.3763440860215054,"AveragePooling. Our findings corroborate the observations of [29], as the gradients (even averaged)
170"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.37849462365591396,"following MaxPooling or strides exhibit checkerboard patterns, providing a plausible explanation for
171"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.38064516129032255,"our quantitative observation of increased high-frequency content.
172"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.3827956989247312,"We employ the same pipeline to calculate the high-frequency content for both a random model and a
173"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.3849462365591398,"trained model, using the identical set of models including ViT [27]. The resulting curves are depicted
174"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.3870967741935484,"in Figures 5 - top curve, for ResNet50 (see appendix for VGG16 and for ViT), showcasing that there is
175"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.38924731182795697,"no discrepancy in high-frequency content between the trained and random CNNs. Given our previous
176"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.3913978494623656,"section’s demonstration that high-frequencies carry negligible information for the model, one would
177"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.3935483870967742,"expect that training could potentially eliminate this content, leaving only relevant information to be
178"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.3956989247311828,"processed. However, as our observations indicate the absence of such behavior despite the models
179"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.3978494623655914,"accomplishing the task, we propose that the models were unable to adapt the gradient’s content,
180"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4,"thereby suggesting it to be an inherent by-product of downsampling operations. In the case of the ViT,
181"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4021505376344086,"however, training appears to introduce some high frequencies from the initial operation, potentially
182"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4043010752688172,"arising from transformers’ pre-processing functions, such as image flattening via patches. These
183"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4064516129032258,"multiple findings suggest that high-frequency content emerges as a by-product of particular operations,
184"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.40860215053763443,"predominantly observed in CNNs, which the models are unable to modulate during training. We
185"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.410752688172043,"therefore propose to consider most of the high-frequency content as noise. Consequently, when
186"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4129032258064516,"generating explanations for the models’ decisions, it is justifiable to disregard high frequencies as
187"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4150537634408602,"they offer limited or negligible information.
188"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4172043010752688,"3.4
FORGrad: a simple strategy to remove noise
189"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.41935483870967744,"An adapted σ⋆per model
With FORGrad, we propose to remove high-frequency content,
190"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.421505376344086,"considered as noise, in order to obtain an optimal explanation related to the optimal frequency band
191"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4236559139784946,"from the gradient. We therefore propose to apply a low-pass filter on the Fourier spectrum of the
192"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4258064516129032,"gradient, employing multiple frequency cutoffs spaced evenly apart. For each filtered explanation,
193"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.42795698924731185,"we compute the score from two different metrics. The first one Deletion – denoted D(φ(x) [9] – is
194"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.43010752688172044,"a measure of the decrease in the likelihood of a particular class as the important pixels (identified
195"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.432258064516129,"by the saliency map) are systematically removed from the image. If the likelihood of the class
196"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4344086021505376,"experiences a rapid decrease, resulting in a small area under the probability curve, this is a strong
197"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.43655913978494626,"indication of a good explanation. Complementary, Insertion, I(φ(x)) [9] measures the significance
198"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.43870967741935485,"of the pixels based on their capacity to create an image, and is calculated by measuring the increase
199"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.44086021505376344,"in the probability of the class of interest as pixels are added in accordance with the generated
200"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.443010752688172,"importance map. Overall, we propose a heuristic to optimize our σ⋆, representing the ideal bandwidth
201"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.44516129032258067,"maximizing the difference σ⋆= arg maxσ ExD(φσ(x)) −I(φσ(x)), combining the score of both
202"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.44731182795698926,"metrics, on a subset of the validation set of ImageNet (1,000 images). Using both deletion and
203"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.44946236559139785,"Figure 5: Evolution of the high-frequency content in Resnet50. We compute the high-frequency
content along the depth of a ResNet50 varying either the weights or the pooling. The top curve
represents the trained model, indicated by the red curve, while the untrained model is represented by
the black curve. The bottom curve illustrates the impact of different poolings, with MaxPooling and
stride shown in dark red and AveragePooling in pink. Each point on the graph corresponds to a layer
within the models. In addition, we present visual examples of averaged gradients across 128 images
after applying MaxPooling. Despite the averaging process, these examples exhibit checkerboard
patterns, serving as a visual demonstration of the presence of high-frequencies."
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.45161290322580644,"insertion metrics can provide a more comprehensive evaluation of the quality of the attribution
204"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.45376344086021503,"map or saliency map generated for a given model. The deletion metric is useful for identifying
205"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4559139784946237,"important regions of an image that contribute to a model’s decision, while the insertion metric is
206"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.45806451612903226,"valuable for assessing the quality of the generated saliency map in terms of its ability to reconstruct
207"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.46021505376344085,"the original image. By combining both metrics, we aim to assess the quality of the explanations
208"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.46236559139784944,"generated by considering the impact of pixel removal and addition on the likelihood and significance
209"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4645161290322581,"of the target class, respectively. In the latter sections, we will consider the faithfulness metric to be
210"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4666666666666667,"the combination [Deletion-Insertion] Additionally, we also evaluate FORGrad on a third metric,
211"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.46881720430107526,"MuFidelity, F(φ(x)), [32]. The fidelity correlation metric serves to verify the correlation between
212"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.47096774193548385,"the attribution score and a random subset of pixels. To achieve this, a set of pixels is randomly chosen
213"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4731182795698925,"and set to a baseline state, after which a prediction score is obtained. The fidelity correlation metric
214"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4752688172043011,"evaluates the correlation between the decrease in the score and the significance of the explanation for
215"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4774193548387097,"each random subset created.
216"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.47956989247311826,"Theoretical foundations
In this section, we build on the empirically demonstrated assumption that
217"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4817204301075269,"the gradient is noisy and prove, through a Fourier perspective, that FORGrad effectively recovers
218"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4838709677419355,"the true gradient. Moreover, assuming that the noise is originally Gaussian, we characterize the
219"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4860215053763441,"distribution of the noise in Fourier space. Finally, we propose a convergence bound for SmoothGrad,
220"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4881720430107527,"valid on finite samples, showing that it also recovers the true gradient at the cost of multiple samplings.
221"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.49032258064516127,"We denote ∥·∥F as the Frobenius norm and ∥·∥2 as the spectral norm. Note that ∥·∥2 ≤∥·∥F in
222"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4924731182795699,"order to interpret our results. Finally, we define Kσ ∈{0, 1}W ×H as the binary Fourier mask,
223"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4946236559139785,"parameterized by σ, that we used to filter high frequency, where each element Kσ
(i,j) is determined
224"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4967741935483871,"as Kσ
(i,j) = 1|i−W"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.4989247311827957,2 |≤σ1|j−H
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5010752688172043,"2 |≤σ, with 1 the indicator function abd ¯
Kσ = 1 −Kσ. As we have
225"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5032258064516129,"discussed above, the gradient of deep models is noisy, and in the following work, we consider that
226"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5053763440860215,"we only have access to ∇x ˆf(x), a noisy estimator of ∇xf(x) such that ∇x ˆf(x) = ∇xf(x) + ε
227"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5075268817204301,"with ε ∈RW ×H. We do not assume any randomness for the noise so far. The following proposition
228"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5096774193548387,"develops the squared residual of the filtered noisy gradient as compared to the true one. Under the
229"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5118279569892473,"condition of finding the optimal filter, the gap between the two is naturally norm of the remaining
230"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.513978494623656,"noise post filtering.
231"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5161290322580645,"Proposition 3.1. Let f : X →Y a predictor, and denote ∇b
f = ∇f + ε as the noisy gradient of f,
232"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5182795698924731,"with ε ∈RW ×H. For σ∗= inf

σ : ∥F(∇f) ⊙¯
Kσ∥2
F = 0
	
, we have
233"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5204301075268817,"∥F−1(F(∇ˆf) ⊙Kσ∗) −∇f∥2
F = ∥F−1(F(ε) ⊙Kσ∗)∥2
F ≤∥ε∥2
F ,
(1)"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5225806451612903,"where ⊙is the Hadamard product, Kσ∗a binary mask for low-pass filtering of frequency σ, and
234"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.524731182795699,"¯
Kσ∗is the opposite mask.
235"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5268817204301075,"Remark 3.2. This result holds as long as we find σ∗. There always exists a σ∗as the set always
236"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5290322580645161,"contains σ = max(H, W) which does not alter the Fourier spectrum of an image of size W × H.
237"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5311827956989247,"However, finding σ∗poses a challenge, leading us to leverage XAI metrics as a heuristic.
238"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5333333333333333,"With the information that the remaining gap between the filtered estimator and the true gradient is
239"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.535483870967742,"the remaining noise, of which the norm is upper bounded by the one of the original noise, we aim
240"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5376344086021505,"at measuring the reduction of the noise. In that way, we demonstrate the always-positive effect of
241"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5397849462365591,"FORGrad on gradient methods. In particular, under the assumption of Gaussian noise, we derive
242"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5419354838709678,"the distribution of the ratio ∥ε∥2
F /∥F−1(F(ε) ⊙Kσ∗)∥2
F .
243"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5440860215053763,"Proposition 3.3. Let the noise ε ∈RW ×H follow a normal distribution ε ∼N(0, ς)⊗N. Then the
244"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.546236559139785,"norm of the Fourier spectra of the noise ∥F(ε)∥2
F ∼Γ(k = 2WH, θ = ς2WH) and filtered noise
245"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5483870967741935,"∥F(ε) ⊙Kσ∥2
F ∼Γ(k = 8σ2, θ = 4ς2σ2) follow Gamma distributions.
246"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5505376344086022,"Therefore, the ratio of the two distributions R = ∥F(ε)∥2
F /∥F(ε) ⊙Kσ∥2
F follows a Beta prime
247"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5526881720430108,"distribution R ∼β′  
2N, 8σ2, 1, W H"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5548387096774193,"4σ2

.
248"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.556989247311828,"This result allows us to directly compute the distribution of the ratio of the norm of the original
249"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5591397849462365,"noise on the norm of the filtered noise (up to a scaling factor, by Parseval’s Theorem). Naturally,
250"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5612903225806452,"this distribution depends on the parameter σ of the filtering. From this, we can deduce probabilistic
251"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5634408602150538,"results, such as, for σ = 10 and ς = 1, the ratio of the norms is larger than 70 with probability almost
252"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5655913978494623,"one.
253"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.567741935483871,"Finally, in the following proposition, we obtain a non-asymptotic result on the concentration of the
254"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5698924731182796,"SmoothGrad procedure to its expected value based on the Matrix Bernstein inequality [33].
255"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5720430107526882,"Proposition 3.4. We recall that SmoothGrad is defined as SG
=
1
n
Pn
i=1 ∇xf(x + δi)
256"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5741935483870968,"with ∀i=1,...,nδi
∈N(0, ς).
Here we compute SG on the noisy estimate of the gradient
257"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5763440860215053,"∇x ˆf(x + δi)
∈
RW ×H, which is then a random matrix d
SG.
Assuming our predictor
258"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.578494623655914,"f ∈L-Lip(X) is L-Lipschitz. We denote ∥·∥2 as the spectral norm, and define the variance
259"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5806451612903226,"as V(SG) = max
 
∥E((SG −ESG) · (SG −ESG)T )∥2, ∥E((SG −ESG)T · (SG −ESG))∥2

.
260"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5827956989247312,"We then have, for t > 0,
261"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5849462365591398,"P

∥d
SG −ESG∥2 ≥t

≤(W + H) · exp"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5870967741935483,−t2n2/2
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.589247311827957,"V(d
SG) + 2Lt/3 ! .
(2)"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5913978494623656,"Our results suggest that in order to effectively eliminate noise using the SmoothGrad method, several
262"
INVESTIGATING THE MECHANISMS INTRODUCING NOISE,0.5935483870967742,"iterations are required as opposed to ours. For instance, to be at least t = L"
AWAY FROM ITS EXPECTED,0.5956989247311828,"10 away from its expected
263"
AWAY FROM ITS EXPECTED,0.5978494623655914,"value, with probability at most 0.01, we need n ≈700 iterations, for ς = 1. Furthermore, the noisy
264"
AWAY FROM ITS EXPECTED,0.6,"SmoothGrad gradually approaches the expected outcome of the non-noisy SmoothGrad. Additionally,
265"
AWAY FROM ITS EXPECTED,0.6021505376344086,"SmoothGrad alleviate the noise but at the cost of employing Monte-Carlo sampling.
266"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6043010752688172,"4
Gradient-based methods perform better and are more efficient
267"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6064516129032258,"The new explanations are free from noise
Figure 6 presents qualitative examples of corrected
268"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6086021505376344,"gradients obtained using the Gradient Input method [34] combined with FORGrad. As we analyze
269"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.610752688172043,"the different images, we observe that gradually removing high frequencies from the gradients has a
270"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6129032258064516,"notable impact on the resulting explanation. The initially noisy patterns transform into larger patches
271"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6150537634408603,"until the saliency map effectively highlights the key features that represent the object for categorization.
272"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6172043010752688,"However, it is crucial to consider the optimal value of σ⋆, as exceeding this threshold leads to the
273"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6193548387096774,"map spreading too widely and the explanation becoming less informative. This observation is further
274"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.621505376344086,"supported by the curve on the right, which demonstrates the evolution of the faithfulness score as σ
275"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6236559139784946,"changes. Prior to finding the optimal σ, the faithfulness score fluctuates around the initial value before
276"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6258064516129033,"gradually increasing to reach its optimal level. As expected, when all the information is removed
277"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6279569892473118,"(represented by the last point on the x-axis), the fidelity score drops to zero.
278"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6301075268817204,"A new ranking of attribution methods
We apply FORGrad on all the gradient-based attri-
279"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.632258064516129,"bution methods and report the scores in Table 1 for three models: ResNet50 [26], ViT [27] and
280"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6344086021505376,"ConvNeXT [28]. GradCAM methods can’t be tested on ViT because they are based on convolution so
281"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6365591397849463,"are limited to CNNs. We can observe two notable findings. Firstly, it is rare to encounter cases where
282"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6387096774193548,"Figure 6: FORGrad : selection of the optimal σ. With FORGrad, we aim to derive the explanation
from the gradient’s corrected version. To achieve this, we determine the optimal cutoff of high
frequencies in order to maximize the faithfulness of the explanation. The images displayed on the
left illustrate the progression for different cutoff values. On the right side, the curve represents the
variation of the metric across 1,000 images from the validation set of ImageNet, as a function of σ,
representing the cutoff value. σ⋆represents the optimal value, selected as the one maximizing the
faithfulness score, equivalent to [Deletion-Insertion]."
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6408602150537634,"ResNet50
ViT
ConvNeXT"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6430107526881721,"Del.(↓)Ins.(↑) Fid.(↑) Comp.
Del.(↓)Ins.(↑) Fid.(↑) Comp.
Del.(↓)Ins.(↑) Fid.(↑) Comp."
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6451612903225806,Gradient-based
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6473118279569893,"Saliency[1]
0.77
0.85
0.07
Θ(2)
0.77
0.82
0.01
Θ(2)
0.85
0.86
0.05
Θ(2)
Saliency⋆
0.74
0.90
0.15
Θ(2)
0.81
0.89
0.03
Θ(2)
0.82
0.88
0.06
Θ(2)"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6494623655913978,"GradInput[34]
0.76
0.87
0.05
Θ(2)
0.78
0.88
0.01
Θ(2)
0.83
0.89
0.05
Θ(2)
GradInput⋆
0.74
0.88
0.13
Θ(2)
0.74
0.89
0.05
Θ(2)
0.81
0.88
0.07
Θ(2)"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6516129032258065,"SmoothGrad[5]
0.74
0.89
0.08
Θ(200)
0.80
0.87
0.03
Θ(200)
0.86
0.86
0.05
Θ(200)
SmoothGrad⋆
0.72
0.93
0.19
Θ(200)
0.78
0.92
0.04
Θ(200)
0.82
0.88
0.06
Θ(200)"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6537634408602151,"VarGrad[35]
0.74
0.91
0.07
Θ(200)
0.72
0.88
0.01
Θ(200)
0.89
0.86
0.02
Θ(200)
VarGrad⋆
0.73
0.91
0.18
Θ(200)
0.74
0.90
0.02
Θ(200)
0.80
0.88
0.02
Θ(200)"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6559139784946236,"Int.Grad[6]
0.75
0.88
0.06
Θ(200)
0.78
0.86
0.01
Θ(200)
0.82
0.90
0.05
Θ(200)
Int.Grad⋆
0.74
0.89
0.15
Θ(200)
0.79
0.87
0.03
Θ(200)
0.81
0.90
0.05
Θ(200)"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6580645161290323,Prediction-based
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6602150537634408,"GradCAM[8]
0.78
0.92
0.06
Θ(2)
n.a
n.a
n.a
n.a
0.87
0.92
0.06
Θ(2)
GradCAM++[36]
0.75
0.93
0.08
Θ(2)
n.a
n.a
n.a
n.a
0.90
0.92
0.02
Θ(2)
Occlusion[34]
0.75
0.85
0.06
Θ(1024)
0.79
0.83
0.01
Θ(1024)
0.83
0.88
0.07
Θ(1024)
HSIC[37]
0.72
0.92
0.05
Θ(2000)
0.77
0.91
0.02
Θ(2000)
0.80
0.92
0.05
Θ(2000)
Sobol[38]
0.74
0.92
0.06
Θ(4000)
0.79
0.91
0.02
Θ(4000)
0.82
0.93
0.08
Θ(4000)
RISE[9]
0.76
0.93
0.07
Θ(8000)
0.80
0.92
0.01
Θ(8000)
0.84
0.94
0.07
Θ(8000)"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6623655913978495,"Table 1: Results on Faithfulness metrics. Deletion, Insertion, and Fidelity scores obtained on 1,000
ImageNet validation set images, on an Nvidia V100 (For Deletion, lower is better and for Insertion
and Fidelity, higher is better). Complexity Θ (Comp.) corresponds to the number of forward +
backward passes required for computation, up to a factor that depends on the model. The first and
second best results are in bold and underlined."
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6645161290322581,"the scores after applying FORGrad are lower than the scores obtained before. In such instances, the
283"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6666666666666666,"decrease in scores is typically observed in only one metric, either Deletion or Insertion. However,
284"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6688172043010753,"since the other metric is optimized, the overall Faithfulness, as measured by [Deletion-Insertion],
285"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6709677419354839,"remains at least as good as before. Secondly, even without explicitly optimizing the Fidelity metric,
286"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6731182795698925,"we observe an improvement in this score across all methods and the three models analyzed. Fur-
287"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6752688172043011,"thermore, after applying FORGrad, we observe that the scores of several gradient-based methods
288"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6774193548387096,"surpass or at least match those of prediction-based methods. Notably, these gradient-based methods
289"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6795698924731183,"offer the additional advantage of being significantly more computationally efficient, as evident from
290"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6817204301075269,"the complexity column.
In order to determine the best method for each model, we propose to
291"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6838709677419355,"aggregate the scores from the three metrics to obtain a single global score for each method and model.
292"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6860215053763441,"This resulting score, is denoted as I(φ(x)) + F(φ(x)) −D(φ(x)), corresponding to the sum of
293"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6881720430107527,"1-Deletion, Insertion and Fidelity score. Interestingly, in Table 2, we observe that the rankings change
294"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6903225806451613,"when we incorporate FORGrad into the analysis. This shift leads to the inclusion of at least two
295"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6924731182795699,"gradient-based methods among the top-5 for all three models. In the case of ResNet50, all five of the
296"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6946236559139785,"top-performing methods are gradient-based, whereas only one of them occupied a position in the
297"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6967741935483871,"previous ranking. Although some prediction-based methods, such as Sobol and HSIC, consistently
298"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.6989247311827957,"ResNet50
ViT
ConvNeXT
Original
FORGrad
Original
FORGrad
Original
FORGrad"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.7010752688172043,"1
GradCAM++
SmoothGrad⋆
VarGrad
SmoothGrad⋆
Sobol
Sobol
2
HSIC
VarGrad⋆
HSIC
VarGrad⋆
RISE
RISE
3
RISE
Saliency⋆
Sobol
HSIC
HSIC
HSIC
4
Sobol
Int.Grad⋆
RISE
Sobol
Occlusion
GradInput⋆
5
VarGrad
GradInput⋆
GradInput
RISE
GradCAM
Int.Grad⋆"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.7032258064516129,"Table 2: Global ranking before (original) and after FORGrad. For each model, we show the 5
attribution methods with highest metrics, before and after applying FORGrad. The explanation
maps were computed on 1000 images from the validation set of ImageNet, based on an aggregation
of the three metrics computed by I(φ(x)) + F(φ(x)) −D(φ(x))."
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.7053763440860215,"demonstrate good performance, we demonstrate that gradient-based methods such as SmoothGrad
299"
GRADIENT-BASED METHODS PERFORM BETTER AND ARE MORE EFFICIENT,0.7075268817204301,"and VarGrad now perform nearly as well, with the added advantage of computational efficiency.
300"
LIMITATIONS,0.7096774193548387,"5
Limitations
301"
LIMITATIONS,0.7118279569892473,"In our study, we have proposed to find an optimal σ value representing an ideal cutoff to improve
302"
LIMITATIONS,0.7139784946236559,"explanations of gradient-based methods. However, we acknowledge that this optimal value is highly
303"
LIMITATIONS,0.7161290322580646,"dependent on the dataset, perhaps more so than on the model itself. Furthermore, while we have
304"
LIMITATIONS,0.7182795698924731,"chosen a single value that maximizes the scores across 1,000 images, it may be beneficial to use
305"
LIMITATIONS,0.7204301075268817,"different values for individual images, but would increase the computational costs. We also optimize
306"
LIMITATIONS,0.7225806451612903,"our value of σ only on 2 metrics, deletion and insertion. Even though it turns out to also increase the
307"
LIMITATIONS,0.7247311827956989,"fidelity score, we could potentially obtain even better results by optimizing on this metric as well. It’s
308"
LIMITATIONS,0.7268817204301076,"however, once again, a very resource-consuming method that we chose to avoid. Furthermore, in our
309"
LIMITATIONS,0.7290322580645161,"ranking computation, we combine metrics that do not precisely capture the same information. While
310"
LIMITATIONS,0.7311827956989247,"Deletion and Insertion can be aggregated, particularly since we optimize the difference between them,
311"
LIMITATIONS,0.7333333333333333,"it should be noted that Deletion, Insertion, and Fidelity are not directly comparable even if they range
312"
LIMITATIONS,0.7354838709677419,"between 0 and 1. We have proposed one approach to integrate these metrics and derive a ranking
313"
LIMITATIONS,0.7376344086021506,"based on the three scores. However, an alternative could involve producing separate rankings for each
314"
LIMITATIONS,0.7397849462365591,"individual score. If we had followed this approach, the FORGrad methods would have emerged as
315"
LIMITATIONS,0.7419354838709677,"the top-5 for both ResNet50 and ViT, according to MuFidelity.
316"
CONCLUSION,0.7440860215053764,"6
Conclusion
317"
CONCLUSION,0.7462365591397849,"This work started with an empirical observation: prediction-based and gradient-based methods
318"
CONCLUSION,0.7483870967741936,"exhibit distinct power spectra in their attribution maps – with gradient-based methods exhibiting
319"
CONCLUSION,0.7505376344086021,"higher power in the high frequencies compared to prediction-based methods. This led us to wonder
320"
CONCLUSION,0.7526881720430108,"whether the frequency content of model gradients is merely noisy information. We demonstrate
321"
CONCLUSION,0.7548387096774194,"that removing this content does not impair our ability to approximate the gradient and conclude that
322"
CONCLUSION,0.7569892473118279,"high frequencies predominantly carry non-essential information. We further conducted an in-depth
323"
CONCLUSION,0.7591397849462366,"analysis of gradient frequency content in CNNs across processing layers and found that downsampling
324"
CONCLUSION,0.7612903225806451,"operations, such as max pooling and striding, contribute to the introduction of high frequencies.
325"
CONCLUSION,0.7634408602150538,"This points to model aliasing as a likely cause of this high-frequency content. Interestingly, even
326"
CONCLUSION,0.7655913978494624,"with training, CNNs are unable to prevent this phenomenon. These results hence raise the question:
327"
CONCLUSION,0.7677419354838709,"Could high-frequencies be filtered out to improve the explanations derived from attribution methods?
328"
CONCLUSION,0.7698924731182796,"We design an optimal filter, σ⋆, and show that the filtering of attribution maps leads to significant
329"
CONCLUSION,0.7720430107526882,"improvements in the quality of the explanations. These improvements were most pronounced for
330"
CONCLUSION,0.7741935483870968,"gradient-based methods, which ended up approaching and sometimes even surpassing the much
331"
CONCLUSION,0.7763440860215054,"more compute-intensive prediction-based methods. Overall, our work leads to a surprising result –
332"
CONCLUSION,0.7784946236559139,"that the almost forgotten gradient-based methods turn out to contain all the information needed to
333"
CONCLUSION,0.7806451612903226,"provide a faithful explanation of a model’s decision and that they can be as interpretable as the newest
334"
CONCLUSION,0.7827956989247312,"methods. In future work, it would be worth exploring the influence of this noise on the model’s
335"
CONCLUSION,0.7849462365591398,"performance and evaluating whether replacing certain operations that introduce noise could affect
336"
CONCLUSION,0.7870967741935484,"both the accuracy and robustness of the models. Furthermore, considering that many adversarial
337"
CONCLUSION,0.789247311827957,"attacks are gradient-based and often exploit additive noise patterns, it is worth investigating whether
338"
CONCLUSION,0.7913978494623656,"these attacks target the noisy high-frequency content in the gradients and whether they might be
339"
CONCLUSION,0.7935483870967742,"prevented by using operations not introducing high-frequencies.
340"
REFERENCES,0.7956989247311828,"References
341"
REFERENCES,0.7978494623655914,"[1] Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. Deep inside convolutional networks: Visualising
342"
REFERENCES,0.8,"image classification models and saliency maps. In Workshop, Proceedings of the International Conference
343"
REFERENCES,0.8021505376344086,"on Learning Representations (ICLR), 2013.
344"
REFERENCES,0.8043010752688172,"[2] Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. Deep inside convolutional networks: Visualising
345"
REFERENCES,0.8064516129032258,"image classification models and saliency maps. In Workshop Proceedings of the International Conference
346"
REFERENCES,0.8086021505376344,"on Learning Representations (ICLR), 2014.
347"
REFERENCES,0.810752688172043,"[3] Matthew D Zeiler and Rob Fergus. Visualizing and understanding convolutional networks. In Proceedings
348"
REFERENCES,0.8129032258064516,"of the IEEE European Conference on Computer Vision (ECCV), 2014.
349"
REFERENCES,0.8150537634408602,"[4] Jost Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, and Martin Riedmiller. Striving for sim-
350"
REFERENCES,0.8172043010752689,"plicity: The all convolutional net. In Workshop Proceedings of the International Conference on Learning
351"
REFERENCES,0.8193548387096774,"Representations (ICLR), 2014.
352"
REFERENCES,0.821505376344086,"[5] Daniel Smilkov, Nikhil Thorat, Been Kim, Fernanda Viégas, and Martin Wattenberg. Smoothgrad:
353"
REFERENCES,0.8236559139784946,"removing noise by adding noise. In Workshop on Visualization for Deep Learning, Proceedings of the
354"
REFERENCES,0.8258064516129032,"International Conference on Machine Learning (ICML), 2017.
355"
REFERENCES,0.8279569892473119,"[6] Mukund Sundararajan, Ankur Taly, and Qiqi Yan. Axiomatic attribution for deep networks. In Proceedings
356"
REFERENCES,0.8301075268817204,"of the International Conference on Machine Learning (ICML), 2017.
357"
REFERENCES,0.832258064516129,"[7] Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. Learning deep features
358"
REFERENCES,0.8344086021505376,"for discriminative localization. In Proceedings of the IEEE conference on computer vision and pattern
359"
REFERENCES,0.8365591397849462,"recognition, pages 2921–2929, 2016.
360"
REFERENCES,0.8387096774193549,"[8] Ramprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and
361"
REFERENCES,0.8408602150537634,"Dhruv Batra. Grad-cam: Visual explanations from deep networks via gradient-based localization. In
362"
REFERENCES,0.843010752688172,"Proceedings of the IEEE International Conference on Computer Vision (ICCV), 2017.
363"
REFERENCES,0.8451612903225807,"[9] Vitali Petsiuk, Abir Das, and Kate Saenko. Rise: Randomized input sampling for explanation of black-box
364"
REFERENCES,0.8473118279569892,"models. In Proceedings of the British Machine Vision Conference (BMVC), 2018.
365"
REFERENCES,0.8494623655913979,"[10] Thomas Fel, Rémi Cadène, Mathieu Chalvidal, Matthieu Cord, David Vigouroux, and Thomas Serre. Look
366"
REFERENCES,0.8516129032258064,"at the variance! efficient black-box explanations with sobol-based sensitivity analysis. Advances in Neural
367"
REFERENCES,0.853763440860215,"Information Processing Systems, 34:26005–26014, 2021.
368"
REFERENCES,0.8559139784946237,"[11] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. ""why should i trust you?"": Explaining the
369"
REFERENCES,0.8580645161290322,"predictions of any classifier. In Knowledge Discovery and Data Mining (KDD), 2016.
370"
REFERENCES,0.8602150537634409,"[12] Beomsu Kim, Junghoon Seo, Seunghyeon Jeon, Jamyoung Koo, Jeongyeol Choe, and Taegyun Jeon. Why
371"
REFERENCES,0.8623655913978494,"are saliency maps noisy? cause of and solution to noisy saliency maps. In 2019 IEEE/CVF International
372"
REFERENCES,0.864516129032258,"Conference on Computer Vision Workshop (ICCVW), pages 4149–4157. IEEE, 2019.
373"
REFERENCES,0.8666666666666667,"[13] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and
374"
REFERENCES,0.8688172043010752,"Dhruv Batra. Grad-cam: Visual explanations from deep networks via gradient-based localization. In
375"
REFERENCES,0.8709677419354839,"Proceedings of the IEEE international conference on computer vision, pages 618–626, 2017.
376"
REFERENCES,0.8731182795698925,"[14] David Baehrens, Timon Schroeter, Stefan Harmeling, Motoaki Kawanabe, Katja Hansen, and Klaus-Robert
377"
REFERENCES,0.875268817204301,"Müller. How to explain individual classification decisions. The Journal of Machine Learning Research, 11:
378"
REFERENCES,0.8774193548387097,"1803–1831, 2010.
379"
REFERENCES,0.8795698924731182,"[15] Zhiqin John Xu. Understanding training and generalization in deep learning by fourier analysis. arXiv
380"
REFERENCES,0.8817204301075269,"preprint arXiv:1808.04295, 2018.
381"
REFERENCES,0.8838709677419355,"[16] Dong Yin, Raphael Gontijo Lopes, Jon Shlens, Ekin Dogus Cubuk, and Justin Gilmer. A fourier perspective
382"
REFERENCES,0.886021505376344,"on model robustness in computer vision. Advances in Neural Information Processing Systems, 32, 2019.
383"
REFERENCES,0.8881720430107527,"[17] Yusuke Tsuzuku and Issei Sato. On the structural sensitivity of deep convolutional networks to the
384"
REFERENCES,0.8903225806451613,"directions of fourier basis functions. In Proceedings of the IEEE/CVF Conference on Computer Vision and
385"
REFERENCES,0.8924731182795699,"Pattern Recognition, pages 51–60, 2019.
386"
REFERENCES,0.8946236559139785,"[18] Gintare Karolina Dziugaite, Zoubin Ghahramani, and Daniel M Roy.
A study of the effect of jpg
387"
REFERENCES,0.896774193548387,"compression on adversarial images. arXiv preprint arXiv:1608.00853, 2016.
388"
REFERENCES,0.8989247311827957,"[19] Chuan Guo, Mayank Rana, Moustapha Cisse, and Laurens Van Der Maaten. Countering adversarial images
389"
REFERENCES,0.9010752688172043,"using input transformations. arXiv preprint arXiv:1711.00117, 2017.
390"
REFERENCES,0.9032258064516129,"[20] Sibo Song, Yueru Chen, Ngai-Man Cheung, and C-C Jay Kuo. Defense against adversarial attacks with
391"
REFERENCES,0.9053763440860215,"saak transform. arXiv preprint arXiv:1808.01785, 2018.
392"
REFERENCES,0.9075268817204301,"[21] Jason Jo and Yoshua Bengio. Measuring the tendency of cnns to learn surface statistical regularities. arXiv
393"
REFERENCES,0.9096774193548387,"preprint arXiv:1711.11561, 2017.
394"
REFERENCES,0.9118279569892473,"[22] Ramesh C. Jain, Rangachar Kasturi, and Brian G. Schunck. Machine vision. 1995.
395"
REFERENCES,0.9139784946236559,"[23] Said Pertuz, Domenec Puig, and Miguel Angel Garcia. Analysis of focus measure operators for shape-
396"
REFERENCES,0.9161290322580645,"from-focus. Pattern Recognition, 46(5):1415–1432, 2013.
397"
REFERENCES,0.9182795698924732,"[24] Hector Zenil, Jean-Paul Delahaye, and Cédric Gaucherel. Image characterization and classification by
398"
REFERENCES,0.9204301075268817,"physical complexity. Complexity, 17(3):26–42, 2012.
399"
REFERENCES,0.9225806451612903,"[25] Andrei N Kolmogorov. On tables of random numbers. Sankhy¯a: The Indian Journal of Statistics, Series A,
400"
REFERENCES,0.9247311827956989,"pages 369–376, 1963.
401"
REFERENCES,0.9268817204301075,"[26] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition.
402"
REFERENCES,0.9290322580645162,"In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.
403"
REFERENCES,0.9311827956989247,"[27] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas
404"
REFERENCES,0.9333333333333333,"Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An image is worth
405"
REFERENCES,0.9354838709677419,"16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929, 2020.
406"
REFERENCES,0.9376344086021505,"[28] Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, and Saining Xie. A
407"
REFERENCES,0.9397849462365592,"convnet for the 2020s. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
408"
REFERENCES,0.9419354838709677,"Recognition (CVPR), pages 11976–11986, June 2022.
409"
REFERENCES,0.9440860215053763,"[29] Chris Olah, Alexander Mordvintsev, and Ludwig Schubert. Feature visualization. Distill, 2017. doi:
410"
REFERENCES,0.946236559139785,"10.23915/distill.00007. https://distill.pub/2017/feature-visualization.
411"
REFERENCES,0.9483870967741935,"[30] Xueyan Zou, Fanyi Xiao, Zhiding Yu, Yuheng Li, and Yong Jae Lee. Delving deeper into anti-aliasing in
412"
REFERENCES,0.9505376344086022,"convnets. International Journal of Computer Vision, 131(1):67–81, 2023.
413"
REFERENCES,0.9526881720430107,"[31] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recogni-
414"
REFERENCES,0.9548387096774194,"tion. arXiv preprint arXiv:1409.1556, 2014.
415"
REFERENCES,0.956989247311828,"[32] Umang Bhatt, Adrian Weller, and José MF Moura. Evaluating and aggregating feature-based model
416"
REFERENCES,0.9591397849462365,"explanations. arXiv preprint arXiv:2005.00631, 2020.
417"
REFERENCES,0.9612903225806452,"[33] Joel A Tropp et al. An introduction to matrix concentration inequalities. Foundations and Trends® in
418"
REFERENCES,0.9634408602150538,"Machine Learning, 8(1-2):1–230, 2015.
419"
REFERENCES,0.9655913978494624,"[34] Marco Ancona, Enea Ceolini, Cengiz Öztireli, and Markus Gross. Towards better understanding of gradient-
420"
REFERENCES,0.967741935483871,"based attribution methods for deep neural networks. In Proceedings of the International Conference on
421"
REFERENCES,0.9698924731182795,"Learning Representations (ICLR), 2018.
422"
REFERENCES,0.9720430107526882,"[35] Junghoon Seo, Jeongyeol Choe, Jamyoung Koo, Seunghyeon Jeon, Beomsu Kim, and Taegyun Jeon.
423"
REFERENCES,0.9741935483870968,"Noise-adding methods of saliency map as series of higher order partial derivative. In Workshop on Human
424"
REFERENCES,0.9763440860215054,"Interpretability in Machine Learning, Proceedings of the International Conference on Machine Learning
425"
REFERENCES,0.978494623655914,"(ICML), 2018.
426"
REFERENCES,0.9806451612903225,"[36] Aditya Chattopadhay, Anirban Sarkar, Prantik Howlader, and Vineeth N Balasubramanian. Grad-cam++:
427"
REFERENCES,0.9827956989247312,"Generalized gradient-based visual explanations for deep convolutional networks. In Proceedings of the
428"
REFERENCES,0.9849462365591398,"IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2018.
429"
REFERENCES,0.9870967741935484,"[37] Paul Novello, Thomas Fel, and David Vigouroux. Making sense of dependence: Efficient black-box
430"
REFERENCES,0.989247311827957,"explanations using dependence measure. In Advances in Neural Information Processing Systems (NeurIPS),
431"
REFERENCES,0.9913978494623656,"2022.
432"
REFERENCES,0.9935483870967742,"[38] Thomas Fel, Remi Cadene, Mathieu Chalvidal, Matthieu Cord, David Vigouroux, and Thomas Serre. Look
433"
REFERENCES,0.9956989247311828,"at the variance! efficient black-box explanations with sobol-based sensitivity analysis. In Advances in
434"
REFERENCES,0.9978494623655914,"Neural Information Processing Systems (NeurIPS), 2021.
435"
