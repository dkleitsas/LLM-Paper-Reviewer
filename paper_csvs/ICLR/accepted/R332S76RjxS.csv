Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0011918951132300357,"Implicit deep learning has received increasing attention recently, since it gener-
alizes the recursive prediction rules of many commonly used neural network ar-
chitectures. Its prediction rule is provided implicitly based on the solution of an
equilibrium equation. Although many recent studies have experimentally demon-
strates its superior performances, the theoretical understanding of implicit neural
networks is limited. In general, the equilibrium equation may not be well-posed
during the training. As a result, there is no guarantee that a vanilla (stochastic)
gradient descent (SGD) training nonlinear implicit neural networks can converge.
This paper ﬁlls the gap by analyzing the gradient ﬂow of Rectiﬁed Linear Unit
(ReLU) activated implicit neural networks. For an m-width implicit neural net-
work with ReLU activation and n training samples, we show that a randomly
initialized gradient descent converges to a global minimum at a linear rate for the
square loss function if the implicit neural network is over-parameterized. It is
worth noting that, unlike existing works on the convergence of (S)GD on ﬁnite-
layer over-parameterized neural networks, our convergence results hold for im-
plicit neural networks, where the number of layers is inﬁnite."
INTRODUCTION,0.0023837902264600714,"1
INTRODUCTION"
INTRODUCTION,0.003575685339690107,"1) Background and Motivation: In the last decade, implicit deep learning (El Ghaoui et al., 2019)
have attracted more and more attention. Its popularity is mainly because it generalizes the recursive
rules of many widely used neural network architectures. A line of recent works (Bai et al., 2019;
El Ghaoui et al., 2019; Bai et al., 2020) have shown that the implicit neural network architecture
is a wider class that includes most current neural network architectures as special cases, such as
feed-forward neural networks, convolution neural networks, residual networks, and recurrent neu-
ral networks. Moreover, implicit deep learning is also well known for its competitive performance
compared to other regular deep neural networks but using signiﬁcantly fewer computational re-
sources (Dabre & Fujita, 2019; Dehghani et al., 2018; Bai et al., 2018)."
INTRODUCTION,0.004767580452920143,"Although a line of literature has been shown the superior performance of implicit neural networks
experimentally, the theoretical understanding is still limited. To date, it is still unknown if a simple
ﬁrst-order optimization method such as (stochastic) gradient descent can converge on an implicit
neural network activated by a nonlinear function. Unlike a regular deep neural network, an implicit
neural network could have inﬁnitely many layers, resulting in the possibility of divergence of the"
INTRODUCTION,0.0059594755661501785,"forward propagation (El Ghaoui et al., 2019; Kawaguchi, 2021). The main challenge in establishing
the convergence of implicit neural network training lies in the fact that, in general, the equilibrium
equation of implicit neural networks cannot be solved in closed-form. What exacerbates the problem
is the well-posedness of the forward propagation. In other words, the equilibrium equation may
have zero or multiple solutions. A line of recent studies have suggested a number of strategies to
handle this well-posedness challenge, but they all involved reformulation or solving subproblems
in each iteration. For example, El Ghaoui et al. (2019) suggested to reformulate the training as
the Fenchel divergence formulation and solve the reformulated optimization problem by projected
gradient descent method. However, this requires solving a projection subproblem in each iteration
and convergence was only demonstrated numerically. By using an extra softmax layer, Kawaguchi
(2021) established global convergence result of gradient descent for a linear implicit neural network.
Unfortunately, their result cannot be extended to nonlinear activations, which are critical to the
learnability of deep neural networks."
INTRODUCTION,0.007151370679380214,"This paper proposes a global convergence theory of gradient descent for implicit neural networks
activated by nonlinear Rectiﬁed Linear Unit (ReLU) activation function by using overparameteriza-
tion. Speciﬁcally, we show that random initialized gradient descent with ﬁxed stepsize converges
to a global minimum of a ReLU implicit neural network at a linear rate as long as the implicit
neural network is overparameterized. Recently, over-parameterization has been shown to be effec-
tive in optimizing ﬁnite-depth neural networks (Zou et al., 2020; Nguyen & Mondelli, 2020; Arora
et al., 2019; Oymak & Soltanolkotabi, 2020). Although the objective function in the training is non-
smooth and non-convex, it can be shown that GD or SGD converge to a global minimum linearly
if the width m of each layer is a polynomial of the number of training sample n and the number of
layers h, i.e., m = poly(n, h). However, these results cannot be directly applied to implicit neural
networks, since implicit neural networks have inﬁnitely many hidden layers, i.e., h →∞, and the
well-posedness problem surfaces during the training process. In fact, Chen et al. (2018); Bai et al.
(2019; 2020) have all observed that the time and number of iterations spent on forward propagation
are gradually increased with the the training epochs. Thus, we have to ensure the unique equilibrium
point always exists throughout the training given that the width m is only polynomial of n."
INTRODUCTION,0.00834326579261025,"2) Preliminaries of Implicit Deep Learning: In this work, we consider an implicit neural network
with the transition at the ℓ-th layer in the following form (El Ghaoui et al., 2019; Bai et al., 2019):"
INTRODUCTION,0.009535160905840286,"zℓ= σ
 γ
√mAzℓ−1 + φ(x)

,
(1)"
INTRODUCTION,0.010727056019070322,"where φ : Rd →Rm is a feature mapping function that transforms an input vector x ∈Rd to a
desired feature vector φ ≜φ(x), zℓ∈Rm is the output of the ℓ-th layer, A ∈Rm×m is a trainable
weight matrix, σ(u) = max{0, u} is the ReLU activation function, and γ ∈(0, 1) is a ﬁxed scalar to
scale A. As will be shown later in Section 2.1, γ plays the role of ensuring the existence of the limit
z∗= limℓ→∞zℓ. In general, the feature mapping function φ is a nonlinear function, which extracts
features from the low-dimensional input vector x. In this paper, we consider a simple nonlinear
feature mapping function φ given by"
INTRODUCTION,0.011918951132300357,"φ(x) ≜
1
√mσ(W x),
(2)"
INTRODUCTION,0.013110846245530394,"where W ∈Rm×d is a trainable parameter matrix. As ℓ→∞, an implicit neural network can be
considered an inﬁnitely deep neural network. Consequently, z∗is not only the limit of the sequence
{zℓ}∞
ℓ=0 with z0 = 0, but it is also the equilibrium point (or ﬁxed point) of the equilibrium equation:"
INTRODUCTION,0.014302741358760428,"z∗= σ(˜γAz∗+ φ),
(3)"
INTRODUCTION,0.015494636471990465,"where ˜γ ≜γ/√m. In implicit neural networks, the prediction ˆy for the input vector x is the
combination of the ﬁxed point z∗and the feature vector φ, i.e.,"
INTRODUCTION,0.0166865315852205,"ˆy = uT z∗+ vT φ,
(4)"
INTRODUCTION,0.017878426698450536,"where u, v ∈Rm are trainable weight vectors. For simplicity, we use θ ≜vec (A, W , u, v) to
group all training parameters. Given a training data set {(xi, yi)}n
i=1, we want to minimize"
INTRODUCTION,0.01907032181168057,"L(θ) = n
X i=1"
INTRODUCTION,0.02026221692491061,"1
2(ˆyi −yi)2 = 1"
INTRODUCTION,0.021454112038140644,"2∥ˆy −y∥2,
(5)"
INTRODUCTION,0.02264600715137068,where ˆy and y are the vectors formed by stacking all the prediction and labels.
INTRODUCTION,0.023837902264600714,"3) Main Results: Our results are based on the following observations. We ﬁrst analyze the for-
ward propagation and ﬁnd that the unique equilibrium point always exists if the scaled matrix ˜γA in
Eq. (3) has an operator norm less than one. Thus, the well-posedness problem is reduced to ﬁnding
a sequence of scalars {γk}∞
k=1 such that ˜γkA(k) is appropriately scaled. To achieve this goal, we
show that the operator norm A(k) is uniformly upper bounded by a constant over all iterations.
Consequently, a ﬁxed scalar γ is enough to ensure the well-posedness of Eq. (3). Our second ob-
servation is from the analysis of the gradient descent method with inﬁnitesimal step-size (gradient
ﬂow). By applying the chain rule with the gradient ﬂow, we derive the dynamics of prediction ˆy(t)
which is governed by the spectral property of a Gram matrix. In particular, if the smallest eigen-
value of the Gram matrix is lower bounded throughout the training, the gradient descent method
enjoys a linear convergence rate. Along with some basic functional analysis results, it can be shown
that the smallest eigenvalue of the Gram matrix at initialization is lower bounded if no two data
samples are parallel. Although the Gram matrix varies in each iteration, the spectral property is
preserved if the Gram matrix is close to its initialization. Thus, the convergence problem is reduced
to showing the Gram matrix in latter iterations is close to its initialization. Our third observation is
that we ﬁnd random initialization, over-parameterization, and linear convergence jointly enforce the
(operator) norms of parameters upper bounded by some constants and close to their initialization.
Accordingly, we can use this property to show that the operator norm of A is upper bounded and the
spectral property of the Gram matrix is preserved throughout the training. Combining all these in-
sights together, we can conclude that the random initialized gradient descent method with a constant
step-size converges to a global minimum of the implicit neural network with ReLU activation."
INTRODUCTION,0.025029797377830752,The main contributions of this paper are summarized as follows:
INTRODUCTION,0.026221692491060787,"(i) By scaling the weight matrix A with a ﬁxed scalar γ, we show that the unique equilibrium
point z∗for each x always exists during the training if the parameters are randomly initialized,
even for the nonlinear ReLU activation function.
(ii) We analyze the gradient ﬂow of implicit neural networks. Despite the non-smooth and non-
convexity of the objective function, the convergence to a global minimum at a linear rate is
guaranteed if the implicit neural network is over-parameterized and the data is non-degenerate.
(iii) Since gradient descent is discretized version of gradient ﬂow, we can show gradient descent
with ﬁxed stepsize converges to a global minimum of implicit neural networks at a linear rate
under the same assumptions made by the gradient ﬂow analysis, as long as the stepsize is
chosen small enough."
INTRODUCTION,0.027413587604290822,"Notation: For a vector x, ∥x∥is the Euclidean norm of x. For a matrix A, ∥A∥is the operator
norm of A. If A is a square matrix, then λmin(A) and λmax(A) denote the smallest and largest
eigenvalue of A, respectively, and λmax(A) ≤∥A∥. We denote [n] ≜{1, 2, · · · , n}."
WELL-POSEDNESS AND GRADIENT COMPUTATION,0.028605482717520857,"2
WELL-POSEDNESS AND GRADIENT COMPUTATION"
WELL-POSEDNESS AND GRADIENT COMPUTATION,0.029797377830750895,"In this section, we provide a simple condition for the equilibrium equation (3) to be well-posed in the
sense that the unique equilibrium point exists. Instead of backpropagating through all the intermedi-
ate iterations of a forward pass, we derive the gradients of trainable parameters by using the implicit
function theorem. In this work, we make the following assumption on parameter initialization.
Assumption 1 (Random Initialization). The entries Aij and Wij are randomly initialized by the
standard Gaussian distribution N(0, 1), and ui and vi are randomly initialized by the symmetric
Bernoulli or Rademacher distribution.
Remark 2.1. This initialization is similar to the approaches widely used in practice (Glorot &
Bengio, 2010; He et al., 2015). The result obtained in this work can be easily extended to the case
where the distributions for Aij, Wij, ui, and vi are replaced by sub-Gaussian random variables."
FORWARD PROPAGATION AND WELL-POSEDNESS,0.03098927294398093,"2.1
FORWARD PROPAGATION AND WELL-POSEDNESS"
FORWARD PROPAGATION AND WELL-POSEDNESS,0.03218116805721097,"In a general implicit neural network, Eq. (3) is not necessarily well-posed, since it may admit zero
or multiple solutions. In this work, we show that scaling the matrix A with ˜γ = γ/√m guarantees"
FORWARD PROPAGATION AND WELL-POSEDNESS,0.033373063170441,"the existence and uniqueness of the equilibrium point z∗with random initialization. This follows
from a foundational result in random matrix theory as restated in the following lemma.
Lemma 2.1 (Vershynin (2018), Theorem 4.4.5). Let A be an m × n random matrix whose entries
Aij are independent, zero-mean, and sub-Gaussian random variables. Then, for any t > 0, we have
∥A∥≤CK(√m + √n + t) with probability at least 1 −2e−t2. Here C > 0 is a ﬁxed constant,
and K = maxi,j ∥Aij∥ψ2."
FORWARD PROPAGATION AND WELL-POSEDNESS,0.03456495828367104,"Under Assumption 1, Lemma 2.1 implies that, with exponentially high probability, ∥A∥≤c√m
for some constant c > 0. By scaling A by a positive scalar ˜γ, we show that the transition Eq. (1) is a
contraction mapping. Thus, the unique equilibrium point exists with detailed proof in Appendix A.1.
Lemma 2.2. If ∥A∥≤c√m for some c > 0, then for any γ0 ∈(0, 1), the scalar γ ≜min{γ0, γ0/c}
uniquely determines the existence of the equilibrium z∗for every x, and ∥zℓ∥≤
1
1−γ0 ∥φ∥for all ℓ."
FORWARD PROPAGATION AND WELL-POSEDNESS,0.03575685339690107,"Lemma 2.2 indicates that equilibria always exist if we can maintain the operator norm of the scaled
matrix (γ/√m)A less than 1 during the training. However, the operator norms of matrix A are
changed by the update of the gradient descent. It is hard to use a ﬁxed scalar γ to scale the matrix
A over all iterations, unless the operator norm of A is bounded. In Section 3, we will show ∥A∥≤
2c√m always holds throughout the training, provided that ∥A(0)∥≤c√m at initialization and the
width m is sufﬁciently large. Thus, by using the scalar γ = min{γ0, γ0/(2c)} for any γ0 ∈(0, 1),
equilibria always exist and the equilibrium equation Eq. (3) is well-posed."
BACKWARD GRADIENT COMPUTING,0.03694874851013111,"2.2
BACKWARD GRADIENT COMPUTING"
BACKWARD GRADIENT COMPUTING,0.03814064362336114,"For a regular network with ﬁnite layers, one needs to store all intermediate parameters and apply
backpropagation to compute the gradients. In contrast, for an implicit neural network, we can derive
the formula of the gradients by using the implicit function theorem. Here, the equilibrium point
z∗is a root of the function f given by f(z, A, W ) ≜z −σ (˜γAz + φ). The essential challenge
is to ensure the partial derivative ∂f/∂z at z∗is always invertible throughout the training. The
following lemma shows that the partial derivative ∂f/∂z at z∗always exists with the scalar γ,
and the gradient derived in the lemma always exists. The gradient derivations for each trainable
parameters are provided in the following lemma and the proof is provided in Appendix A.2.
Lemma 2.3 (Gradients of an Implicit Neural Network). Deﬁne the scalar γ ≜min{γ0, γ0/c}. If
∥A∥≤c√m for some constant c > 0, then for any γ0 ∈(0, 1), the following results hold:"
BACKWARD GRADIENT COMPUTING,0.03933253873659118,"(i) The partial derivatives of f with respect to z, A, and W are
∂f
∂z = [Im −˜γ diag(σ′(˜γAz + φ))A]T ,
(6)"
BACKWARD GRADIENT COMPUTING,0.04052443384982122,"∂f
∂A = −˜γ

zT ⊗diag(σ′(˜γAz + φ))
T ,
(7)"
BACKWARD GRADIENT COMPUTING,0.041716328963051254,"∂f
∂W = −1
√m"
BACKWARD GRADIENT COMPUTING,0.04290822407628129,"
xT ⊗diag(σ′(W x))
T diag(σ′(˜γAz + φ))T ,
(8)"
BACKWARD GRADIENT COMPUTING,0.04410011918951132,where ˜γ ≜γ/√m.
BACKWARD GRADIENT COMPUTING,0.04529201430274136,"(ii) For any vector v, the following inequality holds
λmin {Im −˜γ diag(σ′(v))A} > 1 −γ0 > 0,
(9)
which further implies ∂f/∂z is invertible at the equilibrium point z∗."
BACKWARD GRADIENT COMPUTING,0.04648390941597139,"(iii) The gradient of the objective function L with respect to A and W are given by ∇uL = n
X"
BACKWARD GRADIENT COMPUTING,0.04767580452920143,"i=1
(ˆyi −yi)zi,
∇vL = n
X"
BACKWARD GRADIENT COMPUTING,0.04886769964243146,"i=1
(ˆyi −yi)φi,
(10) ∇AL = n
X"
BACKWARD GRADIENT COMPUTING,0.050059594755661505,"i=1
˜γ(ˆyi −yi)DT
i [Im −˜γDiA]−T uzT
i ,
(11)"
BACKWARD GRADIENT COMPUTING,0.05125148986889154,"∇W L = n
X i=1"
BACKWARD GRADIENT COMPUTING,0.052443384982121574,"1
√m(ˆyi −yi)ET
i
n
DT
i [Im −˜γDiA]−T u + v
o
xT
i ,
(12)"
BACKWARD GRADIENT COMPUTING,0.05363528009535161,"where zi is the equilibrium point for the training data (xi, yi), Di ≜diag(σ′(˜γAzi + φi)),
and Ei ≜diag(σ′(W xi))."
GLOBAL CONVERGENCE OF THE GRADIENT DESCENT METHOD,0.054827175208581644,"3
GLOBAL CONVERGENCE OF THE GRADIENT DESCENT METHOD"
GLOBAL CONVERGENCE OF THE GRADIENT DESCENT METHOD,0.05601907032181168,"In this section, we establish the global convergence results of the gradient descent method in im-
plicit neural networks. In Section 3.1, we ﬁrst study the dynamics of the prediction induced by the
gradient ﬂow, that is, the gradient descent with inﬁnitesimal step-size. We show that the dynamics
of the prediction is controlled by a Gram matrix whose smallest eigenvalue is strictly positive over
iterations with high probability. Based on the ﬁndings in gradient ﬂow, we will show that the ran-
dom initialized gradient descent method with a constant step-size converges to a global minimum at
a linear rate in Section 3.2."
CONTINUOUS TIME ANALYSIS,0.057210965435041714,"3.1
CONTINUOUS TIME ANALYSIS"
CONTINUOUS TIME ANALYSIS,0.058402860548271755,"The gradient ﬂow is equivalent to the gradient descent method with an inﬁnitesimal step-size. Thus,
the analysis of gradient ﬂow can serve as a stepping stone towards understanding discrete-time
gradient-based algorithms. Following previous works on gradient ﬂow of different machine learning
models (Saxe et al., 2013; Du et al., 2019; Arora et al., 2018; Kawaguchi, 2021) the gradient ﬂow of
implicit neural networks is given by the following ordinary differential equations:
dvec (A)"
CONTINUOUS TIME ANALYSIS,0.05959475566150179,"dt
= −∂L(t)"
CONTINUOUS TIME ANALYSIS,0.060786650774731825,"∂A ,
dvec (W )"
CONTINUOUS TIME ANALYSIS,0.06197854588796186,"dt
= −∂L(t)"
CONTINUOUS TIME ANALYSIS,0.0631704410011919,"∂W ,
du"
CONTINUOUS TIME ANALYSIS,0.06436233611442194,dt = −∂L(t)
CONTINUOUS TIME ANALYSIS,0.06555423122765197,"∂u ,
dv"
CONTINUOUS TIME ANALYSIS,0.066746126340882,dt = −∂L(t)
CONTINUOUS TIME ANALYSIS,0.06793802145411204,"∂v ,
(13)"
CONTINUOUS TIME ANALYSIS,0.06912991656734208,where L(t) represents the value of the objective function L(θ) at time t.
CONTINUOUS TIME ANALYSIS,0.07032181168057211,"Our results relies on the analysis of the dynamics of prediction ˆy(t). In particular, Lemma 3.1 shows
that the dynamics of prediction ˆy(t) is governed by the spectral property of a Gram matrix H(t).
Lemma 3.1 (Dynamics of Prediction ˆy(t)). Suppose ∥A(s)∥≤c√m for all 0 ≤s ≤t. Let
X ∈Rn×d, Φ(s) ∈Rn×m, and Z(s) ∈Rn×m be the matrices whose rows are the training data xi,
feature vectors φi, and equilibrium points zi at time s, respectively. With scalar γ ≜min{γ0, γ0/c}
for any γ0 ∈(0, 1), the dynamics of prediction ˆy(t) is given by
dˆy"
CONTINUOUS TIME ANALYSIS,0.07151370679380215,"dt = −

(γ2M(t) + In) ◦Z(t)Z(t)T + Q(t) ◦XXT + Φ(t)Φ(t)T 
(ˆy −y),"
CONTINUOUS TIME ANALYSIS,0.07270560190703218,"≜−H(t)(ˆy −y),
(14)"
CONTINUOUS TIME ANALYSIS,0.07389749702026222,"where ◦is the Hadamard product (i.e., element-wise product), and matrices M(t) ∈Rn×n and
Q(t) ∈Rn×n are deﬁned as follows:"
CONTINUOUS TIME ANALYSIS,0.07508939213349225,M(t)ij ≜1
CONTINUOUS TIME ANALYSIS,0.07628128724672228,"muT (Im −˜γDiA)−1DiDT
j (Im −˜γDjA)−T u,
(15)"
CONTINUOUS TIME ANALYSIS,0.07747318235995232,Q(t)ij ≜1
CONTINUOUS TIME ANALYSIS,0.07866507747318235,"m
 
DT
i (Im −˜γDiA)−1u + v
T EiET
j
 
DT
j (Im −˜γDjA)−T u + v

.
(16)"
CONTINUOUS TIME ANALYSIS,0.07985697258641239,"Note that the matrix H(t) is clearly positive semideﬁnite since it is the sum of three positive semidef-
inite matrices. If there exists a constant λ > 0 such that λmin{H(t)} ≥λ > 0 for all t, i.e., H(t)
is positive deﬁnite, then the dynamics of the loss function L(t) satisﬁes the following inequality
L(t) ≤exp{−λt}L(0),
which immediately indicates that the objective value L(t) is consistently decreasing to zero at a
geometric rate. With random initialization, we will show that H(t) is positive deﬁnite as long as
the number of parameters m is sufﬁciently large and no two data points are parallel to each other. In
particular, by using the nonlinearity of the feature map φ, we will show that the smallest eigenvalue
of the Gram matrix G(t) ≜Φ(t)Φ(t)T is strictly positive over all time t with high probability. As
a result, the smallest eigenvalue of H(t) is always strictly positive."
CONTINUOUS TIME ANALYSIS,0.08104886769964244,"Clearly, G(t) is a time-varying matrix. We ﬁrst analyze its spectral property at its initialization.
When t = 0, it follows from the deﬁnition of the feature vector φ in Eq. (2) that"
CONTINUOUS TIME ANALYSIS,0.08224076281287247,G(0) = Φ(0)Φ(0)T = 1
CONTINUOUS TIME ANALYSIS,0.08343265792610251,"mσ(XW (0)T )σ(XW (0)T )T = 1 m m
X"
CONTINUOUS TIME ANALYSIS,0.08462455303933254,"r=1
σ(Xwr(0))σ(Xwr(0))T ."
CONTINUOUS TIME ANALYSIS,0.08581644815256258,"By Assumption 1, each vector wr(0) follows the standard multivariate normal distribution, i.e.,
wr(0) ∼N(0, Id). By letting m →∞, we obtain the covariance matrix G∞∈Rn×n as follows:"
CONTINUOUS TIME ANALYSIS,0.08700834326579261,"G∞≜Ew∼N(0,Id)[σ(Xw)σ(Xw)T ].
(17)"
CONTINUOUS TIME ANALYSIS,0.08820023837902265,"Here G∞is a Gram matrix induced by the ReLU activation function and the random initialization.
The following lemma shows that the smallest eigenvalue of G∞is strictly positive as long as no
two data points are parallel. Moreover, later in Lemmas 3.3 and 3.4, we conclude that the spectral
property of G∞is preserved in the Gram matrices G(0) and G(t) during the training, as long as the
number of parameter m is sufﬁciently large."
CONTINUOUS TIME ANALYSIS,0.08939213349225268,"Lemma 3.2. Assume ∥xi∥= 1 for all i ∈[n]. If xi ̸∥xj for all i ̸= j, then λ0 ≜λmin{G∞} > 0."
CONTINUOUS TIME ANALYSIS,0.09058402860548272,"Proof. The proof follows from the Hermite Expansions of the matrix G∞and the complete proof is
provided in Appendix A.4."
CONTINUOUS TIME ANALYSIS,0.09177592371871275,"Assumption 2 (Training Data). Without loss of generality, we can assume that each xi is normalized
to have a unit norm, i.e., ∥xi∥= 1, for all i ∈[n]. Moreover, we assume xi ̸∥xj for all i ̸= j."
CONTINUOUS TIME ANALYSIS,0.09296781883194279,"In most real-world datasets, it is extremely rare that two data samples are parallel. If this happens,
by adding some random noise perturbation to the data samples, Assumption 2 can still be satisﬁed.
Next, we show that at the initialization, the spectral property of G∞is preserved in G(0) if m
is sufﬁciently large. Speciﬁcally, the following lemma shows that if m = ˜Ω(n2), then G(0) has
a strictly positive smallest eigenvalue with high probability. The proof follows from the standard
concentration bound for Gaussian random variables, and we relegate the proof to Appendix A.5."
CONTINUOUS TIME ANALYSIS,0.09415971394517282,"Lemma 3.3. Let λ0 = λmin(G∞) > 0. If m = Ω

n2"
CONTINUOUS TIME ANALYSIS,0.09535160905840286,"λ2
0 log
  n"
CONTINUOUS TIME ANALYSIS,0.09654350417163289,"δ

, then with probability of at least"
CONTINUOUS TIME ANALYSIS,0.09773539928486293,"1 −δ, it holds that ∥G(0) −G∞∥2 ≤λ0"
CONTINUOUS TIME ANALYSIS,0.09892729439809297,"4 , and hence λmin(G(0)) ≥3 4λ0."
CONTINUOUS TIME ANALYSIS,0.10011918951132301,"During training, G(t) is time-varying, but it can be shown to be close to G(0) and preserve the
spectral property of G∞, if the matrices W (t) has a bounded operator norm and it is not far away
from W (0). This result is formally stated below and its proof is provided in Appendix A.6."
CONTINUOUS TIME ANALYSIS,0.10131108462455304,"Lemma 3.4. Suppose ∥W (0)∥≤c√m, and λmin{G(0)} ≥3"
CONTINUOUS TIME ANALYSIS,0.10250297973778308,4λ0. For any matrix W ∈Rm×d
CONTINUOUS TIME ANALYSIS,0.10369487485101311,"that satisﬁes ∥W ∥≤2c√m and ∥W −W (0)∥≤
√mλ0
16c∥X∥2 ≜R, the matrix deﬁned by G ≜"
CONTINUOUS TIME ANALYSIS,0.10488676996424315,"1
mσ(XW T )σ(XW T )T satisﬁes ∥G −G(0)∥≤λ0"
CONTINUOUS TIME ANALYSIS,0.10607866507747318,4 and λmin(G) ≥λ0 2 .
CONTINUOUS TIME ANALYSIS,0.10727056019070322,"The next lemma shows three facts: (1) The smallest eigenvalue of G(t) is strictly positive for all
t ≥0; (2) The objective value L(t) converges to zero at a linear convergence rate; (3) The (operator)
norms of all trainable parameters are upper bounded by some constants, which further implies that
unique equilibrium points in matrices Z(t) always exist. We prove this lemma by induction, which
is provided in Appendix A.7.
Lemma 3.5. Suppose that ∥u(0)∥= √m, ∥v(0)∥= √m, ∥W (0)∥≤c√m, ∥A(0)∥≤c√m, and"
CONTINUOUS TIME ANALYSIS,0.10846245530393325,λmin{G(0)} ≥3
CONTINUOUS TIME ANALYSIS,0.10965435041716329,"4λ0 > 0. If m = Ω

c2n∥X∥2"
CONTINUOUS TIME ANALYSIS,0.11084624553039332,"λ3
0
∥ˆy(0) −y∥2
and 0 < γ ≤min{ 1 2, 1"
CONTINUOUS TIME ANALYSIS,0.11203814064362336,"4c}, then for
any t ≥0, the following results hold:"
CONTINUOUS TIME ANALYSIS,0.11323003575685339,"(i) λmin(G(t)) ≥λ0 2 ,"
CONTINUOUS TIME ANALYSIS,0.11442193087008343,(ii) ∥u(t)∥≤16c√n
CONTINUOUS TIME ANALYSIS,0.11561382598331346,"λ0
∥ˆy(0) −y∥,"
CONTINUOUS TIME ANALYSIS,0.11680572109654351,(iii) ∥v(t)∥≤8c√n
CONTINUOUS TIME ANALYSIS,0.11799761620977355,"λ0 ∥ˆy(0) −y∥,"
CONTINUOUS TIME ANALYSIS,0.11918951132300358,"(iv) ∥W (t)∥≤2c√m,"
CONTINUOUS TIME ANALYSIS,0.12038140643623362,"(v) ∥A(t)∥≤2c√m,"
CONTINUOUS TIME ANALYSIS,0.12157330154946365,(vi) ∥ˆy(t) −y∥2 ≤exp{−λ0t}∥ˆy(0) −y∥2.
CONTINUOUS TIME ANALYSIS,0.12276519666269368,"By using simple union bounds in Lemma 2.1 and 3.5, we immediately obtain the global convergence
result for the gradent ﬂow as follows."
CONTINUOUS TIME ANALYSIS,0.12395709177592372,"Theorem 3.1 (Convergence Rate of Gradient Flow). Suppose that Assumptions 1 and 2 hold. If
we set the number of parameter m = Ω

n2"
CONTINUOUS TIME ANALYSIS,0.12514898688915377,"λ2
0 log
  n"
CONTINUOUS TIME ANALYSIS,0.1263408820023838,"δ

and choose 0 < γ ≤min{ 1 2, 1"
CONTINUOUS TIME ANALYSIS,0.12753277711561384,"4c}, then with
probability at least 1 −δ over the initialization, we have
∥ˆy(t) −y∥2 ≤exp{−λ0t}∥ˆy(0) −y∥2,
∀t ≥0."
CONTINUOUS TIME ANALYSIS,0.12872467222884387,"This theorem establishes the global convergence of the gradient ﬂow. Despite the nonconvexity of
the objective function L(θ), Theorem 3.1 shows that if m is sufﬁciently large, then the objective
value is consistently decreasing to zero at a geometric rate. In particular, Theorem 3.1 requires
m = ˜Ω(n2), which is similar or even better than recent results for the neural network with ﬁnite
layers (Nguyen & Mondelli, 2020; Oymak & Soltanolkotabi, 2020; Allen-Zhu et al., 2019; Zou &
Gu, 2019; Du et al., 2019). In particular, previous results showed that m is a polynomial of the
number of training sample n and the number of layers h, i.e., m = Ω(nαhβ) with α ≥2 and
β ≥12 (Nguyen & Mondelli, 2020, Table 1). These results do not apply in our case since we have
inﬁnitely many layers. By taking advantage of the nonlinear feature mapping function, we establish
the global convergence for the gradient ﬂow with m independent of depth h."
DISCRETE TIME ANALYSIS,0.1299165673420739,"3.2
DISCRETE TIME ANALYSIS"
DISCRETE TIME ANALYSIS,0.13110846245530394,"In this section, we show that the randomly initialized gradient descent method with a ﬁxed step-
size converges to a global minimum at a linear rate. With similar argument used in the analysis
of gradient ﬂow, we can show the (operator) norms of the training parameters are upper bounded
by some constants. It is worth noting that, unlike the analysis of gradient ﬂow, we do not have an
explicit formula for the dynamics of prediction ˆy(t) in the discrete time analysis. Instead, we have to
show the difference between the equilibrium points Z(k) in two consecutive iterations are bounded.
Based on this, we can further bound the changes in the predictions ˆy(k) between two consecutive
iterations. Another challenge is to show the objective value consistently decreases over iterations.
A general strategy is to show the objective function is (semi-)smooth with respect to parameter θ,
and apply the descent lemma to the objective function (Nguyen & Mondelli, 2020; Allen-Zhu et al.,
2019; Zou & Gu, 2019). In this section, we take advantage of the nonlinear feature mapping function
in Eq. (4). Consequently, we are able to obtain a Polyak-Łojasiewicz-like condition (Karimi et al.,
2016; Nguyen, 2021), which allows us to provide a much simpler proof."
DISCRETE TIME ANALYSIS,0.13230035756853398,"The following lemma establishes the global convergence for the gradient descent method with a
ﬁxed step-size when the operator norms of A(0) and W (0) are bounded and λmin(G(0)) > 0. The
proof is proved in Appendix A.8.
Lemma 3.6 (Gradient Descent Convergence Rate). Suppose ∥u(0)∥= √m, ∥v(0)∥= √m,
∥W (0)∥≤c√m, ∥A(0)∥≤c√m, and λmin{G(0)} ≥
3
4λ0 > 0. If 0 < γ ≤min{ 1 2, 1 4c},"
DISCRETE TIME ANALYSIS,0.133492252681764,"m = Ω

c2n∥X∥2"
DISCRETE TIME ANALYSIS,0.13468414779499405,"λ3
0
∥ˆy(0) −y∥2
, and stepsize α = O
 
λ0/n2
, then for any k ≥0, we have"
DISCRETE TIME ANALYSIS,0.13587604290822408,"(i) λmin(G(k)) ≥λ0 2 ,"
DISCRETE TIME ANALYSIS,0.13706793802145412,(ii) ∥u(k)∥≤32c√n
DISCRETE TIME ANALYSIS,0.13825983313468415,"λ0
∥ˆy(0) −y∥,"
DISCRETE TIME ANALYSIS,0.1394517282479142,(iii) ∥v(k)∥≤16c√n
DISCRETE TIME ANALYSIS,0.14064362336114422,"λ0
∥ˆy(0) −y∥,"
DISCRETE TIME ANALYSIS,0.14183551847437426,"(iv) ∥W (k)∥≤2c√m,"
DISCRETE TIME ANALYSIS,0.1430274135876043,"(v) ∥A(k)∥≤2c√m,"
DISCRETE TIME ANALYSIS,0.14421930870083433,(vi) ∥ˆy(k) −y∥2 ≤(1 −αλ0/2)k∥ˆy(0) −y∥2.
DISCRETE TIME ANALYSIS,0.14541120381406436,"By using simple union bounds to combine Lemma 2.1 and 3.6, we obtain the global convergence
result for the gradient descent.
Theorem 3.2 (Convergence Rate of Gradient Descent). Suppose that Assumption 1 and 2 hold. If
we set m = Ω

n2
λ0 log
  n"
DISCRETE TIME ANALYSIS,0.1466030989272944,"δ

, 0 < γ ≤min{ 1 2, 1"
DISCRETE TIME ANALYSIS,0.14779499404052443,"4c}, and choose step-size α = O
 
λ0/n2
, then
with probability at least 1 −δ over the initialization, we have"
DISCRETE TIME ANALYSIS,0.14898688915375446,"∥ˆy(k) −y∥2 ≤(1 −αλ0/2)k∥ˆy(0) −y∥2,
∀k ≥0."
DISCRETE TIME ANALYSIS,0.1501787842669845,"0
200
400
600
800
1000
epoch 4.5 4.0 3.5 3.0 2.5 2.0 1.5 1.0 0.5"
DISCRETE TIME ANALYSIS,0.15137067938021453,log(loss)
DISCRETE TIME ANALYSIS,0.15256257449344457,train loss
DISCRETE TIME ANALYSIS,0.1537544696066746,"width 500
width 1000
width 2000
width 4000"
DISCRETE TIME ANALYSIS,0.15494636471990464,(a) Training loss
DISCRETE TIME ANALYSIS,0.15613825983313467,"0
200
400
600
800
1000
epoch 4.0 3.5 3.0 2.5 2.0 1.5 1.0"
DISCRETE TIME ANALYSIS,0.1573301549463647,log(loss)
DISCRETE TIME ANALYSIS,0.15852205005959474,test loss
DISCRETE TIME ANALYSIS,0.15971394517282478,"width 500
width 1000
width 2000
width 4000"
DISCRETE TIME ANALYSIS,0.16090584028605484,(b) Test loss
DISCRETE TIME ANALYSIS,0.16209773539928488,"0
200
400
600
800
1000
epoch"
DISCRETE TIME ANALYSIS,0.1632896305125149,0.1980
DISCRETE TIME ANALYSIS,0.16448152562574495,0.1982
DISCRETE TIME ANALYSIS,0.16567342073897498,0.1984
DISCRETE TIME ANALYSIS,0.16686531585220502,0.1986
DISCRETE TIME ANALYSIS,0.16805721096543505,0.1988
DISCRETE TIME ANALYSIS,0.16924910607866508,0.1990
DISCRETE TIME ANALYSIS,0.17044100119189512,0.1992
DISCRETE TIME ANALYSIS,0.17163289630512515,operator norm
DISCRETE TIME ANALYSIS,0.1728247914183552,operator norm of layer
DISCRETE TIME ANALYSIS,0.17401668653158522,"width 500
width 1000
width 2000
width 4000"
DISCRETE TIME ANALYSIS,0.17520858164481526,(c) Operator norms
DISCRETE TIME ANALYSIS,0.1764004767580453,"0
200
400
600
800
1000
epoch 3.0 2.5 2.0 1.5 1.0 0.5"
DISCRETE TIME ANALYSIS,0.17759237187127533,log(loss)
DISCRETE TIME ANALYSIS,0.17878426698450536,train loss
DISCRETE TIME ANALYSIS,0.1799761620977354,"width 500
width 1000
width 2000
width 4000"
DISCRETE TIME ANALYSIS,0.18116805721096543,(d) Training loss
DISCRETE TIME ANALYSIS,0.18235995232419547,"0
200
400
600
800
1000
epoch 3.0 2.5 2.0 1.5 1.0"
DISCRETE TIME ANALYSIS,0.1835518474374255,log(loss)
DISCRETE TIME ANALYSIS,0.18474374255065554,test loss
DISCRETE TIME ANALYSIS,0.18593563766388557,"width 500
width 1000
width 2000
width 4000"
DISCRETE TIME ANALYSIS,0.1871275327771156,(e) Test loss
DISCRETE TIME ANALYSIS,0.18831942789034564,"0
200
400
600
800
1000
epoch"
DISCRETE TIME ANALYSIS,0.18951132300357568,0.1980
DISCRETE TIME ANALYSIS,0.1907032181168057,0.1982
DISCRETE TIME ANALYSIS,0.19189511323003575,0.1984
DISCRETE TIME ANALYSIS,0.19308700834326578,0.1986
DISCRETE TIME ANALYSIS,0.19427890345649582,0.1988
DISCRETE TIME ANALYSIS,0.19547079856972585,0.1990
DISCRETE TIME ANALYSIS,0.1966626936829559,0.1992
DISCRETE TIME ANALYSIS,0.19785458879618595,operator norm
DISCRETE TIME ANALYSIS,0.19904648390941598,operator norm of layer
DISCRETE TIME ANALYSIS,0.20023837902264602,"width 500
width 1000
width 2000
width 4000"
DISCRETE TIME ANALYSIS,0.20143027413587605,(f) Operator norms
DISCRETE TIME ANALYSIS,0.2026221692491061,"0
200
400
600
800
1000
epoch 1.8 1.6 1.4 1.2 1.0 0.8 0.6 0.4"
DISCRETE TIME ANALYSIS,0.20381406436233612,log(loss)
DISCRETE TIME ANALYSIS,0.20500595947556616,train loss
DISCRETE TIME ANALYSIS,0.2061978545887962,"width 500
width 1000
width 2000
width 4000"
DISCRETE TIME ANALYSIS,0.20738974970202623,(g) Training loss
DISCRETE TIME ANALYSIS,0.20858164481525626,"0
200
400
600
800
1000
epoch 1.8 1.6 1.4 1.2 1.0 0.8 0.6"
DISCRETE TIME ANALYSIS,0.2097735399284863,log(loss)
DISCRETE TIME ANALYSIS,0.21096543504171633,test loss
DISCRETE TIME ANALYSIS,0.21215733015494637,"width 500
width 1000
width 2000
width 4000"
DISCRETE TIME ANALYSIS,0.2133492252681764,(h) Test loss
DISCRETE TIME ANALYSIS,0.21454112038140644,"0
200
400
600
800
1000
epoch"
DISCRETE TIME ANALYSIS,0.21573301549463647,0.1980
DISCRETE TIME ANALYSIS,0.2169249106078665,0.1982
DISCRETE TIME ANALYSIS,0.21811680572109654,0.1984
DISCRETE TIME ANALYSIS,0.21930870083432658,0.1986
DISCRETE TIME ANALYSIS,0.2205005959475566,0.1988
DISCRETE TIME ANALYSIS,0.22169249106078665,0.1990
DISCRETE TIME ANALYSIS,0.22288438617401668,0.1992
DISCRETE TIME ANALYSIS,0.22407628128724671,operator norm
DISCRETE TIME ANALYSIS,0.22526817640047675,operator norm of layer
DISCRETE TIME ANALYSIS,0.22646007151370678,"width 500
width 1000
width 2000
width 4000"
DISCRETE TIME ANALYSIS,0.22765196662693682,(i) Operator norms
DISCRETE TIME ANALYSIS,0.22884386174016685,"0
200
400
600
800
1000
epoch 1.8 1.6 1.4 1.2 1.0 0.8 0.6 0.4"
DISCRETE TIME ANALYSIS,0.2300357568533969,log(loss)
DISCRETE TIME ANALYSIS,0.23122765196662692,train loss
DISCRETE TIME ANALYSIS,0.232419547079857,"width 500
width 1000
width 2000
width 4000"
DISCRETE TIME ANALYSIS,0.23361144219308702,(j) Training loss
DISCRETE TIME ANALYSIS,0.23480333730631706,"0
200
400
600
800
1000
epoch 1.6 1.4 1.2 1.0 0.8"
DISCRETE TIME ANALYSIS,0.2359952324195471,log(loss)
DISCRETE TIME ANALYSIS,0.23718712753277713,test loss
DISCRETE TIME ANALYSIS,0.23837902264600716,"width 500
width 1000
width 2000
width 4000"
DISCRETE TIME ANALYSIS,0.2395709177592372,(k) Test loss
DISCRETE TIME ANALYSIS,0.24076281287246723,"0
200
400
600
800
1000
epoch"
DISCRETE TIME ANALYSIS,0.24195470798569726,0.1980
DISCRETE TIME ANALYSIS,0.2431466030989273,0.1982
DISCRETE TIME ANALYSIS,0.24433849821215733,0.1984
DISCRETE TIME ANALYSIS,0.24553039332538737,0.1986
DISCRETE TIME ANALYSIS,0.2467222884386174,0.1988
DISCRETE TIME ANALYSIS,0.24791418355184744,0.1990
DISCRETE TIME ANALYSIS,0.24910607866507747,0.1992
DISCRETE TIME ANALYSIS,0.25029797377830754,operator norm
DISCRETE TIME ANALYSIS,0.25148986889153757,operator norm of layer
DISCRETE TIME ANALYSIS,0.2526817640047676,"width 500
width 1000
width 2000
width 4000"
DISCRETE TIME ANALYSIS,0.25387365911799764,(l) Operator norms
DISCRETE TIME ANALYSIS,0.2550655542312277,"Figure 1: Results on MNIST, FashionMNIST, CIFAR10, and SVHN. We evaluate the impact of the
width m on the training loss, test loss, and operator norm of the scaled matrix (γ/√m)A(k) on four
real datasets."
EXPERIMENTAL RESULTS,0.2562574493444577,"4
EXPERIMENTAL RESULTS"
EXPERIMENTAL RESULTS,0.25744934445768775,"In this section, we use real-world datasets MNST, FashionMNST, CIFAR10, and SVHN to evalu-
ate our theoretical ﬁndings. We initialize the entries of parameters A, W , u, and v by standard
Gaussian or symmetric Bernoulli distribution independently as suggested in Assumption 1. For
each dataset, we only use classes 0 and 1, and 500 samples are randomly drawn from each class
to generate the training dataset with n = 1000 samples. All data samples are converted to gray
scale and resized into a 28 × 28 pixel image. We also normalize each data to have unit norm. If
two parallel samples are observed, we add a random Gaussian noise perturbation to one of them.
Thus, Assumption 2 is also satisﬁed. We run 1000 epochs of gradient descent with a ﬁxed step-size.
We test three metrics with different width m. We ﬁrst test how the extent of over-parameterization"
EXPERIMENTAL RESULTS,0.2586412395709178,"affects the convergence rates. Then, we test the relation between the extent of over-parameterization
and the operator norms between matrix A(k) and its initialization. Note that the “operator norm” in
the plots denotes the operator norm of the scaled matrix (γ/√m)∥A(k)∥. Third, we test the extent
of over-parameterization and the performance of the trained neural network on the unseen test data.
Similar to the training dataset, We randomly select 500 samples from each class as the test dataset."
EXPERIMENTAL RESULTS,0.2598331346841478,"From Figure 1, the ﬁgures in the ﬁrst column show that as m becomes larger, we have better conver-
gence rates. The ﬁgures in the second column show that as m becomes larger, the neural networks
achieve lower test loss. The ﬁgures in the third column show that the operator norms are slightly
larger for larger m but overall the operator norms are approximately equal to its initialization. The
bell curve from the classical bias-variance trade-off does not appear. This opens the door to a new re-
search direction in implicit neural networks in the analyses of generalization error and bias-variance
trade-off."
RELATED WORKS,0.26102502979737785,"5
RELATED WORKS"
RELATED WORKS,0.2622169249106079,"Implicit models has been explored explored by the deep learning community for decades. For ex-
ample, Pineda (1987) and ALMEIDA (1987) studied implicit differentiation techniques for training
recurrent dynamics, also known as recurrent back-propagation (Liao et al., 2018). Recently, there
has been renewed interested in the implicit models in the deep learning community (El Ghaoui
et al., 2019; Gould et al., 2019). For example, Bai et al. (2019) introduces an implicit neural net-
work called deep equilibrium model for the for the task of sequence modeling. By using implicit
ODE solvers, Chen et al. (2018) proposed neural ordinary differential equation as an implicit resid-
ual network with continuous-depth. Other instantiations of implicit modeling include optimization
layers (Djolonga & Krause, 2017; Amos & Kolter, 2017), differentiable physics engines (de Avila
Belbute-Peres et al., 2018; Qiao et al., 2020), logical structure learning (Wang et al., 2019), and
continuous generative models (Grathwohl et al., 2019)."
RELATED WORKS,0.2634088200238379,"The theoretical study of training ﬁnite-layer neural networks via over-parameterization has been an
active research area. Jacot et al. (2018) showed the trajectory of the gradient descent method can
be characterized by a kernel called neural tangent kernel for smooth activation and inﬁnitely width
neural networks. For a ﬁnite-width neural network with smooth or ReLU activation, Arora et al.
(2019); Du et al. (2019); Li & Liang (2018) showed that the dynamics of the neural network is gov-
erned by a Gram matrix. Consequently, Zou et al. (2020); Du et al. (2019); Allen-Zhu et al. (2019);
Nguyen & Mondelli (2020); Arora et al. (2019); Zou & Gu (2019); Oymak & Soltanolkotabi (2020)
showed that (stochastic) gradient descent can attain global convergence for training a ﬁnite-layer
neural network when the width m is a polynomial of the sample size n and the depth h. However,
their results cannot be applied directly to implicit neural networks since implicit neural networks
have inﬁnite layers and the equilibrium equation may not be well-posed. Our work establishes the
well-posedness of the equilibrium equation even if the width m is only square of the sample size n."
CONCLUSION AND FUTURE WORK,0.26460071513706795,"6
CONCLUSION AND FUTURE WORK"
CONCLUSION AND FUTURE WORK,0.265792610250298,"In this paper, we provided a convergence theory for implicit neural networks with ReLU activation
in the over-parameterization regime. We showed that the random initialized gradient descent method
with ﬁxed step-size converges to a global minimum of the loss function at a linear rate if the width
m = ˜Ω(n2). In particular, by using a ﬁxed scalar γ ∈(0, 1) to scale the random initialized weight
matrix A, we proved that the equilibrium equation is always well-posed throughout the training. By
analyzing the gradient ﬂow, we observe that the dynamics of the prediction vector is controlled by a
Gram matrix whose smallest eigenvalue is lower bounded by a strictly positive constant as long as
m = ˜Ω(n2). We envision several potential future directions based on the observations made in the
experiments. First, we believe that our analysis can be generalized to implicit neural networks with
other scaling techniques and initialization. Here, we use a scalar γ/√m to ensure the existence of
the equilibrium point z∗with random initialization. With an appropriate normalization, the global
convergence for identity initialization can be obtained. Second, we believe that the width m not
only improves the convergence rates but also the generalization performance. In particular, our
experimental results showed that with a larger m value, the test loss is reduced while the classical
bell curve of bias-variance trade-off is not observed."
CONCLUSION AND FUTURE WORK,0.266984505363528,ACKNOWLEDGMENTS
CONCLUSION AND FUTURE WORK,0.26817640047675806,"This work has been supported in part by National Science Foundation grants III-2104797,
DMS1812666, CAREER CNS-2110259, CNS-2112471, CNS-2102233, CCF-2110252, CNS-21-
20448, CCF-19-34884 and a Google Faculty Research Award."
REFERENCES,0.2693682955899881,REFERENCES
REFERENCES,0.27056019070321813,"Zeyuan Allen-Zhu, Yuanzhi Li, and Zhao Song. A convergence theory for deep learning via over-
parameterization. In International Conference on Machine Learning, pp. 242–252. PMLR, 2019."
REFERENCES,0.27175208581644816,"LB ALMEIDA. A learning rule for asynchronous perceptrons with feedback in a combinatorial
environment. In Proceedings, 1st First International Conference on Neural Networks, volume 2,
pp. 609–618. IEEE, 1987."
REFERENCES,0.2729439809296782,"Brandon Amos and J Zico Kolter. Optnet: Differentiable optimization as a layer in neural networks.
In International Conference on Machine Learning, pp. 136–145. PMLR, 2017."
REFERENCES,0.27413587604290823,"Sanjeev Arora, Nadav Cohen, Noah Golowich, and Wei Hu. A convergence analysis of gradient
descent for deep linear neural networks. arXiv preprint arXiv:1810.02281, 2018."
REFERENCES,0.27532777115613827,"Sanjeev Arora, Simon S Du, Wei Hu, Zhiyuan Li, Ruslan Salakhutdinov, and Ruosong Wang. On
exact computation with an inﬁnitely wide neural net. arXiv preprint arXiv:1904.11955, 2019."
REFERENCES,0.2765196662693683,"Shaojie Bai, J Zico Kolter, and Vladlen Koltun. Trellis networks for sequence modeling. arXiv
preprint arXiv:1810.06682, 2018."
REFERENCES,0.27771156138259834,"Shaojie Bai, J Zico Kolter, and Vladlen Koltun.
Deep equilibrium models.
arXiv preprint
arXiv:1909.01377, 2019."
REFERENCES,0.2789034564958284,"Shaojie Bai, Vladlen Koltun, and J Zico Kolter. Multiscale deep equilibrium models. arXiv preprint
arXiv:2006.08656, 2020."
REFERENCES,0.2800953516090584,"Ricky TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. Neural ordinary differ-
ential equations. arXiv preprint arXiv:1806.07366, 2018."
REFERENCES,0.28128724672228844,"Raj Dabre and Atsushi Fujita. Recurrent stacking of layers for compact neural machine translation
models. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 33, pp. 6292–
6299, 2019."
REFERENCES,0.2824791418355185,"Filipe de Avila Belbute-Peres, Kevin Smith, Kelsey Allen, Josh Tenenbaum, and J Zico Kolter. End-
to-end differentiable physics for learning and control. Advances in neural information processing
systems, 31:7178–7189, 2018."
REFERENCES,0.2836710369487485,"Mostafa Dehghani, Stephan Gouws, Oriol Vinyals, Jakob Uszkoreit, and Łukasz Kaiser. Universal
transformers. arXiv preprint arXiv:1807.03819, 2018."
REFERENCES,0.28486293206197855,"Josip Djolonga and Andreas Krause. Differentiable learning of submodular models. Advances in
Neural Information Processing Systems, 30:1013–1023, 2017."
REFERENCES,0.2860548271752086,"Simon Du, Jason Lee, Haochuan Li, Liwei Wang, and Xiyu Zhai. Gradient descent ﬁnds global
minima of deep neural networks. In International Conference on Machine Learning, pp. 1675–
1685. PMLR, 2019."
REFERENCES,0.2872467222884386,"Laurent El Ghaoui, Fangda Gu, Bertrand Travacca, Armin Askari, and Alicia Y Tsai. Implicit deep
learning. arXiv preprint arXiv:1908.06315, 2, 2019."
REFERENCES,0.28843861740166865,"Xavier Glorot and Yoshua Bengio. Understanding the difﬁculty of training deep feedforward neural
networks. In Proceedings of the thirteenth international conference on artiﬁcial intelligence and
statistics, pp. 249–256. JMLR Workshop and Conference Proceedings, 2010."
REFERENCES,0.2896305125148987,"Stephen Gould, Richard Hartley, and Dylan Campbell. Deep declarative networks: A new hope.
arXiv preprint arXiv:1909.04866, 2019."
REFERENCES,0.2908224076281287,"Will Grathwohl, Ricky T. Q. Chen, Jesse Bettencourt, Ilya Sutskever, and David Duvenaud. Ffjord:
Free-form continuous dynamics for scalable reversible generative models. International Confer-
ence on Learning Representations, 2019."
REFERENCES,0.29201430274135876,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectiﬁers: Surpassing
human-level performance on imagenet classiﬁcation. In Proceedings of the IEEE international
conference on computer vision, pp. 1026–1034, 2015."
REFERENCES,0.2932061978545888,"Arthur Jacot, Franck Gabriel, and Cl´ement Hongler. Neural tangent kernel: Convergence and gen-
eralization in neural networks. arXiv preprint arXiv:1806.07572, 2018."
REFERENCES,0.2943980929678188,"Hamed Karimi, Julie Nutini, and Mark Schmidt. Linear convergence of gradient and proximal-
gradient methods under the polyak-łojasiewicz condition. In Joint European Conference on Ma-
chine Learning and Knowledge Discovery in Databases, pp. 795–811. Springer, 2016."
REFERENCES,0.29558998808104886,"Kenji Kawaguchi. On the theory of implicit deep learning: Global convergence with implicit layers.
arXiv preprint arXiv:2102.07346, 2021."
REFERENCES,0.2967818831942789,"Erwin Kreyszig. Introductory functional analysis with applications, volume 1. wiley New York,
1978."
REFERENCES,0.29797377830750893,"Yuanzhi Li and Yingyu Liang. Learning overparameterized neural networks via stochastic gradient
descent on structured data. arXiv preprint arXiv:1808.01204, 2018."
REFERENCES,0.29916567342073896,"Renjie Liao, Yuwen Xiong, Ethan Fetaya, Lisa Zhang, KiJung Yoon, Xaq Pitkow, Raquel Urta-
sun, and Richard Zemel. Reviving and improving recurrent back-propagation. In International
Conference on Machine Learning, pp. 3082–3091. PMLR, 2018."
REFERENCES,0.300357568533969,"Barbara MacCluer. Elementary functional analysis, volume 253. Springer Science & Business
Media, 2008."
REFERENCES,0.30154946364719903,"Quynh Nguyen. On the proof of global convergence of gradient descent for deep relu networks with
linear widths. arXiv preprint arXiv:2101.09612, 2021."
REFERENCES,0.30274135876042907,"Quynh Nguyen and Marco Mondelli. Global convergence of deep networks with one wide layer
followed by pyramidal topology. arXiv preprint arXiv:2002.07867, 2020."
REFERENCES,0.3039332538736591,"Samet Oymak and Mahdi Soltanolkotabi.
Toward moderate overparameterization: Global con-
vergence guarantees for training shallow neural networks. IEEE Journal on Selected Areas in
Information Theory, 1(1):84–105, 2020."
REFERENCES,0.30512514898688914,"Fernando Pineda. Generalization of back propagation to recurrent and higher order neural networks.
In Neural information processing systems, pp. 602–611, 1987."
REFERENCES,0.3063170441001192,"Yi-Ling Qiao, Junbang Liang, Vladlen Koltun, and Ming C Lin. Scalable differentiable physics for
learning and control. arXiv preprint arXiv:2007.02168, 2020."
REFERENCES,0.3075089392133492,"Andrew M Saxe, James L McClelland, and Surya Ganguli. Exact solutions to the nonlinear dynam-
ics of learning in deep linear neural networks. arXiv preprint arXiv:1312.6120, 2013."
REFERENCES,0.30870083432657924,"Roman Vershynin. High-Dimensional Probability: An Introduction with Applications in Data Sci-
ence. Number 47 in Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge
University Press, 2018. ISBN 978-1-108-41519-4."
REFERENCES,0.3098927294398093,"Po-Wei Wang, Priya Donti, Bryan Wilder, and Zico Kolter. Satnet: Bridging deep learning and log-
ical reasoning using a differentiable satisﬁability solver. In International Conference on Machine
Learning, pp. 6545–6554. PMLR, 2019."
REFERENCES,0.3110846245530393,"Difan Zou and Quanquan Gu. An improved analysis of training over-parameterized deep neural
networks. arXiv preprint arXiv:1906.04688, 2019."
REFERENCES,0.31227651966626935,"Difan Zou, Yuan Cao, Dongruo Zhou, and Quanquan Gu.
Gradient descent optimizes over-
parameterized deep relu networks. Machine Learning, 109(3):467–492, 2020."
REFERENCES,0.3134684147794994,"A
APPENDIX"
REFERENCES,0.3146603098927294,"A.1
PROOF OF LEMMA 2.2"
REFERENCES,0.31585220500595945,"Proof. Let γ0 ∈(0, 1). Set γ ≜min{γ0, γ0/c}. Denote ˜γ = γ/√m. Then
zℓ+1 −zℓ =
σ
 
˜γAzℓ+ φ

−σ
 
˜γAzℓ−1 + φ
"
REFERENCES,0.3170441001191895,"≤˜γ
Azℓ−Azℓ−1 ,
σ is 1-Lipschitz continuous"
REFERENCES,0.3182359952324195,"=˜γ
A(zℓ−zℓ−1)"
REFERENCES,0.31942789034564956,"≤˜γ∥A∥∥zℓ−zℓ−1∥,"
REFERENCES,0.3206197854588796,"≤˜γc√m∥zℓ−zℓ−1∥,
∥A∥≤c√m"
REFERENCES,0.3218116805721097,=γ0∥zℓ−zℓ−1∥.
REFERENCES,0.3230035756853397,"Applying the above argument ℓtimes, we obtain"
REFERENCES,0.32419547079856975,"∥zℓ+1 −zℓ∥≤γℓ
0∥z1 −z0∥= γℓ
0∥z1∥= γℓ
0∥σ(φ)∥≤γℓ
0∥φ∥,"
REFERENCES,0.3253873659117998,"where we use the fact z0 = 0. For any positive integers p, q with p ≤q, we have"
REFERENCES,0.3265792610250298,∥zp −zq∥≤∥zp −zp+1∥+ · · · + ∥zq−1 −zq∥
REFERENCES,0.32777115613825986,"≤γp
0∥φ∥+ · · · + γq
0∥φ∥"
REFERENCES,0.3289630512514899,"≤γp
0∥φ∥
 
1 + γ0 + γ2
0 + · · ·
"
REFERENCES,0.3301549463647199,"=
γp
0
1 −γ0
∥φ∥."
REFERENCES,0.33134684147794996,"Since γ0 ∈(0, 1), we have ∥zp −zq∥→0 as p →∞. Hence, {zℓ}∞
ℓ=1 is a Cauchy sequence.
Since Rm is complete, the equilibrium point z∗is the limit of the sequence {zℓ}∞
ℓ=1, so that z exists
and is unique. Moreover, let q →∞, then we obtain ∥zp −z∗∥≤
γp"
REFERENCES,0.33253873659118,"1−γ ∥φ∥, so that the ﬁxed-point
iteration converges to z linearly."
REFERENCES,0.33373063170441003,"Let p = 0 and q = ℓ, then we obtain ∥zℓ∥≤
1
1−γ0 ∥φ∥."
REFERENCES,0.33492252681764006,"A.2
PROOF OF LEMMA 2.3"
REFERENCES,0.3361144219308701,"Proof.
(i) To simplify the notations, we denote D
≜
diag(σ′(˜γAz + φ)), and E
≜
diag(σ′(W x)). The differential of f is given by"
REFERENCES,0.33730631704410013,"df =d(z −˜γσ(˜γAz + φ))
=dz −Dd(˜γAz + φ)
= [Im −˜γDA] dz −˜γD(dA)z −Ddφ."
REFERENCES,0.33849821215733017,Taking vectorization on both sides yields
REFERENCES,0.3396901072705602,vec (df) = [Im −˜γDA] vec (dz) −vec (˜γDdAz) −Dvec (dφ)
REFERENCES,0.34088200238379024,= [Im −˜γDA] vec (dz) −˜γ[zT ⊗D]vec (dA) −Dvec (dφ) .
REFERENCES,0.3420738974970203,"Therefore, the partial derivative of f with respect to z, A, and φ are given by"
REFERENCES,0.3432657926102503,"∂f
∂z = [Im −˜γDA]T ,"
REFERENCES,0.34445768772348034,"∂f
∂A = −˜γ

zT ⊗D
T ,"
REFERENCES,0.3456495828367104,"∂f
∂φ = −DT ."
REFERENCES,0.3468414779499404,It follows from the deﬁnition of the feature vector φ in Eq. (2) that
REFERENCES,0.34803337306317045,"dφ =
1
√mdσ(W x) =
1
√mE(dW )x =
1
√m"
REFERENCES,0.3492252681764005,"
xT ⊗E

vec (dW ) ."
REFERENCES,0.3504171632896305,"Thus, the partial derivative of φ with respect to W is given by
∂φ
∂W =
1
√m"
REFERENCES,0.35160905840286055,"
xT ⊗E
T .
(18)"
REFERENCES,0.3528009535160906,"By using the chain rule, we obtain the partial derivative of f with respect to W as follows
∂f
∂W = ∂φ"
REFERENCES,0.3539928486293206,"∂W
∂f
∂φ = −1
√m"
REFERENCES,0.35518474374255066,"
xT ⊗E
T DT ."
REFERENCES,0.3563766388557807,"(ii) Let v be an arbitrary vector, and u be an arbitrary unit vector. The reverse triangle inequality
implies that"
REFERENCES,0.3575685339690107,∥(Im −˜γ diag(σ′(v))A) u∥≥∥u∥−∥˜γ diag(σ′(v))Au∥
REFERENCES,0.35876042908224076,≥∥u∥−˜γ∥diag(σ′(v))∥∥A∥∥u∥
REFERENCES,0.3599523241954708,"(a)
≥(1 −γ0)∥u∥
=1 −γ0 > 0,"
REFERENCES,0.36114421930870083,"where (a) is due to |σ′(v)| ≤1 and ∥A∥op ≤c√m. Therefore, taking inﬁmum on the
left-hand side over all unit vector u yields the desired result."
REFERENCES,0.36233611442193087,"(iii) Since f(z∗, A, W ) = 0, taking implicit differentiation of f with respect to A at z∗gives us
 ∂z ∂A z=z∗"
REFERENCES,0.3635280095351609,  ∂f ∂z z=z∗
REFERENCES,0.36471990464839094,"
+
 ∂f ∂A z=z∗"
REFERENCES,0.36591179976162097,"
= 0."
REFERENCES,0.367103694874851,The results in part (i)-(ii) imply the smallest eigenvalue of ∂f
REFERENCES,0.36829558998808104,"∂z

z∗is strictly positive, so that it
is invertible. Therefore, we have ∂z∗"
REFERENCES,0.3694874851013111,"∂A = −
 ∂f ∂A z=z∗"
REFERENCES,0.3706793802145411,  ∂f ∂z z=z∗
REFERENCES,0.37187127532777114,"−1
= ˜γ

zT ⊗D
T [Im −˜γDA]−T .
(19)"
REFERENCES,0.3730631704410012,"Similarly, we obtain the partial derivative of z∗with respect to W as follows ∂z∗"
REFERENCES,0.3742550655542312,"∂W = −
 ∂f ∂W z=z∗"
REFERENCES,0.37544696066746125,  ∂f ∂z z=z∗
REFERENCES,0.3766388557806913,"−1
=
1
√m"
REFERENCES,0.3778307508939213,"
xT ⊗E
T DT [Im −˜γDA]−T . (20)"
REFERENCES,0.37902264600715135,"To further simplify the notation, we denote z to be the equilibrium point z∗by omitting the
superscribe, i.e., z = z∗. Let ˆy = uT z + vT φ be the prediction for the training data (x, y).
The differential of ˆy is given by"
REFERENCES,0.3802145411203814,"dˆy = d
 
uT z + vT φ

= uT dz + zdu + vT dφ + φT dv."
REFERENCES,0.3814064362336114,"The partial derivative of ˆy with respect to u, v, z, and φ are given by
∂ˆy
∂z = u,
∂ˆy
∂u = z,
∂ˆy
∂v = φ,
∂ˆy
∂φ = v.
(21)"
REFERENCES,0.38259833134684146,Let ℓ= 1
REFERENCES,0.3837902264600715,"2(ˆy −y)2. Then ∂ℓ/∂ˆy = (ˆy −y). By chain rule, we have"
REFERENCES,0.38498212157330153,"∂ℓ
∂u = ∂ˆy"
REFERENCES,0.38617401668653156,"∂u
∂ℓ
∂ˆy = z(ˆy −y),
(22)"
REFERENCES,0.3873659117997616,"∂ℓ
∂φ = ∂ˆy"
REFERENCES,0.38855780691299163,"∂v
∂ℓ
∂ˆy = φ(ˆy −y).
(23)"
REFERENCES,0.38974970202622167,"By using (19)-(20) and chain rule, we obtain
∂ℓ
∂A = ∂z"
REFERENCES,0.3909415971394517,"∂A
∂ℓ
∂z = ∂z"
REFERENCES,0.39213349225268174,"∂A
∂ˆy
∂z
∂ℓ
∂ˆy = ˜γ(ˆy −y)

zT ⊗D
T [Im −˜γDA]−T u,
(24) and"
REFERENCES,0.3933253873659118,"∂ℓ
∂W = ∂z"
REFERENCES,0.39451728247914186,"∂W
∂ˆy
∂z
∂ℓ
∂ˆy + ∂φ"
REFERENCES,0.3957091775923719,"∂W
∂ˆy
∂φ
∂ℓ
∂ˆy"
REFERENCES,0.39690107270560193,"= 1
√m(ˆy −y)[xT ⊗E]T 
DT (Im −˜γDA)−T u + v

.
(25)"
REFERENCES,0.39809296781883197,"Since L = Pn
i=1 ℓi with ℓi = ℓ(ˆyi, yi), we have dL = Pn
i=1 dℓi and ∂L/∂ℓi = 1. Therefore,
we obtain"
REFERENCES,0.399284862932062,"∂L
∂A = n
X i=1"
REFERENCES,0.40047675804529204,"∂ℓi
∂A = n
X"
REFERENCES,0.40166865315852207,"i=1
˜γ(ˆyi −yi)

zT
i ⊗Di
T [Im −˜γDiA]−T u,
(26)"
REFERENCES,0.4028605482717521,"∂L
∂W = n
X i=1"
REFERENCES,0.40405244338498214,"∂ℓi
∂W = n
X i=1"
REFERENCES,0.4052443384982122,"1
√m(ˆyi −yi)[xT
i ⊗Ei]T 
DT
i (Im −˜γDiA)−T u + v

,
(27)"
REFERENCES,0.4064362336114422,"∂L
∂u = n
X i=1"
REFERENCES,0.40762812872467225,"∂ℓi
∂u = n
X"
REFERENCES,0.4088200238379023,"i=1
(ˆyi −yi)zi,
(28)"
REFERENCES,0.4100119189511323,"∂L
∂v = n
X i=1 ∂ℓi ∂v = n
X"
REFERENCES,0.41120381406436235,"i=1
(ˆyi −yi)φi.
(29)"
REFERENCES,0.4123957091775924,"A.3
PROOF OF LEMMA 3.1"
REFERENCES,0.4135876042908224,"Proof. Let zi denote the i-th equilibrium point for the i-the data sample xi. By using (19), (20),
(26) and (27), we obtain the dynamics of the equilibrium point zi as follows dzi"
REFERENCES,0.41477949940405245,"dt =
∂zi ∂A"
REFERENCES,0.4159713945172825,T dvec (A)
REFERENCES,0.4171632896305125,"dt
+
 ∂zi ∂W"
REFERENCES,0.41835518474374256,T dvec (W ) dt
REFERENCES,0.4195470798569726,"=
∂zi ∂A"
REFERENCES,0.42073897497020263,"T 
−∂L ∂A"
REFERENCES,0.42193087008343266,"
+
 ∂zi ∂W"
REFERENCES,0.4231227651966627,"T 
−∂L ∂W "
REFERENCES,0.42431466030989273,"= −˜γ2
n
X"
REFERENCES,0.42550655542312277,"j=1
(ˆyj −yj) [Im −˜γDiA]−1 [zT
i ⊗Di]

zT
j ⊗Dj
T [Im −˜γDjA]−T u −1 m n
X"
REFERENCES,0.4266984505363528,"j=1
(ˆyj −yj) [Im −˜γDiA]−1 Di

xT
i ⊗Ei

[xT
j ⊗Ej]T 
DT
j (Im −˜γDjA)−T u + v
"
REFERENCES,0.42789034564958284,"= −˜γ2
n
X"
REFERENCES,0.42908224076281287,"j=1
(ˆyj −yj) [Im −˜γDiA]−1 DiDT
j [Im −˜γDjA]−T uzT
i zj −1 m n
X"
REFERENCES,0.4302741358760429,"j=1
(ˆyj −yj) [Im −˜γDiA]−1 DiEiET
j

DT
j (Im −˜γDjA)−T u + v

xT
i xj."
REFERENCES,0.43146603098927294,"By using (18) and 27, we obtain the dynamics of the feature vector φi dφi"
REFERENCES,0.432657926102503,"dt =
 ∂φi ∂W"
REFERENCES,0.433849821215733,T dvec (W ) dt
REFERENCES,0.43504171632896305,"=
 ∂φi ∂W"
REFERENCES,0.4362336114421931,"T 
−∂L ∂W  = −1 m n
X"
REFERENCES,0.4374255065554231,"j=1
(ˆyi −yi)EiET
j [DT
j (Im −˜γDjA)−T u + v]xT
i xj."
REFERENCES,0.43861740166865315,"By chain rule, the dynamics of the prediction ˆyi is given by dˆyi"
REFERENCES,0.4398092967818832,"dt =
 ∂ˆyi ∂zi"
REFERENCES,0.4410011918951132,T dzi
REFERENCES,0.44219308700834326,"dt +
 ∂ˆyi ∂φi"
REFERENCES,0.4433849821215733,T dφi
REFERENCES,0.4445768772348033,"dt +
∂ˆyi ∂u T du"
REFERENCES,0.44576877234803336,"dt +
∂ˆyi ∂v T dv dt"
REFERENCES,0.4469606674612634,"= −˜γ2
n
X"
REFERENCES,0.44815256257449343,"j=1
(ˆyj −yj)

uT (Im −˜γDiA)−1DiDT
j (Im −˜γDjA)−T u

(zT
i zj) −1 m n
X"
REFERENCES,0.44934445768772346,"j=1
(ˆyj −yj)
h 
DT
i (Im −˜γDiA)−1u + v
T EiET
j
 
DT
j (Im −˜γDjA)−T u + v
i
(xT
i xj) − n
X"
REFERENCES,0.4505363528009535,"j=1
(ˆyj −yj)(zT
i zj) − n
X"
REFERENCES,0.45172824791418353,"j=1
(ˆyj −yj)(φT
i φj)."
REFERENCES,0.45292014302741357,Deﬁne the matrices M(t) ∈Rn×n and Q(t) ∈Rn×n as follows
REFERENCES,0.4541120381406436,M(t)ij ≜1
REFERENCES,0.45530393325387364,"muT (Im −˜γDiA)−1DiDT
j (Im −˜γDjA)−T u,"
REFERENCES,0.4564958283671037,Q(t)ij ≜1
REFERENCES,0.4576877234803337,"m
 
DT
i (Im −˜γDiA)−1u + v
T EiET
j
 
DT
j (Im −˜γDjA)−T u + v

."
REFERENCES,0.45887961859356374,"Let X ∈Rn×d, Φ(t) ∈Rn×m, and Z(t) ∈Rn×m be the matrices whose rows are the training
data xi, feature vectors φi, and equilibrium points zi at time t, respectively. The dynamics of the
prediction vector ˆy is given by dˆy"
REFERENCES,0.4600715137067938,"dt = −
 
γ2M(t) + In

◦Z(t)Z(t)T + Q(t) ◦XXT + Φ(t)Φ(t)T 
(ˆy(t) −y)."
REFERENCES,0.4612634088200238,"A.4
PROOF OF LEMMA 3.2"
REFERENCES,0.46245530393325385,"A.4.1
REVIEW OF HERMITE EXPANSIONS"
REFERENCES,0.4636471990464839,"To make the paper self-contained, we review the necessary background about the Hermite polyno-
mials in this section. One can ﬁnd each result in this section from any standard textbooks about
functional analysis such as MacCluer (2008); Kreyszig (1978), or most recent literature (Nguyen &
Mondelli, 2020, Appendix D) and (Oymak & Soltanolkotabi, 2020, Appendix H)."
REFERENCES,0.464839094159714,"We consider an L2-space deﬁned by L2(R, dP), where dP is the Gaussian measure, that is,"
REFERENCES,0.466030989272944,"dP = p(x)dx,
where
p(x) =
1
√"
REFERENCES,0.46722288438617404,2π e−x2 2 .
REFERENCES,0.4684147794994041,"Thus, L2(R, dP) is a collection of functions f for which
Z ∞"
REFERENCES,0.4696066746126341,"−∞
|f(x)|2 dP(x) =
Z ∞"
REFERENCES,0.47079856972586415,"−∞
|f(x)|2 p(x)dx = Ex∼N(0,1) |f(x)|2 < ∞."
REFERENCES,0.4719904648390942,"Lemma A.1. The ReLU activation σ ∈L2(R, dP)."
REFERENCES,0.4731823599523242,"Proof. Note that
Z ∞"
REFERENCES,0.47437425506555425,"−∞
|σ(x)|2 p(x)dx ≤
Z ∞"
REFERENCES,0.4755661501787843,"−∞
|x|2 p(x)dx = Ex∼N(0,1) |x|2 = Var(x) = 1."
REFERENCES,0.4767580452920143,"For any functions f, g ∈L2(R, dP), we deﬁne an inner product"
REFERENCES,0.47794994040524436,"⟨f, g⟩:=
Z ∞"
REFERENCES,0.4791418355184744,"−∞
f(x)g(x)dP(x) =
Z ∞"
REFERENCES,0.4803337306317044,"−∞
f(x)g(x)p(x)dx = Ex∼N(0,1)[f(x)g(x)]."
REFERENCES,0.48152562574493446,"Furthermore, the induced norm ∥· ∥is given by"
REFERENCES,0.4827175208581645,"∥f∥2 = ⟨f, f⟩=
Z ∞"
REFERENCES,0.48390941597139453,"−∞
|f(x)|2 dP(x) = Ex∼N(0,1) |f(x)|2 ."
REFERENCES,0.48510131108462456,"This L2 space has an orthonormal basis with respect to the inner product deﬁned above, called
normalized probabilist’s Hermite polynomials {hn(x)}∞
n=0 that are given by"
REFERENCES,0.4862932061978546,"hn(x) =
1
√"
REFERENCES,0.48748510131108463,"n!
(−1)nex2/2Dn(e−x2/2),
where
Dn(e−x2/2) = dn"
REFERENCES,0.48867699642431467,dxn e−x2/2.
REFERENCES,0.4898688915375447,"Lemma A.2. The normalized probabilist’s Hermite polynomials is an orthonormal basis of
L2(R, dP): ⟨hm, hn⟩= δmn."
REFERENCES,0.49106078665077474,"Proof. Note that Dn(e−x2/2) = e−x2/2Pn(x) for a polynomial with degree of n and leading term
is (−1)nxn. Thus, we can consider hn(x) =
1
√"
REFERENCES,0.4922526817640048,n!(−1)nPn(x).
REFERENCES,0.4934445768772348,Assume m < n
REFERENCES,0.49463647199046484,"⟨hn, hm⟩=Ex∼N(0,1)[hn(x)hm(x)] =
Z ∞"
REFERENCES,0.4958283671036949,"−∞
hn(x)hm(x)
1
√"
REFERENCES,0.4970202622169249,"2π e−x2/2dx, =
1
√ 2π
√"
REFERENCES,0.49821215733015495,"n!
(−1)n
Z ∞"
REFERENCES,0.499404052443385,"−∞
Dn(e−x2/2)hm(x)dx,
rewrite hn(x) by its deﬁnition =
1
√ 2π
√ n!
√"
REFERENCES,0.5005959475566151,"m!
(−1)n+m
Z ∞"
REFERENCES,0.5017878426698451,"−∞
Dn(e−x2/2)Pm(x)dx,
rewrite hm by the polynomial form =
1
√ 2π
√ n!
√"
REFERENCES,0.5029797377830751,"m!
(−1)2n+m
Z ∞"
REFERENCES,0.5041716328963052,"−∞
e−x2/2Dn[Pm(x)]dx,
integration by parts n times"
REFERENCES,0.5053635280095352,"There is no boundary terms because the super exponential decay of e−x2/2 at inﬁnity. Since m < n,
then Dn(Pm) = 0 so that ⟨hm, hn⟩=0. If m = n, then Dn(Pm) = (−1)nn!. Thus, ⟨hn, hn⟩=
1."
REFERENCES,0.5065554231227652,"Remark: Since {hn} is an orthonormal basis, for every f ∈L2(R, dP), we have"
REFERENCES,0.5077473182359953,"f(x) = ∞
X"
REFERENCES,0.5089392133492253,"n=0
⟨f, hn⟩hn(x)"
REFERENCES,0.5101311084624554,in the sense that
REFERENCES,0.5113230035756854,"lim
N→∞"
REFERENCES,0.5125148986889154,"f(x) − N
X"
REFERENCES,0.5137067938021455,"n=0
⟨f, hn⟩hn(x)  2"
REFERENCES,0.5148986889153755,"= lim
N→∞Ex∼N(0,1)"
REFERENCES,0.5160905840286055,"f(x) − N
X"
REFERENCES,0.5172824791418356,"n=0
⟨f, hn⟩hn(x)  2 = 0"
REFERENCES,0.5184743742550656,"Lemma A.3. f ∈L2(R, dP) if and only if P∞
n=0 |⟨f, hn⟩|2 < ∞."
REFERENCES,0.5196662693682956,Proof. Note that
REFERENCES,0.5208581644815257,"⟨f, f⟩=
Z ∞"
REFERENCES,0.5220500595947557,"−∞
|f(x)|2 dP(x) =
Z ∞ −∞ ∞
X"
REFERENCES,0.5232419547079857,"i=0
⟨f, hi⟩hi(x) !  
∞
X"
REFERENCES,0.5244338498212158,"j=0
⟨f, hj⟩hj(x) "
REFERENCES,0.5256257449344458,"dP(x) = ∞
X"
REFERENCES,0.5268176400476758,"i,j=0
⟨f, hi⟩⟨f, hj⟩
Z ∞"
REFERENCES,0.5280095351609059,"−∞
hi(x)hj(x)dP(x) = ∞
X"
REFERENCES,0.5292014302741359,"i=1
|⟨f, hi⟩|2 ."
REFERENCES,0.5303933253873659,"Lemma A.4. Consider a Hilbert space H with inner product ⟨·, ·⟩. If ∥fn−f∥→0 and ∥gn−g∥→
0, then ⟨f, g⟩= limn→∞⟨fn, gn⟩."
REFERENCES,0.531585220500596,Proof. Observe that
REFERENCES,0.532777115613826,"|⟨f, g⟩−⟨fn, gn⟩| ≤|⟨f, g⟩−⟨fn, g⟩| + |⟨fn, g⟩−⟨fn, gn⟩|
≤∥f∥∥g −gn∥+ ∥fn∥∥g −gn∥."
REFERENCES,0.533969010727056,"Let n →∞, then the continuity of ∥· ∥implies the desired result."
REFERENCES,0.5351609058402861,"Lemma A.5. Let {hn(x)} be the normalized probabilist’s Hermite polynomials. For any ﬁxed
number t, we have"
REFERENCES,0.5363528009535161,"ext−t2/2 = ∞
X n=0 tn
√"
REFERENCES,0.5375446960667462,"n!
hn(x).
(30)"
REFERENCES,0.5387365911799762,"Proof. First, we show f(x) = ext−t2/2 ∈H ≜L2(R, dP)."
REFERENCES,0.5399284862932062,"⟨f, f⟩=Ex∼N(0,1) |f(x)|2 =
Z ∞"
REFERENCES,0.5411203814064363,"−∞
e2xt−t2
1
√"
REFERENCES,0.5423122765196663,2π e−x2/2dx
REFERENCES,0.5435041716328963,"=et2 Z ∞ −∞ 1
√"
REFERENCES,0.5446960667461264,"2π exp

−(x −2t)2 2"
REFERENCES,0.5458879618593564,"
dx,
x ∼N(2t, 1)"
REFERENCES,0.5470798569725864,=et2 < ∞.
REFERENCES,0.5482717520858165,"Thus f(x) ∈H. Then f(x) = P∞
n=0 ⟨f, hn⟩hn(x). Note that"
REFERENCES,0.5494636471990465,"⟨f, hn⟩=Ex∼N(0,1)[f(x)hn(x)] =
Z ∞"
REFERENCES,0.5506555423122765,"−∞
ext−t2/2 ·
1
√"
REFERENCES,0.5518474374255066,"n!
(−1)nex2/2Dn(e−x2/2) ·
1
√"
REFERENCES,0.5530393325387366,"2π e−x2/2dx = 1
√"
REFERENCES,0.5542312276519666,"n!
(−1)n
1
√ 2π Z ∞"
REFERENCES,0.5554231227651967,"−∞
ext−t2/2 · Dn(e−x2/2)dx,
integration by parts n times = 1
√"
REFERENCES,0.5566150178784267,"n!
(−1)2n
1
√ 2π Z ∞"
REFERENCES,0.5578069129916567,"−∞
ext−t2/2tn · e−x2/2dx = tn √ n! Z ∞ −∞ 1
√"
REFERENCES,0.5589988081048868,"2π e−(x−t)2/2dx,
x ∼N(t, 1) = tn √ n!
."
REFERENCES,0.5601907032181168,"Lemma A.6. Let a, b ∈Rd with ∥a∥= ∥b∥= 1, then"
REFERENCES,0.5613825983313468,"Ew∼N(0,Id)[hn(⟨a, w⟩)hm(⟨b, w⟩)] = ⟨a, b⟩n δmn."
REFERENCES,0.5625744934445769,"Proof. Given ﬁxed numbers s and t, we deﬁne two functions f(w) = e⟨a,w⟩t−t2/2 and g(w) =
e⟨b,w⟩s−s2/2. Let x = ⟨a, w⟩and y = ⟨b, w⟩. Then we have"
REFERENCES,0.5637663885578069,"f(w) =e⟨a,w⟩t−t2/2 = ext−t2/2 = ∞
X n=0 tn
√"
REFERENCES,0.564958283671037,"n!
hn(x) = ∞
X n=0 tn
√"
REFERENCES,0.566150178784267,"n!
hn(⟨a, w⟩),"
REFERENCES,0.567342073897497,"g(w) =e⟨b,w⟩s−s2/2 = eys−s2/2 = ∞
X n=0 sn
√"
REFERENCES,0.5685339690107271,"n!
hn(y) = ∞
X n=0 sn
√"
REFERENCES,0.5697258641239571,"n!
hn(⟨b, w⟩)."
REFERENCES,0.5709177592371871,"Deﬁne a Hilbert space Hd = L2(Rd, dP), where dP is the multivariate Gaussian measure,
equipped with inner product ⟨f, g⟩≜Ew∼N(0,Id)[f(w)g(w)]. Clearly, f, g ∈Hd. Deﬁne se-
quences {fN} and {gN} as follows"
REFERENCES,0.5721096543504172,"fN(w) = N
X n=0 tn
√"
REFERENCES,0.5733015494636472,"n!
hn(⟨a, w⟩)
and
gN(w) = N
X n=0 sn
√"
REFERENCES,0.5744934445768772,"n!
hn(⟨b, w⟩)."
REFERENCES,0.5756853396901073,"Since ∥f −fN∥→0 and ∥g −gN∥→0, we have"
REFERENCES,0.5768772348033373,"Ew∼N(0,Id)[f(w)g(w)] = ⟨f, g⟩"
REFERENCES,0.5780691299165673,"= lim
N→∞⟨fN, gN⟩"
REFERENCES,0.5792610250297974,"= lim
N→∞Ew∼N(0,Id)[fN(w)gN(w)]"
REFERENCES,0.5804529201430274,"= lim
N→∞ N
X n,m=0"
REFERENCES,0.5816448152562574,"tnsm
√ n!
√"
REFERENCES,0.5828367103694875,"m!
Ew∼N(0,Id)[hn(⟨a, w⟩)gn(⟨b, w⟩)]"
REFERENCES,0.5840286054827175,Note that the LHS is also given by
REFERENCES,0.5852205005959475,"Ew∼N(0,Id)[f(w)g(w)] =e−t2/2−s2/2Ew∼N(0,Id)[e⟨a,w⟩t+⟨b,w⟩s]"
REFERENCES,0.5864123957091776,"=e−t2/2−s2/2Ew∼N(0,Id)[e
Pd
i=1 wi(ait+bis)]"
REFERENCES,0.5876042908224076,"=e−t2/2−s2/2
d
Y"
REFERENCES,0.5887961859356377,"i=1
Ewi∼N(0,1)[ewi(ait+bis)]"
REFERENCES,0.5899880810488677,"=e−t2/2−s2/2
d
Y"
REFERENCES,0.5911799761620977,"i=1
Mwi(ait + bis)"
REFERENCES,0.5923718712753278,"=e⟨a,b⟩st = ∞
X n=0"
REFERENCES,0.5935637663885578,"⟨a, b⟩n (st)n n!
."
REFERENCES,0.5947556615017878,"Since s and t are arbitrary numbers, matching the coefﬁcients yields"
REFERENCES,0.5959475566150179,"Ew∼N(0,Id)[hn(⟨a, w⟩)hm(⟨b, w⟩)] = ⟨a, b⟩n δmn."
REFERENCES,0.5971394517282479,"A.4.2
LOWER BOUND THE SMALLEST EIGENVALUES OF G∞"
REFERENCES,0.5983313468414779,"The result in this subsection is similar to the results in (Nguyen & Mondelli, 2020, Appendix D) and
(Oymak & Soltanolkotabi, 2020, Appendix H). The key difference is the assumptions made on the
training data. In particular, Oymak & Soltanolkotabi (2020) assumes the training data is δ-separable,
i.e., min{∥xi −xj∥, ∥xi + xj∥} ≥δ > 0 for all i ̸= j, and Nguyen & Mondelli (2020) assumes
the data xi follows some sub-Gaussian random variable, while we assume no two data are parallel
to each other, i.e., xi ̸∥xj for all i ̸= j."
REFERENCES,0.599523241954708,"Lemma A.7. Given an activation function σ, if σ ∈L2(R, dP) and ∥xi∥= 1 for all i ∈[n], then G∞= ∞
X"
REFERENCES,0.600715137067938,"k=0
|⟨σ, hk⟩|2  
XXT ◦· · · ◦XXT "
REFERENCES,0.601907032181168,"|
{z
}
k times"
REFERENCES,0.6030989272943981,",
(31)"
REFERENCES,0.6042908224076281,where ◦is elementwise product.
REFERENCES,0.6054827175208581,Proof. Observe
REFERENCES,0.6066746126340882,"G∞
ij =Ew∼N(0,Id) [σ(⟨w, xi⟩)σ(⟨w, xj⟩)] = ∞
X"
REFERENCES,0.6078665077473182,"k,ℓ=0
⟨σ, hk⟩⟨σ, hℓ⟩Ew∼N(0,Id) [hk(⟨w, xi⟩)hℓ(⟨w, xj⟩)] = ∞
X"
REFERENCES,0.6090584028605482,"k,ℓ=0
⟨σ, hk⟩⟨σ, hℓ⟩· ⟨xi, xj⟩k δkℓ = ∞
X"
REFERENCES,0.6102502979737783,"k=0
⟨σ, hk⟩2 ⟨xi, xj⟩k"
REFERENCES,0.6114421930870083,"Note that the tensor product of xi and xi is xi ⊗xi ∈Rd2×1, so that"
REFERENCES,0.6126340882002383,"⟨xi, xj⟩k = *"
REFERENCES,0.6138259833134684,"xi ⊗· · · ⊗xi
|
{z
}
k times"
REFERENCES,0.6150178784266984,", xj ⊗· · · ⊗xj
|
{z
}
k times +"
REFERENCES,0.6162097735399285,"Here we introduce the (row-wise) Khatri–Rao product of two matrices A ∈Rk×m, B ∈Rk×n.
Then"
REFERENCES,0.6174016686531585,A ∗B =  
REFERENCES,0.6185935637663885,"A1∗⊗B1∗
...
Ak∗⊗Bk∗ "
REFERENCES,0.6197854588796186,∈Rk×mn
REFERENCES,0.6209773539928486,"where Ai∗indicates the i-th row of matrix A. Therefore, the i-th row of X ∗· · · ∗X ≜X∗n is
xi ⊗· · · ⊗xi. As a result, we obtain a more compact form of (31) as follows G∞= ∞
X"
REFERENCES,0.6221692491060786,"k=0
|⟨σ, hk⟩|2 (X∗k)(X∗k)T .
(32)"
REFERENCES,0.6233611442193087,"Lemma A.8. If σ(x) is a nonlinear function and |σ(x)| ≤|x| and , then"
REFERENCES,0.6245530393325387,"sup{n : ⟨σ, hn⟩> 0} = ∞."
REFERENCES,0.6257449344457687,"Proof. It is equivalent to show σ(x) is not a ﬁnite linear combination of polynomials. We prove
by contradiction. Suppose σ(x) = a0 + a1x + · · · + anxn. Since σ(0) = 0 = a0, then σ(x) =
a1x + · · · + anxn. Observe that"
REFERENCES,0.6269368295589988,"lim
x→∞
|σ(x)|"
REFERENCES,0.6281287246722288,"|x|
= lim
x→∞
|a1x + · · · + anxn| |x|"
REFERENCES,0.6293206197854588,"= lim
x→∞
a1 + · · · + anxn−1 , =∞"
REFERENCES,0.6305125148986889,which contradicts |σ(x)|
REFERENCES,0.6317044100119189,"|x|
≤1 for all x ̸= 0."
REFERENCES,0.6328963051251489,"Lemma A.9. If xi ̸∥xj for all i ̸= j, then there exists k0 > 0 such that λmin

(X∗k)(X∗k)T 
> 0
for all k ≥k0. Therefore, λmin(G∞) > 0."
REFERENCES,0.634088200238379,"Proof. To simplify the notation, denote K = (X∗k)T ∈Rkd×n. Since xi ̸∥xj and ∥xi∥= 1, then
let δ ≜max{|⟨xi, xj⟩|} = max{|cos θij|} and δ ∈(0, 1), where θij is the angle between xi and
xj. For any unit vector v ∈Rn, we have"
REFERENCES,0.635280095351609,"vT (X∗k)(X∗k)T v =∥Kv∥2 =  n
X"
REFERENCES,0.636471990464839,"i=1
viK∗i  2 = n
X i=1 n
X"
REFERENCES,0.6376638855780691,"j=1
vivj ⟨K∗i, K∗j⟩ = n
X i=1 n
X"
REFERENCES,0.6388557806912991,"j=1
vivj ⟨xi, xj⟩k = n
X"
REFERENCES,0.6400476758045291,"i=1
v2
i ∥xi∥2k +
X"
REFERENCES,0.6412395709177592,"i̸=j
vivj ⟨xi, xj⟩k"
REFERENCES,0.6424314660309892,"=1 +
X"
REFERENCES,0.6436233611442194,"i̸=j
vivj ⟨xi, xj⟩k ,"
REFERENCES,0.6448152562574494,where the last equality is because ∥xi∥= 1 and ∥v∥= 1. Note that X
REFERENCES,0.6460071513706794,"i̸=j
vivj ⟨xi, xj⟩k ≤
X"
REFERENCES,0.6471990464839095,"i̸=j
|vi| |vj| |⟨xi, xj⟩|k ≤δk X"
REFERENCES,0.6483909415971395,"i̸=j
|vi| |vj| ,
by |⟨xi, xj⟩| ≤δ"
REFERENCES,0.6495828367103695,"≤δk
 n
X"
REFERENCES,0.6507747318235996,"i=1
|vi| !2"
REFERENCES,0.6519666269368296,"≤nδk,
by Cauchy-Schwart’s inequlity."
REFERENCES,0.6531585220500596,"By inverse triangle inequality, we have"
REFERENCES,0.6543504171632897,∥Kv∥2 ≥1 −nδk.
REFERENCES,0.6555423122765197,"Choose k0 ≥log n/ log(1/δ), then λmin{(X∗k)(X∗k)T } > 0 for all k ≥k0."
REFERENCES,0.6567342073897497,"A.5
PROOF OF LEMMA 3.3"
REFERENCES,0.6579261025029798,"Proof. Since ∥xi∥= 1 and wr(0) ∼N(0, Id), we have xT
i wr(0) ∼N(0, 1) for all i ∈[n]. Let
Xir ≜σ

xT
i wr(0)

and Z ∼N(0, 1), then for any |λ| ≤1/
√"
REFERENCES,0.6591179976162098,"2, we have"
REFERENCES,0.6603098927294399,"E exp{X2
irλ2} = E exp{σ

xT
i wr(0)
2 λ2} ≤E exp{Z2λ2} = 1/
p"
REFERENCES,0.6615017878426699,"1 −2λ2 ≤e2t2,"
REFERENCES,0.6626936829558999,"where the ﬁrst inequality is due tot |σ(x)| ≤|x|, and the last inequality is by using the numerical"
REFERENCES,0.66388557806913,"inequality 1/(1 −x) ≤e2x. Choose λ ≤
 
log
√"
REFERENCES,0.66507747318236,"2
1/2, we obtain E{X2
irλ2} ≤2. By using
Markov’s inequality, we have for any t ≥0"
REFERENCES,0.66626936829559,"P {|Xir| ≥t} = P
n
|Xir|2 / log
√"
REFERENCES,0.6674612634088201,"2 ≥t2/ log
√"
O,0.6686531585220501,"2
o
≤2 exp
n
−t2 log
√"
O,0.6698450536352801,"2
o
≤2 exp

−t2/4
	
."
O,0.6710369487485102,"Therefore Xir is a sub-Gaussian random variable with sub-Gaussian norm ∥Xi∥ψ2 ≤2 (Vershynin,
2018, Proposition 2.5.2). Then XirXjr is a sub-exponential random variable with sub-exponential
norm ∥XirXjr∥ψ1 ≤4 (Vershynin, 2018, Lemma 2.7.7). Observe that"
O,0.6722288438617402,"Gij(0) = φi(0)T φj(0) = 1 m m
X"
O,0.6734207389749702,"r=1
σ

xT
i wr(0)

σ

xT
j wr(0)

= 1 m m
X"
O,0.6746126340882003,"r=1
XirXjr."
O,0.6758045292014303,"Since G∞
ij = E [Gij(0)], (Vershynin, 2018, Exercise 2.7.10) implies that Gij(0) −G∞
ij is also a
zero-mean sub-exponential random variable. It follows from the Bernstein’s inequality that"
O,0.6769964243146603,"P

∥G(0) −G∞∥2 ≥λ0 4"
O,0.6781883194278904,"
≤P

∥G(0) −G∞∥F ≥λ0 4  =P ("
O,0.6793802145411204,"∥G(0) −G∞∥2
F ≥
λ0 4 2) =P 
  n
X i,j=1"
O,0.6805721096543504,"Gij(0) −G∞
ij
2 ≥
λ0 4"
O,0.6817640047675805,"2

  ≤ n
X"
O,0.6829558998808105,"i,j=1
P"
O,0.6841477949940405,"(
Gij(0) −G∞
ij
2 ≥
 λ0"
N,0.6853396901072706,"4n 2) = n
X"
N,0.6865315852205006,"i,j=1
P
Gij(0) −G∞
ij
 ≥λ0"
N,0.6877234803337307,4n 
N,0.6889153754469607,"≤n2 · 2 exp

−cλ2
0m/n2 ≤δ,"
N,0.6901072705601907,"where c > 0 is some constant, and we use the facts ∥X∥2 ≤∥X∥F , and P{Pn
i=1 xi ≥ε} ≤
Pn
i=1 P{xi ≥ε/n}."
N,0.6912991656734208,"A.6
PROOF OF LEMMA 3.4"
N,0.6924910607866508,"Proof. By using the 1-Lipschitz continuity of σ(x), we have"
N,0.6936829558998808,∥G −G(0)∥= 1
N,0.6948748510131109,m∥σ(XW T )σ(XW T )T −σ(XW (0)T )σ(XW (0)T )T ∥ ≤1
N,0.6960667461263409,m∥σ(XW T )σ(XW T )T −σ(XW T )σ(XW (0)T )T ∥ + 1
N,0.6972586412395709,m∥σ(XW T )σ(XW (0)T )T −σ(XW (0)T )σ(XW (0)T )T ∥ = 1
N,0.698450536352801,m∥σ(XW T )∥∥σ(XW T ) −σ(XW (0)T )∥ + 1
N,0.699642431466031,m∥σ(XW T ) −σ(XW (0)T )∥∥σ(XW (0)T )∥ ≤1
N,0.700834326579261,m∥X∥∥W ∥∥X∥∥W −W (0)∥+ 1
N,0.7020262216924911,m∥X∥∥W −W (0)∥∥X∥∥W (0)∥
N,0.7032181168057211,"≤4c
√m∥X∥2∥W −W (0)∥ ≤λ0 4 ."
N,0.7044100119189511,"A.7
PROOF OF LEMMA 3.5"
N,0.7056019070321812,"Proof. It sufﬁces to show the result holds for γ = min{γ0, γ0/2c}, where γ0 = 1/2. Note that
Lemma 2.1 still holds if one chooses a larger c. Thus, we choose c ≿√λ0/∥X∥. We prove by the
induction. Suppose that for 0 ≤s ≤t, the followings hold"
N,0.7067938021454112,"(i) λmin(G(s)) ≥λ0 2 ,"
N,0.7079856972586412,(ii) ∥u(s)∥≤16c√n
N,0.7091775923718713,"λ0
∥ˆy(0) −y∥,"
N,0.7103694874851013,(iii) ∥v(s)∥≤8c√n
N,0.7115613825983313,"λ0 ∥ˆy(0) −y∥,"
N,0.7127532777115614,"(iv) ∥W (s)∥≤2c√m,"
N,0.7139451728247914,"(v) ∥A(s)∥≤2c√m,"
N,0.7151370679380215,"(vi) ∥ˆy(s) −y∥2 ≤exp{−λ0s}∥ˆy(0) −y∥2,"
N,0.7163289630512515,Since λmin(G(s)) ≥λ0
N,0.7175208581644815,"2 , we have"
N,0.7187127532777116,"d
dt∥ˆy(t) −y∥2 = −2(ˆy(t) −y)T H(t)(ˆy(t) −y)"
N,0.7199046483909416,≤−λ0∥ˆy(t) −y∥2
N,0.7210965435041716,Solving the ordinary differential equation yields
N,0.7222884386174017,∥ˆy(t) −y∥2 ≤exp{−λ0t}∥ˆy(0) −y∥2.
N,0.7234803337306317,"By using the inductive hypothesis ∥W (s)∥≤2c√m, we have"
N,0.7246722288438617,"∥φi(s)∥=

1
√mσ(W (s)xi)
 ≤
1
√m∥W (s)∥∥xi∥≤2c."
N,0.7258641239570918,It follows from Lemma 2.2 with γ0 = 1/2 that
N,0.7270560190703218,"∥z∗
i (s)∥≤2∥φi(s)∥≤4c."
N,0.7282479141835518,Note that
N,0.7294398092967819,"∥∇vL(s)∥≤ n
X"
N,0.7306317044100119,"i=1
|ˆyi(s) −yi| ∥φi(s)∥ ≤2c n
X"
N,0.7318235995232419,"i=1
|ˆyi(s) −yi|"
N,0.733015494636472,≤2c√n∥ˆy(s) −y∥
N,0.734207389749702,≤2c√n exp{−λ0s/2}∥y(0) −y∥
N,0.735399284862932,and so
N,0.7365911799761621,"∥v(t) −v(0)∥≤
Z t"
N,0.7377830750893921,"0
∥∇vL(s)∥ds"
N,0.7389749702026222,"≤2c√n∥y(0) −y∥
Z t"
N,0.7401668653158522,"0
exp{−λ0s/2}ds ≤4c√n"
N,0.7413587604290822,"λ0
∥ˆy(0) −y∥,"
N,0.7425506555423123,"Since vi(0) follows symmetric Bernoulli distribution, then ∥v(0)∥= √m and we obtain"
N,0.7437425506555423,∥v(t)∥≤∥v(t) −v(0)∥+ ∥v(0)∥≤8c√n
N,0.7449344457687723,"λ0
∥ˆy(0) −y∥,"
N,0.7461263408820024,"where the last inequality is due to m = Ω

c2n∥X∥2"
N,0.7473182359952324,"λ3
0
∥ˆy(0) −y∥2
and c ≿√λ0/∥X∥."
N,0.7485101311084624,"Similarly, we have"
N,0.7497020262216925,"∥∇uL(s)∥≤ n
X"
N,0.7508939213349225,"i=1
|ˆyi(s) −yi| ∥z∗
i ∥"
N,0.7520858164481525,≤4c√n∥ˆy(s) −y∥
N,0.7532777115613826,"≤4c√n exp{−λ0s/2}∥ˆy(0) −y∥,"
N,0.7544696066746126,so that
N,0.7556615017878426,"∥u(t) −u(0)∥≤
Z t"
N,0.7568533969010727,"0
∥∇uL(s)∥ds ≤8c√n"
N,0.7580452920143027,"λ0
∥ˆy(0) −y∥."
N,0.7592371871275327,"Since ui(0) follows symmetric Bernoulli distribution, then ∥u(0)∥= √m and we obtain"
N,0.7604290822407628,∥u(t)∥≤∥u(t) −u(0)∥+ ∥u(0)∥≤16c√n
N,0.7616209773539928,"λ0
∥ˆy(0) −y∥."
N,0.7628128724672228,Note that
N,0.7640047675804529,"∥∇W L(s)∥≤ n
X i=1"
N,0.7651966626936829,"1
√m |ˆyi(s) −yi| ∥Ei(s)∥
 
∥Ui(s)−1u(s)∥+ ∥v(s)∥

∥xi∥"
N,0.766388557806913,≤64c√n
N,0.767580452920143,"λ0
∥ˆy(0) −y∥. n
X"
N,0.768772348033373,"i=1
|ˆyi(s) −yi| ≤64cn"
N,0.7699642431466031,"λ0
∥ˆy(0) −y∥· ∥ˆy(s) −y∥ ≤64cn"
N,0.7711561382598331,"λ0
∥ˆy(0) −y∥2 · exp{−λ0s/2},"
N,0.7723480333730631,so that
N,0.7735399284862932,"∥W (t) −W (0)∥≤
Z t"
N,0.7747318235995232,"0
∥∇W L(s)∥ds"
N,0.7759237187127532,≤128cn
N,0.7771156138259833,"λ2
0
√m∥ˆy(0) −y∥2"
N,0.7783075089392133,"≤λ0
√m
16c∥X∥2 ≤R."
N,0.7794994040524433,"Therefore, we obtain"
N,0.7806912991656734,"∥W (t)∥≤∥W (t) −W (0)∥+ ∥W (0)∥≤2c√m,"
N,0.7818831942789034,"Moreover, it follows from Lemma 3.4 that λmin{G(t)} ≥λ0 2 ."
N,0.7830750893921334,Note that
N,0.7842669845053635,"∥∇AL(s)∥≤ n
X i=1"
N,0.7854588796185935,"γ
√m |ˆyi(s) −yi| ∥Di∥∥Ui(s)−1∥∥u(s)∥∥z∗
i ∥"
N,0.7866507747318237,≤32c√n
N,0.7878426698450537,"λ0
√m ∥ˆy(0) −y∥· n
X"
N,0.7890345649582837,"i=1
|ˆyi(s) −yi| ≤32cn"
N,0.7902264600715138,"λ0
√m∥ˆy(0) −y∥· ∥ˆy(s) −y∥ ≤32cn"
N,0.7914183551847438,"λ0
√m∥ˆy(0) −y∥2 · exp{−λ0s/2},"
N,0.7926102502979738,so that
N,0.7938021454112039,"∥A(t) −A(0)∥≤
Z t"
N,0.7949940405244339,"0
∥∇AL(s)∥ds ≤64cn"
N,0.7961859356376639,"λ2
0
√m∥ˆy(0) −y∥2. Then"
N,0.797377830750894,∥A(t)∥≤∥A(t) −A(0)∥+ ∥A(0)∥≤2c√m.
N,0.798569725864124,"A.8
PROOF OF LEMMA 3.6"
N,0.799761620977354,"In this section, we prove the result for discrete time analysis or result for gradient descent. Assume
∥A(0)∥≤c√m and ∥W (0)∥≤c√m. Further, we assume λmin(G(0)) ≥3"
N,0.8009535160905841,4λ0 and we assume
N,0.8021454112038141,"m = Ω

c2n∥X∥2"
N,0.8033373063170441,"λ3
0
∥ˆy(0) −y∥2
and choose 0 < γ ≤min{1/2, 1/4c}. Moreover, we assume the"
N,0.8045292014302742,"stepsize α = O
 
λ0/n2
. We make the inductive hypothesis as follows for all 0 ≤s ≤k"
N,0.8057210965435042,"(i) λmin(G(s)) ≥λ0 2 ,"
N,0.8069129916567342,(ii) ∥u(s)∥≤32c√n
N,0.8081048867699643,"λ0
∥ˆy(0) −y∥,"
N,0.8092967818831943,(iii) ∥v(s)∥≤16c√n
N,0.8104886769964244,"λ0
∥ˆy(0) −y∥,"
N,0.8116805721096544,"(iv) ∥W (s)∥≤2c√m,"
N,0.8128724672228844,"(v) ∥A(s)∥≤2c√m,"
N,0.8140643623361145,(vi) ∥ˆy(s) −y∥2 ≤(1 −αλ0/2)s∥ˆy(0) −y∥2.
N,0.8152562574493445,"Proof. Note that Lemma 2.1 still holds if one chooses a larger c. Thus, we choose c ≿√λ0/∥X∥.
By using the inductive hypothesis, we have for any 0 ≤s ≤k"
N,0.8164481525625745,"∥φi(s)∥= ∥1
√mσ(W (s)xi)∥≤
1
√m∥W (s)∥≤2c and"
N,0.8176400476758046,"∥Φ(s)∥≤∥Φ(s)∥F = n
X"
N,0.8188319427890346,"i=1
∥φi(s)∥2
!1/2"
N,0.8200238379022646,"≤2c√n.
(33)"
N,0.8212157330154947,"By using Lemma 2.2, we obtain the upper bound for the equilibrium point zi(s) for any 0 ≤s ≤k
as follows"
N,0.8224076281287247,"∥zi(s)∥≤
1
1 −γ0
∥φi(s)∥= 2∥φi(s)∥≤4c,"
N,0.8235995232419547,"where the last inequality is because we choose γ0 = 1/2, and"
N,0.8247914183551848,"∥Z(s)∥≤∥Z(s)∥F = n
X"
N,0.8259833134684148,"i=1
∥zi(s)∥2
!1/2"
N,0.8271752085816448,"= 4c√n.
(34)"
N,0.8283671036948749,"By using the upper bound of φi(s), we obtain for any 0 ≤s ≤k"
N,0.8295589988081049,"∥∇vL(s)∥≤ n
X"
N,0.8307508939213349,"i=1
|ˆyi(s) −yi| ∥φi(s)∥ ≤2c n
X"
N,0.831942789034565,"i=1
|ˆyi(s) −yi|"
N,0.833134684147795,≤2c√n∥ˆy(s) −y∥
N,0.834326579261025,≤2c√n(1 −αλ0/2)s/2∥ˆy(0) −y∥.
N,0.8355184743742551,"Let β ≜
p"
N,0.8367103694874851,1 −αλ0/2. Then the upper bound of ∥∇vL(s)∥can be written as
N,0.8379022646007152,"∥∇vL(s)∥≤2c√nβs∥ˆy(0) −y∥,
(35) and"
N,0.8390941597139452,"∥v(k + 1) −v(0)∥≤ k
X"
N,0.8402860548271752,"s=0
∥v(s + 1) −v(s)∥= α k
X"
N,0.8414779499404053,"s=0
∥∇vL(s)∥"
N,0.8426698450536353,"≤α · 2c√n∥ˆy(0) −y∥· k
X"
N,0.8438617401668653,"s=0
βs"
N,0.8450536352800954,=2(1 −β2)
N,0.8462455303933254,"λ0
· 2c√n∥ˆy(0) −y∥1 −βk+1 1 −β ≤8c√n"
N,0.8474374255065554,"λ0
∥ˆy(0) −y∥,"
N,0.8486293206197855,"where the last inequality we use the facts β < 1. By triangle inequality, we obtain"
N,0.8498212157330155,∥v(k + 1)∥≤∥v(k + 1) −v(0)∥+ ∥v(0)∥≤16c√n
N,0.8510131108462455,"λ0
∥ˆy(0) −y∥,"
N,0.8522050059594756,"which proves the result (iii). Similarly, we can upper bound the gradient of u"
N,0.8533969010727056,"∥∇uL(s)∥≤ n
X"
N,0.8545887961859356,"i=1
|ˆyi(s) −yi| ∥zi∥≤4c√n∥ˆy(s) −y∥≤4c√nβs∥ˆy(0) −y∥
(36)"
N,0.8557806912991657,so that
N,0.8569725864123957,∥u(k + 1) −u(0)∥≤16c√n
N,0.8581644815256257,"λ0
∥ˆy −y∥, and"
N,0.8593563766388558,∥u(k)∥≤∥u(k) −u(0)∥+ ∥u(0)∥≤32c√n
N,0.8605482717520858,"λ0
∥ˆy(0) −y∥."
N,0.8617401668653158,The result (ii) is also obtained.
N,0.8629320619785459,"By using the inductive hypothesis, we can upper bound the gradient of W as follows"
N,0.8641239570917759,"∥∇W L(s)∥≤ n
X i=1"
N,0.865315852205006,"1
√m |ˆyi(s) −yi| ∥Ei(s)∥
 
∥Ui(s)−1u(s)∥+ ∥v(s)∥

∥xi∥"
N,0.866507747318236,≤128c√n
N,0.867699642431466,"λ0
√m ∥ˆy(0) −y∥ n
X"
N,0.8688915375446961,"i=1
|ˆyi(s) −yi|"
N,0.8700834326579261,≤128cn
N,0.8712753277711561,"λ0
√m∥ˆy(0) −y∥· ∥ˆy(s) −y∥"
N,0.8724672228843862,≤128cn
N,0.8736591179976162,"λ0
√m∥ˆy(0) −y∥2 · βs,
(37)"
N,0.8748510131108462,so that
N,0.8760429082240763,"∥W (k + 1) −W (0)∥≤α k
X"
N,0.8772348033373063,"s=0
∥∇W L(s)∥"
N,0.8784266984505363,≤α · 128cn
N,0.8796185935637664,"λ2
0
√m∥ˆy(0) −y∥2 · k
X"
N,0.8808104886769964,"s=0
βs"
N,0.8820023837902264,≤512cn
N,0.8831942789034565,"λ2
0
√m∥ˆy(0) −y∥2"
N,0.8843861740166865,"≤
√mλ0
16c∥X∥2 ≤R,"
N,0.8855780691299165,"where the third inequality holds is because m is large, i.e., m = Θ

c2n∥X∥2"
N,0.8867699642431466,"λ3
0
∥ˆy(0) −y∥2
. To
simplify the notation, we assume"
N,0.8879618593563766,m = Cc2n∥X∥2
N,0.8891537544696066,"λ3
0
∥ˆy(0) −y∥2
(38)"
N,0.8903456495828367,"for some large number C > 0. Moreover, we obtain"
N,0.8915375446960667,"∥W (k + 1)∥≤∥W (k + 1) −W (0)∥+ ∥W (0)∥≤2c√m,"
N,0.8927294398092968,"Therefore, it follows from Lemma 3.4 that λmin{G(k + 1)} ≥λ0"
N,0.8939213349225268,"2 . Thus, the results (i) and (iv) are
established."
N,0.8951132300357568,"By using similar argument, we can upper bound the gradient of A as follows Note that"
N,0.8963051251489869,"∥∇AL(s)∥≤ n
X i=1"
N,0.8974970202622169,"γ
√m |ˆyi(s) −yi| ∥Di∥∥Ui(s)−1∥∥u(s)∥∥z∗
i ∥"
N,0.8986889153754469,≤64c√n
N,0.899880810488677,"λ0
√m ∥ˆy(0) −y∥· n
X"
N,0.901072705601907,"i=1
|ˆyi(s) −yi| ≤64cn"
N,0.902264600715137,"λ0
√m∥ˆy(0) −y∥· ∥ˆy(s) −y∥ ≤64cn"
N,0.9034564958283671,"λ0
√m∥ˆy(0) −y∥2 · βs,"
N,0.9046483909415971,so that
N,0.9058402860548271,"∥A(k + 1) −A(0)∥≤α k
X"
N,0.9070321811680572,"s=0
∥∇AL(s)∥"
N,0.9082240762812872,≤α · 64cn
N,0.9094159713945172,"λ0
√m∥ˆy(0) −y∥2 · k
X"
N,0.9106078665077473,"s=0
βs"
N,0.9117997616209773,≤256cn
N,0.9129916567342073,"λ2
0
√m∥ˆy(0) −y∥2."
N,0.9141835518474374,Since m = Cc2n∥X∥2
N,0.9153754469606674,"λ3
0
∥ˆy(0) −y∥2 and c, C > 0 are large enough, we have"
N,0.9165673420738975,∥A(k + 1)∥≤∥A(k + 1) −A(0)∥+ ∥A(0)∥≤2c√m.
N,0.9177592371871275,"Therefore, the result (v) is obtained and the equilibrium points zi(k + 1) exists for all i ∈[n]."
N,0.9189511323003575,"To establish the result (vi), we need to derive the bounds between equilibrium points Z(k) and
feature vectors Φ(k). We ﬁrstly bound the difference between equilibrium points zi(k + 1) and
zi(k). For any ℓ≥1, we have"
N,0.9201430274135876,"∥zℓ+1
i
(k + 1) −zℓ+1
i
(k)∥=∥σ

˜γA(k + 1)zℓ
i(k + 1) + φi(k + 1)

−σ

˜γA(k)zℓ
i(k) + φi(k)

∥"
N,0.9213349225268176,"≤∥˜γA(k + 1)zℓ
i(k + 1) + φi(k + 1) −˜γA(k)zℓ
i(k) −φi(k)∥"
N,0.9225268176400476,"≤˜γ∥A(k + 1)zℓ
i(k + 1) −A(k)zℓ
i(k)∥+ ∥φi(k + 1) −φi(k)∥,"
N,0.9237187127532777,where the ﬁrst term can be bounded as follows
N,0.9249106078665077,"˜γ∥A(k + 1)zℓ
i(k + 1) −A(k)zℓ
i(k)∥"
N,0.9261025029797377,"≤˜γ∥A(k + 1) −A(k)∥∥zℓ
i(k + 1)∥+ ˜γ∥A(k)∥∥zℓ
i(k + 1) −zℓ
i(k)∥"
N,0.9272943980929678,"≤˜γα∥∇AL(k)∥(4c) + ˜γ∥A(k)∥∥zℓ
i(k + 1) −zℓ
i(k)∥"
N,0.9284862932061978,≤64αcn
N,0.929678188319428,"λ0m ∥ˆy(0) −y∥2βk + (1/2)∥zℓ
i(k + 1) −zℓ
i(k)∥,"
N,0.930870083432658,and the second term is bounded as follows
N,0.932061978545888,∥φi(k + 1) −φi(k)∥
N,0.933253873659118,"= 1
√m∥σ[W (k + 1)xi] −σ[W (k)xi]∥"
N,0.9344457687723481,"≤1
√m∥W (k + 1) −W (k)∥∥xi∥"
N,0.9356376638855781,"≤α
√m∥∇W L(k)∥"
N,0.9368295589988082,≤128αcn
N,0.9380214541120382,λ0m ∥ˆy(0) −y∥2 · βk.
N,0.9392133492252682,"Thus, we obtain"
N,0.9404052443384983,"∥zℓ+1
i
(k + 1) −zℓ+1
i
(k)∥≤(1/2)∥zℓ
i(k + 1) −zℓ
i(k)∥+ 256αcn"
N,0.9415971394517283,λ0m ∥ˆy(0) −y∥2 · βk
N,0.9427890345649583,"≤(1/2)ℓ∥z1
i (k + 1) −z1
i (k)∥+ 256αcn"
N,0.9439809296781884,"λ0m ∥ˆy(0) −y∥2 · βk · ∞
X"
N,0.9451728247914184,"j=0
2−j"
N,0.9463647199046484,"≤(1/2)ℓ∥z1
i (k + 1) −z1
i (k)∥+ 512αcn"
N,0.9475566150178785,λ0m ∥ˆy(0) −y∥2 · βk.
N,0.9487485101311085,"By letting ℓ→∞, we obtain"
N,0.9499404052443385,∥zi(k + 1) −zi(k)∥≤512αcn
N,0.9511323003575686,λ0m ∥ˆy(0) −y∥2 · βk.
N,0.9523241954707986,"By using the Cauchy-Schwartz’s inequality, we have"
N,0.9535160905840286,∥Z(k + 1) −Z(k)∥≤∥Z(k + 1) −Z(k)∥F ≤512αcn3/2
N,0.9547079856972587,"λ0m
∥ˆy(0) −y∥2 · βk.
(39)"
N,0.9558998808104887,"In addition, we will also bound the difference in φi(k + 1) and φi(k). Note that"
N,0.9570917759237187,"∥φi(k + 1) −φi(k)∥=
1
√m∥σ[W (k + 1)xi] −σ[W (k)xi]∥≤128αcn"
N,0.9582836710369488,"λ0m ∥ˆy(0) −y∥2 · βk,"
N,0.9594755661501788,so that
N,0.9606674612634089,∥Φ(k + 1) −Φ(k)∥≤∥Φ(k + 1) −Φ(k)∥F ≤128αcn3/2
N,0.9618593563766389,"λ0m
∥ˆy(0) −y∥2 · βk
(40)"
N,0.9630512514898689,"Now, we are ready to establish the result (vi). Note that"
N,0.964243146603099,∥ˆy(k + 1) −y∥2 =∥ˆy(k + 1) −ˆy(k) + ˆy(k) −y∥2
N,0.965435041716329,"=∥ˆy(k + 1) −ˆy(k)∥2 + 2 ⟨ˆy(k + 1) −ˆy(k), ˆy(k) −y⟩+ ∥ˆy(k) −y∥2."
N,0.966626936829559,"In the rest of this proof, we will bound each term in the above inequality. By the prediction rule of
ˆy, we can bound the difference between ˆy(k + 1) and ˆy(k) as follows"
N,0.9678188319427891,"∥ˆy(k + 1) −ˆy(k)∥=∥Z(k + 1)u(k + 1) + Φ(k + 1)v(k + 1) −Z(k)u(k) −Φ(k)v(k)∥
≤∥Z(k + 1)u(k + 1) −Z(k)u(k)∥+ ∥Φ(k + 1)v(k + 1) −Φ(k)v(k)∥,"
N,0.9690107270560191,"where the ﬁrst term can be bounded as follows by using (34), 36, 38, 39, hypothesis (ii), and a large
constant C0 > 0"
N,0.9702026221692491,"∥Z(k + 1)∥∥u(k + 1) −u(k)∥+ ∥Z(k + 1) −Z(k)∥∥u(k)∥
=α∥Z(k + 1)∥∥∇uL(k)∥+ ∥Z(k + 1) −Z(k)∥∥u(k)∥"
N,0.9713945172824792,"≤αC0c2n∥ˆy(0) −y∥· βk,"
N,0.9725864123957092,"and the second term is bounded as follows by using (33), 35, 40, 38, hypothesis (iii), and a large
constant C0 > 0"
N,0.9737783075089392,"∥Φ(k + 1)∥∥v(k + 1) −v(k)∥+ ∥Φ(k + 1) −Φ(k)∥∥v(k)∥
=α∥Φ(k + 1)∥∥∇vL(k)∥+ ∥Φ(k + 1) −Φ(k)∥∥v(k)∥"
N,0.9749702026221693,≤αC0c2n∥ˆy(0) −y∥· βk.
N,0.9761620977353993,"Therefore, we have"
N,0.9773539928486293,"∥ˆy(k + 1) −ˆy(k)∥≤αC0c2n∥ˆy(0) −y∥· βk,
(41)"
N,0.9785458879618594,where the scalar 2 is absorbed in C0 and the constant C0 is difference from C.
N,0.9797377830750894,Let g ≜Z(k)u(k + 1) + Φ(k)v(k + 1). Then we have
N,0.9809296781883194,"⟨ˆy(k + 1) −ˆy(k), ˆy(k) −y⟩= ⟨ˆy(k + 1) −g, ˆy(k) −y⟩+ ⟨g −ˆy(k), ˆy(k) −y⟩."
N,0.9821215733015495,"Let us bound each term individually. By using the Cauchy-Schwartz inequality, we have"
N,0.9833134684147795,"⟨ˆy(k + 1) −g, ˆy(k) −y⟩
= ⟨(Z(k + 1) −Z(k))u(k + 1), ˆy(k) −y⟩+ ⟨(Φ(k + 1) −Φ(k))v(k + 1), ˆy(k) −y⟩
≤(∥Z(k + 1) −Z(k)∥∥u(k + 1)∥+ ∥Φ(k + 1) −Φ(k)∥∥v(k + 1)∥) ∥ˆy(k) −y∥"
N,0.9845053635280095,"≤αC0c2n∥ˆy(0) −y∥· βk∥ˆy(k) −y∥,
by (34), 36, 38, 39"
N,0.9856972586412396,"≤αC0c2n · β2k∥ˆy(0) −y∥2.
(42)"
N,0.9868891537544696,"By using ∇uL(k) = Z(k)T (ˆy(k) −y), ∇vL(k) = Φ(k)T (ˆy(k) −y) and λmin(G(k)) ≥λ0/2,
we get"
N,0.9880810488676997,"⟨g −ˆy(k), ˆy(k) −y⟩= −α(ˆy(k) −y)T 
Z(k)Z(k)T + Φ(k)Φ(k)T 
(ˆy(k) −y) ≤−αλ0"
N,0.9892729439809297,"2 ∥ˆy(k) −y∥2.
(43)"
N,0.9904648390941597,"By combining the inequalities (41), 42, 43, we obtain"
N,0.9916567342073898,"∥ˆy(k + 1) −y∥2 ≤
 
1 −α

λ0 −C0c2n −αC2
0c4n2
β2k∥ˆy(0) −y∥2"
N,0.9928486293206198,"≤

1 −αλ0 2"
N,0.9940405244338498,"
· β2k∥ˆy(0) −y∥2"
N,0.9952324195470799,"=

1 −αλ0 2"
N,0.9964243146603099,"k+1
∥ˆy(0) −y∥2,"
N,0.9976162097735399,"where the second inequality is by α = O
  λ0"
N,0.99880810488677,"n2

. This proves the result (vi) and complete the proof."
