Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.000778816199376947,"General-purpose learning systems should improve themselves in open-ended fash-
1"
ABSTRACT,0.001557632398753894,"ion in ever-changing environments. Conventional learning algorithms for neural
2"
ABSTRACT,0.002336448598130841,"networks, however, suffer from catastrophic forgetting (CF)—previously acquired
3"
ABSTRACT,0.003115264797507788,"skills are forgotten when a new task is learned. Instead of hand-crafting new
4"
ABSTRACT,0.003894080996884735,"algorithms for avoiding CF, we propose Automated Continual Learning (ACL) to
5"
ABSTRACT,0.004672897196261682,"train self-referential neural networks to meta-learn their own in-context continual
6"
ABSTRACT,0.005451713395638629,"(meta-)learning algorithms. ACL encodes continual learning desiderata—good
7"
ABSTRACT,0.006230529595015576,"performance on both old and new tasks—into its meta-learning objectives. Our
8"
ABSTRACT,0.007009345794392523,"experiments demonstrate that, in general, in-context learning algorithms also suffer
9"
ABSTRACT,0.00778816199376947,"from CF but ACL effectively solves such “in-context catastrophic forgetting”. Our
10"
ABSTRACT,0.008566978193146417,"ACL-learned algorithms outperform hand-crafted ones and popular meta-continual
11"
ABSTRACT,0.009345794392523364,"learning methods on the Split-MNIST benchmark in the replay-free setting, and
12"
ABSTRACT,0.010124610591900311,"enables continual learning of diverse tasks consisting of multiple few-shot and stan-
13"
ABSTRACT,0.010903426791277258,"dard image classification datasets. Going beyond, we also highlight the limitations
14"
ABSTRACT,0.011682242990654205,"of in-context continual learning, by investigating the possibilities to extend ACL to
15"
ABSTRACT,0.012461059190031152,"the realm of state-of-the-art CL methods which leverage pre-trained models.1
16"
INTRODUCTION,0.0132398753894081,"1
Introduction
17"
INTRODUCTION,0.014018691588785047,"Enemies of memories are other memories [1]. Continually-learning artificial neural networks (NNs)
18"
INTRODUCTION,0.014797507788161994,"are memory systems in which their weights store memories of task-solving skills or programs, and
19"
INTRODUCTION,0.01557632398753894,"their learning algorithm is responsible for memory read/write operations. Conventional learning
20"
INTRODUCTION,0.016355140186915886,"algorithms—used to train NNs in the standard scenarios where all training data is available at once—
21"
INTRODUCTION,0.017133956386292833,"are known to be inadequate for continual learning (CL) of multiple tasks where data for each task
22"
INTRODUCTION,0.01791277258566978,"is available sequentially and exclusively, one at a time. They suffer from “catastrophic forgetting”
23"
INTRODUCTION,0.018691588785046728,"(CF; [2–5]); the NNs forget, or rather, the learning algorithm erases, previously acquired skills, in
24"
INTRODUCTION,0.019470404984423675,"exchange of learning to solve a new task. Naturally, a certain degree of forgetting is unavoidable
25"
INTRODUCTION,0.020249221183800622,"when the memory capacity is limited, and the amount of things to remember exceeds such an upper
26"
INTRODUCTION,0.02102803738317757,"bound. In general, however, capacity is not the fundamental cause of CF; typically, the same NNs,
27"
INTRODUCTION,0.021806853582554516,"suffering from CF when trained on two tasks sequentially, can perform well on both tasks when they
28"
INTRODUCTION,0.022585669781931463,"are jointly trained on the two tasks at once instead (see, e.g., [6]).
29"
INTRODUCTION,0.02336448598130841,"The real root of CF lies in the learning algorithm as a memory mechanism. A “good” CL algorithm
30"
INTRODUCTION,0.024143302180685357,"should preserve previously acquired knowledge while also leveraging previous learning experiences
31"
INTRODUCTION,0.024922118380062305,"to improve future learning, by maximally exploiting the limited memory space of model parameters.
32"
INTRODUCTION,0.02570093457943925,"All of this is the decision-making problem of learning algorithms. In fact, we can not blame the
33"
INTRODUCTION,0.0264797507788162,"conventional learning algorithms for causing CF, since they are not aware of such a problem. They
34"
INTRODUCTION,0.027258566978193146,"are designed to train NNs for a given task at hand; they treat each learning experience independently
35"
INTRODUCTION,0.028037383177570093,"(they are stationary up to certain momentum parameters in certain optimizers), and ignore any
36"
INTRODUCTION,0.02881619937694704,1Here we’ll add a link to our public GitHub code repository.
INTRODUCTION,0.029595015576323987,"potential influence of current learning on past or future learning experiences. Effectively, more
37"
INTRODUCTION,0.030373831775700934,"sophisticated algorithms previously proposed against CF [7, 8], such as elastic weight consolidation
38"
INTRODUCTION,0.03115264797507788,"[9, 10] or synaptic intelligence [11], often introduce manually-designed constraints as regularization
39"
INTRODUCTION,0.031931464174454825,"terms to explicitly penalize current learning for deteriorating knowledge acquired in past learning.
40"
INTRODUCTION,0.03271028037383177,"Here, instead of hand-crafting learning algorithms for continual learning, we train self-referential
41"
INTRODUCTION,0.03348909657320872,"neural networks [12, 13] to meta-learn their own “in-context” continual learning algorithms. We
42"
INTRODUCTION,0.03426791277258567,"train them through gradient descent on learning objectives that reflect desiderata for continual learn-
43"
INTRODUCTION,0.035046728971962614,"ing algorithms—good performance on both old and new tasks, including forward and backward
44"
INTRODUCTION,0.03582554517133956,"transfer. In fact, by extending the standard settings of few-shot or meta-learning based on sequence-
45"
INTRODUCTION,0.03660436137071651,"processing NNs [14–18], the continual learning problem can also be formulated as a long-span
46"
INTRODUCTION,0.037383177570093455,"sequence processing task [19]. Corresponding CL sequences can be obtained by concatenating multi-
47"
INTRODUCTION,0.0381619937694704,"ple few-shot/meta-learning sub-sequences, where each sub-sequence consists of input/target examples
48"
INTRODUCTION,0.03894080996884735,"corresponding to the task to be learned in-context. As we’ll see in Sec. 3, this setting also allows us
49"
INTRODUCTION,0.0397196261682243,"to seamlessly express classic desiderata for CL as part of objective functions of the meta-learner.
50"
INTRODUCTION,0.040498442367601244,"Once formulated as such a sequence-learning task, we let gradient descent search for CL algorithms
51"
INTRODUCTION,0.04127725856697819,"achieving the desired CL behaviors in the program space of NN weights. In principle, all typical
52"
INTRODUCTION,0.04205607476635514,"challenges of CL—such as the stability-plasticity dilemma [20]—are automatically discovered and
53"
INTRODUCTION,0.042834890965732085,"handled by the gradient-based program search process. Once trained, CL is automated through
54"
INTRODUCTION,0.04361370716510903,"recursive self-modification dynamics of the trained NN, without requiring any human intervention
55"
INTRODUCTION,0.04439252336448598,"such as adding extra regularization or setting hyper-parameters for CL. Therefore, we call our
56"
INTRODUCTION,0.045171339563862926,"method, Automated Continual Learning (ACL).
57"
INTRODUCTION,0.045950155763239874,"Our experiments focus on supervised image classification, making use of standard few-shot learning
58"
INTRODUCTION,0.04672897196261682,"datasets for meta-training, namely, Mini-ImageNet [21, 22], Omniglot [23], and FC100 [24], while
59"
INTRODUCTION,0.04750778816199377,"we also meta-test on other datasets including MNIST [25], FashionMNIST [26] and CIFAR-10 [27].
60"
INTRODUCTION,0.048286604361370715,"Our core contribution is a set of focused experiments showing various facets of in-context CL: (1)
61"
INTRODUCTION,0.04906542056074766,"We first reveal the “in-context catastrophic forgetting” problem using two-task settings (Sec. 4.1) and
62"
INTRODUCTION,0.04984423676012461,"analyse its emergence (Sec. 4.2). We are not aware of any prior work discussing this problem. (2)
63"
INTRODUCTION,0.050623052959501556,"We show very promising results of our ACL-trained learning algorithm on the classic Split-MNIST
64"
INTRODUCTION,0.0514018691588785,"[6, 28] benchmark, outperforming hand-crafted learning algorithms and prior meta-continual learning
65"
INTRODUCTION,0.05218068535825545,"methods [29–31]. (3) We experimentally illustrate the limitations of ACL on 5-datasets [32] and
66"
INTRODUCTION,0.0529595015576324,"Split-CIFAR100 by comparing to more recent prompt-based state-of-the-art CL methods [33, 34].
67"
BACKGROUND,0.053738317757009345,"2
Background
68"
CONTINUAL LEARNING,0.05451713395638629,"2.1
Continual Learning
69"
CONTINUAL LEARNING,0.05529595015576324,"The main focus of this work is on continual learning [35, 36] in supervised learning settings even
70"
CONTINUAL LEARNING,0.056074766355140186,"though high-level principles we discuss here also transfer to reinforcement learning settings [37].
71"
CONTINUAL LEARNING,0.05685358255451713,"In addition, we focus on the realm of CL methods that keep model sizes constant (unlike certain
72"
CONTINUAL LEARNING,0.05763239875389408,"CL methods that incrementally add more parameters as more tasks are presented; see, e.g., [38]),
73"
CONTINUAL LEARNING,0.05841121495327103,"and do not make use of any external replay memory (used in other CL methods; see, e.g., [39–43]).
74"
CONTINUAL LEARNING,0.059190031152647975,"Classic desiderata for a CL system (see, e.g., [44, 45]) are typically summarized as good performance
75"
CONTINUAL LEARNING,0.05996884735202492,"on three metrics: classification accuracies on each dataset (their average), backward transfer (i.e., im-
76"
CONTINUAL LEARNING,0.06074766355140187,"pact of learning a new task on the model’s performance on previous tasks; e.g., catastrophic forgetting
77"
CONTINUAL LEARNING,0.061526479750778816,"is a negative backward transfer), and forward transfer (impact of learning a task for the model’s perfor-
78"
CONTINUAL LEARNING,0.06230529595015576,"mance on a future task). From a broader perspective of meta-learning systems, we may also measure
79"
CONTINUAL LEARNING,0.0630841121495327,"other effects such as learning acceleration (i.e., whether the system leverages previous learning ex-
80"
CONTINUAL LEARNING,0.06386292834890965,"periences to accelerate future learning); here our primary focus remains the classic CL metrics above.
81"
CONTINUAL LEARNING,0.0646417445482866,"2.2
Few-shot/meta-learning via Sequence Learning
82"
CONTINUAL LEARNING,0.06542056074766354,"In Sec. 3, we’ll formulate continual learning as a long-span sequence processing task. This is a direct
83"
CONTINUAL LEARNING,0.06619937694704049,"extension of the classic few-shot/meta learning formulated as a sequence learning problem. In fact,
84"
CONTINUAL LEARNING,0.06697819314641744,"since the seminal works [14–17] (see also [46]), many sequence processing neural networks (see,
85"
CONTINUAL LEARNING,0.06775700934579439,"e.g., [47–58] including Transformers [59, 18]) have been trained as a meta-learner [13, 12] that learn
86"
CONTINUAL LEARNING,0.06853582554517133,"by observing sequences of training examples (i.e., pairs of inputs and their labels) in-context.
87"
CONTINUAL LEARNING,0.06931464174454828,"Figure 1: An illustration of meta-training in Automated Continual Learning (ACL) for a self-
referential/modifying weight matrix W0. Weights WA obtained by observing examples for Task A
(blue) are used to predict a test example for Task A. Weights WA,B obtained by observing examples
for Task A then those for Task B (yellow) are used to predict a test example for Task A (backward
transfer) as well as a test example for Task B (forward transfer)."
CONTINUAL LEARNING,0.07009345794392523,"Here we briefly review such a formulation. Let d, N, K, P be positive integers. In sequential
88"
CONTINUAL LEARNING,0.07087227414330217,"N-way K-shot classification settings, a sequence processing NN with a parameter vector θ ∈RP
89"
CONTINUAL LEARNING,0.07165109034267912,"observes a pair (xt, yt) where xt ∈Rd is the input and yt ∈{1, ..., N} is its label at each step
90"
CONTINUAL LEARNING,0.07242990654205607,"t ∈{1, ..., N · K}, corresponding to K examples for each one of N classes. After the presentation of
91"
CONTINUAL LEARNING,0.07320872274143302,"these N · K examples (often called the support set), one extra input x ∈Rd (often called the query)
92"
CONTINUAL LEARNING,0.07398753894080996,"is fed to the model without its true label but with an “unknown label” token ∅(number of input labels
93"
CONTINUAL LEARNING,0.07476635514018691,"accepted by the model is thus N +1). The model is trained to predict its true label, i.e., the parameters
94"
CONTINUAL LEARNING,0.07554517133956386,"of the model θ are optimized to maximize the probability p(y|(x1, y1), ..., (xN·K, yN·K), (x, ∅); θ)
95"
CONTINUAL LEARNING,0.0763239875389408,"of the correct label y ∈{1, ..., N} of the input query x. Since class-to-label associations are
96"
CONTINUAL LEARNING,0.07710280373831775,"randomized and unique to each sequence ((x1, y1), ..., (xN·K, yN·K), (x, ∅)), each such a sequence
97"
CONTINUAL LEARNING,0.0778816199376947,"represents a new (few-shot or meta) learning example to train the model. To be more specific, this
98"
CONTINUAL LEARNING,0.07866043613707165,"is the synchronous label setting of Mishra et al. [18] where the learning phase (observing examples,
99"
CONTINUAL LEARNING,0.0794392523364486,"(x1, y1) etc.) is separated from the prediction phase (predicting label y given (x, ∅)). We opt for
100"
CONTINUAL LEARNING,0.08021806853582554,"this variant in our experiments as we empirically find this (at least in our specific settings) more
101"
CONTINUAL LEARNING,0.08099688473520249,"stable than the delayed label setting [14] where the model has to make a prediction for every input,
102"
CONTINUAL LEARNING,0.08177570093457943,"and the label is fed to the model with a delay of one time step.
103"
SELF-REFERENTIAL WEIGHT MATRICES,0.08255451713395638,"2.3
Self-Referential Weight Matrices
104"
SELF-REFERENTIAL WEIGHT MATRICES,0.08333333333333333,"Our method (Sec. 3) can be applied to any sequence-processing NN architectures in principle.
105"
SELF-REFERENTIAL WEIGHT MATRICES,0.08411214953271028,"Nevertheless, certain architectures naturally fit better to parameterize a self-improving continual
106"
SELF-REFERENTIAL WEIGHT MATRICES,0.08489096573208722,"learner. Here we use the modern self-referential weight matrix (SRWM; [19, 60]) to build a generic
107"
SELF-REFERENTIAL WEIGHT MATRICES,0.08566978193146417,"self-modifying NN. An SRWM is a weight matrix that sequentially modifies itself as a response
108"
SELF-REFERENTIAL WEIGHT MATRICES,0.08644859813084112,"to a stream of input observations [12, 61]. The modern SRWM belongs to the family of linear
109"
SELF-REFERENTIAL WEIGHT MATRICES,0.08722741433021806,"Transformers (LTs) a.k.a. Fast Weight Programmers (FWPs; [62–68]). Linear Transformers and
110"
SELF-REFERENTIAL WEIGHT MATRICES,0.08800623052959501,"FWPs are an important class of the now popular Transformers [59]: unlike the standard ones whose
111"
SELF-REFERENTIAL WEIGHT MATRICES,0.08878504672897196,"computational requirements grow quadratically and whose state size grows linearly with the context
112"
SELF-REFERENTIAL WEIGHT MATRICES,0.0895638629283489,"length, LTs/FWPs’ complexity is linear and the state size is constant w.r.t. sequence length (like
113"
SELF-REFERENTIAL WEIGHT MATRICES,0.09034267912772585,"in the standard RNNs). This is an important property for in-context CL, since, conceptually, we
114"
SELF-REFERENTIAL WEIGHT MATRICES,0.0911214953271028,"want such a CL system to continue to learn for an arbitrarily long, lifelong time span. Moreover,
115"
SELF-REFERENTIAL WEIGHT MATRICES,0.09190031152647975,"the duality between linear attention and FWPs [67]—and likewise, between linear attention and
116"
SELF-REFERENTIAL WEIGHT MATRICES,0.0926791277258567,"gradient descent-trained linear layers [69, 70]—have played a key role in certain theoretical analyses
117"
SELF-REFERENTIAL WEIGHT MATRICES,0.09345794392523364,"of in-context learning capabilities of Transformers [71, 72].
118"
SELF-REFERENTIAL WEIGHT MATRICES,0.09423676012461059,"The dynamics of an SRWM [19] are described as follows. Let din, dout, t be positive integers, and ⊗
119"
SELF-REFERENTIAL WEIGHT MATRICES,0.09501557632398754,"denote outer product. At each time step t, an SRWM Wt−1 ∈R(dout+2∗din+1)×din observes an input
120"
SELF-REFERENTIAL WEIGHT MATRICES,0.09579439252336448,"xt ∈Rdin, and outputs yt ∈Rdout, while also updating itself to Wt as:
121"
SELF-REFERENTIAL WEIGHT MATRICES,0.09657320872274143,"[yt, kt, qt, βt] = Wt−1xt
(1)
vt = Wt−1ϕ(qt); ¯vt = Wt−1ϕ(kt)
(2)
Wt = Wt−1 + σ(βt)(vt −¯vt) ⊗ϕ(kt)
(3)"
SELF-REFERENTIAL WEIGHT MATRICES,0.09735202492211838,"where vt, ¯vt ∈R(dout+2∗din+1) are value vectors, qt ∈Rdin and kt ∈Rdin are query and key vectors,
122"
SELF-REFERENTIAL WEIGHT MATRICES,0.09813084112149532,"and σ(βt) ∈R is the learning rate. σ and ϕ denote sigmoid and softmax functions respectively. ϕ
123"
SELF-REFERENTIAL WEIGHT MATRICES,0.09890965732087227,"is typically also applied to xt in Eq. 1; here we follow Irie et al. [19]’s few-shot image classification
124"
SELF-REFERENTIAL WEIGHT MATRICES,0.09968847352024922,"setting, and use the variant without it. Eq. 3 corresponds to a rank-one update of the SRWM, from
125"
SELF-REFERENTIAL WEIGHT MATRICES,0.10046728971962617,"Wt−1 to Wt, through the delta learning rule [73, 67] where the self-generated patterns, vt, ϕ(kt),
126"
SELF-REFERENTIAL WEIGHT MATRICES,0.10124610591900311,"and σ(βt), play the role of target, input, and learning rate of the learning rule respectively. The
127"
SELF-REFERENTIAL WEIGHT MATRICES,0.10202492211838006,"delta rule is crucial for the performance of LTs [67, 68, 74, 75].
128"
SELF-REFERENTIAL WEIGHT MATRICES,0.102803738317757,"The initial weight matrix W0 is the only trainable parameters of this layer, that encodes the initial
129"
SELF-REFERENTIAL WEIGHT MATRICES,0.10358255451713395,"self-modification algorithm. We use the layer above as a direct replacement to the self-attention layer
130"
SELF-REFERENTIAL WEIGHT MATRICES,0.1043613707165109,"in the Transformer architecture [59]; and use the multi-head version of the computation above [19].
131"
METHOD,0.10514018691588785,"3
Method
132"
METHOD,0.1059190031152648,"Task Formulation. We formulate continual learning as a long-span sequence learning task. Let
133"
METHOD,0.10669781931464174,"D, N, K, L denote positive integers. Consider two N-way classification tasks A and B to be
134"
METHOD,0.10747663551401869,"learned sequentially (as we’ll see, this can be straightforwardly extended to more tasks). The
135"
METHOD,0.10825545171339564,"formulation here applies to both “meta-training” and “meta-test” phases (see Appendix A.1 for more
136"
METHOD,0.10903426791277258,"on this terminology). We denote the respective training datasets as A and B, and test sets as A′
137"
METHOD,0.10981308411214953,"and B′. We assume that each datapoint in these datasets consists of one input feature x ∈RD of
138"
METHOD,0.11059190031152648,"dimension D (generically denoted as vector x, but it is an image in all our experiments) and one label
139"
METHOD,0.11137071651090343,"y ∈{1, ..., N}. We consider two sequences of L training examples
 
(xA
1 , yA
1 ), ..., (xA
L, yA
L )

and
140
 
(xB
1 , yB
1 ), ..., (xB
L, yB
L)

sampled from the respective training sets A and B. In practice, L = NK
141"
METHOD,0.11214953271028037,"where K is the number of training examples for each class. By concatenating these two sequences,
142"
METHOD,0.11292834890965732,"we obtain one long sequence representing CL examples to be presented as an input sequence to
143"
METHOD,0.11370716510903427,"a (left-to-right) auto-regressive model. At the end of the sequence, the model is tasked to make
144"
METHOD,0.11448598130841121,"predictions on test examples sampled from both A′ and B′; we assume a single test example for
145"
METHOD,0.11526479750778816,"each task (hence, without index): (xA′, yA′) and (xB′, yB′) respectively; which we simply denote as
146"
METHOD,0.11604361370716511,"(xA
test, yA
test) and (xB
test, yB
test) instead.
147"
METHOD,0.11682242990654206,"Our model is a self-referential NN that modifies its own weight matrices as a function of input
148"
METHOD,0.117601246105919,"observations.
To simplify the notation, we denote the state of our self-referential NN as a
149"
METHOD,0.11838006230529595,"single SRWM W∗(even though it may have many of them in practice) where we’ll replace ∗
150"
METHOD,0.1191588785046729,"by various symbols representing the context/inputs it has observed. Given a training sequence
151
 
(xA
1 , yA
1 ), ..., (xA
L, yA
L ), (xB
1 , yB
1 ), ..., (xB
L, yB
L)

, our model auto-regressively consumes one input
152"
METHOD,0.11993769470404984,"at a time, from left to right, in the auto-regressive fashion. Let WA denote the state of the SRWM that
153"
METHOD,0.12071651090342679,"has consumed the first part of the sequence, i.e., the examples from Task A, (xA
1 , yA
1 ), ..., (xA
L, yA
L ),
154"
METHOD,0.12149532710280374,"and let WA,B denote the state of our SRWM having observed the entire sequence.
155"
METHOD,0.12227414330218069,"ACL Meta-Training Objectives. The ACL meta-training objective function tasks the model to
156"
METHOD,0.12305295950155763,"correctly predict the test examples of all tasks learned so far at each task boundaries. That is, in the
157"
METHOD,0.12383177570093458,"case of two-task scenario described above (learning Task A then Task B), we use the weight matrix
158"
METHOD,0.12461059190031153,"WA to predict the label yA
test from input (xA
test, ∅), and we use the weight matrix WA,B to predict the
159"
METHOD,0.12538940809968846,"label yB
test from input (xB
test, ∅) as well as the label yA
test from input (xA
test, ∅). By letting p(y|x; W∗)
160"
METHOD,0.1261682242990654,"denote the model’s output probability for label y ∈{1, .., N} given input x and model weights/state
161"
METHOD,0.12694704049844235,"W∗, the ACL objective can be expressed as:
162"
METHOD,0.1277258566978193,"minimize
θ
−
 
log(p(yA
test|xA
test; WA)) + log(p(yB
test|xB
test; WA,B)) + log(p(yA
test|xA
test; WA,B))

(4)"
METHOD,0.12850467289719625,"for an arbitrary input meta-training sequence
 
(xA
1 , yA
1 ), ..., (xA
L, yA
L ), (xB
1 , yB
1 ), ..., (xB
L, yB
L)

163"
METHOD,0.1292834890965732,"(which is extensible to mini-batches with multiple such sequences), where θ denotes the model
164"
METHOD,0.13006230529595014,"parameters (for the SRWM layer, it is the initial weights W0). Figure 1 illustrates the overall
165"
METHOD,0.1308411214953271,"meta-training process of ACL.
166"
METHOD,0.13161993769470404,"Table 1: 5-way classification accuracies using 15 (meta-test training) examples for each class in the
context. Each row is a single model. Bold numbers highlight cases where in-context catastrophic
forgetting is avoided through ACL."
METHOD,0.13239875389408098,Meta-Test Tasks: Context/Train (top) & Test (bottom)
METHOD,0.13317757009345793,"Meta-Training Tasks
A
A →B
B
B →A"
METHOD,0.13395638629283488,"Task A
Task B
ACL
A
B
A
B
A
B"
METHOD,0.13473520249221183,"Omniglot Mini-ImageNet
No 97.6 ± 0.2 52.8 ± 0.7 22.9 ± 0.7 52.1 ± 0.8 97.8 ± 0.3 20.4 ± 0.6
Yes 98.3 ± 0.2 54.4 ± 0.8 98.2 ± 0.2 54.8 ± 0.9 98.0 ± 0.3 54.6 ± 1.0"
METHOD,0.13551401869158877,"FC100
Mini-ImageNet
No 49.7 ± 0.7 55.0 ± 1.0 21.3 ± 0.7 55.1 ± 0.6 49.9 ± 0.8 21.7 ± 0.8
Yes 53.8 ± 1.7 52.5 ± 1.2 46.2 ± 1.3 59.9 ± 0.7 45.5 ± 0.9 53.0 ± 0.6"
METHOD,0.13629283489096572,Table 2: Similar to Table 1 above but using MNIST and CIFAR-10 (unseen domains) for meta-testing.
METHOD,0.13707165109034267,Meta-Test Tasks: Context/Train (top) & Test (bottom)
METHOD,0.1378504672897196,"Meta-Training Tasks
MNIST
MNIST →CIFAR-10
CIFAR-10
CIFAR-10 →MNIST"
METHOD,0.13862928348909656,"Task A
Task B
ACL
MNIST
CIFAR-10
MNIST
CIFAR-10
MNIST
CIFAR-10"
METHOD,0.1394080996884735,"Omniglot Mini-ImageNet
No 71.1 ± 4.0 49.4 ± 2.4 43.7 ± 2.3 51.5 ± 1.4 68.9 ± 4.1 24.9 ± 3.2
Yes 75.4 ± 3.0 50.8 ± 1.3 81.5 ± 2.7 51.6 ± 1.3 77.9 ± 2.3 51.8 ± 2.0"
METHOD,0.14018691588785046,"FC100
Mini-ImageNet
No 60.1 ± 2.0 56.1 ± 2.3 17.2 ± 3.5 54.4 ± 1.7 58.6 ± 1.6 21.2 ± 3.1
Yes 70.0 ± 2.4 51.0 ± 1.0 68.2 ± 2.7 59.2 ± 1.7 66.9 ± 3.4 52.5 ± 1.3"
METHOD,0.1409657320872274,"The ACL objective function above (Eq. 4) is simple but encapsulates desiderata for continual learning
167"
METHOD,0.14174454828660435,"(Sec. 2.1). The last term of Eq. 4 with p(yA
test|xA
test; WA,B) or schematically p(A′|A, B), optimizes
168"
METHOD,0.1425233644859813,"for backward transfer: (1) remembering the first task A after learning B (combatting catastrophic
169"
METHOD,0.14330218068535824,"forgetting), and (2) leveraging learning of B to improve performance on the past task A. The
170"
METHOD,0.1440809968847352,"second term of Eq. 4, p(yB
test|xB
test; WA,B) or schematically p(B′|A, B), optimizes forward transfer
171"
METHOD,0.14485981308411214,"leveraging the past learning experience of A to improve predictions in the second task B, in addition
172"
METHOD,0.14563862928348908,"to simply learning to solve Task B from the corresponding training examples. To complete, the first
173"
METHOD,0.14641744548286603,"term of Eq. 4 is the single-task meta-learning objective for Task A.
174"
METHOD,0.14719626168224298,"Overall Model Architecture. As we mention in Sec. 2, in our NN architecture, the core sequential
175"
METHOD,0.14797507788161993,"dynamics of CL are learned by the self-referential layers. However, as an image-processing NN, our
176"
METHOD,0.14875389408099687,"model makes use of a vision backend. We use the “Conv-4” architecture [21] (typically used in the
177"
METHOD,0.14953271028037382,"context of few-shot learning) in all our experiments, except in the last one where we use a pre-trained
178"
METHOD,0.15031152647975077,"vision Transformer [76]. Overall, the model takes an image as input, process it through a feedforward
179"
METHOD,0.15109034267912771,"vision NN, whose output is fed to the SRWM-layer block. Note that this is one of the limitations of
180"
METHOD,0.15186915887850466,"this work: more general ACL should also learn to modify the vision components.2
181"
METHOD,0.1526479750778816,"Another crucial architectural choice that is specific to continual/multi-task image processing is
182"
METHOD,0.15342679127725856,"normalization layers (see also Bronskill et al. [78]). Typical NNs used in few-shot learning (e.g.,
183"
METHOD,0.1542056074766355,"Vinyals et al. [21]) contain batch normalization (BN; [79]) layers. All our models use instance
184"
METHOD,0.15498442367601245,"normalization (IN; [80]) instead of BN because in our preliminary experiments, we expectably found
185"
METHOD,0.1557632398753894,"IN to generalize much better than BN layers in the CL setting.
186"
EXPERIMENTS,0.15654205607476634,"4
Experiments
187"
EXPERIMENTS,0.1573208722741433,"4.1
Two-Task Setting: Comprehensible Study
188"
EXPERIMENTS,0.15809968847352024,"We first reveal the problem of “in-context catastrophic forgetting” and show how our ACL method
189"
EXPERIMENTS,0.1588785046728972,"(Sec. 3) can overcome it. As a minimum setting for this, we focus on the two-task “domain-
190"
EXPERIMENTS,0.15965732087227413,"2One “straightforward” architecture fitting the bill is an MLP-mixer architecture (Tolstikhin et al. [77]; built
of several linear layers), where all linear layers are replaced by the self-referential linear layers of Sec. 2.3.
While we implemented such a model, it turned out to be too slow for us to conduct corresponding experiments.
Our public code will include a “self-referential MLP-mixer” implementation, but for further experiments, we
leave the future work on such an architecture using more efficient CUDA kernels."
EXPERIMENTS,0.16043613707165108,"0
1000
2000
3000
4000
5000
6000
Training Step 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 Loss"
EXPERIMENTS,0.16121495327102803,"Task A Position 1
Task A Position 2
Task B Position 1
Task B Position 2
Task A ACL bwd
Task B ACL bwd"
EXPERIMENTS,0.16199376947040497,(a) Case: Two tasks are learned simultaneously.
EXPERIMENTS,0.16277258566978192,"0
1000
2000
3000
4000
5000
Training Step 0.0 0.5 1.0 1.5 2.0 Loss"
EXPERIMENTS,0.16355140186915887,"Task A Position 1
Task A Position 2
Task B Position 1
Task B Position 2
Task A ACL bwd
Task B ACL bwd"
EXPERIMENTS,0.16433021806853582,(b) Case: One task is learned first (here Task A).
EXPERIMENTS,0.16510903426791276,"Figure 2: ACL/No-case meta-training curves displaying 6 individual meta-training loss terms, when
the last term of the ACL objective (the backward tranfer loss; “Task A ACL bwd” and “Task B ACL
bwd” in the legend) is not minimized (ACL/No case in Tables 1 and 2). Here Task A is Omniglot and
Task B is Mini-ImageNet. We observe that, in both cases, without explicit minimization, backward
transfer capability (purple and brown curves) of the learned learning algorithm gradually degrades
as it learns to learn a new task (all other colors), causing in-context catastrophic forgetting. Note
that blue/orange and green/red curve pairs almost overlap; indicating that when a task is learned, the
model can learn it whether it is in the first or second segment of the continual learning sequence."
EXPERIMENTS,0.1658878504672897,"incremental” CL setting (see Appendix A.1). We consider two meta-training task combinations:
191"
EXPERIMENTS,0.16666666666666666,"Omniglot [23] and Mini-ImageNet [21, 22] or FC100 [24] (which is based on CIFAR100 [27]) and
192"
EXPERIMENTS,0.1674454828660436,"Mini-ImageNet. The order of appearance of two tasks within meta-training sequences is alternated
193"
EXPERIMENTS,0.16822429906542055,"for every batch. Appendix A.2 provides further details. We compare systems trained with or without
194"
EXPERIMENTS,0.1690031152647975,"the backward transfer term in the ACL loss (the last term in Eq. 4).
195"
EXPERIMENTS,0.16978193146417445,"Unless otherwise indicated (e.g, later for classic Split-MNIST; Sec. 4.3), all tasks are configured
196"
EXPERIMENTS,0.1705607476635514,"to be a 5-way classification task. This is one of the classic configurations for few-shot learning tasks,
197"
EXPERIMENTS,0.17133956386292834,"and also allows us to evaluate the principle of ACL with reasonable computational costs (like any
198"
EXPERIMENTS,0.1721183800623053,"sequence learning-based meta-learning methods, scaling this to many more classes is challenging; we
199"
EXPERIMENTS,0.17289719626168223,"also discuss this in Sec. 5). For standard datasets such as MNIST, we split the dataset into sub-datasets
200"
EXPERIMENTS,0.17367601246105918,"of disjoint classes [81]: for example for MNIST which is originally a 10-way classification task, we
201"
EXPERIMENTS,0.17445482866043613,"split it into two 5-way tasks, one consisting of images of class ‘0’ to ‘4’ (‘MNIST-04’), and another
202"
EXPERIMENTS,0.17523364485981308,"one made of class ‘5’ to ‘9’ images (‘MNIST-59’). When we refer to a dataset without specifying
203"
EXPERIMENTS,0.17601246105919002,"the class range, we refer to the first sub-set. Unless stated otherwise, we concatenate 15 examples
204"
EXPERIMENTS,0.17679127725856697,"from each class for each task in the context for both meta-training and meta-testing (resulting in
205"
EXPERIMENTS,0.17757009345794392,"sequences of length 75 for each task). All images are resized to 32 × 32-size 3-channel images, and
206"
EXPERIMENTS,0.17834890965732086,"normalized according to the original dataset statistics. We refer to Appendix A for further details.
207"
EXPERIMENTS,0.1791277258566978,"Table 1 shows the results when the models are meta-tested on the test sets of the corresponding
208"
EXPERIMENTS,0.17990654205607476,"few-shot learning datasets used for meta-training. We observe that for both pairs of meta-training
209"
EXPERIMENTS,0.1806853582554517,"tasks, the models without the ACL loss catastrophically forget the first task after learning the second
210"
EXPERIMENTS,0.18146417445482865,"one: the accuracy on the first task is at the chance level of about 20% for 5-way classification after
211"
EXPERIMENTS,0.1822429906542056,"learning the second task in-context (see rows with “ACL No”). The ACL loss clearly addresses this
212"
EXPERIMENTS,0.18302180685358255,"problem: the ACL-learned CL algorithms preserve the performance of the first task. This effect is
213"
EXPERIMENTS,0.1838006230529595,"particularly pronounced in the Omniglot/Mini-ImageNet case (involving two very different domains).
214"
EXPERIMENTS,0.18457943925233644,"Table 2 shows evaluations of the same models but using two standard datasets, 5-way MNIST and
215"
EXPERIMENTS,0.1853582554517134,"CIFAR-10, for meta-testing. Again, ACL-trained models better preserve the memory of the first
216"
EXPERIMENTS,0.18613707165109034,"task after learning the second one. In the Omniglot/Mini-ImageNet case, we even observe certain
217"
EXPERIMENTS,0.18691588785046728,"positive backward tranfer effects: in particular, in the “MNIST-then-CIFAR10” continual learning
218"
EXPERIMENTS,0.18769470404984423,"case, the performance on MNIST noticeably improves after learning CIFAR10 (possibly leveraging
219"
EXPERIMENTS,0.18847352024922118,"‘more data’ provided in-context).
220"
EXPERIMENTS,0.18925233644859812,"4.2
Analysis: Emergence of In-Context Catastrophic Forgetting
221"
EXPERIMENTS,0.19003115264797507,"Now we closely look at the emergence of “in-context catastrophic forgetting” during meta-training
222"
EXPERIMENTS,0.19080996884735202,"for the baseline models trained without the backward transfer term (the last/third term in Eq. 4) in
223"
EXPERIMENTS,0.19158878504672897,"Table 3: Classification accuracies (%) on the Split-MNIST domain-incremental (DIL) and class-
incremental learning (CIL) settings [6]. Both tasks are 5-task CL problems. For the CIL case, we
also report the 2-task case for which we can directly evaluate our out-of-the-box ACL meta-learner
of Sec. 4.1 (trained with a 5-way output and the 2-task ACL loss) which, however, is not applicable
(N.A.) to the 5-task CIL requiring a 10-way output. Mean/std over 10 training/meta-testing runs. No
method here requires replay memory. See Appendix A.7 & B for further details and discussions."
EXPERIMENTS,0.1923676012461059,"Domain Incremental
Class Incremental"
EXPERIMENTS,0.19314641744548286,"Method
5-task
2-task
5-task"
EXPERIMENTS,0.1939252336448598,"Plain Stochastic Gradient Descent (SGD)
63.2 ± 0.4
48.8 ± 0.1 19.5 ± 0.1
Adam
55.2 ± 1.4
49.7 ± 0.1 19.7 ± 0.1"
EXPERIMENTS,0.19470404984423675,"Adam + L2
66.0 ± 3.7
51.8 ± 1.9 22.5 ± 1.1
Elastic Weight Consolidation (EWC)
58.9 ± 2.6
49.7 ± 0.1 19.8 ± 0.1
Online EWC
57.3 ± 1.4
49.7 ± 0.1 19.8 ± 0.1
Synaptic Intelligence (SI)
64.8 ± 3.1
49.4 ± 0.2 19.7 ± 0.1
Memory Aware Synapses (MAS)
68.6 ± 6.9
49.6 ± 0.1 19.5 ± 0.3
Learning w/o Forgetting (LwF)
71.0 ± 1.3
-
24.2 ± 0.3"
EXPERIMENTS,0.1954828660436137,"Online-aware Meta Learning (OML)
69.9 ± 2.8
46.6 ± 7.2 24.9 ± 4.1
+ optimized # meta-testing iterations
73.6 ± 5.3
62.1 ± 7.9 34.2 ± 4.6"
EXPERIMENTS,0.19626168224299065,"Generative Meta-Continual Learning (GeMCL)
63.8 ± 3.8
91.2 ± 2.8 79.0 ± 2.1"
EXPERIMENTS,0.1970404984423676,"ACL (Out-of-the-box, DIL, 2-task ACL model; Sec. 4.1)
72.2 ± 0.9
71.5 ± 5.9
N.A.
+ meta-finetuned with 5-task ACL loss, Omniglot
84.5 ± 1.6
96.0 ± 1.0 84.3 ± 1.2"
EXPERIMENTS,0.19781931464174454,"the ACL objective loss (corresponding to the ACL/No cases in Tables 1 and 2). We focus on the
224"
EXPERIMENTS,0.1985981308411215,"Omniglot/Mini-ImageNet case, but similar trends can also be observed in the FC100/Mini-ImageNet
225"
EXPERIMENTS,0.19937694704049844,"case. Figures 2a and 2b show two representative cases we typically observe. These figures show an
226"
EXPERIMENTS,0.20015576323987538,"evolution of six individual meta-training loss terms (the lower the better), reported separately for
227"
EXPERIMENTS,0.20093457943925233,"the cases where Task A (here Omniglot) or Task B (here Mini-ImageNet) appears at the first (1) or
228"
EXPERIMENTS,0.20171339563862928,"second (2) position in the 2-task CL meta-training training sequences. 4 out of 6 curves correspond to
229"
EXPERIMENTS,0.20249221183800623,"the learning progress, showing whether the model becomes capable of in-context learning the given
230"
EXPERIMENTS,0.20327102803738317,"task (A or B) at the given position (1 or 2). The 2 remaining curves are the ACL backward tranfer
231"
EXPERIMENTS,0.20404984423676012,"losses, also measured for Task A and B separately here.
232"
EXPERIMENTS,0.20482866043613707,"Figure 2a shows the case where two tasks are learned about at the same time. We observe that when
233"
EXPERIMENTS,0.205607476635514,"the learning curves go down, the ACL losses go up, indicating that more the model learns, more it
234"
EXPERIMENTS,0.20638629283489096,"tends to forget the task in-context learned previously. We also find this same trend when one task
235"
EXPERIMENTS,0.2071651090342679,"is learned before the other one as is the case in Figure 2b. Here Task A alone is learned first; while
236"
EXPERIMENTS,0.20794392523364486,"Task B is not learned, both learning and ACL curves go down for Task A (essentially, as the model
237"
EXPERIMENTS,0.2087227414330218,"does not learn the second task, there is no force that encourages forgetting). After around 3000 steps,
238"
EXPERIMENTS,0.20950155763239875,"the model also starts learning Task B. From this point, the ACL loss for Task A also starts to go
239"
EXPERIMENTS,0.2102803738317757,"up, indicating again an opposing force effect between learning a new task and remembering a past
240"
EXPERIMENTS,0.21105919003115264,"task. These observations clearly indicate that, without explicitly taking into account the backward
241"
EXPERIMENTS,0.2118380062305296,"transfer loss as part of learning objectives, our gradient descent search tends to find solutions/CL
242"
EXPERIMENTS,0.21261682242990654,"algorithms that prefer to erase previously learned knowledge (this is rather intuitive; it seems easier to
243"
EXPERIMENTS,0.21339563862928349,"find such algorithms that ignore any influence of the current learning to past learning than those that
244"
EXPERIMENTS,0.21417445482866043,"also preserve prior knowledge). In all cases, we find our ACL objective to be crucial for the learned
245"
EXPERIMENTS,0.21495327102803738,"CL algorithms to be capable of remembering the old task while also learning the new one.
246"
GENERAL EVALUATION,0.21573208722741433,"4.3
General Evaluation
247"
GENERAL EVALUATION,0.21651090342679127,"Evaluation on Standard Split-MNIST. Here we evaluate ACL on the standard Split-MNIST task in
248"
GENERAL EVALUATION,0.21728971962616822,"domain-incremental and class-incremental settings [6, 28], and compare its performance to existing
249"
GENERAL EVALUATION,0.21806853582554517,"CL and meta-CL algorithms (see Appendix A.7 for full references of these methods). Our comparison
250"
GENERAL EVALUATION,0.21884735202492211,"focuses on methods that do not require replay memory. Table 3 shows the results. Since our
251"
GENERAL EVALUATION,0.21962616822429906,"ACL-trained models are general-purpose learners, they can be directly evaluated (meta-tested) on
252"
GENERAL EVALUATION,0.220404984423676,"a new task, here Split-MNIST. The second-to-last row of Table 3, “ACL (Out-of-the-box model)”,
253"
GENERAL EVALUATION,0.22118380062305296,"corresponds to our model from Sec. 4.1 meta-trained on Omniglot and Mini-ImageNet using the
254"
GENERAL EVALUATION,0.2219626168224299,"2-task ACL objective. It performs very competitively with the best existing methods in the domain-
255"
GENERAL EVALUATION,0.22274143302180685,"incremental setting, while it largely outperforms them (all but another meta-CL method, GeMCL) in
256"
GENERAL EVALUATION,0.2235202492211838,"the 2-task class-incremental setting. The same model can be further meta-finetuned using the 5-task
257"
GENERAL EVALUATION,0.22429906542056074,"version of the ACL loss (here we only used Omniglot as the meta-training data). The resulting model
258"
GENERAL EVALUATION,0.2250778816199377,"(the last row of Table 3) outperforms all other methods in all settings studied here. Note that on
259"
GENERAL EVALUATION,0.22585669781931464,"the ‘in-domain’ Omniglot test set, ACL and GeMCL perform similarly (see Appendix B.2/Table 9).
260"
GENERAL EVALUATION,0.2266355140186916,"We are not aware of any existing hand-crafted CL algorithms that can achieve ACL’s performance
261"
GENERAL EVALUATION,0.22741433021806853,"without any replay memory. We refer to Appendix A.7/B for further discussions and ablation studies.
262"
GENERAL EVALUATION,0.22819314641744548,"Evaluation on diverse task domains. Using the setting of Sec. 4.1, we also evaluate our ACL-trained
263"
GENERAL EVALUATION,0.22897196261682243,"models for CL involving more tasks/domains; using meta-test sequences made of MNIST, CIFAR-10,
264"
GENERAL EVALUATION,0.22975077881619937,"and Fashion MNIST. We also evaluate the impact of the number of tasks in the ACL objective: in
265"
GENERAL EVALUATION,0.23052959501557632,"addition to the model meta-trained on Omniglot/Mini-ImageNet (Sec. 4.1), we also meta-train a model
266"
GENERAL EVALUATION,0.23130841121495327,"(with the same architecture and hyper-parameters) using 3 tasks, Omniglot, Mini-ImageNet, and
267"
GENERAL EVALUATION,0.23208722741433022,"FC100, using the 3-task ACL objective (see Appendix A.5); which is meta-trained not only on longer
268"
GENERAL EVALUATION,0.23286604361370716,"CL sequences but also on more data. The full results of this experiment can be found in Appendix
269"
GENERAL EVALUATION,0.2336448598130841,"B.4. We find that the two ACL-trained models are indeed capable of retaining the knowledge without
270"
GENERAL EVALUATION,0.23442367601246106,"catastrophic forgetting for multiple tasks during meta-testing, while the performance on prior tasks
271"
GENERAL EVALUATION,0.235202492211838,"gradually degrades as the model learns new tasks, and performance on new tasks becomes moderate
272"
GENERAL EVALUATION,0.23598130841121495,"(see also Sec. 5 on limitations). The 3-task version outperforms the 2-task one overall, encouragingly
273"
GENERAL EVALUATION,0.2367601246105919,"indicating a potential for further improvements even with a fixed parameter count.
274"
GENERAL EVALUATION,0.23753894080996885,"Going beyond: limitations and outlook. The experiments presented above effectively demonstrate
275"
GENERAL EVALUATION,0.2383177570093458,"the possibility to encode a continual learning algorithm into self-referential weight matrices, that
276"
GENERAL EVALUATION,0.23909657320872274,"outperforms handcrafted learning algorithms and existing metalearning approaches for CL. While
277"
GENERAL EVALUATION,0.2398753894080997,"we consider this as an important result for metalearning and in-context learning in general, we note
278"
GENERAL EVALUATION,0.24065420560747663,"that current state-of-the-art CL methods use neither regularization-based CL algorithms nor meta-
279"
GENERAL EVALUATION,0.24143302180685358,"continual learning methods we mention above, but the so-called learning to prompt (L2P)-family
280"
GENERAL EVALUATION,0.24221183800623053,"of methods [33, 34] that leverage pre-trained models, namely a vision Transformer (ViT) pre-trained
281"
GENERAL EVALUATION,0.24299065420560748,"on ImageNet [76]. A natural question we should ask is whether we could foresee ACL beyond the
282"
GENERAL EVALUATION,0.24376947040498442,"scope considered so far, and evaluate it in such a setting. To study this, we take a pre-trained (frozen)
283"
GENERAL EVALUATION,0.24454828660436137,"vision model, and add self-referential layers (to be meta-trained from scratch) on top of it to build a
284"
GENERAL EVALUATION,0.24532710280373832,"continual learner. This allows us to highlight an important challenge of in-context CL in what follows.
285"
GENERAL EVALUATION,0.24610591900311526,"We use two tasks from the L2P works above [33, 34]: 5-datasets [32] and Split-CIFAR-100, in the
286"
GENERAL EVALUATION,0.2468847352024922,"class-incremental setting, but we focus on a “mini” versions thereof: we only use the two first classes
287"
GENERAL EVALUATION,0.24766355140186916,"within each task (i.e., 2-way version) and for Split-CIFAR100, we only use the 5 first tasks; as we’ll
288"
GENERAL EVALUATION,0.2484423676012461,"see, this setting is enough to illustrate an important limitation of in-context CL. Again following
289"
GENERAL EVALUATION,0.24922118380062305,"L2P [33, 34], we use ViT-B/16 [76] (available via PyTorch) as the pre-trained vision model, which
290"
GENERAL EVALUATION,0.25,"we keep frozen. We use the same configuration for the self-referential component from the Split-
291"
GENERAL EVALUATION,0.2507788161993769,"MNIST experiment. We meta-train the resulting model using Mini-ImageNet and Omniglot with the
292"
GENERAL EVALUATION,0.2515576323987539,"5-task ACL loss. Table 4 shows the results. Even in this simple “mini” version of the tasks, ACL’s
293"
GENERAL EVALUATION,0.2523364485981308,"performance is far behind that of L2P methods. Notably, the frozen ImageNet-pre-trained features
294"
GENERAL EVALUATION,0.2531152647975078,"with the meta-learner trained on Mini-ImageNet and Omniglot are not enough to perform well on the
295"
GENERAL EVALUATION,0.2538940809968847,"5-th task of Split-CIFAR100, and SVHN and notMNIST of 5-datasets. This shows the necessity to
296"
GENERAL EVALUATION,0.2546728971962617,"meta-train on more diverse tasks for in-context CL to be possibly successful in more general settings.
297"
GENERAL EVALUATION,0.2554517133956386,"Table 4: Experiments with “mini” Split-CIFAR100 and 5-datasets tasks. Meta-training is done using
Mini-ImageNet and Omniglot. All meta-evaluation images are therefore from unseen domains.
Numbers marked with * are reference numbers (evaluated in the more challenging, original version
of these tasks) which can not be directly compared to ours."
GENERAL EVALUATION,0.2562305295950156,"Split-CIFAR100
5-datasets"
GENERAL EVALUATION,0.2570093457943925,"L2P [34]
83.9* ± 0.3
81.1* ± 0.9
DualPrompt [34]
86.5* ± 0.3
88.1* ± 0.4"
GENERAL EVALUATION,0.25778816199376947,"ACL (Individual Task)
Task 1
95.9 ± 0.9
CIFAR10
91.3 ± 1.2
Task 2
85.6 ± 3.6
MNIST
98.9 ± 0.3
Task 3
93.4 ± 1.4
Fashion
93.5 ± 2.0
Task 4
97.0 ± 0.7
SVHN
66.1 ± 9.4
Task 5
67.6 ± 7.0
notMNIST
76.3 ± 6.7"
GENERAL EVALUATION,0.2585669781931464,"ACL
68.3 ± 2.0
61.5 ± 2.1"
DISCUSSION,0.25934579439252337,"5
Discussion
298"
DISCUSSION,0.2601246105919003,"Other Limitations. In addition to the limitations already mentioned above, here we discuss others.
299"
DISCUSSION,0.26090342679127726,"First of all, as an in-context/learned learning algorithm, there are challenges in terms of both domain
300"
DISCUSSION,0.2616822429906542,"and length generalization (we qualitatively observe these to some extent in Sec. 4; further discussion
301"
DISCUSSION,0.26246105919003115,"and experimental results are presented in Appendix B.3 & B.5). Regarding the length generalization,
302"
DISCUSSION,0.2632398753894081,"we note that unlike the standard “quadratic"" Transformers, linear Transformers/FWPs-like SRWMs
303"
DISCUSSION,0.26401869158878505,"can be trained by carrying over states across two consecutive batches for arbitrarily long sequences.
304"
DISCUSSION,0.26479750778816197,"Such an approach has been successfully applied to language modeling with FWPs [67]. This
305"
DISCUSSION,0.26557632398753894,"possibility, however, has not been investigated here, and is left for future work. Also, directly scaling
306"
DISCUSSION,0.26635514018691586,"ACL for real-world tasks requiring many more classes does not seem straightforward: it would
307"
DISCUSSION,0.26713395638629284,"require very long training sequences. That said, it may be possible that ACL could be achieved
308"
DISCUSSION,0.26791277258566976,"without exactly following the process we propose; as we discuss below for the case of LLMs, certain
309"
DISCUSSION,0.26869158878504673,"real-world data may naturally give rise to an ACL-like objective. This work is also limited to the
310"
DISCUSSION,0.26947040498442365,"task of image classification, which can be solved by feedforward NNs. Future work may investigate
311"
DISCUSSION,0.2702492211838006,"the possibility to extend ACL to continual learning of sequence learning tasks, such as continually
312"
DISCUSSION,0.27102803738317754,"learning new languages. Finally, ACL learns CL algorithms that are specific to the pre-specified
313"
DISCUSSION,0.2718068535825545,"model architecture; more general meta-learning algorithms may aim at achieving learning algorithms
314"
DISCUSSION,0.27258566978193144,"that are applicable to any model, as is the case for many classic learning algorithms.
315"
DISCUSSION,0.2733644859813084,"Related work. There are several recent works that are catagorized as ‘meta-continual learning’ or
316"
DISCUSSION,0.27414330218068533,"‘continual meta-learning’ (see, e.g., [29, 30, 82–84, 51]). For example, Javed and White [29], Beaulieu
317"
DISCUSSION,0.2749221183800623,"et al. [30] use “model-agnostic meta-learning” (MAML; [85, 86]) to meta-learn representations for
318"
DISCUSSION,0.2757009345794392,"CL while still making use of classic learning algorithms for CL; this requires tuning of the learning
319"
DISCUSSION,0.2764797507788162,"rate and number of iterations for optimal performance during CL at meta-test time (see, e.g., Appendix
320"
DISCUSSION,0.2772585669781931,"A.7). In contrast, our approach learn learning algorithms in the spirit of Hochreiter et al. [14], Younger
321"
DISCUSSION,0.2780373831775701,"et al. [15]; this may be categorized as ‘in-context continual learning.’ Several recent works (see, e.g.,
322"
DISCUSSION,0.278816199376947,"[87, 88]) mention the possibility of such in-context CL but existing works [19, 89, 90] that learn mul-
323"
DISCUSSION,0.279595015576324,"tiple tasks sequentially in-context do not focus on catastrophic forgetting which is one of the central
324"
DISCUSSION,0.2803738317757009,"challenges of CL. Here we show that in-context learning also suffers from catastrophic forgetting in
325"
DISCUSSION,0.2811526479750779,"general (Sec. 4.1-4.2) and propose ACL to address this problem. We also note that the use of SRWM is
326"
DISCUSSION,0.2819314641744548,"relevant to ‘continual meta-learning’ since with a regular sequence processor with slow weights, there
327"
DISCUSSION,0.2827102803738318,"remains the question of how to continually learn the slow weights (meta-parameters). In principle, re-
328"
DISCUSSION,0.2834890965732087,"cursive self-modification as in SRWM is an answer to this question as it collapses such meta-levels into
329"
DISCUSSION,0.2842679127725857,"single self-reference [12]. We also refer to [91–93] for other prior work on meta-continual learning.
330"
DISCUSSION,0.2850467289719626,"Artificial v. Natural ACL in Large Language Models? Recently, “on-the-fly” few-shot/meta
331"
DISCUSSION,0.28582554517133957,"learning capability of sequence processing NNs has attracted broader interests in the context of large
332"
DISCUSSION,0.2866043613707165,"language models (LLMs; [94]). In fact, the task of language modeling itself has a form of sequence
333"
DISCUSSION,0.28738317757009346,"processing with error feedback (essential for meta-learning [95]): the correct label to be predicted is
334"
DISCUSSION,0.2881619937694704,"fed to the model with a delay of one time step in an auto-regressive manner. Trained on a large amount
335"
DISCUSSION,0.28894080996884736,"of text covering a wide variety of credit assignment paths, LLMs exhibit certain sequential few-shot
336"
DISCUSSION,0.2897196261682243,"learning capabilities in practice [96]. This was rebranded as in-context learning, and has been the
337"
DISCUSSION,0.29049844236760125,"subject of numerous recent studies (e.g., [97–103, 71, 72]). Here we explicitly/artificially construct
338"
DISCUSSION,0.29127725856697817,"ACL meta-training sequences and objectives, but in modern LLMs trained on a large amount of data
339"
DISCUSSION,0.29205607476635514,"mixing a large diversity of dependencies using a large backpropagation span, it is conceivable that
340"
DISCUSSION,0.29283489096573206,"some ACL-like objectives may naturally appear in the data.
341"
CONCLUSION,0.29361370716510904,"6
Conclusion
342"
CONCLUSION,0.29439252336448596,"Our Automated Continual Learning (ACL) trains sequence-processing self-referential neural networks
343"
CONCLUSION,0.29517133956386293,"(SRNNs) to learn their own in-context continual (meta-)learning algorithms. ACL encodes classic
344"
CONCLUSION,0.29595015576323985,"desiderata for continual learning (e.g., forward and backward transfer) into the objective function of
345"
CONCLUSION,0.2967289719626168,"the meta-learner. ACL uses gradient descent to deal with classic challenges of CL, to automatically
346"
CONCLUSION,0.29750778816199375,"discover CL algorithms with good behavior. Once trained, our SRNNs autonomously run their
347"
CONCLUSION,0.2982866043613707,"own CL algorithms without requiring any human intervention. Our experiments reveal the original
348"
CONCLUSION,0.29906542056074764,"problem of in-context catastrophic forgetting, and demonstrate the effectiveness of the proposed
349"
CONCLUSION,0.2998442367601246,"approach to combat it. We demonstrate very promising results on the classic Split-MNIST benchmark
350"
CONCLUSION,0.30062305295950154,"where existing hand-crafted algorithms fail, while also discussing its limitations in more general
351"
CONCLUSION,0.3014018691588785,"scenarios. We believe this comprehensive study to be an important step for in-context CL research.
352"
REFERENCES,0.30218068535825543,"References
353"
REFERENCES,0.3029595015576324,"[1] David Eagleman. Livewired: The inside story of the ever-changing brain. 2020.
354"
REFERENCES,0.3037383177570093,"[2] Michael McCloskey and Neal J Cohen. Catastrophic interference in connectionist networks:
355"
REFERENCES,0.3045171339563863,"The sequential learning problem. In Psychology of learning and motivation, volume 24, pages
356"
REFERENCES,0.3052959501557632,"109–165. 1989.
357"
REFERENCES,0.3060747663551402,"[3] Roger Ratcliff. Connectionist models of recognition memory: constraints imposed by learning
358"
REFERENCES,0.3068535825545171,"and forgetting functions. Psychological review, 97(2):285, 1990.
359"
REFERENCES,0.3076323987538941,"[4] Robert M French. Catastrophic forgetting in connectionist networks. Trends in cognitive
360"
REFERENCES,0.308411214953271,"sciences, 3(4):128–135, 1999.
361"
REFERENCES,0.309190031152648,"[5] James L McClelland, Bruce L McNaughton, and Randall C O’Reilly. Why there are comple-
362"
REFERENCES,0.3099688473520249,"mentary learning systems in the hippocampus and neocortex: insights from the successes and
363"
REFERENCES,0.3107476635514019,"failures of connectionist models of learning and memory. Psychological review, 102(3):419,
364"
REFERENCES,0.3115264797507788,"1995.
365"
REFERENCES,0.31230529595015577,"[6] Yen-Chang Hsu, Yen-Cheng Liu, Anita Ramasamy, and Zsolt Kira. Re-evaluating continual
366"
REFERENCES,0.3130841121495327,"learning scenarios: A categorization and case for strong baselines. In NeurIPS Workshop on
367"
REFERENCES,0.31386292834890966,"Continual Learning, Montréal, Canada, December 2018.
368"
REFERENCES,0.3146417445482866,"[7] Chris A Kortge. Episodic memory in connectionist networks. In 12th Annual Conference. CSS
369"
REFERENCES,0.31542056074766356,"Pod, pages 764–771, 1990.
370"
REFERENCES,0.3161993769470405,"[8] Robert M French. Using semi-distributed representations to overcome catastrophic forgetting
371"
REFERENCES,0.31697819314641745,"in connectionist networks. In Proc. Cognitive science society conference, volume 1, pages
372"
REFERENCES,0.3177570093457944,"173–178, 1991.
373"
REFERENCES,0.31853582554517135,"[9] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins,
374"
REFERENCES,0.31931464174454827,"Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska,
375"
REFERENCES,0.32009345794392524,"et al. Overcoming catastrophic forgetting in neural networks. Proc. National academy of
376"
REFERENCES,0.32087227414330216,"sciences, 114(13):3521–3526, 2017.
377"
REFERENCES,0.32165109034267914,"[10] Jonathan Schwarz, Wojciech Czarnecki, Jelena Luketina, Agnieszka Grabska-Barwinska,
378"
REFERENCES,0.32242990654205606,"Yee Whye Teh, Razvan Pascanu, and Raia Hadsell. Progress & compress: A scalable frame-
379"
REFERENCES,0.32320872274143303,"work for continual learning. In Proc. Int. Conf. on Machine Learning (ICML), pages 4535–
380"
REFERENCES,0.32398753894080995,"4544, Stockholm, Sweden, July 2018.
381"
REFERENCES,0.3247663551401869,"[11] Friedemann Zenke, Ben Poole, and Surya Ganguli. Continual learning through synaptic
382"
REFERENCES,0.32554517133956384,"intelligence. In Proc. Int. Conf. on Machine Learning (ICML), pages 3987–3995, Sydney,
383"
REFERENCES,0.3263239875389408,"Australia, August 2017.
384"
REFERENCES,0.32710280373831774,"[12] Jürgen Schmidhuber. Steps towards “self-referential” learning. Technical Report CU-CS-627-
385"
REFERENCES,0.3278816199376947,"92, Dept. of Comp. Sci., University of Colorado at Boulder, November 1992.
386"
REFERENCES,0.32866043613707163,"[13] Jürgen Schmidhuber. Evolutionary principles in self-referential learning, or on learning how
387"
REFERENCES,0.3294392523364486,"to learn: the meta-meta-... hook. PhD thesis, Technische Universität München, 1987.
388"
REFERENCES,0.3302180685358255,"[14] Sepp Hochreiter, A. Steven Younger, and Peter R. Conwell. Learning to learn using gradient
389"
REFERENCES,0.3309968847352025,"descent. In Proc. Int. Conf. on Artificial Neural Networks (ICANN), volume 2130, pages
390"
REFERENCES,0.3317757009345794,"87–94, Vienna, Austria, August 2001.
391"
REFERENCES,0.3325545171339564,"[15] A Steven Younger, Peter R Conwell, and Neil E Cotter. Fixed-weight on-line learning. IEEE
392"
REFERENCES,0.3333333333333333,"Transactions on Neural Networks, 10(2):272–283, 1999.
393"
REFERENCES,0.3341121495327103,"[16] Neil E Cotter and Peter R Conwell. Learning algorithms and fixed dynamics. In Proc. Int.
394"
REFERENCES,0.3348909657320872,"Joint Conf. on Neural Networks (IJCNN), pages 799–801, Seattle, WA, USA, July 1991.
395"
REFERENCES,0.3356697819314642,"[17] Neil E Cotter and Peter R Conwell. Fixed-weight networks can learn. In Proc. Int. Joint Conf.
396"
REFERENCES,0.3364485981308411,"on Neural Networks (IJCNN), pages 553–559, San Diego, CA, USA, June 1990.
397"
REFERENCES,0.3372274143302181,"[18] Nikhil Mishra, Mostafa Rohaninejad, Xi Chen, and Pieter Abbeel. A simple neural attentive
398"
REFERENCES,0.338006230529595,"meta-learner. In Int. Conf. on Learning Representations (ICLR), Vancouver, Cananda, 2018.
399"
REFERENCES,0.338785046728972,"[19] Kazuki Irie, Imanol Schlag, Róbert Csordás, and Jürgen Schmidhuber.
A modern self-
400"
REFERENCES,0.3395638629283489,"referential weight matrix that learns to modify itself. In Proc. Int. Conf. on Machine Learning
401"
REFERENCES,0.34034267912772587,"(ICML), pages 9660–9677, Baltimore, MA, USA, July 2022.
402"
REFERENCES,0.3411214953271028,"[20] Stephen T Grossberg. Studies of mind and brain: Neural principles of learning, perception,
403"
REFERENCES,0.34190031152647976,"development, cognition, and motor control. Springer, 1982.
404"
REFERENCES,0.3426791277258567,"[21] Oriol Vinyals, Charles Blundell, Tim Lillicrap, Koray Kavukcuoglu, and Daan Wierstra.
405"
REFERENCES,0.34345794392523366,"Matching networks for one shot learning. In Proc. Advances in Neural Information Processing
406"
REFERENCES,0.3442367601246106,"Systems (NIPS), pages 3630–3638, Barcelona, Spain, December 2016.
407"
REFERENCES,0.34501557632398755,"[22] Sachin Ravi and Hugo Larochelle. Optimization as a model for few-shot learning. In Int. Conf.
408"
REFERENCES,0.34579439252336447,"on Learning Representations (ICLR), Toulon, France, April 2017.
409"
REFERENCES,0.34657320872274144,"[23] Brenden M Lake, Ruslan Salakhutdinov, and Joshua B Tenenbaum. Human-level concept
410"
REFERENCES,0.34735202492211836,"learning through probabilistic program induction. Science, 350(6266):1332–1338, 2015.
411"
REFERENCES,0.34813084112149534,"[24] Boris N. Oreshkin, Pau Rodríguez López, and Alexandre Lacoste. TADAM: task dependent
412"
REFERENCES,0.34890965732087226,"adaptive metric for improved few-shot learning. In Proc. Advances in Neural Information
413"
REFERENCES,0.34968847352024923,"Processing Systems (NeurIPS), pages 719–729, Montréal, Canada, December 2018.
414"
REFERENCES,0.35046728971962615,"[25] Yann LeCun, Corinna Cortes, and Christopher JC Burges. The MNIST database of handwritten
415"
REFERENCES,0.3512461059190031,"digits. URL http://yann. lecun. com/exdb/mnist, 1998.
416"
REFERENCES,0.35202492211838005,"[26] Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-MNIST: a novel image dataset for
417"
REFERENCES,0.352803738317757,"benchmarking machine learning algorithms. Preprint arXiv:1708.07747, 2017.
418"
REFERENCES,0.35358255451713394,"[27] Alex Krizhevsky. Learning multiple layers of features from tiny images. Master’s thesis,
419"
REFERENCES,0.3543613707165109,"Computer Science Department, University of Toronto, 2009.
420"
REFERENCES,0.35514018691588783,"[28] Gido M Van de Ven and Andreas S Tolias. Three scenarios for continual learning. In NeurIPS
421"
REFERENCES,0.3559190031152648,"Workshop on Continual Learning, Montréal, Canada, December 2018.
422"
REFERENCES,0.35669781931464173,"[29] Khurram Javed and Martha White. Meta-learning representations for continual learning.
423"
REFERENCES,0.3574766355140187,"In Proc. Advances in Neural Information Processing Systems (NeurIPS), pages 1818–1828,
424"
REFERENCES,0.3582554517133956,"Vancouver, BC, Canada, December 2019.
425"
REFERENCES,0.3590342679127726,"[30] Shawn Beaulieu, Lapo Frati, Thomas Miconi, Joel Lehman, Kenneth O. Stanley, Jeff Clune,
426"
REFERENCES,0.3598130841121495,"and Nick Cheney. Learning to continually learn. In Proc. European Conf. on Artificial
427"
REFERENCES,0.3605919003115265,"Intelligence (ECAI), pages 992–1001, August 2020.
428"
REFERENCES,0.3613707165109034,"[31] Mohammadamin Banayeeanzade, Rasoul Mirzaiezadeh, Hosein Hasani, and Mahdieh So-
429"
REFERENCES,0.3621495327102804,"leymani. Generative vs. discriminative: Rethinking the meta-continual learning. In Proc.
430"
REFERENCES,0.3629283489096573,"Advances in Neural Information Processing Systems (NeurIPS), pages 21592–21604, Virtual
431"
REFERENCES,0.3637071651090343,"only, December 2021.
432"
REFERENCES,0.3644859813084112,"[32] Sayna Ebrahimi, Franziska Meier, Roberto Calandra, Trevor Darrell, and Marcus Rohrbach.
433"
REFERENCES,0.3652647975077882,"Adversarial continual learning. In Proc. European Conf. on Computer Vision (ECCV), pages
434"
REFERENCES,0.3660436137071651,"386–402, Glasgow, UK, August 2020.
435"
REFERENCES,0.36682242990654207,"[33] Zifeng Wang, Zizhao Zhang, Chen-Yu Lee, Han Zhang, Ruoxi Sun, Xiaoqi Ren, Guolong Su,
436"
REFERENCES,0.367601246105919,"Vincent Perot, Jennifer G. Dy, and Tomas Pfister. Learning to prompt for continual learning.
437"
REFERENCES,0.36838006230529596,"In Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), pages 139–149,
438"
REFERENCES,0.3691588785046729,"New Orleans, LA, USA, June 2022.
439"
REFERENCES,0.36993769470404986,"[34] Zifeng Wang, Zizhao Zhang, Sayna Ebrahimi, Ruoxi Sun, Han Zhang, Chen-Yu Lee, Xiaoqi
440"
REFERENCES,0.3707165109034268,"Ren, Guolong Su, Vincent Perot, Jennifer G. Dy, and Tomas Pfister. Dualprompt: Complemen-
441"
REFERENCES,0.37149532710280375,"tary prompting for rehearsal-free continual learning. In Proc. European Conf. on Computer
442"
REFERENCES,0.37227414330218067,"Vision (ECCV), pages 631–648, Tel Aviv, Israel, October 2022.
443"
REFERENCES,0.37305295950155765,"[35] Sebastian Thrun. Lifelong learning algorithms. In Learning to learn, pages 181–209. 1998.
444"
REFERENCES,0.37383177570093457,"[36] Rich Caruana. Multitask learning. Machine learning, 28:41–75, 1997.
445"
REFERENCES,0.37461059190031154,"[37] Mark B. Ring. Continual Learning in Reinforcement Environments. PhD thesis, University of
446"
REFERENCES,0.37538940809968846,"Texas at Austin, Austin, TX, USA, 1994.
447"
REFERENCES,0.37616822429906543,"[38] Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick,
448"
REFERENCES,0.37694704049844235,"Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell. Progressive neural networks. Preprint
449"
REFERENCES,0.37772585669781933,"arXiv:1606.04671, 2016.
450"
REFERENCES,0.37850467289719625,"[39] Anthony Robins. Catastrophic forgetting, rehearsal and pseudorehearsal. Connection Science,
451"
REFERENCES,0.3792834890965732,"7(2):123–146, 1995.
452"
REFERENCES,0.38006230529595014,"[40] Hanul Shin, Jung Kwon Lee, Jaehong Kim, and Jiwon Kim. Continual learning with deep
453"
REFERENCES,0.3808411214953271,"generative replay. In Proc. Advances in Neural Information Processing Systems (NIPS), pages
454"
REFERENCES,0.38161993769470404,"2990–2999, Long Beach, CA, USA, December 2017.
455"
REFERENCES,0.382398753894081,"[41] David Rolnick, Arun Ahuja, Jonathan Schwarz, Timothy P. Lillicrap, and Gregory Wayne.
456"
REFERENCES,0.38317757009345793,"Experience replay for continual learning. In Proc. Advances in Neural Information Processing
457"
REFERENCES,0.3839563862928349,"Systems (NeurIPS), pages 348–358, Vancouver, Canada, December 2019.
458"
REFERENCES,0.3847352024922118,"[42] Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina Rish, Yuhai Tu, and
459"
REFERENCES,0.3855140186915888,"Gerald Tesauro. Learning to learn without forgetting by maximizing transfer and minimizing
460"
REFERENCES,0.3862928348909657,"interference. In Int. Conf. on Learning Representations (ICLR), New Orleans, LA, USA, May
461"
REFERENCES,0.3870716510903427,"2019.
462"
REFERENCES,0.3878504672897196,"[43] Yaqian Zhang, Bernhard Pfahringer, Eibe Frank, Albert Bifet, Nick Jin Sean Lim, and Yunzhe
463"
REFERENCES,0.3886292834890966,"Jia. A simple but strong baseline for online continual learning: Repeated augmented rehearsal.
464"
REFERENCES,0.3894080996884735,"In Proc. Advances in Neural Information Processing Systems (NeurIPS), New Orleans, LA,
465"
REFERENCES,0.3901869158878505,"USA, December 2022.
466"
REFERENCES,0.3909657320872274,"[44] David Lopez-Paz and Marc’Aurelio Ranzato. Gradient episodic memory for continual learning.
467"
REFERENCES,0.3917445482866044,"In Proc. Advances in Neural Information Processing Systems (NIPS), pages 6467–6476, Long
468"
REFERENCES,0.3925233644859813,"Beach, CA, USA, December 2017.
469"
REFERENCES,0.39330218068535827,"[45] Tom Veniat, Ludovic Denoyer, and Marc’Aurelio Ranzato. Efficient continual learning with
470"
REFERENCES,0.3940809968847352,"modular networks and task-driven priors. In Int. Conf. on Learning Representations (ICLR),
471"
REFERENCES,0.39485981308411217,"Virtual only, May 2021.
472"
REFERENCES,0.3956386292834891,"[46] Devang K Naik and Richard J Mammone. Meta-neural networks that learn by learning. In
473"
REFERENCES,0.39641744548286606,"Proc. International Joint Conference on Neural Networks (IJCNN), volume 1, pages 437–442,
474"
REFERENCES,0.397196261682243,"Baltimore, MD, USA, June 1992.
475"
REFERENCES,0.39797507788161995,"[47] Tom Bosc. Learning to learn neural networks. In NIPS Workshop on Reasoning, Attention,
476"
REFERENCES,0.3987538940809969,"Memory, Montreal, Canada, December 2015.
477"
REFERENCES,0.39953271028037385,"[48] Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy P. Lillicrap.
478"
REFERENCES,0.40031152647975077,"Meta-learning with memory-augmented neural networks. In Proc. Int. Conf. on Machine
479"
REFERENCES,0.40109034267912774,"Learning (ICML), pages 1842–1850, New York City, NY, USA, June 2016.
480"
REFERENCES,0.40186915887850466,"[49] Yan Duan, John Schulman, Xi Chen, Peter L Bartlett, Ilya Sutskever, and Pieter Abbeel. RL2:
481"
REFERENCES,0.40264797507788164,"Fast reinforcement learning via slow reinforcement learning. Preprint arXiv:1611.02779,
482"
REFERENCES,0.40342679127725856,"2016.
483"
REFERENCES,0.40420560747663553,"[50] Jane Wang, Zeb Kurth-Nelson, Hubert Soyer, Joel Z. Leibo, Dhruva Tirumala, Rémi Munos,
484"
REFERENCES,0.40498442367601245,"Charles Blundell, Dharshan Kumaran, and Matt M. Botvinick. Learning to reinforcement
485"
REFERENCES,0.4057632398753894,"learn. In Proc. Annual Meeting of the Cognitive Science Society (CogSci), London, UK, July
486"
REFERENCES,0.40654205607476634,"2017.
487"
REFERENCES,0.4073208722741433,"[51] Tsendsuren Munkhdalai and Hong Yu. Meta networks. In Proc. Int. Conf. on Machine
488"
REFERENCES,0.40809968847352024,"Learning (ICML), pages 2554–2563, Sydney, Australia, August 2017.
489"
REFERENCES,0.4088785046728972,"[52] Tsendsuren Munkhdalai and Adam Trischler. Metalearning with Hebbian fast weights. Preprint
490"
REFERENCES,0.40965732087227413,"arXiv:1807.05076, 2018.
491"
REFERENCES,0.4104361370716511,"[53] Thomas Miconi, Kenneth Stanley, and Jeff Clune. Differentiable plasticity: training plastic
492"
REFERENCES,0.411214953271028,"neural networks with backpropagation. In Proc. Int. Conf. on Machine Learning (ICML),
493"
REFERENCES,0.411993769470405,"pages 3559–3568, Stockholm, Sweden, July 2018.
494"
REFERENCES,0.4127725856697819,"[54] Thomas Miconi, Aditya Rawal, Jeff Clune, and Kenneth O. Stanley. Backpropamine: training
495"
REFERENCES,0.4135514018691589,"self-modifying neural networks with differentiable neuromodulated plasticity. In Int. Conf. on
496"
REFERENCES,0.4143302180685358,"Learning Representations (ICLR), New Orleans, LA, USA, May 2019.
497"
REFERENCES,0.4151090342679128,"[55] Tsendsuren Munkhdalai, Alessandro Sordoni, Tong Wang, and Adam Trischler. Metalearned
498"
REFERENCES,0.4158878504672897,"neural memory. In Proc. Advances in Neural Information Processing Systems (NeurIPS),
499"
REFERENCES,0.4166666666666667,"pages 13310–13321, Vancouver, Canada, December 2019.
500"
REFERENCES,0.4174454828660436,"[56] Louis Kirsch and Jürgen Schmidhuber. Meta learning backpropagation and improving it. In
501"
REFERENCES,0.4182242990654206,"Proc. Advances in Neural Information Processing Systems (NeurIPS), pages 14122–14134,
502"
REFERENCES,0.4190031152647975,"Virtual only, December 2021.
503"
REFERENCES,0.4197819314641745,"[57] Mark Sandler, Max Vladymyrov, Andrey Zhmoginov, Nolan Miller, Tom Madams, Andrew
504"
REFERENCES,0.4205607476635514,"Jackson, and Blaise Agüera y Arcas. Meta-learning bidirectional update rules. In Proc. Int.
505"
REFERENCES,0.42133956386292837,"Conf. on Machine Learning (ICML), pages 9288–9300, Virtual only, July 2021.
506"
REFERENCES,0.4221183800623053,"[58] Mike Huisman, Thomas M Moerland, Aske Plaat, and Jan N van Rijn. Are LSTMs good
507"
REFERENCES,0.42289719626168226,"few-shot learners? Machine Learning, pages 1–28, 2023.
508"
REFERENCES,0.4236760124610592,"[59] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
509"
REFERENCES,0.42445482866043616,"Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Proc. Advances in Neural
510"
REFERENCES,0.4252336448598131,"Information Processing Systems (NIPS), pages 5998–6008, Long Beach, CA, USA, December
511"
REFERENCES,0.42601246105919005,"2017.
512"
REFERENCES,0.42679127725856697,"[60] Kazuki Irie, Róbert Csordás, and Jürgen Schmidhuber. Practical computational power of linear
513"
REFERENCES,0.42757009345794394,"transformers and their recurrent and self-referential extensions. In Proc. Conf. on Empirical
514"
REFERENCES,0.42834890965732086,"Methods in Natural Language Processing (EMNLP), Sentosa, Singapore, 2023.
515"
REFERENCES,0.42912772585669784,"[61] Jürgen Schmidhuber. A self-referential weight matrix. In Proc. Int. Conf. on Artificial Neural
516"
REFERENCES,0.42990654205607476,"Networks (ICANN), pages 446–451, Amsterdam, Netherlands, September 1993.
517"
REFERENCES,0.43068535825545173,"[62] Jürgen Schmidhuber. Learning to control fast-weight memories: An alternative to recurrent
518"
REFERENCES,0.43146417445482865,"nets. Technical Report FKI-147-91, Institut für Informatik, Technische Universität München,
519"
REFERENCES,0.4322429906542056,"March 1991.
520"
REFERENCES,0.43302180685358255,"[63] Jürgen Schmidhuber. Learning to control fast-weight memories: An alternative to dynamic
521"
REFERENCES,0.4338006230529595,"recurrent networks. Neural Computation, 4(1):131–139, 1992.
522"
REFERENCES,0.43457943925233644,"[64] Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, and François Fleuret. Transformers
523"
REFERENCES,0.4353582554517134,"are RNNs: Fast autoregressive transformers with linear attention. In Proc. Int. Conf. on
524"
REFERENCES,0.43613707165109034,"Machine Learning (ICML), Virtual only, July 2020.
525"
REFERENCES,0.4369158878504673,"[65] Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song, Andreea Gane,
526"
REFERENCES,0.43769470404984423,"Tamas Sarlos, Peter Hawkins, Jared Davis, Afroz Mohiuddin, Lukasz Kaiser, et al. Rethinking
527"
REFERENCES,0.4384735202492212,"attention with performers. In Int. Conf. on Learning Representations (ICLR), Virtual only,
528"
REFERENCES,0.4392523364485981,"2021.
529"
REFERENCES,0.4400311526479751,"[66] Hao Peng, Nikolaos Pappas, Dani Yogatama, Roy Schwartz, Noah A Smith, and Lingpeng
530"
REFERENCES,0.440809968847352,"Kong. Random feature attention. In Int. Conf. on Learning Representations (ICLR), Virtual
531"
REFERENCES,0.441588785046729,"only, 2021.
532"
REFERENCES,0.4423676012461059,"[67] Imanol Schlag, Kazuki Irie, and Jürgen Schmidhuber. Linear Transformers are secretly fast
533"
REFERENCES,0.4431464174454829,"weight programmers. In Proc. Int. Conf. on Machine Learning (ICML), Virtual only, July
534"
REFERENCES,0.4439252336448598,"2021.
535"
REFERENCES,0.4447040498442368,"[68] Kazuki Irie, Imanol Schlag, Róbert Csordás, and Jürgen Schmidhuber. Going beyond linear
536"
REFERENCES,0.4454828660436137,"transformers with recurrent fast weight programmers. In Proc. Advances in Neural Information
537"
REFERENCES,0.4462616822429907,"Processing Systems (NeurIPS), Virtual only, December 2021.
538"
REFERENCES,0.4470404984423676,"[69] Kazuki Irie, Róbert Csordás, and Jürgen Schmidhuber. The dual form of neural networks
539"
REFERENCES,0.44781931464174457,"revisited: Connecting test time predictions to training patterns via spotlights of attention. In
540"
REFERENCES,0.4485981308411215,"Proc. Int. Conf. on Machine Learning (ICML), Baltimore, MD, USA, July 2022.
541"
REFERENCES,0.44937694704049846,"[70] Mark A. Aizerman, Emmanuil M. Braverman, and Lev I. Rozonoer. Theoretical foundations
542"
REFERENCES,0.4501557632398754,"of potential function method in pattern recognition. Automation and Remote Control, 25(6):
543"
REFERENCES,0.45093457943925236,"917–936, 1964.
544"
REFERENCES,0.4517133956386293,"[71] Johannes von Oswald, Eyvind Niklasson, Ettore Randazzo, João Sacramento, Alexander
545"
REFERENCES,0.45249221183800625,"Mordvintsev, Andrey Zhmoginov, and Max Vladymyrov. Transformers learn in-context by
546"
REFERENCES,0.4532710280373832,"gradient descent. In Proc. Int. Conf. on Machine Learning (ICML), Honolulu, HI, USA, July
547"
REFERENCES,0.45404984423676015,"2023.
548"
REFERENCES,0.45482866043613707,"[72] Damai Dai, Yutao Sun, Li Dong, Yaru Hao, Shuming Ma, Zhifang Sui, and Furu Wei. Why can
549"
REFERENCES,0.45560747663551404,"GPT learn in-context? language models secretly perform gradient descent as meta-optimizers.
550"
REFERENCES,0.45638629283489096,"In Proc. Findings Association for Computational Linguistics (ACL), pages 4005–4019, Toronto,
551"
REFERENCES,0.45716510903426794,"Canada, July 2023.
552"
REFERENCES,0.45794392523364486,"[73] Bernard Widrow and Marcian E Hoff. Adaptive switching circuits. In Proc. IRE WESCON
553"
REFERENCES,0.45872274143302183,"Convention Record, pages 96–104, Los Angeles, CA, USA, August 1960.
554"
REFERENCES,0.45950155763239875,"[74] Kazuki Irie, Francesco Faccio, and Jürgen Schmidhuber. Neural differential equations for
555"
REFERENCES,0.4602803738317757,"learning to program neural nets through continuous learning rules. In Proc. Advances in Neural
556"
REFERENCES,0.46105919003115264,"Information Processing Systems (NeurIPS), New Orleans, LA, USA, December 2022.
557"
REFERENCES,0.4618380062305296,"[75] Kazuki Irie and Jürgen Schmidhuber. Images as weight matrices: Sequential image generation
558"
REFERENCES,0.46261682242990654,"through synaptic learning rules. In Int. Conf. on Learning Representations (ICLR), Kigali,
559"
REFERENCES,0.4633956386292835,"Rwanda, May 2023.
560"
REFERENCES,0.46417445482866043,"[76] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai,
561"
REFERENCES,0.4649532710280374,"Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly,
562"
REFERENCES,0.4657320872274143,"Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image
563"
REFERENCES,0.4665109034267913,"recognition at scale. In Int. Conf. on Learning Representations (ICLR), Virtual only, May
564"
REFERENCES,0.4672897196261682,"2021.
565"
REFERENCES,0.4680685358255452,"[77] Ilya O. Tolstikhin, Neil Houlsby, Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Thomas
566"
REFERENCES,0.4688473520249221,"Unterthiner, Jessica Yung, Andreas Steiner, Daniel Keysers, Jakob Uszkoreit, Mario Lucic,
567"
REFERENCES,0.4696261682242991,"and Alexey Dosovitskiy. MLP-Mixer: An all-MLP architecture for vision. In Proc. Advances
568"
REFERENCES,0.470404984423676,"in Neural Information Processing Systems (NeurIPS), pages 24261–24272, Virtual only,
569"
REFERENCES,0.471183800623053,"December 2021.
570"
REFERENCES,0.4719626168224299,"[78] John Bronskill, Jonathan Gordon, James Requeima, Sebastian Nowozin, and Richard E. Turner.
571"
REFERENCES,0.4727414330218069,"TaskNorm: Rethinking batch normalization for meta-learning. In Proc. Int. Conf. on Machine
572"
REFERENCES,0.4735202492211838,"Learning (ICML), pages 1153–1164, Virtual only, 2020.
573"
REFERENCES,0.4742990654205608,"[79] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training
574"
REFERENCES,0.4750778816199377,"by reducing internal covariate shift. In Proc. Int. Conf. on Machine Learning (ICML), pages
575"
REFERENCES,0.47585669781931467,"448–456, Lille, France, July 2015.
576"
REFERENCES,0.4766355140186916,"[80] Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky. Instance normalization: The missing
577"
REFERENCES,0.47741433021806856,"ingredient for fast stylization. Preprint arXiv:1607.08022, 2016.
578"
REFERENCES,0.4781931464174455,"[81] Rupesh Kumar Srivastava, Jonathan Masci, Sohrob Kazerounian, Faustino J. Gomez, and Jür-
579"
REFERENCES,0.47897196261682246,"gen Schmidhuber. Compete to compute. In Proc. Advances in Neural Information Processing
580"
REFERENCES,0.4797507788161994,"Systems (NIPS), pages 2310–2318, Lake Tahoe, NV, USA, December 2013.
581"
REFERENCES,0.48052959501557635,"[82] Massimo Caccia, Pau Rodríguez, Oleksiy Ostapenko, Fabrice Normandin, Min Lin, Lucas
582"
REFERENCES,0.48130841121495327,"Page-Caccia, Issam Hadj Laradji, Irina Rish, Alexandre Lacoste, David Vázquez, and Laurent
583"
REFERENCES,0.48208722741433024,"Charlin. Online fast adaptation and knowledge accumulation (OSAKA): a new approach to
584"
REFERENCES,0.48286604361370716,"continual learning. In Proc. Advances in Neural Information Processing Systems (NeurIPS),
585"
REFERENCES,0.48364485981308414,"Virtual only, December 2020.
586"
REFERENCES,0.48442367601246106,"[83] Xu He, Jakub Sygnowski, Alexandre Galashov, Andrei A Rusu, Yee Whye Teh, and Razvan
587"
REFERENCES,0.48520249221183803,"Pascanu. Task agnostic continual learning via meta learning. Preprint arXiv:1906.05201,
588"
REFERENCES,0.48598130841121495,"2019.
589"
REFERENCES,0.4867601246105919,"[84] Pau Ching Yap, Hippolyt Ritter, and David Barber. Addressing catastrophic forgetting in
590"
REFERENCES,0.48753894080996885,"few-shot problems. In Proc. Int. Conf. on Machine Learning (ICML), pages 11909–11919,
591"
REFERENCES,0.4883177570093458,"Virtual only, July 2021.
592"
REFERENCES,0.48909657320872274,"[85] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast
593"
REFERENCES,0.4898753894080997,"adaptation of deep networks. In Proc. Int. Conf. on Machine Learning (ICML), pages 1126–
594"
REFERENCES,0.49065420560747663,"1135, Sydney, Australia, August 2017.
595"
REFERENCES,0.4914330218068536,"[86] Chelsea Finn and Sergey Levine. Meta-learning and universality: Deep representations
596"
REFERENCES,0.49221183800623053,"and gradient descent can approximate any learning algorithm. In Int. Conf. on Learning
597"
REFERENCES,0.4929906542056075,"Representations (ICLR), Vancouver, Canada, April 2018.
598"
REFERENCES,0.4937694704049844,"[87] Kazuki Irie and Jürgen Schmidhuber. Accelerating neural self-improvement via bootstrapping.
599"
REFERENCES,0.4945482866043614,"In ICLR Workshop on Mathematical and Empirical Understanding of Foundation Models,
600"
REFERENCES,0.4953271028037383,"Kigali, Rwanda, May 2023.
601"
REFERENCES,0.4961059190031153,"[88] Johannes von Oswald, Eyvind Niklasson, Maximilian Schlegel, Seijin Kobayashi, Nicolas
602"
REFERENCES,0.4968847352024922,"Zucchet, Nino Scherrer, Nolan Miller, Mark Sandler, Max Vladymyrov, Razvan Pascanu, et al.
603"
REFERENCES,0.4976635514018692,"Uncovering mesa-optimization algorithms in Transformers. Preprint arXiv:2309.05858, 2023.
604"
REFERENCES,0.4984423676012461,"[89] Julian Coda-Forno, Marcel Binz, Zeynep Akata, Matthew Botvinick, Jane X Wang, and Eric
605"
REFERENCES,0.4992211838006231,"Schulz. Meta-in-context learning in large language models. Preprint arXiv:2305.12907, 2023.
606"
REFERENCES,0.5,"[90] Soochan Lee, Jaehyeon Son, and Gunhee Kim. Recasting continual learning as sequence
607"
REFERENCES,0.5007788161993769,"modeling. In Proc. Advances in Neural Information Processing Systems (NeurIPS), New
608"
REFERENCES,0.5015576323987538,"Orleans, LA, USA, December 2023.
609"
REFERENCES,0.5023364485981309,"[91] Jürgen Schmidhuber. On learning how to learn learning strategies. Technical Report FKI-198-
610"
REFERENCES,0.5031152647975078,"94, Institut für Informatik, Technische Universität München, November 1994.
611"
REFERENCES,0.5038940809968847,"[92] Jürgen Schmidhuber. Beyond “genetic programming"": Incremental self-improvement. In Proc.
612"
REFERENCES,0.5046728971962616,"Workshop on Genetic Programming at ML95, pages 42–49, 1995.
613"
REFERENCES,0.5054517133956387,"[93] Jürgen Schmidhuber, Jieyu Zhao, and Marco Wiering. Shifting inductive bias with success-
614"
REFERENCES,0.5062305295950156,"story algorithm, adaptive Levin search, and incremental self-improvement. Machine Learning,
615"
REFERENCES,0.5070093457943925,"28(1):105–130, 1997.
616"
REFERENCES,0.5077881619937694,"[94] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Lan-
617"
REFERENCES,0.5085669781931464,"guage models are unsupervised multitask learners. [Online]. : https://blog.openai.com/better-
618"
REFERENCES,0.5093457943925234,"language-models/, 2019.
619"
REFERENCES,0.5101246105919003,"[95] Jürgen Schmidhuber. Making the world differentiable: On using fully recurrent self-supervised
620"
REFERENCES,0.5109034267912772,"neural networks for dynamic reinforcement learning and planning in non-stationary environ-
621"
REFERENCES,0.5116822429906542,"ments. Institut für Informatik, Technische Universität München. Technical Report FKI-126,
622"
REFERENCES,0.5124610591900312,"90, 1990.
623"
REFERENCES,0.5132398753894081,"[96] Tom B Brown et al. Language models are few-shot learners. In Proc. Advances in Neural
624"
REFERENCES,0.514018691588785,"Information Processing Systems (NeurIPS), Virtual only, December 2020.
625"
REFERENCES,0.514797507788162,"[97] Sang Michael Xie, Aditi Raghunathan, Percy Liang, and Tengyu Ma. An explanation of
626"
REFERENCES,0.5155763239875389,"in-context learning as implicit bayesian inference. In Int. Conf. on Learning Representations
627"
REFERENCES,0.5163551401869159,"(ICLR), Virtual only, April 2022.
628"
REFERENCES,0.5171339563862928,"[98] Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and
629"
REFERENCES,0.5179127725856698,"Luke Zettlemoyer. Rethinking the role of demonstrations: What makes in-context learning
630"
REFERENCES,0.5186915887850467,"work? In Proc. Conf. on Empirical Methods in Natural Language Processing (EMNLP), pages
631"
REFERENCES,0.5194704049844237,"11048–11064, Abu Dhabi, UAE, December 2022.
632"
REFERENCES,0.5202492211838006,"[99] Kang Min Yoo, Junyeob Kim, Hyuhng Joon Kim, Hyunsoo Cho, Hwiyeol Jo, Sang-Woo
633"
REFERENCES,0.5210280373831776,"Lee, Sang-goo Lee, and Taeuk Kim. Ground-truth labels matter: A deeper look into input-
634"
REFERENCES,0.5218068535825545,"label demonstrations. In Proc. Conf. on Empirical Methods in Natural Language Processing
635"
REFERENCES,0.5225856697819314,"(EMNLP), pages 2422–2437, Abu Dhabi, UAE, December 2022.
636"
REFERENCES,0.5233644859813084,"[100] Stephanie CY Chan, Adam Santoro, Andrew Kyle Lampinen, Jane X Wang, Aaditya K Singh,
637"
REFERENCES,0.5241433021806854,"Pierre Harvey Richemond, James McClelland, and Felix Hill. Data distributional properties
638"
REFERENCES,0.5249221183800623,"drive emergent in-context learning in transformers. In Proc. Advances in Neural Information
639"
REFERENCES,0.5257009345794392,"Processing Systems (NeurIPS), New Orleans, LA, USA, November 2022.
640"
REFERENCES,0.5264797507788161,"[101] Stephanie CY Chan, Ishita Dasgupta, Junkyung Kim, Dharshan Kumaran, Andrew K
641"
REFERENCES,0.5272585669781932,"Lampinen, and Felix Hill. Transformers generalize differently from information stored in
642"
REFERENCES,0.5280373831775701,"context vs in weights. In NeurIPS Workshop on Memory in Artificial and Real Intelligence
643"
REFERENCES,0.528816199376947,"(MemARI), New Orleans, LA, USA, November 2022.
644"
REFERENCES,0.5295950155763239,"[102] Louis Kirsch, James Harrison, Jascha Sohl-Dickstein, and Luke Metz. General-purpose in-
645"
REFERENCES,0.530373831775701,"context learning by meta-learning transformers. In NeurIPS Workshop on Memory in Artificial
646"
REFERENCES,0.5311526479750779,"and Real Intelligence (MemARI), New Orleans, LA, USA, November 2022.
647"
REFERENCES,0.5319314641744548,"[103] Ekin Akyürek, Dale Schuurmans, Jacob Andreas, Tengyu Ma, and Denny Zhou. What learning
648"
REFERENCES,0.5327102803738317,"algorithm is in-context learning? investigations with linear models. In Int. Conf. on Learning
649"
REFERENCES,0.5334890965732088,"Representations (ICLR), Kigali, Rwanda, May 2023.
650"
REFERENCES,0.5342679127725857,"[104] Gido M Van de Ven and Andreas S Tolias. Generative replay with feedback connections as a
651"
REFERENCES,0.5350467289719626,"general strategy for continual learning. Preprint arXiv:1809.10635, 2018.
652"
REFERENCES,0.5358255451713395,"[105] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Baolin Wu, Andrew Y Ng, et al.
653"
REFERENCES,0.5366043613707165,"Reading digits in natural images with unsupervised feature learning. In NIPS workshop on
654"
REFERENCES,0.5373831775700935,"deep learning and unsupervised feature learning, Granada, Spain, December 2011.
655"
REFERENCES,0.5381619937694704,"[106] Yaroslav Bulatov. Notmnist dataset. Google (Books/OCR), Tech. Rep.[Online]. Available:
656"
REFERENCES,0.5389408099688473,"http://yaroslavvb. blogspot. it/2011/09/notmnist-dataset. html, 2011.
657"
REFERENCES,0.5397196261682243,"[107] Tristan Deleu, Tobias Würfl, Mandana Samiei, Joseph Paul Cohen, and Yoshua Bengio.
658"
REFERENCES,0.5404984423676013,"Torchmeta: A meta-learning library for PyTorch. Preprint arXiv:1909.06576, 2019.
659"
REFERENCES,0.5412772585669782,"[108] Jerry A Fodor and Zenon W Pylyshyn. Connectionism and cognitive architecture: A critical
660"
REFERENCES,0.5420560747663551,"analysis. Cognition, 28(1-2):3–71, 1988.
661"
REFERENCES,0.5428348909657321,"[109] Rahaf Aljundi, Francesca Babiloni, Mohamed Elhoseiny, Marcus Rohrbach, and Tinne Tuyte-
662"
REFERENCES,0.543613707165109,"laars. Memory aware synapses: Learning what (not) to forget. In Proc. European Conf. on
663"
REFERENCES,0.544392523364486,"Computer Vision (ECCV), pages 144–161, Munich, Germany, September 2018.
664"
REFERENCES,0.5451713395638629,"[110] Zhizhong Li and Derek Hoiem. Learning without forgetting. In Proc. European Conf. on
665"
REFERENCES,0.5459501557632399,"Computer Vision (ECCV), pages 614–629, Amsterdam, Netherlands, October 2016.
666"
REFERENCES,0.5467289719626168,"[111] Adam Paszke et al. Pytorch: An imperative style, high-performance deep learning library.
667"
REFERENCES,0.5475077881619937,"In Proc. Advances in Neural Information Processing Systems (NeurIPS), pages 8026–8037,
668"
REFERENCES,0.5482866043613707,"Vancouver, Canada, December 2019.
669"
REFERENCES,0.5490654205607477,"[112] Róbert Csordás, Kazuki Irie, and Jürgen Schmidhuber. The devil is in the detail: Simple tricks
670"
REFERENCES,0.5498442367601246,"improve systematic generalization of transformers. In Proc. Conf. on Empirical Methods in
671"
REFERENCES,0.5506230529595015,"Natural Language Processing (EMNLP), Punta Cana, Dominican Republic, November 2021.
672"
REFERENCES,0.5514018691588785,"[113] Kazuki Irie, Imanol Schlag, Róbert Csordás, and Jürgen Schmidhuber. Improving baselines in
673"
REFERENCES,0.5521806853582555,"the wild. In Workshop on Distribution Shifts, NeurIPS, Virtual only, 2021.
674"
REFERENCES,0.5529595015576324,"[114] James Requeima, Jonathan Gordon, John Bronskill, Sebastian Nowozin, and Richard E. Turner.
675"
REFERENCES,0.5537383177570093,"Fast and flexible multi-task classification using conditional neural adaptive processes. In Proc.
676"
REFERENCES,0.5545171339563862,"Advances in Neural Information Processing Systems (NeurIPS), pages 7957–7968, Vancouver,
677"
REFERENCES,0.5552959501557633,"Canada, December 2019.
678"
REFERENCES,0.5560747663551402,"[115] Eleni Triantafillou, Tyler Zhu, Vincent Dumoulin, Pascal Lamblin, Utku Evci, Kelvin Xu, Ross
679"
REFERENCES,0.5568535825545171,"Goroshin, Carles Gelada, Kevin Swersky, Pierre-Antoine Manzagol, and Hugo Larochelle.
680"
REFERENCES,0.557632398753894,"Meta-dataset: A dataset of datasets for learning to learn from few examples. In Int. Conf. on
681"
REFERENCES,0.5584112149532711,"Learning Representations (ICLR), Addis Ababa, Ethiopia, April 2020.
682"
REFERENCES,0.559190031152648,"[116] Jürgen Schmidhuber. One big net for everything. Preprint arXiv:1802.08864, 2018.
683"
REFERENCES,0.5599688473520249,"[117] Alex Graves, Marc G. Bellemare, Jacob Menick, Rémi Munos, and Koray Kavukcuoglu.
684"
REFERENCES,0.5607476635514018,"Automated curriculum learning for neural networks. In Proc. Int. Conf. on Machine Learning
685"
REFERENCES,0.5615264797507789,"(ICML), pages 1311–1320, Sydney, Australia, August 2017.
686"
REFERENCES,0.5623052959501558,"A
Experimental Details
687"
REFERENCES,0.5630841121495327,"A.1
Continual and Meta-learning Terminologies
688"
REFERENCES,0.5638629283489096,"We review the following classic terminologies of continual learning and meta-learning used through-
689"
REFERENCES,0.5646417445482866,"out this paper.
690"
REFERENCES,0.5654205607476636,"Continual learning.
“Domain-incremental learning (DIL)” and “class-incremental learning (CIL)”
691"
REFERENCES,0.5661993769470405,"are two classic settings in continual learning [104, 28, 6]. They differ as follows. Let M and N
692"
REFERENCES,0.5669781931464174,"denote positive integers. Consider continual learning of M tasks where each task is an N-way
693"
REFERENCES,0.5677570093457944,"classification. In the DIL case, a model has an N-way output classification layer, i.e., the class ‘0’ of
694"
REFERENCES,0.5685358255451713,"the first task shares the same weights as the class ‘0’ of the second task, and so on. In the CIL case, a
695"
REFERENCES,0.5693146417445483,"model’s output dimension is N ∗M; the class indices of different tasks are not shared, neither are the
696"
REFERENCES,0.5700934579439252,"corresponding weights in the output layer. In our experiments, all CIL models have the (N ∗M)-way
697"
REFERENCES,0.5708722741433022,"output from the first task (instead of progressively increasing the output size). In this work, we skip
698"
REFERENCES,0.5716510903426791,"the third variant called “task-incremental learning” which assumes that we have access to the task
699"
REFERENCES,0.572429906542056,"identity as an extra input, as it makes the CL problem almost trivial. CIL is typically reported to be
700"
REFERENCES,0.573208722741433,"the hardest setting among them.
701"
REFERENCES,0.57398753894081,"Meta-learning.
We need to introduce “meta-training” and “meta-test” terminologie since each of
702"
REFERENCES,0.5747663551401869,"these phases involve “training/test” processes within itself. Each of them requires the corresponding
703"
REFERENCES,0.5755451713395638,"training and test examples. We refer to these as “meta-training training/test examples”, and “meta-test
704"
REFERENCES,0.5763239875389408,"training/test examples” following the terminology of Beaulieu et al. [30]. While these are rather
705"
REFERENCES,0.5771028037383178,"“heavy” terminologies, they are unambiguous and help avoid potential confusions. In both phases,
706"
REFERENCES,0.5778816199376947,"our sequence-processing neural net observes a sequence of (meta-training or meta-test) training
707"
REFERENCES,0.5786604361370716,"examples—each consisting of input features and a correct label—, and the resulting states of the
708"
REFERENCES,0.5794392523364486,"sequence processor (i.e., weights in the case of SRWM) are used to make predictions on (meta-
709"
REFERENCES,0.5802180685358256,"training or meta-test) test examples—input features presented to the model without its label. During
710"
REFERENCES,0.5809968847352025,"the meta-training phase, we modify the trainable parameters of the meta-learner through gradient
711"
REFERENCES,0.5817757009345794,"descent minimizing the meta-learning loss function (using backpropagation through time). During
712"
REFERENCES,0.5825545171339563,"meta-testing, no human-designed optimization for weight modification is used anymore; the SRWMs
713"
REFERENCES,0.5833333333333334,"modify their own weights following their own learning rules defined as their forward pass (Eqs. 1-3).
714"
REFERENCES,0.5841121495327103,"In connection with the now-popular in-context learning [96], we also refer to a (meta-training or
715"
REFERENCES,0.5848909657320872,"meta-test) training-example sequence as context.
716"
REFERENCES,0.5856697819314641,"A.2
Datasets
717"
REFERENCES,0.5864485981308412,"For classic image classification datasets such as MNIST [25], CIFAR10 [27], and FashionMNIST
718"
REFERENCES,0.5872274143302181,"(FMNIST; Xiao et al. [26]) we refer to the original references for details.
719"
REFERENCES,0.588006230529595,"For Omniglot [23], we use Vinyals et al. [21]’s 1028/172/432-split for the train/validation/test set, as
720"
REFERENCES,0.5887850467289719,"well as their data augmentation methods using rotation of 90, 180, and 270 degrees. Original images
721"
REFERENCES,0.589563862928349,"are grayscale hand-written characters from 50 different alphabets. There are 1632 different classes
722"
REFERENCES,0.5903426791277259,"with 20 examples for each class.
723"
REFERENCES,0.5911214953271028,"Mini-ImageNet contains color images from 100 classes with 600 examples for each class. We use the
724"
REFERENCES,0.5919003115264797,"standard train/valid/test class splits of 64/16/20 following [22].
725"
REFERENCES,0.5926791277258567,"FC100 is based on CIFAR100 [27]. 100 color image classes (600 images per class, each of size
726"
REFERENCES,0.5934579439252337,"32 × 32) are split into train/valid/test classes of 60/20/20 [24].
727"
REFERENCES,0.5942367601246106,"The “5-datasets” dataset [32] consists of 5 datasets: CIFAR10, MNIST, FashionMNST, SVNH [105],
728"
REFERENCES,0.5950155763239875,"and notMNIST [106].
729"
REFERENCES,0.5957943925233645,"Split-CIFAR100 is also based on CIFAR100. The standard setting splits CIFAR100 into 10 10-way
730"
REFERENCES,0.5965732087227414,"classification tasks.
731"
REFERENCES,0.5973520249221184,"Meta-train/test sequence construction procedure. We use torchmeta [107] which provides
732"
REFERENCES,0.5981308411214953,"common few-shot/meta learning settings for these datasets to sample and construct their meta-
733"
REFERENCES,0.5989096573208723,"train/test datasets. The construction of “meta-training training” sequences for an N-way classification,
734"
REFERENCES,0.5996884735202492,"using a dataset containing C classes works as follows; for each sequence, we sample N random
735"
REFERENCES,0.6004672897196262,"but distinct classes out of C (N < C). The resulting classes are re-labelled such that each class is
736"
REFERENCES,0.6012461059190031,"assigned to one out of N distinct random label index which is unique to the sequence. For each of
737"
REFERENCES,0.6020249221183801,"these N classes, we sample K examples. We randomly order these N ∗K examples to obtain a
738"
REFERENCES,0.602803738317757,"sequence. Each such a sequence “simulates” an unknown task the model has to learn.
739"
REFERENCES,0.6035825545171339,"A.3
Training Details & Hyper-Parameters
740"
REFERENCES,0.6043613707165109,"We use the same model and training hyper-parameters in all our experiments. All hyper-parameters
741"
REFERENCES,0.6051401869158879,"are summarized in Table 5. We use the Adam optimizer with the standard Transformer learning rate
742"
REFERENCES,0.6059190031152648,"warmup scheduling [59]. The vision backend is the classic 4-layer convolutional NN of Vinyals
743"
REFERENCES,0.6066978193146417,"et al. [21]. Most configurations follow those of Irie et al. [19]; except that we initialize the ‘query’
744"
REFERENCES,0.6074766355140186,"sub-matrix in the self-referential weight matrix using a normal distribution with a mean value of 0
745"
REFERENCES,0.6082554517133957,"and standard deviation of 0.01/√dhead while other sub-matrices use an std of 1/√dhead (motivated
746"
REFERENCES,0.6090342679127726,"by the fact that a generated query vector is immediately multiplied with the same SRWM to produce
747"
REFERENCES,0.6098130841121495,"a value vector). For any further details, we’ll refer the readers to our public code we’ll release upon
748"
REFERENCES,0.6105919003115264,"acceptance. We conduct our experiments using a single V100-32GB, 2080-12GB or P100-16GB
749"
REFERENCES,0.6113707165109035,"GPUs, and the longest single training run takes about one day.
750"
REFERENCES,0.6121495327102804,Table 5: Hyper-parameters.
REFERENCES,0.6129283489096573,"Parameters
Values"
REFERENCES,0.6137071651090342,"Number of SRWM layers
2
Total hidden size
256
Feedforward block multiplier
2
Number of heads
16
Batch size
16 or 32"
REFERENCES,0.6144859813084113,"A.4
Evaluation Procedure
751"
REFERENCES,0.6152647975077882,"For evaluation on few-shot learning datasets (i.e., Omniglot, Mini-Imagenet and FC100), we use 5
752"
REFERENCES,0.6160436137071651,"different sets consisting of 32 K random test episodes each, and report mean and standard deviation.
753"
REFERENCES,0.616822429906542,"For evaluation on standard datasets, we use 5 different random support sets for in-context learning,
754"
REFERENCES,0.617601246105919,"and evaluate on the entire test set. We report the corresponding mean and standard deviation across
755"
REFERENCES,0.618380062305296,"these 5 evaluation runs.
756"
REFERENCES,0.6191588785046729,"For the Split-MNIST experiment, we do 10 meta-testing runs to compute the mean and standard
757"
REFERENCES,0.6199376947040498,"deviation as the baseline models are also trained for 10 runs in Hsu et al. [6] (see other details in
758"
REFERENCES,0.6207165109034268,"Appendix A.7).
759"
REFERENCES,0.6214953271028038,"A.5
ACL Objectives with More Tasks
760"
REFERENCES,0.6222741433021807,"We can straightforwardly extend the 2-task version of ACL presented in Sec. 3 to more tasks. In
761"
REFERENCES,0.6230529595015576,"the 3-task case (we denote the three tasks as A, B, and C) used in Sec. 4.3, the objective function
762"
REFERENCES,0.6238317757009346,"contains six terms. Following three terms are added to Eq. 4:
763"
REFERENCES,0.6246105919003115,"−

log(p(yC
test|xC
test; WA,B,C)) + log(p(yB
test|xB
test; WA,B,C)) + log(p(yA
test|xA
test; WA,B,C))
"
REFERENCES,0.6253894080996885,"This also naturally extends to the 5-task loss used in the Split-MNIST experiment (Table 3). As
764"
REFERENCES,0.6261682242990654,"one can observe, the number of terms rapidly/quadratically increases with the number of tasks.
765"
REFERENCES,0.6269470404984424,"Nevertheless, computing these loss terms isn’t immediately impractical because they essentially just
766"
REFERENCES,0.6277258566978193,"require forwarding the network for one step, for many independent inputs/images. This can be heavily
767"
REFERENCES,0.6285046728971962,"parallelized as a batch operation. While this can be a concern when scaling up more, a natural open
768"
REFERENCES,0.6292834890965732,"research question is whether we really need all these terms in the case we have many more tasks.
769"
REFERENCES,0.6300623052959502,"Table 6: Impact of the choice of meta-validation datasets. Classification accuracies (%) on three
datasets: Split-CIFAR-10, Split-Fashion MNIST (Split-FMNIST), and Split-MNIST in the domain-
incremental setting (we omit “Split-” in the second column). “OOB” denotes “out-of-the-box”.
“mImageNet” here refers to mini-ImageNet."
REFERENCES,0.6308411214953271,Meta-Test on Split-
REFERENCES,0.631619937694704,"Meta-Finetune Datasets
Meta-Validation Sets
MNIST
FMNIST
CIFAR-10"
REFERENCES,0.632398753894081,"None (OOB: 2-task ACL; Sec. 4.1)
Omniglot + mImageNet
72.2 ± 0.9
75.6 ± 0.7
65.3 ± 1.6"
REFERENCES,0.633177570093458,"Omniglot
MNIST
84.3 ± 1.2
78.1 ± 1.9
55.8 ± 1.2
FMNIST
81.6 ± 1.3
90.4 ± 0.5
59.5 ± 2.1
CIFAR10
75.2 ± 2.3
78.2 ± 0.9
63.4 ± 1.4"
REFERENCES,0.6339563862928349,"Omniglot + mImageNet
MNIST
76.6 ± 1.4
85.3 ± 1.1
66.2 ± 1.1
FMNIST
73.2 ± 2.3
89.9 ± 0.6
66.6 ± 0.7
CIFAR10
76.3 ± 3.0
88.1 ± 1.3
68.6 ± 0.5"
REFERENCES,0.6347352024922118,"Ideally, we want these models to ‘systematically generalize’ to more tasks even when they are trained
770"
REFERENCES,0.6355140186915887,"with only a handful of them [108]. This is an interesting research question on generalization to be
771"
REFERENCES,0.6362928348909658,"studied in a future work.
772"
REFERENCES,0.6370716510903427,"A.6
Auxiliary 1-shot Learning Objective
773"
REFERENCES,0.6378504672897196,"In practice, instead of training the models only for “15-shot learning,” we also add an auxiliary loss
774"
REFERENCES,0.6386292834890965,"for 1-shot learning. This naturally encourages the models to learn in-context from the first examples.
775"
REFERENCES,0.6394080996884736,"A.7
Details of the Split-MNIST experiment
776"
REFERENCES,0.6401869158878505,"Here we provide details of the Split-MNIST experiments presented in Sec. 4 and Table 3.
777"
REFERENCES,0.6409657320872274,"Split-MNIST is obtained by transforming the classic 10-class single-task MNIST dataset into a
778"
REFERENCES,0.6417445482866043,"sequence of 5 tasks by partitioning the 10 classes into 5 groups/pairs of two classes each, in a fixed
779"
REFERENCES,0.6425233644859814,"order from 0 to 9 (i.e., grouping 0/1, 2/3, 4/5, 6/7, and 8/9). Regarding the difference between
780"
REFERENCES,0.6433021806853583,"domain/class-incremental settings, we refer to Appendix A.1.
781"
REFERENCES,0.6440809968847352,"The baseline methods presented in Table 3 include: standard SGD and Adam optimizers, Adam
782"
REFERENCES,0.6448598130841121,"with the L2 regularization, elastic weight consolidation [9] and its online variant [10], synaptic
783"
REFERENCES,0.6456386292834891,"intelligence [11], memory aware synapses [109], learning without forgetting (LwF; Li and Hoiem
784"
REFERENCES,0.6464174454828661,"[110]). For these methods, we directly take the numbers reported in Hsu et al. [6] for the 5-task
785"
REFERENCES,0.647196261682243,"domain/class-incremental settings.
786"
REFERENCES,0.6479750778816199,"For the 2-task class incremental setting, we use Hsu et al. [6]’s code to train the correspond models
787"
REFERENCES,0.6487538940809969,"(the number for LwF is currently missing as it is not implemented in their code base; we plan to add
788"
REFERENCES,0.6495327102803738,"the corresponding/missing entry in Table 3 for the final version of this paper).
789"
REFERENCES,0.6503115264797508,"Finally we also evaluate two meta-CL baselines: Online-aware Meta-Learning (OML; Javed and
790"
REFERENCES,0.6510903426791277,"White [29]) and Generative Meta-Continual Learning (GeMCL; Banayeeanzade et al. [31]). OML is
791"
REFERENCES,0.6518691588785047,"a MAML-based meta-learning approach. We note that as reported by Javed and White [29] in their
792"
REFERENCES,0.6526479750778816,"public code repository; after some critical bug fix, the performance of their OML matches that of
793"
REFERENCES,0.6534267912772586,"Beaulieu et al. [30] (which is a direct application of OML to another model architecture). Therefore,
794"
REFERENCES,0.6542056074766355,"we focus on OML as our main MAML-based baseline. We take the out-of-the-box model (meta-
795"
REFERENCES,0.6549844236760125,"trained for Omniglot, with a 1000-way output) made publicly available by Javed and White [29]. We
796"
REFERENCES,0.6557632398753894,"evaluate the corresponding model in two ways. In the first, ‘out-of-the-box’ case, we take the meta-
797"
REFERENCES,0.6565420560747663,"pre-trained model and only tune its meta-testing learning rate (which is done by Javed and White [29]
798"
REFERENCES,0.6573208722741433,"even for meta-testing in Omniglot). We find that this setting does not perform very well; in the other
799"
REFERENCES,0.6580996884735203,"case (‘optimized # meta-testing iterations’), we additionally tune the number of meta-test training
800"
REFERENCES,0.6588785046728972,"iterations. We’ve done a grid search of the meta-test learning rate in 3 ∗{1e−2, 1e−3, 1e−4, 1e−5}
801"
REFERENCES,0.6596573208722741,"and the number of meta-test training steps in {1, 2, 5, 8, 10} using a meta-validation set based on an
802"
REFERENCES,0.660436137071651,"MNIST validation set (5 K held-out images from the training set); we found the learning rate of 3e−4
803"
REFERENCES,0.6612149532710281,"and 8 steps to consistently perform the best in all our settings. We’ve also tried it ‘with’ and ‘without’
804"
REFERENCES,0.661993769470405,"Table 7: Impact of the number of in-context examples. Classification accuracies (%) on Split-MNIST
in the 2-task and 5-task class-incremental learning (CIL) settings and the 5-task domain-incremental
learning (DIL) setting. For ACL models, we use the same number of examples for meta-validation as
for meta-training. According to Banayeeanzade et al. [31], GeMCL is meta-trained with the 5-shot
setting but meta-validated in the 15-shot setting."
REFERENCES,0.6627725856697819,"Number of Examples
DIL
CIL 2-task
CIL 5-task"
REFERENCES,0.6635514018691588,"Meta-Train/Valid
Meta-Test
GeMCL
ACL
GeMCL
ACL
GeMCL
ACL"
REFERENCES,0.6643302180685359,"5
5
-
84.1 ± 1.2
-
93.4 ± 1.2
-
74.6 ± 2.3
15
-
83.8 ± 2.8
-
94.3 ± 1.9
-
65.5 ± 4.0"
REFERENCES,0.6651090342679128,"15
5
62.2 ± 5.2
83.9 ± 1.0
87.3 ± 2.5
93.6 ± 1.7
71.7 ± 2.5
76.7 ± 3.6
15
63.8 ± 3.8 84.5 ± 1.6 91.2 ± 2.8 96.0 ± 1.0 79.0 ± 2.1 84.3 ± 1.2"
REFERENCES,0.6658878504672897,"the standard mean/std normalization of the MNIST dataset; better performance was achieved without
805"
REFERENCES,0.6666666666666666,"such normalization (which is in fact consistent as they do not normalize the Omniglot dataset for
806"
REFERENCES,0.6674454828660437,"their meta-training/testing). Their performance on the 5-task class-incremental setting is somewhat
807"
REFERENCES,0.6682242990654206,"surprising/disappointing (since genenralization from Omniglot to MNIST is typically straightforward,
808"
REFERENCES,0.6690031152647975,"at least, in common non-continual few-shot learning settings; see, e.g., Munkhdalai and Yu [51]). At
809"
REFERENCES,0.6697819314641744,"the same time, to the best of our knowledge, OML-trained models have not been tested in such a
810"
REFERENCES,0.6705607476635514,"condition in prior work; from what we observe, the publicly available out-of-the-box model might
811"
REFERENCES,0.6713395638629284,"be overtuned for Omniglot/Mini-ImageNet or the frozen ‘representation network’ is not ideal for
812"
REFERENCES,0.6721183800623053,"genenralization. We note that the sensitivity of these MAML-based methods [29, 30] w.r.t. meta-test
813"
REFERENCES,0.6728971962616822,"hyper-parameters has been also noted by Banayeeanzade et al. [31]; these are characteristics of
814"
REFERENCES,0.6736760124610592,"hand-crafted learning algorithms that we want to avoid with learned learning algorithms.
815"
REFERENCES,0.6744548286604362,"We use code and a pre-trained model (trained on Omniglot) made public by Banayeeanzade et al.
816"
REFERENCES,0.6752336448598131,"[31] for the GeMCL baseline (see also Table 7); like our method, GeMCL also do not require any
817"
REFERENCES,0.67601246105919,"special tuning at test-time.
818"
REFERENCES,0.676791277258567,"Our out-of-the-box ACL models (trained on Omniglot and Mini-ImageNet) do not require any
819"
REFERENCES,0.677570093457944,"tuning at meta-test time. Nevertheless, we’ve checked the effect of the number of meta-test training
820"
REFERENCES,0.6783489096573209,"examples (5 vs. 15; 15 is the number used in meta-training); we found the consistent number, i.e., 15,
821"
REFERENCES,0.6791277258566978,"to work better than 5. For the version that is meta-finetuned using the 5-task ACL objective (using
822"
REFERENCES,0.6799065420560748,"only the Omniglot dataset), we use 5 or 15 examples for both meta-train and meta-test training (see an
823"
REFERENCES,0.6806853582554517,"ablation study in Table 7). To obtain a sequence of 5 tasks, we simply sample 5 tasks from Omniglot
824"
REFERENCES,0.6814641744548287,"(in principle, we should make sure that different tasks in the same sequence have no class overlap;
825"
REFERENCES,0.6822429906542056,"in practice, our current implementation simply randomly draws 5 independent tasks from Omniglot).
826"
REFERENCES,0.6830218068535826,"A.8
Details of the Split-CIFAR100 and 5-datasets experiment using ViT
827"
REFERENCES,0.6838006230529595,"As we described in Sec. 4, for the experiments on Split-CIFAR100 and 5-datasets, following
828"
REFERENCES,0.6845794392523364,"Wang et al. [33, 34], we use ViT-B/16 pre-trained on ImageNet [76] which is available through
829"
REFERENCES,0.6853582554517134,"torchvision [111]. In this experiments, we resize all images to 3x224x224 and feed them to the
830"
REFERENCES,0.6861370716510904,"ViT. We remove the output layer of the ViT, and use its 768-dimensional feature from the penultimate
831"
REFERENCES,0.6869158878504673,"layer as the image encoding. The self-referential component which is added to this encoder has the
832"
REFERENCES,0.6876947040498442,"same architecture (2 layers, 16 heads) as the rest of the paper (see all hyper-parameters in Table 5)
833"
REFERENCES,0.6884735202492211,"All ViT parameters are frozen during meta-training.
834"
REFERENCES,0.6892523364485982,"B
Extra Experimental Results
835"
REFERENCES,0.6900311526479751,"B.1
Ablation Studies on the Meta-validation Dataset
836"
REFERENCES,0.690809968847352,"Here we conduct ablation studies on the choice of meta-validation sets to select model checkpoints. In
837"
REFERENCES,0.6915887850467289,"general, when dealing with out-of-domain generalization, the choice of validation procedures to select
838"
REFERENCES,0.692367601246106,"final model checkpoints plays a crucial role in the evaluation of the corresponding method [112, 113].
839"
REFERENCES,0.6931464174454829,"The out-of-the-box models are chosen based on the average meta-validation performance on the
840"
REFERENCES,0.6939252336448598,"validation set corresponding to the few-shot learning datasets used in meta-training: Omniglot and
841"
REFERENCES,0.6947040498442367,"Table 8: Meta-testing on sequences that are longer than those from meta-training. Classification
accuracies (%) on 5-task Split-FMNIST and 5-task Split-MNIST in the domain-incremental
settings. The model is the one finetuned with 5-task ACL loss using Omniglot as the meta-finetuning
set and FMNIST as the meta-validation set (i.e., the numbers in the top part of the table are taken
from Table 6). In the first column, “Split-FMNIST, Split-MNIST” indicates continual learning of 5
Split-FMNIST tasks followed by 5 tasks of Split-MNIST (and “Split-MNIST, Split-FMNIST” is the
opposite order). Performance is measured at the end of the entire sequence."
REFERENCES,0.6954828660436138,Meta-Test Test Tasks
REFERENCES,0.6962616822429907,"Meta-Test Training Task Sequence
# Tasks
Split-FMNIST
Split-MNIST"
REFERENCES,0.6970404984423676,"Split-FMNIST
5
90.4 ± 0.5
-
Split-MNIST
5
-
81.6 ± 1.3"
REFERENCES,0.6978193146417445,"Split-FMNIST, Split-MNIST
10
79.3 ± 2.7
74.3 ± 0.9
Split-MNIST, Split-FMNIST
10
78.1 ± 3.1
78.5 ± 1.7"
REFERENCES,0.6985981308411215,"Table 9: Classification acuracies (%) on 5-task 2-way Split-Omniglot. Mean/std is computed over 10
meta-test runs."
REFERENCES,0.6993769470404985,"Method
Domain Incremental
Class Incremental"
REFERENCES,0.7001557632398754,"GeMCL
64.6 ± 9.2
97.4 ± 2.7
ACL
92.3 ± 0.4
96.8 ± 0.8"
REFERENCES,0.7009345794392523,"mini-ImageNet (or Omniglot, mini-ImageNet, and FC100 in the case of 3-task ACL), independently of
842"
REFERENCES,0.7017133956386293,"any potential meta-test datasets. In contrast, in the meta-finetuning process of Table 3, we selected our
843"
REFERENCES,0.7024922118380063,"model checkpoint by meta-validation on the MNIST validation dataset (we held out 5 K images from
844"
REFERENCES,0.7032710280373832,"the training set). Here we evaluate ACL models meta-finetuned for the “5-task domain-incremental
845"
REFERENCES,0.7040498442367601,"binary classification” on three Split-‘X’ tasks where ‘X’ is MNIST, FashionMNIST (FMNIST) or
846"
REFERENCES,0.7048286604361371,"CIFAR-10 for various choices of meta-validation sets (in each case we hold out 5 K images from
847"
REFERENCES,0.705607476635514,"the corresponding training set). In addition, we also evaluate the effect of meta-finetuning datasets
848"
REFERENCES,0.706386292834891,"(Omniglot only v. Omniglot and mini-ImageNet). Table 6 shows the results (we use 15 meta-training
849"
REFERENCES,0.7071651090342679,"and meta-testing examples except for the Omniglot-finedtuned/MNIST-validated model from Table 3
850"
REFERENCES,0.7079439252336449,"which happens to be configured with 5 examples; this will be fixed in the final version). Effectively,
851"
REFERENCES,0.7087227414330218,"meta-validation on the matching validation set is useful. Also, meta-finetuning only on Omniglot is
852"
REFERENCES,0.7095015576323987,"beneficial for the performance on MNIST when meta-validated on MNIST or FMNIST. However,
853"
REFERENCES,0.7102803738317757,"importantly, we emphasize that our ultimate goal is not to obtain a model that is specifically tuned for
854"
REFERENCES,0.7110591900311527,"certain datasets; we aim at building models that generally work well across a wide range of tasks
855"
REFERENCES,0.7118380062305296,"(ideally on any tasks); in fact, several existing works in the few-shot learning literature evaluate
856"
REFERENCES,0.7126168224299065,"their methods in such settings (see, e.g., Requeima et al. [114], Bronskill et al. [78], Triantafillou
857"
REFERENCES,0.7133956386292835,"et al. [115]). This also goes hand-in-hand with scaling up ACL (our current model is tiny; see
858"
REFERENCES,0.7141744548286605,"hyper-parameters in Table 5; the vision component is also a shallow ‘Conv-4’ net) and various other
859"
REFERENCES,0.7149532710280374,"considerations on self-improving continual learners (see, e.g., Schmidhuber [116]), such as automated
860"
REFERENCES,0.7157320872274143,"curriculum learning [117].
861"
REFERENCES,0.7165109034267912,"B.2
Performance on Split-Omniglot
862"
REFERENCES,0.7172897196261683,"Here we report the performance of the models used in the Split-MNIST experiment (Sec. 4.3) on
863"
REFERENCES,0.7180685358255452,"“in-domain” 5-task 2-way Split-Omniglot. Table 9 shows the result. Performance is very similar
864"
REFERENCES,0.7188473520249221,"between our ACL and the baseline GeMCL on this task in the class incremental setting, unlike on
865"
REFERENCES,0.719626168224299,"Split-MNIST (Table 3) where we observe a larger performance gap between these same models. Here
866"
REFERENCES,0.7204049844236761,"we also include the “domain incremental” setting for the sake of completeness but note that GeMCL
867"
REFERENCES,0.721183800623053,"is not originally trained for this setting.
868"
REFERENCES,0.7219626168224299,"Table 10: 5-way classification accuracies using 15 examples for each class for each task in the context.
2-task models are meta-trained on Omniglot and Mini-ImageNet, while 3-task models are in addition
meta-trained on FC100. ‘A, B’ in ‘Context/Train’ column indicates that models sequentially observe
meta-test training examples of Task A then B; evaluation is only done at the end of the sequence. “no
ACL” is the baseline 2-task models trained without the ACL loss."
REFERENCES,0.7227414330218068,"Meta-Testing Tasks
Number of Meta-Training Tasks"
REFERENCES,0.7235202492211839,"Context/Train
Test
2 (no ACL)
2
3"
REFERENCES,0.7242990654205608,"A: MNIST-04
A
71.1 ± 4.0 75.4 ± 3.0 89.7 ± 1.6
B: CIFAR10-04
B
51.5 ± 1.4 51.6 ± 1.3 55.3 ± 0.9
C: MNIST-59
C
65.9 ± 2.4 63.0 ± 3.3 76.1 ± 2.0
D: FMNIST-04
D
52.8 ± 3.4 54.8 ± 1.3 59.2 ± 4.0
Average
60.3
61.2
70.1"
REFERENCES,0.7250778816199377,"A, B
A
43.7 ± 2.3 81.5 ± 2.7 88.0 ± 2.2
B
49.4 ± 2.4 50.8 ± 1.3 52.9 ± 1.2
Average
46.6
66.1
70.5"
REFERENCES,0.7258566978193146,"A, B, C
A
26.5 ± 3.2 64.5 ± 6.0 82.2 ± 1.7
B
32.3 ± 1.7 50.8 ± 1.2 50.3 ± 2.0
C
56.5 ± 8.1 33.7 ± 2.2 44.3 ± 3.0
Average
38.4
49.7
58.9"
REFERENCES,0.7266355140186916,"A, B, C, D
A
24.6 ± 2.7 64.3 ± 4.8 78.9 ± 2.3
B
20.6 ± 2.3 47.5 ± 1.0 49.2 ± 1.3
C
38.5 ± 4.4 32.7 ± 1.9 45.4 ± 3.9
D
36.1 ± 2.5 31.2 ± 4.9 30.1 ± 5.8
Average
30.0
43.9
50.9"
REFERENCES,0.7274143302180686,"B.3
Effect of Number of In-Context Examples
869"
REFERENCES,0.7281931464174455,"Table 7 shows an ablation study on the number of examples used for meta-training and meta-testing
870"
REFERENCES,0.7289719626168224,"on the Split-MNIST task. We observe that for an ACL model trained only with 5 examples during
871"
REFERENCES,0.7297507788161994,"meta-training, more examples (15 examples) provided during meta-testing is not beneficial. In fact,
872"
REFERENCES,0.7305295950155763,"they even largely hurt in certain cases (see the last column); this is one form of “length generalization”
873"
REFERENCES,0.7313084112149533,"problem. When the number of meta-training examples is consistent with the one used during
874"
REFERENCES,0.7320872274143302,"meta-testing, the 15-example case consistently outperforms the 5-example one.
875"
REFERENCES,0.7328660436137072,"B.4
Effect of Number of Tasks in the ACL Loss
876"
REFERENCES,0.7336448598130841,"Table 10 provides the complete results discussed in Sec. 4.3 under “Evaluation on diverse task
877"
REFERENCES,0.7344236760124611,"domains”.
878"
REFERENCES,0.735202492211838,"B.5
Further Discussion on Limitations
879"
REFERENCES,0.735981308411215,"Here we provide further discussion and experimental results on the limitations of our approach as a
880"
REFERENCES,0.7367601246105919,"learned algorithm.
881"
REFERENCES,0.7375389408099688,"Domain generalization.
As a data-driven learned algorithm, the domain generalization capability
882"
REFERENCES,0.7383177570093458,"is a typical limitation as it depends on the meta-trained data. Certain results we presented above
883"
REFERENCES,0.7390965732087228,"are representative of this limitation. In particular, in Table 6, the model meta-trained/finetuned on
884"
REFERENCES,0.7398753894080997,"Omniglot using Split-MNIST as meta-validation set do not perform well on Split-CIFAR10. While
885"
REFERENCES,0.7406542056074766,"meta-training and meta-validating on a larger/diverse set of datasets may be an immediate remedy
886"
REFERENCES,0.7414330218068536,"to obtain more robust ACL models, we note that since ACL is also a “continual meta-learning”
887"
REFERENCES,0.7422118380062306,"algorithm (Sec. 5), an ideal ACL model should also continually incorporate and learn from more data
888"
REFERENCES,0.7429906542056075,"during potentially lifelong meta-testing; we leave such an investigation for future work.
889"
REFERENCES,0.7437694704049844,"Length generalization.
We already qualitatively observed the limited length generalization capabil-
890"
REFERENCES,0.7445482866043613,"ity in Table 10 (meta-trained with up to 3 tasks and meta-tested with up to 4 tasks). Here we provide
891"
REFERENCES,0.7453271028037384,"one more experiment evaluating ACL models meta-trained for 5 tasks on a concatenation of two
892"
REFERENCES,0.7461059190031153,"5-task Split-MNIST and Split-FMNIST tasks (resulting in 10 tasks). Table 8 shows the results. Again,
893"
REFERENCES,0.7468847352024922,"while the model does not completely break, increasing the number of tasks to 10 rapidly degrades the
894"
REFERENCES,0.7476635514018691,"performance compared to the 5-task setting the model is meta-trained for. Similarly, its performance
895"
REFERENCES,0.7484423676012462,"on the Split-Omniglot domain incremental setting (Sec. B.2) degrades with increased numbers of
896"
REFERENCES,0.7492211838006231,"tasks: accuracies for 5, 10 and 20 tasks are 92.3% ± 0.4, 82.0% ± 0.4 and 67.6% ± 1.1 respectively.
897"
REFERENCES,0.75,"As noted in Sec. 5, this is a general limitation of sequence processing neural networks, and there is a
898"
REFERENCES,0.7507788161993769,"potential remedy for this limitation (meta-training on more tasks and “context carry-over”) which we
899"
REFERENCES,0.7515576323987538,"leave for future work.
900"
REFERENCES,0.7523364485981309,"B.6
A Comment on Meta-Generalization
901"
REFERENCES,0.7531152647975078,"We also note that in general, “unseen” datasets do not necessarily imply that they are harder tasks than
902"
REFERENCES,0.7538940809968847,"“in-domain” test sets; when meta-trained on Omniglot and mini-ImageNet, meta-generalization on
903"
REFERENCES,0.7546728971962616,"“unseen” MNIST is easier (the accuracy is higher) than on the “in-domain” test set of mini-ImageNet
904"
REFERENCES,0.7554517133956387,"with heldout/unseen classes (compare Tables 1 and 2).
905"
REFERENCES,0.7562305295950156,"NeurIPS Paper Checklist
906"
CLAIMS,0.7570093457943925,"1. Claims
907"
CLAIMS,0.7577881619937694,"Question: Do the main claims made in the abstract and introduction accurately reflect the
908"
CLAIMS,0.7585669781931464,"paper’s contributions and scope?
909"
CLAIMS,0.7593457943925234,"Answer: [Yes]
910"
CLAIMS,0.7601246105919003,"Justification: We accurately state contributions and scope of the work in the abstract and
911"
CLAIMS,0.7609034267912772,"introduction.
912"
CLAIMS,0.7616822429906542,"Guidelines:
913"
CLAIMS,0.7624610591900312,"• The answer NA means that the abstract and introduction do not include the claims
914"
CLAIMS,0.7632398753894081,"made in the paper.
915"
CLAIMS,0.764018691588785,"• The abstract and/or introduction should clearly state the claims made, including the
916"
CLAIMS,0.764797507788162,"contributions made in the paper and important assumptions and limitations. A No or
917"
CLAIMS,0.7655763239875389,"NA answer to this question will not be perceived well by the reviewers.
918"
CLAIMS,0.7663551401869159,"• The claims made should match theoretical and experimental results, and reflect how
919"
CLAIMS,0.7671339563862928,"much the results can be expected to generalize to other settings.
920"
CLAIMS,0.7679127725856698,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
921"
CLAIMS,0.7686915887850467,"are not attained by the paper.
922"
LIMITATIONS,0.7694704049844237,"2. Limitations
923"
LIMITATIONS,0.7702492211838006,"Question: Does the paper discuss the limitations of the work performed by the authors?
924"
LIMITATIONS,0.7710280373831776,"Answer: [Yes]
925"
LIMITATIONS,0.7718068535825545,"Justification: We discuss limitations of our method in Sec. 4 and 5.
926"
LIMITATIONS,0.7725856697819314,"Guidelines:
927"
LIMITATIONS,0.7733644859813084,"• The answer NA means that the paper has no limitation while the answer No means that
928"
LIMITATIONS,0.7741433021806854,"the paper has limitations, but those are not discussed in the paper.
929"
LIMITATIONS,0.7749221183800623,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
930"
LIMITATIONS,0.7757009345794392,"• The paper should point out any strong assumptions and how robust the results are to
931"
LIMITATIONS,0.7764797507788161,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
932"
LIMITATIONS,0.7772585669781932,"model well-specification, asymptotic approximations only holding locally). The authors
933"
LIMITATIONS,0.7780373831775701,"should reflect on how these assumptions might be violated in practice and what the
934"
LIMITATIONS,0.778816199376947,"implications would be.
935"
LIMITATIONS,0.7795950155763239,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
936"
LIMITATIONS,0.780373831775701,"only tested on a few datasets or with a few runs. In general, empirical results often
937"
LIMITATIONS,0.7811526479750779,"depend on implicit assumptions, which should be articulated.
938"
LIMITATIONS,0.7819314641744548,"• The authors should reflect on the factors that influence the performance of the approach.
939"
LIMITATIONS,0.7827102803738317,"For example, a facial recognition algorithm may perform poorly when image resolution
940"
LIMITATIONS,0.7834890965732088,"is low or images are taken in low lighting. Or a speech-to-text system might not be
941"
LIMITATIONS,0.7842679127725857,"used reliably to provide closed captions for online lectures because it fails to handle
942"
LIMITATIONS,0.7850467289719626,"technical jargon.
943"
LIMITATIONS,0.7858255451713395,"• The authors should discuss the computational efficiency of the proposed algorithms
944"
LIMITATIONS,0.7866043613707165,"and how they scale with dataset size.
945"
LIMITATIONS,0.7873831775700935,"• If applicable, the authors should discuss possible limitations of their approach to
946"
LIMITATIONS,0.7881619937694704,"address problems of privacy and fairness.
947"
LIMITATIONS,0.7889408099688473,"• While the authors might fear that complete honesty about limitations might be used by
948"
LIMITATIONS,0.7897196261682243,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
949"
LIMITATIONS,0.7904984423676013,"limitations that aren’t acknowledged in the paper. The authors should use their best
950"
LIMITATIONS,0.7912772585669782,"judgment and recognize that individual actions in favor of transparency play an impor-
951"
LIMITATIONS,0.7920560747663551,"tant role in developing norms that preserve the integrity of the community. Reviewers
952"
LIMITATIONS,0.7928348909657321,"will be specifically instructed to not penalize honesty concerning limitations.
953"
THEORY ASSUMPTIONS AND PROOFS,0.793613707165109,"3. Theory Assumptions and Proofs
954"
THEORY ASSUMPTIONS AND PROOFS,0.794392523364486,"Question: For each theoretical result, does the paper provide the full set of assumptions and
955"
THEORY ASSUMPTIONS AND PROOFS,0.7951713395638629,"a complete (and correct) proof?
956"
THEORY ASSUMPTIONS AND PROOFS,0.7959501557632399,"Answer: [NA]
957"
THEORY ASSUMPTIONS AND PROOFS,0.7967289719626168,"Justification: This is not a theoretical paper.
958"
THEORY ASSUMPTIONS AND PROOFS,0.7975077881619937,"Guidelines:
959"
THEORY ASSUMPTIONS AND PROOFS,0.7982866043613707,"• The answer NA means that the paper does not include theoretical results.
960"
THEORY ASSUMPTIONS AND PROOFS,0.7990654205607477,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
961"
THEORY ASSUMPTIONS AND PROOFS,0.7998442367601246,"referenced.
962"
THEORY ASSUMPTIONS AND PROOFS,0.8006230529595015,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
963"
THEORY ASSUMPTIONS AND PROOFS,0.8014018691588785,"• The proofs can either appear in the main paper or the supplemental material, but if
964"
THEORY ASSUMPTIONS AND PROOFS,0.8021806853582555,"they appear in the supplemental material, the authors are encouraged to provide a short
965"
THEORY ASSUMPTIONS AND PROOFS,0.8029595015576324,"proof sketch to provide intuition.
966"
THEORY ASSUMPTIONS AND PROOFS,0.8037383177570093,"• Inversely, any informal proof provided in the core of the paper should be complemented
967"
THEORY ASSUMPTIONS AND PROOFS,0.8045171339563862,"by formal proofs provided in appendix or supplemental material.
968"
THEORY ASSUMPTIONS AND PROOFS,0.8052959501557633,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
969"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8060747663551402,"4. Experimental Result Reproducibility
970"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8068535825545171,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
971"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.807632398753894,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
972"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8084112149532711,"of the paper (regardless of whether the code and data are provided or not)?
973"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.809190031152648,"Answer: [Yes]
974"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8099688473520249,"Justification: We provide experimental details in the main text and details in Appendix A.
975"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8107476635514018,"We also provide our code in the supplemental material.
976"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8115264797507789,"Guidelines:
977"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8123052959501558,"• The answer NA means that the paper does not include experiments.
978"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8130841121495327,"• If the paper includes experiments, a No answer to this question will not be perceived
979"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8138629283489096,"well by the reviewers: Making the paper reproducible is important, regardless of
980"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8146417445482866,"whether the code and data are provided or not.
981"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8154205607476636,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
982"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8161993769470405,"to make their results reproducible or verifiable.
983"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8169781931464174,"• Depending on the contribution, reproducibility can be accomplished in various ways.
984"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8177570093457944,"For example, if the contribution is a novel architecture, describing the architecture fully
985"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8185358255451713,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
986"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8193146417445483,"be necessary to either make it possible for others to replicate the model with the same
987"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8200934579439252,"dataset, or provide access to the model. In general. releasing code and data is often
988"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8208722741433022,"one good way to accomplish this, but reproducibility can also be provided via detailed
989"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8216510903426791,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
990"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.822429906542056,"of a large language model), releasing of a model checkpoint, or other means that are
991"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.823208722741433,"appropriate to the research performed.
992"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.82398753894081,"• While NeurIPS does not require releasing code, the conference does require all submis-
993"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8247663551401869,"sions to provide some reasonable avenue for reproducibility, which may depend on the
994"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8255451713395638,"nature of the contribution. For example
995"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8263239875389408,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
996"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8271028037383178,"to reproduce that algorithm.
997"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8278816199376947,"(b) If the contribution is primarily a new model architecture, the paper should describe
998"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8286604361370716,"the architecture clearly and fully.
999"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8294392523364486,"(c) If the contribution is a new model (e.g., a large language model), then there should
1000"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8302180685358256,"either be a way to access this model for reproducing the results or a way to reproduce
1001"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8309968847352025,"the model (e.g., with an open-source dataset or instructions for how to construct
1002"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8317757009345794,"the dataset).
1003"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8325545171339563,"(d) We recognize that reproducibility may be tricky in some cases, in which case
1004"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8333333333333334,"authors are welcome to describe the particular way they provide for reproducibility.
1005"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8341121495327103,"In the case of closed-source models, it may be that access to the model is limited in
1006"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8348909657320872,"some way (e.g., to registered users), but it should be possible for other researchers
1007"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8356697819314641,"to have some path to reproducing or verifying the results.
1008"
OPEN ACCESS TO DATA AND CODE,0.8364485981308412,"5. Open access to data and code
1009"
OPEN ACCESS TO DATA AND CODE,0.8372274143302181,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
1010"
OPEN ACCESS TO DATA AND CODE,0.838006230529595,"tions to faithfully reproduce the main experimental results, as described in supplemental
1011"
OPEN ACCESS TO DATA AND CODE,0.8387850467289719,"material?
1012"
OPEN ACCESS TO DATA AND CODE,0.839563862928349,"Answer: [Yes]
1013"
OPEN ACCESS TO DATA AND CODE,0.8403426791277259,"Justification: We provide experimental details in the main text and details in Appendix A.
1014"
OPEN ACCESS TO DATA AND CODE,0.8411214953271028,"We also provide our code in the supplemental material. The data we use are classic datasets
1015"
OPEN ACCESS TO DATA AND CODE,0.8419003115264797,"which are publicly available.
1016"
OPEN ACCESS TO DATA AND CODE,0.8426791277258567,"Guidelines:
1017"
OPEN ACCESS TO DATA AND CODE,0.8434579439252337,"• The answer NA means that paper does not include experiments requiring code.
1018"
OPEN ACCESS TO DATA AND CODE,0.8442367601246106,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
1019"
OPEN ACCESS TO DATA AND CODE,0.8450155763239875,"public/guides/CodeSubmissionPolicy) for more details.
1020"
OPEN ACCESS TO DATA AND CODE,0.8457943925233645,"• While we encourage the release of code and data, we understand that this might not be
1021"
OPEN ACCESS TO DATA AND CODE,0.8465732087227414,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
1022"
OPEN ACCESS TO DATA AND CODE,0.8473520249221184,"including code, unless this is central to the contribution (e.g., for a new open-source
1023"
OPEN ACCESS TO DATA AND CODE,0.8481308411214953,"benchmark).
1024"
OPEN ACCESS TO DATA AND CODE,0.8489096573208723,"• The instructions should contain the exact command and environment needed to run to
1025"
OPEN ACCESS TO DATA AND CODE,0.8496884735202492,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
1026"
OPEN ACCESS TO DATA AND CODE,0.8504672897196262,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
1027"
OPEN ACCESS TO DATA AND CODE,0.8512461059190031,"• The authors should provide instructions on data access and preparation, including how
1028"
OPEN ACCESS TO DATA AND CODE,0.8520249221183801,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
1029"
OPEN ACCESS TO DATA AND CODE,0.852803738317757,"• The authors should provide scripts to reproduce all experimental results for the new
1030"
OPEN ACCESS TO DATA AND CODE,0.8535825545171339,"proposed method and baselines. If only a subset of experiments are reproducible, they
1031"
OPEN ACCESS TO DATA AND CODE,0.8543613707165109,"should state which ones are omitted from the script and why.
1032"
OPEN ACCESS TO DATA AND CODE,0.8551401869158879,"• At submission time, to preserve anonymity, the authors should release anonymized
1033"
OPEN ACCESS TO DATA AND CODE,0.8559190031152648,"versions (if applicable).
1034"
OPEN ACCESS TO DATA AND CODE,0.8566978193146417,"• Providing as much information as possible in supplemental material (appended to the
1035"
OPEN ACCESS TO DATA AND CODE,0.8574766355140186,"paper) is recommended, but including URLs to data and code is permitted.
1036"
OPEN ACCESS TO DATA AND CODE,0.8582554517133957,"6. Experimental Setting/Details
1037"
OPEN ACCESS TO DATA AND CODE,0.8590342679127726,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
1038"
OPEN ACCESS TO DATA AND CODE,0.8598130841121495,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
1039"
OPEN ACCESS TO DATA AND CODE,0.8605919003115264,"results?
1040"
OPEN ACCESS TO DATA AND CODE,0.8613707165109035,"Answer: [Yes]
1041"
OPEN ACCESS TO DATA AND CODE,0.8621495327102804,"Justification: We provide experimental details in the main text and details in Appendix A.
1042"
OPEN ACCESS TO DATA AND CODE,0.8629283489096573,"We also provide our code in the supplemental material.
1043"
OPEN ACCESS TO DATA AND CODE,0.8637071651090342,"Guidelines:
1044"
OPEN ACCESS TO DATA AND CODE,0.8644859813084113,"• The answer NA means that the paper does not include experiments.
1045"
OPEN ACCESS TO DATA AND CODE,0.8652647975077882,"• The experimental setting should be presented in the core of the paper to a level of detail
1046"
OPEN ACCESS TO DATA AND CODE,0.8660436137071651,"that is necessary to appreciate the results and make sense of them.
1047"
OPEN ACCESS TO DATA AND CODE,0.866822429906542,"• The full details can be provided either with the code, in appendix, or as supplemental
1048"
OPEN ACCESS TO DATA AND CODE,0.867601246105919,"material.
1049"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.868380062305296,"7. Experiment Statistical Significance
1050"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8691588785046729,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
1051"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8699376947040498,"information about the statistical significance of the experiments?
1052"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8707165109034268,"Answer: [Yes]
1053"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8714953271028038,"Justification: All our results are mean/std computed using 10 evaluation seeds.
1054"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8722741433021807,"Guidelines:
1055"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8730529595015576,"• The answer NA means that the paper does not include experiments.
1056"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8738317757009346,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
1057"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8746105919003115,"dence intervals, or statistical significance tests, at least for the experiments that support
1058"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8753894080996885,"the main claims of the paper.
1059"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8761682242990654,"• The factors of variability that the error bars are capturing should be clearly stated (for
1060"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8769470404984424,"example, train/test split, initialization, random drawing of some parameter, or overall
1061"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8777258566978193,"run with given experimental conditions).
1062"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8785046728971962,"• The method for calculating the error bars should be explained (closed form formula,
1063"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8792834890965732,"call to a library function, bootstrap, etc.)
1064"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8800623052959502,"• The assumptions made should be given (e.g., Normally distributed errors).
1065"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8808411214953271,"• It should be clear whether the error bar is the standard deviation or the standard error
1066"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.881619937694704,"of the mean.
1067"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.882398753894081,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
1068"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.883177570093458,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
1069"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8839563862928349,"of Normality of errors is not verified.
1070"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8847352024922118,"• For asymmetric distributions, the authors should be careful not to show in tables or
1071"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8855140186915887,"figures symmetric error bars that would yield results that are out of range (e.g. negative
1072"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8862928348909658,"error rates).
1073"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8870716510903427,"• If error bars are reported in tables or plots, The authors should explain in the text how
1074"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8878504672897196,"they were calculated and reference the corresponding figures or tables in the text.
1075"
EXPERIMENTS COMPUTE RESOURCES,0.8886292834890965,"8. Experiments Compute Resources
1076"
EXPERIMENTS COMPUTE RESOURCES,0.8894080996884736,"Question: For each experiment, does the paper provide sufficient information on the com-
1077"
EXPERIMENTS COMPUTE RESOURCES,0.8901869158878505,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
1078"
EXPERIMENTS COMPUTE RESOURCES,0.8909657320872274,"the experiments?
1079"
EXPERIMENTS COMPUTE RESOURCES,0.8917445482866043,"Answer: [Yes]
1080"
EXPERIMENTS COMPUTE RESOURCES,0.8925233644859814,"Justification: We provide compute resource related information in Appendix A.
1081"
EXPERIMENTS COMPUTE RESOURCES,0.8933021806853583,"Guidelines:
1082"
EXPERIMENTS COMPUTE RESOURCES,0.8940809968847352,"• The answer NA means that the paper does not include experiments.
1083"
EXPERIMENTS COMPUTE RESOURCES,0.8948598130841121,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
1084"
EXPERIMENTS COMPUTE RESOURCES,0.8956386292834891,"or cloud provider, including relevant memory and storage.
1085"
EXPERIMENTS COMPUTE RESOURCES,0.8964174454828661,"• The paper should provide the amount of compute required for each of the individual
1086"
EXPERIMENTS COMPUTE RESOURCES,0.897196261682243,"experimental runs as well as estimate the total compute.
1087"
EXPERIMENTS COMPUTE RESOURCES,0.8979750778816199,"• The paper should disclose whether the full research project required more compute
1088"
EXPERIMENTS COMPUTE RESOURCES,0.8987538940809969,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
1089"
EXPERIMENTS COMPUTE RESOURCES,0.8995327102803738,"didn’t make it into the paper).
1090"
CODE OF ETHICS,0.9003115264797508,"9. Code Of Ethics
1091"
CODE OF ETHICS,0.9010903426791277,"Question: Does the research conducted in the paper conform, in every respect, with the
1092"
CODE OF ETHICS,0.9018691588785047,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
1093"
CODE OF ETHICS,0.9026479750778816,"Answer: [NA]
1094"
CODE OF ETHICS,0.9034267912772586,"Justification: We do not have anything to report.
1095"
CODE OF ETHICS,0.9042056074766355,"Guidelines:
1096"
CODE OF ETHICS,0.9049844236760125,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
1097"
CODE OF ETHICS,0.9057632398753894,"• If the authors answer No, they should explain the special circumstances that require a
1098"
CODE OF ETHICS,0.9065420560747663,"deviation from the Code of Ethics.
1099"
CODE OF ETHICS,0.9073208722741433,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
1100"
CODE OF ETHICS,0.9080996884735203,"eration due to laws or regulations in their jurisdiction).
1101"
BROADER IMPACTS,0.9088785046728972,"10. Broader Impacts
1102"
BROADER IMPACTS,0.9096573208722741,"Question: Does the paper discuss both potential positive societal impacts and negative
1103"
BROADER IMPACTS,0.910436137071651,"societal impacts of the work performed?
1104"
BROADER IMPACTS,0.9112149532710281,"Answer: [NA]
1105"
BROADER IMPACTS,0.911993769470405,"Justification: Our work does not have any such impacts.
1106"
BROADER IMPACTS,0.9127725856697819,"Guidelines:
1107"
BROADER IMPACTS,0.9135514018691588,"• The answer NA means that there is no societal impact of the work performed.
1108"
BROADER IMPACTS,0.9143302180685359,"• If the authors answer NA or No, they should explain why their work has no societal
1109"
BROADER IMPACTS,0.9151090342679128,"impact or why the paper does not address societal impact.
1110"
BROADER IMPACTS,0.9158878504672897,"• Examples of negative societal impacts include potential malicious or unintended uses
1111"
BROADER IMPACTS,0.9166666666666666,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
1112"
BROADER IMPACTS,0.9174454828660437,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
1113"
BROADER IMPACTS,0.9182242990654206,"groups), privacy considerations, and security considerations.
1114"
BROADER IMPACTS,0.9190031152647975,"• The conference expects that many papers will be foundational research and not tied
1115"
BROADER IMPACTS,0.9197819314641744,"to particular applications, let alone deployments. However, if there is a direct path to
1116"
BROADER IMPACTS,0.9205607476635514,"any negative applications, the authors should point it out. For example, it is legitimate
1117"
BROADER IMPACTS,0.9213395638629284,"to point out that an improvement in the quality of generative models could be used to
1118"
BROADER IMPACTS,0.9221183800623053,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
1119"
BROADER IMPACTS,0.9228971962616822,"that a generic algorithm for optimizing neural networks could enable people to train
1120"
BROADER IMPACTS,0.9236760124610592,"models that generate Deepfakes faster.
1121"
BROADER IMPACTS,0.9244548286604362,"• The authors should consider possible harms that could arise when the technology is
1122"
BROADER IMPACTS,0.9252336448598131,"being used as intended and functioning correctly, harms that could arise when the
1123"
BROADER IMPACTS,0.92601246105919,"technology is being used as intended but gives incorrect results, and harms following
1124"
BROADER IMPACTS,0.926791277258567,"from (intentional or unintentional) misuse of the technology.
1125"
BROADER IMPACTS,0.927570093457944,"• If there are negative societal impacts, the authors could also discuss possible mitigation
1126"
BROADER IMPACTS,0.9283489096573209,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
1127"
BROADER IMPACTS,0.9291277258566978,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
1128"
BROADER IMPACTS,0.9299065420560748,"feedback over time, improving the efficiency and accessibility of ML).
1129"
SAFEGUARDS,0.9306853582554517,"11. Safeguards
1130"
SAFEGUARDS,0.9314641744548287,"Question: Does the paper describe safeguards that have been put in place for responsible
1131"
SAFEGUARDS,0.9322429906542056,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
1132"
SAFEGUARDS,0.9330218068535826,"image generators, or scraped datasets)?
1133"
SAFEGUARDS,0.9338006230529595,"Answer: [NA]
1134"
SAFEGUARDS,0.9345794392523364,"Justification: Our work does not imply any such risks.
1135"
SAFEGUARDS,0.9353582554517134,"Guidelines:
1136"
SAFEGUARDS,0.9361370716510904,"• The answer NA means that the paper poses no such risks.
1137"
SAFEGUARDS,0.9369158878504673,"• Released models that have a high risk for misuse or dual-use should be released with
1138"
SAFEGUARDS,0.9376947040498442,"necessary safeguards to allow for controlled use of the model, for example by requiring
1139"
SAFEGUARDS,0.9384735202492211,"that users adhere to usage guidelines or restrictions to access the model or implementing
1140"
SAFEGUARDS,0.9392523364485982,"safety filters.
1141"
SAFEGUARDS,0.9400311526479751,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
1142"
SAFEGUARDS,0.940809968847352,"should describe how they avoided releasing unsafe images.
1143"
SAFEGUARDS,0.9415887850467289,"• We recognize that providing effective safeguards is challenging, and many papers do
1144"
SAFEGUARDS,0.942367601246106,"not require this, but we encourage authors to take this into account and make a best
1145"
SAFEGUARDS,0.9431464174454829,"faith effort.
1146"
LICENSES FOR EXISTING ASSETS,0.9439252336448598,"12. Licenses for existing assets
1147"
LICENSES FOR EXISTING ASSETS,0.9447040498442367,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
1148"
LICENSES FOR EXISTING ASSETS,0.9454828660436138,"the paper, properly credited and are the license and terms of use explicitly mentioned and
1149"
LICENSES FOR EXISTING ASSETS,0.9462616822429907,"properly respected?
1150"
LICENSES FOR EXISTING ASSETS,0.9470404984423676,"Answer: [Yes]
1151"
LICENSES FOR EXISTING ASSETS,0.9478193146417445,"Justification: Our codebase includes certain publicly available code. The corresponding
1152"
LICENSES FOR EXISTING ASSETS,0.9485981308411215,"license files are included in the supplemental material.
1153"
LICENSES FOR EXISTING ASSETS,0.9493769470404985,"Guidelines:
1154"
LICENSES FOR EXISTING ASSETS,0.9501557632398754,"• The answer NA means that the paper does not use existing assets.
1155"
LICENSES FOR EXISTING ASSETS,0.9509345794392523,"• The authors should cite the original paper that produced the code package or dataset.
1156"
LICENSES FOR EXISTING ASSETS,0.9517133956386293,"• The authors should state which version of the asset is used and, if possible, include a
1157"
LICENSES FOR EXISTING ASSETS,0.9524922118380063,"URL.
1158"
LICENSES FOR EXISTING ASSETS,0.9532710280373832,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
1159"
LICENSES FOR EXISTING ASSETS,0.9540498442367601,"• For scraped data from a particular source (e.g., website), the copyright and terms of
1160"
LICENSES FOR EXISTING ASSETS,0.9548286604361371,"service of that source should be provided.
1161"
LICENSES FOR EXISTING ASSETS,0.955607476635514,"• If assets are released, the license, copyright information, and terms of use in the
1162"
LICENSES FOR EXISTING ASSETS,0.956386292834891,"package should be provided. For popular datasets, paperswithcode.com/datasets
1163"
LICENSES FOR EXISTING ASSETS,0.9571651090342679,"has curated licenses for some datasets. Their licensing guide can help determine the
1164"
LICENSES FOR EXISTING ASSETS,0.9579439252336449,"license of a dataset.
1165"
LICENSES FOR EXISTING ASSETS,0.9587227414330218,"• For existing datasets that are re-packaged, both the original license and the license of
1166"
LICENSES FOR EXISTING ASSETS,0.9595015576323987,"the derived asset (if it has changed) should be provided.
1167"
LICENSES FOR EXISTING ASSETS,0.9602803738317757,"• If this information is not available online, the authors are encouraged to reach out to
1168"
LICENSES FOR EXISTING ASSETS,0.9610591900311527,"the asset’s creators.
1169"
NEW ASSETS,0.9618380062305296,"13. New Assets
1170"
NEW ASSETS,0.9626168224299065,"Question: Are new assets introduced in the paper well documented and is the documentation
1171"
NEW ASSETS,0.9633956386292835,"provided alongside the assets?
1172"
NEW ASSETS,0.9641744548286605,"Answer: [Yes]
1173"
NEW ASSETS,0.9649532710280374,"Justification: The documentations of our code are included in the readme file in the supple-
1174"
NEW ASSETS,0.9657320872274143,"mental material.
1175"
NEW ASSETS,0.9665109034267912,"Guidelines:
1176"
NEW ASSETS,0.9672897196261683,"• The answer NA means that the paper does not release new assets.
1177"
NEW ASSETS,0.9680685358255452,"• Researchers should communicate the details of the dataset/code/model as part of their
1178"
NEW ASSETS,0.9688473520249221,"submissions via structured templates. This includes details about training, license,
1179"
NEW ASSETS,0.969626168224299,"limitations, etc.
1180"
NEW ASSETS,0.9704049844236761,"• The paper should discuss whether and how consent was obtained from people whose
1181"
NEW ASSETS,0.971183800623053,"asset is used.
1182"
NEW ASSETS,0.9719626168224299,"• At submission time, remember to anonymize your assets (if applicable). You can either
1183"
NEW ASSETS,0.9727414330218068,"create an anonymized URL or include an anonymized zip file.
1184"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9735202492211839,"14. Crowdsourcing and Research with Human Subjects
1185"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9742990654205608,"Question: For crowdsourcing experiments and research with human subjects, does the paper
1186"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9750778816199377,"include the full text of instructions given to participants and screenshots, if applicable, as
1187"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9758566978193146,"well as details about compensation (if any)?
1188"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9766355140186916,"Answer: [NA]
1189"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9774143302180686,"Justification: We do not have such experiments.
1190"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9781931464174455,"Guidelines:
1191"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9789719626168224,"• The answer NA means that the paper does not involve crowdsourcing nor research with
1192"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9797507788161994,"human subjects.
1193"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9805295950155763,"• Including this information in the supplemental material is fine, but if the main contribu-
1194"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9813084112149533,"tion of the paper involves human subjects, then as much detail as possible should be
1195"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9820872274143302,"included in the main paper.
1196"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9828660436137072,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
1197"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9836448598130841,"or other labor should be paid at least the minimum wage in the country of the data
1198"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9844236760124611,"collector.
1199"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.985202492211838,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
1200"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.985981308411215,"Subjects
1201"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9867601246105919,"Question: Does the paper describe potential risks incurred by study participants, whether
1202"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9875389408099688,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
1203"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9883177570093458,"approvals (or an equivalent approval/review based on the requirements of your country or
1204"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9890965732087228,"institution) were obtained?
1205"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9898753894080997,"Answer: [NA]
1206"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9906542056074766,"Justification: We do not have such experiments.
1207"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9914330218068536,"Guidelines:
1208"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9922118380062306,"• The answer NA means that the paper does not involve crowdsourcing nor research with
1209"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9929906542056075,"human subjects.
1210"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9937694704049844,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
1211"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9945482866043613,"may be required for any human subjects research. If you obtained IRB approval, you
1212"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9953271028037384,"should clearly state this in the paper.
1213"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9961059190031153,"• We recognize that the procedures for this may vary significantly between institutions
1214"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9968847352024922,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
1215"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9976635514018691,"guidelines for their institution.
1216"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9984423676012462,"• For initial submissions, do not include any information that would break anonymity (if
1217"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9992211838006231,"applicable), such as the institution conducting the review.
1218"
