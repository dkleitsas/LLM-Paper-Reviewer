Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0036101083032490976,"Studies of active learning traditionally assume the target and source data stem from
a single domain. However, in realistic applications, practitioners often require
active learning with multiple sources of out-of-distribution data, where it is unclear
a priori which data sources will help or hurt the target domain. We survey a wide
variety of techniques in active learning (AL), domain shift detection (DS), and
multi-domain sampling to examine this challenging setting for question answering
and sentiment analysis. We ask (1) what family of methods are effective for this
task? And, (2) what properties of selected examples and domains achieve strong
results? Among 18 acquisition functions from 4 families of methods, we ﬁnd H-
Divergence methods, and particularly our proposed variant DAL-E, yield effective
results, averaging 2-3% improvements over the random baseline. We also show the
importance of a diverse allocation of domains, as well as room-for-improvement of
existing methods on both domain and example selection. Our ﬁndings yield the
ﬁrst comprehensive analysis of both existing and novel methods for practitioners
faced with multi-domain active learning for natural language tasks."
INTRODUCTION,0.007220216606498195,"1
INTRODUCTION"
INTRODUCTION,0.010830324909747292,"New natural language problems, outside the watershed of core NLP, are often strictly limited by
a dearth of labeled data. While unlabeled data is frequently available, it is not always from the
same source as the target distribution. This is particularly prevalent for tasks characterized by
(i) signiﬁcant distribution shift over time, (ii) personalization for user subgroups, or (iii) different
collection mediums (see examples in Section A)."
INTRODUCTION,0.01444043321299639,"A widely-used solution to this problem is to bootstrap a larger training set using active learning
(AL): a method to decide which unlabeled training examples should be labeled on a ﬁxed annotation
budget (Cohn et al., 1996; Settles, 2012). However, most active learning literature in NLP assumes
the unlabeled source data is drawn from the same distribution as the target data (Dor et al., 2020).
This simplifying assumption avoids the frequent challenges faced by practitioners in multi-domain
active learning. In this realistic setting, there are multiple sources of data (i.e. domains) to consider.
In this case, it’s unclear whether to optimize for homogeneity or heterogeneity of selected examples.
Secondly, is it more effective to allocate an example budget per domain, or treat examples as a single
unlabeled pool? Where active learning baselines traditionally select examples the model is least
conﬁdent on (Settles, 2009), in this setting it could lead to distracting examples from very dissimilar
distributions."
INTRODUCTION,0.018050541516245487,"In this work we empirically examine four separate families of methods (uncertainty-based, H-
Divergence, reverse classiﬁcation accuracy, and semantic similarity detection) over several question
answering and sentiment analysis datasets, following (Lowell et al., 2019; Elsahar & Gall´e, 2019b),
to provide actionable insights to practitioners facing this challenging variant of active learning for
natural language. We address the following questions:"
INTRODUCTION,0.021660649819494584,"1. What family of methods are effective for multi-domain active learning?
2. What properties of the example and domain selection yield strong results?"
INTRODUCTION,0.02527075812274368,"While previous work has investigated similar settings (Saha et al., 2011; Liu et al., 2015; Zhao et al.,
2021; Kirsch et al., 2021) we contribute, to our knowledge, the ﬁrst rigorous formalization and broad
survey of methods within NLP. We ﬁnd that many families of techniques for active learning and"
INTRODUCTION,0.02888086642599278,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.032490974729241874,"domain shift detection fail to reliably beat random baselines in this challenging variant of active
learning, but certain H-Divergence methods are consistently strong. Our analysis identiﬁes stark
dissimilarities of these methods’ example selection, and suggests domain diversity is an important
factor in achieving strong results. These results may serve as a guide to practitioners facing this
problem, suggesting particular methods that are generally effective and properties of strategies that
increase performance.
2
RELATED WORK"
INTRODUCTION,0.036101083032490974,"Active Learning in NLP
Lowell et al. (2019) shows how inconsistent active learning methods are
in NLP, even under regular conditions. However, Dor et al. (2020); Siddhant & Lipton (2018) survey
active learning methods in NLP and ﬁnd notable gains over random baselines. Kouw & Loog (2019)
survey domain adaptation without target labels, similar to our setting, but for non-language tasks. We
reference more active learning techniques in Section 4."
INTRODUCTION,0.039711191335740074,"Domain Shift Detection
Elsahar & Gall´e (2019b) attempt to predict accuracy drops due to domain
shifts and Rabanser et al. (2018) surveys different domain shift detection methods. Arora et al. (2021)
examine calibration and density estimation for textual OOD detection."
INTRODUCTION,0.04332129963898917,"Active Learning under Distribution Shift
A few previous works investigated active learning
under distribution shifts, though mainly in image classiﬁcation, with single source and target domains.
Kirsch et al. (2021) ﬁnds that BALD, which is often considered the state of the art for unshifted
domain settings, can get stuck on irrelevant source domain or junk data. Zhao et al. (2021) investi-
gates label shift, proposing a combination of predicted class balanced subsampling and importance
weighting. Saha et al. (2011), whose approach corrects joint distribution shift, relies on the covariate
shift assumption. However, in practical settings, there may be general distributional shifts where
neither the covariate shift nor label shift assumptions hold."
INTRODUCTION,0.04693140794223827,"Transfer Learning from Multiple Domains
Attempts to better understand how to handle shifted
domains for better generalization or target performance has motivated work in question answering
(Talmor & Berant, 2019; Fisch et al., 2019; Longpre et al., 2019; Kamath et al., 2020) and classiﬁcation
tasks (Ruder & Plank, 2018; Sheoran et al., 2020). Ruder & Plank (2017) show the beneﬁts of both
data similarity and diversity in transfer learning. R¨uckl´e et al. (2020) ﬁnd that sampling from a wide-
variety of source domains (data scale) outperforms sampling similar domains in question answering.
He et al. (2021) investigate a version of multi-domain active learning where models are trained and
evaluated on examples from all domains, focusing on robustness across domains.
3
MULTI-DOMAIN ACTIVE LEARNING"
INTRODUCTION,0.05054151624548736,"Suppose we have multiple domains D1, D2, ..., Dk.1 Let one of the k domains be the target set DT ,
and let the other k −1 domains comprise the source set DS = S"
INTRODUCTION,0.05415162454873646,"i̸=T
Di."
INTRODUCTION,0.05776173285198556,Given:
INTRODUCTION,0.061371841155234655,"• Target: Small samples of labeled data points (x, y) from the target domain.
Dtrain
T
, Ddev
T
, Dtest
T
∼DT .2"
INTRODUCTION,0.06498194945848375,"• Source: A large sample of unlabeled points (x) from the source domains.
DS = S"
INTRODUCTION,0.06859205776173286,"i̸=T
Di Task:"
INTRODUCTION,0.07220216606498195,"1. Choose n samples from DS to label.
Dchosen
S
⊂DS, |Dchosen
S
| = n, selected by arg maxx∈DS Af(x) where Af is an acquisi-
tion function: a policy to select unlabeled examples from DS for labeling.
2. Train a model M on Dfinal−train, validating on Ddev
T
.
Dfinal−train = Dtrain
T
∪Dchosen
S
3. Evaluate M on Dtest
T
, giving score s."
INTRODUCTION,0.07581227436823104,"1We deﬁne a domain as a dataset collected independently of the others.
2|Dtrain
T
| = 2000 to simulate a small but reasonable quantity of labeled, in-domain training data for active
learning scenarios."
INTRODUCTION,0.07942238267148015,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.08303249097472924,"For Step 1, the practitioner chooses n samples with the highest scores according to their acquisition
function Af. M is ﬁne-tuned on these n samples, then evaluated on Dtest
T
to demonstrate Af’s ability
to choose relevant out-of-distribution training examples."
METHODS,0.08664259927797834,"4
METHODS"
METHODS,0.09025270758122744,"We identify four families of methods relevant to active learning over multiple shifted domains.
Uncertainty methods are common in standard active learning for measuring example uncertainty
or familiarity to a model; H-Divergence techniques train classiﬁers for domain shift detection;
Semantic Similarity Detection ﬁnds data points similar to points in the target domain; and Reverse
Classiﬁcation Accuracy approximates the beneﬁt of training on a dataset. A limitation of our work
is we do not cover all method families, such as domain adaptation, just those we consider most
applicable. We derive ∼18 active learning variants, comprising the most prevalent and effective from
prior work, and novel extensions/variants of existing paradigms for the multi-domain active learning
setting (see KNN, ]
RCA and DAL-E)."
METHODS,0.09386281588447654,"Furthermore, we split the families into two acquisition strategies: Single Pool Strategy and Domain
Budget Allocation. Single Pool Strategy, comprising the ﬁrst three families of methods, treats all
examples as coming from one single unlabeled pool. Domain Budget Allocation, consisting of
Reverse Classiﬁcation Accuracy methods, simply allocate an example budget for each domain."
METHODS,0.09747292418772563,"We enumerate acquisition methods Af below. Each method produces a full ranking of examples
in the source set DS. To rank examples, most acquisition methods train an acquisition model, MA,
using the same model architecture as M. MA is trained on all samples from Dtrain
T
, except for DAL
and KNN, which split Dtrain
T
into two equal segments, one for training MA and one for an internal
model. Some methods have both ascending and descending orders of these rankings (denoted by
↑and ↓respectively, in the method abbreviations), to test whether similar or distant examples are
preferred in a multi-domain setting."
METHODS,0.10108303249097472,"Certain methods use vector representations of candidate examples. We benchmark with both task-
agnostic and task-speciﬁc encoders. The task-agnostic embeddings are taken from the last layer’s CLS
token in Reimers & Gurevych (2019)’s sentence encoder (Appendix for details). The task-speciﬁc
embeddings are taken from the last layer’s CLS token in the trained model MA."
METHODS,0.10469314079422383,"The motivation of the task-speciﬁc variant is that each example’s representation will capture task-
relevant differences between examples while ignoring irrelevant differences.3 The versions of DAL
and KNN methods that use task-speciﬁc vectors are denoted with “∗” in their abbreviation. Otherwise,
they use task-agnostic vectors."
UNCERTAINTY METHODS,0.10830324909747292,"4.1
UNCERTAINTY METHODS"
UNCERTAINTY METHODS,0.11191335740072202,"These methods measure the uncertainty of a trained model on a new example. Uncertainty can reﬂect
either aleatoric uncertainty, due to ambiguity inherent in the example, or epistemic uncertainty, due
to limitations of the model (Kendall & Gal, 2017). For the following methods, let Y be the set of all
possible labels produced from the model M(x) and ly be the logit value for y ∈Y ."
UNCERTAINTY METHODS,0.11552346570397112,"Conﬁdence (CONF)
A model’s conﬁdence P(y|x) in its prediction y estimates the difﬁculty or
unfamiliarity of an example (Guo et al., 2017; Elsahar & Gall´e, 2019a)."
UNCERTAINTY METHODS,0.11913357400722022,"Entropy (ENTR)
Entropy applies Shannon entropy (Shannon, 1948) to the full distribution of
class probabilities for each example, formalized as AENTR."
UNCERTAINTY METHODS,0.12274368231046931,"ACONF(x, MA) = −max(P(y|x))
AENTR(x, MA) = −"
UNCERTAINTY METHODS,0.1263537906137184,"|Y |
X"
UNCERTAINTY METHODS,0.1299638989169675,"i=1
P(yi|x) · log P(yi|x)"
UNCERTAINTY METHODS,0.13357400722021662,"Energy-based Out-of-Distribution Detection (ENG)
Liu et al. (2020) use an energy-based score
to distinguish between in- and out-distribution examples. They demonstrate this method is less
susceptible to overconﬁdence issues of softmax approaches."
UNCERTAINTY METHODS,0.1371841155234657,"3For instance, consider in one domain every example is preﬁxed with “Text:” while the other is not — telling
the difference is trivial, but the examples could be near-identical with respect to the task."
UNCERTAINTY METHODS,0.1407942238267148,Under review as a conference paper at ICLR 2022
UNCERTAINTY METHODS,0.1444043321299639,"Bayesian Active Learning by Disagreement (BALD)
Gal & Ghahramani (2016) introduces
estimating uncertainty by measuring prediction disagreement over multiple inference passes, each
with a distinct dropout mask. BALD isolates epistemic uncertainty, as the model would theoretically
produce stable predictions over inference passes given sufﬁcient capacity. We conduct T = 20
forward passes on x. ˆyt = argmaxiP(yi|x)t, representing the predicted class on the t-th model pass
on x. Following (Lowell et al., 2019), ties are broken by taking the mean label entropy over all T
runs."
UNCERTAINTY METHODS,0.148014440433213,"AENG(x, MA) = −log
X"
UNCERTAINTY METHODS,0.15162454873646208,"y∈Y
ely
ABALD(x, MA) = 1 −count(modet∈T (ˆyt)) T"
H-DIVERGENCE METHODS,0.1552346570397112,"4.2
H-DIVERGENCE METHODS"
H-DIVERGENCE METHODS,0.1588447653429603,"Ben-David et al. (2006; 2010) formalize the divergence between two domains as the H-Divergence,
which they approximate as the difﬁculty for a discriminator to differentiate between the two.4
Discriminative Active Learning (DAL) applies this concept to the active learning setting (Gissin &
Shalev-Shwartz, 2019)."
H-DIVERGENCE METHODS,0.1624548736462094,"We explore variants of DAL, using an XGBoost decision tree (Chen & Guestrin, 2016) as the
discriminator model g.5 For the following methods, let Dtrain−B
T
be the 1k examples from Dtrain
T
that were not used to train MA. Let E be an encoder function, which can be task-speciﬁc or agnostic
as described above. We use samples both from Dtrain−B
T
and DS to train the discriminator. We assign
samples origin labels l, which depend on the DAL variant. Samples from DS with discriminator
predictions closest to 1 are selected for labeling. The acquisition scoring function for each DAL
method and training set deﬁnition, respectively, are:"
H-DIVERGENCE METHODS,0.16606498194945848,"ADAL(x, g, E) = g(E(x))
{(E(x), l) | x ∈Dtrain−B
T
∪DS}"
H-DIVERGENCE METHODS,0.16967509025270758,"Discriminative Active Learning — Target (DAL-T)
DAL-T trains a discriminator g to distin-
guish between target examples in Dtrain−B
T
and out-of-distribution examples from DS. For DAL-T,
l = 1Dtrain−B
T
(x)."
H-DIVERGENCE METHODS,0.17328519855595667,"Discriminative Active Learning — Error (DAL-E)
DAL-E is a novel variant of DAL. DAL-
E’s approach is to ﬁnd examples that are similar to those in the target domain that MA misclassiﬁed.
We partition Dtrain−B
T
further into erroneous samples Derr
T
and correct samples Dcorr
T
, where
Dtrain−B
T
= Derr
T
∪Dcorr
T
. For DAL-E, l = 1Derr
T (x)."
REVERSE CLASSIFICATION ACCURACY,0.17689530685920576,"4.3
REVERSE CLASSIFICATION ACCURACY"
REVERSE CLASSIFICATION ACCURACY,0.18050541516245489,"RCA
Reverse Classiﬁcation Accuracy (RCA) estimates how effective source set Di,i∈S is as a
training data for target test set DT (Fan & Davidson, 2006; Elsahar & Gall´e, 2019b). Without gold
labels for Di we compute soft labels instead, using the BERT-Base MA trained on the small labeled
set Dtrain
T
. We then train a child model Mi on Di using these soft labels, and evaluate the child
model on Ddev
T
. RCA chooses examples randomly from whichever domain i produced the highest
score si."
REVERSE CLASSIFICATION ACCURACY,0.18411552346570398,"ARCA = 1D(arg maxi∈S si)(x)
]
RCA :
τi =
si
sT −si
, |Dchosen
i
| =
τi
P j
sj"
REVERSE CLASSIFICATION ACCURACY,0.18772563176895307,"RCA-Smoothed ( ]
RCA)
Standard RCA only selects examples from one domain Di. We develop
a novel variant which samples from multiple domains, proportional to their relative performance on
the target domain Ddev
T
. RCA-smoothed ( ]
RCA) selects |Dchosen
i
| examples from source domain i,
based on the relative difference between the performance si (of child model Mi trained on domain
i with pseudo-labels from MA) on the target domain, and the performance sT of a model trained
directly on the target domain Ddev
T
. Since these strategies directly estimates model performance on
the target domain resulting from training on each source domain, RCA and ]
RCA are strong Domain
Budget Allocation candidates."
REVERSE CLASSIFICATION ACCURACY,0.19133574007220217,Under review as a conference paper at ICLR 2022
REVERSE CLASSIFICATION ACCURACY,0.19494584837545126,"MRQA Datasets
Sentiment Datasets
Dataset
Q
C
|Q|
Q ⊥C
Dataset
|R|
-
N
+"
REVERSE CLASSIFICATION ACCURACY,0.19855595667870035,"SQuAD
Crowd
Wiki
11

Amzn-Books
144
12.1
8.8
79.1
NewsQA
Crowd
News
8

Amzn-Health
80
9.3
7.0
83.7
TriviaQA
Trivia
Web
16

Amzn-Music
132
36.2
9.1
54.7
SearchQA
Jeopardy
Web
17

Amzn-Software
126
14.2
8.1
77.6
HotpotQA
Crowd
Wiki
22

Amzn-Sports
84
49.9
0.0
50.1
Natural-QS
Search
Wiki
9

Amzn-Tools
89
15.3
7.9
76.8
Imdb
230
16.4
7.5
76.1
Yelp
109
24.3
10.7
65.0"
REVERSE CLASSIFICATION ACCURACY,0.20216606498194944,"Table 1: Datasets: The question answering (left) and sentiment analysis (right) datasets in our
experiments. Left: Query source (Q), Context source (C), mean query length (|Q|), and whether the
query was written independently from the context (Q⊥C). Right: mean review length (|R|) and the
percent representation of negative (-), neutral (N) and positive (+) labels."
REVERSE CLASSIFICATION ACCURACY,0.20577617328519857,"4.4
NEAREST NEIGHBOUR / SEMANTIC SIMILARITY DETECTION (KNN)
Nearest neighbour methods (KNN) are used to ﬁnd examples that are semantically similar. Using
sentence encoders we can search the source set DS to select the top k nearest examples by cosine
similarity to the target set. We represent the target set as the mean embedding of Dtrain
T
. For question
answering, where an example contains two sentences (the query and context), we refer to KNN-Q
where we only encode the query text, KNN-C where we only encode the context text, or KNN-QC
where we encode both concatenated together. The acquisition scoring function per example, uses
either a task-speciﬁc or task-agnostic encoder E:
AKNN(x, E) = CosSim(E(x), Mean(E(Dtrain
T
))"
EXPERIMENTS,0.20938628158844766,"5
EXPERIMENTS"
EXPERIMENTS,0.21299638989169675,"Experiments are conducted on two common NLP tasks: question answering (QA) and sentiment
analysis (SA), each with several available domains."
EXPERIMENTS,0.21660649819494585,"Question Answering
We employ 6 diverse QA datasets from the MRQA 2019 workshop (Fisch
et al., 2019), shown in Table 1 (left).6 We sample 60k examples from each dataset for training, 5k
for validation, and 5k for testing. Questions and contexts are collected with varying procedures and
sources, representing a wide diversity of datasets."
EXPERIMENTS,0.22021660649819494,"Sentiment Analysis
For the sentiment analysis classiﬁcation task, we follow (Blitzer et al., 2007)
and (Ruder & Plank, 2018) by randomly selecting 6 Amazon multi-domain review datasets, as well
as Yelp reviews (Asghar, 2016) and IMDB movie reviews datasets (Maas et al., 2011). 7 Altogether,
these datasets exhibit wide diversity based on review length and topic (see Table 1). We normalize all
datasets to have 5 sentiment classes: very negative, negative, neutral, positive, and very positive. We
sample 50k examples for training, 5k for validation, and 5k for testing."
EXPERIMENTS,0.22382671480144403,"Experimental Setup
To evaluate methods for the multi-domain active learning task, we conduct
the experiment described in Section 3 for each acquisition method, rotating each domain as the target
set. Model M, a BERT-Base model (Devlin et al., 2019), is chosen via hyperparameter grid search
over learning rate, number of epochs, and gradient accumulation. The large volume of experiments
entailed by this search space limits our capacity to benchmark performance variability due to isolated
factors (the acquisition method, the target domain, or ﬁne-tuning ﬁnal models). However, our hyper-
parameter search closely mimics the process of an ML practitioner looking to select a best method
and model, so we believe our experiment design captures a fair comparison among methods. See
Algorithm 1 in Appendix Section B for full details."
EXPERIMENTS,0.22743682310469315,"4The approximation is also referred to as Proxy A-Distance (PAD) from (Elsahar & Gall´e, 2019b)
5Hyperparameter choices and training procedures are detailed in the Appendix.
6The workshop pre-processed all datasets into a similar format, for fully answerable, span-extraction QA:
https://github.com/mrqa/MRQA-Shared-Task-2019.
7https://jmcauley.ucsd.edu/data/amazon/,
https://www.yelp.com/dataset,
https://ai.stanford.edu/˜amaas/data/sentiment/."
EXPERIMENTS,0.23104693140794225,Under review as a conference paper at ICLR 2022 CONF↑ CONF↓ ENTR↑ ENTR↓ ENG↑ ENG↓ BALD↑ BALD↓
EXPERIMENTS,0.23465703971119134,DAL-E*
EXPERIMENTS,0.23826714801444043,DAL-T* DAL-E DAL-T RCA RCA~ KNN* KNN −2 −1 0 1 2 3 4
EXPERIMENTS,0.24187725631768953,Absolute Performance (%)
EXPERIMENTS,0.24548736462093862,H-Divergence RCA
EXPERIMENTS,0.2490974729241877,Semantic Similarity
EXPERIMENTS,0.2527075812274368,Uncertainty
EXPERIMENTS,0.2563176895306859,Family
EXPERIMENTS,0.259927797833935,(a) Sentiment Analysis performance improvement (Accuracy %) by acquisition method. CONF↑ CONF↓ ENTR↑ ENTR↓ ENG↑ ENG↓ BALD↑ BALD↓
EXPERIMENTS,0.26353790613718414,DAL-E*
EXPERIMENTS,0.26714801444043323,DAL-T* DAL-E DAL-T RCA RCA~ KNN* KNN-C KNN-Q
EXPERIMENTS,0.27075812274368233,KNN-Q+C −2 0 2 4 6 8 10
EXPERIMENTS,0.2743682310469314,Absolute Performance (%)
EXPERIMENTS,0.2779783393501805,H-Divergence RCA
EXPERIMENTS,0.2815884476534296,Semantic Similarity
EXPERIMENTS,0.2851985559566787,Uncertainty
EXPERIMENTS,0.2888086642599278,Family
EXPERIMENTS,0.2924187725631769,(b) Question Answering performance improvement (F1 %) by acquisition method.
EXPERIMENTS,0.296028880866426,"Figure 1: Performance by Method: The improvement of each acquisition method over the model
given no extra labelled data. Boxplot and whiskers denote the median, quartiles and min/max scores
aggregated across each target domain and sample sizes (n = {8000, 18000, 28000}). The red line
represents the median performance of a baseline that randomly selects examples to annotate.
6
RESULTS"
COMPARING ACQUISITION METHODS,0.2996389891696751,"6.1
COMPARING ACQUISITION METHODS
Results in Figure 1 show the experiments described in Section 5: benchmarking each acquisition
method for multi-domain active learning. We observe for both question answering (QA) and sentiment
analysis (SA), most methods manage to outperform the no-extra-labelled data baseline (0% at the
y-axis) and very narrowly outperform the random selection baseline (red line). Consistent with
prior work (Lowell et al., 2019), active learning strategies in NLP have brittle and inconsistent
improvements over random selection. Our main empirical ﬁndings, described in this section, include:"
COMPARING ACQUISITION METHODS,0.30324909747292417,"• H-Divergence, and particularly DAL-E variants, consistently outperform baselines and
other families of methods.
• The ordering of examples in Uncertainty methods depend signiﬁcantly on the diversity in
source domains. BALD variants perform best among available options.
• Task-agnostic representations, used in KNN or DAL variants, provide consistently strong
results on average, but task-speciﬁc representations signiﬁcantly beneﬁt certain target sets.
• Different families of methods rely on orthogonal notions of relevance in producing their
example rankings."
COMPARING ACQUISITION METHODS,0.30685920577617326,"H-Divergence methods categorically achieved the highest and most reliable scores, both as a family
and individual methods, represented in the top 3 individual methods 11 / 18 times for QA, and 20 / 24
times for SA. For QA, BALD↑and DAL-E∗had the best mean and median scores respectively, and
for SA DAL-E achieved both the best mean and median scores. Among these methods, our proposed
DAL-E variants routinely outperform DAL-T variants by a small margin on average, with equivalent
training and tuning procedures. We believe this is because DAL-E captures both notions of domain
similarity and uncertainty. By design it prioritizes examples that are similar to in-domain samples,
but also avoids those which are uninformative, because the model already performs well on them."
COMPARING ACQUISITION METHODS,0.3104693140794224,"Among Uncertainty methods, for SA methods which select for higher uncertainty vastly outper-
formed those which selected for low uncertainty. The opposite is true for QA. This suggests the"
COMPARING ACQUISITION METHODS,0.3140794223826715,Under review as a conference paper at ICLR 2022
COMPARING ACQUISITION METHODS,0.3176895306859206,"diversity of QA datasets contain more extreme (harmful) domain shift than the (mostly Amazon-based)
SA datasets.8 In both settings, the right ordering of examples with BALD (epistemic uncertainty)
achieves the best results in this family of methods, over the others, which rely on total uncertainty."
COMPARING ACQUISITION METHODS,0.3212996389891697,"Among Reverse Classiﬁcation Accuracy methods, our ]
RCA variant also noticeably outperforms
standard RCA and most other methods, aside from DAL and BALD. Combining ]
RCA with an
example ranking method is a promising direction for future work, given the performance it achieves
selecting examples randomly as a Domain Budget Allocation strategy."
COMPARING ACQUISITION METHODS,0.3249097472924188,"Lastly, the Semantic Similarity Detection set of methods only rarely or narrowly exceed random
selection. Intuitively, task-agnostic representations (KNN) outperform KNN∗, given the task-agnostic
sentence encoder was optimized for cosine similarity."
COMPARING ACQUISITION METHODS,0.3285198555956679,"Embedding Ablations
To see the effects of embedding space on KNN and DAL, we used both a
task-speciﬁc and task-agnostic embedding space. While a task-speciﬁc embedding space reduces the
examples to features relevant for the task, a task-agnostic embedding space produces generic notions
of similarity, unbiased by the task model."
COMPARING ACQUISITION METHODS,0.33212996389891697,"According to Figure 1, KNN outperforms KNN∗. In the QA setting, KNN∗’s median is below the
random baseline’s. In both plots, KNN∗’s whiskers extend below 0, indicating that in some cases the
method actually chooses source examples that are harmful to target domain performance."
COMPARING ACQUISITION METHODS,0.33574007220216606,"For DAL methods, task-agnostic and task-speciﬁc embeddings demonstrated mostly similar median
performances. Notably, the boxes and whiskers are typically longer for task-speciﬁc methods than
task-agnostic methods. This variability indicates certain target datasets may beneﬁt signiﬁcantly from
task-speciﬁc embeddings, though task-agnostic embeddings achieve more consistent results."
COMPARING ACQUISITION METHODS,0.33935018050541516,"Comparing Example Rankings
For each setting, we quantify how similar acquisition methods
rank examples from DS. In Figure 2, for each pair of methods, we calculate the Kendall’s Tau coefﬁ-
cient between the source example rankings chosen for a target domain, then average this coefﬁcient
over the target domains. Kendall’s Tau gives a scores [−1, 1], with -1 meaning perfect anti-correlation,
0 meaning no correlation, and 1 meaning perfect correlation between the rankings. Methods from
different families show close to no relationship, even if they achieve similar performances, suggesting
each family relies on orthogonal notions of similarity to rank example relevance. This suggests there
is potential for combining methods from different families for this task in future work."
COMPARING ACQUISITION METHODS,0.34296028880866425,"In Sentiment tasks, all uncertainty methods had highly correlated examples. In QA, ENTR had
little correlation with any method. This is likely due to the signiﬁcantly larger output space for QA
models. Compared to only 5 label classes in SA, question answering models distribute their start and
end conﬁdences over sequences of up to 512, where there can be multiple valid answer candidates.
Embedding space also largely inﬂuences the examples that methods chose. DAL methods had higher
correlations with each other when they share the same embedding space; i.e. DAL-E’s ranking has a
higher correlation with DAL-T than with DAL-E∗."
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.34657039711191334,"6.2
PROPERTIES OF OPTIMAL EXAMPLE SELECTION"
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.35018050541516244,"We examine three properties of optimally selected examples: (i) whether selecting from many diverse
or one single domain leads to better performance, (ii) whether the selection of a domain or the
individual examples matters more to performance, and (iii) whether selection strategies can beneﬁt
from source domain information rather than treating samples as drawn from a single pool? Our
ﬁndings regarding properties of optimal selection, as described in this section, include:"
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.35379061371841153,"• Selecting a diversity of domains usually outperforms selecting examples from a single
domain.
• Acquisition functions such as DAL-E∗do rely on example selection, mainly to avoid the
possibility of large negative outcomes.
• Domain Budget Allocation during selection may improve performance. Surprisingly,
even random selection from an “optimal” balance of domains beats our best performing
acquisition methods most of the time."
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.3574007220216607,"8Accordingly, we attempt to derive a relationship between domain distance and method performance in
Appendix F, but ﬁnd intuitive calculations of domain distance uninterpretable."
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.36101083032490977,Under review as a conference paper at ICLR 2022 CONF CONF ENTR ENTR ENER ENER BALD BALD
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.36462093862815886,DAL-E* DAL-E
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.36823104693140796,DAL-T* DAL-T kNN*
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.37184115523465705,kNN (C) kNN-Q
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.37545126353790614,kNN-QC
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.37906137184115524,"CONF
CONF
ENTR
ENTR
ENER
ENER"
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.38267148014440433,"BALD
BALD
DAL-E*"
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.3862815884476534,"DAL-E
DAL-T* DAL-T"
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.3898916967509025,"kNN*
kNN (C)"
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.3935018050541516,"kNN-Q
kNN-QC 1.00 0.75 0.50 0.25 0.00 0.25 0.50 0.75 1.00"
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.3971119133574007,"Figure 2:
Similarities of Example Rankings Measured by Kendall’s Tau Coefﬁcients, for QA
(above diagonal) and SA (below diagonal). Kendall’s Tau coefﬁcient is computed between the
example rankings of each pair of methods. The heatmap contains these coefﬁcients averaged over
each target dataset (some cells are crossed out for SA since SA’s KNN methods don’t have C/Q/QC
variants). 1 indicates a perfect relationship between the rankings, 0 means no relationship, and -1
means an inverse relationship."
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.4007220216606498,"Are Many Diverse or One Single Domain Preferable?
To answer this question we conduct a full
search over all combinations of source datasets. For each target set, we ﬁx 2k in-domain data points
and sample all combinations of other source sets in 2k increments, such that altogether there are 10k
training data points. For each combination of source sets, we conduct a simple grid search, randomly
sampling the source set examples each time, and select the best model, mimicking standard practice
among practitioners."
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.4043321299638989,"The result is a comprehensive search of all combinations of source sets (in 2k increments) up to 10k
training points, so we can rank all combinations of domains per target, by performance. Tables 2a
and 2b show the optimal selections, even as discrete as 2k increments, typically select at least two or
more domains to achieve the best performance. However, 1 of 6 targets for QA, or 2 of 8 for the SA
tasks achieve better results selecting all examples from a single domain, suggesting this is a strong
baseline, if the right source domain is isolated. We also report the mean score of all permutations to
demonstrate the importance of selecting the right set of domains over a random combination."
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.40794223826714804,"Domains or Examples?
Which is more important, to select the right domains or the right examples
within some domain? From the above optimal search experiment we see selecting the right combi-
nation of domains regularly leads to strong improvements over a random combination of domains.
Whether example selection is more important than domain selection may vary depending on the
example variety within each domain. We narrow our focus to how much example selection plays a
role for one of the stronger acquisition functions: DAL-E∗."
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.41155234657039713,"We ﬁx the effect of domain selection (the number of examples from each domain) but vary which
examples are speciﬁcally selected. Using DAL-E∗’s distribution of domains, we compare the mean
performance of models trained on it’s highest ranked examples against a random set of examples
sampled from those same domains. We ﬁnd a +0.46 ± 0.25% improvement for QA, and +0.12 ±
0.19% for SA. We also compare model performances trained on random selection against the lowest
ranked examples by DAL-E∗. Interestingly, we see a -1.64 ± 0.37% performance decrease for QA,
and -1.46 ± 0.56% decrease for sentiment tasks. These results suggest that example selection is an
important factor beyond domain selection, especially for avoiding bad example selections."
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.4151624548736462,"Single Pool or Domain Budget Allocation
Does using information about examples’ domains
during selection lead to better results than treating all examples as coming from a single unlabeled
pool? Originally, we hypothesized Single Pool Strategy methods would perform better on smaller
budget sizes as they add the most informative data points regardless of domain. On the other hand,
we thought that if the budget size is large, Domain Budget Allocation would perform best, as they
choose source domains closest to the target domain. Based on Tables 1b and 1a, we were not able to
draw conclusions about this hypothesis, as each sample size n = {8000, 18000, 28000} produced
roughly similar winning methods. Future work should include a wider range of budget sizes with
larger changes in method performance between sizes."
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.4187725631768953,Under review as a conference paper at ICLR 2022
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.4223826714801444,"Optimal Sample
F1 Score"
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.4259927797833935,"SQ
NE
TR
SE
HT
NQ
Optimal
Mean
Single
Domain
Best AF"
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.4296028880866426,"SQUAD
2k
8k
0
0
0
0
78.0
74.0
78.0
77.0
NEWSQA
6k
2k
0
2k
0
0
56.1
52.0
55.2
55.9
TRIVIAQA
2k
4k
2k
0
0
2k
62.9
58.8
61.8
61.9
SEARCHQA
4k
0
0
2k
2k
2k
64.4
61.2
63.5
65.1
HOTPOTQA
6k
0
0
0
2k
2k
67.1
63.6
66.4
66.0
NATURALQ
2k
4k
0
0
2k
2k
63.7
59.8
63.0
64.6"
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.4332129963898917,"MEAN
65.4
61.5
64.6
65.1"
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.4368231046931408,(a) Optimal domain search for Question Answering (QA).
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.4404332129963899,"Optimal Sample
Accuracy Score"
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.44404332129963897,"A-B
A-H
A-M
A-SO
A-SP
A-T
IM
YE
Optimal
Mean
Single
Domain
Best AF"
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.44765342960288806,"AMZN-B
2k
0
0
2k
2k
0
4k
0
69.0
66.5
67.6
68.7
AMZN-H
0
2k
0
0
0
8k
0
0
69.8
67.8
69.8
70.0
AMZN-M
0
0
2k
0
0
2k
6k
0
70.8
69.0
70.1
70.4
AMZN-SO
2k
0
2k
2k
4k
0
0
0
64.7
62.6
64.7
64.4
AMZN-SP
0
2k
0
2k
2k
4k
0
0
67.5
65.3
67.5
68.1
AMZN-T
0
8k
0
0
0
2k
0
0
68.4
65.7
68.4
68.3
IMDB
4k
2k
0
2k
0
0
2k
0
60.2
57.8
59.9
60.5
YELP
0
2k
0
4k
2k
0
0
2k
67.0
64.9
66.1
67.0"
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.45126353790613716,"MEAN
67.2
64.9
66.6
67.2"
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.4548736462093863,(b) Optimal domain search for Sentiment Analysis (SA).
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.4584837545126354,"Table 2: Optimal Domain Search: The optimal distribution of examples is shown per target domain,
in 2k increments. The underlined value indicates the “Single source Domain” (2k in-domain, 8k
source domain) that gave best results. On the right we show the F1 score for this optimal distribution,
the mean score across all distribution combinations, the best Single source Domain, and the Best
Acquisition Function (from Figure 1). Typically allocating optimal domain budgets and the best
acquisition functions both performed strongly."
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.4620938628158845,"In our main set of experiments, the RCA acquisition functions follow the Domain Budget Allocation
strategy, while all other acquisition functions follow the Single Pool strategies. Based on median
performance, ]
RCA outperformed all other methods (we’re including BALD here due to inconsistency
in performance between QA and SA) except for those in the H-Divergence family. This suggests that
using domain information during selection can lead to performance gains."
PROPERTIES OF OPTIMAL EXAMPLE SELECTION,0.4657039711191336,"The Optimal Domain Search experiments, shown in Tables 2a and 2b, further suggest that allocating
a budget from each domain can improve performance. For 8 out of our 14 experiments, selecting
random samples according to the optimal domain distribution outperform any active learning strategy.
While the optimal domain distributions were not computed a priori in our experiments, this result
shows the potential for Domain Budget Allocation strategies. Future work could reasonably improve
our results by developing an acquisition function that better predicts the optimal domain distributions
than ]
RCA, or to even have greater performance gains by budgeting each domain, then applying an
active learning strategy (e.g. DAL-E) within each budget."
CONCLUSION,0.4693140794223827,"7
CONCLUSION"
CONCLUSION,0.4729241877256318,"We examine a challenging variant of active learning where target data is scarce, and multiple shifted
domains operate as the source set of unlabeled data. For practitioners facing multi-domain active
learning, we benchmark 18 acquisition functions, demonstrating the H-Divergence family of methods
and our proposed variant DAL-E achieve the best results. Our analysis shows the importance of
example selection in existing methods, and also the surprising potential of domain budget allocation
strategies. Combining families of methods, or trying domain adaptation techniques on top of selected
example sets, offer promising directions for future work."
CONCLUSION,0.47653429602888087,Under review as a conference paper at ICLR 2022
REFERENCES,0.48014440433212996,REFERENCES
REFERENCES,0.48375451263537905,"Udit Arora, William Huang, and He He. Types of out-of-distribution texts and how to detect them,
2021."
REFERENCES,0.48736462093862815,"Nabiha Asghar. Yelp dataset challenge: Review rating prediction. arXiv preprint arXiv:1605.05362,
2016."
REFERENCES,0.49097472924187724,"Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira. Analysis of representations for
domain adaptation. In Proceedings of the 19th International Conference on Neural Information
Processing Systems, pp. 137–144, 2006."
REFERENCES,0.49458483754512633,"Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman
Vaughan. A theory of learning from different domains. Machine learning, 79(1):151–175, 2010."
REFERENCES,0.4981949458483754,"John Blitzer, Mark Dredze, and Fernando Pereira. Biographies, Bollywood, boom-boxes and blenders:
Domain adaptation for sentiment classiﬁcation. In Proceedings of the 45th Annual Meeting of
the Association of Computational Linguistics, pp. 440–447, Prague, Czech Republic, June 2007.
Association for Computational Linguistics. URL https://www.aclweb.org/anthology/
P07-1056."
REFERENCES,0.5018050541516246,"Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. A large annotated
corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics,
2015."
REFERENCES,0.5054151624548736,"Daniel Cer, Mona Diab, Eneko Agirre, Inigo Lopez-Gazpio, and Lucia Specia. Semeval-2017 task
1: Semantic textual similarity-multilingual and cross-lingual focused evaluation. arXiv preprint
arXiv:1708.00055, 2017."
REFERENCES,0.5090252707581228,"Tianqi Chen and Carlos Guestrin. XGBoost: A scalable tree boosting system. In Proceedings of
the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,
KDD ’16, pp. 785–794, New York, NY, USA, 2016. ACM. ISBN 978-1-4503-4232-2. doi:
10.1145/2939672.2939785. URL http://doi.acm.org/10.1145/2939672.2939785."
REFERENCES,0.5126353790613718,"David A Cohn, Zoubin Ghahramani, and Michael I Jordan. Active learning with statistical models.
Journal of artiﬁcial intelligence research, 4:129–145, 1996."
REFERENCES,0.516245487364621,"Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep
bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of
the North American Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers), pp. 4171–4186, 2019."
REFERENCES,0.51985559566787,"Liat Ein Dor, Alon Halfon, Ariel Gera, Eyal Shnarch, Lena Dankin, Leshem Choshen, Marina
Danilevsky, Ranit Aharonov, Yoav Katz, and Noam Slonim. Active learning for bert: An empirical
study. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language
Processing (EMNLP), pp. 7949–7962, 2020."
REFERENCES,0.5234657039711191,"Matthew Dunn, Levent Sagun, Mike Higgins, V Ugur Guney, Volkan Cirik, and Kyunghyun Cho.
Searchqa: A new q&a dataset augmented with context from a search engine. arXiv preprint
arXiv:1704.05179, 2017."
REFERENCES,0.5270758122743683,"Hady Elsahar and Matthias Gall´e. To annotate or not? predicting performance drop under domain shift.
In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),
pp. 2163–2173, Hong Kong, China, November 2019a. Association for Computational Linguistics.
doi: 10.18653/v1/D19-1222. URL https://www.aclweb.org/anthology/D19-1222."
REFERENCES,0.5306859205776173,"Hady Elsahar and Matthias Gall´e. To annotate or not? predicting performance drop under domain shift.
In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),
pp. 2163–2173, 2019b."
REFERENCES,0.5342960288808665,Under review as a conference paper at ICLR 2022
REFERENCES,0.5379061371841155,"Wei Fan and Ian Davidson. Reverse testing: an efﬁcient framework to select amongst classiﬁers
under sample selection bias. In Proceedings of the 12th ACM SIGKDD international conference
on Knowledge discovery and data mining, pp. 147–156, 2006."
REFERENCES,0.5415162454873647,"Adam Fisch, Alon Talmor, Robin Jia, Minjoon Seo, Eunsol Choi, and Danqi Chen. Mrqa 2019 shared
task: Evaluating generalization in reading comprehension. In EMNLP 2019 MRQA Workshop, pp.
1, 2019."
REFERENCES,0.5451263537906137,"Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model
uncertainty in deep learning. In Proceedings of the 33rd International Conference on Machine
Learning, New York, NY, USA, 2016."
REFERENCES,0.5487364620938628,"Yarin Gal, Riashat Islam, and Zoubin Ghahramani. Deep bayesian active learning with image data. In
Proceedings of the 34th International Conference on Machine Learning (ICML), Sydney, Australia,
2017. URL http://proceedings.mlr.press/v70/gal17a/gal17a.pdf."
REFERENCES,0.5523465703971119,"Daniel Gissin and Shai Shalev-Shwartz.
Discriminative active learning.
arXiv preprint
arXiv:1907.06347, 2019."
REFERENCES,0.555956678700361,"Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. On calibration of modern neural
networks. In Proceedings of the 34th International Conference on Machine Learning, Sydney,
Australia, 2017. URL http://proceedings.mlr.press/v70/guo17a/guo17a.pdf."
REFERENCES,0.5595667870036101,"Rui He, Shan He, and Ke Tang. Multi-domain active learning: A comparative study. arXiv preprint
arXiv:2106.13516, 2021."
REFERENCES,0.5631768953068592,"Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke Zettlemoyer. Triviaqa: A large scale distantly
supervised challenge dataset for reading comprehension. arXiv preprint arXiv:1705.03551, 2017."
REFERENCES,0.5667870036101083,"Amita Kamath, Robin Jia, and Percy Liang. Selective question answering under domain shift. In
Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp.
5684–5696, 2020."
REFERENCES,0.5703971119133574,"Alex Kendall and Yarin Gal. What uncertainties do we need in bayesian deep learning for computer
vision? In Proceedings of the 31st International Conference on Neural Information Processing
Systems, pp. 5580–5590, 2017."
REFERENCES,0.5740072202166066,"Andreas Kirsch, Tom Rainforth, and Yarin Gal. Active learning under pool set distribution shift and
noisy data, 2021."
REFERENCES,0.5776173285198556,"Wouter Marco Kouw and Marco Loog. A review of domain adaptation without target labels. IEEE
transactions on pattern analysis and machine intelligence, 2019."
REFERENCES,0.5812274368231047,"Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redﬁeld, Michael Collins, Ankur Parikh, Chris
Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al. Natural questions: a
benchmark for question answering research. Transactions of the Association for Computational
Linguistics, 7:453–466, 2019."
REFERENCES,0.5848375451263538,"Anqi Liu, Lev Reyzin, and Brian Ziebart. Shift-pessimistic active learning using robust bias-aware
prediction. Proceedings of the AAAI Conference on Artiﬁcial Intelligence, 29(1), Feb. 2015. URL
https://ojs.aaai.org/index.php/AAAI/article/view/9609."
REFERENCES,0.5884476534296029,"Weitang Liu, Xiaoyun Wang, John D. Owens, and Yixuan Li. Energy-based out-of-distribution detec-
tion. In 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver,
Canada, 2020. URL https://arxiv.org/pdf/2010.03759.pdf."
REFERENCES,0.592057761732852,"Shayne Longpre, Yi Lu, Zhucheng Tu, and Chris DuBois. An exploration of data augmentation and
sampling techniques for domain-agnostic question answering. In Proceedings of the 2nd Workshop
on Machine Reading for Question Answering, pp. 220–227, 2019."
REFERENCES,0.5956678700361011,"David Lowell, Zachary C Lipton, and Byron C Wallace. Practical obstacles to deploying active
learning. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language
Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-
IJCNLP), pp. 21–30, Hong Kong, China, 2019. URL https://www.aclweb.org/anthology/
D19-1003.pdf."
REFERENCES,0.5992779783393501,Under review as a conference paper at ICLR 2022
REFERENCES,0.6028880866425993,"Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher
Potts. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting
of the Association for Computational Linguistics: Human Language Technologies, pp. 142–150,
Portland, Oregon, USA, June 2011. Association for Computational Linguistics. URL http:
//www.aclweb.org/anthology/P11-1015."
REFERENCES,0.6064981949458483,"Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan,
Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas
Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy,
Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala.
Pytorch: An imperative style,
high-performance deep learning library.
In H. Wallach, H. Larochelle, A. Beygelzimer,
F. d'Alch´e-Buc, E. Fox, and R. Garnett (eds.), Advances in Neural Information Processing Systems
32, pp. 8024–8035. Curran Associates, Inc., 2019. URL http://papers.neurips.cc/paper/
9015-pytorch-an-imperative-style-high-performance-deep-learning-library.
pdf."
REFERENCES,0.6101083032490975,"Stephan Rabanser, Stephan G¨unnemann, and Zachary C Lipton. Failing loudly: An empirical study
of methods for detecting dataset shift. arXiv preprint arXiv:1810.11953, 2018."
REFERENCES,0.6137184115523465,"Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. Squad: 100,000+ questions for
machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods in
Natural Language Processing, pp. 2383–2392, 2016."
REFERENCES,0.6173285198555957,"Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bert-networks.
In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing.
Association for Computational Linguistics, 11 2019. URL https://arxiv.org/abs/1908.
10084."
REFERENCES,0.6209386281588448,"Andreas R¨uckl´e, Jonas Pfeiffer, and Iryna Gurevych. Multicqa: Zero-shot transfer of self-supervised
text matching models on a massive scale. In Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing (EMNLP), pp. 2471–2486, 2020."
REFERENCES,0.6245487364620939,"Sebastian Ruder and Barbara Plank. Learning to select data for transfer learning with bayesian
optimization. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language
Processing, pp. 372–382, 2017."
REFERENCES,0.628158844765343,"Sebastian Ruder and Barbara Plank. Strong baselines for neural semi-supervised learning under
domain shift. In Proceedings of the 56th Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pp. 1044–1054, 2018."
REFERENCES,0.631768953068592,"Avishek Saha, Piyush Rai, Hal Daum´e, Suresh Venkatasubramanian, and Scott L. DuVall. Active
supervised domain adaptation. In Dimitrios Gunopulos, Thomas Hofmann, Donato Malerba,
and Michalis Vazirgiannis (eds.), Machine Learning and Knowledge Discovery in Databases, pp.
97–112, Berlin, Heidelberg, 2011. Springer Berlin Heidelberg. ISBN 978-3-642-23808-6."
REFERENCES,0.6353790613718412,Burr Settles. Active learning literature survey. 2009.
REFERENCES,0.6389891696750902,"Burr Settles. Active learning. Synthesis lectures on artiﬁcial intelligence and machine learning, 6(1):
1–114, 2012."
REFERENCES,0.6425992779783394,"Claude E. Shannon. A mathematical theory of communication. In Bell System Technical Journal,
volume 27(3), pp. 379–423, 1948."
REFERENCES,0.6462093862815884,"Akash Sheoran, Diptesh Kanojia, Aditya Joshi, and Pushpak Bhattacharyya. Recommendation chart
of domains for cross-domain sentiment analysis: Findings of a 20 domain study. In Proceedings of
The 12th Language Resources and Evaluation Conference, pp. 4982–4990, 2020."
REFERENCES,0.6498194945848376,"Aditya Siddhant and Zachary C. Lipton. Deep Bayesian active learning for natural language pro-
cessing: Results of a large-scale empirical study. In Proceedings of the 2018 Conference on
Empirical Methods in Natural Language Processing, pp. 2904–2909, Brussels, Belgium, October-
November 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1318. URL
https://aclanthology.org/D18-1318."
REFERENCES,0.6534296028880866,Under review as a conference paper at ICLR 2022
REFERENCES,0.6570397111913358,"Alon Talmor and Jonathan Berant. Multiqa: An empirical investigation of generalization and transfer
in reading comprehension. In Proceedings of the 57th Annual Meeting of the Association for
Computational Linguistics, pp. 4911–4921, 2019."
REFERENCES,0.6606498194945848,"Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip Bachman, and
Kaheer Suleman. Newsqa: A machine comprehension dataset. arXiv preprint arXiv:1611.09830,
2016."
REFERENCES,0.6642599277978339,"Adina Williams, Nikita Nangia, and Samuel Bowman. A broad-coverage challenge corpus for
sentence understanding through inference. In Proceedings of the 2018 Conference of the North
American Chapter of the Association for Computational Linguistics: Human Language Technolo-
gies, Volume 1 (Long Papers), pp. 1112–1122. Association for Computational Linguistics, 2018.
URL http://aclweb.org/anthology/N18-1101."
REFERENCES,0.6678700361010831,"Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W Cohen, Ruslan Salakhutdinov,
and Christopher D Manning. Hotpotqa: A dataset for diverse, explainable multi-hop question
answering. arXiv preprint arXiv:1809.09600, 2018."
REFERENCES,0.6714801444043321,"Eric Zhao, Anqi Liu, Animashree Anandkumar, and Yisong Yue. Active learning under label shift. In
Arindam Banerjee and Kenji Fukumizu (eds.), Proceedings of The 24th International Conference
on Artiﬁcial Intelligence and Statistics, volume 130 of Proceedings of Machine Learning Research,
pp. 3412–3420. PMLR, 13–15 Apr 2021. URL https://proceedings.mlr.press/v130/
zhao21b.html."
REFERENCES,0.6750902527075813,Under review as a conference paper at ICLR 2022
REFERENCES,0.6787003610108303,"A
MULTI-DOMAIN ACTIVE LEARNING TASK"
REFERENCES,0.6823104693140795,"In this section, we would enumerate real-world settings in which a practitioner would be interested
in multi-domain active learning methods. We expect this active learning variant to be applicable to
cold starts, rare classes, personalization, and settings where the modelers are constrained by privacy
considerations, or a lack of labelers with domain expertise."
REFERENCES,0.6859205776173285,"• In the cold start scenario, for a new NLP problem, there is often little to no target data
available yet (labeled or unlabelled), but there are related sources of unlabelled data to try.
Perhaps an engineer has collected small amounts of training data from an internal population.
Because the data size is small, the engineer is considering out-of-domain samples, collected
from user studies, repurposed from other projects, scraped from the web, etc..
• In the rare class scenario, take an example of a new platform/forum/social media company
classifying hate speech against a certain minority group. Perhaps the prevalence of positive,
in-domain samples on the social media platform is small, so an engineer uses out-domain
samples from books, other social media platforms, or from combing the internet.
• In a personalization setting, like spam ﬁltering or auto-completion on a keyboard, each
user may only have a couple hundred of their own samples, but out-domain samples from
other users may be available in greater quantities.
• In the privacy constrained setting, a company may collect data from internal users, user
studies, and beta testers; however, a commitment to user privacy may incentivize the
company to keep the amount of labeled data from the target user population low.
• Lastly, labeling in-domain data may require certain domain knowledge, which would lead
to increased expenses and difﬁculty in ﬁnding annotators. As an example, take a text
classiﬁcation problem in a rare language. It may be easy to produce out-domain samples by
labeling English text and machine translating it to the rare language, whereas generating
in-domain labeled data would require annotators who are ﬂuent in the rare language."
REFERENCES,0.6895306859205776,"In each of these settings, target distribution data may not be amply available, but semi-similar
unlabelled domains often are. This rules out many domain adaptation methods that rely heavily on
unlabelled target data."
REFERENCES,0.6931407942238267,"We were able to simulate the base conditions of this problem with sentiment analysis and question
answering datasets, since they are rich in domain diversity. We believe these datasets are reasonable
proxies to represent the base problem, and yield general-enough insights for a practitioner starting on
this problem."
REFERENCES,0.6967509025270758,"B
REPRODUCIBILITY"
REFERENCES,0.7003610108303249,"B.1
DATASETS AND MODEL TRAINING"
REFERENCES,0.703971119133574,"We choose question answering and sentiment analysis tasks as they are core NLP tasks, somewhat
representative of many classiﬁcation and information-seeking problems. Multi-domain active learning
is not limited to any subset of NLP tasks, so we believe these datasets are a reasonable proxie for the
problem."
REFERENCES,0.7075812274368231,"For question answering, the MRQA shared task (Fisch et al., 2019) includes SQuAD (Rajpurkar
et al., 2016), NewsQA (Trischler et al., 2016), TriviaQA (Joshi et al., 2017), SearchQA (Dunn et al.,
2017), HotpotQA (Yang et al., 2018), and Natural Questions (Kwiatkowski et al., 2019)."
REFERENCES,0.7111913357400722,"For the sentiment analysis classiﬁcation task, we use Amazon datasets following (Blitzer et al., 2007)
and (Ruder & Plank, 2018), as well as Yelp reviews (Asghar, 2016) and IMDB movie reviews datasets
(Maas et al., 2011). 9 Both question answering and sentiment analysis datasets are described in
Table 1."
REFERENCES,0.7148014440433214,"For reproducibility, we share our hyper-parameter selection in Table 3. Hyper-parameters are taken
from Longpre et al. (2019) for training all Question Answering (QA) models since their parameters"
REFERENCES,0.7184115523465704,"9https://jmcauley.ucsd.edu/data/amazon/,
https://www.yelp.com/dataset,
https://ai.stanford.edu/˜amaas/data/sentiment/."
REFERENCES,0.7220216606498195,Under review as a conference paper at ICLR 2022
REFERENCES,0.7256317689530686,"are tuned for the same datasets in the MRQA Shared Task. We found these choices to provide stable
and strong results across all datasets. For sentiment analysis, we initially experimented on a small
portion of the datasets to arrive at a strong set of base hyper-parameters to tune from."
REFERENCES,0.7292418772563177,"Our BERT question answering modules build upon the standard PyTorch (Paszke et al., 2019)
implementations from HuggingFace, and are trained on one NVIDIA Tesla V100 GPU.10."
REFERENCES,0.7328519855595668,"Model Parameter
Value"
REFERENCES,0.7364620938628159,"Base Pre-trained Model
BERT-base
Model Size (# params)
108.3M
Learning Rate
5e −5
Optimizer
Adam
Gradient Accumulation
1
Dropout
0.1
Lower Case
False"
REFERENCES,0.740072202166065,"Question Answering model
Avg. Train Time
2h 20m
Batch Size
25
Num Epochs
2
Max Query Length
64
Max Sequence Length
512"
REFERENCES,0.7436823104693141,"Sentiment Classifcation model
Avg. Train Time
43m
Batch Size
20
Num Epochs
3
Max Sequence Length
128"
REFERENCES,0.7472924187725631,Table 3: Hyperparameter selection for task models.
REFERENCES,0.7509025270758123,"B.2
EXPERIMENTAL DESIGN"
REFERENCES,0.7545126353790613,"For more detail regarding the experimental design we include Algorith 1, using notation described in
the multi-domain active learning task deﬁnition."
REFERENCES,0.7581227436823105,Algorithm 1 EXPERIMENTAL DESIGN
REFERENCES,0.7617328519855595,"1: for each Acquisition Function Af do
2:
for each Target set DT ∼D do
3:
Dtrain
T
, Ddev
T
, Dtest
T
∼DT
4:
DS := {x ∈D | x /∈DT }
5:
MA ←TRAIN(Dtrain
T
, Ddev
T
)
6:
Dchosen ←[Rankx∈DSAf(x, MA)][: n]
7:
Dfinal−train = Dtrain
T
∪Dchosen"
REFERENCES,0.7653429602888087,"8:
M ←GRIDSEARCH(Dfinal−train, Ddev
T
)
9:
(Af, DT ) = s
Af
T
←M(Dtest
T
)
10:
end for
11: end for
12: return Scores Dictionary (Af, DT ) →s
Af
T"
REFERENCES,0.7689530685920578,"C
ACQUISITION FUNCTIONS"
REFERENCES,0.7725631768953068,"C.1
TASK AGNOSTIC EMBEDDINGS"
REFERENCES,0.776173285198556,"To compute the semantic similarity between two examples, we computed the example embeddings
using the pre-trained model from a sentence-transformer (Reimers & Gurevych, 2019). We used the"
REFERENCES,0.779783393501805,10https://github.com/huggingface/transformers
REFERENCES,0.7833935018050542,Under review as a conference paper at ICLR 2022
REFERENCES,0.7870036101083032,"Model Parameter
Value
DAL Discriminator"
REFERENCES,0.7906137184115524,"Model Type
XGBoost
Model Size (# trees)
10
Model Size (maximum depth)
2"
REFERENCES,0.7942238267148014,"Learning Rate
0.1
Objective
binary:logistic
Booster
gbtree
Tree Method
gpu hist
Gamma
5
Min Child Weight
5
Max Delta Step
0
Subsample
1
Colsample Bytree
1
Colsample Bynode
1
Reg Alpha
0
Reg Lambda
5
Scale Pos Weight
1"
REFERENCES,0.7978339350180506,Table 4: Hyperparameter selection for DAL discriminators.
REFERENCES,0.8014440433212996,"RoBERTa large model, which has 24 layers, 1024 hidden layers, 16 heads, 355M parameters, and ﬁne
tuning on the SNLI (Bowman et al., 2015), MultiNLI (Williams et al., 2018), and STSBenchmark
(Cer et al., 2017) datasets. Its training procedure is documented in https://www.sbert.net/
examples/training/sts/README.html."
REFERENCES,0.8050541516245487,"C.2
BAYESIAN ACTIVE LEARNING BY DISAGREEMENT (BALD)"
REFERENCES,0.8086642599277978,"We note that Siddant and Lipton’s presentation of BALD is more closely related to the Variation
Ratios acquisition function described in Gal et al. (2017) than the description of dropout as a Bayesian
approximation given in Gal & Ghahramani (2016). In particular, Gal et al. (2017) found that
Variation Ratios performed on par or better than Houlsby’s BALD on MNIST but was less suitable
for ISIC2016."
REFERENCES,0.8122743682310469,"C.3
DISCRIMINATIVE ACTIVE LEARNING MODEL (DAL) TRAINING"
REFERENCES,0.8158844765342961,"DAL’s training set is created using the methods detailed in Section 4.2. The training set is then
partitioned into ﬁve equally sized folds. In order to predict on data that is not used to train the
discriminator, we use 5-fold cross validation. The model is trained on four folds, balancing the
positive and negative classes using sample weights. The classiﬁer then predicts on the single held-
out fold. This process is repeated ﬁve times so that each example is in the held out fold exactly
once. Custom model parameters are shown in Table 4; model parameters not shown in the table are
the default XGBClassiﬁer parameters in xgboost 1.0.2. The motivations for choice in model and
architecture are the small amount of target domain examples requiring a simple model to prevent
overﬁtting and the ability of decision trees to capture collective interactions between features."
REFERENCES,0.8194945848375451,"D
FULL METHOD PERFORMANCES"
REFERENCES,0.8231046931407943,We provide a full breakdown of ﬁnal method performances in Tables 5 and 6.
REFERENCES,0.8267148014440433,Under review as a conference paper at ICLR 2022
REFERENCES,0.8303249097472925,"Train Size
Target
random
CONF↑
CONF↓
ENTR↑
ENTR↓
ENG↑
ENG↓
BALD↑
BALD↓
DAL-E∗
DAL-T∗
DAL-E
DAL-T
RCA
^
RCA
KNN∗
KNN-C
KNN-Q
KNN-QC 10000"
REFERENCES,0.8339350180505415,"HOTPOTQA
65.76
64.15
64.38
64.59
66.03
65.39
62.39
63.13
61.45
65.42
65.33
63.58
63.18
65.19
65.33
62.25
64.28
63.98
63.51
NATURALQ
63.05
61.59
62.14
64.61
63.56
61.52
62.44
58.35
61.56
63.0
62.79
62.54
62.7
58.72
62.73
59.75
61.94
63.28
61.84
NEWSQA
53.51
47.72
51.82
54.14
52.85
52.54
48.06
55.61
52.76
51.36
50.93
54.41
54.69
55.93
54.31
50.77
53.13
55.52
52.91
SEARCHQA
62.83
58.46
63.84
63.12
64.25
62.18
63.22
63.26
65.12
62.6
62.59
63.28
63.31
62.32
62.03
61.84
63.84
63.27
62.39
SQUAD
75.97
73.23
75.33
76.28
73.41
76.22
73.07
75.65
73.13
76.61
76.75
77.0
76.88
77.0
76.25
76.74
74.24
75.08
74.94
TRIVIAQA
61.44
58.19
60.17
59.75
57.57
59.64
59.4
60.02
58.32
61.89
61.24
61.94
61.06
58.88
60.81
60.45
59.98
60.82
60.37 20000"
REFERENCES,0.8375451263537906,"HOTPOTQA
66.29
64.12
64.3
65.15
67.53
65.86
63.86
67.51
63.76
67.05
67.13
64.48
64.23
65.81
66.78
61.96
64.14
64.68
64.13
NATURALQ
63.62
63.65
62.12
64.87
64.11
63.3
60.32
64.86
63.63
63.99
64.14
63.98
63.38
59.21
63.76
60.34
61.54
63.81
62.43
NEWSQA
54.71
48.32
52.68
55.44
54.78
53.01
47.56
57.69
55.2
52.15
52.1
55.62
56.29
57.33
57.47
50.16
53.55
55.5
54.94
SEARCHQA
62.53
61.93
64.08
63.51
62.56
61.46
63.21
64.27
67.22
62.92
63.14
63.65
63.3
62.13
63.01
62.24
64.88
63.32
63.84
SQUAD
76.32
75.33
75.53
77.61
72.17
76.54
72.79
78.02
74.15
77.51
77.72
77.7
77.59
78.57
78.0
77.79
75.93
76.56
76.27
TRIVIAQA
62.45
61.37
61.97
61.64
61.21
62.38
60.2
61.74
60.54
63.38
62.56
62.7
61.99
59.76
61.65
62.54
61.83
62.08
62.84 30000"
REFERENCES,0.8411552346570397,"HOTPOTQA
65.98
64.79
66.33
64.43
68.3
65.76
63.39
69.17
63.44
67.09
67.51
64.91
65.34
65.92
67.79
62.32
64.09
65.85
64.86
NATURALQ
63.61
63.49
63.18
64.51
64.65
63.87
62.68
66.4
63.62
64.66
65.12
64.84
64.24
59.18
63.64
61.63
62.32
64.24
62.66
NEWSQA
55.18
47.73
54.26
56.79
54.48
54.62
48.38
58.4
56.7
53.48
53.48
55.63
56.17
57.7
56.84
49.19
54.89
56.24
54.54
SEARCHQA
62.28
61.9
62.86
63.73
63.5
62.17
63.85
66.67
68.61
62.97
63.61
63.52
63.3
61.89
62.99
62.4
63.7
63.37
63.76
SQUAD
77.75
74.1
76.78
76.98
75.08
76.76
73.08
78.7
77.04
79.21
78.71
78.08
79.24
80.18
78.38
78.76
75.77
77.88
77.13
TRIVIAQA
63.2
62.34
61.98
62.01
61.87
62.98
60.13
61.85
62.49
64.36
64.35
63.21
62.97
61.36
62.81
63.22
62.94
62.91
63.89"
REFERENCES,0.8447653429602888,"Table 5: MQRA F1 scores from each active learning method over every training set size and target
domain. The best performances are bolded and underlined."
REFERENCES,0.8483754512635379,"Train Size
Target
random
CONF↑
CONF↓
ENTR↑
ENTR↓
ENG↑
ENG↓
BALD↑
BALD↓
DAL-E∗
DAL-T∗
DAL-E
DAL-T
RCA
^
RCA
KNN∗
KNN 10000"
REFERENCES,0.851985559566787,"AMZN-B
65.04
68.66
65.36
65.32
68.08
66.38
68.62
64.46
68.2
67.16
66.98
68.28
67.68
67.24
68.3
65.66
67.06
AMZN-H
66.36
68.98
66.32
67.36
68.84
65.98
69.3
66.64
69.36
70.04
68.4
69.32
69.1
69.6
69.14
68.52
68.84
AMZN-M
68.38
70.2
67.3
68.1
69.66
67.4
70.4
67.42
69.74
70.42
69.4
70.16
70.06
69.88
70.08
69.44
69.56
AMZN-SO
61.06
63.94
61.92
61.38
64.32
62.42
64.3
61.24
64.3
63.46
63.04
64.2
64.22
62.4
64.12
63.72
64.42
AMZN-SP
64.92
67.12
64.22
64.68
66.5
64.68
66.1
64.06
67.58
67.12
66.66
68.04
67.62
68.14
66.98
66.16
66.94
AMZN-T
65.4
67.88
65.94
65.54
67.26
65.56
68.02
64.64
67.8
68.44
65.68
67.86
68.24
66.66
67.06
65.36
67.64
IMDB
58.05
59.32
59.48
58.76
58.78
58.88
58.54
58.02
59.9
59.68
60.46
60.4
60.52
59.94
59.52
58.96
60.1
YELP
66.75
64.94
63.82
64.36
65.58
63.46
65.88
64.42
66.38
66.06
66.4
65.84
66.98
66.0
67.04
66.24
65.46 20000"
REFERENCES,0.855595667870036,"AMZN-B
64.68
69.12
65.92
65.18
68.46
67.08
69.04
66.5
68.88
68.18
65.64
68.16
68.68
67.9
67.88
66.26
67.64
AMZN-H
67.16
69.46
65.04
64.94
69.54
65.94
70.32
65.32
69.84
70.32
68.08
69.94
70.04
70.16
70.28
67.66
69.18
AMZN-M
68.76
70.86
66.2
67.84
69.98
66.18
70.82
66.7
70.52
71.48
69.56
70.84
70.54
71.32
69.86
68.78
70.28
AMZN-SO
61.5
64.98
62.1
62.28
65.56
61.66
65.2
61.82
65.34
64.7
64.74
64.88
64.56
63.18
64.22
64.26
65.3
AMZN-SP
65.68
67.18
65.04
63.78
67.14
65.66
66.34
63.52
67.36
68.22
68.78
68.36
68.72
68.42
67.54
65.32
67.84
AMZN-T
65.92
68.1
66.26
65.04
68.44
65.52
68.18
64.76
69.02
69.62
65.76
69.72
69.1
67.12
68.38
66.6
68.58
IMDB
58.58
59.56
58.88
58.38
58.74
59.74
58.76
58.84
58.96
60.2
60.76
60.1
60.06
59.94
60.54
59.38
59.98
YELP
66.39
66.52
62.92
64.34
65.74
63.34
66.18
64.06
66.62
67.6
66.9
67.2
66.16
65.98
66.86
65.46
67.4 30000"
REFERENCES,0.8592057761732852,"AMZN-B
65.18
68.96
65.02
63.42
68.9
65.96
69.12
63.72
69.42
68.86
67.16
69.22
68.08
68.2
69.06
66.32
68.42
AMZN-H
67.0
71.1
64.82
64.62
69.92
64.78
70.54
63.56
70.38
70.86
67.96
70.38
70.6
70.32
70.2
68.46
70.74
AMZN-M
69.48
70.96
67.16
66.34
70.5
68.06
71.14
66.48
71.14
71.56
70.28
70.38
71.0
71.28
70.98
68.92
70.64
AMZN-SO
62.94
66.06
62.0
61.56
66.06
61.76
65.98
60.52
66.36
65.88
66.0
65.58
65.8
63.44
65.98
64.58
66.22
AMZN-SP
67.06
67.82
63.44
63.08
68.0
64.14
67.82
63.6
69.16
68.7
67.86
69.38
68.56
68.42
68.3
66.24
67.96
AMZN-T
66.1
69.04
65.8
66.14
68.2
66.96
69.0
63.4
69.62
70.22
67.08
70.0
69.62
68.1
68.8
67.2
69.72
IMDB
59.67
58.9
59.84
57.9
59.1
59.66
59.3
58.58
59.76
59.78
61.58
60.7
60.8
60.6
60.32
60.4
60.64
YELP
66.93
66.28
63.68
64.28
66.7
63.38
67.34
63.62
67.16
66.78
67.46
68.2
66.94
66.22
67.18
65.54
67.82"
REFERENCES,0.8628158844765343,"Table 6: Sentiment accuracy scores from each active learning method over every training set size and
target domain. The best performances are bolded and underlined."
REFERENCES,0.8664259927797834,"E
KENDALL’S TAU"
REFERENCES,0.8700361010830325,"E.1
DEFINITION"
REFERENCES,0.8736462093862816,"Kendall’s Tau is a statistic that measures the rank correlation between two quantities. Let X and
Y be random variables with (x1, y1), (x2, y2), ..., (xn, yn) as observations drawn from the joint
distribution. Given a pair (xi, yi) and (xj, yj), where i ̸= j, we have:"
REFERENCES,0.8772563176895307,"yj−yi
xj−xi > 0 : pair is concordant"
REFERENCES,0.8808664259927798,"yj−yi
xj−xi < 0 : pair is discordant"
REFERENCES,0.8844765342960289,"yj−yi
xj−xi = 0 : pair is a tie"
REFERENCES,0.8880866425992779,"Let nc be the number of concordant pairs and nd the number of discordant pairs. Let ties add 0.5 to
the concordant and discordant pair counts each. Then, Kendall’s Tau is computed as:11"
REFERENCES,0.8916967509025271,τ = nc−nd nc+nd
REFERENCES,0.8953068592057761,"E.2
INTER-FAMILY COMPARISON"
REFERENCES,0.8989169675090253,"Here, we extend on our comparison of example rankings by presenting plots of Kendall Tau scores
normalized by intra-family scores in 3. For the sentiment setting, the ranges of intra-family Kendall
Tau coefﬁcients are smaller than the MRQA setting. Methods in the uncertainty family have especially
strong correlations with each other and much weaker with methods outside of the family. For H-
divergence based methods, intra-family correlations are not’t as strong as for the uncertainty family;"
REFERENCES,0.9025270758122743,"11https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/
kendell.htm"
REFERENCES,0.9061371841155235,Under review as a conference paper at ICLR 2022 CONF CONF ENTR ENTR ENER ENER BALD BALD
REFERENCES,0.9097472924187726,DAL-E* DAL-E
REFERENCES,0.9133574007220217,DAL-T* DAL-T kNN* kNN-C kNN-Q
REFERENCES,0.9169675090252708,kNN-QC
REFERENCES,0.9205776173285198,"CONF
CONF
ENTR
ENTR
ENER
ENER
BALD
BALD
DAL-E*"
REFERENCES,0.924187725631769,"DAL-E
DAL-T* DAL-T"
REFERENCES,0.927797833935018,"kNN*
kNN-C
kNN-Q
kNN-QC 1.0 0.5 0.0 0.5 1.0 1.5"
REFERENCES,0.9314079422382672,(a) MRQA CONF CONF ENTR ENTR ENER ENER BALD BALD
REFERENCES,0.9350180505415162,DAL-E* DAL-E
REFERENCES,0.9386281588447654,DAL-T* DAL-T kNN* kNN CONF CONF ENTR ENTR ENER ENER BALD BALD
REFERENCES,0.9422382671480144,DAL-E* DAL-E
REFERENCES,0.9458483754512635,DAL-T* DAL-T 6 5 4 3 2 1 0 1
REFERENCES,0.9494584837545126,(b) Sentiment
REFERENCES,0.9530685920577617,"Figure 3: Kendall Tau scores normalized by intra-family scores according to the family of the method
on the y-axis (with uncertainty-ascending and uncertainty-descending as distinct families). If the
cell’s corresponding Kendall Tau score is within the intra-family range, it’s value will be in [0, 1].
Below the range is negative, and above the range is greater than 1."
REFERENCES,0.9566787003610109,"in fact, the Kendall Taus between DAL-E/KNN and DAL-T/KNN appear to be slightly within the
H-divergence intra-family range."
REFERENCES,0.9602888086642599,"Furthermore, intra-family ranges are quite large for all families in the MRQA setting. For each
method, there is at least one other method from a different family with which it had a higher Kendall
Tau coefﬁcient than the least similar methods of its own family."
REFERENCES,0.9638989169675091,"F
RELATING DOMAIN DISTANCES TO PERFORMANCE"
REFERENCES,0.9675090252707581,"We investigated why certain methods work better than others. One hypothesis is that there exists a
relationship between between target-source domain distances and method performance. We estimated
the distance between two domains by computing the Wasserstein distance between random samples of
3k example embeddings from each domain. We experimented with two kinds of example embeddings:
1. A task agnostic embedding computed by the sentence transformer used in the KNN method, and 2.
A task speciﬁc embedding computed by a model trained with the source domain used in the DAL∗
method. Given that there are k −1 source domains for each target domain, we tried aggregating
domain distances over its mean, minimum, maximum, and variance to see if Wasserstein domain
distances could be indicative of relative performance across all methods."
REFERENCES,0.9711191335740073,"Figure 4, Figure 5, Figure 6, and Figure 7 each show, for a subset of methods, the relationship between
each domain distance aggregation and the ﬁnal performance gap between the best performing method.
Unfortunately, we found no consistent relationship for both MRQA and the sentiment classiﬁcation
tasks. We believe that this result arose either because our estimated domain distances were not reliable
measures of domain relevance, or because the aggregated domain distances are not independently
sufﬁcient to discern relative performance differences across methods."
REFERENCES,0.9747292418772563,Under review as a conference paper at ICLR 2022
REFERENCES,0.9783393501805054,"Figures 3-6: The average domain distance is calculated by ﬁnding the distance between 3k examples
from DT and the combined set made from choosing 3k examples from each domain in DS. Since the
Wasserstein metric is symmetric, this yields k points for comparison."
REFERENCES,0.9819494584837545,Figure 4: Average Wasserstein domain distance vs performance.
REFERENCES,0.9855595667870036,Figure 5: Minimum Wasserstein domain distance vs method performance.
REFERENCES,0.9891696750902527,Figure 6: Maximum Wasserstein domain distance vs method performance.
REFERENCES,0.9927797833935018,Under review as a conference paper at ICLR 2022
REFERENCES,0.9963898916967509,Figure 7: Wasserstein Domain distance variance vs performance.
