Section,Section Appearance Order,Paragraph
THE UNIVERSITY OF SYDNEY,0.0,"3The University of Sydney
tongliang.liu@sydney.edu.au bhanml@comp.hkbu.edu.hk"
ABSTRACT,0.0009293680297397769,ABSTRACT
ABSTRACT,0.0018587360594795538,"Recently Graph Injection Attack (GIA) emerges as a practical attack scenario on
Graph Neural Networks (GNNs), where the adversary can merely inject few ma-
licious nodes instead of modifying existing nodes or edges, i.e., Graph Modiﬁca-
tion Attack (GMA). Although GIA has achieved promising results, little is known
about why it is successful and whether there is any pitfall behind the success. To
understand the power of GIA, we compare it with GMA and ﬁnd that GIA can be
provably more harmful than GMA due to its relatively high ﬂexibility. However,
the high ﬂexibility will also lead to great damage to the homophily distribution
of the original graph, i.e., similarity among neighbors. Consequently, the threats
of GIA can be easily alleviated or even prevented by homophily-based defenses
designed to recover the original homophily. To mitigate the issue, we introduce
a novel constraint – homophily unnoticeability that enforces GIA to preserve the
homophily, and propose Harmonious Adversarial Objective (HAO) to instantiate
it. Extensive experiments verify that GIA with HAO can break homophily-based
defenses and outperform previous GIA attacks by a signiﬁcant margin. We believe
our methods can serve for a more reliable evaluation of the robustness of GNNs."
INTRODUCTION,0.0027881040892193307,"1
INTRODUCTION"
INTRODUCTION,0.0037174721189591076,"Graph Neural Networks (GNNs), as a generalization of deep learning models for graph structured
data, have gained great success in tasks involving relational information (Hamilton et al., 2017a;
Battaglia et al., 2018; Zhou et al., 2020; Wu et al., 2021; Kipf & Welling, 2017; Hamilton et al.,
2017b; Veliˇckovi´c et al., 2018; Xu et al., 2018; 2019b). Nevertheless, GNNs are shown to be in-
herently vulnerable to adversarial attacks (Sun et al., 2018; Jin et al., 2021), or small intentional
perturbations on the input (Szegedy et al., 2014). Previous studies show that moderate changes to
the existing topology or node features of the input graph, i.e., Graph Modiﬁcation Attacks (GMA),
can dramatically degenerate the performance of GNNs (Dai et al., 2018; Z¨ugner et al., 2018; Z¨ugner
& G¨unnemann, 2019; Xu et al., 2019a; Chang et al., 2020). Since in many real-world scenarios, it
is prohibitively expensive to modify the original graph, recently there is increasing attention paid
to Graph Injection Attack (GIA), where the adversary can merely inject few malicious nodes to
perform the attack (Wang et al., 2018; Sun et al., 2020; Wang et al., 2020; Zou et al., 2021)."
INTRODUCTION,0.004646840148698885,"Despite the promising empirical results, why GIA is booming and whether there is any pitfall behind
the success remain elusive. To bridge this gap, we investigate both the advantages and limitations
of GIA by comparing it with GMA in a uniﬁed setting (Sec. 2.2). Our theoretical results show that,
in this setting when there is no defense, GIA can be provably more harmful than GMA due to its
relatively high ﬂexibility. Such ﬂexibility enables GIA to map GMA perturbations into speciﬁc GIA
perturbations, and to further optimize the mapped perturbations to amplify the damage (Fig. 1a).
However, according to the principle of no free lunch, we further ﬁnd that the power of GIA is built
upon the severe damage to the homophily of the original graph. Homophily indicates the tendency of
nodes connecting to others with similar features or labels, which is important for the success of most
existing GNNs (McPherson et al., 2001; London & Getoor, 2014; Klicpera et al., 2019; Battaglia"
INTRODUCTION,0.0055762081784386614,Published as a conference paper at ICLR 2022
INTRODUCTION,0.006505576208178439,"0
50
100
150
200
250
GIA Peturbation Budgets 20 30 40 50 60 70 80 90"
INTRODUCTION,0.007434944237918215,Test Robustness
INTRODUCTION,0.008364312267657992,"0
250
500
750
1000
1250
GMA Perturbation Budgets"
INTRODUCTION,0.00929368029739777,"GMA
MLP
HAO
GIA"
INTRODUCTION,0.010223048327137546,(a) Attack without defense
INTRODUCTION,0.011152416356877323,"0
50
100
150
200
250
GIA Peturbation Budgets 20 30 40 50 60 70 80 90"
INTRODUCTION,0.012081784386617101,Test Robustness
INTRODUCTION,0.013011152416356878,"0
250
500
750
1000
1250
GMA Perturbation Budgets"
INTRODUCTION,0.013940520446096654,"GIA
GMA
MLP
HAO"
INTRODUCTION,0.01486988847583643,(b) Attack with defense =
INTRODUCTION,0.015799256505576207,Pruned
INTRODUCTION,0.016728624535315983,"Normal
Injected"
INTRODUCTION,0.017657992565055763,(c) Illustration of GIA at node u
INTRODUCTION,0.01858736059479554,"Figure 1: The lower test robustness indicates better attack performance. (a) Without defenses: GIA
performs consistently better than GMA; (b) With defenses: GIA without HAO performs consistently
worse than GMA, while GIA with HAO performs the best; (c) Homophily indicates the tendency of
similar nodes connecting with each other (blue & green nodes). The malicious (red) nodes and edges
injected by GIA without HAO will greatly break the homophily hence can be easily identiﬁed and
pruned by homophily defenders. GIA with HAO is aware of preserving homophily that attacks the
targets by injecting unnoticeable (more similar) but still adversarial (dark green) nodes and edges,
which will not be easily pruned hence effectively causing the damage."
INTRODUCTION,0.019516728624535316,"et al., 2018; Hou et al., 2020; Zhu et al., 2020; Yang et al., 2021b). The severe damage to homophily
will disable the effectiveness of GIA to evaluate robustness because non-robust models can easily
mitigate or even prevent GIA merely through exploiting the property of homophily damage."
INTRODUCTION,0.020446096654275093,"Speciﬁcally, having observed the destruction of homophily, it is straightforward to devise a defense
mechanism aiming to recover the homophily, which we term homophily defenders. Homophily de-
fenders are shown to have strong robustness against GIA attacks. Theoretically, they can effectively
reduce the harm caused by GIA to be lower than GMA. Empirically, simple implementations of
homophily defenders with edge pruning (Zhang & Zitnik, 2020) can deteriorate even the state-of-
the-art GIA attacks (Zou et al., 2021) (Fig. 1b). Therefore, overlooking the damage to homophily
will make GIA powerless and further limit its applications for evaluating the robustness of GNNs."
INTRODUCTION,0.02137546468401487,"To enable the effectiveness of GIA in evaluating various robust GNNs, it is necessary to be aware
of preserving the homophily when developing GIA. To this end, we introduce a novel constraint –
homophily unnoticeability that enforces GIA to retain the homophily of the original graph, which
can serve as a supplementary for the unnoticeability constraints in graph adversarial learning. To
instantiate the homophily unnoticeability, we propose Harmonious Adversarial Objective (HAO)
for GIA (Fig. 1c). Speciﬁcally, HAO introduces a novel differentiable realization of homophily
constraint by regularizing the homophily distribution shift during the attack. In this way, adversaries
will not be easily identiﬁed by homophily defenders while still performing effective attacks (Fig. 1b).
Extensive experiments with 38 defense models on 6 benchmarks demonstrate that GIA with HAO
can break homophily defenders and signiﬁcantly outperform all previous works across all settings,
including both non-target attack and targeted attack1. Our contributions are summarized as follows:"
INTRODUCTION,0.022304832713754646,"• We provide a formal comparison between GIA and GMA in a uniﬁed setting and ﬁnd that
GIA can be provably more harmful than GMA due to its high ﬂexibility (Theorem 1)."
INTRODUCTION,0.023234200743494422,"• However, the ﬂexibility of GIA will also cause severe damage to the homophily distribution
which makes GIA easily defendable by homophily defenders (Theorem 2)."
INTRODUCTION,0.024163568773234202,"• To mitigate the issue, we introduce the concept of homophily unnoticeability and a novel
objective HAO to conduct homophily unnoticeable attacks (Theorem 3)."
PRELIMINARIES,0.02509293680297398,"2
PRELIMINARIES"
GRAPH NEURAL NETWORKS,0.026022304832713755,"2.1
GRAPH NEURAL NETWORKS"
GRAPH NEURAL NETWORKS,0.02695167286245353,"Consider a graph G = (A, X) with node set V = {v1, v2, ..., vn} and edge set E = {e1, e2, ..., em},
where A ∈{0, 1}n×n is the adjacency matrix and X ∈Rn×d is the node feature matrix. We are"
GRAPH NEURAL NETWORKS,0.027881040892193308,1Code is available in https://github.com/LFhase/GIA-HAO.
GRAPH NEURAL NETWORKS,0.028810408921933085,Published as a conference paper at ICLR 2022
GRAPH NEURAL NETWORKS,0.02973977695167286,"interested in the semi-supervised node classiﬁcation task (Jin et al., 2021). That is, given the set of
labels Y ∈{0, 1, .., C −1}n from C classes, we can train a graph neural network fθ parameterized
by θ on the training (sub)graph Gtrain by minimizing a classiﬁcation loss Ltrain (e.g., cross-entropy).
Then the trained fθ can predict the labels of nodes in test graph Gtest. A GNN typically follows a
neighbor aggregation scheme to recursively update the node representations as:"
GRAPH NEURAL NETWORKS,0.03066914498141264,"H(k)
u
= σ(Wk · ρ({H(k−1)
v
}|v ∈N(u) ∪{u})),
(1)"
GRAPH NEURAL NETWORKS,0.031598513011152414,"where N(u) is the set of neighbors of node u, H(0)
u
= Xu, ∀u ∈V , H(k)
u
is the hidden represen-
tation of node u after the k-th aggregation, σ(·) is an activation function, e.g., ReLU, and ρ(·) is an
aggregation function over neighbors, e.g., MEAN or SUM."
GRAPH NEURAL NETWORKS,0.032527881040892194,"2.2
GRAPH ADVERSARIAL ATTACK2"
GRAPH NEURAL NETWORKS,0.03345724907063197,"The goal of graph adversarial attack is to fool a GNN model, fθ∗, trained on a graph G = (A, X)
by constructing a graph G′ = (A′, X′) with limited budgets ∥G′ −G∥≤△. Given a set of victim
nodes Vc ⊆V , the graph adversarial attack can be generically formulated as:"
GRAPH NEURAL NETWORKS,0.03438661710037175,"min Latk(fθ∗(G′)), s.t. ∥G′ −G∥≤△,
(2)"
GRAPH NEURAL NETWORKS,0.03531598513011153,"where θ∗= arg minθ Ltrain(fθ(Gtrain)) and Latk is usually taken as −Ltrain. Following previous
works (Z¨ugner et al., 2018; Zou et al., 2021), Graph adversarial attacks can be characterized into
graph modiﬁcation attacks and graph injection attacks by their perturbation constraints."
GRAPH NEURAL NETWORKS,0.0362453531598513,"Graph Modiﬁcation Attack (GMA). GMA generates G′ by modifying the graph structure A and
the node features X of the original graph G. Typically the constraints in GMA are to limit the
number of perturbations on A and X, denoted by △A and △X, respectively, as:"
GRAPH NEURAL NETWORKS,0.03717472118959108,"△A + △X ≤△∈Z, ∥A′ −A∥0 ≤△A ∈Z, ∥X′ −X∥∞≤ϵ ∈R,
(3)"
GRAPH NEURAL NETWORKS,0.03810408921933085,"where the perturbation on X is bounded by ϵ via L-p norm, since we are using continuous features."
GRAPH NEURAL NETWORKS,0.03903345724907063,"Graph Injection Attack (GIA). Differently, GIA generates G′ by injecting a set of malicious nodes"
GRAPH NEURAL NETWORKS,0.039962825278810406,"Vatk as X′ =

X
Xatk"
GRAPH NEURAL NETWORKS,0.040892193308550186,"
, A′ =
 A
Aatk
AT
atk
Oatk"
GRAPH NEURAL NETWORKS,0.041821561338289966,"
, where Xatk is the features of the injected nodes, Oatk is"
GRAPH NEURAL NETWORKS,0.04275092936802974,"the adjacency matrix among injected nodes, and Aatk is the adjacency matrix between the injected
nodes and the original nodes. Let du denote the degree of node u, the constraints in GIA are:"
GRAPH NEURAL NETWORKS,0.04368029739776952,"|Vatk| ≤△∈Z, 1 ≤du ≤b ∈Z, Xu ∈DX ⊆Rd, ∀u ∈Vatk,
(4)"
GRAPH NEURAL NETWORKS,0.04460966542750929,"where the number and degrees of the injected nodes are limited, DX = {C ∈Rd, min(X)·1 ≤C ≤
max(X)·1} where min(X) and max(X) are the minimum and maximum entries in X respectively."
GRAPH NEURAL NETWORKS,0.04553903345724907,"Threat Model. We adopt a uniﬁed setting, i.e., evasion, inductive and black-box, which is also
used by Graph Robustness Benchmark (Zheng et al., 2021). Evasion: The attack only happens at
test time, i.e., Gtest, rather than attacking Gtrain. Inductive: Test nodes are invisible during training.
Black-box: The adversary can not access the architecture or the parameters of the target model."
POWER AND PITFALLS OF GRAPH INJECTION ATTACK,0.046468401486988845,"3
POWER AND PITFALLS OF GRAPH INJECTION ATTACK"
POWER AND PITFALLS OF GRAPH INJECTION ATTACK,0.047397769516728624,"Based on the setting above, we investigate both the advantages and limitations of GIA by comparing
it with GMA. While we ﬁnd GIA is more harmful than GMA when there is no defense (Theorem 1),
we also ﬁnd pitfalls in GIA that can make it easily defendable (Theorem 2)."
POWER OF GRAPH INJECTION ATTACK,0.048327137546468404,"3.1
POWER OF GRAPH INJECTION ATTACK"
POWER OF GRAPH INJECTION ATTACK,0.04925650557620818,"Following previous works (Z¨ugner et al., 2018), we use a linearized GNN, i.e., H(k) = ˆAkXΘ, to
track the changes brought by attacks. Firstly we will elaborate the threats of an adversary as follows.
Deﬁnition 3.1 (Threats). Consider an adversary A, given a perturbation budget △, the threat of A
to a GNN fθ is deﬁned as min∥G′−G∥≤△Latk(fθ(G′)), i.e., the optimal objective value of Eq. 2."
POWER OF GRAPH INJECTION ATTACK,0.05018587360594796,2We leave more details and reasons about the setting used in this work in Appendix B.
POWER OF GRAPH INJECTION ATTACK,0.05111524163568773,Published as a conference paper at ICLR 2022 v 𝑀2 v
POWER OF GRAPH INJECTION ATTACK,0.05204460966542751,(a) Illustration of M2 mapping
POWER OF GRAPH INJECTION ATTACK,0.05297397769516728,"0
250
500
750
1000
1250
GMA Perturbation Budgets 50 55 60 65 70 75 80 85 90 95"
POWER OF GRAPH INJECTION ATTACK,0.05390334572490706,Test Robustness
POWER OF GRAPH INJECTION ATTACK,0.05483271375464684,"GMA
M2
MLP"
POWER OF GRAPH INJECTION ATTACK,0.055762081784386616,(b) GMA v.s. GIA with M2
POWER OF GRAPH INJECTION ATTACK,0.056691449814126396,"−0.2
0.0
0.2
0.4
0.6
0.8
1.0
Homophily 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5"
POWER OF GRAPH INJECTION ATTACK,0.05762081784386617,Density
POWER OF GRAPH INJECTION ATTACK,0.05855018587360595,"orig
gia
gma"
POWER OF GRAPH INJECTION ATTACK,0.05947955390334572,(c) Homophily changes
POWER OF GRAPH INJECTION ATTACK,0.0604089219330855,Figure 2: Power and pitfalls of Graph Injection Attack
POWER OF GRAPH INJECTION ATTACK,0.06133828996282528,"With Deﬁnition 3.1, we can quantitatively compare the threats of different adversaries.
Theorem 1. Given moderate perturbation budgets △GIA for GIA and △GMA for GMA, that is, let
△GIA ≤△GMA ≪|V | ≤|E|, for a ﬁxed linearized GNN fθ trained on G, assume that G has no iso-
lated nodes, and both GIA and GMA follow the optimal strategy, then, ∀△GMA ≥0, ∃△GIA ≤△GMA,
Latk(fθ(G′
GIA)) −Latk(fθ(G′
GMA)) ≤0,
where G′
GIA and G′
GMA are the perturbed graphs generated by GIA and GMA, respectively."
POWER OF GRAPH INJECTION ATTACK,0.062267657992565055,"We prove Theorem 1 in Appendix E.1. Theorem 1 implies that GIA can cause more damage than
GMA with equal or fewer budgets, which is also veriﬁed empirically as shown in Fig. 1a."
POWER OF GRAPH INJECTION ATTACK,0.06319702602230483,"Intuitively, the power of GIA mainly comes from its relatively high ﬂexibility in perturbation gen-
eration. Such ﬂexibility enables us to ﬁnd a mapping that can map any GMA perturbations to GIA
perturbations, leading the same inﬂuences to the predictions of fθ. We will give an example below.
Deﬁnition 3.2 (Plural Mapping M2). M2 maps a perturbed graph G′
GMA generated by GMA with
only edge addition perturbations,3 to a GIA perturbed graph G′
GIA = M2(G′
GMA), such that:
fθ(G′
GIA)u = fθ(G′
GMA)u, ∀u ∈V."
POWER OF GRAPH INJECTION ATTACK,0.06412639405204461,"As illustrated in Fig. 2a, the procedure of M2 is, for each edge (u, v) added by GMA to attack node
u, M2 can inject a new node w to connect u and v, and change Xw to make the same effects to
the prediction on u. Then GIA can be further optimized to bring more damage to node u. We also
empirically verify the above procedure in Fig. 2b. Details about the comparison are in Appendix C."
PITFALLS IN GRAPH INJECTION ATTACK,0.06505576208178439,"3.2
PITFALLS IN GRAPH INJECTION ATTACK"
PITFALLS IN GRAPH INJECTION ATTACK,0.06598513011152417,"Through M2, we show that the ﬂexibility in GIA can make it more harmful than GMA when there
is no defense, however, we also ﬁnd a side-effect raised in the optimization trajectory of Xw from
the above example. Assume GIA uses PGD (Madry et al., 2018) to optimize Xw iteratively, we ﬁnd:"
PITFALLS IN GRAPH INJECTION ATTACK,0.06691449814126393,"sim(Xu, Xw)(t+1) ≤sim(Xu, Xw)(t),
(5)"
PITFALLS IN GRAPH INJECTION ATTACK,0.06784386617100371,"where t is the number of optimization steps and sim(Xu, Xv) =
Xu·Xv
∥Xu∥2∥Xv∥2 . We prove the state-
ment in Appendix E.4. It implies that, under the mapping M2, the similarity between injected nodes
and targets continues to decrease as the optimization processes, and ﬁnally becomes lower than that
in GMA. We ﬁnd this is closely related to the loss of homophily of the target nodes."
PITFALLS IN GRAPH INJECTION ATTACK,0.0687732342007435,"Before that, we will elaborate the deﬁnition of homophily in graph adversarial setting. Different
from typical deﬁnitions that rely on the label information (McPherson et al., 2001; London & Getoor,
2014; Pei et al., 2020; Zhu et al., 2020), as the adversary does not have the access to all labels, we
provide another instantiation of homophily based on node feature similarity as follows:
Deﬁnition 3.3 (Node-Centric Homophily). The homophily of a node u can be deﬁned with the
similarity between the features of node u and the aggregated features of its neighbors:"
PITFALLS IN GRAPH INJECTION ATTACK,0.06970260223048327,"hu = sim(ru, Xu), ru =
X"
PITFALLS IN GRAPH INJECTION ATTACK,0.07063197026022305,j∈N(u)
P,0.07156133828996282,"1
p"
P,0.0724907063197026,"dj
√du
Xj,
(6)"
P,0.07342007434944238,"where du is the degree of node u and sim(·) is a similarity metric, e.g., cosine similarity."
P,0.07434944237918216,"3We focus on edge addition in later discussions since Wu et al. (2019) observed that it produces the most
harm in GMA. Discussions about the other GMA operations can be found in Appendix E.2."
P,0.07527881040892194,Published as a conference paper at ICLR 2022
P,0.0762081784386617,"We also deﬁne edge-centric homophily while we will focus primarily on node-centric homophily.
Details and reasons are in Appendix D.1. With Deﬁnition 3.3, combining Eq. 5, we have:"
P,0.07713754646840149,"hGIA
u
≤hGMA
u
,"
P,0.07806691449814127,"where hGIA
u
and hGMA
u
denote the homophily of node u after GIA and GMA attack, respectively.
It implies that GIA will cause more damage to the homophily of the original graph than GMA.
To verify the discovery for more complex cases, we plot the homophily distributions in Fig. 2c.
The blue part denotes the original homophily distribution. Notably, there is an outstanding out-of-
distribution (orange) part caused by GIA, compared to the relatively minor (canny) changes caused
by GMA. The same phenomenon also appears in other datasets that can be found in Appendix D.2."
P,0.07899628252788105,"Having observed the huge homophily damage led by GIA, it is straightforward to devise a defense
mechanism aiming to recover the original homophily, which we call homophily defenders. We
theoretically elaborate such defenses in the form of edge pruning4, adapted from Eq. 1:"
P,0.07992565055762081,"H(k)
u
= σ(Wk · ρ({1con(u, v) · H(k−1)
v
}| v ∈N(u) ∪{u}).
(7)"
P,0.08085501858736059,"We ﬁnd that simply pruning the malicious edges identiﬁed by a proper condition can empower
homophily defenders with strong theoretical robustness against GIA attacks."
P,0.08178438661710037,"Theorem 2. Given conditions in Theorem 1, consider a GIA attack, which (i) is mapped by M2
(Def. 3.2) from a GMA attack that only performs edge addition perturbations, and (ii) uses a lin-
earized GNN trained with at least one node from each class in G as the surrogate model, and (iii)
optimizes the malicious node features with PGD. Assume that G has no isolated node, and has node
features as Xu =
C
C−1eYu −
1
C−11 ∈Rd, where Yu is the label of node u and eYu ∈Rd is a one-hot
vector with the Yu-th entry being 1 and others being 0. Let the minimum similarity for any pair of
nodes connected in G be sG = min(u,v)∈E sim(Xu, Xv) with sim(Xu, Xv) =
Xu·Xv
∥Xu∥2∥Xv∥2 . For a
homophily defender gθ that prunes edges (u, v) if sim(Xu, Xv) ≤sG, we have:"
P,0.08271375464684015,"Latk(gθ(M2(G′
GMA))) −Latk(gθ(G′
GMA)) ≥0."
P,0.08364312267657993,"We prove Theorem 2 in Appendix E.3. It implies that, by specifying a mild pruning condition, the
homophily defender can effectively reduce the harm caused by GIA to be lower than that of GMA."
P,0.0845724907063197,"Considering a more concrete example with M2, Xw is generated to make Latk(fθ(M2(G′
GMA))) =
Latk(fθ(G′
GMA)) on node u at ﬁrst. Then, due to the ﬂexibility in GIA, Xw can be optimized to some
X′
w that greatly destroys the homophily of node u, i.e., having a negative cosine similarity score
with u. Thus, for a graph with relatively high homophily, i.e., sG ≥0, a mild pruning condition
such as 1sim(u,v)≤0(u, v) = 0 could prune all the malicious edges generated by GIA while possibly
keeping some of those generated by GMA, which makes GIA less threatful than GMA."
P,0.08550185873605948,"In the literature, we ﬁnd that GNNGuard (Zhang & Zitnik, 2020) serves well for an implementation
of homophily defenders as Eq. 7. With GNNGuard, we verify the strong empirical robustness of
homophily defenders against GIA. As Fig. 1b depicts, when with homophily defenders, GIA can
only cause little-to-no damage, while GMA can still effectively perturb the predictions of the target
model on some nodes. To fully demonstrate the power of homophily defenders, we also prove its
certiﬁed robustness for a concrete GIA case in Appendix E.6."
HOMOPHILY UNNOTICEABLE GRAPH INJECTION ATTACK,0.08643122676579926,"4
HOMOPHILY UNNOTICEABLE GRAPH INJECTION ATTACK"
HARMONIOUS ADVERSARIAL OBJECTIVE,0.08736059479553904,"4.1
HARMONIOUS ADVERSARIAL OBJECTIVE"
HARMONIOUS ADVERSARIAL OBJECTIVE,0.08828996282527882,"As shown in Sec. 3, the ﬂexibility of GIA makes it powerful while dramatically hinders its perfor-
mance when combating against homophily defenders, because of the great damage to the homophily
distribution brought by GIA. This observation motivates us to introduce the concept of homophily
unnoticeability that enforces GIA to preserve the original homophily distribution during the attack."
HARMONIOUS ADVERSARIAL OBJECTIVE,0.08921933085501858,"4Actually, homophily defenders can have many implementations other than pruning edges as given in Ap-
pendix F, while we will focus on the design above in our discussion."
HARMONIOUS ADVERSARIAL OBJECTIVE,0.09014869888475836,Published as a conference paper at ICLR 2022
HARMONIOUS ADVERSARIAL OBJECTIVE,0.09107806691449814,"Deﬁnition 4.1 (Homophily Unnoticeability). Let the node-centric homophily distribution for a
graph G be HG. Given the upper bound for the allowed homophily distribution shift △H ≥0,
an attack A is homophily unnoticeable if:"
HARMONIOUS ADVERSARIAL OBJECTIVE,0.09200743494423792,"m(HG, HG′) ≤△H,"
HARMONIOUS ADVERSARIAL OBJECTIVE,0.09293680297397769,"where G′ is the perturbed graph generated by A, and m(·) is a distribution distance measure."
HARMONIOUS ADVERSARIAL OBJECTIVE,0.09386617100371747,"Intuitively, homophily unnoticeability can be a supplementary for the unnoticeability in graph adver-
sarial attack that requires a GIA adversary to consider how likely the new connections between the
malicious nodes and target nodes will appear naturally. Otherwise, i.e., unnoticeability is broken,
the malicious nodes and edges can be easily detected and removed by database administrators or ho-
mophily defenders. However, homophily unnoticeability can not be trivially implemented as a rigid
constraint and be inspected incrementally like that for degree distribution (Z¨ugner et al., 2018). For
example, a trivial implementation such as clipping all connections that do not satisfy the constraint
(Def. 4.1) will trivially clip all the injected edges due to the unconstrained optimization in GIA."
HARMONIOUS ADVERSARIAL OBJECTIVE,0.09479553903345725,"Considering the strong robustness of homophily defenders, we argue that they can directly serve as
external examiners for homophily unnoticeability check. Satisfying the homophily constraint can
be approximately seen as bypassing the homophily defenders. Obviously, GIA with constraints as
Eq. 14 can not guarantee homophily unnoticeability, since it will only optimize towards maximizing
the damage by minimizing the homophily of the target nodes. Hence, we propose a novel realization
of the homophily constraint for GIA that enforces it to meet the homophily unnoticeability softly."
HARMONIOUS ADVERSARIAL OBJECTIVE,0.09572490706319703,"Deﬁnition 4.2 (Harmonious Adversarial Objective (HAO)). Observing the homophily deﬁnition in
Eq. 6 is differentiable with respect to X, we can integrate it into the objective of Eq. 2 as:5"
HARMONIOUS ADVERSARIAL OBJECTIVE,0.09665427509293681,"min
∥G′−G∥≤△Lh
atk(fθ∗(G′)) = Latk(fθ∗(G′)) −λC(G, G′),
(8)"
HARMONIOUS ADVERSARIAL OBJECTIVE,0.09758364312267657,"where C(G, G′) is a regularization term based on homophily and λ ≥0 is the corresponding weight."
HARMONIOUS ADVERSARIAL OBJECTIVE,0.09851301115241635,One possible implementation is to maximize the homophily for each injected node as:
HARMONIOUS ADVERSARIAL OBJECTIVE,0.09944237918215613,"C(G, G′) =
1
|Vatk| X"
HARMONIOUS ADVERSARIAL OBJECTIVE,0.10037174721189591,"u∈Vatk
hu.
(9)"
HARMONIOUS ADVERSARIAL OBJECTIVE,0.10130111524163568,"HAO seizes the possibility of retaining homophily unnoticeability, while still performing effective
attacks. Hence, given the homophily distribution distance measure m(·) in Def. 4.1, we can infer:"
HARMONIOUS ADVERSARIAL OBJECTIVE,0.10223048327137546,"Theorem 3. Given conditions in Theorem 2, we have m(HG, HG′
HAO)≤m(HG, HG′
GIA), hence:"
HARMONIOUS ADVERSARIAL OBJECTIVE,0.10315985130111524,"Latk(gθ(G′
HAO)) −Latk(gθ(G′
GIA)) ≤0,"
HARMONIOUS ADVERSARIAL OBJECTIVE,0.10408921933085502,"where G′
HAO is generated by GIA with HAO, and G′
GIA is generated by GIA without HAO."
HARMONIOUS ADVERSARIAL OBJECTIVE,0.1050185873605948,"We prove Theorem 3 in Appendix E.5. Intuitively, since GIA with HAO can reduce the damage to
homophily, it is more likely to bypass the homophily defenders, thus being more threatful than GIA
without HAO. We also empirically verify Theorem 3 for more complex cases in the experiments."
ADAPTIVE INJECTION STRATEGIES,0.10594795539033457,"4.2
ADAPTIVE INJECTION STRATEGIES"
ADAPTIVE INJECTION STRATEGIES,0.10687732342007435,"GIA is generically composed of two procedures, i.e., node injection and feature update, to solve for
G′ = (A′, X′), where node injection leverages either the gradient information or heuristics to solve
for A′, and feature update usually uses PGD (Madry et al., 2018) to solve for X′. Most previous
works separately optimize A′ and X′ in a greedy manner, which implicitly assumes that the other
will be optimized to maximize the harm. However, HAO does not follow the assumption but stops
the optimization when the homophily is overly broken. Thus, a more suitable injection strategy for
HAO shall be aware of retaining the original homophily. To this end, we propose to optimize A′
and X′ alternatively and introduce three adaptive injection strategies to coordinate with HAO."
ADAPTIVE INJECTION STRATEGIES,0.10780669144981413,5Note that we only use HAO to solve for G′ while still using the original objective to evaluate the threats.
ADAPTIVE INJECTION STRATEGIES,0.1087360594795539,Published as a conference paper at ICLR 2022
ADAPTIVE INJECTION STRATEGIES,0.10966542750929369,"Gradient-Driven Injection. We propose a novel bi-level formulation of HAO to perform the alter-
native optimization using gradients, where we separate the optimization of G′ =(A′, X′) as:"
ADAPTIVE INJECTION STRATEGIES,0.11059479553903345,"X′∗= arg min
X′∈Φ(X′)
Latk(fθ∗(A′∗, X′)) −λAC(G′, G),"
ADAPTIVE INJECTION STRATEGIES,0.11152416356877323,"s.t. A′∗= arg min
A′∈Φ(A′)
Latk(fθ∗(A′, X′)) −λXC(G′, G),
(10)"
ADAPTIVE INJECTION STRATEGIES,0.11245353159851301,"where Φ(A′) and Φ(X′) are the corresponding feasible regions for A′ and X′ induced by the original
constraints. Here we use different homophily constraint weights λA and λX for the optimizations
of A′ and X′, since A′ is discrete while X′ is continuous. We can either adopt Meta-gradients like
Metattack (Z¨ugner & G¨unnemann, 2019) (MetaGIA) or directly optimize edge weights to solve for
A′ (AGIA). The detailed induction of meta-gradients and algorithms are given in Appendix G.1."
ADAPTIVE INJECTION STRATEGIES,0.11338289962825279,"Heuristic-Driven Injection. As the state-of-the-art GIA methods are leveraging heuristics to ﬁnd
A′, based on TDGIA (Zou et al., 2021), we also propose a variant (ATDGIA) using heuristics as:"
ADAPTIVE INJECTION STRATEGIES,0.11431226765799256,"su = ((1 −pu)1(arg max (p) = y′
u))( 0.9
√bdu
+ 0.1"
ADAPTIVE INJECTION STRATEGIES,0.11524163568773234,"du
),
(11)"
ADAPTIVE INJECTION STRATEGIES,0.11617100371747212,where su indicates the vulnerability of node u and 1(·) is to early stop destroying homophily.
ADAPTIVE INJECTION STRATEGIES,0.1171003717472119,"Sequential Injection for large graphs. Since gradient methods require huge computation overhead,
we propose a novel divide-and-conquer strategy (SeqGIA) to iteratively select some of the most
vulnerable targets with Eq. 11 to attack. Detailed algorithm is given in Appendix G.3."
EXPERIMENTS,0.11802973977695168,"5
EXPERIMENTS"
SETUP & BASELINES,0.11895910780669144,"5.1
SETUP & BASELINES"
SETUP & BASELINES,0.11988847583643122,"Datasets. We comprehensively evaluate our methods with 38 defense models on 6 datasets. We se-
lect two classic citation networks Cora and Citeseer (Yang et al., 2016; Giles et al., 1998) reﬁned by
GRB (Zheng et al., 2021). We also use Aminer and Reddit (Tang et al., 2008; Hamilton et al., 2017b;
Zeng et al., 2020) from GRB, Arxiv from OGB (Hu et al., 2020), and a co-purchasing network Com-
puters (McAuley et al., 2015) to cover more domains and scales. Details are in Appendix H.1."
SETUP & BASELINES,0.120817843866171,"Comparing with previous attack methods. We incorporate HAO into several existing GIA meth-
ods as well as our proposed injection strategies to verify its effectiveness and versatility. First of all,
we select PGD (Madry et al., 2018) as it is one of the most widely used adversarial attacks. We also
select TDGIA (Zou et al., 2021) which is the state-of-the-art GIA method. We adopt the implemen-
tations in GRB (Zheng et al., 2021) for the above two methods. We exclude FGSM (Goodfellow
et al., 2015) and AFGSM (Wang et al., 2020), since PGD is better at dealing with non-linear models
than FGSM (Madry et al., 2018), and AFGSM performs comparably with FGSM but is worse than
TDGIA as demonstrated by Zou et al. (2021). For GMA methods, we adopt Metattack (Z¨ugner
& G¨unnemann, 2019) as one of the bi-level implementations. We exclude Nettack (Z¨ugner et al.,
2018) as it is hard to perform incremental updates with GCN (the surrogate model used in our ex-
periments) and leave reinforcement learning methods such as RL-S2V (Dai et al., 2018) and NIPA
(Sun et al., 2020) for future work. More details are given in Appendix H.2."
SETUP & BASELINES,0.12174721189591078,"Categories and complexity analysis of attack methods. We provide categories and complexity
analysis of all attack methods used in our experiments in Table 7, Appendix H.3."
SETUP & BASELINES,0.12267657992565056,"Competing with different defenses. We select both popular GNNs and robust GNNs as the defense
models. For popular GNNs, we select the three most frequently used baselines, i.e., GCN (Kipf
& Welling, 2017), GraphSage (Hamilton et al., 2017b), and GAT (Veliˇckovi´c et al., 2018). For
robust GNNs, we select GCNGuard (Zhang & Zitnik, 2020) for graph puriﬁcation approach, and
RobustGCN (Zhu et al., 2019) for stabilizing hidden representation approach, as representative ones
following the surveys (Sun et al., 2018; Jin et al., 2021). Notably, the author-released GCNGuard
implementation requires O(n2) complexity, which is hard to scale up. To make the comparison fair,
following the principle of homophily defenders, we implement two efﬁcient robust alternatives, i.e.,
Efﬁcient GCNGuard (EGuard) and Robust Graph Attention Network (RGAT). More details are
given in Appendix F.2. Besides, we exclude the robust GNNs learning in a transductive manner like
ProGNN (Jin et al., 2020) that can not be adapted in our setting."
SETUP & BASELINES,0.12360594795539033,Published as a conference paper at ICLR 2022
SETUP & BASELINES,0.12453531598513011,Table 1: Performance of non-targeted attacks against different models
SETUP & BASELINES,0.12546468401486988,"Cora (↓)
Citeseer(↓)
Computers(↓)
Arxiv(↓)"
SETUP & BASELINES,0.12639405204460966,"HAO
Homo
Robust
Combo
Homo
Robust
Combo
Homo
Robust
Combo
Homo
Robust
Combo"
SETUP & BASELINES,0.12732342007434944,"Clean
85.74
86.00
87.29
74.85
75.46
75.87
93.17
93.17
93.32
70.77
71.27
71.40"
SETUP & BASELINES,0.12825278810408922,"PGD
83.08
83.08
85.74
74.70
74.70
75.19
84.91
84.91
91.41
68.18
68.18
71.11
PGD
✓
52.60
62.60
77.99
69.05
69.05
73.04
79.33
79.33
87.83
55.38
62.89
68.68"
SETUP & BASELINES,0.129182156133829,"MetaGIA†
83.61
83.61
85.86
74.70
74.70
75.15
84.91
84.91
91.41
68.47
68.47
71.09
MetaGIA†
✓
49.25
69.83
76.80
68.04
68.04
71.25
78.96
78.96
90.25
57.05
63.30
69.97
AGIA†
83.44
83.44
85.78
74.72
74.72
75.29
85.21
85.21
91.40
68.07
68.07
71.01
AGIA†
✓
47.24
61.59
75.25
70.24
70.24
71.80
75.14
75.14
86.02
59.32
65.62
69.92"
SETUP & BASELINES,0.13011152416356878,"TDGIA
83.44
83.44
85.72
74.76
74.76
75.26
88.32
88.32
91.40
64.49
64.49
70.97
TDGIA
✓
56.95
73.38
79.45
60.91
60.91
72.51
74.77
74.77
90.42
49.36
60.72
63.57
ATDGIA
83.07
83.07
85.39
74.72
74.72
75.12
86.03
86.03
91.41
66.95
66.95
71.02
ATDGIA
✓
42.18
70.30
76.87
61.08
61.08
71.22
80.86
80.86
84.60
45.59
63.30
64.31"
SETUP & BASELINES,0.13104089219330856,"MLP
61.75
65.55
84.14
52.49"
SETUP & BASELINES,0.13197026022304834,↓The lower number indicates better attack performance. †Runs with SeqGIA framework on Computers and Arxiv.
SETUP & BASELINES,0.13289962825278812,Table 2: Performance of targeted attacks against different models
SETUP & BASELINES,0.13382899628252787,"Computers(↓)
Arxiv(↓)
Aminer(↓)
Reddit(↓)"
SETUP & BASELINES,0.13475836431226765,"HAO
Homo
Robust
Combo
Homo
Robust
Combo
Homo
Robust
Combo
Homo
Robust
Combo"
SETUP & BASELINES,0.13568773234200743,"Clean
92.68
92.68
92.83
69.41
71.59
72.09
62.78
66.71
66.97
94.05
97.15
97.13"
SETUP & BASELINES,0.1366171003717472,"PGD
88.13
88.13
91.56
69.19
69.19
71.31
53.16
53.16
56.31
92.44
92.44
93.03
PGD
✓
71.78
71.78
85.81
36.06
37.22
69.38
34.62
34.62
39.47
56.44
86.12
84.94"
SETUP & BASELINES,0.137546468401487,"MetaGIA†
87.67
87.67
91.56
69.28
69.28
71.22
48.97
48.97
52.35
92.40
92.40
93.97
MetaGIA†
✓
70.21
71.61
85.83
38.44
38.44
48.06
41.12
41.12
45.16
46.75
90.06
90.78
AGIA†
87.57
87.57
91.58
66.19
66.19
70.06
50.50
50.50
53.69
91.62
91.62
93.66
AGIA†
✓
69.96
71.58
85.72
38.84
38.84
68.97
35.94
35.94
42.66
80.69
88.84
90.44"
SETUP & BASELINES,0.13847583643122677,"TDGIA
87.21
87.21
91.56
63.66
63.66
71.06
51.34
51.34
54.82
92.19
92.19
93.62
TDGIA
✓
71.39
71.62
77.15
42.56
42.56
42.53
25.78
25.78
29.94
78.16
85.06
88.66
ATDGIA
87.85
87.85
91.56
66.12
66.12
71.16
50.87
50.87
53.68
91.25
91.25
93.03
ATDGIA
✓
72.00
72.53
78.35
38.28
40.81
39.47
22.50
22.50
28.91
64.09
89.06
88.91"
SETUP & BASELINES,0.13940520446096655,"MLP
84.11
52.49
32.80
70.69"
SETUP & BASELINES,0.14033457249070633,↓The lower number indicates better attack performance. †Runs with SeqGIA framework.
SETUP & BASELINES,0.1412639405204461,"Competing with extreme robust defenses. To make the evaluation for attacks more reliable, we
also adopt two widely used robust tricks Layer Normalization (LN) (Ba et al., 2016) and an efﬁ-
cient adversarial training (Goodfellow et al., 2015; Madry et al., 2018) method FLAG (Kong et al.,
2020). Here, as FLAG can effectively enhance the robustness, we exclude other adversarial training
methods for efﬁciency consideration. More details are given in Appendix H.4."
SETUP & BASELINES,0.1421933085501859,"Evaluation protocol. We use a 3-layer GCN as the surrogate model to generate perturbed graphs
with various GIA attacks, and report the mean accuracy of defenses from multiple runs. Details are
in Appendix H.5. For in-detail analysis of attack performance, we categorize all defenses into three
folds by their robustness: Vanilla, Robust, and Extreme Robust (Combo) (Table 8). To examine
how much an attack satisﬁes the homophily unnoticeability and its upper limits, we report maximum
test accuracy of both homophily defenders (Homo) and defenses from the last two categories."
EMPIRICAL PERFORMANCE,0.14312267657992564,"5.2
EMPIRICAL PERFORMANCE"
EMPIRICAL PERFORMANCE,0.14405204460966542,"In Table 1 and Table 2, we report the non-targeted and targeted attack performance of various GIA
methods, respectively. We bold out the best attack and underline the second-best attack when com-
bating against defenses from each category. Full results are in Appendix J.1 and Appendix J.2."
EMPIRICAL PERFORMANCE,0.1449814126394052,"Performance of non-targeted attacks. In Table 1, we can see that HAO signiﬁcantly improves the
performance of all attacks on all datasets up to 30%, which implies the effectiveness and versatility
of HAO. Especially, even coupled with a random injection strategy (PGD), HAO can attack robust
models to be comparable with or inferior to simple MLP which does not consider relational infor-
mation. Meanwhile, adaptive injection strategies outperform previous methods PGD and TDGIA by
a non-trivial margin for most cases, which further indicates that they are more suitable for HAO."
EMPIRICAL PERFORMANCE,0.14591078066914498,"Performance of targeted attack on large-scale graphs. In Table 2, HAO also improves the targeted
attack performance of all attack methods on all datasets by a signiﬁcant margin of up to 15%, which
implies that the beneﬁts of incorporating HAO are universal. Besides, adaptive injections can further
improve the performance of attacks and establish the new state-of-the-art coupled with HAO."
EMPIRICAL PERFORMANCE,0.14684014869888476,Published as a conference paper at ICLR 2022
EMPIRICAL PERFORMANCE,0.14776951672862454,"0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
2.00
Regularziation Weight λ"
EMPIRICAL PERFORMANCE,0.14869888475836432,"25
30
35
40
45
50
55
60
65
70
75
80
85
90"
EMPIRICAL PERFORMANCE,0.1496282527881041,Test Robustness
EMPIRICAL PERFORMANCE,0.15055762081784388,"GCN
Guard
MLP"
EMPIRICAL PERFORMANCE,0.15148698884758363,(a) Varying λ in HAO
EMPIRICAL PERFORMANCE,0.1524163568773234,"Model
Cora†
Computers†
Arxiv†
Computers‡
Aminer‡
Reddit‡"
EMPIRICAL PERFORMANCE,0.1533457249070632,"Clean
84.74
92.25
70.44
91.68
62.39
95.51
PGD
61.09
61.75
54.23
62.41
26.13
62.72
+HAO
56.63
59.16
45.05
59.09
22.15
56.99
MetaGIA
60.56
61.75
53.69
62.08
32.78
60.14
+HAO
58.51
60.29
48.48
58.63
29.91
54.14
AGIA
60.10
60.66
48.86
61.98
31.06
59.96
+HAO
53.79
58.71
48.86
58.37
26.51
56.36
TDGIA
66.86
66.79
49.73
62.47
32.37
57.97
+HAO
65.22
65.46
49.54
59.67
22.32
54.32
ATDGIA
61.14
65.07
46.53
64.66
24.72
61.25
+HAO
58.13
63.31
44.40
59.27
17.62
56.90"
EMPIRICAL PERFORMANCE,0.15427509293680297,The lower is better. †Non-targeted attack. ‡Targeted attack.
EMPIRICAL PERFORMANCE,0.15520446096654275,(b) Averaged performance across all defense models
EMPIRICAL PERFORMANCE,0.15613382899628253,"Figure 3: (a): Effects of HAO with different weights; (b) Averaged attack performance of various
attacks with or without HAO against both homophily defenders and other defense models."
EMPIRICAL PERFORMANCE,0.1570631970260223,"−0.2
0.0
0.2
0.4
0.6
0.8
1.0
Homophily 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5"
EMPIRICAL PERFORMANCE,0.1579925650557621,Density
EMPIRICAL PERFORMANCE,0.15892193308550187,"orig
gia
hao"
EMPIRICAL PERFORMANCE,0.15985130111524162,(a) Homophily change
EMPIRICAL PERFORMANCE,0.1607806691449814,"0
20
40
60
80
100
Node Budgets"
EMPIRICAL PERFORMANCE,0.16171003717472118,"25
30
35
40
45
50
55
60
65
70
75
80
85
90"
EMPIRICAL PERFORMANCE,0.16263940520446096,Test Robustness
EMPIRICAL PERFORMANCE,0.16356877323420074,"TDGIA
TDGIA-HAO
MLP"
EMPIRICAL PERFORMANCE,0.16449814126394052,(b) Varying node budgets
EMPIRICAL PERFORMANCE,0.1654275092936803,"0
5
10
15
20
25
30
Edge Budgets"
EMPIRICAL PERFORMANCE,0.16635687732342008,"25
30
35
40
45
50
55
60
65
70
75
80
85
90"
EMPIRICAL PERFORMANCE,0.16728624535315986,Test Robustness
EMPIRICAL PERFORMANCE,0.16821561338289961,"TDGIA
TDGIA-HAO
MLP"
EMPIRICAL PERFORMANCE,0.1691449814126394,(c) Varying edge budgets
EMPIRICAL PERFORMANCE,0.17007434944237917,"Figure 4: (a) Homophily changes after attacked by GIA without HAO (orange) and GIA with HAO
(canny); (b), (c) Attack performance against GCN and EGuard with different node and edge budgets.
• indicates attack with defenses and ▲indicates attack without defenses;"
ANALYSIS AND DISCUSSIONS,0.17100371747211895,"5.3
ANALYSIS AND DISCUSSIONS"
ANALYSIS AND DISCUSSIONS,0.17193308550185873,"Effects of HAO. Though HAO can substantially improve GIA methods under defenses, we ﬁnd it
essentially trades with the performance under no defenses. In Fig. 3a, as the weight for regularization
term λ increases, HAO trades slightly more of the performance against GCN for the performance
against homophily defenders. Finally, GIA reduces the performance of both GNNs with defenses
and without defenses to be inferior to MLP. Additionally, as also shown in Table 3b, the trade-off
will not hurt the overall performance while consistently brings beneﬁts up to 5%."
ANALYSIS AND DISCUSSIONS,0.17286245353159851,"Analysis of the perturbed graphs. In Fig. 4a, we also analyze the homophily distribution changes
after the attack. It turns out that GIA with HAO can effectively preserve the homophily while still
conducting effective attacks. Similar analysis on other datasets can be found in Appendix D.2."
ANALYSIS AND DISCUSSIONS,0.1737918215613383,"Attacks with limited budgets. We also examine the performance of GIA methods with or without
HAO varying different node and edge budgets. Fig. 4b and Fig. 4c show that HAO can consistently
improve the overall performance by slightly trading with the performance under no defenses."
CONCLUSIONS,0.17472118959107807,"6
CONCLUSIONS"
CONCLUSIONS,0.17565055762081785,"In this paper, we explored the advantages and limitations of GIA by comparing it with GMA. Though
we found that GIA can be provably more harmful than GMA, the severe damage to the homophily
makes it easily defendable by homophily defenders. Hence we introduced homophily unnoticeabil-
ity for GIA to constrain the damage and proposed HAO to instantiate it. Extensive experiments
show that GIA with HAO can break homophily defenders and substantially outperform all previous
works. We provide more discussions and future directions based on HAO in Appendix A."
CONCLUSIONS,0.17657992565055763,Published as a conference paper at ICLR 2022
CONCLUSIONS,0.1775092936802974,ACKNOWLEDGEMENTS
CONCLUSIONS,0.17843866171003717,"We thank the area chair and reviewers for their valuable comments. This work was partially sup-
ported by GRF 14208318 and ECS 22200720 from the RGC of HKSAR, YSF 62006202 from
NSFC, Australian Research Council Projects DE-190101473 and DP-220102121."
ETHICS STATEMENT,0.17936802973977695,ETHICS STATEMENT
ETHICS STATEMENT,0.18029739776951673,"Considering the wide applications and high vulnerability to adversarial attacks of GNNs, it is impor-
tant to develop trustworthy GNNs that are robust to adversarial attacks, especially for safety-critical
applications such as ﬁnancial systems. However, developing trustworthy GNNs heavily rely on the
effective evaluation of the robustness of GNNs, i.e., adversarial attacks that are used to measure the
robustness of GNNs. Unreliable evaluation will incur severe more issues such as overconﬁdence in
the adopted GNNs and further improve the risks of adopting unreliable GNNs. Our work tackles
an important issue in current GIA, hence enhancing the effectiveness of current evaluation on the
robustness of GNNs, and further empowering the community to develop more trustworthy GNNs to
beneﬁt society. Besides, this paper does not raise any ethical concerns. This study does not involve
any human subjects, practices to data set releases, potentially harmful insights, methodologies and
applications, potential conﬂicts of interest and sponsorship, discrimination/bias/fairness concerns,
privacy and security issues, legal compliance, and research integrity issues."
REPRODUCIBILITY STATEMENT,0.1812267657992565,REPRODUCIBILITY STATEMENT
REPRODUCIBILITY STATEMENT,0.1821561338289963,"To ensure the reproducibility of our theoretical, we provide detailed proof for our theoretical discov-
ery in Appendix E. Speciﬁcally, we provide detailed proof in Appendix E.1 for Theorem 1, proof in
Appendix E.3 for Theorem 2, and proof in Appendix E.5 for Theorem 3."
REPRODUCIBILITY STATEMENT,0.18308550185873607,"To ensure the reproducibility of our experimental results, we detail our experimental setting in Ap-
pendix B.2 and Appendix H, and open source our code."
REFERENCES,0.18401486988847585,REFERENCES
REFERENCES,0.18494423791821563,"Lei Jimmy Ba, Jamie Ryan Kiros, and Geoffrey E. Hinton. Layer normalization. arXiv preprint,
arXiv:1607.06450, 2016."
REFERENCES,0.18587360594795538,"Peter W. Battaglia, Jessica B. Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vin´ıcius Flores
Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner,
C¸ aglar G¨ulc¸ehre, H. Francis Song, Andrew J. Ballard, Justin Gilmer, George E. Dahl, Ashish
Vaswani, Kelsey R. Allen, Charles Nash, Victoria Langston, Chris Dyer, Nicolas Heess, Daan
Wierstra, Pushmeet Kohli, Matthew Botvinick, Oriol Vinyals, Yujia Li, and Razvan Pascanu.
Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261,
2018."
REFERENCES,0.18680297397769516,"Heng Chang, Yu Rong, Tingyang Xu, Wenbing Huang, Honglei Zhang, Peng Cui, Wenwu Zhu, and
Junzhou Huang. A restricted black-box adversarial framework towards attacking graph embed-
ding models. In The Thirty-Fourth AAAI Conference on Artiﬁcial Intelligence, pp. 3389–3396,
2020."
REFERENCES,0.18773234200743494,"Hanjun Dai, Hui Li, Tian Tian, Xin Huang, Lin Wang, Jun Zhu, and Le Song. Adversarial attack on
graph structured data. In Proceedings of the 35th International Conference on Machine Learning,
pp. 1123–1132, 2018."
REFERENCES,0.18866171003717472,"Negin Entezari, Saba A. Al-Sayouri, Amirali Darvishzadeh, and Evangelos E. Papalexakis. All you
need is low (rank): Defending against adversarial attacks on graphs. In The Thirteenth ACM
International Conference on Web Search and Data Mining, pp. 169–177, 2020."
REFERENCES,0.1895910780669145,"Fuli Feng, Xiangnan He, Jie Tang, and Tat-Seng Chua. Graph adversarial training: Dynamically
regularizing based on graph structure. IEEE Transactions on Knowledge and Data Engineering,
33(6):2493–2504, 2021."
REFERENCES,0.19052044609665428,Published as a conference paper at ICLR 2022
REFERENCES,0.19144981412639406,"Matthias Fey and Jan E. Lenssen. Fast graph representation learning with PyTorch Geometric. In
ICLR Workshop on Representation Learning on Graphs and Manifolds, 2019."
REFERENCES,0.19237918215613384,"Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation
of deep networks. In Proceedings of the 34th International Conference on Machine Learning, pp.
1126–1135, 2017."
REFERENCES,0.19330855018587362,"C. Lee Giles, Kurt D. Bollacker, and Steve Lawrence. Citeseer: An automatic citation indexing
system. In Proceedings of the 3rd ACM International Conference on Digital Libraries, pp. 89–
98, 1998."
REFERENCES,0.19423791821561337,"Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. 2016. http://www.
deeplearningbook.org."
REFERENCES,0.19516728624535315,"Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. In International Conference on Learning Representations, 2015."
REFERENCES,0.19609665427509293,"William L. Hamilton, Rex Ying, and Jure Leskovec. Representation learning on graphs: Methods
and applications. IEEE Data Engineering Bulletin, 40(3):52–74, 2017a."
REFERENCES,0.1970260223048327,"William L. Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large
graphs. In Advances in Neural Information Processing Systems, pp. 1024–1034, 2017b."
REFERENCES,0.1979553903345725,"Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi
Sugiyama. Co-teaching: Robust training of deep neural networks with extremely noisy labels. In
Advances in Neural Information Processing Systems, 2018."
REFERENCES,0.19888475836431227,"Bo Han, Gang Niu, Xingrui Yu, Quanming Yao, Miao Xu, Ivor Tsang, and Masashi Sugiyama.
SIGUA: Forgetting may make learning with noisy labels more robust. In Proceedings of the 37th
International Conference on Machine Learning, pp. 4006–4016, 2020a."
REFERENCES,0.19981412639405205,"Bo Han, Quanming Yao, Tongliang Liu, Gang Niu, Ivor W. Tsang, James T. Kwok, and Masashi
Sugiyama.
A survey of label-noise representation learning: Past, present and future.
arXiv
preprint, arXiv:2011.04406, 2020b."
REFERENCES,0.20074349442379183,"Kurt Hornik, Maxwell B. Stinchcombe, and Halbert White. Multilayer feedforward networks are
universal approximators. Neural Networks, 2(5):359–366, 1989."
REFERENCES,0.2016728624535316,"Yifan Hou, Jian Zhang, James Cheng, Kaili Ma, Richard T. B. Ma, Hongzhi Chen, and Ming-Chang
Yang.
Measuring and improving the use of graph information in graph neural networks.
In
International Conference on Learning Representations, 2020."
REFERENCES,0.20260223048327136,"Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta,
and Jure Leskovec. Open graph benchmark: Datasets for machine learning on graphs. In Ad-
vances in Neural Information Processing Systems, 2020."
REFERENCES,0.20353159851301114,"Hongwei Jin and Xinhua Zhang. Robust training of graph convolutional networks via latent pertur-
bation. In Machine Learning and Knowledge Discovery in Databases, pp. 394–411, 2021."
REFERENCES,0.20446096654275092,"Wei Jin, Yao Ma, Xiaorui Liu, Xianfeng Tang, Suhang Wang, and Jiliang Tang. Graph structure
learning for robust graph neural networks. In The 26th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining, pp. 66–74, 2020."
REFERENCES,0.2053903345724907,"Wei Jin, Yaxing Li, Han Xu, Yiqi Wang, Shuiwang Ji, Charu Aggarwal, and Jiliang Tang. Adver-
sarial attacks and defenses on graphs. SIGKDD Explorations Newsletter, 22(2):19–34, 2021."
REFERENCES,0.20631970260223048,"Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International
Conference on Learning Representations, 2015."
REFERENCES,0.20724907063197026,"Thomas N. Kipf and Max Welling. Semi-supervised classiﬁcation with graph convolutional net-
works. In International Conference on Learning Representations, 2017."
REFERENCES,0.20817843866171004,"Johannes Klicpera, Aleksandar Bojchevski, and Stephan G¨unnemann. Combining neural networks
with personalized pagerank for classiﬁcation on graphs. In International Conference on Learning
Representations, 2019."
REFERENCES,0.20910780669144982,Published as a conference paper at ICLR 2022
REFERENCES,0.2100371747211896,"Kezhi Kong, Guohao Li, Mucong Ding, Zuxuan Wu, Chen Zhu, Bernard Ghanem, Gavin Taylor, and
Tom Goldstein. FLAG: adversarial data augmentation for graph neural networks. arXiv preprint,
arXiv:2010.09891, 2020."
REFERENCES,0.21096654275092938,"Tongliang Liu and Dacheng Tao. Classiﬁcation with noisy labels by importance reweighting. IEEE
Transactions on Pattern Analysis & Machine Intelligence, 38(03):447–461, 2016."
REFERENCES,0.21189591078066913,"Ben London and Lise Getoor. Collective classiﬁcation of network data. In Data Classiﬁcation:
Algorithms and Applications, pp. 399–416. 2014."
REFERENCES,0.2128252788104089,"Yao Ma, Xiaorui Liu, Neil Shah, and Jiliang Tang.
Is homophily a necessity for graph neural
networks? In International Conference on Learning Representations, 2022."
REFERENCES,0.2137546468401487,"Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. In International Conference on
Learning Representations, 2018."
REFERENCES,0.21468401486988847,"Julian J. McAuley, Christopher Targett, Qinfeng Shi, and Anton van den Hengel. Image-based
recommendations on styles and substitutes. In Proceedings of the 38th International ACM SIGIR
Conference on Research and Development in Information Retrieval, pp. 43–52, 2015."
REFERENCES,0.21561338289962825,"Miller McPherson, Lynn Smith-Lovin, and James M Cook. Birds of a feather: Homophily in social
networks. Annual Review of Sociology, 27(1):415–444, 2001."
REFERENCES,0.21654275092936803,"Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward
Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner,
Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-performance deep
learning library. In Advances in Neural Information Processing Systems, pp. 8024–8035, 2019."
REFERENCES,0.2174721189591078,"Hongbin Pei, Bingzhe Wei, Kevin Chen-Chuan Chang, Yu Lei, and Bo Yang. Geom-gcn: Geometric
graph convolutional networks. In International Conference on Learning Representations, 2020."
REFERENCES,0.2184014869888476,"Yu Rong, Wenbing Huang, Tingyang Xu, and Junzhou Huang. Dropedge: Towards deep graph
convolutional networks on node classiﬁcation. In International Conference on Learning Repre-
sentations, 2020."
REFERENCES,0.21933085501858737,"Nitish Srivastava, Geoffrey E. Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.
Dropout: a simple way to prevent neural networks from overﬁtting. Journal of Machine Learning
Research, 15(1):1929–1958, 2014."
REFERENCES,0.22026022304832713,"Lichao Sun, Yingtong Dou, Carl Yang, Ji Wang, Philip S. Yu, and Bo Li. Adversarial attack and
defense on graph data: A survey. arXiv preprint, arXiv:1812.10528, 2018."
REFERENCES,0.2211895910780669,"Yiwei Sun, Suhang Wang, Xianfeng Tang, Tsung-Yu Hsieh, and Vasant G. Honavar. Adversar-
ial attacks on graph neural networks via node injections: A hierarchical reinforcement learning
approach. In The Web Conference 2020, pp. 673–683, 2020."
REFERENCES,0.22211895910780668,"Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J. Goodfel-
low, and Rob Fergus. Intriguing properties of neural networks. In International Conference on
Learning Representations, 2014."
REFERENCES,0.22304832713754646,"Jie Tang, Jing Zhang, Limin Yao, Juanzi Li, Li Zhang, and Zhong Su. Arnetminer: extraction and
mining of academic social networks. In Proceedings of the 14th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, pp. 990–998, 2008."
REFERENCES,0.22397769516728624,"Petar Veliˇckovi´c, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li`o, and Yoshua
Bengio. Graph Attention Networks. In International Conference on Learning Representations,
2018."
REFERENCES,0.22490706319702602,"Jihong Wang, Minnan Luo, Fnu Suya, Jundong Li, Zijiang Yang, and Qinghua Zheng. Scalable
attack on graph data by injecting vicious nodes. In Proceedings of the European Conference on
Machine Learning and Principles and Practice of Knowledge Discovery in Databases, 2020."
REFERENCES,0.2258364312267658,Published as a conference paper at ICLR 2022
REFERENCES,0.22676579925650558,"Xiaoyun Wang, Minhao Cheng, Joe Eaton, Cho-Jui Hsieh, and Shyhtsun Felix Wu. Attack graph
convolutional networks by adding fake nodes. arXiv preprint, arXiv:1810.10751, 2018."
REFERENCES,0.22769516728624536,"Huijun Wu, Chen Wang, Yuriy Tyshetskiy, Andrew Docherty, Kai Lu, and Liming Zhu. Adversarial
examples for graph data: Deep insights into attack and defense. In Proceedings of the Twenty-
Eighth International Joint Conference on Artiﬁcial Intelligence, pp. 4816–4823, 2019."
REFERENCES,0.22862453531598512,"Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S. Yu. A
comprehensive survey on graph neural networks. IEEE Transactions on Neural Networks and
Learning Systems, 32(1):4–24, 2021."
REFERENCES,0.2295539033457249,"Kaidi Xu, Hongge Chen, Sijia Liu, Pin-Yu Chen, Tsui-Wei Weng, Mingyi Hong, and Xue Lin.
Topology attack and defense for graph neural networks: An optimization perspective. In Pro-
ceedings of the Twenty-Eighth International Joint Conference on Artiﬁcial Intelligence, pp. 3961–
3967, 2019a."
REFERENCES,0.23048327137546468,"Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, and Stefanie
Jegelka. Representation learning on graphs with jumping knowledge networks. In Proceedings
of the 35th International Conference on Machine Learning, pp. 5449–5458, 2018."
REFERENCES,0.23141263940520446,"Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka.
How powerful are graph neural
networks? In International Conference on Learning Representations, 2019b."
REFERENCES,0.23234200743494424,"Han Yang, Kaili Ma, and James Cheng. Rethinking graph regularization for graph neural networks.
In Thirty-Fifth AAAI Conference on Artiﬁcial Intelligence, pp. 4573–4581, 2021a."
REFERENCES,0.23327137546468402,"Han Yang, Xiao Yan, Xinyan Dai, Yongqiang Chen, and James Cheng. Self-enhanced gnn: Improv-
ing graph neural networks using model outputs. In The International Joint Conference on Neural
Networks, pp. 1–8, 2021b."
REFERENCES,0.2342007434944238,"Zhilin Yang, William W. Cohen, and Ruslan Salakhutdinov. Revisiting semi-supervised learning
with graph embeddings. In Proceedings of the 33nd International Conference on Machine Learn-
ing, pp. 40–48, 2016."
REFERENCES,0.23513011152416358,"Hanqing Zeng, Hongkuan Zhou, Ajitesh Srivastava, Rajgopal Kannan, and Viktor K. Prasanna.
Graphsaint: Graph sampling based inductive learning method. In International Conference on
Learning Representations, 2020."
REFERENCES,0.23605947955390336,"Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding
deep learning requires rethinking generalization. In International Conference on Learning Rep-
resentations, 2017."
REFERENCES,0.23698884758364314,"Xiang Zhang and Marinka Zitnik. Gnnguard: Defending graph neural networks against adversarial
attacks. In Advances in Neural Information Processing Systems, 2020."
REFERENCES,0.2379182156133829,"Tong Zhao, Yozen Liu, Leonardo Neves, Oliver J. Woodford, Meng Jiang, and Neil Shah. Data aug-
mentation for graph neural networks. In Thirty-Fifth AAAI Conference on Artiﬁcial Intelligence,
pp. 11015–11023, 2021."
REFERENCES,0.23884758364312267,"Qinkai Zheng, Xu Zou, Yuxiao Dong, Yukuo Cen, Da Yin, Jiarong Xu, Yang Yang, and Jie Tang.
Graph robustness benchmark: Benchmarking the adversarial robustness of graph machine learn-
ing. Neural Information Processing Systems Track on Datasets and Benchmarks, 2021."
REFERENCES,0.23977695167286245,"Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng Wang,
Changcheng Li, and Maosong Sun. Graph neural networks: A review of methods and applica-
tions. AI Open, 1:57–81, 2020."
REFERENCES,0.24070631970260223,"Dingyuan Zhu, Ziwei Zhang, Peng Cui, and Wenwu Zhu. Robust graph convolutional networks
against adversarial attacks. In Proceedings of the 25th ACM SIGKDD International Conference
on Knowledge Discovery & Data Mining, pp. 1399–1407, 2019."
REFERENCES,0.241635687732342,"Jiong Zhu, Yujun Yan, Lingxiao Zhao, Mark Heimann, Leman Akoglu, and Danai Koutra. Beyond
homophily in graph neural networks: Current limitations and effective designs. In Advances in
Neural Information Processing Systems, 2020."
REFERENCES,0.2425650557620818,Published as a conference paper at ICLR 2022
REFERENCES,0.24349442379182157,"Xu Zou, Qinkai Zheng, Yuxiao Dong, Xinyu Guan, Evgeny Kharlamov, Jialiang Lu, and Jie Tang.
Tdgia: Effective injection attacks on graph neural networks. In Proceedings of the 27th ACM
SIGKDD Conference on Knowledge Discovery & Data Mining, pp. 2461–2471, 2021."
REFERENCES,0.24442379182156135,"Daniel Z¨ugner, Amir Akbarnejad, and Stephan G¨unnemann. Adversarial attacks on neural networks
for graph data. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge
Discovery & Data Mining, pp. 2847–2856, 2018."
REFERENCES,0.24535315985130113,"Daniel Z¨ugner and Stephan G¨unnemann. Adversarial attacks on graph neural networks via meta
learning. In 7th International Conference on Learning Representations, 2019."
REFERENCES,0.24628252788104088,"A
ADDITIONAL DISCUSSIONS AND FUTURE DIRECTIONS"
REFERENCES,0.24721189591078066,"A.1
DISCUSSIONS ON HAO AND ITS LIMITATIONS"
REFERENCES,0.24814126394052044,"Discussions on HAO and future implications. It is widely received that it is difﬁcult to give
a proper deﬁnition of unnoticeability for graphs (More details are also given in Appendix B.2.2).
Based on earliest unnoticeability constraints on degree distribution changes (Z¨ugner et al., 2018;
Z¨ugner & G¨unnemann, 2019), empirical observations that graph adversarial attacks may change
some feature statistics and connect dissimilar neighbors are identiﬁed, and leveraged as heuristics
to develop robust GNNs (Wu et al., 2019; Entezari et al., 2020; Zhang & Zitnik, 2020; Jin et al.,
2020). Though empirically effective, however, few of them provide theoretical explanations or re-
late this phenomenon to unnoticeability. In this work, starting from the comparison of GMA and
GIA, we identiﬁed GIA would lead to severe damage to the original homophily. Furthermore, the
relatively high ﬂexibility of GIA ampliﬁes the destruction and ﬁnally results in the break of ho-
mophily unnoticeability. The main reason for this phenomenon is mainly because of the poorly
deﬁned unnoticeability in graph adversarial attack. Without a proper deﬁnition, the developed at-
tacks tend to the shortcut to incur damage instead of capturing the true underlying vulnerability
of GNNs. Consequently, using these attacks to evaluate robustness of GNNs will bring unreliable
results thus hindering the development of trustworthy GNNs."
REFERENCES,0.24907063197026022,"To be more speciﬁc, due to the poor unnoticeability constraint for graph adversarial learning, the de-
veloped attacks tend to leverage the shortcuts to greatly destroy the original homophily, which leads
to the break of unnoticeability. Thus, using homophily defenders can easily defend these seemingly
powerful attacks, even with a simple design, which however brings us unreliable conclusions about
the robustness of homophily defenders. Essentially, HAO penalizes GIA attacks that take the short-
cuts, and retain their unnoticeability in terms of homophily. Thus, HAO mitigates the shortcut issue
of GIA attacks, urges the attacks to capture the underlying vulnerability of GNNs and brings us a
more reliable evaluation result, from which we know simple homophily defenders are essentially
not robust GNNs."
REFERENCES,0.25,"In addition, the proposed realization of unnoticeability check for adversarial attacks provides an-
other approach to instantiate the unnoticeability. Especially for the domains that we can hardly
leverage inductive bias from human, we can still try to identify their homophily, or the underlying
rationales/causality of the data generation process, e.g., grammar correctness, ﬂuency and semantics
for natural languages, to instantiate the unnoticeability constraint with the help of external examin-
ers. Since people are likely to be more sensitive to quantitative numbers like accuracy, those external
examiners can be conveniently leveraged to the corresponding benchmark or leaderboards to further
beneﬁt the community."
REFERENCES,0.25092936802973975,"Limitations of HAO and future implications. Since HAO are mostly developed to preserve the
homophily unnoticeability, it counters the greedy strategy of attacks without HAO that destroys the
homophily to incur more damage. Therefore, it will inevitably reduce the damage of the attacks
without HAO against vanilla GNNs. As observed from the experiments, we ﬁnd HAO essentially
trades the attack performance when against vanilla GNNs for the performance when against ho-
mophily defenders. As Fig. 3a shows, the trade-off effects can be further ampliﬁed with a large
coefﬁcient lambda in HAO. As also shown by Fig. 4b and Fig. 4c, when against vanilla GNNs, com-
pared with GIA without HAO, GIA with HAO show fewer threats. In certain cases, the trade-off
might generate the performance of attacks. Thus, it calls for more tailored optimization methods
to solve for better injection matrix and node features in the future. Moreover, the trade-off effects"
REFERENCES,0.25185873605947956,Published as a conference paper at ICLR 2022
REFERENCES,0.2527881040892193,"also reﬂect the importance of homophily to the performance of node classiﬁcations and the utility
of homophily unnoticeability, where we believe future theoretical works can further study this phe-
nomenon and reveal the underlying causality for node classiﬁcation or even more other downstream
tasks. Thus, we can develop more robust and trustworthy neural graph models that do not depend
on spurious correlations to perform the task."
REFERENCES,0.2537174721189591,"In addition, as homophilous graph is the most common class of graph benchmarks for node classi-
ﬁcation (Yang et al., 2016; Giles et al., 1998; Hu et al., 2020; Zheng et al., 2021), our discussions
are mostly focused on this speciﬁc class of graphs. However, when applying HAO to other classes
of graphs such as non-attributed graphs, a direct adaption of HAO may not work. Nevertheless, if
the underlying information for making correct predictions still resemble the homophily property,
for example, in a non-attributed graph, nodes with similar structures tend to have similar labels, it
is still promising to introduce the node features with node embeddings, derive a new deﬁnition of
homophily and apply HAO. Moreover, recently disassortative graphs appear to be interesting to the
community (Pei et al., 2020; Zhu et al., 2020), which exhibit heterophily property that neighbors
tend to have dissimilar labels, in contrast to homophily. We conduct an investigation on this speciﬁc
class of graphs and detailed results are given in Table 12, from which we surprisingly ﬁnd HAO still
maintains the advance when incorporating various GIA attacks. The reason might be that GNNs
and GIA with HAO can still implicitly learn the homophily such as similarity between class label
distributions (Ma et al., 2022), even without explicit deﬁnitions. To summarize, we believe future
extension of HAO to other classes of graphs is another interesting direction."
REFERENCES,0.25464684014869887,"Besides, the discussions in this paper are only considered the relationship between adversarial ro-
bustness and homophily. However, label noises are another widely existing threats that are deserved
to be paid attention to (Liu & Tao, 2016; Han et al., 2018; 2020a;b). Essentially, our discussions in
Appendix B.3 are also closely related to the vulnerability of GNNs to label noises, where GNNs can
still achieve near perfect ﬁtting to the datasets with full label noises. Thus, it is desirable to broader
the attention and discussion to include the label noises when developing trustworthy GNNs."
REFERENCES,0.2555762081784387,"A.2
MORE FUTURE DIRECTIONS"
REFERENCES,0.25650557620817843,"Besides the future implications inspired from the limitations of HAO, we believe there are also many
promising future works that could be built upon HAO."
REFERENCES,0.25743494423791824,"Rethinking the deﬁnition of unnoticeability in adversarial robustness. Though the study of
adversarial robustness was initially developed around the deep learning models on image classiﬁca-
tion (Szegedy et al., 2014; Goodfellow et al., 2015; Madry et al., 2018), images and classiﬁcation are
far from the only data and the task we want to build neural networks for. Deep learning models are
widely applied to other types of data, such as natural languages and graphs, where human inductive
bias can hardly be leveraged to elaborate a proper deﬁnition of unnoticeability. Moreover, for more
complicated tasks involving implicit reasoning, even in the domain of images, the original deﬁnition
of unnoticeability, i.e., L-p norm, may not be sufﬁcient to secure all shortcuts that can be leveraged
by adversaries. How to establish and justify a proper deﬁnition of unnoticeability in these domains
and tasks, is critical for developing trustworthy deep learning models."
REFERENCES,0.258364312267658,"Applications to other downstream tasks. Given the wide applications of GNNs, we believe the
studies on the robustness of GNNs should be extended to other downstream tasks, such as link
predictions and graph clustering. Speciﬁcally, when with a different task objective, it is interesting
to ﬁnd whether the underlying task still depend on the homophily property and how the different
optimization objectives affect the attack optimization trajectory."
REFERENCES,0.25929368029739774,"Attack with small budgets. In real-life scenarios, the budgets of the adversary may be limited to a
small number. It is interesting to study how to maximize the damage given limited budgets and its
interplay between homophily. For example, how to locate the most vulnerable targets. We show an
initial example through ATDGIA."
REFERENCES,0.26022304832713755,"Mix-up attack of GMA and GIA. In real-life scenarios, both GMA and GIA could happen while
with different budget limits. It is interesting to see whether and how they could be combined to
conduct more powerful attacks."
REFERENCES,0.2611524163568773,"Injection for defense. Actually, not only attackers can inject extra nodes, defenders can also inject
some nodes to promote the robustness of the networks. For example, according the Proposition. E.1,"
REFERENCES,0.2620817843866171,Published as a conference paper at ICLR 2022
REFERENCES,0.26301115241635686,"nodes with higher degrees, higher MLP decision margin and higher homophily tend more unlikely
to be attacked. Hence, defenders may directly inject some nodes the promote the above properties
of vulnerable nodes."
REFERENCES,0.26394052044609667,"Attacks on more complicated and deep GNNs. Most existing graph adversarial works focus on
analyzing linearized GNNs and apply the discoveries to more complex cases. However, with the
development of deep learning and GNNs, some models with complicated structures fail to ﬁt those
theories. For example, methods developed by studying linearized GNNs can hardly adapt to GNNs
with normalizations as also revealed from our experiments. Then they can even more hardly be
adapted to more complex models such as Transformers. On the other hand, most graph adversarial
studies only focus on relatively shallow GNNs. Different from other deep learning models, as GNNs
go deep, besides more parameters, they also require an exponentially growing number of neighbors
as inputs. How the number of layers would affect their robustness and the threats of attacks remain
unexplored. From both theoretical and empirical perspectives, we believe it is very interesting to
study the interplay between the number of GNN layers and homophily, in terms of adversarial
robustness and threats, and how to leverage the discoveries to probe the weakness of complicated
models."
REFERENCES,0.2648698884758364,"Reinforcement Learning based GIA. Reinforcement learning based approaches are shown to ex-
hibit promising performances in previous mixed settings (Dai et al., 2018; Sun et al., 2020). Though
we exclude them for the efforts needed to adapt them to our setting, we believe it is promising
and interesting to incorporate reinforcement learning to develop more tailored injection strategies
and vulnerable nodes selection. Meanwhile, it is also interesting to explore how to leverage the
idea of SeqGIA proposed in Sec. 4 to reduce the computation overhead of reinforcement learning
approaches and enhance their scalability."
REFERENCES,0.26579925650557623,"B
MORE DETAILS AND REASONS ABOUT THE GRAPH ADVERSARIAL
ATTACK SETTING"
REFERENCES,0.266728624535316,We provide more details about the perturbation constraints and the threat model used in Sec. 2.2.
REFERENCES,0.26765799256505574,"B.1
PERTURBATION CONSTRAINTS"
REFERENCES,0.26858736059479554,"Following previous works (Z¨ugner et al., 2018; Zou et al., 2021), Graph adversarial attacks can
be characterized into graph modiﬁcation attacks and graph injection attacks by their perturbation
constraints. Moreover, we adopt standardization methods (i.e., arctan transformation) following
Graph Robustness Benchmark (Zheng et al., 2021) on input features X."
REFERENCES,0.2695167286245353,"Graph Modiﬁcation Attack (GMA). GMA generates G′ by modifying the graph structure A and
the node features X of the original graph G. The most widely adopted constraints in GMA is to limit
the number of perturbations on A and X, denoted by △A and △X, respectively, as:"
REFERENCES,0.2704460966542751,"△A + △X ≤△∈Z, ∥A′ −A∥0 ≤△A ∈Z, ∥X′ −X∥∞≤ϵ ∈R,
(12)"
REFERENCES,0.27137546468401486,"where the perturbation on X is bounded by ϵ via L-p norm, since we are using continuous features."
REFERENCES,0.27230483271375466,"Graph Injection Attack (GIA). Differently, GIA generates G′ by injecting a set of malicious nodes
Vatk as:"
REFERENCES,0.2732342007434944,"X′ =

X
Xatk"
REFERENCES,0.2741635687732342,"
, A′ =
 A
Aatk
AT
atk
Oatk"
REFERENCES,0.275092936802974,"
,
(13)"
REFERENCES,0.2760223048327137,"where Xatk is the features of the injected nodes, Oatk is the adjacency matrix among injected nodes,
and Aatk is the adjacency matrix between the injected nodes and the original nodes. Let du denote
the degree of node u, the constraints in GIA are:"
REFERENCES,0.27695167286245354,"|Vatk| ≤△∈Z, 1 ≤du ≤b ∈Z, Xu ∈DX ⊆Rd, ∀u ∈Vatk,
(14)"
REFERENCES,0.2778810408921933,"where the number and degrees of the injected nodes are limited, DX = {C ∈Rd, min(X)·1 ≤C ≤
max(X)·1} where min(X) and max(X) are the minimum and maximum entries in X respectively.
In other words, each entry of the injected node features are bounded within the minimal entry and
maximal entry of the original node feature matrix, following previous setting (Zou et al., 2021)."
REFERENCES,0.2788104089219331,Published as a conference paper at ICLR 2022
REFERENCES,0.27973977695167285,"B.2
THREAT MODEL"
REFERENCES,0.28066914498141265,"We adopt a uniﬁed setting which is also used by Graph Robustness Benchmark (Zheng et al., 2021),
that is evasion, inductive, and black-box. Next we will elaborate more details and reasons for adopt-
ing the setting."
REFERENCES,0.2815985130111524,"B.2.1
DETAILS OF THE THREAT MODEL"
REFERENCES,0.2825278810408922,"Evasion. The attack only happens at test time, which means that defenders are able to obtain the
original clean graph Gtrain for training, while testing on a perturbed graph G′. The reasons for adopt-
ing the evasion setting is as shown in Appendix B.2.2."
REFERENCES,0.28345724907063197,"Inductive. The training and testing of GNNs is performed in an inductive manner. Speciﬁcally, fθ
is trained on the (sub) training graph Gtrain, which is consist of the training nodes with their labels
and the edges among training nodes. While during testing, the model will access the whole graph
Gtest = G for inferring the labels of test nodes. In particular, G is consist of all of the nodes and the
edges, including Gtrain, the test nodes, the edges among test nodes and the edges between training
nodes and the test nodes. In contrast, if the training and testing is performed in a transductive manner,
the model can access the whole graph during both training and testing, i.e., Gtrain = Gtest = G. Since
we adopt the evasion setting where the adversary may modify the Gtest during testing, the GNN has
to be learned in an inductive manner. More reasons are as elaborated in Appendix B.2.2."
REFERENCES,0.2843866171003718,"Black-box. The adversary has no information about the target model, but the adversary may obtain
the graph and training labels to train a surrogate model for generating perturbed graph G′."
REFERENCES,0.2853159851301115,"Combining all of the above, conducting effective attacks raises special challenges to adversaries,
since defenders can adopt the information extracted from training graph Gtrain to learn more robust
hidden representations (Zhu et al., 2019), or learn to drop noisy edges (Wu et al., 2019; Zhang &
Zitnik, 2020; Jin et al., 2020), or even perform adversarial training (Jin & Zhang, 2021; Feng et al.,
2021) which is known as one of the strongest defense mechanisms in the domain of images (Good-
fellow et al., 2015; Madry et al., 2018)."
REFERENCES,0.2862453531598513,"B.2.2
DISCUSSIONS ABOUT THE THREAT MODEL"
REFERENCES,0.2871747211895911,"Different from images where we can adopt the inductive bias from human vision system to use nu-
merical constraints, i.e., L-p norm, to bound the perturbation range (Goodfellow et al., 2015; Madry
et al., 2018), we cannot use similar numerical constraints to deﬁne the unnoticeability for graphs, as
they are weakly correlated to the information required for node classiﬁcation. For example, previous
work (Z¨ugner et al., 2018) tries to use node degree distribution changes as the unnoticeability con-
straints. However, given the same degree distribution, we can shufﬂe the node features to generate
multiple graphs with completely different semantic meanings, which disables the functionality of
unnoticeability."
REFERENCES,0.28810408921933084,"Because of the difﬁculty to properly deﬁne the unnoticeability for graphs, adopting a poisoning
setting in graph adversarial attack will enlarge the gap between research and practice. Speciﬁcally,
poisoning attacks require an appropriate deﬁnition of unnoticeability so that the defenders are able to
distinguish highly poisoned data from unnoticeable poisoned data and the original data. Otherwise,
attackers can always leverage some underlying shortcuts implied by the poorly deﬁned unnotice-
ability, i.e., homophily in our case, to perform the attacks, since the defenders are blind to these
shortcuts. On the other hand, leveraging shortcuts may generate data which is unlikely to appear in
real-world applications. For example, in a citation network, medical papers are unlikely to cite or be
cited by linguistic papers while the attacks may modify the graphs or inject malicious nodes to make
medical papers cite or be cited by lots of linguistic papers, which is apparently impractical. Using
these attacks to evaluate the robustness of GNNs may bring unreliable conclusions, i.e., homophily
defenders in our case, which will greatly hinders the development of the trustworthy GNNs."
REFERENCES,0.28903345724907065,"Moreover, under a poor unnoticeability deﬁnition, without the presence of the original data, defend-
ers have no idea about to what extent the data is poisoned and whether the original labels remain the
correspondence. Furthermore, it is well-known that neural networks have universal approximation
power (Hornik et al., 1989), thus can easily overﬁt the training set (Goodfellow et al., 2016), or even
memorize the labels appeared during training (Zhang et al., 2017). As a generalization from deep"
REFERENCES,0.2899628252788104,Published as a conference paper at ICLR 2022
REFERENCES,0.2908921933085502,"learning models to graphs, GNNs tend to exhibit similar behaviors, which is shown empirically in
our experiments (See Appendix B.3 for details). Thus, even trained on a highly poisoned graph,
GNNs may still converge to 100% training accuracy, even though the correspondence between the
data and the underlying labels might be totally corrupted. In this case, defenders can hardly distin-
guish whether the training graph is perturbed hence unlikely to make any effective defenses. Besides,
studying the robustness of GNNs trained from such highly poisoned graphs seems to be impractical,
since real world trainers are unlikely to use such highly poisoned data to train GNNs."
REFERENCES,0.29182156133828996,"While in an evasion setting, the defenders are able to use the training graph to tell whether the
incoming data is heavily perturbed and make some effective defenses, even simply leveraging some
feature statistics (Wu et al., 2019; Jin et al., 2020). Notably, A recent benchmark (Zheng et al., 2021)
also has similar positions. Thus, we will focus on the evasion setting in this paper."
REFERENCES,0.29275092936802977,"Given the evasion setting, GNNs can only perform inductive learning where the test nodes and edges
are not visible during training. The reason is that, transductive learning (i.e., the whole graph except
test labels is available), requires the training graph and test graph to be the same. However, it can not
be satisﬁed as the adversary will modify the test graph, i.e., changing some nodes or edges during
GMA attack, or injecting new malicious nodes during GIA attack. Additionally, inductive learning
has many practical scenarios. For example, in an academic network, the graph grows larger and
larger day by day as new papers are published and added to the original network. GNN models must
be inductive to be applied to such evolving graphs."
REFERENCES,0.2936802973977695,"B.3
MEMORIZATION EFFECTS OF GRAPH NEURAL NETWORKS"
REFERENCES,0.29460966542750927,"0
200
400
600
800
1000
Training Epochs 0.2 0.4 0.6 0.8 1.0"
REFERENCES,0.2955390334572491,Accuracy
REFERENCES,0.29646840148698883,"train acc
test acc"
REFERENCES,0.29739776951672864,(a) Original labels
REFERENCES,0.2983271375464684,"0
200
400
600
800
1000
Training Epochs 0.2 0.4 0.6 0.8 1.0"
REFERENCES,0.2992565055762082,Accuracy
REFERENCES,0.30018587360594795,"train acc
test acc"
REFERENCES,0.30111524163568776,(b) Random labels
REFERENCES,0.3020446096654275,"0.0
0.2
0.4
0.6
0.8
1.0
Corruption Rate 0.2 0.4 0.6 0.8 1.0"
REFERENCES,0.30297397769516726,Accuracy
REFERENCES,0.30390334572490707,"train acc
test acc"
REFERENCES,0.3048327137546468,(c) Partial random labels
REFERENCES,0.30576208178438663,Figure 5: Training curve of GCN on Cora with random labels
REFERENCES,0.3066914498141264,"We conduct experiments with GCN (Kipf & Welling, 2017) on Cora (Yang et al., 2016). The ar-
chitecture we select is a 2-Layer GCN with 16 hidden units, optimized using Adam (Kingma &
Ba, 2015) with a learning rate of 0.01 and a L2 weight decay of 5 × 10−4 for the ﬁrst layer. We
train 1000 epochs and report the training accuracy and test accuracy according to the best validation
accuracy. We randomly sample certain percent of nodes from the whole graph and reset their labels.
It can be seen from Fig. 5 (b) and (c) that even with all random labels, the training accuracy can
reach to nearly 100%, which serves as a strong evidence for the existence of memorization effects
in GNNs. In other words, even a GNN is trained on a heavily poisoned graph (changes dramatically
in the sense of semantic), it can still achieve good training accuracy while the defender has no way
to explicitly ﬁnd it or do anything about it. That is against to the original setting and purpose of ad-
versarial attacks (Szegedy et al., 2014; Goodfellow et al., 2015; Madry et al., 2018). Thus, it urges
the community for a proper solution to the ill-deﬁned unnoticeability in current graph adversarial
learning. Till the appearance of a silver bullet for unnoticeability on graphs, evasion attack can serve
as a better solution than poisoning attack."
REFERENCES,0.3076208178438662,"C
MORE DETAILS ABOUT GIA AND GMA COMPARISON"
REFERENCES,0.30855018587360594,"C.1
IMPLEMENTATION OF GRAPH MODIFICATION ATTACK"
REFERENCES,0.30947955390334575,"Following Metattack (Z¨ugner & G¨unnemann, 2019), we implement Graph Modiﬁcation Attack by
taking A as a hyper-parameter. Nevertheless, since we are conducting evasion attack, we do not"
REFERENCES,0.3104089219330855,Published as a conference paper at ICLR 2022
REFERENCES,0.31133828996282525,"have meta-gradients but the gradient of A with respect to Latk, or ∇ALatk. Each step, we take the
maximum entry in ∇ALatk, denoted with max(∇ALatk), and change the corresponding edge, if it is
not contained in the training graph. Then we perform the perturbation as follows:"
REFERENCES,0.31226765799256506,"(a) If max(∇ALatk) ≤0 and the corresponding entry in A is 0, i.e., the edge does not exist before,
we will add the edge.
(b) If max(∇ALatk) ≥0 and the corresponding entry in A is 1, i.e., the edge exists before, we will
remove the edge."
REFERENCES,0.3131970260223048,"If the selected entry can not satisfy neither of the above conditions, we will take the next maxi-
mum entry to perform the above procedure until we ﬁnd one that satisfy the conditions. Here we
exclude perturbations on node features given limited budgets, since Wu et al. (2019) observed the
edge perturbations produce more harm than node perturbations. Besides, as shown in the proof, the
damage brought by perturbations on node features is at most the damage brought by a corresponding
injection to the targets in GIA, hence when given the same budgets to compare GMA and GIA, we
can exclude the perturbations on nodes without loss of generality. Note that given the deﬁnitions
of direct attack and inﬂuencer attack in Nettack (Z¨ugner et al., 2018), our theoretical discussions
are applicable to both direct GMA attack and indirect/inﬂuencer GMA attack, since the results are
derived by establishing mappings between each kind of perturbations in GMA attack that are agnos-
tic to these two types of GMA attacks. Moreover, the GMA attack evaluated in our experiments is
exactly the direct attack. As in our case, all of the test nodes become victim nodes and the adversary
is allowed to modify the connections and features of these nodes to perform the attack."
REFERENCES,0.3141263940520446,"C.2
IMPLEMENTATION OF GRAPH INJECTION ATTACK WITH PLURAL MAPPING"
REFERENCES,0.3150557620817844,"GIA with M2 is implemented based on the GMA above. For each edge appears in the perturbed
graph produced by GMA but does not exist in the original graph, in GIA, we will inject a node to
connect with the corresponding nodes of the edge. After injecting all of the nodes, then we use
PGD (Madry et al., 2018) to optimize the features of the injected nodes."
REFERENCES,0.3159851301115242,"D
MORE HOMOPHILY DISTRIBUTIONS"
REFERENCES,0.31691449814126393,"D.1
EDGE-CENTRIC HOMOPHILY"
REFERENCES,0.31784386617100374,"In addition to node-centric homophily (Def. 6), we can also deﬁne edge-centric homophily as:
Deﬁnition D.1 (Edge-Centric Homophily). The homophily for an edge (u, v) can be deﬁned as.
he = sim(Xu, Xv),
(15)
where sim(·) is also a distance metric, e.g., cosine similarity."
REFERENCES,0.3187732342007435,"With the deﬁnition above, we can probe the natural edge-centric homophily distribution of real-
world benchmarks, as shown in Fig. 6. It turns out that the edge-centric homophily distributes
follows a Gaussian prior. However, it seems to be improper to utilize edge-centric homophily to
instantiate the homophily unnoticeability for several reasons. On the one hand, edge similarity does
not consider the degrees of the neighbors which is misaligned with the popular aggregation scheme
of GNNs. On the other hand, edge-centric and node-centric homophily basically perform similar
functionality to retain the homophily, but if considering the future extension to high-order neighbor
relationships, edge similarity might be harder to extend than node-centric homophily. Thus, we
utilize the node-centric homophily for most of our discussions."
REFERENCES,0.31970260223048325,"D.2
MORE HOMOPHILY DISTRIBUTIONS CHANGES"
REFERENCES,0.32063197026022305,"We provide more homophily distribution results of the benchmarks we used in the experiments for
Cora, Computers and Arxiv, shown as in Fig. 7 and Fig. 8, respectively. GIA is implemented with
TDGIA (Zou et al., 2021). Note that the budgets for TDGIA here is different from that in the
previous sections, which utilized the budgets resulting in the maximum harm when compared with
GMA. Similarly, GIA without HAO would severely break the original homophily distribution hence
making GIA can be easily defended by homophily defenders. While incorporated with HAO, GIA
would retain the original homophily during attack."
REFERENCES,0.3215613382899628,Published as a conference paper at ICLR 2022
REFERENCES,0.3224907063197026,"0.0
0.2
0.4
0.6
0.8
1.0
Homophily 0.0 0.5 1.0 1.5 2.0 2.5"
REFERENCES,0.32342007434944237,Density
REFERENCES,0.3243494423791822,(a) Cora
REFERENCES,0.3252788104089219,"−1.00−0.75−0.50−0.25 0.00
0.25
0.50
0.75
1.00
Homophily 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75"
REFERENCES,0.32620817843866173,Density
REFERENCES,0.3271375464684015,(b) Computers
REFERENCES,0.32806691449814124,"0.2
0.4
0.6
0.8
1.0
Homophily 0 1 2 3 4 5"
REFERENCES,0.32899628252788105,Density
REFERENCES,0.3299256505576208,(c) Arxiv
REFERENCES,0.3308550185873606,Figure 6: Edge-Centric homophily distributions
REFERENCES,0.33178438661710036,"0.0
0.2
0.4
0.6
0.8
1.0
Homophily 0.0 0.5 1.0 1.5 2.0 2.5 3.0"
REFERENCES,0.33271375464684017,Density
REFERENCES,0.3336431226765799,(a) Cora
REFERENCES,0.3345724907063197,"−0.75 −0.50 −0.25
0.00
0.25
0.50
0.75
1.00
Homophily 0.0 0.5 1.0 1.5 2.0"
REFERENCES,0.3355018587360595,Density
REFERENCES,0.33643122676579923,(b) Computers
REFERENCES,0.33736059479553904,"0.2
0.4
0.6
0.8
1.0
Homophily 0 1 2 3 4 5 6 7"
REFERENCES,0.3382899628252788,Density
REFERENCES,0.3392193308550186,(c) Arxiv
REFERENCES,0.34014869888475835,Figure 7: Homophily distributions before attack
REFERENCES,0.34107806691449816,"E
PROOFS AND DISCUSSIONS OF THEOREMS"
REFERENCES,0.3420074349442379,"E.1
PROOF FOR THEOREM 1"
REFERENCES,0.3429368029739777,"Theorem 1. Given moderate perturbation budgets △GIA for GIA and △GMA for GMA, that is,
let △GIA ≤△GMA ≪|V | ≤|E|, for a ﬁxed linearized GNN fθ trained on G, assume that
G has no isolated nodes, and both GIA and GMA adversaries follow the optimal strategy, then,
∀△GMA > 0, ∃△GIA ≤△GMA, such that:"
REFERENCES,0.34386617100371747,"Latk(fθ(G′
GIA)) −Latk(fθ(G′
GMA)) ≤0,"
REFERENCES,0.3447955390334573,"where G′
GIA and G′
GMA are the perturbed graphs generated by GIA and GMA, respectively."
REFERENCES,0.34572490706319703,"Proof. The proof sketch is to show that,"
REFERENCES,0.3466542750929368,"(a) Assume the given GNN model has k layers, there exists a mapping, that when given the same
budget, i.e., △GIA = △GMA ≪|V | ≤|E|, for each perturbation generated by GMA intended
to attack node u by perturbing edge (u, v), or node attributes of node u or some node v that
connects to u within k hops, we can always map it to a corresponding injection attack, that
injects node xw to attack u, and lead to the same effects to the prediction."
REFERENCES,0.3475836431226766,"(b) When the number of perturbation budget increases, the optimal objective values achieved of
GIA is monotonically non-increasing with respect to △GIA, that is"
REFERENCES,0.34851301115241634,"Lk+1
atk (fθ(G′
GIA)) ≤Lk
atk(fθ(G′
GIA)),"
REFERENCES,0.34944237918215615,"where Lk
atk(fθ(G′
GIA)) is the optimal value achieved under the perturbation budget of k, which
is obvious."
REFERENCES,0.3503717472118959,"Once we prove both (a) and (b), the Latk(fθ(G′
GIA)) will approach to Lk
atk(fθ(G′
GMA)) from the above
as △GIA approaches to △GMA, hence proving Theorem 1. Furthermore, for the ﬂexibility of the
constraints on Xw, we may adopt the gradient information of Xw with respect to Latk(fθ(G′
GIA)) to
further optimize Xw and make more damages. Hence, we have Latk(fθ(G′
GIA)) ≤Lk
atk(fθ(G′
GMA))."
REFERENCES,0.3513011152416357,"To prove (a), the key technique is to show that, under a predeﬁned mapping, there exist a corre-
sponding injection matrix Aatk along with the features of the injected nodes Xatk, such that the GIA"
REFERENCES,0.35223048327137546,Published as a conference paper at ICLR 2022
REFERENCES,0.35315985130111527,"−0.2
0.0
0.2
0.4
0.6
0.8
1.0
Homophily 0.0 0.5 1.0 1.5 2.0 2.5 3.0"
REFERENCES,0.354089219330855,Density
REFERENCES,0.3550185873605948,"orig
gia
hao"
REFERENCES,0.3559479553903346,(a) Cora
REFERENCES,0.35687732342007433,"−0.75 −0.50 −0.25
0.00
0.25
0.50
0.75
1.00
Homophily 0.0 0.5 1.0 1.5 2.0"
REFERENCES,0.35780669144981414,Density
REFERENCES,0.3587360594795539,"orig
gia
hao"
REFERENCES,0.3596654275092937,(b) Computers
REFERENCES,0.36059479553903345,"−0.2
0.0
0.2
0.4
0.6
0.8
1.0
Homophily 0 1 2 3 4 5 6 7"
REFERENCES,0.36152416356877326,Density
REFERENCES,0.362453531598513,"orig
gia
hao"
REFERENCES,0.36338289962825276,(c) Arxiv
REFERENCES,0.3643122676579926,Figure 8: Homophily distributions after attack
REFERENCES,0.3652416356877323,"adversary can cause the same damage as GMA. The deﬁnition of the mapping mostly derives how
the injection matrix is generated. While for the generation of Xatk, note that all of the input fea-
tures X is normalized to a speciﬁc range within [−fl, fr] where fl, fr ≥0, following previous
works (Zheng et al., 2021). Thus, for any features Xv ∈DX, αXv ∈DX when 0 ≤α ≤1. We
will use the statement multiple times during the derivation of Xatk."
REFERENCES,0.36617100371747213,"Next, we will start to prove (a). Following Wu et al. (2019), in GMA, adding new connections
between nodes from different classes produces the most beneﬁt to the adversarial objective. Hence,
given the limited perturbation budget, we give our primary focus to the action of connecting nodes
from different classes and will prove (a) also holds for the remaining two actions, i.e., edge deletion
and node attribute perturbation."
REFERENCES,0.3671003717472119,"We prove (a) by induction on the number of linearized layers. First of all, we will show prove (a)
holds for 1-layer and 2-layer linearized GNN as a motivating example. The model is as fθ = ˆA2XΘ
with H = ˆAXΘ and Z = fθ."
REFERENCES,0.3680297397769517,"Plural Mapping M2. Here we deﬁne the mapping M2 for edge addition. For each edge perturba-
tion pair (u, v) generated by GMA, we can insert a new node w to connect u and v. The inﬂuence
of adversaries can be identiﬁed as follows, as Θ is ﬁxed, we may exclude it for simplicity:
In layer (1):"
REFERENCES,0.36895910780669144,• Clean graph:
REFERENCES,0.36988847583643125,"Hi =
X"
REFERENCES,0.370817843866171,t∈N(i)∪{i}
REFERENCES,0.37174721189591076,"1
√didt
Xt
(16)"
REFERENCES,0.37267657992565056,• GMA:
REFERENCES,0.3736059479553903,"H′
i ="
REFERENCES,0.3745353159851301,"






"
REFERENCES,0.3754646840148699,"





 X"
REFERENCES,0.3763940520446097,t∈N(i)∪{i}
P,0.37732342007434944,"1
p"
P,0.37825278810408924,"dt(di + 1)
Xt +
1
p"
P,0.379182156133829,"dv(di + 1)
Xv,
i ∈{u} X"
P,0.38011152416356875,t∈N(i)∪{i}
P,0.38104089219330856,"1
p"
P,0.3819702602230483,"dt(di + 1)
Xt +
1
p"
P,0.3828996282527881,"du(di + 1)
Xu,
i ∈{v}"
P,0.38382899628252787,"Hi,
i /∈{u, v} (17)"
P,0.3847583643122677,• GIA:
P,0.3856877323420074,"H′′
i ="
P,0.38661710037174724,"





"
P,0.387546468401487,"




 X"
P,0.38847583643122674,t∈N(i)∪{i}
P,0.38940520446096655,"1
p"
P,0.3903345724907063,"dt(di + 1)
Xt +
1
p"
P,0.3912639405204461,"3(di + 1)
Xw,
i ∈{u, v}"
P,0.39219330855018586,"Hi,
u /∈{u, v, w}
1
√"
P,0.39312267657992567,"3(
1
√du + 1Xu +
1
√dv + 1Xv + 1
√"
P,0.3940520446096654,"3Xw),
i ∈{w} (18)"
P,0.3949814126394052,"where di refers to the degree of node i with self-loops added for simplicity. Thus, in layer (1), to
make the inﬂuence from GMA and GIA on node u equal, the following constraint has to be satisﬁed:
1
p"
P,0.395910780669145,"3(du + 1)
Xw =
1
p"
P,0.39684014869888473,"(dv + 1)(du + 1)
Xv,
(19)"
P,0.39776951672862454,Published as a conference paper at ICLR 2022
P,0.3986988847583643,which is trivially held by setting Xw = √
P,0.3996282527881041,"3
√dv + 1Xv.
(20)"
P,0.40055762081784385,"Normally, GMA does not consider isolated nodes (Z¨ugner et al., 2018; Z¨ugner & G¨unnemann, 2019)
hence we have dv ≥2 and Xw ∈DX. Note that we can even change Xw to make more affects to
node u with gradient information, then we may generate a more powerful perturbation in this way.
Then, we go deeper to layer 2. In layer (2):"
P,0.40148698884758366,• Clean graph:
P,0.4024163568773234,"Zi =
X"
P,0.4033457249070632,t∈N(i)∪{i}
P,0.40427509293680297,"1
√didt
Ht
(21)"
P,0.4052044609665427,• GMA:
P,0.40613382899628253,"Z′
i ="
P,0.4070631970260223,"












"
P,0.4079925650557621,"











 X"
P,0.40892193308550184,"t∈N(i) Ht
p"
P,0.40985130111524165,"dt(di + 1)
+
H′
i
di + 1 +
H′
v
p"
P,0.4107806691449814,"(dv + 1)(di + 1)
,
u ∈{u} X"
P,0.4117100371747212,"t∈N(i) Ht
p"
P,0.41263940520446096,"dt(di + 1)
+
H′
i
di + 1 +
H′
u
p"
P,0.41356877323420077,"(du + 1)(di + 1)
,
u ∈{v} X"
P,0.4144981412639405,t∈N(i)
P,0.4154275092936803,"H′
t
p"
P,0.4163568773234201,"dt(di + 1)
,
u ∈N(u) ∪N(v)"
P,0.41728624535315983,"Zu,
otherwise
(22)"
P,0.41821561338289964,• GIA:
P,0.4191449814126394,"Z′′
i ="
P,0.4200743494423792,"





"
P,0.42100371747211895,"




 X"
P,0.42193308550185876,t∈N(i)
P,0.4228624535315985,"1
p"
P,0.42379182156133827,"dt(di + 1)
Ht +
1
di + 1H′′
i +
1
p"
P,0.4247211895910781,"3(di + 1)
H′′
w,
i ∈{u, v}"
P,0.4256505576208178,"Hu,
i /∈{u, v, w}
1
√"
P,0.42657992565055763,"3(
1
√du + 1H′′
u +
1
√dv + 1H′′
v + 1
√"
P,0.4275092936802974,"3H′′
w),
i ∈{w} (23)"
P,0.4284386617100372,"Similarly, to make Z′
u = Z′′
u, we have to satisfy the following constraint:
1
du + 1H′′
u +
1
p"
P,0.42936802973977695,"3(du + 1)
H′′
w =
1
du + 1H′
i +
1
p"
P,0.43029739776951675,"(dv + 1)(du + 1)
H′
v, √"
P,0.4312267657992565,"3
du + 1 X"
P,0.43215613382899626,t∈N(u)∪{u}
P,0.43308550185873607,"1
√dt
Xt + 4"
P,0.4340148698884758,"3Xw + 1
√"
P,0.4349442379182156,"3(
1
√du + 1Xu +
1
√dv + 1Xv) =
√"
P,0.4358736059479554,"3
du + 1 X"
P,0.4368029739776952,t∈N(u)∪{u}
P,0.43773234200743494,"Xt
√dt
+
√3Xv
√dv + 1+ √"
P,0.43866171003717475,"3
√dv + 1(
X"
P,0.4395910780669145,"t∈N(v)∪{v} Xt
p"
P,0.44052044609665425,"dt(dv + 1)
+
Xu
p"
P,0.44144981412639406,"(du + 1)(dv + 1)
),"
P,0.4423791821561338,"4
3Xw + 1
√"
P,0.4433085501858736,"3(
1
√du + 1Xu +
1
√dv + 1Xv)"
P,0.44423791821561337,"=
√3Xv
√dv + 1 + √"
P,0.4451672862453532,"3
√dv + 1(
X"
P,0.44609665427509293,"t∈N(v)∪{v} Xt
p"
P,0.44702602230483274,"dt(dv + 1)
+
Xu
p"
P,0.4479553903345725,"(du + 1)(dv + 1)
), (24)"
P,0.44888475836431224,then we let Xw = 3
P,0.44981412639405205,"4(RHS −
1
√"
P,0.4507434944237918,"3(
1
√du+1Xu +
1
√dv+1Xv)) to get the solution of Xw that makes the
same perturbation. Similarly, we can infer Xw ∈DX. The following proof also applies to layer 2."
P,0.4516728624535316,Published as a conference paper at ICLR 2022
P,0.45260223048327136,"Next, we will prove that, for a linearized GNN with k layers (k ≥1), i.e., H(k) = ˆAkXΘ, once
∃Xw, such that the predictions for node u is the same to that perturbed by GMA, i.e., H(k−1)
u
=
E(k−1)
u
, then ∃X′
w, such that H(k)
u
= E(k)
u . Here we use H to denote the prediction of GNN attacked
by GMA and E for that of GIA. Note that, once the theorem holds, as we have already proven the
existence for such Xw, it naturally generalizes to an arbitrary number of layers."
P,0.45353159851301117,"To be more speciﬁc, when H(k−1)
u
= E(k−1)
u
, we need to show that, ∃Xw, s.t.,"
P,0.4544609665427509,"H(k)
u
=
X"
P,0.45539033457249073,j∈N(u)
P,0.4563197026022305,"1
√du + 1
p"
P,0.45724907063197023,"dj
H(k−1)
j
+
1
du + 1H(k−1)
u
+
1
√du + 1√dv + 1H(k−1)
v
,"
P,0.45817843866171004,"E(k)
u
=
X"
P,0.4591078066914498,j∈N(u)
P,0.4600371747211896,"1
√du + 1
p"
P,0.46096654275092935,"dj
E(k−1)
j
+
1
du + 1E(k−1)
u
+
1
√du + 1
√"
P,0.46189591078066916,"3E(k−1)
w
,"
P,0.4628252788104089,"H(k)
u
= E(k)
u . (25)"
P,0.4637546468401487,Here we make a simpliﬁcation to re-write Eq. 25 by deﬁning the inﬂuence score.
P,0.4646840148698885,"Deﬁnition E.1 (Inﬂuence Score). The inﬂuence score from node v to u after k neighbor aggregations
with a ﬁxed GNN following Eq. 1, is the weight for Xv contributing to H(k)
u :"
P,0.4656133828996282,"H(k)
u
=
X"
P,0.46654275092936803,"j∈N(u)∪{u}
Ik
uj · Xj,
(26)"
P,0.4674721189591078,which can be calculated recursively through:
P,0.4684014869888476,"Ik
uw =
X"
P,0.46933085501858735,"j∈N(u)∪{u}
(Iuj · I(k−1)
jw
) + I(k−1)
uw
.
(27)"
P,0.47026022304832715,"As Θ is ﬁxed here, we can simply regard Ik
uv = ˆAk
uv. Compared to the predictions after k-th
propagation onto the clean graph, in GMA, H(k)
u
is additionally inﬂuenced by node v, while in GIA,
H(k)
u
is additionally inﬂuenced by node v and node w. Without loss of generality, we may absorb
the inﬂuence from neighbors of node v into that of node v. Hence we can rewrite Eq. 25 as the
following:
∆H(k)
u
= Ik
GMAuvXv,"
P,0.4711895910780669,"∆E(k)
u
= Ik
GIAuvXv + Ik
GIAuwXw,"
P,0.4721189591078067,"∆H(k)
u
= ∆E(k)
u , (28)"
P,0.47304832713754646,"where
Ik
GIAuv =
X"
P,0.4739776951672863,"j∈N(u)∪{u}
IGIAuj · I(k−1)
GIAjv + IGIAuw · I(k−1)
GIAwv."
P,0.474907063197026,"Then we can further simplify it as,"
P,0.4758364312267658,"(Ik
GMAuv −Ik
GIAuv)Xv = Ik
GIAuwXw.
(29)"
P,0.4767657992565056,"To show the existence of Xw that solves the above equation, it sufﬁces to show Ik
GIAuw ̸= 0 and
Xw ∈DX. Note that ∃Xw s.t.,"
P,0.47769516728624534,"(I(k−1)
GMAuv −I(k−1)
GIAuv )Xv = I(k−1)
GIAuwXw.
(30)"
P,0.47862453531598514,"Since ˆAk ≥0, ∀k ≥0, so we have I(k−1)
GIAuw > 0. Moreover,"
P,0.4795539033457249,"Ik
uw =
X"
P,0.4804832713754647,"j∈N(u)∪{u}
( ˆAuj · ˆA(k−1)
jw
) + I(k−1)
uw
,"
P,0.48141263940520446,"then it is obvious that the Ik
uw > 0. Moreover, with the deﬁnition of Ik
uv = ˆAk
uv, it is obvious that
I(k−1)
GIAuw ≥I(k−1)
GMAuv for v with a degree not less than 1 (i.e., v is not an isolated node). Hence, we have"
P,0.48234200743494426,"(I(k−1)
GMAuv −I(k−1)
GIAuv )/I(k−1)
GIAuw ≤1 and Xw ∈DX."
P,0.483271375464684,Published as a conference paper at ICLR 2022
P,0.48420074349442377,"Now we have proved (a) holds for edge addition. For the remaining actions of GMA, we can use a
new mapping M1 that injects one node w to node u to prove (a)."
P,0.4851301115241636,"For an edge deletion of (u, v), given M1, one may rewrite Eq. 25 for the left nodes other than v, as
well as the equation involving Ik
uw, and derive the same conclusions similarly. Intuitively, for edge
deletion, considering the classiﬁcation probability, removing an edge is equivalent to enlarge the
predicted classiﬁcation probability for other classes, hence it ﬁctionalizes likewise the edge addition
and we can use a similar proof for this action."
P,0.48605947955390333,"Besides, M1 can also apply to the perturbation of features to node u or the other neighbor nodes of
u within k hops, where we inject one node w to make the same effect. In this case, we can rewrite
Eq. 25 and simplify it as following:"
P,0.48698884758364314,"∆H(k)
u
= Ik
GMAuv∆Xv,"
P,0.4879182156133829,"∆E(k)
u
= Ik
GIAuwXw,"
P,0.4888475836431227,"∆H(k)
u
= ∆E(k)
u , (31)"
P,0.48977695167286245,"where v ∈{N k(u) ∪u}, i.e., node u or its k-hop neighbor, and ∆Xv is the perturbation to the
attributes of node v. Similarly, by the deﬁnition of Ik
uv, for node v with a degree not less than 1
(i.e., v is not an isolated node), we have Ik
GIAuw ≥Ik
GMAuv, hence we have Ik
GMAuv/Ik
GIAuw ≤1 and
Xw ∈DX."
P,0.49070631970260226,"Thus, we complete the whole proof."
P,0.491635687732342,"Theorem 1 for other GNNs. We can extend Theorem 1 to other GNNs such as GCN, GraphSage,
etc. Recall the theorem 1 in Xu et al. (2018):"
P,0.49256505576208176,"Lemma 1. Given a k-layer GNN following the neighbor aggregation scheme via Eq. 1, assume that
all paths in the computation graph of the model are activated with the same probability of success
p. Then the inﬂuence distribution Ix for any node x ∈V is equivalent, in expectation, to the k-step
random walk distribution on ˜G starting at node x."
P,0.49349442379182157,"To apply Lemma 1, we observe that the deﬁnition of Ik
uw is analogous to random walk starting from
node u. Thus, one may replace the deﬁnition of Ik
uw here to the inﬂuence score deﬁned by Xu et al.
(2018), conduct a similar proof above with random walk score and obtain the same conclusions,
given the mapping M2, for each edge addition (u, v), ∃Xw, such that"
P,0.4944237918215613,"E(Lk
atk(fθ(G′
GIA))) = E(Lk
atk(fθ(G′
GIA))).
(32)"
P,0.49535315985130113,"Though the original theorem only proves Lemma 1 for GCN and GraphSage, it is obvious one can
easily extend the proof in Xu et al. (2018) for aggregation scheme as Eq. 1."
P,0.4962825278810409,Cases for Less GIA Budget. We can reduce GIA budgets in two ways.
P,0.4972118959107807,"(a) For GMA that performs both node feature perturbation and edge addition, considering a edge
perturbation (u, v), M2 essentially also applies for node feature perturbations on u or v without
additional budgets."
P,0.49814126394052044,"(b) It is very likely that with the mapping above, GIA will produce many similar nodes. Hence,
with one post-processing step to merge similar nodes together and re-optimize them again, GIA
tends to require less budgets to make the same or more harm than GMA. That is also reﬂected
in our experiments as shown in Fig. 1b."
P,0.49907063197026025,"E.2
GIA WITH PLURAL MAPPING FOR MORE GMA OPERATIONS"
P,0.5,"Here we explain how our theoretical results also apply to the remaining actions, i.e., edge deletion
and node feature perturbation, of GMA with M2 (Def. 3.2). In the proof for Theorem 1, we have
proved the existence of mappings for edge removal and node feature perturbation. Once the injected
node features are set to have the same inﬂuence to the predictions on the targets, they can be further
optimized for amplifying the damage, thus all of our theoretical results can be derived similarly like
that for edge addition operation."
P,0.5009293680297398,Published as a conference paper at ICLR 2022
P,0.5018587360594795,"E.3
PROOF FOR THEOREM 2"
P,0.5027881040892194,"Theorem 2. Given conditions in Theorem 1, consider a GIA attack, which (i) is mapped by M2
(Def. 3.2) from a GMA attack that only performs edge addition perturbations, and (ii) uses a lin-
earized GNN trained with at least one node from each class in G as the surrogate model, and (iii)
optimizes the malicious node features with PGD. Assume that G has no isolated node, and has node
features as Xu =
C
C−1eYu −
1
C−11 ∈Rd, where Yu is the label of node u and eYu ∈Rd is a one-hot
vector with the Yu-th entry being 1 and others being 0. Let the minimum similarity for any pair of
nodes connected in G be sG = min(u,v)∈E sim(Xu, Xv) with sim(Xu, Xv) =
Xu·Xv
∥Xu∥2∥Xv∥2 . For a
homophily defender gθ that prunes edges (u, v) if sim(Xu, Xv) ≤sG, we have:"
P,0.5037174721189591,"Latk(gθ(M2(G′
GMA))) −Latk(gθ(G′
GMA)) ≥0."
P,0.5046468401486989,Proof. We prove Theorem 2 by ﬁrstly show the following lemma.
P,0.5055762081784386,"Lemma 2. Given conditions in Theorem 2, as the optimization on Xw with respect to Latk by PGD
approaches, we have:
sim(Xu, Xw)(t+1) ≤sim(Xu, Xw)(t),"
P,0.5065055762081785,where t is the number of optimization steps.
P,0.5074349442379182,"We prove Lemma 2 in the follow-up section, i.e., Appendix E.4. With Lemma 2, known that GIA is
mapped from GMA with M2, Xw will be optimized to have the same effects as GMA at ﬁrst and
continue being optimized to a more harmful state, hence for the unit perturbation case as Fig. 2a, we
know:
sim(Xu, Xw) ≤sim(Xu, Xv),
(33)"
P,0.508364312267658,"as the optimization on Xw approaches. Furthermore, it follows:"
P,0.5092936802973977,"hGIA
u
≤hGMA
u
,
(34)"
P,0.5102230483271375,"where hGIA
u
and hGMA
u
denote the homophily of node u after GIA and GMA attack, respectively.
Now if we go back to the homophily defender gθ, for any threshold speciﬁed to prune the edge
(u, v), as Lemma 2 and Eq. 33 indicates, direct malicious edges in GIA are more likely to be pruned
by gθ. Let τGIA and τGMA denote the corresponding similarity between (u, w) in GIA and (u, v) in
GMA, we have several possibilities compared with sG = min(u,v)∈E sim(Xu, Xv):"
P,0.5111524163568774,"(a) τGIA ≤τGMA ≤sG: all the malicious edges will be pruned, Theorem 2 holds;"
P,0.5120817843866171,"(b) τGIA ≤sG ≤τGMA: all the GIA edges will be pruned, Theorem 2 holds;"
P,0.5130111524163569,"(c) sG ≤τGIA ≤τGMA: this is unlikely to happen, otherwise τGIA can be optimized to even worse
case, Theorem 2 holds;"
P,0.5139405204460966,"Thus, we complete our proof."
P,0.5148698884758365,"Interestingly, we can also set a speciﬁc threshold τh for homophily defender s.t., τh −sG ≤ϵ ≥0,
where some of the original edges will be pruned, too. However, some of previous works indicate
promoting the smoothness or slightly dropping some edges will bring better performance (Rong
et al., 2020; Yang et al., 2021a; Zhao et al., 2021; Yang et al., 2021b). The similar discussion can
also be applied to this case and obtain the same conclusions."
P,0.5157992565055762,"E.4
PROOF FOR LEMMA 2"
P,0.516728624535316,"Proof. To begin with, without loss of generality, we may assume the number of classes is 2 and
Yu = 0, which can be similarly extended to the case of multi-class. With the feature assignment in
the premise, let the label of node u is Yu, we have: Xu ="
P,0.5176579925650557,"(
[1, −1]T ,
Yu = 0,"
P,0.5185873605947955,"[−1, 1]T ,
Yu = 1.
(35)"
P,0.5195167286245354,Published as a conference paper at ICLR 2022
P,0.5204460966542751,"After setting it to having the same inﬂuence as that in GMA following Eq. 29, we have:"
P,0.5213754646840149,"Xw = (Ik
GMAuv −Ik
GIAuv)
Ik
GIAuw
Xv.
(36)"
P,0.5223048327137546,"Then, let Lu denote the training loss Ltrain on node u, we can calculate the gradient of Xw:"
P,0.5232342007434945,"∂Lu
∂Xu
=
∂Lu
∂H(k)
u
· ∂H(k)
u
∂Xw
=
∂Lu
∂H(k)
u
· Ik
GIAuw · Θ.
(37)"
P,0.5241635687732342,"With Cross-Entropy loss, we further have:"
P,0.525092936802974,"∂Lu
∂H(k)
u
= [−1, 1]T .
(38)"
P,0.5260223048327137,"Then, we can induce the update step of optimizing Xw with respect to Latk = −Ltrain by PGD:"
P,0.5269516728624535,"X(t+1)
w
= X(t)
w + ϵ sign(Ik
GIAuw · [−1, 1]T · Θ),
(39)"
P,0.5278810408921933,"where t is the number of update steps. As the model is trained on at least nodes with indicator
features following Eq. 35 from each class, without loss of generality, here we may assume Θ ≥0,
the optimal Θ would converge to Θ ≥0. Thus,"
P,0.5288104089219331,"sign(Ik
GIAuw · [−1, 1]T · Θ) = sign(Ik
GIAuw · [−1, 1]T )."
P,0.5297397769516728,Let us look into the change of cosine similarity between node u and node v as:
P,0.5306691449814126,"∆sim(Xu, Xw) = α(Xu · X(t+1)
w
−Xu · X(t)
w ),
(40)"
P,0.5315985130111525,"where α ≥0 is the normalized factor. To determine the sign of ∆sim(Xu, Xw), we may compare
Xu · X(t+1) with Xu · X(t)
w . Here we expand Xu · X(t+1)
w
. Let Xu0, Xu1 to denote the ﬁrst and
second element in Xu respectively, we have:"
P,0.5325278810408922,"Xu · X(t+1)
w
= Xu · Xw + ϵ sign(Ik
GIAuw · [−1, 1]T )Xu"
P,0.533457249070632,"∥Xu∥2 ·
X(t+1)
w

2 ,"
P,0.5343866171003717,"=
Xu · Xw + ϵ(Xu1 −Xu0)"
P,0.5353159851301115,"∥Xu∥2
p"
P,0.5362453531598513,"X2
w0 + X2
w1 + ϵ2 + 2ϵ(Xw1 −Xw0)
, (41)"
P,0.5371747211895911,"where we omit the sign of Ik
GIAuw for Ik
GIAuw ≥0 according to the deﬁnition. Recall that we let
Yu = 0, hence we have (Xu1 −Xu0) ≤0. Besides, following Eq. 29, we have sign(Xw1 −
Xw0) = sign(Xv1 −Xv0). As GMA tend to connect nodes from different classes, we further have
sign(Xw1 −Xw0) ≥0. Comparing to Xu · X(t)
w , we know in Eq. 41, the numerator decreases and
the denominator increases, as ϵ ≥0, so the overall scale decreases. In other words, we have:"
P,0.5381040892193308,"∆sim(Xu, Xw) = α(Xu · X(t+1)
w
−Xu · X(t)
w ) ≤0,
(42)"
P,0.5390334572490706,"which means that the cosine similarity between node u and node v decreases as the optimization of
Xw with respect to Latk processes. Thus, we complete our proof for Lemma 2."
P,0.5399628252788105,"E.5
PROOF FOR THEOREM 3"
P,0.5408921933085502,"Theorem 3. Given conditions as Theorem 2, when λ > 0, we have m(HG, HG′
HAO) ≤m(HG, HG′
GIA),
hence:
Latk(gθ(G′
HAO)) −Latk(gθ(G′
GIA)) ≤0,
where G′
HAO is generated by GIA with HAO, and G′
GIA is generated by GIA without HAO."
P,0.54182156133829,"Proof. Similar with the proof for Theorem 2, we begin with binary classiﬁcation, without loss of
generality. With the feature assignment in the premise, let the label of node u is Yu, we have: Xu ="
P,0.5427509293680297,"(
[1, −1]T ,
Yu = 0,"
P,0.5436802973977695,"[−1, 1]T ,
Yu = 1.
(43)"
P,0.5446096654275093,Published as a conference paper at ICLR 2022
P,0.5455390334572491,"Let Lu denote the training loss Ltrain on node u, we look into the gradient of Xw with respect to Lu:"
P,0.5464684014869888,"∂Lu
∂Xu
=
∂Lu
∂H(k)
u
· ∂H(k)
u
∂Xw
=
∂Lu
∂H(k)
u
· Ik
GIAuw · Θ.
(44)"
P,0.5473977695167286,"With Cross-Entropy loss, we further have:"
P,0.5483271375464684,"∂Lu
∂H(k)
u
= [−1, 1]T .
(45)"
P,0.5492565055762082,"Together with HAO, we can infer the update step of optimizing Xw with respect to
Latk = −Ltrain + λC(G, G′) by PGD:"
P,0.550185873605948,"X(t+1)
w
= X(t)
w + ϵ sign((Ik
GIAuw · [−1, 1]T + λ[1, −1]T ) · Θ),
(46)"
P,0.5511152416356877,"where t is the number of update steps. Similarly, without loss of generality, we may assume Θ ≥0.
As the optimization approaches, given λ > 0, GIA with HAO will early stop to some stage that
(Ik
GIAuw · [−1, 1]T + λ[1, −1]T ) = 0, hence similar to the proof of Theorem 2, it follows:"
P,0.5520446096654275,"hGIA
u
≤hHAO
u
,
(47)"
P,0.5529739776951673,"where hGIA
u
and hHAO
u
denote the homophily of node u after GIA and GIA with HAO attack, respec-
tively. Likewise, we can infer that:"
P,0.5539033457249071,"Latk(gθ(G′
HAO)) −Latk(gθ(G′
GIA)) ≤0."
P,0.5548327137546468,"Thus, we complete our proof."
P,0.5557620817843866,"E.6
CERTIFIED ROBUSTNESS OF HOMOPHILY DEFENDER"
P,0.5566914498141264,"Here we prove the certiﬁed robustness of homophily for a concrete GIA case. We prove via the
decision margin as follows:"
P,0.5576208178438662,"Deﬁnition E.2 (Decision Margin). Given a k-layer GNN, let H(k)
[u,c] denote the corresponding entry"
P,0.5585501858736059,"in H(k)
u
for the class c, the decision margin on node u with class label Yu can be denoted by:"
P,0.5594795539033457,"mu = H(k)
[u,yu] −
max
c∈{0,..,C−1} H(k)
[u,c]."
P,0.5604089219330854,"A Multi-Layer Perceptron (MLP) can be taken as a 0-layer GNN which the deﬁnition also applies.
Then, we specify the certiﬁed robustness as follows:"
P,0.5613382899628253,"Proposition E.1 (Certiﬁed Robustness of Homophily Defender). Consider a direct GIA attack uses
a linearized GNN trained with at least one node from each class in G, that targets at node u by
injecting a node w connecting to u, let node features xu =
C
C−1onehot(Yu) −
1
C−11, the homophily
of u be τ, the decision margin of a MLP on u be γ, the minimum similarity for any pair of nodes
connected in the original graph be sG = min(u,v)∈E sim(Xu, Xv), homophily defender gθ can
defend such attacks, if −α
1
√"
P,0.5622676579925651,"1+1/du (τ + βγ) ≤sG, and gθ prunes edges (u, v) s.t.,"
P,0.5631970260223048,"sim(Xu, Xw) ≤−α s"
P,0.5641263940520446,"1
1 + 1/du
(τ + βγ),"
P,0.5650557620817844,"where α, β ≥0 are corresponding normalization factors."
P,0.5659851301115242,"Intuitively, effective attacks on a node with higher degrees, homophily or decision margin require a
lower similarity between node w and u hence more destruction to the homophily of node u. GIA
without any constraints tends to optimize sim(Xu, Xw) to a even lower value. Thus, it becomes
easier to ﬁnd a suitable condition for gθ, with which it can painlessly prune all vicious edges while
keeping all original edges."
P,0.5669144981412639,Published as a conference paper at ICLR 2022
P,0.5678438661710037,"Proof. Analogous to the proof for Lemma 2, without loss of generality, we begin with binary clas-
siﬁcation, normalized indicator features and Yu = 0 as follows: Xu ="
P,0.5687732342007435,"(
[1, −1]T ,
Yu = 0,"
P,0.5697026022304833,"[−1, 1]T ,
Yu = 1.
(48)"
P,0.570631970260223,The decision margin based on k-th layer representation can be denoted by
P,0.5715613382899628,"m = H(k)
[u,yu] −
max
c∈{0,..,C−1} H(k)
[u,c],
(49)"
P,0.5724907063197026,"follows the Deﬁnition E.2. In our binary classiﬁcation case, we have"
P,0.5734200743494424,"γ = H(0)
[u,0] −H(0)
[u,1],
(50)"
P,0.5743494423791822,"where H(0) is the output of a 0-layer GNN, or MLP (Multi-Layer Perceptron). A k-layer GNN can
be regarded as generating new hidden representation for node u by aggregating its neighbors, hence,
we may induce the decision margin for a k-layer GNN at node u as"
P,0.5752788104089219,"m = H(k)
[u,0] −H(k)
[u,1] = ([
X"
P,0.5762081784386617,"j∈N(u)
IujXj][0] −[
X"
P,0.5771375464684015,"j∈N(u)
IujXj][1]) + I(k)
uu γ,
(51)"
P,0.5780669144981413,"where we can replace the inﬂuence from neighbors with homophily of node u. Observe that hu
essentially indicates how much neighbors of node u contribute to H(k)
[u,0], for example, in binary
case, let ζ > 0 be the corresponding normalization factor,"
P,0.578996282527881,hu = 1
P,0.5799256505576208,"ζ ([
X"
P,0.5808550185873605,"j∈N(u)
IujXj][0][Xu][0] + [
X"
P,0.5817843866171004,"j∈N(u)
IujXj][1][Xu][1]),"
P,0.5827137546468402,"which means, [
X"
P,0.5836431226765799,"j∈N(u)
IujXj][1] =
1
[Xu][1]
(ζhu −[
X"
P,0.5845724907063197,"j∈N(u)
IujXj][0][Xu][0]),"
P,0.5855018587360595,"replaced with Xu = [1, −1]T ,"
P,0.5864312267657993,"m = H(k)
[u,0] −H(k)
[u,1]"
P,0.587360594795539,"= ([
X"
P,0.5882899628252788,"j∈N(u)
IujXj][0] −[
X"
P,0.5892193308550185,"j∈N(u)
IujXj][1])+"
P,0.5901486988847584,"= ([
X"
P,0.5910780669144982,"j∈N(u)
IujXj][0] −
1
[Xu][1]
(ζhu −[
X"
P,0.5920074349442379,"j∈N(u)
IujXj][0][Xu][0])) + I(k)
uu γ"
P,0.5929368029739777,"= ζhu + I(k)
uu γ. (52)"
P,0.5938661710037175,"Hence, we have:
m = H(k)
[u,0] −H(k)
[u,1] = ζhu + I(k)
uu γ,"
P,0.5947955390334573,"where ζ ≥0 is the factor of hu. With node w injected, the margin can be rewritten as: m′ = r"
P,0.595724907063197,"du
du + 1m + I(k)
uw(X[w,0] −X[w,1]).
(53)"
P,0.5966542750929368,"To perturb the prediction of node u, we make m ≤0, hence, we have m′ = r"
P,0.5975836431226765,"du
du + 1m + I(k)
uw(X[w,0] −X[w,1]) ≤0,"
P,0.5985130111524164,"I(k)
uw(X[w,1] −X[w,0]) ≥ r"
P,0.5994423791821561,"du
du + 1m,"
P,0.6003717472118959,"(X[w,1] −X[w,0]) ≥
1"
P,0.6013011152416357,"I(k)
uw r"
P,0.6022304832713755,"du
du + 1(ζhu + I(k)
uu γ). (54)"
P,0.6031598513011153,Published as a conference paper at ICLR 2022
P,0.604089219330855,"Observe that sim(Xu, Xw) = (X[w,0] −X[w,1]) and hu = τ, hence, we can write Eq. 54 in a clean
form as"
P,0.6050185873605948,"sim(Xu, Xw) ≤−α r"
P,0.6059479553903345,"du
du + 1(τ + βγ),
(55)"
P,0.6068773234200744,"where α, β are corresponding normalization factors whose signs are determined by signs of Ik
uw
and Ik
uu respectively. In other words, GIA has to optimize Xw satisfying the above requirement
to make the attack effective, however, given the premise that all sG = min(u,v)∈E sim(Xu, Xv) ≥ −α
q"
P,0.6078066914498141,"du
du+1(τ + βγ), a defense model gθ will directly prune all of the vicious edges satisfying the
above requirement and make the attack ineffective, which is exactly what we want to prove."
P,0.6087360594795539,"F
MORE IMPLEMENTATIONS OF HOMOPHILY DEFENDER"
P,0.6096654275092936,"There are many ways to design homophily defenders, inheriting the spirit of recovering the origi-
nal homophily. In addition to edge pruning, one could leverage variational inference to learn the
homophily distribution or the similarity distribution among neighbors. Then we use adversarial
training to train the model to denoise. Similarly, learning to promote the smoothness of the graph
can also be leveraged to build homophily defenders (Zhao et al., 2021; Yang et al., 2021a;b). Be-
sides, outlier detection can also be adopted to remove or reduce the aggregation weights of malicious
edges or nodes. In the following two subsections, we will present two variants that perform better
than GNNGuard (Zhang & Zitnik, 2020)."
P,0.6105947955390335,"F.1
DETAILS OF EFFICIENT GNNGUARD"
P,0.6115241635687733,"The originally released GNNGuard requires O(n2) computation for node-node similarity, making it
prohibitive to run on large graphs. To this end, we implement an efﬁcient alternative of GNNGuard
adopting a similar message passing scheme, let τ be the threshold to prune an edge:"
P,0.612453531598513,"H(k)
u
= σ(Wk ·
X"
P,0.6133828996282528,"j∈N(u)∪{u}
αujH(k−1)
j
),
(56)"
P,0.6143122676579925,"where
αuj = softmax(
zuj
P"
P,0.6152416356877324,"v∈N(u)∪{u} zuv
), and zuj ="
P,0.6161710037174721,"




"
P,0.6171003717472119,"



"
P,0.6180297397769516,"1{sim(H(k−1)
j
, H(k−1)
u
) > τ} · sim(H(k−1)
j
· H(k−1)
u
)
P"
P,0.6189591078066915,"v∈N(u) 1{sim(H(k−1)
v
, H(k−1)
u
) > τ} · sim(H(k−1)
v
, H(k−1)
u
)
,
u ̸= j,"
P,0.6198884758364313,"1
P"
P,0.620817843866171,"v∈N(u) 1{sim(H(k−1)
v
· H(k−1)
u
) > τ} + 1
u = j."
P,0.6217472118959108,"Essentially, it only requires O(E) complexity. We will present the performance of Efﬁcient GNN-
Guard (EGNNGuard) in table 3."
P,0.6226765799256505,"F.2
DETAILS OF ROBUST GRAPH ATTENTION NETWORK (RGAT)"
P,0.6236059479553904,"We introduce another implementation of Robust Graph Attention Network (RGAT). We adopt the
same spirit of GCNGuard (Zhang & Zitnik, 2020), that eliminates unlike neighbors during message
passing based on neighbor similarity. Speciﬁcally, we change the standard GAT (Veliˇckovi´c et al.,
2018) attention mechanism as"
P,0.6245353159851301,"αi,j =
1{sim(xi, xj) ≥τ}
P"
P,0.6254646840148699,"k∈N(i)∪{i} 1{sim(xi, xk) ≥τ},"
P,0.6263940520446096,"Additionally, we also adopt the idea of RobustGCN (Zhu et al., 2019) that stabilize the hidden
representations between layers, so we add Layer Normalization (Ba et al., 2016) among layers of
RGAT. Empirical experiments show that RGAT is a more robust model with or without GIA attacks.
For more details, we refer readers to Table 3."
P,0.6273234200743495,Published as a conference paper at ICLR 2022
P,0.6282527881040892,Table 3: Performance of homophily defenders used in experiments
P,0.629182156133829,"Model
Natural Accuracy
Test Robustness
Running Time"
P,0.6301115241635687,"GNNGuard
83.58
64.96
1.76 × 10−3"
P,0.6310408921933085,"EGNNGuard
84.45
64.27
5.39 × 10−5"
P,0.6319702602230484,"RGAT
85.75
66.57
6.03 × 10−5"
P,0.6328996282527881,"GCN
84.99
36.62
5.87 × 10−5"
P,0.6338289962825279,"F.3
PERFORMANCE OF HOMOPHILY DEFENDERS"
P,0.6347583643122676,"We test the performance of different homophily defenders on Cora. Natural Accuracy refers to the
test accuracy on clean graph. Test Robustness refers to their averaged performance against all the
attacks. Running time refers to their averaged running time for one training epoch. We repeat the
evaluation 10 times to obtain the average accuracy. We can see that EGNNGuard has competitive
performance with GNNGuard while 20× faster. RGAT performs slightly better and 10× faster.
Hence, for large graphs and adversarial training of GNNGuard, we will use EGNNGuard instead."
P,0.6356877323420075,"G
MORE DETAILS ABOUT ALGORITHMS USED"
P,0.6366171003717472,Here we provide detailed descriptions of algorithms mentioned in Section. 4.2.
P,0.637546468401487,"G.1
DETAILS OF METAGIA AND AGIA"
P,0.6384758364312267,"G.1.1
INDUCTION OF META GRADIENTS FOR METAGIA"
P,0.6394052044609665,"With the bi-level optimization formulation of GIA, similar to meta-attack, we can infer the meta-
gradients as follows:"
P,0.6403345724907064,"∇meta
Aatk
= ∇AatkLatk(fθ∗(Aatk, X∗
atk)),
X∗
atk = optXatkLatk(fθ∗(Aatk, Xatk)).
(57)"
P,0.6412639405204461,"Consider the opt process, we have"
P,0.6421933085501859,"X(t+1)
atk
= X(t)
atk −α∇X(t)
atk Latk(fθ∗(Aatk, X(t)
atk )).
(58)"
P,0.6431226765799256,"With that, we can derive the meta-gradient for Aatk:"
P,0.6440520446096655,"∇meta
Aatk = ∇AatkLatk(fθ∗(Aatk, X∗
atk))"
P,0.6449814126394052,"= ∇XatkLatk(fθ∗(Aatk, X(t)
atk )) · [∇Aatkfθ∗(Aatk, X(t)
atk ) + ∇X(t)
atk fθ∗(Aatk, X(t)
atk ) · ∇AatkX(t)
atk ],
(59)
where
∇AatkX(t+1)
atk
= ∇AatkX(t)
atk −α∇Aatk∇X(t)
atk Latk(fθ∗(Aatk, X(t)
atk )).
(60)"
P,0.645910780669145,"Note that X(t)
atk depends on Aatk according to Eq. 58, so the derivative w.r.t. Aatk need to be traced
back. Finally, the update schema for Aatk is as follows:"
P,0.6468401486988847,"A(t+1)
atk
= A(t)
atk −β∇meta
A(t)
atk .
(61)"
P,0.6477695167286245,"Directly computing the meta gradients is expensive, following Metattack, we adopt approximations
like MAML (Finn et al., 2017) for efﬁciency consideration. We refer readers to the paper of Metat-
tack for the detailed algorithms by replacing the corresponding variables with those above."
P,0.6486988847583643,"G.2
DETAILS OF AGIA"
P,0.6496282527881041,"For optimizing weights of edge entries in Aatk, we can use either Adam (Kingma & Ba, 2015),
PGD (Madry et al., 2018) or other optimization methods leveraging gradients. For simplicity, we
use PGD to illustrate the algorithm description of AGIA as follows:"
P,0.6505576208178439,Published as a conference paper at ICLR 2022
P,0.6514869888475836,"Algorithm 1: AGIA: Adaptive Graph Injection Attack with Gradient
Input: A graph G = (A, X), a trained GNN model fθ∗, number of injected nodes c, degree
budget b, outer attack epochs eouter, inner attack epochs for node features and adjacency
matrix eX
inner, eA
inner, learning rate η, weight for sparsity penalty β, weight for homophily
penalty λ ;
Output: Perturbed graph G′ = (A′, X′);"
P,0.6524163568773235,"1 Random initialize injection parameters (Aatk, Xatk);"
P,0.6533457249070632,"2 Yorig ←fθ∗(A, X) ;
/* Obtain original predictions on clean graph */"
P,0.654275092936803,3 for epoch ←0 to eouter do
P,0.6552044609665427,"4
Random initialize Xatk;"
P,0.6561338289962825,"5
for epoch ←0 to eX
inner do"
P,0.6570631970260223,"6
A′ ←A ∥Aatk, X′ ←X ∥Xatk ;"
P,0.6579925650557621,"7
Xatk ←Clip(xmin,xmax)(Xatk −η · ∇Xatk(Lh
atk)) ;"
P,0.6589219330855018,"8
for epoch ←0 to eA
inner do"
P,0.6598513011152416,"9
A′ ←A ∥Aatk, X′ ←X ∥Xatk ;"
P,0.6607806691449815,"10
Aatk ←Clip(0,1)(Aatk −η · ∇Aatk(LA
atk)) ;"
P,0.6617100371747212,"11
Aatk ←fk
i=1 arg maxtop b(Aatk[i,:]) ;"
P,0.662639405204461,"Here, Lh
atk refers to the objective of GIA with HAO for the optimization of Xatk. For the optimization
of Aatk, we empirically ﬁnd the λA would degenerate the performance, which we hypothesize that
is because of the noises as Aatk is a discrete variable. Hence, we set λA = 0 in our experiments.
Additionally, we introduce a sparsity regularization term for the optimization of Aatk:"
P,0.6635687732342007,"LA
atk = Latk + β
1
|Vatk| X"
P,0.6644981412639405,"u∈Vatk
|b −∥Aatku,:∥1|.
(62)"
P,0.6654275092936803,"Besides, we empirically observe that Adam performs better than PGD. Hence, we would use Adam
for AGIA in our experiments, and leave other methods for future work. Adopting Adam addition-
ally brings the beneﬁts to utilize momentum and history information to accelerate the optimization
escape from the local optimum, which PGD fails to achieve."
P,0.6663568773234201,"G.3
DETAILS OF SEQGIA"
P,0.6672862453531598,"Since gradient methods require huge computation overhead, we propose a novel divide-and-conquer
strategy to iteratively select some of the most vulnerable targets with Eq. 11 to attack. Note that it is
different from traditional sequential injection methods which still connect the targets in full batch."
P,0.6682156133828996,Published as a conference paper at ICLR 2022
P,0.6691449814126395,"For simplicity, we also illustrate the algorithm with PGD, and one may switch to other optimizer
such as Adam to optimize Aatk. The detailed algorithm is as follows:"
P,0.6700743494423792,"Algorithm 2: SeqGIA: Sequential Adaptive Graph Injection Attack
Input: A graph G = (A, X), a trained GNN model fθ∗, number of injected nodes k, degree
budget b, outer attack epochs eouter, inner attack epochs for node features and adjacency
matrix eX
inner, eA
inner, learning rate η, weight for sparsity penalty β, weight for homophily
penalty λ, sequential step for vicious nodes γatk, sequential step for target nodes γc ;
Output: Perturbed graph G′ = (A′, X′);"
P,0.671003717472119,"1 Initialize injection parameters (Aatk, Xatk);"
P,0.6719330855018587,"2 Yorig ←fθ∗(A, X) ;
;
/* Obtain original predictions on clean graph */"
WHILE NOT INJECTING ALL NODES DO,0.6728624535315985,3 while Not Injecting All Nodes do
WHILE NOT INJECTING ALL NODES DO,0.6737918215613383,"4
natk ←γatk ∗|Vatk|; nc ←γc ∗|Vc| ;"
WHILE NOT INJECTING ALL NODES DO,0.6747211895910781,"5
Ranking and selecting nc targets with Eq. 11;"
WHILE NOT INJECTING ALL NODES DO,0.6756505576208178,"6
Random initialize A(cur)
atk
∈Rnc×natk, X(cur)
atk
∈Rnatk×d ;"
WHILE NOT INJECTING ALL NODES DO,0.6765799256505576,"7
for epoch ←0 to eouter do"
WHILE NOT INJECTING ALL NODES DO,0.6775092936802974,"8
for epoch ←0 to eX
inner do"
WHILE NOT INJECTING ALL NODES DO,0.6784386617100372,"9
A′ ←A ∥Aatk ∥A(cur)
atk , X′ ←X ∥Xatk ∥X(cur)
atk ;"
WHILE NOT INJECTING ALL NODES DO,0.679368029739777,"10
X(cur)
atk
←Clip(xmin,xmax)(X(cur)
atk
−η · ∇X(cur)
atk (Lh
atk)) ;"
WHILE NOT INJECTING ALL NODES DO,0.6802973977695167,"11
for epoch ←0 to eA
inner do"
WHILE NOT INJECTING ALL NODES DO,0.6812267657992565,"12
A′ ←A ∥Aatk ∥A(cur)
atk , X′ ←X ∥Xatk ∥X(cur)
atk ;"
WHILE NOT INJECTING ALL NODES DO,0.6821561338289963,"13
A(cur)
atk
←Clip(0,1)(A(cur)
atk
−η · ∇A(cur)
atk (LA
atk)) ;"
WHILE NOT INJECTING ALL NODES DO,0.6830855018587361,"14
A(cur)
atk
←fnatk
i=1 arg maxtop b(A(cur)
atk[i,:]) ;"
WHILE NOT INJECTING ALL NODES DO,0.6840148698884758,"15
Aatk=Aatk ∥A(cur)
atk ; Xatk=Xatk ∥X(cur)
atk ;"
WHILE NOT INJECTING ALL NODES DO,0.6849442379182156,"Actually, one may also inject few nodes via heuristic based algorithms ﬁrst, then inject the left nodes
with gradients sequentially. Assume that α nodes are injected by heuristic, we may further optimize
the complexity from O( 1"
WHILE NOT INJECTING ALL NODES DO,0.6858736059479554,"γatk
(|Vc| log |Vc| + eouter(eA
inner|Vc|γc|Vatk| + eX
inner|Vatk|d))NVc)"
WHILE NOT INJECTING ALL NODES DO,0.6868029739776952,"to
O(α 1"
WHILE NOT INJECTING ALL NODES DO,0.6877323420074349,"γatk
(|Vc| log |Vc|+|Vatk|b + eX
inner|Vatk|d)NVc+"
WHILE NOT INJECTING ALL NODES DO,0.6886617100371747,(1 −α) 1
WHILE NOT INJECTING ALL NODES DO,0.6895910780669146,"γatk
(|Vc| log |Vc|+eouter(eA
inner|Vc|γc|Vatk| + eX
inner|Vatk|d))NVc)"
WHILE NOT INJECTING ALL NODES DO,0.6905204460966543,in Table 7.
WHILE NOT INJECTING ALL NODES DO,0.6914498141263941,"H
MORE DETAILS ABOUT THE EXPERIMENTS"
WHILE NOT INJECTING ALL NODES DO,0.6923791821561338,"H.1
STATISTICS AND BUDGETS OF DATASETS"
WHILE NOT INJECTING ALL NODES DO,0.6933085501858736,"Here we provide statistics of datasets used in the experiments as Sec. 5.1. The label homophily
utilizes the previous homophily deﬁnition (Zhu et al., 2020), while the avg. homophily utilizes the
node-centric homophily based on node similarity."
WHILE NOT INJECTING ALL NODES DO,0.6942379182156134,"Following previous works (Zou et al., 2021; Zheng et al., 2021), we heuristically specify the budgets
for each dataset according to the the number of target nodes and average degrees."
WHILE NOT INJECTING ALL NODES DO,0.6951672862453532,"For targeted attack, we follow previous works (Z¨ugner et al., 2018) to select 800 nodes as targets
according to the classiﬁcation margins of the surrogate model. Speciﬁcally, we select 200 nodes with
the highest classiﬁcation margin, 200 nodes with lowest classiﬁcation margin and 400 randomly.
For the budgets, we scale down the number of injected nodes and the maximum allowable degrees
accordingly."
WHILE NOT INJECTING ALL NODES DO,0.6960966542750929,Published as a conference paper at ICLR 2022
WHILE NOT INJECTING ALL NODES DO,0.6970260223048327,Table 4: Statistics of datasets
WHILE NOT INJECTING ALL NODES DO,0.6979553903345725,"Datasets
Nodes
Edges
Classes
Avg. Degree
Label Homophily
Avg. Homophily"
WHILE NOT INJECTING ALL NODES DO,0.6988847583643123,"Cora
2680
5148
7
3.84
0.81
0.59
Citeseer
3191
4172
6
2.61
0.74
0.90
Computers
13, 752
245, 861
10
35.76
0.77
0.31
Arxiv
169, 343
1, 166, 243
40
13.77
0.65
0.86
Aminer
659, 574
2, 878, 577
18
8.73
0.65
0.38
Reddit
232, 965
11, 606, 919
41
99.65
0.78
0.31"
WHILE NOT INJECTING ALL NODES DO,0.699814126394052,Table 5: Budgets for non-targeted attacks on different datasets
WHILE NOT INJECTING ALL NODES DO,0.7007434944237918,"Datasets
Nodes
Degree
Node Per.(%)
Edge Per.(%)"
WHILE NOT INJECTING ALL NODES DO,0.7016728624535316,"Cora
60
20
2.24%
23.31%
Citeseer
90
10
2.82%
21.57%
Computers
300
150
2.18%
18.30%
Arxiv
1500
100
0.71%
10.29%"
WHILE NOT INJECTING ALL NODES DO,0.7026022304832714,Table 6: Budgets of targeted attacks on different datasets
WHILE NOT INJECTING ALL NODES DO,0.7035315985130112,"Datasets
Nodes
Degree
Node Per.(%)
Edge Per.(%)"
WHILE NOT INJECTING ALL NODES DO,0.7044609665427509,"Computers
100
150
0.73%
6.1%
Arxiv
120
100
0.07%
1.03%
Aminer
150
50
0.02%
0.26%
Reddit
300
100
0.13%
0.26%"
WHILE NOT INJECTING ALL NODES DO,0.7053903345724907,"H.2
ADDITIONAL DISCUSSIONS ABOUT ATTACK BASELINES"
WHILE NOT INJECTING ALL NODES DO,0.7063197026022305,"For the selection of attack baselines, from the literature reviews (Sun et al., 2018; Jin et al., 2021),
existing reinforcement learning (RL) based approaches adopt different settings from ours, which
either focus on the poisoning attack, transductive learning, edge perturbation or other application
tasks. Even for NIPA (Sun et al., 2020) which has the closest setting to ours, since it focuses on
poisoning and transductive attack, and the features of the injected nodes are generated heuristically
according to the labels assigned by the RL agent, without author released code, the adaption requires
lots of efforts including redesigning the markov decision process in NIPA, hence we would like to
leave them for future work. More discussions on RL based future works are given in Appendix A.2."
WHILE NOT INJECTING ALL NODES DO,0.7072490706319703,"H.3
COMPLEXITY OF ALGORITHMS"
WHILE NOT INJECTING ALL NODES DO,0.70817843866171,"Here we provide complexity analyses of the GIA algorithms used in the experiments as discussed
and selected in Sec. 5.1. As also deﬁned in algorithm description section from Appendix G, eX
inner is
the number of epochs optimized for node features, b is the number of maximum degree of vicious
nodes, d is the number of feature dimension, NVc is the number of k-hop neighbors of the victim
nodes for perform one forwarding of a k-layer GNN, eouter is the number of epochs for optimizing
Aatk, γc is the ratio of target nodes to attack in one batch, γatk is the ratio of vicious nodes to inject
in one batch."
WHILE NOT INJECTING ALL NODES DO,0.7091078066914498,"H.4
DETAILS OF DEFENSE BASELINES"
WHILE NOT INJECTING ALL NODES DO,0.7100371747211895,"Here we provide the categories of defense models used in the experiments as Sec. 5.1. We categorize
all models into Vanilla, Robust and Extreme Robust (Combo). Basically, popular GNNs are belong
to vanilla category, robust GNNs are belong to robust categorty, and a robust trick will enhance the
robust level by one to the next Category. Consistenly to the observation in GRB (Zheng et al., 2021),
we ﬁnd adding Layer Normalization (Ba et al., 2016) before or between convulotion layers can
enhance the model robustness. We use LN to denote adding layer norm before the ﬁrst convulotion
layer and LNi to denote adding layer norm between convulotion layers."
WHILE NOT INJECTING ALL NODES DO,0.7109665427509294,Published as a conference paper at ICLR 2022
WHILE NOT INJECTING ALL NODES DO,0.7118959107806692,Table 7: Complexity of various attacks
WHILE NOT INJECTING ALL NODES DO,0.7128252788104089,"Type
Algorithm
Time Complexity
Space Complexity"
WHILE NOT INJECTING ALL NODES DO,0.7137546468401487,Gradient
WHILE NOT INJECTING ALL NODES DO,0.7146840148698885,"MetaGIA
O(|Vatk|b(|Vc||Vatk| log(|Vc||Vatk|) + eX
innerd(|Vatk| + NVc)))
O(|Vc||Vatk| + eX
innerd(|Vatk| + NVc))"
WHILE NOT INJECTING ALL NODES DO,0.7156133828996283,"AGIA
O(eouter(eA
inner|Vc||Vatk| + (eA
inner + eX
inner)d(NVc + |Vatk|)))
O(|Vc||Vatk| + eX
innerd(|Vatk| + NVc))"
WHILE NOT INJECTING ALL NODES DO,0.716542750929368,"AGIA-SeqGIA
O(eouter(|Vc| log(|Vc|) + eA
innerγc|Vc||Vatk| + (eA
inner + eX
inner)d(NVc + |Vatk|)))
O(γc|Vc|γatk|Vatk| + eX
innerd(|Vatk| + NVc))"
WHILE NOT INJECTING ALL NODES DO,0.7174721189591078,Heuristic
WHILE NOT INJECTING ALL NODES DO,0.7184014869888475,"PGD
O(|Vatk|b + eX
innerd(|Vatk| + NVc))
O(|Vatk|b + eX
innerd(|Vatk| + NVc))"
WHILE NOT INJECTING ALL NODES DO,0.7193308550185874,"TDGIA
O((|Vc| log |Vc| + |Vatk|b + eX
innerd(|Vatk| + NVc))
O(|Vatk|b + eX
innerd(|Vatk| + NVc))"
WHILE NOT INJECTING ALL NODES DO,0.7202602230483272,"ATDGIA
O(|Vc| log |Vc| + |Vatk|b + eX
innerd(|Vatk| + NVc))
O(|Vatk|b + eX
innerd(|Vatk| + NVc))"
WHILE NOT INJECTING ALL NODES DO,0.7211895910780669,Table 8: Defense model categories
WHILE NOT INJECTING ALL NODES DO,0.7221189591078067,"Model
Category
Model
Category
Model
Category
Model
Category"
WHILE NOT INJECTING ALL NODES DO,0.7230483271375465,"GCN
Vanilla
GCN+LN
Robust
GCN+LNi
Robust
GCN+FLAG
Robust"
WHILE NOT INJECTING ALL NODES DO,0.7239776951672863,"GCN+LN+LNi
Combo
GCN+FLAG+LN
Combo
GCN+FLAG+LNi
Combo
GCN+FLAG+LN+LNi
Combo"
WHILE NOT INJECTING ALL NODES DO,0.724907063197026,"Sage
Vanilla
Sage+LN
Robust
Sage+LNi
Robust
Sage+FLAG
Robust"
WHILE NOT INJECTING ALL NODES DO,0.7258364312267658,"Sage+LN+LNi
Combo
Sage+FLAG+LN
Combo
Sage+FLAG+LNi
Combo
Sage+FLAG+LN+LNi
Combo"
WHILE NOT INJECTING ALL NODES DO,0.7267657992565055,"GAT
Vanilla
GAT+LN
Robust
GAT+LNi
Robust
GAT+FLAG
Robust"
WHILE NOT INJECTING ALL NODES DO,0.7276951672862454,"GAT+LN+LNi
Combo
GAT+FLAG+LN
Combo
GAT+FLAG+LNi
Combo
GAT+FLAG+LN+LNi
Combo"
WHILE NOT INJECTING ALL NODES DO,0.7286245353159851,"Guard
Robust
Guard+LN
Combo
Guard+LNi
Combo
EGuard+FLAG
Combo"
WHILE NOT INJECTING ALL NODES DO,0.7295539033457249,"Guard+LN+LNi
Combo
EGuard+FLAG+LN
Combo
EGuard+FLAG+LNi
Combo
EGuard+FLAG+LN+LNi
Combo"
WHILE NOT INJECTING ALL NODES DO,0.7304832713754646,"RGAT
Robust
RGAT+LN
Combo
RGAT+FLAG
Combo
RGAT+FLAG+LN
Combo"
WHILE NOT INJECTING ALL NODES DO,0.7314126394052045,"RobustGCN
Robust
RobustGCN+FLAG
Combo"
WHILE NOT INJECTING ALL NODES DO,0.7323420074349443,"H.5
DETAILS OF EVALUATION AND MODEL SETTINGS"
WHILE NOT INJECTING ALL NODES DO,0.733271375464684,"H.5.1
MODEL SETTING"
WHILE NOT INJECTING ALL NODES DO,0.7342007434944238,"By default, all GNNs used in our experiments have 3 layers, a hidden dimension of 64 for Cora,
Citeseer, and Computers, a hidden dimension of 128 for the rest medium to large scale graphs.
We also adopt dropout (Srivastava et al., 2014) with dropout rate of 0.5 between each layer. The
optimizer we used is Adam (Kingma & Ba, 2015) with a learning rate of 0.01. By default, we set
total training epochs as 400 and employ the early stop of 100 epochs according to the validation
accuracy. For the set of threshold in homophily defenders, we use PGD (Madry et al., 2018) to ﬁnd
the threshold which performs well on both the clean data and perturbed data. By default, we set
the threshold as 0.1, while for Computers and Reddit, we use 0.15 for Guard and EGuard, and for
Citeseer and Arxiv we use 0.2 for RGAT."
WHILE NOT INJECTING ALL NODES DO,0.7351301115241635,"For adversarial training with FLAG (Kong et al., 2020), we set the step size be 1 × 10−3, and train
100 steps for Cora, 50 steps for Citeseer, 10 steps for the rest datasets. We empirically observe
that FLAG can enhance both the natural accuracy and robustness of GNNs. We refer readers to the
results for more details in Sec. J.1 and Sec. J.2."
WHILE NOT INJECTING ALL NODES DO,0.7360594795539034,"H.5.2
EVALUATION SETTING"
WHILE NOT INJECTING ALL NODES DO,0.7369888475836431,"For ﬁnal model selection, we select the ﬁnal model with best validation accuracy. For data splits,
we follow the split methods in GRB (Zheng et al., 2021) which splits the datasets according to the
node degrees, except for non-targeted attack on Arxiv where we use the ofﬁcial split to probe the
performances of various methods in a natural setting. For non-targeted attack, following previous
works (Zou et al., 2021; Zheng et al., 2021), we select all test nodes as targets. While for targeted
attacks, we follow previous works (Z¨ugner et al., 2018) to select 200 nodes with highest classiﬁca-
tion margin and lowest classiﬁcation margin of the surrogate model. Then we randomly select 400
nodes as targets. In other words, there are 800 target nodes in total for targeted attack. Note for tar-
geted attack, the natural accuracy on the target nodes might be different from normal test accuracy."
WHILE NOT INJECTING ALL NODES DO,0.7379182156133829,Published as a conference paper at ICLR 2022
WHILE NOT INJECTING ALL NODES DO,0.7388475836431226,"We also follow previous works to specify the attack budgets as Table. 5 for non-targeted attack and
Table. 6 for targeted attack."
WHILE NOT INJECTING ALL NODES DO,0.7397769516728625,"During evaluation, we follow the black-box setting. Speciﬁcally, we ﬁrstly use the surrogate model
to generate the perturbed graph, then we let the target models which has trained on the clean graph
to test on the perturbed graph. We repeat the evaluation for 10 times on Cora, Citeseer, Computers,
and Arxiv, and 5 times for Aminer and Reddit since model performs more stably on large graphs.
Then we report mean test accuracy of the target models on the target nodes and omit the variance
due to the space limit."
WHILE NOT INJECTING ALL NODES DO,0.7407063197026023,"H.5.3
ATTACKS SETTING"
WHILE NOT INJECTING ALL NODES DO,0.741635687732342,"By default, we use PGD (Madry et al., 2018) to generate malicious node features. The learning step
is 0.01 and the default training epoch is 500. We also employ the early stop of 100 epochs according
to the accuracy of the surrogate model on the target nodes. While for heuristic approaches such as
TDGIA (Zou et al., 2021) and ATDGIA, we follow the setting of TDGIA to update the features.
Empirically, we ﬁnd the original TDGIA feature update suits better for heuristic approaches while
they show no advance over PGD for other approaches. Besides, as Table 7 shows, MetaGIA requires
huge amount of time originally. Thus, to scale up, we use a batch update which updates the injected
edges by a step size of b, i.e., the maximum degree of injected nodes, and limit the overall update
epochs by |Vatk|/6, where we empirically observe this setting performs best in Cora hence we stick
it for the other datasets."
WHILE NOT INJECTING ALL NODES DO,0.7425650557620818,"For the setting of λ for HAO, we search the parameters within 0.5 to 8 by a step size of 0.5 such
that the setting of λ will not degenerate the performance of the attacks on surrogate model. Besides
heuristic approaches, we additionally use a hinge loss to stabilize the gradient information from
Latk and C(G, G′), where the former can be too large that blurs the optimization direction of the
latter. Take Cross Entropy with log softmax as an example, we adopt the following to constrict the
magnitude of Latk:"
WHILE NOT INJECTING ALL NODES DO,0.7434944237918215,"Latk[u] = (−H(k)
[u,Yu]) · 1{
exp(H(k)
[u,Yu])
P"
WHILE NOT INJECTING ALL NODES DO,0.7444237918215614,"i exp(H(k)
[u,i])
≥τ}"
WHILE NOT INJECTING ALL NODES DO,0.7453531598513011,"+ log(
X"
WHILE NOT INJECTING ALL NODES DO,0.7462825278810409,"i
exp(H(k)
[u,i] · 1{
exp(H(k)
[u,i])
P"
WHILE NOT INJECTING ALL NODES DO,0.7472118959107806,"j exp(H(k)
[u,j])
≥τ})), (63)"
WHILE NOT INJECTING ALL NODES DO,0.7481412639405205,"where 1{
exp(H(k)
[u,Yu])
P"
WHILE NOT INJECTING ALL NODES DO,0.7490706319702602,"i exp(H(k)
[u,i]) ≥τ} can be taken as the predicted probability for Yu = u and τ is the"
WHILE NOT INJECTING ALL NODES DO,0.75,corresponding threshold for hinge loss that we set as 1 × 10−8.
WHILE NOT INJECTING ALL NODES DO,0.7509293680297398,"For the hyper-parameter setting of our proposed strategies in Sec. 4.2, we ﬁnd directly adopting λ
in PGD for λX and setting λA = 0 performs empirically better. Hence we stick to the setting for
λA and λX. For the weight of sparsity regularization term in AGIA, we directly adopt 1/b. For the
hyper-parameters in heuristic methods, we directly follow TDGIA (Zou et al., 2021). For SeqGIA,
we set γatk be min(0.2, ⌊|Vc|/2b⌋) and γc = min(|Vc|, γatk|Vatk|b) by default."
WHILE NOT INJECTING ALL NODES DO,0.7518587360594795,"H.6
SOFTWARE AND HARDWARE"
WHILE NOT INJECTING ALL NODES DO,0.7527881040892194,"We implement our methods with PyTorch (Paszke et al., 2019) and PyTorch Geometric (Fey &
Lenssen, 2019). We ran our experiments on Linux Servers with 40 cores Intel(R) Xeon(R) Silver
4114 CPU @ 2.20GHz, 256 GB Memory, and Ubuntu 18.04 LTS installed. One has 4 NVIDIA RTX
2080Ti graphics cards with CUDA 10.2 and the other has 2 NVIDIA RTX 2080Ti and 2 NVIDIA
RTX 3090Ti graphics cards with CUDA 11.3."
WHILE NOT INJECTING ALL NODES DO,0.7537174721189591,"I
MORE EXPERIMENTAL RESULTS"
WHILE NOT INJECTING ALL NODES DO,0.7546468401486989,"In this section, we provide more results from experiments about HAO to further validate its effec-
tiveness. Speciﬁcally, we provide full results of averaged attack performance across all defense
models, as well as initial experiments of HAO on two disassortative graphs."
WHILE NOT INJECTING ALL NODES DO,0.7555762081784386,Published as a conference paper at ICLR 2022
WHILE NOT INJECTING ALL NODES DO,0.7565055762081785,Table 9: Full averaged performance across all defense models
WHILE NOT INJECTING ALL NODES DO,0.7574349442379182,"Model
Cora†
Citeseer†
Computers†
Arxiv†
Arxiv‡
Computers‡
Aminer‡
Reddit‡"
WHILE NOT INJECTING ALL NODES DO,0.758364312267658,"Clean
84.74
74.10
92.25
70.44
70.44
91.68
62.39
95.51
PGD
61.09
54.08
61.75
54.23
36.70
62.41
26.13
62.72
+HAO
56.63
48.12
59.16
45.05
28.48
59.09
22.15
56.99
MetaGIA
60.56
53.72
61.75
53.69
28.78
62.08
32.78
60.14
+HAO
58.51
47.44
60.29
48.48
24.61
58.63
29.91
54.14
AGIA
60.10
54.55
60.66
48.86
32.68
61.98
31.06
59.96
+HAO
53.79
48.30
58.71
48.86
29.52
58.37
26.51
56.36
TDGIA
66.86
52.45
66.79
49.73
31.68
62.47
32.37
57.97
+HAO
65.22
46.61
65.46
49.54
22.04
59.67
22.32
54.32
ATDGIA
61.14
49.46
65.07
46.53
32.08
64.66
24.72
61.25
+HAO
58.13
43.41
63.31
44.40
29.24
59.27
17.62
56.90"
WHILE NOT INJECTING ALL NODES DO,0.7592936802973977,The lower is better. †Non-targeted attack. ‡Targeted attack.
WHILE NOT INJECTING ALL NODES DO,0.7602230483271375,"I.1
FULL RESULTS OF AVERAGED ATTACK PERFORMANCE"
WHILE NOT INJECTING ALL NODES DO,0.7611524163568774,"In this section, we provide full results of averaged attack performance across all defense models, as
a supplementary for Table 3b."
WHILE NOT INJECTING ALL NODES DO,0.7620817843866171,"I.2
MORE RESULTS ON DISASSORTATIVE GRAPHS"
WHILE NOT INJECTING ALL NODES DO,0.7630111524163569,"In this section, we provide initial investigation into the non-targeted attack performances of various
GIA methods with or without HAO on disassortative graphs. Speciﬁcally, we select Chameleon and
Squirrel provided by Pei et al. (2020). Statistics and budgets used for attack are given in Table 10
and Table 11."
WHILE NOT INJECTING ALL NODES DO,0.7639405204460966,Table 10: Statistics of the disassortative datasets
WHILE NOT INJECTING ALL NODES DO,0.7648698884758365,"Datasets
Nodes
Edges
Classes
Avg. Degree
Label Homophily
Avg. Homophily"
WHILE NOT INJECTING ALL NODES DO,0.7657992565055762,"Chameleon
2277
31, 421
5
27.60
0.26
0.62
Squirrel
5201
198, 493
5
76.33
0.23
0.58"
WHILE NOT INJECTING ALL NODES DO,0.766728624535316,"We also heuristically specify the budgets for each dataset according the the number of target nodes
and average degrees."
WHILE NOT INJECTING ALL NODES DO,0.7676579925650557,Table 11: Budgets for non-targeted attacks on disassortative datasets
WHILE NOT INJECTING ALL NODES DO,0.7685873605947955,"Datasets
Nodes
Degree
Node Per.(%)
Edge Per.(%)"
WHILE NOT INJECTING ALL NODES DO,0.7695167286245354,"Chameleon
60
100
2.64%
19.10%
Squirrel
90
50
1.73%
2.27%"
WHILE NOT INJECTING ALL NODES DO,0.7704460966542751,"For the settings of hyperparameters in attack methods and evaluation, we basically follow the same
setup as given in Appendix H.5. In particular, we ﬁnd using a threshold of 0.05 for homophily
defenders work best on Chameleon. Besides, we also observe robust tricks can not always improve
performances of GNNs on these graphs. For example, we observe that using a large step-size of
FLAG may degenerate the performances of GNNs on these datasets, hence we use a smaller step-
size of 5×10−4 as well as a small number of steps of 10. Moreover, using a LN before the ﬁrst GNN
layer may also hurt the performance. For fair comparison, we remove these results from defenses.
Finally, in Table 12, we report both categorized defense results as Table 1 as well as the averaged
attack performance as Table 3b."
WHILE NOT INJECTING ALL NODES DO,0.7713754646840149,"From the results, we observe that, although our methods are not initially designed for disassortative
graphs, HAO still brings empirical improvements. Speciﬁcally, on Chameleon, HAO improves the
attack performance up to 25% against homophily defenders, up to 12% against robust models, up
to 10% against extreme robust models, and ﬁnally brings up to 3% averaged test robustness of all
models. While on Squirrel, the improvements become relatively low while still non-trivial. For"
WHILE NOT INJECTING ALL NODES DO,0.7723048327137546,Published as a conference paper at ICLR 2022
WHILE NOT INJECTING ALL NODES DO,0.7732342007434945,Table 12: Results of non-targeted attacks on disassortative graphs
WHILE NOT INJECTING ALL NODES DO,0.7741635687732342,"Chameleon (↓)
Squirrel(↓)"
WHILE NOT INJECTING ALL NODES DO,0.775092936802974,"HAO
Homo
Robust
Combo
AVG.
Homo
Robust
Combo
AVG."
WHILE NOT INJECTING ALL NODES DO,0.7760223048327137,"Clean
61.89
65.18
64.92
62.58
37.33
43.88
45.87
40.04"
WHILE NOT INJECTING ALL NODES DO,0.7769516728624535,"PGD
61.89
61.89
63.61
33.24
35.66
36.28
40.54
26.03
PGD
✓
52.78
57.87
59.31
38.00
33.32
39.36
35.83
26.37"
WHILE NOT INJECTING ALL NODES DO,0.7778810408921933,"MetaGIA†
61.89
61.89
63.61
34.38
35.66
35.66
39.40
26.09
MetaGIA†
✓
49.25
55.83
55.73
33.63
34.07
38.26
35.24
25.81
AGIA†
61.89
61.89
63.61
35.95
35.66
35.89
39.93
26.93
AGIA†
✓
43.98
48.88
53.33
32.03
35.69
36.31
36.40
26.77"
WHILE NOT INJECTING ALL NODES DO,0.7788104089219331,"TDGIA
61.95
61.95
63.76
41.17
35.66
35.66
40.81
29.02
TDGIA
✓
46.36
51.12
55.14
38.90
31.51
38.21
35.63
28.65
ATDGIA
61.95
61.95
63.76
41.11
35.66
35.66
41.62
29.62
ATDGIA
✓
36.93
57.75
59.25
38.88
32.02
40.00
40.62
30.24"
WHILE NOT INJECTING ALL NODES DO,0.7797397769516728,"MLP
50.15
32.51"
WHILE NOT INJECTING ALL NODES DO,0.7806691449814126,↓The lower number indicates better attack performance. †Runs with SeqGIA framework on Computers and Arxiv.
WHILE NOT INJECTING ALL NODES DO,0.7815985130111525,Table 13: Detailed results of non-targeted attacks on Cora (1)
WHILE NOT INJECTING ALL NODES DO,0.7825278810408922,"EGuard+LNi+FLAG+LN
EGuard+FLAG+LN
EGuard+LNi+FLAG
Guard+LNi+LN
RGAT+FLAG+LN
GCN+LNi+FLAG+LN
RobustGCN+FLAG
RGAT+LN
Guard+LN
EGuard+FLAG"
WHILE NOT INJECTING ALL NODES DO,0.783457249070632,"Clean
83.48
84.17
85.9
79.56
87.29
86.37
86.21
85.29
81.72
85.56"
WHILE NOT INJECTING ALL NODES DO,0.7843866171003717,"PGD
82.53
83.94
85.74
79.74
76.78
71.10
69.57
79.56
81.44
85.35"
WHILE NOT INJECTING ALL NODES DO,0.7853159851301115,"+HAO
77.99
73.04
66.25
74.21
68.09
71.06
70.3
67.92
68.12
53.99"
WHILE NOT INJECTING ALL NODES DO,0.7862453531598513,"MetaGIA
82.68
83.96
85.86
79.51
75.18
69.72
69.4
78.04
81.59
85.48"
WHILE NOT INJECTING ALL NODES DO,0.7871747211895911,"+HAO
69.49
65.92
66.83
63.02
66.38
71.86
76.8
57.75
55.35
56.77"
WHILE NOT INJECTING ALL NODES DO,0.7881040892193308,"AGIA
82.75
83.69
85.78
79.56
75.77
69.25
69.10
79.10
81.43
85.34"
WHILE NOT INJECTING ALL NODES DO,0.7890334572490706,"+HAO
75.25
69.10
61.00
70.12
65.48
69.86
71.08
62.76
60.96
48.54"
WHILE NOT INJECTING ALL NODES DO,0.7899628252788105,"TDGIA
83.13
83.65
85.72
79.13
82.37
79.31
76.11
82.2
81.37
85.39"
WHILE NOT INJECTING ALL NODES DO,0.7908921933085502,"+HAO
77.93
73.58
75.47
73.67
75.18
79.45
78.63
69.58
64.66
65.31"
WHILE NOT INJECTING ALL NODES DO,0.79182156133829,"ATDIGA
82.57
83.54
85.39
79.38
78.76
76.09
73.08
79.8
81.47
84.88"
WHILE NOT INJECTING ALL NODES DO,0.7927509293680297,"+HAO
74.43
71.88
71.21
66.97
72.51
76.87
76.17
60.61
62.38
63.53"
WHILE NOT INJECTING ALL NODES DO,0.7936802973977695,"AVG
79.29
77.86
77.74
74.99
74.89
74.63
74.22
72.96
72.77
72.74"
WHILE NOT INJECTING ALL NODES DO,0.7946096654275093,"example, HAO improves the attack performance up to 4% in terms of test robustness against ho-
mophily defenders. We hypothesize the reason why HAO also works on disassortative graphs is
because GNN can still learn the homophily information implicitly, e.g., similarity between class
label distributions (Ma et al., 2022), which we will leave the in-depth analyses to future work."
WHILE NOT INJECTING ALL NODES DO,0.7955390334572491,"J
DETAILED RESULTS OF ATTACK PERFORMANCE"
WHILE NOT INJECTING ALL NODES DO,0.7964684014869888,"J.1
DETAILED RESULTS OF NON-TARGETED ATTACKS"
WHILE NOT INJECTING ALL NODES DO,0.7973977695167286,"In this section, we present the detailed non-targeted attack results of the methods and datasets used
in our experiments for Table 1. For simplicity, we only give the results of top 20 robust models
according to the averaged test accuracy against all attacks."
WHILE NOT INJECTING ALL NODES DO,0.7983271375464684,"J.2
DETAILED RESULTS OF TARGETED ATTACKS"
WHILE NOT INJECTING ALL NODES DO,0.7992565055762082,"In this section, we present the detailed targeted attack results of the methods and datasets used in our
experiments for Table 2. For simiplicity, we only give the results of top 20 robust models according
to the averaged test accuracy against all attacks."
WHILE NOT INJECTING ALL NODES DO,0.800185873605948,Published as a conference paper at ICLR 2022
WHILE NOT INJECTING ALL NODES DO,0.8011152416356877,Table 14: Detailed results of non-targeted attacks on Cora (2)
WHILE NOT INJECTING ALL NODES DO,0.8020446096654275,"RGAT+FLAG
Guard+LNi
RobustGCN
GCN+FLAG+LN
GCN+LNi+FLAG
RGAT
GAT+LNi+FLAG+LN
Sage+LNi+FLAG+LN
Guard
GCN+LNi+LN"
WHILE NOT INJECTING ALL NODES DO,0.8029739776951673,"Clean
87.21
83.18
84.63
85.86
86.36
85.74
86.55
84.95
83.61
84.47"
WHILE NOT INJECTING ALL NODES DO,0.8039033457249071,"PGD
76.93
83.11
63.20
62.55
60.68
79.28
61.29
61.84
83.08
58.46"
WHILE NOT INJECTING ALL NODES DO,0.8048327137546468,"+HAO
62.35
53.68
62.60
63.60
61.69
52.60
62.81
62.34
44.02
58.78"
WHILE NOT INJECTING ALL NODES DO,0.8057620817843866,"MetaGIA
75.14
83.08
63.53
59.18
60.36
77.97
57.88
61.01
83.61
58.10"
WHILE NOT INJECTING ALL NODES DO,0.8066914498141264,"+HAO
61.53
57.31
69.83
67.00
66.64
49.25
65.82
65.69
45.41
61.94"
WHILE NOT INJECTING ALL NODES DO,0.8076208178438662,"AGIA
76.04
83.08
62.67
61.26
59.09
78.95
57.84
58.61
83.44
57.05"
WHILE NOT INJECTING ALL NODES DO,0.8085501858736059,"+HAO
57.17
49.12
61.59
62.65
59.25
47.24
59.80
59.56
39.87
55.62"
WHILE NOT INJECTING ALL NODES DO,0.8094795539033457,"TDGIA
82.02
83.04
71.34
71.35
73.47
81.79
71.52
70.30
83.44
70.69"
WHILE NOT INJECTING ALL NODES DO,0.8104089219330854,"+HAO
70.52
67.04
73.38
73.52
75.00
56.95
71.96
71.56
50.79
72.90"
WHILE NOT INJECTING ALL NODES DO,0.8113382899628253,"ATDIGA
79.06
82.85
66.96
69.61
65.89
79.91
65.57
63.81
83.07
62.95"
WHILE NOT INJECTING ALL NODES DO,0.8122676579925651,"+HAO
64.50
55.13
70.30
72.46
70.94
42.18
69.26
67.59
40.46
65.53"
WHILE NOT INJECTING ALL NODES DO,0.8131970260223048,"AVG
72.04
70.97
68.18
68.09
67.22
66.53
66.39
66.11
65.53
64.23"
WHILE NOT INJECTING ALL NODES DO,0.8141263940520446,Table 15: Detailed results of non-targeted attacks on Citeseer (1)
WHILE NOT INJECTING ALL NODES DO,0.8150557620817844,"RGAT+LN
RGAT+FLAG+LN
EGuard+LNi+FLAG+LN
Guard+LNi+LN
RGAT
EGuard+FLAG+LN
RGAT+FLAG
EGuard+LNi+FLAG
EGuard+FLAG
GCN+LNi+FLAG+LN"
WHILE NOT INJECTING ALL NODES DO,0.8159851301115242,"Clean
74.82
75.72
75.44
74.25
74.85
73.64
75.56
74.75
73.57
75.67"
WHILE NOT INJECTING ALL NODES DO,0.8169144981412639,"PGD
71.00
71.32
75.19
74.21
69.33
73.55
69.84
74.83
73.57
57.97"
WHILE NOT INJECTING ALL NODES DO,0.8178438661710037,"+HAO
71.00
70.82
66.07
73.04
69.05
61.55
65.78
50.01
47.54
58.77"
WHILE NOT INJECTING ALL NODES DO,0.8187732342007435,"MetaGIA
70.32
70.21
75.15
74.21
68.42
73.55
68.90
74.83
73.57
56.36"
WHILE NOT INJECTING ALL NODES DO,0.8197026022304833,"+HAO
70.37
69.77
64.00
71.25
68.04
59.94
63.10
49.70
46.95
57.17"
WHILE NOT INJECTING ALL NODES DO,0.820631970260223,"AGIA
71.45
70.51
75.29
74.21
70.31
73.60
69.40
74.83
73.61
56.50"
WHILE NOT INJECTING ALL NODES DO,0.8215613382899628,"+HAO
71.80
70.70
64.54
70.58
70.24
59.32
62.31
50.33
46.77
58.02"
WHILE NOT INJECTING ALL NODES DO,0.8224907063197026,"TDGIA
72.29
73.81
75.26
74.21
70.99
73.55
73.34
74.85
73.57
63.01"
WHILE NOT INJECTING ALL NODES DO,0.8234200743494424,"+HAO
72.51
70.18
68.04
56.69
60.91
65.70
53.99
56.73
52.86
66.52"
WHILE NOT INJECTING ALL NODES DO,0.8243494423791822,"ATDIGA
72.23
72.82
75.12
74.21
70.61
73.55
72.37
74.82
73.54
61.55"
WHILE NOT INJECTING ALL NODES DO,0.8252788104089219,"+HAO
71.22
69.63
65.82
52.97
61.08
64.51
53.76
52.94
51.20
64.04"
WHILE NOT INJECTING ALL NODES DO,0.8262081784386617,"AVG
71.73
71.41
70.90
69.98
68.53
68.41
66.21
64.42
62.43
61.42"
WHILE NOT INJECTING ALL NODES DO,0.8271375464684015,Table 16: Detailed results of non-targeted attacks on Citeseer (2)
WHILE NOT INJECTING ALL NODES DO,0.8280669144981413,"Guard+LN
Guard+LNi
RobustGCN+FLAG
Guard
GCN+LNi+FLAG
Sage+LNi+FLAG+LN
GAT+LNi+FLAG+LN
RobustGCN
GCN+LNi+LN
Sage+LNi+FLAG"
WHILE NOT INJECTING ALL NODES DO,0.828996282527881,"Clean
73.97
74.41
75.87
74.78
75.45
73.89
75.60
75.46
74.65
73.70"
WHILE NOT INJECTING ALL NODES DO,0.8299256505576208,"PGD
74.07
74.28
53.81
74.70
47.56
46.82
45.00
39.77
40.69
40.11"
WHILE NOT INJECTING ALL NODES DO,0.8308550185873605,"+HAO
48.48
38.91
51.10
33.83
49.19
46.93
44.06
39.72
40.79
40.88"
WHILE NOT INJECTING ALL NODES DO,0.8317843866171004,"MetaGIA
74.07
74.28
53.11
74.70
47.14
46.13
44.76
39.84
40.87
40.13"
WHILE NOT INJECTING ALL NODES DO,0.8327137546468402,"+HAO
45.32
38.98
50.85
33.95
49.03
46.42
44.08
39.79
41.02
40.90"
WHILE NOT INJECTING ALL NODES DO,0.8336431226765799,"AGIA
74.07
74.29
53.12
74.72
47.30
46.29
44.07
40.16
41.76
40.73"
WHILE NOT INJECTING ALL NODES DO,0.8345724907063197,"+HAO
43.47
41.04
50.88
36.51
49.61
47.28
45.66
41.53
42.32
42.82"
WHILE NOT INJECTING ALL NODES DO,0.8355018587360595,"TDGIA
74.07
74.28
55.01
74.76
49.47
47.06
41.08
37.94
40.68
36.21"
WHILE NOT INJECTING ALL NODES DO,0.8364312267657993,"+HAO
36.83
36.50
60.37
26.45
57.45
49.82
49.74
47.44
43.85
40.83"
WHILE NOT INJECTING ALL NODES DO,0.837360594795539,"ATDIGA
74.07
74.21
54.95
74.72
45.09
41.89
36.24
34.65
32.10
31.17"
WHILE NOT INJECTING ALL NODES DO,0.8382899628252788,"+HAO
30.21
28.74
55.40
21.70
52.22
45.66
45.19
40.35
35.05
38.81"
WHILE NOT INJECTING ALL NODES DO,0.8392193308550185,"AVG
58.97
57.27
55.86
54.62
51.77
48.93
46.86
43.33
43.07
42.39"
WHILE NOT INJECTING ALL NODES DO,0.8401486988847584,Published as a conference paper at ICLR 2022
WHILE NOT INJECTING ALL NODES DO,0.8410780669144982,Table 17: Detailed results of non-targeted attacks on Computers (1)
WHILE NOT INJECTING ALL NODES DO,0.8420074349442379,"EGuard+LNi+FLAG+LN
Guard+LNi+LN
EGuard+FLAG+LN
Guard+LN
RGAT+FLAG+LN
RGAT+FLAG
EGuard+LNi+FLAG
Guard+LNi
RGAT+LN
RGAT"
WHILE NOT INJECTING ALL NODES DO,0.8429368029739777,"Clean
91.04
90.88
91.40
91.23
93.21
93.32
92.16
91.95
93.20
93.17"
WHILE NOT INJECTING ALL NODES DO,0.8438661710037175,"PGD
90.94
90.87
91.41
91.24
81.59
80.19
88.24
87.93
79.68
79.05"
WHILE NOT INJECTING ALL NODES DO,0.8447955390334573,"+HAO
87.83
87.59
80.41
75.94
81.80
82.26
64.18
62.69
79.29
79.33"
WHILE NOT INJECTING ALL NODES DO,0.845724907063197,"MetaGIA
90.94
90.87
91.41
91.24
81.58
80.18
88.23
87.91
79.68
79.06"
WHILE NOT INJECTING ALL NODES DO,0.8466542750929368,"+HAO
90.25
90.21
90.11
88.32
81.64
81.72
78.11
76.58
79.29
78.96"
WHILE NOT INJECTING ALL NODES DO,0.8475836431226765,"AGIA
90.98
90.90
91.40
91.22
78.09
76.59
88.25
87.86
76.62
75.56"
WHILE NOT INJECTING ALL NODES DO,0.8485130111524164,"+HAO
86.02
85.77
75.97
71.49
77.55
78.17
63.96
62.74
75.23
75.14"
WHILE NOT INJECTING ALL NODES DO,0.8494423791821561,"TDGIA
90.97
90.91
91.40
91.24
77.07
75.40
90.26
89.94
75.94
74.66"
WHILE NOT INJECTING ALL NODES DO,0.8503717472118959,"+HAO
90.42
90.34
90.35
89.00
77.12
76.61
74.58
74.22
75.71
74.77"
WHILE NOT INJECTING ALL NODES DO,0.8513011152416357,"ATDIGA
90.97
90.90
91.41
91.24
82.42
81.77
89.24
88.84
81.29
80.76"
WHILE NOT INJECTING ALL NODES DO,0.8522304832713755,"+HAO
84.60
83.93
74.38
69.33
82.97
83.50
69.92
68.50
80.92
80.86"
WHILE NOT INJECTING ALL NODES DO,0.8531598513011153,"AVG
89.54
89.38
87.24
85.59
81.37
80.88
80.65
79.92
79.71
79.21"
WHILE NOT INJECTING ALL NODES DO,0.854089219330855,Table 18: Detailed results of non-targeted attacks on Computers (2)
WHILE NOT INJECTING ALL NODES DO,0.8550185873605948,"GAT+FLAG+LN
EGuard+FLAG
Guard
RobustGCN+FLAG
GAT+LNi+FLAG+LN
RobustGCN
Sage+LNi+FLAG+LN
GAT+LNi+FLAG
GCN+LNi+FLAG+LN
GAT+LNi+LN"
WHILE NOT INJECTING ALL NODES DO,0.8559479553903345,"Clean
92.17
91.68
91.55
92.46
92.40
92.24
91.71
92.45
93.22
92.05"
WHILE NOT INJECTING ALL NODES DO,0.8568773234200744,"PGD
82.31
85.82
84.91
73.27
77.91
67.14
63.83
67.61
54.96
52.20"
WHILE NOT INJECTING ALL NODES DO,0.8578066914498141,"+HAO
69.83
55.62
54.31
72.73
65.08
68.80
62.55
54.93
63.28
69.19"
WHILE NOT INJECTING ALL NODES DO,0.8587360594795539,"MetaGIA
82.31
85.81
84.91
73.28
77.91
67.14
63.83
67.62
54.96
52.21"
WHILE NOT INJECTING ALL NODES DO,0.8596654275092936,"+HAO
77.39
69.73
67.90
70.42
69.52
64.76
62.45
58.24
59.31
63.69"
WHILE NOT INJECTING ALL NODES DO,0.8605947955390335,"AGIA
79.60
86.08
85.21
71.95
75.01
66.01
60.72
64.25
52.34
50.69"
WHILE NOT INJECTING ALL NODES DO,0.8615241635687733,"+HAO
63.02
56.48
55.35
72.18
61.22
68.84
60.68
53.95
62.78
67.54"
WHILE NOT INJECTING ALL NODES DO,0.862453531598513,"TDGIA
80.42
88.64
88.32
72.23
75.27
69.45
63.87
68.58
64.96
58.98"
WHILE NOT INJECTING ALL NODES DO,0.8633828996282528,"+HAO
79.19
69.75
68.76
71.39
70.84
69.11
63.72
63.45
66.56
65.81"
WHILE NOT INJECTING ALL NODES DO,0.8643122676579925,"ATDIGA
82.42
87.11
86.03
76.96
79.13
71.92
68.42
71.15
66.01
53.34"
WHILE NOT INJECTING ALL NODES DO,0.8652416356877324,"+HAO
60.74
61.46
58.81
76.79
64.38
74.26
68.33
57.90
72.34
73.82"
WHILE NOT INJECTING ALL NODES DO,0.8661710037174721,"AVG
77.22
76.20
75.10
74.88
73.52
70.88
66.37
65.47
64.61
63.59"
WHILE NOT INJECTING ALL NODES DO,0.8671003717472119,Table 19: Detailed results of non-targeted attacks on Arxiv (1)
WHILE NOT INJECTING ALL NODES DO,0.8680297397769516,"Guard+LNi+LN
RGAT+LN
RGAT+FLAG+LN
EGuard+LNi+FLAG+LN
EGuard+FLAG+LN
Guard+LN
RobustGCN+FLAG
RobustGCN
GCN+LNi+FLAG+LN
Guard+LNi"
WHILE NOT INJECTING ALL NODES DO,0.8689591078066915,"71.15
70.95
70.84
69.50
69.46
69.76
67.85
67.50
71.40
70.99"
WHILE NOT INJECTING ALL NODES DO,0.8698884758364313,"PGD
71.11
66.57
66.61
69.28
69.24
69.62
60.60
60.81
55.99
70.26"
WHILE NOT INJECTING ALL NODES DO,0.870817843866171,"68.68
66.68
66.60
61.05
61.02
58.92
62.99
62.89
60.02
47.84"
WHILE NOT INJECTING ALL NODES DO,0.8717472118959108,"MetaGIA
71.09
67.87
67.67
69.23
69.22
69.59
64.10
64.10
63.58
70.40"
WHILE NOT INJECTING ALL NODES DO,0.8726765799256505,"69.97
66.81
66.52
66.14
66.13
65.70
63.20
63.30
64.13
58.58"
WHILE NOT INJECTING ALL NODES DO,0.8736059479553904,"AGIA
70.97
65.22
64.46
68.23
68.17
68.57
59.26
59.23
57.26
64.60"
WHILE NOT INJECTING ALL NODES DO,0.8745353159851301,"63.57
57.02
56.60
58.27
58.20
57.73
60.77
60.72
61.50
58.08"
WHILE NOT INJECTING ALL NODES DO,0.8754646840148699,"TDIGA
71.02
67.54
67.28
68.37
68.33
68.72
63.70
63.56
61.01
65.63"
WHILE NOT INJECTING ALL NODES DO,0.8763940520446096,"64.31
61.61
60.99
59.73
59.74
58.33
63.08
63.30
62.81
53.04"
WHILE NOT INJECTING ALL NODES DO,0.8773234200743495,"ATDGIA
71.01
68.49
68.45
68.18
68.14
68.49
64.95
64.88
63.95
66.39"
WHILE NOT INJECTING ALL NODES DO,0.8782527881040892,"69.92
68.67
68.58
66.34
66.35
65.47
65.56
65.62
65.83
55.42"
WHILE NOT INJECTING ALL NODES DO,0.879182156133829,"AVG
69.34
66.13
65.87
65.85
65.82
65.54
63.28
63.26
62.50
61.93"
WHILE NOT INJECTING ALL NODES DO,0.8801115241635687,Published as a conference paper at ICLR 2022
WHILE NOT INJECTING ALL NODES DO,0.8810408921933085,Table 20: Detailed results of non-targeted attacks on Arxiv (2)
WHILE NOT INJECTING ALL NODES DO,0.8819702602230484,"RGAT+FLAG
GCN+LNi+LN
RGAT
GCN+FLAG+LN
GAT+FLAG+LN
EGuard+LNi+FLAG
GCN+LN
EGuard+FLAG
GCN+LNi+FLAG
GAT+LNi+FLAG+LN"
WHILE NOT INJECTING ALL NODES DO,0.8828996282527881,"70.63
71.38
70.77
70.00
70.28
69.37
70.42
69.34
71.31
71.00"
WHILE NOT INJECTING ALL NODES DO,0.8838289962825279,"PGD
66.49
54.46
66.26
54.21
57.44
68.04
51.97
68.03
48.00
57.65"
WHILE NOT INJECTING ALL NODES DO,0.8847583643122676,"57.18
58.40
55.38
55.51
59.16
37.02
52.45
36.80
52.75
53.97"
WHILE NOT INJECTING ALL NODES DO,0.8856877323420075,"MetaGIA
67.42
62.88
67.68
58.54
61.92
68.48
57.04
68.40
55.73
61.56"
WHILE NOT INJECTING ALL NODES DO,0.8866171003717472,"58.21
63.35
57.05
59.65
51.65
50.32
57.39
50.23
57.72
54.63"
WHILE NOT INJECTING ALL NODES DO,0.887546468401487,"AGIA
63.75
57.12
64.49
49.55
45.96
59.35
48.54
59.25
54.55
49.14"
WHILE NOT INJECTING ALL NODES DO,0.8884758364312267,"50.31
61.29
49.36
58.25
49.71
49.24
57.24
49.20
58.10
48.78"
WHILE NOT INJECTING ALL NODES DO,0.8894052044609665,"TDIGA
66.74
58.91
66.95
55.47
56.30
62.18
52.39
62.10
48.86
52.58"
WHILE NOT INJECTING ALL NODES DO,0.8903345724907064,"47.88
61.90
45.59
59.20
49.44
45.08
56.42
44.91
54.68
47.80"
WHILE NOT INJECTING ALL NODES DO,0.8912639405204461,"ATDGIA
67.97
62.21
68.07
58.61
63.36
62.73
55.26
62.67
54.19
58.50"
WHILE NOT INJECTING ALL NODES DO,0.8921933085501859,"60.82
64.82
59.32
62.69
57.51
46.94
59.50
46.83
57.90
56.58"
WHILE NOT INJECTING ALL NODES DO,0.8931226765799256,"AVG
61.58
61.52
60.99
58.33
56.61
56.25
56.24
56.16
55.80
55.65"
WHILE NOT INJECTING ALL NODES DO,0.8940520446096655,Table 21: Detailed results of targeted attacks on Computers (1)
WHILE NOT INJECTING ALL NODES DO,0.8949814126394052,"EGuard+LNi+FLAG+LN
Guard+LNi+LN
EGuard+FLAG+LN
Guard+LN
Guard+LNi
EGuard+LNi+FLAG
RobustGCN+FLAG
RGAT+FLAG
RGAT+FLAG+LN
EGuard+FLAG"
WHILE NOT INJECTING ALL NODES DO,0.895910780669145,"Clean
90.96
90.76
91.56
91.11
91.12
91.29
91.85
92.83
92.78
90.75"
WHILE NOT INJECTING ALL NODES DO,0.8968401486988847,"PGD
90.96
90.76
91.56
91.11
89.38
89.54
72.36
72.17
74.28
88.36"
WHILE NOT INJECTING ALL NODES DO,0.8977695167286245,"+HAO
85.81
85.75
79.51
73.71
65.01
64.15
72.58
74.40
74.08
56.50"
WHILE NOT INJECTING ALL NODES DO,0.8986988847583643,"MetaGIA
90.96
90.76
91.56
91.11
88.93
89.10
73.81
70.58
72.24
88.10"
WHILE NOT INJECTING ALL NODES DO,0.8996282527881041,"+HAO
85.83
85.69
78.46
72.61
65.62
65.53
73.50
72.10
72.00
56.12"
WHILE NOT INJECTING ALL NODES DO,0.9005576208178439,"AGIA
91.00
90.82
91.58
91.06
89.11
89.33
72.96
68.85
69.64
88.00"
WHILE NOT INJECTING ALL NODES DO,0.9014869888475836,"+HAO
85.72
85.71
79.50
74.28
64.71
63.90
73.12
72.61
72.22
56.18"
WHILE NOT INJECTING ALL NODES DO,0.9024163568773235,"TDGIA
90.96
90.76
91.56
91.11
89.15
89.36
72.06
72.42
72.58
87.75"
WHILE NOT INJECTING ALL NODES DO,0.9033457249070632,"+HAO
77.15
75.64
65.21
62.97
69.78
70.43
73.08
74.33
74.00
64.31"
WHILE NOT INJECTING ALL NODES DO,0.904275092936803,"ATDIGA
90.96
90.76
91.56
91.11
88.99
89.22
75.15
75.68
73.32
88.43"
WHILE NOT INJECTING ALL NODES DO,0.9052044609665427,"+HAO
78.35
77.67
62.87
59.65
63.75
63.15
74.06
75.78
74.14
56.51"
WHILE NOT INJECTING ALL NODES DO,0.9061338289962825,"AVG
87.15
86.83
83.18
80.89
78.69
78.64
74.96
74.70
74.66
74.64"
WHILE NOT INJECTING ALL NODES DO,0.9070631970260223,Table 22: Detailed results of targeted attacks on Computers (2)
WHILE NOT INJECTING ALL NODES DO,0.9079925650557621,"Guard
RobustGCN
RGAT
RGAT+LN
GAT+FLAG+LN
GAT+LNi+FLAG+LN
GAT+LNi+FLAG
GCN+LNi+FLAG+LN
GAT+LNi+LN
GCN+LNi+FLAG"
WHILE NOT INJECTING ALL NODES DO,0.9089219330855018,"Clean
90.50
92.07
92.68
92.76
91.07
91.90
91.92
92.25
91.56
92.35"
WHILE NOT INJECTING ALL NODES DO,0.9098513011152416,"PGD
88.13
70.40
71.85
72.65
77.69
75.25
72.57
63.08
58.46
60.79"
WHILE NOT INJECTING ALL NODES DO,0.9107806691449815,"+HAO
54.96
70.76
71.78
71.40
71.03
66.01
62.46
66.01
70.49
64.17"
WHILE NOT INJECTING ALL NODES DO,0.9117100371747212,"MetaGIA
87.67
71.78
70.44
71.33
74.93
73.12
70.89
62.54
57.40
60.71"
WHILE NOT INJECTING ALL NODES DO,0.912639405204461,"+HAO
55.00
71.61
70.21
70.35
69.56
64.82
62.58
64.81
67.57
63.04"
WHILE NOT INJECTING ALL NODES DO,0.9135687732342007,"AGIA
87.57
70.92
68.36
68.58
73.00
71.03
68.50
61.08
56.62
59.26"
WHILE NOT INJECTING ALL NODES DO,0.9144981412639405,"+HAO
54.89
71.58
69.96
69.99
68.44
64.81
61.00
64.68
69.39
62.28"
WHILE NOT INJECTING ALL NODES DO,0.9154275092936803,"TDGIA
87.21
69.86
71.54
71.28
74.24
72.86
70.60
62.74
57.54
60.35"
WHILE NOT INJECTING ALL NODES DO,0.9163568773234201,"+HAO
61.62
71.62
71.39
71.92
54.19
60.51
66.69
66.79
66.74
63.97"
WHILE NOT INJECTING ALL NODES DO,0.9172862453531598,"ATDIGA
87.85
73.33
74.39
72.19
73.36
75.24
74.06
65.14
56.22
62.67"
WHILE NOT INJECTING ALL NODES DO,0.9182156133828996,"+HAO
54.93
72.53
72.00
71.49
62.03
63.19
62.14
68.50
73.15
66.06"
WHILE NOT INJECTING ALL NODES DO,0.9191449814126395,"AVG
73.67
73.31
73.15
73.09
71.78
70.79
69.40
67.06
65.92
65.06"
WHILE NOT INJECTING ALL NODES DO,0.9200743494423792,Published as a conference paper at ICLR 2022
WHILE NOT INJECTING ALL NODES DO,0.921003717472119,Table 23: Detailed results of targeted attacks on Arxiv (1)
WHILE NOT INJECTING ALL NODES DO,0.9219330855018587,"Guard+LNi+LN
EGuard+LNi+FLAG+LN
Guard+LNi
EGuard+FLAG+LN
EGuard+LNi+FLAG
Guard+LN
EGuard+FLAG
Guard
RobustGCN+FLAG
RGAT"
WHILE NOT INJECTING ALL NODES DO,0.9228624535315985,"71.34
71.22
71.22
69.59
70.59
69.78
68.88
69.41
67.28
67.03"
WHILE NOT INJECTING ALL NODES DO,0.9237918215613383,"PGD
71.31
71.16
71.16
69.47
70.47
69.69
68.69
69.19
39.91
39.13"
WHILE NOT INJECTING ALL NODES DO,0.9247211895910781,"69.38
65.69
33.78
47.41
29.12
38.00
14.31
13.94
36.12
36.06"
WHILE NOT INJECTING ALL NODES DO,0.9256505576208178,"MetaGIA
71.03
71.22
70.53
69.59
70.59
69.78
68.84
69.28
42.56
41.81"
WHILE NOT INJECTING ALL NODES DO,0.9265799256505576,"42.56
48.06
33.94
31.84
34.94
26.75
20.34
18.28
38.66
38.44"
WHILE NOT INJECTING ALL NODES DO,0.9275092936802974,"AGIA
71.06
70.94
70.19
69.25
67.72
69.38
64.38
63.66
39.94
39.47"
WHILE NOT INJECTING ALL NODES DO,0.9284386617100372,"38.56
37.22
35.06
24.63
35.31
22.09
16.19
14.09
42.53
42.56"
WHILE NOT INJECTING ALL NODES DO,0.929368029739777,"TDIGA
71.00
71.16
69.78
68.97
68.22
69.41
66.09
66.12
41.25
41.31"
WHILE NOT INJECTING ALL NODES DO,0.9302973977695167,"38.72
34.19
38.78
23.41
33.94
20.78
17.66
16.06
38.38
38.28"
WHILE NOT INJECTING ALL NODES DO,0.9312267657992565,"ATDGIA
71.06
70.88
70.56
69.19
69.03
69.56
66.09
66.19
44.06
43.75"
WHILE NOT INJECTING ALL NODES DO,0.9321561338289963,"68.97
61.03
37.88
41.69
33.69
34.25
19.16
17.28
39.03
38.84"
WHILE NOT INJECTING ALL NODES DO,0.9330855018587361,"AVG
62.27
61.16
54.81
53.19
53.06
50.86
44.60
43.95
42.70
42.43"
WHILE NOT INJECTING ALL NODES DO,0.9340148698884758,Table 24: Detailed results of targeted attacks on Arxiv (2)
WHILE NOT INJECTING ALL NODES DO,0.9349442379182156,"RobustGCN
RGAT+LN
RGAT+FLAG+LN
GCN+LNi+FLAG
RGAT+FLAG
GCN+LNi+LN
GCN+LNi
GCN+LNi+FLAG+LN
GAT+LN
GAT+FLAG+LN"
WHILE NOT INJECTING ALL NODES DO,0.9358736059479554,"67.69
72.06
71.41
71.34
71.16
71.97
71.59
71.75
69.94
69.94"
WHILE NOT INJECTING ALL NODES DO,0.9368029739776952,"PGD
38.66
40.31
38.06
32.19
37.78
29.09
29.97
29.72
36.34
38.84"
WHILE NOT INJECTING ALL NODES DO,0.9377323420074349,"37.22
37.06
34.28
32.75
23.69
28.91
29.56
29.28
28.88
30.47"
WHILE NOT INJECTING ALL NODES DO,0.9386617100371747,"MetaGIA
35.00
42.56
41.28
30.28
41.03
28.91
28.59
28.50
16.00
14.84"
WHILE NOT INJECTING ALL NODES DO,0.9395910780669146,"33.22
34.09
32.53
30.03
27.81
27.50
27.97
27.47
19.44
21.50"
WHILE NOT INJECTING ALL NODES DO,0.9405204460966543,"AGIA
41.06
42.12
42.06
32.53
39.75
33.09
32.56
31.84
23.84
21.12"
WHILE NOT INJECTING ALL NODES DO,0.9414498141263941,"41.97
23.84
23.66
35.19
23.03
34.03
34.47
34.25
16.97
14.94"
WHILE NOT INJECTING ALL NODES DO,0.9423791821561338,"TDIGA
44.28
43.84
43.91
36.31
42.12
36.34
35.12
36.16
27.38
24.50"
WHILE NOT INJECTING ALL NODES DO,0.9433085501858736,"40.81
32.38
31.50
39.47
28.31
38.50
38.62
37.91
27.56
29.28"
WHILE NOT INJECTING ALL NODES DO,0.9442379182156134,"ATDGIA
43.12
44.34
44.22
34.47
41.91
33.53
33.44
33.28
31.06
24.19"
WHILE NOT INJECTING ALL NODES DO,0.9451672862453532,"37.97
39.00
37.84
33.84
30.19
30.53
30.47
30.59
30.28
33.69"
WHILE NOT INJECTING ALL NODES DO,0.9460966542750929,"AVG
41.91
41.05
40.07
37.13
36.98
35.67
35.67
35.52
29.79
29.39"
WHILE NOT INJECTING ALL NODES DO,0.9470260223048327,Table 25: Detailed results of targeted attacks on Aminer (1)
WHILE NOT INJECTING ALL NODES DO,0.9479553903345725,"EGuard+LNi+FLAG
EGuard+LNi+FLAG+LN
Guard+LNi
Guard+LNi+LN
EGuard+FLAG
Guard
RGAT+FLAG
Guard+LN
EGuard+FLAG+LN
RGAT"
WHILE NOT INJECTING ALL NODES DO,0.9488847583643123,"59.03
58.06
60.72
60.85
57.06
57.25
61.75
58.50
58.81
62.78"
WHILE NOT INJECTING ALL NODES DO,0.949814126394052,"PGD
55.25
48.47
56.31
49.40
53.03
53.16
41.84
49.72
48.31
40.72"
WHILE NOT INJECTING ALL NODES DO,0.9507434944237918,"39.06
39.47
37.03
39.40
35.16
34.62
33.53
29.69
29.97
31.75"
WHILE NOT INJECTING ALL NODES DO,0.9516728624535316,"MetaGIA
52.09
50.66
52.35
49.81
49.03
48.97
46.19
48.34
47.59
45.81"
WHILE NOT INJECTING ALL NODES DO,0.9526022304832714,"42.09
45.16
40.26
43.42
37.00
37.09
41.47
36.88
36.62
41.12"
WHILE NOT INJECTING ALL NODES DO,0.9535315985130112,"AGIA
54.06
48.00
54.82
48.17
51.28
51.34
48.72
48.78
47.59
48.25"
WHILE NOT INJECTING ALL NODES DO,0.9544609665427509,"26.44
29.94
23.25
28.08
19.84
18.97
26.50
23.19
24.06
25.78"
WHILE NOT INJECTING ALL NODES DO,0.9553903345724907,"TDIGA
52.75
46.72
53.68
46.92
50.75
50.87
42.50
47.66
46.28
40.81"
WHILE NOT INJECTING ALL NODES DO,0.9563197026022305,"24.31
28.91
18.54
26.07
16.12
15.06
24.00
19.69
20.66
22.5"
WHILE NOT INJECTING ALL NODES DO,0.9572490706319703,"ATDGIA
53.44
51.00
53.69
49.32
50.34
50.50
45.44
49.97
49.59
45.25"
WHILE NOT INJECTING ALL NODES DO,0.95817843866171,"38.19
42.66
35.93
41.07
33.72
33.72
36.72
31.91
31.69
35.94"
WHILE NOT INJECTING ALL NODES DO,0.9591078066914498,"AVG
45.16
44.46
44.23
43.86
41.21
41.05
40.79
40.39
40.11
40.06"
WHILE NOT INJECTING ALL NODES DO,0.9600371747211895,Table 26: Detailed results of targeted attacks on Aminer (2)
WHILE NOT INJECTING ALL NODES DO,0.9609665427509294,"RGAT+FLAG+LN
GCN+LNi+FLAG+LN
RGAT+LN
Sage+LNi+FLAG+LN
GCN+LNi+FLAG
GCN+LNi+LN
Sage+LNi+LN
GAT+LNi+LN
GAT+LNi+FLAG+LN
Sage+LNi+FLAG"
WHILE NOT INJECTING ALL NODES DO,0.9618959107806692,"62.66
64.41
63.78
65.56
63.91
66.88
65.44
66.97
65.78
64.34"
WHILE NOT INJECTING ALL NODES DO,0.9628252788104089,"PGD
31.97
28.03
29.75
26.22
26.81
22.65
23.78
17.00
16.66
22.03"
WHILE NOT INJECTING ALL NODES DO,0.9637546468401487,"29.06
28.16
27.06
26.44
26.81
23.17
23.88
17.58
16.53
22.06"
WHILE NOT INJECTING ALL NODES DO,0.9646840148698885,"MetaGIA
41.38
41.12
40.78
37.56
36.72
38.17
36.56
38.40
37.31
31.25"
WHILE NOT INJECTING ALL NODES DO,0.9656133828996283,"39.62
42.16
38.03
37.38
36.03
37.89
36.03
37.60
37.31
31.12"
WHILE NOT INJECTING ALL NODES DO,0.966542750929368,"AGIA
38.34
34.62
37.47
31.94
33.97
31.21
31.31
29.96
29.62
29.50"
WHILE NOT INJECTING ALL NODES DO,0.9674721189591078,"28.19
29.03
27.06
27.19
28.00
27.14
26.31
22.00
21.09
25.25"
WHILE NOT INJECTING ALL NODES DO,0.9684014869888475,"TDIGA
30.47
28.44
28.25
24.41
24.97
20.85
22.19
15.39
15.16
20.56"
WHILE NOT INJECTING ALL NODES DO,0.9693308550185874,"27.12
27.53
24.97
24.56
24.84
22.19
22.22
15.75
14.03
20.16"
WHILE NOT INJECTING ALL NODES DO,0.9702602230483272,"ATDGIA
39.28
36.62
38.03
33.38
32.09
32.44
32.47
34.83
35.12
27.62"
WHILE NOT INJECTING ALL NODES DO,0.9711895910780669,"32.66
37.72
31.50
31.87
31.78
32.00
30.72
33.97
33.06
26.12"
WHILE NOT INJECTING ALL NODES DO,0.9721189591078067,"AVG
36.43
36.17
35.15
33.32
33.27
32.24
31.90
29.95
29.24
29.09"
WHILE NOT INJECTING ALL NODES DO,0.9730483271375465,Published as a conference paper at ICLR 2022
WHILE NOT INJECTING ALL NODES DO,0.9739776951672863,Table 27: Detailed results of targeted attacks on Reddit (1)
WHILE NOT INJECTING ALL NODES DO,0.974907063197026,"Guard+LNi+LN
RobustGCN
RobustGCN+FLAG
Guard+LNi
Guard+LN
EGuard+LNi+FLAG+LN
EGuard+FLAG+LN
Sage+LNi+FLAG+LN
Guard
EGuard+FLAG"
WHILE NOT INJECTING ALL NODES DO,0.9758364312267658,"94.47
95.08
95.30
94.42
94.61
94.61
94.60
97.10
94.05
94.08"
WHILE NOT INJECTING ALL NODES DO,0.9767657992565055,"PGD
92.91
84.81
83.84
93.03
92.69
92.69
92.53
76.25
92.44
92.72"
WHILE NOT INJECTING ALL NODES DO,0.9776951672862454,"80.03
86.12
84.94
75.53
68.53
69.31
69.34
75.25
56.44
58.03"
WHILE NOT INJECTING ALL NODES DO,0.9786245353159851,"MetaGIA
93.53
88.25
87.22
93.28
93.38
93.66
93.59
80.72
92.40
92.88"
WHILE NOT INJECTING ALL NODES DO,0.9795539033457249,"77.47
90.06
90.44
69.91
65.28
68.00
68.34
83.62
46.75
48.59"
WHILE NOT INJECTING ALL NODES DO,0.9804832713754646,"AGIA
93.62
86.09
87.84
92.84
93.16
92.78
92.69
81.59
92.19
91.31"
WHILE NOT INJECTING ALL NODES DO,0.9814126394052045,"88.66
85.06
87.84
85.34
83.09
77.06
77.31
72.19
78.16
67.06"
WHILE NOT INJECTING ALL NODES DO,0.9823420074349443,"TDIGA
93.03
90.19
89.91
92.25
92.59
92.91
92.53
80.94
91.25
91.59"
WHILE NOT INJECTING ALL NODES DO,0.983271375464684,"86.03
89.06
88.91
80.38
78.69
81.56
81.25
79.78
64.09
66.62"
WHILE NOT INJECTING ALL NODES DO,0.9842007434944238,"ATDGIA
93.34
87.34
84.91
92.38
92.69
93.97
93.81
76.53
91.62
93.00"
WHILE NOT INJECTING ALL NODES DO,0.9851301115241635,"90.78
88.84
88.38
87.94
88.06
79.44
79.25
78.66
80.69
63.22"
WHILE NOT INJECTING ALL NODES DO,0.9860594795539034,"AVG
89.44
88.26
88.14
87.03
85.71
85.09
85.02
80.24
80.01
78.10"
WHILE NOT INJECTING ALL NODES DO,0.9869888475836431,Table 28: Detailed results of targeted attacks on Reddit (2)
WHILE NOT INJECTING ALL NODES DO,0.9879182156133829,"EGuard+LNi+FLAG
Sage+LNi+LN
GAT+LNi+FLAG+LN
Sage+FLAG+LN
Sage+LN
GAT+LNi+LN
GAT+FLAG+LN
GAT+LN
Sage+LNi+FLAG
GCN+LNi+FLAG+LN"
WHILE NOT INJECTING ALL NODES DO,0.9888475836431226,"94.07
97.10
95.19
97.13
97.11
95.37
94.49
94.77
97.09
95.84"
WHILE NOT INJECTING ALL NODES DO,0.9897769516728625,"PGD
92.69
74.94
75.91
67.47
63.75
70.38
73.53
78.12
57.16
71.28"
WHILE NOT INJECTING ALL NODES DO,0.9907063197026023,"58.12
73.91
79.59
67.72
64.72
72.91
78.16
76.47
56.62
70.91"
WHILE NOT INJECTING ALL NODES DO,0.991635687732342,"MetaGIA
92.84
78.63
68.16
84.03
82.53
67.28
59.91
62.94
65.69
62.13"
WHILE NOT INJECTING ALL NODES DO,0.9925650557620818,"48.69
80.56
78.84
80.06
76.59
75.22
74.34
66.12
69.59
59.66"
WHILE NOT INJECTING ALL NODES DO,0.9934944237918215,"AGIA
91.31
69.50
59.53
62.66
57.19
51.75
43.22
50.28
67.88
59.28"
WHILE NOT INJECTING ALL NODES DO,0.9944237918215614,"66.97
58.47
74.19
51.16
49.19
51.12
72.91
46.19
55.75
52.53"
WHILE NOT INJECTING ALL NODES DO,0.9953531598513011,"TDIGA
91.59
78.09
73.12
74.00
68.62
70.34
64.81
73.00
65.28
58.84"
WHILE NOT INJECTING ALL NODES DO,0.9962825278810409,"66.41
77.22
73.91
75.72
71.75
69.72
64.75
67.97
65.44
58.09"
WHILE NOT INJECTING ALL NODES DO,0.9972118959107806,"ATDGIA
93.03
73.31
64.25
68.44
63.59
64.53
53.66
57.91
65.12
62.34"
WHILE NOT INJECTING ALL NODES DO,0.9981412639405205,"63.34
73.78
72.53
69.62
65.00
65.22
62.97
65.50
63.66
57.97"
WHILE NOT INJECTING ALL NODES DO,0.9990706319702602,"AVG
78.10
75.96
74.11
72.55
69.09
68.53
67.52
67.21
66.30
64.44"
