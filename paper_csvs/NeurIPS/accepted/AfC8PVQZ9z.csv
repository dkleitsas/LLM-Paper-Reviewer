Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.004081632653061225,"We study multi-task representation learning for the problem of pure exploration
in bilinear bandits. In bilinear bandits, an action takes the form of a pair of arms
from two different entity types and the reward is a bilinear function of the known
feature vectors of the arms. In the multi-task bilinear bandit problem, we aim
to find optimal actions for multiple tasks that share a common low-dimensional
linear representation. The objective is to leverage this characteristic to expedite the
process of identifying the best pair of arms for all tasks. We propose the algorithm
GOBLIN that uses an experimental design approach to optimize sample allocations
for learning the global representation as well as minimize the number of samples
needed to identify the optimal pair of arms in individual tasks. To the best of
our knowledge, this is the first study to give sample complexity analysis for pure
exploration in bilinear bandits with shared representation. Our results demonstrate
that by learning the shared representation across tasks, we achieve significantly
improved sample complexity compared to the traditional approach of solving tasks
independently."
INTRODUCTION,0.00816326530612245,"1
Introduction"
INTRODUCTION,0.012244897959183673,"Bilinear bandits (Jun et al., 2019; Lu et al., 2021; Kang et al., 2022) are an important class of
sequential decision-making problems. In bilinear bandits (as opposed to the standard linear bandit
setting) we are given a pair of arms xt ∈Rd1 and zt ∈Rd2 at every round t and the interaction
of this pair of arms with a low-rank hidden parameter, Θ∗∈Rd1×d2 generates the noisy feedback
(reward) rt = x⊤
t Θ∗zt + ηt. The ηt is random 1-subGaussian noise."
INTRODUCTION,0.0163265306122449,"A lot of real-world applications exhibit the above bilinear feedback structure, particularly applications
that involve selecting pairs of items and evaluating their compatibility. For example, in a drug
discovery application, scientists may want to determine whether a particular (drug, protein) pair
interacts in the desired way (Luo et al., 2017). Likewise, an online dating service might match a pair
of people and gather feedback about their compatibility (Shen et al., 2023). A clothing website’s
recommendation system may suggest a pair of items (top, bottom) for a customer based on their
likelihood of matching (Reyes et al., 2021). In all of these scenarios, the two items are considered as
a single unit, and the system must utilize available feature vectors (xt, zt) to learn which features of
the pairs are most indicative of positive feedback in order to make effective recommendations. All
the previous works in this setting (Jun et al., 2019; Lu et al., 2021; Kang et al., 2022) exclusively"
INTRODUCTION,0.02040816326530612,"focused on maximizing the number of pairs with desired interactions discovered over time (regret
minimization). However, in many real-world applications where obtaining a sample is expensive
and time-consuming, e.g., clinical trials (Zhao et al., 2009; Zhang et al., 2012), it is often desirable
to identify the optimal option using as few samples as possible, i.e., we face the pure exploration
scenario (Fiez et al., 2019; Katz-Samuels et al., 2020) rather than regret minimization."
INTRODUCTION,0.024489795918367346,"Moreover, in various decision-making scenarios, we may encounter multiple interrelated tasks such
as treatment planning for different diseases (Bragman et al., 2018) and content optimization for
multiple websites (Agarwal et al., 2009). Often, there exists a shared representation among these
tasks, such as the features of drugs or the representations of website items. Therefore, we can
leverage this shared representation to accelerate learning. This area of research is called multi-task
representation learning and has recently generated a lot of attention in machine learning (Bengio
et al., 2013; Li et al., 2014; Maurer et al., 2016; Du et al., 2020; Tripuraneni et al., 2021). There
are many applications of this multi-task representation learning in real-world settings. For instance,
in clinical treatment planning, we seek to determine the optimal treatments for multiple diseases,
and there may exist a low-dimensional representation common to multiple diseases. To avoid the
time-consuming process of conducting clinical trials for individual tasks and collecting samples, we
utilize the shared representation and decrease the number of required samples."
INTRODUCTION,0.02857142857142857,"The above multi-task representation learning naturally shows up in bilinear bandit setting as follows:
Let there be M tasks indexed as m = 1, 2, . . . , M with each task having its own hidden parameter
Θm,∗∈Rd1×d2. Let each Θm,∗has a decomposition of Θm,∗= B1Sm,∗B⊤
2 , where B1 ∈Rd1×k1
and B2 ∈Rd2×k2 are shared across tasks, but Sm,∗∈Rk1×k2 is specific for task m. We assume
that k1, k2 ≪d1, d2 and M ≫d1, d2. Thus, B1 and B2 provide a means of dimensionality
reduction. Furthermore, we assume that each Sm,∗has rank r ≪min{k1, k2}. In the terminology of
multi-task representation learning B1, B2 are called feature extractors and xm,t, zm,t are called rich
observations (Yang et al., 2020, 2022; Du et al., 2023). The reward for the task m ∈{1, 2, . . . , M}
at round t is"
INTRODUCTION,0.0326530612244898,"rm,t = x⊤
m,tΘm,∗zm,t + ηm,t = x⊤
m,tB1
| {z }
g⊤
m,t"
INTRODUCTION,0.036734693877551024,"Sm,∗B⊤
2 zm,t
| {z }
vm,t"
INTRODUCTION,0.04081632653061224,"+ηm,t = g⊤
m,tSm,∗vm,t + ηm,t.
(1)"
INTRODUCTION,0.044897959183673466,"Observe that similar to the learning procedure in Yang et al. (2020, 2022), at each round t = 1, 2, · · · ,
for each task m ∈[M], the learner selects a left and right action xm,t ∈X and zm,t ∈Z. After the
player commits the batch of actions for each task {xm,t, zm,t : m ∈[M]}, it receives the batch of
rewards {rm,t : m ∈[M]}. Also note that in (1) we define the egm,t ∈Rk1, evm,t ∈Rk2 as the latent
features, and both egm,t, evm,t are unknown to the learner and needs to be learned for each task m
(hence the name multi-task representation learning)."
INTRODUCTION,0.04897959183673469,"In this paper, we focus on pure exploration for multi-task representation learning in bilinear bandits
where the goal is to find the optimal left arm xm,∗and right arm zm,∗for each task m with a minimum
number of samples (fixed confidence setting). First, consider a single-task setting and let Θ∗have
low rank r. Let the SVD of the Θ∗= UDV⊤. Prima-facie, if U and V are known then one might
want to project all the left and right arms in the r × r subspace of U and V and reduce the bilinear
bandit problem into a r2 dimension linear bandit setting. Then one can apply one of the algorithms
from Soare et al. (2014); Fiez et al. (2019); Katz-Samuels et al. (2020) to solve this r2 dimensional
linear bandit pure exploration problem. Following the analysis of this line of work (in linear bandits)
(Mason et al., 2021; Mukherjee et al., 2022, 2023) one might conjecture that a sample complexity
bound of eO(r2/∆2) is possible where ∆is the minimum reward gap and eO(·) hides log factors.
Similarly, for the multi-task setting one might be tempted to use the linear bandit analysis of Du et al.
(2023) to convert this problem into M concurrent r2 dimensional linear bandit problems with shared
representation and achieve a sample complexity bound of eO(Mr2/∆2). However, these matrices
(subspaces) are unknown and so there is a model mismatch as noted in the regret analysis of bilinear
bandits (Jun et al., 2019; Lu et al., 2021; Kang et al., 2022). Thus it is difficult to apply the r2
dimensional linear bandit sample complexity analysis. Following the regret analysis of bilinear bandit
setting by Jun et al. (2019); Lu et al. (2021); Kang et al. (2022) we know that the effective dimension
is actually (d1 + d2)r. Similarly for the multi-task representation learning the effective dimension
should scale with the learned latent features (k1 + k2)r. Hence the natural questions to ask are these:"
INTRODUCTION,0.053061224489795916,"1) Can we design a single-task pure exploration bilinear bandit algorithm whose
sample complexity scales as eO((d1 + d2)r/∆2)?"
INTRODUCTION,0.05714285714285714,"2) Can we design an algorithm for multi-task pure exploration bilinear ban-
dit problem that can learn the latent features and has sample complexity that scales as
eO(M(k1 + k2)r/∆2)?"
INTRODUCTION,0.061224489795918366,"In this paper, we answer both these questions affirmatively. In doing so, we make the following novel
contributions to the growing literature of multi-task representation learning in online settings:"
INTRODUCTION,0.0653061224489796,"1) We formulate the multi-task bilinear representation learning problem. To our knowledge, this is
the first work that explores pure exploration in a multi-task bilinear representation learning setting."
INTRODUCTION,0.06938775510204082,"2) We proposed the algorithm GOBLIN for a single-task pure exploration bilinear bandit setting
whose sample complexity scales as eO((d1 + d2)r/∆2). This improves over RAGE (Fiez et al., 2019)
whose sample complexity scales as eO((d1d2)/∆2)."
INTRODUCTION,0.07346938775510205,"3) Our algorithm GOBLIN for multi-task pure exploration bilinear bandit problem learns the latent
features and has sample complexity that scales as eO(M(k1 + k2)r/∆2). This improves over
DouExpDes (Du et al., 2023) whose samples complexity scales as eO(M(k1k2)/∆2)."
INTRODUCTION,0.07755102040816327,"Preliminaries: We assume that ∥x∥2 ≤1, ∥z∥2 ≤1, ∥Θ∗∥F
≤S0 and the r-th largest
singular value of Θ∗∈Rd1×d2 is Sr.
Let p := d1d2 denote the ambient dimension, and
k = (d1 + d2)r denote the effective dimension.
Let [n] := {1, 2, . . . , n}.
Let x∗, z∗:=
arg maxx,z x⊤Θ∗z.
For any x, z define the gap ∆(x, z) := x⊤
∗Θ∗z∗−x⊤Θ∗z and further-
more ∆= minx̸=x∗,z̸=z∗∆(x, z). Similarly, for any arbitrary vector w ∈W define the gap
of w ∈Rp as ∆(w) := (w∗−w)⊤θ∗, for some θ∗∈Rp and furthermore, ∆= minw̸=w∗∆(w).
If A ∈Rd×d
≥0
is a positive semidefinite matrix, and w ∈Rp is a vector, let ∥w∥2
A := w⊤Aw
denote the induced semi-norm. Given any vector b ∈R|W| we denote the w-th component as
bw. Let ∆W :=

b ∈R|W| : bw ≥0, P"
INTRODUCTION,0.08163265306122448,"w∈W bw = 1
	
denote the set of probability distributions
on W. We define Y(W) = {w −w′ : ∀w, w′ ∈W, w ̸= w′} as the directions obtained from the
differences between each pair of arms and Y∗(W) = {w∗−w : ∀w ∈W\w∗} as the directions
obtained from the differences between the optimal arm and each suboptimal arm."
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.08571428571428572,"2
Pure Exploration in Single-Task Bilinear Bandits"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.08979591836734693,"In this section, we consider pure exploration in a single-task bilinear bandit setting as a warm-up to
the main goal of learning representations for the multi-task bilinear bandit. To our knowledge, this
is the first study of pure exploration in single-task bilinear bandits. We first recall the single-task
bilinear bandit setting as follows: At every round t = 1, 2, . . . the learner observes the reward
rt = x⊤
t Θ∗zt + ηt where the low rank hidden parameter Θ∗∈Rd1×d2 is unknown to the learner,
xt ∈Rd1, zt ∈Rd2 are visible to the learner, and ηt is a 1-sub-Gaussian noise. We assume that the
matrix Θ∗has a low rank r which is known to the learner and d1, d2 ≫r. Finally recall that the goal
is to identify the optimal left and right arms x∗, z∗with a minimum number of samples."
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.09387755102040816,"We propose a phase-based, two-stage arm elimination algorithm called G-Optimal Design for Bilinear
Bandits (abbreviated as GOBLIN). GOBLIN proceeds in phases indexed by ℓ= 1, 2, . . . As this
is a pure-exploration problem, the total number of samples is controlled by the total phases which
depends on the intrinsic problem complexity. Each phase ℓof GOBLIN consists of two stages; the
estimation of Θ∗stage, which runs for τ E
ℓrounds, and pure exploration in rotated arms stage that
runs for τ G
ℓrounds. We will define τ E
ℓin Section 2.1, while rotated arms and τ G
ℓare defined in
Section 2.2. At the end of every phase, GOBLIN eliminates sub-optimal arms to build the active
set for the next phase and stops when only the optimal left and right arms are remaining. Now we
discuss the individual stages that occur at every phase ℓof GOBLIN."
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.09795918367346938,"2.1
Estimating Subspaces of Θ∗(Stage 1 of the ℓ-th phase)"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.10204081632653061,"In the first stage of phase ℓ, GOBLIN estimates the row and column sub-spaces Θ∗. Then GOBLIN
uses these estimates to reduce the bilinear bandit problem in the original ambient dimension p :=
d1d2 to a lower effective dimension k := (d1 + d2)r. To do this, GOBLIN first vectorizes the
x ∈Rd1, z ∈Rd2 into a new vector w ∈Rp and then solves the E-optimal design in Step 3 of"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.10612244897959183,"Algorithm 1 (Pukelsheim, 2006; Jun et al., 2019; Du et al., 2023). Let the solution to the E-optimal
design problem at the stage 1 of ℓ-th phase be denoted by bE
ℓ. Then GOBLIN samples each w for
⌈τ E
ℓbE
ℓ,w⌉times, where τ E
ℓ= eO(√d1d2r/Sr) (step 7 of Algorithm 1). In this paper, we sample an
arm ⌈τ E
ℓbE
ℓ,w⌉number of times. However, this may lead to over-sampling of an arm than what the
design (G or E-optimal) is actually suggesting. However, we can match the number of allocations
of an arm to the design using an efficcient Rounding Procedures (see Pukelsheim (2006); Fiez et al.
(2019)). Let bΘℓbe estimate of Θ∗in stage 1 of phase ℓ. GOBLIN estimates this by solving the
following well-defined regularized minimization problem with nuclear norm penalty:"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.11020408163265306,"bΘℓ= arg min
Θ∈Rd1×d2
Lℓ(Θ) + γℓ∥Θ∥nuc,
Lℓ(Θ) = ⟨Θ, Θ⟩−
2
τ E
ℓ"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.11428571428571428,"τ E
ℓ
X"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.11836734693877551,"s=1
⟨eψν(rs · Q(xsz⊤
s )), Θ⟩
(2)"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.12244897959183673,"where Q(·), eψν(·), are appropriate functions stated in Definition 1, 3 respectively in Appendix A.3.
The Q(·) function takes as input the rank-one matrix xsz⊤
s which is obtained after reshaping ws.
Note that xs, and zs are the observed vectors in d1 and d2 dimension and bΘℓ∈Rd1×d2 Finally, set"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.12653061224489795,the regularization parameter γℓ:= 4 r
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.1306122448979592,"2(4+S2
0)Cd1d2 log(2(d1+d2)/δ)"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.1346938775510204,"τ E
ℓ
. This is in step 8 of Algorithm 1."
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.13877551020408163,"2.2
Optimal Design for Rotated Arms (Stage 2 of ℓ-th phase)"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.14285714285714285,"In stage 2 of phase ℓ, GOBLIN leverages the information about the learned sub-space of Θ∗to rotate
the arm set and then run the optimal design on the rotated arm set. Once we recover bΘℓ, one might
be tempted to run a pure exploration algorithm (Soare et al., 2014; Fiez et al., 2019; Katz-Samuels
et al., 2020; Zhu et al., 2021) to identify x∗and z∗. However, then the sample complexity will scale
with d1d2. In contrast GOBLIN uses the information about the learned sub-space of Θ∗to reduce the
problem from ambient dimension d1d2 to effective dimension (d1 + d2)r. This reduction is done as
follows: Let bΘℓ= bUℓbDℓbV⊤
ℓbe the SVD of bΘℓin the ℓ-th phase. Let bUℓ
⊥and bVℓ
⊥be orthonormal
bases of the complementary subspaces of bUℓand bVℓrespectively. Let Xℓand Zℓbe the active set of
arms in the stage 2 of phase ℓ. Then rotate the arm sets such that new rotated arm sets are as follows:"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.1469387755102041,"X ℓ= {x = [ bUℓbU⊥
ℓ]⊤x | x ∈Xℓ}, Zℓ= {z = [ bVℓbV⊥
ℓ]⊤z | z ∈Zℓ}.
(3)"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.1510204081632653,"Let bHℓ= [ bUℓbU⊥
ℓ]⊤bΘℓ[ bVℓbV⊥
ℓ]. Then define vectorized arm set so that the last (d1 −r) · (d2 −r)
components are from the complementary subspaces as follows:"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.15510204081632653,"Wℓ=

vec
 
x1:rz⊤
1:r

; vec
 
xr+1:d1z⊤
1:r

; vec
 
x1:rz⊤
r+1:d2

;"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.15918367346938775,"vec
 
xr+1:d1z⊤
r+1:d2

∈Rd1d2 : x ∈Xℓ, z ∈Zℓ"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.16326530612244897,"bθℓ,1:k = [vec( bHℓ,1:r,1:r); vec( bHℓ,r+1:d1,1:r); vec( bHℓ,1:r,r+1:d2)],
bθℓ,k+1:p = vec( bHℓ,r+1:d1,r+1:d2).
(4)"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.1673469387755102,"which implies ∥bθk+1:p∥2 = O
 
d1d2r/τ E
ℓ

by Lemma 3 in Appendix A.1. So the last p −k
components of bθℓare very small compared to the first k components. Hence, GOBLIN has now
reduced the d1d2 dimensional linear bandit to (d1 + d2)r dimensional linear bandit using (3), (4).
This is shown in step 10 of Algorithm 1."
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.17142857142857143,"Now in stage 2 of phase ℓ, GOBLIN implements G-optimal design (Pukelsheim, 2006; Fiez et al.,
2019) in the rotated arm set X ℓ, Zℓdefined in (3). To do this, first GOBLIN defines the rotated vector
w = [x1:d1; z1:d2] ∈Rp that belong to the set Wℓ. Then GOBLIN solves the G-optimal design
(Pukelsheim, 2006) as follows:"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.17551020408163265,"bbG
ℓ= arg min
bw"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.17959183673469387,"max
w,w′∈Wℓ
∥w −w′∥2
(P"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.1836734693877551,"w∈W bww w⊤+Λℓ/n)−1.
(5)"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.18775510204081633,"This is shown in step 11 of Algorithm 1 and Λℓis defined in (6). It can be shown that sampling ac-
cording to bbG
ℓleads to the optimal sample complexity. This is discussed in Remark 1 in Appendix A.2.
The key point to note from (5) is that due to the estimation in the rotated arm space Wℓwe are
guaranteed that the support of supp(bbG
ℓ) ≤eO(k(k + 1)/2) (Pukelsheim, 2006). On the other hand,"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.19183673469387755,"if the G-optimal design of Fiez et al. (2019); Katz-Samuels et al. (2020) are run in d1d2 dimension
then the support of bbG
ℓwill scale with d1d2 which will lead to higher sample complexity. Then"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.19591836734693877,"GOBLIN samples each w ∈Wℓfor ⌈τ G
ℓbG
ℓ,w⌉times, where τ G
ℓ
:= ⌈8Bℓ
∗ρG(Y(Wℓ)) log(4ℓ2|W|/δ)"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.2,"ϵ2
ℓ
⌉."
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.20408163265306123,"Note that the total length of phase ℓ, combining stages 1 and 2 is (τ E
ℓ+ τ G
ℓ) rounds. Observe that the
stage 1 design is on the whole arm set W whereas stage 2 design is on the refined active set Wℓ."
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.20816326530612245,"Let the observed features in stage 2 of phase ℓbe denoted by Wℓ∈Rτ G
ℓ×p, and rℓ∈Rτ G
ℓbe the
observed rewards. Define the diagonal matrix Λℓas"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.21224489795918366,"Λℓ= diag[λ, . . . , λ
| {z }
k
, λ⊥
ℓ, . . . , λ⊥
ℓ
|
{z
}
p−k ]
(6)"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.2163265306122449,"where, λ⊥
ℓ:= τ G
ℓ−1/8k log(1 + τ G
ℓ−1/λ) ≫λ. Deviating from Soare et al. (2014); Fiez et al. (2019)
GOBLIN constructs a regularized least square estimator at phase ℓas follows"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.22040816326530613,"bθℓ= arg min
θ∈Rp
1
2∥Wℓθ −rℓ∥2
2 + 1"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.22448979591836735,"2∥θ∥2
Λℓ.
(7)"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.22857142857142856,"This regularized least square estimator in (7) forces the last p −k components of bθℓto be very small
compared to the first k components. Then GOBLIN builds the estimate bθℓfrom (7) only from the
observations from this phase (step 13 in Algorithm 1) and eliminates sub-optimal actions in step 14
in Algorithm 1 using the estimator bθℓ. Finally GOBLIN eliminates sub-optimal arms to build the
next phase active set Wℓand stops when |Wℓ| = 1. GOBLIN outputs the arm in Wℓand reshapes it
to get the bx∗and bz∗. The full pseudocode is presented in Algorithm 1."
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.23265306122448978,Algorithm 1 G-Optimal Design for Bilinear Bandits (GOBLIN) for single-task setting
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.23673469387755103,"1: Input: arm set X, Z, confidence δ, rank r of Θ∗, spectral bound Sr of Θ∗, S, S⊥
ℓ
:="
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.24081632653061225,8d1d2r
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.24489795918367346,"τ E
ℓS2r log

d1+d2 δℓ"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.24897959183673468,"
, λ, λ⊥
ℓ:= τ G
ℓ−1/8(d1 +d2)r log(1+
τ G
ℓ−1"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.2530612244897959,"λ ). Let p := d1d2, k := (d1 +d2)r."
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.2571428571428571,"2: LetW1 ←W, ℓ←1, τ G
0 := log(4ℓ2|X|/δ). Define Λℓas in (6), Bℓ
∗:= (8
√"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.2612244897959184,"λS +
q"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.2653061224489796,"λ⊥
ℓS⊥
ℓ)."
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.2693877551020408,"3: Define a vectorized arm w := [x1:d1; z1:d2] and w ∈W. Let τ E
ℓ:=
√"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.27346938775510204,8d1d2r log(4ℓ2|W|/δℓ)
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.27755102040816326,"Sr
. Let"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.2816326530612245,"the E-optimal design be bE
ℓ:= arg minb∈△W
  P"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.2857142857142857,"w∈W bww w⊤−1.
4: while |Wℓ| > 1 do
5:
ϵℓ= 2−ℓ, δℓ= δ/ℓ2.
6:
(Stage 1:) Explore the Low-Rank Subspace"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.2897959183673469,"7:
Pull arm w ∈W exactly
l
bbE
ℓ,wτ E
ℓ
m
times and observe rewards rt, for t = 1, . . . , τ E
ℓ."
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.2938775510204082,"8:
Compute bΘℓusing (2).
9:
(Stage 2:) Reduction to low dimensional linear bandits
10:
Let the SVD of bΘℓ= bUℓbDℓbV⊤
ℓ. Rotate arms in active set Wℓ−1 to build Wℓfollowing (4)."
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.2979591836734694,"11:
Let bbG
ℓ:= arg minbw maxw,w′∈Wℓ∥w −w′∥2
(P"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.3020408163265306,w∈W bww w⊤+Λℓ/n)−1.
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.30612244897959184,"12:
Define ρG(Y(Wℓ)) := minbw maxw,w′∈Wℓ∥w −w′∥2
(P"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.31020408163265306,w∈W bww w⊤+Λℓ/n)−1.
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.3142857142857143,"13:
Set τ G
ℓ:=⌈64Bℓ
∗ρG(Y(Wℓ)) log(4ℓ2|W|/δℓ)"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.3183673469387755,"ϵ2
ℓ
⌉. Then pull arm w ∈W exactly
l
bbG
ℓ,wτ G
ℓ
m
times"
PURE EXPLORATION IN SINGLE-TASK BILINEAR BANDITS,0.3224489795918367,"and construct the least squares estimator bθℓusing only the observations of this phase where
bθℓis defined in (7). Note that bθℓis also rotated following (4).
14:
Eliminate arms such that Wℓ+1 ←Wℓ\{w ∈Wℓ: maxw′∈Wℓ⟨w′ −w, bθℓ⟩> 2ϵℓ}
15:
ℓ←ℓ+ 1
16: Output the arm in Wℓand reshape to get the bx∗and bz∗"
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.32653061224489793,"2.3
Sample Complexity Analysis of Single-Task GOBLIN"
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.3306122448979592,"We now analyze the sample complexity of GOBLIN in the single-task setting through the following
theorem."
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.3346938775510204,"Theorem 1. (informal) With probability at least 1 −δ, GOBLIN returns the best arms x∗, z∗, and
the number of samples used is bounded by eO

(d1+d2)r"
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.33877551020408164,"∆2
+
√d1d2r Sr 
."
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.34285714285714286,"Discussion 1. In Theorem 1 the first quantity is the number of samples needed to identify the best
arms x∗, z∗while the second quantity is the number of samples to learn Θ∗(which is required to
find the best arms). Note that the magnitude of Sr would be free of d1, d2 since Θ∗contains only
r nonzero singular values and ∥Θ∗∥≤1, and hence we assume that Sr = Θ(1/√r) (Kang et al.,
2022). So the sample complexity of single-task GOBLIN scales as eO( (d1+d2)r"
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.3469387755102041,"∆2
). However, if one"
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.3510204081632653,"runs RAGE (Fiez et al., 2019) on the arms in X, Z then the sample complexity will scale as eO( d1d2 ∆2 )."
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.3551020408163265,"Proof (Overview) of Theorem 1: Step 1 (Subspace estimation in high dimension): We denote
the vectorized arms in high dimension as w ∈W. We run the E-optimal design to sample the
arms in W. Note that this E-optimal design satisfies the distribution assumption of Kang et al.
(2022) which enables us to apply the Lemma 3 in Appendix A.1. This leads to ∥bΘℓ−Θ∗∥2
F ≤
C1d1d2r log(2(d1+d2)/δ)"
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.35918367346938773,"τ E
ℓ
for some C1 > 0. Also, note that in the first stage of the ℓ-th phase by"
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.363265306122449,"setting τ E
ℓ=
√"
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.3673469387755102,8d1d2r log(4ℓ2|W|/δℓ)
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.37142857142857144,"Sr
and sampling each arm w ∈W exactly ⌈bbE
ℓ,wτ E
ℓ⌉times we are
guaranteed that ∥θ∗
k+1:p∥2 = O(d1d2r/τ E
ℓ). Summing up over ℓ= 1 to

log2
 
4∆−1
we get that
the total sample complexity of the first stage is bounded by eO(√d1d2r/Sr)."
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.37551020408163266,"Step 2 (Effective dimension for rotated arms): We rotate the arms w ∈W in high dimension to get
the rotated arms w ∈Wℓin step 10 of Algorithm 1. Then we show that the effective dimension of w"
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.3795918367346939,"scales 8k log
 
1 + τ G
ℓ−1/λ

when λ⊥
ℓ=
τ G
ℓ−1
8k log(1+τ G
ℓ−1/λ) in Lemma 7 of Appendix A.4. Note that"
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.3836734693877551,"this requires a different proof technique than Valko et al. (2014) where the budget n is given apriori
and effective dimension scales with log(n). This step also diverges from the pure exploration proof
technique of Fiez et al. (2019); Katz-Samuels et al. (2020) as there is no parameter λ⊥
ℓto control
during phase ℓ, and the effective dimensions in those papers do not depend on phase length."
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.3877551020408163,"Step 3 (Bounded Support): For any phase ℓ, we can show that 1 ≤ρG(Y(Wℓ)) ≤p/γ2
Y where,
γY = max{c > 0 : cY ⊂conv(W ∪−W)} is the gauge norm of Y (Rockafellar, 2015). Note
that this is a worst-case dependence when ρG(Y(Wℓ)) scales with p. Substituting this value of
ρG(Y(Wℓ)) in the definition of λ⊥
ℓwe can show that Λℓdoes not depend on w or y = w −w′.
Then following Theorem 21.1 in Lattimore and Szepesvári (2020) we can show that the G-optimal"
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.39183673469387753,"design bbG
ℓis equivalent to D-optimal design bbD
ℓ= arg maxb log P"
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.39591836734693875,w∈Wℓbww w⊤+Λℓ
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.4,"|Λℓ|
. Then using"
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.40408163265306124,"Frank-Wolfe algorithm (Jamieson and Jain, 2022) we can show the support bbG
ℓor equivalently bbD
ℓis"
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.40816326530612246,"bounded by at most
8k log(1+τ G
ℓ−1/λ)(8k log(1+τ G
ℓ−1/λ)+1)
2
. This is shown in Lemma 9 (Appendix A.4)."
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.4122448979591837,"Step 4 (Phase length and Elimination): Using the Lemma 9, concentration Lemma 5, and using
the log determinant inequality in Lemma 7 and Proposition 1 (Appendix A.4) we show that the
phase length in the second stage is given by τ G
ℓ= ⌈8Bℓ
∗ρ(Y(Wℓ)) log(2|W|/δ)"
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.4163265306122449,"(x⊤(bθℓ−θ∗))2
⌉. This is discussed in
Discussion 3 (Appendix A.4). We show in Lemma 10 (Appendix A.4) that setting this phase length
and sampling each active arm in Wℓexactly ⌈bbℓ,wτ G
ℓ⌉times results in the elimination of sub-optimal
actions with high probability."
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.4204081632653061,"Step 5 (Total Samples): We first show that the total samples in the second phase are bounded by
O( k"
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.42448979591836733,"γ2
Y log( k log2(∆−1)|W|"
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.42857142857142855,"δ
)⌈log2(∆−1)⌉) where the effective dimension k = (d1 + d2)r. Finally,"
SAMPLE COMPLEXITY ANALYSIS OF SINGLE-TASK GOBLIN,0.4326530612244898,"we combine the total samples of phase ℓas (τ E
ℓ+ τ G
ℓ). The final sample complexity is given by
summing over all phases from ℓ= 1 to

log2
 
4∆−1
. The claim of the theorem follows by noting
eO(k/γ2
Y) ≤eO(k/∆2)."
MULTI-TASK REPRESENTATION LEARNING,0.43673469387755104,"3
Multi-task Representation Learning"
MULTI-TASK REPRESENTATION LEARNING,0.44081632653061226,"In this section, we extend GOBLIN to multi-task representation learning for the bilinear bandit setting.
In the multi-task setting, we now have M tasks, where each task m ∈[M] has a reward model stated"
MULTI-TASK REPRESENTATION LEARNING,0.4448979591836735,"in (1). The learning proceeds as follows: At each round t = 1, 2, · · · , for each task m ∈[M], the
learner selects a left and right action xm,t ∈X and zm,t ∈Z. After the player commits the batch
of actions for each task {xm,t, zm,t : m ∈[M]}, it receives the batch of rewards {rm,t : m ∈[M]}.
Finally recall that the goal is to identify the optimal left and right arms xm,∗, zm,∗for each task m
with a minimum number of samples. We now state the following assumptions to enable representation
learning across tasks."
MULTI-TASK REPRESENTATION LEARNING,0.4489795918367347,"Assumption 1. (Low-rank Tasks) We assume that the hidden parameter Θm,∗for all the m ∈[M]
have a decomposition Θm,∗= B1Sm,∗B⊤
2 and each Sm,∗has rank r."
MULTI-TASK REPRESENTATION LEARNING,0.4530612244897959,"This is similar to the assumptions in Yang et al. (2020, 2022); Du et al. (2023) ensuring the feature
extractors are shared across tasks in the bilinear bandit setting."
MULTI-TASK REPRESENTATION LEARNING,0.45714285714285713,Assumption 2. (Diverse Tasks) We assume that σmin( 1
MULTI-TASK REPRESENTATION LEARNING,0.46122448979591835,"M
PM
m=1 Θm,∗) ≥c0"
MULTI-TASK REPRESENTATION LEARNING,0.46530612244897956,"Sr , for some c0 > 0, Sr
is the r-th largest singular value of Θm,∗and σmin(A) denotes the minimum eigenvalue of matrix A."
MULTI-TASK REPRESENTATION LEARNING,0.46938775510204084,"This assumption is similar to the diverse tasks assumption of Yang et al. (2020, 2022); Tripuraneni
et al. (2021); Du et al. (2023) and ensures the possibility of recovering the feature extractors B1 and
B2 shared across tasks."
MULTI-TASK REPRESENTATION LEARNING,0.47346938775510206,"Our extension of GOBLIN to the multi-task setting is now a phase-based, three-stage arm elimination
algorithm. In GOBLIN each phase ℓ= 1, 2, . . . consists of three stages; the stage for estimation of
feature extractors B1, B2, which runs for τ E
ℓrounds, the stage for estimation of Sm,∗which runs for
P
m eτ E
m,ℓrounds, and a stage of pure exploration with rotated arms that runs for P
m τ G
m,ℓrounds.
We will define τ E
m,ℓin Section 3.1, eτ E
m,ℓin Section 3.2, while the rotated arms and τ G
m,ℓare defined
in Section 3.3. At the end of every phase, GOBLIN eliminates sub-optimal arms to build the active
set for the next phase and stops when only the optimal left and right arms are remaining. Now we
discuss the individual stages that occur at every phase ℓ= 1, 2, . . . for multi-task GOBLIN."
MULTI-TASK REPRESENTATION LEARNING,0.4775510204081633,"3.1
Estimating Feature Extractors B1 and B2 (Stage 1 of Phase ℓ)"
MULTI-TASK REPRESENTATION LEARNING,0.4816326530612245,"In the first stage of phase ℓ, GOBLIN leverages the batch of rewards {rm,t : m ∈[M]} at every
round t from M tasks to learn the feature extractors B1 and B2. To do this, GOBLIN first vectorizes
the x ∈X, z ∈Z into a new vector w = [x1:d1; z1:d2] ∈Wm and then solves the E-optimal
design in step 3 of Algorithm 2. Similar to the single-task setting (Section 2) GOBLIN samples
each w ∈Wm for ⌈τ E
ℓbE
ℓ,w⌉times for each task m, where τ E
ℓ= eO(√d1d2r/Sr) and bE
ℓ,w is the
solution to E-optimal design on w. Let the sampled arms for each task m at round s be denoted by
xm,s, zm,s which is obtained after reshaping ws. Then it builds the estimator bZℓas follows:"
MULTI-TASK REPRESENTATION LEARNING,0.4857142857142857,"bZℓ= arg min
Θ∈Rd1×d2
Lℓ(Θ) + γℓ∥Θ∥nuc,"
MULTI-TASK REPRESENTATION LEARNING,0.4897959183673469,"Lℓ(Θ) = ⟨Θ, Θ⟩−
2
Mτ E
ℓ M
X m=1"
MULTI-TASK REPRESENTATION LEARNING,0.49387755102040815,"τ E
ℓ
X"
MULTI-TASK REPRESENTATION LEARNING,0.49795918367346936,"s=1
⟨eψν(rm,s · Q(xm,sz⊤
m,s)), Θ⟩
(8)"
MULTI-TASK REPRESENTATION LEARNING,0.5020408163265306,"Then it performs SVD decomposition on bZℓ, and let bB1, bB2 be the top-k1 and top-k2 left and right
singular vectors of bZℓrespectively. These are the estimation of the feature extractors B1 and B2."
MULTI-TASK REPRESENTATION LEARNING,0.5061224489795918,"3.2
Estimating Hidden Parameter Sm,∗per Task (Stage 2 of phase ℓ)"
MULTI-TASK REPRESENTATION LEARNING,0.5102040816326531,"In the second stage of phase ℓ, the goal is to recover the hidden parameter Sm,∗for each task m.
GOBLIN proceeds as follows: First, let egm = x⊤bB1,ℓand evm = z⊤bB2,ℓbe the latent left and right
arm respectively for each m. Then GOBLIN defines the vector ew = [egm; evm] ∈f
Wm and then
solves the E-optimal design in step 11 of Algorithm 2. It then samples for each task m, the latent
arm ew ∈f
Wm for ⌈eτ E
m,ℓebE
m,ℓ, ew⌉times, where eτ E
m,ℓ:= eO(√k1k2r/Sr) and ebE
m,ℓ, ew is the solution to"
MULTI-TASK REPRESENTATION LEARNING,0.5142857142857142,"E-optimal design on ew. Then it builds estimator bSm,ℓfor each task m in step 12 as follows:
bSm,ℓ= arg min
Θ∈Rk1×k2
L′
ℓ(Θ) + γℓ∥Θ∥nuc,"
MULTI-TASK REPRESENTATION LEARNING,0.5183673469387755,"L′
ℓ(Θ) = ⟨Θ, Θ⟩−
2
eτ E
m,ℓ"
MULTI-TASK REPRESENTATION LEARNING,0.5224489795918368,"eτ E
m,ℓ
X"
MULTI-TASK REPRESENTATION LEARNING,0.5265306122448979,"s=1
⟨eψν(rm,s · Q(egm,sev⊤
m,s)), Θ⟩
(9)"
MULTI-TASK REPRESENTATION LEARNING,0.5306122448979592,"Once GOBLIN recovers the bSm,ℓfor each task m it has reduced the d1d2 bilinear bandit to a k1k2
dimension bilinear bandit where the left and right arms are egm ∈Gm, evm ∈Vm respectively."
MULTI-TASK REPRESENTATION LEARNING,0.5346938775510204,"3.3
Optimal Design for Rotated Arms per Task (Stage 3 of phase ℓ)"
MULTI-TASK REPRESENTATION LEARNING,0.5387755102040817,"In the third stage of phase ℓ, similar to Algorithm 1, the multi-task GOBLIN defines the rotated arm
set Gm, Vm for each task m for these k1k2 dimensional bilinear bandits. Let the SVD of bSm,ℓ=
bUm,ℓbDm,ℓbV⊤
m,ℓ. Define bHm,ℓ= [ bUm,ℓbU⊥
m,ℓ]⊤bSm,ℓ[ bVm,ℓbV⊥
m,ℓ]. Then define the vectorized arm
set so that the last (k1 −r) · (k2 −r) components are from the complementary subspaces as follows:"
MULTI-TASK REPRESENTATION LEARNING,0.5428571428571428,"Wm,ℓ=

vec
 egm,1:rev⊤
m,1:r

; vec
 egm,r+1:k1ev⊤
m,1:r

; vec
 egm,1:rev⊤
m,r+1:k2

;"
MULTI-TASK REPRESENTATION LEARNING,0.5469387755102041,"vec
 egm,r+1:k1ev⊤
m,r+1:k2
"
MULTI-TASK REPRESENTATION LEARNING,0.5510204081632653,"bθm,ℓ,1:k = [vec( bHm,ℓ,1:r,1:r); vec( bHm,ℓ,r+1:k1,1:r); vec( bHm,ℓ,1:r,r+1:k2)],"
MULTI-TASK REPRESENTATION LEARNING,0.5551020408163265,"θℓ,k+1:p = vec( bHm,ℓ,r+1:k1,r+1:k2).
(10)
This is shown in step 14 of Algorithm 2. Now we proceed similarly to Section 2.2. We construct a
per-task optimal design for the rotated arm set Vm, Gm and define the w = [egm,1:d1; evm,1:d2] and
ew ∈f
Wm where egm ∈Gm and evm ∈Vm respectively. Following (5) we know that to minimize the
sample complexity for the m-th bilinear bandit we need to sample according to G-optimal design
bbG
m,ℓ= arg min
bm,w"
MULTI-TASK REPRESENTATION LEARNING,0.5591836734693878,"max
w,w′∈Wm,ℓ
∥w −w′∥2
(P"
MULTI-TASK REPRESENTATION LEARNING,0.563265306122449,"w∈Wm bm,ww w⊤+Λm,ℓ/n)−1
(11)"
MULTI-TASK REPRESENTATION LEARNING,0.5673469387755102,"Then GOBLIN runs G-optimal design on the arm set Wℓfollowing the (11) and then samples each
w ∈Wm,ℓfor ⌈τ G
m,ℓbbG
m,ℓ,w⌉times where bbG
m,ℓ,w is the solution to the G-optimal design, and τ G
ℓ
is defined in step 17 of Algorithm 2. So the total length of phase ℓ, combining stages 1, 2 and 3 is
(τ E
ℓ+ P"
MULTI-TASK REPRESENTATION LEARNING,0.5714285714285714,"m eτ E
m,ℓ+ P"
MULTI-TASK REPRESENTATION LEARNING,0.5755102040816327,"m τ G
m,ℓ) rounds. Observe that the stage 1 and 2 design is on the whole arm"
MULTI-TASK REPRESENTATION LEARNING,0.5795918367346938,"set W, f
Wm whereas the stage 3 design is on the refined active set Wm,ℓ. Let at the stage 3 of ℓ-th"
MULTI-TASK REPRESENTATION LEARNING,0.5836734693877551,"phase the actions sampled be denoted by the matrix Wm,ℓ∈Rτ G
m,ℓ×k1k2 and observed rewards"
MULTI-TASK REPRESENTATION LEARNING,0.5877551020408164,"rm ∈Rτ G
m,ℓ×k1k2. Define the positive diagonal matrix Λm,ℓaccording to (6) but set p = k1k2 and
k = (k1 + k2)r. Then similar to Section 2.2 we can build for each task m only from the observations
from this phase
bθm,ℓ= arg min
θ
1
2∥Wm,ℓθ −rm∥2
2 + 1"
MULTI-TASK REPRESENTATION LEARNING,0.5918367346938775,"2∥θ∥2
Λm,ℓ
(12)"
MULTI-TASK REPRESENTATION LEARNING,0.5959183673469388,"Finally GOBLIN eliminates the sub-optimal arms using the estimator bθm,ℓto build the next phase
active set Wm,ℓand stops when |Wm,ℓ| = 1. The full pseudo-code is given in Algorithm 2."
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6,"3.4
Sample Complexity analysis of Multi-task GOBLIN"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6040816326530613,"We now present the sample complexity of GOBLIN for the multi-task setting.
Theorem 2. (informal) With probability at least 1−δ, GOBLIN returns the best arms xm,∗, zm,∗for"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6081632653061224,"each task m, and the total number of samples is bounded by eO

M(k1+k2)r"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6122448979591837,"∆2
+ M√k1k2r"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6163265306122448,"Sr
+
√d1d2r Sr 
."
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6204081632653061,"Discussion 2. In Theorem 2 the first quantity is the sample complexity to identify the best arms xm,∗,
zm,∗and the second quantity is the number of samples to learn Sm,∗for each task m. This is required
to rotate the arms to reach the effective dimension of (k1 + k2)r. Finally, the third quantity is the
number of samples needed to learn Θm,∗(which in turn is used to estimate the feature extractors
B1 and B2 to learn the Sm,∗). Again we assume that Sr = Θ(1/√r) (Kang et al., 2022). So the
sample complexity of multi-task GOBLIN scales as eO(M(k1 + k2)r/∆2). However, if one runs
DouExpDes (Du et al., 2023) then the sample complexity will scale as eO(M(k1k2)/∆2) which is
worse than GOBLINwhen r ≪k1 or k2."
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6244897959183674,Algorithm 2 G-Optimal Design for Bilinear Bandits (GOBLIN) for multi-task setting
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6285714285714286,"1: Input: arm set X, Z, confidence δ, rank r of Θ∗, spectral bound Sr of Θ∗, S, S⊥
m,ℓ="
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6326530612244898,"8k1k2r
eτ E
m,ℓS2r log( k1+k2"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.636734693877551,"δℓ
), λ, λ⊥
m,ℓ=
τ G
m,ℓ−1
(8(k1+k2)r log(1+τ G
m,ℓ−1/λ)). Let p = k1k2, k = (k1 + k2)r."
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6408163265306123,"2: Let Wm,1 ←Wm, ℓ←1, τ G
0 = log(4ℓ2|X|/δ). Define Λm,ℓas in (6), Bℓ
m,∗:= (8
√ λS+
q"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6448979591836734,"λ⊥
m,ℓS⊥
m,ℓ)"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6489795918367347,"3: Define arm w = [x1:d1; z1:d2] and w ∈Wm. Let τ E
ℓ=
√"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6530612244897959,8d1d2r log(4ℓ2|W|/δℓ)
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6571428571428571,"Sr
. Let E-optimal
design be bE
ℓ=arg minb∈△W
(P"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6612244897959184,"w∈W bww w⊤)−1."
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6653061224489796,"4: while ∃m ∈[M],
Wm,ℓ
 > 1 do
5:
ϵℓ= 2−ℓ, δℓ= δ/ℓ2.
6:
(Stage 1:) Explore the Low-Rank Subspace"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6693877551020408,"7:
Pull arm w ∈W exactly ⌈bbE
ℓ,wτ E
ℓ⌉times for each task m and observe rewards {rm,t}τ E
ℓ
t=1."
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.673469387755102,"8:
Compute bZℓusing (8).
9:
(Stage 2:) Build bSm,ℓfor each task m"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6775510204081633,"10:
Let bB1,ℓ, bB2,ℓbe the top-k1 left and top-k2 right singular vectors of bZℓrespectively. Build
egm = x⊤bB1,ℓand evm = z⊤bB2,ℓfor all x ∈X and z ∈Z for each m."
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6816326530612244,"11:
Define a vectorized arm ew = [egm,1:k1; evm,1:k2] and ew ∈f
Wm for each m. Let eτ E
m,ℓ=
√"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6857142857142857,8k1k2r log(4ℓ2|W|/δℓ)
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.689795918367347,"Sr
, and ebE
m,ℓ= arg minbm∈△f
Wm
  P"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6938775510204082,"ew∈f
Wm bm, ew ew ew⊤−1."
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.6979591836734694,"12:
Pull arm ew ∈f
Wm exactly
l
ebE
m,ℓ, eweτ E
m,ℓ
m
times and observe rewards rm,t, for t ="
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.7020408163265306,"1, . . . , eτ E
m,ℓ, for each task m. Then compute bSm,ℓusing (9) for each m.
13:
(Stage 3:) Reduction to low dimensional linear bandits for each task m
14:
SVD of bSm,ℓ=bUm,ℓbDm,ℓbV⊤
m,ℓ. Rotate arms in active set Wm,ℓ−1 to build Wm,ℓusing (10)."
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.7061224489795919,"15:
Let bbG
m,ℓ=arg minbm,w maxw,w′∈Wm,ℓ∥w −w′∥2
(P"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.710204081632653,"wm∈Wm bm,wwm w⊤
m+Λm,ℓ/n)−1."
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.7142857142857143,"16:
Define ρG(Y(Wm,ℓ))=min
bm,w
max
w,w′∈Wm,ℓ
∥w−w′∥2 (P"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.7183673469387755,"w∈Wm bm,ww w⊤+Λm,ℓ"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.7224489795918367,"n
)−1."
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.726530612244898,"17:
Set τ G
m,ℓ=
64Bℓ
m,∗ρG(Y(Wm,ℓ)) log(4ℓ2|Wm|/δℓ)"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.7306122448979592,"ϵ2
ℓ
. Then pull arm w ∈Wm for each task m"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.7346938775510204,"exactly ⌈bbm,ℓ,wτ G
m,ℓ⌉times and construct the least squares estimator bθm,ℓusing only the"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.7387755102040816,"observations of this phase where bθm,ℓis defined in (12)."
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.7428571428571429,"18:
Eliminate arms such that Wm,ℓ+1 ←Wm,ℓ\
n
wm ∈Wm,ℓ: maxw′
m∈Wm,ℓ
D
w′
m −wm, bθm,ℓ
E
> 2ϵm,ℓ
o"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.746938775510204,"19:
ℓ←ℓ+ 1
20: Output the arm in Wm,ℓand reshape to get the bxm,∗and bzm,∗for each task m."
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.7510204081632653,"Proof (Overview) of Theorem 2: Step 1 (Subspace estimation in high dimension): The first steps
diverge from the proof technique of Theorem 1. We now build the average estimator bZℓto estimate the
quantity Z∗=
1
M
PM
m=1 Θ∗,m using (8). This requires us to modify the Lemma 3 in Appendix A.1
and apply Stein’s lemma (Lemma 1) to get a bound of ∥bZℓ−Z∗∥2
F ≤C1d1d2r log(2(d1+d2)/δ)"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.7551020408163265,"τ E
ℓ
for some"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.7591836734693878,"C1 > 0. This is shown in Lemma 12 in Appendix A.6. Summing up over ℓ= 1 to

log2
 
4∆−1"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.763265306122449,we get that the total samples complexity of the first stage is bounded by eO(√d1d2r/Sr).
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.7673469387755102,"Step 2 (Estimation of left and right feature extractors): Now using the estimator in (8) we get a
good estimation of the feature extractors B1 and B2. Let bB1,ℓ, bB2,ℓbe the top-k1 left and top-k2
right singular vectors of bZℓrespectively. Then using the Davis-Kahan sin θ Theorem (Bhatia, 2013)"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.7714285714285715,"in Lemma 14, 15 (Appendix A.6) we have ∥(bB⊥
1,ℓ)⊤B1∥, ∥(bB⊥
2,ℓ)⊤B2∥≤eO(
q"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.7755102040816326,"(d1 + d2)r/Mτ E
ℓ)."
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.7795918367346939,"Step 3 (Estimation of bSm,ℓin low dimension): Now we estimate the quantity bSm,ℓ∈Rk1×k2 for
each task m. To do this we first build the latent arms egm = x⊤bUℓand evm = z⊤bVℓfor all x ∈X"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.7836734693877551,"and z ∈Z for each m, and sample them following the E-optimal design in step 12 of Algorithm 2.
We also show in Lemma 16 (Appendix A.6) that σmin(P"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.7877551020408163,"ew∈f
W b ew ew ew⊤) > 0 which enables us to
sample following E-optimal design. Then use the estimator in (9). Then in Lemma 19 we show that
∥bSm,ℓ−µ∗Sm,∗∥2
F ≤C1k1k2r log

2(k1+k2) δℓ"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.7918367346938775,"
/τ E
m,ℓholds with probability greater than (1 −δ)."
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.7959183673469388,"Also, note that in the second phase by setting eτ E
m,ℓ=
p"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.8,8k1k2r log(4ℓ2|W|/δℓ)/Sr and sampling
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.8040816326530612,"each arm w ∈W exactly ⌈bbE
ℓ,weτ E
m,ℓ⌉times we are guaranteed that ∥θ∗
k+1:p∥2 = O(k1k2r/eτ E
m,ℓ) in
the ℓ-th phase. Summing up over ℓ= 1 to

log2
 
4∆−1
across each task M we get that the total
samples complexity of the second stage is bounded by eO(M√k1k2r/Sr)."
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.8081632653061225,"Step 4 (Convert to k1k2 bilinear bandits): Once GOBLIN recovers bSm,τ E
ℓit rotates the arm set
following (10) to build Wm to get the k1k2 bilinear bandits. The rest of the steps follow the same
way as in steps 2, 3 and 4 of proof of Theorem 1."
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.8122448979591836,"Step 5 (Total Samples):
We show the total samples in the third phase are bounded by
O( k"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.8163265306122449,"γ2
Y log( k log2(∆−1)|W|"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.8204081632653061,"δ
)⌈log2(∆−1)⌉) where the effective dimension k = (k1 + k2)r. The to-"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.8244897959183674,"tal samples of phase ℓis given by τ E
ℓ+P"
SAMPLE COMPLEXITY ANALYSIS OF MULTI-TASK GOBLIN,0.8285714285714286,"m(eτ E
m,ℓ+τ G
m,ℓ). Finally, we get the total sample complexity
by summing over all phases from ℓ= 1 to ⌈log2
 
4∆−1
⌉. The claim of the theorem follows by
noting eO(k/γ2
Y) ≤eO(k/∆2)."
EXPERIMENTS,0.8326530612244898,"4
Experiments"
EXPERIMENTS,0.8367346938775511,"In this section, we conduct proof-of-concept experiments on both single and multi-task bilinear
bandits. In the single-task experiment, we compare against the state-of-the-art RAGE algorithm (Fiez
et al., 2019). We show in Figure 1 (left) that GOBLIN requires fewer samples than the RAGE with
an increasing number of arms. In the multi-task experiment, we compare against the state-of-the-art
DouExpDes algorithm (Du et al., 2023). We show in Figure 1 (right) that GOBLIN requires fewer
samples than DouExpDes with an increasing number of tasks. As experiments are not a central
contribution, we defer a fuller description of the experimental set-up to Appendix A.8."
EXPERIMENTS,0.8408163265306122,"Figure 1: (Left) Single-task experiment: results show the number of samples required to identify the
optimal action pair for differing numbers of actions. (Right) Multi-task experiment: results show the
number of samples required to identify the optimal action pair for varying numbers of tasks."
CONCLUSIONS AND FUTURE DIRECTIONS,0.8448979591836735,"5
Conclusions and Future Directions"
CONCLUSIONS AND FUTURE DIRECTIONS,0.8489795918367347,"In this paper, we formulated the first pure exploration multi-task representation learning problem. We
introduce an algorithm, GOBLIN that achieves a sample complexity bound of eO((d1 + d2)r/∆2)
which improves upon the eO((d1d2)/∆2) sample complexity of RAGE (Fiez et al., 2019) in a single-
task setting. We then extend GOBLIN for multi-task pure exploration bilinear bandit problems
by learning latent features which enables sample complexity that scales as eO(M(k1 + k2)r/∆2)
which improves over the eO(M(k1k2)/∆2) sample complexity of DouExpDes (Du et al., 2023). Our
analysis opens an exciting opportunity to analyze representation learning in the kernel and neural
bandits (Zhu et al., 2021; Mason et al., 2021). We can leverage the fact that this type of optimal
design does not require the arm set to be an ellipsoid (Du et al., 2023) which enables us to extend our
analysis to non-linear representations."
REFERENCES,0.8530612244897959,References
REFERENCES,0.8571428571428571,"Agarwal, D., Chen, B.-C., and Elango, P. (2009). Explore/exploit schemes for web content optimiza-
tion. In 2009 Ninth IEEE International Conference on Data Mining, pages 1–10. IEEE."
REFERENCES,0.8612244897959184,"Bengio, Y., Courville, A., and Vincent, P. (2013). Representation learning: A review and new
perspectives. IEEE transactions on pattern analysis and machine intelligence, 35(8):1798–1828."
REFERENCES,0.8653061224489796,"Bhatia, R. (2013). Matrix analysis, volume 169. Springer Science & Business Media."
REFERENCES,0.8693877551020408,"Bragman, F. J., Tanno, R., Eaton-Rosen, Z., Li, W., Hawkes, D. J., Ourselin, S., Alexander, D. C.,
McClelland, J. R., and Cardoso, M. J. (2018). Uncertainty in multitask learning: joint representa-
tions for probabilistic mr-only radiotherapy planning. In Medical Image Computing and Computer
Assisted Intervention–MICCAI 2018: 21st International Conference, Granada, Spain, September
16-20, 2018, Proceedings, Part IV 11, pages 3–11. Springer."
REFERENCES,0.8734693877551021,"Du, S. S., Hu, W., Kakade, S. M., Lee, J. D., and Lei, Q. (2020). Few-shot learning via learning the
representation, provably. arXiv preprint arXiv:2002.09434."
REFERENCES,0.8775510204081632,"Du, Y., Huang, L., and Sun, W. (2023). Multi-task representation learning for pure exploration in
linear bandits. arXiv preprint arXiv:2302.04441."
REFERENCES,0.8816326530612245,"Fiez, T., Jain, L., Jamieson, K. G., and Ratliff, L. (2019). Sequential experimental design for
transductive linear bandits. Advances in neural information processing systems, 32."
REFERENCES,0.8857142857142857,"Jamieson, K. and Jain, L. (2022). Interactive machine learning."
REFERENCES,0.889795918367347,"Jun, K.-S., Willett, R., Wright, S., and Nowak, R. (2019). Bilinear bandits with low-rank structure.
In International Conference on Machine Learning, pages 3163–3172. PMLR."
REFERENCES,0.8938775510204081,"Kang, Y., Hsieh, C.-J., and Lee, T. C. M. (2022). Efficient frameworks for generalized low-rank
matrix bandit problems. Advances in Neural Information Processing Systems, 35:19971–19983."
REFERENCES,0.8979591836734694,"Katz-Samuels, J., Jain, L., Jamieson, K. G., et al. (2020). An empirical process approach to the union
bound: Practical algorithms for combinatorial and linear bandits. Advances in Neural Information
Processing Systems, 33:10371–10382."
REFERENCES,0.9020408163265307,"Kiefer, J. and Wolfowitz, J. (1960). The equivalence of two extremum problems. Canadian Journal
of Mathematics, 12:363–366."
REFERENCES,0.9061224489795918,"Lattimore, T. and Szepesvári, C. (2020). Bandit algorithms. Cambridge University Press."
REFERENCES,0.9102040816326531,"Li, J., Zhang, H., Zhang, L., Huang, X., and Zhang, L. (2014). Joint collaborative representation with
multitask learning for hyperspectral image classification. IEEE Transactions on Geoscience and
Remote Sensing, 52(9):5923–5936."
REFERENCES,0.9142857142857143,"Lu, Y., Meisami, A., and Tewari, A. (2021). Low-rank generalized linear bandit problems. In
International Conference on Artificial Intelligence and Statistics, pages 460–468. PMLR."
REFERENCES,0.9183673469387755,"Luo, Y., Zhao, X., Zhou, J., Yang, J., Zhang, Y., Kuang, W., Peng, J., Chen, L., and Zeng, J. (2017).
A network integration approach for drug-target interaction prediction and computational drug
repositioning from heterogeneous information. Nature communications, 8(1):573."
REFERENCES,0.9224489795918367,"Mason, B., Camilleri, R., Mukherjee, S., Jamieson, K., Nowak, R., and Jain, L. (2021). Nearly
optimal algorithms for level set estimation. arXiv preprint arXiv:2111.01768."
REFERENCES,0.926530612244898,"Maurer, A., Pontil, M., and Romera-Paredes, B. (2016). The benefit of multitask representation
learning. Journal of Machine Learning Research, 17(81):1–32."
REFERENCES,0.9306122448979591,"Minsker, S. (2018). Sub-gaussian estimators of the mean of a random matrix with heavy-tailed entries.
The Annals of Statistics, 46(6A):2871–2903."
REFERENCES,0.9346938775510204,"Mukherjee, S., Tripathy, A. S., and Nowak, R. (2022). Chernoff sampling for active testing and
extension to active regression. In International Conference on Artificial Intelligence and Statistics,
pages 7384–7432. PMLR."
REFERENCES,0.9387755102040817,"Mukherjee, S., Xie, Q., Hanna, J., and Nowak, R. (2023). Speed: Experimental design for policy
evaluation in linear heteroscedastic bandits. arXiv preprint arXiv:2301.12357."
REFERENCES,0.9428571428571428,"Pukelsheim, F. (2006). Optimal design of experiments. SIAM."
REFERENCES,0.9469387755102041,"Reyes, L. J. P., Oviedo, N. B., Camacho, E. C., and Calderon, J. M. (2021). Adaptable recommenda-
tion system for outfit selection with deep learning approach. IFAC-PapersOnLine, 54(13):605–610."
REFERENCES,0.9510204081632653,"Rockafellar, R. (2015). Convex analysis. princeton landmarks in mathematics and physics."
REFERENCES,0.9551020408163265,"Shamir, O. (2011). A variant of azuma’s inequality for martingales with subgaussian tails. arXiv
preprint arXiv:1110.2392."
REFERENCES,0.9591836734693877,"Shen, Q., Han, S., Han, Y., and Chen, X. (2023). User review analysis of dating apps based on text
mining. Plos one, 18(4):e0283896."
REFERENCES,0.963265306122449,"Soare, M., Lazaric, A., and Munos, R. (2014). Best-arm identification in linear bandits. Advances in
Neural Information Processing Systems, 27."
REFERENCES,0.9673469387755103,"Stein, C., Diaconis, P., Holmes, S., and Reinert, G. (2004). Use of exchangeable pairs in the analysis
of simulations. Lecture Notes-Monograph Series, pages 1–26."
REFERENCES,0.9714285714285714,"Tripuraneni, N., Jin, C., and Jordan, M. (2021). Provable meta-learning of linear representations. In
International Conference on Machine Learning, pages 10434–10443. PMLR."
REFERENCES,0.9755102040816327,"Valko, M., Munos, R., Kveton, B., and Kocák, T. (2014). Spectral bandits for smooth graph functions.
In International Conference on Machine Learning, pages 46–54. PMLR."
REFERENCES,0.9795918367346939,"Yang, J., Hu, W., Lee, J. D., and Du, S. S. (2020). Impact of representation learning in linear bandits.
arXiv preprint arXiv:2010.06531."
REFERENCES,0.9836734693877551,"Yang, J., Lei, Q., Lee, J. D., and Du, S. S. (2022). Nearly minimax algorithms for linear bandits with
shared representation. arXiv preprint arXiv:2203.15664."
REFERENCES,0.9877551020408163,"Zhang, D., Shen, D., Initiative, A. D. N., et al. (2012). Multi-modal multi-task learning for joint
prediction of multiple regression and classification variables in alzheimer’s disease. NeuroImage,
59(2):895–907."
REFERENCES,0.9918367346938776,"Zhao, Y., Kosorok, M. R., and Zeng, D. (2009). Reinforcement learning design for cancer clinical
trials. Statistics in medicine, 28(26):3294–3315."
REFERENCES,0.9959183673469387,"Zhu, Y., Zhou, D., Jiang, R., Gu, Q., Willett, R., and Nowak, R. (2021). Pure exploration in kernel
and neural bandits. Advances in neural information processing systems, 34:11618–11630."
