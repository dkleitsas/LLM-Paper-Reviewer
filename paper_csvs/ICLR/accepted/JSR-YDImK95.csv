Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0014204545454545455,"Energy-based Models (EBMs) offer a powerful approach for modeling discrete
structure, but both inference and learning of EBM are hard as it involves sam-
pling from discrete distributions. Recent work shows Markov Chain Monte Carlo
(MCMC) with the informed proposal is a powerful tool for such sampling. How-
ever, an informed proposal only allows local updates as it requires evaluating all
energy changes in the neighborhood. In this work, we present a path auxiliary al-
gorithm that uses a composition of local moves to efﬁciently explore large neigh-
borhoods. We also give a fast version of our algorithm that only queries the eval-
uation of energy function twice for each proposal via linearization of the energy
function. Empirically, we show that our path auxiliary algorithms considerably
outperform other generic samplers on various discrete models for sampling, in-
ference, and learning. Our method can also be used to train deep EBMs for high
dimensional discrete data."
INTRODUCTION,0.002840909090909091,"1
INTRODUCTION"
INTRODUCTION,0.004261363636363636,"Many real-world problems involve discrete structured data modeling, such as syntax trees for nat-
ural language processing(Tai et al., 2015), graphical model for molecules(Gilmer et al., 2017), etc.
A powerful approach for modelling the distribution over structured data is Energy Based Mod-
els(LeCun et al., 2006) (EBMs). EBMs deﬁne the distribution with an unnormalized energy func-
tion, which allows great ﬂexibility to ﬁt the target distribution. However, this ﬂexibility also results
in the difﬁculties in inference and learning, as they require sampling from the EBM (Andrieu et al.,
2003; Hinton, 2002), where the partition function is intractable in many cases."
INTRODUCTION,0.005681818181818182,"Markov Chain Monte Carlo (MCMC) algorithms are one of the most widely used methodologies to
sample from intractable distributions (Robert & Casella, 2013). The efﬁciency for MCMC depends
drastically on the proposal distribution. For example, in continuous space, Metropolis-adjusted
Langevin algorithm (MALA) exploits the gradient of the target in single step walk and biases the
proposal distribution toward high probability region (Rossky et al., 1978; Roberts & Rosenthal,
1998; Welling & Teh, 2011); Hamiltonian Monte Carlo (HMC) employs multi-step walk and ex-
plores the distribution more efﬁciently(Neal, 2004; Girolami & Calderhead, 2011; Hoffman et al.,
2014). These methods substantially improve the performance of the MCMC algorithm in theory
and in practice. However, their proposal distributions are derived as discretization of continuous
diffusion process and it is still not clear how to appropriately extend such methods into discrete
space(Zanella, 2020)."
INTRODUCTION,0.007102272727272727,"Recently, Zanella (2020) proposed a general framework called pointwise informed proposal (PIP)
that shows promising results on directly sampling from discrete distributions. PIP utilizes the energy
change in the neighborhood of current state to propose a new state. Following this work, Grathwohl
et al. (2021) propose a more efﬁcient sampler that uses Taylor series to estimate the energy change"
INTRODUCTION,0.008522727272727272,∗Work done during the time at Siemens
INTRODUCTION,0.009943181818181818,Published as a conference paper at ICLR 2022
INTRODUCTION,0.011363636363636364,"in the neighborhood. However, both methods only focus on proposing from a small neighborhood,
for example, a 1-Hamming ball. This is due to the computational expense of evaluating the energy
change or approximation error of Taylor series for a large neighborhood. As a result, the samples in
Markov chain will have strong correlation or even be trapped at local optimum, which deteriorates
the sampling efﬁciency."
INTRODUCTION,0.01278409090909091,"In order to efﬁciently explore a larger neighborhood, we propose a path auxiliary sampler, which is
an auxiliary sampler (Liang et al., 2011) that uses auxiliary path to propose new states. In construc-
tion of the path, we employ a local proposal distribution to make a sequence of small movements
to reach a new state in long distance. A typical challenge for such multi-step proposal is that the
accept ratio could decrease very fast when the number of steps increases. In this work, we show that
the accept ratio of our path auxiliary proposal is independent of the path and only determined by the
property of the current state and the proposed state. As a result, our algorithm is able to maintain a
high accept ratio with multiple local steps. We can provably show that the locally balancing func-
tions are asymptotically optimal for our path auxiliary sampler. We also introduce a scalable version
of the algorithm that uses linearization and can be applied to smooth target distributions."
INTRODUCTION,0.014204545454545454,"We empirically evaluate our methods in inference, sampling, and learning on various discrete EBMs.
We demonstrate that our methods signiﬁcantly improve the sampling efﬁciency on parity model,
weighted permutation model, Ising model, Restricted Boltzmann Machine, and factorial Hidden
Markov Model. Our method can also learn competitive deep EBMs on discrete image data. The code
can be found at https://github.com/ha0ransun/Path-Auxiliary-Sampler.git."
BACKGROUND,0.015625,"2
BACKGROUND"
BACKGROUND,0.017045454545454544,"Energy Based Model: Let X be a ﬁnite state space. An EBM deﬁnes an energy function f :
X →R with target distribution π(x) = e−f(x)/Z, where Z = P"
BACKGROUND,0.018465909090909092,"z∈X e−f(z) (LeCun et al., 2006;
Wainwright & Jordan, 2008; Du & Mordatch, 2019). The unnormalized energy function provides
great ﬂexibility to characterize complex distribution. However, this can also make the partition
function Z intractable to calculate and exacerbate the difﬁculties of learning and inference."
BACKGROUND,0.019886363636363636,"Metropolis-Hastings: MCMC is a commonly used methodology to sample from an intractable
distribution.
Metropolis-Hastings (MH) is one of the most commonly used framework for
MCMC(Metropolis et al., 1953; Hastings, 1970). Given the current state x, a proposal distribu-
tion Q(x, ·) gives a new state y, then MH algorithm accept y with probability of min{1, π(y)Q(y,x)"
BACKGROUND,0.02130681818181818,"π(x)Q(x,y)}
to guarantee the Markov chain is π-reversible. The efﬁciency of MH algorithm highly depends on
the selection of proposal distribution Q."
BACKGROUND,0.022727272727272728,"Peskun Ordering: Peskun ordering provides a method to compare the efﬁciency for two MCMC
algorithms (Peskun, 1973; Tierney, 1998). Let P1, P2 be π-reversible Markov transition kernels on
X such that P1(x, y) > cP2(x, y) for all x ̸= y for a ﬁxed c > 0, then we say P1 is c-times more
efﬁcient than P2 as the following holds: 1) varπ(h, P1) ≤1"
BACKGROUND,0.024147727272727272,"cvarπ(h, P2)+ 1−c"
BACKGROUND,0.02556818181818182,"c varπ(h),
∀h : X →
R; 2) Gap(P1) ≥c Gap(P2). A smaller asymptotic variance varπ(h, P) means a better estimation
for the expectation of h and a larger spectral gap Gap(P) means a faster convergence of the Markov
chain."
BACKGROUND,0.026988636363636364,"Pointwise Informed Proposals and Locally Balancing Function: A pointwise informed pro-
posal (PIP) is a MH algorithm in discrete space (Zanella, 2020). PIP uses proposal distribution
Qg(x, y) = g( π(y)"
BACKGROUND,0.028409090909090908,"π(x))I(x, y)/Zg(x), where the I(x, y) = 1{y∈N(x)} is the membership indicator"
BACKGROUND,0.029829545454545456,"w.r.t a symmetric neighborhood N(·), and the normalizer Zg(x) = P"
BACKGROUND,0.03125,z∈X g( π(z)
BACKGROUND,0.032670454545454544,"π(x))I(x, z). The
weight function g : R+ →R+ determines the efﬁciency of PIP. Zanella (2020) show that the family
of locally balancing functions G = {g : R+ →R+, g(t) = tg( 1"
BACKGROUND,0.03409090909090909,"t ), ∀t > 0} is asymptotically opti-
mal for PIP w.r.t. Peskun ordering. Empirically, Zanella (2020) shows g(t) =
√"
BACKGROUND,0.03551136363636364,"t and g(t) =
t
t+1
have the best performance."
BACKGROUND,0.036931818181818184,"Gibbs with Gradient GWG (Grathwohl et al., 2021) is a scalable version of PIP, where the target
distribution π(·) is approximated via Taylor’s series. Despite being powerful, PIP and GWG requires
the calculate the weight and sample from the neighborhood. Hence, only a small neighborhood,
usually a 1-Hamming ball, is used in existing methods."
BACKGROUND,0.03835227272727273,Published as a conference paper at ICLR 2022
PATH AUXILIARY PROPOSAL,0.03977272727272727,"3
PATH AUXILIARY PROPOSAL"
PATH AUXILIARY PROPOSAL,0.041193181818181816,"Problems occur in point-wise informed proposal (PIP) when merely considering a small neighbor-
hood, especially for distributions with many local optima. For example, consider a parity distribution
where the state space X = {0, 1}p, and the energy function f(x) = U if the number of 1s in x is
odd, otherwise f(x) = 0. When a 1-Hamming ball neighborhood is used, by symmetry, a PIP will
have a uniform probability to propose a new state from neighborhood. Then, the expected time
to leave a low energy state is O(eU), which could be very inefﬁcient when U is large. When a
r-Hamming ball larger neighborhood is used, a PIP can efﬁciently escape a low energy state. How-
ever, the neighborhood will contain O(nr) states, which could be computationally prohibitive when
n or r is large."
PATH AUXILIARY PROPOSAL,0.04261363636363636,"To address such problems with PIP, we propose a path auxiliary sampler. Instead of directly sam-
pling from a large neighborhood, path auxiliary sampler sequentially samples new state from a local
proposal distribution Q0. The computation cost at each step is still manageable as Q0 still samples
locally. Then the composition of small movements forms a path that can lead to a new state that is
distant from the current state. The complexity of the sampling grows linearly instead of exponen-
tially w.r.t. r. In this section, we ﬁrst present the framework of our algorithm. Then, we discuss the
choice of the weight function for path auxiliary sampler. And ﬁnally, we introduce a fast version of
path auxiliary sampler."
PROPOSAL VIA AUXILIARY PATH,0.04403409090909091,"3.1
PROPOSAL VIA AUXILIARY PATH"
PROPOSAL VIA AUXILIARY PATH,0.045454545454545456,"We ﬁrst deﬁne an auxiliary path. Given the neighborhood function N, the set of auxiliary paths on
X is deﬁned as"
PROPOSAL VIA AUXILIARY PATH,0.046875,"Σ(X, N) := {(σ, L) : σi ∈X, i = 0, ..., L; σl ∈N(σl−1)), l = 1, ..., L}
(1)"
PROPOSAL VIA AUXILIARY PATH,0.048295454545454544,"To obtain the auxiliary path, we employ a PIP Q0(·, ·) to make local movements. We also sample
path length from a prior α(·) to assure our chain is aperiodic. The path auxiliary sampler is deﬁned
as follows"
PROPOSAL VIA AUXILIARY PATH,0.04971590909090909,1. Sample a path length L from a prior α(L).
PROPOSAL VIA AUXILIARY PATH,0.05113636363636364,"2. Denote the current state xt = σ0, sample σl ∼Q0(σl−1, ·) for l = 1, ..., L."
PROPOSAL VIA AUXILIARY PATH,0.052556818181818184,"3. Accept xt+1 = σL in probability A(x, σ, L) = min
n
1, π(σL) QL
l=1 Q0(σl,σl−1)
π(σ0) QL
l=1 Q0(σl−1,σl)"
PROPOSAL VIA AUXILIARY PATH,0.05397727272727273,"o
, else xt+1 = xt."
PROPOSAL VIA AUXILIARY PATH,0.05539772727272727,"Theorem 1. The path auxiliary proposal transition rule described above satisﬁes the detailed bal-
ance and induces a reversible Markov chain with π as its invariant distribution."
BENEFIT FROM AUXILIARY PATH,0.056818181818181816,"3.2
BENEFIT FROM AUXILIARY PATH"
BENEFIT FROM AUXILIARY PATH,0.05823863636363636,"We ﬁrst analyze the performance of path auxiliary sampler on parity distribution mentioned above.
Assume we use a uniform prior α(1) = α(2) = 1"
BENEFIT FROM AUXILIARY PATH,0.05965909090909091,"2. If we sample L = 2, then we will transit back to
a new state with same energy as the current state. As a result, we can always escape from a state in
O(1) steps in expectation."
BENEFIT FROM AUXILIARY PATH,0.061079545454545456,"Having a path auxiliary sampler to sample from L-Hamming ball at each step can be more efﬁcient
than performing L steps of MH sampling in a 1-Hamming ball. To mathematically justify it, we
compare their accept ratio. For a path (σ, L): min ("
BENEFIT FROM AUXILIARY PATH,0.0625,"1, π(σL) QL
l=1 Q0(σl, σl−1)"
BENEFIT FROM AUXILIARY PATH,0.06392045454545454,"π(σ0) QL
l=1 Q0(σl−1, σl) ) ≥ L
Y"
BENEFIT FROM AUXILIARY PATH,0.06534090909090909,"l=1
min

1, π(σl)Q0(σl, σl−1)"
BENEFIT FROM AUXILIARY PATH,0.06676136363636363,"π(σl−1)Q0(σl−1, σl) 
(2)"
BENEFIT FROM AUXILIARY PATH,0.06818181818181818,"We can notice that the accept ratio for path auxiliary sampler is the product of the probability for
single-step method before the minimum operator. As a result, an auxiliary path can have a high
accept ratio as long as the product is large. On the contrary, when performing L steps MH sampling,
the transition can probably be blocked at some steps in the path with low accept ratios."
BENEFIT FROM AUXILIARY PATH,0.06960227272727272,Published as a conference paper at ICLR 2022
BALANCED PROPOSAL,0.07102272727272728,"3.3
BALANCED PROPOSAL"
BALANCED PROPOSAL,0.07244318181818182,"Although the product in equation 2 allows the Markov chain to escape from a local optimum when
some steps in the path have high accept ratio, it can also exponentially decrease the accept ratio
w.r.t. the path length L when every step has a low accept ratio. Hence, it is important to select a
good local proposal Q0. In this section, we show that the locally balancing function Zanella (2020)
is asymptotically optimal for path auxiliary sampler. We ﬁrst deﬁne a sub-class of weight function
named as ideal function:
Deﬁnition 1. F is the set of ideal function. A function f ∈F if and only if following conditions
holds: 1) f : R+ →R+; 2) f(1) = 1; 3) f(t) is monotonic increasing;4) f(t)f( 1"
BALANCED PROPOSAL,0.07386363636363637,"t )t ≤1, ∀t ≤1"
BALANCED PROPOSAL,0.07528409090909091,"The next theorem shows that locally balancing function G is asymptotically better than ideal function
F in Peskun Ordering.
Theorem 2. Consider the state space in Cartesian products X = ×n
i=1Xi, where each Xi is a ﬁnite
space with M elements, and the neighborhood is deﬁned as 1-Hamming ball. Let dn be the maximum
degree in conditional independence graph. If 1) limn→∞dn"
BALANCED PROPOSAL,0.07670454545454546,"n = 0; 2) the target distribution satisﬁes
π(y)
π(x) ≤C < ∞, ∀y ∈N(x); 3) the path length prior α is bounded by U. Then for any f ∈F, we
have a function g ∈G = {g(·) : g(t) = tg( 1"
BALANCED PROPOSAL,0.078125,"t )} that is asymptotically more efﬁcient than f, which
implies G is asymptotically optimal in F."
BALANCED PROPOSAL,0.07954545454545454,"The idea to prove this theorem is to use ¯f(t) :=
q"
BALANCED PROPOSAL,0.08096590909090909,f(t)f( 1
BALANCED PROPOSAL,0.08238636363636363,"t )t. By deﬁnition, we have:"
BALANCED PROPOSAL,0.08380681818181818,¯f(t) = r
BALANCED PROPOSAL,0.08522727272727272,f(t)f(1
BALANCED PROPOSAL,0.08664772727272728,t )t = t r
BALANCED PROPOSAL,0.08806818181818182,f(t)f(1 t )1
BALANCED PROPOSAL,0.08948863636363637,t = t ¯f(1
BALANCED PROPOSAL,0.09090909090909091,"t )
(3)"
BALANCED PROPOSAL,0.09232954545454546,"which means ¯f ∈G. Then, the theorem is proved by showing the π-reversible Markov transition
kernel P ¯
f(x, y) ≥Pf(x, y) asymptotically holds. The proof is given in Sec A.5"
BALANCED PROPOSAL,0.09375,"Although Deﬁnition 1 has some constraints, it already contains almost all natural choices of weight
functions, such as f(t) =
2t
1+t, f(t) = min{1, t}, f(t) = max{1, t}, and f(t) = tα, α ≥0. Hence,
the asymptotic optimality for locally balanced function G in ideal function F strongly suggest that
locally balanced function is a good choice for path auxiliary sampler. More discussion for ideal
function can be found in Sec A.3
Property 1. When using a locally balancing function g ∈G as the weight function, the accept ratio
for path auxiliary sampler can be written as:"
BALANCED PROPOSAL,0.09517045454545454,"A(x, y, σ, L) = min

1, Zg(x) Zg(y) 
(4)"
BALANCED PROPOSAL,0.09659090909090909,"The path independent form in Property 1 shows that if the energy function is smooth enough, the
accept ratio in equation 4 will be high when y is close to x. By selecting g(t) =
√"
BALANCED PROPOSAL,0.09801136363636363,"t ∈G, we name
our auxiliary sampler (Liang et al., 2011) as path auxiliary sampler (PAS) and give the algorithm in
Algorithm 1."
SCALABLE PATH AUXILIARY ALGORITHM,0.09943181818181818,"3.4
SCALABLE PATH AUXILIARY ALGORITHM"
SCALABLE PATH AUXILIARY ALGORITHM,0.10085227272727272,"Although path auxiliary proposal reduces the complexity from exponential to linear, it still requires
O(nL) evaluations of the probability π(x) in total. In cases where the computational bottleneck is
evaluating π(x), this cost will be expensive. Fortunately, most distributions of interest have differ-
entiable energy functions, such as deep EBMs , and we can use the linearization as approximation
(Grathwohl et al., 2021). Given the current state σ0, the linearization is
˜fσ0(z) = f(σ0) + ⟨∇f(σ0), z −σ0⟩
(5)"
SCALABLE PATH AUXILIARY ALGORITHM,0.10227272727272728,"we can estimate ˜πσ0(y)/˜πσ0(x)
=
e−⟨∇f(σ0),y−x⟩, and deﬁne our proposal distribution
˜Qg,σ0(x, y) = g( ˜π0(y)"
SCALABLE PATH AUXILIARY ALGORITHM,0.10369318181818182,"˜π0(x))/ ˜Zg,σ0(x), with the normalizer Zg,σ0(x) = P"
SCALABLE PATH AUXILIARY ALGORITHM,0.10511363636363637,z∈N(x) g( ˜π0(z)
SCALABLE PATH AUXILIARY ALGORITHM,0.10653409090909091,˜π0(x)). After sam-
SCALABLE PATH AUXILIARY ALGORITHM,0.10795454545454546,"pling σ, we use the linearization ˜fσL at σL to compute the accept ratio w.r.t. the auxiliary path"
SCALABLE PATH AUXILIARY ALGORITHM,0.109375,"A(x, σ, L) = min ("
SCALABLE PATH AUXILIARY ALGORITHM,0.11079545454545454,"1, π(y) QL
l=1 ˜Qg,σL(σl, σl−1)"
SCALABLE PATH AUXILIARY ALGORITHM,0.11221590909090909,"π(x) Q0
l=1 ˜Qg,σ0(σl−1, σl) ) (6)"
SCALABLE PATH AUXILIARY ALGORITHM,0.11363636363636363,Published as a conference paper at ICLR 2022
SCALABLE PATH AUXILIARY ALGORITHM,0.11505681818181818,Algorithm 1: Path Auxiliary Sampler (PAS) and the fast version (PAFS)
SCALABLE PATH AUXILIARY ALGORITHM,0.11647727272727272,"Input: Target Distribution π, Initial state x0, Path Length Prior α, Weight Function g(t) =
√"
SCALABLE PATH AUXILIARY ALGORITHM,0.11789772727272728,"t
Output: Sample sequence (x1, x2, ...)"
REPEAT,0.11931818181818182,1 repeat
REPEAT,0.12073863636363637,"2
Sample path length L ∼α(L)"
REPEAT,0.12215909090909091,"3
Denote σ0 = xt, sample σl ∼Qg(σl−1, ·) or σl ∼˜Qg,σ0(σl−1, ·) for l = 1, ..., L."
REPEAT,0.12357954545454546,"4
Accept xt+1 = σL in probability A(x, σ, L) = min{1, Zg(xt)"
REPEAT,0.125,Zg(σL)}
REPEAT,0.12642045454545456,"5
or A(x, σ, L) = min
n
1,
π(y) QL
l=1 ˜
Qg,σL(σl,σl−1)
π(x) Q0
l=1 ˜
Qg,σ0(σl−1,σl) o"
REPEAT,0.1278409090909091,", else xt+1 = xt."
REPEAT,0.12926136363636365,6 until ﬁnish sampling;
REPEAT,0.13068181818181818,"By using approximation, we only need to evaluate π(y), π(x), ∇f(y), ∇f(x) once in every pro-
posal, which can signiﬁcantly reduce the computational cost. We name this algorithm as path auxil-
iary fast sampler (PAFS) (see Algorithm 1)."
REPEAT,0.13210227272727273,"The PAS framework also allows different approximations. For example, GWG (Grathwohl et al.,
2021) can be seen as a special case where all indices are sampled from ˜Qg,σ0(σ0, ·) rather than
˜Qg,σ0(σl, ·). Besides, one way to further encourage long range movements is sampling sites without
replacement, that’s to say, the auxiliary path σ does not modify a site more than once. However,
such a sampler requires a decent choice of the path length L. When L is too large, the acceptance
rate drops exponentially fast. Hence, in this work, we focus on PAFS. Similar to GWG (Grathwohl
et al., 2021), the decrease of the proposal quality from PAFS can be bounded.
Theorem 3. Assume the energy function f(x) is differentiable, ∇f(x) is K-Lipschitz. Consider
we use weight function g(t) =
√"
REPEAT,0.13352272727272727,"t, path length prior α bounded by U, and 1-Hamming ball as
neighborhood. Denote P and ˜P as the transition kernel by path auxiliary sampler and path auxiliary
faster sampler, respectively, we have"
REPEAT,0.13494318181818182,"˜P(x, y) ≥e−K U(U+1)"
REPEAT,0.13636363636363635,"2
P(x, y)
(7)"
REPEAT,0.1377840909090909,"Using the Peskun ordering, we know PAFS is at least e−K U(U+1)"
REPEAT,0.13920454545454544,"2
times as efﬁcient as PAS. When
K is small, theorem 3 justify PAFS is a good approximation for PAS. When K is large, a tighter
bound needs more assumptions for the target distribution, e.g. conditional independence. See the
proof and discussion in Sec A.7."
RELATED WORKS,0.140625,"4
RELATED WORKS"
RELATED WORKS,0.14204545454545456,"Informed proposal for Metropolis-Hastings (MH) algorithm has been extensively studied in the
continuous space(Robert & Casella, 2013). The most famous algorithms are Metropolis-adjusted
Langevein algorithm (MALA) (Roberts & Rosenthal, 1998) and Hamiltonian Monte Carlo (HMC).
MALA, HMC, and their variants (Girolami & Calderhead, 2011; Hoffman et al., 2014; Welling &
Teh, 2011; Titsias & Papaspiliopoulos, 2018) exploit the gradient of the target distribution to bias
the proposal distribution towards high probability regions. Although gradient-based methods hav-
ing brought substantial improvements in continuous space, it is still unclear how to extend them to
discrete space."
RELATED WORKS,0.1434659090909091,"A number of methods try to map the discrete space to a continuous space using relaxation, apply
informed methods in continuous space, and then map the new state back into discrete space(Zhang
et al., 2012; Pakman & Paninski, 2013; Nishimura et al., 2017; Han & Liu, 2018; Jaini et al., 2021)
via Gaussian Integral Trick, uniform dequantization, or VAE ﬂow. Such methods work in some
scenarios, but a key challenge is the embedding of discrete space into continuous space can destroy
the inherent discrete structure, resulting in highly multi-modal and irregular target distribution in
continuous spaces."
RELATED WORKS,0.14488636363636365,"Another group of methods directly work on discrete space. Dai et al. (2020) introduces the path as
latent variable in the variational distribution for initializing PCD, but still relies on slow Gibbs sam-
pling for improvement; Titsias & Yau (2017) augment the discrete space with auxiliary variable and"
RELATED WORKS,0.14630681818181818,Published as a conference paper at ICLR 2022
RELATED WORKS,0.14772727272727273,"perform Gibbs sampling in the augmented space based on informed proposal. Zanella (2020) shows
that a family of locally balancing function is asymptotically optimal for informed proposal. Follow-
ing Zanella (2020), Power & Goldman (2019) extends the framework to Markov jumping process,
and Sansone (2021) parameterize locally balanced function to tune it via mutual information to se-
lect good weight function from the locally balanced class. When the target distribution is smooth
enough, Grathwohl et al. (2021) employs a Taylor’s series to approximate the target distribution and
further improve the sampling efﬁciency. Though these informed proposal algorithms successfully
show orders of magnitude improvements when using 1-Hamming ball as neighborhood, they are
not able to explore a large neighborhood. An extension of GWG (Grathwohl et al., 2021) can par-
tially address this problem via sampling multiple dimensions to modify in one step. However, such
procedure can easily lead to backtracks thereby reducing its efﬁciency."
EXPERIMENTS,0.14914772727272727,"5
EXPERIMENTS"
SAMPLERS UNDER CONSIDERATION,0.15056818181818182,"5.1
SAMPLERS UNDER CONSIDERATION"
SAMPLERS UNDER CONSIDERATION,0.15198863636363635,"In this section, we empirically evaluate the sampling efﬁciency of path auxiliary sampler (PAS) and
path auxiliary fast sampler (PAFS). We choose the path length prior α as a uniform distribution on
{1, ..., 2X −1} as suggested in Hoffman et al. (2021) and denote the corresponding samplers as
PAS-X and PAFS-X."
SAMPLERS UNDER CONSIDERATION,0.1534090909090909,"We compare our methods with ﬁve types of baselines: random walk sampler (RW), Gibbs sampler
(Gibbs), Hamming ball sampler (HB), locally balanced sampler (LB), Gibbs with gradient sampler
(GWG). RW is an informed proposal with g(t) = 1 that uniformly propose new state from neighbor-
hood. Gibbs partitions the dimension of a state x into two groups xu and x−u, then updates the state
from conditional distribution p(xu|x−u). We denote it as Gibbs-X, where X refers to the dimension
of xu. HB is a two-stage Gibbs sampler on the extended state space (x, x′) (Titsias & Yau, 2017).
We use HB-10-1, where 10 is the block size, and 1 is the hamming ball size. LB (Zanella, 2020)
is implemented as a single-step PIP with g(t) =
√"
SAMPLERS UNDER CONSIDERATION,0.15482954545454544,"t. GWG (Grathwohl et al., 2021) is a scalable
version of LB, which draw the index to ﬂip via ﬁrst order Taylor’s series of the target distribution.
Although the original paper focuses on ﬂipping one site per step, it is possible for GWG to draw
multiple indices to ﬂip in every step. We denote the algorithm as GWG-X, where X indicates that
the number of indices to modify per step is uniformly sampled from {1, ..., 2X −1}. The difference
between PAFS and GWG is that GWG is more likely to sample the same index repeatedly thereby
reducing the efﬁciency especially after mixing, e.g in ﬁgure 6."
INFERENCE ON ENERGY BASED MODEL,0.15625,"5.2
INFERENCE ON ENERGY BASED MODEL"
INFERENCE ON ENERGY BASED MODEL,0.15767045454545456,"Parity Model: We ﬁrst demonstrate the beneﬁt of path auxiliary sampler versus single-step sampler
in a inference task that estimates the mean µ of a parity distribution. A parity distribution has state
space X = {0, 1}p and energy function"
INFERENCE ON ENERGY BASED MODEL,0.1590909090909091,"f(x) = ((Pp
i=1 xi) mod 2)U
(8)"
INFERENCE ON ENERGY BASED MODEL,0.16051136363636365,"i.e. a state has energy U if it has an odd number of 1s, otherwise 0. The neighborhood is deﬁned as
1-Hamming ball. We run the simulation with p = 100 and U ={1, 3, 5}, and report the estimation"
INFERENCE ON ENERGY BASED MODEL,0.16193181818181818,"0
5000
10000 15000 20000 25000 30000 35000 40000"
INFERENCE ON ENERGY BASED MODEL,0.16335227272727273,Energy Function Evaluations 1 2 3 4 5
INFERENCE ON ENERGY BASED MODEL,0.16477272727272727,"p = 100, U = 1"
INFERENCE ON ENERGY BASED MODEL,0.16619318181818182,"LB
PAS-2"
INFERENCE ON ENERGY BASED MODEL,0.16761363636363635,"0
5000
10000 15000 20000 25000 30000 35000 40000"
INFERENCE ON ENERGY BASED MODEL,0.1690340909090909,Energy Function Evaluations 1 2 3 4 5
INFERENCE ON ENERGY BASED MODEL,0.17045454545454544,"p = 100, U = 3"
INFERENCE ON ENERGY BASED MODEL,0.171875,"LB
PAS-2"
INFERENCE ON ENERGY BASED MODEL,0.17329545454545456,"0
5000
10000 15000 20000 25000 30000 35000 40000"
INFERENCE ON ENERGY BASED MODEL,0.1747159090909091,Energy Function Evaluations 1 2 3 4 5
INFERENCE ON ENERGY BASED MODEL,0.17613636363636365,"p = 100, U = 5"
INFERENCE ON ENERGY BASED MODEL,0.17755681818181818,"LB
PAS-2"
INFERENCE ON ENERGY BASED MODEL,0.17897727272727273,Figure 1: Estimation Error of Distribution Mean on Parity Model
INFERENCE ON ENERGY BASED MODEL,0.18039772727272727,"error En := ∥ˆµn −µ∥2, where ˆµn = Pn
i=1 Xi is the sample mean of the Markov chain at step n.
For each setting and method, we run 5 chains for 20,000 steps, and we plot the mean and standard
deviation of the estimation error in ﬁgure 1. We can observe that the efﬁciency of single step sampler"
INFERENCE ON ENERGY BASED MODEL,0.18181818181818182,Published as a conference paper at ICLR 2022
INFERENCE ON ENERGY BASED MODEL,0.18323863636363635,"0
2000
4000
6000
8000
10000
Energy Function Evaluations 600 500 400 300 200 100 0"
INFERENCE ON ENERGY BASED MODEL,0.1846590909090909,"p = 100, Sigma = 3"
INFERENCE ON ENERGY BASED MODEL,0.18607954545454544,"RW-1
RW-3
LB-1
PAS-3"
INFERENCE ON ENERGY BASED MODEL,0.1875,"0
2000
4000
6000
8000
10000
Energy Function Evaluations 1000 800 600 400 200 0"
INFERENCE ON ENERGY BASED MODEL,0.18892045454545456,"p = 100, Sigma = 5"
INFERENCE ON ENERGY BASED MODEL,0.1903409090909091,"RW-1
RW-3
LB-1
PAS-3"
INFERENCE ON ENERGY BASED MODEL,0.19176136363636365,"0
2000
4000
6000
8000
10000
Energy Function Evaluations 2000 1750 1500 1250 1000 750 500 250 0"
INFERENCE ON ENERGY BASED MODEL,0.19318181818181818,"p = 100, Sigma = 10"
INFERENCE ON ENERGY BASED MODEL,0.19460227272727273,"RW-1
RW-3
LB-1
PAS-3"
INFERENCE ON ENERGY BASED MODEL,0.19602272727272727,Figure 2: Energy Trace on Weighted Permutation Model
INFERENCE ON ENERGY BASED MODEL,0.19744318181818182,"0
2000
4000
6000
8000
10000
MCMC Steps"
INFERENCE ON ENERGY BASED MODEL,0.19886363636363635,160000
INFERENCE ON ENERGY BASED MODEL,0.2002840909090909,140000
INFERENCE ON ENERGY BASED MODEL,0.20170454545454544,120000
INFERENCE ON ENERGY BASED MODEL,0.203125,100000 80000 60000 40000 20000 0
INFERENCE ON ENERGY BASED MODEL,0.20454545454545456,BurnIn in terms of MCMC steps
INFERENCE ON ENERGY BASED MODEL,0.2059659090909091,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
INFERENCE ON ENERGY BASED MODEL,0.20738636363636365,"0
2
4
6
8
MCMC Samplers 103"
INFERENCE ON ENERGY BASED MODEL,0.20880681818181818,ESS in terms of MCMC steps
INFERENCE ON ENERGY BASED MODEL,0.21022727272727273,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
INFERENCE ON ENERGY BASED MODEL,0.21164772727272727,"0
2500
5000
7500
10000 12500 15000 17500 20000
Energy Evaluations"
INFERENCE ON ENERGY BASED MODEL,0.21306818181818182,160000
INFERENCE ON ENERGY BASED MODEL,0.21448863636363635,140000
INFERENCE ON ENERGY BASED MODEL,0.2159090909090909,120000
INFERENCE ON ENERGY BASED MODEL,0.21732954545454544,100000 80000 60000 40000 20000 0
INFERENCE ON ENERGY BASED MODEL,0.21875,BurnIn in terms of Energy Evaluations
INFERENCE ON ENERGY BASED MODEL,0.22017045454545456,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
INFERENCE ON ENERGY BASED MODEL,0.2215909090909091,"0
2
4
6
8
MCMC Samplers 102"
INFERENCE ON ENERGY BASED MODEL,0.22301136363636365,ESS in terms of Energy Evaluations
INFERENCE ON ENERGY BASED MODEL,0.22443181818181818,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
INFERENCE ON ENERGY BASED MODEL,0.22585227272727273,Figure 3: PAS and PAFS in different lengths on 200 × 200 Ising Model
INFERENCE ON ENERGY BASED MODEL,0.22727272727272727,"decreases exponentially when U increases. On the contrary, the path auxiliary sampler can always
escape from the local optima in parity distribution and estimate the distribution mean efﬁciently."
INFERENCE ON ENERGY BASED MODEL,0.22869318181818182,"Weighted Permutation Model: We consider an optimization task on weighted permutation model.
The state space X = Sp is a symmetric group, i.e. for any ρ ∈X, ρ is a permutation of 1, 2, ..., p.
The energy function is deﬁned as:
f(ρ) = Pp"
INFERENCE ON ENERGY BASED MODEL,0.23011363636363635,"i=1 wi,ρ(i)
(9)"
INFERENCE ON ENERGY BASED MODEL,0.2315340909090909,"Following Zanella (2020), the weight {wij}p
i,j=1 are i.i.d. sampled from Gaussian(0, σ2). The
neighborhood is determined by one exchange of the permutation. We use p = 100, σ = 3, 5, 10,
and run 5 simulations for each conﬁgurations. From ﬁgure 2, we can see that LB sampler is trapped
at local optimum, especially when σ is large and the distribution is sharp. On the contrary, PAS can
always efﬁciently ﬁnd good solutions via auxiliary path."
SAMPLING ON ENERGY BASED MODEL,0.23295454545454544,"5.3
SAMPLING ON ENERGY BASED MODEL"
SAMPLING ON ENERGY BASED MODEL,0.234375,"Lattice Ising Model: Consider the state space X = {−1, 1}Vp, where (Vp, Ep) is the p × p square
lattice graph. For each x ∈X, the energy function is deﬁned as:"
SAMPLING ON ENERGY BASED MODEL,0.23579545454545456,"f(x) = −
X"
SAMPLING ON ENERGY BASED MODEL,0.2372159090909091,"i∈Vp αixi −λ
X"
SAMPLING ON ENERGY BASED MODEL,0.23863636363636365,"(i,j)∈Ep xixj
(10)"
SAMPLING ON ENERGY BASED MODEL,0.24005681818181818,"αi ∈R are bias terms representing the property of xi and λ is a global interaction term. We
ﬁrst compare PAS and PAFS in different path lengths. For each length, we run 100 chains with
100,000 steps. We report the burn-in stage as well as effective sample size (ESS) * in terms of both
MCMC steps and energy function evaluation times in ﬁgure 3. We can see that, 1) PAS has slight
improvement in terms of energy function evaluations when we increase the path length; 2) when
compared to PAS, PAFS has very similar proposal quality and signiﬁcantly better efﬁciency. We
also compare our sampler with other competitors. For each sampler, we run 5 Markov chains with
1,000,000 steps and report the ESS to compare the proposal quality in ﬁgure 4. We can see our
sampler leads in both quality and efﬁciency. More results are given in Sec B.1."
SAMPLING ON ENERGY BASED MODEL,0.24147727272727273,"factorial Hidden Markov Model: FHMM is a statistical model that use latent variables in X =
{0, 1}N×K to characterize time series data y ∈RN. Denote p(x) for hidden variables, and p(y|x)
for likelihood:"
SAMPLING ON ENERGY BASED MODEL,0.24289772727272727,"p(x) = N
Y"
SAMPLING ON ENERGY BASED MODEL,0.24431818181818182,"n=1
p(xn,1) K
Y"
SAMPLING ON ENERGY BASED MODEL,0.24573863636363635,"k=2
p(xn,k|xn,k−1),
p(y|x) = N
Y"
SAMPLING ON ENERGY BASED MODEL,0.2471590909090909,"n=1
Gaussian(yn; wxn + b, σ2)
(11)"
SAMPLING ON ENERGY BASED MODEL,0.24857954545454544,"Given data y, we use MCMC to sample x from the posterior p(x|y) and compare the mixing
for different samplers.
We choose parameters N = 1000, K = 10, P(xn,1 = 1) = 0.05,"
SAMPLING ON ENERGY BASED MODEL,0.25,*Computed follows Tensorﬂow Probability
SAMPLING ON ENERGY BASED MODEL,0.25142045454545453,Published as a conference paper at ICLR 2022
SAMPLING ON ENERGY BASED MODEL,0.2528409090909091,"0
2
4
6
8 100 101 102 103"
SAMPLING ON ENERGY BASED MODEL,0.25426136363636365,ESS in terms of Energy Function Evaluations
SAMPLING ON ENERGY BASED MODEL,0.2556818181818182,"Gibbs-1
Gibbs-5
RW-1
RW-10
LB-1
GWG-1
GWG-10
PAS-10
PASF-10"
SAMPLING ON ENERGY BASED MODEL,0.2571022727272727,"0
2
4
6
8"
SAMPLING ON ENERGY BASED MODEL,0.2585227272727273,ESS in terms of MCMC steps
SAMPLING ON ENERGY BASED MODEL,0.2599431818181818,"Gibbs-1
Gibbs-5
RW-1
RW-10
LB-1
GWG-1
GWG-10
PAS-10
PASF-10"
SAMPLING ON ENERGY BASED MODEL,0.26136363636363635,"Figure 4: ESS for Different Samplers on 200 × 200 Ising model
Figure 5: BurnIn in FHMM"
SAMPLING ON ENERGY BASED MODEL,0.2627840909090909,"P(Xn,k = xn,k−1) = 0.85, w ∈Gaussian(0, IK), b ∈Gaussian(0, 1), and σ2 = 0.25. We
run each chain 5 times and report the mean and std for the energy (negative log joint density)
E(ˆx) = −log p(ˆx)p(y|ˆx) and the reconstruction error ∥y−wˆx∥2 w.r.t. the number of evaluations of
energy function. From ﬁgure 5 we can see that both GWG and PAFS gain signiﬁcant improvements
in mixing by using a larger neighborhood. More results are given in Sec B.2"
SAMPLING ON ENERGY BASED MODEL,0.26420454545454547,"Restricted Boltzmann Machine: RBM is bipartite latent-variable model, whose energy function is
deﬁned as:"
SAMPLING ON ENERGY BASED MODEL,0.265625,"f(x) = log(1 + ewT x+c) + bT x
(12)"
SAMPLING ON ENERGY BASED MODEL,0.26704545454545453,"where {W, b, c} are parameters and x ∈{0, 1}D. We follow Grathwohl et al. (2021) to train a
RBM with 500 hidden units on the MNIST dataset using contrastive divergence(Hinton, 2002).
We generate samples via various MCMC samplers on the trained RBM. Besides reporting ESS,
we also estimate the maximum mean discrepancy (MMD) (Gretton et al., 2012) w.r.t. a set of
“ground truth” samples generated by structure known Block-Gibbs sampler. Figure 7 shows PAFS
has large ESS and can efﬁciently match the “ground truth” samples. We also demonstrate an ablation
study on different the approximations of the auxiliary path. Speciﬁcally, we evaluate GWG, PAFS
with different lengths. For each sampler, we run 100 chains and report their ESS and average hop
distance. We can notice GWG suffers from a large path length L, while our PAFS obtains robust"
SAMPLING ON ENERGY BASED MODEL,0.2684659090909091,"2.5
5.0
7.5
10.0
12.5
15.0
17.5
20.0
Average Path Length 0.4 0.5 0.6 0.7 0.8 0.9 1.0"
SAMPLING ON ENERGY BASED MODEL,0.26988636363636365,Average Accept Rate
SAMPLING ON ENERGY BASED MODEL,0.2713068181818182,"GWG
PAFS"
SAMPLING ON ENERGY BASED MODEL,0.2727272727272727,"2.5
5.0
7.5
10.0
12.5
15.0
17.5
20.0
Average Path Length 2 4 6 8 10"
SAMPLING ON ENERGY BASED MODEL,0.2741477272727273,Average Hop Distance
SAMPLING ON ENERGY BASED MODEL,0.2755681818181818,"GWG
PAFS"
SAMPLING ON ENERGY BASED MODEL,0.27698863636363635,"2.5
5.0
7.5
10.0
12.5
15.0
17.5
20.0
Average Path Length 1000 2000 3000 4000 5000 6000 7000 8000 ESS"
SAMPLING ON ENERGY BASED MODEL,0.2784090909090909,"GWG
PAFS"
SAMPLING ON ENERGY BASED MODEL,0.27982954545454547,Figure 6: Sampling on RBM with Different Path Length
SAMPLING ON ENERGY BASED MODEL,0.28125,"improvements for all L by employing a soft no-replacement sampling. This result indicates that
our PAFS provides an efﬁcient framework to sample from a large neighborhood. More results and
discussions, including a no-replacement sampler, are given in Sec B.3."
SAMPLING ON ENERGY BASED MODEL,0.28267045454545453,"0
5000
10000 15000 20000 25000 30000 35000 40000"
SAMPLING ON ENERGY BASED MODEL,0.2840909090909091,Energy Function Evaluations 3.00 2.75 2.50 2.25 2.00 1.75 1.50
SAMPLING ON ENERGY BASED MODEL,0.28551136363636365,RBM log(MMD)
SAMPLING ON ENERGY BASED MODEL,0.2869318181818182,"Gibbs-1
Gibbs-2
HB-10-1
GWG-1
GWG-3
GWG-5
PAFS-3
PAFS-5"
SAMPLING ON ENERGY BASED MODEL,0.2883522727272727,"0
1
2
3
4
5
6
7 102 103"
RBM ESS,0.2897727272727273,"104
RBM ESS"
RBM ESS,0.2911931818181818,"Gibbs-1
Gibbs-2
HB-10-1
GWG-1
GWG-3
GWG-5
PAFS-3
PAFS-5"
RBM ESS,0.29261363636363635,Figure 7: Sampling on RBM trained on MNIST
RBM ESS,0.2940340909090909,"10
20
30
40
50
Sampling Steps 5.0 4.8 4.6 4.4 4.2"
RBM ESS,0.29545454545454547,Log (RMSE) of Connectivity Matrix
RBM ESS,0.296875,"GWG
GWG-eq
GWG-5
PAFS-5"
RBM ESS,0.29829545454545453,Figure 8: Learning Ising
RBM ESS,0.2997159090909091,Published as a conference paper at ICLR 2022
RBM ESS,0.30113636363636365,"Dataset
VAE
VAE
EBM
EBM
EBM
RBM
DBN
(MLP)
(Conv)
(GWG)
(Gibbs)
(PAFS)
Static MNIST
-86.05
-82.41
-80.01
-117.17
-79.58
-86.39
-85.67
Dynamic MNIST
-82.42
-80.40
-80.51
-121.19
-79.59
-
-
Omniglot
-103.52
-97.65
-94.72
-142.06
-90.75
-100.47
-100.78
Caltech Silhouettes
-112.08
-106.35
-96.20
-163.50
-84.56
-
-"
RBM ESS,0.3025568181818182,Table 1: Evaluation of different discrete models on the held-out test set.
LEARNING ON ENERGY BASED MODEL,0.3039772727272727,"5.4
LEARNING ON ENERGY BASED MODEL"
LEARNING ON ENERGY BASED MODEL,0.3053977272727273,"Learning an EBM is a challenge task. Consider the target distribution is π and our energy function
fθ is parameterized by θ. The gradient for the likelihood of πθ(x) ∝e−fθ(x) is:"
LEARNING ON ENERGY BASED MODEL,0.3068181818181818,"∇θ log p(x) = Eπ[∇θfθ(x)] −Eπθ[∇θfθ(x)]
(13)"
LEARNING ON ENERGY BASED MODEL,0.30823863636363635,"The ﬁrst expectation can be estimated using the data from true distribution. The second expectation
requires samples from the current model, which is typically obtained via MCMC. Hence, the success
of training an EBM relies on efﬁcient MCMC algorithms to get an accurate estimation of the second
expectation."
LEARNING ON ENERGY BASED MODEL,0.3096590909090909,"Ising model We ﬁrst learn an Ising model following the setting in Grathwohl et al. (2021), where
the energy function f(x) = θxT Jx. Given a set of samples {xi}, the task is to learn an EBM via
recovering the connectivity matrix J. We generate a 25 × 25 2D cyclic lattice with θ = 0.25 and
sample training data with a long-run Gibbs chain. We train the models to maximize the likelihood
of samples using persistent contrastive divergence (PCD)(Tieleman & Hinton, 2009) and report the
root mean squared error (RMSE) between the inferred connectivity matrix ˆJ and the true matrix J.
For fair comparison, we also include GWG-eq, which runs GWG-1 with more steps such that it has
the same time cost as our PAFS-5. Figure 8 shows larger neighborhood can effectively help learn the
Ising model. GWG-5 having similar performance as PAFS-5 as, using PCD, the learning efﬁciency
is mainly determined by the mixing of the Markov chain."
LEARNING ON ENERGY BASED MODEL,0.31107954545454547,"Deep EBM We evaluate path auxiliary sampler by learning a deep EBM. The experiment follows
the setting in (Grathwohl et al., 2021). We train deep EBMs paramterized by Residual Networks(He
et al., 2016) on small binary image datasets using PCD(Tieleman & Hinton, 2009) with a replay
buffer(Du & Mordatch, 2019). We compare our methods with Variational Autoencoders Kingma &
Welling (2013), GWG (Grathwohl et al., 2021), RBM and a Deep Belief Network(Hinton, 2009).
We estimate the likelihoods using Annealed Importance Sampling(Neal, 2001) and report the results
in table.1. The results for VAE is taken from Tomczak & Welling (2018), RBM and DBN are taken
from Burda et al. (2015), GWG is taken from Grathwohl et al. (2021). We can see that our approach
improves the log-likelihoods for deep EBMs on all datasets."
DISCUSSION AND CONCLUSION,0.3125,"6
DISCUSSION AND CONCLUSION"
DISCUSSION AND CONCLUSION,0.31392045454545453,"The problem for the selection of the path length remains open. In this work, we propose a soft
no-replacement method PAFS. PAFS is not sensitive to the path length larger than the optimal
length, hence has robust proposal quality for different choice of path length. We also considered
no-backtrack samplers that ﬂip sites without replacement. Intuitively, such auxiliary path encour-
ages to propose states in larger distance. However, for no-backtrack samplers, a too large path length
is harmful for the proposal quality and signiﬁcant reduce the efﬁciency of the sampler. As a result,
ﬁnding a principle way to decide the path length is very important. In continuous space, the optimal
step size can be characterized via acceptance rate (Gelman et al., 1997; Roberts & Rosenthal, 1998;
2001; Beskos et al., 2013). PAS is the gradient based sampler in discrete space, we believe it is
possible to derive its optimal path length in a similar manner as continuous case. We will investigate
it in our future work."
DISCUSSION AND CONCLUSION,0.3153409090909091,"In summary, informed proposal has shown good results for inference, sampling, and learning EBMs
in discrete spaces. Our path auxiliary sampler provides an approach allowing informed proposal to
efﬁciently explore large neighborhoods. We believe there is considerable room for future works to
improve the sampling methods in discrete space."
DISCUSSION AND CONCLUSION,0.31676136363636365,Published as a conference paper at ICLR 2022
DISCUSSION AND CONCLUSION,0.3181818181818182,"Acknowledgement: This research was supported in part by the Defense Advanced Research
Projects Agency (DARPA) under Contract FA8750-20-C-0542 (Systemic Generative Engineering).
The views, opinions, and/or ﬁndings expressed are those of the author(s) and should not be in-
terpreted as representing the ofﬁcial views or policies of the Department of Defense or the U.S.
Government."
REFERENCES,0.3196022727272727,REFERENCES
REFERENCES,0.3210227272727273,"Christophe Andrieu, Nando De Freitas, Arnaud Doucet, and Michael I Jordan. An introduction to
mcmc for machine learning. Machine learning, 50(1):5–43, 2003."
REFERENCES,0.3224431818181818,"Alexandros Beskos, Natesh Pillai, Gareth Roberts, Jesus-Maria Sanz-Serna, and Andrew Stuart.
Optimal tuning of the hybrid monte carlo algorithm. Bernoulli, 19(5A):1501–1534, 2013."
REFERENCES,0.32386363636363635,"Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov. Accurate and conservative estimates of mrf
log-likelihood using reverse annealing.
In Artiﬁcial Intelligence and Statistics, pp. 102–110.
PMLR, 2015."
REFERENCES,0.3252840909090909,"Hanjun Dai, Rishabh Singh, Bo Dai, Charles Sutton, and Dale Schuurmans.
Learning discrete
energy-based models via auxiliary-variable local exploration. arXiv preprint arXiv:2011.05363,
2020."
REFERENCES,0.32670454545454547,"Yilun Du and Igor Mordatch. Implicit generation and generalization in energy-based models. arXiv
preprint arXiv:1903.08689, 2019."
REFERENCES,0.328125,"Andrew Gelman, Walter R Gilks, and Gareth O Roberts. Weak convergence and optimal scaling of
random walk metropolis algorithms. The annals of applied probability, 7(1):110–120, 1997."
REFERENCES,0.32954545454545453,"Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural
message passing for quantum chemistry. In International conference on machine learning, pp.
1263–1272. PMLR, 2017."
REFERENCES,0.3309659090909091,"Mark Girolami and Ben Calderhead.
Riemann manifold langevin and hamiltonian monte carlo
methods. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 73(2):
123–214, 2011."
REFERENCES,0.33238636363636365,"Will Grathwohl, Kevin Swersky, Milad Hashemi, David Duvenaud, and Chris J Maddison. Oops i
took a gradient: Scalable sampling for discrete distributions. arXiv preprint arXiv:2102.04509,
2021."
REFERENCES,0.3338068181818182,"Arthur Gretton, Karsten M Borgwardt, Malte J Rasch, Bernhard Sch¨olkopf, and Alexander Smola.
A kernel two-sample test. The Journal of Machine Learning Research, 13(1):723–773, 2012."
REFERENCES,0.3352272727272727,"Jun Han and Qiang Liu. Stein variational gradient descent without gradient. In International Con-
ference on Machine Learning, pp. 1900–1908. PMLR, 2018."
REFERENCES,0.3366477272727273,W Keith Hastings. Monte carlo sampling methods using markov chains and their applications. 1970.
REFERENCES,0.3380681818181818,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.
770–778, 2016."
REFERENCES,0.33948863636363635,"Geoffrey E Hinton. Training products of experts by minimizing contrastive divergence. Neural
computation, 14(8):1771–1800, 2002."
REFERENCES,0.3409090909090909,"Geoffrey E Hinton. Deep belief networks. Scholarpedia, 4(5):5947, 2009."
REFERENCES,0.34232954545454547,"Matthew Hoffman, Alexey Radul, and Pavel Sountsov. An adaptive-mcmc scheme for setting tra-
jectory lengths in hamiltonian monte carlo. In International Conference on Artiﬁcial Intelligence
and Statistics, pp. 3907–3915. PMLR, 2021."
REFERENCES,0.34375,"Matthew D Hoffman, Andrew Gelman, et al. The no-u-turn sampler: adaptively setting path lengths
in hamiltonian monte carlo. J. Mach. Learn. Res., 15(1):1593–1623, 2014."
REFERENCES,0.34517045454545453,Published as a conference paper at ICLR 2022
REFERENCES,0.3465909090909091,"Priyank Jaini, Didrik Nielsen, and Max Welling. Sampling in combinatorial spaces with survae
ﬂow augmented mcmc. In International Conference on Artiﬁcial Intelligence and Statistics, pp.
3349–3357. PMLR, 2021."
REFERENCES,0.34801136363636365,"Diederik P Kingma and Max Welling.
Auto-encoding variational bayes.
arXiv preprint
arXiv:1312.6114, 2013."
REFERENCES,0.3494318181818182,"Yann LeCun, Sumit Chopra, Raia Hadsell, M Ranzato, and F Huang. A tutorial on energy-based
learning. Predicting structured data, 1(0), 2006."
REFERENCES,0.3508522727272727,"Faming Liang, Chuanhai Liu, and Raymond Carroll. Advanced Markov chain Monte Carlo methods:
learning from past samples, volume 714. John Wiley & Sons, 2011."
REFERENCES,0.3522727272727273,"Nicholas Metropolis, Arianna W Rosenbluth, Marshall N Rosenbluth, Augusta H Teller, and Edward
Teller.
Equation of state calculations by fast computing machines.
The journal of chemical
physics, 21(6):1087–1092, 1953."
REFERENCES,0.3536931818181818,"Radford M Neal. Annealed importance sampling. Statistics and computing, 11(2):125–139, 2001."
REFERENCES,0.35511363636363635,"Radford M Neal. Improving asymptotic variance of mcmc estimators: Non-reversible chains are
better. arXiv preprint math/0407281, 2004."
REFERENCES,0.3565340909090909,"Akihiko Nishimura, David Dunson, and Jianfeng Lu. Discontinuous hamiltonian monte carlo for
sampling discrete parameters. arXiv preprint arXiv:1705.08510, 853, 2017."
REFERENCES,0.35795454545454547,"Ari Pakman and Liam Paninski. Auxiliary-variable exact hamiltonian monte carlo samplers for
binary distributions. arXiv preprint arXiv:1311.2166, 2013."
REFERENCES,0.359375,"Peter H Peskun. Optimum monte-carlo sampling using markov chains. Biometrika, 60(3):607–612,
1973."
REFERENCES,0.36079545454545453,"Samuel Power and Jacob Vorstrup Goldman. Accelerated sampling on discrete spaces with non-
reversible markov processes. arXiv preprint arXiv:1912.04681, 2019."
REFERENCES,0.3622159090909091,"Christian Robert and George Casella. Monte Carlo statistical methods. Springer Science & Business
Media, 2013."
REFERENCES,0.36363636363636365,"Gareth O Roberts and Jeffrey S Rosenthal. Optimal scaling of discrete approximations to langevin
diffusions. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 60(1):
255–268, 1998."
REFERENCES,0.3650568181818182,"Gareth O Roberts and Jeffrey S Rosenthal. Optimal scaling for various metropolis-hastings algo-
rithms. Statistical science, 16(4):351–367, 2001."
REFERENCES,0.3664772727272727,"Peter J Rossky, JD Doll, and HL Friedman. Brownian dynamics as smart monte carlo simulation.
The Journal of Chemical Physics, 69(10):4628–4633, 1978."
REFERENCES,0.3678977272727273,"Emanuele Sansone.
Lsb:
Local self-balancing mcmc in discrete spaces.
arXiv preprint
arXiv:2109.03867, 2021."
REFERENCES,0.3693181818181818,"Kai Sheng Tai, Richard Socher, and Christopher D Manning. Improved semantic representations
from tree-structured long short-term memory networks. arXiv preprint arXiv:1503.00075, 2015."
REFERENCES,0.37073863636363635,"Tijmen Tieleman and Geoffrey Hinton. Using fast weights to improve persistent contrastive di-
vergence. In Proceedings of the 26th annual international conference on machine learning, pp.
1033–1040, 2009."
REFERENCES,0.3721590909090909,"Luke Tierney. A note on metropolis-hastings kernels for general state spaces. Annals of applied
probability, pp. 1–9, 1998."
REFERENCES,0.37357954545454547,"Michalis K Titsias and Omiros Papaspiliopoulos. Auxiliary gradient-based sampling algorithms.
Journal of the Royal Statistical Society: Series B (Statistical Methodology), 80(4):749–767, 2018."
REFERENCES,0.375,"Michalis K Titsias and Christopher Yau. The hamming ball sampler. Journal of the American
Statistical Association, 112(520):1598–1611, 2017."
REFERENCES,0.37642045454545453,Published as a conference paper at ICLR 2022
REFERENCES,0.3778409090909091,"Jakub Tomczak and Max Welling. Vae with a vampprior. In International Conference on Artiﬁcial
Intelligence and Statistics, pp. 1214–1223. PMLR, 2018."
REFERENCES,0.37926136363636365,"Martin J Wainwright and Michael Irwin Jordan. Graphical models, exponential families, and vari-
ational inference. Now Publishers Inc, 2008."
REFERENCES,0.3806818181818182,"Max Welling and Yee W Teh. Bayesian learning via stochastic gradient langevin dynamics. In
Proceedings of the 28th international conference on machine learning (ICML-11), pp. 681–688.
Citeseer, 2011."
REFERENCES,0.3821022727272727,"Joe Whittaker. Graphical models in applied multivariate statistics. Wiley Publishing, 2009."
REFERENCES,0.3835227272727273,"Giacomo Zanella. Informed proposals for local mcmc in discrete spaces. Journal of the American
Statistical Association, 115(530):852–865, 2020."
REFERENCES,0.3849431818181818,"Yichuan Zhang, Zoubin Ghahramani, Amos J Storkey, and Charles Sutton. Continuous relaxations
for discrete hamiltonian monte carlo. Advances in Neural Information Processing Systems, 25:
3194–3202, 2012."
REFERENCES,0.38636363636363635,Published as a conference paper at ICLR 2022
REFERENCES,0.3877840909090909,"A
PROOFS"
REFERENCES,0.38920454545454547,"A.1
PROOF FOR THEOREM 1"
REFERENCES,0.390625,"Our path auxiliary sampler is a proposal distribution augmented auxiliary sampler. Before diving
into the proof, we ﬁrst introduce some background knowledge for auxiliary sampler, based on the
results from page 86 in Liang et al. (2011). Given a proposal distribution T(y|x), we can augment
it by an auxiliary variable u, such that T(y|x) =
R
T1(u|x)T2(y|x, u)du. Using this proposal
distribution, we can deﬁne a marginal sampler and an auxiliary sampler."
REFERENCES,0.39204545454545453,"1. For a marginal sampler, the accept rate is"
REFERENCES,0.3934659090909091,"Amar(x, y) = min{1, π(y)
R
T1(u|y)T2(x|y, u)du
π(x)
R
T1(u|x)T2(y|x, u)du} = min{1, π(y)T(x|y)"
REFERENCES,0.39488636363636365,"π(x)T(y|x)}
(14)"
REFERENCES,0.3963068181818182,"and for y ̸= x, its transition kernel is:
Amar(x, y) = T(y|x)Amar(x, y)
(15)"
REFERENCES,0.3977272727272727,"2. For an auxiliary sampler, given x, we ﬁrst sample auxiliary u ∼T1(u|x), then we sample the
new state y ∼T2(y|x, u). The corresponding accept rate is:"
REFERENCES,0.3991477272727273,"Aaux(x, y, u) = min{1, π(y)T1(u|y)T2(x|y, u)"
REFERENCES,0.4005681818181818,"π(x)T1(u|x)T2(y|x, u)}
(16)"
REFERENCES,0.40198863636363635,"Since the proposal and the accept rate depend on the auxiliary u, we need to integrate the auxiliary
variable u to obtain the transition from x to y:"
REFERENCES,0.4034090909090909,"Kaux(x, y) =
Z"
REFERENCES,0.40482954545454547,"u
T1(u|x)T2(y|x, u)A(x, y, u)du
(17)"
REFERENCES,0.40625,"Though a marginal sampler is Peskun better than an auxiliary sampler (Titsias & Papaspiliopoulos,
2018), a marginal sampler is intractable in most of scenarios, as it requires to integrate over auxiliary
variables u in both proposal and accept rate calculation. Hence, our sampler is implemented in an
auxiliary fashion."
REFERENCES,0.40767045454545453,"Going back our theorem, the auxiliary variable u is the auxiliary path (σ, L). Condition on L, we
have:"
REFERENCES,0.4090909090909091,"T1(u|x, L) = T1(σ|x) = L
Y"
REFERENCES,0.41051136363636365,"l=1
Q0(σl−1, σl)
(18)"
REFERENCES,0.4119318181818182,"T2(y|x, u, L) = I{x, y are the two ends of path u(or sayσ)}
(19)
Given path length L, with a little abuse of notation, the transition kernel for our path auxiliary
sampler K(x, y|L) is: X"
REFERENCES,0.4133522727272727,"(σ,L)∈Σ(X,N):
σ0=x """
REFERENCES,0.4147727272727273,"T1(σ|x, L)
z
}|
{
 L
Y"
REFERENCES,0.4161931818181818,"l=1
Q0(σl−1, σl)

T2(y|x, σ, L)
z
}|
{
I{σL = y}"
REFERENCES,0.41761363636363635,"A(x, y, σ|L)
z
}|
{ min ("
REFERENCES,0.4190340909090909,"1, π(y) QL
l=1 Q0(σl, σl−1)I{σ0 = x}"
REFERENCES,0.42045454545454547,"π(x) QL
l=1 Q0(σl−1, σl)I{σL = y} ) #"
REFERENCES,0.421875,"|
{z
}
T1(σ|x, L)T2(y|x, σ, L)A(x, y, σ|L)dσ
|
{z
}
K(x, y|L) =
R"
REFERENCES,0.42329545454545453,"σ T1(σ|x, L)T2(y|x, σ, L)A(x, y, σ|L)dσ
(20)
When σL ̸= y, the accept rate above is not well-deﬁned. To avoid making extra deﬁnition, we
absorb T2, the indicator, as a constraint of the domain in the integration. Then, we have: X"
REFERENCES,0.4247159090909091,"(σ,L)∈Σ(X,N):
σ0=x,σL=y """
REFERENCES,0.42613636363636365,"T1(σ|x, L)
z
}|
{
 L
Y"
REFERENCES,0.4275568181818182,"l=1
Q0(σl−1, σl)
"
REFERENCES,0.4289772727272727,"A(x, y, σ|L)
z
}|
{ min ("
REFERENCES,0.4303977272727273,"1, π(y) QL
l=1 Q0(σl, σl−1)"
REFERENCES,0.4318181818181818,"π(x) QL
l=1 Q0(σl−1, σl) ) #"
REFERENCES,0.43323863636363635,"|
{z
}
K(x, y|L) =
R"
REFERENCES,0.4346590909090909,"σ T1(σ|x, L)T2(y|x, σ, L)A(x, y, σ|L)dσ (21)"
REFERENCES,0.43607954545454547,"With these knowledge prepared, we begin to proof our theorem 1."
REFERENCES,0.4375,Published as a conference paper at ICLR 2022
REFERENCES,0.43892045454545453,"Proof. Denote K(x, y) as the probability that x transit to a different state y, then we have:"
REFERENCES,0.4403409090909091,"π(x)K(x, y)
(22)"
REFERENCES,0.44176136363636365,"= π(x)
X"
REFERENCES,0.4431818181818182,"L
α(L)
X"
REFERENCES,0.4446022727272727,"(σ,L)∈Σ(X,N):
σ0=x,σL=y "" L
Y"
REFERENCES,0.4460227272727273,"l=1
Q0(σl−1, σl) ! min ("
REFERENCES,0.4474431818181818,"1, π(y) QL
l=1 Q0(σl, σl−1)"
REFERENCES,0.44886363636363635,"π(x) QL
l=1 Q0(σl−1, σl) )# (23) =
X"
REFERENCES,0.4502840909090909,"L
α(L)
X"
REFERENCES,0.45170454545454547,"(σ,L)∈Σ(X,N):
σ0=x,σL=y "" π(x) L
Y"
REFERENCES,0.453125,"l=1
Q0(σl−1, σl) ! min ("
REFERENCES,0.45454545454545453,"1, π(y) QL
l=1 Q0(σl, σl−1)"
REFERENCES,0.4559659090909091,"π(x) QL
l=1 Q0(σl−1, σl) )# (24) =
X"
REFERENCES,0.45738636363636365,"L
α(L)
X"
REFERENCES,0.4588068181818182,"(σ,L)∈Σ(X,N):
σ0=x,σL=y min ( π(x) L
Y"
REFERENCES,0.4602272727272727,"l=1
Q0(σl−1, σl), π(y) L
Y"
REFERENCES,0.4616477272727273,"l=1
Q0(σl, σl−1) ) (25) =
X"
REFERENCES,0.4630681818181818,"L
α(L)
X"
REFERENCES,0.46448863636363635,"(σ,L)∈Σ(X,N):
σ0=x,σL=y "" π(y) L
Y"
REFERENCES,0.4659090909090909,"l=1
Q0(σl, σl−1) ! min"
REFERENCES,0.46732954545454547,"(
π(x) QL
l=1 Q0(σl−1, σl)"
REFERENCES,0.46875,"π(y) QL
l=1 Q0(σl, σl−1)
, 1 )# (26)"
REFERENCES,0.47017045454545453,"= π(y)
X"
REFERENCES,0.4715909090909091,"L
α(L)
X"
REFERENCES,0.47301136363636365,"(σ,L)∈Σ(X,N):
σ0=y,σL=x "" L
Y"
REFERENCES,0.4744318181818182,"l=1
Q0(σl, σl−1) ! min"
REFERENCES,0.4758522727272727,"(
π(x) QL
l=1 Q0(σl, σl−1)"
REFERENCES,0.4772727272727273,"π(y) QL
l=1 Q0(σl−1, σl)
, 1 )# (27)"
REFERENCES,0.4786931818181818,"= π(y)K(y, x)
(28)"
REFERENCES,0.48011363636363635,"The key idea for the proof is that (σ, L) is symmetric w.r.t. its two ends, when σ is a path from
x to y, σ is also a path from y to σ. Hence, we are able to exchange the orientation of the path in
equation 27."
REFERENCES,0.4815340909090909,"A.2
PROOF FOR LEMMA 1"
REFERENCES,0.48295454545454547,"Lemma 1. X is a ﬁnite state space with distribution π and a neighborhood function N such that
every state has equal number of states. F is a class of weight functions, such that for any f ∈F,
1) f : R+ →R+, 2) f(1) = 1, 3) f(t) is monotonically increasing, 4) f(t)f( 1"
REFERENCES,0.484375,"t )t ≤1, ∀t ≤1."
REFERENCES,0.48579545454545453,"∀f ∈F, deﬁne ¯f(t) =
q"
REFERENCES,0.4872159090909091,f(t)f( 1
REFERENCES,0.48863636363636365,"t )t, we have"
REFERENCES,0.4900568181818182,"min
x∈X Z ¯
f(x) ≤max
y∈X Zf(y)
(29)"
REFERENCES,0.4914772727272727,"Proof. Since X is ﬁnite, we can always ﬁnd state x1, x2 having highest and lowest probability,
respectively. Then, we have:"
REFERENCES,0.4928977272727273,"Z ¯
f(x1) =
X"
REFERENCES,0.4943181818181818,z∈N(x1)
REFERENCES,0.49573863636363635,¯f( π(z)
REFERENCES,0.4971590909090909,"π(x1)) ≤|N(x1)| = |N(x2)| ≤
X"
REFERENCES,0.49857954545454547,"z∈N(x2)
f( π(z)"
REFERENCES,0.5,"π(x2)) = Zf(x2)
(30)"
REFERENCES,0.5014204545454546,"A.3
DISCUSSION FOR IDEAL FUNCTION"
REFERENCES,0.5028409090909091,"We deﬁne ideal function as a stepping stone to show the advantage of locally balanced function. We
name it ”ideal” as the its properties are ideal assumption for a weight function in PIP. Conditions
1) f : R+ →R+ is a natural requirement for weight function. Condition 2) f(1) = 1 can be
easily realized by substituting f(t) by f(t)/f(1), as PIP only depends on the ratio of weights.
condition 3) f(t) is monotonically increasing, and condition 4) f(t)f( 1"
REFERENCES,0.5042613636363636,"t )t ≤1, ∀t ≤1, though, are
technical requirements, it is reasonable for weight functions. Monotonic increasing in 3) indicates
the proposal distribution match the target distribution, where a point z has a higher probability in
target distribution should also has a higher probability in proposal distribution. Condition 4) is
weaker than the following condition: f(t) ≤t, ∀t ≥1, hence condition 4) is easier to satisfy."
REFERENCES,0.5056818181818182,Published as a conference paper at ICLR 2022
REFERENCES,0.5071022727272727,"Currently deﬁnition of ideal function class already contains most of commonly used weight function,
such as f(t) =
2t
1+t, f(t) = max{1, t}, f(t) = min{1, t}, and f(t) = tα, where α ≥0. Also, we
can following properties
Property 2. The logarithm of ideal function is closed in convex combination.
That’s to say,
∀f1, ..., fn ∈F, and ∀λ1, ..., λn, s.t λi ≥0 and Pn
i=1 λi = 1, we have"
REFERENCES,0.5085227272727273,"F(t) = e
Pn
i=1 λi log fi(t) ∈F
(31)"
REFERENCES,0.5099431818181818,"Proof. Let fi and λi be deﬁned as above. Obviously, F is positive and F(1) = 1, hence satisﬁes
condition 1) and 2). For condition 3), we have:"
REFERENCES,0.5113636363636364,F(t)F(1
REFERENCES,0.5127840909090909,"t )t = e
Pn
i=1 λi log fi(t) · e
Pn
i=1 λi log fi( 1"
REFERENCES,0.5142045454545454,"t ) · e
Pn
i=1 λi log t
(32)"
REFERENCES,0.515625,"= e
Pn
i=1 λi(log fi(t)+log fi( 1"
REFERENCES,0.5170454545454546,"t )+log t)
(33)"
REFERENCES,0.5184659090909091,"= e
Pn
i=1 λi log(fi(t)fi( 1"
REFERENCES,0.5198863636363636,"t )t)
(34)"
REFERENCES,0.5213068181818182,"Hence, ∀t ≤1, we have:"
REFERENCES,0.5227272727272727,F(t)f(1
REFERENCES,0.5241477272727273,"t )t ≤e
Pn
i=1 λi0 = 1
(35)"
REFERENCES,0.5255681818181818,which implies F(t) ∈F.
REFERENCES,0.5269886363636364,"Property 3. Ideal function is a superset for normalized monotonically increasing locally balanced
function GI := {g ∈G : g(1) = 1, g is monotonically increasing}."
REFERENCES,0.5284090909090909,"Proof. ∀g ∈GI, condition 1), 2) and 3) are obviously satisﬁed. For condition 4), since g(t) is locally
balanced, we have:"
REFERENCES,0.5298295454545454,g(t)g(1
REFERENCES,0.53125,"t )t = g2(t) ≤g2(1) = 1
(36)"
REFERENCES,0.5326704545454546,implies g ∈F.
REFERENCES,0.5340909090909091,"Considering the ideal function cover such a large number of functions, we believe the asymptotic
optimality over ideal function strongly suggests locally balanced function is a good choice for path
auxiliary sampler."
REFERENCES,0.5355113636363636,"A.4
PROOF FOR LEMMA 2"
REFERENCES,0.5369318181818182,"The (undirected) conditional independence graph corresponds to Markov random ﬁelds:
Deﬁnition 2. The conditional independence graph of X is the undirected graph G = (K, E), where
K = {1, ..., k} and (i, j) /∈E if and only if Xi ⊥Xj|XK\{i,j}."
REFERENCES,0.5383522727272727,"More details can be found in p.60 Whittaker (2009).
Lemma 2. Consider the state space in Cartesian products X = ×n
i=1Xi, where each Xi is a ﬁnite
space with M elements, and the neighborhood is deﬁned as 1-Hamming ball. Let dn be the maximum
degree in conditional independence graph. Deﬁne c(n)
g
:= supy∈N(x)
Zg(y)
Zg(x). If 1) limn→∞dn"
REFERENCES,0.5397727272727273,n = 0;
REFERENCES,0.5411931818181818,2) the target distribution satisﬁes π(y)
REFERENCES,0.5426136363636364,"π(x) ≤C < ∞, ∀y ∈N(x), then we have:"
REFERENCES,0.5440340909090909,"1 ≤c(n)
g
≤1 + O(dng(C) ng( 1"
REFERENCES,0.5454545454545454,"C ) ))
as n →∞,
∀g ∈F
(37)"
REFERENCES,0.546875,"To simplify the notation, we assume M = 2 in this proof. It is straightforward to extend the proof
to any ﬁnite M."
REFERENCES,0.5482954545454546,"Proof. On one side, by deﬁnition, we can easily see that c(n)
g
≥1. On the other side, given
x, we use index i represent that we select y ∈N(x) by ﬂipping index i for x.
We de-
note gx(j) = g(π(z))/g(π(x)) where z is obtained by ﬂipping index j for x, and we denote
gi(j) = g(π(z))/g(π(y)), where z is obtained by ﬂipping index j for y. We also denote B(i)"
REFERENCES,0.5497159090909091,Published as a conference paper at ICLR 2022
REFERENCES,0.5511363636363636,"as the Markov boundary for i, which means given B(i), i is independent with remaining nodes.
Then, we can write"
REFERENCES,0.5525568181818182,"c(n)
g
= sup
x∈X
sup
i∈[M]"
REFERENCES,0.5539772727272727,"Pn
j=1 gi(j)
Pn
j=1 gx(j)
(38)"
REFERENCES,0.5553977272727273,"= sup
x∈X
sup
i∈[M] P"
REFERENCES,0.5568181818181818,j∈B(i) gi(j) + P
REFERENCES,0.5582386363636364,"j /∈B(i) gi(j)
P"
REFERENCES,0.5596590909090909,j∈B(i) gx(j) + P
REFERENCES,0.5610795454545454,"j /∈B(i) gx(j)
(39)"
REFERENCES,0.5625,"≤sup
x∈X
sup
i∈[M] P"
REFERENCES,0.5639204545454546,"j∈B(i) gi(j)
P"
REFERENCES,0.5653409090909091,j∈B(i) gx(j) +
REFERENCES,0.5667613636363636,"P
j /∈B(i) gi(j)
P"
REFERENCES,0.5681818181818182,j∈B(i) gx(j) + P
REFERENCES,0.5696022727272727,"j /∈B(i) gx(j)
(40)"
REFERENCES,0.5710227272727273,"≤sup
x∈X
sup
i∈[M]
1 + P"
REFERENCES,0.5724431818181818,"j /∈B(i) gi(j)
P"
REFERENCES,0.5738636363636364,j∈B(i) gx(j) + P
REFERENCES,0.5752840909090909,"j /∈B(i) gx(j)
(41)"
REFERENCES,0.5767045454545454,"≤sup
x∈X
sup
i∈[M]
1 + dng(C) ng( 1"
REFERENCES,0.578125,"C )
(42)"
REFERENCES,0.5795454545454546,≤1 + dng(C) ng( 1
REFERENCES,0.5809659090909091,"C )
(43)"
REFERENCES,0.5823863636363636,"If B(i) is not empty, the ﬁrst term in equation 40 equals to 1. If B(i) is empty, the ﬁrst term in
equation 40 does not exist, hence it can still be bounded by 1."
REFERENCES,0.5838068181818182,"Remark: For a ﬁxed ideal function g ∈F, Lemma 2 shows c(n) converges to 1 at a rate 1+O( dn n )"
REFERENCES,0.5852272727272727,"A.5
PROOF FOR THEOREM 2"
REFERENCES,0.5866477272727273,We prove the theorem by using Lemma 1 and Lemma 2.
REFERENCES,0.5880681818181818,"Proof. We ﬁrst show that, for all g ∈F, the transition probability:"
REFERENCES,0.5894886363636364,"P¯g(x, y) ≥( 1"
REFERENCES,0.5909090909090909,"cgcˆg
)UPg(x, y)
(44)"
REFERENCES,0.5923295454545454,"where cg is deﬁned in Lemma 2. We temporarily ignore the superscription and will add it back at the
end of the proof. Consider a path (σ, L), we denote tj,k = π(σk)"
REFERENCES,0.59375,"π(σj) . Then the probability that x = σ0
transits to y = σL is:"
REFERENCES,0.5951704545454546,"Pg(x, y, σ|L) = L
Y"
REFERENCES,0.5965909090909091,"l=1
Qg(σl−1, σl) min ("
REFERENCES,0.5980113636363636,"1, π(y) QL
l=1 Qg(σl, σl−1)"
REFERENCES,0.5994318181818182,"π(x) QL
l=1 Qg(σl−1, σl) ) (45) = min ( L
Y l=1"
REFERENCES,0.6008522727272727,"g(tl−1,l)
Zg(σl−1), L
Y"
REFERENCES,0.6022727272727273,"l=1
tl−1,l
g(tl,l−1)"
REFERENCES,0.6036931818181818,Zg(σl) ) (46)
REFERENCES,0.6051136363636364,"By deﬁnition of cg, we have:"
REFERENCES,0.6065340909090909,"Pg(x, y, σ|L) ≤cL
g
min
nQL
l=1 g(tl−1,l), QL
l=1 tl−1,lg(tl,l−1)
o"
REFERENCES,0.6079545454545454,"maxz∈X (n) ZL
g (z)
(47)"
REFERENCES,0.609375,"P¯g(x, y, σ|L) ≥1 cL
¯g"
REFERENCES,0.6107954545454546,"min
nQL
l=1 ¯g(tl−1,l), QL
l=1 tl−1,l¯g(tl,l−1)
o"
REFERENCES,0.6122159090909091,"minz∈X (n) ZL
¯g (z)
(48)"
REFERENCES,0.6136363636363636,"Use the property of ¯g, we have min ( L
Y"
REFERENCES,0.6150568181818182,"l=1
g(tl−1,l), L
Y"
REFERENCES,0.6164772727272727,"l=1
tl−1,lg(tl,l−1) ) ≤"
REFERENCES,0.6178977272727273,"v
u
u
t L
Y"
REFERENCES,0.6193181818181818,"l=1
g(tl−1,l)g(tl,l−1)tl−1,l = L
Y"
REFERENCES,0.6207386363636364,"l=1
¯g(tl−1,l)
(49)"
REFERENCES,0.6221590909090909,Published as a conference paper at ICLR 2022
REFERENCES,0.6235795454545454,"Combining equation 47, equation 48, equation 49, and Lemma 1 we have:"
REFERENCES,0.625,"P¯g(x, y, σ|L) ≥1 cL
¯g"
REFERENCES,0.6264204545454546,"QL
l=1 ¯g(tl−1,l)
minz∈X (n) ZL
¯g (z)
(50) ≥1 cL
¯g"
REFERENCES,0.6278409090909091,"min
nQL
l=1 g(tl−1,l), QL
l=1 tl−1,lg(tl,l−1)
o"
REFERENCES,0.6292613636363636,"maxz∈X (n) ZL
g (z)
(51)"
REFERENCES,0.6306818181818182,"≥
1
cL
¯g cLg
Pg(x, y, σ|L)
(52)"
REFERENCES,0.6321022727272727,"The inequality holds for arbitrary auxiliary path (σ, L) and the path length L ≤U, hence we prove
the ﬁrst step. Then ∀g ∈F, we use the estimation of c(n)
g
in Lemma 2, we have"
REFERENCES,0.6335227272727273,"P¯g(x, y) ≥C(n)
g
Pg(x, y)
(53) where"
REFERENCES,0.6349431818181818,"C(n)
g
= 1 −O(U dng(C) ng( 1"
REFERENCES,0.6363636363636364,"C ) )
(54)"
REFERENCES,0.6377840909090909,This indicates ¯g is asymptotically better than g and proves the theorem.
REFERENCES,0.6392045454545454,"Remark: In the proof, equation 54 shows the convergence rate depends on g, this factor prevents
a uniform convergence rate for the ideal function class F. We can obtain a uniform rate when we
constraint in smaller function class, for example, if we restrict to FM := {f ∈F : f(C)/f( 1"
REFERENCES,0.640625,"C ) ≤
M}, the convergence rate is 1 −O( dn n )."
REFERENCES,0.6420454545454546,"A.6
PROOF FOR PROPERTY 1"
REFERENCES,0.6434659090909091,Proof.
REFERENCES,0.6448863636363636,"A(x, y, σ, L) = min ("
REFERENCES,0.6463068181818182,"1, π(y) QL
l=1 Q(σl, σl−1)"
REFERENCES,0.6477272727272727,"π(x) QL
l=1 Q(σl−1, σl) ) (55) = min 
 1, L
Y l=1"
REFERENCES,0.6491477272727273,"π(σl)
π(σl−1)"
REFERENCES,0.6505681818181818,"! QL
l=1 g( π(σl−1)"
REFERENCES,0.6519886363636364,"π(σl) )/Zg(σl)
QL
l=1 g(
π(σl)
π(σl−1))/Zg(σl−1) 
"
REFERENCES,0.6534090909090909,"
(56) = min 
 1,  
L
Y l=1"
REFERENCES,0.6548295454545454,"π(σl)
π(σl−1)"
REFERENCES,0.65625,g( π(σl−1)
REFERENCES,0.6576704545454546,π(σl) )
REFERENCES,0.6590909090909091,"g(
π(σl)
π(σl−1))   L
Y l=1"
REFERENCES,0.6605113636363636,Zg(σl−1)
REFERENCES,0.6619318181818182,"Zg(σl) !
"
REFERENCES,0.6633522727272727,"
(57)"
REFERENCES,0.6647727272727273,"= min

1, Zg(x) Zg(y)"
REFERENCES,0.6661931818181818,"
(58)"
REFERENCES,0.6676136363636364,"A.7
PROOF FOR THEOREM 3"
REFERENCES,0.6690340909090909,"The idea to proof theorem 3 is similar to Grathwohl et al. (2021), which uses the Lipschitz condition
to bound the estimation error. The different is, in PAFS, we use the linearization at each state σl to
propose the next state σl+1, hence to need to accumulate the error at each step to obtain our ﬁnal
result."
REFERENCES,0.6704545454545454,Published as a conference paper at ICLR 2022
REFERENCES,0.671875,"Proof. For any path (σ, L), we ﬁrst bound the estimation error ˜f0(z) −˜f0(σl−1), for z ∈N(σl−1).
Since f is M-smooth, we have:
f(z) −f(σl−1)
(59)"
REFERENCES,0.6732954545454546,"≤⟨∇f(σl−1), z −σl−1⟩+ K"
REFERENCES,0.6747159090909091,"2 ∥z −σl−1∥2
(60)"
REFERENCES,0.6761363636363636,"=⟨∇f(σ0), z −σl−1⟩+ ⟨∇f(σl−1) −∇f(σ0), z −σl−1⟩+ K"
REFERENCES,0.6775568181818182,"2 ∥z −σl−1∥2
(61)"
REFERENCES,0.6789772727272727,"≤⟨∇f(σ0), z −σl−1⟩+ K(l −1"
REFERENCES,0.6803977272727273,"2)
(62)"
REFERENCES,0.6818181818181818,"Similarly, we also have:"
REFERENCES,0.6832386363636364,"f(z) −f(σl−1) ≥⟨∇f(σ0), z −σl−1⟩+ K(l + 1"
REFERENCES,0.6846590909090909,"2)
(63)"
REFERENCES,0.6860795454545454,"With this estimation, we have:"
REFERENCES,0.6875,"˜Q0(σl−1, σl) =
e−1"
REFERENCES,0.6889204545454546,"2 ⟨∇f(σ0),σl−σl−1⟩
P"
REFERENCES,0.6903409090909091,z∈N(σl−1) e−1
REFERENCES,0.6917613636363636,"2 ⟨∇f(σ0),σl−σl−1⟩
(64) ≥
e−1"
REFERENCES,0.6931818181818182,2 [f(σl)−f(σl−1)−K(l−1
REFERENCES,0.6946022727272727,"2 )]
P"
REFERENCES,0.6960227272727273,z∈N(σl−1) e−1
REFERENCES,0.6974431818181818,2 [f(z)−f(σl−1)+K(l+ 1
REFERENCES,0.6988636363636364,"2 )]
(65)"
REFERENCES,0.7002840909090909,"= Q(σl−1, σl)e−Kl
(66)
Similarly, we can also obtain
˜QL(σl, σl−1) ≥Q(σl, σl−1)eK(L−l)
(67)
Now, consider the transition kernel"
REFERENCES,0.7017045454545454,"˜P(x, y) =
X"
REFERENCES,0.703125,"L
α(L)
X"
REFERENCES,0.7045454545454546,"(σ,L)∈Σ(X,N):
σ0=x,σL=y L
Y"
REFERENCES,0.7059659090909091,"l=1
˜Q0(σl−1, σl) min ("
REFERENCES,0.7073863636363636,"1, π(y) π(x)"
REFERENCES,0.7088068181818182,"QL
l=1 ˜QL(σl, σl−1)
QL
l=1 ˜Q0(σl−1, σl) ) (68) =
X"
REFERENCES,0.7102272727272727,"L
α(L)
X"
REFERENCES,0.7116477272727273,"(σ,L)∈Σ(X,N):
σ0=x,σL=y min ( L
Y"
REFERENCES,0.7130681818181818,"l=1
˜Q0(σl−1, σl), π(y) π(x) L
Y"
REFERENCES,0.7144886363636364,"l=1
˜QL(σl, σl−1) ) (69) ≥
X"
REFERENCES,0.7159090909090909,"L
α(L)
X"
REFERENCES,0.7173295454545454,"(σ,L)∈Σ(X,N):
σ0=x,σL=y min ( L
Y"
REFERENCES,0.71875,"l=1
Q(σl−1, σl)e−Kl, π(y) π(x) L
Y"
REFERENCES,0.7201704545454546,"l=1
Q(σl, σl−1)e−K(L−l)
) (70) ≥
X"
REFERENCES,0.7215909090909091,"L
α(L)
X"
REFERENCES,0.7230113636363636,"(σ,L)∈Σ(X,N):
σ0=x,σL=y"
REFERENCES,0.7244318181818182,e−K L(L+1)
MIN,0.7258522727272727,"2
min ( L
Y"
MIN,0.7272727272727273,"l=1
Q(σl−1, σl), π(y) π(x) L
Y"
MIN,0.7286931818181818,"l=1
Q(σl, σl−1) ) (71)"
MIN,0.7301136363636364,≥e−K U(U+1)
MIN,0.7315340909090909,"2
P(x, y)
(72)"
MIN,0.7329545454545454,"Remark: Though the theorem proved above is very loose, it provides a framework to prove ap-
proximation bound for path auxiliary sampler via single step approximation in equation 66. More
sophisticated bounds can be obtained by improving the single step estimation in equation 66 via the
property of the conditional independence. Speciﬁcally, a local modifying of the state usually does
not inﬂuence most of the indices, which for example can be characterized by the Markov boundary.
Then, with high probability, the auxiliary path can avoid manipulating correlated indices and hence
result in the approximation error in equation 66 be controlled by a constant, rather than e−Kl. For
example, in Ising model, an auxiliary path has high probability to avoid manipulating two adjacent
nodes, and in this case, the linearization is accurate and we loose nothing in approximation. In deep
EBMs, the conditional independence is usually not available, but we can still expect low correla-
tion between most of dimensions. Such analysis relies on more accurate assumption of conditional
independence and we will leave it to our future work."
MIN,0.734375,Published as a conference paper at ICLR 2022
MIN,0.7357954545454546,"0
500
1000
1500
2000
2500
MCMC Steps 10000 8000 6000 4000 2000 0"
MIN,0.7372159090909091,BurnIn in terms of MCMC steps
MIN,0.7386363636363636,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.7400568181818182,"0
2
4
6
8
MCMC Samplers 103"
MIN,0.7414772727272727,6 × 102
MIN,0.7428977272727273,2 × 103
MIN,0.7443181818181818,3 × 103
MIN,0.7457386363636364,ESS in terms of MCMC steps
MIN,0.7471590909090909,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.7485795454545454,"0
1000
2000
3000
4000
5000
Energy Evaluations 10000 8000 6000 4000 2000 0"
MIN,0.75,BurnIn in terms of Energy Evaluations
MIN,0.7514204545454546,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.7528409090909091,"0
2
4
6
8
MCMC Samplers 103"
MIN,0.7542613636363636,2 × 102
MIN,0.7556818181818182,3 × 102
MIN,0.7571022727272727,4 × 102
MIN,0.7585227272727273,6 × 102
MIN,0.7599431818181818,ESS in terms of Energy Evaluations
MIN,0.7613636363636364,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.7627840909090909,Figure 9: PAS and PAFS in different lengths on 50 × 50 Ising Model
MIN,0.7642045454545454,"0
1000
2000
3000
4000
5000
MCMC Steps 40000 35000 30000 25000 20000 15000 10000 5000 0"
MIN,0.765625,BurnIn in terms of MCMC steps
MIN,0.7670454545454546,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.7684659090909091,"0
2
4
6
8
MCMC Samplers 103"
MIN,0.7698863636363636,3 × 102
MIN,0.7713068181818182,4 × 102
MIN,0.7727272727272727,6 × 102
MIN,0.7741477272727273,ESS in terms of MCMC steps
MIN,0.7755681818181818,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.7769886363636364,"0
2000
4000
6000
8000
10000
Energy Evaluations 40000 35000 30000 25000 20000 15000 10000 5000 0"
MIN,0.7784090909090909,BurnIn in terms of Energy Evaluations
MIN,0.7798295454545454,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.78125,"0
2
4
6
8
MCMC Samplers 102"
MIN,0.7826704545454546,ESS in terms of Energy Evaluations
MIN,0.7840909090909091,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.7855113636363636,Figure 10: PAS and PAFS in different lengths on 100 × 100 Ising Model
MIN,0.7869318181818182,"B
DETAILS FOR EXPERIMENTS"
MIN,0.7883522727272727,"B.1
SAMPLING ON ISING"
MIN,0.7897727272727273,"Following Zanella (2020), we set the interaction term λ = 1, and we set αi = µ + Zi if i in the
center of the square lattice, and αi = −µ + Zi otherwise, where µ = 2 and Zi ∼Unif(−3, 3). We
generate the lattice Ising model in four sizes: p = 50, 100, 150, 200. We ﬁrst run PAS and PAFS
with path lengh L = 1, 2, 3, 5, 10 on Ising model with size p = 50, 100, 150, 200. For each path
length and each model size, we run 100 chains 100,000 steps and compute the ESS using the last
50,000 steps. The results for p = 200 is given in ﬁgure 3. We give the results for p = 50, 100, 150
in the following.
From ﬁgure 9, ﬁgure 10, ﬁgure 11, and ﬁgure 3, we can see that the difference
between PAS and PAFS in terms of MCMC steps is decreasing when the model size is increasing.
The reason is that when the model becomes larger, most of the nodes are conditionally independent.
When the auxiliary path does not involve two adjacent nodes, the approximation has zero error. This
observation provides a possibility to further improve the approximation bound in Theorem 3. We
will study this in our future work."
MIN,0.7911931818181818,"For comparing with other samplers, we report the results for each problem size p = 50, 100, 150, 200
in ﬁgure 12, ﬁgure 13, ﬁgure 14, ﬁgure 4. Our path auxiliary samplers substantially outperform other
competitors."
MIN,0.7926136363636364,"B.2
SAMPLING ON FHMM"
MIN,0.7940340909090909,"We compare PAS and PAFS with different path length on FHMM. We choose parameters K = 10,
P(xn,1 = 1) = 0.05, P(Xn,k = xn,k−1) = 0.85, w ∈Gaussian(0, IK), b ∈Gaussian(0, 1),
and σ2 = 0.25. We simulate PAS, PAFS with path length L = 1, 2, 3, 5, 10 on FHMM with
N = 500, 1000, 1500, 2000. For each conﬁguration, we run 100 chains and report the burn in
period, as well as the ESS in terms of MCMC steps and energy function evaluations."
MIN,0.7954545454545454,"0
1000
2000
3000
4000
5000
6000
7000
MCMC Steps 80000 60000 40000 20000 0"
MIN,0.796875,BurnIn in terms of MCMC steps
MIN,0.7982954545454546,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.7997159090909091,"0
2
4
6
8
MCMC Samplers 103"
MIN,0.8011363636363636,2 × 102
MIN,0.8025568181818182,3 × 102
MIN,0.8039772727272727,4 × 102
MIN,0.8053977272727273,6 × 102
MIN,0.8068181818181818,ESS in terms of MCMC steps
MIN,0.8082386363636364,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.8096590909090909,"0
2000
4000
6000
8000
10000 12000 14000
Energy Evaluations 80000 60000 40000 20000 0"
MIN,0.8110795454545454,BurnIn in terms of Energy Evaluations
MIN,0.8125,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.8139204545454546,"0
2
4
6
8
MCMC Samplers 102"
MIN,0.8153409090909091,ESS in terms of Energy Evaluations
MIN,0.8167613636363636,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.8181818181818182,Figure 11: PAS and PAFS in different lengths on 150 × 150 Ising Model
MIN,0.8196022727272727,Published as a conference paper at ICLR 2022
MIN,0.8210227272727273,"0
2
4
6
8
100 101 102 103"
MIN,0.8224431818181818,ESS in terms of Energy Function Evaluations
MIN,0.8238636363636364,"Gibbs-1
Gibbs-5
RW-1
RW-10
LB-1
GWG-1
GWG-10
PAS-10
PASF-10"
MIN,0.8252840909090909,"0
2
4
6
8"
MIN,0.8267045454545454,ESS in terms of MCMC steps
MIN,0.828125,"Gibbs-1
Gibbs-5
RW-1
RW-10
LB-1
GWG-1
GWG-10
PAS-10
PASF-10"
MIN,0.8295454545454546,Figure 12: Sampling on 50 × 50 Ising model
MIN,0.8309659090909091,"0
2
4
6
8
100 101 102 103"
MIN,0.8323863636363636,ESS in terms of Energy Function Evaluations
MIN,0.8338068181818182,"Gibbs-1
Gibbs-5
RW-1
RW-10
LB-1
GWG-1
GWG-10
PAS-10
PASF-10"
MIN,0.8352272727272727,"0
2
4
6
8"
MIN,0.8366477272727273,ESS in terms of MCMC steps
MIN,0.8380681818181818,"Gibbs-1
Gibbs-5
RW-1
RW-10
LB-1
GWG-1
GWG-10
PAS-10
PASF-10"
MIN,0.8394886363636364,Figure 13: Sampling on 100 × 100 Ising model
MIN,0.8409090909090909,"We can observe that: 1) in terms of MCMC steps, PAFS has very similar burn in time in energy
compared to PAS, while the the gap in ESS is larger than the gap in Ising. The reason is FHMM
is not as close to linear model as Ising and PAFS has larger estimation error. 2) in terms of energy
function evaluations, PAFS still leads the performance as other models. PAS only obtains faster
mixing, and no improvements in ESS. The results show that whether PAS can help depends on the
property of the target distribution."
MIN,0.8423295454545454,"B.3
SAMPLING ON RBM"
MIN,0.84375,"We compare GWG, PAFS, and NB with different path lengths on RBM trained on MNIST dataset.
GWG (Grathwohl et al., 2021) samples all indices to manipulate based on the linearization at starting
state of the path σ0, and we classify it as sampling with replacement. Our PAFS samples the indices
based on the linearization at current state σl and we classify it as sampling with soft no replacement.
Speciﬁcally, consider a binary case, when we ﬂip index i at state σl, then in the remaining of the path,
the energy change for index i will be reversed. Hence, if we ﬂip an index and reduce the system’s
energy, we will have small probability ﬂip it back. A third type sampler is No Backtrack (NB)
sampler. It is also a path auxiliary sampler and it rules out the indices have been selected to assure"
MIN,0.8451704545454546,"0
2
4
6
8 100 101 102 103"
MIN,0.8465909090909091,ESS in terms of Energy Function Evaluations
MIN,0.8480113636363636,"Gibbs-1
Gibbs-5
RW-1
RW-10
LB-1
GWG-1
GWG-10
PAS-10
PASF-10"
MIN,0.8494318181818182,"0
2
4
6
8"
MIN,0.8508522727272727,ESS in terms of MCMC steps
MIN,0.8522727272727273,"Gibbs-1
Gibbs-5
RW-1
RW-10
LB-1
GWG-1
GWG-10
PAS-10
PASF-10"
MIN,0.8536931818181818,Figure 14: Sampling on 150 × 150 Ising model
MIN,0.8551136363636364,Published as a conference paper at ICLR 2022
MIN,0.8565340909090909,"0
200
400
600
800
1000
MCMC Steps 3000 2000 1000 0 1000 2000 3000"
MIN,0.8579545454545454,BurnIn in terms of MCMC steps
MIN,0.859375,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.8607954545454546,"0
200
400
600
800
1000
MCMC Samplers 103"
MIN,0.8622159090909091,Reconstruction Error in terms of MCMC steps
MIN,0.8636363636363636,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.8650568181818182,"0
250
500
750
1000
1250
1500
1750
2000
Energy Evaluations 3000 2000 1000 0 1000 2000 3000"
MIN,0.8664772727272727,BurnIn in terms of Energy Evaluations
MIN,0.8678977272727273,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.8693181818181818,"0
250
500
750
1000
1250
1500
1750
2000
MCMC Samplers 103"
MIN,0.8707386363636364,Reconstruction Error in terms of Energy Evaluations
MIN,0.8721590909090909,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.8735795454545454,Figure 15: PAS and PAFS in different path lengths on FHMM N=500
MIN,0.875,"0
250
500
750
1000
1250
1500
1750
2000
MCMC Steps 6000 4000 2000 0 2000 4000 6000"
MIN,0.8764204545454546,BurnIn in terms of MCMC steps
MIN,0.8778409090909091,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.8792613636363636,"0
250
500
750
1000
1250
1500
1750
2000
MCMC Samplers 103 104"
MIN,0.8806818181818182,Reconstruction Error in terms of MCMC steps
MIN,0.8821022727272727,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.8835227272727273,"0
500
1000
1500
2000
2500
3000
3500
4000
Energy Evaluations 6000 4000 2000 0 2000 4000 6000"
MIN,0.8849431818181818,BurnIn in terms of Energy Evaluations
MIN,0.8863636363636364,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.8877840909090909,"0
500
1000
1500
2000
2500
3000
3500
4000
MCMC Samplers 103 104"
MIN,0.8892045454545454,Reconstruction Error in terms of Energy Evaluations
MIN,0.890625,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.8920454545454546,Figure 16: PAS and PAFS in different path lengths on FHMM N=1000
MIN,0.8934659090909091,"it is sampling with hard no replacement. Speciﬁcally, NB ﬁrst calculate the probability for indices
based on ∇f(σ0) as GWG. Then, once selecting an index i at σl, NB manipulates the probability for
selecting index i in the remaining path. For each sampler with path length L = 1, ..., 20, we run 100
chains and report the MMD (Gretton et al., 2012) w.r.t. a set of “ground truth” samples generated
by structure known Block-Gibbs sampler. We can see that, when increasing the path length, PAFS
has steady fast mixing, GWG decreases the efﬁciency in mixing, and NB fails in mixing. For this
reason, we only compare the statistics for GWG and PAFS in our main text in ﬁgure 6."
MIN,0.8948863636363636,"B.4
RUNNING TIME IN LEARNING ISING"
MIN,0.8963068181818182,"We follow the experiments in Grathwohl et al. (2021). GWG runs faster 1.4x than our PAFS-5 as
the energy function computation is cheap in this experiment. To obtain a fair comparison, we add
GWG-equivalent-length (GWG-eq), which we allow GWG-1 to run 1.4x more sampling steps such
that its running time is the same as our PAFS. When our PAFS runs 5, 10, 25, 50 steps, GWG-eq
runs 6, 13 34, 69 steps. Hence, when we draw ﬁgure 8, the point for GWG-eq at step 5, 10, 25, 50
using the RMSE obtained at setp 6, 13, 34, 69."
MIN,0.8977272727272727,"B.5
DETAILS IN LEARNING DEEP EBMS"
MIN,0.8991477272727273,"DataSet
Static MNIST
Omniglot
Caltech
PAFS-3
0.685
0.885
0.893
PAFS-5
0.746
0.980
0.962
PAFS-7
0.775
1.030
1.010
GWG
0.877
1.130
1.140"
MIN,0.9005681818181818,Table 2: Run Time for One Batch for different discrete models.
MIN,0.9019886363636364,"0
500
1000
1500
2000
2500
3000
MCMC Steps 10000 7500 5000 2500 0 2500 5000 7500 10000"
MIN,0.9034090909090909,BurnIn in terms of MCMC steps
MIN,0.9048295454545454,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.90625,"0
500
1000
1500
2000
2500
3000
MCMC Samplers 103 104"
MIN,0.9076704545454546,Reconstruction Error in terms of MCMC steps
MIN,0.9090909090909091,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.9105113636363636,"0
1000
2000
3000
4000
5000
6000
Energy Evaluations 10000 7500 5000 2500 0 2500 5000 7500 10000"
MIN,0.9119318181818182,BurnIn in terms of Energy Evaluations
MIN,0.9133522727272727,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.9147727272727273,"0
1000
2000
3000
4000
5000
6000
MCMC Samplers 103 104"
MIN,0.9161931818181818,Reconstruction Error in terms of Energy Evaluations
MIN,0.9176136363636364,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.9190340909090909,Figure 17: PAS and PAFS in different path lengths on FHMM N=1500
MIN,0.9204545454545454,Published as a conference paper at ICLR 2022
MIN,0.921875,"0
500
1000
1500
2000
2500
3000
3500
4000
MCMC Steps 10000 5000 0 5000 10000"
MIN,0.9232954545454546,BurnIn in terms of MCMC steps
MIN,0.9247159090909091,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.9261363636363636,"0
500
1000
1500
2000
2500
3000
3500
4000
MCMC Samplers 103 104"
MIN,0.9275568181818182,Reconstruction Error in terms of MCMC steps
MIN,0.9289772727272727,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.9303977272727273,"0
1000
2000
3000
4000
5000
6000
7000
8000
Energy Evaluations 10000 5000 0 5000 10000"
MIN,0.9318181818181818,BurnIn in terms of Energy Evaluations
MIN,0.9332386363636364,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.9346590909090909,"0
1000
2000
3000
4000
5000
6000
7000
8000
MCMC Samplers 103 104"
MIN,0.9360795454545454,Reconstruction Error in terms of Energy Evaluations
MIN,0.9375,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.9389204545454546,Figure 18: PAS and PAFS in different path lengths on FHMM N=2000
MIN,0.9403409090909091,"0
2
4
6
8 102"
MIN,0.9417613636363636,ESS in terms of MCMC steps on L=500
MIN,0.9431818181818182,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.9446022727272727,"0
2
4
6
8
101"
MIN,0.9460227272727273,ESS in terms of MCMC steps on L=1000
MIN,0.9474431818181818,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.9488636363636364,"0
2
4
6
8 101"
MIN,0.9502840909090909,2 × 101
MIN,0.9517045454545454,3 × 101
MIN,0.953125,4 × 101
MIN,0.9545454545454546,6 × 101
MIN,0.9559659090909091,ESS in terms of MCMC steps on L=1500
MIN,0.9573863636363636,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.9588068181818182,"0
2
4
6
8 101"
MIN,0.9602272727272727,2 × 101
MIN,0.9616477272727273,3 × 101
MIN,0.9630681818181818,4 × 101
MIN,0.9644886363636364,ESS in terms of MCMC steps on L=2000
MIN,0.9659090909090909,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.9673295454545454,"0
2
4
6
8 101"
MIN,0.96875,6 × 100
MIN,0.9701704545454546,2 × 101
MIN,0.9715909090909091,3 × 101
MIN,0.9730113636363636,"4 × 101
ESS in terms of Energy Evaluations on L=500"
MIN,0.9744318181818182,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.9758522727272727,"0
2
4
6
8 101"
MIN,0.9772727272727273,ESS in terms of Energy Evaluations on L=1000
MIN,0.9786931818181818,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.9801136363636364,"0
2
4
6
8 101"
MIN,0.9815340909090909,3 × 100
MIN,0.9829545454545454,4 × 100
MIN,0.984375,6 × 100
MIN,0.9857954545454546,2 × 101
MIN,0.9872159090909091,ESS in terms of Energy Evaluations on L=1500
MIN,0.9886363636363636,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.9900568181818182,"0
2
4
6
8 101"
MIN,0.9914772727272727,ESS in terms of Energy Evaluations on L=2000
MIN,0.9928977272727273,"pas-1
pafs-1
pas-2
pafs-2
pas-3
pafs-3
pas-5
pafs-5
pas-10
pafs-10"
MIN,0.9943181818181818,Figure 19: ESS for PAS and PAFS in different path lengths on FHMM
MIN,0.9957386363636364,"We use the same setting as Grathwohl et al. (2021), including the batch size, number of iterations,
the PCD hyper parameters, etc. In principle, both PAFS and GWG requires two energy function
evaluations per MCMC step, despite that PAFS explores much larger neighborhood space via path
auxiliary. As the energy function evaluation and gradient calculation usually dominates the compu-
tation, we expect these two should have similar runtime."
MIN,0.9971590909090909,"In practice, we report the average running time per batch of 100 chains in table 2. We can see for
deep EBMs, our PAFS with different path lengths run slightly faster than GWG. Given that both of
the methods implemented using pytorch, the minor speed up might be due to the implementation
issue. So overall we think it is fair to say the two methods run equally fast in most cases. For
this reason, we use the same number of steps when we train the deep EBMs. As is reported in
Grathwohl et al. (2021), we the same number of steps (40) to train the binary deep EBMs. For
our method, we also tune the expected path length in {3, 5, 7}, and report the result with the best
validation likelihood."
MIN,0.9985795454545454,"Figure 20: GWG Burn In
Figure 21: PAFS Burn In
Figure 22: NB Burn In"
