Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0028011204481792717,"Recent works have shown that the adversarial examples can improve the perfor-
mance of representation learning tasks. In this paper, we boost the performance
of deep metric learning (DML) models with adversarial examples generated by
attacking two new objective functions: intra-class alignment and hyperspherical
uniformity. These two new objectives are motivated by our theoretical and em-
pirical analysis of the tuple-based metric losses on the hyperspherical embedding
space. Our analytical results reveal that a) the metric losses on positive sam-
ple pairs are related to intra-class alignment; b) the metric losses on negative
sample pairs serve as uniformity regularization on hypersphere. Based on our
new understanding on the DML models, we propose Adversarial Deep Metric
Learning model with adversarial samples generated by Alignment or Uniformity
objective (ADML+A or U). With the same network structure and training set-
tings, our ADML+A and ADML+U consistently outperform the state-of-the-art
vanilla DML models and the baseline model, adversarial DML model with attack-
ing triplet objective function, on four metric learning benchmark datasets."
INTRODUCTION,0.0056022408963585435,"1
INTRODUCTION"
INTRODUCTION,0.008403361344537815,"Deep metric learning (DML) has been applied to various computer vision tasks ranging from face
recognition (Schroff et al., 2015; Liu et al., 2017) to zero-shot learning (Romera-Paredes & Torr,
2015; Bucher et al., 2016) and image retrieval (Song et al., 2016; Wu et al., 2017). It has been
proved to be one of the most effective methods for learning the distance-preserving features of
images. The intuition of DML is to pull the embedding of positive images pairs together and push
the negative pairs apart, where the embedding function could be a deep neural network. Most of the
metric losses in DML are tuple-based (Schroff et al., 2015; Song et al., 2016; Wu et al., 2017; Wang
et al., 2019) or classification-based (Movshovitz-Attias et al., 2017; Kim et al., 2020; Boudiaf et al.,
2020), these different losses have been shown to achieve similar performance in the recent reviews
of DML (Roth et al., 2020; Musgrave et al., 2020)."
INTRODUCTION,0.011204481792717087,"One common ground of existing DML models is that the embedding space is a unit hypersphere. It
is widely known that achieving uniformity on hypersphere can increase the generalization of models
and preserve as much information as possible (Bachman et al., 2019; Liu et al., 2018; 2021; Hjelm
et al., 2018), and the objective function that lead to uniformity is called uniformity regularization.
Meanwhile, the downstream tasks in DML favor the models with small intra-class alignment (Wu
et al., 2017; Wang et al., 2019). In this work, we investigate these two properties, intra-class align-
ment and hyperspherical uniformity (Wang & Isola, 2020) for tuple-based metric losses. We derive
the theoretical analysis for the triplet loss to prove that the triplet loss on the positive sample pairs
minimizes the intra-class alignment by mapping all samples from one class to the same vector, while
the triplet loss on the negative sample pairs achieves hyperspherical uniformity. We further conduct
empirical studies to show that the same statement is also valid for other tuple-based metric losses."
INTRODUCTION,0.014005602240896359,"We utilize our new understanding on DML to design novel robust DML methods to enhance the
performance via improved adversarial training. Adversarial training aims at improving the robust-
ness of models towards to certain types of attacks by training with perturbed samples. However,
as shown in the recent work on contrastive representation learning (Jiang et al., 2020), adversarial
training can also enhance the natural performance on the downstream classification task. Due to"
INTRODUCTION,0.01680672268907563,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.0196078431372549,"the similarity between contrastive learning and deep metric learning, we believe it’s also possible
to improve the nature performance of metric learning models with adversarial samples. Following
our new insights on positive and negative metric losses, we generate perturbations by attacking the
alignment or uniformity objective, and create adversarial DML models augmented with both nor-
mal samples and perturbed samples. Our experimental results show that the new adversarial DML
models can significantly boost the natural performance."
INTRODUCTION,0.022408963585434174,The major contributions of our paper can be summarized as follows:
INTRODUCTION,0.025210084033613446,"• We analyze the intra-class alignment and hyperspherical uniformity for tuple-based metric
losses, and establish the connections between these two properties and the positive/negative
metric losses.
• Based on our new analysis and understanding, we propose two new adversarial DML models,
ADML+A and ADML+U, via attacking the alignment or uniformity objective. ADML+A and
ADML+U improve the natural performance on benchmarks significantly."
RELATED WORKS,0.028011204481792718,"2
RELATED WORKS"
RELATED WORKS,0.03081232492997199,"Deep metric learning. There are mainly two kind of metric losses in DML, tuple-based and classi-
fication based losses. Tuple-based losses include contrastive loss (Hadsell et al., 2006), triplet loss
(Schroff et al., 2015), margin loss (Wu et al., 2017), and multi-similarity loss (Wang et al., 2019),
where the objective function is based on the distance between positive pairs and negative pairs. In
classification-based losses, the learning objective is not depend on the positive or negative pairs but
a fixed (Boudiaf et al., 2020) or learnable proxy (Kim et al., 2020). In the recent reviews of metric
learning methods (Roth et al., 2020; Musgrave et al., 2020), it’s concluded the improvement on the
DML performance is mainly due to different training strategies and unfair comparison. The original
contrastive loss and triplet loss still achieved comparable result with other metric losses under the
same network and training strategies. In experiments we apply the training framework of (Roth
et al., 2020) to ensure fair comparison."
RELATED WORKS,0.03361344537815126,"Learning with hyperspherical uniformity. Hyperspherical learning regards learning tasks where
the embedding space is a unit hypersphere. The uniformity of the hypersphere represents the diver-
sity of vectors on the sphere. It encourages vectors to be spaced with angles as large as possible so
that these vectors can be evenly distributed on the hypersphere (Liu et al., 2018). Achieving hyper-
spherical uniformity can help with preventing overfitting and improving generalization of the neural
works (Liu et al., 2021). The objective functions which can lead to the uniformity on hypersphere
are called uniformity regularization. Hyperspherical embedding is widely applied in representation
learning tasks such as contrastive representation learning (Oord et al., 2018; Hjelm et al., 2018) and
DML (Wu et al., 2017; Liu et al., 2017). Wang & Isola (2020) showed that the objective function in
contrastive representation learning optimizes for intra-class alignment and uniformity together."
RELATED WORKS,0.036414565826330535,"Adversarial examples improves natural performance. In classification tasks, it is well known that
the clean accuracy of adversarially trained model is typically worse than the normal model. How-
ever, Xie et al. (2020) showed that adversarial samples can be used to improve the clean accuracy of
image classification models. According to (Jiang et al., 2020), training with adversarial samples can
help improve the natural performance of contrastive learning models on the downstream classifica-
tion tasks. The authors presented adversarial attacks based on the objective of contrastive learning
and achieved improvement on both natural and robustness performance. It’s believed that adversar-
ial examples contain extra features, thus the generalization of models augmented with adversarial
example is increased (Ilyas et al., 2019; Salman et al., 2020; Xie et al., 2020), which contributes to
better natural performance. Duan et al. (2018) utilized the triplet loss as the attacking objective to
generate adversarial examples to improve DML models. To our best knowledge, this is the only one
work using adversarial example to boost the natural performance of DML. In our work, we show
that alignment and uniformity loss can generate stronger adversarial examples comparing to triplet
loss, and thus lead to better generalization of DML models."
"ALIGNMENT AND HYPERSPHERICAL UNIFORMITY IN TUPLE-BASED
METRIC LOSSES",0.0392156862745098,"3
ALIGNMENT AND HYPERSPHERICAL UNIFORMITY IN TUPLE-BASED
METRIC LOSSES"
"ALIGNMENT AND HYPERSPHERICAL UNIFORMITY IN TUPLE-BASED
METRIC LOSSES",0.04201680672268908,"In this section, we will study tuple-based metric losses on the unit hypersphere embedding space.
We assume having n classes X1, · · · , Xn in training set and denote the encoder by f : Rd →Sk−1"
"ALIGNMENT AND HYPERSPHERICAL UNIFORMITY IN TUPLE-BASED
METRIC LOSSES",0.04481792717086835,Under review as a conference paper at ICLR 2022
"ALIGNMENT AND HYPERSPHERICAL UNIFORMITY IN TUPLE-BASED
METRIC LOSSES",0.047619047619047616,"where Sk−1 is the surface of a k-dimensional unit ball. Let pdata(·) be the data distribution over
Rd, ppos(·, ·) be the distribution of positive pairs over Rd × Rd, and ptri(·, ·, ·) be the distribution of
triplet pairs over Rd × Rd × Rd, where the first two entries have the same label and the third entry
is a sample from different classes. Please note that all detailed proofs are included in supplementary
material Appendix E. We also conduct experiments to validate our theoretical analysis, the details
is in Appendix C."
"ALIGNMENT AND HYPERSPHERICAL UNIFORMITY IN TUPLE-BASED
METRIC LOSSES",0.05042016806722689,"The major intuition of DML is to pull the representations of similar samples together and push
dissimilar samples apart. Thus, we reformulate the metric losses as the combination of two parts:"
"ALIGNMENT AND HYPERSPHERICAL UNIFORMITY IN TUPLE-BASED
METRIC LOSSES",0.05322128851540616,"• Positive metric loss: minimizes the distance between embedded positive sample pairs.
• Negative metric loss: maximizes the distance between embedded negative sample pairs."
"ALIGNMENT AND HYPERSPHERICAL UNIFORMITY IN TUPLE-BASED
METRIC LOSSES",0.056022408963585436,"Although in DML models the positive metric losses have different representations, they share one
common optimal solution pattern, where samples from the same class are mapped to the same feature
vector. Thus, we define the alignment loss with minimizing the intra-class distance.
Definition 1. (Intra-class alignment) The expectation of intra-class distance is given by:"
"ALIGNMENT AND HYPERSPHERICAL UNIFORMITY IN TUPLE-BASED
METRIC LOSSES",0.058823529411764705,"Lalignment(f; X, ppos) := E(x,y)∼ppos

||f(x) −f(y)||2
2

(1)"
"ALIGNMENT AND HYPERSPHERICAL UNIFORMITY IN TUPLE-BASED
METRIC LOSSES",0.06162464985994398,"the minimum of this loss is achieved when the samples with the same label are encoded to the same
embedding.
Proposition 1. If the support set of the data distribution is connected and the support set of each
class distribution is closed, the minimum of Lalignment is reached when all samples are projected
to the same vector."
"ALIGNMENT AND HYPERSPHERICAL UNIFORMITY IN TUPLE-BASED
METRIC LOSSES",0.06442577030812324,"In Sec. C.1, we conduct the empirical studies to verify our analysis. Results in Table 8 show that
samples are roughly projected to the same vector if only the positive metric losses are used."
"ALIGNMENT AND HYPERSPHERICAL UNIFORMITY IN TUPLE-BASED
METRIC LOSSES",0.06722689075630252,"The negative metric losses aim at positioning the embedding of dissimilar samples as far as possible.
However, because the embedding space of DML is a unit hypersphere, where the maximum distance
between two points is 2, it’s not possible to separate all negative embeddings with a large margin.
Actually on Sk−1, the number of points with pairwise distance larger or equal than
√"
IS AT MOST,0.0700280112044818,"2 is at most
2k and the embedding dimension k is always much smaller than the number of feature vectors, thus
it’s impossible to make all distances between negative pairs exceed
√"
THEREFORE INVESTIGATING THE,0.07282913165266107,"2. Therefore investigating the
properties of negative metric losses on the unit hypersphere is an interesting and important topic.
We believe the negative metric losses are closely related to the uniformity on the hypersphere and
our experimental results support this argument.
Definition 2. (Hyperspherical uniformity) The embedded samples should be evenly distributed on
the spherical surface."
THEREFORE INVESTIGATING THE,0.07563025210084033,"In practice, the hyperspherical uniformity can be achieved by optimizing the uniformity regulariza-
tion. There exist many different representations of the regularization, and we utilize the hyperspher-
ical energy (HE) (Liu et al., 2018):"
THEREFORE INVESTIGATING THE,0.0784313725490196,"E(s, X) ="
THEREFORE INVESTIGATING THE,0.08123249299719888,"(
Ex∼pdata,y∼pdata[||f(x) −f(y)||−s
2 1x̸=y], s > 0"
THEREFORE INVESTIGATING THE,0.08403361344537816,"Ex∼pdata,y∼pdata[log(||f(x) −f(y)||−1
2 1x̸=y)], s = 0
(2)"
THEREFORE INVESTIGATING THE,0.08683473389355742,"and Gaussian hyperspherical energy (G-HE) (Wang & Isola, 2020):"
THEREFORE INVESTIGATING THE,0.0896358543417367,"EG(s, X) = log Ex∼pdata,y∼pdata[e−s||f(x)−f(y)||2
2], s > 0
(3)"
THEREFORE INVESTIGATING THE,0.09243697478991597,"in the experiments for comparison. The values of HE and G-HE can also be used as measurements
on the uniformity of the embedded samples. We expect the value to be small in order to achieve good
hyperspherical uniformity. We also want to mention that simply maximizing the distance between
samples will not lead to hyperspherical uniformity, and the detailed discussion is in Sec. B.2."
THEREFORE INVESTIGATING THE,0.09523809523809523,"Because finding the optimal solution of the HE or G-HE problem is NP-hard (Liu et al., 2018), we
are not able to calculate the exact position of vectors which are evenly distributed on the sphere. We
provide a primary insight about how should finite vectors be uniformly distributed on unit hyper-
sphere, and our conclusion is consist with the empirical results."
THEREFORE INVESTIGATING THE,0.09803921568627451,Under review as a conference paper at ICLR 2022
THEREFORE INVESTIGATING THE,0.10084033613445378,"Since there exist many different tuple-based metric losses, analyzing all of them theoretically is
impossible in this work. In Sec. 3.1, we will provide the theoretical analysis of the triplet loss. The
analysis of linear loss can be found in Sec. B.2. In Appendix C we will show the empirical results
on four popularly used tuple-based metric losses to verify our statement."
TRIPLET METRIC LOSSES,0.10364145658263306,"3.1
TRIPLET METRIC LOSSES"
TRIPLET METRIC LOSSES,0.10644257703081232,"In this subsection, we provide our theoretical analysis on the triplet metric losses with the following
assumptions."
TRIPLET METRIC LOSSES,0.1092436974789916,"Assumption. Distributions pdata, ppos, ptri should satisfy:"
TRIPLET METRIC LOSSES,0.11204481792717087,"• Random positive sampling: ∀x, y, ppos(x, y) = pdata(x)pdata(y|Xx), where pdata(·|Xx) is the
conditional pdf of pdata on the set of samples Xx similar to x i.e. pdata(·|Xx) =
pdata(·)
pdata(Xx)."
TRIPLET METRIC LOSSES,0.11484593837535013,"• Random negative sampling:
ptri(x, y, x−) = ppos(x, y)p−
data(x−), where p−
data(x−) =
pdata(x−)
R"
TRIPLET METRIC LOSSES,0.11764705882352941,x−pdata(x−)dx−
TRIPLET METRIC LOSSES,0.12044817927170869,• Class-balanced learning: pdata(Xi) = 1
TRIPLET METRIC LOSSES,0.12324929971988796,"n, then
R"
TRIPLET METRIC LOSSES,0.12605042016806722,x−pdata(x−)dx−= n−1 n
TRIPLET METRIC LOSSES,0.12885154061624648,"where x−is a negative sample w.r.t. x and n is the number of classes.
Definition 3. (Triplet loss)"
TRIPLET METRIC LOSSES,0.13165266106442577,"Ltriplet(f, τ) := E(x,y,x−)∼ptri

(||f(x) −f(y)||2
2 −||f(x) −f(x−)||2
2 + τ)+

(4)"
TRIPLET METRIC LOSSES,0.13445378151260504,"Triplet loss can be rewritten into the form of naive linear loss with a different distribution of triplets.
We consider a new distribution:"
TRIPLET METRIC LOSSES,0.13725490196078433,"p′
tri =
0,
when ||f(x) −f(y)||2
2 −||f(x) −f(x−)||2
2 + τ < 0,
Cptri,
else,"
TRIPLET METRIC LOSSES,0.1400560224089636,"where C = 1/E(x,y,x−)∼ptri[1{||f(x)−f(y)||2
2−||f(x)−f(x−)||2
2+τ≥0}], then"
TRIPLET METRIC LOSSES,0.14285714285714285,"Ltriplet(f, τ) = Llinear(f; X, p′
tri) = E(x,y,x−)∼p′
tri[||f(x) −f(y)||2
2 −||f(x) −f(x−)||2
2]."
TRIPLET METRIC LOSSES,0.14565826330532214,"Apparently the positive part of the triplet loss is minimizing the intra-class distance under a new
distribution p′
tri, which has similar effect as the alignment loss with ptri shown in the experiments
(Table 8). Now we focus on the negative part of the triplet loss.
Theorem 1. Denote the probability density function (pdf) of d2(x, y) := ||f(x) −f(y)||2
2 w.r.t.
y ∼pdata(·|Xx) by q(d2(x, y)). Then the pdf of u = ||f(x) −f(y)||2
2 −||f(x) −f(x′)||2
2 + τ with
fixed x, x′ is q(u −τ + d2(x, x′)), let S(x, x′) =
R ∞
0
q(u −τ + d2(x, x′))du ∈[0, 1], then"
TRIPLET METRIC LOSSES,0.1484593837535014,"−E(x,y,x−)∼p′
tri[||f(x) −f(x−)||2
2] = −
n
n −1Ex∼pdata,x′∼pdata[||f(x) −f(x′)||2
2S(x, x′)]"
TRIPLET METRIC LOSSES,0.15126050420168066,"+
1
n −1E(x,x′)∼ppos[||f(x) −f(x′)||2
2S(x, x′)]"
TRIPLET METRIC LOSSES,0.15406162464985995,"The negative triplet loss consists of two parts, where the first part dominants the second part be-
cause n is always large in practice. The first part is actually a weighted unbiased regularization with
weight S(x, x′). We think S(x, x′) may help the unbiased regularization to achieve hyperspher-
ical uniformity. Because the closed form of q(d2(x, y)) is intractable, it’s impossible to analyze
S(x, x′) theoretically without any assumptions. We assume q(d2(x, y)) is exponentially distributed
and show the gradient flow of negative triplet loss is asymptotically equal to the gradient of Gaus-
sian hyperspherical energy. Therefore in this case the negative triplet loss can lead to hyperspherical
uniformity."
TRIPLET METRIC LOSSES,0.1568627450980392,"Proposition 2. Assume q(d2(x, y)) =
1
Ae−Ad2(x,y), S(x, x′) =
1
Ae−A(d2(x,x−)−τ) and for the
network parameter θ, we have"
TRIPLET METRIC LOSSES,0.15966386554621848,"−∇θE(x,y,x−)∼p′
tri[||f(x) −f(x−)||2
2] =
eAτn
A2(n −1)∇θEG(A, X) + O( 1 n)"
TRIPLET METRIC LOSSES,0.16246498599439776,the negative triplet loss has asymptotically the same gradient as Gaussian hyperspherical energy.
TRIPLET METRIC LOSSES,0.16526610644257703,Under review as a conference paper at ICLR 2022
TRIPLET METRIC LOSSES,0.16806722689075632,"Despite the theoretical analysis, we also empirically show that the negative triplet loss achieves
hyperspherical uniformity without any assumption on S(x, x′). Besides, the negative part of other
metric losses are also shown to achieve hyperspherical uniformity in our empirical study. The details
is shown in Appendix C."
TRIPLET METRIC LOSSES,0.17086834733893558,"In summary, the tuple-based metric losses on the unit hypersphere are closely related to intra-class
alignment and hyperspherical uniformity. The positive metric losses target at minimizing the intra-
class alignment and the negative metric losses try to keep all samples distributed uniformly on the
hypersphere."
TRIPLET METRIC LOSSES,0.17366946778711484,"Connection to adversarial examples and adversarial training. The goal of adversarial examples
is to fool the neural network by reducing the model performance. Attacking alignment loss, which
positions the embedding of similar samples apart, or attacking the uniformity loss, which pulls
dissimilar samples together, can definitely destroy the representation learned by DML models. Thus
alignment and uniformity loss are suitable objectives for generating adversarial examples."
"DESIGNING NEW ADVERSARIAL DML MODELS BASED ON BETTER
UNDERSTANDING OF DML LOSS",0.17647058823529413,"4
DESIGNING NEW ADVERSARIAL DML MODELS BASED ON BETTER
UNDERSTANDING OF DML LOSS"
"DESIGNING NEW ADVERSARIAL DML MODELS BASED ON BETTER
UNDERSTANDING OF DML LOSS",0.1792717086834734,"In this section, we introduce our new adversarial DML models: adversarial DML with alignment or
uniformity objective (ADML+A or ADML+U). Before we introduce the details of our models, we
share our motivation for designing ADML+A/U models by answering the following questions:"
"DESIGNING NEW ADVERSARIAL DML MODELS BASED ON BETTER
UNDERSTANDING OF DML LOSS",0.18207282913165265,"How can adversarial training helps improve DML models? One of the most reasonable explana-
tions is that training with adversarial examples brings additional features to neural networks. For
example, compared with clean images, adversarial examples make network representations more
consistent with salient data features and human perception (Tsipras et al., 2018). Another possible
reason is that adversarial examples can be regarded as a data augmentation method, which prevents
overfitting of the neural networks. Augmentation techniques which are similar to adversarial train-
ing, e.g. using masking out (DeVries & Taylor, 2017) or adding Gaussian noise (Lopes et al., 2019)
to regions in images, can help to achieve better performance on image recognizing tasks."
"DESIGNING NEW ADVERSARIAL DML MODELS BASED ON BETTER
UNDERSTANDING OF DML LOSS",0.18487394957983194,"Why do we need new objectives for adversarial DML models? Based on our analysis in Sec. 3,
the DML embedding of each image is depend on all other positive and negative samples from per-
spective of alignment and uniformity objective. Therefore if we want to generate the adversarial
sample x′ for one image x, we need to push the adversarial sample away from the similar samples
of x (maximize the alignment loss w.r.t. x′), or pull the adversarial sample close to the dissimilar
samples of x (maximize the uniformity loss w.r.t. x′). Currently, the existing adversarial DML
models (Duan et al., 2018; Panum et al., 2021) generate adversarial samples by attacking the triplet
loss (Definition 3). In this case, only one positive and one negative samples are used to generat-
ing adversarial sample x′, which is obviously less powerful than the alignment/uniformity objective
(which utilizes more positive or negative samples). Our experimental results in Table 1 also show
the adversarial examples generated by alignment/uniformity objectives is more powerful than the
triplet objective. Thus it is critical to design new objectives for attacking DML models, which can
take advantage of the representation information from more data samples."
"DESIGNING NEW ADVERSARIAL DML MODELS BASED ON BETTER
UNDERSTANDING OF DML LOSS",0.1876750700280112,"Adversarial training. We first recall the standard tuple-based DML training setting. Denote the
metric loss function by L(·; θ), where θ is the model parameters, our learning objective is:"
"DESIGNING NEW ADVERSARIAL DML MODELS BASED ON BETTER
UNDERSTANDING OF DML LOSS",0.19047619047619047,"min
θ
E(x,x+,x−)∼p[L((x, x+, x−); θ)]"
"DESIGNING NEW ADVERSARIAL DML MODELS BASED ON BETTER
UNDERSTANDING OF DML LOSS",0.19327731092436976,"In the regular adversarial training framework (Madry et al., 2017), we train networks with perturbed
samples from distribution p(adv)"
"DESIGNING NEW ADVERSARIAL DML MODELS BASED ON BETTER
UNDERSTANDING OF DML LOSS",0.19607843137254902,"min
θ
E(x,x+,x−)∼p(adv)[L((x, x+, x−); θ)"
"DESIGNING NEW ADVERSARIAL DML MODELS BASED ON BETTER
UNDERSTANDING OF DML LOSS",0.19887955182072828,"As our goal is to improve the DML performance on clean images by leveraging the regularization
power of adversarial examples, we treat adversarial images as additional data augmentations and
train networks with a mixture of adversarial examples and clean images. Our learning objective is"
"DESIGNING NEW ADVERSARIAL DML MODELS BASED ON BETTER
UNDERSTANDING OF DML LOSS",0.20168067226890757,"min
θ (E(x,x+,x−)∼p[L((x, x+, x−); θ)] + λE(x,x+,x−)∼p(adv)[L((x, x+, x−); θ)])
(5)"
"DESIGNING NEW ADVERSARIAL DML MODELS BASED ON BETTER
UNDERSTANDING OF DML LOSS",0.20448179271708683,where λ is the strength of the adversarial training.
"DESIGNING NEW ADVERSARIAL DML MODELS BASED ON BETTER
UNDERSTANDING OF DML LOSS",0.20728291316526612,Under review as a conference paper at ICLR 2022
"DESIGNING NEW ADVERSARIAL DML MODELS BASED ON BETTER
UNDERSTANDING OF DML LOSS",0.21008403361344538,"Table 1: Performance of DML model evaluated on adversarial samples generated by different objec-
tives. The threatened model is a pretrained Triplet-D model. Adversarial samples are generated from
triplet, alignment or uniformity loss. Lower score indicates better quality of adversarial samples."
"DESIGNING NEW ADVERSARIAL DML MODELS BASED ON BETTER
UNDERSTANDING OF DML LOSS",0.21288515406162464,"CUB200-2011
CARS196
Online-products
Attack objective
R@1
NMI
mAP@C
R@1
NMI
mAP@C
R@1
NMI
mAP@C
No attack
62.40
67.21
23.56
77.59
66.64
23.83
77.53
89.98
41.12
Triplet
28.33
44.48
6.61
22.42
34.30
3.47
53.77
83.43
25.21
Alignment
8.71
23.42
0.46
10.99
17.11
0.55
8.82
80.05
1.49
Uniformity
13.47
32.87
3.54
14.30
24.07
2.05
4.68
79.90
0.51"
"DESIGNING NEW ADVERSARIAL DML MODELS BASED ON BETTER
UNDERSTANDING OF DML LOSS",0.21568627450980393,"Generate adversarial samples. We use l∞PGD-FSGM (Madry et al., 2017) method for generating
adversarial samples. We consider DML models require class-balanced batches for training, and
propose to generate perturbations by maximizing the intra-batch alignment or uniformity. Given
a batch S and a sample x, the l∞FSGM adversarial sample of x generated by maximizing the
alignment objective is given by,"
"DESIGNING NEW ADVERSARIAL DML MODELS BASED ON BETTER
UNDERSTANDING OF DML LOSS",0.2184873949579832,"ADV(x) : = ΠB∞(x,ϵ)(x + α∇xLalignment(f; S))
(6)"
"DESIGNING NEW ADVERSARIAL DML MODELS BASED ON BETTER
UNDERSTANDING OF DML LOSS",0.22128851540616246,"where ΠB∞(x,ϵ) is the projecting function on the l∞ball centering at x with radius ϵ, and α is
the attack strength. Analogously, the adversarial sample generated by maximizing the uniformity
objective (Eq. 2 and Eq. 3) is"
"DESIGNING NEW ADVERSARIAL DML MODELS BASED ON BETTER
UNDERSTANDING OF DML LOSS",0.22408963585434175,"ADV(x) : = ΠB∞(x,ϵ)(x + α∇xLuniformity(f; S))
(7)"
"DESIGNING NEW ADVERSARIAL DML MODELS BASED ON BETTER
UNDERSTANDING OF DML LOSS",0.226890756302521,"In PGD-FSGM method, we will update the adversarial samples iterative by x(l+1) = ADV (x(l)) for
L steps. The output perturbed samples x(L) will be used in our adversarial training objective Eq. 5.
In ADML-A we use alignment loss (Eq. 1) to generate adversarial samples and in ADML-U we use
Gaussian uniformity loss G-HE (Eq. 3). We include the algorithm of ADML-A and ADML-U in the
appendix (Alg. 1 and Alg. 2). In experiments, we apply multi-similarity losses as the metric loss L
with attacking alignment and uniformity objective, both models achieve significantly better results
on benchmarks (Table 2 and Table 3)."
EXPERIMENTS,0.22969187675070027,"5
EXPERIMENTS"
EXPERIMENTS,0.23249299719887956,"In our experiments, we first conduct the empirical studies to verify the theoretical analysis results in
Sec. 3 (the results are discussed in Appendix C). After that, we show that alignment and uniformity
objectives can help to generate better adversarial examples than the triplet loss, then we compare
the natural and robust performance of our adversarial DML model with the state-of-the-art methods.
The natural performance is the performance of DML models evaluated with clean samples, while
the robust performance is evaluated with adversarial samples."
EXPERIMENTAL SETUP,0.23529411764705882,"5.1
EXPERIMENTAL SETUP"
EXPERIMENTAL SETUP,0.23809523809523808,"Datasets.
We test our model on four DML benchmarks, CUB200-2011 (Wah et al., 2011),
CARS196 (Krause et al., 2013), Online-product (Song et al., 2016), and In-shop (Liu et al., 2016).
We follow the previous work (Song et al., 2016) and (Liu et al., 2016) for the train-test split. The
statistics of these datasets is introduced in Sec. D.2"
EXPERIMENTAL SETUP,0.24089635854341737,"Training Frameworks. In all experiments, we use the DML framework from (Roth et al., 2020) for
training. This framework enables us to train and evaluate DML models under the same settings and
ensure fair comparison of the model performance. The backbone network is ResNet50 (He et al.,
2016) with ImageNet pretrained (Krizhevsky et al., 2012) and frozen Batch-Normalization layers,
the embedding dimension of samples is 128. The initial learning rate is 0.00001 with no scheduling
and the batch size is 112. Experiments are performed on a 24GB Nvidia Tesla P40."
EXPERIMENTAL SETUP,0.24369747899159663,"Baseline models. We compare ADML+A/U with the state-of-the-art DML models. First we select
three of the best DML models according to (Roth et al., 2020): margin loss with distance sampling
(Wu et al., 2017), multisimilarity loss (Wang et al., 2019) and triplet loss with distance sampling.
Besides, we take another two SOTA DML models which were published recently but not included"
EXPERIMENTAL SETUP,0.24649859943977592,Under review as a conference paper at ICLR 2022
EXPERIMENTAL SETUP,0.24929971988795518,"Table 2: Performance of metric learning models on clustering and retrieval tasks averaged over 5
runs on CUB200-2011 and CARS196. Our Adversarial DML models, ADML+A, and ADML+U,
outperform the rest models. The model settings and training parameters are same for all models."
EXPERIMENTAL SETUP,0.25210084033613445,"CUB200-2011
CARS196
Models
R@1
NMI
mAP@C
R@1
NMI
mAP@C
ImageNet pretrain
43.77
57.56
8.99
36.39
37.96
4.93
Linear
38.42
43.28
7.64
32.45
35.12
3.48
Triplet-D
62.31 ± 0.41
67.23 ± 0.34
23.29 ± 0.25
79.08 ± 0.41
66.02 ± 0.33
24.02 ± 0.31
Margin
62.42 ± 0.36
67.11 ± 0.49
23.54 ± 0.21
78.11 ± 0.32
66.87 ± 0.35
23.94 ± 0.27
Multi-Similarity
62.73 ± 0.61
67.45 ± 0.39
22.65 ± 0.34
79.94 ± 0.28
67.59 ± 0.43
24.12 ± 0.25
Proxy-Anchor
64.16 ± 0.48
67.84 ± 0.37
23.91 ± 0.32
80.13 ± 0.33
67.31 ± 0.41
23.86 ± 0.26
Cross-Entropy
61.58 ± 0.31
66.67 ± 0.39
22.25 ± 0.20
78.41 ± 0.39
66.35 ± 0.31
23.63 ± 0.34
Info-NCE
61.79 ± 0.51
66.91 ± 0.42
22.43 ± 0.28
77.52 ± 0.37
66.75 ± 0.57
23.41 ± 0.22
ADML+T
64.37 ± 0.43
68.13 ± 0.49
24.05 ± 0.30
80.88 ± 0.46
66.47 ± 0.51
23.91 ± 0.39
ADML+A
66.02 ± 0.35
68.78 ± 0.37
24.46 ± 0.23
81.95 ± 0.38
67.97 ± 0.49
24.21 ± 0.28
ADML+U
65.46 ± 0.40
68.60 ± 0.33
24.58 ± 0.28
82.06 ± 0.36
68.21 ± 0.35
24.82 ± 0.34
ADML+A+U
64.24 ± 0.38
67.73 ± 0.45
23.88 ± 0.26
80.95 ± 0.41
67.64 ± 0.39
23.85 ± 0.30"
EXPERIMENTAL SETUP,0.2549019607843137,"in Roth et al. (2020)’s work: Proxy-Anchor loss (Kim et al., 2020) and Cross-Entropy loss (Boudiaf
et al., 2020). Next we apply the Info-NCE loss (Wang & Isola, 2020), which is a contrastive learning
objective, as one of the baselines. Finally we compare our models with the only existing adversarial
DML model (Duan et al., 2018), ADML+T (triplet objective), in the experiments."
EXPERIMENTAL SETUP,0.25770308123249297,"Evaluation Metrics. We measure the performance of DML and ADML models with Recall@k
(R@k) (Jegou et al., 2010), Normalized Mutual Information (NMI) (Christopher et al., 2008) and
Mean Average Precision measured on recall (mAP@k) (Musgrave et al., 2020). The details of these
metrics are introduced in Sec. D.3."
COMPARE THE QUALITY OF ADVERSARIAL EXAMPLES WITH DIFFERENT OBJECTIVES,0.2605042016806723,"5.2
COMPARE THE QUALITY OF ADVERSARIAL EXAMPLES WITH DIFFERENT OBJECTIVES"
COMPARE THE QUALITY OF ADVERSARIAL EXAMPLES WITH DIFFERENT OBJECTIVES,0.26330532212885155,"Settings. The threatened model is a pretrained DML model with triplet loss and distance sampling
(Wu et al., 2017), which is one of the most competitive DML models according to Roth et al.
(2020). We consider three different attack objectives, triplet loss (Eq. 4), alignment loss (Eq. 1), and
Gaussian hyperspherical uniformity (Eq. 3), for generating adversarial samples. We use l∞PGD-
FSGM attacks with strength ϵ = 0.0314, L = 7 steps and step size α = 0.007, we keep this settings
for all three attack objectives in our experiments."
COMPARE THE QUALITY OF ADVERSARIAL EXAMPLES WITH DIFFERENT OBJECTIVES,0.2661064425770308,"Results. In Table 1, the adversarial samples generated by alignment or uniformity objectives are
significantly stronger than the samples generated by triplet loss. This indicates that adversarial sam-
ples from alignment or uniformity contain more features that are not captured by the vanilla DML
models. Thus we believe the Adversarial DML model with alignment or uniformity objectives could
be more generalized than the vanilla DML models or ADML with triplet loss. Our experimental re-
sults in Table 2 and Table 3, which show that ADML+A and ADML+U outperform the baseline
models on metric learning tasks, also support our analysis. We also notice that using both A and U
in ADML have similar performance as ADML+T, which suggests we should use the attack objective
(A or U) separately. In Appendix F we also shows the T-SNE plot of the embedding generated by
the vanilla DML and ADML+A, which shows ADML+A can better separate different classes."
ADVERSARIAL DML MODELS IMPROVE NATURAL PERFORMANCE,0.2689075630252101,"5.3
ADVERSARIAL DML MODELS IMPROVE NATURAL PERFORMANCE"
ADVERSARIAL DML MODELS IMPROVE NATURAL PERFORMANCE,0.27170868347338933,"Settings. We train all DML models for 100 epochs. For our adversarial DML models we apply
ADML+A and ADML+U. The adversarial training strength λ in ADML+A/U is 0.1 for CUB200-
2011 and 0.15 for CARS196. For generating adversarial examples we use l∞PGD-FSGM attacks
with strength ϵ = 0.0314, L = 7 steps and step size α = 0.007. For Online-products and In-shop
we use λ = 0.005, ϵ = 0.01, L = 5, and α = 0.003. The ImageNet model is the model only with
ImageNet pretrain."
ADVERSARIAL DML MODELS IMPROVE NATURAL PERFORMANCE,0.27450980392156865,"Results. In Table 2, our ADML+A and ADML+U models outperform the SOTA metric learning
models. ADML+A/U improve the R@1 over 1% on CUB200-2011 and CARS196, and also have
considerable improvement on Online-product and In-shop dataset. Besides, the performance of
ADML+A/U under the NMI and mAP@C metrics is also comparable or better than the SOTA."
ADVERSARIAL DML MODELS IMPROVE NATURAL PERFORMANCE,0.2773109243697479,Under review as a conference paper at ICLR 2022
ADVERSARIAL DML MODELS IMPROVE NATURAL PERFORMANCE,0.2801120448179272,"Table 3: Performance of DML models on clustering and retrieval tasks averaged over 5 runs on
Online-products and In-shop. Our Adversarial DML models, ADML+A, and ADML+U, outperform
the rest models in most cases. The model settings and training parameters are same for all models."
ADVERSARIAL DML MODELS IMPROVE NATURAL PERFORMANCE,0.28291316526610644,"Online-product
In-shop
Models
R@1
NMI
mAP@C
R@1
NMI
mAP@C
ImageNet pretrain
48.51
84.24
17.37
21.62
76.53
4.02
Linear
20.53
81.20
5.78
16.03
75.81
2.47
Triplet-D
77.41 ± 0.19
90.04 ± 0.05
41.05 ± 0.14
87.31 ± 0.18
89.76 ± 0.09
28.45 ± 0.17
Margin
77.66 ± 0.14
89.93 ± 0.06
41.41 ± 0.12
87.56 ± 0.15
89.93 ± 0.07
28.45 ± 0.13
Multi-Similarity
77.75 ± 0.11
90.00 ± 0.04
41.39 ± 0.10
87.33 ± 0.20
89.85 ± 0.12
29.61 ± 0.16
Proxy-Anchor
77.11 ± 0.13
89.90 ± 0.05
40.98 ± 0.15
87.14 ± 0.17
89.41 ± 0.05
28.11 ± 0.11
Cross-Entropy
76.92 ± 0.36
89.82 ± 0.11
41.31 ± 0.42
86.75 ± 0.32
89.71 ± 0.13
28.38 ± 0.51
Info-NCE
76.21 ± 0.15
89.71 ± 0.04
39.42 ± 0.09
86.24 ± 0.14
89.62 ± 0.04
27.94 ± 0.17
ADML+T
77.13 ± 0.11
89.59 ± 0.03
40.75 ± 0.07
87.47 ± 0.12
89.65 ± 0.10
29.05 ± 0.12
ADML+A
78.12 ± 0.16
89.95 ± 0.04
41.56 ± 0.11
87.94 ± 0.15
89.93 ± 0.05
30.12 ± 0.15
ADML+U
78.01 ± 0.12
89.97 ± 0.03
41.21 ± 0.12
87.86 ± 0.18
89.57 ± 0.08
29.93 ± 0.16
ADML+A+U
77.41 ± 0.15
89.88 ± 0.07
40.91 ± 0.14
87.65 ± 0.12
89.71 ± 0.09
29.72 ± 0.13"
ADVERSARIAL DML MODELS IMPROVE NATURAL PERFORMANCE,0.2857142857142857,"(a) CUB-ADML+A
(b) CUB-ADML+U
(c) CARS-ADML+A
(d) CARS-ADML+U"
ADVERSARIAL DML MODELS IMPROVE NATURAL PERFORMANCE,0.28851540616246496,"Figure 1: Performance of ADML+A and ADML+U with different adversarial training strength λ on
CUB200-2011 and CARS196."
ADVERSARIAL DML MODELS IMPROVE NATURAL PERFORMANCE,0.2913165266106443,"Since all the models are training under the same framework and settings, we can conclude that
adversarial training helps to enhance the natuaral performance of DML models."
ROBUSTNESS PERFORMANCE OF ADVERSARIAL DML MODELS,0.29411764705882354,"5.4
ROBUSTNESS PERFORMANCE OF ADVERSARIAL DML MODELS"
ROBUSTNESS PERFORMANCE OF ADVERSARIAL DML MODELS,0.2969187675070028,"We evaluate the robustness performance of our ADML+A and ADML+U models against attacking
the alignment objective, which is the strongest DML attack according to our experiment in Sec. 5.2,
on CUB200-2011 and CARS196 datasets. For baseline models we use margin, multi-similarity, and
ADML+Triplet models. The settings of alignment attack are the same as the settings in Sec. 5.2,
the settings of ADML+A/U and baseline models are the same as the settings in Sec. 5.3. As seen in
Table 4, ADML+T has slightly better performance than the vanilla DML models, while ADML+A
and ADML+U outperform the baseline models with a large margin under the alignment attacks.
Notice ADML+A takes the advantage of adversarial training with alignment loss, it’s reasonable
that the performance ADML+A is slightly better than ADML+U under alignment attacks."
ROBUSTNESS PERFORMANCE OF ADVERSARIAL DML MODELS,0.29971988795518206,"Table 4: Robustness performance of DML models and ADML models against adversarial samples
generated by attacking alignment loss."
ROBUSTNESS PERFORMANCE OF ADVERSARIAL DML MODELS,0.3025210084033613,"CUB200-2011
CARS196
Online-Products
Models
R@1
NMI
mAP@C
R@1
NMI
mAP@C
R@1
NMI
mAP@C
Margin
8.04
24.59
0.58
8.39
17.17
0.56
8.27
80.02
1.34
Multi-similarity
8.90
24.13
0.51
11.95
18.32
0.55
8.93
80.06
1.45
ADML+T
11.58
25.26
0.74
25.35
21.22
1.31
10.69
80.20
1.74
ADML+A
17.37
29.16
1.27
39.97
26.05
2.54
13.98
80.40
2.01
ADML+U
15.10
27.89
1.06
33.09
24.48
2.30
11.32
80.29
1.85"
ROBUSTNESS PERFORMANCE OF ADVERSARIAL DML MODELS,0.30532212885154064,Under review as a conference paper at ICLR 2022
ROBUSTNESS PERFORMANCE OF ADVERSARIAL DML MODELS,0.3081232492997199,"Table 5: Robustness with different adversarial training strength λ on CUB200-2011 under the align-
ment attacks. The metric is Recall@1."
ROBUSTNESS PERFORMANCE OF ADVERSARIAL DML MODELS,0.31092436974789917,"λ
0
0.2
0.4
0.6
0.8
1.0
ADML+A
8.90
19.15
22.51
24.47
25.29
25.93
ADML+U
8.90
16.21
18.36
20.23
21.06
21.55"
ABLATION STUDY,0.3137254901960784,"5.5
ABLATION STUDY"
ABLATION STUDY,0.3165266106442577,"Strength of adversarial training. In this part, we evaluate the effect of adversarial training strength
λ on the performance of ADML+A and ADML+U. The backbone is DML with multi-similarity
loss. We expect the performance will first increase with λ then decrease, because when λ is close to
0, the ADML models can hardly learn adversarial features and the improvement is small, when λ is
large, the adversarial features will dominate the DML models and the performance on clean features
will be poor. The model settings are the same as in Sec. 5.3. The experimental results illustrated
in Fig. 1 are consistent with our analysis, when increasing the adversarial training strength, the
natural performance of ADML+A and ADML+U is first improved then decreased. Table 5 shows
the robustness of ADML+A and ADML+U model with adversarial training strength λ and alignment
attacks. Both models become increasingly robust against alignment attacks."
ABLATION STUDY,0.31932773109243695,"ADML on different metric loss. In this experiment, we apply our ADML approach with triplet,
alignment, uniformity, and alignment+uniformity objectives on different metric losses, including
triplet, margin, multi-similarity, and info-NCE losses. The metric is Recall@1. The model settings
are the same as in Sec. 5.3. From Table 6, we can observe that all ADML methods boost the
performance of all DML losses. ADML+A achieves the most significant improvement across all
attacks and metric losses."
ABLATION STUDY,0.32212885154061627,Table 6: Recall@1 of different metric learning losses with ADML methods on CUB200-2011
ABLATION STUDY,0.32492997198879553,"Vanilla
ADML+T
ADML+A
ADML+U
ADML+A+U
Triplet
62.29
63.68
65.11
64.72
63.17
Margin
62.48
64.26
65.92
65.61
64.32
Multi-similarity
62.71
64.45
66.13
65.58
64.39
Info-NCE
61.42
62.74
64.01
63.85
62.91"
ABLATION STUDY,0.3277310924369748,"A mixture of alignment and uniformity attacks. In this experiment, we study the effect of different
weight of alignment and uniformity objectives in ADML+A+U. The backbone is DML with multi-
similarity loss. The model settings are the same as in Sec. 5.3. Specifically, we assign weight (1−β)
to the alignment objective and β to the uniformity objective. The results are shown in Table 7. When
β increases, the performance of the ADML model first decreases and then increases, which indicates
that attacking alignment and uniformity loss separately can lead to better results."
ABLATION STUDY,0.33053221288515405,"Table 7: Recall@1 of ADML+(1 −β)A+β U on CUB200-2011 with different β.
β
0
0.2
0.4
0.5
0.6
0.8
1
ADML+(1 −β)A+(β) U
66.13
65.81
64.67
64.39
64.55
65.33
65.58"
CONCLUSION,0.3333333333333333,"6
CONCLUSION"
CONCLUSION,0.33613445378151263,"In this work, we investigated two important properties, intra-class alignment and hyperspherical
uniformity, of tuple-based metric losses on unit sphere. According to our theoretical analysis and
experimental results, the positive metric losses contribute to the intra-class alignment and the neg-
ative metric losses achieve hyperspherical uniformity. Based on our new understanding, we design
two novel adversarial DML models, ADML+A and ADML+U, where the perturbations are gen-
erated by maximizing the alignment loss or the uniformity loss. Our ADML+A and ADML+U
improve both of natural and robust DML performance by enhancing model generalization. Poten-
tial future work directions include analyzing other tuple-based metric losses theoretically, designing
new metric losses based on the alignment and uniformity, and exploring the trade-off between nature
and robustness performance in metric learning."
CONCLUSION,0.3389355742296919,Under review as a conference paper at ICLR 2022
ETHICS STATEMENT,0.34173669467787116,ETHICS STATEMENT
ETHICS STATEMENT,0.3445378151260504,"In this paper, we design new adversarial deep metric learning (DML) models for improving the
vanilla DML. Our method can boost the robustness of neural networks again adversarial attacks,
which contributes to the trustworthy AI and machine learning."
ETHICS STATEMENT,0.3473389355742297,REPRODUCIBILITY
ETHICS STATEMENT,0.35014005602240894,"All datasets, baseline models, general training settings are provided in Sec. 5.1. For specific tasks
we also include the detailed settings in the corresponding sections. For example, the detailed model
structure and hyperparameter settings for the natural performance of ADML models are written in
Sec. 5.3. We will release the code if the paper is accepted."
REFERENCES,0.35294117647058826,REFERENCES
REFERENCES,0.3557422969187675,"Philip Bachman, R Devon Hjelm, and William Buchwalter. Learning representations by maximizing
mutual information across views. arXiv preprint arXiv:1906.00910, 2019."
REFERENCES,0.3585434173669468,"Malik Boudiaf, J´erˆome Rony, Imtiaz Masud Ziko, Eric Granger, Marco Pedersoli, Pablo Piantanida,
and Ismail Ben Ayed. A unifying mutual information view of metric learning: cross-entropy vs.
pairwise losses. In European Conference on Computer Vision, pp. 548–564. Springer, 2020."
REFERENCES,0.36134453781512604,"Maxime Bucher, St´ephane Herbin, and Fr´ed´eric Jurie. Improving semantic embedding consistency
by metric learning for zero-shot classiffication. In European Conference on Computer Vision, pp.
730–746. Springer, 2016."
REFERENCES,0.3641456582633053,"D Manning Christopher, Raghavan Prabhakar, Sch¨utze Hinrich, et al. Introduction to information
retrieval. An Introduction To Information Retrieval, 151(177):5, 2008."
REFERENCES,0.36694677871148457,"Terrance DeVries and Graham W Taylor. Improved regularization of convolutional neural networks
with cutout. arXiv preprint arXiv:1708.04552, 2017."
REFERENCES,0.3697478991596639,"Yueqi Duan, Wenzhao Zheng, Xudong Lin, Jiwen Lu, and Jie Zhou. Deep adversarial metric learn-
ing. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp.
2780–2789, 2018."
REFERENCES,0.37254901960784315,"Raia Hadsell, Sumit Chopra, and Yann LeCun. Dimensionality reduction by learning an invariant
mapping. In 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recogni-
tion (CVPR’06), volume 2, pp. 1735–1742. IEEE, 2006."
REFERENCES,0.3753501400560224,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.
770–778, 2016."
REFERENCES,0.37815126050420167,"R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil Bachman, Adam
Trischler, and Yoshua Bengio. Learning deep representations by mutual information estimation
and maximization. arXiv preprint arXiv:1808.06670, 2018."
REFERENCES,0.38095238095238093,"Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon Tran, and Aleksander
Madry. Adversarial examples are not bugs, they are features. arXiv preprint arXiv:1905.02175,
2019."
REFERENCES,0.38375350140056025,"Herve Jegou, Matthijs Douze, and Cordelia Schmid.
Product quantization for nearest neighbor
search. IEEE transactions on pattern analysis and machine intelligence, 33(1):117–128, 2010."
REFERENCES,0.3865546218487395,"Ziyu Jiang, Tianlong Chen, Ting Chen, and Zhangyang Wang. Robust pre-training by adversarial
contrastive learning. arXiv preprint arXiv:2010.13337, 2020."
REFERENCES,0.38935574229691877,"G. A. Kabatjanskii and V. I. Levenstein. Bounds for packings on a sphere and in space. Problemy
Peredachy Informatsii, 1978."
REFERENCES,0.39215686274509803,"Sungyeon Kim, Dongwon Kim, Minsu Cho, and Suha Kwak. Proxy anchor loss for deep metric
learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recogni-
tion, pp. 3238–3247, 2020."
REFERENCES,0.3949579831932773,Under review as a conference paper at ICLR 2022
REFERENCES,0.39775910364145656,"Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei. 3d object representations for fine-grained
categorization.
In 4th International IEEE Workshop on 3D Representation and Recognition
(3dRR-13), Sydney, Australia, 2013."
REFERENCES,0.4005602240896359,"Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep con-
volutional neural networks. Advances in neural information processing systems, 25:1097–1105,
2012."
REFERENCES,0.40336134453781514,"Weiyang Liu, Yandong Wen, Zhiding Yu, Ming Li, Bhiksha Raj, and Le Song. Sphereface: Deep
hypersphere embedding for face recognition. In Proceedings of the IEEE conference on computer
vision and pattern recognition, pp. 212–220, 2017."
REFERENCES,0.4061624649859944,"Weiyang Liu, Rongmei Lin, Zhen Liu, Lixin Liu, Zhiding Yu, Bo Dai, and Le Song. Learning
towards minimum hyperspherical energy. arXiv preprint arXiv:1805.09298, 2018."
REFERENCES,0.40896358543417366,"Weiyang Liu, Rongmei Lin, Zhen Liu, Li Xiong, Bernhard Sch¨olkopf, and Adrian Weller. Learn-
ing with hyperspherical uniformity. In International Conference on Artificial Intelligence and
Statistics, pp. 1180–1188. PMLR, 2021."
REFERENCES,0.4117647058823529,"Ziwei Liu, Ping Luo, Shi Qiu, Xiaogang Wang, and Xiaoou Tang. Deepfashion: Powering robust
clothes recognition and retrieval with rich annotations. In Proceedings of IEEE Conference on
Computer Vision and Pattern Recognition (CVPR), June 2016."
REFERENCES,0.41456582633053224,"Raphael Gontijo Lopes, Dong Yin, Ben Poole, Justin Gilmer, and Ekin D Cubuk.
Improv-
ing robustness without sacrificing accuracy with patch gaussian augmentation. arXiv preprint
arXiv:1906.02611, 2019."
REFERENCES,0.4173669467787115,"Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083,
2017."
REFERENCES,0.42016806722689076,"Yair Movshovitz-Attias, Alexander Toshev, Thomas K Leung, Sergey Ioffe, and Saurabh Singh. No
fuss distance metric learning using proxies. In Proceedings of the IEEE International Conference
on Computer Vision, pp. 360–368, 2017."
REFERENCES,0.42296918767507,"Kevin Musgrave, Serge Belongie, and Ser-Nam Lim. A metric learning reality check. In European
Conference on Computer Vision, pp. 681–699. Springer, 2020."
REFERENCES,0.4257703081232493,"Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predic-
tive coding. arXiv preprint arXiv:1807.03748, 2018."
REFERENCES,0.42857142857142855,"Thomas Kobber Panum, Zi Wang, Pengyu Kan, Earlence Fernandes, and Somesh Jha. Exploring
adversarial robustness of deep metric learning. arXiv preprint arXiv:2102.07265, 2021."
REFERENCES,0.43137254901960786,"Bernardino Romera-Paredes and Philip Torr. An embarrassingly simple approach to zero-shot learn-
ing. In International conference on machine learning, pp. 2152–2161. PMLR, 2015."
REFERENCES,0.4341736694677871,"Karsten Roth, Timo Milbich, Samarth Sinha, Prateek Gupta, Bjorn Ommer, and Joseph Paul Co-
hen. Revisiting training strategies and generalization performance in deep metric learning. In
International Conference on Machine Learning, pp. 8242–8252. PMLR, 2020."
REFERENCES,0.4369747899159664,"Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, and Aleksander Madry. Do adver-
sarially robust imagenet models transfer better? arXiv preprint arXiv:2007.08489, 2020."
REFERENCES,0.43977591036414565,"Florian Schroff, Dmitry Kalenichenko, and James Philbin. Facenet: A unified embedding for face
recognition and clustering. In Proceedings of the IEEE conference on computer vision and pattern
recognition, pp. 815–823, 2015."
REFERENCES,0.4425770308123249,"Hyun Oh Song, Yu Xiang, Stefanie Jegelka, and Silvio Savarese. Deep metric learning via lifted
structured feature embedding. In IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), 2016."
REFERENCES,0.44537815126050423,"Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and Aleksander Madry.
There is no free lunch in adversarial robustness (but there are unexpected benefits). arXiv preprint
arXiv:1805.12152, 2(3), 2018."
REFERENCES,0.4481792717086835,Under review as a conference paper at ICLR 2022
REFERENCES,0.45098039215686275,"C. Wah, S. Branson, P. Welinder, P. Perona, and S. Belongie. The Caltech-UCSD Birds-200-2011
Dataset. Technical report, 2011."
REFERENCES,0.453781512605042,"Tongzhou Wang and Phillip Isola. Understanding contrastive representation learning through align-
ment and uniformity on the hypersphere. In International Conference on Machine Learning, pp.
9929–9939. PMLR, 2020."
REFERENCES,0.4565826330532213,"Xun Wang, Xintong Han, Weilin Huang, Dengke Dong, and Matthew R Scott. Multi-similarity loss
with general pair weighting for deep metric learning. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition, pp. 5022–5030, 2019."
REFERENCES,0.45938375350140054,"Chao-Yuan Wu, R Manmatha, Alexander J Smola, and Philipp Krahenbuhl. Sampling matters in
deep embedding learning. In Proceedings of the IEEE International Conference on Computer
Vision, pp. 2840–2848, 2017."
REFERENCES,0.46218487394957986,"Cihang Xie, Mingxing Tan, Boqing Gong, Jiang Wang, Alan L Yuille, and Quoc V Le. Adversarial
examples improve image recognition. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, pp. 819–828, 2020."
REFERENCES,0.4649859943977591,Under review as a conference paper at ICLR 2022
REFERENCES,0.4677871148459384,"APPENDIX A
CODE"
REFERENCES,0.47058823529411764,"We use the open source DML training framework https://github.com/Confusezius/
Deep-Metric-Learning-Baselines. We include the code of our Alg. 1 and Alg. 2 in the
supplementary material. All datasets used in this paper are available online. We will release the full
code package if our paper is accepted."
REFERENCES,0.4733893557422969,"APPENDIX B
THEORETICAL EXPLANATION OF POSITIVE AND NEGATIVE
METRIC LOSSES"
REFERENCES,0.47619047619047616,"B.1
NUMBER OF NEARLY ORTHOGONAL VECTORS IN HIGH DIMENSIONAL SPHERE."
REFERENCES,0.4789915966386555,"Lemma 1. (Kabatjanskii-Levenstein bound (Kabatjanskii & Levenstein, 1978)) For a hypersphere"
REFERENCES,0.48179271708683474,"Sk−1 ∈Rk, there exist at least kM vectors with pairwise distance in the range of
√"
REFERENCES,0.484593837535014,"2±O(
q"
REFERENCES,0.48739495798319327,"M log k k
)."
REFERENCES,0.49019607843137253,"Lemma 1 shows the number of nearly orthogonal vectors we can take from a high dimensional
sphere. If k = 128 and M = 3, the amount of nearly orthogonal vectors could be more than one
million, which exceeds the volume of benchmark datasets X in DML a lot. Following the former
discussion, we know the pairwise distance cannot be larger than
√"
REFERENCES,0.49299719887955185,"2 for all negative pairs. Therefore
we think the uniformity regularization with DML benchmarks will lead to an embedding space
where the feature vectors are nearly orthogonal. The plots of pairwise distance distribution in Fig. 2
with hyperspherical regularization also support our analysis."
REFERENCES,0.4957983193277311,"B.2
NAIVE LINEAR METRIC LOSSES"
REFERENCES,0.49859943977591037,"With the same Assumption in Sec. 3.1, we can prove that the positive part of the linear loss minimizes
the intra-class distance and the negative part maximizes an unbiased term, which doesn’t achieve
hyperspherical uniformity. The theoretical analysis results are summarized in the following theorem.
Definition 4. (Naive linear loss)"
REFERENCES,0.5014005602240896,"Llinear(f; X, ptri) := E(x,y,x−)∼ptri

||f(x) −f(y)||2
2 −||f(x) −f(x−)||2
2

."
REFERENCES,0.5042016806722689,Definition 5. (Unbiased regularization)
REFERENCES,0.5070028011204482,"Lunbiased(f; X, pdata) := ||Ex∼pdata[f(x)]||2
2 ."
REFERENCES,0.5098039215686274,"the minimum of this loss is reached when the centroid coincide with the origin.
Theorem 2. Naive linear loss consists of alignment loss and unbiased loss with a constant multi-
plier."
REFERENCES,0.5126050420168067,"Positive part: E(x,y,x−)∼ptri

||f(x) −f(y)||2
2

= Lalignment"
REFERENCES,0.5154061624649859,"Negative part: −E(x,y,x−)∼ptri

||f(x) −f(x−)||2
2

=
n
n −1(2Lunbiased −2) +
1
n −1Lalignment"
REFERENCES,0.5182072829131653,"Combining them we have Llinear =
n
n−1(2Lunbiased + Lalignment −2)."
REFERENCES,0.5210084033613446,"Because the number of classes n is always large and the magnitude of Lunbiased −1 and Lalignment
are similar, in negative linear loss the dominant objective is the unbiased regularization. Thus simply
maximizing the distance between negative pairs will lead to the unbiased regularization instead of
hyperspherical uniformity. In Figure 2(e) and Figure 2(c) of the appendix, we can observe the
difference between the models with negative linear loss and uniformity regularization. We also show
the interesting connection between the naive linear loss and linear discriminant analysis (LDA) in
Sec. E.5."
REFERENCES,0.5238095238095238,"Remark. Naive linear loss doesn’t work at all in practice (see the experimental results of Linear
model in Table 2 and Table 3). Based on our analysis, we believe it’s because linear loss doesn’t op-
timize the hyperspherical uniformity. In the next section, we will introduce our theoretical analysis
of triplet loss, which is a simple variant of linear loss. We find triplet loss optimize the hyperspheri-
cal uniformity, which could be the reason that triplet loss works well empirically."
REFERENCES,0.5266106442577031,Under review as a conference paper at ICLR 2022
REFERENCES,0.5294117647058824,"APPENDIX C
EMPIRICAL STUDY OF POSITIVE AND NEGATIVE METRIC
LOSSES"
REFERENCES,0.5322128851540616,"In this subsection, we study the effect of tuple-based metric losses on positive or negative pairs em-
pirically, and focus on the four tuple-based losses: naive linear, triplet, margin, and multi-similarity
loss. In experiments we train all DML models with either positive metric losses or negative metric
losses."
REFERENCES,0.5350140056022409,"C.1
DML MODELS WITH POSITIVE METRIC LOSSES"
REFERENCES,0.5378151260504201,"Settings. We train 4 DML models with linear, triplet, margin, and multi-similarity losses on the
positive sample pairs. The gradient flow of negative pairs is stopped. We train all models for 50
epochs. We compare the average distance between positive/negative/all pairs of embedded samples."
REFERENCES,0.5406162464985994,"Results. In Table 8, the DML models trained with only positive metric losses have average pairwise
distance close to 0. Therefore, minimizing the intra-class alignment will lead to a model which maps
all samples to the same feature vector."
REFERENCES,0.5434173669467787,"Table 8: Comparison of DML models trained with the positive metric losses on CUB200-2011 and
CARS196. We calculate the average distance (Avgdist), average distance of positive pairs (Avgdist-
Pos), and average distance of negative pairs (AvgdistNeg) with the embedded samples."
REFERENCES,0.5462184873949579,"CUB200-2011
CARS196
AvgdistPos
AvgdistNeg
Avgdist
AvgdistPos
AvgdistNeg
Avgdist
Linear
2.010e-3
3.190e-3
3.178e-3
1.497e-3
3.162e-3
3.183e-3
Triplet
1.934e-3
3.187e-3
3.174e-3
1.476e-3
3.163e-3
3.184e-3
Margin
7.565e-2
8.200e-2
8.192e-2
3.195e-2
3.468e-2
3.465e-2
MS
2.558e-3
3.324e-3
3.316e-3
2.242e-3
3.264e-3
3.277e-3"
REFERENCES,0.5490196078431373,"C.2
COMPARE NEGATIVE METRIC LOSSES WITH UNIFORMITY REGULARIZATION"
REFERENCES,0.5518207282913166,"Settings. We compare 8 different models in this experiment, including a) the original model with
only ImageNet pretrain; b) four models trained with linear, triplet, margin, and multi-similarity
losses on negative pairs; c) three models trained with HE(s=0), HE(s=1) (Eq. 2) and G-HE(s=1)
(Eq. 3) regularization, those regularization functions are introduced in Appendix C. We train all
models with 50 epochs. For the models with negative metric losses, the gradient flow of positive
pairs is stopped."
REFERENCES,0.5546218487394958,"Evaluation Metrics. We use the regularization score on HE(s=0) (Eq. 2) and G-HE(s=1) (Eq. 3)
to measure the uniformity of embedded samples on hypersphere. Smaller score indicates better
uniformity. We also check the average of pairwise distance of different models, we expect it to be
close to
√"
REFERENCES,0.5574229691876751,2 for good hyperspherical uniformity.
REFERENCES,0.5602240896358543,"Results. In experiments we compare the regularization strength of negative metric losses with HE
and G-HE. Fig. 2 and Fig. 3 illustrates the pairwise distance of the test samples on CUB200-2011
and CARS196 dataset. The DML models with negative metric losses have similar pairwise dis-
tance distributions as the uniformity regularization methods, and the only exception is the negative
naive linear loss, which will not lead to the hyperspherical uniformity based on our analysis in
Sec. B.2. We also include the distance distribution before training (Figure 2(a)) as a reference. Be-
sides, we also compare those models under the hyperspherical uniformity metrics. In Table 9, the
negative metric losses achieve comparable results with the uniformity regularization methods. The
G-HE(s=1) outperforms the rest models."
REFERENCES,0.5630252100840336,Under review as a conference paper at ICLR 2022
REFERENCES,0.5658263305322129,"Table 9: Comparison of DML models trained with the negative metric losses and uniformity regu-
larization on CUB200-2011 and CARS196. All negative metric losses except Linear achieve com-
parable performance to uniformity regularization. The details of models and training settings are in
Sec. C.2."
REFERENCES,0.5686274509803921,"CUB200-2011
CARS196
Avgdist
HE(s=0)
G-HE(s=1)
Avgdist
HE(s=0)
G-HE(s=1)
ImageNet
0.7220
0.3368
0.5939
0.6557
0.4326
0.6497
Linear
1.2398
-0.1670
0.2535
1.3194
-0.1686
0.2449
Triplet
1.3877
-0.3254
0.1496
1.4039
-0.3376
0.1420
Margin
1.3929
-0.3297
0.1465
1.4016
-0.3363
0.1426
MS
1.3825
-0.3221
0.1509
1.3985
-0.3338
0.1441
HE regularization (s=0)
1.4001
-0.3347
0.1438
1.4064
-0.3395
0.1411
HE regularization (s=1)
1.4009
-0.3355
0.1432
1.4068
-0.3398
0.1407
G-HE regularization (s=1)
1.4028
-0.3369
0.1424
1.4077
-0.3406
0.1402"
REFERENCES,0.5714285714285714,"(a) ImageNet
(b) G-HE (s=1)
(c) HE (s=0)
(d) HE (s=1)"
REFERENCES,0.5742296918767507,"(e) Linear
(f) Triplet
(g) Margin
(h) Multi-similarity"
REFERENCES,0.5770308123249299,"Figure 2: Illustration of pairwise distance distributions of the embedded CUB200-2011 samples
generated by DML models trained with negative metric losses or uniformity regularization. The
details of models and training settings are in Sec. C.2."
REFERENCES,0.5798319327731093,Under review as a conference paper at ICLR 2022
REFERENCES,0.5826330532212886,"(a) ImageNet
(b) G-HE(s=1)
(c) HE(s=0)
(d) HE(s=1)"
REFERENCES,0.5854341736694678,"(e) Linear
(f) Triplet
(g) Margin
(h) Multi-similarity"
REFERENCES,0.5882352941176471,"Figure 3: Illustration of pairwise distance distributions of the embedded CARS196 samples with
negative metric losses or uniformity regularization. The details of models and training settings are
in Sec. 5.3."
REFERENCES,0.5910364145658263,"APPENDIX D
ADML ALGORITHMS AND EXPERIMENTAL SETTINGS"
REFERENCES,0.5938375350140056,"D.1
ALGORITHM OF ADML+A AND ADML+U"
REFERENCES,0.5966386554621849,"Algorithm 1 ADML+A
Input: training set X; number of epochs N; original classifier f; weight of adversarial training λ;
PGD attack step L; PGD attack strength ϵ
Initialize class balanced sampler S;
for i ∈epochs do"
REFERENCES,0.5994397759103641,"for S ∈mini-batch{S1, ..., Sn} do"
REFERENCES,0.6022408963585434,"S(0) = S;
Generate adversarial samples of S with PGD-FSGM attack
for t ∈0 : L −1 do"
REFERENCES,0.6050420168067226,"S(t+1) = ΠB∞(S(0),ϵ)(S(t) + α∇S(t)Lalignment(f, S(t)));"
REFERENCES,0.6078431372549019,"end
Sadv = S(L);
Calculate objective function
Ltotal = L(f, S) + λL(f, Sadv);
L can be an arbitrary metric loss, in our paper we use margin and multisimilarity loss
Update network parameters of f with Ltotal;"
REFERENCES,0.6106442577030813,"end
end"
REFERENCES,0.6134453781512605,Under review as a conference paper at ICLR 2022
REFERENCES,0.6162464985994398,"Algorithm 2 ADML+U
Input: training set X; number of epochs N; original classifier f; weight of adversarial training λ;
PGD attack step L; PGD attack strength ϵ
Initialize class balanced sampler S;
for i ∈epochs do"
REFERENCES,0.6190476190476191,"for S ∈mini-batch{S1, ..., Sn} do"
REFERENCES,0.6218487394957983,"S(0) = S;
Generate adversarial samples of S with PGD-FSGM attack
for t ∈0 : L −1 do"
REFERENCES,0.6246498599439776,"S(t+1) = ΠB∞(S(0),ϵ)(S(t) + α∇S(t)Luniformity(f, S(t)));"
REFERENCES,0.6274509803921569,"end
Sadv = S(L);
Calculate objective function
Ltotal = L(f, S) + λL(f, Sadv);
L can be an arbitrary metric loss, in our paper we use margin and multisimilarity loss
Update network parameters of f with Ltotal;"
REFERENCES,0.6302521008403361,"end
end"
REFERENCES,0.6330532212885154,"D.2
DATASET DETAILS"
REFERENCES,0.6358543417366946,"• CUB200-2011 contains 200 species of birds and 11,788 images (Wah et al., 2011). We use the
first 100 species as training set and the rest as test set.
• CARS196 has 196 models of cars and 16,185 images. (Krause et al., 2013). We use the first 98
models as training set and the rest as test set.
• Online-product includes 22,634 classes of products and 120,053 images (Song et al., 2016).
We use the first 11,318 classes as training set and the rest as test set.
• In-shop contains 7982 classes of clothing and 54,624 images (Liu et al., 2016). We use the
first 3,997 classes as training set and the rest as test set. The test set is further partitioned into
a query set with 14,218 images of 3,985 classes and a gallery set with 12,612 images of 3,985
classes."
REFERENCES,0.6386554621848739,"D.3
EVALUATION METRICS"
REFERENCES,0.6414565826330533,"We use the following metrics to evaluate the DML models with retrieval and clustering downstream
tasks."
REFERENCES,0.6442577030812325,"Recall@k. For the retrieval task we apply the Recall@k (R@k) metric (Jegou et al., 2010). For a
test set M := {(x1, y1), · · · , (xn, yn)}, the indices of the first k nearest neighborhood of a sample
xi is given by Sk(xi) := arg max|S|=k
P"
REFERENCES,0.6470588235294118,"j∈S,j̸=i ||f(xi) −f(xj)||2, and"
REFERENCES,0.6498599439775911,"R@k := 1 n n
X"
REFERENCES,0.6526610644257703,"i=1
1{∃j∈Sk(xi),yj=yi}."
REFERENCES,0.6554621848739496,"NMI. We use Normalized Mutual Information (NMI) (Christopher et al., 2008) to measure the
quality of the clustering task. We use K-means to generate the clusters of the embedded samples,
then we calculate the label assignment Γ = {γ1, ..., γn} from clustering. Denote the ground truth
labels by Ω= {y1, ..., yn}, the NMI is computed as"
REFERENCES,0.6582633053221288,"NMI(Ω, Γ) = I(Ω, Γ)/[2(H(Ω) + H(Γ))],"
REFERENCES,0.6610644257703081,"where I(·, ·) is the mutual information function and H(·) is the entropy function."
REFERENCES,0.6638655462184874,"mAP@C. According to (Musgrave et al., 2020), we also include mean average precision measured
on recall (mAP@k) as an additional metric. We first compute the recalled samples, which are
determined by the k nearest neighbour ranking. Then compute the mAP-score follows the standard
mAP procedure. mAP@C is the mean over the class-wise average precision@kc, where kc is the"
REFERENCES,0.6666666666666666,Under review as a conference paper at ICLR 2022
REFERENCES,0.6694677871148459,"number of samples in class c, which means we only recall kc nearest neighbour. Following the
notation of Recall@k, the value of mAP@C is given by"
REFERENCES,0.6722689075630253,mAP@C := 1 n X c∈C X yq=c
REFERENCES,0.6750700280112045,"|{xi ∈Skc(xq)|yi = yq}| kc
."
REFERENCES,0.6778711484593838,"APPENDIX E
MISSING PROOFS"
REFERENCES,0.680672268907563,"E.1
PROOF OF PROPOSITION 1"
REFERENCES,0.6834733893557423,"Denote the support set of the distribution of each class by S1, . . . , Sn, according to Definition 1, the
minimum of alignment loss is reached when the encoder f ∗maps all samples in one class to the
same feature vector i.e. ∀i, f ∗(Si) = {vi}. For arbitrary i, j, because ∪n
k=1Sk is connected and
each Sk is closed, we can select a set sequence Sk0, . . . , Skm such that Sk0 = Si, Skm = Sj and
Skl ∩Skl+1 ̸= ∅, l ∈[m −1]. By Skl ∩Skl+1 ̸= ∅we have vkl = vkl+1 for all l ∈[m −1], thus
∀i, j, f ∗(Si) = f ∗(Sj). So all samples are projected to the same feature vector."
REFERENCES,0.6862745098039216,"E.2
PROOF OF THEOREM 2"
REFERENCES,0.6890756302521008,Proof. Recall that the naive linear loss is given by
REFERENCES,0.6918767507002801,"Llinear(f; X, ptri) := E(x,y,x−)∼ptri[||f(x) −f(y)||2
2 −||f(x) −f(x−)||2
2]"
REFERENCES,0.6946778711484594,Consider the positive part
REFERENCES,0.6974789915966386,"E(x,y,x−)∼ptri[||f(x) −f(y)||2
2] = E(x,y)∼ppos[||f(x) −f(y)||2
2] = Lalignment
(8)"
REFERENCES,0.7002801120448179,Consider the negative part
REFERENCES,0.7030812324929971,"−E(x,y,x−)∼ptri[||f(x) −f(x−)||2
2] = 2E(x,y,x−)∼ptri[f(x)T f(x−)] −2 and"
REFERENCES,0.7058823529411765,"E(x,y,x−)∼ptri[f(x)T f(x−)]"
REFERENCES,0.7086834733893558,"=E(x,y)∼ppos[f(x)T Ex−∼p−
data[f(x−)]]"
REFERENCES,0.711484593837535,"=Ex∼pdata[f(x)T
1
R"
REFERENCES,0.7142857142857143,x−pdata(x−)dx−(Ex′∼pdata[f(x′)] −Ex′∼pdata[f(x′)1x′∈Xx])]
REFERENCES,0.7170868347338936,"=
n
n −1(Ex∼pdata[f(x)T Ex′∼pdata[f(x′)]] −Ex∼pdata[f(x)T Ex′∼pdata[f(x′)1x′∈Xx]])"
REFERENCES,0.7198879551820728,"=
n
n −1(Ex∼pdata[f(x)T Ex′∼pdata[f(x′)]] −Ex∼pdata[f(x)T pdata(Xx)Ex′∼pdata(·|Xx)[f(x′)]])"
REFERENCES,0.7226890756302521,"=
n
n −1Ex∼pdata[f(x)]T Ex∼pdata[f(x)] −
1
n −1E(x,y)∼ppos[f(x)T f(y)]"
REFERENCES,0.7254901960784313,"=
n
n −1Ex∼pdata[f(x)]T Ex∼pdata[f(x)] −
1
n −1E(x,y)∼ppos[f(x)T f(y)]"
REFERENCES,0.7282913165266106,"=
n
n −1Lunbiased +
1
2(n −1)(Lalignment −2)"
REFERENCES,0.7310924369747899,"(9)
where we denote the class of sample x by Xx."
REFERENCES,0.7338935574229691,"Combining Eq. 8 and Eq. 9 together, we have"
REFERENCES,0.7366946778711485,"Llinear(f) =
2n
n −1Lunbiased +
1
n −1(Lalignment −2) −2 + Lalignment"
REFERENCES,0.7394957983193278,"=
n
n −1(2Lunbiased + Lalignment −2)
(10)"
REFERENCES,0.742296918767507,Under review as a conference paper at ICLR 2022
REFERENCES,0.7450980392156863,"E.3
PROOF OF THEOREM 2"
REFERENCES,0.7478991596638656,Proof. The triplet loss is
REFERENCES,0.7507002801120448,"Ltriplet(f, τ) = Llinear(f; X, p′
tri) = E(x,y,x−)∼p′
tri[||f(x) −f(y)||2
2 −||f(x) −f(x−)||2
2]"
REFERENCES,0.7535014005602241,"= E(x,y,x−)∼ptri[(||f(x) −f(y)||2
2 −||f(x) −f(x−)||2
2)1{||f(x)−f(y)||2
2−||f(x)−f(x−)||2
2+τ≥0}]"
REFERENCES,0.7563025210084033,"= E(x,y,x−)∼ptri[||f(x) −f(y)||2
21{||f(x)−f(y)||2
2−||f(x)−f(x−)||2
2+τ≥0}]"
REFERENCES,0.7591036414565826,"−E(x,y,x−)∼ptri[||f(x) −f(x−)||2
21{||f(x)−f(y)||2
2−||f(x)−f(x−)||2
2+τ≥0}]"
REFERENCES,0.7619047619047619,"Consider the negative part,"
REFERENCES,0.7647058823529411,"−E(x,y,x−)∼ptri[||f(x) −f(x−)||2
21{||f(x)−f(y)||2
2−||f(x)−f(x−)||2
2+τ≥0}]"
REFERENCES,0.7675070028011205,"= −Ex∼pdata,x−∼p−
data[||f(x) −f(x−)||2
2Ey∼pdata(·|Xx)[1{||f(x)−f(y)||2
2−||f(x)−f(x−)||2
2+τ≥0}]]"
REFERENCES,0.7703081232492998,"= −
n
n −1Ex∼pdata,x′∼pdata[||f(x) −f(x′)||2
2Ey∼pdata(·|Xx)[1{||f(x)−f(y)||2
2−||f(x)−f(x′)||2
2+τ≥0}]]"
REFERENCES,0.773109243697479,"+
n
n −1Ex∼pdata,x′∼pdata[||f(x) −f(x′)||2
21x′∈XxEy∼pdata(·|Xx)[1{||f(x)−f(y)||2
2−||f(x)−f(x′)||2
2+τ≥0}]]"
REFERENCES,0.7759103641456583,"= −
n
n −1Ex∼pdata,x′∼pdata[||f(x) −f(x′)||2
2Ey∼pdata(·|Xx)[1{||f(x)−f(y)||2
2−||f(x)−f(x′)||2
2+τ≥0}]]"
REFERENCES,0.7787114845938375,"+
1
n −1E(x,x′)∼ppos[||f(x) −f(x′)||2
2Ey∼pdata(·|Xx)[1{||f(x)−f(y)||2
2−||f(x)−f(x′)||2
2+τ≥0}]]"
REFERENCES,0.7815126050420168,"= −
n
n −1Ex∼pdata,x′∼pdata[||f(x) −f(x′)||2
2S(x, x′)]"
REFERENCES,0.7843137254901961,"+
1
n −1E(x,x′)∼ppos[||f(x) −f(x′)||2
2S(x, x′)]"
REFERENCES,0.7871148459383753,where Xx is the set of samples have the same label as x. The last equation is based on
REFERENCES,0.7899159663865546,"S(x, x′) =
Z ∞"
REFERENCES,0.7927170868347339,"0
q(u + d2(x, x′) −τ) = Eq(d2(x,y))[1{u≥0}] = Ey∼pdata(·|Xx)[1{u≥0}]"
REFERENCES,0.7955182072829131,"= Ey∼pdata(·|Xx)[1{||f(x)−f(y)||2
2−||f(x)−f(x′)||2
2+τ≥0}]"
REFERENCES,0.7983193277310925,"E.4
PROOF OF PROPOSITION 2"
REFERENCES,0.8011204481792717,"Proof. By q(d2(x, y))
=
1
Ae−Ad2(x,y), the pdf of u
=
d2(x, y) −d2(x, x′) + τ is
1
Ae−A(u+d2(x,x′)−τ), then"
REFERENCES,0.803921568627451,"S(x, x′) = 1 A Z ∞"
REFERENCES,0.8067226890756303,"0
e−A(u+d2(x,x′)−τ)du = 1"
REFERENCES,0.8095238095238095,"Ae−A(d2(x,x′)−τ)"
REFERENCES,0.8123249299719888,"Consider the gradient of the negative triplet loss E(x,y,x−)∼p′
tri[||f(x) −f(x−)||2
2], during training
we first sampling from p′
tri then calculate the gradient. In this case the actual gradient flow is given
by"
REFERENCES,0.8151260504201681,"−E(x,y,x−)∼p′
tri[∇θ||f(x) −f(x−)||2
2]"
REFERENCES,0.8179271708683473,Under review as a conference paper at ICLR 2022
REFERENCES,0.8207282913165266,"Analogous with the discussion in Sec. E.3, we have"
REFERENCES,0.8235294117647058,"−E(x,y,x−)∼p′
tri[∇θ||f(x) −f(x−)||2
2]"
REFERENCES,0.8263305322128851,"= −
n
n −1Ex∼pdata,x′∼pdata[S(x, x′)∇θ||f(x) −f(x′)||2
2]"
REFERENCES,0.8291316526610645,"+
1
n −1E(x,x′)∼ppos[S(x, x′)∇θ||f(x) −f(x′)||2
2]"
REFERENCES,0.8319327731092437,"= −
eAτn
A(n −1)Ex∼pdata,x′∼pdata[e−Ad2(x,x′)∇d(x,x′)d2(x, x′)∂d(x, x′)"
REFERENCES,0.834733893557423,"∂θ
] + O( 1 n)"
REFERENCES,0.8375350140056023,"= −
eAτn
A(n −1)Ex∼pdata,x′∼pdata[e−Ad2(x,x′)2d(x, x′)∂d(x, x′)"
REFERENCES,0.8403361344537815,"∂θ
] + O( 1 n)"
REFERENCES,0.8431372549019608,"=
eAτn
A2(n −1)Ex∼pdata,x′∼pdata[∇d(x,x′)(e−Ad2(x,x′))∂d(x, x′)"
REFERENCES,0.84593837535014,"∂θ
] + O( 1 n)"
REFERENCES,0.8487394957983193,"=
eAτn
A2(n −1)∇θEx∼pdata,x′∼pdata[e−Ad2(x,x′)] + O( 1 n)"
REFERENCES,0.8515406162464986,"=
eAτn
A2(n −1)∇θEG(A, X) + O( 1 n)"
REFERENCES,0.8543417366946778,"E.5
CONNECTION BETWEEN NAIVE LINEAR LOSS AND LDA"
REFERENCES,0.8571428571428571,"The intuition of multiple linear discriminant analysis (LDA) is to maximize the inter-class variance
while minimizing the intra-class variance. In this section we will show linear metric loss have a
similar effect.
Definition 6. (Total variation) For a random vector x, the total variation is"
REFERENCES,0.8599439775910365,"TV (x) := tr(E[(x −E[x])(x −E[x])T ]) = E[(x −E[x])T (x −E[x])] = E[xT x] −E[x]T E[x]
(11)
Definition 7. (Centroid) Define the centroid of samples in an arbitrary set Y by"
REFERENCES,0.8627450980392157,"cY := Ey∼pdata(·|Y )[f(y)] =
1
pdata(Y )Ey∼pdata[f(y)1y∈Y ]
(12)"
REFERENCES,0.865546218487395,Proposition 3. (Intra-class total variation) The within-class variation
REFERENCES,0.8683473389355743,TVintra(X) := Ex∼pdata[(f(x) −cXx)T (f(x) −cXx)]
REFERENCES,0.8711484593837535,"is proportional to alignment loss
Laligned(f) = 2TVintra(X)
(13)"
REFERENCES,0.8739495798319328,Proof.
REFERENCES,0.876750700280112,"TVintra(X) = Ex∼pdata[(f(x) −cXx)T (f(x) −cXx)] = n
X"
REFERENCES,0.8795518207282913,"i=1
pdata(Xi)(Ex∼pdata(·|Xi)[f(x)T f(x)] −cT
XicXi) = 1 n n
X"
REFERENCES,0.8823529411764706,"i=1
(1 −nEx∼pdata,x′∼pdata(·|Xx)[f(x)T f(x′)1x∈Xi])"
REFERENCES,0.8851540616246498,"= 1 −Ex∼pdata,x′∼pdata(·|Xx)[f(x)T f(x′) n
X"
REFERENCES,0.8879551820728291,"i=1
1x∈Xi]"
REFERENCES,0.8907563025210085,"= 1 −E(x,y)∼ppos[f(x)T f(y)] = 1"
REFERENCES,0.8935574229691877,2Laligned(f) (14)
REFERENCES,0.896358543417367,Under review as a conference paper at ICLR 2022
REFERENCES,0.8991596638655462,Proposition 4. (Inter-class total variation) The inter-class total variation
REFERENCES,0.9019607843137255,"TVinter(X) := Ex∼pdata[(cXx −c)T (cXx −c)],"
REFERENCES,0.9047619047619048,"where c is the centroid of all samples, is proportional to triplet loss"
REFERENCES,0.907563025210084,Llinear(f) = −2n
REFERENCES,0.9103641456582633,"n −1TVinter(X)
(15)"
REFERENCES,0.9131652661064426,Proof.
REFERENCES,0.9159663865546218,"TVinter(X) = Ex∼pdata[cT
XxcXx] −cT c
(16)
Firstly,"
REFERENCES,0.9187675070028011,"c =
1
pdata(X)Ex∼pdata[f(x)1x∈X] = Ex∼pdata[f(x)]"
REFERENCES,0.9215686274509803,"Hence cT c = Lunbiased(f). Next,"
REFERENCES,0.9243697478991597,"Ex∼pdata[cT
XxcXx] = n
X"
REFERENCES,0.927170868347339,"i=1
pdata(Xi)Ex∼pdata(·|Xi)[cT
XicXi] = n
X"
REFERENCES,0.9299719887955182,"i=1
pdata(Xi)cT
XicXi = n
X"
REFERENCES,0.9327731092436975,"i=1
Ex∼pdata,y∼pdata(·|Xx)[f(x)T f(y)1x∈Xi]"
REFERENCES,0.9355742296918768,"= Ex∼pdata,y∼pdata(·|Xx)[f(x)T f(y) n
X"
REFERENCES,0.938375350140056,"i=1
1x∈Xi]"
REFERENCES,0.9411764705882353,"= Ex∼pdata,y∼pdata(·|Xx)[f(x)T f(y)]"
REFERENCES,0.9439775910364145,"= E(x,y)∼ppos[f(x)T f(y)]"
REFERENCES,0.9467787114845938,"Thus Ex∼pdata[cT
XxcXx]
=
1 −
1
2Laligned(f), and TVinter(X)
=
1 −
1
2Laligned(f) −
Lunbiased(f) = −n−1"
REFERENCES,0.9495798319327731,2n Llinear(f)
REFERENCES,0.9523809523809523,Proposition 5. (Total variation of the dataset) The total variation of dataset X
REFERENCES,0.9551820728291317,"TVtotal(X) := Ex∼pdata[(x −c)T (x −c)],"
REFERENCES,0.957983193277311,"where c is the centroid of all samples, is proportional to the unbiased loss"
REFERENCES,0.9607843137254902,"Lunbiased(f) = 1 −TVtotal(X)
(17)"
REFERENCES,0.9635854341736695,Proof.
REFERENCES,0.9663865546218487,"TVtotal(X) = Ex∼pdata[f(x)T f(x)] −Ex∼pdata[f(x)]T Ex∼pdata[f(x)]
= 1 −Lunbiased(f)
(18)"
REFERENCES,0.969187675070028,"We can also check if TVtotal(X) = TVwithin(X) + TVbetween(X) holds to validate the proofs
above."
REFERENCES,0.9719887955182073,"APPENDIX F
T-SNE EVALUATION OF ADML+A AND VANILLA DML."
REFERENCES,0.9747899159663865,"In experiments, we visualize the embedding of the first 10 classes of CUB200-2011 generated by
a vanilla DML model (with multi-similarity loss) and an ADML+A model (with multi-similarity
loss). The Recall@1 of the DML model and the ADML+A model are 62.71 and 66.13, respectively.
Fig. 4 (a) plots the T-SNE result for vanilla DML and Fig. 4 (b) plots the T-SNE result for ADML+A.
Comparing two figures, we can see that ADML+A has better separation on the (red, green, orange)
samples."
REFERENCES,0.9775910364145658,Under review as a conference paper at ICLR 2022
REFERENCES,0.9803921568627451,"30
20
10
0
10
20
30
40
Dim1 40 30 20 10 0 10 20 30 Dim2 class"
REFERENCES,0.9831932773109243,"0.0
1.0
2.0
3.0
4.0
5.0
6.0
7.0
8.0
9.0"
REFERENCES,0.9859943977591037,(a) Vanilla DML
REFERENCES,0.988795518207283,"40
30
20
10
0
10
20
30
40
Dim1 30 20 10 0 10 20 30 Dim2 class"
REFERENCES,0.9915966386554622,"0.0
1.0
2.0
3.0
4.0
5.0
6.0
7.0
8.0
9.0"
REFERENCES,0.9943977591036415,(b) ADML+A
REFERENCES,0.9971988795518207,"Figure 4: T-SNE visualization of embedding generated by a vanilla DML and an ADML+A model
on CUB200-2011."
