Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0024154589371980675,"In the context of personalized federated learning (FL), the critical challenge is to
balance local model improvement and global model tuning when the personal and
global objectives may not be exactly aligned. Inspired by Bayesian hierarchical
models, we develop a self-aware personalized FL method where each client can
automatically balance the training of its local personal model and the global
model that implicitly contributes to other clients’ training. Such a balance is
derived from the inter-client and intra-client uncertainty quantiﬁcation. A larger
inter-client variation implies more personalization is needed. Correspondingly,
our method uses uncertainty-driven local training steps and aggregation rule
instead of conventional local ﬁne-tuning and sample size-based aggregation. With
experimental studies on synthetic data, Amazon Alexa audio data, and public
datasets such as MNIST, FEMNIST and Sent140, we show that our proposed
method can achieve signiﬁcantly improved personalization performance compared
with the existing counterparts."
INTRODUCTION,0.004830917874396135,"1
Introduction"
INTRODUCTION,0.007246376811594203,"Federated learning (FL) (Konevcny et al., 2016; McMahan et al., 2017) is transforming machine learn-
ing (ML) ecosystems from “centralized in-the-cloud” to “distributed across-clients,” to potentially
leverage the computation and data resources of billions of edge devices (Lim et al., 2020), without
raw data leaving the devices. As a distributed ML framework, FL aims to train a global model that
aggregates gradients or model updates from the participating edge devices. Recent research in FL
has signiﬁcantly extended its original scope to address the emerging concern of personalization, a
broad term that often refers to an FL system that accommodates client-speciﬁc data distributions of
interest (Ding et al., 2022)."
INTRODUCTION,0.00966183574879227,"In particular, each client in a personalized FL system holds data that can be potentially non-identically
and independently distributed (non-IID). For example, smart edge devices at different houses may
collect audio data (Purington et al., 2017) of heterogeneous nature due to, e.g., accents, background
noises, and house structures. Each device hopes to improve its on-device model through personalized
FL without transmitting sensitive data."
INTRODUCTION,0.012077294685990338,"While the practical beneﬁts of personalization have been widely acknowledged, its theoretical
understanding remains unclear. Existing works on personalized FL often derive algorithms based on
a pre-speciﬁed optimization formulation, but explanations regarding the formulation or its tuning
parameters rarely go beyond heuristic statements."
INTRODUCTION,0.014492753623188406,"In this work, we take a different approach. Instead of specifying an optimization problem to solve,
we start with a toy example and develop insights into the nature of personalization from a statistical
uncertainty perspective. We aim to answer the following critical questions regarding personalized FL.
(Q1) The lower-bound baselines of personalized FL can be obtained in two cases, i.e., each client"
INTRODUCTION,0.016908212560386472,"performs local training without FL, or all clients participate in conventional FL training. However,
the upper-bound for the client is unclear."
INTRODUCTION,0.01932367149758454,(Q2) Suppose that the goal of each client is to improve its local model performance. How to design
INTRODUCTION,0.021739130434782608,"an FL training that interpret the global model, suitably aggregate local models and ﬁne-tune each
client’s local training automatically?
Both questions Q1 and Q2 are quite challenging. Q1 demands a systematic way to characterize the
client-speciﬁc and globally-shared information. Such a characterization is agnostic to any particular
training process being used. To this end, instead of studying personalized data in full generality, we
restrict our attention to a simpliﬁed and analytically tractable setting: two-level Bayesian hierarchical
models, where the top and bottom level describes inter-client and intra-client uncertainty, respectively.
The above Q2 requires FL updates to be adaptive to the nature of the underlying discrepancy among
client-speciﬁc local data, including sample sizes and distributions. The popular aggregation approach
that uses a sample size-based weighting mechanism (McMahan et al., 2017) does not account for
the distribution discrepancy. Meanwhile, since clients’ data is not shared, estimating the underlying
data distributions is unrealistic. Consequently, it is highly nontrivial to measure and calibrate such a
discrepancy in FL settings. Addressing the above issues is a key motivation of our work."
INTRODUCTION,0.024154589371980676,"1.1
Contributions"
INTRODUCTION,0.026570048309178744,We make the following technical contributions:
INTRODUCTION,0.028985507246376812,• Interpreting personalization from a hierarchical model-based perspective and providing
INTRODUCTION,0.03140096618357488,"theoretical analyses for FL training.
• Proposing Self-FL, an active personalized FL solution that guides local training and global"
INTRODUCTION,0.033816425120772944,"aggregation via inter- and intra-client uncertainty quantiﬁcation.
• Presenting a novel implementation of Self-FL for deep learning, consisting of automated"
INTRODUCTION,0.036231884057971016,"hyper-parameter tuning for clients and an adaptive aggregation rule.
• Evaluating Self-FL on Sent140 and Amazon Alexa audio data. Empirical results show"
INTRODUCTION,0.03864734299516908,promising personalization performance compared with existing methods.
INTRODUCTION,0.04106280193236715,"To our best knowledge, Self-FL is the ﬁrst work that connects personalized FL with hierarchical
modeling and utilizes uncertainty quantiﬁcation to drive personalization."
LIT REVIEW,0.043478260869565216,"1.2
Related work"
LIT REVIEW,0.04589371980676329,"Personalized FL. The term personalization in FL often refers to the development of client-speciﬁc
model parameters for a given model architecture. In this context, each client aims to obtain a local
model that has desirable test performance on its local data distribution. Personalized FL is critical for
applications that involve statistical heterogeneity among clients."
LIT REVIEW,0.04830917874396135,"A research trend is to adapt the global model for accommodating personalized local models. To this
end, prior works often integrate FL with other frameworks such as multi-task learning (Smith et al.,
2017), meta-learning (Jiang et al., 2019; Khodak et al., 2019; Fallah et al., 2020a,b; Al-Shedivat et al.,
2021), transfer learning (Wang et al., 2019; Mansour et al., 2020), knowledge distillation (Li and
Wang, 2019), and lottery ticket hypothesis (Li et al., 2020a). For example, DITTO (Li et al., 2021)
formulates personalized FL as a multi-task learning (MTL) problem and regularizes the discrepancy
of the local models to the global model using the `2 norm. FedEM Marfoq et al. (2021) uses the MTL
formulation for personalization under a ﬁnite-mixture model assumption and provides federated EM-
like algorithms. We refer to Vanhaesebrouck et al. (2017); Hanzely et al. (2020); Huang et al. (2021)
for more MTL-based approaches and theoretical bounds on the optimization problem. From the
perspective of meta-learning, pFedMe (Dinh et al., 2020) formulates a bi-level optimization problem
for personalized FL and introduces Moreau envelopes as clients’ regularized loss. PerFedAvg (Fallah
et al., 2020b) proposes a method to ﬁnd a proper initial global model that allows a quick adaptation
to local data. pFedHN Shamsian et al. (2021) proposes to train a central hypernetwork for generating
personalized models. FedFOMO Zhang et al. (2020) introduces a method to compute the optimally
weighted model aggregation for personalization by characterizing the contribution of other models to
one client. Later on, we will focus on the experimental comparison of Self-FL with DITTO, pFedMe,
and PerFedAvg, since they represent two popular personalized FL formulations, namely multi-task
learning and meta-learning."
LIT REVIEW,0.050724637681159424,"A limitation of existing personalized FL methods is that they do not provide a clear answer to question
Q1. Consequently, it is unclear how to interpret the FL-trained results. For example, in the extreme
case where the clients are equipped with irrelevant tasks and data, any personalized FL methods that
require a pre-speciﬁed global objective (e.g., Ditto (Li et al., 2021), pFedMe (Dinh et al., 2020)) may
cause signiﬁcant biases to local clients."
LIT REVIEW,0.05314009661835749,"2
Bayesian Perspective of Personalized FL"
LIT REVIEW,0.05555555555555555,"We discuss how Self-FL approaches personalized FL with theoretical insights from the Bayesian
perspective in this section. The notations are deﬁned as follows. Let N(µ, σ2) denote Gaussian
distribution with mean µ and variance σ2. For a positive integer M, let [M] denote the set {1, . . . , M}.
Let P"
LIT REVIEW,0.057971014492753624,"m6=i denote the summation over all m 2 [M] except for m = i. We summarize frequently
used notation in Table 3 of Appendix and the derivation for general parametric models in Section D."
LIT REVIEW,0.06038647342995169,"2.1
Understanding personalized FL through a two-level Gaussian model
To develop insights, we ﬁrst restrict our attention to the following simpliﬁed case. Suppose that there
are M clients. From the server’s perspective, it is postulated that data z1, . . . , zM are generated from
the following two-layer Bayesian hierarchical model:"
LIT REVIEW,0.06280193236714976,✓m | ✓0
LIT REVIEW,0.06521739130434782,"IID
⇠N(✓0, σ2"
LIT REVIEW,0.06763285024154589,"0),
zm | ✓m"
LIT REVIEW,0.07004830917874397,"IID
⇠N(✓m, σ2"
LIT REVIEW,0.07246376811594203,"m),
(1)"
LIT REVIEW,0.0748792270531401,"for all clients with indices m = 1, . . . , M. Here, σ2"
LIT REVIEW,0.07729468599033816,"0 is a constant, and ✓0 is a hyperparameter
with a non-informative ﬂat prior (denoted by ⇡0). The above model represents both the connections
and heterogeneity across clients. In particular, each client’s data are distributed according to a
client-speciﬁc parameter (✓m), which follows a distribution decided by a parent parameter (✓0). The
parent parameter is interpreted as the root of shared information. In the rest of the section, we often
study client 1’s local model as parameterized by ✓1 without loss of generality. Under the above model
assumption, the parent parameter ✓0 that represents the global model has a posterior distribution
p(✓0 | z1:M) ⇠N(✓(G), v(G)), where:"
LIT REVIEW,0.07971014492753623,✓(G) ∆= P
LIT REVIEW,0.0821256038647343,m2[M](σ2
LIT REVIEW,0.08454106280193237,0 + σ2
LIT REVIEW,0.08695652173913043,"m)−1zm
P"
LIT REVIEW,0.0893719806763285,m2[M](σ2
LIT REVIEW,0.09178743961352658,"0 + σ2m)−1
,
v(G) ∆=
1
P"
LIT REVIEW,0.09420289855072464,m2[M](σ2
LIT REVIEW,0.0966183574879227,"0 + σ2m)−1 .
(2)"
LIT REVIEW,0.09903381642512077,The zm in Eqn. (2) may also be denoted by ✓(L)
LIT REVIEW,0.10144927536231885,"m , for reasons that will be seen in Eqn. (3). From the
perspective of client m, we suppose that the postulated model is Eqn. (1) for m = 2, . . . , M, and
✓1 = ✓0. It can be veriﬁed that the posterior distributions of ✓1 without and with global Bayesian
learning are p(✓1 | z1) ⇠N(✓(L)"
LIT REVIEW,0.10386473429951691,"1 , v(L)"
LIT REVIEW,0.10628019323671498,1 ) and p(✓1 | z1:M) ⇠N(✓(FL)
LIT REVIEW,0.10869565217391304,"1
, v(FL)"
LIT REVIEW,0.1111111111111111,"1
), respectively, which can
be computed as: ✓(L) 1"
LIT REVIEW,0.11352657004830918,"∆= z1,
v(L) 1 ∆= σ2 1, ✓(FL) 1 ∆= σ−2"
LIT REVIEW,0.11594202898550725,"1 ✓(L) 1
+ P"
LIT REVIEW,0.11835748792270531,m6=1(σ2
LIT REVIEW,0.12077294685990338,0 + σ2
LIT REVIEW,0.12318840579710146,"m)−1✓(L) m
σ−2 1
+ P"
LIT REVIEW,0.12560386473429952,m6=1(σ2
LIT REVIEW,0.1280193236714976,"0 + σ2m)−1
,
(3) v(FL) 1"
LIT REVIEW,0.13043478260869565,"∆=
1
σ−2 1
+ P"
LIT REVIEW,0.13285024154589373,m6=1(σ2
LIT REVIEW,0.13526570048309178,0 + σ2m)−1 .
LIT REVIEW,0.13768115942028986,"The ﬁrst and the second distribution above describe the learned result of client 1 from its local data
and from all clients’ data in hindsight, respectively. Using mean square error as risk, the Bayes
estimate of ✓1 or ✓0 is the mean of the posterior distribution, namely ✓(L)"
LIT REVIEW,0.14009661835748793,"1
and ✓(FL)"
LIT REVIEW,0.14251207729468598,"1
as deﬁned above."
LIT REVIEW,0.14492753623188406,"The ﬂat prior on ✓0 can be replaced with any other distribution to bake prior knowledge into the
calculation. We consider the ﬂat prior because the knowledge of the shared model is often vague
in practice. The above posterior mean ✓(FL)"
LIT REVIEW,0.1473429951690821,"1
can be regarded as the optimal point estimation of ✓1
given all the clients’ data, thus is referred to as “FL-optimal”. ✓(G) can be regarded as the “global-
optimal.” The posterior variance quantiﬁes the reduced uncertainty conditional on other clients’ data.
Speciﬁcally, we deﬁne the following Personalized FL gain for client 1 as: GAIN1"
LIT REVIEW,0.1497584541062802,∆= v(L)
LIT REVIEW,0.15217391304347827,"1
v(FL) 1"
LIT REVIEW,0.15458937198067632,= 1 + σ2 1 X m6=1 (σ2
LIT REVIEW,0.1570048309178744,0 + σ2 m)−1.
LIT REVIEW,0.15942028985507245,"Remark 2.1 (Interpretations of the posterior quantities). Each client, say client 1, aims to learn ✓1
in the personalized FL context. Its learned information regarding ✓1 is represented by the Bayesian
posterior of ✓1 conditional on either its local data z1 (without communications with others), or the data
z1:M in hindsight (with communications). For the former case, the posterior uncertainty described
by v(L)"
LIT REVIEW,0.16183574879227053,"1
depends only on the local data quality σ2"
LIT REVIEW,0.1642512077294686,"1. For the latter case, the posterior mean ✓(FL)"
LIT REVIEW,0.16666666666666666,"1
is a
weighted sum of clients’ local posterior means, and the uncertainty will be reduced by a factor of"
LIT REVIEW,0.16908212560386474,"GAIN1. Since a point estimation of ✓1 is of particular interest in practical implementations, we treat
✓(FL)"
LIT REVIEW,0.17149758454106281,"1
as the theoretical limit in the FL context (recall question Q1). To develop further insights into
✓(FL)"
LIT REVIEW,0.17391304347826086,"1
, we consider the following extreme cases."
LIT REVIEW,0.17632850241545894,• As σ2
LIT REVIEW,0.178743961352657,"0 ! 1, meaning that the clients are barely connected, the quantities ✓(FL)"
LIT REVIEW,0.18115942028985507,"1
and v(FL)"
LIT REVIEW,0.18357487922705315,"1
reduce to
✓(L)"
LIT REVIEW,0.1859903381642512,"1
and v(L)"
LIT REVIEW,0.18840579710144928,"1 , respectively; meanwhile, the personalized FL gain approaches one, the global parameter
mean ✓(G) becomes a simple average of ✓(L)"
LIT REVIEW,0.19082125603864733,"m (or zm), and the global parameter has a large variance."
LIT REVIEW,0.1932367149758454,• When σ2
LIT REVIEW,0.1956521739130435,"0 = 0, meaning that the clients follow the same underlying data-generating process and the
personalized FL becomes a standard FL, we have ✓(FL)"
LIT REVIEW,0.19806763285024154,"1
= ✓(G), which is a weighted sum of clients’
local optimal solution with weight proportional to σ−2"
LIT REVIEW,0.20048309178743962,m (namely client m’s precision).
LIT REVIEW,0.2028985507246377,• When σ2
LIT REVIEW,0.20531400966183574,1 is much smaller than all other σ2
LIT REVIEW,0.20772946859903382,m’s and σ2
LIT REVIEW,0.21014492753623187,"0, and M is not too large, meaning that client 1
has much higher quality data compared with the other clients combined, we have ✓(FL)"
LIT REVIEW,0.21256038647342995,"1
⇡z1 = ✓(L)"
LIT REVIEW,0.21497584541062803,"1
and GAIN1 ⇡1. In other words, client 1 almost learns on its own. Meanwhile, client 1 can still
contribute to other clients through the globally shared parameter ✓0. For example, the gain for client
2 would be GAIN2 ≥σ2 2/σ2"
LIT REVIEW,0.21739130434782608,"1, which is much larger than one."
LIT REVIEW,0.21980676328502416,Remark 2.2 (Local training steps to achieve ✓(FL)
LIT REVIEW,0.2222222222222222,"1
). Suppose that client 1 performs ` training steps
using its local data and negative log-likelihood loss. We show that with a suitable number of steps
and initial value, client 1 can obtain the intended ✓(FL)"
LIT REVIEW,0.2246376811594203,"1
. The local objective is:"
LIT REVIEW,0.22705314009661837,✓7! (✓−z1)2/(2σ2
LIT REVIEW,0.22946859903381642,1) = (✓−✓(L)
LIT REVIEW,0.2318840579710145,1 )2/(2σ2
LIT REVIEW,0.23429951690821257,"1),
(4)"
LIT REVIEW,0.23671497584541062,"which coincides with the quadratic loss. Let ⌘2 (0, 1) denote the learning rate. By running the
gradient descent: ✓`"
LIT REVIEW,0.2391304347826087,"1  ✓`−1 1
−⌘@ @✓ ✓"
LIT REVIEW,0.24154589371980675,(✓−✓(L)
LIT REVIEW,0.24396135265700483,1 )2/(2σ2 1) ◆ |✓`−1 1
LIT REVIEW,0.2463768115942029,= ✓`−1
LIT REVIEW,0.24879227053140096,"1
−⌘(✓`−1"
LIT REVIEW,0.25120772946859904,"1
−✓(L)"
LIT REVIEW,0.2536231884057971,"1 )/σ2 1
(5)"
LIT REVIEW,0.2560386473429952,for ` steps with the initial value ✓INIT
LIT REVIEW,0.2584541062801932,"1
, client 1 will obtain: ✓` 1 = $"
LIT REVIEW,0.2608695652173913,1 −(1 −σ−2
LIT REVIEW,0.2632850241545894,1 ⌘)`% ✓(L)
LIT REVIEW,0.26570048309178745,"1
+ (1 −σ−2"
LIT REVIEW,0.26811594202898553,1 ⌘)`✓
LIT REVIEW,0.27053140096618356,"INIT
1
.
(6)"
LIT REVIEW,0.27294685990338163,It can be veriﬁed that Eqn. (6) becomes ✓(FL)
LIT REVIEW,0.2753623188405797,"1
in Eqn. (3) if and only if: ✓"
LIT REVIEW,0.2777777777777778,"INIT
1
= P"
LIT REVIEW,0.28019323671497587,m6=1(σ2
LIT REVIEW,0.2826086956521739,0 + σ2
LIT REVIEW,0.28502415458937197,"m)−1✓(L) m
P"
LIT REVIEW,0.28743961352657005,m6=1(σ2
LIT REVIEW,0.2898550724637681,"0 + σ2m)−1
,
(7)"
LIT REVIEW,0.2922705314009662,(1 −σ−2
LIT REVIEW,0.2946859903381642,1 ⌘)` = P
LIT REVIEW,0.2971014492753623,m6=1(σ2
LIT REVIEW,0.2995169082125604,"0 + σ2 m)−1 σ−2 1
+ P"
LIT REVIEW,0.30193236714975846,m6=1(σ2
LIT REVIEW,0.30434782608695654,"0 + σ2m)−1 .
(8)"
LIT REVIEW,0.30676328502415456,"In other words, with a suitably chosen initial value ✓INIT"
LIT REVIEW,0.30917874396135264,"1
, learning rate ⌘, and the number of (early-
stop) steps `, client 1 can obtain the desired ✓(FL) 1
."
IMPLEMENTATION/METHODS,0.3115942028985507,"3
Proposed Solution for Personalized FL"
IMPLEMENTATION/METHODS,0.3140096618357488,"Our proposed Self-FL framework has three key components as detailed in this section: (i) proper
initialization for local clients at each round, (ii) automatic determination of the local training steps,
(iii) discrepancy-aware aggregation rule for the global model. These components are interconnected
and contribute together to Self-FL’s effectiveness. Note that points (i) and (iii) direct Self-FL to
the regions that beneﬁt personalization in the optimization space during local training, which is not
considered in prior works such as DITTO Li et al. (2021) and pFedMe Dinh et al. (2020). Therefore,
Self-FL is more than imposing implicit regularization via early stopping."
IMPLEMENTATION/METHODS,0.3164251207729469,"3.1
From posterior quantities to FL updating rules"
IMPLEMENTATION/METHODS,0.3188405797101449,"In this section, we show how the posterior quantities of interest in Section 2 can be connected with
FL, where clients’ parameters suitably deviate from the global parameter, and the global parameter
is a proper aggregation of clients’ parameters. For notional brevity, we still consider the two-level
Gaussian model in Subsection 2.1. For regular parametric models, we mentioned in Subsection D
that one may treat zm as the local optimal solution ✓(L)"
IMPLEMENTATION/METHODS,0.321256038647343,"m , and its variance σ2"
IMPLEMENTATION/METHODS,0.32367149758454106,m as the variance of ✓(L)
IMPLEMENTATION/METHODS,0.32608695652173914,"m
due to ﬁnite sample."
IMPLEMENTATION/METHODS,0.3285024154589372,Recall that each client m can obtain the FL-optimal solution ✓(FL)
IMPLEMENTATION/METHODS,0.3309178743961353,"m
with the initial value ✓INIT"
IMPLEMENTATION/METHODS,0.3333333333333333,"m
in
Eqn. (7) and tuning parameters ⌘, ` in Eqn. (8). Also, it can be shown that ✓INIT"
IMPLEMENTATION/METHODS,0.3357487922705314,"m
is connected with the
global-optimal ✓(G) deﬁned in Eqn. (2) through: ✓"
IMPLEMENTATION/METHODS,0.33816425120772947,"INIT
m
= ✓(G) −
(σ2"
IMPLEMENTATION/METHODS,0.34057971014492755,0 + σ2
IMPLEMENTATION/METHODS,0.34299516908212563,"m)−1
P"
IMPLEMENTATION/METHODS,0.34541062801932365,k: k6=m(σ2
IMPLEMENTATION/METHODS,0.34782608695652173,0 + σ2
IMPLEMENTATION/METHODS,0.3502415458937198,k)−1 (✓(L)
IMPLEMENTATION/METHODS,0.3526570048309179,"m −✓(G)).
(9)"
IMPLEMENTATION/METHODS,0.35507246376811596,The initial value ✓INIT
IMPLEMENTATION/METHODS,0.357487922705314,"m
in Eqn. (9) is unknown during training since ✓(L)"
IMPLEMENTATION/METHODS,0.35990338164251207,"m , ✓(G) are unknown. A natural
solution is to update ✓INIT"
IMPLEMENTATION/METHODS,0.36231884057971014,"m , ✓(L)"
IMPLEMENTATION/METHODS,0.3647342995169082,"m , and ✓(G) iteratively, leading to the following personalized FL rule."
IMPLEMENTATION/METHODS,0.3671497584541063,"Generic Self-FL: At the t-th (t = 1, 2, . . .) round of FL:
• Each client m receives the latest global model ✓t−1 from the server and calculates:"
IMPLEMENTATION/METHODS,0.3695652173913043,"✓t,INIT m"
IMPLEMENTATION/METHODS,0.3719806763285024,"∆= ✓t−1 −
(σ2"
IMPLEMENTATION/METHODS,0.3743961352657005,0 + σ2
IMPLEMENTATION/METHODS,0.37681159420289856,"m)−1
P"
IMPLEMENTATION/METHODS,0.37922705314009664,k: k6=m(σ2
IMPLEMENTATION/METHODS,0.38164251207729466,0 + σ2
IMPLEMENTATION/METHODS,0.38405797101449274,k)−1 (✓t−1
IMPLEMENTATION/METHODS,0.3864734299516908,"m
−✓t−1),
(10)"
IMPLEMENTATION/METHODS,0.3888888888888889,where ✓t−1
IMPLEMENTATION/METHODS,0.391304347826087,"m
is client m’s latest personal parameter at round t −1, initialized to be ✓0. Starting
from the above ✓t,INIT"
IMPLEMENTATION/METHODS,0.39371980676328505,"m
, client m performs gradient descent-based local updates with optimization
parameters following Eqn. (8) or its approximations, and obtains a personal parameter ✓t"
IMPLEMENTATION/METHODS,0.3961352657004831,"m.
• Server collects ✓t"
IMPLEMENTATION/METHODS,0.39855072463768115,"m, m = 1, . . . , M, and calculates: ✓t ∆= P"
IMPLEMENTATION/METHODS,0.40096618357487923,m2[M](σ2
IMPLEMENTATION/METHODS,0.4033816425120773,0 + σ2
IMPLEMENTATION/METHODS,0.4057971014492754,"m)−1✓t m
P"
IMPLEMENTATION/METHODS,0.4082125603864734,m2[M](σ2
IMPLEMENTATION/METHODS,0.4106280193236715,"0 + σ2m)−1
.
(11)"
IMPLEMENTATION/METHODS,0.41304347826086957,"In general, the above σ2 0, σ2"
IMPLEMENTATION/METHODS,0.41545893719806765,"m represent “inter-client uncertainty” and “intra-client uncertainty,”
respectively. When σ2"
IMPLEMENTATION/METHODS,0.4178743961352657,0 and σ2
IMPLEMENTATION/METHODS,0.42028985507246375,"m’s are unknown, they can be approximated using asymptotics of
M-estimators or using practical ﬁnite-sample approximations (elaborated in Subsection 3.2)."
IMPLEMENTATION/METHODS,0.4227053140096618,"We provide a theoretical understanding of the convergence. Consider the data-generating process that
✓(L)"
IMPLEMENTATION/METHODS,0.4251207729468599,"m ⇠N(✓m, σ2"
IMPLEMENTATION/METHODS,0.427536231884058,"m) are independent, and ✓m"
IMPLEMENTATION/METHODS,0.42995169082125606,"IID
⇠N(✓0, σ2"
IMPLEMENTATION/METHODS,0.4323671497584541,0) where σ2
IMPLEMENTATION/METHODS,0.43478260869565216,0 is a ﬁxed constant and each σ2
IMPLEMENTATION/METHODS,0.43719806763285024,"m
may or may not depend on M. Let Op denote the standard stochastic boundedness. The following
result gives an error bound of each client’s personalized parameter and the server’s parameter."
IMPLEMENTATION/METHODS,0.4396135265700483,Proposition 3.1. Assume that maxm2[M] σ2
IMPLEMENTATION/METHODS,0.4420289855072464,"m is upper bounded by a constant, and there exists a
constant q 2 (0, 1) such that:"
IMPLEMENTATION/METHODS,0.4444444444444444,"max
m2[M] P"
IMPLEMENTATION/METHODS,0.4468599033816425,k: k6=m(σ2
IMPLEMENTATION/METHODS,0.4492753623188406,k + σ2 0)−1
IMPLEMENTATION/METHODS,0.45169082125603865,"σ−2
m + P"
IMPLEMENTATION/METHODS,0.45410628019323673,k: k6=m(σ2
IMPLEMENTATION/METHODS,0.45652173913043476,k + σ2
IMPLEMENTATION/METHODS,0.45893719806763283,"0)−1 q.
(12)"
IMPLEMENTATION/METHODS,0.4613526570048309,"Suppose that at t = 0, the gap between the initial parameter and each client’s FL-optimal value
satisﬁes |ˆ✓0 −✓(FL)"
IMPLEMENTATION/METHODS,0.463768115942029,"m | C for all m 2 [M]. Then, for every positive integer t, the quantities
maxm2[1:M] |✓t"
IMPLEMENTATION/METHODS,0.46618357487922707,m −✓(FL)
IMPLEMENTATION/METHODS,0.46859903381642515,"m |, |✓t −✓(G)| are both upper bounded by C · qt + Op(M −1/2) as M ! 1."
IMPLEMENTATION/METHODS,0.47101449275362317,"Remark 3.2 (Interpretation of Proposition 3.1). The proposition shows that the estimation error of
each personalized parameter ✓t"
IMPLEMENTATION/METHODS,0.47342995169082125,"m and the server parameter ✓t can uniformly go to zero as the number
of clients M and the FL round t go to inﬁnity. The error bound involves two terms. The ﬁrst term
qt corresponds to the optimization error. Typically, every σm is a small value. If each client has a
sample size of N, q will be at the order of M/(N + M). The second term Op(M −1/2) is a statistical
error that vanishes as more clients participate. Intuitively, the initial model of each client and the
global model at each round are averaged over many clients, so a larger pool leads to a smaller bias.
The proof is nontrivial because the averaged terms are statistically dependent. For the particular case
that each σ2"
IMPLEMENTATION/METHODS,0.4758454106280193,"m is at the order of N −1, we can see that the error is tiny when both M and N/M grow."
IMPLEMENTATION/METHODS,0.4782608695652174,"3.2
SGD-based practical algorithm for deep learning"
IMPLEMENTATION/METHODS,0.4806763285024155,"For the training method proposed in Subsection 3.1, the quantities σ2"
IMPLEMENTATION/METHODS,0.4830917874396135,0 and σ2
IMPLEMENTATION/METHODS,0.4855072463768116,"m are crucial as they
affect the choice of learning rate ⌘m and the early-stop rule. For many complex learning models, we
do not know σ2"
IMPLEMENTATION/METHODS,0.48792270531400966,0 and σ2
IMPLEMENTATION/METHODS,0.49033816425120774,"m, and the asymptotic approximation of σ2"
IMPLEMENTATION/METHODS,0.4927536231884058,0 and σ2
IMPLEMENTATION/METHODS,0.49516908212560384,"m’s may not be valid due to
a lack of regularity conditions. Furthermore, one often uses SGD instead of GD to perform local
updates, so the stop rule depends on the batch size. In this subsection, we consider the above aspects
and develop a practical algorithm for deep learning. Following the discussions in Subection D, we"
IMPLEMENTATION/METHODS,0.4975845410628019,can generally treat σ2
IMPLEMENTATION/METHODS,0.5,m as “uncertainty of the local optimal solution ✓(L)
IMPLEMENTATION/METHODS,0.5024154589371981,"m of client m”, and σ2"
IMPLEMENTATION/METHODS,0.5048309178743962,"0 as
“uncertainty of clients’ underlying parameters.” We propose a way to approximate them."
IMPLEMENTATION/METHODS,0.5072463768115942,"Assume that for each client m, we had u independent samples of its data and the corresponding local
optimal parameter ✓m,1, . . . , ✓m,u. We could then estimate σ2"
IMPLEMENTATION/METHODS,0.5096618357487923,"m by their sample variance. In practice,
we can treat each round of local training as the optimization from a bootstrapped sample. In other
words, at the round t, let client m run sufﬁciently many steps (not limited by our tuning parameter `)
until it approximately converges to a local minimum, denoted by ✓m,t. To save computational costs,
a client does not necessarily wait for its local convergence. Instead, we recommend that each client
use its personal parameter as a surrogate of ✓m,t at each round t, namely to use ✓t"
IMPLEMENTATION/METHODS,0.5120772946859904,"m. In other words,
at round t, we approximate σ2"
IMPLEMENTATION/METHODS,0.5144927536231884,m with:
IMPLEMENTATION/METHODS,0.5169082125603864,"c
σ2m = empirical variance of {✓1"
IMPLEMENTATION/METHODS,0.5193236714975845,"m, . . . , ✓t"
IMPLEMENTATION/METHODS,0.5217391304347826,"m}.
(13)
Likewise, at round t, we estimate σ2"
IMPLEMENTATION/METHODS,0.5241545893719807,"0 by:
c
σ2"
IMPLEMENTATION/METHODS,0.5265700483091788,0 = empirical variance of {✓t
IMPLEMENTATION/METHODS,0.5289855072463768,"1, . . . , ✓t"
IMPLEMENTATION/METHODS,0.5314009661835749,"M}.
(14)"
IMPLEMENTATION/METHODS,0.533816425120773,"For multi-dimensional parameters, a counterpart of the derivations in earlier sections will involve
matrix multiplications, which does not ﬁt the usual SGD-based learning process. We thus simplify the
problem by introducing the following uncertainty measures. For vectors x1, . . . , xM, their empirical
variance is deﬁned as the trace of P"
IMPLEMENTATION/METHODS,0.5362318840579711,"m2[M](xm −¯x)(xm −¯x)T, which is the sum of entry-wise"
IMPLEMENTATION/METHODS,0.538647342995169,"empirical variances. c
σ2m and c
σ2"
IMPLEMENTATION/METHODS,0.5410628019323671,"0 will be deﬁned from such empirical variances, similar to Eqn. (13)
and (14). In practice, for large neural network models, we suggest deploying Self-FL after the
baseline FL training runs for certain rounds (namely warm-start) so that the ﬂuctuation of local
models does not hinder variance approximation.
Combining the above discussion and the generic method in Subsection 3.1, we propose our personal-
ized FL solution in Algorithm 1. We include the implementation details of Self-FL in Section 4 and
Appendix. We derived how to learn ✓(G) and ✓(FL)"
IMPLEMENTATION/METHODS,0.5434782608695652,"m
for parametric models in Subsection D. The key
motivation of Algorithm 1 is that a client often cannot obtain the exact ✓(L)"
IMPLEMENTATION/METHODS,0.5458937198067633,"m (especially in DL), so
we interweave local training and personalization through an iterative FL procedure. Note that the
computation of ✓(G) and ✓(FL)"
IMPLEMENTATION/METHODS,0.5483091787439613,"m
requires uncertainty measurements approximated from communications
between the clients and the server. In the case where a client does not have sufﬁcient labeled data,
this client’s intra-client uncertainty value σ2"
IMPLEMENTATION/METHODS,0.5507246376811594,"m tends to be large and the local training step l computed
via Equation (8) will be small. This means that Self-FL will suggest a client with limited labeled data
train only a few epochs on their local dataset, thus alleviating over-ﬁtting."
IMPLEMENTATION/METHODS,0.5531400966183575,"Algorithm 1 Self-aware Personal FL (Self-FL)
Input: A server and M clients. Communication rounds T, client activity rate C, client m’s local"
IMPLEMENTATION/METHODS,0.5555555555555556,"data Dm and learning rate ⌘m.
for each communication round t = 1, . . . T do"
IMPLEMENTATION/METHODS,0.5579710144927537,"Sample clients: Mt  max(bC · Mc, 1)
for each client m 2 Mt in parallel do"
IMPLEMENTATION/METHODS,0.5603864734299517,"Distribute server model ✓t−1 to client m
Estimate c
σ2m using Eqn. (13)
Compute local step lm from Eqn. (8) and local initialization ✓INIT"
IMPLEMENTATION/METHODS,0.5628019323671497,"m
via Eqn. (7)
✓t"
IMPLEMENTATION/METHODS,0.5652173913043478,m  LocalTrain(✓INIT
IMPLEMENTATION/METHODS,0.5676328502415459,"m , ⌘m, lm; Dm)
Server estimates c
σ2"
IMPLEMENTATION/METHODS,0.5700483091787439,"0 using Eqn. (14)
Server performs global aggregation and updates global model ✓t via Eqn. (11)"
IMPLEMENTATION/METHODS,0.572463768115942,"Discussion. The proposed Self-FL framework (described in Alg. 1) requires the selected clients to
send their updated local models ✓t"
IMPLEMENTATION/METHODS,0.5748792270531401,m and the intra-client uncertainty values σ2
IMPLEMENTATION/METHODS,0.5772946859903382,"m to the server. After
uncertainty-aware model aggregation, the server distributes the updated global model and the inter-
client uncertainty σ2"
IMPLEMENTATION/METHODS,0.5797101449275363,"0 to the clients. Therefore, the communication cost of Self-FL is the same level
as the standard FedAvg except for the additional cost of transmitting the uncertainty values (which
are scalars). Compared to baseline FedAvg, Self-FL requires additional computation to obtain the
inter-client and intra-client uncertainties via sample variance as shown in Eqn. (13) and (14). The
extra computation cost of Self-FL is small since these sample variances are updated in an online
manner as detailed in Appendix Subsection E. It is worth noting that our proposed personalization
method for balancing local and global training in FL is applicable to other tasks involving auxiliary
data since Self-FL does not depend on a particular formulation of the empirical risk."
RESULTS/EXPERIMENTS,0.5821256038647343,"4
Experimental Studies"
RESULTS/EXPERIMENTS,0.5845410628019324,"4.1
Experimental setup"
RESULTS/EXPERIMENTS,0.5869565217391305,"We use AWS p316 instances for all experiments. To evaluate the performance of Self-FL, we consider
synthetic data, images, texts, and audios. The loss in Alg. 1 can be general. For our experiments
on MNIST, FEMNIST, CIFAR10, Sent140, and wake-word detection, we used the cross-entropy
loss. Our empirical results on DL problems suggest that Self-FL provides promising personalization
performance in complex scenarios."
RESULTS/EXPERIMENTS,0.5893719806763285,"Synthetic Data. We construct a synthetic dataset based on the two-layer Bayesian model discussed
in Subsection 2.1 where each data point is a scalar. The FL system has a total of M = 20 clients,
and the task is to estimate the global and local model parameters. The heterogeneity level of the data
can be controlled by specifying the inter-client uncertainty σ2"
RESULTS/EXPERIMENTS,0.5917874396135265,"0 and the local dataset size Nm for each
client m. We construct two synthetic FL datasets, one with high homogeneity and one with high
heterogeneity, to investigate the performance of FL algorithms in different scenarios. The empirical
results are provided in Appendix Subsection G.1."
RESULTS/EXPERIMENTS,0.5942028985507246,"MNIST Data. This image dataset has 10 output classes and input dimension of 28 ⇥28. We use
a multinomial logistic regression model for this task. The FL system has a total of 1, 000 clients.
We use the same non-IID MNIST dataset as FedProx (Li, 2020), where each client has samples of
two-digit classes, and the local sample size of clients follows a power law (Li et al., 2020b)."
RESULTS/EXPERIMENTS,0.5966183574879227,"FEMNIST Data. The federated extended MNIST (FEMNIST) dataset has 62 output classes. The
FL system has M = 200 clients. We use the same approach as FedProx (Li et al., 2020b) for
heterogeneous data generation where ten lower-case characters (‘a’-‘j’) from EMNIST are selected,
and each client holds ﬁve classes of them."
RESULTS/EXPERIMENTS,0.5990338164251208,"CIFAR10 Data. This image dataset has images of dimension 32 ⇥32 ⇥3 and 10 output classes. We
use the non-i.i.d. data provided by the pFedMe repository Canh T. Dinh (2020). There are a total of
20 clients in the system where each user has images of three classes."
RESULTS/EXPERIMENTS,0.6014492753623188,"Sent140 Data. This is a text sentiment analysis dataset containing tweets from Sentiment140 Go
et al. (2009). It has two output classes and 772 clients. We generate non-i.i.d. data using the same
procedure as FedProx Li (2020). Detailed setup and our experimental results on Sent140 are provided
in Appendix Subsection G.3."
RESULTS/EXPERIMENTS,0.6038647342995169,"Private Wake-word Data. We also evaluate Self-FL on a private audio data from Amazon Alexa for
the wake-word detection task. This is a common task for smart home devices where the on-device
model needs to determine whether the user says a pre-speciﬁed keyword to wake up the device. This
task has two output classes, namely ‘wake-word detected’ and ‘wake-word absent.’ The audio stream
from the speaker is represented as a spectrogram and is fed into a convolution neural network (CNN).
The CNN is a stack of convolutional and max-pooling layers (11 in total). The number of trainable
parameters is around 3 · 106. The heterogeneity between clients comes from the intrinsic property
of different device types (e.g., determined by hardware and use scenarios). We use an in-house
far-ﬁeld corpus that contains de-identiﬁed far-ﬁeld data collected from millions of speakers under
different conditions with users’ content. This dataset contains 39 thousand hours of training data and
14 thousand hours of test data."
RESULTS/EXPERIMENTS,0.606280193236715,"To support practical FL systems where only a subset of clients participate in one communication
round (also known as client sampling), Self-FL can update the global model ✓t with smoothing
average. Particularly, given an activity rate (i.e., ratio of clients selected in each round) C 2 (0, 1),
we ﬁrst obtain the current estimation ˆ✓t by applying Eqn. (11) to the active clients. Then, the server
updates the global model using ✓t = (1 −C) · ✓t−1 + C · ˆ✓t. Updating the global model with a
smoothing average allows us to integrate historical information and reduce instability, especially for
a small activity rate."
RESULTS/EXPERIMENTS,0.6086956521739131,"4.2
Effectiveness on the image domain
Results on MNIST and FEMNIST. A description of MNIST and FEMNIST data are detailed in
Subsection 4.1. The activity rate is set to C = 0.1. For MNIST, we use learning rate ⌘= 0.03 and
batch size 10 as suggested in FedProx (Li, 2020). For FEMNIST, we use ⌘= 0.01 and batch size 10.
The FL training starts from scratch and runs for 200 rounds. For comparison, we implement FedAvg
and three other personalized FL techniques, DITTO (Li et al., 2021), pFedMe (Dinh et al., 2020), and
PerFedAvg (Fallah et al., 2020b) with the same hyper-parameter conﬁgurations."
RESULTS/EXPERIMENTS,0.6111111111111112,"(a) MNIST
(b) FEMNIST
Figure 1: Weighted client-level test accuracy in different rounds (with 0.1 activity rate)."
RESULTS/EXPERIMENTS,0.6135265700483091,"For real-world data, the theoretical value of the local training steps lm computed using Eqn. (16)
might be too large for the client (due to limitation of client’s computation/memory budget). In this ex-
periment, we determine the actual local training steps for Self-FL framework as ˆlm = min{lm, lmax}
where lmax is a pre-deﬁned cutoff threshold. We use a ﬁxed local training step of 20 for other FL
algorithms and set lmax = 40 for Self-FL. Note that σ2"
RESULTS/EXPERIMENTS,0.6159420289855072,"m represents the variance of ✓m (i.e., model
parameters such as neural coefﬁcients). In our experiments, σ2"
RESULTS/EXPERIMENTS,0.6183574879227053,"m is approximated using the empirical
variance of ✓m across rounds.
Figures 1a and 1b compare the convergence performance of different FL algorithms on MNIST and
FEMNIST, respectively. The horizontal axis denotes the communication round. The vertical axis
denotes the weighted test accuracy of individual clients, where the weight is proportional to the
sample size. We observe that: (i) Self-FL algorithm yields more stable convergence compared with
FedAvg and the other three personalized FL methods due to our smoothing average in aggregation;
(ii) Self-FL achieves the highest personalized accuracy when the global model converges."
RESULTS/EXPERIMENTS,0.6207729468599034,"To corroborate that the performance advantage of Self-FL does not come from a larger potential local
training steps (we set lmax = 40 for Self-FL), we perform an additional experiment where we use a
local step as l = 40 (instead of 20) for DITTO, pFedMe, and PerFedAvg on the FEMNIST dataset.
In this scenario, the test accuracy of these three FL algorithms is 71.33%, 68.87%, and 71.08%,
respectively. Our proposed method achieves a test accuracy of 76.93%. Furthermore, it is worth
noting that other FL methods do not have a principled way to determine the value of l. The adaptive
local steps in Self-FL also address this challenge."
RESULTS/EXPERIMENTS,0.6231884057971014,"Results on CIFAR10. We also perform experiments on the CIFAR-10 dataset (from the pFedMe
repository Canh T. Dinh (2020)) with the CNN model from PyTorch example PyTorch (2022). In
each round, we randomly select 5 out of 20 clients to participate in FL training. We use a learning rate
of 0.01 for all FL algorithms and set the local training step as 40 for the baseline methods. Figure 2a
visualizes the test accuracy comparison, showing that Self-FL achieves a higher accuracy."
RESULTS/EXPERIMENTS,0.6256038647342995,"(a) CIFAR10
(b) FEMNIST"
RESULTS/EXPERIMENTS,0.6280193236714976,Figure 2: Weighted client-level test accuracy.
RESULTS/EXPERIMENTS,0.6304347826086957,"Ablation study on Self-FL. Recall that Self-FL consists of three key components: (i) Adjusting local
initialization; (ii) Dynamic local training steps; (iii) Variance-weighted global aggregation (Section 3).
To investigate the effect of each component, we perform an ablation study where we apply the full
deployment of Self-FL and only only component of it. Figure 2b compares the test accuracy of the
global model on FEMNIST benchmark in these four settings. We can observe that adjusting the local
initialization at each round (Eqn. (10)) gives the highest contribution to Self-FL’s performance."
RESULTS/EXPERIMENTS,0.6328502415458938,"To characterize the distribution of personalized performance across clients, we deﬁne two new metrics
to evaluate different FL algorithms: (i) weighted test accuracy of clients that have top 10% most
samples; (ii) worst 10% clients’ average test accuracy. The evaluation results on FEMNIST (where the
client sample size ranges from 1 to 206) are shown in Table 1 (standard errors in parentheses). We can
observe that Self-FL outperforms other FL algorithms in terms of these auxiliary metrics. In addition,
we visualize the distribution of Self-FL’s personalization performance in Figure 3 by plotting the
histograms of the user-level test accuracy. This user-level accuracy is obtained by evaluating the
ﬁnal local model (acquired by Algorithm 1) of each client on his local dataset. The same metric
is measured for the baseline FedAvg. We can see from Figure 3 that the user-level test accuracy
distribution under Self-FL is shifted toward the right side of its counterpart under baseline FedAvg,
suggesting that Self-FL effectively improves the local model performance for individual clients and
achieves the goal of personalization."
RESULTS/EXPERIMENTS,0.6352657004830918,Table 1: Test accuracy comparison on FEMNIST.
RESULTS/EXPERIMENTS,0.6376811594202898,"FL Alg.
FedAvg
DITTO
pFedMe
PerFedAvg
Self-FL"
RESULTS/EXPERIMENTS,0.6400966183574879,"Top 10%
most samples"
RESULTS/EXPERIMENTS,0.642512077294686,"70.48%
(0.07%)"
RESULTS/EXPERIMENTS,0.644927536231884,"70.58%
(0.14%)"
RESULTS/EXPERIMENTS,0.6473429951690821,"72.76%
(0.28%)"
RESULTS/EXPERIMENTS,0.6497584541062802,"74.95%
(0.56%)"
RESULTS/EXPERIMENTS,0.6521739130434783,"76.24%
(0.07%)
Worst 10%
user avg acc"
RESULTS/EXPERIMENTS,0.6545893719806763,"0%
(0%)"
RESULTS/EXPERIMENTS,0.6570048309178744,"0%
(0%)"
RESULTS/EXPERIMENTS,0.6594202898550725,"17.97%
(1.23%)"
RESULTS/EXPERIMENTS,0.6618357487922706,"24.51%
(1.55%)"
RESULTS/EXPERIMENTS,0.6642512077294686,"37.01%
(1.57%)"
RESULTS/EXPERIMENTS,0.6666666666666666,"(a) FEMNIST
(b) MNIST
(c) CIFAR10"
RESULTS/EXPERIMENTS,0.6690821256038647,Figure 3: Distribution of the user-level personalized performance on the test set.
RESULTS/EXPERIMENTS,0.6714975845410628,"4.3
Effectiveness on the audio domain"
RESULTS/EXPERIMENTS,0.6739130434782609,"In this section, we evaluate the performance of Self-FL on an audio dataset (Subsection 4.1) for wake-
word detection. Particularly, we use a CNN that is pre-trained on the training data of different device
types (i.e., heterogeneous data) as the initial global model to warm-start FL training for all evaluated
FL algorithms. The personalization task aims to improve the wake-word detection performance at the
device type level. In this experiment, we assume there are ﬁve clients in the FL system. Each client
only has the training data for a speciﬁc device without data overlapping. Furthermore, all the clients
participate in each communication round. Note that FedAvg (McMahan et al., 2017) and DITTO (Li
et al., 2021) typically use the sample size-based weighted average to aggregate models, which do not
take data heterogeneity into account. For comparison, we implement FedAvg and DITTO with both
equal-weighted and sample size-based weighted model averaging (denoted by the sufﬁx “-e’ and
‘-w’, respectively) during aggregation. For meta-learning-based PerFedAvg (Fallah et al., 2020b), we"
RESULTS/EXPERIMENTS,0.6763285024154589,"use its ﬁrst-order approximation and equal-weighted aggregation. We did not report pFedMe on this
dataset because we found it did not converge with various hyper-parameters."
RESULTS/EXPERIMENTS,0.678743961352657,"Evaluation metric. One can control the trade-off between false accepts and false rejects of wake-
word detection by tuning the threshold. Since we use a pre-trained model to warm-start FL, we
ﬁrst evaluate the detection performance of this pre-trained model as the baseline. To compare the"
RESULTS/EXPERIMENTS,0.6811594202898551,"performance of different FL algorithms, we use the relative false accept (FA) value of the resulting
model when the corresponding relative false reject (FR) is close to one as the metric. So a relative FA
smaller than one is preferred. Here, the relative FA and FR are computed with respect to the baseline.
We detail the results in two scenarios below."
RESULTS/EXPERIMENTS,0.6835748792270532,"Table 2a summarizes the results of the updated global model. Recall that a smaller relative FA
indicates better performance. Each column reports the relative FA for a speciﬁc device type. The
results show that Self-FL achieves the lowest relative FA. Several updated global models have worse
performance than the baseline model, e.g., for FedAvg-w and DITTO-w in Table 2a. This is due
to the setting here that local models are initialized from a pre-trained model, and the comparison
is relative to that warm-start. Because clients’ data are highly heterogeneous, a sample size-based
aggregation rule used in FedAvg-w and Ditto-w results in a deteriorated global model compared
with the original start. We provide ablation studies in the client sampling setting in the Appendix
Subsection G.4, which show Self-FL still performs well."
RESULTS/EXPERIMENTS,0.6859903381642513,Table 2: Detection performance (relative FA) of model on a test dataset.
RESULTS/EXPERIMENTS,0.6884057971014492,"FL methods
Device Types
A
B
C
D
E"
RESULTS/EXPERIMENTS,0.6908212560386473,"Self-FL
0.92
0.94
0.91
0.91
1.01
FedAvg-w
8.39
4.00
12.80
8.61
10.62
FedAvg-e
0.97
0.96
1.00
0.92
1.00
DITTO-w
8.38
4.00
12.75
8.61
10.23
DITTO-e
0.97
0.95
1.00
0.93
0.99
PerFedAvg
1.06
0.98
1.08
0.93
1.01"
RESULTS/EXPERIMENTS,0.6932367149758454,(a) Global model.
RESULTS/EXPERIMENTS,0.6956521739130435,"FL methods
Device Type
A
B
C
D
E"
RESULTS/EXPERIMENTS,0.6980676328502415,"Self-FL
0.93
0.91
0.90
0.90
0.99
FedAvg-e
0.95
0.95
0.93
0.91
0.98
DITTO-e
0.97
0.96
0.93
0.91
0.96
PerFedAvg
1.02
1.11
1.08
1.00
0.93"
RESULTS/EXPERIMENTS,0.7004830917874396,(b) Personalized model.
RESULTS/EXPERIMENTS,0.7028985507246377,"We further compare the personalization performance of Self-FL with FedAvg-e and two personalized
FL algorithms, DITTO-e and PerFedAvg, on each device type’s test data and summarize the results
in Table 2b. We do not consider FedAvg-w and DITTO-w in this experiment since they result in
performance degradation, as seen from Table 2a. One can see that Self-FL outperforms the other
methods across all device types, thus demonstrating a better personalization capability."
CONCLUSION/DISCUSSION,0.7053140096618358,"5
Concluding Remarks"
CONCLUSION/DISCUSSION,0.7077294685990339,"In this paper, we proposed Self-FL to address the challenge of balancing local model regularization
and global model aggregation in personalized FL. Its key component is using uncertainty-driven local
training steps and aggregation rules instead of conventional local ﬁne-tuning and size-based weights.
Overall, Self-FL connects personalized FL with hierarchical modeling and utilizes uncertainty
quantiﬁcation to drive personalization. Extensive empirical studies of Self-FL show its promising
performance. We do not envision any negative societal impact of the work."
CONCLUSION/DISCUSSION,0.7101449275362319,"The Appendix contains further experimental studies, remarks, related works, and technical proofs."
CONCLUSION/DISCUSSION,0.7125603864734299,Acknowledgments and Disclosure of Funding
CONCLUSION/DISCUSSION,0.714975845410628,"This work was done when Huili Chen worked as a Applied Scientist Intern at Alexa AI, Amazon."
REFERENCES,0.717391304347826,References
REFERENCES,0.7198067632850241,"Jakub Konevcny, H Brendan McMahan, Felix X Yu, Peter Richtárik, Ananda Theertha Suresh, and"
REFERENCES,0.7222222222222222,"Dave Bacon. Federated learning: Strategies for improving communication efﬁciency. arXiv
preprint arXiv:1610.05492, 2016."
REFERENCES,0.7246376811594203,"Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas."
REFERENCES,0.7270531400966184,"Communication-efﬁcient learning of deep networks from decentralized data. In Proc. AISTATS,
pages 1273–1282. PMLR, 2017."
REFERENCES,0.7294685990338164,"Wei Yang Bryan Lim, Nguyen Cong Luong, Dinh Thai Hoang, Yutao Jiao, Ying-Chang Liang,"
REFERENCES,0.7318840579710145,"Qiang Yang, Dusit Niyato, and Chunyan Miao. Federated learning in mobile edge networks: A
comprehensive survey. IEEE Communications Surveys & Tutorials, 2020."
REFERENCES,0.7342995169082126,"Jie Ding, Eric Tramel, Anit Kumar Sahu, Shuang Wu, Salman Avestimehr, and Tao Zhang. Federated"
REFERENCES,0.7367149758454107,"learning challenges and opportunities: An outlook. International Conference on Acoustics, Speech,
and Signal Processing (ICASSP), 2022."
REFERENCES,0.7391304347826086,"Amanda Purington, Jessie G Taft, Shruti Sannon, Natalya N Bazarova, and Samuel Hardman Taylor."
REFERENCES,0.7415458937198067,"""alexa is my new bff"" social roles, user satisfaction, and personiﬁcation of the amazon echo.
In Proceedings of the 2017 CHI conference extended abstracts on human factors in computing
systems, pages 2853–2859, 2017."
REFERENCES,0.7439613526570048,"Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet S Talwalkar. Federated multi-task"
REFERENCES,0.7463768115942029,"learning. In Advances in Neural Information Processing Systems, pages 4424–4434, 2017."
REFERENCES,0.748792270531401,"Yihan Jiang, Jakub Konevcn`y, Keith Rush, and Sreeram Kannan. Improving federated learning"
REFERENCES,0.751207729468599,"personalization via model agnostic meta learning. arXiv preprint arXiv:1909.12488, 2019."
REFERENCES,0.7536231884057971,"Mikhail Khodak, Maria-Florina F Balcan, and Ameet S Talwalkar. Adaptive gradient-based meta-"
REFERENCES,0.7560386473429952,"learning methods. In Advances in Neural Information Processing Systems, pages 5917–5928,
2019."
REFERENCES,0.7584541062801933,"Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. Personalized federated learning: A meta-"
REFERENCES,0.7608695652173914,"learning approach. arXiv preprint arXiv:2002.07948, 2020a."
REFERENCES,0.7632850241545893,"Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. Personalized federated learning: A meta-"
REFERENCES,0.7657004830917874,"learning approach. arXiv preprint arXiv:2002.07948, 2020b."
REFERENCES,0.7681159420289855,"Maruan Al-Shedivat, Liam Li, Eric Xing, and Ameet Talwalkar. On data efﬁciency of meta-learning."
REFERENCES,0.7705314009661836,"In International Conference on Artiﬁcial Intelligence and Statistics, pages 1369–1377. PMLR,
2021."
REFERENCES,0.7729468599033816,"Kangkang Wang, Rajiv Mathews, Chloé Kiddon, Hubert Eichner, FranKcoise Beaufays, and Daniel"
REFERENCES,0.7753623188405797,"Ramage. Federated evaluation of on-device personalization. arXiv preprint arXiv:1910.10252,
2019."
REFERENCES,0.7777777777777778,"Yishay Mansour, Mehryar Mohri, Jae Ro, and Ananda Theertha Suresh. Three approaches for"
REFERENCES,0.7801932367149759,"personalization with applications to federated learning. arXiv preprint arXiv:2002.10619, 2020."
REFERENCES,0.782608695652174,Daliang Li and Junpu Wang. Fedmd: Heterogenous federated learning via model distillation. arXiv
REFERENCES,0.785024154589372,"preprint arXiv:1910.03581, 2019."
REFERENCES,0.7874396135265701,"Ang Li, Jingwei Sun, Binghui Wang, Lin Duan, Sicheng Li, Yiran Chen, and Hai Li. Lotteryﬂ:"
REFERENCES,0.7898550724637681,"Personalized and communication-efﬁcient federated learning with lottery ticket hypothesis on
non-iid datasets. arXiv preprint arXiv:2008.03371, 2020a."
REFERENCES,0.7922705314009661,"Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia Smith. Ditto: Fair and robust federated learning"
REFERENCES,0.7946859903381642,"through personalization. In International Conference on Machine Learning, pages 6357–6368.
PMLR, 2021."
REFERENCES,0.7971014492753623,"Othmane Marfoq, Giovanni Neglia, Aurélien Bellet, Laetitia Kameni, and Richard Vidal. Federated"
REFERENCES,0.7995169082125604,"multi-task learning under a mixture of distributions. Advances in Neural Information Processing
Systems, 34, 2021."
REFERENCES,0.8019323671497585,"Paul Vanhaesebrouck, Aurélien Bellet, and Marc Tommasi. Decentralized collaborative learning"
REFERENCES,0.8043478260869565,"of personalized models over networks. In Artiﬁcial Intelligence and Statistics, pages 509–517.
PMLR, 2017."
REFERENCES,0.8067632850241546,"Filip Hanzely, Slavomír Hanzely, Samuel Horváth, and Peter Richtárik. Lower bounds and optimal"
REFERENCES,0.8091787439613527,"algorithms for personalized federated learning. Advances in Neural Information Processing
Systems, 33:2304–2315, 2020."
REFERENCES,0.8115942028985508,"Yutao Huang, Lingyang Chu, Zirui Zhou, Lanjun Wang, Jiangchuan Liu, Jian Pei, and Yong Zhang."
REFERENCES,0.8140096618357487,"Personalized cross-silo federated learning on non-iid data. In Proceedings of the AAAI Conference
on Artiﬁcial Intelligence, volume 35, pages 7865–7873, 2021."
REFERENCES,0.8164251207729468,"Canh T Dinh, Nguyen H Tran, and Tuan Dung Nguyen. Personalized federated learning with moreau"
REFERENCES,0.8188405797101449,"envelopes. arXiv preprint arXiv:2006.08848, 2020."
REFERENCES,0.821256038647343,"Aviv Shamsian, Aviv Navon, Ethan Fetaya, and Gal Chechik. Personalized federated learning using"
REFERENCES,0.8236714975845411,"hypernetworks. In International Conference on Machine Learning, pages 9489–9502. PMLR,
2021."
REFERENCES,0.8260869565217391,"Michael Zhang, Karan Sapra, Sanja Fidler, Serena Yeung, and Jose M Alvarez. Personalized"
REFERENCES,0.8285024154589372,"federated learning with ﬁrst order model optimization. In International Conference on Learning
Representations, 2020."
REFERENCES,0.8309178743961353,Tian Li. Github repo of paper federated optimization in heterogeneous networks. https://
REFERENCES,0.8333333333333334,"github.com/litian96/FedProx, July 2020."
REFERENCES,0.8357487922705314,"Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith."
REFERENCES,0.8381642512077294,"Federated optimization in heterogeneous networks. In Proceedings of Machine Learning and
Systems, volume 2, pages 429–450, 2020b."
REFERENCES,0.8405797101449275,"Tuan Dung Nguyen Canh T. Dinh, Nguyen H. Tran. Personalized federated learning with moreau"
REFERENCES,0.8429951690821256,"envelopes (neurips 2020). https://github.com/CharlieDinh/pFedMe, Jan 2020."
REFERENCES,0.8454106280193237,"Alec Go, Richa Bhayani, and Lei Huang. Twitter sentiment classiﬁcation using distant supervision."
REFERENCES,0.8478260869565217,"CS224N project report, Stanford, 1(12):2009, 2009."
REFERENCES,0.8502415458937198,PyTorch. Training a classiﬁer. https://pytorch.org/tutorials/beginner/blitz/
REFERENCES,0.8526570048309179,"cifar10_tutorial.html, April 2022."
REFERENCES,0.855072463768116,"Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir"
REFERENCES,0.857487922705314,"Ivanov, Chloe Kiddon, Jakub Konevcn`y, Stefano Mazzocchi, H Brendan McMahan, et al. Towards
federated learning at scale: System design. arXiv preprint arXiv:1902.01046, 2019."
REFERENCES,0.8599033816425121,"Dan Alistarh, Demjan Grubic, Jerry Li, Ryota Tomioka, and Milan Vojnovic. Qsgd: Communication-"
REFERENCES,0.8623188405797102,"efﬁcient sgd via gradient quantization and encoding. In Advances in Neural Information Processing
Systems, pages 1709–1720, 2017."
REFERENCES,0.8647342995169082,"Nikita Ivkin, Daniel Rothchild, Enayat Ullah, Ion Stoica, Raman Arora, et al. Communication-"
REFERENCES,0.8671497584541062,"efﬁcient distributed sgd with sketching. In Advances in Neural Information Processing Systems,
pages 13144–13154, 2019."
REFERENCES,0.8695652173913043,"Enmao Diao, Jie Ding, and Vahid Tarokh. HeteroFL: Computation and communication efﬁcient"
REFERENCES,0.8719806763285024,"federated learning for heterogeneous clients. International Conference on Learning Representations
(ICLR), 2020."
REFERENCES,0.8743961352657005,"Maruan Al-Shedivat, Jennifer Gillenwater, Eric Xing, and Afshin Rostamizadeh.
Federated
learning via posterior averaging: A new perspective and practical algorithms. arXiv preprint
arXiv:2010.05273, 2020."
REFERENCES,0.8768115942028986,Hong-You Chen and Wei-Lun Chao. Fedbe: Making bayesian model ensemble applicable to federated
REFERENCES,0.8792270531400966,"learning. arXiv preprint arXiv:2009.01974, 2020."
REFERENCES,0.8816425120772947,"Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Konevcn`y,"
REFERENCES,0.8840579710144928,"Sanjiv Kumar, and H Brendan McMahan. Adaptive federated optimization. arXiv preprint
arXiv:2003.00295, 2020."
REFERENCES,0.8864734299516909,"Mikhail Khodak, Renbo Tu, Tian Li, Liam Li, Maria-Florina F Balcan, Virginia Smith, and Ameet"
REFERENCES,0.8888888888888888,"Talwalkar. Federated hyperparameter tuning: Challenges, baselines, and connections to weight-
sharing. Advances in Neural Information Processing Systems, 34, 2021."
REFERENCES,0.8913043478260869,"Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Challenges,"
REFERENCES,0.893719806763285,"methods, and future directions. IEEE Signal Processing Magazine, 37(3):50–60, 2020c."
REFERENCES,0.8961352657004831,Takayuki Nishio and Ryo Yonetani. Client selection for federated learning with heterogeneous
REFERENCES,0.8985507246376812,"resources in mobile edge. In ICC 2019-2019 IEEE International Conference on Communications
(ICC), pages 1–7. IEEE, 2019."
REFERENCES,0.9009661835748792,"Tian Li, Maziar Sanjabi, Ahmad Beirami, and Virginia Smith. Fair resource allocation in federated"
REFERENCES,0.9033816425120773,"learning. arXiv preprint arXiv:1905.10497, 2019."
REFERENCES,0.9057971014492754,"Xun Xian, Xinran Wang, Jie Ding, and Reza Ghanadan. Assisted learning: a framework for multi-"
REFERENCES,0.9082125603864735,"organization learning. Proc. NeurIPS 2020, 2020."
REFERENCES,0.9106280193236715,"Enmao Diao, Jie Ding, and Vahid Tarokh.
Gradient assisted learning.
arXiv preprint
arXiv:2106.01425, 2021a."
REFERENCES,0.9130434782608695,"Enmao Diao, Vahid Tarokh, and Jie Ding. Privacy-preserving multi-target multi-domain recommender"
REFERENCES,0.9154589371980676,"systems with assisted autoencoders. arXiv preprint arXiv:2110.13340, 2021b."
REFERENCES,0.9178743961352657,"Xinran Wang, Yu Xiang, Jun Gao, and Jie Ding. Information laundering for model privacy. Proc."
REFERENCES,0.9202898550724637,"ICLR, 2021."
REFERENCES,0.9227053140096618,"Aad W Van der Vaart. Asymptotic statistics, volume 3. Cambridge university press, 2000."
REFERENCES,0.9251207729468599,"Jeffrey Pennington, Richard Socher, and Christopher D Manning. Glove: Global vectors for word"
REFERENCES,0.927536231884058,"representation. In Proceedings of the 2014 conference on empirical methods in natural language
processing (EMNLP), pages 1532–1543, 2014."
REFERENCES,0.9299516908212561,"Enmao Diao, Jie Ding, and Vahid Tarokh. SemiFL: Communication efﬁcient semi-supervised"
REFERENCES,0.9323671497584541,"federated learning with unlabeled clients. arXiv preprint arXiv:2106.01432, 2021c."
REFERENCES,0.9347826086956522,"Jiawei Zhang, Jie Ding, and Yuhong Yang. A binary regression adaptive goodness-of-ﬁt test. Journal"
REFERENCES,0.9371980676328503,"of the American Statistical Association, 2021."
OTHER,0.9396135265700483,Checklist
OTHER,0.9420289855072463,1. For all authors...
OTHER,0.9444444444444444,(a) Do the main claims made in the abstract and introduction accurately reﬂect the paper’s
OTHER,0.9468599033816425,"contributions and scope? [Yes] Our empirical results in Section 4 justify ours claims.
(b) Did you describe the limitations of your work? [Yes] We discuss our limitations in"
OTHER,0.9492753623188406,"Appendix Section G.7.
(c) Did you discuss any potential negative societal impacts of your work? [Yes] We do"
OTHER,0.9516908212560387,"not envision any potential negative societal impacts of this work and mentioned that in
Section 5.
(d) Have you read the ethics review guidelines and ensured that your paper conforms to"
OTHER,0.9541062801932367,"them? [Yes]
2. If you are including theoretical results..."
OTHER,0.9565217391304348,(a) Did you state the full set of assumptions of all theoretical results? [Yes] . We state the
OTHER,0.9589371980676329,"full assumptions in Section 2 of the main body and Section D in the Appendix.
(b) Did you include complete proofs of all theoretical results? [Yes] . We provide complete"
OTHER,0.961352657004831,"proofs in Section 2, Appendix Section D and Section H.
3. If you ran experiments..."
OTHER,0.9637681159420289,"(a) Did you include the code, data, and instructions needed to reproduce the main ex-"
OTHER,0.966183574879227,"perimental results (either in the supplemental material or as a URL)? [Yes] We have
included the codes in the supplementary material.
(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they"
OTHER,0.9685990338164251,"were chosen)? [Yes] . We specify the training details in Section 4.1 and Appendix
Section G.
(c) Did you report error bars (e.g., with respect to the random seed after running exper-"
OTHER,0.9710144927536232,"iments multiple times)? [Yes] . We report the standard error of our experiments in
Section 4 and Appendix Section G."
OTHER,0.9734299516908212,"(d) Did you include the total amount of compute and the type of resources used (e.g.,"
OTHER,0.9758454106280193,"type of GPUs, internal cluster, or cloud provider)? [Yes] . We provide the computing
resources in Section 4.1.
4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets..."
OTHER,0.9782608695652174,"(a) If your work uses existing assets, did you cite the creators? [Yes] . We use the open-"
OTHER,0.9806763285024155,"sourced GitHub repository of FedProx, pFedMe, and PerFedAvg in our experiments
(Section 4) and we cited the authors.
(b) Did you mention the license of the assets? [Yes] ."
OTHER,0.9830917874396136,"(c) Did you include any new assets either in the supplemental material or as a URL? [No]
(d) Did you discuss whether and how consent was obtained from people whose data you’re"
OTHER,0.9855072463768116,"using/curating? [N/A]
(e) Did you discuss whether the data you are using/curating contains personally identiﬁable"
OTHER,0.9879227053140096,"information or offensive content? [N/A]
5. If you used crowdsourcing or conducted research with human subjects..."
OTHER,0.9903381642512077,"(a) Did you include the full text of instructions given to participants and screenshots, if"
OTHER,0.9927536231884058,"applicable? [N/A]
(b) Did you describe any potential participant risks, with links to Institutional Review"
OTHER,0.9951690821256038,"Board (IRB) approvals, if applicable? [N/A]
(c) Did you include the estimated hourly wage paid to participants and the total amount"
OTHER,0.9975845410628019,spent on participant compensation? [N/A]
