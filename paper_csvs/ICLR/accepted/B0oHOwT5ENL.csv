Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0026455026455026454,"A deep equilibrium (DEQ) model abandons traditional depth by solving for the
ﬁxed point of a single nonlinear layer fθ. This structure enables decoupling the
internal structure of the layer (which controls representational capacity) from how
the ﬁxed point is actually computed (which impacts inference-time efﬁciency),
which is usually via classic techniques such as Broyden’s method or Anderson
acceleration. In this paper, we show that one can exploit such decoupling and
substantially enhance this ﬁxed point computation using a custom neural solver.
Speciﬁcally, our solver uses a parameterized network to both guess an initial value
of the optimization and perform iterative updates, in a method that generalizes
a learnable form of Anderson acceleration and can be trained end-to-end in an
unsupervised manner. Such a solution is particularly well suited to the implicit
model setting, because inference in these models requires repeatedly solving for
a ﬁxed point of the same nonlinear layer for different inputs, a task at which our
network excels. Our experiments show that these neural equilibrium solvers are
fast to train (only taking an extra 0.9-1.1% over the original DEQ’s training time),
require few additional parameters (1-3% of the original model size), yet lead to a
2× speedup in DEQ network inference without any degradation in accuracy across
numerous domains and tasks."
INTRODUCTION,0.005291005291005291,"1
INTRODUCTION"
INTRODUCTION,0.007936507936507936,"Recent progress on implicit networks, such as Neural ODEs (NODEs) (Chen et al., 2018b;
Dupont et al., 2019; Rubanova et al., 2019; Jia & Benson, 2019; Kelly et al., 2020) and deep
equilibrium (DEQ) models (Bai et al., 2019; Winston & Kolter, 2020; Kawaguchi, 2021; Bai
et al., 2020; Gilton et al., 2021), has motivated this novel class of networks to the forefront
of deep learning research.
Instead of stacking a series of operators hierarchically, implicit"
INTRODUCTION,0.010582010582010581,"0
100
200
300
400
500
600
700
Inference ms/batch (size=12) 20 30 40 50 60"
INTRODUCTION,0.013227513227513227,Validation perplexity
INTRODUCTION,0.015873015873015872,"DEQ
DEQ (regularized)
HyperDEQ (reg.) (ours)"
INTRODUCTION,0.018518518518518517,Transformer-XL
INTRODUCTION,0.021164021164021163,"Figure 1: Pareto curves of the same DEQ
with different solvers on WikiText-103
language modeling (on 1 GPU)."
INTRODUCTION,0.023809523809523808,"models deﬁne their outputs as solutions to nonlinear dy-
namical systems. For example, DEQ models (which
this paper will focus on) deﬁne their outputs as ﬁxed
points (a.k.a. equilibria) of a layer fθ and input x; i.e.,
output z⋆= fθ(z⋆,x). Then, in the backward pass, a
DEQ implicitly differentiates through the ﬁnal ﬁxed point
z⋆(Krantz & Parks, 2012; Bai et al., 2019; Fung et al.,
2021), regardless of how forward pass is computed in
the ﬁrst place. Such insulated forward and backward
passes enable an equilibrium model to leverage arbitrary
black-box solvers to reach the ﬁxed points without storing
intermediate activations, thus consuming constant train-
ing memory. Recent works have successfully applied
the DEQ framework on high-dimensional tasks such as
language modeling (Merity et al., 2017) and semantic segmentation (Cordts et al., 2016), with
performance competitive with architectures like Transformers (Vaswani et al., 2017; Dai et al., 2019)."
INTRODUCTION,0.026455026455026454,"However, it is also well-known that these implicit models are slow, which is (arguably) their single
most limiting drawback compared to traditional feedforward models (Duvenaud et al., 2020; Dupont
et al., 2019; Bai et al., 2021). For example, Neural ODEs could take well over 100 forward solver
iterations (i.e., evaluations of fθ) even on MNIST classiﬁcation; DEQs can scale to realistic tasks, but"
INTRODUCTION,0.0291005291005291,Published as a conference paper at ICLR 2022
INTRODUCTION,0.031746031746031744,"the overhead of ﬁxed-point solvers is magniﬁed by the task scales, rendering the model 3-6× slower
than state-of-the-art (SOTA) explicit networks (Vaswani et al., 2017; Wang et al., 2020) at inference."
INTRODUCTION,0.03439153439153439,"Can we make equilibrium models faster by taking advantage of their implicitness? One beneﬁt of
DEQ’s formulation is the fact that they decouple the representational capacity (determined by fθ)
and forward computation (controlled by the solver), which is not possible in any explicit model (e.g.,
ResNet-101 (He et al., 2016)). Hence, given a trained DEQ, one can trade off inference time and the
accuracy of the estimated ﬁxed point by simply reducing the number of solver iterations. This yields
a speed/accuracy trade-off curve, as shown in Fig. 1. However, this trade-off (i.e., movements along
the pareto curves) can be highly risky: as we gradually increase inference speed by compromising
the quality of ﬁxed point estimates, model accuracy also degrades drastically."
INTRODUCTION,0.037037037037037035,"In this work, we show that we can shift the DEQ speed/accuracy trade-off curve by exploiting such
decoupling to customize the ﬁxed-point solving. Prior work on equilibrium models relies on classic
solvers, which are manually designed and generic (e.g., Broyden’s Method (Broyden, 1965)). We
propose a tiny, learnable, and content-aware solver module that is automatically customized to a
speciﬁc DEQ. Our hypersolver consists of two parts. First, we introduce a learned initializer that
estimates a good starting point for the optimization. Second, we introduce a generalized parameterized
version of Anderson mixing (Anderson, 1965) that learns the iterative updates as an input-dependent
temporal process. Overall, the hypersolver consumes a tiny amount of parameters. Since fθ is frozen
when the hypersolver is trained, the training is very fast and does not compromise generalization."
INTRODUCTION,0.03968253968253968,"Our experiments apply this approach to diverse domains with large datasets: WikiText-103 language
modeling (Merity et al., 2017), ImageNet classiﬁcation (Deng et al., 2009), and Cityscapes segmenta-
tion with megapixel images (Cordts et al., 2016). Our results suggest that neural deep equilibrium
solvers add little overhead to training (only taking an extra 0.9-1.1% over the original DEQ’s training
time), are extremely compact (about 1-3% of the DEQ’s model size), and lead to a consistent and
universal 1.6-2× acceleration of inference with no compromise in accuracy. Overall, we believe this
paper achieves two major objectives, both vital for the quickly growing community studying implicit
models: ﬁrst, we advance these large-scale implicit models to a much more practical level across
architectures (e.g., almost as fast as Transformers); and second, we formally bring up and exploit this
valuable notion of how implicit layers decouple representational capacity and forward computation,
opening a new door to signiﬁcantly advancing the agenda of deploying implicit models in practice."
RELATED WORK,0.042328042328042326,"2
RELATED WORK"
RELATED WORK,0.04497354497354497,"Deep Implicit Models.
Recent research on models without a prescribed computation graph or
hierarchical stacking led to a new class of deep learning models where the output is deﬁned as the
solution of nonlinear systems (Duvenaud et al., 2020; Amos & Kolter, 2017; Chen et al., 2018b;
Wang et al., 2019; El Ghaoui et al., 2019; Bai et al., 2019; 2020; Gould et al., 2019; Gu et al., 2020;
Wang et al., 2020). Neural ODEs (NODEs) (Chen et al., 2018b; Dupont et al., 2019), for example,
model inﬁntesimal steps of a residual layer fθ by solving an initial value problem (IVP) (Coddington
& Levinson, 1955) parameterized by this layer; i.e. ∂z"
RELATED WORK,0.047619047619047616,"∂t = fθ(z(t),t), z(0) = x, t = 0,...,T. Deep
equilibrium (DEQ) models (Bai et al., 2019; Winston & Kolter, 2020) seek to directly solve for
a “ﬁxed-point” representation corresponding to a (not necessarily residual) layer fθ and input x;
i.e. z⋆= fθ(z⋆,x). Implicit models are appealing in part due to their analytical backward passes
(e.g., adjoint method or implicit differentiation) that only depend on the ﬁnal output, which can
dramatically reduce memory consumption during training."
RELATED WORK,0.05026455026455026,"Regularizing Implicit Models.
Implicit models are known to be slow during training and inference.
To address this, recent works have developed certain regularization methods that encourage these
models to be more stable and thus easier to solve. For NODEs, Dupont et al. (2019) augment the
neural ODE hidden state; Grathwohl et al. (2019) use spectral normalization (Miyato et al., 2018)
to stabilize the NODE dynamics; Kelly et al. (2020) regularize higher-order time derivatives of the
ODE system. For DEQs, Winston & Kolter (2020) propose a parameterization of fθ that guarantees
stability of DEQ models (i.e., unique ﬁxed point). Fung et al. (2021) show that one can simplify
the implicit differentiation of Lipschitz DEQs (Revay et al., 2020) to accelerate the backward pass.
Bai et al. (2021) summarize DEQ stability issues and propose to address them by regularizing the
Jacobian matrices of equilibrium layers. In comparison, our work focuses on the solver rather than
the layer fθ, and is orthogonal and complementary to regularization methods."
RELATED WORK,0.05291005291005291,Published as a conference paper at ICLR 2022
RELATED WORK,0.05555555555555555,"Improving Implicit Model Solvers.
Of particular relevance to our work are recent advances in
the Neural ODE literature that improve the ODE ﬂow solver. Poli et al. (2020) introduce a Neural
ODE formulation that adds a learnable residual ﬁtting step to the original solver steps, aiming to
approximate the higher-order terms of canonical ODE solvers (e.g., Euler’s method) on each solution
checkpoint along the ODE path. Another recent work (Kidger et al., 2021) focuses on improving the
adjoint method by replacing the usual L2 norm with a more ﬂexible seminorm to make the NODE
backward solver faster. To the best of our knowledge, no such solver improvement has been explored
in the equilibrium model context. Unlike Neural ODEs, DEQs do not use ODE solvers and do not
have unique & well-deﬁned trajectories to the solution (even if one starts at the same initial point
z[0]). Our work is the ﬁrst to propose a neural ﬁxed-point solver for equilibrium models."
RELATED WORK,0.0582010582010582,"Learning to Optimize/Learn.
An important line of work has explored learnable optimization
methods. Li & Malik (2016; 2017) propose to use reinforcement learning (guided policy search)
to learn a new generic unconstrained continuous optimization algorithm, where the training set
consists of numerous randomly generated objective functions. Andrychowicz et al. (2016) intro-
duce the “learning to learn” (L2L) framework, where a gradient update rule for the parameters is
learned by an LSTM with a pre-deﬁned horizon T of parameter update steps. However, such ap-
proaches (Andrychowicz et al., 2016; Chen et al., 2017; Wichrowska et al., 2017; Ravi & Larochelle,
2016) have had some difﬁculty in generalizing to larger tasks due to the need to unroll for a large T
(e.g., 128 (Andrychowicz et al., 2016)). Our work is related to these prior efforts in L2L, but differs
in important ways. First, the L2L framework aims to learn a learning algorithm that will be applied
to multiple models and tasks, while we aim to ﬁt the nonlinear dynamics of a speciﬁc implicit model.
Second, the optimization we tackle is not on the parameter space, but on the hidden unit space; this
means that the RNN optimizer used in L2L would not work here, because the ﬁxed points themselves
can be of variable sizes at test time (e.g., sequence lengths, image sizes). Third, while L2L methods
cannot know a priori what a good “initial guess” of optimal parameters may be, we show that it is
possible and reasonable to infer this in the hidden unit space with implicit models. Concurrent to
our work, Venkataraman & Amos (2021) studies an RNN-based learnable ﬁxed-point acceleration
scheme speciﬁcally in the application of convex cone programming."
RELATED WORK,0.06084656084656084,"3
BACKGROUND: EQUILIBRIUM MODELS AND FIXED-POINT SOLVERS"
RELATED WORK,0.06349206349206349,"Deep Equilibrium Models.
Given a layer (usually a shallow block; e.g., self-attention (Vaswani
et al., 2017)) fθ and an input x, a DEQ model aims to solve for an “inﬁnite-level” feature representa-
tion without actually stacking the fθ layer inﬁnite times. Instead, we can solve directly for the ﬁxed
point z⋆of the system:
gθ(z⋆,x) ∶= fθ(z⋆,x) −z⋆= 0.
The ﬁxed point can be estimated by quasi-Newton (or Newton’s) methods, which provide superlinear
(or even quadratic) convergence (Broyden, 1965; Anderson, 1965). Subsequently, in the backward
pass, one can implicitly differentiate through the equilibrium point, even without knowledge of
how it is estimated, and produce gradients with respect to the model parameters θ by solving a
Jacobian-based linear equation:"
RELATED WORK,0.06613756613756613,"∂ℓ
∂θ = ∂ℓ"
RELATED WORK,0.06878306878306878,"∂z⋆(I −∂fθ(z⋆,x)"
RELATED WORK,0.07142857142857142,"∂z⋆
´¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¸¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¹¶
Jacobian of fθ )"
RELATED WORK,0.07407407407407407,"−1 ∂fθ(z⋆,x)"
RELATED WORK,0.07671957671957672,"∂θ
= −∂ℓ"
RELATED WORK,0.07936507936507936,"∂z⋆Jg(z⋆)−1 ∂fθ(z⋆,x)"
RELATED WORK,0.082010582010582,"∂θ
.
(1)"
RELATED WORK,0.08465608465608465,"The most important message from Eq. equation 1 is that the backward pass can be computed with
merely the knowledge of z⋆, irrespective of how it is found. More recently, Fung et al. (2021)
prove the feasibility of directly replacing Jg(z⋆) with −I (i.e., Jacobian-free backward pass), which
signiﬁcantly accelerates training."
RELATED WORK,0.0873015873015873,"Fixed-point Solvers for DEQs.
Prior works have explored a number of techniques for ﬁnding
the ﬁxed points of DEQs. For example, Bai et al. (2019; 2020); Lu et al. (2021) used Broyden’s
method (Broyden, 1965), the memory consumption of which grows linearly with the number of
iterations since all low-rank updates are stored. Other recent work (Duvenaud et al., 2020; Gilton
et al., 2021) shifted to Anderson acceleration (AA) (Anderson, 1965), a lightweight solver that
is provably equivalent to a multi-secant quasi-Newton method (Fang & Saad, 2009). We brieﬂy
introduce AA here, since our approach will use it as the starting point."
RELATED WORK,0.08994708994708994,Published as a conference paper at ICLR 2022
RELATED WORK,0.09259259259259259,Algorithm 1 Anderson acceleration (AA) prototype (with parameter β and m)
RELATED WORK,0.09523809523809523,"1: Input: initial point z[0] ∈Rn, ﬁxed-point function fθ ∶Rn →Rn, max storage size m
2: for k = 0,...,K do
3:
1) Set mk = min{m,k}
4:
2) Compute weights αk
i for the past mk Anderson steps s.t. ∑mk
i=0 αk
i = 1.
5:
3) z[k+1] = β ∑mk
i=0 αk
i fθ(z[k−mk+i]) + (1 −β)∑mk
i=0 αk
i z[k−mk+i]
(AA_update step)
6: end for"
RELATED WORK,0.09788359788359788,"Prototype algorithm 1 illustrates the main idea of Anderson acceleration: we maintain a size-m
storage of the most recent steps, and update the iteration as a normalized linear combination of these
steps with weights αi (step 3). In the canonical AA algorithm, the weights are computed in a greedy
manner at each step to minimize the linear combination:"
RELATED WORK,0.10052910052910052,"αk = arg
min
α∈Rmk+1 ∥G[k]α∥2, s.t. 1⊺α = 1,
(2)"
RELATED WORK,0.10317460317460317,"where G[k] = [gθ(z[k−mk]) ... gθ(z[k])] are the past (up to m + 1) residuals; typically, β = 1 and
m ≤5. Eq. equation 2 can be solved by a least-squares method. In all prior works with DEQs (Bai
et al., 2019; 2020; Winston & Kolter, 2020; Revay et al., 2020; Fung et al., 2021; Lu et al., 2021), the
ﬁxed point iteration starts with an initial z[0] that is either 0 or a random sample from N(0,I)."
NEURAL DEEP EQUILIBRIUM SOLVERS,0.10582010582010581,"4
NEURAL DEEP EQUILIBRIUM SOLVERS"
NEURAL DEEP EQUILIBRIUM SOLVERS,0.10846560846560846,"While classic ﬁxed-point estimation algorithms, as presented in Section 3, already work well, they
are generic and make minimal assumptions about the speciﬁc problem being solved. For example,
while multiple papers in optimization literature have acknowledged that tuning m (and mk) as well
as varying β = (βk)k=0,...,K for each Anderson iteration k could accelerate AA’s convergence to the
ﬁxed point (Anderson, 1965; Fang & Saad, 2009; Walker & Ni, 2011), this is rarely considered in
practice because it’s unclear what schedule should be applied to these parameters."
NEURAL DEEP EQUILIBRIUM SOLVERS,0.1111111111111111,"We propose to make ﬁxed-point solvers for DEQ models learnable and content-based, which is made
possible by the unique properties of implicit models. First, unlike generic problems, the nonlinear
system for each DEQ is uniquely deﬁned by the input x (e.g., an image, etc.): z⋆(x) = z⋆= fθ(z⋆,x).
This opens the door to learning to make an informed initial guess, followed by content-based iterative
updates in the solver. Second, due to implicit models’ disentanglement of representation capacity
with forward computation, our goal of improving solvers is decoupled from the original learning goal
of the DEQ model itself (i.e., the solver is not aware of the original task, such as to predict the class
of an image). Hence, we are able to train this neural solver in a lightweight and unsupervised manner,
directly with the help of groundtruth ﬁxed-point solutions (see below)."
GENERAL FORMULATION,0.11375661375661375,"4.1
GENERAL FORMULATION"
GENERAL FORMULATION,0.1164021164021164,"For a given DEQ layer fθ and (possibly random) input x, we assume access to its exact ﬁxed point
z⋆= z⋆(x) = fθ(z⋆,x), which can be obtained by taking a classic solver (e.g., Broyden’s method)
and running it for as many iterations as needed (e.g., 100 steps) to a high level of precision."
GENERAL FORMULATION,0.11904761904761904,"The overall structure of the hypersolver is shown in Fig. 2. We use a tiny neural network parameterized
by ω = {φ,ξ} (explained below) to learn the initialization and iterative solving process, and unroll
the learnable solver for some K steps to yield a prediction z[K](x). To train this neural solver, we
minimize an objective L(ω,K) (discussed in Sec. 4.2) by backpropagating through this K-step
temporal process (Mozer, 1989; Robinson & Fallside, 1987). The original DEQ parameters θ are
frozen, and only the hypersolver parameters ω are trained here. We also do not need the groundtruth
label y (e.g., the class of an image) that corresponds to input x, which means these neural equilibrium
solvers can also be ﬁne-tuned on the ﬂy after deployment, at inference time."
GENERAL FORMULATION,0.12169312169312169,"Initializer.
The initial values can have a signiﬁcant impact on the optimization process and its
convergence speed. We propose to make an input-based guess with a tiny network hφ: z[0] = hφ(x),
where φ are the parameters. Note that the goal of the initializer is not to solve the underlying problem"
GENERAL FORMULATION,0.12433862433862433,Published as a conference paper at ICLR 2022
GENERAL FORMULATION,0.12698412698412698,Algorithm 2 HyperAnderson Iterations (parameterized parts highlighted in color)
GENERAL FORMULATION,0.12962962962962962,"1: Input: initial point z[0] = hφ(x) ∈Rn, (frozen) layer fθ, storage G = 0 ∈R(m+1)×n with size
m + 1, HyperAnderson network sξ.
2: Deﬁne gθ(z) = fθ(z) −z. Set G[0] = gθ(z[0]).
3: for k = 0,...,K do
4:
Set mk = min{m,k} and G[k] = G[0:(mk + 1)] ∈R(mk+1)×n"
GENERAL FORMULATION,0.13227513227513227,"5:
Compute ˆαk,βk = sξ(G[k]), where ˆαk = (ˆαk
0,..., ˆαk
mk) ∈R(mk+1)"
GENERAL FORMULATION,0.1349206349206349,"6:
αk = ˆαk + (1−1⊺ˆαk)"
GENERAL FORMULATION,0.13756613756613756,"mk+1
⋅1
(normalization step)"
GENERAL FORMULATION,0.1402116402116402,"7:
z[k+1] = βk ⋅1⊺G[k] + ∑mk
i=0 αk
i z[k−mk+i]
(same AA_update as in Alg. 1, simpliﬁed)
8:
Update G = concat(G[1:], [gθ(z[k+1])])
9: end for
10: Return z[k+1]"
GENERAL FORMULATION,0.14285714285714285,Iteration k
GENERAL FORMULATION,0.1455026455026455,"G[k]
Solve ↵k = arg
min
↵2Rmk+1 kG[k]↵k2 s.t. 1>↵= 1"
GENERAL FORMULATION,0.14814814814814814,"z[K]
G[0] = [g✓(z[0]), 0, . . . , 0]
|
{z
}
storage size m + 1"
GENERAL FORMULATION,0.15079365079365079,z[0] = 0 2 Rn
GENERAL FORMULATION,0.15343915343915343,Set β = βk = 1
GENERAL FORMULATION,0.15608465608465608,Canonical Anderson Mixing
GENERAL FORMULATION,0.15873015873015872,"G[k+1], z[k+1] = AA Update(G[k], z[k], ↵k, βk)"
GENERAL FORMULATION,0.16137566137566137,Input x
GENERAL FORMULATION,0.164021164021164,(a) The original generic Anderson solver
GENERAL FORMULATION,0.16666666666666666,Iteration k
GENERAL FORMULATION,0.1693121693121693,"G[0] = [g✓(z[0]), 0, . . . , 0]
|
{z
}
storage size m + 1"
GENERAL FORMULATION,0.17195767195767195,"G[k]
ˆG[k]
“Compress”"
GENERAL FORMULATION,0.1746031746031746,z[0] = hφ(x) 2 Rn
GENERAL FORMULATION,0.17724867724867724,"Temporal
Convolution m + 1"
GENERAL FORMULATION,0.17989417989417988,"(a compressed
version of G[k])"
GENERAL FORMULATION,0.18253968253968253,↵k = (↵k
GENERAL FORMULATION,0.18518518518518517,"0, . . . , ↵k m) βk n p"
GENERAL FORMULATION,0.18783068783068782,"Predict
↵k, βk = s⇠( ˆG[k]) s⇠"
GENERAL FORMULATION,0.19047619047619047,"G[k+1], z[k+1] = AA Update(G[k], z[k], ↵k, βk) z[K]"
GENERAL FORMULATION,0.1931216931216931,Neural Equilibrium Solver (ours)
GENERAL FORMULATION,0.19576719576719576,"(past m + 1
residuals)"
GENERAL FORMULATION,0.1984126984126984,"Parameters ! = {φ, ⇠}"
GENERAL FORMULATION,0.20105820105820105,Input x
GENERAL FORMULATION,0.2037037037037037,(b) Our proposed (tiny but learnable) HyperAnderson solver
GENERAL FORMULATION,0.20634920634920634,"Figure 2: 2a: The canonical Anderson solver is based on a local least-squares solution at each
iteration, with β = βk set to a constant. 2b: Our neural ﬁxed-point solver provides a better initial
guess z[0] and learnable iterative updates."
GENERAL FORMULATION,0.20899470899470898,"at all (e.g., to classify an image; we don’t even need the groundtruth label y), but only to yield a quick
initial estimate. For example, in language modeling, where x ∈RT ×d is a length-T sequence, we set"
GENERAL FORMULATION,0.21164021164021163,"hφ(x) = ReLU(Conv1dk=3(x))W , where Conv1dk=3 ∶RT ×d →RT ×p
(3)"
GENERAL FORMULATION,0.21428571428571427,"and where W ∈Rp×q, with q being the dimension of the ﬁxed point of a single token. We set p to be
very small (e.g., 100), so that hφ is tiny and fast. Note that this 1-layer initializer by itself has very
low expressivity and is usually a poor model for the original task, as we verify in Sec. 5.3."
GENERAL FORMULATION,0.21693121693121692,"HyperAnderson Iterations.
We further parameterize the setting of βk and αk
i while following the
AA prototype outlined in Alg. 1. In lieu of setting Eq. 2 for α to a least-squares solution over the
past few residuals G, we make both α ∈R(mk+1) and β ∈R explicit learnable functions of G with a
neural network sξ(G) ∶R(mk+1)×n →(R(mk+1) × R); see Alg. 2."
GENERAL FORMULATION,0.21957671957671956,"A challenge here is that n (the dimension of z⋆) is typically large in practice, as it is affected by the
scale of the input (e.g., in DEQ sequence models (Bai et al., 2019), n is over 1.5 ⋅105 on a single
textual sequence of length 200). This makes sξ map from an extremely high-dimensional space to
a low-dimensional space (e.g., m = 5). To keep sξ fast, small, and applicable to inputs of varying
dimensionalities (e.g., sequence length or image size), we propose to ﬁrst compress each gθ(z[k])
to form a smaller yet still representative version ˆG[k] of G[k] = [gθ(z[k−mk]),...,gθ(z[k])]. For
example, when each gθ(z[k]) is a image feature map residual of dimension n = C × H × W, we can"
GENERAL FORMULATION,0.2222222222222222,Published as a conference paper at ICLR 2022
GENERAL FORMULATION,0.22486772486772486,"hφ, s⇠
#1. Deﬁne Hypersolver"
GENERAL FORMULATION,0.2275132275132275,#2. Compute precise ﬁxed point
GENERAL FORMULATION,0.23015873015873015,for each x
GENERAL FORMULATION,0.2328042328042328,x ! z?(x)
GENERAL FORMULATION,0.23544973544973544,#3. Compute with neural solver (K steps)
GENERAL FORMULATION,0.23809523809523808,"NeuralSolve(x, hφ, s⇠)"
GENERAL FORMULATION,0.24074074074074073,"!(z[k], g[k]"
GENERAL FORMULATION,0.24338624338624337,"✓, ↵k, βk)k=0,...,K"
GENERAL FORMULATION,0.24603174603174602,#4. Compute loss for the hypersolver
GENERAL FORMULATION,0.24867724867724866,"(with potentially as many generic
solver steps as needed)"
GENERAL FORMULATION,0.25132275132275134,Frozen (trained) f✓
GENERAL FORMULATION,0.25396825396825395,"L(!, K) = λ1Lconv + λ2Linit + λ3L↵"
GENERAL FORMULATION,0.2566137566137566,#5. Update hypersolver by…
GENERAL FORMULATION,0.25925925925925924,"r⇠L(!, K) = λ1r⇠Lconv + λ3r⇠L↵
where ! = {φ, ⇠}
Gradients rφL(!, K) = λ2rφLinit"
GENERAL FORMULATION,0.2619047619047619,"Figure 3: The training procedure of the neural deep equilibrium solver. With a given fθ and input
x, we optimize the hypersolver parameters ω = {φ,ξ} via losses applied on the HyperAnderson
iterations and the initializer (see Sec. 4.2)."
GENERAL FORMULATION,0.26455026455026454,"perform global pooling to form a C-dimensional vector Pool(gθ(z[k])) as its compressed version:
ˆG[k] = [Pool(gθ(z[k−mk])),...,Pool(gθ(z[k]))] ∈RC×(mk+1),
and predict αk,βk = sξ( ˆG[k])
(4)
Once we have this representative collection ˆG[k], we treat it as a mini time-series of length (mk + 1)
that encodes the latest estimates of the ﬁxed point. We then apply a 2-layer temporal convolu-
tion (van den Oord et al., 2016) to learn to predict: 1) a relative weight αk
i for each of these past
residuals i ∈[mk]; and 2) the HyperAnderson mixing coefﬁcient βk for the current iteration. There-
fore, sξ shall gradually learn to adjust these parameters α and β in light of the previous hypersolver
steps, and receive gradients from later iterations. We explain the detailed design choices of sξ in
Appendix B, while noting that it still completely captures the AA prototype (see Alg. 1)."
TRAINING THE NEURAL EQUILIBRIUM SOLVERS,0.2671957671957672,"4.2
TRAINING THE NEURAL EQUILIBRIUM SOLVERS"
TRAINING THE NEURAL EQUILIBRIUM SOLVERS,0.2698412698412698,"One beneﬁt of training hypersolvers on implicit models is that they can be trained in an unsupervised
manner via z⋆(x), which a slower classic method can provide as many as needed, and for any given
(possibly even random) input tensor x. Moreover, unlike NODE solvers (Chen et al., 2018b; Poli
et al., 2020), a DEQ model does not have a unique trajectory and thus its hypersolvers do not need
trajectory ﬁtting at all. All that we need is to drive everything to be as close to z⋆as possible. As
an example, a neural solver could learn to sacriﬁce progress in earlier iterations if it subsequently
converges to the equilibrium faster. Formally, given a hypersolver {hφ,sξ} that yields a set of states
(z[k],G[k],αk,βk)k=0,...,K (recall z[0] = hφ(x)), we introduce 3 objectives for its training."
TRAINING THE NEURAL EQUILIBRIUM SOLVERS,0.2724867724867725,"Fixed-point Convergence Loss.
The ﬁrst loss aims to encourage convergence at all intermediate
estimates [z[k]]k=1,...,K of the HyperAnderson iterations: Lconv = ∑K
k=1 wk∥z[k] −z⋆∥2, where wk
is the weight for the loss from iteration k such that ∑K
k=1 wk = 1. We set wk to be monotonically
increasing with k such that later iterations apply a heavier penalty for deviation from the ﬁxed point."
TRAINING THE NEURAL EQUILIBRIUM SOLVERS,0.2751322751322751,"Initializer Loss.
We also train the initializer by maximizing the proximity of the initial guess to
the ﬁxed point: Linit = ∥hφ(x) −z⋆∥2, We separate this objective from Lconv since the initialization is
predicted directly from the input x and does not go through HyperAnderson updates."
TRAINING THE NEURAL EQUILIBRIUM SOLVERS,0.2777777777777778,"Alpha Loss.
Although we replace the generic Anderson solver (Anderson, 1965) in terms of how
αk,βk are computed in each iteration, we empirically found it still beneﬁcial to guide the hypersolvers’
prediction of α with an auxiliary loss especially at the start of the training: Lα = ∑K
k=0 ∥G[k]αk∥2. In
practice, we gradually decay the weight of this loss to 0 as training progresses. We summarize the
complete training procedure of a neural solver on top of a DEQ in Fig. 3."
DISCUSSION,0.2804232804232804,"4.3
DISCUSSION"
DISCUSSION,0.2830687830687831,"Complexity of hypersolver.
Note that fθ remains frozen during hypersolver training. This means
that for a given DEQ model fθ and input x, the ﬁxed point z⋆(x) = fθ(z⋆;x) also remains the same –
we are just trying to learn to ﬁnd it faster, with a limited K-iteration budget. Moreover, we designed
the initializer hφ and HyperAnderson network sξ to be intentionally simple (e.g, 1 layer with few
hidden units), so that each hypersolver step is even faster than the original Anderson step, whose
main computational overhead occurs in solving the constrained optimization in Eq. 2."
DISCUSSION,0.2857142857142857,"These points also highlight the difference between the neural solver and techniques such as model
compression (Han et al., 2015) or distillation (Hinton et al., 2015), where a pruned/smaller (but still"
DISCUSSION,0.28835978835978837,Published as a conference paper at ICLR 2022
DISCUSSION,0.291005291005291,"representationally rich) model is trained to match the output and performance of a larger model.
Speciﬁcally, in our case, as the ﬁxed point z⋆is determined solely by fθ and x, the hypersolver itself
does not have much representational capacity, since its only goal is to produce an “educated” initial
guess and learnable iterations to facilitate the optimization process. E.g., the 1-layer Conv1d-based
initializer Sec. 4.1 would be a bad language model by itself since it is tiny and only sees the past 2
tokens (see Sec. 5.3 for empirical evidence), yet this limited capacity and context turn out sufﬁcient
to guide and substantially improve the solver."
DISCUSSION,0.29365079365079366,"Training hypersolver via BPTT.
While a generic Anderson solver computes αk by optimizing
locally with G[k], backpropagating through the HyperAnderson steps ensures that the iterative update
network sξ can receive gradient and learn from later iterations. This is appealing because, arguably,
only the output of the Kth iteration matters in the end. Indeed, we empirically verify via ablation
studies in Sec. 5 that such learned α and β predictors already signiﬁcantly accelerate the convergence
process even without the presence of the initializer. Note that as DEQ models’ fθ layer is typically
richly parameterized, the backpropagation-through-time (BPTT) might consume a lot of memory. To
limit memory consumption, we use small batch sizes for hypersolver training. (This does not affect
the training of the DEQ model itself, which is separate.) We have observed that hypersolver training
is highly effective with small batch sizes, as reported in Sec. 5 and App. A. As an alternative solution,
since these hypersolvers are very fast to train in practice, one could also use methods such as gradient
checkpointing (Chen et al., 2016)."
DISCUSSION,0.2962962962962963,"Complementarity with DEQ regularizations.
Besides tiny size and fast training, the value and
usefulness of neural equilibrium solvers are highlighted by how DEQ models decouple representa-
tional capacity and forward solver choice. In particular, our method is orthogonal to prior work that
accelerates DEQ models by structural regularization of fθ (Winston & Kolter, 2020; Revay et al.,
2020; Bai et al., 2021) or approximating the Jacobian of fθ in the backward pass (Fung et al., 2021). In
Sec. 5, we show evidence that our method (which is solver-based) integrates well with regularization
approaches (which are fθ-based) and yields broad improvements compared to canonical solvers (e.g.,
Broyden or Anderson methods) regardless of how fθ was trained or what structure it uses."
EXPERIMENTS,0.29894179894179895,"5
EXPERIMENTS"
EXPERIMENTS,0.30158730158730157,"In this section, we verify the various beneﬁts of exploiting neural solvers in implicit models. Specif-
ically, as our goal is to show the superiority of the learnable solvers over generic solvers on both
performance and efﬁciency aspects, we compare the movement of the entire speed/accuracy pareto
curve rather than a single point on the curve. To achieve this purpose, we study the hypersolver
on some of the largest-scale experiments that DEQs have been used on: WikiText-103 language
modeling (Merity et al., 2017), ImageNet classiﬁcation (Deng et al., 2009), and Cityscapes semantic
segmentation with megapixel images (Cordts et al., 2016). Overall, we show that: 1) neural solvers
bring universal improvement over generic solvers on DEQ models in all scenarios, with a typically
1.6-2× speedup at inference and no loss in performance (i.e., the new pareto curves strictly dominates
old ones); 2) these hypersolvers can be trained very quickly; and 3) these methods complement prior
methods such as regularizations on fθ to bring these implicit models to a new competitive level. At
the end of this section, we also conduct extensive ablative studies on the design of the hypersolver."
EXPERIMENTS,0.30423280423280424,"Note that since the neural solver training is independent of the DEQ training, we do not need to
train the actual DEQ model fθ itself (but could instead directly work on top of a pre-trained DEQ).
Therefore, the major hyperparameters in our setting are only the relative weights of the loss objectives
(see Sec. 4.2 and Appendix A). We also clarify that the use of hypersolver does implicitly assume
local stability around z⋆for convergence – which we ﬁnd almost always holds empirically, and can be
regularized for (Bai et al., 2021). Code is available at https://github.com/locuslab/deq."
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.30687830687830686,"5.1
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS"
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.30952380952380953,"To evaluate the the neural deep equilibrium solvers, we apply them on three largest-scale and highest-
dimensional tasks the implicit models have ever been applied on, across the vision and language
modalities. In contrast to prior works (Chen et al., 2018b; Winston & Kolter, 2020; Bai et al., 2021)
that measure the number of function evaluations (NFEs), we directly measure wall-clock inference
speed under the exact same experimental settings (e.g., input scale). We elaborate on the detailed
experimental settings and the implications of the results below."
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.31216931216931215,Published as a conference paper at ICLR 2022
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.3148148148148148,"0
100
200
300
400
500
600
700
Inference ms/batch (size=12) 20 30 40 50 60"
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.31746031746031744,Validation perplexity
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.3201058201058201,Wikitext-103 Language Modeling
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.32275132275132273,"DEQ (no reg.) (Anderson)
HyperDEQ (no reg.) (ours)"
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.3253968253968254,"DEQ (reg.) (Anderson)
HyperDEQ (reg.) (ours)"
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.328042328042328,Transformer-XL
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.3306878306878307,(a) Wikitext-103 language modeling
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.3333333333333333,"0
50
100
150
200
250
300
350
400
Inference ms/batch (size=48) 55 60 65 70 75"
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.335978835978836,Top-1 Accuracy
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.3386243386243386,ImageNet classification
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.3412698412698413,"DEQ (no reg.) (Anderson)
HyperDEQ (no reg.) (ours)"
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.3439153439153439,"DEQ (reg.) (Anderson)
HyperDEQ (reg.) (ours)"
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.34656084656084657,ResNet-50
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.3492063492063492,(b) ImageNet classiﬁcation
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.35185185185185186,"0
200
400
600
800
1000 1200 1400 1600
Inference ms/batch (size=3)"
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.3544973544973545,"40
45
50
55
60
65
70
75
80"
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.35714285714285715,mean IoU
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.35978835978835977,Cityscapes semantic segmentation
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.36243386243386244,"DEQ (no reg.) (Anderson)
HyperDEQ (no reg.) (ours)"
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.36507936507936506,HRNet-W18-v1
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.36772486772486773,(c) Cityscapes segmentation 0% 20% 40% 60% 80% 100%
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.37037037037037035,"WikiText-103
ImageNet
Cityscapes"
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.373015873015873,% of total model size
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.37566137566137564,Relative model size
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.3783068783068783,Neural solver (HyperDEQ) model size (%)
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.38095238095238093,DEQ model size (%) 0% 20% 40% 60% 80% 100%
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.3835978835978836,"WikiText-103
ImageNet
Cityscapes"
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.3862433862433862,% of total training time
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.3888888888888889,Relative training overhead
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.3915343915343915,Neural solver (HyperDEQ) training time (%)
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.3941798941798942,DEQ training time (%) 0.91% 99.1%
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.3968253968253968,"0.76%
1.18%"
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.3994708994708995,"99.2%
98.8%"
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.4021164021164021,"0.63%
3.87%
2.68%"
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.40476190476190477,"99.4%
96.1%
97.3%"
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.4074074074074074,(d) Overhead comparison
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.41005291005291006,"Figure 4: 4a- 4c: Comparisons of DEQs with classic and neural solvers. All speed/accuracy curves
within the same plot are benchmarked on the same GPU with the same experimental setting, averaged
over 6 independent runs. 4d: The overhead of DEQ hypersolver is extremely small."
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.4126984126984127,"WikiText-103 Language Modeling.
In this experiment, fθ is a Transformer layer (Vaswani et al.,
2017; Dai et al., 2019; Bai et al., 2019) and the ﬁxed points z⋆are (embeddings of) text sequences. We
train the neural solver on sequences of length 60 for 5000 steps, and demonstrate its inference-time
effect in Figure 4a (where we use a validation sequence length of 150). Speciﬁcally, compared
with the original DEQ-Transformer (Bai et al., 2019) (Y curve), which uses generic Anderson
acceleration (Anderson, 1965) or Broyden’s method (Broyden, 1965) (both have similar pareto
curves; see App. C), this same DEQ model solved with our neural approach (dubbed HyperDEQ;
see
curve) achieves signiﬁcantly better efﬁciency. Moreover, our method is complementary to
prior work that builds faster implicit models by Jacobian regularizations (Finlay et al., 2020; Bai
et al., 2021). To demonstrate this, we additionally train a DEQ-Transformer model with Jacobian
regularization (Bai et al., 2021) (
curve), and apply the neural solver on this regularized DEQ (⋆
curve). This movement of the speed/perplexity curves validates the DEQ property at the core of this
paper: the decoupling of the representational capacity (i.e., fθ) and the forward computation (i.e., the
solver). With everything combined, we bring the performance of implicit Transformer-based DEQs
close to the explicit Transformer-XL (Dai et al., 2019), which is the SOTA architecture on this task."
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.41534391534391535,"ImageNet classiﬁcation.
We additionally evaluate HyperDEQ on ImageNet classiﬁcation (224 ×
224 images), customizing a neural solver on top of a 4-resolutional multiscale DEQ models (Bai
et al., 2020). We train the HyperDEQ with 12 HyperAnderson iterations, and the speed/accuracy
curves are shown in Figure 4b (
and ⋆curves). Note that while Jacobian regularization (
curve)
eventually hurts the performance of a multiscale DEQ (cf. Y curve) due to the strong constraint it
imposes, the DEQ model with neural solver achieves faster inference without sacriﬁng any accuracy
(since fθ, and thus z⋆, are identical); e.g., we reach 75.0% accuracy while being almost 2× faster."
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.41798941798941797,"Cityscapes semantic segmentation.
We also show that our neural solver approach works well in
domains where existing regularization-based methods (see Sec. 2) fail. Speciﬁcally, we apply the
neural equilibrium solver on Cityscapes semantic segmentation, where the task objective is to label
every pixel on a high-resolution (typically 2048 × 1024) image with the class of the object that the
pixel belongs to. As in the ImageNet and WikiText-103 tasks, we found that there is a consistent gain
in using the neural solver over the generic alternative, accelerating ﬁxed-point convergence by more
than a factor of 2 (see Figure 4c). In contrast, prior methods such as Jacobian regularization (Bai et al.,
2021) do not work in this setting, due to their dependence on the exact structure of fθ. (Speciﬁcally,
when fθ is convolution-based and the image is very large, Jacobian regularization that encourages
contractivity is at odds with the gradual broadening of the receptive ﬁeld.) Our neural solver is
orthogonal to the structure of fθ (which is frozen), and we only improve how the solver functions."
LARGE-SCALE EXPERIMENTS ON VISION AND LANGUAGE TASKS,0.42063492063492064,Published as a conference paper at ICLR 2022
TRAINING EFFICIENCY OF THE NEURAL SOLVER,0.42328042328042326,"5.2
TRAINING EFFICIENCY OF THE NEURAL SOLVER"
TRAINING EFFICIENCY OF THE NEURAL SOLVER,0.42592592592592593,"We also provide extra training analysis in Fig. 4d. Not only is our approach effective, but the overhead
for training the neural solver is also extremely small: the neural solver module is tiny (< 4% of the
DEQ model size) and requires only about 1% of the training time needed by the original DEQ model
(e.g., on WikiText-103, a DEQ requires 130 hours on 4 GPUs; the neural solver requires only about
1.2 extra hours). We believe this is strong evidence that neural solvers are simple, lightweight, and
effective tools that take advantage of the decoupling properties of equilibrium models to yield an
almost-free acceleration at inference time. We also perform convergence analysis in App. D."
TRAINING EFFICIENCY OF THE NEURAL SOLVER,0.42857142857142855,"Interestingly, one can also employ the neural solver to accelerate the DEQ training, but with three
caveats: 1) during training the ﬁxed point manifold also keeps changing; 2) we want to amortize the
cost of computing “groudtruth” z⋆; and 3) we still keep the backward implicit differentiation intact.
Thus, we propose to train the neural solver {hφ,sξ} and the DEQ model fθ in an alternating manner,
and elaborate more in App. D. We empirically observe this leads to a 16-20% DEQ training speedup."
ABLATIVE STUDIES AND LIMITATIONS,0.4312169312169312,"5.3
ABLATIVE STUDIES AND LIMITATIONS"
ABLATIVE STUDIES AND LIMITATIONS,0.43386243386243384,"Finally, we perform a series of ablation studies to understand the beneﬁts of multiple components"
ABLATIVE STUDIES AND LIMITATIONS,0.4365079365079365,Table 1: Perplexity (ppl) on WikiText-103
ABLATIVE STUDIES AND LIMITATIONS,0.43915343915343913,"Model Size
Test ppl"
ABLATIVE STUDIES AND LIMITATIONS,0.4417989417989418,"Gated ConvNet (Dauphin et al., 2017)
230M
37.2
Transformer-XL (Dupont et al., 2019)
165M
24.2"
ABLATIVE STUDIES AND LIMITATIONS,0.4444444444444444,"HyperDEQ (reg.) w/ 12 iters (ours)
98M
23.4
Initializer hφ (Conv1d)
0.4M
836.94"
ABLATIVE STUDIES AND LIMITATIONS,0.4470899470899471,"100
150
200
250
300
350
Inference ms/batch (size=12) 25 30 35 40 45 50"
ABLATIVE STUDIES AND LIMITATIONS,0.4497354497354497,Validation perplexity
ABLATIVE STUDIES AND LIMITATIONS,0.4523809523809524,Wikitext-103 Language Modeling (Ablative)
ABLATIVE STUDIES AND LIMITATIONS,0.455026455026455,"DEQ (reg.) (Anderson)
DEQ (reg.) (Broyden)
HyperDEQ (reg.) only init
HyperDEQ (reg.) w/o init"
ABLATIVE STUDIES AND LIMITATIONS,0.4576719576719577,"HyperDEQ (reg.) only 
k and init"
ABLATIVE STUDIES AND LIMITATIONS,0.4603174603174603,"HyperDEQ (reg.) only 
k and init"
ABLATIVE STUDIES AND LIMITATIONS,0.46296296296296297,HyperDEQ (reg.) (ours)
ABLATIVE STUDIES AND LIMITATIONS,0.4656084656084656,Figure 5: Ablative studies on HyperDEQ (reg.).
ABLATIVE STUDIES AND LIMITATIONS,0.46825396825396826,"within our design of the neural equilibrium
solvers.
We use the language modeling task
on WikiText-103 for this purpose (where fθ is
a Transformer layer), while noting that we’ve
noticed similar trends in all other settings. The
results are presented in Fig. 5. The HyperDEQ
with everything combined (initializer, αk, and
βk predictions) performs best. Making the An-
derson iterations learnable generally improves
convergence. Moreover, although simply adding
an initializer to a generic solver ( curve) does
not help much, learning and backpropagating
through the HyperAnderson iterations makes the
initializer quite useful (cf.
and ⋆curves). We
additionally take the learned initializer hφ from
HyperDEQ and verify that this tiny module is by
itself still a poor language model (see Table 1 and
Sec. 4.3), but is valuable to our HyperAnderson
iterations. More ablation studies (e.g., how α is predicted) are reported in Appendix C."
ABLATIVE STUDIES AND LIMITATIONS,0.4708994708994709,"We also note two caveats for our approach. First, as mentioned in Sec. 4.3, backpropagating through
the HyperAnderson iterations means the memory could grow with the number of steps K that we
run for. However, we don’t ﬁnd this to be problematic in practice, as we observed the training of
these hypersolvers to be very insensitive to batch size , and that at inference time hypersolvers do
easily generalize to iterations > K (see also App. D). Second, though our method brings consistent
improvements over generic solvers, in some cases a certain amount of iterations may still be required
for good performance (e.g., fθ is a 3 × 3 convolution and the input is a large image)."
DISCUSSION,0.47354497354497355,"6
DISCUSSION"
DISCUSSION,0.47619047619047616,"We introduce a neural ﬁxed-point solver for deep equilibrium (DEQ) models. The approach is
simple, customizable, and extremely lightweight. Unlike prior works that regularize the structures or
parameterizations of the implicit layer design (usually at the cost of accuracy), we propose to exploit
this valuable notion of how implicit models decouple the representation (i.e., fθ) from the forwards
computation. We directly learn a model-speciﬁc equilibrium solver that provides: 1) better-informed
initial guesses; and 2) parameterized iterations that generalize Anderson acceleration and take into
account future steps. Our experiments show that these modiﬁcations substantially improve the
speed/accuracy trade-off across diverse large-scale tasks, while adding almost no overhead to training.
We see these encouraging results as a signiﬁcant step towards making implicit models more practical,
and hope that this work will further motivate the application of implicit models such as Neural ODEs,
DEQs, and other variants (Gu et al., 2020; Wang et al., 2020) to real, large-scale datasets."
DISCUSSION,0.47883597883597884,Published as a conference paper at ICLR 2022
ACKNOWLEDGEMENT,0.48148148148148145,"7
ACKNOWLEDGEMENT"
ACKNOWLEDGEMENT,0.48412698412698413,"Shaojie Bai is supported by a grant from the Bosch Center for Artiﬁcial Intelligence (BCAI). We
thank Brandon Amos for the helpful discussions."
REFERENCES,0.48677248677248675,REFERENCES
REFERENCES,0.4894179894179894,"Brandon Amos and J. Zico Kolter. OptNet: Differentiable optimization as a layer in neural networks.
In International Conference on Machine Learning (ICML), 2017."
REFERENCES,0.49206349206349204,"Donald G Anderson. Iterative procedures for nonlinear integral equations. Journal of the ACM
(JACM), 12(4):547–560, 1965."
REFERENCES,0.4947089947089947,"Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoffman, David Pfau, Tom Schaul,
Brendan Shillingford, and Nando De Freitas. Learning to learn by gradient descent by gradient
descent. In Neural Information Processing Systems, 2016."
REFERENCES,0.4973544973544973,"Shaojie Bai, J. Zico Kolter, and Vladlen Koltun. Deep equilibrium models. In Neural Information
Processing Systems, 2019."
REFERENCES,0.5,"Shaojie Bai, Vladlen Koltun, and J. Zico Kolter. Multiscale deep equilibrium models. In Neural
Information Processing Systems, 2020."
REFERENCES,0.5026455026455027,"Shaojie Bai, J. Zico Kolter, and Vladlen Koltun.
Stabilizing equilibrium models by Jacobian
regularization. In International Conference on Machine Learning (ICML), 2021."
REFERENCES,0.5052910052910053,"Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are
few-shot learners. arXiv:2005.14165, 2020."
REFERENCES,0.5079365079365079,"Charles G Broyden. A class of methods for solving nonlinear simultaneous equations. Mathematics
of Computation, 1965."
REFERENCES,0.5105820105820106,"Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L. Yuille.
DeepLab: Semantic image segmentation with deep convolutional nets, atrous convolution, and
fully connected CRFs. IEEE Transactions on Pattern Analysis and Machine Intelligence, 40(4),
2018a."
REFERENCES,0.5132275132275133,"Tian Qi Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. Neural ordinary differen-
tial equations. In Neural Information Processing Systems, 2018b."
REFERENCES,0.5158730158730159,"Tianqi Chen, Bing Xu, Chiyuan Zhang, and Carlos Guestrin. Training deep nets with sublinear
memory cost. arXiv:1604.06174, 2016."
REFERENCES,0.5185185185185185,"Yutian Chen, Matthew W Hoffman, Sergio Gómez Colmenarejo, Misha Denil, Timothy P Lillicrap,
Matt Botvinick, and Nando Freitas. Learning to learn without gradient descent by gradient descent.
In International Conference on Machine Learning (ICML), 2017."
REFERENCES,0.5211640211640212,"Bowen Cheng, Maxwell D Collins, Yukun Zhu, Ting Liu, Thomas S Huang, Hartwig Adam, and
Liang-Chieh Chen. Panoptic-deeplab: A simple, strong, and fast baseline for bottom-up panoptic
segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition, pp. 12475–12485, 2020."
REFERENCES,0.5238095238095238,"Earl A Coddington and Norman Levinson. Theory of ordinary differential equations. Tata McGraw-
Hill Education, 1955."
REFERENCES,0.5264550264550265,"Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo
Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The Cityscapes dataset for semantic urban
scene understanding. In Computer Vision and Pattern Recognition (CVPR), 2016."
REFERENCES,0.5291005291005291,"Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V. Le, and Ruslan Salakhutdinov.
Transformer-XL: Attentive language models beyond a ﬁxed-length context. In Annual Meeting of
the Association for Computational Linguistics (ACL), 2019."
REFERENCES,0.5317460317460317,Published as a conference paper at ICLR 2022
REFERENCES,0.5343915343915344,"Yann N. Dauphin, Angela Fan, Michael Auli, and David Grangier. Language modeling with gated
convolutional networks. In International Conference on Machine Learning (ICML), 2017."
REFERENCES,0.5370370370370371,"Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Fei-Fei Li. ImageNet: A large-scale
hierarchical image database. In Computer Vision and Pattern Recognition (CVPR), 2009."
REFERENCES,0.5396825396825397,"Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep
bidirectional transformers for language understanding. In NAACL-HLT, 2019."
REFERENCES,0.5423280423280423,"Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas
Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An
image is worth 16x16 words: Transformers for image recognition at scale.
arXiv preprint
arXiv:2010.11929, 2020."
REFERENCES,0.544973544973545,"Emilien Dupont, Arnaud Doucet, and Yee Whye Teh. Augmented neural ODEs. In Neural Information
Processing Systems, 2019."
REFERENCES,0.5476190476190477,"David Duvenaud, J. Zico Kolter, and Matthew Johnson. Deep implicit layers tutorial - neural ODEs,
deep equilibirum models, and beyond. Neural Information Processing Systems Tutorial, 2020."
REFERENCES,0.5502645502645502,"Laurent El Ghaoui, Fangda Gu, Bertrand Travacca, and Armin Askari. Implicit deep learning.
arXiv:1908.06315, 2019."
REFERENCES,0.5529100529100529,"Haw-ren Fang and Yousef Saad. Two classes of multisecant methods for nonlinear acceleration.
Numerical Linear Algebra with Applications, 16(3):197–221, 2009."
REFERENCES,0.5555555555555556,"Chris Finlay, Jörn-Henrik Jacobsen, Levon Nurbekyan, and Adam M Oberman. How to train your
neural ODE. arXiv:2002.02798, 2020."
REFERENCES,0.5582010582010583,"Samy Wu Fung, Howard Heaton, Qiuwei Li, Daniel McKenzie, Stanley Osher, and Wotao Yin. Fixed
point networks: Implicit depth models with Jacobian-free backprop. arXiv:2103.12803, 2021."
REFERENCES,0.5608465608465608,"Davis Gilton, Gregory Ongie, and Rebecca Willett. Deep equilibrium architectures for inverse
problems in imaging. arXiv:2102.07944, 2021."
REFERENCES,0.5634920634920635,"Stephen Gould, Richard Hartley, and Dylan Campbell. Deep declarative networks: A new hope.
arXiv:1909.04866, 2019."
REFERENCES,0.5661375661375662,"Will Grathwohl, Ricky TQ Chen, Jesse Betterncourt, Ilya Sutskever, and David Duvenaud. FFJORD:
Free-form continuous dynamics for scalable reversible generative models. In International Confer-
ence on Learning Representations (ICLR), 2019."
REFERENCES,0.5687830687830688,"Fangda Gu, Heng Chang, Wenwu Zhu, Somayeh Sojoudi, and Laurent El Ghaoui. Implicit graph
neural networks. In Neural Information Processing Systems, 2020."
REFERENCES,0.5714285714285714,"Song Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks
with pruning, trained quantization and huffman coding. arXiv:1510.00149, 2015."
REFERENCES,0.5740740740740741,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Computer Vision and Pattern Recognition (CVPR), 2016."
REFERENCES,0.5767195767195767,"Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network.
arXiv:1503.02531, 2015."
REFERENCES,0.5793650793650794,"Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural Computation, 9(8),
1997."
REFERENCES,0.582010582010582,"Junteng Jia and Austin R Benson. Neural jump stochastic differential equations. arXiv:1905.10403,
2019."
REFERENCES,0.5846560846560847,"Kenji Kawaguchi. On the theory of implicit deep learning: Global convergence with implicit layers.
In International Conference on Learning Representations (ICLR), 2021."
REFERENCES,0.5873015873015873,"Jacob Kelly, Jesse Bettencourt, Matthew James Johnson, and David Duvenaud. Learning differential
equations that are easy to solve. In Neural Information Processing Systems, 2020."
REFERENCES,0.58994708994709,Published as a conference paper at ICLR 2022
REFERENCES,0.5925925925925926,"Patrick Kidger, Ricky TQ Chen, and Terry Lyons. “hey, that’s not an ODE”: Faster ODE adjoints
with 12 lines of code. In International Conference on Machine Learning (ICML), 2021."
REFERENCES,0.5952380952380952,"Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International
Conference on Learning Representations (ICLR), 2015."
REFERENCES,0.5978835978835979,"Steven G Krantz and Harold R Parks. The implicit function theorem: History, theory, and applications.
Springer, 2012."
REFERENCES,0.6005291005291006,"Ke Li and Jitendra Malik. Learning to optimize. arXiv:1606.01885, 2016."
REFERENCES,0.6031746031746031,"Ke Li and Jitendra Malik. Learning to optimize neural nets. arXiv:1703.00441, 2017."
REFERENCES,0.6058201058201058,"Ilya Loshchilov and Frank Hutter. SGDR: Stochastic gradient descent with warm restarts. In
International Conference on Learning Representations (ICLR), 2017."
REFERENCES,0.6084656084656085,"Cheng Lu, Jianfei Chen, Chongxuan Li, Qiuhao Wang, and Jun Zhu. Implicit normalizing ﬂows. In
International Conference on Learning Representations (ICLR), 2021."
REFERENCES,0.6111111111111112,"Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. Pointer sentinel mixture
models. In International Conference on Learning Representations (ICLR), 2017."
REFERENCES,0.6137566137566137,"Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for
generative adversarial networks. In International Conference on Learning Representations (ICLR),
2018."
REFERENCES,0.6164021164021164,"Michael C Mozer. A focused back-propagation algorithm for temporal pattern recognition. Complex
Systems, 3(4):349–381, 1989."
REFERENCES,0.6190476190476191,"Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and
Luke Zettlemoyer. Deep contextualized word representations. arXiv preprint arXiv:1802.05365,
2018."
REFERENCES,0.6216931216931217,"Michael Poli, Stefano Massaroli, Atsushi Yamashita, Hajime Asama, and Jinkyoo Park. Hypersolvers:
Toward fast continuous-depth models. arXiv:2007.09601, 2020."
REFERENCES,0.6243386243386243,"Sachin Ravi and Hugo Larochelle. Optimization as a model for few-shot learning. In International
Conference on Learning Representations (ICLR), 2016."
REFERENCES,0.626984126984127,"Max Revay, Ruigang Wang, and Ian R Manchester. Lipschitz bounded equilibrium networks.
arXiv:2010.01732, 2020."
REFERENCES,0.6296296296296297,"AJ Robinson and Frank Fallside. The utility driven dynamic error propagation network. University
of Cambridge Department of Engineering Cambridge, MA, 1987."
REFERENCES,0.6322751322751323,"Yulia Rubanova, Ricky TQ Chen, and David Duvenaud. Latent ODEs for irregularly-sampled time
series. arXiv:1907.03907, 2019."
REFERENCES,0.6349206349206349,"Aäron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves,
Nal Kalchbrenner, Andrew W. Senior, and Koray Kavukcuoglu. WaveNet: A generative model for
raw audio. arXiv:1609.03499, 2016."
REFERENCES,0.6375661375661376,"Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
Kaiser, and Illia Polosukhin. Attention is all you need. In Neural Information Processing Systems,
2017."
REFERENCES,0.6402116402116402,"Shobha Venkataraman and Brandon Amos. Neural ﬁxed-point acceleration for convex optimization.
arXiv preprint arXiv:2107.10254, 2021."
REFERENCES,0.6428571428571429,"Homer F Walker and Peng Ni. Anderson acceleration for ﬁxed-point iterations. SIAM Journal on
Numerical Analysis, 49(4):1715–1735, 2011."
REFERENCES,0.6455026455026455,"J. Wang, K. Sun, T. Cheng, B. Jiang, C. Deng, Y. Zhao, D. Liu, Y. Mu, M. Tan, X. Wang, W. Liu, and
B. Xiao. Deep high-resolution representation learning for visual recognition. IEEE Transactions
on Pattern Analysis and Machine Intelligence, 2020."
REFERENCES,0.6481481481481481,Published as a conference paper at ICLR 2022
REFERENCES,0.6507936507936508,"Po-Wei Wang, Priya Donti, Bryan Wilder, and Zico Kolter. SATNet: Bridging deep learning and
logical reasoning using a differentiable satisﬁability solver. In International Conference on Machine
Learning (ICML), 2019."
REFERENCES,0.6534391534391535,"Tiancai Wang, Xiangyu Zhang, and Jian Sun. Implicit feature pyramid network for object detection.
arXiv preprint arXiv:2012.13563, 2020."
REFERENCES,0.656084656084656,"Olga Wichrowska, Niru Maheswaranathan, Matthew W Hoffman, Sergio Gomez Colmenarejo, Misha
Denil, Nando Freitas, and Jascha Sohl-Dickstein. Learned optimizers that scale and generalize. In
International Conference on Machine Learning (ICML), 2017."
REFERENCES,0.6587301587301587,"Ezra Winston and J. Zico Kolter. Monotone operator equilibrium networks. In Neural Information
Processing Systems, 2020."
REFERENCES,0.6613756613756614,"Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, and Quoc V
Le. Xlnet: Generalized autoregressive pretraining for language understanding. arXiv preprint
arXiv:1906.08237, 2019."
REFERENCES,0.6640211640211641,Published as a conference paper at ICLR 2022
REFERENCES,0.6666666666666666,"Table 2: Task settings (see Sec. 5). Note that in WikiText-103 and ImageNet, we train the neural
solver only for a few thousand gradient steps, which is far less than a complete epoch on these
datasets. †In addition, we decay the loss weight λ3 (for Lα) to 5e-8 on a linear schedule over the ﬁrst
1.5-2K training steps (see below)."
REFERENCES,0.6693121693121693,"Task
Language modeling
Image classiﬁcation
Semantic segmentation
Dataset
WikiText-103 (Merity et al., 2017)
ImageNet (Deng et al., 2009)
Cityscapes (Cordts et al., 2016)
Download link
Link
Link
Link
Split (train/val/test)
103M/218K/246K (words)
1.28M/ - /150K (images)
2975/500/1525 (images)
Vocabulary size
267,735
Not Applicable
Not Applicable
Input type
Text Sequence
Image
Image
Implicit model arch.
DEQ-Transformer
Multiscale-DEQ
Multiscale-DEQ
Input scale (train)
Length=60
H × W=224 × 224
H × W=2048 × 1024
Input scale (train)
Length=150
H × W=224 × 224
H × W=1024 × 512
Jg(z⋆) size (per sample)
(1.05 ⋅105) × (1.05 ⋅105)
(1.88 ⋅105) × (1.88 ⋅105)
(7.86 ⋅106) × (7.86 ⋅106)
Batch size (train)
16
32
8
Optimizer (lr)
Adam (0.001)
Adam (0.001)
Adam (0.001)
HyperAnderson K (train)
10
10
12
HyperAnderson storage m
5
5
5
Training steps T
5000
4000
3000
Loss weight λ1 (for Lconv)
0.1
0.1
0.1
Loss weight λ2 (for Linit)
0.05
0.02
0.02
†Loss weight λ3 (for Lα)
1e-4
1e-5
1e-5"
REFERENCES,0.671957671957672,"A
EXPERIMENTAL DETAILS"
REFERENCES,0.6746031746031746,"We describe here (and summarize in Table 2) the datasets, pretrained models and the training settings
(including hyperparameters) for the experimental results reported in Sec. 5. We note that overall,
since our approach is orthogonal to how these DEQ models were trained in the ﬁrst place, we directly
downloaded the pretrained DEQ models from the publicly released DEQ repo (Bai et al., 2019) (for
language modeling) and the MDEQ repo (Bai et al., 2020) (for image classiﬁcation and segmentation),
which our code base is built upon. All of our experiments were conducted on NVIDIA RTX 2080 Ti
GPUs. The pareto efﬁciencies were benchmarked on 1 GPU, averaged over 6 independently trained
hypersolvers (i.e., 6 random seeds) for each task."
REFERENCES,0.6772486772486772,"A.1
WIKITEXT-103 WORD-LEVEL LANGUAGE MODELING"
REFERENCES,0.6798941798941799,"In a language modeling task, an autoregressive network is trained to predict the next token given a
sequence of the past ones. Large-scale contextualized language models have been widely studied in
literature, and is the cornerstone of many recent progress in realistic natural language AI models;
e.g., ELMO (Peters et al., 2018), BERT (Devlin et al., 2019), XLNet (Yang et al., 2019),and GPT-
3 (Brown et al., 2020). Formally, given an autoregressive network F (like a Transformer (Vaswani
et al., 2017) or LSTMs (Hochreiter & Schmidhuber, 1997)) and input sequence x1∶t, the prediction
ˆy1∶t = F(x1∶t) ∈Rt×N should be ideally as close as possible to the groundtruth “next words” x2∶t+1,
with yt ∈RN (i.e., like an N-way classiﬁcation, where N is the vocabulary size). Our experiments
follow the exact same settings as the DEQ-Transformer network in Bai et al. (2019), where a deep
equilibrium (DEQ) model is as a sequence model and fθ a single Transformer block (i.e., multi-head
self-attention (Vaswani et al., 2017; Dai et al., 2019)); i.e.,"
REFERENCES,0.6825396825396826,"ˆy1∶t = h(z⋆
1∶t) where z⋆
1∶t = fθ(z⋆
1∶t,x1∶t), and h a linear layer.
(5)"
REFERENCES,0.6851851851851852,"We use one of the most commonly-used and the largest-scale textual corpus, Wikitext-103 (Merity
et al., 2017), to evaluate our method. This dataset can be downloaded at this link. Speciﬁcally,
the Wikitext-103 corpus contains over 103M words in its training split, and 218K/246K words for
validation/test. Moreover, the entire corpus contains N = 267,735 unique words, which retain rare
words, numbers, punctuation and case (as opposed to all text being lowercased) from the original
Wikipedia articles."
REFERENCES,0.6878306878306878,"Note that our approach only introduces minimal new hyperparameters (as the original DEQ model
parameters are frozen). For the language modeling task, we use Adam optimizer (Kingma & Ba,
2015) with start learning rate 0.001 and cosine learning rate annealing (Loshchilov & Hutter, 2017).
The neural solver is trained for 5000 steps, with sequences of length 60 and batch size 10, on top of"
REFERENCES,0.6904761904761905,Published as a conference paper at ICLR 2022
REFERENCES,0.6931216931216931,"a pretrained DEQ with word embedding dimension 700. We set the HyperAnderson iteration limit
K to 10 (i.e., the HyperAnderson module is unrolled for 10 steps at training), while evaluating the
hypersolver at validation time for up to K = 16 steps for the pareto efﬁciency curve benchmarking
(see Fig. 4a)."
REFERENCES,0.6957671957671958,"A.2
IMAGENET CLASSIFICATION"
REFERENCES,0.6984126984126984,"In both the Imagenet classiﬁcation and the Cityscapes segmentation tasks (see below), we use a
pretrained multiscale-DEQ (MDEQ-small, with 4 resolutions) model (Bai et al., 2020) for training
our neural equilibrium solvers. In this case, feature maps maintained at multiple (e.g., n) resolutions
are driven to their equilibria simultaneously; i.e.,"
REFERENCES,0.701058201058201,"z⋆= [z⋆
1,...,z⋆
n] = fθ([z⋆
1,...,z⋆
n],x)
(6)"
REFERENCES,0.7037037037037037,"To verify our approach, we directly train and test on the largest vision datasets trained and reported
for implicit models. The ImageNet dataset (Deng et al., 2009) contains 128,1280 training images and
over 150K test images of resolution 224 × 224, which are distributed over 1,000 classes. Notably, as
the DEQ model is already trained and frozen, we do not perform data augmentations (e.g., random
cropping or horizontal ﬂipping, which are standard practice for training models) to the input images,
and make sure that the train/test inputs undergo the exact same transformations. The neural solver is
trained for 4000 steps, each with 10 HyperAnderson iterations."
REFERENCES,0.7063492063492064,"A.3
CITYSCAPES SEGMENTATION"
REFERENCES,0.708994708994709,"The other, even higher-resolution, vision dataset we apply the hypersolver on is the Cityscapes
dataset (Cordts et al., 2016). This is a large-scale dataset that contains a diverse set of high-quality
stereo video sequences recorded in street scenes from 50 different cities (at different times of the day,
spanning several months), with pixel-level annotations of 5,000 frames over 19 classes (e.g., road,
person, rider, truck, bus, etc.). Speciﬁcally, these 5,000 frames are divided into 2,975 training, 500
validation and 1,525 test images. The multiscale-DEQ (MDEQ) we use follow the exact formulation
as in the ImageNet case above, with 4 resolutions driven to the ﬁxed-point simultaneously."
REFERENCES,0.7116402116402116,"The Cityscapes pixel-level semantic segmentation task is also a standard widely-used bench-
mark (Chen et al., 2018a; Wang et al., 2020; Cheng et al., 2020), and is especially challenging
because of its rich contents and high resolution. To train the neural solver, as in ImageNet, we do not
perform data augmentations like horizontal ﬂipping (but perform random cropping to 1024 × 512) on
the training set, where we set the HyperAnderson step limit to K = 12 and the batch size to 6. The
neural solver is then evaluated in the standard full-resolution setting, on Cityscapes val 2048 × 1024
images."
REFERENCES,0.7142857142857143,"A.4
GROUNDTRUTH SOLVERS AND LOSS WEIGHTS"
REFERENCES,0.716931216931217,"In all of the experiments, we use the canonical Broyden’s method (Broyden, 1965) with 60 standard
quasi-Newton steps as the “groundtruth” solver that yields the exact ﬁxed point solution. However,
overall we found the choice of this high-precision solver not important as long as we run it for enough
number of steps to ensure proper convergence (e.g., a canonical Anderson acceleration algorithm
with 60 steps would also sufﬁce, since it’s the same groundtruth ﬁxed point)."
REFERENCES,0.7195767195767195,"The major hyperparameters introduced by the neural solver are the relative loss weights. For the
ﬁxed-point convergence loss Lconv = ∑K
k=1 wk∥z[k]−z⋆∥2 (see Sec. 4), we apply weights wk > 0 to all
intermediate HyperAnderson steps, with wk monotonically increasing (such as later HyperAnderson
steps are applied a heavier penalty for deviation from the ﬁxed point) and sum to 1; e.g., we can
simply do"
REFERENCES,0.7222222222222222,"wk =
k"
REFERENCES,0.7248677248677249,"∑K
i=1 i
(7)"
REFERENCES,0.7275132275132276,"Note that other similar formulations are possible, such as wk =
k2"
REFERENCES,0.7301587301587301,"∑K
i=1 i2 , and we generally do not ﬁnd
them empirically make a huge difference. We further illustrate this in the ablation studies presented
in Appendix C."
REFERENCES,0.7328042328042328,Published as a conference paper at ICLR 2022 . . .
REFERENCES,0.7354497354497355,Initializer hφ
REFERENCES,0.7380952380952381,Initial guess z[0] = . . .
REFERENCES,0.7407407407407407,Past m + 1 residuals
REFERENCES,0.7433862433862434,g✓(z[k+1])
REFERENCES,0.746031746031746,g✓(z[k−m])
REFERENCES,0.7486772486772487,g✓(z[k−m+1])
REFERENCES,0.7513227513227513,"G[k]
ˆG[k]
HyperAnderson Iteration (compression step)"
REFERENCES,0.753968253968254,"""The son of farmer… in 1932 .”"
REFERENCES,0.7566137566137566,Input (embeddings) x 2 RT ⇥d . . .
REFERENCES,0.7592592592592593,Linear + ReLU d
REFERENCES,0.7619047619047619,"p
d ≫p . . . . . . . . ."
REFERENCES,0.7645502645502645,"(A compressed
version of G[k],
independent of
input scale T) m + 1"
REFERENCES,0.7671957671957672,"Causal Conv1d
(kernel size 3)"
REFERENCES,0.7698412698412699,"Select the last
(most contextualized)
token and project"
REFERENCES,0.7724867724867724,Linear(·)
REFERENCES,0.7751322751322751,"(a) Visualization of DEQ-Transformer (for WikiText-103 language modeling) initializer and HyperAnderson
compression module."
REFERENCES,0.7777777777777778,=Conv2d (kernel size 3) + ReLU . . . . . .
REFERENCES,0.7804232804232805,Input (injection) x 2 RC⇥H⇥W
REFERENCES,0.783068783068783,Initializer hφ
REFERENCES,0.7857142857142857,Initial guess z[0] = . . . . . . . . . . . .
REFERENCES,0.7883597883597884,Past m + 1 residuals
REFERENCES,0.791005291005291,g✓(z[k+1])
REFERENCES,0.7936507936507936,g✓(z[k−m])
REFERENCES,0.7962962962962963,g✓(z[k−m+1])
REFERENCES,0.798941798941799,GlobalPool2d(·)
REFERENCES,0.8015873015873016,"Select lowest
resolution feature,
then global pool"
REFERENCES,0.8042328042328042,"G[k]
ˆG[k]"
REFERENCES,0.8068783068783069,"(A compressed
version of G[k],
independent of
input scale H, W)"
REFERENCES,0.8095238095238095,HyperAnderson Iteration (compression step) m + 1
REFERENCES,0.8121693121693122,"(b) Visualization of multiscale-DEQ (for ImageNet classiﬁcations and Cityscapes segmentations) initializer and
HyperAnderson compression module."
REFERENCES,0.8148148148148148,"Figure 6: Visualization of the neural equilibrium solver design. We use a local context and shallow
layer to build the initializer, and perform global pooling over the input (1D sequences or 2D images)
to create compressed (but representative) versions of the iterate G[k]."
REFERENCES,0.8174603174603174,"We applied a simple grid search on the relative loss weights λ1,λ2 and λ3 on the three losses, ﬁnding
it overall beneﬁcial to adjust these weights so that the 3 losses at the start of the training be at
roughly the same magnitude/scale. Moreover, we empirically ﬁnd it useful to set λ3 larger initially
to encourage Anderson-like iterations (cf. Eq. equation 2), but later gradually decay this weight to
almost 0, so that the hypersolver can more ﬂexibly exploit the αk in each HyperAnderson iterations.
In all experiments, we decay λ3 to 5e-8 on a linear schedule over 2,000 steps."
REFERENCES,0.8201058201058201,"B
ADDITIONAL DISCUSSIONS ON THE NEURAL EQULIBRIUM SOLVER
DESIGN"
REFERENCES,0.8227513227513228,"We brieﬂy illustrate in this section the designs of the initializer and the HyperAnderson iteration, and
how we make them both lightweight and expressive (of the feature map). This implies two design
principles that affect the model we use: 1) the hypersolver module itself should have an as minimial
number of parameters as possible, which implies projections to low-dimensions; 2) it should be also
invariant to input dimensionality while being able to cover the entire input. The second point is
especially important since the original implicit model can be applied on inputs of various scales (e.g.,
sequences of length, 100, 200, etc.; same for images), and so it is preferable that the neural solver
is also adaptive to such variety. We note that this rules out the learning-to-learn (L2L; see Sec. 2)
way of parameterizing optmizers by RNNs: whereas the parameter space has a ﬁxed dimensionality,
hidden unit space does not."
REFERENCES,0.8253968253968254,"HyperDEQ for sequences.
In the sequence modeling task, as mentioned in Sec. 4, our initializer
hφ is simply an 1D causal convolution followed by a non-linear projection (see Fig. 6a):"
REFERENCES,0.828042328042328,hφ(x) = ReLU(Conv1dk=3(x))W
REFERENCES,0.8306878306878307,"where
Conv1dk=3 ∶RT ×d →RT ×p
(1D causal convolution with kernel size 3)"
REFERENCES,0.8333333333333334,Published as a conference paper at ICLR 2022
REFERENCES,0.8359788359788359,"220
240
260
280
300
320
340
360
380
400
Inference ms/batch (size=12) 22 24 26 28 30 32 34 36"
REFERENCES,0.8386243386243386,Validation perplexity
REFERENCES,0.8412698412698413,Wikitext-103 Language Modeling (Ablative)
REFERENCES,0.843915343915344,"DEQ (no reg.) (Anderson)
DEQ (no reg.) (Broyden)"
REFERENCES,0.8465608465608465,"HyperDEQ (no reg.) (
= softmax( ))"
REFERENCES,0.8492063492063492,HyperDEQ (no reg.) (  unnormalized)
REFERENCES,0.8518518518518519,HyperDEQ (no reg.) (ours)
REFERENCES,0.8544973544973545,"(a) Ablations on the importance of α normalization
and learning.
curve is our proposed method."
REFERENCES,0.8571428571428571,"220
240
260
280
300
320
340
360
380
400
Inference ms/batch (size=12) 22 24 26 28 30 32 34 36"
REFERENCES,0.8597883597883598,Validation perplexity
REFERENCES,0.8624338624338624,Wikitext-103 Language Modeling (Ablative)
REFERENCES,0.8650793650793651,"DEQ (no reg.) (Anderson)
DEQ (no reg.) (Broyden)
HyperDEQ (no reg.) (wk = 1[k = K])"
REFERENCES,0.8677248677248677,HyperDEQ (no reg.) (uniform wk)
REFERENCES,0.8703703703703703,"HyperDEQ (no reg.) (no 
)"
REFERENCES,0.873015873015873,"HyperDEQ (no reg.) (no 
init)"
REFERENCES,0.8756613756613757,"HyperDEQ (no reg.) (no initializer)
HyperDEQ (no reg.) (ours)"
REFERENCES,0.8783068783068783,"(b) Ablations on loss components and relative loss
weights.
curve is our proposed method."
REFERENCES,0.8809523809523809,"Figure 7: Further ablations on the neural solver design (in terms of the α prediction and loss
components. Note that we use an unregularized DEQ here (in contrast to Fig. 5) to better demonstrate
the curve differences, which could sometimes be small.)"
REFERENCES,0.8835978835978836,"In particular, we set p ≪d (e.g., in the WikiText-103 experiment, d = 700 and p = 100) so that
this module requires little parameters and is fast to evaluate. We reiterate here that this is possible
because the goal of the initializer is not to solve the original problem (e.g., high-dimensional language
modeling), but only to give a “reasonable” initial guess to the ﬁxed point solver. In other words,
the initial guess itself may be bad in a task perspective (as we veriﬁed in Table 1) but good in an
optimization perspective (see Fig. 5)."
REFERENCES,0.8862433862433863,"Moreover, we compress the past and current residuals G[k] = [gθ(z[k−m]),...,gθ(z[k+1])] ∈
R(m+1)×T ×q by simply taking the last and most contextualized token of each sequence; i.e.,
(gθ(z[i]))T ∈Rq. This is reasonable because the design of a sequence model like Transformer
layers (which parameterizes our fθ for DEQ) already ensures that the last token contains most of
the contextual information of the entire sequence (and this technique is frequently used for textual
classiﬁcation tasks, or in vision transformers (Dosovitskiy et al., 2020)). We therefore propose to
compress the past residuals of the ﬁxed point estimates by directly using the (a projection of the) very
last tokens (see Fig. 6a), which are collected and treated as a mini time-series as mentioned in Sec. 4."
REFERENCES,0.8888888888888888,"HyperDEQ (multiscale) for vision.
The initializer for multiscale DEQ models is similarly de-
signed, with a series of small-context 1-layer convolutions (e.g., kernel size 3) to generate the initial
guess for each resolution stream (see Fig. 6b). To compress the past residuals, we leverage the fact
that all resolutions are fused in each layer of the multiscale DEQ design, and only take the lowest-
resolution feature map z[i]
n of the past ﬁxed point estimate z[i] = [z[i]
1 ,...,z[i]
n ] (in practice, we use
n = 4). As shown in Fig. 6b, we directly apply global pooling to pass into the later HyperAnderson
steps (by treating it as a mini time-series, like in the sequence case)."
REFERENCES,0.8915343915343915,"C
ADDITIONAL EFFICIENCY AND ABLATIVE STUDIES"
REFERENCES,0.8941798941798942,"We further study some ablative settings not covered in Sec. 5.3 here. We speciﬁcally focus on two
aspects: 1) how α is predicted; and 2) the effects of different loss components."
REFERENCES,0.8968253968253969,"In the original AA prototype, the values of α is determined by solving a least-squared solution over
the past m steps, as described by the constrained optimization problem equation 2. In particular,
these αk = (αk
0,...,αk
m) values can be any real value, but has to sum to 1. In our hypersolver, we
propose to “normalize” the predicted ˆαk by a shift: αk = ˆαk + (1−1⊺ˆαk)"
REFERENCES,0.8994708994708994,"mk+1
⋅1. We here compare two
alternatives: no normalization at all (i.e., have α learned freely; see
in Fig. 7a), and softmax-based
normalization (i.e., requiring αk to be all-positive; see
in Fig. 7a). Speciﬁcally, we ﬁnd that the
exact choice of α normalization does not affect the overall substantial pareto curve improvement
(e.g., compare them with the Y curve baseline), but ensuring that the αk values can be negative while"
REFERENCES,0.9021164021164021,Published as a conference paper at ICLR 2022
REFERENCES,0.9047619047619048,"2
4
6
8
10
Fixed-point solver step K 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40"
REFERENCES,0.9074074074074074,"Relative residual 
|f(z)
z|
|z|"
REFERENCES,0.91005291005291,"Fixed-point Convergence (WT103, Jacobian reg.)"
REFERENCES,0.9126984126984127,"Canonical Anderson
Neural Solver (trained on K = 6)"
REFERENCES,0.9153439153439153,"(a) The neural equilibrium solver improves upon the
convergence path of canonical Anderson acceleration.
The speedup of HyperDEQ is a result of this faster
convergence and the more lightweight solver step."
REFERENCES,0.917989417989418,"0
50
100
150
200
Training Time w/ 4 GPUs (Hours) 25 30 35 40 45 50"
REFERENCES,0.9206349206349206,Validation Set Perplexity
REFERENCES,0.9232804232804233,Training WT103 Perplexity vs. Time
REFERENCES,0.9259259259259259,"DEQ
DEQ (reg.)
HyperDEQ (reg.) (ours)"
REFERENCES,0.9285714285714286,"(b) Hypersolver can also be used at training time to
further accelerate the DEQ model training by alter-
nating their training (in addition to existing methods
like Jacobian stabilization)."
REFERENCES,0.9312169312169312,"Figure 8: Left: Convergence analysis of the hypersolver at inference time. Right: Although trained
with a frozen fθ, the neural equilibrium solver can also be used to accelerate DEQ training."
REFERENCES,0.9338624338624338,"still normalized (i.e., sum to 1) overall beneﬁt the performance. For instance, with the same inference
speed, we get a 1-1.5 perplexity improvement."
REFERENCES,0.9365079365079365,"We also analyze the effect of different loss components in Fig. 7b. For the main ﬁxed-point conver-
gence loss Lconv, we compare two alternatives of the relative weights applied on the intermediate
HyperAnderson steps: only apply wk = 1 at the ﬁnal output K (see  curve), or set wk to be uniform
for all k (see  curve). We empirically ﬁnd that the hypersolver trained in both scenarios perform
well, but the monotonically incresing wk we use (i.e., putting larger emphasis on later iterations)
perform best. Moreover, removing either the initializer loss Linit (note that we still keep the initializer
hφ itself, just don’t supervise it; see the ) or the alpha loss (the
curve) Lα impacts the performance.
Interestingly, removing the Linit loss on the initializer yields even worse performance than even
removing the initializer itself (the
curve). However, we note that all of these ablative settings still
signiﬁcantly outperform the speed/accuracy efﬁciency than the generic solvers, which suggests the
overall beneﬁt of using customized learnable solvers for implicit models."
REFERENCES,0.9391534391534392,"Finally, we provide additional empirical evidence on the convergence and generalizability of the
neural solvers in Fig. 8a, where we compare the convergence of a pre-trained, regularized Transformer-
based DEQ model under 1) canonical Anderson acceleration; and 2) a neural solver (with initializer)
trained to unroll for K = 6 HyperAnderson steps. The shaded areas around the curves correspond
to the standard deviation of the relative residual at each solver step, measured on 1000 randomly
selected textual sequences of length 100. From Figure 8a, we ﬁrst note that a hypersolver trained
with K unrolling steps is able to generalize (i.e., converge well) beyond K, although both solvers
eventually plateau at some of ε residual value. Second, with the parameterized ﬁxed-point solving,
we see that the neural solver consistently improves over the canonical solver’s convergence, while
being more lightweight to compute (i.e., each solver neural solver step is cheaper than canonical
Anderson step), which account for the 2× speedup we observe across the board for DEQ model
inference efﬁciency in Sec. 5."
REFERENCES,0.9417989417989417,"D
USE HYPERSOLVER FOR DEQ TRAINING"
REFERENCES,0.9444444444444444,"It turns out we could also leverage its acceleration power to improve the not just the inference but
also training of the original DEQ model (i.e., replace the classical solver at DEQ training with a
hypersolver). However, we note three major caveats. First, as the DEQ model is being trained (e.g.,
by SGD), parameterization of the layer fθ also changes, which means the ﬁxed-point manifold of this
implicit model constantly gets updated. Therefore, a neural deep equilibrium solver {hφ,sξ} trained
on a parameter state fθ0 may gradually deviate from accurate and stable convergence as fθ also
deviates from fθ0 as a result of more and more parameter updates. Second, precisely computing the
groundtruth ﬁxed points z⋆with a classical solver at every training step would add heavy burden to
the training overhead. Third, the usage of hypersolver to solve forward pass ﬁxed point does not affect
the backward pass implicit differentiation (notably, decoupled forward and backward trajectories is"
REFERENCES,0.9470899470899471,Published as a conference paper at ICLR 2022
REFERENCES,0.9497354497354498,"also a major feature of implicit models), implying the training efﬁciency improvement will be much
smaller than that at the inference time (about 2×, as mentioned in Sec. 5)."
REFERENCES,0.9523809523809523,"Despite these challenges, exploiting the fact that model parameters θ drift only gradually with training
iterations (i.e., at training step t and t + 1, we assume ∥θt −θt+1∥is small), we propose to train the
neural solver {hφ,sξ} (which are tiny, lightweight, and have little representational capacity) and the
implicit layer fθ (which are huge, representationally rich, and requires many training steps) in an
alternating way. Speciﬁcally, we adopt the following procedure:"
REFERENCES,0.955026455026455,1. Warmup and train the DEQ model for some small number of steps.
REFERENCES,0.9576719576719577,"2. Take a snapshot of the current implicit layer fθ and train from scratch a hypersolver {hφ,sξ}
customized on top of it."
REFERENCES,0.9603174603174603,"3. Use the current hypersolver {hφ,sξ} to solve for the ﬁxed point and train the DEQ model
for the next M steps."
REFERENCES,0.9629629629629629,"4. Take a snapshot of the current implicit layer fθ, and ﬁne-tune the existing hypersolver
{hφ,sξ} on top of it by minimizing L(ω,K) for some T hypersolver training steps."
REFERENCES,0.9656084656084656,5. Repeat step 3 & 4 until we reach max training steps for the DEQ model.
REFERENCES,0.9682539682539683,"Empirically, we ﬁnd that the proposed neural solver generalizes surprisingly well for values of M
that are not too large (i.e., even though fθ gets updated, the hypersolver can still reliably converge to
the correct ﬁxed points during the next M DEQ training steps). Moreover, as previously mentioned,
training neural solver is extremely lightweight, and even more so for ﬁne-tuning it, suggesting that T
is very small in pratice. For example, on WikiText-103 language modeling with a transformer-based
fθ (which has 300K DEQ training steps), we set M = 5000 and T = 200; in other words, we ﬁne-tune
the hypersolver for merely 200 steps (again, on very small batch size and sequence length; see
Table 2) after every 5000 DEQ training steps, in order to keep the neural solver “up to date” with the
implicit layer. This extra (but minor) cost of constantly ﬁne-tuning hypersolver is counterbalanced by
the huge gain in using hypersolver over a canonical generic root solver."
REFERENCES,0.9708994708994709,"Fig. 8b shows the training efﬁciency improvement as a result of adopting hypersolver in DEQ training.
With the hypersolver ﬁne-tuned intermittently (green curve), we are able to reduce the total training
time over that of the classical-solver-based DEQ counterpart by about 20% (purple curve). Note that
just like at inference time, this improvement via hypersolver is orthogonal (and thus additional) to the
acceleration effect of regularization-based methods, like Jacobian regularizations (cf. purple and pink
curves)."
REFERENCES,0.9735449735449735,"E
ADDITIONAL EXPERIMENT ON TINY EQUILIBRIUM MODELS"
REFERENCES,0.9761904761904762,While Fig. 4 provides strong evidence on how the hypersolver could improve the speed/accuracy
REFERENCES,0.9788359788359788,"0
10
20
30
40
50
Inference ms/batch (size=16)"
REFERENCES,0.9814814814814815,"72
74
76
78
80
82
84
86
88"
REFERENCES,0.9841269841269841,Accuracy
REFERENCES,0.9867724867724867,CIFAR-10 classification (no augmentation)
REFERENCES,0.9894179894179894,"DEQ (reg.) (Anderson)
HyperDEQ (reg.) (ours)"
REFERENCES,0.9920634920634921,ResNet-18
REFERENCES,0.9947089947089947,"Figure 9: The beneﬁt of hypersolver holds on
tiny implicit models. Inference speed is bench-
marked with batch size 16, averaged over 5 runs."
REFERENCES,0.9973544973544973,"pareto efﬁciency of these large-scale DEQ mod-
els (e.g., DEQ-Transformer contains almost 100M
parameters), we also perform additional exper-
iments to validate its efﬁcacy on much smaller
networks. Speciﬁcally, we train a hypersolver on a
tiny MDEQ model that is pretrained on CIFAR-10
classiﬁcation task (the same setting as in Bai et al.
(2020), but with Jacobian regularization) which
contains only 170K parameters. The hypersolver
contains about 8K parameters (including the ini-
tializer hφ), and is trained for only 1000 training
steps. The results are shown in Fig. 9. The im-
provement in pareto frontier again suggests that
the neural solvers provide a lightweight and yet
effective solution to improving these implicit models."
