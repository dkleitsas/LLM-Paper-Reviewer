Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0008410428931875525,"Meta-learning has been demonstrated to be useful to improve the sampling efﬁ-
1"
ABSTRACT,0.001682085786375105,"ciency of Bayesian optimization (BO) and surrogate-assisted evolutionary algo-
2"
ABSTRACT,0.002523128679562658,"rithms (SAEAs) when solving expensive optimization problems (EOPs). However,
3"
ABSTRACT,0.00336417157275021,"existing studies focuses on only single-objective optimization, leaving other ex-
4"
ABSTRACT,0.004205214465937763,"pensive optimization scenarios unconsidered. We propose a generalized few-shot
5"
ABSTRACT,0.005046257359125316,"evolutionary optimization (FSEO) framework and focus on its performance on two
6"
ABSTRACT,0.005887300252312868,"common expensive optimization scenarios: multi-objective EOPs (EMOPs) and
7"
ABSTRACT,0.00672834314550042,"constrained EOPs (ECOPs). We develop a novel meta-learning modeling approach
8"
ABSTRACT,0.007569386038687973,"to train surrogates for our FSEO framework, an accuracy-based update strategy is
9"
ABSTRACT,0.008410428931875526,"designed to adapt surrogates during the optimization process. The surrogates in
10"
ABSTRACT,0.009251471825063078,"FSEO framework combines neural network with Gaussian Processes (GPs), their
11"
ABSTRACT,0.010092514718250631,"network parameters and some parameters of GPs represent useful experience and
12"
ABSTRACT,0.010933557611438183,"are meta-learned across related optimization tasks, the remaining GPs parameters
13"
ABSTRACT,0.011774600504625737,"are task-speciﬁc parameters that represent unique features of the target task. We
14"
ABSTRACT,0.012615643397813289,"demonstrate that our FSEO framework is able to improve sampling efﬁciency on
15"
ABSTRACT,0.01345668629100084,"both EMOP and ECOP. Empirical conclusions are made to guide the application of
16"
ABSTRACT,0.014297729184188394,"our FSEO framework.
17"
INTRODUCTION,0.015138772077375946,"1
Introduction
18"
INTRODUCTION,0.0159798149705635,"Expensive optimization problems (EOPs) aim to ﬁnd as good as possible solutions within a budget
19"
INTRODUCTION,0.01682085786375105,"of limited solution evaluations. Conventional Bayesian optimization (BO) and surrogate-assisted
20"
INTRODUCTION,0.017661900756938603,"evolutionary algorithms (SAEAs) have been widely used to solve EOPs, but they train surrogate
21"
INTRODUCTION,0.018502943650126155,"models from the scratch. To further improve the sampling efﬁciency and optimization performance,
22"
INTRODUCTION,0.01934398654331371,"many efforts have been made to pre-train surrogates with the prior experience gain from related
23"
INTRODUCTION,0.020185029436501262,"optimization tasks, resulting in experience-based optimization algorithms [1, 21, 36, 35].
24"
INTRODUCTION,0.021026072329688814,"This work considers solving EOPs on the context of few-shot problems [5, 41], where plenty of
25"
INTRODUCTION,0.021867115222876366,"expensive related tasks are available and each of them can provide a small dataset for experience
26"
INTRODUCTION,0.022708158116063918,"learning. Therefore, many experience-based optimization approaches such as multi-tasking optimiza-
27"
INTRODUCTION,0.023549201009251473,"tion [43, 2, 47], transfer optimization [35, 17, 16] are not considered as they cannot learn experience
28"
INTRODUCTION,0.024390243902439025,"from small related tasks (A discussion is available in Appendix A). In comparison, meta-learning
29"
INTRODUCTION,0.025231286795626577,"[14] has been proved to be powerful in solving few-shot problems, leading to a new subcategory of
30"
INTRODUCTION,0.02607232968881413,"experience-based optimization, namely few-shot optimization (FSO) [46].
31"
INTRODUCTION,0.02691337258200168,"Existing studies on FSO are mainly few-shot Bayesian optimization (FSBO) where meta-learning
32"
INTRODUCTION,0.027754415475189236,"approaches are combined with BO to solve EOPs with only one objective. In this paper, we propose
33"
INTRODUCTION,0.028595458368376788,"a generalized few-shot evolutionary optimization (FSEO) framework to address EOPs from the
34"
INTRODUCTION,0.02943650126156434,"perspective of SAEAs and consider two expensive optimization scenarios which have been limited
35"
INTRODUCTION,0.030277544154751892,"studied: multi-objective EOPs (EMOPs) and constrained EOPs (ECOPs). Major contributions are
36"
INTRODUCTION,0.031118587047939444,"summarized as follows.
37"
INTRODUCTION,0.031959629941127,"• A novel meta-learning method, namely Meta Deep Kernel Learning (MDKL), is developed
38"
INTRODUCTION,0.03280067283431455,"to gain prior experience from related expensive tasks. Our model architecture and parameter
39"
INTRODUCTION,0.0336417157275021,"designs make it possible to generate a regression-based surrogate on the prior experience
40"
INTRODUCTION,0.034482758620689655,"and then continually adapt the surrogate to approximate the target task.
41"
INTRODUCTION,0.03532380151387721,"• We propose a FSEO framework to solve EOPs from the perspective of SAEAs. FSEO
42"
INTRODUCTION,0.03616484440706476,"framework is applicable to regression-based SAEAs since FSEO embed our meta-learning
43"
INTRODUCTION,0.03700588730025231,"models in these SAEAs as their surrogates. In addition, an update strategy is designed to
44"
INTRODUCTION,0.03784693019343986,"adapt surrogates constantly during the optimization. Note that our FSEO framework is a
45"
INTRODUCTION,0.03868797308662742,"general framework but we focus on its performance on EMOPs and ECOPs in this paper.
46"
INTRODUCTION,0.03952901597981497,"• Experiments are conducted on EMOPs and ECOPs to show our FSEO framework is effec-
47"
INTRODUCTION,0.040370058873002525,"tive. Our comprehensive ablation studies discover the inﬂuence of some factors on FSEO
48"
INTRODUCTION,0.04121110176619008,"performance and provide empirical guidance to the application of FSEO framework.
49"
RELATED WORK,0.04205214465937763,"2
Related Work
50"
RELATED WORK,0.04289318755256518,"Experience-based optimization can be divided into several subcategories according to the techniques
51"
RELATED WORK,0.04373423044575273,"of learning prior experience from related tasks. A detailed classiﬁcation and discussion on these
52"
RELATED WORK,0.044575273338940284,"subcategories is available in Appendix A. This subsection focuses on related work on FSO.
53"
RELATED WORK,0.045416316232127836,"FSO studies in the literature can be classiﬁed based on their model architectures. Most studies meta-
54"
RELATED WORK,0.04625735912531539,"learn parameters for Gaussian Processes (GPs) [44], namely FSBO or Meta Bayesian Optimization
55"
RELATED WORK,0.04709840201850295,"(MBO) [32, 42, 26, 38]. In addition, [23] meta-learns with transformer neural processes and [46, 6]
56"
RELATED WORK,0.0479394449116905,"meta-learn parameters for the architecture of deep kernel learning (DKL) [45]. The MDKL model in
57"
RELATED WORK,0.04878048780487805,"our FSEO belongs to the last category as its model architecture is relevant to DKL.
58"
RELATED WORK,0.0496215306980656,"Our work is different from existing studies in three points: Firstly, many studies [46] use existing
59"
RELATED WORK,0.050462573591253154,"meta-learning models [27] as their surrogates. No further adaptations are made to these surrogates
60"
RELATED WORK,0.051303616484440706,"during optimization since they are not originally designed for optimization. In comparison, we try to
61"
RELATED WORK,0.05214465937762826,"develop a meta-learning model, MDKL, for optimization purpose. MDKL has explicit task-speciﬁc
62"
RELATED WORK,0.05298570227081581,"parameters, which allows continually model adaptations during the optimization. Secondly, existing
63"
RELATED WORK,0.05382674516400336,"work investigated only global optimization, leaving other optimization scenarios such as EMOP and
64"
RELATED WORK,0.054667788057190914,"ECOP still awaiting for investigation. As our MDKL is designed for optimization and is capable of
65"
RELATED WORK,0.05550883095037847,"continually adaptation, we pay attention on EMOPs and ECOPs which require more effective models
66"
RELATED WORK,0.056349873843566024,"than global optimization. Our work widens the scope of existing FSO research and it focuses on the
67"
RELATED WORK,0.057190916736753576,"perspective of SAEAs instead of BO. Lastly, in-depth ablation studies are lacking in the literature,
68"
RELATED WORK,0.05803195962994113,"making it unclear which factors affect the performance of FSO. Our extensive ablation studies ﬁll
69"
RELATED WORK,0.05887300252312868,"this gap and we conclude some empirical rules to improve the performance of FSO.
70"
BACKGROUND,0.05971404541631623,"3
Background
71"
BACKGROUND,0.060555088309503784,"This section gives preliminaries about meta-learning and DKL. The former is the method of experience
72"
BACKGROUND,0.061396131202691336,"learning, the latter is the underlying structure of experience representation.
73"
META-LEARNING IN FEW-SHOT PROBLEMS,0.06223717409587889,"3.1
Meta-Learning in Few-Shot Problems
74"
META-LEARNING IN FEW-SHOT PROBLEMS,0.06307821698906645,"In the context of few-shot problems, we have plenty of related tasks, each task T contributes a couple
75"
META-LEARNING IN FEW-SHOT PROBLEMS,0.063919259882254,"of small datasets D = {(S, Q)}, namely support dataset S and query dataset Q, respectively. After
76"
META-LEARNING IN FEW-SHOT PROBLEMS,0.06476030277544155,"learning from datasets of random related tasks, a support set S∗from new unseen task T∗is given
77"
META-LEARNING IN FEW-SHOT PROBLEMS,0.0656013456686291,"and one is asked to estimate the labels or values of a query set Q∗. The problem is called 1-shot or
78"
META-LEARNING IN FEW-SHOT PROBLEMS,0.06644238856181665,"5-shot when only 1 data point or 5 data points are provided in S∗. A comprehensive deﬁnition of
79"
META-LEARNING IN FEW-SHOT PROBLEMS,0.0672834314550042,"few-shot problems is available in [5, 41].
80"
META-LEARNING IN FEW-SHOT PROBLEMS,0.06812447434819176,"Meta-learning methods have been widely used to solve few-shot problems [41]. They learn domain-
81"
META-LEARNING IN FEW-SHOT PROBLEMS,0.06896551724137931,"speciﬁc features that are shared among related tasks as experience, such experience is used to
82"
META-LEARNING IN FEW-SHOT PROBLEMS,0.06980656013456686,"understand and interpret the data collected from new tasks encountered in the future.
83"
META-LEARNING IN FEW-SHOT PROBLEMS,0.07064760302775441,"3.2
Deep Kernel Learning (DKL)
84"
META-LEARNING IN FEW-SHOT PROBLEMS,0.07148864592094197,"DKL aims at constructing kernels that encapsulate the expressive power of deep architectures for GPs.
85"
META-LEARNING IN FEW-SHOT PROBLEMS,0.07232968881412952,"To create expressive and scalable closed form covariance kernels, DKL combines the non-parametric
86"
META-LEARNING IN FEW-SHOT PROBLEMS,0.07317073170731707,"ﬂexibility of kernel methods and the structural properties of deep neural networks. In practice, a deep
87"
META-LEARNING IN FEW-SHOT PROBLEMS,0.07401177460050462,"kernel k(xi, xj|γ) transforms the inputs x of a base kernel k(xi, xj|θ) through a non-linear mapping
88"
META-LEARNING IN FEW-SHOT PROBLEMS,0.07485281749369217,"given by a deep architecture φ(x|w, b):
89"
META-LEARNING IN FEW-SHOT PROBLEMS,0.07569386038687972,"k(xi, xj|γ) = k(φ(xi|w, b), φ(xj|w, b)|θ),
(1)"
META-LEARNING IN FEW-SHOT PROBLEMS,0.07653490328006729,"where θ and (w, b) are parameter vectors of the base kernel and the deep architecture, respectively.
90"
META-LEARNING IN FEW-SHOT PROBLEMS,0.07737594617325484,"γ = {θ, w, b} is the set of all parameters in this deep kernel. Note that in DKL, all parameters γ of a
91"
META-LEARNING IN FEW-SHOT PROBLEMS,0.0782169890664424,"deep kernel k(xi, xj|γ) are learned jointly by using the log marginal likelihood function of GPs as a
92"
META-LEARNING IN FEW-SHOT PROBLEMS,0.07905803195962995,"loss function. Such a jointly learning strategy has been shown to make a DKL algorithm outperform
93"
META-LEARNING IN FEW-SHOT PROBLEMS,0.0798990748528175,"a combination of a deep neural network and a GP model, where a trained GP model is applied to the
94"
META-LEARNING IN FEW-SHOT PROBLEMS,0.08074011774600505,"output layer of a trained deep neural network [45].
95"
META-LEARNING ON DKL,0.0815811606391926,"3.3
Meta-Learning on DKL
96"
META-LEARNING ON DKL,0.08242220353238015,"An important distinction between DKL algorithms and the applications of meta-learning to DKL is
97"
META-LEARNING ON DKL,0.0832632464255677,"that DKL algorithms learn their deep kernels from single tasks instead of collections of related tasks.
98"
META-LEARNING ON DKL,0.08410428931875526,"Such a difference alleviates two drawbacks of single task DKL [39]: First, the scalability of deep
99"
META-LEARNING ON DKL,0.08494533221194281,"kernels is no longer an issue as datasets in meta-learning are small. Second, the risk of overﬁtting is
100"
META-LEARNING ON DKL,0.08578637510513036,"decreased since diverse data points are sampled across tasks.
101"
META-LEARNING ON DKL,0.08662741799831791,"4
Few-Shot Evolutionary Optimization (FSEO) Framework
102"
META-LEARNING ON DKL,0.08746846089150546,"In this paper, T∗denotes the target optimization task, and plenty of small datasets Di sampled from
103"
META-LEARNING ON DKL,0.08830950378469302,"related tasks Ti are available for experience learning. A complete list of notations is available at the
104"
META-LEARNING ON DKL,0.08915054667788057,"beginning of Appendix.
105"
OVERALL WORKING MECHANISM,0.08999158957106812,"4.1
Overall Working Mechanism
106"
OVERALL WORKING MECHANISM,0.09083263246425567,Figure 1: Diagram of our FSEO framework.
OVERALL WORKING MECHANISM,0.09167367535744322,"As illustrated in Fig. 1, all modules covering the optimization of target task T∗are included in a
107"
OVERALL WORKING MECHANISM,0.09251471825063078,"grey block. The modules beyond the grey block are associated with related tasks Ti and experience
108"
OVERALL WORKING MECHANISM,0.09335576114381834,"learning, which distinguishes our FSEO framework from conventional SAEAs and BO. The MDKL
109"
OVERALL WORKING MECHANISM,0.0941968040370059,"surrogate modeling method consists of two procedures: meta-learning procedure and adaptation
110"
OVERALL WORKING MECHANISM,0.09503784693019345,"procedure. The former learns prior experience from Ti, the latter uses experience to adapt surrogates
111"
OVERALL WORKING MECHANISM,0.095878889823381,"to ﬁt T∗. The framework of FSEO is depicted in Alg. 1, it consists of the following major steps.
112"
OVERALL WORKING MECHANISM,0.09671993271656855,"1. Experience learning: Before expensive optimization starts, a meta-learning procedure is
113"
OVERALL WORKING MECHANISM,0.0975609756097561,"conducted to train task-independent parameters γe for MDKL surrogates (line 2). Nm
114"
OVERALL WORKING MECHANISM,0.09840201850294365,"datasets {Dm1, . . . , DmNm} collected from N related tasks {T1, . . . , TN} are used to train
115"
OVERALL WORKING MECHANISM,0.0992430613961312,"γe. γe is the experience that represents the domain-speciﬁc features of related tasks.
116"
OVERALL WORKING MECHANISM,0.10008410428931876,"2. Initialize surrogates with experience: Optimization starts when a target optimization task
117"
OVERALL WORKING MECHANISM,0.10092514718250631,"T∗is given. An initial dataset S∗is sampled (line 3) to adapt task-speciﬁc parameters γ∗on
118"
OVERALL WORKING MECHANISM,0.10176619007569386,"the basis of experience γe. After that, MDKL surrogates are updated (line 4).
119"
OVERALL WORKING MECHANISM,0.10260723296888141,"3. Reproduction: MDKL surrogates h(γ∗) are combined with a SAEA optimizer Opt to
120"
OVERALL WORKING MECHANISM,0.10344827586206896,"search for optimal solution(s) x∗on h(γ∗) (line 7). This is implemented by replacing the
121"
OVERALL WORKING MECHANISM,0.10428931875525652,"original (regression-based) surrogates in a SAEA with h(γ∗).
122"
OVERALL WORKING MECHANISM,0.10513036164844407,"4. Update archive and surrogates: New optimal solution(s) x∗is evaluated on target task T∗
123"
OVERALL WORKING MECHANISM,0.10597140454163162,"(line 8). The evaluated solutions will be added to dataset S∗(line 9) which serves as an
124"
OVERALL WORKING MECHANISM,0.10681244743481917,"archive. Then, surrogate adaptation is triggered, surrogates h(γ∗) are updated (line 10).
125"
OVERALL WORKING MECHANISM,0.10765349032800672,"5. Stop criterion: Once the evaluation budget has run out, the evolutionary optimization will
126"
OVERALL WORKING MECHANISM,0.10849453322119428,"be terminated and the optimal solutions in dataset S∗will be outputted. Otherwise, the
127"
OVERALL WORKING MECHANISM,0.10933557611438183,"algorithm goes back to step 3.
128"
OVERALL WORKING MECHANISM,0.11017661900756939,Algorithm 1 FSEO Framework.
OVERALL WORKING MECHANISM,0.11101766190075694,"1: Input: Di: Datasets collected from related tasks Ti, i={1, . . . , N}; Nm: Number of subsets Dm
for meta-learning; |Dm|: Size of subsets Dm. |Dm| ≤|Di| due to Dm ⊆Di; Batch size B;
Surrogate learning rates α, β; Target task T∗; A SAEA optimizer Opt; Fitness evaluation budget
FEmax.
2: Experience γe ←Meta-learning(Di, Nm, |Dm|, B, α). /∗Alg. 2.∗/
3: S∗←Sampling 1d solutions from T∗.
4: h(γ∗) ←Adaptation(γe, S∗, β). /∗Initialize surrogate.∗/
5: Set evaluation counter FE = |S∗|.
6: while FE < FEmax do
7:
Candidate solution(s) x∗←Surrogate-assisted optimization (Opt, h(γ∗)).
8:
f(x∗) ←Evaluate x∗on T∗.
9:
S∗←S∗∪{(x∗, f(x∗))}.
10:
h(γ∗) ←Update(γ∗, S∗, β). /∗Alg. 4.∗/
11:
Update FE.
12: end while
13: Output: Optimal solutions in S∗."
LEARNING AND USING EXPERIENCE BY MDKL,0.1118587047939445,"4.2
Learning and Using Experience by MDKL
129"
LEARNING AND USING EXPERIENCE BY MDKL,0.11269974768713205,"In MDKL, the domain-speciﬁc features of related tasks are used as experience, which are represented
130"
LEARNING AND USING EXPERIENCE BY MDKL,0.1135407905803196,"by the task-independent parameters γe learned across related tasks. To make MDKL more capable of
131"
LEARNING AND USING EXPERIENCE BY MDKL,0.11438183347350715,"expressing complex domain-speciﬁc features, the base kernel k(xi, xj| θ) in GP is combined with a
132"
LEARNING AND USING EXPERIENCE BY MDKL,0.1152228763666947,"neural network φ(w, b) to construct a deep kernel (see Eq.(1)). The modeling of a MDKL model
133"
LEARNING AND USING EXPERIENCE BY MDKL,0.11606391925988226,"consists of two procedures: meta-learning procedure and adaptation procedure. To make a clear
134"
LEARNING AND USING EXPERIENCE BY MDKL,0.11690496215306981,"illustration, we introduce frameworks of two procedures and then explain them in detail.
135"
LEARNING AND USING EXPERIENCE BY MDKL,0.11774600504625736,"Meta-learning procedure: Learning experience
136"
LEARNING AND USING EXPERIENCE BY MDKL,0.11858704793944491,"Our MDKL model uses the kernel in [18] as its base kernel:
137"
LEARNING AND USING EXPERIENCE BY MDKL,0.11942809083263246,"k(xi, xj|θ, p) = exp(− d
X"
LEARNING AND USING EXPERIENCE BY MDKL,0.12026913372582002,"k=1
θk|xi
k −xj
k|pk).
(2)"
LEARNING AND USING EXPERIENCE BY MDKL,0.12111017661900757,"Therefore, the deep kernel will be:
138"
LEARNING AND USING EXPERIENCE BY MDKL,0.12195121951219512,"k(xi, xj|γ) = exp(− d
X"
LEARNING AND USING EXPERIENCE BY MDKL,0.12279226240538267,"k=1
θk|φ(xi
k) −φ(xj
k)|pk),
(3)"
LEARNING AND USING EXPERIENCE BY MDKL,0.12363330529857022,"where γ = {w, b, θ, p} is a set of deep kernel parameters. φ, w and b are neural network and its
139"
LEARNING AND USING EXPERIENCE BY MDKL,0.12447434819175777,"parameters (see Eq.(1)). Details about alternative base kernels are available in [44].
140"
LEARNING AND USING EXPERIENCE BY MDKL,0.12531539108494533,"The aim of meta-learning procedure is to learn experience γe from related tasks {T1, . . . , TN},
141"
LEARNING AND USING EXPERIENCE BY MDKL,0.1261564339781329,"including neural network parameters w, b, and task-independent base kernel parameters θe, pe. The
142"
LEARNING AND USING EXPERIENCE BY MDKL,0.12699747687132043,"pseudo-code of meta-learning procedure is given in Alg. 2. Ideally, the experience γe is learned from
143"
LEARNING AND USING EXPERIENCE BY MDKL,0.127838519764508,"plenty of (Nm) small datasets Dm collected from different related tasks. However, in practice, the
144"
LEARNING AND USING EXPERIENCE BY MDKL,0.12867956265769553,"number of available related tasks N may be much smaller than Nm. Hence, the meta-learning is
145"
LEARNING AND USING EXPERIENCE BY MDKL,0.1295206055508831,"conducted gradually over U update iterations (line 3). During each update iteration, a small batch of
146"
LEARNING AND USING EXPERIENCE BY MDKL,0.13036164844407064,"related
tasks
contribute
B
small
datasets
{Dm1, . . . , DmB}
for
meta-learning
purpose
(lines 5 and 7). Note that
if N < Nm, a related task
Ti can be used multiple
times in the meta-learning
procedure.
For a given dataset Dmi,
we denote θi = θe + ∆θi
and pi = pe + ∆pi as
the task-speciﬁc kernel pa-
rameters, where ∆θi, ∆pi
are the distance we need
to move from the task-
independent parameters to
the task-speciﬁc parame-
ters (line 9). The loss func-
tion L of MDKL is the like-
lihood function deﬁned as
follows [18]:"
LEARNING AND USING EXPERIENCE BY MDKL,0.1312026913372582,"Algorithm 2 Meta-learning(Di, Nm, |Dm|, B, α)"
LEARNING AND USING EXPERIENCE BY MDKL,0.13204373423044574,"1: Input: Di: Datasets collected from related tasks Ti, i={1, . . . , N}; Nm:
Number of subsets Dm for meta-learning; |Dm|: Size of subsets Dm.
|Dm| ≤|Di| due to Dm ⊆Di; Batch size B; Learning rate for priors α.
2: Randomly initialize w, b, θe, pe.
3: Set the number of update iterations U = Nm/B.
4: for j = 1 to U do
5:
{D′
1, . . . , D′
B}
←Randomly select a batch of datasets from
{D1, . . . , DN}.
6:
for all D′
i in the batch do
7:
Dmi ←A subset of size |Dm| from D′
i.
8:
Initialize task-speciﬁc increment ∆θi, ∆pi.
9:
Compute task-speciﬁc parameters: θi = θe + ∆θi,pi = pe + ∆pi.
10:
Obtain deep kernel k(xi, xj|γ) based GP: h(γ), where γ
=
{w, b, θi, pi} (Eq.(3)).
11:
Compute the loss function L(Dmi, h(γ)) (Eq.(4)).
12:
end for
13:
Update w, b, θe, pe via gradient descent: α ▽L(Dmi, h(γ)) (Eq.(5)).
14: end for
15: Output: Task-independent parameters: γe = {w, b, θe, pe}. 147"
LEARNING AND USING EXPERIENCE BY MDKL,0.1328847771236333,"1
(2π)n/2(σ2)n/2|R|1/2 exp[−(y −1µ)T R−1(y −1µ)"
LEARNING AND USING EXPERIENCE BY MDKL,0.13372582001682085,"2σ2
],
(4)"
LEARNING AND USING EXPERIENCE BY MDKL,0.1345668629100084,"where |R| is the determinant of the correlation matrix R, each element in the matrix is computed
148"
LEARNING AND USING EXPERIENCE BY MDKL,0.13540790580319595,"through Eq.(3). y is the ﬁtness vector of Dmi. µ and σ2 are the mean and the variance of the prior
149"
LEARNING AND USING EXPERIENCE BY MDKL,0.13624894869638352,"distribution, respectively. Experience γe = {w, b, θe, pe} is updated by gradient descent (line 13),
150"
LEARNING AND USING EXPERIENCE BY MDKL,0.13708999158957108,"take θe as an example:
151"
LEARNING AND USING EXPERIENCE BY MDKL,0.13793103448275862,"θe ←θe −α B B
X"
LEARNING AND USING EXPERIENCE BY MDKL,0.13877207737594618,"i=1
▽θeL(Dmi, h(γ)).
(5)"
LEARNING AND USING EXPERIENCE BY MDKL,0.13961312026913372,"After U iterations, γe has been trained sufﬁciently by Nm small datasets Dm and will be used in
152"
LEARNING AND USING EXPERIENCE BY MDKL,0.1404541631623213,"target task T∗later.
153"
LEARNING AND USING EXPERIENCE BY MDKL,0.14129520605550883,"Adaptation procedure: Using experience
154"
LEARNING AND USING EXPERIENCE BY MDKL,0.1421362489486964,"The meta-learning of experience γe enables MDKL to handle a family of related tasks in general. To
155"
LEARNING AND USING EXPERIENCE BY MDKL,0.14297729184188393,"approximate a speciﬁc task T∗well, surrogate h(γe) needs to adapt task-speciﬁc increments ∆θ∗
156"
LEARNING AND USING EXPERIENCE BY MDKL,0.1438183347350715,"and ∆p∗in the way described in Alg. 3. A diagram of the deep kernel implemented in our MDKL
157"
LEARNING AND USING EXPERIENCE BY MDKL,0.14465937762825903,"model is illustrated in Fig. 2.
158"
LEARNING AND USING EXPERIENCE BY MDKL,0.1455004205214466,"Algorithm 3 Adaptation(γ∗, S∗, β)"
LEARNING AND USING EXPERIENCE BY MDKL,0.14634146341463414,"1: Input: Current surrogate parameters γ∗; A dataset S∗sam-
pled from target task T∗(Archive); Learning rate for adap-
tation β.
2: if γ∗== γe then
3:
Initialize task-speciﬁc increments ∆θ∗, ∆p∗.
4:
Compute task-speciﬁc parameters: θ∗= θe + ∆θ∗,
p∗= pe + ∆p∗.
5:
Obtain deep kernel k(xi, xj|γ∗) based GP: h(γ∗), where
γ∗= {w, b, θ∗, p∗} (Eq.(3)).
6: end if
7: Compute the loss function L(S∗, h(γ∗)) (Eq.(4)).
8: Update
∆θ∗, ∆p∗
using
gradient
descent:
β▽
L(S∗, h(γ∗)).
9: Output: Adapted MDKL h(γ∗)."
LEARNING AND USING EXPERIENCE BY MDKL,0.1471825063078217,"Figure 2: Diagram of our deep
kernel implementation. The solid
lines depict the training process,
the dotted lines depict the infer-
ence process. Q∗denotes query
samples to be evaluated on our
surrogates. 159"
LEARNING AND USING EXPERIENCE BY MDKL,0.14802354920100924,"Surrogate prediction. Due to the nature of a GP, when predicting the ﬁtness of a solution x∗, a
160"
LEARNING AND USING EXPERIENCE BY MDKL,0.1488645920941968,"MDKL surrogate produces a predictive Gaussian distribution N(ˆy(x∗), ˆs2(x∗)) , the predicted mean
161"
LEARNING AND USING EXPERIENCE BY MDKL,0.14970563498738435,"ˆy(x∗) and covariance ˆs2(x∗) are speciﬁed as [18]:
162"
LEARNING AND USING EXPERIENCE BY MDKL,0.1505466778805719,"ˆy(x∗) = µ + r′R−1(y −1µ),
(6) 163"
LEARNING AND USING EXPERIENCE BY MDKL,0.15138772077375945,"ˆs2(x∗) = σ2(1 −r′R−1r),
(7)"
LEARNING AND USING EXPERIENCE BY MDKL,0.15222876366694701,"where r is a correlation vector consisting of covariances between x∗and S∗, other variables are
164"
LEARNING AND USING EXPERIENCE BY MDKL,0.15306980656013458,"explained in Eq.(4).
165"
SURROGATE UPDATE STRATEGY,0.15391084945332212,"4.3
Surrogate Update Strategy
166"
SURROGATE UPDATE STRATEGY,0.15475189234650968,"In this subsection, we describe the update strategy in our FSEO framework. To properly integrate
167"
SURROGATE UPDATE STRATEGY,0.15559293523969722,"experience and data from T∗, our update strategy is designed to determine whether a MDKL surrogate
168"
SURROGATE UPDATE STRATEGY,0.1564339781328848,"should be adapted in the current iteration or not, ensuring an optimal update frequency of surrogates.
169"
SURROGATE UPDATE STRATEGY,0.15727502102607233,"As illustrated in Alg. 4, the surrogate update starts
when a new optimal solution(s) has been evaluated on
expensive functions and an updated archive S∗is avail-
able. For a given surrogate h(γ∗), its mean squared
error (MSE) on S∗is selected as the update criterion:
If the MSE after an adaptation e1 (line 4) is larger than
the MSE without an adaptation e0 (line 2), then the sur-
rogate will roll back to the status before the adaptation.
This indicates the surrogate update has been refused
and h(γ∗) will not be adapted in the current iteration.
Otherwise, the adapted surrogate will be chosen (line
6). Note that no matter whether surrogate adaptations
are accepted or refused, the resulting surrogates will
be treated as updated surrogates, which are employed
to assist the SAEA optimizer in the next iteration."
SURROGATE UPDATE STRATEGY,0.1581160639192599,"Algorithm 4 Update(γ∗, S∗, β)"
SURROGATE UPDATE STRATEGY,0.15895710681244743,"1: Input:
Current surrogate parameters γ∗;
Updated archive S∗;
Learning rate for further adaptations β.
2: e0 ←MSE(h(γ∗), S∗).
3: h(γ′) ←Adaptation(γ∗, S∗, β).
/∗Temporary surrogate, Alg. 3.∗/
4: e1 ←MSE(h(γ′), S∗).
5: if e0 > e1 then
6:
update γ∗= γ′, obtain new h(γ∗).
7: end if
8: Output: Surrogate h(γ∗). 170"
COMPUTATIONAL STUDIES,0.159798149705635,"5
Computational Studies
171"
COMPUTATIONAL STUDIES,0.16063919259882253,"Our computational studies can be divided into three parts: (1). Appendix D evaluates the effectiveness
172"
COMPUTATIONAL STUDIES,0.1614802354920101,"of learning experience through a synthetic problem and a real-world engine modeling problem. (2).
173"
COMPUTATIONAL STUDIES,0.16232127838519764,"Sections 5.1 to 5.2 use EMOPs as examples to investigate the performance of our FSEO framework
174"
COMPUTATIONAL STUDIES,0.1631623212783852,"in depth. Empirical evidence is provided to guide the use of our FSEO framework. (3). Section
175"
COMPUTATIONAL STUDIES,0.16400336417157274,"5.3 investigates the performance of our FSEO framework on a real-world ECOP. The source code
176"
COMPUTATIONAL STUDIES,0.1648444070647603,"is available online1 For all meta-learning methods used in our experiments, their basic setups are
177"
COMPUTATIONAL STUDIES,0.16568544995794784,"listed in Table 1. The neural network structure is suggested by [10, 27], and the learning rates are the
178"
COMPUTATIONAL STUDIES,0.1665264928511354,"default values that have been widely used in many meta-learning methods [13, 27].
179"
PERFORMANCE ON EMOPS,0.16736753574432295,"5.1
Performance on EMOPs
180"
PERFORMANCE ON EMOPS,0.16820857863751051,"In the following subsections, we aim to demonstrate the effectiveness of our FSEO framework. The
181"
PERFORMANCE ON EMOPS,0.16904962153069805,"experiment in this subsection is designed to answer the question below: With the experience learned
182"
PERFORMANCE ON EMOPS,0.16989066442388562,"from related tasks, can our FSEO framework helps a SAEA to save 9d solutions without a loss of
183"
PERFORMANCE ON EMOPS,0.17073170731707318,"optimization performance?
184"
PERFORMANCE ON EMOPS,0.17157275021026072,"The computational study is conducted on the DTLZ test problems [8]. All the DTLZ problems have
185"
PERFORMANCE ON EMOPS,0.1724137931034483,"d = 10 decision variables and 3 objectives, as the setups that have been widely used in [25, 33].
186"
PERFORMANCE ON EMOPS,0.17325483599663583,"The details of generating DTLZ variants (related tasks) are provided in Appendix C. We test our
187"
PERFORMANCE ON EMOPS,0.1740958788898234,"FSEO framework using an instantiation on MOEA/D-EGO, resulting MOEA/D-FS. Details of the
188"
PERFORMANCE ON EMOPS,0.17493692178301093,"comparison algorithms are given in Appendix E.1.
189"
PERFORMANCE ON EMOPS,0.1757779646761985,1A link will be disclosed here once the paper is accepted.
PERFORMANCE ON EMOPS,0.17661900756938603,"Table 1: Parameter setups for meta-learning
methods."
PERFORMANCE ON EMOPS,0.1774600504625736,"Module
Parameter
Value
Meta-learning
Number of meta-learning datasets Nm
20000
Number of update iterations U
2000
Batch size B
10
Neural network
Number of hidden layers
2
Number of units in each hidden layer
40
Learning rates α, β
0.001, 0.001
Activation function
ReLU"
PERFORMANCE ON EMOPS,0.17830109335576114,"Table 2: Parameter setups for DTLZ optimiza-
tion."
PERFORMANCE ON EMOPS,0.1791421362489487,"Parameter
MOEA/D-FS
Comparisons
Number of related tasks N
20000 (Nm in Table 1)
-
Size of datasets from related tasks |Di|
20 (2d)
-
Size of datasets for meta-learning |Dm|
|Di|
-
Evaluations for initialization
10 (1d)
100 (10d)
Evaluations for further optimization
50
50
Total evaluations
60
150"
EXPERIMENTAL SETUPS,0.17998317914213624,"5.1.1
Experimental setups
190"
EXPERIMENTAL SETUPS,0.1808242220353238,"The parameter setups for this multi-objective optimization experiment are listed in Table 2. During
191"
EXPERIMENTAL SETUPS,0.18166526492851134,"the optimization process, an initial dataset S∗is sampled using Latin-Hypercube Sampling (LHS)
192"
EXPERIMENTAL SETUPS,0.1825063078216989,"method [24], then extra evaluations are conducted until the evaluation budget has run out. Note that
193"
EXPERIMENTAL SETUPS,0.18334735071488645,"we aim to use related tasks to save 9d evaluations without a loss of SAEA optimization performance.
194"
EXPERIMENTAL SETUPS,0.184188393608074,"Hence, the total evaluation budgets for MOEA/D-FS and comparison algorithms are different.
195"
EXPERIMENTAL SETUPS,0.18502943650126155,"Since the test problems have 3 objectives, we employ inverted generational distance plus (IGD+) [15]
196"
EXPERIMENTAL SETUPS,0.18587047939444912,"as our performance indicator, where smaller IGD+ values indicate better optimization results. 5000
197"
EXPERIMENTAL SETUPS,0.18671152228763668,"reference points are generated for computing IGD+ values, as suggested in [25]. More results in IGD
198"
EXPERIMENTAL SETUPS,0.18755256518082422,"[4] and HV [55] metrics are reported in Appendix E.3.
199"
RESULTS AND ANALYSIS,0.1883936080740118,"5.1.2
Results and analysis
200"
RESULTS AND ANALYSIS,0.18923465096719932,"The statistical test results are reported in Fig. 3 and Appendix E.2 (Table 5). It can be seen from Fig. 3
201"
RESULTS AND ANALYSIS,0.1900756938603869,"that, although 90 fewer evaluations are used in surrogate initialization, MOEA/D-FS can still achieve
202"
RESULTS AND ANALYSIS,0.19091673675357443,"competitive or even smaller IGD+ values than MOEA/D-EGO on all DTLZ problems except for
203"
RESULTS AND ANALYSIS,0.191757779646762,"DTLZ7. In addition, the IGD+ values obtained by MOEA/D-FS drop rapidly, especially during the
204"
RESULTS AND ANALYSIS,0.19259882253994953,"ﬁrst few evaluations, implying the experience learned from DTLZ variants are effective. Therefore,
205"
RESULTS AND ANALYSIS,0.1934398654331371,"in most situations, our FSEO framework is able to assist MOEA/D-EGO in reaching competitive
206"
RESULTS AND ANALYSIS,0.19428090832632464,"or even better optimization results, with the number of evaluations used for surrogate initialization
207"
RESULTS AND ANALYSIS,0.1951219512195122,reduced from 10d to only 1d.
RESULTS AND ANALYSIS,0.19596299411269974,"Figure 3: IGD+ curves averaged over 30 runs on the DTLZ problems. Solid lines are mean values,
while shadows are error regions. Upper: DTLZ1, DTLZ2, DTLZ3, DTLZ4. Lower: DTLZ5,
DTLZ6, DTLZ7. MOEA/D-FSs and comparison algorithms initialize their surrogates with 10, 100
samples, respectively. X-axis denotes the extra 50 evaluations allowed in the further optimization.
Note that ‘FS(out)’ indicates the target task is excluded from the range of related tasks during the
meta-learning procedure) (see Appendix F). 208"
RESULTS AND ANALYSIS,0.1968040370058873,"MOEA/D-FS is less effective on DTLZ7 than on other DTLZ problems, which might be attributed to
209"
RESULTS AND ANALYSIS,0.19764507989907484,"the discontinuity of the Pareto front on DTLZ7. Note that MOEA/D-FS learns experience from small
210"
RESULTS AND ANALYSIS,0.1984861227922624,"datasets such as Dm and S∗. The solutions in these small datasets are sampled at random, hence, the
211"
RESULTS AND ANALYSIS,0.19932716568544995,"probability of having optimal solutions being sampled is small. However, it is difﬁcult to learn the
212"
RESULTS AND ANALYSIS,0.2001682085786375,"discontinuity of the Pareto front from the sampled non-optimal solutions. As a result, the knowledge
213"
RESULTS AND ANALYSIS,0.20100925147182505,"of ‘there are four discrete optimal regions’ cannot be learned from such small datasets (|Dm| = 20)
214"
RESULTS AND ANALYSIS,0.20185029436501262,"collected from related tasks. The performance analysis between MOEA/D-FS and other comparison
215"
RESULTS AND ANALYSIS,0.20269133725820015,"algorithms are available in Appendix E.2.
216"
MORE COMPARISON EXPERIMENTS,0.20353238015138772,"5.1.3
More comparison experiments
217"
MORE COMPARISON EXPERIMENTS,0.2043734230445753,"We also compared the performance of our FSEO framework when only 10 evaluations are used for
218"
MORE COMPARISON EXPERIMENTS,0.20521446593776282,"surrogate initialization for comparison algorithms. The results are reported in Table 8 in Appendix
219"
MORE COMPARISON EXPERIMENTS,0.2060555088309504,"E.4. In addition, the performance of our FSEO framework in the context of extremely expensive
220"
MORE COMPARISON EXPERIMENTS,0.20689655172413793,"optimization has been investigated in Appendix H (Table 11 and Fig. 7).
221"
MORE COMPARISON EXPERIMENTS,0.2077375946173255,"The question raised at the beginning of this subsection can be answered by the results discussed so
222"
MORE COMPARISON EXPERIMENTS,0.20857863751051303,"far. Due to the integration of the experience learned from related tasks (DTLZ variants), although the
223"
MORE COMPARISON EXPERIMENTS,0.2094196804037006,"evaluation cost of surrogates initialization has been reduced from 10d to 1d, our FSEO framework is
224"
MORE COMPARISON EXPERIMENTS,0.21026072329688814,"still capable of assisting regression-based SAEAs to achieve competitive or even better optimization
225"
MORE COMPARISON EXPERIMENTS,0.2111017661900757,"results in most situations.
226"
ABLATION STUDIES,0.21194280908326324,"5.2
Ablation Studies
227"
ABLATION STUDIES,0.2127838519764508,"We conduct two ablation studies to investigate the inﬂuence of task similarity and that of the dataset
228"
ABLATION STUDIES,0.21362489486963834,"size used in meta-learning, results and analysis are reported in Appendixes F and G, respectively.
229"
PERFORMANCE ON REAL-WORLD ECOPS,0.2144659377628259,"5.3
Performance on Real-World ECOPs
230"
PERFORMANCE ON REAL-WORLD ECOPS,0.21530698065601345,"The experiments on EMOPs have investigated the performance of our FSEO framework in depth. In
231"
PERFORMANCE ON REAL-WORLD ECOPS,0.216148023549201,"this subsection, we evaluate our FSEO framework on a real-world gasoline motor engine calibration
232"
PERFORMANCE ON REAL-WORLD ECOPS,0.21698906644238855,"problem, which is an ECOP.
233"
PERFORMANCE ON REAL-WORLD ECOPS,0.21783010933557612,"The calibration problem has 6 adjustable engine parameters, namely the throttle angle, waste gate
234"
PERFORMANCE ON REAL-WORLD ECOPS,0.21867115222876365,"oriﬁce, ignition timing, valve timings, state of injection, and air-fuel-ratio. The calibration aims at
235"
PERFORMANCE ON REAL-WORLD ECOPS,0.21951219512195122,"minimizing the BSFC while satisfying 4 constraints in terms of temperature, pressure, CA50, and
236"
PERFORMANCE ON REAL-WORLD ECOPS,0.22035323801513879,"load simultaneously [53].
237"
COMPARISON ALGORITHMS,0.22119428090832632,"5.3.1
Comparison algorithms
238"
COMPARISON ALGORITHMS,0.2220353238015139,"Since the comparison algorithms in the DTLZ optimization experiments are not designed for handling
239"
COMPARISON ALGORITHMS,0.22287636669470143,"constrained optimization, our comparison is conducted with 3 state-of-the-art constrained optimization
240"
COMPARISON ALGORITHMS,0.223717409587889,"algorithms used in industry: A variant of EGO designed to handle constrained optimization problems
241"
COMPARISON ALGORITHMS,0.22455845248107653,"(cons_EGO) [53], a GA customized for this calibration problem (adaptiveGA) [53], and a bilevel
242"
COMPARISON ALGORITHMS,0.2253994953742641,"constrained SAEA (SAB-DE) [50]. The settings of the comparison algorithms are the same as
243"
COMPARISON ALGORITHMS,0.22624053826745164,"suggested in the literature. In this experiment, we apply our FSEO framework to cons_EGO and
244"
COMPARISON ALGORITHMS,0.2270815811606392,"investigate its optimization performance. The GP surrogates in cons_EGO are replaced by our MDKL
245"
COMPARISON ALGORITHMS,0.22792262405382674,"surrogates to conduct the comparison, and the resulting algorithm is denoted as cons_FS.
246"
EXPERIMENTAL SETUPS,0.2287636669470143,"5.3.2
Experimental setups
247"
EXPERIMENTAL SETUPS,0.22960470984020184,"The setup of related tasks (N, Di) is the same as described in Appendix D. In the meta-learning
248"
EXPERIMENTAL SETUPS,0.2304457527333894,"procedure, both the support set and the query set contain 6 data points, thus |Dm| = 12. The total
249"
EXPERIMENTAL SETUPS,0.23128679562657695,"evaluation budget for all algorithms is set to 60. For adaptiveGA, all evaluations are used in the
250"
EXPERIMENTAL SETUPS,0.2321278385197645,"optimization process as it is not a SAEA. For cons_EGO and SAB-DE, 40 samples are used to
251"
EXPERIMENTAL SETUPS,0.23296888141295205,"initialize the surrogates and 20 extra evaluations are used in the optimization process. For cons_FS,
252"
EXPERIMENTAL SETUPS,0.23380992430613962,"only 6 samples are used to initialize MDKL surrogates, and the remaining evaluations are used for
253"
EXPERIMENTAL SETUPS,0.23465096719932715,"further optimization.
254"
OPTIMIZATION RESULTS AND ANALYSIS,0.23549201009251472,"5.3.3
Optimization results and analysis
255"
OPTIMIZATION RESULTS AND ANALYSIS,0.23633305298570226,"The left side and right side of Fig. 4 plot the normalized BSFC results and the number of feasible
256"
OPTIMIZATION RESULTS AND ANALYSIS,0.23717409587888982,"solutions found over the number of used evaluations, respectively. Solid lines are mean lines, while
257"
OPTIMIZATION RESULTS AND ANALYSIS,0.2380151387720774,"shadows are error regions. From the left side of Fig. 4, it can be observed that the minimal BSFC
258"
OPTIMIZATION RESULTS AND ANALYSIS,0.23885618166526493,"Figure 4: Results of 30 runs on the real-world engine calibration problem, all BSFC values are
normalized. Solid lines are mean values, while shadows are error regions. Left ﬁgure shows how
BSFC varies with the number of evaluations. The star markers highlight the results achieved when 20
evaluations are used in the optimization process. Right ﬁgure illustrates how the number of feasible
solutions varies with the number of evaluations."
OPTIMIZATION RESULTS AND ANALYSIS,0.2396972245584525,"obtained by cons_FS decreases drastically in the ﬁrst few evaluations, implying that the experience
259"
OPTIMIZATION RESULTS AND ANALYSIS,0.24053826745164003,"learned from related tasks is effective. In comparison, the minimal BSFC obtained by adaptiveGA
260"
OPTIMIZATION RESULTS AND ANALYSIS,0.2413793103448276,"and cons_EGO drops in a relatively slow rate, even though cons_EGO has used 34 more samples
261"
OPTIMIZATION RESULTS AND ANALYSIS,0.24222035323801513,"to initialize its surrogates. The star marker denotes the point at which cons_FS has evaluated 20
262"
OPTIMIZATION RESULTS AND ANALYSIS,0.2430613961312027,"samples after surrogate initialization. It is worth noting that when 20 samples have been evaluated
263"
OPTIMIZATION RESULTS AND ANALYSIS,0.24390243902439024,"in the optimization, cons_FS achieves a smaller BSFC value than cons_EGO. After the star marker,
264"
OPTIMIZATION RESULTS AND ANALYSIS,0.2447434819175778,"the decrease of BSFC becomes slow as cons_FS has reached the optimal region. Therefore, further
265"
OPTIMIZATION RESULTS AND ANALYSIS,0.24558452481076534,"improvement in the normalized BSFC value is not signiﬁcant and thus hard to be observed. The
266"
OPTIMIZATION RESULTS AND ANALYSIS,0.2464255677039529,"advantages of our FSEO framework can also be observed in constraint handling. In the right side of
267"
OPTIMIZATION RESULTS AND ANALYSIS,0.24726661059714045,"Fig. 4, cons_FS ﬁnds more feasible solutions than the 3 comparison algorithms. These results indicate
268"
OPTIMIZATION RESULTS AND ANALYSIS,0.248107653490328,"that our FSEO framework improves the performance of cons_EGO on both objective function and
269"
OPTIMIZATION RESULTS AND ANALYSIS,0.24894869638351555,"constraint functions. Meanwhile, only 1d evaluations are used to initialize surrogates.
270"
DISCUSSION ON RUNTIME,0.24978973927670312,"5.3.4
Discussion on runtime
271"
DISCUSSION ON RUNTIME,0.25063078216989065,"It should be noted that real engine performance evaluations on engine facilities are very costly in
272"
DISCUSSION ON RUNTIME,0.2514718250630782,"terms of both time and ﬁnancial budget [49]. Since a single real engine performance evaluation can
273"
DISCUSSION ON RUNTIME,0.2523128679562658,"cost several hours [22, 49], the time cost of the meta-learning procedure is negligible as it takes only
274"
DISCUSSION ON RUNTIME,0.2531539108494533,"a few minutes. Savings from reduced real engine performance evaluations on engine facilities and the
275"
DISCUSSION ON RUNTIME,0.25399495374264086,"reduced development cycle due to our FSEO framework could amount to millions of dollars [49]. our
276"
DISCUSSION ON RUNTIME,0.25483599663582845,"FSEO framework is an effective and efﬁcient method to solve this real-world calibration problem.
277"
CONCLUSION AND FURTHER WORK,0.255677039529016,"6
Conclusion and further work
278"
CONCLUSION AND FURTHER WORK,0.25651808242220353,"Conclusion. In this paper, we present a FSEO framework to address EMOPs and ECOPs from the
279"
CONCLUSION AND FURTHER WORK,0.25735912531539107,"perspective of SAEAs. A novel meta-learning approach MDKL is proposed to learn prior experience
280"
CONCLUSION AND FURTHER WORK,0.25820016820857866,"from related expensive tasks. Our MDKL model is designed for optimization and has explicit
281"
CONCLUSION AND FURTHER WORK,0.2590412111017662,"task-speciﬁc parameters, which allows continually update of task-speciﬁc parameters during the
282"
CONCLUSION AND FURTHER WORK,0.25988225399495374,"optimization process. Our empirical experiments show that the FSEO framework is able to improve
283"
CONCLUSION AND FURTHER WORK,0.2607232968881413,"the sampling efﬁciency and thus save expensive evaluations for existing regression-based SAEAs.
284"
CONCLUSION AND FURTHER WORK,0.26156433978132887,"Ablation studies reveal the inﬂuence between optimization performance and solutions similarity as
285"
CONCLUSION AND FURTHER WORK,0.2624053826745164,"well as the size of datasets for meta-learning.
286"
CONCLUSION AND FURTHER WORK,0.26324642556770395,"Limitation and further work. The limitations of this work can be summarized as the following
287"
CONCLUSION AND FURTHER WORK,0.2640874684608915,"two points: First, we do not have a mathematical deﬁnition of related tasks. Second, the proposed
288"
CONCLUSION AND FURTHER WORK,0.2649285113540791,"framework is currently for regression-based SAEAs only.
289"
REFERENCES,0.2657695542472666,"References
290"
REFERENCES,0.26661059714045415,"[1] Tianyi Bai, Yang Li, Yu Shen, Xinyi Zhang, Wentao Zhang, and Bin Cui. Transfer learning for
291"
REFERENCES,0.2674516400336417,"bayesian optimization: A survey. arXiv preprint arXiv:2302.05927, 2023.
292"
REFERENCES,0.2682926829268293,"[2] Kavitesh Kumar Bali, Yew-Soon Ong, Abhishek Gupta, and Puay Siew Tan. Multifactorial
293"
REFERENCES,0.2691337258200168,"evolutionary algorithm with online transfer parameter estimation: MFEA-II. IEEE Transactions
294"
REFERENCES,0.26997476871320436,"on Evolutionary Computation, 24(1):69–83, 2019.
295"
REFERENCES,0.2708158116063919,"[3] Hongli Bian, Jie Tian, Jialiang Yu, and Han Yu. Bayesian co-evolutionary optimization based
296"
REFERENCES,0.2716568544995795,"entropy search for high-dimensional many-objective optimization. Knowledge-Based Systems,
297"
REFERENCES,0.27249789739276703,"274:110630, 2023.
298"
REFERENCES,0.27333894028595457,"[4] Peter AN Bosman and Dirk Thierens. The balance between proximity and diversity in multiob-
299"
REFERENCES,0.27417998317914216,"jective evolutionary algorithms. IEEE Transactions on Evolutionary Computation, 7(2):174–188,
300"
REFERENCES,0.2750210260723297,"2003.
301"
REFERENCES,0.27586206896551724,"[5] Wei-Yu Chen, Yen-Cheng Liu, Zsolt Kira, Yu-Chiang Frank Wang, and Jia-Bin Huang. A closer
302"
REFERENCES,0.2767031118587048,"look at few-shot classiﬁcation. In Proceedings of the 7th International Conference on Learning
303"
REFERENCES,0.27754415475189237,"Representations (ICLR’19), 2019.
304"
REFERENCES,0.2783851976450799,"[6] Wenlin Chen, Austin Tripp, and José Miguel Hernández-Lobato. Meta-learning adaptive deep ker-
305"
REFERENCES,0.27922624053826745,"nel gaussian processes for molecular property prediction. In Proceedings of the 11th International
306"
REFERENCES,0.280067283431455,"Conference on Learning Representations (ICLR’23), 2023.
307"
REFERENCES,0.2809083263246426,"[7] Tinkle Chugh, Yaochu Jin, Kaisa Miettinen, Jussi Hakanen, and Karthik Sindhya. A surrogate-
308"
REFERENCES,0.2817493692178301,"assisted reference vector guided evolutionary algorithm for computationally expensive many-
309"
REFERENCES,0.28259041211101765,"objective optimization. IEEE Transactions on Evolutionary Computation, 22(1):129–142, 2016.
310"
REFERENCES,0.2834314550042052,"[8] Kalyanmoy Deb, Lothar Thiele, Marco Laumanns, and Eckart Zitzler. Scalable test problems
311"
REFERENCES,0.2842724978973928,"for evolutionary multiobjective optimization. In Evolutionary Multiobjective Optimization, pages
312"
REFERENCES,0.2851135407905803,"105–145. Springer, London, U.K., 2005.
313"
REFERENCES,0.28595458368376786,"[9] Jinliang Ding, Cuie Yang, Yaochu Jin, and Tianyou Chai. Generalized multitasking for evolu-
314"
REFERENCES,0.2867956265769554,"tionary optimization of expensive problems. IEEE Transactions on Evolutionary Computation,
315"
REFERENCES,0.287636669470143,"23(1):44–58, 2017.
316"
REFERENCES,0.28847771236333053,"[10] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adapta-
317"
REFERENCES,0.28931875525651807,"tion of deep networks. In Proceedings of the 34th International Conference on Machine Learning
318"
REFERENCES,0.29015979814970566,"(ICML’17), pages 1126–1135, 2017.
319"
REFERENCES,0.2910008410428932,"[11] Zhendong Guo, Haitao Liu, Yew-Soon Ong, Xinghua Qu, Yuzhe Zhang, and Jianmin Zheng.
320"
REFERENCES,0.29184188393608074,"Generative multiform Bayesian optimization. IEEE Transactions on Cybernetics, 53(7):4347–
321"
REFERENCES,0.2926829268292683,"4360, 2022.
322"
REFERENCES,0.29352396972245587,"[12] Abhishek Gupta, Yew-Soon Ong, and Liang Feng. Insights on transfer optimization: Be-
323"
REFERENCES,0.2943650126156434,"cause experience is the best teacher. IEEE Transactions on Emerging Topics in Computational
324"
REFERENCES,0.29520605550883094,"Intelligence, 2(1):51–64, 2017.
325"
REFERENCES,0.2960470984020185,"[13] James Harrison, Apoorva Sharma, and Marco Pavone. Meta-learning priors for efﬁcient online
326"
REFERENCES,0.2968881412952061,"Bayesian regression. In Proceedings of the 13th Workshop on the Algorithmic Foundations of
327"
REFERENCES,0.2977291841883936,"Robotics (WAFR’18), pages 318–337, 2018.
328"
REFERENCES,0.29857022708158115,"[14] Timothy M. Hospedales, Antreas Antoniou, Paul Micaelli, and Amos J Storkey. Meta-learning
329"
REFERENCES,0.2994112699747687,"in neural networks: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence,
330"
REFERENCES,0.3002523128679563,"2021.
331"
REFERENCES,0.3010933557611438,"[15] Hisao Ishibuchi, Hiroyuki Masuda, Yuki Tanigaki, and Yusuke Nojima. Modiﬁed distance
332"
REFERENCES,0.30193439865433136,"calculation in generational distance and inverted generational distance. In Proceedings of the
333"
REFERENCES,0.3027754415475189,"8th International Conference on Evolutionary Multi-criterion Optimization (EMO’15), pages
334"
REFERENCES,0.3036164844407065,"110–125, 2015.
335"
REFERENCES,0.30445752733389403,"[16] Min Jiang, Zhenzhong Wang, Shihui Guo, Xing Gao, and Kay Chen Tan. Individual-based
336"
REFERENCES,0.30529857022708157,"transfer learning for dynamic multiobjective optimization. IEEE Transactions on Cybernetics,
337"
REFERENCES,0.30613961312026916,"51(10):4968–4981, 2020.
338"
REFERENCES,0.3069806560134567,"[17] Min Jiang, Zhenzhong Wang, Liming Qiu, Shihui Guo, Xing Gao, and Kay Chen Tan. A fast
339"
REFERENCES,0.30782169890664424,"dynamic evolutionary multiobjective algorithm via manifold transfer learning. IEEE Transactions
340"
REFERENCES,0.3086627417998318,"on Cybernetics, 51(7):3417–3428, 2020.
341"
REFERENCES,0.30950378469301937,"[18] Donald R. Jones, Matthias Schonlau, and William J. Welch. Efﬁcient global optimization of
342"
REFERENCES,0.3103448275862069,"expensive black-box functions. Journal of Global Optimization, 13(4):455–492, 1998.
343"
REFERENCES,0.31118587047939444,"[19] Joshua Knowles. ParEGO: A hybrid algorithm with on-line landscape approximation for
344"
REFERENCES,0.312026913372582,"expensive multiobjective optimization problems. IEEE Transactions on Evolutionary Computation,
345"
REFERENCES,0.3128679562657696,"10(1):50–66, 2006.
346"
REFERENCES,0.3137089991589571,"[20] Rung-Tzuo Liaw and Chuan-Kang Ting. Evolutionary manytasking optimization based on
347"
REFERENCES,0.31455004205214465,"symbiosis in biocoenosis. In Proceedings of the 33rd AAAI Conference on Artiﬁcial Intelligence
348"
REFERENCES,0.3153910849453322,"(AAAI’19), pages 4295–4303, 2019.
349"
REFERENCES,0.3162321278385198,"[21] Shengcai Liu, Ke Tang, and Xin Yao. Experience-based optimization: A coevolutionary
350"
REFERENCES,0.3170731707317073,"approach. arXiv preprint arXiv:1703.09865, 2017.
351"
REFERENCES,0.31791421362489486,"[22] He Ma. Control Oriented Engine Modeling and Engine Multi-objective Optimal Feedback
352"
REFERENCES,0.3187552565180824,"Control. PhD thesis, University of Birmingham, 2013.
353"
REFERENCES,0.31959629941127,"[23] Alexandre Maraval, Matthieu Zimmer, Antoine Grosnit, and Haitham Bou Ammar. End-to-end
354"
REFERENCES,0.32043734230445753,"meta-bayesian optimisation with transformer neural processes. arXiv preprint arXiv:2305.15930,
355"
REFERENCES,0.32127838519764507,"2023.
356"
REFERENCES,0.32211942809083266,"[24] Michael D. McKay, Richard J. Beckman, and William J. Conover. A comparison of three
357"
REFERENCES,0.3229604709840202,"methods for selecting values of input variables in the analysis of output from a computer code.
358"
REFERENCES,0.32380151387720774,"Technometrics, 42(1):55–61, 2000.
359"
REFERENCES,0.3246425567703953,"[25] Linqiang Pan, Cheng He, Ye Tian, Handing Wang, Xingyi Zhang, and Yaochu Jin.
A
360"
REFERENCES,0.32548359966358287,"classiﬁcation-based surrogate-assisted evolutionary algorithm for expensive many-objective opti-
361"
REFERENCES,0.3263246425567704,"mization. IEEE Transactions on Evolutionary Computation, 23(1):74–88, 2018.
362"
REFERENCES,0.32716568544995794,"[26] Jiarong Pan, Stefan Falkner, Felix Berkenkamp, and Joaquin Vanschoren. MALIBO: Meta-
363"
REFERENCES,0.3280067283431455,"learning for likelihood-free bayesian optimization. arXiv preprint arXiv:2307.03565, 2023.
364"
REFERENCES,0.3288477712363331,"[27] Massimiliano Patacchiola, Jack Turner, Elliot J Crowley, Michael O’Boyle, and Amos Storkey.
365"
REFERENCES,0.3296888141295206,"Bayesian meta-learning for the few-shot setting via deep kernels. In Advance in Neural Information
366"
REFERENCES,0.33052985702270815,"Processing Systems 33 (NeurIPS’20), 2020.
367"
REFERENCES,0.3313708999158957,"[28] Shufen Qin, Chaoli Sun, Farooq Akhtar, and Gang Xie. Expensive many-objective evolutionary
368"
REFERENCES,0.3322119428090833,"optimization guided by two individual inﬁll criteria. Memetic Computing, pages 1–15, 2023.
369"
REFERENCES,0.3330529857022708,"[29] Gan Ruan, Leandro L. Minku, Stefan Menzel, Bernhard Sendhoff, and Xin Yao. When and how
370"
REFERENCES,0.33389402859545836,"to transfer knowledge in dynamic multi-objective optimization. In Proceedings of the 2019 IEEE
371"
REFERENCES,0.3347350714886459,"Symposium Series on Computational Intelligence (SSCI’19), pages 2034–2041, 2019.
372"
REFERENCES,0.3355761143818335,"[30] Gan Ruan, Leandro L. Minku, Stefan Menzel, Bernhard Sendhoff, and Xin Yao. Computa-
373"
REFERENCES,0.33641715727502103,"tional study on effectiveness of knowledge transfer in dynamic multi-objective optimization. In
374"
REFERENCES,0.33725820016820857,"Proceedings of the 22nd IEEE Congress on Evolutionary Computation (CEC’20), pages 1–8,
375"
REFERENCES,0.3380992430613961,"2020.
376"
REFERENCES,0.3389402859545837,"[31] Jerome Sacks, William J. Welch, Toby J. Mitchell, and Henry P. Wynn. Design and analysis of
377"
REFERENCES,0.33978132884777124,"computer experiments. Statistical Science, 4(4):409–423, 1989.
378"
REFERENCES,0.3406223717409588,"[32] Gresa Shala, Thomas Elsken, Frank Hutter, and Josif Grabocka. Transfer NAS with meta-
379"
REFERENCES,0.34146341463414637,"learned bayesian surrogates. In Proceedings of the 11th International Conference on Learning
380"
REFERENCES,0.3423044575273339,"Representations (ICLR’23), 2023.
381"
REFERENCES,0.34314550042052144,"[33] Zhenshou Song, Handing Wang, Cheng He, and Yaochu Jin. A Kriging-assisted two-archive
382"
REFERENCES,0.343986543313709,"evolutionary algorithm for expensive many-objective optimization. IEEE Transactions on Evolu-
383"
REFERENCES,0.3448275862068966,"tionary Computation, 25(6):1013–1027, 2021.
384"
REFERENCES,0.3456686291000841,"[34] Michael L. Stein. Interpolation of Spatial Data: Some Theory for Kriging. Springer Science &
385"
REFERENCES,0.34650967199327165,"Business Media, New York, NY, 1999.
386"
REFERENCES,0.3473507148864592,"[35] Kay Chen Tan, Liang Feng, and Min Jiang. Evolutionary transfer optimization-a new frontier
387"
REFERENCES,0.3481917577796468,"in evolutionary computation research. IEEE Computational Intelligence Magazine, 16(1):22–33,
388"
REFERENCES,0.3490328006728343,"2021.
389"
REFERENCES,0.34987384356602186,"[36] Ke Tang, Shengcai Liu, Peng Yang, and Xin Yao. Few-shots parallel algorithm portfolio
390"
REFERENCES,0.3507148864592094,"construction via co-evolution. IEEE Transactions on Evolutionary Computation, 25(3):595–607,
391"
REFERENCES,0.351555929352397,"2021.
392"
REFERENCES,0.3523969722455845,"[37] Ye Tian, Ran Cheng, Xingyi Zhang, and Yaochu Jin. PlatEMO: A MATLAB platform for
393"
REFERENCES,0.35323801513877207,"evolutionary multi-objective optimization [educational forum]. IEEE Computational Intelligence
394"
REFERENCES,0.3540790580319596,"Magazine, 12(4):73–87, 2017.
395"
REFERENCES,0.3549201009251472,"[38] Petru Tighineanu, Lukas Grossberger, Paul Baireuther, Kathrin Skubch, Stefan Falkner, Julia
396"
REFERENCES,0.35576114381833474,"Vinogradska, and Felix Berkenkamp. Scalable meta-learning with gaussian processes. arXiv
397"
REFERENCES,0.3566021867115223,"preprint arXiv:2312.00742, 2023.
398"
REFERENCES,0.35744322960470987,"[39] Prudencio Tossou, Basile Dura, Francois Laviolette, Mario Marchand, and Alexandre Lacoste.
399"
REFERENCES,0.3582842724978974,"Adaptive deep kernel learning. arXiv preprint arXiv:1905.12131, 2019.
400"
REFERENCES,0.35912531539108494,"[40] Michael Volpp, Lukas P. Fröhlich, Kirsten Fischer, Andreas Doerr, Stefan Falkner, Frank
401"
REFERENCES,0.3599663582842725,"Hutter, and Christian Daniel. Meta-learning acquisition functions for transfer learning in Bayesian
402"
REFERENCES,0.3608074011774601,"optimization. In Proceedings of the 8th International Conference on Learning Representations
403"
REFERENCES,0.3616484440706476,"(ICLR’20), 2020.
404"
REFERENCES,0.36248948696383515,"[41] Yaqing Wang, Quanming Yao, James T. Kwok, and Lionel M. Ni. Generalizing from a few
405"
REFERENCES,0.3633305298570227,"examples: A survey on few-shot learning. ACM Computing Surveys, 53(3):1–34, 2020.
406"
REFERENCES,0.3641715727502103,"[42] Zi Wang, George E. Dahl, Kevin Swersky, Chansoo Lee, Zachary Nado, Justin Gilmer, Jasper
407"
REFERENCES,0.3650126156433978,"Snoek, and Zoubin Ghahramani. Pre-trained gaussian processes for bayesian optimization. arXiv
408"
REFERENCES,0.36585365853658536,"preprint arXiv:2109.08215, 2021.
409"
REFERENCES,0.3666947014297729,"[43] Tingyang Wei, Shibin Wang, Jinghui Zhong, Dong Liu, and Jun Zhang. A review on evolutionary
410"
REFERENCES,0.3675357443229605,"multi-task optimization: Trends and challenges. IEEE Transactions on Evolutionary Computation,
411"
REFERENCES,0.368376787216148,"26(5):941–960, 2021.
412"
REFERENCES,0.36921783010933557,"[44] Christopher KI Williams and Carl Edward Rasmussen. Gaussian Processes for Machine
413"
REFERENCES,0.3700588730025231,"Learning. MIT press, Cambridge, MA, 2006.
414"
REFERENCES,0.3708999158957107,"[45] Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, and Eric P. Xing. Deep kernel
415"
REFERENCES,0.37174095878889823,"learning. In Proceedings of the 19th International Conference on Artiﬁcial Intelligence and
416"
REFERENCES,0.3725820016820858,"Statistics (AISTATS’16), pages 370–378, 2016.
417"
REFERENCES,0.37342304457527337,"[46] Martin Wistuba and Josif Grabocka. Few-shot Bayesian optimization with deep kernel surro-
418"
REFERENCES,0.3742640874684609,"gates. In Proceedings of the 9th International Conference on Learning Representations (ICLR’21),
419"
REFERENCES,0.37510513036164844,"2021.
420"
REFERENCES,0.375946173254836,"[47] Xiaoming Xue, Kai Zhang, Kay Chen Tan, Liang Feng, Jian Wang, Guodong Chen, Xinggang
421"
REFERENCES,0.3767872161480236,"Zhao, Liming Zhang, and Jun Yao. Afﬁne transformation-enhanced multifactorial optimization
422"
REFERENCES,0.3776282590412111,"for heterogeneous problems. IEEE Transactions on Cybernetics, pages 1–15, 2020.
423"
REFERENCES,0.37846930193439865,"[48] Xunzhao Yu, Xin Yao, Yan Wang, Ling Zhu, and Dimitar Filev. Domination-based ordinal
424"
REFERENCES,0.3793103448275862,"regression for expensive multi-objective optimization. In Proceedings of the 2019 IEEE Symposium
425"
REFERENCES,0.3801513877207738,"Series on Computational Intelligence (SSCI’19), pages 2058–2065, 2019.
426"
REFERENCES,0.3809924306139613,"[49] Xunzhao Yu, Ling Zhu, Yan Wang, Dimitar Filev, and Xin Yao. Internal combustion engine
427"
REFERENCES,0.38183347350714886,"calibration using optimization algorithms. Applied Energy, 305:117894, 2022.
428"
REFERENCES,0.3826745164003364,"[50] Xunzhao Yu, Yan Wang, Ling Zhu, Dimitar Filev, and Xin Yao. Engine calibration with
429"
REFERENCES,0.383515559293524,"surrogate-assisted bilevel evolutionary algorithm. IEEE Transactions on Cybernetics (Early
430"
REFERENCES,0.3843566021867115,"Access), 2023.
431"
REFERENCES,0.38519764507989906,"[51] Qingfu Zhang, Wudong Liu, Edward Tsang, and Botond Virginas. Expensive multiobjective
432"
REFERENCES,0.3860386879730866,"optimization by MOEA/D with gaussian process model. IEEE Transactions on Evolutionary
433"
REFERENCES,0.3868797308662742,"Computation, 14(3):456–474, 2010.
434"
REFERENCES,0.38772077375946173,"[52] Liangjie Zhang, Yuling Xie, Jianjun Chen, Liang Feng, Chao Chen, and Kai Liu. A study on
435"
REFERENCES,0.3885618166526493,"multiform multi-objective evolutionary optimization. Memetic Computing, 13(3):307–318, 2021.
436"
REFERENCES,0.3894028595458368,"[53] Ling Zhu, Yan Wang, Anuj Pal, and Guoming Zhu. Engine calibration using global optimization
437"
REFERENCES,0.3902439024390244,"methods with customization. Technical Report 2020-01-0270, SAE Technical Paper, 2020.
438"
REFERENCES,0.39108494533221194,"[54] Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Hui
439"
REFERENCES,0.3919259882253995,"Xiong, and Qing He. A comprehensive survey on transfer learning. Proceedings of the IEEE,
440"
REFERENCES,0.3927670311185871,"109(1):43–76, 2020.
441"
REFERENCES,0.3936080740117746,"[55] Eckart Zitzler and Lothar Thiele. Multiobjective optimization using evolutionary algorithms - a
442"
REFERENCES,0.39444911690496215,"comparative case study. In Proceedings of the 5th International Conference on Parallel Problem
443"
REFERENCES,0.3952901597981497,"Solving from Nature (PPSN V), pages 292–301, 1998.
444"
REFERENCES,0.3961312026913373,"A
Discussion on Experience-based Optimization
445"
REFERENCES,0.3969722455845248,"In the past decade, experience-based optimization has attracted much attention as it uses the experience
446"
REFERENCES,0.39781328847771236,"gained from other optimization problems to improve the optimization efﬁciency of target problems,
447"
REFERENCES,0.3986543313708999,"which mimics human capabilities of cognitive and knowledge generalization [12]. The optimization
448"
REFERENCES,0.3994953742640875,"problems that provide experience or knowledge are regarded as source tasks, while the target
449"
REFERENCES,0.400336417157275,"optimization problems are regarded as target tasks. To obtain useful experience, the tasks that are
450"
REFERENCES,0.40117746005046256,"related to target tasks are chosen as source tasks since they usually share domain-speciﬁc features
451"
REFERENCES,0.4020185029436501,"with target tasks. Diverse experience-based optimization methods have been proposed to use the
452"
REFERENCES,0.4028595458368377,"experience gained from related tasks to tackle target tasks. They can be divided into two categories
453"
REFERENCES,0.40370058873002523,"based on the direction of experience transformation.
454"
REFERENCES,0.40454163162321277,"In the ﬁrst category, experience is transformed mutually. Every considered optimization problem is a
455"
REFERENCES,0.4053826745164003,"target task and also is one of the source tasks of other optimization problems. In other words, the
456"
REFERENCES,0.4062237174095879,"roles of source task and target task are compatible. One representative tributary is EMTO that aims to
457"
REFERENCES,0.40706476030277544,"solve multiple optimization tasks concurrently [9, 43, 20, 2, 47]. In EMTO, experience is learned,
458"
REFERENCES,0.407905803195963,"updated, and spontaneously shared among target tasks through multi-task learning techniques. A
459"
REFERENCES,0.4087468460891506,"variant of EMTO is multiforms optimization [12, 52, 11]. In multiforms optimization, multi-task
460"
REFERENCES,0.4095878889823381,"learning methods are employed to learn experience from distinct formulations of a single target task.
461"
REFERENCES,0.41042893187552565,"In the second category, experience is transformed unidirectionally. The roles of source task and
462"
REFERENCES,0.4112699747687132,"target task are not compatible, an optimization problem cannot serve as a source task and a target
463"
REFERENCES,0.4121110176619008,"task simultaneously. One popular tributary is transfer optimization which employs transfer learning
464"
REFERENCES,0.4129520605550883,"techniques to transform experience from source tasks to target tasks [35, 17, 16, 40]. In transfer
465"
REFERENCES,0.41379310344827586,"learning, experience can be transformed from a single source task, multiple source tasks, or even
466"
REFERENCES,0.4146341463414634,"source tasks from a different domain [54]. However, these transfer learning techniques pay more
467"
REFERENCES,0.415475189234651,"attention to experience transformation instead of experience learning. Despite diverse and complex
468"
REFERENCES,0.4163162321278385,"situations of experience transformation have been studied [29, 30], the difﬁcult of learning experience
469"
REFERENCES,0.41715727502102606,"from small (expensive) source tasks has not been well studied. Actually, a common scenario in
470"
REFERENCES,0.4179983179142136,"transfer learning is that the source task(s) is/are large enough such that useful experience can be
471"
REFERENCES,0.4188393608074012,"obtained easily through solving source task(s) [54]. In contrast to transfer optimization, recently, some
472"
REFERENCES,0.41968040370058873,"experience-based optimization algorithms attempted to use meta-learning methods to learn experience
473"
REFERENCES,0.42052144659377627,"from small source tasks, which are known as few-shot optimization (FSO)[46]. Since meta-learning
474"
REFERENCES,0.4213624894869638,"only works for related tasks in the same domain, the situations of experience transformation are less
475"
REFERENCES,0.4222035323801514,"complex than that of transfer learning. As a result, meta-learning pays more attention to experience
476"
REFERENCES,0.42304457527333894,"learning instead of experience transformation. Domain-speciﬁc features are extracted as experience
477"
REFERENCES,0.4238856181665265,"and no related task needs to be solved.
478"
REFERENCES,0.4247266610597141,"Our work belongs to the FSO in the second category discussed above since our experience is
479"
REFERENCES,0.4255677039529016,"transformed unidirectionally. More importantly, our experience is learned across many related
480"
REFERENCES,0.42640874684608915,"expensive tasks, rather than gained through solving more or less source tasks. Therefore, our work is
481"
REFERENCES,0.4272497897392767,"different from transfer optimization.
482"
REFERENCES,0.4280908326324643,"B
Discussion on Framework Compatibility and Limitation
483"
REFERENCES,0.4289318755256518,"Our FSEO framework is applicable to regression-based SAEAs as our MDKL surrogates can be
484"
REFERENCES,0.42977291841883936,"embedded in these SAEAs directly. Classiﬁcation-based SAEAs are not compatible with our FSEO
485"
REFERENCES,0.4306139613120269,"framework. The classiﬁcation surrogates in these SAEAs are employed to learn the relation between
486"
REFERENCES,0.4314550042052145,"pairs of solutions, or the relation between solutions and a set of reference solutions. The class labels
487"
REFERENCES,0.432296047098402,"used for surrogate training can be ﬂuctuating during the optimization and thus hard to be learned
488"
REFERENCES,0.43313708999158956,"over related tasks. Similarly, in ordinal-regression-based SAEAs, the ordinal relation values to be
489"
REFERENCES,0.4339781328847771,"learned are not as stable as the ﬁtness of expensive functions. So ordinal-regression-based SAEAs are
490"
REFERENCES,0.4348191757779647,"also not compatible with our FSEO framework. In this paper, we focus on FSO for regression-based
491"
REFERENCES,0.43566021867115223,"SAEAs, while other SAEA categories are left to be discussed in future work.
492"
REFERENCES,0.43650126156433977,"C
Generation of DTLZ variants
493"
REFERENCES,0.4373423044575273,"Our DTLZ optimization experiments generate m-objective DTLZ variants in the following ways:
494"
REFERENCES,0.4381833473507149,"DTLZ1:
495"
REFERENCES,0.43902439024390244,"f1 = (a1 + g)0.5 m−1
Y"
REFERENCES,0.43986543313709,"i=1
xi,
(8) 496"
REFERENCES,0.44070647603027757,"fj=2:m−1 = (aj + g)(0.5 m−j
Y"
REFERENCES,0.4415475189234651,"i=1
xi)(1 −xm−j+1),
(9) 497"
REFERENCES,0.44238856181665265,"fm = (am + g)0.5(1 −x1),
(10)
498"
REFERENCES,0.4432296047098402,"g = 100  k + k
X i=1"
REFERENCES,0.4440706476030278," 
(zi −0.5)2 −cos (20π(zi −0.5))

!"
REFERENCES,0.4449116904962153,",
(11)"
REFERENCES,0.44575273338940286,"where z is a vector consisting of the last k = d −m + 1 variables in x.
In other words,
499"
REFERENCES,0.4465937762825904,"z = {z1, . . . , zk} = {xm, . . . , xd}.
The variants of DTLZ1 introduce only one variable
500"
REFERENCES,0.447434819175778,"a ∈[0.1, 5.0]m in Eq.(8), Eq.(9), and Eq.(10), where a = 1 in the original DTLZ1. For out-of-range
501"
REFERENCES,0.4482758620689655,"test, a ∈[1.5, 5.0]m.
502 503"
REFERENCES,0.44911690496215306,"DTLZ2:
504"
REFERENCES,0.4499579478553406,"f1 = (a1 + g) m−1
Y"
REFERENCES,0.4507989907485282,"i=1
cos(xiπ"
REFERENCES,0.45164003364171573,"b1
),
(12) 505"
REFERENCES,0.45248107653490327,"fj=2:m−1 = (aj + g) m−j
Y"
REFERENCES,0.4533221194280908,"i=1
cos(xiπ bj
) !"
REFERENCES,0.4541631623212784,sin(xm−j+1π
REFERENCES,0.45500420521446594,"bj
),
(13) 506"
REFERENCES,0.4558452481076535,fm = (am + g)sin(x1π
REFERENCES,0.456686291000841,"bm
),
(14) 507 g = k
X"
REFERENCES,0.4575273338940286,"i=1
(zi −0.5)2.
(15)"
REFERENCES,0.45836837678721615,"The variants of DTLZ2 introduce two variables a ∈[0.1, 5.0]m and b ∈[0.5, 2.0]m in Eq.(12),
508"
REFERENCES,0.4592094196804037,"Eq.(13), and Eq.(14), where a = 1 and b = 2 in the original DTLZ2. For out-of-range test,
509"
REFERENCES,0.4600504625735913,"a ∈[1.5, 5.0]m, b ∈[0.5, 1.5]m.
510 511"
REFERENCES,0.4608915054667788,"DTLZ3: The variants of DTLZ3 are generated using the same way as described in DTLZ2, except
512"
REFERENCES,0.46173254835996635,"the equation g from Eq.(15) is replaced by the one from Eq.(11).
513 514"
REFERENCES,0.4625735912531539,"DTLZ4: The variants of DTLZ4 are generated using the same way as described in DTLZ2, except
515"
REFERENCES,0.4634146341463415,"all xi are replaced by x100
i
.
516 517"
REFERENCES,0.464255677039529,"DTLZ5: The variants of DTLZ5 are generated using the same way as described in DTLZ2, except
518"
REFERENCES,0.46509671993271656,"all x2, . . . , xm−1 are replaced by 1+2gxi"
REFERENCES,0.4659377628259041,"2(1+g) .
519 520"
REFERENCES,0.4667788057190917,"DTLZ6:
521 g = k
X"
REFERENCES,0.46761984861227923,"i=1
z0.1
i
.
(16)"
REFERENCES,0.46846089150546677,"The variants of DTLZ6 are generated using the same way as described in DTLZ5, except the equation
522"
REFERENCES,0.4693019343986543,"g from Eq.(15) is replaced by the one from Eq.(16).
523 524"
REFERENCES,0.4701429772918419,"DTLZ7:
525"
REFERENCES,0.47098402018502944,"fj=1:m−1 = xj + aj,
(17) 526"
REFERENCES,0.471825063078217,"fm = (1 + g)  m − m−1
X i=1"
REFERENCES,0.4726661059714045,"
fi
1 + g (1 + sin(3πfi))
!"
REFERENCES,0.4735071488645921,",
(18) 527"
REFERENCES,0.47434819175777965,"g = am + 9 k
X i=1 zi"
REFERENCES,0.4751892346509672,"k .
(19)"
REFERENCES,0.4760302775441548,"The variants of DTLZ7 introduce one variable a ∈[0.1, 5.0]m in Eq.(17) and Eq.(19), where
528"
REFERENCES,0.4768713204373423,"aj=1:m−1 = 0 and am = 1 in the original DTLZ7. For out-of-range test, a ∈[1.5, 5.0]m.
529"
REFERENCES,0.47771236333052985,"D
Effectiveness of Learning Experience
530"
REFERENCES,0.4785534062237174,"Evaluating the effectiveness of learning experiences aims to demonstrate that our MDKL model can
531"
REFERENCES,0.479394449116905,"learn experience from related tasks and outperforms other meta-learning models. For this reason, the
532"
REFERENCES,0.4802354920100925,"experiment is designed to answer the following questions:
533"
REFERENCES,0.48107653490328006,"• Given a small dataset S∗from target task T∗, can MDKL learn experience from related tasks
534"
REFERENCES,0.4819175777964676,"and then generate a model that has the smallest MSE?
535"
REFERENCES,0.4827586206896552,"• If yes, which components of MDKL contribute to the effectiveness of learning experience?
536"
REFERENCES,0.48359966358284273,"Meta-learning or/and deep kernel learning? If not, why not?
537"
REFERENCES,0.48444070647603027,"To answer the two questions above, we consider two experiments to evaluate the effectiveness
538"
REFERENCES,0.4852817493692178,"of learning experience: amplitude prediction for unknown periodic sinusoid functions, and fuel
539"
REFERENCES,0.4861227922624054,"consumption prediction for a gasoline motor engine. The former is a few-shot regression problem
540"
REFERENCES,0.48696383515559294,"that motivates many meta-learning studies [10, 13, 39, 27], while the latter is a real-world regression
541"
REFERENCES,0.4878048780487805,"problem [53].
542"
REFERENCES,0.488645920941968,"D.1
Effectiveness of Learning Experience: Sinusoid Function Regression
543"
REFERENCES,0.4894869638351556,"In the sinusoid regression experiment, we learn experience from a series of 1-dimensional sinusoid
544"
REFERENCES,0.49032800672834315,"functions:
545"
REFERENCES,0.4911690496215307,"y = Asin(wx + b) + ϵ,
(20)"
REFERENCES,0.4920100925147183,"where the amplitude A and phase w of sine waves are varied between functions. The target is to
546"
REFERENCES,0.4928511354079058,"approximate an unknown sinusoid function with a small support dataset S∗and the learned experience.
547"
REFERENCES,0.49369217830109335,"Clearly, by integrating experience with S∗, we estimate parameters (A, w, b) for an unknown sinusoid
548"
REFERENCES,0.4945332211942809,"function. As a result, the output y of the given sinusoid function can be predicted once a query data x
549"
REFERENCES,0.4953742640874685,"is inputted.
550"
REFERENCES,0.496215306980656,"D.1.1
Generation of Sinusoid Function Variants
551"
REFERENCES,0.49705634987384356,"As suggested in [10, 13], we set amplitude A ∈[0.1, 5.0], frequency w ∈[0.999, 1.0], phase b ∈[0,
552"
REFERENCES,0.4978973927670311,"π], and Gaussian noise ϵ ∼(0, 0.1). Therefore, a sinusoid function can be generated by sampling
553"
REFERENCES,0.4987384356602187,"three parameters (A, w, b) from their ranges uniformly. In total, Nm = N = 20000 related sinusoid
554"
REFERENCES,0.49957947855340623,"functions are generated at random.
555"
REFERENCES,0.5004205214465938,"D.1.2
Experimental Setups
556"
REFERENCES,0.5012615643397813,"All data points x are sampled from the range ∈[-5.0, 5.0]. In the meta-learning procedure, both
557"
REFERENCES,0.5021026072329688,"support set and query set contain 5 data points. Hence, a dataset Di is sampled from each (related)
558"
REFERENCES,0.5029436501261564,"sinusoid function Ti, and |Di| = |Dm| = 10. Six experiments are conducted where |S∗| =
559"
REFERENCES,0.503784693019344,"{2, 3, 5, 10, 20, 30} data points are sampled from the target function. Considering Gaussian noise ϵ
560"
REFERENCES,0.5046257359125316,"could be relatively large when amplitude A is close to 0.1, normalized mean squared error (NMSE) is
561"
REFERENCES,0.5054667788057191,"chosen as a performance indicator. NMSE is measured using a dataset that contains 100 data points
562"
REFERENCES,0.5063078216989066,"sampled uniformly from the x range.
563"
REFERENCES,0.5071488645920942,"Table 3: Mean NMSE and standard deviation (in parentheses) of 30 runs on the amplitude regression
of sinusoid function. GP [34] is a widely used surrogate in SAEAs, MAML [10], ALPaCA [13], and
DKT [27] are meta-learning methods. GP_Adam is a GP model ﬁtted by Adam optimizer. DKL
is a deep kernel learning algorithm that adds a neural network to GP_Adam. MDKL_NN applies
meta-learning to DKL, but no task-independent base kernel parameters are shared between related
tasks. Support data points are used to train non-meta surrogates or adapt meta-learning surrogates.
‘+’, ‘≈’, and ‘−’ denote MDKL is statistically signiﬁcantly superior to, almost equivalent to, and
inferior to the compared modelling methods in the Wilcoxon rank sum test (signiﬁcance level is 0.05),
respectively. The last row counts the total win/tie/loss results. It shows that MDKL and DKT have
lower NMSE than other models. The effectiveness of meta-learning on both the neural network and
the base kernel has been demonstrated on this example."
REFERENCES,0.5079899074852817,"Support data
GP
GP_Adam
DKL
MDKL_NN
MDKL (ours)
DKT
MAML
ALPaCA
points |S∗|
[34]
[27]
[10]
[13]
2
1.63e-1(9.18e-2)≈
1.93e-1(9.72e-2)+
1.63e-1(9.05e-2)≈
1.57e-1(9.26e-2)≈
1.56e-1(9.49e-2)
1.56e-1(9.49e-2)≈
2.09e-1(3.63e-1)≈
1.07e+0(2.57e+0)≈
3
1.27e-1(6.04e-2)≈
1.62e-1(6.53e-2)+
1.21e-1(5.96e-2)≈
1.16e-1(5.95e-2)≈
1.10e-1(6.20e-2)
1.10e-1(6.20e-2)≈
2.09e-1(3.60e-1)≈
4.36e-1(8.57e-1)≈
5
6.76e-2(4.62e-2)≈
1.09e-1(5.61e-2)+
7.52e-2(4.40e-2)+
6.38e-2(3.91e-2)≈
4.79e-2(3.73e-2)
4.79e-2(3.70e-2)≈
2.08e-1(3.59e-1)+
4.31e-1(8.04e-1)≈
10
1.70e-2(1.87e-2)≈
6.13e-2(4.58e-2)+
2.87e-2(1.89e-2)+
1.89e-2(1.61e-2)+
1.07e-2(1.16e-2)
1.09e-2(1.17e-2)≈
2.08e-1(3.58e-1)+
6.59e-1(2.14e+0)+
20
5.42e-3(7.64e-3)+
3.92e-2(4.29e-2)+
9.64e-3(1.02e-2)+
5.24e-3(6.57e-3)+
2.57e-3(4.53e-3)
2.63e-3(4.61e-3)≈
2.08e-1(3.58e-1)+
1.13e-1(3.39e-1)+
30
3.97e-3(7.40e-3)+
3.32e-2(4.18e-2)+
4.81e-3(6.68e-3)+
3.20e-3(5.85e-3)+
1.68e-3(3.61e-3)
1.60e-3(3.39e-3)≈
2.08e-1(3.58e-1)+
7.59e-2(2.01e-1)+
+/ ≈/−
2/4/0
6/0/0
4/2/0
3/3/0
-/-/-
0/6/0
4/2/0
3/3/0"
REFERENCES,0.5088309503784693,"D.1.3
Comparison methods
564"
REFERENCES,0.5096719932716569,"In this experiment, three families of modeling methods are compared with our MDKL model:
565"
REFERENCES,0.5105130361648444,"• Meta-learning methods that were proposed for regression tasks: MAML [10], ALPaCA
566"
REFERENCES,0.511354079058032,"[13], and DKT [27]. The conﬁgurations of MAML, ALPaCA, and DKT are the same as
567"
REFERENCES,0.5121951219512195,"suggested in the original literature.
568"
REFERENCES,0.5130361648444071,"• Non-meta-learning method that is widely used for regression tasks: the GP model. We
569"
REFERENCES,0.5138772077375946,"choose a GP as a baseline since it is effective and more relevant to MDKL than other
570"
REFERENCES,0.5147182506307821,"non-meta-learning modeling methods. We set the range of base kernel parameters in the GP
571"
REFERENCES,0.5155592935239697,"model as θ ∈[10−5, 10] and p ∈[1, 2].
572"
REFERENCES,0.5164003364171573,"• MDKL related methods that are designed to investigate which components of MDKL
573"
REFERENCES,0.5172413793103449,"contribute to the modeling performance: GP_Adam, DKL, and MDKL_NN. GP_Adam is a
574"
REFERENCES,0.5180824222035324,"GP model ﬁtted by Adam optimizer. The combination of GP_Adam and a neural network
575"
REFERENCES,0.5189234650967199,"results in a kind of DKL algorithm. MDKL_NN is a meta-learning version of DKL, but it
576"
REFERENCES,0.5197645079899075,"learns only neural network parameters through meta-learning and has no task-independent
577"
REFERENCES,0.520605550883095,"base kernel parameters.
578"
REFERENCES,0.5214465937762826,"D.1.4
Results and Analysis
579"
REFERENCES,0.5222876366694701,"Table 3 reports the statistical test results of the NMSE values achieved by comparison algorithms
580"
REFERENCES,0.5231286795626577,"in sinusoid function regression experiments. Each row lists the results obtained when the same
581"
REFERENCES,0.5239697224558453,"number of ﬁtness evaluations |S∗| are used to train models. The results of Wilcoxon rank sum test
582"
REFERENCES,0.5248107653490328,"between MDKL and other compared algorithms are listed in the last row. It can be observed that both
583"
REFERENCES,0.5256518082422204,"MDKL and DKT have achieved the smallest NMSE values on all tests in the comparison with other
584"
REFERENCES,0.5264928511354079,"meta-learning and non-meta-learning modeling methods.
585"
REFERENCES,0.5273338940285954,"Contributions of MDKL components are analyzed through statistical tests between MDKL related
586"
REFERENCES,0.528174936921783,"methods. The statistical test results between DKL and GP_Adam are 5/1/0, showing that DKL is
587"
REFERENCES,0.5290159798149706,"preferable to GP_Adam when only a few data points are available for modeling. Hence, using a
588"
REFERENCES,0.5298570227081582,"neural network to build a deep kernel for GP is able to enhance the performance of modeling. When
589"
REFERENCES,0.5306980656013457,"meta-learning technique is applied to DKL, the statistical test results between MDKL_NN and DKL
590"
REFERENCES,0.5315391084945332,"are 3/3/0. The meta-learning of neural network parameters is necessary since it contributes to the
591"
REFERENCES,0.5323801513877208,"performance of MDKL. Further statistical test between MDKL and MDKL_NN gives results of 3/3/0,
592"
REFERENCES,0.5332211942809083,"indicating that the meta-learning of base kernel parameters is effective on this regression problem.
593"
REFERENCES,0.5340622371740958,"D.2
Effectiveness of Learning Experience: Engine Performance Regression
594"
REFERENCES,0.5349032800672834,"In this subsection, we focus on a Brake Special Fuel Consumption (BSFC) regression task for a
595"
REFERENCES,0.535744322960471,"gasoline motor engine [53], where BSFC is evaluated on a gasoline engine simulation (denoted by
596"
REFERENCES,0.5365853658536586,"T∗).
597"
REFERENCES,0.5374264087468461,"Table 4: Mean MSE and standard deviation (in parentheses) of 30 runs on the regression of engine
fuel consumption. Support data points are used to train non-meta surrogates or adapt meta-learning
surrogates. All results are normalized since the actual engine data is unable to be disclosed. The
symbols ‘+’, ‘≈’, ‘−’ denote the win/tie/loss result of Wilcoxon rank sum test (signiﬁcance level is
0.05) between MDKL and comparison modeling methods, respectively. The last row counts the total
win/tie/loss results."
REFERENCES,0.5382674516400336,"Support data
GP
GP_Adam
DKL
MDKL_NN
MDKL (ours)
DKT
MAML
ALPaCA
points |S∗|
[34]
[27]
[10]
[13]
2
2.23e+1(3.20e+0)+
2.37e+1(6.30e+0)+
2.30e+1(5.87e+0)+
1.73e+1(6.33e+0)≈
1.72e+1(6.34e+0)
1.81e+1(5.68e+0)≈
1.87e+1(6.37e+0)≈
1.91e+1(1.02e+1)≈
3
2.14e+1(3.74e+0)+
2.41e+1(1.38e+1)+
2.20e+1(3.74e+0)+
1.45e+1(7.13e+0)≈
1.45e+0(7.01e+0)
1.55e+1(6.66e+0)≈
1.80e+1(4.69e+0)≈
2.13e+1(1.97e+1)≈
5
2.13e+1(3.27e+0)+
2.46e+1(1.00e+1)+
2.07e+1(3.95e+0)+
1.12e+1(6.65e+0)≈
1.10e+1(6.58e+0)
1.21e+1(6.49e+0)≈
1.84e+1(6.05e+0)+
1.99e+1(2.29e+1)+
10
1.84e+1(1.89e+0)+
2.06e+1(1.19e+1)+
2.10e+1(5.79e+0)+
7.19e+0(4.82e+0)≈
7.08e+0(4.77e+0)
7.99e+0(4.87e+0)≈
1.70e+1(5.54e+0)+
1.38e+1(8.12e+0)+
20
1.56e+1(2.00e+0)+
2.38e+1(1.05e+1)+
1.76e+1(2.42e+0)+
5.03e+0(1.82e+0)≈
4.86e+0(1.71e+0)
5.74e+0(1.91e+0)+
1.50e+1(2.59e+0)+
1.01e+1(5.52e+0)+
40
1.28e+1(2.03e+0)+
1.48e+1(7.35e+0)+
1.67e+1(3.73e+0)+
4.13e+0(7.90e-1)≈
4.00e+0(8.59e-1)
4.92e+0(1.09e+0)+
1.45e+1(1.85e+0)+
8.01e+0(3.35e+0)+
+/ ≈/−
6/0/0
6/0/0
6/0/0
0/6/0
-/-/-
2/4/0
4/2/0
4/2/0"
REFERENCES,0.5391084945332212,"D.2.1
Experimental setups
598"
REFERENCES,0.5399495374264087,"The related tasks Ti used in our experiment are N = 100 gasoline engine models. These engine
599"
REFERENCES,0.5407905803195963,"models have different behaviors when compared with T∗, but they share the basic features of gasoline
600"
REFERENCES,0.5416316232127838,"engines. All related tasks and the target task have the same six decision variables. Each related task
601"
REFERENCES,0.5424726661059714,"Ti provides only 60 solutions, forming a dataset Di. The size of datasets used for meta-learning
602"
REFERENCES,0.543313708999159,"|Dm| is set to 40. Six tests are conducted where |S∗| = {2, 3, 5, 10, 20, 40} data points are sampled
603"
REFERENCES,0.5441547518923465,"from the real engine simulation T∗. MSE is chosen as an indicator of modeling accuracy, which is
604"
REFERENCES,0.5449957947855341,"measured using a dataset consisting of 12500 data points that are sampled uniformly from the engine
605"
REFERENCES,0.5458368376787216,"decision space. The comparison algorithms are the same as described in Appendix D.1.
606"
REFERENCES,0.5466778805719091,"D.2.2
Results and analysis
607"
REFERENCES,0.5475189234650967,"The statistical test results of the MSE values achieved by comparison algorithms in BSFC regression
608"
REFERENCES,0.5483599663582843,"experiments are summarized in Table 4. Each row lists the results obtained when the same number
609"
REFERENCES,0.5492010092514719,"of ﬁtness evaluations |S∗| are used to train models. The results of Wilcoxon rank sum test between
610"
REFERENCES,0.5500420521446594,"MDKL and other compared algorithms are listed in the last row. It can be observed that MDKL and
611"
REFERENCES,0.5508830950378469,"MDKL_NN outperform other comparison modeling methods since they have achieved the smallest
612"
REFERENCES,0.5517241379310345,"MSE on all tests.
613"
REFERENCES,0.552565180824222,"Additional Wilcoxon rank sum tests have been conducted between MDKL related algorithms to
614"
REFERENCES,0.5534062237174096,"answer our second question (results are not reported in Table 4). The statistical test results between
615"
REFERENCES,0.5542472666105971,"DKL and GP_Adam are 1/5/0, indicating that the neural network in DKL makes some contributions
616"
REFERENCES,0.5550883095037847,"to the performance of MDKL. The statistical test results between MDKL_NN and DKL are 6/0/0,
617"
REFERENCES,0.5559293523969723,"demonstrating that the meta-learning of neural network parameters constructs a useful deep kernel
618"
REFERENCES,0.5567703952901598,"and contributes to the improvement of modeling accuracy. However, there is no signiﬁcant difference
619"
REFERENCES,0.5576114381833474,"between the performance of MDKL and that of MDKL_NN, the meta-learning on base kernel
620"
REFERENCES,0.5584524810765349,"parameters does not play a critical role on this engine problem. In comparison, the meta-learning on
621"
REFERENCES,0.5592935239697224,"base kernel parameters is effective in sinusoid function regression experiments (see Appendix D.1).
622"
REFERENCES,0.56013456686291,"In addition, the statistical test results between MDKL_NN and MAML are 4/2/0. Considering that
623"
REFERENCES,0.5609756097560976,"MAML is a neural network regressor learned through meta-learning, we can conclude that GP is an
624"
REFERENCES,0.5618166526492852,"essential component of our MDKL. In summary, all components in MDKL are necessary, they all
625"
REFERENCES,0.5626576955424727,"contribute to the effectiveness of learning experience.
626"
REFERENCES,0.5634987384356602,"The comparison experiments on sinusoid functions and the gasoline motor engine have demonstrated
627"
REFERENCES,0.5643397813288478,"the effectiveness of our MDKL modeling method in the learning of experience. Given a small
628"
REFERENCES,0.5651808242220353,"dataset of the target task, the model learned through MDKL method has the smallest MSE among
629"
REFERENCES,0.5660218671152228,"all comparison models. Additionally, the investigation between MDKL and its variants shows that
630"
REFERENCES,0.5668629100084104,"all components in MDKL have made their contributions to the effectiveness of learning experience.
631"
REFERENCES,0.567703952901598,"However, similar to other meta-learning studies [10, 13], we have not deﬁned the similarity between
632"
REFERENCES,0.5685449957947856,"tasks. In other words, the boundary between related tasks and unrelated tasks has not been deﬁned.
633"
REFERENCES,0.5693860386879731,"This should be a topic of further study on meta-learning. Moreover, the relationship between task
634"
REFERENCES,0.5702270815811606,"similarity and modeling performance has not been investigated. Instead, we study the relationship
635"
REFERENCES,0.5710681244743482,"between task similarity and SAEA optimization performance in Section F, since our main focus is
636"
REFERENCES,0.5719091673675357,"the surrogate-assisted evolutionary optimization.
637"
REFERENCES,0.5727502102607233,"Table 5: Mean IGD+ values and standard deviation (in parentheses) obtained from 30 runs on the
DTLZ problems. MOEA/D-FS and the comparison algorithms initialize their surrogates with 10, 100
samples, respectively. Extra 50 evaluations are allowed in the further optimization."
REFERENCES,0.5735912531539108,"Problem
MOEA/D-EGO
MOEA/D-FS (ours)
ParEGO
K-RVEA
KTA2
CSEA
OREA
ESBCEO
KMOEA-TIC
DTLZ1
1.07e+2(2.05e+1)+
9.70e+1(1.87e+1)
7.82e+1(1.54e+1)−
1.18e+2(2.45e+1)+
1.01e+2(2.38e+1)≈
1.10e+2(2.50e+1)+
1.02e+2(1.97e+1)≈
8.81e+1(1.18e+1)≈
1.10e+2(2.29e+1)+
DTLZ2
2.99e-1(7.01e-2)+
1.43e-1(2.29e-2)
3.17e-1(4.12e-2)+
2.69e-1(5.97e-2)+
2.14e-1(3.84e-2)+
2.98e-1(5.25e-2)+
1.76e-1(4.69e-2)+
3.39e-1(3.78e-2)+
2.10e-1(7.10e-2)+
DTLZ3
3.15e+2 (6.04e+1)+
1.97e+2 (1.64e+1)
2.30e+2 (5.99e+1)≈
3.24e+2 (5.90e+1)+
2.67e+2 (6.70e+1)+
2.82e+2(6.97e+1)+
2.72e+2(6.88e+1)+
2.09e+2(4.23e+1)≈
2.98e+2(6.14e+1)+
DTLZ4
5.04e-1(8.25e-2)≈
4.44e-1(1.35e-1)
5.44e-1(7.58e-2)+
4.57e-1(1.14e-1)≈
4.51e-1(9.54e-2)≈
4.75e-1(1.09e-1)≈
3.18e-1(1.54e-1)−
4.99e-1(7.37e-2)≈
4.26e-1(9.19e-2)≈
DTLZ5
2.39e-1(7.17e-2)+
1.13e-1(2.24e-2)
2.58e-1(3.68e-2)+
1.92e-1 (5.97e-2)+
1.44e-1(4.60e-2)+
2.14e-1(4.05e-2)+
7.84e-2(2.42e-2)−
2.68e-1(3.62e-2)+
8.73e-2(2.77e-2)−
DTLZ6
1.29e+0(4.74e-1)≈
1.11e+0(5.71e-1)
1.67e+0(6.77e-1)+
4.62e+0(6.42e-1)+
3.37e+0(6.71e-1)+
6.26e+0(3.40e-1)+
4.60e+0(1.19e+0)+
2.41e+0(7.97e-1)+
2.90e+0(5.34e-1)+
DTLZ7
3.31e-1(3.11e-1)−
2.47e+0(1.89e+0)
3.66e-1(1.31e-1)−
1.74e-1(3.57e-2)−
4.34e-1(2.20e-1)−
4.17e+0(1.13e+0)+
2.14e+0(1.15e+0)≈
5.47e-1(2.46e-1)−
9.44e-2(1.23e-2)−
+/ ≈/−
4/2/1
-/-/-
4/1/2
5/1/1
4/2/1
6/1/0
3/2/2
3/3/1
4/1/2"
REFERENCES,0.5744322960470984,"E
Additional Details on Expensive Multi-Objective Optimization
638"
REFERENCES,0.575273338940286,"E.1
Comparison algorithms
639"
REFERENCES,0.5761143818334735,"As explained in Section B, our FSEO framework is compatible with regression-based SAEAs. Hence,
640"
REFERENCES,0.5769554247266611,"we select MOEA/D-EGO [51] as an example and replace its GP surrogates by our MDKL surrogates.
641"
REFERENCES,0.5777964676198486,"The resulting algorithm is denoted as MOEA/D-FS. Note that it is not necessary to specially select a
642"
REFERENCES,0.5786375105130361,"newly proposed regression-based SAEA as our example, our main objective is to save evaluations
643"
REFERENCES,0.5794785534062237,"with experience and observe if there is any damage to the optimization performance caused by the
644"
REFERENCES,0.5803195962994113,"saving of evaluations. Therefore, it does not make any difference which regression-based SAEA
645"
REFERENCES,0.5811606391925989,"or BO we choose as our example. Additionally, to demonstrate the improvement of optimization
646"
REFERENCES,0.5820016820857864,"performance caused by using experience on DTLZ problems is signiﬁcant, several state-of-the-art
647"
REFERENCES,0.5828427249789739,"SAEAs and MOBO are also compared as baselines, including ParEGO [19], K-RVEA [7], CSEA [25],
648"
REFERENCES,0.5836837678721615,"OREA [48], KTA2 [33], ESBCEO [3], and KMOEA-TIC [28]. Among these algorithms, ParEGO,
649"
REFERENCES,0.584524810765349,"K-RVEA, KTA2, KMOEA-TIC use regression-based surrogates, CSEA uses a classiﬁcation-based
650"
REFERENCES,0.5853658536585366,"surrogate, OREA employs an ordinal-regression-based surrogate, and ESBCEO is a recently proposed
651"
REFERENCES,0.5862068965517241,"MOBO.
652"
REFERENCES,0.5870479394449117,"We implemented the FSEO framework, MOEA/D-EGO, ParEGO, and OREA, while the code of
653"
REFERENCES,0.5878889823380993,"K-RVEA, CSEA, KTA2, and ESBCEO [3] is available on PlatEMO [37], an open source MATLAB
654"
REFERENCES,0.5887300252312868,"platform for evolutionary multi-objective optimization. The code of KMOEA-TIC [28] is obtained
655"
REFERENCES,0.5895710681244744,"from its authors. To make a fair comparison, all comparison algorithms share the same initial dataset
656"
REFERENCES,0.5904121110176619,"S∗in an independent run. We also set θ ∈[10−5, 100]d and p = 2 for all GP surrogates as suggested
657"
REFERENCES,0.5912531539108494,"in [33], these GP surrogates are implemented through DACE [31]. Other conﬁgurations are the same
658"
REFERENCES,0.592094196804037,"as suggested in their original literature.
659"
REFERENCES,0.5929352396972245,"E.2
Result Table and Analysis of Expensive Multi-Objective Optimization
660"
REFERENCES,0.5937762825904122,"The experience learned from related tasks makes MOEA/D-EGO more competitive when compared
661"
REFERENCES,0.5946173254835997,"to other SAEAs. The use of MDKL surrogates results in signiﬁcantly smaller IGD+ values on DTLZ1,
662"
REFERENCES,0.5954583683767872,"DTLZ2, DTLZ3, and DTLZ5 than before. As a result, MOEA/D-FS achieves the smallest IGD+
663"
REFERENCES,0.5962994112699748,"values on DTLZ2 and DTLZ3, and its optimization results on DTLZ1 and DTLZ5 are much closer
664"
REFERENCES,0.5971404541631623,"to the best optimization results (e.g. results obtained by ParEGO and OREA) than MOEA/D-EGO.
665"
REFERENCES,0.5979814970563498,"Although MOEA/D-FS does not achieve the smallest IGD+ values on all DTLZ problems, it should
666"
REFERENCES,0.5988225399495374,"be noted that MOEA/D-FS is still the best algorithm among comparison SAEAs due to its overall
667"
REFERENCES,0.599663582842725,"performance. Table 5 shows that no comparison SAEA outperforms MOEA/D-FS on three DTLZ
668"
REFERENCES,0.6005046257359126,"problems, but MOEA/D-FS outperforms all comparison SAEAs on at least three DTLZ problems.
669"
REFERENCES,0.6013456686291001,"Furthermore, the IGD+ values of MOEA/D-FS are achieved with an evaluation budget of 60, while
670"
REFERENCES,0.6021867115222876,"the IGD+ values of other SAEAs are reached with a cost of 150 evaluations (see Table 2).
671"
REFERENCES,0.6030277544154752,"E.3
Result Tables and Figures in IGD and HV Metrics
672"
REFERENCES,0.6038687973086627,"The performance of our method and the comparison algorithms are also evaluated on inverted
673"
REFERENCES,0.6047098402018503,"generational distance (IGD) [4] and Hypervolume (HV) [55] metrics.
674"
REFERENCES,0.6055508830950378,"Results in IGD values are reported in Table 6 and Fig. 5. A smaller IGD value indicates a better
675"
REFERENCES,0.6063919259882254,"optimization result.
676"
REFERENCES,0.607232968881413,"Results in HV values are reported in Table 7 and Fig. 6. A larger HV value indicates a better
677"
REFERENCES,0.6080740117746005,"optimization result.
678"
REFERENCES,0.6089150546677881,"Table 6: Mean IGD values and standard deviation (in parentheses) obtained from 30 runs on 7
DTLZ problems. MOEA/D-FS and comparison algorithms initialize their surrogates with 10, 100
samples, respectively. Extra 50 evaluations are allowed in the further optimization. ‘+’, ‘≈’, and ‘−’
denote MOEA/D-FS is statistically signiﬁcantly superior to, almost equivalent to, and inferior to the
compared algorithms in the Wilcoxon rank sum test (signiﬁcance level is 0.05), respectively. The last
row counts the total win/tie/loss results."
REFERENCES,0.6097560975609756,"Problems
MOEAD-EGO
MOEAD-FS
ParEGO
K-RVEA
KTA2
CSEA
OREA
ESBCEO
KMOEATIC
DTLZ1
1.07e+2(2.05e+1)+
9.70e+1(1.87e+1)
7.82e+1(1.54e+1)−
1.18e+2(2.41e+1)+
1.01e+2(2.34e+1)≈
1.10e+2(2.46e+1)+
1.02e+2(1.97e+1)≈
8.81e+1(1.18e+1)≈
1.10e+2(2.29e+1)+
DTLZ2
3.30e-1(7.23e-2)+
1.72e-1(2.41e-2)
3.59e-1(2.82e-2)+
3.08e-1(4.93e-2)+
2.45e-1(3.57e-2)+
3.36e-1(3.96e-2)+
2.14e-1(4.10e-2)+
3.64e-1(3.29e-2)+
2.86e-1(6.31e-2)+
DTLZ3
3.15e+2(6.04e+1)+
1.97e+2(1.64e+1)
2.30e+2(5.99e+1)≈
3.24e+2(5.80e+1)+
2.67e+2(6.58e+1)+
2.82e+2(6.85e+1)+
2.72e+2(6.88e+1)+
2.09e+2(4.23e+1)≈
2.98e+2(6.14e+1)+
DTLZ4
7.51e-1(1.50e-1)≈
7.96e-1(2.25e-1)
7.65e-1(1.14e-1)≈
5.94e-1(1.28e-1)−
6.30e-1(1.51e-1)−
7.00e-1(1.48e-1)−
5.64e-1(2.01e-1)−
6.70e-1(8.05e-2)−
5.23e-1(8.60e-2)−
DTLZ5
2.47e-1(7.21e-2)+
1.17e-1(2.08e-2)
2.83e-1(3.13e-2)+
2.13e-1(5.55e-2)+
1.61e-1(4.60e-2)+
2.33e-1(3.65e-2)+
8.64e-2(2.48e-2)−
2.83e-1(3.00e-2)+
1.18e-1(3.17e-2)≈
DTLZ6
1.36e+0(4.10e-1)≈
1.18e+0(5.35e-1)
1.78e+0(6.29e-1)+
4.63e+0(6.26e-1)+
3.37e+0(6.50e-1)+
6.26e+0(3.28e-1)+
4.61e+0(1.18e+0)+
2.45e+0(7.92e-1)+
2.92e+0(5.35e-1)+
DTLZ7
4.22e-1(3.16e-1)−
2.56e+0(1.86e+0)
5.34e-1(1.25e-1)−
2.55e-1(4.36e-2)−
5.54e-1(2.38e-1)−
4.20e+0(1.11e+0)+
2.21e+0(1.11e+0)≈
6.21e-1(2.43e-1)−
1.85e-1(1.81e-2)−
+/ ≈/−
4/2/1
-/-/-
3/2/2
5/0/2
4/1/2
6/0/1
3/2/2
3/2/2
4/1/2"
REFERENCES,0.6105971404541631,"Figure 5: IGD curves averaged over 30 runs on 7 DTLZ problems. Solid lines are mean values,
while shadows are error regions. Upper: DTLZ1, DTLZ2, DTLZ3, DTLZ4. Lower: DTLZ5,
DTLZ6, DTLZ7. MOEA/D-FSs and comparison algorithms initialize their surrogates with 10,
100 samples, respectively. Extra 50 evaluations are allowed in the further optimization. Note that
‘FS(out)’ indicates the target task is excluded from the range of related tasks during the meta-learning
procedure). X-axis denotes the number of evaluations used after the surrogate initialization."
REFERENCES,0.6114381833473507,"Table 7: Mean HV values and standard deviation (in parentheses) obtained from 30 runs on 7
DTLZ problems. MOEA/D-FS and comparison algorithms initialize their surrogates with 10, 100
samples, respectively. Extra 50 evaluations are allowed in the further optimization. ‘+’, ‘≈’, and ‘−’
denote MOEA/D-FS is statistically signiﬁcantly superior to, almost equivalent to, and inferior to the
compared algorithms in the Wilcoxon rank sum test (signiﬁcance level is 0.05), respectively. The last
row counts the total win/tie/loss results."
REFERENCES,0.6122792262405383,"Problems
MOEAD-EGO
MOEAD-FS
ParEGO
K-RVEA
KTA2
CSEA
OREA
ESBCEO
KMOEATIC
DTLZ1
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
DTLZ2
2.02e-1(1.28e-1)+
4.69e-1(3.70e-2)
1.21e-1(4.31e-2)+
1.93e-1(8.93e-2)+
3.19e-1(6.49e-2)+
1.59e-1(5.39e-2)+
3.80e-1(7.64e-2)+
1.39e-1(4.55e-2)+
2.91e-1(1.29e-1)+
DTLZ3
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
DTLZ4
6.25e-2(5.53e-2)+
1.43e-1(7.17e-2)
2.03e-2(2.71e-2)+
3.81e-2(4.24e-2)+
6.49e-2(7.42e-2)+
4.30e-2(5.29e-2)+
2.11e-1(1.37e-1)≈
2.27e-2(2.65e-2)+
6.50e-2(7.07e-2)+
DTLZ5
4.50e-2(4.17e-2)+
1.63e-1(1.60e-2)
1.29e-2(1.30e-2)+
4.82e-2(2.78e-2)+
7.98e-2(3.80e-2)+
3.08e-2(1.61e-2)+
1.49e-1(2.88e-2)≈
1.64e-2(1.42e-2)+
1.58e-1(3.69e-2)≈
DTLZ6
1.24e-3(3.77e-3)≈
1.59e-2(3.46e-2)
2.02e-5(1.09e-4)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
DTLZ7
3.83e-1(8.50e-2)−
1.12e-1(1.27e-1)
2.21e-1(9.60e-2)−
3.79e-1(2.61e-2)−
3.70e-1(3.88e-2)−
3.14e-5(1.69e-4)+
2.97e-2(4.45e-2)≈
1.71e-1(8.33e-2)−
4.67e-1(1.27e-2)−
+/ ≈/−
3/3/1
-/-/-
3/3/1
3/3/1
3/3/1
4/3/0
1/6/0
3/3/1
2/4/1"
REFERENCES,0.6131202691337259,"E.4
Performance on Expensive Multi-Objective Optimization Under the Same Evaluation
679"
REFERENCES,0.6139613120269134,"Budget
680"
REFERENCES,0.6148023549201009,"The statistical test results reported in the last row of Table 5 show that ParEGO [19] and OREA [48]
681"
REFERENCES,0.6156433978132885,"are the best two comparison algorithms when compared with our MOEA/D-FS. In this subsection,
682"
REFERENCES,0.616484440706476,"we evaluate the performance of MOEA/D-FS when no extra evaluation is saved. For this purpose, we
683"
REFERENCES,0.6173254835996635,"compare the optimization performance of these three SAEAs under the same evaluation budget: 10
684"
REFERENCES,0.6181665264928511,"evaluations (1d) for surrogate initialization and 50 evaluations for further optimization. The statistical
685"
REFERENCES,0.6190075693860387,"test results are reported in Table 8. It can be seen that our MOEA/D-FS generally outperforms the
686"
REFERENCES,0.6198486122792263,"Figure 6: HV curves averaged over 30 runs on 7 DTLZ problems. Solid lines are mean values,
while shadows are error regions. Upper: DTLZ1, DTLZ2, DTLZ3, DTLZ4. Lower: DTLZ5,
DTLZ6, DTLZ7. MOEA/D-FSs and comparison algorithms initialize their surrogates with 10,
100 samples, respectively. Extra 50 evaluations are allowed in the further optimization. Note that
‘FS(out)’ indicates the target task is excluded from the range of related tasks during the meta-learning
procedure). X-axis denotes the number of evaluations used after the surrogate initialization."
REFERENCES,0.6206896551724138,"Table 8: Mean IGD+ values and standard deviation (in parentheses) obtained from 30 runs on DTLZ
problems. MOEA/D-FS is compared with ParEGO and OREA under the same evaluation budget: 10
evaluations for surrogate initialization and 50 evaluations for the optimization process. ‘+’, ‘≈’, and
‘−’ denote MOEA/D-FS is statistically signiﬁcantly superior to, almost equivalent to, and inferior to
the compared two algorithms in the Wilcoxon rank sum test (signiﬁcance level is 0.05), respectively.
The last row counts the total win/tie/loss results."
REFERENCES,0.6215306980656014,"Problem
MOEA/D-FS
ParEGO
OREA
DTLZ1
9.70e+1(1.87e+1)
6.70e+1(4.75e+0)−
1.10e+2(3.65e+1)≈
DTLZ2
1.43e-1(2.29e-2)
5.51e-1(5.37e-2)+
4.28e-1(6.68e-2)+
DTLZ3
1.97e+2 (1.64e+1)
1.84e+2(8.86e+0)≈
2.72e+2(6.59e+1)+
DTLZ4
4.44e-1(1.35e-1)
6.29e-1(7.99e-2)+
6.45e-1(1.24e-1)+
DTLZ5
1.13e-1(2.24e-2)
4.32e-1(8.88e-2)+
3.02e-1(7.63e-2)+
DTLZ6
1.11e+0(5.71e-1)
1.03e+0(4.78e-1)≈
5.71e+0(6.73e-1)+
DTLZ7
2.47e+0(1.89e+0)
4.38e-1(1.39e-1)−
7.12e+0(1.77e+0)+
+/ ≈/−
-/-/-
3/2/2
6/1/0"
REFERENCES,0.6223717409587889,"compared SAEAs when only 1d evaluations are used to initialize their surrogates. The effectiveness
687"
REFERENCES,0.6232127838519764,"of our FSEO framework has been demonstrated. Note that OREA is an evolutionary algorithm
688"
REFERENCES,0.624053826745164,"assisted by ordinal-regression-based surrogates. Currently, our FSEO framework is applicable to the
689"
REFERENCES,0.6248948696383515,"SAEAs working with regression-based surrogates. The meta-learning of ordinal-regression models
690"
REFERENCES,0.6257359125315392,"can be a topic of further research.
691"
REFERENCES,0.6265769554247267,"F
Inﬂuence of Task Similarity
692"
REFERENCES,0.6274179983179142,"In real-world applications, it is optimistic to assume that some related tasks are very similar to the
693"
REFERENCES,0.6282590412111018,"target task. A more common situation is that all related tasks have limited similarity to the target task.
694"
REFERENCES,0.6291000841042893,"To investigate the relationship between task similarity and FSEO optimization performance, we also
695"
REFERENCES,0.6299411269974768,"test the performance in an ‘out-of-range’ situation, where the original DTLZ is excluded from the
696"
REFERENCES,0.6307821698906644,"range of DTLZ variants during the MDKL meta-learning procedure. As a result, only the DTLZ
697"
REFERENCES,0.631623212783852,"variants that are quite different from the original DTLZ problem can be used to learn experience. The
698"
REFERENCES,0.6324642556770396,"‘out-of-range’ situation eliminates the probability that MDKL surrogates beneﬁt greatly from the
699"
REFERENCES,0.6333052985702271,"Table 9: Mean IGD+ values and standard deviation (in parentheses) obtained from 30 runs on DTLZ
problems. Both MOEA/D-FSs initialize their surrogates with 10 samples, extra 50 evaluations are
allowed in the further optimization. The last two rows count the statistical test results between
MOEA/D-FSs and other compared algorithms."
REFERENCES,0.6341463414634146,"MOEA/D-FSs
In-range
Out-of-range
DTLZ1
9.70e+1(1.87e+1)≈
9.11e+1(1.53e+1)
DTLZ2
1.43e-1(2.29e-2)≈
1.41e-1(1.75e-2)
DTLZ3
1.97e+2 (1.64e+1)≈
1.98e+1(1.51e+1)
DTLZ4
4.44e-1(1.35e-1)≈
4.96e-1(8.63e-2)
DTLZ5
1.13e-1(2.24e-2)≈
1.03e-1(2.39e-2)
DTLZ6
1.11e+0(5.71e-1)≈
1.17e+0(6.88e-1)
DTLZ7
2.47e+0(1.89e+0)≈
2.86e+0(1.87e+0)
+/ ≈/−
0/7/0
-/-/-
vs MOEA/D-EGO
4/2/1
4/2/1
vs 6 Comparisons
26/9/7
27/7/8"
REFERENCES,0.6349873843566022,"DTLZ variants that are very similar to the original DTLZ problem. Detailed deﬁnitions of the related
700"
REFERENCES,0.6358284272497897,"tasks used in the ‘out-of-range’ situation are given in Appendix C. Apart from the related tasks used,
701"
REFERENCES,0.6366694701429773,"the remaining experimental setups are the same as the setups described in Section 5.1. For the sake
702"
REFERENCES,0.6375105130361648,"of convenience, we denote the situation we tested in Section 5.1 as ‘in-range’ below.
703"
REFERENCES,0.6383515559293524,"The statistical test results reported in Table 9 show that the ‘out-of-range’ situation achieves competi-
704"
REFERENCES,0.63919259882254,"tive IGD+ values to the ‘in-range’ situation on all 7 test instances. This suggests that related tasks
705"
REFERENCES,0.6400336417157275,"that are very similar to the target task have a limited impact on the optimization performance of our
706"
REFERENCES,0.6408746846089151,"FSEO framework. Useful experience can be learned from related tasks that are not very similar to
707"
REFERENCES,0.6417157275021026,"the target task. Crucially, when comparing the performance of the ‘out-of-range’ situation and that
708"
REFERENCES,0.6425567703952901,"of MOEA/D-EGO, we can still observe competitive or improved optimization results on 6 DTLZ
709"
REFERENCES,0.6433978132884777,"problems (see Table 9, the row titled by ‘vs MOEA/D-EGO’, or Fig. 3). Moreover, it can be seen
710"
REFERENCES,0.6442388561816653,"from the last row of Table 9 that the ‘out-of-range’ situation achieves better/competitive/worse IGD+
711"
REFERENCES,0.6450798990748529,"values than all compared SAEAs on 27/7/8 test instances. In comparison, the corresponding statistical
712"
REFERENCES,0.6459209419680404,"test results for the ‘in-range’ situation are 26/9/7. The difference between these statistical test results
713"
REFERENCES,0.6467619848612279,"is not signiﬁcant.
714"
REFERENCES,0.6476030277544155,"A study on the ‘out-of-range’ situation in the context of extremely expensive multi-objective opti-
715"
REFERENCES,0.648444070647603,"mization is presented in Appendix H.2. Consistent results can be observed from Table 12 and Fig.
716"
REFERENCES,0.6492851135407905,"7.
717"
REFERENCES,0.6501261564339781,"Consequently, related tasks that are very similar to the target task are not essential to the optimization
718"
REFERENCES,0.6509671993271657,"performance of our FSEO framework. In the ‘out-of-range’ situation, our MOEA/D-FS can still
719"
REFERENCES,0.6518082422203533,"achieve competitive or better optimization results than MOEA/D-EGO while using only 1d samples
720"
REFERENCES,0.6526492851135408,"for surrogate initialization.
721"
REFERENCES,0.6534903280067283,"G
Inﬂuence of the Size of Datasets Used in Meta-Learning
722"
REFERENCES,0.6543313708999159,"We also investigated the performance of our FSEO framework when different sizes of datasets |Dm|
723"
REFERENCES,0.6551724137931034,"are used in the meta-learning procedure. The experimental setups are the same as the setups of
724"
REFERENCES,0.656013456686291,"MOEA/D-FS in Section 5.1 except for |Dm|.
725"
REFERENCES,0.6568544995794785,"It is evident from Table 10 that when each DTLZ variant provides |Dm| = 60 samples for the
726"
REFERENCES,0.6576955424726662,"meta-learning of MDKL surrogates, the performance of both MOEA/D-FSs are improved on 2 or
727"
REFERENCES,0.6585365853658537,"3 DTLZ problems. Particularly, a signiﬁcant improvement can be observed from the optimization
728"
REFERENCES,0.6593776282590412,"results of DTLZ7. As we discussed in Section 5.1, the poor performance of our experience-based
729"
REFERENCES,0.6602186711522288,"optimization on DTLZ7 is caused by the small size of Dm. Optimal solutions have few chances to
730"
REFERENCES,0.6610597140454163,"be included in a small Dm, which makes Dm fails to provide the experience about the discontinuity
731"
REFERENCES,0.6619007569386038,"of optimal regions. In comparison, the experience of ‘optimal regions’ can be learned from large
732"
REFERENCES,0.6627417998317914,"datasets Dm and thus the optimization results are improved signiﬁcantly.
733"
REFERENCES,0.663582842724979,"In conclusion, for our FSEO framework, a large Dm for the meta-learning procedure indicates
734"
REFERENCES,0.6644238856181666,"more useful experience can be learned from related tasks, which further improves the performance
735"
REFERENCES,0.6652649285113541,"of experience-based optimization. Therefore, when applying our FSEO framework to real-world
736"
REFERENCES,0.6661059714045416,"Table 10: Mean IGD+ values and standard deviation (in parentheses) obtained from 30 runs on DTLZ
problems. 10 samples are used for initialization and extra 50 evaluations are allowed in the further
optimization. |Dm| is the size of the dataset collected from each related task."
REFERENCES,0.6669470142977292,"Problem
In-range
Out-of-range
|Dm|=20
|Dm|=60
|Dm|=20
|Dm|=60
DTLZ1
9.70e+1(1.87e+1)≈
9.77e+1(1.73e+1)
9.11e+1(1.53e+1)≈
9.93e+1(1.87e+1)
DTLZ2
1.43e-1(2.29e-2)+
1.24e-1(2.11e-2)
1.41e-1(1.75e-2)+
1.29e-1(2.36e-2)
DTLZ3
1.97e+2 (1.64e+1)≈
1.98e+2 (2.21e+1)
1.98e+1(1.51e+1)≈
1.93e+2(1.19e+1)
DTLZ4
4.44e-1(1.35e-1)≈
5.17e-1(5.68e-2)
4.96e-1(8.63e-2)≈
5.17e-1(5.38e-2)
DTLZ5
1.13e-1(2.24e-2)+
9.96e-2(2.18e-2)
1.03e-1(2.39e-2)≈
1.05e-1(2.73e-2)
DTLZ6
1.11e+0(5.71e-1)≈
1.04e+0(6.06e-1)
1.17e+0(6.88e-1)≈
1.22e+0(6.41e-1)
DTLZ7
2.47e+0(1.89e+0)+
7.49e-1(2.61e-1)
2.86e+0(1.87e+0)+
6.96e-1(2.41e-1)
+/ ≈/−
3/4/0
-/-/-
2/5/0
-/-/-"
REFERENCES,0.6677880571909167,"Table 11: Mean IGD+ values and standard deviation (in parentheses) obtained from 30 runs on the
DTLZ problems. MOEA/D-FS and the comparison algorithms initialize their surrogates with 10,
60 samples, respectively. Extra 30 evaluations are allowed in the further optimization. ‘+’, ‘≈’,
and ‘−’ denote MOEA/D-FS is statistically signiﬁcantly superior to, equivalent to, and inferior to
the compared algorithms in the Wilcoxon rank sum test (signiﬁcance level is 0.05), respectively.
The last row is the total win/tie/loss results. Performance improvement can be observed from
the comparisons between MOEA/D-FS and MOEA/D-EGO, while 50 evaluations are saved from
surrogate initialization."
REFERENCES,0.6686291000841043,"Problems
MOEAD-EGO
MOEAD-FS (ours)
ParEGO
K-RVEA
KTA2
CSEA
OREA
ESBCEO
KMOEATIC
DTLZ1
1.07e+2(2.73e+1)≈
1.03e+2(2.34e+1)
8.70e+1(2.53e+1)−
1.22e+2(3.20e+1)+
1.15e+2(3.03e+1)≈
1.08e+2(2.64e+1)≈
1.11e+2(2.25e+1)+
1.00e+2(2.07e+1)≈
1.20e+2(2.71e+1)+
DTLZ2
3.49e-1(5.82e-2)+
1.57e-1(2.29e-2)
3.51e-1(5.01e-2)+
3.72e-1(4.32e-2)+
3.57e-1(4.60e-2)+
3.55e-1(5.14e-2)+
3.14e-1(3.76e-2)+
3.83e-1(3.83e-2)+
3.79e-1(4.46e-2)+
DTLZ3
3.07e+2(5.32e+1)+
2.03e+2(2.42e+1)
2.16e+2(4.89e+1)≈
3.53e+2(7.76e+1)+
3.23e+2(8.67e+1)+
3.35e+2(6.83e+1)+
3.39e+2(7.72e+1)+
2.41e+2(5.51e+1)+
3.27e+2(8.10e+1)+
DTLZ4
5.45e-1(1.09e-1)≈
4.91e-1(1.24e-1)
6.36e-1(8.67e-2)+
5.53e-1(9.79e-2)≈
5.47e-1(1.02e-1)≈
5.84e-1(9.59e-2)+
5.14e-1(1.21e-1)≈
5.47e-1(7.55e-2)≈
4.53e-1(1.03e-1)≈
DTLZ5
2.79e-1(5.69e-2)+
1.18e-1(2.25e-2)
2.78e-1(5.59e-2)+
2.82e-1(5.42e-2)+
2.60e-1(5.50e-2)+
2.77e-1(4.34e-2)+
1.99e-1(4.53e-2)+
2.94e-1(4.92e-2)+
2.69e-1(6.11e-2)+
DTLZ6
2.04e+0(7.33e-1)+
1.29e+0(6.44e-1)
2.47e+0(7.39e-1)+
5.23e+0(6.17e-1)+
4.58e+0(6.36e-1)+
6.44e+0(3.53e-1)+
5.79e+0(6.70e-1)+
3.04e+0(9.46e-1)+
3.55e+0(6.90e-1)+
DTLZ7
1.90e+0(9.19e-1)−
4.16e+0(2.54e+0)
1.39e+0(1.49e+0)−
3.13e-1(6.07e-2)−
2.05e+0(2.16e+0)−
5.47e+0(1.31e+0)+
5.51e+0(1.32e+0)+
9.57e-1(5.40e-1)−
2.68e-1(1.47e-1)−
+/ ≈/−
4/2/1
-/-/-
4/1/2
5/1/1
4/2/1
6/1/0
6/1/0
4/2/1
5/1/1"
REFERENCES,0.6694701429772918,"optimization problems, it is preferable to collect more data from related tasks for experience learning.
737 738"
REFERENCES,0.6703111858704794,"H
Experiments on Extremely Expensive Multi-Objective Optimization
739"
REFERENCES,0.671152228763667,"In this section, we investigate the performance of our FSEO framework in the context of extremely
740"
REFERENCES,0.6719932716568545,"expensive optimization, where the allowed ﬁtness evaluations on target problems are fewer than that
741"
REFERENCES,0.6728343145500421,"in the experiment carried out in Sections 5.1 of the main ﬁle and Appendix F.
742"
REFERENCES,0.6736753574432296,"H.1
Performance between Comparison Algorithms
743"
REFERENCES,0.6745164003364171,"We conduct the experiment described in Section 5.1 of the main ﬁle, but with a smaller evaluation
744"
REFERENCES,0.6753574432296047,"budget than the budget listed in Table 2. The size of the initial dataset S∗is set to 10, 60 for our
745"
REFERENCES,0.6761984861227922,"MOEA/D-FS and comparison algorithms, respectively. 30 extra evaluations for further optimization
746"
REFERENCES,0.6770395290159799,"are allowed. The total evaluation budget is 40, 90 for our MOEA/D-FS and comparison algorithms,
747"
REFERENCES,0.6778805719091674,"respectively.
748"
REFERENCES,0.6787216148023549,"The aim of this subsection is to answer the question below:
749"
REFERENCES,0.6795626576955425,"• Is our FSEO framework more suitable for the optimization problems in which evaluations are
750"
REFERENCES,0.68040370058873,"extremely expensive? In other words, will the advantage of our FSEO framework become
751"
REFERENCES,0.6812447434819175,"more prominent if the optimization problems allow a smaller evaluation budget?
752"
REFERENCES,0.6820857863751051,"The comparison results reported in Fig. 7 and Table 11 show that MOEA/D-FS has achieved
753"
REFERENCES,0.6829268292682927,"competitive or smaller IGD+ values than MOEA/D-EGO on all DTLZ problems except for DTLZ7.
754"
REFERENCES,0.6837678721614803,"Meanwhile, 5d evaluations have been saved.
755"
REFERENCES,0.6846089150546678,"Consistent with the results discussed in Section 5.1 of the main ﬁle, MOEA/D-FS fails to achieve a
756"
REFERENCES,0.6854499579478553,"competitive result compared to MOEA/D-EGO on DTLZ7 since experience is learned from small
757"
REFERENCES,0.6862910008410429,"datasets collected from related tasks. Although we set a different evaluation budget for all SAEAs,
758"
REFERENCES,0.6871320437342304,"the size of datasets for meta-learning |Dm| has not been modiﬁed. However, it can be observed from
759"
REFERENCES,0.687973086627418,"the statistical test results (see the last row of Tables 5 and 11) that our MOEA/D-FS outperforms
760"
REFERENCES,0.6888141295206055,"the comparison algorithms on 26, 29 test instances when the total evaluation budget of comparison
761"
REFERENCES,0.6896551724137931,"Figure 7: IGD+ curves averaged over 30 runs on 7 DTLZ problems. Solid lines are mean values,
while shadows are error regions. Upper: DTLZ1, DTLZ2, DTLZ3, DTLZ4. Lower: DTLZ5,
DTLZ6, DTLZ7. MOEA/D-FSs and comparison algorithms initialize their surrogates with 10, 60
samples, respectively. Extra 30 evaluations are allowed in the further optimization. Note that ‘FS(out)’
indicates the target task is excluded from the range of related tasks during the meta-learning procedure.
X-axis denotes the number of evaluations used after the surrogate initialization. In comparison to
MOEA/D-EGO, both MOEA/D-FSs achieve smaller or competitive IGD+ values on all DTLZ test
problems except for DTLZ7, while 50 evaluations are saved with the assistance from related tasks.
Moreover, MOEA/D-FSs achieve the smallest IGD+ values on DTLZ2, DTLZ3, DTLZ4, DTLZ5
and DTLZ6."
REFERENCES,0.6904962153069807,"algorithms is set to 150, 90, respectively. This answers the question we raised before: The advantage
762"
REFERENCES,0.6913372582001682,"of our FSEO framework is more prominent in the extremely expensive problems where a smaller
763"
REFERENCES,0.6921783010933558,"evaluation budget is allowed. The comparison between the results obtained from Tables 5 and 11 has
764"
REFERENCES,0.6930193439865433,"demonstrated that our FSEO framework is preferable when solving optimization problems within a
765"
REFERENCES,0.6938603868797308,"very limited evaluation budget.
766"
REFERENCES,0.6947014297729184,"H.2
Out-Of-Range Analysis on Extremely Expensive Optimization
767"
REFERENCES,0.695542472666106,"In Section F of the main ﬁle, we carried out an experiment to study the inﬂuence of task similarity
768"
REFERENCES,0.6963835155592936,"on the performance of experience-based expensive multi-objective optimization. The optimization
769"
REFERENCES,0.6972245584524811,"results obtained from the ‘in-range’ and the ‘out-of-range’ situations are compared. In this subsection,
770"
REFERENCES,0.6980656013456686,"we conduct an experiment to investigate the difference between the ‘in-range’ and the ‘out-of-range’
771"
REFERENCES,0.6989066442388562,"situations for extremely expensive multi-objective optimization. The experimental setups are the
772"
REFERENCES,0.6997476871320437,"same as the setups described in Section F of the main ﬁle, except the allowed ﬁtness evaluation budget
773"
REFERENCES,0.7005887300252313,"is the same as described in Appendix H.1.
774"
REFERENCES,0.7014297729184188,"Table 12 gives the statistical test results, it can be seen that the ‘out-of-range’ situation achieves
775"
REFERENCES,0.7022708158116064,"competitive IGD+ values to the ‘in-range’ situation on all 7 test instances. In comparison to MOEA/D-
776"
REFERENCES,0.703111858704794,"EGO, the experience gained in the ‘out-of-range’ situation leads to competitive or smaller IGD+
777"
REFERENCES,0.7039529015979815,"values on 6 DTLZ problems. Furthermore, similar results can be observed in the last row of Table 12,
778"
REFERENCES,0.704793944491169,"the ‘out-of-range’ situation achieves better/competitive/worse IGD+ values than all compared SAEAs
779"
REFERENCES,0.7056349873843566,"on 28/9/5 test instances. In comparison, the ‘in-range’ situation achieves better/competitive/worse
780"
REFERENCES,0.7064760302775441,"IGD+ values than all compared SAEAs on 29/8/5 test instances. There is only a minor difference
781"
REFERENCES,0.7073170731707317,"between the optimization results obtained in two situations. These observations are consistent with
782"
REFERENCES,0.7081581160639192,"the conclusions we made in Section F of the main ﬁle.
783"
REFERENCES,0.7089991589571069,"Table 12: Mean IGD+ values and standard deviation (in parentheses) obtained from 30 runs on
DTLZ problems. ‘Out-of-range’ indicates the target task is excluded from the range of related tasks
during the meta-learning procedure. Both MOEA/D-FSs initialize their surrogates with 10 samples,
extra 30 evaluations are allowed in the further optimization. ‘+’, ‘≈’, and ‘−’ denote the result
of the ‘out-of-range’ situation is statistically signiﬁcantly superior to, almost equivalent to, and
inferior to that of the ‘in-range’ situation in the Wilcoxon rank sum test (signiﬁcance level is 0.05),
respectively. The last two rows count the statistical test results between MOEA/D-FSs and other
compared algorithms."
REFERENCES,0.7098402018502944,"MOEA/D-FSs
In-range
Out-of-range
DTLZ1
1.03e+2(2.34e+1)≈
9.84e+1(2.04e+1)
DTLZ2
1.57e-1(2.29e-2)≈
1.62e-1(1.90e-2)
DTLZ3
2.03e+2(2.42e+1)≈
2.06e+2(2.13e+1)
DTLZ4
4.91e-1(1.24e-1)≈
5.20e-1(6.92e-2)
DTLZ5
1.18e-1(2.25e-2)+
1.11e-1(2.41e-2)
DTLZ6
1.29e+0(6.44e-1)≈
1.36e+0(7.36e-1)
DTLZ7
4.16e+0(2.54e+0)≈
4.94e+0(2.31e+0)
+/ ≈/−
0/7/0
-/-/-
vs MOEA/D-EGO
4/2/1
4/2/1
vs 6 Comparisons
29/8/5
28/9/5"
REFERENCES,0.7106812447434819,"H.3
Result Tables and Figures in IGD and HV Metrics
784"
REFERENCES,0.7115222876366695,"Results in IGD values are reported in Table 13 and Fig. 8. A smaller IGD value indicates a better
785"
REFERENCES,0.712363330529857,optimization result.
REFERENCES,0.7132043734230445,"Table 13: Mean IGD values and standard deviation (in parentheses) obtained from 30 runs on 7
DTLZ problems. MOEA/D-FS and comparison algorithms initialize their surrogates with 10, 60
samples, respectively. Extra 30 evaluations are allowed in the further optimization. ‘+’, ‘≈’, and ‘−’
denote MOEA/D-FS is statistically signiﬁcantly superior to, almost equivalent to, and inferior to the
compared algorithms in the Wilcoxon rank sum test (signiﬁcance level is 0.05), respectively. The last
row counts the total win/tie/loss results."
REFERENCES,0.7140454163162321,"Problems
MOEAD-EGO
MOEAD-FS
ParEGO
K-RVEA
KTA2
CSEA
OREA
ESBCEO
KMOEATIC
DTLZ1
1.07e+2(2.73e+1)≈
1.03e+2(2.34e+1)
8.70e+1(2.53e+1)−
1.22e+2(3.20e+1)+
1.15e+2(3.03e+1)≈
1.08e+2(2.64e+1)≈
1.11e+2(2.25e+1)+
1.00e+2(2.07e+1)≈
1.20e+2(2.71e+1)+
DTLZ2
3.69e-1(5.72e-2)+
1.91e-1(2.19e-2)
3.95e-1(3.35e-2)+
3.96e-1(3.55e-2)+
3.80e-1(4.24e-2)+
3.84e-1(4.05e-2)+
3.38e-1(3.44e-2)+
4.05e-1(3.07e-2)+
4.07e-1(3.85e-2)+
DTLZ3
3.07e+2(5.32e+1)+
2.03e+2(2.42e+1)
2.16e+2(4.89e+1)≈
3.53e+2(7.76e+1)+
3.23e+2(8.67e+1)+
3.35e+2(6.83e+1)+
3.39e+2(7.72e+1)+
2.41e+2(5.51e+1)+
3.27e+2(8.10e+1)+
DTLZ4
8.36e-1(1.51e-1)≈
8.47e-1(1.87e-1)
9.14e-1(1.22e-1)≈
7.28e-1(1.16e-1)−
7.93e-1(1.49e-1)≈
8.41e-1(1.48e-1)≈
7.89e-1(1.67e-1)≈
7.68e-1(1.21e-1)−
5.97e-1(1.23e-1)−
DTLZ5
2.88e-1(5.64e-2)+
1.22e-1(2.10e-2)
3.10e-1(4.36e-2)+
2.99e-1(5.02e-2)+
2.73e-1(5.06e-2)+
2.97e-1(3.77e-2)+
2.12e-1(4.27e-2)+
3.10e-1(4.29e-2)+
2.93e-1(5.32e-2)+
DTLZ6
2.08e+0(7.16e-1)+
1.36e+0(6.03e-1)
2.54e+0(7.09e-1)+
5.24e+0(6.15e-1)+
4.58e+0(6.36e-1)+
6.45e+0(3.51e-1)+
5.79e+0(6.67e-1)+
3.10e+0(8.82e-1)+
3.57e+0(6.85e-1)+
DTLZ7
2.02e+0(8.97e-1)−
4.22e+0(2.52e+0)
1.53e+0(1.42e+0)−
4.03e-1(7.19e-2)−
2.12e+0(2.13e+0)−
5.49e+0(1.31e+0)+
5.53e+0(1.32e+0)+
1.02e+0(5.29e-1)−
3.59e-1(1.49e-1)−
+/ ≈/−
4/2/1
-/-/-
3/2/2
5/0/2
4/2/1
5/2/0
6/1/0
4/1/2
5/0/2 786"
REFERENCES,0.7148864592094197,"Results in HV values are reported in Table 14 and Fig. 9. A larger HV value indicates a better
787"
REFERENCES,0.7157275021026073,optimization result.
REFERENCES,0.7165685449957948,"Table 14: Mean HV values and standard deviation (in parentheses) obtained from 30 runs on 7
DTLZ problems. MOEA/D-FS and comparison algorithms initialize their surrogates with 10, 60
samples, respectively. Extra 30 evaluations are allowed in the further optimization. ‘+’, ‘≈’, and ‘−’
denote MOEA/D-FS is statistically signiﬁcantly superior to, almost equivalent to, and inferior to the
compared algorithms in the Wilcoxon rank sum test (signiﬁcance level is 0.05), respectively. The last
row counts the total win/tie/loss results."
REFERENCES,0.7174095878889823,"Problems
MOEAD-EGO
MOEAD-FS
ParEGO
K-RVEA
KTA2
CSEA
OREA
ESBCEO
KMOEATIC
DTLZ1
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
DTLZ2
1.63e-1(8.93e-2)+
4.37e-1(3.48e-2)
9.85e-2(3.44e-2)+
1.05e-1(4.43e-2)+
1.25e-1(4.84e-2)+
1.17e-1(5.59e-2)+
1.73e-1(4.75e-2)+
1.25e-1(5.19e-2)+
9.43e-2(4.62e-2)+
DTLZ3
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
DTLZ4
6.44e-2(6.93e-2)≈
1.00e-1(6.58e-2)
8.65e-3(1.74e-2)+
2.28e-2(4.11e-2)+
2.18e-2(3.52e-2)+
1.01e-2(2.38e-2)+
5.58e-2(6.13e-2)+
1.55e-2(2.64e-2)+
4.77e-2(5.93e-2)+
DTLZ5
2.62e-2(2.46e-2)+
1.60e-1(1.54e-2)
7.89e-3(1.16e-2)+
1.51e-2(1.58e-2)+
2.60e-2(1.91e-2)+
1.08e-2(1.14e-2)+
4.57e-2(2.76e-2)+
1.43e-2(1.32e-2)+
2.04e-2(2.38e-2)+
DTLZ6
3.82e-4(2.06e-3)≈
1.07e-2(2.64e-2)
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
8.07e-3(3.02e-2)≈
0.00e+0(0.00e+0)≈
DTLZ7
6.98e-2(1.00e-1)≈
4.14e-2(8.25e-2)
8.22e-2(8.32e-2)−
2.65e-1(3.94e-2)−
1.31e-1(1.20e-1)−
0.00e+0(0.00e+0)≈
0.00e+0(0.00e+0)≈
8.06e-2(8.74e-2)−
3.58e-1(4.00e-2)−
+/ ≈/−
2/5/0
-/-/-
3/3/1
3/3/1
3/3/1
3/4/0
3/4/0
3/3/1
3/3/1 788"
REFERENCES,0.7182506307821699,"I
Summary of Experiments
789"
REFERENCES,0.7190916736753574,"Our computational studies have demonstrated the following: First, we provide empirical evidence to
790"
REFERENCES,0.719932716568545,"show the effectiveness of learning experience: The meta-learning of neural network parameters and
791"
REFERENCES,0.7207737594617325,"Figure 8: IGD curves averaged over 30 runs on 7 DTLZ problems. Solid lines are mean values,
while shadows are error regions. Upper: DTLZ1, DTLZ2, DTLZ3, DTLZ4. Lower: DTLZ5,
DTLZ6, DTLZ7. MOEA/D-FSs and comparison algorithms initialize their surrogates with 10, 60
samples, respectively. Extra 30 evaluations are allowed in the further optimization. Note that ‘FS(out)’
indicates the target task is excluded from the range of related tasks during the meta-learning procedure.
X-axis denotes the number of evaluations used after the surrogate initialization."
REFERENCES,0.7216148023549201,"Figure 9: HV curves averaged over 30 runs on 7 DTLZ problems. Solid lines are mean values,
while shadows are error regions. Upper: DTLZ1, DTLZ2, DTLZ3, DTLZ4. Lower: DTLZ5,
DTLZ6, DTLZ7. MOEA/D-FSs and comparison algorithms initialize their surrogates with 10, 60
samples, respectively. Extra 30 evaluations are allowed in the further optimization. Note that ‘FS(out)’
indicates the target task is excluded from the range of related tasks during the meta-learning procedure.
X-axis denotes the number of evaluations used after the surrogate initialization."
REFERENCES,0.7224558452481077,"base kernel parameters are essential to the modeling accuracy of a MDKL model. As a result, our
792"
REFERENCES,0.7232968881412952,"MDKL model outperforms the compared meta-learning modeling and non-meta-learning modeling
793"
REFERENCES,0.7241379310344828,"methods on both the engine fuel consumption regression task and the sinusoid function regression
794"
REFERENCES,0.7249789739276703,"task.
795"
REFERENCES,0.7258200168208578,"Second, we demonstrate the main contribution of this work: In most situations, the proposed FSEO
796"
REFERENCES,0.7266610597140454,"framework can assist regression-based SAEAs to reach competitive or even better optimization
797"
REFERENCES,0.7275021026072329,"results, while the cost of surrogate initialization is only 1d samples. Due to the effectiveness of
798"
REFERENCES,0.7283431455004206,"saving evaluations, our FSEO framework is preferable to other SAEAs when solving problems within
799"
REFERENCES,0.7291841883936081,"a very limited evaluation budget. Moreover, some empirical guidelines are concluded to help the
800"
REFERENCES,0.7300252312867956,"application of our FSEO framework. For the inﬂuence of task similarity, we ﬁnd that related tasks that
801"
REFERENCES,0.7308662741799832,"are very similar to the target task are not necessary to the application of our approach. The inﬂuence
802"
REFERENCES,0.7317073170731707,"of these similar tasks on the optimization performance is limited. Our FSEO framework can achieve
803"
REFERENCES,0.7325483599663583,"competitive results without datasets from very similar related tasks. Besides, for the related tasks
804"
REFERENCES,0.7333894028595458,"used for meta-learning, we have demonstrated that more useful experience can be learned if more
805"
REFERENCES,0.7342304457527334,"data points are sampled from related tasks.
806"
REFERENCES,0.735071488645921,"Third, the effectiveness of our FSEO framework is validated on a real-world engine calibration
807"
REFERENCES,0.7359125315391085,"problem. Competitive or better results are achieved on the objective and constraint functions, while
808"
REFERENCES,0.736753574432296,"1d samples are used to initialize surrogates. Therefore, our FSEO framework can also be applied to
809"
REFERENCES,0.7375946173254836,"optimization scenarios such as single-objective optimization and constrained optimization.
810"
REFERENCES,0.7384356602186711,"NeurIPS Paper Checklist
811"
CLAIMS,0.7392767031118587,"1. Claims
812"
CLAIMS,0.7401177460050462,"Question: Do the main claims made in the abstract and introduction accurately reﬂect the
813"
CLAIMS,0.7409587888982339,"paper’s contributions and scope?
814"
CLAIMS,0.7417998317914214,"Answer: [Yes]
815"
CLAIMS,0.7426408746846089,"Justiﬁcation: Claims we made accurately reﬂect the paper’s contributions and scope.
816"
CLAIMS,0.7434819175777965,"Guidelines:
817"
CLAIMS,0.744322960470984,"• The answer NA means that the abstract and introduction do not include the claims
818"
CLAIMS,0.7451640033641715,"made in the paper.
819"
CLAIMS,0.7460050462573591,"• The abstract and/or introduction should clearly state the claims made, including the
820"
CLAIMS,0.7468460891505467,"contributions made in the paper and important assumptions and limitations. A No or
821"
CLAIMS,0.7476871320437343,"NA answer to this question will not be perceived well by the reviewers.
822"
CLAIMS,0.7485281749369218,"• The claims made should match theoretical and experimental results, and reﬂect how
823"
CLAIMS,0.7493692178301093,"much the results can be expected to generalize to other settings.
824"
CLAIMS,0.7502102607232969,"• It is ﬁne to include aspirational goals as motivation as long as it is clear that these goals
825"
CLAIMS,0.7510513036164844,"are not attained by the paper.
826"
LIMITATIONS,0.751892346509672,"2. Limitations
827"
LIMITATIONS,0.7527333894028595,"Question: Does the paper discuss the limitations of the work performed by the authors?
828"
LIMITATIONS,0.7535744322960471,"Answer: [Yes]
829"
LIMITATIONS,0.7544154751892347,"Justiﬁcation: See Appendix B.
830"
LIMITATIONS,0.7552565180824222,"Guidelines:
831"
LIMITATIONS,0.7560975609756098,"• The answer NA means that the paper has no limitation while the answer No means that
832"
LIMITATIONS,0.7569386038687973,"the paper has limitations, but those are not discussed in the paper.
833"
LIMITATIONS,0.7577796467619848,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
834"
LIMITATIONS,0.7586206896551724,"• The paper should point out any strong assumptions and how robust the results are to
835"
LIMITATIONS,0.7594617325483599,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
836"
LIMITATIONS,0.7603027754415476,"model well-speciﬁcation, asymptotic approximations only holding locally). The authors
837"
LIMITATIONS,0.7611438183347351,"should reﬂect on how these assumptions might be violated in practice and what the
838"
LIMITATIONS,0.7619848612279226,"implications would be.
839"
LIMITATIONS,0.7628259041211102,"• The authors should reﬂect on the scope of the claims made, e.g., if the approach was
840"
LIMITATIONS,0.7636669470142977,"only tested on a few datasets or with a few runs. In general, empirical results often
841"
LIMITATIONS,0.7645079899074853,"depend on implicit assumptions, which should be articulated.
842"
LIMITATIONS,0.7653490328006728,"• The authors should reﬂect on the factors that inﬂuence the performance of the approach.
843"
LIMITATIONS,0.7661900756938604,"For example, a facial recognition algorithm may perform poorly when image resolution
844"
LIMITATIONS,0.767031118587048,"is low or images are taken in low lighting. Or a speech-to-text system might not be
845"
LIMITATIONS,0.7678721614802355,"used reliably to provide closed captions for online lectures because it fails to handle
846"
LIMITATIONS,0.768713204373423,"technical jargon.
847"
LIMITATIONS,0.7695542472666106,"• The authors should discuss the computational efﬁciency of the proposed algorithms
848"
LIMITATIONS,0.7703952901597981,"and how they scale with dataset size.
849"
LIMITATIONS,0.7712363330529857,"• If applicable, the authors should discuss possible limitations of their approach to
850"
LIMITATIONS,0.7720773759461732,"address problems of privacy and fairness.
851"
LIMITATIONS,0.7729184188393609,"• While the authors might fear that complete honesty about limitations might be used by
852"
LIMITATIONS,0.7737594617325484,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
853"
LIMITATIONS,0.7746005046257359,"limitations that aren’t acknowledged in the paper. The authors should use their best
854"
LIMITATIONS,0.7754415475189235,"judgment and recognize that individual actions in favor of transparency play an impor-
855"
LIMITATIONS,0.776282590412111,"tant role in developing norms that preserve the integrity of the community. Reviewers
856"
LIMITATIONS,0.7771236333052985,"will be speciﬁcally instructed to not penalize honesty concerning limitations.
857"
THEORY ASSUMPTIONS AND PROOFS,0.7779646761984861,"3. Theory Assumptions and Proofs
858"
THEORY ASSUMPTIONS AND PROOFS,0.7788057190916736,"Question: For each theoretical result, does the paper provide the full set of assumptions and
859"
THEORY ASSUMPTIONS AND PROOFS,0.7796467619848613,"a complete (and correct) proof?
860"
THEORY ASSUMPTIONS AND PROOFS,0.7804878048780488,"Answer: [NA]
861"
THEORY ASSUMPTIONS AND PROOFS,0.7813288477712363,"Justiﬁcation: Not applicable.
862"
THEORY ASSUMPTIONS AND PROOFS,0.7821698906644239,"Guidelines:
863"
THEORY ASSUMPTIONS AND PROOFS,0.7830109335576114,"• The answer NA means that the paper does not include theoretical results.
864"
THEORY ASSUMPTIONS AND PROOFS,0.783851976450799,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
865"
THEORY ASSUMPTIONS AND PROOFS,0.7846930193439865,"referenced.
866"
THEORY ASSUMPTIONS AND PROOFS,0.7855340622371741,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
867"
THEORY ASSUMPTIONS AND PROOFS,0.7863751051303617,"• The proofs can either appear in the main paper or the supplemental material, but if
868"
THEORY ASSUMPTIONS AND PROOFS,0.7872161480235492,"they appear in the supplemental material, the authors are encouraged to provide a short
869"
THEORY ASSUMPTIONS AND PROOFS,0.7880571909167368,"proof sketch to provide intuition.
870"
THEORY ASSUMPTIONS AND PROOFS,0.7888982338099243,"• Inversely, any informal proof provided in the core of the paper should be complemented
871"
THEORY ASSUMPTIONS AND PROOFS,0.7897392767031118,"by formal proofs provided in appendix or supplemental material.
872"
THEORY ASSUMPTIONS AND PROOFS,0.7905803195962994,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
873"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7914213624894869,"4. Experimental Result Reproducibility
874"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7922624053826746,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
875"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7931034482758621,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
876"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7939444911690496,"of the paper (regardless of whether the code and data are provided or not)?
877"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7947855340622372,"Answer: [Yes]
878"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7956265769554247,"Justiﬁcation: Experimental setups are described in detail.
879"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7964676198486123,"Guidelines:
880"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7973086627417998,"• The answer NA means that the paper does not include experiments.
881"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7981497056349874,"• If the paper includes experiments, a No answer to this question will not be perceived
882"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.798990748528175,"well by the reviewers: Making the paper reproducible is important, regardless of
883"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7998317914213625,"whether the code and data are provided or not.
884"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.80067283431455,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
885"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8015138772077376,"to make their results reproducible or veriﬁable.
886"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8023549201009251,"• Depending on the contribution, reproducibility can be accomplished in various ways.
887"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8031959629941127,"For example, if the contribution is a novel architecture, describing the architecture fully
888"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8040370058873002,"might sufﬁce, or if the contribution is a speciﬁc model and empirical evaluation, it may
889"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8048780487804879,"be necessary to either make it possible for others to replicate the model with the same
890"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8057190916736754,"dataset, or provide access to the model. In general. releasing code and data is often
891"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8065601345668629,"one good way to accomplish this, but reproducibility can also be provided via detailed
892"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8074011774600505,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
893"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.808242220353238,"of a large language model), releasing of a model checkpoint, or other means that are
894"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8090832632464255,"appropriate to the research performed.
895"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8099243061396131,"• While NeurIPS does not require releasing code, the conference does require all submis-
896"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8107653490328006,"sions to provide some reasonable avenue for reproducibility, which may depend on the
897"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8116063919259883,"nature of the contribution. For example
898"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8124474348191758,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
899"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8132884777123633,"to reproduce that algorithm.
900"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8141295206055509,"(b) If the contribution is primarily a new model architecture, the paper should describe
901"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8149705634987384,"the architecture clearly and fully.
902"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.815811606391926,"(c) If the contribution is a new model (e.g., a large language model), then there should
903"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8166526492851135,"either be a way to access this model for reproducing the results or a way to reproduce
904"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8174936921783011,"the model (e.g., with an open-source dataset or instructions for how to construct
905"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8183347350714887,"the dataset).
906"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8191757779646762,"(d) We recognize that reproducibility may be tricky in some cases, in which case
907"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8200168208578638,"authors are welcome to describe the particular way they provide for reproducibility.
908"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8208578637510513,"In the case of closed-source models, it may be that access to the model is limited in
909"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8216989066442388,"some way (e.g., to registered users), but it should be possible for other researchers
910"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8225399495374264,"to have some path to reproducing or verifying the results.
911"
OPEN ACCESS TO DATA AND CODE,0.8233809924306139,"5. Open access to data and code
912"
OPEN ACCESS TO DATA AND CODE,0.8242220353238016,"Question: Does the paper provide open access to the data and code, with sufﬁcient instruc-
913"
OPEN ACCESS TO DATA AND CODE,0.8250630782169891,"tions to faithfully reproduce the main experimental results, as described in supplemental
914"
OPEN ACCESS TO DATA AND CODE,0.8259041211101766,"material?
915"
OPEN ACCESS TO DATA AND CODE,0.8267451640033642,"Answer: [No]
916"
OPEN ACCESS TO DATA AND CODE,0.8275862068965517,"Justiﬁcation: Will release our code after acceptation, or we can provide the code if any
917"
OPEN ACCESS TO DATA AND CODE,0.8284272497897393,"reviewers are interested in it during the review process. Anyway, the details about the code
918"
OPEN ACCESS TO DATA AND CODE,0.8292682926829268,"have already described in the paper.
919"
OPEN ACCESS TO DATA AND CODE,0.8301093355761143,"Guidelines:
920"
OPEN ACCESS TO DATA AND CODE,0.830950378469302,"• The answer NA means that paper does not include experiments requiring code.
921"
OPEN ACCESS TO DATA AND CODE,0.8317914213624895,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
922"
OPEN ACCESS TO DATA AND CODE,0.832632464255677,"public/guides/CodeSubmissionPolicy) for more details.
923"
OPEN ACCESS TO DATA AND CODE,0.8334735071488646,"• While we encourage the release of code and data, we understand that this might not be
924"
OPEN ACCESS TO DATA AND CODE,0.8343145500420521,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
925"
OPEN ACCESS TO DATA AND CODE,0.8351555929352397,"including code, unless this is central to the contribution (e.g., for a new open-source
926"
OPEN ACCESS TO DATA AND CODE,0.8359966358284272,"benchmark).
927"
OPEN ACCESS TO DATA AND CODE,0.8368376787216149,"• The instructions should contain the exact command and environment needed to run to
928"
OPEN ACCESS TO DATA AND CODE,0.8376787216148024,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
929"
OPEN ACCESS TO DATA AND CODE,0.8385197645079899,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
930"
OPEN ACCESS TO DATA AND CODE,0.8393608074011775,"• The authors should provide instructions on data access and preparation, including how
931"
OPEN ACCESS TO DATA AND CODE,0.840201850294365,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
932"
OPEN ACCESS TO DATA AND CODE,0.8410428931875525,"• The authors should provide scripts to reproduce all experimental results for the new
933"
OPEN ACCESS TO DATA AND CODE,0.8418839360807401,"proposed method and baselines. If only a subset of experiments are reproducible, they
934"
OPEN ACCESS TO DATA AND CODE,0.8427249789739276,"should state which ones are omitted from the script and why.
935"
OPEN ACCESS TO DATA AND CODE,0.8435660218671153,"• At submission time, to preserve anonymity, the authors should release anonymized
936"
OPEN ACCESS TO DATA AND CODE,0.8444070647603028,"versions (if applicable).
937"
OPEN ACCESS TO DATA AND CODE,0.8452481076534903,"• Providing as much information as possible in supplemental material (appended to the
938"
OPEN ACCESS TO DATA AND CODE,0.8460891505466779,"paper) is recommended, but including URLs to data and code is permitted.
939"
OPEN ACCESS TO DATA AND CODE,0.8469301934398654,"6. Experimental Setting/Details
940"
OPEN ACCESS TO DATA AND CODE,0.847771236333053,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
941"
OPEN ACCESS TO DATA AND CODE,0.8486122792262405,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
942"
OPEN ACCESS TO DATA AND CODE,0.8494533221194281,"results?
943"
OPEN ACCESS TO DATA AND CODE,0.8502943650126157,"Answer: [Yes]
944"
OPEN ACCESS TO DATA AND CODE,0.8511354079058032,"Justiﬁcation: We have described all the details about of experiments.
945"
OPEN ACCESS TO DATA AND CODE,0.8519764507989908,"Guidelines:
946"
OPEN ACCESS TO DATA AND CODE,0.8528174936921783,"• The answer NA means that the paper does not include experiments.
947"
OPEN ACCESS TO DATA AND CODE,0.8536585365853658,"• The experimental setting should be presented in the core of the paper to a level of detail
948"
OPEN ACCESS TO DATA AND CODE,0.8544995794785534,"that is necessary to appreciate the results and make sense of them.
949"
OPEN ACCESS TO DATA AND CODE,0.8553406223717409,"• The full details can be provided either with the code, in appendix, or as supplemental
950"
OPEN ACCESS TO DATA AND CODE,0.8561816652649286,"material.
951"
OPEN ACCESS TO DATA AND CODE,0.8570227081581161,"7. Experiment Statistical Signiﬁcance
952"
OPEN ACCESS TO DATA AND CODE,0.8578637510513036,"Question: Does the paper report error bars suitably and correctly deﬁned or other appropriate
953"
OPEN ACCESS TO DATA AND CODE,0.8587047939444912,"information about the statistical signiﬁcance of the experiments?
954"
OPEN ACCESS TO DATA AND CODE,0.8595458368376787,"Answer: [Yes]
955"
OPEN ACCESS TO DATA AND CODE,0.8603868797308662,"Justiﬁcation: We have conducted statistical tests in our experiments, error bars are plotted in
956"
OPEN ACCESS TO DATA AND CODE,0.8612279226240538,"ﬁgures.
957"
OPEN ACCESS TO DATA AND CODE,0.8620689655172413,"Guidelines:
958"
OPEN ACCESS TO DATA AND CODE,0.862910008410429,"• The answer NA means that the paper does not include experiments.
959"
OPEN ACCESS TO DATA AND CODE,0.8637510513036165,"• The authors should answer ""Yes"" if the results are accompanied by error bars, conﬁ-
960"
OPEN ACCESS TO DATA AND CODE,0.864592094196804,"dence intervals, or statistical signiﬁcance tests, at least for the experiments that support
961"
OPEN ACCESS TO DATA AND CODE,0.8654331370899916,"the main claims of the paper.
962"
OPEN ACCESS TO DATA AND CODE,0.8662741799831791,"• The factors of variability that the error bars are capturing should be clearly stated (for
963"
OPEN ACCESS TO DATA AND CODE,0.8671152228763667,"example, train/test split, initialization, random drawing of some parameter, or overall
964"
OPEN ACCESS TO DATA AND CODE,0.8679562657695542,"run with given experimental conditions).
965"
OPEN ACCESS TO DATA AND CODE,0.8687973086627419,"• The method for calculating the error bars should be explained (closed form formula,
966"
OPEN ACCESS TO DATA AND CODE,0.8696383515559294,"call to a library function, bootstrap, etc.)
967"
OPEN ACCESS TO DATA AND CODE,0.8704793944491169,"• The assumptions made should be given (e.g., Normally distributed errors).
968"
OPEN ACCESS TO DATA AND CODE,0.8713204373423045,"• It should be clear whether the error bar is the standard deviation or the standard error
969"
OPEN ACCESS TO DATA AND CODE,0.872161480235492,"of the mean.
970"
OPEN ACCESS TO DATA AND CODE,0.8730025231286795,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
971"
OPEN ACCESS TO DATA AND CODE,0.8738435660218671,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
972"
OPEN ACCESS TO DATA AND CODE,0.8746846089150546,"of Normality of errors is not veriﬁed.
973"
OPEN ACCESS TO DATA AND CODE,0.8755256518082423,"• For asymmetric distributions, the authors should be careful not to show in tables or
974"
OPEN ACCESS TO DATA AND CODE,0.8763666947014298,"ﬁgures symmetric error bars that would yield results that are out of range (e.g. negative
975"
OPEN ACCESS TO DATA AND CODE,0.8772077375946173,"error rates).
976"
OPEN ACCESS TO DATA AND CODE,0.8780487804878049,"• If error bars are reported in tables or plots, The authors should explain in the text how
977"
OPEN ACCESS TO DATA AND CODE,0.8788898233809924,"they were calculated and reference the corresponding ﬁgures or tables in the text.
978"
EXPERIMENTS COMPUTE RESOURCES,0.87973086627418,"8. Experiments Compute Resources
979"
EXPERIMENTS COMPUTE RESOURCES,0.8805719091673675,"Question: For each experiment, does the paper provide sufﬁcient information on the com-
980"
EXPERIMENTS COMPUTE RESOURCES,0.8814129520605551,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
981"
EXPERIMENTS COMPUTE RESOURCES,0.8822539949537427,"the experiments?
982"
EXPERIMENTS COMPUTE RESOURCES,0.8830950378469302,"Answer: [No]
983"
EXPERIMENTS COMPUTE RESOURCES,0.8839360807401178,"Justiﬁcation: We did not provide information about compute workers and memory since our
984"
EXPERIMENTS COMPUTE RESOURCES,0.8847771236333053,"experiments do not have speciﬁc requirements on memory or other computation resource.
985"
EXPERIMENTS COMPUTE RESOURCES,0.8856181665264928,"Guidelines:
986"
EXPERIMENTS COMPUTE RESOURCES,0.8864592094196804,"• The answer NA means that the paper does not include experiments.
987"
EXPERIMENTS COMPUTE RESOURCES,0.8873002523128679,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
988"
EXPERIMENTS COMPUTE RESOURCES,0.8881412952060556,"or cloud provider, including relevant memory and storage.
989"
EXPERIMENTS COMPUTE RESOURCES,0.8889823380992431,"• The paper should provide the amount of compute required for each of the individual
990"
EXPERIMENTS COMPUTE RESOURCES,0.8898233809924306,"experimental runs as well as estimate the total compute.
991"
EXPERIMENTS COMPUTE RESOURCES,0.8906644238856182,"• The paper should disclose whether the full research project required more compute
992"
EXPERIMENTS COMPUTE RESOURCES,0.8915054667788057,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
993"
EXPERIMENTS COMPUTE RESOURCES,0.8923465096719932,"didn’t make it into the paper).
994"
CODE OF ETHICS,0.8931875525651808,"9. Code Of Ethics
995"
CODE OF ETHICS,0.8940285954583683,"Question: Does the research conducted in the paper conform, in every respect, with the
996"
CODE OF ETHICS,0.894869638351556,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
997"
CODE OF ETHICS,0.8957106812447435,"Answer: [NA]
998"
CODE OF ETHICS,0.896551724137931,"Justiﬁcation: Not applicable.
999"
CODE OF ETHICS,0.8973927670311186,"Guidelines:
1000"
CODE OF ETHICS,0.8982338099243061,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
1001"
CODE OF ETHICS,0.8990748528174937,"• If the authors answer No, they should explain the special circumstances that require a
1002"
CODE OF ETHICS,0.8999158957106812,"deviation from the Code of Ethics.
1003"
CODE OF ETHICS,0.9007569386038689,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
1004"
CODE OF ETHICS,0.9015979814970564,"eration due to laws or regulations in their jurisdiction).
1005"
BROADER IMPACTS,0.9024390243902439,"10. Broader Impacts
1006"
BROADER IMPACTS,0.9032800672834315,"Question: Does the paper discuss both potential positive societal impacts and negative
1007"
BROADER IMPACTS,0.904121110176619,"societal impacts of the work performed?
1008"
BROADER IMPACTS,0.9049621530698065,"Answer: [No]
1009"
BROADER IMPACTS,0.9058031959629941,"Justiﬁcation: We do not think optimization algorithm can cause any negative social impacts.
1010"
BROADER IMPACTS,0.9066442388561816,"Guidelines:
1011"
BROADER IMPACTS,0.9074852817493693,"• The answer NA means that there is no societal impact of the work performed.
1012"
BROADER IMPACTS,0.9083263246425568,"• If the authors answer NA or No, they should explain why their work has no societal
1013"
BROADER IMPACTS,0.9091673675357443,"impact or why the paper does not address societal impact.
1014"
BROADER IMPACTS,0.9100084104289319,"• Examples of negative societal impacts include potential malicious or unintended uses
1015"
BROADER IMPACTS,0.9108494533221194,"(e.g., disinformation, generating fake proﬁles, surveillance), fairness considerations
1016"
BROADER IMPACTS,0.911690496215307,"(e.g., deployment of technologies that could make decisions that unfairly impact speciﬁc
1017"
BROADER IMPACTS,0.9125315391084945,"groups), privacy considerations, and security considerations.
1018"
BROADER IMPACTS,0.913372582001682,"• The conference expects that many papers will be foundational research and not tied
1019"
BROADER IMPACTS,0.9142136248948697,"to particular applications, let alone deployments. However, if there is a direct path to
1020"
BROADER IMPACTS,0.9150546677880572,"any negative applications, the authors should point it out. For example, it is legitimate
1021"
BROADER IMPACTS,0.9158957106812448,"to point out that an improvement in the quality of generative models could be used to
1022"
BROADER IMPACTS,0.9167367535744323,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
1023"
BROADER IMPACTS,0.9175777964676198,"that a generic algorithm for optimizing neural networks could enable people to train
1024"
BROADER IMPACTS,0.9184188393608074,"models that generate Deepfakes faster.
1025"
BROADER IMPACTS,0.9192598822539949,"• The authors should consider possible harms that could arise when the technology is
1026"
BROADER IMPACTS,0.9201009251471826,"being used as intended and functioning correctly, harms that could arise when the
1027"
BROADER IMPACTS,0.9209419680403701,"technology is being used as intended but gives incorrect results, and harms following
1028"
BROADER IMPACTS,0.9217830109335576,"from (intentional or unintentional) misuse of the technology.
1029"
BROADER IMPACTS,0.9226240538267452,"• If there are negative societal impacts, the authors could also discuss possible mitigation
1030"
BROADER IMPACTS,0.9234650967199327,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
1031"
BROADER IMPACTS,0.9243061396131202,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
1032"
BROADER IMPACTS,0.9251471825063078,"feedback over time, improving the efﬁciency and accessibility of ML).
1033"
SAFEGUARDS,0.9259882253994953,"11. Safeguards
1034"
SAFEGUARDS,0.926829268292683,"Question: Does the paper describe safeguards that have been put in place for responsible
1035"
SAFEGUARDS,0.9276703111858705,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
1036"
SAFEGUARDS,0.928511354079058,"image generators, or scraped datasets)?
1037"
SAFEGUARDS,0.9293523969722456,"Answer: [No]
1038"
SAFEGUARDS,0.9301934398654331,"Justiﬁcation: Code will be released after acceptation, it would be open access, no safeguards
1039"
SAFEGUARDS,0.9310344827586207,"are required.
1040"
SAFEGUARDS,0.9318755256518082,"Guidelines:
1041"
SAFEGUARDS,0.9327165685449958,"• The answer NA means that the paper poses no such risks.
1042"
SAFEGUARDS,0.9335576114381834,"• Released models that have a high risk for misuse or dual-use should be released with
1043"
SAFEGUARDS,0.9343986543313709,"necessary safeguards to allow for controlled use of the model, for example by requiring
1044"
SAFEGUARDS,0.9352396972245585,"that users adhere to usage guidelines or restrictions to access the model or implementing
1045"
SAFEGUARDS,0.936080740117746,"safety ﬁlters.
1046"
SAFEGUARDS,0.9369217830109335,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
1047"
SAFEGUARDS,0.9377628259041211,"should describe how they avoided releasing unsafe images.
1048"
SAFEGUARDS,0.9386038687973086,"• We recognize that providing effective safeguards is challenging, and many papers do
1049"
SAFEGUARDS,0.9394449116904963,"not require this, but we encourage authors to take this into account and make a best
1050"
SAFEGUARDS,0.9402859545836838,"faith effort.
1051"
LICENSES FOR EXISTING ASSETS,0.9411269974768713,"12. Licenses for existing assets
1052"
LICENSES FOR EXISTING ASSETS,0.9419680403700589,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
1053"
LICENSES FOR EXISTING ASSETS,0.9428090832632464,"the paper, properly credited and are the license and terms of use explicitly mentioned and
1054"
LICENSES FOR EXISTING ASSETS,0.943650126156434,"properly respected?
1055"
LICENSES FOR EXISTING ASSETS,0.9444911690496215,"Answer: [Yes]
1056"
LICENSES FOR EXISTING ASSETS,0.945332211942809,"Justiﬁcation: We cited the algorithm platform and the data we used in our paper.
1057"
LICENSES FOR EXISTING ASSETS,0.9461732548359967,"Guidelines:
1058"
LICENSES FOR EXISTING ASSETS,0.9470142977291842,"• The answer NA means that the paper does not use existing assets.
1059"
LICENSES FOR EXISTING ASSETS,0.9478553406223718,"• The authors should cite the original paper that produced the code package or dataset.
1060"
LICENSES FOR EXISTING ASSETS,0.9486963835155593,"• The authors should state which version of the asset is used and, if possible, include a
1061"
LICENSES FOR EXISTING ASSETS,0.9495374264087468,"URL.
1062"
LICENSES FOR EXISTING ASSETS,0.9503784693019344,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
1063"
LICENSES FOR EXISTING ASSETS,0.9512195121951219,"• For scraped data from a particular source (e.g., website), the copyright and terms of
1064"
LICENSES FOR EXISTING ASSETS,0.9520605550883096,"service of that source should be provided.
1065"
LICENSES FOR EXISTING ASSETS,0.9529015979814971,"• If assets are released, the license, copyright information, and terms of use in the
1066"
LICENSES FOR EXISTING ASSETS,0.9537426408746846,"package should be provided. For popular datasets, paperswithcode.com/datasets
1067"
LICENSES FOR EXISTING ASSETS,0.9545836837678722,"has curated licenses for some datasets. Their licensing guide can help determine the
1068"
LICENSES FOR EXISTING ASSETS,0.9554247266610597,"license of a dataset.
1069"
LICENSES FOR EXISTING ASSETS,0.9562657695542472,"• For existing datasets that are re-packaged, both the original license and the license of
1070"
LICENSES FOR EXISTING ASSETS,0.9571068124474348,"the derived asset (if it has changed) should be provided.
1071"
LICENSES FOR EXISTING ASSETS,0.9579478553406223,"• If this information is not available online, the authors are encouraged to reach out to
1072"
LICENSES FOR EXISTING ASSETS,0.95878889823381,"the asset’s creators.
1073"
NEW ASSETS,0.9596299411269975,"13. New Assets
1074"
NEW ASSETS,0.960470984020185,"Question: Are new assets introduced in the paper well documented and is the documentation
1075"
NEW ASSETS,0.9613120269133726,"provided alongside the assets?
1076"
NEW ASSETS,0.9621530698065601,"Answer: [NA]
1077"
NEW ASSETS,0.9629941126997477,"Justiﬁcation: We did not introduce any new assets.
1078"
NEW ASSETS,0.9638351555929352,"Guidelines:
1079"
NEW ASSETS,0.9646761984861227,"• The answer NA means that the paper does not release new assets.
1080"
NEW ASSETS,0.9655172413793104,"• Researchers should communicate the details of the dataset/code/model as part of their
1081"
NEW ASSETS,0.9663582842724979,"submissions via structured templates. This includes details about training, license,
1082"
NEW ASSETS,0.9671993271656855,"limitations, etc.
1083"
NEW ASSETS,0.968040370058873,"• The paper should discuss whether and how consent was obtained from people whose
1084"
NEW ASSETS,0.9688814129520605,"asset is used.
1085"
NEW ASSETS,0.9697224558452481,"• At submission time, remember to anonymize your assets (if applicable). You can either
1086"
NEW ASSETS,0.9705634987384356,"create an anonymized URL or include an anonymized zip ﬁle.
1087"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9714045416316233,"14. Crowdsourcing and Research with Human Subjects
1088"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9722455845248108,"Question: For crowdsourcing experiments and research with human subjects, does the paper
1089"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9730866274179983,"include the full text of instructions given to participants and screenshots, if applicable, as
1090"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9739276703111859,"well as details about compensation (if any)?
1091"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9747687132043734,"Answer: [NA]
1092"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.975609756097561,"Justiﬁcation: We do not have any experiments or research with human subjects.
1093"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9764507989907485,"Guidelines:
1094"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.977291841883936,"• The answer NA means that the paper does not involve crowdsourcing nor research with
1095"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9781328847771237,"human subjects.
1096"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9789739276703112,"• Including this information in the supplemental material is ﬁne, but if the main contribu-
1097"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9798149705634988,"tion of the paper involves human subjects, then as much detail as possible should be
1098"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9806560134566863,"included in the main paper.
1099"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9814970563498738,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
1100"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9823380992430614,"or other labor should be paid at least the minimum wage in the country of the data
1101"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9831791421362489,"collector.
1102"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9840201850294366,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
1103"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9848612279226241,"Subjects
1104"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9857022708158116,"Question: Does the paper describe potential risks incurred by study participants, whether
1105"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9865433137089992,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
1106"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9873843566021867,"approvals (or an equivalent approval/review based on the requirements of your country or
1107"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9882253994953742,"institution) were obtained?
1108"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9890664423885618,"Answer: [NA]
1109"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9899074852817493,"Justiﬁcation: We do not have any experiments or research with human subjects.
1110"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.990748528174937,"Guidelines:
1111"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9915895710681245,"• The answer NA means that the paper does not involve crowdsourcing nor research with
1112"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.992430613961312,"human subjects.
1113"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9932716568544996,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
1114"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9941126997476871,"may be required for any human subjects research. If you obtained IRB approval, you
1115"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9949537426408747,"should clearly state this in the paper.
1116"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9957947855340622,"• We recognize that the procedures for this may vary signiﬁcantly between institutions
1117"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9966358284272497,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
1118"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9974768713204374,"guidelines for their institution.
1119"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9983179142136249,"• For initial submissions, do not include any information that would break anonymity (if
1120"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9991589571068125,"applicable), such as the institution conducting the review.
1121"
