Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0008481764206955047,"Finding an optimal decision tree for a supervised learning task is a challenging
1"
ABSTRACT,0.0016963528413910093,"combinatorial problem to solve at scale. It was recently proposed to frame this
2"
ABSTRACT,0.002544529262086514,"problem as a Markov Decision Problem (MDP) and use deep reinforcement learn-
3"
ABSTRACT,0.0033927056827820186,"ing to tackle scaling. Unfortunately, these methods are not competitive with the
4"
ABSTRACT,0.004240882103477523,"current branch-and-bound state of the art. Instead, we propose to scale the res-
5"
ABSTRACT,0.005089058524173028,"olution of such MDPs using an information-theoretic tests generating function
6"
ABSTRACT,0.005937234944868533,"that heuristically, and dynamically for every state, limits the set of admissible
7"
ABSTRACT,0.006785411365564037,"test actions to a few good candidates. As a solver, we show empirically that our
8"
ABSTRACT,0.007633587786259542,"algorithm is at the very least competitive with branch-and-bound alternatives. As
9"
ABSTRACT,0.008481764206955046,"a machine learning tool, a key advantage of our approach is to solve for multiple
10"
ABSTRACT,0.009329940627650551,"complexity-performance trade-offs at virtually no additional cost. With such a set
11"
ABSTRACT,0.010178117048346057,"of solutions, a user can then select the tree that generalizes best and which has the
12"
ABSTRACT,0.01102629346904156,"interpretability level that best suits their needs, which no current branch-and-bound
13"
ABSTRACT,0.011874469889737066,"method allows.
14"
INTRODUCTION,0.01272264631043257,"1
Introduction
15"
INTRODUCTION,0.013570822731128074,"Decision trees (DTs) remain the dominant machine learning model in applications where interpretabil-
16"
INTRODUCTION,0.01441899915182358,"ity is essential [Costa and Pedreira, 2023]. Thanks to recent advances in hardware, a new class of
17"
INTRODUCTION,0.015267175572519083,"decision tree learning algorithms returning optimal trees has emerged [Bertsimas and Dunn, 2017,
18"
INTRODUCTION,0.016115351993214587,"Demirovic et al., 2022, Mazumder et al., 2022]. These algorithms are based on a branch-and-bound
19"
INTRODUCTION,0.016963528413910092,"solver that minimizes a regularized empirical loss, where the number of nodes is used as a regularizer.
20"
INTRODUCTION,0.017811704834605598,"These optimization problems have long been known to be NP-Hard [Hyafil and Rivest, 1976] and
21"
INTRODUCTION,0.018659881255301103,"despite hardware improvements, solvers of such problems do not scale well beyond trees of depth 3
22"
INTRODUCTION,0.019508057675996608,"when attributes take continuous values [Mazumder et al., 2022]. On the other hand, greedy approaches
23"
INTRODUCTION,0.020356234096692113,"such as CART [Breiman et al., 1984] are still considered state-of-the-art decision tree algorithms
24"
INTRODUCTION,0.021204410517387615,"because they scale and offer more advanced mechanisms to control the complexity of the tree. By
25"
INTRODUCTION,0.02205258693808312,"framing decision tree learning as a sequential decision problem, and by carefully controlling the
26"
INTRODUCTION,0.022900763358778626,"size of the search space, we achieve in this paper a best of both worlds, solving the combinatorial
27"
INTRODUCTION,0.02374893977947413,"optimization problem with accuracies close to optimal ones, while improving scaling and offering a
28"
INTRODUCTION,0.024597116200169637,"better control of the complexity-performance trade-off than any existing optimal algorithm.
29"
INTRODUCTION,0.02544529262086514,"To do so, we formulate the problem of decision tree learning as a Markov Decision Problem (MDP,
30"
INTRODUCTION,0.026293469041560644,"[L. Puterman, 1994]) for which the optimal policy builds a decision tree. Actions in such an MDP
31"
INTRODUCTION,0.02714164546225615,"include tests comparing an attribute to a threshold (a.k.a. splits). This action space could include all
32"
INTRODUCTION,0.027989821882951654,"possible splits or a heuristically chosen subset, yielding a continuum between optimal algorithms and
33"
INTRODUCTION,0.02883799830364716,"heuristic approaches. Furthermore, the reward function of the MDP encodes a trade-off between the
34"
INTRODUCTION,0.029686174724342665,"complexity and the performance of the learned tree. In our work, complexity takes the meaning of
35"
INTRODUCTION,0.030534351145038167,"simulatability [Lipton, 2018], i.e. the average number of splits the tree will perform on the train dataset.
36"
INTRODUCTION,0.031382527565733676,"The MDP reward is parameterized by α, trading-off between train accuracy and regularization. One
37"
INTRODUCTION,0.032230703986429174,"of the main benefits of our formulation is that the biggest share of the computational cost is due to
38"
INTRODUCTION,0.03307888040712468,"the construction of the MDP transition function which is completely independent of α, allowing us to
39"
INTRODUCTION,0.033927056827820185,"find optimal policies for a large choice of values of α at virtually no additional cost.
40"
INTRODUCTION,0.03477523324851569,"Branch-and-Bound (BnB) algorithms similarly optimize a complexity performance trade-off
41"
INTRODUCTION,0.035623409669211195,"[Demirovic et al., 2022, Mazumder et al., 2022] but require the user to provide the maximum
42"
INTRODUCTION,0.0364715860899067,"number of test nodes as an input to their algorithm. Providing such a value a priori is difficult
43"
INTRODUCTION,0.037319762510602206,"since a smaller tree (e.g. with 3 test nodes) might be only marginally worse on a given dataset than
44"
INTRODUCTION,0.03816793893129771,"a larger tree (e.g. with 15 test nodes) with respect to the training accuracy but might generalize
45"
INTRODUCTION,0.039016115351993216,"better or be deemed more interpretable a posteriori by the user. As such, it is critical to consider
46"
INTRODUCTION,0.03986429177268872,"the multi-objective nature of the optimization problem and seek algorithms returning a set of trees
47"
INTRODUCTION,0.04071246819338423,"that are located on the Pareto front of the complexity-performance trade-off. To the best of our
48"
INTRODUCTION,0.041560644614079725,"knowledge, this has been so far neglected by BnB approaches. None of the BnB implementations
49"
INTRODUCTION,0.04240882103477523,"return a set of trees for different regularizer weights unlike greedy algorithms like CART or C4.5
50"
INTRODUCTION,0.043256997455470736,"that can return trees with different complexity-performance trade-offs using minimal complexity
51"
INTRODUCTION,0.04410517387616624,"post-pruning [Breiman et al., 1984], making it a more useful machine learning tool in practice.
52"
RELATED WORK,0.04495335029686175,"2
Related Work
53"
RELATED WORK,0.04580152671755725,"2.1
Optimal Decision Trees.
54"
RELATED WORK,0.04664970313825276,"Decision tree learning has been formulated as an optimization problem in which the goal is to
55"
RELATED WORK,0.04749787955894826,"construct a tree that correctly fits the data while using a minimal number of splits. In [Bertsimas
56"
RELATED WORK,0.04834605597964377,"and Dunn, 2017, Aghaei et al., 2020, Verwer and Zhang, 2019], decision tree learning is formulated
57"
RELATED WORK,0.04919423240033927,"as a Mixed Integer Program (MIP). Instead of using a generic MIP solver, [Demirovic et al., 2022,
58"
RELATED WORK,0.05004240882103478,"Mazumder et al., 2022] design specialized solvers based on the Branch-and-Bound (BnB) principle.
59"
RELATED WORK,0.05089058524173028,"Quant-BnB [Mazumder et al., 2022] is currently the latest work in this line of research for datasets
60"
RELATED WORK,0.05173876166242578,"with continuous attributes and is considered state-of-the-art. However, direct optimization is not a
61"
RELATED WORK,0.05258693808312129,"convenient approach since finding the optimal tree is known to be NP-Hard [Hyafil and Rivest, 1976].
62"
RELATED WORK,0.05343511450381679,"Despite hardware improvements, Quant-BnB does not scale beyond trees depth of 3. To reduce the
63"
RELATED WORK,0.0542832909245123,"search space, optimal decision tree algorithms on binary datasets, such as MurTree, Blossom and
64"
RELATED WORK,0.0551314673452078,"Pystreed [Demirovic et al., 2022, Demirovi´c et al., 2023, van der Linden et al., 2023], employ
65"
RELATED WORK,0.05597964376590331,"heuristics to binarize a dataset with continuous attributes during a pre-processing step following
66"
RELATED WORK,0.056827820186598814,"for example the Minimum Description Length Principle [Rissanen, 1978]. The tests generating
67"
RELATED WORK,0.05767599660729432,"function of our MDP formulation is similar in principle except that it is state-dependent, which, as
68"
RELATED WORK,0.058524173027989825,"demonstrated experimentally, greatly improves the performance of our solver.
69"
RELATED WORK,0.05937234944868533,"2.2
Greedy approaches.
70"
RELATED WORK,0.06022052586938083,"Greedy approaches like CART iteratively partition the training dataset by taking the most informative
71"
RELATED WORK,0.061068702290076333,"splits in the sense of the Gini index or the entropy gain. CART is only one-step optimal but can
72"
RELATED WORK,0.06191687871077184,"scale to very deep trees. This might lead to overfitting and algorithms such as Minimal Complexity
73"
RELATED WORK,0.06276505513146735,"Post-Pruning (see Section 3.3 from [Breiman et al., 1984]) iteratively prune the deep tree, returning
74"
RELATED WORK,0.06361323155216285,"a set of smaller trees with decreasing complexity and potentially improved generalization. The
75"
RELATED WORK,0.06446140797285835,"trees returned by our algorithms provably dominate—in the multi-objective optimization sense—all
76"
RELATED WORK,0.06530958439355386,"the above smaller trees in terms of train accuracy vs. average number of tests performed, and we
77"
RELATED WORK,0.06615776081424936,"experimentally show that they often generalize better than the trees returned by CART.
78"
RELATED WORK,0.06700593723494487,"2.3
Markov Decision Problem formulations.
79"
RELATED WORK,0.06785411365564037,"In [Topin et al., 2021], a base MDP is extended to an Iterative Bounding MDP (IBMDP) allowing
80"
RELATED WORK,0.06870229007633588,"the use of any Deep Reinforcement Learning (DRL) algorithm to learn DT policies solving the
81"
RELATED WORK,0.06955046649703138,"base MDP. While more general and scalable, this method is not state-of-the-art for learning DTs for
82"
RELATED WORK,0.07039864291772689,"supervised learning tasks. Prior to IBMDPs, [Garlapati et al., 2015] formulated the learning of DTs
83"
RELATED WORK,0.07124681933842239,"for classification tasks with ordinal attributes as an MDP. To be able to handle continuous features,
84"
RELATED WORK,0.0720949957591179,"[Nunes et al., 2020] used Monte-Carlo tree search [Kocsis and Szepesvári, 2006] in combination
85"
RELATED WORK,0.0729431721798134,"with a tests generating function that limits the branching factor of the tree. Our MDP formulation is
86"
RELATED WORK,0.0737913486005089,"different as it considers a regularized objective while [Nunes et al., 2020] optimize accuracy on a
87"
RELATED WORK,0.07463952502120441,"validation set. Our tests generating function is also different and dramatically improves scaling as
88"
RELATED WORK,0.07548770144189991,"shown in the comparison of Sec. 5.1.1, making our algorithm competitive with BnB solvers, while
89"
RELATED WORK,0.07633587786259542,"[Nunes et al., 2020] only compared their algorithm against greedy approaches. A comparison of our
90"
RELATED WORK,0.07718405428329092,"method with other MDP approaches is presented in the supplementary material.
91"
RELATED WORK,0.07803223070398643,"2.4
Interpretability of Decision Trees.
92"
RELATED WORK,0.07888040712468193,"The interpretability of a decision tree is usually associated with its complexity, e.g. its depth or its
93"
RELATED WORK,0.07972858354537744,"total number of nodes. For trees with 3 to 12 leaves, [Piltaver et al., 2016] observed a strong negative
94"
RELATED WORK,0.08057675996607294,"correlation between the number of leaves in a tree and a “comprehensibility” score given by users.
95"
RELATED WORK,0.08142493638676845,"Most of the literature considers the total number of test nodes as its complexity measure, but other
96"
RELATED WORK,0.08227311280746395,"definitions of complexity exist. [Lipton, 2018] coined the term simulatability, which is related to the
97"
RELATED WORK,0.08312128922815945,"average number of tests performed before taking a decision. This quantity naturally arises in our
98"
RELATED WORK,0.08396946564885496,"MDP formulation. We show in a qualitative study that both criteria are often correlated but on some
99"
RELATED WORK,0.08481764206955046,"datasets, DPDT returns an unbalanced tree with more test nodes that are only traversed by a few
100"
RELATED WORK,0.08566581849024597,"samples.
101"
DECISION TREES FOR SUPERVISED LEARNING,0.08651399491094147,"3
Decision Trees for Supervised Learning
102"
DECISION TREES FOR SUPERVISED LEARNING,0.08736217133163698,"Let us consider a training dataset D = {(xi, yi)}i∈{1,...,N}, made of (data, label) pairs, (xi, yi) ∈
103"
DECISION TREES FOR SUPERVISED LEARNING,0.08821034775233248,"(X, Y ), where X ⊆Rp. A decision tree T sequentially applies tests to xi ∈X before assigning it a
104"
DECISION TREES FOR SUPERVISED LEARNING,0.089058524173028,"value in Y , which we denote T(xi) ∈Y . The tree has two types of nodes: test nodes that apply a
105"
DECISION TREES FOR SUPERVISED LEARNING,0.0899067005937235,"test and leaf nodes that assign a value in Y . A test compares the value of an attribute with a given
106"
DECISION TREES FOR SUPERVISED LEARNING,0.090754877014419,"threshold value, x.,2 ≤3"". In this paper, we focus on binary decision trees, where decision nodes
107"
DECISION TREES FOR SUPERVISED LEARNING,0.0916030534351145,"split into a left and a right child with axis aligned splits as in [Breiman et al., 1984]. However, all our
108"
DECISION TREES FOR SUPERVISED LEARNING,0.09245122985581,"results generalize straitghforwardly to tests involving functions of multiple attributes. Furthermore,
109"
DECISION TREES FOR SUPERVISED LEARNING,0.09329940627650551,"we look for trees with a maximum depth D, where D is the maximum number of tests a tree can
110"
DECISION TREES FOR SUPERVISED LEARNING,0.09414758269720101,"apply to classify a single xi ∈X. We let TD be the set of all binary decision trees of depth ≤D.
111"
DECISION TREES FOR SUPERVISED LEARNING,0.09499575911789652,"Given a loss ℓdefined on Y × Y we look for trees in TD satisfying
112"
DECISION TREES FOR SUPERVISED LEARNING,0.09584393553859202,"T ∗= argmin
T ∈TD
Lα(T),
(1)"
DECISION TREES FOR SUPERVISED LEARNING,0.09669211195928754,"= argmin
T ∈TD"
N,0.09754028837998303,"1
N N
X"
N,0.09838846480067855,"i=0
ℓ(yi, T(xi)) + αC(T),
(2)"
N,0.09923664122137404,"where C : T →R is a function that quantifies the complexity of a tree. It could be the number
113"
N,0.10008481764206956,"of nodes as in [Mazumder et al., 2022]. In our work, we are interested in the expected number of
114"
N,0.10093299406276506,"tests a tree applies on any arbitrary data x ∈D. As for ℓ, in a regression problem Y ⊂R and
115"
N,0.10178117048346055,"ℓ(yi, T(xi)) can be (yi −T(xi))2. For supervised classification problems, Y = {1, ..., K}, where K
116"
N,0.10262934690415607,"is the number of class labels, and ℓ(yi, T(xi)) = 1{yi̸=T (xi)}. In our work, we focus on supervised
117"
N,0.10347752332485156,"classification but the MDP formulation extends naturally to regression.
118"
DECISION TREE LEARNING AS AN MDP,0.10432569974554708,"4
Decision Tree Learning as an MDP
119"
DECISION TREE LEARNING AS AN MDP,0.10517387616624257,"Our approach encodes the decision tree learning problem expressed by Eq. (2) as a finite horizon
120"
DECISION TREE LEARNING AS AN MDP,0.10602205258693809,"Markov Decision Problem (MDP) ⟨S, A, Rα, P, D⟩. We present this MDP for a supervised clas-
121"
DECISION TREE LEARNING AS AN MDP,0.10687022900763359,"sification problem with continuous features, but again, our method extends to regression and to
122"
DECISION TREE LEARNING AS AN MDP,0.1077184054283291,"other types of features. The state space of this MDP is made of subsets X of the dataset D as well
123"
DECISION TREE LEARNING AS AN MDP,0.1085665818490246,"as a depth value d: S = {(X, d) ∈P(D) × {0, ..., D}}, where P(D) is the power set of D. Let
124"
DECISION TREE LEARNING AS AN MDP,0.10941475826972011,"F = {f : f(.) = 1{.≤xij}, ∀i ∈{1, ..., N}, ∀j ∈{1, ..., p}} be a set of binary functions. We
125"
DECISION TREE LEARNING AS AN MDP,0.1102629346904156,"consider only tests that compare attributes to values within the dataset because comparing attributes to
126"
DECISION TREE LEARNING AS AN MDP,0.1111111111111111,"other values cannot further reduce the training objective. The action space A of the MDP is then the set
127"
DECISION TREE LEARNING AS AN MDP,0.11195928753180662,"of all possible binary tests as well as class assignments: A = F ∪{1, ..., K}. When taking an action
128"
DECISION TREE LEARNING AS AN MDP,0.11280746395250212,"a ∈F, the MDP will transit from state (X, d) to either its “left"" state sl = (Xl, d + 1) or its “right""
129"
DECISION TREE LEARNING AS AN MDP,0.11365564037319763,"state sr = (Xr, d+1). In particular the MDP will transit to sl = ({(xi, yi) ∈X : a(xi) = 1}, d+1)
130"
DECISION TREE LEARNING AS AN MDP,0.11450381679389313,with probability pl = |Xl|
DECISION TREE LEARNING AS AN MDP,0.11535199321458864,"|X| or to sr = (X \ Xl, d + 1) with probability pr = 1 −pl. Furthermore,
131"
DECISION TREE LEARNING AS AN MDP,0.11620016963528414,"to enforce a maximum tree depth of D, whenever a state is s = (., D) then only class assignment
132"
DECISION TREE LEARNING AS AN MDP,0.11704834605597965,"actions are possible in s. When taking an action in {1, ..., K} the MDP will transit to a terminal state
133"
DECISION TREE LEARNING AS AN MDP,0.11789652247667515,"denoted sdone that is absorbing and has null rewards. The reward of taking an action a in state s is
134"
DECISION TREE LEARNING AS AN MDP,0.11874469889737066,"given by the parameterized mapping Rα : S × A →R that enforces a trade-off between the expected
135"
DECISION TREE LEARNING AS AN MDP,0.11959287531806616,"number of tests and the classification accuracy. It is defined by:
136"
DECISION TREE LEARNING AS AN MDP,0.12044105173876166,"Rα(s, a) = Rα((X, d), a), = 
 "
DECISION TREE LEARNING AS AN MDP,0.12128922815945717,"−α,
if a ∈F,
−1 |X|
P"
DECISION TREE LEARNING AS AN MDP,0.12213740458015267,"yi∈X
1yi̸=a
if a ∈{1, ..., K}."
DECISION TREE LEARNING AS AN MDP,0.12298558100084818,"The complexity-performance trade-off is encoded by the value 0 ≤α ≤1, which is the price to
137"
DECISION TREE LEARNING AS AN MDP,0.12383375742154368,"pay to obtain more information by testing a feature. A more detailed study of the trade-off is given
138"
DECISION TREE LEARNING AS AN MDP,0.12468193384223919,"in section 6.4. The maximum depth parameter D is a time horizon, i.e. the number of actions it is
139"
DECISION TREE LEARNING AS AN MDP,0.1255301102629347,"possible to take in one episode. An algorithm solving such an MDP can always return a deterministic
140"
DECISION TREE LEARNING AS AN MDP,0.1263782866836302,"policy [L. Puterman, 1994] of the form: π : S →A that maximizes the expected sum of rewards
141"
DECISION TREE LEARNING AS AN MDP,0.1272264631043257,"during an episode:
142"
DECISION TREE LEARNING AS AN MDP,0.1280746395250212,"π = argmax
π
Jα(π),
(3)"
DECISION TREE LEARNING AS AN MDP,0.1289228159457167,"Jα(π) = E "" D
X"
DECISION TREE LEARNING AS AN MDP,0.1297709923664122,"t=0
Rα(st, π(st)) # ,
(4)"
DECISION TREE LEARNING AS AN MDP,0.13061916878710772,"where the expectation is w.r.t. random variables st+1 ∼P(st, π(at)) with initial state s0 = (D, 0).
143"
DECISION TREE LEARNING AS AN MDP,0.13146734520780323,"From deterministic policy to binary DT. One can transform any deterministic policy π of the above
144"
DECISION TREE LEARNING AS AN MDP,0.13231552162849872,"MDP into a binary decision tree T with a simple extraction routine E(π, s), where s ∈S is a state.
145"
DECISION TREE LEARNING AS AN MDP,0.13316369804919423,"E is defined recursively in the following manner. If π(s) is a class assignment then E(π, s) returns a
146"
DECISION TREE LEARNING AS AN MDP,0.13401187446988974,"leaf node with class assignment π(s). Otherwise E(π, s) returns a binary decision tree that has a test
147"
DECISION TREE LEARNING AS AN MDP,0.13486005089058525,"node π(s) at its root, and E(π, sl) and E(π, sr) as, respectively, the left and right sub-trees of the
148"
DECISION TREE LEARNING AS AN MDP,0.13570822731128074,"root node. To obtain T from π, we call E(π, s0) on the initial state s0 = (D, 0).
149"
DECISION TREE LEARNING AS AN MDP,0.13655640373197625,"Equivalence of objectives. When the complexity measure C of Lα is the expected number of tests
150"
DECISION TREE LEARNING AS AN MDP,0.13740458015267176,"performed by a decision tree, the key property of our MDP formulation is that finding the optimal
151"
DECISION TREE LEARNING AS AN MDP,0.13825275657336725,"policy in the MDP is equivalent to finding T ∗, as given by the following proposition
152"
DECISION TREE LEARNING AS AN MDP,0.13910093299406276,"Proposition 1: Let π be a deterministic policy of the MDP and π∗one of its optimal deterministic
153"
DECISION TREE LEARNING AS AN MDP,0.13994910941475827,"policies, then Jα(π) = −Lα(E(π, s0)) and T ∗= E(π∗, s0).
154"
DECISION TREE LEARNING AS AN MDP,0.14079728583545378,"The proof is given in the Appendix H.
155"
ALGORITHM,0.14164546225614927,"5
Algorithm
156"
ALGORITHM,0.14249363867684478,"We now present the Dynamic Programming Decision Tree (DPDT) algorithm. The algorithm is made
157"
ALGORITHM,0.1433418150975403,"of two essential steps. The first and most computationally expensive step constructs the MDP of
158"
ALGORITHM,0.1441899915182358,"Section 4. The second step is to solve it to obtain policies maximizing Eq.(4) for different values of
159"
ALGORITHM,0.1450381679389313,"α. Both steps are now detailed.
160"
CONSTRUCTING THE MDP,0.1458863443596268,"5.1
Constructing the MDP
161"
CONSTRUCTING THE MDP,0.14673452078032231,"An algorithm constructing the MDP of Section 4 essentially computes the set of all possible decision
162"
CONSTRUCTING THE MDP,0.1475826972010178,"trees of maximum depth D whose decision nodes are in F. This specific MDP is a directed acyclic
163"
CONSTRUCTING THE MDP,0.1484308736217133,"graph. Each node of this graph corresponds to a state for which one computes the transition and
164"
CONSTRUCTING THE MDP,0.14927905004240882,"reward functions. To limit memory usage of non-terminal nodes, instead of storing all the samples
165"
CONSTRUCTING THE MDP,0.15012722646310434,"in (X, d), we only store d and the binary vector of size N, xbin = (1{xi∈X})i∈{1,...,N}. Even then,
166"
CONSTRUCTING THE MDP,0.15097540288379982,"considering all possible splits in F will not scale. We thus introduce a state-dependent action space
167"
CONSTRUCTING THE MDP,0.15182357930449533,"As, much smaller than A and populated by the tests generating function.
168"
TESTS GENERATING FUNCTIONS,0.15267175572519084,"5.1.1
Tests generating functions
169"
TESTS GENERATING FUNCTIONS,0.15351993214588636,"A tests generating function is any function ϕ of the form ϕ : S →P(F), where P(F) is the power
170"
TESTS GENERATING FUNCTIONS,0.15436810856658184,"set of all possible data splits F. For a state s ∈S, the state-dependent action space is defined by
171"
TESTS GENERATING FUNCTIONS,0.15521628498727735,"As = ϕ(s) ∪{1, ..., K}. Because for a given state s we might have that ϕ(s) ̸= F, solving the
172"
TESTS GENERATING FUNCTIONS,0.15606446140797287,"101
102
103
104
105
106"
TESTS GENERATING FUNCTIONS,0.15691263782866835,Number of MDP states 0.970 0.975 0.980 0.985 0.990
TESTS GENERATING FUNCTIONS,0.15776081424936386,Accuracy
TESTS GENERATING FUNCTIONS,0.15860899067005937,"Exhaustive
TOP 55
TOP 10
TOP 5
CART (TOP 1)
DPDT-2
DPDT-3
DPDT-4"
TESTS GENERATING FUNCTIONS,0.1594571670907549,"Figure 1: Comparison of DPDT algorithm on the Iris dataset in
terms of the number of states in the MDP when using different
tests generating functions. “TOP B” are tests function return-
ing the B most informative splits for each state. “Exhaustive”
returns all possible states (equivalent to the search space of
Quant-BnB). DPDT-Dcart are the tests functions that make
calls to the CART algorithm."
TESTS GENERATING FUNCTIONS,0.16030534351145037,"MDP with state-dependent actions As is not guaranteed to yield the minimizing tree in Eq. (2), as
173"
TESTS GENERATING FUNCTIONS,0.16115351993214588,"optimization is now carried on a subset of TD. In this section, we compare different choices of ϕ on a
174"
TESTS GENERATING FUNCTIONS,0.1620016963528414,"sufficiently small dataset such that ϕ(s) = F, ∀s ∈S remains tractable. As a baseline, we use a tests
175"
TESTS GENERATING FUNCTIONS,0.1628498727735369,"generating function proposed in [Nunes et al., 2020], and compare with our proposed ϕ in terms of
176"
TESTS GENERATING FUNCTIONS,0.1636980491942324,"quality of the best tree vs. size of the MDP.
177"
TESTS GENERATING FUNCTIONS,0.1645462256149279,"Algorithm 1: DPDT-K MDP generation
Data: Dataset D, max depth D
Result: Decision Tree Search MDP
d ←0
s0 ←[D, d]
MDP.AddState(s0) # MDP of Sec. 4
while d < D do"
TESTS GENERATING FUNCTIONS,0.16539440203562342,"# For all states at the current
depth d
for s = (Ds, ds) ∈MDP s.t. ds = d do"
TESTS GENERATING FUNCTIONS,0.1662425784563189,"# Test generating function
follwing Sec. 5.1.1
Tcart ←CART(Ds, maxdepth=K)
As ←ExtractSplits(Tcart)
for a ∈As do"
TESTS GENERATING FUNCTIONS,0.1670907548770144,"# MDP expansion
follwoing Sec. 4
MDP.AddRewardAndTransition(s, a)
MDP.AddStates(NextStates(s, a))
end
end
d ←d + 1;
end"
TESTS GENERATING FUNCTIONS,0.16793893129770993,"Exhaustive function. When ϕ(s) = F, ∀s ∈S, the
178"
TESTS GENERATING FUNCTIONS,0.16878710771840544,"MDP contains all possible data splits. In this case,
179"
TESTS GENERATING FUNCTIONS,0.16963528413910092,"the MDP ‘spans’ all trees of depth at most D and the
180"
TESTS GENERATING FUNCTIONS,0.17048346055979643,"solution to Eq. (4) will be the optimal decision tree of
181"
TESTS GENERATING FUNCTIONS,0.17133163698049195,"Eq. (2). In this case, the number of states in the MDP
182"
TESTS GENERATING FUNCTIONS,0.17217981340118746,"would be of the order of
D−1
P"
TESTS GENERATING FUNCTIONS,0.17302798982188294,"d=0
K(2Np)d which scales
183"
TESTS GENERATING FUNCTIONS,0.17387616624257846,"exponentially with the maximum depth of the tree:
184"
TESTS GENERATING FUNCTIONS,0.17472434266327397,"this limits the learning to very shallow trees (D ≤3)
185"
TESTS GENERATING FUNCTIONS,0.17557251908396945,"as discussed in [Mazumder et al., 2022]. The goal
186"
TESTS GENERATING FUNCTIONS,0.17642069550466496,"of a more heuristic choice of ϕ is to have a maximal
187"
TESTS GENERATING FUNCTIONS,0.17726887192536048,"number of splits B = maxs∈S |ϕ(s)| that is orders
188"
TESTS GENERATING FUNCTIONS,0.178117048346056,"of magnitude smaller than that of the exhaustive case
189"
TESTS GENERATING FUNCTIONS,0.17896522476675147,"|F| = Np such that the size of the MDP, which is
190"
TESTS GENERATING FUNCTIONS,0.179813401187447,"now in the order of
D−1
P"
TESTS GENERATING FUNCTIONS,0.1806615776081425,"d=0
K(2B)d, remains tractable
191"
TESTS GENERATING FUNCTIONS,0.181509754028838,"for deeper trees.
192"
TESTS GENERATING FUNCTIONS,0.1823579304495335,"Top B most informative splits. [Nunes et al., 2020]
193"
TESTS GENERATING FUNCTIONS,0.183206106870229,"proposed to generate tests with a function that returns
194"
TESTS GENERATING FUNCTIONS,0.18405428329092452,"for any state s = (X, d) the B most informative splits
195"
TESTS GENERATING FUNCTIONS,0.18490245971162,"over X in the sense of entropy gain. In practice, we
196"
TESTS GENERATING FUNCTIONS,0.18575063613231552,"noticed that the returned set of splits lacked diversity
197"
TESTS GENERATING FUNCTIONS,0.18659881255301103,"and often consists of splits on the same attribute with minor changes to the threshold value. While
198"
TESTS GENERATING FUNCTIONS,0.18744698897370654,"this still leads to improvements over greedy methods—as shown in the study presented next—it is at
199"
TESTS GENERATING FUNCTIONS,0.18829516539440203,"the expense of a much larger MDP, i.e., search space.
200"
TESTS GENERATING FUNCTIONS,0.18914334181509754,"Top B most discriminative splits. Instead of returning the most informative splits, we propose at
201"
TESTS GENERATING FUNCTIONS,0.18999151823579305,"every state s = (X, d), to find the most discriminative splits, i.e. the attribute comparisons with which
202"
TESTS GENERATING FUNCTIONS,0.19083969465648856,"one can best predict the class of data points in X. This is similar to the minimum description length
203"
TESTS GENERATING FUNCTIONS,0.19168787107718405,"principle used in [Demirovic et al., 2022] that transforms a dataset with continuous attributes to a
204"
TESTS GENERATING FUNCTIONS,0.19253604749787956,"binary dataset. However, we perform this transformation dynamically at every state while building
205"
TESTS GENERATING FUNCTIONS,0.19338422391857507,"the MDP. In practice, this amounts to calling CART with a maximum depth Dcart (a hyperparameter
206"
TESTS GENERATING FUNCTIONS,0.19423240033927056,"of DPDT) on every state s, and using the test nodes of the tree returned by CART as ϕ(s).
207"
TESTS GENERATING FUNCTIONS,0.19508057675996607,"While restricting the action space at a given state s to the actions of the tests generating function ϕ(s)
208"
TESTS GENERATING FUNCTIONS,0.19592875318066158,"loses the guarantees of finding T ∗, we are still guaranteed to find trees better than those of CART:
209"
TESTS GENERATING FUNCTIONS,0.1967769296013571,"Proposition 2: Let π∗be an optimal deterministic policy of the MDP, where the action space at every
210"
TESTS GENERATING FUNCTIONS,0.19762510602205258,"state is restricted to the top B most informative or discriminative splits. Let T0 be the tree learned by
211"
TESTS GENERATING FUNCTIONS,0.1984732824427481,"CART and {T1, . . . , TM} be the set of trees returned by postprocessing pruning on T0, then for any
212"
TESTS GENERATING FUNCTIONS,0.1993214588634436,"α > 0, Lα(E(π∗, s0)) ≤min0≤i≤M Lα(Ti).
213"
TESTS GENERATING FUNCTIONS,0.2001696352841391,"The proof for Prop. 5.1.1 follows from the fact that policies generating the tree returned by CART
214"
TESTS GENERATING FUNCTIONS,0.2010178117048346,"and all of its sub-trees (which is a superset of the trees returned by the pruning procedure) are
215"
TESTS GENERATING FUNCTIONS,0.2018659881255301,"representable in the MDP and by virtue of the optimality of π∗and the equivalence in Prop. 4, are
216"
TESTS GENERATING FUNCTIONS,0.20271416454622562,"worse in terms of regularized loss Lα than the tree E(π∗, s0). The consequences of Prop. 5.1.1
217"
TESTS GENERATING FUNCTIONS,0.2035623409669211,"are clearly observed experimentally in Fig. 3. While this proposition holds for the latter two test
218"
TESTS GENERATING FUNCTIONS,0.20441051738761662,"generating functions, in practice, the tests returned by our proposed function are of much higher
219"
TESTS GENERATING FUNCTIONS,0.20525869380831213,"quality as discussed next.
220"
TESTS GENERATING FUNCTIONS,0.20610687022900764,"Comparing tests generating functions. We conduct a small study comparing the exhaustive ϕ
221"
TESTS GENERATING FUNCTIONS,0.20695504664970313,"(labeled “Exhaustive”) against the ϕ proposed in [Nunes et al., 2020] (labeled “Top B”) and the one
222"
TESTS GENERATING FUNCTIONS,0.20780322307039864,"used in our algorithm (labeled “DPDT-K”, where K is the maximum depth given to CART), on the Iris
223"
TESTS GENERATING FUNCTIONS,0.20865139949109415,"dataset. Figure 1 shows that while the latter two ϕ generalize the greedy approach (labeled “CART”),
224"
TESTS GENERATING FUNCTIONS,0.20949957591178966,"DPDT scales much more gracefully than when using the ϕ of [Nunes et al., 2020]. With Dcart = 4,
225"
TESTS GENERATING FUNCTIONS,0.21034775233248515,"DPDT-4 finds the optimal tree in an MDP having several orders of magnitude less states (a few
226"
TESTS GENERATING FUNCTIONS,0.21119592875318066,"hundreds vs a few millions) than the one built using the exhaustive ϕ. This favorable comparison
227"
TESTS GENERATING FUNCTIONS,0.21204410517387617,"against exhaustive methods also holds for larger datasets as shown in Sec. 6.2.
228"
TESTS GENERATING FUNCTIONS,0.21289228159457166,"The MDP construction of DPDT-K using the tests generating function is explained in Alg. 1. Starting
229"
TESTS GENERATING FUNCTIONS,0.21374045801526717,"from s0, the state containing the whole dataset, CART with a maximum depth of K is called which
230"
TESTS GENERATING FUNCTIONS,0.21458863443596268,"generates a tree with up to 2K −1 split nodes. These splits are what constitutes As0, the set of binary
231"
TESTS GENERATING FUNCTIONS,0.2154368108566582,"tests admissible at s0. For every such action, we compute the reward and transition probabilities to a
232"
TESTS GENERATING FUNCTIONS,0.21628498727735368,"set of new states at depth 1. This process is then iterated for every state at depth 1, calling CART with
233"
TESTS GENERATING FUNCTIONS,0.2171331636980492,"the same maximum depth of K on each of the states at depth 1, generating a new set of binary tests As
234"
TESTS GENERATING FUNCTIONS,0.2179813401187447,"for each of these states s and so on until reaching the maximum depth. Upon termination of Alg. 1,
235"
TESTS GENERATING FUNCTIONS,0.21882951653944022,"we compute the rewards for labelling actions at every state and we call the dynamic programming
236"
TESTS GENERATING FUNCTIONS,0.2196776929601357,"routine below to extract the optimal policy.
237"
DYNAMIC PROGRAMMING,0.2205258693808312,"5.2
Dynamic Programming
238"
DYNAMIC PROGRAMMING,0.22137404580152673,"Having built the MDP, we backpropagate using dynamic programming the best optimal actions from
239"
DYNAMIC PROGRAMMING,0.2222222222222222,"the terminal states to the initial states. We use Bellman’s optimality equation to compute the value of
240"
DYNAMIC PROGRAMMING,0.22307039864291772,"the best actions recursively:
241"
DYNAMIC PROGRAMMING,0.22391857506361323,"Q∗(s, a) = E
h
rd+1 + max
a′ Q∗(sd+1, a′)|sd = s, ad = a
i
, =
X"
DYNAMIC PROGRAMMING,0.22476675148430875,"s′
P(s, a, s′)
h
R(s, a) + max
a′ Q∗(s′, a′)
i
."
DYNAMIC PROGRAMMING,0.22561492790500423,"Pareto front.
As our reward function is a linear combination of the complexity and performance
242"
DYNAMIC PROGRAMMING,0.22646310432569974,"measures, we can reach any tree “spanned” by the MDP that lies on the convex hull of the Pareto
243"
DYNAMIC PROGRAMMING,0.22731128074639526,"front of the complexity-performance trade-off. In DPDT, we compute the optimal policy for several
244"
DYNAMIC PROGRAMMING,0.22815945716709077,"choices of α using a vectorial representation of the Q-function that now depends on α:
245"
DYNAMIC PROGRAMMING,0.22900763358778625,"Q∗(s, a, α) =
X"
DYNAMIC PROGRAMMING,0.22985581000848176,"s′
P(s, a, s′)
h
Rα(s, a) + max
a′ Q∗(s′, a′, α)
i
."
DYNAMIC PROGRAMMING,0.23070398642917728,"We can then find all policies greedy w.r.t. Q∗π∗(s, α) = argmax
a∈A
Q∗(s, a, α). Such policies satisfy
246"
DYNAMIC PROGRAMMING,0.23155216284987276,"Eq. (4) for any value of α. Given a set of values of α in [0, 1], we can compute in a single backward
247"
DYNAMIC PROGRAMMING,0.23240033927056827,"pass Q∗(s, a, α) and π∗(s, α) and return a set of trees, optimal for different values of α (see Fig.7 for
248"
DYNAMIC PROGRAMMING,0.23324851569126379,"an illustrative example). In practice, the computational cost is dominated by the construction of the
249"
DYNAMIC PROGRAMMING,0.2340966921119593,"MDP 1 and one can promptly back-propagate the Q-values of over 103 values of α.
250"
EXPERIMENTS,0.23494486853265478,"6
Experiments
251"
EXPERIMENTS,0.2357930449533503,"In this section we study DPDT from different perspectives. First, in Sec. 6.2, we study DPDT in
252"
EXPERIMENTS,0.2366412213740458,"terms of its performance as a solver for the combinatorial optimization problem of Eq. (2). Here, we
253"
EXPERIMENTS,0.23748939779474132,"focus on smaller problems (maximum depth ≤3) in which the optimal solution can be computed
254"
EXPERIMENTS,0.2383375742154368,"by Branch-and-Bound (BnB) algorithms. In this first set of experiments, we only report the training
255"
EXPERIMENTS,0.23918575063613232,"accuracy vs. the wall-clock time as done in prior work [Mazumder et al., 2022]. Then we study DPDT
256"
EXPERIMENTS,0.24003392705682783,"for model selection (Sec. 6.3). From the perspective of the end user, a decision tree algorithm may
257"
EXPERIMENTS,0.2408821034775233,"be used for selecting either a tree that generalizes well to unseen data or a tree that is interpretable.
258"
EXPERIMENTS,0.24173027989821882,"We compare classification of unseen data of trees obtained by DPDT to other baselines described
259"
EXPERIMENTS,0.24257845631891434,"below. Then, we plot the train accuracy of trees learned by CART and DPDT as a function of their
260"
EXPERIMENTS,0.24342663273960985,"complexity to observe how a user can choose the complexity-performance trade-off. We use the 16
261"
EXPERIMENTS,0.24427480916030533,"classification datasets with continuous attributes experimented with in [Mazumder et al., 2022].
262"
EXPERIMENTS,0.24512298558100085,"When considering other optimal BnB baselines [Demirovic et al., 2022, van der Linden et al., 2023],
263"
EXPERIMENTS,0.24597116200169636,"two problems arise for fair comparison with DPDT in terms of model selection. First, to obtain a set
264"
EXPERIMENTS,0.24681933842239187,"of tree from such baselines, the optmization algorithms need to be ran as many times as trees wanted
265"
EXPERIMENTS,0.24766751484308736,"by the user. For example, one can obtain a set of trees of depth ≤5 by running MurTree 25 times
266"
EXPERIMENTS,0.24851569126378287,"with different maximum number of test nodes allowed in the learned trees. This could require up
267"
EXPERIMENTS,0.24936386768447838,"to 25 times the runtime of a single optimization. Second, MurTree and Pystreed [Demirovic et al.,
268"
EXPERIMENTS,0.2502120441051739,"2022, van der Linden et al., 2023] require binary attributes. Learned trees are not comparable directly
269"
EXPERIMENTS,0.2510602205258694,"with trees trained on continuous attributes because each tree node testing a binary feature actually
270"
EXPERIMENTS,0.25190839694656486,"does at least two tests on the original continuous feature (see Appendix F.1 or Appendix D1 from
271"
EXPERIMENTS,0.2527565733672604,"[Mazumder et al., 2022]). DPDT is coded in Python and the code is available in the supplementary
272"
EXPERIMENTS,0.2536047497879559,"material. All experiments are run on a single core from a Intel i7-8665U CPU. All the links to
273"
EXPERIMENTS,0.2544529262086514,"code used for the baselines are given in the Appenix A
274"
BASELINES,0.2553011026293469,"6.1
Baselines
275"
BASELINES,0.2561492790500424,"Quant-BnB. [Mazumder et al., 2022] propose a scalable BnB algorithm that returns optimal trees.
276"
BASELINES,0.25699745547073793,"We emphasize that Quant-BnB is not meant to scale beyond tree depths of 3 (explicitly stated in the
277"
BASELINES,0.2578456318914334,"Quant-BnB paper) and the authors’ implementation of Quant-BnB does not support learning trees of
278"
BASELINES,0.2586938083121289,"depth > 3.
279"
BASELINES,0.2595419847328244,"MurTree, Pystreed. To use [Demirovic et al., 2022, van der Linden et al., 2023] with continuous
280"
BASELINES,0.26039016115351993,"features datasets, the minimum length description principle is used to obtain bins in a continuous
281"
BASELINES,0.26123833757421544,"feature domain, then a one hot encoding is applied to binarize the binned dataset. This can result in
282"
BASELINES,0.26208651399491095,"datasets with more than 500 features. As MurTree and Pystreed memory scales with the square of
283"
BASELINES,0.26293469041560646,"number of binary attributes, using those algorithms to find trees of depths greater than 3 often results
284"
BASELINES,0.263782866836302,"in Out Of Memory (OOM) errors.
285"
BASELINES,0.26463104325699743,"Deep Reinforcement Learning. We use Custard [Topin et al., 2021] as a DRL baseline. Custard
286"
BASELINES,0.26547921967769295,"has two hyperparameters: the DRL algorithm to learn a policy in the IBMDP and a tests generating
287"
BASELINES,0.26632739609838846,"function that gives p tests per feature. In our experiments, Custard-5 and Custard-3 correspond to
288"
BASELINES,0.26717557251908397,"DQN agents [Mnih et al., 2015] that can test each dataset attribute against 5 or 3 values respectively.
289"
BASELINES,0.2680237489397795,"CART [Breiman et al., 1984] is a greedy algorithm that can build suboptimal trees for any dataset.
290"
OPTIMALITY GAP,0.268871925360475,"6.2
Optimality gap
291"
OPTIMALITY GAP,0.2697201017811705,"Because we use a tests generating function that heuristically reduces the search space, a first question
292"
OPTIMALITY GAP,0.27056827820186596,"we want to investigate is how good is our solver for the combinatorial problem of decision tree search.
293"
OPTIMALITY GAP,0.2714164546225615,"To do so, we focus on max depth 3 problems for which T ∗can be computed exactly using Quant-BnB
294"
OPTIMALITY GAP,0.272264631043257,"[Mazumder et al., 2022]. As Quant-BnB has a different complexity regularization (number of nodes in
295"
OPTIMALITY GAP,0.2731128074639525,"the tree) than DPDT (average number of tests per classified data), we set the complexity regularizing
296"
OPTIMALITY GAP,0.273960983884648,"term α to 0 to allow direct comparisons. This does not create an artificial learning and on 14 out of
297"
OPTIMALITY GAP,0.2748091603053435,"16 datasets, trees with α = 0 generalize best, and second best on the remaining 2. That is because at
298"
OPTIMALITY GAP,0.27565733672603904,"depth 3 the risk of overfitting is small.
299"
OPTIMALITY GAP,0.2765055131467345,"We run DPDT with calls to CART with maximum depth 4 or 5 as a tests generating function (DPDT-4
300"
OPTIMALITY GAP,0.27735368956743,"and DPDT-5 respectively). Quant-BnB is first run without a time limit to obtain optimal decision trees
301"
OPTIMALITY GAP,0.2782018659881255,"w.r.t. Eq.(2). Quant-BnB is also run a second time with a time limit equal to DPDT-5’s runtime (we
302"
OPTIMALITY GAP,0.27905004240882103,"also added in the supplementary material results for Quant-BnB-T+5 and Quant-BnB-T+50 that add
303"
OPTIMALITY GAP,0.27989821882951654,"extra seconds to Quant-BnB-T). CART is run with the maximum depth set to 3 and the information
304"
OPTIMALITY GAP,0.28074639525021206,"gain based on entropy. All algorithms are run on the same hardware. Custard is run 5 times per dataset
305"
OPTIMALITY GAP,0.28159457167090757,"because it is a stochastic algorithm. We use stable-baselines3 implementation of DQN [Raffin et al.,
306"
OPTIMALITY GAP,0.2824427480916031,"2021] with default hyperparameters. A Custard run usually takes 10 minutes. We provide learning
307"
OPTIMALITY GAP,0.28329092451229854,"curves in Fig. 4. The key result from Table 1 is that DPDT-5 has better train accuracies than the
308"
OPTIMALITY GAP,0.28413910093299405,"<= -5
[-2.5:0]
[0:2.5]
[2.5:5]
[5:7.5]
[7.5:10]
[10:12.5] [12.5:15]
>15
Accuracy gain over CART 0 2 4 6 8 10 12 14"
OPTIMALITY GAP,0.28498727735368956,Number of datasets
OPTIMALITY GAP,0.2858354537743851,"DPDT-2
DPDT-3
Quant-BnB
MurTree
Pystreed"
OPTIMALITY GAP,0.2866836301950806,"<=-3
[-2:-2.5]
[-1.5:-2]
[-1:-1.5]
[-0.5:-1]
[0:-0.5]
> 0.5
[-2.5:-3]"
OPTIMALITY GAP,0.2875318066157761,DPDT trees average #tests gain over CART trees 0 1 2 3 4 5 6
OPTIMALITY GAP,0.2883799830364716,Number of datasets
OPTIMALITY GAP,0.28922815945716707,"DPDT-2
DPDT-3"
OPTIMALITY GAP,0.2900763358778626,"Figure 2: Performance gain of DTs over CART trees. Left, accuracy on unseen data gain of trees
with depth ≤5 selected with procedure of Sec. 6.3. Right, average number of tests of those trees."
OPTIMALITY GAP,0.2909245122985581,"other non-greedy methods when run in similar runtimes across all classification tasks. Furthermore,
309"
OPTIMALITY GAP,0.2917726887192536,"the train accuracy gaps between the optimal decision trees obtained from Quant-BnB, in sometimes
310"
OPTIMALITY GAP,0.2926208651399491,"several hours, and DPDT are usually small (the maximum gap is 1.5% for the bean dataset).
311"
OPTIMALITY GAP,0.29346904156064463,"Table 1: Train accuracy of decision tree algorithms. The “Quant-BnB” columns correspond to
results for Quant-BnB with no time limit, i.e returing the optimal tree. The “Quant-BnB-T” column
corresponds to results for Quant-BnB run for as long as DPDT-5. The “Greedy” columns correspond
to CART with maximum depth of 3."
OPTIMALITY GAP,0.29431721798134014,"Datasets
Accuracy (train %) of depth-3 trees
Runtime in seconds
Names
Samples
p
Classes
Quant-BnB
Quant-BnB-T
DPDT-5
DPDT-4
Custard-5
Custard-3
Greedy
Quant-BnB
DPDT-5
DPDT-4
Custard-5
Custard-3
Greedy
avila
10430
10
12
58.5
57.3
58.5∗
58
40.9 ± 0.6
41 ± 0.3
53.8
4188
5.645
2.14
553
632
0.031
bank
1097
4
2
98.3
97.1
98
98
49.6 ± 1.6
35.5 ± 20.9
95.3
4.4
0.158
0.142
648
661
0.003
bean
10888
16
7
87.1
85.3
85.6
85
18.2 ± 2.3
19.2 ± 4.1
80.5
1014
16.194
5.836
697
687
0.114
bidding
5056
9
2
99.3
98.6
99.3∗
99.3∗
81 ± 4.4
79.4 ± 2.1
98.2
30
0.545
0.377
693
671
0.006
eeg
11984
14
2
70.8
68.3
70.3
70
54.9 ± 0.1
54.8 ± 0.5
66.6
4042
8.927
3.032
692
682
0.023
fault
1552
27
7
68.2
64.6
68
65.7
30.3 ± 1.4
27.5 ± 8.6
55.3
−
2.46
1.243
720
711
0.015
htru
14318
8
2
98.1
98
98
98
86 ± 0.9
59.4 ± 31.7
97.9
10303
11.316
4.246
690
684
0.055
magic
15216
10
2
83.1
82.6
83
82.7
58.1 ± 4.3
58.5 ± 3.0
79.3
1090
14.838
5.443
685
675
0.069
occupancy
8143
5
2
99.4
99.3
99.4∗
99.3
64.7 ± 0.5
65.1 ± 8.3
99.1
106
1.458
0.786
687
664
0.008
page
4378
10
5
97.1
96.5
97
97.0
90.2 ± 0.4
88.3 ± 4.8
96.3
471
2.859
1.29
708
687
0.01
raisin
720
7
2
89.4
88.1
88.5
88.3
50.9 ± 2.2
49.7 ± 1.0
86.9
167
0.501
0.3
668
667
0.003
rice
3048
7
2
93.8
93.7
93.7
93.6
51.9 ± 0.9
48.1 ± 3.4
93.0
1340
2.004
0.809
668
666
0.01
room
8103
16
4
99.2
98.8
99.2∗
99.2∗
71.5 ± 3.4
67.6 ± 5.6
97.7
180
2.714
1.884
1362
1389
0.01
segment
1848
18
7
88.7
79.1
88.2
88.2
13.7 ± 0.5
13.9 ± 0.5
81.6
153
0.771
0.397
812
761
0.009
skin
196045
3
2
96.9
96.7
96.7
96.7
61.2 ± 2.2
62.2 ± 8.7
96.6
350
48.894
19.239
752
745
0.082
wilt
4339
5
2
99.6
99.4
99.5
99.5
98.4 ± 0.2
98.3 ± 0.1
99.1
67
0.582
0.352
663
610
0.008"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.2951653944020356,"6.3
Selecting the best tree for unseen data
312"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.2960135708227311,"We now investigate whether DPDT is suited for model selection i.e. whether DPDT can identify an
313"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.2968617472434266,"accurate decision tree that will generalize well to unseen data for a given classification task. We used
314"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.29770992366412213,"the following model selection procedure for each classification task. First, we learn a set of decision
315"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.29855810008481765,"trees of depth D ≤5 with DPDT-3, DPDT-2, and CART on a training set using different values of
316"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.29940627650551316,"α for DPDT or minimal complexity post-pruning for CART. Because Quant-BnB simply cannot
317"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.30025445292620867,"compute trees of depth > 3, we only report the accuracy on unseen data of Quant-BnB trees from
318"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.3011026293469042,"Table 1. Because the BnB baselines MurTree and Pystreed are not designed to return a set of trees,
319"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.30195080576759964,"we brute force the computation of at most 25 trees from each by setting the maximum tree nodes
320"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.30279898218829515,"parameter to 0, ..., 25 −1. Then, for each baseline we evaluate each learned tree (only one tree for
321"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.30364715860899066,"Quant-BnB) on a test set and select the tree with highest test accuracy. Fig 2 reports the number of
322"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.3044953350296862,"datasets for which each baseline has better generalization performances than CART, and the number
323"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.3053435114503817,"of datasets for which DPDT-K returned trees performing less tests on average than CART trees. A
324"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.3061916878710772,"table with accuracies of the selected trees on a validation set, the runtime in seconds to obtain the set
325"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.3070398642917727,"of trees to select from, and the average number of tests performed on data in Appendix. All BnB
326"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.30788804071246817,"baselines required more than 5 minutes to generate a single tree. As such, the runtime for BnB to
327"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.3087362171331637,"obtain the whole set of trees is order of magnitudes higher than CART and DPDT. DPDT learns a set
328"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.3095843935538592,"of trees of at most depth 5 on the complexity-performance convex-hull in seconds which highlights
329"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.3104325699745547,"its ability to scale to non-shallow trees. For that purpose, DPDT built the MDP of possible solution
330"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.3112807463952502,"trees of at most depth 5 using CART as a tests generating function, and backpropagated state-action
331"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.31212892281594573,"values for 1000 different α.
332"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.31297709923664124,"After applying the above selection procedure, we see on Table 2 that DPDT generalized better than
333"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.3138252756573367,"CART on 10 out of 16 datasets while CART outperformed DPDT on only one dataset. When accuracy
334"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.3146734520780322,"on test data for CART is already close to 100%, our approach can of course not largely outperform it.
335"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.3155216284987277,"However, the benefits of our method have to also be appreciated in terms of gains in average number
336"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.31636980491942324,"of tests. We can see that when CART does not generalize well, our method can have clear gains in
337"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.31721798134011875,"generalization (e.g. avila, eeg and fault). Otherwise, when CART is close to 100% accuracy, our
338"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.31806615776081426,"method can achieve similar results with less tests. In raisin, rice and room we need two fewer tests
339"
SELECTING THE BEST TREE FOR UNSEEN DATA,0.3189143341815098,"which is substantial when tests are expensive, e.g. an MRI scan when testing patients.
340"
SELECTING THE MOST INTERPRETABLE TREE,0.3197625106022053,"6.4
Selecting the most interpretable tree
341"
SELECTING THE MOST INTERPRETABLE TREE,0.32061068702290074,"0
1
2
3
4
5
average tests per sample 0.55 0.60 0.65 0.70 0.75"
SELECTING THE MOST INTERPRETABLE TREE,0.32145886344359625,accuracy eeg
SELECTING THE MOST INTERPRETABLE TREE,0.32230703986429177,"DPDT-3 Train in 57.038s
DPDT-2 Train in 4.347s
CART-PP Train in 1.25s"
SELECTING THE MOST INTERPRETABLE TREE,0.3231552162849873,"0
1
2
3
4
5
average tests per sample 0.4 0.5 0.6 0.7 0.8"
SELECTING THE MOST INTERPRETABLE TREE,0.3240033927056828,accuracy fault
SELECTING THE MOST INTERPRETABLE TREE,0.3248515691263783,"DPDT-3 Train in 35.185s
DPDT-2 Train in 2.611s
CART-PP Train in 0.913s"
SELECTING THE MOST INTERPRETABLE TREE,0.3256997455470738,"Figure 3: Complexity-performance trade-offs of CART and DPDT on two different classification
datasets. CART returns a set of trees with the minimal complexity post-pruning algorithm. DPDT
returns a set of trees by returning policies for 1000 different α."
SELECTING THE MOST INTERPRETABLE TREE,0.3265479219677693,"In this section, we show how a user can use DPDT to select a tree with complexity preferences. In
342"
SELECTING THE MOST INTERPRETABLE TREE,0.3273960983884648,"Figure 3, we plot the trade-offs of trees returned by CART and DPDT. The trade-off is between
343"
SELECTING THE MOST INTERPRETABLE TREE,0.3282442748091603,"accuracy and average number of tests. Because this is the trade-off that DPDT optimizes and because
344"
SELECTING THE MOST INTERPRETABLE TREE,0.3290924512298558,"the trees of CART are “spanned” by the MDP created by DPDT, all trees returned by DPDT will
345"
SELECTING THE MOST INTERPRETABLE TREE,0.3299406276505513,"dominate in the multi-objective sense trees returned by CART. This is well demonstrated in practice by
346"
SELECTING THE MOST INTERPRETABLE TREE,0.33078880407124683,"Figure 3 where the curve of DPDT is always above that of CART. Learned trees and their accuracies
347"
SELECTING THE MOST INTERPRETABLE TREE,0.33163698049194235,"as functions of number of nodes and tests are presented in Appendices 5 8 9. Finally, decision tree
348"
SELECTING THE MOST INTERPRETABLE TREE,0.3324851569126378,"search being a combinatorial problem, there are always limits to scalability. In Appendix 6 we scale
349"
SELECTING THE MOST INTERPRETABLE TREE,0.3333333333333333,"up to a tree depth of 10 by running DPDT-2 up to a depth of 6 then switch to DPTD-1 (i.e. greedy)
350"
SELECTING THE MOST INTERPRETABLE TREE,0.3341815097540288,"thereafter. The rationale is that a non-greedy approach is more critical closer to the root.
351"
SELECTING THE MOST INTERPRETABLE TREE,0.33502968617472434,"7
Limitations, Future Work, and Conclusion
352"
SELECTING THE MOST INTERPRETABLE TREE,0.33587786259541985,"Limitations. In our opinion, both the strength and the weakness of DPDT come from the choice of
353"
SELECTING THE MOST INTERPRETABLE TREE,0.33672603901611536,"the tests generating function. If the tests generating function generates too much tests in each MDP
354"
SELECTING THE MOST INTERPRETABLE TREE,0.3375742154368109,"state, the runtime will grow and there is a risk for out-of-memory errors. This can be alleviated with
355"
SELECTING THE MOST INTERPRETABLE TREE,0.3384223918575064,"parallelizing (expanding MDP states on different processes) and caching (only expand unseen MDP
356"
SELECTING THE MOST INTERPRETABLE TREE,0.33927056827820185,"states), similar to [Demirovic et al., 2022]. A rule of thumb for running DPDT on personal CPUs is
357"
SELECTING THE MOST INTERPRETABLE TREE,0.34011874469889736,"to choose a tests generating function resulting in an MDP with at most 106 states.
358"
SELECTING THE MOST INTERPRETABLE TREE,0.34096692111959287,"Future Work. DPDT could scale to bigger datasets by combining Custard [Topin et al., 2021] with
359"
SELECTING THE MOST INTERPRETABLE TREE,0.3418150975402884,"tests generating functions and tabular deep learning techniques [Kossen et al., 2021]. The latter is a
360"
SELECTING THE MOST INTERPRETABLE TREE,0.3426632739609839,"promising research avenue. The transformer-based architecture from [Kossen et al., 2021] takes a
361"
SELECTING THE MOST INTERPRETABLE TREE,0.3435114503816794,"whole train dataset as input and learns representations taking in account relationships between all
362"
SELECTING THE MOST INTERPRETABLE TREE,0.3443596268023749,"training samples and all labels. Test actions are then the output of such a neural architecture: the tests
363"
SELECTING THE MOST INTERPRETABLE TREE,0.3452078032230704,"generating function is learned.
364"
SELECTING THE MOST INTERPRETABLE TREE,0.3460559796437659,"Conclusion. In this work we solve MDPs whose optimal policies are decision trees optimizing a trade-
365"
SELECTING THE MOST INTERPRETABLE TREE,0.3469041560644614,"off between tree accuracy and complexity. We introduced the Dynamic Programming Decision Tree
366"
SELECTING THE MOST INTERPRETABLE TREE,0.3477523324851569,"algorithm that returns several optimal policies for different reward functions. DPDT has reasonable
367"
SELECTING THE MOST INTERPRETABLE TREE,0.3486005089058524,"runtimes and is able to scale to trees with depth greater than 3 using information-theoretic tests
368"
SELECTING THE MOST INTERPRETABLE TREE,0.34944868532654794,"generating functions. To the best of our knowledge, DPDT is the first scalable decision tree search
369"
SELECTING THE MOST INTERPRETABLE TREE,0.35029686174724345,"algorithm that runs fast enough on continuous attributes to be an alternative to CART for model
370"
SELECTING THE MOST INTERPRETABLE TREE,0.3511450381679389,"selection of any-depth trees. DPDT is a promising research avenue for new algorithms offering
371"
SELECTING THE MOST INTERPRETABLE TREE,0.3519932145886344,"human users a greater control than CART over tree selection in terms of generalization performance
372"
SELECTING THE MOST INTERPRETABLE TREE,0.35284139100932993,"and interpretability.
373"
REFERENCES,0.35368956743002544,"References
374"
REFERENCES,0.35453774385072095,"Sina Aghaei, Andres Gomez, and Phebe Vayanos. Learning optimal classification trees: Strong
375"
REFERENCES,0.35538592027141647,"max-flow formulations, 2020.
376"
REFERENCES,0.356234096692112,"Dimitris Bertsimas and Jack Dunn. Optimal classification trees. Machine Learning, 106:1039–1082,
377"
REFERENCES,0.3570822731128075,"2017.
378"
REFERENCES,0.35793044953350295,"Leo Breiman, Jerome Friedman, R.A. Olshen, and Charles J. Stone. Classification And Regression
379"
REFERENCES,0.35877862595419846,"Trees. Taylor and Francis, New York, 1984.
380"
REFERENCES,0.359626802374894,"Vinicius G Costa and Carlos E Pedreira. Recent advances in decision trees: An updated survey.
381"
REFERENCES,0.3604749787955895,"Artificial Intelligence Review, 56(5):4765–4800, 2023.
382"
REFERENCES,0.361323155216285,"Emir Demirovic, Anna Lukina, Emmanuel Hebrard, Jeffrey Chan, James Bailey, Christopher Leckie,
383"
REFERENCES,0.3621713316369805,"Kotagiri Ramamohanarao, and Peter J. Stuckey. Murtree: Optimal decision trees via dynamic
384"
REFERENCES,0.363019508057676,"programming and search. Journal of Machine Learning Research, 23(26):1–47, 2022. URL
385"
REFERENCES,0.3638676844783715,"http://jmlr.org/papers/v23/20-520.html.
386"
REFERENCES,0.364715860899067,"Emir Demirovi´c, Emmanuel Hebrard, and Louis Jean. Blossom: an anytime algorithm for com-
387"
REFERENCES,0.3655640373197625,"puting optimal decision trees. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara
388"
REFERENCES,0.366412213740458,"Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, Proceedings of the 40th International
389"
REFERENCES,0.3672603901611535,"Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research,
390"
REFERENCES,0.36810856658184904,"pages 7533–7562. PMLR, 23–29 Jul 2023. URL https://proceedings.mlr.press/v202/
391"
REFERENCES,0.36895674300254455,"demirovic23a.html.
392"
REFERENCES,0.36980491942324,"Abhinav Garlapati, Aditi Raghunathan, Vaishnavh Nagarajan, and Balaraman Ravindran. A rein-
393"
REFERENCES,0.3706530958439355,"forcement learning approach to online learning of decision trees, 2015.
394"
REFERENCES,0.37150127226463103,"Laurent Hyafil and Ronald L. Rivest. Constructing optimal binary decision trees is np-complete.
395"
REFERENCES,0.37234944868532655,"Information Processing Letters, 5(1):15–17, 1976. ISSN 0020-0190. doi: https://doi.org/10.1016/
396"
REFERENCES,0.37319762510602206,"0020-0190(76)90095-8. URL https://www.sciencedirect.com/science/article/pii/
397"
REFERENCES,0.37404580152671757,"0020019076900958.
398"
REFERENCES,0.3748939779474131,"Levente Kocsis and Csaba Szepesvári. Bandit based monte-carlo planning. In European conference
399"
REFERENCES,0.3757421543681086,"on machine learning, pages 282–293. Springer, 2006.
400"
REFERENCES,0.37659033078880405,"Hecotr Kohler, Riad Akrour, and Philippe Preux. Limits of actor-critic algorithms for decision tree
401"
REFERENCES,0.37743850720949956,"policies learning in ibmdps, 2023.
402"
REFERENCES,0.3782866836301951,"Jannik Kossen, Neil Band, Clare Lyle, Aidan N Gomez, Thomas Rainforth, and Yarin Gal. Self-
403"
REFERENCES,0.3791348600508906,"attention between datapoints: Going beyond individual input-output pairs in deep learning. Ad-
404"
REFERENCES,0.3799830364715861,"vances in Neural Information Processing Systems, 34:28742–28756, 2021.
405"
REFERENCES,0.3808312128922816,"Martin L. Puterman, editor. Markov Decision Processes: Discrete Stochastic Dynamic Programming.
406"
REFERENCES,0.3816793893129771,"John Wiley & Sons, Hoboken, 1994.
407"
REFERENCES,0.3825275657336726,"Zachary C. Lipton. The mythos of model interpretability: In machine learning, the concept of
408"
REFERENCES,0.3833757421543681,"interpretability is both important and slippery. Queue, 16(3):31–57, jun 2018. ISSN 1542-7730.
409"
REFERENCES,0.3842239185750636,"doi: 10.1145/3236386.3241340. URL https://doi.org/10.1145/3236386.3241340.
410"
REFERENCES,0.3850720949957591,"Rahul Mazumder, Xiang Meng, and Haoyue Wang. Quant-BnB: A scalable branch-and-bound
411"
REFERENCES,0.38592027141645463,"method for optimal decision trees with continuous features. In Kamalika Chaudhuri, Stefanie
412"
REFERENCES,0.38676844783715014,"Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato, editors, Proceedings of the
413"
REFERENCES,0.38761662425784565,"39th International Conference on Machine Learning, volume 162 of Proceedings of Machine
414"
REFERENCES,0.3884648006785411,"Learning Research, pages 15255–15277. PMLR, 17–23 Jul 2022. URL https://proceedings.
415"
REFERENCES,0.3893129770992366,"mlr.press/v162/mazumder22a.html.
416"
REFERENCES,0.39016115351993214,"Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G Bellemare,
417"
REFERENCES,0.39100932994062765,"Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, et al. Human-level control
418"
REFERENCES,0.39185750636132316,"through deep reinforcement learning. nature, 518(7540):529–533, 2015.
419"
REFERENCES,0.3927056827820187,"Cecília Nunes, Mathieu De Craene, Hélène Langet, Oscar Camara, and Anders Jonsson. Learning
420"
REFERENCES,0.3935538592027142,"decision trees through monte carlo tree search: An empirical evaluation. WIREs Data Mining
421"
REFERENCES,0.3944020356234097,"and Knowledge Discovery, 10(3):e1348, 2020. doi: https://doi.org/10.1002/widm.1348. URL
422"
REFERENCES,0.39525021204410515,"https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/widm.1348.
423"
REFERENCES,0.39609838846480067,"Rok Piltaver, Mitja Luštrek, Matjaž Gams, and Sanda Martinˇci´c-Ipši´c. What makes classification
424"
REFERENCES,0.3969465648854962,"trees comprehensible? Expert Systems with Applications, 62:333–346, 2016. ISSN 0957-4174.
425"
REFERENCES,0.3977947413061917,"doi: https://doi.org/10.1016/j.eswa.2016.06.009. URL https://www.sciencedirect.com/
426"
REFERENCES,0.3986429177268872,"science/article/pii/S0957417416302901.
427"
REFERENCES,0.3994910941475827,"Antonin Raffin, Ashley Hill, Adam Gleave, Anssi Kanervisto, Maximilian Ernestus, and Noah
428"
REFERENCES,0.4003392705682782,"Dormann. Stable-baselines3: Reliable reinforcement learning implementations. Journal of Machine
429"
REFERENCES,0.4011874469889737,"Learning Research, 22(268):1–8, 2021. URL http://jmlr.org/papers/v22/20-1364.html.
430"
REFERENCES,0.4020356234096692,"J. Rissanen. Modeling by shortest data description. Automatica, 14(5):465–471, 1978. ISSN 0005-
431"
REFERENCES,0.4028837998303647,"1098. doi: https://doi.org/10.1016/0005-1098(78)90005-5. URL https://www.sciencedirect.
432"
REFERENCES,0.4037319762510602,"com/science/article/pii/0005109878900055.
433"
REFERENCES,0.40458015267175573,"John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy
434"
REFERENCES,0.40542832909245125,"optimization algorithms. CoRR, abs/1707.06347, 2017. URL http://arxiv.org/abs/1707.
435"
REFERENCES,0.40627650551314676,"06347.
436"
REFERENCES,0.4071246819338422,"Olivier Sigaud and Olivier Buffet. Markov decision processes in artificial intelligence. John Wiley &
437"
REFERENCES,0.4079728583545377,"Sons, 2013.
438"
REFERENCES,0.40882103477523324,"Nicholay Topin, Stephanie Milani, Fei Fang, and Manuela Veloso. Iterative bounding MDPs:
439"
REFERENCES,0.40966921119592875,"Learning interpretable policies via non-interpretable methods. Proceedings of the AAAI Conference
440"
REFERENCES,0.41051738761662426,"on Artificial Intelligence, 35(11):9923–9931, May 2021. doi: 10.1609/aaai.v35i11.17192. URL
441"
REFERENCES,0.4113655640373198,"https://ojs.aaai.org/index.php/AAAI/article/view/17192.
442"
REFERENCES,0.4122137404580153,"Jacobus van der Linden, Mathijs de Weerdt, and Emir Demirovi´c. Necessary and sufficient conditions
443"
REFERENCES,0.41306191687871074,"for optimal decision trees using dynamic programming. In A. Oh, T. Neumann, A. Globerson,
444"
REFERENCES,0.41391009329940626,"K. Saenko, M. Hardt, and S. Levine, editors, Advances in Neural Information Processing Systems,
445"
REFERENCES,0.41475826972010177,"volume 36, pages 9173–9212. Curran Associates, Inc., 2023.
446"
REFERENCES,0.4156064461407973,"Sicco Verwer and Yingqian Zhang. Learning optimal classification trees using a binary linear program
447"
REFERENCES,0.4164546225614928,"formulation. In Proceedings of the AAAI conference on artificial intelligence, volume 33, pages
448"
REFERENCES,0.4173027989821883,"1625–1632, 2019.
449"
REFERENCES,0.4181509754028838,"A
Code links
450"
REFERENCES,0.41899915182357933,"Quant-BnB.
The
Julia
code
for
Quant-BnB
is
available
at
https://github.com/
451"
REFERENCES,0.4198473282442748,"mengxianglgal/Quant-BnB.
452"
REFERENCES,0.4206955046649703,"CART. We use the scikit-learn Cython implementation of CART available at https://
453"
REFERENCES,0.4215436810856658,"scikit-learn.org/stable/modules/tree.html#tree-classification with the criterion
454"
REFERENCES,0.4223918575063613,"parameter fixed to “entropy”.
455"
REFERENCES,0.42324003392705684,"MurTree, Pystreed. Codes are available at https://github.com/MurTree/pymurtree and at
456"
REFERENCES,0.42408821034775235,"https://github.com/AlgTUDelft/pystreed.
457"
REFERENCES,0.42493638676844786,"B
On the failure of deep reinforcement learning.
458"
REFERENCES,0.4257845631891433,"For the dataset X = {(1, 2), (2, 1), (3, 4), (4, 3)}, Y = {0, 1, 2, 3} both our MDP and IBMDP are
459"
REFERENCES,0.42663273960983883,"equivalent for learning the optimal decision tree of depth 2. We show on Fig. 4 that two different
460"
REFERENCES,0.42748091603053434,"DRL algorithms exhibit opposite performance: DQN can learn the optimal decision tree while PPO
461"
REFERENCES,0.42832909245122985,"[Schulman et al., 2017] cannot. For that reason, we only trained Custard using DQN as the DRL agent.
462"
REFERENCES,0.42917726887192537,"We see on Fig. 4 and Table 1 that Custard-5 converged to trees worst than CART for all classification
463"
REFERENCES,0.4300254452926209,"datasets. This shows that while more scalable, DRL approaches are still not competitive on these
464"
REFERENCES,0.4308736217133164,"types of problems. [Kohler et al., 2023] studied potential failure modes of DRL in our setting.
465"
REFERENCES,0.43172179813401185,"100
200
300
400
500
600
walltime in sec. 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0"
REFERENCES,0.43256997455470736,cumulative MDP rewards
REFERENCES,0.43341815097540287,"DQN
PPO
Opt. Depth 2 Tree"
REFERENCES,0.4342663273960984,"0
200
400
600
800
1000
walltime in sec. 1.0 0.8 0.6 0.4 0.2 0.0"
REFERENCES,0.4351145038167939,DQN-5 cumulative MDP rewards
REFERENCES,0.4359626802374894,"avila
bank
bean
bidding
eeg
fault
htru
magic
occupancy
page
raisin
rice
room
segment
skin
wilt"
REFERENCES,0.4368108566581849,"Figure 4: Left, DRL to learn the optimal depth 2 tree. Right, Custard-5 to learn depth 3 decision trees
on classification datasets"
REFERENCES,0.43765903307888043,"C
Tree plots
466 7"
REFERENCES,0.4385072094995759,x18 ≤ 0.047 3
REFERENCES,0.4393553859202714,"(a) A=0.5, N=3, T=1 7
  6"
REFERENCES,0.4402035623409669,x12 ≤ 0.5
REFERENCES,0.4410517387616624,x14 ≤ 0.192
REFERENCES,0.44189991518235794,x11 ≤ 0.236
REFERENCES,0.44274809160305345,x17 ≤ 0.462 7
REFERENCES,0.44359626802374896,"x18 ≤ 0.047 2
  2 4
  7"
REFERENCES,0.4444444444444444,x15 ≤ 0
REFERENCES,0.44529262086513993,"(b) A=0.69, N=13, T=2.9"
REFERENCES,0.44614079728583544,"7
  7
   7"
REFERENCES,0.44698897370653096,x5 ≤ 0
REFERENCES,0.44783715012722647,x18 ≤ 0.047
REFERENCES,0.448685326547922,x25 ≤ 0.73
REFERENCES,0.4495335029686175,"x11 ≤ 0.236
x11 ≤ 0.249 3 4 7"
REFERENCES,0.45038167938931295,"(c) A=0.53, N=11, T=3.2"
REFERENCES,0.45122985581000846,"7
  7
   7"
REFERENCES,0.452078032230704,x5 ≤ 0
REFERENCES,0.4529262086513995,x18 ≤ 0.047
REFERENCES,0.453774385072095,x25 ≤ 0.73
REFERENCES,0.4546225614927905,"x11 ≤ 0.236
x11 ≤ 0.249 7
  6 3 4"
REFERENCES,0.455470737913486,x14 ≤ 0.019
REFERENCES,0.45631891433418154,"(d) A=0.55, N=13, T=3.6"
REFERENCES,0.457167090754877,"Figure 5: Trees for the fault dataset. Top: trees from DPDT. Bottom: trees from CART. A is accuracy,
N the number of nodes, T the average number of tests."
REFERENCES,0.4580152671755725,"D
Schematics DTDP
467"
REFERENCES,0.458863443596268,"E
Detailed res of model selection
468"
REFERENCES,0.45971162001696353,"F
Comparisons with baselines operating on binary datasets
469"
REFERENCES,0.46055979643765904,"F.1
Why comparisons with baselines that binarize datasets is not fair in our favor?
470"
REFERENCES,0.46140797285835455,"Algorithms finding optimal DTs for binary datasets such as MurTree [Demirovic et al., 2022] use
471"
REFERENCES,0.46225614927905007,"a binarization method to transform a dataset with continuous attributes to a dataset with binary
472"
REFERENCES,0.4631043256997455,"attributes. However, a DT learned on the binary dataset, whenever it tests the value of a binary
473"
REFERENCES,0.46395250212044103,"attribute, can lead to up to two tests on the respective continuous attribute. Hence, DTs of a given
474"
REFERENCES,0.46480067854113655,"maximum depth on the binary dataset are actually deeper if transformed into DTs on the original
475"
REFERENCES,0.46564885496183206,"dataset with continuous attributes. Despite this, we show in Table 1 of this supplementary material
476"
REFERENCES,0.46649703138252757,"class
class y"
REFERENCES,0.4673452078032231,"x ≤ 0.2
x ≤ 0.6
y ≤ 0.3"
REFERENCES,0.4681933842239186,"done
done"
REFERENCES,0.46904156064461405,"p = 1
r = -1/3"
REFERENCES,0.46988973706530957,"p = 1
r = -2/3"
REFERENCES,0.4707379134860051,"p = 1/3
    r = 𝛼"
REFERENCES,0.4715860899067006,"p = 1/3
     r = 𝛼"
REFERENCES,0.4724342663273961,"p = 2/3
     r = 𝛼
  p = 1/3
       r = 𝛼 class done"
REFERENCES,0.4732824427480916,"p = 1
   r = 0 class done"
REFERENCES,0.4741306191687871,"p = 1
r = -1/2 class done class done"
REFERENCES,0.47497879558948264,"p = 1
   r = 0 class done"
REFERENCES,0.4758269720101781,"p = 1
   r = 0 class done class done class done"
REFERENCES,0.4766751484308736,"p = 2/3
    r = 𝛼"
REFERENCES,0.4775233248515691,"p = 2/3
    r = 𝛼"
REFERENCES,0.47837150127226463,"p = 1
   r = 0"
REFERENCES,0.47921967769296014,"p = 1
 r = -1/2"
REFERENCES,0.48006785411365566,"p = 1
 r = -1/2
   p = 1
r = -1/2"
REFERENCES,0.48091603053435117,"Figure 6: MDP for a training dataset made of three samples (illustrated with an oval and 2 diamonds),
two continuous attributes (x and y), and two classes. The tests generating function generated three
possible tests. There is an initial state (D, 0) (the training dataset at depth 0), and six non-terminal
states (three tests times two children states). Rewards are either α or the misclassification, and
transition probabilities are one, or the size of the child state over the size of the parent. class class y"
REFERENCES,0.4817642069550466,"x ≤ 0.2
x ≤ 0.6"
REFERENCES,0.48261238337574214,y ≤ 0.3
REFERENCES,0.48346055979643765,"done
done x  class done"
REFERENCES,0.48430873621713316,"Q𝛼*(s,a) = [0,0] class done class done class done class done class done class done class done [0,0]"
REFERENCES,0.4851569126378287,"[-1/3,-1/3]"
REFERENCES,0.4860050890585242,"[-2/3,-2/3]"
REFERENCES,0.4868532654792197,"[-½,-½ ]
[-½,-½ ] [0,0]
[0,0]
[-½ ,-½]
[-½ ,-½]"
REFERENCES,0.48770144189991516,"[-4/3 , -1/3]
[-1 ,0]"
REFERENCES,0.48854961832061067,"[-4/3 , -1/3]"
REFERENCES,0.4893977947413062,"Figure 7: For α = 0 and α = 1, the values of Q∗(s, a, α) are backpropagated from leaf states to the
initial state and are given in squared brackets. The optimal policy π∗(., α = 1), in pink, is a depth-0
tree with accuracy 2"
REFERENCES,0.4902459711620017,"3. The optimal policy π∗(., α = 0), in green, is a depth-1 tree with accuracy 1."
REFERENCES,0.4910941475826972,"Table 2: Trees of depth ≤5 selected with the procedure described in Sec. 6.3.
Datasets
Accuracy (%) on unseen data
Runtime (s.)
Average Nb.Tests
Names
DPDT-3
DPDT-2
CART
Quant-BnB
MurTree
Pystreed
DPDT-3
DPDT-2
CART
DPDT-3
DPDT-2
CART
avila
66.9
65.7
60.5
57.3
OOM
OOM
51.625
2.701
1.031
4.9
4.9
4.8
bank
99.3
97.8
99.3
97.8
48.6
48.6
2.054
0.353
0.031
3.2
3.7
3.4
bean
91.1
91.1
89.9
84.7
OOM
OOM
88.142
7.571
5.369
4.6
4.9
5.0
bidding
99.2
99.2
99.2
98.5
97.5
97.5
2.963
0.545
0.081
1.4
1.4
2.3
eeg
78.0
74.6
73.0
73.0
OOM
OOM
57.038
4.347
0.892
4.6
4.8
5.0
fault
71.8
72.8
57.9
61.2
OOM
OOM
35.185
2.611
0.536
5.0
4.5
4.9
htru
98.0
98.3
98.3
97.9
OOM
91.2
63.519
5.189
2.174
1.1
2.4
4.7
magic
84.5
84.8
82.5
82.1
OOM
OOM
98.623
7.06
3.189
5.0
4.8
5.0
occupancy
99.5
99.5
99.5
96.3
OOM
82.3
11.113
1.263
0.162
1.0
1.0
1.4
page
97.1
97.1
96.7
95.8
OOM
93.4
26.596
2.547
0.369
3.5
5.0
4.8
raisin
87.8
91.1
90.0
89.0
45.6
45.6
7.756
1.775
0.069
3.1
2.3
4.5
rice
93.7
94.2
93.4
93.9
87.1
87.1
17.915
1.693
0.356
1.6
1.7
3.6
room
99.2
99.4
99.4
98.6
OOM
OOM
19.134
1.574
0.247
2.5
2.3
4.1
segment
93.5
93.1
87.4
82.7
OOM
OOM
6.488
0.879
0.184
3.7
3.9
3.9
skin
99.5
99.2
98.6
98.6
OOM
OOM
265.243
18.066
1.985
3.8
3.8
4.2
wilt
87.2
84.8
87.6
81.3
70.4
70.4
3.898
0.462
0.125
4.1
3.2
3.9"
REFERENCES,0.4919423240033927,"that DPDT typically finds better solutions (in terms of training accuracy) than MurTree + binarization
477"
REFERENCES,0.49279050042408823,"even though the comparison is not fair in our favor since MurTree is considering deeper trees.
478"
REFERENCES,0.49363867684478374,"To illustrate this unbalance with an example, we present a dataset with 3 samples, 2 classes, and 1
479"
REFERENCES,0.4944868532654792,"continuous attribute. After binning the continuous attribute and binarizing the dataset into 3 binary
480"
REFERENCES,0.4953350296861747,"attributes, we compute the optimal depth 1 tree like [Demirovic et al., 2022] or [Verwer and Zhang,
481"
REFERENCES,0.4961832061068702,"2019] would do. To apply this depth 1 tree to the original continuous attribute dataset, the root node
482"
REFERENCES,0.49703138252756573,"""a ∈[0.2, 0.22]"" should be decomposed in two decision nodes ""a ≤0.19"" and ""a ≤0.22"" before
483"
REFERENCES,0.49787955894826125,"making a label assignment. So the corresponding tree that can be applied on the continuous attribute
484"
REFERENCES,0.49872773536895676,"is actually of depth 2.
485"
REFERENCES,0.49957591178965227,"a
y
x1
0.1
1
x2
0.2
2
x3
0.22
2
x4
0.3
1 →"
REFERENCES,0.5004240882103478,"[0, 0.19]
[0.2, 0.22]
[0.23, 0.3]
y
x1
1
0
0
1
x2
0
1
0
2
x3
0
1
0
2
x3
0
0
1
1 486 ←
487"
REFERENCES,0.5012722646310432,"F.2
Experiments
488"
REFERENCES,0.5021204410517388,"Comparing baselines such as [Verwer and Zhang, 2019] or [Demirovic et al., 2022] to DPDT or
489"
REFERENCES,0.5029686174724343,"Quant-BnB [Mazumder et al., 2022] that operate directly on continuous attributes with the same
490"
REFERENCES,0.5038167938931297,"maximum depth is not fair in favor of the latter algorithms as discussed above. Still, for the sake of
491"
REFERENCES,0.5046649703138253,"curiosity we performed comparisons on datasets of prior works. These can be split into two groups.
492"
REFERENCES,0.5055131467345207,"1) MurTree:
Demirovic et al. [2022] propose an algorithm that retrieves optimal trees for large
493"
REFERENCES,0.5063613231552163,"datasets with binary features using dynamic programming. They also propose a binarization method
494"
REFERENCES,0.5072094995759118,"to retrieve suboptimal shallow trees for large datasets with continuous features. We do not run
495"
REFERENCES,0.5080576759966073,"MurTree but use of the results in Table 6 from Mazumder et al. [2022] (see the “approx” column)
496"
REFERENCES,0.5089058524173028,"which previously compared Quant-BnB to MurTree.
497"
REFERENCES,0.5097540288379983,"2) OCT, MFOCT, BinOCT:
Bertsimas and Dunn [2017], Aghaei et al. [2020], Verwer and
498"
REFERENCES,0.5106022052586938,"Zhang [2019] propose optimal tree algorithms which formulate the learning problem as a MIP.
499"
REFERENCES,0.5114503816793893,"OCT and MFOCT can produce optimal trees for small datasets with continuous features. BinOCT
500"
REFERENCES,0.5122985581000848,"can also produce optimal trees for small datasets with continuous features after they have been
501"
REFERENCES,0.5131467345207803,"binarized. We make use of the results available at https://github.com/LucasBoTang/Optimal_
502"
REFERENCES,0.5139949109414759,"Classification_Trees.
503"
REFERENCES,0.5148430873621713,"Reproducibility:
as mentioned above, we did not run the additional baselines but instead used
504"
REFERENCES,0.5156912637828668,"available results. As such runtimes were provided only when available. OCT, MFOCT, BinOCT were
505"
REFERENCES,0.5165394402035624,"run on a single core of an Intel(R) Core(TM) CPU i7-7700HQ @ 2.80GHz. MurTree was run
506"
REFERENCES,0.5173876166242578,"on a single core of a Intel Xeon 2.30GHz. According to online benchmarks the performances of
507"
REFERENCES,0.5182357930449534,"those machines are similar to our Laptopt CPU Intel® Core™i7-8665U CPU.
508"
REFERENCES,0.5190839694656488,"G
Markov Decision Problem formulations of the Decision Tree Learning
509"
REFERENCES,0.5199321458863444,"Problem
510"
REFERENCES,0.5207803223070399,"In this section we compare our Markov Decision Problem (MDP) formulation of decision tree
511"
REFERENCES,0.5216284987277354,"learning from Section 4 to that of prior work, namely [Garlapati et al., 2015] and [Topin et al.,
512"
REFERENCES,0.5224766751484309,"2021]. In a nutshell, prior work viewed the task as a deterministic and Partially Observable MDP
513"
REFERENCES,0.5233248515691263,"[Sigaud and Buffet, 2013] and used algorithms such as Q-learning [Garlapati et al., 2015] or deep
514"
REFERENCES,0.5241730279898219,"Q-learning [Topin et al., 2021] to solve them in an online fashion one datum from the dataset at a
515"
REFERENCES,0.5250212044105174,"time. Our approach is different in that it builds a stochastic and fully observable MDP. Our MDP
516"
REFERENCES,0.5258693808312129,"makes it possible to perform two operations that are critical for DPDT: i) being able to call the
517"
REFERENCES,0.5267175572519084,"tests generating function which does not operate online but needs full offline access of the dataset
518"
REFERENCES,0.527565733672604,"ii) being able to efficiently compute through dynamic programming optimal policies for different
519"
REFERENCES,0.5284139100932994,"complexity-performance trade-offs, which is critical in practice as our improved training accuracy
520"
REFERENCES,0.5292620865139949,"compared to greedy methods would otherwise quickly lead to overfitting. High level differences
521"
REFERENCES,0.5301102629346904,"Datasets
Accuracy of depth-3 trees
Names
Samples
Features
Classes
Opt.
DPDT-5
DPDT-4
MurTree
CART
avila
10430
10
12
58.5%
58.5∗%
58 %
58.5∗%
53.2%
bank
1097
4
2
98.3%
98%
98%
97.3%
93.3%
bean
10888
16
7
87.1%
85.6%
85%
86.9%
77.7%
bidding
5056
9
2
99.3%
99.3∗%
99.3%
98.1%
98.1%
eeg
11984
14
2
70.8%
70.3%
70%
68.8%
66.6%
fault
1552
27
7
68.2%
68%
65.7%
67.3%
55.3%
htru
14318
8
2
98.1%
98%
98%
97.9%
97.9%
magic
15216
10
2
83.1%
83%
82.7%
81.1%
80.1%
occupancy
8143
5
2
99.4%
99.4∗%
99.3%
99.1%
98.9%
page
4378
10
5
97.1%
97%
97%
96.6%
96.4%
raisin
720
7
2
89.4%
88.5%
88.3%
87.5%
86.9%
rice
3048
7
2
93.8%
93.7%
93.6%
93.4%
93.3%
room
8103
16
4
99.2%
99.2∗%
99.2%
99.2∗%
96.8%
segment
1848
18
7
88.7%
88.2%
88.2%
88.1%
57.4%
skin
196045
3
2
96.9%
96.7%
96.7%
96.8%
96.6%
wilt
4339
5
2
99.6%
99.5%
99.5%
98.7%
99.3%
Table 3: Training accuracy of different decision tree learning algorithms. All algorithms learn trees
of depth at most 3 on 16 classification datasets. MurTree returns decision trees for datasets binarized
using using the minimum description length principle. Results for MurTree are taken from Tables 2
and 6 from [Mazumder et al., 2022]."
REFERENCES,0.5309584393553859,"Datasets
Train Accuracy depth-5
Test Accuracy depth-5
Runtime depth-5
Names
Samples
Features
Classes
DPDT-4
DPDT-5
OCT
MFOCT
BinOCT
CART
DPDT-4
DPDT-5
OCT
MFOCT
BinOCT
CART
DPDT-4
DPDT-5
OCT
MFOCT
BinOCT
CART
balance-scale
624
4
3
90.9%
91.0%
71.8%
82.6%
67.5%
86.5%
77.1%
74.8%
66.9%
71.3%
61.6%
76.4%
68.34
401.71
605.51
600.1
603.95
< 0.001
breast-cancer
276
9
2
94.2%
94.7%
88.6%
91.1%
75.4%
87.9%
66.4%
67.6%
67.1%
73.8%
62.4%
70.3%
19.09
62.36
603.39
600.25
603.67
0.001
car-evaluation
1728
6
4
92.2%
92.2%
70.1%
80.4%
84.0%
87.1%
90.3%
90.3%
69.5%
79.8%
82.3%
87.1%
5.39
38.07
618.09
600.49
613.14
< 0.001
hayes-roth
160
9
3
93.3%
94.2%
82.9%
95.4%
64.6%
76.7%
75.4%
71.2%
77.5%
77.5%
54.2%
69.2%
0.91
2.58
602.02
600.19
601.83
0.001
house-votes-84
232
16
2
100.0%
100.0%
100.0%
100.0%
100.0%
99.4%
95.4%
95.4%
93.7%
94.3%
96.0%
95.1%
0.44
0.65
105.72
10.74
6.6
< 0.001
soybean-small
46
50
4
100.0%
100.0%
100.0%
100.0%
76.8%
100.0%
93.1%
93.1%
94.4%
91.7%
72.2%
93.1%
0.01
0.01
4.18
0.41
1.84
< 0.001
spect
266
22
2
93.0%
93.0%
92.5%
93.0%
92.2%
88.5%
73.1%
73.9%
75.6%
74.6%
73.1%
75.1%
6.32
16.78
604.87
600.33
605.57
0.001
tic-tac-toe
958
24
2
90.8%
91.1%
68.5%
76.1%
85.7%
85.8%
82.1%
82.5%
69.6%
73.6%
79.6%
81.0%
107.94
626.34
615.28
600.45
621.81
0.001"
REFERENCES,0.5318066157760815,"Table 4: Train/test accuracies and runtimes of different decision tree learning algorithms. Note that
we are not using any regularization in this experiment (in order for all solvers to optimize the same
objective function) and as such we might overfit compared to CART that does not optimize the
training error as intensively. All algorithms learn trees of depth at most 5 on 8 classification datasets.
A time limit of 10 minutes is set for OCT-type algorithms. DPDT is used with two different test
generating functions: CART with a maximum depth of 4 and CART with a maximum depth of 5.
The values in this table are averaged over 3 seeds giving 3 different train/test datasets."
REFERENCES,0.5326547921967769,"between MDPs are summarized in Table 5. For the sake of self-completeness we then detail both
522"
REFERENCES,0.5335029686174725,"MDPs of [Topin et al., 2021] and [Garlapati et al., 2015] which are to be contrasted with our MDP
523"
REFERENCES,0.5343511450381679,"formulation in Section 4.
524"
REFERENCES,0.5351993214588634,"Table 5: MDP formulations of the decision tree learning problem
MDP properties
IBMDP [Topin et al., 2021]
[Garlapati et al., 2015]
Ours
Training samples attributes
Any
Categorical
Any
Discounted
Yes
Yes
No
Horizon
Infinite
Finite
Finite
States
Partial information about a single training sample
Partial information about a single training sample
A full dataset in P(D)
Actions
Tests and label assignments
State dependent tests and label assignments
State dependent tests and label assignments
Transitions
Deterministic
Deterministic
Stochastic"
REFERENCES,0.536047497879559,"G.1
Iteratvie Bounding MDPs
525"
REFERENCES,0.5368956743002544,"An IBMDP [Topin et al., 2021] is an episodic, infinite horizon, discounted MDP. IBMDPs can be
526"
REFERENCES,0.53774385072095,"used for learning decision trees of any base MDP. We discuss here the case where the base MDP is a
527"
REFERENCES,0.5385920271416454,"classification task. In this case, during each episode, an agent has to classify a hidden training sample
528"
REFERENCES,0.539440203562341,"xi drawn uniformly from a training dataset with continuous attributes. We assume whiteout loss of
529"
REFERENCES,0.5402883799830365,"generality that the training dataset X ⊂[0, 1]N×p has continuous attributes in [0, 1]. On the other
530"
REFERENCES,0.5411365564037319,"hand, the set of labels is Y = {1, ..., K}. An IBMDP is defined as follows.
531"
REFERENCES,0.5419847328244275,"State space: the state space is the hypercube [0, 1]3·p. A IBMDP state has two parts. The continuous
532"
REFERENCES,0.542832909245123,"attributes of the hidden training sample xi = (xi1, ..., xip) to classify, and a lower and upper
533"
REFERENCES,0.5436810856658185,"bound (Lk, Uk) for each of the p attributes. For each attribute xik, (Lk, Uk) represents the current
534"
REFERENCES,0.544529262086514,"agent knowledge about its hidden value. Initially, (Lk, Uk) = (0, 1) for all k, which are iteratively
535"
REFERENCES,0.5453774385072095,"refined by taking tests actions.
536"
REFERENCES,0.546225614927905,"Action space: an agent in an IBMDP can either take an assignment action a ∈Y, or a test action
537"
REFERENCES,0.5470737913486005,"1{xik≤v·(Uk−Lk)+Lk} with k ∈{1, . . . , p} and v ∈{
1
d+1, ...,
d
d+1}, with d ∈N a hyperparameter of
538"
REFERENCES,0.547921967769296,"the IBMDP.
539"
REFERENCES,0.5487701441899915,"Transition function: if an agent takes a label assignment action, the IBMDP transits to a ter-
540"
REFERENCES,0.549618320610687,"minal state, a new training sample x is drawn at random from X, and the attributes bounds
541"
REFERENCES,0.5504664970313825,"(L1, ..., Lp, U1, .., Up) are reset to 0 or 1. If an agent takes a test action, the attributes bounds
542"
REFERENCES,0.5513146734520781,"are refined. Let xik be the value of the k-th attribute of the hidden training sample xi, and (Lk, Uk)
543"
REFERENCES,0.5521628498727735,"be the current bounds of xik. If 1{xik≤v·(Uk−Lk)+Lk} is true, then Lk is updated to v·(Uk−Lk)+Lk,
544"
REFERENCES,0.553011026293469,"else, it is Uk that is updated to v · (Uk −Lk) + Lk.
545"
REFERENCES,0.5538592027141646,"Reward function: the reward for assigning the label yi ∈Y to the hidden training sample xi is
546"
REFERENCES,0.55470737913486,"1a=yi · r+ + 1a̸=yi · r−, with r+ > 0 and r−< 0. The reward for taking a test action is α < 0.
547"
REFERENCES,0.5555555555555556,"G.2
MDP formulation of [Garlapati et al., 2015]
548"
REFERENCES,0.556403731976251,"MDP formulations based on [Garlapati et al., 2015] assume categorical attributes, i.e, the training
549"
REFERENCES,0.5572519083969466,"dataset D is in ZN×p. The MDP is episodic with a discount factor and a finite horizon p + 1. An
550"
REFERENCES,0.5581000848176421,"episode of this MDP consists of costly queries of a training sample’s attributes until a label assignment
551"
REFERENCES,0.5589482612383376,"is made.
552"
REFERENCES,0.5597964376590331,"State space: a state of the above MDP has partial information about a training sample to classify.
553"
REFERENCES,0.5606446140797285,"At every step of the MDP, an agent queries a hidden attribute and updates its knowledge about the
554"
REFERENCES,0.5614927905004241,"training sample by concatenating all revealed attributes.
555"
REFERENCES,0.5623409669211196,"Acion space: at every step t in the MDP, an agent can either assign a class label in Y = {1, ..., K},
556"
REFERENCES,0.5631891433418151,"or, make a query at of a hidden attribute of a training sample: At = ({1, ..., p} \
t−1
S"
REFERENCES,0.5640373197625106,"h=0
ah) ∪Y.
557"
REFERENCES,0.5648854961832062,"Transition function: the current state of the MDP contains values of previously queried attributes.
558"
REFERENCES,0.5657336726039016,"At t = 0, s = {}. Assuming the hidden training sample to be classified during the current episode
559"
REFERENCES,0.5665818490245971,"is xi = (xi1, ..., xip), then the deterministic transition function is: T(s, a = xij) = s ∪xij or
560"
REFERENCES,0.5674300254452926,"T(s, a ∈Y) = sterminal. At the start of a new episode, a new training sample is drawn uniformly
561"
REFERENCES,0.5682782018659881,"from D.
562"
REFERENCES,0.5691263782866837,"Reward function: at time t, when the hidden training sample to classify is xi, if the an agent takes
563"
REFERENCES,0.5699745547073791,"an assignment action a ∈D, the reward is 1a=yi · r+ + 1a̸=yi · r−, with r+ > 0 and r−< 0. So an
564"
REFERENCES,0.5708227311280747,"agent gets a positive signal for making a correct label assignment and negative signal otherwise. If
565"
REFERENCES,0.5716709075487701,"the agent takes a query action, the reward is a negative value α in order to discourage taking to much
566"
REFERENCES,0.5725190839694656,"queries and control the tree complexity.
567"
REFERENCES,0.5733672603901612,"H
Proof of equivalence of learning objectives
568"
REFERENCES,0.5742154368108566,"In this section, we prove the equivalence between learning an optimal policy in the MDP of Section
569"
REFERENCES,0.5750636132315522,"4 and finding the minimizing tree of Eq. (2). We first define C(T), the expected number of tests
570"
REFERENCES,0.5759117896522477,"performed by tree T on dataset D. Here T is induced by policy π, i.e. T = E(π, s0). C(T) can be
571"
REFERENCES,0.5767599660729432,"defined recursively as C(T) = 0 if T is a leaf node, and C(T) = 1 + plC(Tl) + prC(Tr), where
572"
REFERENCES,0.5776081424936387,"Tl = E(π, sl) and Tr = E(π, sr). In words, when the root of T is a test node, the expected number
573"
REFERENCES,0.5784563189143341,"of tests is one plus the expected number of tests of the left and right sub-trees of the root node.
574"
REFERENCES,0.5793044953350297,"For the purpose of the proof, we overload the definition of Jα and Lα, to make explicit the dependency
575"
REFERENCES,0.5801526717557252,"on the dataset and the maximum depth. As such, Jα(π) becomes Jα(π, D, D) and Lα(T) becomes
576"
REFERENCES,0.5810008481764207,"Lα(T, D). Let us first show that the relation Jα(π, D, 0) = −Lα(T, D) is true. If the maximum
577"
REFERENCES,0.5818490245971162,"depth is D = 0 then π(s0) is necessarily a class assignment, in which case the expected number of
578"
REFERENCES,0.5826972010178118,"tests is zero and the relation is obviously true since the reward is minus the average classification loss.
579"
REFERENCES,0.5835453774385072,"Now assume it is true for any dataset and tree of depth at most D with D ≥0 and let us prove that it
580"
REFERENCES,0.5843935538592027,"holds for all trees of depth D + 1. For a tree T of depth D + 1 the root is necessarily a test node.
581"
REFERENCES,0.5852417302798982,"Let Tl = E(π, sl) and Tr = E(π, sr) be the left and right sub-trees of the root node of T. Since
582"
REFERENCES,0.5860899067005937,"both sub-trees are of depth at most D, the relation holds and we have Jα(π, Xl, D) = Lα(Tl, Xl)
583"
REFERENCES,0.5869380831212893,"and Jα(π, Xr, D) = Lα(Tr, Xr), where Xl and Xr are the datasets of the “right"" and “left"" states
584"
REFERENCES,0.5877862595419847,"to which the MDP transitions—with probabilities pl and pr—upon application of π(s0) in s0, as
585"
REFERENCES,0.5886344359626803,"described in the MDP formulation. Moreover, from the definition of the policy return we have
586"
REFERENCES,0.5894826123833757,"Jα(π, D, D + 1) = −α + pl ∗Jα(π, Xl, D) + pr ∗Jα(π, Xr, D)
= −α −pl ∗Lα(Tl, Xl) −pr ∗Lα(Tr, D)"
REFERENCES,0.5903307888040712,= −α −pl ∗
REFERENCES,0.5911789652247668,"1
|Xl| X"
REFERENCES,0.5920271416454622,"(xi,yi)∈Xl
ℓ(yi, Tl(xi)) + αC(Tl) ! −pr ∗"
REFERENCES,0.5928753180661578,"1
|Xr| X"
REFERENCES,0.5937234944868532,"(xi,yi)∈Xr
ℓ(yi, Tr(xi)) + αC(Tr) ! = −1 N X"
REFERENCES,0.5945716709075488,"(xi,yi)∈X
ℓ(yi, T(xi)) −α(1 + plC(Tl) + prC(Tr))"
REFERENCES,0.5954198473282443,"= −L(T, D)"
REFERENCES,0.5962680237489398,"I
Deeper trees experiments
587"
REFERENCES,0.5971162001696353,"In this section, we push the limits of DPDT to learn trees of at most depth 10. We run two instances
588"
REFERENCES,0.5979643765903307,"of DPDT. The first one will generate a MDP using a depth dependant tests generating function.
589"
REFERENCES,0.5988125530110263,"DPDT-2... generates a MDP where actions availabe at states corresponding to depth ≤5 are given by
590"
REFERENCES,0.5996607294317218,"running CART with a maximum depth of 2, and actions for other states are given by CART with a
591"
REFERENCES,0.6005089058524173,"maximum depth of 1 (the maximum information gain splits given the dataset X in the state ((X, d))).
592"
REFERENCES,0.6013570822731128,"DPDT-2+1... generates a bigger MDP than DPDT-2... as actions available to states with depths up to
593"
REFERENCES,0.6022052586938084,"6 are given by CART run with a maximum depth of 2. On Table 6 we observe that deep trees learnt
594"
REFERENCES,0.6030534351145038,"by CART and DPDT perform similarly well on unseen data of different classificiation problems.
595"
REFERENCES,0.6039016115351993,"CART runs way faster than DPDT to compute deep trees. However, DPDT learns more interpretable
596"
REFERENCES,0.6047497879558948,"trees with respect to the average number of tests performed on data which is a very useful feature
597"
REFERENCES,0.6055979643765903,"for real-life applications such as medicine where each additional test before a diagnostic can be very
598"
REFERENCES,0.6064461407972859,expensive (for example performing an addition MRI scan).
REFERENCES,0.6072943172179813,Table 6: Test accuracy of trees of depth ≤10 selected with the procedure described in Sec. 6.2.
REFERENCES,0.6081424936386769,"Datasets
Accuracy (%) on unseen data
Runtime (s.)
Average Nb.Tests
Names
DPDT-2...
DPDT-2+1...
CART
DPDT-2...
DPDT-2+1...
CART
DPDT-2...
DPDT-2+1...
CART
avila
94.3
95.1
87.8
86.476
187.313
1.579
8.4
8.4
8.8
bank
99.3
99.3
99.3
1.664
2.174
0.028
3.3
3.3
3.4
bean
91.3
90.9
91.2
102.796
309.981
8.287
5.2
4.0
6.1
bidding
99.4
99.4
99.4
1.833
3.226
0.095
2.4
2.4
2.4
eeg
83.6
83.5
82.0
85.198
229.49
2.386
8.1
8.2
9.3
fault
73.3
73.8
68.7
35.09
108.265
1.148
5.6
5.6
6.9
htru
97.6
98.0
98.1
45.941
123.689
4.234
2.2
1.2
3.4
magic
85.4
84.9
84.8
146.253
391.594
7.021
5.8
5.9
8.1
occupancy
99.5
99.5
99.5
6.847
15.608
0.226
1.0
1.0
1.4
page
96.5
96.9
96.5
22.526
58.102
0.713
4.5
6.2
7.7
raisin
85.6
86.7
88.9
8.717
19.652
0.115
2.1
2.1
6.5
rice
93.4
93.2
93.7
20.18
44.867
0.626
1.8
1.8
3.0
room
99.3
99.6
99.6
5.186
8.55
0.318
2.3
4.1
4.1
segment
97.0
97.0
94.8
9.796
22.562
0.286
5.1
5.1
5.0
skin
99.9
99.9
99.8
120.576
308.577
2.94
6.3
6.2
5.4
wilt
86.0
86.0
84.8
2.274
3.583
0.151
4.3
4.4
4.4 599"
REFERENCES,0.6089906700593724,"J
Additional comparisons with Quant-BnB
600"
REFERENCES,0.6098388464800678,"In Table 7 we compare DPDT with Quant-BnB on train and test sets of different classification
601"
REFERENCES,0.6106870229007634,"problems. Quant-BnB has a time limit equal to DPDT-5’ runtime on each problem. We also run
602"
REFERENCES,0.6115351993214588,"Quant-BnB with bonuses of 5 and 50 seconds to see if the latter can outperform DPDT with just a
603"
REFERENCES,0.6123833757421544,"little more time or if it would require almost twice the time (see Table 7 for DPDT-5’ runtimes). We
604"
REFERENCES,0.6132315521628499,"observe that for both train and test accuracies, Quant-BnB-t+50 (DPDT-5 runtime plus 50 seconds
605"
REFERENCES,0.6140797285835454,"bonus) outperforms DPDT most often.
606"
REFERENCES,0.6149279050042409,Table 7: Train and Tests accuracies of DPDT and Quant-BnB for Trees of maximum depth 3
REFERENCES,0.6157760814249363,"Datasets
Train Accuracies
Test Accuracies
Names
DPDT-3
DPDT-4
DPDT-5
Quant-BnB-T
Quant-BnB-t+5
Quant-BnB-t+50
DPDT-3
DPDT-4
DPDT-5
Quant-BnB-T
Quant-BnB-t+5
Quant-BnB-t+50
avila
58
58
58.5
57.3
57.3
57.3
57.9
57.9
58.2
57.1
57.1
57.1
bank
98
98
98
97.1
98.3
98.3
97.8
97.8
97.8
97.8
97.8
97.8
bean
85
85
85.6
85.3
85.3
85.3
85.1
85.1
84.9
85.6
85.6
85.6
bidding
99.3
99.3
99.3
98.6
98.7
99.3
99
99
99
98.6
98.7
99
eeg
69.4
70
70.3
68.3
68.3
68.9
71
69.8
70
69.8
69.8
68.5
fault
65.7
65.7
68
64.6
64.6
66.9
64.8
64.8
65.3
63.2
63.2
64.3
htru
98
98
98
98
98
98
98.2
97.9
97.9
98.1
98.1
98.1
magic
82.7
82.7
82.9
82.6
82.6
82.7
82
82
82.2
82.2
82.2
82.3
occupancy
99.3
99.3
99.4
99.3
99.3
99.4
93.4
93.4
93.9
89.6
89.6
91
page
97
97
97
96.5
96.7
97
96
96
96.1
96.7
95.9
95.9
raisin
88.3
88.3
88.5
88.1
88.6
89
87.2
87.2
88.3
88.9
88.3
89.4
rice
93.5
93.6
93.7
93.7
93.7
93.7
92.1
92.1
92.7
92
92
92
room
99.2
99.2
99.2
98.8
98.8
99
99
99
99
98.6
98.6
98.8
segment
88.2
88.2
88.2
79.1
87.8
87.8
84
84
84
76.8
84.2
84.2
skin
96.7
96.7
96.7
96.7
96.7
96.7
96.7
96.7
96.7
96.6
96.6
96.6
wilt
99.5
99.5
99.5
99.4
99.4
99.6
80.4
79.2
79.2
77.6
81.2
78.8"
REFERENCES,0.6166242578456319,"K
Additional figures for different complexity measures
607"
REFERENCES,0.6174724342663274,"We show here the complexity-performance trade-offs for all 16 datasets. We show the plot for two
608"
REFERENCES,0.6183206106870229,"complexity measures: average number of tests (what DPDT optimize) and total number of nodes
609"
REFERENCES,0.6191687871077184,"(what the post-process prunning of CART optimizes). On the first measure, the trees that DPDT finds
610"
REFERENCES,0.620016963528414,"dominate those of CART, which matches the theory. On the second measure, even though we do not
611"
REFERENCES,0.6208651399491094,"optimize for the total number of nodes, we are still able to find better trade-offs w.r.t. this metric than
612"
REFERENCES,0.6217133163698049,"CART for several datasets.
613"
REFERENCES,0.6225614927905004,"K.1
Average number of tests vs accuracy
614"
REFERENCES,0.6234096692111959,"0
1
2
3
4
5
average tests per sample 0.40 0.45 0.50 0.55 0.60 0.65"
REFERENCES,0.6242578456318915,accuracy avila
REFERENCES,0.6251060220525869,"DPDT-3 in 51s
CART-postpruning in 1s"
REFERENCES,0.6259541984732825,"0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
average tests per sample 0.6 0.7 0.8 0.9 1.0"
REFERENCES,0.6268023748939779,accuracy bank
REFERENCES,0.6276505513146734,"DPDT-3 in 2s
CART-postpruning in 0s"
REFERENCES,0.628498727735369,"0
1
2
3
4
5
average tests per sample 0.3 0.4 0.5 0.6 0.7 0.8 0.9"
REFERENCES,0.6293469041560644,accuracy bean
REFERENCES,0.63019508057676,"DPDT-3 in 88s
CART-postpruning in 8s"
REFERENCES,0.6310432569974554,"0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
average tests per sample 0.90 0.92 0.94 0.96 0.98 1.00"
REFERENCES,0.631891433418151,accuracy
REFERENCES,0.6327396098388465,bidding
REFERENCES,0.6335877862595419,"DPDT-3 in 2s
CART-postpruning in 0s"
REFERENCES,0.6344359626802375,"0
1
2
3
4
5
average tests per sample 0.55 0.60 0.65 0.70 0.75"
REFERENCES,0.635284139100933,accuracy eeg
REFERENCES,0.6361323155216285,"DPDT-3 in 57s
CART-postpruning in 1s"
REFERENCES,0.636980491942324,"0
1
2
3
4
5
average tests per sample 0.4 0.5 0.6 0.7 0.8"
REFERENCES,0.6378286683630195,accuracy fault
REFERENCES,0.638676844783715,"DPDT-3 in 35s
CART-postpruning in 0s"
REFERENCES,0.6395250212044106,"0
1
2
3
4
5
average tests per sample 0.91 0.92 0.93 0.94 0.95 0.96 0.97 0.98"
REFERENCES,0.640373197625106,accuracy htru
REFERENCES,0.6412213740458015,"DPDT-3 in 63s
CART-postpruning in 3s"
REFERENCES,0.642069550466497,"0
1
2
3
4
5
average tests per sample 0.65 0.70 0.75 0.80 0.85"
REFERENCES,0.6429177268871925,accuracy magic
REFERENCES,0.6437659033078881,"DPDT-3 in 98s
CART-postpruning in 5s"
REFERENCES,0.6446140797285835,"0
1
2
3
4
5
average tests per sample 0.80 0.85 0.90 0.95 1.00"
REFERENCES,0.6454622561492791,accuracy
REFERENCES,0.6463104325699746,occupancy
REFERENCES,0.64715860899067,"DPDT-3 in 11s
CART-postpruning in 0s"
REFERENCES,0.6480067854113656,"0
1
2
3
4
5
average tests per sample 0.90 0.92 0.94 0.96 0.98"
REFERENCES,0.648854961832061,accuracy page
REFERENCES,0.6497031382527566,"DPDT-3 in 26s
CART-postpruning in 0s"
REFERENCES,0.6505513146734521,"0
1
2
3
4
average tests per sample 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95"
REFERENCES,0.6513994910941476,accuracy rice
REFERENCES,0.6522476675148431,"DPDT-3 in 17s
CART-postpruning in 0s"
REFERENCES,0.6530958439355385,"0
1
2
3
4
5
average tests per sample 0.5 0.6 0.7 0.8 0.9"
REFERENCES,0.6539440203562341,accuracy
REFERENCES,0.6547921967769296,raisin
REFERENCES,0.6556403731976251,"DPDT-3 in 7s
CART-postpruning in 0s"
REFERENCES,0.6564885496183206,"0
1
2
3
4
average tests per sample 0.2 0.4 0.6 0.8 1.0"
REFERENCES,0.6573367260390162,accuracy
REFERENCES,0.6581849024597116,segment
REFERENCES,0.6590330788804071,"DPDT-3 in 6s
CART-postpruning in 0s"
REFERENCES,0.6598812553011026,"0
1
2
3
4
average tests per sample 0.825 0.850 0.875 0.900 0.925 0.950 0.975 1.000"
REFERENCES,0.6607294317217981,accuracy room
REFERENCES,0.6615776081424937,"DPDT-3 in 19s
CART-postpruning in 0s"
REFERENCES,0.6624257845631891,"0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
average tests per sample"
REFERENCES,0.6632739609838847,0.9825
REFERENCES,0.6641221374045801,0.9850
REFERENCES,0.6649703138252756,0.9875
REFERENCES,0.6658184902459712,0.9900
REFERENCES,0.6666666666666666,0.9925
REFERENCES,0.6675148430873622,0.9950
REFERENCES,0.6683630195080577,0.9975
REFERENCES,0.6692111959287532,1.0000
REFERENCES,0.6700593723494487,accuracy wilt
REFERENCES,0.6709075487701441,"DPDT-3 in 3s
CART-postpruning in 0s"
REFERENCES,0.6717557251908397,"0
1
2
3
4
average tests per sample 0.800 0.825 0.850 0.875 0.900 0.925 0.950 0.975 1.000"
REFERENCES,0.6726039016115352,accuracy skin
REFERENCES,0.6734520780322307,"DPDT-3 in 265s
CART-postpruning in 3s"
REFERENCES,0.6743002544529262,"Figure 8: Average number of tests-accuracies trade-offs of CART and DPDT-3 on classification
training datasets. Both algorithms learn trees of depths at most 5. CART makes a trade-off with the
minimal complexity post-pruning algorithm. DPDT-3 makes a trade-off by returning policies for
1000 different α."
REFERENCES,0.6751484308736218,"K.2
Total number of nodes vs accuracy
615"
REFERENCES,0.6759966072943172,"L
Codes to reproduce experiments
616"
REFERENCES,0.6768447837150128,"Anonymized
github
for
DPDT
code:
https://anonymous.4open.science/r/
617"
REFERENCES,0.6776929601357082,"reproduce-E9BD/README.md
618"
REFERENCES,0.6785411365564037,"Anonymized github of our clone of Quant-BnB code: https://anonymous.4open.science/r/
619"
REFERENCES,0.6793893129770993,"reproduce-quant-bnb-80ED/README.md
620"
REFERENCES,0.6802374893977947,"0
10
20
30
40
50
60
nodes 0.40 0.45 0.50 0.55 0.60 0.65"
REFERENCES,0.6810856658184903,accuracy avila
REFERENCES,0.6819338422391857,"DPDT-3 in 51s
CART-postpruning in 1s"
REFERENCES,0.6827820186598813,"0
10
20
30
40
nodes 0.6 0.7 0.8 0.9 1.0"
REFERENCES,0.6836301950805768,accuracy bank
REFERENCES,0.6844783715012722,"DPDT-3 in 2s
CART-postpruning in 0s"
REFERENCES,0.6853265479219678,"0
10
20
30
40
50
60
nodes 0.3 0.4 0.5 0.6 0.7 0.8 0.9"
REFERENCES,0.6861747243426632,accuracy bean
REFERENCES,0.6870229007633588,"DPDT-3 in 88s
CART-postpruning in 8s"
REFERENCES,0.6878710771840543,"0
5
10
15
20
25
30
35
40
nodes 0.90 0.92 0.94 0.96 0.98 1.00"
REFERENCES,0.6887192536047498,accuracy
REFERENCES,0.6895674300254453,bidding
REFERENCES,0.6904156064461408,"DPDT-3 in 2s
CART-postpruning in 0s"
REFERENCES,0.6912637828668363,"0
10
20
30
40
50
60
nodes 0.55 0.60 0.65 0.70 0.75"
REFERENCES,0.6921119592875318,accuracy eeg
REFERENCES,0.6929601357082273,"DPDT-3 in 57s
CART-postpruning in 1s"
REFERENCES,0.6938083121289228,"0
10
20
30
40
50
60
nodes 0.4 0.5 0.6 0.7 0.8"
REFERENCES,0.6946564885496184,accuracy fault
REFERENCES,0.6955046649703138,"DPDT-3 in 35s
CART-postpruning in 0s"
REFERENCES,0.6963528413910093,"0
10
20
30
40
50
60
nodes 0.91 0.92 0.93 0.94 0.95 0.96 0.97 0.98"
REFERENCES,0.6972010178117048,accuracy htru
REFERENCES,0.6980491942324003,"DPDT-3 in 63s
CART-postpruning in 3s"
REFERENCES,0.6988973706530959,"0
10
20
30
40
50
60
nodes 0.65 0.70 0.75 0.80 0.85"
REFERENCES,0.6997455470737913,accuracy magic
REFERENCES,0.7005937234944869,"DPDT-3 in 98s
CART-postpruning in 5s"
REFERENCES,0.7014418999151824,"0
10
20
30
40
50
nodes 0.80 0.85 0.90 0.95 1.00"
REFERENCES,0.7022900763358778,accuracy
REFERENCES,0.7031382527565734,occupancy
REFERENCES,0.7039864291772688,"DPDT-3 in 11s
CART-postpruning in 0s"
REFERENCES,0.7048346055979644,"0
10
20
30
40
50
60
nodes 0.90 0.92 0.94 0.96 0.98"
REFERENCES,0.7056827820186599,accuracy page
REFERENCES,0.7065309584393554,"DPDT-3 in 26s
CART-postpruning in 0s"
REFERENCES,0.7073791348600509,"0
10
20
30
40
50
60
nodes 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95"
REFERENCES,0.7082273112807463,accuracy rice
REFERENCES,0.7090754877014419,"DPDT-3 in 17s
CART-postpruning in 0s"
REFERENCES,0.7099236641221374,"0
10
20
30
40
50
60
nodes 0.5 0.6 0.7 0.8 0.9"
REFERENCES,0.7107718405428329,accuracy
REFERENCES,0.7116200169635284,raisin
REFERENCES,0.712468193384224,"DPDT-3 in 7s
CART-postpruning in 0s"
REFERENCES,0.7133163698049194,"0
5
10
15
20
25
30
35
40
nodes 0.2 0.4 0.6 0.8 1.0"
REFERENCES,0.714164546225615,accuracy
REFERENCES,0.7150127226463104,segment
REFERENCES,0.7158608990670059,"DPDT-3 in 6s
CART-postpruning in 0s"
REFERENCES,0.7167090754877015,"0
10
20
30
40
nodes 0.825 0.850 0.875 0.900 0.925 0.950 0.975 1.000"
REFERENCES,0.7175572519083969,accuracy room
REFERENCES,0.7184054283290925,"DPDT-3 in 19s
CART-postpruning in 0s"
REFERENCES,0.719253604749788,"0
10
20
30
40
nodes"
REFERENCES,0.7201017811704835,0.9825
REFERENCES,0.720949957591179,0.9850
REFERENCES,0.7217981340118744,0.9875
REFERENCES,0.72264631043257,0.9900
REFERENCES,0.7234944868532655,0.9925
REFERENCES,0.724342663273961,0.9950
REFERENCES,0.7251908396946565,0.9975
REFERENCES,0.726039016115352,1.0000
REFERENCES,0.7268871925360475,accuracy wilt
REFERENCES,0.727735368956743,"DPDT-3 in 3s
CART-postpruning in 0s"
REFERENCES,0.7285835453774385,"0
10
20
30
40
nodes 0.800 0.825 0.850 0.875 0.900 0.925 0.950 0.975 1.000"
REFERENCES,0.729431721798134,accuracy skin
REFERENCES,0.7302798982188295,"DPDT-3 in 265s
CART-postpruning in 3s"
REFERENCES,0.731128074639525,"Figure 9: Nodes-accuracies trade-offs of CART and DPDT-3 on classification training datasets. Both
algorithms learn trees of depths at most 5. CART makes a trade-off with the minimal complexity
post-pruning algorithm. DPDT-3 makes a trade-off by returning policies for 1000 different α. Even
though we do not optimize for this complexity metric, we are still able to find better trade-offs than
CART with post-pruning in several cases."
REFERENCES,0.7319762510602206,"NeurIPS Paper Checklist
621"
CLAIMS,0.732824427480916,"1. Claims
622"
CLAIMS,0.7336726039016115,"Question: Do the main claims made in the abstract and introduction accurately reflect the
623"
CLAIMS,0.734520780322307,"paper’s contributions and scope?
624"
CLAIMS,0.7353689567430025,"Answer: [Yes]
625"
CLAIMS,0.7362171331636981,"Justification: All the algorithms and claims mentionned in the intro are studied and presented
626"
CLAIMS,0.7370653095843935,"in detail in the main paper. Please see 1 2.
627"
CLAIMS,0.7379134860050891,"Guidelines:
628"
CLAIMS,0.7387616624257846,"• The answer NA means that the abstract and introduction do not include the claims
629"
CLAIMS,0.73960983884648,"made in the paper.
630"
CLAIMS,0.7404580152671756,"• The abstract and/or introduction should clearly state the claims made, including the
631"
CLAIMS,0.741306191687871,"contributions made in the paper and important assumptions and limitations. A No or
632"
CLAIMS,0.7421543681085666,"NA answer to this question will not be perceived well by the reviewers.
633"
CLAIMS,0.7430025445292621,"• The claims made should match theoretical and experimental results, and reflect how
634"
CLAIMS,0.7438507209499576,"much the results can be expected to generalize to other settings.
635"
CLAIMS,0.7446988973706531,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
636"
CLAIMS,0.7455470737913485,"are not attained by the paper.
637"
LIMITATIONS,0.7463952502120441,"2. Limitations
638"
LIMITATIONS,0.7472434266327396,"Question: Does the paper discuss the limitations of the work performed by the authors?
639"
LIMITATIONS,0.7480916030534351,"Answer: [Yes]
640"
LIMITATIONS,0.7489397794741306,"Justification: Dedicated sections in the experiments and in the conclusion for limitations.
641"
LIMITATIONS,0.7497879558948262,"Please see 7.
642"
LIMITATIONS,0.7506361323155216,"Guidelines:
643"
LIMITATIONS,0.7514843087362172,"• The answer NA means that the paper has no limitation while the answer No means that
644"
LIMITATIONS,0.7523324851569126,"the paper has limitations, but those are not discussed in the paper.
645"
LIMITATIONS,0.7531806615776081,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
646"
LIMITATIONS,0.7540288379983037,"• The paper should point out any strong assumptions and how robust the results are to
647"
LIMITATIONS,0.7548770144189991,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
648"
LIMITATIONS,0.7557251908396947,"model well-specification, asymptotic approximations only holding locally). The authors
649"
LIMITATIONS,0.7565733672603902,"should reflect on how these assumptions might be violated in practice and what the
650"
LIMITATIONS,0.7574215436810857,"implications would be.
651"
LIMITATIONS,0.7582697201017812,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
652"
LIMITATIONS,0.7591178965224766,"only tested on a few datasets or with a few runs. In general, empirical results often
653"
LIMITATIONS,0.7599660729431722,"depend on implicit assumptions, which should be articulated.
654"
LIMITATIONS,0.7608142493638677,"• The authors should reflect on the factors that influence the performance of the approach.
655"
LIMITATIONS,0.7616624257845632,"For example, a facial recognition algorithm may perform poorly when image resolution
656"
LIMITATIONS,0.7625106022052587,"is low or images are taken in low lighting. Or a speech-to-text system might not be
657"
LIMITATIONS,0.7633587786259542,"used reliably to provide closed captions for online lectures because it fails to handle
658"
LIMITATIONS,0.7642069550466497,"technical jargon.
659"
LIMITATIONS,0.7650551314673452,"• The authors should discuss the computational efficiency of the proposed algorithms
660"
LIMITATIONS,0.7659033078880407,"and how they scale with dataset size.
661"
LIMITATIONS,0.7667514843087362,"• If applicable, the authors should discuss possible limitations of their approach to
662"
LIMITATIONS,0.7675996607294318,"address problems of privacy and fairness.
663"
LIMITATIONS,0.7684478371501272,"• While the authors might fear that complete honesty about limitations might be used by
664"
LIMITATIONS,0.7692960135708228,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
665"
LIMITATIONS,0.7701441899915182,"limitations that aren’t acknowledged in the paper. The authors should use their best
666"
LIMITATIONS,0.7709923664122137,"judgment and recognize that individual actions in favor of transparency play an impor-
667"
LIMITATIONS,0.7718405428329093,"tant role in developing norms that preserve the integrity of the community. Reviewers
668"
LIMITATIONS,0.7726887192536047,"will be specifically instructed to not penalize honesty concerning limitations.
669"
THEORY ASSUMPTIONS AND PROOFS,0.7735368956743003,"3. Theory Assumptions and Proofs
670"
THEORY ASSUMPTIONS AND PROOFS,0.7743850720949957,"Question: For each theoretical result, does the paper provide the full set of assumptions and
671"
THEORY ASSUMPTIONS AND PROOFS,0.7752332485156913,"a complete (and correct) proof?
672"
THEORY ASSUMPTIONS AND PROOFS,0.7760814249363868,"Answer: [Yes]
673"
THEORY ASSUMPTIONS AND PROOFS,0.7769296013570822,"Justification: Propositions and theorems are proven. Note that is not paper is not a theory
674"
THEORY ASSUMPTIONS AND PROOFS,0.7777777777777778,"paper. Please see H.
675"
THEORY ASSUMPTIONS AND PROOFS,0.7786259541984732,"Guidelines:
676"
THEORY ASSUMPTIONS AND PROOFS,0.7794741306191688,"• The answer NA means that the paper does not include theoretical results.
677"
THEORY ASSUMPTIONS AND PROOFS,0.7803223070398643,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
678"
THEORY ASSUMPTIONS AND PROOFS,0.7811704834605598,"referenced.
679"
THEORY ASSUMPTIONS AND PROOFS,0.7820186598812553,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
680"
THEORY ASSUMPTIONS AND PROOFS,0.7828668363019508,"• The proofs can either appear in the main paper or the supplemental material, but if
681"
THEORY ASSUMPTIONS AND PROOFS,0.7837150127226463,"they appear in the supplemental material, the authors are encouraged to provide a short
682"
THEORY ASSUMPTIONS AND PROOFS,0.7845631891433418,"proof sketch to provide intuition.
683"
THEORY ASSUMPTIONS AND PROOFS,0.7854113655640373,"• Inversely, any informal proof provided in the core of the paper should be complemented
684"
THEORY ASSUMPTIONS AND PROOFS,0.7862595419847328,"by formal proofs provided in appendix or supplemental material.
685"
THEORY ASSUMPTIONS AND PROOFS,0.7871077184054284,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
686"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7879558948261238,"4. Experimental Result Reproducibility
687"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7888040712468194,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
688"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7896522476675149,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
689"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7905004240882103,"of the paper (regardless of whether the code and data are provided or not)?
690"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7913486005089059,"Answer: [Yes]
691"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7921967769296013,"Justification: Code and data links are provided. Algorithms are described explicitly. Please
692"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7930449533502969,"see A L.
693"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7938931297709924,"Guidelines:
694"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7947413061916879,"• The answer NA means that the paper does not include experiments.
695"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7955894826123834,"• If the paper includes experiments, a No answer to this question will not be perceived
696"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7964376590330788,"well by the reviewers: Making the paper reproducible is important, regardless of
697"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7972858354537744,"whether the code and data are provided or not.
698"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7981340118744699,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
699"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7989821882951654,"to make their results reproducible or verifiable.
700"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7998303647158609,"• Depending on the contribution, reproducibility can be accomplished in various ways.
701"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8006785411365565,"For example, if the contribution is a novel architecture, describing the architecture fully
702"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8015267175572519,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
703"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8023748939779474,"be necessary to either make it possible for others to replicate the model with the same
704"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8032230703986429,"dataset, or provide access to the model. In general. releasing code and data is often
705"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8040712468193384,"one good way to accomplish this, but reproducibility can also be provided via detailed
706"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.804919423240034,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
707"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8057675996607294,"of a large language model), releasing of a model checkpoint, or other means that are
708"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.806615776081425,"appropriate to the research performed.
709"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8074639525021204,"• While NeurIPS does not require releasing code, the conference does require all submis-
710"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8083121289228159,"sions to provide some reasonable avenue for reproducibility, which may depend on the
711"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8091603053435115,"nature of the contribution. For example
712"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8100084817642069,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
713"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8108566581849025,"to reproduce that algorithm.
714"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.811704834605598,"(b) If the contribution is primarily a new model architecture, the paper should describe
715"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8125530110262935,"the architecture clearly and fully.
716"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.813401187446989,"(c) If the contribution is a new model (e.g., a large language model), then there should
717"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8142493638676844,"either be a way to access this model for reproducing the results or a way to reproduce
718"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.81509754028838,"the model (e.g., with an open-source dataset or instructions for how to construct
719"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8159457167090755,"the dataset).
720"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.816793893129771,"(d) We recognize that reproducibility may be tricky in some cases, in which case
721"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8176420695504665,"authors are welcome to describe the particular way they provide for reproducibility.
722"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.818490245971162,"In the case of closed-source models, it may be that access to the model is limited in
723"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8193384223918575,"some way (e.g., to registered users), but it should be possible for other researchers
724"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.820186598812553,"to have some path to reproducing or verifying the results.
725"
OPEN ACCESS TO DATA AND CODE,0.8210347752332485,"5. Open access to data and code
726"
OPEN ACCESS TO DATA AND CODE,0.821882951653944,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
727"
OPEN ACCESS TO DATA AND CODE,0.8227311280746396,"tions to faithfully reproduce the main experimental results, as described in supplemental
728"
OPEN ACCESS TO DATA AND CODE,0.823579304495335,"material?
729"
OPEN ACCESS TO DATA AND CODE,0.8244274809160306,"Answer: [Yes]
730"
OPEN ACCESS TO DATA AND CODE,0.825275657336726,"Justification: Anonymized github repo and data links are provided. Please see A L.
731"
OPEN ACCESS TO DATA AND CODE,0.8261238337574215,"Guidelines:
732"
OPEN ACCESS TO DATA AND CODE,0.8269720101781171,"• The answer NA means that paper does not include experiments requiring code.
733"
OPEN ACCESS TO DATA AND CODE,0.8278201865988125,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
734"
OPEN ACCESS TO DATA AND CODE,0.8286683630195081,"public/guides/CodeSubmissionPolicy) for more details.
735"
OPEN ACCESS TO DATA AND CODE,0.8295165394402035,"• While we encourage the release of code and data, we understand that this might not be
736"
OPEN ACCESS TO DATA AND CODE,0.8303647158608991,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
737"
OPEN ACCESS TO DATA AND CODE,0.8312128922815946,"including code, unless this is central to the contribution (e.g., for a new open-source
738"
OPEN ACCESS TO DATA AND CODE,0.8320610687022901,"benchmark).
739"
OPEN ACCESS TO DATA AND CODE,0.8329092451229856,"• The instructions should contain the exact command and environment needed to run to
740"
OPEN ACCESS TO DATA AND CODE,0.833757421543681,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
741"
OPEN ACCESS TO DATA AND CODE,0.8346055979643766,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
742"
OPEN ACCESS TO DATA AND CODE,0.8354537743850721,"• The authors should provide instructions on data access and preparation, including how
743"
OPEN ACCESS TO DATA AND CODE,0.8363019508057676,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
744"
OPEN ACCESS TO DATA AND CODE,0.8371501272264631,"• The authors should provide scripts to reproduce all experimental results for the new
745"
OPEN ACCESS TO DATA AND CODE,0.8379983036471587,"proposed method and baselines. If only a subset of experiments are reproducible, they
746"
OPEN ACCESS TO DATA AND CODE,0.8388464800678541,"should state which ones are omitted from the script and why.
747"
OPEN ACCESS TO DATA AND CODE,0.8396946564885496,"• At submission time, to preserve anonymity, the authors should release anonymized
748"
OPEN ACCESS TO DATA AND CODE,0.8405428329092451,"versions (if applicable).
749"
OPEN ACCESS TO DATA AND CODE,0.8413910093299406,"• Providing as much information as possible in supplemental material (appended to the
750"
OPEN ACCESS TO DATA AND CODE,0.8422391857506362,"paper) is recommended, but including URLs to data and code is permitted.
751"
OPEN ACCESS TO DATA AND CODE,0.8430873621713316,"6. Experimental Setting/Details
752"
OPEN ACCESS TO DATA AND CODE,0.8439355385920272,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
753"
OPEN ACCESS TO DATA AND CODE,0.8447837150127226,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
754"
OPEN ACCESS TO DATA AND CODE,0.8456318914334181,"results?
755"
OPEN ACCESS TO DATA AND CODE,0.8464800678541137,"Answer: [Yes]
756"
OPEN ACCESS TO DATA AND CODE,0.8473282442748091,"Justification: Evertyhing is detailed clearly in the main paper, in the appendix and in the
757"
OPEN ACCESS TO DATA AND CODE,0.8481764206955047,"code repos. Please see 6.
758"
OPEN ACCESS TO DATA AND CODE,0.8490245971162002,"Guidelines:
759"
OPEN ACCESS TO DATA AND CODE,0.8498727735368957,"• The answer NA means that the paper does not include experiments.
760"
OPEN ACCESS TO DATA AND CODE,0.8507209499575912,"• The experimental setting should be presented in the core of the paper to a level of detail
761"
OPEN ACCESS TO DATA AND CODE,0.8515691263782866,"that is necessary to appreciate the results and make sense of them.
762"
OPEN ACCESS TO DATA AND CODE,0.8524173027989822,"• The full details can be provided either with the code, in appendix, or as supplemental
763"
OPEN ACCESS TO DATA AND CODE,0.8532654792196777,"material.
764"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8541136556403732,"7. Experiment Statistical Significance
765"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8549618320610687,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
766"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8558100084817643,"information about the statistical significance of the experiments?
767"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8566581849024597,"Answer: [Yes]
768"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8575063613231552,"Justification: When processes are stochastic error values are provided in result tables. Please
769"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8583545377438507,"see 1.
770"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8592027141645462,"Guidelines:
771"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8600508905852418,"• The answer NA means that the paper does not include experiments.
772"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8608990670059372,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
773"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8617472434266328,"dence intervals, or statistical significance tests, at least for the experiments that support
774"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8625954198473282,"the main claims of the paper.
775"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8634435962680237,"• The factors of variability that the error bars are capturing should be clearly stated (for
776"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8642917726887193,"example, train/test split, initialization, random drawing of some parameter, or overall
777"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8651399491094147,"run with given experimental conditions).
778"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8659881255301103,"• The method for calculating the error bars should be explained (closed form formula,
779"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8668363019508057,"call to a library function, bootstrap, etc.)
780"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8676844783715013,"• The assumptions made should be given (e.g., Normally distributed errors).
781"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8685326547921968,"• It should be clear whether the error bar is the standard deviation or the standard error
782"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8693808312128923,"of the mean.
783"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8702290076335878,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
784"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8710771840542832,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
785"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8719253604749788,"of Normality of errors is not verified.
786"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8727735368956743,"• For asymmetric distributions, the authors should be careful not to show in tables or
787"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8736217133163698,"figures symmetric error bars that would yield results that are out of range (e.g. negative
788"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8744698897370653,"error rates).
789"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8753180661577609,"• If error bars are reported in tables or plots, The authors should explain in the text how
790"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8761662425784563,"they were calculated and reference the corresponding figures or tables in the text.
791"
EXPERIMENTS COMPUTE RESOURCES,0.8770144189991518,"8. Experiments Compute Resources
792"
EXPERIMENTS COMPUTE RESOURCES,0.8778625954198473,"Question: For each experiment, does the paper provide sufficient information on the com-
793"
EXPERIMENTS COMPUTE RESOURCES,0.8787107718405428,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
794"
EXPERIMENTS COMPUTE RESOURCES,0.8795589482612384,"the experiments?
795"
EXPERIMENTS COMPUTE RESOURCES,0.8804071246819338,"Answer: [Yes]
796"
EXPERIMENTS COMPUTE RESOURCES,0.8812553011026294,"Justification: Exact CPU model as well as ram are provided. Please see 6.
797"
EXPERIMENTS COMPUTE RESOURCES,0.8821034775233249,"Guidelines:
798"
EXPERIMENTS COMPUTE RESOURCES,0.8829516539440203,"• The answer NA means that the paper does not include experiments.
799"
EXPERIMENTS COMPUTE RESOURCES,0.8837998303647159,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
800"
EXPERIMENTS COMPUTE RESOURCES,0.8846480067854113,"or cloud provider, including relevant memory and storage.
801"
EXPERIMENTS COMPUTE RESOURCES,0.8854961832061069,"• The paper should provide the amount of compute required for each of the individual
802"
EXPERIMENTS COMPUTE RESOURCES,0.8863443596268024,"experimental runs as well as estimate the total compute.
803"
EXPERIMENTS COMPUTE RESOURCES,0.8871925360474979,"• The paper should disclose whether the full research project required more compute
804"
EXPERIMENTS COMPUTE RESOURCES,0.8880407124681934,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
805"
EXPERIMENTS COMPUTE RESOURCES,0.8888888888888888,"didn’t make it into the paper).
806"
CODE OF ETHICS,0.8897370653095844,"9. Code Of Ethics
807"
CODE OF ETHICS,0.8905852417302799,"Question: Does the research conducted in the paper conform, in every respect, with the
808"
CODE OF ETHICS,0.8914334181509754,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
809"
CODE OF ETHICS,0.8922815945716709,"Answer: [Yes]
810"
CODE OF ETHICS,0.8931297709923665,"Justification: Research is done ethically with na lot of concerns for reproduciblity and
811"
CODE OF ETHICS,0.8939779474130619,"validity of the results.
812"
CODE OF ETHICS,0.8948261238337574,"Guidelines:
813"
CODE OF ETHICS,0.8956743002544529,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
814"
CODE OF ETHICS,0.8965224766751484,"• If the authors answer No, they should explain the special circumstances that require a
815"
CODE OF ETHICS,0.897370653095844,"deviation from the Code of Ethics.
816"
CODE OF ETHICS,0.8982188295165394,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
817"
CODE OF ETHICS,0.899067005937235,"eration due to laws or regulations in their jurisdiction).
818"
BROADER IMPACTS,0.8999151823579304,"10. Broader Impacts
819"
BROADER IMPACTS,0.9007633587786259,"Question: Does the paper discuss both potential positive societal impacts and negative
820"
BROADER IMPACTS,0.9016115351993215,"societal impacts of the work performed?
821"
BROADER IMPACTS,0.9024597116200169,"Answer: [NA]
822"
BROADER IMPACTS,0.9033078880407125,"Justification: No societal impact, our work simply proposes a classification/regression
823"
BROADER IMPACTS,0.904156064461408,"tree algorithms like many before. So the ethical and societal concers are inherited from
824"
BROADER IMPACTS,0.9050042408821035,"supervised learning ones.
825"
BROADER IMPACTS,0.905852417302799,"Guidelines:
826"
BROADER IMPACTS,0.9067005937234945,"• The answer NA means that there is no societal impact of the work performed.
827"
BROADER IMPACTS,0.90754877014419,"• If the authors answer NA or No, they should explain why their work has no societal
828"
BROADER IMPACTS,0.9083969465648855,"impact or why the paper does not address societal impact.
829"
BROADER IMPACTS,0.909245122985581,"• Examples of negative societal impacts include potential malicious or unintended uses
830"
BROADER IMPACTS,0.9100932994062765,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
831"
BROADER IMPACTS,0.910941475826972,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
832"
BROADER IMPACTS,0.9117896522476675,"groups), privacy considerations, and security considerations.
833"
BROADER IMPACTS,0.9126378286683631,"• The conference expects that many papers will be foundational research and not tied
834"
BROADER IMPACTS,0.9134860050890585,"to particular applications, let alone deployments. However, if there is a direct path to
835"
BROADER IMPACTS,0.914334181509754,"any negative applications, the authors should point it out. For example, it is legitimate
836"
BROADER IMPACTS,0.9151823579304496,"to point out that an improvement in the quality of generative models could be used to
837"
BROADER IMPACTS,0.916030534351145,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
838"
BROADER IMPACTS,0.9168787107718406,"that a generic algorithm for optimizing neural networks could enable people to train
839"
BROADER IMPACTS,0.917726887192536,"models that generate Deepfakes faster.
840"
BROADER IMPACTS,0.9185750636132316,"• The authors should consider possible harms that could arise when the technology is
841"
BROADER IMPACTS,0.9194232400339271,"being used as intended and functioning correctly, harms that could arise when the
842"
BROADER IMPACTS,0.9202714164546225,"technology is being used as intended but gives incorrect results, and harms following
843"
BROADER IMPACTS,0.9211195928753181,"from (intentional or unintentional) misuse of the technology.
844"
BROADER IMPACTS,0.9219677692960135,"• If there are negative societal impacts, the authors could also discuss possible mitigation
845"
BROADER IMPACTS,0.9228159457167091,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
846"
BROADER IMPACTS,0.9236641221374046,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
847"
BROADER IMPACTS,0.9245122985581001,"feedback over time, improving the efficiency and accessibility of ML).
848"
SAFEGUARDS,0.9253604749787956,"11. Safeguards
849"
SAFEGUARDS,0.926208651399491,"Question: Does the paper describe safeguards that have been put in place for responsible
850"
SAFEGUARDS,0.9270568278201866,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
851"
SAFEGUARDS,0.9279050042408821,"image generators, or scraped datasets)?
852"
SAFEGUARDS,0.9287531806615776,"Answer: [NA]
853"
SAFEGUARDS,0.9296013570822731,"Justification: no risk (see above)
854"
SAFEGUARDS,0.9304495335029687,"Guidelines:
855"
SAFEGUARDS,0.9312977099236641,"• The answer NA means that the paper poses no such risks.
856"
SAFEGUARDS,0.9321458863443596,"• Released models that have a high risk for misuse or dual-use should be released with
857"
SAFEGUARDS,0.9329940627650551,"necessary safeguards to allow for controlled use of the model, for example by requiring
858"
SAFEGUARDS,0.9338422391857506,"that users adhere to usage guidelines or restrictions to access the model or implementing
859"
SAFEGUARDS,0.9346904156064462,"safety filters.
860"
SAFEGUARDS,0.9355385920271416,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
861"
SAFEGUARDS,0.9363867684478372,"should describe how they avoided releasing unsafe images.
862"
SAFEGUARDS,0.9372349448685326,"• We recognize that providing effective safeguards is challenging, and many papers do
863"
SAFEGUARDS,0.9380831212892281,"not require this, but we encourage authors to take this into account and make a best
864"
SAFEGUARDS,0.9389312977099237,"faith effort.
865"
LICENSES FOR EXISTING ASSETS,0.9397794741306191,"12. Licenses for existing assets
866"
LICENSES FOR EXISTING ASSETS,0.9406276505513147,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
867"
LICENSES FOR EXISTING ASSETS,0.9414758269720102,"the paper, properly credited and are the license and terms of use explicitly mentioned and
868"
LICENSES FOR EXISTING ASSETS,0.9423240033927057,"properly respected?
869"
LICENSES FOR EXISTING ASSETS,0.9431721798134012,"Answer: [Yes]
870"
LICENSES FOR EXISTING ASSETS,0.9440203562340967,"Justification: Appropriate credits is given when necessary and other code not from the
871"
LICENSES FOR EXISTING ASSETS,0.9448685326547922,"authors are open sourced. Please see A L.
872"
LICENSES FOR EXISTING ASSETS,0.9457167090754877,"Guidelines:
873"
LICENSES FOR EXISTING ASSETS,0.9465648854961832,"• The answer NA means that the paper does not use existing assets.
874"
LICENSES FOR EXISTING ASSETS,0.9474130619168787,"• The authors should cite the original paper that produced the code package or dataset.
875"
LICENSES FOR EXISTING ASSETS,0.9482612383375743,"• The authors should state which version of the asset is used and, if possible, include a
876"
LICENSES FOR EXISTING ASSETS,0.9491094147582697,"URL.
877"
LICENSES FOR EXISTING ASSETS,0.9499575911789653,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
878"
LICENSES FOR EXISTING ASSETS,0.9508057675996607,"• For scraped data from a particular source (e.g., website), the copyright and terms of
879"
LICENSES FOR EXISTING ASSETS,0.9516539440203562,"service of that source should be provided.
880"
LICENSES FOR EXISTING ASSETS,0.9525021204410518,"• If assets are released, the license, copyright information, and terms of use in the
881"
LICENSES FOR EXISTING ASSETS,0.9533502968617472,"package should be provided. For popular datasets, paperswithcode.com/datasets
882"
LICENSES FOR EXISTING ASSETS,0.9541984732824428,"has curated licenses for some datasets. Their licensing guide can help determine the
883"
LICENSES FOR EXISTING ASSETS,0.9550466497031382,"license of a dataset.
884"
LICENSES FOR EXISTING ASSETS,0.9558948261238338,"• For existing datasets that are re-packaged, both the original license and the license of
885"
LICENSES FOR EXISTING ASSETS,0.9567430025445293,"the derived asset (if it has changed) should be provided.
886"
LICENSES FOR EXISTING ASSETS,0.9575911789652247,"• If this information is not available online, the authors are encouraged to reach out to
887"
LICENSES FOR EXISTING ASSETS,0.9584393553859203,"the asset’s creators.
888"
NEW ASSETS,0.9592875318066157,"13. New Assets
889"
NEW ASSETS,0.9601357082273113,"Question: Are new assets introduced in the paper well documented and is the documentation
890"
NEW ASSETS,0.9609838846480068,"provided alongside the assets?
891"
NEW ASSETS,0.9618320610687023,"Answer: [Yes]
892"
NEW ASSETS,0.9626802374893978,"Justification: Code is documented to the best we could. Please see L.
893"
NEW ASSETS,0.9635284139100933,"Guidelines:
894"
NEW ASSETS,0.9643765903307888,"• The answer NA means that the paper does not release new assets.
895"
NEW ASSETS,0.9652247667514843,"• Researchers should communicate the details of the dataset/code/model as part of their
896"
NEW ASSETS,0.9660729431721798,"submissions via structured templates. This includes details about training, license,
897"
NEW ASSETS,0.9669211195928753,"limitations, etc.
898"
NEW ASSETS,0.9677692960135709,"• The paper should discuss whether and how consent was obtained from people whose
899"
NEW ASSETS,0.9686174724342663,"asset is used.
900"
NEW ASSETS,0.9694656488549618,"• At submission time, remember to anonymize your assets (if applicable). You can either
901"
NEW ASSETS,0.9703138252756573,"create an anonymized URL or include an anonymized zip file.
902"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9711620016963528,"14. Crowdsourcing and Research with Human Subjects
903"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9720101781170484,"Question: For crowdsourcing experiments and research with human subjects, does the paper
904"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9728583545377438,"include the full text of instructions given to participants and screenshots, if applicable, as
905"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9737065309584394,"well as details about compensation (if any)?
906"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9745547073791349,"Answer:[NA]
907"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9754028837998303,"Justification: no user studies
908"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9762510602205259,"Guidelines:
909"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9770992366412213,"• The answer NA means that the paper does not involve crowdsourcing nor research with
910"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9779474130619169,"human subjects.
911"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9787955894826124,"• Including this information in the supplemental material is fine, but if the main contribu-
912"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9796437659033079,"tion of the paper involves human subjects, then as much detail as possible should be
913"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9804919423240034,"included in the main paper.
914"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.981340118744699,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
915"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9821882951653944,"or other labor should be paid at least the minimum wage in the country of the data
916"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9830364715860899,"collector.
917"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9838846480067854,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
918"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9847328244274809,"Subjects
919"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9855810008481765,"Question: Does the paper describe potential risks incurred by study participants, whether
920"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9864291772688719,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
921"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9872773536895675,"approvals (or an equivalent approval/review based on the requirements of your country or
922"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9881255301102629,"institution) were obtained?
923"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9889737065309584,"Answer: [NA]
924"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.989821882951654,"Justification: no user studies
925"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9906700593723494,"Guidelines:
926"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.991518235793045,"• The answer NA means that the paper does not involve crowdsourcing nor research with
927"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9923664122137404,"human subjects.
928"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.993214588634436,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
929"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9940627650551315,"may be required for any human subjects research. If you obtained IRB approval, you
930"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9949109414758269,"should clearly state this in the paper.
931"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9957591178965225,"• We recognize that the procedures for this may vary significantly between institutions
932"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.996607294317218,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
933"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9974554707379135,"guidelines for their institution.
934"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.998303647158609,"• For initial submissions, do not include any information that would break anonymity (if
935"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9991518235793045,"applicable), such as the institution conducting the review.
936"
