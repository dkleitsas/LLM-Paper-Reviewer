Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.001763668430335097,"Imperfect score-matching leads to a shift between the training and the sampling
distribution of diffusion models. Due to the recursive nature of the generation
process, errors in previous steps yield sampling iterates that drift away from the
training distribution. However, the standard training objective via Denoising Score
Matching (DSM) is only designed to optimize over non-drifted data. To train
on drifted data, we propose to enforce a Consistency property (CP) which states
that predictions of the model on its own generated data are consistent across time.
Theoretically, we show that the differential equation that describes CP together
with the one that describes a conservative vector field, have a unique solution
given some initial condition. Consequently, if the score is learned well on non-
drifted points via DSM (enforcing the true initial condition) then enforcing CP on
drifted points propagates true score values. Empirically, we show that enforcing
CP improves the generation quality for conditional and unconditional generation
on CIFAR-10, and in AFHQ and FFHQ. We open-source our code and models:
https://github.com/giannisdaras/cdm."
INTRODUCTION,0.003527336860670194,"1
Introduction"
INTRODUCTION,0.005291005291005291,"The diffusion-based [47, 49, 18] approach to generative models has been successful across various
modalities, including images [41, 44, 14, 39, 29, 51, 43, 16, 10, 11], videos [19, 20, 21], audio [32],
3D structures [40], proteins [1, 53, 45, 9], and medical applications [23, 3]."
INTRODUCTION,0.007054673721340388,"Diffusion models generate data by first drawing a sample from a noisy distribution and slowly
denoising this sample to ultimately obtain a sample from the target distribution. This is achieved by
sampling, in reverse from time t = 1 down to t = 0, a stochastic process {xt}t∈[0,1] wherein x0 is
distributed according to the target distribution p0 and, for all t,"
INTRODUCTION,0.008818342151675485,"xt ∼pt where pt := p0 ⊕N(0, σ2
t Id),
(1)"
INTRODUCTION,0.010582010582010581,"where ⊕denotes the convolution operator. That is, pt is the distribution resulting from corrupting a
sample from p0 with noise sampled from N(0, σ2
t Id), where σt is given by an increasing function of
t, such that σ0 = 0 and σ1 is sufficiently large so that p1 is nearly indistinguishable from pure noise.
We note that diffusion models have been generalized to other types of corruptions by the recent works"
INTRODUCTION,0.012345679012345678,∗These authors contributed equally to this work.
INTRODUCTION,0.014109347442680775,"of Daras et al. [12], Bansal et al. [4], Hoogeboom and Salimans [22], Deasy et al. [13], Nachmani
et al. [38]."
INTRODUCTION,0.015873015873015872,"In order to sample from a diffusion model, i.e. sample the afore-described process in reverse time, it
suffices to know the score function s(x, t) = ∇x log p(x, t), where p(x, t) is the density of xt ∼pt.
Indeed, given a sample xt ∼pt, one can use the score function at xt, i.e. s(xt, t), to generate a
sample from pt−dt by taking an infinitesimal step of a stochastic or an ordinary differential equation
[51, 48], or by using Langevin dynamics [17, 50].2 Hence, in order to train a diffusion model to
sample from a target distribution of interest p∗
0 it suffices to learn the score function s∗(x, t) using
samples from the corrupted distributions p∗
t resulting from p∗
0 and a particular noise schedule σt.
Notice that those samples can be easily drawn given samples from p∗
0."
INTRODUCTION,0.01763668430335097,"The Sampling Drift Challenge:
Unfortunately, the true score function s∗(x, t) is not perfectly
learned during training. Thus, at generation time, the samples xt drawn using the learned score
function, sθ(x, t), in the ways discussed above, drift astray in distribution from the true corrupted
distributions p∗
t . This drift becomes larger for smaller t due to compounding of errors and is
accentuated by the fact that the further away a sample xt is from the likely support of the true p∗
t
the larger the error ∥sθ(xt, t) −s∗(xt, t)∥between the learned and the true score function at xt,
which feeds into an even larger drift between the distribution of xt′ from p∗
t′ for t′ < t; see e.g.
[46, 18, 39, 6]. These challenges motivate the question:
Question. How can one train diffusion models to improve the error ∥sθ(x, t) −s∗(x, t)∥between the
learned and true score function on inputs (x, t) where x is unlikely under the target noisy distribution
p∗
t ?"
INTRODUCTION,0.019400352733686066,"A direct approach to this challenge is to train our model to minimize the afore-described error on
pairs (x, t) where x is sampled from distributions other than p∗
t . However, there is no straightforward
way to do so, because we do not have direct access to the values of the true score function s∗(x, t)."
INTRODUCTION,0.021164021164021163,"This motivates us to propose a training method to mitigate sampling drift by enforcing that the learned
score function satisfies an invariant, that we call the Consistency Property (CP). This property can be
optimized without using any samples from the target distribution p∗
0. We will show that theoretically,
enforcing CP on drifted points, in conjunction with minimizing the standard score matching objective
on non drifted points, suffices to learn the correct score everywhere - at least in the theoretical limit
where the error approaches zero and when one also enforces conservative vector field. We also
provide experiments illustrating that regularizing the standard score matching objective using our CP
improves sample quality. Further, we provide an ablation study that further provides evidence to this
phenomenon of score propagation."
INTRODUCTION,0.02292768959435626,"Our Approach:
The true score function s∗(x, t) is closely related to another function, called the
optimal denoiser, which predicts a clean sample x0 ∼p∗
0 from a noisy observation xt = x0 + σtη
where the noise is η ∼N(0, Id). The optimal denoiser (under the ℓ2 loss) is the conditional
expectation:
h∗(x, t) := E
x0∼p∗
0
xt=x0+σtη
η∼N(0,Id)"
INTRODUCTION,0.024691358024691357,"[x0 | xt = x],"
INTRODUCTION,0.026455026455026454,"and the true score function can be obtained from the optimal denoiser as follows: s∗(x, t) =
(h∗(x, t) −x)/σ2
t . This result is known as Tweedie’s Formula [15]. Indeed, the standard training
technique, via score-matching, explicitly trains for the score through the denoiser h∗[54, 15, 36, 30,
35]."
INTRODUCTION,0.02821869488536155,"We are now ready to state our Consistency Property (CP). We will say that a (denoising) function
hθ(x, t) satisfies CP iff
Eθ[x0|xt = x] = hθ(x, t), ∀t ∈[0, 1], ∀x,
where the expectation is with respect to a sample from the learned reverse process, defined in terms
of the implied score function sθ(x, t) = (hθ(x, t) −x)/σ2
t , when this is initialized at xt = x and run
backwards in time to sample x0. See Eq. (3) for the precise stochastic differential equation and its
justification. In particular, hθ satisfies CP if the prediction hθ(x, t) of the conditional expectation
of the clean image x0 given xt = x equals the expected value of an image that is generated by the"
INTRODUCTION,0.029982363315696647,"2Some of these methods, such as Langevin dynamics, require also to know the score function in the
neighborhood of xt."
INTRODUCTION,0.031746031746031744,"learned reversed process, starting from xt = x. Equivalently, one can formulate this property as
requiring xt to follow a reverse Martingale (see Lemma 3.1)."
INTRODUCTION,0.03350970017636684,"While there are several other properties that the score function of a diffusion process must sat-
isfy, e.g. the Fokker-Planck equation [33], our first theoretical result is that the hθ(x, t) satisfying
the Consistency Property suffices (in conjunction with the conservativeness of its score function
sθ(x, t) = (hθ(x, t) −x)/σ2
t ) to guarantee that sθ must be the score function of a diffusion process
(and must thus satisfy any other property that a diffusion process must satisfy). If additionally sθ(x, t)
equals the score function s∗(x, t) of a target diffusion process at a single time t = t0 and an open
subset of x ∈Rd, then it equals s∗everywhere. We comment that the formal theorem is proved for
an idealistic setting when the error is (or approaches) zero. Still, it is likely to believe that even in the
finite-error regime, training with DSM in-sample and enforcing CP off-sample is expected to improve
the score function values off-sample. The statement is summarized as follows below:"
INTRODUCTION,0.03527336860670194,"Theorem 1.1 (informal). If some denoiser hθ(x, t) satisfies CP and its corresponding score function
sθ(x, t) = (hθ(x, t) −x)/σ2
t is a conservative field, then sθ(x, t) is the score function of a diffusion
process, i.e. the generation process using score function sθ, is the inverse of a diffusion process. If
additionally sθ(x, t) = s∗(x, t) for a single t = t0 and for all x in an open subset of Rd, where s∗is
the score function of a target diffusion process, then sθ(x, t) = s∗(x, t) everywhere."
INTRODUCTION,0.037037037037037035,"Simply put, the above statement states that: i) satisfying CP and being a conservative vector field is
enough to guarantee that the sampling process is the inverse of some diffusion process and ii) to learn
the score function everywhere it suffices to learn it for a single t0 and an open subset of x’s."
INTRODUCTION,0.03880070546737213,"We propose a loss function to train for the Consistency Property and we show experimentally that
regularizing the standard score matching objective using our property leads to better models."
INTRODUCTION,0.04056437389770723,Summary of Contributions:
INTRODUCTION,0.042328042328042326,"1. We identify an invariant property, consistency of the denoiser hθ, that any perfectly trained
model should satisfy."
INTRODUCTION,0.04409171075837742,"2. We prove that if the denoiser hθ(x, t) satisfies CP and its implied score function sθ(x, t) =
(hθ(x, t)−x)/σ2
t is a conservative field, then sθ(x, t) is the score function of some diffusion
process, even if there are learning errors with respect to the score of the target process, which
generates the training data."
WE PROVE THAT OPTIMIZING FOR THE SCORE IN A SUBSET OF THE DOMAIN AND ENFORCING THESE TWO,0.04585537918871252,"3. We prove that optimizing for the score in a subset of the domain and enforcing these two
properties, guarantees that the score is learned correctly in all the domain, in the limit where
the error approaches zero."
WE PROVE THAT OPTIMIZING FOR THE SCORE IN A SUBSET OF THE DOMAIN AND ENFORCING THESE TWO,0.047619047619047616,"4. We propose a novel training objective that enforces the Consistency Property. Our new
objective optimizes the network to have consistent predictions on data points from the
learned distribution."
WE PROVE THAT OPTIMIZING FOR THE SCORE IN A SUBSET OF THE DOMAIN AND ENFORCING THESE TWO,0.04938271604938271,"5. We show experimentally that, paired with the original Denoising Score Matching (DSM)
loss, our objective improves generation quality on conditional and unconditional generation
on CIFAR-10, and in AFHQ and FFHQ."
WE CONDUCT AN ABLATION STUDY WHICH SHOWCASES THAT EVEN IF WE DO NOT OPTIMIZE FOR DSM FOR,0.05114638447971781,"6. We conduct an ablation study which showcases that even if we do not optimize for DSM for
some values of t, satisfying CP enforces good score approximation there."
BACKGROUND,0.05291005291005291,"2
Background"
BACKGROUND,0.054673721340388004,"Diffusion processes, score functions and denoising.
Diffusion models are trained by solving a
supervised regression problem [49, 18]. The function that one aims to learn, called the score function
(defined below), is equivalent (up to a linear transformation) to a denoising function [15, 54], whose
goal is to denoise an image that was injected with noise. In particular, for some target distribution p0,
one’s goal is to learn the following function h: Rd × [0, 1] →Rd:"
BACKGROUND,0.0564373897707231,"h(x, t) = Ex0∼p0, xt∼N(x0,σ2
t Id)[x0 | xt = x].
(2)"
BACKGROUND,0.0582010582010582,"In other words, the goal is to predict the expected “clean” image x0 given a corrupted version of
it, assuming that the image was sampled from p0 and its corruption was done by adding noise to it"
BACKGROUND,0.059964726631393295,"from N(0, σ2
t Id), where σ2
t is a non-negative and increasing function of t. Given such a function h,
we can generate samples from p0 by solving a Stochastic Differential Equation (SDE) that depends
on h [51]. Specifically, one starts by sampling x1 from some fixed distribution and then runs the
following SDE backwards in time:"
BACKGROUND,0.06172839506172839,"dxt = −g(t)2 h(xt, t) −xt"
BACKGROUND,0.06349206349206349,"σ2
t
dt + g(t)dBt,
(3)"
BACKGROUND,0.06525573192239859,"where Bt is a reverse-time Brownian motion3 and g(t)2 = dσ2
t
dt . To explain how Eq. (3) was derived,
consider the forward SDE that starts with a clean image x0 and slowly injects noise:"
BACKGROUND,0.06701940035273368,"dxt = g(t)dBt, x0 ∼p0,
(4)"
BACKGROUND,0.06878306878306878,"where Bt is a standard Brownian motion. We notice here that the xt under Eq. (4) is N(x0, σ2
t Id),
where x0 ∼p0, so it has the same distribution as in Eq. (2). Remarkably, such SDEs are reversible in
time [2]. Hence, the diffusion process of Eq. (4) can be viewed as a reversed-time diffusion:"
BACKGROUND,0.07054673721340388,"dxt = −g(t)2∇x log p(xt, t)dt + g(t)dBt,
(5)"
BACKGROUND,0.07231040564373897,"where p(xt, t) is the density of xt at time t. We note that s(x, t) := ∇x log p(x, t) is called the score
function of xt at time t. Using Tweedie’s lemma [15], one obtains the following relationship between
the denoising function h and the score function:"
BACKGROUND,0.07407407407407407,"∇x log p(x, t) = h(x, t) −x"
BACKGROUND,0.07583774250440917,"σ2
t
.
(6)"
BACKGROUND,0.07760141093474426,"Substituting Eq. (6) in Eq. (5), one obtains Eq. (3)."
BACKGROUND,0.07936507936507936,"Training via denoising score matching.
The standard way to train hθ is via denoising score
matching. This is performed by obtaining samples of x0 ∼p0 and xt ∼N(x0, σ2
t Id) and training to
minimize"
BACKGROUND,0.08112874779541446,"Ex0∼p0,xt∼N(x0,σ2
t Id) LSM
t,xt,x0(θ) = Ex0∼p0,xt∼N(x0,σ2
t Id) ∥hθ(xt, t) −x0∥2 ,"
BACKGROUND,0.08289241622574955,"where the optimization is over some family of functions, {hθ}θ∈Θ. It was shown by Vincent [54]
that optimizing Eq. (2) is equivalent to optimizing hθ in mean-squared-error on a random point xt
that is a noisy image, xt ∼N(x0, σ2
t Id) where x0 ∼p0:"
BACKGROUND,0.08465608465608465,"Ext ∥hθ(xt, t) −h∗(xt, t)∥2 ,"
BACKGROUND,0.08641975308641975,where h∗is the true denoising function from Eq. (2).
THEORY,0.08818342151675485,"3
Theory"
THEORY,0.08994708994708994,"We define below the Consistency Property that a function h should satisfy. Simply put, it states that
the output of h(x, t) (which is meant to approximate the conditional expectation of x0 conditioned
on xt = x) is consistent with the average point x0 generated using h and conditioning on xt = x.
Recall from the previous section that generation according to h conditioning on xt = x is done by
running the following SDE backwards in time conditioning on xt = x:"
THEORY,0.09171075837742504,"dxt = −g(t)2 h(xt, t) −xt"
THEORY,0.09347442680776014,"σ2
t
dt + g(t)2dBt,
(7)"
THEORY,0.09523809523809523,"CP is therefore defined as follows:
Property 1 (Consistency Property.). A function h: Rd × [0, 1] →Rd is said to satisfy CP iff for all
t ∈(0, 1] and all x ∈Rd,
h(x, t) = Eh[x0 | xt = x],
(8)
where Eh[x0 | xt = x] corresponds to the conditional expectation of x0 in the process that starts with
xt = x and samples x0 by running the SDE of Eq. (7) backwards in time (where note that the SDE
uses h)."
THEORY,0.09700176366843033,"3A Brownian motion Bt is a stochatic process that injects noise while one goes forward in time, and a
reverse-time Brownian motion ¯Bt injects noise while one goes backwards in time."
THEORY,0.09876543209876543,"The following lemma states that Property 1 holds if and only if the model prediction, h(x, t), h(xt, t)
is a reverse-Martingale under the same process of Eq. (7).
Lemma 3.1. Property 1 holds if and only if the following two properties hold:"
THEORY,0.10052910052910052,"• The function h is a reverse-Martingale, namely: for all t > t′ and for any x:"
THEORY,0.10229276895943562,"h(x, t) = Eh[h(xt′, t′) | xt = x],"
THEORY,0.10405643738977072,"where the expectation is over xt′ that is sampled according to Eq. (7) with the same function
h, given the initial condition xt = x."
THEORY,0.10582010582010581,"• For all x ∈Rd, h(x, 0) = x."
THEORY,0.10758377425044091,"The proof of this lemma is included in Section B.2. Further, we introduce one more property that will
be required for our theoretical results: the learned vector-field should be conservative.
Property 2 (Conservative vector field / Score Property.). Let h: Rd × [0, 1] →Rd. We say that
h induces a conservative vector field (or that satisfies the score property) if for any t ∈(0, 1] there
exists some probability density p(·, t) such that"
THEORY,0.10934744268077601,"h(x, t) −x"
THEORY,0.1111111111111111,"σ2
t
= ∇log p(x, t)."
THEORY,0.1128747795414462,"We note that the optimal denoiser, i.e., h, defined as in Eq. (2), satisfies both of the properties we
introduced. In the paper, we will focus on enforcing CP and we are going to assume conservativeness
for our theoretical results. This assumption can be relaxed to hold only at a single t ∈(0, 1] using the
results of Lai et al. [33]."
THEORY,0.1146384479717813,"Next, we show the theoretical consequences of enforcing Properties 1 and 2. First, we show that
this enforces h to indeed correspond to a denoising function, namely, h satisfies Eq. (2) for some
distribution p′
0 over x0. However, this does not imply that p0 is the correct underlying distribution
that we are trying to learn. Indeed, these properties can apply to any distribution p0. Yet, we can
show that if we learn h correctly for some inputs and if these properties apply everywhere then h is
learned correctly everywhere.
Theorem 3.2. Let h: Rd × [0, 1] →Rd be a bounded continuous function. Then:"
THEORY,0.1164021164021164,"1. The function h satisfies both Properties 1 and 2 if and only if h is defined by Eq. (2) for some
distribution p0."
THEORY,0.11816578483245149,"2. Assume that h satisfies Properties 1 and 2. Further, let h∗be another function that cor-
responds to Eq. (2) with some initial distribution p∗
0. Assume that h = h∗on some open
set U ⊆Rd and some fixed t0 ∈(0, 1], namely, h(x, t0) = h∗(x, t0) for all x ∈U. Then,
h∗(x, t) = h(x, t) for all x and all t.
Remark 3.3. While our theorem uses Eq. (2) which describes the VE-SDE (Variance Exploding
SDE), it is also valid for VP-SDE (Variance Preserving SDE), as these two SDEs are equivalent up to
appropriate scaling (see e.g. [31, 28])."
METHOD,0.11992945326278659,"4
Method"
METHOD,0.12169312169312169,"Theorem 3.2 motivates enforcing CP on the learned model. We notice that the CP Equation Eq. (8)
may be expensive to train for, because it requires one to generate whole trajectories. Rather, we use
the equivalent Martingale assumption of Lemma 3.1, which can be observed locally with only partial
trajectories4. We suggest the following loss function, for some fixed t, t′ and x:"
METHOD,0.12345679012345678,"LCP
t,t′,x(θ) = 1"
METHOD,0.12522045855379188,"2 ||Eθ[hθ(xt′, t′) | xt = x] −hθ(x, t)||2 ,"
METHOD,0.12698412698412698,"where the expectation Eθ[· | xt = x] is taken according to process Eq. (7) parameterized by hθ with
the initial condition xt = x. Differentiating this expectation, one gets the following (see Section B.1"
METHOD,0.12874779541446207,"4According to Lemma 3.1, in order to completely train for Property 1, one has to also enforce hθ(x, 0) = x,
however, this is taken care from the denoising score matching objective Eq. (2)."
METHOD,0.13051146384479717,for full derivation):
METHOD,0.13227513227513227,"∇LCP
t,t′,x(θ) = Eθ [hθ(xt′, t′) −hθ(xt, t) | xt = x]⊤Eθ"
METHOD,0.13403880070546736,"
hθ(xt′, t′)∇θ log (pθ(xt′ | xt = x)) +"
METHOD,0.13580246913580246,"∇θhθ(xt′, t′) −∇θhθ(xt, t)
 xt = x

,"
METHOD,0.13756613756613756,"where pθ corresponds to the same probability measure where the expectation Eθ is taken from and
∇θhθ corresponds to the Jacobian matrix of hθ where the derivatives are taken with respect to θ.
Notice, however, that computing the expectation accurately might require a large number of samples.
Instead, it is possible to obtain a stochastic gradient of this target by taking two samples, xt′ and x′
t′,
independently, from the conditional distribution of xt′ conditioned on xt = x and replace each of the
two expectations in the formula above with one of these two samples."
METHOD,0.13932980599647266,We further notice the gradient of the CP loss can be written as
METHOD,0.14109347442680775,"∇θLCP
t,t′,x(θ) = 1"
METHOD,0.14285714285714285,"2 ∇θ ∥Eθ[hθ(xt′, t′)] −hθ(x, t)∥2
|
{z
}
A +"
METHOD,0.14462081128747795,"Eθ [hθ(xt′, t′) −hθ(x, t)]⊤Eθ [∇θ log (p(xt′)) hθ(xt′, t′)]
(9)"
METHOD,0.14638447971781304,"In order to save on computation time, we trained by taking gradient steps with respect to only the first
summand (term A) in this decomposition. This term appears in line (4), while we ignored the term in
line (9). Notice that if CP is preserved then this term becomes zero, which implies that no update is
made, as desired."
METHOD,0.14814814814814814,"It remains to determine how to select t, t′ and xt′. Notice that t has to vary throughout the whole
range of [0, 1] whereas t′ can either vary over [0, t], however, it is sufficient to take t′ ∈[t −ϵ, t].
However, the further away t and t′ are, we need to run more steps of the reverse SDE to avoid
large discretization errors. Instead, we enforce the property only on small time windows using
that consistency over small intervals implies global consistency. We notice that xt can be chosen
arbitrarily and two possible choices are to sample it from the target noisy distribution pt or from the
model. See Section D, Algorithm 1 for a pseudocode with more implementation details.
Remark 4.1. It is important to sample xt′ conditioned on xt according to the specific SDE Eq. (7).
While a variety of alternative SDEs exist which preserve the same marginal distribution at any t, they
might not preseve the conditionals."
EXPERIMENTS,0.14991181657848324,"5
Experiments"
EXPERIMENTS,0.15167548500881833,"For all our experiments, we rely on the official open-sourced code and the training and evaluation
hyper-parameters from the paper “Elucidating the Design Space of Diffusion-Based Generative
Models” [28] that, to the best of our knowledge, holds the current state-of-the-art on conditional
generation on CIFAR-10 and unconditional generation on CIFAR-10, AFHQ (64 × 64 resolution),
FFHQ (64 × 64 resolution). We refer to the models trained with our regularization as “CDM (Ours)”
and to models trained with vanilla Denoising Score Matching (DSM) as “EDM” models. “CDM”
models are trained with the weighted objective:"
EXPERIMENTS,0.15343915343915343,"Lours
λ
(θ) = Et"
EXPERIMENTS,0.15520282186948853,"
Ex0∼p0,xt∼N(x0,σ2
t Id) LSM
t,xt,x0(θ) + λ Ext∼pt Et′∼U[t−ϵ,t]LCP
t,t′,xt(θ)

,"
EXPERIMENTS,0.15696649029982362,"while the “EDM” models are trained only with the first term of the outer expectation. We also denote
in the name whether the models have been trained with the Variance Preserving (VP) [51, 18] or the
Variance Exploding [51, 50, 49], e.g. we write EDM-VP. Finally, for completeness, we also report
scores from the models of Song et al. [51], following the practice of the EDM paper. We refer to the
latter baselines as “NCSNv3” baselines."
EXPERIMENTS,0.15873015873015872,"We train diffusion models, with and without our regularization, for conditional generation on CIFAR-
10 and unconditional generation on CIFAR-10 and AFHQ (64 × 64 resolution). For the re-trained
models on CIFAR-10, we use exactly the same training hyperparameters as in Karras et al. [28] and
we verify that our re-trained models match (within 1%) the FID numbers mentioned in the paper. For
AFHQ, we dropped the batch size from the suggested value of 512 to 256 to save on computational"
EXPERIMENTS,0.16049382716049382,"resources, which increased the FID from 1.96 (reported value) to 2.29. All models were trained
for 200k iterations, as in Karras et al. [28]. Finally, we retrain a baseline model on FFHQ for 150k
iterations and we finetune it for 5k steps using our proposed objective."
EXPERIMENTS,0.16225749559082892,"Implementation Choices and Computational Requirements.
As mentioned, when enforcing
CP, we are free to choose t′ anywhere in the interval [0, t]. When t, t′ are far away, sampling x′
t
from the distribution pθ
t′(x′
t|xt) requires many sampling steps (to reduce discretization errors). Since
this needs to be done for every Gradient Descent update, the training time increases significantly.
Instead, we notice that local consistency implies global consistency. Hence, we first fix the number
of sampling steps to run in every training iteration and then we sample t′ uniformly in the interval
[t −ϵ, t] for some specified ϵ. For all our experiments, we fix the number of sampling steps to 6
which roughly increases the training time needed by 1.5x. We train all our models on a DGX server
with 8 A100 GPUs with 80GBs of memory each."
CONSISTENCY PROPERTY TESTING,0.164021164021164,"5.1
Consistency Property Testing"
CONSISTENCY PROPERTY TESTING,0.1657848324514991,"We are now ready to present our results. The first thing that we check is whether regularizing for
CP actually leads to models that are more consistent with their predictions, as the property implies.
Specifically, we want to check that the model trained with Lours
λ
achieves lower Consistency error, i.e.
lower LCP
t,t′,xt. To check this, we do the following two tests: i) we fix t = 1 and we show how LCP
t,t′,xt
changes as t′ changes in [0, 1], ii) we fix t′ = 0 and we show how the loss is changing as you change
t in [0, 1]. Intuitively, the first test shows how the violation of CP splits across the sampling process
and the second test shows how much you finally (t′ = 0) violate the property if the violation started
at time t. The results are shown in Figures 1a, 1b, respectively, for the models trained on AFHQ. We
include additional results for CIFAR-10, FFHQ in Figures 4, 5, 6, 7 of the Appendix. As shown,
indeed regularizing for the CP Loss drops the LCP
t,t′,xt as expected. See Section C.1 for additional
details and discussion."
CONSISTENCY PROPERTY TESTING,0.1675485008818342,"0
10
20
30
40
50
60
70
80 t 0.000 0.001 0.002 0.003 0.004 0.005"
CONSISTENCY PROPERTY TESTING,0.1693121693121693,"||
x0
p (x0|xt)[x0]
h (xt, t)||2"
CONSISTENCY PROPERTY TESTING,0.1710758377425044,"Baseline
Ours"
CONSISTENCY PROPERTY TESTING,0.1728395061728395,Consistency Property Testing (AFHQ)
CONSISTENCY PROPERTY TESTING,0.1746031746031746,Backward Sampler (1000) steps
CONSISTENCY PROPERTY TESTING,0.1763668430335097,"(a) Consistency Property Testing on AFHQ. The
plot illustrates how the Consistency Loss, LCP
t,t′,xt,
behaves for t′ = 0, as t changes."
CONSISTENCY PROPERTY TESTING,0.1781305114638448,"0
10
20
30
40
50
60
70
80 t 0.000 0.001 0.002 0.003 0.004 0.005"
CONSISTENCY PROPERTY TESTING,0.17989417989417988,"||
xt
p (xt|x1)[h (xt, t)]
h (x1, 1.0)||2"
CONSISTENCY PROPERTY TESTING,0.18165784832451498,"Baseline
Ours"
CONSISTENCY PROPERTY TESTING,0.18342151675485008,Consistency Property Testing (AFHQ)
CONSISTENCY PROPERTY TESTING,0.18518518518518517,Backward Sampler (1000) steps
CONSISTENCY PROPERTY TESTING,0.18694885361552027,"(b) Consistency Property Testing on AFHQ. The
plot illustrates how the Consistency Loss, LCP
t,t′,xt,
behaves for t = 0, as t′ changes."
CONSISTENCY PROPERTY TESTING,0.18871252204585537,Figure 1: Consistency Property Testing on AFHQ.
CONSISTENCY PROPERTY TESTING,0.19047619047619047,"Performance. We evaluate the performance of our models. Following the methodology of Karras
et al. [28], we generate 150k images from each model and we report the minimum FID computed
on three sets of 50k images each. We keep checkpoints during training and we report FID for
30k, 70k, 100k, 150k, 180k and 200k iterations in Table 1. We also report the best FID found for
each model, after evaluating checkpoints every 5k iterations (i.e. we evaluate 40 models spanning
200k steps of training). As shown in the Table, the proposed CP regularization yields improvements
throughout the training. In the case of CIFAR-10 (conditional and unconditional) where the re-trained
baseline was trained with exactly the same hyperparameters as the models in the EDM [28] paper,"
CONSISTENCY PROPERTY TESTING,0.19223985890652556,"(a) Uncurated images by our model trained on
AFHQ. FID: 2.21, NFEs: 79."
CONSISTENCY PROPERTY TESTING,0.19400352733686066,"(b) Uncurated images by our conditional CIFAR-
10 model. FID: 1.77, NFEs: 35."
CONSISTENCY PROPERTY TESTING,0.19576719576719576,Figure 2: Comparison of uncurated images generated by two different models.
CONSISTENCY PROPERTY TESTING,0.19753086419753085,"Model
30k
70k
100k
150k
180k
200k
Best
CDM-VP (Ours) AFHQ"
CONSISTENCY PROPERTY TESTING,0.19929453262786595,"3.00
2.44
2.30
2.31
2.25
2.44
2.21
EDM-VP (retrained)
3.27
2.41
2.61
2.43
2.29
2.61
2.26
EDM-VP (reported)∗5
1.96
EDM-VE (reported)∗
2.16
NCSNv3-VP (reported)∗
2.58
NCSNv3-VE (reported)∗
18.52
CDM-VP (Ours)
2.44
1.94
1.88
1.88
1.80
1.82
1.77
EDM-VP (retrained)
2.50
1.99
1.94
1.85
1.86
1.90
1.82
EDM-VP (reported)
CIFAR-10
1.79
EDM-VE (reported)
(cond.)
1.79
NCSNv3-VP (reported)
2.48
NCSNv3-VE (reported)
3.11
CDM-VP (Ours)
2.83
2.21
2.14
2.08
1.99
2.03
1.95
EDM-VP (retrained)
2.90
2.32
2.15
2.09
2.01
2.13
2.01
EDM-VP (reported)
CIFAR-10
1.97
EDM-VE (reported)
(uncond.)
1.98
NCSNv3-VP (reported)
3.01
NCSNv3-VE (reported)
3.77
CDM-VP (finetuned)
FFHQ
2.61
EDM-VP (retrained)
2.68"
CONSISTENCY PROPERTY TESTING,0.20105820105820105,"Table 1: FID results for deterministic sampling, using the Karras et al. [28] second-order samplers.
For the CIFAR-10 models, we do 35 function evaluations and for AFHQ 79."
CONSISTENCY PROPERTY TESTING,0.20282186948853614,"our CDM models achieve a new state-of-the-art. We further show that our CP regularization can be
applied on top of a pre-trained model. Specifically, we train a baseline EDM-VP model on FFHQ
64 × 64 for 150k using vanilla Denoising Score Matching. We then do 5k steps of finetuning, with
and without our CP regularization and we measure the FID score of both models. The baseline model
achieves FID 2.68 while the model finetuned with CP regularization achieves 2.61. This experiment
shows the potential of applying our CP regularization to pre-trained models, potentially even at large
scale, e.g. we could apply this idea with text-to-image models such as Stable Diffusion [42]. We
leave this direction for future work."
CONSISTENCY PROPERTY TESTING,0.20458553791887124,"Uncurated samples from our best models on AFHQ, CIFAR-10 and FFHQ are given in Figures 2a, 2b
and 8. One benefit of the deterministic samplers is the unique identifiability property [51]. Intuitively,
this means that by using the same noise and the same deterministic sampler, we can directly compare"
CONSISTENCY PROPERTY TESTING,0.20634920634920634,"visually models that might have been trained in completely different ways. We select a couple of
images from Figure 2a (AFHQ generations) and we compare the generated images from our model
with the ones from the EDM baseline for the same noises. The results are shown in Figure 3. As
shown, the CP regularization fixes several geometric inconsistencies for the picked images. We
underline that the shown images are examples for which CP regularization helped and that potentially
there are images for which the baseline models give more realistic results."
CONSISTENCY PROPERTY TESTING,0.20811287477954143,"We note that an appropriate regularization parameter λ for our consistency loss has to be chosen. We
found that an excessively large λ harms the performance: while the CP regularization enforces the
model to obey some diffusion process, it does not enforce it to obey the true diffusion process, and a
large λ might disturb with the score-matching signal."
CONSISTENCY PROPERTY TESTING,0.20987654320987653,"Figure 3: Visual comparison of EDM model
(top) and CDM model (Ours, bottom) us-
ing deterministic sampling initiated with the
same noise. As seen, the CP regularization
fixes several geometric inconsistencies and
artifacts in the generated images. In order
to obtain this comparison, we generated 64
images both with EDM and CDM. We found
that in 14 of these images, CDM provided
considerable improvement and for the remain-
der there was no significant difference."
CONSISTENCY PROPERTY TESTING,0.21164021164021163,"Model
FID
EDM (baseline)
5.81"
CONSISTENCY PROPERTY TESTING,0.21340388007054673,"CDM, all times t
5.45"
CONSISTENCY PROPERTY TESTING,0.21516754850088182,"CDM, for some t
6.59"
CONSISTENCY PROPERTY TESTING,0.21693121693121692,"CDM, for some t
14.52
early stopped sampling"
CONSISTENCY PROPERTY TESTING,0.21869488536155202,"Table 2: Ablation study on removing the
DSM loss for some t. Table reports FID re-
sults after 10k steps of training on CIFAR-10."
CONSISTENCY PROPERTY TESTING,0.2204585537918871,"Ablation Study for Theoretical Predictions. One interesting implication of Theorem 3.2 is that
it suggests that we only need to learn the score perfectly on some fixed t0 and then the CP implies
that the score is learned everywhere (for all t and in the whole space). This motivates the following
experiment: instead of using as our loss the weighted sum of DSM and our CP regularization for all t,
we will not use DSM for t ≤tthreshold, for some tthreshold that we test our theory for."
CONSISTENCY PROPERTY TESTING,0.2222222222222222,"We pick tthreshold such that for 20% of the diffusion (on the side of clean images), we do not train
with DSM. For the rest 80% we train with both DSM and our CP regularization. Since this is only an
ablation study, we train for only 10k steps on (conditional) CIFAR-10. We report FID numbers for
three models: i) training with only DSM, ii) training with DSM and CP regularization everywhere,
iii) training with DSM for 80% of times t and CP regularization everywhere. In our reported models,
we also include FID of an early stopped sampling of the latter model, i.e. we do not run the sampling
for t < tthreshold and we just output hθ(xtthreshold, tthreshold). The numbers are summarized in Table
2. As shown, the theory is predictive since early stopping the generation at time t gives significantly
worse results than continuing the sampling through the times that were never explicitly trained for
approximating the score (i.e. we did not use DSM for those times). That said, the best results are
obtained by combining DSM and our CP regularization everywhere, which is what we did for all the
other experiments in the paper."
RELATED WORK,0.2239858906525573,"6
Related Work"
RELATED WORK,0.2257495590828924,"The fact that imperfect learning of the score function introduces a shift between the training and
the sampling distribution has been well known. Chen et al. [6, 7] analyze how the l2 error in the
approximation of the score function propagates to Total Variation distance error bounds between the
true and the learned distribution. Several methods for mitigating this issue have been proposed, but
the majority of the attempts focus on changing the sampling process [51, 28, 24, 46]. A related work
is the Analog-Bits paper [8] that conditions the model during training with past model predictions."
RELATED WORK,0.2275132275132275,"Karras et al. [28] discusses potential violations of invariances, such as the non-conservativity of the
induced vector field, due to imperfect score matching. However, they do not formally test or enforce
this property. Chao et al. [5] shows that failure to satisfy the conservativity property can harm the
performance, and they propose a modification to relieve this degradation. Lai et al. [33] study the
problem of regularizing diffusion models to satisfy the Fokker-Planck equation. While we show
in Theorem 3.2 that perfect conservative training enforces the Fokker-Planck equation, we notice
that their training method is different: they suggest enforcing the equation locally by using the finite
differences method to approximate the derivatives. Further, they do not train on drifted data. Instead,
we notice that our CP loss is well suited to handle drifted data since it operates across trajectories
generated by the model."
RELATED WORK,0.2292768959435626,"A concurrent work by Song et al. [52] proposes Consistency Models (CM), a new class of generative
models that output directly the solution of the Probability Flow ODE. This idea resembles the
consistency in the model outputs that we enforce through CP, but the motivation is different: CM
attempts to accelerate sampling and we attempt to improve generation quality. The two methods are
similar in that they enforce a property that the model should satisfy. In the case of the CM, the ODE
solver should produce the same solution when evaluated at points that belong to the same trajectory.
Our property is that on expectation the predictions should not be changing for points that have the
same origin. One way to view it is that CM applies our consistency condition but on the deterministic
sampler (for which the expectation becomes the point itself). Subsequent work by Lai et al. [34]
compares our CDM to Consistency Models [52] and to Fokker Planck regularization [33]."
CONCLUSIONS AND FUTURE WORK,0.2310405643738977,"7
Conclusions and Future Work"
CONCLUSIONS AND FUTURE WORK,0.2328042328042328,"We proposed an objective that enforces the trained network to follow a reverse Martingale, thereby
having self-consistent predictions over time. We optimize this objective with points from the sampling
distribution, effectively reducing the sampling drift observed in prior empirical works. Theoretically,
we show that CP implies that we are sampling from the reverse of some diffusion process. Together
with the assumption that the network has learned the score correctly in a subset of the domain, we
can prove that CP (together with conservativity of the vector field) implies that the score is learned
correctly everywhere - in the limit where the error approaches zero. Empirically, we use our objective
to obtain state-of-the-art for CIFAR-10 and baseline improvements on AFHQ and FFHQ."
CONCLUSIONS AND FUTURE WORK,0.2345679012345679,"There are limitations of our method and several directions for future work. The proposed regulariza-
tion increases the training time. It would be interesting to explore how to enforce CP in more effective
ways in future work. Further, our method does not test nor enforce that the induced vector-field is
conservative, which is a key theoretical assumption. Our method guarantees only indirectly improve
the performance in the samples from the learned distribution by enforcing some invariant. Finally,
our theoretical result holds in the limit where the error of our regularized objective approaches zero
and it would be meaningful to theoretically study also the constant-error regime."
ACKNOWLEDGMENTS,0.23633156966490299,"8
Acknowledgments"
ACKNOWLEDGMENTS,0.23809523809523808,"This research has been supported by NSF Grants CCF 1763702, AF 1901292, CNS 2148141, Tripods
CCF 1934932, IFML CCF 2019844, the Texas Advanced Computing Center (TACC) and research
gifts by Western Digital, WNCG IAP, UT Austin Machine Learning Lab (MLL), Cisco and the Archie
Straiton Endowed Faculty Fellowship. Giannis Daras has been supported by the Onassis Fellowship,
the Bodossaki Fellowship and the Leventis Fellowship. Constantinos Daskalakis has been supported
by NSF Awards CCF-1901292, DMS-2022448 and DMS2134108, a Simons Investigator Award, the
Simons Collaboration on the Theory of Algorithmic Fairness and a DSTA grant."
REFERENCES,0.23985890652557318,References
REFERENCES,0.24162257495590828,"[1] Namrata Anand and Tudor Achim. Protein structure and sequence generation with equivariant
denoising diffusion probabilistic models. arXiv preprint arXiv:2205.15019, 2022."
REFERENCES,0.24338624338624337,"[2] Brian D.O. Anderson. Reverse-time diffusion equation models. Stochastic Processes and their
Applications, 12(3):313–326, 1982."
REFERENCES,0.24514991181657847,"[3] Marius Arvinte, Ajil Jalal, Giannis Daras, Eric Price, Alex Dimakis, and Jonathan I Tamir.
Single-shot adaptation using score-based models for mri reconstruction. In International Society
for Magnetic Resonance in Medicine, Annual Meeting, 2022."
REFERENCES,0.24691358024691357,"[4] Arpit Bansal, Eitan Borgnia, Hong-Min Chu, Jie S Li, Hamid Kazemi, Furong Huang, Micah
Goldblum, Jonas Geiping, and Tom Goldstein. Cold Diffusion: Inverting arbitrary image
transforms without noise. arXiv preprint arXiv:2208.09392, 2022."
REFERENCES,0.24867724867724866,"[5] Chen-Hao Chao, Wei-Fang Sun, Bo-Wun Cheng, and Chun-Yi Lee. On investigating the
conservative property of score-based generative models. 2023."
REFERENCES,0.25044091710758376,"[6] Sitan Chen, Sinho Chewi, Jerry Li, Yuanzhi Li, Adil Salim, and Anru R Zhang. Sampling is as
easy as learning the score: theory for diffusion models with minimal data assumptions. arXiv
preprint arXiv:2209.11215, 2022."
REFERENCES,0.25220458553791886,"[7] Sitan Chen, Giannis Daras, and Alexandros G Dimakis. Restoration-degradation beyond linear
diffusions: A non-asymptotic analysis for ddim-type samplers. arXiv preprint arXiv:2303.03384,
2023."
REFERENCES,0.25396825396825395,"[8] Ting Chen, Ruixiang Zhang, and Geoffrey Hinton. Analog bits: Generating discrete data using
diffusion models with self-conditioning. arXiv preprint arXiv:2208.04202, 2022."
REFERENCES,0.25573192239858905,"[9] Gabriele Corso, Hannes Stärk, Bowen Jing, Regina Barzilay, and Tommi Jaakkola. Diffdock:
Diffusion steps, twists, and turns for molecular docking. arXiv preprint arXiv:2210.01776,
2022."
REFERENCES,0.25749559082892415,"[10] Giannis Daras and Alexandros G Dimakis. Multiresolution textual inversion. arXiv preprint
arXiv:2211.17115, 2022."
REFERENCES,0.25925925925925924,"[11] Giannis Daras, Yuval Dagan, Alexandros G Dimakis, and Constantinos Daskalakis. Score-
guided intermediate layer optimization: Fast langevin mixing for inverse problem. arXiv
preprint arXiv:2206.09104, 2022."
REFERENCES,0.26102292768959434,"[12] Giannis Daras, Mauricio Delbracio, Hossein Talebi, Alexandros G Dimakis, and Peyman Milan-
far. Soft diffusion: Score matching for general corruptions. arXiv preprint arXiv:2209.05442,
2022."
REFERENCES,0.26278659611992944,"[13] Jacob Deasy, Nikola Simidjievski, and Pietro Liò. Heavy-tailed denoising score matching.
arXiv preprint arXiv:2112.09788, 2021."
REFERENCES,0.26455026455026454,"[14] Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis.
Advances in Neural Information Processing Systems, 34:8780–8794, 2021."
REFERENCES,0.26631393298059963,"[15] Bradley Efron. Tweedie’s formula and selection bias. Journal of the American Statistical
Association, 106(496):1602–1614, 2011."
REFERENCES,0.26807760141093473,"[16] Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit H. Bermano, Gal Chechik, and
Daniel Cohen-Or. An image is worth one word: Personalizing text-to-image generation using
textual inversion, 2022. URL https://arxiv.org/abs/2208.01618."
REFERENCES,0.2698412698412698,"[17] Ulf Grenander and Michael I Miller. Representations of knowledge in complex systems. Journal
of the Royal Statistical Society: Series B (Methodological), 56(4):549–581, 1994."
REFERENCES,0.2716049382716049,"[18] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances
in Neural Information Processing Systems, 33:6840–6851, 2020."
REFERENCES,0.27336860670194,"[19] Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, Alexey Gritsenko,
Diederik P Kingma, Ben Poole, Mohammad Norouzi, David J Fleet, et al. Imagen video: High
definition video generation with diffusion models. arXiv preprint arXiv:2210.02303, 2022."
REFERENCES,0.2751322751322751,"[20] Jonathan Ho, Tim Salimans, Alexey Gritsenko, William Chan, Mohammad Norouzi, and David J
Fleet. Video diffusion models. arXiv:2204.03458, 2022."
REFERENCES,0.2768959435626102,"[21] Wenyi Hong, Ming Ding, Wendi Zheng, Xinghan Liu, and Jie Tang. Cogvideo: Large-scale
pretraining for text-to-video generation via transformers. arXiv preprint arXiv:2205.15868,
2022."
REFERENCES,0.2786596119929453,"[22] Emiel Hoogeboom and Tim Salimans.
Blurring diffusion models.
arXiv preprint
arXiv:2209.05557, 2022."
REFERENCES,0.2804232804232804,"[23] Ajil Jalal, Marius Arvinte, Giannis Daras, Eric Price, Alexandros G Dimakis, and Jon Tamir.
Robust compressed sensing mri with deep generative priors. Advances in Neural Information
Processing Systems, 34:14938–14954, 2021."
REFERENCES,0.2821869488536155,"[24] Alexia Jolicoeur-Martineau, Ke Li, Rémi Piché-Taillefer, Tal Kachman, and Ioannis Mitliagkas.
Gotta go fast when generating data with score-based models. arXiv preprint arXiv:2105.14080,
2021."
REFERENCES,0.2839506172839506,"[25] Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative
adversarial networks. In Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition, pages 4401–4410, 2019."
REFERENCES,0.2857142857142857,"[26] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila.
Analyzing and improving the image quality of stylegan. In Proceedings of the IEEE/CVF
conference on computer vision and pattern recognition, pages 8110–8119, 2020."
REFERENCES,0.2874779541446208,"[27] Tero Karras, Miika Aittala, Samuli Laine, Erik Härkönen, Janne Hellsten, Jaakko Lehtinen,
and Timo Aila. Alias-free generative adversarial networks. Advances in Neural Information
Processing Systems, 34:852–863, 2021."
REFERENCES,0.2892416225749559,"[28] Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine. Elucidating the design space of
diffusion-based generative models. arXiv preprint arXiv:2206.00364, 2022."
REFERENCES,0.291005291005291,"[29] Dongjun Kim, Seungjae Shin, Kyungwoo Song, Wanmo Kang, and Il-Chul Moon. Soft
truncation: A universal training technique of score-based diffusion model for high precision
score estimation. In International Conference on Machine Learning, pages 11201–11228.
PMLR, 2022."
REFERENCES,0.2927689594356261,"[30] Kwanyoung Kim and Jong Chul Ye. Noise2score: tweedie’s approach to self-supervised image
denoising without clean images. Advances in Neural Information Processing Systems, 34:
864–874, 2021."
REFERENCES,0.2945326278659612,"[31] Diederik Kingma, Tim Salimans, Ben Poole, and Jonathan Ho. Variational diffusion models.
Advances in neural information processing systems, 34:21696–21707, 2021."
REFERENCES,0.2962962962962963,"[32] Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, and Bryan Catanzaro. Diffwave: A versatile
diffusion model for audio synthesis. In International Conference on Learning Representations,
2021."
REFERENCES,0.2980599647266314,"[33] Chieh-Hsin Lai, Yuhta Takida, Naoki Murata, Toshimitsu Uesaka, Yuki Mitsufuji, and Stefano
Ermon. Regularizing score-based models with score fokker-planck equations. In NeurIPS 2022
Workshop on Score-Based Methods, 2022."
REFERENCES,0.2998236331569665,"[34] Chieh-Hsin Lai, Yuhta Takida, Toshimitsu Uesaka, Naoki Murata, Yuki Mitsufuji, and Stefano
Ermon. On the equivalence of consistency-type models: Consistency models, consistent
diffusion models, and fokker-planck regularization. arXiv preprint arXiv:2306.00367, 2023."
REFERENCES,0.30158730158730157,"[35] Calvin Luo.
Understanding diffusion models: A unified perspective.
arXiv preprint
arXiv:2208.11970, 2022."
REFERENCES,0.30335097001763667,"[36] Chenlin Meng, Yang Song, Wenzhe Li, and Stefano Ermon. Estimating high order gradients of
the data distribution by denoising. Advances in Neural Information Processing Systems, 34:
25359–25369, 2021."
REFERENCES,0.30511463844797176,"[37] Sachit Menon, Alexandru Damian, Shijia Hu, Nikhil Ravi, and Cynthia Rudin. Pulse: Self-
supervised photo upsampling via latent space exploration of generative models. In Proceedings
of the ieee/cvf conference on computer vision and pattern recognition, pages 2437–2445, 2020."
REFERENCES,0.30687830687830686,"[38] Eliya Nachmani, Robin San Roman, and Lior Wolf. Denoising diffusion gamma models. arXiv
preprint arXiv:2110.05948, 2021."
REFERENCES,0.30864197530864196,"[39] Alexander Quinn Nichol and Prafulla Dhariwal. Improved denoising diffusion probabilistic
models. In International Conference on Machine Learning, pages 8162–8171. PMLR, 2021."
REFERENCES,0.31040564373897706,"[40] Ben Poole, Ajay Jain, Jonathan T. Barron, and Ben Mildenhall. Dreamfusion: Text-to-3d using
2d diffusion. arXiv, 2022."
REFERENCES,0.31216931216931215,"[41] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical
text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 2022."
REFERENCES,0.31393298059964725,"[42] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. High-
resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition, pages 10684–10695, 2022."
REFERENCES,0.31569664902998235,"[43] Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and Kfir Aberman.
Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation. 2022."
REFERENCES,0.31746031746031744,"[44] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed
Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S Sara Mahdavi, Rapha Gontijo Lopes, et al.
Photorealistic text-to-image diffusion models with deep language understanding. arXiv preprint
arXiv:2205.11487, 2022."
REFERENCES,0.31922398589065254,"[45] Arne Schneuing, Yuanqi Du, Charles Harris, Arian Jamasb, Ilia Igashov, Weitao Du, Tom
Blundell, Pietro Lió, Carla Gomes, Max Welling, et al. Structure-based drug design with
equivariant diffusion models. arXiv preprint arXiv:2210.13695, 2022."
REFERENCES,0.32098765432098764,"[46] Vikash Sehwag, Caner Hazirbas, Albert Gordo, Firat Ozgenel, and Cristian Canton. Generating
high fidelity data from low-density regions using diffusion models. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11492–11501,
2022."
REFERENCES,0.32275132275132273,"[47] Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsuper-
vised learning using nonequilibrium thermodynamics. In International Conference on Machine
Learning, pages 2256–2265. PMLR, 2015."
REFERENCES,0.32451499118165783,"[48] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. In
International Conference on Learning Representations, 2021."
REFERENCES,0.3262786596119929,"[49] Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data
distribution. Advances in Neural Information Processing Systems, 32, 2019."
REFERENCES,0.328042328042328,"[50] Yang Song and Stefano Ermon. Improved techniques for training score-based generative models.
Advances in neural information processing systems, 33:12438–12448, 2020."
REFERENCES,0.3298059964726631,"[51] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and
Ben Poole. Score-based generative modeling through stochastic differential equations. In
International Conference on Learning Representations, 2021."
REFERENCES,0.3315696649029982,"[52] Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever. Consistency models. arXiv
preprint arXiv:2303.01469, 2023."
REFERENCES,0.3333333333333333,"[53] Brian L Trippe, Jason Yim, Doug Tischer, Tamara Broderick, David Baker, Regina Barzilay,
and Tommi Jaakkola. Diffusion probabilistic modeling of protein backbones in 3d for the
motif-scaffolding problem. arXiv preprint arXiv:2206.04119, 2022."
REFERENCES,0.3350970017636684,"[54] Pascal Vincent. A connection between score matching and denoising autoencoders. Neural
computation, 23(7):1661–1674, 2011."
REFERENCES,0.3368606701940035,"A
Proof of Theorem 3.2"
REFERENCES,0.3386243386243386,"In Section A.1 we present a proof overview, in Section A.2 we present some preliminaries to the
proof, in Section A.3 we include the proof, with proofs of some lemmas omitted and in the remaining
sections we prove these lemmas."
REFERENCES,0.3403880070546737,"A.1
Proof overview"
REFERENCES,0.3421516754850088,"We start with the first part of the theorem. We assume that h satisfies Properties 1 and 2 and we will
show that h is defined by Eq. (2) for some distribution p0 (while the other direction in the equivalence
follows trivially from the definitions of these properties). Motivated by Eq. (6), define the function
s: Rd × (0, 1] according to"
REFERENCES,0.3439153439153439,"s(x, t) = h(x, t) −x"
REFERENCES,0.345679012345679,"σ2
t
.
(10)"
REFERENCES,0.3474426807760141,We will first show that s satisfies the partial differential equation ∂s
REFERENCES,0.3492063492063492,"∂t = g(t)2

Jss + 1"
REFERENCES,0.3509700176366843,"2△s

,
(11)"
REFERENCES,0.3527336860670194,"where Js ∈Rd×d is the Jacobian of s, (Js)ij = ∂si"
REFERENCES,0.3544973544973545,xj and each coordinate i of △s ∈Rd is the
REFERENCES,0.3562610229276896,"Laplacian of coordinate i of s, (△s)i = Pn
j=1
∂2si"
REFERENCES,0.35802469135802467,"∂x2
j . In order to obtain Eq. (11), first, we use a
generalization of Ito’s lemma, which states that for an SDE"
REFERENCES,0.35978835978835977,"dxt = µ(xt, t)dt + g(t)dBtx
(12)"
REFERENCES,0.36155202821869487,"and for f : Rd × [0, 1] →Rd, f(xt, t) satisfies the SDE"
REFERENCES,0.36331569664902996,"df(xt, t) =
∂f"
REFERENCES,0.36507936507936506,∂t + Jfµ −g(t)2
REFERENCES,0.36684303350970016,"2
△f

dt + g(t)JfdBt."
REFERENCES,0.36860670194003525,"If f is a reverse-Martingale then the term that multiplies dt has to equal zero, namely, ∂f"
REFERENCES,0.37037037037037035,∂t + Jfµ −g(t)2
REFERENCES,0.37213403880070545,"2
△f = 0."
REFERENCES,0.37389770723104054,"By Lemma 3.1, h(xt, t) is a reverse Martingale, therefore we can substitute f = h and substitute
µ = −g(t)2s according to Eq. (7), to deduce that ∂h"
REFERENCES,0.37566137566137564,∂t −g(t)2Jhs −g(t)2
REFERENCES,0.37742504409171074,"2
△h = 0."
REFERENCES,0.37918871252204583,"Substituting h(x, t) = σ2
t s(x, t) + x according to Eq. (6) yields Eq. (11) as required."
REFERENCES,0.38095238095238093,"Next, we show that any s′ that is the score-function (i.e. gradient of log probability) of some diffusion
process that follows the SDE Eq. (4), also satisfies Eq. (11). To obtain this, one can use the Fokker-
Planck equation, whose special case states that the density function p(x, t) of any stochastic process
that satisfies the SDE Eq. (4) satisfies the PDE ∂p"
REFERENCES,0.38271604938271603,"∂t = g(t)2 2
△p"
REFERENCES,0.3844797178130511,"where △corresponds to the Laplacian operator. Using this one can obtain a PDE for ∇x log p which
happens to be exactly Eq. (11) if the process is defined by Eq. (4)."
REFERENCES,0.3862433862433862,"Next, we use Property 2 to deduce that there exists some densities p(·, t) for t ∈[0, 1] such that"
REFERENCES,0.3880070546737213,"s(x, t) = h(x, t) −x"
REFERENCES,0.3897707231040564,"σ2
t
= ∇x log p(x, t)."
REFERENCES,0.3915343915343915,"Denote by p′(x, t) the score function of the diffusion process that is defined by the SDE of Eq. (4)
with the initial condition that p(x, 0) = p′(x, 0) for all x. Denote by s′(x, t) = ∇x log p′(x, t) the
score function of p′. As we proved above, both s and s′ satisfy the PDE Eq. (11) and the same initial"
REFERENCES,0.3932980599647266,"condition at t = 0. By the uniqueness of the PDE, it holds that s(x, t) = s′(x, t) for all t ≥t0.
Denote by h∗the function that satisfies Eq. (2) with the initial condition x0 ∼p0. By Eq. (6),"
REFERENCES,0.3950617283950617,"s′(x, t) = h∗(x, t) −x"
REFERENCES,0.3968253968253968,"σ2
t
."
REFERENCES,0.3985890652557319,"By Eq. (10) and since s = s′, it follows that h = h∗and this is what we wanted to prove."
REFERENCES,0.400352733686067,"We proceed with proving part 2 of the theorem. We use the notion of an analytic function on Rd: that
is a function f : Rd →R such that at any x0 ∈Rd, the Taylor series of f centered at x0 converges for
all x ∈Rd to f(x). We use the property that an analytic function is uniquely determined by its value
on any open subset: If f and g are analytic functions that identify in some open subset U ⊂Rd then
f = g everywhere. We prove this statement in the remainder of this paragraph, as follows: Represent
f and g as Taylor series around some x0 ∈U. The Taylor series of f and g identify: indeed, these
series are functions of the derivatives of f and g which are functions of only the values in U. Since f
and g equal their Taylor series, they are equal."
REFERENCES,0.4021164021164021,"Next, we will show that for any diffusion process that is defined by Eq. (4), the probability density of
p(x, t0) at any time t0 > 0 is analytic as a function of x. Recall that the distribution of x0 is defined
in Eq. (4) as p0 and it holds that the distribution of xt0 is obtained from p0 by adding a Gaussian
noise N(0, σ2
t I) and its density at any x equals"
REFERENCES,0.4038800705467372,"p(x, t0) =
Z"
REFERENCES,0.4056437389770723,"a∈Rd
1
√"
REFERENCES,0.4074074074074074,"2πσt0
exp

−(x −a)2 2σ2
t"
REFERENCES,0.4091710758377425,"
dp0(a)."
REFERENCES,0.4109347442680776,"Since the function exp(−(x −a)2/(2σ2
t )) is analytic, one could deduce that p(x, t0) is also analytic.
Further, p(x, t0) > 0 for all x which implies that there is no singularity for log p(x, t0) which can be
used to deduce that log p(x, t0) is also analytic and further that ∇x log p(x, t0) is analytic as well."
REFERENCES,0.4126984126984127,"We use the first part of the theorem to deduce that s is the score function of some diffusion process
hence it is analytic. By assumption, s identifies with some target score function s∗in some open
subset U ⊆Rd at some t0, which, by the fact that s(x, t0) and s∗(x, t0) are analytic, implies that
s(x, t0) = s∗(x, t0) for all x. Finally, since s and s∗both satisfy the PDE Eq. (11) and they satsify
the same initial condition at t0, it holds that by uniqueness of the PDE s(x, t) = s∗(x, t) for all x
and t."
REFERENCES,0.4144620811287478,"A.2
Preliminaries"
REFERENCES,0.41622574955908287,"Preliminaries on diffusion processes
In the next definition we define for a function F : Rd →Rd
its Jacobian JF , its divergence ∇· F and its Laplacian △F that is computed separately on each
coordinate of F:
Definition A.1. Given a function F = (f1, . . . , fn): Rd →Rd, denote by JF : Rd →Rd×d its
Jacobian:"
REFERENCES,0.41798941798941797,"(JF )ij = ∂fi(x) ∂xj
."
REFERENCES,0.41975308641975306,The divergence of F is defined as
REFERENCES,0.42151675485008816,"∇· F(x) := n
X i=1"
REFERENCES,0.42328042328042326,"∂fi(x) ∂xi
."
REFERENCES,0.42504409171075835,Denote by △F : Rd →Rd the function whose ith entry is the Laplacian of fi:
REFERENCES,0.42680776014109345,"(△F(x))i = n
X j=1"
REFERENCES,0.42857142857142855,∂2fi(x)
REFERENCES,0.43033509700176364,"∂x2
j
."
REFERENCES,0.43209876543209874,"If F is a function of both x ∈Rd and t ∈R, then JF , △f and ∇· F correspond to F as a function
of x, whereas t is kept fixed. In particular,"
REFERENCES,0.43386243386243384,"(JF (x, t))ij = ∂fi(x, t)"
REFERENCES,0.43562610229276894,"∂xj
,
(△F(x, t))i = n
X j=1"
REFERENCES,0.43738977072310403,"∂2fi(x, t)"
REFERENCES,0.43915343915343913,"∂x2
j
,
∇· F = n
X i=1"
REFERENCES,0.4409171075837742,"∂fi(x, t) ∂xi
."
REFERENCES,0.4426807760141093,"We use the celebrated Ito’s lemma and some of its immediate generalizations:
Lemma A.2 (Ito’s Lemma). Let xt be a stochastic process xt ∈Rd, that is defined by the following
SDE:
dxt = µ(xt, t)dt + g(t)dBt,
where Bt is a standard Brownian motion. Let f : Rd × R →R. Then,"
REFERENCES,0.4444444444444444,"df(xt, t) =
df"
REFERENCES,0.4462081128747795,"dt + ∇xf ⊤µ(xt, t) + g(t)2"
REFERENCES,0.4479717813051146,"2
△f

dt + g(t)∇xf ⊤dBt."
REFERENCES,0.4497354497354497,"Further, if F : Rd × R →Rd is a multi-valued function, then"
REFERENCES,0.4514991181657848,"dF(xt, t) =
dF"
REFERENCES,0.4532627865961199,dt + JF µ + g(t)2
REFERENCES,0.455026455026455,"2
△F

dt + g(t)JF dBt."
REFERENCES,0.4567901234567901,"Lastly, if xt is instead defined with a reverse noise,"
REFERENCES,0.4585537918871252,"dxt = µ(xt, t)dt + g(t)dBt,"
REFERENCES,0.4603174603174603,then the multi-valued Ito’s lemma is modified as follows:
REFERENCES,0.4620811287477954,"dF(xt, t) =
dF"
REFERENCES,0.4638447971781305,dt + JF µ −g(t)2
REFERENCES,0.4656084656084656,"2
△F

dt + g(t)JF dBt.
(13)"
REFERENCES,0.4673721340388007,"Lastly, we present the Fokker-Planck equation which states that the probability distribution that
corresponds to diffusion processes satisfy a certain partial differential equation:
Lemma A.3 (Fokker-Planck equation). Let xt be defined by"
REFERENCES,0.4691358024691358,"dxt = µ(xt, t)dt + g(t)dBt,"
REFERENCES,0.4708994708994709,"where xt, µ(x, t) ∈Rd and Bt is a Brownian motion in Rd. Denote by p(x, t) the density at point x
on time t. Then,"
REFERENCES,0.47266313932980597,"∂
∂tp(x, t) = −∇· (µ(x, t)p(x, t)) + g(t)2"
REFERENCES,0.47442680776014107,"2
△p(x, t) = −p∇· µ −µ∇· p + g(t)2 2
△p."
REFERENCES,0.47619047619047616,"Preliminaries on analytic functions
Definition A.4. A function f : Rd →R is analytic on Rd if for any x0, x ∈Rd, the Taylor series
of f around x0, evaluated at x, converges to f(x). We say that F = (f1, . . . , fn): Rd →Rd is an
analytic function if fi is analytic for all i ∈{1, . . . , n}."
REFERENCES,0.47795414462081126,"The following holds:
Lemma A.5. If F, G: Rd →Rd are two analytic functions and if F = G for all x ∈U where
U ⊆Rd, U ̸= 0, is an open set, then F = G on all Rd."
REFERENCES,0.47971781305114636,This is a well known result and a proof sketch was given in Section 3.
REFERENCES,0.48148148148148145,"The heat equation.
The following is a Folklore lemma on the uniqueness of the solutions to the
heat equation:
Lemma A.6. Let p and p′ be two continuous functions on Rd × [t0, 1] that satisfy the heat equation ∂p"
REFERENCES,0.48324514991181655,∂t = g(t)2
REFERENCES,0.48500881834215165,"2
△p.
(14)"
REFERENCES,0.48677248677248675,"Further, assume that p(·, t0) = p′(·, t0). Then, p = p′ for all t ∈[t0, 1]."
REFERENCES,0.48853615520282184,"A.3
Main proof"
REFERENCES,0.49029982363315694,In what appears below we denote
REFERENCES,0.49206349206349204,"s(x, t) := h(x, t) −x"
REFERENCES,0.49382716049382713,"σ2
t
.
(15)"
REFERENCES,0.49559082892416223,"We start by claiming that if h satisfies Property 1, then s satisfies the PDE Eq. (11): (proof in
Section A.4)"
REFERENCES,0.4973544973544973,"Lemma A.7. Let h satisfy Property 1 and define s according to Eq. (15). Then, s satisfies Eq. (11)."
REFERENCES,0.4991181657848324,"Next, we claim that the score function of any diffusion process satisfies the PDE Eq. (11): (proof in
Section A.5)
Lemma A.8. Let s be the score function of some diffusion process that is defined by Eq. (4). Then, s
satisfies the PDE Eq. (11)."
REFERENCES,0.5008818342151675,"To complete the first part of the proof, denote by p(·, t) the probability distribution such that s(x, t) =
∇log p(x, t), whose existence follows from Property 2. We would like to argue that {p(·, t)}t∈(0,1]
corresponds the probability density of the diffusion"
REFERENCES,0.5026455026455027,"dxt = g(t)dBt.
(16)"
REFERENCES,0.5044091710758377,"It suffices to show that for any t0 > 0, {p(·, t)}t∈(t0,1] corresponds to the same diffusion. To show the
latter, let t0 ∈(0, 1) and consider the diffusion process according to Eq. (16) with the initial condition
that xt0 ∼p(·, t0). Denote its score function by s′ and notice that it satisfies the PDE Eq. (11) and
the initial condition s′(x, t0) = ∇x log p(x, t0) = s(x, t0), where the first equality follows from
the definition of a score function and the second from the construction of p(x, t0). Further, recall
that s(x, t) satisfies the same PDE Eq. (11) by Lemma A.4. Next we will show that s = s′ for all
t ∈[t0, 1], and this will follow from the following lemma: (proof in Section A.6)
Lemma A.9. Let s and s′ be two solutions for the PDE (11) on the domain Rd × [t0, 1] that
satisfy the same initial condition at t0: s(x, t0) = s′(x, t0) for all x. Further, assume that for all
t ∈[t0, 1] there exist probability densities p(·, t) and p′(·, t) such that s(x, t) = ∇x log p(x, t) and
s′(x, t) = ∇x log p′(x, t) for all x. Then, s = s′ on all of Rd × [t0, 1]."
REFERENCES,0.5061728395061729,"Then, by uniqueness of the PDE one obtains that s = s′ for all t ∈[t0, 1]. Hence, s is the score of a
diffusion for all t ≥t0 and this holds for any t0 > 0, hence this holds for any t > 0. This concludes
the proof of the first part of the theorem."
REFERENCES,0.5079365079365079,"For the second part, let s∗denote some score function of a diffusion process that satisfies Eq. (4).
Assume that for some t0 > 0 and some open subset U ⊆Rd, s = s∗, namely s(x, t0) = s∗(x, t0)
for all t0 > 0 and all x ∈U. First, we would like to argue that if s(x, t) is the score function of
some diffusion process that satisfies Eq. (4), then for any t0 > 0 it holds that s(x, t0) is an analytic
function (proof in Section A.7)
Lemma A.10. Let xt obey the SDE Eq. (4) with the initial condition x0 ∼µ0. Let t > 0 and let
s(x, t) denote the score function of xt, namely, s(x, t) = ∇x log p(x, t) where p(x, t) is the density
of xt. Assume that µ0 is a bounded-support distribution. Then, s(x, t) is an analytic function."
REFERENCES,0.5097001763668431,"Since both s and s∗are scores of diffusion processes, then s(x, t0) and s∗(x, t0) are analytic functions.
Using the fact that s = s∗on U × {t0} and using Lemma A.5 we derive that s(x, t0) = s∗(x, t0)
for all x. Let p and p∗denote the densities that correspond to the score functions s and s∗and by
definition of a score function, we obtain that for all x,"
REFERENCES,0.5114638447971781,"∇log p(x, t0) = s(x, t0) = s∗(x, t0) = ∇log p∗(x, t0),"
REFERENCES,0.5132275132275133,"which implies, by integration, that"
REFERENCES,0.5149911816578483,"log p(x, t0) = log p∗(x, t0) + c"
REFERENCES,0.5167548500881834,"for some constant c ∈R. However, c = 0. Indeed,"
REFERENCES,0.5185185185185185,"1 =
Z
p(x, t0)dx =
Z
elog p(x,t0)dx =
Z
elog p∗(x,t0)+cdx =
Z
p∗(x, t0)ecdx = ec,"
REFERENCES,0.5202821869488536,"which implies that c = 0 as required. As a consequence, the following lemma implies that p(x, 0) =
p∗(x, 0) for all x (proof in Section A.8):
Lemma A.11. Let xt and yt be stochastic processes that follow Eq. (4) with initial conditions
x0 ∼µ0 and y0 ∼µ′
0 and assume that µ0 and µ′
0 are bounded-support. Assume that for some t0 > 0,
xt0 and yt0 have the same distribution. Then, µ0 = µ′
0."
REFERENCES,0.5220458553791887,"Without loss of generality, one can replace 0 with any ˜t ∈(0, t0), to obtain that p(x, ˜t) = p∗(x, ˜t) for
any ˜t ∈[0, t0]. Now, p(x, t0) is analytic, from Lemma A.5, hence it is continuous. Consequently,
Lemma A.6 implies that p = p∗in Rd × [t0, 1]. This concludes that p = p∗in all the domain, which
implies that s = ∇log p = ∇log p∗= s∗, as required."
REFERENCES,0.5238095238095238,"A.4
Proof of Lemma A.7"
REFERENCES,0.5255731922398589,"We use Ito’s lemma, and in particular Eq. (13), to get a PDE for the function h(xt, t) where xt
satisfies the stochastic process"
REFERENCES,0.527336860670194,"dxt = −g(t)2s(xt, t)dt + g(t)dBt."
REFERENCES,0.5291005291005291,Ito’s formula yields that
REFERENCES,0.5308641975308642,"dh(xt, t) =
∂h"
REFERENCES,0.5326278659611993,∂t −g(t)2JF s −g(t)2
REFERENCES,0.5343915343915344,"2
△h

dt + σJhd ¯Bt."
REFERENCES,0.5361552028218695,"Since (h, s) satisfies Property 1 and using Lemma 3.1, h is a reverse martingale which implies that
the term that multiplies dt has to equal zero. In particular, we have that ∂h"
REFERENCES,0.5379188712522046,∂t −g(t)2Jhs −g(t)2
REFERENCES,0.5396825396825397,"2
△h = 0.
(17)"
REFERENCES,0.5414462081128748,"By Eq. (15),"
REFERENCES,0.5432098765432098,s = h −x
REFERENCES,0.544973544973545,"σ2
t
."
REFERENCES,0.54673721340388,"Therefore,
h = x + σ2
t s.
Substituting this in Eq. (17) and using the relation dσ2
t /dt = g(t)2 that follows from Eq. (15), one
obtains that 0 = ∂"
REFERENCES,0.5485008818342152,"∂t(x + σ2
t s) −g(t)2Jx+σ2
t ss −g(t)2"
REFERENCES,0.5502645502645502,"2
△(x + σ2
t s)"
REFERENCES,0.5520282186948854,"= g(t)2s + σ2
t
∂s"
REFERENCES,0.5537918871252204,"∂t −g(t)2(I + σ2
t Js)s −g(t)2σ2
t
2
△s"
REFERENCES,0.5555555555555556,"= σ2
t
∂s"
REFERENCES,0.5573192239858906,"∂t −g(t)2σ2
t Jss −g(t)2σ2
t
2
△s."
REFERENCES,0.5590828924162258,"Dividing by σ2
t , we get that
∂s"
REFERENCES,0.5608465608465608,∂t −g(t)2Jss −g(t)2
REFERENCES,0.562610229276896,"2
△s = 0,"
REFERENCES,0.564373897707231,which is what we wanted to prove.
REFERENCES,0.5661375661375662,"A.5
Proof of Lemma A.8"
REFERENCES,0.5679012345679012,"We present as a consequence of the Fokker-Plank equation (Lemma A.3) a PDE for the log density
log p:
Lemma A.12. Let xt be defined by"
REFERENCES,0.5696649029982364,"dxt = µ(xt, t)dt + g(t)dBt."
REFERENCES,0.5714285714285714,"Then,
∂log p"
REFERENCES,0.5731922398589065,"∂t
= −∇· µ −µ∇· log p + g(t)2∥∇log p∥2"
REFERENCES,0.5749559082892416,"2
+ g(t)2△log p 2"
REFERENCES,0.5767195767195767,"Proof. We would like to replace the partial derivatives of p that appear in Lemma A.3 with the partial
derivatives of log p. Using the formula"
REFERENCES,0.5784832451499118,∂log p
REFERENCES,0.5802469135802469,"∂t
= 1 p
∂p ∂t ,"
REFERENCES,0.582010582010582,"one obtains that
∂p"
REFERENCES,0.5837742504409171,"∂t = p∂log p ∂t
."
REFERENCES,0.5855379188712522,"Similarly,
∂p
∂xi
= p∂log p"
REFERENCES,0.5873015873015873,"∂xi
(18)"
REFERENCES,0.5890652557319224,"which also implies that
∇p = p∇log p,
∇· p = p∇· log p.
Differentiating Eq. (18) again with respect to xi and applying Eq. (18) once more, one obtains that"
REFERENCES,0.5908289241622575,"∂2p
∂x2
i
=
∂
∂xi"
REFERENCES,0.5925925925925926,"
p∂log p ∂xi"
REFERENCES,0.5943562610229277,"
= ∂p ∂xi"
REFERENCES,0.5961199294532628,∂log p
REFERENCES,0.5978835978835979,"∂xi
+ p∂2 log p"
REFERENCES,0.599647266313933,"∂x2
i
= p"
REFERENCES,0.6014109347442681,∂log p ∂xi
REFERENCES,0.6031746031746031,"2
+ ∂2 log p ∂x2
i ! ."
REFERENCES,0.6049382716049383,"Summing over i, one obtains that"
REFERENCES,0.6067019400352733,"△p = p n
X i=1"
REFERENCES,0.6084656084656085,∂log p ∂xi
REFERENCES,0.6102292768959435,"2
+ ∂2 log p ∂x2
i !"
REFERENCES,0.6119929453262787,"= p∥∇log p∥2 + p△log p.
(19)"
REFERENCES,0.6137566137566137,"Substituting the partials derivatives of p inside the Fokker-Planck equation in Lemma A.3, one obtains
that"
REFERENCES,0.6155202821869489,p∂log p
REFERENCES,0.6172839506172839,"∂t
= −p∇· µ −µ(p∇· log p) + g(t)2"
REFERENCES,0.6190476190476191,"2
 
p∥∇log p∥2 + p△log p

."
REFERENCES,0.6208112874779541,"Dividing by p, one gets that"
REFERENCES,0.6225749559082893,∂log p
REFERENCES,0.6243386243386243,"∂t
= −∇· µ −µ∇· log p + g(t)2∥∇log p∥2"
REFERENCES,0.6261022927689595,"2
+ g(t)2△log p 2
."
REFERENCES,0.6278659611992945,as required.
REFERENCES,0.6296296296296297,"We are ready to prove Lemma A.8: Substituting µ = 0 in Lemma A.12, one obtains that"
REFERENCES,0.6313932980599647,∂log p
REFERENCES,0.6331569664902998,"∂t
= g(t)2∥∇log p∥2"
REFERENCES,0.6349206349206349,"2
+ g(t)2△log p 2
."
REFERENCES,0.63668430335097,"Taking the gradient with respect to x, one obtains that"
REFERENCES,0.6384479717813051,∇∂log p
REFERENCES,0.6402116402116402,"∂t
= g(t)2∇∥∇log p∥2"
REFERENCES,0.6419753086419753,"2
+ g(t)2∇△log p"
REFERENCES,0.6437389770723104,"2
.
(20)"
REFERENCES,0.6455026455026455,"Since ∂/∂xi commutes with ∂/∂t, it holds that"
REFERENCES,0.6472663139329806,∇∂log p
REFERENCES,0.6490299823633157,"∂t
= ∂"
REFERENCES,0.6507936507936508,∂t∇log p = ∂s
REFERENCES,0.6525573192239859,"∂t ,
(21)"
REFERENCES,0.654320987654321,"recalling that by definition s = ∇log p. Further,"
REFERENCES,0.656084656084656,"∂
∂xi
∥∇log p∥2 = n
X j=1 ∂
∂xi"
REFERENCES,0.6578483245149912,∂log p ∂xj
REFERENCES,0.6596119929453262,"2
= 2 n
X j=1"
REFERENCES,0.6613756613756614,"∂2 log p
∂xi∂xj"
REFERENCES,0.6631393298059964,∂log p
REFERENCES,0.6649029982363316,"∂xj
= 2(Hlog p∇log p)i,"
REFERENCES,0.6666666666666666,"where for any function f : Rd →R, Hf is the Hessian function of f that is defined by"
REFERENCES,0.6684303350970018,"(Hf)ij =
∂2f
∂xi∂xj"
REFERENCES,0.6701940035273368,"This implies that
∇∥∇log p∥2 = 2Hlog p∇log p.
Further, notice that
Hf = J∇f,
which implies that
∇∥∇log p∥2 = 2J∇log p∇log p = 2Jss.
(22)
Lastly, we get that by the commutative property of partial derivatives,"
REFERENCES,0.671957671957672,"∇△log p = △∇log p = △s.
(23)"
REFERENCES,0.673721340388007,"Substituting Eq. (21), Eq. (22) and Eq. (23) in Eq. (20), one obtains that ∂s"
REFERENCES,0.6754850088183422,"∂t = g(t)2Jss + g(t)2△s 2
,"
REFERENCES,0.6772486772486772,as required.
REFERENCES,0.6790123456790124,"A.6
Proof of Lemma A.9"
REFERENCES,0.6807760141093474,"We will prove that p and p′ satisfy the same PDE (which is the heat equation). Recall that s and s′
satisfy
∂s"
REFERENCES,0.6825396825396826,"∂t = g(t)2

Jss + 1"
REFERENCES,0.6843033509700176,"2△s

= g(t)2"
REFERENCES,0.6860670194003528,"2
 
∇∥s∥2 + △s
"
REFERENCES,0.6878306878306878,"By substituting s = ∇log p,"
REFERENCES,0.689594356261023,∂∇log p
REFERENCES,0.691358024691358,"∂t
= g(t)2"
REFERENCES,0.6931216931216931,"2
 
∇∥∇log p∥2 + △∇log p

."
REFERENCES,0.6948853615520282,"By exchanging the order of derivatives, we obtain that"
REFERENCES,0.6966490299823633,∇∂log p
REFERENCES,0.6984126984126984,"∂t
= ∇g(t)2"
REFERENCES,0.7001763668430335,"2
 
∥∇log p∥2 + △log p

."
REFERENCES,0.7019400352733686,"By integrating, this implies that"
REFERENCES,0.7037037037037037,∂log p
REFERENCES,0.7054673721340388,"∂t
= g(t)2"
REFERENCES,0.7072310405643739,"2
 
∥∇log p∥2 + △log p

+ c(t),"
REFERENCES,0.708994708994709,where c(t) depends only on t. Eq. (19) shows that
REFERENCES,0.7107583774250441,△log p = △p
REFERENCES,0.7125220458553791,p −∥∇log p∥2.
REFERENCES,0.7142857142857143,"By substituting this in the equation above, we obtain that"
REFERENCES,0.7160493827160493,∂log p
REFERENCES,0.7178130511463845,"∂t
= g(t)2 2
△p"
REFERENCES,0.7195767195767195,p + c(t).
REFERENCES,0.7213403880070547,"By multiplying both sides with p, we get that ∂p"
REFERENCES,0.7231040564373897,∂t = p∂log p
REFERENCES,0.7248677248677249,"∂t
= g(t)2"
REFERENCES,0.7266313932980599,"2
△p + c(t).
(24)"
REFERENCES,0.7283950617283951,"Since p is a probability distribution,
Z"
REFERENCES,0.7301587301587301,"Rd p(x, t)dx = 1,"
REFERENCES,0.7319223985890653,"therefore,
Z ∂p(x, t)"
REFERENCES,0.7336860670194003,"∂t
dx = ∂ ∂t Z"
REFERENCES,0.7354497354497355,"Rd p(x, t)dx = ∂1"
REFERENCES,0.7372134038800705,∂t = 0.
REFERENCES,0.7389770723104057,Integrating over Eq. (24) we obtain that
REFERENCES,0.7407407407407407,"0 =
Z g(t)2"
REFERENCES,0.7425044091710759,"2
△p + c(t)dx = 0 +
Z
c(t)dx,"
REFERENCES,0.7442680776014109,"where the last equation holds since the integral of a Laplacian of probability density integrates to 0. It
follows that c(t) = 0 which implies that ∂p"
REFERENCES,0.746031746031746,∂t = g(t)2
REFERENCES,0.7477954144620811,"2
△p,
(25)"
REFERENCES,0.7495590828924162,"and the same PDE holds where p′ replaces p, and this follows without loss of generality. Further,
since log p and log p′ are differentiable, it holds that p(·, t) and p′(·, t) are continuous for all fixed
t. This implies that p and p′ are continuous as functions of x and t since they both satisfy the
heat equation Eq. (14). Consequently, Lemma A.6 implies that p = p′ on Rd × [t0, 1]. Finally,
s = ∇log p = ∇log p′ = s′, as required."
REFERENCES,0.7513227513227513,"A.7
Proof of Lemma A.10"
REFERENCES,0.7530864197530864,"First, recall that since xt satisfies Eq. (4) with the initial condition x0 ∼µ0, then xt ∼µ0+N(0, σ2
t I),
namely, xt is the addition of a random variable drawn from µ0 and an independent Gaussian
N(0, σ2
t I). Therefore, the density of xt, which we denote by p(x, t), equals"
REFERENCES,0.7548500881834215,"p(x, a) = Ea∼µ0 
1
√"
REFERENCES,0.7566137566137566,"2πσt
exp

−∥x −a∥2 2σ2
t 
."
REFERENCES,0.7583774250440917,Using the equation
REFERENCES,0.7601410934744268,∇x log f(x) = ∇xf(x)
REFERENCES,0.7619047619047619,"f(x) ,"
REFERENCES,0.763668430335097,we get that
REFERENCES,0.7654320987654321,"s(x, a) = ∇x log p(x, a) = ∇xp(x, a)"
REFERENCES,0.7671957671957672,"p(x, a)
=
Ea∼µ0
h
1
√"
REFERENCES,0.7689594356261023,"2πσt
x−a"
REFERENCES,0.7707231040564374,"σ2
t exp

−∥x−a∥2 2σ2
t i"
REFERENCES,0.7724867724867724,"Ea∼µ0
h
1
√"
REFERENCES,0.7742504409171076,"2πσt exp

−∥x−a∥2 2σ2
t"
REFERENCES,0.7760141093474426,"i
(26)"
REFERENCES,0.7777777777777778,"By using the fact that the Taylor formula for ex equals ex = ∞
X i=0 ei i! ,"
REFERENCES,0.7795414462081128,"we obtain that the right hand side of Eq. (26) equals Ea∼µ0 
1
√"
REFERENCES,0.781305114638448,"2πσt
x−a"
REFERENCES,0.783068783068783,"σ2
t
P∞
i=0
(−1)i"
REFERENCES,0.7848324514991182,"i!

∥x−a∥2 2σ2
t i Ea∼µ0 
1
√"
REFERENCES,0.7865961199294532,"2πσt
P∞
i=0
(−1)i"
REFERENCES,0.7883597883597884,"i!

∥x−a∥2 2σ2
t"
REFERENCES,0.7901234567901234,"i
=
Ea∼µ0 
x−a"
REFERENCES,0.7918871252204586,"σ2
t
P∞
i=0
(−1)i"
REFERENCES,0.7936507936507936,"i!

∥x−a∥2 2σ2
t i Ea∼µ0"
REFERENCES,0.7954144620811288,"P∞
i=0
(−1)i"
REFERENCES,0.7971781305114638,"i!

∥x−a∥2 2σ2
t"
REFERENCES,0.798941798941799,"i
(27)"
REFERENCES,0.800705467372134,"We will use the following property of analytic functions: if f and g are analytic functions over Rd
and g(x) ̸= 0 for all x then f/g is analytic over Rd. Since the denominator at the right hand side of
Eq. (27) is nonzero, it suffices to prove that the numerator and the denominator are analytic. We will
prove for the denominator and the proof for the numerator is nearly identical. By assumption of this
lemma, the support of µ0 is bounded, hence there is some M > 0 such that ∥x∥≤M for any x in
the support. Then,

(−1)i i!"
REFERENCES,0.8024691358024691,"∥x −a∥2 2σ2
t"
REFERENCES,0.8042328042328042,i ≤1 i!
REFERENCES,0.8059964726631393,"x2 + a2 σ2
t"
REFERENCES,0.8077601410934744,"i
= M 2i"
REFERENCES,0.8095238095238095,"σ2i
t i!."
REFERENCES,0.8112874779541446,"This bound is independent on a, and summing these abvolute values of coefficients for i ∈N,
one obtains a convergent series. Hence we can replace the summation and the expectation in the
denominator at the right hand side of Eq. (27) to get that it equals ∞
X i=0 (−1)i"
REFERENCES,0.8130511463844797,"i!
Ea∼µ0"
REFERENCES,0.8148148148148148,"""∥x −a∥2 2σ2
t i#"
REFERENCES,0.8165784832451499,".
(28)"
REFERENCES,0.818342151675485,"This is the Taylor series around 0 of the above-described denominator it converges to the value of the
denominator at any x. While this Taylor series is taken around 0, we note the Taylor series around
any other point x0 ∈Rn converges as well. This can be shown by shifting the coordinate system
by a constant vector such that x0 shifts to 0 and applying the same proof. One deduces that the
Taylor series for the denominator around any point x0 converges on all Rd, which implies that the
denominator in the right hand side of Eq. (27) is analytic. The numerator is analytic as well by the
same argument. Therefore the ratio, which equals s(x, t), is analytic as well as required."
REFERENCES,0.8201058201058201,"A.8
Proof of Lemma A.11"
REFERENCES,0.8218694885361552,"Let t > 0, denote by µt and µ′
t the distributions of xt and x′
t, respectively, and by p(x, t) and p′(x, t)
the densities of these variables. Then, µt = µ0 + N(0, σ2
t I), namely, µt is obtained by adding an
independent sample from µ0 with an independent N(0, σ2
t I) variable, and similarly for µ′
t. Hence,
the density p(x, t) is the convolution of the densities p(x, 0) with the density of a Gaussian N(0, σ2
t I)."
REFERENCES,0.8236331569664903,"Denote by ˆp(y, t) the Fourier transform of the density p(x, t) with respect to x (while keeping t fixed)
and similarly define ˆp′ as the Fourier transform of p′. Denote by g and by ˆg the density of N(0, σ2
t I)
and its Fourier transform, respectively. Denote the convolution of two functions by the operator ∗.
Then,
p(x, t) = p(x, 0) ∗g(x),
p′(x, t) = p′(x, 0) ∗g(x)."
REFERENCES,0.8253968253968254,"Since the Fourier transform turns convolutions into multiplications, one obtains that"
REFERENCES,0.8271604938271605,"ˆp(y, t) = ˆp(y, 0)ˆg(y),
ˆp′(y, t) = ˆp′(y, 0)ˆg(y)."
REFERENCES,0.8289241622574955,"Since p(x, t) = p′(x, t) we obtain that ˆp(y, t) = ˆp′(y, t). Consequently,"
REFERENCES,0.8306878306878307,"ˆp(y, 0)ˆg(y) = ˆp′(y, 0)ˆg(y)"
REFERENCES,0.8324514991181657,"Since the Fourier transform of a Gaussian is nonzero, we can divide by ˆg(y) to get that"
REFERENCES,0.8342151675485009,"ˆp(y, 0) = ˆp′(y, 0)."
REFERENCES,0.8359788359788359,"This implies that the Fourier transform of p(x, 0) equals that of p′(x, 0) hence p(x, 0) = p′(x, 0) for
all x, as required."
REFERENCES,0.8377425044091711,"B
Other proofs"
REFERENCES,0.8395061728395061,"B.1
Differentiating the loss function"
REFERENCES,0.8412698412698413,"Denote our parameter space as Θ ⊆Rm. In order to differentiate LSM
t,t′,x(θ) with respect to θ ∈Θ,
we make the following calculations below, and we notice that Eθ is used to denote an expectation
with respect to the distribution of x[t′,t] according to Eq. (7) with s = sθ and the initial condition
xt = x. In other words, the expectation is over x[t′,t] that is taken with respect to the sampler that
is parameterized by θ with the initial condition xt = x. We denote by pθ(x[t′,t] | xt = x) the
corresponding density of x[t′,t]. For any function f = (f1, . . . , fn): Θ →Rn, denote by ∇θf the
Jacobian matrix of f, where"
REFERENCES,0.8430335097001763,"(∇θf)i,j = ∂fi ∂θj
."
REFERENCES,0.8447971781305115,"For notational consistency, if f is a single-valued function, namely, if n = 1, then ∇θf is a column
vector. We begin with the following:"
REFERENCES,0.8465608465608465,"∇θ Eθ [hθ(xt′, t′)] = ∇θ Z"
REFERENCES,0.8483245149911817,"Rd hθ(xt′, t′)pθ(x[t′,t] | xt = x)dxt′ =
Z"
REFERENCES,0.8500881834215167,"Rd ∇θhθ(xt′, t′)pθ(x[t′,t] | xt = x)dxt′ +
Z"
REFERENCES,0.8518518518518519,"Rd hθ(xt′, t′)∇θpθ(x[t′,t]|xt = x)dxt′"
REFERENCES,0.8536155202821869,"= Eθ [∇θhθ(xt′, t′)] + Eθ"
REFERENCES,0.855379188712522,"
hθ(xt′, t′)∇θpθ(x[t′,t]|xt = x)"
REFERENCES,0.8571428571428571,"pθ(x[t′,t]|xt = x) "
REFERENCES,0.8589065255731922,"= Eθ [∇θhθ(xt′, t′)] + Eθ

hθ(xt′, t′)∇θ log
 
pθ(x[t′,t] | xt = x)
"
REFERENCES,0.8606701940035273,"Differentiating the whole loss, we get the following:"
REFERENCES,0.8624338624338624,"∇θLSM
t,t′,x(θ) = 1"
REFERENCES,0.8641975308641975,"2∇θ (Eθ[hθ(xt′, t′)] −hθ(x, t))2"
REFERENCES,0.8659611992945326,"= (Eθ[hθ(xt′, t′)] −hθ(x, t))⊤(∇θ E[hθ(xt′, t′)] −∇θhθ(x, t))"
REFERENCES,0.8677248677248677,"= Eθ [hθ(xt′, t′) −hθ(x, t)]⊤Eθ [∇θhθ(xt′, t′) −∇θhθ(x, t)]"
REFERENCES,0.8694885361552028,"+ Eθ [hθ(xt′, t′) −hθ(x, t)]⊤Eθ

hθ(xt′, t′)∇θ log
 
pθ(x[t′,t] | xt = x)
"
REFERENCES,0.8712522045855379,"Let us compute the gradient of the log density. We use the discrete process, and let us assume that
t = t0 > t1 > · · · > tk = t′ are the sampling times. Then,"
REFERENCES,0.873015873015873,"pθ(x[t′,t] | xt = x) = k
Y"
REFERENCES,0.8747795414462081,"i=1
pθ(xti | xti−1)."
REFERENCES,0.8765432098765432,"We assume that
pθ(xti | ti−1) = N(µθ,i, giId).
Then,"
REFERENCES,0.8783068783068783,"pθ(x[t′,t] | xt = x) ∝ k
Y"
REFERENCES,0.8800705467372134,"i=1
exp

−∥µθ,i −(xti −xti−1)∥2 2g2
i "
REFERENCES,0.8818342151675485,Therefore
REFERENCES,0.8835978835978836,"log pθ(x[t′,t] | xt = x) = C + k
X i=1"
REFERENCES,0.8853615520282186,"∥µθ,i −(xti −xti−1)∥2 2g2
i"
REFERENCES,0.8871252204585538,"where C corresponds to the normalizing factor that is independent of θ. Differentiating, we get that"
REFERENCES,0.8888888888888888,"∇θ log pθ(x[t′,t] | xt = x) = k
X i=1"
REFERENCES,0.890652557319224," 
µθ,i −(xti −xti−1)
⊤∇θµθ,i
g2
i"
REFERENCES,0.892416225749559,"B.2
Proof of Lemma 3.1"
REFERENCES,0.8941798941798942,"In what appears below, the expectation E[· | xt = x] is taken with respect to the distribution obtained
by Eq. (7), namely, the backward SDE that corresponds to the function s, with the initial condition
xt = x. Similarly, E[· | xt′] is taken with the initial condition at xt′. To prove the first direction
in the equivalence, assume that Property 1 holds and our goal is to prove the two consequences as
described in the lemma. To prove the first consequence, by the law of total expectation and by the
fact that xt −xt′ −x0 is a Markov chain, namely, x0 and xt are independent conditioned on xt′, we
obtain that"
REFERENCES,0.8959435626102292,"h(x, t) = E[x0 | xt = x] = E[E[x0 | xt′] | xt = x] = E[h(xt′, t′) | xt = x]."
REFERENCES,0.8977072310405644,"To prove the second consequence, by Property 1"
REFERENCES,0.8994708994708994,"h(x, 0) = E[x0 | x0 = x] = x0."
REFERENCES,0.9012345679012346,This concludes the first direction in the equivalence.
REFERENCES,0.9029982363315696,"To prove the second direction, assume that h(x, t) = E[h(xt′, t′) | xt = x] and that h(x, 0) = x and
notice that by substituting t′ = 0 we derive the following:"
REFERENCES,0.9047619047619048,"h(x, t) = E[h(x0, 0) | xt = x] = E[x0 | xt = x],"
REFERENCES,0.9065255731922398,as required.
REFERENCES,0.908289241622575,"C
Additional Results"
REFERENCES,0.91005291005291,"C.1
Property Testing"
REFERENCES,0.9118165784832452,"Discussion.
We add some details about the plots:"
REFERENCES,0.9135802469135802,"• We note that the plots are not monotonic. This might be attributed to the model being closer
to the ideal denoiser at certain noise levels and perhaps for having the capacity to correct
previous mistakes.
• For each plot, we sample 32 images, and for each t we get 32 stochastic samples conditioned
on each one of the images and we measure the violation of MP. Standard deviation was
small that it was not visible in the plot.
• σt denotes the standard deviation of the noise at time t and it is a monotonic function of t."
REFERENCES,0.9153439153439153,"We underline that for the perfect denoiser, the error would have been 0 everywhere. However, even
after the MP regularization, the learning is not perfect hence there are errors."
REFERENCES,0.9171075837742504,"0
10
20
30
40
50
60
70
80 t"
REFERENCES,0.9188712522045855,0.0000
REFERENCES,0.9206349206349206,0.0005
REFERENCES,0.9223985890652557,0.0010
REFERENCES,0.9241622574955908,0.0015
REFERENCES,0.9259259259259259,0.0020
REFERENCES,0.927689594356261,0.0025
REFERENCES,0.9294532627865961,"||
x0
p (x0|xt)[x0]
h (xt, t)||2"
REFERENCES,0.9312169312169312,"Baseline
Ours"
REFERENCES,0.9329805996472663,Consistency Property Testing (CIFAR10)
REFERENCES,0.9347442680776014,Backward Sampler (300) steps
REFERENCES,0.9365079365079365,"Figure 4: Consistency Property Testing on CIFAR-10. The plot illustrates how the Consistency Loss,
LCP
t,t′,xt, behaves for t′ = 0, as t changes."
REFERENCES,0.9382716049382716,"0
10
20
30
40
50
60
70
80 t"
REFERENCES,0.9400352733686067,0.0000
REFERENCES,0.9417989417989417,0.0005
REFERENCES,0.9435626102292769,0.0010
REFERENCES,0.9453262786596119,0.0015
REFERENCES,0.9470899470899471,0.0020
REFERENCES,0.9488536155202821,0.0025
REFERENCES,0.9506172839506173,"||
xt
p (xt|x1)[h (xt, t)]
h (x1, 1.0)||2"
REFERENCES,0.9523809523809523,"Baseline
Ours"
REFERENCES,0.9541446208112875,Consistency Property Testing (CIFAR10)
REFERENCES,0.9559082892416225,Backward Sampler (300) steps
REFERENCES,0.9576719576719577,"Figure 5: Consistency Property Testing on CIFAR-10. The plot illustrates how the Consistency Loss,
LCP
t,t′,xt, behaves for t = 0, as t′ changes."
REFERENCES,0.9594356261022927,"0
10
20
30
40
50
60
70
80 t 0.000 0.001 0.002 0.003 0.004 0.005"
REFERENCES,0.9611992945326279,"||
x0
p (x0|xt)[x0]
h (xt, t)||2"
REFERENCES,0.9629629629629629,"Baseline
Ours"
REFERENCES,0.9647266313932981,Consistency Property Testing (FFHQ)
REFERENCES,0.9664902998236331,Backward Sampler (1000) steps
REFERENCES,0.9682539682539683,"Figure 6: Consistency Property Testing on FFHQ. The plot illustrates how the Consistency Loss,
LCP
t,t′,xt, behaves for t′ = 0, as t changes."
REFERENCES,0.9700176366843033,"0
10
20
30
40
50
60
70
80 t 0.000 0.001 0.002 0.003 0.004 0.005"
REFERENCES,0.9717813051146384,"||
xt
p (xt|x1)[h (xt, t)]
h (x1, 1.0)||2"
REFERENCES,0.9735449735449735,"Baseline
Ours"
REFERENCES,0.9753086419753086,Consistency Property Testing (FFHQ)
REFERENCES,0.9770723104056437,Backward Sampler (1000) steps
REFERENCES,0.9788359788359788,"Figure 7: Consistency Property Testing on FFHQ. The plot illustrates how the Consistency Loss,
LCP
t,t′,xt, behaves for t = 0, as t′ changes."
REFERENCES,0.9805996472663139,"C.2
Uncurated Samples"
REFERENCES,0.982363315696649,"Figure 8: Uncurated generated images by our fine-tuned model on FFHQ. FID: 2.61, NFEs: 79."
REFERENCES,0.9841269841269841,"D
Implementation details"
REFERENCES,0.9858906525573192,"Algorithm 1 Consistent Diffusion Models (CDM) Training
Input: dataset D, noise schedule {σt}T
0 , initial model parameters θ, learning rate η, Consistency
Property (CP) regularization strength λ, maximum distance ϵ between t and t′, and step size ∆t for
discretizing the Reverse SDE."
REFERENCES,0.9876543209876543,repeat
REFERENCES,0.9894179894179894,"Sample x0 ∼D
▷(Clean image)
Sample σt uniformly from {σt}T
ϵ
▷(Corruption level)
Sample xt ∼N(x0, σ2
t Id)
▷(Corrupted image)
LSM ←||hθ(xt, t) −x0||2
▷(Compute Score Matching loss)
Sample t′ ∼U[t −ϵ, t]
▷(Level with less corruption)
Stopgrad
Sample x(1)
t′ , x(2)
t′
by running ⌊ϵ"
REFERENCES,0.9911816578483245,"∆t⌋steps of the Reverse SDE ▷(Sample less corrupted images)
Resumegrad"
REFERENCES,0.9929453262786596,"LCP ←

hθ(x(1)
t′ , t′) −hθ(xt, t)
T 
hθ(x(2)
t′ , t′) −hθ(xt, t)

▷Enforce CP with stochastic
gradient."
REFERENCES,0.9947089947089947,"θ ←θ −η∇θ
 
LSM + λLCP
▷(Update parameters)
until convergence"
REFERENCES,0.9964726631393298,"E
Limitations"
REFERENCES,0.9982363315696648,"The capacity for generative models to exert consequential societal influence in myriad ways is
undeniable, and it also brings along a multiplicity of inherent risks [37, 25, 26, 27]. These models, for
instance, may be exploited to fabricate counterfeit images, and furthermore, they have the potential to
intensify societal prejudices. This work does not seem to exert a direct influence on these particular
biases. It is imperative to acknowledge that addressing such biases presents a substantial challenge."
