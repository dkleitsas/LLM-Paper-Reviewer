Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.002398081534772182,"Polythetic classiﬁcations, based on shared patterns of features that need neither be universal
nor constant among members of a class, are common in the natural world and greatly
outnumber monothetic classiﬁcations over a set of features. We show that threshold
meta-learners, such as Prototypical Networks, require an embedding dimension that is
exponential in the number of task-relevant features to emulate these functions. In contrast,
attentional classiﬁers, such as Matching Networks, are polythetic by default and able
to solve these problems with a linear embedding dimension. However, we ﬁnd that in
the presence of task-irrelevant features, inherent to meta-learning problems, attentional
models are susceptible to misclassiﬁcation. To address this challenge, we propose a self-
attention feature-selection mechanism that adaptively dilutes non-discriminative features.
We demonstrate the effectiveness of our approach in meta-learning Boolean functions, and
synthetic and real-world few-shot learning tasks."
INTRODUCTION,0.004796163069544364,"1
INTRODUCTION"
INTRODUCTION,0.007194244604316547,"Classiﬁcation meta-learning is typically approached from the perspective of few-shot learning: Can we train
a model that generalises to unseen ‘natural’ classes at test time? For example, in the Omniglot task (Lake
et al., 2011) we have access to a labelled set of handwritten characters during training and we are tasked
with distinguishing new characters, from unseen writing systems, at test time. From this perspective each
example is associated with a consistent class and members of that class share a common set of properties
(e.g. all handwritten characters have the shape of the underlying character class). Alternatively, we may
consider meta-learning over unseen ways of categorising: Can we train a model on character recognition that
generalises to alphabet recognition? or to distinguishing upper from lower case letters? In this setting, features
need to be understood in relation to a given classiﬁcation: For instance, when tasked with distinguishing
equids (horses, zebras, donkeys) from big cats, the presence of stripes on both zebra and tigers is irrelevant,
and potentially misleading. On the other hand, stripes are the key to distinguishing horses from zebra."
INTRODUCTION,0.009592326139088728,"Understanding features in the context of a classiﬁcation is central to the concepts of monothetic and polythetic
classes recognised in the ﬁelds of taxonomy and knowledge organisation. Monothetic classiﬁcations are
based on universal attributes: there is at least one necessary and sufﬁcient attribute for class membership.
Polythetic classiﬁcations are instead based on combinations of attributes, none of which are sufﬁcient in
isolation to indicate membership and, potentially, none of which are necessary. Carl Linneaus, inventor of
the binomial nomenclature for species and “father of taxonomy,” recognised that natural orders could not
be deﬁned monothetically, lacking features that were unique and constant over families and that, until such
features could be found, such classiﬁcations were necessarily polythetic (Hjørland, 2017; Stevens, 1998)."
INTRODUCTION,0.011990407673860911,"Figure 1 illustrates Linnaeus’ system for classifying plants, which relies on polythetic classiﬁcations and is
still in use today. Consider, for example, that we can distinguish A from B by the number of ﬁlaments, but not"
INTRODUCTION,0.014388489208633094,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.016786570743405275,"B from C; we can distinguish B from C based on whether there are split anthers (the ends), but not C from A,
and so on. To recognise classes it is necessary to consider their attributes in the context of other attributes."
INTRODUCTION,0.019184652278177457,"Figure 1: Section of Methodus Plantarum Sexualis,
Georg Ehret, illustrating Linnaeus’s Systema Naturae,
1735. Class deﬁning attributes need not be exclusive or
universal, and useful classiﬁcations may be contextual."
INTRODUCTION,0.02158273381294964,"Threshold functions are a related concept in Boolean
algebra. A threshold function evaluates positively
if a weighted sum of binary inputs crosses some
threshold. Lacking a preferred feature basis, we can
identify monothetic classiﬁcations with threshold
functions, as threshold functions that are polythetic
in one basis, such as logical OR(x, y), may be re-
cast in a basis where they are monothetic e.g. bi-
nary OR(x, y) evaluates as the unary MIN(x+y, 1).
We can compare the frequency of monothetic and
polythetic classiﬁcations in this general case. The
number of binary inputs of length n is 2n and the
total number of Boolean functions is the number of
binary labellings of these inputs, 22n, whereas the
number of threshold functions grows only singly ex-
ponentially (≤2n2), and therefore monothetic clas-
siﬁcations represent a vanishingly small proportion
of the total (see Gruzling (2007); Irmatov (1993))."
INTRODUCTION,0.023980815347721823,"This work explores meta-learning for polythetic classiﬁcation. Speciﬁcally, we"
INTRODUCTION,0.026378896882494004,"• consider the limitations of widely used threshold classiﬁers, such as Prototypical Networks (Snell
et al., 2017), and how they are able to learn and approximate non-threshold functions in practice;
• show that simple alternatives based on attention, such as Matching Networks (Vinyals et al., 2016),
are polythetic by default but susceptible to misclassiﬁcation due to excessive sensitivity;
• characterise the challenge of spurious correlations in irrelevant features for attentional classiﬁers;
• and propose a simple solution to this challenge that is non-parametric and based on self-attention."
INTRODUCTION,0.02877697841726619,"Throughout, we evidence these ﬁndings and the effectiveness of our proposals with experiments on synthetic
and real-world few-shot learning tasks."
BACKGROUND,0.03117505995203837,"2
BACKGROUND"
BACKGROUND,0.03357314148681055,"Problem formulation.
We are interested in few-shot classiﬁcation: provided with a small number of
labelled points S = {xi, yi}i∈IS, the support set, with feature vectors xi ∈Rn and labels yi ∈{1, . . . , K},
we want to predict the labels of the query set Q = {xj}j∈IQ. Sk denotes the set of support elements with
label k and I⋆is the index set of the subscript e.g. IS is the index set of the support. The label space is
arbitrary and potentially unique to a task (also referred to as an episode) — both the number of classes, k, and
assigned labels may vary over tasks — and, importantly, examples that share labels under one categorisation
will not necessarily share labels under another. We will refer to classiﬁcation functions over n features simply
as classiﬁcations, and in meta-learning we are often interested in classiﬁcations that only depend on some
features, α, and not the remainder, β = n −α."
BACKGROUND,0.03597122302158273,"Classiﬁers.
Deep neural models for problems of this kind are usually equipped with either a threshold
classiﬁer or an attentional classiﬁer. Threshold classiﬁers are based, as the name suggests, on using thresholds
to partition a space into regions associated with each class. Prototypical Networks (Snell et al., 2017) are an
example of such a model. This model embeds examples using a learned neural function, fφ, ﬁnds the average
embedding for each class in the support, ck, and classiﬁes queries based on their proximity (measured with a"
BACKGROUND,0.03836930455635491,Under review as a conference paper at ICLR 2022
BACKGROUND,0.0407673860911271,"Prototype, x = 0 ++ +− −+ −−"
BACKGROUND,0.04316546762589928,"Attention, x = 0 ++ +− −+ −−"
BACKGROUND,0.045563549160671464,"Prototype, y = −x + 2/3 ++ +− −+ −−"
BACKGROUND,0.047961630695443645,"Attention, y = −ln(tanh(x))/2 ++ +− −+ −−"
BACKGROUND,0.050359712230215826,"Prototype, undeﬁned ++ +− −+ −−"
BACKGROUND,0.05275779376498801,"Attention, y = 0, x = 0 ++ +− −+ −−"
BACKGROUND,0.05515587529976019,"f1(x, y) = x
f2(x, y) =AND(x, y)
f3(x, y) =XOR(x, y)"
BACKGROUND,0.05755395683453238,"Figure 2: Conﬁdence heatmaps and decision boundaries of prototype and attention classiﬁers on 2-
variable Boolean functions. The attention classiﬁer shown uses a temperature of 1, lower temperatures
‘harden’ the classiﬁcation and produce decision boundaries more closely aligned with the axes (see
Appendix B). As XOR(x, y) is not a threshold function, simple prototypes fail to produce a correct
classiﬁcation scheme, in this case the prototypes are equal (= (0, 0)) and there is no decision boundary."
BACKGROUND,0.05995203836930456,distance function d) to these class prototypes:
BACKGROUND,0.06235011990407674,"ck =
1
|Sk| X"
BACKGROUND,0.06474820143884892,"i∈ISk
fφ(xi)
;
pφ(y = k|x) =
exp(−d(fφ(x), ck))
P"
BACKGROUND,0.0671462829736211,"k′ exp(−d(fφ(x), ck′))
(1)"
BACKGROUND,0.06954436450839328,"The key advantage of such an approach is that salient class features are preserved when forming the prototype
while irrelevant aspects of particular examples are washed out. Attentional classiﬁers instead use a similarity
function to directly compare queries with each example in the support. For example, Matching Networks
(Vinyals et al., 2016) also learn embedding functions, but each query is compared with every member of
the support to weight a sum over their labels, which we can write simply as ˆy = P"
BACKGROUND,0.07194244604316546,"i∈IS a(ˆx, xi)yi. In the
popular terminology of transformers we may write the embedded queries as Q, the embedded support as keys
K and their labels as values V, and dot-product attention classiﬁcation with temperature τ −1 as"
BACKGROUND,0.07434052757793765,"DotAttn(Q, K, V, τ) = softmax(τQKT )V ∈R|Q|×k.
(2)"
BACKGROUND,0.07673860911270983,Attentional classiﬁers are more sensitive to variations within a class at the cost of additional computation.
BACKGROUND,0.07913669064748201,"Boolean tasks.
In comparing these classiﬁers we make repeated use of tasks based on Boolean functions,
and on exclusive-OR (XOR) in particular. For a binary feature vector x ∈{−1, 1}n, the number χA(x) =
Q"
BACKGROUND,0.0815347721822542,"i∈A xi is the parity function or exclusive-or (XOR) over the bits (xi)i∈A. We write a parity function of α
bits XORα. The set of parity functions over n bits form a linearly independent basis (O’Donnell, 2014) and,
as such, being able to model the partition functions guarantees that one can model any other Boolean function
over that domain. Put another way, the decision boundaries of XORα are at least as complicated as those for
any other α-variable Boolean function: there is one between every possible pair of feature vectors. For these
reasons, XOR is our polythetic function of choice in derivations, examples, and experiments."
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.08393285371702638,"3
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.08633093525179857,"Threshold and attentional classiﬁers have their own strengths and, in meta-learning polythetic classiﬁcations,
their own weaknesses. Threshold classiﬁers are insufﬁciently ﬂexible and attentional classiﬁers are prone to
misclassiﬁcation."
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.08872901678657075,"Threshold classiﬁers.
Figure 2 shows the decision boundaries formed by a prototypical threshold classiﬁer
and an attentional classiﬁer for a selection of 2-variable Boolean functions, highlighting the problem with
using threshold classiﬁers for polythetic classiﬁcation: logical XOR(x, y) is not a threshold function and the
prototypes fail to produce a useful decision boundary. This is the perceptron problem identiﬁed by Minsky &"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.09112709832134293,Under review as a conference paper at ICLR 2022
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.09352517985611511,"1
4
9
16
25
36
49
64
81
100
Embedding dimension"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.09592326139088729,"2
3
4
5
6
7
8
9
10
11
Sequence length"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.09832134292565947,"1.00
1.00
1.00
1.00
1.00
1.00
1.00
1.00
1.00
1.00"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.10071942446043165,"0.66
1.00
0.99
1.00
1.00
0.99
0.99
1.00
1.00
1.00"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.10311750599520383,"0.60
0.88
1.00
0.99
0.99
0.99
0.99
0.99
0.99
0.99"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.10551558752997602,"0.60
0.74
0.93
0.98
0.98
0.98
0.97
0.98
0.98
0.98"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.1079136690647482,"0.56
0.65
0.81
0.95
0.94
0.95
0.94
0.94
0.94
0.94"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.11031175059952038,"0.54
0.60
0.72
0.85
0.84
0.90
0.91
0.90
0.90
0.91"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.11270983213429256,"0.55
0.60
0.66
0.72
0.75
0.81
0.85
0.85
0.84
0.85"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.11510791366906475,"0.54
0.58
0.62
0.69
0.71
0.75
0.78
0.77
0.78
0.79"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.11750599520383694,"0.53
0.57
0.62
0.64
0.70
0.68
0.71
0.71
0.73
0.73"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.11990407673860912,"0.52
0.56
0.60
0.63
0.63
0.66
0.67
0.66
0.69
0.69"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.1223021582733813,Prototypical networks accuracy for XOR2 0.5 0.6 0.7 0.8 0.9 1.0
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.12470023980815348,"Figure 3: A non-threshold function of 2-variables, the pseudo-variable solution, and Prototypical
Network performance on the XOR2 problem. (a) XOR(x, y), which does not have a threshold solution
in 2 dimensions. (b) Appending the pseudo-variable XOR(x, y) gives a 3-dimensional embedding in
which all 2-variable Boolean functions have threshold solutions. XOR(x, y) is a pseudo-variable in
that it is determined by the other variables and cannot freely vary, for example the hatched circle at
(1, 0, 0) cannot occur. Right: Accuracy of prototypical networks for the XOR2 problem over sequence
length and embedding dimension. Mean over 1000 tasks, |S| = 40. See Appendix F for details."
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.12709832134292565,"Papert (1969). However, deep networks using threshold classiﬁers can learn XOR. This is possible because
the network can learn additional pseudo-features for the non-threshold functions it observes. Figure 3 shows
an example for 2-variables: one can embed the corners of the square at the corners of a tetrahedron with
coordinates
 
x, y, XOR(x, y)

and produce linear thresholds solutions for every 2-variable Boolean function."
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.12949640287769784,"There are two problems with this approach, both of which are exacerbated in the meta-learning context: i)
the required number of pseudo-variables grows as
 n
α

∼O(nα) to account for all combinations of α active
components, and ii) the method does not generalise to unseen non-threshold functions (see Appendix A). The
right plot in Figure 3 demonstrates these shortcomings for XOR2: the required number of pseudo-variables is
 n
2

∼O(n2) and initially we ﬁnd that a quadratic embedding is able to maintain performance, but for longer
sequences the number of threshold-functions unseen in training grows and performance degrades."
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.13189448441247004,"Attentional classiﬁers.
Attentional classiﬁers avoid these problems — the required embedding dimension
is linear in the number of features and the classiﬁer generalises to unseen classiﬁcations — but suffer from
over-sensitivity to irrelevant features. This results in misclassiﬁcation, which we quantify in the case of
Boolean functions to understand the scaling properties of this problem generally."
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.1342925659472422,"Consider classiﬁcations over binary feature vectors x ∈{−1, 1}n, with the class determined by XORα over
α elements with the remaining β = n −α being irrelevant. Assume each of the 2α variations of the active
elements are present with equal frequency, r, for a support set S of size |S| = r2α, and that the remaining
β elements follow a Bernoulli distribution with probability p. Using an attention classiﬁer of the form
ˆy = P"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.1366906474820144,"i∈S softmaxi
 
a(ˆx, xi)

yi, where a(ˆx, xi) is a measure of the similarity of ˆx and xi, how likely is it
that we misclassify a query drawn from the same distribution as S?"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.13908872901678657,"Without loss of generality, we can focus on the positive examples (with label = 1) for which a positive output
gives the correct classiﬁcation. Using dot-product attention, the mean and variance of the classiﬁer output are,
with ¯p = p2 + (1 −p)2 and ¯q = 1 −¯p,"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.14148681055155876,"µ = r(e −e−1)α

¯pe + ¯qe−1β
= r(e −e−1)α[cβ],
(3)"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.14388489208633093,"σ2 = r(e2 + e−2)α

¯pe2 + ¯qe−2β
−

¯pe + ¯qe−12β
= r(e2 + e−2)α[dβ −c2β],
(4)"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.14628297362110312,Under review as a conference paper at ICLR 2022
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.1486810551558753,"introducing c and d for compactness. The mean is positive, as desired, but we are interested in the rate of
misclassiﬁcation, which may be interpreted using the scale-free and dimensionless coefﬁcient-of-variation (the
ratio of the standard deviation to the mean) where greater variation indicates a greater rate of misclassiﬁcation.
From Equations 3 and 4, we have"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.1510791366906475,"σ
µ =
1
√r √"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.15347721822541965,e2 + e−2
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.15587529976019185,e −e−1
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.15827338129496402,"!α   d c2 β
−1 !1/2 .
(5)"
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.1606714628297362,"Starting with the leftmost term, increasing the number of repetitions, r, reduces the relative variability. This
aligns with intuition and limits, where an empty support set, r = 0, provides no basis on which to make
predictions and at the other extreme, r ≫2β, the support set is likely to span the input domain reducing
classiﬁcation to look-up. The term raised to α is approximately 3.2, and so the variability increases with the
number of active elements. An intuitive explanation is that the number of immediate neighbours of each
point grows as
 n
α

= α and this reduces the conﬁdence with which the point is classiﬁed, so the barrier to
misclassiﬁcation is reduced. Finally, d > c2 and so the rightmost term is positive and grows exponentially in
β, meaning that misclassiﬁcation increases with the number of irrelevant features. A full derivation, including
alternative attention functions, is provided in Appendix C."
CHALLENGES IN META-LEARNING POLYTHETIC CLASSIFICATIONS,0.1630695443645084,"The problem of misclassiﬁcation due to over-sensitivity in attentional classiﬁers was recognised in the work
of Luong et al. (2015) on sequence processing. There the problem was addressed by attending only to a
subset of elements within some distance of the target position. However, sets do not have such an ordering
and so we instead propose a feature-selection method to resolve the problem more generally."
ATTENTIONAL FEATURE SELECTION,0.16546762589928057,"4
ATTENTIONAL FEATURE SELECTION"
ATTENTIONAL FEATURE SELECTION,0.16786570743405277,"A key challenge of meta-learning is that not all features are relevant in all tasks and that the support is unlikely
to span the input domain. The model must choose, using incomplete information, what to focus on and what
to ignore by detecting the salient features within and between classes. For monothetic classiﬁcations this is
straightforward: by deﬁnition, averaging highlights necessary features whilst diminishing irrelevant features.
Prototype methods rely on this process. In the polythetic case, attentional classiﬁers have the advantage
of being able to learn non-threshold functions without the need for pseudo-variables but do not beneﬁt, as
prototypes do, from ‘washing-out’ irrelevant features through averaging. Indeed, attentional classiﬁers are
susceptible even in the monothetic setting to misclassifying on the basis of closely matching features that"
ATTENTIONAL FEATURE SELECTION,0.17026378896882494,"[1.00, 1.00, 1.00, 1.00, 1.00, 1.00] n = 0"
ATTENTIONAL FEATURE SELECTION,0.17266187050359713,"[1.00, 1.00, 1.00, 0.88, 0.76, 0.85] n = 5"
ATTENTIONAL FEATURE SELECTION,0.1750599520383693,"[1.00, 1.00, 1.00, 0.89, 0.80, 0.69]"
ATTENTIONAL FEATURE SELECTION,0.1774580335731415,n = 10
ATTENTIONAL FEATURE SELECTION,0.17985611510791366,"[1.00, 1.00, 1.00, 0.87, 0.78, 0.66]"
ATTENTIONAL FEATURE SELECTION,0.18225419664268586,n = 25
ATTENTIONAL FEATURE SELECTION,0.18465227817745802,"Figure 4: Feature values and attention coefﬁcients during the feature-selection self-attention (n =
{0, 5, 10, 25}) within a class of XOR3. Nodes depict examples of the support set: the colour of the
left halves represents the active features; the right halves represents the magnitude of the irrelevant
features. Edge width and opacity indicate the attention strength between a pair of nodes. The red,
green, blue and white groups, different variants, automatically segregate which preserves their active
features while the irrelevant features converge, as shown in the feature scores beneath each plot. In
this way, the active features identify themselves."
ATTENTIONAL FEATURE SELECTION,0.18705035971223022,Under review as a conference paper at ICLR 2022
ATTENTIONAL FEATURE SELECTION,0.18944844124700239,"are not relevant to the problem (putting a zebra with the big-cats because its stripes match those of a tiger
in the support set, for example). Misclassiﬁcation occurs when irrelevant features overwhelm the signal
from the active elements. As this is a problem of highlighting the salient patterns within a set, we propose a
self-attention based mechanism for feature selection, presented in Algorithm 1 and illustrated in Figure 4."
ATTENTIONAL FEATURE SELECTION,0.19184652278177458,"Intuitively, the process exploits the over-representation of patterns within features that are relevant to the
classiﬁcation as compared to patterns within the irrelevant features. We ﬁrst standardise the features to prevent
those common to the entire support, which are not discriminating, from dominating (Line 1) and stabilise, ϵ, to
prevent weakly activated features from being excessively scaled-up. We then repeatedly self-attend within each
separate class k of the support set, using dot product attention with scale τ, Xk ←DotAttn(Xk, Xk, Xk, τ).
Self-attention maps elements of a set of vectors to the interior of their convex hull. If every member of a class
has some feature in common, the convex hull in that dimension is a point and the features do not change. In
the polythetic case it is patterns of features that matter, and by attending more strongly between elements of
the support set with such feature-patterns, these too are preserved. Figure 4, for example, shows polythetic
variations within a class of XOR3 with three active and three irrelevant features (α = β = 3). The patterns
in the active features self-reinforce, forming cliques of strongly connected elements, whilst the irrelevant
features decay. Finally, features are scored by their dispersion over the support set (Line 5) which indicates
how well they have been preserved through the self-attention iterations, and thus how relevant they are."
ATTENTIONAL FEATURE SELECTION,0.19424460431654678,"Algorithm 1: Self-attention feature scoring. Scores can be used for rescaling or masking. Note that the
z-normalisation is over the entire support set whilst the self-attention is within classes. The choice of
dispersion measure is of secondary importance and discussed in the main text.
Input
:Support set S = {xi, yi}i∈IS with class labels yi ∈{1, . . . , K} and features xi ∈RF , Sk denoting the
subset of S containing all samples with yi = k and Xk ∈R|Sk|×F an arbitrarily ordered matrix of feature
vectors belonging to Sk; small numerical constant, ϵ; attention temperature, τ −1; repetitions, R.
Output :Feature scores, f ∈RF ."
ATTENTIONAL FEATURE SELECTION,0.19664268585131894,"1 xi ←(xi −µX)/(σX + ϵ) ;
// standardise"
REPEAT R TIMES,0.19904076738609114,2 repeat R times
REPEAT R TIMES,0.2014388489208633,"3
for k ←1 to K do
// for each class"
REPEAT R TIMES,0.2038369304556355,"4
Xk ←softmax(τXkXT
k )Xk ;
// softmax is row-wise"
REPEAT R TIMES,0.20623501199040767,"5 f ←dispersion({xi}i∈Si) ;
// mean-absolute-deviation, std.
dev etc."
REPEAT R TIMES,0.20863309352517986,"The scores can be used directly to rescale features across the support and query sets before applying the
classiﬁer, as in Figure 5, or in top-k selection. We focus on rescaling as the method that makes the fewest
assumptions about the underlying classiﬁcation, but using top-k is highly effective when the number of active
elements is known, as shown in Appendix D."
EXPERIMENTS,0.21103117505995203,"5
EXPERIMENTS"
EXPERIMENTS,0.21342925659472423,"We compare the proposed method (FS) with Prototypical Networks (PN) (Snell et al., 2017), a threshold
classiﬁer, and Matching Networks (MN) (Vinyals et al., 2016), an attentional classiﬁer without feature-
selection, in a sequence of increasingly complex synthetic and real-world few-shot learning problems. As
our approach is non-parametric and operates directly on high-level features, it is agnostic to the choice of
feature extractor, and we are free to choose as appropriate e.g. a convolutional neural network for images or
a multi-layer perceptron for tabular data, and in all experiments we use the same embedding model for all
methods (see experimental details in Appendix F)."
EXPERIMENTS,0.2158273381294964,"Binary strings. We consider meta-learning Boolean functions of n = α + β variables. Labels for inputs
x ∈{−1, 1}n are generated by computing the XOR of a random subset of components of size α. Each
variation in the active elements occurs 5 times in the support, |S| = 5 · 2α. The subset of active components"
EXPERIMENTS,0.2182254196642686,Under review as a conference paper at ICLR 2022
EXPERIMENTS,0.22062350119904076,"1
2
3
4
5
6
7
8
9
10
Variant examples, r"
EXPERIMENTS,0.22302158273381295,"1
2
3
4
5
6
7
8
9 10
Inactive components, β"
EXPERIMENTS,0.22541966426858512,0.58 0.77 0.88 0.92 0.94 0.96 0.97 0.98 0.99 0.99
EXPERIMENTS,0.2278177458033573,0.54 0.61 0.69 0.76 0.80 0.85 0.87 0.90 0.91 0.93
EXPERIMENTS,0.2302158273381295,0.54 0.57 0.61 0.65 0.68 0.72 0.75 0.78 0.80 0.82
EXPERIMENTS,0.23261390887290168,0.51 0.56 0.58 0.61 0.63 0.65 0.68 0.69 0.71 0.73
EXPERIMENTS,0.23501199040767387,0.52 0.54 0.56 0.58 0.60 0.62 0.63 0.64 0.66 0.67
EXPERIMENTS,0.23741007194244604,0.50 0.53 0.54 0.56 0.58 0.59 0.60 0.62 0.62 0.63
EXPERIMENTS,0.23980815347721823,0.50 0.53 0.53 0.55 0.56 0.57 0.58 0.59 0.60 0.61
EXPERIMENTS,0.2422062350119904,0.51 0.52 0.53 0.55 0.55 0.56 0.57 0.58 0.58 0.59
EXPERIMENTS,0.2446043165467626,0.50 0.51 0.52 0.53 0.54 0.55 0.55 0.56 0.57 0.58
EXPERIMENTS,0.24700239808153476,0.51 0.51 0.52 0.53 0.54 0.54 0.55 0.55 0.56 0.56
EXPERIMENTS,0.24940047961630696,Directly on inputs
EXPERIMENTS,0.2517985611510791,"1
2
3
4
5
6
7
8
9
10
Variant examples, r"
EXPERIMENTS,0.2541966426858513,"1
2
3
4
5
6
7
8
9 10"
EXPERIMENTS,0.2565947242206235,0.85 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00
EXPERIMENTS,0.2589928057553957,0.74 0.99 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00
EXPERIMENTS,0.26139088729016785,0.66 0.95 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00
EXPERIMENTS,0.2637889688249401,0.60 0.84 0.98 1.00 1.00 1.00 1.00 1.00 1.00 1.00
EXPERIMENTS,0.26618705035971224,0.57 0.73 0.90 0.98 1.00 1.00 1.00 1.00 1.00 1.00
EXPERIMENTS,0.2685851318944844,0.55 0.65 0.78 0.90 0.96 0.99 1.00 1.00 1.00 1.00
EXPERIMENTS,0.2709832134292566,0.53 0.59 0.68 0.77 0.87 0.93 0.97 0.98 0.99 1.00
EXPERIMENTS,0.2733812949640288,0.54 0.56 0.62 0.68 0.75 0.82 0.88 0.92 0.95 0.97
EXPERIMENTS,0.27577937649880097,0.52 0.56 0.59 0.62 0.66 0.72 0.77 0.80 0.85 0.88
EXPERIMENTS,0.27817745803357313,0.51 0.54 0.56 0.59 0.62 0.64 0.67 0.70 0.74 0.78
EXPERIMENTS,0.2805755395683453,with soft feature selection
EXPERIMENTS,0.2829736211031175,"1
2
3
4
5
6
7
8
9
10
Variant examples, r"
EXPERIMENTS,0.2853717026378897,"1
2
3
4
5
6
7
8
9 10"
EXPERIMENTS,0.28776978417266186,0.27 0.23 0.12 0.08 0.06 0.04 0.03 0.02 0.01 0.01
EXPERIMENTS,0.290167865707434,0.20 0.39 0.31 0.24 0.20 0.15 0.13 0.10 0.09 0.07
EXPERIMENTS,0.29256594724220625,0.13 0.38 0.39 0.35 0.32 0.28 0.25 0.22 0.20 0.18
EXPERIMENTS,0.2949640287769784,0.09 0.29 0.40 0.39 0.37 0.35 0.32 0.31 0.29 0.27
EXPERIMENTS,0.2973621103117506,0.05 0.19 0.34 0.39 0.40 0.38 0.37 0.36 0.34 0.33
EXPERIMENTS,0.2997601918465228,0.05 0.12 0.24 0.34 0.39 0.40 0.39 0.38 0.38 0.37
EXPERIMENTS,0.302158273381295,0.03 0.06 0.15 0.23 0.31 0.36 0.39 0.39 0.39 0.39
EXPERIMENTS,0.30455635491606714,0.03 0.04 0.09 0.13 0.19 0.26 0.31 0.34 0.37 0.38
EXPERIMENTS,0.3069544364508393,0.02 0.04 0.06 0.08 0.12 0.17 0.21 0.24 0.28 0.31
EXPERIMENTS,0.30935251798561153,0.01 0.04 0.04 0.06 0.08 0.10 0.12 0.14 0.18 0.21
EXPERIMENTS,0.3117505995203837,∆accuracy 0.5 0.6 0.7 0.8 0.9 1.0 0.5 0.6 0.7 0.8 0.9 1.0 0.08 0.16 0.24 0.32 0.40
EXPERIMENTS,0.31414868105515587,"Figure 5: Attention classiﬁcation of the XOR4 problem over variant frequency, r, and number
of inactive components β. Increasing r assists feature selection, in agreement with the derived
misclassiﬁcation distribution. Soft feature-selection rescales features according to their scores, as
determined by the proposed self-attention procedure. This greatly improves performance even at low
repetitions, for example at 2 repetitions and 3 inactive components the change in accuracy is +38pp.
Neither method is effective at high β with low r."
EXPERIMENTS,0.31654676258992803,"Table 1: Binary strings. Accuracy by embedding dimension for sequences of length n = 5 and n = 10.
Mean and standard error calculated over 1000 tasks."
EXPERIMENTS,0.31894484412470026,"n = 5
n = 10"
EXPERIMENTS,0.3213429256594724,"Model
Emb.
XOR2
XOR3
XOR4
XOR2
XOR3
XOR4 PN"
EXPERIMENTS,0.3237410071942446,"1
57.6 ± 0.5
55.3 ± 0.5
60.8 ± 0.7
51.7 ± 0.4
50.2 ± 0.2
50.1 ± 0.2
n
73.6 ± 0.5
70.3 ± 0.7
91.4 ± 0.4
56.7 ± 0.4
50.1 ± 0.2
50.4 ± 0.2
n2
90.4 ± 0.3
77.8 ± 0.7
100.0 ± 0.0
62.1 ± 0.4
50.3 ± 0.2
50.6 ± 0.2"
EXPERIMENTS,0.3261390887290168,"FS+MN
n
99.6 ± 0.2
100.0 ± 0.0
100.0 ± 0.0
75.9 ± 1.3
82.6 ± 1.1
96.3 ± 0.5"
EXPERIMENTS,0.328537170263789,"is unknown to the meta-learner. Appendix I shows a concrete example of an XOR2 task. Table 1 summarises
the performances of Prototypical Networks and our approach. PN accuracy decreases sharply with sequence
length n and the number of embedding units required to effectively solve this problem grows rapidly with n,
as shown previously in Figure 3. This suggests that PN are indeed learning pseudo-variables and demonstrates
the limitations of threshold classiﬁers in solving polythetic problems."
EXPERIMENTS,0.33093525179856115,"Polythetic MNIST. We evaluate the ability of the models to jointly extract high-level features and identify
polythetic patterns. We build tasks (episodes) using MNIST digits (LeCun et al., 2010), where an example
consists of 4 coloured digits (RGB). An example task and further details are provided in Appendix J. For
monothetic tasks, a single high-level feature (e.g. colour of the top-right digit) distinguishes classes. For
polythetic tasks, class membership derives from XOR interactions over a subset of features, and the remainder
are problem-irrelevant. Table 2 shows the performances on three versions of the polythetic MNIST dataset:
clean (excluding non-discriminative digits), colourless (task-irrelevant digits but no colour), and full (both task-
irrelevant digits and colour). The models are trained on monothetic tasks and evaluated both on monothetic
and polythetic tasks. Protonets excel at identifying monothetic features and ignoring non-discriminative
features, but have a close to random performance on polythetic tasks. Conversely, matching networks, which
are polythetic classiﬁers by default, are highly sensitive to task-irrelevant features. The proposed approach
(FS) can simultaneously detect salient features and perform polythetic classiﬁcations. Furthermore, as shown
in Figure 6, we found our classiﬁer to be robust to the rate of polythetic tasks seen during training in a second
experiment."
EXPERIMENTS,0.3333333333333333,"Omniglot. The Omniglot dataset (Lake et al., 2011) consists of handwritten characters from 50 writing
systems with 20 hand drawn examples of each character. Training tasks are formed using examples from 30
of the alphabets and test tasks draw from the other 20. We compare our method to PN, MN, Inﬁnite Mixture"
EXPERIMENTS,0.33573141486810554,Under review as a conference paper at ICLR 2022
EXPERIMENTS,0.3381294964028777,"Table 2: Polythetic MNIST. Evaluation accuracy on monothetic and polythetic tasks in three settings.
Mean and standard error calculated over 1000 tasks."
EXPERIMENTS,0.3405275779376499,"Clean
Colourless
Full"
EXPERIMENTS,0.34292565947242204,"Model
Monothetic
Polythetic
Monothetic
Polythetic
Monothetic
Polythetic"
EXPERIMENTS,0.34532374100719426,"PN
97.9 ± 0.1
50.6 ± 0.3
92.8 ± 0.3
49.9 ± 0.3
94.5 ± 0.3
49.8 ± 0.2
MN
79.6 ± 0.6
57.6 ± 0.4
69.7 ± 0.4
61.0 ± 0.5
70.1 ± 0.7
56.6 ± 0.5"
EXPERIMENTS,0.34772182254196643,"FS+MN
96.8 ± 0.1
98.3 ± 0.0
94.5 ± 0.2
98.0 ± 0.0
75.0 ± 0.7
60.4 ± 0.7"
EXPERIMENTS,0.3501199040767386,"0
1
Polythetic proportion during training 50% 100%"
EXPERIMENTS,0.35251798561151076,Test time accuracy
EXPERIMENTS,0.354916067146283,Monothetic test
EXPERIMENTS,0.35731414868105515,"FS
PN
MN"
EXPERIMENTS,0.3597122302158273,"0
1
Polythetic proportion during training 50% 100%"
EXPERIMENTS,0.36211031175059955,Polythetic test
EXPERIMENTS,0.3645083932853717,"Figure 6: Polythetic MNIST (colourless) by polythetic proportion
during training. FS matches or outperforms the other models at
all training proportions and is far less affected by the training mix.
Mean and standard deviation over 1000 tasks at each proportion."
EXPERIMENTS,0.3669064748201439,"Table 3: Omniglot. 20-way, 5-shot
characters; 3-way alphabets. Mean
and standard error on 1000 tasks."
EXPERIMENTS,0.36930455635491605,"Characters
Alphabets"
EXPERIMENTS,0.37170263788968827,"PN
98.6 ± 0.0
83.4 ± 0.3
MN
91.1 ± 0.1
78.4 ± 0.3
FS+MN
96.2 ± 0.0
94.2 ± 0.2
IMP
98.6 ± 0.0
96.0 ± 0.2
MAML
94.0 ± 0.1
89.9 ± 0.3"
EXPERIMENTS,0.37410071942446044,"MN*
97.9 ± 0.1
81.3 ± 0.3
NN*
98.3 ± 0.0
95.7 ± 0.3
FS+MN*
98.1 ± 0.0
96.0 ± 0.2
FS+NN*
98.3 ± 0.0
96.0 ± 0.2"
EXPERIMENTS,0.3764988009592326,"Prototypes (IMP) (Allen et al., 2019), and MAML (Finn et al., 2017) with a threshold classiﬁer (Triantaﬁllou
et al., 2020). We train the models for character recognition, and additionally evaluate performance on
3-way alphabet recognition (inherently polythetic). Our approach can be used in conjunction with most
few-shot learning approaches – we speciﬁcally apply FS prior to MN and single-nearest-neighbours (NN),
corresponding to MN with softmax converging to argmax (see Appendix B). Table 3 shows the results of
this experiment. The end-to-end trained model (FS+MN) is competitive with PN and IMP, while performing
better than MN and MAML in character recognition. In alphabet recognition, FS+MN performs better
than other methods, while being competitive with IMP. We further evaluate the performance when using
a pre-trained feature extractor (methods marked with *), obtained by training a PN threshold classiﬁer on
character recognition. FS+MN* improves over MN* in both tasks. Compared to PN, the accuracy of FS+MN*
and FS+NN* in character recognition is reduced by at most 0.5pp; yet improved in alphabet recognition by
12.6pp, while performing similarly to the more complex IMP."
EXPERIMENTS,0.37889688249400477,"TieredImageNet. TieredImageNet (Ren et al., 2018) is a subset of ILSVRC-12 (Russakovsky et al., 2015)
with polythetic characteristics, with classes grouped into categories corresponding to higher-level nodes in
the ImageNet hierarchy. There are 34 categories of 10 to 30 classes each. We compare our method (FS) to"
EXPERIMENTS,0.381294964028777,"Table 4: TieredImageNet. Model accu-
racy by categories (C) and groups (G)
over 500 tasks."
EXPERIMENTS,0.38369304556354916,"G
C = 2
C = 4
C = 8"
FS,0.38609112709832133,"5
FS
83.5 ± 0.3
66.4 ± 0.3
48.9 ± 0.2
MN
82.7 ± 0.4
65.4 ± 0.3
48.3 ± 0.2
PN
81.4 ± 0.3
64.6 ± 0.3
49.4 ± 0.1"
FS,0.38848920863309355,"10
FS
83.6 ± 0.3
65.8 ± 0.3
48.7 ± 0.1
MN
82.9 ± 0.3
64.9 ± 0.3
48.0 ± 0.1
PN
81.1 ± 0.3
63.3 ± 0.3
48.2 ± 0.1"
FS,0.3908872901678657,"Table 5: TieredImageNet. Head-to-head comparison
over 500 tasks by categories (C) and subgroups (G).
Bold indicates signiﬁcance at the p < 0.001 level."
FS,0.3932853717026379,"C = 2
C = 4
C = 8"
FS,0.39568345323741005,"G
X
Y
X / Y
(tie)
X / Y
(tie)
X / Y
(tie)"
"FS
MN",0.3980815347721823,"5
FS
MN
230 / 162
(108)
329 / 101
(70)
343 / 113
(44)
FS
PN
319 / 136
(45)
339 / 142
(19)
239 / 247
(14)"
"FS
MN",0.40047961630695444,"10
FS
MN
258 / 185
(57)
357 / 108
(35)
413 / 68
(19)
FS
PN
374 / 101
(25)
396 / 99
(5)
296 / 191
(13)"
"FS
MN",0.4028776978417266,Under review as a conference paper at ICLR 2022
"FS
MN",0.4052757793764988,"PN and MN classiﬁers. We use a publicly available pre-trained ResNet-12 (Zhang et al., 2020), pre-trained
using the training classes in TieredImageNet, as the feature extractor for all models. Table 4 presents the
aggregate accuracy while Table 5 shows the head-to-head results of this experiment. FS leads to signiﬁcant
improvements in performance (except C=8/G=5, where the difference between PN and FS is not signiﬁcant)
in this full scale, naturally polythetic problem, particularly in the “more polythetic” case with 10 subgroups."
RELATED WORK,0.407673860911271,"6
RELATED WORK"
RELATED WORK,0.41007194244604317,"We characterise meta-learning approaches for few-shot classiﬁcation. In addition to evaluating their ability to
generalise to unseen classes, we investigate how well they can adapt to polythetic tasks (generalisation to
unseen ways of cateogorising). Adaptability in few-shot settings has been studied through different paradigms
such as fast weights (Ba et al., 2016), learnable plasticity (Miconi et al., 2018) and meta-learning. Recent
work on meta-learning for few-shot classiﬁcation includes approaches that are able to quickly adapt through
various mechanisms such as recurrent architectures (Mishra et al., 2018; Santoro et al., 2016) for learning
parameter updates (Ravi & Larochelle, 2017). Other more general optimisation-based approaches (Finn
et al., 2017; Nichol et al., 2018; Rusu et al., 2019), tackle these tasks by explicitly optimising the model’s
parameters. These, however, are typically model-agnostic and commonly used in conjunction with threshold
classiﬁers (Triantaﬁllou et al., 2020), inheriting their limitations in a polythetic scenarios."
RELATED WORK,0.41247002398081534,"Our work aligns more closely with metric-learning approaches for few-shot classiﬁcation (Chen et al., 2019)
that apply distance functions between queries and the support in a common embedding space (Allen et al.,
2019; Oreshkin et al., 2018; Snell et al., 2017; Sung et al., 2018; Vinyals et al., 2016; Zhang et al., 2020).
Methods that construct class-wise prototypes from the support (Allen et al., 2019; Ren et al., 2018; Snell
et al., 2017) can successfully tackle monothetic tasks, but can struggle with task-adaptiveness in a polythetic
context. Attentional meta-classiﬁers (Hou et al., 2019; Jiang et al., 2020; Kim et al., 2019; Vinyals et al.,
2016) adapt to polythetic tasks but lack crucial mechanisms for focusing exclusively on relevant features."
RELATED WORK,0.4148681055155875,"Attending over datapoints has been considered previously. Luong et al. (2015) introduced dot-product
attention in the context of attending over sequences. Vinyals et al. (2016) considered ˆy = P"
RELATED WORK,0.4172661870503597,"i∈IS a(ˆx, xi)yi
and provided the conditions under which such a model carries out kernel density estimation or k-nearest-
neighbours classiﬁcation. Vaswani et al. (2017) used explicit scaling in hidden attention layers, but scaling a
classifying softmax by a temperature parameter dates to the work of Boltzmann and later Gibbs (1902). Plötz
& Roth (2018) note that their neural-nearest-neighbours (N3) block recovers a soft-attention weighting when
the number of neighbours is set to 1, and deploy their model on an outlier-detection set-reasoning task."
CONCLUSION,0.4196642685851319,"7
CONCLUSION"
CONCLUSION,0.42206235011990406,"In this work we have articulated the difference between monothetic and polythetic classiﬁcations and
considered the limitations of standard meta-learning classiﬁers in the polythetic case. We have shown that
threshold classiﬁers require an embedding space that is exponential in the number of active features and
that attentional classiﬁers are overly sensitive and susceptible to misclassiﬁcation. To address this, we have
proposed an attention based method for feature-selection and demonstrated the effectiveness of our approach
in several synthetic and real-world few-shot learning problems. Our approach is simple and can be used
in conjunction with most few-shot meta-learners. We expect polythetic meta-learners to ﬁnd real-world
application in domains where data is typically scarce and complex, such as healthcare or bioinformatics. For
example, we envision a use in classifying rare diseases — there are around 7000 rare diseases, affecting ∼1/17
of the worldwide population — from DNA sequences, where mutations often lead to different phenotypes. In
such scenarios, few-shot learning approaches able to generalise over unseen combinations of mutations (i.e.
ways of categorising), in a similar vein to our binary strings experiment, may lead to better performance in
diagnosing rare diseases and shed new insights into their molecular mechanisms."
CONCLUSION,0.4244604316546763,Under review as a conference paper at ICLR 2022
REPRODUCIBILITY STATEMENT,0.42685851318944845,REPRODUCIBILITY STATEMENT
REPRODUCIBILITY STATEMENT,0.4292565947242206,"In Section 3 we discuss the challenges of polythetic classiﬁcation and the limitations of current work on
meta-classiﬁers. Our proposed self-attention feature scoring algorithm is described in detail in Section 4, and
in particular, Algorithm 1 (and Appendix H). To ensure the work is readily reproducible, besides descriptions
of the experimental setup provided in Section 5 and the supplementary material (Appendices F, G, I, J) - we
also provide code used for producing the results in the paper."
REFERENCES,0.4316546762589928,REFERENCES
REFERENCES,0.434052757793765,"Kelsey R. Allen, Evan Shelhamer, Hanul Shin, and Joshua B. Tenenbaum. Inﬁnite mixture prototypes for
few-shot learning. In Proceedings of the 36th International Conference on Machine Learning, ICML 2019,
9-15 June 2019, Long Beach, California, USA, volume 97 of Proceedings of Machine Learning Research,
pp. 232–241. PMLR, 2019."
REFERENCES,0.4364508393285372,"Jimmy Ba, Geoffrey E. Hinton, Volodymyr Mnih, Joel Z. Leibo, and Catalin Ionescu. Using fast weights to
attend to the recent past. In NIPS, pp. 4331–4339, 2016."
REFERENCES,0.43884892086330934,"Wei-Yu Chen, Yen-Cheng Liu, Zsolt Kira, Yu-Chiang Frank Wang, and Jia-Bin Huang. A closer look at
few-shot classiﬁcation. In 7th International Conference on Learning Representations, ICLR 2019, New
Orleans, LA, USA, May 6-9, 2019, 2019."
REFERENCES,0.4412470023980815,"Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep
networks. In Doina Precup and Yee Whye Teh (eds.), Proceedings of the 34th International Conference
on Machine Learning, volume 70 of Proceedings of Machine Learning Research, pp. 1126–1135. PMLR,
06–11 Aug 2017."
REFERENCES,0.44364508393285373,"J Willard Gibbs. Elementary principles in statistical mechanics. Charles Scribner’s Sons, 1902."
REFERENCES,0.4460431654676259,"Nicolle Gruzling. Linear separability of the vertices of an n-dimensional hypercube. 2007. doi: 10.24124/
2007/bpgub464."
REFERENCES,0.44844124700239807,"Birger Hjørland. Classiﬁcation. Knowledge Organization, 44(2):97–128, 2017. URL http://www.isko.
org/cyclo/classification."
REFERENCES,0.45083932853717024,"Ruibing Hou, Hong Chang, Bingpeng Ma, Shiguang Shan, and Xilin Chen. Cross attention network for
few-shot classiﬁcation. In Advances in Neural Information Processing Systems 32: Annual Conference
on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC,
Canada, pp. 4005–4016, 2019."
REFERENCES,0.45323741007194246,"Anwar A Irmatov. On the number of threshold functions. Discrete Mathematics and Applications, 3(4):
429–432, 1993."
REFERENCES,0.4556354916067146,"Zihang Jiang, Bingyi Kang, Kuangqi Zhou, and Jiashi Feng. Few-shot classiﬁcation via adaptive attention."
REFERENCES,0.4580335731414868,"CoRR, abs/2008.02465, 2020."
REFERENCES,0.460431654676259,"Hyunjik Kim, Andriy Mnih, Jonathan Schwarz, Marta Garnelo, Ali Eslami, Dan Rosenbaum, Oriol Vinyals,
and Yee Whye Teh. Attentive neural processes. In International Conference on Learning Representations,
2019. URL https://openreview.net/forum?id=SkE6PjC9KX."
REFERENCES,0.4628297362110312,"Brenden Lake, Ruslan Salakhutdinov, Jason Gross, and Joshua Tenenbaum. One shot learning of simple
visual concepts. In Proceedings of the annual meeting of the cognitive science society, volume 33, 2011."
REFERENCES,0.46522781774580335,Under review as a conference paper at ICLR 2022
REFERENCES,0.4676258992805755,"Yann LeCun, Corinna Cortes, and CJ Burges. MNIST handwritten digit database. ATT Labs [Online]."
REFERENCES,0.47002398081534774,"Available: http://yann.lecun.com/exdb/mnist, 2, 2010."
REFERENCES,0.4724220623501199,"Thang Luong, Hieu Pham, and Christopher D. Manning. Effective approaches to attention-based neural ma-
chine translation. In Lluís Màrquez, Chris Callison-Burch, Jian Su, Daniele Pighin, and Yuval Marton (eds.),
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP
2015, Lisbon, Portugal, September 17-21, 2015, pp. 1412–1421. The Association for Computational Lin-
guistics, 2015. doi: 10.18653/v1/d15-1166. URL https://doi.org/10.18653/v1/d15-1166."
REFERENCES,0.4748201438848921,"Thomas Miconi, Kenneth Stanley, and Jeff Clune. Differentiable plasticity: training plastic neural networks
with backpropagation. In Jennifer Dy and Andreas Krause (eds.), Proceedings of the 35th International
Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pp. 3559–
3568. PMLR, 10–15 Jul 2018."
REFERENCES,0.47721822541966424,Marvin Minsky and Seymour Papert. Perceptrons. 1969.
REFERENCES,0.47961630695443647,"Nikhil Mishra, Mostafa Rohaninejad, Xi Chen, and Pieter Abbeel. A simple neural attentive meta-learner. In"
REFERENCES,0.48201438848920863,"International Conference on Learning Representations, 2018."
REFERENCES,0.4844124700239808,"Alex Nichol, Joshua Achiam, and John Schulman. On ﬁrst-order meta-learning algorithms, 2018."
REFERENCES,0.486810551558753,"Ryan O’Donnell. Analysis of Boolean functions. Cambridge University Press, 2014."
REFERENCES,0.4892086330935252,"Boris N. Oreshkin, Pau Rodríguez López, and Alexandre Lacoste. TADAM: task dependent adaptive
metric for improved few-shot learning.
In Advances in Neural Information Processing Systems 31:
Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018,
Montréal, Canada, pp. 719–729, 2018."
REFERENCES,0.49160671462829736,"Tobias Plötz and Stefan Roth. Neural nearest neighbors networks. In S. Bengio, H. Wallach, H. Larochelle,
K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural Information Processing Systems,
volume 31. Curran Associates, Inc., 2018. URL https://proceedings.neurips.cc/paper/
2018/file/f0e52b27a7a5d6a1a87373dffa53dbe5-Paper.pdf."
REFERENCES,0.4940047961630695,"Sachin Ravi and H. Larochelle. Optimization as a model for few-shot learning. In ICLR, 2017."
REFERENCES,0.49640287769784175,"Mengye Ren, Eleni Triantaﬁllou, Sachin Ravi, Jake Snell, Kevin Swersky, Joshua B. Tenenbaum, Hugo
Larochelle, and Richard S. Zemel. Meta-learning for semi-supervised few-shot classiﬁcation. In 6th
International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 -
May 3, 2018, Conference Track Proceedings, 2018."
REFERENCES,0.4988009592326139,"Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej
Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. Imagenet large scale
visual recognition challenge. International Journal of Computer Vision, 115(3):211–252, Dec 2015. ISSN
1573-1405."
REFERENCES,0.5011990407673861,"Andrei A. Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan Pascanu, Simon Osindero, and
Raia Hadsell. Meta-learning with latent embedding optimization. In International Conference on Learning
Representations, 2019."
REFERENCES,0.5035971223021583,"Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy Lillicrap. Meta-learning
with memory-augmented neural networks. In Maria Florina Balcan and Kilian Q. Weinberger (eds.),
Proceedings of The 33rd International Conference on Machine Learning, volume 48 of Proceedings of
Machine Learning Research, pp. 1842–1850, New York, New York, USA, 20–22 Jun 2016. PMLR."
REFERENCES,0.5059952038369304,Under review as a conference paper at ICLR 2022
REFERENCES,0.5083932853717026,"Jake Snell,
Kevin Swersky,
and Richard Zemel.
Prototypical networks for few-shot learn-
ing.
In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan,
and R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 30. Curran
Associates, Inc., 2017.
URL https://proceedings.neurips.cc/paper/2017/file/
cb8da6767461f2812ae4290eac7cbc42-Paper.pdf."
REFERENCES,0.5107913669064749,"P.F. Stevens.
Linnaeus, Carl von (1707-78).
1998.
doi:
10.4324/9780415249126-Q059-1.
URL
https://www.rep.routledge.com/articles/biographical/
linnaeus-carl-von-1707-78/v-1/sections/the-natural-method."
REFERENCES,0.513189448441247,"Flood Sung, Yongxin Yang, Li Zhang, Tao Xiang, Philip H.S. Torr, and Timothy M. Hospedales. Learning
to compare: Relation network for few-shot learning. In 2018 IEEE/CVF Conference on Computer Vision
and Pattern Recognition, pp. 1199–1208, 2018."
REFERENCES,0.5155875299760192,"Eleni Triantaﬁllou, Tyler Zhu, Vincent Dumoulin, Pascal Lamblin, Utku Evci, Kelvin Xu, Ross Goroshin,
Carles Gelada, Kevin Swersky, Pierre-Antoine Manzagol, and Hugo Larochelle. Meta-dataset: A dataset of
datasets for learning to learn from few examples. In International Conference on Learning Representations,
2020."
REFERENCES,0.5179856115107914,"Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser,
and Illia Polosukhin. Attention is all you need. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach,
R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems,
volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper/
2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf."
REFERENCES,0.5203836930455635,"Oriol Vinyals, Charles Blundell, Timothy Lillicrap, koray kavukcuoglu, and Daan Wierstra.
Match-
ing networks for one shot learning.
In D. Lee,
M. Sugiyama,
U. Luxburg,
I. Guyon,
and R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 29. Curran
Associates, Inc., 2016.
URL https://proceedings.neurips.cc/paper/2016/file/
90e1357833654983612fb05e3ec9148c-Paper.pdf."
REFERENCES,0.5227817745803357,"Chi Zhang, Yujun Cai, Guosheng Lin, and Chunhua Shen. Deepemd: Few-shot image classiﬁcation with
differentiable earth mover’s distance and structured classiﬁers. In IEEE/CVF Conference on Computer
Vision and Pattern Recognition (CVPR), June 2020."
REFERENCES,0.5251798561151079,Under review as a conference paper at ICLR 2022
REFERENCES,0.5275779376498801,"A
PARTITIONED XOR PERFORMANCES"
REFERENCES,0.5299760191846523,"We hypothesise that, in order to solve polythetic tasks, prototypical networks need to create pseudo-variables
in the embedding space (e.g. XOR for each pair of components for binary strings tasks). To test this, we train
a prototypical network on binary strings tasks (where pairs of active components are always chosen from the
5 ﬁrst components) and evaluate the performance on unseen combinations of components (i.e. combinations
of the 5 ﬁrst components not seen during training). Table 6 shows the accuracies for sequences of length
n = 5 + β (where β is the number of variables that are always inactive). We attribute the better-than-chance
performances (i.e. for 100-dimensional embeddings) to the high-dimensionality of the embeddings – by
chance, large numbers of non-linear features (e.g. output by a random feature extractor) will include some
features that are useful for the task of interest (i.e. similar to extreme learning machines). Overall, these
results highlight the inability of prototypical networks to generalise to unseen combinations and support our
hypothesis."
REFERENCES,0.5323741007194245,"Table 6: Accuracy of prototypical networks on unseen non-threshold functions by embedding di-
mension. We use sequences of length n = 5 + β, where β is the number of components that are
always inactive. The labels are derived from XOR2 combinations over the ﬁrst 5 components and
the sets of combinations seen at train and test times are disjoint. In other words, the combinations
of variables (0, 1), (0, 2), (1, 3), (2, 4), (3, 4) are only seen active at train time, whereas, the combina-
tions (0, 3), (0, 4), (1, 2), (1, 4), (2, 3) are only seen at test time, with r = 5 repetitions for each XOR
combination. Each of the 5 ﬁrst variables has the same expected frequency of being active at train and
test times. The inability to generalise in this scenario suggests that protonets need pseudo-variables
(i.e. XOR functions applied to each pair of components) to solve the binary strings task."
REFERENCES,0.5347721822541966,"Emb.
β = 0
β = 1
β = 2"
REFERENCES,0.5371702637889688,"1
48.741 ± 0.276
48.855 ± 0.282
49.558 ± 0.284
10
50.350 ± 0.282
49.397 ± 0.286
49.479 ± 0.265
20
50.705 ± 0.271
51.057 ± 0.247
50.144 ± 0.255
100
52.246 ± 0.256
52.390 ± 0.265
52.573 ± 0.258"
REFERENCES,0.539568345323741,"B
TEMPERATURE IN ATTENTION CLASSIFICATION"
REFERENCES,0.5419664268585132,"The softmax in attention mechanisms permits a temperature scaling that interpolates between argmax and
uniform (and argmin.) This is controlled by T = 1"
REFERENCES,0.5443645083932853,"β , as"
REFERENCES,0.5467625899280576,"softmaxi(x, β) =
exp(βxi)
P"
REFERENCES,0.5491606714628298,j exp(βxj)
REFERENCES,0.5515587529976019,"with softmax converging to argmax as β →∞, and to uniform (i.e. all elements equal to the reciprocal of the
length of the vector) as β →0."
REFERENCES,0.5539568345323741,"For attention classiﬁers, a decrease in temperature increases the model conﬁdence and can cause decision
boundaries to move. As β →∞and the softmax converges to argmax, the classiﬁer tends to the single
nearest neighbour classiﬁcation scheme; for β = 0 the classiﬁer returns the support set class balance. For
Boolean functions, changes in temperature effect the degree to which decision boundaries are axis-aligned.
For example, Figure 2 shows the decision boundary for f(x, y) = AND(x, y) using a softmax temperature of"
REFERENCES,0.5563549160671463,Under review as a conference paper at ICLR 2022 T = 1 ++ +− −+ −−
REFERENCES,0.5587529976019184,T = 1/2 ++ +− −+ −−
REFERENCES,0.5611510791366906,T = 1/3 ++ +− −+ −−
REFERENCES,0.5635491606714629,T = 1/5 ++ +− −+ −−
REFERENCES,0.565947242206235,"Figure 7: Changes in conﬁdence and decision boundary of the attention classiﬁer with temperature for
AND(x, y)."
REFERENCES,0.5683453237410072,1 at y = −1
REFERENCES,0.5707434052757794,"2 ln (tanh x), which we derive as"
REFERENCES,0.5731414868105515,p(class 1) = p(class 0)
REFERENCES,0.5755395683453237,"exp
 
β(x + y)

P exp(...)
= exp
 
β(−x −y)

+ exp
 
β(−x + y)

+ exp
 
β(x −y)

P exp(...)"
REFERENCES,0.5779376498800959,"exp
 
β(x + y)

−exp
 
−β(x + y)

= exp
 
β(−x + y)

+ exp
 
β(x −y)
"
REFERENCES,0.580335731414868,sinh(β(x + y)) = cosh(β(x −y))
REFERENCES,0.5827338129496403,"sinh(βx)
 
cosh(βy) + sinh(βy)

= cosh(βx)
 
cosh(βy) −sinh(βy)
"
REFERENCES,0.5851318944844125,tanh(βx) = cosh(βy) + sinh(βy)
REFERENCES,0.5875299760191847,"cosh(βy) −sinh(βy)
tanh(βx) = exp(−2βy)"
REFERENCES,0.5899280575539568,y = −1
REFERENCES,0.592326139088729,"2β ln
 
tanh (βx)

."
REFERENCES,0.5947242206235012,The effect of decreasing the temperature on the decision boundary is shown in Figure 7.
REFERENCES,0.5971223021582733,"C
MISCLASSIFICATION DISTRIBUTION FULL DERIVATION"
REFERENCES,0.5995203836930456,"We ﬁrst present a more detailed derivation for the case of dot-product attention. We will make repeated use of
the Binomial theorem"
REFERENCES,0.6019184652278178,"(x + y)n = n
X k=0 n
k"
REFERENCES,0.60431654676259,"
xn−kyk = n
X k=0 n
k"
REFERENCES,0.6067146282973621,"
xkyn−k.
(6)"
REFERENCES,0.6091127098321343,"Recall that we consider classiﬁcations over binary feature vectors x ∈{−1, 1}n, with the class determined
by XORα over α elements with the remaining β = n −α being irrelevant. Assume each of the 2α variations
of the active elements are present with equal frequency, r, for a support set S of size |S| = r2α, and that the
remaining β elements follow a Bernoulli distribution with probability p. There are
 α
δ

strings over the active
elements that differ from a given example in δ positions. XOR ﬂips the classiﬁcation with each difference, so
if δ is even the class is the same, if δ is odd the class is different (parity)."
REFERENCES,0.6115107913669064,Under review as a conference paper at ICLR 2022
REFERENCES,0.6139088729016786,"The class is determined by the sign of the sum of contributions at an even distance subtract those at an odd
distance. Putting those into a single sum we have"
REFERENCES,0.6163069544364509,"class = sign  
α
X"
REFERENCES,0.6187050359712231,"δ=0
r(−1)δ
α
δ"
REFERENCES,0.6211031175059952,"
exp (α −2δ) "
REFERENCES,0.6235011990407674,".
(7)"
REFERENCES,0.6258992805755396,"We can factor out the number of repetitions, r, and as it is positive it doesn’t change the sign. We can then
rearrange to match the Binomial theorem form and recover the form in the main text:"
REFERENCES,0.6282973621103117,"class = sign  
α
X δ=0 α
δ"
REFERENCES,0.6306954436450839,"
eα−δ
−1 e δ
"
REFERENCES,0.6330935251798561,"= sign

e −e−1α
= +.
(8)"
REFERENCES,0.6354916067146283,"Next we give the Binomial distribution of the irrelevant feature contribution as 2B(β, ¯p) −β with ¯p =
p2 −(1 −p)2 = 2p2 −2p + 1. Something that is important to the behaviour of the mean and variance later,
and breaks the usual symmetry of p and q = (1 −p), is that ¯p ≥0.5 and is quadratic in p deﬁned by the
three points (p, ¯p) = {(0, 1), (0.5, 0.5), (1, 1)}. ¯q has the usual deﬁnition 1 −¯p, so ¯q ≤0.5 and so on. The
contribution at a difference δ is then X(δ) ∼exp (α −2δ + 2B(β, ¯p) −β). The expectation is computed in
the usual way"
REFERENCES,0.6378896882494005,"E[X(δ)] =
X"
REFERENCES,0.6402877697841727,"i
P(X = xi)xi = β
X"
REFERENCES,0.6426858513189448,"b=0
P(B(β, ¯p) = b) exp (α −2δ + 2b −β)"
REFERENCES,0.645083932853717,"= exp (α −2δ) β
X b=0 β
b"
REFERENCES,0.6474820143884892,"
¯pb¯q(β−b) exp (2b −β)"
REFERENCES,0.6498800959232613,"= exp (α −2δ) β
X b=0 β
b"
REFERENCES,0.6522781774580336,"
(¯pe)b(¯qe−1)β−b = exp (α −2δ)

¯pe + ¯qe−1β
."
REFERENCES,0.6546762589928058,"Finding the variance in the traditional way, Var[X(δ)] = E[X(δ)2] −E[X(δ)]2, ﬁrst E[X(δ)2] following the
derivation for E[X(δ)]:"
REFERENCES,0.657074340527578,"E[X(δ)2] =
X"
REFERENCES,0.6594724220623501,"i
P(X = xi)x2
i = β
X"
REFERENCES,0.6618705035971223,"b=0
P(B(β, ¯p) = b) exp (2α −4δ + 4b −2β)
(9)"
REFERENCES,0.6642685851318945,"= exp (2α −4δ) β
X b=0 β
b"
REFERENCES,0.6666666666666666,"
¯pb¯q(β−b) exp (4b −2β)
(10)"
REFERENCES,0.6690647482014388,"= exp (2α −4δ)

¯pe2 + ¯qe−2β
.
(11)"
REFERENCES,0.6714628297362111,From this we can write the variance
REFERENCES,0.6738609112709832,"Var[X(δ)] = exp (2α −4δ)

¯pe2 + ¯qe−2β
−

¯pe + ¯qe−12β
.
(12)"
REFERENCES,0.6762589928057554,"Next we want to ﬁnd the expectation of the sum of the contributions at each difference δ. As pointed out there
are
 α
δ

many strings at a difference of δ. We apply E[P
i Xi] = P
i E[Xi] and Var[X−Y] = Var[X]+Var[Y],"
REFERENCES,0.6786570743405276,Under review as a conference paper at ICLR 2022
REFERENCES,0.6810551558752997,"and, remembering to change the sign with each increase in δ, E
hP"
REFERENCES,0.6834532374100719,"i∈S(−1)δiX(δi)
i
= α
X"
REFERENCES,0.6858513189448441,"δ=0
r(−1)δ
α
δ"
REFERENCES,0.6882494004796164,"
E[X(δ)]
(13)"
REFERENCES,0.6906474820143885,"= r

¯pe2 + ¯qe−2β
α
X δ=0 α
δ"
REFERENCES,0.6930455635491607,"
e(α−δ)
−1 e"
REFERENCES,0.6954436450839329,"δ
(14)"
REFERENCES,0.697841726618705,"= r

¯pe2 + ¯qe−2β 
e −e−1α
,
(15) and"
REFERENCES,0.7002398081534772,"Var
hP
i∈S(−1)δiX(δi)
i
= Var
hP
i∈S X(δi)
i
= α
X"
REFERENCES,0.7026378896882494,"δ=0
r
α
δ"
REFERENCES,0.7050359712230215,"
Var[X(δ)]
(16)"
REFERENCES,0.7074340527577938,"= r

¯pe2 + ¯qe−2β
−

¯pe + ¯qe−12β
α
X δ=0 α
δ"
REFERENCES,0.709832134292566," 
e2α−δ 
e−2δ
(17)"
REFERENCES,0.7122302158273381,"= r

¯pe2 + ¯qe−2β
−

¯pe + ¯qe−12β
(e2 + e−2)α.
(18)"
REFERENCES,0.7146282973621103,"C.1
DIFFERENT ATTENTION MECHANISMS"
REFERENCES,0.7170263788968825,"For dot-product and cosine-similarity attention, ‘angular’ difference mechanisms, we use (+, −) to encode
the input variables. This is because we want the score to be greater when the variables are the same and lesser
when they are opposed (if we were to use (1, 0) we’d have 0 × 0 ̸= 1 × 1 and 0 × 1 = 0 × 0). With these
methods we get"
REFERENCES,0.7194244604316546,"fdot(δ) = α −2δ,
(19)"
REFERENCES,0.7218225419664268,fcos(δ) = 1 −2δ
REFERENCES,0.7242206235011991,"α .
(20)"
REFERENCES,0.7266187050359713,"The change for cosine-similarity introduces a factor of exp (1/α) to the mean and exp (2/α) to the variance,
and the overall picture doesn’t change"
REFERENCES,0.7290167865707434,"E
hP
i∈S(−1)δiXcos(δi)
i
= r

¯pe2 + ¯qe−2β 
e
1/α −e
−1/αα
(21)"
REFERENCES,0.7314148681055156,"Var
hP"
REFERENCES,0.7338129496402878,"i∈S(−1)δiXcos(δi)
i
= r

¯pe2 + ¯qe−2β
−

¯pe + ¯qe−12β 
e
2/α + e
−2/αα
.
(22)"
REFERENCES,0.7362110311750599,"For squared Euclidean distance attention (which coincides with the ‘Laplace attention’ L1 norm in this
encoding), if we encode the inputs as (1, 0) we get fL2(δ) = −(
√"
REFERENCES,0.7386091127098321,"δ)2 = −δ, introducing a factor of
exp (−α) to the mean and exp (−2α) to the variance, which also doesn’t change the overall picture."
REFERENCES,0.7410071942446043,Under review as a conference paper at ICLR 2022
REFERENCES,0.7434052757793765,"D
TOP-K FEATURE SELECTION"
REFERENCES,0.7458033573141487,Top-k feature selection masks out all but the k highest scoring features. That is x ←m ⊙x with mi =
REFERENCES,0.7482014388489209,"(
1
if rank(s)i ≤k
0
otherwise
(23)"
REFERENCES,0.750599520383693,"As compared to soft feature selection which rescales as x ←s ⊙x, or x ←s′ ⊙x with normalised s′."
REFERENCES,0.7529976019184652,"1
2
3
4
5
6
7
8
9
10"
REFERENCES,0.7553956834532374,"1
2
3
4
5
6
7
8
9 10
Inactive components, β"
REFERENCES,0.7577937649880095,"0.61
0.78
0.88
0.93
0.95
0.96
0.97
0.98
0.98
0.99"
REFERENCES,0.7601918465227818,"0.56
0.63
0.70
0.76
0.81
0.85
0.88
0.90
0.91
0.93"
REFERENCES,0.762589928057554,"0.54
0.57
0.62
0.66
0.69
0.72
0.76
0.78
0.80
0.82"
REFERENCES,0.7649880095923262,"0.53
0.56
0.58
0.61
0.64
0.65
0.68
0.69
0.71
0.73"
REFERENCES,0.7673860911270983,"0.52
0.54
0.57
0.59
0.60
0.62
0.64
0.65
0.66
0.68"
REFERENCES,0.7697841726618705,"0.51
0.53
0.55
0.57
0.58
0.59
0.61
0.62
0.63
0.64"
REFERENCES,0.7721822541966427,"0.51
0.53
0.54
0.56
0.56
0.57
0.58
0.59
0.60
0.61"
REFERENCES,0.7745803357314148,"0.50
0.52
0.53
0.55
0.55
0.56
0.57
0.58
0.58
0.59"
REFERENCES,0.7769784172661871,"0.51
0.52
0.53
0.54
0.54
0.55
0.56
0.56
0.57
0.58"
REFERENCES,0.7793764988009593,"0.51
0.51
0.52
0.53
0.54
0.54
0.55
0.56
0.56
0.56
Directly on inputs"
REFERENCES,0.7817745803357314,"1
2
3
4
5
6
7
8
9
10"
REFERENCES,0.7841726618705036,"1
2
3
4
5
6
7
8
9 10"
REFERENCES,0.7865707434052758,"0.89
0.96
1.00
1.00
1.00
1.00
1.00
1.00
1.00
1.00"
REFERENCES,0.7889688249400479,"0.80
0.98
1.00
1.00
1.00
1.00
1.00
1.00
1.00
1.00"
REFERENCES,0.7913669064748201,"0.73
0.96
1.00
1.00
1.00
1.00
1.00
1.00
1.00
1.00"
REFERENCES,0.7937649880095923,"0.67
0.90
0.99
1.00
1.00
1.00
1.00
1.00
1.00
1.00"
REFERENCES,0.7961630695443646,"0.63
0.80
0.93
0.98
1.00
1.00
1.00
1.00
1.00
1.00"
REFERENCES,0.7985611510791367,"0.59
0.70
0.83
0.93
0.98
0.99
1.00
1.00
1.00
1.00"
REFERENCES,0.8009592326139089,"0.56
0.64
0.74
0.82
0.91
0.95
0.98
0.99
1.00
1.00"
REFERENCES,0.8033573141486811,"0.53
0.61
0.67
0.74
0.81
0.87
0.91
0.95
0.97
0.98"
REFERENCES,0.8057553956834532,"0.54
0.59
0.63
0.66
0.72
0.76
0.81
0.85
0.88
0.92"
REFERENCES,0.8081534772182254,"0.53
0.57
0.60
0.63
0.66
0.69
0.72
0.76
0.79
0.82
with soft feature selection"
REFERENCES,0.8105515587529976,"1
2
3
4
5
6
7
8
9
10
Variant examples, r"
REFERENCES,0.8129496402877698,"1
2
3
4
5
6
7
8
9 10
Inactive components, β"
REFERENCES,0.815347721822542,"0.89
0.96
1.00
1.00
1.00
1.00
1.00
1.00
1.00
1.00"
REFERENCES,0.8177458033573142,"0.81
0.98
1.00
1.00
1.00
1.00
1.00
1.00
1.00
1.00"
REFERENCES,0.8201438848920863,"0.74
0.96
1.00
1.00
1.00
1.00
1.00
1.00
1.00
1.00"
REFERENCES,0.8225419664268585,"0.70
0.92
0.99
1.00
1.00
1.00
1.00
1.00
1.00
1.00"
REFERENCES,0.8249400479616307,"0.67
0.87
0.95
0.99
1.00
1.00
1.00
1.00
1.00
1.00"
REFERENCES,0.8273381294964028,"0.63
0.80
0.92
0.97
1.00
1.00
1.00
1.00
1.00
1.00"
REFERENCES,0.829736211031175,"0.60
0.78
0.86
0.93
0.96
0.99
0.99
1.00
1.00
1.00"
REFERENCES,0.8321342925659473,"0.59
0.73
0.85
0.89
0.93
0.97
0.99
0.99
0.99
1.00"
REFERENCES,0.8345323741007195,"0.57
0.71
0.81
0.86
0.91
0.93
0.96
0.97
0.99
0.99"
REFERENCES,0.8369304556354916,"0.60
0.67
0.76
0.82
0.90
0.89
0.93
0.94
0.96
0.97
with top-k selection (k = 4)"
REFERENCES,0.8393285371702638,"1
2
3
4
5
6
7
8
9
10
Variant examples, r"
REFERENCES,0.841726618705036,"1
2
3
4
5
6
7
8
9 10"
REFERENCES,0.8441247002398081,"-0.00 -0.00 0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00"
REFERENCES,0.8465227817745803,"0.00 -0.01 -0.00 0.00
0.00
0.00
0.00
0.00
0.00
0.00"
REFERENCES,0.8489208633093526,"0.01 -0.00 -0.00 0.00
0.00
0.00
0.00
0.00
0.00
0.00"
REFERENCES,0.8513189448441247,"0.03
0.02
0.01
0.00
0.00
0.00
0.00
0.00
0.00
0.00"
REFERENCES,0.8537170263788969,"0.03
0.07
0.01
0.01
0.00
0.00
0.00
0.00
0.00
0.00"
REFERENCES,0.8561151079136691,"0.04
0.10
0.08
0.03
0.02
0.00
0.00
0.00
0.00
0.00"
REFERENCES,0.8585131894484412,"0.05
0.14
0.12
0.10
0.05
0.03
0.01
0.01
0.00
0.00"
REFERENCES,0.8609112709832134,"0.06
0.12
0.19
0.15
0.12
0.11
0.08
0.05
0.02
0.02"
REFERENCES,0.8633093525179856,"0.03
0.12
0.18
0.20
0.19
0.17
0.15
0.12
0.10
0.07"
REFERENCES,0.8657074340527577,"0.07
0.10
0.16
0.19
0.24
0.20
0.21
0.18
0.17
0.15
∆(top-k, soft-feature) 0.5 0.6 0.7 0.8 0.9 1.0 0.5 0.6 0.7 0.8 0.9 1.0 0.5 0.6 0.7 0.8 0.9 1.0 0.00 0.05 0.10 0.15 0.20"
REFERENCES,0.86810551558753,"Figure 8: Comparing soft and top-k feature selection in the same setting as Figure 5: classiﬁcation
of XOR4 over variant frequency, r, and number of inactive components β. Examples of a variant
satisfy the XOR in the same way, i.e. the active components are equal, but may not have the same
inactive components. The top-k version uses a binary mask to leave the k highest scoring features
unchanged and zeroing the rest. This produces signiﬁcant improvements over even the soft feature
selection method at high values of β, but requires knowledge of the number of active elements."
REFERENCES,0.8705035971223022,Under review as a conference paper at ICLR 2022
REFERENCES,0.8729016786570744,"E
CONVERGENCE OF FEATURE VECTORS ACROSS SELF-ATTENTION ITERATIONS"
REFERENCES,0.8752997601918465,"Figure 9 illustrates how feature vectors converge on the XOR2 task across self-attention iterations of the
feature selection mechanism. r = 0"
REFERENCES,0.8776978417266187,"[0.78, 0.80, 0.87] r = 1"
REFERENCES,0.8800959232613909,"[0.81, 0.83, 0.67] r = 2"
REFERENCES,0.882494004796163,"[0.89, 0.88, 0.49] r = 3"
REFERENCES,0.8848920863309353,"[0.99, 0.94, 0.31] r = 4"
REFERENCES,0.8872901678657075,"[1.06, 0.97, 0.23]"
REFERENCES,0.8896882494004796,"Figure 9: Feature vectors converging under iterated self-attention on a XOR2 classiﬁcation of vectors
uniformly sampled over the sphere, in 3D (top) and down the z-axis (bottom). Colours indicate classes.
The vectors quickly align by xy-quadrant and the variation in z is ‘washed-out,’ also seen in the feature
selection scores (mean-absolute-deviation) [x, y, z]."
REFERENCES,0.8920863309352518,Under review as a conference paper at ICLR 2022
REFERENCES,0.894484412470024,"F
EXPERIMENTAL DETAILS"
REFERENCES,0.8968824940047961,We use the same feature extractor architecture and train loop for all the baselines.
REFERENCES,0.8992805755395683,"Feature extractor. We leverage a convolutional neural network with 4 blocks as a feature extractor. Each
block consists of a convolutional layer (64 output channels and 3 × 3 ﬁlters), followed by batch normalisation
(momentum 0.01), a ReLU activation, and 2 × 2 max pooling:"
REFERENCES,0.9016786570743405,"Conv2d(64, 3 × 3) →BN →ReLU →MaxPool(2 × 2)"
REFERENCES,0.9040767386091128,"Then, we ﬂatten the output and apply a linear layer to map the data into a 64-dimensional embedding
space (unless otherwise stated). As explained in the main manuscript, each method then manipulates these
embeddings in different way."
REFERENCES,0.9064748201438849,"Train loop. We train all models in an episodic manner. At each training iteration, we follow these steps:"
REFERENCES,0.9088729016786571,"• First, we sample task-speciﬁc support and query sets. For polythetic MNIST, the support set has
96 samples (2 classes, 2 groups per class, and 24 group-speciﬁc examples per group). The query
set consists of 32 samples (2 classes, 2 groups per class, and 8 group-speciﬁc examples per group).
For Omniglot, the support set consists of 5 examples for 20 classes (20-way, 5 shot). The query set
consists of 15 examples per class.
• Second, we compute embeddings using the feature extractor and produce class probabilities for
the query points. The way in which these probabilities are computed depends on the method (e.g.
attentional classiﬁcation for matching networks or softmax over prototype distances for prototypical
networks).
• Finally, we compute the cross entropy for the query examples and optimise the feature extractor via
gradient descent. We employ an Adam optimise with learning rate 0.001."
REFERENCES,0.9112709832134293,"We train the models for 10,000 iterations (i.e. tasks) for all experiments, except for full polythetic MNIST
(100,000 tasks). We then compute the performances on a held-out dataset and average the results across 1,000
tasks."
REFERENCES,0.9136690647482014,"G
MULTI-CATEGORICAL PRE-TRAINING"
REFERENCES,0.9160671462829736,"In this experiment we ﬁrst train a classiﬁer in the multi-categorical setting for the full polythetic MNIST
task. In this case there are no task-irrelevant digits or colours as the label describes all four digits with
their colours: there are four 10-way labels for the digits (∈R4×10) and four 3-way labels for the colours
(∈R4×3) for a combined multi-hot output vector ∈R52. The model architectures match that used in the
other experiments, see Appendix F, other than using a variation of the MLP head that takes the ﬂattened
output from the convolutional network. The variation has two hidden layers with 512 units each and ReLU
activations, before linear layers with softmaxes for each of the label heads. The model is pre-trained over 800
batches of 16 examples drawn at random from the label combinations. In the multi-categorical pre-training,
the model achieved a validation accuracy of 95.6% on the digit labels and 100% on the colour labels over
1600 validation examples."
REFERENCES,0.9184652278177458,"The pre-trained model was then used with prototypical and attentional classiﬁers in the polythetic MNIST
few-shot classiﬁcation setting discussed in Section 5 and detailed further in Appendix F. We compared
performance using the multi-headed softmax activations the model was pre-trained with and an elementwise
sigmoid for both the monothetic and polythetic settings. The results are presented in Table 7, and conform
to the trend we see in other experiments: threshold classiﬁcation has the advantage in monothetic tasks but
perform no better than chance for polythetic tasks. Attentional classiﬁers are weaker in the monothetic setting,
but more than make up for this defeict in the polythetic setting."
REFERENCES,0.920863309352518,Under review as a conference paper at ICLR 2022
REFERENCES,0.9232613908872902,Table 7: Polythetic MNIST problem with multicategorical pre-training. Mean over 1000 tasks.
REFERENCES,0.9256594724220624,"Softmax
Sigmoid"
REFERENCES,0.9280575539568345,"Model
Monothetic
Polythetic
Monothetic
Polythetic"
REFERENCES,0.9304556354916067,"Proto.
97.95
50.18
94.64
50.21
Attn.
93.48
93.40
88.16
86.24"
REFERENCES,0.9328537170263789,"H
AN ILLUSTRATIVE EXAMPLE OF THE METHOD"
REFERENCES,0.935251798561151,"Figure 10 provides a more comprehensive overview of the proposed method. In this example, we are interested
in distinguishing between big-cats and equids (horses, donkeys, and in the case zebra). We ﬁrst extract
features from all samples in the support and query sets. Here, we imagine these features as corresponding
to some general ‘cat’ properties, patterns (such as stripes, dots etc.) and general ‘equid’ properties. Next
(as presented in lines 2 : 4 in Algorithm 1), we perform repeated self-attention with respect to the separate
classes of the support set, which yields updated features for each support sample."
REFERENCES,0.9376498800959233,"We then aggregate the resulting support features with an appropriate dispersion metric, e.g. mean absolute
deviation or standard deviation, (line 5 in Algorithm 1) to obtain a vector of feature scores. These scores
quantify the relevance of each feature in a given task. Next, we rescale both the query and (initial) support
features, i.e. multiplying by the feature scores, to dilute the task-irrelevant and (potentially) misleading
features. In this particular example, this would correspond to diluting the ‘patterns’ feature, since it is
irrelevant when distinguishing between cats and equids. Finally, we produce class probabilities via an
attentional classiﬁer."
REFERENCES,0.9400479616306955,"Figure 10: Diagram of the proposed approach. Note how the misleading features of stripes and spots,
which may cause misclassiﬁcation, are diluted through the feature selection process."
REFERENCES,0.9424460431654677,Under review as a conference paper at ICLR 2022
REFERENCES,0.9448441247002398,"I
CONSTRUCTION OF BINARY STRINGS TASKS"
REFERENCES,0.947242206235012,"For binary strings tasks, we construct training tasks by sampling |S| = 5·2α support examples and |Q| = 5·2α
query examples. Each example consists of α + β bits. The location of the α active bits is completely random
and consistent between the support and query sets within the same task. The labels are computed as the XOR
over the α active components. The remaining β noisy components are randomly sampled from a Bernoulli
distribution with protability 0.5. Figure 11 shows an example of a binary strings task with α = 2 active
components, β = 3 noisy bits, and r = 1 repetitions."
REFERENCES,0.9496402877697842,"Support set
−−−+ −→−
+ −−−+ →+
+ + + −−→+
−+ + −+ →−"
REFERENCES,0.9520383693045563,"Query set
+ + −−−→−
−+ −+ + →+
−+ + + −→+
−−+ + + →−"
REFERENCES,0.9544364508393285,"Figure 11: Example of an XORα task with α = 2 active components (3rd and 5th bits), β = 3 noisy
bits, and r = 1 repetitions for each combination of active components. The support and query sets
contain r2α examples each."
REFERENCES,0.9568345323741008,"J
CONSTRUCTION OF POLYTHETIC MNIST TASKS"
REFERENCES,0.9592326139088729,"For polythetic MNIST tasks, the support set consists of 96 samples, with 48 samples for class 0 and 48
samples for class 1. Each class is further divided into 2 groups of 24 samples and each group is deﬁned by a
speciﬁc set of traits. The groups are complementary between classes, e.g. red ones and blue zeros for class 0;
and blue ones and red zeros for class 1. The set of traits is sampled randomly for each task. The query set is
sampled in the same manner, with 2 groups per class and 8 samples per group. Tables 8 and 9 summarise the
details of the support and query sets and Figures 13, 14, and 15 show the whole support set for the clean,
colourless, and full versions of polythetic MNIST."
REFERENCES,0.9616306954436451,"Class: 0
Class: 0
Class: 0
Class: 0
Class: 0
Class: 0
Class: 1
Class: 1
Class: 1
Class: 1
Class: 1
Class: 1"
REFERENCES,0.9640287769784173,"Class: 1
Class: 1
Class: 1
Class: 1
Class: 1
Class: 1
Class: 0
Class: 0
Class: 0
Class: 0
Class: 0
Class: 0"
REFERENCES,0.9664268585131894,"Figure 12: Example of an MNIST polythetic task. Examples from class 0 have either digit 1 (in any
colour) in the bottom-left corner with a red digit in the bottom-right corner (top row); or digit 6 in the
bottom-left corner with a green digit in the bottom-right (bottom row). Examples from class 1 can
have either digit 1 in the bottom-left with a green digit in the bottom-right (top row); or digit 6 in the
bottom-left with a red digit in the bottom-right corner (bottom row)."
REFERENCES,0.9688249400479616,Under review as a conference paper at ICLR 2022
REFERENCES,0.9712230215827338,Figure 13: Example of the support set for a polythetic MNIST task (clean).
REFERENCES,0.973621103117506,Under review as a conference paper at ICLR 2022
REFERENCES,0.9760191846522782,Figure 14: Example of the support set for a polythetic MNIST task (colourless).
REFERENCES,0.9784172661870504,Under review as a conference paper at ICLR 2022
REFERENCES,0.9808153477218226,Figure 15: Example of the support set for a polythetic MNIST task (full).
REFERENCES,0.9832134292565947,Under review as a conference paper at ICLR 2022
REFERENCES,0.9856115107913669,"|S| = 96
Examples
Groups
Examples per group
Example of groups"
REFERENCES,0.988009592326139,"Class 0
48
2
24
green ones and blue threes
Class 1
48
2
24
blue ones and green threes"
REFERENCES,0.9904076738609112,Table 8: Support set details
REFERENCES,0.9928057553956835,"|Q| = 32
Examples
Groups
Examples per group
Example of groups"
REFERENCES,0.9952038369304557,"Class 0
16
2
8
green ones and blue threes
Class 1
16
2
8
blue ones and green threes"
REFERENCES,0.9976019184652278,Table 9: Query set details
