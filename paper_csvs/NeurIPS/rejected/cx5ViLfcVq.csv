Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.001557632398753894,"This paper uses information-theoretic tools to analyze the generalization error in
1"
ABSTRACT,0.003115264797507788,"unsupervised domain adaptation (UDA). This study presents novel upper bounds
2"
ABSTRACT,0.004672897196261682,"for two notions of generalization errors. The first notion measures the gap between
3"
ABSTRACT,0.006230529595015576,"the population risk in the target domain and that in the source domain, and the
4"
ABSTRACT,0.00778816199376947,"second measures the gap between the population risk in the target domain and the
5"
ABSTRACT,0.009345794392523364,"empirical risk in the source domain. While our bounds for the first kind of error
6"
ABSTRACT,0.010903426791277258,"are in line with the traditional analysis and give similar insights, our bounds on
7"
ABSTRACT,0.012461059190031152,"the second kind of error are algorithm-dependent and also inspire insights into
8"
ABSTRACT,0.014018691588785047,"algorithm designs. Specifically, we present two simple techniques for improving
9"
ABSTRACT,0.01557632398753894,"generalization in UDA and validate them experimentally.
10"
INTRODUCTION,0.017133956386292833,"1
Introduction
11"
INTRODUCTION,0.018691588785046728,"This paper focuses on the unsupervised domain adaptation (UDA) task, where the learner is confronted
12"
INTRODUCTION,0.020249221183800622,"with a source domain and a target domain and the algorithm is allowed to access to a labeled training
13"
INTRODUCTION,0.021806853582554516,"sample from the source domain and an unlabeled training sample from the target domain. The goal is
14"
INTRODUCTION,0.02336448598130841,"to find a predictor that performs well on the target domain.
15"
INTRODUCTION,0.024922118380062305,"A main obstacle in such a task is the discrepancy between the two domains. Some recent works have
16"
INTRODUCTION,0.0264797507788162,"[1–9] proposed various measures to quantify such discrepancy, either for the UDA setting or for the
17"
INTRODUCTION,0.028037383177570093,"more general domain generalization tasks, and many learning algorithms are proposed. For example,
18"
INTRODUCTION,0.029595015576323987,"most recently, Nguyen et al. [9] uses a (reverse) KL divergence to measure the misalignment of
19"
INTRODUCTION,0.03115264797507788,"the distributions of the two domains, and motivated by their generalization bound, they design an
20"
INTRODUCTION,0.03271028037383177,"algorithm that penalizes the KL divergence between the marginal distributions of two domains in the
21"
INTRODUCTION,0.03426791277258567,"representation space. Despite that this “KL guided domain adaptation” algorithm is demonstrated
22"
INTRODUCTION,0.03582554517133956,"to outperform many existing marginal alignment algorithms [10, 11, 6, 12], it is not clear whether
23"
INTRODUCTION,0.037383177570093455,"KL-based alignment of marginal distributions is adequate for UDA, and more fundamentally what
24"
INTRODUCTION,0.03894080996884735,"role the unlabelled target-domain training sample should play to achieve cross-domain generalization.
25"
INTRODUCTION,0.040498442367601244,"Notably, most UDA algorithms are heuristically designed and intuitively justified and most existing
26"
INTRODUCTION,0.04205607476635514,"generalization bounds are algorithm-independent. Then there appears significant room for both
27"
INTRODUCTION,0.04361370716510903,"deeper theoretical understanding and more principled algorithm design.
28"
INTRODUCTION,0.045171339563862926,"In this paper, we analyze the generalization ability of hypotheses and algorithms for UDA tasks using
29"
INTRODUCTION,0.04672897196261682,"an information-theoretic framework developed in [13, 14]. The foundation of our bounding technique
30"
INTRODUCTION,0.048286604361370715,"is the Donsker-Varadhan representation of KL divergence (see Lemma A.1) with the application of
31"
INTRODUCTION,0.04984423676012461,"sub-gaussianity (see Assumption 2). We present novel upper bounds for two notions of generalization
32"
INTRODUCTION,0.0514018691588785,"errors. The first notion (“PP generalization error”) measures the gap between the population risk
33"
INTRODUCTION,0.0529595015576324,"in the target domain and that in the source domain for a hypothesis, and the second (“expected EP
34"
INTRODUCTION,0.05451713395638629,"generalization error”) measures the gap between the population risk in the target domain and the
35"
INTRODUCTION,0.056074766355140186,"empirical risk in the source domain for a learning algorithm. The specific contributions of this work
36"
INTRODUCTION,0.05763239875389408,"are as follows. We show that the PP generalization error for all hypotheses are uniformly bounded
37"
INTRODUCTION,0.059190031152647975,"by a quantity governed by the KL divergence between the two domain distributions, which, under
38"
INTRODUCTION,0.06074766355140187,"bounded losses, recovers the the bound in [9]. We then show that such this KL term upper-bounds
39"
INTRODUCTION,0.06230529595015576,"some other measures including Total-Variation distance [1], Wasserstein distance [6] and domain
40"
INTRODUCTION,0.06386292834890965,"disagreement [7]. Thus, minimizing KL-divergence forces the minimization of other discrepancy
41"
INTRODUCTION,0.06542056074766354,"measures as well. This, together with the ease of minimizing KL [9], explains the effectiveness
42"
INTRODUCTION,0.06697819314641744,"of the KL-guided alignment approach. For expected EP generalization error, we develop several
43"
INTRODUCTION,0.06853582554517133,"algorithm-dependent generalization bounds. These algorithm-dependent bounds further inspire the
44"
INTRODUCTION,0.07009345794392523,"design of two new and yet simple strategies that can further boost the performance of the KL guided
45"
INTRODUCTION,0.07165109034267912,"marginal alignment algorithms. Experiments are performed on standard benchmarks to verify the
46"
INTRODUCTION,0.07320872274143302,"effectiveness of these strategies.
47"
RELATED WORK,0.07476635514018691,"2
Related Work
48"
RELATED WORK,0.0763239875389408,"Domain Adaptation
From a theoretical perspective, many domain adaptation generalization bounds
49"
RELATED WORK,0.0778816199376947,"have been developed [1, 2, 15, 3, 6, 5, 7, 8], and some discrepancy measures are designed to derive
50"
RELATED WORK,0.0794392523364486,"these bounds including the reduction of the total variation [1, 2, 15, 3], Wasserstein distance [6],
51"
RELATED WORK,0.08099688473520249,"domain disagreement [7] and so on. In particular, bounds based on H∆H in [2] are restricted to
52"
RELATED WORK,0.08255451713395638,"a binary classification setting and assume a deterministic labeling function. Furthermore, [2] also
53"
RELATED WORK,0.08411214953271028,"assumes the loss is the L1 distance between the predicted label and true label (which is bounded).
54"
RELATED WORK,0.08566978193146417,"Our bounds work for the general supervised learning problems with any labelling mechanism (e.g.,
55"
RELATED WORK,0.08722741433021806,"stochastic labelling), and we do not require the specific choice of the loss (which could be unbounded).
56"
RELATED WORK,0.08878504672897196,"[16] proposed some generalization bounds based on Jensen-Shannon (JS) divergence, which are
57"
RELATED WORK,0.09034267912772585,"related to our Corollary 4.2. Most existing works including [2, 16] that give upper bounds for Err,
58"
RELATED WORK,0.09190031152647975,"while we give upper bounds for its absolute value, |Err|, which also serves as a lower bound for
59"
RELATED WORK,0.09345794392523364,"generalization, highlighting some fundamental difficulty of the UDA learning task (see Corollary 4.1).
60"
RELATED WORK,0.09501557632398754,"For more details about the domain adaptation theory, we refer readers to [17] for a completed
61"
RELATED WORK,0.09657320872274143,"survey. From the algorithmic perspective of the domain adaptation, the most common method is to
62"
RELATED WORK,0.09813084112149532,"align the marginal distribution of representation between the source domain and the target domain,
63"
RELATED WORK,0.09968847352024922,"including using the adversarial training mechanism [10, 6, 8] and aligning the first two moments of
64"
RELATED WORK,0.10124610591900311,"the representation distribution [11]. There are numerous other domain adaptation algorithms, and we
65"
RELATED WORK,0.102803738317757,"refer readers to [18–21] for recent advances.
66"
RELATED WORK,0.1043613707165109,"Information-Theoretic Generalization Bounds
Information-theoretic analysis are usually used
67"
RELATED WORK,0.1059190031152648,"to analyze the expected generalization error of supervised learning, where the training and testing
68"
RELATED WORK,0.10747663551401869,"data come from the same distribution [13, 22, 14, 23–27]. By exploiting the chain rule property of
69"
RELATED WORK,0.10903426791277258,"mutual information, these bounds are successfully applied to characterize the generalization ability of
70"
RELATED WORK,0.11059190031152648,"stochastic gradient based optimization algorithms [28, 24, 26, 29–31]. Recently, this framework has
71"
RELATED WORK,0.11214953271028037,"also been used in the multi task setting including meta-learning [32–35], semi-supervised learning
72"
RELATED WORK,0.11370716510903427,"[36, 37] and some other transfer learning problems [38, 32, 39–41]. In particular, [38, 39] consider a
73"
RELATED WORK,0.11526479750778816,"different transfer learning problem setup with ours. Specifically, their expected generalization error is
74"
RELATED WORK,0.11682242990654206,"the gap between the target population risk and the empirical weighted risk (or the convex combination
75"
RELATED WORK,0.11838006230529595,"of the source empirical risk and the target empirical risk), while our “EP” error is the gap between
76"
RELATED WORK,0.11993769470404984,"the target population risk and the source empirical risk. That is to say, our work studies how to make
77"
RELATED WORK,0.12149532710280374,"use of the unlabelled target data to improve the generalization performance on target domain except
78"
RELATED WORK,0.12305295950155763,"for minimizing the empirical risk of source domain, and their works assume the training objective
79"
RELATED WORK,0.12461059190031153,"function for the target domain data, which could be labelled, has already been known. In addition,
80"
RELATED WORK,0.1261682242990654,"bounds in [38, 39] fail to characterize the dependence between W and S′
X′. More precisely, the
81"
RELATED WORK,0.1277258566978193,"algorithm-dependent term in their bounds is I(W; Zi) or I(W; S), while our algorithm-dependent
82"
RELATED WORK,0.1292834890965732,"term is IX′
j(W; Zi) that directly depends on the unlabelled target data (see Theorem C.1 for more
83"
RELATED WORK,0.1308411214953271,"discussion in Appendix).
84"
PRELIMINARY,0.13239875389408098,"3
Preliminary
85"
PRELIMINARY,0.13395638629283488,"Unless otherwise noted, a random variable will be denoted by a capitalized letter, and its realization
86"
PRELIMINARY,0.13551401869158877,"denoted by the corresponding lower-case letter. Consider a prediction task with instance space
87"
PRELIMINARY,0.13707165109034267,"Z = X × Y, where X and Y are the input space and the label (or output) space respectively. Let F
88"
PRELIMINARY,0.13862928348909656,"be the hypothesis space of interesting, in which each f ∈F is a function or predictor mapping X to
89"
PRELIMINARY,0.14018691588785046,"Y. We assume that each hypothesis f ∈F is parameterized by some weight parameter w in some
90"
PRELIMINARY,0.14174454828660435,"space W and may write f as fw as needed.
91"
PRELIMINARY,0.14330218068535824,"Let µ and µ′ be two distributions on Z, unknown to the learner. Normally, µ and µ′ are not the
92"
PRELIMINARY,0.14485981308411214,"same and we consider µ characterizing the source domain and µ′ characterizing the target domain.
93"
PRELIMINARY,0.14641744548286603,"For the ease of notation, we may also write µ as PZ or PXY and µ′ as PZ′ or PX′Y ′, which also
94"
PRELIMINARY,0.14797507788161993,"defines random variables Z = (X, Y ) and Z′ = (X′, Y ′). Let S = {Zi}n
i=1 ∼µ⊗n be a labeled
95"
PRELIMINARY,0.14953271028037382,"source-domain training sample and S′
X′ = {X′
j}m
j=1 ∼P ⊗m
X′
be an unlabelled target-domain training
96"
PRELIMINARY,0.15109034267912771,"sample. The objective of UDA is to design an algorithm A takes S and S′
X′ as the input and outputs
97"
PRELIMINARY,0.1526479750778816,"a weight W ∈W, giving rise to a predictor fW ∈F that “works well” on the target domain. Note
98"
PRELIMINARY,0.1542056074766355,"that the algorithm A is in general characterized by a conditional distribution PW |S,S′
X′.
99"
PRELIMINARY,0.1557632398753894,"To be precise on the performance metric of UDA, let ℓ: Y × Y →R+
0 be a loss function. Then for
100"
PRELIMINARY,0.1573208722741433,"each weight configuration w ∈W, its population risk in the target domain is defined as
101"
PRELIMINARY,0.1588785046728972,"Rµ′(w) ≜EZ′[ℓ(fw(X′), Y ′)]."
PRELIMINARY,0.16043613707165108,"and a good UDA algorithm hopes to return a weight w that minimizes this risk. Since µ′ is unknown,
102"
PRELIMINARY,0.16199376947040497,"this risk can not be measured or minimized. On the other hand, one does have access to the empirical
103"
PRELIMINARY,0.16355140186915887,"risk in the source domain, as is defined by
104"
PRELIMINARY,0.16510903426791276,"RS(w) ≜1 n n
X"
PRELIMINARY,0.16666666666666666,"i=1
ℓ(fw(Xi), Yi)."
PRELIMINARY,0.16822429906542055,"Then the notion generalization error in this setting measures how well the hypothesis returned from
105"
PRELIMINARY,0.16978193146417445,"the algorithm generalize from the source-domain training sample to the target-domain unknown
106"
PRELIMINARY,0.17133956386292834,"distribution µ′. Taking into account the stochastic nature of the algorithm A, a natural notion of
107"
PRELIMINARY,0.17289719626168223,"generalization error for UDA can be defined by
108"
PRELIMINARY,0.17445482866043613,"Err ≜EW,S [Rµ′(W) −RS(W)] = EW,S,S′
X′ [Rµ′(W) −RS(W)],
(1)"
PRELIMINARY,0.17601246105919002,"where the expectation in the first equation is taken over the joint distribution of (W, S) ∼PW |S×µ⊗n,
109"
PRELIMINARY,0.17757009345794392,"and the expectation of the second equation is taken over the joint distribution of (W, S, S′
X′) ∼
110"
PRELIMINARY,0.1791277258566978,"PW |S,S′
X′ × µ⊗n × P ⊗m
X′ .
111"
PRELIMINARY,0.1806853582554517,"Note that there is another notion of generalization error, more traditional in the domain adaptation
112"
PRELIMINARY,0.1822429906542056,"literature, namely, the gap between the population risk in the target domain and that in the source
113"
PRELIMINARY,0.1838006230529595,"domain, as us define by
114"
PRELIMINARY,0.1853582554517134,"g
Err(w) ≜Rµ′(w) −Rµ(w).
(2)"
PRELIMINARY,0.18691588785046728,"where Rµ(w) ≜EZ[ℓ(fw(X), Y )]. It is apparent that g
Err(w) and Err are related by the following
115"
PRELIMINARY,0.18847352024922118,"triangle inequality:
116"
PRELIMINARY,0.19003115264797507,|Rµ′(w) −RS(w)| ≤|Rµ′(w) −Rµ(w)| + |Rµ(w) −RS(w)|.
PRELIMINARY,0.19158878504672897,"where the second term on the right hand side is the standard generalization error in the source domain,
117"
PRELIMINARY,0.19314641744548286,"which can be bounded by classical learning-theoretic tools, e.g., Rademacher complexity [42]. Thus
118"
PRELIMINARY,0.19470404984423675,"bounding g
Err(w) helps bounding Err.
119"
PRELIMINARY,0.19626168224299065,"This paper studies both notions of generalization error for UDA. Specifically, starting from Section 5,
120"
PRELIMINARY,0.19781931464174454,"we will mainly use information-theoretic tools to bound Err directly, without going through g
Err(w).
121"
PRELIMINARY,0.19937694704049844,"For the ease of reference, we refer to g
Err(w) as the population-to-population (PP) generalization
122"
PRELIMINARY,0.20093457943925233,"error for w and Err as the expected empirical-to-population (EP) generalization error for the
123"
PRELIMINARY,0.20249221183800623,"algorithm A.
124"
PRELIMINARY,0.20404984423676012,"Some definitions are prerequisite in this paper, we now present some uncommon notions and defer
125"
PRELIMINARY,0.205607476635514,"the common notions to Appendix.
126"
PRELIMINARY,0.2071651090342679,"Definition 1 (Disintegrated Mutual Information). Let X, Y and Z be random variables and z be
127"
PRELIMINARY,0.2087227414330218,"a realization of Z. The disintegrated mutual information of X and Y given Z = z is Iz(X; Y ) ≜
128"
PRELIMINARY,0.2102803738317757,"DKL(PX,Y |Z=z||PX|Z=zPY |Z=z).
129"
PRELIMINARY,0.2118380062305296,"Note that the conditional mutual information I(X; Y |Z) = EZIZ(X; Y ).
130"
PRELIMINARY,0.21339563862928349,"Definition 2 (Lautum Information [43]). Define the lautum information between X and Y as
131"
PRELIMINARY,0.21495327102803738,"L(X; Y ) ≜DKL(PXPY ||PXY ).
132"
UPPER BOUNDS FOR PP GENERALIZATION ERROR,0.21651090342679127,"4
Upper Bounds for PP Generalization Error
133"
UPPER BOUNDS FOR PP GENERALIZATION ERROR,0.21806853582554517,"In this section, we present some upper bounds for g
Err(w). The key techniques used in developing
134"
UPPER BOUNDS FOR PP GENERALIZATION ERROR,0.21962616822429906,"these bounds are the information-theoretic tools in the style of Lemma A.1. All these bounds adopt
135"
UPPER BOUNDS FOR PP GENERALIZATION ERROR,0.22118380062305296,"certain KL divergence as a key quantity measuring the discrepancy between the source and target
136"
UPPER BOUNDS FOR PP GENERALIZATION ERROR,0.22274143302180685,"domain. Notably, some previously established bounds are recovered under a different assumption of
137"
UPPER BOUNDS FOR PP GENERALIZATION ERROR,0.22429906542056074,"the loss function. Additionally we demonstrate that under certain conditions, the KL-based bound is
138"
UPPER BOUNDS FOR PP GENERALIZATION ERROR,0.22585669781931464,"an upper bound of many other discrepancy measures and hence minimizing the KL divergence forces
139"
UPPER BOUNDS FOR PP GENERALIZATION ERROR,0.22741433021806853,"the minimization of these other measures.
140"
UPPER BOUNDS FOR PP GENERALIZATION ERROR,0.22897196261682243,"We first list some common assumptions on the loss function, which we consider in this paper.
141"
UPPER BOUNDS FOR PP GENERALIZATION ERROR,0.23052959501557632,"Assumption 1 (Boundedness). ℓ(·, ·) is bounded in [0, M].
142"
UPPER BOUNDS FOR PP GENERALIZATION ERROR,0.23208722741433022,"Assumption 2 (Subgaussianity). ℓ(fw(X), Y ) is R-subgaussian1 under µ for any w ∈W.
143"
UPPER BOUNDS FOR PP GENERALIZATION ERROR,0.2336448598130841,"Remark 4.1. Note that Assumption 1 implies Assumption 2, i.e., if ℓ(fw(X), Y ) is bounded in [0, M],
144"
UPPER BOUNDS FOR PP GENERALIZATION ERROR,0.235202492211838,"then it is also M/2-subgaussian. Thus, Assumption 2 is weaker than Assumption 1.
145"
UPPER BOUNDS FOR PP GENERALIZATION ERROR,0.2367601246105919,"Assumption 3 (Lipschitzness). ℓ(fw(X), Y ) is β-Lipschitz continues in Z for any w ∈W, i.e.,
146"
UPPER BOUNDS FOR PP GENERALIZATION ERROR,0.2383177570093458,"|ℓ(fw(x1), y1) −ℓ(fw(x2), y2)| ≤βd(z1, z2).
147"
UPPER BOUNDS FOR PP GENERALIZATION ERROR,0.2398753894080997,"Remark 4.2. Note that Assumption 1 implies Assumption 3 when d is a discrete metric, i.e., if
148"
UPPER BOUNDS FOR PP GENERALIZATION ERROR,0.24143302180685358,"ℓ(fw(X), Y ) is bounded in [0, M], then it is also M-Lipschitz under the discrete metric.
149"
UPPER BOUNDS FOR PP GENERALIZATION ERROR,0.24299065420560748,"Assumption 4 (Triangle). ℓ(·, ·) satisfies the following the triangle inequality: ℓ(y1, y2) ≤ℓ(y1, y3)+
150"
UPPER BOUNDS FOR PP GENERALIZATION ERROR,0.24454828660436137,"ℓ(y3, y2) for any y1, y2, y3 ∈Y.
151"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.24610591900311526,"4.1
Generalization Bounds via the Subgaussian Condition
152"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.24766355140186916,"The following generalization bound is established by combining Lemma A.1 and Assumption 2, a
153"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.24922118380062305,"technique developed in [14] for information-theoretic analysis of generalization.
154"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.2507788161993769,"Theorem 4.1. If Assumption 2 holds, then for any w ∈W,
g
Err(w)
 ≤
p"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.2523364485981308,"2R2DKL(µ′||µ).
155"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.2538940809968847,"We note that this result on one hand can be turned into a generalization upper bound providing
156"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.2554517133956386,"guidance to algorithm design, and on the other hand provides a lower bound of the generalization
157"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.2570093457943925,"error, which highlights some fundamental difficulty of the learning task. To illustrate this, we present
158"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.2585669781931464,"an corollary of Theorem 4.1, while noting that similar development can also be applied to other
159"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.2601246105919003,"bounds presented later in this paper.
160"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.2616822429906542,"To that end, suppose that each fw in the model family is expressed as the composition g ◦h, where h
161"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.2632398753894081,"is a function mapping X to a representation space T and g is a function mapping T to Y. For any
162"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.26479750778816197,"given h : X →T , denote by µh the distribution on T × Y obtained by pushing over µ via h, that is,
163"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.26635514018691586,"µh(t, y) =
R
δ(t −h(x))dµ(x, y), where δ is the Dirac measure on T . Similarly, let µ′
h denote the
164"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.26791277258566976,"distribution on T × Y obtained by pushing over µ′ via h.
165"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.26947040498442365,"Corollary 4.1. Suppose that fw = g ◦h and that Assumption 2 holds. then for any w ∈W,
166"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.27102803738317754,"Rµ(w) −
p"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.27258566978193144,"2R2DKL(µ′||µ) ≤Rµ′(w) ≤Rµ(w) +
q"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.27414330218068533,"2R2DKL(µ′
h||µh)."
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.2757009345794392,"In this result, the lower bound of Rµ′(w) indicates a fundamental difficulty in UDA learning in that,
167"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.2772585669781931,"using the same predictor mapping fw, there is no way for the population risk in the target domain to
168"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.278816199376947,"be lower than that of the source domain less a constant which depends only on the domain difference.
169"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.2803738317757009,"On the other hand, the upper bound suggests that it is possible to squeeze the gap between the two
170"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.2819314641744548,"population risks by choosing an appropriate representation map h - evidently such a map should be
171"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.2834890965732087,"attempting to align µ′
h with µh or to align their respective proxies.
172"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.2850467289719626,"It is also remarkable that under Assumption 1 and due to Remark 4.1, Theorem 4.1 implies
173"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.2866043613707165,"g
Err(w)
 ≤M
√ 2 q"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.2881619937694704,"DKL(PX′||PX) + DKL(PY ′|X′||PY |X).
(3)"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.2897196261682243,"Similarly applying this result in the representation space T , we see that Eq. (3) recovers the bound in
174"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.29127725856697817,"Proposition 1 of [9]. Notice that unlike [9], Theorem 4.1 ( or Eq. (3)) does not require the loss to be
175"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.29283489096573206,"the cross entropy loss.
176"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.29439252336448596,"1A random variable X is R-subgaussian if for any ρ, log E exp (ρ (X −EX)) ≤ρ2R2/2."
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.29595015576323985,"Theorem 4.1 and [9] both use the KL divergence from source domain to target domain, DKL(µ′||µ),
177"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.29750778816199375,"and in fact,
g
Err(w)
 can also be upper bounded by DKL(µ||µ′). This can be done by invoking the
178"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.29906542056074764,"subgaussianality of ℓ(fw(X′), Y ′) (rather than ℓ(fw(X), Y )); for bounded loss, the subgaussianality
179"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.30062305295950154,"of ℓ(fw(X′), Y ′) is also satisfied. Then we obtain the following corollary.
180"
GENERALIZATION BOUNDS VIA THE SUBGAUSSIAN CONDITION,0.30218068535825543,"Corollary 4.2. If Assumption 1 holds,
g
Err(w)
 ≤
M
√"
P,0.3037383177570093,"2
p"
P,0.3052959501557632,"min{DKL(µ||µ′), DKL(µ′||µ)} ≤
181 M"
P,0.3068535825545171,"2
p"
P,0.308411214953271,"DKL(µ||µ′) + DKL(µ′||µ).
182"
P,0.3099688473520249,"Remark 4.3. In the second inequality of Corollary 4.2, DKL(µ||µ′) + DKL(µ′||µ) is usually called
183"
P,0.3115264797507788,"the symmetrized KL divergence (or Jeffrey’s divergence [44]), and the regularization term used in
184"
P,0.3130841121495327,"[9] is indeed the symmetrized KL divergence between the distributions of the source and target
185"
P,0.3146417445482866,"representations. Notice that bounds in [16] are based on the JS divergence. Since there is a sharp
186"
P,0.3161993769470405,"upper bound of the JS divergence based on Jeffrey’s divergence [45], minimizing Jeffrey’s divergence
187"
P,0.3177570093457944,"(in the representation space) will simultaneously penalize the JS divergence.
188"
P,0.31931464174454827,"In UDA, since Y ′ is completely unavailable to the algorithm A, it is impossible to minimize the
189"
P,0.32087227414330216,"misalignment of conditional distributions, i.e. DKL(PY ′|T ′||PY |T ), without any additional infor-
190"
P,0.32242990654205606,"mation. A common method is to assign pseudo labels to target data. However, it may also cause
191"
P,0.32398753894080995,"some additional issues. For concreteness, suppose the trained model Q can well approximate the
192"
P,0.32554517133956384,"real mapping between X and Y on source domain (i.e. QY |T = PY |T ), which is usually the training
193"
P,0.32710280373831774,"objective. Let ˆY ′ be the pseudo label of T ′ generated by the trained model, i.e., Q ˆ
Y ′|T ′ = QY |T . Let
194"
P,0.32866043613707163,"QT ′, ˆ
Y ′ = PT ′Q ˆ
Y ′|T ′, then the following holds,
195"
P,0.3302180685358255,"DKL(PT ′,Y ′||PT,Y ) = EPT ′,Y ′ log
PT ′,Y ′QT ′, ˆ
Y ′
QT ′, ˆ
Y ′PT,Y
= DKL(PT ′||PT ) + DKL(PY ′|T ′||Q ˆ
Y ′|T ′). (4)"
P,0.3317757009345794,"For a specific t′, if P(Y ′ = y′|T ′ = t′) ̸= 0 and P( ˆY ′ = y′|T ′ = t′) = 0, then the second term
196"
P,0.3333333333333333,"in RHS of Eq. (4), DKL(PY ′|T ′||Q ˆ
Y ′|T ′) →∞. In this case, even the marginal distributions are
197"
P,0.3348909657320872,"perfectly aligned, the overall value of the upper bound is large. Thus, incorrect pseudo labels may
198"
P,0.3364485981308411,"even have negative impact on the target domain performance, and we hope two supports, Supp(PY ′)
199"
P,0.338006230529595,"and Supp(P ˆ
Y ′), could largely overlap with each other for every target data.
200"
P,0.3395638629283489,"Indeed, the misalignment of the conditional distributions appears to be the main difficulty of UDA
201"
P,0.3411214953271028,"[1, 8]. The next corollary suggests that this difficulty may be alleviated when the loss function satisfies
202"
P,0.3426791277258567,"the triangle property, namely, Assumption 4. It can be verified that this assumption is satisfied by the
203"
P,0.3442367601246106,"0-1 loss and square error loss; this assumption has also been considered in previous works [3, 6].
204"
P,0.34579439252336447,"Theorem 4.2. If Assumption 4 holds and let ℓ(fw′(X), fw(X)) be R-subgaussian for any w, w′ ∈W.
205"
P,0.34735202492211836,"Then for any w, g
Err(w) ≤
p"
P,0.34890965732087226,"2R2DKL(PX′||PX) + λ∗, where λ∗= minw∈W Rµ′(w) + Rµ(w).
206"
P,0.35046728971962615,"In this theorem, λ∗measures the possibility of whether the domain adaptation algorithm will succeed
207"
P,0.35202492211838005,"under the oracle knowledge of µ and µ′. In particular, if the hypothesis space is large enough,
208"
P,0.35358255451713394,"the minimizer w∗for the “joint population risk” Rµ′(w) + Rµ(w) may give rise to Rµ′(w∗) =
209"
P,0.35514018691588783,"Rµ(w∗) = 0. then we’re likely to generalize well on the target domain. Then the KL divergence
210"
P,0.35669781931464173,"DKL(PX′||PX) between the two X-marginals alone bounds the PP generalization error uniformly
211"
P,0.3582554517133956,"for all w ∈W.
212"
P,0.3598130841121495,"This theorem motivates the strategy of penalizing DKL(PT ′||PT ) in the representation space to
213"
P,0.3613707165109034,"achieve better a generalization error. The next theorem suggests that such an approach also penalizes
214"
P,0.3629283489096573,"other notions of domain discrepancy, for example, domain disagreement defined in [7, Definition 1.]
215"
P,0.3644859813084112,"and serving as a key quantity in the PAC-Bayes type of domain adaptation generalization bounds [7]:
216"
P,0.3660436137071651,"dis(PX, PX′) ≜|EW,W ′,X′ [ℓ(fW (X′), fW ′(X′))] −EW,W ′,X [ℓ(fW (X), fW ′(X))]| .
(5)
Theorem 4.3. If ℓ(fw′(X), fw(X)) is R-subgaussian for any w, w′ ∈H, then dis(PX, PX′) ≤
217
p"
P,0.367601246105919,"2R2DKL(PX′||PX).
218"
P,0.3691588785046729,"Note that unlike [7], here we do not require the loss function to be the 0-1 loss.
219"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.3707165109034268,"4.2
Generalization Bounds via the Lipschitz Condition
220"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.37227414330218067,"Wasserstein distance based generalization bound are often directly connected to, or even included
221"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.37383177570093457,"in, the information-theoretic bounds [46, 27]. We now present such a bound for UDA under the
222"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.37538940809968846,"Lipschitz continuity assumption of the loss function.
223"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.37694704049844235,"Theorem 4.4. If Assumption 3 holds, then
g
Err(w)
 ≤βW(µ′, µ).
224"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.37850467289719625,"Note that Theorem 4.4 can be related to the KL divergence based bounds in the previous section
225"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.38006230529595014,"when the Wasserstein distance is defined with respect to the discrete metric d. In this case, if the loss
226"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.38161993769470404,"function is bounded, it is also Liptschitz continuous, and hence Theorem 4.4 applies. On the other
227"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.38317757009345793,"hand, Wasserstein distance is equivalent to the total variation distance [1, 2, 15, 3], while the latter is
228"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.3847352024922118,"connected to the KL divergence via Pinsker’s inequality [47, Theorem 6.5] and the Bretagnolle-Huber
229"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.3862928348909657,"inequality [48, Lemma 2.1]. Thus we arrive at the following result.
230"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.3878504672897196,"Corollary 4.3. If Assumption 1 holds holds and let d be the discrete metric, then
231"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.3894080996884735,"g
Err(w)
 ≤MTV(µ′, µ) ≤M s"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.3909657320872274,"min
1"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.3925233644859813,"2DKL(µ′||µ), 1 −e−DKL(µ′||µ)

."
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.3940809968847352,"The bound in Corollary 4.3 can be immediately verified to be tighter than the bound in Eq. (3).
232"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.3956386292834891,"Parallel to Theorem 4.2, if the loss function satisfies the triangle property, we may establish another
233"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.397196261682243,"bound below, which recovers a similar result in [6, Theorem 1.].
234"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.3987538940809969,"Theorem 4.5. If Assumption 4 holds and ℓ(fw(X), fw′(X)) is β-Lipschitz in X for any w, w′ ∈W,
235"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.40031152647975077,"then for any w ∈W, g
Err(w) ≤LW(PX′, PX) + λ∗, where λ∗= minw∈W Rµ′(w) + Rµ(w).
236"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.40186915887850466,"Unlike the bound in [6], we do not require the classification tasks to be binary in Theorem 4.5, and
237"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.40342679127725856,"the loss does not need to be the L1 distance.
238"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.40498442367601245,"This section may convey the following message. Since the KL divergence based bounds upper-
239"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.40654205607476634,"bounds those based on other measures of domain differences, (e.g. total variation distance, domain
240"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.40809968847352024,"discrepancy etc), if we penalize the KL divergence, we will also penalize those other measures. This is
241"
GENERALIZATION BOUNDS VIA THE LIPSCHITZ CONDITION,0.40965732087227413,"practically advantageous since it is usually easier and more stable to minimize the KL divergence[9].
242"
UPPER BOUNDS FOR EXPECTED EP GENERALIZATION ERROR AND APPLICATIONS,0.411214953271028,"5
Upper Bounds for Expected EP Generalization Error and Applications
243"
UPPER BOUNDS FOR EXPECTED EP GENERALIZATION ERROR AND APPLICATIONS,0.4127725856697819,"There are two limitations in the bounds on the PP generalization error developed in the previous
244"
UPPER BOUNDS FOR EXPECTED EP GENERALIZATION ERROR AND APPLICATIONS,0.4143302180685358,"section and in the traditional analysis of domain adaptation. First, such bounds are independent of w
245"
UPPER BOUNDS FOR EXPECTED EP GENERALIZATION ERROR AND APPLICATIONS,0.4158878504672897,"and hence algorithm-independent. Second, although these bounds may inspire strategies to exploit the
246"
UPPER BOUNDS FOR EXPECTED EP GENERALIZATION ERROR AND APPLICATIONS,0.4174454828660436,"unlabelled target sample, e.g., aligning its marginal distribution with that of the source sample in the
247"
UPPER BOUNDS FOR EXPECTED EP GENERALIZATION ERROR AND APPLICATIONS,0.4190031152647975,"representation space, they only provide very limited knowledge on the role that the unlabelled target
248"
UPPER BOUNDS FOR EXPECTED EP GENERALIZATION ERROR AND APPLICATIONS,0.4205607476635514,"sample plays in the algorithm. We now derive upper bounds for the EP generalization error, which
249"
UPPER BOUNDS FOR EXPECTED EP GENERALIZATION ERROR AND APPLICATIONS,0.4221183800623053,"better utilize the dependence of the algorithm output on the unlabelled target data. Applications of
250"
UPPER BOUNDS FOR EXPECTED EP GENERALIZATION ERROR AND APPLICATIONS,0.4236760124610592,"these bounds in designing the learning algorithms are also presented.
251"
BOUNDS,0.4252336448598131,"5.1
Bounds
252"
BOUNDS,0.42679127725856697,"Theorem 5.1. Assume ℓ(fw(X′), Y ′) is R-subgaussian under µ′ for any w ∈W. Then
253"
BOUNDS,0.42834890965732086,"|Err| ≤
1
nm m
X j=1 n
X"
BOUNDS,0.42990654205607476,"i=1
EX′
j q"
BOUNDS,0.43146417445482865,"2R2IX′
j(W; Zi) +
p"
BOUNDS,0.43302180685358255,2R2DKL(µ||µ′). 254
BOUNDS,0.43457943925233644,"Remark 5.1. Note that the unlabelled target data plays a role in the first term of the bound. Indeed,
255"
BOUNDS,0.43613707165109034,"more source and target data will reduce the first term of the bound. Specifically, moving the
256"
BOUNDS,0.43769470404984423,"expectation inside the square root function by Jensen’s inequality and since Zi ⊥⊥X′
j, the equations
257"
BOUNDS,0.4392523364485981,"I(W; Zi|X′
j) = I(W; Zi|X′
j) + I(Zi; X′
j) = I(W; Zi) + I(X′
j; Zi|W) hold by the chain rule. The
258"
BOUNDS,0.440809968847352,"term I(W; Zi) will vanish as n →∞and the term I(X′
j; Zi|W) will also vanish as n, m →∞.
259"
BOUNDS,0.4423676012461059,"It is also worth mentioning that, from a practical perspective, the number of samples may have
260"
BOUNDS,0.4439252336448598,"different impact on the different algorithms. For example, the second term (KL divergence) in
261"
BOUNDS,0.4454828660436137,"our Theorem 5.1 can not be computed in the original space and we can only estimate it in the
262"
BOUNDS,0.4470404984423676,"representation space. On the one hand, it seems that having more data will make the approximation
263"
BOUNDS,0.4485981308411215,"(of KL between marginal distributions) more accurate. While on the other hand, some domain
264"
BOUNDS,0.4501557632398754,"adaptation algorithms involve the pseudo labelling process, and assigning incorrect pseudo labels to
265"
BOUNDS,0.4517133956386293,"the target data may even have negative impact on the target domain performance (as discussed in
266"
BOUNDS,0.4532710280373832,"Section 4). In this case, having more target data will not improve the performance.
267"
BOUNDS,0.45482866043613707,"Corollary 5.1. Let Assumption 1 hold. Then
268"
BOUNDS,0.45638629283489096,"|Err| ≤
M
√"
NM,0.45794392523364486,"2nm m
X j=1 n
X"
NM,0.45950155763239875,"i=1
EX′
j r"
NM,0.46105919003115264,"min
n
IX′
j(W; Zi), LX′
j(W; Zi)
o
+ M
√ 2 p"
NM,0.46261682242990654,"min {DKL(µ||µ′), DKL(µ′||µ)}."
NM,0.46417445482866043,"where LX′
j(·; ·) is the disintegrated version of Lautum information.
269"
NM,0.4657320872274143,"Theorem 5.2. Assume ℓis Lipschitz for both w ∈W and z ∈Z, i.e., |ℓ(fw(x), y)−ℓ(fw(x′), y′)| ≤
270"
NM,0.4672897196261682,"βd1(z, z′) for all z, z′ ∈Z and |ℓ(fw(x), y) −ℓ(fw′(x), y)| ≤β′d2(w, w′) for all w, w′ ∈W, then
271"
NM,0.4688473520249221,"|Err| ≤β′ nm m
X j=1 n
X"
NM,0.470404984423676,"i=1
EX′
j,ZiW(PW |Zi,X′
j, PW |X′
j) + βW(µ, µ′)."
NM,0.4719626168224299,"This bound is tighter than the bound in Theorem 5.1, as can be indicated by the following corollary.
272"
NM,0.4735202492211838,"Corollary 5.2. Let Assumption 1 hold. Then
273"
NM,0.4750778816199377,"g
Err
 ≤M nm m
X j=1 n
X"
NM,0.4766355140186916,"i=1
EX′
j,Zi
h
TV(PW |Zi,X′
j, PW |X′
j)
i
+ MTV(µ, µ′)"
NM,0.4781931464174455,"≤
1
nm m
X j=1 n
X"
NM,0.4797507788161994,"i=1
EX′
j,Zi r M 2"
NM,0.48130841121495327,"2 DKL(PW |Zi,X′
j||PW |X′
j) + r M 2"
NM,0.48286604361370716,2 DKL(µ||µ′).
NM,0.48442367601246106,"Notice that to recover Theorem 5.1 from Corollary 5.2, we can use Jensen’s inequality to move the
274"
NM,0.48598130841121495,"expectation over Zi inside the convex square root function.
275"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.48753894080996885,"5.2
Gradient Penalty as an Universal Regularizer
276"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.48909657320872274,"The algorithm-dependent bound in Theorem 5.1 tells us that one can reduce the expected generaliza-
277"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.49065420560747663,"tion error by limiting the disintegrated mutual information IX′
j(W; Zi). In the stochastic gradient
278"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.49221183800623053,"based optimization algorithms, this term can be controlled by penalizing the gradient. To see this, we
279"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.4937694704049844,"now consider a “noisy” iterative algorithm for updating W, e.g., SGLD. At each time step t, let the
280"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.4953271028037383,"labelled mini-batch from the source domain be ZBt, let the unlabelled mini-batch from the target
281"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.4968847352024922,"domain be X′
Bt, and let g(Wt−1, ZBt, X′
Bt) be the gradient at time t. Thus, the updating rule of W
282"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.4984423676012461,"is Wt = Wt−1 −ηtg(Wt−1, ZBt, X′
Bt) + Nt where ηt is the learning rate and Nt ∼N(0, σ2Id) is
283"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5,"an isotropic Gaussian noise. The next theorem is an application of Theorem 5.1 in this setting.
284"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5015576323987538,"Theorem 5.3. Let the total iteration number be T and let Gt = g(Wt−1, ZBt, X′
Bt), then
285"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5031152647975078,|Err| ≤
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5046728971962616,"v
u
u
tR2 n T
X t=1"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5062305295950156,"η2
t
σ2
t
ES′
X′,Wt−1,S
h
||Gt||2i
+
p"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5077881619937694,2R2DKL(µ||µ′).
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5093457943925234,"Remark 5.2. Considering a noisy iterative algorithm here is to simplify analysis. In fact it is also
286"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5109034267912772,"possible to analyze the original iterative gradient optimization method without noise injected. For
287"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5124610591900312,"example, one can follow the same development in [30, 31] to analyze vanilla SGD. In that case, there
288"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.514018691588785,"will be some additional terms in the bound, which are related to flatness of the found minima.
289"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5155763239875389,"Theorem 5.3 hints that to reduce the generalization error, one can restrict the gradient norm at each
290"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5171339563862928,"step. This strategy will also restrict the distance between the final output WT and the initialization
291"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5186915887850467,"W0, effectively shrinking the hypothesis space accessible by the algorithm.
292"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5202492211838006,"Indeed, adding gradient penalty can be applied to any existing UDA algorithm and it is simple but
293"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5218068535825545,"effective in practice. Later on we will show that even when the algorithm A does not access to
294"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5233644859813084,"any target data, in which case I(W; Zi|X′
j) reduces to I(W; Zi) and g(Wt−1, ZBt, X′
Bt) becomes
295"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5249221183800623,"g(Wt−1, ZBt), minimizing the empirical loss of source domain sample while penalizing gradient
296"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5264797507788161,"norm will still improve the performance. Notice that gradient penalty is also used in Wasserstein
297"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5280373831775701,"distance based adversarial training [49, 6], and their motivation is to stabilize the training to avoid
298"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5295950155763239,"gradient vanishing problem while here we use it to improve the generalization performance directly.
299"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5311526479750779,"Notably the bound in Theorem 5.3 only depends on the size n of labelled source sample and does
300"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5327102803738317,"not explicitly depend on m, the size of unlabelled target sample. With a more careful design, if we
301"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5342679127725857,"consider the mutual information as the expected KL divergence of a posterior and a prior, based
302"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5358255451713395,"on IX′
j(W; Zi) in Theorem 5.1, it is possible to create a target data dependent prior and derive a
303"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5373831775700935,"tighter bound based on some quantity similar to ""gradient incoherence"" in [24]. As this will introduce
304"
GRADIENT PENALTY AS AN UNIVERSAL REGULARIZER,0.5389408099688473,"additional complexity in practice, we leave this as a future study.
305"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5404984423676013,"5.3
Controlling Label Information for KL Guided Marginal Alignment
306"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5420560747663551,"Consider instances in the representation space, Z = (T, Y ) and Z′ = (T ′, Y ). Theorem 5.1 also
307"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.543613707165109,"encourage us to align the distributions of two domains in the representation space, as argued earlier.
308"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5451713395638629,"Then the KL guided marginal alignment algorithm proposed in [9] can be invoked here. One may
309"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5467289719626168,"notice that Theorem 5.1 uses DKL(µ||µ′) while [9] uses DKL(µ′||µ). As already discussed in
310"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5482866043613707,"Section 4, this inconsistency can be ignored when loss is bounded (see Corollary 5.1).
311"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5498442367601246,"Most domain adaptation algorithms aim to align the marginal distributions of two domains in the
312"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5514018691588785,"representation space. However, without accessing to Y ′, it remains unknown if an UDA algorithm
313"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5529595015576324,"will work well since we cannot guarantee that discrepancy between conditional distribution PY |T
314"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5545171339563862,"and PY ′|T ′ won’t become too large when we align the marginals. In [9], the authors show that
315"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5560747663551402,"DKL(PY ′|T ′||PY |T ) can be upper-bounded by DKL(PY ′|X′||PY |X), if I(X; Y ) = I(T; Y ). The
316"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.557632398753894,"authors then argue that penalizing the KL divergence of the marginals distributions is safe.
317"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.559190031152648,"We now argue that in practice the condition I(X; Y ) = I(T; Y ) can be difficult to satisfy if the
318"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5607476635514018,"cross-entropy loss is used to define the source-domain empirical risk.
319"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5623052959501558,"By data processing inequality on Y −X −T, we know that I(X; Y ) ≥I(T; Y ) = H(Y )−H(Y |T).
320"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5638629283489096,"Thus, to let I(T; Y ) reach its maximum, one must minimize H(Y |T). On the other hand, let QY |T,W
321"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5654205607476636,"be the predictive distribution of labels in the source domain generated by the classifier. The expected
322"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5669781931464174,"cross-entropy loss for each Zi in the representation space is then
323"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5685358255451713,"EW,Zi [ℓ(fW (Ti), Yi)] = EZi

EW |Zi

−log QYi|Ti,W

,"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5700934579439252,"which also decomposes as [50, 51]
324"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5716510903426791,"EW,Zi [ℓ(fW (Ti), Yi)] = H(Yi|Ti) + ETi,W

DKL(PYi|Ti,W ||QYi|Ti,W )

−I(W; Yi|Ti).
(6)"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.573208722741433,"Then minimizing the expected cross-entropy loss may not adequately reduce H(Yi|Ti) but rather
325"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5747663551401869,"cause I(W; Yi|Ti) to significantly increase, particularly when the model capacity is large. This
326"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5763239875389408,"may have two negative effects. First, the condition I(X; Y ) = I(T; Y ) is significantly violated,
327"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5778816199376947,"and DKL(PY ′|T ′||PY |T ) is no longer upper bounded by DKL(PY ′|X′||PY |X). As a consequence,
328"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5794392523364486,"aligning the two marginals alone may not be adequate. Second, large I(W; Yi|Ti) indicates W
329"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5809968847352025,"just simply memorizes the label Yi, resulting a form of overfitting and hurting the generalization
330"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5825545171339563,"performance.
331"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5841121495327103,"The key take-away from the above analysis is that when aligning the marginals in UDA, controlling the
332"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5856697819314641,"source label information in the weights can be important to achieve good cross-domain generalization.
333"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5872274143302181,"A similar message can also be deduced from Theorem 5.1, when it is viewed in the repsentation space
334"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5887850467289719,"and noting IT ′
j(W; Zi) = IT ′
j(W; Ti, ) + IT ′
j(W; Yi|Ti).
335"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5903426791277259,"To control label information, [51] proposed an approach called LIMIT. However this method is rather
336"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5919003115264797,"complicated and arguably hard to train in domain adaptation (see Appendix). We now derive a simple
337"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5934579439252337,"alternative strategy for this purpose.
338"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5950155763239875,"Notice that IT ′
j(W; Yi|Ti) ≤infQ ETi

DKL(P(W|Yi, Ti, T ′
j = t′
j)||Q(W|Ti, T ′
j = t′
j))

, which is
339"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5965732087227414,"a simple extension of variational representation of mutual information [47, Corollary 3.1.]. Here
340"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5981308411214953,"Q could be any distribution. By assuming P = N(W, σ2Id|Yi, Ti, T ′
j = t′
j) and taking Q =
341"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.5996884735202492,"N(f
W, ˜σ2Id|Ti, T ′
j = t′
j), we have
342"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.6012461059190031,"IT ′
j(W; Yi|Ti) ≤inf
Q ETi
h
DKL(P(W|Yi, Ti, T ′
j = t′
j)||Q( ˜W|Ti, T ′
j = t′
j))
i
∝||W −f
W||2."
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.602803738317757,"Thus, we may create an auxiliary classifier f e
w that is not allowed to access to the real source label
343"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.6043613707165109,"Y . In each iteration, we use the pseudo labels of target data (and source data) assigned by fw to
344"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.6059190031152648,"train f e
w and adding ||W −f
W||2 as a regularizer in the training of W. The algorithm is given in
345"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.6074766355140186,"the Appendix. Remarkably the regularizer here resembles “Projection Norm” designed in [52] for
346"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.6090342679127726,"out-of-distribution generalization.
347"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.6105919003115264,Table 1: RotatedMNIST and Digits Experiments. Results of baseline methods are reported from [9].
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.6121495327102804,"RotatedMNIST (0◦as source domain)
Digits"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.6137071651090342,"Method
15◦
30◦
45◦
60◦
75◦
Ave
M →U
U →M
S →M
Ave"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.6152647975077882,"ERM
97.5±0.2
84.1±0.8
53.9±0.7
34.2±0.4
22.3±0.5
58.4
73.1±4.2
54.8±6.2
65.9±1.4
64.6
DANN
97.3±0.4
90.6±1.1
68.7±4.2
30.8±0.6
19.0±0.6
61.3
90.7±0.4
91.2±0.8
71.1±0.5
84.3
MMD
97.5±0.1
95.3±0.4
73.6±2.1
44.2±1.8
32.1±2.1
68.6
91.8±0.3
94.4±0.5
82.8±0.3
89.7
CORAL
97.1±0.3
82.3±0.3
56.0±2.4
30.8±0.2
27.1±1.7
58.7
88.0±1.9
83.3±0.1
69.3±0.6
80.2
WD
96.7±0.3
93.1±1.2
64.1±3.3
41.4±7.6
27.6±2.0
64.6
88.2±0.6
60.2±1.8
68.4±2.5
72.3
KL
97.8±0.1
97.1±0.2
93.4±0.8
75.5±2.4
68.1±1.8
86.4
98.2±0.2
97.3±0.5
92.5±0.9
96.0"
CONTROLLING LABEL INFORMATION FOR KL GUIDED MARGINAL ALIGNMENT,0.616822429906542,"ERM-GP
97.5±0.1
86.2±0.5
62.0±1.9
34.8±2.1
26.1±1.2
61.2
91.3±1.6
72.7±4.2
68.4±0.2
77.5
KL-GP
98.2±0.2
96.9±0.1
95.0±0.6
88.0±8.1
78.1±2.5
91.2
98.8±0.1
97.8±0.1
93.8±1.1
96.8
KL-CL
98.4±0.2
97.3±0.2
95.6±0.1
83.0±8.2
73.6±4.0
89.6
98.9±0.1
97.7±0.1
93.0±0.3
96.5"
EXPERIMENTAL RESULTS,0.618380062305296,"6
Experimental Results
348"
EXPERIMENTAL RESULTS,0.6199376947040498,"We now perform experiments to verify the proposed techniques inspired by our theory in the previous
349"
EXPERIMENTAL RESULTS,0.6214953271028038,"section. The experimental setup follows that in [9].
350"
EXPERIMENTAL RESULTS,0.6230529595015576,"Datasets
We select two popular small datasets, RotatedMNIST and Digits, to compare the different
351"
EXPERIMENTAL RESULTS,0.6246105919003115,"methods. In particular, RotatedMNIST is built based on the MNIST dataset [53] and consists of six
352"
EXPERIMENTAL RESULTS,0.6261682242990654,"domains with each domain containing 11, 666 images. These six domains are rotated MNIST images
353"
EXPERIMENTAL RESULTS,0.6277258566978193,"with rotation angle 0◦, 15◦, 30◦, 45◦, 60◦and 75◦, respectively. We will take the original MNIST
354"
EXPERIMENTAL RESULTS,0.6292834890965732,"dataset (0◦) as the source domain and take other five domains as target domains. Hence there are five
355"
EXPERIMENTAL RESULTS,0.6308411214953271,"domain adaptation tasks on RotatedMNIST. Digits consists of three sub-datasets, namely MNIST,
356"
EXPERIMENTAL RESULTS,0.632398753894081,"USPS [54] and SVHN [55], and the corresponding domain adaptation tasks are MNIST→USPS
357"
EXPERIMENTAL RESULTS,0.6339563862928349,"(M→U), USPS→MNIST (U→M), SVHN→MNIST (S→M).
358"
EXPERIMENTAL RESULTS,0.6355140186915887,"Compared Methods
Baseline methods are some popular marginal alignment UDA methods
359"
EXPERIMENTAL RESULTS,0.6370716510903427,"including DANN [10], MMD [12], CORAL [11], WD [6] and KL [9]. We also choose ERM for
360"
EXPERIMENTAL RESULTS,0.6386292834890965,"another baseline in which the algorithm can only access to the source domain sample during training.
361"
EXPERIMENTAL RESULTS,0.6401869158878505,"To verify the strategies inspired by our theory, we first add the gradient penalty to the ERM algorithm
362"
EXPERIMENTAL RESULTS,0.6417445482866043,"(ERM-GP), and we then combine gradient penalty (GP) and controlling label information (CL)
363"
EXPERIMENTAL RESULTS,0.6433021806853583,"with the recent proposed KL guided marginal alignment method, which are denoted by KL-GP and
364"
EXPERIMENTAL RESULTS,0.6448598130841121,"KL-CL, respectively.
365"
EXPERIMENTAL RESULTS,0.6464174454828661,"Implementation Details
Most part of the implementation is based on the famous DomainBed
366"
EXPERIMENTAL RESULTS,0.6479750778816199,"suite [56]. Other settings are exactly the same with [9] and the results of baseline methods are
367"
EXPERIMENTAL RESULTS,0.6495327102803738,"reported directly from [9]. Specifically, each algorithm is run three times and we show the average
368"
EXPERIMENTAL RESULTS,0.6510903426791277,"performance with the error bar. Every dataset has a validation set, and the model selection scheme is
369"
EXPERIMENTAL RESULTS,0.6526479750778816,"based on the best performance achieved on the validation set of target domain during training (oracle).
370"
EXPERIMENTAL RESULTS,0.6542056074766355,"The hype-parameter searching process is also built upon the implementation in the DomainBed suite.
371"
EXPERIMENTAL RESULTS,0.6557632398753894,"Other details and additional experiments can be found in Appendix.
372"
EXPERIMENTAL RESULTS,0.6573208722741433,"Results
From Table 1, we first notice that gradient penalty is able to help ERM to be more
373"
EXPERIMENTAL RESULTS,0.6588785046728972,"comparable with other marginal alignment methods. For example, on RotatedMNIST, ERM-GP
374"
EXPERIMENTAL RESULTS,0.660436137071651,"outperforms CORAL and performs nearly the same with DANN. On Digits, ERM-GP outperforms
375"
EXPERIMENTAL RESULTS,0.661993769470405,"WD. When GP and CL combined with KL guided algorithm, we can see that the performance can be
376"
EXPERIMENTAL RESULTS,0.6635514018691588,"further boosted. This justifies the discussion in Section 5.2 and Section 5.3.
377"
CONCLUSION,0.6651090342679128,"7
Conclusion
378"
CONCLUSION,0.6666666666666666,"Despite that the numerous learning techniques have been developed for domain adaptation, significant
379"
CONCLUSION,0.6682242990654206,"room exists for more in-depth theoretical understanding and more principled design of learning algo-
380"
CONCLUSION,0.6697819314641744,"rithms. This paper presents the information-theoretic analysis for unsupervised domain adaptation,
381"
CONCLUSION,0.6713395638629284,"where we query two notions of the generalization errors in this context and present novel learning
382"
CONCLUSION,0.6728971962616822,"bounds. Some of these bounds recover the previous KL-based bounds under different conditions and
383"
CONCLUSION,0.6744548286604362,"confirm the insights in the learning algorithms that align the source and target distributions in the
384"
CONCLUSION,0.67601246105919,"representation space. Our other bounds are algorithm-dependent, better exploiting the unlabelled
385"
CONCLUSION,0.677570093457944,"target data, which have inspired novel and yet simple schemes for the design of learning algorithms.
386"
CONCLUSION,0.6791277258566978,"We demonstrate the effectiveness of these schemes on standard benchmark datasets.
387"
REFERENCES,0.6806853582554517,"References
388"
REFERENCES,0.6822429906542056,"[1] Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira. Analysis of representations
389"
REFERENCES,0.6838006230529595,"for domain adaptation. Advances in neural information processing systems, 19, 2006.
390"
REFERENCES,0.6853582554517134,"[2] Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jen-
391"
REFERENCES,0.6869158878504673,"nifer Wortman Vaughan. A theory of learning from different domains. Machine Learning, 79
392"
REFERENCES,0.6884735202492211,"(1-2):151–175, 2010.
393"
REFERENCES,0.6900311526479751,"[3] Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Domain adaptation: Learning
394"
REFERENCES,0.6915887850467289,"bounds and algorithms. In The 22nd Conference on Learning Theory, 2009.
395"
REFERENCES,0.6931464174454829,"[4] Han Zhao, Remi Tachet Des Combes, Kun Zhang, and Geoffrey Gordon. On learning invariant
396"
REFERENCES,0.6947040498442367,"representations for domain adaptation. In International Conference on Machine Learning, pages
397"
REFERENCES,0.6962616822429907,"7523–7532. PMLR, 2019.
398"
REFERENCES,0.6978193146417445,"[5] Yuchen Zhang, Tianle Liu, Mingsheng Long, and Michael Jordan. Bridging theory and algorithm
399"
REFERENCES,0.6993769470404985,"for domain adaptation. In International Conference on Machine Learning, pages 7404–7413.
400"
REFERENCES,0.7009345794392523,"PMLR, 2019.
401"
REFERENCES,0.7024922118380063,"[6] Jian Shen, Yanru Qu, Weinan Zhang, and Yong Yu. Wasserstein distance guided representation
402"
REFERENCES,0.7040498442367601,"learning for domain adaptation. In Thirty-second AAAI conference on artificial intelligence,
403"
REFERENCES,0.705607476635514,"2018.
404"
REFERENCES,0.7071651090342679,"[7] Pascal Germain, Amaury Habrard, François Laviolette, and Emilie Morvant. Pac-bayes and
405"
REFERENCES,0.7087227414330218,"domain adaptation. Neurocomputing, 379:379–397, 2020.
406"
REFERENCES,0.7102803738317757,"[8] David Acuna, Guojun Zhang, Marc T Law, and Sanja Fidler. f-domain adversarial learning:
407"
REFERENCES,0.7118380062305296,"Theory and algorithms. In International Conference on Machine Learning, pages 66–75. PMLR,
408"
REFERENCES,0.7133956386292835,"2021.
409"
REFERENCES,0.7149532710280374,"[9] A. Tuan Nguyen, Toan Tran, Yarin Gal, Philip Torr, and Atilim Gunes Baydin. KL guided
410"
REFERENCES,0.7165109034267912,"domain adaptation. In International Conference on Learning Representations, 2022. URL
411"
REFERENCES,0.7180685358255452,"https://openreview.net/forum?id=0JzqUlIVVDd.
412"
REFERENCES,0.719626168224299,"[10] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, François
413"
REFERENCES,0.721183800623053,"Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural
414"
REFERENCES,0.7227414330218068,"networks. The journal of machine learning research, 17(1):2096–2030, 2016.
415"
REFERENCES,0.7242990654205608,"[11] Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation.
416"
REFERENCES,0.7258566978193146,"In European conference on computer vision, pages 443–450. Springer, 2016.
417"
REFERENCES,0.7274143302180686,"[12] Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C Kot. Domain generalization with
418"
REFERENCES,0.7289719626168224,"adversarial feature learning. In Proceedings of the IEEE conference on computer vision and
419"
REFERENCES,0.7305295950155763,"pattern recognition, pages 5400–5409, 2018.
420"
REFERENCES,0.7320872274143302,"[13] Daniel Russo and James Zou. Controlling bias in adaptive data analysis using information
421"
REFERENCES,0.7336448598130841,"theory. In Artificial Intelligence and Statistics. PMLR, 2016.
422"
REFERENCES,0.735202492211838,"[14] Aolin Xu and Maxim Raginsky. Information-theoretic analysis of generalization capability of
423"
REFERENCES,0.7367601246105919,"learning algorithms. Advances in Neural Information Processing Systems, 2017.
424"
REFERENCES,0.7383177570093458,"[15] Shai Ben David, Tyler Lu, Teresa Luu, and Dávid Pál. Impossibility theorems for domain
425"
REFERENCES,0.7398753894080997,"adaptation. In Proceedings of the Thirteenth International Conference on Artificial Intelligence
426"
REFERENCES,0.7414330218068536,"and Statistics, pages 129–136. JMLR Workshop and Conference Proceedings, 2010.
427"
REFERENCES,0.7429906542056075,"[16] Changjian Shui, Qi Chen, Jun Wen, Fan Zhou, Christian Gagné, and Boyu Wang. Beyond
428"
REFERENCES,0.7445482866043613,"H-divergence: Domain adaptation theory with jensen-shannon divergence. arXiv preprint
429"
REFERENCES,0.7461059190031153,"arXiv:2007.15567, 2020.
430"
REFERENCES,0.7476635514018691,"[17] Ievgen Redko, Emilie Morvant, Amaury Habrard, Marc Sebban, and Younes Bennani. A survey
431"
REFERENCES,0.7492211838006231,"on domain adaptation theory. arXiv preprint arXiv:2004.11829, 2020.
432"
REFERENCES,0.7507788161993769,"[18] Gabriela Csurka. Domain adaptation for visual applications: A comprehensive survey. arXiv
433"
REFERENCES,0.7523364485981309,"preprint arXiv:1702.05374, 2017.
434"
REFERENCES,0.7538940809968847,"[19] Garrett Wilson and Diane J Cook. A survey of unsupervised deep domain adaptation. ACM
435"
REFERENCES,0.7554517133956387,"Transactions on Intelligent Systems and Technology (TIST), 11(5):1–46, 2020.
436"
REFERENCES,0.7570093457943925,"[20] Kaiyang Zhou, Ziwei Liu, Yu Qiao, Tao Xiang, and Chen Change Loy. Domain generalization:
437"
REFERENCES,0.7585669781931464,"A survey. arXiv e-prints, pages arXiv–2103, 2021.
438"
REFERENCES,0.7601246105919003,"[21] Jindong Wang, Cuiling Lan, Chang Liu, Yidong Ouyang, Wenjun Zeng, and Tao Qin. General-
439"
REFERENCES,0.7616822429906542,"izing to unseen domains: A survey on domain generalization. arXiv preprint arXiv:2103.03097,
440"
REFERENCES,0.7632398753894081,"2021.
441"
REFERENCES,0.764797507788162,"[22] Daniel Russo and James Zou. How much does your data exploration overfit? controlling bias
442"
REFERENCES,0.7663551401869159,"via information usage. IEEE Transactions on Information Theory, 66(1):302–323, 2019.
443"
REFERENCES,0.7679127725856698,"[23] Yuheng Bu, Shaofeng Zou, and Venugopal V Veeravalli. Tightening mutual information based
444"
REFERENCES,0.7694704049844237,"bounds on generalization error. In 2019 IEEE International Symposium on Information Theory
445"
REFERENCES,0.7710280373831776,"(ISIT), pages 587–591. IEEE, 2019.
446"
REFERENCES,0.7725856697819314,"[24] Jeffrey Negrea, Mahdi Haghifam, Gintare Karolina Dziugaite, Ashish Khisti, and Daniel M Roy.
447"
REFERENCES,0.7741433021806854,"Information-theoretic generalization bounds for sgld via data-dependent estimates. Advances in
448"
REFERENCES,0.7757009345794392,"Neural Information Processing Systems, 2019.
449"
REFERENCES,0.7772585669781932,"[25] Thomas Steinke and Lydia Zakynthinou. Reasoning about generalization via conditional mutual
450"
REFERENCES,0.778816199376947,"information. In Conference on Learning Theory. PMLR, 2020.
451"
REFERENCES,0.780373831775701,"[26] Mahdi Haghifam, Jeffrey Negrea, Ashish Khisti, Daniel M Roy, and Gintare Karolina Dziugaite.
452"
REFERENCES,0.7819314641744548,"Sharpened generalization bounds based on conditional mutual information and an application
453"
REFERENCES,0.7834890965732088,"to noisy, iterative algorithms. Advances in Neural Information Processing Systems, 2020.
454"
REFERENCES,0.7850467289719626,"[27] Borja Rodríguez Gálvez, Germán Bassi, Ragnar Thobaben, and Mikael Skoglund. Tighter
455"
REFERENCES,0.7866043613707165,"expected generalization error bounds via wasserstein distance. Advances in Neural Information
456"
REFERENCES,0.7881619937694704,"Processing Systems, 34, 2021.
457"
REFERENCES,0.7897196261682243,"[28] Ankit Pensia, Varun Jog, and Po-Ling Loh. Generalization error bounds for noisy, iterative
458"
REFERENCES,0.7912772585669782,"algorithms. In 2018 IEEE International Symposium on Information Theory (ISIT). IEEE, 2018.
459"
REFERENCES,0.7928348909657321,"[29] Hao Wang, Rui Gao, and Flavio P Calmon. Generalization bounds for noisy iterative algorithms
460"
REFERENCES,0.794392523364486,"using properties of additive noise channels. arXiv preprint arXiv:2102.02976, 2021.
461"
REFERENCES,0.7959501557632399,"[30] Gergely Neu, Gintare Karolina Dziugaite, Mahdi Haghifam, and Daniel M Roy. Information-
462"
REFERENCES,0.7975077881619937,"theoretic generalization bounds for stochastic gradient descent. In Conference on Learning
463"
REFERENCES,0.7990654205607477,"Theory. PMLR, 2021.
464"
REFERENCES,0.8006230529595015,"[31] Ziqiao Wang and Yongyi Mao. On the generalization of models trained with SGD: Information-
465"
REFERENCES,0.8021806853582555,"theoretic bounds and implications. In International Conference on Learning Representations,
466"
REFERENCES,0.8037383177570093,"2022. URL https://openreview.net/forum?id=oWZsQ8o5EA.
467"
REFERENCES,0.8052959501557633,"[32] Sharu Theresa Jose and Osvaldo Simeone. Information-theoretic generalization bounds for
468"
REFERENCES,0.8068535825545171,"meta-learning and applications. Entropy, 23(1):126, 2021.
469"
REFERENCES,0.8084112149532711,"[33] Sharu Theresa Jose, Osvaldo Simeone, and Giuseppe Durisi.
Transfer meta-learning:
470"
REFERENCES,0.8099688473520249,"Information-theoretic bounds and information meta-risk minimization. IEEE Transactions on
471"
REFERENCES,0.8115264797507789,"Information Theory, 68(1):474–501, 2021.
472"
REFERENCES,0.8130841121495327,"[34] Arezou Rezazadeh, Sharu Theresa Jose, Giuseppe Durisi, and Osvaldo Simeone. Conditional
473"
REFERENCES,0.8146417445482866,"mutual information-based generalization bound for meta learning. In 2021 IEEE International
474"
REFERENCES,0.8161993769470405,"Symposium on Information Theory (ISIT), pages 1176–1181. IEEE, 2021.
475"
REFERENCES,0.8177570093457944,"[35] Qi Chen, Changjian Shui, and Mario Marchand. Generalization bounds for meta-learning: An
476"
REFERENCES,0.8193146417445483,"information-theoretic analysis. Advances in Neural Information Processing Systems, 34, 2021.
477"
REFERENCES,0.8208722741433022,"[36] Haiyun He, Hanshu Yan, and Vincent YF Tan. Information-theoretic generalization bounds for
478"
REFERENCES,0.822429906542056,"iterative semi-supervised learning. arXiv preprint arXiv:2110.00926, 2021.
479"
REFERENCES,0.82398753894081,"[37] Gholamali Aminian, Mahed Abroshan, Mohammad Mahdi Khalili, Laura Toni, and Miguel
480"
REFERENCES,0.8255451713395638,"Rodrigues. An information-theoretical approach to semi-supervised learning under covariate-
481"
REFERENCES,0.8271028037383178,"shift. In International Conference on Artificial Intelligence and Statistics, pages 7433–7449.
482"
REFERENCES,0.8286604361370716,"PMLR, 2022.
483"
REFERENCES,0.8302180685358256,"[38] Xuetong Wu, Jonathan H Manton, Uwe Aickelin, and Jingge Zhu. Information-theoretic
484"
REFERENCES,0.8317757009345794,"analysis for transfer learning. In 2020 IEEE International Symposium on Information Theory
485"
REFERENCES,0.8333333333333334,"(ISIT), pages 2819–2824. IEEE, 2020.
486"
REFERENCES,0.8348909657320872,"[39] Sharu Theresa Jose and Osvaldo Simeone. Information-theoretic bounds on transfer general-
487"
REFERENCES,0.8364485981308412,"ization gap based on jensen-shannon divergence. In 2021 29th European Signal Processing
488"
REFERENCES,0.838006230529595,"Conference (EUSIPCO), pages 1461–1465. IEEE, 2021.
489"
REFERENCES,0.839563862928349,"[40] Mohammad Saeed Masiha, Amin Gohari, Mohammad Hossein Yassaee, and Mohammad Reza
490"
REFERENCES,0.8411214953271028,"Aref.
Learning under distribution mismatch and model misspecification.
In 2021 IEEE
491"
REFERENCES,0.8426791277258567,"International Symposium on Information Theory (ISIT), pages 2912–2917. IEEE, 2021.
492"
REFERENCES,0.8442367601246106,"[41] Yuheng Bu, Gholamali Aminian, Laura Toni, Gregory W Wornell, and Miguel Rodrigues.
493"
REFERENCES,0.8457943925233645,"Characterizing and understanding the generalization error of transfer learning with gibbs
494"
REFERENCES,0.8473520249221184,"algorithm. In International Conference on Artificial Intelligence and Statistics, pages 8673–
495"
REFERENCES,0.8489096573208723,"8699. PMLR, 2022.
496"
REFERENCES,0.8504672897196262,"[42] Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds
497"
REFERENCES,0.8520249221183801,"and structural results. Journal of Machine Learning Research, 3(Nov):463–482, 2002.
498"
REFERENCES,0.8535825545171339,"[43] Daniel P Palomar and Sergio Verdú. Lautum information. IEEE transactions on information
499"
REFERENCES,0.8551401869158879,"theory, 54(3):964–975, 2008.
500"
REFERENCES,0.8566978193146417,"[44] Harold Jeffreys. An invariant form for the prior probability in estimation problems. Proceedings
501"
REFERENCES,0.8582554517133957,"of the Royal Society of London. Series A. Mathematical and Physical Sciences, 186(1007):
502"
REFERENCES,0.8598130841121495,"453–461, 1946.
503"
REFERENCES,0.8613707165109035,"[45] Gavin E. Crooks. Inequalities between the jenson-shannon and jeffreys divergences. In Tech.
504"
REFERENCES,0.8629283489096573,"Note 004, 2008.
505"
REFERENCES,0.8644859813084113,"[46] Hao Wang, Mario Diaz, José Cândido S Santos Filho, and Flavio P Calmon. An information-
506"
REFERENCES,0.8660436137071651,"theoretic view of generalization via wasserstein distance. In 2019 IEEE International Symposium
507"
REFERENCES,0.867601246105919,"on Information Theory (ISIT), pages 577–581. IEEE, 2019.
508"
REFERENCES,0.8691588785046729,"[47] Yury Polyanskiy and Yihong Wu. Lecture notes on information theory. Lecture Notes for 6.441
509"
REFERENCES,0.8707165109034268,"(MIT), ECE 563 (UIUC), STAT 364 (Yale), 2019., 2019.
510"
REFERENCES,0.8722741433021807,"[48] Jean Bretagnolle and Catherine Huber. Estimation des densités: risque minimax. Zeitschrift für
511"
REFERENCES,0.8738317757009346,"Wahrscheinlichkeitstheorie und verwandte Gebiete, 47(2):119–137, 1979.
512"
REFERENCES,0.8753894080996885,"[49] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville.
513"
REFERENCES,0.8769470404984424,"Improved training of wasserstein gans. Advances in neural information processing systems, 30,
514"
REFERENCES,0.8785046728971962,"2017.
515"
REFERENCES,0.8800623052959502,"[50] Alessandro Achille and Stefano Soatto. Emergence of invariance and disentanglement in deep
516"
REFERENCES,0.881619937694704,"representations. The Journal of Machine Learning Research, 19(1):1947–1980, 2018.
517"
REFERENCES,0.883177570093458,"[51] Hrayr Harutyunyan, Kyle Reing, Greg Ver Steeg, and Aram Galstyan. Improving generalization
518"
REFERENCES,0.8847352024922118,"by controlling label-noise information in neural network weights. In International Conference
519"
REFERENCES,0.8862928348909658,"on Machine Learning, pages 4071–4081. PMLR, 2020.
520"
REFERENCES,0.8878504672897196,"[52] Yaodong Yu, Zitong Yang, Alexander Wei, Yi Ma, and Jacob Steinhardt. Predicting out-of-
521"
REFERENCES,0.8894080996884736,"distribution error with the projection norm. arXiv preprint arXiv:2202.05834, 2022.
522"
REFERENCES,0.8909657320872274,"[53] Yann LeCun, Corinna Cortes, and CJ Burges. Mnist handwritten digit database. ATT Labs
523"
REFERENCES,0.8925233644859814,"[Online]. Available: http://yann.lecun.com/exdb/mnist, 2, 2010.
524"
REFERENCES,0.8940809968847352,"[54] Jonathan J. Hull. A database for handwritten text recognition research. IEEE Transactions on
525"
REFERENCES,0.8956386292834891,"pattern analysis and machine intelligence, 16(5):550–554, 1994.
526"
REFERENCES,0.897196261682243,"[55] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng.
527"
REFERENCES,0.8987538940809969,"Reading digits in natural images with unsupervised feature learning. In NeurIPS Workshop on
528"
REFERENCES,0.9003115264797508,"Deep Learning and Unsupervised Feature Learning, 2011.
529"
REFERENCES,0.9018691588785047,"[56] Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. In International
530"
REFERENCES,0.9034267912772586,"Conference on Learning Representations, 2021. URL https://openreview.net/forum?
531"
REFERENCES,0.9049844236760125,"id=lQdXeXDoWtI.
532"
REFERENCES,0.9065420560747663,"[57] XuanLong Nguyen, Martin J Wainwright, and Michael I Jordan. Estimating divergence func-
533"
REFERENCES,0.9080996884735203,"tionals and the likelihood ratio by convex risk minimization. IEEE Transactions on Information
534"
REFERENCES,0.9096573208722741,"Theory, 56(11):5847–5861, 2010.
535"
REFERENCES,0.9112149532710281,"[58] Jiantao Jiao, Yanjun Han, and Tsachy Weissman. Dependence measures bounding the explo-
536"
REFERENCES,0.9127725856697819,"ration bias for general measurements. In 2017 IEEE International Symposium on Information
537"
REFERENCES,0.9143302180685359,"Theory (ISIT), pages 1475–1479. IEEE, 2017.
538"
REFERENCES,0.9158878504672897,"[59] Rohit Agrawal and Thibaut Horel. Optimal bounds between f-divergences and integral prob-
539"
REFERENCES,0.9174454828660437,"ability metrics. In International Conference on Machine Learning, pages 115–124. PMLR,
540"
REFERENCES,0.9190031152647975,"2020.
541"
REFERENCES,0.9205607476635514,"[60] Villani Cédric. Optimal Transport: Old and New (Grundlehren der mathematischen Wis-
542"
REFERENCES,0.9221183800623053,"senschaften, 338). Springer, 2008.
543"
REFERENCES,0.9236760124610592,"[61] Clément L Canonne.
A short note on an inequality between kl and tv.
arXiv preprint
544"
REFERENCES,0.9252336448598131,"arXiv:2202.07198, 2022.
545"
REFERENCES,0.926791277258567,"[62] Vladimir Vapnik. Statistical learning theory. Wiley, 1998. ISBN 978-0-471-03003-4.
546"
REFERENCES,0.9283489096573209,"[63] Thomas M. Cover and Joy A. Thomas. Elements of Information Theory (Wiley Series in Telecom-
547"
REFERENCES,0.9299065420560748,"munications and Signal Processing). Wiley-Interscience, USA, 2006. ISBN 0471241954.
548"
REFERENCES,0.9314641744548287,"[64] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan,
549"
REFERENCES,0.9330218068535826,"Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative
550"
REFERENCES,0.9345794392523364,"style, high-performance deep learning library. Advances in Neural Information Processing
551"
REFERENCES,0.9361370716510904,"Systems, 32:8026–8037, 2019.
552"
REFERENCES,0.9376947040498442,"[65] Diederik P Kingma and Max Welling.
Auto-encoding variational bayes.
arXiv preprint
553"
REFERENCES,0.9392523364485982,"arXiv:1312.6114, 2013.
554"
REFERENCES,0.940809968847352,"Checklist
555"
REFERENCES,0.942367601246106,"1. For all authors...
556"
REFERENCES,0.9439252336448598,"(a) Do the main claims made in the abstract and introduction accurately reflect the paper’s
557"
REFERENCES,0.9454828660436138,"contributions and scope? [Yes]
558"
REFERENCES,0.9470404984423676,"(b) Did you describe the limitations of your work? [Yes] See Section 7.
559"
REFERENCES,0.9485981308411215,"(c) Did you discuss any potential negative societal impacts of your work? [N/A] This is a
560"
REFERENCES,0.9501557632398754,"theoretical work and we do not see any potential negative societal impacts.
561"
REFERENCES,0.9517133956386293,"(d) Have you read the ethics review guidelines and ensured that your paper conforms to
562"
REFERENCES,0.9532710280373832,"them? [Yes]
563"
REFERENCES,0.9548286604361371,"2. If you are including theoretical results...
564"
REFERENCES,0.956386292834891,"(a) Did you state the full set of assumptions of all theoretical results? [Yes] e.g., see
565"
REFERENCES,0.9579439252336449,"Section 4.
566"
REFERENCES,0.9595015576323987,"(b) Did you include complete proofs of all theoretical results? [Yes] See Appendices.
567"
REFERENCES,0.9610591900311527,"3. If you ran experiments...
568"
REFERENCES,0.9626168224299065,"(a) Did you include the code, data, and instructions needed to reproduce the main experi-
569"
REFERENCES,0.9641744548286605,"mental results (either in the supplemental material or as a URL)? [Yes] See Section 6
570"
REFERENCES,0.9657320872274143,"and supplemental material.
571"
REFERENCES,0.9672897196261683,"(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they
572"
REFERENCES,0.9688473520249221,"were chosen)? [Yes] See Section 6 and Appendices.
573"
REFERENCES,0.9704049844236761,"(c) Did you report error bars (e.g., with respect to the random seed after running experi-
574"
REFERENCES,0.9719626168224299,"ments multiple times)? [Yes] See Table 1.
575"
REFERENCES,0.9735202492211839,"(d) Did you include the total amount of compute and the type of resources used (e.g., type
576"
REFERENCES,0.9750778816199377,"of GPUs, internal cluster, or cloud provider)? [Yes] See Appendices.
577"
REFERENCES,0.9766355140186916,"4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...
578"
REFERENCES,0.9781931464174455,"(a) If your work uses existing assets, did you cite the creators? [Yes]
579"
REFERENCES,0.9797507788161994,"(b) Did you mention the license of the assets? [Yes] See Appendices.
580"
REFERENCES,0.9813084112149533,"(c) Did you include any new assets either in the supplemental material or as a URL? [N/A]
581 582"
REFERENCES,0.9828660436137072,"(d) Did you discuss whether and how consent was obtained from people whose data you’re
583"
REFERENCES,0.9844236760124611,"using/curating? [N/A]
584"
REFERENCES,0.985981308411215,"(e) Did you discuss whether the data you are using/curating contains personally identifiable
585"
REFERENCES,0.9875389408099688,"information or offensive content? [N/A]
586"
REFERENCES,0.9890965732087228,"5. If you used crowdsourcing or conducted research with human subjects...
587"
REFERENCES,0.9906542056074766,"(a) Did you include the full text of instructions given to participants and screenshots, if
588"
REFERENCES,0.9922118380062306,"applicable? [N/A]
589"
REFERENCES,0.9937694704049844,"(b) Did you describe any potential participant risks, with links to Institutional Review
590"
REFERENCES,0.9953271028037384,"Board (IRB) approvals, if applicable? [N/A]
591"
REFERENCES,0.9968847352024922,"(c) Did you include the estimated hourly wage paid to participants and the total amount
592"
REFERENCES,0.9984423676012462,"spent on participant compensation? [N/A]
593"
