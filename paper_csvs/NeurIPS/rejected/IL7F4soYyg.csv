Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0018018018018018018,"The current state-of-the-art single-cell pre-trained models are greatly inspired by
1"
ABSTRACT,0.0036036036036036037,"the success of large language models. They trained transformers by treating genes
2"
ABSTRACT,0.005405405405405406,"as tokens and cells as sentences. However, three fundamental differences between
3"
ABSTRACT,0.007207207207207207,"single-cell data and natural language data are overlooked: (1) scRNA-seq data are
4"
ABSTRACT,0.009009009009009009,"presented as bag-of-genes instead of sequences of RNAs; (2) Cell-cell relations
5"
ABSTRACT,0.010810810810810811,"are more intricate and important than inter-sentence relations; and (3) The quantity
6"
ABSTRACT,0.012612612612612612,"of single-cell data is considerably inferior to text data, and they are very noisy.
7"
ABSTRACT,0.014414414414414415,"In light of these characteristics, we propose a new pre-trained model CellPLM,
8"
ABSTRACT,0.016216216216216217,"which takes cells as tokens and tissues as sentences. In addition, we leverage
9"
ABSTRACT,0.018018018018018018,"spatially-resolved transcriptomic data in pre-training to facilitate learning cell-cell
10"
ABSTRACT,0.01981981981981982,"relationships and introduce a Gaussian mixture prior distribution as an additional
11"
ABSTRACT,0.021621621621621623,"inductive bias to overcome data limitation. CellPLM is the first single-cell pre-
12"
ABSTRACT,0.023423423423423424,"trained transformer that encodes cell-cell relations and it achieves state-of-the-art
13"
ABSTRACT,0.025225225225225224,"performance in various downstream tasks.
14"
INTRODUCTION,0.02702702702702703,"1
Introduction
15"
INTRODUCTION,0.02882882882882883,"Next-generation sequencing technologies such as single-cell RNA sequencing (scRNA-seq [1]) have
16"
INTRODUCTION,0.03063063063063063,"produced vast amounts of data, sparking a surge of interest in developing large-scale pre-trained
17"
INTRODUCTION,0.032432432432432434,"models for single-cell analysis [2, 3, 4, 5]. These models seek to capture underlying structures and
18"
INTRODUCTION,0.03423423423423423,"patterns from unlabeled scRNA-seq data, and can be fine-tuned on specific downstream datasets
19"
INTRODUCTION,0.036036036036036036,"to deliver accurate predictions and nuanced insights into cellular mechanisms. Particularly, these
20"
INTRODUCTION,0.03783783783783784,"pre-trained models have been inspired by the success of large language models, such as BERT and
21"
INTRODUCTION,0.03963963963963964,"GPT [6, 7], and treat genes as words (tokens) and cells as sentences to train transformers [8]. However,
22"
INTRODUCTION,0.04144144144144144,"we argue that these approaches may have limitations due to the fundamental differences between
23"
INTRODUCTION,0.043243243243243246,"single-cell data and natural language data, which have been largely overlooked in existing literature:
24"
INTRODUCTION,0.04504504504504504,"First, unlike sentences, the scRNA-seq data utilized by existing pre-trained models are not sequential.
25"
INTRODUCTION,0.04684684684684685,"Before the training stage, RNA sequences have been identified as functional units, i.e., genes. Instead
26"
INTRODUCTION,0.04864864864864865,"of original sequences, data is denoted as a cell-by-gene count matrix that measures the abundance
27"
INTRODUCTION,0.05045045045045045,"of individual genes within each cell. This is analogous to bag-of-words model in natural languages,
28"
INTRODUCTION,0.05225225225225225,"where the set of genes is fixed, and there is no sequential relationship among them.
29"
INTRODUCTION,0.05405405405405406,"Second, the relationship between cells is remarkably more intricate and important than that of
30"
INTRODUCTION,0.055855855855855854,"sentences, since cell-cell interactions play an essential role in determining cell states and cell
31"
INTRODUCTION,0.05765765765765766,"development [9]. Additionally, within tissues, there are numerous cells from the same or similar cell
32"
INTRODUCTION,0.05945945945945946,"lineage, which grants them similar gene expression profile and hence provides valuable supplementary
33"
INTRODUCTION,0.06126126126126126,"information for denoising and identifying cell states [10, 11, 12]. As a result, many recent methods [13,
34"
INTRODUCTION,0.06306306306306306,"14, 15, 16] have constructed cell-cell graphs to advance representation learning for single-cell data.
35"
INTRODUCTION,0.06486486486486487,"Figure 1: An illustration of the difference in the language models between existing single-cell
pre-trained models and CellPLM. Existing pre-trained models only consider conditional probability
between gene expressions within the same cell, while in CellPLM, gene expression distribution is
also conditioned on other cells. See details in Section 3."
INTRODUCTION,0.06666666666666667,"Such evidence demonstrates the importance of cell-cell relationship, which is usually neglected by
36"
INTRODUCTION,0.06846846846846846,"existing pre-trained models.
37"
INTRODUCTION,0.07027027027027027,"Third, the quantity and quality of single-cell datasets are significantly lower than those of natural
38"
INTRODUCTION,0.07207207207207207,"language data. For comparison, the high-quality filtered English dataset extracted from Common
39"
INTRODUCTION,0.07387387387387387,"Crawl corpora [17] consists of 32 billion sentences, whereas the largest collection of single-cell
40"
INTRODUCTION,0.07567567567567568,"datasets, namely the Human Cell Atlas [18], includes less than 50 million cells. To make things
41"
INTRODUCTION,0.07747747747747748,"worse, single-cell data often suffer from technical artifacts and dropout events [19, 20], as well as
42"
INTRODUCTION,0.07927927927927927,"significant batch effects between sequencing platforms and experiments [21, 22].
43"
INTRODUCTION,0.08108108108108109,"The aforementioned differences introduce distinct challenges which call for new pre-training strategies
44"
INTRODUCTION,0.08288288288288288,"tailored for single-cell data. To bridge this gap, we propose a novel single-Cell Pre-trained Language
45"
INTRODUCTION,0.08468468468468468,"Model (CellPLM), which addresses these challenges from following perspective: First, As shown
46"
INTRODUCTION,0.08648648648648649,"in Figure 1, CellPLM proposes a cell language model to account for cell-cell relations. The cell
47"
INTRODUCTION,0.08828828828828829,"embeddings are initialized by aggregating gene embeddings since gene expressions are bag-of-word
48"
INTRODUCTION,0.09009009009009009,"features. Second, CellPLM leverages a new type of data, spatially-resolved transcriptomic (SRT)
49"
INTRODUCTION,0.0918918918918919,"data, to gain an additional reference for uncovering cell-cell interactions. Compared to scRNA-seq
50"
INTRODUCTION,0.0936936936936937,"data, SRT data provide additional positional information for cells. Both types of data are jointly
51"
INTRODUCTION,0.09549549549549549,"modeled by transformers. Third, CellPLM introduces inductive bias to overcome the limitation of
52"
INTRODUCTION,0.0972972972972973,"data quantity and quality by utilizing a Gaussian mixture model as the prior distribution in the latent
53"
INTRODUCTION,0.0990990990990991,"space. This design can lead to smoother and better cell latent representations [23, 15, 24]. To the best
54"
INTRODUCTION,0.1009009009009009,"of our knowledge, the proposed CellPLM is the first pre-trained transformer framework that encodes
55"
INTRODUCTION,0.10270270270270271,"inter-cell relations, leverages spatially-resolved transcriptomic data, and adopts a reasonable prior
56"
INTRODUCTION,0.1045045045045045,"distribution. It is evident from our experiments that CellPLM demonstrates superior performance in
57"
INTRODUCTION,0.1063063063063063,"various downstream tasks.
58"
SINGLE-CELL PRE-TRAINED MODELS,0.10810810810810811,"2
Single-cell Pre-trained Models
59"
SINGLE-CELL PRE-TRAINED MODELS,0.10990990990990991,"Deep learning methods for single-cell data have garnered significant research interest in recent
60"
SINGLE-CELL PRE-TRAINED MODELS,0.11171171171171171,"years [11]. However, due to the distinct model architectures, the knowledge learned by models is
61"
SINGLE-CELL PRE-TRAINED MODELS,0.11351351351351352,"not transferable across tasks. To address this issue, there is an emerging effort [2, 3, 4, 5] from the
62"
SINGLE-CELL PRE-TRAINED MODELS,0.11531531531531532,"research community to explore the potential of a foundation model that first extracts latent knowledge
63"
SINGLE-CELL PRE-TRAINED MODELS,0.11711711711711711,"from unlabeled scRNA-seq data and subsequently generalizes this knowledge to a variety of tasks.
64"
SINGLE-CELL PRE-TRAINED MODELS,0.11891891891891893,"The first such pre-trained model for single-cell data, scBERT [2], takes genes as tokens and leverages
65"
SINGLE-CELL PRE-TRAINED MODELS,0.12072072072072072,"an efficient transformer [25] to encode over 16,000 gene tokens for each cell. By randomly masking a
66"
SINGLE-CELL PRE-TRAINED MODELS,0.12252252252252252,"fraction of non-zero gene expression values and predicting them based on the remaining data, scBERT
67"
SINGLE-CELL PRE-TRAINED MODELS,0.12432432432432433,"effectively learns intricate relationships between genes, leading to improved cellular representation.
68"
SINGLE-CELL PRE-TRAINED MODELS,0.12612612612612611,"Later, xTrimoGene [3] made two key enhancements to scBERT: pruning zero-expressed genes and
69"
SINGLE-CELL PRE-TRAINED MODELS,0.12792792792792793,"improving expression binning strategies by an auto-discretization strategy. These modifications
70"
SINGLE-CELL PRE-TRAINED MODELS,0.12972972972972974,"notably enhance scalability and feature resolutions. Another latest preprint, scGPT [5], introduces a
71"
SINGLE-CELL PRE-TRAINED MODELS,0.13153153153153152,"variant of masked language modeling that mimics the auto-regressive generation in natural language
72"
SINGLE-CELL PRE-TRAINED MODELS,0.13333333333333333,"processing, where the masked genes are iteratively predicted according to model’s confidence. Unlike
73"
SINGLE-CELL PRE-TRAINED MODELS,0.13513513513513514,"the aforementioned models, tGPT [4] completely abandons masked language modeling. It constructs
74"
SINGLE-CELL PRE-TRAINED MODELS,0.13693693693693693,"sequences of genes based on the ranking of gene expressions within each cell, and the model is trained
75"
SINGLE-CELL PRE-TRAINED MODELS,0.13873873873873874,"to autoregressively predict the name of the next gene. Despite discarding the precise expressions,
76"
SINGLE-CELL PRE-TRAINED MODELS,0.14054054054054055,"this approach demonstrates enhanced robustness against batch effects and can be generalized to bulk
77"
SINGLE-CELL PRE-TRAINED MODELS,0.14234234234234233,"RNA data.
78"
SINGLE-CELL PRE-TRAINED MODELS,0.14414414414414414,"The aforementioned models all regard genes as tokens and focus solely on modeling gene relationships
79"
SINGLE-CELL PRE-TRAINED MODELS,0.14594594594594595,"within individual cells, neglecting the intercellular information in an organism. In contrast, CellPLM
80"
SINGLE-CELL PRE-TRAINED MODELS,0.14774774774774774,"overcomes this limitation by introducing a cell language model that extends beyond single cells.
81"
SINGLE-CELL PRE-TRAINED MODELS,0.14954954954954955,"Furthermore, by leveraging the spatial information of cells acquired from SRT data, along with a
82"
SINGLE-CELL PRE-TRAINED MODELS,0.15135135135135136,"prior Gaussian mixture distribution, the model achieves unparalleled performance on a range of
83"
SINGLE-CELL PRE-TRAINED MODELS,0.15315315315315314,"downstream tasks.
84"
CELL LANGUAGE MODEL BEYOND SINGLE CELLS,0.15495495495495495,"3
Cell Language Model Beyond Single Cells
85"
CELL LANGUAGE MODEL BEYOND SINGLE CELLS,0.15675675675675677,"In this section, we introduce the concept of the cell language models and detailed implementation
86"
CELL LANGUAGE MODEL BEYOND SINGLE CELLS,0.15855855855855855,"of the proposed CellPLM. As illustrated in Figure 2, CellPLM consists of four modules: a gene
87"
CELL LANGUAGE MODEL BEYOND SINGLE CELLS,0.16036036036036036,"expression embedder, an encoder, latent space, and a decoder, which we will demonstrate in Sec-
88"
CELL LANGUAGE MODEL BEYOND SINGLE CELLS,0.16216216216216217,"tion 3.2. At a higher level, there are two stages in our framework: pre-training and fine-tuning. During
89"
CELL LANGUAGE MODEL BEYOND SINGLE CELLS,0.16396396396396395,"pre-training, the model is trained on unlabeled data with a masked language modeling objective. For
90"
CELL LANGUAGE MODEL BEYOND SINGLE CELLS,0.16576576576576577,"fine-tuning, the model is first initialized with the pre-trained parameters, and then all of the parameters
91"
CELL LANGUAGE MODEL BEYOND SINGLE CELLS,0.16756756756756758,"are fine-tuned using data and labels (if available) from the downstream datasets. We demonstrate the
92"
CELL LANGUAGE MODEL BEYOND SINGLE CELLS,0.16936936936936936,"pre-training and fine-tuning framework in Section 3.3 and 3.3, respectively.
93"
CELL LANGUAGE MODEL,0.17117117117117117,"3.1
Cell Language Model
94"
CELL LANGUAGE MODEL,0.17297297297297298,"Due to the recent achievements of large language models [7], several studies [2, 3, 4, 5] have drawn
95"
CELL LANGUAGE MODEL,0.17477477477477477,"inspiration from natural language processing in an attempt to establish a foundational model for
96"
CELL LANGUAGE MODEL,0.17657657657657658,"single-cell analysis. These studies consider genes as tokens and train transformers on them, aiming to
97"
CELL LANGUAGE MODEL,0.1783783783783784,"model the conditional probability between gene expressions. Concretely, previous pre-trained models
98"
CELL LANGUAGE MODEL,0.18018018018018017,"are trained on scRNA-seq data, which are stored in the format of a cell-by-gene matrix X ∈RN×k,
99"
CELL LANGUAGE MODEL,0.18198198198198198,"where N is the number of cells, and k is the number of distinct gene types. The value of Xi,j denotes
100"
CELL LANGUAGE MODEL,0.1837837837837838,"the count of gene j observed in cell i, also known as gene expression. The pre-training goal of these
101"
CELL LANGUAGE MODEL,0.18558558558558558,"models is to estimate a conditional probability distribution, which can be formulated as:
102"
CELL LANGUAGE MODEL,0.1873873873873874,"p
 
Xi,j|{Xi,o}o∈O(i)

, j ∈U(i),
(1)"
CELL LANGUAGE MODEL,0.1891891891891892,"where i refers to the i-th cell and O(i) is the set of observed genes in cell i whose expressions are
103"
CELL LANGUAGE MODEL,0.19099099099099098,"known; U(i) denotes the set of unobserved genes in cell i whose expression will be predicted by the
104"
CELL LANGUAGE MODEL,0.1927927927927928,"model, typically referring as masked genes. If we consider genes as words, this objective is analogous
105"
CELL LANGUAGE MODEL,0.1945945945945946,"to the language model in computational linguistics [26], and thus can be named a “gene language
106"
CELL LANGUAGE MODEL,0.1963963963963964,"model”. In this way, the model is trained to capture the intrinsic relations between genes, which can
107"
CELL LANGUAGE MODEL,0.1981981981981982,"provide prior knowledge for downstream analysis.
108"
CELL LANGUAGE MODEL,0.2,"However, in Eq. (1), the distribution of unobserved gene expressions only depends on genes within
109"
CELL LANGUAGE MODEL,0.2018018018018018,"the same cell, while disregarding the information of other cells within the same tissue, which does not
110"
CELL LANGUAGE MODEL,0.2036036036036036,"align with the inherent nature of biology. Therefore, in CellPLM, we provide a different perspective
111"
CELL LANGUAGE MODEL,0.20540540540540542,"to model scRNA-seq data by treating cells as tokens:
112"
CELL LANGUAGE MODEL,0.2072072072072072,"p
 
Xi,j|{Xu,v}(u,v)∈MC

, (i, j) ∈M,
(2)"
CELL LANGUAGE MODEL,0.209009009009009,"where we denote M as the set of masked gene expressions in X, and MC is the complement, i.e., the
113"
CELL LANGUAGE MODEL,0.21081081081081082,"set of unmasked expressions. The distribution of a masked entry Xi,j depends on both the observed
114"
CELL LANGUAGE MODEL,0.2126126126126126,"genes in cell i and genes from other cells that are not masked. We hereby name it as “cell language
115"
CELL LANGUAGE MODEL,0.21441441441441442,"model”, which models the distribution of cellular features beyond single cells. By estimating the
116"
CELL LANGUAGE MODEL,0.21621621621621623,"conditional probability distribution in Eq. (2), CellPLM is trained to capture the intricate relationships
117"
CELL LANGUAGE MODEL,0.218018018018018,"that exist between not only genes but also cells.
118"
CELL LANGUAGE MODEL,0.21981981981981982,"From a biology perspective, there are particularly two types of inter-cell relations that can be beneficial
119"
CELL LANGUAGE MODEL,0.22162162162162163,"to CellPLM. First, within tissues, there are numerous cells from the same or similar cell lineage, which
120"
CELL LANGUAGE MODEL,0.22342342342342342,"mutually provide valuable supplementary information for denoising and identifying cell states [10,
121"
CELL LANGUAGE MODEL,0.22522522522522523,"11, 12]. The other type of relations, cell-cell interactions (a.k.a, cell-cell communications), plays
122"
CELL LANGUAGE MODEL,0.22702702702702704,"an essential role in determining cell development and cell states [9]. Existing analysis methods [27,
123"
CELL LANGUAGE MODEL,0.22882882882882882,"28, 29] have already explored the cell-cell communications on the cell type or cluster levels, while
124"
CELL LANGUAGE MODEL,0.23063063063063063,"Figure 2: An illustration of the pre-training framework of CellPLM. CellPLM is pre-trained with
cell-level masked language modeling task. The model consists of four modules: a gene expression
embedder, a transformer encoder, a gaussian mixiture latent space, and a batch-aware decoder."
CELL LANGUAGE MODEL,0.23243243243243245,"CellPLM aims to capture the intricate “language” of cell-cell communications between single cells.
125"
CELL LANGUAGE MODEL,0.23423423423423423,"Overall, CellPLM presents a novel cell language model that aligns well with biological principles
126"
CELL LANGUAGE MODEL,0.23603603603603604,"and holds great potentials to enhance downstream tasks by extracting valuable cellular knowledge
127"
CELL LANGUAGE MODEL,0.23783783783783785,"from unlabeled single-cell data.
128"
MODEL ARCHITECTURE,0.23963963963963963,"3.2
Model Architecture
129"
MODEL ARCHITECTURE,0.24144144144144145,"Gene Expression Embedder. The first module in CellPLM model is a gene expression embedder,
130"
MODEL ARCHITECTURE,0.24324324324324326,"which projects input gene expressions into a low-dimensional cellular feature space. In light of the
131"
MODEL ARCHITECTURE,0.24504504504504504,"nature that scRNA-seq is profiled as bag-of-genes features, CellPLM learns an embedding vector for
132"
MODEL ARCHITECTURE,0.24684684684684685,"each type of gene, and then aggregates these gene embeddings according to their expression levels
133"
MODEL ARCHITECTURE,0.24864864864864866,"in each cell. Formally speaking, for gene j ∈{1, ..., k}, a learnable embedding vector hj ∈Rd
134"
MODEL ARCHITECTURE,0.25045045045045045,"is assigned, where d is the hidden dimension of the encoder layers. hj can be either randomly
135"
MODEL ARCHITECTURE,0.25225225225225223,"initialized or initialized by prior knowledge, e.g., gene2vec [30]. The gene expression embedding
136"
MODEL ARCHITECTURE,0.25405405405405407,"matrix E ∈RN×d is then generated by aggregating gene embeddings according to their expressions:
137 Ei = k
X"
MODEL ARCHITECTURE,0.25585585585585585,"j=1
Xi,jhj,
(3)"
MODEL ARCHITECTURE,0.25765765765765763,"where Ei is the i-th row vector of E, corresponding to the gene expression embedding for cell i.
138"
MODEL ARCHITECTURE,0.2594594594594595,"Note that the gene expression matrix X is a sparse matrix since the zero-rate of scRNA-seq can be up
139"
MODEL ARCHITECTURE,0.26126126126126126,"to 90% [31]. In addition, unmeasured genes (per sequencing platforms) also lead to zero entries in X.
140"
MODEL ARCHITECTURE,0.26306306306306304,"Therefore, when implementing Eq. (3), CellPLM leverages a sparse linear layer instead of a regular
141"
MODEL ARCHITECTURE,0.2648648648648649,"fully connected layer. This significantly improves memory and computational efficiency.
142"
MODEL ARCHITECTURE,0.26666666666666666,"Transformer Encoder. The proposed CellPLM follows an encoder-decoder structure, where the
143"
MODEL ARCHITECTURE,0.26846846846846845,"encoder is based on transformers [8]. The transformer model was originally developed for processing
144"
MODEL ARCHITECTURE,0.2702702702702703,"textual data. It leverages multi-head self-attention mechanisms to capture relationships between
145"
MODEL ARCHITECTURE,0.27207207207207207,"input tokens and incorporates positional encoding to represent the token positions. In CellPLM,
146"
MODEL ARCHITECTURE,0.27387387387387385,"by considering cells as tokens, we can readily apply the transformer model to capture intercellular
147"
MODEL ARCHITECTURE,0.2756756756756757,"relationships. When applying the transformer, we consider the embedding at l-th layer H(l) ∈RN×d
148"
MODEL ARCHITECTURE,0.2774774774774775,"as a set of N tokens, where N is the total number of cells in a tissue sample, and d is the hidden
149"
MODEL ARCHITECTURE,0.27927927927927926,"dimension. By stacking L transformer layers, CellPLM gradually encodes cellular and inter-cellular
150"
MODEL ARCHITECTURE,0.2810810810810811,"information into cell embeddings, formulated as:
151"
MODEL ARCHITECTURE,0.2828828828828829,"H(l) = TransformerLayer(l)(H(l−1)).
(4)"
MODEL ARCHITECTURE,0.28468468468468466,"In practice, N can scale up to ten thousands, which is out of the capacity of an ordinary transformer.
152"
MODEL ARCHITECTURE,0.2864864864864865,"Therefore, we adopt an efficient variant of transformers with linear complexity (i.e., Performer [25])
153"
MODEL ARCHITECTURE,0.2882882882882883,"for the implementation of transformer layers.
154"
MODEL ARCHITECTURE,0.29009009009009007,"To further inform inter-cellular relations, we incorporate spatial positional information of individual
155"
MODEL ARCHITECTURE,0.2918918918918919,"cells from a novel type of data, spatially-resolved transcriptomic (SRT) data. Specifically, SRT data
156"
MODEL ARCHITECTURE,0.2936936936936937,"consist of two parts. One is a gene expression matrix X ∈RN×k same as scRNA-seq data, and
157"
MODEL ARCHITECTURE,0.2954954954954955,"the other part is a 2D coordinate matrix C ∈RN×2. The coordinates denote the center position of
158"
MODEL ARCHITECTURE,0.2972972972972973,"each cell within a field-of-view (FOV) where the cells are located (an illustration can be found in
159"
MODEL ARCHITECTURE,0.2990990990990991,"Appendix A). This feature helps locate the microenvironment surrounding each cell, providing an
160"
MODEL ARCHITECTURE,0.3009009009009009,"additional reference for identifying cell lineage and cell communications, which were introduced in
161"
MODEL ARCHITECTURE,0.3027027027027027,"Section 3.1. To encode this extra positional information, we leverage the idea of positional encodings
162"
MODEL ARCHITECTURE,0.3045045045045045,"(PE) in transformers. Since sinusoidal PE achieves competitive performance and has lower complexity
163"
MODEL ARCHITECTURE,0.3063063063063063,"on SRT data [16], we generate a 2D sinusoid PE for cells in SRT data, denoted as P ∈RN×d, where
164"
MODEL ARCHITECTURE,0.3081081081081081,"Pi is the d dimensional PE vector for cell i (see details in Appendix B). For scRNA-seq data,
165"
MODEL ARCHITECTURE,0.3099099099099099,"a randomly initialized d-dimensional vector p′ is shared among all cells, which also results in a
166"
MODEL ARCHITECTURE,0.3117117117117117,"placeholder PE matrix P. The initial cell embeddings are now formulated as H(0) = E + P, where
167"
MODEL ARCHITECTURE,0.31351351351351353,"E is the expression embeddings from Eq. (3) and P is the positional embeddings.
168"
MODEL ARCHITECTURE,0.3153153153153153,"Gaussian Mixture Latent Space. One of the highlights of CellPLM is the design of probabilistic
169"
MODEL ARCHITECTURE,0.3171171171171171,"latent space. Prior studies have employed variational autoencoders for single-cell analysis, which
170"
MODEL ARCHITECTURE,0.31891891891891894,"typically assumes an isotropic Gaussian distribution as the prior distribution of the latent space [32,
171"
MODEL ARCHITECTURE,0.3207207207207207,"33]. While this approach can effectively remove batch effects, it may also result in a loss of
172"
MODEL ARCHITECTURE,0.3225225225225225,"information regarding the underlying biological structure of cell groups. To address this limitation,
173"
MODEL ARCHITECTURE,0.32432432432432434,"CellPLM incorporates the concept of Gaussian mixture variational encoder [34, 35, 15], which utilizes
174"
MODEL ARCHITECTURE,0.3261261261261261,"a mixture of Gaussians to capture the information of distinct functional groups of cells. Formally, for
175"
MODEL ARCHITECTURE,0.3279279279279279,"i ∈{1, . . . , N}, the generative model of cell i can be formulated as:
176"
MODEL ARCHITECTURE,0.32972972972972975,"p(yi; π) = Multinomial(π),"
MODEL ARCHITECTURE,0.33153153153153153,"p (zi | yi) = L
Y"
MODEL ARCHITECTURE,0.3333333333333333,"i=1
N

µyi,l, diag

σ2
yi,l

,"
MODEL ARCHITECTURE,0.33513513513513515,"pθdec (xi | zi) = N
 
µzi, σ2I

, (5)"
MODEL ARCHITECTURE,0.33693693693693694,"where yi ∈RL represents the one-hot latent cluster variable and π is its prior; yi,l denotes the
177"
MODEL ARCHITECTURE,0.3387387387387387,"l-th entry of yi; µyl ∈Rdz and σ2
yl ∈Rdz×dz denote the mean and variance of the l-th Gaussian
178"
MODEL ARCHITECTURE,0.34054054054054056,"component, respectively; and µzi ∈Rk and σ2I ∈Rk×k denote the posterior mean and variance of
179"
MODEL ARCHITECTURE,0.34234234234234234,"expression xi, respectively. In this work, we assume that σ2 is a constant and the posterior mean is
180"
MODEL ARCHITECTURE,0.3441441441441441,"parameterized by µzi = fdec(zi; θdec).
181"
MODEL ARCHITECTURE,0.34594594594594597,"To estimate the posterior of zi and yi, we parameterize the inference process with neural networks.
182"
MODEL ARCHITECTURE,0.34774774774774775,"Specifically, we assume that the cluster variables y are independent of the expression xi condition on
183"
MODEL ARCHITECTURE,0.34954954954954953,"latent variables zi. The inference model can be formulated as:
184"
MODEL ARCHITECTURE,0.35135135135135137,"qηµ,ησ(zi | xi) = N
 ˆµi, diag
 ˆσ2
i

,"
MODEL ARCHITECTURE,0.35315315315315315,"qηπ(yi | zi) = Multinomial(ˆπi),
(6)"
MODEL ARCHITECTURE,0.35495495495495494,"where the estimations are given by
185"
MODEL ARCHITECTURE,0.3567567567567568,"hi = fenc(xi; ηenc),
ˆµi = fµ (hi; ηµ) ,"
MODEL ARCHITECTURE,0.35855855855855856,"log
 ˆσ2
i

= fσ (hi; ησ) ,"
MODEL ARCHITECTURE,0.36036036036036034,ˆπi = fπ (zi; ηπ) . (7)
MODEL ARCHITECTURE,0.3621621621621622,"Here fenc(·; ηenc) represents the transformer encoder, fµ(·; ηµ), fσ(·; ησ) and fπ(·; ηπ) are neural
186"
MODEL ARCHITECTURE,0.36396396396396397,"networks. A log-evidence lower bound (ELBO) can be derived from this generative model for
187"
MODEL ARCHITECTURE,0.36576576576576575,"the optimization purpose [34]. However, as mentioned in Section 3.1, our pre-training framework
188"
MODEL ARCHITECTURE,0.3675675675675676,"incorporates a cell language model, where parts of the input gene expression matrix X are masked.
189"
MODEL ARCHITECTURE,0.36936936936936937,"This will result in a modified objective. To formalize the problem, recall that previously we defined
190"
MODEL ARCHITECTURE,0.37117117117117115,"the masked set as M. On top of that, we denote M ∈RN×k as a mask indicator matrix such that
191"
MODEL ARCHITECTURE,0.372972972972973,"Mi,j =

1
if (i, j) ̸∈M,
0
if (i, j) ∈M."
MODEL ARCHITECTURE,0.3747747747747748,"Let ˜X ∈RN×k be the masked gene expression matrix given by the element-wise multiplication
192"
MODEL ARCHITECTURE,0.37657657657657656,"˜X = M ⊙X. The objective of cell language model with Gaussian mixture prior, i.e., a denoising
193"
MODEL ARCHITECTURE,0.3783783783783784,"variational lower bound [36], can be formulated as:
194"
MODEL ARCHITECTURE,0.3801801801801802,"LCellLM =Eq(Z,Y| ˜
X)Ep( ˜
X|X) """
MODEL ARCHITECTURE,0.38198198198198197,"ln pθ(X, Z, Y)"
MODEL ARCHITECTURE,0.3837837837837838,"qη(Z, Y | ˜X) # (8)"
MODEL ARCHITECTURE,0.3855855855855856,"= Eqηenc(Z| ˜
X)Ep( ˜
X|X) [log pθdec(X | Z)]
|
{z
}
Lrecon"
MODEL ARCHITECTURE,0.38738738738738737,"−Eqηπ (Y|Z)
h
KL

qηenc(Z | ˜X)∥p(Z | Y)
i"
MODEL ARCHITECTURE,0.3891891891891892,"|
{z
}
Lcond
−Eqηenc(Z| ˜
X) [KL (qηπ(Y | Z)∥p(Y))]
|
{z
}
LY ."
MODEL ARCHITECTURE,0.390990990990991,"Similar to previous works [34], we refer to the three terms in Eq. (8) as reconstruction term Lrecon,
195"
MODEL ARCHITECTURE,0.3927927927927928,"conditional prior term Lcond and Y prior term LY. The approximation and estimation of the denoising
196"
MODEL ARCHITECTURE,0.3945945945945946,"variational lower bound are specified in Section 3.3.
197"
MODEL ARCHITECTURE,0.3963963963963964,"Batch-aware Decoder. The decoder in CellPLM operates by decoding each cell individually, given
198"
MODEL ARCHITECTURE,0.3981981981981982,"that the tissue context has already been encoded into the latent space by the encoder. The decoder’s
199"
MODEL ARCHITECTURE,0.4,"purpose is twofold: to reconstruct masked features and to help remove batch effects from the latent
200"
MODEL ARCHITECTURE,0.4018018018018018,"space. In order to accomplish this goal, the decoder stacks several feed-forward layers (FFLayers)
201"
MODEL ARCHITECTURE,0.4036036036036036,"atop the input of latent variables z, and a batch embedding, denoted as b ∈Rdz. Specifically, for
202"
MODEL ARCHITECTURE,0.40540540540540543,"each cell, the batch embedding is loaded from a learnable lookup table as b = LookUp(b), where b
203"
MODEL ARCHITECTURE,0.4072072072072072,"is the label indicating the specific tissue sample (or FOV for SRT data) from which the cell has been
204"
MODEL ARCHITECTURE,0.409009009009009,"drawn. By feeding the batch label to the decoder, a batch-effect-free latent space can be achieved, as
205"
MODEL ARCHITECTURE,0.41081081081081083,"empirically evidenced in scVI [32]. The decoder can thus be formulated as:
206"
MODEL ARCHITECTURE,0.4126126126126126,"h(0) = z + b,
h(l) = FFLayer(l)(h(l−1)),"
MODEL ARCHITECTURE,0.4144144144144144,"where l indicates the number of the layer, h(l) is the hidden vector of layer l ∈(1..L −1), and L
207"
MODEL ARCHITECTURE,0.41621621621621624,"is the total number of fully connected layers. The dimension of the last layer is different from the
208"
MODEL ARCHITECTURE,0.418018018018018,"previous layers because the last layer is considered as an output layer, with hL ∈Rk, where k is the
209"
MODEL ARCHITECTURE,0.4198198198198198,"size of gene sets in the gene expression matrix X ∈RN×k.
210"
MODEL PRE-TRAINING & FINE-TUNING,0.42162162162162165,"3.3
Model Pre-training & Fine-tuning
211"
MODEL PRE-TRAINING & FINE-TUNING,0.42342342342342343,"Pre-training. The pre-training of CellPLM follows a cell language modeling objective, as demon-
212"
MODEL PRE-TRAINING & FINE-TUNING,0.4252252252252252,"strated in Eq. (8). Specifically, given a batch of cell tokens as input, we first decide which cells
213"
MODEL PRE-TRAINING & FINE-TUNING,0.42702702702702705,"should be masked. Instead of completely masking these cell tokens, we selectively mask a certain
214"
MODEL PRE-TRAINING & FINE-TUNING,0.42882882882882883,"percentage of the gene expressions within them. This allows the model to recover underlying cor-
215"
MODEL PRE-TRAINING & FINE-TUNING,0.4306306306306306,"relations between cells, as proposed in a recent preprint, SpaFormer [16]. A significant concern
216"
MODEL PRE-TRAINING & FINE-TUNING,0.43243243243243246,"in CellPLM is the disparity in the number of genes measured by different sequencing platforms.
217"
MODEL PRE-TRAINING & FINE-TUNING,0.43423423423423424,"Notably, the gap between scRNA-seq and SRT can be substantial, ranging from 1,000 to 30,000.
218"
MODEL PRE-TRAINING & FINE-TUNING,0.436036036036036,"Taking this into consideration, CellPLM only masks the expression of genes that are measured in
219"
MODEL PRE-TRAINING & FINE-TUNING,0.43783783783783786,"each dataset, implying that the reconstruction loss is calculated exclusively on these measured genes.
220"
MODEL PRE-TRAINING & FINE-TUNING,0.43963963963963965,"When optimizing the denoising variational lower bound in Eq. (8), we apply reparameterization trick
221"
MODEL PRE-TRAINING & FINE-TUNING,0.44144144144144143,"and Monte Calo sampling, as proposed in VAE [37]. Furthermore, under the independent Gaussian
222"
MODEL PRE-TRAINING & FINE-TUNING,0.44324324324324327,"assumption, we reformulate and estimate the reconstruction term Lrecon in Eq. (8) with a mean
223"
MODEL PRE-TRAINING & FINE-TUNING,0.44504504504504505,"squared error (MSE). Therefore, the pre-training loss function of CellPLM can be formulated as:
224"
MODEL PRE-TRAINING & FINE-TUNING,0.44684684684684683,"LMSE =
M ⊙

H(L) −(1 −M) ⊙X

2"
MODEL PRE-TRAINING & FINE-TUNING,0.4486486486486487,"F , Lpretrain = LMSE + Lcond + LY,
(9)"
MODEL PRE-TRAINING & FINE-TUNING,0.45045045045045046,"where ⊙signifies element-wise multiplication, H(L) ∈RN×k is the output from the decoder, X and
225"
MODEL PRE-TRAINING & FINE-TUNING,0.45225225225225224,"M are the ground-truth gene expression matrix and the mask indicator matrix respectively, as defined
226"
MODEL PRE-TRAINING & FINE-TUNING,0.4540540540540541,"above. Lcond and LY are derived from Eq. (8).
227"
MODEL PRE-TRAINING & FINE-TUNING,0.45585585585585586,"Task-specific Fine-tuning. When fine-tuning CellPLM, the model is first initialized with the pre-
228"
MODEL PRE-TRAINING & FINE-TUNING,0.45765765765765765,"trained parameters. In downstream tasks that require gene expressions as output, the pre-trained
229"
MODEL PRE-TRAINING & FINE-TUNING,0.4594594594594595,"decoder is fine-tuned on the downstream datasets. Otherwise, the decoder will be replaced with
230"
MODEL PRE-TRAINING & FINE-TUNING,0.46126126126126127,"a task-specific head. The entire model is then fine-tuned with task-specific loss functions, which
231"
MODEL PRE-TRAINING & FINE-TUNING,0.46306306306306305,"helps align the general knowledge of the model to the specific downstream task. For example, in the
232"
MODEL PRE-TRAINING & FINE-TUNING,0.4648648648648649,"spatial transcriptomic imputation task, the model is fine-tuned on a query SRT dataset and a reference
233"
MODEL PRE-TRAINING & FINE-TUNING,0.4666666666666667,"scRNA-seq dataset, where two datasets are sampled from the same type of tissue. In this case, the
234"
MODEL PRE-TRAINING & FINE-TUNING,0.46846846846846846,"loss function remains the same as Eq.(9). After fine-tuned on these datasets, CellPLM fit the data
235"
MODEL PRE-TRAINING & FINE-TUNING,0.4702702702702703,"distribution of the target tissue and can readily perform imputation. The design and implementation
236"
MODEL PRE-TRAINING & FINE-TUNING,0.4720720720720721,"of heads and loss functions for some downstream tasks are elucidated in Appendix E.
237"
EXPERIMENT,0.47387387387387386,"4
Experiment
238"
EXPERIMENT,0.4756756756756757,"CellPLM is first pre-trained on more than 9 Million scRNA-seq cells and 2 Million SRT cells, with
239"
EXPERIMENT,0.4774774774774775,"the masked language modeling objective demonstrated in Section 3.3. To explore an appropriate
240"
EXPERIMENT,0.47927927927927927,"model size, we created three different sizes of pre-trained models, with 5M, 10M and 40M parameters,
241"
EXPERIMENT,0.4810810810810811,"respectively. All experiments were finished within 24 hours on a GPU server with 8 Nvidia Tesla
242"
EXPERIMENT,0.4828828828828829,"v100 16GB cards. The hyperparameters, datasets, and reproduciability information for pre-trained
243"
EXPERIMENT,0.4846846846846847,"models are detailed in Appendix D. Our preliminary results (See Appendix D) show that the 10M
244"
EXPERIMENT,0.4864864864864865,"model achieved the best parameter efficiency. Therefore, in the downstream evaluation, we take
245"
EXPERIMENT,0.4882882882882883,"CellPLM 10M as the base model without special mentioning.
246"
EXPERIMENT,0.4900900900900901,"In the following sections, we evaluate the performance of CellPLM 10M on various downstream
247"
EXPERIMENT,0.4918918918918919,"tasks, including scRNA-seq denoising, spatial transctiptomic imputation, and perturbation prediction.
248"
EXPERIMENT,0.4936936936936937,"With the selected tasks, we aim to answer the following research questions:
249"
EXPERIMENT,0.4954954954954955,"RQ1: Does CellPLM present extraordinary denoising power compared to non-pretrained models?
250"
EXPERIMENT,0.4972972972972973,"RQ2: Does CellPLM succeed in jointly modeling scRNA-seq and SRT data, thus benefiting from
251"
EXPERIMENT,0.4990990990990991,"both the spatial information of SRT and the abundant transcriptomic profiles of scRNA-seq?
252"
EXPERIMENT,0.5009009009009009,"RQ3: Although being trained on a cell language model beyond single cells, does CellPLM also
253"
EXPERIMENT,0.5027027027027027,"perform well on gene-level task?
254"
EXPERIMENT,0.5045045045045045,"4.1
Task 1: scRNA-seq Denoising
255"
EXPERIMENT,0.5063063063063064,"Given that single-cell RNA-Seq protocols capture only a subset of the mRNA molecules within
256"
EXPERIMENT,0.5081081081081081,"individual cells, the resulting measurements exhibit substantial technical noise [38]. Therefore, we
257"
EXPERIMENT,0.5099099099099099,"consider denoising power as the most desired and essential power for a single-cell foundation model.
258"
EXPERIMENT,0.5117117117117117,"The goal of the denoising task is to estimate the true expression level of each gene in each cell from
259"
EXPERIMENT,0.5135135135135135,"a noisy observation. To assess the denoising efficacy of CellPLM, we conduct an evaluation on
260"
EXPERIMENT,0.5153153153153153,"two single-cell RNA-Seq datasets, i.e., PBMC 5K and Jurkat from 10x Genomics [39]. Following
261"
EXPERIMENT,0.5171171171171172,"the setting of scGNN [13] and scGNN2.0 [40], we apply a random flipping process to a subset
262"
EXPERIMENT,0.518918918918919,"of non-zero entries, transforming them into zeros in order to simulate the effects of dropout. In
263"
EXPERIMENT,0.5207207207207207,"order to establish a performance benchmark for CellPLM, we conduct a comparative analysis with
264"
EXPERIMENT,0.5225225225225225,"contemporary approaches, including DeepImpute [41], scGNN2.0 [40], SAVER [42], DCA [43],
265"
EXPERIMENT,0.5243243243243243,"MAGIC [44] and scImpute [45], which are considered state-of-the-art methods in the field. We
266"
EXPERIMENT,0.5261261261261261,"evaluate scRNA-seq denoising performance based on two popular regression metrics, i.e., Root
267"
EXPERIMENT,0.527927927927928,"Mean Square Error (RMSE) and Mean Absolute Error (MAE), to measure the degree of similarity
268"
EXPERIMENT,0.5297297297297298,"between predicted gene expression and the actual ones. More details pertaining to these methods, the
269"
EXPERIMENT,0.5315315315315315,"fine-tuning of CellPLM, and the evaluation metrics under the task of scRNA-seq denoising can be
270"
EXPERIMENT,0.5333333333333333,"found in Appendix E.1.
271"
EXPERIMENT,0.5351351351351351,"It is evident that the fine-tuned CellPLM consistently exhibits superior performance compared to
272"
EXPERIMENT,0.5369369369369369,"all baseline models on both datasets. Note that even under the zero-shot setting, CellPLM shows
273"
EXPERIMENT,0.5387387387387388,"satisfactory results that surpass five baselines on the Jurkat dataset. These observations support that
274"
EXPERIMENT,0.5405405405405406,"our proposed CellPLM outperforms the state-of-the-art denoising techniques, which answers the
275"
EXPERIMENT,0.5423423423423424,"question of RQ1. This superiority can be attributed to the knowledge it acquires from unsupervised
276"
EXPERIMENT,0.5441441441441441,"pre-training.
277"
EXPERIMENT,0.5459459459459459,Table 1: (Task 1) The scRNA-seq denoising performance on the PBMC 5K and Jurkat datasets.
EXPERIMENT,0.5477477477477477,"PBMC 5K
Jurkat
Model
RMSE (↓)
MAE (↓)
RMSE (↓)
MAE (↓)"
EXPERIMENT,0.5495495495495496,"DeepImpute
1.168 ± 0.018
1.051 ± 0.025
0.786 ± 0.006
0.557 ± 0.003
scGNN 2.0
1.376 ± 0.015
1.237 ± 0.019
1.001 ± 0.016
0.917 ± 0.021
GraphSCI
1.068 ± 0.007
0.924 ± 0.009
0.659 ± 0.030
0.481 ± 0.024
SAVER
0.884 ± 0.001
0.748 ± 0.001
0.569 ± 0.001
0.472 ± 0.001
DCA
0.775 ± 0.002
0.621 ± 0.002
0.423 ± 0.001
0.351 ± 0.001
MAGIC
0.793 ± 0.001
0.639 ± 0.001
0.424 ± 0.001
0.351 ± 0.002
scImpute
1.170 ± 0.003
1.002 ± 0.001
0.624 ± 0.002
0.529 ± 0.001"
EXPERIMENT,0.5513513513513514,"CellPLM (Zero-shot)
0.920
0.754
0.543
0.448
CellPLM (Fine-tuned)
0.657 ± 0.002
0.485 ± 0.001
0.421 ± 0.002
0.336 ± 0.001"
EXPERIMENT,0.5531531531531532,"4.2
Task 2: Spatial Transcriptomic Imputation
278"
EXPERIMENT,0.554954954954955,"Spatially resolved transcriptomics has revolutionized single-cell analysis by incorporating physical
279"
EXPERIMENT,0.5567567567567567,"locations along with gene expression, leading to exciting breakthroughs. However, due to the highly
280"
EXPERIMENT,0.5585585585585585,"detailed spatial resolution, spatial transcriptomic data at the cellular level often encounter substantial
281"
EXPERIMENT,0.5603603603603604,"missing values, which pose challenges in data analysis. To assess the potential benefits of the
282"
EXPERIMENT,0.5621621621621622,"pre-trained model in the given task, we evaluate CellPLM on two spatial transcriptomic datasets
283"
EXPERIMENT,0.563963963963964,"at single-cell resolution, i.e., Lung2 and Liver2 [46]. Following the setting of baselines including
284"
EXPERIMENT,0.5657657657657658,"SpaGE [47], stPlus [48], gimVI [49] and Tangram [50], we impute the unseen genes of the SRT
285"
EXPERIMENT,0.5675675675675675,"dataset utilizing a scRNA-seq dataset as reference. We identify the testing gene set in SRT data
286"
EXPERIMENT,0.5693693693693693,"by stratified sampling according to gene sparsity [51] and holdout those genes in fine-tuning stage.
287"
EXPERIMENT,0.5711711711711712,"To evaluate the accuracy of spatial transcriptomic imputation, we employ Root Mean Square Error
288"
EXPERIMENT,0.572972972972973,"(RMSE), Pearson correlation coefficient (Corr), and cosine similarity (Cosine) to measure the degree
289"
EXPERIMENT,0.5747747747747748,"of similarity between the predicted spatial gene expressions and the corresponding ground-truth
290"
EXPERIMENT,0.5765765765765766,"expression values.
291"
EXPERIMENT,0.5783783783783784,"Remarkably, the fine-tuned CellPLM takes the lead in all three metrics on both datasets. In addition,
292"
EXPERIMENT,0.5801801801801801,"the impressive zero-shot performance indicates that CellPLM can leverage pre-training information
293"
EXPERIMENT,0.581981981981982,"to impute the SRT data, effectively addressing the research question RQ2. For additional information
294"
EXPERIMENT,0.5837837837837838,"regarding baselines, the fine-tuning of the CellPLM, and the evaluation metrics under this task, please
295"
EXPERIMENT,0.5855855855855856,"refer to Appendix E.2.
296"
EXPERIMENT,0.5873873873873874,Table 2: (Task 2) The results of spatial tanscriptomic imputation on the Lung2 and Liver2 datasets.
EXPERIMENT,0.5891891891891892,"Lung2
Liver2
Model
RMSE (↓)
Corr (↑)
Cosine (↑)
RMSE (↓)
Corr (↑)
Cosine (↑)"
EXPERIMENT,0.590990990990991,"SpaGE
0.617 ± 0.032
0.227 ± 0.011
0.352 ± 0.015
0.656 ± 0.012
0.253 ± 0.014
0.376 ± 0.005
stPlus
0.678 ± 0.038
0.177 ± 0.021
0.360 ± 0.014
0.801 ± 0.044
0.224 ± 0.010
0.399 ± 0.012
gimVI
1.230 ± 0.081
0.130 ± 0.010
0.325 ± 0.010
1.596 ± 0.551
0.163 ± 0.019
0.338 ± 0.010
Tangram
1.259 ± 0.193
0.123 ± 0.005
0.285 ± 0.008
1.209 ± 0.157
0.168 ± 0.024
0.309 ± 0.008"
EXPERIMENT,0.5927927927927928,"CellPLM (Zero-shot)
0.620
0.237
0.395
0.686
0.228
0.408
CellPLM (Fine-tuned)
0.612 ± 0.013
0.251 ± 0.011
0.402 ± 0.019
0.641 ± 0.011
0.278 ± 0.008
0.427 ± 0.004"
EXPERIMENT,0.5945945945945946,"4.3
Task 3: Perturbation Prediction
297"
EXPERIMENT,0.5963963963963964,"The perturb-seq technology has been established to examine the gene expression response at the single-
298"
EXPERIMENT,0.5981981981981982,"cell level when subjected to pooled perturbations [52]. By comparing the gene expression before and
299"
EXPERIMENT,0.6,"after perturbation, downstream analysis of differential expression (DE) enables the identification of
300"
EXPERIMENT,0.6018018018018018,"genes that play a crucial role in disease progression. To assess the potential benefits of CellPLM in
301"
EXPERIMENT,0.6036036036036037,"the given task, we conduct experiments to predict the expression value of genes after perturbation.
302"
EXPERIMENT,0.6054054054054054,"Following the setting of GEARS [53], we partition the perturbations into training, validation, and
303"
EXPERIMENT,0.6072072072072072,"test sets, ensuring that none of the test perturbations are encountered during the optimization process.
304"
EXPERIMENT,0.609009009009009,"Two perturbation datasets are employed for evaluation: (1) the Adamson Perturb-Seq dataset [54],
305"
EXPERIMENT,0.6108108108108108,"consisting of 87 one-gene perturbations; and (2) the Norman Perturb-Seq dataset [55], containing 131
306"
EXPERIMENT,0.6126126126126126,"two-gene perturbations and 105 one-gene perturbations. To evaluate the performance of perturbation
307"
EXPERIMENT,0.6144144144144145,"prediction, we employ Root Mean Square Error (RMSE) to measure the degree of similarity between
308"
EXPERIMENT,0.6162162162162163,"the predicted gene expressions and the corresponding ground-truth expression values. In addition,
309"
EXPERIMENT,0.618018018018018,"Adam. All
Adam. DE
Norman.0 All
Norman.0 DE
Norman.1 All
Norman.1 DE
0.00 0.05 0.10 0.15 0.20 0.25 0.30 RMSE"
EXPERIMENT,0.6198198198198198,"CellPLM
GEARS
scGEN"
EXPERIMENT,0.6216216216216216,"Figure 3: (Task 3) The RMSE performance (↓) on Adamson Perturb-Seq and the Norman Perturb-Seq
datasets. The Norman Perturb-seq dataset consists of two settings: one-gene perturbations and
two-gene perturbations, denoted as Norm.0 and Norm.1, respectively."
EXPERIMENT,0.6234234234234234,"Figure 4: The ablation study of different pre-training settings. Zero-shot RMSE performance (↓) on
PBMC 5K denoising task and Lung2 SRT imputation task, respectively.
following previous settings in GEARS [53], we also present the RMSE calculated on the top 20
310"
EXPERIMENT,0.6252252252252253,"deferentially-expressed genes.
311"
EXPERIMENT,0.6270270270270271,"We compare the performance between CellPLM and two baselines, i.e., a recent preprint GEARS
312"
EXPERIMENT,0.6288288288288288,"method [53], and scGen [56]. The results in Figure 3 imply that CellPLM achieves the lowest
313"
EXPERIMENT,0.6306306306306306,"RMSE values across all settings, which successfully tackles research question RQ3. For additional
314"
EXPERIMENT,0.6324324324324324,"information regarding baselines, the fine-tuning of the CellPLM, and the evaluation metrics, please
315"
EXPERIMENT,0.6342342342342342,"refer to Appendix E.3.
316"
ABLATION STUDY,0.6360360360360361,"4.4
Ablation study
317"
ABLATION STUDY,0.6378378378378379,"To verify the contribution of our model design, we conduct an ablation study on SRT data, Gaussian
318"
ABLATION STUDY,0.6396396396396397,"mixture prior and transformer encoder. Specifically, we remove SRT data from the pre-training
319"
ABLATION STUDY,0.6414414414414414,"dataset, replace transformer encoder with an MLP encoder and remove the Gaussian mixture prior, to
320"
ABLATION STUDY,0.6432432432432432,"examine its impact on the zero-shot performance in downstream tasks. All three models are modified
321"
ABLATION STUDY,0.645045045045045,"based on CellPLM 10M. Our results demonstrate that, on the whole, the full 10M model exhibits the
322"
ABLATION STUDY,0.6468468468468469,"best performance, and its individual components display notable significance. Specifically, in the SRT
323"
ABLATION STUDY,0.6486486486486487,"imputation task, the GMM latent model contributes the most, while the removal of SRT data or the
324"
ABLATION STUDY,0.6504504504504505,"transformer component leads to the most substantial decrease in scRNA-seq denoising performance.
325"
ABLATION STUDY,0.6522522522522523,"The ablation study provides additional support, indicating that all elements within CellPLM offer
326"
ABLATION STUDY,0.654054054054054,"valuable assistance in specific tasks.
327"
DISCUSSION,0.6558558558558558,"5
Discussion
328"
DISCUSSION,0.6576576576576577,"In this work, we propose cell language model, a novel paradigm of single-cell pre-trained model,
329"
DISCUSSION,0.6594594594594595,"which aligns well with the fundamental characteristics of single-cell data. This has leaded to
330"
DISCUSSION,0.6612612612612613,"CellPLM, the first pre-trained transformer framework that encodes inter-cell relations, leverages
331"
DISCUSSION,0.6630630630630631,"spatially-resolved transcriptomic data, and adopts a reasonable prior distribution. Our experiments on
332"
DISCUSSION,0.6648648648648648,"three downstream tasks demonstrate the power of CellPLM, which has a great potential to facilitate
333"
DISCUSSION,0.6666666666666666,"future research in single-cell biology.
334"
DISCUSSION,0.6684684684684684,"Limitations and future directions: Despite the superior performance and results from the abla-
335"
DISCUSSION,0.6702702702702703,"tion study suggesting that our model has learned complex cell-cell relationships, extracting explicit
336"
DISCUSSION,0.6720720720720721,"knowledge and insights from the model remains a challenging task. Therefore, enhancing model
337"
DISCUSSION,0.6738738738738739,"interpretability is one foremost future objective. Moreover, due to the unavailability of implemen-
338"
DISCUSSION,0.6756756756756757,"tations, we could not compare our model with existing pre-trained models. However, we intend to
339"
DISCUSSION,0.6774774774774774,"conduct a more comprehensive comparison in future studies.
340"
REFERENCES,0.6792792792792792,"References
341"
REFERENCES,0.6810810810810811,"[1] Fuchou Tang, Catalin Barbacioru, Yangzhou Wang, Ellen Nordman, Clarence Lee, Nanlan Xu,
342"
REFERENCES,0.6828828828828829,"Xiaohui Wang, John Bodeau, Brian B Tuch, Asim Siddiqui, Kaiqin Lao, and M Azim Surani.
343"
REFERENCES,0.6846846846846847,"mrna-seq whole-transcriptome analysis of a single cell. Nature Methods, 6(5):377–382, 2009.
344"
REFERENCES,0.6864864864864865,"[2] Fan Yang, Wenchuan Wang, Fang Wang, Yuan Fang, Duyu Tang, Junzhou Huang, Hui Lu, and
345"
REFERENCES,0.6882882882882883,"Jianhua Yao. scbert as a large-scale pretrained deep language model for cell type annotation of
346"
REFERENCES,0.69009009009009,"single-cell rna-seq data. Nature Machine Intelligence, 4(10):852–866, 2022.
347"
REFERENCES,0.6918918918918919,"[3] Jing Gong, Minsheng Hao, Xin Zeng, Chiming Liu, Jianzhu Ma, Xingyi Cheng, Taifeng Wang,
348"
REFERENCES,0.6936936936936937,"Xuegong Zhang, and Le Song. xtrimogene: An efficient and scalable representation learner for
349"
REFERENCES,0.6954954954954955,"single-cell rna-seq data. bioRxiv, pages 2023–03, 2023.
350"
REFERENCES,0.6972972972972973,"[4] Hongru Shen, Jilei Liu, Jiani Hu, Xilin Shen, Chao Zhang, Dan Wu, Mengyao Feng, Meng
351"
REFERENCES,0.6990990990990991,"Yang, Yang Li, Yichen Yang, et al. Generative pretraining from large-scale transcriptomes for
352"
REFERENCES,0.7009009009009008,"single-cell deciphering. iScience, 2023.
353"
REFERENCES,0.7027027027027027,"[5] Haotian Cui, Chloe Wang, Hassaan Maan, and Bo Wang. scgpt: Towards building a foundation
354"
REFERENCES,0.7045045045045045,"model for single-cell multi-omics using generative ai. bioRxiv, pages 2023–04, 2023.
355"
REFERENCES,0.7063063063063063,"[6] Jacob Devlin Ming-Wei Chang Kenton and Lee Kristina Toutanova. Bert: Pre-training of deep
356"
REFERENCES,0.7081081081081081,"bidirectional transformers for language understanding. In Proceedings of NAACL-HLT, pages
357"
REFERENCES,0.7099099099099099,"4171–4186, 2019.
358"
REFERENCES,0.7117117117117117,"[7] Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece
359"
REFERENCES,0.7135135135135136,"Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. Sparks of artificial general
360"
REFERENCES,0.7153153153153153,"intelligence: Early experiments with gpt-4. arXiv preprint arXiv:2303.12712, 2023.
361"
REFERENCES,0.7171171171171171,"[8] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
362"
REFERENCES,0.7189189189189189,"Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information
363"
REFERENCES,0.7207207207207207,"processing systems, 30, 2017.
364"
REFERENCES,0.7225225225225225,"[9] Erick Armingol, Adam Officer, Olivier Harismendy, and Nathan E Lewis. Deciphering cell–cell
365"
REFERENCES,0.7243243243243244,"interactions and communication from gene expression. Nature Reviews Genetics, 22(2):71–88,
366"
REFERENCES,0.7261261261261261,"2021.
367"
REFERENCES,0.7279279279279279,"[10] Robrecht Cannoodt, Wouter Saelens, and Yvan Saeys. Computational methods for trajectory
368"
REFERENCES,0.7297297297297297,"inference from single-cell transcriptomics. European journal of immunology, 46(11):2496–2506,
369"
REFERENCES,0.7315315315315315,"2016.
370"
REFERENCES,0.7333333333333333,"[11] Dylan Molho, Jiayuan Ding, Zhaoheng Li, Hongzhi Wen, Wenzhuo Tang, Yixin Wang, Julian
371"
REFERENCES,0.7351351351351352,"Venegas, Wei Jin, Renming Liu, Runze Su, et al. Deep learning in single-cell analysis. arXiv
372"
REFERENCES,0.736936936936937,"preprint arXiv:2210.12385, 2022.
373"
REFERENCES,0.7387387387387387,"[12] Kelly Street, Davide Risso, Russell B Fletcher, Diya Das, John Ngai, Nir Yosef, Elizabeth
374"
REFERENCES,0.7405405405405405,"Purdom, and Sandrine Dudoit. Slingshot: cell lineage and pseudotime inference for single-cell
375"
REFERENCES,0.7423423423423423,"transcriptomics. BMC genomics, 19:1–16, 2018.
376"
REFERENCES,0.7441441441441441,"[13] Juexin Wang, Anjun Ma, Yuzhou Chang, Jianting Gong, Yuexu Jiang, Ren Qi, Cankun Wang,
377"
REFERENCES,0.745945945945946,"Hongjun Fu, Qin Ma, and Dong Xu. scgnn is a novel graph neural network framework for
378"
REFERENCES,0.7477477477477478,"single-cell rna-seq analyses. Nature communications, 12(1):1882, 2021.
379"
REFERENCES,0.7495495495495496,"[14] Xin Shao, Chengyu Li, Haihong Yang, Xiaoyan Lu, Jie Liao, Jingyang Qian, Kai Wang, Junyun
380"
REFERENCES,0.7513513513513513,"Cheng, Penghui Yang, Huajun Chen, et al. Knowledge-graph-based cell-cell communication
381"
REFERENCES,0.7531531531531531,"inference for spatially resolved transcriptomic data with spatalk. Nature Communications,
382"
REFERENCES,0.7549549549549549,"13(1):4429, 2022.
383"
REFERENCES,0.7567567567567568,"[15] Junlin Xu, Jielin Xu, Yajie Meng, Changcheng Lu, Lijun Cai, Xiangxiang Zeng, Ruth Nussinov,
384"
REFERENCES,0.7585585585585586,"and Feixiong Cheng. Graph embedding and gaussian mixture variational autoencoder network
385"
REFERENCES,0.7603603603603604,"for end-to-end analysis of single-cell rna sequencing data. Cell Reports Methods, page 100382,
386"
REFERENCES,0.7621621621621621,"2023.
387"
REFERENCES,0.7639639639639639,"[16] Hongzhi Wen, Wenzhuo Tang, Wei Jin, Jiayuan Ding, Renming Liu, Feng Shi, Yuying Xie,
388"
REFERENCES,0.7657657657657657,"and Jiliang Tang. Single cells are spatial tokens: Transformers for spatial transcriptomic data
389"
REFERENCES,0.7675675675675676,"imputation. arXiv preprint arXiv:2302.03038, 2023.
390"
REFERENCES,0.7693693693693694,"[17] Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary, Francisco
391"
REFERENCES,0.7711711711711712,"Guzmán, Armand Joulin, and Edouard Grave. CCNet: Extracting high quality monolingual
392"
REFERENCES,0.772972972972973,"datasets from web crawl data. In Proceedings of the Twelfth Language Resources and Evaluation
393"
REFERENCES,0.7747747747747747,"Conference, pages 4003–4012, Marseille, France, May 2020. European Language Resources
394"
REFERENCES,0.7765765765765765,"Association.
395"
REFERENCES,0.7783783783783784,"[18] Aviv Regev, Sarah A Teichmann, Eric S Lander, Ido Amit, Christophe Benoist, Ewan Birney,
396"
REFERENCES,0.7801801801801802,"Bernd Bodenmiller, Peter Campbell, Piero Carninci, Menna Clatworthy, et al. The human cell
397"
REFERENCES,0.781981981981982,"atlas. elife, 6:e27041, 2017.
398"
REFERENCES,0.7837837837837838,"[19] Valentine Svensson, Kedar Nath Natarajan, Lam-Ha Ly, Ricardo J Miragaia, Charlotte Labalette,
399"
REFERENCES,0.7855855855855856,"Iain C Macaulay, Ana Cvejic, and Sarah A Teichmann. Power analysis of single-cell rna-
400"
REFERENCES,0.7873873873873873,"sequencing experiments. Nature methods, 14(4):381–387, 2017.
401"
REFERENCES,0.7891891891891892,"[20] Peng Qiu. Embracing the dropouts in single-cell rna-seq analysis. Nature communications,
402"
REFERENCES,0.790990990990991,"11(1):1169, 2020.
403"
REFERENCES,0.7927927927927928,"[21] Hoa Thi Nhu Tran, Kok Siong Ang, Marion Chevrier, Xiaomeng Zhang, Nicole Yee Shin
404"
REFERENCES,0.7945945945945946,"Lee, Michelle Goh, and Jinmiao Chen. A benchmark of batch-effect correction methods for
405"
REFERENCES,0.7963963963963964,"single-cell rna sequencing data. Genome biology, 21:1–32, 2020.
406"
REFERENCES,0.7981981981981981,"[22] Ricard Argelaguet, Anna SE Cuomo, Oliver Stegle, and John C Marioni. Computational
407"
REFERENCES,0.8,"principles and challenges in single-cell data integration. Nature biotechnology, 39(10):1202–
408"
REFERENCES,0.8018018018018018,"1215, 2021.
409"
REFERENCES,0.8036036036036036,"[23] Christopher Heje Grønbech, Maximillian Fornitz Vording, Pascal N Timshel, Casper Kaae
410"
REFERENCES,0.8054054054054054,"Sønderby, Tune H Pers, and Ole Winther. scvae: variational auto-encoders for single-cell gene
411"
REFERENCES,0.8072072072072072,"expression data. Bioinformatics, 36(16):4415–4422, 2020.
412"
REFERENCES,0.809009009009009,"[24] Jing Jiang, Junlin Xu, Yuansheng Liu, Bosheng Song, Xiulan Guo, Xiangxiang Zeng, and Quan
413"
REFERENCES,0.8108108108108109,"Zou. Dimensionality reduction and visualization of single-cell rna-seq data with an improved
414"
REFERENCES,0.8126126126126126,"deep variational autoencoder. Briefings in Bioinformatics, page bbad152, 2023.
415"
REFERENCES,0.8144144144144144,"[25] Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song, Andreea Gane,
416"
REFERENCES,0.8162162162162162,"Tamas Sarlos, Peter Hawkins, Jared Davis, Afroz Mohiuddin, Lukasz Kaiser, et al. Rethinking
417"
REFERENCES,0.818018018018018,"attention with performers. arXiv preprint arXiv:2009.14794, 2020.
418"
REFERENCES,0.8198198198198198,"[26] Yoshua Bengio, Réjean Ducharme, and Pascal Vincent. A neural probabilistic language model.
419"
REFERENCES,0.8216216216216217,"Advances in neural information processing systems, 13, 2000.
420"
REFERENCES,0.8234234234234235,"[27] Rui Hou, Elena Denisenko, Huan Ting Ong, Jordan A Ramilowski, and Alistair RR Forrest. Pre-
421"
REFERENCES,0.8252252252252252,"dicting cell-to-cell communication networks using natmi. Nature communications, 11(1):5011,
422"
REFERENCES,0.827027027027027,"2020.
423"
REFERENCES,0.8288288288288288,"[28] S Jin, CF Guerrero-Juarez, L Zhang, I Chang, R Ramos, CH Kuan, P Myung, MV Plikus, and
424"
REFERENCES,0.8306306306306306,"Q Nie. Inference and analysis of cell-cell communication using cellchat. nat. commun. 12,
425"
REFERENCES,0.8324324324324325,"1088, 2021.
426"
REFERENCES,0.8342342342342343,"[29] Micha Sam Brickman Raredon, Taylor Sterling Adams, Yasir Suhail, Jonas Christian Schupp,
427"
REFERENCES,0.836036036036036,"Sergio Poli, Nir Neumark, Katherine L Leiby, Allison Marie Greaney, Yifan Yuan, Corey
428"
REFERENCES,0.8378378378378378,"Horien, et al. Single-cell connectomic analysis of adult mammalian lungs. Science advances,
429"
REFERENCES,0.8396396396396396,"5(12):eaaw3851, 2019.
430"
REFERENCES,0.8414414414414414,"[30] Jingcheng Du, Peilin Jia, Yulin Dai, Cui Tao, Zhongming Zhao, and Degui Zhi. Gene2vec:
431"
REFERENCES,0.8432432432432433,"distributed representation of genes based on co-expression. BMC genomics, 20:7–15, 2019.
432"
REFERENCES,0.8450450450450451,"[31] Ruochen Jiang, Tianyi Sun, Dongyuan Song, and Jingyi Jessica Li. Statistics or biology: the
433"
REFERENCES,0.8468468468468469,"zero-inflation controversy about scrna-seq data. Genome biology, 23(1):1–24, 2022.
434"
REFERENCES,0.8486486486486486,"[32] Romain Lopez, Jeffrey Regier, Michael B Cole, Michael I Jordan, and Nir Yosef. Deep
435"
REFERENCES,0.8504504504504504,"generative modeling for single-cell transcriptomics. Nature methods, 15(12):1053–1058, 2018.
436"
REFERENCES,0.8522522522522522,"[33] Chenling Xu, Romain Lopez, Edouard Mehlman, Jeffrey Regier, Michael I Jordan, and Nir
437"
REFERENCES,0.8540540540540541,"Yosef. Probabilistic harmonization and annotation of single-cell transcriptomics data with deep
438"
REFERENCES,0.8558558558558559,"generative models. Molecular systems biology, 17(1):e9620, 2021.
439"
REFERENCES,0.8576576576576577,"[34] Nat Dilokthanakul, Pedro AM Mediano, Marta Garnelo, Matthew CH Lee, Hugh Salimbeni,
440"
REFERENCES,0.8594594594594595,"Kai Arulkumaran, and Murray Shanahan. Deep unsupervised clustering with gaussian mixture
441"
REFERENCES,0.8612612612612612,"variational autoencoders. arXiv preprint arXiv:1611.02648, 2016.
442"
REFERENCES,0.863063063063063,"[35] Linxiao Yang, Ngai-Man Cheung, Jiaying Li, and Jun Fang. Deep clustering by gaussian
443"
REFERENCES,0.8648648648648649,"mixture variational autoencoders with graph embedding. In Proceedings of the IEEE/CVF
444"
REFERENCES,0.8666666666666667,"International Conference on Computer Vision, pages 6440–6449, 2019.
445"
REFERENCES,0.8684684684684685,"[36] Daniel Im Im, Sungjin Ahn, Roland Memisevic, and Yoshua Bengio. Denoising criterion for
446"
REFERENCES,0.8702702702702703,"variational auto-encoding framework. In Proceedings of the AAAI conference on artificial
447"
REFERENCES,0.872072072072072,"intelligence, volume 31, 2017.
448"
REFERENCES,0.8738738738738738,"[37] Diederik P. Kingma and Max Welling. Auto-encoding variational bayes. In Yoshua Bengio and
449"
REFERENCES,0.8756756756756757,"Yann LeCun, editors, 2nd International Conference on Learning Representations, ICLR 2014,
450"
REFERENCES,0.8774774774774775,"Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings, 2014.
451"
REFERENCES,0.8792792792792793,"[38] Dominic Grün, Lennart Kester, and Alexander Van Oudenaarden. Validation of noise models
452"
REFERENCES,0.8810810810810811,"for single-cell transcriptomics. Nature methods, 11(6):637–640, 2014.
453"
REFERENCES,0.8828828828828829,"[39] 10x
genomics
datasets.
https://support.10xgenomics.com/
454"
REFERENCES,0.8846846846846846,"single-cellgene-expression/datasets.
455"
REFERENCES,0.8864864864864865,"[40] Haocheng Gu, Hao Cheng, Anjun Ma, Yang Li, Juexin Wang, Dong Xu, and Qin Ma. scgnn
456"
REFERENCES,0.8882882882882883,"2.0: a graph neural network tool for imputation and clustering of single-cell rna-seq data.
457"
REFERENCES,0.8900900900900901,"Bioinformatics, 38(23):5322–5325, 2022.
458"
REFERENCES,0.8918918918918919,"[41] Cédric Arisdakessian, Olivier Poirion, Breck Yunits, Xun Zhu, and Lana X Garmire. Deepim-
459"
REFERENCES,0.8936936936936937,"pute: an accurate, fast, and scalable deep neural network method to impute single-cell rna-seq
460"
REFERENCES,0.8954954954954955,"data. Genome biology, 20(1):1–14, 2019.
461"
REFERENCES,0.8972972972972973,"[42] Mo Huang, Jingshu Wang, Eduardo Torre, Hannah Dueck, Sydney Shaffer, Roberto Bonasio,
462"
REFERENCES,0.8990990990990991,"John I Murray, Arjun Raj, Mingyao Li, and Nancy R Zhang. Saver: gene expression recovery
463"
REFERENCES,0.9009009009009009,"for single-cell rna sequencing. Nature methods, 15(7):539–542, 2018.
464"
REFERENCES,0.9027027027027027,"[43] Gökcen Eraslan, Lukas M Simon, Maria Mircea, Nikola S Mueller, and Fabian J Theis. Single-
465"
REFERENCES,0.9045045045045045,"cell rna-seq denoising using a deep count autoencoder. Nature communications, 10(1):390,
466"
REFERENCES,0.9063063063063063,"2019.
467"
REFERENCES,0.9081081081081082,"[44] David Van Dijk, Roshan Sharma, Juozas Nainys, Kristina Yim, Pooja Kathail, Ambrose J
468"
REFERENCES,0.9099099099099099,"Carr, Cassandra Burdziak, Kevin R Moon, Christine L Chaffer, Diwakar Pattabiraman, et al.
469"
REFERENCES,0.9117117117117117,"Recovering gene interactions from single-cell data using data diffusion. Cell, 174(3):716–729,
470"
REFERENCES,0.9135135135135135,"2018.
471"
REFERENCES,0.9153153153153153,"[45] Wei Vivian Li and Jingyi Jessica Li. An accurate and robust imputation method scimpute for
472"
REFERENCES,0.9171171171171171,"single-cell rna-seq data. Nature communications, 9(1):997, 2018.
473"
REFERENCES,0.918918918918919,"[46] Merscope
ffpe
human
immuno-oncology
datasets.
https://info.vizgen.com/
474"
REFERENCES,0.9207207207207208,"ffpe-showcase?submissionGuid=88ba0a44-26e2-47a2-8ee4-9118b9811fbf.
475"
REFERENCES,0.9225225225225225,"[47] Tamim Abdelaal, Soufiane Mourragui, Ahmed Mahfouz, and Marcel JT Reinders. Spage:
476"
REFERENCES,0.9243243243243243,"spatial gene enhancement using scrna-seq. Nucleic acids research, 48(18):e107–e107, 2020.
477"
REFERENCES,0.9261261261261261,"[48] Chen Shengquan, Zhang Boheng, Chen Xiaoyang, Zhang Xuegong, and Jiang Rui. stplus: a
478"
REFERENCES,0.9279279279279279,"reference-based method for the accurate enhancement of spatial transcriptomics. Bioinformatics,
479"
REFERENCES,0.9297297297297298,"37(Supplement_1):i299–i307, 2021.
480"
REFERENCES,0.9315315315315316,"[49] Romain Lopez, Achille Nazaret, Maxime Langevin, Jules Samaran, Jeffrey Regier, Michael I
481"
REFERENCES,0.9333333333333333,"Jordan, and Nir Yosef. A joint model of unpaired data from scrna-seq and spatial transcriptomics
482"
REFERENCES,0.9351351351351351,"for imputing missing gene expression measurements. arXiv preprint arXiv:1905.02269, 2019.
483"
REFERENCES,0.9369369369369369,"[50] Tommaso Biancalani, Gabriele Scalia, Lorenzo Buffoni, Raghav Avasthi, Ziqing Lu, Aman
484"
REFERENCES,0.9387387387387387,"Sanger, Neriman Tokcan, Charles R Vanderburg, Åsa Segerstolpe, Meng Zhang, et al. Deep
485"
REFERENCES,0.9405405405405406,"learning and alignment of spatially resolved single-cell transcriptomes with tangram. Nature
486"
REFERENCES,0.9423423423423424,"methods, 18(11):1352–1362, 2021.
487"
REFERENCES,0.9441441441441442,"[51] Gülben Av¸sar and Pınar Pir. A comparative performance evaluation of imputation methods in
488"
REFERENCES,0.9459459459459459,"spatially resolved transcriptomics data. Molecular Omics, 2023.
489"
REFERENCES,0.9477477477477477,"[52] Atray Dixit, Oren Parnas, Biyu Li, Jenny Chen, Charles P Fulco, Livnat Jerby-Arnon, Ne-
490"
REFERENCES,0.9495495495495495,"manja D Marjanovic, Danielle Dionne, Tyler Burks, Raktima Raychowdhury, et al. Perturb-seq:
491"
REFERENCES,0.9513513513513514,"dissecting molecular circuits with scalable single-cell rna profiling of pooled genetic screens.
492"
REFERENCES,0.9531531531531532,"cell, 167(7):1853–1866, 2016.
493"
REFERENCES,0.954954954954955,"[53] Yusuf Roohani, Kexin Huang, and Jure Leskovec. Gears: Predicting transcriptional outcomes
494"
REFERENCES,0.9567567567567568,"of novel multi-gene perturbations. BioRxiv, pages 2022–07, 2022.
495"
REFERENCES,0.9585585585585585,"[54] Britt Adamson, Thomas M Norman, Marco Jost, Min Y Cho, James K Nuñez, Yuwen Chen,
496"
REFERENCES,0.9603603603603603,"Jacqueline E Villalta, Luke A Gilbert, Max A Horlbeck, Marco Y Hein, et al. A multiplexed
497"
REFERENCES,0.9621621621621622,"single-cell crispr screening platform enables systematic dissection of the unfolded protein
498"
REFERENCES,0.963963963963964,"response. Cell, 167(7):1867–1882, 2016.
499"
REFERENCES,0.9657657657657658,"[55] Thomas M Norman, Max A Horlbeck, Joseph M Replogle, Alex Y Ge, Albert Xu, Marco Jost,
500"
REFERENCES,0.9675675675675676,"Luke A Gilbert, and Jonathan S Weissman. Exploring genetic interaction manifolds constructed
501"
REFERENCES,0.9693693693693693,"from rich single-cell phenotypes. Science, 365(6455):786–793, 2019.
502"
REFERENCES,0.9711711711711711,"[56] Mohammad Lotfollahi, F Alexander Wolf, and Fabian J Theis. scgen predicts single-cell
503"
REFERENCES,0.972972972972973,"perturbation responses. Nature methods, 16(8):715–721, 2019.
504"
REFERENCES,0.9747747747747748,"[57] Grace XY Zheng, Jessica M Terry, Phillip Belgrader, Paul Ryvkin, Zachary W Bent, Ryan
505"
REFERENCES,0.9765765765765766,"Wilson, Solongo B Ziraldo, Tobias D Wheeler, Geoff P McDermott, Junjie Zhu, et al. Massively
506"
REFERENCES,0.9783783783783784,"parallel digital transcriptional profiling of single cells. Nature communications, 8(1):14049,
507"
REFERENCES,0.9801801801801802,"2017.
508"
REFERENCES,0.9819819819819819,"[58] Feiyang Ma and Matteo Pellegrini. Actinn: automated identification of cell types in single cell
509"
REFERENCES,0.9837837837837838,"rna sequencing. Bioinformatics, 36(2):533–538, 2020.
510"
REFERENCES,0.9855855855855856,"[59] C Domínguez Conde, C Xu, LB Jarvis, DB Rainbow, SB Wells, T Gomes, SK Howlett,
511"
REFERENCES,0.9873873873873874,"O Suchanek, K Polanski, HW King, et al. Cross-tissue immune cell analysis reveals tissue-
512"
REFERENCES,0.9891891891891892,"specific features in humans. Science, 376(6594):eabl5197, 2022.
513"
REFERENCES,0.990990990990991,"[60] Yuqi Tan and Patrick Cahan. Singlecellnet: a computational tool to classify single cell rna-seq
514"
REFERENCES,0.9927927927927928,"data across platforms and across species. Cell systems, 9(2):207–213, 2019.
515"
REFERENCES,0.9945945945945946,"[61] Jiawei Chen, Hao Xu, Wanyu Tao, Zhaoxiong Chen, Yuxuan Zhao, and Jing-Dong J Han.
516"
REFERENCES,0.9963963963963964,"Transformer for one stop interpretable cell type annotation. Nature Communications, 14(1):223,
517"
REFERENCES,0.9981981981981982,"2023.
518"
