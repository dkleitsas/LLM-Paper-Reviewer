Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0033783783783783786,"We present a differentiable approach to learn the probabilistic factors used for in-
ference by a nonparametric belief propagation algorithm. Existing nonparametric
belief propagation methods rely on domain-speciﬁc features encoded in the prob-
abilistic factors of a graphical model. In this work, we replace each crafted factor
with a differentiable neural network enabling the factors to be learned using an
efﬁcient optimization routine from labeled data. By combining differentiable neu-
ral networks with an efﬁcient belief propagation algorithm, our method learns to
maintain a set of marginal posterior samples using end-to-end training. We evalu-
ate our differentiable nonparametric belief propagation (DNBP) method on a set of
articulated pose tracking tasks and compare performance with learned baselines.
Results from these experiments demonstrate the effectiveness of using learned fac-
tors for tracking and suggest the practical advantage over hand-crafted approaches.
The project webpage is available at: https://sites.google.com/view/diff-nbp."
ABSTRACT,0.006756756756756757,"t −1
t"
ABSTRACT,0.010135135135135136,Nonparametric Graphical
ABSTRACT,0.013513513513513514,Model Inference
ABSTRACT,0.016891891891891893,Maximum Likelihood
ABSTRACT,0.02027027027027027,Estimation
ABSTRACT,0.02364864864864865,"Pose Estimates with 
Reported Uncertainty"
ABSTRACT,0.02702702702702703,Marginal Belief over Pose
ABSTRACT,0.030405405405405407,Oﬄine Gradient Descent
ABSTRACT,0.033783783783783786,L = −bel(x⇤)
ABSTRACT,0.037162162162162164,"Feature Extraction
Observation"
ABSTRACT,0.04054054054054054,Sequence
ABSTRACT,0.04391891891891892,Deep Neural Network
ABSTRACT,0.0472972972972973,Gradient
ABSTRACT,0.05067567567567568,"Figure 1: Architecture diagram of differentiable nonparametric belief propagation. DNBP combines domain
knowledge in the form of graphical models with differentiable neural networks for tractable inference in con-
tinuous spaces. Input features from a deep neural network and the probabilistic relationships encoded in a
graphical model are learned jointly in an end-to-end fashion using backpropagation. Following ofﬂine training,
DNBP can be applied to unseen data without hand-tuning."
INTRODUCTION,0.05405405405405406,"1
INTRODUCTION"
INTRODUCTION,0.057432432432432436,"A signiﬁcant challenge for robotic applications is the ability to estimate the pose of articulated
objects in high noise environments. Nonparametric belief propagation (NBP) algorithms (Sudderth
et al., 2003; Isard, 2003) have proven effective for inference in visual perception tasks such as human
pose tracking (Sigal et al., 2004) and articulated object tracking in robotic perception (Desingh et al.,
2019; Pavlasek et al., 2020). Moreover, these algorithms are able to account for uncertainty in
their estimates when environmental noise is high and show promising computational properties in
practice (Desingh et al., 2019; Ortiz et al., 2021). Their adaptability to new applications, however, is
limited by the need to deﬁne hand-crafted functions that describe the distinct statistical relationships
in a particular dataset. Current methods that utilize NBP rely on extensive domain knowledge to
parameterize these relationships. Reducing the domain knowledge required by NBP methods would
enable their use in a broader range of applications."
INTRODUCTION,0.060810810810810814,"As a form of probabilistic graphical model inference, NBP algorithms leverage domain knowledge
encoded in graph-based representations, such as the Markov random ﬁeld (MRF). Their capacity to"
INTRODUCTION,0.06418918918918919,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.06756756756756757,"perform inference using arbitrary graphs sets them apart from other algorithms such as the recursive
Bayes ﬁlter (Thrun et al., 2005) (e.g. particle ﬁlter (Godsill, 2019)) and has been shown to be impor-
tant in computational perception because it allows for modeling of non-causal relationships (Sud-
derth et al., 2003). Data-driven approaches are an alternative for computational perception (Xiang
et al., 2018; Tremblay et al., 2018). These methods generally avoid the need for extensive domain
knowledge by learning from large amounts of labelled data. Data-driven approaches, however, are
prone to noisy estimates and have limited capacity to represent uncertainty inherent in their esti-
mates. In robotic applications, both of these limitations negatively impact the ability for a robot to
operate effectively in unstructured environments."
INTRODUCTION,0.07094594594594594,"In this paper, we present a differentiable nonparametric belief propagation (DNBP) method, a hy-
brid approach which leverages neural networks to parameterize the NBP algorithm. Through dif-
ferentiable inference, DNBP leverages the explainability and robustness of probabilistic inference
techniques and capitalizes on the efﬁciency and generalizability of data-driven approaches. Inspired
by the differentiable particle ﬁlter (DPF) from Jonschkowski et al. (2018) and the pull message pass-
ing for nonparametric belief propagation (PMPNBP) algorithm (Desingh et al., 2019), we develop a
differentiable nonparametric belief propagation algorithm. DNBP performs end-to-end learning of
each probabilistic factor required for graphical model inference."
INTRODUCTION,0.07432432432432433,"The effectiveness of DNBP is demonstrated on two simulated articulated tracking tasks and on a
real-world hand pose tracking tasks in challenging noisy environments. An analysis of the learned
probabilistic factors and resulting tracking performance is used to validate the approach. Results
show that our approach can leverage the graph structure to report uncertainty about its estimates
while signiﬁcantly reducing the need for prior domain knowledge required by previous NBP meth-
ods. DNBP performs competitively in comparison to traditional learning-based approaches on the
tracking tasks. Collectively, these results indicate that DNBP has the potential to be successfully
applied to robotic perception tasks, where a notion of uncertainty in the inference is inevitable."
RELATED WORK,0.0777027027027027,"2
RELATED WORK"
RELATED WORK,0.08108108108108109,"Belief Propagation: In the context of graphical models, inference refers to the process in which
information about observed variables is used to derive the posterior distribution(s) of unobserved
variables. Belief propagation (BP) is a message passing algorithm for inference on graphical models.
BP computes exact marginal distributions on trees (Pearl, 1988), and has demonstrated empirical
success on loopy graphs (Murphy et al., 1999; Sun et al., 2003; Lee et al., 2008; Lan et al., 2006).
In order to apply inference techniques such as BP and LBP, the parameters of a graphical model
(e.g. the probabilistic factors) must be fully speciﬁed. Maximum likelihood estimation (MLE)
has been shown to be an effective approach for learning the parameters of a graphical model from
data (Murphy, 2012; Koller & Friedman, 2009; Ping & Ihler, 2017). In contrast, this current study
focuses on parameter learning for use with inference of continuous random variables."
RELATED WORK,0.08445945945945946,"Nonparametric Belief Propagation: For continuous spaces, such as six degrees-of-freedom object
pose, exact integrals called for in BP and LBP become intractable and approximate methods for
inference have been considered. Nonparametric belief propagation (NBP) methods (Isard, 2003;
Sudderth et al., 2003), have been proposed which represent the inferred marginal distributions using
mixtures of Gaussians and deﬁne efﬁcient message passing approximations for inference. Isard
(2003) demonstrated the effectiveness of PAMPAS using a set of synthetic visual datasets each
modeled with hand-crafted factors. Sudderth et al. (2003) applied their NBP method successfully
to a visual parts-based face localization task as well as a human hand tracking task (Sudderth et al.,
2004). In both applications, NBP relied on factor models which were chosen based on task-level
domain knowledge (e.g. valid conﬁgurations of human hands). Sigal et al. (2004) extended these
NBP methods to human pose estimation and tracking using factors which were each trained separate
from the inference algorithm using independent training objectives."
RELATED WORK,0.08783783783783784,"Ihler & McAllester (2009) described a conceptual theory of particle belief propagation, where mes-
sages being sent to inform the marginal of a particular variable could be generated using a shared
proposal distribution. Following the work of Ihler and McAllester, Desingh et al. (2019) presented
an efﬁcient “pull” message passing algorithm (PMPNBP) which uses a weighted particle set to ap-
proximate messages between random variables. PMPNBP was shown to be effective on robot pose
estimation tasks using hand-crafted factors. Using a similar approximation of belief propagation,"
RELATED WORK,0.09121621621621621,Under review as a conference paper at ICLR 2022
RELATED WORK,0.0945945945945946,"Pavlasek et al. (2020) took a step toward neural network-based potential functions by introducing
a pre-trained image segmentation network to the unary factors. An important limitation of these
works is they assume the probabilistic factors expressed in the graph are provided as input or rely on
domain knowledge to separately model and train each function. The potential for neural networks to
learn the parameters used by alternative inference techniques has been demonstrated (Do & Arti`eres,
2010; Tompson et al., 2014). The recent work of Xiong & Ruozzi (2020) demonstrated promising
inference performance on discrete classiﬁcation and synthetic datasets using learned probabilistic
factors with a Bethe free energy approximation. In contrast, this paper focuses on inference in high
dimensional continuous state spaces using learned probabilistic factors with the particle-based in-
ference process of NBP."
RELATED WORK,0.09797297297297297,"Differentiable Bayes Filtering: In the context of robot state estimation, many approaches have re-
cently been proposed that incorporate neural networks with recursive inference algorithms in an end-
to-end fashion. Haarnoja et al. (2016) introduced a differentiable Kalman ﬁlter, and Jonschkowski &
Brock (2016) proposed a differentiable, histogram-based Bayes ﬁlter algorithm. Jonschkowski et al.
(2018) and Karkus et al. (2018) both proposed differentiable particle ﬁlter algorithms for modeling
continuous state spaces. Kloss et al. (2021) evaluate recent differentiable ﬁltering techniques. Yi
et al. (2021) propose an end-to-end learning method for inference over factor-graph models. In con-
trast to these methods, which model a single object body using variants of the Bayes ﬁlter, this work
sets out to study the potential for NBP to be used as an algorithmic prior for modeling multi-part
articulated objects. Recently, this line of research on differentiable state estimation algorithms has
extended into the planning domain (Karkus et al., 2019; Wang et al., 2020; Anderson et al., 2019).
Exploration of embedding DNBP within a differentiable planning system is left as future work."
BELIEF PROPAGATION,0.10135135135135136,"3
BELIEF PROPAGATION"
BELIEF PROPAGATION,0.10472972972972973,"Consider a Markov Random Field (MRF) deﬁned by the undirected graph G = {V, E}, where V de-
notes a set of nodes and E denotes a set of edges. An example MRF model is shown in Fig. 2b. Each
node in V represents an observed (grey) or unobserved (white) random variable, while each edge
in E represents a pairwise relationship between two random variables in V. The joint probability
distribution for G is:"
BELIEF PROPAGATION,0.10810810810810811,"p(X, Y) = 1 Z Y"
BELIEF PROPAGATION,0.11148648648648649,"(s,d)∈E
ψsd(Xs, Xd)
Y"
BELIEF PROPAGATION,0.11486486486486487,"d∈V
φd(Xd, Yd)
(1)"
BELIEF PROPAGATION,0.11824324324324324,"where X = {Xd | d ∈V} is the set of unobserved variables and Y = {Yd | d ∈V} is the set of cor-
responding observed variables. The scalar Z is a normalizing constant. For each node, the function
φd(·) is the unary potential, describing the compatibility of Xd with a corresponding observed vari-
able Yd. For each edge, the function ψsd(·) is the pairwise potential, describing the compatibility
of neighboring variables Xs and Xd. This work considers MRF models limited to pairwise clique
potentials."
BELIEF PROPAGATION,0.12162162162162163,"Given the factorization of the joint distribution deﬁned in Eq. (1), BP provides an algorithm for in-
ference of the marginal posterior distributions, know as the beliefs, beld(Xd). BP deﬁnes a message
passing scheme for calculation of the beliefs as follows:"
BELIEF PROPAGATION,0.125,"beld(Xd) ∝φd(Xd, Yd)
Y"
BELIEF PROPAGATION,0.12837837837837837,"s∈ρ(d)
ms→d(Xd)
(2)"
BELIEF PROPAGATION,0.13175675675675674,where ρ(s) denotes the set of neighboring nodes of s. A message from node s to d is deﬁned as:
BELIEF PROPAGATION,0.13513513513513514,"ms→d(Xd) =
Z"
BELIEF PROPAGATION,0.13851351351351351,"Xs
φs(Xs, Ys) ψsd(Xs, Xd) ×
Y"
BELIEF PROPAGATION,0.14189189189189189,"u∈ρ(s)\d
mu→s(Xs) dXs
(3)"
BELIEF PROPAGATION,0.14527027027027026,"Performing inference of random variables in continuous space causes the integral in Eq. (3) to be-
come intractable. This motivates the use of efﬁcient algorithms that approximate the message pass-
ing scheme of Eq. (2) and Eq. (3)."
NONPARAMETRIC BELIEF PROPAGATION,0.14864864864864866,"3.1
NONPARAMETRIC BELIEF PROPAGATION"
NONPARAMETRIC BELIEF PROPAGATION,0.15202702702702703,"Nonparametric belief propagation (NBP) (Sudderth et al., 2003) uses Gaussian mixtures to repre-
sent the beliefs and messages for continuous random variables. Later works, including Ihler &"
NONPARAMETRIC BELIEF PROPAGATION,0.1554054054054054,Under review as a conference paper at ICLR 2022
NONPARAMETRIC BELIEF PROPAGATION,0.15878378378378377,"McAllester (2009) and Desingh et al. (2019), further improve upon the tractibility of approximate
nonparametric inference by representing beliefs and messages with sets of weighted particles. These
particle-based NBP methods infer an approximation of the beliefs using an iterative message pass-
ing algorithm, in which beliefs and messages are updated at each iteration t. In particular, Desingh
et al. (2019) avoid the expensive message generation of NBP by approximating Eq. (3) with a “pull”
strategy. A message, mt
s→d, outgoing from s to d, is generated by ﬁrst sampling M independent
samples from belt−1
d
(Xd) then reweighting and resampling from this set."
DIFFERENTIABLE NONPARAMETRIC BELIEF PROPAGATION,0.16216216216216217,"4
DIFFERENTIABLE NONPARAMETRIC BELIEF PROPAGATION"
DIFFERENTIABLE NONPARAMETRIC BELIEF PROPAGATION,0.16554054054054054,"We propose a differentiable nonparametric belief propagation (DNBP) method. DNBP maintains a
representation of the uncertainty in the estimate by efﬁciently approximating the marginal posterior
distributions encoded in an MRF. Our method avoids the need to deﬁne hand-crafted functions for
each domain by modeling the potentials needed for the computation of the distributions with neural
networks that are trained end-to-end. This hybrid generative-discriminative approach leverages the
strengths of both NBP and neural networks."
DIFFERENTIABLE NONPARAMETRIC BELIEF PROPAGATION,0.16891891891891891,"DNBP uses an iterative, differentiable message passing scheme to infer the beliefs over hidden
variables in an MRF. DNBP approximates the belief and messages in Eq. (2) and Eq. (3) at iteration
t by sets of N and M weighted particles respectively:"
DIFFERENTIABLE NONPARAMETRIC BELIEF PROPAGATION,0.17229729729729729,"belt
d(Xd) =
n
µ(i)
d , w(i)
d
oN"
DIFFERENTIABLE NONPARAMETRIC BELIEF PROPAGATION,0.17567567567567569,"i=1
(4)"
DIFFERENTIABLE NONPARAMETRIC BELIEF PROPAGATION,0.17905405405405406,"mt
s→d =
n
µ(i)
sd , w(i)
sd
oM"
DIFFERENTIABLE NONPARAMETRIC BELIEF PROPAGATION,0.18243243243243243,"i=1
(5)"
DIFFERENTIABLE NONPARAMETRIC BELIEF PROPAGATION,0.1858108108108108,"DNBP relies on a “pull” message passing strategy similar to the one presented by Desingh et al.
(2019). In this strategy, each iteration of the algorithm is deﬁned in terms of a message update
step and a belief update step. The message update generates a new set of message particles as a
reweighted set of samples from the previous iteration’s belief. Crucially, the weights associated
with these updated message samples result from learned probabilistic factors as opposed to hand-
crafted ones. Following a message update, the belief update combines information that is incoming
to each node from the newly generated messages. Pseudocode of DNBP’s message and belief update
schemes is included in Appendix A.1. The following sections describe the networks used to compute
the message and belief updates."
DIFFERENTIABLE NONPARAMETRIC BELIEF PROPAGATION,0.1891891891891892,"Unary Potential Functions: According to the factorization of the MRF joint distribution in Eq. (1),
each unobserved variable Xd, for d ∈V, is related to a corresponding observed variable Yd by the
unary potential function φd(Xd, Yd). DNBP models each unary function with a feedforward neural
network. The unary potential for a particle, xd, given an observed image, yd, is:"
DIFFERENTIABLE NONPARAMETRIC BELIEF PROPAGATION,0.19256756756756757,"φd(Xd = xd, Yd = yd) = ld (xd ⊕fd(yd))
(6)"
DIFFERENTIABLE NONPARAMETRIC BELIEF PROPAGATION,0.19594594594594594,"where fd is a convolutional neural network, ld is a fully connected neural network, and the sym-
bol ⊕denotes concatenation of feature vectors. Details of network architectures are given in Ap-
pendix A.2, Table 1."
DIFFERENTIABLE NONPARAMETRIC BELIEF PROPAGATION,0.19932432432432431,"Pairwise Potential Functions: For any pair of hidden variables, Xs and Xd, which are connected by
an edge in E, a pairwise potential function, ψsd(Xs, Xd), represents the probabilistic relationship
between the two variables. DNBP models each pairwise potential using a pair of feedforward,
fully connected neural networks, ψsd(Xs, Xd) = {ψρ
sd(·), ψ∼
sd(·)}. The pairwise density network,
ψρ
sd(·), evaluates the unnormalized potential for a pair of particles. The pairwise sampling network,
ψ∼
sd(·), is used to form samples of node s conditioned on node d and vice versa. Details of network
architectures are given in the Appendix A.2, Table 1. The weight computation is detailed in the
pseudocode in Appendix A.1."
DIFFERENTIABLE NONPARAMETRIC BELIEF PROPAGATION,0.20270270270270271,"Particle Diffusion: DNBP uses a learned particle diffusion model for each hidden variable, mod-
eled as distinct feedforward neural networks, τ ∼
d (·) for d ∈V. This diffusion model replaces the
Gaussian diffusion models typically used by particle-based inference methods. At the outset of mes-
sage generation at iteration t, DNBP’s belief particles from iteration t−1 are resampled then passed
through the diffusion model at the beginning of iteration t to form the messages used to update the
distributions at iteration t."
DIFFERENTIABLE NONPARAMETRIC BELIEF PROPAGATION,0.20608108108108109,Under review as a conference paper at ICLR 2022
DIFFERENTIABLE NONPARAMETRIC BELIEF PROPAGATION,0.20945945945945946,Base Joint
DIFFERENTIABLE NONPARAMETRIC BELIEF PROPAGATION,0.21283783783783783,Middle Joint
DIFFERENTIABLE NONPARAMETRIC BELIEF PROPAGATION,0.21621621621621623,End Effector (a) Yt 0 Yt 1 Yt 2 Xt 0 Xt 1 Xt 2
DIFFERENTIABLE NONPARAMETRIC BELIEF PROPAGATION,0.2195945945945946,"(b)
(c) Yt 5 Yt"
XT,0.22297297297297297,"2
Xt 5 Xt"
YT,0.22635135135135134,"2
Yt 0 Yt"
YT,0.22972972972972974,"3
Yt 6 Xt 0 Xt"
XT,0.23310810810810811,"3
Xt 6 Yt 4 Yt 1 Xt 4 Xt 1 (d)"
XT,0.23648648648648649,"Figure 2: a) Geometry and example conﬁguration of the double pendulum. b) Graphical model used by DNBP
for the double pendulum task. c) Geometry and an example conﬁguration of the spider structure. d) Graphical
model used by DNBP for the spider task."
XT,0.23986486486486486,"Particle Resampling: The ﬁnal operation of the belief update algorithm in NBP is a weighted re-
sampling of belief particles. This resampling operation is non-differentiable (Karkus et al., 2018;
Jonschkowski et al., 2018). It follows that the iterative belief update algorithm is non-differentiable
due to the resampling step. DNBP addresses the non-differentiability of the belief update algorithm
by relocating the resampling and diffusion operations to the beginning of the message update algo-
rithm. With this modiﬁcation, the belief update returns a weighted set of particles approximating
the marginal beliefs. The resulting belief density estimate is differentiable up to the beginning of the
message update, when particles from the previous iteration were resampled. The resulting algorithm
is differentiable through one belief update and message passing updates."
SUPERVISED TRAINING,0.24324324324324326,"4.1
SUPERVISED TRAINING"
SUPERVISED TRAINING,0.24662162162162163,"DNBP’s training approach is inspired by the work of Jonschkowski et al. (2018) with modiﬁcations
to enable learning the potential functions distinct to DNBP. During training, DNBP uses a set of
observation sequences, and a corresponding set of ground truth sequences. Using the observation
sequences, DNBP estimates belief of each unobserved variable at each sequence step. Then, by
maximizing estimated belief at the ground truth label of each unobserved variable, DNBP learns its
network parameters by maximum likelihood estimation. Further details regarding the implementa-
tion of the training procedure are discussed in Appendix A.2."
SUPERVISED TRAINING,0.25,"Objective Function: Given a set of weighted particles representing the belief of Xd produced by
the inference procedure at iteration t, the density of the belief can be expressed as a mixture of
Gaussians, with a component centered at each particle. The density of a sample xd can be computed
as follows:"
SUPERVISED TRAINING,0.2533783783783784,"bel
t
d(xd) = N
X"
SUPERVISED TRAINING,0.25675675675675674,"i=1
w(i)
d · N(xd; µ(i)
d , Σ)
(7)"
SUPERVISED TRAINING,0.26013513513513514,DNBP deﬁnes a loss function one each hidden node d ∈G as:
SUPERVISED TRAINING,0.2635135135135135,"Lt
d = −log(bel
t
d(xt,∗
d ))
(8)"
SUPERVISED TRAINING,0.2668918918918919,"where xt,∗
d
denotes the ground truth label for node d at sequence step t. The loss for each hidden
node is computed and optimized separately. At each sequence step during training, DNBP iterates
through the nodes of the graph, updating each node’s incoming messages and belief followed by a
single optimization step of Eq. (8) using stochastic gradient descent."
RESULTS,0.2702702702702703,"5
RESULTS"
RESULTS,0.27364864864864863,"The capability of DNBP is demonstrated on three challenging articulated tracking tasks. The ﬁrst
two tasks involve visually tracking the articulated joints of simulated articulated structures, as illus-
trated in Fig. 2. To increase the difﬁculty of these tasks, simulated clutter1 in the form of static and"
RESULTS,0.27702702702702703,"1In this work, clutter ratio is deﬁned as the ratio of pixels occluded by simulated clutter to the total number
of image pixels and is averaged over a full sequence of images."
RESULTS,0.28040540540540543,Under review as a conference paper at ICLR 2022
RESULTS,0.28378378378378377,"dynamic geometric shapes are rendered into the image sequences. In the second task, we evaluate
DNBP on its ability to track the articulated pose of human hands. In both experiments, DNBP is
directly compared to learned baseline approaches that are not NBP."
DATASETS,0.28716216216216217,"5.1
DATASETS"
DATASETS,0.2905405405405405,"Simulated Double Pendulum: To characterize DNBP’s tracking performance under chaotic mo-
tion, the double pendulum task was chosen as an initial evaluation. The double pendulum structure
consists of two revolute joints connected to two rigid-body links in series (see Fig. 2a for illus-
tration), which are acted on by gravity. The pose of the double pendulum is modeled by the 2-
dimensional position of its two revolute joints, rendered as yellow circles, and one end effector. The
training set on this task consists of 1024 total sequences with 20 frames per sequence while the vali-
dation set consists of 150 total sequences with 20 frames per sequence. Both training and validation
sequences are split evenly among three bins of clutter ratio: none, 0 to 0.04 and 0.04 to 0.1. Of the
training and validation sequences with any amount of clutter, half contain static clutter and the other
half contain dynamic clutter. The held-out test set is evenly split among clutter ratio deciles from 0
to 0.95, thus contains a shift in distribution from the training set, which was limited to clutter ratios
below 0.1. Each decile contains 50 sequences with 100 frames per sequence. For test sequences
with any amount of clutter, half contain static clutter and the other half contain dynamic clutter."
DATASETS,0.2939189189189189,"Simulated Articulated Spider: The spider task was chosen to further characterize DNBP’s per-
formance using a structure with added articulations and a larger graphical model. As depicted in
Fig. 2c, the spider is comprised of three revolute-prismatic joints, three purely revolute joints, and
six rigid-body links. An example of the spider is shown in Fig. 2c, in which the joints are rendered
as yellow circles and the rigid-body links are rendered as coloured rectangles. Unlike the double
pendulum, which contained a stationary base joint, the spider is not tethered to any position and
can move freely throughout the image under simulated joint control. The training, validation and
test set for this task follow the same respective distributions of clutter as were used in the double
pendulum datasets. The training set consists of 2, 048 total sequences and the validation set consists
of 300 sequences. The training and validation sequences are split evenly among ﬁve bins of clutter
ratio: none, 0 to 0.04 and 0.04 to 0.1, 0.1 to 0.2 and 0.2 to 0.3. There are 20 frames per sequence in
each of the spider datasets. Both simulated tasks use images of size 128 × 128 pixels. Ground truth
keypoint locations are represented as continuous valued coordinates scaled to range of [−1, +1]."
DATASETS,0.2972972972972973,"First-Person Hand Action Benchmark: The FPHAB dataset (Garcia-Hernando et al., 2018) con-
sists of RGB-D image sequences taken from the ﬁrst-person perspective. Thus, the dataset captures
the pose and motion of human hands as they perform typical actions. This is a challenging dataset
with extreme occlusions where complete observations of all the ﬁnger joints are rare. In total, there
are 1175 distinct sequences and 105459 individual image frames. Each image is labeled with the
3D position of 21 hand joints (illustration of joint relations shown in center column of Fig. 1).
The best-performing hand pose estimation baseline proposed by Garcia-Hernando et al. (2018) is
used for comparison in the current study. Just like Garcia-Hernando et al. (2018), DNBP uses only
depth observations. To ensure fair comparisons with the FPHAB baseline, this study follows the 1:1
cross-subject training protocol as described in FPHAB."
IMPLEMENTATION DETAILS,0.30067567567567566,"5.2
IMPLEMENTATION DETAILS"
IMPLEMENTATION DETAILS,0.30405405405405406,"On all three tasks, Adam (Kingma & Ba, 2015) is used for network optimization with a batch size
of 6 and models are trained until convergence of the validation loss. The graphs used by DNBP
are shown in Figs. 1, 2b and 2d. While DNBP uses tree-structured graphs in these experiments, the
inference strategy is compatible with graphs containing cycles. DNBP is trained using 100 particles
per message and tested using 200 particles per message. During training, one message update is
performed at each sequence step, while two message updates are used at test time. The pairwise
density, pairwise sampling and diffusion sampling processes of DNBP are deﬁned over the relative
translations between neighboring nodes. The maximum weighted particle from each marginal belief
set of DNBP is used during evaluation for comparison with the ground truth."
IMPLEMENTATION DETAILS,0.30743243243243246,"On both simulated tasks, DNBP is compared to an LSTM recurrent neural network (Hochreiter &
Schmidhuber, 1997). Both models use image inputs that are normalized channel-wise based on
training set statistics. The total number of trainable parameters between LSTM and DNBP were"
IMPLEMENTATION DETAILS,0.3108108108108108,Under review as a conference paper at ICLR 2022
IMPLEMENTATION DETAILS,0.3141891891891892,Average Euclidean Error
IMPLEMENTATION DETAILS,0.31756756756756754,(Pixels)
IMPLEMENTATION DETAILS,0.32094594594594594,Clutter Ratio
IMPLEMENTATION DETAILS,0.32432432432432434,"Figure 3: Average error of DNBP and LSTM
predictions as a function of clutter ratio and
keypoint type for double pendulum tracking."
IMPLEMENTATION DETAILS,0.3277027027027027,Clutter Ratio
IMPLEMENTATION DETAILS,0.3310810810810811,Average Euclidean Error
IMPLEMENTATION DETAILS,0.3344594594594595,(Pixels)
IMPLEMENTATION DETAILS,0.33783783783783783,"Figure 4: Average error of DNBP and LSTM
predictions as a function of clutter ratio for ar-
ticulated ‘spider’ tracking."
IMPLEMENTATION DETAILS,0.34121621621621623,"chosen to be similar. For hand tracking, the preprocessing protocol of Xiong et al. (2019), is fol-
lowed. Notably, preprocessing on the hand tracking task assumes ground truth bounding boxes to
ensure fair comparison with the baseline method published by Garcia-Hernando et al. (2018). Sim-
ilarly, the feature extractor used by DNBP in the following experiments was designed to emulate
the feature extractor of compared baseline. Details of network parameters and inspection of learned
relationships are included in the Appendices A.2 and A.6."
PERFORMANCE METRICS,0.34459459459459457,"5.3
PERFORMANCE METRICS"
PERFORMANCE METRICS,0.34797297297297297,"As a quantitative measure of tracking error, average Euclidean error is used. On the simulated tasks,
Euclidean error is averaged over all images in the test set. On the hand tracking task, Euclidean error
is averaged over all joints per frame then used to calculate the percent of frames satisfying variable
error thresholds as used by Garcia-Hernando et al. (2018)."
PERFORMANCE METRICS,0.35135135135135137,"Discrete entropy (Shannon, 1948) is used as a quantitative measure of uncertainty estimated by
DNBP. Discrete entropy is calculated by binning samples from each marginal belief set. For qual-
itative analysis of the uncertainty estimated by DNBP, samples from an approximation of the joint
posterior distribution (i.e. for collection of all unobserved variables) are formed using a sequential
Monte Carlo sampling approach (Naesseth et al., 2014). Visualization of these samples are formed
by plotting a rendered link between each pair of keypoint samples."
DOUBLE PENDULUM TRACKING RESULTS,0.3547297297297297,"5.4
DOUBLE PENDULUM TRACKING RESULTS"
DOUBLE PENDULUM TRACKING RESULTS,0.3581081081081081,"As shown in Fig. 3, the keypoint tracking error of DNBP is directly compared to that of the LSTM
baseline on the held-out test set for each keypoint type (base, middle and end effector) across the full
range of clutter ratios. Results from this comparison show that DNBP’s average keypoint tracking
error is comparable to the LSTM’s corresponding error for both the mid joint and end effector
keypoints, independent of clutter ratio. For the base joint keypoint, which is stationary at the center
position of every image, the LSTM was able to memorize the correct position. DNBP, which diffuses
particles based on the message passing scheme, does not memorize the base joint position and
registers a consistently larger error which increased with clutter ratio."
DOUBLE PENDULUM TRACKING RESULTS,0.3614864864864865,"DNBP provides measures of uncertainty associated with its predictions, which are generated ac-
cording to the algorithmic prior of belief propagation. Next tested was the hypothesis that the DNBP
model would generate increased uncertainty under conditions in which an occluding object is placed
into the input images such that it covers portions of the double pendulum. This test was performed
by rendering an occluding block onto a test sequence as shown in Fig. 5a-c. Under optimal condi-
tions, in which the pendulum is minimally occluded (< 25% by surface area), the model’s output
indicates a low level of uncertainty (see Fig. 5d,f,g.) for each keypoint and each frame. In contrast,
under conditions in which the pendulum is occluded by the superimposed object, the model’s output
indicates relatively high levels of uncertainty precisely at frames in which the superimposed object"
DOUBLE PENDULUM TRACKING RESULTS,0.36486486486486486,Under review as a conference paper at ICLR 2022
DOUBLE PENDULUM TRACKING RESULTS,0.36824324324324326,"Input
Marginal"
DOUBLE PENDULUM TRACKING RESULTS,0.3716216216216216,Entropy
DOUBLE PENDULUM TRACKING RESULTS,0.375,(Nats) Frame
DOUBLE PENDULUM TRACKING RESULTS,0.3783783783783784,"Frame 34
Frame 44
Frame 54"
DOUBLE PENDULUM TRACKING RESULTS,0.38175675675675674,"a.
b.
c."
DOUBLE PENDULUM TRACKING RESULTS,0.38513513513513514,"f.
e.
d. g. DNBP"
DOUBLE PENDULUM TRACKING RESULTS,0.3885135135135135,Predictions
DOUBLE PENDULUM TRACKING RESULTS,0.3918918918918919,"Figure 5:
Tracking of double pendulum by
DNBP under partial occlusion (orange block).
Uncertainty associated with predictions is
shown as samples from the joint distribution
in pink and blue (d,e,f). (g) Marginal entropy
for each keypoint across test sequence; base
keypoint (red), middle keypoint (green), end-
effector keypoint (blue). Sequence steps high-
lighted by gray correspond to images in which
> 25% of the pendulum is occluded."
DOUBLE PENDULUM TRACKING RESULTS,0.3952702702702703,"Ground Truth
LSTM"
DOUBLE PENDULUM TRACKING RESULTS,0.39864864864864863,Predictions
DOUBLE PENDULUM TRACKING RESULTS,0.40202702702702703,"Frame 1
Frame 10 DNBP"
DOUBLE PENDULUM TRACKING RESULTS,0.40540540540540543,Predictions
DOUBLE PENDULUM TRACKING RESULTS,0.40878378378378377,"Frame 20
a.
b.
c."
DOUBLE PENDULUM TRACKING RESULTS,0.41216216216216217,"d.
e.
f."
DOUBLE PENDULUM TRACKING RESULTS,0.4155405405405405,"g.
h.
i."
DOUBLE PENDULUM TRACKING RESULTS,0.4189189189189189,"Figure 6: Comparison of articulated ‘spider’
tracking by LSTM (d,e,f) and DNBP (g,h,i) un-
der cluttered conditions. Predicted and ground
truth keypoints shown as yellow circles. Clutter
shown as faded shapes for illustration to high-
light predictions."
DOUBLE PENDULUM TRACKING RESULTS,0.4222972972972973,"occludes a portion (> 25%) of the double pendulum (see Fig. 5e,g.). These results demonstrate that
the estimate of uncertainty produced by DNBP can identify predictions which are unreliable."
ARTICULATED SPIDER TRACKING RESULTS,0.42567567567567566,"5.5
ARTICULATED SPIDER TRACKING RESULTS"
ARTICULATED SPIDER TRACKING RESULTS,0.42905405405405406,"After having established the performance characteristics of DNBP on the relatively straightforward
double pendulum task, we next set out to determine DNBP’s capability for tracking more complex
structures. To this end, the 3-arm spider structure was used as a more challenging articulated pose
tracking task. Each model’s performance was quantitatively assessed on the held-out test set of the
articulated spider tracking task using the same approach as described for the double pendulum ex-
periment by varying clutter ratio (Fig. 4). Similar to the results of the double pendulum experiment,
average error on the spider task increases as a function of clutter ratio for both the LSTM and for
DNBP. For clutter ratios between 0 and 0.25, average error for both models remains near 6 pixels
then increases consistently with clutter ratio, reaching above 30 pixels of average error for clutter
ratios above 0.85. As in the case of the double pendulum experiment, these results demonstrate
comparable performance between LSTM and DNBP on an articulated pose tracking task."
ARTICULATED SPIDER TRACKING RESULTS,0.43243243243243246,"Next, a qualitative example of tracking performance under conditions of clutter is shown in Fig. 6.
In Fig. 6(a-c), the ground truth pose is shown amidst distracting shapes across selected frames of a
test sequence with clutter ratio of 0.25. Pose predictions generated by LSTM are shown in Fig. 6(d-
f) and by DNBP in (g-i). Qualitative assessment of the images indicates both the LSTM and DNBP
place their predictions in the correct region of the image. Additionally, each model is shown to
correctly predict the relative positions of the three arms. Over the sequence, both models track the
motion of each keypoint, however appear to struggle with certain keypoint predictions."
HUMAN HAND TRACKING RESULTS,0.4358108108108108,"5.6
HUMAN HAND TRACKING RESULTS"
HUMAN HAND TRACKING RESULTS,0.4391891891891892,"To evaluate DNBP’s capability for application to real-world tasks, the algorithm’s state estimation
and tracking performance was evaluated on the FPHAB dataset. This is a challenging dataset with
extreme occlusions where complete observations of all the ﬁnger joints are rare. Firstly, Euclidean"
HUMAN HAND TRACKING RESULTS,0.44256756756756754,Under review as a conference paper at ICLR 2022
HUMAN HAND TRACKING RESULTS,0.44594594594594594,Ground
HUMAN HAND TRACKING RESULTS,0.44932432432432434,"Truth
Estimate
Thumb 
Uncertainty"
HUMAN HAND TRACKING RESULTS,0.4527027027027027,"Index 
Uncertainty"
HUMAN HAND TRACKING RESULTS,0.4560810810810811,"Middle 
Uncertainty"
HUMAN HAND TRACKING RESULTS,0.4594594594594595,"Ring 
Uncertainty"
HUMAN HAND TRACKING RESULTS,0.46283783783783783,"Pinky 
Uncertainty"
HUMAN HAND TRACKING RESULTS,0.46621621621621623,Figure 7: Output from DNBP on randomly sampled frames. See Appendix A.7 for more examples.
HUMAN HAND TRACKING RESULTS,0.46959459459459457,"Error Threshold 
(mm)
✏"
HUMAN HAND TRACKING RESULTS,0.47297297297297297,Percentage of Frames
HUMAN HAND TRACKING RESULTS,0.47635135135135137,with error < ✏
HUMAN HAND TRACKING RESULTS,0.4797297297297297,"Figure 8: Quantitative comparison between DNBP and neural network baseline on hand pose tracking task
of the FPHAB dataset. For each model the percent of frames with predicted pose less than a set threshold is
calculated as the threshold is varied from 0mm to 80mm."
HUMAN HAND TRACKING RESULTS,0.4831081081081081,"error between the estimated and ground truth pose is measured for every frame in the test set. For this
ﬁrst evaluation, DNBP is applied as a frame-by-frame estimator without maintaining its belief over
time. The quantitative results from this experiment, are included in Fig. 8 with direct comparison to
a pure neural network baseline. The results from this experiment indicate that for error thresholds
below 50mm, DNBP will consistently have an accuracy of 95% and above."
HUMAN HAND TRACKING RESULTS,0.4864864864864865,"Following the comparison against a state of the art baseline, it was hypothesized that DNBP’s per-
formance would improve when applied as a tracking method which maintains belief over time. To
perform this test, DNBP was applied sequentially to each test sequence and evaluated under the
same error metric. The result from this test, as shown in Fig. 8, demonstrates that DNBP does im-
prove in terms of frame error when allowed to track its uncertainty over time. Qualitative examples
(on frames from randomly chosen sequences) showing DNBP’s tracking performance are shown
in Fig. 7 and Appendix A.7. The tracking videos showing the DNBP’s estimates and belief are in-
cluded in the supplementary material and project webpage: https://sites.google.com/view/diff-nbp."
CONCLUSION,0.48986486486486486,"6
CONCLUSION"
CONCLUSION,0.49324324324324326,"In this work, we proposed a novel formulation of belief propagation which is differentiable and
uses a nonparametric representation of belief. It was hypothesized that combining maximum like-
lihood estimation with the nonparametric inference approach would enable end-to-end learning of
the probabilistic factors needed for inference. Results on both qualitative and quantitative exper-
iments demonstrate successful application of this approach and highlight the capability of DNBP
to estimate useful measures of uncertainty, which are crucial for applications where incorrect esti-
mates lead to catastrophic decisions, such as robotics. The current approach is limited by its use of
non-differentiable resampling and its demand for a graph model as input. Exploration of methods to
overcome these limitations, such as by incorporating a soft-resampling strategy Karkus et al. (2018),
are left as future work."
CONCLUSION,0.4966216216216216,Under review as a conference paper at ICLR 2022
REFERENCES,0.5,REFERENCES
REFERENCES,0.5033783783783784,"Peter Anderson, Ayush Shrivastava, Devi Parikh, Dhruv Batra, and Stefan Lee. Chasing ghosts:
Instruction following as Bayesian state tracking. In Advances in Neural Information Processing
Systems, pp. 369–379, 2019."
REFERENCES,0.5067567567567568,"Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and
Wojciech Zaremba. Openai gym, 2016."
REFERENCES,0.5101351351351351,"Alex Clark. Pillow (pil fork) documentation, 2015."
REFERENCES,0.5135135135135135,"Karthik Desingh, Shiyang Lu, Anthony Opipari, and Odest Chadwicke Jenkins. Efﬁcient nonpara-
metric belief propagation for pose estimation and manipulation of articulated objects. Science
Robotics, 4(30), 2019. doi: 10.1126/scirobotics.aaw4523."
REFERENCES,0.5168918918918919,"Trinh Minh Tri Do and Thierry Arti`eres. Neural conditional random ﬁelds. In Yee Whye Teh and
D. Mike Titterington (eds.), Proceedings of the Thirteenth International Conference on Artiﬁcial
Intelligence and Statistics, AISTATS 2010, Chia Laguna Resort, Sardinia, Italy, May 13-15, 2010,
volume 9 of JMLR Proceedings, pp. 177–184. JMLR.org, 2010."
REFERENCES,0.5202702702702703,"Guillermo Garcia-Hernando, Shanxin Yuan, Seungryul Baek, and Tae-Kyun Kim. First-person hand
action benchmark with rgb-d videos and 3d hand pose annotations. In Proceedings of Computer
Vision and Pattern Recognition (CVPR), 2018."
REFERENCES,0.5236486486486487,"S. Godsill. Particle ﬁltering: the ﬁrst 25 years and beyond. In International Conference on Acoustics,
Speech and Signal Processing (ICASSP), pp. 7760–7764. IEEE, 2019. doi: 10.1109/ICASSP.
2019.8683411."
REFERENCES,0.527027027027027,"Tuomas Haarnoja, Anurag Ajay, Sergey Levine, and Pieter Abbeel. Backprop KF: learning discrim-
inative deterministic state estimators. In Advances in Neural Information Processing Systems, pp.
4376–4384, 2016."
REFERENCES,0.5304054054054054,"Sepp Hochreiter and J¨urgen Schmidhuber. Long short-term memory. Neural Comput., 9(8):1735–
1780, 1997. doi: 10.1162/neco.1997.9.8.1735."
REFERENCES,0.5337837837837838,"Alexander Ihler and David McAllester. Particle belief propagation. In Artiﬁcial Intelligence and
Statistics, pp. 256–263, 2009."
REFERENCES,0.5371621621621622,"Michael Isard. PAMPAS: Real-valued graphical models for computer vision. In Conference on
Computer Vision and Pattern Recognition (CVPR). IEEE Computer Society, 2003."
REFERENCES,0.5405405405405406,"Rico Jonschkowski and Oliver Brock. End-to-end learnable histogram ﬁlters. In Workshop on Deep
Learning for Action and Interaction at NeurIPS, December 2016."
REFERENCES,0.543918918918919,"Rico Jonschkowski, Divyam Rastogi, and Oliver Brock. Differentiable particle ﬁlters: End-to-end
learning with algorithmic priors. In Robotics: Science and Systems (RSS), 2018. doi: 10.15607/
RSS.2018.XIV.001."
REFERENCES,0.5472972972972973,"P´eter Karkus, David Hsu, and Wee Sun Lee. Particle ﬁlter networks with application to visual
localization. In Conference on Robot Learning (CoRL), volume 87, pp. 169–178. PMLR, 2018."
REFERENCES,0.5506756756756757,"P´eter Karkus, Xiao Ma, David Hsu, Leslie Pack Kaelbling, Wee Sun Lee, and Tom´as Lozano-
P´erez. Differentiable algorithm networks for composable robot learning. In Robotics: Science
and Systems, 2019. doi: 10.15607/RSS.2019.XV.039."
REFERENCES,0.5540540540540541,"Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Yoshua Bengio
and Yann LeCun (eds.), 3rd International Conference on Learning Representations, ICLR 2015,
San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015."
REFERENCES,0.5574324324324325,"Alina Kloss, Georg Martius, and Jeannette Bohg. How to train your differentiable ﬁlter. Autonomous
Robots, pp. 1–18, 2021."
REFERENCES,0.5608108108108109,"Daphne Koller and Nir Friedman. Probabilistic Graphical Models - Principles and Techniques. MIT
Press, 2009. ISBN 978-0-262-01319-2."
REFERENCES,0.5641891891891891,Under review as a conference paper at ICLR 2022
REFERENCES,0.5675675675675675,"Xiangyang Lan, Stefan Roth, Daniel P. Huttenlocher, and Michael J. Black. Efﬁcient belief prop-
agation with learned higher-order markov random ﬁelds. In European Conference on Computer
Vision (ECCV), volume 3952 of Lecture Notes in Computer Science, pp. 269–282. Springer, 2006.
doi: 10.1007/11744047\ 21."
REFERENCES,0.5709459459459459,"Kuang-chih Lee, Dragomir Anguelov, Baris Sumengen, and Salih Burak G¨okt¨urk. Markov random
ﬁeld models for hair and face segmentation. In International Conference on Automatic Face and
Gesture Recognition (FG 2008), pp. 1–6. IEEE Computer Society, 2008. doi: 10.1109/AFGR.
2008.4813431."
REFERENCES,0.5743243243243243,"Kevin P. Murphy. Machine learning - a probabilistic perspective. Adaptive computation and ma-
chine learning series. MIT Press, 2012. ISBN 0262018020."
REFERENCES,0.5777027027027027,"Kevin P. Murphy, Yair Weiss, and Michael I. Jordan. Loopy belief propagation for approximate
inference: An empirical study. In Conference on Uncertainty in Artiﬁcial Intelligence (UAI), pp.
467–475. Morgan Kaufmann, 1999."
REFERENCES,0.581081081081081,"Christian A. Naesseth, Fredrik Lindsten, and Thomas B. Sch¨on. Sequential Monte Carlo for graph-
ical models. In Advances in Neural Information Processing Systems, pp. 1862–1870, 2014."
REFERENCES,0.5844594594594594,"Joseph Ortiz, Talfan Evans, and Andrew J. Davison. A visual introduction to gaussian belief propa-
gation. arXiv preprint arXiv:2107.02308, 2021."
REFERENCES,0.5878378378378378,"Jana Pavlasek, Stanley Lewis, Karthik Desingh, and Odest Chadwicke Jenkins. Parts-based ar-
ticulated object localization in clutter using belief propagation. In International Conference on
Intelligent Robots and Systems (IROS). IEEE, 2020."
REFERENCES,0.5912162162162162,"Judea Pearl. Chapter 4 - belief updating by network propagation. In Judea Pearl (ed.), Probabilistic
Reasoning in Intelligent Systems, pp. 143 – 237. Morgan Kaufmann, San Francisco (CA), 1988.
ISBN 978-0-08-051489-5. doi: https://doi.org/10.1016/B978-0-08-051489-5.50010-2."
REFERENCES,0.5945945945945946,"Wei Ping and Alexander T. Ihler. Belief propagation in conditional rbms for structured prediction.
In Aarti Singh and Xiaojin (Jerry) Zhu (eds.), Proceedings of the 20th International Conference
on Artiﬁcial Intelligence and Statistics, AISTATS 2017, 20-22 April 2017, Fort Lauderdale, FL,
USA, volume 54 of Proceedings of Machine Learning Research, pp. 1141–1149. PMLR, 2017."
REFERENCES,0.597972972972973,"Claude E. Shannon. A mathematical theory of communication. Bell Syst. Tech. J., 27(3):379–423,
1948. doi: 10.1002/j.1538-7305.1948.tb01338.x."
REFERENCES,0.6013513513513513,"Leonid Sigal, Sidharth Bhatia, Stefan Roth, Michael J. Black, and Michael Isard. Tracking loose-
limbed people. In Computer Vision and Pattern Recognition (CVPR), pp. 421–428. IEEE Com-
puter Society, 2004. doi: 10.1109/CVPR.2004.252."
REFERENCES,0.6047297297297297,"Erik B. Sudderth, Alexander T. Ihler, William T. Freeman, and Alan S. Willsky. Nonparametric
belief propagation. In Computer Vision and Pattern Recognition (CVPR), pp. 605–612. IEEE
Computer Society, 2003. doi: 10.1109/CVPR.2003.1211409."
REFERENCES,0.6081081081081081,"Erik B Sudderth, Michael I Mandel, William T Freeman, and Alan S Willsky. Visual hand tracking
using nonparametric belief propagation. In IEEE Conference on Computer Vision and Pattern
Recognition Workshop (CVPRW’04), pp. 189–189, 2004."
REFERENCES,0.6114864864864865,"Jian Sun, Nanning Zheng, and Heung-Yeung Shum. Stereo matching using belief propagation. IEEE
Trans. Pattern Anal. Mach. Intell., 25(7):787–800, 2003. doi: 10.1109/TPAMI.2003.1206509."
REFERENCES,0.6148648648648649,"Sebastian Thrun, Wolfram Burgard, and Dieter Fox. Probabilistic Robotics. MIT Press, 2005. ISBN
978-0-262-20162-9."
REFERENCES,0.6182432432432432,"Jonathan Tompson, Arjun Jain, Yann LeCun, and Christoph Bregler. Joint training of a convolutional
network and a graphical model for human pose estimation. In Advances in Neural Information
Processing Systems, pp. 1799–1807, 2014."
REFERENCES,0.6216216216216216,"Jonathan Tremblay, Thang To, Balakumar Sundaralingam, Yu Xiang, Dieter Fox, and Stan Birch-
ﬁeld. Deep object pose estimation for semantic robotic grasping of household objects. In Confer-
ence on Robot Learning (CoRL), 2018."
REFERENCES,0.625,Under review as a conference paper at ICLR 2022
REFERENCES,0.6283783783783784,"Yunbo Wang, Bo Liu, Jiajun Wu, Yuke Zhu, Simon S. Du, Fei-Fei Li, and Joshua B. Tenenbaum.
Dualsmc: Tunneling differentiable ﬁltering and planning under continuous pomdps. In Interna-
tional Joint Conference on Artiﬁcial Intelligence (IJCAI), pp. 4190–4198. ijcai.org, 2020. doi:
10.24963/ijcai.2020/579."
REFERENCES,0.6317567567567568,"Yu Xiang, Tanner Schmidt, Venkatraman Narayanan, and Dieter Fox. PoseCNN: A convolutional
neural network for 6D object pose estimation in cluttered scenes.
In Robotics: Science and
Systems (RSS), 2018."
REFERENCES,0.6351351351351351,"Fu Xiong, Boshen Zhang, Yang Xiao, Zhiguo Cao, Taidong Yu, Joey Zhou Tianyi, and Junsong
Yuan. A2j: Anchor-to-joint regression network for 3d articulated pose estimation from a single
depth image. In International Conference on Computer Vision (ICCV), 2019."
REFERENCES,0.6385135135135135,"Hao Xiong and Nicholas Ruozzi. General purpose MRF learning with neural network potentials.
In Christian Bessiere (ed.), Proceedings of the Twenty-Ninth International Joint Conference on
Artiﬁcial Intelligence, IJCAI 2020, pp. 2769–2776. ijcai.org, 2020. doi: 10.24963/ijcai.2020/384."
REFERENCES,0.6418918918918919,"Qianru Ye, Shanxin Yuan, and Tae-Kyun Kim. Spatial attention deep net with partial pso for hierar-
chical hybrid hand pose estimation. In ECCV, 2016."
REFERENCES,0.6452702702702703,"Brent Yi, Michelle Lee, Alina Kloss, Roberto Mart´ın-Mart´ın, and Jeannette Bohg. Differentiable
factor graph optimization for learning smoothers.
In International Conference on Intelligent
Robots and Systems (IROS). IEEE, 2021."
REFERENCES,0.6486486486486487,Under review as a conference paper at ICLR 2022
REFERENCES,0.652027027027027,"A
APPENDIX"
REFERENCES,0.6554054054054054,"A.1
ALGORITHM PSEUDOCODE"
REFERENCES,0.6587837837837838,"In this section, pseudo code of the DNBP message passing algorithm is given for reference. As
discussed in Section 4, this algorithm is a differentiable variant of the PMPNBP algorithm Desingh
et al. (2019)."
REFERENCES,0.6621621621621622,Algorithm 1: Message update
REFERENCES,0.6655405405405406,"input : Belief set beln−1
d
(Xd) = {(w(i)
d , µ(i)
d )}T
i=1
Incoming messages mn−1
u→s(Xs) = {(w(i)
us, µ(i)
us)}M
i=1 for each node u ∈ρ(s) \ d
output: Outgoing messages, mn
s→d(Xd) = {(µ(i)
sd , w(i)
sd )}M
i=1"
REFERENCES,0.668918918918919,"1 Draw (1 −γn−1) · M independent samples from beln−1
d
(Xd)"
REFERENCES,0.6722972972972973,"{µ(i)
sd ←beln−1
d
(Xd)}(1−γn−1)·M
i=1
;"
APPLY PARTICLE DIFFUSION TO EACH SAMPLED PARTICLE,0.6756756756756757,"2 Apply particle diffusion to each sampled particle
µ(i)
sd = µ(i)
sd + τd(ϵ);"
APPLY PARTICLE DIFFUSION TO EACH SAMPLED PARTICLE,0.6790540540540541,3 Draw remaining γn−1 · M samples independently from uniform proposal distribution;
APPLY PARTICLE DIFFUSION TO EACH SAMPLED PARTICLE,0.6824324324324325,"4 foreach {µ(i)
sd }M
i=1 do"
APPLY PARTICLE DIFFUSION TO EACH SAMPLED PARTICLE,0.6858108108108109,"5
for ℓ= [1 : U] do"
APPLY PARTICLE DIFFUSION TO EACH SAMPLED PARTICLE,0.6891891891891891,"6
Sample ˆ
Xs
(i) ∼ψsd(Xs, Xd = µ(i)
sd );"
APPLY PARTICLE DIFFUSION TO EACH SAMPLED PARTICLE,0.6925675675675675,"7
w(i)
unary = w(i)
unary + φs(Xs = ˆ
Xs
(i), Ys);"
END,0.6959459459459459,"8
end"
END,0.6993243243243243,"9
w(i)
unary =
w(i)
unary U
;"
END,0.7027027027027027,"10
foreach u ∈ρ(s) \ d do"
END,0.706081081081081,"11
W (i)
u
=
M
P"
END,0.7094594594594594,"j=1
w(j)
us × w(ij)
u
where w(ij)
u
= ψsd(Xs = µ(j)
us , Xd = µ(i)
sd );"
END,0.7128378378378378,"12
end"
END,0.7162162162162162,"13
w(i)
neigh =
Q"
END,0.7195945945945946,"u∈ρ(s)\d
W (i)
u ;"
END,0.722972972972973,"14
w(i)
sd = w(i)
unary × w(i)
neigh;"
END,0.7263513513513513,15 end
END,0.7297297297297297,"16 Associate {w(i)
sd }M
i=1 with {µ(i)
sd }M
i=1 to form outgoing mn
s→d(Xd);"
END,0.7331081081081081,Algorithm 2: Belief update
END,0.7364864864864865,"input : Incoming messages, mn
s→d(Xd) = {(w(i)
sd , µ(i)
sd )}M
i=1, for each node s ∈ρ(d)
output: Belief set beln
d(Xd) = {(w(i)
d , µ(i)
d )}T
i=1"
END,0.7398648648648649,1 foreach s ∈ρ(d) do
UPDATE MESSAGE WEIGHTS,0.7432432432432432,"2
Update message weights
w(i)
sd = w(i)
sd × φd(Xd = µ(i)
sd , Yd) for i ∈[1 : M];"
NORMALIZE MESSAGE WEIGHTS,0.7466216216216216,"3
Normalize message weights"
NORMALIZE MESSAGE WEIGHTS,0.75,"w(i)
sd =
w(i)
sd
M
P"
NORMALIZE MESSAGE WEIGHTS,0.7533783783783784,"j=1
w(j)
sd
for i ∈[1 : M];"
END,0.7567567567567568,4 end
FORM BELIEF SET BELN,0.7601351351351351,"5 Form belief set beln
d(Xd) =
S"
FORM BELIEF SET BELN,0.7635135135135135,"s∈ρ(d)
mn
s→d(Xd);"
NORMALIZE BELIEF WEIGHTS,0.7668918918918919,6 Normalize belief weights
NORMALIZE BELIEF WEIGHTS,0.7702702702702703,"w(i)
d
=
w(i)
d
PT
j=1 w(j)
d
for i ∈[1 : T];"
NORMALIZE BELIEF WEIGHTS,0.7736486486486487,Under review as a conference paper at ICLR 2022
NORMALIZE BELIEF WEIGHTS,0.777027027027027,"Table 1: Network parameters of learned DNBP potential functions used on both simulated articu-
lated tracking tasks. Note s, d ∈V, and (s, d) ∈E. Unary potentials: ls(fs(·)). Pairwise potentials:
{ψρ
sd, ψ∼
sd}. Particle diffusion: τ ∼
s ."
NORMALIZE BELIEF WEIGHTS,0.7804054054054054,"NETWORK
UNIT LAYERS"
NORMALIZE BELIEF WEIGHTS,0.7837837837837838,"fs
5 x [conv(3x3, 10, stride=2, ReLU), maxpool(2x2, 2)]
ls
2 x fc(64, ReLU), fc(1, Sigmoid scaled to [0.005, 1])
ψρ
sd
4 x fc(32, ReLU), fc(1, Sigmoid scaled to [0.005, 1])
ψ∼
sd
2 x fc(64, ReLU), fc(2)
τ ∼
s
2 x fc(64, ReLU), fc(2)"
NORMALIZE BELIEF WEIGHTS,0.7871621621621622,"Results in this work were generated with U set to 10, while past related work (Desingh et al., 2019)
used U = 1. It was observed that this modiﬁcation improved training stability during preliminary
development. Note that γ is a hyperparameter that controls the resampling strategy and is set to 0.9
in our experiments. γ is used only during training; during evaluation, all M samples are drawn from
beln−1
d
(Xd)."
NORMALIZE BELIEF WEIGHTS,0.7905405405405406,"A.2
NETWORK ARCHITECTURE & TRAINING"
NORMALIZE BELIEF WEIGHTS,0.793918918918919,"For both simulated articulated tracking tasks, the network architecture for each sub-network de-
scribed in Section 4 is summarized in Table 1. For the hand tracking task, each network follows
the same structure as those in Table 1, with two exceptions: (1) the feature extractor, fs(·), used for
hand tracking is based on the architecture used by the FPHAB baseline that was introduced by Ye
et al. (2016). (2) each node likelihood network, ls(·), has one additional feature reduction layer of
[fc(64, BatchNorm,ReLU)] preceeding the layers of the corresponding network in Table 1."
NORMALIZE BELIEF WEIGHTS,0.7972972972972973,"The following sections describe speciﬁc implementation details used in the supervised training of
DNBP. To ensure independence from spatial location, the pairwise density, pairwise sampling and
diffusion sampling processes of DNBP are deﬁned over the space of transformations between vari-
ables. Specifically, each of these networks takes as input or produces as output a translation between
samples of their corresponding random variables."
NORMALIZE BELIEF WEIGHTS,0.8006756756756757,"Gradient Decoupling: The belief weight, wt,(i)
d
, of particle i is proportional to the product of com-
ponent weights, wt,(i)
unaryd ×wt,(i)
unarys ×wt,(i)
neighs, where s is the neighbor of node d from which particle
i originated (see Algorithm 2). Since each of these component weights is produced by a separate
potential network (either φd, ψ∼
sd, or ψρ
sd respectively), direct optimization of the belief density will
lead to interdependence of the potential network gradients during training. In the context of DNBP,
interdependence between different potential functions is inconsistent with the factorization given in
G. Tompson et al. (2014) describe a similar phenomenon they refer to as gradient coupling which
was addressed by expressing a product of features in log-space which “decouples” the gradients."
NORMALIZE BELIEF WEIGHTS,0.8040540540540541,"To avoid interdependence between potential functions during training, we consider the partial-belief
densities which are deﬁned for each node d ∈V as mixtures of Gaussian density functions:"
NORMALIZE BELIEF WEIGHTS,0.8074324324324325,"bel
t
d,unaryd(Xd) = N
X"
NORMALIZE BELIEF WEIGHTS,0.8108108108108109,"i=1
wt,(i)
unaryd · N(Xd; µ(i)
d , Σ)
(9)"
NORMALIZE BELIEF WEIGHTS,0.8141891891891891,"bel
t
d,unaryρ(d)(Xd) = N
X"
NORMALIZE BELIEF WEIGHTS,0.8175675675675675,"i=1
wt,(i)
unarys · N(Xd; µ(i)
d , Σ)
(10)"
NORMALIZE BELIEF WEIGHTS,0.8209459459459459,"bel
t
d,neighρ(d)(Xd) = N
X"
NORMALIZE BELIEF WEIGHTS,0.8243243243243243,"i=1
wt,(i)
neighs · N(Xd; µ(i)
d , Σ)
(11)"
NORMALIZE BELIEF WEIGHTS,0.8277027027027027,"Using these deﬁnitions, direct interaction between the potential networks’ gradients is avoided by
maximizing the product of partial-beliefs at the ground truth of each node in log space. The product
of partial-beliefs is deﬁned:"
NORMALIZE BELIEF WEIGHTS,0.831081081081081,"bel
t
d(Xd) = bel
t
d,unaryd(Xd) × bel
t
d,unaryρ(d)(Xd) × bel
t
d,neighρ(d)(Xd)
(12)"
NORMALIZE BELIEF WEIGHTS,0.8344594594594594,Under review as a conference paper at ICLR 2022
NORMALIZE BELIEF WEIGHTS,0.8378378378378378,"Unary Potentials: During training of DNBP, only those gradients derived from the belief update
of each node are used to update the corresponding node’s unary potential network parameters. Any
gradients derived from the outgoing messages of a particular node are manually stopped from prop-
agating to that node’s unary network. This is done to avoid confounding the objective functions
of neighboring nodes, which each rely on the others’ unary network during message passing. This
approach can be implemented with standard deep learning frameworks by dynamically stopping the
parameter update of each unary network depending on where in the algorithm its forward pass was
registered."
NORMALIZE BELIEF WEIGHTS,0.8412162162162162,"Pairwise Density Networks: To speed up and stabilize the training of pairwise density potential
networks, the following substitution is made during training. While calculating w(i)
sd for outgoing
message i from node s to d, the summation over incoming messages from u ∈ρ(s) to s is replaced
by a single evaluation of:
W (i)
u
= ψsd(Xs = x∗
s, Xd = µ(i)
sd )
(13)
where x∗
s is the ground truth label of sender node s. This change improves inference time and
reduces memory demands by removing a summation over M particles while also providing more
stable training feedback to the network. This substitution is removed at test time after training is
complete."
NORMALIZE BELIEF WEIGHTS,0.8445945945945946,"Pairwise Sampling Networks: The pairwise sampling networks, ψ∼
s,d, take a random sample of
Gaussian noise as input and generate conditional samples using the following rule:"
NORMALIZE BELIEF WEIGHTS,0.847972972972973,"ϵ ∼N(0, 1)
(14)
xs|d = xd + ψ∼
s,d(ϵ)
(15)"
NORMALIZE BELIEF WEIGHTS,0.8513513513513513,"where xs|d is the sample of variable Xs conditioned on neighboring sample xd and where ϵ is
a noise vector sampled from a zero-mean, unit variance multivariate Gaussian distribution with
dim(ϵ) = 64. Similarly, for sampling in the opposite conditioning direction (node d conditioned on
s), memory efﬁciency is gained by reusing the ψ∼
s,d network but negating the sampled translation."
NORMALIZE BELIEF WEIGHTS,0.8547297297297297,"A.3
DOUBLE PENDULUM CLUTTER"
NORMALIZE BELIEF WEIGHTS,0.8581081081081081,"As summarized in Section 5.1, the double pendulum dataset was generated using a modiﬁed ver-
sion of the OpenAI Brockman et al. (2016) Acrobot environment. Synthetic geometric shapes are
rendered into each image of the dataset to simulate noisy, cluttered environments. All simulated
clutter on the double pendulum task is generated according to the following parameters: 50% of
clutter is rendered visually beneath the pendulum while the remaining 50% is rendered on top of
the pendulum. For dynamic clutter, each geometry simulates motion using a random, constant posi-
tion velocity ( ˙x, ˙y) and orientation velocity ( ˙θ). Position velocities are sampled from N(0, 0.025).
Orientation velocities are sampled from N(0, 0.05). Clutter is simulated as either rectangles with
80% probability or circles with 20% probability. Clutter rectangles are sized randomly with length
of max(0, l ∼N(0.2, 0.05)) and height of max(0, h ∼N(0.8, 0.2)). Color of clutter rectangles is
randomly chosen with RGB of (0, 204, 204) or (245, 87, 77). Clutter circles are sized randomly with
radius of max(0, r ∼N(0.1, 0.1)) and colored randomly with RGB of (204, 204, 0) or (96, 217, 63).
Size and color distributions were chosen to ensure clutter visually resembles the double pendulum
parts. The position of each clutter geometry was randomly initialized within 1.5x the extent of the
image boundary."
NORMALIZE BELIEF WEIGHTS,0.8614864864864865,"The training and validation datasets were distributed evenly among clutter ratios of [0, 0 −0.04,
and 0.04 −0.1]. For the training/validation sequences that included clutter, the number of clutters
rendered beneath and on top of the double pendulum was individually randomly sampled from
independent Binomial distributions using n = 15, p = 0.3. To generate the test set, which was
uniformly distributed among clutter ratios as described in Section 5.1, rejection sampling was used
with variable numbers of rendered geometries."
NORMALIZE BELIEF WEIGHTS,0.8648648648648649,"A.4
ARTICULATED SPIDER MODEL"
NORMALIZE BELIEF WEIGHTS,0.8682432432432432,"Data for the articulated spider tracking task of Section 5.5 was simulated using the Pillow Clark
(2015) image processing library. Three revolute-prismatic joints are all centrally located and treated"
NORMALIZE BELIEF WEIGHTS,0.8716216216216216,Under review as a conference paper at ICLR 2022
NORMALIZE BELIEF WEIGHTS,0.875,"as the root of the spider’s kinematic tree. The remaining three revolute joints are attached to pairs of
links, forming three distinct ’arms’ of the spider. Each joint is rendered as a yellow circle while the
six rigid-body links are rendered as distinct red, green or blue rectangles respectively. Size param-
eters that follow are with respect to rendered image size of 500x500px. The three inner revolute-
prismatic joints include rotational constraints limiting each to a non-overlapping 120◦range of artic-
ulation as well as prismatic constraints limiting the extension to within [20, 80] pixels of translation.
The three purely revolute joints are constrained to rotations between ±35◦with respect to their local
origins. Each rigid-body link has width of 20px and height of 80px pixels while each joint has radius
of 10px."
NORMALIZE BELIEF WEIGHTS,0.8783783783783784,"For every simulated sequence, the spider is initialized with uniformly random root position within
the central 180x180px window and uniformly random root orientation from [0, 2π]. Furthermore,
each joint state is initialized uniformly at random within its particular articulation constraints. The
spider is simulated with dynamics using randomized, constant root, and joint velocities with respect
to a time step (dt) of 0.01. The root’s position velocities ( ˙x, ˙y) are each sampled from an equally
weighted 2-component Gaussian mixture with means (+24, −24) and standard deviations (15, 15).
Whereas, the root’s orientation velocity ( ˙θ) is sampled from an equally weighted 2-component Gaus-
sian mixture with means (+0.3, −0.3) and standard deviations (0.1, 0.1). Each rotational joint’s
velocity is sampled from an equally weighted 2-component Gaussian mixture with means (+0.3,
−0.3) and standard deviations (0.1, 0.1). Similarly, each prismatic joint’s velocity is sampled from
an equally weighted 2-component Gaussian mixture with means (+500, −500) and standard devia-
tions (60, 60). Note that if any joint reaches an articulation limit during simulation, the direction of
its velocity is reversed."
NORMALIZE BELIEF WEIGHTS,0.8817567567567568,"A.5
ARTICULATED SPIDER CLUTTER"
NORMALIZE BELIEF WEIGHTS,0.8851351351351351,"Clutter generation for the articulated spider tracking task follows a similar generation process as was
used for the double pendulum task. Clutter parameters that follow are with respect to rendered image
size of 500x500px and time step (dt) of 0.01. 50% of clutter is rendered beneath and 50% is rendered
on top of the spider. For dynamic clutter, each geometry simulates motion using a random, constant
position velocity ( ˙x, ˙y) and orientation velocity ( ˙θ). Position velocities are sampled from N(0, 3)
while orientation velocities are sampled from N(0, 0.05). Clutter is simulated as either a rectangle
with 70% probability or a circle with 30% probability. Clutter rectangles are sized randomly with
length of max(0, l ∼N(20, 3)) and height of max(0, h ∼N(80, 5)). The color of clutter rectangles
is chosen uniformly at random from the same colors as were used for the spider arms. Clutter circles
are sized randomly with a radius of max(0, r ∼N(10, 3)) and colored yellow to match the color of
the spider’s joints. The position of each clutter geometry was randomly initialized within the image
boundary."
NORMALIZE BELIEF WEIGHTS,0.8885135135135135,"For the training/validation sequences that included clutter, the number of clutter shapes rendered
beneath and on top of the double pendulum was each randomly sampled from independent Binomial
distributions using n = 10, p = 0.5. The test set was generated with uniformly distributed clutter
ratios, as described in Section 5.1, using rejection sampling with variable numbers of rendered
geometries."
NORMALIZE BELIEF WEIGHTS,0.8918918918918919,"A.6
LEARNED PAIRWISE INSPECTION"
NORMALIZE BELIEF WEIGHTS,0.8952702702702703,"As further validation of DNBP, the learned pairwise potentials are inspected in Fig. 9. The nor-
malized histogram of pairwise translations computed from the training set for X1 −X0 (top) and
X2 −X1 (bottom) are shown in the left column of Fig. 9. The middle column shows the normal-
ized histogram of samples from learned pairwise sampler networks, ψ∼
0,1(·) and ψ∼
1,2(·). Finally, the
right column shows output from the learned pairwise density networks, ψρ
0,1(·) and ψρ
1,2(·), gen-
erated with 100x100 uniform samples across pairwise translation space. The qualitative similarity
between each learned potential model and the corresponding true distribution of pairwise transla-
tions indicates that DNBP is successful in learning to model each pairwise potential factor. The
circular pairwise relationships are explained by the fact that each pair of double pendulum keypoints
is related by a revolute joint. The effect of simulated gravity in the double pendulum experiment can
be observed by the bias of each pairwise potential in favor of the lower half of each plot as indicated
by increased likelihood."
NORMALIZE BELIEF WEIGHTS,0.8986486486486487,Under review as a conference paper at ICLR 2022
NORMALIZE BELIEF WEIGHTS,0.902027027027027,"Training Set 
Distribution"
NORMALIZE BELIEF WEIGHTS,0.9054054054054054,"Likelihood
Likelihood"
NORMALIZE BELIEF WEIGHTS,0.9087837837837838,"Likelihood
Likelihood"
NORMALIZE BELIEF WEIGHTS,0.9121621621621622,"Potential
Potential"
NORMALIZE BELIEF WEIGHTS,0.9155405405405406,"Pixels
Pixels
Pixels"
NORMALIZE BELIEF WEIGHTS,0.918918918918919,"Pixels
Pixels
 1,2(X2|X1)
 0,1(X1|X0)"
NORMALIZE BELIEF WEIGHTS,0.9222972972972973,"Learned 
Distribution"
NORMALIZE BELIEF WEIGHTS,0.9256756756756757,"Learned 
Potentials"
NORMALIZE BELIEF WEIGHTS,0.9290540540540541,Figure 9: Inspection of learned pairwise potentials from double pendulum tracking.
NORMALIZE BELIEF WEIGHTS,0.9324324324324325,"1,4(X4|X1)"
NORMALIZE BELIEF WEIGHTS,0.9358108108108109,"Training Set 
Distribution"
NORMALIZE BELIEF WEIGHTS,0.9391891891891891,"Learned 
Distribution"
NORMALIZE BELIEF WEIGHTS,0.9425675675675675,"Learned 
Potentials"
NORMALIZE BELIEF WEIGHTS,0.9459459459459459,"Likelihood
Likelihood"
NORMALIZE BELIEF WEIGHTS,0.9493243243243243,"Likelihood
Likelihood"
NORMALIZE BELIEF WEIGHTS,0.9527027027027027,"Potential
Potential"
NORMALIZE BELIEF WEIGHTS,0.956081081081081,"Pixels
Pixels
Pixels"
NORMALIZE BELIEF WEIGHTS,0.9594594594594594,"Pixels
Pixels
 0,1(X1|X0)"
NORMALIZE BELIEF WEIGHTS,0.9628378378378378,"Figure 10: Inspection of DNBP’s learned pairwise potentials from spider tracking. Only two of the six are
shown to avoid redundancy, remaining four show very similar output."
NORMALIZE BELIEF WEIGHTS,0.9662162162162162,"The pairwise potential functions learned by DNBP in the spider tracking task are visualized as was
done in the double pendulum task. Fig. 10 shows qualitative output from two of the six models. Only
two are shown to avoid redundancy; chosen results are representative of remaining four potential
functions. The left column of Fig. 10 shows the normalized histogram of pairwise translations as
computed from the training set for X1 −X0 (top) and X4 −X1 (bottom). The middle column
of Fig. 10 shows the normalized histogram of samples from learned pairwise sampler networks,
ψ∼
0,1(·) and ψ∼
1,4(·). Finally in the right column of Fig. 10, uniformly sampled output (100x100
samples across pixel space) of the learned pairwise density networks is shown. Once again, the
visual similarity between each learned potential function and the corresponding true distribution of
pairwise translations is an indicator that DNBP is successful in learning to model each pairwise
factor. Observe that the learned potential functions for ψ1,4(·), which correspond to a revolute
articulation, show no bias in favor of the downward conﬁguration. This result is notably different
from the potential functions learned on the double pendulum task and can be explained by the
absence of gravity in the spider simulation. Similarly, the learned models for ψ0,1(·) on the spider
task exhibit a torus shape due to the effect of prismatic motion associated with the corresponding
joint’s articulation type and constraint."
NORMALIZE BELIEF WEIGHTS,0.9695945945945946,Under review as a conference paper at ICLR 2022
NORMALIZE BELIEF WEIGHTS,0.972972972972973,"A.7
HAND TRACKING RESULTS"
NORMALIZE BELIEF WEIGHTS,0.9763513513513513,Ground
NORMALIZE BELIEF WEIGHTS,0.9797297297297297,"Truth
Estimate
Thumb 
Uncertainty"
NORMALIZE BELIEF WEIGHTS,0.9831081081081081,"Index 
Uncertainty"
NORMALIZE BELIEF WEIGHTS,0.9864864864864865,"Middle 
Uncertainty"
NORMALIZE BELIEF WEIGHTS,0.9898648648648649,"Ring 
Uncertainty"
NORMALIZE BELIEF WEIGHTS,0.9932432432432432,"Pinky 
Uncertainty (1) (2) (3) (4) (5) (6) (7) (8)"
NORMALIZE BELIEF WEIGHTS,0.9966216216216216,"Figure 11: Output from DNBP on randomly sampled frames of the hand pose tracking experiment. Visualized
model uncertainty is calculated from the marginal belief estimates of DNBP as 1 standard deviation in the x
and y dimensions respectively as calculated by estimated covariance of belief particles. Uncertainty in depth
dimension is not visualized."
