Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.004878048780487805,"Evaluation metrics are essential for assessing the performance of generative mod-
els in image synthesis. However, existing metrics often involve high memory and
time consumption as they compute the distance between generated samples and
real data points. In our study, the new evaluation metric called the ”TTJac score”
is proposed to measure the fidelity of individual synthesized images in a data-free
manner. The study first establishes a theoretical approach to directly evaluate the
generated sample density. Then, a method incorporating feature extractors and
discrete function approximation through tensor train is introduced to effectively
assess the quality of generated samples. Furthermore, the study demonstrates that
this new metric can be used to improve the fidelity-variability trade-off when ap-
plying the truncation trick. The experimental results of applying the proposed
metric to StyleGAN 2 and StyleGAN 2 ADA models on FFHQ, AFHQ-Wild,
LSUN-Cars, and LSUN-Horse datasets are presented. The code used in this re-
search will be made publicly available online for the research community to access
and utilize."
INTRODUCTION,0.00975609756097561,"1
INTRODUCTION"
INTRODUCTION,0.014634146341463415,"Advancements in Generative Adversarial Networks (GANs) Goodfellow et al. (2014) have led to a
wide range of applications, including image manipulation Voynov & Babenko (2020); Shen et al.
(2020); H¨ark¨onen et al. (2020), domain translation Isola et al. (2017); Zhu et al. (2017); Choi et al.
(2017; 2020); Kim et al. (2020), and image/video generation Kim et al. (2022); Kim & Ha (2022);
Karras et al. (2019; 2020b;a). GANs have demonstrated high-quality results in these tasks, as vali-
dated by standard evaluation metrics such as Fr´echet inception distance (FID) Heusel et al. (2018),
kernel inception distance (KID) Bi´nkowski et al. (2018), Precision Kynk¨a¨anniemi et al. (2019), and
Recall Kynk¨a¨anniemi et al. (2019). These metrics are typically based on clustering real data points
using the k-nearest neighbours algorithm. Initially, real images are passed through a feature extractor
network to obtain meaningful embeddings, and pairwise distances to other real images are computed
for the algorithm. In the evaluation stage, the fidelity of an individual sample is determined by com-
puting its distance to the clusters of real manifold. However, this procedure can be computationally
expensive and memory-intensive, particularly for large datasets, as all real embeddings need to be
stored."
INTRODUCTION,0.01951219512195122,"In order to overcome these challenges, this research introduces a novel metric for evaluating the
quality of individual samples. Instead of assessing sample fidelity relative to the real manifold,
this metric directly calculates the density of a sample by utilizing only the trained generator. The
computation process involves evaluating the model Jacobian, which can be particularly demanding
for high-resolution models. To mitigate the memory and time costs associated with this computation,
feature extractors are employed to reduce the size of the Jacobian."
INTRODUCTION,0.024390243902439025,"Furthermore, the proposed metric function is approximated on a discrete grid using tensor train
decomposition. This approximation provides a significant reduction in inference time since the
batch of sample scores is only required to compute the tensor decomposition stage. The evaluation
procedure simply entails obtaining the value of decomposed tensor at specified indexes."
INTRODUCTION,0.02926829268292683,Published as a conference paper at ICOMP 2024
INTRODUCTION,0.03414634146341464,"Figure 1: The general pipeline of the presented work involves several steps. Firstly, latent code sam-
ples z are generated from a normal distribution, then the generated latent codes are passed through
the generator network, which produces corresponding images x. The VGG feature extractor is em-
ployed to extract meaningful features f. After obtaining the features, the computation of feature
density is carried out using generalized change of variables formula Ben-Israel (1999). Finally, the
metric score samples are approximated using the Tensor Train (TT) algorithm."
INTRODUCTION,0.03902439024390244,"The proposed metric function also has an application in the sampling procedure, particularly as an
enhancement for the truncation trick. The truncation trick Brock et al. (2019) operates by sorting
samples based on the norm of the input vector, which can be effectively replaced by the TTJac score.
This upgrade provides a better trade-off between fidelity and variability compared to the standard
technique."
INTRODUCTION,0.04390243902439024,"To evaluate the effectiveness of the proposed metric function, standard GAN models like StyleGAN
2 Karras et al. (2020b) and StyleGAN 2 ADA Karras et al. (2020a) were considered, using various
datasets such as Flickr-Faces-HQ Dataset (FFHQ) Karras et al. (2019), AFHQ Wild Choi et al.
(2020), LSUN Car Yu et al. (2016), and LSUN Horse Yu et al. (2016). In summary, the contributions
of this paper include:"
INTRODUCTION,0.04878048780487805,"1. Introducing a new metric for sample evaluation that does not rely on dataset information.
2. Presenting a methodology for effective usage of the proposed metric, involving feature
extractors and tensor train approximation.
3. Proposing a metric-based upgrade for the truncation trick, enabling a better trade-off be-
tween fidelity and variability."
IMPLEMENTATION/METHODS,0.05365853658536585,"2
METHOD"
IMPLEMENTATION/METHODS,0.05853658536585366,"The primary component of a GAN model is the generator network, denoted as G, which generates
an image x from a given latent code (network input) z. Typically, the evaluation of individual sample
quality x = G(z) is performed using a realism score or trucnation trick."
IMPLEMENTATION/METHODS,0.06341463414634146,"The realism score requires access to a dataset to compute distances for the k-nearest neighbors
algorithm, while truncation trick assesses sample fidelity based on the norm of the corresponding
input vector. This approach allows for resampling latent codes that lie outside a chosen radius."
IMPLEMENTATION/METHODS,0.06829268292682927,"In contrast, we propose a metric function that defines the score based on the density of the generator
output. We use the generalized change-of-variable formula Ben-Israel (1999):"
IMPLEMENTATION/METHODS,0.07317073170731707,"ρ(z) = ρ(x)Vol(J)
where J = dG(z)/dz represents the generator Jacobian. By taking the logarithm and making the
appropriate substitution, the final expression for the score function is derived:"
IMPLEMENTATION/METHODS,0.07804878048780488,s(x) = log ρ(x) = log(ρ(z)) −log(Vol(J))
IMPLEMENTATION/METHODS,0.08292682926829269,Published as a conference paper at ICOMP 2024 X
IMPLEMENTATION/METHODS,0.08780487804878048,"Low
Middle
High"
IMPLEMENTATION/METHODS,0.09268292682926829,"VGG
DINO"
IMPLEMENTATION/METHODS,0.0975609756097561,"Figure 2: Qualitative comparison of different image features. Three types of output considered:
original image (X), VGG19 features (VGG), Dino features (DINO). For each type the sample density
was computed. Three images with low, middle, and high scores are presented for each output type."
IMPLEMENTATION/METHODS,0.1024390243902439,where Vol(J) = 1
IMPLEMENTATION/METHODS,0.1073170731707317,"2 log(det(JT J)) =
N
P"
IMPLEMENTATION/METHODS,0.11219512195121951,"i=1
log(σi(J)), σi(J) represents the i-th singular value of the"
IMPLEMENTATION/METHODS,0.11707317073170732,Jacobian. Finally score function turns into:
IMPLEMENTATION/METHODS,0.12195121951219512,"s(x) = log(ρ(z)) − N
X"
IMPLEMENTATION/METHODS,0.12682926829268293,"i=1
log(σi(J))"
IMPLEMENTATION/METHODS,0.13170731707317074,"At this stage, we considered the image density in pixel representation. Nevertheless, the proposed
idea can be applied to an arbitrary representation of the image. This aspect is discussed in the next
part."
IMPLEMENTATION/METHODS,0.13658536585365855,"2.1
FEATURE DENSITY SCORING"
IMPLEMENTATION/METHODS,0.14146341463414633,"High-resolution images can be generated by high-quality GANs (Generative Adversarial Networks).
For instance, the StyleGAN2 model trained on the FFHQ dataset can generate images of size 1024×
1024 with a latent space size of 512. However, computing the Jacobian matrix, which contains 109
values in this case, can be challenging in terms of both time and memory consumption."
IMPLEMENTATION/METHODS,0.14634146341463414,"To mitigate these costs, we propose to use feature extraction. Instead of evaluating sample quality
based on pixel values, a score function can be used that assesses the density of features. The score
function is defined as:"
IMPLEMENTATION/METHODS,0.15121951219512195,s(x) = log ρ(f(x)) = log(ρ(z)) −log(Vol(J))
IMPLEMENTATION/METHODS,0.15609756097560976,"Here, J = df(G(z))"
IMPLEMENTATION/METHODS,0.16097560975609757,"dz
represents the Jacobian matrix, and f denotes the feature extraction network. In
Figure 1 we presented a whole pipeline of our work. The detailed explanations on last step delivered
in next section."
IMPLEMENTATION/METHODS,0.16585365853658537,"In our work, we considered two options for the feature extraction network: VGG19Simonyan &
Zisserman (2015) and DinoCaron et al. (2021). VGG networks are based on convolutional layers
and have demonstrated high efficiency in classification tasks. They are widely used for extracting
meaningful information from image data. On the other hand, Dino is a transformer-based network,
which is known to be more accurate but has longer inference times compared to convolution-based
networks."
IMPLEMENTATION/METHODS,0.17073170731707318,"To compare the performance of these feature extraction networks, we generated 100 images Style-
GAN 2 ADA model trained on FFHQ dataset and evaluated the proposed metric. The experiments
were conducted on a Tesla V100-SXM2 GPU with 16 GB of memory. Three types of output were
considered: X (pixel-based density), VGG (VGG19-based feature density), and Dino (Dino-based
feature density)."
IMPLEMENTATION/METHODS,0.17560975609756097,"After conducting a sorting procedure, we selected three images with the lowest, middle, and highest
scores for each output type. Figure 2 illustrates that VGG produces results that are comparable"
IMPLEMENTATION/METHODS,0.18048780487804877,Published as a conference paper at ICOMP 2024
IMPLEMENTATION/METHODS,0.18536585365853658,"Table 1: Comparison results of time consumption for metric inference. Three types of output density
considered: Original - pixel based density, VGG - VGG features based density, Dino - Dino features
based density"
IMPLEMENTATION/METHODS,0.1902439024390244,"Feature
extractor
Original
VGG
Dino"
IMPLEMENTATION/METHODS,0.1951219512195122,"Time per
sample (s)
450
25
90"
IMPLEMENTATION/METHODS,0.2,"Table 2: Quantitative evaluation of TT approximation of TTJac score on discrete grid for different
domains: FFHQ, AFHQ-Wild, LSUN Car, LSUN Horse"
IMPLEMENTATION/METHODS,0.2048780487804878,"Domain
FFHQ
Wild
Car
Horse
MSE
0.018
0.026
0.017
0.018"
IMPLEMENTATION/METHODS,0.2097560975609756,"to pixel-based and Dino based density. Additionally, computing the VGG features-based density
requires significantly less time per sample. For further experiments, we utilized VGG features for
metric computation. Table 1 provides a comprehensive comparison of the time consumption for
different output types."
IMPLEMENTATION/METHODS,0.2146341463414634,"2.2
INFERENCE TIME ACCELERATION THROUGH TENSOR TRAIN"
IMPLEMENTATION/METHODS,0.21951219512195122,"Presented in previous section reduction in inference time is insufficient for the computation of a
large number of samples. Currently, the computation of 50,000 scores takes around 2 weeks on a
single GPU, even with the use of VGG based features. A potential solution to this problem is to
discretize the metric on a grid and compress the resulting tensor using tensor decomposition. The
proposed solution pipeline consists of two stages:"
IMPLEMENTATION/METHODS,0.22439024390243903,1. Score computation for a large number of samples
IMPLEMENTATION/METHODS,0.22926829268292684,"2. Computation of the logarithm density approximation using the samples obtained from the
previous stage"
IMPLEMENTATION/METHODS,0.23414634146341465,"To evaluate a sample ˆx within this pipeline, the following steps can be followed:"
IMPLEMENTATION/METHODS,0.23902439024390243,"1. Find the closest point to the latent code ˆz in the discrete latent space z[i1, ..., id]. This can
be achieved by minimizing the Euclidean distance between the discrete latent codes and ˆz:"
IMPLEMENTATION/METHODS,0.24390243902439024,"(ˆi1, ...,ˆid) = arg min (i1, ..., id)∥z[i1, ..., id] −ˆz∥"
IMPLEMENTATION/METHODS,0.24878048780487805,"2. Compute the score value at this point using the density tensor ρ[i1, ..., id] stored in com-
pressed format:
s(ˆx) = ρ[ˆi1, ...,ˆid]"
IMPLEMENTATION/METHODS,0.25365853658536586,"2.3
NON UNIFORM GRID"
IMPLEMENTATION/METHODS,0.25853658536585367,"One crucial component in our scheme is the grid used for discretization. We found usage of a uni-
form grid is not suitable for GANs when sampling latent codes from a normal distribution. Certain
latent regions may lack sufficient data, posing challenges for computation of tensor train descompo-
sition."
IMPLEMENTATION/METHODS,0.2634146341463415,"To address this challenge, we opted for a grid where the integrals of the normal density over each
grid interval are equal. This approach ensures a uniform distribution of samples along each grid
index, effectively working in our case. More details can be found in Appendix A."
IMPLEMENTATION/METHODS,0.2682926829268293,"2.3.1
CALCULATION OF TENSOR TRAIN APPROXIMATION"
IMPLEMENTATION/METHODS,0.2731707317073171,"The TT decomposition of a tensor represents the element at position [i1, ..., iN] as the product of
matrices:"
IMPLEMENTATION/METHODS,0.2780487804878049,Published as a conference paper at ICOMP 2024 TTJac
IMPLEMENTATION/METHODS,0.28292682926829266,"Low
Middle
High"
IMPLEMENTATION/METHODS,0.28780487804878047,"Realism
Rarity"
IMPLEMENTATION/METHODS,0.2926829268292683,"High
Middle
Low = 1.5"
IMPLEMENTATION/METHODS,0.2975609756097561,Truncation
IMPLEMENTATION/METHODS,0.3024390243902439,"= 1.0
 = 0.5"
IMPLEMENTATION/METHODS,0.3073170731707317,"Figure 3: Qualitative comparison of metrics for individual image evaluation: TTJac score, Realism
score, Rarity score, Truncation Trick. For each metric we presented 8 images with lowest, middle,
and highest score values. For the TTJac and Realism scores, we arranged the images in increasing
order from low to high scores. Conversely, for the Rarity score and Truncation Trick, we intention-
ally reversed the order to ensure ease of comparison between the metrics."
IMPLEMENTATION/METHODS,0.3121951219512195,"T[i1, ..., iN] = G1[i1]...GN[iN]"
IMPLEMENTATION/METHODS,0.3170731707317073,"Here, G1, ..., GN are the TT cores. The low-rank pairwise dependency between tensor components
allows for an efficient approximation of the proposed metric function in discrete form using well
known Tensor Train decomposition Oseledets (2011). It showed impressive results on different
tasks Chertkov et al. (2023); Ahmadi-Asl et al. (2023); Liu et al. (2023); Li et al. (2023) due to
the storage efficiency, capturing complex dependencies and fast inference capabilities. Obtaining an
element of the tensor stored in TT format requires only 511 matrix-by-vector multiplications. It also
can be easily accelerated for the batch of elements using multiprocessing tools. Actually the batch
size could be enormously large for TT format since it on each step of output computation algorithm
stores the matrix of size (N, r) where N number of elements to compute, r - rank of decomposition.
This aspect has significat impact on use of proposed metric for truncation trick, where we need to
evaluate huge number of samples."
IMPLEMENTATION/METHODS,0.32195121951219513,"However, it should be noted that the computation of samples for core computation is time-
consuming. This renders standard iterative methods for tensor train calculation ineffective, as they
tend to overfit to given tensor samples and fail to capture underlined dependencies. In such case, it
is more suitable to use explicit methods for tensor train decompositions, such as ANOVA decompo-
sition Potts & Schmischke (2021). The authors in Chertkov et al. (2023) have presented an effective
method for computing ANOVA decomposition in TT format, which we have found accurate enough
for our purposes. See Table 2 where we presented the results of TT approximation for discretized
metric in different domains."
IMPLEMENTATION/METHODS,0.32682926829268294,"2.3.2
UPGRADED TRUNCATION TRICK"
IMPLEMENTATION/METHODS,0.33170731707317075,"The truncation trick, initially proposed in Brock et al. (2019), offers a means to adjust the balance
between variability and fidelity. It involves two practical steps: evaluating the norm of generated"
IMPLEMENTATION/METHODS,0.33658536585365856,Published as a conference paper at ICOMP 2024
IMPLEMENTATION/METHODS,0.34146341463414637,"TTJac
Rarity
Realism
Truncation"
IMPLEMENTATION/METHODS,0.3463414634146341,"TTJac
Rarity
Realism
Truncation 1.00 0.75 0.50 0.25 0.00 0.25 0.50 0.75 1.00"
IMPLEMENTATION/METHODS,0.35121951219512193,"Figure 4: Correlation matrix for metrics measuring individual sample quality: TTJac score, Realism
score, Rarity score, and Truncation."
IMPLEMENTATION/METHODS,0.35609756097560974,"samples and resampling those with a norm exceeding a specified threshold. This threshold de-
termines the balance between variability and fidelity. By removing samples with high norms, we
effectively reduce the number of samples with low latent code density and, possibly, lower visual
quality. This approach can enhance the overall fidelity of the generated samples, albeit at the expense
of variability."
IMPLEMENTATION/METHODS,0.36097560975609755,"Instead of evaluating latent code density, we suggest assessing image feature density using a modern
feature extractor such as VGG. In next section, we provide evidence that this replacement criterion
achieves a more desirable trade-off between fidelity and variability."
RESULTS/EXPERIMENTS,0.36585365853658536,"3
EXPERIMENT"
RESULTS/EXPERIMENTS,0.37073170731707317,"To evaluate the proposed metric, we conducted experiments on various widely-used datasets for
image generation, including FFHQ Karras et al. (2019), AFHQ-Wild Choi et al. (2020), LSUN-
Cars Yu et al. (2016), and LSUN-Horse Yu et al. (2016). Additionally, we considered the method
effectiveness on StyleGAN 2 Karras et al. (2020b) and StyleGAN 2 ADA Karras et al. (2020a)
models, known for their high performance in generating images in standard domains where data
may be limited or noisy."
RESULTS/EXPERIMENTS,0.375609756097561,"For the learning process of the metric, we computed 60k samples for the FFHQ dataset and 30k sam-
ples for the AFHQ-Wild, LSUN-Cars, and LSUN-Horse datasets. Feature extraction was performed
using the VGG19 network Simonyan & Zisserman (2015)."
RESULTS/EXPERIMENTS,0.3804878048780488,"To discretize the metric, we utilized a grid with a size of 32. The metric was then approximated by
applying ANOVA decomposition of order 1, which was later converted to the tensor train format."
RESULTS/EXPERIMENTS,0.3853658536585366,All experiments were carried out using a 3 Tesla V100-SXM2 GPU with 16 GB of memory.
RESULTS/EXPERIMENTS,0.3902439024390244,"3.1
COMPARISON WITH OTHER METRICS"
RESULTS/EXPERIMENTS,0.3951219512195122,"To demonstrate the effectiveness of the TTJac score in evaluating individual samples, we compared
it with similar metrics such as the Realism score Kynk¨a¨anniemi et al. (2019), Truncation trick Brock
et al. (2019), and Rarity score Han et al. (2022). We randomly selected 10k latent samples and
presented the comparison results in Figure 3."
RESULTS/EXPERIMENTS,0.4,"In order to facilitate the comparison process, we reversed the order for the Rarity score and Trun-
cation. The Realism score showed high results in evaluating sample fidelity but sometimes failed
on visually appealing images. It is important to note that high realism values often correspond to
images with low variability. Similarly, the Truncation trick allows for manipulation of image qual-"
RESULTS/EXPERIMENTS,0.40487804878048783,Published as a conference paper at ICOMP 2024
RESULTS/EXPERIMENTS,0.4097560975609756,"Table 3: Quantitative results of correlation between TTJac score and other considered metrics: Rar-
ity score, Realism score, Truncation. Computation was done for certain number of samples repre-
senting the higher and lower extremes of the TTJac score - border samples."
RESULTS/EXPERIMENTS,0.4146341463414634,"Number
of border
samples"
RESULTS/EXPERIMENTS,0.4195121951219512,"Rarity
Realism
Truncation"
RESULTS/EXPERIMENTS,0.424390243902439,"3000
-0.051
0.42
0.007
2000
-0.059
0.472
0.156
1000
-0.048
0.54
0.006
500
-0.048
0.584
0.049
100
-0.043
0.651
0.135"
RESULTS/EXPERIMENTS,0.4292682926829268,"ity at the expense of variability. However, samples with the highest variability tend to have lower
realism compared to other metrics. On the other hand, the Rarity score measures the uniqueness of
the given image, effectively identifying images with distinct features, but some of them may appear
less realistic."
RESULTS/EXPERIMENTS,0.43414634146341463,"The proposed TTJac score functions similarly to the realism score but does not require any real
data for processing. It effectively extracts samples with high fidelity, reflected by a high score.
Conversely, low scores often indicate the presence of visual artifacts. However, the TTJac score
does have a limitation – images with high scores tend to have fewer unique features, while visually
appealing images can be found among those with low scores."
RESULTS/EXPERIMENTS,0.43902439024390244,"We also computed the correlation between the presented metrics. The results confirmed quite high
similarity between the realism and TTJac scores, as shown in Figure 4. Furthermore, when measur-
ing metrics correlation for samples with the highest and lowest TTJac scores, results of proposed
metric becomes even more close to realism score. See Table 3 for confirmation. Thus, the data free
metric TTJac is able to filter out very low quality images as effectively as the Realism score using a
dataset of real images."
RESULTS/EXPERIMENTS,0.44390243902439025,"3.2
FIDELITY-VARIABILITY TRADE-OFF EVALUATION"
RESULTS/EXPERIMENTS,0.44878048780487806,"In method section, we discussed the potential use of the proposed metric to enhance the performance
of the truncation trick. In this section, we compare the trade-off provided by the standard criteria
based on latent code norm, and the TTJac score. To demonstrate the effectiveness, we plotted
precision-recall curves for the FFHQ, AFHQ-Wild, LSUN-Car, and LSUN-Horse domains."
RESULTS/EXPERIMENTS,0.45365853658536587,"For the FFHQ, LSUN Horse, and LSUN Car domains, the use of the TTJac score allows for a better
balance between precision and recall compared to the standard tool. In Figure 5, the curve for the
TTJac score consistently lies above the curve for the Truncation trick. The benefit is not significant
for the AFHQ-Wild domain. This can be attributed to the fact that the GAN model already exhibits
a high level of precision in this specific domain. Furthermore, the evaluation of TT approximation
accuracy presented the least favorable outcome when compared to other domains. And also on the
FFHQ domain, after an improvement in precision by 5%, a decline begins and the curve falls below
that for the standard truncation trick. It can be attributed to the presence of an error in the metric
approximation. However, for the LSUN-Car domain, the TTJac score proves to be highly effective,
providing a significant improvement in precision with negligible loss in recall."
RESULTS/EXPERIMENTS,0.4585365853658537,"It is important to note that due to the presence of errors in the approximation of the metric score,
it is not possible to achieve the maximum possible precision with minimal recall value, as seen in
standard precision-recall curves."
RESULTS/EXPERIMENTS,0.4634146341463415,"Overall, this comparison highlights the potential of the TTJac score in achieving a better trade-off
between precision and recall in the evaluated domains, with notable improvements observed in the
LSUN-Car domain."
RESULTS/EXPERIMENTS,0.4682926829268293,Published as a conference paper at ICOMP 2024
RESULTS/EXPERIMENTS,0.47317073170731705,"0.68
0.70
0.72
0.74
0.76
0.78
0.80
Precision 0.34 0.36 0.38 0.40 0.42 0.44 0.46 0.48 0.50"
RESULTS/EXPERIMENTS,0.47804878048780486,Recall FFHQ
RESULTS/EXPERIMENTS,0.48292682926829267,"TTJac score
Truncation trick"
RESULTS/EXPERIMENTS,0.4878048780487805,"0.760
0.765
0.770
0.775
0.780
0.785
Precision 0.039 0.040 0.041 0.042 0.043 0.044 0.045 0.046 0.047"
RESULTS/EXPERIMENTS,0.4926829268292683,Recall
RESULTS/EXPERIMENTS,0.4975609756097561,AFHQ-Wild
RESULTS/EXPERIMENTS,0.5024390243902439,"TTJac score
Truncation trick"
RESULTS/EXPERIMENTS,0.5073170731707317,"0.68
0.70
0.72
0.74
0.76
0.78
Precision 0.40 0.42 0.44 0.46 0.48 0.50 0.52"
RESULTS/EXPERIMENTS,0.5121951219512195,Recall
RESULTS/EXPERIMENTS,0.5170731707317073,LSUN Car
RESULTS/EXPERIMENTS,0.5219512195121951,"TTJac score
Truncation trick"
RESULTS/EXPERIMENTS,0.526829268292683,"0.625
0.630
0.635
0.640
0.645
0.650
Precision"
RESULTS/EXPERIMENTS,0.5317073170731708,0.3700
RESULTS/EXPERIMENTS,0.5365853658536586,0.3725
RESULTS/EXPERIMENTS,0.5414634146341464,0.3750
RESULTS/EXPERIMENTS,0.5463414634146342,0.3775
RESULTS/EXPERIMENTS,0.551219512195122,0.3800
RESULTS/EXPERIMENTS,0.5560975609756098,0.3825
RESULTS/EXPERIMENTS,0.5609756097560976,0.3850
RESULTS/EXPERIMENTS,0.5658536585365853,0.3875
RESULTS/EXPERIMENTS,0.5707317073170731,Recall
RESULTS/EXPERIMENTS,0.5756097560975609,LSUN Horse
RESULTS/EXPERIMENTS,0.5804878048780487,"TTJac score
Truncation trick"
RESULTS/EXPERIMENTS,0.5853658536585366,"Figure 5: Quantitative comparison of fidelity-variability trade-off computed using TTJac score and
Truncation trick. Four domains were examined: FFHQ, AFHQ-Wild, LSUN Car, LSUN Horse.
For each domain 50k samples were generated for precision and recall calculation. The results were
averaged along 3 random seeds. The higher - the better."
RESULTS/EXPERIMENTS,0.5902439024390244,"3.3
DOMAIN WISE METRIC EVALUATION"
RESULTS/EXPERIMENTS,0.5951219512195122,"In this part, we conducted a qualitative evaluation of the TTJac score for various domains. In Fig-
ure 6, it is demonstrated that the TTJac score efficiently detects visual artifacts in the evaluated
domains."
RESULTS/EXPERIMENTS,0.6,"For the FFHQ domain, the TTJac score assigns low scores to images that do not contain a face or
have unrealistic prints. Additionally, images with visually poor backgrounds are also marked with
low score values. Similarly, in the LSUN Car domain, images that lack key elements of a car are
identified as lower quality by the TTJac score."
RESULTS/EXPERIMENTS,0.6048780487804878,"The TTJac score exhibits similar behavior in the AFHQ-Wild and LSUN-Horse domains. It effec-
tively detects unrealistic horses, such as instances where two horses are merged into one image.
However, in the AFHQ-Wild domain, the metric faces a more challenging situation. While it accu-
rately identifies images where different species are merged, such as an image with half wolf and half
lion, the overall fidelity of the images in this domain is quite close. This observation is connected
to the fact that the model trained on the AFHQ-Wild dataset has a higher precision compared to the
other considered models."
RESULTS/EXPERIMENTS,0.6097560975609756,"In summary, the TTJac score demonstrates high efficiency in evaluating sample fidelity while sac-
rificing some variability. It effectively detects visual artifacts and accurately identifies unrealistic
elements in the evaluated domains."
RESULTS/EXPERIMENTS,0.6146341463414634,Published as a conference paper at ICOMP 2024 FFHQ
RESULTS/EXPERIMENTS,0.6195121951219512,"Low
Middle
High"
RESULTS/EXPERIMENTS,0.624390243902439,"AFHQ-Wild
LSUN Car
LSUN Horse"
RESULTS/EXPERIMENTS,0.6292682926829268,"Figure 6: Qualitative comparison of metric evaluation capabilities four domains were examined:
FFHQ, AFHQ-Wild, LSUN Car, LSUN Horse. For each domain 30k samples were sorted based on
their scores and selected three images to represent the samples with the lowest, middle, and highest
score values."
CONCLUSION/DISCUSSION,0.6341463414634146,"4
CONCLUSION"
CONCLUSION/DISCUSSION,0.6390243902439025,"We have proposed a new approach for evaluating image quality without using real data, which is
based on the density of meaningful features extracted from the image. A method was also proposed
for efficient storage and inference metrics using TT approximation. We compared the TTJac score
with other metrics. The TTJac score performs similarly to the realism score. It effectively detects
visual artifacts and identifies unrealistic elements in different domains such as FFHQ, AFHQ-Wild,
LSUN Car, and LSUN Horse. We also evaluated the trade-off between fidelity and variability using
precision-recall curves. The TTJac score showed a better balance, especially in the LSUN Car do-
main where it significantly improved precision with minimal loss in recall. In qualitative evaluation,
the TTJac score successfully detected missing key elements or unrealistic features in images across
various domains. Overall, the TTJac score demonstrates high efficiency in evaluating sample fidelity
and can be a valuable tool for assessing image generation models."
REFERENCES,0.6439024390243903,REFERENCES
REFERENCES,0.6487804878048781,"Salman Ahmadi-Asl, Maame Gyamfua Asante-Mensah, Andrzej Cichocki, Anh Huy Phan, Ivan
Oseledets, and Jun Wang.
Fast cross tensor approximation for image and video completion.
Signal Processing, pp. 109121, 2023. ISSN 0165-1684. doi: https://doi.org/10.1016/j.sigpro.
2023.109121.
URL https://www.sciencedirect.com/science/article/pii/
S0165168423001950."
REFERENCES,0.6536585365853659,"Adi Ben-Israel. The change-of-variables formula using matrix volume. Siam Journal on Matrix
Analysis and Applications - SIAM J MATRIX ANAL APPLICAT, 21, 01 1999. doi: 10.1137/
S0895479895296896."
REFERENCES,0.6585365853658537,"Mikołaj Bi´nkowski, Danica J. Sutherland, Michael Arbel, and Arthur Gretton. Demystifying mmd
gans, 2018. URL https://arxiv.org/abs/1801.01401."
REFERENCES,0.6634146341463415,Published as a conference paper at ICOMP 2024
REFERENCES,0.6682926829268293,"Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale GAN training for high fidelity
natural image synthesis. In International Conference on Learning Representations, 2019. URL
https://openreview.net/forum?id=B1xsqj09Fm."
REFERENCES,0.6731707317073171,"Mathilde Caron, Hugo Touvron, Ishan Misra, Herv´e J´egou, Julien Mairal, Piotr Bojanowski, and
Armand Joulin. Emerging properties in self-supervised vision transformers. In Proceedings of
the International Conference on Computer Vision (ICCV), 2021."
REFERENCES,0.6780487804878049,"Andrei Chertkov, Gleb Ryzhakov, and Ivan Oseledets.
Black box approximation in the tensor
train format initialized by anova decomposition.
SIAM Journal on Scientific Computing, 45
(4):A2101–A2118, 2023. doi: 10.1137/22M1514088. URL https://doi.org/10.1137/
22M1514088."
REFERENCES,0.6829268292682927,"Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, and Jaegul Choo. Star-
gan: Unified generative adversarial networks for multi-domain image-to-image translation. arXiv
preprint arXiv:1711.09020, 2017."
REFERENCES,0.6878048780487804,"Yunjey Choi, Youngjung Uh, Jaejun Yoo, and Jung-Woo Ha. Stargan v2: Diverse image synthesis
for multiple domains. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition, 2020."
REFERENCES,0.6926829268292682,"Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sher-
jil Ozair,
Aaron Courville,
and Yoshua Bengio.
Generative adversarial nets.
In
Z. Ghahramani,
M. Welling,
C. Cortes,
N. Lawrence,
and K.Q. Weinberger (eds.),
Advances in Neural Information Processing Systems,
volume 27. Curran Associates,
Inc.,
2014.
URL
https://proceedings.neurips.cc/paper/2014/file/
5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf."
REFERENCES,0.697560975609756,"Jiyeon Han, Hwanil Choi, Yunjey Choi, Junho Kim, Jung-Woo Ha, and Jaesik Choi.
Rarity
score: A new metric to evaluate the uncommonness of synthesized images.
arXiv preprint
arXiv:2206.08549, 2022."
REFERENCES,0.7024390243902439,"Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
Gans trained by a two time-scale update rule converge to a local nash equilibrium, 2018."
REFERENCES,0.7073170731707317,"Sebastian Holtz, Thorsten Rohwedder, and Reinhold Schneider. The alternating linear scheme for
tensor optimization in the tensor train format. SIAM J. Sci. Comput., 34, 2012. URL https:
//api.semanticscholar.org/CorpusID:39160026."
REFERENCES,0.7121951219512195,"Erik H¨ark¨onen, Aaron Hertzmann, Jaakko Lehtinen, and Sylvain Paris. Ganspace: Discovering
interpretable gan controls. In Proc. NeurIPS, 2020."
REFERENCES,0.7170731707317073,"Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with
conditional adversarial networks. CVPR, 2017."
REFERENCES,0.7219512195121951,"Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative ad-
versarial networks. In 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition
(CVPR), pp. 4396–4405, 2019. doi: 10.1109/CVPR.2019.00453."
REFERENCES,0.7268292682926829,"Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko Lehtinen, and Timo Aila. Training
generative adversarial networks with limited data. In Proc. NeurIPS, 2020a."
REFERENCES,0.7317073170731707,"Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Ana-
lyzing and improving the image quality of stylegan. In 2020 IEEE/CVF Conference on Computer
Vision and Pattern Recognition (CVPR), pp. 8107–8116, 2020b. doi: 10.1109/CVPR42600.2020.
00813."
REFERENCES,0.7365853658536585,"Junho Kim, Minjae Kim, Hyeonwoo Kang, and Kwang Hee Lee. U-gat-it: Unsupervised generative
attentional networks with adaptive layer-instance normalization for image-to-image translation. In
International Conference on Learning Representations, 2020. URL https://openreview.
net/forum?id=BJlZ5ySKPH."
REFERENCES,0.7414634146341463,"Junho Kim, Yunjey Choi, and Youngjung Uh. Feature statistics mixing regularization for generative
adversarial networks. In CVPR, 2022."
REFERENCES,0.7463414634146341,Published as a conference paper at ICOMP 2024
REFERENCES,0.751219512195122,"Yunji Kim and Jung-Woo Ha. Contrastive fine-grained class clustering via generative adversarial
networks. 2022."
REFERENCES,0.7560975609756098,"Tuomas Kynk¨a¨anniemi, Tero Karras, Samuli Laine, Jaakko Lehtinen, and Timo Aila. Improved
precision and recall metric for assessing generative models. CoRR, abs/1904.06991, 2019."
REFERENCES,0.7609756097560976,"Sijing Li, Zhongjian Wang, Stephen Shing-Toung Yau, and Zhiwen Zhang. Solving nonlinear filter-
ing problems using a tensor train decomposition method. IEEE Transactions on Automatic Con-
trol, 68:4405–4412, 2023.
URL https://api.semanticscholar.org/CorpusID:
254326539."
REFERENCES,0.7658536585365854,"Huazhong Liu, Jiawei Wang, Xiaoxue Yin, Jihong Ding, Laurence Tianruo Yang, Tong Yao, Jing
Yang, and Yuan Gao. Tensor-train-based multiuser multivariate multiorder physical markov pro-
cess informed multimodal prediction for industrial trajectory applications. IEEE Transactions
on Industrial Informatics, 19:8900–8909, 2023. URL https://api.semanticscholar.
org/CorpusID:253610564."
REFERENCES,0.7707317073170732,"I. V. Oseledets. Tensor-train decomposition. SIAM Journal on Scientific Computing, 33(5):2295–
2317, 2011. doi: 10.1137/090752286. URL https://doi.org/10.1137/090752286."
REFERENCES,0.775609756097561,"Daniel Potts and Michael Schmischke. Approximation of high-dimensional periodic functions with
fourier-based methods, 2021."
REFERENCES,0.7804878048780488,"Yujun Shen, Jinjin Gu, Xiaoou Tang, and Bolei Zhou. Interpreting the latent space of gans for
semantic face editing. In CVPR, 2020."
REFERENCES,0.7853658536585366,"Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image
recognition, 2015."
REFERENCES,0.7902439024390244,"Andrey Voynov and Artem Babenko. Unsupervised discovery of interpretable directions in the gan
latent space. In International Conference on Machine Learning, pp. 9786–9796. PMLR, 2020."
REFERENCES,0.7951219512195122,"Fisher Yu, Ari Seff, Yinda Zhang, Shuran Song, Thomas Funkhouser, and Jianxiong Xiao. Lsun:
Construction of a large-scale image dataset using deep learning with humans in the loop, 2016."
REFERENCES,0.8,"Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation
using cycle-consistent adversarial networks. In Computer Vision (ICCV), 2017 IEEE Interna-
tional Conference on, 2017."
OTHER,0.8048780487804879,"A
APPENDIX A"
OTHER,0.8097560975609757,The general representation of a tensor T in the TT format is:
OTHER,0.8146341463414634,"T[i1, ..., id] ≈G1[i1]G2[i2]...Gd[id]"
OTHER,0.8195121951219512,"Here, G1, ..., Gd are matrices of size (r, r) (if the compression rank is equal), and d is the size of the
latent space."
OTHER,0.824390243902439,"The most common way to find the cores Gk for a tensor represented by random elements is the al-
ternative least squares algorithm (ALS) Holtz et al. (2012). This algorithm consists of an alternating
best fit for each of the cores Gk in the order of k = 1, ..., d. For each core Gk, we need to solve an
independent least squares problem:"
OTHER,0.8292682926829268,"ˆGk = arg min Gk|T −[G1, ..., Gk, ...Gd]|"
OTHER,0.8341463414634146,"Here, [G1, ..., Gk, ...Gd] is a short notation for the tensor represented in the TT format, and ˆGk is the
solution for the least squares problem. This problem can be solved independently for each matrix
Gk[i], where i = 1, ..., N (N is the grid size):"
OTHER,0.8390243902439024,"ˆGk[i] = arg min Gk[i]∥T k
i −LkGk[i]Rk∥"
OTHER,0.8439024390243902,Published as a conference paper at ICOMP 2024
OTHER,0.848780487804878,"In the above equation, Lk[i1, ..., ik−1]
=
G1[i1]...Gk−1[ik−1] left side of TT format for
core k, Rk[ik+1, ..., id]
=
Gk+1[ik+1]...Gd[id] right side of TT format for core k, and
T k
i [i1, ..., ik−1, ik+1, ..., id] = T[i1, ..., ik = i, ..., id] represents a (d−1)-dimensional target tensor."
OTHER,0.8536585365853658,"If we have M tensor elements, then Lk becomes a set of vectors Lk[m] = Lk[i1 = im
1 , ..., ik−1 =
im
k−1] representing the left side of the TT format for m = 1, ..., M samples, im
1 , ..., im
d - indexes of
m-th tensor sample. Rk similarly turns into a corresponding set of vectors Rk[m] = Rk[ik+1 =
im
k+1, ..., id = im
d ]. Both Lk and Rk here have size (M k
i , r), where M k
i represents the number of
samples for which ik = i. In this case, T k
i becomes a vector of values of tensor samples correspond-
ing to ik = i. Finally the problem can then be formulated as a standard linear problem:"
OTHER,0.8585365853658536,"ˆGk[i] = arg min Gk[i]∥T k
i −(Rk ⊙Lk)vec(Gk[i])∥"
OTHER,0.8634146341463415,"In the above equation, Rk ⊙Lk represents the face-splitting product of matrices Lk and Rk of size
(M k
i , r2), and vec(Gk[i]) represents the vectorization of matrix Gk[i]. To solve the problem, M k
i
should be greater than or equal to r2 for any k and i. If this condition is not met, the system becomes
underdetermined, necessitating the setting of additional constraints."
OTHER,0.8682926829268293,"This is the main problem where the grid type affects tensor decomposition. Let us consider a uniform
grid with the following parameters: minimal value a = −3, maximal value b = 3, and grid size
N = 64. For a normally distributed variable zk, the relative number of samples inside interval
[ti, ti+1] is given by:"
OTHER,0.8731707317073171,"pk
i ="
OTHER,0.8780487804878049,"R ti+1
ti
exp(−z2
k/2)
R tN−1
t0
exp(−z2
k/2)"
OTHER,0.8829268292682927,"Here, ti = a + (b−a)"
OTHER,0.8878048780487805,"(N−1)i, and i represents the grid index in the range [0, N −1]."
OTHER,0.8926829268292683,"Based on this, we can find the ratio between the number of samples inside the first interval i = 0
and the middle one i = N/2 −1 = 31:"
OTHER,0.8975609756097561,"pk
0
pk
31
= 0.013"
OTHER,0.9024390243902439,"The discrepancy in the number of equations between i = 0 and i = 31 poses a limitation on the
rank of the decomposition. For i = 31, the system has approximately 100 times more equations
compared to i = 0. Additionally, when considering the total number of samples M = 50k, on
average, only 24 samples have i = 0 restricting the rank of the decomposition to a maximum of 4."
OTHER,0.9073170731707317,"To
address
this
issue,
we
propose
using
a
non-uniform
grid
with
intervals
[t0, t1], [t1, t2], ..., [tN−2, tN−1] such that the integral of the normal density over these inter-
vals is equal:"
OTHER,0.9121951219512195,Z ti+1
OTHER,0.9170731707317074,"ti
exp

−z2
k
2"
OTHER,0.9219512195121952,"
=
Z tj+1"
OTHER,0.926829268292683,"tj
exp

−z2
k
2 "
OTHER,0.9317073170731708,"Here, i and j can be any arbitrary values in the range [0, N −2]. By imposing this condition on grid
points, the number of equations in the linear system becomes equal for all values of i."
OTHER,0.9365853658536586,"B
APPENDIX B"
OTHER,0.9414634146341463,"Computation of tensor train cores rise a question of choosing optimal hyperparameters like rank,
method, core initialization, number of iterations (if applicable). To find the optimal rank we con-
structed the matrix C describing the pair wise dependency between two components k1 and k2:"
OTHER,0.9463414634146341,"C[jr, jc] =
E
ik,k̸=[k1,k2] T[i1, ..., ik1 = jr, ..., ik2 = jc, ..., id]"
OTHER,0.9512195121951219,Published as a conference paper at ICOMP 2024
OTHER,0.9560975609756097,"0
5
10
15
20
25
30
K 10
4 10
3 10
2 10
1 100 K/
0"
OTHER,0.9609756097560975,"Components 54 and 304
Components 113 and 318
Components 225 and 15
Components 434 and 329
Components 263 and 406"
OTHER,0.9658536585365853,"Figure 7: Normalized cumulative sum of singular values for matrix C computed for random pairs
of components"
OTHER,0.9707317073170731,"where C[jr, jc] - the element on intersection of jr-th row and jc-th column. Taking into consid-
eration the TT approximation T ≈[G1, ..., Gd] we can express previous equation from TT format
side:"
OTHER,0.975609756097561,"C[jr, jc] ≈
E
ik,k̸=[k1,k2] G1[i1]...Gk1[ik1 = jr]...Gk2[ik2 = jc]...Gd[id]"
OTHER,0.9804878048780488,"Here G1 is a vector (first TT core). Summation made along second dimension of each core produces
the following result:"
OTHER,0.9853658536585366,"C[jr, jc] ≈Gk1−1
1
Gk1[ik1 = jr]Gk2−1
k1+1Gk2[ik2 = jc]Gd
k2+1"
OTHER,0.9902439024390244,"where Gk1−1
1
is a vector representing product of averaged along middle dimension cores before k1
component, Gk2−1
k1+1 is a matrix of size (r, r) representing product of averaged along middle dimen-
sion cores after k1 and before k2 components, Gd
k2+1 is a vector representing product of averaged
along middle dimension cores after k2 component."
OTHER,0.9951219512195122,"The rank of matrix C is equal to rank(Gk1−1
1
Gk1Gk2−1
k1+1Gk2Gd
k2+1) ≤r since the smallest dimen-
sion size of tensors in the product is r. So following this formulation we could estimate the optimal
rank by evaluating the rank of matrix C computed for target tensor T. Figure 7 presents normalized
singular values for matrix C computed for different random pairs of tensor components. Based on
results we can conclude that tensor could be accurately compressed with small rank."
