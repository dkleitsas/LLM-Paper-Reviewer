Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0022624434389140274,"Neural Architecture Search (NAS) has become a popular method for discover-
1"
ABSTRACT,0.004524886877828055,"ing effective model architectures, especially for target hardware. As such, NAS
2"
ABSTRACT,0.006787330316742082,"methods that ﬁnd optimal architectures under constraints are essential. In our
3"
ABSTRACT,0.00904977375565611,"paper, we propose LayerNAS to address the challenge of multi-objective NAS
4"
ABSTRACT,0.011312217194570135,"by transforming it into a combinatorial optimization problem, which effectively
5"
ABSTRACT,0.013574660633484163,"constrains the search complexity to be polynomial.
6"
ABSTRACT,0.01583710407239819,"LayerNAS rigorously derives its method from the fundamental assumption that
7"
ABSTRACT,0.01809954751131222,"modiﬁcations to previous layers have no impact on the subsequent layers. When
8"
ABSTRACT,0.020361990950226245,"dealing with search spaces containing L layers that meet this requirement, the
9"
ABSTRACT,0.02262443438914027,"method performs layerwise-search for each layer, selecting from a set of search
10"
ABSTRACT,0.024886877828054297,"options S. LayerNAS groups model candidates based on one objective, such
11"
ABSTRACT,0.027149321266968326,"as model size or latency, and searches for the optimal model based on another
12"
ABSTRACT,0.029411764705882353,"objective, thereby splitting the cost and reward elements of the search. This
13"
ABSTRACT,0.03167420814479638,"approach limits the search complexity to O(H · |S| · L), where H is a constant set
14"
ABSTRACT,0.033936651583710405,"in LayerNAS.
15"
ABSTRACT,0.03619909502262444,"Our experiments show that LayerNAS is able to consistently discover superior mod-
16"
ABSTRACT,0.038461538461538464,"els across a variety of search spaces in comparison to strong baselines, including
17"
ABSTRACT,0.04072398190045249,"search spaces derived from NATS-Bench, MobileNetV2 and MobileNetV3.
18"
INTRODUCTION,0.042986425339366516,"1
Introduction
19"
INTRODUCTION,0.04524886877828054,"With the surge of ever-growing neural models used across all ML-based disciplines, the efﬁciency
20"
INTRODUCTION,0.04751131221719457,"of neural networks is becoming a fundamental factor in their success and applicability. A carefully
21"
INTRODUCTION,0.049773755656108594,"crafted architecture can achieve good quality while maintaining efﬁciency during inference. However,
22"
INTRODUCTION,0.05203619909502263,"designing optimized architectures is a complex and time-consuming process – this is especially
23"
INTRODUCTION,0.05429864253393665,"true when multiple objectives are involved, including the model’s performance and one or more
24"
INTRODUCTION,0.05656108597285068,"cost factors reﬂecting the model’s size, Multiply-Adds (MAdds) and inference latency. Neural
25"
INTRODUCTION,0.058823529411764705,"Architecture Search (NAS), is a highly effective paradigm for dealing with such complexities. NAS
26"
INTRODUCTION,0.06108597285067873,"automates the task and discovers more intricate and complex architectures than those that can be
27"
INTRODUCTION,0.06334841628959276,"found by humans. Additionally, recent literature shows that NAS allows to search for optimal models
28"
INTRODUCTION,0.06561085972850679,"under speciﬁc constraints (e.g., latency), with remarkable applications on architectures such as
29"
INTRODUCTION,0.06787330316742081,"MobileNetV3 [15], EfﬁcientNet [34] and FBNet [36].
30"
INTRODUCTION,0.07013574660633484,"Most NAS algorithms encode model architectures using a list of integers, where each integer
31"
INTRODUCTION,0.07239819004524888,"represents a selected search option for the corresponding layer. In particular, notice that for a
32"
INTRODUCTION,0.0746606334841629,"given model with L layers, where each layer is selected from a set of search options S, the search
33"
INTRODUCTION,0.07692307692307693,"space contains O(|S|L) candidates with different architectures. This exponential complexity presents
34"
INTRODUCTION,0.07918552036199095,"a signiﬁcant efﬁciency challenge for NAS algorithms.
35"
INTRODUCTION,0.08144796380090498,Figure 1: Comparison with baseline models and NAS methods.
INTRODUCTION,0.083710407239819,"In this paper, we present LayerNAS, an algorithm that addresses the problem of Neural Architecture
36"
INTRODUCTION,0.08597285067873303,"Search (NAS) through the framework of combinatorial optimization. The proposed approach decou-
37"
INTRODUCTION,0.08823529411764706,"ples the constraints of the model and the evaluation of its quality, and explores the factorized search
38"
INTRODUCTION,0.09049773755656108,"space more effectively in a layerwise manner, reducing the search complexity from exponential to
39"
INTRODUCTION,0.09276018099547512,"polynomial.
40"
INTRODUCTION,0.09502262443438914,"LayerNAS rigorously derives the method from the fundamental assumption: optimal models when
41"
INTRODUCTION,0.09728506787330317,"searching for layeri can be constructed from one of the models in layeri−1. For search spaces that
42"
INTRODUCTION,0.09954751131221719,"satisfy this assumption, LayerNAS enforces a directional search process from the ﬁrst layer to the
43"
INTRODUCTION,0.10180995475113122,"last layer. The directional layerwise search makes the search complexity O(C · |S| · L), where C is
44"
INTRODUCTION,0.10407239819004525,"the number of candidates to search per layer.
45"
INTRODUCTION,0.10633484162895927,"For multi-objective NAS problems, LayerNAS treats model constraints and model quality as separate
46"
INTRODUCTION,0.1085972850678733,"metrics. Rather than utilizing a single objective function that combines multi-objectives, LayerNAS
47"
INTRODUCTION,0.11085972850678733,"stores model candidates by their constraint metric value. Let Mi,h be the best model candidate for
48"
INTRODUCTION,0.11312217194570136,"layeri with cost = h. LayerNAS searches for optimal models under different constraints in the next
49"
INTRODUCTION,0.11538461538461539,"layer by adding the cost of the selected search option for next layer to the current layer, i.e., Mi,h.
50"
INTRODUCTION,0.11764705882352941,"This transforms the problem into the following combinatorial optimization problem: for a model with
51"
INTRODUCTION,0.11990950226244344,"L layers, what is the optimal combination of options for all layers needed to achieve the best quality
52"
INTRODUCTION,0.12217194570135746,"under the cost constraint? If we bucketize the potential model candidates by their cost, the search
53"
INTRODUCTION,0.1244343891402715,"space is limited to O(H · |S| · L), where H is number of buckets per layer. In practice, capping the
54"
INTRODUCTION,0.12669683257918551,"search at 100 buckets achieves reasonable performance. Since this holds H constant, it makes the
55"
INTRODUCTION,0.12895927601809956,"search complexity polynomial.
56"
INTRODUCTION,0.13122171945701358,"Our contributions can be summarized as follows:
57"
INTRODUCTION,0.1334841628959276,"• We propose LayerNAS, an algorithm that transforms the multi-objective NAS problem to a
58"
INTRODUCTION,0.13574660633484162,"Combinatorial Optimization problem. This is a novel formulation of NAS.
59"
INTRODUCTION,0.13800904977375567,"• LayerNAS is directly designed to tackle the search complexity of NAS, and reduce the
60"
INTRODUCTION,0.14027149321266968,"search complexity from O(|S|L) to O(H · |S| · L), where H is a constant deﬁned in the
61"
INTRODUCTION,0.1425339366515837,"algorithm.
62"
INTRODUCTION,0.14479638009049775,"• We demonstrate the effectiveness of LayerNAS by identifying high-performing model
63"
INTRODUCTION,0.14705882352941177,"architectures under various Multiply-Adds (MAdds) constraints, by searching through
64"
INTRODUCTION,0.1493212669683258,"search spaces derived from MobileNetV2 [30] and MobileNetV3 [15].
65"
RELATED WORK,0.1515837104072398,"2
Related Work
66"
RELATED WORK,0.15384615384615385,"The survey by [12] categorizes methods for Neural Architecture Search into three dimensions: search
67"
RELATED WORK,0.15610859728506787,"space, search strategy, and performance estimation strategy. The formulation of NAS as different
68"
RELATED WORK,0.1583710407239819,"Figure 2: Illustration of the LayerNAS Algorithm described in Algorithm 1. For each layer: (1) select
a model candidate from current layer and generate children candidates; (2) ﬁlter out candidates not in
the target objective range; (3) update the model in the bucket if there’s a candidate with better quality;
and ﬁnally, move to the next layer."
RELATED WORK,0.16063348416289594,"problems has led to the development of a diverse array of search algorithms. Bayesian Optimization
69"
RELATED WORK,0.16289592760180996,"is ﬁrst adopted for hyper-parameter tuning [3, 9, 13, 20]. Reinforcement Learning is utilized for
70"
RELATED WORK,0.16515837104072398,"training an agent to interact with a search space [45, 27, 46, 19]. Evolutionary algorithms [24, 29]
71"
RELATED WORK,0.167420814479638,"have been employed by encoding model architectures to DNA and evolving the candidate pool.
72"
RELATED WORK,0.16968325791855204,"ProgressiveNAS [22] uses heuristic search to gradually build models by starting from simple and
73"
RELATED WORK,0.17194570135746606,"shallow model architectures and incrementally adding more operations to arrive at deep and complex
74"
RELATED WORK,0.17420814479638008,"ﬁnal architectures. This is in contrast to LayerNAS, which iterates over changes in the layers of a full
75"
RELATED WORK,0.17647058823529413,"complex model.
76"
RELATED WORK,0.17873303167420815,"Recent advancements in mobile image models, such as MobileNetV3 [15], EfﬁcientNet [34], FB-
77"
RELATED WORK,0.18099547511312217,"Net [36], are optimized by NAS. The search for these models is often constrained by metrics such
78"
RELATED WORK,0.1832579185520362,"as FLOPs, model size, latency, and others. To solve this multi-objective problem, most NAS al-
79"
RELATED WORK,0.18552036199095023,"gorithms [33, 5] design an objective function that combines these metrics into a single objective.
80"
RELATED WORK,0.18778280542986425,"LEMONADE [11] proposes a method to split two metrics, and searches for a Pareto front of a family
81"
RELATED WORK,0.19004524886877827,"of models. Once-for-All [4] proposes progressive shrinking algorithm to efﬁciently ﬁnd optimal
82"
RELATED WORK,0.19230769230769232,"model architectures under different constraints.
83"
RELATED WORK,0.19457013574660634,"Larger models tend to have better performance compared to smaller models. However, the increased
84"
RELATED WORK,0.19683257918552036,"size of models also means increased computational resource requirement. As a result, the optimization
85"
RELATED WORK,0.19909502262443438,"of neural architectures within constrained resources is an important and meaningful aspect of NAS
86"
RELATED WORK,0.20135746606334842,"problems, which can be solved as multi-objective optimization [16]. There is increasing interest in
87"
RELATED WORK,0.20361990950226244,"treating NAS as a compression problem [43, 42] from an over-sized model. These works indicate
88"
RELATED WORK,0.20588235294117646,"that compressing with different conﬁgurations on each layer leads to a model better than uniform
89"
RELATED WORK,0.2081447963800905,"compression. Here, NAS can be used to search for optimal conﬁgurations [14, 25, 35].
90"
RELATED WORK,0.21040723981900453,"The applicability of NAS is signiﬁcantly inﬂuenced by the efﬁciency of its search process. One-shot
91"
RELATED WORK,0.21266968325791855,"algorithms [23, 5, 1, 2] provide a novel approach by constructing a supernet from the search space to
92"
RELATED WORK,0.2149321266968326,"perform more efﬁcient NAS. However, this approach has limit on number of branches in supernet due
93"
RELATED WORK,0.2171945701357466,"to the constraints of supernet size. The search cost is not only bounded by the complexity of search
94"
RELATED WORK,0.21945701357466063,"space, but also the cost of training under ""train-and-eval"" paradigm. Training-free NAS [26, 6, 44, 32]
95"
RELATED WORK,0.22171945701357465,"breaks this paradigm by estimating the model quality with other metrics that are fast to compute.
96"
RELATED WORK,0.2239819004524887,"However, the search quality heavily relies on the effectiveness of the metrics.
97"
RELATED WORK,0.22624434389140272,"3
Problem Deﬁnition
98"
RELATED WORK,0.22850678733031674,"Most NAS algorithms do not differentiate the various types of NAS problems. Rather, they employ
99"
RELATED WORK,0.23076923076923078,"a single encoding of the search space with a general solution for the search process. However, the
100"
RELATED WORK,0.2330316742081448,"unique characteristics of NAS problems can be leveraged to design a tailored approach. We categorize
101"
RELATED WORK,0.23529411764705882,"NAS problems into three major types:
102"
RELATED WORK,0.23755656108597284,"• Topology search: the search space deﬁnes a graph with multiple nodes. The objective is
103"
RELATED WORK,0.2398190045248869,"to identify an optimal topology for connecting nodes with different operations. This task
104"
RELATED WORK,0.2420814479638009,"allows for the exploration of novel architectures.
105"
RELATED WORK,0.24434389140271492,"• Size search or compression search: the search occurs on a predeﬁned model architecture
106"
RELATED WORK,0.24660633484162897,"with multiple layers. Each layer can be selected from as a set of search options. Empirically,
107"
RELATED WORK,0.248868778280543,"the best-performing model is normally the one with the most parameters per layer. Therefore,
108"
RELATED WORK,0.251131221719457,"in practice, we aim to search for the optimal model under certain constraints. NATSBench
109"
RELATED WORK,0.25339366515837103,"size search [10] provides a public dataset for this type of task. MobilNetV3 [15], Efﬁcient-
110"
RELATED WORK,0.25565610859728505,"Net [34], FBNet [36] also establish the search space in this manner. This problem can also
111"
RELATED WORK,0.2579185520361991,"be viewed as a compression problem [14], as reducing the layer size serves as a means of
112"
RELATED WORK,0.26018099547511314,"compression by decreasing the model size, FLOPs and latency.
113"
RELATED WORK,0.26244343891402716,"• Scale search: model architectures are uniformly conﬁgured by hyper-parameters, such
114"
RELATED WORK,0.2647058823529412,"as number of layers or size of fully-connected layers. This task views the model as a
115"
RELATED WORK,0.2669683257918552,"holistic entity and uniformly scales it up or down, rather than adjusting individual layers or
116"
RELATED WORK,0.2692307692307692,"components.
117"
RELATED WORK,0.27149321266968324,"This taxonomy illustrates the signiﬁcant variation among NAS problems. Rather than proposing
118"
RELATED WORK,0.2737556561085973,"a general solution to address all of them, we propose to tackle with search spaces in a layerwise
119"
RELATED WORK,0.27601809954751133,"manner. Speciﬁcally, we aim to ﬁnd a model with L layers. For each layeri, we select from a set of
120"
RELATED WORK,0.27828054298642535,"search options Si. A model candidate M can be represented as a tuple with size L: (s1, s2, ..., sL).
121"
RELATED WORK,0.28054298642533937,"si ∈Si is a selected search option on layeri. The objective is to ﬁnd an optimal model architecture
122"
RELATED WORK,0.2828054298642534,"M = (s1, s2, ..., sL) with the highest accuracy:
123"
RELATED WORK,0.2850678733031674,"argmax
(s1,s2,...,sL)
Accuracy(M)
(1)"
METHOD,0.2873303167420814,"4
Method
124"
METHOD,0.2895927601809955,"We propose LayerNAS as an algorithm that leverages layerwise attributes. When searching models
125"
METHOD,0.2918552036199095,"Mi on layeri, we are searching for architectures in the form of (s1..i−1, xi, oi+1..L). s1..i−1 are
126"
METHOD,0.29411764705882354,"the selected options for layer1..i−1, and oi+1..L are the default, predeﬁned options. xi is the search
127"
METHOD,0.29638009049773756,"option selected for layeri, which is the current layer in the search. In this formulation, only layeri
128"
METHOD,0.2986425339366516,"can be changed, all preceding layers are ﬁxed, and all succeeding layers are using the default option.
129"
METHOD,0.3009049773755656,"In topology search, the default option is usually no-op; in size search, the default option can be the
130"
METHOD,0.3031674208144796,"option with most computation.
131"
METHOD,0.3054298642533937,"LayerNAS operates on a search space that meets the following assumption, which has been implicitly
132"
METHOD,0.3076923076923077,"utilized by past chain-structured NAS techniques [22, 33, 15].
133"
METHOD,0.30995475113122173,"Assumption 4.1. The optimal model Mi on layeri can be constructed from a model m ∈Mi−1,
134"
METHOD,0.31221719457013575,"where Mi−1 is a set of model candidates on layeri−1.
135"
METHOD,0.31447963800904977,"This assumption implies:
136"
METHOD,0.3167420814479638,"• Enforcing a sequential search process is possible when exploring layeri because improve-
137"
METHOD,0.3190045248868778,"ments to the model cannot be achieved by modifying layeri−1.
138"
METHOD,0.3212669683257919,"• The information for ﬁnding an optimal model architecture on layeri was collected when
139"
METHOD,0.3235294117647059,"searching for model architectures on layeri−1.
140"
METHOD,0.3257918552036199,"• Search spaces that are constructed in a layerwise manner, such as those in size search
141"
METHOD,0.32805429864253394,"problems discussed in Section 3, can usually meet this assumption. Each search option can
142"
METHOD,0.33031674208144796,"completely deﬁne how to construct a succeeding layer, and does not depend on the search
143"
METHOD,0.332579185520362,"options in previous layers.
144"
METHOD,0.334841628959276,"• It’s worth noting that not all search spaces can meet the assumption. Succeeding layers
145"
METHOD,0.33710407239819007,"may be coupled with or affect preceding layers in some cases. In practice, we transform the
146"
METHOD,0.3393665158371041,"search space in Section 5 to ensure that it meets the assumption.
147"
LAYERNAS FOR TOPOLOGY SEARCH,0.3416289592760181,"4.1
LayerNAS for Topology Search
148"
LAYERNAS FOR TOPOLOGY SEARCH,0.3438914027149321,"The LayerNAS algorithm is described by the pseudo code in Algorithm 1. Ml is a set of model candi-
149"
LAYERNAS FOR TOPOLOGY SEARCH,0.34615384615384615,"dates on layerl. Ml,h is the model on layerl mapped to h ∈H, a lower dimensional representation.
150"
LAYERNAS FOR TOPOLOGY SEARCH,0.34841628959276016,"H is usually a ﬁnite integer set, so that we can index and store models.
151"
LAYERNAS FOR TOPOLOGY SEARCH,0.3506787330316742,Algorithm 1 LayerNAS algorithm
LAYERNAS FOR TOPOLOGY SEARCH,0.35294117647058826,"Inputs: L (num layers), R (num searches per layer), T (num models to generate in next layer)
l = 1
M1 = {∀M1}
repeat"
LAYERNAS FOR TOPOLOGY SEARCH,0.3552036199095023,for i = 1 to R do
LAYERNAS FOR TOPOLOGY SEARCH,0.3574660633484163,"Ml = select(Ml)
for j = 1 to T do"
LAYERNAS FOR TOPOLOGY SEARCH,0.3597285067873303,"Ml+1 = apply_search_option(Ml, Sl+1)
h = ϕ(Ml+1)
accuracy = train_and_eval(Ml+1)
if accuracy > Accuracy(Ml+1,h) then"
LAYERNAS FOR TOPOLOGY SEARCH,0.36199095022624433,"Ml+1,h = Ml+1
end if
end for
end for
l = l + 1
if l == L then"
LAYERNAS FOR TOPOLOGY SEARCH,0.36425339366515835,"l = 1
end if
until no available candidates"
LAYERNAS FOR TOPOLOGY SEARCH,0.3665158371040724,"Some functions can be customized for different NAS problems with a-priori knowledge:
152"
LAYERNAS FOR TOPOLOGY SEARCH,0.36877828054298645,"• select: samples a model from a set of model candidates in the previous layer Ml. It could
153"
LAYERNAS FOR TOPOLOGY SEARCH,0.37104072398190047,"be a mechanism of evolutionary algorithm [29] or a trained predictor [22] to select most
154"
LAYERNAS FOR TOPOLOGY SEARCH,0.3733031674208145,"promising candidates. The method will also ﬁlter out model architectures that we do not
155"
LAYERNAS FOR TOPOLOGY SEARCH,0.3755656108597285,"need to search, usually a model architecture that is invalid or known not to generate better
156"
LAYERNAS FOR TOPOLOGY SEARCH,0.3778280542986425,"candidates. This can signiﬁcantly reduce the number of candidates to search.
157"
LAYERNAS FOR TOPOLOGY SEARCH,0.38009049773755654,"• apply_search_option: applies a search option from Sl+1 on Ml to generate Ml+1. We
158"
LAYERNAS FOR TOPOLOGY SEARCH,0.38235294117647056,"currently use random selection in the implementation, though, other methods could lead to
159"
LAYERNAS FOR TOPOLOGY SEARCH,0.38461538461538464,"improved search option.
160"
LAYERNAS FOR TOPOLOGY SEARCH,0.38687782805429866,"• ϕ : M →H maps model architecture in M to a lower dimensional representation H. ϕ
161"
LAYERNAS FOR TOPOLOGY SEARCH,0.3891402714932127,"could be an encoded index of model architecture, or other identiﬁers that group similar
162"
LAYERNAS FOR TOPOLOGY SEARCH,0.3914027149321267,"model architectures. We discuss this further in 4.2. When there is a unique id for each
163"
LAYERNAS FOR TOPOLOGY SEARCH,0.3936651583710407,"model, LayerNAS will store all model candidates in M.
164"
LAYERNAS FOR TOPOLOGY SEARCH,0.39592760180995473,"In this algorithm, the total number of model candidates we need to search is PL
i=1 |Mi| · |Si|. It has
165"
LAYERNAS FOR TOPOLOGY SEARCH,0.39819004524886875,"a polynomial form, but |ML| = O(|S|L) if we set ϕ(M) as unique id of models. This does not limit
166"
LAYERNAS FOR TOPOLOGY SEARCH,0.4004524886877828,"the order of |ML| to search. For topology search, we can design a sophisticated ϕ to group similar
167"
LAYERNAS FOR TOPOLOGY SEARCH,0.40271493212669685,"model candidates. In the following discussion, we will demonstrate how to lower the order of |ML|
168"
LAYERNAS FOR TOPOLOGY SEARCH,0.40497737556561086,"in multi-objective NAS.
169"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4072398190045249,"4.2
LayerNAS for Multi-objective NAS
170"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4095022624434389,"LayerNAS is aimed at designing an efﬁcient algorithm for size search or compression search problems.
171"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4117647058823529,"As discussed in Section 3, such problems satisfy Assumption 4.1 by nature. Multi-objective NAS
172"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.41402714932126694,"usually searches for an optimal model under some constraints, such as model size, inference latency,
173"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.416289592760181,"hardware-speciﬁc FLOPs or energy consumption. We use “cost” as a general term to refer to these
174"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.41855203619909503,"constraints. These “cost” metrics are easy to calculate and can be determined when the model
175"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.42081447963800905,"architecture is ﬁxed. This is in contrast to calculating accuracy, which requires completing the model
176"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4230769230769231,"training. Because the model is constructed in a layer-wise manner, the cost of the model can be
177"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4253393665158371,"estimated by summing the costs of all layers.
178"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4276018099547511,"Hence, we can express the multi-objective NAS problem as,
179"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4298642533936652,"argmax
(s1,s2,...,sL)
Accuracy(ML) s.t. L
X"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4321266968325792,"i=1
Cost(si) ≤target
(2)"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4343891402714932,"where Cost(si) is the cost of applying option si on layeri.
180"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.43665158371040724,"We introduce an additional assumption by considering the cost in Assumption 4.1:
181"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.43891402714932126,"Assumption 4.2. The optimal model Mi with cost = C when searching for layeri can be con-
182"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4411764705882353,"structed from the optimal model Mi−1 with cost = C −Cost(si) from Mi−1.
183"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4434389140271493,"In this assumption, we only keep one optimal model out of a set of models with similar costs. Suppose
184"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4457013574660634,"we have two models with the same cost, but Mi has better quality than M′
i. The assumption will be
185"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4479638009049774,"satisﬁed if any changes on following layers to Mi will generate a better model than making the same
186"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4502262443438914,"change to M′
i.
187"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.45248868778280543,"By applying Assumption 4.2 to Equation (2), we can formulate the problem as combinatorial
188"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.45475113122171945,"optimization:
189"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.45701357466063347,"argmax
xi
Accuracy(Mi) s.t. i−1
X"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4592760180995475,"j=1
Cost(s1..i−1, xi, oi+1,L) ≤target"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.46153846153846156,"where
Mi = (s1..i−1, xi, oi+1..L), Mi−1 = (s1..i−1, oi..L) ∈Mi−1,h′ (3)"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4638009049773756,"This formulation decouples cost from reward, so there is no need to manually design an objective
190"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4660633484162896,"function to combine these metrics into a single value, and we can avoid tuning hyper-parameters of
191"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4683257918552036,"such an objective. Formulating the problem as combinatorial optimization allows solving it efﬁciently
192"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.47058823529411764,"using dynamic programming. Ml,h can be considered as a memorial table to record best models on
193"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.47285067873303166,"layerl at cost h. For layerl, Ml generates the Ml+1 by applying different options selected from
194"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4751131221719457,"Sl+1 on layerl+1. The search complexity is O(H · |S| · L).
195"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.47737556561085975,"We do not need to store all Ml,h candidates, but rather group them with the following transformation:
196 197"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4796380090497738,"ϕ(Mi) =

Cost(Mi) −min Cost(Mi)
max Cost(Mi) −min Cost(Mi) × H

(4)"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4819004524886878,"where H is the desired number of buckets to keep. Each bucket contains model candidates with costs
198"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.4841628959276018,"in a speciﬁc range. In practice, we can set H = 100, meaning we store optimal model candidates
199"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.48642533936651583,"within 1% of the cost range.
200"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.48868778280542985,"Equation (4) limits |Mi| to be a constant value since H is a constant.
min Cost(Mi) and
201"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.49095022624434387,"max Cost(Mi) can be easily calculated when we know how to select the search option from Si+1..SL
202"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.49321266968325794,"in order to maximize or minimize the model cost. This can be achieved by deﬁning the order within
203"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.49547511312217196,"Si. Let si = 1 represent the option with the maximal cost on layeri, and si = |S| represent the
204"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.497737556561086,"option with the minimal cost on layeri. This approach for constructing the search space facilitates an
205"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.5,"efﬁcient calculation of maximal and minimal costs.
206"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.502262443438914,"The optimization applied above leads to achieving polynomial search complexity O(H · |S| · L)
207"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.504524886877828,". O(|M|) = H is upper bound of the number of model candidates in each layer, and becomes a
208"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.5067873303167421,"constant after applying Equation (4). |S| is the number of search options on each layer.
209"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.5090497737556561,"LayerNAS for Multi-objective NAS does not change the implementation of Algorithm 1. Instead, we
210"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.5113122171945701,"conﬁgure methods to perform dynamic programming with the same framework:
211"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.5135746606334841,"• ϕ: groups Mi by their costs with Equation (4)
212"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.5158371040723982,"• select: ﬁlters out Ml if all Ml+1 constructed from it are out of the range of target cost. This
213"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.5180995475113123,"signiﬁcantly reduces the number of candidates to search.
214"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.5203619909502263,"• In practice, Assumption 4.2 is not always true because accuracy may vary in each training
215"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.5226244343891403,"trial. The algorithm may store a lucky model candidate that happens to get a better accuracy
216"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.5248868778280543,"due to variation. We store multiple candidates for each h to reduce the problem from training
217"
LAYERNAS FOR MULTI-OBJECTIVE NAS,0.5271493212669683,"accuracy variation.
218"
EXPERIMENTS,0.5294117647058824,"5
Experiments
219"
SEARCH ON IMAGENET,0.5316742081447964,"5.1
Search on ImageNet
220"
SEARCH ON IMAGENET,0.5339366515837104,"Search Space: we construct several search spaces based on MobileNetV2, MobileNetV2 (width
221"
SEARCH ON IMAGENET,0.5361990950226244,"multiplier=1.4), MobileNetV3-Small and MobileNetV3-Large. For each search space, we set similar
222"
SEARCH ON IMAGENET,0.5384615384615384,"backbone of the base model. For each layer, we consider kernel sizes from {3, 5, 7}, base ﬁlters and
223"
SEARCH ON IMAGENET,0.5407239819004525,"expanded ﬁlters from a set of integers, and a ﬁxed strides. The objective is to ﬁnd better models with
224"
SEARCH ON IMAGENET,0.5429864253393665,"similar MAdds of the base model.
225"
SEARCH ON IMAGENET,0.5452488687782805,"To avoid coupling between preceding and succeeding layers, we ﬁrst search the shared base ﬁlters in
226"
SEARCH ON IMAGENET,0.5475113122171946,"each block to create residual shortcuts, and search for kernel sizes and expanded ﬁlters subsequently.
227"
SEARCH ON IMAGENET,0.5497737556561086,"This ensures the search space satisfy Assumption 4.1.
228"
SEARCH ON IMAGENET,0.5520361990950227,"We estimate and compare the number of unique model candidates deﬁned by the search space and
229"
SEARCH ON IMAGENET,0.5542986425339367,"the maximal number of searches in Table 1. In the experiments, we set H = 100, and store 3 best
230"
SEARCH ON IMAGENET,0.5565610859728507,"models with same h-value. Note that the maximal number of searches does not mean actual searches
231"
SEARCH ON IMAGENET,0.5588235294117647,"conducted in the experiments, but rather an upper bound deﬁned by the algorithm.
232"
SEARCH ON IMAGENET,0.5610859728506787,"A comprehensive description of the search spaces and discovered model architectures in this experi-
233"
SEARCH ON IMAGENET,0.5633484162895928,"ment can be found in the Appendix for further reference.
234"
SEARCH ON IMAGENET,0.5656108597285068,Table 1: Comparison of model candidates in the search spaces
SEARCH ON IMAGENET,0.5678733031674208,Search Space
SEARCH ON IMAGENET,0.5701357466063348,"Target
MAdds
# Unique
Models
# Max
Trials
MobileNetV3-Small
60M
5.0e + 20
1.2e + 5
MobileNetV3-Large
220M
4.8e + 26
1.5e + 5
MobileNetV2
300M
5.3e + 30
1.4e + 5
MobileNetV2 1.4x
600M
1.6e + 39
2.0e + 6"
SEARCH ON IMAGENET,0.5723981900452488,"Search, train and evaluation:
235"
SEARCH ON IMAGENET,0.5746606334841629,"During the search process, we train the model candidates for 5 epochs, and use the top-1 accuracy on
236"
SEARCH ON IMAGENET,0.5769230769230769,"ImageNet as a proxy metrics. Following the search process, we select several model architectures
237"
SEARCH ON IMAGENET,0.579185520361991,"with best accuracy on 5 epochs, train and evaluate them on 4x4 TPU with 4096 batch size (128
238"
SEARCH ON IMAGENET,0.581447963800905,"images per core). We use RMSPropOptimizer with 0.9 momentum, train for 500 epochs. Initial
239"
SEARCH ON IMAGENET,0.583710407239819,"learning rate is 2.64, with 12.5 warmup epochs, then decay with cosine schedule.
240"
SEARCH ON IMAGENET,0.5859728506787331,"Results
241"
SEARCH ON IMAGENET,0.5882352941176471,"We list the best models discovered by LayerNAS, and compare them with baseline models and
242"
SEARCH ON IMAGENET,0.5904977375565611,"results from recent NAS works in Table 2. For all targeted MAdds, the models discovered by
243"
SEARCH ON IMAGENET,0.5927601809954751,"LayerNAS achieve better performance: 69.0% top-1 accuracy on ImageNet for 61M MAdds, a
244"
SEARCH ON IMAGENET,0.5950226244343891,"1.6% improvement over MobileNetV3-Small; 75.6% for 229M MAdds, a 0.4% improvement over
245"
SEARCH ON IMAGENET,0.5972850678733032,"MobileNetV3-Large; 77.1% accuracy for 322M MAdds, a 5.1% improvement over MobileNetV2;
246"
SEARCH ON IMAGENET,0.5995475113122172,"and ﬁnally, 78.6% accuracy for 627M MAdds, a 3.9% improvement over MobileNetV2 1.4x.
247"
SEARCH ON IMAGENET,0.6018099547511312,"Note that for all of these models, we include squeeze-and-excitation blocks [17] and use Swish
248"
SEARCH ON IMAGENET,0.6040723981900452,"activation [28], in order to to achieve the best performance. Some recent works on NAS algorithms,
249"
SEARCH ON IMAGENET,0.6063348416289592,"as well as the original MobileNetV2, do not use these techniques. For a fair comparison, we also
250"
SEARCH ON IMAGENET,0.6085972850678733,"list the model performance after removing squeeze-and-excitation and replacing Swish activation
251"
SEARCH ON IMAGENET,0.6108597285067874,"with ReLU. The results show that the relative improvement from LayerNAS is present even after
252"
SEARCH ON IMAGENET,0.6131221719457014,"removing these components.
253"
SEARCH ON IMAGENET,0.6153846153846154,Table 2: Comparison of models on ImageNet
SEARCH ON IMAGENET,0.6176470588235294,"Model
Top1 Acc.
Params
MAdds
MobileNetV3-Small†[15]
67.4
2.5M
56M
MNasSmall [33]
64.9
1.9M
65M
LayerNAS (Ours)†
69.0
3.7M
61M
MobileNetV3-Large†[15]
75.2
5.4M
219M
LayerNAS (Ours) †
75.6
5.1M
229M
MobileNetV2⋆[30]
72.0
3.5M
300M
ProxylessNas-mobile⋆[5]
74.6
4.1M
320M
MNasNet-A1 [33]
75.2
3.9M
315M
FairNAS-C⋆[8]
74.7
5.6M
325M
LayerNAS-no-SE(Ours)⋆
75.5
3.5M
319M
EfﬁcientNet-B0 [34]
77.1
5.3M
390M
SGNAS-B [18]
76.8
-
326M
FairNAS-C†[8]
76.7
5.6M
325M
GreedyNAS-B†[41]
76.8
5.2M
324M
LayerNAS (Ours)†
77.1
5.2M
322M
MobileNetV2 1.4x⋆[30]
74.7
6.9M
585M
ProgressiveNAS⋆[22]
74.2
5.1M
588M
Shapley-NAS⋆[37]
76.1
5.4M
582M
MAGIC-AT⋆[38]
76.8
6M
598M
LayerNAS-no-SE (Ours)⋆
77.1
7.6M
598M
LayerNAS (Ours) †
78.6
9.7M
627M"
SEARCH ON IMAGENET,0.6199095022624435,"⋆Without squeeze-and-excitation blocks.
† With squeeze-and-excitation blocks."
NATS-BENCH,0.6221719457013575,"5.2
NATS-Bench
254"
NATS-BENCH,0.6244343891402715,"The following experiments compare LayerNAS with others NAS algorithms on NATS-Bench [10].
255"
NATS-BENCH,0.6266968325791855,"We evaluate NAS algorithms from these three perspectives:
256"
NATS-BENCH,0.6289592760180995,"• Candidate quality: the quality of the best candidate found by the algorithm, as can be
257"
NATS-BENCH,0.6312217194570136,"indicated by the peak value in the chart.
258"
NATS-BENCH,0.6334841628959276,"• Stability: the ability to ﬁnd the best candidate, after running multiple searches and analyzing
259"
NATS-BENCH,0.6357466063348416,"the average value and range of variation.
260"
NATS-BENCH,0.6380090497737556,"• Efﬁciency: The training time required to ﬁnd the best candidate. The sooner the peak
261"
NATS-BENCH,0.6402714932126696,"accuracy candidate is reached, the more efﬁcient the algorithm.
262"
NATS-BENCH,0.6425339366515838,"NATS-Bench topology search
263"
NATS-BENCH,0.6447963800904978,"NATS-Bench topology search deﬁnes a search space on 6 ops that connect 4 tensors, each op has
264"
NATS-BENCH,0.6470588235294118,"5 options (conv1x1, conv3x3, maxpool3x3, no-op, skip). It contains 15625 candidates with their
265"
NATS-BENCH,0.6493212669683258,"number of parameters, FLOPs, accuracy on Cifar-10, Cifar-100 [21], ImageNet16-120 [7].
266"
NATS-BENCH,0.6515837104072398,"In Table 3, we compare with recent state-of-the-art methods. Although training-free NAS has
267"
NATS-BENCH,0.6538461538461539,"advantage of lower search cost, LayerNAS can achieve much better results.
268"
NATS-BENCH,0.6561085972850679,"NATS-Bench size search
269"
NATS-BENCH,0.6583710407239819,"NATS-Bench size search deﬁnes a search space on a 5-layer CNN model, each layer has 8 options
270"
NATS-BENCH,0.6606334841628959,"on different number of channels, from 8 to 64. The search space contains 32768 model candidates.
271"
NATS-BENCH,0.6628959276018099,"The one with the highest accuracy has 64 channels for all layers, we can refer this candidate as “the
272"
NATS-BENCH,0.665158371040724,"largest model”. Instead of searching for the best model, we set the goal to search for the optimal
273"
NATS-BENCH,0.667420814479638,"model with 50% FLOPs of the largest model.
274"
NATS-BENCH,0.669683257918552,"Under this constraints for size search, we implement popular NAS algorithms for comparison, which
275"
NATS-BENCH,0.6719457013574661,"are also used in the original benchmark papers [40, 10]: random search, proximal policy optimization
276"
NATS-BENCH,0.6742081447963801,"(PPO) [31] and regularized evolution (RE) [29]. We conduct 5 runs for each algorithm, and record
277"
NATS-BENCH,0.6764705882352942,"the best accuracy at different training costs.
278"
NATS-BENCH,0.6787330316742082,"LayerNAS treats this as a compression problem. The base model, which is the largest model, has 64
279"
NATS-BENCH,0.6809954751131222,"channels on all layers. By applying search options with fewer channels, the model becomes smaller,
280"
NATS-BENCH,0.6832579185520362,"faster and less accurate. The search process is to ﬁnd the optimal model with expected FLOPs. By
281"
NATS-BENCH,0.6855203619909502,"ﬁltering out candidates that do not produce architectures falling within the expected FLOPs range,
282"
NATS-BENCH,0.6877828054298643,"we can signiﬁcantly reduce the number of candidates that need to be searched.
283"
NATS-BENCH,0.6900452488687783,"Table 3: Comparison on NATS-Bench topology search. Mean and deviation of test accuracy on 5
runs."
NATS-BENCH,0.6923076923076923,"Cifar10
Cifar100
ImageNet16-120
Search cost (sec)"
NATS-BENCH,0.6945701357466063,"RS
92.39±0.06
63.54±0.24
42.71±0.34
1e+5
RE [29]
94.13±0.18
71.40±0.50
44.76±0.64
1e+5
PPO [31]
94.02±0.13
71.68±0.65
44.95±0.52
1e+5
KNAS [39]
93.05
68.91
34.11
4200
TE-NAS [6]
93.90±0.47
71.24±0.56
42.38±0.46
1558
EigenNas [44]
93.46±0.02
71.42±0.63
45.54±0.04
-
NASI [32]
93.55±0.10
71.20±0.14
44.84±1.41
120
FairNAS [8]
93.23±0.18
71.00±1.46
42.19±0.31
1e+5
SGNAS [18]
93.53±0.12
70.31±1.09
44.98±2.10
9e+4
LayerNAS
94.34±0.12
73.01±0.63
46.58±0.59
1e+5
Optimal test accuracy
94.37
73.51
47.31"
NATS-BENCH,0.6968325791855203,Table 4: Comparison on NATS-Bench size search. Average on 5 runs.
NATS-BENCH,0.6990950226244343,"Cifar10
Cifar100
ImageNet16-120
Training time (sec)
2e+5
4e+5
6e+5
Target mFLOPs
140
140
35"
NATS-BENCH,0.7013574660633484,"Validation
Test
Validation
Test
Validation
Test
RS
0.8399
0.9265
0.5947
0.6935
0.3638
0.4381
RE [29]
0.8440
0.9282
0.6057
0.6962
0.3770
0.4476
PPO [31]
0.8432
0.9283
0.6033
0.6957
0.3723
0.4438
LayerNAS
0.8440
0.9320
0.6067
0.7064
0.3812
0.4537
Optimal validation
0.8452
0.9264
0.6060
0.6922
0.3843
0.4500
Optimal test
0.8356
0.9334
0.5870
0.7086
0.3530
0.4553"
CONCLUSION AND FUTURE WORK,0.7036199095022625,"6
Conclusion and Future Work
284"
CONCLUSION AND FUTURE WORK,0.7058823529411765,"In this research, we propose LayerNAS that formulates Multi-objective Neural Architecture Search
285"
CONCLUSION AND FUTURE WORK,0.7081447963800905,"to Combinatorial Optimization. By decoupling multi-objectives into cost and accuracy, and leverages
286"
CONCLUSION AND FUTURE WORK,0.7104072398190046,"layerwise attributes, we are able to reduce the search complexity from O(|S|L) to O(H · |S| · L).
287"
CONCLUSION AND FUTURE WORK,0.7126696832579186,"Our experiment results demonstrate the effectiveness of LayerNAS in discovering models that achieve
288"
CONCLUSION AND FUTURE WORK,0.7149321266968326,"superior performance compared to both baseline models and models discovered by other NAS
289"
CONCLUSION AND FUTURE WORK,0.7171945701357466,"algorithms under various constraints of MAdds. Speciﬁcally, models discovered through LayerNAS
290"
CONCLUSION AND FUTURE WORK,0.7194570135746606,"achieve top-1 accuracy on ImageNet of 69% for 61M MAdds, 75.6% for 229M MAdds, 77.1%
291"
CONCLUSION AND FUTURE WORK,0.7217194570135747,"for 322M MAdds, 78.6% for 627M MAdds. Furthermore, our analysis reveals that LayerNAS
292"
CONCLUSION AND FUTURE WORK,0.7239819004524887,"outperforms other NAS algorithms on NATS-Bench in all aspects including best model quality,
293"
CONCLUSION AND FUTURE WORK,0.7262443438914027,"stability and efﬁciency.
294"
CONCLUSION AND FUTURE WORK,0.7285067873303167,"While the current implementation of LayerNAS has shown promising results, several current limita-
295"
CONCLUSION AND FUTURE WORK,0.7307692307692307,"tions that can be addressed by future work:
296"
CONCLUSION AND FUTURE WORK,0.7330316742081447,"• LayerNAS is not designed to solve scale search problems mentioned in Section 3, because
297"
CONCLUSION AND FUTURE WORK,0.7352941176470589,"many hyper-parameters of model architecture are interdependent in scale search problem,
298"
CONCLUSION AND FUTURE WORK,0.7375565610859729,"which contradicts the statement in Assumption 4.1.
299"
CONCLUSION AND FUTURE WORK,0.7398190045248869,"• One-shot NAS algorithms have been shown to be more efﬁcient. We aim to investigate the
300"
CONCLUSION AND FUTURE WORK,0.7420814479638009,"potential of applying LayerNAS to One-shot NAS algorithms.
301"
REFERENCES,0.744343891402715,"References
302"
REFERENCES,0.746606334841629,"[1] Bender, G., Kindermans, P.-J., Zoph, B., Vasudevan, V., and Le, Q. (2018). Understanding and simplifying
303"
REFERENCES,0.748868778280543,"one-shot architecture search. In International conference on machine learning, pages 550–559. PMLR.
304"
REFERENCES,0.751131221719457,"[2] Bender, G., Liu, H., Chen, B., Chu, G., Cheng, S., Kindermans, P.-J., and Le, Q. V. (2020). Can weight
305"
REFERENCES,0.753393665158371,"sharing outperform random architecture search? an investigation with tunas. In Proceedings of the IEEE/CVF
306"
REFERENCES,0.755656108597285,"Conference on Computer Vision and Pattern Recognition, pages 14323–14332.
307"
REFERENCES,0.7579185520361991,"[3] Bergstra, J., Yamins, D., and Cox, D. (2013).
Making a science of model search: Hyperparameter
308"
REFERENCES,0.7601809954751131,"optimization in hundreds of dimensions for vision architectures. In International conference on machine
309"
REFERENCES,0.7624434389140271,"learning, pages 115–123. PMLR.
310"
REFERENCES,0.7647058823529411,"[4] Cai, H., Gan, C., Wang, T., Zhang, Z., and Han, S. (2020). Once for all: Train one network and specialize it
311"
REFERENCES,0.7669683257918553,"for efﬁcient deployment. In International Conference on Learning Representations.
312"
REFERENCES,0.7692307692307693,"[5] Cai, H., Zhu, L., and Han, S. (2018). Proxylessnas: Direct neural architecture search on target task and
313"
REFERENCES,0.7714932126696833,"hardware. In International Conference on Learning Representations.
314"
REFERENCES,0.7737556561085973,"[6] Chen, W., Gong, X., and Wang, Z. (2021). Neural architecture search on imagenet in four gpu hours: A
315"
REFERENCES,0.7760180995475113,"theoretically inspired perspective. arXiv preprint arXiv:2102.11535.
316"
REFERENCES,0.7782805429864253,"[7] Chrabaszcz, P., Loshchilov, I., and Hutter, F. (2017). A downsampled variant of imagenet as an alternative
317"
REFERENCES,0.7805429864253394,"to the cifar datasets. arXiv preprint arXiv:1707.08819.
318"
REFERENCES,0.7828054298642534,"[8] Chu, X., Zhang, B., and Xu, R. (2021). Fairnas: Rethinking evaluation fairness of weight sharing neural
319"
REFERENCES,0.7850678733031674,"architecture search. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages
320"
REFERENCES,0.7873303167420814,"12239–12248.
321"
REFERENCES,0.7895927601809954,"[9] Domhan, T., Springenberg, J. T., and Hutter, F. (2015). Speeding up automatic hyperparameter optimization
322"
REFERENCES,0.7918552036199095,"of deep neural networks by extrapolation of learning curves. In Twenty-fourth international joint conference
323"
REFERENCES,0.7941176470588235,"on artiﬁcial intelligence.
324"
REFERENCES,0.7963800904977375,"[10] Dong, X., Liu, L., Musial, K., and Gabrys, B. (2021). Nats-bench: Benchmarking nas algorithms for
325"
REFERENCES,0.7986425339366516,"architecture topology and size. IEEE transactions on pattern analysis and machine intelligence.
326"
REFERENCES,0.8009049773755657,"[11] Elsken, T., Metzen, J. H., and Hutter, F. (2018). Efﬁcient multi-objective neural architecture search via
327"
REFERENCES,0.8031674208144797,"lamarckian evolution. In International Conference on Learning Representations.
328"
REFERENCES,0.8054298642533937,"[12] Elsken, T., Metzen, J. H., and Hutter, F. (2019). Neural architecture search: A survey. The Journal of
329"
REFERENCES,0.8076923076923077,"Machine Learning Research, 20(1):1997–2017.
330"
REFERENCES,0.8099547511312217,"[13] Falkner, S., Klein, A., and Hutter, F. (2018). Bohb: Robust and efﬁcient hyperparameter optimization at
331"
REFERENCES,0.8122171945701357,"scale. In International Conference on Machine Learning, pages 1437–1446. PMLR.
332"
REFERENCES,0.8144796380090498,"[14] He, Y., Lin, J., Liu, Z., Wang, H., Li, L.-J., and Han, S. (2018). Amc: Automl for model compression and
333"
REFERENCES,0.8167420814479638,"acceleration on mobile devices. In Proceedings of the European conference on computer vision (ECCV),
334"
REFERENCES,0.8190045248868778,"pages 784–800.
335"
REFERENCES,0.8212669683257918,"[15] Howard, A., Sandler, M., Chu, G., Chen, L.-C., Chen, B., Tan, M., Wang, W., Zhu, Y., Pang, R., Vasudevan,
336"
REFERENCES,0.8235294117647058,"V., et al. (2019). Searching for mobilenetv3. In Proceedings of the IEEE/CVF international conference on
337"
REFERENCES,0.8257918552036199,"computer vision, pages 1314–1324.
338"
REFERENCES,0.8280542986425339,"[16] Hsu, C.-H., Chang, S.-H., Liang, J.-H., Chou, H.-P., Liu, C.-H., Chang, S.-C., Pan, J.-Y., Chen, Y.-T., Wei,
339"
REFERENCES,0.830316742081448,"W., and Juan, D.-C. (2018). Monas: Multi-objective neural architecture search using reinforcement learning.
340"
REFERENCES,0.832579185520362,"arXiv preprint arXiv:1806.10332.
341"
REFERENCES,0.834841628959276,"[17] Hu, J., Shen, L., and Sun, G. (2018). Squeeze-and-excitation networks. In Proceedings of the IEEE
342"
REFERENCES,0.8371040723981901,"conference on computer vision and pattern recognition, pages 7132–7141.
343"
REFERENCES,0.8393665158371041,"[18] Huang, S.-Y. and Chu, W.-T. (2021). Searching by generating: Flexible and efﬁcient one-shot nas with
344"
REFERENCES,0.8416289592760181,"architecture generator. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
345"
REFERENCES,0.8438914027149321,"Recognition, pages 983–992.
346"
REFERENCES,0.8461538461538461,"[19] Jaafra, Y., Laurent, J. L., Deruyver, A., and Naceur, M. S. (2019). Reinforcement learning for neural
347"
REFERENCES,0.8484162895927602,"architecture search: A review. Image and Vision Computing, 89:57–66.
348"
REFERENCES,0.8506787330316742,"[20] Kandasamy, K., Neiswanger, W., Schneider, J., Poczos, B., and Xing, E. P. (2018). Neural architecture
349"
REFERENCES,0.8529411764705882,"search with bayesian optimisation and optimal transport. Advances in neural information processing systems,
350"
REFERENCES,0.8552036199095022,"31.
351"
REFERENCES,0.8574660633484162,"[21] Krizhevsky, A., Hinton, G., et al. (2009). Learning multiple layers of features from tiny images.
352"
REFERENCES,0.8597285067873304,"[22] Liu, C., Zoph, B., Neumann, M., Shlens, J., Hua, W., Li, L.-J., Fei-Fei, L., Yuille, A., Huang, J., and
353"
REFERENCES,0.8619909502262444,"Murphy, K. (2018a). Progressive neural architecture search. In Proceedings of the European conference on
354"
REFERENCES,0.8642533936651584,"computer vision (ECCV), pages 19–34.
355"
REFERENCES,0.8665158371040724,"[23] Liu, H., Simonyan, K., and Yang, Y. (2018b). Darts: Differentiable architecture search. In International
356"
REFERENCES,0.8687782805429864,"Conference on Learning Representations.
357"
REFERENCES,0.8710407239819005,"[24] Liu, Y., Sun, Y., Xue, B., Zhang, M., Yen, G. G., and Tan, K. C. (2021). A survey on evolutionary neural
358"
REFERENCES,0.8733031674208145,"architecture search. IEEE transactions on neural networks and learning systems.
359"
REFERENCES,0.8755656108597285,"[25] Liu, Z., Mu, H., Zhang, X., Guo, Z., Yang, X., Cheng, K.-T., and Sun, J. (2019). Metapruning: Meta
360"
REFERENCES,0.8778280542986425,"learning for automatic neural network channel pruning. In Proceedings of the IEEE/CVF international
361"
REFERENCES,0.8800904977375565,"conference on computer vision, pages 3296–3305.
362"
REFERENCES,0.8823529411764706,"[26] Mellor, J., Turner, J., Storkey, A., and Crowley, E. J. (2021). Neural architecture search without training.
363"
REFERENCES,0.8846153846153846,"In International Conference on Machine Learning, pages 7588–7598. PMLR.
364"
REFERENCES,0.8868778280542986,"[27] Pham, H., Guan, M., Zoph, B., Le, Q., and Dean, J. (2018). Efﬁcient neural architecture search via
365"
REFERENCES,0.8891402714932126,"parameters sharing. In International conference on machine learning, pages 4095–4104. PMLR.
366"
REFERENCES,0.8914027149321267,"[28] Ramachandran, P., Zoph, B., and Le, Q. V. (2017). Searching for activation functions. arXiv preprint
367"
REFERENCES,0.8936651583710408,"arXiv:1710.05941.
368"
REFERENCES,0.8959276018099548,"[29] Real, E., Aggarwal, A., Huang, Y., and Le, Q. V. (2019). Regularized evolution for image classiﬁer
369"
REFERENCES,0.8981900452488688,"architecture search. In Proceedings of the aaai conference on artiﬁcial intelligence, volume 33, pages
370"
REFERENCES,0.9004524886877828,"4780–4789.
371"
REFERENCES,0.9027149321266968,"[30] Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., and Chen, L.-C. (2018). Mobilenetv2: Inverted
372"
REFERENCES,0.9049773755656109,"residuals and linear bottlenecks. In Proceedings of the IEEE conference on computer vision and pattern
373"
REFERENCES,0.9072398190045249,"recognition, pages 4510–4520.
374"
REFERENCES,0.9095022624434389,"[31] Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O. (2017). Proximal policy optimization
375"
REFERENCES,0.9117647058823529,"algorithms. arXiv preprint arXiv:1707.06347.
376"
REFERENCES,0.9140271493212669,"[32] Shu, Y., Cai, S., Dai, Z., Ooi, B. C., and Low, B. K. H. (2021). Nasi: Label-and data-agnostic neural
377"
REFERENCES,0.916289592760181,"architecture search at initialization. arXiv preprint arXiv:2109.00817.
378"
REFERENCES,0.918552036199095,"[33] Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., and Le, Q. V. (2019). Mnasnet:
379"
REFERENCES,0.920814479638009,"Platform-aware neural architecture search for mobile. In Proceedings of the IEEE/CVF Conference on
380"
REFERENCES,0.9230769230769231,"Computer Vision and Pattern Recognition, pages 2820–2828.
381"
REFERENCES,0.9253393665158371,"[34] Tan, M. and Le, Q. (2019). Efﬁcientnet: Rethinking model scaling for convolutional neural networks. In
382"
REFERENCES,0.9276018099547512,"International conference on machine learning, pages 6105–6114. PMLR.
383"
REFERENCES,0.9298642533936652,"[35] Wang, K., Liu, Z., Lin, Y., Lin, J., and Han, S. (2019). Haq: Hardware-aware automated quantization with
384"
REFERENCES,0.9321266968325792,"mixed precision. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
385"
REFERENCES,0.9343891402714932,"pages 8612–8620.
386"
REFERENCES,0.9366515837104072,"[36] Wu, B., Dai, X., Zhang, P., Wang, Y., Sun, F., Wu, Y., Tian, Y., Vajda, P., Jia, Y., and Keutzer, K. (2019).
387"
REFERENCES,0.9389140271493213,"Fbnet: Hardware-aware efﬁcient convnet design via differentiable neural architecture search. In Proceedings
388"
REFERENCES,0.9411764705882353,"of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10734–10742.
389"
REFERENCES,0.9434389140271493,"[37] Xiao, H., Wang, Z., Zhu, Z., Zhou, J., and Lu, J. (2022). Shapley-nas: Discovering operation contribution
390"
REFERENCES,0.9457013574660633,"for neural architecture search. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
391"
REFERENCES,0.9479638009049773,"Recognition, pages 11892–11901.
392"
REFERENCES,0.9502262443438914,"[38] Xu, J., Tan, X., Song, K., Luo, R., Leng, Y., Qin, T., Liu, T.-Y., and Li, J. (2022). Analyzing and
393"
REFERENCES,0.9524886877828054,"mitigating interference in neural architecture search. In International Conference on Machine Learning,
394"
REFERENCES,0.9547511312217195,"pages 24646–24662. PMLR.
395"
REFERENCES,0.9570135746606335,"[39] Xu, J., Zhao, L., Lin, J., Gao, R., Sun, X., and Yang, H. (2021). Knas: green neural architecture search. In
396"
REFERENCES,0.9592760180995475,"International Conference on Machine Learning, pages 11613–11625. PMLR.
397"
REFERENCES,0.9615384615384616,"[40] Ying, C., Klein, A., Christiansen, E., Real, E., Murphy, K., and Hutter, F. (2019). Nas-bench-101: Towards
398"
REFERENCES,0.9638009049773756,"reproducible neural architecture search. In International Conference on Machine Learning, pages 7105–7114.
399"
REFERENCES,0.9660633484162896,"PMLR.
400"
REFERENCES,0.9683257918552036,"[41] You, S., Huang, T., Yang, M., Wang, F., Qian, C., and Zhang, C. (2020). Greedynas: Towards fast one-shot
401"
REFERENCES,0.9705882352941176,"nas with greedy supernet. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
402"
REFERENCES,0.9728506787330317,"Recognition, pages 1999–2008.
403"
REFERENCES,0.9751131221719457,"[42] Yu, J. and Huang, T. (2019). Autoslim: Towards one-shot architecture search for channel numbers. arXiv
404"
REFERENCES,0.9773755656108597,"preprint arXiv:1903.11728.
405"
REFERENCES,0.9796380090497737,"[43] Zhou, H., Yang, M., Wang, J., and Pan, W. (2019). Bayesnas: A bayesian approach for neural architecture
406"
REFERENCES,0.9819004524886877,"search. In International conference on machine learning, pages 7603–7613. PMLR.
407"
REFERENCES,0.9841628959276018,"[44] Zhu, Z., Liu, F., Chrysos, G. G., and Cevher, V. (2022). Generalization properties of nas under activation
408"
REFERENCES,0.9864253393665159,"and skip connection search. arXiv preprint arXiv:2209.07238.
409"
REFERENCES,0.9886877828054299,"[45] Zoph, B. and Le, Q. V. (2017). Neural architecture search with reinforcement learning. In International
410"
REFERENCES,0.9909502262443439,"Conference on Learning Representations.
411"
REFERENCES,0.9932126696832579,"[46] Zoph, B., Vasudevan, V., Shlens, J., and Le, Q. V. (2018). Learning transferable architectures for scalable
412"
REFERENCES,0.995475113122172,"image recognition. In 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),
413"
REFERENCES,0.997737556561086,"pages 8697–8710. IEEE Computer Society.
414"
