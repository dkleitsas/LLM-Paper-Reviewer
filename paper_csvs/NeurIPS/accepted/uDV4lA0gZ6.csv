Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.002785515320334262,"Bayesian Optimization (BO) is a sample-efficient optimization algorithm widely
employed across various applications. In some challenging BO tasks, input uncer-
tainty arises due to the inevitable randomness in the optimization process, such
as machining errors, execution noise, or contextual variability. This uncertainty
deviates the input from the intended value before evaluation, resulting in signifi-
cant performance fluctuations in final result. In this paper, we introduce a novel
robust Bayesian Optimization algorithm, AIRBO, which can effectively identify a
robust optimum that performs consistently well under arbitrary input uncertainty.
Our method directly models the uncertain inputs of arbitrary distributions by em-
powering the Gaussian Process with the Maximum Mean Discrepancy (MMD)
and further accelerates the posterior inference via Nyström approximation. Rig-
orous theoretical regret bound is established under MMD estimation error and
extensive experiments on synthetic functions and real problems demonstrate that
our approach can handle various input uncertainties and achieve a state-of-the-art
performance."
INTRODUCTION,0.005571030640668524,"1
Introduction"
INTRODUCTION,0.008356545961002786,"Bayesian Optimization (BO) is a powerful sequential decision-making algorithm for high-cost black-
box optimization. Owing to its remarkable sample efficiency and capacity to balance exploration
and exploitation, BO has been successfully applied in diverse domains, including neural architec-
ture search [32], hyper-parameter tuning [4, 29, 12], and robotic control [18, 5], among others.
Nevertheless, in some real-world problems, the stochastic nature of the optimization process, such
as machining error during manufacturing, execution noise of control, or variability in contextual
factor, inevitably introduces input randomness, rendering the design parameter x to deviate to x′
before evaluation. This deviation produces a fluctuation of function value y and eventually leads
to a performance instability of the outcome. In general, the input randomness is determined by the
application scenario and can be of arbitrary distribution, even quite complex ones. Moreover, in some
cases, we cannot observe the exact deviated input x′ but a rough estimation for the input uncertainty.
This is quite common for robotics and process controls. For example, consider a robot control task
shown in Figure 1a, a drone is sent to a target location x to perform a measurement task. However,
due to the execution noise caused by the fuzzy control or a sudden wind, the drone ends up at location
x′ ∼P(x) and gets a noisy measurement y = f(x′) + ζ. Instead of observing the exact value of"
INTRODUCTION,0.011142061281337047,"(a) An example case: drone mea-
surement with execution noise."
INTRODUCTION,0.013927576601671309,(b) Problem formulation.
INTRODUCTION,0.016713091922005572,"Figure 1: Robust Bayesian optimization problem.
x′, we only have a coarse estimation of the input uncertainty P(x). The goal is to identify a robust
location that gives the maximal expected measurement under the process randomness."
INTRODUCTION,0.019498607242339833,"To find a robust optimum, it is crucial to account for input uncertainty during the optimization
process. Existing works [24, 3, 7, 10] along this direction assume that the exact input value, i.e.,
x′ in Figure 1b, is observable and construct a surrogate model using these exact inputs. Different
techniques are then employed to identify the robust optimum: Nogueira et al. utilize the unscented
transform to propagate input uncertainty to the acquisition function [24], while Beland and Nair
integrate over the exact GP model to obtain the posterior with input uncertainty [3]. Meanwhile,
[7] designs a robust confidence-bounded acquisition and applies min-max optimization to identify
the robust optimum. Similarly, [10] constructs an adversarial surrogate with samples from the exact
surrogate. These methods work quite well but are constrained by their dependence on observable
input values, which may not always be practical."
INTRODUCTION,0.022284122562674095,"An alternative approach involves directly modeling the uncertain inputs. A pioneering work by
Moreno et al. [20] assumes Gaussian input distribution and employs a symmetric Kullback-Leibler
divergence (SKL) to measure the distance of input variables. Dallaire et al. [13] implement a Gaussian
process model with an expected kernel and derive a closed-form solution by restricting the kernel to
linear, quadratic, or squared exponential kernels and assuming Gaussian inputs. Nonetheless, the
applicability of these methods is limited due to their restrictive Gaussian input distribution assumption
and kernel choice. To surmount these limitations, Oliveira et al. propose a robust Gaussian process
model that incorporates input distribution by computing an integral kernel. Although this kernel can
be applied to various distributions and offers a rigorous regret bound, its posterior inference requires
a large sampling and can be time-consuming."
INTRODUCTION,0.025069637883008356,"In this work, we propose an Arbitrary Input uncertainty Robust Bayesian Optimization algorithm
(AIRBO). This algorithm can directly model the uncertain input of arbitrary distribution and propagate
the input uncertainty into the surrogate posterior, which can then be used to guide the search for
robust optimum. To achieve this, we employ Gaussian Process (GP) as the surrogate and empower its
kernel design with the Maximum Mean Discrepancy (MMD), which allows us to comprehensively
compare the uncertain inputs in Reproducing Kernel Hilbert Space (RKHS) and accurately quantify
the target function under various input uncertainties(Sec. 3.1). Moreover, to stabilize the MMD
estimation and accelerate the posterior inference, we utilize Nyström approximation to reduce the
space complexity of MMD estimation from O(m2) to O(mh), where h ≪m (Sec. 3.2). This can
substantially improve the parallelization of posterior inference and a rigorous theoretical regret bound
is also established under the approximation error (Sec. 4). Comprehensive evaluations on synthetic
functions and real problems in Sec.5 demonstrate that our algorithm can efficiently identify robust
optimum under complex input uncertainty and achieve state-of-the-art performance."
PROBLEM FORMULATION,0.027855153203342618,"2
Problem Formulation"
PROBLEM FORMULATION,0.03064066852367688,"In this section, we first formulize the robust optimization problem under input uncertainty then briefly
review the intuition behind Bayesian Optimization and Gaussian Processes."
OPTIMIZATION WITH INPUT UNCERTAINTY,0.033426183844011144,"2.1
Optimization with Input Uncertainty"
OPTIMIZATION WITH INPUT UNCERTAINTY,0.036211699164345405,"As illustrated in Figure 1b, we consider an optimization of expensive black-box function: f(x),
where x is the design parameter to be tuned. At each iteration n, we select a new query point xn"
OPTIMIZATION WITH INPUT UNCERTAINTY,0.03899721448467967,"according to the optimization heuristics. However, due to the stochastic nature of the process, such as
machining error or execution noise, the query point is perturbed to x′
n before the function evaluation.
Moreover, we cannot observe the exact value of x′
n and only have a vague probability estimation of
its value: Pxn. After the function evaluation, we get a noisy measurement y = f(x′
n) + ζn, where ζn
is homogeneous measurement noise sampled from N(0, σ2). The goal is to find an optimal design
parameter x∗that maximizes the expected function value under input uncertainty:"
OPTIMIZATION WITH INPUT UNCERTAINTY,0.04178272980501393,"x∗= arg max
x Z"
OPTIMIZATION WITH INPUT UNCERTAINTY,0.04456824512534819,"x′∼Px
f(x′)dx′ = arg max
x
EPx[f]
(1)"
OPTIMIZATION WITH INPUT UNCERTAINTY,0.04735376044568245,"Depending on the specific problem and randomness source, the input distribution Px can be arbitrary
in general and even become quite complex sometimes. Here we do not place any additional assump-
tion on them, except assuming we can sample from these input distributions, which can be easily
done by approximating it with Bayesian methods and learning a parametric probabilistic model [16].
Additionally, we assume the exact values of x′ are inaccessible, which is quite common in some
real-world applications, particularly in robotics and process control [25]."
BAYESIAN OPTIMIZATION,0.05013927576601671,"2.2
Bayesian Optimization"
BAYESIAN OPTIMIZATION,0.052924791086350974,"In this paper, we focus on finding the robust optimum with BO. Each iteration of BO involves two
key steps: I) fitting a surrogate model and II) maximizing an acquisition function."
BAYESIAN OPTIMIZATION,0.055710306406685235,"Gaussian Process Surrogate: To build a sample-efficient surrogate, we choose Gaussian Process
(GP) as the surrogate model in this paper. Following [34], GP can be interpreted from a weight-
space view: given a set of n observations, Dn = {(xi, yi)|i = 1, ..., n}. Denote all the inputs as
X ∈RD×n and all the output vector as y ∈Rn×1. We first consider a linear surrogate:"
BAYESIAN OPTIMIZATION,0.0584958217270195,"f(x) = xT w, y = f(x) + ζ, ζ ∼N(0, σ2),
(2)"
BAYESIAN OPTIMIZATION,0.06128133704735376,"where w is the model parameters and ζ is the observation noise. This model’s capacity is limited due
to its linear form. To obtain a more powerful surrogate, we can extend it by projecting the input x into
a feature space ϕ(x). By taking a Bayesian treatment and placing a zero mean Gaussian prior on the
weight vector: w ∼N(0, Σp), its predictive distribution can be derived as follows (see Section2.1
of [34] for detailed derivation):"
BAYESIAN OPTIMIZATION,0.06406685236768803,"f∗|x∗, X, y ∼N
 
ϕT (x∗)Σpϕ(X)(A + σ2
nI)−1y,"
BAYESIAN OPTIMIZATION,0.06685236768802229,"ϕT (x∗)Σpϕ(x∗) −ϕT (x∗)Σpϕ(X)(A + σ2
nI)−1ϕT (X)Σpϕ(x∗)

,
(3)"
BAYESIAN OPTIMIZATION,0.06963788300835655,"where A = ϕT (X)Σpϕ(X) and I is a identity matrix. Note the predictive distribution is also a
Gaussian and the feature mappings are always in the form of inner product with respect to Σp.
This implies we are comparing inputs in a feature space and enables us to apply kernel trick.
Therefore, instead of exactly defining a feature mapping ϕ(·), we can define a kernel: k(x, x′) =
ϕ(x)T Σpϕ(x′) = ψ(x) · ψ(x′). Substituting it into Eq. 3 gives the vanilla GP posterior:"
BAYESIAN OPTIMIZATION,0.07242339832869081,"f∗|X, y, X∗∼N(µ∗, Σ∗), where µ∗= K(X∗, X)[K(X, X) + σ2
nI]−1y,"
BAYESIAN OPTIMIZATION,0.07520891364902507,"Σ∗= K(X∗, X∗) −K(X∗, X)[K(X, X) + σ2
nI]−1K(X, X∗).
(4)"
BAYESIAN OPTIMIZATION,0.07799442896935933,"From this interpretation of GP, we note that its core idea is to project the input x to a (possibly
infinite) feature space ψ(x) and compare them in the Reproducing Kernel Hilbert Space (RKHS)
defined by kernel."
BAYESIAN OPTIMIZATION,0.0807799442896936,"Acquisition Function Optimization: Given the posterior of GP surrogate model, the next step is
to decide a query point xn. The exploitation and exploration balance is achieved by designing an
acquisition function α(x|Dn). Through numerous acquisition functions exist [28], we follow [25, 7]
and adopt the Upper Confidence Bound (UCB) acquisition:"
BAYESIAN OPTIMIZATION,0.08356545961002786,"α(x|Dn) = µ∗(x) + βσ∗(x),
(5)"
BAYESIAN OPTIMIZATION,0.08635097493036212,where β is a hyper-parameter to control the level of exploration.
PROPOSED METHOD,0.08913649025069638,"3
Proposed Method"
PROPOSED METHOD,0.09192200557103064,"To cope with randomness during the optimization process, we aim to build a robust surrogate that can
directly accept the uncertain inputs of arbitrary distributions and propagate the input uncertainty into"
PROPOSED METHOD,0.0947075208913649,"the posterior. Inspired by the weight-space interpretation of GP, we empower GP kernel with MMD
to compare the uncertain inputs in RKHS. In this way, the input randomness is considered during the
covariance computation and naturally reflected in the resulting posterior , which then can be used to
guide the search for a robust optimum(Sec. 3.1). To further accelerate the posterior inference, we
employ Nyström approximation to stabilize the MMD estimation and reduce its space complexity
(Sec. 3.2)."
MODELING THE UNCERTAIN INPUTS,0.09749303621169916,"3.1
Modeling the Uncertain Inputs"
MODELING THE UNCERTAIN INPUTS,0.10027855153203342,"Assume Px ∈PX ⊂P are a set of distribution densities over Rd, representing the distributions of
the uncertain inputs. We are interested in building a GP surrogate over the probability space P, which
requires to measure the difference between the uncertain inputs."
MODELING THE UNCERTAIN INPUTS,0.10306406685236769,"To do so, we turn to the Integral Probabilistic Metric (IPM) [23]. The basic idea behind IPM is
to define a distance measure between two distributions P and Q as the supremum over a class of
functions G of the absolute expectation difference:"
MODELING THE UNCERTAIN INPUTS,0.10584958217270195,"d(P, Q) = sup
g∈G
|Eu∼P g(u) −Ev∼Qg(v)|,
(6)"
MODELING THE UNCERTAIN INPUTS,0.10863509749303621,"where G is a class of functions that satisfies certain conditions. Different choices of G lead to various
IPMs. For example, if we restrict the function class to be uniformly bounded in RKHS we can get the
MMD [15], while a Lipschitz-continuous G realizes the Wasserstein distance [14]."
MODELING THE UNCERTAIN INPUTS,0.11142061281337047,"In this work, we choose MMD as the distance measurement for the uncertain inputs because of
its intrinsic connection with distance measurement in RKHS. Given a characteristic kernel k :
Rd × Rd →R and associate RKHS Hk, define the mean map ψ : P →Hk such that ⟨ψ(P), g⟩=
EP [g], ∀g ∈Hk. The MMD between P, Q ∈P is defined as:"
MODELING THE UNCERTAIN INPUTS,0.11420612813370473,"MMD(P, Q) =
sup
||g||k≤1
[Eu∼P g(u) −Ev∼Qg(v)] = ||ψP −ψQ||,
(7)"
MODELING THE UNCERTAIN INPUTS,0.116991643454039,"Without any additional assumption on the input distributions, except we can get m samples
{ui}m
i=1, {vi}m
i=1 from P, Q respectively, MMD can be empirically estimated as follows [21]:"
MODELING THE UNCERTAIN INPUTS,0.11977715877437325,"MMD2(P, Q) ≈
1
m(m −1) X"
MODELING THE UNCERTAIN INPUTS,0.12256267409470752,"1≤i,j≤m,i̸=j
(k(ui, uj) + k(vi, vj)) −2 m2
X"
MODELING THE UNCERTAIN INPUTS,0.12534818941504178,"1≤i,j≤m
k(ui, vj),
(8)"
MODELING THE UNCERTAIN INPUTS,0.12813370473537605,"To integrate MMD into the GP surrogate, we design an MMD-based kernel over P as follows:"
MODELING THE UNCERTAIN INPUTS,0.1309192200557103,"ˆk(P, Q) = exp(−αMMD2(P, Q)),
(9)"
MODELING THE UNCERTAIN INPUTS,0.13370473537604458,"with a learnable scaling parameter α. This is a valid kernel, and universal w.r.t. C(P) under mild
conditions (see Theorem 2.2, [11]). Also, it is worth to mention that, to compute the GP posterior, we
only need to sample m points from the input distributions, but do not require their corresponding
function values."
MODELING THE UNCERTAIN INPUTS,0.13649025069637882,"With the MMD kernel, our surrogate model places a prior GP(0, ˆk(Px, Px′)) and obtain a dataset
Dn = {(ˆxi, yi)|ˆxi ∼Pxi, i = 1, 2, ..., n)}. The posterior is Gaussian with mean and variance:"
MODELING THE UNCERTAIN INPUTS,0.1392757660167131,"ˆµn(P∗) = ˆkn(P∗)T ( ˆKn + σ2I)−1yn
(10)"
MODELING THE UNCERTAIN INPUTS,0.14206128133704735,"ˆσ2
n(P∗) = ˆk(P∗, P∗) −ˆkn(P∗)T ( ˆKn + σ2I)−1ˆkn(P∗),
(11)"
MODELING THE UNCERTAIN INPUTS,0.14484679665738162,"where yn := [y1, · · · , yn]T , ˆkn(P∗) := [ˆk(P∗, Px1), · · · , ˆk(P∗, Pxn)]T and [ ˆKn]ij = ˆk(Pxi, Pxj)."
MODELING THE UNCERTAIN INPUTS,0.14763231197771587,"3.2
Boosting posterior inference with Nyström Approximation"
MODELING THE UNCERTAIN INPUTS,0.15041782729805014,"To derive the posterior distribution of our robust GP surrogate, it requires estimating the MMD
between each pair of inputs. Gretton et al. prove the empirical estimator in Eq. 8 approximates MMD
in a bounded and asymptotic way [15]. However, the sampling size m used for estimation greatly
affects the approximation error and insufficient sampling leads to a high estimation variance(ref.
Figure 3a)."
MODELING THE UNCERTAIN INPUTS,0.1532033426183844,"Such an MMD estimation variance causes numerical instability of the covariance matrix and propa-
gates into the posterior distribution and acquisition function, rendering the search for optimal query
point a challenging task. Figure 3b gives an example of MMD-GP posterior with insufficient samples,
which produces a noisy acquisition function and impedes the search of optima. Increasing the
sampling size can help alleviate this issue. However, the computation and space complexities of
the empirical MMD estimator scale quadratically with the sampling size m. This leaves us with a
dilemma that insufficient sampling results in a highly-varied posterior while a larger sample size can
occupy significant GPU memory and reduce the ability for parallel computation."
MODELING THE UNCERTAIN INPUTS,0.15598885793871867,"To reduce the space and computation complexity while retaining a stable MMD estimation, we resort
to the Nyström approximation [33]. This method alleviates the computational cost of kernel matrix by
randomly selecting h subsamples from the m samples(h ≪m) and computes an approximated matrix
via ˜K = KmhK+
h KT
mh. Combining this with the MMD definition gives its Nyström estimator:"
MODELING THE UNCERTAIN INPUTS,0.15877437325905291,"MMD2(P, Q) = Eu,u′∼P N P [k(u, u′)] + Ev,v′∼Q N Q[k(v, v′)] −2Eu,v∼P N Q[k(u, v)]"
MODELING THE UNCERTAIN INPUTS,0.1615598885793872,"≈
1
m2 1T
mU1m + 1"
MODELING THE UNCERTAIN INPUTS,0.16434540389972144,"m2 1T
mV 1m −2"
MODELING THE UNCERTAIN INPUTS,0.1671309192200557,"m2 1T
mW1m"
MODELING THE UNCERTAIN INPUTS,0.16991643454038996,"≈
1
m2 1T
mUmhU +
h U T
mh1n + 1"
MODELING THE UNCERTAIN INPUTS,0.17270194986072424,"m2 1T
mVmhV +
h V T
mh1m −2"
MODELING THE UNCERTAIN INPUTS,0.17548746518105848,"m2 1T
mWmhW +
h W T
mh1m
(12)"
MODELING THE UNCERTAIN INPUTS,0.17827298050139276,"where U = K(u, u′), V = K(v, v′), W = K(u, v) are the kernel matrices, 1m represents a
m-by-1 vector of ones, m defines the sampling size and h controls the sub-sampling size. Note that
this Nyström estimator reduces the space complexity of posterior inference from O(MNm2) to
O(MNmh), where M and N are the numbers of training and testing samples, m is the sampling
size for MMD estimation while h ≪m is the sub-sampling size. This can significantly boost the
posterior inference of robust GP by allowing more inference to run in parallel on GPU."
THEORETICAL ANALYSIS,0.181058495821727,"4
Theoretical Analysis"
THEORETICAL ANALYSIS,0.18384401114206128,"Assume x ∈X ⊂Rd, and Px ∈PX ⊂P are a set of distribution densities over Rd, representing the
distribution of the noisy input. Given a characteristic kernel k : Rd × Rd →R and associate RKHS
Hk, we define the mean map ψ : P →Hk such that ⟨ψ(P), g⟩= EP [g], ∀g ∈Hk."
THEORETICAL ANALYSIS,0.18662952646239556,"We consider a more general case. Choosing any suitable functional L such that ˆk(P, P ′) :=
L(ψP , ψP ′) is a positive-definite kernel over P, for example the linear kernel ⟨ψP , ψP ′⟩k and radial
kernels exp(−α∥ψP −ψP ′∥2
k) using the MMD distance as a metric. Such a kernel ˆk is associated
with a RKHS Hˆk containing functions over the space of probability measures P."
THEORETICAL ANALYSIS,0.1894150417827298,"One important theoretical guarantee to conduct GP model is that our object function can be ap-
proximated by functions in Hˆk, which relies on the universality of ˆk. Let C(P) be the class of
continuous functions over P endowed with the topology of weak convergence and the associated
Borel σ-algebra, and we define ˆf ∈C(P) such that"
THEORETICAL ANALYSIS,0.19220055710306408,"ˆf(P) := EP [f], ∀P ∈P,"
THEORETICAL ANALYSIS,0.19498607242339833,"which is just our object function, For ˆk be radial kernels, it has been shown that ˆk is universal w.r.t
C(P) given that X is compact and the mean map ψ is injective [11, 22]. For ˆk be linear kernel which
is not universal, it has been shown in Lemma 1, [26] that ˆf ∈Hˆk if and only if f ∈H and further
∥ˆf∥ˆk = ∥f∥k. Thus, in the remain of this chapter, we may simply assume ˆf ∈Hˆk."
THEORETICAL ANALYSIS,0.1977715877437326,"Suppose we have an approximation kernel function ˜k(P, Q) near to the exact kernel function ˆk(P, Q).
The mean ˆµn(p∗) and variance ˆσ2
n(p∗) are approximated by"
THEORETICAL ANALYSIS,0.20055710306406685,"˜µn(P∗) = ˜kn(P∗)T ( ˜Kn + σ2I)−1yn
(13)"
THEORETICAL ANALYSIS,0.20334261838440112,"˜σ2
n(P∗) = ˜k(P∗, P∗) −˜kn(P∗)T ( ˜Kn + σ2I)−1˜kn(P∗),
(14)"
THEORETICAL ANALYSIS,0.20612813370473537,"where yn := [y1, · · · , yn]T , ˜kn(P∗) := [˜k(P∗, P1), · · · , ˜k(P∗, Pn)]T and [ ˜Kn]ij = ˜k(Pi, Pj)."
THEORETICAL ANALYSIS,0.20891364902506965,The maximum information gain corresponding to the kernel ˆk is denoted as
THEORETICAL ANALYSIS,0.2116991643454039,"ˆγn :=
sup
R∈PX ;|R|=n
ˆI(yn;ˆfn|R) = 1"
THEORETICAL ANALYSIS,0.21448467966573817,"2 ln det(I + σ−2 ˆKn),"
THEORETICAL ANALYSIS,0.21727019498607242,"Denote e(P, Q) = ˆk(P, Q)−˜k(P, Q) as the error function when estimating the kernel ˆk. We suppose
e(P, Q) has an upper bound with high probability:
Assumption 1. For any ε > 0, P, Q ∈PX , we may choose an estimated ˜k(P, Q) such that
the error function e(P, Q) can be upper-bounded by eε with probability at least 1 −ε, that is,
P (|e(P, Q)| ≤eε) > 1 −ε."
THEORETICAL ANALYSIS,0.2200557103064067,"Remark. Note that this assumption is standard in our case: we may assume maxx∈X ∥ϕ∥k ≤Φ,
where ϕ is the feature map corresponding to the k. Then when using empirical estimator, the error
between MMDempirical and MMD is controlled by 4Φ
p"
THEORETICAL ANALYSIS,0.22284122562674094,"2 log(6/ε)m−1 with probability at least 1 −ε
according to Lemma E.1, [8]. When using the Nyström estimator, the error has a similar form as the
empirical one, and under mild conditions, when h = O(√m log(m)), we get the error of the order
O(m−1/2 log(1/ε)) with probability at least 1 −ε. One can check more details in Lemma 1."
THEORETICAL ANALYSIS,0.22562674094707522,"Now we restrict our Gaussian process in the subspace PX = {Px, x ∈X} ⊂P. We assume the
observation yi = f(xi) + ζi with the noise ζi. The input-induced noise is defined as ∆fpxi :=
f(xi) −EPxi[f] = f(xi) −ˆf(Pxi). Then the total noise is yi −EPxi[f] = ζi + ∆fpxi . We can state
our main result, which gives a cumulative regret bound under inexact kernel calculations,
Theorem 1. Let δ > 0, f ∈Hk, and the corresponding ∥ˆf∥ˆk ≤b, maxx∈X |f(x)| = M. Suppose
the observation noise ζi = yi −f(xi) is σζ-sub-Gaussian, and thus with high probability |ζi| < A
for some A > 0. Assume that both k and Px satisfy the conditions for ∆fPx to be σE-sub-Gaussian,
for a given σE > 0. Then, under Assumption 1 with ε > 0 and corresponding eε, setting σ2 = 1+ 2"
THEORETICAL ANALYSIS,0.22841225626740946,"n,
running Gaussian Process with acquisition function
˜α(x|Dn) = ˜µn(Px) + βn˜σn(Px)
(15)"
THEORETICAL ANALYSIS,0.23119777158774374,"where βn =

b +
q"
THEORETICAL ANALYSIS,0.233983286908078,"σ2
E + σ2
ζ
p"
THEORETICAL ANALYSIS,0.23676880222841226,"2 (ˆγn + 1 −ln δ)

,"
THEORETICAL ANALYSIS,0.2395543175487465,"we have that the uncertain-inputs cumulative regret satisfies:
˜Rn ∈O
p"
THEORETICAL ANALYSIS,0.24233983286908078,nˆγn(ˆγn −ln δ) + n2p
THEORETICAL ANALYSIS,0.24512534818941503,"(ˆγn −ln δ)eε + n3eε

(16)"
THEORETICAL ANALYSIS,0.2479108635097493,"with probability at least 1 −δ −nε. Here ˜Rn = Pn
t=1 ˜rt, and ˜rt = maxx∈X EPx[f] −EPxt[f]"
THEORETICAL ANALYSIS,0.25069637883008355,The proof of our main theorem 1 can be found in appendix B.3.
THEORETICAL ANALYSIS,0.25348189415041783,"The assumption that ζi is σζ-sub-Gaussian is standard in GP fields. The assumption that ∆fPx is
σE-sub-Gaussian can be met when Px is uniformly bounded or Gaussian, as stated in Proposition 3,
[26]. Readers may check the definition of sub-Gaussian in appendix, Definition 1."
THEORETICAL ANALYSIS,0.2562674094707521,"To achieve an regret of order ˜Rn ∈O(√nˆγn) , the same order as the exact Improved GP regret (23),
and ensure this with high probability, we need to take ε = O(δ/n), eε = O(n−5"
THEORETICAL ANALYSIS,0.2590529247910863,"2 ˆγn(ˆγ−2
n
∧n−1"
THEORETICAL ANALYSIS,0.2618384401114206,"2 )),
and this requires a sample size m of order O(n5ˆγ−2
n (ˆγ4
n ∨n) log(n)) for MCMC approximation, or
with a same sample size m and a subsample size h of order O(n
5
2 +νˆγ−1−ν
n
(ˆγ2
n ∨n
1
2 )) for Nyström
approximation with some ν > 0. Note that (16) only offers an upper bound for cumulative regret, in
real applications the calculated regret may be much smaller than this bound, as the approximation
error eϵ can be fairly small even with a few samples when the input noise is relatively weak."
THEORETICAL ANALYSIS,0.2646239554317549,"To analysis the exact order of ˆγn could be difficult, as it is influenced by the specific choice of
embedding kernel k and input uncertainty distributions Pxi, xi ∈X. Nevertheless, we can deduce
the following result for a wide range of cases, showing that cumulative regret is sub-linear under mild
conditions. One can check the proof in appendix B.4.
Theorem 2 (Bounding the Maximum information gain). Suppose k is r-th differentiable with bounded
derivatives and translation invariant, i.e., k(x, y) = k(x −y, 0). Suppose the input uncertainty is
i.i.d., that is, the noised input density satisfies Pxi(x) = P0(x −xi), ∀xi ∈X. Then if the space X
is compact in Rd, the maximum information gain ˆγn satisfies"
THEORETICAL ANALYSIS,0.26740947075208915,ˆγn = O(n
THEORETICAL ANALYSIS,0.27019498607242337,"d(d+1)
r+d(d+1) log(n)).
Thus, when r > d(d + 1), the accumulate regret is sub-linear respect to n, with sufficiently small eε."
THEORETICAL ANALYSIS,0.27298050139275765,"(a) GP posterior with a
Gaussian input uncertainty
P = N(0, 0.01)."
THEORETICAL ANALYSIS,0.2757660167130919,"(b)
MMDGP
posterior
with an input uncertainty
P = N(0, 0.01)."
THEORETICAL ANALYSIS,0.2785515320334262,"(c) MMDGP posterior with
a variance-changing beta
distribution."
THEORETICAL ANALYSIS,0.28133704735376047,"(d)
MMDGP
posterior
with a Chi-squared distri-
bution of changing DoF."
THEORETICAL ANALYSIS,0.2841225626740947,Figure 2: Modeling results under different types of input uncertainties.
EVALUATION,0.28690807799442897,"5
Evaluation"
EVALUATION,0.28969359331476324,"In this section, we first experimentally demonstrate AIRBO’s ability to model uncertain inputs of
arbitrary distributions, then validate the Nyström-based inference acceleration for GP posterior,
followed by experiments on robust optimization of synthetic functions and real-world benchmark."
ROBUST SURROGATE,0.2924791086350975,"5.1
Robust Surrogate"
ROBUST SURROGATE,0.29526462395543174,"Modeling arbitrary uncertain inputs: We demonstrate MMDGP’s capabilities by employing
an RKHS function as the black-box function and randomly selecting 10 samples from its input
domain. Various types of input randomness are introduced into the observation and produce training
datasets of D = {(xi, f(xi + δi))|δi ∼Pxi}10
i=1 with different Px configurations. Figure 2a and 2b
compare the modeling results of a conventional GP and MMDGP under a Gaussian input uncertainty
Px = N(0, 0.012). We observe that the GP model appears to overfit the observed samples without
recognizing the input uncertainty, whereas MMDGP properly incorporates the input randomness into
its posterior."
ROBUST SURROGATE,0.298050139275766,"To further examine our model’s ability under complex input uncertainty, we design the input dis-
tribution to follow a beta distribution with input-dependent variance: Px = beta(α = 0.5, β =
0.5, σ = 0.9(sin 4πx + 1)). The MMDGP posterior is shown in Figure 2c. As the input variance
σ changes along x, inputs from the left and right around a given location xi yield different MMD
distances, resulting in an asymmetric posterior (e.g., around x = 0.05 and x = 0.42). This suggests
that MMDGP can precisely model the multimodality and asymmetry of the input uncertainty."
ROBUST SURROGATE,0.3008356545961003,"Moreover, we evaluated MMDGP using a step-changing Chi-squared distribution Px = χ2(g(x), σ =
0.01), where g(x) = 0.5 if x ∈[0, 0.6], and g(x) = 7.0 otherwise. This abrupt change in g(x)
significantly alters the input distribution from a sharply peaked distribution to a flat one with a long
tail. Figure 2d illustrates that our model can accurately capture this distribution shape variation,
as evidenced by the sudden posterior change around x = 0.6. This demonstrates our model can
thoroughly quantify the characteristics of complex input uncertainties."
ROBUST SURROGATE,0.30362116991643456,"Comparing with the other surrogate models: We also compare our model with the other surrogate
models under the step-changing Chi-squared input distribution. The results are reported in Figure 7
and they demonstrate our model outperforms obviously under such a complex input uncertainty (see
Appendix D.1 for more details)"
ACCELERATING THE POSTERIOR INFERENCE,0.3064066852367688,"5.2
Accelerating the Posterior Inference"
ACCELERATING THE POSTERIOR INFERENCE,0.30919220055710306,"Estimation variance of MMD: We first examine the variance of MMD estimation by employing
two beta distributions P = beta(α = 0.4, β = 0.2, σ = 0.1) and Q = beta(α = 0.4, β = 0.2, σ =
0.1) + c, where c is an offset value. Figure 3a shows the empirical MMDs computed via Eq. 8 with
varying sampling sizes as Q moves away from P. We find that a sampling size of 20 is inadequate,
leading to high estimation variance, and increasing the sampling size to 100 stabilizes the estimation."
ACCELERATING THE POSTERIOR INFERENCE,0.31197771587743733,"We further utilize this beta distribution P as the input distribution and derive the MMDGP posterior
via empirical estimator in Figure 3b. Note that the MMD instability caused by inadequate sampling
subsequently engenders a fluctuating posterior and culminates in a noisy acquisition function, which
prevents the acquisition optimizer (e.g., L-BFGS-B in this experiment) from identifying the optima.
Although Figure 3c shows that this issue can be mitigated by using more samples during empirical"
ACCELERATING THE POSTERIOR INFERENCE,0.3147632311977716,"(a) The empirical MMD
and covariance values be-
tween two beta distribu-
tions P and Q as Q moves
away from P."
ACCELERATING THE POSTERIOR INFERENCE,0.31754874651810583,"(b) The noisy posterior de-
rived from a sampling size
of 20 (upper) traps the
acq. optimizer at x = 0
(lower)."
ACCELERATING THE POSTERIOR INFERENCE,0.3203342618384401,"(c) The posterior becomes
smoother with a sampling
size of 100 and acq. op-
timizer can easily identify
the optima."
ACCELERATING THE POSTERIOR INFERENCE,0.3231197771587744,"(d) The Nyström estima-
tor with less memory con-
sumption also produces a
smooth posterior that is
easy to optimize."
ACCELERATING THE POSTERIOR INFERENCE,0.32590529247910865,"Figure 3: The posterior derived from the empirical and Nyström MMD approximators with varying
sampling sizes."
ACCELERATING THE POSTERIOR INFERENCE,0.3286908077994429,"Table 1: Performance of Posterior inference for 512 samples.
Method
Sampling Size
Sub-sampling Size
Inference Time (seconds)
Batch Size (samples)"
ACCELERATING THE POSTERIOR INFERENCE,0.33147632311977715,"Empirical
20
-
1.143 ± 0.083
512
Empirical
100
-
8.117 ± 0.040
128
Empirical
1000
-
840.715 ± 2.182
1
Nystrom
100
10
0.780 ± 0.001
512
Nystrom
1000
100
21.473 ± 0.984
128"
ACCELERATING THE POSTERIOR INFERENCE,0.3342618384401114,"MMD estimation, it is crucial to note that a larger sampling size significantly increases GPU memory
usage because of its quadratic space complexity of O(MNm2) (M and N are the sample number of
training and testing, m is the sampling size for MMD estimation). This limitation severely hinders
parallel inference for multiple samples and slows the overall speed of posterior computation."
ACCELERATING THE POSTERIOR INFERENCE,0.3370473537604457,"Table 1 summarizes the inference time of MMDGP posteriors at 512 samples with different sampling
sizes. We find that, for beta distribution defined in this experiment, the Nyström MMD estimator
with a sampling size of 100 and sub-sampling size of 10 already delivers a comparable result to the
empirical estimator with 100 samples (as seen in the acquisition plot of Figure 3d). Also, the inference
time is reduced from 8.117 to 0.78 seconds by enabling parallel computation for more samples. For
the cases that require much more samples for MMD estimation (e.g., the input distribution is quite
complex or high-dimensional), this Nyström-based acceleration can have a more pronounced impact."
ACCELERATING THE POSTERIOR INFERENCE,0.3398328690807799,"Effect of Nyström estimator on optimization: To investigate the effect of Nyström estimator on
optimization, we also perform an ablation study in Appendix D.2, the results in Figure 8 suggest that
Nyström estimator slightly degrades the optimization performance but greatly improves the inference
efficiency."
ROBUST OPTIMIZATION,0.3426183844011142,"5.3
Robust Optimization"
ROBUST OPTIMIZATION,0.34540389972144847,"Experiment setup: To experimentally validate AIRBO’s performance, we implement our algorithm 1
based on BoTorch [2] and employ a linear combination of multiple rational quadratic kernels [6] to
compute the MMD as Eq. 9. We compare our algorithm with several baselines: 1) uGP-UCB [26]
is a closely related work that employs an integral kernel to model the various input distributions.
It has a quadratic inference complexity of O(MNm2), where M and N are the sample numbers
of the training and testing set, and m indicates the sampling size of the integral kernel. 3)GP-UCB
is the standard GP with UCB acquisition, which represents a broad range of existing methods that"
ROBUST OPTIMIZATION,0.34818941504178275,"1The code will be available on https://github.com/huawei-noah/HEBO, and more implementation
details can be found in Appendix C.1."
ROBUST OPTIMIZATION,0.35097493036211697,"(a) The RKHS function
(b)
Robust
regrets
of
RKHS function."
ROBUST OPTIMIZATION,0.35376044568245124,"(c) The double-peak func-
tion"
ROBUST OPTIMIZATION,0.3565459610027855,"(d)
Robust
regrets
of
double-peak function"
ROBUST OPTIMIZATION,0.3593314763231198,"Figure 4: Robust optimization results on synthetic functions.
focus on non-robust optimization. 3) SKL-UCB employs symmetric Kullback-Leibler divergence to
measure the distance between the uncertain inputs [20]. Its closed-form solution only exists if the
input distributions are the Gaussians. 4) ERBF-UCB is the robust GP with the expected Radial Basis
Function kernel proposed in [13]. It computes the expected kernel under input distribution using the
Gaussian integrals. Assuming the input distributions are sub-Gaussians, this method can efficiently
find the robust optimum. Since all the methods use UCB acquisition, we simply distinguish them by
their surrogate names in the following tests."
ROBUST OPTIMIZATION,0.362116991643454,"At the end of the optimization, each algorithm needs to decide a final outcome xr
n, perceived to be
the robust optimum under input uncertainty at step n. For a fair comparison, we employ the same
outcome policy across all the algorithms: xr
n = arg maxx∈Dn ˆµ∗(x), where ˆµ∗(x) is the posterior
mean of robust surrogate at x and Dn = {(xi, f(xi + δi))|δi ∼Pxi} are the observations so far. The
optimization performance is measured in terms of robust regret as follows:"
ROBUST OPTIMIZATION,0.3649025069637883,"r(xr
n) = Eδ∼Px∗[f(x∗+ δ)] −Eδ∼Pxrn[f(xr
n + δ)],
(17)"
ROBUST OPTIMIZATION,0.36768802228412256,"where x∗is the global robust optimum and xr
n represents the outcome point at step n. For each
algorithm, we repeat the optimization process 12 times and compare the average robust regret."
ROBUST OPTIMIZATION,0.37047353760445684,"1D RKHS function: We begin the optimization evaluation with an RKHS function that is widely used
in previous BO works [1, 24, 10]. Figure 4a shows its exact global optimum resides at x = 0.892
while the robust optimum is around x = 0.08 when the inputs follow a Gaussian distribution
N(0, 0.012). According to Figure 4b, all the robust BO methods work well with Gaussian uncertain
inputs and efficiently identify the robust optimum, but the GP-UCB stagnates at a local optimum
due to its neglect of input uncertainty. Also, we notice the regret of our method decrease slightly
slower than uGP works in this low-dimensional and Gaussian-input case, but later cases with higher
dimension and more complex distribution show our method is more stable and efficient."
ROBUST OPTIMIZATION,0.3732590529247911,"1D double-peak function: To test with more complex input uncertainty, we design a blackbox
function with double peaks and set the input distribution to be a multi-modal distribution Px =
beta(α = 0.4, β = 0.2, σ = 0.1). Figure 4c shows the blackbox function (black solid line) and the
corresponding function expectations estimated numerically via sampling from the input distribution
(i.e., the colored lines). Note the true robust optimum is around x = 0.251 under the beta distribution,
but an erroneous location at x = 0.352 may be determined if the input uncertainty is incorrectly
presumed to be Gaussian. This explains the results in Figure 4d: the performance of SKL-UCB and
ERBF-UCB are sub-optimal due to their misidentification of inputs as Gaussian variables, while our
method accurately quantifies the input uncertainty and outperforms the others."
ROBUST OPTIMIZATION,0.37604456824512533,"10D bumped-bowl function: we also extend our evaluation to a 10D bumped-bowl function [27]
under a concatenated circular distribution. Figure 9 demonstrates AIRBO scales efficiently to high
dimension and outperforms the others under complex input uncertainty(see Appendix D.3)."
ROBUST OPTIMIZATION,0.3788300835654596,"Robust robot pushing: To evaluate AIRBO in a real-world problem, we employ a robust robot
pushing benchmark from [31], in which a ball is placed at the origin point of a 2D space and a robot
learns to push it to a predefined target location (gx, gy). This benchmark takes a 3-dimensional
input (rx, ry, rt), where rx, ry ∈[−5, +5] are the 2D coordinates of the initial robot location
and rt ∈[0, 30] controls the push duration. We set four targets in separate quadrants, i.e., g1 =
(−3, −3), g2 = (−3, 3), g3 = (4.3, 4.3), and a “twin” target at g′
3 = (5.1, 3.0), and describe the input
uncertainty via a two-component Gaussian Mixture Model (defined in Appendix D.4). Following [7,
10], this blackbox benchmark outputs the minimum distance to these 4 targets under squared and
linear distances: loss = min(d2(g1, l), d(g2, l), d(g3, l), d(g′
3, l)), where d(gi, l) is the Euclidean
distance between the ball’s ending location l and the i-th target. This produces a loss landscape as"
ROBUST OPTIMIZATION,0.3816155988857939,"(a) Contour of the robot push world
(b) Robust regrets of different algorithms"
ROBUST OPTIMIZATION,0.38440111420612816,Figure 5: Robust optimization of the robot push problem.
ROBUST OPTIMIZATION,0.3871866295264624,Figure 6: The robot’s initial locations and push times found by different algorithms
ROBUST OPTIMIZATION,0.38997214484679665,"shown in Figure 5a. Note that g2 is a more robust target than g1 because of its linear-form distance
while pushing the ball to quadrant I is the best choice as the targets, g3 and g′
3, match the dual-mode
pattern of the input uncertainty. According to Figure 5b, our method obviously outperforms the others
because it efficiently quantifies the multimodal input uncertainty. This can be further evidenced by
the push configurations found by different algorithms in Figure 6, in which each dot represents the
robot’s initial location and its color represents the push duration. We find that AIRBO successfully
recognizes the targets in quadrant I as an optimal choice and frequently pushes from quadrant III
to quadrant I. Moreover, the pushes started close to the origin can easily go far away under input
variation, so our method learns to push the ball from a corner with a long push duration, which is
more robust in this case."
DISCUSSION AND CONCLUSION,0.39275766016713093,"6
Discussion and Conclusion"
DISCUSSION AND CONCLUSION,0.3955431754874652,"In this work, we generalize robust Bayesian Optimization to an uncertain input setting. The weight-
space interpretation of GP inspires us to empower the GP kernel with MMD and build a robust
surrogate for uncertain inputs of arbitrary distributions. We also employ the Nyström approximation
to boost the posterior inference and provide theoretical regret bound under approximation error. The
experiments on synthetic blackbox function and benchmarks demonstrate our method can handle
various input uncertainty and achieve state-of-the-art optimization performance."
DISCUSSION AND CONCLUSION,0.3983286908077994,"There are several interesting directions that worth to explore: though we come to current MMD-based
kernel from the weight-space interpretation of GP and the RKHS realization of MMD, our kernel
design exhibits a deep connection with existing works on kernel over probability measures [22, 11].
Along this direction, as our theoretic regret analysis in Section 4 does not assume any particular
form of kernel and the Nyström acceleration can also be extended to the other kernel computation, it
is possible that AIRBO can be further generalized to a more rich family of kernels. Moreover, the
MMD used in our kernel is by no means limited to its RKHS realization. In fact, any function class F
that comes with uniform convergence guarantees and is sufficiently rich can be used, which renders
different realizations of MMD. With proper choice of function class F, MMD can be expressed as
the Kolmogorov metric or other Earth-mover distances [15]. It is also interesting to extend AIRBO
with the other IPMs."
ACKNOWLEDGEMENTS,0.4011142061281337,"7
Acknowledgements"
ACKNOWLEDGEMENTS,0.403899721448468,"We sincerely thank Yanbin Zhu and Ke Ma for their help on formulating the problem. Also, a heartfelt
appreciation goes to Lu Kang for her constant encouragement and support throughout this work."
REFERENCES,0.40668523676880225,References
REFERENCES,0.40947075208913647,"[1]
John-Alexander M Assael et al. “Heteroscedastic treed bayesian optimisation”. In: arXiv
preprint arXiv:1410.7172 (2014).
[2]
Maximilian Balandat et al. “BoTorch: A Framework for Efficient Monte-Carlo Bayesian
Optimization”. In: Advances in Neural Information Processing Systems 33. 2020. URL: http:
//arxiv.org/abs/1910.06403.
[3]
Justin J Beland and Prasanth B Nair. “Bayesian Optimization Under Uncertainty”. In: (2017),
p. 5.
[4]
James Bergstra et al. “Algorithms for hyper-parameter optimization”. In: Advances in neural
information processing systems 24 (2011).
[5]
Felix Berkenkamp, Andreas Krause, and Angela P Schoellig. “Bayesian optimization with
safety constraints: safe and automatic parameter tuning in robotics”. In: Machine Learning
(2021), pp. 1–35.
[6]
Mikołaj Bi´nkowski et al. Demystifying MMD GANs. 2021. DOI: 10.48550/arXiv.1801.
01401. arXiv: 1801.01401.
[7]
Ilija Bogunovic et al. “Adversarially Robust Optimization with Gaussian Processes”. In:
Advances in Neural Information Processing Systems. Vol. 31. Curran Associates, Inc., 2018.
[8]
Antoine Chatalic et al. “Nyström Kernel Mean Embeddings”. In: International Conference on
Machine Learning. 2022.
[9]
Sayak Ray Chowdhury and Aditya Gopalan. “On Kernelized Multi-armed Bandits”. In:
International Conference on Machine Learning. 2017.
[10]
Ryan B. Christianson and Robert B. Gramacy. Robust Expected Improvement for Bayesian
Optimization. 2023. arXiv: 2302.08612.
[11]
Andreas Christmann and Ingo Steinwart. “Universal Kernels on Non-Standard Input Spaces”.
In: NIPS. 2010.
[12]
Alexander I Cowen-Rivers et al. “HEBO: pushing the limits of sample-efficient hyper-
parameter optimisation”. In: Journal of Artificial Intelligence Research 74 (2022), pp. 1269–
1349.
[13]
Patrick Dallaire, Camille Besse, and Brahim Chaib-draa. “An Approximate Inference with
Gaussian Process to Latent Functions from Uncertain Data”. In: Neurocomputing. Adaptive
Incremental Learning in Neural Networks 74.11 (2011), pp. 1945–1955. DOI: 10.1016/j.
neucom.2010.09.024.
[14]
Arthur Gretton, Dougal Sutherland, and Wittawat Jitkrittum. “Interpretable comparison of
distributions and models”. In: Advances in Neural Information Processing Systems [Tutorial]
(2019).
[15]
Arthur Gretton et al. “A kernel two-sample test”. In: The Journal of Machine Learning
Research 13.1 (2012), pp. 723–773.
[16]
Trevor Hastie et al. The elements of statistical learning: data mining, inference, and prediction.
Vol. 2. Springer, 2009.
[17]
Thomas Kühn. “Eigenvalues of integral operators with smooth positive definite kernels”. In:
Archiv der Mathematik 49 (1987), pp. 525–534. URL: https://api.semanticscholar.
org/CorpusID:121372638.
[18]
Ruben Martinez-Cantin et al. “Active policy learning for robot planning and exploration under
uncertainty.” In: Robotics: Science and systems. Vol. 3. 2007, pp. 321–328.
[19]
Seyedali Mirjalili and Andrew Lewis. “Obstacles and difficulties for robust benchmark prob-
lems: A novel penalty-based robust optimisation method”. In: Information Sciences 328 (2016),
pp. 485–509.
[20]
Pedro Moreno, Purdy Ho, and Nuno Vasconcelos. “A Kullback-Leibler Divergence Based Ker-
nel for SVM Classification in Multimedia Applications”. In: Advances in Neural Information
Processing Systems. Vol. 16. MIT Press, 2003.
[21]
Krikamol Muandet et al. “Kernel Mean Embedding of Distributions: A Review and Beyond”.
In: Foundations and Trends® in Machine Learning 10.1-2 (2017), pp. 1–141. DOI: 10.1561/
2200000060. arXiv: 1605.09522.
[22]
Krikamol Muandet et al. “Learning from Distributions via Support Measure Machines”. In:
NIPS. 2012."
REFERENCES,0.41225626740947074,"[23]
Alfred Müller. “Integral probability metrics and their generating classes of functions”. In:
Advances in applied probability 29.2 (1997), pp. 429–443.
[24]
Jose Nogueira et al. “Unscented Bayesian Optimization for Safe Robot Grasping”. In: 2016
IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). Daejeon, South
Korea: IEEE, 2016, pp. 1967–1972. ISBN: 978-1-5090-3762-9. DOI: 10.1109/IROS.2016.
7759310.
[25]
Rafael Oliveira, Lionel Ott, and Fabio Ramos. “Bayesian Optimisation under Uncertain In-
puts”. In: Proceedings of the Twenty-Second International Conference on Artificial Intelligence
and Statistics. PMLR, 2019, pp. 1177–1184.
[26]
Rafael Oliveira, Lionel Ott, and Fabio Ramos. Bayesian optimisation under uncertain inputs.
2019. arXiv: 1902.07908.
[27]
Nicholas D. Sanders et al. Bayesian Search for Robust Optima. 2021. arXiv: 1904.11416.
[28]
Bobak Shahriari et al. “Taking the Human Out of the Loop: A Review of Bayesian Optimiza-
tion”. In: Proceedings of the IEEE 104.1 (Jan. 2016), pp. 148–175. DOI: 10.1109/JPROC.
2015.2494218.
[29]
Jasper Snoek, Hugo Larochelle, and Ryan P Adams. “Practical bayesian optimization of
machine learning algorithms”. In: Advances in neural information processing systems 25
(2012).
[30]
Niranjan Srinivas et al. “Gaussian Process Optimization in the Bandit Setting: No Regret
and Experimental Design”. In: International Conference on Machine Learning. 2009. URL:
https://api.semanticscholar.org/CorpusID:59031327.
[31]
Zi Wang and Stefanie Jegelka. “Max-value entropy search for efficient Bayesian optimization”.
In: International Conference on Machine Learning. PMLR. 2017, pp. 3627–3635.
[32]
Colin White, Willie Neiswanger, and Yash Savani. “Bananas: Bayesian optimization with
neural architectures for neural architecture search”. In: Proceedings of the AAAI Conference
on Artificial Intelligence. Vol. 35. 12. 2021, pp. 10293–10301.
[33]
Christopher Williams and Matthias Seeger. “Using the Nyström Method to Speed Up Kernel
Machines”. In: Advances in Neural Information Processing Systems. Vol. 13. MIT Press, 2000.
[34]
Christopher KI Williams and Carl Edward Rasmussen. Gaussian processes for machine
learning. Vol. 2. 3. MIT press Cambridge, MA, 2006."
REFERENCES,0.415041782729805,"A
Nyström Estimator Error Bound"
REFERENCES,0.4178272980501393,"Nyström estimator can easily approximate the kernel mean embedding ψp1, ψp2 as well as the MMD
distance between two distribution density p1 and p2. We need first assume the boundedness of the
feature map to the kernel k:
Assumption 2. There exists a positive constant K ≤∞such that supx∈X ∥ϕ(x)∥≤K"
REFERENCES,0.4206128133704735,"The true MMD distance between p1 and p2 is denoted as MMD(p1, p2). The estimated MMD
distance when using a Nyström sample size mi, sub-sample size hi for pi respectively, is denoted as
MMD(pi,mi,hi). Then the error"
REFERENCES,0.4233983286908078,"Err(pi,mi,hi) := |MMD(p1, p2) −MMD(pi,mi,hi)|"
REFERENCES,0.42618384401114207,"and now we have the lemma from Theorem 5.1 in [8]
Lemma 1. Let Assumption 2 hold.
Furthermore, assume that for i ∈1, 2, the data points
Xi
1, · · · , Xi
mi are drawn i.i.d. from the distribution ρi and that hi ≤mi sub-samples ˜Xi
1, · · · , ˜Xi
hi
are drawn uniformly with replacement from the dataset {Xi
1, · · · , Xi
mi}. Then, for any δ ∈(0, 1), it
holds with probability at least 1 −2δ"
REFERENCES,0.42896935933147634,"Err(pi,mi,hi) ≤
X i=1,2 "
REFERENCES,0.43175487465181056,"c1
√mi
+ c2 hi
+ p"
REFERENCES,0.43454038997214484,log(hi/δ) hi s
REFERENCES,0.4373259052924791,"N pi(12K2 log(hi/δ) hi
)  ,"
REFERENCES,0.4401114206128134,"provided that, for i ∈{1, 2},"
REFERENCES,0.4428969359331476,"hi ≥max(67, 12K2∥Ci∥−1
L(H)) log(hi/δ)"
REFERENCES,0.4456824512534819,"where c1 = 2K
p"
REFERENCES,0.44846796657381616,"2 log(6/δ), c2 = 4
√"
REFERENCES,0.45125348189415043,"3K log(12/δ) and c4 = 6K
p"
REFERENCES,0.45403899721448465,"log(12/δ). The notation N pi
denotes the effective dimension associated to the distribution pk."
REFERENCES,0.4568245125348189,"Specifically, when the effective dimension N satisfies, for some c ≥0,"
REFERENCES,0.4596100278551532,"• either N ρi(σ2) ≤cσ2−γ for some γ ∈(0, 1),"
REFERENCES,0.4623955431754875,"• or N ρi(σ2) ≤log(1 + c/σ2)/β, for some β > 0."
REFERENCES,0.46518105849582175,"Then, choosing the subsample size m to be"
REFERENCES,0.467966573816156,"• hi = m1/(2−γ)
i
log(mi/δ) in the first case"
REFERENCES,0.47075208913649025,"• or hi = √mi log(√mi max(1/δ, c/(6K2)) in the second case,"
REFERENCES,0.4735376044568245,"we get Err(ρi,mi,hi) = O(1/√mi)"
REFERENCES,0.4763231197771588,"B
Proofs of Section 4"
REFERENCES,0.479108635097493,"B.1
Exact Kernel Uncertainty GP Formulating"
REFERENCES,0.4818941504178273,"Following the same notation in Section 4, now we can construct a Gaussian process GP(0, ˆk)
modelling functions over P. This GP model can then be applied to learn ˆf from a given set of
observations Dn = {(Pi, yi)}n
i=1. Under zero mean condition, the value of ˆf(P∗) for a given P∗∈P
follows a Gaussian posterior distribution with"
REFERENCES,0.48467966573816157,"ˆµn(P∗) = ˆkn(P∗)T ( ˆKn + σ2I)−1yn
(18)"
REFERENCES,0.48746518105849584,"ˆσ2
n(P∗) = ˆk(P∗, P∗) −ˆkn(P∗)T ( ˆKn + σ2I)−1ˆkn(P∗),
(19)"
REFERENCES,0.49025069637883006,"where yn := [y1, · · · , yn]T , ˆkn(P∗) := [ˆk(P∗, P1), · · · , ˆk(P∗, Pn)]T and [ ˆKn]ij = ˆk(Pi, Pj)."
REFERENCES,0.49303621169916434,"Now we restrict our Gaussian process in the subspace PX = {Px, x ∈X} ⊂P. We assume the
observation yi = f(xi) + ζi with the noise ζi. The input-induced noise is defined as ∆fpxi :=
f(xi)−EPxi[f] = f(xi)−ˆf(Pxi). Then the total noise is yi −EPxi[f] = ζi +∆fpxi . To formulate
the regret bounds, we introduce the information gain and estimated information gain given any
{Pt}n
t=1 ⊂P:"
REFERENCES,0.4958217270194986,"ˆI(yn;ˆfn|{Pt}n
t=1) := 1"
REFERENCES,0.4986072423398329,"2 ln det(I + σ−2 ˆKn),
(20)"
REFERENCES,0.5013927576601671,"˜I(yn;ˆfn|{Pt}n
t=1) := 1"
REFERENCES,0.5041782729805014,"2 ln det(I + σ−2 ˜Kn),
(21)"
REFERENCES,0.5069637883008357,"and the maximum information gain is defined as ˆγn := supR∈PX ;|R|=n ˆI(yn;ˆfn|R). Here ˆfn :=
[ ˆf(p1), · · · , ˆf(pn)]T ."
REFERENCES,0.5097493036211699,"We define the sub-Gaussian condition as follows:
Definition 1. For a given σξ > 0, a real-valued random variable ξ is said to be σξ-sub-Gaussian if:"
REFERENCES,0.5125348189415042,"∀λ ∈R, E[eλξ] ≤eλ2σ2
ξ/2"
REFERENCES,0.5153203342618384,"Now we can state the lemma for bounding the uncertain-inputs regret of exact kernel evaluations,
which is originally stated in Theorem 5 in [26]."
REFERENCES,0.5181058495821727,"Lemma 2. Let δ ∈(0, 1), f ∈Hk, and the corresponding ∥ˆf∥ˆk ≤b. Suppose the observation noise
ζi = yi −f(xi) is conditionally σζ-sub-Gaussian. Assume that both k and Px satisfy the conditions
for ∆fPx to be σE-sub-Gaussian, for a given σE > 0. Then, we have the following results:"
REFERENCES,0.520891364902507,• The following holds for all x ∈X and t ≥1:
REFERENCES,0.5236768802228412,"|ˆµn(Px) −ˆf(Px)| ≤  b +
q"
REFERENCES,0.5264623955431755,"σ2
E + σ2
ζ r"
REFERENCES,0.5292479108635098,"2

ˆI(yn;ˆfn|{Pt}n
t=1) + 1 + ln(1/δ)
!"
REFERENCES,0.532033426183844,ˆσn(Px) (22)
REFERENCES,0.5348189415041783,"• Running with upper confidence bound (UCB) acquisition function α(x|Dn) = ˆµn(Px) +
ˆβnˆσn(Px) where"
REFERENCES,0.5376044568245125,"ˆβn = b +
q"
REFERENCES,0.5403899721448467,"σ2
E + σ2
ζ r"
REFERENCES,0.5431754874651811,"2

ˆI(yn;ˆfn|{Pt}n
t=1) + 1 + ln(1/δ)

,"
REFERENCES,0.5459610027855153,"and set σ2 = 1 + 2/n, the uncertain-inputs cumulative regret satisfies:"
REFERENCES,0.5487465181058496,"ˆRn ∈O(
p"
REFERENCES,0.5515320334261838,"nˆγn(b +
p"
REFERENCES,0.5543175487465181,"ˆγn + ln(1/δ)))
(23)"
REFERENCES,0.5571030640668524,with probability at least 1 −δ.
REFERENCES,0.5598885793871866,"Note that although the original theorem restricted to the case when ˆk(p, q) = ⟨ψP , ψQ⟩k, the results
can be easily generated to other kernels over P, as long as its universal w.r.t C(P) given that X is
compact and the mean map ψ is injective [11, 22]."
REFERENCES,0.5626740947075209,"B.2
Error Estimates for Inexact Kernel Approximation"
REFERENCES,0.5654596100278552,"Now let us derivative the inference under the introduce of inexact kernel estimations.
Theorem 3. Under the Assumption 1 for ε > 0, let ˜µn, ˜σn, ˜I(yn;ˆfn|{Pt}n
t=1) as defined in
(13),(14),(21) respectively, and ˆµn, ˆσn, ˆI(yn;ˆfn|{Pt}n
t=1) as defined in (18),(19),(20). Assume
maxx∈X f(x) = M, and assume the observation error ζi = yi −f(xi) satisfies |ζi| < A for all i.
Then we have the following error bound holds with probability at least 1 −nε:"
REFERENCES,0.5682451253481894,|ˆµn(P∗) −˜µn(P∗)| < ( n
REFERENCES,0.5710306406685237,σ2 + n2
REFERENCES,0.5738161559888579,"σ4 )(M + A)eε + O(e2
ε)
(24)"
REFERENCES,0.5766016713091922,"|ˆσ2
n(P∗) −˜σ2
n(P∗)| < (1 + n"
REFERENCES,0.5793871866295265,"σ2 )2eε + O(e2
ε)
(25)"
REFERENCES,0.5821727019498607,"˜I(yn;ˆfn|{Pt}n
t=1) −ˆI(yn;ˆfn|{Pt}n
t=1)
 < n3/2"
REFERENCES,0.584958217270195,"2σ2 eε + O(e2
ε)
(26)"
REFERENCES,0.5877437325905293,"Proof. Denote e(P∗, Q) = ˜k(P∗, Q) −ˆk(P∗, Q), en(P∗) = [e(P∗, P1), · · · , e(P∗.Pn)]T , and
[En]i,j = e(Pi, Pj). Now according to the matrix inverse perturbation expansion,"
REFERENCES,0.5905292479108635,"(X + δX)−1 = X−1 −X−1δXX−1 + O(∥δX∥2),"
REFERENCES,0.5933147632311978,we have
REFERENCES,0.596100278551532,"( ˆKn + σ2I + En)−1 = ( ˆKn + σ2I)−1 −( ˆKn + σ2I)−1En( ˆKn + σ2I)−1 + O(∥En∥2), thus"
REFERENCES,0.5988857938718662,˜µn(P∗) =(ˆkn(P∗) + en(P∗))T ( ˆKn + σ2I + En)−1yn
REFERENCES,0.6016713091922006,"=ˆµn(P∗) + en(P∗)T ( ˆKn + σ2I)−1yn −ˆkn(P∗)T ( ˆKn + σ2I)−1En( ˆKn + σ2I)−1yn
+ O(∥En∥2) + O(∥en(P∗))∥· ∥En∥)"
REFERENCES,0.6044568245125348,"˜σ2
n(P∗) =ˆσ2
n(P∗) + e(P∗, P∗) −(ˆkn(P∗) + en(P∗))T ( ˆKn + σ2I + En)−1(ˆkn(P∗) + en(P∗))"
REFERENCES,0.6072423398328691,"=ˆσ2
n(P∗) + e(P∗, P∗) −2en(P)T ( ˆKn + σ2I)−1ˆkn(P∗)"
REFERENCES,0.6100278551532033,+ ˆkn(P)T ( ˆKn + σ2I)−1En( ˆKn + σ2I)−1ˆkn(P∗)
REFERENCES,0.6128133704735376,+ O(∥En∥2) + O(∥en∥· ∥En∥) + O(∥en∥2 · ∥En∥)
REFERENCES,0.6155988857938719,"Notic that the following holds with a probability at least 1 −nε, according to the Assumption 1,"
REFERENCES,0.6183844011142061,|en(P∗)T ( ˆKn + σ2I)−1yn| ≤∥en(P∗)∥2∥( ˆKn + σ2I)−1∥2∥yn∥2 ≤n
REFERENCES,0.6211699164345403,"σ2 (M + A)eε,"
REFERENCES,0.6239554317548747,"|ˆkn(P∗)T ( ˆKn + σ2I)−1En( ˆKn + σ2I)−1yn| ≤∥ˆkn(P∗)∥2∥( ˆKn + σ2I)−1∥2
2∥En∥2∥yn∥2"
REFERENCES,0.6267409470752089,"≤√nσ−4neε
√n(M + A) = n2"
REFERENCES,0.6295264623955432,"σ4 (M + A),"
REFERENCES,0.6323119777158774,"here we use the fact that ˆKn semi-definite (which means ∥( ˆKn + σ2I)−1∥2 ≤σ−2), ˆk(P∗, P∗) ≤1,
|yi| ≤M + A. Combining these results, we have that"
REFERENCES,0.6350974930362117,|˜µn(P∗) −ˆµn(P∗)| < ( n
REFERENCES,0.637883008356546,σ2 + n2
REFERENCES,0.6406685236768802,"σ4 )(M + A)eε + O(e2
ε),"
REFERENCES,0.6434540389972145,holds with a probability at least 1 −nε.
REFERENCES,0.6462395543175488,"Similarly, we can conduct the same estimation to en(P)T ( ˆKn + σ2I)−1ˆkn(P∗) and ˆkn(P)T ( ˆKn +
σ2I)−1En( ˆKn + σ2I)−1ˆkn(P∗), and get"
REFERENCES,0.649025069637883,"|˜σ2
n(P∗) −ˆσ2
n(P∗)| < (1 + n"
REFERENCES,0.6518105849582173,"σ2 )2eε + O(e2
ε)"
REFERENCES,0.6545961002785515,holds with a probability at least 1 −nε.
REFERENCES,0.6573816155988857,"It remains to estimate the error for estimating the information gain. Notice that, with a probability at
least 1 −nε,"
REFERENCES,0.6601671309192201,"˜I(yn;ˆfn|{pt}n
t=1) −ˆI(yn;ˆfn|{pt}n
t=1)
 ="
REFERENCES,0.6629526462395543,"1
2 log det(I + σ−2 ˜Kn)"
REFERENCES,0.6657381615598886,det(I + σ−2 ˆKn) 
REFERENCES,0.6685236768802229,"=

1
2 log det(I −(σ2I + ˆKn)−1En)"
REFERENCES,0.6713091922005571,"=

1
2Tr(log(I −(σ2I + ˆKn)−1En))"
REFERENCES,0.6740947075208914,"=

1
2Tr(−(σ2I + ˆKn)−1En) + O(∥En∥2) ≤n3/2"
REFERENCES,0.6768802228412256,"2σ2 eε + O(∥En∥2),"
REFERENCES,0.6796657381615598,"here the second equation uses the fact that det(AB−1) = det(A) det(B)−1, and the third and fourth
equations use log det(I + A) = Tr log(I + A) = Tr(A −A2"
REFERENCES,0.6824512534818942,"2 + · · · ). The last inequality follows
from the fact"
REFERENCES,0.6852367688022284,Tr(σ2I + ˆKn)−1En) ≤∥(σ2I + ˆKn)−1∥F ∥En∥F ≤n3/2σ−2eε
REFERENCES,0.6880222841225627,and ˆKn is semi-definite.
REFERENCES,0.6908077994428969,"With the uncertainty bound given by Lemma 3, let us prove that under inexact kernel estimations, the
posterior mean is concentrated around the unknown reward function ˆf
Theorem 4. Under the former setting as in Theorem 3, with probability at least 1 −δ −nε, let
σν =
q"
REFERENCES,0.6935933147632312,"σ2
ζ + σ2
E, taking σ = 1 + 2"
REFERENCES,0.6963788300835655,"n, the following holds for all x ∈X:"
REFERENCES,0.6991643454038997,"|˜µn(Px) −ˆf(Px)| ≤βn˜σn(Px) + βn(1 + n)e1/2
ε
+
 
n + n2
(M + A)eε,
(27)"
REFERENCES,0.7019498607242339,"where βn =

b + σν
p"
REFERENCES,0.7047353760445683,"2(ˆγn −ln(δ) + 1)
"
REFERENCES,0.7075208913649025,"Proof. According to Lemma 2, equation (22), we have"
REFERENCES,0.7103064066852368,|ˆµn(Px) −ˆf(Px)| ≤ˆβnˆσn(Px)
REFERENCES,0.713091922005571,"with
ˆβn = b + σν r"
REFERENCES,0.7158774373259053,"2

ˆI(yn;ˆfn|{Pt}n
t=1) + 1 + ln(1/δ)

≤βn."
REFERENCES,0.7186629526462396,"Notice that
|˜µn(Px) −ˆf(Px)| ≤|˜µn(Px) −ˆµn(Px)| + |ˆµn(Px) −ˆf(Px)|,
(28)"
REFERENCES,0.7214484679665738,"We also have (25), which means"
REFERENCES,0.724233983286908,"ˆσn(Px) =
p"
REFERENCES,0.7270194986072424,"ˆσn(Px)2 ≤
p"
REFERENCES,0.7298050139275766,"˜σn(Px)2 + (1 + n)2eε ≤˜σn(Px) + (1 + n)e1/2
ε
,
(29)"
REFERENCES,0.7325905292479109,"combining (24), (28) and (29), we finally get the result in (27)."
REFERENCES,0.7353760445682451,"B.3
Proofs for Theorem 1"
REFERENCES,0.7381615598885793,Now we can prove our main theorem 1.
REFERENCES,0.7409470752089137,"Proof of Theorem 1. Let x∗maximize ˆf(Px) over X. Observing that at each round n ≥1, by the
choice of xn to maximize the aquisition function ˜α(x|Dn−1) = ˜µn−1(Px) + βn−1˜σn−1(Px), we
have"
REFERENCES,0.7437325905292479,"˜rn = ˆf(Px∗) −ˆf(Pxn)
≤˜µn−1(Px∗) + βn−1˜σn−1(Px∗) −˜µn−1(Pxn) + βn−1˜σn−1(Pxn) + 2Err(n −1, eε)
≤2βn−1˜σn−1(Pxn) + 2Err(n −1, eε)."
REFERENCES,0.7465181058495822,"Here we denote Err(n, eε) :=
 
βn(1 + n) + ˜σn(Px)σνn3/4
e1/2
ε
+
 
n + n2
(M + A)eε. The
second inequality follows from (27),"
REFERENCES,0.7493036211699164,"ˆf(Px∗) −˜µn−1(Px∗) ≤βn−1˜σn−1(Px∗) + Err(n −1, eε)"
REFERENCES,0.7520891364902507,"˜µn−1(Pxn) −ˆf(Pxn) ≤βn−1˜σn−1(Pxn) + Err(n −1, eε),"
REFERENCES,0.754874651810585,and the third inequality follows from the choice of xn:
REFERENCES,0.7576601671309192,˜µn−1(Px∗) + βn−1˜σn−1(Px∗) ≤˜µn−1(Pxn) + βn−1˜σn−1(Pxn).
REFERENCES,0.7604456824512534,"Thus we have ˜Rn = n
X"
REFERENCES,0.7632311977715878,"t=1
˜rt ≤2βn n
X"
REFERENCES,0.766016713091922,"t=1
˜σt−1(Pxt) + T
X"
REFERENCES,0.7688022284122563,"t=1
Err(t −1, eε)."
REFERENCES,0.7715877437325905,"From Lemma 4 in [9], we have that n
X"
REFERENCES,0.7743732590529248,"t=1
˜σt−1(Pxt) ≤
q"
REFERENCES,0.7771587743732591,4(n + 2) ln det(I + σ−2 ˜Kn) ≤ s
REFERENCES,0.7799442896935933,"4(n + 2)(ˆγn + n
3
2
2 eε),"
REFERENCES,0.7827298050139275,"and thus 2βn n
X"
REFERENCES,0.7855153203342619,"t=1
˜σt−1(Pxt) = O
p"
REFERENCES,0.7883008356545961,"nˆγn +
p"
REFERENCES,0.7910863509749304,"nˆγn(ˆγn −ln δ) +
q"
REFERENCES,0.7938718662952646,"n
5
2 eε +
q"
REFERENCES,0.7966573816155988,"n
5
2 (ˆγn −ln δ)eε"
REFERENCES,0.7994428969359332,"
.
(30)"
REFERENCES,0.8022284122562674,"On the other hand, notice that n
X"
REFERENCES,0.8050139275766016,"t=1
Err(t −1, eε) = O

n2p"
REFERENCES,0.807799442896936,"(ˆγn −ln δ)eε + (n2 + n3)eϵ

,
(31)"
REFERENCES,0.8105849582172702,"we find that the eε term in (30) can be controlled by in (31), thus we immediately get the result."
REFERENCES,0.8133704735376045,"B.4
Proofs for Theorem 2"
REFERENCES,0.8161559888579387,"Proof. Define the square of the MMD distance between Px1, Px2 as dM(x1, x2), we have"
REFERENCES,0.8189415041782729,"dM(x1, x2) =
Z"
REFERENCES,0.8217270194986073,"Rd k(x, x′)Px1(x)Px1(x′)dxdx′ +
Z"
REFERENCES,0.8245125348189415,"Rd k(x, x′)Px2(x)Px2(x′)dxdx′ −2
Z"
REFERENCES,0.8272980501392758,"Rd k(x, x′)Px1(x)Px2(x′)dxdx′ =
Z"
REFERENCES,0.83008356545961,"Rd(k(x −x1, x′ −x1) + k(x −x2, x′ −x2) −2k(x −x1, x′ −x2))P0(x)P0(x′)dxdx′."
REFERENCES,0.8328690807799443,"It is not hard to verify that dM is shift invariant: dM(x1, x2) = dM(x1 −x2, 0), and dM has r-th
bounded derivatives, thus ˆk∗(x1, x2) := ˆk(Px1, Px2) = exp(−αdM(x1, x2)) is shift invariant with
r-th bounded derivatives. Then take µ(x) as the Lebesgue measure over X, according to Theorem 4,
[17], the integral operator Tk,µ : Tk,µf(x) =
R"
REFERENCES,0.8356545961002786,"X K(x, y)f(y)dµ(y) is a symmetric compact operator
in L2(X, µ), and the spectrum of Tk,µ satisfies"
REFERENCES,0.8384401114206128,"λn(Tk,µ) = O(n−1−r/d)."
REFERENCES,0.841225626740947,"Then according to Theorem 5 in [30], we have ˆγn = O(n"
REFERENCES,0.8440111420612814,"d(d+1)
r+d(d+1) log(n)), which finish the proof."
REFERENCES,0.8467966573816156,"C
Evaluation Details"
REFERENCES,0.8495821727019499,"C.1
Implementation"
REFERENCES,0.8523676880222841,"In our implementation of AIRBO, we design the kernel k used for MMD estimation to be a linear
combination of multiple Rational Quadratic kernels as its long tail behavior circumvents the fast
decay issue of kernel [6]:"
REFERENCES,0.8551532033426184,"k(x, x′) =
X"
REFERENCES,0.8579387186629527,"ai∈{0.2,0.5,1,2,5}"
REFERENCES,0.8607242339832869," 
1 + (x −x′)2"
REFERENCES,0.8635097493036211,"2ail2
i"
REFERENCES,0.8662952646239555,"−ai,
(32)"
REFERENCES,0.8690807799442897,"where li is a learnable lengthscale and ai determines the relative weighting of large-scale and
small-scale variations."
REFERENCES,0.871866295264624,"Depending on the form of input distributions, the sampling and sub-sampling sizes for Nyström
MMD estimator are empirically selected via experiments. Moreover, as the input uncertainty is
already modeled in the surrogate, we employ a classic UCB-based acquisition as Eq. 5 with β = 2.0
and maximize it via an L-BFGS-B optimizer."
REFERENCES,0.8746518105849582,"D
More Experiments"
REFERENCES,0.8774373259052924,"D.1
Comparing with the Other Models"
REFERENCES,0.8802228412256268,"To compare the modeling performances with the other models, we design the input uncertainty to
follow a step-changing Chi-squared distribution: Px = χ2(g(x), σ = 0.01), where g(x) = 0.5
if x ∈[0.0, 0.6) and g(x) = 7.0 when x ∈[0.6, 1.0]. Due to this sudden parameter change, the
uncertainty at point x = 0.6 is expected to be asymmetric: 1) on its left-hand side, as the Chi-squared
distribution becomes quite lean and sharp with a small value of g(x) = 0.5, the distance from x = 0.6
to its LHS points, xlhs ∈[0.0, 0.6), are relatively large, thus their covariances are small, resulting
a fast-growing uncertainty. 2)Meanwhile, when x ∈[0.6, 1.0], the g(x) suddenly increases to 7.0,
rendering the input distribution a quite flat one with a long tail. Therefore, the distances between
x = 0.6 and its RHS points become relatively small, which leads to large covariances and small
uncertainties for points in [0.6, 1.0]. As a result, we expect to observe an asymmetric posterior
uncertainty at x = 0.6."
REFERENCES,0.883008356545961,"Several surrogate models are employed in this comparison, including:"
REFERENCES,0.8857938718662952,"• MMDGP-nystrom(160/10) is our method with a sampling size m = 160 and sub-sampling
size h = 10. Its complexity is O(MNmh), where M and N are the sizes of training and
test samples (Note: all the models in this experiment use the same training and testing
samples for a fair comparison)."
REFERENCES,0.8885793871866295,"• uGP(40) is the surrogate from [25], which employs an integral kernel with sampling size
m = 40. Due to its O(MNm2) complexity, we set the sampling size m = 40 to ensure a
similar complexity as ours."
REFERENCES,0.8913649025069638,"• uGP(160) is also the surrogate from [25] but uses a much larger sampling size (m =
160). Given the same training and testing samples, its complexity is 16 times higher than
MMDGP-nystrom(160/10)."
REFERENCES,0.8941504178272981,"• skl is a robust GP surrogate equipped with a symmetric KL-based kernel, which is described
in [20]."
REFERENCES,0.8969359331476323,"• ERBF [13] assumes the input uncertainty to be Gaussians and employs a close-form
expected RBF kernel."
REFERENCES,0.8997214484679665,• GP utilizes a noisy Gaussian Process model with a learnable output noise level.
REFERENCES,0.9025069637883009,"According to Figure 7a, our method, MMDGP-nystrom(160/10), can comprehensively quantify
the sudden change of the input uncertainty, evidenced by its abrupt posterior change at x = 0.6.
However, Figure 7b shows that uGP(40) with the same complexity fails to model the uncertainty
correctly. We suspect this is because uGP requires much larger samples to stabilize its estimation of
the integral kernel and thus can perform poorly with insufficient sample size, so we further evaluate
the uGP(160) with a much larger sampling size m = 160 in Figure 7c. It does successfully alleviate
the issue but also results in a 16 times higher complexity. Apart from this, Figure 7d suggests the
noisy GP model with a learnable output noise level is not aware of this uncertainty change at all as it
treats the inputs as the exact values instead of random variables. Moreover, Figure 7e and 7f show
that both the skl and ERBF fail in this case, this may be due to their misassumption of Gaussian input
uncertainty."
REFERENCES,0.9052924791086351,"D.2
Ablation Test for Nyström Approximation"
REFERENCES,0.9080779944289693,"In this experiment, we aim to examine the effect of Nyström approximation for optimization. To
this end, we choose to optimize an RKHS function (Figure 4a) under a beta input distribution:
Px = beta(α = 0.4, β = 0.2, σ = 0.1). Several amortized candidates include:"
REFERENCES,0.9108635097493036,"(a) MMD-GP with a Nystrom es-
timator, in which the sampling
size m = 160 and sub-sampling
size h = 10."
REFERENCES,0.9136490250696379,"(b) uGP model that uses an inte-
gral kernel [26] and a sampling
size of m = 40."
REFERENCES,0.9164345403899722,"(c) uGP with an integral ker-
nel [26] and uses a much larger
sampling size (m = 160)."
REFERENCES,0.9192200557103064,"(d) Conventional noisy GP model.
(e) GP model with a symmetric
KL-divergence kernel [20]."
REFERENCES,0.9220055710306406,"(f) Robust GP model with an ex-
pected RBF kernel [13]"
REFERENCES,0.924791086350975,Figure 7: Modeling performance with a step-changing Chi-squared distribution.
REFERENCES,0.9275766016713092,Figure 8: Ablation test for the Nyström approximation.
REFERENCES,0.9303621169916435,"• MMDGP-nystrom is our method with Nystrom approximation, in which the sampling size
m = 16 and sub-sampling size h = 9. Its complexity is O(MNmh), where M and N
are the sizes of training and test samples respectively, m is the sampling size for MMD
estimation, and h indicates the sub-sampling size during the Nystrom approximation."
REFERENCES,0.9331476323119777,"• MMDGP-raw-S does not use the Nystrom approximation but employs an empirical MMD
estimator. Due to its O(MNm2) complexity, we set the sampling size m = 12 to ensure a
similar complexity as the MMDGP-nystrom."
REFERENCES,0.935933147632312,"• MMDGP-raw-L also uses an empirical MMD estimator, but with a larger sampling size
(m = 16)."
REFERENCES,0.9387186629526463,"• GP utilizes a vanilla GP with a learnable output noise level and optimizes with the upper-
confidence-bound acquisition2."
REFERENCES,0.9415041782729805,"According to Figure 8, we find that 1) with sufficient computation power, the MMDGP-raw-L can
obtain the best performance by using a large sample size. 2)However, with limited complexity, the
performance MMDGP-raw-S degrades obviously while the MMDGP-nystrom performs much better.
This suggests that the Nyström approximation can significantly improve the efficiency with a mild
cost of performance degradation. 3) All the MMDGP-based methods are better than the vanilla
GP-UCB."
REFERENCES,0.9442896935933147,"2For a fair comparison, all the methods in this test use a UCB acquisition."
REFERENCES,0.947075208913649,Figure 9: Optimization regret on 10D bumped-bowl problem.
REFERENCES,0.9498607242339833,"Figure 10: The input GMM
distribution."
REFERENCES,0.9526462395543176,Figure 11: Simulation results of the push configurations found by different algorithms.
REFERENCES,0.9554317548746518,"D.3
Optimization on 10D Bumped-Bowl Problem"
REFERENCES,0.958217270194986,"To further evaluate AIRBO’s optimization performance on the high-dimensional problem, we employ
a 10-dimensional bumped bowl function from [27, 19]:"
REFERENCES,0.9610027855153204,"f(x) = g(x1:2)h(x3:), where"
REFERENCES,0.9637883008356546,"(
g(x) = 2 log (0.8∥x∥2 + e−10∥x∥2) + 2.54
h(x) = Pd
i 5x2
i + 1
(33)"
REFERENCES,0.9665738161559888,"Here, xi is the i-th dimension of x, x1:2 represents the first 2 dimensions for the variable, and x3:
indicates the rest dimensions. The input uncertainty is designed to follow a concatenated distribution
of a 2D circular distribution(r = 0.5) and a multivariate normal distribution with a zero mean and
diagonal covariance of 0.01."
REFERENCES,0.9693593314763231,"Figure 9 shows the mean and std values of the optimization regrets. We note that 1)when it comes
to a high-dimensional problem and complex input distribution, the misassumption of Gaussian
input uncertainty renders the skl and ERBF fail to locate the robust optimum and get stuck at local
optimums. 2)Our method outperforms the others and can find the robust optimum efficiently and
stably, while the uGP with a similar inference cost suffers the instability caused by insufficient
sampling and stumbles over iterations, which can be evidenced by its high std values of optimization
regret."
REFERENCES,0.9721448467966574,"D.4
Robust Robot Pushing"
REFERENCES,0.9749303621169917,"This benchmark is based on a Box2D simulator from [31], where our objective is to identify a robust
push configuration, enabling a robot to push a ball to predetermined targets under input randomness.
In our experiment, we simplify the task by setting the push angle to ra = arctan ry"
REFERENCES,0.9777158774373259,"rx , ensuring the
robot is always facing the ball. Also, we intentionally define the input distribution as a two-component
Gaussian Mixture Model as follows:"
REFERENCES,0.9805013927576601,"(rx, ry, rt) ∼GMM
 
µ =

0
0
0
−1
1
0"
REFERENCES,0.9832869080779945,"
, Σ = "
REFERENCES,0.9860724233983287,"
0.12
−0.32
1e −6
−0.32
0.12
1e −6
1e −6
1e −6
1.02 "
REFERENCES,0.9888579387186629,", w =

0.5
0.5"
REFERENCES,0.9916434540389972," 
,
(34)"
REFERENCES,0.9944289693593314,"where the covariance matrix Σ is shared among components and w is the weights of mixture
components. Meanwhile, as the SKL-UCB and ERBF-UCB surrogates can only accept Gaussian
input distributions, we choose to approximate the true input distribution with a Gaussian. As shown
in Figure 10, the approximation error is obvious, which explains the performance gap among these
algorithms in Figure 5b."
REFERENCES,0.9972144846796658,"Apart from the statistics of the found pre-images in Figure 6, we also simulate the robot pushes
according to the found configurations and visualize the results in Figure 11. In this figure, each black
hollow square represents an instance of the robot’s initial location, the grey arrow indicates the push
direction and duration, and the blue circle marks the ball’s ending position after the push. We can
find that, as the GP-UCB ignores the input uncertainty, it randomly pushes to these targets and the
ball ending positions fluctuate. Also, due to the incorrect assumption of the input distribution, the
SKL-UCB and ERBF-UCB fail to control the ball’s ending position under input randomness. On
the contrary, AIRBO successfully recognizes the twin targets in quadrant I as an optimal choice
and frequently pushes to this area. Moreover, all the ball’s ending positions are well controlled and
centralized around the targets under input randomness."
