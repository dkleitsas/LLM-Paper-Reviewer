Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0034482758620689655,"This paper investigates unsupervised learning of Full-Waveform Inversion (FWI),
which has been widely used in geophysics to estimate subsurface velocity maps
from seismic data. This problem is mathematically formulated by a second order
partial differential equation (PDE), but is hard to solve. Moreover, acquiring ve-
locity map is extremely expensive, making it impractical to scale up a supervised
approach to train the mapping from seismic data to velocity maps with convolu-
tional neural networks (CNN).We address these difﬁculties by integrating PDE
and CNN in a loop, thus shifting the paradigm to unsupervised learning that only
requires seismic data. In particular, we use ﬁnite difference to approximate the
forward modeling of PDE as a differentiable operator (from velocity map to seis-
mic data) and model its inversion by CNN (from seismic data to velocity map).
Hence, we transform the supervised inversion task into an unsupervised seismic
data reconstruction task. We also introduce a new large-scale dataset OpenFWI,
to establish a more challenging benchmark for the community. Experiment results
show that our model (using seismic data alone) yields comparable accuracy to the
supervised counterpart (using both seismic data and velocity map). Furthermore,
it outperforms the supervised model when involving more seismic data."
ABSTRACT,0.006896551724137931,"Figure 1: Schematic illustration of our proposed method, which comprises a CNN to learn an inverse
mapping and a differentiable operator to approximate the forward modeling of PDE."
INTRODUCTION,0.010344827586206896,"1
INTRODUCTION"
INTRODUCTION,0.013793103448275862,"Geophysical properties (such as velocity, impedance, and density) play an important role in various
subsurface applications including subsurface energy exploration, carbon capture and sequestration,"
INTRODUCTION,0.017241379310344827,"∗Equal contribution.
Dataset is available at https://openfwi-lanl.github.io."
INTRODUCTION,0.020689655172413793,Published as a conference paper at ICLR 2022
INTRODUCTION,0.02413793103448276,"(a)
(b)"
INTRODUCTION,0.027586206896551724,"Figure 2: An example of (a) a velocity map and (b) seismic measurements (named shot gather in
geophysics) and the 1D time-series signal recorded by a receiver."
INTRODUCTION,0.03103448275862069,"estimating pathways of subsurface contaminant transport, and earthquake early warning systems
to provide critical alerts. These properties can be obtained via seismic surveys, i.e., receiving re-
ﬂected/refracted seismic waves generated by a controlled source. This paper focuses on recon-
structing subsurface velocity maps from seismic measurements. Mathematically, the velocity map
and seismic measurements are correlated through an acoustic-wave equation (a second-order partial
differential equation) as follows:"
INTRODUCTION,0.034482758620689655,"∇2p(r, t) −
1
v(r)2
∂2p(r, t)"
INTRODUCTION,0.03793103448275862,"∂t2
= s(r, t) ,
(1)"
INTRODUCTION,0.041379310344827586,"where p(r, t) denotes the pressure waveﬁeld at spatial location r and time t, v(r) represents the
velocity map, and s(r, t) is the source term. Full-Waveform Inversion (FWI) is a methodology that
determines high-resolution velocity maps v(r) of subsurface via matching synthetic seismic wave-
forms to raw recorded seismic data p(˜r, t), where ˜r represents the locations of seismic receivers."
INTRODUCTION,0.04482758620689655,"A velocity map describes the wave propagation speed in the subsurface region of interest. An exam-
ple in 2D scenario is shown in Figure 2a. Particularly, the x-axis represents the horizontal offset of a
region, and the y-axis stands for the depth. The regions with the same geologic information (veloc-
ity) are called a layer in velocity maps. In a sample of seismic measurements (termed a shot gather
in geophysics) as depicted in Figure 2b, each grid in the x-axis represents a receiver, and the value
in the y-axis is a 1D time-series signal recorded by each receiver."
INTRODUCTION,0.04827586206896552,"Existing approaches solve FWI in two directions: physics-driven and data-driven. Physics-driven
approaches rely on the forward modeling of Equation 1, which simulates seismic data from velocity
map by ﬁnite difference. They optimize velocity map per seismic sample, by iteratively updating
velocity map from an initial guess such that simulated seismic data (after forward modeling) is close
to the input seismic measurements. However, these methods are slow and difﬁcult to scale up as the
iterative optimization is required per input sample. Data-driven approaches consider FWI problem
as an image-to-image translation task and apply convolution neural networks (CNN) to learn the
mapping from seismic data to velocity maps (Wu & Lin, 2019). The limitation of these methods
is that they require paired seismic data and velocity maps to train the network. Such ground truth
velocity maps are hardly accessible in real-world scenario because generating them is extremely
time-consuming even for domain experts."
INTRODUCTION,0.05172413793103448,"In this work, we leverage advantages of both directions (physics + data driven) and shift the paradigm
to unsupervised learning of FWI by connecting forward modeling and CNN in a loop. Speciﬁcally,
as shown in Figure 1, a CNN is trained to predict a velocity map from seismic data, which is followed
by forward modeling to reconstruct seismic data. The loop is closed by applying reconstruction loss
on seismic data to train the CNN. Due to the differentiable forward modeling, the whole loop can
be trained end-to-end. Note that the CNN is trained in an unsupervised manner, as the ground
truth of velocity map is not needed. We name our unsupervised approach as UPFWI (Unsupervised
Physics-informed Full-Waveform Inversion)."
INTRODUCTION,0.05517241379310345,"Additionally, we ﬁnd that perceptual loss (Johnson et al., 2016) is crucial to improve the overall
quality of predicted velocity maps due to its superior capability in preserving the coherence of the
reconstructed waveforms comparing with other losses like Mean Squared Error (MSE) and Mean
Absolute Error (MAE)."
INTRODUCTION,0.05862068965517241,Published as a conference paper at ICLR 2022
INTRODUCTION,0.06206896551724138,"Mean Squared Error (MSE)
Structural Similarity (SSIM)"
INTRODUCTION,0.06551724137931035,"Figure 3: Unsupervised UPFWI (ours) vs. Supervised H-PGNN+ (Sun et al., 2021). Our method
achieves better performance, e.g. lower Mean Squared Error (MSE) and higher Structural Similar-
ity (SSIM), when involving more unlabeled data (>24k)."
INTRODUCTION,0.06896551724137931,"To encourage fair comparison on a large dataset with more complicate geological structures, we
introduce a new synthetic dataset named OpenFWI, which contains 60,000 labeled data (velocity
map and seismic data pairs) and 48,000 unlabeled data (seismic data alone). 30,000 of those velocity
maps contain curved layers that are more challenge for inversion. We also add geological faults with
various shift distances and tilting angles to all velocity maps."
INTRODUCTION,0.07241379310344828,"We evaluate our method on this dataset. Experimental results show that for velocity maps with ﬂat
layers, our UPFWI trained with 48,000 unlabeled data achieves 1146.09 in MSE, which is 26.77%
smaller than that of the supervised baseline H-PGNN+ (Sun et al., 2021), and 0.9895 in Struc-
tured Similarity (SSIM), which is 0.0021 higher; for velocity maps with curved layers, our UPFWI
achieves 3639.96 in MSE, which is 28.30% smaller, and 0.9756 in SSIM, which is 0.0057 higher."
INTRODUCTION,0.07586206896551724,Our contribution is summarized as follows:
INTRODUCTION,0.07931034482758621,"• We propose to solve FWI in an unsupervised manner by connecting CNN and forward
modeling in a loop, enabling end-to-end learning from seismic data alone.
• We ﬁnd that perceptual loss is helpful to boost the performance comparable to the super-
vised counterpart.
• We introduce a large-scale dataset as benchmark to encourage further research on FWI."
INTRODUCTION,0.08275862068965517,"2
PRELIMINARIES OF FULL-WAVEFORM INVERSION (FWI)"
INTRODUCTION,0.08620689655172414,"The goal of FWI in geophysics is to invert for a velocity map v ∈RW ×H from seismic measure-
ments p ∈RS×T ×R, where W and H denote the horizontal and vertical dimensions of the velocity
map, S is the number of sources used to generate waves during data acquisition process, T de-
notes the number of samples in the waveﬁelds recorded by each receiver, and R represents the total
number of receivers."
INTRODUCTION,0.0896551724137931,"In conventional physics-driven methods, forward modeling is commonly referred to the process
of simulating seismic data ˜p from given estimated velocity maps ˆv. For simplicity, the forward
acoustic-wave operator f can be expressed as"
INTRODUCTION,0.09310344827586207,"˜p = f(ˆv) .
(2)"
INTRODUCTION,0.09655172413793103,"Given this forward operator f, the physics-driven FWI can be posed as a minimization prob-
lem (Virieux & Operto, 2009)"
INTRODUCTION,0.1,"E(ˆv) = min
ˆv"
INTRODUCTION,0.10344827586206896,"n
||p −f(ˆv)||2
2 + λR(ˆv)
o
,
(3)"
INTRODUCTION,0.10689655172413794,"where ||p −f(ˆv)||2
2 is the the ℓ2 distance between true seismic measurements p and the corre-
sponding simulated data f(ˆv), λ is a regularization parameter and R(ˆv) is the regularization term
which is often the ℓ2 or ℓ1 norm of ˆv. This requires optimization per sample, which is slow as the
optimization involves multiple iterations from an initial guess."
INTRODUCTION,0.1103448275862069,"Data-driven methods leverage CNNs to directly learn the inverse mapping as (Adler et al., 2021)"
INTRODUCTION,0.11379310344827587,"ˆv = gθ(p) ≈f −1(p) ,
(4)"
INTRODUCTION,0.11724137931034483,Published as a conference paper at ICLR 2022
INTRODUCTION,0.1206896551724138,"where gθ(·) is the approximated inverse operator of f(·) parameterized by θ. In practice, gθ is
usually implemented as a CNN (Adler et al., 2021; Wu & Lin, 2019). This requires paired seismic
data and velocity maps for supervised learning. However, the acquisition of large volume of velocity
maps in ﬁeld applications can be extremely challenging and computationally prohibitive."
METHOD,0.12413793103448276,"3
METHOD"
METHOD,0.12758620689655173,"In this section, we present our Unsupervised Physics-informed solution (named UPFWI), which
connects CNN and forward modeling in a loop. It addresses limitations of both physics-driven and
data-driven approaches, as it requires neither optimization at inference (per sample), nor velocity
maps as supervision."
METHOD,0.1310344827586207,"3.1
UPFWI: CONNECTING CNN AND FORWARD MODELING"
METHOD,0.13448275862068965,"As depicted in Figure 1, our UPFWI connects a CNN gθ and a differentiable forward operator f
to form a loop. In particular, the CNN takes seismic measurements p as input and generates the
corresponding velocity map ˆv. We then apply forward acoustic-wave operator f (see Equation 2)
on the estimated velocity map ˆv to reconstruct the seismic data ˜p. Typically, the forward modeling
employs ﬁnite difference (FD) to discretize the wave equation (Equation 1). The details of forward
modeling will be discussed Section 3.3. The loop is closed by the reconstruction loss between input
seismic data p and reconstructed seismic data ˜p = f(gθ(p)). Notice that the ground truth of the
velocity map v is not involved, and the training process is unsupervised. Since the forward operator
is differentiable, the reconstruction loss can be backpropagated (via gradient descent) to update the
parameters θ in the CNN."
CNN NETWORK ARCHITECTURE,0.13793103448275862,"3.2
CNN NETWORK ARCHITECTURE"
CNN NETWORK ARCHITECTURE,0.1413793103448276,"We use an encoder-decoder structured CNN (similar to Wu & Lin (2019) and Zhang & Lin (2020))
to model the mapping from seismic data p ∈RS×T ×R to velocity map v ∈RW ×H. The encoder
compresses the seismic input and then transforms the latent vector to build the velocity estimation
through a decoder. See the implementation details in Appendix A.1."
DIFFERENTIABLE FORWARD MODELING,0.14482758620689656,"3.3
DIFFERENTIABLE FORWARD MODELING"
DIFFERENTIABLE FORWARD MODELING,0.1482758620689655,"We apply the standard ﬁnite difference (FD) in the space domain and time domain to discretize
the original wave equation.
Speciﬁcally, the second-order central ﬁnite difference in time do-
main ( ∂2p(r,t)"
DIFFERENTIABLE FORWARD MODELING,0.15172413793103448,"∂t2
in Equation 1) is approximated as follows:"
DIFFERENTIABLE FORWARD MODELING,0.15517241379310345,"∂2p(r, t)"
DIFFERENTIABLE FORWARD MODELING,0.15862068965517243,"∂t2
≈
1
(∆t)2 (pt+1
r
−2pt
r + pt−1
r
) + O[(∆t)2] ,
(5)"
DIFFERENTIABLE FORWARD MODELING,0.16206896551724137,"where pt
r denotes the pressure waveﬁelds at timestep t, and pt+1
r
and pt−1
r
are the waveﬁelds at
t + ∆t and t −∆t, respectively. The Laplacian of p(r, t) can be estimated in the similar way on the
space domain (see Appendix A.2). Therefore, the wave equation can then be written as"
DIFFERENTIABLE FORWARD MODELING,0.16551724137931034,"pt+1
r
= (2 −v2∇2)pt
r −pt−1
r
−v2(∆t)2st
r ,
(6)"
DIFFERENTIABLE FORWARD MODELING,0.16896551724137931,where ∇2 here denotes the discrete Laplace operator.
DIFFERENTIABLE FORWARD MODELING,0.1724137931034483,"The initial waveﬁeld at the initial timestep is set to zero (i.e. p0
r = 0). Thus, the gradient of loss L
with respect to estimated velocity at spatial location r can be computed using the chain rule as"
DIFFERENTIABLE FORWARD MODELING,0.17586206896551723,"∂L
∂v(r) = T
X t=0"
DIFFERENTIABLE FORWARD MODELING,0.1793103448275862,"
∂L
∂p(r, t)"
DIFFERENTIABLE FORWARD MODELING,0.18275862068965518,"∂p(r, t)"
DIFFERENTIABLE FORWARD MODELING,0.18620689655172415,"∂v(r) ,
(7)"
DIFFERENTIABLE FORWARD MODELING,0.1896551724137931,where T indicates the total number of timesteps.
DIFFERENTIABLE FORWARD MODELING,0.19310344827586207,Published as a conference paper at ICLR 2022
LOSS FUNCTION,0.19655172413793104,"3.4
LOSS FUNCTION"
LOSS FUNCTION,0.2,The reconstruction loss of our UPFWI includes a pixel-wise loss and a perceptual loss as follows:
LOSS FUNCTION,0.20344827586206896,"L(p, ˜p) = Lpixel(p, ˜p) + Lperceptual(p, ˜p),
(8)"
LOSS FUNCTION,0.20689655172413793,"where p and ˜p are input and reconstructed seismic data, respectively. The pixel-wise loss Lpixel
combines ℓ1 and ℓ2 distance as:"
LOSS FUNCTION,0.2103448275862069,"Lpixel(p, ˜p) = λ1ℓ1(p, ˜p) + λ2ℓ2(p, ˜p),
(9)"
LOSS FUNCTION,0.21379310344827587,"where λ1 and λ2 are two hyper-parameters to control the relative importance. For the perceptual
loss Lperceptual, we extract features from conv5 in a VGG-16 network (Simonyan & Zisserman,
2015) pretrained on ImageNet (Krizhevsky et al., 2012) and combine the ℓ1 and ℓ2 distance as:"
LOSS FUNCTION,0.21724137931034482,"Lperceptual(p, ˜p) = λ3ℓ1(φ(p), φ(˜p)) + λ4ℓ2(φ(p), φ(˜p)),
(10)"
LOSS FUNCTION,0.2206896551724138,"where φ(·) represents the output of conv5 in the VGG-16 network, and λ3 and λ4 are two hyper-
parameters. Compared to the pixel-wise loss, the perceptual loss is better to capture the region-wise
structure, which reﬂects the waveform coherence. This is crucial to boost the overall accuracy of
velocity maps (e.g. the quantitative velocity values and the structural information)."
OPENFWI DATASET,0.22413793103448276,"4
OPENFWI DATASET"
OPENFWI DATASET,0.22758620689655173,"We introduce a new large-scale geophysics FWI dataset OpenFWI, which consists of 108K seismic
data for two types of velocity maps: one with ﬂat layers (named FlatFault) and the other one with
curved layers (named CurvedFault). Each type has 54K seismic data, including 30K with paired
velocity maps (labeled) and 24K unlabeled. The 30K labeled pairs are splitted as 24K/3K/3K for
training, validation and testing respectively. Samples are shown in Appendix A.3."
OPENFWI DATASET,0.23103448275862068,"The shape of curves in our dataset follows a sine function. Velocity maps in CurvedFault are de-
signed to validate the effectiveness of FWI methods on curved topography. Compared to the maps
with ﬂat layers, curved velocity maps yield much more irregular geological structures, making in-
version more challenging. Both FlatFault and CurvedFault contain 30,000 samples with 2 to 4 layers
and their corresponding seismic data. Each velocity map has dimensions of 70×70, and the grid size
is 15 meter in both directions. The layer thickness ranges from 15 grids to 35 grids, and the veloc-
ity in each layer is randomly sampled from a uniform distribution between 3,000 meter/second and
6,000 meter/second. The velocity is designed to increase with depth to be more physically realistic.
We also add geological faults to every velocity map. The faults shift from 10 grids to 20 grids, and
the tilting angle ranges from -123◦to 123◦."
OPENFWI DATASET,0.23448275862068965,"To synthesize seismic data, ﬁve sources are evenly placed on surface with a 255-meter spacing, and
seismic traces are recorded by 70 receivers at each grid with an interval of 15 meter. The source is
a Ricker wavelet with a central frequency of 25 Hz (Wang, 2015). Each receiver records time-series
data for 1 second, and we use a 1 millisecond sample rate to generate 1,000 timesteps. Therefore, the
dimensions of seismic data become 5×1000×70. Compared to existing datasets (Yang & Ma, 2019;
Moseley et al., 2020), OpenFWI is signiﬁcantly larger. It includes more complicated and physically
realistic velocity maps. We hope it establishes a more challenging benchmark for the community."
EXPERIMENTS,0.23793103448275862,"5
EXPERIMENTS"
EXPERIMENTS,0.2413793103448276,"In this section, we present experimental results of our proposed UPFWI evaluated on the OpenFWI."
IMPLEMENTATION DETAILS,0.24482758620689654,"5.1
IMPLEMENTATION DETAILS"
IMPLEMENTATION DETAILS,0.2482758620689655,"Training Details:
The input seismic data are normalized to range [−1, 1].
We employ
AdamW (Loshchilov & Hutter, 2018) optimizer with momentum parameters β1 = 0.9, β2 = 0.999
and a weight decay of 1 × 10−4 to update all parameters of the network. The initial learning rate is
set to 3.2 × 10−4, and we reduce the learning rate by a factor of 10 when validation loss reaches a
plateau. The minimum learning rate is set to 3.2 × 10−6. The size of a mini-batch is set to 128. All"
IMPLEMENTATION DETAILS,0.2517241379310345,Published as a conference paper at ICLR 2022
IMPLEMENTATION DETAILS,0.25517241379310346,"Supervision
Method
FlatFault
CurvedFault
MAE ↓
MSE ↓
SSIM ↑
MAE ↓
MSE ↓
SSIM ↑"
IMPLEMENTATION DETAILS,0.25862068965517243,Supervised
IMPLEMENTATION DETAILS,0.2620689655172414,"InversionNet
15.83
2156.00
0.9832
23.77
5285.38
0.9681
VelocityGAN
16.15
1770.31
0.9857
25.83
5076.79
0.9699
H-PGNN+
(our implementation)"
IMPLEMENTATION DETAILS,0.2655172413793103,"12.91
1565.02
0.9874
24.19
5139.60
0.9685"
IMPLEMENTATION DETAILS,0.2689655172413793,"Unsupervised
UPFWI-24K (ours)
16.27
1705.35
0.9866
29.59
5712.25
0.9652
UPFWI-48K (ours)
14.60
1146.09
0.9895
23.56
3639.96
0.9756"
IMPLEMENTATION DETAILS,0.27241379310344827,"Table 1: Quantitative results evaluated on OpenFWI in terms of MAE, MSE and SSIM. Our
UPFWI yields comparable inversion accuracy comparing to supervised baselines. For H-PGNN+,
we use our network architecture to replace the original one reported in their paper, and an additional
perceptual loss between seismic data is added during training."
IMPLEMENTATION DETAILS,0.27586206896551724,"Ground Truth
InversionNet
VelocityGAN
H-PGNN+
UPFWI-24K (Ours)
UPFWI-48K (Ours)"
IMPLEMENTATION DETAILS,0.2793103448275862,"Figure 4: Comparison of different methods on inverted velocity maps of FlatFault (top) and
CurvedFault (bottom).
For FlatFault, our UPFWI-48K reveals more accurate details at layer
boundaries and the slope of the fault in deep region. For CurvedFault, our UPFWI reconstructs
the geological anomalies on the surface that best match the ground truth."
IMPLEMENTATION DETAILS,0.2827586206896552,"trade-off hyper-parameters λ in our loss function are set to 1. We implement our models in Pytorch
and train them on 8 NVIDIA Tesla V100 GPUs. All models are randomly initialized."
IMPLEMENTATION DETAILS,0.28620689655172415,"Evaluation Metrics: We consider three metrics for evaluating the velocity maps inverted by our
method: MAE, MSE and SSIM. Both MAE and MSE have been employed in existing methods (Wu
& Lin, 2019; Zhang & Lin, 2020) to measure pixel-wise errors. Considering the layered-structured
velocity maps contain highly structured information, degradation or distortion can be easily per-
ceived by a human. To better align with human vision, we employ SSIM to measure perceptual
similarity. Note that for MAE and MSE calculation, we denormalize velocity maps to their original
scale while we keep them in normalized scale [-1, 1] for SSIM according to the algorithm."
IMPLEMENTATION DETAILS,0.2896551724137931,"Comparison: We compare our method with three state-of-the-art algorithms: two pure data-driven
methods, i.e., InversionNet (Wu & Lin, 2019) and VelocityGAN (Zhang & Lin, 2020), and a physics-
informed method H-PGNN (Sun et al., 2021). We follow the implementation described in these
papers and search for the best hyper-parameters for OpenFWI dataset. Note that we improve H-
PGNN by replacing the network architecture with the CNN in our UPFWI and adding perceptual
loss, resulting in a signiﬁcant boosted performance. We refer our implementation as H-PGNN+,
which is a strong supervised baseline. Our method has two variants (UPFWI-24K and UPFWI-
48K), using 24K and 48K unlabeled seismic data respectively."
MAIN RESULTS,0.29310344827586204,"5.2
MAIN RESULTS"
MAIN RESULTS,0.296551724137931,"Results on FlatFault: Table 1 shows the results of different methods on FlatFault. Compared to
InversionNet and VelocityGAN, our UPFWI-24K performs better in MSE and SSIM, but is slightly
worse in MAE score. Compared to H-PGNN+, there is a gap between our UPFWI-24K and H-
PGNN+ when trained with the same amount of data. However, after we double the size of unlabeled
data (from 24K to 48K), a signiﬁcant improvement is observed in our UPFWI-48K for all three
metrics, and it outperforms all three supervised baselines in MSE and SSIM. This demonstrates the
potential of our UPFWI for achieving higher performance with more unlabeled data involved."
MAIN RESULTS,0.3,Published as a conference paper at ICLR 2022
MAIN RESULTS,0.30344827586206896,"(a)
(b)"
MAIN RESULTS,0.30689655172413793,"Ground Truth
pixel-ℓ2
pixel-ℓ1ℓ2
pixel-ℓ1ℓ2+
perceptual"
MAIN RESULTS,0.3103448275862069,"Figure 5: Comparison of UPFWI with different loss functions on (a) waveform residual and
their corresponding inversion results (ground truth provided in the ﬁrst column), and (b) single trace
residuals recorded by the receiver at 525 m offset. Our UPFWI trained with pixel-wise loss (ℓ1+ℓ2
distance) and perceptual loss yields the most accurate results. Best viewed in color."
MAIN RESULTS,0.3137931034482759,"The velocity maps inverted by different methods are shown in the top row of Figure 4. Consistent
with our quantitative analysis, more accurate details are observed in the velocity maps generated
by UPFWI-48K. For instance, we ﬁnd in the visualization results that both InversionNet and Ve-
locityGAN generate blurry results in deep region, while H-PGNN+, UPFWI-24K and UPFWI-48K
yield much clearer boundaries. We attribute this ﬁnding as the impact of seismic loss. We further
observe that the slope of the fault in deep region is different from that in the shallow region, yet only
UPFWI-48K replicates this result as highlighted by the green square."
MAIN RESULTS,0.31724137931034485,"Results on CurvedFault: Table 1 shows the results of CurvedFault. Performance degradation is ob-
served for all models, due to the more complicated geological structures in CurvedFault. Although
our UPFWI-24K underperforms the three supervised baselines, our UPFWI-48K signiﬁcantly boosts
the performance, outperforming all supervised methods in terms of all three metrics. This demon-
strates the power of unsupervised learning in our UPFWI that greatly beneﬁts from more unlabeled
data when dealing with more complicated curved structure."
MAIN RESULTS,0.32068965517241377,"The bottom row of Figure 4 shows the visualized velocity maps in CurvedFault obtained using dif-
ferent methods. Similar to the observation in FlatFault, our UPFWI-48K yields more accurate details
compared to the results of supervised methods. For instance, only our UPFWI-24K and UPFWI-
48K precisely reconstruct the fault beneath the curve around the top-left corner as highlighted by
the yellow square. Although some artifacts are observed in the results of UPFWI-24K around the
layer boundary in deep region, they are eliminated in the results of UPFWI-48K. More visualization
results are shown in Appendix A.3."
ABLATION STUDY,0.32413793103448274,"5.3
ABLATION STUDY"
ABLATION STUDY,0.3275862068965517,"Loss
Velocity Error
Seismic Error"
ABLATION STUDY,0.3310344827586207,"pixel-ℓ2
pixel-ℓ1
perceptual
MAE ↓
MSE ↓
SSIM ↑
MAE ↓
MSE ↓
SSIM ↑"
ABLATION STUDY,0.33448275862068966,"✓
32.61
10014.47
0.9735
0.0167
0.0023
0.9978"
ABLATION STUDY,0.33793103448275863,"✓
✓
21.71
2999.55
0.9775
0.0155
0.0025
0.9977"
ABLATION STUDY,0.3413793103448276,"✓
✓
✓
16.27
1705.35
0.9866
0.0140
0.0021
0.9984"
ABLATION STUDY,0.3448275862068966,"Table 2: Quantitative results of our UPFWI with different loss
function settings."
ABLATION STUDY,0.3482758620689655,"Loss Terms: We study the con-
tribution of each loss term in our
loss function: (a) pixel-wise ℓ2
distance (MSE), (b) pixel-wise
ℓ1 distance (MAE), and (c) per-
ceptual loss.
All experiments
are conducted on FlatFault using
24,000 unlabeled data."
ABLATION STUDY,0.35172413793103446,"Figure 5a shows the predicted velocity maps for using three loss combinations (pixel-ℓ2, pixel-ℓ1ℓ2,
pixel-ℓ1ℓ2+perceptual) in UPFWI. The ground truth seismic data and velocity map are shown in the
left column. For each loss option, we show the difference between the reconstructed and the input
seismic data (on the top) and predicted velocity (on the bottom). When using pixel-wise loss in l2
distance alone, there are some obvious artifacts in both seismic data (around 600 millisecond) and
velocity map. These artifacts are mitigated by introducing additional pixel-wise loss in l1 distance."
ABLATION STUDY,0.35517241379310344,Published as a conference paper at ICLR 2022
ABLATION STUDY,0.3586206896551724,"Method
Marmousi
Salt
MAE↓
MSE↓
SSIM↑
MAE↓
MSE↓
SSIM↑"
ABLATION STUDY,0.3620689655172414,"InversionNet
149.67
45936.23
0.7889
25.98
8669.98
0.9764"
ABLATION STUDY,0.36551724137931035,"UPFWI
221.93
125825.75
0.7920
150.34
164595.28
0.7837"
ABLATION STUDY,0.3689655172413793,"Table 3: Quantitative results of our UPFWI evaluated on
Marmousi and Salt datasets."
ABLATION STUDY,0.3724137931034483,"Network
MAE↓
MSE↓
SSIM↑"
ABLATION STUDY,0.3758620689655172,"CNN
16.27
1705.35
0.9866"
ABLATION STUDY,0.3793103448275862,"ViT
41.44
11029.01
0.9461"
ABLATION STUDY,0.38275862068965516,"MLP-Mixer
22.32
4177.37
0.9726"
ABLATION STUDY,0.38620689655172413,"Table 4: Quantitative results of our UP-
FWI with different architectures."
ABLATION STUDY,0.3896551724137931,"With perceptual loss added, more details are correctly retained (e.g. seismic data from 400 millisec-
ond to 600 millisecond, velocity boundary between layers). Figure 5b compares the reconstructed
seismic data (in terms of residual to the ground truth) at a slice of 525 meter offset (orange dash line
in Figure 5a). Clearly, the combination of pixel-wise and perceptual loss has the smallest residual."
ABLATION STUDY,0.3931034482758621,"The quantitative results are shown in Table 2. They are consistent with our observation in qualitative
analysis (Figure 5a). In particular, using pixel-wise loss in ℓ2 distance has the worst performance.
The involvement of ℓ1 distance mitigates velocity errors but is slightly worse on MSE and SSIM
of seismic error. Adding perceptual loss boosts the performance in all metrics by a clear margin.
This shows perceptual loss is helpful to retain waveform coherence, which is correlated to velocity
boundary, and validates our proposed loss function (combining pixel-wise and perceptual loss)."
ABLATION STUDY,0.39655172413793105,"σ
(10−4)"
ABLATION STUDY,0.4,"FlatFault
CurvedFault
PSNR
MAE↓
MSE↓
SSIM↑
PSNR
MAE↓
MSE↓
SSIM↑"
ABLATION STUDY,0.40344827586206894,"0.5
61.60
15.68
1343.21
0.9888
61.72
23.78
3704.00
0.9751"
ABLATION STUDY,0.4068965517241379,"1.0
58.70
24.84
4010.78
0.9733
58.70
24.84
4010.78
0.9733"
ABLATION STUDY,0.4103448275862069,"5.0
51.58
44.33
7592.57
0.9681
51.68
46.90
10415.38
0.9441"
ABLATION STUDY,0.41379310344827586,"Table 5: Quantitative results of our UPFWI tested on seismic
inputs with different noise levels."
ABLATION STUDY,0.41724137931034483,"More Challenging Datasets: We
further evaluate our UPFWI on two
more challenging tests including
Marmousi and Salt (Yang & Ma,
2019) datasets and achieve solid re-
sults. For Marmousi dataset, we fol-
low the work of Feng et al. (2021)
and employ the Marmousi velocity
map as the style image to construct a low-resolution dataset. Table 3 shows the quantitative results
on both datasets. Although our UPFWI achieves good results on Salt dataset with preserved sub-
surface structures, it has clearly larger errors than the supervised InversionNet. This is due to two
reasons: (a) Salt dataset has a small amount of training data (120 samples), which is very chal-
lenging for unsupervised methods; (b) the variability between training and testing samples is small,
providing a signiﬁcantly larger favor to supervised methods than the unsupervised counterparts. The
visualization of results on Marmousi dataset and Salt data are shown in Appendix A.4."
ABLATION STUDY,0.4206896551724138,"Missing
Traces"
ABLATION STUDY,0.4241379310344828,"FlatFault
CurvedFault
MAE↓
MSE↓
SSIM↑
MAE↓
MSE↓
SSIM↑"
ABLATION STUDY,0.42758620689655175,"4 (5%)
21.23
1772.05
0.9868
41.33
6914.12
0.9622"
ABLATION STUDY,0.43103448275862066,"7 (10%)
33.66
3504.25
0.9814
61.72
12445.90
0.9453"
ABLATION STUDY,0.43448275862068964,"17 (25%)
85.21
16731.69
0.9457
121.06
36770.77
0.8853"
ABLATION STUDY,0.4379310344827586,"Table 6: Quantitative results of our UPFWI tested on
seismic inputs with missing traces."
ABLATION STUDY,0.4413793103448276,"Other Network Architectures: We fur-
ther conducted experiments by using Vision
Transformer (ViT, Dosovitskiy et al., 2020)
and MLP-Mixer (Tolstikhin et al., 2021) to
replace CNN as the encoder. Table 4 further
shows the quantitative results. Solid results
are obtained for both network architectures,
indicating our proposed method is model-
agnostic. Visualization results are shown in Appendix A.4."
ABLATION STUDY,0.44482758620689655,"Robustness Evaluation: We validate the robustness of our UPFWI models by two additional tests:
(1) testing data contaminated by Gaussian noise and (2) testing data with missing traces. The quan-
titative results are shown in Table 5 and Table 6, respectively. We observe that in both experiments
our model is robust to a certain level of noise and irregular acquisition. Visualization results are
shown in Appendix A.4."
DISCUSSION,0.4482758620689655,"6
DISCUSSION"
DISCUSSION,0.4517241379310345,"Our UPFWI has two major limitations. Firstly, it needs further improvement on a small number of
challenging velocity maps where adjacent layers have very close velocity values. We ﬁnd that the
lack of supervision is not the cause as our UPFWI yields comparable or even better results compared
to its supervised counterparts. Another limitation is the speed and memory consumption for forward
modeling, as the gradient of ﬁnite difference (see Equation 6) need to be stored for backpropagation.
We will explore different loss functions (e.g. adversarial loss) and methods that can balance the
requirement of computation resources and the accuracy in the future work. We believe the idea"
DISCUSSION,0.45517241379310347,Published as a conference paper at ICLR 2022
DISCUSSION,0.4586206896551724,"of connecting CNN and PDE to solve full-waveform inversion has potential to be applied to other
inverse problems with a governing PDE such as medical imaging and ﬂow estimation."
RELATED WORK,0.46206896551724136,"7
RELATED WORK"
RELATED WORK,0.46551724137931033,"Physics-driven Methods: In the past few decades, many regularization techniques have been pro-
posed to alleviate the ill-posedness and non-linearity of FWI (Hu et al., 2009; Burstedde & Ghattas,
2009; Ram´ırez & Lewis, 2010; Lin & Huang, 2017; 2015b;a; Guitton, 2012; Treister & Haber,
2016). Other researchers focused on multi-scale techniques and decomposed the data into different
frequency bands (Bunks et al., 1995; Boonyasiriwat et al., 2009)."
RELATED WORK,0.4689655172413793,"Data-driven Methods: Recently, some researchers employed neural networks to solve FWI. Those
methods can be further divided into supervised and unsupervised methods."
RELATED WORK,0.4724137931034483,"Supervised: One type of supervised methods require labeled samples to directly learn the inverse
mapping, and they can be formulated as:"
RELATED WORK,0.47586206896551725,"ˆv(p) = gθ∗(p) s.t. θ∗(Φs) = arg min
θ X"
RELATED WORK,0.4793103448275862,"{vi,pi}∈Φs
L(gθ(pi), vi),
(11)"
RELATED WORK,0.4827586206896552,"where p denotes the seismic measurements, v is the velocity map, θ represents the trainable weights
in the inversion network gθ(·), f(·) is the forward modeling, and L(·, ·) is a loss function. One exam-
ple of supervised methods is the fully connected network proposed by Araya-Polo et al. (2018). Wu
& Lin (2019) developed an encoder-decoder structured network to handle more complex velocity
maps. Zhang & Lin (2020) adopted GAN and transfer learning to improve generalizability. Li et al.
(2020) designed SeisInvNet to solve misaligned issue when dealing sources from different locations.
In Yang & Ma (2019), a U-Net architecture was proposed with skip connections. Feng et al. (2021)
proposed a multi-scale framework by considering different frequency components. Rojas-G´omez
et al. (2020) developed an adaptive data augmentation method to improvegeneralizability. Sun et al.
(2021) combined the data-driven and physics-based methods and proposed H-PGNN model."
RELATED WORK,0.4862068965517241,"Another type of supervised methods GANs to learn a distribution from velocity maps in training set
as a prior (Richardson, 2018; Mosser et al., 2020). They can be formulated as:
ˆv(z∗) = gθ∗(z∗) s.t. z∗(p) = arg min
z
L(f(gθ∗(z)), p),"
RELATED WORK,0.4896551724137931,"θ∗(Φv) = arg min
θ X"
RELATED WORK,0.49310344827586206,"vi∈Φv
LGAN(gθ(αi), vi),
(12)"
RELATED WORK,0.496551724137931,"where Φv is a training dataset including numerous velocity maps. z and αi are tensors sampled
from the normal distribution. The iterative optimization is then performed on z to draw a velocity
map sampled from the prior distribution."
RELATED WORK,0.5,"Unsupervised: The existing unsupervised methods follow the iterative optimization paradigm and
perform FWI per sample. They employ neural networks to reparameterize velocity maps. The
networks serve as an implicit regularization and are required to be pretrained on an expert initial
guess. Those methods can be formulated as:
ˆv(p) = gθ∗(p)(a) s.t. θ∗(p) = arg min
θ
L(f(gθ(a)), p),
(13)"
RELATED WORK,0.503448275862069,"where a is a random tensor. Different network architectures have been proposed including CNN-
domain FWI (Wu & McMechan, 2019) and DNN-FWI (He & Wang, 2021). Zhu et al. (2021)
developed NNFWI which does not need pretraining ahead, but the initial guess is still required to be
fed into the PDE with estimated velocity maps."
CONCLUSION,0.506896551724138,"8
CONCLUSION"
CONCLUSION,0.5103448275862069,"In this study, we introduce an unsupervised method named UPFWI to solve FWI by connecting CNN
and forward modeling in a loop. Our method can learn the inverse mapping from seismic data alone
in an end-to-end manner. We demonstrate through a series of experiments that our UPFWI trained
with sufﬁcient amount of unlabeled data outperforms the supervised counterpart on our dataset. The
ablation study further substantiates that perceptual loss is a critical component in our loss function
and has a great contribution to the performance of our UPFWI."
CONCLUSION,0.5137931034482759,Published as a conference paper at ICLR 2022
CONCLUSION,0.5172413793103449,ACKNOWLEDGMENTS
CONCLUSION,0.5206896551724138,"This work was supported by the Center for Space and Earth Science at Los Alamos National Labora-
tory (LANL), and by the Laboratory Directed Research and Development program under the project
number 20210542MFR at LANL."
REFERENCES,0.5241379310344828,REFERENCES
REFERENCES,0.5275862068965518,"Amir Adler, Mauricio Araya-Polo, and Tomaso Poggio. Deep learning for seismic inverse problems:
toward the acceleration of geophysical analysis workﬂows. IEEE Signal Processing Magazine,
38(2):89–119, 2021."
REFERENCES,0.5310344827586206,"Mauricio Araya-Polo, Joseph Jennings, Amir Adler, and Taylor Dahlke. Deep-learning tomography."
REFERENCES,0.5344827586206896,"The Leading Edge, 37(1):58–66, 2018."
REFERENCES,0.5379310344827586,"Chaiwoot Boonyasiriwat, Paul Valasek, Partha Routh, Weiping Cao, Gerard T Schuster, and Brian
Macy. An efﬁcient multiscale method for time-domain waveform tomography. Geophysics, 74
(6):WCC59–WCC68, 2009."
REFERENCES,0.5413793103448276,"Carey Bunks, Fatimetou Saleck, S Zaleski, and G Chavent. Multiscale seismic waveform inversion."
REFERENCES,0.5448275862068965,"Geophysics, 60(5):1457–1473, 1995."
REFERENCES,0.5482758620689655,"Carsten Burstedde and Omar Ghattas. Algorithmic strategies for full waveform inversion: 1D ex-
periments. Geophysics, 74(6):37–46, 2009."
REFERENCES,0.5517241379310345,"Francis Collino and Chrysoula Tsogka. Application of the perfectly matched absorbing layer model
to the linear elastodynamic problem in anisotropic heterogeneous media. Geophysics, 66(1):
294–307, 2001."
REFERENCES,0.5551724137931034,"Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas
Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An
image is worth 16x16 words: Transformers for image recognition at scale.
In International
Conference on Learning Representations, 2020."
REFERENCES,0.5586206896551724,"Shihang Feng, Youzuo Lin, and Brendt Wohlberg. Multiscale data-driven seismic full-waveform
inversion with ﬁeld data study. IEEE Transactions on Geoscience and Remote Sensing, pp. 1–14,
2021. doi: 10.1109/TGRS.2021.3114101."
REFERENCES,0.5620689655172414,"Antoine Guitton.
Blocky regularization schemes for full waveform inversion.
Geophysical
Prospecting, 60:870–884, 2012."
REFERENCES,0.5655172413793104,"Qinglong He and Yanfei Wang. Reparameterized full-waveform inversion using deep neural net-
works. Geophysics, 86(1):V1–V13, 2021."
REFERENCES,0.5689655172413793,"Wenyi Hu, Aria Abubakar, and Tarek Habashy. Simultaneous multifrequency inversion of full-
waveform seismic data. Geophysics, 74(2):1–14, 2009."
REFERENCES,0.5724137931034483,"Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by
reducing internal covariate shift. In International Conference on Machine Learning, pp. 448–456.
PMLR, 2015."
REFERENCES,0.5758620689655173,"Justin Johnson, Alexandre Alahi, and Li Fei-Fei. Perceptual losses for real-time style transfer and
super-resolution. In European Conference on Computer Vision, pp. 694–711. Springer, 2016."
REFERENCES,0.5793103448275863,"Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. ImageNet classiﬁcation with deep convo-
lutional neural networks. Advances in Neural Information Processing Systems, 25:1097–1105,
2012."
REFERENCES,0.5827586206896552,"Shucai Li, Bin Liu, Yuxiao Ren, Yangkang Chen, Senlin Yang, Yunhai Wang, and Peng Jiang. Deep-
learning inversion of seismic data. IEEE Transactions on Geoscience and Remote Sensing, 58(3):
2135–2149, 2020. doi: 10.1109/TGRS.2019.2953473."
REFERENCES,0.5862068965517241,Published as a conference paper at ICLR 2022
REFERENCES,0.5896551724137931,"Youzuo Lin and Lianjie Huang. Acoustic- and elastic-waveform inversion using a modiﬁed Total-
Variation regularization scheme. Geophysical Journal International, 200(1):489–502, 2015a. doi:
10.1093/gji/ggu393."
REFERENCES,0.593103448275862,"Youzuo Lin and Lianjie Huang.
Quantifying subsurface geophysical properties changes using
double-difference seismic-waveform inversion with a modiﬁed Total-Variation regularization
scheme. Geophysical Journal International, 203(3):2125–2149, 2015b. doi: 10.1093/gji/ggv429."
REFERENCES,0.596551724137931,"Youzuo Lin and Lianjie Huang. Building subsurface velocity models with sharp interfaces using
interface-guided seismic full-waveform inversion. Pure and Applied Geophysics, 174(11):4035–
4055, 2017. doi: 10.1007/s00024-017-1628-5."
REFERENCES,0.6,"Ilya Loshchilov and Frank Hutter.
Decoupled weight decay regularization.
In International
Conference on Learning Representations, 2018."
REFERENCES,0.603448275862069,"Ben Moseley, Tarje Nissen-Meyer, and Andrew Markham. Deep learning for fast simulation of
seismic waves in complex media. Solid Earth, 11(4):1527–1549, 2020."
REFERENCES,0.6068965517241379,"Lukas Mosser, Olivier Dubrule, and Martin J Blunt. Stochastic seismic waveform inversion using
generative adversarial networks as a geological prior. Mathematical Geosciences, 52(1):53–79,
2020."
REFERENCES,0.6103448275862069,Vinod Nair and Geoffrey E Hinton. Rectiﬁed linear units improve restricted Boltzmann machines. In
REFERENCES,0.6137931034482759,"Proceedings of the 27th International Conference on Machine Learning (ICML-10), pp. 807–814,
2010."
REFERENCES,0.6172413793103448,"Adriana Ram´ırez and Winston Lewis.
Regularization and full-waveform inversion: A two-step
approach.
In 80th Annual International Meeting, SEG, Expanded Abstracts, pp. 2773–2778,
2010."
REFERENCES,0.6206896551724138,"Alan Richardson.
Generative adversarial networks for model order reduction in seismic full-
waveform inversion. arXiv preprint arXiv:1806.00828, 2018."
REFERENCES,0.6241379310344828,"Ren´an Rojas-G´omez, Jihyun Yang, Youzuo Lin, James Theiler, and Brendt Wohlberg. Physics-
consistent data-driven waveform inversion with adaptive data augmentation. IEEE Geoscience
and Remote Sensing Letters, 2020."
REFERENCES,0.6275862068965518,"Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image
recognition. In International Conference on Learning Representations, 2015."
REFERENCES,0.6310344827586207,"Jian Sun, Kristopher A Innanen, and Chao Huang. Physics-guided deep learning for seismic inver-
sion with hybrid training and uncertainty analysis. Geophysics, 86(3):R303–R317, 2021."
REFERENCES,0.6344827586206897,"Ilya Tolstikhin, Neil Houlsby, Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Thomas Un-
terthiner, Jessica Yung, Andreas Peter Steiner, Daniel Keysers, Jakob Uszkoreit, et al. Mlp-mixer:
An all-mlp architecture for vision. In Thirty-Fifth Conference on Neural Information Processing
Systems, 2021."
REFERENCES,0.6379310344827587,Eran Treister and Eldad Haber. Full waveform inversion guided by travel time tomography. SIAM
REFERENCES,0.6413793103448275,"Journal on Scientiﬁc Computing, 39:S587–S609, 2016."
REFERENCES,0.6448275862068965,"Jean Virieux and St´ephane Operto. An overview of full-waveform inversion in exploration geo-
physics. Geophysics, 74(6):WCC1–WCC26, 2009."
REFERENCES,0.6482758620689655,"Yanghua Wang. Frequencies of the Ricker wavelet. Geophysics, 80(2):A31–A37, 2015."
REFERENCES,0.6517241379310345,"Yue Wu and Youzuo Lin. InversionNet: An efﬁcient and accurate data-driven full waveform inver-
sion. IEEE Transactions on Computational Imaging, 6(1):419–433, 2019."
REFERENCES,0.6551724137931034,"Yulang Wu and George A McMechan.
Parametric convolutional neural network-domain full-
waveform inversion. Geophysics, 84(6):R881–R896, 2019."
REFERENCES,0.6586206896551724,"Fangshu Yang and Jianwei Ma. Deep-learning inversion: A next-generation seismic velocity model
building method. Geophysics, 84(4):R583–R599, 2019."
REFERENCES,0.6620689655172414,Published as a conference paper at ICLR 2022
REFERENCES,0.6655172413793103,"Zhongping Zhang and Youzuo Lin. Data-driven seismic waveform inversion: A study on the robust-
ness and generalization. IEEE Transactions on Geoscience and Remote Sensing, 58:6900–6913,
2020."
REFERENCES,0.6689655172413793,"Weiqiang Zhu, Kailai Xu, Eric Darve, Biondo Biondi, and Gregory C Beroza. Integrating deep
neural networks with full-waveform inversion: Reparametrization, regularization, and uncertainty
quantiﬁcation. Geophysics, 87(1):1–103, 2021."
REFERENCES,0.6724137931034483,"A
APPENDIX"
REFERENCES,0.6758620689655173,"A.1
NETWORK ARCHITECTURE"
REFERENCES,0.6793103448275862,"Since the number of receivers R and the number of timesteps T in seismic measurements are unbal-
anced (T ≫R), we ﬁrst stack a 7×1 and six 3×1 convolutional layers (with stride 2 every the other
layer to reduce dimension) to extract temporal features until the temporal dimension is close to R.
Then, six 3×3 convolutional layers are followed to extract spatial-temporal features. The resolution
is down-sampled every the other layer by using stride 2. Next, the feature map is ﬂattened and a
fully connected layer is applied to generate the latent feature with dimension 512. The decoder ﬁrst
repeats the latent vector by 25 times to generate a 5×5×512 tensor. Then it is followed by ﬁve 3×3
convolutional layers with nearest neighbor upsampling in between, resulting in a feature map with
size 80×80×32. Finally, we center-crop the feature map (70×70) and apply a 3×3 convolution
layer to output a single channel velocity map."
REFERENCES,0.6827586206896552,"All the aforementioned convolutional and upsampling layers are followed by a batch normaliza-
tion (Ioffe & Szegedy, 2015) and a leaky ReLU (Nair & Hinton, 2010) as activation function."
REFERENCES,0.6862068965517242,"A.2
DERIVATION OF FORWARD MODELING IN PRACTICE"
REFERENCES,0.6896551724137931,"Similar to the ﬁnite difference in time domain, in 2D situation, by applying the fourth-order central
ﬁnite difference in space, the Laplacian of p(r, t) can be discretized as"
REFERENCES,0.6931034482758621,"∇2p(r, t) = ∂2p"
REFERENCES,0.696551724137931,"∂x2 + ∂2p ∂z2 ,"
REFERENCES,0.7,"≈
1
(∆x)2"
X,0.7034482758620689,"2
X"
X,0.7068965517241379,"i=−2
cipt
x+i,z +
1
(∆z)2"
X,0.7103448275862069,"2
X"
X,0.7137931034482758,"i=−2
cipt
x,z+i"
X,0.7172413793103448,"+ O[(∆x)4 + (∆z)4] , (14)"
X,0.7206896551724138,where c0 = −5
X,0.7241379310344828,"2, c1 = 4"
X,0.7275862068965517,"3, c2 = −1"
X,0.7310344827586207,"12, ci = c−i, and x and z stand for the horizontal offset and the
depth of a 2D velocity map, respectively. For convenience, we assume that the vertical grid spacing
∆z is identical to the horizontal grid spacing ∆x."
X,0.7344827586206897,"Given the approximation in Equations 5 and 14, we can rewrite the Equation 1 as"
X,0.7379310344827587,"pt+1
x,z = (2 −5α)pt
x,z −pt−1
x,z −(∆x)2αst
x,z + α"
X,0.7413793103448276,"2
X"
X,0.7448275862068966,"i=−2
i̸=0"
X,0.7482758620689656,"ci(pt
x+i,z + pt
x,z+i) ,
(15)"
X,0.7517241379310344,where α = ( v∆t
X,0.7551724137931034,∆x )2.
X,0.7586206896551724,"During the simulation of the forward modeling, the boundaries of the velocity maps should be care-
fully handled because they may cause reﬂection artifacts that interfere with the desired waves. One
of the standard methods to reduce the boundary effects is to add absorbing layers around the original
velocity map. Waves are trapped and attenuated by a damping parameter when propagating through
those absorbing layers. Here, we follow Collino & Tsogka (2001) and implement the damping
parameter as"
X,0.7620689655172413,κ = d(u) = 3uv
X,0.7655172413793103,"2L2 ln(R) ,
(16)"
X,0.7689655172413793,"where L denotes the overall thickness of absorbing layers, u indicates the distance between the
current position and the closest boundary of the original velocity map, and R is the theoretical"
X,0.7724137931034483,Published as a conference paper at ICLR 2022
X,0.7758620689655172,"reﬂection coefﬁcient chosen to be 10−7. With absorbing layers added, Equation 6 can be ultimately
written as"
X,0.7793103448275862,"pt+1
x,z = (2 −5α −κ)pt
x,z −(1 −κ)pt−1
x,z −(∆x)2αst
x,z + α"
X,0.7827586206896552,"2
X"
X,0.7862068965517242,"i=−2
i̸=0"
X,0.7896551724137931,"ci(pt
x+i,z + pt
x,z+i) .
(17)"
X,0.7931034482758621,"A.3
OPENFWI EXAMPLES AND INVERSION RESULTS OF DIFFERENT METHODS"
X,0.7965517241379311,Velocity
X,0.8,"Seismic Measurements in Five Channels
Channel 1
Channel 2
Channel 3
Channel 4
Channel 5"
X,0.803448275862069,"Figure 6: More examples of velocity maps and their corresponding seismic measurements in Open-
FWI dataset."
X,0.8068965517241379,Published as a conference paper at ICLR 2022
X,0.8103448275862069,"Ground Truth
InversionNet
VelocityGAN
H-PGNN+
UPFWI-24K
(Ours)"
X,0.8137931034482758,"UPFWI-48K
(Ours)"
X,0.8172413793103448,"Figure 7: Comparison of different methods on inverted velocity maps of FlatFault. The details
revealed by our UPFWI are highlighted."
X,0.8206896551724138,Published as a conference paper at ICLR 2022
X,0.8241379310344827,"Ground Truth
InversionNet
VelocityGAN
H-PGNN+
UPFWI-24K
(Ours)"
X,0.8275862068965517,"UPFWI-48K
(Ours)"
X,0.8310344827586207,"Figure 8: Comparison of different methods on inverted velocity maps of CurvedFault. The details
revealed by our UPFWI are highlighted."
X,0.8344827586206897,Published as a conference paper at ICLR 2022
X,0.8379310344827586,"A.4
ADDITIONAL EXPERIMENT RESULTS
Ground Truth
Ground Truth
Prediction
Prediction"
X,0.8413793103448276,"Figure 9: Results of low-resolution Marmousi Dataset. This dataset contains low-resolution ve-
locity maps generated using style tranfer with the Marmousi velocity map as the style images. Our
UPFWI model yields good results in shallow regions, and it also captures some geological structures
in deeper regions. Similar phenomenon is also observed in the prediction of the smoothed Marmousi
velocity map (bottom-right corner)."
X,0.8448275862068966,"Figure 10: Results of salt bodies dataset. This dataset contains more complicated velocity maps.
Our UPFWI model yields good velocity map prediction (bottom) on both salt bodies and background
geological structures compared to the ground truth (top)."
X,0.8482758620689655,Published as a conference paper at ICLR 2022
X,0.8517241379310345,"Ground Truth
CNN
MLP-Mixer
ViT"
X,0.8551724137931035,"Figure 11: Results of UPFWI with different network architectures. We replace the CNN in our
model with Vision Transformer (ViT) and MLP-Mixer as the encoder and test them on the FlatFault
dataset. Both models yield reasonable velocity maps. This demonstrates that our proposed learning
paradigm is model-agnostic."
X,0.8586206896551725,Published as a conference paper at ICLR 2022
X,0.8620689655172413,Seismic Input
X,0.8655172413793103,Velocity Map
X,0.8689655172413793,Seismic Input
X,0.8724137931034482,Velocity Map
X,0.8758620689655172,"Ground Truth
Clean
PSNR=61.60dB
PSNR=58.70dB
PSNR=51.58dB"
X,0.8793103448275862,"Figure 12: Results of adding Gaussian noise to FlatFault. The model is trained on the clean data
(without noise) and tested on different levels (PSNR) of Gaussian noises. Clearly, our method is
robust to the noise although slight degradation is observed when noise level increases."
X,0.8827586206896552,Seismic Input
X,0.8862068965517241,Velocity Map
X,0.8896551724137931,Seismic Input
X,0.8931034482758621,Velocity Map
X,0.896551724137931,"Ground Truth
Clean
PSNR=61.72dB
PSNR=58.70dB
PSNR=51.68dB"
X,0.9,"Figure 13: Results of adding Gaussian noise to CurvedFault. The model is trained on the clean
data (without noise) and tested on different levels (PSNR) of Gaussian noises. Similar to the results
of FlatFault, our method is robust to the noise although slight degradation is observed when noise
level increases."
X,0.903448275862069,Published as a conference paper at ICLR 2022
X,0.906896551724138,Seismic Input
X,0.9103448275862069,Velocity Map
X,0.9137931034482759,Seismic Input
X,0.9172413793103448,Velocity Map
X,0.9206896551724137,"Ground Truth
Clean
7 Missing
10 Missing
17 Missing"
X,0.9241379310344827,"Figure 14: Results of randomly missing traces on FlatFault. The model is trained on the clean
data (without missing traces) and tested on multiple missing rates from 5% to 25%. Our method is
robust to the missing traces. Although the higher missing rate leads to shifts in velocity values, the
geological structures are well preserved."
X,0.9275862068965517,Seismic Input
X,0.9310344827586207,Velocity Map
X,0.9344827586206896,Seismic Input
X,0.9379310344827586,Velocity Map
X,0.9413793103448276,"Ground Truth
Clean
7 Missing
10 Missing
17 Missing"
X,0.9448275862068966,"Figure 15: Results of randomly missing traces on CurvedFault. The model is trained on the clean
data (without missing traces) and tested on multiple missing rates from 5% to 25%. Similar to the
results of FlatFault, our method is robust to the missing traces. Although the higher missing rate
leads to shifts in velocity values, the geological structures are well preserved."
X,0.9482758620689655,Published as a conference paper at ICLR 2022
X,0.9517241379310345,"Additional experiments to investigate generalization. We conducted two additional experiments:
(1) training our model on the CurvedFault dataset and further testing on the FlatFault dataset (visu-
alization results are listed in Figure 16, and quantitative results are shown in Table 7); (2) testing our
model on time-lapse imaging problems (visualization results are listed in Figure 17). The results
demonstrate that our proposed model yields generalization ability to a certain degree."
X,0.9551724137931035,"Training Dataset
Test Dataset
MAE↓
MSE↓
SSIM↑"
X,0.9586206896551724,"FlatFault
FlatFault
14.60
1146.09
0.9895"
X,0.9620689655172414,"CurvedFault
FlatFault
50.80
17627.65
0.9253"
X,0.9655172413793104,Table 7: Quantitative results of our UPFWI models evaluated on FlatFault.
X,0.9689655172413794,Ground Truth
X,0.9724137931034482,Prediction
X,0.9758620689655172,"Figure 16: Results on generalization across datasets. The test is performed on FlatFault by apply-
ing a UPFWI model that is trained on CurvedFault dataset. Although the artifact is not negligible,
the fault structures and velocity values are well preserved. This demonstrates that our model has
generalizability to a certain degree."
X,0.9793103448275862,Ground Truth
X,0.9827586206896551,Prediction
X,0.9862068965517241,Ground Truth
X,0.9896551724137931,Prediction
X,0.993103448275862,"t = 0
t = 1
t = 2
t = 3"
X,0.996551724137931,"Figure 17: Results on generalizability over geological anomalies. The test is performed on a
dataset where we add additional geological anomalies to simulate time-lapse imaging problems.
The velocity maps containing those anomalies are not included during training. However, our model
captures the spatial and temporal dynamics of anomalies in prediction. This demonstrates that our
model has generalizability to a certain degree."
