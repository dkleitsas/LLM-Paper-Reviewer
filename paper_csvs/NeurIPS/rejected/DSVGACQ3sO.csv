Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0009140767824497258,"Supervised learning approaches for causal discovery from observational data often
1"
ABSTRACT,0.0018281535648994515,"achieve competitive performance despite seemingly avoiding explicit assumptions
2"
ABSTRACT,0.002742230347349177,"that traditional methods make for identifiability. In this work, we investigate CSIvA
3"
ABSTRACT,0.003656307129798903,"[1], a transformer-based model promising to train on synthetic data and transfer
4"
ABSTRACT,0.004570383912248629,"to real data. First, we bridge the gap with existing identifiability theory and show
5"
ABSTRACT,0.005484460694698354,"that constraints on the training data distribution implicitly define a prior on the test
6"
ABSTRACT,0.006398537477148081,"observations. Consistent with classical approaches, good performance is achieved
7"
ABSTRACT,0.007312614259597806,"when we have a good prior on the test data, and the underlying model is identifiable.
8"
ABSTRACT,0.008226691042047532,"At the same time, we find new trade-offs. Training on datasets generated from
9"
ABSTRACT,0.009140767824497258,"different classes of causal models, unambiguously identifiable in isolation,
10"
ABSTRACT,0.010054844606946984,"improves the test generalization. Performance is still guaranteed, as the ambiguous
11"
ABSTRACT,0.010968921389396709,"cases resulting from the mixture of identifiable causal models are unlikely to occur
12"
ABSTRACT,0.011882998171846435,"(which we formally prove). Overall, our study finds that amortized causal discovery
13"
ABSTRACT,0.012797074954296161,"still needs to obey identifiability theory, but it also differs from classical methods
14"
ABSTRACT,0.013711151736745886,"in how the assumptions are formulated, trading more reliance on assumptions on
15"
ABSTRACT,0.014625228519195612,"the noise type for fewer hypotheses on the mechanisms.
16"
INTRODUCTION,0.015539305301645339,"1
Introduction
17"
INTRODUCTION,0.016453382084095063,"Causal discovery aims to uncover the underlying causal relationships between variables of a system
18"
INTRODUCTION,0.01736745886654479,"from pure observations, which is crucial for answering interventional and counterfactual queries when
19"
INTRODUCTION,0.018281535648994516,"experimentation is impractical or unfeasible [2, 3, 4]. Unfortunately, causal discovery is inherently
20"
INTRODUCTION,0.019195612431444242,"ill-posed [5]: unique identification of causal directions requires restrictive assumptions on the class
21"
INTRODUCTION,0.02010968921389397,"of structural causal models (SCMs) that generated the data [6, 7, 8]. These theoretical limitations
22"
INTRODUCTION,0.02102376599634369,"often render existing methods inapplicable, as the underlying assumptions are usually untestable or
23"
INTRODUCTION,0.021937842778793418,"difficult to verify in practice [9].
24"
INTRODUCTION,0.022851919561243144,"Recently, supervised learning algorithms trained on synthetic data have been proposed to overcome
25"
INTRODUCTION,0.02376599634369287,"the need for specific hypotheses, which restrains the application of classical causal discovery methods
26"
INTRODUCTION,0.024680073126142597,"to real-world problems [1, 10, 11, 12, 13]. Seminal work from Lopez-Paz et al. [10] argues that
27"
INTRODUCTION,0.025594149908592323,"this learning-based approach to causal discovery would allow dealing with complex data-generating
28"
INTRODUCTION,0.026508226691042046,"processes and would greatly reduce the need for explicitly crafting identifiability conditions a-priori:
29"
INTRODUCTION,0.027422303473491772,"despite this ambitious goal, the output of these methods is generally considered unreliable, as no
30"
INTRODUCTION,0.0283363802559415,"theoretical guarantee is provided. A pair of non-identifiable structural causal models can be associated
31"
INTRODUCTION,0.029250457038391225,"with different causal graphs G ̸= ˜G, while entailing the same joint distribution p on the system’s
32"
INTRODUCTION,0.03016453382084095,"variables. It is thus unclear how a learning algorithm presented with observational data generated from
33"
INTRODUCTION,0.031078610603290677,"p would be able to overcome these theoretical limits and correctly identify a unique causal structure.
34"
INTRODUCTION,0.031992687385740404,"However, the available empirical evidence seems not to care about impossibility results, as these
35"
INTRODUCTION,0.03290676416819013,"methods yield surprising generalization results on several synthetic benchmarks. Our work aims to
36"
INTRODUCTION,0.033820840950639856,"bridge this gap by studying the performance of a transformer architecture for causal discovery through
37"
INTRODUCTION,0.03473491773308958,"the lens of the theory of identifiability from observational data. Specifically, we analyze the CSIvA
38"
INTRODUCTION,0.0356489945155393,"(Causal Structure Induction via Attention) model for causal discovery [1], focusing on bivariate graphs,
39"
INTRODUCTION,0.03656307129798903,"as they offer a controlled yet non-trivial setting for the investigation. As our starting point, we provide
40"
INTRODUCTION,0.037477148080438755,"closed-form examples that identify the limitations of CSIvA in recovering causal structures of linear
41"
INTRODUCTION,0.038391224862888484,"non-Gaussian and nonlinear additive noise models, which are notably identifiable, and demonstrate the
42"
INTRODUCTION,0.03930530164533821,"expected failures through empirical evidence. These findings suggest that the class of structural causal
43"
INTRODUCTION,0.04021937842778794,"models that can be identified by CSIvA is inherently dependent on the specific class of SCMs observed
44"
INTRODUCTION,0.04113345521023766,"during training. Thus, the need for restrictive hypotheses on the data-generating process is intrinsic
45"
INTRODUCTION,0.04204753199268738,"to causal discovery, both in the traditional and modern learning-based approaches: assumptions on
46"
INTRODUCTION,0.04296160877513711,"the test distribution either are posited when selecting the algorithm (traditional methods) or in the
47"
INTRODUCTION,0.043875685557586835,"choice of the training data (learning-based methods). To address this limitation, we theoretically and
48"
INTRODUCTION,0.044789762340036565,"empirically analyze when training CSIvA on datasets generated by multiple identifiable SCMs with
49"
INTRODUCTION,0.04570383912248629,"different structural assumptions improves its generalization at test time. In summary:
50"
INTRODUCTION,0.04661791590493602,"• We show that the class of structural causal models that CSIvA can identify is defined by the
51"
INTRODUCTION,0.04753199268738574,"class of SCMs observed through samples during the training. We reinforce the notion that
52"
INTRODUCTION,0.048446069469835464,"identifiability in causal discovery inherently requires assumptions, which must be encoded
53"
INTRODUCTION,0.04936014625228519,"in the training data in the case of learning-based approaches.
54"
INTRODUCTION,0.050274223034734916,"• To overcome this limitation, we study the benefits of CSIvA training on mixtures of causal
55"
INTRODUCTION,0.051188299817184646,"models. We analyze when algorithms learned on multiple models are expected to identify
56"
INTRODUCTION,0.05210237659963437,"broad classes of SCMs (unlike many classical methods). Empirically, we show that training
57"
INTRODUCTION,0.05301645338208409,"on samples generated by multiple identifiable causal models with different assumptions on
58"
INTRODUCTION,0.05393053016453382,"mechanisms and noise distribution results in significantly improved generalization abilities.
59"
INTRODUCTION,0.054844606946983544,"Closely related works and their relation with CSIvA.
In this paper, we study amortized inference
60"
INTRODUCTION,0.055758683729433274,"of causal graphs, i.e. optimization of an inference model to directly predict a causal structure from
61"
INTRODUCTION,0.056672760511883,"newly provided data. This is the first work that attempts to understand the connection between
62"
INTRODUCTION,0.05758683729433273,"identifiability theory and amortized inference, while several algorithms have been proposed. In the
63"
INTRODUCTION,0.05850091407678245,"context of purely observational data, Lopez-Paz et al. [10] defines a distribution regression problem
64"
INTRODUCTION,0.05941499085923217,"[14] mapping the kernel mean embedding of the data distribution to a causal graph, while Li et al.
65"
INTRODUCTION,0.0603290676416819,"[11] relies on equivariant neural network architectures. More recently, Lippe et al. [12] and Lorch
66"
INTRODUCTION,0.061243144424131625,"et al. [13] proposed learning on interventional data, in addition to observations (in the same spirit as
67"
INTRODUCTION,0.062157221206581355,"CSIvA). Despite different algorithmic implementations, the target object of estimation of most of
68"
INTRODUCTION,0.06307129798903108,"these methods is the distribution over the space of all possible graphs, conditional on the input dataset
69"
INTRODUCTION,0.06398537477148081,"(similarly, the ENCO algorithm in Lippe et al. [12] models the conditional distribution of individual
70"
INTRODUCTION,0.06489945155393052,"edges). This justifies our choice of restricting our study to the CSIvA architecture (despite this
71"
INTRODUCTION,0.06581352833638025,"being a clear limitation), as in the infinite observational sample limit, these methods approximate the
72"
INTRODUCTION,0.06672760511882998,"same distribution. Methods necessarily requiring interventional data [15, 16, 17], and learning-based
73"
INTRODUCTION,0.06764168190127971,"algorithms unsuitable for amortized inference [18, 19, 20, 21, 22] are out of the scope of this work.
74"
BACKGROUND AND MOTIVATION,0.06855575868372943,"2
Background and motivation
75"
BACKGROUND AND MOTIVATION,0.06946983546617916,"We start introducing structural causal models (SCMs), an intuitive framework that formalizes causal
76"
BACKGROUND AND MOTIVATION,0.07038391224862889,"relations. Let X be a set of random variables in R defined according to the set of structural equations:
77"
BACKGROUND AND MOTIVATION,0.0712979890310786,"Xi := fi(XPAG
i , Ni), ∀i = 1, . . . , k.
(1)"
BACKGROUND AND MOTIVATION,0.07221206581352833,"Ni ∈R are noise random variables. The function fi is the causal mechanism mapping the set of direct
78"
BACKGROUND AND MOTIVATION,0.07312614259597806,"causes XPAG
i of Xi and the noise term Ni, to Xi’s value. The causal graph G is a directed acyclic
79"
BACKGROUND AND MOTIVATION,0.0740402193784278,"graph (DAG) with nodes X = {X1, . . . , Xk}, and edges {Xj →Xi : Xj ∈XPAG
i }, with PAG
i
80"
BACKGROUND AND MOTIVATION,0.07495429616087751,"indices of the parent nodes of Xi in G. The causal model induces a density pX over the vector X.
81"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.07586837294332724,"2.1
Causal discovery from observational data
82"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.07678244972577697,"Causal discovery from observational data is the inference of the causal graph G from a dataset
83"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.07769652650822668,"of i.i.d. observations of the random vector X. In general, without restrictive assumptions on the
84"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.07861060329067641,"mechanisms and the noise distributions, the direction of edges in the graph G is not identifiable, i.e.
85"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.07952468007312614,"it can not be found from the population density pX. In particular, it is possible to identify only a
86"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.08043875685557587,"Markov equivalence class, which is the set of graphs encoding the same conditional independencies
87"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.08135283363802559,"as the density pX. To clarify with an example, consider the causal graph X1 →X2 associated
88"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.08226691042047532,"with a structural causal model inducing a density pX1,X2. If the model is not identifiable, there
89"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.08318098720292505,"exists an SCM with causal graph X2 →X1 that entails the same joint density pX1,X2. The set
90"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.08409506398537477,"{X1 →X2, X2 →X1} is the Markov equivalence class of the graph X1 →X2, i.e. the set of all
91"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.0850091407678245,"graphs with X1, X2 mutually dependent. Clearly, in this setting, even the exact knowledge of pX1,X2
92"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.08592321755027423,"cannot inform us about the correct causal direction.
93"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.08683729433272395,"Definition 1 (Identifiable causal model). Consider a structural causal model with underlying graph G
94"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.08775137111517367,"and pX joint density of the causal variables. We say that the model is identifiable from observational
95"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.0886654478976234,"data if the density pX can not be entailed by a structural causal model with graph ˜G ̸= G.
96"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.08957952468007313,"We define the post-additive noise model (post-ANM) as the causal model with the set of equations:
97"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.09049360146252285,"Xi := f2,i(f1,i(XPAG
i ) + Ni), ∀i = 1, . . . , d,
(2)"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.09140767824497258,"with f2,i invertible map and mutually independent noise terms. When f2,i is a nonlinear function,
98"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.0923217550274223,"the post-ANM amounts to the identifiable post-nonlinear model (PNL) [8]. When f2,i is the identity
99"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.09323583180987204,"function and f1,i nonlinear, it simplifies to the nonlinear additive noise model (ANM)[7, 23], which
100"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.09414990859232175,"is known to be identifiable, and is described by the set of structural equations:
101"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.09506398537477148,"Xi := f1,i(XPAG
i ) + Ni.
(3)"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.09597806215722121,"If, additionally, we restrict the mechanisms f1,i to be linear and the noise terms Ni to a non-Gaussian
102"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.09689213893967093,"distribution, we recover the identifiable linear non-Gaussian additive model or LiNGAM [6]:
103"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.09780621572212066,"Xi =
X"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.09872029250457039,"j∈PAG
i"
CAUSAL DISCOVERY FROM OBSERVATIONAL DATA,0.09963436928702012,"αjXj + Ni,
αj ∈R.
(4)"
MOTIVATION AND PROBLEM DEFINITION,0.10054844606946983,"2.2
Motivation and problem definition
104"
MOTIVATION AND PROBLEM DEFINITION,0.10146252285191956,"Causal discovery from observational data relies on specific assumptions, which can be challenging to
105"
MOTIVATION AND PROBLEM DEFINITION,0.10237659963436929,"verify in practice [9]. To address this, recent methods leverage supervised learning for the amortized
106"
MOTIVATION AND PROBLEM DEFINITION,0.10329067641681901,"inference of causal graphs [1, 10, 11, 12, 13, 16, 24], optimizing an inference model to directly
107"
MOTIVATION AND PROBLEM DEFINITION,0.10420475319926874,"predict a causal structure from a provided dataset. While these approaches aim to reduce reliance on
108"
MOTIVATION AND PROBLEM DEFINITION,0.10511882998171847,"explicit identifiability assumptions, they often lack a clear connection to the existing causal discovery
109"
MOTIVATION AND PROBLEM DEFINITION,0.10603290676416818,"theory, making their outputs generally unreliable. We illustrate this limitation through an example.
110"
MOTIVATION AND PROBLEM DEFINITION,0.10694698354661791,"Example 1. We consider the CSIvA transformer architecture proposed by Ke et al. [1], which can
111"
MOTIVATION AND PROBLEM DEFINITION,0.10786106032906764,"learn a map from observational data to a causal graph. The authors of the paper show that, in the in-
112"
MOTIVATION AND PROBLEM DEFINITION,0.10877513711151737,"finite sample regime, the CSIvA architecture exactly approximates the conditional distribution p(·|D)
113"
MOTIVATION AND PROBLEM DEFINITION,0.10968921389396709,"over the space of possible graphs, given a dataset D. Identifiability theory in causal discovery tells us
114"
MOTIVATION AND PROBLEM DEFINITION,0.11060329067641682,"that if the class of structural causal models that generated the observations is sufficiently constrained,
115"
MOTIVATION AND PROBLEM DEFINITION,0.11151736745886655,"then there is only one graph that can fit the data within that class. For example, consider the case
116"
MOTIVATION AND PROBLEM DEFINITION,0.11243144424131626,"of a dataset that is known to be generated by a nonlinear additive noise model, and let p(·|D, ANM)
117"
MOTIVATION AND PROBLEM DEFINITION,0.113345521023766,"be the conditional distribution that incorporates this prior knowledge on the SCM: then p(·|D, ANM)
118"
MOTIVATION AND PROBLEM DEFINITION,0.11425959780621572,"concentrates all the mass on a single point G∗, the true graph underlying the D observations. Instead,
119"
MOTIVATION AND PROBLEM DEFINITION,0.11517367458866545,"in the absence of restrictions on the structural causal model, all the graphs in a Markov equivalence
120"
MOTIVATION AND PROBLEM DEFINITION,0.11608775137111517,"class are equally likely to be the correct solution given the data. Hence, p(·|D), the distribution
121"
MOTIVATION AND PROBLEM DEFINITION,0.1170018281535649,"learned by CSIvA, assigns equal probability to each graph in the Markov equivalence class of G∗.
122"
MOTIVATION AND PROBLEM DEFINITION,0.11791590493601463,"Our arguments of Example 1 are valid for all learning methods that approximate the conditional
123"
MOTIVATION AND PROBLEM DEFINITION,0.11882998171846434,"distribution over the space of graphs given the input data [1, 10, 11, 12, 13], and suggest that these
124"
MOTIVATION AND PROBLEM DEFINITION,0.11974405850091407,"algorithms are at most informative about the equivalence class of the causal graph underlying the
125"
MOTIVATION AND PROBLEM DEFINITION,0.1206581352833638,"observations. However, the available empirical evidence does not seem to highlight these limitations,
126"
MOTIVATION AND PROBLEM DEFINITION,0.12157221206581353,"as in practice these methods can infer the true causal DAG on several synthetic benchmarks. Thus, fur-
127"
MOTIVATION AND PROBLEM DEFINITION,0.12248628884826325,"ther investigation is necessary if we want to rely on their output in any meaningful sense. In this work,
128"
MOTIVATION AND PROBLEM DEFINITION,0.12340036563071298,"we analyze these ""black-box"" approaches through the lens of established theory of causal discovery
129"
MOTIVATION AND PROBLEM DEFINITION,0.12431444241316271,"from observational data (causal inference often lacks experimental data, which we do not consider).
130"
MOTIVATION AND PROBLEM DEFINITION,0.12522851919561243,"We study in detail the CSIvA architecture [1] (see Appendix A), a variation of the transformer neural
131"
MOTIVATION AND PROBLEM DEFINITION,0.12614259597806216,"network [25] for the supervised learning of algorithms for amortized causal discovery. This model is
132"
MOTIVATION AND PROBLEM DEFINITION,0.12705667276051189,"optimized via maximum likelihood estimation, i.e. finding Θ that minimizes −EG,D[ln ˆp(G|D; Θ)],
133"
MOTIVATION AND PROBLEM DEFINITION,0.12797074954296161,"where ˆp(G|D; Θ) is the conditional distribution of a graph G given a dataset D parametrized by Θ.
134"
MOTIVATION AND PROBLEM DEFINITION,0.12888482632541134,"We limit the analysis to CSIvA as it is a simple yet competitive end-to-end approach to learning causal
135"
MOTIVATION AND PROBLEM DEFINITION,0.12979890310786105,"models. While this is clearly a limitation of the paper, our theoretical and empirical conclusions
136"
MOTIVATION AND PROBLEM DEFINITION,0.13071297989031078,"exemplify both the role of theoretical identifiability in modern approaches and the new opportunities
137"
MOTIVATION AND PROBLEM DEFINITION,0.1316270566727605,"they provide. Additionally, it fits well within a line of works arguing that specifically transformers
138"
MOTIVATION AND PROBLEM DEFINITION,0.13254113345521024,"can learn causal concepts [26, 27, 28] and identify different assumptions in context [29].
139"
EXPERIMENTAL RESULTS THROUGH THE LENS OF THEORY,0.13345521023765997,"3
Experimental results through the lens of theory
140"
EXPERIMENTAL RESULTS THROUGH THE LENS OF THEORY,0.1343692870201097,"In this section, we present a comprehensive analysis of causal discovery with transformers and its
141"
EXPERIMENTAL RESULTS THROUGH THE LENS OF THEORY,0.13528336380255943,"relation to the theoretical boundaries of causal discovery from observational data. We show that
142"
EXPERIMENTAL RESULTS THROUGH THE LENS OF THEORY,0.13619744058500913,"suitable assumptions must be encoded in the training distribution to ensure the identifiability of the
143"
EXPERIMENTAL RESULTS THROUGH THE LENS OF THEORY,0.13711151736745886,"test data, and we additionally study the effectiveness of training on mixtures of causal models to
144"
EXPERIMENTAL RESULTS THROUGH THE LENS OF THEORY,0.1380255941499086,"overcome these limitations, improving generalization abilities.
145"
EXPERIMENTAL DESIGN,0.13893967093235832,"3.1
Experimental design
146"
EXPERIMENTAL DESIGN,0.13985374771480805,"We concentrate our research on causal models of two variables, causally related according to one of the
147"
EXPERIMENTAL DESIGN,0.14076782449725778,"two graphs X →Y , Y →X. Bivariate models are the simplest non-trivial setting with a well-known
148"
EXPERIMENTAL DESIGN,0.1416819012797075,"theory of causality inference [7, 8, 23], but also amenable to manipulation. This allows for compre-
149"
EXPERIMENTAL DESIGN,0.1425959780621572,"hensive training and analysis of diverse SCMs and facilitates a clear interpretation of the results.
150"
EXPERIMENTAL DESIGN,0.14351005484460694,"Datasets.
Unless otherwise specified, in our experiments we train CSIvA on a sample of 15000
151"
EXPERIMENTAL DESIGN,0.14442413162705667,"synthetically generated datasets, consisting of 1500 i.i.d. observations. Each dataset is generated ac-
152"
EXPERIMENTAL DESIGN,0.1453382084095064,"cording to a single class of SCMs, defined by the mechanism type and the noise terms distribution. The
153"
EXPERIMENTAL DESIGN,0.14625228519195613,"coefficients of the linear mechanisms are sampled in the range [−3, −0.5]∪[0.5, 3], removing small co-
154"
EXPERIMENTAL DESIGN,0.14716636197440586,"efficients to avoid close-to-unfaithful effects [30]. Nonlinear mechanisms are parametrized according
155"
EXPERIMENTAL DESIGN,0.1480804387568556,"to a neural network with random weights, a strategy commonly adopted in the literature of causal dis-
156"
EXPERIMENTAL DESIGN,0.1489945155393053,"covery [1, 9]. The post-nonlinearity of the PNL model consists of a simple map z 7→z3. Noise terms
157"
EXPERIMENTAL DESIGN,0.14990859232175502,"are sampled from common distributions and a randomly generated density that we call mlp, previously
158"
EXPERIMENTAL DESIGN,0.15082266910420475,"adopted in Montagna et al. [9], defined by a standard Gaussian transformed by a multilayer perceptron
159"
EXPERIMENTAL DESIGN,0.15173674588665448,"(MLP) (Appendix B.2). We name these datasets mechanism-noise to refer to their underlying causal
160"
EXPERIMENTAL DESIGN,0.1526508226691042,"model. For example, data sampled from a nonlinear ANM with Gaussian noise are named nonlinear-
161"
EXPERIMENTAL DESIGN,0.15356489945155394,"gaussian. More details on the synthetic data generation schema are found in Appendix B.2. All data
162"
EXPERIMENTAL DESIGN,0.15447897623400367,"are standardized by their empirical variance to remove opportunities to learn shortcuts [31, 32, 33].
163"
EXPERIMENTAL DESIGN,0.15539305301645337,"Metric and random baseline.
As our metric we use the structural Hamming distance (SHD), which
164"
EXPERIMENTAL DESIGN,0.1563071297989031,"is the number of edge removals, insertions or flips to transform one graph to another. In the context
165"
EXPERIMENTAL DESIGN,0.15722120658135283,"of bivariate causal graphs with a single edge, this is simply an error count, so correct inference corre-
166"
EXPERIMENTAL DESIGN,0.15813528336380256,"sponds to SHD = 0, and an incorrect prediction gives SHD = 1. Additionally, we define a reference
167"
EXPERIMENTAL DESIGN,0.1590493601462523,"random baseline, which assigns a causal direction according to a fair coin, achieving SHD = 0.5 in ex-
168"
EXPERIMENTAL DESIGN,0.15996343692870202,"pectation. Each architecture we analyze in the experiments is trained 3 times, with different parameter
169"
EXPERIMENTAL DESIGN,0.16087751371115175,"initialization and training samples: the SHD presented in the plots is the average of each of the 3 mod-
170"
EXPERIMENTAL DESIGN,0.16179159049360145,"els on 1500 distinct test datasets of 1500 points each, and the error bars are 95% confidence intervals.
171"
EXPERIMENTAL DESIGN,0.16270566727605118,"We detail the training hyperparameters in Appendix B.1. Next, we analyze our experimental results,
172"
EXPERIMENTAL DESIGN,0.1636197440585009,"starting by investigating how well CSIvA generalizes on distributions unseen during training.
173"
EXPERIMENTAL DESIGN,0.16453382084095064,"3.2
Warm up: is CSIvA capable of in and out-of-distribution generalization?
174"
EXPERIMENTAL DESIGN,0.16544789762340037,"In-distribution generalization.
First, we investigate the generalization of CSIvA on datasets
175"
EXPERIMENTAL DESIGN,0.1663619744058501,"sampled from the structural casual model that generates the train distribution, with mechanisms and
176"
EXPERIMENTAL DESIGN,0.16727605118829983,"noise distributions fixed between training and testing. We call this in-distribution generalization. As
177"
EXPERIMENTAL DESIGN,0.16819012797074953,"a benchmark, we present the performance of several state-of-the-art approaches from the literature
178"
EXPERIMENTAL DESIGN,0.16910420475319926,"on causal discovery: we consider the DirectLiNGAM, and NoGAM algorithms [34, 35], respectively
179"
EXPERIMENTAL DESIGN,0.170018281535649,"designed for the inference on LiNGAM and nonlinear ANM generated data1. The results of Figure 1
180"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.17093235831809872,"1The causal-learn implementation of the PNL algorithm could not perform better than random on our
synthetic post-nonlinear data, and we observed that this was due to the sensitivity of the algorithm to the variance"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.17184643510054845,"CSIvA
benchmark"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.17276051188299818,"0.0
0.2
0.4
SHD beta exp gamma"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.1736745886654479,gumbel mlp
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.1745886654478976,uniform
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.17550274223034734,Noise distributions
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.17641681901279707,(a) Linear
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.1773308957952468,"0.0
0.2
0.4
SHD"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.17824497257769653,(b) Nonlinear
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.17915904936014626,"0.0
0.2
0.4
SHD"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.180073126142596,(c) PNL1
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.1809872029250457,"Figure 1: In-distribution generalization of CSIvA trained and tested on data generated according to the same
structural causal models, fixing mechanisms, and noise distributions between training and testing). As baselines
for comparison, we use DirectLiNGAM on linear SCMs and NoGAM on nonlinear ANM (we use their causal-
learn and dodiscover implementations). CSIvA performance is clearly non-trivial and generalizing well."
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.18190127970749542,"show that CSIvA can properly generalize to unseen samples from the training distribution: the majority
181"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.18281535648994515,"of the trained models present SHD close to zero and comparable to the relative benchmark algorithm.
182"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.18372943327239488,"Out-of-distribution generalization.
In practice, we generally do not know the SCM defining the
183"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.1846435100548446,"test distribution, so we are interested in CSIvA’s ability to generalize to data sampled from a class
184"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.18555758683729434,"of causal models that is unobserved during training. We call this out-of-distribution generalization
185"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.18647166361974407,"(OOD). We study OOD generalization to different noise terms, analyzing the network performance
186"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.18738574040219377,"on datasets generated from causal models where the mechanisms are fixed with respect to the
187"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.1882998171846435,"training, while the noise distribution varies (e.g., given linear-mlp training samples, testing occurs
188"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.18921389396709323,"on linear-uniform data). Orthogonally to these experiments, we empirically validate CSIvA’s OOD
189"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.19012797074954296,"generalization over different mechanism types (linear, nonlinear, post-nonlinear), while leaving the
190"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.1910420475319927,"noise distribution (mlp) fixed across test and training. In Figure 2a, we observe that CSIvA cannot
191"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.19195612431444242,"generalize across the different mechanisms, as the SHD of a network tested on unseen causal mech-
192"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.19287020109689215,"anisms approximates that of the random baseline. Further, Figure 2b shows that out-of-distribution
193"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.19378427787934185,"generalization across noise terms does not work reliably, and it is hard to predict when it might occur.
194"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.19469835466179158,"Implications.
CSIvA generalizes well to test data generated by the same class of SCMs used
195"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.1956124314442413,"for training, in line with the findings in Ke et al. [1], which validates our implementation and
196"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.19652650822669104,"training procedure. However, it struggles when the test data are out-of-distribution, not generated
197"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.19744058500914077,"by causal models with the same mechanisms and noise terms it was trained on. While training on
198"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.1983546617915905,"a wider class of SCMs might overcome this limitation, it requires caution. The identifiability of
199"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.19926873857404023,"causal graphs indeed results from the interplay between the data-generating mechanisms and noise
200"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.20018281535648993,"distribution. However, as we argue in our Example 1, the class of causal models that a supervised
201"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.20109689213893966,"learning algorithm can identify is generally not clear. In what follows, we investigate this point and
202"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2020109689213894,"its implications for CSIvA, showing that the identifiability of the test samples can be ensured by
203"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.20292504570383912,"imposing suitable assumptions on the class of SCMs generating the training distribution.
204"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.20383912248628885,"3.3
How does CSIvA relate to identifiability theory for causal graphs?
205"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.20475319926873858,"The CSIvA algorithm does not make structural assumptions about the causal model underlying the
206"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2056672760511883,"input data. This implies that the output of this method is unclear: as CSIvA targets the conditional dis-
207"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.20658135283363802,"tribution p(·|D) over the space of graphs, in the absence of restrictions on the functional mechanisms
208"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.20749542961608775,"scale. So we report the plot of Figure 1c without benchmark comparison. We remark that the point of this
experiment is not to make any claims on CSIvA being state-of-the-art but to validate that the performance we
obtain in our re-implementation is non-trivial. This is clear for PNL, even without comparison."
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.20840950639853748,"linear nonlinear
pnl
Training dataset 0.0 0.2 0.4 0.6 SHD"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2093235831809872,"linear
nonlinear
pnl"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.21023765996343693,(a) Mechanisms
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.21115173674588666,"linear
nonlinear
pnl
Training dataset 0.0 0.2 0.4 0.6 0.8 SHD"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.21206581352833637,"beta
gamma"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2129798903107861,"gumbel
exp"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.21389396709323583,"mlp
uniform"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.21480804387568556,(b) Noise distributions
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.21572212065813529,"Figure 2: Out-of-distribution generalisation. We train three CSIvA models on data sampled from SCMs with
linear, nonlinear additive, and post-nonlinear mechanisms; and noise fixed mlp noise distribution. In Figure
(a) we test across different noise distributions, with test mechanisms fixed from training. In Figure (b) we test
each network on different mechanisms and fixed mlp noise. CSIvA struggles to generalize to unseen causal
mechanisms and often displays degraded performance over new noise distributions."
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.21663619744058502,"and the distribution of the noise terms, the causal graph X →Y is indistinguishable from Y →X,
209"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.21755027422303475,"as they are both equally likely to underlie the joint density pX,Y generating the data. As we discuss in
210"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.21846435100548445,"Example 1, the graphical output of the trained architecture could at most identify the equivalence class
211"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.21937842778793418,"of the true causal graph. Yet, our experiments of Section 3.2 show that CSIvA is capable of good in-
212"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2202925045703839,"distribution generalization, often inferring the correct DAG at test time. We explain this seeming con-
213"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.22120658135283364,"tradiction with the following hypothesis, which motivates the analysis in the remainder of this section.
214"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.22212065813528337,"Hypothesis 1. The class of structural causal models that can be identified by CSIvA is defined by the
215"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2230347349177331,"class of structural causal models underlying the generation of the training data.
216"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.22394881170018283,"To support and clarify our statement, we present the following example, adapted from Hoyer et al. [7].
217"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.22486288848263253,"Example 2. Consider the causal model Y = f(X) + N, where f(X) = −X and pX, pN are
218"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.22577696526508226,"Gumbel densities pX(x) = exp(−x −exp(−x)) and pN(n) = exp(−n −exp(−n)). This model
219"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.226691042047532,"satisfies the assumptions of the LiNGAM, so it is identifiable, in the sense that a backward linear
220"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.22760511882998172,"model with the same distribution does not exist. However, in this special case, we can build a
221"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.22851919561243145,"backward nonlinear additive noise model X = g(Y ) + ˜N with independent noise terms: taking
222"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.22943327239488118,"pY (y) = exp(−y −2 log(1 + exp(−y))) to be the density of a logistic distribution, p ˜
N(˜n) =
223"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2303473491773309,"exp(−2˜n −exp(−˜n)) and g(y) = log(1 + exp(−y)); we see that pX,Y can factorize according
224"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2312614259597806,"to two opposite causal directions, as pX,Y (x, y) = pN(y −f(x))pX(x) = p ˜
N(x −g(y))pY (y).
225"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.23217550274223034,"Given a dataset D of observations from the forward linear model, causal discovery methods like
226"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.23308957952468007,"DirectLiNGAM [34] can provably identify the correct causal direction X →Y , assuming that
227"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2340036563071298,"sufficient samples are provided. Instead, the behavior of CSIvA seems hard to predict: given that
228"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.23491773308957953,"the network approximates the conditional distribution p(·|D) over the possible graphs, for D with
229"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.23583180987202926,"arbitrary many samples we have p(X →Y |D) = p(Y →X|D) = 0.5. On the other hand, given
230"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.236745886654479,"the prior knowledge that the data-generating SCM is a linear non-gaussian additive noise model, we
231"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2376599634369287,"have p(X →Y |D, LiNGAM) = 1, because the LiNGAM is identifiable. In this sense, the class
232"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.23857404021937842,"of structural causal models that CSIvA correctly infers appears to be determined by the structural
233"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.23948811700182815,"causal models underlying the generation of the training data. Under our Hypothesis 1, training CSIvA
234"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.24040219378427788,"exclusively on LiNGAM-generated data is equivalent to learning the distribution p(·|D, LiNGAM),
235"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2413162705667276,"such that the network should be able to identify the forward linear model, whereas it could only infer
236"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.24223034734917734,"the equivalence class of the causal graph if its training datasets include observations from a nonlinear
237"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.24314442413162707,"additive noise model.
238"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.24405850091407677,"The empirical results of Figure 3a show that CSIvA behaves according to our hypothesis: when
239"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2449725776965265,"training exclusively occurs on datasets {Di,→}i generated by the forward linear-gumbel model of
240"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.24588665447897623,"Example 2, the network can identify the causal direction of test data generated according to the same
241"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.24680073126142596,"SCM. Similarly, the transformer trained on datasets {Di,←}i from the backward nonlinear model
242"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2477148080438757,"of the example can generalize to test data coming from the same distribution. According to our claim,
243"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.24862888482632542,"instead, the network that is trained on the union of the training samples {Di,→}i ∪{Di,←}i from
244"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.24954296160877515,"the forward and backward models (50:50 ratio in Figure 3a) displays the same test SHD (around
245"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.25045703839122485,"0.5) as a random classifier assigning the causal direction with equal probability.
246"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2513711151736746,"0:100
33:67
50:50
67:33
100:0
Ratio of linear:nonlinear training datasets 0.00 0.25 0.50 0.75 SHD"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2522851919561243,"linear invertible
nonlinear invertible"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.253199268738574,(a) Invertible data
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.25411334552102377,"100:0
50:50
0:100
Ratio of linear:nonlinear training datasets 0 0.25 0.5 SHD"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.25502742230347347,"validation
test (linear gauss)"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.25594149908592323,(b) Linear Gaussian test data
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.25685557586837293,"Figure 3: Experiments on identifiability theory. In Figure (a) we test the performance on linear-Gaussian data.
Models are trained with different ratios of samples from linear and nonlinear SCMs with Gaussian noise terms.
The validation results showcase that the networks were trained successfully. Figure (b) shows the SHD of models
trained on different ratios of linear and nonlinear invertible data of Example 2. CSIvA behaves according to
identifiability theory, failing to predict on linear Gaussian models and invertible data (50:50 ratio)."
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2577696526508227,"Further, we investigate CSIvA’s relation with known identifiability theory by training and testing the
247"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2586837294332724,"architecture on data from a linear Gaussian model, which is well-known to be unidentifiable. Not
248"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2595978062157221,"surprisingly, the results of Figure 3b show that none of the algorithms that we learn can infer the
249"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.26051188299817185,"causal order of linear Gaussian models with test SHD any better than a random baseline.
250"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.26142595978062155,"Implications.
Our experiments show that CSIvA learns algorithms that closely follow identifiability
251"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2623400365630713,"theory for causal discovery. In particular, while the method itself does not require explicit assumptions
252"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.263254113345521,"on the data-generating process, the chosen training data ultimately determines the class of causal
253"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.26416819012797077,"models identifiable during inference. Notably, previous work has argued that supervised learning
254"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.26508226691042047,"approaches in causal discovery would help with ""dealing with complex data-generating processes and
255"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2659963436928702,"greatly reduce the need of explicitly crafting identifiability conditions a-priori"", Lopez-Paz et al. [10].
256"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.26691042047531993,"In the case of CSIvA, this expectation does not appear to be fulfilled, as the assumptions still need
257"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.26782449725776963,"to be encoded explicitly in the training data. However, this observation opens two new important
258"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2687385740402194,"questions: (1) Can we train a single network to encompass multiple (or even all) identifiable causal
259"
THE CAUSAL-LEARN IMPLEMENTATION OF THE PNL ALGORITHM COULD NOT PERFORM BETTER THAN RANDOM ON OUR,0.2696526508226691,"structures? (2) How much ambiguity might exist between these identifiable models?
260"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.27056672760511885,"3.4
A low-dimensions argument in favor of learning from multiple causal models
261"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.27148080438756855,"Example 2 of the previous section shows that elements of distinct classes of identifiable structural
262"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.27239488117001825,"causal models, such as LiNGAM and nonlinear ANM, may become non-identifiable when we
263"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.273308957952468,"consider their union. In this section, we show that in the class of post-additive noise models given
264"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.2742230347349177,"by equation (2) (obtained as the union of the LiNGAM, the nonlinear ANM, and the post-nonlinear
265"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.27513711151736747,"model), the set of distributions that is non-identifiable is negligible. Our proposition extends the
266"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.2760511882998172,"results of Hoyer et al. [7], which are limited to the case of linear and nonlinear additive noise models,
267"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.27696526508226693,"and Zhang and Hyvärinen [8], which provides the conditions of identifiability of the post-ANM
268"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.27787934186471663,"without bounding the set of non-identifiable distributions.
269"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.27879341864716634,"Let X, Y be a pair of random variables generated according to the causal direction X →Y and the
270"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.2797074954296161,"post-additive noise model structural equation:
271"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.2806215722120658,"Y = f2(f1(X) + NY ),
(5)"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.28153564899451555,"where NY and X are independent random variables, and f2 is invertible. If the SCM is non-
272"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.28244972577696525,"identifiable, the data-generating process can be described by a backward model with the structural
273"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.283363802559415,"equation:
274"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.2842778793418647,"X = g2(g1(Y ) + NX),
(6)"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.2851919561243144,"NX independent from Y , and g2 invertible. We introduce the random variables ˜X, ˜Y , such that the
275"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.2861060329067642,"forward and backward equations can be rewritten as
276"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.2870201096892139,"Y = f2( ˜Y ),
˜Y := f1(X) + NY ,"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.28793418647166363,"X = g2( ˜X),
˜X := g1(Y ) + NX."
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.28884826325411334,"mixed
single
in-distribution"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.2897623400365631,"0
0.25
0.5
SHD"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.2906764168190128,"lin, nl"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.2915904936014625,"lin, pnl all nl pnl"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.29250457038391225,Training datasets
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.29341864716636196,(a) Linear test data
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.2943327239488117,"0
0.25
0.5
SHD"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.2952468007312614,"lin, nl"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.2961608775137112,"nl, pnl all pnl lin"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.2970749542961609,(b) Nonlinear test data
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.2979890310786106,"0
0.25
0.5
SHD"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.29890310786106034,"lin, pnl"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.29981718464351004,"nl, pnl all nl lin"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3007312614259598,(c) PNL test data
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3016453382084095,"Figure 4: Mixture of causal mechanisms. We train four models on samples from structural casual models with
different mechanism types. We compare their test SHD (the lower, the better) against networks trained on
datasets generated according to a single type of mechanism. The dashed line indicates the test SHD of a model
trained on samples with the same mechanisms as test SCM. Training on multiple causal models with different
mechanisms (mixed bars) always improves performance compared to training on single SCMs."
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.30255941499085925,"We note that this implies that the following invertible additive noise models on ˜X, ˜Y hold:
277"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.30347349177330896,"˜Y = hY ( ˜X) + NY ,
hY := f1 ◦g2,
(7)
˜X = hX( ˜Y ) + NX,
hX := g1 ◦f2.
(8)"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.30438756855575866,"Proposition 1 (Adapted from Hoyer et al. [7]). Let pNY , hX, hY be fixed, and define νY := log pNY ,
278"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3053016453382084,"ξ := log p ˜
X. Suppose that pNY and p ˜
X are strictly positive densities, and that νY , ξ, f1, f2, g1, and
279"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3062157221206581,"g2 are three times differentiable. Further, assume that for a fixed pair hY , νY exists ˜y ∈R s.t. ν′′
Y (˜y −
280"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3071297989031079,"hY (˜x))h′
Y (˜x) ̸= 0 is satisfied for all but a countable set of points ˜x ∈R. Then, the set of all densities
281"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3080438756855576,"p ˜
X of ˜X such that both equations (5) and (6) are satisfied is contained in a 2-dimensional space.
282"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.30895795246800734,"Implications.
Our result is closely related to Theorem 1 of Hoyer et al. [7], which we simply
283"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.30987202925045704,"generalize to the post-ANM. Intuitively, it says that the space of all continuous distributions such that
284"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.31078610603290674,"the bivariate post-ANM is non-identifiable is contained in a 2-dimensional space. As the space of
285"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3117001828153565,"continuous distributions of random variables is infinite-dimensional, we conclude that the post-ANM
286"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3126142595978062,"is generally identifiable, which suggests that the setting of Example 2 is rather artificial. Our results
287"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.31352833638025596,"provide a theoretical ground for training causal discovery algorithms on datasets generated from
288"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.31444241316270566,"multiple identifiable SCMs. This is particularly appealing in the case of CSIvA, given the poor OOD
289"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3153564899451554,"generalization ability observed in our experiments of Section 3.2.
290"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3162705667276051,"3.5
Can we train CSIvA on multiple causal models for better generalization?
291"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3171846435100548,"In this section, we investigate the benefits of training over multiple causal models, i.e. on samples
292"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3180987202925046,"generated by a combination of classes of identifiable SCMs characterized by different mechanisms
293"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3190127970749543,"and noise terms distribution. Our motivation is as follows: given that our empirical evidence
294"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.31992687385740404,"shows that CSIvA is capable of in-distribution generalization, whereas dramatically degrades the
295"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.32084095063985374,"performance when testing occurs out-of-distribution, it is thus desirable to increase the class of
296"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3217550274223035,"causal models represented in the training datasets. We separately study the effects of training over
297"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3226691042047532,"multiple mechanisms and multiple noise distributions and compare the testing performance against
298"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3235831809872029,"architectures trained on samples of a single SCM.
299"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.32449725776965266,"Mixture of causal mechanisms.
We consider four networks optimized by training of CSIvA on
300"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.32541133455210236,"datasets generated from pairs (or triples) of distinct SCMs, with fixed mlp noise and which differ in
301"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3263254113345521,"terms of their mechanisms type: linear and nonlinear; nonlinear and post-nonlinear; linear and post-
302"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3272394881170018,"nonlinear; linear, nonlinear and post-nonlinear. The number of training datasets for each architecture is
303"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3281535648994516,"fixed (15000) and equally split between the causal models with different mechanism types. The results
304"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3290676416819013,"of Figure 4 show that the networks trained on mixtures of mechanisms all present significantly better
305"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.329981718464351,"test SHD compared to CSIvA models trained on a single mechanism type. We find that learning on
306"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.33089579524680074,"multiple SCMs improves the SHD from ∼0.5 to ∼0.2 both on linear and nonlinear test data (Figures
307"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.33180987202925044,"4a and 4b), and even better accuracy is achieved on post-nonlinear samples, as shown in Figure 4c.
308"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3327239488117002,"all distributions
only mlp"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3336380255941499,"0.00
0.25
0.50
0.75
SHD beta gamma"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.33455210237659966,gumbel exp mlp
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.33546617915904936,uniform
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.33638025594149906,Test noise
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3372943327239488,(a) Linear test data
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3382084095063985,"0.00
0.25
0.50
0.75
SHD"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3391224862888483,(b) Nonlinear test data
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.340036563071298,"0.00
0.25
0.50
0.75
SHD"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.34095063985374774,(c) PNL test data
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.34186471663619744,"Figure 5: Mixture of noise distributions. We train three networks on samples from SCMs with different noise
terms distributions and fixed mechanism types: linear, nonlinear, and post-nonlinear. We present their test SHD
(the lower, the better) on data from SCMs with the mechanisms fixed with respect to training, and noise terms
changing between each dataset. Training on multiple causal models with different noises (all distributions bars)
always improves performance compared to training on single SCMs with fixed mlp noise (only mlp bars)."
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.34277879341864714,"Mixture of noise distributions.
Next, we analyze the test performance of three CSIvA networks
309"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3436928702010969,"optimized on samples from structural causal models that have different distributions for their noise
310"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3446069469835466,"terms, while keeping the mechanism types fixed. Figure 5 shows that training over different noises
311"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.34552102376599636,"(beta, gamma, gumbel, exponential, mlp, uniform) always results in a network that is agnostic with
312"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.34643510054844606,"respect to the noise distributions of the SCM generating the test samples, always achieving SHD < 0.1,
313"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3473491773308958,"with the exception of datasets with mlp error terms (0.2 average SHD on nonlinear and pnl data).
314"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3482632541133455,"Implications.
We have shown that learning on mixtures of SCMs with different noise term dis-
315"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3491773308957952,"tributions and mechanism types leads to models generalizing to a much broader class of structural
316"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.350091407678245,"causal models during testing. Hence, combining datasets generated from multiple models looks
317"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3510054844606947,"like a promising framework to overcome the limited out-of-distribution generalization abilities of
318"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.35191956124314444,"CSIvA observed in Section 3.2. However, it is easier to incorporate prior assumptions on the class of
319"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.35283363802559414,"causal mechanisms (linear, non-linear, post-non-linear) compared to the noise distributions (which are
320"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3537477148080439,"potentially infinite). This introduces a trade-off between amortized inference and classical methods
321"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3546617915904936,"for causal discovery: for example, RESIT, NoGAM, and CAM [23, 35, 36] algorithms require no
322"
A LOW-DIMENSIONS ARGUMENT IN FAVOR OF LEARNING FROM MULTIPLE CAUSAL MODELS,0.3555758683729433,"assumptions on the noise type, but only work for a limited class of mechanisms (nonlinear).
323"
CONCLUSION,0.35648994515539306,"4
Conclusion
324"
CONCLUSION,0.35740402193784276,"In this work, we investigate the interplay between identifiability theory and supervised learning
325"
CONCLUSION,0.3583180987202925,"for amortized inference of causal graphs, using CSIvA as the ground of our study. Consistent
326"
CONCLUSION,0.3592321755027422,"with classical algorithms, we demonstrate that good performance can be achieved if (i) we have
327"
CONCLUSION,0.360146252285192,"a good prior on the structural causal model generating the test data (ii) the setting is identifiable.
328"
CONCLUSION,0.3610603290676417,"In particular, prior knowledge of the test distribution is encoded in the training data in the form
329"
CONCLUSION,0.3619744058500914,"of constraints on the structural causal model underlying their generation. With these results, we
330"
CONCLUSION,0.36288848263254114,"highlight the need for identifiability theory in modern learning-based approaches to causality, while
331"
CONCLUSION,0.36380255941499084,"past works have mostly disregarded this connection. Further, our findings provide the theoretical
332"
CONCLUSION,0.3647166361974406,"ground for training on observations sampled from multiple classes of identifiable SCMs, a strategy
333"
CONCLUSION,0.3656307129798903,"that improves test generalization to a broad class of causal models. Finally, we highlight an interesting
334"
CONCLUSION,0.36654478976234006,"new trade-off regarding identifiability: traditional methods like LiNGAM, RESIT, and PNL require
335"
CONCLUSION,0.36745886654478976,"strong restrictions on the structural mechanisms underlying the data generation (linear, nonlinear
336"
CONCLUSION,0.36837294332723947,"or post-nonlinear) while generally being agnostic relative to the noise terms distribution. Training
337"
CONCLUSION,0.3692870201096892,"on mixtures of causal models instead offers an alternative that is less reliant on assumptions on the
338"
CONCLUSION,0.3702010968921389,"mechanisms, while incorporating knowledge about all possible noise distributions in the training data
339"
CONCLUSION,0.3711151736745887,"is practically impossible to achieve. We leave it to future work to reproduce our analysis on a wider
340"
CONCLUSION,0.3720292504570384,"class of architectures, as well as extending our study to interventional data with more than two nodes.
341"
REFERENCES,0.37294332723948814,"References
342"
REFERENCES,0.37385740402193784,"[1] Nan Rosemary Ke, Silvia Chiappa, Jane X. Wang, Jorg Bornschein, Anirudh Goyal, Melanie
343"
REFERENCES,0.37477148080438755,"Rey, Theophane Weber, Matthew Botvinick, Michael Curtis Mozer, and Danilo Jimenez
344"
REFERENCES,0.3756855575868373,"Rezende. Learning to Induce Causal Structure. In International Conference on Learning Repre-
345"
REFERENCES,0.376599634369287,"sentations, September 2022. URL https://openreview.net/forum?id=hp_RwhKDJ5.
346"
REFERENCES,0.37751371115173676,"[2] Jonas Peters, Dominik Janzing, and Bernhard Schölkopf.
Elements of Causal Inference:
347"
REFERENCES,0.37842778793418647,"Foundations and Learning Algorithms. Adaptive Computation and Machine Learning. The MIT
348"
REFERENCES,0.3793418647166362,"Press, Cambridge, Mass, 2017. ISBN 978-0-262-03731-0.
349"
REFERENCES,0.3802559414990859,"[3] Judea Pearl. Causality. Cambridge University Press, Cambridge, 2nd edition, 2009.
350"
REFERENCES,0.3811700182815356,"[4] Peter Spirtes. Introduction to causal inference. Journal of Machine Learning Research, 11(54):
351"
REFERENCES,0.3820840950639854,"1643–1662, 2010. URL http://jmlr.org/papers/v11/spirtes10a.html.
352"
REFERENCES,0.3829981718464351,"[5] Clark Glymour, Kun Zhang, and Peter Spirtes. Review of causal discovery methods based on
353"
REFERENCES,0.38391224862888484,"graphical models. Frontiers in Genetics, 10, 2019. ISSN 1664-8021. doi: 10.3389/fgene.2019.
354"
REFERENCES,0.38482632541133455,"00524. URL https://www.frontiersin.org/articles/10.3389/fgene.2019.00524.
355"
REFERENCES,0.3857404021937843,"[6] Shohei Shimizu, Patrik O. Hoyer, Aapo Hyvärinen, and Antti Kerminen. A linear non-gaussian
356"
REFERENCES,0.386654478976234,"acyclic model for causal discovery. Journal of Machine Learning Research, 7:2003–2030, dec
357"
REFERENCES,0.3875685557586837,"2006. ISSN 1532-4435.
358"
REFERENCES,0.38848263254113347,"[7] Patrik Hoyer, Dominik Janzing, Joris M Mooij, Jonas Peters, and Bernhard Schölkopf. Non-
359"
REFERENCES,0.38939670932358317,"linear causal discovery with additive noise models. In D. Koller, D. Schuurmans, Y. Bengio,
360"
REFERENCES,0.3903107861060329,"and L. Bottou, editors, Advances in Neural Information Processing Systems, volume 21. Cur-
361"
REFERENCES,0.3912248628884826,"ran Associates, Inc., 2008. URL https://proceedings.neurips.cc/paper/2008/file/
362"
REFERENCES,0.3921389396709324,"f7664060cc52bc6f3d620bcedc94a4b6-Paper.pdf.
363"
REFERENCES,0.3930530164533821,"[8] Kun Zhang and Aapo Hyvärinen. On the identifiability of the post-nonlinear causal model. In
364"
REFERENCES,0.3939670932358318,"Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, UAI ’09,
365"
REFERENCES,0.39488117001828155,"page 647–655, Arlington, Virginia, USA, 2009. AUAI Press. ISBN 9780974903958.
366"
REFERENCES,0.39579524680073125,"[9] Francesco Montagna, Atalanti Mastakouri, Elias Eulig, Nicoletta Noceti, Lorenzo Rosasco,
367"
REFERENCES,0.396709323583181,"Dominik Janzing, Bryon Aragam, and Francesco Locatello.
Assumption violations
368"
REFERENCES,0.3976234003656307,"in causal discovery and the robustness of score matching.
In A. Oh, T. Neumann,
369"
REFERENCES,0.39853747714808047,"A. Globerson, K. Saenko, M. Hardt, and S. Levine, editors, Advances in Neural
370"
REFERENCES,0.39945155393053017,"Information Processing Systems, volume 36, pages 47339–47378. Curran Associates,
371"
REFERENCES,0.40036563071297987,"Inc., 2023. URL https://proceedings.neurips.cc/paper_files/paper/2023/file/
372"
REFERENCES,0.4012797074954296,"93ed74938a54a73b5e4c52bbaf42ca8e-Paper-Conference.pdf.
373"
REFERENCES,0.40219378427787933,"[10] David Lopez-Paz, Krikamol Muandet, Bernhard Schölkopf, and Ilya Tolstikhin. Towards a
374"
REFERENCES,0.4031078610603291,"learning theory of cause-effect inference. In Proceedings of the 32nd International Conference
375"
REFERENCES,0.4040219378427788,"on International Conference on Machine Learning - Volume 37, ICML’15, page 1452–1461.
376"
REFERENCES,0.40493601462522855,"JMLR.org, 2015.
377"
REFERENCES,0.40585009140767825,"[11] Hebi Li, Qi Xiao, and Jin Tian. Supervised Whole DAG Causal Discovery, June 2020.
378"
REFERENCES,0.40676416819012795,"[12] Phillip Lippe, Taco Cohen, and Efstratios Gavves. Efficient neural causal discovery without
379"
REFERENCES,0.4076782449725777,"acyclicity constraints. In International Conference on Learning Representations, 2022. URL
380"
REFERENCES,0.4085923217550274,"https://openreview.net/forum?id=eYciPrLuUhG.
381"
REFERENCES,0.40950639853747717,"[13] Lars Lorch, Scott Sussex, Jonas Rothfuss, Andreas Krause, and Bernhard Schölkopf. Amortized
382"
REFERENCES,0.41042047531992687,"inference for causal structure learning. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and
383"
REFERENCES,0.4113345521023766,"Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022. URL
384"
REFERENCES,0.41224862888482633,"https://openreview.net/forum?id=eV4JI-MMeX.
385"
REFERENCES,0.41316270566727603,"[14] Zoltan Szabo, Bharath Sriperumbudur, Barnabas Poczos, and Arthur Gretton. Learning theory
386"
REFERENCES,0.4140767824497258,"for distribution regression. Journal of Machine Learning Research, 17:1–40, 09 2016.
387"
REFERENCES,0.4149908592321755,"[15] Philippe Brouillard, Sébastien Lachapelle, Alexandre Lacoste, Simon Lacoste-Julien,
388"
REFERENCES,0.41590493601462525,"and Alexandre Drouin.
Differentiable causal discovery from interventional data.
In
389"
REFERENCES,0.41681901279707495,"H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin, editors, Advances in Neu-
390"
REFERENCES,0.41773308957952465,"ral Information Processing Systems, volume 33, pages 21865–21877. Curran Associates,
391"
REFERENCES,0.4186471663619744,"Inc., 2020. URL https://proceedings.neurips.cc/paper_files/paper/2020/file/
392"
REFERENCES,0.4195612431444241,"f8b7aa3a0d349d9562b424160ad18612-Paper.pdf.
393"
REFERENCES,0.42047531992687387,"[16] Nan Rosemary Ke, Olexa Bilaniuk, Anirudh Goyal, Stefan Bauer, Hugo Larochelle, Bernhard
394"
REFERENCES,0.42138939670932357,"Schölkopf, Michael Curtis Mozer, Christopher Pal, and Yoshua Bengio. Neural causal structure
395"
REFERENCES,0.42230347349177333,"discovery from interventions. Transactions on Machine Learning Research, 2023. ISSN
396"
REFERENCES,0.42321755027422303,"2835-8856. URL https://openreview.net/forum?id=rdHVPPVuXa. Expert Certification.
397"
REFERENCES,0.42413162705667273,"[17] Nino Scherrer, Olexa Bilaniuk, Yashas Annadani, Anirudh Goyal, Patrick Schwab, Bernhard
398"
REFERENCES,0.4250457038391225,"Schölkopf, Michael C. Mozer, Yoshua Bengio, Stefan Bauer, and Nan Rosemary Ke. Learning
399"
REFERENCES,0.4259597806215722,"neural causal models with active interventions, 2022.
400"
REFERENCES,0.42687385740402195,"[18] Sébastien Lachapelle, Philippe Brouillard, Tristan Deleu, and Simon Lacoste-Julien. Gradient-
401"
REFERENCES,0.42778793418647165,"based neural dag learning. In International Conference on Learning Representations, 2020.
402"
REFERENCES,0.4287020109689214,"URL https://openreview.net/forum?id=rklbKA4YDS.
403"
REFERENCES,0.4296160877513711,"[19] Ignavier Ng, AmirEmad Ghassami, and Kun Zhang. On the role of sparsity and dag constraints
404"
REFERENCES,0.4305301645338208,"for learning linear dags. In Proceedings of the 34th International Conference on Neural
405"
REFERENCES,0.43144424131627057,"Information Processing Systems, NIPS ’20, Red Hook, NY, USA, 2020. Curran Associates Inc.
406"
REFERENCES,0.4323583180987203,"ISBN 9781713829546.
407"
REFERENCES,0.43327239488117003,"[20] Xun Zheng, Bryon Aragam, Pradeep Ravikumar, and Eric P. Xing.
Dags with no tears:
408"
REFERENCES,0.43418647166361973,"Continuous optimization for structure learning. In Neural Information Processing Systems,
409"
REFERENCES,0.4351005484460695,"2018. URL https://api.semanticscholar.org/CorpusID:53217974.
410"
REFERENCES,0.4360146252285192,"[21] Zhen Zhang, Ignavier Ng, Dong Gong, Yuhang Liu, Ehsan M Abbasnejad, Mingming Gong,
411"
REFERENCES,0.4369287020109689,"Kun Zhang, and Javen Qinfeng Shi. Truncated matrix power iteration for differentiable DAG
412"
REFERENCES,0.43784277879341865,"learning. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors,
413"
REFERENCES,0.43875685557586835,"Advances in Neural Information Processing Systems, 2022. URL https://openreview.net/
414"
REFERENCES,0.4396709323583181,"forum?id=I4aSjFR7jOm.
415"
REFERENCES,0.4405850091407678,"[22] Kevin Bello, Bryon Aragam, and Pradeep Kumar Ravikumar. DAGMA: Learning DAGs via
416"
REFERENCES,0.44149908592321757,"m-matrices and a log-determinant acyclicity characterization. In Alice H. Oh, Alekh Agarwal,
417"
REFERENCES,0.4424131627056673,"Danielle Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing
418"
REFERENCES,0.443327239488117,"Systems, 2022. URL https://openreview.net/forum?id=8rZYMpFUgK.
419"
REFERENCES,0.44424131627056673,"[23] Jonas Peters, Joris M. Mooij, Dominik Janzing, and Bernhard Schölkopf. Causal discovery
420"
REFERENCES,0.44515539305301643,"with continuous additive noise models. J. Mach. Learn. Res., 15(1):2009–2053, jan 2014. ISSN
421"
REFERENCES,0.4460694698354662,"1532-4435.
422"
REFERENCES,0.4469835466179159,"[24] Sindy Löwe, David Madras, Richard S. Zemel, and Max Welling. Amortized causal discovery:
423"
REFERENCES,0.44789762340036565,"Learning to infer causal graphs from time-series data. In CLEaR, 2020. URL https://api.
424"
REFERENCES,0.44881170018281535,"semanticscholar.org/CorpusID:219955853.
425"
REFERENCES,0.44972577696526506,"[25] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N
426"
REFERENCES,0.4506398537477148,"Gomez, Łukasz Kaiser, and Illia Polosukhin.
Attention is all you need.
In I. Guyon,
427"
REFERENCES,0.4515539305301645,"U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, ed-
428"
REFERENCES,0.4524680073126143,"itors, Advances in Neural Information Processing Systems, volume 30. Curran Associates,
429"
REFERENCES,0.453382084095064,"Inc., 2017. URL https://proceedings.neurips.cc/paper_files/paper/2017/file/
430"
REFERENCES,0.45429616087751373,"3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf.
431"
REFERENCES,0.45521023765996343,"[26] Zhijing Jin, Yuen Chen, Felix Leeb, Luigi Gresele, Ojasv Kamal, Zhiheng Lyu, Kevin Blin,
432"
REFERENCES,0.45612431444241314,"Fernando Gonzalez Adauto, Max Kleiman-Weiner, Mrinmaya Sachan, et al. Cladder: A
433"
REFERENCES,0.4570383912248629,"benchmark to assess causal reasoning capabilities of language models. Advances in Neural
434"
REFERENCES,0.4579524680073126,"Information Processing Systems, 36, 2024.
435"
REFERENCES,0.45886654478976235,"[27] Jiaqi Zhang, Joel Jennings, Agrin Hilmkil, Nick Pawlowski, Cheng Zhang, and Chao Ma.
436"
REFERENCES,0.45978062157221206,"Towards causal foundation model: on duality between causal inference and attention, 2024.
437"
REFERENCES,0.4606946983546618,"[28] Meyer Scetbon, Joel Jennings, Agrin Hilmkil, Cheng Zhang, and Chao Ma. Fip: a fixed-point
438"
REFERENCES,0.4616087751371115,"approach for causal generative modeling, 2024.
439"
REFERENCES,0.4625228519195612,"[29] Shantanu Gupta, Cheng Zhang, and Agrin Hilmkil. Learned causal method prediction, 2023.
440"
REFERENCES,0.463436928702011,"[30] Caroline Uhler, G. Raskutti, Peter Bühlmann, and B. Yu. Geometry of the faithfulness assump-
441"
REFERENCES,0.4643510054844607,"tion in causal inference. The Annals of Statistics, 41, 07 2012. doi: 10.1214/12-AOS1080.
442"
REFERENCES,0.46526508226691043,"[31] Robert Geirhos, Jörn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel,
443"
REFERENCES,0.46617915904936014,"Matthias Bethge, and Felix Wichmann. Shortcut learning in deep neural networks. Nature
444"
REFERENCES,0.4670932358318099,"Machine Intelligence, 2:665–673, 11 2020. doi: 10.1038/s42256-020-00257-z.
445"
REFERENCES,0.4680073126142596,"[32] Alexander G. Reisach, Christof Seiler, and Sebastian Weichwald. Beware of the simulated dag!
446"
REFERENCES,0.4689213893967093,"causal discovery benchmarks may be easy to game. In Neural Information Processing Systems,
447"
REFERENCES,0.46983546617915906,"2021. URL https://api.semanticscholar.org/CorpusID:239998404.
448"
REFERENCES,0.47074954296160876,"[33] Francesco Montagna, Nicoletta Noceti, Lorenzo Rosasco, and Francesco Locatello. Shortcuts
449"
REFERENCES,0.4716636197440585,"for causal discovery of nonlinear models by score matching, 2023.
450"
REFERENCES,0.4725776965265082,"[34] Shohei Shimizu, Takanori Inazumi, Yasuhiro Sogawa, Aapo Hyvarinen, Yoshinobu Kawahara,
451"
REFERENCES,0.473491773308958,"Takashi Washio, Patrik Hoyer, and Kenneth Bollen. DirectLiNGAM: A direct method for
452"
REFERENCES,0.4744058500914077,"learning a linear non-gaussian structural equation model. Journal of Machine Learning Research,
453"
REFERENCES,0.4753199268738574,"12, 01 2011.
454"
REFERENCES,0.47623400365630714,"[35] Francesco Montagna, Nicoletta Noceti, Lorenzo Rosasco, Kun Zhang, and Francesco Locatello.
455"
REFERENCES,0.47714808043875684,"Causal discovery with score matching on additive models with arbitrary noise. In 2nd Conference
456"
REFERENCES,0.4780621572212066,"on Causal Learning and Reasoning, 2023. URL https://openreview.net/forum?id=
457"
REFERENCES,0.4789762340036563,"rVO0Bx90deu.
458"
REFERENCES,0.47989031078610606,"[36] Peter Bühlmann, Jonas Peters, and Jan Ernest. CAM: Causal additive models, high-dimensional
459"
REFERENCES,0.48080438756855576,"order search and penalized regression.
The Annals of Statistics, 42(6), dec 2014.
URL
460"
REFERENCES,0.48171846435100546,"https://doi.org/10.1214%2F14-aos1260.
461"
REFERENCES,0.4826325411334552,"[37] Jannik Kossen, Neil Band, Clare Lyle, Aidan Gomez, Tom Rainforth, and Yarin Gal. Self-
462"
REFERENCES,0.4835466179159049,"attention between datapoints: Going beyond individual input-output pairs in deep learning.
463"
REFERENCES,0.4844606946983547,"In A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan, editors, Advances in
464"
REFERENCES,0.4853747714808044,"Neural Information Processing Systems, 2021. URL https://openreview.net/forum?id=
465"
REFERENCES,0.48628884826325414,"wRXzOa2z5T.
466"
REFERENCES,0.48720292504570384,"[38] Juan Lin.
Factorizing multivariate function classes.
In M. Jordan, M. Kearns, and
467"
REFERENCES,0.48811700182815354,"S. Solla, editors, Advances in Neural Information Processing Systems, volume 10. MIT
468"
REFERENCES,0.4890310786106033,"Press, 1997.
URL https://proceedings.neurips.cc/paper_files/paper/1997/
469"
REFERENCES,0.489945155393053,"file/8fb21ee7a2207526da55a679f0332de2-Paper.pdf.
470"
REFERENCES,0.49085923217550276,"A
Learning to induce: causal discovery with transformers
471"
REFERENCES,0.49177330895795246,"A.1
A supervised learning approach to causal discovery
472"
REFERENCES,0.4926873857404022,"First, we describe the training procedure for the CSIvA architecture, which aims to learn the dis-
473"
REFERENCES,0.4936014625228519,"tribution of causal graphs conditioned on observational and/or interventional datasets. We omit
474"
REFERENCES,0.4945155393053016,"interventional datasets from the discussion as they are not of interest to our work. Training data are
475"
REFERENCES,0.4954296160877514,"generated from the joint distribution pG,D between a graph G and a dataset D. First, we sample a set
476"
REFERENCES,0.4963436928702011,"of directed acyclic graphs {Gi}n
i=1 with nodes X1, . . . , Xd, from a distribution pG. Then, for each
477"
REFERENCES,0.49725776965265084,"graph we sample a dataset of m observations of the graph nodes Di = {xj
1, . . . , xj
d}m
j=1, i = 1, . . . , n.
478"
REFERENCES,0.49817184643510054,"Hence, we build a training dataset {Gi, Di}n
i=1.
479"
REFERENCES,0.4990859232175503,"The CSIvA model defines a distribution ˆpG|D(·; Θ) of graphs conditioned on the observational data
and parametrized by Θ. Given an invertible map G 7→A from a graph to its binary adjacency matrix"
REFERENCES,0.5,"representation of d × d entries (where Aij = 1 iff Xi →Xj in G), we consider an equivalent
estimated distribution ˆpA|D(·; Θ), which has the following autoregressive form:"
REFERENCES,0.5009140767824497,"ˆpA,D(A|D; Θ) = d2
Y"
REFERENCES,0.5018281535648994,"l=1
σ(Al; ρ = fΘ(A1, . . . , Al−1, D)),"
REFERENCES,0.5027422303473492,"where σ(·; ρ) is a Bernoulli distribution parametrized by ρ. ρ itself is a function of fΘ defined by the
480"
REFERENCES,0.5036563071297989,"encoder-decoder transformer architecture, taking as input previous elements of the matrix A (here
481"
REFERENCES,0.5045703839122486,"represented as a vector of d2 entries) and the dataset D. Θ is optimized via maximum likelihood
482"
REFERENCES,0.5054844606946983,"estimation, i.e. Θ∗= argminΘ −EG,D[ln ˆp(G|D; Θ)], which corresponds to the usual cross-entropy
483"
REFERENCES,0.506398537477148,"loss for the Bernoulli distribution. Training is achieved using stochastic gradient descent, in which
484"
REFERENCES,0.5073126142595978,"each gradient update is performed using a pair (Di, Ai), i = 1 . . . , d. In the infinite sample limit,
485"
REFERENCES,0.5082266910420475,"we have ˆpG|D(·; Θ∗) = pG|D(·), while in the finite-capacity case, it is only an approximation of the
486"
REFERENCES,0.5091407678244972,"target distribution.
487"
REFERENCES,0.5100548446069469,"A.2
CSIvA architecture
488"
REFERENCES,0.5109689213893968,"In this section, we summarize the architecture of CSIvA, a transformer neural network that can learn
489"
REFERENCES,0.5118829981718465,"a map from data to causally interpreted graphs, under supervised training.
490"
REFERENCES,0.5127970749542962,"Transformer neural network.
Transformers [25] are a popular neural network architecture for
491"
REFERENCES,0.5137111517367459,"modeling structured, sequential data data. They consist of an encoder, a stack of layers that learns
492"
REFERENCES,0.5146252285191956,"a representation of each element in the input sequence based on its relation with all the other
493"
REFERENCES,0.5155393053016454,"sequence’s elements, through the mechanism of self-attention, and a decoder, which maps the learned
494"
REFERENCES,0.5164533820840951,"representation to the target of interest. Note that data for causal discovery are not sequential in their
495"
REFERENCES,0.5173674588665448,"nature, which motivates the adaptations introduced by Ke et al. [1] in their CSIvA architecture.
496"
REFERENCES,0.5182815356489945,"CSIvA embeddings.
Each element xj
i of an input dataset is embedded into a vector of dimension-
497"
REFERENCES,0.5191956124314442,"ality E. Half of this vector is allocated to embed the value xj
i itself, while the other half is allocated
498"
REFERENCES,0.520109689213894,"to embed the unique identity for the node Xi. We use a node-specific embedding because the values
499"
REFERENCES,0.5210237659963437,"of each node may have very different interpretations and meanings. The node identity embedding
500"
REFERENCES,0.5219378427787934,"is obtained using a standard 1D transformer positional embedding over node indices. The value
501"
REFERENCES,0.5228519195612431,"embedding is obtained by passing xj
i, through a multi-layer perceptron (MLP).
502"
REFERENCES,0.5237659963436929,"CSIvA alternating attention.
Similarly to the transformer’s encoder, CSIvA stacks a number of
503"
REFERENCES,0.5246800731261426,"identical layers, performing self-attention followed by a nonlinear mapping, most commonly an
504"
REFERENCES,0.5255941499085923,"MLP layer. The main difference relative to the standard encoder is in the implementation of the
505"
REFERENCES,0.526508226691042,"self-attention layer: as transformers are in their nature suitable for the representation of sequences,
506"
REFERENCES,0.5274223034734917,"given an input sample of D elements, self-attention is usually run across all elements of the sequence.
507"
REFERENCES,0.5283363802559415,"However, data for causal discovery are tabular, rather than sequential: one option would be to unravel
508"
REFERENCES,0.5292504570383912,"the n×d matrix of the data, where n is the number of observations and d the number of variables, into
509"
REFERENCES,0.5301645338208409,"a vector of n · d elements, and let this be the input sequence of the encoder. CSIvA adopts a different
510"
REFERENCES,0.5310786106032906,"strategy: the self-attention in each encoder layer consists of alternate passes over the attribute and
511"
REFERENCES,0.5319926873857403,"the sample dimensions, known as alternating attention [37]. As a clarifying example, consider a
512"
REFERENCES,0.5329067641681902,"dataset {(xi
1, xi
2)}n
i=1 of n i.i.d. samples from the joint distribution of the pair of random variables
513"
REFERENCES,0.5338208409506399,"X1, X2. For each layer of the encoder, in the first step (known as attention between attributes),
514"
REFERENCES,0.5347349177330896,"attention operates across all nodes of a single sample (xi
1, xi
2) to encode the relationships between
515"
REFERENCES,0.5356489945155393,"the two nodes. In the second step (attention between samples), attention operates across all samples
516"
REFERENCES,0.5365630712979891,"(x1
k, . . . , xn
k), k ∈{1, 2} of a given node, to encode information about the distribution of single node
517"
REFERENCES,0.5374771480804388,"values.
518"
REFERENCES,0.5383912248628885,"CSIvA encoder summary.
The encoder produces a summary vector si with H elements for each
519"
REFERENCES,0.5393053016453382,"node Xi, which captures essential information about the node’s behavior and its interactions with other
520"
REFERENCES,0.5402193784277879,"nodes. The summary representation is formed independently for each node and involves combining
521"
REFERENCES,0.5411334552102377,"information across the n samples. This is achieved with a method often used with transformers that
522"
REFERENCES,0.5420475319926874,"involves a weighted average based on how informative each sample is. The weighting is obtained
523"
REFERENCES,0.5429616087751371,"using the embeddings of a summary ""sample"" n + 1 to form queries, and embeddings of node’s
524"
REFERENCES,0.5438756855575868,"samples {xj
i}n
j=1 to provide keys and values, and then using standard key-value attention.
525"
REFERENCES,0.5447897623400365,"Hypeparameter
Value"
REFERENCES,0.5457038391224863,"Hidden state dimension
64
Encoder transformer layers
8
Decoder transformer layers
8
Num. attention heads
8
Optimizer
Adam
Learning rate
10−4
Samples per dataset (n)
1500
Num. training datasets
15000
Num. iterations
< 150000
Batch size
5"
REFERENCES,0.546617915904936,Table 1: Hyperparameters for the training of the CSIvA models of the experiments in Section 3.
REFERENCES,0.5475319926873857,"CSIvA decoder.
The decoder uses the summary information from the encoder to generate a
526"
REFERENCES,0.5484460694698354,"prediction of the adjacency matrix A of the underlying G. It operates sequentially, at each step
527"
REFERENCES,0.5493601462522852,"producing a binary output indicating the prediction ˆAi,j of Ai,j, proceeding row by row. The decoder
528"
REFERENCES,0.5502742230347349,"is an autoregressive transformer, meaning that each prediction ˆAi,j is obtained based on all elements
529"
REFERENCES,0.5511882998171846,"of A previously predicted, as well as the summary produced by the encoder. The method does not
530"
REFERENCES,0.5521023765996343,"enforce acyclicity, although Ke et al. [1] shows that in cyclic outputs genereally don’t occur, in
531"
REFERENCES,0.553016453382084,"practice.
532"
REFERENCES,0.5539305301645339,"B
Training details
533"
REFERENCES,0.5548446069469836,"B.1
Hyperparameters
534"
REFERENCES,0.5557586837294333,"In Table 1 we detail the hyperparameters of the training of the network of the experiments. We define
535"
REFERENCES,0.556672760511883,"an iteration as a gradient update over a batch of 5 datasets. Models are trained until convergence,
536"
REFERENCES,0.5575868372943327,"using a patience of 5 (training until five consecutive epochs without improvement) on the validation
537"
REFERENCES,0.5585009140767825,"loss - this always occurs before the 25-th epoch (corresponding to ≈150000 iterations). The batch
538"
REFERENCES,0.5594149908592322,"size is limited to 5 due to memory constraints.
539"
REFERENCES,0.5603290676416819,"B.2
Synthetic data
540"
REFERENCES,0.5612431444241316,"In this section, we provide additional details on the synthetic data generation, which was performed
541"
REFERENCES,0.5621572212065814,"with the causally2 Python library [9]. Our data-generating framework follows that of Montagna
542"
REFERENCES,0.5630712979890311,"et al. [9], an extensive benchmark of causal discovery methods on different classes of SCMs.
543"
REFERENCES,0.5639853747714808,"Causal mechanisms.
The nonlinear mechanisms of the PNL model and the nonlinear ANM model
544"
REFERENCES,0.5648994515539305,"are generated by a neural network with one hidden layer with 10 hidden units, with a parametric
545"
REFERENCES,0.5658135283363802,"ReLU activation function. The network weights are randomly sampled according to a standard
546"
REFERENCES,0.56672760511883,"Gaussian distribution. The linear mechanisms are generated by sampling the regression coefficients
547"
REFERENCES,0.5676416819012797,"in the range [−3, −0.5] ∪[0.5, 3].
548"
REFERENCES,0.5685557586837294,"Distribution of the noise terms.
We generated datasets from structural causal models with the
549"
REFERENCES,0.5694698354661791,"following distribution of the noise terms: Beta, Gamma, Gaussian (for nonlinear data), Gumbel,
550"
REFERENCES,0.5703839122486288,"Exponential, and Uniform. Additionally, we define the mlp distribution by nonlinear transformations
551"
REFERENCES,0.5712979890310786,"of gaussian samples from a guassian distribution centered at zero and with standard deviation σ
552"
REFERENCES,0.5722120658135283,"uniformly sampled between 0.5 and 1. The nonlinear transformation is parametrized by a neural
553"
REFERENCES,0.573126142595978,"network with one hidden layer with 100 units, and sigmoid activation function. The weights of the
554"
REFERENCES,0.5740402193784278,"network are uniformly sampled in the range [−1.5, 1.5]. We additionally standardized the output of
555"
REFERENCES,0.5749542961608776,"each mlp sample by the empirical variance computed over all samples.
556"
REFERENCES,0.5758683729433273,"Data are standardized with their empirical variance, which removes the presence of shortcuts which
557"
REFERENCES,0.576782449725777,"could be learned by the network, notably varsortability [32] and score-sortability [33].
558"
REFERENCES,0.5776965265082267,2https://causally.readthedocs.io/en/latest/
REFERENCES,0.5786106032906764,"B.3
Computer resources
559"
REFERENCES,0.5795246800731262,"Our experiments were run on a local computing cluster, using any and all available GPUs (all
560"
REFERENCES,0.5804387568555759,"NVIDIA). For replication purposes, GTX 1080 Ti’s are entirely suitable, as the batch size was set
561"
REFERENCES,0.5813528336380256,"to match their memory capacity, when working with bivariate graphs. All jobs ran with 10GB of
562"
REFERENCES,0.5822669104204753,"RAM and 4 CPU cores. The results presented in this paper were produced after 145 days of GPU
563"
REFERENCES,0.583180987202925,"time, of which 68 were on GTX 1080 Ti’s, 13 on RTX 2080 Ti’s, 11 on A10s, 19 on A40s, and 35
564"
REFERENCES,0.5840950639853748,"on RTX 3090s. Together with previous experiments, while developing our code and experimental
565"
REFERENCES,0.5850091407678245,"design, we used 376 days of GPU time (for reference, at a total cost of 492.14 Euros), similarly split
566"
REFERENCES,0.5859232175502742,"across whichever GPUs were available at the time: 219 on GTX 1080 Ti’s, 38 on RTX 2080 Ti’s, 18
567"
REFERENCES,0.5868372943327239,"on A10s, 63 on RTX 3090s, 31 on A40s, and 6 on A100s.
568"
REFERENCES,0.5877513711151737,"C
Further experiments
569"
REFERENCES,0.5886654478976234,"We present our experimental results on one further question, to help clarify the results in the main text
570"
REFERENCES,0.5895795246800731,"of the paper. Our aim is to understand when to make tradeoffs between computational resources, and
571"
REFERENCES,0.5904936014625228,"having models that have been trained on a wider variety of SCMs. We compare training on multiple
572"
REFERENCES,0.5914076782449725,"SCMs to single-SCM training, when all models see the same amount of training data from each SCM
573"
REFERENCES,0.5923217550274223,"type as a non-mixed model (i.e. a mixed network trains on 15, 000 linear datasets and 15, 000 PNL
574"
REFERENCES,0.593235831809872,"datasets, instead of 15, 000 divided between the two SCM types).
575"
REFERENCES,0.5941499085923218,"In the main text of this paper, we compare neural networks trained on a mix of structural causal
576"
REFERENCES,0.5950639853747715,"models (e.g. noise distributions, or mechanism types), to models trained on a single mechanism-noise
577"
REFERENCES,0.5959780621572212,"combination, where all models have the same amount of training data, 15, 000 datasets. In mixed
578"
REFERENCES,0.596892138939671,"training, we split these evenly, so a ""lin, nl"" model is trained on 7, 500 datasets from linear SCMs, and
579"
REFERENCES,0.5978062157221207,"7, 500 from nonlinear SCMs. Our results in this framework are promising, and show that for many
580"
REFERENCES,0.5987202925045704,"combinations of SCM types, we can train one model instead of two, and achieve good progress, while
581"
REFERENCES,0.5996343692870201,"making a 50% savings on training costs. However, if our training budget is high/unlimited, we should
582"
REFERENCES,0.6005484460694699,"also ask whether there is a downside to mixed training - can we achieve the same performance as a
583"
REFERENCES,0.6014625228519196,"model trained on a single SCM type? Fig. 6 shows good results in this direction - the models trained
584"
REFERENCES,0.6023765996343693,"with the same number of datasets per SCM type as an unmixed model had similar (or even better,
585"
REFERENCES,0.603290676416819,"for PNL data) performance as the un-mixed model trained on the same SCM type as the test data.
586"
REFERENCES,0.6042047531992687,"These mixed models are also significantly more useful than having 2 or 3 separate models per SCM
587"
REFERENCES,0.6051188299817185,"type, as they have good across-the-board performance. However, if we used the same computational
588"
REFERENCES,0.6060329067641682,"resources to train 3 separate networks (one for each mechanism type) and wanted to use them for
589"
REFERENCES,0.6069469835466179,"causal discovery on a dataset with unknown assumptions, we would be left with the rather difficult
590"
REFERENCES,0.6078610603290676,task of deciding which model to trust.
REFERENCES,0.6087751371115173,"mixed (15k each)
mixed
single
in-distribution"
REFERENCES,0.6096892138939671,"0
0.25
0.5
SHD"
REFERENCES,0.6106032906764168,"lin, nl"
REFERENCES,0.6115173674588665,"lin, pnl all"
REFERENCES,0.6124314442413162,"nl
pnl"
REFERENCES,0.613345521023766,Training datasets
REFERENCES,0.6142595978062158,(a) Linear test data
REFERENCES,0.6151736745886655,"0
0.25
0.5
SHD"
REFERENCES,0.6160877513711152,"lin, nl"
REFERENCES,0.6170018281535649,"nl, pnl all"
REFERENCES,0.6179159049360147,"lin
pnl"
REFERENCES,0.6188299817184644,(b) Nonlinear test data
REFERENCES,0.6197440585009141,"0
0.25
0.5
SHD"
REFERENCES,0.6206581352833638,"lin, pnl"
REFERENCES,0.6215722120658135,"nl, pnl all lin nl"
REFERENCES,0.6224862888482633,(c) PNL test data
REFERENCES,0.623400365630713,"Figure 6: Mixtures of causal mechanisms, with varying amounts of training data. We train eight models on
samples from structural casual models with different mechanisms. Four (in purple), were trained on 15, 000
samples for each SCM type (so the ""lin,nl"" model saw 30, 000 samples in total, and the ""all"" model saw 45, 000),
and the other four (blue) are the same as in Fig. 4, and were trained on 15, 000 samples in total, evenly split
between the SCM types they were trained on. We compare their test SHD (the lower, the better) against networks
trained on datasets generated according to a single type of mechanism. The dashed line indicates the test SHD of
a model trained on samples with the same mechanisms as the test SCM. Training on multiple causal models with
different mechanisms (mixed bars) always improves performance compared to training on single SCMs. 591"
REFERENCES,0.6243144424131627,"D
Theoretical results and proofs
592"
REFERENCES,0.6252285191956124,"Before stating the proof of Proposition 1, we show under which condition the pair of random
593"
REFERENCES,0.6261425959780622,"variables X, Y satisfies the forward and backward models of equations (5), (6): this is relevant for
594"
REFERENCES,0.6270566727605119,"our discussion, as the proof of Proposition 1 consists of showing that this condition is almost never
595"
REFERENCES,0.6279707495429616,"satisfied.
596"
REFERENCES,0.6288848263254113,"Notation.
We adopt the following notation: νX := log pNX, νY := log pNY , ξ := log p ˜
X, η :=
597"
REFERENCES,0.629798903107861,"log p ˜Y , and π := log p ˜
X, ˜Y .
598"
REFERENCES,0.6307129798903108,"Theorem 1 (Theorem 1 of Zhang and Hyvärinen [8]). Assume that X, Y satisfies both causal
599"
REFERENCES,0.6316270566727605,"relations of equations (5) and (6). Further, suppose that pNY and p ˜
X are positive densities on the
600"
REFERENCES,0.6325411334552102,"support of NY and ˜X respectively, and that νY , ξ, f1, f2, g1, and g2 are third order differentiable.
601"
REFERENCES,0.6334552102376599,"Then, for each pair (˜x, ˜y) satisfying ν′′
Y (˜y −hY (˜x))hY (˜x) ̸= 0, the following differential equation
602"
REFERENCES,0.6343692870201096,"holds:
603"
REFERENCES,0.6352833638025595,"ξ′′′ = ξ′′
h′′
Y
h′
Y
−ν′′′
Y h′
Y
ν′′
Y"
REFERENCES,0.6361974405850092,"
+ ν′′′
Y ν′
Y h′′
Y h′
Y
ν′′
Y
−ν′
Y (h′′
Y )2"
REFERENCES,0.6371115173674589,"h′
Y
−2ν′′
Y h′′
Y h′
Y + ν′
Y h′′′
Y ,"
REFERENCES,0.6380255941499086,"and hX is constrained in the following way:
604"
REFERENCES,0.6389396709323584,"1
h′
X
= ξ′′ + ν′′
Y (h′
Y )2 −ν′
Y h′′
Y
ν′′
Y h′
Y
,
(9)"
REFERENCES,0.6398537477148081,"where the arguments of the functions have been left out for clarity.
605"
REFERENCES,0.6407678244972578,"Proof of Theorem 1. We demonstrate separately the two statements of the theorem.
606"
REFERENCES,0.6416819012797075,"Part 1.
Given that equations (5) and (6) hold, this implies that the forward and backward models
607"
REFERENCES,0.6425959780621572,"on ˜X, ˜Y of equations (7) and (8) are also valid, namely that:
608"
REFERENCES,0.643510054844607,"˜Y = hY ( ˜X) + NY ,
˜X = hX( ˜Y ) + NX."
REFERENCES,0.6444241316270567,"These are the structural equations of two causal models, associated with the forward ˜X →˜Y and
backward ˜Y →˜X graphs, respectively. Applying the Markov factorization of the distribution
according to the forward direction, we get:"
REFERENCES,0.6453382084095064,"p ˜
X, ˜
Y (˜x, ˜y) = p ˜
Y | ˜
X(˜y|˜x)p ˜
X(˜x) = pNY (˜y −hY (˜x))p ˜
X(˜x),"
REFERENCES,0.6462522851919561,"which implies
609"
REFERENCES,0.6471663619744058,"π(˜x, ˜y) = νY (˜y −hY (˜x)) + ξ(˜x),
(10)
for any ˜x, ˜y. Similarly, the Markov factorization on the backward model implies:
610"
REFERENCES,0.6480804387568556,"π(˜x, ˜y) = νX(˜x −hX(˜y)) + η(˜y).
(11)"
REFERENCES,0.6489945155393053,"From (11), we have that:
611 ∂2"
REFERENCES,0.649908592321755,"∂˜x2 π(˜x, ˜y) = ν′′
X(˜x −hX(˜y)) ∂2"
REFERENCES,0.6508226691042047,"∂˜x∂˜y π(˜x, ˜y) = −ν′′
X(˜x −hX(˜y))h′
X(˜y),"
REFERENCES,0.6517367458866545,"which implies
612 ∂
∂˜x"
REFERENCES,0.6526508226691042,"∂2
∂˜x2 π(˜x, ˜y)"
REFERENCES,0.6535648994515539,"∂2
∂˜x∂˜yπ(˜x, ˜y) !"
REFERENCES,0.6544789762340036,"= 0.
(12)"
REFERENCES,0.6553930530164533,"Computing the same set of partial derivatives from (10), we find:
613 ∂2"
REFERENCES,0.6563071297989032,"∂˜x2 π(˜x, ˜y) = ν′′
Y (˜y −hY (˜x))(h′
Y (˜x))2 −ν′
Y (˜y −hY (˜x))h′′
Y (˜x) + ξ′′(˜x) ∂2"
REFERENCES,0.6572212065813529,"∂˜x∂˜y π(˜x, ˜y) = −ν′′
Y (˜y −hY (˜x))h′
Y (˜x)."
REFERENCES,0.6581352833638026,"from which follows:
614 ∂
∂˜x"
REFERENCES,0.6590493601462523,"∂2
∂˜x2 π(˜x, ˜y)"
REFERENCES,0.659963436928702,"∂2
∂˜x∂˜yπ(˜x, ˜y) !"
REFERENCES,0.6608775137111518,"= −2h′′
Y + ν′
Y h′′′
Y
ν′′
Y h′
Y
−
ξ′′′"
REFERENCES,0.6617915904936015,"ν′′
Y h′
Y
+ ν′′′
Y ν′
Y h′′
Y
(ν′′
Y )2
−ν′
Y (h′′
Y )2"
REFERENCES,0.6627056672760512,"ν′′
Y (h′
Y )2 +
ξ′′ν′′′
Y h′′
Y
(ν′′
Y )2ν′′
Y (h′
Y )2 = 0."
REFERENCES,0.6636197440585009,"where we drop the input arguments for conciseness. The equality with 0 is given by the equality with
615"
REFERENCES,0.6645338208409507,"(12). Manipulating the above expression, the first claim follows.
616"
REFERENCES,0.6654478976234004,"Part 2.
Next, we prove the constraint derived on hX. To do this, we exploit the fact that ˜Y is
617"
REFERENCES,0.6663619744058501,"independent of NX, which implies the following condition [38]:
618 ∂2"
REFERENCES,0.6672760511882998,"∂˜y∂nx
log p(˜y, nx) = 0,
(13)"
REFERENCES,0.6681901279707495,"for any (˜y, nx). According to equations (7), (8), we have that:
619"
REFERENCES,0.6691042047531993,"˜Y = hY ( ˜X) + NY ,"
REFERENCES,0.670018281535649,"NX = ˜X −hX( ˜Y ),"
REFERENCES,0.6709323583180987,"such that we can define an invertible map Φ : (˜y, nx) 7→(˜x, nY ). It is easy to show that the Jacobian
of the transformation has determinant |JΦ| = 1, such that"
REFERENCES,0.6718464351005484,"p(˜y, nY ) = p(˜x, nY ),"
REFERENCES,0.6727605118829981,"where (˜x, nY ) = Φ−1(˜y, nX). Thus, being ˜X, NY independent random variables, we have that:"
REFERENCES,0.6736745886654479,"log p(˜y, nX) = log p(˜x) + log p(nY ) = ξ(˜x) + νY (nY )."
REFERENCES,0.6745886654478976,"Given that ˜X = hX( ˜Y ) + NX, we have that ∂2"
REFERENCES,0.6755027422303473,"∂˜y∂˜nX
log p(˜x) = ξ′′h′
X,"
REFERENCES,0.676416819012797,while NY = ˜Y −hY ( ˜X) implies ∂2
REFERENCES,0.6773308957952467,"∂˜y∂˜nX
log p(nY ) = −ν′′
Y h′
Y + ν′′
Y h′
X(h′
Y )2 −ν′
Y h′
Xh′′
Y ,"
REFERENCES,0.6782449725776966,"such that
log p(˜x, nY ) = ξ′′h′
X + −ν′′
Y h′
Y + ν′′
Y h′
X(h′
Y )2 −ν′
Y h′
Xh′′
Y ,"
REFERENCES,0.6791590493601463,"which must be equal to zero, being equal to the LHS of (13). Thus, we conclude that"
REFERENCES,0.680073126142596,"1
h′
X
= ξ′′ + ν′′
Y (h′
Y )2 −ν′
Y h′′
Y
ν′′
Y h′
Y
,"
REFERENCES,0.6809872029250457,"proving the claim.
620"
REFERENCES,0.6819012797074955,"D.1
Proof of Proposition 1
621"
REFERENCES,0.6828153564899452,"Proof. Under the hypothesis that equations (5), (6) hold, i.e. when the data generating process satisfy
622"
REFERENCES,0.6837294332723949,"both a forward and a backward model, by Theorem 1 we have that:
623"
REFERENCES,0.6846435100548446,"ξ′′′(˜x) = ξ′′(˜x)G(˜x, ˜y) + H(˜x, ˜y),
(14)"
REFERENCES,0.6855575868372943,"where
624"
REFERENCES,0.6864716636197441,"G(˜x, ˜y) =
h′′
Y
h′
Y
−ν′′′
Y h′
Y
ν′′
Y 
,"
REFERENCES,0.6873857404021938,"H(˜x, ˜y) = ν′′′
Y ν′
Y h′′
Y h′
Y
ν′′
Y
−ν′
Y (h′′
Y )2"
REFERENCES,0.6882998171846435,"h′
Y
−2ν′′
Y h′′
Y h′
Y + ν′
Y h′′′
Y ."
REFERENCES,0.6892138939670932,"Define z := ξ′′′, such that the above equation can be written as z′(˜x) = z(˜x)G(˜x, ˜y) + H(˜x, ˜y).
625"
REFERENCES,0.6901279707495429,"given that such function z exists, it is given by:
626"
REFERENCES,0.6910420475319927,z(˜x) = z(˜x0)e
REFERENCES,0.6919561243144424,"R ˜x
˜x0 G(t,y)dt +
Z ˜x"
REFERENCES,0.6928702010968921,"˜x0
e
R ˜x
ˆt G(t,y)dtH(ˆt, y)dˆt.
(15)"
REFERENCES,0.6937842778793418,"Let ˜y such that ν′′
Y (˜y −hY (˜x))h′
Y (˜x) ̸= 0 holds for all but countable values of ˜x. Then, z is
determined by z(˜x0), as we can extend equation (15) to all the remaining points. The set of
all functions ξ satisfying the differential equation (14) is a 3-dimensional affine space, as fixing
ξ(˜x0), ξ′′(˜x0), ξ′′(˜x0) for some point ˜x0 completely determines the solution ξ. Moreover, given
νY , hX, hY fixed, ξ′′ is specified by (9) of theorem 1, which implies:"
REFERENCES,0.6946983546617916,"ξ′′ = ν′′
Y h′
Y
h′
X
+ ν′
Y h′′
Y −ν′′
Y (h′
Y )2,"
REFERENCES,0.6956124314442413,"which confines ξ solutions of (14) to a 2-dimensional affine space.
627"
REFERENCES,0.696526508226691,"NeurIPS Paper Checklist
628"
CLAIMS,0.6974405850091407,"1. Claims
629"
CLAIMS,0.6983546617915904,"Question: Do the main claims made in the abstract and introduction accurately reflect the
630"
CLAIMS,0.6992687385740403,"paper’s contributions and scope?
631"
CLAIMS,0.70018281535649,"Answer: [Yes]
632"
CLAIMS,0.7010968921389397,"Justification: Supervised learning models in causal discovery do not provide connections
633"
CLAIMS,0.7020109689213894,"with the known identifiability theory. In the abstract, we present this open problem, and
634"
CLAIMS,0.7029250457038391,"highlight our main empirical findings and how they connect to the theory of identifiability in
635"
CLAIMS,0.7038391224862889,"causality. The content of the paper (mostly Section 3) unravels the abstract claims in all of
636"
CLAIMS,0.7047531992687386,"their details.
637"
CLAIMS,0.7056672760511883,"Guidelines:
638"
CLAIMS,0.706581352833638,"• The answer NA means that the abstract and introduction do not include the claims
639"
CLAIMS,0.7074954296160878,"made in the paper.
640"
CLAIMS,0.7084095063985375,"• The abstract and/or introduction should clearly state the claims made, including the
641"
CLAIMS,0.7093235831809872,"contributions made in the paper and important assumptions and limitations. A No or
642"
CLAIMS,0.7102376599634369,"NA answer to this question will not be perceived well by the reviewers.
643"
CLAIMS,0.7111517367458866,"• The claims made should match theoretical and experimental results, and reflect how
644"
CLAIMS,0.7120658135283364,"much the results can be expected to generalize to other settings.
645"
CLAIMS,0.7129798903107861,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
646"
CLAIMS,0.7138939670932358,"are not attained by the paper.
647"
LIMITATIONS,0.7148080438756855,"2. Limitations
648"
LIMITATIONS,0.7157221206581352,"Question: Does the paper discuss the limitations of the work performed by the authors?
649"
LIMITATIONS,0.716636197440585,"Answer: [Yes]
650"
LIMITATIONS,0.7175502742230347,"Justification: We discuss the limitations of our work in Section 1, paragraph ""Closely related
651"
LIMITATIONS,0.7184643510054844,"works and their relation with CSIvA"", regarding the use of CSIvA as our only architecture
652"
LIMITATIONS,0.7193784277879341,"for the experiments. Additionally, in the same paragraph, we remark that the scope of this
653"
LIMITATIONS,0.720292504570384,"study is limited to the context of causal discovery on observational data. Finally, in Section
654"
LIMITATIONS,0.7212065813528337,"2.2, we discuss our choice of limiting the empirical study to the case of bivariate graphs.
655"
LIMITATIONS,0.7221206581352834,"Guidelines:
656"
LIMITATIONS,0.7230347349177331,"• The answer NA means that the paper has no limitation while the answer No means that
657"
LIMITATIONS,0.7239488117001828,"the paper has limitations, but those are not discussed in the paper.
658"
LIMITATIONS,0.7248628884826326,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
659"
LIMITATIONS,0.7257769652650823,"• The paper should point out any strong assumptions and how robust the results are to
660"
LIMITATIONS,0.726691042047532,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
661"
LIMITATIONS,0.7276051188299817,"model well-specification, asymptotic approximations only holding locally). The authors
662"
LIMITATIONS,0.7285191956124314,"should reflect on how these assumptions might be violated in practice and what the
663"
LIMITATIONS,0.7294332723948812,"implications would be.
664"
LIMITATIONS,0.7303473491773309,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
665"
LIMITATIONS,0.7312614259597806,"only tested on a few datasets or with a few runs. In general, empirical results often
666"
LIMITATIONS,0.7321755027422303,"depend on implicit assumptions, which should be articulated.
667"
LIMITATIONS,0.7330895795246801,"• The authors should reflect on the factors that influence the performance of the approach.
668"
LIMITATIONS,0.7340036563071298,"For example, a facial recognition algorithm may perform poorly when image resolution
669"
LIMITATIONS,0.7349177330895795,"is low or images are taken in low lighting. Or a speech-to-text system might not be
670"
LIMITATIONS,0.7358318098720292,"used reliably to provide closed captions for online lectures because it fails to handle
671"
LIMITATIONS,0.7367458866544789,"technical jargon.
672"
LIMITATIONS,0.7376599634369287,"• The authors should discuss the computational efficiency of the proposed algorithms
673"
LIMITATIONS,0.7385740402193784,"and how they scale with dataset size.
674"
LIMITATIONS,0.7394881170018281,"• If applicable, the authors should discuss possible limitations of their approach to
675"
LIMITATIONS,0.7404021937842779,"address problems of privacy and fairness.
676"
LIMITATIONS,0.7413162705667276,"• While the authors might fear that complete honesty about limitations might be used by
677"
LIMITATIONS,0.7422303473491774,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
678"
LIMITATIONS,0.7431444241316271,"limitations that aren’t acknowledged in the paper. The authors should use their best
679"
LIMITATIONS,0.7440585009140768,"judgment and recognize that individual actions in favor of transparency play an impor-
680"
LIMITATIONS,0.7449725776965265,"tant role in developing norms that preserve the integrity of the community. Reviewers
681"
LIMITATIONS,0.7458866544789763,"will be specifically instructed to not penalize honesty concerning limitations.
682"
THEORY ASSUMPTIONS AND PROOFS,0.746800731261426,"3. Theory Assumptions and Proofs
683"
THEORY ASSUMPTIONS AND PROOFS,0.7477148080438757,"Question: For each theoretical result, does the paper provide the full set of assumptions and
684"
THEORY ASSUMPTIONS AND PROOFS,0.7486288848263254,"a complete (and correct) proof?
685"
THEORY ASSUMPTIONS AND PROOFS,0.7495429616087751,"Answer: [Yes]
686"
THEORY ASSUMPTIONS AND PROOFS,0.7504570383912249,"Justification: Proposition 1 is proved in detail in Appendix D.1, which is based on Theorem
687"
THEORY ASSUMPTIONS AND PROOFS,0.7513711151736746,"1 of Zhang and Hyvärinen [8], which we report in the Appendix together with its proof. We
688"
THEORY ASSUMPTIONS AND PROOFS,0.7522851919561243,"do not provide an explicit sketch of the proof of our Proposition 1 in the main text, as we
689"
THEORY ASSUMPTIONS AND PROOFS,0.753199268738574,"already detail the intuition behind it in the content of Section 3.3.
690"
THEORY ASSUMPTIONS AND PROOFS,0.7541133455210237,"Guidelines:
691"
THEORY ASSUMPTIONS AND PROOFS,0.7550274223034735,"• The answer NA means that the paper does not include theoretical results.
692"
THEORY ASSUMPTIONS AND PROOFS,0.7559414990859232,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
693"
THEORY ASSUMPTIONS AND PROOFS,0.7568555758683729,"referenced.
694"
THEORY ASSUMPTIONS AND PROOFS,0.7577696526508226,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
695"
THEORY ASSUMPTIONS AND PROOFS,0.7586837294332724,"• The proofs can either appear in the main paper or the supplemental material, but if
696"
THEORY ASSUMPTIONS AND PROOFS,0.7595978062157221,"they appear in the supplemental material, the authors are encouraged to provide a short
697"
THEORY ASSUMPTIONS AND PROOFS,0.7605118829981719,"proof sketch to provide intuition.
698"
THEORY ASSUMPTIONS AND PROOFS,0.7614259597806216,"• Inversely, any informal proof provided in the core of the paper should be complemented
699"
THEORY ASSUMPTIONS AND PROOFS,0.7623400365630713,"by formal proofs provided in appendix or supplemental material.
700"
THEORY ASSUMPTIONS AND PROOFS,0.7632541133455211,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
701"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7641681901279708,"4. Experimental Result Reproducibility
702"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7650822669104205,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
703"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7659963436928702,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
704"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7669104204753199,"of the paper (regardless of whether the code and data are provided or not)?
705"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7678244972577697,"Answer: [Yes]
706"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7687385740402194,"Justification: We have specified our data generation methods in Appendix B.2, as well
707"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7696526508226691,"as the CSIvA method (which is a previously published model) in Appendix A, and our
708"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7705667276051188,"hyperparameters for training in Appendix B.1. We will also release our implementation of
709"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7714808043875686,"CSIvA, our data generation code (which is a thin wrapper around the causally https:
710"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7723948811700183,"//causally.readthedocs.io/en/latest/ Python library), and our experimental code.
711"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.773308957952468,"Guidelines:
712"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7742230347349177,"• The answer NA means that the paper does not include experiments.
713"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7751371115173674,"• If the paper includes experiments, a No answer to this question will not be perceived
714"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7760511882998172,"well by the reviewers: Making the paper reproducible is important, regardless of
715"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7769652650822669,"whether the code and data are provided or not.
716"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7778793418647166,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
717"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7787934186471663,"to make their results reproducible or verifiable.
718"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.779707495429616,"• Depending on the contribution, reproducibility can be accomplished in various ways.
719"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7806215722120659,"For example, if the contribution is a novel architecture, describing the architecture fully
720"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7815356489945156,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
721"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7824497257769653,"be necessary to either make it possible for others to replicate the model with the same
722"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.783363802559415,"dataset, or provide access to the model. In general. releasing code and data is often
723"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7842778793418648,"one good way to accomplish this, but reproducibility can also be provided via detailed
724"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7851919561243145,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
725"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7861060329067642,"of a large language model), releasing of a model checkpoint, or other means that are
726"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7870201096892139,"appropriate to the research performed.
727"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7879341864716636,"• While NeurIPS does not require releasing code, the conference does require all submis-
728"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7888482632541134,"sions to provide some reasonable avenue for reproducibility, which may depend on the
729"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7897623400365631,"nature of the contribution. For example
730"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7906764168190128,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
731"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7915904936014625,"to reproduce that algorithm.
732"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7925045703839122,"(b) If the contribution is primarily a new model architecture, the paper should describe
733"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.793418647166362,"the architecture clearly and fully.
734"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7943327239488117,"(c) If the contribution is a new model (e.g., a large language model), then there should
735"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7952468007312614,"either be a way to access this model for reproducing the results or a way to reproduce
736"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7961608775137111,"the model (e.g., with an open-source dataset or instructions for how to construct
737"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7970749542961609,"the dataset).
738"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7979890310786106,"(d) We recognize that reproducibility may be tricky in some cases, in which case
739"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7989031078610603,"authors are welcome to describe the particular way they provide for reproducibility.
740"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.79981718464351,"In the case of closed-source models, it may be that access to the model is limited in
741"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8007312614259597,"some way (e.g., to registered users), but it should be possible for other researchers
742"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8016453382084096,"to have some path to reproducing or verifying the results.
743"
OPEN ACCESS TO DATA AND CODE,0.8025594149908593,"5. Open access to data and code
744"
OPEN ACCESS TO DATA AND CODE,0.803473491773309,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
745"
OPEN ACCESS TO DATA AND CODE,0.8043875685557587,"tions to faithfully reproduce the main experimental results, as described in supplemental
746"
OPEN ACCESS TO DATA AND CODE,0.8053016453382084,"material?
747"
OPEN ACCESS TO DATA AND CODE,0.8062157221206582,"Answer: [Yes]
748"
OPEN ACCESS TO DATA AND CODE,0.8071297989031079,"Justification: We will release our implementation of CSIvA, our data generation code
749"
OPEN ACCESS TO DATA AND CODE,0.8080438756855576,"(which is a thin wrapper around the causally https://causally.readthedocs.io/
750"
OPEN ACCESS TO DATA AND CODE,0.8089579524680073,"en/latest/ Python library), and our experimental code.
751"
OPEN ACCESS TO DATA AND CODE,0.8098720292504571,"Guidelines:
752"
OPEN ACCESS TO DATA AND CODE,0.8107861060329068,"• The answer NA means that paper does not include experiments requiring code.
753"
OPEN ACCESS TO DATA AND CODE,0.8117001828153565,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
754"
OPEN ACCESS TO DATA AND CODE,0.8126142595978062,"public/guides/CodeSubmissionPolicy) for more details.
755"
OPEN ACCESS TO DATA AND CODE,0.8135283363802559,"• While we encourage the release of code and data, we understand that this might not be
756"
OPEN ACCESS TO DATA AND CODE,0.8144424131627057,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
757"
OPEN ACCESS TO DATA AND CODE,0.8153564899451554,"including code, unless this is central to the contribution (e.g., for a new open-source
758"
OPEN ACCESS TO DATA AND CODE,0.8162705667276051,"benchmark).
759"
OPEN ACCESS TO DATA AND CODE,0.8171846435100548,"• The instructions should contain the exact command and environment needed to run to
760"
OPEN ACCESS TO DATA AND CODE,0.8180987202925045,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
761"
OPEN ACCESS TO DATA AND CODE,0.8190127970749543,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
762"
OPEN ACCESS TO DATA AND CODE,0.819926873857404,"• The authors should provide instructions on data access and preparation, including how
763"
OPEN ACCESS TO DATA AND CODE,0.8208409506398537,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
764"
OPEN ACCESS TO DATA AND CODE,0.8217550274223034,"• The authors should provide scripts to reproduce all experimental results for the new
765"
OPEN ACCESS TO DATA AND CODE,0.8226691042047533,"proposed method and baselines. If only a subset of experiments are reproducible, they
766"
OPEN ACCESS TO DATA AND CODE,0.823583180987203,"should state which ones are omitted from the script and why.
767"
OPEN ACCESS TO DATA AND CODE,0.8244972577696527,"• At submission time, to preserve anonymity, the authors should release anonymized
768"
OPEN ACCESS TO DATA AND CODE,0.8254113345521024,"versions (if applicable).
769"
OPEN ACCESS TO DATA AND CODE,0.8263254113345521,"• Providing as much information as possible in supplemental material (appended to the
770"
OPEN ACCESS TO DATA AND CODE,0.8272394881170019,"paper) is recommended, but including URLs to data and code is permitted.
771"
OPEN ACCESS TO DATA AND CODE,0.8281535648994516,"6. Experimental Setting/Details
772"
OPEN ACCESS TO DATA AND CODE,0.8290676416819013,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
773"
OPEN ACCESS TO DATA AND CODE,0.829981718464351,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
774"
OPEN ACCESS TO DATA AND CODE,0.8308957952468007,"results?
775"
OPEN ACCESS TO DATA AND CODE,0.8318098720292505,"Answer: [Yes]
776"
OPEN ACCESS TO DATA AND CODE,0.8327239488117002,"Justification: Yes, we provide these details in Section 3.1 and Appendix B.
777"
OPEN ACCESS TO DATA AND CODE,0.8336380255941499,"Guidelines:
778"
OPEN ACCESS TO DATA AND CODE,0.8345521023765996,"• The answer NA means that the paper does not include experiments.
779"
OPEN ACCESS TO DATA AND CODE,0.8354661791590493,"• The experimental setting should be presented in the core of the paper to a level of detail
780"
OPEN ACCESS TO DATA AND CODE,0.8363802559414991,"that is necessary to appreciate the results and make sense of them.
781"
OPEN ACCESS TO DATA AND CODE,0.8372943327239488,"• The full details can be provided either with the code, in appendix, or as supplemental
782"
OPEN ACCESS TO DATA AND CODE,0.8382084095063985,"material.
783"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8391224862888482,"7. Experiment Statistical Significance
784"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.840036563071298,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
785"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8409506398537477,"information about the statistical significance of the experiments?
786"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8418647166361974,"Answer: [Yes]
787"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8427787934186471,"Justification: For each plot, we provide error bars in the form of 95% confidence intervals
788"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8436928702010968,"computed on 1.5k points (hence, it’s reasonable to apply the central limit theorem to argue
789"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8446069469835467,"that the confidence intervals are valid).
790"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8455210237659964,"Guidelines:
791"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8464351005484461,"• The answer NA means that the paper does not include experiments.
792"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8473491773308958,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
793"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8482632541133455,"dence intervals, or statistical significance tests, at least for the experiments that support
794"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8491773308957953,"the main claims of the paper.
795"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.850091407678245,"• The factors of variability that the error bars are capturing should be clearly stated (for
796"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8510054844606947,"example, train/test split, initialization, random drawing of some parameter, or overall
797"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8519195612431444,"run with given experimental conditions).
798"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8528336380255942,"• The method for calculating the error bars should be explained (closed form formula,
799"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8537477148080439,"call to a library function, bootstrap, etc.)
800"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8546617915904936,"• The assumptions made should be given (e.g., Normally distributed errors).
801"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8555758683729433,"• It should be clear whether the error bar is the standard deviation or the standard error
802"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.856489945155393,"of the mean.
803"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8574040219378428,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
804"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8583180987202925,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
805"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8592321755027422,"of Normality of errors is not verified.
806"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8601462522851919,"• For asymmetric distributions, the authors should be careful not to show in tables or
807"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8610603290676416,"figures symmetric error bars that would yield results that are out of range (e.g. negative
808"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8619744058500914,"error rates).
809"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8628884826325411,"• If error bars are reported in tables or plots, The authors should explain in the text how
810"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8638025594149908,"they were calculated and reference the corresponding figures or tables in the text.
811"
EXPERIMENTS COMPUTE RESOURCES,0.8647166361974405,"8. Experiments Compute Resources
812"
EXPERIMENTS COMPUTE RESOURCES,0.8656307129798904,"Question: For each experiment, does the paper provide sufficient information on the com-
813"
EXPERIMENTS COMPUTE RESOURCES,0.8665447897623401,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
814"
EXPERIMENTS COMPUTE RESOURCES,0.8674588665447898,"the experiments?
815"
EXPERIMENTS COMPUTE RESOURCES,0.8683729433272395,"Answer: [Yes]
816"
EXPERIMENTS COMPUTE RESOURCES,0.8692870201096892,"Justification: We provide all details on our computer resources in Appendix B.3.
817"
EXPERIMENTS COMPUTE RESOURCES,0.870201096892139,"Guidelines:
818"
EXPERIMENTS COMPUTE RESOURCES,0.8711151736745887,"• The answer NA means that the paper does not include experiments.
819"
EXPERIMENTS COMPUTE RESOURCES,0.8720292504570384,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
820"
EXPERIMENTS COMPUTE RESOURCES,0.8729433272394881,"or cloud provider, including relevant memory and storage.
821"
EXPERIMENTS COMPUTE RESOURCES,0.8738574040219378,"• The paper should provide the amount of compute required for each of the individual
822"
EXPERIMENTS COMPUTE RESOURCES,0.8747714808043876,"experimental runs as well as estimate the total compute.
823"
EXPERIMENTS COMPUTE RESOURCES,0.8756855575868373,"• The paper should disclose whether the full research project required more compute
824"
EXPERIMENTS COMPUTE RESOURCES,0.876599634369287,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
825"
EXPERIMENTS COMPUTE RESOURCES,0.8775137111517367,"didn’t make it into the paper).
826"
CODE OF ETHICS,0.8784277879341865,"9. Code Of Ethics
827"
CODE OF ETHICS,0.8793418647166362,"Question: Does the research conducted in the paper conform, in every respect, with the
828"
CODE OF ETHICS,0.8802559414990859,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
829"
CODE OF ETHICS,0.8811700182815356,"Answer: [Yes]
830"
CODE OF ETHICS,0.8820840950639853,"Justification: We do not believe any of the concerns in the Code of Ethics apply to our work.
831"
CODE OF ETHICS,0.8829981718464351,"Guidelines:
832"
CODE OF ETHICS,0.8839122486288848,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
833"
CODE OF ETHICS,0.8848263254113345,"• If the authors answer No, they should explain the special circumstances that require a
834"
CODE OF ETHICS,0.8857404021937842,"deviation from the Code of Ethics.
835"
CODE OF ETHICS,0.886654478976234,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
836"
CODE OF ETHICS,0.8875685557586838,"eration due to laws or regulations in their jurisdiction).
837"
BROADER IMPACTS,0.8884826325411335,"10. Broader Impacts
838"
BROADER IMPACTS,0.8893967093235832,"Question: Does the paper discuss both potential positive societal impacts and negative
839"
BROADER IMPACTS,0.8903107861060329,"societal impacts of the work performed?
840"
BROADER IMPACTS,0.8912248628884827,"Answer: [NA]
841"
BROADER IMPACTS,0.8921389396709324,"Justification: Our work is about assessing and studying pre-existing causal discovery models.
842"
BROADER IMPACTS,0.8930530164533821,"As we release no new model, there is no societal impact that could be caused by our work.
843"
BROADER IMPACTS,0.8939670932358318,"Guidelines:
844"
BROADER IMPACTS,0.8948811700182815,"• The answer NA means that there is no societal impact of the work performed.
845"
BROADER IMPACTS,0.8957952468007313,"• If the authors answer NA or No, they should explain why their work has no societal
846"
BROADER IMPACTS,0.896709323583181,"impact or why the paper does not address societal impact.
847"
BROADER IMPACTS,0.8976234003656307,"• Examples of negative societal impacts include potential malicious or unintended uses
848"
BROADER IMPACTS,0.8985374771480804,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
849"
BROADER IMPACTS,0.8994515539305301,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
850"
BROADER IMPACTS,0.9003656307129799,"groups), privacy considerations, and security considerations.
851"
BROADER IMPACTS,0.9012797074954296,"• The conference expects that many papers will be foundational research and not tied
852"
BROADER IMPACTS,0.9021937842778793,"to particular applications, let alone deployments. However, if there is a direct path to
853"
BROADER IMPACTS,0.903107861060329,"any negative applications, the authors should point it out. For example, it is legitimate
854"
BROADER IMPACTS,0.9040219378427788,"to point out that an improvement in the quality of generative models could be used to
855"
BROADER IMPACTS,0.9049360146252285,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
856"
BROADER IMPACTS,0.9058500914076782,"that a generic algorithm for optimizing neural networks could enable people to train
857"
BROADER IMPACTS,0.906764168190128,"models that generate Deepfakes faster.
858"
BROADER IMPACTS,0.9076782449725777,"• The authors should consider possible harms that could arise when the technology is
859"
BROADER IMPACTS,0.9085923217550275,"being used as intended and functioning correctly, harms that could arise when the
860"
BROADER IMPACTS,0.9095063985374772,"technology is being used as intended but gives incorrect results, and harms following
861"
BROADER IMPACTS,0.9104204753199269,"from (intentional or unintentional) misuse of the technology.
862"
BROADER IMPACTS,0.9113345521023766,"• If there are negative societal impacts, the authors could also discuss possible mitigation
863"
BROADER IMPACTS,0.9122486288848263,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
864"
BROADER IMPACTS,0.9131627056672761,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
865"
BROADER IMPACTS,0.9140767824497258,"feedback over time, improving the efficiency and accessibility of ML).
866"
SAFEGUARDS,0.9149908592321755,"11. Safeguards
867"
SAFEGUARDS,0.9159049360146252,"Question: Does the paper describe safeguards that have been put in place for responsible
868"
SAFEGUARDS,0.916819012797075,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
869"
SAFEGUARDS,0.9177330895795247,"image generators, or scraped datasets)?
870"
SAFEGUARDS,0.9186471663619744,"Answer: [NA]
871"
SAFEGUARDS,0.9195612431444241,"Justification: The data and models in this paper do not have high risk for misuse.
872"
SAFEGUARDS,0.9204753199268738,"Guidelines:
873"
SAFEGUARDS,0.9213893967093236,"• The answer NA means that the paper poses no such risks.
874"
SAFEGUARDS,0.9223034734917733,"• Released models that have a high risk for misuse or dual-use should be released with
875"
SAFEGUARDS,0.923217550274223,"necessary safeguards to allow for controlled use of the model, for example by requiring
876"
SAFEGUARDS,0.9241316270566727,"that users adhere to usage guidelines or restrictions to access the model or implementing
877"
SAFEGUARDS,0.9250457038391224,"safety filters.
878"
SAFEGUARDS,0.9259597806215722,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
879"
SAFEGUARDS,0.926873857404022,"should describe how they avoided releasing unsafe images.
880"
SAFEGUARDS,0.9277879341864717,"• We recognize that providing effective safeguards is challenging, and many papers do
881"
SAFEGUARDS,0.9287020109689214,"not require this, but we encourage authors to take this into account and make a best
882"
SAFEGUARDS,0.9296160877513712,"faith effort.
883"
LICENSES FOR EXISTING ASSETS,0.9305301645338209,"12. Licenses for existing assets
884"
LICENSES FOR EXISTING ASSETS,0.9314442413162706,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
885"
LICENSES FOR EXISTING ASSETS,0.9323583180987203,"the paper, properly credited and are the license and terms of use explicitly mentioned and
886"
LICENSES FOR EXISTING ASSETS,0.93327239488117,"properly respected?
887"
LICENSES FOR EXISTING ASSETS,0.9341864716636198,"Answer: [Yes]
888"
LICENSES FOR EXISTING ASSETS,0.9351005484460695,"Justification: We cite the authors of all papers we build our work on. Additionally, we
889"
LICENSES FOR EXISTING ASSETS,0.9360146252285192,"provide the URL to all previously existing code we rely on, which is available in the form of
890"
LICENSES FOR EXISTING ASSETS,0.9369287020109689,"public GitHub repository under MIT license.
891"
LICENSES FOR EXISTING ASSETS,0.9378427787934186,"Guidelines:
892"
LICENSES FOR EXISTING ASSETS,0.9387568555758684,"• The answer NA means that the paper does not use existing assets.
893"
LICENSES FOR EXISTING ASSETS,0.9396709323583181,"• The authors should cite the original paper that produced the code package or dataset.
894"
LICENSES FOR EXISTING ASSETS,0.9405850091407678,"• The authors should state which version of the asset is used and, if possible, include a
895"
LICENSES FOR EXISTING ASSETS,0.9414990859232175,"URL.
896"
LICENSES FOR EXISTING ASSETS,0.9424131627056673,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
897"
LICENSES FOR EXISTING ASSETS,0.943327239488117,"• For scraped data from a particular source (e.g., website), the copyright and terms of
898"
LICENSES FOR EXISTING ASSETS,0.9442413162705667,"service of that source should be provided.
899"
LICENSES FOR EXISTING ASSETS,0.9451553930530164,"• If assets are released, the license, copyright information, and terms of use in the
900"
LICENSES FOR EXISTING ASSETS,0.9460694698354661,"package should be provided. For popular datasets, paperswithcode.com/datasets
901"
LICENSES FOR EXISTING ASSETS,0.946983546617916,"has curated licenses for some datasets. Their licensing guide can help determine the
902"
LICENSES FOR EXISTING ASSETS,0.9478976234003657,"license of a dataset.
903"
LICENSES FOR EXISTING ASSETS,0.9488117001828154,"• For existing datasets that are re-packaged, both the original license and the license of
904"
LICENSES FOR EXISTING ASSETS,0.9497257769652651,"the derived asset (if it has changed) should be provided.
905"
LICENSES FOR EXISTING ASSETS,0.9506398537477148,"• If this information is not available online, the authors are encouraged to reach out to
906"
LICENSES FOR EXISTING ASSETS,0.9515539305301646,"the asset’s creators.
907"
NEW ASSETS,0.9524680073126143,"13. New Assets
908"
NEW ASSETS,0.953382084095064,"Question: Are new assets introduced in the paper well documented and is the documentation
909"
NEW ASSETS,0.9542961608775137,"provided alongside the assets?
910"
NEW ASSETS,0.9552102376599635,"Answer: [Yes]
911"
NEW ASSETS,0.9561243144424132,"Justification: As our work is an analysis of pre-existing methods of causal discovery, we do
912"
NEW ASSETS,0.9570383912248629,"not release new assets other than the code strictly needed for reproducing our experimental
913"
NEW ASSETS,0.9579524680073126,"results. This code is attached to this submission to facilitate the reproducibility of our
914"
NEW ASSETS,0.9588665447897623,"results. All the documentation necessary for reproducing our results is provided in the main
915"
NEW ASSETS,0.9597806215722121,"manuscript.
916"
NEW ASSETS,0.9606946983546618,"Guidelines:
917"
NEW ASSETS,0.9616087751371115,"• The answer NA means that the paper does not release new assets.
918"
NEW ASSETS,0.9625228519195612,"• Researchers should communicate the details of the dataset/code/model as part of their
919"
NEW ASSETS,0.9634369287020109,"submissions via structured templates. This includes details about training, license,
920"
NEW ASSETS,0.9643510054844607,"limitations, etc.
921"
NEW ASSETS,0.9652650822669104,"• The paper should discuss whether and how consent was obtained from people whose
922"
NEW ASSETS,0.9661791590493601,"asset is used.
923"
NEW ASSETS,0.9670932358318098,"• At submission time, remember to anonymize your assets (if applicable). You can either
924"
NEW ASSETS,0.9680073126142597,"create an anonymized URL or include an anonymized zip file.
925"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9689213893967094,"14. Crowdsourcing and Research with Human Subjects
926"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9698354661791591,"Question: For crowdsourcing experiments and research with human subjects, does the paper
927"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9707495429616088,"include the full text of instructions given to participants and screenshots, if applicable, as
928"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9716636197440585,"well as details about compensation (if any)?
929"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9725776965265083,"Answer: [NA]
930"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.973491773308958,"Justification: We do not work with human subjects or crowdsourcing.
931"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9744058500914077,"Guidelines:
932"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9753199268738574,"• The answer NA means that the paper does not involve crowdsourcing nor research with
933"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9762340036563071,"human subjects.
934"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9771480804387569,"• Including this information in the supplemental material is fine, but if the main contribu-
935"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9780621572212066,"tion of the paper involves human subjects, then as much detail as possible should be
936"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9789762340036563,"included in the main paper.
937"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.979890310786106,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
938"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9808043875685558,"or other labor should be paid at least the minimum wage in the country of the data
939"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9817184643510055,"collector.
940"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9826325411334552,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
941"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9835466179159049,"Subjects
942"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9844606946983546,"Question: Does the paper describe potential risks incurred by study participants, whether
943"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9853747714808044,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
944"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9862888482632541,"approvals (or an equivalent approval/review based on the requirements of your country or
945"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9872029250457038,"institution) were obtained?
946"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9881170018281535,"Answer: [NA]
947"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9890310786106032,"Justification: We do not work with human subjects or crowdsourcing.
948"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9899451553930531,"Guidelines:
949"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9908592321755028,"• The answer NA means that the paper does not involve crowdsourcing nor research with
950"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9917733089579525,"human subjects.
951"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9926873857404022,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
952"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.993601462522852,"may be required for any human subjects research. If you obtained IRB approval, you
953"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9945155393053017,"should clearly state this in the paper.
954"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9954296160877514,"• We recognize that the procedures for this may vary significantly between institutions
955"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9963436928702011,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
956"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9972577696526508,"guidelines for their institution.
957"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9981718464351006,"• For initial submissions, do not include any information that would break anonymity (if
958"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9990859232175503,"applicable), such as the institution conducting the review.
959"
