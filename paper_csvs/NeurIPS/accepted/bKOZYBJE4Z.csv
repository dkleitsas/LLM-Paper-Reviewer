Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0015723270440251573,"Estimating treatment effects over time holds significance in various domains, in-
cluding precision medicine, epidemiology, economy, and marketing. This paper
introduces a unique approach to counterfactual regression over time, emphasizing
long-term predictions. Distinguishing itself from existing models like Causal Trans-
former, our approach highlights the efficacy of employing RNNs for long-term
forecasting, complemented by Contrastive Predictive Coding (CPC) and Infor-
mation Maximization (InfoMax). Emphasizing efficiency, we avoid the need for
computationally expensive transformers. Leveraging CPC, our method captures
long-term dependencies in the presence of time-varying confounders. Notably,
recent models have disregarded the importance of invertible representation, com-
promising identification assumptions. To remedy this, we employ the InfoMax
principle, maximizing a lower bound of mutual information between sequence
data and its representation. Our method achieves state-of-the-art counterfactual
estimation results using both synthetic and real-world data, marking the pioneering
incorporation of Contrastive Predictive Encoding in causal inference."
INTRODUCTION,0.0031446540880503146,"1
Introduction"
INTRODUCTION,0.0047169811320754715,"It’s vital in real-world applications to estimate potential responses, i.e., responses under hypothetical
treatment strategies. Individuals show diverse responses to the same treatment, emphasizing the
need to quantify individual response trajectories. This enables personalized interventions, enhancing
decision-making efficacy. In medical contexts, precise response estimation enables tailored treat-
ments for patients [2, 70, 49]. This paper focuses on counterfactual regression over time, estimating
responses under hypothetical treatment plans based on individual records, including past covariates,
responses, and treatment sequences up to the current prediction time [64, 62]. In addressing the chal-
lenges of this time-varying setting, we tackle: (1) Time-dependent confounding [55]: confounders
influenced by past treatment, impacting subsequent treatments and responses. (2) Selection bias: im-
balanced covariate distributions across treatment regimes in observational data, requiring time-aware
handling beyond methods in static settings [64, 67, 41]. (3) Long-term dependencies: enduring
interdependencies among covariates, treatments, and responses, enabling long-range interactions
[15, 54].
Recent advancements in neural networks, such as Recurrent Marginal Structural Networks (RMSNs)
[42], Counterfactual Recurrent Networks (CRN) [7], and G-Net [39], have tackled these causal
inference challenges. However, their reliance on RNNs limits their ability to capture long-term
dependencies. Recent studies [48] propose integrating transformers to better represent temporal
dynamics. Rather than viewing this as a limitation of RNNs, we see it as an opportunity to em-
phasize their strengths. We design specific architectures for counterfactual regression over large
horizons, avoiding complex, hard-to-interpret models like transformers. Our approach leverages"
INTRODUCTION,0.006289308176100629,∗mouad.el-bouchattaoui@centralesupelec.fr
INTRODUCTION,0.007861635220125786,"the computational efficiency of RNNs, incorporating Contrastive Predictive Coding (CPC) [52, 29]
for learning data history representations. This enhances model performance while maintaining effi-
ciency, offering a compelling alternative to transformer-based approaches. Furthermore, we usually
formulate identification assumptions of counterfactual responses over the original process history
space (Appendix B.1). However, these assumptions may not hold in the representation space for
arbitrary functions. Since identification often involves conditional independence, it applies when
using an invertible representation function. Current models for time-varying settings [42, 7, 48] do
not enforce representation invertibility. To address this, instead of adding complexity with a decoder,
we implicitly push the history process to be ""reconstructable"" from the encoded representation by
maximizing Mutual Information (MI) between representation and input, following the InfoMax
principle [43], akin to Deep InfoMax [32]."
CONTRIBUTIONS,0.009433962264150943,"2
Contributions"
CONTRIBUTIONS,0.0110062893081761,"Our approach is inspired by self-supervised learning using MI objectives [32]. We aim to maximize
MI between different views of the same input, introducing counterfactual regression over time
through CPC to capture long-term dependencies. Additionally, we propose a tractable lower bound
to the original InfoMax objectives for more efficient representations. This is challenging due to the
sequential nature and high dimensionality, marking a novelty. We demonstrate the importance of
regularization terms via an ablation study. Previous work leveraging contrastive learning for causal
inference applies only to the static setting with no theoretical grounding [16]. To our knowledge,
we frame for the first time the representation balancing problem from an information-theoretic
perspective and show that the suggested adversarial game (Theorem 5.4) yields theoretically balanced
representations using the Contrastive Log-ratio Upper Bound (CLUB) of MI, computed efficiently.
Key innovations of our Causal CPC model include: (1) We showcase the capability of leveraging
CPC to capture long-term dependencies in the process history using InfoNCE [25, 26, 52], an
unexplored area in counterfactual regression over time where its integration into process history
modeling is not straightforward in causality. (2) We enforce input reconstruction from representation
by contrasting the representation with its input. Such quality is generally overlooked in baselines,
yet it ensures that confounding information is retained, preventing biased counterfactual estimation.
(3) Applying InfoMax to process history while respecting its dynamic nature is challenging. We
provide a tractable lower bound to the original InfoMax problem, also bringing theoretical insights
on the bound’s tightness. (4) We suggest minimizing an upper bound on MI between representation
and treatment to make the representation non-predictive of the treatment, using the CLUB of MI
[13]. This novel information-theoretic perspective results in a theoretically balanced representation
across all treatment regimes. (5) By using a simple Gated Recurrent Unit (GRU) layer [14] as the
model backbone, we demonstrate that well-designed regularizations can outperform more complex
models like transformers. Finally, our experiments on synthetic data (cancer simulation [24]) and
semi-synthetic data based on real-world datasets (MIMIC-III [35]) show the superiority of Causal
CPC at accurately estimating counterfactual responses."
RELATED WORK,0.012578616352201259,"3
Related Work"
RELATED WORK,0.014150943396226415,"Models for Counterfactual Regression Through Time
Traditionally, causal inference addresses
time-varying confounders using Marginal Structural Models (MSMs) [64], which rely on inverse
probability of treatment weighting [62]. However, MSMs can yield high variance estimates, especially
with extreme values, and are limited to pooled logistic regression, impractical for high-dimensional,
dynamic data. RMSNs [41] enhance MSMs by integrating RNNs for propensity and outcome
modeling. CRN [7] employs adversarial domain training with a gradient reversal layer [23] to establish
a treatment-invariant representation space, reducing bias induced by time-varying confounders.
Similarly, G-Net [39] combines g-computation and RNNs to predict counterfactuals in dynamic
treatment regimes. Causal Transformer (CT) [48] uses transformers to estimate counterfactuals over
time and handles selection bias by learning a treatment-invariant representation via Counterfactual
Domain Confusion loss (CDC) [78]. These models, like ours, assume sequential ignorability [62], in
contrast to a body of work which does not fully verify our assumptions [45, 73, 68, 60, 80, 79, 8, 28,
12, 38, 58, 69, 19, 10, 31, 34, 6, 11, 82, 22], which we discuss in detail in Appendix C.1.2. In contrast,
we introduce a contrastive learning approach to capture long-term dependencies while maintaining
a simple model and ensuring high computational efficiency in both training and prediction. This
demonstrates that simple models with well-designed regularization terms can still achieve high"
RELATED WORK,0.015723270440251572,"prediction quality. Additionally, previous works [62, 64, 41, 39, 48] did not consider the role of
invertible representation in improving counterfactual regression. Here, we introduce an InfoMax
regularization term to make our encoder easier to invert. Appendix C.1 provides a detailed overview
of counterfactual regression models."
RELATED WORK,0.01729559748427673,"InfoMax Principle
The InfoMax principle aims to learn a representation that maximizes MI
with its input [43, 5]. Estimating MI for high-dimensional data is challenging, often addressed by
maximizing a simple and tractable lower bound on MI [32, 56, 40]. Another approach involves
maximizing MI between two lower-dimensional representations of different views of the same input
[3, 29, 75, 77], offering a more practical solution. We adopt this strategy by dividing our process
history into two views, past and future, and maximizing a tractable lower bound on MI between them.
This encourages a ""reconstructable"" representation of the process history. To our knowledge, the
only work applying an InfoMax approach to counterfactual regression, albeit in static settings, is [16].
They propose maximizing MI between an individual’s representation and a global representation,
aggregating information from all individuals into a single vector. However, the global representation
lacks clarity and interpretability, raising uncertainties about its theoretical underpinnings in capturing
confounders. Furthermore, there’s a lack of theoretical analysis on how minimizing MI between
individual and treatment-predictive representations could yield a treatment-invariant representation.
As a novelty, we extend the InfoMax principle to longitudinal data, providing a theoretical guarantee
of learning balanced representations. Appendix C.2 discusses self-supervision and MI, with all proofs
in Appendix G."
PROBLEM FORMULATION,0.018867924528301886,"4
Problem Formulation Y≤t W≤t X≤t Yt+1 Wt+1 Xt+1 V"
PROBLEM FORMULATION,0.020440251572327043,Figure 1: Causal graph over Ht+1
PROBLEM FORMULATION,0.0220125786163522,"Setup
In the framework of Potential Outcomes (PO) [65],
and following [63], we track a cohort of individuals (units)
i ∈{1, 2, . . . , N} over tmax time steps. At each time t ∈
{1, 2, . . . , tmax}, we observe the following: (1) Discrete treat-
ment Wit ∈W = {0, 1, . . . , K −1}, e.g., in medical contexts,
Wit may represent treatments like radiotherapy or chemother-
apy. (2) Outcome of interest Yit ∈Y ⊂R, such as tumor
volume. (3) Time-varying context Xit ∈X ⊂Rdx, con-
taining information about the individual that may influence
treatment decisions and outcomes. Xit is a dx-dimensional
vector of confounders, such as health records or clinical mea-
surements. (4) Static confounders V ∈V ⊂Rdv, such as
gender, which remain constant over time. (5) Partially observed potential outcomes Yit(ωi,≤t),
representing the outcomes that would have been observed for individual i at time t under treat-
ment sequence ωi,≤t = (ωi,1, . . . , ωi,t) ∈Wt. We define the history process up to time t + 1 as
Ht+1 = [V, X≤t+1, W≤t, Y≤t], capturing all information prior to the assignment of treatment Wt+1.
This history is illustrated in the causal graph shown in Figure 1."
PROBLEM FORMULATION,0.02358490566037736,"Goal
Given a training dataset {Hi,t+1, i = 1, . . . , N} sampled from the empirical distribution
PHt+1, we address the following causal inference problem: Given a history process Ht+1, how can we
efficiently estimate counterfactual responses up to time t + τ (where τ ≥1 is the prediction horizon)
for a potential treatment sequence ωt+1:t+τ = (ωt+1, . . . , ωt+τ)? The goal is to estimate the causal
quantity: E(Yt+τ(ωt+1:t+τ) | Ht+1), i.e., the expected outcome at time t + τ, given the history
Ht+1 and a sequence of treatments ωt+1:t+τ. We identify this causal quantity from observational
data using the assumption of sequential ignorability [62, 42, 39, 48], which is implicitly assumed in
Figure 1 and explicitly discussed in Appendix B.1. This allows us to express the counterfactual as:"
PROBLEM FORMULATION,0.025157232704402517,"E(Yt+τ(ωt+1:t+τ) | Ht+1) = E (Yt+τ | Ht+1, Wt+1:t+τ = ωt+1:t+τ) ."
CAUSAL CPC,0.026729559748427674,"5
Causal CPC"
REPRESENTATION LEARNING,0.02830188679245283,"5.1
Representation Learning"
REPRESENTATION LEARNING,0.029874213836477988,"Contrastive Predictive Coding
We employ contrastive learning to efficiently represent the process
history Ht. Causal forecasting over multiple time horizons requires representations that capture
variability in Ht. For short-term predictions, local features and smooth signal variations are critical,"
REPRESENTATION LEARNING,0.031446540880503145,"while long-term predictions rely on capturing global structures and long-term dependencies, as shared
information between history and future points diminishes.
To achieve this, we learn a representation of Ht that predicts future components over multi-
ple time steps.
For each horizon j = 1, . . . , τ, future components are defined as Ut+j =
[V, Xt+j, Wt+j−1, Yt+j−1] ∈U ⊂R(dv+dx+K+1). First, local features are extracted by encoding
[V, Xt, Wt−1, Yt−1] into Zt = Φθ1([V, Xt, Wt−1, Yt−1]). Then, the full process history Ht is sum-
marized into a context representation Ct, given by an autoregressive model: Φar
θ2 (Z≤t) = Ct, where
Φar
θ2 is implemented with a GRU [14]. This results in the representation function: Φθ1,θ2(Ht) = Ct.
To train the model, we use a contrastive loss that encourages the context Ct to predict future local
features Zt+1, . . . , Zt+τ while distinguishing them from the features of other individuals. This is
done by minimizing the InfoNCE loss L(InfoNCE)
j
for each horizon j:"
REPRESENTATION LEARNING,0.0330188679245283,"L(InfoNCE)
j
(θ1, θ2, Γj) := −EB"
REPRESENTATION LEARNING,0.03459119496855346,"
log
exp(Tj(Ut+j,Ct))
P|B|
l=1 exp(Tj(Ul,t+j,Ct))"
REPRESENTATION LEARNING,0.036163522012578615,"
,
(1)"
REPRESENTATION LEARNING,0.03773584905660377,"where B is a batch containing individual histories, and Γj is a weight matrix. The discriminator
Tj(., .) classifies the correct future feature among negative samples from other individuals:"
REPRESENTATION LEARNING,0.03930817610062893,"Tj(Ut+j, Φθ1,θ2(Ht)) = Φθ1(Ut+j)T ΓjCt = ZT
t+jΓjCt.
(2)"
REPRESENTATION LEARNING,0.040880503144654086,"In practice, Ct predicts ˆZt+j, and prediction quality is measured by the dot product Z⊤
t+j ˆZt+j."
REPRESENTATION LEARNING,0.04245283018867924,"Minimizing the InfoNCE loss L(InfoNCE)
j
provides a lower bound on the MI between the context
and future features I(Ut+j, Ct) [52]:"
REPRESENTATION LEARNING,0.0440251572327044,"I(Ut+j, Ct) ≥log(|B|) −L(InfoNCE)
j
.
(3)"
REPRESENTATION LEARNING,0.04559748427672956,"For multiple forecasting horizons j = 1, 2, . . . , τ, we learn long-term dependencies by minimizing
the InfoNCE loss across all horizons:"
REPRESENTATION LEARNING,0.04716981132075472,"LCP C(θ1, θ2, {Γj}τ
j=1) := 1"
REPRESENTATION LEARNING,0.04874213836477988,"τ
Pτ
j=1 L(InfoNCE)
j
(θ1, θ2, Γj).
(4)"
REPRESENTATION LEARNING,0.050314465408805034,"Thus, minimizing LCP C maximizes the shared information between the context and future compo-
nents as shown in Eq. (5), pushing the model to capture the global structure of the process over large
horizons—crucial for counterfactual regression across multiple time steps:"
REPRESENTATION LEARNING,0.05188679245283019,"1
τ
Pτ
j=1 I(Ut+j, Ct) ≥log(|B|) −LCP C.
(5)"
REPRESENTATION LEARNING,0.05345911949685535,"InfoMax Principle
We introduce a regularization term to make the context representation of the
process history Ht ""reconstructable."" We leverage the InfoMax principle to maximize the MI between
Ht and the context Ct. However, we avoid computing the contrastive loss between Ct and Ht for
two main reasons. First, Ht is a high-dimensional sequence, making the loss computation very
demanding. Secondly, we are still interested in incorporating inductive bias toward capturing global
dependencies, this time by pushing any subsequence to be predictive of any future subsequence
within Ht. Hence, we divide the process history into two non-overlapping views, Hh
t := U1:t0,
Hf
t := Ut0+1:t representing a historical subsequence and a future subsequence within the process
history Ht, with t0 randomly chosen per batch. We then maximize the MI between the representations
of these views, Ch
t and Cf
t , resulting in a lower bound to the InfoMax objective as formulated below:"
REPRESENTATION LEARNING,0.055031446540880505,"Proposition 5.1. I(Ch
t , Cf
t ) ≤I(Ht, (Ch
t , Cf
t ))."
REPRESENTATION LEARNING,0.05660377358490566,"We provide an intuitive discussion of the inequality by providing an exact writing of the gap in 5.1:
Theorem 5.2."
REPRESENTATION LEARNING,0.05817610062893082,"I(Ht; (Cf
t , Ch
t )) −I(Cf
t , Ch
t ) = I(Ht; Cf
t | Ch
t ) + Eht∼PHtEcf
t ∼PCf
t |ht"
REPRESENTATION LEARNING,0.059748427672955975,"h
DKL[PCh
t |ht||PCh
t |cf
t ]
i
.
(6)"
REPRESENTATION LEARNING,0.06132075471698113,"Both terms on the RHS of Eq. (6) are positive, providing an alternative proof to Proposition 5.1.
When equality holds, it implies I(Ht; Cf
t | Ch
t ) = 0, indicating that Ht is independent of Cf
t given
Ch
t . This suggests that Ch
t retains sufficient information from Ht that is predictive of Cf
t . The
symmetry of MI also leads to the occurrence of the second term on the RHS when conditioning
on Cf
t . The equality in Proposition 5.1 implies PCh
t |ht = PCh
t |cf
t , suggesting that Cf
t efficiently
encodes its subsequence while sharing maximum information with Ch
t ."
REPRESENTATION LEARNING,0.06289308176100629,"By considering the proposed variant of the InfoMax principle, we can compute a contrastive bound
to I(Ch
t , Cf
t ) more efficiently, as the random vectors reside in a low-dimensional space thanks to the
encoding. We define a contrastive loss using InfoNCE similar to Eq. (1):"
REPRESENTATION LEARNING,0.06446540880503145,"L(InfoMax)(θ1, θ2, η) := −EB"
REPRESENTATION LEARNING,0.0660377358490566,"
log
exp(Tη(Cf
t ,Ch
t ))
P|B|
l=1 exp(Tη(Cf
l,t,Ch
t ))"
REPRESENTATION LEARNING,0.06761006289308176,"
.
(7)"
REPRESENTATION LEARNING,0.06918238993710692,"We use a non-linear discriminator Tη parametrized by η (detailed in Appendix I). The representation
of the past subsequence Ch
t is mapped to a prediction of the future subsequence ˆCf
t := Fη(Ch
t ) and"
REPRESENTATION LEARNING,0.07075471698113207,"Tη = Cf ⊤
t
ˆCf
t .
Theorem 5.2 and Proposition 5.1 justify using the loss in Eq. (7) by showing that our InfoMax
simplification provides a valid lower bound. Thus, the contrastive loss in Eq. (7) is valid, as:"
REPRESENTATION LEARNING,0.07232704402515723,"log(|B|) −L(InfoMax) ≤I(Ch
t , Cf
t ) ≤I(Ht, (Ch
t , Cf
t )).
(8)"
REPRESENTATION LEARNING,0.07389937106918239,"The ""mental model"" behind our regularization term comes from the MI, I(Ht, (Ch
t , Cf
t )) = H(Ht)−
H(Ht | (Ch
t , Cf
t )), which can be written using entropy. Since the entropy term is constant and
parameter-free, minimizing the conditional entropy H(Ht | (Ch
t , Cf
t )) ≥0 ensures that Ht is
almost surely a function of (Ch
t , Cf
t ) (Appendix G.4, Proposition G.2). When MI is maximized,
the theoretical existence of such a function suggests that the learned context Ct can decode and
reconstruct Ht.
Beyond the idea of reconstruction, it was shown that the InfoNCE objective implicitly learns to invert
the data’s generative model under mild assumptions [86]. Recent works [18, 44] extend this insight
to multi-modal settings, which can reframe our InfoMax problem: Hh
t and Hf
t can be seen as two
coupled modalities, allowing us to identify latent generative factors up to some mild indeterminacies
(e.g rotations, affine mappings). We plan to extend multi-modal causal representation learning to the
longitudinal setting, where we anticipate minimizing our InfoMax objective, in the limit of infinite
data, will effectively invert the data generation process up to a class of indeterminacies that we
conjecture to be broader and under weaker assumptions than those in current causal representation
learning literature, given our focus is on causal inference rather than the identification of causal latent
variables. We initiate a formal basis for this claim in Appendix G.5."
BALANCED REPRESENTATION LEARNING,0.07547169811320754,"5.2
Balanced representation learning"
BALANCED REPRESENTATION LEARNING,0.0770440251572327,"Motivation
Our goal is counterfactual regression, specifically estimating E(Yt+τ(ωt+1:t+τ) |
Ht+1). For simplicity, with τ = 1, we estimate the potential outcome for a given treatment
Wt+1 = ωt+1, where Wt+1 ∈{0, 1, . . . , K −1}, expressed as E(Yt+1(ωt+1) | Ht+1), which under
standard assumptions is identified as:"
BALANCED REPRESENTATION LEARNING,0.07861635220125786,"E(Yt+1(ωt+1) | Ht+1) = E(Yt+1 | Ht+1, Wt+1 = ωt+1)."
BALANCED REPRESENTATION LEARNING,0.08018867924528301,"The RHS can be estimated from data as E(Yt+1 | Ht+1, Wt+1) = f(Ht+1, Wt+1). Since only
one treatment is observed per individual at each time step, Wi,t+1 = ωi,t+1, our model ˆf gener-
ates counterfactual responses by switching treatments ˆf(hi,t+1, ω′
t+1), where ω′
t+1 ̸= ωt+1 (e.g.,
chemotherapy vs. radiotherapy). The challenge is that Ht+1 and Wt+1 are not independent, introduc-
ing potential bias in counterfactual estimation [61], leading to covariate shift or selection bias. To
address this, we learn a representation Φ(Ht+1) that enforces distributional balance during decoding."
BALANCED REPRESENTATION LEARNING,0.08176100628930817,"Setup
To mitigate selection bias, we leverage the context representation Ct of Ht and introduce
two sub-networks: one for response prediction and one for treatment prediction, both using a mapping
of the context representation:"
BALANCED REPRESENTATION LEARNING,0.08333333333333333,"Φt = SELU(Linear(Ct)) = ΦθR(Ht),"
BALANCED REPRESENTATION LEARNING,0.08490566037735849,"where SELU represents the Scaled Exponential Linear Unit [37], and θR denotes all parameters of the
representation learner, i.e., θR = [θ1, θ2]. Following [7, 48], our objective is to learn a representation
that accurately predicts outcomes while remaining distributionally balanced across all possible
treatment choices Wt = 0, 1, . . . , K −1. To achieve this, we frame the problem as an adversarial
game: one network learns to predict the next treatment from the representation, while a regularization
term ensures that the representation is non-predictive of the treatment."
BALANCED REPRESENTATION LEARNING,0.08647798742138364,"GRU
GRU CPC"
BALANCED REPRESENTATION LEARNING,0.0880503144654088,Process History
BALANCED REPRESENTATION LEARNING,0.08962264150943396,"Historical subsequence
Future subsequence"
BALANCED REPRESENTATION LEARNING,0.09119496855345911,Encode
BALANCED REPRESENTATION LEARNING,0.09276729559748427,Decoder
BALANCED REPRESENTATION LEARNING,0.09433962264150944,Encode GRU GRU Zoom
BALANCED REPRESENTATION LEARNING,0.0959119496855346,"GRU
GRU"
BALANCED REPRESENTATION LEARNING,0.09748427672955975,"GRU
GRU
GRU"
BALANCED REPRESENTATION LEARNING,0.09905660377358491,FC layers
BALANCED REPRESENTATION LEARNING,0.10062893081761007,Linear + Activation
BALANCED REPRESENTATION LEARNING,0.10220125786163523,Outcome Prediction Function
BALANCED REPRESENTATION LEARNING,0.10377358490566038,Treatment prediction Function
BALANCED REPRESENTATION LEARNING,0.10534591194968554,Legend:
BALANCED REPRESENTATION LEARNING,0.1069182389937107,"Figure 2: Causal CPC architecture: The left shows the encoder, which learns context Ct from process
history Ht, with CPC and InfoMax objectives used for pretraining. The right shows the decoder,
which autoregressively predicts the future outcome sequence from Ct."
BALANCED REPRESENTATION LEARNING,0.10849056603773585,"Factual response prediction
Since we intend to predict counterfactual responses for τ steps ahead
in time, we train a decoder to predict the factual responses Yt+1, . . . , Yt+τ given the sequence of
treatments (Wt+1, . . . , Wt+τ). We minimize the negative conditional likelihood"
BALANCED REPRESENTATION LEARNING,0.11006289308176101,"LY (θR, θY ) = −log pθY (yt+1:t+τ | Φt, ωt+1:t+τ) = − τ
X"
BALANCED REPRESENTATION LEARNING,0.11163522012578617,"j=1
log pθY (yt+j | yt+1:t+j−1, Φt, ωt+1:t+j)."
BALANCED REPRESENTATION LEARNING,0.11320754716981132,"We denote Ij
t := [Yt+1:t+j−1, Φt, Wt+1:t+j] and assume a Gaussian distribution for the conditional
responses Yt+j | Ij
t ∼N(GY (Ij
t ), σ2), where GY models the mean of the conditional response
(see right side of Figure 2). We set σ = 0.05 throughout our experiments. The response sequence is
estimated autoregressively using a GRU-based decoder without teacher forcing [81] to ensure model
training’s consistency with testing in real-world scenarios (Figure 2 and Algorithm 2 in Appendix H)."
BALANCED REPRESENTATION LEARNING,0.11477987421383648,"Treatment prediction
We learn a treatment prediction sub-network parameterized by θW that takes
as input the representation Φt+1 and predicts a distribution qθW (ωt+1 | Φt+1) over the treatment
Wt+1 by minimizing the negative log-likelihood, LW = −log qθW (ωt+1 | Φt+1). To assess the
quality of the representation in predicting the treatment, the gradient from LW only updates the
treatment network parameters θW and is not backpropagated through the response of the parameters
for the representation Φt+1 (Algorithm 2, Appendix H)."
BALANCED REPRESENTATION LEARNING,0.11635220125786164,"Adversarial learning
To create an adversarial game, we update the representation learning pa-
rameters, and in the next step, the treatment network qθW (· | Φt+1) with adverse losses such that
the representation Φt+1 becomes invariant with respect to the assignment of Wt+1. Different from
SOTA models (as highlighted in related work) and in line with our information guidelines principles,
learning a balanced representation Φt+1 amounts to ensuring Φt+1 ⊥⊥Wt+1, which is equivalent
to I(Φt+1, Wt+1) = 0. Hence, we minimize the MI as a way to confuse the treatment classifier.
Specifically, we minimize an upper bound on I(Φt+1, Wt+1), namely the CLUB of MI [13]."
BALANCED REPRESENTATION LEARNING,0.1179245283018868,"ICLUB(Φ(Ht), Wt+1; qθW ) := EP(Φ(Ht),Wt+1) [log qθW (Wt+1 | Φ(Ht+1))]"
BALANCED REPRESENTATION LEARNING,0.11949685534591195,"−EPΦ(Ht)EPWt+1 [log qθW (Wt+1 | Φ(Ht+1))] .
(9)"
BALANCED REPRESENTATION LEARNING,0.12106918238993711,"We use the objective in Eq. (9) to update the representation learner Φ(.) [9, 32]. This update aims
to minimize the discrepancy between the conditional likelihood of treatments for units sampled
from P(Ht,Wt+1) and the conditional likelihood of treatments under the assumption of independent
sampling from the product of marginals PHt+1 ⊗PWt+1. In practice, we generate samples from the
product of marginals by shuffling the treatment Wt+1 across the batch dimension similar to [9, 32].
When minimizing LW , qθW (ωt+1 | Φt+1) gets closer to the true conditional distribution p(ωt+1 |
Φt+1), and, in this case, the objective in Eq. (9) provides an upper bound of the MI between
representation and treatment. We formalize the intuition by adapting the result of [13]:"
BALANCED REPRESENTATION LEARNING,0.12264150943396226,"Theorem 5.3. [13] Let qθW (Φt+1, ωt+1) := qθW (ωt+1|Φt+1)p(Φt+1) be the joint distribution
induced by qθW (ωt+1|Φt+1) over the representation space of Φt+1. If:"
BALANCED REPRESENTATION LEARNING,0.12421383647798742,"DKL(p(Φt+1, ωt+1)||qθW (Φt+1, ωt+1)) ≤DKL(p(Φt+1)p(ωt+1)||qθW (Φt+1, ωt+1)),"
BALANCED REPRESENTATION LEARNING,0.12578616352201258,"then I(Φt+1, Wt+1) ≤ICLUB(Φt+1, Wt+1; q)."
BALANCED REPRESENTATION LEARNING,0.12735849056603774,"Based on Theorem 5.3, our adversarial training is interpretable and can be explained as follows:
the treatment classifier seeks to minimize EP(Ht,Wt+1) [LW ], which is equivalent to minimizing
Kullback-Leibler divergence DKL(p(Φt+1, ωt+1)||qθW (Φt+1, ωt+1)). Therefore, qθW (Φt+1, ωt+1)
could get closer to p(Φt+1, ωt+1) than, ultimately, to p(Φt+1)p(ωt+1), as we train the network to
predict Wt+1 from Φt+1. In such a case and by Theorem 5.3, ICLUB provides an upper bound on the
MI. Hence, in a subsequent step, we minimize ICLUB w.r.t the representation parameters, minimizing
the MI I(Φt+1, Wt+1) and achieving balance. We theoretically formulate such behavior by proving
in the following theorem that, at the Nash equilibrium of this adversarial game, the representation is
exactly balanced across the different treatment regimes provided by Wt+1."
BALANCED REPRESENTATION LEARNING,0.1289308176100629,"Theorem 5.4. Let t ∈{1, 2, . . . , tmax}, Φ = ΦθR and q = qθW are, respectively, any representation
and treatment network. Let PΦ(Ht) be the probability distribution over the representation space and
PΦ(Ht)|Wt+1 its conditional counterpart. Then, there exist Φ∗and q∗such that:"
BALANCED REPRESENTATION LEARNING,0.13050314465408805,"Φ∗= arg min
Φ ICLUB(Φ(Ht), Wt+1; q∗)"
BALANCED REPRESENTATION LEARNING,0.1320754716981132,"q∗= arg max
q
EPΦ∗(Ht) [log q(Wt+1 | Φ∗(Ht))] .
(10)"
BALANCED REPRESENTATION LEARNING,0.13364779874213836,"Such an equilibrium holds if and only if PΦ(Ht)|Wt+1=0 =PΦ(Ht)|Wt+1=1 =. . .=PΦ(Ht)|Wt+1=k−1,
almost surely."
BALANCED REPRESENTATION LEARNING,0.13522012578616352,"Since we target multi-timestep forecasting, covariate balancing in the representation space extends
beyond t+1. For simplicity, we presented it for t+1, but in practice, the adversarial game applies the
balancing across all forecasting horizons (Algorithm 2). The theorem also holds for other horizons
by replacing Φ(Ht) with Φ(Ht+j−1) and Wt+1 with Wt+j, for 2 ≤j ≤τ."
BALANCED REPRESENTATION LEARNING,0.13679245283018868,"Causal CPC Training
The Causal CPC model is trained in two stages: (1) Encoder pretraining:
We first learn an efficient representation of the process history by minimizing loss:"
BALANCED REPRESENTATION LEARNING,0.13836477987421383,"Lenc = LCP C(θ1, θ2, {Γj}τ
j=1) + L(InfoMax)(θ1, θ2, γ)."
BALANCED REPRESENTATION LEARNING,0.139937106918239,"(2) Decoder training: After pretraining, we fine-tune the encoder by optimizing the factual outcome
and treatment networks in the adversarial game from Theorem 5.4. Formally:"
BALANCED REPRESENTATION LEARNING,0.14150943396226415,"min
θR,θY Ldec(θR, θY , θW ) = LY (θR, θY ) + ICLUB(ΦθR(Ht), Wt+1; qθW ),"
BALANCED REPRESENTATION LEARNING,0.1430817610062893,"min
θW LW (θW , θR) = −EΦθR(Ht) [log qθW (Wt+1 | ΦθR(Ht))] ."
EXPERIMENTS,0.14465408805031446,"6
Experiments"
EXPERIMENTS,0.14622641509433962,"We compare Causal CPC with SOTA baselines: MSMs [64], RMSN [41], CRN [7], G-Net [39], and
CT [48]. All models are fine-tuned via a grid search over hyperparameters, including architecture
and optimizers. Model selection is based on mean squared error (MSE) on factual outcomes from a
validation set, and the same criterion is used for early stopping. Further details on hyperparameters
and training procedures are provided in Appendices J and D."
EXPERIMENTS WITH SYNTHETIC DATA,0.14779874213836477,"6.1
Experiments with Synthetic Data"
EXPERIMENTS WITH SYNTHETIC DATA,0.14937106918238993,"Tumor Growth
We use the PharmacoKinetic-PharmacoDynamic (PK-PD) model [24] to simulate
responses of non-small cell lung cancer patients, following previous works [41, 7, 48]. We evaluate
our approach on simulated counterfactual trajectories, varying the confounding level via the parameter
γ (Appendix E.1). Unlike [48], who used larger datasets (10,000 for training, 1,000 for testing),
we use a smaller, more challenging dataset (1,000 for training, 500 for testing) to reflect real-world
data limitations. For long-horizon forecasting, we set the prediction horizon to 10 and evaluate two
training sequence lengths: 60 and 40, with covariates of dimension 4."
EXPERIMENTS WITH SYNTHETIC DATA,0.1509433962264151,"2
4
6
8
10
Time Step 0.4 0.6 0.8 1.0 1.2 1.4 1.6 NRMSE"
EXPERIMENTS WITH SYNTHETIC DATA,0.15251572327044025,"Causal CPC
CT
G-Net
CRN
RMSN"
EXPERIMENTS WITH SYNTHETIC DATA,0.1540880503144654,"(a) γ = 1, sequence length 60"
EXPERIMENTS WITH SYNTHETIC DATA,0.15566037735849056,"1
2
3
4
5
6
7
8
9
10
Time Step 1.0 1.1 1.2 1.3 1.4 1.5 1.6 1.7 NRMSE"
EXPERIMENTS WITH SYNTHETIC DATA,0.15723270440251572,"Causal CPC
CT
G-Net
CRN
RMSN"
EXPERIMENTS WITH SYNTHETIC DATA,0.15880503144654087,"(b) γ = 2, sequence length 60"
EXPERIMENTS WITH SYNTHETIC DATA,0.16037735849056603,"2
4
6
8
10
Time Step 1.2 1.4 1.6 1.8 2.0 2.2 2.4 NRMSE"
EXPERIMENTS WITH SYNTHETIC DATA,0.1619496855345912,"Causal CPC
CT
G-Net
CRN
RMSN"
EXPERIMENTS WITH SYNTHETIC DATA,0.16352201257861634,"(c) γ = 3, sequence length 60"
EXPERIMENTS WITH SYNTHETIC DATA,0.1650943396226415,"2
4
6
8
10
Time Step 1.0 1.2 1.4 1.6 1.8 2.0 2.2 NRMSE"
EXPERIMENTS WITH SYNTHETIC DATA,0.16666666666666666,"Causal CPC
CT
G-Net
CRN
RMSN"
EXPERIMENTS WITH SYNTHETIC DATA,0.16823899371069181,"(d) γ = 1, sequence length 40"
EXPERIMENTS WITH SYNTHETIC DATA,0.16981132075471697,"2
4
6
8
10
Time Step 1.2 1.4 1.6 1.8 2.0 2.2 2.4 NRMSE"
EXPERIMENTS WITH SYNTHETIC DATA,0.17138364779874213,"Causal CPC
CT
G-Net
CRN
RMSN"
EXPERIMENTS WITH SYNTHETIC DATA,0.17295597484276728,"(e) γ = 2, sequence length 40"
EXPERIMENTS WITH SYNTHETIC DATA,0.17452830188679244,"2
4
6
8
10
Time Step 1.25 1.50 1.75 2.00 2.25 2.50 2.75 3.00 NRMSE"
EXPERIMENTS WITH SYNTHETIC DATA,0.1761006289308176,"Causal CPC
CT
G-Net
CRN
RMSN"
EXPERIMENTS WITH SYNTHETIC DATA,0.17767295597484276,"(f) γ = 3, sequence length 40"
EXPERIMENTS WITH SYNTHETIC DATA,0.1792452830188679,"Figure 3: Evolution of error (NRMSE) in estimating counterfactual responses for cancer simulation
data. Top: training sequence length 60. Bottom: training sequence length 40. In both cases, τ = 10.
MSM is excluded due to high prediction errors."
EXPERIMENTS WITH SYNTHETIC DATA,0.18081761006289307,"Results
We tested all models on the cancer simulation data across three confounding lev-
els, γ
=
1, 2, 3.
Figures 3a, 3b and 3c show the evolution of Normalized Root Mean
Squared Error (NRMSE) over counterfactual tumor volume as the prediction horizon in-
creases.
Causal CPC consistently outperforms all baselines at larger horizons, demonstrat-
ing its effectiveness in long-term predictions.
This confirms the quality of Ct in pre-
dicting future components across multiple time steps, capturing the global structure of the
process as discussed in Eq.
(5).
Extended results are provided in Appendix E.2.1."
EXPERIMENTS WITH SYNTHETIC DATA,0.18238993710691823,"2
4
6
8
10
12
14
Time Step 1.0 1.2 1.4 1.6 1.8 2.0 2.2 NRMSE"
EXPERIMENTS WITH SYNTHETIC DATA,0.18396226415094338,"Causal CPC
CT
G-Net
CRN
RMSN"
EXPERIMENTS WITH SYNTHETIC DATA,0.18553459119496854,"Figure 4: Models’ performance for can-
cer simulation, γ = 2, τ = 15."
EXPERIMENTS WITH SYNTHETIC DATA,0.1871069182389937,"In the more challenging case where the maximum se-
quence length is 40 (Figures 3d, 3e and 3f), the error
evolution remains similar to Figure 3a, 3b and 3c. Our
model maintains its advantage, outperforming most base-
lines in long-term forecasting. However, Causal CPC does
not outperform other models in short-term forecasting, a
consistent limitation across experiments. Still, the model’s
superior long-term performance highlights its potential in
applications requiring long-term accuracy. At higher lev-
els of confounding, the model does not always outperform
SOTA models at certain time steps. This may be due to the
low dimensionality of the time-varying components and
static covariates, Ut = [V, Xt, Wt−1, Yt−1], which have only four dimensions. Our model leverages
contrastive learning-based regularization to excel on datasets with higher confounding dimensions, as
demonstrated on MIMIC-III where Ut has 72 dimensions. In this setting, our model consistently
outperforms baselines at longer prediction horizons. The occasional underperformance of Causal
CPC at the final horizon is due to τ = 10 being the last contrasted horizon, not an issue specific
to τ = 10. To support this, we reran all models with a sequence length of 60, τ = 15, and γ = 2.
As shown in Figure 4, Causal CPC still outperforms SOTA for horizons beyond τ = 10 due to the
encoder’s retraining, where the InfoNCE loss is computed over all 15 time steps. The last prediction
error remains close to SOTA, suggesting that training over larger horizons than initially intended may
be beneficial."
EXPERIMENTS WITH SEMI-SYNTHETIC AND REAL DATA,0.18867924528301888,"6.2
Experiments with semi-synthetic and real data"
EXPERIMENTS WITH SEMI-SYNTHETIC AND REAL DATA,0.19025157232704404,"Semi-synthetic MIMIC-III
We used a semi-synthetic dataset constructed by [48] based on
the MIMIC-III dataset [35], incorporating both endogenous temporal dependencies and exoge-
nous dependencies from observational patient trajectories, as detailed in Appendix F.1.
The"
EXPERIMENTS WITH SEMI-SYNTHETIC AND REAL DATA,0.1918238993710692,"Table 1: Evolution of RMSEs for the semi-synthetic MIMIC III, sequence length 100."
EXPERIMENTS WITH SEMI-SYNTHETIC AND REAL DATA,0.19339622641509435,"Model
τ = 1
τ = 2
τ = 3
τ = 4
τ = 5
τ = 6
τ = 7
τ = 8
τ = 9
τ = 10
Causal CPC (ours)
0.32±0.04
0.45±0.08
0.54±0.06
0.61 ±0.10
0.66± 0.10
0.69±0.11
0.71± 0.11
0.73± 0.06
0.75 ± 0.05
0.77± 0.10
CT
0.42 ± 0.38
0.40± 0.06
0.52± 0.08
0.60± 0.005
0.67±0.10
0.72 ±0.12
0.77±0.13
0.81±0.14
0.85 ±0.16
0.88 ±0.17
G-Net
0.54 ± 0.13
0.72±0.14
0.85 ±0.16
0.96 ± 0.17
1.05 ± 0.18
1.14 ±0.18
1.24± 0.17
1.33±0.16
1.41 ± 0.16
1.49±0.16
CRN
0.27 ±0.03
0.45±0.08
0.58 ± 0.09
0.72± 0.11
0.82± 0.15
0.92 ± 0.20
1.00 ± 0.25
1.06 ± 0.28
1.12 ± 0.32
1.17 ± 0.35
RMSN
0.40 ± 0.16
0.70 ± 0.21
0.80± 0.19
0.88 ± 0.17
0.94 ± 0.16
1.00 ± 0.15
1.05 ± 0.14
1.10 ± 0.14
1.14 ± 0.13
1.18 ± 0.13"
EXPERIMENTS WITH SEMI-SYNTHETIC AND REAL DATA,0.1949685534591195,"patient trajectories are high-dimensional and exhibit long-range dependencies. Similar to the
cancer simulation, the training data consisted of relatively few sequences (500 for training,
100 for validation, and 400 for testing).
Table 1 presents the mean and standard deviation
of counterfactual predictions across multiple horizons (τ = 10).
We test two maximum se-
quence lengths, 100 and 60, to assess the models’ robustness for long-horizon forecasting."
EXPERIMENTS WITH SEMI-SYNTHETIC AND REAL DATA,0.19654088050314467,"2
4
6
8
10
Time Step 0.2 0.4 0.6 0.8 1.0 1.2 RMSE"
EXPERIMENTS WITH SEMI-SYNTHETIC AND REAL DATA,0.19811320754716982,"Causal CPC
CT
G-Net
CRN
RMSN"
EXPERIMENTS WITH SEMI-SYNTHETIC AND REAL DATA,0.19968553459119498,"Figure 5: Performance for MIMIC III
semi-synthetic, sequence length 60."
EXPERIMENTS WITH SEMI-SYNTHETIC AND REAL DATA,0.20125786163522014,"Results
Causal CPC consistently outperformed the base-
lines, especially at larger horizons, both with a sequence
length of 100 and a reduced length of 60 (Figures 1, 5).
Its superior performance at longer horizons is likely due
to the high number of covariates, making it well-suited to
contrastive-based training. We also tested the models with
800/200/200 individuals for training/validation/testing, as
in [48] (Appendix F.2.2), where Causal CPC achieved
state-of-the-art (SOTA) results comparable to CT but with
much shorter training and prediction times."
EXPERIMENTS WITH SEMI-SYNTHETIC AND REAL DATA,0.2028301886792453,"Table 2: Models complexity and the running time av-
eraged over five seeds. Results are reported for tu-
mor growth simulation (γ = 1). Hardware: GPU-
1xNVIDIA Tesla M60."
EXPERIMENTS WITH SEMI-SYNTHETIC AND REAL DATA,0.20440251572327045,"Model
Trainable parameters (k)
Training time (min)
Prediction time (min)"
EXPERIMENTS WITH SEMI-SYNTHETIC AND REAL DATA,0.2059748427672956,"Causal CPC (encoder + decoder)
8.2
16± 3
4 ± 1
CT
11
12± 2
30± 3
G-Net
1.2
2 ± 0.5
35 ± 3
CRN
5.2
13± 2
4± 1
RMSN
1.6
22± 2
4± 1
MSM
<0.1
1±0.5
1±0.5"
EXPERIMENTS WITH SEMI-SYNTHETIC AND REAL DATA,0.20754716981132076,"Table 3: Ablation study with NRMSE
averaged across (1 ≤τ ≤10) for cancer
simulation (γ = 1) and MIMIC III."
EXPERIMENTS WITH SEMI-SYNTHETIC AND REAL DATA,0.20911949685534592,"Model
Cancer_Sim
MIMIC III"
EXPERIMENTS WITH SEMI-SYNTHETIC AND REAL DATA,0.21069182389937108,"Causal CPC (Full)
1.05
0.62
Causal CPC (w/o L(InfoNCE))
1.07
0.68
Causal CPC (w/o L(InfoMax))
1.13
0.74
Causal CPC (w CDC loss)
1.07
0.73
Causal CPC (w/o balancing)
1.08
0.69"
EXPERIMENTS WITH SEMI-SYNTHETIC AND REAL DATA,0.21226415094339623,"Computational Efficiency and Model Complexity
Efficient execution is crucial for practical
deployment, especially with periodic retraining. Beyond training, challenges arise in evaluating
multiple counterfactual trajectories per individual, which grow exponentially with the forecasting
horizon as Kτ, where K is the number of possible treatments. This is particularly relevant when
generating multiple treatment plans, such as minimizing tumor volume. Table 2 shows the models’
complexity (number of parameters) and running time, split between model fitting and prediction.
Causal CPC is highly efficient during prediction due to its simple 1-layer GRU, similar to CRN
(1-layer LSTM), while providing better ITEs estimation. In contrast, CT is less efficient due to its
transformer architecture and teacher forcing, which requires recursive data loading during inference.
G-Net also has longer prediction times due to Monte Carlo sampling. Overall, Causal CPC strikes a
strong balance between accuracy and efficiency, making it well-suited under constrained resources."
EXPERIMENTS WITH SEMI-SYNTHETIC AND REAL DATA,0.2138364779874214,"2
4
6
8
10
Time Step 6 8 10 12 14 16 RMSE"
EXPERIMENTS WITH SEMI-SYNTHETIC AND REAL DATA,0.21540880503144655,"Causal CPC
CT
G-Net
CRN
RMSN"
EXPERIMENTS WITH SEMI-SYNTHETIC AND REAL DATA,0.2169811320754717,"Figure 6: Evolution of RMSEs, Real
MIMIC III, sequence length 100."
EXPERIMENTS WITH SEMI-SYNTHETIC AND REAL DATA,0.21855345911949686,"Real MIMIC-III Data
We evaluated our model on real
MIMIC-III data, where counterfactual trajectories cannot be
assessed due to the absence of observed counterfactual re-
sponses. However, performance can still be measured by fore-
casting factual (observed) responses over time. Our model es-
timates responses for each individual based on their observed
treatment trajectory. As shown in Figure 6, Causal CPC
consistently outperforms all baselines, especially at larger
horizons, demonstrating its robustness and effectiveness in
real-world settings."
DISCUSSION,0.22012578616352202,"7
Discussion"
DISCUSSION,0.22169811320754718,"Why does Causal CPC outperform SOTA at large horizons?
Our context Ct is designed to
capture shared information across future representations, particularly covariates, by minimizing the"
DISCUSSION,0.22327044025157233,"InfoNCE loss over multiple time steps (Eq. 1). As shown in Eq. (5), minimizing LCP C maximizes
shared information between the context and future components, helping capture the global structure of
the process. This is especially beneficial for counterfactual regression over long horizons, explaining
the model’s superior performance. However, it may not always outperform SOTA in shorter-term
predictions due to its focus on long-term dependencies."
DISCUSSION,0.2248427672955975,"Short-term Counterfactual Regression
While our model is designed for long-term predic-
tions, it may not consistently outperform SOTA for short-horizon tasks. However, the use of
contrastive loss, particularly InfoNCE (Eq. 4), suggests potential adaptability to balance both
short- and long-term predictions without retraining. A trade-off could be achieved by adjust-
ing the contrastive term weights across time steps in Eq. (4), which we leave for future work."
DISCUSSION,0.22641509433962265,"2
4
6
8
10
Time Step 0.3 0.4 0.5 0.6 0.7 0.8 0.9 RMSE"
DISCUSSION,0.2279874213836478,"Full
w/o InfoNCE loss
w/o InfoMax loss
w/o balancing
w CDC loss"
DISCUSSION,0.22955974842767296,"Figure 7: Ablation study of Causal CPC
on MIMIC III."
DISCUSSION,0.23113207547169812,"Ablation study
We examined the model’s performance
in various configurations—full model, without CPC, and
without InfoMax. Table 3 and Figure 7 show that remov-
ing either term reduces counterfactual accuracy across all
horizons, underscoring their significance. Additionally,
replacing our ICLUB objective with CDC loss [48] or
removing balancing increases errors. We also tested differ-
ent MI lower bounds like NWJ [50] and MINE [4] for both
CPC and InfoMax (Appendix C.2), finding that InfoNCE
yielded the best results (Table 10). Full ablation results
are in Appendices E.2.2 and F.2.1."
DISCUSSION,0.23270440251572327,"Falsifiability Test
This study assumes sequential ignorability, common in causal inference [41,
7, 39, 48]. To assess robustness, we performed a falsifiability test by omitting certain confounders
during training, while they remained in MIMIC-III data construction. As seen in Table 4, violating
sequential ignorability increased prediction errors for Causal CPC, CT, and CRN, though RMSN was
less affected but underperformed at τ ≥2. Despite this, Causal CPC maintained its lead at larger
horizons, demonstrating strong encoding of long-term dependencies."
DISCUSSION,0.23427672955974843,Table 4: Results on the MIMIC III when sequential ignorability is violated reported by RMSEs
DISCUSSION,0.2358490566037736,"Model
τ = 1
τ = 2
τ = 3
τ = 4
τ = 5
τ = 6
τ = 7
τ = 8
τ = 9
τ = 10
Causal CPC
0.44± 0.04
0.56± 0.07
0.66±0.07
0.73 ± 0.08
0.78± 0.08
0.83±0.06
0.86± 0.10
0.88± 0.08
0.91 ± 0.08
0.95± 0.07
Causal Transformer
0.34±0.07
0.48±0.07
0.60±0.07
0.68±0.06
0.75± 0.06
0.80±0.07
0.86± 0.09
0.91±0.11
0.95 ±0.13
1.00 ±0.15
CRN
0.40± 0.07
0.54± 0.09
0.70± 0.09
0.84± 0.09
0.97± 0.09
1.08± 0.13
1.18± 0.16
1.26± 0.19
1.33± 0.21
1.39± 0.23
RMSN
0.38± 0.08
0.67± 0.21
0.78± 0.16
0.84± 0.14
0.91± 0.14
0.98± 0.15
1.04± 0.16
1.09± 0.18
1.15± 0.19
1.20± 0.23"
DISCUSSION,0.23742138364779874,"Tightness of MI Upper Bounds
Estimating MI bounds for high-dimensional variables is chal-
lenging and expensive [59, 57], often limited to low-dimensional inputs or Gaussian assumptions.
In MI-constrained models, batch size is crucial. As shown in Eq. (3), increasing the batch size B
tightens the lower bound via log(|B|), and to balance memory and performance, we chose batch
sizes of 256 for the encoder and 128 for the decoder. While these bounds may not be perfectly tight,
mutual information and self-supervision biases significantly enhance performance (Appendix C.2),
as confirmed by ablation studies. Other MI estimators like NWJ and MINE [50, 4] did not improve
performance; our initial setup consistently performed better (Appendix F.2.1)."
DISCUSSION,0.2389937106918239,"Extending Causal CPC to Continuous Treatment
Our approach could be extended to continuous
treatments by replacing the treatment classifier with a regressor. Since the method maximizes
likelihood, the equilibrium in Theorem 5.4 remains valid. However, in practice, continuous treatments
will be represented by a single dimension, unlike discrete treatments with K-dimensional one-hot
encoding. This risks losing important treatment information in counterfactual predictions. A simpler
adaptation to our model could involve discretizing continuous treatments."
DISCUSSION,0.24056603773584906,"Conclusion
We introduced a novel approach to long-term counterfactual regression, combining
RNNs with CPC to achieve SOTA results without relying on complex transformer models. Prioritizing
computational efficiency, we incorporated contrastive loss-based regularization guided by mutual
information (MI). Our method consistently outperforms existing models on both synthetic and real-
world datasets, marking the first application of CPC in causal inference. Future work could focus on
improving interpretability by integrating Shapley values into the causal framework [30]. Additionally,
developing uncertainty-aware models tailored for longitudinal data is crucial for enhancing the
reliability of predictions in our causal framework [19, 33, 84]."
REFERENCES,0.24213836477987422,References
REFERENCES,0.24371069182389937,"[1] S. Arora, H. Khandeparkar, M. Khodak, O. Plevrakis, and N. Saunshi. A theoretical analysis of
contrastive unsupervised representation learning. arXiv preprint arXiv:1902.09229, 2019."
REFERENCES,0.24528301886792453,"[2] O. Atan, J. Jordon, and M. Van der Schaar. Deep-treat: Learning optimal personalized treatments
from observational data using neural networks. In Proceedings of the AAAI Conference on
Artificial Intelligence, volume 32, 2018."
REFERENCES,0.2468553459119497,"[3] P. Bachman, R. D. Hjelm, and W. Buchwalter. Learning representations by maximizing mutual
information across views. Advances in neural information processing systems, 32, 2019."
REFERENCES,0.24842767295597484,"[4] M. I. Belghazi, A. Baratin, S. Rajeshwar, S. Ozair, Y. Bengio, A. Courville, and D. Hjelm.
Mutual information neural estimation. In International conference on machine learning, pages
531–540. PMLR, 2018."
REFERENCES,0.25,"[5] A. J. Bell and T. J. Sejnowski. An information-maximization approach to blind separation and
blind deconvolution. Neural computation, 7(6):1129–1159, 1995."
REFERENCES,0.25157232704402516,"[6] J. Berrevoets, A. Curth, I. Bica, E. McKinney, and M. van der Schaar.
Disentangled
counterfactual recurrent networks for treatment effect inference over time. arXiv preprint
arXiv:2112.03811, 2021."
REFERENCES,0.2531446540880503,"[7] I. Bica, A. M. Alaa, J. Jordon, and M. van der Schaar.
Estimating counterfactual treat-
ment outcomes over time through adversarially balanced representations.
arXiv preprint
arXiv:2002.04083, 2020."
REFERENCES,0.25471698113207547,"[8] I. Bica, A. M. Alaa, and M. van der Schaar. Time series deconfounder: Estimating treatment
effects over time in the presence of hidden confounders. In International Conference on Machine
Learning, 2020."
REFERENCES,0.2562893081761006,"[9] P. Brakel and Y. Bengio. Learning independent features with adversarial nets for non-linear ica.
arXiv preprint arXiv:1710.05050, 2017."
REFERENCES,0.2578616352201258,"[10] D. Cao, J. Enouen, and Y. Liu. Estimating treatment effects in continuous time with hidden
confounders. arXiv e-prints, pages arXiv–2302, 2023."
REFERENCES,0.25943396226415094,"[11] Y. Chen, A. Prati, J. Montgomery, and R. Garnett. A multi-task gaussian process model for
inferring time-varying treatment effects in panel data. In International Conference on Artificial
Intelligence and Statistics, pages 4068–4088. PMLR, 2023."
REFERENCES,0.2610062893081761,"[12] L. Cheng, R. Guo, and H. Liu. Causal mediation analysis with hidden confounders. Proceedings
of the Fifteenth ACM International Conference on Web Search and Data Mining, null:null,
2021."
REFERENCES,0.26257861635220126,"[13] P. Cheng, W. Hao, S. Dai, J. Liu, Z. Gan, and L. Carin. Club: A contrastive log-ratio upper bound
of mutual information. In International conference on machine learning, pages 1779–1788.
PMLR, 2020."
REFERENCES,0.2641509433962264,"[14] K. Cho, B. Van Merriënboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, and
Y. Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine
translation. arXiv preprint arXiv:1406.1078, 2014."
REFERENCES,0.26572327044025157,"[15] E. Choi, M. T. Bahadori, J. Sun, J. Kulas, A. Schuetz, and W. Stewart. Retain: An interpretable
predictive model for healthcare using reverse time attention mechanism. Advances in neural
information processing systems, 29, 2016."
REFERENCES,0.2672955974842767,"[16] Z. Chu, S. L. Rathbun, and S. Li. Learning infomax and domain-independent representations
for causal effect inference with real-world data. In Proceedings of the 2022 SIAM International
Conference on Data Mining (SDM), pages 433–441. SIAM, 2022."
REFERENCES,0.2688679245283019,"[17] T. M. Cover. Elements of information theory. John Wiley & Sons, 1999."
REFERENCES,0.27044025157232704,"[18] I. Daunhawer, A. Bizeul, E. Palumbo, A. Marx, and J. E. Vogt. Identifiability results for
multimodal contrastive learning. arXiv preprint arXiv:2303.09166, 2023."
REFERENCES,0.2720125786163522,"[19] E. De Brouwer, J. Gonzalez, and S. Hyland. Predicting the impact of treatments over time
with uncertainty aware neural differential equations. In International Conference on Artificial
Intelligence and Statistics, pages 4705–4722. PMLR, 2022."
REFERENCES,0.27358490566037735,"[20] M. D. Donsker and S. S. Varadhan. Asymptotic evaluation of certain markov process expec-
tations for large time. iv. Communications on pure and applied mathematics, 36(2):183–212,
1983."
REFERENCES,0.2751572327044025,"[21] W. Falcon and The PyTorch Lightning team. PyTorch Lightning, Mar. 2019."
REFERENCES,0.27672955974842767,"[22] D. Frauen, T. Hatt, V. Melnychuk, and S. Feuerriegel. Estimating average causal effects from
patient trajectories. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37,
pages 7586–7594, 2023."
REFERENCES,0.2783018867924528,"[23] Y. Ganin and V. Lempitsky. Unsupervised domain adaptation by backpropagation. In Interna-
tional conference on machine learning, pages 1180–1189. PMLR, 2015."
REFERENCES,0.279874213836478,"[24] C. Geng, H. Paganetti, and C. Grassberger. Prediction of treatment response for combined
chemo-and radiation therapy for non-small cell lung cancer patients using a bio-mathematical
model. Scientific reports, 7(1):1–12, 2017."
REFERENCES,0.28144654088050314,"[25] M. Gutmann and A. Hyvärinen. Noise-contrastive estimation: A new estimation principle
for unnormalized statistical models. In Proceedings of the thirteenth international conference
on artificial intelligence and statistics, pages 297–304. JMLR Workshop and Conference
Proceedings, 2010."
REFERENCES,0.2830188679245283,"[26] M. U. Gutmann and A. Hyvärinen. Noise-contrastive estimation of unnormalized statistical
models, with applications to natural image statistics. Journal of machine learning research,
13(2), 2012."
REFERENCES,0.28459119496855345,"[27] J. Z. HaoChen, C. Wei, A. Gaidon, and T. Ma. Provable guarantees for self-supervised deep
learning with spectral contrastive loss. Advances in Neural Information Processing Systems,
34:5000–5011, 2021."
REFERENCES,0.2861635220125786,"[28] T. Hatt and S. Feuerriegel. Sequential deconfounding for causal inference with unobserved
confounders. arXiv preprint arXiv:2104.09323, 2021."
REFERENCES,0.28773584905660377,"[29] O. Henaff. Data-efficient image recognition with contrastive predictive coding. In International
conference on machine learning, pages 4182–4192. PMLR, 2020."
REFERENCES,0.2893081761006289,"[30] T. Heskes, E. Sijben, I. G. Bucur, and T. Claassen. Causal shapley values: Exploiting causal
knowledge to explain individual predictions of complex models. Advances in neural information
processing systems, 33:4778–4789, 2020."
REFERENCES,0.2908805031446541,"[31] Ç. Hızlı, S. John, A. T. Juuti, T. T. Saarinen, K. H. Pietiläinen, and P. Marttinen. Causal modeling
of policy interventions from treatment-outcome sequences. In International Conference on
Machine Learning, pages 13050–13084. PMLR, 2023."
REFERENCES,0.29245283018867924,"[32] R. D. Hjelm, A. Fedorov, S. Lavoie-Marchildon, K. Grewal, P. Bachman, A. Trischler, and
Y. Bengio. Learning deep representations by mutual information estimation and maximization.
In International Conference on Learning Representations, 2019."
REFERENCES,0.2940251572327044,"[33] A. Jesson, S. Mindermann, U. Shalit, and Y. Gal. Identifying causal-effect inference failure
with uncertainty-aware models. Advances in Neural Information Processing Systems, 33:11637–
11649, 2020."
REFERENCES,0.29559748427672955,"[34] S. Jiang, Z. Huang, X. Luo, and Y. Sun. Cf-gode: Continuous-time causal inference for multi-
agent dynamical systems. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining, KDD ’23, page 997–1009, New York, NY, USA, 2023. Association
for Computing Machinery."
REFERENCES,0.2971698113207547,"[35] A. E. Johnson, T. J. Pollard, L. Shen, L.-w. H. Lehman, M. Feng, M. Ghassemi, B. Moody,
P. Szolovits, L. Anthony Celi, and R. G. Mark. Mimic-iii, a freely accessible critical care
database. Scientific data, 3(1):1–9, 2016."
REFERENCES,0.29874213836477986,"[36] D. P. Kingma and J. Ba.
Adam: A method for stochastic optimization.
arXiv preprint
arXiv:1412.6980, 2014."
REFERENCES,0.300314465408805,"[37] G. Klambauer, T. Unterthiner, A. Mayr, and S. Hochreiter. Self-normalizing neural networks.
Advances in neural information processing systems, 30, 2017."
REFERENCES,0.3018867924528302,"[38] M. Kuzmanovic, T. Hatt, and S. Feuerriegel. Deconfounding temporal autoencoder: estimating
treatment effects over time using noisy proxies. In Machine Learning for Health, pages 143–155.
PMLR, 2021."
REFERENCES,0.30345911949685533,"[39] R. Li, S. Hu, M. Lu, Y. Utsumi, P. Chakraborty, D. M. Sow, P. Madan, J. Li, M. F. Ghalwash,
Z. Shahn, and L. wei H. Lehman. G-net: a recurrent network approach to g-computation for
counterfactual prediction under a dynamic treatment regime. In ML4H@NeurIPS, 2021."
REFERENCES,0.3050314465408805,"[40] P. P. Liang, Z. Deng, M. Ma, J. Zou, L.-P. Morency, and R. Salakhutdinov. Factorized contrastive
learning: Going beyond multi-view redundancy. In Advances in Neural Information Processing
Systems, 2023."
REFERENCES,0.30660377358490565,"[41] B. Lim. Forecasting treatment responses over time using recurrent marginal structural networks.
advances in neural information processing systems, 31, 2018."
REFERENCES,0.3081761006289308,"[42] B. Lim. Forecasting treatment responses over time using recurrent marginal structural networks.
advances in neural information processing systems, 31, 2018."
REFERENCES,0.30974842767295596,"[43] R. Linsker. Self-organization in a perceptual network. Computer, 21(3):105–117, 1988."
REFERENCES,0.3113207547169811,"[44] Y. Liu, Z. Zhang, D. Gong, B. Huang, M. Gong, A. v. d. Hengel, K. Zhang, and J. Q. Shi.
Revealing multimodal contrastive representation learning through latent partial causal models.
arXiv preprint arXiv:2402.06223, 2024."
REFERENCES,0.3128930817610063,"[45] M. J. Lopez and R. Gutman. Estimation of causal effects with multiple treatments: a review
and new ideas. Statistical Science, pages 432–454, 2017."
REFERENCES,0.31446540880503143,"[46] I. Loshchilov and F. Hutter.
Decoupled weight decay regularization.
arXiv preprint
arXiv:1711.05101, 2017."
REFERENCES,0.3160377358490566,"[47] S. Matthes, Z. Han, and H. Shen. Towards a unified framework of contrastive learning for
disentangled representations. Advances in Neural Information Processing Systems, 36:67459–
67470, 2023."
REFERENCES,0.31761006289308175,"[48] V. Melnychuk, D. Frauen, and S. Feuerriegel. Causal transformer for estimating counterfactual
outcomes. ArXiv, abs/2204.07258, 2022."
REFERENCES,0.3191823899371069,"[49] S. Mueller and J. Pearl. Personalized decision making–a conceptual introduction. Journal of
Causal Inference, 11(1):20220050, 2023."
REFERENCES,0.32075471698113206,"[50] X. Nguyen, M. J. Wainwright, and M. I. Jordan. Estimating divergence functionals and the
likelihood ratio by convex risk minimization. IEEE Transactions on Information Theory,
56(11):5847–5861, 2010."
REFERENCES,0.3223270440251572,"[51] S. Nowozin, B. Cseke, and R. Tomioka. f-gan: Training generative neural samplers using
variational divergence minimization. Advances in neural information processing systems, 29,
2016."
REFERENCES,0.3238993710691824,"[52] A. v. d. Oord, Y. Li, and O. Vinyals. Representation learning with contrastive predictive coding.
arXiv preprint arXiv:1807.03748, 2018."
REFERENCES,0.32547169811320753,"[53] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin,
N. Gimelshein, L. Antiga, A. Desmaison, A. Köpf, E. Yang, Z. DeVito, M. Raison, A. Tejani,
S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, and S. Chintala. Pytorch: An imperative style,
high-performance deep learning library. In Neural Information Processing Systems, 2019."
REFERENCES,0.3270440251572327,"[54] T. Pham, T. Tran, D. Phung, and S. Venkatesh. Predicting healthcare trajectories from medical
records: A deep learning approach. Journal of biomedical informatics, 69:218–229, 2017."
REFERENCES,0.32861635220125784,"[55] R. W. Platt, E. F. Schisterman, and S. R. Cole. Time-modified confounding. American journal
of epidemiology, 170(6):687–694, 2009."
REFERENCES,0.330188679245283,"[56] B. Poole, S. Ozair, A. Van Den Oord, A. Alemi, and G. Tucker. On variational bounds of mutual
information. In International Conference on Machine Learning, pages 5171–5180. PMLR,
2019."
REFERENCES,0.33176100628930816,"[57] B. Poole, S. Ozair, A. Van Den Oord, A. Alemi, and G. Tucker. On variational bounds of mutual
information. In International Conference on Machine Learning, pages 5171–5180. PMLR,
2019."
REFERENCES,0.3333333333333333,"[58] Z. Qian, Y. Zhang, I. Bica, A. Wood, and M. van der Schaar. Synctwin: Treatment effect
estimation with longitudinal outcomes. Advances in Neural Information Processing Systems,
34:3178–3190, 2021."
REFERENCES,0.33490566037735847,"[59] T. Rainforth, A. Kosiorek, T. A. Le, C. Maddison, M. Igl, F. Wood, and Y. W. Teh. Tighter
variational bounds are not necessarily better. In International Conference on Machine Learning,
pages 4277–4285. PMLR, 2018."
REFERENCES,0.33647798742138363,"[60] R. Ranganath and A. Perotte. Multiple causal inference with latent confounding. arXiv preprint
arXiv:1805.08273, 2018."
REFERENCES,0.3380503144654088,"[61] J. M. Robins. Association, causation, and marginal structural models. Synthese, 121(1/2):151–
179, 1999."
REFERENCES,0.33962264150943394,"[62] J. M. Robins and M. A. Hernán. Estimation of the causal effects of time-varying exposures.
Longitudinal data analysis, 553:599, 2009."
REFERENCES,0.3411949685534591,"[63] J. M. Robins and M. A. Hernán. Estimation of the causal effects of time-varying exposures.
Longitudinal data analysis, 553:599, 2009."
REFERENCES,0.34276729559748426,"[64] J. M. Robins, M. A. Hernan, and B. Brumback. Marginal structural models and causal inference
in epidemiology, 2000."
REFERENCES,0.3443396226415094,"[65] D. B. Rubin. Causal inference using potential outcomes: Design, modeling, decisions. Journal
of the American Statistical Association, 100(469):322–331, 2005."
REFERENCES,0.34591194968553457,"[66] N. Saunshi, J. Ash, S. Goel, D. Misra, C. Zhang, S. Arora, S. Kakade, and A. Krishnamurthy.
Understanding contrastive learning requires incorporating inductive biases. In International
Conference on Machine Learning, pages 19250–19286. PMLR, 2022."
REFERENCES,0.3474842767295597,"[67] E. F. Schisterman, S. R. Cole, and R. W. Platt. Overadjustment bias and unnecessary adjustment
in epidemiologic studies. Epidemiology (Cambridge, Mass.), 20(4):488, 2009."
REFERENCES,0.3490566037735849,"[68] P. Schulam and S. Saria. Reliable decision support using counterfactual models. Advances in
neural information processing systems, 30, 2017."
REFERENCES,0.35062893081761004,"[69] N. Seedat, F. Imrie, A. Bellot, Z. Qian, and M. van der Schaar. Continuous-time modeling
of counterfactual outcomes using neural controlled differential equations. arXiv preprint
arXiv:2206.08311, 2022."
REFERENCES,0.3522012578616352,"[70] U. Shalit. Can we learn individual-level treatment policies from clinical data? Biostatistics,
21(2):359–362, 2020."
REFERENCES,0.35377358490566035,"[71] R. Shwartz Ziv and Y. LeCun. To compress or not to compress—self-supervised learning and
information theory: A review. Entropy, 26(3):252, 2024."
REFERENCES,0.3553459119496855,"[72] H. Soleimani, J. Hensman, and S. Saria. Scalable joint models for reliable uncertainty-aware
event prediction. IEEE transactions on pattern analysis and machine intelligence, 40(8):1948–
1963, 2017."
REFERENCES,0.35691823899371067,"[73] H. Soleimani, A. Subbaswamy, and S. Saria. Treatment-response models for counterfactual
reasoning with continuous-time, continuous-valued interventions. ArXiv, abs/1704.02038, 2017."
REFERENCES,0.3584905660377358,"[74] I. Sutskever, J. Martens, G. Dahl, and G. Hinton. On the importance of initialization and
momentum in deep learning. In International conference on machine learning, pages 1139–
1147. PMLR."
REFERENCES,0.360062893081761,"[75] Y. Tian, D. Krishnan, and P. Isola. Contrastive multiview coding. In Computer Vision–ECCV
2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XI 16,
pages 776–794. Springer, 2020."
REFERENCES,0.36163522012578614,"[76] C. Tosh, A. Krishnamurthy, and D. Hsu. Contrastive learning, multi-view redundancy, and
linear models. In Algorithmic Learning Theory, pages 1179–1206. PMLR, 2021."
REFERENCES,0.3632075471698113,"[77] M. Tschannen, J. Djolonga, P. K. Rubenstein, S. Gelly, and M. Lucic. On mutual infor-
mation maximization for representation learning. In International Conference on Learning
Representations, 2020."
REFERENCES,0.36477987421383645,"[78] E. Tzeng, J. Hoffman, T. Darrell, and K. Saenko. Simultaneous deep transfer across domains
and tasks. In Proceedings of the IEEE international conference on computer vision, pages
4068–4076, 2015."
REFERENCES,0.3663522012578616,"[79] V. Veitch, D. Sridhar, and D. Blei. Adapting text embeddings for causal inference. In Conference
on Uncertainty in Artificial Intelligence, pages 919–928. PMLR, 2020."
REFERENCES,0.36792452830188677,"[80] Y. Wang and D. M. Blei. The blessings of multiple causes. Journal of the American Statistical
Association, 114(528):1574–1596, 2019."
REFERENCES,0.3694968553459119,"[81] R. J. Williams and D. Zipser. A learning algorithm for continually running fully recurrent neural
networks. Neural computation, 1(2):270–280, 1989."
REFERENCES,0.3710691823899371,"[82] S. Wu, W. Zhou, M. Chen, and S. Zhu. Counterfactual generative models for time-varying
treatments. arXiv preprint arXiv:2305.15742, 2023."
REFERENCES,0.37264150943396224,"[83] Y. Yazıcı, C.-S. Foo, S. Winkler, K.-H. Yap, G. Piliouras, and V. Chandrasekhar. The un-
usual effectiveness of averaging in GAN training. In International Conference on Learning
Representations, 2019."
REFERENCES,0.3742138364779874,"[84] M. Yin, C. Shi, Y. Wang, and D. M. Blei. Conformal sensitivity analysis for individual treatment
effects. Journal of the American Statistical Association, 119(545):122–135, 2024."
REFERENCES,0.3757861635220126,"[85] N. Zhao, Z. Wu, R. W. Lau, and S. Lin. What makes instance discrimination good for transfer
learning? arXiv preprint arXiv:2006.06606, 2020."
REFERENCES,0.37735849056603776,"[86] R. S. Zimmermann, Y. Sharma, S. Schneider, M. Bethge, and W. Brendel. Contrastive learning
inverts the data generating process. In International Conference on Machine Learning, pages
12979–12990. PMLR, 2021."
REFERENCES,0.3789308176100629,"A
Impact Statements"
REFERENCES,0.3805031446540881,"Our paper seeks to advance the field of Trustworthy Machine Learning by focusing on the accurate
estimation of counterfactual trajectories. This capability holds significant potential to enhance
decision-making processes across various domains, particularly in healthcare, where clinicians can
leverage models designed to mitigate bias and promote fairness. Additionally, by focusing on
efficiency, our contributions extend beyond traditional machine learning considerations to address
environmental concerns associated with energy consumption. By advocating for the prudent use of
computational resources, especially in training complex models deployed in real-world scenarios, we
aim to promote sustainability in developing and applying machine learning solutions."
REFERENCES,0.38207547169811323,"B
Causal assumptions"
REFERENCES,0.3836477987421384,"B.1
Identifiability Assumptions in Causal CPC"
REFERENCES,0.38522012578616355,"In this section, we detail the assumptions used for the identifiability of the counterfactual responses
E(Yt+τ(ωt+1:t+τ) | Ht+1). As briefly stated in Section 3, we follows similar assumptions to
[62, 64, 7, 48], namely"
REFERENCES,0.3867924528301887,"Assumption B.1 (Consistency). For every time step t and given any manner by which a unit i receives
the sequence of treatment ωi,≤t, we always observe the potential outcome Yit(ωi,≤t). Formally:"
REFERENCES,0.38836477987421386,"Wi,≤t = wi,≤t =⇒Yit = Yit(wi,≤t)."
REFERENCES,0.389937106918239,"Assumption B.2 (Sequential Ignorability). Given any time step t, we have the conditional indepen-
dence:
Yit(ωit) ⊥⊥Wit|Hit = hit
∀(ωit, hit)"
REFERENCES,0.3915094339622642,"Assumption B.3 (Overlap/positivity). Given any time step t, and for any possible historical context
ht, the probability of observing any of the possible treatment regimes is strictly positive but not
deterministic:
p(ht) ̸= 0 =⇒0 < p(Wt = ωt|ht) < 1"
REFERENCES,0.39308176100628933,"The three assumptions are sufficient for the identification of the counterfactual responses from
observational data, which we formulate in the following proposition."
REFERENCES,0.3946540880503145,"Proposition B.4. Assuming consistency, overlap, and ignorability (assumptions B.1, B.2, B.3), the
causal quantity E(Yt+τ(ωt+1:t+τ) | Ht+1) is identifiable from observational data following"
REFERENCES,0.39622641509433965,"E(Yt+τ(ωt+1:t+τ) | Ht+1) = E (Yt+τ | Ht+1, Wt+1:t+τ = ωt+1:t+τ)"
REFERENCES,0.3977987421383648,Proof. See [62]
REFERENCES,0.39937106918238996,"B.2
On the Causal Graph"
REFERENCES,0.4009433962264151,"We repeat the causal graph introduced in Figure 1 to explain the data generation process. here,
all of the past observed data encompassed in Ht+1 confounds future treatments and responses,
Wt+1, Wt+2, . . . , Wtmax and Yt+1, Yt+2, . . . , Ytmax, which create long-term dependencies. The fact
that post-covariates are affected by past treatments creates time-dependent confounding. The static
covariates are assumed to be affecting all of the time-varying variables. Since we suppose sequential
ignorability, there are no possible exogenous noises affecting both treatments and responses. However,
such noise may possibly affect responses, time-varying covariates, and response variables.
In the figure, for simplicity, we represent past treatments as W≤t such that each element in that
sub-sequence confounds the next treatment and response Wt+1 and Yt+1. Idem for Y≤t and X≤t.
The static covariates V are assumed to be affecting all the time-varying variables. We omit the
representation of exogenous noise for simplicity. Interactions between W≤t , X≤t, and Y≤t were
also omitted for simplicity. Y≤t W≤t X≤t Yt+1 Wt+1 Xt+1 V"
REFERENCES,0.4025157232704403,"C
Extended related work"
REFERENCES,0.40408805031446543,"C.1
Counterfactual regression over time: Methods overview"
REFERENCES,0.4056603773584906,"C.1.1
Methods included in experiments"
REFERENCES,0.40723270440251574,"In this section, we give a brief overview of models included in our experiments: MSMs [62], RMSN
[41], CRN [7], G-Net [39], and CT [48]. To delineate the differences between these models and
Causal CPC, we detail in Table 5 the main design differences between all these models."
REFERENCES,0.4088050314465409,"Table 5: A summary of the methods included in our experiments
Model
Model Backbone
Tailored to long-term
forecast?"
REFERENCES,0.41037735849056606,"Learning
of
long-
term dependencies"
REFERENCES,0.4119496855345912,"Use
of
contrastive
learning"
REFERENCES,0.41352201257861637,"Prediction of counter-
factuals"
REFERENCES,0.41509433962264153,"handling
selection
bias"
REFERENCES,0.4166666666666667,"Invertibility of repre-
sentation
Causal CPC (ours)
GRU
yes
CPC
learn long-term rela-
tions"
REFERENCES,0.41823899371069184,"Autoregressive
Balanced representa-
tion"
REFERENCES,0.419811320754717,"yes, contrast represen-
tation with input
CT
3 Transformers
yes
Transformer architec-
ture"
REFERENCES,0.42138364779874216,"N/A
Autoregressive
Balanced representa-
tion N/A"
REFERENCES,0.4229559748427673,"G-Net
LSTM
No
N/A
N/A
Autoregressive
G-Computation
Current covariates Xt
CRN
LSTM
No
N/A
N/A
Autoregressive
Balanced representa-
tion N/A"
REFERENCES,0.42452830188679247,"RMSN
LSTM
No
N/A
N/A
Autoregressive
Weighting
N/A
MSM
Logistic+linear
model"
REFERENCES,0.4261006289308176,"No
N/A
N/A
Autoregressive
Weighting
N/A"
REFERENCES,0.4276729559748428,"C.1.2
Methods Violating Our Assumptions"
REFERENCES,0.42924528301886794,"Our work relies on the assumption of sequential ignorability, yet several alternative models operate
under different assumptions, often addressing the presence of unobserved confounders. Some of these
models are rooted in deconfounding theory [45, 60, 80], which has been extended to time-varying
settings. Deconfounding involves imposing a factor model on treatment assignment, where each
treatment becomes conditionally independent given latent variables that act as proxies for unobserved
confounders. Examples of this approach include [8, 28, 10]. Other models assume the presence of
proxy variables, inferring a representation of unobserved confounders through probabilistic models
based on these proxies [79, 12, 38].
In contrast to our setting, which is governed by the three causal assumptions in Appendix B.1, many
models assume a data-generating process similar to [73, 72, 58]. These methods, often non- or semi-
parametric, tend to either ignore static covariates or handle them linearly, leading to computational
inefficiencies and scalability issues. Nevertheless, some non- or semi-parametric approaches—such
as [68, 69, 19, 31]—align with our causal assumptions but extend them to continuous time, treating
sequential ignorability in a continuous setting.
Additionally, models like [34] incorporate continuous-time and assume interactions between units,
where an individual’s outcome depends on both their treatment and the treatments of others. [6], focus-
ing on binary treatment sequences, requires a stronger version of sequential ignorability—conditional
on current covariates—whereas our model assumes a weaker version, conditioning on the entire
history of covariates to account for long-lasting confounding effects.
Furthermore, [11] focuses solely on binary treatments and targets the estimation of the average treat-
ment effect on the treated (ATT). The authors assume a specific treatment regime, where individuals
enter a post-treatment state after a defined point in time. This assumption is restrictive compared
to our framework, which allows for complex, individualized treatment assignment mechanisms"
REFERENCES,0.4308176100628931,"and non-binary treatments, where treatment values can fluctuate over time. As a result, [11] is
incompatible with our causal assumptions.
Other methods, like [82], address high-dimensional counterfactual generation based on time-varying
treatment plans under the same sequential ignorability assumption. However, they are not designed
for causal forecasting over multiple time steps, as required in our setting. Similarly, [22] focuses
on estimating the average causal effect and is not suited for predicting individual treatment effects
or conditional counterfactual responses, as it targets marginal counterfactual expectations via g-
computation."
REFERENCES,0.43238993710691825,"C.2
Mutual Information and Self-Supervision"
REFERENCES,0.4339622641509434,"Self-Supervised Learning and Mutual Information In self-supervised learning, Deep InfoMax
[32] uses MI computation between input images and their representations, focusing on maximizing
MI to improve reconstruction quality. Local MI between representations and image patches captures
detailed patterns across regions, enhancing encoding. By maximizing average MI with local regions,
Deep InfoMax significantly boosts downstream task performance, while global MI plays a key role
in reconstructing the entire input from the representation.
CPC aligns with the MI-based approach seen in Deep InfoMax, emphasizing the maximization of
MI between global and local representation pairs. Distinct from Deep InfoMax, CPC processes
local features sequentially, constructing partial ""summary features"" to predict specific local features
in the future. While classical self-supervised paradigms often focus on tasks like classification or
reconstruction-based objectives—favoring either local or global MI maximization—integrating both
approaches becomes essential for downstream tasks such as counterfactual regression over time,
which justifies why Causal CPC is designed to support both local and global MI maximization to
improve temporal predictions.
Several other methods share similarities with CPC, such as Contrastive Multiview Coding [75]. This
method emphasizes maximizing mutual information between representations of different views of
the same observation. Augmented Multiscale Deep InfoMax [3], akin to CPC, makes predictions
across space but differs by predicting representations across layers in the model. While Instance Dis-
crimination [85] encourages representations capable of discriminating between individual examples
in the dataset, our preference for CPC arises from its adaptability in processing sequential features in
an ordered and autoregressive manner, which aligns with the requirements of our specific context,
especially when dealing with counterfactual regression over time.
Mutual Information and Inductive Bias. Mutual information (MI) estimation success relies not
only on MI’s properties but also on the inductive biases from feature representation choices and MI
estimator parameterization [77]. Experimental evidence shows that, although MI remains invariant
under homeomorphisms, maximization with an invertible encoder during random initialization
enhances downstream performance. While higher-capacity critics yield tighter MI bounds, findings
consistent with [59] suggest that simpler critics provide better representations, even with looser MI
bounds. Accordingly, we selected a simple bilinear critic function for contrastive losses. In vision
tasks, augmentations and contrastive loss properties are crucial for representation efficiency [1, 76, 27],
and [66] highlights that inductive bias, via function class representation and optimizers, significantly
affects downstream performance, offering theoretical, non-vacuous guarantees on representation
quality.
Variational Approaches and MI Estimation Challenges The estimation of MI faces inherent
challenges, particularly within variational lower bounds. These bounds often degrade as MI increases,
creating a delicate trade-off between high bias and high variance. To address this, methods that
utilize upper bounds on MI have been developed, attempting to mitigate challenges associated with
variational bounds. One strategy for MI maximization involves computing gradients of a lower MI
bound concerning the parameters of a stochastic encoder. This computational approach potentially
eliminates the need for direct MI estimation, providing a more tractable solution. However, estimating
MI from samples remains challenging, and traditional approaches encounter scalability issues in
modern machine-learning problems.
It’s crucial to note that higher estimated MI between observations and learned representations does
not consistently translate to improved predictive performance in downstream supervised learning
tasks. CPC is an example, exhibiting less variance but more bias, with estimates capped at log |B|.
Strategies to reduce bias, such as increasing the batch size, introduce higher computational complexity,
requiring additional evaluations for estimating each batch with the encoding function."
REFERENCES,0.43553459119496857,"In our empirical approach, we adopt a specific sampling strategy for sequences, considering a one-
time step per batch. This facilitates computing the InfoNCE between local summary features at
time t and the future prediction of local features, leading to a reduction in algorithmic complexity
for contrastive loss computation. Empirical observations demonstrate non-decreased representation
quality and improved prediction of factual and counterfactual outcomes.
Other MI lower bounds. The Mutual Information Neural Estimator (MINE) [4] leverages the
relationship between MI and the Kullback-Leibler (KL) divergence. MI can be expressed as the KL
divergence between the joint distribution and the product of marginals:
I(X; Z) := DKL(P(X,Z) ∥PX ⊗PZ)"
REFERENCES,0.4371069182389937,MINE employs the Donsker-Varadhan representation [20] of the KL divergence:
REFERENCES,0.4386792452830189,"DKL(P ∥Q) =
sup
T :Ω→R
EP[T] −log
 
EQ[eT ]

(11)"
REFERENCES,0.44025157232704404,"Here, the supremum is taken over all functions T where the expectations exist. For a specific class of
functions F, potentially represented by a class of neural networks, we obtain the lower bound:"
REFERENCES,0.4418238993710692,"DKL(P ∥Q) ≥sup
T ∈F
EP[T] −log
 
EQ[eT ]

(12)"
REFERENCES,0.44339622641509435,"In practice, we maximize
ˆIMINE
γ
(P ∥Q) = EP[Tγ] −log
 
EQ[eTγ]

,
where Tγ is a discriminator parameterized by γ, representing neural network parameters. The MINE
estimator is a strongly consistent estimator of the true MI (Theorem 2, [4]).
Alternatively, the f-divergence representation of DKL [51] allows us to derive another MI lower
bound, known as the Nguyen, Wainwright, and Jordan (NWJ) estimator [50]:"
REFERENCES,0.4449685534591195,"DKL(P ∥Q) ≥sup
T ∈F
EP[T] −log
 
EQ[eT −1]

(13)"
REFERENCES,0.44654088050314467,"This results in the estimator:
ˆINWJ
γ
(P, Q) = EP[Tγ] −log
 
EQ[eTγ−1]

."
REFERENCES,0.4481132075471698,"Unlike the InfoNCE estimator, which exhibits high bias and low variance, the NWJ estimator has a
low bias but high variance [57]."
REFERENCES,0.449685534591195,"D
Experimental protocol"
REFERENCES,0.45125786163522014,"All models were implemented using PyTorch [53] and PyTorch Lightning [21]. In contrast to the
approach in [48], we employed early stopping for all models. The stopping criterion was defined as
the Mean Squared Error over factual outcomes for a dedicated validation dataset. Specifically, for the
Causal CPC encoder, the stopping criterion was determined by the validation loss of the encoder.
While all models in the benchmark were trained using the Adam optimizer [36], we opted for training
Causal CPC (encoder plus decoder without the treatment subnetwork) with AdamW [46] due to its
observed stability during training. Similar to the common practice in training GAN discriminators,
the treatment subnetwork was optimized using SGD with momentum [74].
The CT employed the Exponential Moving Average (EMA) [83] of parameters to enhance training
stability. However, this technique was not applied to Causal CPC, as experimental evidence suggested
only marginal improvements. Weight decay was set to zero for all models.
For each experiment, the models were trained over five different seeds, and the reported performance
metrics include the mean and standard deviation of the results.
The counterfactual trajectories are generated following two strategies:"
REFERENCES,0.4528301886792453,"• Single sliding treatment [7, 48]: Trajectories are generated with a single treatment per tra-
jectory while the treatment slides over the forecasting range to generate multiple trajectories.
Similar to [7], we apply such a generation scheme to cancer simulation data.
• Random trajectories: Trajectories are generated such that at each time step, treatment is
generated randomly. We apply random trajectories to semi-synthetic MIMIC data."
REFERENCES,0.45440251572327045,"For the falsifiability test on MIMIC III datset, we mask two confounders from the inputs of the
benchmark models, namely sodium and glucose measurements."
REFERENCES,0.4559748427672956,"E
Experiments on synthetic data: Details"
REFERENCES,0.45754716981132076,"E.1
Description of the Simulation Model"
REFERENCES,0.4591194968553459,"We present a tumor growth simulation model, focusing on the PharmacoKinetic-PharmacoDynamic
(PK-PD) model as discussed in [24], a recent approach to predicting treatment responses in non-small
cell lung cancer patients. This simulation models the evolution of tumor volume, denoted by V (t), in
discrete time, where t represents the number of days since diagnosis:"
REFERENCES,0.4606918238993711,V (t) = 
REFERENCES,0.46226415094339623,"

1 + Λ log

K
V (t −1) "
REFERENCES,0.4638364779874214,"|
{z
}
Tumor Growth"
REFERENCES,0.46540880503144655,"−κcC(t)
| {z }
Chemotherapy"
REFERENCES,0.4669811320754717,"−
 
κrdRd(t) + υRd(t)2"
REFERENCES,0.46855345911949686,"|
{z
}
Radiation"
REFERENCES,0.470125786163522,"+ et
|{z}
Noise "
REFERENCES,0.4716981132075472,"

V (t −1) (14)"
REFERENCES,0.47327044025157233,"Here, the model parameters Λ, K, κc, κrd, υ are sampled for each patient based on prior distributions
from [24]. Additionally, Rd(t) represents the radiation dose applied at time t, and C(t) denotes the
drug concentration.
We introduce confounding into the assignment of radiotherapy/chemotherapy treatment by making it
dependent on past tumor volume evolution. Treatment is simulated using a Bernoulli distribution
with probability σ(πt), where:"
REFERENCES,0.4748427672955975,"πt =
γ
Dmax"
REFERENCES,0.47641509433962265,"  ¯D(t) −δ

(15)"
REFERENCES,0.4779874213836478,"In this context: ¯D(t) represents the average tumor diameter over the last 15 days, Dmax = 13 cm is
the maximum tumor diameter, δ is set to δ = Dmax/2.
The parameter γ controls the level of time-dependent confounding, with a higher γ value assigning
more weight to the history of tumor diameter in treatment assignment."
REFERENCES,0.47955974842767296,"E.2
Additional results"
REFERENCES,0.4811320754716981,"E.2.1
Comparison to benchmark models"
REFERENCES,0.4827044025157233,"We report in this section detailed counterfactual errors for Causal CPC and baselines over the cancer
simulation dataset, which are responsible for Figure 3."
REFERENCES,0.48427672955974843,"Table 6: Results on the synthetic data set with sequence length 60: mean±standard deviation of
NRMSEs. The best value for each metric is given in bold: smaller is better."
REFERENCES,0.4858490566037736,"γ = 1
Model
τ = 1
τ = 2
τ = 3
τ = 4
τ = 5
τ = 6
τ = 7
τ = 8
τ = 9
τ = 10
Causal CPC (ours)
0.83± 0.06
0.86 ± 0.09
0.94± 0.09
0.97± 0.08
1.03± 0.10
1.07 ± 0.10
1.12± 0.10
1.17 ± 0.09
1.22± 0.08
1.26± 0.08
CT
0.99± 0.13
0.92 ± 0.14
0.98± 0.14
1.05± 0.15
1.11 ± 0.18
1.11 ±0.11
1.21 ± 17
1.26± 0.16
1.31 ± 0.005
1.35± 0.16
G-Net
0.91±0.15
1.1±0.16
1.24±0 16
1.33±0.17
1.40±0.18
1.47±0.19
1.52±0.18
1.57±0.22
1.63±0.22
1.7±0.25
CRN
0.84±0.10
0.83±0.09
0.92±0.10
1.00±0.11
1.09±0.12
1.17±0.14
1.25±0.16
1.32±0.18
1.37±0.23
1.43±0.26
RMSN
0.99±0.13
0.91±0.04
1.30±0.65
1.43±0.76
1.56±0.83
1.66±0.88
1.73±0.91
1.77±0.89
1.81±0.88
1.84±0.86
MSM
1.20±0.10
1.83±0.26
2.07±0.44
2.38±0.44
2.54±0.45
2.90±0.37
3.01±.38
3.06±0.36
3.08±0.36
3.08±0.36
γ = 2
Causal CPC (ours)
1.16± 0.22
0.91 ± 0.10
0.95 ± 0.13
1.00 ± 0.15
1.07± 0.19
1.17 ± 0.24
1.27 ± 0.25
1.38 ± 0.28
1.49 ± 0.30
1.60 ± 0.34
CT
1.24±0.20
1.13±0.15
1.27±021
1.36±0.28
1.44±0.29
1.55±0.27
1.64±0.28
1.69±0.20
1.74±0.28
1.77 ± 0.29
G-Net
1.05±0.21
1.05±0.08
1.26±0.16
1.38±0.23
1.48±0.27
1.57±0.31
1.64±0.33
1.70±0.36
1.75±0.39
1.8±0.42
CRN
1.25±0.25
1.08±0.06
1.14±0.12
1.21±0.17
1.30± 0.21
1.41±0.25
1.54±0.32
1.67±0.41
1.8±0.51
1.92±0.63
RMSN
1.47±0.27
1.33±0.25
1.30±0.23
1.33±0.24
1.38±0.26
1.45±0.28
1.52±0.31
1.60±0.25
1.67±0.38
1.75±0.42
MSM
1.43±0.27
2.22±0.53
2.67±0.63
2.98±0.70
3.19±0.74
3.33±0.77
3.41±0.79
3.44±0.25
3.45±0.78
3.34±0.77
γ = 3
Causal CPC (ours)
1.37±0.31
1.16±0.27
1.26±0.30
1.38±0.35
1.53±0.40
1.69±0.47
1.84±0.52
2.00±0.51
2.14±0.61
2.28±0.66
CT
1.36±0.32
1.42±0.36
1.62±0.46
1.78±0.53
1.89±0.58
2.01±0.63
2.13±0.66
2.22±0.69
2.31±0.69
2.37±0.73
G-Net
1.14±0.24
1.22±0.15
1.54±0.26
1.77±0.33
1.94±0.36
2.09±0.40
2.23±0.43
2.34±0.47
2.44±0.52
2.52±0.56
CRN
1.46±0.29
1.54±0.38
1.70±0.48
1.79±0.53
1.86±0.92
1.92±0.58
1.98±0.59
2.04±0.61
2.10±0.63
2.16±0.64
RMSN
1.22±0.26
1.28±0.29
1.43±0.40
1.56±0.48
1.70±0.53
1.83±0.57
1.95±0.59
2.06±0.61
2.14±0.61
2.21±0.61
MSM
1.70±0.35
2.73±0.88
3.22±1.03
3.25±1.12
3.71±1.18
3.85±1.22
3.91±1.23
3.95±1.24
3.96±1.24
3.94±1.23"
REFERENCES,0.48742138364779874,"E.2.2
Ablation study"
REFERENCES,0.4889937106918239,"We detail here the results of the ablation study conducted on the cancer simulation dataset (Table 3).
The (full) Causal CPC model, as presented in the core paper, gives, in most cases, better results than
any ablation configuration."
REFERENCES,0.49056603773584906,"Table 7: Results on the synthetic data set with sequence length 40: mean±standard deviation of
NRMSEs. The best value for each metric is given in bold: smaller is better."
REFERENCES,0.4921383647798742,"γ = 1
Model
τ = 1
τ = 2
τ = 3
τ = 4
τ = 5
τ = 6
τ = 7
τ = 8
τ = 9
τ = 10
Causal CPC (ours)
1.21±0.07
1.13±0.12
1.22±0.12
1.27±0.17
1.35±0.19
1.43±0.21
1.48±0.22
1.54±0.22
1.58±0.23
1.62±0.23
CT
1.21±0.09
1.34±0.10
1.43±0.14
1.52±0.19
1.59±0.22
1.65±0.23
1.71±0.23
1.76±0.21
1.78±0.21
1.80±0.18
G-Net
1.11±0.10
1.30±0.17
1.52±0.20
1.65±0.21
1.76±0.24
1.86±0.29
1.96±0.34
2.05±0.40
2.13±0.46
2.19±0.52
CRN
1.01±0.12
1.11±0.14
1.19±0.14
1.30±0.13
1.41±0.12
1.49±0.09
1.56±0.07
1.62±0.05
1.67±0.04
1.70±0.04
RMSN
1.14±0.03
1.20±0.08
1.24±0.07
1.32±0.08
1.40±0.08
1.49±0.08
1.57±0.08
1.64±0.06
1.71±0.05
1.76±0.04
γ = 2
Causal CPC (ours)
1.41±0.09
1.30±0.17
1.33±0.20
1.41±0.25
1.50±0.28
1.56±0.31
1.60±0.23
1.66±0.27
1.70±0.26
1.74±0.25
CT
1.36±0.15
1.38±0.19
1.40±0.25
1.48±0.28
1.54±0.30
1.62±0.31
1.70±0.31
1.75±0.31
1.82±0.32
1.85±0.29
G-Net
1.26±0.09
1.47±0.20
1.74±0.28
1.90±0.34
2.02±0.40
2.12±0.44
2.22±0.50
2.31±0.55
2.39±0.61
2.47±0.68
CRN
1.24±0.22
1.21±0.18
1.31±0.22
1.42±0.25
1.55±0.29
1.67±0.34
1.79±0.41
1.91±0.50
2.03±0.59
2.13±0.70
RMSN
1.28±0.15
1.28±0.13
1.37±0.12
1.49±0.15
1.62±0.19
1.76±0.25
1.89±0.30
2.03±0.36
2.15±0.41
2.26±0.46
γ = 3
Causal CPC (ours)
1.52±0.19
1.19±0.16
1.26±0.23
1.38±0.25
1.52±0.24
1.66±0.25
1.79±0.27
1.91±0.32
2.02±0.38
2.11±0.46
CT
1.56±0.18
1.68±0.33
1.77±0.54
1.95±0.75
2.05±0.83
2.19±0.92
2.29±1.00
2.35±1.04
2.43±1.09
2.43±1.07
G-Net
1.19±0.02
1.38±0.04
1.72±0.02
1.92±0.08
2.11±0.18
2.32±0.29
2.52±0.41
2.72±0.54
2.93±0.68
3.13±0.83
CRN
1.50±0.01
1.47±0.07
1.62±0.24
1.76±0.40
1.89±0.51
1.98±0.57
2.05±0.61
2.10±0.62
2.13±0.61
2.15±0.58
RMSN
1.48±0.19
1.40±0.13
1.66±0.35
1.86±0.52
2.01±0.61
2.14±0.65
2.24±0.67
2.32±0.67
2.37±0.66
2.39±0.65"
REFERENCES,0.4937106918238994,"Table 8: Results of the ablation study on the synthetic data set: mean±standard deviation of
Normalized Rooted Mean Squared Errors (NRMSEs). The best value for each metric is given in bold:
smaller is better."
REFERENCES,0.49528301886792453,"Model
τ = 1
τ = 2
τ = 3
τ = 4
τ = 5
τ = 6
τ = 7
τ = 8
τ = 9
τ = 10
CAUSAL CPC (FULL)
0.83 ± 0.06
0.86 ± 0.06
0.94± 0.09
0.97 ± 0.08
1.03 ± 0.10
1.07±0.10
1.12± 0.10
1.17± 0.06
1.22 ± 0.08
1.26± 0.08
Causal CPC (w/o L(InfoNCE))
0.84±0.04
0.91±0.07
0.95± 0.07
0.99± 0.09
1.03±0.10
1.10± 0.07
1.15±0.14
1.20 ± 0.14
1.23±0.14
1.28±0.15
Causal CPC (w/o L(InfoMax))
0.84±0.04
0.86±0.09
0.91±0.08
0.99±0.10
1.07±0.08
1.16± 0.08
1.24± 0.10
1.31 ± 0.12
1.38±0.08
1.46±0.10
Causal CPC (w CDC loss)
0.83±0.02
0.89±0.07
0.96± 0.07
1.03± 0.07
1.07±0.08
1.10± 0.07
1.13±0.10
1.18 ± 0.09
1.24±0.11
1.28±0.11
Causal CPC (w Balancing
0.84±0.04
0.88±0.05
0.97± 0.05
1.04± 0.07
1.08±0.10
1.13± 0.08
1.15±0.14
1.20± 0.10
1.25±0.08
1.29±0.12
F
Experiments on semi-synthetic data: Details"
REFERENCES,0.4968553459119497,"F.1
Description of the simulation model"
REFERENCES,0.49842767295597484,"In this section, we provide a concise overview of the simulation model built upon the MIMIC III
dataset, as introduced by [48]. Initially, a cohort of 1,000 patients is extracted from the MIMIC III
data, and the simulation proposed by [48] extends the model of [68].
Let dy be the dimension of the outcome variable. In the case of multiple outcomes, untreated
outcomes, denoted as Zj,(i)
t
for j = 1, . . . , dy, are generated for each patient i within the cohort. The
generation process is defined as follows:"
REFERENCES,0.5,"Zj,(i)
t
= αj
SB-spline(t) + αj
ggj,(i)(t)
|
{z
}
endogenous"
REFERENCES,0.5015723270440252,"+ αj
ff j
Z

X(i)
t
"
REFERENCES,0.5031446540880503,"|
{z
}
exogenous"
REFERENCES,0.5047169811320755,"+ εt
|{z}
noise
(16)"
REFERENCES,0.5062893081761006,"where: the B-spline B-spline(t) is an endogenous component, gj,(i)(·) is sampled independently for
each patient from a Gaussian process with a Matérn kernel and f j
Z(·) is sampled from a Random
Fourier Features (RFF) approximation of a Gaussian process.
To introduce confounding in the assignment mechanism, current time-varying covariates are incorpo-
rated via a random function f l
Y (Xt) and the average of the subset of the previous Tl treated outcomes,
¯ATl
 "
REFERENCES,0.5078616352201258,"Yt−1

. For da binary treatments Al
t, where l = 1, . . . , da, the assignment mechanism is mod-
eled as:"
REFERENCES,0.5094339622641509,"pAl
t = σ
 
γl
A ¯ATl
 "
REFERENCES,0.5110062893081762,"Yt−1

+ γl
Xf l
Y (Xt) + bl

,"
REFERENCES,0.5125786163522013,"Al
t ∼Bernoulli

pAl
t 
."
REFERENCES,0.5141509433962265,"Subsequently, treatments are applied to the untreated outcomes using the following expression:"
REFERENCES,0.5157232704402516,"Ej(t) = t
X"
REFERENCES,0.5172955974842768,i=t−wl
REFERENCES,0.5188679245283019,"minl=1,...,da ⊮[Al
i=1]pAl
iβlj"
REFERENCES,0.5204402515723271,"(wl −i)2
(17)"
REFERENCES,0.5220125786163522,The final outcome combines the treatment effect and the untreated simulated outcome:
REFERENCES,0.5235849056603774,"Y j
t = Zj
t + Ej(t).
(18)"
REFERENCES,0.5251572327044025,"F.2
Additional results"
REFERENCES,0.5267295597484277,"F.2.1
Ablation study"
REFERENCES,0.5283018867924528,"We detail here the results of the ablation study conducted on the MIMIC III semi-synthetic dataset
(Table 3). The (full) Causal CPC model, as presented in the core paper, gives consistently better
results than any ablation configuration."
REFERENCES,0.529874213836478,"Table 9: Results on MIMIC III semi-synthetic data set: mean±standard deviation of Normalized
Rooted Mean Squared Errors (NRMSEs). The best value for each metric is given in bold: smaller is
better."
REFERENCES,0.5314465408805031,"Model
τ = 1
τ = 2
τ = 3
τ = 4
τ = 5
τ = 6
τ = 7
τ = 8
τ = 9
τ = 10
Causal CPC (ful)
0.32± 0.04
0.45± 0.08
0.54±0.06
0.61 ± 0.10
0.66± 0.10
0.69±0.11
0.71± 0.11
0.73± 0.06
0.75 ± 0.05
0.77± 0.10
Causal CPC (w/o L(InfoNCE))
0.35± 0.04
0.50± 0.05
0.59± 0.06
0.66± 0.06
0.71± 0.08
0.75± 0.06
0.77± 0.07
0.79± 0.08
0.81± 0.07
0.83± 0.07
Causal CPC (w/o L(InfoMax))
0.36± 0.02
0.53± 0.03
0.64± 0.04
0.71± 0.05
0.77± 0.05
0.77± 0.05
0.83± 0.05
0.86± 0.05
0.88± 0.08
0.90± 0.05
Causal CPC (CDC loss)
0.36± 0.02
0.54± 0.03
0.65± 0.05
0.72± 0.05
0.77± 0.05
0.70± 0.04
0.83± 0.04
0.85± 0.03
0.86± 0.03
0.88± 0.08
Causal CPC (w/o balancing)
0.35± 0.03
0.50± 0.05
0.60± 0.06
0.67± 0.06
0.72± 0.06
0.76± 0.06
0.78± 0.06
0.80± 0.06
0.83± 0.06
0.85± 0.06"
REFERENCES,0.5330188679245284,"Furthermore, We replace the InfoNCE objective used to compute the CPC term and InfoMax terms
with that of NWJ and MINE (Section C.2). We repeat the same MIMIC III experimentation while
varying the objective used for CPC and InfoMax. Table 10 shows the counterfactual errors for
each configuration compared to the original formulation of Causal CPC. In all cases, The InfoNCE
objective performs better with notable error reduction at large horizons."
REFERENCES,0.5345911949685535,"Table 10: Results of NWJ and MINE MI lower bounds when used for CPC and InfoMax for MIMIC
III semi-synthetic data set: mean±standard deviation of Normalized Rooted Mean Squared Errors
(NRMSEs). The best value for each metric is given in bold: smaller is better."
REFERENCES,0.5361635220125787,"Model
τ = 1
τ = 2
τ = 3
τ = 4
τ = 5
τ = 6
τ = 7
τ = 8
τ = 9
τ = 10
Original Model
0.34± 0.04
0.45± 0.08
0.54±0.06
0.61 ± 0.10
0.66± 0.10
0.69±0.11
0.71± 0.11
0.73± 0.06
0.75 ± 0.05
0.77± 0.10
CPC with NWJ
0.34± 0.04
0.48± 0.05
0.58± 0.06
0.66± 0.07
0.71± 0.08
0.75± 0.07
0.78± 0.07
0.81± 0.06
0.84± 0.06
0.87± 0.06
CPC with MINE
0.35± 0.03
0.50± 0.05
0.61± 0.04
0.69± 0.04
0.75± 0.04
0.79± 0.03
0.82± 0.03
0.85± 0.02
0.88± 0.02
0.91± 0.02
InfoMax with NWJ
0.42± 0.08
0.56± 0.04
0.69± 0.07
0.77± 0.08
0.83± 0.09
0.87± 0.09
0.90± 0.09
0.92± 0.09
0.94± 0.08
0.96± 0.08
InfoMax with MINE
0.37± 0.05
0.52± 0.03
0.65± 0.06
0.73± 0.8
0.80± 0.10
0.84± 0.11
0.87± 0.11
0.89± 0.10
0.91± 0.10
0.93± 0.09"
REFERENCES,0.5377358490566038,"F.2.2
Comparison to benchmark models: standard train/test split"
REFERENCES,0.539308176100629,"As mentioned in Section 6.2, We also tested Causal CPC on MIMIC III semi-synthetic data using the
same experimental protocol as [48], namely by using the split of patients into train/validation/test as
800/200/200. As a result, baseline performances in Table 11 are exactly the same as in [48]."
REFERENCES,0.5408805031446541,"Table 11: Results over the MIMIC III semi-synthetic data set (same experimental protocol as in [48]):
mean±standard deviation of Rooted Mean Squared Errors (RMSEs). The best value for each metric
is given in bold: smaller is better."
REFERENCES,0.5424528301886793,"Model
τ = 1
τ = 2
τ = 3
τ = 4
τ = 5
τ = 6
τ = 7
τ = 8
τ = 9
τ = 10
Causal CPC (ours)
0.25 ± 0.03
0.37 ± 0.02
0.40 ± 0.01
0.45 ± 0.01
0.49 ± 0.02
0.52 ± 0.02
0.55 ± 0.03
0.56 ± 0.03
0.58 ± 0.04
0.60 ± 0.03
CT
0.20 ± 0.01
0.38 ± 0.01
0.45 ± 0.01
0.49 ± 0.01
0.52 ± 0.02
0.53 ± 0.02
0.55 ± 0.02
0.56 ± 0.02
0.58 ± 0.02
0.59 ± 0.02
G-Net
0.34 ± 0.01
0.67 ± 0.03
0.83 ± 0.04
0.94 ± 0.04
1.03 ± 0.05
1.10 ± 0.05
1.16 ± 0.05
1.21 ± 0.06
1.25 ± 0.06
1.29 ± 0.06
CRN
0.30 ± 0.01
0.48 ± 0.02
0.59 ± 0.02
0.65 ± 0.02
0.68 ± 0.02
0.71 ± 0.01
0.72 ± 0.01
0.74 ± 0.01
0.76 ± 0.01
0.78 ± 0.02
RMSN
0.24 ± 0.01
0.47 ± 0.01
0.60 ± 0.01
0.70 ± 0.02
0.78 ± 0.04
0.84 ± 0.05
0.89 ± 0.06
0.94 ± 0.08
0.97 ± 0.09
1.00 ± 0.11
MSM
0.37 ± 0.01
0.57 ± 0.03
0.74 ± 0.06
0.88 ± 0.03
1.14 ± 0.10
1.95 ± 1.48
3.44 ± 4.57
> 10.0
> 10.0
> 10.0"
REFERENCES,0.5440251572327044,"F.2.3
Running time and model complexity"
REFERENCES,0.5455974842767296,"In this section, we complement the table about complexity and running time given for cancer
simulation in the core paper by providing the exact same table but for MIMIC III semi-synthetic data."
REFERENCES,0.5471698113207547,"G
Proofs of theoretical results"
REFERENCES,0.5487421383647799,"G.1
Relation between InfoNCE loss and mutual information"
REFERENCES,0.550314465408805,Proposition G.1.
REFERENCES,0.5518867924528302,"I(Ut+j, Ct) ≥log(|B|) −L(InfoNCE)
j"
REFERENCES,0.5534591194968553,"Table 12: The number of parameters to train for each model after hyper-parameters fine-tuning and
the corresponding running time averaged over five seeds. Results are reported for semi-synthetic
MIMIC III data; the processing unit is GPU - 1 x NVIDIA Tesla M60 ."
REFERENCES,0.5550314465408805,"MODEL
TRAINABLE PARAMETERS (K)
TRAINING TIME (MIN)
PREDICTION TIME (MIN)"
REFERENCES,0.5566037735849056,"CAUSAL CPC (OURS)
9.8
12±2
4±1
CT
12
14±1
38±2
G-NET
14.7
7±1
40±3
CRN
15.1
21±2
5±1
RMSN
20
48±4
5±1"
REFERENCES,0.5581761006289309,"Proof. In the following, we draw inspiration from the proof of [52]. The InfoNCE loss corresponds
to the categorical cross-entropy of classifying the positive sample Ut+j correctly, given the context
Ct, with a probability:"
REFERENCES,0.559748427672956,"exp(Tj(Ut+j, Ct))
P|B|
l=1 exp(Tj(Ul,t+j, Ct))
."
REFERENCES,0.5613207547169812,"The positive sample Ut+j is one element in the batch B, where the remaining elements serve as
negative samples. Let pos ∈{1, . . . , |B|} be the indicator of the positive sample Ut+j. The optimal
probability is given by:"
REFERENCES,0.5628930817610063,"p(Index = pos | B, Ct) =
p(upos,t+j | Ct) Q"
REFERENCES,0.5644654088050315,"l=1,...,|B|;l̸=pos p(ul,t+j)
P|B|
j=1
h
p(uj,t+j | Ct) Q"
REFERENCES,0.5660377358490566,"l=1,...,|B|;l̸=j p(ul,t+j)
i ="
REFERENCES,0.5676100628930818,"p(upos,t+j|Ct)"
REFERENCES,0.5691823899371069,"p(upos,t+j)
P|B|
j=1
p(uj,t+j|Ct)"
REFERENCES,0.5707547169811321,"p(uj,t+j)
."
REFERENCES,0.5723270440251572,"For the score exp(Tj(Ut+j, Ct)) to be optimal, it should be proportional to p(upos,t+j|Ct)"
REFERENCES,0.5738993710691824,"p(upos,t+j) . The
mutual information (MI) lower bound arises from the fact that exp(Tj(Ut+j, Ct)) estimates the
density ratio p(upos,t+j|Ct)"
REFERENCES,0.5754716981132075,"p(upos,t+j) ."
REFERENCES,0.5770440251572327,"L(InfoNCE)
j
= −EB log  "
REFERENCES,0.5786163522012578,p(ut+j|ct)
REFERENCES,0.5801886792452831,"p(ut+j)
p(ut+j|ct)"
REFERENCES,0.5817610062893082,"p(ut+j)
+ P"
REFERENCES,0.5833333333333334,"ul,t+j∈Bneg
p(ul,t+j|ct)"
REFERENCES,0.5849056603773585,"p(ul,t+j)  "
REFERENCES,0.5864779874213837,= EB log 
REFERENCES,0.5880503144654088,"1 +
p (ut+j)
p (ut+j | ct) X"
REFERENCES,0.589622641509434,"ul,t+j∈Bneg"
REFERENCES,0.5911949685534591,"p (ul,t+j | ct)"
REFERENCES,0.5927672955974843,"p (ul,t+j)  "
REFERENCES,0.5943396226415094,"≈EB log

1 +
p (ut+j)
p (ul,t+j | ct)(|B| −1)EUt+j
p (ul,t+j | ct)"
REFERENCES,0.5959119496855346,"p (ul,t+j) "
REFERENCES,0.5974842767295597,"= EB log

1 +
p (ut+j)
p (ut+j | ct)(|B| −1)
"
REFERENCES,0.5990566037735849,"≥EB log

p (ut+j)
p (ut+j | ct)|B|
"
REFERENCES,0.60062893081761,"= −I (ut+j, ct) + log(|B|), (19)"
REFERENCES,0.6022012578616353,"The approximation in the third equation, Eq. (19), becomes more precise as the batch size increases."
REFERENCES,0.6037735849056604,"G.2
Relation between InfoMax and Input Reconstruction"
REFERENCES,0.6053459119496856,"We now prove Proposition 5.1, which states that:"
REFERENCES,0.6069182389937107,"I(Ch
t , Cf
t ) ≤I(Ht, (Ch
t , Cf
t ))."
REFERENCES,0.6084905660377359,"Proof. This follows from two applications of the data processing inequality [17], which states that
for random variables A, B, and C satisfying the Markov relation A →B →C, the inequality
I(A; C) ≤I(A; B) holds."
REFERENCES,0.610062893081761,"First, since Ch
t = Φθ1,θ2(Hh
t ) and Cf
t = Φθ1,θ2(Hf
t ), we can write Hh
t = truncf(Ht) and
Hf
t = trunch(Ht), where truncf and trunch truncate the future and history processes, respectively,
given a splitting time t0."
REFERENCES,0.6116352201257862,"Thus, we have the Markov relation:"
REFERENCES,0.6132075471698113,"Ch
t
Φθ1,θ2◦truncf
←−−−−−−−−−Ht
Φθ1,θ2◦trunch
−−−−−−−−−→Cf
t ,"
REFERENCES,0.6147798742138365,which is Markov equivalent to:
REFERENCES,0.6163522012578616,"Ch
t
Φθ1,θ2◦truncf
−−−−−−−−−→Ht
Φθ1,θ2◦trunch
−−−−−−−−−→Cf
t ."
REFERENCES,0.6179245283018868,"By the data processing inequality, this results in I(Ch
t , Cf
t ) ≤I(Ht, Ch
t ). On the other hand, we have
the trivial Markov relation Ht →(Ch
t , Cf
t ) →Ch
t , which implies I(Ht, Ch
t ) ≤I(Ht, (Ch
t , Cf
t )).
Combining these two inequalities proves the proposition."
REFERENCES,0.6194968553459119,"G.3
Proof of Theorem 5.2"
REFERENCES,0.6210691823899371,"To begin, we split the process history into two non-overlapping views (Figure 2): Hh
t := U1:t0 and
Hf
t := Ut0+1:t, representing a historical subsequence and a future subsequence within the process
history Ht, respectively. We then computed representations of these two views denoted Ch
t and Cf
t ,
respectively. This naturally gives rise to the Markov chain, as in showed in the proof of proposition
5.1:"
REFERENCES,0.6226415094339622,"Ch
t ←−Ht −→Cf
t"
REFERENCES,0.6242138364779874,which is Markov equivalent to:
REFERENCES,0.6257861635220126,"Ch
t −→Ht −→Cf
t"
REFERENCES,0.6273584905660378,"Following this Markov chain, we can show that [71]:"
REFERENCES,0.6289308176100629,"I(Cf
t , Ch
t ) = I(Ht, Ch
t ) −Eht∼PHtEcf
t ∼PCf
t |ht"
REFERENCES,0.6305031446540881,"h
DKL[PCh
t |ht||PCh
t |cf
t ]
i"
REFERENCES,0.6320754716981132,"On the other hand, by applying the chain rule of the mutual information to I(Ht; (Ch
t , Cf
t )) we get:"
REFERENCES,0.6336477987421384,"I(Ht; (Cf
t , Ch
t )) = I(Ht, Ch
t ) + I(Ht; Cf
t | Ch
t )"
REFERENCES,0.6352201257861635,"Combining these equations, the tightness of our bounds can be written as:"
REFERENCES,0.6367924528301887,"I(Ht; (Cf
t , Ch
t )) −I(Cf
t , Ch
t ) = I(Ht; Cf
t | Ch
t ) + Eht∼PHtEcf
t ∼PCf
t |ht"
REFERENCES,0.6383647798742138,"h
DKL[PCh
t |ht||PCh
t |cf
t ]
i"
REFERENCES,0.639937106918239,"G.4
On the Relation Between Conditional Entropy and Reconstruction"
REFERENCES,0.6415094339622641,"We now prove the statement in the core paper, which asserts that the conditional entropy H(Ht |
(Ch
t , Cf
t )) ≥0 is minimized if Ht is almost surely a function of (Ch
t , Cf
t ). The proof is adapted
from [17]."
REFERENCES,0.6430817610062893,"Proposition G.2. If H(A | B) = 0, then A = f(B) almost surely."
REFERENCES,0.6446540880503144,"Proof. For simplicity, suppose A and B are discrete random variables. Assume, by contradiction,
that there exists b0 and two distinct values a1 and a2 such that p(a1 | b0) > 0 and p(a2 | b0) > 0.
Then, the conditional entropy is given by:"
REFERENCES,0.6462264150943396,"H(A | B) = −
X"
REFERENCES,0.6477987421383647,"b
p(b)
X"
REFERENCES,0.64937106918239,"a
p(a | b) log p(a | b)."
REFERENCES,0.6509433962264151,"In particular, we have:"
REFERENCES,0.6525157232704403,H(A | B) ≥p(b0) (−p(a1 | b0) log p(a1 | b0) −p(a2 | b0) log p(a2 | b0)) > 0.
REFERENCES,0.6540880503144654,"Since −t log t ≥0 for 0 ≤t ≤1 and is strictly positive for t not equal to 0 or 1, the conditional
entropy H(A | B) = 0 if and only if A is almost surely a function of B."
REFERENCES,0.6556603773584906,"G.5
On the benefit of the InfoMax loss on inverting the data generation process"
REFERENCES,0.6572327044025157,"To ensure identifiability in the latent space, we leverage recent advances in causal and disentangled
representation learning. Suppose the true data-generating process is given by Ht = g(zt), where
zt represents the true latent factors. In the sequential context, we assume that the same function g
generates two historical subsequences:"
REFERENCES,0.6588050314465409,"Hf
t = g(zf
t ),
Hh
t = g(zh
t )."
REFERENCES,0.660377358490566,We assume a general dependency of the form:
REFERENCES,0.6619496855345912,"p(zf
t | zh
t ) = Q(zf
t )
Z(zh
t ) exp(−d(zf
t , zh
t ))."
REFERENCES,0.6635220125786163,"Here, Φ is an encoder, and we use the InfoMax regularization term as follows:"
REFERENCES,0.6650943396226415,"L(InfoMax)(Φ, d, B) := −EB """
REFERENCES,0.6666666666666666,"log
exp(−d(Φ(Hf
t ), Φ(Hh
t )))
P|B|
l=1 exp(−d(Φ(Hf
l,t), Φ(Hh
t )))
. #"
REFERENCES,0.6682389937106918,"According to [47], under certain conditions, if the encoder f minimizes L(InfoMax), then h = g ◦f
is a scaled permutation matrix. This result suggests that when the encoder achieves a minimizer for
L(InfoMax), the encoder function f closely approximates an invertible transformation of g.
From a causal inference perspective, if Yit(ωit) ⊥⊥Wit | Hit and Hit = g(Zit), then an invertible
function g ◦f ensures that:"
REFERENCES,0.6698113207547169,Yit(ωit) ⊥⊥Wit | g ◦f(Hit).
REFERENCES,0.6713836477987422,"Thus, Yit(ωit) ⊥⊥Wit | g(Cit) and since g is invertible, we have:"
REFERENCES,0.6729559748427673,Yit(ωit) ⊥⊥Wit | Cit.
REFERENCES,0.6745283018867925,"This demonstrates that the representation Cit retains the essential independence structure, facilitating
accurate counterfactual inference."
REFERENCES,0.6761006289308176,"G.6
Proof of theorem 5.4"
REFERENCES,0.6776729559748428,"To prove the Theorem 5.4, we first prove the following lemma and proposition."
REFERENCES,0.6792452830188679,"Lemma G.3. Let Φ be a fixed representation function. Given that q(Wt+1 | Φ(Ht)) is the conditional
likelihood of observing the treatment Wt+1, denote the probability of observing each treatment value
as qj = q(Φ(Ht)) := q(Wt+1 = j | Φ(Ht)) for j ∈{0, 1, . . . , K −1}. Then, the optimal treatment
prediction function is such that"
REFERENCES,0.6808176100628931,"qj,∗(Φ(Ht)) =
p(Φ(Ht) | Wt+1 = j)
PK−1
l=0 p(Φ(Ht) | Wt+1 = l)p(Wt+1 = l)
(20)"
REFERENCES,0.6823899371069182,"Proof. For a fixed representation Φ, finding the optimal treatment probabilities amounts to solving
the following optimization problem:"
REFERENCES,0.6839622641509434,"max
q
EP(Φ(Ht),Wt+1) [log q(Wt+1 | Φ(Ht))]
subject to K−1
X"
REFERENCES,0.6855345911949685,"l=0
ql(Φ(Ht)) = 1
(21)"
REFERENCES,0.6871069182389937,"First, we write the likelihood q(Wt+1 | Φ(Ht)) using the conditional probabilities qj(Φ(Ht))."
REFERENCES,0.6886792452830188,"q(Wt+1 | Φ(Ht)) = K−1
Y"
REFERENCES,0.690251572327044,"j=0
qj(Φ(Ht))1{Wt+1=j}"
REFERENCES,0.6918238993710691,"Then, the treatment likelihood can be written as"
REFERENCES,0.6933962264150944,"EP(Φ(Ht),Wt+1) [log q(Wt+1 | Φ(Ht))] = EP(Φ(Ht),Wt+1)"
REFERENCES,0.6949685534591195,"""K−1
X"
REFERENCES,0.6965408805031447,"l=0
log(ql(Φ(Ht)))1{Wt+1=j} # = K−1
X l=0"
REFERENCES,0.6981132075471698,"Z
log(ql(Φ(Ht))1{Wt+1=j}p(Wt+1 | Φ(Ht))p(Φ(Ht))dWt+1dΦ(Ht) = K−1
X l=0"
REFERENCES,0.699685534591195,"Z
log(ql(Φ(Ht))p(Wt+1 = l | Φ(Ht))p(Φ(Ht))dΦ(Ht) = K−1
X l=0"
REFERENCES,0.7012578616352201,"Z
log(ql(Φ(Ht))p(Φ(Ht) | Wt+1 = l)p(Wt+1 = l)dΦ(Ht)"
REFERENCES,0.7028301886792453,"Let’s denote αl = p(Wt+1 = l), the marginal probability of observing the l-th treatment regime, and
pΦ
l (Ht) = p(Φ(Ht) | Wt+1 = l) with a corresponding probability distribution PΦ
l . We intend to
maximize point-wise the objective in Eq. (21). Plugging the latter formulation of the conditional
likelihood in Eq. (21) and writing the Lagrangian function, we get max
q K−1
X"
REFERENCES,0.7044025157232704,"l=0
log(ql(Φ(Ht))pΦ
j (Ht)αl + λ( K−1
X"
REFERENCES,0.7059748427672956,"l=0
ql(Φ(Ht)) −1)
(22)"
REFERENCES,0.7075471698113207,"Computing the gradient w.r.t ql(Φ(Ht)) for l ∈{0, 1, . . . , K −1} and setting to zero, we have"
REFERENCES,0.7091194968553459,"ql,∗(Φ(Ht)) = −αlpΦ
j (Ht)"
REFERENCES,0.710691823899371,"λ
(23)"
REFERENCES,0.7122641509433962,"Then, by the equality constraint, we find that λ = −PK−1
l=0 αlpΦ
j (Ht)."
REFERENCES,0.7138364779874213,"Proposition G.4. Let Φ be a fixed representation function. The ICLUB objective when the treatment
prediction function is optimal (i.e. q = q∗) has the following form:"
REFERENCES,0.7154088050314465,"ICLUB = K−1
X"
REFERENCES,0.7169811320754716,"j=0
αlDKL(PΦ
j || K−1
X"
REFERENCES,0.7185534591194969,"l=0
αlPΦ
l ) + EPΦ(Ht)

DKL(PWt+1||PWt+1|Φ(Ht))

.
(24)"
REFERENCES,0.720125786163522,"Proof. First, recall that"
REFERENCES,0.7216981132075472,"ICLUB(Φ(Ht), Wt+1; q∗) = EP(Φ(Ht+1),Wt+1) [log q∗(Wt+1 | Φ(Ht+1))]−EPΦ(Ht+1)EPWt+1 (log q∗(Wt+1 | Φ(Ht+1)))
i"
REFERENCES,0.7232704402515723,"ICLUB(Φ(Ht), Wt+1; q∗) = A −B
Let’s detail A and B separately, A = K−1
X j=0"
REFERENCES,0.7248427672955975,"Z
αj log(ql,∗(Φ(Ht))pΦ
j (Ht)dΦ(Ht) = K−1
X j=0"
REFERENCES,0.7264150943396226,"Z
αj log(
αjpΦ
j (Ht)
PK−1
l=0 pΦ
l (Ht)αl
)pΦ
j (Ht)dΦ(Ht) = K−1
X j=0"
REFERENCES,0.7279874213836478,"Z
αj log(
pΦ
j (Ht)
PK−1
l=0 pΦ
l (Ht)αl
)pΦ
j (Ht)dΦ(Ht) + log(αj)αj = K−1
X"
REFERENCES,0.7295597484276729,"j=0
αjDKL(PΦ
j || K−1
X"
REFERENCES,0.7311320754716981,"l=0
αlPΦ
l ) + K−1
X"
REFERENCES,0.7327044025157232,"j=0
log(αj)αj"
REFERENCES,0.7342767295597484,"Finally, we can write A = K−1
X"
REFERENCES,0.7358490566037735,"j=0
αjDKL(PΦ
j || K−1
X"
REFERENCES,0.7374213836477987,"l=0
αlPΦ
l ) −H(Wt+1)
(25)"
REFERENCES,0.7389937106918238,"For the remaining term B, we have"
REFERENCES,0.7405660377358491,"B = EPΦ(Ht)EPWt+1 (log q∗(Wt+1 | Φ(Ht+1))] = K−1
X"
REFERENCES,0.7421383647798742,"j=0
EPΦ(Ht)EPWt+1

log(qj(Φ(Ht)))1{Wt+1=j}
 = K−1
X"
REFERENCES,0.7437106918238994,"j=0
EPΦ(Ht)

αj log(qj(Φ(Ht)))
 = K−1
X"
REFERENCES,0.7452830188679245,"j=0
αj Z
log"
REFERENCES,0.7468553459119497,"""
αjpΦ
j (Ht)
PK−1
l=0 pΦ
l (Ht)αl #"
REFERENCES,0.7484276729559748,"p(Φ(Ht))dΦ(Ht) = K−1
X"
REFERENCES,0.75,"j=0
αj Z
log"
REFERENCES,0.7515723270440252,"""
p(Φ(Ht))
PK−1
l=0 pΦ
l (Ht)αl"
REFERENCES,0.7531446540880503,p(Wt+1 = j | Φ(Ht))
REFERENCES,0.7547169811320755,p(Wt+1 = j) #
REFERENCES,0.7562893081761006,p(Φ(Ht))dΦ(Ht)
REFERENCES,0.7578616352201258,"−H(Wt+1) = K−1
X"
REFERENCES,0.7594339622641509,"j=0
αj Z
log"
REFERENCES,0.7610062893081762,"""
p(Φ(Ht))
PK−1
l=0 pΦ
l (Ht)αl #"
REFERENCES,0.7625786163522013,"|
{z
}
=0"
REFERENCES,0.7641509433962265,"p(Φ(Ht))dΦ(Ht) + K−1
X"
REFERENCES,0.7657232704402516,"j=0
αj"
REFERENCES,0.7672955974842768,"Z
log
p(Wt+1 = j | Φ(Ht))"
REFERENCES,0.7688679245283019,p(Wt+1 = j)
REFERENCES,0.7704402515723271,"
p(Φ(Ht))dΦ(Ht) −H(Wt+1)"
REFERENCES,0.7720125786163522,The final form of B is therefore
REFERENCES,0.7735849056603774,"B = −
Z
DKL(PWt+1|PWt+1|Φ(Ht))p(Φ(Ht))dΦ(Ht) −H(Wt+1)
(26)"
REFERENCES,0.7751572327044025,The proposition follows immediately from Equations (25) and (26).
REFERENCES,0.7767295597484277,"Proof. (Theorem 5.4) Since by lemma G.3, the ICLUB formulation in proposition G.4 holds, then to
prove that the representation is balanced, it is enough to see that by the positivity of DKL"
REFERENCES,0.7783018867924528,"ICLUB ≥EPΦ(Ht)

DKL(PWt+1||PWt+1|Φ(Ht))

≥0
(27)"
REFERENCES,0.779874213836478,"ICLUB is minimal when ICLUB = 0, which happens if and only if for j ∈{0, 1, . . . , K −1}
p(Wt+1 = j) = p(Wt+1 = j | Φ(Ht)) almost surely which, by Bayes rule is equivalent to say
p(Φ(Ht)) = p(Φ(Ht) | Wt+1 = j)."
REFERENCES,0.7814465408805031,"H
Causal CPC Pseudo algorithm"
REFERENCES,0.7830188679245284,"In this section, we present a detailed overview of the training procedure for Causal CPC. Initially, we
train the Encoder using only the contrastive terms, as outlined in Algorithm 1. Our primary objective
is to ensure that, for each time step t, the process history Ht is predictive of future local features Zt.
However, calculating the InfoNCE loss for a batch across all possible time steps t = 0, . . . , tmax can
be computationally demanding.
To address this, we adopt a more efficient approach by uniformly sampling a single time step t per
batch. Subsequently, the corresponding process history Ht is contrasted. The sampled Ht is then
employed as input for the InfoMax objective and randomly partitioned into future Hf
t and past Hh
t
sub-processes.
The decoder is trained while taking the encoder as input (Algorithm 2), utilizing a lower learning
rate compared to the untrained part of the decoder. It is trained autoregressively and without teacher
forcing. This implies that for each time step t, our GRU-based decoder should predict the future
sequence of treatments ˆYt+1:t+τ with its hidden state initialized to the representation Φt of the
historical process up to time t."
REFERENCES,0.7845911949685535,Algorithm 1 Pretraining of the encoder
REFERENCES,0.7861635220125787,"Require: Encoder parameters θ1,2,3, learning rate µ"
REFERENCES,0.7877358490566038,"Input: data {Hi,tmax, i = 1, . . . , N}
for p ∈{1, . . . , epochmax} do"
REFERENCES,0.789308176100629,"for B = {Hi,tmax, i = 1, . . . , |B|} do"
REFERENCES,0.7908805031446541,"Zt = Φθ1([Xt, Wt−1, Yt−1]) for t = 0, . . . , tmax.
Choose t ∼U([1, tmax −1]).
Compute Ct = Φθ1,θ2(Ht).
Compute LCP C(θ1, θ2, {Γj}τ
j=1).
Choose t0 ∼U([1, t]).
Compute Ch
t = Φθ1,θ2(Hh
t ), Cf
t = Φθ1,θ2(Hf
t ),
Compute L(InfoMax)(θ1, θ2, γ).
Update parameters"
REFERENCES,0.7924528301886793,"θ1,2,3 ←θ1,2,3 −µ"
REFERENCES,0.7940251572327044,"∂LCP C(θ1, θ2, {Γj}τ
j=1)
∂θ1,2,3
+ ∂L(InfoMax)(θ1, θ2, γ)"
REFERENCES,0.7955974842767296,"∂θ1,2,3 !"
REFERENCES,0.7971698113207547,"end for
end for
Return: Trained encoder."
REFERENCES,0.7987421383647799,"To enhance training efficiency, instead of predicting ˆYi,t+1:t+τ for all individuals i in a batch and for
all possible time steps t, we randomly select m time indices ti,1, . . . , ti,m for each individual i. From
these indices, we compute future treatment response sequences ˆYi,ti,1+1:ti,1+τ, . . . , ˆYi,ti,m+1:ti,m+τ.
We found that is enough to train while selecting randomly 10% of the time steps."
REFERENCES,0.800314465408805,Algorithm 2 Training of the decoder
REFERENCES,0.8018867924528302,"Require: Encoder parameters θ1,2,3, Decoder parameters θ4, θY , θW .
Require: Encoder learning rate µenc, Treatment learning rate µW , Outcome learning rate µY .
Require: Number of random time indices m."
REFERENCES,0.8034591194968553,"Input: data {Hi,tmax, i = 1, . . . , N}
for p ∈{1, . . . , epochmax} do"
REFERENCES,0.8050314465408805,"for B = {Hi,tmax, i = 1, . . . , |B|} do"
REFERENCES,0.8066037735849056,"Compute Ci,t = encoder(Hi,t) for t = 0, . . . , tmax, i = 1, . . . , |B|.
Compute Φt = ΦθR(Ht).
for i = 1, . . . , |B| do"
REFERENCES,0.8081761006289309,"Choose ti,1, . . . , ti,m ∼U([1, tmax −τ]).
for t ∈{ti,1, . . . , ti,m} do"
REFERENCES,0.809748427672956,"Compute ˆYi,t+1:t+τ, ˆWi,t+1:t+τ, Φi,t+1:t+τ−1 = decoder(Φt, Vi, Wi,t, Yi,t, Wi,t+1:t+τ)
end for
end for
Compute Ldec(θR, θY , θW ) and LW (θW , θR).
Update parameters in the order."
REFERENCES,0.8113207547169812,"θ1,2,3 ←θ1,2,3 −µenc"
REFERENCES,0.8128930817610063,"∂Ldec(θR, θY , θW )"
REFERENCES,0.8144654088050315,"∂θ1,2,3 "
REFERENCES,0.8160377358490566,"θ4,Y ←θ4,Y −µY"
REFERENCES,0.8176100628930818,"∂Ldec(θR, θY , θW ) ∂θ4,Y "
REFERENCES,0.8191823899371069,θW ←θW −µW
REFERENCES,0.8207547169811321,"∂LW (θW , θR) ∂θW "
REFERENCES,0.8223270440251572,"end for
end for
Return: Trained decoder."
REFERENCES,0.8238993710691824,"I
Causal CPC: Architecture details"
REFERENCES,0.8254716981132075,"Inputs: [Xt, Wt−1, Yt−1]"
REFERENCES,0.8270440251572327,"Linear Layer
WeightNorm"
REFERENCES,0.8286163522012578,"SELU
Linear Layer
WeightNorm
Outputs: Zt = Φθ1([Xt, Wt−1, Yt−1])
Table 13: Architecture for learning local features Zt"
REFERENCES,0.8301886792452831,"Inputs: Z≤t
GRU (1 layer)
Outputs: Hidden state Ct = Φar
θ2 (Z≤t)
Table 14: Architecture for learning context representation Ct"
REFERENCES,0.8317610062893082,"Inputs: [Φt, Wt]"
REFERENCES,0.8333333333333334,"Linear Layer
WeightNorm"
REFERENCES,0.8349056603773585,"SELU
Linear Layer
WeightNorm"
REFERENCES,0.8364779874213837,"Outputs: ˆYt
Table 15: Architecture for outcome prediction"
REFERENCES,0.8380503144654088,"Inputs: Φt
Linear Layer
SpectralNorm"
REFERENCES,0.839622641509434,"SELU
Linear Layer
SpectralNorm"
REFERENCES,0.8411949685534591,"Outputs: ˆWt
Table 16: Architecture for treatment prediction"
REFERENCES,0.8427672955974843,"J
Models hyperparameters"
REFERENCES,0.8443396226415094,"In this section, we report the range of all hyperparameters to be fine-tuned, as well as fixed hyperpa-
rameters for all models and across the different datasets used in experiments. Best hyperparameter
values are reported in the configuration files in the code repository."
REFERENCES,0.8459119496855346,"Table 17: Hyper-parameters search range for RMSN
Model
Sub-model
Hyperparameter
Cancer simulation
MIMIC III (SS)"
REFERENCES,0.8474842767295597,"RMSNs
Propensity Treatment Network"
REFERENCES,0.8490566037735849,"LSTM layers
1
1
Learning rate
0.01, 0.005, 0.001, 0.0001
0.01, 0.005, 0.001, 0.0001
Batch size
32, 64, 128
32, 64, 128
LSTM hidden units
4, 6, . . . , 12
4, 6, . . . , 30
LSTM dropout rate
-
-
Max gradient norm
0.5, 1, 2
0.5, 1, 2
Early Stopping (min delta)
0.0001
0.0001
Early Stopping (patience)
30
30"
REFERENCES,0.85062893081761,Propensity History Network
REFERENCES,0.8522012578616353,"LSTM layers
1
1
Learning rate
0.01, 0.005, 0.001, 0.0001
0.01, 0.005, 0.001, 0.0001
Batch size
32, 64, 128
64, 128, 256
LSTM hidden units
4, 6, . . . , 20
4, 6, . . . , 30
LSTM dropout rate
-
-
Early Stopping (min delta)
0.0001
0.0001
Early Stopping (patience)
30
30"
REFERENCES,0.8537735849056604,Encoder
REFERENCES,0.8553459119496856,"LSTM layers
1
1
Learning rate
0.01, 0.005, 0.001, 0.0001
0.01, 0.005, 0.001, 0.0001
Batch size
32, 64, 128
32, 64, 128
LSTM hidden units
4, 6, . . . , 20
4, 6, . . . , 30
LSTM dropout rate
-
-
Early Stopping (min delta)
0.0001
0.0001
Early Stopping (patience)
30
30"
REFERENCES,0.8569182389937107,Decoder
REFERENCES,0.8584905660377359,"LSTM layers
1
1
Learning rate
0.01, 0.005, 0.001, 0.0001
0.01, 0.005, 0.001, 0.0001
Batch size
32, 64, 128
128, 512, 1024
LSTM hidden units
4, 6, . . . , 20
4, 6, . . . , 30
LSTM dropout rate
-
-
Max gradient norm
0.5, 1, 2
0.5, 1, 2
Early Stopping (min delta)
0.0001
0.0001
Early Stopping (patience)
30
30"
REFERENCES,0.860062893081761,"Table 18: Hyper-parameters search range for CRN
Model
Sub-model
Hyperparameter
Cancer simulation
MIMIC III (SS)"
REFERENCES,0.8616352201257862,"CRN
Encoder"
REFERENCES,0.8632075471698113,"LSTM layers
1
1
Learning rate
0.01, 0.005, 0.001, 0.0001
0.01, 0.005, 0.001, 0.0001
Batch size
32, 64, 128
32, 64, 128
LSTM hidden units
4, 6, . . . , 30
4, 6, . . . , 30
LSTM dropout rate
-
-
BR size
4, 6, . . . , 20
4, 6, . . . , 30
Early Stopping (min delta)
0.0001
0.0001
Early Stopping (patience)
30
30"
REFERENCES,0.8647798742138365,Decoder
REFERENCES,0.8663522012578616,"LSTM layers
1
1
Learning rate
0.01, 0.005, 0.001, 0.0001
0.01, 0.005, 0.001, 0.0001
Batch size
128, 256, 512
256, 512, 1024
LSTM hidden units
4, 6, . . . , 30
4, 6, . . . , 30
LSTM dropout rate
-
-
BR size
4, 6, . . . , 20
4, 6, . . . , 30
Early Stopping (min delta)
0.0001
0.0001
Early Stopping (patience)
30
30"
REFERENCES,0.8679245283018868,"Table 19: Hyper-parameters search range for G-Net
Hyperparameter
Cancer simulation
MIMIC III (SS)
LSTM layers
1
1
Learning rate
0.01, 0.005, 0.001, 0.0001
0.01, 0.005, 0.001, 0.0001
Batch size
32, 64, 128
32, 64, 128
LSTM hidden units
4, 6, . . . , 30
4, 6, . . . , 30
FC hidden units
4, 6, . . . , 30
4, 6, . . . , 30
LSTM dropout rate
-
-
R size
4, 6, . . . , 20
4, 6, . . . , 30
MC samples
10
10
Early Stopping (min delta)
0.0001
0.0001
Early Stopping (patience)
30
30"
REFERENCES,0.8694968553459119,Table 20: Hyper-parameters search range for Causal Transfomer
REFERENCES,0.8710691823899371,"Hyperparameter
Cancer simulation
MIMIC III (SS)
Transformer blocks
1
1
Learning rate
0.01, 0.005, 0.001, 0.0001
0.01, 0.005, 0.001, 0.0001
Batch size
32, 64, 128
32, 64, 128
Attention heads
2
2
Transformer units
4, 6, . . . , 20
4, 6, . . . , 20
LSTM dropout rate
-
-
BR size
4, 6, . . . , 20
4, 6, . . . , 20
FC hidden units
4, 6, . . . , 20
4, 6, . . . , 20
Sequential dropout rate
0.1, 0.2, 0.3
0.1, 0.2, 0.3
Max positional encoding
15
15
Early Stopping (min delta)
0.0001
0.0001
Early Stopping (patience)
30
30"
REFERENCES,0.8726415094339622,"Table 21: Hyper-parameters search range for Causal CPC
Model
Sub-model
Hyperparameter
Cancer simulation
MIMIC III (SS)"
REFERENCES,0.8742138364779874,"Causal CPC
Encoder"
REFERENCES,0.8757861635220126,"GRU layers
1
1
Learning rate
0.01, 0.005, 0.001, 0.0001
0.01, 0.005, 0.001, 0.0001
Batch size
32, 64, 128
64, 128, 256
GRU hidden units
4, 6, . . . , 30
4, 6, . . . , 30
GRU dropout rate
-
-
Local features (LF) size
4, 6, . . . , 20
4, 6, . . . , 20
Context Representation (CR) size
4, 6, . . . , 20
4, 6, . . . , 20
Early Stopping (min delta)
0.001
0.001
Early Stopping (patience)
100
100"
REFERENCES,0.8773584905660378,Decoder
REFERENCES,0.8789308176100629,"GRU layers
1
1
Learning rate (decoder w/o treatment sub-network)
0.01, 0.005, 0.001, 0.0001
0.01, 0.005, 0.001, 0.0001
Learning rate (encoder fine-tuning)
0.001, 0.0005, 0.0001, 0.00005
0.001, 0.0005, 0.0001, 0.00005
Learning rate (treatment sub-network)
0.05, 0.01, 0.005, 0.0001
0.05, 0.01, 0.005, 0.0001
Batch size
32, 64, 128
32, 64, 128
GRU hidden units
CR size
CR size
GRU dropout rate
-
-
BR size
CR size
CR size
GRU layers (Treat Encoder)
1
1
GRU hidden units (Treat Encoder)
6
6
FC hidden units
4, 6, . . . , 20
4, 6, . . . , 20
Random time indices (m)
10%
10%
Early Stopping (min delta)
0.001
0.001
Early Stopping (patience)
50
50"
REFERENCES,0.8805031446540881,"Table 22: Hyper-parameters search range for Causal CPC
Model
Sub-model
Hyperparameter
Cancer simulation
MIMIC III (SS)"
REFERENCES,0.8820754716981132,"Causal CPC
Encoder"
REFERENCES,0.8836477987421384,"GRU layers
1
1
Learning rate
0.01, 0.005, 0.001, 0.0001
0.01, 0.005, 0.001, 0.0001
Batch size
32, 64, 128
64, 128, 256
GRU hidden units
4, 6, . . . , 30
4, 6, . . . , 30
GRU dropout rate
-
-
Local features (LF) size
4, 6, . . . , 20
4, 6, . . . , 20
Context Representation (CR) size
4, 6, . . . , 20
4, 6, . . . , 20
Early Stopping (min delta)
0.001
0.001
Early Stopping (patience)
100
100"
REFERENCES,0.8852201257861635,Decoder
REFERENCES,0.8867924528301887,"GRU layers
1
1
Learning rate (decoder w/o treatment sub-network)
0.01, 0.005, 0.001, 0.0001
0.01, 0.005, 0.001, 0.0001
Learning rate (encoder fine-tuning)
0.001, 0.0005, 0.0001, 0.00005
0.001, 0.0005, 0.0001, 0.00005
Learning rate (treatment sub-network)
0.05, 0.01, 0.005, 0.0001
0.05, 0.01, 0.005, 0.0001
Batch size
32, 64, 128
32, 64, 128
GRU hidden units
CR size
CR size
GRU dropout rate
-
-
BR size
CR size
CR size
GRU layers (Treat Encoder)
1
1
GRU hidden units (Treat Encoder)
6
6
FC hidden units
4, 6, . . . , 20
4, 6, . . . , 20
Random time indices (m)
10%
10%
Early Stopping (min delta)
0.001
0.001
Early Stopping (patience)
50
50
NeurIPS Paper Checklist"
CLAIMS,0.8883647798742138,1. Claims
CLAIMS,0.889937106918239,"Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]"
CLAIMS,0.8915094339622641,"Justification: The paper introduces a novel method combining RNNs with CPC for long-term
counterfactual regression, leveraging MI objectives for efficient representation learning, and
demonstrates state-of-the-art results on both synthetic and real-world data. These claims are
substantiated by the detailed theoretical 5 and empirical analyses 6 provided in the paper.
Guidelines:"
CLAIMS,0.8930817610062893,"• The answer NA means that the abstract and introduction do not include the claims
made in the paper.
• The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
• The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
• It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2. Limitations"
CLAIMS,0.8946540880503144,"Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]"
CLAIMS,0.8962264150943396,"Justification: While Causal CPC excels at large horizon predictions, it does not outperform
SOTA models on short-term predictions (Table 1).
Guidelines:"
CLAIMS,0.8977987421383647,"• The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate ""Limitations"" section in their paper.
• The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
• The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
• The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
• The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
• If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
• While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3. Theory Assumptions and Proofs"
CLAIMS,0.89937106918239,"Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: Detailed proofs are provided in Appendix G.
Guidelines:"
CLAIMS,0.9009433962264151,"• The answer NA means that the paper does not include theoretical results.
• All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
• All assumptions should be clearly stated or referenced in the statement of any theorems.
• The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
• Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4. Experimental Result Reproducibility"
CLAIMS,0.9025157232704403,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: All the experimental details related to the training and evaluation protocol (D),
datasets descriptions (E.1 and F.1) are provided. A detailed description of the Causal CPC
architecture is provided in I. Pseudo-algorithms for both the encoder and the decoder are
also provided in H. Code is provided in the supplementary material."
CLAIMS,0.9040880503144654,Guidelines:
CLAIMS,0.9056603773584906,"• The answer NA means that the paper does not include experiments.
• If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
• If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
• Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
• While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a) If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b) If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c) If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d) We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results."
OPEN ACCESS TO DATA AND CODE,0.9072327044025157,5. Open access to data and code
OPEN ACCESS TO DATA AND CODE,0.9088050314465409,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?"
OPEN ACCESS TO DATA AND CODE,0.910377358490566,Answer: [Yes]
OPEN ACCESS TO DATA AND CODE,0.9119496855345912,Justification: Code is provided in the supplementary material at submission.
OPEN ACCESS TO DATA AND CODE,0.9135220125786163,Guidelines:
OPEN ACCESS TO DATA AND CODE,0.9150943396226415,"• The answer NA means that paper does not include experiments requiring code.
• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
public/guides/CodeSubmissionPolicy) for more details.
• While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
• The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines (https:
//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
• The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
• The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why."
OPEN ACCESS TO DATA AND CODE,0.9166666666666666,"• At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
• Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted."
OPEN ACCESS TO DATA AND CODE,0.9182389937106918,6. Experimental Setting/Details
OPEN ACCESS TO DATA AND CODE,0.9198113207547169,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?"
OPEN ACCESS TO DATA AND CODE,0.9213836477987422,Answer: [Yes]
OPEN ACCESS TO DATA AND CODE,0.9229559748427673,"Justification: Models’ hyperparameter search range is provided in Appendix J, the selection
method is provided at the beginning of Section 6, and remaining details about training and
testing are provided in the experimental protocol (Appendix D)."
OPEN ACCESS TO DATA AND CODE,0.9245283018867925,Guidelines:
OPEN ACCESS TO DATA AND CODE,0.9261006289308176,"• The answer NA means that the paper does not include experiments.
• The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
• The full details can be provided either with the code, in appendix, or as supplemental
material."
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9276729559748428,7. Experiment Statistical Significance
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9292452830188679,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9308176100628931,Answer: [No]
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9323899371069182,"Justification: It is computationally demanding to compute errors bars for all neural network
models in our benchmark. However, we reported the mean and standard deviation of metrics
for each experiment, computed from multiple runs."
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9339622641509434,Guidelines:
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9355345911949685,"• The answer NA means that the paper does not include experiments.
• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
• The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
• The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
• It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
• It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
• For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
• If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text."
EXPERIMENTS COMPUTE RESOURCES,0.9371069182389937,8. Experiments Compute Resources
EXPERIMENTS COMPUTE RESOURCES,0.9386792452830188,"Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?"
EXPERIMENTS COMPUTE RESOURCES,0.940251572327044,Answer: [Yes]
EXPERIMENTS COMPUTE RESOURCES,0.9418238993710691,"Justification: We provided the computation resources used in the title of Table 2 as well
as the time of execution in the same table for cancer simulation data. A similar table is
provided in Appendix F.2 for MIMIC III data (Table 12)."
EXPERIMENTS COMPUTE RESOURCES,0.9433962264150944,Guidelines:
EXPERIMENTS COMPUTE RESOURCES,0.9449685534591195,"• The answer NA means that the paper does not include experiments.
• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
• The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
• The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper)."
CODE OF ETHICS,0.9465408805031447,9. Code Of Ethics
CODE OF ETHICS,0.9481132075471698,"Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?"
CODE OF ETHICS,0.949685534591195,Answer: [Yes]
CODE OF ETHICS,0.9512578616352201,"Justification: Authors acknowledge conducting research in conformity with the NeurIPS
Code of Ethics."
CODE OF ETHICS,0.9528301886792453,Guidelines:
CODE OF ETHICS,0.9544025157232704,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
• If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction)."
BROADER IMPACTS,0.9559748427672956,10. Broader Impacts
BROADER IMPACTS,0.9575471698113207,"Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?"
BROADER IMPACTS,0.9591194968553459,Answer: [Yes]
BROADER IMPACTS,0.960691823899371,Justification: An impact statement is included in Appendix A.
BROADER IMPACTS,0.9622641509433962,Guidelines:
BROADER IMPACTS,0.9638364779874213,"• The answer NA means that there is no societal impact of the work performed.
• If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
• Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
• The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
• The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
• If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML)."
SAFEGUARDS,0.9654088050314465,11. Safeguards
SAFEGUARDS,0.9669811320754716,"Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?"
SAFEGUARDS,0.9685534591194969,Answer: [NA]
SAFEGUARDS,0.970125786163522,Justification:
SAFEGUARDS,0.9716981132075472,Guidelines:
SAFEGUARDS,0.9732704402515723,"• The answer NA means that the paper poses no such risks.
• Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
• Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
• We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort."
LICENSES FOR EXISTING ASSETS,0.9748427672955975,12. Licenses for existing assets
LICENSES FOR EXISTING ASSETS,0.9764150943396226,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?"
LICENSES FOR EXISTING ASSETS,0.9779874213836478,Answer: [Yes]
LICENSES FOR EXISTING ASSETS,0.9795597484276729,"Justification: Authors of models and datasets are appropriately cited in the paper in the intro-
duction (1) and experiment (6) sections. Original owners of some model implementations
are properly credited in our code."
LICENSES FOR EXISTING ASSETS,0.9811320754716981,Guidelines:
LICENSES FOR EXISTING ASSETS,0.9827044025157232,"• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
• The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
• For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
• If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
• For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
• If this information is not available online, the authors are encouraged to reach out to
the asset’s creators."
NEW ASSETS,0.9842767295597484,13. New Assets
NEW ASSETS,0.9858490566037735,"Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?"
NEW ASSETS,0.9874213836477987,Answer: [Yes]
NEW ASSETS,0.9889937106918238,Justification: Code for Causal CPC is provided in the supplementary material.
NEW ASSETS,0.9905660377358491,Guidelines:
NEW ASSETS,0.9921383647798742,"• The answer NA means that the paper does not release new assets.
• Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc."
NEW ASSETS,0.9937106918238994,"• The paper should discuss whether and how consent was obtained from people whose
asset is used.
• At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14. Crowdsourcing and Research with Human Subjects"
NEW ASSETS,0.9952830188679245,"Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification:
Guidelines:"
NEW ASSETS,0.9968553459119497,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification:
Guidelines:"
NEW ASSETS,0.9984276729559748,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
• We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
• For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review."
