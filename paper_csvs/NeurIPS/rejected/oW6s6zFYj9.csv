Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0011695906432748538,"Spiking Neural Networks (SNNs) seek to mimic the spiking behavior of biological
1"
ABSTRACT,0.0023391812865497076,"neurons and are expected to play a key role in the advancement of neural computing
2"
ABSTRACT,0.0035087719298245615,"and artificial intelligence. The efficiency of SNNs is often determined by the
3"
ABSTRACT,0.004678362573099415,"neural coding schemes. Existing coding schemes either cause huge delays and
4"
ABSTRACT,0.005847953216374269,"energy consumption or necessitate intricate neuron models and training techniques.
5"
ABSTRACT,0.007017543859649123,"To address these issues, we propose a novel Stepwise Weighted Spike (SWS)
6"
ABSTRACT,0.008187134502923977,"coding scheme to enhance the encoding of information in spikes. This approach
7"
ABSTRACT,0.00935672514619883,"compresses the spikes by weighting the significance of the spike in each step of
8"
ABSTRACT,0.010526315789473684,"neural computation, achieving high performance and low energy consumption. A
9"
ABSTRACT,0.011695906432748537,"Ternary Self-Amplifying (TSA) neuron model with a silent period is proposed for
10"
ABSTRACT,0.012865497076023392,"supporting SWS-based computing, aimed at minimizing the residual error resulting
11"
ABSTRACT,0.014035087719298246,"from stepwise weighting in neural computation. Our experimental results show
12"
ABSTRACT,0.0152046783625731,"that the SWS coding scheme outperforms the existing neural coding schemes in
13"
ABSTRACT,0.016374269005847954,"very deep SNNs, and significantly reduces operations and latency.
14"
INTRODUCTION,0.017543859649122806,"1
Introduction
15"
INTRODUCTION,0.01871345029239766,"Spiking Neural Networks (SNNs) are known as the third generation of neural network models
16"
INTRODUCTION,0.019883040935672516,"inspired by the biological structures and functions in the brain [32]. Unlike traditional Artificial
17"
INTRODUCTION,0.021052631578947368,"Neural Networks (ANNs) that use continuous activation functions, SNNs incorporate discrete spiking
18"
INTRODUCTION,0.022222222222222223,"events, enabling them to capture temporal dynamics and process information in a manner that closely
19"
INTRODUCTION,0.023391812865497075,"mimics the brain’s functioning [31]. This event-driven paradigm aligns with the brain’s energy-
20"
INTRODUCTION,0.02456140350877193,"efficient computation and has the potential for more efficient and lower-power computing systems.
21"
INTRODUCTION,0.025730994152046785,"[33].
22"
INTRODUCTION,0.026900584795321637,"Various coding schemes have been proposed to describe neural activities, including rate coding and
23"
INTRODUCTION,0.028070175438596492,"temporal coding [9]. Rate coding counts the number of spikes fired within a broad time window
24"
INTRODUCTION,0.029239766081871343,"[23, 3, 18, 6], which effectively mitigates the impact of short-term interference on the signal. It was
25"
INTRODUCTION,0.0304093567251462,"widely accepted in the early days and typically outperformed temporal coding [11, 34, 4, 29, 20].
26"
INTRODUCTION,0.031578947368421054,"However, the rate coding scheme disregards the information in the temporal domain of the input
27"
INTRODUCTION,0.03274853801169591,"spike sequence and requires many pulses to represent the input signal value, making it an inefficient
28"
INTRODUCTION,0.03391812865497076,"coding method that negates the low-power benefits of SNN. Due to the functional similarity to the
29"
INTRODUCTION,0.03508771929824561,"biological neural network, spiking neural networks can embrace the sparsity found in biology and
30"
INTRODUCTION,0.03625730994152047,"are highly compatible with temporal coding [31, 33, 27, 28, 21, 15]. Temporal coding relies on
31"
INTRODUCTION,0.03742690058479532,"the specific timing or patterns of input spikes, allowing for greater information capacity in a single
32"
INTRODUCTION,0.03859649122807018,"pulse. However, it requires a large number of time steps to provide fine-grained timing, which
33"
INTRODUCTION,0.03976608187134503,"increases inference latency. Its sensitivity to variations in spike timing also makes it more vulnerable
34"
INTRODUCTION,0.04093567251461988,"to temporal jitter or delays [25, 24]. Additionally, decoding temporal-coded information usually
35"
INTRODUCTION,0.042105263157894736,"requires more complex neuron models [30, 36] and training methodologies [17, 26].
36"
INTRODUCTION,0.04327485380116959,"In the study of the temporal information dynamics of spikes, Kim et al. [16] discovered a phenomenon
37"
INTRODUCTION,0.044444444444444446,"of temporal information concentration in SNNs. It is found that after training, information becomes
38"
INTRODUCTION,0.0456140350877193,"highly concentrated in the first few timesteps. Based on this observation, we hypothesize that, from
39"
INTRODUCTION,0.04678362573099415,"the perspective of the postsynaptic neuron, the first arriving spikes contain more information and
40"
INTRODUCTION,0.047953216374269005,"require stronger responses. Consequently, we propose a mechanism whereby the neuron augments
41"
INTRODUCTION,0.04912280701754386,"its own membrane potential with a specific coefficient prior to processing the subsequent input.
42"
INTRODUCTION,0.050292397660818715,"This enhancement serves to increase the importance of preceding pulses on neurons, which is why
43"
INTRODUCTION,0.05146198830409357,"the spikes are designated as Stepwise Weighted Spikes (SWS). Nevertheless, the amplification of
44"
INTRODUCTION,0.05263157894736842,"the membrane potential makes it difficult for neurons to reduce its value through traditional ""soft
45"
INTRODUCTION,0.05380116959064327,"reset"" (i.e. subtracted by an amount equal to the firing threshold), which can result in residual errors
46"
INTRODUCTION,0.05497076023391813,"after neuron firing. To address this issue, we make the membrane potential reduced by a magnitude
47"
INTRODUCTION,0.056140350877192984,"exceeding the threshold after firing. As a result, the membrane potential has both positive and negative
48"
INTRODUCTION,0.05730994152046784,"residual values, which will generate both positive and negative spikes. This neuron is designated as a
49"
INTRODUCTION,0.05847953216374269,"Ternary Self-Amplifying (TSA) neuron. To further reduce the error caused by the weighting process,
50"
INTRODUCTION,0.05964912280701754,"a silent period is incorporated into the TSA neuron, allowing it to receive more input information
51"
INTRODUCTION,0.0608187134502924,"before firing. We perform the classification tasks with SWS-based SNN on MNIST, CIFAR10, and
52"
INTRODUCTION,0.06198830409356725,"ImageNet. The results show that the SWS coding scheme can achieve better performance with much
53"
INTRODUCTION,0.06315789473684211,"fewer coding and computing steps. Even in very deep SNN, SWS coding scheme still performs well
54"
INTRODUCTION,0.06432748538011696,"and achieves similar accuracy to the ANN with the same structure. Our major contributions to this
55"
INTRODUCTION,0.06549707602339182,"paper can be summarized as follows:
56"
INTRODUCTION,0.06666666666666667,"• We propose the SWS coding scheme, which enables easy implementation of SNNs with
57"
INTRODUCTION,0.06783625730994151,"low energy consumption and high accuracy. The stepwise weighting process enhances
58"
INTRODUCTION,0.06900584795321638,"the information-carrying capacity of the preceding pulses, greatly reducing the number
59"
INTRODUCTION,0.07017543859649122,"of coding spikes. Negative pulses are introduced in SWS coding to ensure an accurate
60"
INTRODUCTION,0.07134502923976609,"information transmission.
61"
INTRODUCTION,0.07251461988304093,"• A novel TSA neuron model is proposed. TSA neuron progressively weights the input by
62"
INTRODUCTION,0.07368421052631578,"augmenting its residual membrane potential before receiving the subsequent spike. The
63"
INTRODUCTION,0.07485380116959064,"introduction of negative residual membrane potential and negative thresholds enhances the
64"
INTRODUCTION,0.07602339181286549,"accuracy of the model’s output.
65"
INTRODUCTION,0.07719298245614035,"• A silent period is added to TSA neuron to markedly improve accuracy at minimal latency
66"
INTRODUCTION,0.0783625730994152,"cost. By adjusting the silent period step and coding step, SWS-based SNNs can exhibit
67"
INTRODUCTION,0.07953216374269007,"performance advantages in different aspects, improving the flexibility of applications.
68"
RELATED WORK,0.08070175438596491,"2
Related work
69"
RELATED WORK,0.08187134502923976,"SNNs use spike sequences to convey information, making the encoding of real data into pulses a
70"
RELATED WORK,0.08304093567251462,"crucial step. Currently, the mainstream schemes of neural coding are rate coding and temporal coding
71"
RELATED WORK,0.08421052631578947,"[9, 33, 32]. Rate coding represents different activities with the number of spikes emitted within
72"
RELATED WORK,0.08538011695906433,"a specific time window. Due to its simplicity, rate coding is commonly used in deep learning of
73"
RELATED WORK,0.08654970760233918,"SNNs. However, it distributes information uniformly across a large number of spikes, resulting in an
74"
RELATED WORK,0.08771929824561403,"inefficient transmission process that increases network latency and energy consumption. Numerous
75"
RELATED WORK,0.08888888888888889,"researchers have proposed solutions to optimize inference latency in rate coding. Han et al.[11]
76"
RELATED WORK,0.09005847953216374,"proposed a ""soft reset"" spiking neuron model that retains a residual membrane potential after firing
77"
RELATED WORK,0.0912280701754386,"to better mimic the ReLU functionality. They demonstrated near lossless ANN-SNN conversion by
78"
RELATED WORK,0.09239766081871345,"using 2-8 times fewer inference time steps. Still, a delay of thousands of steps is required in large
79"
RELATED WORK,0.0935672514619883,"datasets or deep networks. In [14], Hu et al. reduced the encode time steps by converting a quantized
80"
RELATED WORK,0.09473684210526316,"low-precision ANN to a rate-coded SNN. They also proposed a layer-wise fine-tuning mechanism
81"
RELATED WORK,0.09590643274853801,"to minimize the inference latency. However, their neuron model and the subsequent fine-tuning
82"
RELATED WORK,0.09707602339181287,"algorithm are relatively complex. Furthermore, in deeper neural networks such as ResNet56, a 1.5%
83"
RELATED WORK,0.09824561403508772,"drop in accuracy can be observed. The above rate encoding solutions are limited because they do not
84"
RELATED WORK,0.09941520467836257,"consider the significance of each spike.
85"
RELATED WORK,0.10058479532163743,"In [15], Kim et al. proposed phase coding, which assigns different weights to spikes based on their
86"
RELATED WORK,0.10175438596491228,"time phase. However, the transmission amount of information is bounded by the global phase, which
87"
RELATED WORK,0.10292397660818714,"causes inefficiency in hidden layers, resulting in a latency of up to three thousand steps for a 32-layer
88"
RELATED WORK,0.10409356725146199,"network. Burst coding [21] attempts to overcome this issue by introducing burst spikes, which
89"
RELATED WORK,0.10526315789473684,"utilize Inter-Spike Interval (ISI). Burst spikes are capable of conveying more information quickly and
90"
RELATED WORK,0.1064327485380117,"accurately by inducing Post-Synaptic Potential (PSP) dramatically. Nevertheless, it is still deficient
91"
RELATED WORK,0.10760233918128655,Table 1: Common symbols and their meanings in this paper.
RELATED WORK,0.10877192982456141,"Symbol
Meaning"
RELATED WORK,0.10994152046783626,"Sl
i(t)
The spike train fired by the ith neuron in the lth layer
ul
i(t)
The membrane potential of the ith neuron in the lth layer
zl
i(t)
The integrated inputs to the ith neuron in the lth layer
V l
th
The firing threshold of the neurons in the lth layer
θl
The amplitude of the spikes fired by the neurons in the lth layer"
RELATED WORK,0.1111111111111111,"in terms of latency and efficiency. Rueckauer and Liu [27] proposed an efficient temporal encoding
92"
RELATED WORK,0.11228070175438597,"scheme where the analog activation values of the ANN neurons are represented by the inverse Time-
93"
RELATED WORK,0.11345029239766082,"To-First-Spike (TTFS) in the SNN neurons. Their new spiking network model generates 7-10 times
94"
RELATED WORK,0.11461988304093568,"fewer pulses by utilizing temporal information carried by a single spike. However, as pointed out
95"
RELATED WORK,0.11578947368421053,"in [10], TTFS coding scheme incurs expensive memory access and computational overhead, which
96"
RELATED WORK,0.11695906432748537,"diminishes the benefit of reduced pulse count. Furthermore, TTFS necessitates a large number of time
97"
RELATED WORK,0.11812865497076024,"steps to differentiate between various time points, which also increases network latency. Han and
98"
RELATED WORK,0.11929824561403508,"Roy [10] proposed the Temporal-Switch-Coding (TSC) scheme, in which each input image pixel is
99"
RELATED WORK,0.12046783625730995,"represented by two spikes, and its intensity is proportional to the timing between the two pulses. Their
100"
RELATED WORK,0.1216374269005848,"results showed a reduction in energy expenditure. However, TSC coding requires a large number of
101"
RELATED WORK,0.12280701754385964,"time steps to provide distinguishable time intervals, rendering it an ineffective approach to addressing
102"
RELATED WORK,0.1239766081871345,"the issue of the long latency.
103"
RELATED WORK,0.12514619883040937,"Overall, rate coding employs a large number of pulses to encode information, which results in a
104"
RELATED WORK,0.12631578947368421,"considerable energy overhead and inference delays. On the other hand, temporal coding allows for
105"
RELATED WORK,0.12748538011695906,"greater information capacity in a single spike, but this does not reduce the computing latency as a
106"
RELATED WORK,0.1286549707602339,"precise time point or period can be identified only with a sufficient number of time steps. Therefore,
107"
RELATED WORK,0.12982456140350876,"new neural coding schemes should be developed.
108"
STEPWISE WEIGHTED SPIKE CODING SCHEME,0.13099415204678364,"3
Stepwise weighted spike coding scheme
109"
STEPWISE WEIGHTING,0.13216374269005848,"3.1
Stepwise weighting
110"
STEPWISE WEIGHTING,0.13333333333333333,"The spike train Sl
i(t) of the ith neuron in the lth layer can be expressed as follows:
111"
STEPWISE WEIGHTING,0.13450292397660818,"Sl
i(t) =
X"
STEPWISE WEIGHTING,0.13567251461988303,"tl,(f)
i
∈F l
i"
STEPWISE WEIGHTING,0.1368421052631579,"θlδ(t −tl,(f)
i
)
(1)"
STEPWISE WEIGHTING,0.13801169590643275,"where δ(t) is the Dirac delta function, θl is the spike amplitude of the lth layer, which is usually set
112"
STEPWISE WEIGHTING,0.1391812865497076,"to the same value as the firing threshold. f is the index of the spike in the sequence, and F l
i denotes a
113"
STEPWISE WEIGHTING,0.14035087719298245,"set of spike times which satisfies the firing condition:
114"
STEPWISE WEIGHTING,0.1415204678362573,"tl,(f)
i
: ul
i(tl,(f)
i
) ≥V l
th
(2)"
STEPWISE WEIGHTING,0.14269005847953217,"where ul
i(t) denotes the membrane potential and V l
th denotes the firing threshold of the neurons in
115"
STEPWISE WEIGHTING,0.14385964912280702,"the lth layer.
116"
STEPWISE WEIGHTING,0.14502923976608187,"Our basic idea is to amplify the membrane potential before the receipt of the subsequent input, which
117"
STEPWISE WEIGHTING,0.14619883040935672,"amplifies and prolongs the impact of the preceding input spikes on membrane potential, emulating the
118"
STEPWISE WEIGHTING,0.14736842105263157,"phenomenon of information concentration identified in [16]. For clarity, the meanings of important
119"
STEPWISE WEIGHTING,0.14853801169590644,"symbols are provided in table 1. The action of a neuron in SWS-SNN can be described as follows:
120"
STEPWISE WEIGHTING,0.1497076023391813,"ul
j(t) = βul
j(t −1) + zl
j(t) −Sl
j(t)
(3)"
STEPWISE WEIGHTING,0.15087719298245614,"where β is the amplification factor which should be greater than one, zl
j(t) denotes the PSP (i.e.
121"
STEPWISE WEIGHTING,0.15204678362573099,"integrated inputs):
122"
STEPWISE WEIGHTING,0.15321637426900586,"zl
j(t) =
X"
STEPWISE WEIGHTING,0.1543859649122807,"i
ωl
ijSl−1
i
(t) + bl
j
(4)"
STEPWISE WEIGHTING,0.15555555555555556,"where ωij is the synaptic weight and bl
j is the bias. Begin with the initial value ul
j(0) = 0 and
123"
STEPWISE WEIGHTING,0.1567251461988304,"iteratively apply eq. (3) for each subsequent value until ul
j(n) and substitute eq. (1) and eq. (4) into it,
124"
STEPWISE WEIGHTING,0.15789473684210525,"Figure 1: (a) Illustration of the stepwise weighting process. The meanings of the symbol zl
j(t), ul
j(t)
and Sl
j(t) can be found in table 1. The blue dotted line represents the membrane potential prior to the
spike firing, and the black exponential function-like dotted line is employed to illustrate the trend of
membrane potential amplification. (b) A V l
th equal to θl results in residual errors, leaving a lot of
information unencoded. (c) V l
th is set to 1"
STEPWISE WEIGHTING,0.15906432748538013,"2θl, which increases the possibility to fire spikes early to
better limit the residual. (d) Use negative spikes to correct the excessively emitted information."
STEPWISE WEIGHTING,0.16023391812865498,"eq. (3) can be written as:
125"
STEPWISE WEIGHTING,0.16140350877192983,"ul
j(n) = βnul
j(0) + n
X"
STEPWISE WEIGHTING,0.16257309941520467,"τ=1
βn−τzl
j(τ) =
X"
STEPWISE WEIGHTING,0.16374269005847952,"tl−1,(f)
i X i n
X"
STEPWISE WEIGHTING,0.1649122807017544,"τ=1
βn−τωl
ijθl−1δ(τ −tl−1,(f)
i
) + βn−τbl
j (5)"
STEPWISE WEIGHTING,0.16608187134502925,"Note that Sl
j(t) is set to zero for simplicity. From eq. (5), it can be seen that the stepwise augment of
126"
STEPWISE WEIGHTING,0.1672514619883041,"the membrane potential results in the spike input at time tl−1,(f)
i
encoding the value θl−1βn−tl−1,(f)
i
.
127"
STEPWISE WEIGHTING,0.16842105263157894,"This process is thus referred to as stepwise weighting, and βn−tl−1,(f)
i
serves as the weight. The
128"
STEPWISE WEIGHTING,0.1695906432748538,"earlier the input pulse, the greater its ability to carry information. This solves the problem of excessive
129"
STEPWISE WEIGHTING,0.17076023391812867,"encoding steps in previous schemes, allowing faster information transmission.
130"
RESIDUAL ERROR,0.17192982456140352,"3.2
Residual error
131"
RESIDUAL ERROR,0.17309941520467836,"Stepwise weighting effectively assigns more weight to earlier arriving pulses, but it also makes spike
132"
RESIDUAL ERROR,0.1742690058479532,"generation more tricky. To ensure that input information is efficiently encoded and transmitted to
133"
RESIDUAL ERROR,0.17543859649122806,"the next layer, the residual membrane potential should be minimized after neural computation is
134"
RESIDUAL ERROR,0.17660818713450294,"completed. The stepwise weighting, however, amplifies the residual potential from the previous
135"
RESIDUAL ERROR,0.17777777777777778,"time step. If zl
j(t) remains high in subsequent steps, reducing the membrane potential becomes
136"
RESIDUAL ERROR,0.17894736842105263,"challenging, as shown in fig. 1(b). This vicious cycle ultimately leads to a persistently high membrane
137"
RESIDUAL ERROR,0.18011695906432748,"potential, indicating that a substantial amount of information remains unencoded.
138"
RESIDUAL ERROR,0.18128654970760233,"We refer to this phenomenon as residual error. One contributing factor is that the threshold is set
139"
RESIDUAL ERROR,0.1824561403508772,"too high, resulting in a pulse being emitted only when the membrane potential exceeds the value θl.
140"
RESIDUAL ERROR,0.18362573099415205,"While this prevents excessive information transmission, it results in missed opportunities to bring
141"
RESIDUAL ERROR,0.1847953216374269,"down ul
j(t) by firing a spike.
142"
RESIDUAL ERROR,0.18596491228070175,"To address this issue, we propose setting the firing threshold V l
th to 1"
RESIDUAL ERROR,0.1871345029239766,"2θl. This adjustment facilitates
143"
RESIDUAL ERROR,0.18830409356725147,"pulse generation and reduces the residual membrane potential. After the neuron firing, the membrane
144"
RESIDUAL ERROR,0.18947368421052632,"potential is subtracted by θl, which leads to the emergence of a negative residual that will be stepwise
145"
RESIDUAL ERROR,0.19064327485380117,"Figure 2: (a) Uncertainty in the input distribution leads to residual errors. (b) The silent period allows
more information to be known when firing pulses. Ts is set to 1 here. V l
th is amplified by βTs, and the
original threshold is represented by a gray solid line. The orange dashed line represents the amount of
membrane potential reduction after firing. (c) The silent period also avoids some unnecessary spikes
and increases sparsity. Without the silent period, since ul
j(1) exceeds the original threshold, a pulse
will be generated at t = 1, which will later be corrected by another negative spike. (d) The impact of
the silent period on network latency. The output spike sequences corresponding to different inputs
are drawn in blocks of different colors. The pulses drawn in the spike sequence are for illustrative
purposes only."
RESIDUAL ERROR,0.19181286549707602,"weighted over time. The coefficient 1/2 is selected as it is capable of controlling both positive and
146"
RESIDUAL ERROR,0.19298245614035087,"negative residuals within a narrow and balanced range. A negative threshold −V l
th is introduced into
147"
RESIDUAL ERROR,0.19415204678362574,"the neuron model, which initiates a negative spike when the membrane potential falls below this
148"
RESIDUAL ERROR,0.1953216374269006,"threshold. This mechanism allows the excessively emitted information to be corrected by the negative
149"
RESIDUAL ERROR,0.19649122807017544,"spike, as shown in fig. 1(d). Given the above characteristics, we designate this neuron model as a
150"
RESIDUAL ERROR,0.1976608187134503,"TSA neuron.
151"
SILENT PERIOD,0.19883040935672514,"3.3
Silent period
152"
SILENT PERIOD,0.2,"Another contributing factor to residual error is the imbalanced distribution of zl
j(t). A burst input of
153"
SILENT PERIOD,0.20116959064327486,"zl
j(t) at time point τ results in a sharp rise in membrane potential, making it difficult for subsequent
154"
SILENT PERIOD,0.2023391812865497,"spikes to reduce it, as shown in fig. 2(a).
155"
SILENT PERIOD,0.20350877192982456,"This can be addressed by incorporating a silent period Ts into the TSA neuron model. The neurons
156"
SILENT PERIOD,0.2046783625730994,"only integrates input and performs stepwise weighting, but are not allowed to fire in the first Ts
157"
SILENT PERIOD,0.20584795321637428,"steps. This enables the acquisition of more known information before spike generation, resulting
158"
SILENT PERIOD,0.20701754385964913,"in increased accuracy, as illustrated in fig. 2(b). Since the preceding input information has been
159"
SILENT PERIOD,0.20818713450292398,"amplified by βTs after the silent period, V l
th also needs to be adjusted accordingly, which is set to
160 βTs"
SILENT PERIOD,0.20935672514619882,"2 θl. Similarly, after firing, the membrane potential should be subtracted by θlβTs. Note that the
161"
SILENT PERIOD,0.21052631578947367,"fired spike amplitude remains unchanged, that is, θl.
162"
SILENT PERIOD,0.21169590643274855,"The impact of the silent period on network latency is shown in fig. 2(d). The output results for
163"
SILENT PERIOD,0.2128654970760234,"different input sequences are distinguished by blocks of different colors. It can be observed that
164"
SILENT PERIOD,0.21403508771929824,"as network depth increases, the silent period accumulates, leading to a higher output latency. The
165"
SILENT PERIOD,0.2152046783625731,"inference latency of SWS-SNN can be calculated as follows:
166"
SILENT PERIOD,0.21637426900584794,"Tinf = Tc + Ts · LTSA
(6)"
SILENT PERIOD,0.21754385964912282,"where Tinf is the inference delay, Tc is the coding time steps, Ts is the length of the silent period and
167"
SILENT PERIOD,0.21871345029239767,"LTSA is the number of TSA neuron layers. The neuron model in other coding schemes yields a zero
168"
SILENT PERIOD,0.2198830409356725,"Ts, leading to an output delay equal to the coding time step, which is consistent with the definition in
169"
SILENT PERIOD,0.22105263157894736,"the previous scheme. From fig. 2(d), it can be seen that different input sequences are processed in a
170"
SILENT PERIOD,0.2222222222222222,"pipeline-like manner, and the value of Tc + Ts determines the throughput rate of SWS-SNN.
171"
INPUT ENCODING,0.22339181286549709,"3.4
Input encoding
172"
INPUT ENCODING,0.22456140350877193,"According to eq. (5), the value that can be losslessly encoded under the SWS coding scheme can be
173"
INPUT ENCODING,0.22573099415204678,"expressed as follows:
174 Aj = Tc
X"
INPUT ENCODING,0.22690058479532163,"τ=1
aτ
j · θ0βTc−τ
(7)"
INPUT ENCODING,0.22807017543859648,"where Aj denotes the encoded value. aτ
j ∈{−1, 0, 1} indicates the type of the output spike at time τ:
175"
INPUT ENCODING,0.22923976608187135,"1 for a positive pulse, −1 for a negative pulse and 0 for no pulse. Tc denoted the time steps used for
176"
INPUT ENCODING,0.2304093567251462,"encoding. The weight βTc−τ results from the stepwise weighting process described in section 3.1. θ0
177"
INPUT ENCODING,0.23157894736842105,"denotes the spike amplitude of the input encoding layer, which can be assigned an appropriate value
178"
INPUT ENCODING,0.2327485380116959,"based on the range to be encoded.
179"
INPUT ENCODING,0.23391812865497075,"According to eq. (7), given a fixed Tc and θ0, the distribution of Aj is determined by β. Setting β to
180"
INPUT ENCODING,0.23508771929824562,"2 is reasonable, as it ensures Aj is evenly distributed within the codable range. Compared to rate
181"
INPUT ENCODING,0.23625730994152047,"coding, which necessitates 2Tc coding steps to encode the same range with same precision, SWS
182"
INPUT ENCODING,0.23742690058479532,"coding significantly enhances coding efficiency. Note that with the introduction of negative pulses,
183"
INPUT ENCODING,0.23859649122807017,"setting β to 3 can also achieve a uniform distribution of Aj and offers even more values for accurate
184"
INPUT ENCODING,0.23976608187134502,"encoding compared to β = 2.1 When β is less than 2, the distribution of Aj becomes denser at
185"
INPUT ENCODING,0.2409356725146199,"smaller values, which may be suitable for encoding data that follows a similar distribution.
186"
INPUT ENCODING,0.24210526315789474,"For static image classification tasks, the pixel value pj can be encoded by applying a constant input
187"
INPUT ENCODING,0.2432748538011696,"z0
j (t) to the TSA neuron. Considering the stepwise weighting process, we can write:
188 pj = Tc
X τ=1"
INPUT ENCODING,0.24444444444444444,"z0
j
 βTc−τ
(8)"
INPUT ENCODING,0.24561403508771928,"where
z0
j
 denotes the amplitude of the constant input z0
j (t). Solve for
z0
j
 and we have:
189"
INPUT ENCODING,0.24678362573099416,"z0
j (t) = Tc
X σ=1"
INPUT ENCODING,0.247953216374269,"pj
PTc
τ=1 βTc−τ · δ(t −σ)
(9)"
INPUT ENCODING,0.24912280701754386,"Given that z0
j (t) is a constant at each step, Ts can be set to 0 for the encoding layer. However, the
190"
INPUT ENCODING,0.25029239766081873,"neuron must await Ts time steps after the completion of an encoding. This allows neurons in the
191"
INPUT ENCODING,0.25146198830409355,"subsequent layer to complete the previous neural computing before receiving the next encoded input.
192"
EXPERIMENTS,0.25263157894736843,"4
Experiments
193"
EXPERIMENTS,0.25380116959064325,"In this section, we convert quantized ANNs to SWS-based SNNs2 and conduct experiments on
194"
EXPERIMENTS,0.2549707602339181,"MNIST, CIFAR10, and ImageNet. Firstly, an overview of SWS-SNN’s performance across various
195"
EXPERIMENTS,0.256140350877193,"datasets is provided. Subsequently, the network’s inference latency and energy consumption is
196"
EXPERIMENTS,0.2573099415204678,"compared with other spike coding schemes. Finally, an ablation study is conducted to investigate the
197"
EXPERIMENTS,0.2584795321637427,"impact of lowered thresholds and silent periods on reducing residuals and enhancing accuracy.
198"
EXPERIMENTS,0.2596491228070175,"ANNs used for conversion are all quantized to 8 bits. β is set to 2 in the experiments to ensure that
199"
EXPERIMENTS,0.2608187134502924,"codable values are evenly distributed. Compared to β = 3, a smaller amplification factor reduces the
200"
EXPERIMENTS,0.26198830409356727,"impact of residual errors, resulting in more accurate output.
201"
EXPERIMENTS,0.2631578947368421,"1Setting β to 2 introduces some coding redundancy. E.g., a1
j = 1, a2
j = −1 and a1
j = 0, a2
j = 1 encodes the
same amount of information.
2Details of the conversion process can be found in appendix A.1 and appendix A.2"
EXPERIMENTS,0.26432748538011697,Table 2: Performance on CIFAR10 and ImageNet.
EXPERIMENTS,0.2654970760233918,"Category
Methods
Architecture
Time
Step
Ts
SNN
Acc
∆Acc†"
EXPERIMENTS,0.26666666666666666,CIFAR10
EXPERIMENTS,0.26783625730994154,"Directly
Learning
STBP-tdBN[35]
ResNet-19
6
-
93.16%
-
TET[5]
ResNet-19
6
-
94.50%
-"
EXPERIMENTS,0.26900584795321636,ANN-SNN
EXPERIMENTS,0.27017543859649124,"TTRBR[20]
ResNet-18
64
-
95.04%
−0.13%
DSR[19]
PreAct-ResNet-18
20
-
95.24%
-
Calibration[18]
VGG-16
256
-
95.79%
+0.05%
OPI[1]
VGG-16
256
-
94.49%
−0.08%
Opt Conversion[4]
ResNet-20
128
-
93.56%
+1.25%"
EXPERIMENTS,0.27134502923976606,"ANN-SNN
SWS (ours)
ResNet-18
8
1
95.67%
+0.22%
VGG-16
8
2
95.86%
−0.04%"
EXPERIMENTS,0.27251461988304093,ImageNet
EXPERIMENTS,0.2736842105263158,"Directly
Learning"
EXPERIMENTS,0.27485380116959063,"TET[5]
SEW-ResNet-34
4
-
68.00%
-
STBP-tdBN[35]
SEW-ResNet-34
4
-
67.04%
-
SEW Resnet[8]
SEW-ResNet-152
4
-
69.26%
-"
EXPERIMENTS,0.2760233918128655,ANN-SNN
EXPERIMENTS,0.2771929824561403,"Hybrid training[26]
ResNet-34
250
-
61.48%
−8.72%
Spiking ResNet[13]
ResNet-50
350
-
72.75%
−2.70%
QCFS[2]
VGG-16
64
-
72.85%
−1.44%
Fast-SNN[14]
VGG-16
7
-
72.95%
−0.41%
COS[12]
ResNet-34
8
-
74.17%
−0.05%
RMP-SNN[11]
ResNet-34
4096
-
69.89%
−0.75%
TTRBR[20]
ResNet-50
512
-
75.04%
−0.98%"
EXPERIMENTS,0.2783625730994152,"ANN-SNN
SWS (ours)"
EXPERIMENTS,0.2795321637426901,"VGG-16
8
2
75.27%
−0.11%
ResNet-34
8
2
76.10%
−0.08%
Inception-v3
8
2
76.70%
−0.70%
ResNet-50
8
2
80.34%
−0.35%
ResNeXt101_32x8d
8
1
81.32%
−1.17%
ResNeXt101_32x8d
8
2
82.06%
−0.42%"
EXPERIMENTS,0.2807017543859649,† ∆Acc = AccSNN −AccANN
OVERALL PERFORMANCE,0.2818713450292398,"4.1
Overall performance
202"
OVERALL PERFORMANCE,0.2830409356725146,"For simple classification tasks such as CIFAR10, our proposed SWS coding scheme has a faster
203"
OVERALL PERFORMANCE,0.28421052631578947,"inference speed than other ANN-SNN models while achieving similar classification accuracy, or has
204"
OVERALL PERFORMANCE,0.28538011695906434,"higher classification accuracy than direct learning at similar inference speeds. For example, ResNet18
205"
OVERALL PERFORMANCE,0.28654970760233917,"with SWS improves throughput seven times over [20] while simultaneously improving accuracy.
206"
OVERALL PERFORMANCE,0.28771929824561404,"Although the network in [5] has a slightly higher throughput, its accuracy is 1.17% lower than our
207"
OVERALL PERFORMANCE,0.28888888888888886,"scheme. To fully test the potential of our proposed coding scheme, we conducted experiments on
208"
OVERALL PERFORMANCE,0.29005847953216374,"ImageNet using networks with various structures. The experimental results demonstrate that SWS
209"
OVERALL PERFORMANCE,0.2912280701754386,"coding has distinct advantages on extremely deep SNNs. Our SWS-based ResNet50 and ResNeXt101
210"
OVERALL PERFORMANCE,0.29239766081871343,"achieved over 80% accuracy on ImageNet with only eight coding steps. The model in [12] achieves
211"
OVERALL PERFORMANCE,0.2935672514619883,"an almost lossless conversion with eight time steps. However, their method has to adjust the resting
212"
OVERALL PERFORMANCE,0.29473684210526313,"potential of neurons layer by layer, and the calibration effect for deeper networks is unclear. In [14],
213"
OVERALL PERFORMANCE,0.295906432748538,"the original ANN needs to be quantized to 3 bits, resulting in a larger conversion loss. Directly trained
214"
OVERALL PERFORMANCE,0.2970760233918129,"SNNs typically achieve higher throughput, but their accuracy still requires improvement. In addition,
215"
OVERALL PERFORMANCE,0.2982456140350877,"the SWS coding scheme is easy to implement. No further fine-tuning is required after the conversion.
216"
OVERALL PERFORMANCE,0.2994152046783626,"4.2
Accuracy vs. latency
217"
OVERALL PERFORMANCE,0.30058479532163745,"The comparison of latency results between SWS-SNN and other ANN-converted SNNs[1, 11, 10,
218"
OVERALL PERFORMANCE,0.3017543859649123,"4, 18, 2, 7] is illustrated in fig. 3. The latency of the network is calculated with eq. (6). In the
219"
OVERALL PERFORMANCE,0.30292397660818715,"counterpart models, the variation of delay is mainly caused by the changes in Tc. In contrast,
220"
OVERALL PERFORMANCE,0.30409356725146197,"Ts determines latency in deep SWS-SNNs. Therefore, SWS-SNN has an upper limit on latency:
221"
OVERALL PERFORMANCE,0.30526315789473685,"T max
inf
= Tc(1 + LTSA), which causes our curve to terminate earlier in fig. 3.
222"
OVERALL PERFORMANCE,0.3064327485380117,"To ensure a fair comparison, we represent the ANN accuracy of each counterpart with dotted lines of
223"
OVERALL PERFORMANCE,0.30760233918128654,"the same color. The experimental results indicate that SWS-SNN can achieve optimal performance
224"
OVERALL PERFORMANCE,0.3087719298245614,"with minimal latency. Specifically, SWS-based VGG-16 can converge to the ANN performance
225"
OVERALL PERFORMANCE,0.30994152046783624,"24
25
26
27
28
29
Latency 88 89 90 91 92 93 94 95 96"
OVERALL PERFORMANCE,0.3111111111111111,CIFAR10 acc (%)
OVERALL PERFORMANCE,0.312280701754386,(a) VGG-16 on CIFAR10
OVERALL PERFORMANCE,0.3134502923976608,"TWS (ours)
RMP
Calibration
OPI
Opt
RNL"
OVERALL PERFORMANCE,0.3146198830409357,"24
25
26
27
28
29
210
Latency 56 58 60 62 64 66 68 70 72 74 76"
OVERALL PERFORMANCE,0.3157894736842105,ImageNet acc (%)
OVERALL PERFORMANCE,0.3169590643274854,(b) VGG-16 on ImageNet
OVERALL PERFORMANCE,0.31812865497076026,"TWS (ours)
RMP
Calibration
OPI
QCFS
TSC"
OVERALL PERFORMANCE,0.3192982456140351,"24
25
26
27
28
29
210
Latency 54 56 58 60 62 64 66 68 70 72 74 76"
OVERALL PERFORMANCE,0.32046783625730996,ImageNet acc (%)
OVERALL PERFORMANCE,0.3216374269005848,(c) ResNet34 on ImageNet
OVERALL PERFORMANCE,0.32280701754385965,"TWS (ours)
RMP
Calibration
QCFS
TSC"
OVERALL PERFORMANCE,0.32397660818713453,"Figure 3: Latency versus accuracy. The ANN accuracy of each compared SNN is marked by dotted
lines of the same colour. (a) VGG-16 on CIFAR10. (b) VGG-16 on ImageNet. (c) ResNet34 on
ImageNet."
OVERALL PERFORMANCE,0.32514619883040935,"0.4
0.6
0.8
1.0
1.2
1.4
1.6
1.8
OPF (M) 99.10 99.15 99.20 99.25 99.30 99.35 99.40 99.45"
OVERALL PERFORMANCE,0.3263157894736842,MNIST acc (%) (a)
OVERALL PERFORMANCE,0.32748538011695905,"Ts=0
Ts=1
Ts=2"
OVERALL PERFORMANCE,0.3286549707602339,"0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
OPF (M)"
OVERALL PERFORMANCE,0.3298245614035088,"97.8
98.0
98.2
98.4
98.6
98.8
99.0
99.2
99.4"
OVERALL PERFORMANCE,0.3309941520467836,MNIST acc (%) (b)
OVERALL PERFORMANCE,0.3321637426900585,"SWS (Tc=8)
SWS (Tc=6)
SWS (Tc=5)
SWS (Tc=4)
Rate (44 steps)
Rate (18 steps)"
OVERALL PERFORMANCE,0.3333333333333333,"TTFS (base)
TTFS (dyn thresh)
TTFS (clamped)
Pattern (4bits)
Pattern (8bits)
TC=4"
OVERALL PERFORMANCE,0.3345029239766082,"Tc=5
Tc=6"
OVERALL PERFORMANCE,0.33567251461988307,"Tc=7
Tc=8"
OVERALL PERFORMANCE,0.3368421052631579,"Figure 4: (a) Accuracy versus OPF with different combinations of Tc and Ts. (b) Comparison of
accuracy and energy consumption of SWS-SNN with other SNNs."
OVERALL PERFORMANCE,0.33801169590643276,"in the shortest time on CIFAR10 and reduce the inference latency on ImageNet by more than one
226"
OVERALL PERFORMANCE,0.3391812865497076,"order. Even though the silent period accumulates when the network gets deeper, the results in fig. 3(c)
227"
OVERALL PERFORMANCE,0.34035087719298246,"demonstrate that our scheme still achieves the fastest inference speed with the highest accuracy in a
228"
OVERALL PERFORMANCE,0.34152046783625734,"34-layer network. Note that Ts is set to the same value for each TSA layer for simplicity, resulting in
229"
OVERALL PERFORMANCE,0.34269005847953216,"discontinuous Tinf values. This causes a sharp drop in accuracy at smaller delays.
230"
OPERATION COUNTING,0.34385964912280703,"4.3
Operation counting
231"
OPERATION COUNTING,0.34502923976608185,"To compare the energy consumption of SWS-SNN with SNNs under other encoding schemes, we
232"
OPERATION COUNTING,0.34619883040935673,"adopt the method as in [29, 27, 28] to count operations:
233"
OPERATION COUNTING,0.3473684210526316,OPF = (Tc + Ts)NTSA +
OPERATION COUNTING,0.3485380116959064,"LTSA
X l=1"
OPERATION COUNTING,0.3497076023391813,"Tsl+Tc
X"
OPERATION COUNTING,0.3508771929824561,"τ=Tsl+1
f l
outnl(τ)
(10)"
OPERATION COUNTING,0.352046783625731,"where OPF (Operations Per Frame) denotes the number of operations for the classification of one
234"
OPERATION COUNTING,0.3532163742690059,"frame, Tc and Ts denotes the coding steps and the length of the silent period, respectively. LTSA
235"
OPERATION COUNTING,0.3543859649122807,"denotes the number of TSA layers, f l
out denotes the fan-out of neurons in layer l, nl(t) denotes the
236"
OPERATION COUNTING,0.35555555555555557,"number of spikes fired in layer l at time τ and NTSA denotes the number of TSA neurons. The
237"
OPERATION COUNTING,0.3567251461988304,"first term on the right-hand side of the equation arises from the TSA’s requirement to amplify the
238"
OPERATION COUNTING,0.35789473684210527,"membrane potential. Note that due to the accumulation of Ts over the network depth, the time period
239"
OPERATION COUNTING,0.35906432748538014,"for counting nl(t) varies with l.
240"
OPERATION COUNTING,0.36023391812865496,"Experiments were conducted on MNIST using LeNet-5. We varied the silent periods and adjusted
241"
OPERATION COUNTING,0.36140350877192984,"the coding steps to study their effects on OPF. The results are presented in fig. 4(a). As indicated in
242"
OPERATION COUNTING,0.36257309941520466,"eq. (10), reducing Tc lowers energy overhead. This presents a trade-off between energy consumption
243"
OPERATION COUNTING,0.36374269005847953,"and inference accuracy, as fewer coding steps also reduce the number of values that can be accurately
244"
OPERATION COUNTING,0.3649122807017544,"encoded. A larger Ts requires TSA neurons to perform more operations to amplify the membrane
245"
OPERATION COUNTING,0.36608187134502923,"potential. On the other hand, it reduces the number of unnecessary pulse emissions. Overall, silent
246"
OPERATION COUNTING,0.3672514619883041,"period has a negligible impact on OPF.
247"
OPERATION COUNTING,0.3684210526315789,"0.2
0.4
0.6
0.8
1.0
1.2
1.4
1.6
Residual (normalized) 0 20 40 60 80 100"
OPERATION COUNTING,0.3695906432748538,Prob. density (a)
OPERATION COUNTING,0.3707602339181287,"Vl
th =
l, Ts = 0"
OPERATION COUNTING,0.3719298245614035,"Vl
th =
l, Ts = 1"
OPERATION COUNTING,0.3730994152046784,"Vl
th =
l, Ts = 2"
OPERATION COUNTING,0.3742690058479532,"Vl
th =
l"
OPERATION COUNTING,0.37543859649122807,"2 , Ts = 0"
OPERATION COUNTING,0.37660818713450295,"Vl
th =
l"
OPERATION COUNTING,0.37777777777777777,"2 , Ts = 1"
OPERATION COUNTING,0.37894736842105264,"Vl
th =
l"
OPERATION COUNTING,0.38011695906432746,"2 , Ts = 2"
OPERATION COUNTING,0.38128654970760234,"0.20
0.25
0.30
200 250 300 350 400 0 20 40 60 80 100"
OPERATION COUNTING,0.3824561403508772,CIFAR10 acc (%) 9.91
OPERATION COUNTING,0.38362573099415204,84.21 94.89 35.41
OPERATION COUNTING,0.3847953216374269,95.67 95.68 (b)
OPERATION COUNTING,0.38596491228070173,"Vl
th =
l, Ts = 0"
OPERATION COUNTING,0.3871345029239766,"Vl
th =
l, Ts = 1"
OPERATION COUNTING,0.3883040935672515,"Vl
th =
l, Ts = 2"
OPERATION COUNTING,0.3894736842105263,"Vl
th =
l"
OPERATION COUNTING,0.3906432748538012,"2 , Ts = 0"
OPERATION COUNTING,0.391812865497076,"Vl
th =
l"
OPERATION COUNTING,0.3929824561403509,"2 , Ts = 1"
OPERATION COUNTING,0.39415204678362575,"Vl
th =
l"
OPERATION COUNTING,0.3953216374269006,"2 , Ts = 2"
OPERATION COUNTING,0.39649122807017545,"Figure 5: (a) The probability density of the residuals with/without a lowered V l
th and a silent period.
(b) Inference accuracy of SWS-ResNet18 on CIFAR10 with/without a lowered V l
th and a silent
period."
OPERATION COUNTING,0.39766081871345027,"In fig. 4(b), the energy consumption of SWS-based SNN is compared with that of other SNNs. The
248"
OPERATION COUNTING,0.39883040935672515,"experimental results demonstrate that our coding scheme can achieve a favorable balance between
249"
OPERATION COUNTING,0.4,"accuracy and energy consumption. The SWS coding scheme is superior to rate coding and temporal
250"
OPERATION COUNTING,0.40116959064327484,"pattern coding in that it requires fewer operations and achieves higher accuracy. In TTFS encoding,
251"
OPERATION COUNTING,0.4023391812865497,"each neuron fires at most one spike at a time, theoretically demanding the least OPF. With Tc = 4,
252"
OPERATION COUNTING,0.40350877192982454,"SWS-SNN can achieve significantly higher accuracy with minimal increase in OPF. Note that if
253"
OPERATION COUNTING,0.4046783625730994,"the ANN is quantized to a lower number of bits (e.g., 4 bits), the error caused by the reduced Tc
254"
OPERATION COUNTING,0.4058479532163743,"can actually be compensated by the quantization algorithm, which can potentially result in a higher
255"
OPERATION COUNTING,0.4070175438596491,"performance.
256"
ABLATION STUDY,0.408187134502924,"4.4
Ablation study
257"
ABLATION STUDY,0.4093567251461988,"In section 3.2 and section 3.3, we proposed reducing the firing threshold and introducing a silent
258"
ABLATION STUDY,0.4105263157894737,"period to mitigate residual error. To assess the impact of these two adjustments, we conducted
259"
ABLATION STUDY,0.41169590643274856,"experiments on CIFAR10 using ResNet18. After the neural computation, the residuals (absolute
260"
ABLATION STUDY,0.4128654970760234,"values) of the TSA neurons were analyzed. We first scaled the residuals by 1/βTs to counteract the
261"
ABLATION STUDY,0.41403508771929826,"effect of membrane potential amplification caused by the silent period, and then normalized them in
262"
ABLATION STUDY,0.4152046783625731,"units of θl. The probability density of the residuals is shown in fig. 5(a).
263"
ABLATION STUDY,0.41637426900584795,"The results demonstrate that lowering V l
th shifts the residual distribution from around 0.5θl to
264"
ABLATION STUDY,0.41754385964912283,"approximately 0.25θl, corresponding to the quantization errors (i.e. rounding errors) under their
265"
ABLATION STUDY,0.41871345029239765,"respective thresholds. The addition of silent periods further concentrates the distribution and reduces
266"
ABLATION STUDY,0.4198830409356725,"large deviations. As can be seen from the green curve in fig. 5(a), setting Ts to 2 and V l
th to θl/2
267"
ABLATION STUDY,0.42105263157894735,"makes the residuals almost all distributed around the quantization error. Compared to the red curve
268"
ABLATION STUDY,0.4222222222222222,"(without a lowered V l
th or a silent period), the residuals are greatly reduced, which fully proves the
269"
ABLATION STUDY,0.4233918128654971,"effectiveness of lowering the threshold and adding a silent period. The inference results on CIFAR10
270"
ABLATION STUDY,0.4245614035087719,"is shown in fig. 5(b). When setting V l
th to θl and Ts to zero, the network’s output is almost random.
271"
ABLATION STUDY,0.4257309941520468,"Lowering the threshold and adding a silent period improve the accuracy to 35.41% and 84.21%,
272"
ABLATION STUDY,0.4269005847953216,"respectively. Ultimately, the combination of both adjustments enabled SWS-ResNet18 to achieve an
273"
ABLATION STUDY,0.4280701754385965,"accuracy of 95.68% on CIFAR10.
274"
CONCLUSION,0.42923976608187137,"5
Conclusion
275"
CONCLUSION,0.4304093567251462,"In this work, we have proposed a novel SWS spike coding scheme. The stepwise weighting process
276"
CONCLUSION,0.43157894736842106,"enhances the information-carrying capacity of the preceding pulses, greatly reducing the number of
277"
CONCLUSION,0.4327485380116959,"time steps for encoding. Combined with a silent period, our proposed TSA neuron model solves the
278"
CONCLUSION,0.43391812865497076,"problem of residual errors and achieves fast and accurate information transmission. Our experimental
279"
CONCLUSION,0.43508771929824563,"results have demonstrated that SWS coding is highly effective in extremely deep SNNs and achieves
280"
CONCLUSION,0.43625730994152045,"state-of-the-art accuracy. The SWS coding scheme is also highly flexible and can adapt to various
281"
CONCLUSION,0.43742690058479533,"needs.
282"
REFERENCES,0.43859649122807015,"References
283"
REFERENCES,0.439766081871345,"[1] Bu, T., Ding, J., Yu, Z., Huang, T.: Optimized potential initialization for low-latency spiking
284"
REFERENCES,0.4409356725146199,"neural networks (2022)
285"
REFERENCES,0.4421052631578947,"[2] Bu, T., Fang, W., Ding, J., Dai, P., Yu, Z., Huang, T.: Optimal ann-snn conversion for high-
286"
REFERENCES,0.4432748538011696,"accuracy and ultra-low-latency spiking neural networks (2023)
287"
REFERENCES,0.4444444444444444,"[3] Cao, Y., Chen, Y., Khosla, D.:
Spiking deep convolutional neural networks for
288"
REFERENCES,0.4456140350877193,"energy-efficient object recognition. International Journal of Computer Vision 113(1), 54–
289"
REFERENCES,0.44678362573099417,"66 (May 2015). https://doi.org/10.1007/s11263-014-0788-3, https://doi.org/10.1007/
290"
REFERENCES,0.447953216374269,"s11263-014-0788-3
291"
REFERENCES,0.44912280701754387,"[4] Deng, S., Gu, S.: Optimal conversion of conventional artificial neural networks to spiking neural
292"
REFERENCES,0.4502923976608187,"networks (2021)
293"
REFERENCES,0.45146198830409356,"[5] Deng, S., Li, Y., Zhang, S., Gu, S.: Temporal efficient training of spiking neural network via
294"
REFERENCES,0.45263157894736844,"gradient re-weighting (2022)
295"
REFERENCES,0.45380116959064326,"[6] Diehl, P.U., Neil, D., Binas, J., Cook, M., Liu, S.C., Pfeiffer, M.:
Fast-classifying,
296"
REFERENCES,0.45497076023391814,"high-accuracy spiking deep networks through weight and threshold balancing. In:
297"
REFERENCES,0.45614035087719296,"2015 International Joint Conference on Neural Networks (IJCNN). pp. 1–8 (2015).
298"
REFERENCES,0.45730994152046783,"https://doi.org/10.1109/IJCNN.2015.7280696
299"
REFERENCES,0.4584795321637427,"[7] Ding, J., Yu, Z., Tian, Y., Huang, T.: Optimal ann-snn conversion for fast and accurate inference
300"
REFERENCES,0.45964912280701753,"in deep spiking neural networks (2021)
301"
REFERENCES,0.4608187134502924,"[8] Fang, W., Yu, Z., Chen, Y., Huang, T., Masquelier, T., Tian, Y.: Deep residual learning in
302"
REFERENCES,0.4619883040935672,"spiking neural networks (2022)
303"
REFERENCES,0.4631578947368421,"[9] Guo, W., Fouda, M.E., Eltawil, A.M., Salama, K.N.: Neural coding in spiking neural net-
304"
REFERENCES,0.464327485380117,"works: A comparative study for robust neuromorphic systems. Frontiers in Neuroscience
305"
REFERENCES,0.4654970760233918,"15 (2021). https://doi.org/10.3389/fnins.2021.638474, https://www.frontiersin.org/
306"
REFERENCES,0.4666666666666667,"journals/neuroscience/articles/10.3389/fnins.2021.638474
307"
REFERENCES,0.4678362573099415,"[10] Han, B., Roy, K.: Deep spiking neural network: Energy efficiency through time based coding.
308"
REFERENCES,0.46900584795321637,"In: Vedaldi, A., Bischof, H., Brox, T., Frahm, J.M. (eds.) Computer Vision – ECCV 2020. pp.
309"
REFERENCES,0.47017543859649125,"388–404. Springer International Publishing, Cham (2020)
310"
REFERENCES,0.47134502923976607,"[11] Han, B., Srinivasan, G., Roy, K.: Rmp-snn: Residual membrane potential neuron for enabling
311"
REFERENCES,0.47251461988304094,"deeper high-accuracy and low-latency spiking neural network (2020)
312"
REFERENCES,0.47368421052631576,"[12] Hao, Z., Ding, J., Bu, T., Huang, T., Yu, Z.: Bridging the gap between anns and snns by
313"
REFERENCES,0.47485380116959064,"calibrating offset spikes (2023)
314"
REFERENCES,0.4760233918128655,"[13] Hu,
Y.,
Tang,
H.,
Pan,
G.:
Spiking
deep
residual
networks.
IEEE
Transac-
315"
REFERENCES,0.47719298245614034,"tions
on
Neural
Networks
and
Learning
Systems
34(8),
5200–5205
(2023).
316"
REFERENCES,0.4783625730994152,"https://doi.org/10.1109/TNNLS.2021.3119238
317"
REFERENCES,0.47953216374269003,"[14] Hu, Y., Zheng, Q., Jiang, X., Pan, G.: Fast-snn: Fast spiking neural network by converting
318"
REFERENCES,0.4807017543859649,"quantized ann. IEEE Transactions on Pattern Analysis and Machine Intelligence 45(12), 14546–
319"
REFERENCES,0.4818713450292398,"14562 (2023). https://doi.org/10.1109/TPAMI.2023.3275769
320"
REFERENCES,0.4830409356725146,"[15] Kim, J., Kim, H., Huh, S., Lee, J., Choi, K.: Deep neural networks with weighted spikes. Neuro-
321"
REFERENCES,0.4842105263157895,"computing 311, 373–386 (2018). https://doi.org/https://doi.org/10.1016/j.neucom.2018.05.087,
322"
REFERENCES,0.4853801169590643,"https://www.sciencedirect.com/science/article/pii/S0925231218306726
323"
REFERENCES,0.4865497076023392,"[16] Kim, Y., Li, Y., Park, H., Venkatesha, Y., Hambitzer, A., Panda, P.: Exploring temporal
324"
REFERENCES,0.48771929824561405,"information dynamics in spiking neural networks (2022)
325"
REFERENCES,0.4888888888888889,"[17] Lee, C., Sarwar, S.S., Panda, P., Srinivasan, G., Roy, K.: Enabling spike-based back-
326"
REFERENCES,0.49005847953216375,"propagation for training deep neural network architectures. Frontiers in Neuroscience
327"
REFERENCES,0.49122807017543857,"14 (Feb 2020). https://doi.org/10.3389/fnins.2020.00119, http://dx.doi.org/10.3389/
328"
REFERENCES,0.49239766081871345,"fnins.2020.00119
329"
REFERENCES,0.4935672514619883,"[18] Li, Y., Deng, S., Dong, X., Gong, R., Gu, S.: A free lunch from ann: Towards efficient, accurate
330"
REFERENCES,0.49473684210526314,"spiking neural networks calibration (2021)
331"
REFERENCES,0.495906432748538,"[19] Meng, Q., Xiao, M., Yan, S., Wang, Y., Lin, Z., Luo, Z.Q.: Training high-performance low-
332"
REFERENCES,0.49707602339181284,"latency spiking neural networks by differentiation on spike representation (2023)
333"
REFERENCES,0.4982456140350877,"[20] Meng, Q., Yan, S., Xiao, M., Wang, Y., Lin, Z., Luo, Z.Q.: Training much deeper spiking
334"
REFERENCES,0.4994152046783626,"neural networks with a small number of time-steps. Neural Networks 153, 254–268 (2022).
335"
REFERENCES,0.5005847953216375,"https://doi.org/https://doi.org/10.1016/j.neunet.2022.06.001, https://www.sciencedirect.
336"
REFERENCES,0.5017543859649123,"com/science/article/pii/S0893608022002064
337"
REFERENCES,0.5029239766081871,"[21] Park, S., Kim, S., Choe, H., Yoon, S.: Fast and efficient information transmission with burst
338"
REFERENCES,0.504093567251462,"spikes in deep spiking neural networks (2019)
339"
REFERENCES,0.5052631578947369,"[22] Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z.,
340"
REFERENCES,0.5064327485380117,"Gimelshein, N., Antiga, L., Desmaison, A., Köpf, A., Yang, E., DeVito, Z., Raison, M., Tejani,
341"
REFERENCES,0.5076023391812865,"A., Chilamkurthy, S., Steiner, B., Fang, L., Bai, J., Chintala, S.: Pytorch: An imperative style,
342"
REFERENCES,0.5087719298245614,"high-performance deep learning library (2019)
343"
REFERENCES,0.5099415204678363,"[23] Pérez-Carrasco, J.A., Zhao, B., Serrano, C., Acha, B., Serrano-Gotarredona, T., Chen, S.,
344"
REFERENCES,0.5111111111111111,"Linares-Barranco, B.: Mapping from frame-driven to frame-free event-driven vision sys-
345"
REFERENCES,0.512280701754386,"tems by low-rate rate coding and coincidence processing–application to feedforward convnets.
346"
REFERENCES,0.5134502923976608,"IEEE Transactions on Pattern Analysis and Machine Intelligence 35(11), 2706–2719 (2013).
347"
REFERENCES,0.5146198830409356,"https://doi.org/10.1109/TPAMI.2013.71
348"
REFERENCES,0.5157894736842106,"[24] Querlioz, D., Bichler, O., Dollfus, P., Gamrat, C.: Immunity to device variations in a spiking
349"
REFERENCES,0.5169590643274854,"neural network with memristive nanodevices. IEEE Transactions on Nanotechnology 12(3),
350"
REFERENCES,0.5181286549707602,"288–295 (2013). https://doi.org/10.1109/TNANO.2013.2250995
351"
REFERENCES,0.519298245614035,"[25] Querlioz, D., Bichler, O., Gamrat, C.: Simulation of a memristor-based spiking neural network
352"
REFERENCES,0.52046783625731,"immune to device variations. In: The 2011 International Joint Conference on Neural Networks.
353"
REFERENCES,0.5216374269005848,"pp. 1775–1781 (2011). https://doi.org/10.1109/IJCNN.2011.6033439
354"
REFERENCES,0.5228070175438596,"[26] Rathi, N., Srinivasan, G., Panda, P., Roy, K.: Enabling deep spiking neural networks with hybrid
355"
REFERENCES,0.5239766081871345,"conversion and spike timing dependent backpropagation (2020)
356"
REFERENCES,0.5251461988304094,"[27] Rueckauer, B., Liu, S.C.: Conversion of analog to spiking neural networks using sparse temporal
357"
REFERENCES,0.5263157894736842,"coding. In: 2018 IEEE International Symposium on Circuits and Systems (ISCAS). pp. 1–5
358"
REFERENCES,0.5274853801169591,"(2018). https://doi.org/10.1109/ISCAS.2018.8351295
359"
REFERENCES,0.5286549707602339,"[28] Rueckauer, B., Liu, S.C.:
Temporal pattern coding in deep spiking neural networks.
360"
REFERENCES,0.5298245614035088,"In: 2021 International Joint Conference on Neural Networks (IJCNN). pp. 1–8 (2021).
361"
REFERENCES,0.5309941520467836,"https://doi.org/10.1109/IJCNN52387.2021.9533837
362"
REFERENCES,0.5321637426900585,"[29] Rueckauer, B., Lungu, I.A., Hu, Y., Pfeiffer, M., Liu, S.C.: Conversion of continuous-valued
363"
REFERENCES,0.5333333333333333,"deep networks to efficient event-driven networks for image classification. Frontiers in Neuro-
364"
REFERENCES,0.5345029239766081,"science 11 (2017). https://doi.org/10.3389/fnins.2017.00682
365"
REFERENCES,0.5356725146198831,"[30] Stöckl, C., Maass, W.: Optimized spiking neurons can classify images with high accu-
366"
REFERENCES,0.5368421052631579,"racy through temporal coding with two spikes. Nature Machine Intelligence 3(3), 230–
367"
REFERENCES,0.5380116959064327,"238 (Mar 2021). https://doi.org/10.1038/s42256-021-00311-4, https://doi.org/10.1038/
368"
REFERENCES,0.5391812865497077,"s42256-021-00311-4
369"
REFERENCES,0.5403508771929825,"[31] Taherkhani, A., Belatreche, A., Li, Y., Cosma, G., Maguire, L.P., McGinnity, T.: A re-
370"
REFERENCES,0.5415204678362573,"view of learning in biologically plausible spiking neural networks. Neural Networks 122,
371"
REFERENCES,0.5426900584795321,"253–272 (2020). https://doi.org/https://doi.org/10.1016/j.neunet.2019.09.036, https://www.
372"
REFERENCES,0.543859649122807,"sciencedirect.com/science/article/pii/S0893608019303181
373"
REFERENCES,0.5450292397660819,"[32] Wang,
X.,
Lin,
X.,
Dang,
X.:
Supervised learning in spiking neural networks:
374"
REFERENCES,0.5461988304093567,"A review of algorithms and evaluations. Neural Networks 125,
258–280 (2020).
375"
REFERENCES,0.5473684210526316,"https://doi.org/https://doi.org/10.1016/j.neunet.2020.02.011, https://www.sciencedirect.
376"
REFERENCES,0.5485380116959064,"com/science/article/pii/S0893608020300563
377"
REFERENCES,0.5497076023391813,"[33] Yamazaki, K., Vo-Ho, V.K., Bulsara, D., Le, N.: Spiking neural networks and their applications:
378"
REFERENCES,0.5508771929824562,"A review. Brain Sci 12(7) (Jun 2022)
379"
REFERENCES,0.552046783625731,"[34] Yan, Z., Zhou, J., Wong, W.: Near lossless transfer learning for spiking neural networks. In:
380"
REFERENCES,0.5532163742690058,"AAAI Conference on Artificial Intelligence (2021), https://api.semanticscholar.org/
381"
REFERENCES,0.5543859649122806,"CorpusID:235349069
382"
REFERENCES,0.5555555555555556,"[35] Zheng, H., Wu, Y., Deng, L., Hu, Y., Li, G.: Going deeper with directly-trained larger spiking
383"
REFERENCES,0.5567251461988304,"neural networks (2020)
384"
REFERENCES,0.5578947368421052,"[36] Zhou, S., LI, X., Chen, Y., Chandrasekaran, S.T., Sanyal, A.: Temporal-coded deep spiking
385"
REFERENCES,0.5590643274853802,"neural network with easy training and robust performance (2021)
386"
REFERENCES,0.560233918128655,"A
Appendix
387"
REFERENCES,0.5614035087719298,"A.1
Convert quantized ANNs to SWS-SNNs
388"
REFERENCES,0.5625730994152047,"A pretrained ANN was first obtained from torchvision, which is part of the PyTorch[22] project, and
389"
REFERENCES,0.5637426900584795,"then quantized into n bits following the Quantization-Aware Training (QAT) Workflow provided by
390"
REFERENCES,0.5649122807017544,"PyTorch (8 bits in the actual experiment, with n bits used here for generality). The quantized ANN
391"
REFERENCES,0.5660818713450292,"can be characterized by the parameters listed in table 3, and the basic idea of the conversion process is
392"
REFERENCES,0.5672514619883041,"illustrated in fig. 6(a). The activations of the quantized ANN can be mapped to an integer Q between
393"
REFERENCES,0.5684210526315789,"[0, 2n −1] using a scaling factor C and a zero point Z. With the same weight and bias between Ql
i
394"
REFERENCES,0.5695906432748538,"and Ql
o, the TSA layer can generate Sl, which encodes Ql
o, provided that Sl−1 encodes Ql
i and no
395"
REFERENCES,0.5707602339181287,"residual error occurs. In the actual SNN, the pulse amplitude θl is normalized to 1. Therefore, the
396"
REFERENCES,0.5719298245614035,"bias need to be further scaled to derive the final weight W l and bias bl for the SWS-SNN.
397"
REFERENCES,0.5730994152046783,Table 3: The notations and meanings of parameters in the quantized network.
REFERENCES,0.5742690058479533,"Notation
Meaning"
REFERENCES,0.5754385964912281,"ˆXl
i
The quantized input of the lth layer
ˆXl
o
The quantized output of the lth layer
Cl
i
The scaling factor of the quantized input of the lth layer
Zl
i
The zero point of the quantized input of the lth layer
Cl
o
The scaling factor of the quantized output of the lth layer
Zl
o
The zero point of the quantized output of the lth layer
ˆW l
The quantized weight of layer l
Cl
w
The scaling factor of the quantized weight of layer l
Zl
w
The zero point of the quantized weight of layer l
ˆbl
The bias of layer l"
REFERENCES,0.5766081871345029,"The derivation is as follows. After QAT, we have:
398"
REFERENCES,0.5777777777777777,"ˆW l ˆXl
i + ˆbl = ˆXl
o,
(11)"
REFERENCES,0.5789473684210527,"Ql
i =
ˆXl
i
Cl
i
+ Zl
i,
(12)"
REFERENCES,0.5801169590643275,"Ql
o =
ˆXl
o
Clo
+ Zl
o,
(13)"
REFERENCES,0.5812865497076023,"where Ql
i, Ql
o represent the integers to which the quantized input and output are mapped, respectively.
399"
REFERENCES,0.5824561403508772,"Substitute eq. (12) and eq. (13) into eq. (11), and we can write:
400"
REFERENCES,0.583625730994152,"ˆW l(Ql
i −Zl
i)Cl
i + ˆbl = (Ql
o −Zl
o)Cl
o,
(14)
which gives:
401"
REFERENCES,0.5847953216374269,"Ql
o = ˆW l Cl
i
Clo
Ql
i +
ˆbl"
REFERENCES,0.5859649122807018,"Clo
+ Zl
o −
ˆW lZl
iCl
i
Clo
= ˜W lQl
i + ˜bl, (15)"
REFERENCES,0.5871345029239766,"Figure 6: (a) Convert quantized ANNs to SWS-SNNs. Ql
i and Ql
o represent the integers to which ˆXl
i
and ˆXl
o are mapped, respectively. ˜W l and ˜bl denotes the weight and bias to get Ql
o from Ql
i. W l and
bl denotes the weight and bias in SWS-SNN. The process of transferring weights and biases from
the quantized ANN to SWS-SNN is indicated by white arrows. The core of the conversion is that
the distribution of the integer Ql
o is known and can be easily encoded by Sl. (b) Process the input
pixels to encode by pulses with an amplitude of 1. ¯P denotes the original pixel value, P denotes the
mapped value and ˜P denotes the value after scaled by 1/θ0."
REFERENCES,0.5883040935672514,"where
402"
REFERENCES,0.5894736842105263,"˜W l = ˆW l Cl
i
Clo
,
(16)"
REFERENCES,0.5906432748538012,"˜bl =
ˆbl"
REFERENCES,0.591812865497076,"Clo
+ Zl
o −
ˆW lZl
iCl
i
Clo
.
(17)"
REFERENCES,0.5929824561403508,"As seen in eq. (15), with the weight and bias set to ˜W l and ˜bl respectively, the layer outputs Ql
o when
403"
REFERENCES,0.5941520467836258,"receiving Ql
i. The pulse amplitude θl can be set to any value as long as the codable range calculated
404"
REFERENCES,0.5953216374269006,"by eq. (7) covers [0, 2n −1]. Then we have:
405"
REFERENCES,0.5964912280701754,W l = ˜W l θl−1
REFERENCES,0.5976608187134503,"θl
= ˆW l Cl
i
Clo θl−1"
REFERENCES,0.5988304093567252,"θl
(18)"
REFERENCES,0.6,"Considering the membrane potential amplification, bl can be calculated as follows:
406"
REFERENCES,0.6011695906432749,"bl =
1
PTc
τ=1 βTc−τ
˜bl =
1
PTc
τ=1 βTc−τ (
ˆbl"
REFERENCES,0.6023391812865497,"Clo
+ Zl
o −
ˆW lZl
iCl
i
Clo
)
(19)"
REFERENCES,0.6035087719298246,"Once the Tc, β and θl (θl−1 is given by the previous layer) have been determined, all values on the
407"
REFERENCES,0.6046783625730994,"right side of eq. (18) and eq. (19) are known. Consequently, Wl and bl in the SWS-SNN can be
408"
REFERENCES,0.6058479532163743,"readily calculated from the weight and bias of the quantized ANN.
409"
REFERENCES,0.6070175438596491,"After configuring the weights and biases as described above, the input pixel must be encoded into a
410"
REFERENCES,0.6081871345029239,"pulse sequence with an amplitude of 1 as well. This process is illustrated in fig. 6(b). First, map the
411"
REFERENCES,0.6093567251461989,"pixel value to [0, 2n −1] using C0
i and Z0
i obtained from QAT. Assuming this range can be encoded
412"
REFERENCES,0.6105263157894737,"by SWSs with an amplitude of θ0, scaling the pixel value by 1/θ0 allows the use of a sequence with
413"
REFERENCES,0.6116959064327485,"θ0 = 1 for encoding. Finally, encode the scaled pixels following section 3.4, and the required input
414"
REFERENCES,0.6128654970760234,"spike sequence is obtained.
415"
REFERENCES,0.6140350877192983,"A.2
Details for QAT
416"
REFERENCES,0.6152046783625731,"QAT is the quantization method that typically results in the highest accuracy. We basically follows
417"
REFERENCES,0.6163742690058479,"the workflow provided by PyTorch. The default QAT quantization configuration is chosen to specify
418"
REFERENCES,0.6175438596491228,"the kind of fake-quantization inserted after weights and activations. We choose Stochastic Gradient
419"
REFERENCES,0.6187134502923977,"Descent (SGD) optimizer in QAT, with the value of momentum set to 0.9 and the learning rate set to
420"
REFERENCES,0.6198830409356725,"1 × 10−4 since the weights only need to be fine-tuned. QAT is done for 12 epochs and 20 batches in
421"
REFERENCES,0.6210526315789474,"each epoch. We freeze the batch norm mean and variance estimates after three epochs and freeze the
422"
REFERENCES,0.6222222222222222,"quantizer parameters (scaling factor and zero point) after another two epochs.
423"
REFERENCES,0.623391812865497,"NeurIPS Paper Checklist
424"
CLAIMS,0.624561403508772,"1. Claims
425"
CLAIMS,0.6257309941520468,"Question: Do the main claims made in the abstract and introduction accurately reflect the
426"
CLAIMS,0.6269005847953216,"paper’s contributions and scope?
427"
CLAIMS,0.6280701754385964,"Answer: [Yes]
428"
CLAIMS,0.6292397660818714,"Justification: Stepwise weighting enhances the encoding of information in spikes, as is
429"
CLAIMS,0.6304093567251462,"proved in eq. (5) in section 3.1. Our proposed SWS coding scheme achieves high perfor-
430"
CLAIMS,0.631578947368421,"mance and low energy consumption, which is supported by our experimental results in
431"
CLAIMS,0.632748538011696,"section 4. The TSA neuron model effectively minimizes the residual error, which can be
432"
CLAIMS,0.6339181286549708,"proved from the ablation study in section 4.4.
433"
CLAIMS,0.6350877192982456,"Guidelines:
434"
CLAIMS,0.6362573099415205,"• The answer NA means that the abstract and introduction do not include the claims
435"
CLAIMS,0.6374269005847953,"made in the paper.
436"
CLAIMS,0.6385964912280702,"• The abstract and/or introduction should clearly state the claims made, including the
437"
CLAIMS,0.639766081871345,"contributions made in the paper and important assumptions and limitations. A No or
438"
CLAIMS,0.6409356725146199,"NA answer to this question will not be perceived well by the reviewers.
439"
CLAIMS,0.6421052631578947,"• The claims made should match theoretical and experimental results, and reflect how
440"
CLAIMS,0.6432748538011696,"much the results can be expected to generalize to other settings.
441"
CLAIMS,0.6444444444444445,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
442"
CLAIMS,0.6456140350877193,"are not attained by the paper.
443"
LIMITATIONS,0.6467836257309941,"2. Limitations
444"
LIMITATIONS,0.6479532163742691,"Question: Does the paper discuss the limitations of the work performed by the authors?
445"
LIMITATIONS,0.6491228070175439,"Answer: [Yes]
446"
LIMITATIONS,0.6502923976608187,"Justification: The inclusion of silent periods can lead to increased latency, as noted in
447"
LIMITATIONS,0.6514619883040935,"section 3.3, which is a limitation we’ve found so far. However, our experimental results
448"
LIMITATIONS,0.6526315789473685,"demonstrate that our delay performance still surpasses that of other SNNs.
449"
LIMITATIONS,0.6538011695906433,"Guidelines:
450"
LIMITATIONS,0.6549707602339181,"• The answer NA means that the paper has no limitation while the answer No means that
451"
LIMITATIONS,0.656140350877193,"the paper has limitations, but those are not discussed in the paper.
452"
LIMITATIONS,0.6573099415204678,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
453"
LIMITATIONS,0.6584795321637427,"• The paper should point out any strong assumptions and how robust the results are to
454"
LIMITATIONS,0.6596491228070176,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
455"
LIMITATIONS,0.6608187134502924,"model well-specification, asymptotic approximations only holding locally). The authors
456"
LIMITATIONS,0.6619883040935672,"should reflect on how these assumptions might be violated in practice and what the
457"
LIMITATIONS,0.6631578947368421,"implications would be.
458"
LIMITATIONS,0.664327485380117,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
459"
LIMITATIONS,0.6654970760233918,"only tested on a few datasets or with a few runs. In general, empirical results often
460"
LIMITATIONS,0.6666666666666666,"depend on implicit assumptions, which should be articulated.
461"
LIMITATIONS,0.6678362573099416,"• The authors should reflect on the factors that influence the performance of the approach.
462"
LIMITATIONS,0.6690058479532164,"For example, a facial recognition algorithm may perform poorly when image resolution
463"
LIMITATIONS,0.6701754385964912,"is low or images are taken in low lighting. Or a speech-to-text system might not be
464"
LIMITATIONS,0.6713450292397661,"used reliably to provide closed captions for online lectures because it fails to handle
465"
LIMITATIONS,0.672514619883041,"technical jargon.
466"
LIMITATIONS,0.6736842105263158,"• The authors should discuss the computational efficiency of the proposed algorithms
467"
LIMITATIONS,0.6748538011695906,"and how they scale with dataset size.
468"
LIMITATIONS,0.6760233918128655,"• If applicable, the authors should discuss possible limitations of their approach to
469"
LIMITATIONS,0.6771929824561403,"address problems of privacy and fairness.
470"
LIMITATIONS,0.6783625730994152,"• While the authors might fear that complete honesty about limitations might be used by
471"
LIMITATIONS,0.6795321637426901,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
472"
LIMITATIONS,0.6807017543859649,"limitations that aren’t acknowledged in the paper. The authors should use their best
473"
LIMITATIONS,0.6818713450292397,"judgment and recognize that individual actions in favor of transparency play an impor-
474"
LIMITATIONS,0.6830409356725147,"tant role in developing norms that preserve the integrity of the community. Reviewers
475"
LIMITATIONS,0.6842105263157895,"will be specifically instructed to not penalize honesty concerning limitations.
476"
THEORY ASSUMPTIONS AND PROOFS,0.6853801169590643,"3. Theory Assumptions and Proofs
477"
THEORY ASSUMPTIONS AND PROOFS,0.6865497076023391,"Question: For each theoretical result, does the paper provide the full set of assumptions and
478"
THEORY ASSUMPTIONS AND PROOFS,0.6877192982456141,"a complete (and correct) proof?
479"
THEORY ASSUMPTIONS AND PROOFS,0.6888888888888889,"Answer: [Yes]
480"
THEORY ASSUMPTIONS AND PROOFS,0.6900584795321637,"Justification: The membrane potential amplification enhances the information-carrying
481"
THEORY ASSUMPTIONS AND PROOFS,0.6912280701754386,"capacity of the preceding pulses and is proved in eq. (5).
482"
THEORY ASSUMPTIONS AND PROOFS,0.6923976608187135,"Guidelines:
483"
THEORY ASSUMPTIONS AND PROOFS,0.6935672514619883,"• The answer NA means that the paper does not include theoretical results.
484"
THEORY ASSUMPTIONS AND PROOFS,0.6947368421052632,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
485"
THEORY ASSUMPTIONS AND PROOFS,0.695906432748538,"referenced.
486"
THEORY ASSUMPTIONS AND PROOFS,0.6970760233918128,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
487"
THEORY ASSUMPTIONS AND PROOFS,0.6982456140350877,"• The proofs can either appear in the main paper or the supplemental material, but if
488"
THEORY ASSUMPTIONS AND PROOFS,0.6994152046783626,"they appear in the supplemental material, the authors are encouraged to provide a short
489"
THEORY ASSUMPTIONS AND PROOFS,0.7005847953216374,"proof sketch to provide intuition.
490"
THEORY ASSUMPTIONS AND PROOFS,0.7017543859649122,"• Inversely, any informal proof provided in the core of the paper should be complemented
491"
THEORY ASSUMPTIONS AND PROOFS,0.7029239766081872,"by formal proofs provided in appendix or supplemental material.
492"
THEORY ASSUMPTIONS AND PROOFS,0.704093567251462,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
493"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7052631578947368,"4. Experimental Result Reproducibility
494"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7064327485380117,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
495"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7076023391812866,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
496"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7087719298245614,"of the paper (regardless of whether the code and data are provided or not)?
497"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7099415204678362,"Answer: [Yes]
498"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7111111111111111,"Justification: We set specific random number seeds when conducting experiments to ensure
499"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.712280701754386,"that all the results of section 4 are reproducible.
500"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7134502923976608,"Guidelines:
501"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7146198830409357,"• The answer NA means that the paper does not include experiments.
502"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7157894736842105,"• If the paper includes experiments, a No answer to this question will not be perceived
503"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7169590643274854,"well by the reviewers: Making the paper reproducible is important, regardless of
504"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7181286549707603,"whether the code and data are provided or not.
505"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7192982456140351,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
506"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7204678362573099,"to make their results reproducible or verifiable.
507"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7216374269005847,"• Depending on the contribution, reproducibility can be accomplished in various ways.
508"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7228070175438597,"For example, if the contribution is a novel architecture, describing the architecture fully
509"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7239766081871345,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
510"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7251461988304093,"be necessary to either make it possible for others to replicate the model with the same
511"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7263157894736842,"dataset, or provide access to the model. In general. releasing code and data is often
512"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7274853801169591,"one good way to accomplish this, but reproducibility can also be provided via detailed
513"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7286549707602339,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
514"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7298245614035088,"of a large language model), releasing of a model checkpoint, or other means that are
515"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7309941520467836,"appropriate to the research performed.
516"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7321637426900585,"• While NeurIPS does not require releasing code, the conference does require all submis-
517"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7333333333333333,"sions to provide some reasonable avenue for reproducibility, which may depend on the
518"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7345029239766082,"nature of the contribution. For example
519"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.735672514619883,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
520"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7368421052631579,"to reproduce that algorithm.
521"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7380116959064328,"(b) If the contribution is primarily a new model architecture, the paper should describe
522"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7391812865497076,"the architecture clearly and fully.
523"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7403508771929824,"(c) If the contribution is a new model (e.g., a large language model), then there should
524"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7415204678362574,"either be a way to access this model for reproducing the results or a way to reproduce
525"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7426900584795322,"the model (e.g., with an open-source dataset or instructions for how to construct
526"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.743859649122807,"the dataset).
527"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7450292397660818,"(d) We recognize that reproducibility may be tricky in some cases, in which case
528"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7461988304093568,"authors are welcome to describe the particular way they provide for reproducibility.
529"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7473684210526316,"In the case of closed-source models, it may be that access to the model is limited in
530"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7485380116959064,"some way (e.g., to registered users), but it should be possible for other researchers
531"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7497076023391813,"to have some path to reproducing or verifying the results.
532"
OPEN ACCESS TO DATA AND CODE,0.7508771929824561,"5. Open access to data and code
533"
OPEN ACCESS TO DATA AND CODE,0.752046783625731,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
534"
OPEN ACCESS TO DATA AND CODE,0.7532163742690059,"tions to faithfully reproduce the main experimental results, as described in supplemental
535"
OPEN ACCESS TO DATA AND CODE,0.7543859649122807,"material?
536"
OPEN ACCESS TO DATA AND CODE,0.7555555555555555,"Answer: [No]
537"
OPEN ACCESS TO DATA AND CODE,0.7567251461988304,"Justification: Code will be released when the paper is accepted.
538"
OPEN ACCESS TO DATA AND CODE,0.7578947368421053,"Guidelines:
539"
OPEN ACCESS TO DATA AND CODE,0.7590643274853801,"• The answer NA means that paper does not include experiments requiring code.
540"
OPEN ACCESS TO DATA AND CODE,0.7602339181286549,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
541"
OPEN ACCESS TO DATA AND CODE,0.7614035087719299,"public/guides/CodeSubmissionPolicy) for more details.
542"
OPEN ACCESS TO DATA AND CODE,0.7625730994152047,"• While we encourage the release of code and data, we understand that this might not be
543"
OPEN ACCESS TO DATA AND CODE,0.7637426900584795,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
544"
OPEN ACCESS TO DATA AND CODE,0.7649122807017544,"including code, unless this is central to the contribution (e.g., for a new open-source
545"
OPEN ACCESS TO DATA AND CODE,0.7660818713450293,"benchmark).
546"
OPEN ACCESS TO DATA AND CODE,0.7672514619883041,"• The instructions should contain the exact command and environment needed to run to
547"
OPEN ACCESS TO DATA AND CODE,0.7684210526315789,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
548"
OPEN ACCESS TO DATA AND CODE,0.7695906432748538,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
549"
OPEN ACCESS TO DATA AND CODE,0.7707602339181286,"• The authors should provide instructions on data access and preparation, including how
550"
OPEN ACCESS TO DATA AND CODE,0.7719298245614035,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
551"
OPEN ACCESS TO DATA AND CODE,0.7730994152046784,"• The authors should provide scripts to reproduce all experimental results for the new
552"
OPEN ACCESS TO DATA AND CODE,0.7742690058479532,"proposed method and baselines. If only a subset of experiments are reproducible, they
553"
OPEN ACCESS TO DATA AND CODE,0.775438596491228,"should state which ones are omitted from the script and why.
554"
OPEN ACCESS TO DATA AND CODE,0.776608187134503,"• At submission time, to preserve anonymity, the authors should release anonymized
555"
OPEN ACCESS TO DATA AND CODE,0.7777777777777778,"versions (if applicable).
556"
OPEN ACCESS TO DATA AND CODE,0.7789473684210526,"• Providing as much information as possible in supplemental material (appended to the
557"
OPEN ACCESS TO DATA AND CODE,0.7801169590643274,"paper) is recommended, but including URLs to data and code is permitted.
558"
OPEN ACCESS TO DATA AND CODE,0.7812865497076024,"6. Experimental Setting/Details
559"
OPEN ACCESS TO DATA AND CODE,0.7824561403508772,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
560"
OPEN ACCESS TO DATA AND CODE,0.783625730994152,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
561"
OPEN ACCESS TO DATA AND CODE,0.7847953216374269,"results?
562"
OPEN ACCESS TO DATA AND CODE,0.7859649122807018,"Answer: [Yes]
563"
OPEN ACCESS TO DATA AND CODE,0.7871345029239766,"Justification: The details for acquiring different delays and the OPF calculation method
564"
OPEN ACCESS TO DATA AND CODE,0.7883040935672515,"are provided in section 4.2 and section 4.3, respectively. The parameters used during QAT
565"
OPEN ACCESS TO DATA AND CODE,0.7894736842105263,"training is outlined in appendix A.2.
566"
OPEN ACCESS TO DATA AND CODE,0.7906432748538011,"Guidelines:
567"
OPEN ACCESS TO DATA AND CODE,0.791812865497076,"• The answer NA means that the paper does not include experiments.
568"
OPEN ACCESS TO DATA AND CODE,0.7929824561403509,"• The experimental setting should be presented in the core of the paper to a level of detail
569"
OPEN ACCESS TO DATA AND CODE,0.7941520467836257,"that is necessary to appreciate the results and make sense of them.
570"
OPEN ACCESS TO DATA AND CODE,0.7953216374269005,"• The full details can be provided either with the code, in appendix, or as supplemental
571"
OPEN ACCESS TO DATA AND CODE,0.7964912280701755,"material.
572"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7976608187134503,"7. Experiment Statistical Significance
573"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7988304093567251,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
574"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8,"information about the statistical significance of the experiments?
575"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8011695906432749,"Answer: [No]
576"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8023391812865497,"Justification: We believe it is not necessary to include error bars in the results because each
577"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8035087719298246,"experimental result itself is already the average of a large number of tests (E.g., the test
578"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8046783625730994,"accuracy for an epoch is averaged over Num_of_batches × Batch_size input images,
579"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8058479532163743,"and is therefore very close to each other in every test epoch).
580"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8070175438596491,"Guidelines:
581"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.808187134502924,"• The answer NA means that the paper does not include experiments.
582"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8093567251461988,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
583"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8105263157894737,"dence intervals, or statistical significance tests, at least for the experiments that support
584"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8116959064327486,"the main claims of the paper.
585"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8128654970760234,"• The factors of variability that the error bars are capturing should be clearly stated (for
586"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8140350877192982,"example, train/test split, initialization, random drawing of some parameter, or overall
587"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8152046783625732,"run with given experimental conditions).
588"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.816374269005848,"• The method for calculating the error bars should be explained (closed form formula,
589"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8175438596491228,"call to a library function, bootstrap, etc.)
590"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8187134502923976,"• The assumptions made should be given (e.g., Normally distributed errors).
591"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8198830409356725,"• It should be clear whether the error bar is the standard deviation or the standard error
592"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8210526315789474,"of the mean.
593"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8222222222222222,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
594"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8233918128654971,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
595"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8245614035087719,"of Normality of errors is not verified.
596"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8257309941520468,"• For asymmetric distributions, the authors should be careful not to show in tables or
597"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8269005847953217,"figures symmetric error bars that would yield results that are out of range (e.g. negative
598"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8280701754385965,"error rates).
599"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8292397660818713,"• If error bars are reported in tables or plots, The authors should explain in the text how
600"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8304093567251462,"they were calculated and reference the corresponding figures or tables in the text.
601"
EXPERIMENTS COMPUTE RESOURCES,0.8315789473684211,"8. Experiments Compute Resources
602"
EXPERIMENTS COMPUTE RESOURCES,0.8327485380116959,"Question: For each experiment, does the paper provide sufficient information on the com-
603"
EXPERIMENTS COMPUTE RESOURCES,0.8339181286549707,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
604"
EXPERIMENTS COMPUTE RESOURCES,0.8350877192982457,"the experiments?
605"
EXPERIMENTS COMPUTE RESOURCES,0.8362573099415205,"Answer: [No]
606"
EXPERIMENTS COMPUTE RESOURCES,0.8374269005847953,"Justification: We found it difficult to quantify the computing resources used in every
607"
EXPERIMENTS COMPUTE RESOURCES,0.8385964912280702,"experiments.
608"
EXPERIMENTS COMPUTE RESOURCES,0.839766081871345,"Guidelines:
609"
EXPERIMENTS COMPUTE RESOURCES,0.8409356725146199,"• The answer NA means that the paper does not include experiments.
610"
EXPERIMENTS COMPUTE RESOURCES,0.8421052631578947,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
611"
EXPERIMENTS COMPUTE RESOURCES,0.8432748538011696,"or cloud provider, including relevant memory and storage.
612"
EXPERIMENTS COMPUTE RESOURCES,0.8444444444444444,"• The paper should provide the amount of compute required for each of the individual
613"
EXPERIMENTS COMPUTE RESOURCES,0.8456140350877193,"experimental runs as well as estimate the total compute.
614"
EXPERIMENTS COMPUTE RESOURCES,0.8467836257309942,"• The paper should disclose whether the full research project required more compute
615"
EXPERIMENTS COMPUTE RESOURCES,0.847953216374269,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
616"
EXPERIMENTS COMPUTE RESOURCES,0.8491228070175438,"didn’t make it into the paper).
617"
CODE OF ETHICS,0.8502923976608188,"9. Code Of Ethics
618"
CODE OF ETHICS,0.8514619883040936,"Question: Does the research conducted in the paper conform, in every respect, with the
619"
CODE OF ETHICS,0.8526315789473684,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
620"
CODE OF ETHICS,0.8538011695906432,"Answer: [Yes]
621"
CODE OF ETHICS,0.8549707602339182,"Justification: We have read the NeurIPS Code of Ethics and the research conducted in this
622"
CODE OF ETHICS,0.856140350877193,"paper conforms with it.
623"
CODE OF ETHICS,0.8573099415204678,"Guidelines:
624"
CODE OF ETHICS,0.8584795321637427,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
625"
CODE OF ETHICS,0.8596491228070176,"• If the authors answer No, they should explain the special circumstances that require a
626"
CODE OF ETHICS,0.8608187134502924,"deviation from the Code of Ethics.
627"
CODE OF ETHICS,0.8619883040935673,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
628"
CODE OF ETHICS,0.8631578947368421,"eration due to laws or regulations in their jurisdiction).
629"
BROADER IMPACTS,0.8643274853801169,"10. Broader Impacts
630"
BROADER IMPACTS,0.8654970760233918,"Question: Does the paper discuss both potential positive societal impacts and negative
631"
BROADER IMPACTS,0.8666666666666667,"societal impacts of the work performed?
632"
BROADER IMPACTS,0.8678362573099415,"Answer: [NA]
633"
BROADER IMPACTS,0.8690058479532163,"Justification: There is no societal impact of the work performed.
634"
BROADER IMPACTS,0.8701754385964913,"Guidelines:
635"
BROADER IMPACTS,0.8713450292397661,"• The answer NA means that there is no societal impact of the work performed.
636"
BROADER IMPACTS,0.8725146198830409,"• If the authors answer NA or No, they should explain why their work has no societal
637"
BROADER IMPACTS,0.8736842105263158,"impact or why the paper does not address societal impact.
638"
BROADER IMPACTS,0.8748538011695907,"• Examples of negative societal impacts include potential malicious or unintended uses
639"
BROADER IMPACTS,0.8760233918128655,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
640"
BROADER IMPACTS,0.8771929824561403,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
641"
BROADER IMPACTS,0.8783625730994152,"groups), privacy considerations, and security considerations.
642"
BROADER IMPACTS,0.87953216374269,"• The conference expects that many papers will be foundational research and not tied
643"
BROADER IMPACTS,0.8807017543859649,"to particular applications, let alone deployments. However, if there is a direct path to
644"
BROADER IMPACTS,0.8818713450292398,"any negative applications, the authors should point it out. For example, it is legitimate
645"
BROADER IMPACTS,0.8830409356725146,"to point out that an improvement in the quality of generative models could be used to
646"
BROADER IMPACTS,0.8842105263157894,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
647"
BROADER IMPACTS,0.8853801169590644,"that a generic algorithm for optimizing neural networks could enable people to train
648"
BROADER IMPACTS,0.8865497076023392,"models that generate Deepfakes faster.
649"
BROADER IMPACTS,0.887719298245614,"• The authors should consider possible harms that could arise when the technology is
650"
BROADER IMPACTS,0.8888888888888888,"being used as intended and functioning correctly, harms that could arise when the
651"
BROADER IMPACTS,0.8900584795321638,"technology is being used as intended but gives incorrect results, and harms following
652"
BROADER IMPACTS,0.8912280701754386,"from (intentional or unintentional) misuse of the technology.
653"
BROADER IMPACTS,0.8923976608187134,"• If there are negative societal impacts, the authors could also discuss possible mitigation
654"
BROADER IMPACTS,0.8935672514619883,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
655"
BROADER IMPACTS,0.8947368421052632,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
656"
BROADER IMPACTS,0.895906432748538,"feedback over time, improving the efficiency and accessibility of ML).
657"
SAFEGUARDS,0.8970760233918129,"11. Safeguards
658"
SAFEGUARDS,0.8982456140350877,"Question: Does the paper describe safeguards that have been put in place for responsible
659"
SAFEGUARDS,0.8994152046783626,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
660"
SAFEGUARDS,0.9005847953216374,"image generators, or scraped datasets)?
661"
SAFEGUARDS,0.9017543859649123,"Answer: [NA]
662"
SAFEGUARDS,0.9029239766081871,"Justification: The paper poses no such risks.
663"
SAFEGUARDS,0.904093567251462,"Guidelines:
664"
SAFEGUARDS,0.9052631578947369,"• The answer NA means that the paper poses no such risks.
665"
SAFEGUARDS,0.9064327485380117,"• Released models that have a high risk for misuse or dual-use should be released with
666"
SAFEGUARDS,0.9076023391812865,"necessary safeguards to allow for controlled use of the model, for example by requiring
667"
SAFEGUARDS,0.9087719298245615,"that users adhere to usage guidelines or restrictions to access the model or implementing
668"
SAFEGUARDS,0.9099415204678363,"safety filters.
669"
SAFEGUARDS,0.9111111111111111,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
670"
SAFEGUARDS,0.9122807017543859,"should describe how they avoided releasing unsafe images.
671"
SAFEGUARDS,0.9134502923976608,"• We recognize that providing effective safeguards is challenging, and many papers do
672"
SAFEGUARDS,0.9146198830409357,"not require this, but we encourage authors to take this into account and make a best
673"
SAFEGUARDS,0.9157894736842105,"faith effort.
674"
LICENSES FOR EXISTING ASSETS,0.9169590643274854,"12. Licenses for existing assets
675"
LICENSES FOR EXISTING ASSETS,0.9181286549707602,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
676"
LICENSES FOR EXISTING ASSETS,0.9192982456140351,"the paper, properly credited and are the license and terms of use explicitly mentioned and
677"
LICENSES FOR EXISTING ASSETS,0.92046783625731,"properly respected?
678"
LICENSES FOR EXISTING ASSETS,0.9216374269005848,"Answer: [Yes]
679"
LICENSES FOR EXISTING ASSETS,0.9228070175438596,"Justification: The pretrained ANN model and the QAT workflow is provided by PyTorch
680"
LICENSES FOR EXISTING ASSETS,0.9239766081871345,"and we cited the original paper in appendix A.1 as [22].
681"
LICENSES FOR EXISTING ASSETS,0.9251461988304094,"Guidelines:
682"
LICENSES FOR EXISTING ASSETS,0.9263157894736842,"• The answer NA means that the paper does not use existing assets.
683"
LICENSES FOR EXISTING ASSETS,0.927485380116959,"• The authors should cite the original paper that produced the code package or dataset.
684"
LICENSES FOR EXISTING ASSETS,0.928654970760234,"• The authors should state which version of the asset is used and, if possible, include a
685"
LICENSES FOR EXISTING ASSETS,0.9298245614035088,"URL.
686"
LICENSES FOR EXISTING ASSETS,0.9309941520467836,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
687"
LICENSES FOR EXISTING ASSETS,0.9321637426900585,"• For scraped data from a particular source (e.g., website), the copyright and terms of
688"
LICENSES FOR EXISTING ASSETS,0.9333333333333333,"service of that source should be provided.
689"
LICENSES FOR EXISTING ASSETS,0.9345029239766082,"• If assets are released, the license, copyright information, and terms of use in the
690"
LICENSES FOR EXISTING ASSETS,0.935672514619883,"package should be provided. For popular datasets, paperswithcode.com/datasets
691"
LICENSES FOR EXISTING ASSETS,0.9368421052631579,"has curated licenses for some datasets. Their licensing guide can help determine the
692"
LICENSES FOR EXISTING ASSETS,0.9380116959064327,"license of a dataset.
693"
LICENSES FOR EXISTING ASSETS,0.9391812865497076,"• For existing datasets that are re-packaged, both the original license and the license of
694"
LICENSES FOR EXISTING ASSETS,0.9403508771929825,"the derived asset (if it has changed) should be provided.
695"
LICENSES FOR EXISTING ASSETS,0.9415204678362573,"• If this information is not available online, the authors are encouraged to reach out to
696"
LICENSES FOR EXISTING ASSETS,0.9426900584795321,"the asset’s creators.
697"
NEW ASSETS,0.9438596491228071,"13. New Assets
698"
NEW ASSETS,0.9450292397660819,"Question: Are new assets introduced in the paper well documented and is the documentation
699"
NEW ASSETS,0.9461988304093567,"provided alongside the assets?
700"
NEW ASSETS,0.9473684210526315,"Answer: [NA]
701"
NEW ASSETS,0.9485380116959065,"Justification: The paper does not release new assets.
702"
NEW ASSETS,0.9497076023391813,"Guidelines:
703"
NEW ASSETS,0.9508771929824561,"• The answer NA means that the paper does not release new assets.
704"
NEW ASSETS,0.952046783625731,"• Researchers should communicate the details of the dataset/code/model as part of their
705"
NEW ASSETS,0.9532163742690059,"submissions via structured templates. This includes details about training, license,
706"
NEW ASSETS,0.9543859649122807,"limitations, etc.
707"
NEW ASSETS,0.9555555555555556,"• The paper should discuss whether and how consent was obtained from people whose
708"
NEW ASSETS,0.9567251461988304,"asset is used.
709"
NEW ASSETS,0.9578947368421052,"• At submission time, remember to anonymize your assets (if applicable). You can either
710"
NEW ASSETS,0.9590643274853801,"create an anonymized URL or include an anonymized zip file.
711"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.960233918128655,"14. Crowdsourcing and Research with Human Subjects
712"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9614035087719298,"Question: For crowdsourcing experiments and research with human subjects, does the paper
713"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9625730994152046,"include the full text of instructions given to participants and screenshots, if applicable, as
714"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9637426900584796,"well as details about compensation (if any)?
715"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9649122807017544,"Answer: [NA]
716"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9660818713450292,"Justification: The paper does not involve crowdsourcing nor research with human subjects.
717"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9672514619883041,"Guidelines:
718"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.968421052631579,"• The answer NA means that the paper does not involve crowdsourcing nor research with
719"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9695906432748538,"human subjects.
720"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9707602339181286,"• Including this information in the supplemental material is fine, but if the main contribu-
721"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9719298245614035,"tion of the paper involves human subjects, then as much detail as possible should be
722"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9730994152046784,"included in the main paper.
723"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9742690058479532,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
724"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9754385964912281,"or other labor should be paid at least the minimum wage in the country of the data
725"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9766081871345029,"collector.
726"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9777777777777777,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
727"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9789473684210527,"Subjects
728"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9801169590643275,"Question: Does the paper describe potential risks incurred by study participants, whether
729"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9812865497076023,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
730"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9824561403508771,"approvals (or an equivalent approval/review based on the requirements of your country or
731"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9836257309941521,"institution) were obtained?
732"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9847953216374269,"Answer: [NA]
733"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9859649122807017,"Justification: The paper does not involve crowdsourcing nor research with human subjects.
734"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9871345029239766,"Guidelines:
735"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9883040935672515,"• The answer NA means that the paper does not involve crowdsourcing nor research with
736"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9894736842105263,"human subjects.
737"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9906432748538012,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
738"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.991812865497076,"may be required for any human subjects research. If you obtained IRB approval, you
739"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9929824561403509,"should clearly state this in the paper.
740"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9941520467836257,"• We recognize that the procedures for this may vary significantly between institutions
741"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9953216374269006,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
742"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9964912280701754,"guidelines for their institution.
743"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9976608187134502,"• For initial submissions, do not include any information that would break anonymity (if
744"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9988304093567252,"applicable), such as the institution conducting the review.
745"
