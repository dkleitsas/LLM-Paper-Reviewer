Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0022675736961451248,"We propose a new framework of synthesizing data using deep generative models in
a differentially private manner. Within our framework, sensitive data are sanitized
with rigorous privacy guarantees in a one-shot fashion, such that training deep
generative models is possible without re-using the original data. Hence, no extra
privacy costs or model constraints are incurred, in contrast to popular gradient
sanitization approaches, which, among other issues, cause degradation in privacy
guarantees as the training iteration increases. We demonstrate a realization of
our framework by making use of the characteristic function and an adversarial
re-weighting objective, which are of independent interest as well. Our proposal
has theoretical guarantees of performance, and empirical evaluations on multiple
datasets show that our approach outperforms other methods at reasonable levels of
privacy."
INTRODUCTION,0.0045351473922902496,"1
INTRODUCTION"
INTRODUCTION,0.006802721088435374,"Synthesizing data under differential privacy (DP) (Dwork (2006; 2011); Dwork et al. (2014)) enables
us to share the synthetic data and generative model with rigorous privacy guarantees. Particularly,
DP approaches of data synthesis involving the use of deep generative models have received attention
lately (Takagi et al. (2021); Xie et al. (2018); Torkzadehmahani et al. (2019); Frigerio et al. (2019);
Jordon et al. (2019); Chen et al. (2020); Harder et al. (2021))."
INTRODUCTION,0.009070294784580499,"Typically, the training of such models utilizes gradient sanitization techniques (Abadi et al. (2016))
that add noises to the gradient updates to preserve privacy. While such methods are conducive to
deep learning, due to composability, each access to data leads to degradation in privacy guarantees,
and as a result, the training iteration is limited by the privacy budget. Recently, Harder et al. (2021)
has proposed DP-MERF, which ﬁrst represents the sensitive data as random features in a DP manner
and then learns a generator by minimizing the discrepancy between the (ﬁxed) representation and
generated data points. DP-MERF can iterate the learning process of the generator without further
consuming the privacy budget; however, it is limited in the learning and generalization capabilities
due to its ﬁxed representation. In this work, we seek a strategy of training deep generative models
privately that is able to resolve the aforementioned shortcomings, and is practical in terms of privacy
(e.g., usable image data at ϵ ≃1.)"
INTRODUCTION,0.011337868480725623,"We propose a private learning framework called PEARL (Private Embeddings and Adversarial
Reconstruction Learning). In this framework, we have i) no limitation in learning iterations, and
ii) well-reconstruction capability. Towards those preferable properties, our framework ﬁrst obtains
(1) informative embedding of sensitive data and (2) auxiliary information (e.g., hyperparameters)
useful for training, both in a differentially private manner, then (3) the generative model is trained
implicitly like GANs via the private embedding and auiliary information, where the learning is based
on a stochastic procedure that generates data, and (4) a critic distinguishing between the real and
generated data. The overview of PEARL is illustrated in Fig. 1."
INTRODUCTION,0.013605442176870748,"As a concrete realization of PEARL, We ﬁrst identify that the characteristic function (CF) representa-
tion of data can be sanitized as the private embedding of PEARL. Consequently, it is possible to train
deep generative models using an appropriately deﬁned metric measuring the discrepancy between the
real (but sanitized) and generated data distribution based on the CF without re-using the original data.
As will be explained in detail in later Sections, the generative modelling approach using CFs also"
INTRODUCTION,0.015873015873015872,Published as a conference paper at ICLR 2022
INTRODUCTION,0.018140589569160998,"Sensitive 
Data"
INTRODUCTION,0.02040816326530612,"Privately 
Embedded 
1"
INTRODUCTION,0.022675736961451247,"Privately 
Embedded 
2"
INTRODUCTION,0.024943310657596373,"Privately 
Embedded 
k Aux"
INTRODUCTION,0.027210884353741496,Synthesized 1
INTRODUCTION,0.02947845804988662,Synthesized 2
INTRODUCTION,0.031746031746031744,Synthesized k
INTRODUCTION,0.034013605442176874,Critic
INTRODUCTION,0.036281179138321996,"Adv. 
Recon.
Learner"
INTRODUCTION,0.03854875283446712,Generator (1) (2) (3) (4)
INTRODUCTION,0.04081632653061224,DP flow (one-shot)
INTRODUCTION,0.04308390022675737,"Training loop …
…"
INTRODUCTION,0.045351473922902494,Data flow (one-shot)
INTRODUCTION,0.047619047619047616,"Figure 1: PEARL is a private learning framework that has i) no limitation in learning iterations, and
ii) well-reconstruction capability. Towards those preferable properties, our framework ﬁrst obtains (1)
private embedding and (2) auxiliary information from the sensitive data, then (3) trains a generator
while (4) optimizing a critic to distinguish between the real and generated data."
INTRODUCTION,0.049886621315192746,"involves sampling “frequencies” from an ad hoc distribution, to project the data to the embedding. It
is desirable to optimize the sampling distribution to better represent the data as an embedding, but
the naive way of optimizing it would require re-accessing the data via sampling, coming at a cost of
privacy budget. Henceforth, we also propose to incorporate a privacy-preserving critic to optimize the
sampling strategy, which, through re-weighting, chooses the best representation from a ﬁxed samples
of frequencies without extra privacy costs."
INTRODUCTION,0.05215419501133787,"To this end, we propose the following minimax optimization training objective:"
INTRODUCTION,0.05442176870748299,"inf
θ∈Θ sup
ω∈Ω k
X i=1"
INTRODUCTION,0.05668934240362812,"ω(ti)
ω0(ti)"
INTRODUCTION,0.05895691609977324,"eΦPr(ti) −bΦQθ(ti)
2.
(1)"
INTRODUCTION,0.061224489795918366,"See later parts for notations and details. Theoretically, we show that our proposed objective has
properties similar to those that are suited to training GANs, i.e., continuity and differentiability
of the generator’s parameters, and continuity in weak topology. We also prove the consistency of
our privacy-preserving sampling strategy at the asymptotic limit of inﬁnite sampling. Empirical
evaluations show that PEARL is able to high-quality synthetic data at reasonable privacy levels."
INTRODUCTION,0.06349206349206349,"Related works. Traditional methods of synthesizing data are mainly concerned with discrete data or
data preprocessed to the discrete form (Zhang et al. (2017); Qardaji et al. (2014); He et al. (2015);
Chen et al. (2015); Cai et al. (2021); Zhang et al. (2021)), whereas we are interested in more general
methods involving continuous data. Deep generative models under the DP setting are suitable for
this type of tasks (Takagi et al. (2021); Xie et al. (2018); Torkzadehmahani et al. (2019); Frigerio
et al. (2019); Jordon et al. (2019); Chen et al. (2020); Harder et al. (2021)). The private training
of deep generative models is usually performed using gradient sanitization methods. An exception
is DP-MERF (Harder et al. (2021)), which is closest to our work. There, random features used
to approximate the maximum mean discrepancy (MMD) objective are privatized and utilized for
training a generator. PEARL, which, as a realization, uses CFs, may be viewed as a generalization of
DP-MERF. Additionally, PEARL has several distinctive features which are lacking in DP-MERF.
The ﬁrst lies in the introduction of a privacy-preserving critic, which leads to an improvement of
performance. The second is the private selection of the parameter of the sampling distribution, which
is also shown to be vital. Moreover, DP-MERF uses non-characteristic kernels when treating tabular
data, in contrast to ours, which is characteristic and has guarantees in convergence. We ﬁnally note
that generative models using CFs but only non-privately have been explored before (Ansari et al.
(2020); Li et al. (2020)) ."
INTRODUCTION,0.06575963718820861,"Contributions. Our contribution in this paper is three-fold: (i) We propose a general framework
called PEARL, where, unlike gradient sanitization methods, the generator training process and
iteration are unconstrained; reliance on ad-hoc (non-private) hyperparameter tuning is reduced by
extracting hyperparameters (auxiliary information) privately. (ii) We demonstrate a realization of our
framework by making use of the characteristic function and an adversarial re-weighting objective.
(iii) Our proposal has theoretical guarantees of performance, and empirical evaluations show that our
approach outperforms competitors at reasonable levels of privacy (ϵ ≃1)."
INTRODUCTION,0.06802721088435375,Published as a conference paper at ICLR 2022
PRELIMINARIES,0.07029478458049887,"2
PRELIMINARIES"
PRELIMINARIES,0.07256235827664399,"This Section gives a brief review of essential preliminaries about differential privacy, characteristic
function and the related notations."
DIFFERENTIAL PRIVACY,0.07482993197278912,"2.1
DIFFERENTIAL PRIVACY"
DIFFERENTIAL PRIVACY,0.07709750566893424,"Deﬁnition 1 ((ϵ, δ)-Differential Privacy). Given privacy parameters ϵ ≥0 and δ ≥0, a randomized
mechanism, M : D →R with domain D and range R satisﬁes (ϵ, δ)-differential privacy (DP) if for
any two adjacent inputs d, d′ ∈D and for any subset of outputs S ⊆R, the following holds:
Pr[M(d) ∈S] ≤eϵ · Pr[M(d′) ∈S] + δ.
(2)"
DIFFERENTIAL PRIVACY,0.07936507936507936,"We next consider concrete ways of sanitizing certain outputs with DP. A typical paradigm of DP is
applying the randomized mechanism, M, to a certain deterministic function f : D →R such that the
output of f is DP. The noise magnitude added by M is determined by the sensitivity of f, deﬁned as
∆f = supd,d′∈D ∥f(d) −f(d′)∥, where || · || is a norm function deﬁned on f’s output domain. d and
d′ are any adjacent pairs of dataset. Laplacian and Gaussian mechanisms are the standard randomized
mechanisms. We primarily utilize the Gaussian mechanism in this paper (Dwork et al. (2014)):
Deﬁnition 2 (Gaussian Mechanism). Let f : X →R be an arbitrary function with sensitivity ∆f.
The Gaussian Mechanism, Mσ, parameterized by σ, adds noise to the output of f as follows:
Mσ(x) = f(x) + N(0, σ2I).
(3)
One of the most important properties of DP relevant to our work is the post-processing theorem
(Dwork et al. (2014)):
Theorem 1 (Post-processing Theorem). Let M : D →R be (ϵ, δ)-DP and let f : R →R′ be an
arbitrary randomized function. Then, f ◦M : D →R′ is (ϵ, δ)-DP."
DIFFERENTIAL PRIVACY,0.08163265306122448,It ensures that the DP-sanitized data can be re-used without further consuming privacy budgets.
CHARACTERISTIC FUNCTIONS,0.08390022675736962,"2.2
CHARACTERISTIC FUNCTIONS"
CHARACTERISTIC FUNCTIONS,0.08616780045351474,"Characteristic function (CF) is widely utilized in statistics and probability theory, and perhaps is best
known to be used to prove the central limit theorem (Williams (1991)). The deﬁnition is as follows.
Deﬁnition 3 (Characteristic Function). Given a random variable X ⊆Rd and P as the probability
measure associated with it, and t ∈Rd, the corresponding characteristic function (CF) is given by"
CHARACTERISTIC FUNCTIONS,0.08843537414965986,"ΦP(t) = Ex∼P[eit·x] =
Z"
CHARACTERISTIC FUNCTIONS,0.09070294784580499,"Rd eit·xdP.
(4)"
CHARACTERISTIC FUNCTIONS,0.09297052154195011,"Here, i is the imaginary number. From the signal processing point of view, this mathematical
operation is equivalent to the Fourier transformation, and ΦP(t) is the Fourier transform at frequency
t. It is noted that we deal with the discrete approximation of CFs in practice. That is, given a dataset
with n i.i.d. samples, {xj}n
j=1 from P, the empirical CF is written as bΦP(t) = 1"
CHARACTERISTIC FUNCTIONS,0.09523809523809523,"n
Pn
i=j eit·xj. We
next introduce characteristic function distance (CFD) (Heathcote (1972); Chwialkowski et al. (2015)):
Deﬁnition 4 (Characteristic Function Distance). Given two distributions P and Q of random variables
residing in Rd, and ω a sampling distribution on t ∈Rd, the squared characteristic function distance
(CFD) between P and Q is computed as:"
CHARACTERISTIC FUNCTIONS,0.09750566893424037,"C2(P, Q) = Et∼ω(t)[
ΦP(t) −ΦQ(t)
2] =
Z Rd"
CHARACTERISTIC FUNCTIONS,0.09977324263038549,"ΦP(t) −ΦQ(t)
2ω(t)dt.
(5)"
CHARACTERISTIC FUNCTIONS,0.10204081632653061,"Notations.
Let us make a short note on the notations before continuing. Let k be the num-
ber of t drawn from ω and P be the probability measure of a random variable.
We group
the CFs associated to P of different frequencies, (bΦP(t1), . . . , bΦP(tk))⊤more compactly as
bφP(x). To make the dependence of bφP(x) on the sampled data explicit, we also use the fol-"
CHARACTERISTIC FUNCTIONS,0.10430839002267574,lowing notation: bφP(x) = 1
CHARACTERISTIC FUNCTIONS,0.10657596371882086,"n
Pn
j=1 bφP(xj). We notice that ∥bφP(x)∥2 ≡
qPk
m=1 |bΦP(tm)|2 =
qPk
m=1 | Pn
l=1 eitm·xl/n|2 ≤
qPk
m=1 | Pn
l=1 1/n|2 =
√"
CHARACTERISTIC FUNCTIONS,0.10884353741496598,"k, where the norm is taken over the"
CHARACTERISTIC FUNCTIONS,0.1111111111111111,"(complex) frequency space. With a slight abuse of notation, we abbreviate bφP as bφ when there is no
ambiguity in the underlying probability measure associated with the CF."
CHARACTERISTIC FUNCTIONS,0.11337868480725624,Published as a conference paper at ICLR 2022
GENERATIVE MODEL OF PEARL,0.11564625850340136,"3
GENERATIVE MODEL OF PEARL"
GENERATIVE MODEL OF PEARL,0.11791383219954649,"Let us describe generative modelling under the PEARL framework. The realization is summarized by
the following Proposition:
Proposition 1. Let the real data distribution be Pr, and the output distribution of an implicit
generative model Gθ by Qθ. Let n be the total number of real data instances and consider releasing k
CFs from the dataset. Then, Gθ trained to optimize the empirical CFD, min
θ∈Θ
bC2(Pr, Qθ) with the CF"
GENERATIVE MODEL OF PEARL,0.12018140589569161,"sanitized according to the Gaussian mechanism (Defn. 3) with sensitivity 2
√"
GENERATIVE MODEL OF PEARL,0.12244897959183673,"k/n satisﬁes (ϵ, δ)-DP,
where σ ≥
p"
GENERATIVE MODEL OF PEARL,0.12471655328798185,2 log(1.25/δ)/ϵ.
GENERATIVE MODEL OF PEARL,0.12698412698412698,"Proof. In the following we give a detailed explanation of the above Proposition. The ﬁrst step of
PEARL is projecting the data to the CF as in Eq. 4, where the number of embeddings is the number
of frequency drawn from ω(t)."
GENERATIVE MODEL OF PEARL,0.1292517006802721,"We note that CF has several attractive properties. CF is uniformly continuous and bounded, as can be
seen from its expression in Eq. 4. Unlike the density function, the CF of a random variable always
exists, and the uniqueness theorem implies that two distributions are identical if and only if the CFs
of the random variables are equal (Lukacs (1972))."
GENERATIVE MODEL OF PEARL,0.13151927437641722,The CF is sanitized with DP by applying the Gaussian mechanism (Defn. 3) to bφ(x):
GENERATIVE MODEL OF PEARL,0.13378684807256236,"eφ(x) = bφ(x) + N(0, ∆2
b
φ(x)σ2I),
(6)"
GENERATIVE MODEL OF PEARL,0.1360544217687075,"where we write the sanitized CF as eφ(x); ∆b
φ(x) denotes the sensitivity of the CF, σ denotes the noise
scale which is determined by the privacy budget, (ϵ, δ)."
GENERATIVE MODEL OF PEARL,0.1383219954648526,"The calculation of sensitivity is tractable (no ad-hoc clipping commonly required by gradient sanitiza-
tion methods) Without loss of generality, consider two neighboring datasets of size n where only the
last instance differs (xn ̸= x′
n). The sensitivity of bφ(x) may then be calculated as"
GENERATIVE MODEL OF PEARL,0.14058956916099774,"∆b
φ(x) = max
D,D′ "
N,0.14285714285714285,"1
n n
X"
N,0.14512471655328799,"j=1
bφ(xj) −1 n n
X"
N,0.1473922902494331,"j=1
bφ(x′
j) 2"
N,0.14965986394557823,"= max
xn,x′n 1"
N,0.15192743764172337,n bφ(xn) −1
N,0.15419501133786848,"n bφ(x′
n)

2 = 2
√ k
n ,"
N,0.1564625850340136,"where we have used triangle inequality and ∥bφ(·)∥2 ≤
√"
N,0.15873015873015872,"k. It can be seen that the sensitivity is
proportional to the square root of the number of embeddings (releasing more embeddings requires
more DP noises to be added to bφ) but inversely proportional to the dataset size, which is important
for controlling the magnitude of noise injection at practical privacy levels, as will be discussed in
later Sections."
N,0.16099773242630386,"We would like to train a generative model where the CFs constructed from the generated data
distribution, Y ⊆Rd, matches those (sanitized) from the real data distribution, X ⊆Rd. A natural
way of achieving this is via implicit generative modelling (MacKay (1995); Goodfellow et al. (2014)).
We introduce a generative model parametrized by θ, Gθ : Z →Rd, which takes a low-dimensional
latent vector z ∈Z sampled from a pre-determined distribution (e.g., Gaussian distribution) as the
input."
N,0.16326530612244897,"In order to quantify the discrepancy between the real and generated data distribution, we use the CFD
deﬁned in Eq. 5. Empirically, when a ﬁnite number of frequencies, k, are sampled from ω, C2(P, Q)
is approximated by"
N,0.1655328798185941,"bC2(P, Q) = 1 k k
X i=1"
N,0.16780045351473924,"bΦP(ti) −bΦQ(ti)
2 ≡
 bφP(x) −bφQ(x)

2"
N,0.17006802721088435,"2 ,
(7)"
N,0.17233560090702948,"where bΦP(t) and bΦQ(t) are the empirical CFs evaluated from i.i.d. samples of distributions P and Q
respectively. The training objective of the generator is to ﬁnd the optimal θ ∈Θ that minimizes the
empirical CFD: min
θ∈Θ
bC2(Pr, Qθ). It can be shown via uniqueness theorem that as long as ω resides in"
N,0.1746031746031746,"Rd, C(P, Q) = 0 ⇐⇒P = Q (Sriperumbudur et al. (2011)). This makes CFD an ideal distance
metric for training the generator."
N,0.17687074829931973,Published as a conference paper at ICLR 2022
N,0.17913832199546487,"Optimization procedure. The generator parameter, θ, is updated as follows. bφPr(x) is ﬁrst sanitized
to obtain eφPr(x), as in Eq. 6. This is performed only for once (one-shot). Then, at each iteration, m
samples of z are drawn to calculate bφQθ(x). Gradient updates on θ are performed by minimizing the"
N,0.18140589569160998,"CFD,
 eφPr(x) −bφQθ(x)

2."
N,0.1836734693877551,"We note that only the ﬁrst term, eφPr(x), has access to the real data distribution, X, of which privacy
is of concern. Then, by Thm. 1, Gθ trained with respect to eφPr(x) is DP. Furthermore, unlike gradient
sanitization methods, the training of Gθ is not affected by network structure or training iterations.
Once the sanitized CF is released, there is no additional constraints due to privacy on the training
procedure."
N,0.18594104308390022,"DP release of auxiliary information. Auxiliary information, e.g., hyperparameters regarding to the
dataset useful for generating data with better quality may be obtained under DP. In our case, one may
extract auxiliary information privately from the dataset to select good parameters for the sampling
distribution ω(t). This will be discussed in more detail in the next Sections."
N,0.18820861678004536,"Another example is the modelling of tabular data. Continuous columns of tabular data consisting of
multiple modes may be modelled using Gaussian mixture models (GMMs) (Xu et al. (2019)). GMMs
are trainable under DP using a DP version of the expectation-maximization algorithm (Park et al.
(2017)). The total privacy budget due to multiple releases of information is accounted for using the
Rényi DP composition. See App. A for the deﬁnition of Rényi DP."
ADVERSARIAL RECONSTRUCTION LEARNING,0.19047619047619047,"4
ADVERSARIAL RECONSTRUCTION LEARNING"
ADVERSARIAL RECONSTRUCTION LEARNING,0.1927437641723356,"This Section is devoted to proposing a privacy-preserving critic for optimizing ω(t), while giving
provable guarantees of performance."
ADVERSARIAL RECONSTRUCTION LEARNING,0.19501133786848074,"Back to Eq. 5 and Eq. 7, we note that choosing a “good” ω(t) or a “good” set of sampled frequencies
is vital at helping to discriminate between P and Q. For example, if the difference between P and Q
lies in the high-frequency region, one should choose to use t with large values to, in the language of
two-sample testing, improve the test power."
ADVERSARIAL RECONSTRUCTION LEARNING,0.19727891156462585,"Adversarial objective. If the resulting empirical CFD remains small due to under-optimized ω(t),
while the two distributions still differ signiﬁcantly, the generator cannot be optimally trained to
generate high-quality samples resembling the real data. Hence, we consider training the generator by,
in addition to minimizing the empirical CFD, maximizing the empirical CFD using an adversarial
objective which acts as a critic, where the empirical CFD is maximized by ﬁnding the best sampling
distribution. We consider a training objective of the form"
ADVERSARIAL RECONSTRUCTION LEARNING,0.19954648526077098,"inf
θ∈Θ sup
ω∈Ω
c
Cω
2(Pr, Qθ),
(8)"
ADVERSARIAL RECONSTRUCTION LEARNING,0.2018140589569161,where Ωis some set of probability distribution space of which the sampling distribution ω lives in.
ADVERSARIAL RECONSTRUCTION LEARNING,0.20408163265306123,"Privacy-preserving optimization. It is intractable to directly optimize ω in the integral form as in
Eq. 5. In this work, we opt for a privacy-preserving one-shot sampling strategy where once the
private data is released (by sampling from ω), optimization is performed without further spending the
privacy budget. We believe that such a new formulation of distribution learning is of independent
interest as well."
ADVERSARIAL RECONSTRUCTION LEARNING,0.20634920634920634,"Effectiveness of the critic. To further motivate why it is preferable to introduce an adversarial
objective as in Eq. 8, we present a simple demonstration through the lens of two-sample testing
(Chwialkowski et al. (2015); Jitkrittum et al. (2016)) using synthetic data generated from Gaussian
distributions. We generate two unit-variance multivariate Gaussian distributions P, Q, where all
dimensions but one have zero mean. We conduct a two-sample test using the CF to distinguish
between the two distributions, which gets more difﬁcult as the dimensionality increases. We test
if the null hypothesis where the samples are drawn from the same distribution is rejected. Higher
rejection rate indicates better test power."
ADVERSARIAL RECONSTRUCTION LEARNING,0.20861678004535147,"Note that the ﬁrst dimension (where the distribution differs) of the frequency used to construct CFs
is the most discriminative dimension for distinguishing the distributions. We consider three sets of"
ADVERSARIAL RECONSTRUCTION LEARNING,0.2108843537414966,Published as a conference paper at ICLR 2022
ADVERSARIAL RECONSTRUCTION LEARNING,0.21315192743764172,"frequencies: “unoptimized”, “normal”, and “optimized”, where the set of “unoptimized” frequencies
is optimized with re-weighting. More details can be found in App. C."
ADVERSARIAL RECONSTRUCTION LEARNING,0.21541950113378686,"20
25
30
35
40
45
50
Dimensions 0.0 0.2 0.4 0.6 0.8 1.0"
ADVERSARIAL RECONSTRUCTION LEARNING,0.21768707482993196,Rejection Rate
ADVERSARIAL RECONSTRUCTION LEARNING,0.2199546485260771,"Unoptimized
Normal
Optimized"
ADVERSARIAL RECONSTRUCTION LEARNING,0.2222222222222222,"Figure 2: Increased test power upon optimization
(green) in two-sample test."
ADVERSARIAL RECONSTRUCTION LEARNING,0.22448979591836735,"Fig. 2 shows the hypothesis rejection rate versus
the number of dimensions for the three cases
considered above. As can be observed, the “op-
timized” case gives overall the best test power.
While this experiment is somewhat contrived,
it can be understood that although both “unop-
timized” and “optimized” sets of frequencies
contain the discriminative t0, the re-weighting
procedure of selecting the most discriminative
CF improves the test power signiﬁcantly. Even
without re-sampling from a “better” ω(t), re-
weighting the existing frequencies can improve
the test power. The fact that re-weighting can im-
prove the test power is crucial privacy-wise be-
cause the altenative method, re-sampling, causes
degradation in privacy."
ADVERSARIAL RECONSTRUCTION LEARNING,0.22675736961451248,"Proposal. Recall that the empirical CFD, bC2(Pr, Qθ) = 1"
ADVERSARIAL RECONSTRUCTION LEARNING,0.2290249433106576,"k
Pk
i=1
eΦPr(ti) −bΦQθ(ti)
2, is obtained
by drawing k frequencies from a base distribution ω0. Our idea is to ﬁnd a (weighted) set of
frequencies that gives the best test power from the drawn set. We propose Eq. 1 as the optimization
objective, restated below:"
ADVERSARIAL RECONSTRUCTION LEARNING,0.23129251700680273,"inf
θ∈Θ sup
ω∈Ω k
X i=1"
ADVERSARIAL RECONSTRUCTION LEARNING,0.23356009070294784,"ω(ti)
ω0(ti)"
ADVERSARIAL RECONSTRUCTION LEARNING,0.23582766439909297,"eΦPr(ti) −bΦQθ(ti)
2."
ADVERSARIAL RECONSTRUCTION LEARNING,0.23809523809523808,"Note that the generator trained with this objective still satisﬁes DP as given in Prop. 1 due to Thm. 1.
The following Lemma ensures that the discrete approximation of the inner maximization of Eq. 1
approaches the population optimum as the number of sampling frequency increases (k →∞):
Lemma 1. Let ω0 be any probability distribution deﬁned on Rd, and let f : Rd →R′ be any function.
Also let t ∈Rd and ω∗be the maximal distribution of ω with respect to Eω[f(t)] ≡
R
f(t)ω(t)dt.
Assume that the empirical approximation bEω[f(t)] →Eω[f(t)] at the asymptotic limit for any ω.
Then, bEω0[f(t) ω∗(t)"
ADVERSARIAL RECONSTRUCTION LEARNING,0.24036281179138322,ω0(t)] →Eω∗[f(t)] at the asymptotic limit as well.
ADVERSARIAL RECONSTRUCTION LEARNING,0.24263038548752835,"The proof is in App. B, and is based on importance sampling. Empirically, we ﬁnd that treating ω(ti)
as a free parameter and optimizing it directly does not lead to improvement in performance. This may
be due to the optimization procedure focusing too much on uninformative frequencies that contain
merely noises due to DP or sampling. We perform parametric optimization instead, that is, e.g., we
perform optimization with respect to {µ, σ} if ω is of the Gaussian form, N(µ, σ2)."
ADVERSARIAL RECONSTRUCTION LEARNING,0.24489795918367346,"Performance guarantees. Let us discuss the theoretical properties of Eq. 8. The objective deﬁned
in Eq. 8 shares beneﬁcial properties similar to those required to train good GANs, ﬁrst formulated
in (Arjovsky et al. (2017)). First, the generator learns from a distance continuous and differentiable
almost everywhere within the generator’s parameters. Second, the distance is continuous in weak
topology, and thus provides informative feedback to the generator (different from, e.g., the Jensen-
Shannon divergence, which does not satisfy this property). We make assumptions similar to those
given in (Arjovsky et al. (2017)), and state the ﬁrst theorem as follows.
Theorem 2. Assume that Gθ(z) is locally Lipschitz with respect to (θ, z); there exists L((θ, z) satis-
fying Ez [L(θ, z)] < ∞; and supω∈ΩEω [|t|] < ∞for all t. Then, the function supω∈ΩC2
ω(Pr, Qθ)
is continuous in θ ∈Θ everywhere, and differentiable in θ ∈Θ almost everywhere."
ADVERSARIAL RECONSTRUCTION LEARNING,0.2471655328798186,"Note that the local Lipschitz assumptions are satisﬁed by commonly used neural network components,
such as fully connected layers and ReLU activations. The continuity and differentiability conditions
with respect to θ stated above allow Gθ to be trained via gradient descent. The theorem related to
continuity in weak topology is the following:
Theorem 3. Let P be a distribution on X and (Pn)n∈N be a sequence of distributions on X. Under
the assumption supω∈ΩEω(t) [∥t∥] < ∞, the function supω∈ΩC2
ω(Pn, P) is continuous in the"
ADVERSARIAL RECONSTRUCTION LEARNING,0.2494331065759637,Published as a conference paper at ICLR 2022
ADVERSARIAL RECONSTRUCTION LEARNING,0.25170068027210885,"weak topology, i.e., if Pn
D
−→P, then supω∈ΩC2
ω(Pn, P)
D
−→0, where
D
−→denotes convergence in
distribution."
ADVERSARIAL RECONSTRUCTION LEARNING,0.25396825396825395,"Weakness is desirable as the easier (weaker) it is for the distributions to converge, the easier it will be
for the model to learn to ﬁt the data distribution. The core ideas used to prove both of these theorems
are the fact that the difference of the CFs (which is of the form eia) can be bounded as follows:
|eia −eib| ≤|a −b|, and showing that the function is locally Lipschitz, which ensures the desired
properties of continuity and differentiability. See App. B for the full proofs."
EXPERIMENTS,0.2562358276643991,"5
EXPERIMENTS"
EXPERIMENTAL SETUP,0.2585034013605442,"5.1
EXPERIMENTAL SETUP"
EXPERIMENTAL SETUP,0.26077097505668934,"To test the efﬁcacy of PEARL, we perform empirical evaluations on three datasets, namely MNIST
(LeCun et al. (2010)), Fashion-MNIST (Xiao et al. (2017)) and Adult (Asuncion & Newman (2007)).
Detailed setups are available in App. H."
EXPERIMENTAL SETUP,0.26303854875283444,"Training Procedure. As our training involves minimax optimization (Eq. 1), we perform gradient
descent updates based on the minimization and maximization objectives alternately. We use a zero-
mean diagonal standard-deviation Gaussian distribution, N(0, diag(σ2) as the sampling distribution,
ω. Maximization is performed with respect to σ. Let us give a high-level description of the
full training procedure: draw k frequencies from ω, calculate the CFs with them and perform
DP sanitization, train a generator with the sanitized CFs using the minimax optimization method.
The pseudo-code of the full algorithm is presented in App. E. We further give the computational
complexity analysis of our algorithm in App. F."
EXPERIMENTAL SETUP,0.2653061224489796,"DP release of auxiliary information. We also note that applying maximization (re-weighting) on
a randomly selected set of frequencies would not work well. We initially ﬁx the inverse standard
deviation of the base distribution, ω0, to be the DP estimate of the mean of the pairwise distance of
the data, to obtain (privately) a spectrum of frequencies that overlaps with the ""good"" frequencies.
This is motivated by the median heuristic (Garreau et al. (2017)). Mean is estimated instead of median
as its sensitivity is more tractable when considering neighboring datasets. We obtain ∆= 2
√"
EXPERIMENTAL SETUP,0.2675736961451247,"d/n
as its sensitivity, where d and n are the data dimension and the number data instances respectively.
See App. D for the derivation. 1 Using this DP estimate, we also investigate as a ablation study the
generator performance with minimization objective only (w/o critic). The full PEARL framework
includes the use of the critic to ﬁnd the ""best"" frequencies among the selected spectrum to distinguish
the distributions (and overall perform a minimax optimization)."
EXPERIMENTAL SETUP,0.2698412698412698,"Evaluation Metrics. In the main text and App. I, we show qualitative results, i.e., synthetic images
(image dataset) and histograms (tabular dataset) generated with PEARL. Furthermore, for image
datasets, the Fréchet Inception Distance (FID) (Heusel et al. (2017)) and Kernel Inception Distance
(KID) (Bi´nkowski et al. (2018)) are used to evaluate the quantitative performance. For tabular data,
we use the synthetic data as the training data of 10 scikit-learn classiﬁers (Pedregosa et al. (2011))
and evaluate the classiﬁers’ performances on real test data. The performance indicates how well
synthetic data generalize to the real data distribution and how useful synthetic data are in machine
learning tasks. ROC (area under the receiver operating characteristics curve) and PRC (area under
the precision recall curve) are the evaluation metrics. Deﬁnitions of FID and KID are in App. G."
EVALUATION DETAILS,0.272108843537415,"5.2
EVALUATION DETAILS"
EVALUATION DETAILS,0.2743764172335601,"MNIST and Fashion-MNIST. Privacy budget is allocated equally between the sanitization of CFs
and the release of auxiliary information. 2 On a single GPU (Tesla V100-PCIE-32GB), training
MNIST (with 100 epochs) requires less than 10 minutes."
EVALUATION DETAILS,0.2766439909297052,"1We note that DP-MERF also uses a sampling distribution. Since privacy budget is not allocated for calculat-
ing the parameters of the sampling distribution there, we ﬁx its sampling distribution to be N(0, diag(1)).
2We expect that CF sanitization requires more privacy allocation as it is involved in doing the heavy lifting
of training the model. We ﬁnd that allocating around 80-90% of the budget to CF sanitization can increase the
performance by around 15%. Nevertheless, we utilize an equal share of privacy budget for fairness reasons, as
tuning the budget allocation would require re-using the private data and this can lead to privacy leakage."
EVALUATION DETAILS,0.2789115646258503,Published as a conference paper at ICLR 2022
EVALUATION DETAILS,0.2811791383219955,"(a) ϵ = 0.2 (MNIST)
(b) ϵ = 1 (MNIST)
(c) ϵ = 10 (MNIST)
(d) ϵ = ∞(MNIST)"
EVALUATION DETAILS,0.2834467120181406,"(e) ϵ = 0.2 (FMNIST)
(f) ϵ = 1 (FMNIST)
(g) ϵ = 10 (FMNIST)
(h) ϵ = ∞(FMNIST)"
EVALUATION DETAILS,0.2857142857142857,Figure 3: Generated MNIST and Fashion-MNIST samples for various values of ϵ and δ = 10−5.
EVALUATION DETAILS,0.28798185941043086,"Datasets
Metrics
DPGAN
DPCGAN
DP-MERF
Ours (w/o critic)
Ours"
EVALUATION DETAILS,0.29024943310657597,"MNIST
FID
22.1 ± 1.01
17.3 ± 2.90
49.9 ± 0.22
3.79 ± 0.06
3.52 ± 0.06
KID (×103)
573 ± 41.2
286 ± 69.5
148 ± 46.2
77.8 ± 9.88
70.5 ± 10.3"
EVALUATION DETAILS,0.2925170068027211,"Fashion-MNIST
FID
16.6 ± 1.34
14.61 ± 1.75
37.0 ± 0.15
1.99 ± 0.04
1.92 ± 0.04
KID (×103)
535 ± 61.5
425 ± 64.2
1220 ± 36.1
24.0 ± 6.90
26.9 ± 6.80"
EVALUATION DETAILS,0.2947845804988662,"Table 1: FID and KID (lower is better) on image datasets at (ϵ, δ) = (1, 10−5)."
EVALUATION DETAILS,0.29705215419501135,"Some of the generated images of ours and baseline models are shown in Fig. 3, and more (including
baselines’) can be found in App. I. At the non-private limit, the image quality is worse than other
popular non-private approaches such as GANs due to two reasons. First, projecting data to a lower
dimension causes information loss. Second, our architecture does not have a discriminator-like
network as in the vanilla GAN framework. However, we notice that the quality of the images does
not drop much as the privacy level increases (except at ϵ = 0.2, where the quality starts to degrade
visibly) because the noise added to the CFs is small as it scales inversely proportional to the total
sample size. It also indicates that our approach works particularly well at practical levels of privacy."
EVALUATION DETAILS,0.29931972789115646,"We now provide quantitative results by performing evaluation at (ϵ, δ) = (1, 10−5). Note that we
focus on this high privacy region despite the fact that many previous studies experimented with
ϵ ≃10, because recent analyses showed that realistic attacks can lead to privacy violations at low
privacy (Jagielski et al. (2020); Nasr et al. (2021)). Particularly, the claim “values of ϵ that offer
no meaningful theoretical guarantees” (ϵ ≫1) can be chosen in practice has been “refuted” in
general (Nasr et al. (2021)). This motivates us to perform evaluation at ϵ with meaningful theoretical
guarantees (ϵ ≃1)."
EVALUATION DETAILS,0.30158730158730157,"At this privacy region, we compare PEARL with models using gradient sanitization and DP-MERF
(Harder et al. (2021)) as other methods do not produce usable images at single-digit ϵ. 3 We run
the experiment ﬁve times (with different random seeds each time), and for each time, 60k samples
are generated to evaluate the FID and KID. In Table 1, the FID and KID (average and error) of
DP-MERF, DPGAN, PEARL without critic, and PEARL are shown. It can be seen that PEARL
outperforms DP-MERF signiﬁcantly, and the critic leads to improvement in the scores."
EVALUATION DETAILS,0.30385487528344673,"3In the gradient sanitized generative model literature, GS-WGAN (Chen et al. (2020)) is known to be the
state-of-the-art, but we are unable to train a stable model at ϵ = 1. Thus, we make comparisons with other
standard methods, namely DPGAN (Xie et al. (2018)) and DPCGAN (Torkzadehmahani et al. (2019))."
EVALUATION DETAILS,0.30612244897959184,Published as a conference paper at ICLR 2022
EVALUATION DETAILS,0.30839002267573695,"Real data
DP-MERF
Ours"
EVALUATION DETAILS,0.31065759637188206,"ROC
PRC
ROC
PRC
ROC
PRC"
EVALUATION DETAILS,0.3129251700680272,"LR
0.788
0.681
0.661 ± 0.059
0.542 ± 0.041
0.752 ± 0.009
0.641 ± 0.015
Gaussian NB
0.629
0.511
0.587 ± 0.079
0.491 ± 0.06
0.661 ± 0.036
0.537 ± 0.028
Bernoulli NB
0.769
0.651
0.588 ± 0.056
0.488 ± 0.04
0.763 ± 0.008
0.644 ± 0.009
Linear SVM
0.781
0.671
0.568 ± 0.091
0.489 ± 0.067
0.752 ± 0.009
0.640 ± 0.015
Decision Tree
0.759
0.646
0.696 ± 0.081
0.576 ± 0.063
0.675 ± 0.03
0.582 ± 0.028
LDA
0.782
0.670
0.634 ± 0.060
0.541 ± 0.048
0.755 ± 0.005
0.640 ± 0.007
Adaboost
0.789
0.682
0.642 ± 0.097
0.546 ± 0.071
0.709 ± 0.031
0.628 ± 0.024
Bagging
0.772
0.667
0.659 ± 0.06
0.538 ± 0.042
0.687 ± 0.041
0.601 ± 0.039
GBM
0.800
0.695
0.706 ± 0.069
0.586 ± 0.047
0.709 ± 0.029
0.635 ± 0.025
MLP
0.776
0.660
0.667 ± 0.088
0.558 ± 0.063
0.744 ± 0.012
0.635 ± 0.015"
EVALUATION DETAILS,0.31519274376417233,"Average
0.765
0.654
0.641 ± 0.044
0.536 ± 0.034
0.721 ± 0.035
0.618 ± 0.033"
EVALUATION DETAILS,0.31746031746031744,"Table 2: Quantitative results for the Adult dataset evaluated at (ϵ, δ) = (1, 10−5)."
EVALUATION DETAILS,0.3197278911564626,"0.0
1.0
2.0
3.0
4.0
5.0
6.0
category 101 102 103 count"
EVALUATION DETAILS,0.3219954648526077,"Real
Ours
DP-MERF"
EVALUATION DETAILS,0.3242630385487528,(a) “marital-status”
EVALUATION DETAILS,0.32653061224489793,0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.011.012.013.014.0
EVALUATION DETAILS,0.3287981859410431,category 102 103 104 count
EVALUATION DETAILS,0.3310657596371882,"Real
Ours
DP-MERF"
EVALUATION DETAILS,0.3333333333333333,(b) “occupation”
EVALUATION DETAILS,0.3356009070294785,"0.0
1.0
2.0
3.0
4.0
5.0
category 103 count"
EVALUATION DETAILS,0.3378684807256236,"Real
Ours
DP-MERF"
EVALUATION DETAILS,0.3401360544217687,(c) “relationship”
EVALUATION DETAILS,0.3424036281179138,"0.0
1.0
2.0
3.0
4.0
category 102 103 104 count"
EVALUATION DETAILS,0.34467120181405897,"Real
Ours
DP-MERF"
EVALUATION DETAILS,0.3469387755102041,(d) “race”
EVALUATION DETAILS,0.3492063492063492,"20
30
40
50
60
70
80
90
value 10 3 10 2 count"
EVALUATION DETAILS,0.35147392290249435,"Real
DP­MERF
Ours"
EVALUATION DETAILS,0.35374149659863946,(e) “age”
EVALUATION DETAILS,0.35600907029478457,"0
500
1000
1500
2000
2500
3000
3500
4000
value 10 6 10 5 10 4 10 3 count"
EVALUATION DETAILS,0.35827664399092973,"Real
DP­MERF
Ours"
EVALUATION DETAILS,0.36054421768707484,(f) “capital-loss”
EVALUATION DETAILS,0.36281179138321995,"0
20000
40000
60000
80000
100000
value 10 7 10 6 10 5 10 4 count"
EVALUATION DETAILS,0.36507936507936506,"Real
DP­MERF
Ours"
EVALUATION DETAILS,0.3673469387755102,(g) “capital-gain”
EVALUATION DETAILS,0.36961451247165533,"0.0
0.2
0.4
0.6
0.8
1.0
1.2
value
1e6 10 8 10 7 10 6 10 5 count"
EVALUATION DETAILS,0.37188208616780044,"Real
DP­MERF
Ours"
EVALUATION DETAILS,0.3741496598639456,(h) “fnlwgt”
EVALUATION DETAILS,0.3764172335600907,"Figure 4: Histogram plots for the the Adult dataset. Evaluation is performed at (ϵ, δ) = (1, 10−5)."
EVALUATION DETAILS,0.3786848072562358,"Adult. The Adult dataset consists of continuous and categorical features. As data pre-processing,
continuous features are scaled to [0, 1]. We also compare our results with DP-MERF, as DP-MERF
performs best among other existing methods (e.g., DPCGAN achieves ROC and PRC around 0.5;
see Table 4.) Again, auxiliary information and CFs share equal budget of privacy, and we perform
evaluation at (ϵ, δ) = (1, 10−5). 11k synthetic samples are generated for evaluation."
EVALUATION DETAILS,0.38095238095238093,"Histogram plots of the attributes comparing the real and synthetic data is shown in Fig. 4. As can be
observed in the Figure, PEARL is able to model the real data better than DP-MERF, e.g., covering
more modes in categorical variables with less discrepancy in the frequency of each mode. PEARL is
also able to better model the descending trend of the continuous variable “age”. The average ROC
and PRC scores (average and error) are shown in Table 2. ROC and PRC scores based on PEARL’s
training data are shown to be closer to those based on real training data compared to DP-MERF. More
histogram plots in higher resolution are available in App. I. Also, in App. I, we present experimental
results of another tabular dataset (Credit), as well as evaluations with other metrics/tasks using the
synthetic data. PEARL still performs favorably under these different conditions. Overall, we have
demonstrated that PEARL is able to produce high-quality synthetic data at practical privacy levels."
CONCLUSION,0.3832199546485261,"6
CONCLUSION"
CONCLUSION,0.3854875283446712,"We have developed a DP framework to synthesize data with deep generative models. Our approach
provides synthetic samples at practical privacy levels, and sidesteps difﬁculties encountered in
gradient sanitization methods. While we have limited ourselves to characteristic functions, it is
interesting to adopt and adapt other paradigms to the PEARL framework as a future direction."
CONCLUSION,0.3877551020408163,Published as a conference paper at ICLR 2022
REFERENCES,0.3900226757369615,REFERENCES
REFERENCES,0.3922902494331066,"Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and
Li Zhang. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC
Conference on Computer and Communications Security, pp. 308–318. ACM, 2016."
REFERENCES,0.3945578231292517,"Abdul Fatir Ansari, Jonathan Scarlett, and Harold Soh. A characteristic function approach to deep
implicit generative modeling. In Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition, pp. 7478–7487, 2020."
REFERENCES,0.3968253968253968,"Martin Arjovsky, Soumith Chintala, and Léon Bottou. Wasserstein generative adversarial networks.
In International conference on machine learning, pp. 214–223. PMLR, 2017."
REFERENCES,0.39909297052154197,"Arthur Asuncion and David Newman. Uci machine learning repository, 2007."
REFERENCES,0.4013605442176871,"Mikołaj Bi´nkowski, Dougal J Sutherland, Michael Arbel, and Arthur Gretton. Demystifying MMD
GANs. arXiv preprint arXiv:1801.01401, 2018."
REFERENCES,0.4036281179138322,"Kuntai Cai, Xiaoyu Lei, Jianxin Wei, and Xiaokui Xiao. Data synthesis via differentially private
markov random ﬁelds. Proceedings of the VLDB Endowment, 14(11):2190–2202, 2021."
REFERENCES,0.40589569160997735,"Dingfan Chen, Tribhuvanesh Orekondy, and Mario Fritz. Gs-wgan: A gradient-sanitized approach
for learning differentially private generators. Advances in Neural Information Processing Systems,
33:12673–12684, 2020."
REFERENCES,0.40816326530612246,"Rui Chen, Qian Xiao, Yu Zhang, and Jianliang Xu. Differentially private high-dimensional data
publication via sampling-based inference. In Proceedings of the 21th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, pp. 129–138, 2015."
REFERENCES,0.41043083900226757,"Kacper P Chwialkowski, Aaditya Ramdas, Dino Sejdinovic, and Arthur Gretton. Fast two-sample
testing with analytic representations of probability measures. In Advances in Neural Information
Processing Systems, pp. 1981–1989, 2015."
REFERENCES,0.4126984126984127,"Andrea Dal Pozzolo, Olivier Caelen, Reid A Johnson, and Gianluca Bontempi. Calibrating prob-
ability with undersampling for unbalanced classiﬁcation. In 2015 IEEE Symposium Series on
Computational Intelligence, pp. 159–166. IEEE, 2015."
REFERENCES,0.41496598639455784,"Cynthia Dwork. Differential privacy. In Proceedings of the 33rd international conference on
Automata, Languages and Programming-Volume Part II, pp. 1–12, 2006."
REFERENCES,0.41723356009070295,"Cynthia Dwork. A ﬁrm foundation for private data analysis. Communications of the ACM, 54(1):
86–95, 2011."
REFERENCES,0.41950113378684806,"Cynthia Dwork, Aaron Roth, et al. The algorithmic foundations of differential privacy. Found. Trends
Theor. Comput. Sci., 9(3-4):211–407, 2014."
REFERENCES,0.4217687074829932,"Herbert Federer. Geometric measure theory. Springer, 2014."
REFERENCES,0.42403628117913833,"Lorenzo Frigerio, Anderson Santana de Oliveira, Laurent Gomez, and Patrick Duverger. Differentially
private generative adversarial networks for time series, continuous, and discrete open data. In IFIP
International Conference on ICT Systems Security and Privacy Protection, pp. 151–164. Springer,
2019."
REFERENCES,0.42630385487528344,"Damien Garreau, Wittawat Jitkrittum, and Motonobu Kanagawa. Large sample analysis of the median
heuristic. arXiv preprint arXiv:1707.07269, 2017."
REFERENCES,0.42857142857142855,"Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio.
Generative adversarial nets.
In Advances in Neural
Information Processing Systems, pp. 2672–2680, 2014."
REFERENCES,0.4308390022675737,"Frederik Harder, Kamil Adamczewski, and Mijung Park. Dp-merf: Differentially private mean
embeddings with randomfeatures for practical privacy-preserving data generation. In International
conference on artiﬁcial intelligence and statistics, pp. 1819–1827. PMLR, 2021."
REFERENCES,0.4331065759637188,Published as a conference paper at ICLR 2022
REFERENCES,0.43537414965986393,"Xi He, Graham Cormode, Ashwin Machanavajjhala, Cecilia M Procopiuc, and Divesh Srivastava.
Dpt: differentially private trajectory synthesis using hierarchical reference systems. Proceedings
of the VLDB Endowment, 8(11):1154–1165, 2015."
REFERENCES,0.4376417233560091,"CE Heathcote. A test of goodness of ﬁt for symmetric random variables. Australian Journal of
Statistics, 14(2):172–181, 1972."
REFERENCES,0.4399092970521542,"Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans
trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural
information processing systems, 30, 2017."
REFERENCES,0.4421768707482993,"Matthew Jagielski, Jonathan Ullman, and Alina Oprea. Auditing differentially private machine
learning: How private is private sgd? Advances in Neural Information Processing Systems, 33:
22205–22216, 2020."
REFERENCES,0.4444444444444444,"Wittawat Jitkrittum, Zoltán Szabó, Kacper P. Chwialkowski, and Arthur Gretton. Interpretable
distribution features with maximum testing power. In Advances in Neural Information Processing
Systems, pp. 181–189, 2016."
REFERENCES,0.4467120181405896,"James Jordon, Jinsung Yoon, and Mihaela van der Schaar. PATE-GAN: generating synthetic data
with differential privacy guarantees. In International Conference on Learning Representations,
ICLR, 2019."
REFERENCES,0.4489795918367347,"Achim Klenke. Probability theory: a comprehensive course. Springer Science & Business Media,
2013."
REFERENCES,0.4512471655328798,"Yann LeCun, Corinna Cortes, and CJ Burges. Mnist handwritten digit database. ATT Labs [Online].
Available: http://yann.lecun.com/exdb/mnist, 2, 2010."
REFERENCES,0.45351473922902497,"Shengxi Li, Zeyang Yu, Min Xiang, and Danilo P. Mandic. Reciprocal adversarial learning via
characteristic functions. In Advances in Neural Information Processing Systems, 2020."
REFERENCES,0.4557823129251701,"Eugene Lukacs. A survey of the theory of characteristic functions. Advances in Applied Probability,
4(1):1–37, 1972."
REFERENCES,0.4580498866213152,"David J.C MacKay. Bayesian neural networks and density networks. Nuclear Instruments and
Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated
Equipment, pp. 73–80, 1995."
REFERENCES,0.4603174603174603,"Ilya Mironov. Rényi differential privacy. In 2017 IEEE 30th Computer Security Foundations
Symposium (CSF), pp. 263–275. IEEE, 2017."
REFERENCES,0.46258503401360546,"Milad Nasr, Shuang Songi, Abhradeep Thakurta, Nicolas Papemoti, and Nicholas Carlin. Adversary
instantiation: Lower bounds for differentially private machine learning. In 2021 IEEE Symposium
on Security and Privacy (SP), pp. 866–882. IEEE, 2021."
REFERENCES,0.46485260770975056,"Mijung Park, James R. Foulds, Kamalika Choudhary, and Max Welling. DP-EM: differentially
private expectation maximization. In Proceedings of the 20th International Conference on Artiﬁcial
Intelligence and Statistics, pp. 896–904, 2017."
REFERENCES,0.4671201814058957,"Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier
Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. Scikit-learn:
Machine learning in python. the Journal of machine Learning research, 12:2825–2830, 2011."
REFERENCES,0.46938775510204084,"Wahbeh Qardaji, Weining Yang, and Ninghui Li. Priview: practical differentially private release of
marginal contingency tables. In Proceedings of the 2014 ACM SIGMOD international conference
on Management of data, pp. 1435–1446, 2014."
REFERENCES,0.47165532879818595,"Bharath K Sriperumbudur, Kenji Fukumizu, and Gert RG Lanckriet. Universality, characteristic
kernels and rkhs embedding of measures. Journal of Machine Learning Research, 12(7), 2011."
REFERENCES,0.47392290249433106,"Shun Takagi, Tsubasa Takahashi, Yang Cao, and Masatoshi Yoshikawa.
P3gm: Private high-
dimensional data release via privacy preserving phased generative model. In 2021 IEEE 37th
International Conference on Data Engineering (ICDE), pp. 169–180. IEEE, 2021."
REFERENCES,0.47619047619047616,Published as a conference paper at ICLR 2022
REFERENCES,0.47845804988662133,"Reihaneh Torkzadehmahani, Peter Kairouz, and Benedict Paten. Dp-cgan: Differentially private
synthetic data and label generation. In The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR) Workshops, June 2019."
REFERENCES,0.48072562358276644,"Yu-Xiang Wang, Borja Balle, and Shiva Prasad Kasiviswanathan. Subsampled rényi differential
privacy and analytical moments accountant. In The 22nd International Conference on Artiﬁcial
Intelligence and Statistics, pp. 1226–1235. PMLR, 2019."
REFERENCES,0.48299319727891155,"David Williams. Probability with martingales. Cambridge University Press, 1991."
REFERENCES,0.4852607709750567,"Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking
machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017."
REFERENCES,0.4875283446712018,"Liyang Xie, Kaixiang Lin, Shu Wang, Fei Wang, and Jiayu Zhou. Differentially private generative
adversarial network. arXiv preprint arXiv:1802.06739, 2018."
REFERENCES,0.4897959183673469,"Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, and Kalyan Veeramachaneni. Modeling tabular
data using conditional gan. In Advances in Neural Information Processing Systems, volume 32,
2019."
REFERENCES,0.49206349206349204,"Jun Zhang, Graham Cormode, Cecilia M Procopiuc, Divesh Srivastava, and Xiaokui Xiao. Privbayes:
Private data release via bayesian networks. ACM Transactions on Database Systems (TODS), 42
(4):1–41, 2017."
REFERENCES,0.4943310657596372,"Zhikun Zhang, Tianhao Wang, Ninghui Li, Jean Honorio, Michael Backes, Shibo He, Jiming Chen,
and Yang Zhang. PrivSyn: Differentially private data synthesis. In 30th USENIX Security
Symposium (USENIX Security 21), pp. 929–946, 2021."
REFERENCES,0.4965986394557823,Published as a conference paper at ICLR 2022
REFERENCES,0.4988662131519274,"A
ADDITIONAL DEFINITIONS AND PREVIOUS RESULTS"
REFERENCES,0.5011337868480725,"Deﬁnition 5 (Rényi differential privacy). A randomized mechanism M is said to satisfy ε-Rényi
differential privacy of order λ, when"
REFERENCES,0.5034013605442177,"Dλ(M(d)∥M(d′)) =
1
λ −1 log Ex∼M(d)"
REFERENCES,0.5056689342403629,""" Pr[M(d) = x]"
REFERENCES,0.5079365079365079,Pr[M(d′) = x] λ−1# ≤ε
REFERENCES,0.5102040816326531,"is satisﬁed for any adjacent datasets d and d′. Here, Dλ(P∥Q) =
1
λ−1 log Ex∼Q[(P(x)/Q(x))λ] is"
REFERENCES,0.5124716553287982,"the Rényi divergence. Furthermore, a ε-RDP mechanism of order λ is also (ε + log 1/δ"
REFERENCES,0.5147392290249433,"λ−1 , δ)-DP."
REFERENCES,0.5170068027210885,"Next, we note that the Gaussian mechanism is (λ, λ∆2f 2"
REFERENCES,0.5192743764172335,"2σ2 )-RDP (Mironov (2017)). The particular
advantage of using RDP is that it gives a convenient way of tracking the privacy costs when a
sequence of mechanisms is applied. More precisely, the following theorem holds (Mironov (2017)):
Theorem 4 (RDP Composition). For a sequence of mechanisms M1, ..., Mk s.t. Mi is (λ, εi)-RDP
∀i, the composition M1 ◦... ◦Mk is (λ, P"
REFERENCES,0.5215419501133787,i εi)-RDP.
REFERENCES,0.5238095238095238,We use the autodp package to keep track of the privacy budget (Wang et al. (2019)).
REFERENCES,0.5260770975056689,"B
PROOFS"
REFERENCES,0.528344671201814,"B.1
PROOF OF THM. 2"
REFERENCES,0.5306122448979592,"Proof. Let Pr denote the real data distribution, Qθ denote the data distribution generated by Gθ using
a latent vector, z sampled from a pre-determined distribution, and ω a sampling distribution. | · |
denotes the modulus of ·. Then, the CFD between the distributions is"
REFERENCES,0.5328798185941043,"C2
ω(Pr, Qθ) = Et∼ω(t)
h
|ΦPr(t) −ΦQθ(t)|2i
,"
REFERENCES,0.5351473922902494,"where ΦP(t) = Ex∼P

eit·x
is the CF of P. For notational brevity, we write ΦPr(t) as Φr(t), and
ΦQθ(t) as Φθ(t) in the following."
REFERENCES,0.5374149659863946,"We consider the optimized CFD, sup
ω∈Ω
C2
ω(Pr, Qθ), and would like to show that it is locally Lips-"
REFERENCES,0.5396825396825397,"chitz, 4 which subsequently means that it is continuous. Since the Radamacher’s theorem (Federer
(2014)) implies that any locally Lipschitz function is differentiable almost everywhere, the claim of
differentiability is also justiﬁed once the Lipschitz locality is proven."
REFERENCES,0.5419501133786848,"We ﬁrst note that the difference of two maximal functions’ values is smaller or equal to the maximal
difference of the two functions. Then, for any θ and θ′,
sup
ω∈Ω
C2
ω(Pr, Qθ) −sup
ω∈Ω
C2
ω(Pr, Qθ′)
 ≤sup
ω∈Ω"
REFERENCES,0.54421768707483,"C2
ω(Pr, Qθ) −C2
ω(Pr, Qθ′)
.
(9)"
REFERENCES,0.546485260770975,"We note that the absolute difference of any two complex values represented in terms of its real-number
amplitude (A, B) and phase (α, β) satisﬁes |Aeiα −Beiβ| ≤|A| + |B|. Writing the maximal ω as
ω∗, the RHS of Eq. 9 can be written as
C2
ω∗(Pr, Qθ) −C2
ω∗(Pr, Qθ′)

(10)"
REFERENCES,0.5487528344671202,"= Et∼ω∗(t) [(Cω∗(Pr, Qθ) + Cω∗(Pr, Qθ′)) (Cω∗(Pr, Qθ) −Cω∗(Pr, Qθ′))]"
REFERENCES,0.5510204081632653,= Et∼ω∗(t) [(|Φr(t) −Φθ(t)| + |Φr(t) −Φθ′(t)|)(|Φr(t) −Φθ(t)| −|Φr(t) −Φθ′(t)|)]
REFERENCES,0.5532879818594104,≤Et∼ω∗(t) [(2|Φr(t)| + |Φθ(t)| + |Φθ′(t)|)(|Φr(t) −Φθ(t)| −|Φr(t) −Φθ′(t)|)]
REFERENCES,0.5555555555555556,"(a)
≤4Et∼ω∗(t) [|Φr(t) −Φθ(t)| −|Φr(t) −Φθ′(t)|]"
REFERENCES,0.5578231292517006,"(b)
≤4Et∼ω∗(t) [|Φθ(t) −Φθ′(t)|] ,"
REFERENCES,0.5600907029478458,"4A function f is locally Lipschitz if there exist constants δ ≥0 and M ≥0 such that |x −y| < δ →
|f(x) −f(y)| ≤M · |x −y| for all x, y."
REFERENCES,0.562358276643991,Published as a conference paper at ICLR 2022
REFERENCES,0.564625850340136,"where we have used (a) |ΦP| ≤1, (b) triangle inequality. By interpreting a complex number as
a vector on a 2D plane, and using trigonometric arguments, one can deduce that |eia −eib| =
2 sin(|a −b|/2) ≤|a −b|. Then,"
REFERENCES,0.5668934240362812,"4Et∼ω∗(t) [|Φθ(t) −Φθ′(t)|] = 4Et∼ω∗(t)
h
|Ez[eit·Gθ(z)] −Ez[eit·Gθ′(z)]|
i
(11)"
REFERENCES,0.5691609977324263,"(c)
≤4Et∼ω∗(t) [Ez[|t · Gθ(z) −t · Gθ′(z)|]]"
REFERENCES,0.5714285714285714,"(d)
≤4Et∼ω∗(t)Ez [|t| · |Gθ(z) −Gθ′(z)|] ."
REFERENCES,0.5736961451247166,"In (c), we have also used the Jensen inequality. In (d), the Cauchy-Schwarz inequality has been
applied. As we are assuming that Gθ is a L(θ, z)-Lipschitz function, we have"
REFERENCES,0.5759637188208617,"Et∼ω∗(t)Ez [|t| · |Gθ(z) −Gθ′(z)|] ≤4Et∼ω∗(t)[|t|] · Ez[L(θ, z)] · |θ −θ′|.
(12)"
REFERENCES,0.5782312925170068,"Since we are also assuming that Et∼ω∗(t)[|t|], Ez[L(θ, z)] ≤∞, we have shown that sup
ω∈Ω
Cω is"
REFERENCES,0.5804988662131519,"locally Lipschitz, as required. It is therefore continuous and differentiable almost everywhere, as
discussed above."
REFERENCES,0.5827664399092971,"B.2
PROOF OF THM. 3"
REFERENCES,0.5850340136054422,"Proof. We denote xn ∼Pn and x ∼P, and ω∗the maximal function of ω. Notice that"
REFERENCES,0.5873015873015873,"C2
ω∗(Pn, P) = Et∼ω∗(t)
hExn

eit·xn
−Ex

eit·x2i"
REFERENCES,0.5895691609977324,"= Et∼ω∗(t)
Exn

eit·xn
−Ex

eit·x ·
Exn

eit·xn
−Ex

eit·x"
REFERENCES,0.5918367346938775,"(a)
≤2 Et∼ω∗(t)
Exn

eit·xn
−Ex

eit·x"
REFERENCES,0.5941043083900227,"(b)
≤2 Et∼ω∗(t) Exn,x
eit·xn −eit·x"
REFERENCES,0.5963718820861678,"(c)
≤2 Et∼ω∗(t) [|t|] Exn,x [|xn −x|] .
(13)"
REFERENCES,0.5986394557823129,"Here, (a) uses |Aeiα −Beiβ| ≤|A| + |B| as argued above Eq. 10; (b) uses Jensen inequality; (c)
uses the argument |eia −eib| = 2 sin(|a −b|/2) ≤|a −b|, given above Eq. 11. Then, by weak
convergence equivalence (Klenke (2013)), the RHS of Eq. 13 approaches zero as Pn
D
−→P, hence
proving the theorem."
REFERENCES,0.6009070294784581,"B.3
PROOF OF LEMMA. 1"
REFERENCES,0.6031746031746031,"Proof. Recall that for any two distributions, ω(t), ω0(t) and any function f(t),"
REFERENCES,0.6054421768707483,"Eω[f(t)] =
Z
f(t)ω(t)dt"
REFERENCES,0.6077097505668935,"=
Z
f(t) ω(t)"
REFERENCES,0.6099773242630385,ω0(t)ω0(t)dt
REFERENCES,0.6122448979591837,= Eω0[f(t) ω(t)
REFERENCES,0.6145124716553289,ω0(t)].
REFERENCES,0.6167800453514739,"Hence, Eω(t)[f(t)] = Eω0[f(t) ω(t)"
REFERENCES,0.6190476190476191,ω0(t)]. Let ω∗be the maximal probability distribution. It is then
REFERENCES,0.6213151927437641,clear that bEω[f(t)] →Eω[f(t)] implies bEω0[f(t) ω∗(t)
REFERENCES,0.6235827664399093,"ω0(t)] →Eω∗[f(t)], as desired."
REFERENCES,0.6258503401360545,"C
EXPERIMENTAL SETUP OF TWO-SAMPLE TESTING ON SYNTHETIC DATA"
REFERENCES,0.6281179138321995,"Let us describe in more detail the experiment presented in Sec. 4. Data are generated from two
unit-variance multivariate Gaussian distributions P, Q, where all dimensions but one have zero mean
(P ∼N(0d, Id), Q ∼N((1, 0, . . . , 0)⊤, Id)). We wish to conduct a two-sample test using the CF to"
REFERENCES,0.6303854875283447,Published as a conference paper at ICLR 2022
REFERENCES,0.6326530612244898,"distinguish between the two distributions, which gets more difﬁcult as the dimensionality increases.
We test if the null hypothesis where the samples are drawn from the same distribution is rejected."
REFERENCES,0.6349206349206349,"Three sets of frequencies are considered. The number of frequncies in each set is set to 20. The
ﬁrst set is an “unoptimized” set of frequencies. The ﬁrst dimension of all but one frequency
has the value of zero. Other dimensions have values generated randomly from a zero-mean unit-
variance multivariate Gaussian distribution. We denote the frequency with non-zero value in the
ﬁrst dimension by t0 without loss of generality. A “normal” set of frequencies is also considered
for comparison, where the frequencies of all dimensions are sampled randomly from a multivariate
Gaussian distributions. Finally, we consider an “optimized” set of frequencies, where from the
“unoptimized” set of frequencies, only t0 is selected to be used for two-sample testing. In other words,
we re-weight the set of frequencies such that all but t0 has zero weight. 1,000 samples are generated
from each of P and Q. We repeat the problem for 100 trials to obtain the rejection rate (and repeat
the whole experiment 5 times to get the error bar)."
REFERENCES,0.63718820861678,"D
DP ESTIMATE OF THE MEAN OF PAIRWISE DISTANCE"
REFERENCES,0.6394557823129252,"Median heuristic is applied widely in kernel methods applications to determine the bandwidth of the
radial basis function (RBF) kernels (Garreau et al. (2017)). The bandwidth is taken to be the median
of all pairwise distances of data samples. Here we give a DP estimation of the mean instead as the
calculation of mean is more tractable. Let x be samples of a certain data distribution of dimension d
and assume that the values lie in [0, 1]d. Given n samples, there is a total of n(n −1)/2 pairwise
distance pairs. Then, the mean of the pairwise distance of samples is"
REFERENCES,0.6417233560090703,"Dn(x) =
2
n(n −1) n
X"
REFERENCES,0.6439909297052154,"i̸=j
∥xi −xj∥2."
REFERENCES,0.6462585034013606,where ∥· ∥2 indicates the Euclidean norm.
REFERENCES,0.6485260770975056,"Consider a pair of neighboring datasets, D, D′. Without loss of generality, let xn ̸= x′
n and xi = x′
i
for i ̸= n. Then, the sensitivity of Dn(x) is"
REFERENCES,0.6507936507936508,"∆Dn(x) = max
D,D′ "
REFERENCES,0.6530612244897959,"2
n(n −1) n
X"
REFERENCES,0.655328798185941,"i̸=j
∥xi −xj∥2 −
2
n(n −1) n
X"
REFERENCES,0.6575963718820862,"i̸=j
∥x′
i −x′
j∥2 2"
REFERENCES,0.6598639455782312,"(a)
=
2
n(n −1) max
D,D′  n−1
X"
REFERENCES,0.6621315192743764,"i=1
∥xi −xn∥2 − n−1
X"
REFERENCES,0.6643990929705216,"i=1
∥xi −x′
n∥2 2"
REFERENCES,0.6666666666666666,"(b)
=
2
n(n −1) · (n −1)
√ d = 2
√ d
n ."
REFERENCES,0.6689342403628118,"In (a), we cancel out all terms unrelated to xn or x′
n. In (b), we use the fact that ∥xi −xn∥2
and ∥xi −x′
n∥2 lie in [0,
√"
REFERENCES,0.671201814058957,"d]. After obtaining the sensitivity, one can then applies the Gaussian
mechanism as in Eq. 6 to obtain the DP estimate of the mean of the pairwise distance of samples."
REFERENCES,0.673469387755102,"E
TRAINING ALGORITHM"
REFERENCES,0.6757369614512472,The pseudo-code of the proposed training algorithm is given in Algorithm 1.
REFERENCES,0.6780045351473923,"F
COMPUTATIONAL COMPLEXITY ANALYSIS"
REFERENCES,0.6802721088435374,"PEARL is trained based on deep learning methods, which is efﬁcient computation-wise using a
GPU. Nevertheless, let us give a computational complexity analysis in a traditional sense by ignoring
(partially) the parallel computing capability."
REFERENCES,0.6825396825396826,Published as a conference paper at ICLR 2022
REFERENCES,0.6848072562358276,Algorithm 1: PEARL Training
REFERENCES,0.6870748299319728,"Input: Sensitive data {x}n
i=1, differential privacy noise scale σDP, number of frequencies k,
base sampling distribution variance σ0, training iterations T, learning rates ηC and
ηG, number of generator iterations per critic iteration ngen, batch size B, latent
distribution Pz
Output: Differentially private generator Gθ"
REFERENCES,0.6893424036281179,"1 Obtain auxiliary information (e.g., base sampling distribution variance σ0);"
REFERENCES,0.691609977324263,"2 Sample frequencies {t}k
i=1 with t ∼N(0, diag(σ0));"
REFERENCES,0.6938775510204082,"3 for i in {1, ..., k} do"
REFERENCES,0.6961451247165533,"4
bΦP(ti) = 1"
REFERENCES,0.6984126984126984,"n
Pn
j=1 eiti·xj"
REFERENCES,0.7006802721088435,"5
eΦP(ti) = bΦP(ti) + N(0, ∆2
b
φ(x)σ2
DPI)"
END,0.7029478458049887,6 end
END,0.7052154195011338,7 Accumulate privacy cost ϵ;
END,0.7074829931972789,"8 eφ(x) ←(eΦP(t1), . . . , eΦP(tk))⊤"
END,0.7097505668934241,"9 Initialize generator Gθ, sampling distribution variance σ ;"
END,0.7120181405895691,"10 for step in {1, ..., T} do"
END,0.7142857142857143,"11
for t in {1, ..., ngen} do"
END,0.7165532879818595,"12
Sample batch {zi}B
i=1 with zi ∼Pz;"
END,0.7188208616780045,"13
for i in {1, ..., k} do"
END,0.7210884353741497,"14
bΦQ(ti) = 1"
END,0.7233560090702947,"B
PB
j=1 eiti·Gθ(zj)"
END,0.7256235827664399,"15
end"
END,0.7278911564625851,"16
bφ(z) ←(bΦQ(t1), . . . , bΦQ(tk))⊤"
END,0.7301587301587301,"17
θ ←θ −ηG · ∇θc
Cω
2(eφ(x), bφ(z))"
END,0.7324263038548753,"18
end"
END,0.7346938775510204,"19
Sample batch {zi}B
i=1 with zi ∼Pz;"
END,0.7369614512471655,"20
for i in {1, ..., k} do"
END,0.7392290249433107,"21
bΦQ(ti) = 1"
END,0.7414965986394558,"B
PB
j=1 eiti·Gθ(zj)"
END,0.7437641723356009,"22
end"
END,0.746031746031746,"23
bφ(z) ←(bΦQ(t1), . . . , bΦQ(tk))⊤"
END,0.7482993197278912,"24
σ ←σ + ηC · ∇σc
Cω
2(eφ(x), bφ(z))"
END,0.7505668934240363,25 end
END,0.7528344671201814,26 Return Gθ
END,0.7551020408163265,"Time complexity. We sample k frequencies and calculate its inner product with data points (of
dimension d), make a summation with respect to n data points to build k CFs. Since inner product
takes d steps, summation n steps, and we do it for k times, the time complexity of generating CFs is
nkd. We additionally train the generative model, requiring ttr. Note that unlike graphical models
like PrivBayes, which gradually add nodes to the Bayesian network, our method can be parallelized
efﬁciently with GPU. As we sample n records from the generative model during data generation,
the time complexity of dataset generation is n times the inference time, tinf. The total training and
inference time is O(nkd + ntinf + ttr)."
END,0.7573696145124716,"Space complexity. We need to store the k CF values during training. We also need to store the
generative model with m parameters. The space complexity is O(k + m)."
END,0.7596371882086168,"G
EVALUATION METRICS"
END,0.7619047619047619,"We utilize evaluation metrics commonly used to evaluate GAN’s performance, namely Fréchet
Inception Distance (FID) (Heusel et al. (2017)) and Kernel Inception Distance (KID) (Bi´nkowski
et al. (2018)). FID corresponds to computing the Fréchet distance between the Gaussian ﬁts of the
Inception features obtained from real and fake distributions. KID is the calculation of the MMD of
the Inception features between real and fake distributions using a polynomial kernel of degree 3."
END,0.764172335600907,Published as a conference paper at ICLR 2022
END,0.7664399092970522,"The precision deﬁnitions are as follows. Let {xri}n
i=1 be samples from the real data distribution Pr
and {xθi}m
i=1 be samples from the generated data distribution Qθ. The corresponding feature vectors
extracted from a pre-trained network (LeNet in our case) are {zri}n
i=1 and {zθi}m
i=1 respectively.
The FID and KID are deﬁned as"
END,0.7687074829931972,"FID(Pr, Qθ) =∥µr −µθ∥2
2 + Tr(Σr + Σθ −2(ΣrΣθ)1/2),
(14)"
END,0.7709750566893424,"KID(Pr, Qθ) =
1
n(n −1) n
X i=1 n
X"
END,0.7732426303854876,"j=1,j̸=i"
END,0.7755102040816326,"
κ(zr
i , zr
j)
"
END,0.7777777777777778,"+
1
m(m −1) m
X i=1 m
X"
END,0.780045351473923,"j=1,j̸=i"
END,0.782312925170068,"
κ(zθ
i , zθ
j)

(15)"
END,0.7845804988662132,"−
2
mn n
X i=1 m
X j=1"
END,0.7868480725623582,"
κ(zr
i , zθ
j)

,"
END,0.7891156462585034,"where (µr, Σr) and (µθ, Σθ) are the sample mean & covariance matrix of the inception features of
the real and generated data distributions, and κ is a polynomial kernel of degree 3:"
END,0.7913832199546486,"κ(x, y) =
1"
END,0.7936507936507936,"dx · y + 1
3
,
(16)"
END,0.7959183673469388,"where d is the dimensionality of the feature vectors. We compute FID with 10 bootstrap resamplings
and KID by sampling 100 elements without replacement from the whole generated dataset."
END,0.7981859410430839,"H
IMPLEMENTATION DETAILS"
END,0.800453514739229,"Datasets. For MNIST and Fashion-MNIST, we use the default train subset of the torchvision
5 library for training the generator, and the default subset for evaluation. For Adult, we follow the
preprocessing procedure in Harder et al. (2021) to make the dataset more balanced by downsampling
the class with the most number of samples."
END,0.8027210884353742,Neural networks. The generator for image datasets has the following network architecture:
END,0.8049886621315193,"• fc →bn →fc →bn →upsamp →relu →upconv →sigmoid,"
END,0.8072562358276644,"where fc, bn, upsamp, relu, upconv, sigmoid refers to fully connected, batch normalization, 2D
bilinear upsampling, ReLU, up-convolution, and Sigmoid layers respectively."
END,0.8095238095238095,"For tabular dataset, we use the following architecture:"
END,0.8117913832199547,"• fc →bn →relu →fc →bn →relu →fc →tanh/softmax,"
END,0.8140589569160998,"where tanh and softmax are the Tanh and softmax layers respectively. Network output corresponding
to the continuous attribute is passed through the Tanh layer, whereas network output corresponding
to the categorical attribute is passed through the softmax layer, where the category with the highest
value from the softmax output is set to be the generated value of the categorical attribute. We train
both networks conditioned on the class labels. For DP-MERF, we use the same architectures for fair
comparisons."
END,0.8163265306122449,"Hyperparameters. We use Adam optimizer with learning rates of 0.01 for both the minimization
and maximization objectives. Batch size is 100 (1,100) for the image datasets (tabular dataset). The
number of frequencies is set to 1,000 (3,000) for MNIST and tabular datasets (Fashion-MNIST).
The training iterations are 6,000, 3,000, and 8,000 for MNIST, Fashion-MNIST, and tabular datasets
respectively."
END,0.81859410430839,5https://pytorch.org/vision/stable/index.html
END,0.8208616780045351,Published as a conference paper at ICLR 2022
END,0.8231292517006803,"Datasets
Methods
ROC
PRC
Range
Marginal
MMD"
END,0.8253968253968254,"Adult
DP-MERF
0.64
0.54
0.10
1.37
2 × 10−3"
END,0.8276643990929705,"Ours
0.72
0.62
0.06
0.71
1 × 10−7"
END,0.8299319727891157,"Credit
DP-MERF
0.66
0.26
0.049
0.95
2 × 10−5"
END,0.8321995464852607,"Ours
0.84
0.68
0.026
0.72
1 × 10−8"
END,0.8344671201814059,"Table 3: Evaluation with ROC, PRC (higher is better), range query, marginal release and MMD
(lower is better) on tabular datasets at (ϵ, δ) = (1, 10−5)."
END,0.8367346938775511,"Real data
DPCGAN
Ours"
END,0.8390022675736961,"ROC
PRC
ROC
PRC
ROC
PRC"
END,0.8412698412698413,"LR
0.788
0.681
0.501 ± 0.001
0.484 ± 0.001
0.752 ± 0.009
0.641 ± 0.015
Gaussian NB
0.629
0.511
0.499 ± 0.005
0.483 ± 0.003
0.661 ± 0.036
0.537 ± 0.028
Bernoulli NB
0.769
0.651
0.482 ± 0.159
0.498 ± 0.091
0.763 ± 0.008
0.644 ± 0.009
Linear SVM
0.781
0.671
0.501 ± 0.001
0.484 ± 0.001
0.752 ± 0.009
0.640 ± 0.015
Decision Tree
0.759
0.646
0.599 ± 0.078
0.546 ± 0.056
0.675 ± 0.03
0.582 ± 0.028
LDA
0.782
0.670
0.501 ± 0.002
0.484 ± 0.002
0.755 ± 0.005
0.640 ± 0.007
Adaboost
0.789
0.682
0.523 ± 0.065
0.5 ± 0.036
0.709 ± 0.031
0.628 ± 0.024
Bagging
0.772
0.667
0.546 ± 0.082
0.516 ± 0.058
0.687 ± 0.041
0.601 ± 0.039
GBM
0.800
0.695
0.544 ± 0.101
0.518 ± 0.066
0.709 ± 0.029
0.635 ± 0.025
MLP
0.776
0.660
0.503 ± 0.004
0.486 ± 0.004
0.744 ± 0.012
0.635 ± 0.015"
END,0.8435374149659864,"Table 4: Quantitative results for the Adult dataset evaluated at (ϵ, δ) = (1, 10−5)."
END,0.8458049886621315,"I
ADDITIONAL RESULTS"
END,0.8480725623582767,"I.1
ADDITIONAL TASKS AND DATASET FOR TABULAR DATA"
END,0.8503401360544217,"We here present more results relevant to PEARL’s generative modeling of tabular data. We ﬁrst
compare PEARL with DPCGAN in Table 4 using the same classiﬁers as in the main text."
END,0.8526077097505669,"Three additional metrics/tasks are utilized: Range query. 1000 range queries containing three
attributes are sampled randomly. The average l1 error between the original and synthetic datasets is
evaluated. Marginal release. All 2-way marginals are calculated and the average l1 error is evaluated.
MMD. The max mean discrepancy (MMD) between the original and synthetic dataset is evaluated.
We use the MMD because it is a powerful measure that could in principle detect any discrepancy
between two distributions. A Gaussian kernel is used in the evaluation."
END,0.854875283446712,"Additionally, we perform evaluation on another tabular dataset: Credit (Dal Pozzolo et al. (2015)).
Our results comparing with DP-MERF as shown in Table 3 demonstrate that PEARL is competitive
with various tasks and datasets."
END,0.8571428571428571,"I.2
MNIST AND FASHION-MNIST IMAGES"
END,0.8594104308390023,"Fig. 5 and Fig. 6 show more enlarged images of MNIST and Fashion-MNIST at various level of ϵ
generated with PEARL. We also show images generated by PEARL but without critic, and DPGAN.
Note that we are unable to generate meaningful images from DP-MERF after taking privacy into
account appropriately (see Sec. 5)."
END,0.8616780045351474,"I.3
ADULT HISTOGRAMS"
END,0.8639455782312925,"We show more histogram plots for continuous and categorical attributes comparing our method with
DP-MERF in Fig. 9 and Fig. 10."
END,0.8662131519274376,Published as a conference paper at ICLR 2022
END,0.8684807256235828,"(a) ϵ = ∞
(b) ϵ = 10"
END,0.8707482993197279,"(c) ϵ = 1
(d) ϵ = 0.2"
END,0.873015873015873,Figure 5: Additional generated MNIST images at various ϵ.
END,0.8752834467120182,Published as a conference paper at ICLR 2022
END,0.8775510204081632,"(a) ϵ = ∞
(b) ϵ = 10"
END,0.8798185941043084,"(c) ϵ = 1
(d) ϵ = 0.2"
END,0.8820861678004536,Figure 6: Additional generated Fashion-MNIST images at various ϵ.
END,0.8843537414965986,"(a) ϵ = 1, MNIST (DPGAN)
(b) ϵ = 1, FMNIST(DPGAN)"
END,0.8866213151927438,Figure 7: Images generated by DPGAN at ϵ = 1.
END,0.8888888888888888,"(a) ϵ = 1, MNIST (Ours w/o critic)
(b) ϵ = 1, FMNIST(Ours w/o critic)"
END,0.891156462585034,Figure 8: Images generated by our proposal (PEARL) but without critic at ϵ = 1.
END,0.8934240362811792,Published as a conference paper at ICLR 2022
END,0.8956916099773242,"20
40
60
80 10 3 10 2"
END,0.8979591836734694,DP­MERF
END,0.9002267573696145,"20
40
60
80 10 3 10 2 Ours"
END,0.9024943310657596,"real
synthetic"
END,0.9047619047619048,(a) Age
END,0.9070294784580499,"0.00
0.25
0.50
0.75
1.00
1.25 1e6 10 8 10 7 10 6 10 5"
END,0.909297052154195,DP­MERF
END,0.9115646258503401,"0.00
0.25
0.50
0.75
1.00
1.25 1e6 10 8 10 7 10 6"
END,0.9138321995464853,"10 5
Ours"
END,0.9160997732426304,"real
synthetic"
END,0.9183673469387755,(b) fnlwgt
END,0.9206349206349206,"0
20000
40000
60000
80000 100000 10 7 10 6 10 5 10 4"
END,0.9229024943310657,DP­MERF
END,0.9251700680272109,"0
20000
40000
60000
80000 100000 10 7 10 6 10 5 10 4 Ours"
END,0.927437641723356,"real
synthetic"
END,0.9297052154195011,(c) Capital Gain
END,0.9319727891156463,"0
1000
2000
3000
4000 10 6 10 5 10 4 10 3"
END,0.9342403628117913,DP­MERF
END,0.9365079365079365,"0
1000
2000
3000
4000 10 6 10 5 10 4 10 3 Ours"
END,0.9387755102040817,"real
synthetic"
END,0.9410430839002267,(d) Capital loss
END,0.9433106575963719,Published as a conference paper at ICLR 2022
END,0.9455782312925171,0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.011.012.013.014.015.0
END,0.9478458049886621,category 101 102 103 104 count
END,0.9501133786848073,"Real
Ours
DP-MERF"
END,0.9523809523809523,(a) Education
END,0.9546485260770975,0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.011.012.013.014.0
END,0.9569160997732427,category 102 103 104 count
END,0.9591836734693877,"Real
Ours
DP-MERF"
END,0.9614512471655329,(b) Occupation
END,0.963718820861678,"0.0
1.0
2.0
3.0
4.0
5.0
6.0
7.0
8.0
category 101 102 103 104 count"
END,0.9659863945578231,"Real
Ours
DP-MERF"
END,0.9682539682539683,(c) Work class
END,0.9705215419501134,"0.0
1.0
2.0
3.0
4.0
5.0
category 103 count"
END,0.9727891156462585,"Real
Ours
DP-MERF"
END,0.9750566893424036,(d) Relationship
END,0.9773242630385488,"0.0
1.0
category"
END,0.9795918367346939,3 × 103
END,0.981859410430839,4 × 103
END,0.9841269841269841,6 × 103 count
END,0.9863945578231292,"Real
Ours
DP-MERF"
END,0.9886621315192744,(e) Sex
END,0.9909297052154195,"0.0
1.0
2.0
3.0
4.0
category 102 103 104 count"
END,0.9931972789115646,"Real
Ours
DP-MERF"
END,0.9954648526077098,(f) Race
END,0.9977324263038548,"Figure 10: Histograms of various categorical attributes of Adult dataset comparing real and synthetic
data."
