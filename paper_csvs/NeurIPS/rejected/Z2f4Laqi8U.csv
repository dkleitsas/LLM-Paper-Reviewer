Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0008561643835616438,"We propose a greedy search-and-score algorithm for ancestral graphs, which in-
1"
ABSTRACT,0.0017123287671232876,"clude directed as well as bidirected edges, originating from unobserved latent
2"
ABSTRACT,0.0025684931506849314,"variables. The normalized likelihood score of ancestral graphs is estimated in terms
3"
ABSTRACT,0.003424657534246575,"of multivariate information over relevant subsets of vertices, C, that are connected
4"
ABSTRACT,0.004280821917808219,"through collider paths conﬁned to the ancestor set of C. For computational efﬁ-
5"
ABSTRACT,0.005136986301369863,"ciency, the proposed two-step algorithm relies on local information scores limited
6"
ABSTRACT,0.0059931506849315065,"to the close surrounding vertices of each node (step 1) and edge (step 2). This
7"
ABSTRACT,0.00684931506849315,"computational strategy is shown to outperform state-of-the-art causal discovery
8"
ABSTRACT,0.007705479452054794,"methods on challenging benchmark datasets.
9"
INTRODUCTION,0.008561643835616438,"1
Introduction
10"
INTRODUCTION,0.009417808219178082,"The likelihood function plays a central role in the selection of a graphical model G based on
11"
INTRODUCTION,0.010273972602739725,"observational data D. Given N independent samples from D, the likelihood LD|G that they might
12"
INTRODUCTION,0.01113013698630137,"have been generated by the graphical model G is given by [1],
13"
INTRODUCTION,0.011986301369863013,"LD|G =
1
ZD,G
exp

−NH(p, q)
 (1)"
INTRODUCTION,0.012842465753424657,"where H(p, q) = −P"
INTRODUCTION,0.0136986301369863,"x p(x) log q(x) is the cross-entropy between the empirical probability distribu-
14"
INTRODUCTION,0.014554794520547944,"tion p(x) of the observed data D and the theoretical probability distribution q(x) of the model G and
15"
INTRODUCTION,0.015410958904109588,"ZD,G a data- and model-dependent factor ensuring proper normalization condition for ﬁnite dataset. In
16"
INTRODUCTION,0.016267123287671232,"short, Eq.1 results from the asymptotic probability that the N independent samples, x(1), · · · , x(N),
17"
INTRODUCTION,0.017123287671232876,"are drawn from the model distribution, q(x), i.e. LD|G ≡q(x(1), · · · , x(N)) = Q"
INTRODUCTION,0.01797945205479452,"i q(x(i)), rather
18"
INTRODUCTION,0.018835616438356163,"than the empirical distribution, p(x). This leads to, log LD|G = P"
INTRODUCTION,0.019691780821917807,"ilog q(x(i)), which converges
19"
INTRODUCTION,0.02054794520547945,towards N P
INTRODUCTION,0.021404109589041095,"x p(x) log q(x) = −N H(p, q) in the large sample size limit, N →∞, with
20"
INTRODUCTION,0.02226027397260274,"log ZD,G = O(log N).
21"
INTRODUCTION,0.023116438356164382,"The structural constraints of the model G translate into the factorization form of the theoretical
22"
INTRODUCTION,0.023972602739726026,"probability distribution, q(x) [2–6]. In particular, the probability distribution of Bayesian networks
23"
INTRODUCTION,0.02482876712328767,"(BN) factorizes in terms of conditional probabilities of each variable given its parents, as qBN(x) =
24
Q"
INTRODUCTION,0.025684931506849314,"i q(xi|paXi), where paXi denote the values of the parents of node Xi in G, PaXi. For Bayesian
25"
INTRODUCTION,0.026541095890410957,"networks, the factors of the model distribution, q(xi|paXi), can be directly estimated with the
26"
INTRODUCTION,0.0273972602739726,"empirical conditional probabilities of each node given its parents as, q(xi|paXi) ≡p(xi|paXi),
27"
INTRODUCTION,0.028253424657534245,"leading to the well known estimation of the likelihood function in terms of conditional entropies
28"
INTRODUCTION,0.02910958904109589,H(Xi|PaXi) = −P
INTRODUCTION,0.029965753424657533,"x p(xi, paXi) log p(xi|paXi),
29"
INTRODUCTION,0.030821917808219176,"LD|GBN =
1
ZD,GBN
exp

−N"
INTRODUCTION,0.031678082191780824,"vertices
X"
INTRODUCTION,0.032534246575342464,"Xi∈V
H(Xi|PaXi)

(2)"
INTRODUCTION,0.03339041095890411,"This paper concerns the experimental setting for which some variables of the underlying Bayesian
30"
INTRODUCTION,0.03424657534246575,"model are not observed. This frequently occurs in practice for many applications. We derive an
31"
INTRODUCTION,0.0351027397260274,"explicit likelihood function for the class of ancestral graphs, which include directed as well as
32"
INTRODUCTION,0.03595890410958904,"bidirected edges, arising from the presence of unobserved latent variables. Tian and Pearl 2002 [7]
33"
INTRODUCTION,0.036815068493150686,"showed that the probability distribution of such graphs factorizes into c-components including subsets
34"
INTRODUCTION,0.03767123287671233,"of variables connected through bidirected paths (i.e. containing only bidirected edges). Richardson
35"
INTRODUCTION,0.038527397260273974,"2009 [6] later proposed a reﬁned factorization of the model distribution of the broader class of acyclic
36"
INTRODUCTION,0.039383561643835614,"directed mixed graphs in terms of conditional probabilities over “head” and “tail” subsets of variables
37"
INTRODUCTION,0.04023972602739726,"within each ancestrally closed subsets of vertices. However, unlike with Bayesian networks, the
38"
INTRODUCTION,0.0410958904109589,"contributions of c-components or head-and-tail factors to the likelihood function cannot simply be
39"
INTRODUCTION,0.04195205479452055,"estimated in terms of empirical distribution p(x), as shown below. This leaves the likelihood function
40"
INTRODUCTION,0.04280821917808219,"of ancestral graphs difﬁcult to estimate from empirical data, in general, although iterative methods
41"
INTRODUCTION,0.04366438356164384,"have been developped when the data is normally distributed [8–13].
42"
INTRODUCTION,0.04452054794520548,"The present paper provides an explicit decomposition of the likelihood function of ancestral graphs
43"
INTRODUCTION,0.045376712328767124,"in terms of multivariate cross-information over relevant ‘ac-connected’ subsets of variables, Figs. 1.,
44"
INTRODUCTION,0.046232876712328765,"which do not rely on the head-and-tail factorization but coincide with the parametrizing sets [14]
45"
INTRODUCTION,0.04708904109589041,"derived from the head-and-tail factorization. It suggests a natural estimation of these revelant
46"
INTRODUCTION,0.04794520547945205,"contributions to the likelihood function in terms of empirical distribution p(x). This result extends
47"
INTRODUCTION,0.0488013698630137,"the likelihood expression of Bayesian Networks (Eq. 2) to include the effect of unobserved latent
48"
INTRODUCTION,0.04965753424657534,"variables and enables the implementation of a greedy search-and-score algorithm for ancestral graphs.
49"
INTRODUCTION,0.05051369863013699,"For computational efﬁciency, the proposed two-step algorithm relies on local information scores
50"
INTRODUCTION,0.05136986301369863,"limited to the close surrounding vertices of each node (step 1) and edge (step 2). This computational
51"
INTRODUCTION,0.052226027397260275,"strategy is shown to outperform state-of-the-art causal discovery methods on challenging benchmark
52"
INTRODUCTION,0.053082191780821915,"datasets.
53"
THEORETICAL RESULTS,0.05393835616438356,"2
Theoretical results
54"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.0547945205479452,"2.1
Multivariate cross-entropy and cross-information
55"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.05565068493150685,"The theoretical result of the paper (Theorem 1) is expressed in terms of multivariate cross-information
56"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.05650684931506849,"derived from multivariate cross-entropies through the Inclusion-Exclusion Principle. The same
57"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.05736301369863014,"expressions can be written between multivariate information and multivariate entropies by simply
58"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.05821917808219178,"substituting q({xi}) with p({xi}) in the equations below and will be used to estimate the likelihood
59"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.059075342465753425,"function of ancestral graphs (Proposition 3).
60"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.059931506849315065,"As recalled above, the cross-entropy between m variables, V = {X1, · · · , Xm}, is deﬁned as,
61"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.06078767123287671,"H(V ) = −
X"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.06164383561643835,"{xi}
p(x1, · · · , xm) log q(x1, · · · , xm)
(3)"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.0625,"62
where p({xi}) is the empirical joint probability distribution of the variables {Xi} and q({xi}) the
63"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.06335616438356165,"joint probability distribution of the model. Bayes formula, q({xi}, {yj}) = q({xi}|{yj}) q({yj}),
64"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.0642123287671233,"directly translates into the deﬁnition of conditional cross-entropy through the decomposition,
65"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.06506849315068493,"H({Xi}, {Yj}) = H({Xi}|{Yj}) + H({Yj})
(4)"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.06592465753424658,"Multivariate (cross) information, I(V ) ≡I(X1; · · · ; Xm), are deﬁned from multivariate (cross)
66"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.06678082191780822,"entropies through Inclusion-Exclusion formulas over all subsets of variables [15–18] as,
67"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.06763698630136987,"I(X)
=
H(X)
I(X; Y )
=
H(X) + H(Y ) −H(X, Y )
I(X; Y ; Z)
=
H(X) + H(Y ) + H(Z) −H(X, Y ) −H(X, Z) −H(Y, Z) +H(X, Y, Z)"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.0684931506849315,"I(V )
=
−
X"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.06934931506849315,"S⊆V
(−1)|S|H(S)
(5)"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.0702054794520548,"where the semicolon separators are needed to distinguish multipoint (cross) information from joint
68"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.07106164383561644,"variables as {X, Z} in I({X, Z}; Y ) = I(X; Y )+I(Z; Y )−I(X; Y ; Z). Below, implicit separators
69"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.07191780821917808,"between non-conditioning variables in multivariate (cross) information will always correspond to
70"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.07277397260273973,"semicolons, e.g. as in I(V ) in Eq. 5. Unlike multivariate (cross) entropies, which are always positive,
71"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.07363013698630137,"H(X1, · · · , Xk) ⩾0, multivariate (cross) information, I(X1; · · · ; Xk), can be positive or negative
72"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.07448630136986302,"for k ⩾3, while they remain always positive for k < 3, i.e. I(X; Y ) ⩾0 and I(X) ⩾0.
73"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.07534246575342465,"In turn, multivariate (cross) entropies can be expressed through the Principle of Inclusion-Exclusion
74"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.0761986301369863,"into the same expression form but in terms of multivariate (cross) information,
75"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.07705479452054795,"H(V )
=
−
X"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.0779109589041096,"S⊆V
(−1)|S|I(S),
(6)"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.07876712328767123,"Conditional multivariate (cross) information I(V |Z) are deﬁned similarly as multivariate (cross)
76"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.07962328767123288,"information I(V ) but in terms of conditional (cross) entropies as,
77"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.08047945205479452,"I(V |Z)
=
−
X"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.08133561643835617,"S⊆V
(−1)|S|H(S|Z)
(7)"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.0821917808219178,"Eqs. 5 & 7 lead to a decomposition rule relative to a variable Z, Eq. 8, which can be conditioned
78"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.08304794520547945,"on a set of joint variables, A = {A1, · · · , Am}, with implicit comma separators for conditioning
79"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.0839041095890411,"variables in Eq. 9,
80"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.08476027397260275,"I(V ) = I(V |Z) + I(V ; Z)
(8)
I(V |A) = I(V |Z, A) + I(V ; Z|A)
(9)
Alternatively, conditional (cross) information, such as I(X; Y |A), can be expressed in terms of
81"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.08561643835616438,"non-conditional (cross) entropies using Eq. 4,
82"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.08647260273972603,"I(X; Y |A) = H(X|A) + H(Y |A) −H(X, Y |A)
= H(X, A) + H(Y, A) −H(X, Y, A) −H(A)
(10)
which can in turn be expressed in terms of non-conditional (cross) information as,
83"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.08732876712328767,I(X; Y |A) = I(X; Y ) −· · · (−1)k X
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.08818493150684932,"i1<···<ik
I(X; Y ; Ai1; · · ·; Aik) + · · · (−1)mI(X; Y ; A1; · · ·; Am) ="
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.08904109589041095,"X,Y ∈S′
X"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.0898972602739726,"S′⊆S
(−1)|S′|I(S′),
(11)"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.09075342465753425,"where S = {X, Y } ∪A. This corresponds, up to an opposite sign, to all (cross) information terms
84"
MULTIVARIATE CROSS-ENTROPY AND CROSS-INFORMATION,0.0916095890410959,"including both X and Y in the expression of the multivariate (cross) entropy, H(X, Y, A), Eq. 6.
85"
GRAPHS AND CONNECTION CRITERIA,0.09246575342465753,"2.2
Graphs and connection criteria
86"
DIRECTED MIXED GRAPHS AND ANCESTRAL GRAPHS,0.09332191780821918,"2.2.1
Directed mixed graphs and ancestral graphs
87"
DIRECTED MIXED GRAPHS AND ANCESTRAL GRAPHS,0.09417808219178082,"Two vertices are said to be adjacent if there is an edge (of any type) between them, X∗∗Y , where
88"
DIRECTED MIXED GRAPHS AND ANCESTRAL GRAPHS,0.09503424657534247,"∗stands for any (head or tail) end mark. X and Y are said to be neighbors if X
Y , parent and
89"
DIRECTED MIXED GRAPHS AND ANCESTRAL GRAPHS,0.0958904109589041,"child if X →Y and spouses if X ←→Y in G.
90"
DIRECTED MIXED GRAPHS AND ANCESTRAL GRAPHS,0.09674657534246575,"A path in G is a sequence of distinct vertices V1, . . . , Vn consecutively adjacent in G, as,
91"
DIRECTED MIXED GRAPHS AND ANCESTRAL GRAPHS,0.0976027397260274,"V1∗∗V2∗∗· · · ∗∗Vn−1∗∗Vn. In particular, a collider path between V1 and Vn has the form
92"
DIRECTED MIXED GRAPHS AND ANCESTRAL GRAPHS,0.09845890410958905,"V1∗→V2 ←→· · · ←→Vn−1 ←∗Vn and a directed path corresponds to V1 →V2 →· · · →Vn.
93"
DIRECTED MIXED GRAPHS AND ANCESTRAL GRAPHS,0.09931506849315068,"X is called an ancestor of Y and Y a descendant of X if X = Y or there is a directed path from
94"
DIRECTED MIXED GRAPHS AND ANCESTRAL GRAPHS,0.10017123287671233,"X to Y , X →· · · →Y . AnG(Y ) denotes the set of ancestors of Y in G. By extension, for any
95"
DIRECTED MIXED GRAPHS AND ANCESTRAL GRAPHS,0.10102739726027397,"subset of vertices, C ⊆V , AnG(C) denotes the set of ancestors for all Y ∈C in G.
96"
DIRECTED MIXED GRAPHS AND ANCESTRAL GRAPHS,0.10188356164383562,"A directed mixed graph is a vertex-edge graph G = (V , E) that can contain two types of edges:
97"
DIRECTED MIXED GRAPHS AND ANCESTRAL GRAPHS,0.10273972602739725,"directed (→) and bidirected (←→) edges.
98"
DIRECTED MIXED GRAPHS AND ANCESTRAL GRAPHS,0.1035958904109589,"A directed cycle occurs in G when X ∈AnG(Y ) and X ←Y . An almost directed cycle occurs
99"
DIRECTED MIXED GRAPHS AND ANCESTRAL GRAPHS,0.10445205479452055,"when X ∈AnG(Y ) and X ←→Y .
100"
DIRECTED MIXED GRAPHS AND ANCESTRAL GRAPHS,0.1053082191780822,"Deﬁnition 1. An ancestral graph is a directed mixed graph:
101"
DIRECTED MIXED GRAPHS AND ANCESTRAL GRAPHS,0.10616438356164383,"i) without directed cycles;
102"
DIRECTED MIXED GRAPHS AND ANCESTRAL GRAPHS,0.10702054794520548,"ii) without almost directed cycles.
103"
DIRECTED MIXED GRAPHS AND ANCESTRAL GRAPHS,0.10787671232876712,"An ancestral graph is said to be maximal if every missing edge corresponds to a structural indepen-
104"
DIRECTED MIXED GRAPHS AND ANCESTRAL GRAPHS,0.10873287671232877,"dence. If an ancestral graph G is not maximal, there exists a unique maximal ancestral graph ¯G by
105"
DIRECTED MIXED GRAPHS AND ANCESTRAL GRAPHS,0.1095890410958904,"adding bidirected edges to G [8].
106"
AC-CONNECTING PATHS AND AC-CONNECTED SUBSETS,0.11044520547945205,"2.2.2
ac-connecting paths and ac-connected subsets
107"
AC-CONNECTING PATHS AND AC-CONNECTED SUBSETS,0.1113013698630137,"Let us now deﬁne ancestor collider connecting paths or ac-connecting paths, which entail simpler
108"
AC-CONNECTING PATHS AND AC-CONNECTED SUBSETS,0.11215753424657535,"path connecting criterion than the traditional m-connecting criterion, discussed in the Appendix A.
109"
AC-CONNECTING PATHS AND AC-CONNECTED SUBSETS,0.11301369863013698,"Yet, ac-connecting paths and ac-connected subsets will turn out to be directly relevant to character-
110"
AC-CONNECTING PATHS AND AC-CONNECTED SUBSETS,0.11386986301369863,"ize the likelihood decomposition and Markov equivalent classes of ancestral graphs.
111"
AC-CONNECTING PATHS AND AC-CONNECTED SUBSETS,0.11472602739726027,"Deﬁnition 2. [ac-connecting path] An ac-connecting path between X and Y given a subset of
112"
AC-CONNECTING PATHS AND AC-CONNECTED SUBSETS,0.11558219178082192,"variables C (possibly including X and Y ) is a collider path, X ∗→Z1 ←→· · · ←→ZK ←∗Y ,
113"
AC-CONNECTING PATHS AND AC-CONNECTED SUBSETS,0.11643835616438356,"with all Zi ∈AnG({X, Y } ∪C), that is, with Zi in C or connected to {X, Y } ∪C by an ancestor
114"
AC-CONNECTING PATHS AND AC-CONNECTED SUBSETS,0.1172945205479452,"path, i.e. Zi →· · · →T with T ∈{X, Y } ∪C.
115"
AC-CONNECTING PATHS AND AC-CONNECTED SUBSETS,0.11815068493150685,"Deﬁnition 3. [ac-connected subset] A subset C is said to be ac-connected if ∀X, Y ∈C, X and
116"
AC-CONNECTING PATHS AND AC-CONNECTED SUBSETS,0.1190068493150685,"Y are connected (through any type of edge) or there is an ac-connecting path between X and Y
117"
AC-CONNECTING PATHS AND AC-CONNECTED SUBSETS,0.11986301369863013,"given C.
118"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.12071917808219178,"2.3
Likelihood decomposition of ancestral graphs
119"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.12157534246575342,"Theorem 1. [likelihood of ancestral graphs] The cross-entropy H(p, q) and likelihood LD|G of an
120"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.12243150684931507,"ancestral graph G is decomposable in terms of multivariate cross-information, I(C), summed over
121"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1232876712328767,"all ac-connected subsets of variables, C (Deﬁnition 3),
122"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.12414383561643835,"H(p, q) = −"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.125,"ac−connected
X"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.12585616438356165,"C⊆V
(−1)|C|I(C)"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1267123287671233,"LD|G =
1
ZD,G
exp

N"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.12756849315068494,"ac−connected
X"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1284246575342466,"C⊆V
(−1)|C|I(C)
 (12)"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1292808219178082,"where N is the number of iid samples in the dataset D and ZD,G a data- and model-dependent
123"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.13013698630136986,"normalization constant.
124"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1309931506849315,"The proof of Theorem 1 is left to the Appendix B. It is based on a partition of the cross-entropy (Eq. 6)
125"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.13184931506849315,"into cross-information contributions from ac-connected and non-ac-connected subsets of variables,
126"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1327054794520548,"which do not rely on head-and-tail factorizations. Hu and Evans [14] proposed an equivalent result
127"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.13356164383561644,"(Proposition 3.3 in [14]) with a proof using head-and-tail decomposition to deﬁne parametrizing
128"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1344178082191781,"sets, which happen to coincide with the ac-connected sets deﬁned here (Deﬁnition 3). Theorem 1
129"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.13527397260273974,"characterizes in particular the Markov equivalence class of ancestral graphs [8, 19–24] as,
130"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.13613013698630136,"Corollary 2. Two ancestral graphs are Markov equivalent if and only if they have the same ac-
131"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.136986301369863,"connected subsets of vertices.
132"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.13784246575342465,"Note, in particular, that Eq. 12 holds for maximal ancestral graphs (MAG), for which all pairs of
133"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1386986301369863,"ac-connected variables are connected by an edge, and their Markov equivalent representatives, the
134"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.13955479452054795,"partial ancestral graphs (PAG) [8, 25–27].
135"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1404109589041096,"Proposition 3. The likelihood decomposition of ancestral graphs (Eq. 12, Theorem 1) can be
136"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.14126712328767124,"estimated by replacing the model distribution q by the empirical distribution p in the retained
137"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1421232876712329,"multivariate cross-information terms I(C) corresponding to all ac-connected subsets of variables, C.
138"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1429794520547945,"Hence, Proposition 3 amounts to estimating all relevant cross-information terms in the likelihood
139"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.14383561643835616,"function with the corresponding multivariate information terms computed from the available data,
140"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1446917808219178,"while assuming by construction that the model distribution obeys all local and global conditional inde-
141"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.14554794520547945,"pendences entailed by the ancestral graph. The corresponding factorization of the model distribution
142"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1464041095890411,"can be expressed in terms of empirical distribution, assuming positive distributions, see Appendix C.
143"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.14726027397260275,"Fig. 1 illustrates the cross-entropy decomposition for a few graphical models in terms of cross-
144"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1481164383561644,"information contributions from their ac-connected subsets of vertices. In particular, an unshielded
145"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.14897260273972604,"non-collider (e.g. X →Z →W, Fig. 1A), is less likely (i.e. higher cross-entropy) than an unshielded
146"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.14982876712328766,"collider or ‘v-structure’ (e.g. X →Z ←W, Fig. 1B), if the corresponding three-point information
147"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1506849315068493,"term is negative, I(X; Z; W) < 0, in agreement with earlier results [28, 29]. However, this early
148"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.15154109589041095,"approach, exploiting the sign and magnitude of three-point information to orient v-structures, does
149"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1523972602739726,"not include higher order terms involving multiple v-structures, which can lead to orientation conﬂicts
150"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.15325342465753425,"between unshielded triples, in practice. Resolving such orientation conﬂicts requires to include
151"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1541095890410959,"Xi
Xi
Xj
− Σ
Edges
I(   ;    )
=
Σ I(    )
Vertices X
Z
Y T"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.15496575342465754,"Xi
Xi
Xj
− Σ
Edges
I(   ;    )
=
Σ I(    )
Vertices X
Z
Y T X
Z"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1558219178082192,"Xi
Xi
Xj
− Σ
Edges
I(   ;    )
=
Σ I(    )
Vertices"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1566780821917808,"Xi
Xi
Xj
− Σ
Edges
I(   ;    )
=
Σ I(    )
Vertices Y T X
Y T Z Y T X
Z X
T
+ X
Z
Y T − − − Z
Y T X
Z T X
Z T Z
Y T Z
Y T Z
Y T"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.15753424657534246,"Xi
Xj
Xk
Xi
Xi
Xj
− Σ
Edges
I(   ;    )
=
Σ I(    )
Vertices"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1583904109589041,"Xi
Xi
Xj
− Σ
Edges
I(   ;    )
=
Σ I(    )
Vertices"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.15924657534246575,"Xi
Xi
Xj
− Σ
Edges
I(   ;    )
=
Σ I(    )
Vertices"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1601027397260274,"Xi
Xi
Xj
− Σ
Edges
I(   ;    )
=
Σ I(    )
Vertices"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.16095890410958905,"Xi
Xj
Xk
Xl"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1618150684931507,"Xi
Xi
Xj
− Σ
Edges
I(   ;    )
=
Σ I(    )
Vertices B C A"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.16267123287671234,"Xi
Xi
Xj
− Σ
Edges
I(   ;    )
=
Σ I(    )
Vertices G H I F E
− − W Z X W Z X T Y
Z
X T Y
Z
X T Y
Z
X T"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.16352739726027396,"Y
Z
X
+ + + T
X"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1643835616438356,"+ Σ I(   ;    ;    )
H(p,q)"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.16523972602739725,ac−connected
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1660958904109589,Triples + X Z W Y X Z W Y X Z W Y
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.16695205479452055,"I(   ;    ;    ;    )
4−uples"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1678082191780822,"ac−connected D X Z
Y W
+ + X Z
Y W − W X Z
Y Y
Z W
+ Z
Y W
X Z
Y X Y
Z W
X"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.16866438356164384,"Z
Y
Z
Y W W
X Y X Z W + ... Z
Y W − Σ X X Z
Y"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1695205479452055,"Figure 1: Cross-entropy decomposition of ancestral graphs. Examples of cross-entropy decomposition of
ancestral graphs (red edges, lhs) in terms of relevant multivariate cross-information contributions I(C) with
C ⊆V (red nodes, rhs). Simple graphs: (A) without unshielded colliders, (B) with a single or non-overlapping
unshielded colliders, (C) with overlapping unshielded colliders through three or more (conditionally) independent
parents or (D) through a two-(or more)-collider path. (E) Bayesian graph corresponding to the head-and-tail
factorization of the two-collider path in (D) estimated using the empirical distribution p(.), see Appendix C. (F)
Simple Bayesian graph not Markov equivalent to an ancestral graph (G) sharing the same edges and unshielded
collider [24]. Solid black edges correspond to direct connections or collider paths conﬁned to the corresponding
ac-connected subset C, while wiggly edges indicate collider paths extending beyond C yet indirectly connected
to C by an ancestor path, marked with dashed edges, see Deﬁnition 2. By contrast, graphs H and I illustrate the
fact that collider paths may not be unique nor conserved between two Markov equivalent graphs (i.e. sharing the
same cross-information terms) [24]."
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1703767123287671,"information contributions from higher-order ac-connected subgraphs, such as star-like ac-connected
152"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.17123287671232876,"subsets including three or more parents, Fig. 1C. Similarly, the cross-entropies of collider paths
153"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1720890410958904,"involving several colliders also include higher-order terms, as with the simple example of a two-
154"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.17294520547945205,"collider path, Fig. 1D. By contrast, the cross-entropy based on the head-and-tail factorization of the
155"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1738013698630137,"same two-collider path, i.e. q(x, z, y, w) = q(z, y|x, w)q(x)q(w) [6], is found to be equivalent to
156"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.17465753424657535,"the cross-entropy of a Bayesian graph without bidirected edge, Fig. 1E, when estimated with the
157"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.175513698630137,"empirical distribution p(.), see Appendix C. This observation illustrates the difﬁculty to estimate the
158"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.17636986301369864,"likelihood functions of ancestral graphs using head-and-tail factorization.
159"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.17722602739726026,"Further examples of graphical models, Figs. 1F-I, show the relative simplicity of the decomposition
160"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1780821917808219,"with only few (non-trivial) ac-connected contributing subsets C with |C| ⩾3, as compared to
161"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.17893835616438356,"the much larger number of non-ac-connected non-contributing subsets, that cancel each other by
162"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1797945205479452,"construction due to conditional independence constraints of the underlying model. Note, in particular,
163"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.18065068493150685,"that most contributing multivariate information I(C) only concern direct connections or collider
164"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1815068493150685,"paths within a single component subgraph induced by C (solid line edges in Fig. 1). However,
165"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.18236301369863014,"occasionally, collider paths extending beyond C into AnG(C) \ C (marked with wiggly edges) with
166"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1832191780821918,"corresponding ancestor path(s) (marked with dashed edges) do occur, as shown in Fig. 1G.
167"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1840753424657534,"In addition, the present information-theoretic decomposition of the likelihood of ancestral graphs
168"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.18493150684931506,"can readily distinguish their Markov equivalence classes according to Corollary 2. For instance, the
169"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1857876712328767,"ancestral graphs of Fig. 1F and Fig. 1G, despite sharing the same edges and the same unshielded
170"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.18664383561643835,"collider (X →Z ←T), turn out not to be Markov equivalent, as discussed in [24]. Indeed, their
171"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1875,"cross-entropy decompositions differ by two ac-connected contributing terms: a three-point cross
172"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.18835616438356165,"information I(X; Y ; T) with a collider path not conﬁned in C (i.e. X ⇝Z ↭T ←→Y and
173"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1892123287671233,"corresponding ancestor path Z 99K Y ) and a four-point information term I(X; Y ; Z; T) due to
174"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.19006849315068494,"the two-collider path (X →Z ←→T ←→Y ). More quantitatively, it shows that the graph of
175"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1909246575342466,"Fig. 1G with a two-collider path is more likely than the graph of Fig. 1F whenever I(X; Y ; T) −
176"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1917808219178082,"I(X; Y ; Z; T) = I(X; Y ; T|Z) = I(X; Y |Z) −I(X; Y |Z, T)<0. Finally, the Markov equivalent
177"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.19263698630136986,"graphs of Fig. 1H and Fig. 1I, also due to [24], illustrate the fact that the actual ancestor collider path
178"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1934931506849315,"between unconnected pairs does not need to be unique nor conserved between Markov equivalent
179"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.19434931506849315,"graphs (as long as their cross-entropies share the same multivariate cross-information decomposition).
180"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1952054794520548,"3
Efﬁcient search-and-score causal discovery using local information scores
181"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.19606164383561644,"The likelihood estimation of ancestral graphs (Theorem 1 and Proposition 3) enables the implemen-
182"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.1969178082191781,"tation of a search-and-score algorithm for this broad class of graphs, which has attracted a number
183"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.19777397260273974,"of contributions recently [11–13, 30–32]. Our speciﬁc objective is not to develop an exact method
184"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.19863013698630136,"limited to simple graphical models with a few nodes and small datasets but to implement an efﬁcient
185"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.199486301369863,"and reliable heuristic method applicable to more challenging graphical models and large datasets.
186"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.20034246575342465,"Indeed, search-and-score structure learning methods need to rely on heuristic rather than exhaustive
187"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2011986301369863,"search, in general, given that the number of ancestral graphs grows super-exponentially as the number
188"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.20205479452054795,"of vertices increases. This can be implemented for instance with a Monte Carlo algorithmic scheme
189"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2029109589041096,"with random restarts, which efﬁciently probes relevant graphical models. Here, we opt, instead, to
190"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.20376712328767124,"use the prediction of an efﬁcient hybrid causal discovery method, MIIC [29, 33, 34], as starting point
191"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2046232876712329,"for a subsequent search-and-score approach based on the proposed likelihood estimation of ancestral
192"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2054794520547945,"graphs (Eq. 12 and Proposition 3).
193"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.20633561643835616,"Moreover, while the likelihood decomposition of ancestral graphs may involve extended ac-connected
194"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2071917808219178,"subsets of variables, as illustrated in Fig. 1, we aim to implement a computationally efﬁcient search-
195"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.20804794520547945,"and-score causal discovery method based on approximate local scores limited to the close surrounding
196"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2089041095890411,"vertices of each node and edge. Yet, while MIIC only relies on unshielded triple scores, the novel
197"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.20976027397260275,"search-and-score extension, MIIC_search&score, uses also higher-order local information scores to
198"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2106164383561644,"compare alternative subgraphs, as detailed below.
199"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.21147260273972604,"The proposed method is shown to outperform MIIC and other state-of-the-art causal discovery
200"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.21232876712328766,"methods on challenging datasets including latent variables.
201"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2131849315068493,"3.1
MIIC, an hybrid causal discovery method based on unshielded triple scores
202"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.21404109589041095,"MIIC is an hybrid causal discovery method combining constraint-based and information-theoretic
203"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2148972602739726,"frameworks [29, 35]. Unlike traditional constraint-based methods [4, 5], MIIC does not directly
204"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.21575342465753425,"attempt to uncover conditional independences but, instead, iteratively substracts the most signiﬁcant
205"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2166095890410959,"three-point (conditional) information contributions of successive contributors, A1, A2, ..., An, from
206"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.21746575342465754,"the mutual information between each pair of variables, I(X; Y ), as,
207"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2183219178082192,"I(X; Y ) −I(X; Y ; A1) −I(X; Y ; A2|A1) −· · · −I(X; Y ; An|{Ai}n−1) = I(X; Y |{Ai}n)
(13)"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2191780821917808,"where I(X; Y ; Ak|{Ai}k−1) > 0 is the positive information contribution from Ak to I(X; Y )
208"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.22003424657534246,"[28, 36]. Conditional independence is eventually established when the residual conditional mutual
209"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2208904109589041,"information on the right hand side of Eq. 13, I(X; Y |{Ai}n), becomes smaller than a complexity
210"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.22174657534246575,"term, i.e. kX;Y |{Ai}(N) ⩾I(X; Y |{Ai}n) ⩾0, which dependents on the considered variables and
211"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2226027397260274,"sample size N.
212"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.22345890410958905,"This leads to an undirected skeleton, which MIIC then (partially) orients based on the sign and
213"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2243150684931507,"amplitude of the regularized conditional 3-point information terms [28, 29]. In particular, negative
214"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.22517123287671234,"conditional 3-point information terms, I(X; Y ; Z|{Ai})<0, correspond to the signature of causality
215"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.22602739726027396,"in observational data [28] and lead to the prediction of a v-structure, X →Z ←Y , if X and Y
216"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2268835616438356,"are not connected in the skeleton. By contrast, a positive conditional 3-point information term,
217"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.22773972602739725,"I(X; Y ; Z|{Ai})>0, implies the absence of a v-structure and suggests to propagate the orientation
218"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2285958904109589,"of a previously directed edge X →Z
Y as X →Z →Y .
219"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.22945205479452055,"In practice, MIIC’s strategy to circumvent spurious conditional independences signiﬁcantly improves
220"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2303082191780822,"recall, that is, the fraction of correctly recovered edges, compared to traditional constraint-based
221"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.23116438356164384,"methods [28, 29]. Yet, MIIC only relies on unshielded triple scores to reliably uncover signiﬁcant
222"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2320205479452055,"contributors and orient v-structures, as outlined above. MIIC has been recently improved to ensure
223"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2328767123287671,"the consistency of the separating set in terms of indirect paths in the ﬁnal skeleton or (partially)
224"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.23373287671232876,"oriented graphs [37, 34] and to improve the reliably of predicted orientations [33, 34].
225"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2345890410958904,"The predictions of this recent version of MIIC, which include three type of edges (directed, bidirected
226"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.23544520547945205,"and undirected), have been used as starting point for the subsequent local search-and-score method
227"
LIKELIHOOD DECOMPOSITION OF ANCESTRAL GRAPHS,0.2363013698630137,"implemented in the present paper.
228"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.23715753424657535,"3.2
New search-and-score method based on higher-order local information scores
229"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.238013698630137,"Starting from the structure predicted by MIIC, as detailed above, MIIC_search&score method
230"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.23886986301369864,"proceeds in two steps.
231"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.23972602739726026,"3.2.1
Step 1: Node scores for edge orientation priming and edge removal
232"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2405821917808219,"The ﬁrst step consists in minimizing a node score corresponding to the local normalized log likelihood
233"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.24143835616438356,"of each node w.r.t. its possible parents or spouses amongst the connected nodes predicted by MIIC.
234"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2422945205479452,"To this end, the node score assesses the conditional entropy of each node w.r.t. a selection of
235"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.24315068493150685,"parents, spouses or neighbors, Pa′
Xi ⊆PaXi∪SpXi∪NeXi, and a factorized Normalized Maximum
236"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2440068493150685,"Likelihood (fNML) regularization [28], see Appendix D for details,
237"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.24486301369863014,"Scoren(Xi) = H(Xi|Pa′
Xi) + 1 N qxi
X"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2457191780821918,"j
log C
rxi
nj
(14)"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2465753424657534,"where qxi corresponds to the combination of levels of Pa′
Xi, while rxi is the number of levels of Xi,
238"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.24743150684931506,"and nj the number of samples corresponding to a particular combination of levels j in each summand,
239"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2482876712328767,"with P
j nj = N, the total number of samples. log C
rxi
nj is the fNML regulatization cost summed
240"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.24914383561643835,"over all combinations of levels, qxi, [38, 39], see Appendix D.
241"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.25,"This ﬁrst algorithm is looped over each node, priming the orientations of their surrounding edges (as
242"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2508561643835616,"directed, bidirected or undirected), until convergence. Edges without orientation priming at either
243"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2517123287671233,"extremity are removed at the end of Step 1.
244"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2525684931506849,"3.2.2
Step 2: Edge orientation scores
245"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2534246575342466,"The second step consists in minimizing an edge orientation score corresponding to the local normal-
246"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2542808219178082,"ized log likelihood of each edge w.r.t. its nodes’ parents and spouses inferred in Step 1. To this end,
247"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2551369863013699,"the edge score assesses the conditional information and a fNML complexity cost with respect to the
248"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2559931506849315,"type of orientation, given three sets of parents and spouses of X and Y , i.e. Pa′
X\Y = PaX ∪SpX\Y ,
249"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2568493150684932,"Pa′
Y\X = PaY ∪SpY\X and Pa′
XY = Pa′
X\Y ∪Pa′
Y\X with their corresponding combinations of
250"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2577054794520548,"levels, qy\x, qx\y and qxy. These orientation scores, listed in Table 1, include symmetrized fNML com-
251"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2585616438356164,"plexity terms to enforce Markov equivalence, if X and Y share the same parents or spouses (excluding
252"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2594178082191781,"X and Y ), see Appendix D. Indeed, all three scores become equals if Pa′
Y\X = Pa′
X\Y = Pa′
XY
253"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2602739726027397,"implying also the same combinations of parent and spouse levels, qy\x = qx\y = qxy.
254"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2611301369863014,"This second algorithm is looped over each edge to compute an orientation score decrement, given the
255"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.261986301369863,"orientations of its surrounding edges. The orientation change corresponding to the largest orientation
256"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2628424657534247,"score decrement is then chosen at each iteration until convergence or until a limit cycle is reached
257"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2636986301369863,"and stopped at the lowest sum of local orientation scores.
258"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2645547945205479,Table 1: Local scores for the orientation of a single directed or bidirected edge.
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2654109589041096,"Edge
Information
Symmetrized fNML complexity (Markov equivalent)"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2662671232876712,"X →Y
−I(X; Y |Pa′
Y\X )
1
2N
 Pqx\yry
j
log Crx
nj −Pqx\y
j
log Crx
nj + Pqy\xrx
j
log C
ry
nj −Pqy\x
j
log C
ry
nj
"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2671232876712329,"X ←Y
−I(X; Y |Pa′
X\Y )
1
2N
 Pqx\yry
j
log Crx
nj −Pqx\y
j
log Crx
nj + Pqy\xrx
j
log C
ry
nj −Pqy\x
j
log C
ry
nj
"
NEW SEARCH-AND-SCORE METHOD BASED ON HIGHER-ORDER LOCAL INFORMATION SCORES,0.2679794520547945,"X ↔Y
−I(X; Y |Pa′
XY )
1
2N
 Pqxy ry
j
log Crx
nj −Pqxy
j
log Crx
nj + Pqyx rx
j
log C
ry
nj −Pqyx
j
log C
ry
nj
"
EXPERIMENTAL RESULTS,0.2688356164383562,"4
Experimental results
259"
EXPERIMENTAL RESULTS,0.2696917808219178,"We ﬁrst tested whether MIIC_search&score orientation scores (Table 1) effectively predicts bidirected
260"
EXPERIMENTAL RESULTS,0.2705479452054795,"orientations on three simple ancestral models, Fig. 3, when the end nodes do not share the same
261"
EXPERIMENTAL RESULTS,0.2714041095890411,"parents (Fig. 3, Model 1), share some parents (Fig. 3, Model 2) or when the bidirected edge is part of
262"
EXPERIMENTAL RESULTS,0.2722602739726027,"a longer than two-collider paths (Fig. 3, Model 3). The prediction of the edge orientation scores are
263"
EXPERIMENTAL RESULTS,0.2731164383561644,"summarized in Table 3, Appendix E, and show good predictions for large enough datasets.
264"
EXPERIMENTAL RESULTS,0.273972602739726,"Beyond these simple examples, focussing on the discovery of bidirected edges in small toy models
265"
EXPERIMENTAL RESULTS,0.2748287671232877,"of ancestral graphs, we also analyzed more challenging benchmarks from the bnlearn repository
266"
EXPERIMENTAL RESULTS,0.2756849315068493,"[40], Fig. 2. They concern ancestral graphs obtained by hiding up to 20% of variables in Bayesian
267"
EXPERIMENTAL RESULTS,0.276541095890411,"Networks of increasing complexity (number of nodes and parameters), such as Alarm (37 nodes, 46
268"
EXPERIMENTAL RESULTS,0.2773972602739726,"links, 509 parameters), Insurance (27 nodes, 52 links, 984 parameters), and Barley (48 nodes, 84
269"
EXPERIMENTAL RESULTS,0.2782534246575342,"links, 114,005 parameters). We then assessed causal discovery performance in terms of Precision,
270"
EXPERIMENTAL RESULTS,0.2791095890410959,"TP/(TP + FP), and Recall, TP/(TP + FN), relative to the theoretical PAGs, while counting as
271"
EXPERIMENTAL RESULTS,0.2799657534246575,"false positive (FP), all correctly predicted edges but without or with a different orientation as the
272"
EXPERIMENTAL RESULTS,0.2808219178082192,"directed or bidirected edges of the PAG.
273"
EXPERIMENTAL RESULTS,0.2816780821917808,"Fig. 2 compares MIIC_search&score performance to MIIC results used as starting point for
274"
EXPERIMENTAL RESULTS,0.2825342465753425,"MIIC_search&score and to FCI [41]. MIIC and MIIC_search&score settings were set as described
275"
EXPERIMENTAL RESULTS,0.2833904109589041,"in section 3 above. The open-source MIIC R package (v1.5.2, GPL-3.0 license) was obtained at
276"
EXPERIMENTAL RESULTS,0.2842465753424658,"https://github.com/miicTeam/miic_R_package. FCI from the python causal-learn package
277"
EXPERIMENTAL RESULTS,0.2851027397260274,"(v0.1.3.8, MIT license) [41] was obtained at https://github.com/py-why/causal-learn and
278"
EXPERIMENTAL RESULTS,0.285958904109589,"run with G2-conditional independence test and default parameter α = 0.05.
279"
EXPERIMENTAL RESULTS,0.2868150684931507,"Overall, MIIC_search&score is found to outperform MIIC in terms of edge precision with little to no
280"
EXPERIMENTAL RESULTS,0.2876712328767123,"decrease in edge recall, Fig. 2, demonstrating the beneﬁt of MIIC_search&score’s rationale to improve
281"
EXPERIMENTAL RESULTS,0.288527397260274,"MIIC predictions by extending MIIC information scores from unshielded triples to higher-order
282"
EXPERIMENTAL RESULTS,0.2893835616438356,"information contributions. These originate from ac-connected subsets including nodes with more than
283"
EXPERIMENTAL RESULTS,0.2902397260273973,"two parents or spouses, or ac-connected subsets including two-collider paths. MIIC_search&score is
284"
EXPERIMENTAL RESULTS,0.2910958904109589,"also found to outperform FCI on complex ancestral benchmark networks with many parameters, such
285"
EXPERIMENTAL RESULTS,0.2919520547945205,"as Barley (114,005 parameters), Fig. 2. However, FCI is found to reach similar or better precision
286"
EXPERIMENTAL RESULTS,0.2928082191780822,"scores on easier benchmarks with fewer parameters (i.e. Alarm and Insurance), although its recall
287"
EXPERIMENTAL RESULTS,0.2936643835616438,"remains usually lower than MIIC_search&score, especially at small sample size, as expected for a
288"
EXPERIMENTAL RESULTS,0.2945205479452055,"purely constraint-based causal discovery approach.
289"
EXPERIMENTAL RESULTS,0.2953767123287671,"Importantly, the benchmark PAGs used to score the causal discovery results with increasing propor-
290"
EXPERIMENTAL RESULTS,0.2962328767123288,"tions of latent variables, Fig. 2, include not only bidirected edges originating from hidden common
291"
EXPERIMENTAL RESULTS,0.2970890410958904,"causes but also additional directed or undirected edges arising, in particular, from indirect effects of
292"
EXPERIMENTAL RESULTS,0.2979452054794521,"Precision
Recall
Precision
Recall
Precision
Recall"
EXPERIMENTAL RESULTS,0.2988013698630137,"1,000
10,000
100
1,000
10,000
100
1,000
10,000
100
1,000
10,000
1,000
10,000
100
1,000
10,000 0 1 0 1 0 1"
EXPERIMENTAL RESULTS,0.2996575342465753,"ALARM  (509 parameters)
BARLEY  (114,005 parameters) 100"
EXPERIMENTAL RESULTS,0.300513698630137,Sample  Size  (N) 100 0 1
EXPERIMENTAL RESULTS,0.3013698630136986,"20 %  LV
10 %  LV
5 %  LV
0 %  LV"
EXPERIMENTAL RESULTS,0.3022260273972603,"INSURANCE  (1,008 parameters)"
EXPERIMENTAL RESULTS,0.3030821917808219,"Figure 2: Benchmark results on ancestral graphs of increasing complexity. Benchmark results on ancestral
graphs obtained by hiding 0%, 5%, 10% or 20% of variables in Bayesian Networks of increasing complexity
(see main text): Alarm (lhs), Insurance (middle), and Barley (rhs). MIIC_search&score results are compared
to MIIC results used as starting point for MIIC_search&score and FCI [41]. Causal discovery performance is
assessed in terms of Precision and Recall relative to the theoretical PAGs, while counting as false positive all
correctly predicted edges but without or with a different orientation as the directed or bidirected edges of the
PAG. Error bars (±σ): standard deviations."
EXPERIMENTAL RESULTS,0.3039383561643836,"hidden variables with observed parents. Irrespective of their orientations, all these additional edges
293"
EXPERIMENTAL RESULTS,0.3047945205479452,"originating from indirect effects of hidden variables generally correspond to weaker effects (i.e. lower
294"
EXPERIMENTAL RESULTS,0.3056506849315068,"mutual information of indirect effects due to the Data Processing Inequality) and are more difﬁcult to
295"
EXPERIMENTAL RESULTS,0.3065068493150685,"uncover than the edges of the original graphical model without hidden variables.
296"
LIMITATIONS,0.3073630136986301,"5
Limitations
297"
LIMITATIONS,0.3082191780821918,"The main limitation of the paper concerns the local scores used in the search-and-score algorithm,
298"
LIMITATIONS,0.3090753424657534,"which are limited to ac-connected subsets of vertices with a maximum of two-collider paths.
299"
LIMITATIONS,0.3099315068493151,"While this approach could be extended to higher-order information contributions including three-
300"
LIMITATIONS,0.3107876712328767,"or more collider paths, it allows for a simple two-step search-and-score scheme at the level of
301"
LIMITATIONS,0.3116438356164384,"individual nodes (step 1) and edges (step 2), as detailed in section 3. This already shows a signiﬁcant
302"
LIMITATIONS,0.3125,"improvement in causal discovery performance (i.e. combing good precision and good recall on
303"
LIMITATIONS,0.3133561643835616,"challenging benchmarks) as compared to existing state-of-the-art methods.
304"
REFERENCES,0.3142123287671233,"References
305"
REFERENCES,0.3150684931506849,"[1] D. Koller, N. Friedman, Probabilistic Graphical Models: Principles and Techniques (MIT Press, 2009).
306"
REFERENCES,0.3159246575342466,"[2] J. Pearl, A. Paz, Graphoids: A graph-based logic for reasoning about relevance relations, or when would x
307"
REFERENCES,0.3167808219178082,"tell you more about y if you already know z, Tech. rep., UCLA Computer Science Department (1985).
308"
REFERENCES,0.3176369863013699,"[3] J. Pearl, Probabilistic reasoning in intelligent systems (Morgan Kaufmann, San Mateo, CA, 1988).
309"
REFERENCES,0.3184931506849315,"[4] J. Pearl, Causality: models, reasoning and inference (Cambridge University Press, 2009), second edn.
310"
REFERENCES,0.3193493150684932,"[5] P. Spirtes, C. Glymour, R. Scheines, Causation, Prediction, and Search (MIT press, , 2000), second edn.
311"
REFERENCES,0.3202054794520548,"[6] T. S. Richardson, A factorization criterion for acyclic directed mixed graphs, Proceedings of the Twenty-
312"
REFERENCES,0.3210616438356164,"Fifth Conference on Uncertainty in Artiﬁcial Intelligence, UAI ’09 (AUAI Press, Arlington, VA, USA,
313"
REFERENCES,0.3219178082191781,"2009), p. 462–470.
314"
REFERENCES,0.3227739726027397,"[7] J. Tian, J. Pearl, A general identiﬁcation condition for causal effects, Proceedings of the National Confer-
315"
REFERENCES,0.3236301369863014,"ence on Artiﬁcial Intelligence (Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999,
316"
REFERENCES,0.324486301369863,"2002), pp. 567–573.
317"
REFERENCES,0.3253424657534247,"[8] T. Richardson, P. Spirtes, Ancestral graph markov models. Ann. Statist. 30, 962–1030 (2002).
318"
REFERENCES,0.3261986301369863,"[9] M. Drton, M. Eichler, T. S. Richardson, Computing maximum likelihood estimates in recursive linear
319"
REFERENCES,0.3270547945205479,"models with correlated errors. Journal of Machine Learning Research 10, 2329–2348 (2009).
320"
REFERENCES,0.3279109589041096,"[10] R. J. Evans, T. S. Richardson, Maximum likelihood ﬁtting of acyclic directed mixed graphs to binary
321"
REFERENCES,0.3287671232876712,"data, Proceedings of the 26th Conference on Uncertainty in Artiﬁcial Intelligence, UAI’10 (AUAI Press,
322"
REFERENCES,0.3296232876712329,"Corvallis, OR, USA, 2010).
323"
REFERENCES,0.3304794520547945,"[11] S. Triantaﬁllou, I. Tsamardinos, Score-based vs constraint-based causal learning in the presence of
324"
REFERENCES,0.3313356164383562,"confounders, CFA@UAI (2016).
325"
REFERENCES,0.3321917808219178,"[12] K. Rantanen, A. Hyttinen, M. Järvisalo, Maximal ancestral graph structure learning via exact search,
326"
REFERENCES,0.3330479452054795,"Proceedings of the Thirty-Seventh Conference on Uncertainty in Artiﬁcial Intelligence, C. de Campos,
327"
REFERENCES,0.3339041095890411,"M. H. Maathuis, eds. (PMLR, 2021), vol. 161 of Proceedings of Machine Learning Research, pp. 1237–
328"
REFERENCES,0.3347602739726027,"1247.
329"
REFERENCES,0.3356164383561644,"[13] T. Claassen, I. G. Bucur, Greedy equivalence search in the presence of latent confounders, Proceedings of
330"
REFERENCES,0.336472602739726,"the Thirty-Eighth Conference on Uncertainty in Artiﬁcial Intelligence, J. Cussens, K. Zhang, eds. (PMLR,
331"
REFERENCES,0.3373287671232877,"2022), vol. 180 of Proceedings of Machine Learning Research, pp. 443–452.
332"
REFERENCES,0.3381849315068493,"[14] Z. Hu, R. Evans, Faster algorithms for markov equivalence, Proceedings of the 36th Conference on Uncer-
333"
REFERENCES,0.339041095890411,"tainty in Artiﬁcial Intelligence (UAI), J. Peters, D. Sontag, eds. (PMLR, 2020), vol. 124 of Proceedings of
334"
REFERENCES,0.3398972602739726,"Machine Learning Research, pp. 739–748.
335"
REFERENCES,0.3407534246575342,"[15] W. J. McGill, Multivariate information transmission. Trans. of the IRE Professional Group on Information
336"
REFERENCES,0.3416095890410959,"Theory (TIT) 4, 93-111 (1954).
337"
REFERENCES,0.3424657534246575,"[16] H. K. Ting, On the amount of information. Theory Probab. Appl. 7, 439-447 (1962).
338"
REFERENCES,0.3433219178082192,"[17] T. S. Han, Multiple mutual informations and multiple interactions in frequency data. Information and
339"
REFERENCES,0.3441780821917808,"Control 46, 26-45 (1980).
340"
REFERENCES,0.3450342465753425,"[18] R. W. Yeung, A new outlook on shannon’s information measures. IEEE transactions on information theory
341"
REFERENCES,0.3458904109589041,"37, 466–474 (1991).
342"
REFERENCES,0.3467465753424658,"[19] P. Spirtes, T. Richardson, A polynomial time algorithm for determinint dag equivalence in the presence of
343"
REFERENCES,0.3476027397260274,"latent variables and selection bias, Proceedings of the 6th International Workshop on Artiﬁcial Intelligence
344"
REFERENCES,0.348458904109589,"and Statistics (1996).
345"
REFERENCES,0.3493150684931507,"[20] T. Richardson, Markov properties for acyclic directed mixed graphs. Scandinavian Journal of Statistics 30,
346"
REFERENCES,0.3501712328767123,"145-157 (2003).
347"
REFERENCES,0.351027397260274,"[21] R. A. Ali, T. S. Richardson, Markov equivalence classes for maximal ancestral graphs, Proceedings of the
348"
REFERENCES,0.3518835616438356,"Eighteenth Conference on Uncertainty in Artiﬁcial Intelligence, UAI’02 (Morgan Kaufmann Publishers
349"
REFERENCES,0.3527397260273973,"Inc., San Francisco, CA, USA, 2002), pp. 1–9.
350"
REFERENCES,0.3535958904109589,"[22] R. A. Ali, T. S. Richardson, P. Spirtes, J. Zhang, Towards characterizing markov equivalence classes for
351"
REFERENCES,0.3544520547945205,"directed acyclic graphs with latent variables, Proceedings of the Fifteenth Conference on Uncertainty in
352"
REFERENCES,0.3553082191780822,"Artiﬁcial Intelligence, UAI’05 (Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 2005).
353"
REFERENCES,0.3561643835616438,"[23] J. Tian, Generating markov equivalent maximal ancestral graphs by single edge replacement, Proceedings
354"
REFERENCES,0.3570205479452055,"of the Fifteenth Conference on Uncertainty in Artiﬁcial Intelligence, UAI’05 (Morgan Kaufmann Publishers
355"
REFERENCES,0.3578767123287671,"Inc., San Francisco, CA, USA, 2005).
356"
REFERENCES,0.3587328767123288,"[24] R. A. Ali, T. S. Richardson, P. Spirtes, Markov equivalence for ancestral graphs. Ann. Statist. 37, 2808–2837
357"
REFERENCES,0.3595890410958904,"(2009).
358"
REFERENCES,0.3604452054794521,"[25] T. Richardson, P. Spirtes, Scoring ancestral graph models, Tech. rep. (1999). Available as Technical Report
359"
REFERENCES,0.3613013698630137,"CMU-PHIL 98.
360"
REFERENCES,0.3621575342465753,"[26] J. Zhang, A characterization of markov equivalence classes for directed acyclic graphs with latent variables,
361"
REFERENCES,0.363013698630137,"Proceedings of the Seventeenth Conference on Uncertainty in Artiﬁcial Intelligence, UAI’07 (Morgan
362"
REFERENCES,0.3638698630136986,"Kaufmann Publishers Inc., San Francisco, CA, USA, 2007).
363"
REFERENCES,0.3647260273972603,"[27] J. Zhang, On the completeness of orientation rules for causal discovery in the presence of latent confounders
364"
REFERENCES,0.3655821917808219,"and selection bias. Artif. Intell. 172, 1873-1896 (2008).
365"
REFERENCES,0.3664383561643836,"[28] S. Affeldt, H. Isambert, Robust reconstruction of causal graphical models based on conditional 2-point and
366"
REFERENCES,0.3672945205479452,"3-point information, Proceedings of the Thirty-First Conference on Uncertainty in Artiﬁcial Intelligence,
367"
REFERENCES,0.3681506849315068,"UAI 2015, July 12-16, 2015, Amsterdam, The Netherlands (2015), pp. 42–51.
368"
REFERENCES,0.3690068493150685,"[29] L. Verny, N. Sella, S. Affeldt, P. P. Singh, H. Isambert, Learning causal networks with latent variables from
369"
REFERENCES,0.3698630136986301,"multivariate information in genomic data. PLoS Comput. Biol. 13, e1005662 (2017).
370"
REFERENCES,0.3707191780821918,"[30] B. Andrews, G. F. Cooper, T. S. Richardson, P. Spirtes, The m-connecting imset and factorization for admg
371"
REFERENCES,0.3715753424657534,"models, Preprint (2022). Arxiv 2207.08963.
372"
REFERENCES,0.3724315068493151,"[31] Z. Hu, R. J. Evans, Towards standard imsets for maximal ancestral graphs. Bernoulli 30 (2024).
373"
REFERENCES,0.3732876712328767,"[32] Z. Hu, R. Evans, A fast score-based search algorithm for maximal ancestral graphs using entropy, Preprint
374"
REFERENCES,0.3741438356164384,"(2024). Arxiv 2402.04777.
375"
REFERENCES,0.375,"[33] V. Cabeli, H. Li, M. da Câmara Ribeiro-Dantas, F. Simon, H. Isambert, Reliable causal discovery based on
376"
REFERENCES,0.3758561643835616,"mutual information supremum principle for ﬁnite datasets, WHY21, 35rd Conference on Neural Information
377"
REFERENCES,0.3767123287671233,"Processing Systems (NeurIPS, 2021).
378"
REFERENCES,0.3775684931506849,"[34] M. d. C. Ribeiro-Dantas, H. Li, V. Cabeli, L. Dupuis, F. Simon, L. Hettal, A.-S. Hamy, H. Isambert,
379"
REFERENCES,0.3784246575342466,"Learning interpretable causal networks from very large datasets, application to 400, 000 medical records of
380"
REFERENCES,0.3792808219178082,"breast cancer patients. iScience 27, 109736 (2024).
381"
REFERENCES,0.3801369863013699,"[35] V. Cabeli, L. Verny, N. Sella, G. Uguzzoni, M. Verny, H. Isambert, Learning clinical networks from medical
382"
REFERENCES,0.3809931506849315,"records based on information estimates in mixed-type data. PLoS Comput. Biol. 16, e1007866 (2020).
383"
REFERENCES,0.3818493150684932,"[36] S. Affeldt, L. Verny, H. Isambert, 3off2: A network reconstruction algorithm based on 2-point and 3-point
384"
REFERENCES,0.3827054794520548,"information statistics. BMC Bioinformatics 17 (2016).
385"
REFERENCES,0.3835616438356164,"[37] H. Li, V. Cabeli, N. Sella, H. Isambert, Constraint-based causal structure learning with consistent separating
386"
REFERENCES,0.3844178082191781,"sets. Advances in Neural Information Processing Systems (NeurIPS) 32 (2019).
387"
REFERENCES,0.3852739726027397,"[38] P. Kontkanen, P. Myllymäki, A linear-time algorithm for computing the multinomial stochastic complexity.
388"
REFERENCES,0.3861301369863014,"Inf. Process. Lett. 103, 227–233 (2007).
389"
REFERENCES,0.386986301369863,"[39] T. Roos, T. Silander, P. Kontkanen, P. Myllymäki, Bayesian network structure learning using factorized
390"
REFERENCES,0.3878424657534247,"nml universal models, Proc. 2008 Information Theory and Applications Workshop (ITA-2008) (IEEE Press,
391"
REFERENCES,0.3886986301369863,"2008).
392"
REFERENCES,0.3895547945205479,"[40] M. Scutari, Learning Bayesian Networks with the bnlearn R Package. J. Stat. Softw. 35, 1–22 (2010).
393"
REFERENCES,0.3904109589041096,"[41] Y. Zheng, B. Huang, W. Chen, J. Ramsey, M. Gong, R. Cai, S. Shimizu, P. Spirtes, K. Zhang, Causal-learn:
394"
REFERENCES,0.3912671232876712,"Causal discovery in python. Journal of Machine Learning Research 25, 1–8 (2024).
395"
REFERENCES,0.3921232876712329,"[42] Y. M. Shtarkov, Universal sequential coding of single messages. Problems of Information Transmission 23,
396"
REFERENCES,0.3929794520547945,"3–17 (1987).
397"
REFERENCES,0.3938356164383562,"[43] J. Rissanen, I. Tabus, Adv. Min. Descrip. Length Theory Appl. (MIT Press, 2005), pp. 245–264.
398"
REFERENCES,0.3946917808219178,"[44] W. Szpankowski, Average case analysis of algorithms on sequences (John Wiley & Sons, , 2001).
399"
REFERENCES,0.3955479452054795,"[45] P. Kontkanen, W. Buntine, P. Myllymäki, J. Rissanen, H. Tirri, Efﬁcient computation of stochastic
400"
REFERENCES,0.3964041095890411,"complexity. in: C. Bishop, B. Frey (Eds.) Proceedings of the Ninth International Conference on Artiﬁcial
401"
REFERENCES,0.3972602739726027,"Intelligence and Statistics, Society for Artiﬁcial Intelligence and Statistics 103, 233–238 (2003).
402"
REFERENCES,0.3981164383561644,"[46] P. Kontkanen, Computationally efﬁcient methods for mdl-optimal density estimation and data clustering,
403"
REFERENCES,0.398972602739726,"Ph.D. thesis (2009).
404"
REFERENCES,0.3998287671232877,"[47] D. M. Chickering, A Transformational Characterization of Equivalent Bayesian Network Structures, UAI
405"
REFERENCES,0.4006849315068493,"’95: Proceedings of the Eleventh Annual Conference on Uncertainty in Artiﬁcial Intelligence (Morgan
406"
REFERENCES,0.401541095890411,"Kaufmann, 1995), pp. 87–98.
407"
REFERENCES,0.4023972602739726,"[48] M. Kalisch, M. Mächler, D. Colombo, M. H. Maathuis, P. Bühlmann, Causal inference using graphical
408"
REFERENCES,0.4032534246575342,"models with the r package pcalg. J. Stat. Softw. 47, 1–26 (2012).
409"
REFERENCES,0.4041095890410959,"Appendix / supplemental material
410"
REFERENCES,0.4049657534246575,"A
Preliminaries: connection and separation criteria
411"
REFERENCES,0.4058219178082192,"A.1
m-connection vs m’-connection criteria
412"
REFERENCES,0.4066780821917808,"An ancestral graph can be interpreted as encoding a set of conditional indepencence relations by
413"
REFERENCES,0.4075342465753425,"a graphical criterion, called m-separation, based on the concept of m-connecting paths, which
414"
REFERENCES,0.4083904109589041,"generalizes the separation criteria of Markov and Bayesian networks to ancestral graphs.
415"
REFERENCES,0.4092465753424658,"Deﬁnition 4. [m-connecting path] A path π between X and Y is m-connecting given a (possibly
416"
REFERENCES,0.4101027397260274,"empty) subset C ⊆V (with X, Y /∈C) if:
417"
REFERENCES,0.410958904109589,"i) its non-collider(s) are not in C, and
418"
REFERENCES,0.4118150684931507,"ii) its collider(s) are in AnG(C).
419"
REFERENCES,0.4126712328767123,"Deﬁnition 5. [m-separation criterion] The subsets A and B are said to be m-separated by C, noted
420"
REFERENCES,0.413527397260274,"A⊥m B|C, if there is no m-connecting path between any vertex in A and any vertex in B given C.
421"
REFERENCES,0.4143835616438356,"The probabilistic interpretation of ancestral graph is given by its global and pairwise Markov properties
422"
REFERENCES,0.4152397260273973,"(which are equivalent [8]): if A and B are m-separated by C, then A and B are conditionally
423"
REFERENCES,0.4160958904109589,"independent given C and ∀X ∈A and ∀Y ∈B, there is a probability distribution P faithful
424"
REFERENCES,0.4169520547945205,"to G such that their conditional mutual information vanishes, i.e. IP (X; Y |C) = 0, also noted
425"
REFERENCES,0.4178082191780822,"X ⊥⊥P Y |C.
426"
REFERENCES,0.4186643835616438,"However, as discussed above, the proof of Theorem 1 will require to introduce a weaker m′-connection
427"
REFERENCES,0.4195205479452055,"criterion deﬁned below.
428"
REFERENCES,0.4203767123287671,"Deﬁnition 6. [m′-connecting path] A path π between X and Y is m′-connecting given a subset
429"
REFERENCES,0.4212328767123288,"C ⊆V (with X, Y possibly in C) if:
430"
REFERENCES,0.4220890410958904,"i) its non-collider(s) are not in C, and
431"
REFERENCES,0.4229452054794521,"ii) its collider(s) are in AnG({X, Y } ∪C).
432"
REFERENCES,0.4238013698630137,"Note, in particular, that an m-connecting path is necessary an m′-connecting path but that the
433"
REFERENCES,0.4246575342465753,"converse is not always true. For example, the path X →Z ←→T ←→Y in Fig. 1G (with Z →Y ) is
434"
REFERENCES,0.425513698630137,"an m′-connecting path given T (as Z ∈AnG({X, Y } ∪T)) but not an m-connecting path given T
435"
REFERENCES,0.4263698630136986,"(as Z /∈AnG(T)).
436"
REFERENCES,0.4272260273972603,"However, Richardson and Spirtes 2002 [8] have shown the following lemma,
437"
REFERENCES,0.4280821917808219,"Lemma 4. [Corollary 3.15 in [8]] In an ancestral graph G, there is a m′-connecting path µ between
438"
REFERENCES,0.4289383561643836,"X and Y given C if and only if there is a (possibly different) m-connecting path π between X and
439"
REFERENCES,0.4297945205479452,"Y given C.
440"
REFERENCES,0.4306506849315068,"Hence, Lemma 4 implies that m′-separation and m-separation criteria are in fact equivalent, as an
441"
REFERENCES,0.4315068493150685,"absence of m′-connecting paths implies an absence of m-connecting paths and vice versa. This
442"
REFERENCES,0.4323630136986301,"enables to reformulate the m-separation criterion above as,
443"
REFERENCES,0.4332191780821918,"Deﬁnition 7. [m′-separation (and m-separation) criteria] The subsets A and B are said to be m′-
444"
REFERENCES,0.4340753424657534,"separated (or m-separated) by C, if all paths from any X ∈A to any Y ∈B have either
445"
REFERENCES,0.4349315068493151,"i) a non-collider in C, or
446"
REFERENCES,0.4357876712328767,"ii) a collider not in AnG({X, Y } ∪C).
447"
REFERENCES,0.4366438356164384,"The probabilistic interpretation of an ancestral graph is given by its (global) Markov property: if A
448"
REFERENCES,0.4375,"and B are m-separated (or m′-separated) by C, then A and B are conditionally independent given
449"
REFERENCES,0.4383561643835616,"C, noted as, A ⊥m B|C.
450"
REFERENCES,0.4392123287671233,"A.2
ac-connecting paths and ac-connected subsets
451"
REFERENCES,0.4400684931506849,"Let us now recall the deﬁnition of ancestor collider connecting paths or ac-connecting paths,
452"
REFERENCES,0.4409246575342466,"which is directly relevant to characterize the likelihood decomposition and Markov equivalent classes
453"
REFERENCES,0.4417808219178082,"of ancestral graphs (Theorem 1). We give here a different yet equivalent deﬁnition of ac-connecting
454"
REFERENCES,0.4426369863013699,"paths as deﬁned in the main text (Deﬁnition 2) in order to underline the similarities and differencies
455"
REFERENCES,0.4434931506849315,"with the notion of m′-connecting path (Deﬁnition 6).
456"
REFERENCES,0.4443493150684932,"Deﬁnition 8. [ac-connecting path] A path π between X and Y is an ac-connecting path given a
457"
REFERENCES,0.4452054794520548,"subset C ⊆V (with X and Y possibly in C) if:
458"
REFERENCES,0.4460616438356164,"i) π does not have any noncollider, and
459"
REFERENCES,0.4469178082191781,"ii) its collider(s) are in AnG({X, Y } ∪C).
460"
REFERENCES,0.4477739726027397,"Hence, more simply (following Deﬁnition 2 in the main text), an ac-connecting path given C is a
461"
REFERENCES,0.4486301369863014,"collider path, X ∗→Z1 ↔· · · ↔ZK ←∗Y , with all Zi ∈AnG({X, Y } ∪C), i.e. with Zi in C or
462"
REFERENCES,0.449486301369863,"connected to {X, Y } ∪C by an ancestor path, Zi →· · · →T with T ∈{X, Y } ∪C.
463"
REFERENCES,0.4503424657534247,"Deﬁnition 9. [ac-separation criterion] The subsets A and B are said to be ac-separated by C if there
464"
REFERENCES,0.4511986301369863,"is no ac-connecting path between any vertex in A and any vertex in B given C.
465"
REFERENCES,0.4520547945205479,"Previous deﬁnitions and Lemma 4 readily lead to the following corollary between the different
466"
REFERENCES,0.4529109589041096,"connection and separation criteria:
467"
REFERENCES,0.4537671232876712,"Corollary 5.
468"
REFERENCES,0.4546232876712329,"i)
m-connecting path π =⇒m′-connecting path π
469"
REFERENCES,0.4554794520547945,"ii) ac-connecting path π =⇒m′-connecting path π
470"
REFERENCES,0.4563356164383562,"iii)
m-separation ⇐⇒m′-separation
471"
REFERENCES,0.4571917808219178,"iv)
m/m′-separation =⇒ac-separation
472"
REFERENCES,0.4580479452054795,"Finally, we recall the notion of ac-connected subset (Deﬁnition 3 in the main text), which is central
473"
REFERENCES,0.4589041095890411,"for the decomposition of the likelihood of ancestral graphs (Theorem 1): A subset C is said to be
474"
REFERENCES,0.4597602739726027,"ac-connected if ∀X, Y ∈C, there is an ac-connecting path between X and Y w.r.t. C.
475"
REFERENCES,0.4606164383561644,"B
Proof of Theorem 1.
476"
REFERENCES,0.461472602739726,"In order to prove that the likelihood function of an ancestral graph, Eq. 12, contains all and only the
477"
REFERENCES,0.4623287671232877,"ac-connected subsets of vertices in G (Deﬁnition 3), we will ﬁrst show (i) that all non-ac-connected
478"
REFERENCES,0.4631849315068493,"subsets S′ are included in a cancelling combination of multivariate information terms I(X; Y |A) = 0,
479"
REFERENCES,0.464041095890411,"with X, Y ∈S′ and S′ ⊆S = {X, Y } ∪A. Conversely, we will then show (ii) that cancelling
480"
REFERENCES,0.4648972602739726,"combinations of multivariate information terms associated to pairwise conditional independence,
481"
REFERENCES,0.4657534246575342,"I(X; Y |A) = PX,Y ∈S′"
REFERENCES,0.4666095890410959,"S′⊆S
(−1)|S′|I(S′) = 0 do not contain any ac-connected subset S′. Finally, we
482"
REFERENCES,0.4674657534246575,"will prove (iii) that the information terms which appear in multiple cancelling combinations from
483"
REFERENCES,0.4683219178082192,"different pairwise independence constraints do not modify the multivariate information decomposition
484"
REFERENCES,0.4691780821917808,"of the likelihood function of ancestral graphs, Eq. 12, as these shared/overlapping terms in fact all
485"
REFERENCES,0.4700342465753425,"cancel through more global Markov independence relationships involving higher order (three or more
486"
REFERENCES,0.4708904109589041,"points) vanishing multivariate information terms, such as I(X; Y ; Z|A) = 0.
487"
REFERENCES,0.4717465753424658,"i) Let’s ﬁrst prove that all non-ac-connected subsets S′ are included in at least one cancelling
488"
REFERENCES,0.4726027397260274,"combination of multivariate information terms, I(X; Y |A) = 0, with X, Y ∈S′ and S′ ⊆{X, Y}∪A.
489"
REFERENCES,0.473458904109589,"If S′ is a non-ac-connected subset, there is at least one disconnected pair X and Y for which each
490"
REFERENCES,0.4743150684931507,"path πj between X and Y contains either some collider(s) not in AnG(S′) or, if all colliders along
491"
REFERENCES,0.4751712328767123,"πj are in AnG(S′), there must be some non-collider(s) at node(s) Zj but not necessarily in S′. Let’s
492"
REFERENCES,0.476027397260274,"deﬁne S = S′ ∪j Zj. X and Y can be shown to be m-separated given S \ {X, Y }, as for each
493"
REFERENCES,0.4768835616438356,"path πj between X and Y , its non-collider(s) are in S at node(s) Zj (when all collider(s) along πj
494"
REFERENCES,0.4777397260273973,"are in S′) or there is some collider(s) not in AnG(S′), which are not in AnG(S′) either. The latter
495"
REFERENCES,0.4785958904109589,"statement is proven by contradiction assuming that there is a collider at Z /∈AnG(S′) such that
496"
REFERENCES,0.4794520547945205,"Z ∈AnG(S). There is therefore a directed path Z →· · · →W with W ∈S. Hence, W ∈S′ or
497"
REFERENCES,0.4803082191780822,"there is a noncollider at W ∈Zj which is on a path πj between X and Y along which all colliders
498"
REFERENCES,0.4811643835616438,"are in AnG(S′) by construction of S. This leads by induction to Z →· · · →W →· · · →T where
499"
REFERENCES,0.4820205479452055,"T ∈S′ and thus Z ∈AnG(S′), which is a contradiction. Hence, all non-ac-connected subsets S′
500"
REFERENCES,0.4828767123287671,"are included in a cancelling combination of multivariate information terms I(X; Y |A) = 0, with
501"
REFERENCES,0.4837328767123288,"X, Y ∈S′ and S′ ⊆S = {X, Y } ∪A.
502"
REFERENCES,0.4845890410958904,"ii) Conversely, we will now show that cancelling combinations of multivariate information terms
503"
REFERENCES,0.4854452054794521,"associated to pairwise conditional independence, I(X; Y |A) = PX,Y ∈S′"
REFERENCES,0.4863013698630137,"S′⊆S
(−1)|S′|I(S′) = 0, do
504"
REFERENCES,0.4871575342465753,"not contain any ac-connected subset S′.
505"
REFERENCES,0.488013698630137,"We will prove it by contradiction assuming that there exists a subset W ⊆A, such that S′ =
506"
REFERENCES,0.4888698630136986,"{X, Y } ∪W is ac-connected. In particular, there should be an ac-connecting path between X and Y
507"
REFERENCES,0.4897260273972603,"conﬁned to AnG(S′) and thus to AnG(S) ⊇AnG(S′), which is an m′-connecting path between X
508"
REFERENCES,0.4905821917808219,"and Y given A, contradicting the above hypothesis of m′-separation given A, i.e. I(X; Y |A) = 0.
509"
REFERENCES,0.4914383561643836,"The use of m′-separation, i.e. the absence of m′-connecting paths with colliders in AnG(S) rather
510"
REFERENCES,0.4922945205479452,"than m-connecting paths with colliders in AnG(A), is necessary here, see Deﬁnitions 4 and 6. Hence,
511"
REFERENCES,0.4931506849315068,"no ac-connected subset S′ is included in cancelling combinations of multivariate information terms
512"
REFERENCES,0.4940068493150685,"associated to pairwise conditional independence, I(X; Y |A) = PX,Y ∈S′"
REFERENCES,0.4948630136986301,"S′⊆S
(−1)|S′|I(S′) = 0.
513"
REFERENCES,0.4957191780821918,"iii) Finally, we will show that the information terms which appear in multiple cancelling combina-
514"
REFERENCES,0.4965753424657534,"tions from different pairwise independence constraints do not modify the multivariate information
515"
REFERENCES,0.4974315068493151,"decomposition of the likelihood function of ancestral graphs, Eq. 12, as these shared/overlapping
516"
REFERENCES,0.4982876712328767,"terms in fact all cancel through more global Markov independence relationships involving higher
517"
REFERENCES,0.4991438356164384,"order (three or more points) vanishing multivariate information terms, such as I(X; Y ; Z|A) = 0.
518"
REFERENCES,0.5,"This result requires to use an ordering of the nodes, Xk ≻Xj ≻Xi, that is compatible with the
519"
REFERENCES,0.5008561643835616,"directed edges of the ancestral graph assumed to have no undirected edges, i.e. Xj /∈An(Xi) if
520"
REFERENCES,0.5017123287671232,"Xj ≻Xi. Under this ordering, higher order nodes Xk ≻Xi ≻Xj can be a priori excluded from all
521"
REFERENCES,0.502568493150685,"separating sets Aij of pairs of lower order nodes, i.e. if I(Xi; Xj|Aij) = 0 then Xk /∈Aij.
522"
REFERENCES,0.5034246575342466,"In particular, the two pairwise conditional independence relations I(Xk; Xℓ|Akℓ) = 0, with Xℓ≻
523"
REFERENCES,0.5042808219178082,"Xk, and I(Xi; Xj|Aij) = 0, with Xj ≻Xi, do not share any multivariate information terms, if
524"
REFERENCES,0.5051369863013698,"Xℓ̸= Xj. Indeed, as I(Xk; Xℓ|Akℓ) contains all information terms including both Xk and Xℓas
525"
REFERENCES,0.5059931506849316,"well as every subset (possibly empty) of Akℓ, none of them includes Xj if Xℓ≻Xj. Therefore
526"
REFERENCES,0.5068493150684932,"I(Xk; Xℓ|Akℓ) does not contain any information term of I(Xi; Xj|Aij) which contains both Xi and
527"
REFERENCES,0.5077054794520548,"Xj as well as every subset (possibly empty) of Aij. This property eliminates all multiple counting of
528"
REFERENCES,0.5085616438356164,"multivariate informations terms shared if Xℓ̸= Xj. Note that this result does not hold in general for
529"
REFERENCES,0.509417808219178,"ancestral graphs including undirected edges.
530"
REFERENCES,0.5102739726027398,"Hence, the issue of redundant multivariate information terms in the likelihood decomposition, Eq. 12,
531"
REFERENCES,0.5111301369863014,"is related to the conditional independences of two or more pairs, {Xi, Xr}, {Xj, Xr}, ..., {Xℓ, Xr},
532"
REFERENCES,0.511986301369863,"sharing the same higher order node, Xr. However, this situation also entails a more global Markov
533"
REFERENCES,0.5128424657534246,"independence constraint between Xr and {Xi, Xj, · · · , Xℓ}, given a separating set A, which can be
534"
REFERENCES,0.5136986301369864,"decomposed into more local independence constraints using the chain rule and the decomposition
535"
REFERENCES,0.514554794520548,"rules of multivariate information (Eq. 9),
536"
REFERENCES,0.5154109589041096,"0
=
I({Xi, Xj, · · · , Xℓ}; Xr|A)"
REFERENCES,0.5162671232876712,"=
 
I(Xi; Xr|A) + I(Xj; Xr|A, Xi)

+

I(Xk; Xr|A, Xi, Xj)

+ · · · + I(Xℓ; Xr|A, · · · )"
REFERENCES,0.5171232876712328,"=
 
I(Xi; Xr|A) + I(Xj; Xr|A) −I(Xi; Xj; Xr|A)
"
REFERENCES,0.5179794520547946,"+

I(Xk; Xr|A, Xi) −I(Xj; Xk; Xr|A, Xi)

+ · · · + I(Xℓ; Xr|A, · · · )"
REFERENCES,0.5188356164383562,"=
 
I(Xi; Xr|A) + I(Xj; Xr|A) −I(Xi; Xj; Xr|A)
"
REFERENCES,0.5196917808219178,"+

I(Xk; Xr|A) −I(Xj; Xk; Xr|A) −I(Xi; Xk; Xr|A) + I(Xi; Xj; Xk; Xr|A)

+ · · ·"
REFERENCES,0.5205479452054794,"where all the conditional multivariate information terms vanish by induction due to the non-
537"
REFERENCES,0.521404109589041,"negativity of (conditional) mutual information.
In particular, the conditional multivariate in-
538"
REFERENCES,0.5222602739726028,"formation terms in the last expression, i.e. between Xr and each subset of {Xi, Xj, · · · , Xℓ}
539"
REFERENCES,0.5231164383561644,"given the separating set A, all vanish.
This result can be readily extended to any subsets
540"
REFERENCES,0.523972602739726,"{Xr, Xs, · · · , Xz} (conditionally) independent of {Xi, Xj, · · · , Xℓ} given a separating set A,
541"
REFERENCES,0.5248287671232876,"i.e. I({Xi, Xj, · · · , Xℓ}; {Xr, Xs, · · · , Xz}|A) = 0. Hence, as the ﬁnal conditional multivari-
542"
REFERENCES,0.5256849315068494,"ate cross information terms of the decomposition all vanish while not sharing any subsets of variables,
543"
REFERENCES,0.526541095890411,"it proves the absence of redundancy and a global cancellation of non-ac-connected subsets (from
544"
REFERENCES,0.5273972602739726,"pairwise and higher order conditional independence relations) in the likelihood function of ancestral
545"
REFERENCES,0.5282534246575342,"graphs without undirected edges, Eq. 12.
546"
REFERENCES,0.5291095890410958,"Hence, only ac-connected subsets effectively contribute to the cross-entropy of an ancestral graph
547"
REFERENCES,0.5299657534246576,"with only directed and bidirected edges, Eq. 12.
□
548"
REFERENCES,0.5308219178082192,"C
Factorization of the probability distribution of ancestral graphs
549"
REFERENCES,0.5316780821917808,"C.1
Factorization resulting from Theorem 1 and Proposition 3
550"
REFERENCES,0.5325342465753424,"Before presenting the factorization of the model distribution of ancestral graphs resulting from
551"
REFERENCES,0.5333904109589042,"Theorem 1 and Proposition 3, it is instructive to obtain an equivalent factorization for Bayesian
552"
REFERENCES,0.5342465753424658,"graphs, assuming a positive empirical distributions, p(x1, · · · , xm) = Qm
i=1 p(xi|xi−1, · · · , x1) > 0,
553"
REFERENCES,0.5351027397260274,"q(x1, · · · , xm)
= m
Y"
REFERENCES,0.535958904109589,"i=1
q(xi|paxi) = m
Y"
REFERENCES,0.5368150684931506,"i=1
p(xi|paxi)"
REFERENCES,0.5376712328767124,"=
p(x1, · · · , xm) m
Y i=1"
REFERENCES,0.538527397260274,"p(xi|paxi)
p(xi|xi−1, · · · , x1)"
REFERENCES,0.5393835616438356,"=
p(x1, · · · , xm) m
Y i=1"
REFERENCES,0.5402397260273972,p(xi|paxi)p(xi−1\paxi|paxi)
REFERENCES,0.541095890410959,"p(xi, xi−1\paxi|paxi)
(15)"
REFERENCES,0.5419520547945206,"This leads to the following alternative expressions for the cross-entropy H(p, q)
=
554 −P"
REFERENCES,0.5428082191780822,"x p(x) log q(x) in terms of multivariate entropy and information, which only depend on the
555"
REFERENCES,0.5436643835616438,"empirical joint distribution p(x),
556"
REFERENCES,0.5445205479452054,"H(p, q)
= m
X"
REFERENCES,0.5453767123287672,"i=1
H(xi|PaXi)"
REFERENCES,0.5462328767123288,"=
H(X1, · · · , Xm) + m
X"
REFERENCES,0.5470890410958904,"i=1
I(Xi; Xi−1\PaXi|PaXi)
(16)"
REFERENCES,0.547945205479452,"where Pm
i=1 I(Xi; Xi−1\PaXi|PaXi) can be decomposed, using the chain rule and Eq. 11, into
557"
REFERENCES,0.5488013698630136,"unconditional multivariate information terms, which exactly cancel all the multivariate information
558"
REFERENCES,0.5496575342465754,"of the non-ac-connected subsets of variables in the multivariate entropy decomposition, Eq. 6.
559"
REFERENCES,0.550513698630137,"Note, however, that this result obtained for Bayesian networks requires an explicit factorization of the
560"
REFERENCES,0.5513698630136986,"global model distribution, q(x), in terms of the empirical distribution, p(x), which is not known and
561"
REFERENCES,0.5522260273972602,"presumably does not exist, in general, for ancestral graphs.
562"
REFERENCES,0.553082191780822,"Alternatively, assuming that the empirical and model distributions are positive (∀x, p(x) > 0,
563"
REFERENCES,0.5539383561643836,"q(x) > 0), it is always possible to factorize them into factors associated to each (cross) information
564"
REFERENCES,0.5547945205479452,"term in the (cross) entropy decomposition, Eq. 6, as,
565"
REFERENCES,0.5556506849315068,"q(x)
= m
Y"
REFERENCES,0.5565068493150684,"i=1
q(xi) × m
Y i<j"
REFERENCES,0.5573630136986302,"q(xi, xj)
q(xi)q(xj) × m
Y i<j<k"
REFERENCES,0.5582191780821918,"q(xi, xj, xk)q(xi)q(xj)q(xk)"
REFERENCES,0.5590753424657534,"q(xi, xj)q(xi, xk)q(xj, xk) × · · ·
(17)"
REFERENCES,0.559931506849315,"where all the marginal distributions over a subset of variables, e.g. q(xi, xj, xk) = P"
REFERENCES,0.5607876712328768,"ℓ̸=i,j,k q(x) or
566"
REFERENCES,0.5616438356164384,"p(xi, xj, xk) = P"
REFERENCES,0.5625,"ℓ̸=i,j,k p(x), cancel two-by-two by construction.
567"
REFERENCES,0.5633561643835616,"This can be illustrated on a simple example of a two-collider path including one bidirected edge,
568"
REFERENCES,0.5642123287671232,"X →Z ←→Y ←W (Fig. 1D), valid for q(.) and p(.) alike,
569"
REFERENCES,0.565068493150685,"q(x, z, y, w) = q(x) q(z) q(y) q(w)"
REFERENCES,0.5659246575342466,"×
q(x, z)
q(x) q(z)
q(z, y)
q(z) q(y)
q(y, w)
q(y) q(w)"
REFERENCES,0.5667808219178082,"q(x, y)
q(x) q(y)
q(x, w)
q(x) q(w)
q(z, w)
q(z) q(w)"
REFERENCES,0.5676369863013698,"× q(x) q(z) q(y) q(x, z, y)"
REFERENCES,0.5684931506849316,"q(x, z) q(x, y) q(z, y)
q(z) q(y) q(w) q(z, y, w)"
REFERENCES,0.5693493150684932,"q(z, y) q(z, w) q(y, w)"
REFERENCES,0.5702054794520548,"× q(x) q(z) q(w) q(x, z, w)"
REFERENCES,0.5710616438356164,"q(x, z) q(x, w) q(z, w)
q(x) q(y) q(w) q(x, y, w)"
REFERENCES,0.571917808219178,"q(x, y) q(x, w) q(y, w)"
REFERENCES,0.5727739726027398,"×
q(x, z) q(z, y) q(y, w) q(x, y) q(x, w) q(z, w) q(x, z, y, w)
q(x, z, y) q(x, z, w) q(x, y, w) q(z, y, w) q(x) q(y) q(z) q(w)
(18)"
REFERENCES,0.5736301369863014,"where all individual distribution marginals on subsets of variables, e.g. q(x), q(x, z), q(x, z, y) (or
570"
REFERENCES,0.574486301369863,"p(x), p(x, z), p(x, z, y)), cancel two-by-two by construction, except q(x, z, y, w) (or p(x, z, y, w)).
571"
REFERENCES,0.5753424657534246,"In addition and only for the model distribution q(.), all ratios in gray in Eq. 18 also cancel due to
572"
REFERENCES,0.5761986301369864,"Markov independence relations across non-ac-connected subsets (see proof of Theorem 1). This
573"
REFERENCES,0.577054794520548,"leaves a truncated factorization retaining all and only the ac-connected subsets of variables in the
574"
REFERENCES,0.5779109589041096,"graph, which we propose to estimate on empirical data by substituting the remaining q(.) terms by
575"
REFERENCES,0.5787671232876712,"their empirical counterparts p(.), see Proposition 3.
576"
REFERENCES,0.5796232876712328,"This leads to the following global factorization for q(.) in terms of p(.),
577"
REFERENCES,0.5804794520547946,"q(x, z, y, w) ≡p(x) p(z) p(y) p(w)
p(x, z)
p(x) p(z)
p(z, y)
p(z) p(y)
p(y, w)
p(y) p(w)"
REFERENCES,0.5813356164383562,"× p(x) p(z) p(y) p(x, z, y)"
REFERENCES,0.5821917808219178,"p(x, z) p(x, y) p(z, y)
p(z) p(y) p(w) p(z, y, w)"
REFERENCES,0.5830479452054794,"p(z, y) p(z, w) p(y, w)"
REFERENCES,0.583904109589041,"×
p(x, z) p(z, y) p(y, w) p(x, y) p(x, w) p(z, w) p(x, z, y, w)
p(x, z, y) p(x, z, w) p(x, y, w) p(z, y, w) p(x) p(y) p(z) p(w)"
REFERENCES,0.5847602739726028,"= p(x, z, y, w) p(x) p(y)"
REFERENCES,0.5856164383561644,"p(x, y)
p(x) p(w)"
REFERENCES,0.586472602739726,"p(x, w)
p(z) p(w)"
REFERENCES,0.5873287671232876,"p(z, w)"
REFERENCES,0.5881849315068494,"×
p(x, z) p(x, w) p(z, w)
p(x) p(z) p(w) p(x, z, w)
p(x, y) p(x, w) p(y, w)
p(x) p(y) p(w) p(x, y, w)
(19)"
REFERENCES,0.589041095890411,"where the terms in gray have been passed to the lhs of Eq. 18 applied to p(.). This ultimately
578"
REFERENCES,0.5898972602739726,"leads to the analog of the Bayesian Network factorization in Eq. 15 but for the two-collider path,
579"
REFERENCES,0.5907534246575342,"X →Z ←→Y ←W (Fig. 1D),
580"
REFERENCES,0.5916095890410958,"q(x, z, y, w) ≡p(x, z, y, w) p(x) p(w)"
REFERENCES,0.5924657534246576,"p(x, w)
p(z|x) p(w|x)"
REFERENCES,0.5933219178082192,"p(z, w|x)
p(x|w) p(y|w)"
REFERENCES,0.5941780821917808,"p(x, y|w)
(20)"
REFERENCES,0.5950342465753424,"where the last three factors “correct” the expression of p(x, z, y, w) for the three (conditional)
581"
REFERENCES,0.5958904109589042,"independences entailed by the underlying graph, that is, X ⊥W, Z ⊥W|X, and X ⊥Y |W.
582"
REFERENCES,0.5967465753424658,"C.2
Relation to the head-and-tail factorizations
583"
REFERENCES,0.5976027397260274,"The head-and-tail factorizations of the model distribution of an acyclic directed mixed graph, intro-
584"
REFERENCES,0.598458904109589,"duced by Richardson 2009 [6], enable the parametrization of the joint probability distribution with
585"
REFERENCES,0.5993150684931506,"independent parameters for ancestrally closed subsets of vertices.
586"
REFERENCES,0.6001712328767124,"For instance, the head-and-tail factorizations of the simple two-collider path including one bidirected
587"
REFERENCES,0.601027397260274,"edge, X →Z ←→Y ←W, introduced above, Fig. 1D, are [6],
588"
REFERENCES,0.6018835616438356,"q(x, w) = q(x) q(w)
q(x, z) = q(z|x) q(x)
q(y, w) = q(y|w) q(w)
q(x, z, w) = q(z|x) q(x) q(w)
q(x, y, w) = q(y|w) q(w) q(x)
q(x, z, y, w) = q(z, y|x, w) q(x) q(w)
(21)"
REFERENCES,0.6027397260273972,"Importantly, these head-and-tail factorizations imply additional relations such as q(y|w) = q(y|x, w)
589"
REFERENCES,0.603595890410959,"(i.e. X ⊥Y |W) obtained by comparing the last two relations in Eq. 21 after marginalizing
590"
REFERENCES,0.6044520547945206,"q(x, z, y, w) over z. However, such implicit conditional independence relations are not veriﬁed
591"
REFERENCES,0.6053082191780822,"by the empirical distribution p(.) in general and prevent the estimation of the head-and-tail factoriza-
592"
REFERENCES,0.6061643835616438,"tions by substituting the rhs q(.) terms in Eq. 21 with their empirical counterparts p(.), as in the case
593"
REFERENCES,0.6070205479452054,"of Bayesian networks, Eq. 15.
594"
REFERENCES,0.6078767123287672,"Indeed, while the head-and-tail factorization relations, Eq. 21, obey the local and global Markov
595"
REFERENCES,0.6087328767123288,"independence relations entailed by the graphical model, Fig. 1D, leading to the cancellation of all
596"
REFERENCES,0.6095890410958904,"factors associated to non-ac-connected subsets in gray in Eq. 18, the remaining head-and-tail factors
597"
REFERENCES,0.610445205479452,"cannot be readily estimated with the empirical distribution p(.).
598"
REFERENCES,0.6113013698630136,"In particular, the cross-entropy of the two-collider path of interest, Fig. 1D, obtained with the head-
599"
REFERENCES,0.6121575342465754,"and-tail factorizations corresponds to1 H(p, q)=−P p(x, z, y, w) log q(z, y|x, w) q(x) q(w). Then,
600"
REFERENCES,0.613013698630137,"estimating the q(.) terms with their p(.) counterparts leads to the cross-entropy of a Bayesian graph,
601"
REFERENCES,0.6138698630136986,"Fig. 1E, with a different Markov equivalent class than the ancestral graph of interest, Fig. 1D. A
602"
REFERENCES,0.6147260273972602,"similar discrepancy is obtained with a c-component factorization which leads to the cross-entropy of
603"
REFERENCES,0.615582191780822,"the Bayesian graph of Fig. 1E without edge X →Y , corresponding to a different Markov equivalence
604"
REFERENCES,0.6164383561643836,"class than the previous two graphs, Figs. 1D & E.
605"
REFERENCES,0.6172945205479452,"These examples illustrate the difﬁculty to exploit the c-component or head-and-tail factorizations to
606"
REFERENCES,0.6181506849315068,"estimate the likelihood of ancestral graphs including bidirected edge(s).
607"
REFERENCES,0.6190068493150684,"D
Node and edge scores based on Normalized Maximum Likelihood criteria
608"
REFERENCES,0.6198630136986302,"Search-and-score methods based on likelihood estimates need to properly account for ﬁnite sample
609"
REFERENCES,0.6207191780821918,"size, as cross-entropy minimization leads to ever more complex models, resulting in model overﬁtting
610"
REFERENCES,0.6215753424657534,"for ﬁnite datasets. While BIC regularization is valid in the asymptotic limit of very large datasets, it
611"
REFERENCES,0.622431506849315,"tends to overestimate ﬁnite size corrections, leading to lower recall, in general. In order to better take
612"
REFERENCES,0.6232876712328768,"into account ﬁnite sample size, we used instead the (universal) Normalized Maximum Likelihood
613"
REFERENCES,0.6241438356164384,"(NML) criteria [42, 43, 38, 39], which amounts to normalizing the likelihood function over all
614"
REFERENCES,0.625,"possible datasets with the same number N of samples.
615"
REFERENCES,0.6258561643835616,"Node score. We ﬁrst used the factorized Normalized Maximum Likelihood (fNML) complexity [38,
616"
REFERENCES,0.6267123287671232,"39] to deﬁne a local score for each node Xi, which extends the decomposable likelihood of Bayesian
617"
REFERENCES,0.627568493150685,"graphs given each node’s parents, Eq. 2, to all non-descendant neighbors, Pa′
Xi,
618"
REFERENCES,0.6284246575342466,"LD|GXi = e−N. Scoren(Xi)
=
e−NH(Xi|Pa′
Xi )
P"
REFERENCES,0.6292808219178082,"|D′|=N e−NH(Xi|Pa′
Xi )
(22)"
REFERENCES,0.6301369863013698,"=
e−NH(Xi|Pa′
Xi )−Pqi
j log C
ri
nj
(23)"
REFERENCES,0.6309931506849316,"=
e
N Pqi
j
Pri
k
njk"
REFERENCES,0.6318493150684932,"N
log
 njk nj"
REFERENCES,0.6327054794520548,"
−Pqi
j log C
ri
nj
(24) = qi
Y j"
REFERENCES,0.6335616438356164,"Qri
k

njk nj njk"
REFERENCES,0.634417808219178,"Cri
nj (25)"
REFERENCES,0.6352739726027398,"where njk corresponds to the number of data points for which Xi is in its kth state and its non-
619"
REFERENCES,0.6361301369863014,"descendant neighbors in their jth state, with nj = Pri
k njk. The universal normalization constant Cr
n
620"
REFERENCES,0.636986301369863,"is then computed by summing the numerator over all possible partitions of the n data points into a
621"
REFERENCES,0.6378424657534246,"maximum of r subsets, ℓ1 + ℓ2 + · · · + ℓr = n with ℓk ⩾0,
622"
REFERENCES,0.6386986301369864,"Cr
n =
X"
REFERENCES,0.639554794520548,ℓ1+ℓ2+···+ℓr=n
REFERENCES,0.6404109589041096,"n!
ℓ1!ℓ2! · · · ℓr! r
Y k=1 ℓk n"
REFERENCES,0.6412671232876712,"ℓk
(26)"
REFERENCES,0.6421232876712328,"which can in fact be computed in linear-time using the following recursion [38],
623"
REFERENCES,0.6429794520547946,"Cr
n = Cr−1
n
+
n
r −2Cr−2
n
(27)"
REFERENCES,0.6438356164383562,"with C1
n = 1 for all n and applying Eq. 30 below for r = 2. However, for large n and r, Cr
n
624"
REFERENCES,0.6446917808219178,"computation tends to be numerically unstable, which can be circumvented by implementing the
625"
REFERENCES,0.6455479452054794,"recursion on parametric complexity ratios Dr
n = Cr
n/Cr−1
n
rather than parametric complexities
626"
REFERENCES,0.646404109589041,"themselves [35] as,
627"
REFERENCES,0.6472602739726028,"Dr
n
=
1 +
n
(r −2)Dr−1
n (28)"
REFERENCES,0.6481164383561644,"log Cr
n
= r
X"
REFERENCES,0.648972602739726,"k=2
log Dk
n
(29)"
REFERENCES,0.6498287671232876,"1Indeed, all terms in Eq. 18 actually cancel two-by-two by construction, whatever their factorization
expression, except for the remaining joint-distribution over all variables, q(x, z, y, w)=q(z, y|x, w) q(x) q(w)."
REFERENCES,0.6506849315068494,"for r ⩾3, with C1
n = 1 and C2
n = D2
n, which can be computed directly with the general formula,
628"
REFERENCES,0.651541095890411,"Eq. 26, for r = 2,
629"
REFERENCES,0.6523972602739726,"C2
n = n
X h=0 n
h  h n"
REFERENCES,0.6532534246575342,h n −h n
REFERENCES,0.6541095890410958,"n−h
(30)"
REFERENCES,0.6549657534246576,"or its Szpankowski approximation for large n (needed for n > 1000 in practice) [44–46],
630"
REFERENCES,0.6558219178082192,"C2
n =
rnπ 2  1 + 2 3 r"
REFERENCES,0.6566780821917808,"2
nπ +
1
12n + O
 1 n3/2 ! (31) ≃
rnπ"
EXP,0.6575342465753424,2 exp r
EXP,0.6583904109589042,"8
9nπ + 3π −16 36nπ ! (32) 631"
EXP,0.6592465753424658,"This leads to the following local score for each node Xi, which is minimized over alternative
632"
EXP,0.6601027397260274,"combinations of non-descendant neighbors, Pa′
Xi ⊆PaXi∪SpXi∪NeXi, in the ﬁrst step of the
633"
EXP,0.660958904109589,"local search-and-score algorithm (step 1) detailed in the main text,
634"
EXP,0.6618150684931506,"Scoren(Xi) = H(Xi|Pa′
Xi) + 1 N qxi
X"
EXP,0.6626712328767124,"j
log C
rxi
nj
(33)"
EXP,0.663527397260274,"Edge scores. We then deﬁned several edge scores to optimize the orientation of each edge, X
Y ,
635"
EXP,0.6643835616438356,"given its close surrounding vertices.
636"
EXP,0.6652397260273972,"To this end, we ﬁrst introduced a local score for node pairs which simply sums the node scores, Eq. 33,
637"
EXP,0.666095890410959,"for each node. The resulting pair scores are listed in Table 2 for unconnected node pairs and for pairs
638"
EXP,0.6669520547945206,"of nodes connected by a directed edge, where Pa′
X\Y = PaX ∪SpX\Y and Pa′
Y\X = PaY ∪SpY\X
639"
EXP,0.6678082191780822,"with their corresponding combinations of levels, qy\x and qx\y.
640"
EXP,0.6686643835616438,Table 2: Local scores for node pairs
EXP,0.6695205479452054,"Pair score
Information
fNML Complexity"
EXP,0.6703767123287672,"X ̸
Y
H(X|Pa′
X\Y ) + H(Y |Pa′
Y\X)
1
N
 Pqx\y
j
log Crx
nj + Pqy\x
j
log Cry
nj
"
EXP,0.6712328767123288,"X →Y
H(X|Pa′
X\Y ) + H(Y |Pa′
Y\X, X)
1
N
 Pqx\y
j
log Crx
nj + Pqy\xrx
j
log Cry
nj
"
EXP,0.6720890410958904,"X ←Y
H(X|Pa′
X\Y , Y ) + H(Y |Pa′
Y\X)
1
N
 Pqx\y ry
j
log Crx
nj + Pqy\x
j
log Cry
nj
"
EXP,0.672945205479452,"Then, edge scores for directed edges, X →Y and Y →X, are deﬁned w.r.t. to the edge removal
641"
EXP,0.6738013698630136,"score, X ̸
Y , by substracting the pair scores of unconnected pairs to the pair scores of directed
642"
EXP,0.6746575342465754,"edges, leading to the following edge orientation scores,
643"
EXP,0.675513698630137,"Score(X →Y )
=
−I(X; Y |Pa′
Y\X) + 1 N"
EXP,0.6763698630136986,"
qy\xrx
X"
EXP,0.6772260273972602,"j
log Cry
nj −"
EXP,0.678082191780822,"qy\x
X"
EXP,0.6789383561643836,"j
log Cry
nj
 (34)"
EXP,0.6797945205479452,"Score(Y →X)
=
−I(X; Y |Pa′
X\Y ) + 1 N"
EXP,0.6806506849315068,"
qx\y ry
X"
EXP,0.6815068493150684,"j
log Crx
nj −"
EXP,0.6823630136986302,"qx\y
X"
EXP,0.6832191780821918,"j
log Crx
nj
 (35)"
EXP,0.6840753424657534,"However, if rx ̸= ry, the fNML complexities of these orientation scores are not identical for
644"
EXP,0.684931506849315,"Markov equivalent edge orientations between nodes sharing the same parents (or spouses) [47],
645"
EXP,0.6857876712328768,"Pa′
Y\X = Pa′
X\Y = Pa′ and qy\x = qx\y, despite sharing the same conditional mutual information,
646"
EXP,0.6866438356164384,"I(X; Y |Pa′)
=
1
2"
EXP,0.6875,"
H(X|Pa′) + H(Y |Pa′, X)

+ 1 2"
EXP,0.6883561643835616,"
H(X|Pa′, Y ) + H(Y |Pa′)
 (36)"
EXP,0.6892123287671232,"This suggests to symmetrize the fNML complexities for edge orientation scores by averaging them
647"
EXP,0.690068493150685,"over each directed orientation, as for the conditional information in Eq. 36, leading to the proposed
648"
EXP,0.6909246575342466,"fNML complexity for directed edges given in Table 1 in the main text.
649"
EXP,0.6917808219178082,"For bidirected edges, the proposed local orientation score accounts for all ac-connected subsets in
650"
EXP,0.6926369863013698,"close vicinity of the bidirected edge, which concerns all subsets including either X and any combi-
651"
EXP,0.6934931506849316,"nation (possibly void) of parents or spouses different from Y (i.e. corresponding to the information
652"
EXP,0.6943493150684932,"contributions H(X|Pa′
X\Y )) or Y and any combination of parents or spouses different from X
653"
EXP,0.6952054794520548,"(i.e. corresponding to the information contributions H(Y |Pa′
Y\X)) or, else, including both nodes X
654"
EXP,0.6960616438356164,"and Y plus any combination of their parents or spouses, corresponding to the following information
655"
EXP,0.696917808219178,"contribution, −I(X; Y |Pa′
XY ), where Pa′
XY = Pa′
X\Y ∪Pa′
Y\X. This last term, −I(X; Y |Pa′
XY ),
656"
EXP,0.6977739726027398,"contains all the remaining information contributions once the bidirected orientation score is given
657"
EXP,0.6986301369863014,"relative to the edge removal score (Table 2) as for the two directed orientation scores, above. Finally,
658"
EXP,0.699486301369863,"the symmetrized fNML complexity associated with a bidirected edge should be computed with
659"
EXP,0.7003424657534246,"the whole set of conditioning parents or spouses, Pa′
XY , as indicated in Table 1. Note that this
660"
EXP,0.7011986301369864,"bidirected orientation score becomes also Markov equivalent to the two directed orientation scores,
661"
EXP,0.702054794520548,"as required, when the nodes share the same parents and spouses, i.e. Pa′
XY = Pa′
Y\X = Pa′
X\Y and
662"
EXP,0.7029109589041096,"qxy = qy\x = qx\y in Table 1.
663"
EXP,0.7037671232876712,"E
Toy models
664"
EXP,0.7046232876712328,"Fig. 3 shows three simple ancestral models used to test MIIC_search&score orientation scores
665"
EXP,0.7054794520547946,"(Table 1) to effectively predict bidirected orientations when the end nodes do not share the same
666"
EXP,0.7063356164383562,"parents (Model 1), share some parents (Model 2) or when the bidirected edge is part of a longer than
667"
EXP,0.7071917808219178,"two-collider paths (Model 3).
668"
EXP,0.7080479452054794,"The data is generated from the theoretical DAG using the rmvDAG function in the pcalg package
669"
EXP,0.708904109589041,"[48]. Each node follows a normal distribution, and the data is discretized using bnlearn’s discretize
670"
EXP,0.7097602739726028,"function using Hartemink’s pairwise mutual information method [40]. For these toy models, the edge
671"
EXP,0.7106164383561644,"orientation scores are computed assuming the correct parents of each node.
672"
EXP,0.711472602739726,"The prediction of the edge orientation scores are summarized in Table 3 in % of replicates displaying
673"
EXP,0.7123287671232876,"directed edges (wrong) or bidirected edge (correct) as a function of increasing dataset size N.
674"
EXP,0.7131849315068494,"Model 2
Model 3
Model 1"
EXP,0.714041095890411,Figure 3: Simple ancestral graphs.
EXP,0.7148972602739726,"Table 3:
Model 1, X2
X4
Model 2, X2
X4
Model 3, X2
X4
Model 3, X4
X6"
EXP,0.7157534246575342,"N
←
→
↔
←
→
↔
←
→
↔
←
→
↔
1000
0
100
0
50
42
8
8
88
4
91.7
6.2
2.1
5000
0
68
32
18
2
80
2
80
18
76
24
0
10000
0
10
90
0
0
100
0
6
94
62
22
16
20000
0
0
100
0
0
100
0
0
100
2
0
98
35000
0
0
100
0
0
100
0
0
100
0
0
100
50000
0
0
100
0
0
100
0
0
100
0
0
100"
EXP,0.7166095890410958,"NeurIPS Paper Checklist
675"
CLAIMS,0.7174657534246576,"1. Claims
676"
CLAIMS,0.7183219178082192,"Question: Do the main claims made in the abstract and introduction accurately reﬂect the
677"
CLAIMS,0.7191780821917808,"paper’s contributions and scope?
678"
CLAIMS,0.7200342465753424,"Answer: [Yes]
679"
CLAIMS,0.7208904109589042,"Justiﬁcation: The main claims of the paper are supported by the theoretical and experimental
680"
CLAIMS,0.7217465753424658,"results shown in Figs. 1 & 2, respectively.
681"
CLAIMS,0.7226027397260274,"Guidelines:
682"
CLAIMS,0.723458904109589,"• The answer NA means that the abstract and introduction do not include the claims
683"
CLAIMS,0.7243150684931506,"made in the paper.
684"
CLAIMS,0.7251712328767124,"• The abstract and/or introduction should clearly state the claims made, including the
685"
CLAIMS,0.726027397260274,"contributions made in the paper and important assumptions and limitations. A No or
686"
CLAIMS,0.7268835616438356,"NA answer to this question will not be perceived well by the reviewers.
687"
CLAIMS,0.7277397260273972,"• The claims made should match theoretical and experimental results, and reﬂect how
688"
CLAIMS,0.728595890410959,"much the results can be expected to generalize to other settings.
689"
CLAIMS,0.7294520547945206,"• It is ﬁne to include aspirational goals as motivation as long as it is clear that these goals
690"
CLAIMS,0.7303082191780822,"are not attained by the paper.
691"
LIMITATIONS,0.7311643835616438,"2. Limitations
692"
LIMITATIONS,0.7320205479452054,"Question: Does the paper discuss the limitations of the work performed by the authors?
693"
LIMITATIONS,0.7328767123287672,"Answer: [Yes]
694"
LIMITATIONS,0.7337328767123288,"Justiﬁcation: We have added a Discussion & Limitation section at the end of the paper. The
695"
LIMITATIONS,0.7345890410958904,"main limitation of the experimental results is the fact that we did not have sufﬁcient time
696"
LIMITATIONS,0.735445205479452,"to perform many dataset replicates of the benchmark ancestral graphs. While the obtained
697"
LIMITATIONS,0.7363013698630136,"statistics already support our main experimental results, we intend to perform more dataset
698"
LIMITATIONS,0.7371575342465754,"replicates for the ﬁnal version of the paper.
699"
LIMITATIONS,0.738013698630137,"Guidelines:
700"
LIMITATIONS,0.7388698630136986,"• The answer NA means that the paper has no limitation while the answer No means that
701"
LIMITATIONS,0.7397260273972602,"the paper has limitations, but those are not discussed in the paper.
702"
LIMITATIONS,0.740582191780822,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
703"
LIMITATIONS,0.7414383561643836,"• The paper should point out any strong assumptions and how robust the results are to
704"
LIMITATIONS,0.7422945205479452,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
705"
LIMITATIONS,0.7431506849315068,"model well-speciﬁcation, asymptotic approximations only holding locally). The authors
706"
LIMITATIONS,0.7440068493150684,"should reﬂect on how these assumptions might be violated in practice and what the
707"
LIMITATIONS,0.7448630136986302,"implications would be.
708"
LIMITATIONS,0.7457191780821918,"• The authors should reﬂect on the scope of the claims made, e.g., if the approach was
709"
LIMITATIONS,0.7465753424657534,"only tested on a few datasets or with a few runs. In general, empirical results often
710"
LIMITATIONS,0.747431506849315,"depend on implicit assumptions, which should be articulated.
711"
LIMITATIONS,0.7482876712328768,"• The authors should reﬂect on the factors that inﬂuence the performance of the approach.
712"
LIMITATIONS,0.7491438356164384,"For example, a facial recognition algorithm may perform poorly when image resolution
713"
LIMITATIONS,0.75,"is low or images are taken in low lighting. Or a speech-to-text system might not be
714"
LIMITATIONS,0.7508561643835616,"used reliably to provide closed captions for online lectures because it fails to handle
715"
LIMITATIONS,0.7517123287671232,"technical jargon.
716"
LIMITATIONS,0.752568493150685,"• The authors should discuss the computational efﬁciency of the proposed algorithms
717"
LIMITATIONS,0.7534246575342466,"and how they scale with dataset size.
718"
LIMITATIONS,0.7542808219178082,"• If applicable, the authors should discuss possible limitations of their approach to
719"
LIMITATIONS,0.7551369863013698,"address problems of privacy and fairness.
720"
LIMITATIONS,0.7559931506849316,"• While the authors might fear that complete honesty about limitations might be used by
721"
LIMITATIONS,0.7568493150684932,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
722"
LIMITATIONS,0.7577054794520548,"limitations that aren’t acknowledged in the paper. The authors should use their best
723"
LIMITATIONS,0.7585616438356164,"judgment and recognize that individual actions in favor of transparency play an impor-
724"
LIMITATIONS,0.759417808219178,"tant role in developing norms that preserve the integrity of the community. Reviewers
725"
LIMITATIONS,0.7602739726027398,"will be speciﬁcally instructed to not penalize honesty concerning limitations.
726"
THEORY ASSUMPTIONS AND PROOFS,0.7611301369863014,"3. Theory Assumptions and Proofs
727"
THEORY ASSUMPTIONS AND PROOFS,0.761986301369863,"Question: For each theoretical result, does the paper provide the full set of assumptions and
728"
THEORY ASSUMPTIONS AND PROOFS,0.7628424657534246,"a complete (and correct) proof?
729"
THEORY ASSUMPTIONS AND PROOFS,0.7636986301369864,"Answer: [Yes]
730"
THEORY ASSUMPTIONS AND PROOFS,0.764554794520548,"Justiﬁcation: For the theoretical results (notably Theorem 1) we provide the full set of
731"
THEORY ASSUMPTIONS AND PROOFS,0.7654109589041096,"assumptions (section 2 and Appendix A)and a complete proof (Appendix B).
732"
THEORY ASSUMPTIONS AND PROOFS,0.7662671232876712,"Guidelines:
733"
THEORY ASSUMPTIONS AND PROOFS,0.7671232876712328,"• The answer NA means that the paper does not include theoretical results.
734"
THEORY ASSUMPTIONS AND PROOFS,0.7679794520547946,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
735"
THEORY ASSUMPTIONS AND PROOFS,0.7688356164383562,"referenced.
736"
THEORY ASSUMPTIONS AND PROOFS,0.7696917808219178,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
737"
THEORY ASSUMPTIONS AND PROOFS,0.7705479452054794,"• The proofs can either appear in the main paper or the supplemental material, but if
738"
THEORY ASSUMPTIONS AND PROOFS,0.771404109589041,"they appear in the supplemental material, the authors are encouraged to provide a short
739"
THEORY ASSUMPTIONS AND PROOFS,0.7722602739726028,"proof sketch to provide intuition.
740"
THEORY ASSUMPTIONS AND PROOFS,0.7731164383561644,"• Inversely, any informal proof provided in the core of the paper should be complemented
741"
THEORY ASSUMPTIONS AND PROOFS,0.773972602739726,"by formal proofs provided in appendix or supplemental material.
742"
THEORY ASSUMPTIONS AND PROOFS,0.7748287671232876,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
743"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7756849315068494,"4. Experimental Result Reproducibility
744"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.776541095890411,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
745"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7773972602739726,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
746"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7782534246575342,"of the paper (regardless of whether the code and data are provided or not)?
747"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7791095890410958,"Answer: [Yes]
748"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7799657534246576,"Justiﬁcation: We provided the full description of the experiments run in the paper (sections 2
749"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7808219178082192,"& 3 and Appendix D). The open-source code reproducing the experimental results presented
750"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7816780821917808,"in the paper will be provided with the camera-ready version of the paper.
751"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7825342465753424,"Guidelines:
752"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7833904109589042,"• The answer NA means that the paper does not include experiments.
753"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7842465753424658,"• If the paper includes experiments, a No answer to this question will not be perceived
754"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7851027397260274,"well by the reviewers: Making the paper reproducible is important, regardless of
755"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.785958904109589,"whether the code and data are provided or not.
756"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7868150684931506,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
757"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7876712328767124,"to make their results reproducible or veriﬁable.
758"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.788527397260274,"• Depending on the contribution, reproducibility can be accomplished in various ways.
759"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7893835616438356,"For example, if the contribution is a novel architecture, describing the architecture fully
760"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7902397260273972,"might sufﬁce, or if the contribution is a speciﬁc model and empirical evaluation, it may
761"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.791095890410959,"be necessary to either make it possible for others to replicate the model with the same
762"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7919520547945206,"dataset, or provide access to the model. In general. releasing code and data is often
763"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7928082191780822,"one good way to accomplish this, but reproducibility can also be provided via detailed
764"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7936643835616438,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
765"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7945205479452054,"of a large language model), releasing of a model checkpoint, or other means that are
766"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7953767123287672,"appropriate to the research performed.
767"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7962328767123288,"• While NeurIPS does not require releasing code, the conference does require all submis-
768"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7970890410958904,"sions to provide some reasonable avenue for reproducibility, which may depend on the
769"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.797945205479452,"nature of the contribution. For example
770"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7988013698630136,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
771"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7996575342465754,"to reproduce that algorithm.
772"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.800513698630137,"(b) If the contribution is primarily a new model architecture, the paper should describe
773"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8013698630136986,"the architecture clearly and fully.
774"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8022260273972602,"(c) If the contribution is a new model (e.g., a large language model), then there should
775"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.803082191780822,"either be a way to access this model for reproducing the results or a way to reproduce
776"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8039383561643836,"the model (e.g., with an open-source dataset or instructions for how to construct
777"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8047945205479452,"the dataset).
778"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8056506849315068,"(d) We recognize that reproducibility may be tricky in some cases, in which case
779"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8065068493150684,"authors are welcome to describe the particular way they provide for reproducibility.
780"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8073630136986302,"In the case of closed-source models, it may be that access to the model is limited in
781"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8082191780821918,"some way (e.g., to registered users), but it should be possible for other researchers
782"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8090753424657534,"to have some path to reproducing or verifying the results.
783"
OPEN ACCESS TO DATA AND CODE,0.809931506849315,"5. Open access to data and code
784"
OPEN ACCESS TO DATA AND CODE,0.8107876712328768,"Question: Does the paper provide open access to the data and code, with sufﬁcient instruc-
785"
OPEN ACCESS TO DATA AND CODE,0.8116438356164384,"tions to faithfully reproduce the main experimental results, as described in supplemental
786"
OPEN ACCESS TO DATA AND CODE,0.8125,"material?
787"
OPEN ACCESS TO DATA AND CODE,0.8133561643835616,"Answer: [No]
788"
OPEN ACCESS TO DATA AND CODE,0.8142123287671232,"Justiﬁcation: We do not include a new code with the initial submission, as it is not yet
789"
OPEN ACCESS TO DATA AND CODE,0.815068493150685,"properly packaged at submission time, but we deﬁnitely intend to release this open-source
790"
OPEN ACCESS TO DATA AND CODE,0.8159246575342466,"code including proper annotation and userguide with the ﬁnal camera-ready version of the
791"
OPEN ACCESS TO DATA AND CODE,0.8167808219178082,"paper. MIIC and FCI open-source packages used for benchmark comparison are already
792"
OPEN ACCESS TO DATA AND CODE,0.8176369863013698,"published and available on public servers.
793"
OPEN ACCESS TO DATA AND CODE,0.8184931506849316,"Guidelines:
794"
OPEN ACCESS TO DATA AND CODE,0.8193493150684932,"• The answer NA means that paper does not include experiments requiring code.
795"
OPEN ACCESS TO DATA AND CODE,0.8202054794520548,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
796"
OPEN ACCESS TO DATA AND CODE,0.8210616438356164,"public/guides/CodeSubmissionPolicy) for more details.
797"
OPEN ACCESS TO DATA AND CODE,0.821917808219178,"• While we encourage the release of code and data, we understand that this might not be
798"
OPEN ACCESS TO DATA AND CODE,0.8227739726027398,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
799"
OPEN ACCESS TO DATA AND CODE,0.8236301369863014,"including code, unless this is central to the contribution (e.g., for a new open-source
800"
OPEN ACCESS TO DATA AND CODE,0.824486301369863,"benchmark).
801"
OPEN ACCESS TO DATA AND CODE,0.8253424657534246,"• The instructions should contain the exact command and environment needed to run to
802"
OPEN ACCESS TO DATA AND CODE,0.8261986301369864,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
803"
OPEN ACCESS TO DATA AND CODE,0.827054794520548,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
804"
OPEN ACCESS TO DATA AND CODE,0.8279109589041096,"• The authors should provide instructions on data access and preparation, including how
805"
OPEN ACCESS TO DATA AND CODE,0.8287671232876712,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
806"
OPEN ACCESS TO DATA AND CODE,0.8296232876712328,"• The authors should provide scripts to reproduce all experimental results for the new
807"
OPEN ACCESS TO DATA AND CODE,0.8304794520547946,"proposed method and baselines. If only a subset of experiments are reproducible, they
808"
OPEN ACCESS TO DATA AND CODE,0.8313356164383562,"should state which ones are omitted from the script and why.
809"
OPEN ACCESS TO DATA AND CODE,0.8321917808219178,"• At submission time, to preserve anonymity, the authors should release anonymized
810"
OPEN ACCESS TO DATA AND CODE,0.8330479452054794,"versions (if applicable).
811"
OPEN ACCESS TO DATA AND CODE,0.833904109589041,"• Providing as much information as possible in supplemental material (appended to the
812"
OPEN ACCESS TO DATA AND CODE,0.8347602739726028,"paper) is recommended, but including URLs to data and code is permitted.
813"
OPEN ACCESS TO DATA AND CODE,0.8356164383561644,"6. Experimental Setting/Details
814"
OPEN ACCESS TO DATA AND CODE,0.836472602739726,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
815"
OPEN ACCESS TO DATA AND CODE,0.8373287671232876,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
816"
OPEN ACCESS TO DATA AND CODE,0.8381849315068494,"results?
817"
OPEN ACCESS TO DATA AND CODE,0.839041095890411,"Answer: [Yes]
818"
OPEN ACCESS TO DATA AND CODE,0.8398972602739726,"Justiﬁcation: We provided the full description of the experiments run in the paper (sections
819"
OPEN ACCESS TO DATA AND CODE,0.8407534246575342,"2 3 and Appendix D).
820"
OPEN ACCESS TO DATA AND CODE,0.8416095890410958,"Guidelines:
821"
OPEN ACCESS TO DATA AND CODE,0.8424657534246576,"• The answer NA means that the paper does not include experiments.
822"
OPEN ACCESS TO DATA AND CODE,0.8433219178082192,"• The experimental setting should be presented in the core of the paper to a level of detail
823"
OPEN ACCESS TO DATA AND CODE,0.8441780821917808,"that is necessary to appreciate the results and make sense of them.
824"
OPEN ACCESS TO DATA AND CODE,0.8450342465753424,"• The full details can be provided either with the code, in appendix, or as supplemental
825"
OPEN ACCESS TO DATA AND CODE,0.8458904109589042,"material.
826"
OPEN ACCESS TO DATA AND CODE,0.8467465753424658,"7. Experiment Statistical Signiﬁcance
827"
OPEN ACCESS TO DATA AND CODE,0.8476027397260274,"Question: Does the paper report error bars suitably and correctly deﬁned or other appropriate
828"
OPEN ACCESS TO DATA AND CODE,0.848458904109589,"information about the statistical signiﬁcance of the experiments?
829"
OPEN ACCESS TO DATA AND CODE,0.8493150684931506,"Answer: [Yes]
830"
OPEN ACCESS TO DATA AND CODE,0.8501712328767124,"Justiﬁcation: The 1-sigma error bars are plotted in Fig. 2. While these statistics already
831"
OPEN ACCESS TO DATA AND CODE,0.851027397260274,"support our experimental results, we intend to perform more dataset replicates for the
832"
OPEN ACCESS TO DATA AND CODE,0.8518835616438356,"ﬁnal version of the paper, which we did not have sufﬁcient time to perform by the time of
833"
OPEN ACCESS TO DATA AND CODE,0.8527397260273972,"submission. This should reduce some error bars, in particular, those for the results displaying
834"
OPEN ACCESS TO DATA AND CODE,0.853595890410959,"large error bars.
835"
OPEN ACCESS TO DATA AND CODE,0.8544520547945206,"Guidelines:
836"
OPEN ACCESS TO DATA AND CODE,0.8553082191780822,"• The answer NA means that the paper does not include experiments.
837"
OPEN ACCESS TO DATA AND CODE,0.8561643835616438,"• The authors should answer ""Yes"" if the results are accompanied by error bars, conﬁ-
838"
OPEN ACCESS TO DATA AND CODE,0.8570205479452054,"dence intervals, or statistical signiﬁcance tests, at least for the experiments that support
839"
OPEN ACCESS TO DATA AND CODE,0.8578767123287672,"the main claims of the paper.
840"
OPEN ACCESS TO DATA AND CODE,0.8587328767123288,"• The factors of variability that the error bars are capturing should be clearly stated (for
841"
OPEN ACCESS TO DATA AND CODE,0.8595890410958904,"example, train/test split, initialization, random drawing of some parameter, or overall
842"
OPEN ACCESS TO DATA AND CODE,0.860445205479452,"run with given experimental conditions).
843"
OPEN ACCESS TO DATA AND CODE,0.8613013698630136,"• The method for calculating the error bars should be explained (closed form formula,
844"
OPEN ACCESS TO DATA AND CODE,0.8621575342465754,"call to a library function, bootstrap, etc.)
845"
OPEN ACCESS TO DATA AND CODE,0.863013698630137,"• The assumptions made should be given (e.g., Normally distributed errors).
846"
OPEN ACCESS TO DATA AND CODE,0.8638698630136986,"• It should be clear whether the error bar is the standard deviation or the standard error
847"
OPEN ACCESS TO DATA AND CODE,0.8647260273972602,"of the mean.
848"
OPEN ACCESS TO DATA AND CODE,0.865582191780822,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
849"
OPEN ACCESS TO DATA AND CODE,0.8664383561643836,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
850"
OPEN ACCESS TO DATA AND CODE,0.8672945205479452,"of Normality of errors is not veriﬁed.
851"
OPEN ACCESS TO DATA AND CODE,0.8681506849315068,"• For asymmetric distributions, the authors should be careful not to show in tables or
852"
OPEN ACCESS TO DATA AND CODE,0.8690068493150684,"ﬁgures symmetric error bars that would yield results that are out of range (e.g. negative
853"
OPEN ACCESS TO DATA AND CODE,0.8698630136986302,"error rates).
854"
OPEN ACCESS TO DATA AND CODE,0.8707191780821918,"• If error bars are reported in tables or plots, The authors should explain in the text how
855"
OPEN ACCESS TO DATA AND CODE,0.8715753424657534,"they were calculated and reference the corresponding ﬁgures or tables in the text.
856"
EXPERIMENTS COMPUTE RESOURCES,0.872431506849315,"8. Experiments Compute Resources
857"
EXPERIMENTS COMPUTE RESOURCES,0.8732876712328768,"Question: For each experiment, does the paper provide sufﬁcient information on the com-
858"
EXPERIMENTS COMPUTE RESOURCES,0.8741438356164384,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
859"
EXPERIMENTS COMPUTE RESOURCES,0.875,"the experiments?
860"
EXPERIMENTS COMPUTE RESOURCES,0.8758561643835616,"Answer: [Yes]
861"
EXPERIMENTS COMPUTE RESOURCES,0.8767123287671232,"Justiﬁcation: The computer resource used for all experiments is a simple laptop with intel i7
862"
EXPERIMENTS COMPUTE RESOURCES,0.877568493150685,"processors, 12 cores and 16 threads.
863"
EXPERIMENTS COMPUTE RESOURCES,0.8784246575342466,"Guidelines:
864"
EXPERIMENTS COMPUTE RESOURCES,0.8792808219178082,"• The answer NA means that the paper does not include experiments.
865"
EXPERIMENTS COMPUTE RESOURCES,0.8801369863013698,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
866"
EXPERIMENTS COMPUTE RESOURCES,0.8809931506849316,"or cloud provider, including relevant memory and storage.
867"
EXPERIMENTS COMPUTE RESOURCES,0.8818493150684932,"• The paper should provide the amount of compute required for each of the individual
868"
EXPERIMENTS COMPUTE RESOURCES,0.8827054794520548,"experimental runs as well as estimate the total compute.
869"
EXPERIMENTS COMPUTE RESOURCES,0.8835616438356164,"• The paper should disclose whether the full research project required more compute
870"
EXPERIMENTS COMPUTE RESOURCES,0.884417808219178,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
871"
EXPERIMENTS COMPUTE RESOURCES,0.8852739726027398,"didn’t make it into the paper).
872"
CODE OF ETHICS,0.8861301369863014,"9. Code Of Ethics
873"
CODE OF ETHICS,0.886986301369863,"Question: Does the research conducted in the paper conform, in every respect, with the
874"
CODE OF ETHICS,0.8878424657534246,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
875"
CODE OF ETHICS,0.8886986301369864,"Answer: [Yes]
876"
CODE OF ETHICS,0.889554794520548,"Justiﬁcation: The paper does not use or produce sensitive data nor concern potentially
877"
CODE OF ETHICS,0.8904109589041096,"harmful applications.
878"
CODE OF ETHICS,0.8912671232876712,"Guidelines:
879"
CODE OF ETHICS,0.8921232876712328,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
880"
CODE OF ETHICS,0.8929794520547946,"• If the authors answer No, they should explain the special circumstances that require a
881"
CODE OF ETHICS,0.8938356164383562,"deviation from the Code of Ethics.
882"
CODE OF ETHICS,0.8946917808219178,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
883"
CODE OF ETHICS,0.8955479452054794,"eration due to laws or regulations in their jurisdiction).
884"
BROADER IMPACTS,0.896404109589041,"10. Broader Impacts
885"
BROADER IMPACTS,0.8972602739726028,"Question: Does the paper discuss both potential positive societal impacts and negative
886"
BROADER IMPACTS,0.8981164383561644,"societal impacts of the work performed?
887"
BROADER IMPACTS,0.898972602739726,"Answer: [Yes]
888"
BROADER IMPACTS,0.8998287671232876,"Justiﬁcation: The paper does not use or produce sensitive data nor concern potentially
889"
BROADER IMPACTS,0.9006849315068494,"harmful applications.
890"
BROADER IMPACTS,0.901541095890411,"Guidelines:
891"
BROADER IMPACTS,0.9023972602739726,"• The answer NA means that there is no societal impact of the work performed.
892"
BROADER IMPACTS,0.9032534246575342,"• If the authors answer NA or No, they should explain why their work has no societal
893"
BROADER IMPACTS,0.9041095890410958,"impact or why the paper does not address societal impact.
894"
BROADER IMPACTS,0.9049657534246576,"• Examples of negative societal impacts include potential malicious or unintended uses
895"
BROADER IMPACTS,0.9058219178082192,"(e.g., disinformation, generating fake proﬁles, surveillance), fairness considerations
896"
BROADER IMPACTS,0.9066780821917808,"(e.g., deployment of technologies that could make decisions that unfairly impact speciﬁc
897"
BROADER IMPACTS,0.9075342465753424,"groups), privacy considerations, and security considerations.
898"
BROADER IMPACTS,0.9083904109589042,"• The conference expects that many papers will be foundational research and not tied
899"
BROADER IMPACTS,0.9092465753424658,"to particular applications, let alone deployments. However, if there is a direct path to
900"
BROADER IMPACTS,0.9101027397260274,"any negative applications, the authors should point it out. For example, it is legitimate
901"
BROADER IMPACTS,0.910958904109589,"to point out that an improvement in the quality of generative models could be used to
902"
BROADER IMPACTS,0.9118150684931506,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
903"
BROADER IMPACTS,0.9126712328767124,"that a generic algorithm for optimizing neural networks could enable people to train
904"
BROADER IMPACTS,0.913527397260274,"models that generate Deepfakes faster.
905"
BROADER IMPACTS,0.9143835616438356,"• The authors should consider possible harms that could arise when the technology is
906"
BROADER IMPACTS,0.9152397260273972,"being used as intended and functioning correctly, harms that could arise when the
907"
BROADER IMPACTS,0.916095890410959,"technology is being used as intended but gives incorrect results, and harms following
908"
BROADER IMPACTS,0.9169520547945206,"from (intentional or unintentional) misuse of the technology.
909"
BROADER IMPACTS,0.9178082191780822,"• If there are negative societal impacts, the authors could also discuss possible mitigation
910"
BROADER IMPACTS,0.9186643835616438,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
911"
BROADER IMPACTS,0.9195205479452054,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
912"
BROADER IMPACTS,0.9203767123287672,"feedback over time, improving the efﬁciency and accessibility of ML).
913"
SAFEGUARDS,0.9212328767123288,"11. Safeguards
914"
SAFEGUARDS,0.9220890410958904,"Question: Does the paper describe safeguards that have been put in place for responsible
915"
SAFEGUARDS,0.922945205479452,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
916"
SAFEGUARDS,0.9238013698630136,"image generators, or scraped datasets)?
917"
SAFEGUARDS,0.9246575342465754,"Answer: [NA]
918"
SAFEGUARDS,0.925513698630137,"Justiﬁcation: The paper does not use or produce sensitive data nor concern potentially
919"
SAFEGUARDS,0.9263698630136986,"harmful applications.
920"
SAFEGUARDS,0.9272260273972602,"Guidelines:
921"
SAFEGUARDS,0.928082191780822,"• The answer NA means that the paper poses no such risks.
922"
SAFEGUARDS,0.9289383561643836,"• Released models that have a high risk for misuse or dual-use should be released with
923"
SAFEGUARDS,0.9297945205479452,"necessary safeguards to allow for controlled use of the model, for example by requiring
924"
SAFEGUARDS,0.9306506849315068,"that users adhere to usage guidelines or restrictions to access the model or implementing
925"
SAFEGUARDS,0.9315068493150684,"safety ﬁlters.
926"
SAFEGUARDS,0.9323630136986302,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
927"
SAFEGUARDS,0.9332191780821918,"should describe how they avoided releasing unsafe images.
928"
SAFEGUARDS,0.9340753424657534,"• We recognize that providing effective safeguards is challenging, and many papers do
929"
SAFEGUARDS,0.934931506849315,"not require this, but we encourage authors to take this into account and make a best
930"
SAFEGUARDS,0.9357876712328768,"faith effort.
931"
LICENSES FOR EXISTING ASSETS,0.9366438356164384,"12. Licenses for existing assets
932"
LICENSES FOR EXISTING ASSETS,0.9375,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
933"
LICENSES FOR EXISTING ASSETS,0.9383561643835616,"the paper, properly credited and are the license and terms of use explicitly mentioned and
934"
LICENSES FOR EXISTING ASSETS,0.9392123287671232,"properly respected?
935"
LICENSES FOR EXISTING ASSETS,0.940068493150685,"Answer: [Yes]
936"
LICENSES FOR EXISTING ASSETS,0.9409246575342466,"Justiﬁcation: We have credited all previously published resources (including license details)
937"
LICENSES FOR EXISTING ASSETS,0.9417808219178082,"used in the paper.
938"
LICENSES FOR EXISTING ASSETS,0.9426369863013698,"Guidelines:
939"
LICENSES FOR EXISTING ASSETS,0.9434931506849316,"• The answer NA means that the paper does not use existing assets.
940"
LICENSES FOR EXISTING ASSETS,0.9443493150684932,"• The authors should cite the original paper that produced the code package or dataset.
941"
LICENSES FOR EXISTING ASSETS,0.9452054794520548,"• The authors should state which version of the asset is used and, if possible, include a
942"
LICENSES FOR EXISTING ASSETS,0.9460616438356164,"URL.
943"
LICENSES FOR EXISTING ASSETS,0.946917808219178,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
944"
LICENSES FOR EXISTING ASSETS,0.9477739726027398,"• For scraped data from a particular source (e.g., website), the copyright and terms of
945"
LICENSES FOR EXISTING ASSETS,0.9486301369863014,"service of that source should be provided.
946"
LICENSES FOR EXISTING ASSETS,0.949486301369863,"• If assets are released, the license, copyright information, and terms of use in the
947"
LICENSES FOR EXISTING ASSETS,0.9503424657534246,"package should be provided. For popular datasets, paperswithcode.com/datasets
948"
LICENSES FOR EXISTING ASSETS,0.9511986301369864,"has curated licenses for some datasets. Their licensing guide can help determine the
949"
LICENSES FOR EXISTING ASSETS,0.952054794520548,"license of a dataset.
950"
LICENSES FOR EXISTING ASSETS,0.9529109589041096,"• For existing datasets that are re-packaged, both the original license and the license of
951"
LICENSES FOR EXISTING ASSETS,0.9537671232876712,"the derived asset (if it has changed) should be provided.
952"
LICENSES FOR EXISTING ASSETS,0.9546232876712328,"• If this information is not available online, the authors are encouraged to reach out to
953"
LICENSES FOR EXISTING ASSETS,0.9554794520547946,"the asset’s creators.
954"
NEW ASSETS,0.9563356164383562,"13. New Assets
955"
NEW ASSETS,0.9571917808219178,"Question: Are new assets introduced in the paper well documented and is the documentation
956"
NEW ASSETS,0.9580479452054794,"provided alongside the assets?
957"
NEW ASSETS,0.958904109589041,"Answer: [NA]
958"
NEW ASSETS,0.9597602739726028,"Justiﬁcation: We do not include a new code with the initial submission, as it is not yet
959"
NEW ASSETS,0.9606164383561644,"properly packaged at submission time, but we deﬁnitely intend to release this open-source
960"
NEW ASSETS,0.961472602739726,"code including proper annotation and userguide with the ﬁnal camera-ready version of the
961"
NEW ASSETS,0.9623287671232876,"paper.
962"
NEW ASSETS,0.9631849315068494,"Guidelines:
963"
NEW ASSETS,0.964041095890411,"• The answer NA means that the paper does not release new assets.
964"
NEW ASSETS,0.9648972602739726,"• Researchers should communicate the details of the dataset/code/model as part of their
965"
NEW ASSETS,0.9657534246575342,"submissions via structured templates. This includes details about training, license,
966"
NEW ASSETS,0.9666095890410958,"limitations, etc.
967"
NEW ASSETS,0.9674657534246576,"• The paper should discuss whether and how consent was obtained from people whose
968"
NEW ASSETS,0.9683219178082192,"asset is used.
969"
NEW ASSETS,0.9691780821917808,"• At submission time, remember to anonymize your assets (if applicable). You can either
970"
NEW ASSETS,0.9700342465753424,"create an anonymized URL or include an anonymized zip ﬁle.
971"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9708904109589042,"14. Crowdsourcing and Research with Human Subjects
972"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9717465753424658,"Question: For crowdsourcing experiments and research with human subjects, does the paper
973"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9726027397260274,"include the full text of instructions given to participants and screenshots, if applicable, as
974"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.973458904109589,"well as details about compensation (if any)?
975"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9743150684931506,"Answer: [NA]
976"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9751712328767124,"Justiﬁcation: The paper does not involve crowdsourcing nor research with human subjects
977"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.976027397260274,"Guidelines:
978"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9768835616438356,"• The answer NA means that the paper does not involve crowdsourcing nor research with
979"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9777397260273972,"human subjects.
980"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.978595890410959,"• Including this information in the supplemental material is ﬁne, but if the main contribu-
981"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9794520547945206,"tion of the paper involves human subjects, then as much detail as possible should be
982"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9803082191780822,"included in the main paper.
983"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9811643835616438,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
984"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9820205479452054,"or other labor should be paid at least the minimum wage in the country of the data
985"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9828767123287672,"collector.
986"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9837328767123288,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
987"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9845890410958904,"Subjects
988"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.985445205479452,"Question: Does the paper describe potential risks incurred by study participants, whether
989"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9863013698630136,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
990"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9871575342465754,"approvals (or an equivalent approval/review based on the requirements of your country or
991"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.988013698630137,"institution) were obtained?
992"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9888698630136986,"Answer: [NA]
993"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9897260273972602,"Justiﬁcation: The paper does not involve crowdsourcing nor research with human subjects.
994"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.990582191780822,"Guidelines:
995"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9914383561643836,"• The answer NA means that the paper does not involve crowdsourcing nor research with
996"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9922945205479452,"human subjects.
997"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9931506849315068,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
998"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9940068493150684,"may be required for any human subjects research. If you obtained IRB approval, you
999"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9948630136986302,"should clearly state this in the paper.
1000"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9957191780821918,"• We recognize that the procedures for this may vary signiﬁcantly between institutions
1001"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9965753424657534,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
1002"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.997431506849315,"guidelines for their institution.
1003"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9982876712328768,"• For initial submissions, do not include any information that would break anonymity (if
1004"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9991438356164384,"applicable), such as the institution conducting the review.
1005"
