Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.006329113924050633,"In this work, we build a knowledge graph that captures key attributes of content and
notiﬁcations in a digital health platform for diabetes management. We propose a Deep
Neural Network-based recommender that uses the knowledge graph embeddings to
recommend health nudges for maximizing engagement by combating the cold-start
and sparsity problems. We use a leave-one-out approach to evaluate the model. We
compare the proposed model performance with a text similarity and Deep-and-Cross
Network-based approach as the baseline. The overall improvement in Click-Through-
Rate prediction AUC for the Knowledge-Graph-based model was 11%. We also
observe that our model improved the average AUC by 5 % in cold-start situations."
INTRODUCTION,0.012658227848101266,"1
INTRODUCTION"
INTRODUCTION,0.0189873417721519,"The recent global pandemic has brought with it a permanent shift away from traditional in-person health
consultations, towards large digital telehealth platforms that support remote consults. This research
is performed in the context of one such platform that provides a mobile application to help people
manage chronic diseases such as diabetes, hypertension and obesity. As solution designers, some of
the key problems we face is to get our users’ attention, foster awareness and encourage them to take
actions that help manage their chronic health conditions. Sending notiﬁcations that nudge users is one
efﬁcient way to encourage engagement. However, user preferences for engaging with these nudges
can vary greatly, different users require different persuasion techniques. Even within a homogeneous
messaging context, different tones in messages can appeal to different users."
INTRODUCTION,0.02531645569620253,"Recommendation systems can be applied to model preference patterns and predict effective personalized
nudge notiﬁcations. Collaborative recommender systems are well established tools for predicting user
preference and have been shown to perform very well, provided there is sufﬁcient information available
to model the users preferences, as highlighted by seminal papers in the ﬁeld such as Resnick et al.
(1994). For new or esoteric items, or users, there is frequently a lack of sufﬁcient information to
make a good prediction. These conditions, known in the literature as ’cold start’ are the focus of our
experiments in this paper. Speciﬁcally in the context of recommending health nudges, which are created
by experts who inherently follow guidelines set by associations such as American Diabetes Association
ame (2021). Our primary research question asks whether a knowledge graph can be applied to mitigate
cold start problems, in the speciﬁc task of recommending a ﬁnite set of highly structured health nudge
messages."
KNOWLEDGE GRAPH-BASED RECOMMENDATION,0.03164556962025317,"1.1
KNOWLEDGE GRAPH-BASED RECOMMENDATION"
KNOWLEDGE GRAPH-BASED RECOMMENDATION,0.0379746835443038,"Online content and services have undergone a huge volume of growth in recent years. Accordingly,
recommender systems are increasingly relied upon to help people get to the right information at the
right time and also in the right way [Ricci et al. (2011)]. They help customers shorten their times
exploring products or services in various applications such as news portals [Wang et al. (2018b)],
E-commerce [Zhang & Jiao (2007), Hwangbo et al. (2018)], accommodations [Haldar et al. (2019)],
or music recommendation [Van Den Oord et al. (2013)]. However, our problems are different from
these recommendation applications. First, in other applications like E-commerce, users can see a list
of products and select their interested items. They can visit websites to search for items of interests
anytime they like. In our nudge notiﬁcations, our users can just see one nudge at a time, and hence
we cannot ﬂush a lot of nudges as it will disturb our users and can negatively impact their level
of engagement. Hence, recommending the nudges that match user preferences while also ensuring
that there is a diversity in the actions we are recommending, and achieving good performance in
as few notiﬁcations as possible is a crucial requirement in this setting. Also, we frequently need to"
KNOWLEDGE GRAPH-BASED RECOMMENDATION,0.04430379746835443,Under review as a conference paper at ICLR 2022
KNOWLEDGE GRAPH-BASED RECOMMENDATION,0.05063291139240506,"support the creation of new nudges. Within this setting, using embeddings from supervised learning
methodologies may not be able to solve our problems. To learn efﬁcient embeddings from those
approaches, we require a lot of data for each item. Organizing and aggregating nudge attributes such as
themes, tones or objectives can help the cold-start problem as we can transfer the knowledge of user
preferences on nudge attributes to new nudges and help us understand and optimize to user behaviors
quickly. For example, if a user has positive responses to encouragement-tone nudges, we can send
more encouragement-tone based messages to this user."
KNOWLEDGE GRAPH-BASED RECOMMENDATION,0.056962025316455694,"Knowledge graphs (KG) have been applied in various tasks such as search engines [Yang et al. (2017)],
text classiﬁcation [Hu et al. (2021)] and word embedding [Celikyilmaz et al. (2015)]. They have also
been previously introduced to recommendation systems to improve the precision of recommended
items and the explainability [Wang et al. (2019)]. A knowledge graph is a directed heterogeneous graph
representing real-world objects and relationship among these objects. Nodes in a KG represent entities,
which can be items or the attributes that describe the item. The edges represent relations between
each entity. Knowledge graphs give recommendation systems the beneﬁt of enriching the semantic
relationships among items [Wang et al. (2019)]. When we know users’ interests in a KG graph, we can
extend the diversity of recommended items from the node connections present in the graph."
KNOWLEDGE GRAPH-BASED RECOMMENDATION,0.06329113924050633,"Our problem domain is selecting nudge notiﬁcations for our mobile applications that are personalized
to individual users preferences. We have different types of nudge notiﬁcations such as alerting users
in regards to their health condition, reminding users to follow their health routine, providing some
useful education related to their health, or introducing new services and events to users. We want to
personalize nudges to each user to increase their engagement and reduce over-sending nudges that
might disturb the users. The contributions of this work are summarized as follows:"
KNOWLEDGE GRAPH-BASED RECOMMENDATION,0.06962025316455696,"• We propose a new method using a neural network that combines user attributes with a
knowledge graph to overcome the cold-start problem."
KNOWLEDGE GRAPH-BASED RECOMMENDATION,0.0759493670886076,"• We conduct experiments demonstrating the effectiveness of our new approach, particularly
under cold-start conditions."
DIGITAL HEALTH SYSTEM FOR DIABETES SELF-CARE,0.08227848101265822,"1.2
DIGITAL HEALTH SYSTEM FOR DIABETES SELF-CARE"
DIGITAL HEALTH SYSTEM FOR DIABETES SELF-CARE,0.08860759493670886,"This work is based on a system that leverages a Blood-Glucose (BG) monitoring device, and a Mobile
App that is used to provide useful information and suggest actions to users that are relevant and helpful
for managing Diabetes. As a part of this system, users are provided with short text messages, about 180
characters long. The text is designed to nudge a user to speciﬁc actions that are relevant to managing
the condition, such as, healthy recipes ideas, articles that explain and motivate users to add exercise to
their routine, reminders to check and monitor BG levels, talking to expert coaches etc."
DIGITAL HEALTH SYSTEM FOR DIABETES SELF-CARE,0.0949367088607595,"The short text is accompanied with two buttons, one of which is used to guide the target user to perform
a speciﬁc action (e.g. read content, schedule a call with a coach), and the other can be used to dismiss
the recommendation. In this work we call these recommendations on the Mobile-App, Mobile Nudges
(or Nudges for short)."
RELATED WORK,0.10126582278481013,"2
RELATED WORK"
RECOMMENDER SYSTEMS IN DIGITAL HEALTH,0.10759493670886076,"2.1
RECOMMENDER SYSTEMS IN DIGITAL HEALTH"
RECOMMENDER SYSTEMS IN DIGITAL HEALTH,0.11392405063291139,"Over the past decade, a rapidly increasing volume of digital information to support clinical decision
making has become available to be leveraged by healthcare recommender systems. Automated health
recommender systems have been deployed in various domains. Some applications aim for improving
lifestyle to be healthier through diet [Elsweiler et al. (2017), Achananuparp & Weber (2016)] or physical
activity recommendations [Dharia et al. (2016)]. One such system, known as Pro-ﬁt [Dharia et al.
(2016)] applies a hybrid approach to personalize workout sessions based on a user’s contextual data
and calendar events. Achananuparp & Weber (2016) proposed a healthier food substitute suggestion
system by introducing a food-context matrix and applying Singular Value Decomposition to get the
low-dimensional representation of each food item. The similarity between two food items is measured
by cosine similarity. Narducci et al. (2015) introduced an HealthNet to personalize doctors and hospitals
to users, given the user proﬁle and the health data shared by the community. The iDoctor system in
Zhang et al. (2017b) provides doctor recommendations by using sentiment analysis from their rating
and reviews and Latent Dirichlet Allocation for user preference and doctor features. The hybrid matrix
factorization is applied to predict the doctor rating."
RECOMMENDER SYSTEMS IN DIGITAL HEALTH,0.12025316455696203,Under review as a conference paper at ICLR 2022
RECOMMENDER SYSTEMS IN DIGITAL HEALTH,0.12658227848101267,"Recommendation systems have also been used for optimizing treatment plan such as drug recom-
mendation [Zhang et al. (2017a), Stark et al. (2017)]. Zhang et al. (2017a) applied the concept of
neighborhood-based method in a drug-drug interaction prediction to help reduce unexpected effects
from using multiple drugs. A drug recommendation system for Migraine diseases proposed by Stark
et al. (2017) using a graph database and collaborative ﬁltering approach."
KNOWLEDGE GRAPH EMBEDDING,0.13291139240506328,"2.2
KNOWLEDGE GRAPH EMBEDDING"
KNOWLEDGE GRAPH EMBEDDING,0.13924050632911392,"Knowledge graph embedding (KGE) is a process to transform a knowledge graph into low-dimensional
continuous vector space which still preserves the network structure information. The knowledge graph
can be represented as a group of triplets, each of which contains two nodes (items or attributes) and
the relationship between these nodes. With these triples KGE will project all entities and relations
into a low dimensional vector space that preserves their graph structure in these vector representations.
There are several approaches for building these representations in the KGE setting. Translation distance
models such as TransE [Bordes et al. (2013)], TransH [Wang et al. (2014)], TransR [Lin et al. (2015)]
and semantic matching models such as DistMult [Yang et al. (2014)] are some of the popular methods."
KNOWLEDGE GRAPH EMBEDDING IN RECOMMENDATION SYSTEMS,0.14556962025316456,"2.3
KNOWLEDGE GRAPH EMBEDDING IN RECOMMENDATION SYSTEMS"
KNOWLEDGE GRAPH EMBEDDING IN RECOMMENDATION SYSTEMS,0.1518987341772152,"Knowledge graphs have been applied to many recommendation applications. Wang et al. (2018a)
proposed the RippleNet, an end-to-end recommendation framework that incorporates knowledge graph
into recommendation systems. RippleNet extends user interest of items through links in the knowledge
graph which help increasing the diversity. Wang et al. (2018b) introduced Deep Knowledge-aware
Network (DKN) for news recommendation. The key component of DKN is knowledge-aware convo-
lutional neural network (KCNN) for incorporating word-level and knowledge-level representations.
Zhang et al. (2018) extends a collaborative ﬁltering framework to learn over the knowledge graph
embedding. A user-item graph is used, where each connection between nodes depicts how a user
interacted with an item, for example (buy, also bought, also view)
Another method for using a knowledge graph in a recommenation system is path-based approach,
which uses the connection patterns in the knowledge graph to generate the recommendation. Hete-CF
[Luo et al. (2014)], a collaborative ﬁltering recommendation method on Heterogeneous Social Network,
which combines different types of meta-paths (user-user, user-item and item-item) and calculates the
similarity. Yu et al. (2014) introduced HeteRec which represents the connectivity between users and
items with meta path-based latent features. HeteRec recommendation models are further deﬁned
into two levels: global (HeteRec-g) and personalized (HeteRec-p) levels. In the HeteRec-p, users
are clustered based on their interests and preferences into subgroups and then learn recommendation
models for each user subgroup."
PROBLEM FORMULATION,0.15822784810126583,"3
PROBLEM FORMULATION"
PROBLEM FORMULATION,0.16455696202531644,"Our nudge recommendation can be seen as a binary classiﬁcation problem where we try to predict
the probability that a user will have a positive engagement with a nudge (i.e. accepted the action or
suggestion provided by the nudge). Let U = {u1, u2, ... } and V = {v1, v2, ... } denote the sets of
users and nudges respectively. A user-item interactive matrix is deﬁned as Y = {yu,v|u ∈U, v ∈V }
where"
PROBLEM FORMULATION,0.17088607594936708,"yu,v =
1
if the user u positively engaged with the nudge v
0
otherwise
(1)"
PROBLEM FORMULATION,0.17721518987341772,"We want our model to learn and predict a probability of ui will click on the nudge vj or ˆyui,vj =
f(ui, vj)."
METHODOLOGY,0.18354430379746836,"4
METHODOLOGY"
METHODOLOGY,0.189873417721519,"Our approach to nudge recommendation is based on a combination of item and user-based collaborative
ﬁltering. In our model, a user is represented as a triple u ∈d, i, a where d is the a set of demographic
proﬁle information such as age and gender; i is the set of clicks on nudges, and a is the set of attributes
of the nudges that were effective in engaging that user. The objective is to transform users and items
(in our case, nudges) into a vector space and make a prediction based on similarity in the latent space.
To learn an embedding of a user proﬁle, we rely on their click history. This information helps us to
passively infer preferences based on how they interacted with nudges in the past. If a candidate item"
METHODOLOGY,0.1962025316455696,Under review as a conference paper at ICLR 2022
METHODOLOGY,0.20253164556962025,"is similar to a user’s history of clicked nudges, it is likely that a user will also like this nudge too.
However, using only a proﬁle of click history has signiﬁcant limitations and can result in a narrow
set of recommended items, lacking in diversity –essentially a similar narrowness problem to that
of a traditional content-based recommender system. To mitigate this problem, which is particularly
apparent in cold-start conditions where there are less click data available, we proposed a novel use
of “nudge attribute” preferences to user embeddings. Attributes of recommended nudges effectively
extend a user’s preference proﬁle by creating new edges to explore in the item-to-item graph. Even
for a completely new user with no click history, we can infer nudge attribute preferences from the
demographic proﬁle until preference data becomes available through click interactions."
METHODOLOGY,0.2088607594936709,"The model training occurs in two parts. We ﬁrst train knowledge graph embeddings to generate nudge,
nudge attributes and relation type embeddings. Next, we construct a deep neural network model to
predict the click-through rate (CTR) probability of a user ui on a nudge vj. The user embeddings eui
(section 4.2.1) are constructed by combining the user click history embeddings hui, nudge attribute
preference embeddings nui and user proﬁle embeddings pui. To learn nudge attribute preference
embeddings, we apply the concept of attention mechanism Vaswani et al. (2017) to get a set of values
for our attention-based network layer. A nudge prediction is then calculated from a function of eui and
evj where evj is an embedding of nudge vj."
KNOWLEDGE GRAPH FOR DIABETES SELF-CARE,0.21518987341772153,"4.1
KNOWLEDGE GRAPH FOR DIABETES SELF-CARE"
KNOWLEDGE GRAPH FOR DIABETES SELF-CARE,0.22151898734177214,"We evaluate our proposed models for CTR prediction on our mobile nudge dataset, which we described
in Section 1.2. The actions suggested to the users in the nudges cover themes such as monitoring their
blood glucose level, improving physical activity, adhering to medication etc. These actions may have
different levels of effort to complete. For example, requesting a healthy recipe might be done directly
on the mobile application, while talk to a coach or an expert might require the user to ﬁnd an available
time and schedule. We also have nudges that might recommend the same action but use a different
tone in the communication text. Furthermore, the nudges can also be categorized based on the intent of
support the nudges are be providing, such as providing knowledge or requesting preferences through
short questions. We use such categorizations that are used to create new nudges for the users as the
attributes for the nudges. These attributes capture not only the theme and intent of the nudge but also
some information around the experience accessing the working on the action recommended by nudge.
Table A shows seven attribute types with descriptions and examples values relating to a nudge “In a
dinner rut? Our meal plan is packed with tasty, colorful, and super-healthy recipes, Want it?”. These
attributes and the associated values have been developed by working with the business and subject
matter experts."
KNOWLEDGE GRAPH FOR DIABETES SELF-CARE,0.22784810126582278,"Figure 3 shows two example health nudges with their associated, and sometimes overlapping attributes.
The full set of nudges and attributes in our library are used to deﬁne a graph that becomes the initial
input to the CareGraph recommender system. The nudges and the attribute values form the nodes
of the graph, as highlighted in Figure 3. For example, the blood-glucose monotoring nudge and
the holiday nutrition nudge both share the attribute that they send a user to a website for additional
information, and that they foster broad awareness of the chronic health condition. More formally,
the attribute types are the relations that deﬁne the edges of the graph, i.e. the edge describes how a
nudge is related to the attribute. This can be represented in a form of triples (h, r, t) where h is the
nudge (head), r is the attribute type (relation) and t is the attribute value (tail). For example, if a nudge
CGM CONTENT BGM COMPARE has monitoring as the theme, then this relationship is
represented as CGM CONTENT BGM COMPARE
theme
−−−→monitoring, and forms the triplet
(CGM CONTENT BGM COMPARE, theme, monitoring).
While this is a useful representation for the structure with which nudges are created and described, it
will be beneﬁcial to develop continuous representations that can be used for training a recommender
model. These representations are called knowledge graph embeddings, and are described in Section
2.2. There are various algorithms that can be used develop these embeddings. Given the relatively
simple structure of the graph and the simplicity of the algorithm we use the standard TransE algorithm
[Bordes et al. (2013)] in our methodology."
CAREGRAPH MODEL,0.23417721518987342,"4.2
CAREGRAPH MODEL"
CAREGRAPH MODEL,0.24050632911392406,"The CareGraph model, shown as a ﬂow diagram in Figure 1 is trained in two phases. We ﬁrst train
knowledge graph embeddings for nudges, nudge attributes and attribute types embeddings. Next we"
CAREGRAPH MODEL,0.2468354430379747,Under review as a conference paper at ICLR 2022
CAREGRAPH MODEL,0.25316455696202533,Figure 1: CareGraph model architecture.
CAREGRAPH MODEL,0.25949367088607594,"construct a deep neural network model to predict the CTR probability for a target user ui on a nudge vj.
The user embeddings eui (section 4.2.1) are constructed by combining user click history embeddings
hui, nudge attribute embeddings nui and user proﬁle embeddings pui. The prediction is calculated
from a function of eui and evj where evj is an embedding of nudge vj."
USER EMBEDDING,0.26582278481012656,"4.2.1
USER EMBEDDING"
USER EMBEDDING,0.2721518987341772,"User click history embedding
A user’s click history helps us understand which nudges the user
liked in the past. We gather all clicked nudges that the user ui clicked in the past and construct a
click history list nudge histui where nudge histui = {vk|vk ∈V, yui,vk = 1}. For users who have
never clicked on any nudge, their click history will be an empty list. To represent nudge histui as a
embedding vector hui, we use embedding vectors for all vk ∈nudge histu from our knowledge graph
embeddings and use the equation 2 to aggregate them."
USER EMBEDDING,0.27848101265822783,hui = Wm(
USER EMBEDDING,0.2848101265822785,"P
vk∈nudge histui evk
∥nudge histui∥
) + bm
(2)"
USER EMBEDDING,0.2911392405063291,"where evk is an embedding vector of the nudge vk from the knowledge graph embedding. In the
equation 2, we ﬁrst average all embeddings in nudge histui and apply a linear function where Wm
and bm are transformation weight and bias respectively. For a user whose click history is empty, the
hm will be a zero vector."
USER EMBEDDING,0.2974683544303797,"Nudge attribute embedding
In user click history embeddings, we focus only on nudge embeddings
that the user interacted with in the past. We can leverage nudge attribute nodes to extend user preferences
by propagating to neighbor entities around users’ historical clicked nudges. Since neighbors of nudge
entity are nudge attributes entities, we refer to this as the set of attribute embeddings nui."
USER EMBEDDING,0.3037974683544304,"From a intuitive motivation that different users have different preference on nudge attributes, for exam-
ple, a user may be interested in a formal clinical information nudge than a cheerful-tone encouragement
nudge, we should use user preference weights on nudge attributes instead of averaging them directly as
in equation 2. Given a set of nudge attributes and their relation types, we apply the concept of attention
mechanism Vaswani et al. (2017) to learn user preference weights of each nudge attribute.
Considering an nudge entity h in the knowledge graph where its connections are represented in
the form of (h, r, t), The set of neighbor entities, or nudge attributes, of a user ui is Nui = {t|h ∈
nudge histui, (h, r, t) ∈kg} and the relation types Rui = {r|h ∈nudge histui, (h, r, t) ∈kg}.
For a user whose click history list is empty, we randomly select a set of nudge attribute entities. The
embedding aggregation of nudge attributes can be formulated as"
USER EMBEDDING,0.310126582278481,Under review as a conference paper at ICLR 2022
USER EMBEDDING,0.31645569620253167,"eNui =
X"
USER EMBEDDING,0.3227848101265823,"ni∈Nui
αieni
(3)"
USER EMBEDDING,0.3291139240506329,"Where α = (α1, α2, ...αi) is an attention weight vector. We calculate the vector α from user proﬁle
features gui of the user u by the following formula:"
USER EMBEDDING,0.33544303797468356,"αi =
eT
ri(Wrgu + br)
P"
USER EMBEDDING,0.34177215189873417,"rj∈Rui eTrj(Wrgu + br)
(4)"
USER EMBEDDING,0.34810126582278483,"The Wr and br a transformation matrix and bias respectively. It will transform the user proﬁle feature
gu into the r vector space and then perform the inner product with the embedding vector eri of the
attribute type ri. A softmax function is used to compute user relation type preference weights, and then
the ﬁnal nudge attribute embedding nu is calculated from this equation:
nui = WneNui + bn
(5)"
USER EMBEDDING,0.35443037974683544,"User proﬁle embedding
We also include explicit user features into the user embedding. All user raw
data is transformed into a user feature vector and then apply a function to get the ﬁnal representation.
pui = Wpgui + bp
(6)"
USER EMBEDDING,0.36075949367088606,"Information Aggregation
The last step to get the ﬁnal embedding of the user ui is by combining
user history embedding hui from equation 2, nudge attribute embedding nui from equation 5, and user
proﬁle embedding pui from equation 6. We concatenate all three embeddings and transform it by a
linear function to get the ﬁnal user embedding eui.
oui = hui ⊕nui ⊕pui
(7)"
USER EMBEDDING,0.3670886075949367,"eu = Wuoui + bu
(8)"
MODEL PREDICTION,0.37341772151898733,"4.3
MODEL PREDICTION"
MODEL PREDICTION,0.379746835443038,"To calculate the probability that the user ui will click on the nudge vj. We use the ﬁnal user embedding
eui from equation 8 and nudge embedding evj of the nudge vj from knowledge graph embedding. We
predict a user engagement score from the matching score by"
MODEL PREDICTION,0.3860759493670886,"ˆy(ui, vj) = σ(eT
ui(Wvevj + bv))
(9)"
MODEL PREDICTION,0.3924050632911392,"where σ is a nonlinear function, similar to the sigmoid function. We can see from the equation 9, the
CTR prediction of user ui and nudge vj, ˆy(ui, vj), is dependant on how similar the user embedding
eui is to the nudge embedding evj."
CAREGRAPH WITH TEXT EMBEDDING,0.3987341772151899,"5
CAREGRAPH WITH TEXT EMBEDDING"
CAREGRAPH WITH TEXT EMBEDDING,0.4050632911392405,"The CareGraph model supports addition of new features such as text embeddings. A basic nudge is a
short text message, and we can aggregate these embeddings into the model to improve its performance.
Here the premise is that text similarity across the broader library of nudges can be leveraged to improve
the relevance of nudges for a target user. In this section, we introduce two such extensions of the base
model architecture: CareGraph + TextSim and CareGraph+TextEmbedding."
CAREGRAPH WITH TEXT EMBEDDING,0.41139240506329117,"CareGraph+TextSim
The approach taken in this model stems from our intuitive assumption that if
a text message of a nudge vj is similar to contents in historical clicked nudges of user ui, it will be
likely that a user ui will also like the nudge vj. With this assumption, we add text similarity score
at the prediction step. The other parts of model are still the same. The text similarity score tvj is be
calculated by equation 10 tvj = P"
CAREGRAPH WITH TEXT EMBEDDING,0.4177215189873418,"hk∈nudge histui dist(xhk, xvj)"
CAREGRAPH WITH TEXT EMBEDDING,0.4240506329113924,"|nudge histui|
(10)"
CAREGRAPH WITH TEXT EMBEDDING,0.43037974683544306,"where xv is a text embedding of the nudge v and dist is a distance function of text embedding, such as
cosine similarity. The CTR prediction score in equation 9 will be replaced with"
CAREGRAPH WITH TEXT EMBEDDING,0.43670886075949367,"ˆy(ui, vj) = σ(w1eT
uievj + w2tvj)
(11)"
CAREGRAPH WITH TEXT EMBEDDING,0.4430379746835443,Under review as a conference paper at ICLR 2022
CAREGRAPH WITH TEXT EMBEDDING,0.44936708860759494,"CareGraph+TextEmb
Another way to include text embedding into the CareGraph model is to
include them as part of the user embedding eu in equation 7 and 8 and nudge embedding in evj."
CAREGRAPH WITH TEXT EMBEDDING,0.45569620253164556,We ﬁrst get text embeddings of all nudges in nudge histui and aggregate them by simple averaging. qui = P
CAREGRAPH WITH TEXT EMBEDDING,0.4620253164556962,vk∈nudge histui xvk
CAREGRAPH WITH TEXT EMBEDDING,0.46835443037974683,"|nudge histui|
(12)"
CAREGRAPH WITH TEXT EMBEDDING,0.47468354430379744,"tui = Wtqut + bt
(13)"
CAREGRAPH WITH TEXT EMBEDDING,0.4810126582278481,"To include text embedding tui into user embedding eu, we update the equations 7 as follow:
oui = hui ⊕nui ⊕pui ⊕tui
(14)
and then calculate the ﬁnal eu in 8. In the equation 9, we add text embedding of the nudge vj into evj
by"
CAREGRAPH WITH TEXT EMBEDDING,0.4873417721518987,"ˆy(ui, vj) = σ(eT
ui(Wv(evj ⊕xvj) + bv))
(15)"
EXPERIMENT SETUP,0.4936708860759494,"6
EXPERIMENT SETUP"
EXPERIMENT SETUP,0.5,"The data used for this analysis consists of interactions from 283,743 unique users. As mentioned in
the description of the Nudges system, the nudge consists on two buttons, one for taking the suggested
action and the other for dismissing the Nudge. For the purpose of this analysis a user accepting the
recommended nudge is considered a positive rating or a click. The data has been collected from
283,743 users over a period of 12 months, and have an average Click-Through-Rate (CTR) of 16.77%."
PROCEDURE,0.5063291139240507,"6.1
PROCEDURE"
PROCEDURE,0.5126582278481012,"In order to determine the performance of the proposed model two distinct cases are considered. In the
ﬁrst case we evaluate the improvement in predicting the click behavior across all users and all available
Nudges in the data. In the second case, the performance of the model is evaluated in Cold-Start cases.
Speciﬁcally, the case when new Nudges are added is simulated by leaving one nudge out in the training
data and determining the performance in predicting the click behavior for that Nudge. This is a typical
situation that is encountered in practice where new content and nudges are created and it is important
to direct them to most receptive users in a timely fashion. The performance of the proposed model in
both cases is compared to a Deep and Cross baseline model, as described below."
BASELINE MODEL FOR PERFORMANCE EVALUATION,0.5189873417721519,"6.1.1
BASELINE MODEL FOR PERFORMANCE EVALUATION"
BASELINE MODEL FOR PERFORMANCE EVALUATION,0.5253164556962026,"A Deep and Cross Network (DNC), similar to Wang et al. (2021) is used as the baseline model to
predict the click on the Nudge. The DCN model starts with an embedding and a stacking layer to
transform categorical features into a dense vector. A Cross Network and a Deep Network work in
parallel and their output is combined in the last layer. The Cross Network is composed of cross layers
which applied feature crossing at each layer. A cross layer is to calculate this following function:"
BASELINE MODEL FOR PERFORMANCE EVALUATION,0.5316455696202531,"wl+1 = x0xT
l wl + bl + xl = f(xl, wl, bl) + xl
(16)"
BASELINE MODEL FOR PERFORMANCE EVALUATION,0.5379746835443038,"where xl, xl+1 ∈Rd is the output vector at the layer l-th and l + 1-th layer, respectively. The x0 is the
embedding vector from the embedding and stacking layer. By adding more cross layers into the cross
network, it increases the polynomial degree of the input x0."
BASELINE MODEL FOR PERFORMANCE EVALUATION,0.5443037974683544,"The deep network is a standard fully-connected feed-forward neural network. For each layer, the output
of the subsequent layer l + 1 is calculated by:"
BASELINE MODEL FOR PERFORMANCE EVALUATION,0.5506329113924051,"hl+1 = f(Wlhl + bl)
(17)"
BASELINE MODEL FOR PERFORMANCE EVALUATION,0.5569620253164557,"where Wl is a weight matrix and bl is the bias of the layer l. The ﬁnal output of the deep network
is an embedding vector hL where L denotes the total number of deep layers. The prediction step is
performed by concatenating the outputs from the cross network and the deep network and feeding them"
BASELINE MODEL FOR PERFORMANCE EVALUATION,0.5632911392405063,Under review as a conference paper at ICLR 2022
BASELINE MODEL FOR PERFORMANCE EVALUATION,0.569620253164557,Table 1: The AUC results of nudge CTR prediction in a general case
BASELINE MODEL FOR PERFORMANCE EVALUATION,0.5759493670886076,"Approach
AUC
Deep-and-cross model
0.6421
Caregraph model
0.7142
Caregraph+TextSim model
0.7156
Caregraph+TextEmb model
0.7113"
BASELINE MODEL FOR PERFORMANCE EVALUATION,0.5822784810126582,"to the logit layer. The sigmoid function is used to calculate the ﬁnal prediction on how likely the user is
to engage with the recommended nudge."
TRAINING THE CAREGRAPH MODEL,0.5886075949367089,"6.2
TRAINING THE CAREGRAPH MODEL"
TRAINING THE CAREGRAPH MODEL,0.5949367088607594,"We trained our knowledge graph embeddings for all nudges, nudge attributes and attribute types
(relation types). The embedding sizes e in the knowledge graph embedding are set to 100. We use
the pretrained Universal Sentence Encoder from Tensorﬂow Hub (https://www.tensorﬂow.org/hub) to
extract the text embeddings."
TRAINING THE CAREGRAPH MODEL,0.6012658227848101,"We use Adam to train both of our recommendation models and the deep-and-cross model by optimizing
log loss. We apply hyper-parameters search for knowledge graph embedding size, hidden layer units
and L2 regularization. The hidden layer in equation 2, 5 and 8 are set to 24 dimensions. For the deep
and cross model, the ﬁnal model architecture is two hidden layers with 240 and 48 dimensions in a
deep network and 2 cross layers in the cross network. To evaluate recommendation results with the
deep-and-cross model, we use AUC as the evaluation metric."
RESULTS,0.6075949367088608,"6.3
RESULTS"
RESULTS,0.6139240506329114,We evaluate our proposed model with the baseline model in a general case and cold-start situations.
RESULTS,0.620253164556962,"General case
This objective of this experiment is to compare recommendation results of our proposed
models with the baseline model in a overall case. We split the training, validation and testing data into
60:10:30 respectively. We compared AUC from our three proposed models: CareGraph (section 4.2),
CareGraph+TextSim (section 5) and CareGraph+TextEmb (section 5) with the deep-and-cross model.
The results are shown in Table 1.
From the table 1, all CareGraph approaches outperform a deep-and-cross model. We have tried two
different model architectures that integrate text information into our CareGraph model. Our initial
hypothesis was that the text embeddings would improve recommendation accuracy because similarity
could be computed on more underlying data. However, results showed that this was not the case.
AUC did not improve in the text-enabled treatments. A possible reason for this unexpected result
is that the kg-embeddings may have already captured enough information to generate high quality
predictions. Further studies of model architectures CareGraph with text may be required to prove that
this generalizes to all integrations of text similarity to the model."
RESULTS,0.6265822784810127,"Cold start experiments
We simulated cold-start cases by using a leave-one-out approach. Among
155 nudges, one nudge is selected as testing data and keep the the rest nudges for training. We repeated
this process for all 155 nudges and compare all AUC with the baseline. In this experiment, we compare
our CareGraph model with the baseline model. For the baseline approach, since the deep-and-cross
model cannot learn the nudge embedding for new nudge in the training process, we use the prediction
results of the most text-based similarity nudge in the training data for a new nudge. In average, our
approach has 61.76% AUC and the baseline approach have 58.17% AUC. Our model outperform the
baseline model for 96 nudges out of 155 nudges. The distribution of AUC over all nudges shows in
Figure 2."
RESULTS,0.6329113924050633,"Cold start analysis
The main objective of using a knowledge graph embedding is to overcome the
cold-start and data sparsity problems. A key question in this research is whether knowledge graph
embeddings of nudges, nudge attributes, and attribute types capture enough information for new nudge
prediction. If we have a new nudge that is different from existing nudges, how that will impact to
prediction performance?
In the cold-start experiment, we compare the prediction results with a text-based similarity approach.
Text-similarity based approach is heavily depends on existing nudges in the training dataset. If a text
message of new nudge has different meaning from the existing nudges, the prediction result can be"
RESULTS,0.6392405063291139,Under review as a conference paper at ICLR 2022
RESULTS,0.6455696202531646,Text similarity to the nearest nudge
RESULTS,0.6518987341772152,"approach
< 0.5
≥0.5
our CareGraph
0.6176
0.6127
deep-and-cross model
0.5816
0.5822"
RESULTS,0.6582278481012658,"Figure 2: Left: The distributions of AUC, and the distribution w.r.t text similarity ."
RESULTS,0.6645569620253164,"less precise. In our mobile application, it is very likely that we will develop new content. For the
knowledge graph embeddings based approach, the embeddings of each nudge preserve connection
structures with other entities. Even when we have a new nudge from a new service or program, as long
as there are shared attributes with existing nudges, the kg-embedding of new nudge will be not be too
far away from existing nudges in the vector space. Also, by adding our nudge attribute embedding nui
in Equation 5 into the user embedding eui, this embedding will show how this new nudge is similar to
user attribute preferences.
In Figure 2, we compare the AUC distributions of CareGraph and the text-based similarity deep-and-
cross approaches over the text distance. The x-axis shows the nearest text cosine-similarity of each new
nudge to existing nudges. A lower distance means a new nudge content is different from its nearest
existing nudge. At the text distances ranging between 0.4 and 0.6, there is a group of nudges that the
baseline approach has lower AUC than our proposed approach. Also, if we consider the AUC results
of nudges whose nearest text cosine similarity is less than 0.5, our approach improves the AUC by
6.17% and 5.24% for greater than or equal to 0.5. This result shows that we improve AUC more if a
new nudge has more different content than existing nudges."
FUTURE WORK AND CONCLUSION,0.6708860759493671,"7
FUTURE WORK AND CONCLUSION"
FUTURE WORK AND CONCLUSION,0.6772151898734177,"This research produced several avenues for future work, including analysing different methods to
integrate text-based similarity into the model to improve both regular performance and performance
under cold start conditions. To conclude, the primary research question in this work asked whether a
knowledge graph can be applied to mitigate cold start problems, in the speciﬁc task of recommending a
ﬁnite set of highly structured health nudge messages. To facilitate this we developed a novel knowledge
graph based recommender system, which we called CareGraph, for predicting health nudges to manage
chronic disease on a large digital health platform. Our results conﬁrmed that the knowledge graph does
improve predictive accuracy in cold-start situations, showing a 5% improvement over a benchmark
model. In addition, a text-similarity based model was evaluated and it was shown that structure in the
knowledge graph produced more accurate recommendations than those based on text similarity."
REFERENCES,0.6835443037974683,REFERENCES
REFERENCES,0.689873417721519,"Introduction: Standards of medical care in diabetes—2021. Diabetes Care, 44(Supplement 1):S1–S2,
2021. ISSN 0149-5992. doi: 10.2337/dc21-Sint. URL https://care.diabetesjournals.
org/content/44/Supplement_1/S1."
REFERENCES,0.6962025316455697,"Palakorn Achananuparp and Ingmar Weber. Extracting food substitutes from food diary via distribu-
tional similarity, 2016."
REFERENCES,0.7025316455696202,Under review as a conference paper at ICLR 2022
REFERENCES,0.7088607594936709,"Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko. Trans-
lating embeddings for modeling multi-relational data. Advances in neural information processing
systems, 26, 2013."
REFERENCES,0.7151898734177216,"Asli Celikyilmaz, Dilek Hakkani-Tur, Panupong Pasupat, and Ruhi Sarikaya. Enriching word embed-
dings using knowledge graph for semantic tagging in conversational dialog systems. In 2015 AAAI
Spring Symposium Series, 2015."
REFERENCES,0.7215189873417721,"Saumil Dharia, Vijesh Jain, Jvalant Patel, Jainikkumar Vora, Shaurya Chawla, and Magdalini Eirinaki.
Pro-ﬁt: A personalized ﬁtness assistant framework. In SEKE, 2016."
REFERENCES,0.7278481012658228,"David Elsweiler, Christoph Trattner, and Morgan Harvey. Exploiting food choice biases for healthier
recipe recommendation. In Proceedings of the 40th International ACM SIGIR Conference on
Research and Development in Information Retrieval, 2017."
REFERENCES,0.7341772151898734,"Malay Haldar, Mustafa Abdool, Prashant Ramanathan, Tao Xu, Shulin Yang, Huizhong Duan, Qing
Zhang, Nick Barrow-Williams, Bradley C Turnbull, Brendan M Collins, et al. Applying deep
learning to airbnb search. In Proceedings of the 25th ACM SIGKDD International Conference on
Knowledge Discovery & Data Mining, pp. 1927–1935, 2019."
REFERENCES,0.740506329113924,"Linmei Hu, Mengmei Zhang, Shaohua Li, Jinghan Shi, Chuan Shi, Cheng Yang, and Zhiyuan Liu.
Text-graph enhanced knowledge graph representation learning. Frontiers in Artiﬁcial Intelligence, 4,
2021."
REFERENCES,0.7468354430379747,"Hyunwoo Hwangbo, Yang Sok Kim, and Kyung Jin Cha. Recommendation system development for
fashion retail e-commerce. Electronic Commerce Research and Applications, 28:94–101, 2018."
REFERENCES,0.7531645569620253,"Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu. Learning entity and relation
embeddings for knowledge graph completion.
In Twenty-ninth AAAI conference on artiﬁcial
intelligence, 2015."
REFERENCES,0.759493670886076,"Chen Luo, Wei Pang, Zhe Wang, and Chenghua Lin. Hete-cf: Social-based collaborative ﬁltering
recommendation using heterogeneous relations. In 2014 IEEE International Conference on Data
Mining, pp. 917–922, 2014."
REFERENCES,0.7658227848101266,"Fedelucio Narducci, Cataldo Musto, Marco Polignano, Marco de Gemmis, Pasquale Lops, and Giovanni
Semeraro. A recommender system for connecting patients to the right doctors in the healthnet social
network. In Proceedings of the 24th International Conference on World Wide Web, WWW ’15
Companion, pp. 81–82, 2015."
REFERENCES,0.7721518987341772,"Paul Resnick, Neophytos Iacovou, Mitesh Suchak, Peter Bergstrom, and John Riedl. Grouplens: an
open architecture for collaborative ﬁltering of netnews. In CSCW ’94: Proceedings of the 1994 ACM
conference on Computer supported cooperative work, pp. 175–186, New York, NY, USA, 1994. ACM
Press. ISBN 0-89791-689-1. URL http://dx.doi.org/10.1145/192844.192905."
REFERENCES,0.7784810126582279,"Francesco Ricci, Lior Rokach, Bracha Shapira, and Paul B. Kantor. Recommender systems handbook.
Springer, New York; London, 2011."
REFERENCES,0.7848101265822784,"Benjamin Stark, Constanze Knahl, Mert Aydin, Mohammad Samarah, and Karim O. Elish. Betterchoice:
A migraine drug recommendation system based on neo4j. In 2017 2nd IEEE International Conference
on Computational Intelligence and Applications (ICCIA), 2017."
REFERENCES,0.7911392405063291,"A¨aron Van Den Oord, Sander Dieleman, and Benjamin Schrauwen. Deep content-based music
recommendation. In Neural Information Processing Systems Conference (NIPS 2013), volume 26.
Neural Information Processing Systems Foundation (NIPS), 2013."
REFERENCES,0.7974683544303798,"Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz
Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wal-
lach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing
Systems, volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.
cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf."
REFERENCES,0.8037974683544303,Under review as a conference paper at ICLR 2022
REFERENCES,0.810126582278481,"Hongwei Wang, Fuzheng Zhang, Jialin Wang, Miao Zhao, Wenjie Li, Xing Xie, and Minyi Guo.
Ripplenet: Propagating user preferences on the knowledge graph for recommender systems. In
Proceedings of the 27th ACM International Conference on Information and Knowledge Management,
CIKM ’18, pp. 417–426. Association for Computing Machinery, 2018a. ISBN 9781450360142."
REFERENCES,0.8164556962025317,"Hongwei Wang, Fuzheng Zhang, Xing Xie, and Minyi Guo. Dkn: Deep knowledge-aware network for
news recommendation. In Proceedings of the 2018 World Wide Web Conference, WWW ’18, pp.
1835–1844. International World Wide Web Conferences Steering Committee, 2018b."
REFERENCES,0.8227848101265823,"Hongwei Wang, Miao Zhao, Xing Xie, Wenjie Li, and Minyi Guo. Knowledge graph convolutional
networks for recommender systems. corr abs/1904.12575 (2019). arXiv preprint arXiv:1904.12575,
2019."
REFERENCES,0.8291139240506329,"Ruoxi Wang, Rakesh Shivanna, Derek Cheng, Sagar Jain, Dong Lin, Lichan Hong, and Ed Chi. Dcn
v2: Improved deep cross network and practical lessons for web-scale learning to rank systems. In
Proceedings of the Web Conference 2021, WWW ’21, pp. 1785–1797, New York, NY, USA, 2021.
Association for Computing Machinery. ISBN 9781450383127. doi: 10.1145/3442381.3450078.
URL https://doi.org/10.1145/3442381.3450078."
REFERENCES,0.8354430379746836,"Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. Knowledge graph embedding by translating
on hyperplanes. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 28, 2014."
REFERENCES,0.8417721518987342,"Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. Embedding entities and relations
for learning and inference in knowledge bases. arXiv preprint arXiv:1412.6575, 2014."
REFERENCES,0.8481012658227848,"Shuo Yang, Lei Zou, Zhongyuan Wang, Jun Yan, and Ji-Rong Wen. Efﬁciently answering technical
questions—a knowledge graph approach. In Thirty-First AAAI Conference on Artiﬁcial Intelligence,
2017."
REFERENCES,0.8544303797468354,"Xiao Yu, Xiang Ren, Yizhou Sun, Quanquan Gu, Bradley Sturt, Urvashi Khandelwal, Brandon Norick,
and Jiawei Han. Personalized entity recommendation: A heterogeneous information network
approach. In Proceedings of the 7th ACM International Conference on Web Search and Data Mining,
WSDM ’14, pp. 283–292. Association for Computing Machinery, 2014. ISBN 9781450323512."
REFERENCES,0.8607594936708861,"Wen Zhang, Yanlin Chen, Feng Liu, Fei Luo, Gang Tian, and Xiaohong Li. Predicting potential
drug-drug interactions by integrating chemical, biological, phenotypic and network data. BMC
bioinformatics, 18(1):1–12, 2017a."
REFERENCES,0.8670886075949367,"Yin Zhang, Min Chen, Dijiang Huang, Di Wu, and Yong Li. idoctor: Personalized and professionalized
medical recommendations based on hybrid matrix factorization. Future Gener. Comput. Syst., 66:
30–35, 2017b."
REFERENCES,0.8734177215189873,"Yiyang Zhang and Jianxin Roger Jiao. An associative classiﬁcation-based recommendation system for
personalization in b2c e-commerce applications. Expert Systems with Applications, 33(2):357–367,
2007."
REFERENCES,0.879746835443038,"Yongfeng Zhang, Qingyao Ai, Xu Chen, and Pengfei Wang. Learning over knowledge-base embeddings
for recommendation. CoRR, abs/1803.06540, 2018. URL http://arxiv.org/abs/1803.
06540."
REFERENCES,0.8860759493670886,Under review as a conference paper at ICLR 2022
REFERENCES,0.8924050632911392,"A
KNOWLEDGE GRAPH ATTRIBUTES AND EXAMPLE"
REFERENCES,0.8987341772151899,Figure 3: An example of our knowledge graph of nudges
REFERENCES,0.9050632911392406,"Attribute Type
Description
Example Value
Theme
Top diabetes self-management cate-
gories such as healthy eating, physi-
cal activity, monitoring etc."
REFERENCES,0.9113924050632911,Nutrition
REFERENCES,0.9177215189873418,"Topics
Key topics around which nudges are
designed, such as Reducing Risk,
Education, Event participation etc."
REFERENCES,0.9240506329113924,Recipe
REFERENCES,0.930379746835443,"Action Mode
Attribute to capture the level of ef-
fort needed to complete the sugges-
tion action. e.g. Schedule a coach-
ing session, Read content on the mo-
bile application, etc."
REFERENCES,0.9367088607594937,Read/View a content
REFERENCES,0.9430379746835443,"Action Channel or Surface
Channel or destination for an re-
quired action e.g. redirect to a web-
site, go to the app, redirect to coach
scheduling channel."
REFERENCES,0.9493670886075949,Website (redirect)
REFERENCES,0.9556962025316456,"Tone
Mood of messages e.g. encourage-
ment, descriptive etc."
REFERENCES,0.9620253164556962,Descriptive
REFERENCES,0.9683544303797469,"Intent
Intention categories e.g.
Broad
awareness, Alert, Suggestion"
REFERENCES,0.9746835443037974,Broad awareness
REFERENCES,0.9810126582278481,"Speciﬁcity
e.g. general, speciﬁc to a group of
users or occasion."
REFERENCES,0.9873417721518988,General
REFERENCES,0.9936708860759493,"Table 2: Attribute types, descriptions and example values for the health nudge “In a dinner rut? Our
meal plan is packed with tasty, colorful, and super-healthy recipes, Want it?”"
