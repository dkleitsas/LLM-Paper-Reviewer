Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0006172839506172839,"We study multi-agent reinforcement learning (RL) where agents cooperate through
1"
ABSTRACT,0.0012345679012345679,"asynchronous communications with a central server to learn a shared environ-
2"
ABSTRACT,0.001851851851851852,"ment. Our first focus is on the case of multi-agent contextual bandits with general
3"
ABSTRACT,0.0024691358024691358,"function approximation, for which we introduce the Async-NLin-UCB algorithm.
4"
ABSTRACT,0.0030864197530864196,"This algorithm is proven to achieve a regret of eO(
p"
ABSTRACT,0.003703703703703704,"T dimE(F) log N(F)) and a
5"
ABSTRACT,0.004320987654320987,"communication complexity of eO(M 2 dimE(F)), where M is the total number of
6"
ABSTRACT,0.0049382716049382715,"agents and T is the number of rounds, while dimE(F) and N(F) are the Eluder
7"
ABSTRACT,0.005555555555555556,"dimension and the covering number of function space F respectively. We then
8"
ABSTRACT,0.006172839506172839,"progress to the more intricate setting of multi-agent RL with general function ap-
9"
ABSTRACT,0.006790123456790123,"proximation, and present the Async-NLSVI-UCB algorithm. This algorithm enjoys
10"
ABSTRACT,0.007407407407407408,a regret of eO(H2p
ABSTRACT,0.008024691358024692,"K dimE(F) log N(F)) and a communication complexity of
11"
ABSTRACT,0.008641975308641974,"eO(HM 2 dimE(F)), where H is the horizon length and K the number of episodes.
12"
ABSTRACT,0.009259259259259259,"Our findings showcase the provable efficiency of both algorithms for collaborative
13"
ABSTRACT,0.009876543209876543,"learning within nonlinear environments and minimal communication overhead.
14"
INTRODUCTION,0.010493827160493827,"1
Introduction
15"
INTRODUCTION,0.011111111111111112,"Multi-agent reinforcement learning (RL) is an important paradigm in RL, and has been successfully
16"
INTRODUCTION,0.011728395061728396,"applied to real-world tasks such as robotics [Williams et al., 2016, Liu et al., 2019, Ding et al., 2020,
17"
INTRODUCTION,0.012345679012345678,"Liu et al., 2020, Na et al., 2022], games [Vinyals et al., 2017, Berner et al., 2019, Jaderberg et al.,
18"
INTRODUCTION,0.012962962962962963,"2019, Ye et al., 2020], and control systems [Bazzan, 2009, Yu et al., 2014, 2020, Min et al., 2022, Xu
19"
INTRODUCTION,0.013580246913580247,"et al., 2023]. By learning cooperatively, agents benefit from sharing learning experiences, enabling
20"
INTRODUCTION,0.014197530864197531,"them to collectively enhance their decision-making capabilities. This collaborative process is usually
21"
INTRODUCTION,0.014814814814814815,"accomplished through the utilization of a central server, whose task is to aggregate local data and
22"
INTRODUCTION,0.015432098765432098,"deliver feedback for the agents.
23"
INTRODUCTION,0.016049382716049384,"There has been an excellent line of work establishing provably efficient algorithms for multi-agent
24"
INTRODUCTION,0.016666666666666666,"bandits and RL. However, most existing works are restricted to the synchronous setting, where com-
25"
INTRODUCTION,0.01728395061728395,"munications between all agents and the server must happen simultaneously. This is impractical since
26"
INTRODUCTION,0.017901234567901235,"in many scenarios the availability of agents may vary and be unpredictable. Ideally, communication
27"
INTRODUCTION,0.018518518518518517,"should be allowed to happen asynchronously to offer the agents more flexibility. He et al. [2022] and
28"
INTRODUCTION,0.019135802469135803,"Min et al. [2023] studied this setting respectively for linear contextual bandits and linear Markov
29"
INTRODUCTION,0.019753086419753086,"Decision Processes (MDPs), both of which assumes linearity in the environment, and introduced
30"
INTRODUCTION,0.020370370370370372,"algorithms with low regret and communication cost. Yet the linear function class is quite limited, and
31"
INTRODUCTION,0.020987654320987655,"does not encompass practical reinforcement learning scenarios where nonlinearity is prevalent.
32"
INTRODUCTION,0.021604938271604937,"To address the aforementioned drawback, in this work, we tackle environments with general function
33"
INTRODUCTION,0.022222222222222223,"approximation, broadening the applicability of the algorithm to more realistic and complex scenarios.
34"
INTRODUCTION,0.022839506172839506,"We first delve into multi-agent contextual bandits with general function approximation, where multiple
35"
INTRODUCTION,0.02345679012345679,"agents interact with homogeneous environments in parallel to solve a common objective. Notably,
36"
INTRODUCTION,0.024074074074074074,"the communication protocol is designed to be flexible and asynchronous, allowing agents to initiate
37"
INTRODUCTION,0.024691358024691357,"communication with the server and acquire new policy functions whenever the need arises. The
38"
INTRODUCTION,0.025308641975308643,"primary objective is to minimize total regret while reducing communication cost as much as possible.
39"
INTRODUCTION,0.025925925925925925,"We propose an algorithm Async-NLin-UCB, which adapts a fully asynchronous communication
40"
INTRODUCTION,0.02654320987654321,"protocol, and leverages various methods for tackling nonlinear function approximation. Despite the
41"
INTRODUCTION,0.027160493827160494,"flexibility of communication, our algorithm performs almost as well as a single agent, in terms of a
42"
INTRODUCTION,0.027777777777777776,"regret that is mostly independent of the number of agents and a low communication cost.
43"
INTRODUCTION,0.028395061728395062,"We then progress to multi-agent RL with general function approximation under similar requirements
44"
INTRODUCTION,0.029012345679012345,"and objectives. We propose an algorithm named Async-NLSVI-UCB based on Least-Squares Value
45"
INTRODUCTION,0.02962962962962963,"Iteration (LSVI) to learn the underlying Markov decision processes (MDPs), which demonstrates
46"
INTRODUCTION,0.030246913580246913,"similar advantages with provably low regret and communication cost.
47"
INTRODUCTION,0.030864197530864196,"Our main contributions are summarized in the following:
48"
INTRODUCTION,0.03148148148148148,"• For asynchronous multi-agent nonlinear contextual bandits, we propose the algorithm
49"
INTRODUCTION,0.03209876543209877,"Async-NLin-UCB, which enjoys an eO(
p"
INTRODUCTION,0.03271604938271605,"T dimE(F) log N(F) + dimE(F)) regret and an
50"
INTRODUCTION,0.03333333333333333,"eO(M 2 dimE(F)) communication complexity, where dimE(F) and N(F) are respectively the
51"
INTRODUCTION,0.033950617283950615,"Eluder dimension and the covering number of function space F.
52"
INTRODUCTION,0.0345679012345679,"• For asynchronous multi-agent nonlinear MDPs, we propose the algorithm Async-NLSVI-UCB,
53"
INTRODUCTION,0.03518518518518519,which enjoys an eO(H2p
INTRODUCTION,0.03580246913580247,"K dimE(F) log N(F) + H2 dimE(F)) regret and a communication
54"
INTRODUCTION,0.03641975308641975,"complexity of eO(HM 2 dimE(F)).
55"
INTRODUCTION,0.037037037037037035,"• At the core of our algorithm, we design a communication criterion in order to tackles the challenges
56"
INTRODUCTION,0.037654320987654324,"posed by both asynchronous communication and the nonlinearity of function approximation. To
57"
INTRODUCTION,0.03827160493827161,"guarantee a low communication cost, we propose a low switching communication criterion that
58"
INTRODUCTION,0.03888888888888889,"allows the agent to trigger communication rounds.
59"
INTRODUCTION,0.03950617283950617,"• We carefully design our download content from server to local agents, which consist only of
60"
INTRODUCTION,0.040123456790123455,"decision and bonus functions, with no mention of any specific historical data. This effectively
61"
INTRODUCTION,0.040740740740740744,"protects user data against exposure by disallowing local users from obtaining the data of others.
62"
INTRODUCTION,0.04135802469135803,"Notation. We use lower case letters to denote scalars. We denote by [n] the set {1, . . . , n}. For
63"
INTRODUCTION,0.04197530864197531,"two positive sequences {an} and {bn} with n = 1, 2, . . . , we write an = O(bn) if there exists an
64"
INTRODUCTION,0.04259259259259259,"absolute constant C > 0 such that an ≤Cbn holds for all n ≥1. We use eO(·) to further hide the
65"
INTRODUCTION,0.043209876543209874,"polylogarithmic factors. For two non-negative integers a, b satisfying a < b and a sequence {si}
66"
INTRODUCTION,0.043827160493827164,"indexed by integers i, we use s[a:b] to denote the subsequence {sa, sa+1, · · · , sb}.
67"
RELATED WORK,0.044444444444444446,"2
Related Work
68"
MULTI-AGENT BANDITS,0.04506172839506173,"2.1
Multi-Agent Bandits
69"
MULTI-AGENT BANDITS,0.04567901234567901,"First, there is a multitude of previous work on distributed or federated multi-armed bandits and
70"
MULTI-AGENT BANDITS,0.046296296296296294,"stochastic linear bandits [Liu and Zhao, 2010, Szorenyi et al., 2013, Landgren et al., 2016, Chakraborty
71"
MULTI-AGENT BANDITS,0.04691358024691358,"et al., 2017, Landgren et al., 2018, Martínez-Rubio et al., 2019, Sankararaman et al., 2019, Wang et al.,
72"
MULTI-AGENT BANDITS,0.047530864197530866,"2020a,c, Zhu et al., 2021, Huang et al., 2021]. For the more realistic setting of contextual bandits, most
73"
MULTI-AGENT BANDITS,0.04814814814814815,"previous work are within the scope of linear contextual bandits with synchronized communication.
74"
MULTI-AGENT BANDITS,0.04876543209876543,"Korda et al. [2016] introduced two novel distributed confidence ball (DCB) algorithms for linear
75"
MULTI-AGENT BANDITS,0.04938271604938271,"bandit problems in peer-to-peer networks. Wang et al. [2020c] considered both P2P and star-shaped
76"
MULTI-AGENT BANDITS,0.05,"communication, achieving near-optimal regret and low communication cost that is largely independent
77"
MULTI-AGENT BANDITS,0.050617283950617285,"of the time horizon in their algorithm DisLinUCB. Dubey and Pentland [2020] proposed FedUCB,
78"
MULTI-AGENT BANDITS,0.05123456790123457,"an algorithm focusing on differential-privacy.
79"
MULTI-AGENT BANDITS,0.05185185185185185,"Li and Wang [2022] first considered an asynchronous communication protocol and proposed the
80"
MULTI-AGENT BANDITS,0.05246913580246913,"algorithm Async-LinUCB with near-optimal regret, yet the algorithm contains a download step
81"
MULTI-AGENT BANDITS,0.05308641975308642,"for all agents triggered by the central server. Their results are flexible and contains a parameter to
82"
MULTI-AGENT BANDITS,0.053703703703703705,"control the trade-off between regret and communication cost. He et al. [2022] improved the setting
83"
MULTI-AGENT BANDITS,0.05432098765432099,"to a fully asynchronous communication, proposing the algorithm FedLinUCB with near-optimal
84"
MULTI-AGENT BANDITS,0.05493827160493827,"regret of eO(d
√"
MULTI-AGENT BANDITS,0.05555555555555555,"T) and low communication cost of eO(dm2), comparable to the benchmark in single-
85"
MULTI-AGENT BANDITS,0.05617283950617284,"agent contextual linear bandits [Abbasi-Yadkori et al., 2011]. We consider the same communication
86"
MULTI-AGENT BANDITS,0.056790123456790124,"protocol in our results. A summary of these results along with ours can be found in the first four rows
87"
MULTI-AGENT BANDITS,0.05740740740740741,"of Table 1.
88"
MULTI-AGENT RL,0.05802469135802469,"2.2
Multi-Agent RL
89"
MULTI-AGENT RL,0.05864197530864197,"Multi-agent reinforcement learning is decidedly more challenging than contextual bandits. There is
90"
MULTI-AGENT RL,0.05925925925925926,"also a vast literature on this setting, with many works discussing different aspects of multi-agent RL
91"
MULTI-AGENT RL,0.059876543209876544,"Algorithm
Regret
Communication
Fully
asynchrnous
DisLinUCB
d
√"
MULTI-AGENT RL,0.06049382716049383,"MT log2 T
d3M 3/2
✘
[Wang et al., 2020c]"
MULTI-AGENT RL,0.06111111111111111,"Async-LinUCB
dM (1−γ)/2√"
MULTI-AGENT RL,0.06172839506172839,"T log T
dM 1+γ log T
✘
[Li and Wang, 2022]"
MULTI-AGENT RL,0.06234567901234568,"FedLinUCB
d
√"
MULTI-AGENT RL,0.06296296296296296,"T log T
dM 2 log T
✓
[He et al., 2022]
Async-NLin-UCB
√dimE log NT log T
dimE M 2 log2 T
✓
(ours)
Coop-LSVI
d3/2H2√"
MULTI-AGENT RL,0.06358024691358025,"MK log K
dHM 3
✘
[Dubey and Pentland, 2021]"
MULTI-AGENT RL,0.06419753086419754,"Async-Coop-LSVI-UCB
d3/2H2√K log K
dHM 2 log K
✓
[Min et al., 2023]
Async-NLSVI-UCB
√dimE log NH2√"
MULTI-AGENT RL,0.06481481481481481,"K log K
dimE HM 2 log2 K
✓
(ours)
Table 1: Comparison of our result against baseline methods for multi-agent contextual bandits and
MDPs. Note that the first four rows are for contextual bandits, and the last three are for reinforcement
learning. Only our algorithms are in the general function approximation setting. We abbreviate
dimE = dimE(F) and N = N(F), and hide logarithmic factors. For algorithms with synchronized
communication, each communication round actually corresponds to M rounds in asynchronous
settings, which explains the extra M terms."
MULTI-AGENT RL,0.0654320987654321,"than ours. For example, there are works focusing on convergence guarantees [Zhang et al., 2018b,a,
92"
MULTI-AGENT RL,0.06604938271604938,"Wai et al., 2018], non-stationary or heterogeneous environments [Lowe et al., 2017, Yu et al., 2021,
93"
MULTI-AGENT RL,0.06666666666666667,"Dubey and Pentland, 2021, Kuba et al., 2022, Liu et al., 2022, Jin et al., 2022], and deep federated RL
94"
MULTI-AGENT RL,0.06728395061728396,"[Clemente et al., 2017, Espeholt et al., 2018, Horgan et al., 2018, Nair et al., 2015, Zhuo et al., 2019],
95"
MULTI-AGENT RL,0.06790123456790123,"to name a few. We refer to a recent survey on federated reinforcement learning Qi et al. [2021] for a
96"
MULTI-AGENT RL,0.06851851851851852,"more comprehensive summary.
97"
MULTI-AGENT RL,0.0691358024691358,"Narrowing it down to multi-agent RL with function approximation, the benchmark is the LSVI-UCB
98"
MULTI-AGENT RL,0.06975308641975309,"algorithm in the single-agent setting [Jin et al., 2020], with an eO(d3/2H2√"
MULTI-AGENT RL,0.07037037037037037,"K) regret. Dubey and
99"
MULTI-AGENT RL,0.07098765432098765,"Pentland [2021] proposed CoopLSVI for multi-agent linear MDPs, which requires a synchronized
100"
MULTI-AGENT RL,0.07160493827160494,"communication through central server, and proves a regret of eO(d3/2H2√"
MULTI-AGENT RL,0.07222222222222222,"MK). They also extended
101"
MULTI-AGENT RL,0.0728395061728395,"their result to the heterogeneous setting. Min et al. [2023] considered the fully asynchronous setting
102"
MULTI-AGENT RL,0.0734567901234568,"and introduced the Async-Coop-LSVI-UCB algorithm, with a eO(d3/2H2√"
MULTI-AGENT RL,0.07407407407407407,"K) regret not dependent
103"
MULTI-AGENT RL,0.07469135802469136,"on the number of agents M, as well as a low communication cost. A summary of these results along
104"
MULTI-AGENT RL,0.07530864197530865,"with ours can be found in the last three rows of Table 1.
105"
GENERAL FUNCTION APPROXIMATION,0.07592592592592592,"2.3
General function approximation
106"
GENERAL FUNCTION APPROXIMATION,0.07654320987654321,"Reinforcement learning with general function approximation extends the well-studied case of linear
107"
GENERAL FUNCTION APPROXIMATION,0.07716049382716049,"MDPs to more general classes of MDPs, and has gained a lot of traction in recent years [Wang et al.,
108"
GENERAL FUNCTION APPROXIMATION,0.07777777777777778,"2020b, Jin et al., 2021, Foster et al., 2023, Du et al., 2021, Agarwal and Zhang, 2022, Agarwal
109"
GENERAL FUNCTION APPROXIMATION,0.07839506172839507,"et al., 2023]. Previous works focus on different measures of complexity for the function classes, for
110"
GENERAL FUNCTION APPROXIMATION,0.07901234567901234,"example the Bellman rank proposed by Jiang et al. [2017], the Bellman Eluder dimension introduced
111"
GENERAL FUNCTION APPROXIMATION,0.07962962962962963,"in Jin et al. [2021], the Decision-Estimation Coefficient in Foster et al. [2023], and generalized Eluder
112"
GENERAL FUNCTION APPROXIMATION,0.08024691358024691,"dimension in Agarwal et al. [2023]. Our work considers the Eluder dimension with the introduction
113"
GENERAL FUNCTION APPROXIMATION,0.0808641975308642,"of uncertainty estimators D2, which has been widely utilized to establish results in RL with general
114"
GENERAL FUNCTION APPROXIMATION,0.08148148148148149,"function approximation [Agarwal et al., 2023, Zhao et al., 2023, Ye et al., 2023, Di et al., 2023].
115"
PRELIMINARIES,0.08209876543209876,"3
Preliminaries
116"
PRELIMINARIES,0.08271604938271605,"In this section, we introduce the formal definition of both multi-agent nonlinear contextual bandits
117"
PRELIMINARIES,0.08333333333333333,"and MDPs and some related concepts, and discuss the asynchronous communication protocol.
118"
MULTI-AGENT CONTEXTUAL BANDITS WITH GENERAL FUNCTION APPROXIMATION,0.08395061728395062,"3.1
Multi-Agent Contextual Bandits with General Function Approximation
119"
MULTI-AGENT CONTEXTUAL BANDITS WITH GENERAL FUNCTION APPROXIMATION,0.08456790123456791,"We assume a global action set A that is known to all agents. At each round t ∈[T], a single arbitrary
120"
MULTI-AGENT CONTEXTUAL BANDITS WITH GENERAL FUNCTION APPROXIMATION,0.08518518518518518,"agent mt ∈[M] is chosen to participate. The agent receives a contextual decision set At ⊆A and
121"
MULTI-AGENT CONTEXTUAL BANDITS WITH GENERAL FUNCTION APPROXIMATION,0.08580246913580247,"chooses from the set an action at ∈At to perform, and subsequently receives a random reward rt.
122"
MULTI-AGENT CONTEXTUAL BANDITS WITH GENERAL FUNCTION APPROXIMATION,0.08641975308641975,"The assumption of general function approximation is that the reward is generated according to
123"
MULTI-AGENT CONTEXTUAL BANDITS WITH GENERAL FUNCTION APPROXIMATION,0.08703703703703704,"rt = f ∗(at) + ηt,
(1)"
MULTI-AGENT CONTEXTUAL BANDITS WITH GENERAL FUNCTION APPROXIMATION,0.08765432098765433,"where f ∗is the ground truth objective function, and ηt is a random noise variable. We assume the
124"
MULTI-AGENT CONTEXTUAL BANDITS WITH GENERAL FUNCTION APPROXIMATION,0.0882716049382716,"the objective function lies within a known function class F. In addition, we also make the following
125"
MULTI-AGENT CONTEXTUAL BANDITS WITH GENERAL FUNCTION APPROXIMATION,0.08888888888888889,"assumptions regarding the function class and noise variables, which are standard assumptions for
126"
MULTI-AGENT CONTEXTUAL BANDITS WITH GENERAL FUNCTION APPROXIMATION,0.08950617283950617,"contextual bandits [Abbasi-Yadkori et al., 2011, He et al., 2022]:
127"
MULTI-AGENT CONTEXTUAL BANDITS WITH GENERAL FUNCTION APPROXIMATION,0.09012345679012346,"Assumption 3.1. Suppose the following conditions hold for the contextual bandits environment:
128"
MULTI-AGENT CONTEXTUAL BANDITS WITH GENERAL FUNCTION APPROXIMATION,0.09074074074074075,"• For any f ∈F and a ∈A, |f(a)| ≤1;
129"
MULTI-AGENT CONTEXTUAL BANDITS WITH GENERAL FUNCTION APPROXIMATION,0.09135802469135802,"• ηt is R-sub-Gaussian conditioned on data history: E

eληta1:t, m1:t, r1:t−1

≤exp(R2λ2/2), ∀λ.
130"
MULTI-AGENT CONTEXTUAL BANDITS WITH GENERAL FUNCTION APPROXIMATION,0.09197530864197531,"Learning Objective. The primary goal of contextual bandits is to minimize the cumulative regret
131"
MULTI-AGENT CONTEXTUAL BANDITS WITH GENERAL FUNCTION APPROXIMATION,0.09259259259259259,"Reg(T) = PT
t=1[f ∗(at) −maxa∈At f ∗(a)]."
MULTI-AGENT CONTEXTUAL BANDITS WITH GENERAL FUNCTION APPROXIMATION,0.09320987654320988,"Notice that this summation is across all time steps does not depend on agent participation order,
132"
MULTI-AGENT CONTEXTUAL BANDITS WITH GENERAL FUNCTION APPROXIMATION,0.09382716049382717,"as should be the case for the resulting regret bound. To achieve this goal, agents are allowed to
133"
MULTI-AGENT CONTEXTUAL BANDITS WITH GENERAL FUNCTION APPROXIMATION,0.09444444444444444,"communicate with the server to upload their interaction history and update their policy. The secondary
134"
MULTI-AGENT CONTEXTUAL BANDITS WITH GENERAL FUNCTION APPROXIMATION,0.09506172839506173,"learning objective is to reduce communication overhead. We will explain the communication protocol
135"
MULTI-AGENT CONTEXTUAL BANDITS WITH GENERAL FUNCTION APPROXIMATION,0.09567901234567901,"further in Section 3.4.
136"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.0962962962962963,"3.2
Multi-Agent Episodic MDPs with General Function Approximation
137"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.09691358024691359,"We consider episodic MDPs, which are a classic family of models in reinforcement learning [Sutton
138"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.09753086419753086,"and Barto, 2018]. It is characterized by the following elements, which we assume to be homogeneous
139"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.09814814814814815,"across all agents: a state space S, an action space A, the horizon length H, transition probability
140"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.09876543209876543,"functions P = {Ph(·|·, ·)}H
h=1 and reward functions {rh(·, ·)}H
h=1). Similar to the bandit case,
141"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.09938271604938272,"for each episode k = 1, · · · , K, a single agent m = mk is chosen to participate. An episode
142"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.1,"k begins with an initial state sk
1, which is drawn from an unknown fixed distribution. Then for
143"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.10061728395061728,"steps h = 1, · · · , H, the participating agent m selects an action ak
h based on the observed state
144"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.10123456790123457,"sk
h. After each action, the agent receives a reward rk
h = rh(sk
h, ak
h), where rh : S × A →R is the
145"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.10185185185185185,"reward function at step h. Here for the sake of convenience, we assume the reward function to be
146"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.10246913580246914,"deterministic, but it is not difficult to generalize our result to stochastic rewards. We also assume
147"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.10308641975308643,"rh(s, a) ∈[0, 1] for all (s, a) ∈S × A without loss of generality. The environment then transitions
148"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.1037037037037037,"to the next state according to sk
h+1 ∼Ph(·|sk
h, ak
h), where Ph is the transition probability at step h.
149"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.10432098765432099,"The episode terminates when rH is observed.
150"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.10493827160493827,"The strategy an agent employs to interact with the environment is called the agent’s policy, which can
151"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.10555555555555556,"be described by a set of decision functions π = {πh}H
h=1, where πh : S →A is the decision function
152"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.10617283950617284,"at level h, mapping the current state to an action to select.
153"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.10679012345679012,"Value Functions. For any policy π = {πh}, we define Q-value functions and V -value functions:
154"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.10740740740740741,"Qπ
h(sh, ah) := E
PH
h′=hrh′(sh′, ah′)
sh, ah"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.10802469135802469,"
,
V π
h (sh) := E
PH
h′=hrh′(sh′, ah′)
sh"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.10864197530864197,"
,
(2)"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.10925925925925926,"where the expectation is taken over the trajectory (s1, a1, · · · , sh, ah), determined by the transition
probability functions P and policy π. The optimal strategy π∗is the maximizer of the value functions:"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.10987654320987654,"π∗:= argmaxπ V π
1 (s1), ∀s1."
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.11049382716049383,"We also have optimal value functions Q∗
h := Qπ∗
h and V ∗
h := V π∗
h , which satisfy Bellman equations
155"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.1111111111111111,"Q∗
h(sh, ah) = rh(sh, ah) + E

V ∗
h+1(sh+1)
sh, ah

,
V ∗
h (sh) = maxa∈A Q∗
h(sh, a).
(3)"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.1117283950617284,"Function Approximation.
We approximate Q-value functions with function classes {Fh}H
h=1,
which contain real value functions with domain S × A. One basic assumption is that Q∗
h ∈Fh for
all steps h ∈[H]. Now with the convention that functions at level H + 1 are uniformly zero, i.e.,
fH+1 = 0, we define the Bellman operator Th:"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.11234567901234568,"(Thfh+1)(sh, ah) := E

rh(sh, ah) + fh+1(sh+1)
sh, ah

,"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.11296296296296296,"and we expect Th to map any function in Fh+1 to a function in Fh, i.e., ThFh+1 ⊆Fh. This is
156"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.11358024691358025,"called the completeness assumption, which is a fundamental assumption in RL with general function
157"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.11419753086419752,"approximation [Wang et al., 2020b, Jin et al., 2021].
158"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.11481481481481481,"Learning Objective. The primary goal in multi-agent MDPs is to minimize the cumulative regret
over K episodes
Reg(K) = PK
k=1

V ∗
1 (sk
1) −V πm,k
1
(sk
1)

,
where πm,k is the policy of agent m = mk at round k, while the secondary objective is to minimize
159"
MULTI-AGENT EPISODIC MDPS WITH GENERAL FUNCTION APPROXIMATION,0.1154320987654321,"the communication cost.
160"
ELUDER DIMENSION AND COVERING NUMBER,0.11604938271604938,"3.3
Eluder Dimension and Covering Number
161"
ELUDER DIMENSION AND COVERING NUMBER,0.11666666666666667,"To measure the complexity of the learning objective, Russo and Van Roy [2013] first proposed the
162"
ELUDER DIMENSION AND COVERING NUMBER,0.11728395061728394,"concept of Eluder dimension, which we define below.
163"
ELUDER DIMENSION AND COVERING NUMBER,0.11790123456790123,"Definition 3.2 (ϵ-dependence). For a function class F on domain D, a point z ∈D is ϵ-dependent
164"
ELUDER DIMENSION AND COVERING NUMBER,0.11851851851851852,"on Z ⊆D if, for any f1, f2 ∈F satisfying
qP"
ELUDER DIMENSION AND COVERING NUMBER,0.1191358024691358,"z′∈Z
 
f1(z′) −f2(z′)
2 ≤ϵ, it must hold that
165"
ELUDER DIMENSION AND COVERING NUMBER,0.11975308641975309,"|f1(z) −f2(z)| ≤ϵ. Accordingly, z is ϵ-independent of Z if it is not ϵ-dependent on Z.
166"
ELUDER DIMENSION AND COVERING NUMBER,0.12037037037037036,"Definition 3.3 (Eluder dimension). The ϵ-Eluder dimension dimE(F, ϵ) is the length of the longest
167"
ELUDER DIMENSION AND COVERING NUMBER,0.12098765432098765,"sequence of elements in D satisfying that, for some ϵ0 > ϵ, each element is ϵ0-independent of the set
168"
ELUDER DIMENSION AND COVERING NUMBER,0.12160493827160494,"consisting of its predecessors.
169"
ELUDER DIMENSION AND COVERING NUMBER,0.12222222222222222,"It has been demonstrated that the Eluder dimension roughly corresponds to regular dimension
170"
ELUDER DIMENSION AND COVERING NUMBER,0.12283950617283951,"concepts in linear and quadratic cases [Russo and Van Roy, 2013], and that the Eluder family is
171"
ELUDER DIMENSION AND COVERING NUMBER,0.12345679012345678,"strictly larger than the generalized linear class [Li et al., 2022]. Note that our Eluder definition can be
172"
ELUDER DIMENSION AND COVERING NUMBER,0.12407407407407407,"applied to either the contextual bandit case with D = A or the MDPs case with D = S × A.
173"
ELUDER DIMENSION AND COVERING NUMBER,0.12469135802469136,"We also introduce covering number for function classes [Wainwright, 2019] in the following:
174"
ELUDER DIMENSION AND COVERING NUMBER,0.12530864197530864,"Definition 3.4 (Covering number). An ϵ-cover of F is any subset Fϵ ⊆F such that for any f ∈F,
175"
ELUDER DIMENSION AND COVERING NUMBER,0.1259259259259259,"there exists f ′ ∈Fϵ that ∥f −f ′∥∞≤ϵ. The covering number of F, denoted by N(F, ϵ), is the
176"
ELUDER DIMENSION AND COVERING NUMBER,0.12654320987654322,"minimal cardinality of its ϵ-cover.
177"
COMMUNICATION PROTOCOL,0.1271604938271605,"3.4
Communication Protocol
178"
COMMUNICATION PROTOCOL,0.12777777777777777,"We consider a star-shaped communication model [He et al., 2022, Min et al., 2023], where the agents
179"
COMMUNICATION PROTOCOL,0.12839506172839507,"communicate through a central server to collaborate. To ensure asynchronous communication, we
180"
COMMUNICATION PROTOCOL,0.12901234567901235,"mandate that all communications must be initiated by a participating agent. Specifically, at the end of
181"
COMMUNICATION PROTOCOL,0.12962962962962962,"a time step / episode, the agent will decide whether or not to trigger a communication round. If so,
182"
COMMUNICATION PROTOCOL,0.13024691358024693,"the agent uploads its local data history and receives some global data for future decision making. The
183"
COMMUNICATION PROTOCOL,0.1308641975308642,"communication cost is the total number of communication rounds initiated by the agents.
184"
COMMUNICATION PROTOCOL,0.13148148148148148,"One variability is the form of global data that the communicating agent downloads from server. It
185"
COMMUNICATION PROTOCOL,0.13209876543209875,"may be tempting to have the server send all its stored trajectories to the agent for future decision
186"
COMMUNICATION PROTOCOL,0.13271604938271606,"making, but this will unnecessarily expose other agents’ data to the current participating agent. We
187"
COMMUNICATION PROTOCOL,0.13333333333333333,"will come back to this issue and our solution in Section 4.2.
188"
MULTI-AGENT CONTEXTUAL BANDITS,0.1339506172839506,"4
Multi-Agent Contextual Bandits
189"
MULTI-AGENT CONTEXTUAL BANDITS,0.1345679012345679,"In this section, we introduce the Asynchronous Nonlinear UCB (Async-NLin-UCB) algorithm
190"
MULTI-AGENT CONTEXTUAL BANDITS,0.13518518518518519,"designed for multi-agent contextual bandits with general function approximation, and provide a
191"
MULTI-AGENT CONTEXTUAL BANDITS,0.13580246913580246,"theoretical result for its regret and communication cost.
192"
MULTI-AGENT CONTEXTUAL BANDITS,0.13641975308641976,"4.1
Algorithm: Async-NLin-UCB
193"
MULTI-AGENT CONTEXTUAL BANDITS,0.13703703703703704,"Algorithm 1 takes as input the total number of time steps T, regularization parameter λ, communica-
194"
MULTI-AGENT CONTEXTUAL BANDITS,0.13765432098765432,"tion parameter α and exploration radii {βt}T
t=1.
195"
MULTI-AGENT CONTEXTUAL BANDITS,0.1382716049382716,"In the algorithm, there are some variables that go through different versions as t progresses through
196"
MULTI-AGENT CONTEXTUAL BANDITS,0.1388888888888889,"1, · · · , T. For clarity, here we give them an extra subscript t to denote the version of that variable
197"
MULTI-AGENT CONTEXTUAL BANDITS,0.13950617283950617,"before (not included) the least squares calculation on Line 12 at round t.
198"
MULTI-AGENT CONTEXTUAL BANDITS,0.14012345679012345,"Throughout the learning process, the server maintains a global history set Zser
t
that stores action-
199"
MULTI-AGENT CONTEXTUAL BANDITS,0.14074074074074075,"reward pairs (a, r) ∈A×[0, 1], initialized on Line 2 and updated only during communication rounds.
200"
MULTI-AGENT CONTEXTUAL BANDITS,0.14135802469135803,"Each local agent m maintains a decision function fm,t for taking action, a bonus function bm,t for
201"
MULTI-AGENT CONTEXTUAL BANDITS,0.1419753086419753,"checking communication criterion, and a local data history set Zloc
m,t, all initialized on Line 3. Each
202"
MULTI-AGENT CONTEXTUAL BANDITS,0.1425925925925926,"step of Algorithm 1 contains two parts: local exploration and server updates.
203"
MULTI-AGENT CONTEXTUAL BANDITS,0.14320987654320988,"Part I: Local Exploration. At step t a single agent m = mt is active (Line 5). It receives a decision
204"
MULTI-AGENT CONTEXTUAL BANDITS,0.14382716049382716,"set, finds the greedy action according to its decision function fm,t, receives a reward, and updates its
205"
MULTI-AGENT CONTEXTUAL BANDITS,0.14444444444444443,"local dataset Zloc
m,t (Lines 5 - 7).
206"
MULTI-AGENT CONTEXTUAL BANDITS,0.14506172839506173,Algorithm 1 Async-NLin-UCB
MULTI-AGENT CONTEXTUAL BANDITS,0.145679012345679,"1: Input: total number of rounds T, parameters λ, α, βt for t = 1, . . . , T.
2: Server init: Set Zser = ∅.
3: Local init: For all m ∈[M], set fm = 1, bm = BA(∅, F; λ, β0) and Zloc
m = ∅.
4: for t = 1, . . . , T do
5:
Agent m = mt ∈[M] is active.
6:
Receive decision set At ⊆A and take action at ∈argmaxa∈Dt fm(a) and receive reward rt.
7:
Update local history Zloc
m = Zloc
m ∪{(at, rt)}.
8:
if switch condition (4) is met then
9:
Send new data Zloc
m to server.
10:
on server:
11:
Update Zser = Zser ∪Zloc
m .
12:
Calculate bf according to (5) and the bonus function b = BA(Zser, F; λ, βt).
13:
Send bf + b and b to agent m.
14:
end of server
15:
Agent m receives decision and bonus functions fm = bf + b, bm = b, then set Zloc
m = ∅.
16:
end if
17: end for"
MULTI-AGENT CONTEXTUAL BANDITS,0.14629629629629629,"After exploration, the agent checks if the switch condition is true using its bonus function:
207
P
(a,r)∈Zloc
m,t b2
m,t(a)/
 
β2
t′ + λ

≥α,
(4)"
MULTI-AGENT CONTEXTUAL BANDITS,0.1469135802469136,"where t′ is the last time step when agent m communicated with the server. If so, the agent initiates a
208"
MULTI-AGENT CONTEXTUAL BANDITS,0.14753086419753086,"communication round and uploads its local data (Line 9), prompting the server to begin global policy
209"
MULTI-AGENT CONTEXTUAL BANDITS,0.14814814814814814,"updates. We will discuss the reasons behind this switch condition in Section 4.2.
210"
MULTI-AGENT CONTEXTUAL BANDITS,0.14876543209876544,"Part II: Server Updates. After receiving a new local data history from an agent, the server merges
211"
MULTI-AGENT CONTEXTUAL BANDITS,0.14938271604938272,"the data into its global dataset Zser
t
(Line 11), and calculate a function bft+1 ∈F which minimizes
212"
MULTI-AGENT CONTEXTUAL BANDITS,0.15,"the sum of squares error according to the current dataset Zser
t
(Line 12):
213"
MULTI-AGENT CONTEXTUAL BANDITS,0.1506172839506173,"bft+1 = argminf∈F
P"
MULTI-AGENT CONTEXTUAL BANDITS,0.15123456790123457,"(a,r)∈Zser
t
 
f(a) −r
2.
(5)"
MULTI-AGENT CONTEXTUAL BANDITS,0.15185185185185185,"The next step is to obtain a bonus function bt+1 from the oracle BA from Definition 4.1 (Line ??).
214"
MULTI-AGENT CONTEXTUAL BANDITS,0.15246913580246912,"We discuss the specifics of this construction in detail up next in Section 4.2. Finally, the server sends
215"
MULTI-AGENT CONTEXTUAL BANDITS,0.15308641975308643,"the optimistic value function bft+1 + bt+1 and the bonus function bt+1 back to agent m for future
216"
MULTI-AGENT CONTEXTUAL BANDITS,0.1537037037037037,"exploration and updates; agent m also resets its local data history to an empty set (Lines 13 and 15).
217"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.15432098765432098,"4.2
Uncertainty Estimators and Bonus Functions
218"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.15493827160493828,"In this section, we introduce uncertainty estimators and bonus functions, and give a detailed explana-
219"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.15555555555555556,"tion for our communication criterion (4). Most of these apply to the MDPs setting as well.
220"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.15617283950617283,"Uncertainty Estimators. First we define the uncertainty estimator of new data a against data history
221"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.15679012345679014,"Z, which is considered in many works on bandits and RL with general function approximation
222"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.1574074074074074,"[Gentile et al., 2022, Agarwal et al., 2023]:
223"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.1580246913580247,"Dλ,F(a; Z) = supf1,f2∈F |f1(a) −f2(a)|
q λ + P"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.15864197530864196,"(a′,r)∈Z |f1(a′) −f2(a′)|2,
(6)"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.15925925925925927,"here λ is the regularization parameter, F is a function class. Intuitively, the uncertainty estimator
224"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.15987654320987654,"measures the difference between functions on new data a against the difference on historical data Z.
225"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.16049382716049382,"Switch Condition Based On Uncertainty Estimators.
The determinant-based criterion is a
226"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.16111111111111112,"common technique used in contextual bandits and RL with linear function approximation to reduce
227"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.1617283950617284,"policy switching or communication cost [Abbasi-Yadkori et al., 2011]. For nonlinear function
228"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.16234567901234567,"approximation, one can use uncertainty estimators to formulate a new form of switch condition:
229
P"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.16296296296296298,"(a,r)∈Znew
t
D2
λ,F(a; Zold
t ) ≥α.
(7)"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.16358024691358025,"where we use Znew
t
and Zold
t
to denote newly accumulated data and old historical data. This criterion
230"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.16419753086419753,"has a similar function as the determinant-based criterion in linear settings. Parameter α controls
231"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.1648148148148148,"communication frequency: smaller α indicates more frequent communication, more accurate decision
232"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.1654320987654321,"functions and smaller regret, thus implying a trade-off between regret and communication cost.
233"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.16604938271604938,"Bonus Function Oracle.
Next, we introduce bonus functions obtained through oracles that
234"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.16666666666666666,"approximate the uncertainty estimators.
235"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.16728395061728396,"Definition 4.1 (Bonus Function Oracle BD). Given domain D, the oracle BD(Z, F; λ, β) takes the
236"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.16790123456790124,"following as inputs: a dataset Z consisting of a series of data points (z, e), where z ∈D and e is some
237"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.1685185185185185,"additional data content; function class F with functions f : D →R≥0; regularization parameter λ
238"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.16913580246913582,"and exploration radius β. It returns a function b ∈WD : D →R≥0 satisfying for any z ∈D that
239"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.1697530864197531,"• b(z) ≥max
nf1(z) −f2(z)
 : f1, f2 ∈F, P"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.17037037037037037,"(z,e)∈Z
 
f1(z) −f2(z)
2 ≤β2o
;
240"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.17098765432098764,"• Dλ,F(z; Z) ≤b(z)/
p"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.17160493827160495,"β2 + λ ≤CBDλ,F(z; Z),
241"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.17222222222222222,"where CB is an absolute constant.
242"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.1728395061728395,"Remark 4.2. Similar bonus function oracles have been proposed in previous works (Definition 3
243"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.1734567901234568,"in Agarwal et al. [2023]). The accessibility of these oracles is also supported by previous works
244"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.17407407407407408,"that proposed methods to compute bonus functions [Kong et al., 2023, Wang et al., 2020b]. In this
245"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.17469135802469135,"definition, we leave the domain and data format to be variable so the oracle can be applied to both
246"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.17530864197530865,"contextual bandits and MDPs. For bandits, the domain is A, and the data format has z = a and e = r.
247"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.17592592592592593,"The first property of the bonus function guarantees the optimism of decision functions bft+1 + bt+1
248"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.1765432098765432,"(see Lemma 6.1 for MDPs or Lemma A.2 for bandits), while the second property links bonuses to
249"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.17716049382716048,"uncertainty estimators.
250"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.17777777777777778,"Switch Condition Based On Bonus Functions. If we try to adapt the switch condition (7) in our
251"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.17839506172839506,"setting, a local agent will require access to historical data Zold
t
to calculate uncertainty estimators
252"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.17901234567901234,"D2
λ,F(a; Zold
t ). For multi-agent learning, this dataset consists of the collective data from all agents,
253"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.17962962962962964,"and giving local agent access is a clear violation of data privacy. Our solution is to let local agents
254"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.18024691358024691,"download bonus functions and set communication criterion to (4), using bonus functions instead of
255"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.1808641975308642,"uncertainty estimators.
256"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.1814814814814815,"Decision Functions Based On Bonus Functions. Another benefit of introducing the bonus function
257"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.18209876543209877,"is evident from our exploration method in line 6. A common practice for nonlinear RL algorithms is
258"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.18271604938271604,"to construct confidence sets of functions during policy update, and find the optimal function within the
259"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.18333333333333332,"confidence sets during exploration [Agarwal et al., 2023, Ye et al., 2023]. However, in a multi-agent
260"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.18395061728395062,"setting, this would involve the download of confidence sets, which is impractical due to the complex
261"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.1845679012345679,"nature of function classes. With the bonus function, local agents need only download the decision
262"
UNCERTAINTY ESTIMATORS AND BONUS FUNCTIONS,0.18518518518518517,"function from the server for future exploration, which for contextual bandits is simply bft+1 + bt+1.
263"
THEORETICAL RESULTS,0.18580246913580248,"4.3
Theoretical Results
264"
THEORETICAL RESULTS,0.18641975308641975,"Our main results for Algorithm 1 are summarized in the following theorem, which provides a regret
265"
THEORETICAL RESULTS,0.18703703703703703,"upper bound and communication complexity order.
266"
THEORETICAL RESULTS,0.18765432098765433,"Theorem 4.3. By taking γ = O(1/T), βt = Cβ,1
 √"
THEORETICAL RESULTS,0.1882716049382716,"λ + RC(M, α) log(3MN(F, γ)/δ)

and
267"
THEORETICAL RESULTS,0.18888888888888888,"C(M, α) =
√"
THEORETICAL RESULTS,0.18950617283950616,"1 + Mα
 √"
THEORETICAL RESULTS,0.19012345679012346,"1 + Mα + M√α

, the regret of Algorithm 1 within T rounds is
268 O
√"
THEORETICAL RESULTS,0.19074074074074074,"T eβ1
p"
THEORETICAL RESULTS,0.19135802469135801,"(1 + Mα) dimE log(T/ min{1, λ}) + (1 + Mα) dimE log2(T/ min{1, λ})

,"
THEORETICAL RESULTS,0.19197530864197532,"where we abbreviate dimE := dimE(F, λ/T); the total communication complexity is
269"
THEORETICAL RESULTS,0.1925925925925926,"O

(1 + Mα)2/α dimE log2(T/ min{1, λ})
"
THEORETICAL RESULTS,0.19320987654320987,"Remark 4.4. When reduced to linear contextual bandits, where dimE(F, λ/T) =
eO(d) and
270"
THEORETICAL RESULTS,0.19382716049382717,"log N(F, γ) = eO(d), our result on regret correspond exactly to Theorem 5.1 of He et al. [2022],
271"
THEORETICAL RESULTS,0.19444444444444445,"except for an extra 1 + Mα term in the communication cost, an unimportant term when taking
272"
THEORETICAL RESULTS,0.19506172839506172,"α = 1/M 2 that comes from the complication of communication cost analysis in nonlinear settings.
273"
MULTI-AGENT REINFORCEMENT LEARNING,0.195679012345679,"5
Multi-Agent Reinforcement Learning
274"
MULTI-AGENT REINFORCEMENT LEARNING,0.1962962962962963,"In this section, we introduce the Asynchronous Nonlinear Least Squares Value Iteration UCB
275"
MULTI-AGENT REINFORCEMENT LEARNING,0.19691358024691358,"(Async-NLin-UCB) algorithm for multi-agent MDPs with general function approximation, and a
276"
MULTI-AGENT REINFORCEMENT LEARNING,0.19753086419753085,"corresponding theoretical result.
277"
MULTI-AGENT REINFORCEMENT LEARNING,0.19814814814814816,"5.1
Algorithm: Async-NLSVI-UCB
278"
MULTI-AGENT REINFORCEMENT LEARNING,0.19876543209876543,"To better represent the elements in the datasets, we sometimes use oh to represent the tuple
279"
MULTI-AGENT REINFORCEMENT LEARNING,0.1993827160493827,"(sh, ah, rh, sh+1) and zh to represent (sh, ah) when there is no confusion. Similar to the ban-
280"
MULTI-AGENT REINFORCEMENT LEARNING,0.2,"dit case, we give some variables an extra subscript k here for clarity, which denotes the version of the
281"
MULTI-AGENT REINFORCEMENT LEARNING,0.2006172839506173,"variable before (not included) Line 14 at episode k.
282"
MULTI-AGENT REINFORCEMENT LEARNING,0.20123456790123456,Algorithm 2 Federated Nonlinear MDPs
MULTI-AGENT REINFORCEMENT LEARNING,0.20185185185185187,"1: Input: total number of rounds K, parameters λ, α, βk,h for k = [K] and h ∈[H]
2: Server init: Set Zser
h = ∅for all h ∈[H].
3: Local init: ∀m ∈[M] and h ∈[H], set Qm,h = 1, bm,h = B(∅, Fh; λ, β0,h), Zloc
m,h = ∅.
4: for k = 1, . . . , K do
5:
Agent m = mk ∈[M] is active and receives initial state sk
1 ∈S.
6:
for h = 1, . . . , H do
7:
Take action ak
h = argmaxa∈A Qm,h(sk
h, a), receive reward rk
h and next state sk
h+1.
8:
Update Zloc
m,h = Zloc
m,h ∪{(sk
h, ak
h, rk
h, sk
h+1)}.
9:
end for
10:
if switch condition (8) is met then
11:
Send new data {Zloc
m,h}h∈[H] to server.
12:
on server:
13:
Update Zser
h = Zser
h ∪Zloc
m,h.
14:
Initialize QH+1 = VH+1 = 0.
15:
for h = H, H −1, · · · , 1 do
16:
Calculate bfh according to (9) and bonus function bh = BS×A(Zser
h , Fh; λ, βk,h).
17:
Calculate Qh and Vh according to (11).
18:
end for
19:
Send {Qh}H
h=1 and {bh}H
h=1 to agent m.
20:
end of server
21:
Agent m receives Qm,h = Qh, bm,h = bh and resets Zloc
m,h = ∅for all h ∈[H].
22:
end if
23: end for"
MULTI-AGENT REINFORCEMENT LEARNING,0.20246913580246914,"The server maintains global historical datasets Zser
k,h containing sequences of tuples (sh, ah, rh, sh+1),
283"
MULTI-AGENT REINFORCEMENT LEARNING,0.20308641975308642,"initialized in Line 2. Each local agent m maintains optimistic value functions {Qm,k,h}H
h=1, bonus
284"
MULTI-AGENT REINFORCEMENT LEARNING,0.2037037037037037,"functions {bm,k,h}H
h=1, and local datasets {Zloc
m,k,h}H
h=1, all initialized in Line 3.
285"
MULTI-AGENT REINFORCEMENT LEARNING,0.204320987654321,"Each episode k of Algorithm 2 also consists of the two parts local exploration and server updates.
286"
MULTI-AGENT REINFORCEMENT LEARNING,0.20493827160493827,"Part I: Local Exploration. At step k an agent m = mk is active (Line 5). It interacts with
287"
MULTI-AGENT REINFORCEMENT LEARNING,0.20555555555555555,"the environment by executing the greedy policy according to {Qm,k,h}H
h=1, obtaining a trajectory
288"
MULTI-AGENT REINFORCEMENT LEARNING,0.20617283950617285,"{(sk
h, ak
h, rk
h, sk
h+1)}H
h=1, which is then stored into the local historical datasets Zloc
m,k,h (lines 6 - 9).
289"
MULTI-AGENT REINFORCEMENT LEARNING,0.20679012345679013,"After exploration, the agent checks for the following switch condition: there exists h ∈[H] so that
290
P"
MULTI-AGENT REINFORCEMENT LEARNING,0.2074074074074074,"oh∈Zloc
m,k,h b2
m,k,h(sh, ah)/
 
β2
k′,h + λ

≥α,
(8)"
MULTI-AGENT REINFORCEMENT LEARNING,0.2080246913580247,"where k′ is the last communication round for m. If so, the agent triggers communication (Line 11).
291"
MULTI-AGENT REINFORCEMENT LEARNING,0.20864197530864198,"Part II: Server Updates. After receiving new data, the server merges it with its global datasets Zser
k,h
292"
MULTI-AGENT REINFORCEMENT LEARNING,0.20925925925925926,"(Line 13) and calculates value function estimates {Qk+1,h}H
h=1 and {Vk+1,h}H
h=1 using LSVI.
293"
MULTI-AGENT REINFORCEMENT LEARNING,0.20987654320987653,"Suppose we already have Q- and V -value function estimates Qk+1,h+1 and Vk+1,h+1 at level h + 1.
294"
MULTI-AGENT REINFORCEMENT LEARNING,0.21049382716049383,"We solve the least squares problem for bfh to minimize the Bellman error (Line 16):
295"
MULTI-AGENT REINFORCEMENT LEARNING,0.2111111111111111,"bfk+1,h = argminfh∈Fh
P"
MULTI-AGENT REINFORCEMENT LEARNING,0.21172839506172839,"oh∈Zser
k,h
 
fh(zh) −rh −Vk+1,h+1(sh+1)
2.
(9)"
MULTI-AGENT REINFORCEMENT LEARNING,0.2123456790123457,"We now also define the uncertainty estimator of a new pair of data z = (s, a) against data history Z
296"
MULTI-AGENT REINFORCEMENT LEARNING,0.21296296296296297,"with normalization parameter λ and function class F as
297"
MULTI-AGENT REINFORCEMENT LEARNING,0.21358024691358024,"Dλ,F(z; Z) = supf1,f2∈F |f1(z) −f2(z)|
p λ + P"
MULTI-AGENT REINFORCEMENT LEARNING,0.21419753086419754,"o′∈Z |f1(z′) −f2(z′)|2.
(10)
Similar to the bandits setting, the uncertainty can be approximated with the bonus function acquired
298"
MULTI-AGENT REINFORCEMENT LEARNING,0.21481481481481482,"from an oracle BS×A in Definition 4.1. In this case, the domain D = S × A, and the data format
299"
MULTI-AGENT REINFORCEMENT LEARNING,0.2154320987654321,"corresponds to z = (s, a) and e = (r, s′). Despite these definitions not depending on the step h, we
300"
MULTI-AGENT REINFORCEMENT LEARNING,0.21604938271604937,"expect the parameters z, Z, F to always come from same step h. Finally, we allow the bonus function
301"
MULTI-AGENT REINFORCEMENT LEARNING,0.21666666666666667,"classes Wh = Wh,S×A to vary between different levels.
302"
MULTI-AGENT REINFORCEMENT LEARNING,0.21728395061728395,"After calling oracle for bk+1,h (Line 16), we can obtain value function estimates (Line 17):
303"
MULTI-AGENT REINFORCEMENT LEARNING,0.21790123456790123,"Qk+1,h(s, a) = bfk+1,h(s, a) + bk+1,h(s, a),
Vk+1,h(s) = supa∈A Qk+1,h(s, a).
(11)
Iterating through h = H, · · · , 1, the server calculates a set of updated Q-value functions
304"
MULTI-AGENT REINFORCEMENT LEARNING,0.21851851851851853,"{Qk+1,h}H
h=1 and bonus functions {bk+1,h}H
h=1, and send them back to agent m for future ex-
305"
MULTI-AGENT REINFORCEMENT LEARNING,0.2191358024691358,"ploration and updates (lines 19 and 21).
306"
THEORETICAL RESULTS,0.21975308641975308,"5.2
Theoretical Results
307"
THEORETICAL RESULTS,0.22037037037037038,"We summarize the regret and communication cost of Algorithm 2 in the following theorem:
308"
THEORETICAL RESULTS,0.22098765432098766,"Theorem 5.1. Taking γ = O(1/HK), βh,k = Cβ,2
h√"
THEORETICAL RESULTS,0.22160493827160493,"λ + HC(M, α)
p"
THEORETICAL RESULTS,0.2222222222222222,"log(3HMN(γ)/δ)
i
and
309"
THEORETICAL RESULTS,0.2228395061728395,"N(γ) := maxh N(Fh, γ)N(Fh+1, γ)N(Wh+1, γ), the regret within K rounds is bounded by
310"
THEORETICAL RESULTS,0.2234567901234568,"O

H eβ2
p"
THEORETICAL RESULTS,0.22407407407407406,"(1 + Mα) dimE K log(K/ min{1, λ}) + H2(1 + Mα) dimE log2(K/ min{1, λ})

."
THEORETICAL RESULTS,0.22469135802469137,"where we abbreviate dimE := dimE(F, λ/K); the total communication complexity is
O
 
H(1 + Mα)2α dimE(F, λ/K) log2(K/ min{1, λ})

.
Remark 5.2. This result when reduced to linear MDPs correspond well to Theorem 5.1 in Min
311"
THEORETICAL RESULTS,0.22530864197530864,"et al. [2023]. Taking α = 1/M 2, we get a regret of eO
 
H2√K dimE log N + H2 dimE

and a
312"
THEORETICAL RESULTS,0.22592592592592592,"communication cost of eO
 
HM 2 dimE

, where N = maxh{N(Fh, γ), N(Wh, γ)}.
313"
PROOF SKETCH,0.22654320987654322,"6
Proof Sketch
314"
PROOF SKETCH,0.2271604938271605,"In this section, we provide an outline for the proof of Theorem 5.1, while a more detailed proof can
315"
PROOF SKETCH,0.22777777777777777,"be found in Appendix B, and the full versions of the following lemmas are in Appendix B.1.
316"
REGRET UPPER BOUND,0.22839506172839505,"6.1
Regret Upper Bound
317"
REGRET UPPER BOUND,0.22901234567901235,"For the regret upper bound, the first lemma establishes optimism of value function estimates.
318"
REGRET UPPER BOUND,0.22962962962962963,"Lemma 6.1. Taking βk,h as in Theorem 5.1, with probability at least 1 −δ, for all k, z ∈S × A and
319"
REGRET UPPER BOUND,0.2302469135802469,"h ∈[H], |ThQk+1,h+1(z) −bfk+1,h(z)| ≤bk+1,h(z).
320"
REGRET UPPER BOUND,0.2308641975308642,"This allows us to decompose regret into a sum of bonuses:
321"
REGRET UPPER BOUND,0.23148148148148148,"Reg(K) = PK
k=1

V ∗
1 (sk
1) −V πm,k
1
(sk
1)
"
REGRET UPPER BOUND,0.23209876543209876,"≤PK
k=1
PH
h=1 Eπm,k

Qm,k,h −ThQm,k,h+1

(sk
h, ak
h) ≤PK
k=1
PH
h=12bm,k,h(sk
h, ak
h).
(12)
The sum of bonuses is equal to the sum of uncertainty up to a constant, which we bound in the
322"
REGRET UPPER BOUND,0.23271604938271606,"following lemma corresponding to the elliptical potential lemma [Abbasi-Yadkori et al., 2011].
323"
REGRET UPPER BOUND,0.23333333333333334,"Lemma 6.2. Define universal datasets as Zall
k,h = {ok′
h }k′∈[k]. Then we have for any h ∈[H]:
324"
REGRET UPPER BOUND,0.2339506172839506,"PK
k=1D2
λ,F(zk
h; Zall
k−1,h) = O
 
dimE(F, λ/K) log2(K/ min{1, λ})

."
REGRET UPPER BOUND,0.2345679012345679,"Careful examination exposes a problem: the uncertainty Dλ,F(z; Zser
k,h) corresponding to bonuses are
325"
REGRET UPPER BOUND,0.2351851851851852,"based on server data Zser
k,h instead of universal data Zall
k,h. The next lemma bridges this gap:
326"
REGRET UPPER BOUND,0.23580246913580247,"Lemma 6.3. For any z ∈S × A, k ∈[K], h ∈[H], D2
λ,F(z; Zser
k,h) ≤(1 + Mα)D2
λ,F(z; Zall
k,h).
327"
REGRET UPPER BOUND,0.23641975308641974,"With these, we can deduce the regret bound from (12).
328"
COMMUNICATION COST,0.23703703703703705,"6.2
Communication Cost
329"
COMMUNICATION COST,0.23765432098765432,"For communication cost, we employ an epoch segmentation scheme, which defines N epochs
330"
COMMUNICATION COST,0.2382716049382716,"segmented by episodes {ki}N
i=1, with ki being the smallest episode satisfying
331
P"
COMMUNICATION COST,0.2388888888888889,"oh∈Zser
ki,h\Zser
ki−1,h
PH
h=1 D2
λ,Fh(zh; Zser
ki−1,h) ≥1.
(13)"
COMMUNICATION COST,0.23950617283950618,"This is a generalization of epoch segmentation based on doubling determinants in linear settings, yet
332"
COMMUNICATION COST,0.24012345679012345,"the lack of determinant in the nonlinear case dramatically increases its complexity. Intuitively, switch
333"
COMMUNICATION COST,0.24074074074074073,"condition (8) suggests an agent must gather a substantial amount of data to trigger communication,
334"
COMMUNICATION COST,0.24135802469135803,"yet a careful analysis according to (13) yields a maximum of M +C/α communication rounds within
335"
COMMUNICATION COST,0.2419753086419753,"one epoch. With this we only need an upper bound for the number of epochs N. This is derived by
336"
COMMUNICATION COST,0.24259259259259258,"summing (13) over all epochs, then using Lemma 6.1 and Lemma 6.3 to bound the left hand side.
337"
CONCLUSIONS,0.24320987654320989,"7
Conclusions
338"
CONCLUSIONS,0.24382716049382716,"We propose the algorithms Async-NLin-UCB and Async-NLSVI-UCB to tackle multi-agent nonlinear
339"
CONCLUSIONS,0.24444444444444444,"contextual bandits and MDPs with asynchronous communication. We prove that our algorithms enjoy
340"
CONCLUSIONS,0.24506172839506174,"low regret and communication cost, which are comparable to previous results.
341"
CONCLUSIONS,0.24567901234567902,"Our algorithms employ a communication criterion that allows the agents to trigger communication
342"
CONCLUSIONS,0.2462962962962963,"rounds, effectively controlling communication cost while promoting the asynchronous protocol.
343"
CONCLUSIONS,0.24691358024691357,"Moreover, we carefully design the contents of server download to guard against data exposure.
344"
REFERENCES,0.24753086419753087,"References
345"
REFERENCES,0.24814814814814815,"Yasin Abbasi-Yadkori, Dávid Pál, and Csaba Szepesvári. Improved algorithms for linear stochastic bandits.
346"
REFERENCES,0.24876543209876542,"Advances in neural information processing systems, 24:2312–2320, 2011.
347"
REFERENCES,0.24938271604938272,"Alekh Agarwal and Tong Zhang. Model-based RL with optimistic posterior sampling: Structural conditions
348"
REFERENCES,0.25,"and sample complexity. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors,
349"
REFERENCES,0.2506172839506173,"Advances in Neural Information Processing Systems, 2022.
350"
REFERENCES,0.25123456790123455,"Alekh Agarwal, Yujia Jin, and Tong Zhang. Voql: Towards optimal regret in model-free rl with nonlinear function
351"
REFERENCES,0.2518518518518518,"approximation. In Gergely Neu and Lorenzo Rosasco, editors, Proceedings of Thirty Sixth Conference on
352"
REFERENCES,0.25246913580246916,"Learning Theory, volume 195 of Proceedings of Machine Learning Research, pages 987–1063. PMLR, 12–15
353"
REFERENCES,0.25308641975308643,"Jul 2023.
354"
REFERENCES,0.2537037037037037,"Ana LC Bazzan. Opportunities for multiagent systems and multiagent reinforcement learning in traffic control.
355"
REFERENCES,0.254320987654321,"Autonomous Agents and Multi-Agent Systems, 18(3):342–375, 2009.
356"
REFERENCES,0.25493827160493826,"Christopher Berner, Greg Brockman, Brooke Chan, Vicki Cheung, Przemysław D˛ebiak, Christy Dennison,
357"
REFERENCES,0.25555555555555554,"David Farhi, Quirin Fischer, Shariq Hashme, Chris Hesse, Rafal Józefowicz, Scott Gray, Catherine Olsson,
358"
REFERENCES,0.25617283950617287,"Jakub Pachocki, Michael Petrov, Henrique P. d. O. Pinto, Jonathan Raiman, Tim Salimans, Jeremy Schlatter,
359"
REFERENCES,0.25679012345679014,"Jonas Schneider, Szymon Sidor, Ilya Sutskever, Jie Tang, Filip Wolski, and Susan Zhang. Dota 2 with large
360"
REFERENCES,0.2574074074074074,"scale deep reinforcement learning. arXiv preprint arXiv:1912.06680, 2019.
361"
REFERENCES,0.2580246913580247,"Mithun Chakraborty, Kee Yuan Peh Chua, Sanmay Das, and Brendan Juba. Coordinated versus decentralized
362"
REFERENCES,0.25864197530864197,"exploration in multi-agent multi-armed bandits. In IJCAI, 2017.
363"
REFERENCES,0.25925925925925924,"Alfredo V Clemente, Humberto N Castejón, and Arjun Chandra. Efficient parallel methods for deep reinforce-
364"
REFERENCES,0.2598765432098765,"ment learning. arXiv preprint arXiv:1705.04862, 2017.
365"
REFERENCES,0.26049382716049385,"Qiwei Di, Heyang Zhao, Jiafan He, and Quanquan Gu. Pessimistic nonlinear least-squares value iteration for
366"
REFERENCES,0.2611111111111111,"offline reinforcement learning. arXiv preprint arXiv:2310.01380, 2023.
367"
REFERENCES,0.2617283950617284,"Guohui Ding, Joewie J Koh, Kelly Merckaert, Bram Vanderborght, Marco M Nicotra, Christoffer Heckman,
368"
REFERENCES,0.2623456790123457,"Alessandro Roncone, and Lijun Chen. Distributed reinforcement learning for cooperative multi-robot object
369"
REFERENCES,0.26296296296296295,"manipulation. In Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent
370"
REFERENCES,0.26358024691358023,"Systems, pages 1831–1833, 2020.
371"
REFERENCES,0.2641975308641975,"Simon Du, Sham Kakade, Jason Lee, Shachar Lovett, Gaurav Mahajan, Wen Sun, and Ruosong Wang. Bilinear
372"
REFERENCES,0.26481481481481484,"classes: A structural framework for provable generalization in rl. In Marina Meila and Tong Zhang, editors,
373"
REFERENCES,0.2654320987654321,"Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of
374"
REFERENCES,0.2660493827160494,"Machine Learning Research, pages 2826–2836. PMLR, 18–24 Jul 2021.
375"
REFERENCES,0.26666666666666666,"Abhimanyu Dubey and Alex Pentland. Provably efficient cooperative multi-agent reinforcement learning with
376"
REFERENCES,0.26728395061728394,"function approximation. arXiv preprint arXiv:2103.04972, 2021.
377"
REFERENCES,0.2679012345679012,"Abhimanyu Dubey and AlexSandy’ Pentland. Differentially-private federated linear bandits. Advances in Neural
378"
REFERENCES,0.26851851851851855,"Information Processing Systems, 33:6003–6014, 2020.
379"
REFERENCES,0.2691358024691358,"Lasse Espeholt, Hubert Soyer, Remi Munos, Karen Simonyan, Vlad Mnih, Tom Ward, Yotam Doron, Vlad
380"
REFERENCES,0.2697530864197531,"Firoiu, Tim Harley, Iain Dunning, et al. Impala: Scalable distributed deep-rl with importance weighted
381"
REFERENCES,0.27037037037037037,"actor-learner architectures. In International conference on machine learning, pages 1407–1416. PMLR, 2018.
382"
REFERENCES,0.27098765432098765,"Dylan J. Foster, Sham M. Kakade, Jian Qian, and Alexander Rakhlin. The statistical complexity of interactive
383"
REFERENCES,0.2716049382716049,"decision making, 2023.
384"
REFERENCES,0.2722222222222222,"Claudio Gentile, Zhilei Wang, and Tong Zhang. Fast rates in pool-based batch active learning, 2022.
385"
REFERENCES,0.27283950617283953,"Jiafan He, Tianhao Wang, Yifei Min, and Quanquan Gu. A simple and provably efficient algorithm for
386"
REFERENCES,0.2734567901234568,"asynchronous federated contextual linear bandits. In Advances in Neural Information Processing Systems,
387"
REFERENCES,0.2740740740740741,"2022.
388"
REFERENCES,0.27469135802469136,"Dan Horgan, John Quan, David Budden, Gabriel Barth-Maron, Matteo Hessel, Hado van Hasselt, and David
389"
REFERENCES,0.27530864197530863,"Silver. Distributed prioritized experience replay. In International Conference on Learning Representations,
390"
REFERENCES,0.2759259259259259,"2018.
391"
REFERENCES,0.2765432098765432,"Ruiquan Huang, Weiqiang Wu, Jing Yang, and Cong Shen. Federated linear contextual bandits. In A. Beygelz-
392"
REFERENCES,0.2771604938271605,"imer, Y. Dauphin, P. Liang, and J. Wortman Vaughan, editors, Advances in Neural Information Processing
393"
REFERENCES,0.2777777777777778,"Systems, 2021.
394"
REFERENCES,0.27839506172839507,"Max Jaderberg, Wojciech M Czarnecki, Iain Dunning, Luke Marris, Guy Lever, Antonio Garcia Castaneda,
395"
REFERENCES,0.27901234567901234,"Charles Beattie, Neil C Rabinowitz, Ari S Morcos, Avraham Ruderman, et al. Human-level performance in
396"
REFERENCES,0.2796296296296296,"3d multiplayer games with population-based reinforcement learning. Science, 364(6443):859–865, 2019.
397"
REFERENCES,0.2802469135802469,"Nan Jiang, Akshay Krishnamurthy, Alekh Agarwal, John Langford, and Robert E. Schapire. Contextual decision
398"
REFERENCES,0.2808641975308642,"processes with low Bellman rank are PAC-learnable. In Doina Precup and Yee Whye Teh, editors, Proceedings
399"
REFERENCES,0.2814814814814815,"of the 34th International Conference on Machine Learning, volume 70 of Proceedings of Machine Learning
400"
REFERENCES,0.2820987654320988,"Research, pages 1704–1713. PMLR, 06–11 Aug 2017.
401"
REFERENCES,0.28271604938271605,"Chi Jin, Zhuoran Yang, Zhaoran Wang, and Michael I Jordan. Provably efficient reinforcement learning with
402"
REFERENCES,0.2833333333333333,"linear function approximation. In Conference on Learning Theory, pages 2137–2143. PMLR, 2020.
403"
REFERENCES,0.2839506172839506,"Chi Jin, Qinghua Liu, and Sobhan Miryoosefi. Bellman eluder dimension: New rich classes of RL problems,
404"
REFERENCES,0.2845679012345679,"and sample-efficient algorithms. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan, editors,
405"
REFERENCES,0.2851851851851852,"Advances in Neural Information Processing Systems, 2021.
406"
REFERENCES,0.2858024691358025,"Hao Jin, Yang Peng, Wenhao Yang, Shusen Wang, and Zhihua Zhang. Federated reinforcement learning with
407"
REFERENCES,0.28641975308641976,"environment heterogeneity. In International Conference on Artificial Intelligence and Statistics, pages 18–37.
408"
REFERENCES,0.28703703703703703,"PMLR, 2022.
409"
REFERENCES,0.2876543209876543,"Dingwen Kong, Ruslan Salakhutdinov, Ruosong Wang, and Lin F. Yang. Online sub-sampling for reinforcement
410"
REFERENCES,0.2882716049382716,"learning with general function approximation, 2023.
411"
REFERENCES,0.28888888888888886,"Nathan Korda, Balázs Szörényi, and Shuai Li. Distributed clustering of linear bandits in peer to peer networks.
412"
REFERENCES,0.2895061728395062,"In Proceedings of the 33rd International Conference on International Conference on Machine Learning -
413"
REFERENCES,0.29012345679012347,"Volume 48, ICML’16, page 1301–1309. JMLR.org, 2016.
414"
REFERENCES,0.29074074074074074,"Jakub Grudzien Kuba, Ruiqing Chen, Muning Wen, Ying Wen, Fanglei Sun, Jun Wang, and Yaodong Yang. Trust
415"
REFERENCES,0.291358024691358,"region policy optimisation in multi-agent reinforcement learning. In International Conference on Learning
416"
REFERENCES,0.2919753086419753,"Representations, 2022.
417"
REFERENCES,0.29259259259259257,"Peter Landgren, Vaibhav Srivastava, and Naomi Ehrich Leonard. On distributed cooperative decision-making in
418"
REFERENCES,0.2932098765432099,"multiarmed bandits. In 2016 European Control Conference (ECC), pages 243–248, 2016.
419"
REFERENCES,0.2938271604938272,"Peter Landgren, Vaibhav Srivastava, and Naomi Ehrich Leonard. Social imitation in cooperative multiarmed
420"
REFERENCES,0.29444444444444445,"bandits: Partition-based algorithms with strictly local information. In 2018 IEEE Conference on Decision and
421"
REFERENCES,0.29506172839506173,"Control (CDC), 2018.
422"
REFERENCES,0.295679012345679,"Chuanhao Li and Hongning Wang. Asynchronous upper confidence bound algorithms for federated linear
423"
REFERENCES,0.2962962962962963,"bandits. In International Conference on Artificial Intelligence and Statistics, pages 6529–6553. PMLR, 2022.
424"
REFERENCES,0.29691358024691356,"Gene Li, Pritish Kamath, Dylan J Foster, and Nati Srebro. Understanding the eluder dimension. In S. Koyejo,
425"
REFERENCES,0.2975308641975309,"S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information
426"
REFERENCES,0.29814814814814816,"Processing Systems, volume 35, pages 23737–23750. Curran Associates, Inc., 2022.
427"
REFERENCES,0.29876543209876544,"Boyi Liu, Lujia Wang, and Ming Liu. Lifelong federated reinforcement learning: a learning architecture for
428"
REFERENCES,0.2993827160493827,"navigation in cloud robotic systems. IEEE Robotics and Automation Letters, 4(4):4555–4562, 2019.
429"
REFERENCES,0.3,"Dianbo Liu, Vedant Shah, Oussama Boussif, Cristian Meo, Anirudh Goyal, Tianmin Shu, Michael Mozer,
430"
REFERENCES,0.30061728395061726,"Nicolas Heess, and Yoshua Bengio. Stateful active facilitator: Coordination and environmental heterogeneity
431"
REFERENCES,0.3012345679012346,"in cooperative multi-agent reinforcement learning. arXiv preprint arXiv:2210.03022, 2022.
432"
REFERENCES,0.30185185185185187,"Dongfang Liu, Yiming Cui, Zhiwen Cao, and Yingjie Chen. Indoor navigation for mobile agents: A multimodal
433"
REFERENCES,0.30246913580246915,"vision fusion model. In 2020 International Joint Conference on Neural Networks (IJCNN), pages 1–8. IEEE,
434"
REFERENCES,0.3030864197530864,"2020.
435"
REFERENCES,0.3037037037037037,"Keqin Liu and Qing Zhao. Distributed learning in multi-armed bandit with multiple players. IEEE Transactions
436"
REFERENCES,0.304320987654321,"on Signal Processing, 58(11):5667–5681, 2010. doi: 10.1109/TSP.2010.2062509.
437"
REFERENCES,0.30493827160493825,"Ryan Lowe, Yi I Wu, Aviv Tamar, Jean Harb, OpenAI Pieter Abbeel, and Igor Mordatch. Multi-agent actor-critic
438"
REFERENCES,0.3055555555555556,"for mixed cooperative-competitive environments. Advances in neural information processing systems, 30,
439"
REFERENCES,0.30617283950617286,"2017.
440"
REFERENCES,0.30679012345679013,"David Martínez-Rubio, Varun Kanade, and Patrick Rebeschini. Decentralized cooperative stochastic bandits.
441"
REFERENCES,0.3074074074074074,"In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett, editors, Advances in
442"
REFERENCES,0.3080246913580247,"Neural Information Processing Systems. Curran Associates, Inc., 2019.
443"
REFERENCES,0.30864197530864196,"Yifei Min, Tianhao Wang, Ruitu Xu, Zhaoran Wang, Michael Jordan, and Zhuoran Yang. Learn to match with no
444"
REFERENCES,0.30925925925925923,"regret: Reinforcement learning in markov matching markets. In Advances in Neural Information Processing
445"
REFERENCES,0.30987654320987656,"Systems, 2022.
446"
REFERENCES,0.31049382716049384,"Yifei Min, Jiafan He, Tianhao Wang, and Quanquan Gu. Cooperative multi-agent reinforcement learning:
447"
REFERENCES,0.3111111111111111,"Asynchronous communication and linear function approximation. In Andreas Krause, Emma Brunskill,
448"
REFERENCES,0.3117283950617284,"Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, Proceedings of the 40th
449"
REFERENCES,0.31234567901234567,"International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research,
450"
REFERENCES,0.31296296296296294,"pages 24785–24811. PMLR, 23–29 Jul 2023.
451"
REFERENCES,0.3135802469135803,"Seongin Na, Tomáš Rouˇcek, Jiˇrí Ulrich, Jan Pikman, Tomáš Krajník, Barry Lennox, and Farshad Arvin.
452"
REFERENCES,0.31419753086419755,"Federated reinforcement learning for collective navigation of robotic swarms, 2022.
453"
REFERENCES,0.3148148148148148,"Arun Nair, Praveen Srinivasan, Sam Blackwell, Cagdas Alcicek, Rory Fearon, Alessandro De Maria, Vedavyas
454"
REFERENCES,0.3154320987654321,"Panneershelvam, Mustafa Suleyman, Charles Beattie, Stig Petersen, et al. Massively parallel methods for
455"
REFERENCES,0.3160493827160494,"deep reinforcement learning. arXiv preprint arXiv:1507.04296, 2015.
456"
REFERENCES,0.31666666666666665,"Jiaju Qi, Qihao Zhou, Lei Lei, and Kan Zheng. Federated reinforcement learning: techniques, applications, and
457"
REFERENCES,0.3172839506172839,"open challenges. arXiv preprint arXiv:2108.11887, 2021.
458"
REFERENCES,0.31790123456790126,"Daniel Russo and Benjamin Van Roy. Eluder dimension and the sample complexity of optimistic exploration.
459"
REFERENCES,0.31851851851851853,"In C.J. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K.Q. Weinberger, editors, Advances in Neural
460"
REFERENCES,0.3191358024691358,"Information Processing Systems, volume 26. Curran Associates, Inc., 2013.
461"
REFERENCES,0.3197530864197531,"Abishek Sankararaman, Ayalvadi Ganesh, and Sanjay Shakkottai. Social learning in multi agent multi armed
462"
REFERENCES,0.32037037037037036,"bandits. Proc. ACM Meas. Anal. Comput. Syst., 3(3), 2019.
463"
REFERENCES,0.32098765432098764,"Richard S Sutton and Andrew G Barto. Reinforcement learning: An introduction. MIT press, 2018.
464"
REFERENCES,0.3216049382716049,"Balazs Szorenyi, Robert Busa-Fekete, Istvan Hegedus, Robert Ormandi, Mark Jelasity, and Balazs Kegl. Gossip-
465"
REFERENCES,0.32222222222222224,"based distributed stochastic bandit algorithms. In Proceedings of the 30th International Conference on
466"
REFERENCES,0.3228395061728395,"Machine Learning, 2013.
467"
REFERENCES,0.3234567901234568,"Oriol Vinyals, Timo Ewalds, Sergey Bartunov, Petko Georgiev, Alexander Sasha Vezhnevets, Michelle Yeo,
468"
REFERENCES,0.32407407407407407,"Alireza Makhzani, Heinrich Küttler, John Agapiou, Julian Schrittwieser, et al. Starcraft ii: A new challenge
469"
REFERENCES,0.32469135802469135,"for reinforcement learning. arXiv preprint arXiv:1708.04782, 2017.
470"
REFERENCES,0.3253086419753086,"Hoi-To Wai, Zhuoran Yang, Zhaoran Wang, and Mingyi Hong. Multi-agent reinforcement learning via double
471"
REFERENCES,0.32592592592592595,"averaging primal-dual optimization. Advances in Neural Information Processing Systems, 31, 2018.
472"
REFERENCES,0.32654320987654323,"Martin Wainwright. High-Dimensional Statistics: A Non-Asymptotic Viewpoint. 02 2019. ISBN 9781108498029.
473"
REFERENCES,0.3271604938271605,"Po-An Wang, Alexandre Proutiere, Kaito Ariu, Yassir Jedra, and Alessio Russo. Optimal algorithms for
474"
REFERENCES,0.3277777777777778,"multiplayer multi-armed bandits. In Silvia Chiappa and Roberto Calandra, editors, Proceedings of the Twenty
475"
REFERENCES,0.32839506172839505,"Third International Conference on Artificial Intelligence and Statistics, volume 108 of Proceedings of Machine
476"
REFERENCES,0.32901234567901233,"Learning Research, pages 4120–4129. PMLR, 26–28 Aug 2020a.
477"
REFERENCES,0.3296296296296296,"Ruosong Wang, Russ R Salakhutdinov, and Lin Yang. Reinforcement learning with general value function
478"
REFERENCES,0.33024691358024694,"approximation: Provably efficient approach via bounded eluder dimension. In H. Larochelle, M. Ranzato,
479"
REFERENCES,0.3308641975308642,"R. Hadsell, M.F. Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems, volume 33,
480"
REFERENCES,0.3314814814814815,"pages 6123–6135. Curran Associates, Inc., 2020b.
481"
REFERENCES,0.33209876543209876,"Yuanhao Wang, Jiachen Hu, Xiaoyu Chen, and Liwei Wang. Distributed bandit learning: Near-optimal regret
482"
REFERENCES,0.33271604938271604,"with efficient communication. In International Conference on Learning Representations, 2020c.
483"
REFERENCES,0.3333333333333333,"Grady Williams, Paul Drews, Brian Goldfain, James M Rehg, and Evangelos A Theodorou. Aggressive
484"
REFERENCES,0.3339506172839506,"driving with model predictive path integral control. In 2016 IEEE International Conference on Robotics and
485"
REFERENCES,0.3345679012345679,"Automation (ICRA), pages 1433–1440. IEEE, 2016.
486"
REFERENCES,0.3351851851851852,"Ruitu Xu, Yifei Min, Tianhao Wang, Michael I Jordan, Zhaoran Wang, and Zhuoran Yang. Finding regular-
487"
REFERENCES,0.3358024691358025,"ized competitive equilibria of heterogeneous agent macroeconomic models via reinforcement learning. In
488"
REFERENCES,0.33641975308641975,"International Conference on Artificial Intelligence and Statistics, pages 375–407. PMLR, 2023.
489"
REFERENCES,0.337037037037037,"Chenlu Ye, Wei Xiong, Quanquan Gu, and Tong Zhang.
Corruption-robust algorithms with uncertainty
490"
REFERENCES,0.3376543209876543,"weighting for nonlinear contextual bandits and Markov decision processes. In Andreas Krause, Emma
491"
REFERENCES,0.33827160493827163,"Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, Proceedings of
492"
REFERENCES,0.3388888888888889,"the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning
493"
REFERENCES,0.3395061728395062,"Research, pages 39834–39863. PMLR, 23–29 Jul 2023.
494"
REFERENCES,0.34012345679012346,"Deheng Ye, Guibin Chen, Wen Zhang, Sheng Chen, Bo Yuan, Bo Liu, Jia Chen, Zhao Liu, Fuhao Qiu, Hongsheng
495"
REFERENCES,0.34074074074074073,"Yu, et al. Towards playing full moba games with deep reinforcement learning. Advances in Neural Information
496"
REFERENCES,0.341358024691358,"Processing Systems, 33:621–632, 2020.
497"
REFERENCES,0.3419753086419753,"Chao Yu, Akash Velu, Eugene Vinitsky, Yu Wang, Alexandre Bayen, and Yi Wu. The surprising effectiveness of
498"
REFERENCES,0.3425925925925926,"ppo in cooperative, multi-agent games. arXiv preprint arXiv:2103.01955, 2021.
499"
REFERENCES,0.3432098765432099,"Shuai Yu, Xu Chen, Zhi Zhou, Xiaowen Gong, and Di Wu. When deep reinforcement learning meets federated
500"
REFERENCES,0.34382716049382717,"learning: Intelligent multitimescale resource management for multiaccess edge computing in 5g ultradense
501"
REFERENCES,0.34444444444444444,"network. IEEE Internet of Things Journal, 8(4):2238–2251, 2020.
502"
REFERENCES,0.3450617283950617,"Tao Yu, HZ Wang, Bin Zhou, Ka Wing Chan, and J Tang. Multi-agent correlated equilibrium q (λ) learning for
503"
REFERENCES,0.345679012345679,"coordinated smart generation control of interconnected power grids. IEEE transactions on power systems, 30
504"
REFERENCES,0.34629629629629627,"(4):1669–1679, 2014.
505"
REFERENCES,0.3469135802469136,"Kaiqing Zhang, Zhuoran Yang, and Tamer Basar. Networked multi-agent reinforcement learning in continuous
506"
REFERENCES,0.3475308641975309,"spaces. In 2018 IEEE conference on decision and control (CDC), pages 2771–2776. IEEE, 2018a.
507"
REFERENCES,0.34814814814814815,"Kaiqing Zhang, Zhuoran Yang, Han Liu, Tong Zhang, and Tamer Basar. Fully decentralized multi-agent
508"
REFERENCES,0.3487654320987654,"reinforcement learning with networked agents. In International Conference on Machine Learning, pages
509"
REFERENCES,0.3493827160493827,"5872–5881. PMLR, 2018b.
510"
REFERENCES,0.35,"Heyang Zhao, Jiafan He, and Quanquan Gu. A nearly optimal and low-switching algorithm for reinforcement
511"
REFERENCES,0.3506172839506173,"learning with general function approximation, 2023.
512"
REFERENCES,0.3512345679012346,"Zhaowei Zhu, Jingxuan Zhu, Ji Liu, and Yang Liu. Federated bandit: A gossiping approach. Proc. ACM Meas.
513"
REFERENCES,0.35185185185185186,"Anal. Comput. Syst., 5(1), 2021.
514"
REFERENCES,0.35246913580246914,"Hankz Hankui Zhuo, Wenfeng Feng, Yufeng Lin, Qian Xu, and Qiang Yang. Federated deep reinforcement
515"
REFERENCES,0.3530864197530864,"learning. arXiv preprint arXiv:1901.08277, 2019.
516"
REFERENCES,0.3537037037037037,"Impact Statement
517"
REFERENCES,0.35432098765432096,"Our work has the potential to enhance cooperative learning systems across diverse fields. By
518"
REFERENCES,0.3549382716049383,"introducing algorithms that enable efficient collaboration among agents with minimal communication
519"
REFERENCES,0.35555555555555557,"overhead, our research paves the way for advancements in distributed systems, including robotics,
520"
REFERENCES,0.35617283950617284,"traffic management, and distributed sensor networks. This could lead to more adaptive, efficient,
521"
REFERENCES,0.3567901234567901,"and scalable systems capable of tackling complex problems in dynamic environments, ultimately
522"
REFERENCES,0.3574074074074074,"contributing to technological progress and societal well-being.
523"
REFERENCES,0.35802469135802467,"As far as we can tell, there is hardly any negative social impact from our work, mainly because we do
524"
REFERENCES,0.358641975308642,"not include experiments apart from our theoretical analysis.
525"
REFERENCES,0.3592592592592593,"A
The Bandit Case: Proof of Theorem 4.3
526"
REFERENCES,0.35987654320987655,"Before we begin the analysis of Algorithm 1, we reiterate and add some notations for clarity and
convenience. Define the data collected by agent m that has already been uploaded to the server
by round t as Zup
m,t, and the universal data at round t as Zall
t . Apart from these we also have from
the algorithm the datasets Zloc
m,t and Zser
t . It is not difficult to check that they satisfy the following
relation:"
REFERENCES,0.36049382716049383,"Zall
t = M
[ m=1"
REFERENCES,0.3611111111111111," 
Zup
m,t ∪Zloc
m,t

."
REFERENCES,0.3617283950617284,"Furthermore, when t is not a communication round, we also have"
REFERENCES,0.36234567901234566,"Zser
t
= M
["
REFERENCES,0.362962962962963,"m=1
Zup
m,t,"
REFERENCES,0.36358024691358026,and when it is a communication round that
REFERENCES,0.36419753086419754,"Zser
t
=

M
["
REFERENCES,0.3648148148148148,"m=1
Zup
m,t"
REFERENCES,0.3654320987654321,"
∪Zloc
mt,t,"
REFERENCES,0.36604938271604937,"which will be useful in our proof of Lemma A.1 and B.1 in Section C.1.
527"
REFERENCES,0.36666666666666664,"Next, we assume that at rounds 0 = t0 < t1 < · · · < tL < tL+1 = T + 1, the participating agent
528"
REFERENCES,0.36728395061728397,"communicates with the server, where t0 and tK+1 are dummy rounds. The subscripts will be denoted
529"
REFERENCES,0.36790123456790125,"as l = 1, · · · , L in the future.
530"
REFERENCES,0.3685185185185185,"We now describe a participant reordering trick for our asynchronous multi-agent setting, which we will
531"
REFERENCES,0.3691358024691358,"use multiple times in the proof. The basic idea is that, as long as the communication order remains the
532"
REFERENCES,0.3697530864197531,"same, and for any given agent, the number of rounds between two consecutive communication rounds
533"
REFERENCES,0.37037037037037035,"remains the same, one can switch the episodes around and change the order of agent participation to
534"
REFERENCES,0.3709876543209877,"a certain degree. For example, we may assume that mt = mtl for all t ∈(tl−1, tl] by reordering the
535"
REFERENCES,0.37160493827160496,"participants, which means all participation of any given agent happens immediately before a certain
536"
REFERENCES,0.37222222222222223,"communication round; as another example, we may assume mt = mtl−1 for all t ∈[tl−1, tl), which
537"
REFERENCES,0.3728395061728395,"means all participation happen immediately after communication rounds. It should be noted that one
538"
REFERENCES,0.3734567901234568,"needs to be careful when utilizing this argument, since switching the participation order changes the
539"
REFERENCES,0.37407407407407406,"values of tl and many associated elements, so applying this trick twice in succession would lead to
540"
REFERENCES,0.37469135802469133,"contradictions.
541"
REFERENCES,0.37530864197530867,"For a dataset Z, we define the Z-norm on function set F as ∥f∥2
Z := P"
REFERENCES,0.37592592592592594,"(a,r)∈Z f 2(a) for any f ∈F.
Then we have the shortened notation"
REFERENCES,0.3765432098765432,"Dλ,F(a; Z) =
sup
f1,f2∈F"
REFERENCES,0.3771604938271605,"|f1(a) −f2(a)|
p"
REFERENCES,0.37777777777777777,"λ + ∥f1 −f2∥2
Z
."
REFERENCES,0.37839506172839504,"Finally, we define the confidence set of functions at round t + 1 as:
542"
REFERENCES,0.3790123456790123,"Ft+1 =

f ∈F :
X"
REFERENCES,0.37962962962962965,"(a,r)∈Zser
t"
REFERENCES,0.3802469135802469," 
f(a) −bft+1(a)
2 ≤β2
t"
REFERENCES,0.3808641975308642,"
,
(14)"
REFERENCES,0.3814814814814815,"which is a common construction in reinforcement learning.
543"
REFERENCES,0.38209876543209875,"A.1
Auxiliary Lemmas
544"
REFERENCES,0.38271604938271603,"In this section we present some auxiliary lemmas that will be used in the proof of Theorem 4.3. Note
545"
REFERENCES,0.38333333333333336,"these lemmas correspond well to the lemmas presented in 6, only that these are for the contextual
546"
REFERENCES,0.38395061728395063,"bandit case. The proofs for these lemmas can be found in Section C.
547"
REFERENCES,0.3845679012345679,"Lemma A.1. For any t ∈[T], m ∈[M] and f1, f2 ∈F, as long as agent m does not communicate
with the server at time step t, we have λ +
X"
REFERENCES,0.3851851851851852,"m′∈[M]
∥f1 −f2∥2
Zup
m′,t ≥1"
REFERENCES,0.38580246913580246,"α∥f1 −f2∥2
Zloc
m,t."
REFERENCES,0.38641975308641974,"Furthermore, for any t ∈[T] and f1, f2 ∈F,"
REFERENCES,0.387037037037037,"λ + ∥f1 −f2∥2
Zser
t ≥
1
1 + Mα
 
λ + ∥f1 −f2∥2
Zall
t

,"
REFERENCES,0.38765432098765434,"and as a corollary, for any a ∈A,"
REFERENCES,0.3882716049382716,"D2
λ,F(a; Zser
t ) ≤(1 + Mα)D2
λ,F(a; Zall
t )"
REFERENCES,0.3888888888888889,"This lemma describes the discrepancy between different datasets. Crucially, it provides a worst case
548"
REFERENCES,0.38950617283950617,"ratio between uncertainty measured on the server dataset and universal dataset. This is an important
549"
REFERENCES,0.39012345679012345,"tool for bridging between the different uncertainty estimators in the following proofs. The proof can
550"
REFERENCES,0.3907407407407407,"be found in Section C.1.
551"
REFERENCES,0.391358024691358,Lemma A.2. By taking γ = O(1/T) and
REFERENCES,0.39197530864197533,"βt = eβ1 := Cβ,1
√ λ +
p"
REFERENCES,0.3925925925925926,"(γ2 + γR)T + RC(M, α) log(3MN(F, γ)/δ)

,"
REFERENCES,0.3932098765432099,"with Cβ,1 = 6, where C(M, α) :=
√"
REFERENCES,0.39382716049382716,"1 + Mα + M√α, we have f ∗∈Ft+1 for all t ∈{tl}L
l=1 with
552"
REFERENCES,0.39444444444444443,"probability at least 1 −δ. As a corollary, we also have |f∗(a) −bft+1(a)| ≤bt+1(a) for any a ∈At
553"
REFERENCES,0.3950617283950617,"and t ∈{tl}L
l=1.
554"
REFERENCES,0.39567901234567904,"This is the central optimism lemma present in all provably efficient reinforcement learning literature.
555"
REFERENCES,0.3962962962962963,"It states that the confidence function set contains the ground truth function f ∗with high probability,
556"
REFERENCES,0.3969135802469136,"and in our case, that the decision function bft + bt is optimistic. With this, we define the good event
557"
REFERENCES,0.39753086419753086,"ET = {f ∗∈Ft+1, ∀t ∈{tl}L
l=1}. Then according to A.2, P(ET ) ≥1 −δ. The proof can be found
558"
REFERENCES,0.39814814814814814,"in Section C.2.
559"
REFERENCES,0.3987654320987654,"Lemma A.3. The sum of squared uncertainty estimators of new data over all historical data can be
bounded as follows with some absolute constant CD: T
X"
REFERENCES,0.3993827160493827,"t=1
D2
λ,F(at; Zall
t−1) ≤CD dimE(F, λ/T) log2(T/ min{1, λ})"
REFERENCES,0.4,"This lemma corresponds to the elliptical potential argument from the linear setting [Abbasi-Yadkori
560"
REFERENCES,0.4006172839506173,"et al., 2011]. In the nonlinear setting, this lemma essentially reveals the relationship between the sum
561"
REFERENCES,0.4012345679012346,"of Eluder-like confidence quantities and the Eluder dimension. The proof can be found in Section
562"
REFERENCES,0.40185185185185185,"C.3.
563"
REFERENCES,0.4024691358024691,"A.2
The Epoch Segmentation Scheme
564"
REFERENCES,0.4030864197530864,"In this section, we introduce an epoch segmentation scheme, which is needed for both the regret and
565"
REFERENCES,0.40370370370370373,"communication cost proofs presented in the next two sections. It is a generalization of the epoch
566"
REFERENCES,0.404320987654321,"segmentation scheme based on doubling determinant in the linear bandits / MDPs setting [He et al.,
567"
REFERENCES,0.4049382716049383,"2022, Min et al., 2023], but the lack of a Gram matrix (used for linear regression) in the nonlinear
568"
REFERENCES,0.40555555555555556,"case complicates matters significantly.
569"
REFERENCES,0.40617283950617283,"We segment the entire run of t = 1, · · · , T into N epochs as follows. Define iteratively 0 = l0 <
l1 < · · · < lN ≤L as"
REFERENCES,0.4067901234567901,"li = min

l > li−1 : l
X"
REFERENCES,0.4074074074074074,l′=li−1+1 X
REFERENCES,0.4080246913580247,"(a,r)∈Zloc
m,tl′"
REFERENCES,0.408641975308642,"D2
λ,F(a; Zser
tli−1) ≥1

,"
REFERENCES,0.40925925925925927,"where for a given l′ in the summation, m = mtl′ is the participating agent at tl′. In the iterative
570"
REFERENCES,0.40987654320987654,"process, if the above minimum does not exist, simply define N = i −1 and end the process there.
571"
REFERENCES,0.4104938271604938,"Correspondingly, the i-th epoch is defined by the time steps [tli−1, tli).
572"
REFERENCES,0.4111111111111111,"The following sections will make use of this epoch scheme as befit their needs, but here we shall give
573"
REFERENCES,0.41172839506172837,"an upper bound for the total number of epochs N. Based on the definition of li, we have for any
574"
REFERENCES,0.4123456790123457,"li−1 ≤l < li that
575 1 ≥ l
X"
REFERENCES,0.412962962962963,l′=li−1+1 X
REFERENCES,0.41358024691358025,"(a,r)∈Zloc
mtl′ ,tl′"
REFERENCES,0.4141975308641975,"D2
λ,F(a; Zser
tli−1) = l
X"
REFERENCES,0.4148148148148148,l′=li−1+1 X
REFERENCES,0.4154320987654321,"(a,r)∈Zser
tl′ \Zser
tl′−1"
REFERENCES,0.4160493827160494,"sup
f1,f2∈F"
REFERENCES,0.4166666666666667,[f1(a) −f2(a)]2
REFERENCES,0.41728395061728396,"λ + ∥f1 −f2∥2
Zser
tli−1"
REFERENCES,0.41790123456790124,"≥
sup
f1,f2∈F P"
REFERENCES,0.4185185185185185,"(a,r)∈Zser
tl \Zser
tli−1
[f1(a) −f2(a)]2"
REFERENCES,0.4191358024691358,"λ + ∥f1 −f2∥2
Zser
tli−1"
REFERENCES,0.41975308641975306,"=
sup
f1,f2∈F"
REFERENCES,0.4203703703703704,"λ + ∥f1 −f2∥2
Zser
tl
λ + ∥f1 −f2∥2
Zser
tli−1 −1,"
REFERENCES,0.42098765432098767,"which gives λ + ∥f1 −f2∥2
Zser
tl ≤2
 
λ + ∥f1 −f2∥2
Zser
tli−1"
REFERENCES,0.42160493827160495,"
for any f1, f2 ∈F. Then we have
576"
REFERENCES,0.4222222222222222,"D2
λ,F(a; Zser
tli−1) ≤2D2
λ,F(a; Zser
tl )
(15)"
REFERENCES,0.4228395061728395,"for any a, and so
577 1 ≤
X"
REFERENCES,0.42345679012345677,"(a,r)∈Zser
tli \Zser
tli−1"
REFERENCES,0.42407407407407405,"D2
λ,F(a; Zser
tli−1) = li
X"
REFERENCES,0.4246913580246914,l=li−1+1 X
REFERENCES,0.42530864197530865,"(a,r)∈Zser
tl \Zser
tl−1"
REFERENCES,0.42592592592592593,"D2
λ,F(a; Zser
tli−1) ≤2 li
X"
REFERENCES,0.4265432098765432,l=li−1+1 X
REFERENCES,0.4271604938271605,"(a,r)∈Zser
tl \Zser
tl−1"
REFERENCES,0.42777777777777776,"D2
λ,F(a; Zser
tl−1),"
REFERENCES,0.4283950617283951,"and summing over i = 1, · · · , N −1 that:
578"
REFERENCES,0.42901234567901236,"N −1 ≤2 L
X l=1 X"
REFERENCES,0.42962962962962964,"(a,r)∈Zser
tl \Zser
tl−1"
REFERENCES,0.4302469135802469,"D2
λ,F(a; Zser
tl−1)."
REFERENCES,0.4308641975308642,"If we apply the participant reordering trick and let mt = mtl for all t ∈(tl−1, tl] and l ∈[L], we get
579"
REFERENCES,0.43148148148148147,"Zser
tl \Zser
tl−1 = {(at, rt)}tl
t=tl−1+1, and so applying Lemma A.1 and Lemma A.3, we get
580"
REFERENCES,0.43209876543209874,"N −1 ≤2 L
X l=1 tl
X"
REFERENCES,0.4327160493827161,"t=tl−1+1
D2
λ,F(at; Zser
tl−1)"
REFERENCES,0.43333333333333335,"≤2(1 + Mα) L
X l=1 tl
X"
REFERENCES,0.4339506172839506,"t=tl−1+1
D2
λ,F(at; Zall
t−1)"
REFERENCES,0.4345679012345679,"≤2(1 + Mα) T
X"
REFERENCES,0.4351851851851852,"t=1
D2
λ,F(at; Zall
t−1)"
REFERENCES,0.43580246913580245,"≤C(1 + Mα) dimE(F, λ/T) log(T/λ) log T,"
REFERENCES,0.4364197530864197,"which gives the order of total number of epochs:
581"
REFERENCES,0.43703703703703706,"N = O

(1 + Mα) dimE(F, λ/T) log2(T/ min{1, λ})

.
(16)"
REFERENCES,0.43765432098765433,"Notice that the participant reordering trick is only used to bound the number of epochs, which itself
582"
REFERENCES,0.4382716049382716,"does not depend on the specific order of participation. This is crucial since it suggests this reordering
583"
REFERENCES,0.4388888888888889,"does not change anything essential, and is in fact not necessary for the proof - it just made the proof
584"
REFERENCES,0.43950617283950616,"easier to read. Therefore we can still reorder participants as we see fit in other parts of our proof.
585"
REFERENCES,0.44012345679012344,"A.3
Proof of Regret Upper Bound
586"
REFERENCES,0.44074074074074077,"Now we are ready to prove the first part of Theorem 4.3 concerning the regret upper bound. We
587"
REFERENCES,0.44135802469135804,"begin by applying the participation reordering trick to assume, without loss of generality, that the
588"
REFERENCES,0.4419753086419753,"same agent is active within the rounds [tl, tl+1 −1], i.e. mtl = mtl+1 = · · · = mtl+1−1. Under this
589"
REFERENCES,0.4425925925925926,"assumption, we have t1 = 1.
590"
REFERENCES,0.44320987654320987,"Let a∗
t := argmaxa∈Dt f∗(a) be the best arm at time t. Then by Lemma A.2, f∗(a∗
t ) ≤
  bfmt,t +
591"
REFERENCES,0.44382716049382714,"bmt,t

(a∗
t ) ≤
  bfmt,t + bmt,t

(at), where the second inequality is due to the choice of at at round t.
592"
REFERENCES,0.4444444444444444,"Hence we get
593"
REFERENCES,0.44506172839506175,"Reg(T) = T
X t=1"
REFERENCES,0.445679012345679,"
f∗(a∗
t ) −f∗(at)
"
REFERENCES,0.4462962962962963,"≤min

T
X t=1"
REFERENCES,0.4469135802469136,"  bfmt,t + bmt,t −f ∗
(at), 4
 ≤ T
X"
REFERENCES,0.44753086419753085,"t=1
min{2bmt,t(at), 4} = 2 L
X l=1"
REFERENCES,0.44814814814814813,"tl+1−1
X"
REFERENCES,0.4487654320987654,"t=tl+1
btl(at) + 2 L
X"
REFERENCES,0.44938271604938274,"l=1
min{bmtl,tl(atl), 2},
(17)"
REFERENCES,0.45,"where the first inequality is due to |f| ≤1 from Assumption 3.1, and the second inequality again
594"
REFERENCES,0.4506172839506173,"uses Lemma A.2. We first bound the second term here using the epoch scheme in Section A.2. We
595"
REFERENCES,0.45123456790123456,"start by converting the bonus term to uncertainty:
596"
REFERENCES,0.45185185185185184,"bmtl,tl(atl) = btl−1(atl) ≤CB
q"
REFERENCES,0.4524691358024691,"β2
tl−1 + λ · Dλ,F(atl; Zser
tl−1).
(18)"
REFERENCES,0.45308641975308644,"Now consider the episodes in an epoch i, specifically {tli−1, tli−1+1, · · · , tli}. For any li−1 < l < li,
597"
REFERENCES,0.4537037037037037,"since Zser
tli−1 ⊆Zser
tl−1, we can deduce that
598"
REFERENCES,0.454320987654321,"D2
λ,F(ztl; Zser
tl−1) ≤D2
λ,F(ztl; Zser
tli−1) ≤2D2
λ,F(ztl; Zser
tl ),"
REFERENCES,0.45493827160493827,"where the second inequality is borrowed from (15) from Section A.2. Therefore continuing from
599"
REFERENCES,0.45555555555555555,"(18),
600 L
X"
REFERENCES,0.4561728395061728,"l=1
min{bmtl,tl(ztl), 2} ≤
X"
REFERENCES,0.4567901234567901,"l̸∈{li}N
i=1 √"
"CB
Q",0.45740740740740743,"2CB
q"
"CB
Q",0.4580246913580247,"β2
tl−1 + λ · Dλ,F(ztl; Zser
tl )

+ N
X i=1
2 ≤
√"
CB,0.458641975308642,"2CB L
X"
CB,0.45925925925925926,"l=1
Dλ,F(ztl; Zser
tl )
q"
CB,0.45987654320987653,"β2
h + λ + 2N.
(19)"
CB,0.4604938271604938,"Now combine this result with the first term in (17) and use again (18), we get
601"
CB,0.46111111111111114,"Reg(T) ≤2CB L
X l=1"
CB,0.4617283950617284,"tl+1−1
X"
CB,0.4623456790123457,"t=tl+1
Dλ,F(at; Zser
tl )
q"
CB,0.46296296296296297,"β2
tl + λ + 2
√"
CB,0.46358024691358024,"2CB L
X"
CB,0.4641975308641975,"l=1
Dλ,F(ztl; Zser
tl )
q"
CB,0.4648148148148148,"β2
h + λ + 4N ≤2
√"
CB,0.4654320987654321,"2CB L
X l=1"
CB,0.4660493827160494,"tl+1−1
X"
CB,0.4666666666666667,"t=tl
Dλ,F(at; Zser
tl )
q"
CB,0.46728395061728395,"β2
tl + λ + 4N ≤2
√"
CB,0.4679012345679012,"2CB 
L
X l=1"
CB,0.4685185185185185,"tl+1−1
X"
CB,0.4691358024691358,"t=tl
D2
λ,F(at; Zser
tl )
1/2
T
X t=1"
CB,0.4697530864197531," eβ2
1 + λ
1/2
+ 4N"
CB,0.4703703703703704,"where
eβ1 = Cβ √"
CB,0.47098765432098766,"λ + RC(M, α)
p"
CB,0.47160493827160493,"log(3N()M/δ)

."
CB,0.4722222222222222,"According to Lemma A.1 and Lemma A.3, the term
602 L
X l=1"
CB,0.4728395061728395,"tl+1−1
X"
CB,0.4734567901234568,"t=tl
D2
λ,F(at; Zser
tl ) ≤(1 + Mα) L
X l=1"
CB,0.4740740740740741,"tl+1−1
X"
CB,0.47469135802469137,"t=tl
D2
λ,F(at; Zall
t−1)"
CB,0.47530864197530864,"= (1 + Mα) T
X"
CB,0.4759259259259259,"t=1
D2
λ,F(at; Zall
t−1)"
CB,0.4765432098765432,"≤C(1 + Mα) dimE(F, λ/T) log2  
T/ min{1, λ}

."
CB,0.47716049382716047,"combining this with (16), we get
603"
CB,0.4777777777777778,"Reg(T) ≤C

(1 + Mα) dimE(F, λ/T) log2  
T/ min{1, λ}
1/2

T
X"
CB,0.4783950617283951,"t=1
(β2
t + λ)
1/2
+ 4N"
CB,0.47901234567901235,"= O
√"
CB,0.47962962962962963,"T eβ1
p"
CB,0.4802469135802469,"(1 + Mα) dimE(F, λ/T) log(T/ min{1, λ})"
CB,0.4808641975308642,"+ (1 + Mα) dimE(F, λ/T) log2(T/ min{1, λ})

."
CB,0.48148148148148145,"A.4
Proof of Communication Cost
604"
CB,0.4820987654320988,"In this section we prove the second part of Theorem 4.3, by calculating the communication com-
605"
CB,0.48271604938271606,"plexity. First, for each communication round tl, assume the last time before tl when the agent mtl
606"
CB,0.48333333333333334,"communicated with the server was tl′, then
607 X"
CB,0.4839506172839506,"(a,r)∈Zloc
m,tl"
CB,0.4845679012345679,"D2
λ,F(a; Zup
m,tl) ≥
X"
CB,0.48518518518518516,"(a,r)∈Zloc
m,tl"
CB,0.4858024691358025,"
btl′(a)/C
2"
CB,0.48641975308641977,"β2
tl′ + λ
≥α C2 ,"
CB,0.48703703703703705,"Now employing the epoch segmentation scheme from section A.2, for the i-th epoch consisting of
608"
CB,0.4876543209876543,"the time steps [tli−1, tli), we have the inequality
609 1 ≥"
CB,0.4882716049382716,"li−1
X"
CB,0.4888888888888889,l=li−1+1 X
CB,0.48950617283950615,"(a,r)∈Zloc
m,tl"
CB,0.4901234567901235,"D2
λ,F(a; Zser
tli−1) ≥"
CB,0.49074074074074076,"li−1
X"
CB,0.49135802469135803,l=li−1+1 X
CB,0.4919753086419753,"(a,r)∈Zloc
m,tl"
CB,0.4925925925925926,"D2
λ,F
 
a; Zup
m,tl ∪Zser
tli−1

."
CB,0.49320987654320986,"For m ∈[M], assume the agent m communicated with the server a total of nm times within [tli−1, tli).
Then except for the first of these communication rounds, for each l ∈[li−1 +1, li −1] with mtl = m,
there exists l′ ∈[li−1, l) with mtl′ = m, thus we have Zup
m,tl ⊃Zup
m,tl′+1 = Zser
tl′ ⊃Zser
tli−1 . With this
we have the corresponding term
X"
CB,0.49382716049382713,"(a,r)∈Zloc
m,tl"
CB,0.49444444444444446,"D2
λ,F(a; Zup
m,tl ∪Zser
tli−1) =
X"
CB,0.49506172839506174,"(a,r)∈Zloc
m,tl"
CB,0.495679012345679,"D2
λ,F(a; Zup
m,tl) ≥α"
CB,0.4962962962962963,"C2
B
,"
CB,0.49691358024691357,"therefore
610 1 ≥ M
X"
CB,0.49753086419753084,"m=1
(nm −1) ·
α
4C2 ⇒ M
X"
CB,0.4981481481481482,"m=1
nm ≤M + C2
B
α"
CB,0.49876543209876545,"Notice that PM
m=1 nm = li −li−1 is the number of communication rounds within [tli−1, tli), hence
summing over i the total number of communication rounds is upper bounded by N(M + C2
B/α).
Combine this with (16), we have the total number of communication rounds throughout the algorithm
is"
CB,0.4993827160493827,"O
(1 + Mα)2"
CB,0.5,"α
dimE(F, λ/T) log2  
T/ min{1, λ}

."
CB,0.5006172839506173,"B
The MDPs Case: Proof of Theorem 5.1
611"
CB,0.5012345679012346,"Similar to the bandit case, we define Zloc
m,k,h, Zup
m,k,h, Zser
k,h, and Zall
k,h to be the local, uploaded, server
612"
CB,0.5018518518518519,"and universal data, with corresponding subscripts of agent m ∈[M], episode k ∈[K], h ∈[H].
613"
CB,0.5024691358024691,"Suppose at rounds 0 = k0 < k1 < · · · < kL < kL+1 = T + 1, the participating agent communicates
614"
CB,0.5030864197530864,"with the server, where k0 and kL+1 are dummy rounds.
615"
CB,0.5037037037037037,"For a dataset Zh in the MDPs setting, we again define the Zh-norm on function set Fh as ∥f∥2
Z :=
P"
CB,0.504320987654321,"oh∈Z f 2(zh) for any f ∈F. As a reminder, the tuples oh = (sh, ah, rh, sh+1) and zh = (sh, ah).
Then we have the shortened notation"
CB,0.5049382716049383,"Dλ,Fh(zh; Zh) =
sup
f1,f2∈Fh"
CB,0.5055555555555555,"|f1(zh) −f2(zh)|
q"
CB,0.5061728395061729,"λ + ∥f1 −f2∥2
Zh
."
CB,0.5067901234567901,"Finally, we define the confidence set of functions at round k + 1 and step h as:
616"
CB,0.5074074074074074,"Fk+1,h =

f ∈Fh :
X"
CB,0.5080246913580246,"oh∈Zser
k,h"
CB,0.508641975308642," 
f(zh) −bfk+1,h(zh)
2 ≤(βk,h)2

.
(20)"
CB,0.5092592592592593,"B.1
Auxiliary Lemmas
617"
CB,0.5098765432098765,"In this section we present some auxiliary lemmas that will be used in the proof of Theorem 5.1. These
618"
CB,0.5104938271604939,"lemmas are generalizations / restatements to the lemmas presented in 6, and their detailed proofs can
619"
CB,0.5111111111111111,"be found in Section C.
620"
CB,0.5117283950617284,"Lemma B.1 (Restatement of Lemma 6.3). For any k ∈[K], m ∈[M], h ∈[H] and f1, f2 ∈F, as
long as agent m does not communicate with the server at episode k, we have λ +
X"
CB,0.5123456790123457,"m′∈[M]
∥f1 −f2∥2
Zup
m′,k,h ≥1"
CB,0.512962962962963,"α∥f1 −f2∥2
Zloc
m,k,h."
CB,0.5135802469135803,"Furthermore, we have for any k ∈[K] and f1, f2 ∈F,"
CB,0.5141975308641975,"λ + ∥f1 −f2∥2
Zser
k,h ≥
1
1 + Mα
 
λ + ∥f1 −f2∥2
Zall
k,h

,"
CB,0.5148148148148148,"and as a corollary, for any z = (s, a) ∈S × A,"
CB,0.5154320987654321,"D2
λ,F(z; Zser
k,h) ≤(1 + Mα)D2
λ,F(z; Zall
k,h)"
CB,0.5160493827160494,"Similar to Lemma A.1, this lemma provides a worst case ratio between uncertainty measured on the
621"
CB,0.5166666666666667,"server dataset and universal dataset. The proof can be found in Section C.1.
622"
CB,0.5172839506172839,"Lemma B.2 (Restatement of Lemma 6.1). By taking γ = 1/(CγKH) with Cγ ≥20, as well as
623"
CB,0.5179012345679013,"βk,h = eβ2 := Cβ,2 √"
CB,0.5185185185185185,"λ + HC(M, α)
p"
CB,0.5191358024691358,"log(3HMNh(γ)/δ)

,"
CB,0.519753086419753,"with Cβ,2 = 12 for all k ∈[K] and h ∈[H], where Nh(γ) = N(Fh, γ)·N(Fh+1, γ)·N(Wh+1, γ),
624"
CB,0.5203703703703704,"we have with probability at least 1−δ that ThQk+1,h+1 ∈Fk+1,h for all k ∈{kl}L
l=1 with probability
625"
CB,0.5209876543209877,"at least 1 −δ. As a corollary, we also have |ThQk+1,h+1(s, a) −bfk+1,h(s, a)| ≤bk+1,h(s, a) for
626"
CB,0.5216049382716049,"any (s, a) ∈S × A, k ∈{kl}L
l=1 and h ∈[H].
627"
CB,0.5222222222222223,"This is the central optimism lemma. It states that the Bellman operator of Q-value function at level
628"
CB,0.5228395061728395,"h + 1 is within the confidences set at level h. The conclusion immediately gives the optimism
629"
CB,0.5234567901234568,"inequality ThQk+1,h+1(s, a) ≤Qk+1,h(s, a), which we will use at the start of the regret upper
630"
CB,0.524074074074074,"bound prove. The proof of the lemma can be found in Section C.2.
631"
CB,0.5246913580246914,"With this, we define the good event ET = {ThQk+1,h+1 ∈Fk+1,h, ∀k ∈{kl}L
l=1, h ∈[H]}. Then
632"
CB,0.5253086419753087,"according to Lemma B.2, P(ET ) ≥1 −δ.
633"
CB,0.5259259259259259,"Lemma B.3. For some absolute constant CD, the following holds for all level h ∈[H]: K
X"
CB,0.5265432098765432,"k=1
D2
λ,F(zk
h; Zall
k−1,h) ≤CD dimE(F, λ/T) log2(T/ min{1, λ})"
CB,0.5271604938271605,"This lemma is essentially the same as Lemma A.3. It reveals the relationship between the sum of
634"
CB,0.5277777777777778,"Eluder-like confidence quantities and the Eluder dimension. The proof can be found in Section C.3.
635"
CB,0.528395061728395,"B.2
The Epoch Segmentation Scheme
636"
CB,0.5290123456790123,"In this section, we introduce the epoch segmentation scheme for MDPs, which is again needed for
637"
CB,0.5296296296296297,"both the regret and communication cost proofs presented in the next two sections. All of this is
638"
CB,0.5302469135802469,"quite similar to the bandit case in Section A.2, but the introduction of multiple levels h ∈[H] does
639"
CB,0.5308641975308642,"complicate things a bit.
640"
CB,0.5314814814814814,"We segment the entire run of episodes k = 1, · · · , K into N epochs as follows. Define iteratively
0 = l0 < l1 < · · · < lN ≤L as"
CB,0.5320987654320988,"li = min

l > li−1 : l
X"
CB,0.532716049382716,"l′=li−1+1 H
X h=1 X"
CB,0.5333333333333333,"oh∈Zloc
m,kl′ ,h"
CB,0.5339506172839507,"D2
λ,Fh(zh; Zser
kli−1,h) ≥1

,"
CB,0.5345679012345679,"where for a given l′ in the summation, m = mkl′ is the participating agent at kl′. In the iterative
641"
CB,0.5351851851851852,"process, if the above minimum does not exist, simply define N = i −1 and end the process there.
642"
CB,0.5358024691358024,"Correspondingly, the i-th epoch is defined by the episodes [kli−1, kli).
643"
CB,0.5364197530864198,"The following sections will make use of this epoch scheme as befit their needs, but here we shall give
644"
CB,0.5370370370370371,"an upper bound for the total number of epochs N. Based on the definition of li, we have for any
645"
CB,0.5376543209876543,"li−1 ≤l < li that
646 1 ≥ l
X"
CB,0.5382716049382716,"l′=li−1+1 H
X h=1 X"
CB,0.5388888888888889,"oh∈Zloc
m,kl′ ,h"
CB,0.5395061728395062,"D2
λ,F(zh; Zser
kli−1,h) = l
X"
CB,0.5401234567901234,"l′=li−1+1 H
X h=1 X"
CB,0.5407407407407407,"oh∈Zser
kl′ ,h\Zser
kl′−1,h
sup
f1,f2∈F"
CB,0.5413580246913581,[f1(zh) −f2(zh)]2
CB,0.5419753086419753,"λ + ∥f1 −f2∥2
Zser
kli−1 ,h ≥ H
X"
CB,0.5425925925925926,"h=1
sup
f1,f2∈Fh P"
CB,0.5432098765432098,"oh∈Zser
kl,h\Zser
kli−1 ,h[f1(zh) −f2(zh)]2"
CB,0.5438271604938272,"λ + ∥f1 −f2∥2
Zser
kli−1 ,h = H
X h=1"
CB,0.5444444444444444,"
sup
f1,f2∈Fh"
CB,0.5450617283950617,"λ + ∥f1 −f2∥2
Zser
kl,h
λ + ∥f1 −f2∥2
Zser
kli−1 ,h
−1

,"
CB,0.5456790123456791,"which gives λ + ∥f1 −f2∥2
Zser
kl,h ≤2
 
λ + ∥f1 −f2∥2
Zser
kli−1 ,h

for any h ∈[H] and f1, f2 ∈Fh. Then
647"
CB,0.5462962962962963,"we have
648"
CB,0.5469135802469136,"D2
λ,F(zh; Zser
kli−1,h) ≤2D2
λ,F(zh; Zser
kl,h)
(21)"
CB,0.5475308641975308,"for any h ∈[H] and zh ∈S × A, and so
649 1 ≤ li
X"
CB,0.5481481481481482,"l=li−1+1 H
X h=1 X"
CB,0.5487654320987654,"oh∈Zloc
m,kl,h"
CB,0.5493827160493827,"D2
λ,Fh(zh; Zser
kli−1,h) ≤2 li
X"
CB,0.55,"l=li−1+1 H
X h=1 X"
CB,0.5506172839506173,"oh∈Zser
kl,h\Zser
kl−1,h
D2
λ,Fh(zh; Zser
kl−1,h),"
CB,0.5512345679012346,"and summing over i = 1, · · · , N −1 that:
650"
CB,0.5518518518518518,"N −1 ≤2 H
X h=1 L
X l=1 X"
CB,0.5524691358024691,"oh∈Zser
kl,h\Zser
kl−1,h
D2
λ,Fh(zh; Zser
kl−1,h)."
CB,0.5530864197530864,"If we apply the participant reordering trick and let mk = mkl for all k ∈(kl−1, kl] and l ∈[L], we
651"
CB,0.5537037037037037,"get Zser
kl,h\Zser
kl−1,h = {ok
h}kl
k=kl−1+1, and so applying Lemma 6.3 and Lemma 6.2, we get
652"
CB,0.554320987654321,"N −1 ≤2 H
X h=1 L
X l=1 kl
X"
CB,0.5549382716049382,"k=kl−1+1
D2
λ,Fh(zk
h; Zser
kl−1,h)"
CB,0.5555555555555556,"≤2(1 + Mα) H
X h=1 L
X l=1 kl
X"
CB,0.5561728395061728,"k=kl−1+1
D2
λ,Fh(zk
h; Zall
k−1,h)"
CB,0.5567901234567901,"≤2(1 + Mα) H
X h=1 K
X"
CB,0.5574074074074075,"k=1
D2
λ,Fh(zk
h; Zall
k−1,h)"
CB,0.5580246913580247,"≤CH(1 + Mα) dimE(F, λ/T) log(T/λ) log T,"
CB,0.558641975308642,"which gives the order of total number of epochs:
653"
CB,0.5592592592592592,"N = O

H(1 + Mα) dimE(F, λ/T) log2(T/ min{1, λ})

.
(22)"
CB,0.5598765432098766,"B.3
Proof of Regret Upper Bound
654"
CB,0.5604938271604938,"In this section, we prove the first half of Theorem 5.1, which gives an upper bound for the cumulative
655"
CB,0.5611111111111111,"regret of Algorithm 2.
656"
CB,0.5617283950617284,"Using the participant reordering trick, assume without loss of generality that the same agent is active
657"
CB,0.5623456790123457,"within the rounds [kl, kl+1 −1], i.e. mkl = mkl+1 = · · · = mkl+1−1. Under this assumption, we
658"
CB,0.562962962962963,"have k1 = 1.
659"
CB,0.5635802469135802,"We first prove via induction that Q∗
h ≤Qm,k,h for any m ∈[M], k ∈[K] and h ∈[H+1]. This holds
true for h = H + 1 trivially since both value functions at H + 1 are uniformly 0. Suppose we already
have Q∗
h+1 ≤Qm,k,h+1, we have from Lemma B.2 that for the last communication round k′ for agent
m, the server functions satisfy ThQk′+1,h+1(s, a) ≤bfk′+1,h(s, a) + bk′+1,h(s, a) = Qk′+1,h(s, a).
Couple this with the fact that Qm,k,h = Qk′+1,h, we can prove that"
CB,0.5641975308641975,"Q∗
h = ThQ∗
h+1 ≤ThQm,k,h+1 ≤Qm,k,h,"
CB,0.5648148148148148,"which finishes the induction process.
660"
CB,0.5654320987654321,"Now let ak∗
h := argmaxa∈A Q∗
h(sk
h, a) be the best action at time t, then V ∗
h (sk
h) = Q∗
h(sk
h, ak∗
h ) ≤
661"
CB,0.5660493827160494,"Qm,k,h(sk
h, ak∗
h ) ≤Qm,k,h(sk
h, ak
h), where the second inequality is due to the choice of ak
h at round
662"
CB,0.5666666666666667,"k. Hence we get
663"
CB,0.567283950617284,"Reg(K) = K
X k=1"
CB,0.5679012345679012,"
V ∗
1 (sk
1) −V πk
1 (sk
1)
 ≤ K
X"
CB,0.5685185185185185,"k=1
min

Vm,k,1(sk
1) −V πk
1 (sk
1), 2H = K
X k=1 H
X"
CB,0.5691358024691358,"h=1
min

Eπk

Qm,k,h(sk
h, ak
h) −ThQm,k,h+1(sk
h, ak
h)

, 2 = K
X k=1 H
X"
CB,0.5697530864197531,"h=1
min

Eπk
 bfk′+1,h(sk
h, ak
h) + bk′+1,h(sk
h, ak
h) −ThQm,k,h+1(sk
h, ak
h)

, 2 ≤ K
X k=1 H
X"
CB,0.5703703703703704,"h=1
min

2bk′,h(sk
h, ak
h), 2 = 2 L
X l=1"
CB,0.5709876543209876,"kl+1−1
X"
CB,0.571604938271605,"k=kl+1 H
X"
CB,0.5722222222222222,"h=1
bkl+1,h(zk
h) + 2 L
X l=1 H
X"
CB,0.5728395061728395,"h=1
min{bmkl,kl,h(zkl
h ), 1}.
(23)"
CB,0.5734567901234567,"where the second equality uses the Value-decomposition Lemma from Jiang et al. [2017], the second
664"
CB,0.5740740740740741,"inequality uses again Lemma B.2, and from the third inequality onward we let k′ be the last time
665"
CB,0.5746913580246914,"agent m communicated with the server.
666"
CB,0.5753086419753086,"We now bound the second term here using the epoch scheme in Section B.2. We start by converting
667"
CB,0.575925925925926,"the bonus term to uncertainty:
668"
CB,0.5765432098765432,"bmkl,kl,h(zkl
h ) = bkl−1,h(zkl
h ) ≤CB
q"
CB,0.5771604938271605,"β2
kl−1,h + λ · Dλ,Fh(zkl
h ; Zser
kl−1,h).
(24)"
CB,0.5777777777777777,"Now consider the episodes in an epoch i, specifically {kli−1, kli−1+1, · · · , kli}. For any li−1 < l < li,
669"
CB,0.578395061728395,"since Zser
kli−1,h ⊆Zser
kl−1,h, we can deduce that
670"
CB,0.5790123456790124,"D2
λ,Fh(zkl
h ; Zser
kl−1,h) ≤D2
λ,Fh(zkl
h ; Zser
kli−1,h) ≤2D2
λ,Fh(zkl
h ; Zser
kl,h),"
CB,0.5796296296296296,"where the second inequality is borrowed from (21) from Section B.2. Therefore continuing from
671"
CB,0.5802469135802469,"(24),
672 L
X l=1 H
X"
CB,0.5808641975308642,"h=1
min{bmkl,kl,h(zkl
h ), 1} ≤
X"
CB,0.5814814814814815,"l̸∈{li}N
i=1 H
X h=1 √"
"CB
Q",0.5820987654320988,"2CB
q"
"CB
Q",0.582716049382716,"β2
kl−1,h + λ · Dλ,Fh(zkl
h ; Zser
kl,h)

+ N
X i=1 H
X h=1
1 ≤
√"
CB,0.5833333333333334,"2CB L
X l=1 H
X"
CB,0.5839506172839506,"h=1
Dλ,Fh(zkl
h ; Zser
kl,h)
q"
CB,0.5845679012345679,"β2
h + λ + NH.
(25)"
CB,0.5851851851851851,"Now combine this result with the first term in (23) and use again (24), we get
673"
CB,0.5858024691358025,"Reg(K) ≤CB L
X l=1"
CB,0.5864197530864198,"kl+1−1
X"
CB,0.587037037037037,"k=kl+1 H
X h=1"
CB,0.5876543209876544,"
Dλ,Fh(zk
h; Zser
kl,h)
q"
CB,0.5882716049382716,"β2
h + λ

+
√"
CB,0.5888888888888889,"2CB L
X l=1 H
X h=1"
CB,0.5895061728395061,"
Dλ,Fh(zkl
h ; Zser
kl,h)
q"
CB,0.5901234567901235,"β2
h + λ

+ NH ≤
√"
CB,0.5907407407407408,"2CB L
X l=1"
CB,0.591358024691358,"kl+1−1
X k=kl H
X h=1"
CB,0.5919753086419753,"
Dλ,Fh(zk
h; Zser
kl,h)
q"
CB,0.5925925925925926,"β2
h + λ

+ NH ≤
√"
CB,0.5932098765432099,"2CB 
L
X l=1"
CB,0.5938271604938271,"kl+1−1
X k=kl H
X"
CB,0.5944444444444444,"h=1
D2
λ,Fh(zk
h; Zser
kl,h)
1/2 K
X k=1 H
X h=1"
CB,0.5950617283950618," 
β2
h + λ
1/2
+ NH."
CB,0.595679012345679,"According to Lemma 6.3 and Lemma 6.2, the term
674 L
X l=1"
CB,0.5962962962962963,"kl+1−1
X k=kl H
X"
CB,0.5969135802469135,"h=1
D2
λ,Fh(zk
h; Zser
kl,h) ≤(1 + Mα) L
X l=1"
CB,0.5975308641975309,"kl+1−1
X k=kl H
X"
CB,0.5981481481481481,"h=1
D2
λ,Fh(zk
h; Zall
k−1,h)"
CB,0.5987654320987654,"≤(1 + Mα) K
X k=1 H
X"
CB,0.5993827160493828,"h=1
D2
λ,Fh(zk
h; Zall
k−1,h)"
CB,0.6,"≤H(1 + Mα) dimE(F, λ/T) log(T/λ) log T."
CB,0.6006172839506173,"Now with γ = O(1/KH), we have
675"
CB,0.6012345679012345,βh = O(1)βh+1 + Cβ √
CB,0.6018518518518519,"λ + H
p"
CB,0.6024691358024692,"(1 + Mα) log(3HNh(γ)/δ) + M
p"
CB,0.6030864197530864,"α log(3HMNh(γ)/δ)
"
CB,0.6037037037037037,"therefore, with C(M, α) =
√"
CB,0.604320987654321,"1 + Mα + M√α and the upper bound for number of epochs N in
676"
CB,0.6049382716049383,"(22), we have
677 L
X l=1"
CB,0.6055555555555555,"kl+1−1
X"
CB,0.6061728395061728,"k=kl+1 H
X"
CB,0.6067901234567902,"h=1
bkl,h(zk
h)"
CB,0.6074074074074074,"≤O

H(1 + Mα) dimE(F, λ/K) log2(K/ min{1, λ})
1/2

K H
X"
CB,0.6080246913580247,"h=1
(β2
h + λ)
1/2
+ HN
"
CB,0.608641975308642,"= O

H
√"
CB,0.6092592592592593,"K eβ2
p"
CB,0.6098765432098765,"(1 + Mα) dimE(F, λ/K) log(K/ min{1, λ})"
CB,0.6104938271604938,"+ H2(1 + Mα) dimE(F, λ/K) log2(K/ min{1, λ})

,"
CB,0.6111111111111112,"where eβ2 = Cβ,2 √"
CB,0.6117283950617284,"λ + HC(M, α) log
 
HMN(F, γ)N(W, γ)/δ

is the choice of βk,h in the
678"
CB,0.6123456790123457,"algorithm.
679"
CB,0.6129629629629629,"B.4
Proof of Communication Cost
680"
CB,0.6135802469135803,"Next up, we calculate the communication complexity of Algorithm 2 and prove the second half of
681"
CB,0.6141975308641975,"Theorem 5.1. For each communication round kl, assume the last time before kl when the agent
682"
CB,0.6148148148148148,"m = mkl communicated with the server was kl′, then by the communication rule there exists
683"
CB,0.6154320987654321,hl ∈[H] such that P
CB,0.6160493827160494,"ohl∈Zloc
m,kl,hl b2
kl′,hl(zhl)/(β2
kl′,hl + λ) ≥α,
684 X"
CB,0.6166666666666667,"ohl∈Zloc
m,kl,hl"
CB,0.6172839506172839,"D2
λ,Fhl (zhl; Zup
m,kl,hl) ≥
X"
CB,0.6179012345679012,"ohl∈Zloc
m,kl,hl"
CB,0.6185185185185185,"
bkl′,hl(zhl)/C
2"
CB,0.6191358024691358,"β2
kl′,hl + λ
≥α C2 ,"
CB,0.6197530864197531,"Next we will make use of the epoch segmentation scheme in Section B.2. For the i-th epoch consisting
685"
CB,0.6203703703703703,"of the time steps [kli−1, kli), we have the inequality
686 1 ≥"
CB,0.6209876543209877,"li−1
X"
CB,0.6216049382716049,"l=li−1+1 H
X h=1 X"
CB,0.6222222222222222,"oh∈Zloc
m,kl,h"
CB,0.6228395061728395,"D2
λ,Fh(zh; Zser
kli−1,h) ≥"
CB,0.6234567901234568,"li−1
X"
CB,0.6240740740740741,"l=li−1+1 H
X h=1 X"
CB,0.6246913580246913,"oh∈Zloc
m,kl,h"
CB,0.6253086419753087,"D2
λ,Fh
 
zh; Zup
m,kl,h ∪Zser
kli−1,h

."
CB,0.6259259259259259,"For m ∈[M], assume the agent m communicated with the server a total of nm times within
[kli−1, kli). Then except for the first of these communication rounds, for each l ∈[li−1 + 1, li −1]
with mkl = m, there exists l′ ∈[li−1, l) with mkl′ = m, thus we have Zup
m,kl,h ⊃Zup
m,kl′+1,h =
Zser
kl′,h ⊃Zser
kli−1,h for all h ∈[H]. With this we have H
X h=1 X"
CB,0.6265432098765432,"oh∈Zloc
m,kl,h"
CB,0.6271604938271605,"D2
λ,Fh
 
zh; Zup
m,kl,h ∪Zser
kli−1,h

= H
X h=1 X"
CB,0.6277777777777778,"oh∈Zloc
m,kl,h"
CB,0.6283950617283951,"D2
λ,Fh
 
zh; Zup
m,kl,h

≥
α
4C2 ,"
CB,0.6290123456790123,"therefore
687 1 ≥ M
X"
CB,0.6296296296296297,"m=1
(nm −1) ·
α
4C2 ⇒ M
X"
CB,0.6302469135802469,"m=1
nm ≤M + 4C2 α"
CB,0.6308641975308642,"Notice that PM
m=1 nm = li −li−1 is the number of communication rounds within [kli−1, kli), hence
summing over i the total number of communication rounds is upper bounded by N(M + 4C2/α).
Combine this with the result in (22), we have the total number of communication rounds throughout
the algorithm is"
CB,0.6314814814814815,"O

H (1 + Mα)2"
CB,0.6320987654320988,"α
dimE(F, λ/K) log2(K/ min{1, λ})

."
CB,0.6327160493827161,"C
Proof of Auxiliary Lemmas
688"
CB,0.6333333333333333,"In this section we prove all the auxiliary lemmas in Section A.1 and Section B.1. Note that some of
689"
CB,0.6339506172839506,"these lemmas are very similar in nature, for which we will only give the proof for the version for the
690"
CB,0.6345679012345679,"MDPs case, and briefly remark on the version for the bandit case.
691"
CB,0.6351851851851852,"C.1
Proof of Lemma A.1 and Lemma B.1
692"
CB,0.6358024691358025,"Here we prove Lemma B.1 in detail. The proof for Lemma A.1 is very similar, and so we will only
693"
CB,0.6364197530864197,"give a short remark on how to apply this to the bandit case.
694"
CB,0.6370370370370371,"Proof of Lemma B.1. First, for an episode k ∈[K] and agent m ∈[M] such that m does not
695"
CB,0.6376543209876543,"communicate with the server at episode k (either m is not participating or k is not a communication
696"
CB,0.6382716049382716,"round), from the communication criterion we have
697 α ≥
X"
CB,0.6388888888888888,"oh∈Zloc
m,k,h"
CB,0.6395061728395062,"b2
m,k,h(a)
β2
k′,h + λ ≥
X"
CB,0.6401234567901235,"oh∈Zloc
m,k,h"
CB,0.6407407407407407,"D2
λ,Fh(zh; Zser
k′,h) =
X"
CB,0.641358024691358,"oh∈Zloc
m,k,h"
CB,0.6419753086419753,"sup
f1,f2∈Fh"
CB,0.6425925925925926,|f1(zh) −f2(zh)|2
CB,0.6432098765432098,"λ + ∥f1 −f2∥Zser
k′,h"
CB,0.6438271604938272,"≥
sup
f1,f2∈Fh"
CB,0.6444444444444445,"∥f1 −f2∥2
Zloc
m,k,h
λ + ∥f1 −f2∥2
Zser
k′,h
,"
CB,0.6450617283950617,"where k′ is the last communication round for agent m. This means that for any f1, f2 ∈Fh,
(1/α)∥f1 −f2∥2
Zloc
m,k,h ≤λ+∥f1 −f2∥2
Zser
k′,h. Observing that Zser
k′,h ⊂Zser
k,h = SM
m′=1 Zup
m′,k,h proves
the first conclusion that"
CB,0.645679012345679,"1
α∥f1 −f2∥2
Zloc
m,k,h ≤λ + M
X"
CB,0.6462962962962963,"m′=1
∥f1 −f2∥2
Zup
m′,k,h."
CB,0.6469135802469136,"Second, for any f1, f2 ∈Fh, from the above conclusion we have for any k ∈[K]\{kl}L
l=1 that
698"
CB,0.6475308641975308,"λ + ∥f1 −f2∥2
Zser
k,h = λ + M
X"
CB,0.6481481481481481,"m=1
∥f1 −f2∥2
Zup
m,k,h"
CB,0.6487654320987655,"≥
1
Mα M
X"
CB,0.6493827160493827,"m=1
∥f1 −f2∥2
Zloc
m,k,h"
CB,0.65,"=
1
Mα∥f1 −f2∥2
Zall
k,h\Zser
k,h,"
CB,0.6506172839506172,"and when k = kl for some l ∈[L], we have alternatively
699"
CB,0.6512345679012346,"λ + ∥f1 −f2∥2
Zser
k,h = λ +
X"
CB,0.6518518518518519,"m′̸=mt
∥f1 −f2∥2
Zup
m′,k,h + ∥f1 −f2∥2
Zup
mk,k,h∪Zloc
mk,k,h ≥λ + M
X"
CB,0.6524691358024691,"m=1
∥f1 −f2∥2
Zup
m,k,h"
CB,0.6530864197530865,"≥
1
(M −1)α X"
CB,0.6537037037037037,"m′̸=mk
∥f1 −f2∥2
Zloc
m′,k,h"
CB,0.654320987654321,"≥
1
Mα∥f1 −f2∥2
Zall
k,h\Zser
k,h."
CB,0.6549382716049382,"Either way, we can deduce for any k ∈[K] that"
CB,0.6555555555555556,"(1 + Mα)
 
λ + ∥f1 −f2∥2
Zser
k,h

≥λ + ∥f1 −f2∥2
Zall
k,h."
CB,0.6561728395061729,"Finally, from the above we immediately have
700"
CB,0.6567901234567901,"D2
λ,F(zh; Zser
k,h) =
sup
f1,f2∈Fh"
CB,0.6574074074074074,[f1(zh) −f2(zh)]2
CB,0.6580246913580247,"λ + ∥f1 −f2∥2
Zser
k,h"
CB,0.658641975308642,"≤(1 + Mα)
sup
f1,f2∈F"
CB,0.6592592592592592,[f1(zh) −f2(zh)]2
CB,0.6598765432098765,"λ + ∥f1 −f2∥2
Zall
k,h
= (1 + Mα)D2
λ,F(a; Zall
k,h). 701"
CB,0.6604938271604939,"Remark C.1. Notice that this prove does not depend on the multi-level structure of episodic MDPs,
702"
CB,0.6611111111111111,"but is a direct result of the communication criterion and protocol. This means the proof can be
703"
CB,0.6617283950617284,"converted to the bandit case of Lemma A.1 without any essential changes: simply change episode k
704"
CB,0.6623456790123456,"into time step t, disregard all mentions of level h, and consider z = a instead of z = (s, a).
705"
CB,0.662962962962963,"C.2
Proof of Lemma A.2 and Lemma B.2
706"
CB,0.6635802469135802,"We begin with the proof of Lemma A.2, which is an almost direct application of Lemma D.3.
707"
CB,0.6641975308641975,"Proof of Lemma A.2. We invoke Lemma D.3 with ϵ0 = 0, then with probability at least 1 −δ, for all
t ∈{tl}L
l=1, X"
CB,0.6648148148148149,"(a,r)∈Zser
t"
CB,0.6654320987654321,"  bft+1(a)−f ∗(a)
2 ≤CERM"
CB,0.6660493827160494,"
λ+γ2T+γTR+R2(1+Mα) log(3N/δ)+R2M 2α log(3NM/δ)

≤eβ2
1,"
CB,0.6666666666666666,"if
we
let
γ
=
O(1/T)
be
sufficiently
small
and
take
eβ1
=
Cβ,1 √"
CB,0.667283950617284,"λ +
708"
CB,0.6679012345679012,"RC(M, α) log(3MN(F, γ)/δ)

with Cβ,1 = √CERM = 6.
Thus taking βt = eβ1, accord-
709"
CB,0.6685185185185185,"ing to the definition of Ft+1, this directly implies f ∗∈Ft+1.
710"
CB,0.6691358024691358,"With this, since the bonus function satisfy"
CB,0.6697530864197531,"bt+1(a) ≥|f1(a) −f2(a)|,
∀f1, f2 ∈F
s.t.
X"
CB,0.6703703703703704,"(a,r)∈Zser
t"
CB,0.6709876543209876," 
f1(a) −f2(a)
2 ≤β2
t ,"
CB,0.671604938271605,"which is based on the first property of the bonus oracle in Definition 4.1, by taking f1 = bft+1 and
711"
CB,0.6722222222222223,"f2 = f ∗we get for any a ∈A that bt+1(a) ≥|f∗(a) −bft+1(a)|, which finishes the proof.
712"
CB,0.6728395061728395,"Next we prove Lemma B.2, which is more challenging and requires an analysis on the least squares
713"
CB,0.6734567901234568,"value iteration method.
714"
CB,0.674074074074074,"Proof of Lemma B.2. Take Fh+1,γ as a γ-cover of Fh+1, and Wh+1,γ as a γ-cover of Wh+1. Select
715"
CB,0.6746913580246914,"¯fk+1,h+1 ∈Fh+1,γ
L Wh+1,γ so that ∥Qk+1,h+1 −¯fk+1,h+1∥∞≤¯ϵ := (1 + βk+1,h+1)γ. For
716"
CB,0.6753086419753086,"oh = (sh, ah, rh, sh+1), define the corresponding yh = rh + Vk+1,h+1(sh+1) and ¯yh = rh +
717"
CB,0.6759259259259259,"supa∈A ¯fk+1,h+1(sh+1, a). Let
718"
CB,0.6765432098765433,"efk+1,h = argmin
fh∈Fh X"
CB,0.6771604938271605,"oh∈Zser
k,h"
CB,0.6777777777777778," 
fh(sh, ah) −¯yh
2."
CB,0.678395061728395,"Then we have
719 
X"
CB,0.6790123456790124,"oh∈Zser
k,h"
CB,0.6796296296296296,"  bfk+1,h(sh, ah) −¯yh
2
1/2
≤

X"
CB,0.6802469135802469,"oh∈Zser
k,h"
CB,0.6808641975308642,"  bfk+1,h(sh, ah) −yh
2
1/2
+ ¯ϵ
√ k ≤

X"
CB,0.6814814814814815,"oh∈Zser
k,h"
CB,0.6820987654320988,"  efk+1,h(sh, ah) −yh
2
1/2
+ ¯ϵ
√ k ≤

X"
CB,0.682716049382716,"oh∈Zser
k,h"
CB,0.6833333333333333,"  efk+1,h(sh, ah) −¯yh
2
1/2
+ 2¯ϵ
√ k."
CB,0.6839506172839506,"Now notice that E¯yh = Th ¯fk+1,h(sh, ah), and the difference ¯yh −Th ¯fk+1,h(sh, ah) is bounded
720"
CB,0.6845679012345679,"in [−H, H], hence we may apply Lemma D.3 with f ∗= Th ¯fk+1,h, rt = ¯yh, R = H, ϵ0 = 2¯ϵ
721"
CB,0.6851851851851852,"and δ = δ/3HN(Fh+1, γ) · N(Wh+1, γ), taking a union bound over ¯f ∈Fh+1,γ
L Wh+1,γ and
722"
CB,0.6858024691358025,"h ∈[H], we have
723 
X"
CB,0.6864197530864198,"oh∈Zser
k,h"
CB,0.687037037037037,"  bfk+1,h(sh, ah) −ThQk+1,h+1(sh, ah)
2
1/2 ≤

X"
CB,0.6876543209876543,"oh∈Zser
k,h"
CB,0.6882716049382716,"  bfk+1,h(sh, ah) −Th ¯fk+1,h+1(sh, ah)
2
1/2
+ γ
√ k ≤
p"
CB,0.6888888888888889,"CERM
p"
CB,0.6895061728395062,"λ + (γ + 2¯ϵ)2K + (γ + 2¯ϵ)KH + H2(1 + Mα) log(3HNh(γ)/δ) + H2M 2α log(3HMNh(γ)/δ) + γ
√ k ≤
p CERM √"
CB,0.6901234567901234,"λ + γ(3 + 2βk+1,h+1)
√ K +
q"
CB,0.6907407407407408,"γ(3 + 2βk+1,h+1)KH + HC(M, α)
p"
CB,0.691358024691358,"log(3HMNh(γ)/δ)

,"
CB,0.6919753086419753,"where Nh(γ) = N(Fh, γ)·N(Fh+1, γ)·N(Wh+1, γ). By taking γ = 1/(CγKH) with sufficiently
large absolute constant Cγ (for example, Cγ = 20), the second and third terms within the bracket
above are both less than (1/2)βk+1,h+1, and hence we can easily prove via induction on h that the
above is no greater than eβ2, where"
CB,0.6925925925925925,"eβ2 = Cβ,2 √"
CB,0.6932098765432099,"λ + HC(M, α)
p"
CB,0.6938271604938272,"log(3HMN(γ)/δ)
"
CB,0.6944444444444444,"with Cβ,2 = 2√CERM = 12 and N(γ) = maxh∈[H] Nh(γ).
724 725"
CB,0.6950617283950618,"C.3
Proof of Lemma A.3 and Lemma B.3
726"
CB,0.695679012345679,"In this section we prove Lemma B.3 in detail. The proof for Lemma A.3 is very similar, and so we
727"
CB,0.6962962962962963,"will again only give a short remark on how to apply this to the bandit case.
728"
CB,0.6969135802469136,"Proof of Lemma B.3. We fix the level h ∈[H] throughout the proof. For an index set K0 ⊆[K], we
729"
CB,0.6975308641975309,"denote Z(K0) := {zk
h : k ∈K0}.
730"
CB,0.6981481481481482,"First, let n = ⌈log(K/λ)/ log 2⌉, and we divide the set of episodes K = [K] into n + 1 disjoint
episode sets as follows. For any 1 ≤l ≤L and kl ≤k < kl+1, let"
CB,0.6987654320987654,"( ¯fk,1, ¯fk,2) = argmax
f1,f2∈Fh"
CB,0.6993827160493827," 
f1(zk
h) −f2(zk
h)
2"
CB,0.7,"λ + ∥f1 −f2∥2
Zall
h,k−1
,"
CB,0.7006172839506173,"and define Lk : S × A →R as Lk(z) =
  ¯fk,1(z) −¯fk,2(z)
2. Now we define Kι := {k ∈K :
731"
CB,0.7012345679012346,"Lk(zk
h) ∈(2−ι−1, 2−ι]} for ι ∈{0, 1, · · · , n −1} and Kn := {k ∈K : Lk(zk
h) ∈[0, 2−n]}. We
732"
CB,0.7018518518518518,"note that for k ∈Kn, Lk(zk
h) ≤λ/K.
733"
CB,0.7024691358024692,"Now define the mapping τ : [K] →[K], such that for any k ∈[K], τ(k) is the last episode when
734"
CB,0.7030864197530864,agent mk communicated with the server (not including k). We will bound P
CB,0.7037037037037037,"k∈Kι D2
λ,Fh(zk
h; Zall
h,k−1)
735"
CB,0.7043209876543209,"for ι ∈{0, · · · , n −1}.
736"
CB,0.7049382716049383,"For a fixed ι ≤n −1, we now decompose Kι = Snι+1
j=1 Kι
j, where nι =

|Kι|/ dimE(Fh, 2−ι−1)

.
737"
CB,0.7055555555555556,"We start off each set Kι
j = ∅, and fill them up gradually by iterating through k ∈Kι one by one
738"
CB,0.7061728395061728,"in increasing order to decide which subset Kι
j should k belong to. Specifically, we define j(k) to
739"
CB,0.7067901234567902,"be the smallest index j < nι such that is zk
h is 2−(ι+1)/2-independent of Z(Kι
j), and assign k to
740"
CB,0.7074074074074074,"the set Kι
j(k). If such a j does not exist, we simply let j(k) = nι + 1 assign k to Kι
nι+1. Finally
741"
CB,0.7080246913580247,"after the assignment process, we define Kι
j,k = Kι
j ∩[k] for any k ∈[K]. Then we have the
742"
CB,0.7086419753086419,"elements added into Kι
j(k)−1,k form a sequence where each data corresponding to a new member
743"
CB,0.7092592592592593,"is 2−(ι+1)/2-independent of the old members, and so there are no more than dimE(Fh, 2−ι−1)
744"
CB,0.7098765432098766,"members within each of them. Moreover, for all k ∈Kι that zk
h is 2−(ι+1)/2-dependent on each of
745"
CB,0.7104938271604938,"Z(Kι
1,k), · · · , Z(Kι
j(k)−1,k).
746"
CB,0.7111111111111111,"Now for any k ∈Kι by the definition of Kι, we have
  ¯fk,1(zk
h)−¯fk,2(zk
h)
2 ≥2−ι−1. This combined
with the 2−ι−1-dependencies imply that for each j′ = 1, · · · , j(k)−1, ∥¯fk,1−¯fk,2∥2
Z(Kι
j′,k) ≥2−ι−1."
CB,0.7117283950617284,"Notice that Z(Kι
j′,k) ⊂Zall
h,k−1 for any j′ ∈[j(k) −1], and that Z(Kι
j′,k) for j′ ∈[j(k) −1] are
disjoint, therefore"
CB,0.7123456790123457,(j(k) −1)2−ι−1 ≤
CB,0.7129629629629629,"j(k)−1
X"
CB,0.7135802469135802,"j′=1
∥¯fk,1 −¯fk,2∥2
Z(Kι
j′,k) ≤∥¯fk,1 −¯fk,2∥2
Zall
h,k−1."
CB,0.7141975308641976,"It follows that
747"
CB,0.7148148148148148,"D2
λ,Fh(zk
h; Zall
h,k−1) ="
CB,0.7154320987654321,"  ¯fk,1(zk
h) −¯fk,2(zk
h)
2"
CB,0.7160493827160493,"λ + ∥¯fk,1 −¯fk,2∥2
Zall
h,k−1 ≤
2−ι"
CB,0.7166666666666667,λ + (j(k) −1)2−ι−1
CB,0.717283950617284,"=
2
(j(k) −1) + 2ι+1λ,"
CB,0.7179012345679012,"where the first inequality uses the definition of Kι. Summing over k ∈Kι, we have
748 X"
CB,0.7185185185185186,"k∈Kι
D2
λ,Fh(zk
h; Zall
h,k−1) ="
CB,0.7191358024691358,"nι+1
X j=1 X"
CB,0.7197530864197531,"k∈Kι
j
D2
λ,Fh(zk
h; Zall
h,k−1) ≤ nι
X j=1"
CB,0.7203703703703703,"2
Kι
j"
CB,0.7209876543209877,"(j −1) + 2ι+1λ + 2
Kι
nι+1"
CB,0.721604938271605,nι + 2ι+1λ
CB,0.7222222222222222,"≤2 dimE(Fh, 2−ι−1)"
CB,0.7228395061728395,"2ι+1λ
+ nι
X j=2"
CB,0.7234567901234568,"2 dimE(Fh, 2−ι−1)"
CB,0.7240740740740741,"j −1
+ 2
Kι · dimE(Fh, 2−ι−1)
Kι"
CB,0.7246913580246913,"≤dimE(Fh, 2−ι−1)
 
2 log nι + 4 + 1/(2ιλ)

,"
CB,0.7253086419753086,"where we used the relation
Kι
j
 ≤dimE(Fh, 2−ι−1) and the definition of nι in the second inequality.
749"
CB,0.725925925925926,"Additionally, for ι = n we also have
750 X"
CB,0.7265432098765432,"k∈Kn
D2
λ,Fh(zk
h; Zall
h,k−1) ≤
X k∈Kn"
CB,0.7271604938271605,"Lk(zk
h)
λ
≤|Kn| · λ/K λ
≤1,"
CB,0.7277777777777777,"and so finally we sum over ι = 0, · · · , n to get
751 K
X"
CB,0.7283950617283951,"k=1
D2
λ,Fh(zk
h; Zall
h,k−1) ≤ n−1
X"
CB,0.7290123456790123,"ι=0
dimE(Fh, 2−ι−1)
 
2 log nι + 4 + 1/(2ιλ)

+ 1"
CB,0.7296296296296296,"≤n dimE(Fh, 2−n)
 
2 log K + 4 + 1/λ

+ 1"
CB,0.730246913580247,"≤C dimE(Fh, λ/K) log(K/ min{1, λ}),"
CB,0.7308641975308642,"where the final step makes the assumption that λ = O(1/ log K), in which case it holds with some
752"
CB,0.7314814814814815,"absolute constant CD.
753"
CB,0.7320987654320987,"Remark C.2. Again, this prove does not depend on the multi-level structure of episodic MDPs. In
754"
CB,0.7327160493827161,"fact, it only relies on the Eluder dimensionality of Fh. This means the proof can be converted to the
755"
CB,0.7333333333333333,"bandit case of Lemma A.3 without any essential changes: simply change episode k into time step t,
756"
CB,0.7339506172839506,"disregard all mentions of level h, and consider z = a instead of z = (s, a).
757"
CB,0.7345679012345679,"D
Technical Lemmas
758"
CB,0.7351851851851852,"In this section, we provide a technical concentration lemma that serves as the core of our results. For
759"
CB,0.7358024691358025,"one, this lemma is based on the following concentration inequality:
760"
CB,0.7364197530864197,"Lemma D.1. For a sequence of random variables {Zt}t∈N adapted to the filtration {St}t∈N and
761"
CB,0.737037037037037,"function f ∈F, for any λ > 0, with probability at least 1 −δ, for all t ∈N, we have
762 −1 λ t
X"
CB,0.7376543209876543,"s=1
log E

exp[−λf(Zs)]
Ss−1

− t
X"
CB,0.7382716049382716,"s=1
f(Zs) ≤1 λδ ."
CB,0.7388888888888889,"The proof for this lemma can be found under Lemma 4 of Russo and Van Roy [2013]. Apart from
763"
CB,0.7395061728395061,"this, we need yet another basic concentration lemma:
764"
CB,0.7401234567901235,"Lemma D.2. Suppose {ηt}T
t=1 is a sequence of conditional R-sub-Gaussian random variables
satisfying E

eµηtHt−1

≤exp
 
R2µ2/2

, where Ht−1 denotes all history before time t, with
probability 1 −δ, we have
T
X"
CB,0.7407407407407407,"t=1
η2
t ≤2Tσ2 + 3σ2 log(1/δ)."
CB,0.741358024691358,"A proof of this lemma can be found under Lemma G.2 of Ye et al. [2023]. With this, we can prove
765"
CB,0.7419753086419754,"the following lemma characterizing the accuracy of least squares solution. Even though we need
766"
CB,0.7425925925925926,"this lemma for both bandit and RL settings, we will follow the notations presented in multi-agent
767"
CB,0.7432098765432099,"contextual bandits. Detailed explanation of how this translates to multi-agent MDPs can be found in
768"
CB,0.7438271604938271,"Section C.2.
769"
CB,0.7444444444444445,"Lemma D.3. Suppose we have a sequence of inputs {(at, rt)}T
t=1 that follow the rule rt = f ∗(at)+ηt
for some ground truth f ∗∈F, with ηt being conditionally R-sub-Gaussian:"
CB,0.7450617283950617,"E

eµηta1:t, r1:t−1

≤exp(R2µ2/2), ∀µ ∈R."
CB,0.745679012345679,"We also have server datasets Zser
t
at different time steps, collected following the communication
770"
CB,0.7462962962962963,"protocol in our settings. Note that strictly speaking, the conditions under which ηt is sub-Gaussian
771"
CB,0.7469135802469136,"should also include the former participants m1:t, but we will omit this dependency for convenience.
772"
CB,0.7475308641975309,"Consider bf ser
t+1, the approximate ERM solution to the least squares problem:
773 
X"
CB,0.7481481481481481,"(a,r)∈Zser
t"
CB,0.7487654320987654,"  bf ser
t+1(a) −r
2
1/2
≤min
f∈Ft 
X"
CB,0.7493827160493827,"(a,r)∈Zser
t"
CB,0.75," 
f(a) −r
2
1/2
+ ϵ0
√ t,"
CB,0.7506172839506173,"Then abbreviating N = N(F, γ) and taking CERM = 36, with probability at least 1 −δ,
774 X"
CB,0.7512345679012346,"(a,r)∈Zser
t"
CB,0.7518518518518519,"  bf ser
t+1(a) −f ∗(a)
2 ≤CERM"
CB,0.7524691358024691,"
λ + (γ + ϵ0)2T + (γ + ϵ0)TR + R2(1 + Mα) log(3N/δ) + R2M 2α log(3NM/δ)
"
CB,0.7530864197530864,"Proof of Lemma D.3. Let Fγ be a γ-cover of the function class F with respect to the infinity norm
∥· ∥∞. For f ∈F and (at, rt) for some t ∈[T], let"
CB,0.7537037037037037,"ϕ(f, at, rt) = −(f(at) −rt)2 + (f ∗(at) −rt)2,"
CB,0.754320987654321,"Since rt = f ∗(at) + ηt, we can write ϕ(f, at, rt) as
775"
CB,0.7549382716049383,"ϕ(f, at, rt) = −
 
f(at) −f ∗(at) + ηt
2 + η2
t"
CB,0.7555555555555555,"= −2
 
f(at) −f ∗(at)

ηt −
 
f(at) −f ∗(at)
2"
CB,0.7561728395061729,"Since ηt is R-sub-Gaussian conditional on Zall
t−1, at, we have for any positive parameter µ that
776"
CB,0.7567901234567901,"log E

exp(µϕ(f, at, rt))
Zall
t−1, at

≤2µ2R2(f(at) −f ∗(at))2 −µ(f(at) −f ∗(at))2"
CB,0.7574074074074074,= (2µ2R2 −µ)(f(at) −f ∗(at))2
CB,0.7580246913580246,"Using Lemma D.1, we have with probability at least 1 −δ/3, for all f ∈Fγ and t ∈[T],
777"
CB,0.758641975308642,"µall
X"
CB,0.7592592592592593,"(a,r)∈Zall
t"
CB,0.7598765432098765,"ϕ(f, a, r) ≤(2µ2
allR2 −µall)
X"
CB,0.7604938271604939,"(a,r)∈Zall
t"
CB,0.7611111111111111,"(f(a) −f ∗(a))2 + log(3N/δ),
(26)"
CB,0.7617283950617284,"where µall > 0 is a parameter we will determine later.
778"
CB,0.7623456790123457,"On the other hand, if we consider any local agent m, when mt = m, we have ηt is R-sub-Gaussian
779"
CB,0.762962962962963,"conditional on Zup
m,t−1 ∪Zloc
m,t−1 and at, i.e. all the data agent m has received from the environment
780"
CB,0.7635802469135803,"up to this point. Thus we have for any µ > 0 that
781"
CB,0.7641975308641975,"log E

exp(−µϕ(f, at, rt))
Zup
m,t−1 ∪Zloc
m,t−1, at

≤2µ2R2(f(at) −f ∗(at))2 + µ(f(at) −f ∗(at))2"
CB,0.7648148148148148,= (2µ2R2 + µ)(f(at) −f ∗(at))2
CB,0.7654320987654321,"Then again using Lemma D.1 and taking summation on Zloc
m,t, with probability at least 1 −δ/3, the
782"
CB,0.7660493827160494,"following holds for any m ∈[M]:
783"
CB,0.7666666666666667,"−µloc
X"
CB,0.7672839506172839,"(a,r)∈Zloc
m,t"
CB,0.7679012345679013,"ϕ(f, a, r) ≤(2µ2
locR2 + µloc)
X"
CB,0.7685185185185185,"(a,r)∈Zloc
m,t"
CB,0.7691358024691358,"(f(a) −f ∗(a))2 + log(3NM/δ),
(27)"
CB,0.769753086419753,"where µloc > 0 is a parameter we will determine later.
784"
CB,0.7703703703703704,"Taking the summation of (27) for all m ∈[M] and combining (26), while observing that Zser
t
=
785"
CB,0.7709876543209877,"Zall
t
 SM
m=1 Zloc
m,t, we get
786 X"
CB,0.7716049382716049,"(a,r)∈Zser
t
ϕ(f, a, r) =
X"
CB,0.7722222222222223,"(a,r)∈Zall
t"
CB,0.7728395061728395,"ϕ(f, a, r) − M
X m=1 X"
CB,0.7734567901234568,"(a,r)∈Zloc
m,t"
CB,0.774074074074074,"ϕ(f, a, r)"
CB,0.7746913580246914,"≤(2µallR2 −1)
X"
CB,0.7753086419753087,"(a,r)∈Zall
t"
CB,0.7759259259259259,(f(a) −f ∗(a))2 + 1
CB,0.7765432098765432,"µall
log(3N/δ)"
CB,0.7771604938271605,"+ (2µlocR2 + 1) M
X m=1 X"
CB,0.7777777777777778,"(a,r)∈Zloc
m,t"
CB,0.778395061728395,"(f(a) −f ∗(a))2 +
1
µloc
M log(3NM/δ)"
CB,0.7790123456790123,"= 2R2(µall + µloc)∥f −f ∗∥2
Zall
t −(2µlocR2 + 1)∥f −f ∗∥2
Zser
t + 1"
CB,0.7796296296296297,"µall
log(3N/δ) +
1
µloc
M log(3NM/δ)."
CB,0.7802469135802469,"From Lemma A.1, we have λ+∥f−f ∗∥2
Zall
t ≤(1+Mα)
 
λ+∥f−f ∗∥2
Zser
t

⇔∥f−f ∗∥2
Zall
t ≤Mαλ+
787"
CB,0.7808641975308642,"(1 + Mα)∥f −f ∗∥2
Zser
t . Plugging this inequality into the above and letting µall = 1/8R2(1 + Mα)
788"
CB,0.7814814814814814,"and µloc = 1/8R2Mα, we get
789 X"
CB,0.7820987654320988,"(a,r)∈Zser
t
ϕ(f, a, r) ≤2R2(µall + µloc)Mαλ −
 
1 −2MαµlocR2 −2(1 + Mα)µallR2
∥f −f ∗∥2
Zser
t + 1"
CB,0.782716049382716,"µall
log(3N/δ) +
1
µloc
M log(3NM/δ) ≤−1"
CB,0.7833333333333333,"2∥f −f ∗∥2
Zser
t + 1"
CB,0.7839506172839507,2λ + 8R2(1 + Mα) log(3N/δ) + 8R2M 2α log(3NM/δ). (28)
CB,0.7845679012345679,"Now for bf ser
t+1, there exists ef ∈Fγ such that ∥ef −bf ser
t+1∥∞≤γ. Using Lemma D.2, this gives us the
790"
CB,0.7851851851851852,"following with probability at least 1 −δ/3:
791 −
X"
CB,0.7858024691358024,"(a,r)∈Zser
t
ϕ( ef, a, r) =
X"
CB,0.7864197530864198,"(a,r)∈Zser
t"
CB,0.7870370370370371,"  ef(a) −r
2 −
 
f ∗(a) −r
2
"
CB,0.7876543209876543,"≤
s
X"
CB,0.7882716049382716,"(a,r)∈Zser
t"
CB,0.7888888888888889,"  bf ser
t+1(a) −r
2 +
p"
CB,0.7895061728395062,"tγ2
2
−
X"
CB,0.7901234567901234,"(a,r)∈Zser
t"
CB,0.7907407407407407," 
f ∗(a) −r
2"
CB,0.7913580246913581,"≤
s
X"
CB,0.7919753086419753,"(a,r)∈Zser
t"
CB,0.7925925925925926," 
f ∗(a) −r
2 +
√"
CB,0.7932098765432098,"t(γ + ϵ0)
2
−
X"
CB,0.7938271604938272,"(a,r)∈Zser
t"
CB,0.7944444444444444," 
f ∗(a) −r
2"
CB,0.7950617283950617,"= (γ + ϵ0)2t + 2(γ + ϵ0)
√"
CB,0.7956790123456791,"t

t
X"
CB,0.7962962962962963,"s=1
η2
s 1/2"
CB,0.7969135802469136,"≤(γ + ϵ0)2t + 2(γ + ϵ0)
p"
CB,0.7975308641975308,"2T 2R2 + 3TR2 log(3/δ),"
CB,0.7981481481481482,"where we used the basic inequality
pP(a + b)2 ≤
pP a2 +
pP b2 in the first inequality and
792"
CB,0.7987654320987654,"used the property of bf ser
t+1 in the second inequality. Finally, taking a union bound and combining this
793"
CB,0.7993827160493827,"with (28), we have with probability at least 1 −δ,
794 X"
CB,0.8,"(a,r)∈Zser
t"
CB,0.8006172839506173,"  bf ser
t+1(a) −f ∗(a)
2"
CB,0.8012345679012346,"≤2γ2t + 2
X"
CB,0.8018518518518518,"(a,r)∈Zser
t"
CB,0.8024691358024691,"  ef(a) −f ∗(a)
2"
CB,0.8030864197530864,"≤2γ2t −2
X"
CB,0.8037037037037037,"(a,r)∈Zser
t
ϕ( ef, a, r) + λ + 32R2(1 + Mα) log(3N/δ) + 32R2M 2α log(3NM/δ)"
CB,0.804320987654321,"≤2γ2T + 2(γ + ϵ0)2T + 4(γ + ϵ0)
p"
CB,0.8049382716049382,2T 2R2 + 3TR2 log(3/δ) + λ + 32R2(1 + Mα) log(3N/δ) + 32R2M 2α log(3NM/ ≤CERM
CB,0.8055555555555556,"
λ + (γ + ϵ0)2T + (γ + ϵ0)TR + R2(1 + Mα) log(3N/δ) + R2M 2α log(3NM/δ)

,"
CB,0.8061728395061728,"where the first inequality uses again ∥ef −bf ser
t+1∥∞≤γ, and it can be verified that the last inequality
795"
CB,0.8067901234567901,"holds when CERM ≥36.
796"
CB,0.8074074074074075,"NeurIPS Paper Checklist
797"
CLAIMS,0.8080246913580247,"1. Claims
798"
CLAIMS,0.808641975308642,"Question: Do the main claims made in the abstract and introduction accurately reflect the
799"
CLAIMS,0.8092592592592592,"paper’s contributions and scope?
800"
CLAIMS,0.8098765432098766,"Answer: [Yes]
801"
CLAIMS,0.8104938271604938,"Justification: We accurately summarize our contribution and main results in the abstract,
802"
CLAIMS,0.8111111111111111,"and elaborate further on motivation and main techniques in our introduction.
803"
CLAIMS,0.8117283950617284,"Guidelines:
804"
CLAIMS,0.8123456790123457,"• The answer NA means that the abstract and introduction do not include the claims
805"
CLAIMS,0.812962962962963,"made in the paper.
806"
CLAIMS,0.8135802469135802,"• The abstract and/or introduction should clearly state the claims made, including the
807"
CLAIMS,0.8141975308641975,"contributions made in the paper and important assumptions and limitations. A No or
808"
CLAIMS,0.8148148148148148,"NA answer to this question will not be perceived well by the reviewers.
809"
CLAIMS,0.8154320987654321,"• The claims made should match theoretical and experimental results, and reflect how
810"
CLAIMS,0.8160493827160494,"much the results can be expected to generalize to other settings.
811"
CLAIMS,0.8166666666666667,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
812"
CLAIMS,0.817283950617284,"are not attained by the paper.
813"
LIMITATIONS,0.8179012345679012,"2. Limitations
814"
LIMITATIONS,0.8185185185185185,"Question: Does the paper discuss the limitations of the work performed by the authors?
815"
LIMITATIONS,0.8191358024691358,"Answer: [Yes]
816"
LIMITATIONS,0.8197530864197531,"Justification: All assumptions made for our theoretical analysis are present and stated
817"
LIMITATIONS,0.8203703703703704,"clearly within the main paragraphs of our paper. Discussions on the applicability of these
818"
LIMITATIONS,0.8209876543209876,"assumptions are also included.
819"
LIMITATIONS,0.821604938271605,"Guidelines:
820"
LIMITATIONS,0.8222222222222222,"• The answer NA means that the paper has no limitation while the answer No means that
821"
LIMITATIONS,0.8228395061728395,"the paper has limitations, but those are not discussed in the paper.
822"
LIMITATIONS,0.8234567901234567,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
823"
LIMITATIONS,0.8240740740740741,"• The paper should point out any strong assumptions and how robust the results are to
824"
LIMITATIONS,0.8246913580246914,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
825"
LIMITATIONS,0.8253086419753086,"model well-specification, asymptotic approximations only holding locally). The authors
826"
LIMITATIONS,0.825925925925926,"should reflect on how these assumptions might be violated in practice and what the
827"
LIMITATIONS,0.8265432098765432,"implications would be.
828"
LIMITATIONS,0.8271604938271605,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
829"
LIMITATIONS,0.8277777777777777,"only tested on a few datasets or with a few runs. In general, empirical results often
830"
LIMITATIONS,0.828395061728395,"depend on implicit assumptions, which should be articulated.
831"
LIMITATIONS,0.8290123456790124,"• The authors should reflect on the factors that influence the performance of the approach.
832"
LIMITATIONS,0.8296296296296296,"For example, a facial recognition algorithm may perform poorly when image resolution
833"
LIMITATIONS,0.8302469135802469,"is low or images are taken in low lighting. Or a speech-to-text system might not be
834"
LIMITATIONS,0.8308641975308642,"used reliably to provide closed captions for online lectures because it fails to handle
835"
LIMITATIONS,0.8314814814814815,"technical jargon.
836"
LIMITATIONS,0.8320987654320988,"• The authors should discuss the computational efficiency of the proposed algorithms
837"
LIMITATIONS,0.832716049382716,"and how they scale with dataset size.
838"
LIMITATIONS,0.8333333333333334,"• If applicable, the authors should discuss possible limitations of their approach to
839"
LIMITATIONS,0.8339506172839506,"address problems of privacy and fairness.
840"
LIMITATIONS,0.8345679012345679,"• While the authors might fear that complete honesty about limitations might be used by
841"
LIMITATIONS,0.8351851851851851,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
842"
LIMITATIONS,0.8358024691358025,"limitations that aren’t acknowledged in the paper. The authors should use their best
843"
LIMITATIONS,0.8364197530864198,"judgment and recognize that individual actions in favor of transparency play an impor-
844"
LIMITATIONS,0.837037037037037,"tant role in developing norms that preserve the integrity of the community. Reviewers
845"
LIMITATIONS,0.8376543209876544,"will be specifically instructed to not penalize honesty concerning limitations.
846"
THEORY ASSUMPTIONS AND PROOFS,0.8382716049382716,"3. Theory Assumptions and Proofs
847"
THEORY ASSUMPTIONS AND PROOFS,0.8388888888888889,"Question: For each theoretical result, does the paper provide the full set of assumptions and
848"
THEORY ASSUMPTIONS AND PROOFS,0.8395061728395061,"a complete (and correct) proof?
849"
THEORY ASSUMPTIONS AND PROOFS,0.8401234567901235,"Answer: [Yes]
850"
THEORY ASSUMPTIONS AND PROOFS,0.8407407407407408,"Justification: All assumptions are listed in the main paper, while a very detailed and sound
851"
THEORY ASSUMPTIONS AND PROOFS,0.841358024691358,"proof is displayed in the appendices.
852"
THEORY ASSUMPTIONS AND PROOFS,0.8419753086419753,"Guidelines:
853"
THEORY ASSUMPTIONS AND PROOFS,0.8425925925925926,"• The answer NA means that the paper does not include theoretical results.
854"
THEORY ASSUMPTIONS AND PROOFS,0.8432098765432099,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
855"
THEORY ASSUMPTIONS AND PROOFS,0.8438271604938271,"referenced.
856"
THEORY ASSUMPTIONS AND PROOFS,0.8444444444444444,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
857"
THEORY ASSUMPTIONS AND PROOFS,0.8450617283950618,"• The proofs can either appear in the main paper or the supplemental material, but if
858"
THEORY ASSUMPTIONS AND PROOFS,0.845679012345679,"they appear in the supplemental material, the authors are encouraged to provide a short
859"
THEORY ASSUMPTIONS AND PROOFS,0.8462962962962963,"proof sketch to provide intuition.
860"
THEORY ASSUMPTIONS AND PROOFS,0.8469135802469135,"• Inversely, any informal proof provided in the core of the paper should be complemented
861"
THEORY ASSUMPTIONS AND PROOFS,0.8475308641975309,"by formal proofs provided in appendix or supplemental material.
862"
THEORY ASSUMPTIONS AND PROOFS,0.8481481481481481,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
863"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8487654320987654,"4. Experimental Result Reproducibility
864"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8493827160493828,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
865"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.85,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
866"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8506172839506173,"of the paper (regardless of whether the code and data are provided or not)?
867"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8512345679012345,"Answer: [NA]
868"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8518518518518519,"Justification: Our theoretical paper does not present any experimental results.
869"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8524691358024692,"Guidelines:
870"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8530864197530864,"• The answer NA means that the paper does not include experiments.
871"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8537037037037037,"• If the paper includes experiments, a No answer to this question will not be perceived
872"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.854320987654321,"well by the reviewers: Making the paper reproducible is important, regardless of
873"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8549382716049383,"whether the code and data are provided or not.
874"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8555555555555555,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
875"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8561728395061728,"to make their results reproducible or verifiable.
876"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8567901234567902,"• Depending on the contribution, reproducibility can be accomplished in various ways.
877"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8574074074074074,"For example, if the contribution is a novel architecture, describing the architecture fully
878"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8580246913580247,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
879"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.858641975308642,"be necessary to either make it possible for others to replicate the model with the same
880"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8592592592592593,"dataset, or provide access to the model. In general. releasing code and data is often
881"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8598765432098765,"one good way to accomplish this, but reproducibility can also be provided via detailed
882"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8604938271604938,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
883"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8611111111111112,"of a large language model), releasing of a model checkpoint, or other means that are
884"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8617283950617284,"appropriate to the research performed.
885"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8623456790123457,"• While NeurIPS does not require releasing code, the conference does require all submis-
886"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8629629629629629,"sions to provide some reasonable avenue for reproducibility, which may depend on the
887"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8635802469135803,"nature of the contribution. For example
888"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8641975308641975,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
889"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8648148148148148,"to reproduce that algorithm.
890"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8654320987654321,"(b) If the contribution is primarily a new model architecture, the paper should describe
891"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8660493827160494,"the architecture clearly and fully.
892"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8666666666666667,"(c) If the contribution is a new model (e.g., a large language model), then there should
893"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8672839506172839,"either be a way to access this model for reproducing the results or a way to reproduce
894"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8679012345679012,"the model (e.g., with an open-source dataset or instructions for how to construct
895"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8685185185185185,"the dataset).
896"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8691358024691358,"(d) We recognize that reproducibility may be tricky in some cases, in which case
897"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8697530864197531,"authors are welcome to describe the particular way they provide for reproducibility.
898"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8703703703703703,"In the case of closed-source models, it may be that access to the model is limited in
899"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8709876543209877,"some way (e.g., to registered users), but it should be possible for other researchers
900"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8716049382716049,"to have some path to reproducing or verifying the results.
901"
OPEN ACCESS TO DATA AND CODE,0.8722222222222222,"5. Open access to data and code
902"
OPEN ACCESS TO DATA AND CODE,0.8728395061728395,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
903"
OPEN ACCESS TO DATA AND CODE,0.8734567901234568,"tions to faithfully reproduce the main experimental results, as described in supplemental
904"
OPEN ACCESS TO DATA AND CODE,0.8740740740740741,"material?
905"
OPEN ACCESS TO DATA AND CODE,0.8746913580246913,"Answer: [NA]
906"
OPEN ACCESS TO DATA AND CODE,0.8753086419753087,"Justification: Our theoretical paper does not present any experimental results.
907"
OPEN ACCESS TO DATA AND CODE,0.8759259259259259,"Guidelines:
908"
OPEN ACCESS TO DATA AND CODE,0.8765432098765432,"• The answer NA means that paper does not include experiments requiring code.
909"
OPEN ACCESS TO DATA AND CODE,0.8771604938271605,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
910"
OPEN ACCESS TO DATA AND CODE,0.8777777777777778,"public/guides/CodeSubmissionPolicy) for more details.
911"
OPEN ACCESS TO DATA AND CODE,0.8783950617283951,"• While we encourage the release of code and data, we understand that this might not be
912"
OPEN ACCESS TO DATA AND CODE,0.8790123456790123,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
913"
OPEN ACCESS TO DATA AND CODE,0.8796296296296297,"including code, unless this is central to the contribution (e.g., for a new open-source
914"
OPEN ACCESS TO DATA AND CODE,0.8802469135802469,"benchmark).
915"
OPEN ACCESS TO DATA AND CODE,0.8808641975308642,"• The instructions should contain the exact command and environment needed to run to
916"
OPEN ACCESS TO DATA AND CODE,0.8814814814814815,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
917"
OPEN ACCESS TO DATA AND CODE,0.8820987654320988,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
918"
OPEN ACCESS TO DATA AND CODE,0.8827160493827161,"• The authors should provide instructions on data access and preparation, including how
919"
OPEN ACCESS TO DATA AND CODE,0.8833333333333333,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
920"
OPEN ACCESS TO DATA AND CODE,0.8839506172839506,"• The authors should provide scripts to reproduce all experimental results for the new
921"
OPEN ACCESS TO DATA AND CODE,0.8845679012345679,"proposed method and baselines. If only a subset of experiments are reproducible, they
922"
OPEN ACCESS TO DATA AND CODE,0.8851851851851852,"should state which ones are omitted from the script and why.
923"
OPEN ACCESS TO DATA AND CODE,0.8858024691358025,"• At submission time, to preserve anonymity, the authors should release anonymized
924"
OPEN ACCESS TO DATA AND CODE,0.8864197530864197,"versions (if applicable).
925"
OPEN ACCESS TO DATA AND CODE,0.8870370370370371,"• Providing as much information as possible in supplemental material (appended to the
926"
OPEN ACCESS TO DATA AND CODE,0.8876543209876543,"paper) is recommended, but including URLs to data and code is permitted.
927"
OPEN ACCESS TO DATA AND CODE,0.8882716049382716,"6. Experimental Setting/Details
928"
OPEN ACCESS TO DATA AND CODE,0.8888888888888888,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
929"
OPEN ACCESS TO DATA AND CODE,0.8895061728395062,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
930"
OPEN ACCESS TO DATA AND CODE,0.8901234567901235,"results?
931"
OPEN ACCESS TO DATA AND CODE,0.8907407407407407,"Answer: [NA]
932"
OPEN ACCESS TO DATA AND CODE,0.891358024691358,"Justification: Our theoretical paper does not present any experimental results.
933"
OPEN ACCESS TO DATA AND CODE,0.8919753086419753,"Guidelines:
934"
OPEN ACCESS TO DATA AND CODE,0.8925925925925926,"• The answer NA means that the paper does not include experiments.
935"
OPEN ACCESS TO DATA AND CODE,0.8932098765432098,"• The experimental setting should be presented in the core of the paper to a level of detail
936"
OPEN ACCESS TO DATA AND CODE,0.8938271604938272,"that is necessary to appreciate the results and make sense of them.
937"
OPEN ACCESS TO DATA AND CODE,0.8944444444444445,"• The full details can be provided either with the code, in appendix, or as supplemental
938"
OPEN ACCESS TO DATA AND CODE,0.8950617283950617,"material.
939"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.895679012345679,"7. Experiment Statistical Significance
940"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8962962962962963,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
941"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8969135802469136,"information about the statistical significance of the experiments?
942"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8975308641975308,"Answer: [NA]
943"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8981481481481481,"Justification: Our theoretical paper does not present any experimental results.
944"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8987654320987655,"Guidelines:
945"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8993827160493827,"• The answer NA means that the paper does not include experiments.
946"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
947"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9006172839506172,"dence intervals, or statistical significance tests, at least for the experiments that support
948"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9012345679012346,"the main claims of the paper.
949"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9018518518518519,"• The factors of variability that the error bars are capturing should be clearly stated (for
950"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9024691358024691,"example, train/test split, initialization, random drawing of some parameter, or overall
951"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9030864197530865,"run with given experimental conditions).
952"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9037037037037037,"• The method for calculating the error bars should be explained (closed form formula,
953"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.904320987654321,"call to a library function, bootstrap, etc.)
954"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9049382716049382,"• The assumptions made should be given (e.g., Normally distributed errors).
955"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9055555555555556,"• It should be clear whether the error bar is the standard deviation or the standard error
956"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9061728395061729,"of the mean.
957"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9067901234567901,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
958"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9074074074074074,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
959"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9080246913580247,"of Normality of errors is not verified.
960"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.908641975308642,"• For asymmetric distributions, the authors should be careful not to show in tables or
961"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9092592592592592,"figures symmetric error bars that would yield results that are out of range (e.g. negative
962"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9098765432098765,"error rates).
963"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9104938271604939,"• If error bars are reported in tables or plots, The authors should explain in the text how
964"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9111111111111111,"they were calculated and reference the corresponding figures or tables in the text.
965"
EXPERIMENTS COMPUTE RESOURCES,0.9117283950617284,"8. Experiments Compute Resources
966"
EXPERIMENTS COMPUTE RESOURCES,0.9123456790123456,"Question: For each experiment, does the paper provide sufficient information on the com-
967"
EXPERIMENTS COMPUTE RESOURCES,0.912962962962963,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
968"
EXPERIMENTS COMPUTE RESOURCES,0.9135802469135802,"the experiments?
969"
EXPERIMENTS COMPUTE RESOURCES,0.9141975308641975,"Answer: [NA]
970"
EXPERIMENTS COMPUTE RESOURCES,0.9148148148148149,"Justification: Our theoretical paper does not present any experimental results.
971"
EXPERIMENTS COMPUTE RESOURCES,0.9154320987654321,"Guidelines:
972"
EXPERIMENTS COMPUTE RESOURCES,0.9160493827160494,"• The answer NA means that the paper does not include experiments.
973"
EXPERIMENTS COMPUTE RESOURCES,0.9166666666666666,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
974"
EXPERIMENTS COMPUTE RESOURCES,0.917283950617284,"or cloud provider, including relevant memory and storage.
975"
EXPERIMENTS COMPUTE RESOURCES,0.9179012345679012,"• The paper should provide the amount of compute required for each of the individual
976"
EXPERIMENTS COMPUTE RESOURCES,0.9185185185185185,"experimental runs as well as estimate the total compute.
977"
EXPERIMENTS COMPUTE RESOURCES,0.9191358024691358,"• The paper should disclose whether the full research project required more compute
978"
EXPERIMENTS COMPUTE RESOURCES,0.9197530864197531,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
979"
EXPERIMENTS COMPUTE RESOURCES,0.9203703703703704,"didn’t make it into the paper).
980"
CODE OF ETHICS,0.9209876543209876,"9. Code Of Ethics
981"
CODE OF ETHICS,0.921604938271605,"Question: Does the research conducted in the paper conform, in every respect, with the
982"
CODE OF ETHICS,0.9222222222222223,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
983"
CODE OF ETHICS,0.9228395061728395,"Answer: [Yes]
984"
CODE OF ETHICS,0.9234567901234568,"Justification: We have thoroughly reviewed the NeurIPS Code of Ethics, and believe our
985"
CODE OF ETHICS,0.924074074074074,"work conforms fully the the Code.
986"
CODE OF ETHICS,0.9246913580246914,"Guidelines:
987"
CODE OF ETHICS,0.9253086419753086,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
988"
CODE OF ETHICS,0.9259259259259259,"• If the authors answer No, they should explain the special circumstances that require a
989"
CODE OF ETHICS,0.9265432098765433,"deviation from the Code of Ethics.
990"
CODE OF ETHICS,0.9271604938271605,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
991"
CODE OF ETHICS,0.9277777777777778,"eration due to laws or regulations in their jurisdiction).
992"
BROADER IMPACTS,0.928395061728395,"10. Broader Impacts
993"
BROADER IMPACTS,0.9290123456790124,"Question: Does the paper discuss both potential positive societal impacts and negative
994"
BROADER IMPACTS,0.9296296296296296,"societal impacts of the work performed?
995"
BROADER IMPACTS,0.9302469135802469,"Answer: [Yes]
996"
BROADER IMPACTS,0.9308641975308642,"Justification: See Impact Statement before appendices
997"
BROADER IMPACTS,0.9314814814814815,"Guidelines:
998"
BROADER IMPACTS,0.9320987654320988,"• The answer NA means that there is no societal impact of the work performed.
999"
BROADER IMPACTS,0.932716049382716,"• If the authors answer NA or No, they should explain why their work has no societal
1000"
BROADER IMPACTS,0.9333333333333333,"impact or why the paper does not address societal impact.
1001"
BROADER IMPACTS,0.9339506172839506,"• Examples of negative societal impacts include potential malicious or unintended uses
1002"
BROADER IMPACTS,0.9345679012345679,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
1003"
BROADER IMPACTS,0.9351851851851852,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
1004"
BROADER IMPACTS,0.9358024691358025,"groups), privacy considerations, and security considerations.
1005"
BROADER IMPACTS,0.9364197530864198,"• The conference expects that many papers will be foundational research and not tied
1006"
BROADER IMPACTS,0.937037037037037,"to particular applications, let alone deployments. However, if there is a direct path to
1007"
BROADER IMPACTS,0.9376543209876543,"any negative applications, the authors should point it out. For example, it is legitimate
1008"
BROADER IMPACTS,0.9382716049382716,"to point out that an improvement in the quality of generative models could be used to
1009"
BROADER IMPACTS,0.9388888888888889,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
1010"
BROADER IMPACTS,0.9395061728395062,"that a generic algorithm for optimizing neural networks could enable people to train
1011"
BROADER IMPACTS,0.9401234567901234,"models that generate Deepfakes faster.
1012"
BROADER IMPACTS,0.9407407407407408,"• The authors should consider possible harms that could arise when the technology is
1013"
BROADER IMPACTS,0.941358024691358,"being used as intended and functioning correctly, harms that could arise when the
1014"
BROADER IMPACTS,0.9419753086419753,"technology is being used as intended but gives incorrect results, and harms following
1015"
BROADER IMPACTS,0.9425925925925925,"from (intentional or unintentional) misuse of the technology.
1016"
BROADER IMPACTS,0.9432098765432099,"• If there are negative societal impacts, the authors could also discuss possible mitigation
1017"
BROADER IMPACTS,0.9438271604938272,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
1018"
BROADER IMPACTS,0.9444444444444444,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
1019"
BROADER IMPACTS,0.9450617283950618,"feedback over time, improving the efficiency and accessibility of ML).
1020"
SAFEGUARDS,0.945679012345679,"11. Safeguards
1021"
SAFEGUARDS,0.9462962962962963,"Question: Does the paper describe safeguards that have been put in place for responsible
1022"
SAFEGUARDS,0.9469135802469136,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
1023"
SAFEGUARDS,0.9475308641975309,"image generators, or scraped datasets)?
1024"
SAFEGUARDS,0.9481481481481482,"Answer: [NA]
1025"
SAFEGUARDS,0.9487654320987654,"Justification: Our theoretical paper does not present any experimental results, and thus does
1026"
SAFEGUARDS,0.9493827160493827,"not feature such data and models.
1027"
SAFEGUARDS,0.95,"Guidelines:
1028"
SAFEGUARDS,0.9506172839506173,"• The answer NA means that the paper poses no such risks.
1029"
SAFEGUARDS,0.9512345679012346,"• Released models that have a high risk for misuse or dual-use should be released with
1030"
SAFEGUARDS,0.9518518518518518,"necessary safeguards to allow for controlled use of the model, for example by requiring
1031"
SAFEGUARDS,0.9524691358024692,"that users adhere to usage guidelines or restrictions to access the model or implementing
1032"
SAFEGUARDS,0.9530864197530864,"safety filters.
1033"
SAFEGUARDS,0.9537037037037037,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
1034"
SAFEGUARDS,0.9543209876543209,"should describe how they avoided releasing unsafe images.
1035"
SAFEGUARDS,0.9549382716049383,"• We recognize that providing effective safeguards is challenging, and many papers do
1036"
SAFEGUARDS,0.9555555555555556,"not require this, but we encourage authors to take this into account and make a best
1037"
SAFEGUARDS,0.9561728395061728,"faith effort.
1038"
LICENSES FOR EXISTING ASSETS,0.9567901234567902,"12. Licenses for existing assets
1039"
LICENSES FOR EXISTING ASSETS,0.9574074074074074,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
1040"
LICENSES FOR EXISTING ASSETS,0.9580246913580247,"the paper, properly credited and are the license and terms of use explicitly mentioned and
1041"
LICENSES FOR EXISTING ASSETS,0.9586419753086419,"properly respected?
1042"
LICENSES FOR EXISTING ASSETS,0.9592592592592593,"Answer: [NA]
1043"
LICENSES FOR EXISTING ASSETS,0.9598765432098766,"Justification: Our paper does not include any such assets.
1044"
LICENSES FOR EXISTING ASSETS,0.9604938271604938,"Guidelines:
1045"
LICENSES FOR EXISTING ASSETS,0.9611111111111111,"• The answer NA means that the paper does not use existing assets.
1046"
LICENSES FOR EXISTING ASSETS,0.9617283950617284,"• The authors should cite the original paper that produced the code package or dataset.
1047"
LICENSES FOR EXISTING ASSETS,0.9623456790123457,"• The authors should state which version of the asset is used and, if possible, include a
1048"
LICENSES FOR EXISTING ASSETS,0.9629629629629629,"URL.
1049"
LICENSES FOR EXISTING ASSETS,0.9635802469135802,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
1050"
LICENSES FOR EXISTING ASSETS,0.9641975308641976,"• For scraped data from a particular source (e.g., website), the copyright and terms of
1051"
LICENSES FOR EXISTING ASSETS,0.9648148148148148,"service of that source should be provided.
1052"
LICENSES FOR EXISTING ASSETS,0.9654320987654321,"• If assets are released, the license, copyright information, and terms of use in the
1053"
LICENSES FOR EXISTING ASSETS,0.9660493827160493,"package should be provided. For popular datasets, paperswithcode.com/datasets
1054"
LICENSES FOR EXISTING ASSETS,0.9666666666666667,"has curated licenses for some datasets. Their licensing guide can help determine the
1055"
LICENSES FOR EXISTING ASSETS,0.967283950617284,"license of a dataset.
1056"
LICENSES FOR EXISTING ASSETS,0.9679012345679012,"• For existing datasets that are re-packaged, both the original license and the license of
1057"
LICENSES FOR EXISTING ASSETS,0.9685185185185186,"the derived asset (if it has changed) should be provided.
1058"
LICENSES FOR EXISTING ASSETS,0.9691358024691358,"• If this information is not available online, the authors are encouraged to reach out to
1059"
LICENSES FOR EXISTING ASSETS,0.9697530864197531,"the asset’s creators.
1060"
NEW ASSETS,0.9703703703703703,"13. New Assets
1061"
NEW ASSETS,0.9709876543209877,"Question: Are new assets introduced in the paper well documented and is the documentation
1062"
NEW ASSETS,0.971604938271605,"provided alongside the assets?
1063"
NEW ASSETS,0.9722222222222222,"Answer: [NA]
1064"
NEW ASSETS,0.9728395061728395,"Justification: Our theoretical paper does not introduce any new assets.
1065"
NEW ASSETS,0.9734567901234568,"Guidelines:
1066"
NEW ASSETS,0.9740740740740741,"• The answer NA means that the paper does not release new assets.
1067"
NEW ASSETS,0.9746913580246913,"• Researchers should communicate the details of the dataset/code/model as part of their
1068"
NEW ASSETS,0.9753086419753086,"submissions via structured templates. This includes details about training, license,
1069"
NEW ASSETS,0.975925925925926,"limitations, etc.
1070"
NEW ASSETS,0.9765432098765432,"• The paper should discuss whether and how consent was obtained from people whose
1071"
NEW ASSETS,0.9771604938271605,"asset is used.
1072"
NEW ASSETS,0.9777777777777777,"• At submission time, remember to anonymize your assets (if applicable). You can either
1073"
NEW ASSETS,0.9783950617283951,"create an anonymized URL or include an anonymized zip file.
1074"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9790123456790123,"14. Crowdsourcing and Research with Human Subjects
1075"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9796296296296296,"Question: For crowdsourcing experiments and research with human subjects, does the paper
1076"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.980246913580247,"include the full text of instructions given to participants and screenshots, if applicable, as
1077"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9808641975308642,"well as details about compensation (if any)?
1078"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9814814814814815,"Answer: [NA]
1079"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9820987654320987,"Justification: Our theoretical paper does not present any experimental results.
1080"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9827160493827161,"Guidelines:
1081"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9833333333333333,"• The answer NA means that the paper does not involve crowdsourcing nor research with
1082"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9839506172839506,"human subjects.
1083"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9845679012345679,"• Including this information in the supplemental material is fine, but if the main contribu-
1084"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9851851851851852,"tion of the paper involves human subjects, then as much detail as possible should be
1085"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9858024691358025,"included in the main paper.
1086"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9864197530864197,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
1087"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.987037037037037,"or other labor should be paid at least the minimum wage in the country of the data
1088"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9876543209876543,"collector.
1089"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9882716049382716,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
1090"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9888888888888889,"Subjects
1091"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9895061728395061,"Question: Does the paper describe potential risks incurred by study participants, whether
1092"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9901234567901235,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
1093"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9907407407407407,"approvals (or an equivalent approval/review based on the requirements of your country or
1094"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.991358024691358,"institution) were obtained?
1095"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9919753086419754,"Answer: [NA]
1096"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9925925925925926,"Justification: Our theoretical paper does not present any experimental results.
1097"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9932098765432099,"Guidelines:
1098"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9938271604938271,"• The answer NA means that the paper does not involve crowdsourcing nor research with
1099"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9944444444444445,"human subjects.
1100"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9950617283950617,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
1101"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.995679012345679,"may be required for any human subjects research. If you obtained IRB approval, you
1102"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9962962962962963,"should clearly state this in the paper.
1103"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9969135802469136,"• We recognize that the procedures for this may vary significantly between institutions
1104"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9975308641975309,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
1105"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9981481481481481,"guidelines for their institution.
1106"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9987654320987654,"• For initial submissions, do not include any information that would break anonymity (if
1107"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9993827160493827,"applicable), such as the institution conducting the review.
1108"
