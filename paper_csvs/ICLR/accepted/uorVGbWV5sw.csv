Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.001,"The noise in stochastic gradient descent (SGD), caused by minibatch sampling,
is poorly understood despite its practical importance in deep learning. This work
presents the ﬁrst systematic study of the SGD noise and ﬂuctuations close to a
local minimum. We ﬁrst analyze the SGD noise in linear regression in detail and
then derive a general formula for approximating SGD noise in different types of
minima. For application, our results (1) provide insight into the stability of training
a neural network, (2) suggest that a large learning rate can help generalization
by introducing an implicit regularization, (3) explain why the linear learning rate-
batchsize scaling law fails at a large learning rate or at a small batchsize and (4) can
provide an understanding of how discrete-time nature of SGD affects the recently
discovered power-law phenomenon of SGD."
INTRODUCTION,0.002,"1
INTRODUCTION"
INTRODUCTION,0.003,"Stochastic gradient descent (SGD) is the simple and efﬁcient optimization algorithm behind the
success of deep learning (Allen-Zhu et al., 2019; Xing et al., 2018; Zhang et al., 2018; Wang et al.,
2020; He and Tao, 2020; Liu et al., 2021; Simsekli et al., 2019; Wu et al., 2020). Minibatch noise, also
known as the SGD noise, is the primary type of noise in the learning dynamics of neural networks.
Practically, minibatch noise is unavoidable because a modern computer’s memory is limited while the
size of the datasets we use is large; this demands the dataset to be split into “minibatches"" for training.
At the same time, using minibatch is also a recommended practice because using a smaller batch
size often leads to better generalization performance (Hoffer et al., 2017). Therefore, understanding
minibatch noise in SGD has been one of the primary topics in deep learning theory. Dominantly many
theoretical studies take two approximations: (1) the continuous-time approximation, which takes
the inﬁnitesimal step-size limit; (2) the Hessian approximation, which assumes that the covariance
matrix of the SGD noise is equal to the Hessian H. While these approximations have been shown to
provide some qualitative understanding, the limitation of these approximations is not well understood.
For example, it is still unsure when such approximations are valid, which hinders our capability to
assess the correctness of the results obtained by approximations."
INTRODUCTION,0.004,"In this work, we ﬁll this gap by deriving analytical formulae for discrete-time SGD with arbitrary
learning rates and exact minibatch noise covariance. In summary, the main contributions are: (1)
we derive the strength and the shape of the minibatch SGD noise in the cases where the noise for
discrete-time SGD is analytically solvable; (2) we show that the SGD noise takes a different form
in different kinds of minima and propose general and more accurate approximations. This work is
organized as follows: Sec. 2 introduces the background. Sec. 3 discusses the related works. Sec. 4
outlines our theoretical results. Sec. 5 derives new approximation formulae for SGD noises. In
Sec. 6, we show how our results can provide practical and theoretical insights to problems relevant to
contemporary machine learning research. For reference, the relationship of this work to the previous
works is shown in Table 1."
BACKGROUND,0.005,"2
BACKGROUND"
BACKGROUND,0.006,"In this section, we introduce the minibatch SGD algorithm. Let {xi,yi}N
i=1 be a training set. We
can deﬁne the gradient descent (GD) algorithm for a differentiable loss function L as wt = wt−1 −
λ∇wL(w,{x,y}), where λ is the learning rate and w ∈RD is the weights of the model. We consider
an additive loss function for applying the minibatch SGD.
Deﬁnition
1.
A
loss
function
L({xi,yi}N
i=1,w)
is
additive
if
L({xi,yi}N
i=1,w)
=
1
N ∑N
i=1 ℓ(xi,yi,w) for some differentiable, non-negative function ℓ(⋅)."
BACKGROUND,0.007,Published as a conference paper at ICLR 2022
BACKGROUND,0.008,"Table 1: Summary of related works on the noise and stationary distribution of SGD. This work ﬁlls the gap of
the lack of theoretical results for the actual SGD dynamics, which is discrete-time and with minibatch noise."
BACKGROUND,0.009,"Setting
Artiﬁcial Noise
Hessian Approximation Noise
Minibatch Noise
Continuous-time
Sato and Nakagawa (2014); Welling and Teh (2011)
Jastrzebski et al. (2018); Zhu et al. (2019)
Blanc et al. (2020); Mori et al. (2021)
Mandt et al. (2017); Meng et al. (2020)
Wu et al. (2020); Xie et al. (2021)
Discrete-time
Yaida (2019); Gitman et al. (2019)
Liu et al. (2021)
This Work
Liu et al. (2021)"
BACKGROUND,0.01,"This deﬁnition is quite general. Most commonly studied and used loss functions are additive, e.g.,
the mean-square error (MSE) and cross-entropy loss. For an additive loss, the minibatch SGD with
momentum algorithm can be deﬁned.
Deﬁnition 2. The minibatch SGD with momentum algorithm by sampling with replacement computes
the update to the parameter w with the following set of equations:
⎧⎪⎪⎪⎪⎨⎪⎪⎪⎪⎩"
BACKGROUND,0.011,ˆgt = 1
BACKGROUND,0.012,"S ∑i∈Bt ∇ℓ(xi,yi,wt−1);
mt = µmt−1 + ˆgt;
wt = wt−1 −λmt.
(1)"
BACKGROUND,0.013,"where µ ∈[0,1) is the momentum hyperparameter, S ∶= ∣Bt∣is the minibatch size, and the set
Bt = {i1,...iS} are S i.i.d. random integers sampled uniformly from [1,N]."
BACKGROUND,0.014,"One can decompose the gradient into a deterministic plus a stochastic term. Note that EB[ˆgt] = ∇L
is equal to the gradient for the GD algorithm. We use EB(⋅) to denote the expectation over batches,
and use Ew(⋅) to denote the expectation over the stationary distribution of the model parameters.
Therefore, we can write ˆgt = EB[ˆgt] + ηt, where ηt ∶= 1"
BACKGROUND,0.015,"S ∑i∈Bt ∇ℓ(xi,yi,wt−1) −EB[ˆgt] is the
noise term; the noise covariance is C(wt) ∶= cov(ηt,ηt). Of central importance to us is the averaged
asymptotic noise covariance C ∶= limt→∞Ewt[C(wt)]. Also, we consider the asymptotic model
ﬂuctuation Σ ∶= limt→∞cov(wt,wt). Σ gives the strength and shape of the ﬂuctuation of w around
a local minimum and is another quantity of central importance to this work. Throughout this work, C
is called the “noise"" and Σ the “ﬂuctuation""."
RELATED WORKS,0.016,"3
RELATED WORKS"
RELATED WORKS,0.017,"Noise and Fluctuation in SGD. Deep learning models are trained with SGD and its variants. To
understand the parameter distribution in deep learning, one needs to understand the stationary
distribution of SGD (Mandt et al., 2017). Sato and Nakagawa (2014) describes the stationary
distribution of stochastic gradient Langevin dynamics using discrete-time Fokker-Planck equation.
Yaida (2019) connects the covariance of parameter Σ to that of the noise C through the ﬂuctuation-
dissipation theorem. When Σ is known, one may obtain by Laplace approximation the stationary
distribution of the model parameter around a local minimum w∗as N(w∗,Σ). Therefore, knowing
Σ can be of great practical use. For example, it has been used to estimate the local minimum escape
efﬁciency (Zhu et al., 2019; Liu et al., 2021) and argue that SGD prefers a ﬂatter minimum; it can
also be used to assess parameter uncertainty and prediction uncertainty when a Bayesian prior is
speciﬁed (Mandt et al., 2017; Gal and Ghahramani, 2016; Pearce et al., 2020). Empirically, both the
ﬂuctuation and the noise are known to crucially affect the generalization of a deep neural network.
Wu et al. (2020) shows that the strength and shape of the Σ due to the minibatch noise lead to better
generalization of neural networks in comparison to an artiﬁcially constructed noise."
RELATED WORKS,0.018,"Hessian Approximation of the Minibatch Noise. However, it is not yet known what form C and
Σ actually take for SGD in a realistic learning setting. Early attempts assume isotropic noise in the
continuous-time limit (Sato and Nakagawa, 2014; Mandt et al., 2017). In this setting, the noise is
an isotropic Gaussian with C ∼ID, and Σ is known to be proportional to the inverse Hessian H−1.
More recently, the importance of noise structure was realized (Hoffer et al., 2017; Jastrzebski et al.,
2018; Zhu et al., 2019; HaoChen et al., 2020). “Hessian approximation"", which assumes C ≈c0H
for some unknown constant c0, has often been adopted for understanding SGD (see Table 1); this
assumption is often motivated by the fact that C = Jw ≈H, where Jw is the Fisher information matrix
(FIM) (Zhu et al., 2019); the ﬂuctuation can be solved to be isotropic: Σ ∼ID. However, it is not
known under what conditions the Hessian approximation is valid, while previous works have argued
that it can be very inaccurate (Martens, 2014; Liu et al., 2021; Thomas et al., 2020; Kunstner et al.,
2019). However, Martens (2014) and Kunstner et al. (2019) only focuses on the natural gradient
descent (NGD) setting; Thomas et al. (2020) is closest to ours, but it does not apply to the case with
momentum, a matrix learning rate, or regularization."
RELATED WORKS,0.019,Published as a conference paper at ICLR 2022
RELATED WORKS,0.02,"Discrete-time SGD with a Large Learning Rate. Recently, it has been realized that networks
trained at a large learning rate have a dramatically better performance than networks trained with a
vanishing learning rate (lazy training) (Chizat and Bach, 2018). Lewkowycz et al. (2020) shows that
there is a qualitative difference between the lazy training regime and the large learning rate regime;
the performance features two plateaus in testing accuracy in the two regimes, with the large learning
rate regime performing much better. However, the theory regarding discrete-time SGD at a large
learning rate is almost non-existent, and it is also not known what Σ may be when the learning rate is
non-vanishing. Our work also sheds light on the behavior of SGD at a large learning rate. Some other
works also consider discrete-time SGD in a similar setting (Fontaine et al., 2021; Dieuleveut et al.,
2020; Toulis et al., 2017), but the focus is not on deriving analytical formulae or does not deal with
the stationary distribution."
SGD NOISE AND FLUCTUATION IN LINEAR REGRESSION,0.021,"4
SGD NOISE AND FLUCTUATION IN LINEAR REGRESSION"
SGD NOISE AND FLUCTUATION IN LINEAR REGRESSION,0.022,"This section derives the shape and strength of SGD noise and ﬂuctuation for linear regression;
concurrent to our work, Kunin et al. (2021) also studies the same problem but with continuous-time
approximation; our result is thus more general. To emphasize the message, we discuss the label noise
case in more detail. The other situations also deserve detailed analysis; we delay such discussion
to the appendix due to space constraints. Notation: S denotes the minibatch size. w ∈RD is the
model parameter viewed in a vectorized form; λ ∈R+ denotes a scalar learning rate; when the
learning rate takes the form of a preconditioning matrix, we use Λ ∈RD×D. A ∈RD×D denotes the
covariance matrix of the input data. When a matrix X is positive semi-deﬁnite, we write X ≥0;
throughout, we require Λ ≥0. γ ∈R denotes the weight decay hyperparameter; when the weight
decay hyperparameter is a matrix, we write Γ ∈RD×D. µ is the momentum hyperparameter in SGD.
For two matrices X,Y , the commutator is deﬁned as [X,Y ] ∶= XY −Y X. Other notations are
introduced in the context.1 The results of this section are numerically veriﬁed in Appendix A."
KEY PREVIOUS RESULTS,0.023,"4.1
KEY PREVIOUS RESULTS
When N ≫S, the following proposition is well-known and gives the exact noise due to minibatch
sampling. See Appendix E.1 for a derivation.
Proposition 1. The noise covariance of SGD as deﬁned in Deﬁnition 2 is"
KEY PREVIOUS RESULTS,0.024,"C(w) =
1
SN"
KEY PREVIOUS RESULTS,0.025,"N
∑
i=1
∇ℓi(w)∇ℓi(w)T −1"
KEY PREVIOUS RESULTS,0.026,"S ∇L(w)∇L(w)T,
(2)"
KEY PREVIOUS RESULTS,0.027,"where the notations ℓi(w) ∶= l(xi,yi,w) and L(w) ∶= L({xi,yi}N
i=1,w) are used."
KEY PREVIOUS RESULTS,0.028,"This gradient covariance matrix C is crucial to understand the minibatch noise. The standard
literature often assumes C(w) ≈H(w); however, the following well-known proposition shows that
this approximation can easily break down.
Proposition 2. Let w∗be the solution such that L(w∗) = 0, then C(w∗) = 0."
KEY PREVIOUS RESULTS,0.029,"Proof. Because ℓi is non-negative for all i, L(w∗) = 0 implies that ℓi(w∗) = 0. The differentiability
in turn implies that each ∇ℓi(w∗) = 0; therefore, C = 0. ◻"
KEY PREVIOUS RESULTS,0.03,"This proposition implies that there is no noise if our model can achieve zero training loss (which is
achievable for an overparametrized model). This already suggests that the Hessian approximation
C ∼H is wrong since the Hessian is unlikely to vanish in any minimum. The fact that the noise
strength vanishes at L = 0 suggests that the SGD noise might at least be proportional to L(w), which
we will show to be true for many cases. The following theorem relates C and Σ of the discrete-time
SGD algorithm with momentum for a matrix learning rate.
Theorem 1. (Liu et al., 2021) Consider running SGD on a quadratic loss function with Hessian H,
learning rate matrix Λ, momentum µ. Assuming ergodicity, then"
KEY PREVIOUS RESULTS,0.031,(1 −µ)(ΛHΣ + ΣHΛ) −1 + µ2
KEY PREVIOUS RESULTS,0.032,"1 −µ2 ΛHΣHΛ +
µ
1 −µ2 (ΛHΛHΣ + ΣHΛHΛ) = ΛCΛ.
(3)"
KEY PREVIOUS RESULTS,0.033,"Propostion 1 and Theorem 1 allow one to solve C and Σ. Equation (3) can be seen as a general
form of the Lyapunov equation (Lyapunov, 1992) and is hard to solve in general (Hammarling, 1982;
Ye et al., 1998; Simoncini, 2016). Solving this analytical equation in settings of machine learning
relevance is one of the main technical contributions of this work."
KEY PREVIOUS RESULTS,0.034,"1We use the word global minimum to refer to the global minimum of the loss function, i.e., where L = 0 and
a local minimum refers to a minimum that has a non-negative loss, i.e., L ≥0."
KEY PREVIOUS RESULTS,0.035,Published as a conference paper at ICLR 2022
RANDOM NOISE IN THE LABEL,0.036,"4.2
RANDOM NOISE IN THE LABEL"
RANDOM NOISE IN THE LABEL,0.037,We ﬁrst consider the case when the labels contain noise. The loss function takes the form
RANDOM NOISE IN THE LABEL,0.038,"L(w) =
1
2N"
RANDOM NOISE IN THE LABEL,0.039,"N
∑
i=1
(wTxi −yi)2,
(4)"
RANDOM NOISE IN THE LABEL,0.04,"where xi ∈RD are drawn from a zero-mean Gaussian distribution with feature covariance A ∶=
EB[xxT], and yi = uTxi + ϵi, for some ﬁxed u and ϵi ∈R is drawn from a distribution with zero
mean and ﬁnite second momentum σ2. We redeﬁne w −u →w and let N →∞with D held ﬁxed.
The following lemma ﬁnds C as a function of Σ."
RANDOM NOISE IN THE LABEL,0.041,"Lemma 1. (Covariance matrix for SGD noise in the label) Let N →∞and the model be updated
according to Eq. (1) with loss function in Eq. (4). Then, C = 1"
RANDOM NOISE IN THE LABEL,0.042,"S (AΣA + Tr[AΣ]A + σ2A).
(5)"
RANDOM NOISE IN THE LABEL,0.043,The model ﬂuctuation can be obtained using this lemma.
RANDOM NOISE IN THE LABEL,0.044,"Theorem 2. (Fluctuation of model parameters with random noise in the label) Let the assumptions
be the same as in Lemma 1 and [Λ,A] = 0. Then,"
RANDOM NOISE IN THE LABEL,0.045,Σ = σ2
RANDOM NOISE IN THE LABEL,0.046,S (1 + κµ
RANDOM NOISE IN THE LABEL,0.047,"S )ΛG−1
µ ,
(6)"
RANDOM NOISE IN THE LABEL,0.048,"where κµ ∶=
Tr[ΛAG−1
µ ]
1−1"
RANDOM NOISE IN THE LABEL,0.049,"S Tr[ΛAG−1
µ ] with Gµ ∶= 2(1 −µ)ID −( 1−µ"
RANDOM NOISE IN THE LABEL,0.05,1+µ + 1
RANDOM NOISE IN THE LABEL,0.051,S )ΛA.
RANDOM NOISE IN THE LABEL,0.052,"Remark. This result is numerically validated in Appendix A. The subscript µ refers to momentum.
To obtain results for vanilla SGD, one can set µ = 0, which has the effect of reducing Gµ →G =
2ID −(1 + 1"
RANDOM NOISE IN THE LABEL,0.053,"S )ΛA. From now on, we focus on the case when µ = 0 for notational simplicity, but we
note that the results for momentum can be likewise studied. The assumption [Λ,A] = 0 is not too
strong because this condition holds for a scalar learning rate and common second-order methods
such as Newton’s method."
RANDOM NOISE IN THE LABEL,0.054,"If σ2 = 0, then Σ = 0. This means that when there is no label noise, the model parameter has a
vanishing stationary ﬂuctuation, which corroborates Proposition 2. When a scalar learning rate λ ≪1
and 1 ≪S, we have"
RANDOM NOISE IN THE LABEL,0.055,Σ ≈λσ2
RANDOM NOISE IN THE LABEL,0.056,"2S ID,
(7)"
RANDOM NOISE IN THE LABEL,0.057,"which is the result one would expect from the continuous-time theory with the Hessian approximation
(Liu et al., 2021; Xie et al., 2021; Zhu et al., 2019), except for a correction factor of σ2. Therefore, a
Hessian approximation fails to account for the randomness in the data of strength σ2. We provide a
systematic and detailed comparison with the Hessian approximation in Table 2 of Appendix B."
RANDOM NOISE IN THE LABEL,0.058,"Moreover, it is worth comparing the exact result in Theorem 2 with Eq. (7) in the regime of non-
vanishing learning rate and small batch size. One notices two differences: (1) an anisotropic
enhancement, appearing in the matrix Gµ and taking the form −λ(1 + 1/S)A; compared with the
result in Liu et al. (2021), this term is due to the compound effect of using a large learning rate
and a small batchsize; (2) an isotropic enhancement term κ, which causes the overall magnitude
of ﬂuctuations to increase; this term does not appear in the previous works that are based on the
Hessian approximation and is due to the minibatch sampling process alone. As the numerical
example in Appendix A shows, at large batch size, the discrete-time nature of SGD is the leading
source of ﬂuctuation; at small batch size, the isotropic enhancement becomes the dominant source of
ﬂuctuation. Therefore, the minibatch sampling process causes two different kinds of enhancement to
the ﬂuctuation, potentially increasing the exploration power of SGD at initialization but reducing the
convergence speed."
RANDOM NOISE IN THE LABEL,0.059,"Now, combining Theorem 2 and Lemma 1, one can obtain an explicit form of the noise covariance."
RANDOM NOISE IN THE LABEL,0.06,Theorem 3. The noise covariance matrix of minibatch SGD with random noise in the label is
RANDOM NOISE IN THE LABEL,0.061,C = σ2
RANDOM NOISE IN THE LABEL,0.062,S A + σ2
RANDOM NOISE IN THE LABEL,0.063,S2 (1 + κµ
RANDOM NOISE IN THE LABEL,0.064,"S )(ΛAG−1
µ + Tr[ΛAG−1
µ ]ID)A.
(8)"
RANDOM NOISE IN THE LABEL,0.065,Published as a conference paper at ICLR 2022
RANDOM NOISE IN THE LABEL,0.066,"By deﬁnition, C = J is the FIM. The Hessian approximation, in sharp contrast, can only account
for the term in orange. A signiﬁcant modiﬁcation containing both anisotropic and isotropic (up
to Hessian) is required to fully understand SGD noise, even in this simple example. Additionally,
comparing this result with the training loss (127), one can ﬁnd that the noise covariance contains one
term that is proportional to the training loss. In fact, we will derive in Sec. 5 that containing a term
proportional to training loss is a general feature of the SGD noise. We also study the case when the
input is contaminated with noise. Interestingly, the result is the same with the label noise case with
σ2 replaced by a more complicated term of the form Tr[AK−1BU]. We thus omit this part from the
main text. A detailed discussion can be found in Appendix E.3.1. In the next section, we study the
effect of regularization on SGD noise and ﬂuctuation."
LEARNING WITH REGULARIZATION,0.067,"4.3
LEARNING WITH REGULARIZATION"
LEARNING WITH REGULARIZATION,0.068,"Now, we show that regularization also causes a unique SGD noise. The loss function for Γ −L2
regularized linear regression is"
LEARNING WITH REGULARIZATION,0.069,"LΓ(w) =
1
2N"
LEARNING WITH REGULARIZATION,0.07,"N
∑
i=1
[(w −u)Txi]
2 + 1"
LEARNING WITH REGULARIZATION,0.071,2wTΓw = 1
LEARNING WITH REGULARIZATION,0.072,2(w −u)TA(w −u) + 1
LEARNING WITH REGULARIZATION,0.073,"2wTΓw,
(9)"
LEARNING WITH REGULARIZATION,0.074,"where Γ is a symmetric matrix; conventionally, one set Γ = γID with a scalar γ > 0. For conciseness,
we assume that there is no noise in the label, namely yi = uTxi with a constant vector u. One
important quantity in this case will be uuT ∶= U. The noise for this form of regularization can be
calculated but takes a complicated form.
Proposition 3. (Noise covariance matrix for learning with L2 regularization) Let the algorithm be
updated according to Eq. (1) on loss function (9) with N →∞and [A,Γ] = 0. Then, C = 1"
LEARNING WITH REGULARIZATION,0.075,"S (AΣA + Tr[AΣ]A + Tr[Γ′TAΓ′U]A + ΓA′UA′Γ),
(10)"
LEARNING WITH REGULARIZATION,0.076,"where A′ ∶= K−1A, Γ′ ∶= K−1Γ with K ∶= A + Γ."
LEARNING WITH REGULARIZATION,0.077,"Notice that the last term ΓA′UA′Γ in C is unique to the regularization-based noise: it is rank-1
because U is rank-1. This term is due to the mismatch between the regularization and the minimum of
the original loss. Also, note that the term Tr[AΣ] is proportional to the training loss. Deﬁne the test
loss to be Ltest ∶= limt→∞Ewt[ 1"
LEARNING WITH REGULARIZATION,0.078,"2(wt −u)TA(wt −u)], we can prove the following theorem. We
will show that one intriguing feature of discrete-time SGD is that the weight decay can be negative.
Theorem 4. (Test loss and model ﬂuctuation for L2 regularization) Let the assumptions be the same
as in Proposition 3. Then"
LEARNING WITH REGULARIZATION,0.079,Ltest = λ
LEARNING WITH REGULARIZATION,0.08,2S (Tr[AK−2Γ2U]κ + r) + 1
LEARNING WITH REGULARIZATION,0.081,"2Tr[AK−2Γ2U],
(11)"
LEARNING WITH REGULARIZATION,0.082,"where κ ∶=
Tr[A2K−1G−1]
1−λ"
LEARNING WITH REGULARIZATION,0.083,"S Tr[A2K−1G−1], r ∶= Tr[A3K−3Γ2G−1U] 1−λ"
LEARNING WITH REGULARIZATION,0.084,"S Tr[A2K−1G−1], with G ∶= 2ID −λ(K + 1"
LEARNING WITH REGULARIZATION,0.085,"S K−1A2). Moreover,"
LEARNING WITH REGULARIZATION,0.086,"let [Γ,U] = 0, then Σ = λ"
LEARNING WITH REGULARIZATION,0.087,S Tr[AK−2Γ2U](1 + λκ
LEARNING WITH REGULARIZATION,0.088,S )AK−1G−1 + λ
LEARNING WITH REGULARIZATION,0.089,S (A2K−2Γ2U + λr
LEARNING WITH REGULARIZATION,0.09,"S A)K−1G−1.
(12)"
LEARNING WITH REGULARIZATION,0.091,"This result is numerically validated in Appendix A. The test loss (11) has an interesting consequence.
One can show that there exist situations where the optimal Γ is negative.2 When discussing the test
loss, we make the convention that if wt diverges, then Ltest = ∞.
Corollary 1. Let γ∗= arg minγ Ltest. There exist a, λ and S such that γ∗< 0."
LEARNING WITH REGULARIZATION,0.092,"The proof shows that when the learning rate is sufﬁciently large, only negative weight decay is
allowed. This agrees with the argument in Liu et al. (2021) that discrete-time SGD introduces an
implicit L2 regularization that favors small norm solutions. A too-large learning rate requires a
negative weight decay because a large learning rate already over-regularizes the model and one needs"
LEARNING WITH REGULARIZATION,0.093,"2Some readers might argue that discussing test loss is meaningless when N →∞; however, this criticism
does not apply because the size of the training set is not the only factor that affects generalization. In fact, this
section’s crucial message is that using a large learning rate affects the generalization by implicitly regularizing
the model and, if one over-regularizes, one needs to offset this effect."
LEARNING WITH REGULARIZATION,0.094,Published as a conference paper at ICLR 2022
LEARNING WITH REGULARIZATION,0.095,"to introduce an explicit negative weight decay to offset this over-regularization effect of SGD. This is
a piece of direct evidence that using a large learning rate can help regularize the models. It has been
hypothesized that the dynamics of SGD implicitly regularizes neural networks such that the training
favors simpler solutions (Kalimeris et al., 2019). Our result suggests one new mechanism for such a
regularization."
NOISE STRUCTURE FOR GENERIC SETTINGS,0.096,"5
NOISE STRUCTURE FOR GENERIC SETTINGS"
NOISE STRUCTURE FOR GENERIC SETTINGS,0.097,"The results in the previous sections suggest that (1) the SGD noises differ for different kinds of
situations, and (2) SGD noise contains a term proportional to the training loss in general. These two
facts motivate us to derive the noise covariance differently for different kinds of minima. Let f(w,x)
denote the output of the model for a given input x ∈RD. Here, we consider a more general case;
f(w,x) may be any differentiable function, e.g., a non-linear deep neural network. The number of
parameters in the model is denoted by P, and hence w ∈RP . For a training dataset {xi,yi}i=1,2,...,N,
the loss function with a L2 regularization is given by"
NOISE STRUCTURE FOR GENERIC SETTINGS,0.098,LΓ(w) = L0(w) + 1
NOISE STRUCTURE FOR GENERIC SETTINGS,0.099,"2wTΓw,
(13)"
NOISE STRUCTURE FOR GENERIC SETTINGS,0.1,"where L0(w) =
1
N ∑N
i=1 ℓ(f(w,xi),yi) is the loss function without regularization, and H0 is the
Hessian of L0. We focus on the MSE loss ℓ(f(w,xi),yi) = [f(w,xi) −yi]2/2. Our result crucially
relies on the following two assumptions, which relate to the conditions of different kinds of local
minima.
Assumption 1. (Fluctuation decays with batch size) Σ is proportional to S−1, i.e. Σ = O(S−1)."
NOISE STRUCTURE FOR GENERIC SETTINGS,0.101,"This is justiﬁed by the results in all the related works (Liu et al., 2021; Xie et al., 2021; Meng et al.,
2020; Mori et al., 2021), where Σ is found to be O(S−1).
Assumption 2. (Weak homogeneity) ∣L −ℓi∣is small; in particular, it is of order o(L)."
NOISE STRUCTURE FOR GENERIC SETTINGS,0.102,"This assumption amounts to assuming that the current training loss L reﬂects the actual level of
approximation for each data point well. In fact, since L ≥0, one can easily show that ∣L −ℓi∣= O(L).
Here, we require a slightly stronger condition for a more clean expression, when ∣L −ℓi∣= O(L)
we can still get a similar expression but with some constant that hinders the clarity. Relaxing this
condition can be an important and interesting future work. The above two conditions allow us to state
our general theorem formally.
Theorem 5. Let the training loss be LΓ = L0 + 1"
NOISE STRUCTURE FOR GENERIC SETTINGS,0.103,"2wTΓw and the models be optimized with SGD in
the neighborhood of a local minimum w∗. Then,"
NOISE STRUCTURE FOR GENERIC SETTINGS,0.104,C(w) = 2L0(w)
NOISE STRUCTURE FOR GENERIC SETTINGS,0.105,"S
H0(w) −1"
NOISE STRUCTURE FOR GENERIC SETTINGS,0.106,"S ∇LΓ(w)∇LΓ(w)T + o(L0).
(14)"
NOISE STRUCTURE FOR GENERIC SETTINGS,0.107,"The noise takes different forms for different kinds of local minima.
Corollary 2. Omitting the terms of order o(L0), when Γ ≠0,"
NOISE STRUCTURE FOR GENERIC SETTINGS,0.108,C = 2L0(w∗)
NOISE STRUCTURE FOR GENERIC SETTINGS,0.109,"S
H0(w∗) −1"
NOISE STRUCTURE FOR GENERIC SETTINGS,0.11,"S Γw∗w∗TΓ + O(S−2) + O(∣w −w∗∣2).
(15)"
NOISE STRUCTURE FOR GENERIC SETTINGS,0.111,"When Γ = 0 and L0(w∗) ≠0,"
NOISE STRUCTURE FOR GENERIC SETTINGS,0.112,C = 2L0(w∗)
NOISE STRUCTURE FOR GENERIC SETTINGS,0.113,"S
H0(w∗) + O(S−2) + O(∣w −w∗∣2).
(16)"
NOISE STRUCTURE FOR GENERIC SETTINGS,0.114,"When Γ = 0 and L0(w∗) = 0, C = 1"
NOISE STRUCTURE FOR GENERIC SETTINGS,0.115,"S (Tr[H0(w∗)Σ]ID −H0(w∗)Σ)H0(w∗) + O(S−2) + O(∣w −w∗∣2).
(17)"
NOISE STRUCTURE FOR GENERIC SETTINGS,0.116,"Remark. Assumption 2 can be replaced by a weaker but more technical assumption called the
“decoupling assumption"", which has been used in recent works to derive the continuous-time distri-
bution of SGD (Mori et al., 2021; Wojtowytsch, 2021). The Hessian approximation was invoked in
most of the literature without considering the conditions of its applicability (Jastrzebski et al., 2018;
Zhu et al., 2019; Liu et al., 2021; Wu et al., 2020; Xie et al., 2021). Our result does provide such"
NOISE STRUCTURE FOR GENERIC SETTINGS,0.117,Published as a conference paper at ICLR 2022
NOISE STRUCTURE FOR GENERIC SETTINGS,0.118,"conditions for applicability. As indicated by the two assumptions, this theorem is applicable when
the batch size is not too small and when the local minimum has a loss close to 0. The reason for
the failure of the Hessian approximation is that, while the FIM is equal to the expected Hessian
J = E[H], there is no reason to expect the expected Hessian to be close to the actual Hessian of the
minimum."
NOISE STRUCTURE FOR GENERIC SETTINGS,0.119,"The proof is given in Appendix C. Two crucial messages this corollary delivers are (1) the SGD
noise is different in strength and shape in different kinds of local minima and that they need to be
analyzed differently; (2) the SGD noise contains a term that is proportional to the training loss L0 in
general. Recently, it has been experimentally demonstrated that the SGD noise is indeed proportional
to the training loss in realistic deep neural network settings, both when the loss function is MSE
and cross-entropy (Mori et al., 2021); our result offers a theoretical justiﬁcation. The previous
works all treat all the minima as if the noise is similar (Jastrzebski et al., 2018; Zhu et al., 2019;
Liu et al., 2021; Wu et al., 2020; Xie et al., 2021), which can lead to inaccurate or even incorrect
understanding. For example, Theorem 3.2 in Xie et al. (2021) predicts a high escape probability from
a sharp local or global minimum. However, this is incorrect because a model at a global minimum has
zero probability of escaping due to a vanishing gradient. In contrast, the escape rate results derived
in Mori et al. (2021) correctly differentiate the local and global minima. We also note that these
general formulae are consistent with the exact solutions we obtained in the previous section than the
Hessian approximation. For example, the dependence of the noise strength on the training loss in
Theorem 2, and the rank-1 noise of regularization are all reﬂected in these formulae. In contrast, the
simple Hessian approximation misses these crucial distinctions. Lastly, combining Theorem 5 with
Theorem 1, one can also ﬁnd the ﬂuctuation.
Corollary 3. Let the noise be as in Theorem 5, and omit the terms of order O(S−2) and
O(∣w −w∗∣2). Then, when Γ ≠0 and when Λ, H0(w∗) and Γ commute with each other, Pr′Σ ="
S,0.12,"1
S
Λ
1−µ(2L0H0 −Γw∗w∗TΓ)(H0 + Γ)+ [2ID −
Λ
1+µ(H0 + Γ)]
−1
. When Γ = 0 and L0(w∗) ≠0,"
S,0.121,"PrΣ =
2L0
S(1−µ)PrΛ(2ID −
Λ
1+µH0)
−1
. When Γ = 0 and L0(w∗) = 0, PrΣ = 0. Here the superscript
+ is the Moore-Penrose pseudo inverse, Pr ∶= diag(1,...,1,0,...,0) is the projection operator with
r non-zero entries, r ≤D is the rank of the Hessian H0, and r′ ≤D is the rank of H0 + Γ. For the
null space H0, Σ can be arbitrary."
APPLICATIONS,0.122,"6
APPLICATIONS"
APPLICATIONS,0.123,"One major advantage of analytical solutions is that they can be applied in a simple “plug-in"" manner
by the practitioners or theorists to analyze new problems they encounter. In this section, we brieﬂy
outline a few examples where the proposed theories can be relevant."
HIGH-DIMENSIONAL REGRESSION,0.124,"6.1
HIGH-DIMENSIONAL REGRESSION"
HIGH-DIMENSIONAL REGRESSION,0.125,"We ﬁrst apply our result to the high-dimensional regression problem and show how over-and-
underparametrization might play a role in determining the minibatch noise. Here, we take N,D →∞
with the ratio α ∶= N/D held ﬁxed. The loss function is L(w) =
1
2N ∑N
i=1 (wTxi −yi)
2. As in the
standard literature (Hastie et al., 2019), we assume the existence of label noise: yi = uTxi + ϵi, with
Var[ϵi] = σ2. A key difference between our setting and the standard high-dimensional setting is
that, in the standard setting (Hastie et al., 2019), one uses the GD algorithm with vanishing learning
rate λ instead of the minibatch SGD algorithm with a non-vanishing learning rate. Tackling the
high-dimensional regression problem with non-vanishing λ and a minibatch noise is another main
technical contribution of this work. In this setting, we can obtain the following result on the noise
covariance matrix.
Proposition 4. Let ˆA = 1"
HIGH-DIMENSIONAL REGRESSION,0.126,"N ∑N
i xixT
i and suppose assumptions 1 and 2 hold. With ﬁxed S, λ, then C = 1"
HIGH-DIMENSIONAL REGRESSION,0.127,"S (Tr[ ˆAΣ]ID −ˆAΣ) ˆA + max{0, σ2"
HIGH-DIMENSIONAL REGRESSION,0.128,S (1 −1
HIGH-DIMENSIONAL REGRESSION,0.129,α)} ˆA.
HIGH-DIMENSIONAL REGRESSION,0.13,"We note that this proposition follows from Theorem 5, showing an important theoretical application
of our general theory. An interesting observation is that one Σ-independent term proportional to σ2
emerges in the underparametrized regime (α > 1). However, for the overparametrized regime, the
noise is completely dependent on Σ, which is a sign that the stationary solution has no ﬂuctuation.
This shows that the degree of underparametrization also plays a distinctive role in the ﬂuctuation. In
fact, one can prove the following theorem, which is veriﬁed in Appendix A.2."
HIGH-DIMENSIONAL REGRESSION,0.131,Published as a conference paper at ICLR 2022
HIGH-DIMENSIONAL REGRESSION,0.132,"Figure 1: Realistic learning settings with neural networks and logistic regression. Left: Variance of training loss
of a neural network with width d and tanh activation on the MNIST dataset. We see that the variance explodes
after d ≥200. In contrast, rescaling the learning rate by 1/d results in a constant noise level in training. This
suggests that the stability condition we derived for high-dimension regression is also useful for understanding
deep learning. Middle: Stability of Adam with the same setting. Adam also experiences a similar stability
problem when the model width increases. Right: Logistic regression on MNIST trained with SGD; with λ = 1.5,
S = 32. We see that the optimal performance is also achieved at negative weight decay strength γ, suggesting
that a large learning rate can indeed introduce effective regularization."
HIGH-DIMENSIONAL REGRESSION,0.133,"Theorem 6. When a stationary solution exists for w, we have Tr[ ˆAΣ] = max{0, λσ2"
HIGH-DIMENSIONAL REGRESSION,0.134,S (1 −1
HIGH-DIMENSIONAL REGRESSION,0.135,"α) ˆκ},"
HIGH-DIMENSIONAL REGRESSION,0.136,"where ˆκ ∶=
Tr[ ˆ
G−1 ˆ
A]
1−λ"
HIGH-DIMENSIONAL REGRESSION,0.137,"S Tr[ ˆ
G−1 ˆ
A] with ˆG ∶= 2ID −λ(1 −1"
HIGH-DIMENSIONAL REGRESSION,0.138,S ) ˆA.
IMPLICATION FOR NEURAL NETWORK TRAINING,0.139,"6.2
IMPLICATION FOR NEURAL NETWORK TRAINING"
IMPLICATION FOR NEURAL NETWORK TRAINING,0.14,"It is commonly believed that the high-dimensional linear regression problem can be a minimal model
for deep learning. Taking this stance, Theorem 6 suggests a technique for training neural networks.
For SGD to converge, a positive semi-deﬁnite Σ must exist; however, Σ ≥0 if and only if ˆκ ≥0.
From ˆκ > 0, we have ∑D
i=1
1
2/λai−1+1/S < S, where ai are the eigenvalues of ˆA. This means that each
summand should have the order of D/S. Thus the upper bound of λ should have the order of 2S/aD,
where a is the typical value of ai’s. One implication of the dependence on the dimension is that the
stability of a neural network trained with SGD may strongly depend on its width d, and one may
rescale the learning rate according to the width to stabilize neural network training. See Figure 1-Left
and Middle. We train a two-layer tanh neural network on MNIST and plot the variance of its training
loss in the ﬁrst epoch with ﬁxed λ = 0.5. We see that, when d ≥200, the training starts to destabilize,
and the training loss begins to ﬂuctuate dramatically. When rescaling the learning rate by 1/d, we see
that the variance of the training loss is successfully kept roughly constant across all d. This suggests
a training technique worth being explored by practitioners in the ﬁeld. In Figure 1-Middle, we also
use Adam for training the same network and ﬁnd a similar stabilizing trick to work for Adam."
A NATURAL LEARNING EXAMPLE WITH NEGATIVE WEIGHT DECAY,0.141,"6.3
A NATURAL LEARNING EXAMPLE WITH NEGATIVE WEIGHT DECAY
Sec. 4.3 shows that a too-large learning rate introduces an effective L2 regularization that can be
corrected by setting the weight decay to be negative. This effect can be observed in more realistic
learning settings. We train a logistic regressor on the MNIST dataset with a large learning rate (of
order O(1)). Figure 1-Right conﬁrms that, at a large learning rate, the optimal weight decay can
indeed be negative. This agrees with our argument that using a large learning rate can effectively
regularize the training."
SECOND-ORDER METHODS,0.142,"6.4
SECOND-ORDER METHODS
Understanding stochastic second-order methods (including the adaptive gradient methods) is also
important for deep learning (Agarwal et al., 2017; Zhang and Liu, 2021; Martens, 2014; Kunstner
et al., 2019). In this section, we apply our theory to two standard second-order methods: damped
Newton’s method (DNM) and natural gradient descent (NGD). We provide more accurate results
than those derived in Liu et al. (2021). The derivations are given in Appendix D.2. For DNM, the
preconditioning learning rate matrix is deﬁned as Λ ∶= λA−1. The model ﬂuctuation is shown to
be proportional to the inverse of the Hessian: Σ =
λσ2"
SECOND-ORDER METHODS,0.143,"gS−λDA−1, where g ∶= 2(1 −µ) −( 1−µ"
SECOND-ORDER METHODS,0.144,1+µ + 1
SECOND-ORDER METHODS,0.145,"S )λ.
The main difference with the previous results is that the ﬂuctuation now depends explicitly on the
dimension D, and implies a stability condition: S ≥λD/g, corroborating the stability condition
we derived above. For NGD, the preconditioning matrix is deﬁned by the inverse of the Fisher
information that Λ ∶=
λ
S J(w)−1 =
λ
S C−1. We show that Σ = λ"
SECOND-ORDER METHODS,0.146,"2 (
1
1+D
1
1+µ +
1
1−µ
1
S )A−1 is one
solution when σ = 0, which also contains a correction related to D compared to the result in Liu
et al. (2021) which is Σ = λ"
SECOND-ORDER METHODS,0.147,"2 (
1
1+µ +
1
1−µ
1
S )A−1. A consequence is that J ∼Σ−1. The surprising"
SECOND-ORDER METHODS,0.148,Published as a conference paper at ICLR 2022
SECOND-ORDER METHODS,0.149,"fact is that the stability of both NGD and DNM now crucially depends on D; combining with the
results in Sec. 6.1, this suggests that the dimension of the problem may crucially affect the stability
and performance of the minibatch-based algorithms. This result also implies that some features we
derived are shared across many algorithms that depend on minibatch noise and that our results may
be relevant to a broad class of optimization algorithms other than SGD."
SECOND-ORDER METHODS,0.15,"6.5
FAILURE OF THE λ −S SCALING LAW
One well-known technique in deep learning training is that one can scale λ linearly as one increases
the batch size S to achieve high-efﬁciency training without hindering the generalization performance;
however, it is known that this scaling law fails when the learning rate is too large, or the batch size is
too small (Goyal et al., 2017). In Hoffer et al. (2017), this scaling law is established on the ground
that Σ ∼λ/S. However, our result in Theorem 2 suggests the reason for the failure even for the
simple setting of linear regression. Recall that the exact Σ takes the form:"
SECOND-ORDER METHODS,0.151,Σ = λσ2
SECOND-ORDER METHODS,0.152,"S
(1 + κµ"
SECOND-ORDER METHODS,0.153,"S )G−1
µ"
SECOND-ORDER METHODS,0.154,"for a scalar λ. One notices that the leading term is indeed proportional to λ/S. However, the
discrete-time SGD results in a second-order correction in S, and the term proportional to 1/S2 does
not contain a corresponding λ; this explains the failure of the scaling law in small S, where the
second-order contribution of S becomes signiﬁcant. To understand the failure at large λ, we need to
look at the term Gµ:"
SECOND-ORDER METHODS,0.155,Gµ = 2(1 −µ)ID −(λ1 −µ
SECOND-ORDER METHODS,0.156,1 + µ + λ S )A.
SECOND-ORDER METHODS,0.157,"One notices that the second term contains a part that only depends on λ but not on S. This part is
negligible compared to the ﬁrst term when λ is small; however, it becomes signiﬁcant as the second
term approaches the ﬁrst term. Therefore, increasing λ changes this part of the ﬂuctuation, and the
scaling law no more holds if λ is large."
POWER LAW TAIL IN DISCRETE-TIME SGD,0.158,"6.6
POWER LAW TAIL IN DISCRETE-TIME SGD"
POWER LAW TAIL IN DISCRETE-TIME SGD,0.159,"Figure 2: Comparison of the pro-
posed theory with the continuous-
time theory on the SGD station-
ary distribution for aλ = 1. The
proposed theory agrees with the
experiment exactly."
POWER LAW TAIL IN DISCRETE-TIME SGD,0.16,"It has recently been discovered that the SGD noise causes a heavy-
tail distribution (Simsekli et al., 2019; 2020), with a tail decaying
like a power law with tail index β (Hodgkinson and Mahoney,
2020). In continuous-time, the stationary distribution has been
found to obey a Student’s t-like distribution, p(w) ∼L−(1+β)/2 ∼"
POWER LAW TAIL IN DISCRETE-TIME SGD,0.161,"(σ2 + aw2)
−(1+β)/2 (Meng et al., 2020; Mori et al., 2021; Wo-
jtowytsch, 2021).
However, this result is only established for
continuous-time approximations to SGD and one does not know
what affects the exponent β for discrete-time SGD. Our result in
Theorem 2 can serve as a tool to ﬁnd the discrete-time correction
to the tail index of the stationary distribution. In Appendix D.3, we
show that the tail index of discrete-time SGD in 1d can be estimated
as β(λ,S) = 2S"
POWER LAW TAIL IN DISCRETE-TIME SGD,0.162,"aλ −S. A clear discrete-time contribution is −(S + 1)
which depends only on the batch size, while 2S"
POWER LAW TAIL IN DISCRETE-TIME SGD,0.163,"aλ +1 is the tail index in the continuous-time limit (Mori
et al., 2021). See Figure 2; the proposed formula agrees with the experiment. Knowing the tail index
β is important for understanding the SGD dynamics because β is equal to the smallest moment of
w that diverges. For example, when β ≤4, then the kurtosis of w diverges, and one expects to see
outliers of w very often during training; when β ≤2, then the second moment of w diverges, and
one does not expect w to converge in the minimum under consideration. Our result suggests that the
discrete-time dynamics always leads to a heavier tail than the continuous-time theory expects, and
therefore is more unstable."
OUTLOOK,0.164,"7
OUTLOOK"
OUTLOOK,0.165,"In this work, we have presented a systematic analysis with a focus on exactly solvable results to
promote our fundamental understanding of SGD. One major limitation is that we have only focused
on studying the asymptotic behavior of SGD in local minimum. For example, Ziyin et al. (2022)
showed that SGD can converge to a local maximum when the learning rate is large. One important
future step is thus to understand the SGD noise beyond a strongly convex landscape."
OUTLOOK,0.166,Published as a conference paper at ICLR 2022
OUTLOOK,0.167,ACKNOWLEDGEMENT
OUTLOOK,0.168,"Liu Ziyin thanks Jie Zhang, Junxia Wang, and Shoki Sugimoto. Ziyin is supported by the GSS
Scholarship of The University of Tokyo. Kangqiao Liu was supported by the GSGC program of
the University of Tokyo. This work was supported by KAKENHI Grant Numbers JP18H01145 and
JP21H05185 from the Japan Society for the Promotion of Science."
REFERENCES,0.169,REFERENCES
REFERENCES,0.17,"Agarwal, N., Bullins, B., and Hazan, E. (2017). Second-order stochastic optimization for machine
learning in linear time. The Journal of Machine Learning Research, 18(1):4148–4187."
REFERENCES,0.171,"Allen-Zhu, Z., Li, Y., and Song, Z. (2019). A convergence theory for deep learning via over-
parameterization. In International Conference on Machine Learning, pages 242–252. PMLR."
REFERENCES,0.172,"Amari, S.-I. (1998). Natural gradient works efﬁciently in learning. Neural Comput., 10(2):251–276."
REFERENCES,0.173,"Blanc, G., Gupta, N., Valiant, G., and Valiant, P. (2020). Implicit regularization for deep neural
networks driven by an ornstein-uhlenbeck like process. In Conference on learning theory, pages
483–513. PMLR."
REFERENCES,0.174,"Chizat, L. and Bach, F. (2018). A note on lazy training in supervised differentiable programming.
arXiv preprint arXiv:1812.07956, 8."
REFERENCES,0.175,"Clauset, A., Shalizi, C. R., and Newman, M. E. (2009). Power-law distributions in empirical data.
SIAM review, 51(4):661–703."
REFERENCES,0.176,"Dieuleveut, A., Durmus, A., Bach, F., et al. (2020). Bridging the gap between constant step size
stochastic gradient descent and markov chains. Annals of Statistics, 48(3):1348–1382."
REFERENCES,0.177,"Fontaine, X., Bortoli, V. D., and Durmus, A. (2021). Convergence rates and approximation results
for sgd and its continuous-time counterpart."
REFERENCES,0.178,"Gal, Y. and Ghahramani, Z. (2016). Dropout as a bayesian approximation: Representing model
uncertainty in deep learning. In international conference on machine learning, pages 1050–1059.
PMLR."
REFERENCES,0.179,"Gitman, I., Lang, H., Zhang, P., and Xiao, L. (2019). Understanding the role of momentum in
stochastic gradient methods. In Advances in Neural Information Processing Systems, pages
9633–9643."
REFERENCES,0.18,"Goyal, P., Dollár, P., Girshick, R., Noordhuis, P., Wesolowski, L., Kyrola, A., Tulloch, A., Jia, Y.,
and He, K. (2017). Accurate, large minibatch sgd: Training imagenet in 1 hour. arXiv preprint
arXiv:1706.02677."
REFERENCES,0.181,"Hammarling, S. J. (1982). Numerical solution of the stable, non-negative deﬁnite lyapunov equation
lyapunov equation. IMA Journal of Numerical Analysis, 2(3):303–323."
REFERENCES,0.182,"HaoChen, J. Z., Wei, C., Lee, J. D., and Ma, T. (2020). Shape matters: Understanding the implicit
bias of the noise covariance. arXiv preprint arXiv:2006.08680."
REFERENCES,0.183,"Hastie, T., Montanari, A., Rosset, S., and Tibshirani, R. J. (2019). Surprises in high-dimensional
ridgeless least squares interpolation. arXiv preprint arXiv:1903.08560."
REFERENCES,0.184,"He, F. and Tao, D. (2020). Recent advances in deep learning theory. arXiv preprint arXiv:2012.10931."
REFERENCES,0.185,"Hodgkinson, L. and Mahoney, M. W. (2020). Multiplicative noise and heavy tails in stochastic
optimization. arXiv preprint arXiv:2006.06293."
REFERENCES,0.186,"Hoffer, E., Hubara, I., and Soudry, D. (2017). Train longer, generalize better: closing the generaliza-
tion gap in large batch training of neural networks. In Advances in Neural Information Processing
Systems, pages 1731–1741."
REFERENCES,0.187,Published as a conference paper at ICLR 2022
REFERENCES,0.188,"Janssen, P. H. M. and Stoica, P. (1988). On the expectation of the product of four matrix-valued
gaussian random variables. IEEE Transactions on Automatic Control, 33(9):867–870."
REFERENCES,0.189,"Jastrzebski, S., Kenton, Z., Arpit, D., Ballas, N., Fischer, A., Storkey, A., and Bengio, Y. (2018).
Three factors inﬂuencing minima in SGD."
REFERENCES,0.19,"Kalimeris, D., Kaplun, G., Nakkiran, P., Edelman, B., Yang, T., Barak, B., and Zhang, H. (2019). Sgd
on neural networks learns functions of increasing complexity. Advances in Neural Information
Processing Systems, 32:3496–3506."
REFERENCES,0.191,"Kunin, D., Sagastuy-Brena, J., Gillespie, L., Margalit, E., Tanaka, H., Ganguli, S., and Yamins, D. L.
(2021). Rethinking the limiting dynamics of sgd: modiﬁed loss, phase space oscillations, and
anomalous diffusion. arXiv preprint arXiv:2107.09133."
REFERENCES,0.192,"Kunstner, F., Balles, L., and Hennig, P. (2019). Limitations of the empirical ﬁsher approximation for
natural gradient descent. arXiv preprint arXiv:1905.12558."
REFERENCES,0.193,"Levy, M. and Solomon, S. (1996). Power laws are logarithmic boltzmann laws. International Journal
of Modern Physics C, 7(04):595–601."
REFERENCES,0.194,"Lewkowycz, A., Bahri, Y., Dyer, E., Sohl-Dickstein, J., and Gur-Ari, G. (2020). The large learning
rate phase of deep learning: the catapult mechanism. arXiv preprint arXiv:2003.02218."
REFERENCES,0.195,"Liu, K., Ziyin, L., and Ueda, M. (2021). Noise and ﬂuctuation of ﬁnite learning rate stochastic
gradient descent. arXiv preprint arXiv:2012.03636."
REFERENCES,0.196,"Lyapunov, A. M. (1992). The general problem of the stability of motion. International journal of
control, 55(3):531–534."
REFERENCES,0.197,"Mandt, S., Hoffman, M. D., and Blei, D. M. (2017). Stochastic gradient descent as approximate
bayesian inference. J. Mach. Learn. Res., 18(1):4873–4907."
REFERENCES,0.198,"Martens, J. (2014).
New insights and perspectives on the natural gradient method.
cite
arxiv:1412.1193Comment: New title and abstract. Added multiple sections, including a proper
introduction/outline and one on convergence speed. Many other revisions throughout."
REFERENCES,0.199,"Meng, Q., Gong, S., Chen, W., Ma, Z.-M., and Liu, T.-Y. (2020). Dynamic of stochastic gradient
descent with state-dependent noise. arXiv preprint arXiv:2006.13719."
REFERENCES,0.2,"Mori, T., Ziyin, L., Liu, K., and Ueda, M. (2021). Logarithmic landscape and power-law escape rate
of sgd. arXiv preprint arXiv:2105.09557."
REFERENCES,0.201,"Pearce, T., Leibfried, F., and Brintrup, A. (2020). Uncertainty in neural networks: Approximately
bayesian ensembling. In International conference on artiﬁcial intelligence and statistics, pages
234–244. PMLR."
REFERENCES,0.202,"Sato, I. and Nakagawa, H. (2014). Approximation analysis of stochastic gradient langevin dynamics
by using fokker-planck equation and ito process. In International Conference on Machine Learning,
pages 982–990. PMLR."
REFERENCES,0.203,"Simoncini, V. (2016). Computational methods for linear matrix equations. SIAM Review, 58(3):377–
441."
REFERENCES,0.204,"Simsekli, U., Sagun, L., and Gurbuzbalaban, M. (2019). A tail-index analysis of stochastic gradient
noise in deep neural networks. In International Conference on Machine Learning, pages 5827–
5837. PMLR."
REFERENCES,0.205,"Simsekli, U., Sener, O., Deligiannidis, G., and Erdogdu, M. A. (2020). Hausdorff dimension, heavy
tails, and generalization in neural networks. Advances in Neural Information Processing Systems,
33."
REFERENCES,0.206,"Thomas, V., Pedregosa, F., Merriënboer, B., Manzagol, P.-A., Bengio, Y., and Le Roux, N. (2020).
On the interplay between noise and curvature and its effect on optimization and generalization. In
International Conference on Artiﬁcial Intelligence and Statistics, pages 3503–3513. PMLR."
REFERENCES,0.207,Published as a conference paper at ICLR 2022
REFERENCES,0.208,"Toulis, P., Airoldi, E. M., et al. (2017). Asymptotic and ﬁnite-sample properties of estimators based
on stochastic gradients. Annals of Statistics, 45(4):1694–1727."
REFERENCES,0.209,"Wang, X., Zhao, Y., and Pourpanah, F. (2020). Recent advances in deep learning. International
Journal of Machine Learning and Cybernetics, 11(4):747–750."
REFERENCES,0.21,"Welling, M. and Teh, Y. W. (2011). Bayesian learning via stochastic gradient langevin dynamics. In
Proceedings of the 28th international conference on machine learning (ICML-11), pages 681–688.
Citeseer."
REFERENCES,0.211,"Wojtowytsch, S. (2021). Stochastic gradient descent with noise of machine learning type. part ii:
Continuous time analysis. arXiv preprint arXiv:2106.02588."
REFERENCES,0.212,"Wu, J., Hu, W., Xiong, H., Huan, J., Braverman, V., and Zhu, Z. (2020). On the noisy gradient descent
that generalizes as sgd. In International Conference on Machine Learning, pages 10367–10376.
PMLR."
REFERENCES,0.213,"Xie, Z., Sato, I., and Sugiyama, M. (2021). A diffusion theory for deep learning dynamics: Stochastic
gradient descent exponentially favors ﬂat minima. In International Conference on Learning
Representations."
REFERENCES,0.214,"Xing, C., Arpit, D., Tsirigotis, C., and Bengio, Y. (2018).
A walk with sgd.
arXiv preprint
arXiv:1802.08770."
REFERENCES,0.215,"Yaida, S. (2019). Fluctuation-dissipation relations for stochastic gradient descent. In International
Conference on Learning Representations."
REFERENCES,0.216,"Ye, H., Michel, A. N., and Hou, L. (1998). Stability theory for hybrid dynamical systems. IEEE
transactions on automatic control, 43(4):461–474."
REFERENCES,0.217,"Zhang, C., Liao, Q., Rakhlin, A., Miranda, B., Golowich, N., and Poggio, T. (2018). Theory of deep
learning iib: Optimization properties of sgd. arXiv preprint arXiv:1801.02254."
REFERENCES,0.218,"Zhang, Z. and Liu, Z. (2021). On the distributional properties of adaptive gradients. In Uncertainty
in Artiﬁcial Intelligence, pages 419–429. PMLR."
REFERENCES,0.219,"Zhu, Z., Wu, J., Yu, B., Wu, L., and Ma, J. (2019). The anisotropic noise in stochastic gradient
descent: Its behavior of escaping from sharp minima and regularization effects. In International
Conference on Machine Learning, pages 7654–7663. PMLR."
REFERENCES,0.22,"Ziyin, L., Li, B., Simon, J. B., and Ueda, M. (2022). SGD can converge to local maxima. In
International Conference on Learning Representations."
REFERENCES,0.221,Published as a conference paper at ICLR 2022
REFERENCES,0.222,"Figure 3: Left: 1d experiments with label noise. The parameters are set to be a = 1.5 and λ = 1.
Right: Experiments with L2 regularization with weight decay strength γ. The parameters are set to
be a = 1, λ = 0.5, S = 1. This is the standard case with a vanishing optimal γ. The vertical lines show
where our theory predicts a divergence."
REFERENCES,0.223,"(a) a = 1, S = 10
(b) S = 50
(c) S = 10"
REFERENCES,0.224,"Figure 4: Comparison between theoretical predictions and experiments. (a) 1d experiment. We plot
Σ as an increasing function of λ. We see that the continuous-time approximation fails to predict the
divergence at a learning rate and the prediction in Liu et al. (2021) severely underestimates the model
ﬂuctuation. In contrast, our result is accurate throughout the entire range of learning rates. (b)-(c) 2d
experiments. The straight line shows where the proposed theory predicts a divergence in the variance,
which agrees with experiment exactly. The Hessian has eigenvalues 1 and 0.5, and λ = 1.5. For a
large batch size, the discrete-time Hessian approximation is quite accurate; for a small S, the Hessian
approximation underestimates the overall strength of the ﬂuctuation. In contrast, the continuous-time
result is both inaccurate in shape and in strength."
REFERENCES,0.225,"A
EXPERIMENTS"
REFERENCES,0.226,"A.1
LABEL NOISE AND REGULARIZATION"
REFERENCES,0.227,"Theorem 2 can be veriﬁed empirically. We run 1d experiment in Figure 4(a) and high dimensional
experiments in Figures 4(b)-(c), where we choose D = 2 for visualization. We see that the continuous
Hessian approximation fails badly for both large and small batch sizes. When the batch size is
large, both the discrete-time Hessian approximation and our solution give a accurate estimate of the
shape and the spread of the distribution. This suggests that when the batch size is large, discreteness
is the determining factor of the ﬂuctuation. When the batch size is small, the discrete Hessian
approximation severely underestimates the strength of the noise. This reﬂects the fact that the
isotropic noise enhancement is dominant at a small batch size."
REFERENCES,0.228,"In Figure 3-Left, we run a 1d experiment with λ = 1, N = 10000 and σ2 = 0.25. Comparing the
predicted Σ, we see that the proposed theory agrees with the experiment across all ranges of S.
The continuous theory with the Hessian approximation fails almost everywhere, while the recently
proposed discrete theory with the Hessian approximation underestimates the ﬂuctuation when S
is small. In Figure 3-Right, we plot a standard case where the optimal regularization strength γ is
vanishing."
REFERENCES,0.229,"Now, we validate the existence of the optimal negative weight decay as predicted by our formula. For
illustration, we plot in Figure 5 the test loss (11) for a 1d example while varying either S or λ. The
orange vertical lines show the place where the theory predicts a divergence in the test loss. We also"
REFERENCES,0.23,Published as a conference paper at ICLR 2022
REFERENCES,0.231,"Figure 5: 1d experiments with L2 regularization with weight decay strength γ. The parameters are
set to be a = 4, λ = 1, S = 64. This shows a case where the optimal γ is negative. The vertical lines
show where our theory predicts a divergence."
REFERENCES,0.232,"Figure 6: High-dimensional linear regression. We see that the predicted ﬂuctuation coefﬁcient agrees
with the experiment well. The slight deviation is due to a ﬁnite training time and ﬁnite N and D. On
the other hand, a naive Hessian approximation results in a qualitatively wrong result."
REFERENCES,0.233,"plot a standard case where the optimal γ is close to 0 in Appendix A. Also, we note that the proposed
theory agrees better with the experiment."
REFERENCES,0.234,"A.2
HIGH-DIMENSIONAL REGRESSION"
REFERENCES,0.235,"See Figure 6-Left. We vary N with D = 1000 held ﬁxed. We set λ = 0.01 and S = 32. We see that
the agreement between the theory and experiment is good, even for this modest dimension number D.
The vertical line shows where the over-to-underparametrization transition takes place. As expected,
there is no ﬂuctuation when α < 1, and the ﬂuctuation gradually increases as α →∞. On the other
hand, the Hessian approximation gives a wrong picture, predicting ﬂuctuation to rise when there is
no ﬂuctuation and predicting a constant ﬂuctuation just when the ﬂuctuation starts to rise."
REFERENCES,0.236,Published as a conference paper at ICLR 2022
REFERENCES,0.237,"Table 2: Comparison with previous results. For notational conciseness, we compare the case when
all the relevant matrices commute. The model ﬂuctuation Σ, the expected training loss Ltrain
and the expected test loss Ltest calculated by continuous- and discrete-time theories with Hessian
approximation C ≈H are presented. Exact solutions to these quantities obtained in the present work
are shown in the rightmost column."
REFERENCES,0.238,"Hessian Approximation
Exact Solution"
REFERENCES,0.239,"Cts-time Approximation
D-time Solution
This Work Σ
Σ
Σ"
REFERENCES,0.24,"Label Noise
λ
2S ID
λ
S (2ID −λA)−1
λσ2"
REFERENCES,0.241,S (1 + λκ
REFERENCES,0.242,S ) [2ID −λ (1 + 1
REFERENCES,0.243,"S ) A]
−1"
REFERENCES,0.244,"Input Noise
λ
2S ID
λ
S (2ID −λK)−1
λTr[AK−1BU]"
REFERENCES,0.245,"S
(1 + λκ′"
REFERENCES,0.246,S ) [2ID −λ (1 + 1
REFERENCES,0.247,"S ) K]
−1"
REFERENCES,0.248,"L2 Regularization
λ
2S ID
λ
S (2ID −λK)−1
Eq. (12)"
REFERENCES,0.249,"Ltrain
Ltrain
Ltrain
Label Noise
λ
4S Tr[A] + 1"
REFERENCES,0.25,"2σ2
Eq. (20)
σ2"
REFERENCES,0.251,2 (1 + λκ S )
REFERENCES,0.252,"Input Noise
λ
4S Tr[K] + 1"
REFERENCES,0.253,"2Tr[AK−1BU]
Eq. (28)
1
2Tr[AK−1BU] (1 + λ S κ′)"
REFERENCES,0.254,"L2 Regularization
λ
4S Tr[K] + 1"
REFERENCES,0.255,"2Tr[AK−1ΓU]
Eq. (37)
Eq. (151)"
REFERENCES,0.256,"Ltest
Ltest
Ltest
Label Noise
λ
4S Tr[A]
λ
2S Tr[A(2ID −λA)−1]
λσ2 2S κ"
REFERENCES,0.257,"Input Noise
λ
4S Tr[A] + 1"
REFERENCES,0.258,"2Tr[B′TAB′U]
Eq. (29)
λ
2S Tr[AK−1BU]κ′ + 1"
REFERENCES,0.259,2Tr[B′TAB′U]
REFERENCES,0.26,"L2 Regularization
λ
4S Tr[A] + 1"
REFERENCES,0.261,"2Tr[AK−2Γ2U]
Eq. (38)
Eq. (11)"
REFERENCES,0.262,"B
COMPARISON WITH CONVENTIONAL HESSIAN APPROXIMATION"
REFERENCES,0.263,"We compare our results for the three cases with the results obtained with the conventional Hessian
approximation of the noise covariance, i.e., C ≈H, where H is the Hessian of the loss function. We
summarize the analytical results for a special case in Table 2."
REFERENCES,0.264,"B.1
LABEL NOISE"
REFERENCES,0.265,We ﬁrst consider discrete-time dynamics with the Hessian approximation. The matrix equation is
REFERENCES,0.266,ΣA + AΣ −λAΣA = λ
REFERENCES,0.267,"S A.
(18)"
REFERENCES,0.268,"Compared with the exact result (3), it is a large-S limit up to the constant σ2. This constant factor is
ignored during the approximation that J(w) ∶= EB[∇l∇lT] ≈EB[∇∇Tl] ∶= H(w), which is exact
only when l({xi},w) is a negative log likelihood function of w. Solving the matrix equation yields Σ = λ"
REFERENCES,0.269,"S (2ID −λA)−1.
(19)"
REFERENCES,0.27,The training loss and the test loss are
REFERENCES,0.271,Ltrain = λ
REFERENCES,0.272,2S Tr[A(2ID −λA)−1] + 1
REFERENCES,0.273,"2σ2,
(20)"
REFERENCES,0.274,Ltest = λ
REFERENCES,0.275,"2S Tr[A(2ID −λA)−1].
(21)"
REFERENCES,0.276,"On the other hand, by taking the large-S limit directly from the exact equation (3), the factor σ2 is
present:"
REFERENCES,0.277,ΣA + AΣ −λAΣA = λ
REFERENCES,0.278,"S σ2A.
(22)"
REFERENCES,0.279,"For the continuous-time limit with the Hessian approximation, the matrix equation is"
REFERENCES,0.28,ΣA + AΣ = λ
REFERENCES,0.281,"S A,
(23)"
REFERENCES,0.282,which is the small-λ limit up to the factor σ2. The variance is Σ = λ
REFERENCES,0.283,"2S ID.
(24)"
REFERENCES,0.284,Published as a conference paper at ICLR 2022
REFERENCES,0.285,The training and the test error are
REFERENCES,0.286,Ltrain = λ
REFERENCES,0.287,4S Tr[A] + 1
REFERENCES,0.288,"2σ2,
(25)"
REFERENCES,0.289,Ltest = λ
REFERENCES,0.29,"4S Tr[A].
(26)"
REFERENCES,0.291,"Again, taking the small-λ limit directly from the exact result (3) shows the presence of the factor σ2
on the right hand side of the matrix equation."
REFERENCES,0.292,"B.2
INPUT NOISE"
REFERENCES,0.293,"The case with the input noise is similar to the label noise. This can be understood if we replace
A by K and σ2 by Tr[AK−1BU]. The model parameter variance resulting from the discrete-time
dynamics under the Hessian approximation is Σ = λ"
REFERENCES,0.294,"S (2ID −λK)−1.
(27)"
REFERENCES,0.295,The training and the test error are
REFERENCES,0.296,Ltrain = λ
REFERENCES,0.297,2S Tr[K(2ID −λK)−1] + 1
REFERENCES,0.298,"2Tr[AK−1BU],
(28)"
REFERENCES,0.299,Ltest = λ
REFERENCES,0.3,2S Tr[A(2ID −λK)−1] + 1
REFERENCES,0.301,"2Tr[B′TAB′U].
(29)"
REFERENCES,0.302,"The large-S limit from the exact matrix equation (144) results in a prefactor Tr[AK−1BU] in the
ﬂuctuation: Σ = λ"
REFERENCES,0.303,"S Tr[AK−1BU](2ID −λK)−1.
(30)"
REFERENCES,0.304,"For the continuous-time limit, we take λ →0. The Hessian approximation gives Σ = λ"
REFERENCES,0.305,"2S ID,
(31)"
REFERENCES,0.306,Ltrain = λ
REFERENCES,0.307,4S Tr[K] + 1
REFERENCES,0.308,"2Tr[AK−1BU],
(32)"
REFERENCES,0.309,Ltest = λ
REFERENCES,0.31,4S Tr[A] + 1
REFERENCES,0.311,"2Tr[B′TAB′U].
(33)"
REFERENCES,0.312,The large-S limit again produces a prefactor Tr[AK−1BU].
REFERENCES,0.313,"B.3
L2 REGULARIZATION"
REFERENCES,0.314,"For learning with regularization, there is a more difference between the Hessian approximation and
the limit taken directly from the exact theory. We ﬁrst adopt the Hessian approximation for the
discrete-time dynamics. The matrix equation is"
REFERENCES,0.315,ΣK + KΣ −λKΣK = λ
REFERENCES,0.316,"S K,
(34)"
REFERENCES,0.317,"which is similar to the previous subsection. However, it is different from the large-S limit of the exact
matrix equation (154):"
REFERENCES,0.318,ΣK + KΣ −λKΣK = λ
REFERENCES,0.319,"S (Tr[AK−2Γ2U]A + AK−1ΓUΓK−1A).
(35)"
REFERENCES,0.32,"This signiﬁcant difference suggests that the conventional Fisher-to-Hessian approximation J ≈H
fails badly. The ﬂuctuation, the training loss, and the test loss with the Hessian approximation are Σ = λ"
REFERENCES,0.321,"S (2ID −λK)−1,
(36)"
REFERENCES,0.322,Ltrain = λ
REFERENCES,0.323,2S Tr[K(2ID −λK)−1] + 1
REFERENCES,0.324,"2Tr[AK−1ΓU],
(37)"
REFERENCES,0.325,Ltest = λ
REFERENCES,0.326,2S Tr[A(2ID −λK)−1] + 1
REFERENCES,0.327,"2Tr[AK−2Γ2U],
(38)"
REFERENCES,0.328,Published as a conference paper at ICLR 2022
REFERENCES,0.329,while the large-S limit of the exact theory yields Σ = λ
REFERENCES,0.33,S Tr[AK−2Γ2U]AK−1(2ID −λK)−1 + λ
REFERENCES,0.331,"S A2K−3Γ2(2ID −λK)−1U,
(39)"
REFERENCES,0.332,Ltrain = λ
REFERENCES,0.333,2S Tr[AK−2Γ2U]Tr[A(2ID −λK)−1] + λ
REFERENCES,0.334,2S Tr[A2K−2Γ2(2ID −λK)−1U] + 1
REFERENCES,0.335,"2Tr[AK−1ΓU],
(40)"
REFERENCES,0.336,Ltest = λ
REFERENCES,0.337,2S Tr[AK−2Γ2U]Tr[A(2ID −λK)−1] + λ
REFERENCES,0.338,2S Tr[A3K−3Γ2(2ID −λK)−1U] + 1
REFERENCES,0.339,"2Tr[AK−2Γ2U].
(41)"
REFERENCES,0.34,"The continuous-time results are obtained by taking the small-λ limit on Eqs. (36)-(38) for the Hessian
approximation and on Eqs. (39)-(41) for the limiting cases of the exact theory. Speciﬁcally, for the
Hessian approximation, we have Σ = λ"
REFERENCES,0.341,"2S ID,
(42)"
REFERENCES,0.342,Ltrain = λ
REFERENCES,0.343,4S Tr[K] + 1
REFERENCES,0.344,"2Tr[AK−1ΓU],
(43)"
REFERENCES,0.345,Ltest = λ
REFERENCES,0.346,4S Tr[A] + 1
REFERENCES,0.347,"2Tr[AK−2Γ2U].
(44)"
REFERENCES,0.348,The small-λ limit of the exact theory yields Σ = λ
REFERENCES,0.349,2S Tr[AK−2Γ2U]AK−1 + λ
REFERENCES,0.35,"2S A2K−3Γ2U,
(45)"
REFERENCES,0.351,Ltrain = λ
REFERENCES,0.352,4S Tr[AK−2Γ2U]Tr[A] + λ
REFERENCES,0.353,4S Tr[A2K−2Γ2U] + 1
REFERENCES,0.354,"2Tr[AK−1ΓU],
(46)"
REFERENCES,0.355,Ltest = λ
REFERENCES,0.356,4S Tr[AK−2Γ2U]Tr[A] + λ
REFERENCES,0.357,4S Tr[A3K−3Γ2U] + 1
REFERENCES,0.358,"2Tr[AK−2Γ2U].
(47)"
REFERENCES,0.359,Published as a conference paper at ICLR 2022
REFERENCES,0.36,"C
PROOF OF THE GENERAL FORMULA"
REFERENCES,0.361,"C.1
PROOF OF THEOREM 5 AND COROLLARY 2"
REFERENCES,0.362,We restate the theorem.
REFERENCES,0.363,Theorem 7. Let the training loss be LΓ = L0 + 1
REFERENCES,0.364,"2wTΓw and the models be optimized with SGD in
the neighborhood of a local minimum w∗. When Γ ≠0, the noise covariance is given by"
REFERENCES,0.365,C = 2L0(w∗)
REFERENCES,0.366,"S
H0(w∗) −1"
REFERENCES,0.367,"S Γw∗w∗TΓ + O(S−2) + O(∣w −w∗∣2).
(48)"
REFERENCES,0.368,"When Γ = 0 and L0(w∗) ≠0,"
REFERENCES,0.369,C = 2L0(w∗)
REFERENCES,0.37,"S
H0(w∗) + O(S−2) + O(∣w −w∗∣2).
(49)"
REFERENCES,0.371,"When Γ = 0 and L0(w∗) = 0, C = 1"
REFERENCES,0.372,"S (Tr[H0(w∗)Σ]ID −H0(w∗)Σ)H0(w∗) + O(S−2) + O(∣w −w∗∣2).
(50)"
REFERENCES,0.373,"Proof. We will use the following shorthand notations: ℓi ∶= ℓ(f(w,xi),yi), ℓ′
i ∶= ∂ℓi"
REFERENCES,0.374,"∂f , ℓ′′
i ∶= ∂2ℓi"
REFERENCES,0.375,"∂f 2 .
The Hessian of the loss function without regularization H0(w) = ∇∇TL0(w) is given by"
REFERENCES,0.376,H0(w) = 1 N
REFERENCES,0.377,"N
∑
i=1
ℓ′′
i ∇f(w,xi)∇f(w,xi)T + 1 N"
REFERENCES,0.378,"N
∑
i=1
ℓ′
i∇∇Tf(w,xi).
(51)"
REFERENCES,0.379,"The last term of Eq. (51) can be ignored when L0 ≪1, since ∥1 N"
REFERENCES,0.38,"N
∑
i=1
ℓ′
i∇∇Tf(w,xi)∥"
REFERENCES,0.381,"F
≤( 1 N"
REFERENCES,0.382,"N
∑
i=1
(ℓ′
i)2)"
REFERENCES,0.383,"1/2
( 1 N"
REFERENCES,0.384,"N
∑
i=1
∥∇∇Tf(w,xi)∥2
F ) 1/2"
REFERENCES,0.385,= ⟨ℓ′2⟩1/2 ( 1 N
REFERENCES,0.386,"N
∑
i=1
∥∇∇Tf(w,xi)∥2
F ) 1
2
, =
√"
REFERENCES,0.387,2L0(w)( 1 N
REFERENCES,0.388,"N
∑
i=1
∥∇∇Tf(w,xi)∥2
F ) 1
2
,"
REFERENCES,0.389,"where ∥⋅∥F stands for the Frobenius norm3, and we have deﬁned the variable ⟨ℓ′2⟩∶= 1"
REFERENCES,0.39,"N ∑N
i=1(ℓ′
i)2.
Since ℓ′′
i = 1 for the mean-square error, we obtain"
REFERENCES,0.391,H0(w) = 1 N
REFERENCES,0.392,"N
∑
i=1
∇f(w,xi)∇f(w,xi)T + O (
√"
REFERENCES,0.393,"L0)
(52)"
REFERENCES,0.394,near a minimum. The Hessian with regularization HΓ(w) = ∇∇TLΓ(w) is just given by H0(w)+Γ.
REFERENCES,0.395,"On the other hand, the SGD noise covariance C(w) is given by Eq. (2). By assumption 2, the SGD
noise covariance is directly related to the Hessian:"
REFERENCES,0.396,C(w) = ⟨ℓ′2⟩ SN
REFERENCES,0.397,"N
∑
i=1
∇f(w,xi)∇f(w,xi)T −1"
REFERENCES,0.398,S ∇LΓ(w)∇LΓ(w)T
REFERENCES,0.399,"+
2
SN"
REFERENCES,0.4,"N
∑
i=1
(ℓi −L0)∇f(w,xi)∇f(w,xi)T"
REFERENCES,0.401,= 2L0(w)
REFERENCES,0.402,"S
H0(w) −1"
REFERENCES,0.403,"S ∇LΓ(w)∇LΓ(w)T + o(L0).
(53)"
REFERENCES,0.404,This ﬁnishes the proof. ◻
REFERENCES,0.405,"3In the linear regression problem, the last term of Eq. (51) does not exist since ∇∇Tf(w, xi) = 0."
REFERENCES,0.406,Published as a conference paper at ICLR 2022
REFERENCES,0.407,Now we prove Corollary 2.
REFERENCES,0.408,"Proof. Near a minimum w∗of the full loss LΓ(w), we have"
REFERENCES,0.409,"∇LΓ(w) = H0(w∗)(w −w∗) + Γw∗+ O(∣w −w∗∣2),
(54)"
REFERENCES,0.41,"within the approximation LΓ(w) = LΓ(w∗)+(1/2)(w−w∗)THΓ(w∗)(w−w∗)T +O(∣w−w∗∣2).
Equations (14) and (54) give the SGD noise covariance near a minimum of LΓ(w)."
REFERENCES,0.411,"Now it is worth discussing two different cases separately: (1) with regularization and (2) without
regularization. We ﬁrst discuss the case when regularization is present. In this case, the regularization
Γ is not small enough, and the SGD noise covariance is not proportional to the Hessian. Near a local
or global minimum w ≈w∗, the ﬁrst term of the right-hand side of Eq. (54) is negligible, and hence
we obtain"
REFERENCES,0.412,Ew[C(w)] = 2L0(w∗)
REFERENCES,0.413,"S
H0(w∗) −1"
REFERENCES,0.414,S Γw∗w∗TΓ
REFERENCES,0.415,+ Ew [ 1
REFERENCES,0.416,S H0(w∗)(w −w∗)(w −w∗)TH0(w∗)] + O(∣w −w∗∣2)
REFERENCES,0.417,= 2L0(w∗)
REFERENCES,0.418,"S
H0(w∗) −1"
REFERENCES,0.419,"S Γw∗w∗TΓ + O(S−2) + O(∣w −w∗∣2).
(55)"
REFERENCES,0.42,"where we have used the fact that E[w] = w∗. The SGD noise does not vanish even at a global
minimum of LΓ(w). Note that this also agrees with the exact result derived in Sec. 4.3: together with
an anisotropic noise that is proportional to the Hessian, a rank-1 noise proportional to the strength of
the regularization appears. This rank-1 noise is a signature of regularization."
REFERENCES,0.421,"On the other hand, as we will see below, the SGD noise covariance is proportional to the Hessian
near a minimum when there is no regularization, i.e., Γ = 0. We have"
REFERENCES,0.422,C(w) = 2L0(w)
REFERENCES,0.423,"S
H0(w) −1"
REFERENCES,0.424,"S H0(w∗)(w −w∗)(w −w∗)TH0(w∗) + O(∣w −w∗∣2).
(56)"
REFERENCES,0.425,"For this case, we need to differentiate between a local minimum and a global minimum. When
L0(w∗) is not small enough (e.g. at a local but not global minimum),"
REFERENCES,0.426,C(w) = 2L0(w∗)
REFERENCES,0.427,"S
H0(w) + (w −w∗)TH0(w∗)(w −w∗)"
REFERENCES,0.428,"S
H0(w) −1"
REFERENCES,0.429,S H0(w∗)(w −w∗)(w −w∗)TH0(w∗) + O(∣w −w∗∣2)
REFERENCES,0.43,= 2L0(w∗)
REFERENCES,0.431,"S
H0(w) + O(S−2) + O(∣w −w∗∣2)"
REFERENCES,0.432,= 2L0(w∗)
REFERENCES,0.433,"S
H0(w∗) + O(S−2) + O(∣w −w∗∣2),
(57)"
REFERENCES,0.434,"and so, to leading order,"
REFERENCES,0.435,C = 2L0(w∗)
REFERENCES,0.436,"S
H0(w∗),
(58)"
REFERENCES,0.437,which is proportional to the Hessian but also proportional to the achievable approximation error.
REFERENCES,0.438,"On the other hand, when L0(w∗) is vanishingly small (e.g. at a global minimum), we have 2L0(w) ≈
(w −w∗)TH0(w∗)(w −w∗), and thus obtain"
REFERENCES,0.439,C(w) = 1
REFERENCES,0.44,S [(w −w∗)TH0(w∗)(w −w∗)H0(w∗) −H0(w∗)(w −w∗)(w −w∗)TH0(w∗)]
REFERENCES,0.441,"+ O(S−2) + O(∣w −w∗∣2),
(59) i.e.,"
REFERENCES,0.442,E[C] = 1
REFERENCES,0.443,"S (Tr[H0Σ]ID −H0Σ)H0 + O(S−2) + O(∣w −w∗∣2).
(60)"
REFERENCES,0.444,This completes the proof.
REFERENCES,0.445,Published as a conference paper at ICLR 2022
REFERENCES,0.446,"Remark. It should be noted that the second term on the right-hand side of Eq. (59) would typically be
much smaller than the ﬁrst term for large D. For example, when H0(w∗) = aID with a > 0, the ﬁrst
and the second terms are respectively given by (a2/S)∥w−w∗∥2ID and −(a2/S)(w−w∗)(w−w∗)T.
The Frobenius norm of the former is given by (Da2/S)∥w −w∗∥2, while that of the latter is given
by (a2/S)∥w −w∗∥2, which indicates that in Eq. (59), the ﬁrst term is dominant over the second
term for large D. Therefore the second term of Eq. (59) can be dropped for large D, and Eq. (59) is
simpliﬁed as
⎧⎪⎪⎨⎪⎪⎩"
REFERENCES,0.447,C(w) ≈(w−w∗)TH0(w∗)(w−w∗)
REFERENCES,0.448,"S
H0(w∗);
E[C] ≈Tr[H0Σ]"
REFERENCES,0.449,"S
H0.
(61)"
REFERENCES,0.45,"Again, the SGD noise covariance is proportional to the Hessian."
REFERENCES,0.451,"In conclusion, as long as the regularization is small enough, that the SGD noise covariance near
a minimum is proportional to the Hessian is a good approximation. This implies that the noise is
multiplicative, which is known to lead to a heavy tail distribution (Clauset et al., 2009; Levy and
Solomon, 1996). Thus, we have studied the nature of the minibatch SGD noise in three different
situations. As an example, we have demonstrated the power of this general formulation by applying
it to the high-dimensional linear regression problem in Sec. 6.1."
REFERENCES,0.452,"C.2
PROOF OF COROLLARY 3"
REFERENCES,0.453,"Proof. We prove the case where Γ = 0 and L(w∗) ≠0 as an example. Substituting Theorem 5 into
Theorem 1yields"
REFERENCES,0.454,"[2ID −
1
1 + µΛH0]ΛH0Σ =
2L0
S(1 −µ)Λ2H0,
(62)"
REFERENCES,0.455,"where we have assumed necessary commutation relations. Suppose that the Hessian H0 is of rank-r
with r ≤D. The singular-value decomposition and its Moore-Penrose pseudo inverse are given by
H0 = USV T and H+
0 = V S+U T, respectively, where U and V are unitary, S is a rank-r diagonal
matrix with elements being singular values of H0, and S+ is obtained by inverting every non-zero
entry of S. Multiplying H+
0 to both sides of the above equation, we have"
REFERENCES,0.456,"PrΣ =
2L0
S(1 −µ)PrΛ(2ID −
Λ
1 + µH0)"
REFERENCES,0.457,"−1
,
(63)"
REFERENCES,0.458,"where Pr = diag(1,1,...,1,0,...,0) is the projection operator with r non-zero entries. When the
Hessian is full-rank, i.e., r = D, the Moore-Penrose pseudo inverse is nothing but the usual inverse.
The other cases can be calculated similarly."
REFERENCES,0.459,Published as a conference paper at ICLR 2022
REFERENCES,0.46,"D
APPLICATIONS"
REFERENCES,0.461,"D.1
INFINITE-DIMENSIONAL LIMIT OF THE LINEAR REGRESSION PROBLEM"
REFERENCES,0.462,"Now we apply the general theory in Sec. 5 to linear regressions in the high-dimensional limit, namely
N,D →∞with α ∶= N/D held ﬁxed."
REFERENCES,0.463,"D.1.1
PROOF OF PROPOSITION 4"
REFERENCES,0.464,The loss function
REFERENCES,0.465,"L(w) =
1
2N"
REFERENCES,0.466,"N
∑
i=1
(wTxi −yi)
2
(64)"
REFERENCES,0.467,with yi = uT + ϵi can be written as
REFERENCES,0.468,L(w) = 1
REFERENCES,0.469,"2 (w −u −ˆA+v)
T ˆA(w −u −ˆA+v) −1"
REFERENCES,0.47,2vT ˆA+v + 1
N,0.471,2N
N,0.472,"N
∑
i=1
ϵ2
i ,
(65)"
N,0.473,where ˆA ∶= 1
N,0.474,"N ∑N
i=1 xixT
i is an empirical covariance for the training data and v ∶= 1"
N,0.475,"N ∑N
i=1 xiϵi. The
symbol (⋅)+ denotes the Moore-Penrose pseudoinverse. We also introduce the the averaged traing
loss: Ltrain ∶= Ew[L(w)]"
N,0.476,The minimum of the loss function is given by
N,0.477,"w∗= u + ˆA+v + Πr,
(66)"
N,0.478,"where r ∈RD is an arbitrary vector and Π is the projection onto the null space of ˆA. Since
1 −Π = ˆA+ ˆA, w∗is also expressed as"
N,0.479,"w∗= ˆA+( ˆAu + v) + Πr.
(67)"
N,0.48,"In an underparameterized regime α > 1, Π = 0 almost surely holds as long as the minimum eigenvalue
of A (not ˆA) is positive (Hastie et al., 2019). In this case, ˆA+ = ˆA−1 and we obtain"
N,0.481,"w∗= u + ˆA−1v
for α > 1.
(68)"
N,0.482,"On the other hand, in an overparameterized regime α > 1, Π ≠0 and there are inﬁnitely many global
minima. In the ridgeless regression, we consider the global minimum that has the minimum norm
∥w∗∥, which corresponds to"
N,0.483,"w∗= ˆA+( ˆAu + v) = (1 −Π)u + ˆA+v
for ridgeless regression with α < 1.
(69)"
N,0.484,"In both cases, the loss function is expressed as"
N,0.485,L(w) = 1
N,0.486,2 (w −w∗)T ˆA(w −w∗) −1
N,0.487,2vT ˆAv + 1
N,0.488,2N
N,0.489,"N
∑
i=1
ϵ2
i .
(70)"
N,0.49,"Asymptotically, wt converges to a stationary point w∗with ﬂuctuation Σ obeying the following
equation (Theorem 1:
λ ˆAΣ + λΣ ˆA −λ2 ˆAΣ ˆA = λ2C.
(71)"
N,0.491,"The SGD noise covariance C is given by Eq. (14). In the present case, the Hessian is given by H = ˆA
and we also have"
N,0.492,"1
N"
N,0.493,"N
∑
i=1
(ℓ′
i)2 = 1 N"
N,0.494,"N
∑
i=1
(wTxi −yi)
2 = 2 N"
N,0.495,"N
∑
i=1
ℓi = 2L(w).
(72)"
N,0.496,"On the other hand, ∇L(w)∇L(w)T = ˆA(w−w∗)(w−w∗)T ˆA, and hence Ew[∇L(w)∇L(w)T] =
ˆAΣ ˆA. Therefore we obtain"
N,0.497,C = Ew[C(w)] = 2Ltrain
N,0.498,"S
ˆA −1"
N,0.499,"S
ˆAΣ ˆA.
(73)"
N,0.5,Published as a conference paper at ICLR 2022
N,0.501,"Now, we ﬁnd Ltrain. First, we deﬁne X ∈RN×D as Xik = (xi)k, and ⃗ϵ ∈RN as ⃗ϵi = ϵi. Then
w∗= (1 −Π)u + ˆA+v = (1 −Π)u + (XTX)+XT⃗ϵ."
N,0.502,"With this notation, we have ˆA = XTX/N, and the loss function is expressed as"
N,0.503,L(w) = 1
N,0.504,2(w −w∗)T ˆA(w −w∗) −1
N,0.505,2N ⃗ϵTX(XTX)+XT⃗ϵ + 1
N,0.506,2N
N,0.507,"N
∑
i=1
ϵ2
i .
(74)"
N,0.508,We therefore obtain
N,0.509,Ltrain = 1
N,0.51,2Tr[ ˆAΣ] −1
N,0.511,2N E[⃗ϵTX(XTX)+XT⃗ϵ] + σ2
N,0.512,"2 .
(75)"
N,0.513,"Here,
E[⃗ϵTX(XTX)+XT⃗ϵ] = σ2Tr[(XTX)(XTX)+] = σ2Tr(1 −Π).
(76)
We can prove that the following identity is almost surely satisﬁed (Hastie et al., 2019) as long as the
smallest eigenvalue of A (not ˆA) is positive:"
N,0.514,"Tr(1 −Π) = min{D,N}.
(77)"
N,0.515,We therefore obtain
N,0.516,Ltrain = 1
N,0.517,2Tr[ ˆAΣ] −σ2
N,0.518,"2N min{D,N} + σ2 2 ="
N,0.519,⎧⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎩
N,0.52,"1
2Tr[ ˆAΣ] + 1"
N,0.521,2 (1 −1
N,0.522,"α)σ2
for α > 1,"
N,0.523,"1
2Tr[ ˆAΣ]
for α ≤1
(78)"
N,0.524,"By substituting Eq. (78) into Eq. (73), we obtain the following SGD noise covariance: C ="
N,0.525,⎧⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎩
N,0.526,"1
S (Tr[ ˆAΣ] −ˆAΣ) ˆA + σ2"
N,0.527,S (1 −1
N,0.528,"α) ˆA
for α > 1,"
N,0.529,"1
S (Tr[ ˆAΣ] −ˆAΣ) ˆA
for α ≤1.
(79)"
N,0.53,This ﬁnishes the proof. ◻
N,0.531,"D.1.2
PROOF OF THEOREM 6"
N,0.532,Proof. We have to solve this equation:
N,0.533,"ˆAΣ + Σ ˆA −λ ˆAΣ ˆA = λC,
(80)"
N,0.534,where C is given in Proposition 4. Using the similar trick of multiplying by ˆG ∶= 2ID −λ(1 −1
N,0.535,"S ) ˆA
as in Appendix E.2.2, one obtains"
N,0.536,"Tr[ ˆAΣ] = {
λσ2"
N,0.537,S (1 −1
N,0.538,"α) ˆκ
for α > 1;
0
for α ≤1,
(81)"
N,0.539,"where ˆκ ∶=
Tr[ ˆ
G−1 ˆ
A]
1−λ"
N,0.54,"S Tr[ ˆ
G−1 ˆ
A] with ˆG ∶= 2ID −λ(1 −1"
N,0.541,S ) ˆA.
N,0.542,"Substituting the above trace into the matrix equation, we have"
N,0.543,"Σ = {
λσ2"
N,0.544,S (1 −1
N,0.545,α)(1 + λ
N,0.546,"S ˆκ) ˆG−1
for α > 1;
0
for α ≤1.
(82)"
N,0.547,"D.2
SECOND-ORDER METHODS"
N,0.548,"Proposition 5. Suppose that we run DNM with Λ ∶= λA−1 with random noise in the label. The model
ﬂuctuation is"
N,0.549,"Σ =
λσ2"
N,0.55,"gS −λDA−1,
(83)"
N,0.551,where g ∶= 2(1 −µ) −( 1−µ
N,0.552,1+µ + 1 S )λ.
N,0.553,Published as a conference paper at ICLR 2022
N,0.554,Proof. Substituting Λ = λA−1 into Eqs. (3) and (5) yields
N,0.555,gΣ = λ
N,0.556,"S (Tr[AΣ] + σ2)A−1,
(84)"
N,0.557,where g ∶== 2(1 −µ) −( 1−µ
N,0.558,1+µ + 1
N,0.559,"S )λ. Multiplying A and taking trace on both sides, we have"
N,0.56,"Tr[AΣ] =
λDσ2"
N,0.561,"gS −λD.
(85)"
N,0.562,"Therefore, the model ﬂuctuation is"
N,0.563,"Σ =
λσ2"
N,0.564,"gS −λDA−1.
(86)"
N,0.565,Proposition 6. Suppose that we run NGD with Λ ∶= λ
N,0.566,S J(w)−1 ≈λ
N,0.567,"S C−1 with random noise in the
label. The model ﬂuctuation is Σ ="
N,0.568,⎡⎢⎢⎢⎢⎢⎣
N,0.569,"λ
4 g −1 2
σ2"
N,0.57,1 + D + 1 4
N,0.571,"¿
Á
Á
Àλ2g2 + 4λ(g −
2
1 + D
1
1 + µ)
σ2"
N,0.572,1 + D + 4( σ2
N,0.573,1 + D)
N,0.574,2⎤⎥⎥⎥⎥⎥⎦
N,0.575,"A−1,
(87)"
N,0.576,"where g ∶=
1
1+D
1
1+µ +
1
1−µ
1
S ."
N,0.577,"Proof. Similarly to the previous case, the matrix equation satisﬁed by Σ is"
N,0.578,(1 −µ)(C−1AΣ + ΣAC−1) −1 + µ2
N,0.579,"1 −µ2
λ
S C−1AΣAC−1 +
µ
1 −µ2
λ
S (C−1AC−1AΣ + ΣAC−1AC−1) = λ"
N,0.58,S C−1. (88)
N,0.581,"Although it is not obvious how to directly solve this equation, it is possible to guess one solution
according to the hope that Σ be proportional to J−1, in turn, A−1 (Amari, 1998; Liu et al., 2021).
We assume that Σ = xA−1 and substitute it into the above equation to solve for x. This yields one
solution without claiming its uniqueness. By simple algebra, this x is solved to be x = λ"
N,0.582,"4 g −1 2
σ2"
N,0.583,1 + D + 1 4
N,0.584,"¿
Á
Á
Àλ2g2 + 4λ(g −
2
1 + D
1
1 + µ)
σ2"
N,0.585,1 + D + 4( σ2
N,0.586,1 + D)
N,0.587,"2
.
(89)"
N,0.588,Let σ = 0. We obtain the result in Sec. 6.4.
N,0.589,"D.3
ESTIMATION OF TAIL INDEX"
N,0.59,"In Mori et al. (2021); Meng et al. (2020), it is shown that the (1d) discrete-time SGD results in a
distribution that is similar to a Student’s t-distribution:"
N,0.591,p(w) ∼(σ2 + aw2)−1+β
N,0.592,"2 ,
(90)"
N,0.593,"where σ2 is the degree of noise in the label, and a is the local curvature of the minimum. For large w,
this distribution is a power-law distribution with tail index:"
N,0.594,"p(∣w∣) ∼∣w∣−(1+β),
(91)"
N,0.595,"and it is not hard to check that β also equal to the smallest moment of w that diverges: E[wβ] = ∞.
Therefore, estimating β can be of great use both empirically and theoretically."
N,0.596,"In continuous-time, it is found that βcts = 2S"
N,0.597,"aλ + 1 (Mori et al., 2021). For discrete-time SGD, we
hypothesize that the discrete-time nature causes a change in the tail index β = βcts + ϵ, and we are
interested in ﬁnding ϵ. We propose a “semi-continuous"" approximation to give the formula to estimate
the tail index. Notice that Theorem 2 gives the variance of the discrete-time SGD, while Eq. (90)
can be integrated to give another value of the variance, and the two expressions must be equal for
consistency. This gives us an equation that β must satisfy:"
N,0.598,"∫p(w;β)(w −E[w])2 = Var[w],
(92)"
N,0.599,Published as a conference paper at ICLR 2022
N,0.6,"Figure 7: Tail index β of the stationary distribution of SGD in a 1d linear regression problem. Left to
Right: aλ = 0.2, 1.0, 1.8."
N,0.601,this procedure gives the following formula:
N,0.602,"β(λ,S) = 2S"
N,0.603,"aλ −S = βcts + ϵ,
(93)"
N,0.604,"and one immediately recognizes that −(S + 1) is the discrete-time contribution to the tail index. See
Figure 7 for additional experiments. We see that the proposed formula agrees with the experimentally
measured value of the tail index for all ranges of the learning rate, while the result of Mori et al.
(2021) is only correct when λ →0+. Hodgkinson and Mahoney (2020) also studies the tail exponent
of discrete-time SGD; however, their conclusion is only that the “index decreases with the learning
rate and increases with the batch size"". In contrast, our result give the functional form of the tail index
directly. In fact, this is the ﬁrst work that gives any functional form for the tail index of discrete-time
SGD ﬂuctuation to the best of our knowledge."
N,0.605,The following proposition gives the intermediate steps in the calculation.
N,0.606,Proposition 7. (Tail index estimation for discrete-time SGD) Let the parameter distribution be
N,0.607,"p(w) ∼(σ2 + aw2)
−1+β"
N,0.608,"2 , and Var[w] be given by Theorem 2. Then"
N,0.609,"β(λ,S) = 2S"
N,0.61,"aλ −S.
(94)"
N,0.611,Proof. The normalization factor for the distribution exists if β > 0:
N,0.612,"N =
√a"
N,0.613,"π
σβΓ( 1+β 2 ) Γ( β"
N,0.614,"2 )
.
(95)"
N,0.615,"If β > 2, the variance exists and the value is"
N,0.616,"Var[w] =
σ2"
N,0.617,"a(β −2).
(96)"
N,0.618,"By equating Eq. (96) with the exact variance (6), we are able to solve for an expression of the tail
index as
β(λ,S) = 2S"
N,0.619,"aλ −S.
(97)"
N,0.62,Published as a conference paper at ICLR 2022
N,0.621,"E
PROOFS AND ADDITIONAL THEORETICAL CONSIDERATIONS"
N,0.622,"E.1
PROOF OF PROPOSITION 1"
N,0.623,"The with-replacement sampling is deﬁned in Deﬁnition 2. Let us here deﬁne the without-replacement
sampling.
Deﬁnition 3. A minibatch SGD without replacement computes the update to the parameter w with
the following set of equations:"
N,0.624,{ˆgt = 1
N,0.625,"S ∑i∈Bt ∇ℓ(xi,yi,wt−1);
wt = wt−1 −λˆgt,
(98)"
N,0.626,"where S ∶= ∣Bt∣≤N is the minibatch size, and the set Bt is an element uniformly-randomly drawn
from the set of all S-size subsets of {1,...,N}."
N,0.627,"From the deﬁnition of the update rule for sampling with or without replacement, the covariance
matrix of the SGD noise can be exactly derived.
Proposition 8. The covariance matrices of noise in SGD due to minibatch sampling as deﬁned in
Deﬁnitions 2 and 3 with an arbitrary N are"
N,0.628,C(w) = {
N,0.629,"1
S [ 1"
N,0.63,"N ∑N
i=1 ∇ℓi∇ℓT
i −∇L(w)∇L(w)T],
(with replacement)
N−S
S(N−1) [ 1"
N,0.631,"N ∑N
i=1 ∇ℓi∇ℓT
i −∇L(w)∇L(w)T],
(without replacement)
(99)"
N,0.632,"where the shorthand notation ℓi(w) ∶= l(xi,yi,w) is used."
N,0.633,"In the limit of S = 1 or N ≫S, two cases coincide. In the N ≫S limit, both methods of sampling
have the same noise covariance as stated in Proposition 1:"
N,0.634,"C(w) =
1
SN"
N,0.635,"N
∑
i=1
∇ℓi∇ℓT
i −1"
N,0.636,"S ∇L(w)∇L(w)T.
(100)"
N,0.637,"Remark. We also note that a different way of deﬁning minibatch noise exists in Hoffer et al. (2017).
The difference is that our deﬁnition requires the size of each minibatch to be exactly S, while Hoffer
et al. (2017) treats the batch size also as a random variable and is only expected to be S. In
comparison, our deﬁnition agrees better with the common practice."
N,0.638,Now we prove Proposition 8.
N,0.639,"Proof. We derive the noise covariance matrices for sampling with and without replacement. We ﬁrst
derive the case with replacement. According to the deﬁnition, the stochastic gradient for sampling
with replacement can be rewritten as"
N,0.64,ˆg = 1 S
N,0.641,"N
∑
n=1
gnsn,
(101)"
N,0.642,where gn ∶= ∇ℓn and
N,0.643,"sn = l, if l −multiple n′s are sampled in S, with 0 ≤l ≤S.
(102)"
N,0.644,The probability of sn assuming value l is given by the multinomial distribution
N,0.645,"P(sn = l) = (S
l )( 1 N )"
N,0.646,"l
(1 −1 N )"
N,0.647,"S−l
.
(103)"
N,0.648,"Therefore, the expectation value of sn is given by"
N,0.649,"EB[sn] =
S
∑
l=0
lP(sn = l) = S"
N,0.65,"N ,
(104)"
N,0.651,which gives
N,0.652,EB[ˆg] = g ∶= 1 N
N,0.653,"N
∑
n=1
gn = ∇L(w).
(105)"
N,0.654,Published as a conference paper at ICLR 2022
N,0.655,"For the covariance, we ﬁrst calculate the covariance between sn and sn′. Due to the properties of the
covariance of multinomial distribution, we have for n ≠n′"
N,0.656,"EB[snsn′] = cov[sn,sn′] + E[sn]2 = −S"
N,0.657,N 2 + S2 N 2
N,0.658,= S(S −1)
N,0.659,"N 2
;
(106)"
N,0.66,and for n = n′
N,0.661,EB[snsn] = Var[sn] + E[sn]2 = S
N,0.662,"N
N −1"
N,0.663,"N
+ S2 N 2"
N,0.664,= SN + S(S −1)
N,0.665,"N 2
.
(107)"
N,0.666,Substituting these results into the deﬁnition of the noise covariance yields
N,0.667,C(w) = EB[ˆgˆgT] −EB[ˆg]EB[ˆg]T = 1 S2
N,0.668,"N
∑
n=1"
N,0.669,"N
∑
n′=1
gngT
n′EB[snsn′] −ggT = 1 S2"
N,0.67,"N
∑
n,n′=1
gngT
n′ S(S −1)"
N,0.671,"N 2
+ 1 S2"
N,0.672,"N
∑
n=1
gngT
n [SN + S(S −1)"
N,0.673,"N 2
−S(S −1)"
N,0.674,"N 2
] −ggT"
N,0.675,"=
1
NS"
N,0.676,"N
∑
n=1
gngT
n −1 S ggT = 1 S [ 1 N"
N,0.677,"N
∑
i=1
∇ℓi∇ℓT
i −∇L(w)∇L(w)T].
(108)"
N,0.678,"Then, we derive the noise covariance for sampling without replacement. Similarly, according to the
deﬁnition, the stochastic gradient for sampling without replacement can be rewritten as"
N,0.679,ˆg = 1 S
N,0.68,"N
∑
n=1
gnsn,
(109) where"
N,0.681,"sn = {0,if n ∉S;
1,if n ∈S.
(110)"
N,0.682,The probability of n that is sampled in S from N is given by
N,0.683,"P(sn = 1) =
(N−1
S−1)"
N,0.684,"(N
S)
= S"
N,0.685,"N .
(111)"
N,0.686,The expectation value of sn is then given by
N,0.687,EB[sn] = P(sn = 1) = S
N,0.688,"N ,
(112)"
N,0.689,which gives
N,0.69,EB[ˆg] = g ∶= 1 N
N,0.691,"N
∑
n=1
gn = ∇L(w).
(113)"
N,0.692,"For the covariance, we ﬁrst calculate the covariance between sn and sn′. By deﬁnition, we have for
n ≠n′"
N,0.693,"EB[snsn′] = P(sn = 1,s′
n = 1) = P(sn = 1∣s′
n = 1)P(s′
n = 1)"
N,0.694,"=
(N−2
S−2)"
N,0.695,"(N−1
S−1)"
N,0.696,"(N−1
S−1)"
N,0.697,"(N
S)
= S(S −1)"
N,0.698,"N(N −1);
(114)"
N,0.699,Published as a conference paper at ICLR 2022
N,0.7,and for n = n′
N,0.701,EB[snsn] = P(sn = l) = S
N,0.702,"N .
(115)"
N,0.703,Substituting these results into the deﬁnition of the noise covariance yields
N,0.704,C(w) = EB[ˆgˆgT] −EB[ˆg]EB[ˆg]T = 1 S2
N,0.705,"N
∑
n=1"
N,0.706,"N
∑
n′=1
gngT
n′EB[snsn′] −ggT = 1 S2"
N,0.707,"N
∑
n,n′=1
gngT
n′ S(S −1)"
N,0.708,N(N −1) + 1 S2
N,0.709,"N
∑
n=1
gngT
n [ S"
N,0.71,N −S(S −1)
N,0.711,N(N −1)] −ggT
N,0.712,"=
1
NS
N −S N −1"
N,0.713,"N
∑
n=1
gngT
n −
N −S
S(N −1)ggT"
N,0.714,"=
N −S
S(N −1) [ 1 N"
N,0.715,"N
∑
i=1
∇ℓi∇ℓT
i −∇L(w)∇L(w)T].
(116)"
N,0.716,"E.2
PROOFS IN SEC. 4.2"
N,0.717,"E.2.1
PROOF OF LEMMA 1"
N,0.718,"Proof. From the deﬁnition of noise covariance (2), the covariance matrix for the noise in the label is"
N,0.719,"C(w) =
1
NS"
N,0.72,"N
∑
i=1
∇li(wt−1)∇li(wt−1)T −1"
N,0.721,"S ∇L(wt−1)∇L(wt−1)T = 1 S
1
N"
N,0.722,"N
∑
i
(wTxi −ϵi)xixT
i (wTxi −ϵi)T −1 S [ 1 N"
N,0.723,"N
∑
i
(wTxi −ϵi)xi]
⎡⎢⎢⎢⎣"
N,0.724,"1
N"
N,0.725,"N
∑
j
xT
j (wTxj −ϵj)T⎤⎥⎥⎥⎦ = 1 S
1
N"
N,0.726,"N
∑
i
(wTxixixT
i xT
i w + ϵ2
i xixT
i ) −1 S [ 1 N"
N,0.727,"N
∑
i
(wTxixi)]
⎡⎢⎢⎢⎣"
N,0.728,"1
N"
N,0.729,"N
∑
j
(xT
i xT
i w)
⎤⎥⎥⎥⎦
(117) = 1"
N,0.73,"S (AwwTA + Tr[AwwT]A + σ2A),
(118)"
N,0.731,"where we have invoked the law of large numbers and the expectation value of the product of four
Gaussian random variables in the third line is evaluated as follows."
N,0.732,"Because N is large, we invoke the law of large numbers to obtain the (j,k)-th component of the
matrix as"
N,0.733,"lim
N→∞
1
N"
N,0.734,"N
∑
i=1
(wTxixixT
i xT
i w)jk = EB[wTxxxTxTw]jk = EB [
D
∑
i
wixixjxk"
N,0.735,"D
∑
i′ xi′wi′].
(119)"
N,0.736,"Because the average is taken with respect to x and each x is a Gaussian random variable, we apply the
expression for the product of four Gaussian random variables E[x1x2x3x4] = E[x1x2]E[x3x4] +
E[x1x3]E[x2x4]+E[x1x4]E[x2x3]−2E[x1]E[x2]E[x3]E[x4] (Janssen and Stoica, 1988) to obtain"
N,0.737,"EB [
D
∑
i
wixixjxk"
N,0.738,"D
∑
i′ xi′wi′]"
N,0.739,"= EB [
D
∑
i
wixixj]EB [xk"
N,0.74,"D
∑
i′ xi′wi′] + EB [
D
∑
i
wixixk]EB [xj"
N,0.741,"D
∑
i′ xi′wi′]"
N,0.742,"+ EB [
D
∑
i
wixi"
N,0.743,"D
∑
i′ xi′wi′]EB [xjxk]"
N,0.744,"= 2(AwwTA)jk + Tr[AwwT]Ajk.
(120)"
N,0.745,"Writing Σ ∶= Ew[wwT], we obtain"
N,0.746,Ew[C(w)] =∶C = 1
N,0.747,"S (AΣA + Tr[AΣ]A + σ2A).
(121)"
N,0.748,Published as a conference paper at ICLR 2022
N,0.749,This method has been utilized repeatedly in this work.
N,0.75,"E.2.2
PROOF OF THEOREM 2"
N,0.751,"Proof. We substitute Eq. (5) into Eq. (3) which is a general solution obtained in a recent work (Liu
et al., 2021):"
N,0.752,(1 −µ)(ΛAΣ + ΣAΛ) −1 + µ2
N,0.753,"1 −µ2 ΛAΣAΛ +
µ
1 −µ2 (ΛAΛAΣ + ΣAΛAΛ) = ΛCΛ.
(122)"
N,0.754,"To solve it, we assume the commutation relation that [Λ,A] ∶= ΛA −AΛ = 0. Therefore, the above
equation can be alternatively rewritten as"
N,0.755,[(1 −µ)ID −1
N,0.756,2 (1 −µ
N,0.757,1 + µ + 1
N,0.758,S )ΛA]ΣAΛ + ΛAΣ[(1 −µ)ID −1
N,0.759,2 (1 −µ
N,0.76,1 + µ + 1
N,0.761,S )ΛA] −1
N,0.762,S Tr[AΣ]ΛA = 1
N,0.763,"S σ2ΛA.
(123)"
N,0.764,"To solve this equation, we ﬁrst need to solve for Tr[AΣ]. Multiplying Eq. (123) by G−1
µ
∶="
N,0.765,[2(1 −µ)ID −( 1−µ
N,0.766,1+µ + 1
N,0.767,"S )ΛA]
−1
and taking trace, we obtain"
N,0.768,Tr[AΣ] −1
N,0.769,"S Tr[AΣ]Tr[ΛAG−1
µ ] = 1"
N,0.77,"S σ2Tr[ΛAG−1
µ ],
(124)"
N,0.771,which solves to give
N,0.772,Tr[AΣ] = σ2 S
N,0.773,"Tr[ΛAG−1
µ ] 1 −1"
N,0.774,"S Tr[ΛAG−1
µ ] ∶= σ2"
N,0.775,"S κµ.
(125)"
N,0.776,"Therefore, Σ is"
N,0.777,Σ = σ2
N,0.778,S (1 + κ
N,0.779,S )Λ[2(1 −µ)ID −(1 −µ
N,0.78,1 + µ + 1
N,0.781,S )ΛA]
N,0.782,"−1
.
(126)"
N,0.783,"E.2.3
TRAINING ERROR AND TEST ERROR FOR LABEL NOISE"
N,0.784,"In the following theorem, we calculate the expected training and test loss for random noise in the
label.
Theorem 8. (Approximation error and test loss for SGD noise in the label) The expected approxi-
mation error, or the training loss, is deﬁned as Ltrain ∶= Ew[L(w)]; the expected test loss is deﬁned
as Ltest ∶= 1"
N,0.785,"2EwEB [(wTx)2]. For SGD with noise in the label given by Eq. (5), the expected
approximation error and test loss are"
N,0.786,Ltrain = σ2
N,0.787,2 (1 + λκ
N,0.788,"S ),
(127)"
N,0.789,Ltest = λσ2
N,0.79,"2S κ.
(128)"
N,0.791,"Remark. Notably, the training loss decomposes into two additive terms. The term that is proportional
to 1 is the bias, caused by insufﬁcient model expressivity to perfectly ﬁt all the data points, while
the second term that is proportional to λκ/S is the variance in the model parameter, induced by the
randomness of minibatch noise.
Remark. When the learning rate λ is vanishingly small, the expected test loss diminishes whereas
the training error remains ﬁnite as long as label noise exists."
N,0.792,"Proof. We ﬁrst calculate the approximation error. By deﬁnition,"
N,0.793,Ltrain ∶= Ew[L(w)] = 1
N,0.794,2Tr[AΣ] + 1
N,0.795,"2σ2 = 1 2
λσ2"
N,0.796,S κ + 1 2σ2 = σ2
N,0.797,2 (1 + λκ
N,0.798,"S ).
(129)"
N,0.799,Published as a conference paper at ICLR 2022
N,0.8,The test loss is
N,0.801,Ltest = 1
N,0.802,2Ew [wTAw] = 1
N,0.803,2Tr[AΣ] = λσ2
N,0.804,"2S κ.
(130)"
N,0.805,"E.3
MINIBATCH NOISE FOR RANDOM NOISE IN THE INPUT"
N,0.806,"E.3.1
NOISE STRUCTURE"
N,0.807,"Similar to label noise, noise in the input data can also cause ﬂuctuation. We assume that the training
data points ˜xi = xi+ηi can be decomposed into a signal part and a random part. As before, we assume
Gaussian distributions, xi ∼N(0,A) and ηi ∼N(0,B). The problem remains analytically solvable
if we replace the Gaussian assumption by the weaker assumption that the fourth-order moment exists
and takes some matrix form. For conciseness, we assume that there is no noise in the label, namely
yi = uTxi with a constant vector u. One important quantity in this case will be uuT ∶= U. Notice
that the trick w −u = w no more works, and so we write the difference explicitly here. The loss
function then takes the form"
N,0.808,"L(w) =
1
2N"
N,0.809,"N
∑
i=1
[(w −u)Txi + wTηi]
2 = 1"
N,0.81,2(w −u)TA(w −u) + 1
N,0.811,"2wTBw.
(131)"
N,0.812,"The gradient ∇L = (A + B)(w −u) + Bu vanishes at w∗∶= (A + B)−1Au, which is the minimum
of the loss function and the expectation of the parameter at convergence. It can be seen that, even
at the minimum w∗, the loss function remains ﬁnite unless u = 0, which reﬂects the fact that in the
presence of input noise, the network is not expressive enough to memorize all the information of the
data. The SGD noise covariance for this type of noise is calculated in the following proposition.
Proposition 9. (Covariance matrix for SGD noise in the input) Let the algorithm be updated
according to Eq. (1) or (98) with random noise in the input while the limit N →∞is taken with D
held ﬁxed. Then the noise covariance is C = 1"
N,0.813,"S {KΣK + Tr[KΣ]K + Tr[AK−1BU]K},
(132)"
N,0.814,"where K ∶= A + B, and Σ ∶= Ew [(w −w∗)(w −w∗)T].
Remark. It can be seen that the form of the covariance (132) of input noise is similar to that of label
noise (5) with replacing A by K and σ2 by Tr[AK−1BU], suggesting that these two types of noise
share a similar nature."
N,0.815,"Deﬁning the test loss as Ltest ∶=
1
2EwEB [(wTx −uTx)2], Proposition 9 can then be used to
calculate the test loss and the model ﬂuctuation.
Theorem 9. (Training error, test loss and model ﬂuctuation for noise in the input) The expected
training loss is deﬁned as Ltrain ∶= Ew[L(w)], and the expected test loss is deﬁned as Ltest ∶=
1
2EwEB [(wTx −uTx)2]. For SGD with noise in the input given in Proposition (9), the expected
approximation error and test loss are"
N,0.816,Ltrain = 1
N,0.817,2Tr[AK−1BU](1 + λ
N,0.818,"S κ′),
(133)"
N,0.819,Ltest = λ
N,0.82,2S Tr[AK−1BU]κ′ + 1
N,0.821,"2Tr[B′TAB′U],
(134)"
N,0.822,"where κ′ ∶=
Tr[KG′−1]
1−λ 1"
N,0.823,S Tr[KG′−1] with G′ ∶= 2ID−λ(1 + 1
N,0.824,"S )K, and B′ ∶= K−1B. Moreover, let [K,U] = 0.
Then the covariance matrix of model parameters is"
N,0.825,Σ = λTr[AK−1BU]
N,0.826,"S
(1 + λκ′"
N,0.827,S )[2ID −λ(1 + 1 S )K]
N,0.828,"−1
.
(135)"
N,0.829,"Remark. Note that [K,U] = 0 is necessary only for an analytical expression of Σ. It can be obtained
by solving Eq. (144) even without invoking [K,U] = 0. In general, the condition that [K,U] = 0
does not hold. Therefore, only the training and test error can be calculated exactly.
Remark. The test loss is always smaller than or equal to the training loss because all matrices
involved here are positive semideﬁnite."
N,0.83,Published as a conference paper at ICLR 2022
N,0.831,"E.3.2
PROOF OF PROPOSITION 9"
N,0.832,"Proof. We deﬁne Σ ∶= Ew [(w −w∗)(w −w∗)T]. Then,"
N,0.833,"Ew[wwT] = Σ + (A + B)−1AUA(A + B)−1 ∶= Σ + A′UA′T ∶= ΣA,
(136)"
N,0.834,"Ew [(w −u)(w −u)T] = Σ + B′UB′T ∶= ΣB,
(137)"
N,0.835,"where we use the shorthand notations A′ ∶= (A+B)−1A, B′ ∶= (A+B)−1B and ΣA ∶= Σ+A′UA′T,
ΣB ∶= Σ + B′UB′T. We remark that the covariance matrix Σ here still satisﬁes the matrix equation
(3) with the Hessian being K ∶= A + B."
N,0.836,The noise covariance is
N,0.837,"C(w) = 1 S
1
N"
N,0.838,"N
∑
i
(wT˜xi −uTxi)˜xi˜xT
i (wT˜xi −uTxi)T −1"
N,0.839,S ∇L(w)∇L(w)T = 1
N,0.84,S {A(w −u)(w −u)TA + BwwTB + A(w −u)wTB + Bw(w −u)TA
N,0.841,"+ Tr[A(w −u)(w −u)T]K + Tr[BwwT]K}.
(138)"
N,0.842,"In Eq. (138), there are four terms without trace and two terms with trace. We ﬁrst calculate the
traceless terms. For the latter two terms, we have"
N,0.843,"Ew[(w −u)wT] = Σ −A′UB′T,
(139)"
N,0.844,"Ew[w(w −u)T] = Σ −B′UA′T.
(140)"
N,0.845,"Because A′ + B′ = ID, after simple algebra the four traceless terms result in 2(A + B)Σ(A + B)."
N,0.846,"The two traceful terms add to Tr[AΣB + BΣA]K. With the relation AB′ = BA′, what inside the
trace is"
N,0.847,"AΣB + BΣA = KΣ + AK−1BU.
(141)"
N,0.848,"Therefore, the asymptotic noise is"
N,0.849,C ∶= Ew[C(w)] = 1
N,0.85,"S {KΣK + Tr[AΣB + BΣA]K}
(142) = 1"
N,0.851,"S {KΣK + Tr[KΣ]K + Tr[AK−1BU]K}.
(143)"
N,0.852,"E.3.3
PROOF OF THEOREM 9"
N,0.853,Proof. The matrix equation satisﬁed by Σ is
N,0.854,ΣK + KΣ −λ(1 + 1
N,0.855,S )KΣK = λ
N,0.856,"S (Tr[KΣ]K + Tr[AK−1BU]K).
(144)"
N,0.857,"By using a similar technique as in Appendix E.2.2, the trace Tr[KΣ] can be calculated to give"
N,0.858,Tr[KΣ] = λTr[AK−1BU]
N,0.859,"S
κ′,
(145)"
N,0.86,"where κ′ ∶=
Tr[KG′−1]
1−λ 1"
N,0.861,S Tr[KG′−1] with G′ ∶= 2ID −λ(1 + 1 S )K.
N,0.862,"With Eq. (145), the training error and the test error can be calculated. The approximation error is"
N,0.863,Ltrain = Ew[L(w)] = 1
N,0.864,2Tr[AΣB + BΣA] = 1
N,0.865,2Tr[AK−1BU](1 + λ
N,0.866,"S κ′).
(146)"
N,0.867,Published as a conference paper at ICLR 2022
N,0.868,The test loss takes the form of a bias-variance tradeoff:
N,0.869,Ltest = 1
N,0.87,2EwEB [(wTx −uTx)2] = 1
N,0.871,2Ew [(w −u)TA(w −u)] = 1
N,0.872,2Tr[AΣB] = λ
N,0.873,2S Tr[AK−1BU](1 + λκ′
N,0.874,S )Tr[AG′−1] + 1
N,0.875,2Tr[B′TAB′U] = λ
N,0.876,2S Tr[AK−1BU]κ′ + 1
N,0.877,"2Tr[B′TAB′U].
(147)"
N,0.878,"Let [K,U] = 0. Then Σ can be explicitly solved because it is a function of K and U. Speciﬁcally,"
N,0.879,Σ = λTr[AK−1BU]
N,0.88,"S
(1 + λκ′"
N,0.881,S )[2ID −λ(1 + 1 S )K]
N,0.882,"−1
.
(148)"
N,0.883,"E.4
PROOFS IN SEC. 4.3"
N,0.884,"E.4.1
PROOF OF PROPOSITION 3"
N,0.885,Proof. The covariance matrix of the noise is
N,0.886,"C(w) = 1 S
1
N"
N,0.887,"N
∑
i
[(w −u)Txixi + Γw][xT
i xT
i (w −u) + wTΓ] −1"
N,0.888,S ∇LΓ(w)∇LΓ(w)T = 1
N,0.889,"S {A(w −u)(w −u)TA + Tr[A(w −u)(w −u)T]A}.
(149)"
N,0.89,"Using a similar trick as in Appendix E.3.2, the asymptotic noise is C = 1"
N,0.891,"S (AΣA + Tr[AΣ]A + Tr[Γ′TAΓ′U]A + ΓA′UA′Γ).
(150)"
N,0.892,"E.4.2
PROOF OF THEOREM 4"
N,0.893,"Besides the test loss and the model ﬂuctuation, we derive the approximation error here as well."
N,0.894,"Theorem. (Training error, test loss and model ﬂuctuation for learning with L2 regularization) The
expected training loss is deﬁned as Ltrain ∶= Ew[L(w)], and the expected test loss is deﬁned as
Ltest ∶= 1"
N,0.895,"2EwEB [(wTx −uTx)2]. For noise induced by L2 regularization given in Proposition 3,
let [A,Γ] = 0. Then the expected approximation error and test loss are"
N,0.896,Ltrain = λ
N,0.897,2S Tr[AK−2Γ2U]Tr[AG−1](1 + λκ
N,0.898,S ) + λ
N,0.899,2S (Tr[A2K−2Γ2G−1U] + λr
N,0.9,S Tr[AG−1]) + 1
N,0.901,"2Tr[AK−1ΓU],
(151)"
N,0.902,Ltest = λ
N,0.903,2S (Tr[AK−2Γ2U]κ + r) + 1
N,0.904,"2Tr[AK−2Γ2U],
(152)"
N,0.905,"where κ ∶=
Tr[A2K−1G−1]
1−λ"
N,0.906,"S Tr[A2K−1G−1], r ∶= Tr[A3K−3Γ2G−1U] 1−λ"
N,0.907,"S Tr[A2K−1G−1], with G ∶= 2ID −λ(K + 1"
N,0.908,"S K−1A2). Moreover,
if A, Γ and U commute with each other, the model ﬂuctuation is Σ = λ"
N,0.909,S Tr[AK−2Γ2U](1 + λκ
N,0.91,S )AK−1G−1 + λ
N,0.911,S (A2K−2Γ2U + λr
N,0.912,"S A)K−1G−1.
(153)"
N,0.913,"Remark. Because Γ may not be positive semideﬁnite, the test loss can be larger than the training
loss, which is different from the input noise case."
N,0.914,Published as a conference paper at ICLR 2022
N,0.915,Proof. The matrix equation obeyed by Σ is
N,0.916,ΣK + KΣ −λKΣK −λ
N,0.917,S AΣA = λ
N,0.918,S Tr[AΣ]A + λ
N,0.919,"S (Tr[AK−2Γ2U]A + AK−1ΓUΓK−1A), (154)"
N,0.92,"where we use the shorthand notation K ∶= A + Γ. Let [A,Γ] = 0. Using the trick in Appendix E.2.2,
the trace term Tr[AΣ] is calculated as"
N,0.921,Tr[AΣ] = λ
N,0.922,"S (Tr[AK−2Γ2U]κ + r),
(155)"
N,0.923,"where κ ∶=
Tr[A2K−1G−1]
1−λ"
N,0.924,"S Tr[A2K−1G−1], r ∶= Tr[A3K−3Γ2G−1U] 1−λ"
N,0.925,"S Tr[A2K−1G−1], and G ∶= 2ID −λ(K + 1"
N,0.926,S K−1A2).
N,0.927,The training error is
N,0.928,Ltrain = 1
N,0.929,2Tr[AΣΓ + ΓΣA] = 1
N,0.93,2Tr[KΣ] + 1
N,0.931,2Tr[AK−1ΓU] = λ
N,0.932,2S Tr[AK−2Γ2U]Tr[AG−1](1 + λκ
N,0.933,S ) + λ
N,0.934,2S (Tr[A2K−2Γ2G−1U] + λr
N,0.935,S Tr[AG−1]) + 1
N,0.936,"2Tr[AK−1ΓU].
(156)"
N,0.937,The test loss is
N,0.938,Ltest = 1
N,0.939,2EwEB [(wTx −uTx)2] = 1
N,0.94,2Ew [(w −u)TA(w −u)] = 1
N,0.941,2Tr[AΣΓ] = λ
N,0.942,2S (Tr[AK−2Γ2U]κ + r) + 1
N,0.943,"2Tr[AK−2Γ2U].
(157)"
N,0.944,"Let A, Γ and U commute with each other. Then, Σ = λ"
N,0.945,S Tr[AK−2Γ2U](1 + λκ
N,0.946,S )AK−1G−1 + λ
N,0.947,S (A2K−2Γ2U + λr
N,0.948,"S A)K−1G−1.
(158)"
N,0.949,"E.4.3
PROOF OF COROLLARY 1"
N,0.95,"For a 1d example, the training loss and the test loss have a simple form. We use lowercase letters for
1d cases."
N,0.951,"Corollary 4. For a 1d SGD with L2 regularization, the training loss and the test loss are"
N,0.952,"Ltrain =
aγ
2(a + γ)"
N,0.953,2(a + γ) −λ[(a + γ)2 + 2
N,0.954,S a(a −γ)]
N,0.955,2(a + γ) −λ[(a + γ)2 + 2
N,0.956,"S a2]
u2,
(159)"
N,0.957,"Ltest =
aγ2"
N,0.958,"2(a + γ)
2 −λ(a + γ)
2(a + γ) −λ[(a + γ)2 + 2"
N,0.959,"S a2]u2.
(160)"
N,0.96,Proof. The training error and the test loss for 1d cases can be easily obtained from Theorem E.4.2.
N,0.961,Now we prove Corollary 1.
N,0.962,Proof. The condition for convergence is 1 −λ
N,0.963,"S Tr[A2K−1G−1] > 0. Speciﬁcally,"
N,0.964,λ(a + γ)2 −2(a + γ) + λ 2
N,0.965,"S a2 < 0.
(161)"
N,0.966,Published as a conference paper at ICLR 2022
N,0.967,"For a given γ, the learning rate needs to satisfy"
N,0.968,"λ <
2(a + γ)
(a + γ)2 + 2"
N,0.969,"S a2 .
(162)"
N,0.97,"For a given λ, γ needs to satisfy"
N,0.971,"1 −aλ −
√ 1 −2"
N,0.972,S a2λ2
N,0.973,"λ
< γ <
1 −aλ +
√ 1 −2"
N,0.974,S a2λ2
N,0.975,"λ
,
(163)"
N,0.976,which indicates a constraint on λ: aλ < √ S
N,0.977,"2 .
(164)"
N,0.978,"If γ is allowed to be non-negative, the optimal value can only be 0 due to the convergence condition.
Therefore, a negative optimal γ requires an upper bound on it being negative, namely"
N,0.979,"1 −aλ +
√ 1 −2"
N,0.98,S a2λ2
N,0.981,"λ
< 0.
(165)"
N,0.982,"Solving it, we have"
N,0.983,"aλ >
2
1 + 2"
N,0.984,"S
.
(166)"
N,0.985,"By combining with Eq. (164), a necessary condition for the existence of a negative optimal γ is"
N,0.986,"2
1 + 2 S
< √ S"
N,0.987,"2 →(S −2)2 > 0 →S ≠2.
(167)"
N,0.988,"Hence, a negative optimal γ exists, if and only if"
N,0.989,"2
1 + 2"
N,0.99,"S
< aλ < √ S"
N,0.991,"2 , and S ≠2.
(168)"
N,0.992,"For higher dimension with Γ = γID, it is possible to calculate the optimal γ for minimizing the test
loss (11) as well. Speciﬁcally, the condition is given by"
N,0.993,"d
dγ Ltest ∶= 1"
D,0.994,"2
d
dγ
f(γ)
g(γ) = 0,
(169) where"
D,0.995,f(γ) ∶= γ2Tr[AK−2 (ID + λ
D,0.996,"S A2K−1G−1)U],
(170)"
D,0.997,g(γ) ∶= 1 −λ
D,0.998,"S Tr[A2K−1G−1].
(171)"
D,0.999,"Although it is impossible to solve the equation analytically, it can be solved numerically."
