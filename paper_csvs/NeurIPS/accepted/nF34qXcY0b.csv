Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.00211864406779661,"This paper focuses on the system identification of an important class of nonlinear
systems: nonlinear systems that are linearly parameterized, which enjoy wide
applications in robotics and other mechanical systems. We consider two system
identification methods: least-squares estimation (LSE), which is a point estimation
method; and set-membership estimation (SME), which estimates an uncertainty
set that contains the true parameters. We provide non-asymptotic convergence
rates for LSE and SME under i.i.d. control inputs and control policies with i.i.d.
random perturbations, both of which are considered as non-active-exploration
inputs. Compared with the counter-example based on piecewise-affine systems
in the literature, the success of non-active exploration in our setting relies on a
key assumption about the system dynamics: we require the system functions to
be real-analytic. Our results, together with the piecewise-affine counter-example,
reveal the importance of differentiability in nonlinear system identification through
non-active exploration. Lastly, we numerically compare our theoretical bounds
with the empirical performance of LSE and SME on a pendulum example and a
quadrotor example."
INTRODUCTION,0.00423728813559322,"1
Introduction"
INTRODUCTION,0.006355932203389831,"Learning control-dynamical systems with statistical methodology has received significant attention in
the past decade (Sarker et al., 2023; Li et al., 2023b; Chen and Hazan, 2021; Simchowitz and Foster,
2020; Wagenmaker and Jamieson, 2020; Simchowitz et al., 2018; Dean et al., 2018; Abbasi-Yadkori
and Szepesvári, 2011; Li et al., 2021b). In particular, the estimation of linear dynamical systems, e.g.
xt+1 = A∗xt+B∗ut+wt, is relatively well-studied: it has been shown that non-active exploration by
i.i.d. noises on control inputs ut and system disturbances wt are already enough for accurate system
identification, and least square estimation (LSE) can achieve the optimal estimation convergence rate
(Simchowitz and Foster, 2020; Simchowitz et al., 2018)."
INTRODUCTION,0.00847457627118644,"However, nonlinear control systems are ubiquitous in real-world applications, e.g. robotics (Siciliano
et al., 2010; Alaimo et al., 2013), power systems (Simpson-Porco et al., 2016), transportation (Kong
et al., 2015), etc. Motivated by this, there has been a lot of attention on learning nonlinear systems
recently. One natural and popular direction to study nonlinear system identification is on learning
linearly parameterized nonlinear systems as defined below, which is a straightforward extension from"
INTRODUCTION,0.01059322033898305,"the standard linear systems (Mania et al., 2022; Khosravi, 2023; Foster et al., 2020)"
INTRODUCTION,0.012711864406779662,"xt+1 = θ∗ϕ(xt, ut) + wt"
INTRODUCTION,0.014830508474576272,"where θ∗is a vector of unknown parameters and ϕ(xt, ut) is a known vector of nonlinear features."
INTRODUCTION,0.01694915254237288,"On the one hand, some classes of these systems are shown to enjoy similar benefits of linear systems.
For example, bilinear systems can also be estimated by LSE under non-active exploration with i.i.d.
noises (Sattar et al., 2022), as well as linear systems with randomly perturbed nonlinear policies (Li
et al., 2023b)."
INTRODUCTION,0.019067796610169493,"On the other hand, it is also known that non-active exploration is insufficient for general linearly
parameterized nonlinear systems. In particular, (Mania et al., 2022) provides a counter example
showing that non-active exploration is insufficient to learn accurate models under piece-wise affine
feature functions. This motivates a sequence of follow-up work on the design of active exploration
for nonlinear system estimation, which is largely motivated by the non-smooth feature functions such
as ReLu in neural networks (Mania et al., 2022; Kowshik et al., 2021; Khosravi, 2023)."
INTRODUCTION,0.0211864406779661,"However, there is a big gap between bilinear systems, which is infinitely differentiable, and the
counter example by non-smooth systems. A natural question is: to what extent can non-active
exploration still work for linearly parameterized nonlinear systems?"
INTRODUCTION,0.023305084745762712,"Contributions.
One major contribution of this paper is showing that LSE with non-active i.i.d.
noises can efficiently learn any linearly parameterized nonlinear systems with real-analytic feature
functions and provide a non-asymptotic convergence rate. Notice that real-analytic feature functions
are common in physical systems. For example, polynomial systems satisfy this requirement and have
wide applications in power systems (Simpson-Porco et al., 2016), fluid dynamics (Noack et al., 2003),
etc. Further, trigonometric functions also satisfy the real-analytic property so a large range of robotics
and mechanical systems also satisfy this requirement (Siciliano et al., 2010; Alaimo et al., 2013)."
INTRODUCTION,0.025423728813559324,"A side product of our LSE convergence rate analysis is the convergence rate for another commonly
used uncertainty quantification method in control: set membership estimation (SME)."
INTRODUCTION,0.02754237288135593,"Numerically, we test our theoretical results in pendulum and quadrotor systems. Simulations show
that LSE and SME can indeed efficiently explore the system and converge to the true parameter under
non-active exploration noises."
INTRODUCTION,0.029661016949152543,"Technically, the key step in our proof is establishing the block-martingale-small-ball condition
(BMSB) for general analytic feature functions, which greatly generalizes the bilinear feature function
in Sattar et al. (2022). Our result is built on an intuition inspired by the counter example in (Mania
et al., 2022): the counter example in (Mania et al., 2022) requires that some feature function is zero
in a certain region, so nothing can be learned about its parameter if the states stay in this region.
However, analytic functions cannot be a constant zero in a positive-measure region unless it is a
constant zero everywhere. Therefore, the counter example does not work, and non-active exploration
around any states can provide some useful information. Our proof formalizes this intuition by utilizing
the Paley-Zygmund Petrov inequality (Petrov, 2007)."
INTRODUCTION,0.03177966101694915,"Related work.
Inspired by neural network parameterization, nonlinear systems of the form xt+1 =
ϕ(A∗xt) + wt is also studied in the literature, where ϕ(·) is a known nonlinear link function and
A∗is unknown. The least square cost is no longer quadratic or even convex in this case and various
optimization methods have been proposed to learn this type of systems (Kowshik et al., 2021; Sattar
et al., 2022; Foster et al., 2020)."
INTRODUCTION,0.03389830508474576,"Another related line of research focuses on nonlinear regression with dependent data (Ziemann and
Tu, 2022; Ziemann et al., 2023, 2024),1 which can be applied to nonlinear system identification.
The nonlinear regression in (Ziemann and Tu, 2022; Ziemann et al., 2023, 2024) is based on non-
parametric LSE and its variants, and their convergence rates under different scenarios have been
analyzed. It is interesting to note that this line of work usually assumes certain persistent excitation
assumptions,2 whereas our paper demonstrates that persistent excitation holds by establishing the
BMSB condition for linearly parameterized and real-analytic nonlinear control systems."
INTRODUCTION,0.036016949152542374,"1yt = f∗(xt) + wt is considered, where xt and yt correlate with the historical data.
2For example, (Ziemann and Tu, 2022) assumes hyper-contractivity, and (Ziemann et al., 2024) assumes the
empirical covariance of the {xt}t≥0 process is invertible with high probability (Corollary 3.2)."
INTRODUCTION,0.038135593220338986,"Uncertainty set estimation is crucial for robust control under model uncertainties Lu and Cannon
(2023); Lorenzen et al. (2019); Li et al. (2021a). SME is a widely adopted uncertainty set estimation
method in robust adaptive control (Lorenzen et al., 2019; Lu and Cannon, 2023; Bertsekas, 1971; Bai
et al., 1995). Recently, there is an emerging interest in analyzing SME’s convergence and convergence
rate for dynamical systems (Li et al., 2024; Lu et al., 2019; Xu and Li, 2024), because previous
analysis focus more on the linear regression problem (e.g. (Akçay, 2004; Bai et al., 1998)). There are
also recent applications of SME to online control Yu et al. (2023), power systems Yeh et al. (2024),
and computer vision Gao et al. (2024); Tang et al. (2024)."
INTRODUCTION,0.04025423728813559,"Notation. The set of non-negative real numbers is denoted by R≥0. The notation ⌈·⌉stands for the
ceiling function. For a real vector z ∈Rn, ∥z∥2 represents its ℓ2 norm, ∥z∥∞represents its ℓ∞norm,
and zi represents its i-th component with i = 1 · · · n. The set of real symmetric matrices is denoted
by Sn. For a real matrix Z, Z⊺represents its transpose, ∥Z∥2 its maximum singular value, ∥Z∥F its
Frobenius norm, σmin(Z) its minimum singular value, vec(Z) its vectorization obtained by stacking
its columns, and for a real square matrix Z, tr(Z) represents its trace. For a real symmetric matrix
Z, Z ≻0 and Z ⪰0 indicate that Z is positive definite and positive semi-definite, respectively.
For a measurable set E ⊂Rn, λn(E) represents its Lebesgue measure in Rn and Ec represents its
complement in Rn. The notation ∅stands for the empty set. For a set T of matrices θ ∈Rn×m,
diam(T ) denotes its diameter and it is defined as diam(T ) = supθ,θ′∈T ∥θ −θ′∥F . For zi ∈R with
i = 1, · · · , ℓ, the notation diag(z1, · · · , zℓ) denotes a matrix in Rℓ×ℓwith diagonal entries of zi.
This paper uses truncated-Gaussian(0, σw, [−wmax, wmax]) to refer to the truncated Gaussian
distribution generated by Gaussian distribution with zero mean and σ2
w variance with truncated range
[−wmax, wmax]. The same applies to multi-variate truncated Gaussian distributions."
PROBLEM FORMULATION AND PRELIMINARIES,0.0423728813559322,"2
Problem Formulation and Preliminaries"
PROBLEM FORMULATION AND PRELIMINARIES,0.04449152542372881,This paper studies the system identification/estimation of linearly parameterized nonlinear systems:
PROBLEM FORMULATION AND PRELIMINARIES,0.046610169491525424,"xt+1 = θ∗ϕ
 
xt, ut

+ wt,
(1)"
PROBLEM FORMULATION AND PRELIMINARIES,0.048728813559322036,"where xt ∈Rnx, ut ∈Rnu, and wt ∈Rnx denote the state, control input, and system disturbance
respectively; θ∗∈Rnx×nϕ denotes the unknown parameters to be estimated, and ϕ(·) denotes a
vector of known nonlinear feature/basis functions, i.e., ϕ(·) = (ϕ1(·), · · · , ϕnϕ(·))⊺, where ϕi(·) :
Rnx+nu →R. Without loss of generality, we consider zero initial condition, i.e. x0 = 0, and linearly
independent feature functions, that is, Pnϕ
i=1 ciϕi(xt, ut) = 0 implies that ci = 0 for all i.3"
PROBLEM FORMULATION AND PRELIMINARIES,0.05084745762711865,"The linearly parameterized nonlinear system (1) is a natural generalization of linear control systems
xt+1 = A∗xt + B∗ut + wt and has wide applications in, for example, robotics (Siciliano et al.,
2010; Alaimo et al., 2013), power systems (Simpson-Porco et al., 2016), transportation (Kong et al.,
2015), etc. Therefore, there has been a lot of research on learning this type of system (1) utilizing the
methodology and insights from linear system estimation. For example, it is common to estimate a
linearly parameterized nonlinear system by least squares estimation (LSE), which enjoys desirable
performance in linear systems."
PROBLEM FORMULATION AND PRELIMINARIES,0.05296610169491525,"In particular, LSE for (1) is reviewed below"
PROBLEM FORMULATION AND PRELIMINARIES,0.05508474576271186,"ˆθT = arg min
ˆθ"
PROBLEM FORMULATION AND PRELIMINARIES,0.057203389830508475,"T −1
X t=0"
PROBLEM FORMULATION AND PRELIMINARIES,0.059322033898305086,"xt+1 −ˆθϕ(xt, ut)
2
2.
(2)"
PROBLEM FORMULATION AND PRELIMINARIES,0.0614406779661017,"For linear systems, LSE enjoys the following good property: LSE can achieve the optimal rate of
convergence with i.i.d. noises wt and i.i.d. control inputs ut under proper conditions ( (Simchowitz
et al., 2018)). This good property has been generalized to some linearly parameterized nonlinear
systems, such as bilinear systems, and linear systems with nonlinear control policies. Unfortunately,
general linearly parameterized nonlinear systems do not enjoy this good property of linear systems,
meaning i.i.d. random inputs may not provide enough exploration for non-smooth feature functions
ϕ(·). Therefore, a series of follow-up work focuses on the design of active exploration methods."
PROBLEM FORMULATION AND PRELIMINARIES,0.0635593220338983,"However, due to the simplicity of implementation, i.i.d. random inputs remain a popular method in
empirical research of system identification and sometimes enjoy satisfactory performance, despite"
PROBLEM FORMULATION AND PRELIMINARIES,0.06567796610169492,"3If the features are not independent, they can be converted to independent ones since the features are known."
PROBLEM FORMULATION AND PRELIMINARIES,0.06779661016949153,"the lack of theoretical guarantees. Therefore, this paper aims to establish more general conditions
that allow provable convergence of nonlinear system estimation under i.i.d. random inputs."
PROBLEM FORMULATION AND PRELIMINARIES,0.06991525423728813,"In the rest of this paper, we will show that with certain smoothness and continuous conditions, i.i.d.
random inputs are sufficient for estimation of (1), which recovers the good property of linear systems."
ASSUMPTIONS,0.07203389830508475,"2.1
Assumptions"
ASSUMPTIONS,0.07415254237288135,"In the following, we formally describe the smoothness and continuity conditions that enables efficient
exploration of (1) by i.i.d. random inputs."
ASSUMPTIONS,0.07627118644067797,"Assumption 1 (Analytic feature functions). All components of the feature vector ϕ(·) are real analytic
functions in Rnx+nu,4 i.e., for every 1 ≤i ≤nϕ, ϕi(x, u) is an infinitely differentiable function
such that the Taylor expansion in every (¯x, ¯u) converges point-wise to ϕi(x, u) in a neighborhood of
(¯x, ¯u)."
ASSUMPTIONS,0.07838983050847458,"Analytic functions include polynomial functions and trigonometric functions, which are important
components of many physical systems in real-world applications, e.g. power systems, robotics,
transportation systems, etc. In particular, we provide two illustrative examples below."
ASSUMPTIONS,0.08050847457627118,"Example 1 (Pendulum). Many multilink robotic manipulators can be understood as interconnected
pendulum dynamics. The motion equations of a single pendulum, consisting of a mass m suspended
from a weightless rod of length l fixed at a pivot without friction, can be expressed as:"
ASSUMPTIONS,0.0826271186440678,¨α = −g
ASSUMPTIONS,0.0847457627118644,"l sin(α) +
u
ml2 + w,"
ASSUMPTIONS,0.08686440677966102,"where α represents the angle of the rod relative to the vertical axis, g is the gravity constant, u is the
torque input, and w is the disturbance applied to this system. After discretization the system dynamics
can be rewritten in the structure of (1) with the feature vector consisting of expressions involving
sin(α) and u, all of which are analytic functions. The matrix of unknown parameters contains terms
of the pendulum’s mass and the rod’s length."
ASSUMPTIONS,0.08898305084745763,"Example 2 (Quadrotor (Alaimo et al., 2013)). Let p ∈R3 and v ∈R3 represent the center of
mass position and velocity of the quadrotor in the inertial frame, respectively; let ω ∈R3 denote its
angular velocity in the body-fixed frame and q ∈R4 denote the quaternion vector. The quadrotor’s
equations of motion can then be expressed as: d
dt  
"
ASSUMPTIONS,0.09110169491525423,"p
v
q
ω  
=  
"
ASSUMPTIONS,0.09322033898305085,"v
−gez + 1"
ASSUMPTIONS,0.09533898305084745,"mQfu
1
2Ωq
I−1(τu −ω × Iω) "
ASSUMPTIONS,0.09745762711864407,"
+ w,"
ASSUMPTIONS,0.09957627118644068,"where g is the gravity constant, m is its total mass, I = diag(Ixx, Iyy, Izz) its inertia matrix with
respect to the body-fixed frame, fu ∈R the total thrust, τu ∈R3 the total moment in the body-fixed"
ASSUMPTIONS,0.1016949152542373,"frame, ez = (0, 0, 1)⊺, Q = "
ASSUMPTIONS,0.1038135593220339,"
q2
0 + q2
1 −q2
2 −q2
3
2(q1q2 −q0q3)
2(q0q2 −q1q3)
2(q1q2 −q0q3)
q2
0 −q2
1 + q2
2 −q2
3
2(q2q3 −q0q1)
2(q1q3 −q0q2)
2(q0q1 −q2q3)
q2
0 −q2
1 −q2
2 + q2
3 "
ASSUMPTIONS,0.1059322033898305,", and Ω=  
"
ASSUMPTIONS,0.10805084745762712,"0
−ω1
−ω2
−ω3
ω1
0
ω3
−ω2
ω2
−ω3
0
ω1
ω3
ω2
−ω1
0  
."
ASSUMPTIONS,0.11016949152542373,"Similar to the pendulum example, after discretization the system dynamics can be rewritten in the
structure of (1) with the feature vector consisting of cubic polynomials in states and inputs, which
are real-analytic. The unknown parameters contain terms of the mass and inertial moments of the
quadrotor."
ASSUMPTIONS,0.11228813559322035,"Next, we introduce the assumption on the random inputs, which relies on the following definition."
ASSUMPTIONS,0.11440677966101695,"Definition 1 (Semi-continuous distribution). We define a probability distribution P as semi-continuous
if there does not exist a set E with Lebesgue measure zero such that P(E) = 1."
ASSUMPTIONS,0.11652542372881355,4This assumption can be relaxed to locally analytic functions in a large enough bounded set.
ASSUMPTIONS,0.11864406779661017,"The semi-continuous distribution is a weaker requirement than continuous distributions. In particular,
any continuous distributions, or a mixture distribution with one component as a continuous distribu-
tion, can satisfy the requirement of semi-continuity. The semi-continuity can also be interpreted by
the Lebesgue Decomposition Theorem (Chapter 6 of (Halmos, 2013)) as discussed below.
Remark 1 (Connection with Lebesgue Decomposition Theorem). Definition 1 can be interpreted
by the Lebesgue Decomposition Theorem, which suggests that any probability distribution can be
decomposed into a purely atomic component and a non-atomic component (see more details in
Halmos (2013)). A semi-continuous distribution as defined in Definition 1 requires the distribution’s
non-atomic component to be nonzero."
ASSUMPTIONS,0.12076271186440678,"In the following, we provide the assumptions on wt and ut using the semi-continuity definition.
Assumption 2 (Bounded i.i.d. and semi-continuous disturbance). wt is i.i.d. following a semi-
continuous distribution with zero mean and a positive definite covariance matrix Σw ⪰σ2
wInx ≻0
and a bounded support, i.e. ∥wt∥∞≤wmax almost surely for all t."
ASSUMPTIONS,0.1228813559322034,"The i.i.d. assumption is common in the literature of system identification for linear and nonlinear
systems. As for the bounded assumption on wt, although it is stronger than the sub-Gaussian
assumption on wt in the literature of linear system estimation, it is a common assumption in the
literature of nonlinear system estimation (Mania et al., 2022; Shi et al., 2021; Kim and Lavaei, 2024).
Further, in many physical applications, noises are usually bounded, e.g. the wind disturbances in
quadrotor systems are bounded, the renewable energy injections in power systems are also bounded,
etc."
ASSUMPTIONS,0.125,"The semi-continuity assumption may seem restrictive since it rules out the discrete distributions.
However, the disturbances in many realistic systems can satisfy the semi-continuity because realistic
noises are usually generated from a mixture distribution where at least one component is continuous,
e.g. the wind disturbances and renewable generations are continuous."
ASSUMPTIONS,0.1271186440677966,"For the control inputs ut, we first impose the same assumption as Assumption 2 for simplicity. Later
in Section 3, we will also discuss the relaxation of this assumption to include control policies.
Assumption 3 (Bounded i.i.d. and semi-continuous inputs). ut is i.i.d. following a semi-continuous
distribution with zero mean and positive definite covariance Σu ⪰σ2
uInx ≻0 and bounded support,
i.e. ∥ut∥∞≤umax almost surely for all t."
ASSUMPTIONS,0.1292372881355932,"Lastly, we introduce our stability assumption based on the input-to-state stability definition below.
Definition 2 (Locally input-to-state stability (LISS)). Consider the general nonlinear system xt+1 =
f(xt, dt) with xt ∈Rnx, dt ∈Rnd, f being a continuous function such that f(0, 0) = 0. This
system is called locally input-to-state stable (LISS) if there exist constants ρx > 0, ρ > 0 and
functions γ ∈K, β ∈KL such that for all x0 ∈{x0 ∈Rnx : ∥x0∥2 ≤ρx} and any input
dt ∈{d ∈Rnd : supt ∥dt∥∞≤ρ} , it holds that ∥xt∥2 ≤β
 
∥x0∥2, t

+ γ
 
supt ∥dt∥∞

for all
t ≥0.5"
ASSUMPTIONS,0.13135593220338984,"Assumption 4 (LISS system). System (1) is LISS with parameters ρx and ρ such that ρx ≥∥x0∥2
and ρ ≥max(wmax, umax), respectively."
ASSUMPTIONS,0.13347457627118645,"Assumption 4 is imposed, together with the bounded disturbances and inputs in Assumptions 2
and 3, to guarantee bounded states during the control dynamics (for instance, see the proof of
Theorem 1in Appendix A). In particular, many studies on learning-based nonlinear control require
a certain boundedness on the states for theoretical analysis Sattar and Oymak (2022); Foster et al.
(2020); Li et al. (2023a)."
ASSUMPTIONS,0.13559322033898305,"In addition, it is interesting to note that this paper only requires local stability of the dynamics, whereas
several learning-based nonlinear control papers assume certain global properties, such as global
exponential stability in (Foster et al., 2020), global exponential incremental stability in (Sattar and
Oymak, 2022; Li et al., 2023a; Lin et al., 2024), or global Lipschitz smoothness in (Lee et al., 2024).6
This difference in the dynamics assumption reflects a trade-off with the disturbance assumptions:"
ASSUMPTIONS,0.13771186440677965,"5A function γ : R≥0 →R≥0 is a K function if it is continuous, strictly increasing and γ(0) = 0. A function
β : R≥0 × R≥0 →R≥0 is a KL function if, for each fixed t ≥0, the function β(·, t) is a K function, and for
each fixed s ≥0, the function β(s, ·) is decreasing and β(s, t) →0 as t →∞.
6Global Lipschitz smoothness may exclude system dynamics with higher-order polynomials."
ASSUMPTIONS,0.13983050847457626,"we assume a stronger assumption on the boundedness of disturbances and a weaker assumption
on local stability, whereas much of the literature considers (sub)Gaussian distributions (which can
be unbounded) but requires stronger global properties for dynamics. Since this paper is largely
motivated by physical systems, which typically encounter bounded disturbances/inputs and generally
only satisfy local stability (Slotine and Li, 1991), we address this trade-off through our current set of
assumptions, leaving it as an exciting future direction to consider relaxing these assumptions."
MAIN RESULTS,0.1419491525423729,"3
Main Results"
MAIN RESULTS,0.1440677966101695,"In this section, we provide the estimation error bounds of LSE for linearly parameterized nonlinear
systems under i.i.d. random inputs. The estimation error bounds rely on the establishment of
probabilistic persistent excitation, which will be introduced in the first subsection. Later, we also
generalize the results to include control policies and discuss the convergence rate of another popular
uncertainty quantification method in the control literature, set membership estimation, whose formal
definition is deferred to the corresponding subsection."
PROBABILISTIC PERSISTENT EXCITATION,0.1461864406779661,"3.1
Probabilistic Persistent Excitation"
PROBABILISTIC PERSISTENT EXCITATION,0.1483050847457627,"It is well-known that persistent excitation (PE) is a crucial condition for successful system identifi-
cation (Narendra and Annaswamy, 1987). In the following, we introduce the persistent excitation
condition for our linearly parameterized nonlinear systems.
Definition 3 (Persistent excitation (Skantze et al., 2000; Sastry and Bodson, 2011)). System (1) is
persistently excited if there exist s > 0 and m ≥1 such that for any t0 ≥0, we have"
M,0.1504237288135593,"1
m"
M,0.15254237288135594,"t0+m−1
X"
M,0.15466101694915255,"t=t0
ϕ
 
xt, ut

ϕ⊺ 
xt, ut

⪰s2Inϕ."
M,0.15677966101694915,"In the stochastic setting, PE is closely related with a block-martingale small-ball (BMSB) condition
proposed in Simchowitz et al. (2018), which can be viewed as a probabilistic version of PE.
Definition 4 (BMSB (Simchowitz et al., 2018)). Let {Ft}t≥1 denote a filtration and let {yt}t≥1 be
an {Ft}t≥1-adapted random process taking values in Rny. We say {yt}t≥1 satisfies the (k, Γsb, p)-
block martingale small-ball (BMSB) condition for a positive integer k, a Γsb ≻0, and a p ∈[0, 1],
if for any fixed v ∈Rny such that ∥v∥2 = 1, the process {yt}t≥1 satisfies 1"
M,0.15889830508474576,"k
Pk
i=1 P
 
|v⊺yt+i| ≥
√v⊺Γsbv | Ft

≥p almost surely for any t ≥1."
M,0.16101694915254236,"One major contribution of this paper is formally establishing the BMSB condition for linearly
parameterized nonlinear systems with real-analytic feature functions."
M,0.163135593220339,"In the following, we first investigate the open-loop system with i.i.d. inputs and later extend the
results to the closed-loop systems with inputs ut = π(xt) + ηt, where ηt represents the noise and
π : Rnx →Rnu denotes a control policy. The following theorem considers the open-loop systems.
Theorem 1 (BMSB for open-loop systems). Let ut = ηt and consider the filtration Ft =
F(w0, · · · , wt−1, x0, · · · , xt, η0, · · · , ηt). Suppose Assumptions 1, 2, 3, 4 hold, then there ex-
ist sϕ > 0 and pϕ ∈(0, 1) such that the {Ft}t≥1-adapted process

ϕ
 
xt, ut
"
M,0.1652542372881356,"t≥1 satisfies the
 
1, s2
ϕInϕ, pϕ

-BMSB condition."
M,0.1673728813559322,"Proof Sketch. Intuitively, BMSB requires that any linear combination of feature functions remains
positive with a non-vanishing probability. Notice that a linear combination of real-analytic functions
is itself real-analytic, and the zeros of an analytic function have measure zero. These facts allow us to
show that the probability of a linear combination of linearly independent feature functions equaling
zero is less than one, as long as the noises follow semi-continuous distributions, by the connection of
the Lebesgue measure and the probability measure in Definition 1."
M,0.1694915254237288,"In more detail, the proof leverages a variant of the Paley-Zygmund argument (Petrov, 2007), which
provides a lower bound for the tail properties of positive random variables. Specifically, it states that
the probability of a positive random variable being small depends on the ratio of its even moments."
M,0.1716101694915254,"We apply this result to the random variable |vT ϕ
 
xt+1, ut+1

| Ft| with ∥v∥2 = 1 and aim to show
that the lower bound is non-trivial for any direction v with ∥v∥2 = 1 and any filtration Ft, t ≥0. We
then use results from measure theory to demonstrate the existence of such a non-trivial lower bound.
This is done by showing that the Lebesgue measure of the set where |vT ϕ
 
xt+1, ut+1

| = 0 is zero,
and thus the even moments of |vT ϕ
 
xt+1, ut+1

| Ft| are non-zero, provided that the noise and
disturbance distributions are semi-continuous. For further details, please refer to Appendix A."
M,0.17372881355932204,"It is worth pointing out that Theorem 1 only establishes the existence of the constants (sϕ, pϕ),
and deriving explicit formulas of these constants are left for future work. In particular, it can be
challenging to derive a generic formula for all linearly parameterized nonlinear systems, but an
exciting direction is to study reasonable sub-classes of systems and construct their corresponding
formulas of the constants (sϕ, pϕ)."
NON-ASYMPTOTIC BOUNDS FOR LSE,0.17584745762711865,"3.2
Non-asymptotic Bounds for LSE"
NON-ASYMPTOTIC BOUNDS FOR LSE,0.17796610169491525,"We are now prepared to present the non-asymptotic convergence rate for the LSE in learning the
unknown parameters of the system (1).
Theorem 2 (LSE’s convergence rate for open-loop systems). Consider the dynamical system de-
scribed in (1) with i.i.d. inputs ut = ηt and assume that Assumptions 1, 2, 3, 4 are satisfied. Let sϕ
and pϕ be as defined in Theorem 1, and define ¯bϕ = supt≥0 E

∥ϕ(zt)∥2
2

. For a fixed δ ∈(0, 1) and
T ≥1, if T satisfies the condition T ≥10 pϕ"
NON-ASYMPTOTIC BOUNDS FOR LSE,0.18008474576271186,"
log
1 δ"
NON-ASYMPTOTIC BOUNDS FOR LSE,0.18220338983050846,"
+ 2nϕ log
10 pϕ"
NON-ASYMPTOTIC BOUNDS FOR LSE,0.1843220338983051,"
+ nϕ log
 ¯bϕ δs2
ϕ 
,"
NON-ASYMPTOTIC BOUNDS FOR LSE,0.1864406779661017,then LSE’s estimation ˆθT satisfies the following error bound with probability at least 1 −3δ.
NON-ASYMPTOTIC BOUNDS FOR LSE,0.1885593220338983,"ˆθT −θ∗

2 ≤90σw pϕ"
NON-ASYMPTOTIC BOUNDS FOR LSE,0.1906779661016949,"v
u
u
u
tnx + log

1
δ"
NON-ASYMPTOTIC BOUNDS FOR LSE,0.19279661016949154,"
+ nϕ log

10
pϕ"
NON-ASYMPTOTIC BOUNDS FOR LSE,0.19491525423728814,"
+ nϕ log

¯bϕ
δs2
ϕ "
NON-ASYMPTOTIC BOUNDS FOR LSE,0.19703389830508475,"Ts2
ϕ
."
NON-ASYMPTOTIC BOUNDS FOR LSE,0.19915254237288135,"The proof relies on Theorem 1 and Theorem 2.4 in (Simchowitz et al., 2018). The complete proof is
provided in Appendix B.1."
NON-ASYMPTOTIC BOUNDS FOR LSE,0.20127118644067796,"Theorem 2 demonstrates that LSE converges to the true parameters under random control inputs and
random disturbances (non-active exploration) at a rate of
1
√"
NON-ASYMPTOTIC BOUNDS FOR LSE,0.2033898305084746,"T for linearly parameterized nonlinear
systems. This is consistent with the convergence rates of LSE for linear systems in terms of T."
NON-ASYMPTOTIC BOUNDS FOR LSE,0.2055084745762712,"Regarding the dependence of the convergence rate on dimension, the explicit dependence is
√nx + nϕ, where nx and nϕ refer to the dimensions of the state and the characteristic vector,
respectively. In addition, it is worth mentioning that other parameters, such as sϕ, pϕ,¯bϕ, may also
implicitly depend on the dimensions. For some special systems, such as bilinear systems, it has been
shown that these constants are independent of dimensions (Sattar et al., 2022). It is left as future work
to explore other nonlinear systems’ implicit dimension dependence."
NON-ASYMPTOTIC BOUNDS FOR LSE,0.2076271186440678,"Next, we can generalize the i.i.d. inputs ut to include control policies, i.e., ut = π(xt) + ηt, where
ηt satisfies Assumption 3 and π(xt) is analytic.
Corollary 1 (LSE’s convergence rate for closed-loop systems). Consider inputs ut = π(xt) +
ηt, where π(·) is real-analytic, ηt satisfies Assumption 3, and the closed-loop system xt+1 =
θ∗ϕ(xt, π(xt) + ηt) + wt satisfies Assumption 4 for both wt and ηt. Then, the same convergence
rate as in Theorem 2 holds."
NON-ASYMPTOTIC BOUNDS FOR LSE,0.2097457627118644,The proof is provided in Appendix B.2.
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.211864406779661,"3.3
Non-asymptotic Diameter Bounds for SME"
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.21398305084745764,"Set membership estimation (SME) is another popular method for uncertainty quantification in control
system estimation (Bertsekas, 1971; Fogel and Huang, 1982; Lu and Cannon, 2023; Li et al., 2024).
Unlike LSE, SME is a set-estimator and directly estimates the uncertainty set. Since the analysis
of SME also relies on the probabilistic persistent excitation analysis, we can also establish the"
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.21610169491525424,"convergence rate of SME for linearly parameterized nonlinear systems under i.i.d. noises in the
following. In particular, SME estimates the uncertainty set as ΘT ="
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.21822033898305085,"T −1
\ t=0"
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.22033898305084745,"
ˆθ : xt+1 −ˆθϕ(xt, ut) ∈W

,
(3)"
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.22245762711864406,where W is a bounded set such that wt ∈W for all t ≥0.
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2245762711864407,"The convergence of SME relies on an additional assumption as shown in the following: the tightness
of the bound W on the support of wt’. This tightness assumption is commonly considered in SME’s
literature (Li et al., 2024; Lu et al., 2019; Akçay, 2004). In addition, (Li et al., 2024) discusses the
relaxation of this assumption by learning a tight bound at the same time as learning the uncertainty
set of θ∗for linear systems. Similar tricks can be applied to nonlinear systems, but this paper only
considers the vanilla case of SME for simplicity."
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2266949152542373,"Assumption 5 (Tight bound on disturbances). Assume for any ϵ > 0, there exists qw(ϵ) > 0, such
that for any 1 ≤j ≤n and t ≥0, we have P(wj
t + wmax ≤ϵ) ≥qw(ϵ) > 0, P(wmax −wj
t ≤ϵ) ≥
qw(ϵ) > 0."
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2288135593220339,"Assumption 5 requires that wt can visit the boundary of the set W’ arbitrarily closely with a
positive probability. For example, for a one-dimensional wt bounded by −wmax ≤wt ≤wmax, the
assumption 5 requires that there is a positive probability that wt is close to wmax and −wmax, that is,
for any ϵ > 0, we have P(wmax −ϵ ≤wt ≤wmax) > 0 and P(−wmax ≤wt ≤−wmax + ϵ) > 0."
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2309322033898305,"Next, we state a non-asymptotic bound on the diameter of the uncertainty set estimated by SME."
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2330508474576271,"Theorem 3 (SME’s diameter bound for open-loop systems). Consider the system (1) with i.i.d. inputs
ut = ηt. Suppose Assumptions 1, 2, 3, 4 are satisfied. Consider sϕ and pϕ defined in Theorem 1 and
let bϕ = supt≥0 ∥ϕ(zt)∥2. For any m ≥0 and δ ∈(0, 1), when T > m, we have"
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.23516949152542374,"P

diam(ΘT ) > δ

≤T"
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.23728813559322035,"m
˜O
 
n2.5
ϕ

anϕ
2 exp(−a3m) + ˜O
 
n2.5
x n2.5
ϕ

anxnϕ
4"
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.23940677966101695,"
1 −qw  a1δ 4√nx  T m
,"
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.24152542372881355,where a1 = sϕpϕ
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.24364406779661016,"4 , a2 =
64b2
ϕ
s2
ϕp2
ϕ , a3 =
p2
ϕ
8 , a4 = 16bϕ
√nx
sϕpϕ
. The constants hidden in ˜O are provided in
the Appendix C.1."
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2457627118644068,"The proof of Theorem 3 is based on Theorem 1 in this paper and Theorem 1 from (Li et al., 2024).
The detailed proof is provided in Appendix C.1."
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2478813559322034,"Theorem 3 establishes an upper bound on the ""failure"" probability of SME, that is, the probability
that the diameter of the uncertainty set exceeds δ. To ensure that the failure probability is less than 1,
one can select m = O(log(T)) and choose a sufficiently large T such that T ≥m = O(log(T)). If
wt is more likely to visit the boundaries of the set W (meaning larger q(ℓ)), the SME is less likely to
estimate an uncertainty set with a diameter greater than δ."
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.25,"To provide more intuitions on the diameter bound in Theorem 3, we consider qw(ℓ) = cwℓfor some
cw > 0. Note that several common distributions, including the uniform distribution and the truncated
Gaussian distribution, satisfy this property on qw(ℓ) (see Appendix C.2 for explicit formulas of cw).
With qw(ℓ) = cwℓ, we can provide a convergence rate of the SME in terms of T in the following."
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2521186440677966,"Corollary 2 (SME’s convergence rate when qw(ℓ) = cwℓ). For any ϵ > 0, let m ≥O"
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2542372881355932,"log
  T"
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2563559322033898,"ϵ

+ nϕ log
  8bϕ"
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2584745762711864,"sϕpϕ
 p2
ϕ ! ."
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2605932203389831,"If wt’s distribution satisfies qw(ℓ) = cwℓfor all ℓ> 0, then when T > m, we have:"
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2627118644067797,diam(ΘT ) ≤O
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2648305084745763,"m√nx log
  1"
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2669491525423729,"ϵ

+ mn1.5
x nϕ log
  bϕnx"
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2690677966101695,"sϕpϕ
"
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2711864406779661,"cwsϕpϕT ! ,"
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2733050847457627,with probability at least 1 −2ϵ. Here the constants hidden in O(·) are provided in Appendix C.
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2754237288135593,The proof of Corollary 2 is provided in Appendix C.2.
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2775423728813559,"Finally, similar to LSE, we can extend SME’s convergence rates from open-loop systems to closed-
loop systems with real-analytic control policies, i.e., ut = π(xt) + ηt, where ηt satisfies Assumption
3 and π(xt) is real-analytic."
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2796610169491525,"Corollary 3 (SME’s convergence rate for closed-loop systems). Consider inputs ut = π(xt) +
ηt, where π(·) is real-analytic, ηt satisfies Assumption 3, and the closed-loop system xt+1 =
θ∗ϕ(xt, π(xt) + ηt) + wt satisfies Assumption 4 in terms of both wt and ηt. Then, the same
convergence rates as in Theorem 3 and Corollary 2 still hold."
NON-ASYMPTOTIC DIAMETER BOUNDS FOR SME,0.2817796610169492,The proof of Corollary 3 is provided in Appendix C.3.
NUMERICAL EXPERIMENTS,0.2838983050847458,"4
Numerical Experiments"
NUMERICAL EXPERIMENTS,0.2860169491525424,"In this section, we evaluate the performance of LSE in estimating the unknown parameter θ∗and
SME in estimating the uncertainty set for the unknown parameters using the pendulum and quadrotor
examples outlined in Section 2. We compare the empirical convergence rates of LSE and SME with
the theoretical rates in Theorem 2 and Corollary 2. In each case, the input ut is composed of a
control policy and i.i.d. noise, such that ut = π(xt) + ηt. For our experiments, we employ noise
and disturbances drawn from uniform and truncated-Gaussian distributions. To compute theoretical
rates, we numerically estimate parameters such as sϕ and pϕ (see Appendix E). Further details can be
found in our source code.7"
NUMERICAL EXPERIMENTS,0.288135593220339,The details for these scenarios are outlined below:
NUMERICAL EXPERIMENTS,0.2902542372881356,"• Pendulum 1: In the pendulum example described in Section 2, the control input is ut ="
NUMERICAL EXPERIMENTS,0.2923728813559322,−k ˙αt + ηt. This scenario includes two unknown parameters: θ1 = 1
NUMERICAL EXPERIMENTS,0.2944915254237288,"l and θ2 =
1
ml2 ."
NUMERICAL EXPERIMENTS,0.2966101694915254,"• Quadrotor 2: For the quadrotor example in Section 2, the control input is defined as
ut = π(xt) + ηt, where π(xt) follows the controller proposed by Alaimo et al. (2013). The
quadrotor system involves 13 states and 4 inputs, with the unknown parameter matrix θ∗
containing 7 parameters, including the mass m and specific elements of the inertia matrix I."
NUMERICAL EXPERIMENTS,0.298728813559322,Further details on controller gains and unknown parameters are provided in Appendix D.
NUMERICAL EXPERIMENTS,0.3008474576271186,"LSE Results:
Figures 1a and 1b present a comparison between the LSE theoretical bound from
Theorem 2 with its empirical estimation error of the unknown parameters θ∗versus trajectory length
T for the pendulum example, with uniform and truncated-Gaussian noises and disturbances. Similarly,
Figures 1c and 1d show this comparison for the quadrotor example. In each figure, both the theoretical
bound and empirical error are normalized by the l2 norm of the nominal parameter θ∗. The log-log
plots for both scenarios demonstrate that the empirical error rate achieves O( 1
√"
NUMERICAL EXPERIMENTS,0.3029661016949153,"T ) which in consistent
with the theoretical rate in Theorem 2."
NUMERICAL EXPERIMENTS,0.3050847457627119,"SME Results:
Figures 2a and 2b show the empirical convergence rate of SME for the pendulum
example, for uniform and truncated-Gaussian noises and disturbances, in comparison to the theoretical
rate from Corollary 2. Both the theoretical bound and empirical error in the figures are normalized by
the l2 norm of the nominal parameter θ∗. The log-log plots indicate that the empirical rate achieves
O( 1"
NUMERICAL EXPERIMENTS,0.3072033898305085,"T ), which is consistent with the results from Corollary 2 and with the related results for linear
systems in (Li et al., 2024). A similar result can be observed for the quadrotor example, in Figures 2c
and 2d. Additionally, Figure 3 shows the uncertainty sets estimated by SME for the two unknown
parameters, labeled θ1 and θ2, in the pendulum example, along with the diameters of these sets as
trajectory length grows. We observe that these sets contract as trajectory length increases, with the
true values of the unknown parameters lying within the estimated uncertainty sets. The illustration of
uncertainty sets for the quadrotor example is provided in Appendix D.2."
NUMERICAL EXPERIMENTS,0.3093220338983051,7https://github.com/NeginMusavi/real-analytic-nonlinear-sys-id
NUMERICAL EXPERIMENTS,0.3114406779661017,"(a) Uniform
(b) Truncated-Gaussian
(c) Uniform
(d) Truncated-Gaussian"
NUMERICAL EXPERIMENTS,0.3135593220338983,"Figure 1: Convergence rate of the LSE for pendulum and quadrotor scenarios: (a) Pendulum example with
uniform, (b) Pendulum example with truncated-Gaussian, (c) Quadrotor example with uniform, and (d) Quadrotor
example with truncated-Gaussian noises and disturbances. Here, uniform noises and disturbances are i.i.d.
generated from uniform([−1, 1]), and truncated-Gaussian noises and disturbances are i.i.d. generated from
truncated-Gaussian(0, 0.1, [−1, 1]). ""theo"" denotes the theoretical convergence rate, and ""empr"" represents
the empirical rate. The mean error across 20 trials is shown by dots on the empirical plots, with shaded areas
illustrating empirical standard deviation."
NUMERICAL EXPERIMENTS,0.3156779661016949,"(a) Uniform
(b) Truncated-Gaussian
(c) Uniform
(d) Truncated-Gaussian"
NUMERICAL EXPERIMENTS,0.3177966101694915,"Figure 2: Convergence rate of the SME for pendulum and quadrotor scenarios: (a) Pendulum example with
uniform, (b) Pendulum example with truncated-Gaussian, (c) Quadrotor example with uniform, and (d) Quadrotor
example with truncated-Gaussian noises and disturbances. Here, uniform noises and disturbances are i.i.d.
generated from uniform([−1, 1]), and truncated-Gaussian noises and disturbances are i.i.d. generated from
truncated-Gaussian(0, 0.5, [−1, 1]). ""theo"" denotes the theoretical convergence rate, and ""empr"" represents
the empirical rate. The mean error across 10 trials is shown by dots on the empirical plots, with shaded areas
illustrating empirical standard deviation."
CONCLUDING REMARKS,0.3199152542372881,"5
Concluding Remarks"
CONCLUDING REMARKS,0.3220338983050847,"Conclusion. This study examines the probabilistic persistent excitation in a class of nonlinear systems
influenced by i.i.d. noise and stochastic disturbances, with the stipulation that their distributions do
not concentrate on sets of Lebesgue measure zero. Based on this we then present an explicit bound
on the convergence rate of SME estimations and LSE estimations for this class of dynamical systems.
Additionally, numerical experiments in the context of robotics are provided to illustrate both methods."
CONCLUDING REMARKS,0.3241525423728814,"Limitations. One limitation of this work is that our analysis relies on a specific class of i.i.d. noises
and stochastic disturbances, where the probability distribution is not concentrated on sets of Lebesgue
measure zero. While this is a sufficient condition, it is possible that the BMSB conditions are satisfied
under other circumstances. Another limitation is that, though we provide sufficient conditions for the
existence of parameters satisfying the BMSB condition, the explicit dependence is not detailed here.
Lastly, imperfect observations are not considered here."
CONCLUDING REMARKS,0.326271186440678,"Future Work. Our future work includes several promising directions, e.g., to explore cases that do
not satisfy our semi-continuity assumption, such as discrete noises, and to investigate the explicit
dependence of the BMSB parameter on system attributes, such as state, input, and feature dimensions,
etc. Furthermore, extending this work to imperfect state observations is an important next step.
Finally, a potential direction is to provide a non-asymptotic analysis of the volumes of uncertainty
sets estimated by SME uncertainty sets, as opposed to the current focus on their diameters."
CONCLUDING REMARKS,0.3283898305084746,"(a) Pendulum
(b) Uncertainty set diameter
(c) Uncertainty set"
CONCLUDING REMARKS,0.3305084745762712,"Figure 3: Performance of SME for pendulum in (a) with control input ut = −k ˙αt + ηt where k = 0.1,
ηt i.i.d. generated from truncated-Gaussian(0, 2, [−2, 2]) and disturbed with wt i.i.d. generated from
truncated-Gaussian(0, 1, [−1, 1]). (b) Diameter of the uncertainty set estimated by SME. (c) Uncertainty
set depicted for T = 50, 200, 250, 400, 500."
CONCLUDING REMARKS,0.3326271186440678,Broader Impact
CONCLUDING REMARKS,0.3347457627118644,"This paper is a foundation research and develops theoretical insight to estimation of nonlinear control
systems. We do not see a direct path to negative applications in general. But we want to mention that
successful applications of our theoretical results rely on verifying the assumptions in this paper."
REFERENCES,0.336864406779661,References
REFERENCES,0.3389830508474576,"Yasin Abbasi-Yadkori and Csaba Szepesvári. Regret bounds for the adaptive control of linear
quadratic systems. In Proceedings of the 24th Annual Conference on Learning Theory, pages 1–26.
JMLR Workshop and Conference Proceedings, 2011."
REFERENCES,0.3411016949152542,"Hüseyin Akçay. The size of the membership-set in a probabilistic framework. Automatica, 40(2):
253–260, 2004."
REFERENCES,0.3432203389830508,"Andrea Alaimo, Valeria Artale, C Milazzo, Angela Ricciardello, and LUCA Trefiletti. Mathematical
modeling and control of a hexacopter. In 2013 International conference on unmanned aircraft
systems (ICUAS), pages 1043–1050. IEEE, 2013."
REFERENCES,0.3453389830508475,"Er-Wei Bai, Roberto Tempo, and Hyonyong Cho. Membership set estimators: size, optimal inputs,
complexity and relations with least squares.
IEEE Transactions on Circuits and Systems I:
Fundamental Theory and Applications, 42(5):266–277, 1995."
REFERENCES,0.3474576271186441,"Er-Wei Bai, Hyonyong Cho, and Roberto Tempo. Convergence properties of the membership set.
Automatica, 34(10):1245–1249, 1998."
REFERENCES,0.3495762711864407,"Dimitri P Bertsekas. Control of uncertain systems with a set-membership description of the uncertainty.
PhD thesis, Massachusetts Institute of Technology, 1971."
REFERENCES,0.3516949152542373,"Vladimir Igorevich Bogachev and Maria Aparecida Soares Ruas. Measure theory, volume 1. Springer,
2007."
REFERENCES,0.3538135593220339,"Xinyi Chen and Elad Hazan. Black-box control for linear dynamical systems. In Conference on
Learning Theory, pages 1114–1143. PMLR, 2021."
REFERENCES,0.3559322033898305,"Alexandru Cr˘aciun and Debarghya Ghoshdastidar. On the stability of gradient descent for large
learning rate. arXiv preprint arXiv:2402.13108, 2024."
REFERENCES,0.3580508474576271,"Sarah Dean, Horia Mania, Nikolai Matni, Benjamin Recht, and Stephen Tu. Regret bounds for robust
adaptive control of the linear quadratic regulator. Advances in Neural Information Processing
Systems, 31:4188–4197, 2018."
REFERENCES,0.3601694915254237,"Eli Fogel and Yih-Fang Huang. On the value of information in system identification—bounded noise
case. Automatica, 18(2):229–238, 1982."
REFERENCES,0.3622881355932203,"Dylan Foster, Tuhin Sarkar, and Alexander Rakhlin. Learning nonlinear dynamical systems from a
single trajectory. In Learning for Dynamics and Control, pages 851–861. PMLR, 2020."
REFERENCES,0.3644067796610169,"Yihuai Gao, Yukai Tang, Han Qi, and Heng Yang. Closure: Fast quantification of pose uncertainty
sets. arXiv preprint arXiv:2403.09990, 2024."
REFERENCES,0.3665254237288136,"Paul R Halmos. Measure theory, volume 18. Springer, 2013."
REFERENCES,0.3686440677966102,"Mohammad Khosravi. Representer theorem for learning koopman operators. IEEE Transactions on
Automatic Control, 2023."
REFERENCES,0.3707627118644068,"Jihun Kim and Javad Lavaei. Online bandit control with dynamic batch length and adaptive learning
rate. 2024."
REFERENCES,0.3728813559322034,"Jason Kong, Mark Pfeiffer, Georg Schildbach, and Francesco Borrelli. Kinematic and dynamic vehicle
models for autonomous driving control design. In 2015 IEEE intelligent vehicles symposium (IV),
pages 1094–1099. IEEE, 2015."
REFERENCES,0.375,"Suhas Kowshik, Dheeraj Nagaraj, Prateek Jain, and Praneeth Netrapalli. Near-optimal offline and
streaming algorithms for learning non-linear dynamical systems. Advances in Neural Information
Processing Systems, 34:8518–8531, 2021."
REFERENCES,0.3771186440677966,"Steven G Krantz and Harold R Parks. A primer of real analytic functions. Springer Science &
Business Media, 2002."
REFERENCES,0.3792372881355932,"Bruce D Lee, Ingvar Ziemann, George J Pappas, and Nikolai Matni. Active learning for control-
oriented identification of nonlinear systems. arXiv preprint arXiv:2404.09030, 2024."
REFERENCES,0.3813559322033898,"Yingying Li, Subhro Das, and Na Li. Online optimal control with affine constraints. In Proceedings
of the AAAI Conference on Artificial Intelligence, volume 35, pages 8527–8537, 2021a."
REFERENCES,0.3834745762711864,"Yingying Li, Yujie Tang, Runyu Zhang, and Na Li. Distributed reinforcement learning for decentral-
ized linear quadratic control: A derivative-free policy optimization approach. IEEE Transactions
on Automatic Control, 67(12):6429–6444, 2021b."
REFERENCES,0.3855932203389831,"Yingying Li, James A Preiss, Na Li, Yiheng Lin, Adam Wierman, and Jeff S Shamma. Online
switching control with stability and regret guarantees. In Learning for Dynamics and Control
Conference, pages 1138–1151. PMLR, 2023a."
REFERENCES,0.3877118644067797,"Yingying Li, Tianpeng Zhang, Subhro Das, Jeff Shamma, and Na Li. Non-asymptotic system
identification for linear systems with nonlinear policies. IFAC-PapersOnLine, 56(2):1672–1679,
2023b."
REFERENCES,0.3898305084745763,"Yingying Li, Jing Yu, Lauren Conger, Taylan Kargin, and Adam Wierman. Learning the uncertainty
sets of linear control systems via set membership: A non-asymptotic analysis. In Proceedings of
the 41st International Conference on Machine Learning, pages 29234–29265. PMLR, 2024. URL
https://proceedings.mlr.press/v235/li24ci.html."
REFERENCES,0.3919491525423729,"Yiheng Lin, James A Preiss, Emile Anand, Yingying Li, Yisong Yue, and Adam Wierman. On-
line adaptive policy selection in time-varying systems: No-regret via contractive perturbations.
Advances in Neural Information Processing Systems, 36, 2024."
REFERENCES,0.3940677966101695,"Matthias Lorenzen, Mark Cannon, and Frank Allgöwer. Robust mpc with recursive model update.
Automatica, 103:461–471, 2019."
REFERENCES,0.3961864406779661,"Xiaonan Lu and Mark Cannon. Robust adaptive model predictive control with persistent excitation
conditions. Automatica, 152:110959, 2023."
REFERENCES,0.3983050847457627,"Xiaonan Lu, Mark Cannon, and Denis Koksal-Rivet. Robust adaptive model predictive control:
Performance and parameter estimation. International Journal of Robust and Nonlinear Control,
2019."
REFERENCES,0.4004237288135593,"Horia Mania, Michael I Jordan, and Benjamin Recht. Active learning for nonlinear system identifica-
tion with guarantees. Journal of Machine Learning Research, 23(32):1–30, 2022."
REFERENCES,0.4025423728813559,"Kumpati S Narendra and Anuradha M Annaswamy. Persistent excitation in adaptive systems.
International Journal of Control, 45(1):127–160, 1987."
REFERENCES,0.4046610169491525,"Bernd R Noack, Konstantin Afanasiev, Marek Morzy´nski, Gilead Tadmor, and Frank Thiele. A
hierarchy of low-dimensional models for the transient and post-transient cylinder wake. Journal of
Fluid Mechanics, 497:335–363, 2003."
REFERENCES,0.4067796610169492,"Valentin V Petrov. On lower bounds for tail probabilities. Journal of statistical planning and
inference, 137(8):2703–2705, 2007."
REFERENCES,0.4088983050847458,"Arnab Sarker, Peter Fisher, Joseph E Gaudio, and Anuradha M Annaswamy. Accurate parameter
estimation for safety-critical systems with unmodeled dynamics. Artificial Intelligence, page
103857, 2023."
REFERENCES,0.4110169491525424,"Shankar Sastry and Marc Bodson. Adaptive control: stability, convergence and robustness. Courier
Corporation, 2011."
REFERENCES,0.413135593220339,"Yahya Sattar and Samet Oymak. Non-asymptotic and accurate learning of nonlinear dynamical
systems. Journal of Machine Learning Research, 23(140):1–49, 2022."
REFERENCES,0.4152542372881356,"Yahya Sattar, Samet Oymak, and Necmiye Ozay. Finite sample identification of bilinear dynamical
systems. In 2022 IEEE 61st Conference on Decision and Control (CDC), pages 6705–6711. IEEE,
2022."
REFERENCES,0.4173728813559322,"Guanya Shi, Kamyar Azizzadenesheli, Michael O’Connell, Soon-Jo Chung, and Yisong Yue. Meta-
adaptive nonlinear control: Theory and algorithms. Advances in Neural Information Processing
Systems, 34:10013–10025, 2021."
REFERENCES,0.4194915254237288,"B. Siciliano, L. Sciavicco, L. Villani, and G. Oriolo. Robotics: Modelling, Planning and Con-
trol. Advanced Textbooks in Control and Signal Processing. Springer London, 2010. ISBN
9781846286414. URL https://books.google.com/books?id=jPCAFmE-logC."
REFERENCES,0.4216101694915254,"Max Simchowitz and Dylan Foster. Naive exploration is optimal for online lqr. In International
Conference on Machine Learning, pages 8937–8948. PMLR, 2020."
REFERENCES,0.423728813559322,"Max Simchowitz, Horia Mania, Stephen Tu, Michael I Jordan, and Benjamin Recht. Learning without
mixing: Towards a sharp analysis of linear system identification. In Conference On Learning
Theory, pages 439–473. PMLR, 2018."
REFERENCES,0.4258474576271186,"John W Simpson-Porco, Florian Dörfler, and Francesco Bullo. Voltage stabilization in microgrids via
quadratic droop control. IEEE Transactions on Automatic Control, 62(3):1239–1253, 2016."
REFERENCES,0.4279661016949153,"Fredrik P Skantze, A Koji´c, A-P Loh, and Anuradha M Annaswamy. Adaptive estimation of
discrete-time systems with nonlinear parameterization. Automatica, 36(12):1879–1887, 2000."
REFERENCES,0.4300847457627119,"Jean-Jacques E Slotine and Weiping Li. Applied nonlinear control, volume 199. Prentice hall
Englewood Cliffs, NJ, 1991."
REFERENCES,0.4322033898305085,"Yukai Tang, Jean-Bernard Lasserre, and Heng Yang. Uncertainty quantification of set-membership
estimation in control and perception: Revisiting the minimum enclosing ellipsoid. In 6th Annual
Learning for Dynamics & Control Conference, pages 286–298. PMLR, 2024."
REFERENCES,0.4343220338983051,"Andrew Wagenmaker and Kevin Jamieson. Active learning for identification of linear dynamical
systems. In Conference on Learning Theory, pages 3487–3582. PMLR, 2020."
REFERENCES,0.4364406779661017,"Haonan Xu and Yingying Li. On the convergence rates of set membership estimation of linear
systems with disturbances bounded by general convex sets. arXiv preprint arXiv:2406.00574,
2024."
REFERENCES,0.4385593220338983,"Christopher Yeh, Jing Yu, Yuanyuan Shi, and Adam Wierman. Online learning for robust voltage
control under uncertain grid topology. IEEE Transactions on Smart Grid, 2024."
REFERENCES,0.4406779661016949,"Jing Yu, Dimitar Ho, and Adam Wierman. Online adversarial stabilization of unknown networked
systems. Proceedings of the ACM on Measurement and Analysis of Computing Systems, 7(1):1–43,
2023."
REFERENCES,0.4427966101694915,"Ingvar Ziemann and Stephen Tu. Learning with little mixing. Advances in Neural Information
Processing Systems, 35:4626–4637, 2022."
REFERENCES,0.4449152542372881,"Ingvar Ziemann, Anastasios Tsiamis, Bruce Lee, Yassir Jedra, Nikolai Matni, and George J Pappas.
A tutorial on the non-asymptotic theory of system identification. In 2023 62nd IEEE Conference
on Decision and Control (CDC), pages 8921–8939. IEEE, 2023."
REFERENCES,0.4470338983050847,"Ingvar Ziemann, Stephen Tu, George J Pappas, and Nikolai Matni. Sharp rates in dependent learning
theory: Avoiding sample size deflation for the square loss. arXiv preprint arXiv:2402.05928, 2024."
REFERENCES,0.4491525423728814,Appendix
REFERENCES,0.451271186440678,Roadmap
REFERENCES,0.4533898305084746,• Appendix A provides a proof of Theorem 1.
REFERENCES,0.4555084745762712,• Appendix B provides proofs of Theorem 2 and Corollary 1.
REFERENCES,0.4576271186440678,• Appendix C presents a proof of Theorem 3 and Corollaries 2 and 3.
REFERENCES,0.4597457627118644,• Appendix D provides more details of the simulation settings.
REFERENCES,0.461864406779661,"• Appendix E discusses the numerical estimation of the BMSB parameters (sϕ, pϕ) in Theo-
rem 1."
REFERENCES,0.4639830508474576,• The NeurIPS Paper Checklist is provided after the appendices.
REFERENCES,0.4661016949152542,"A
Proof Theorem 1"
REFERENCES,0.4682203389830508,"Proof. Given that ut = ηt and satisfies the conditions in Assumption 3, ut is bounded, meaning
ut ∈U, where U is a compact set. Moreover, since the system is LISS, there exist functions γ ∈K
and β ∈KL, such that for all t ≥0, the following holds:"
REFERENCES,0.4703389830508475,"xt ∈X =

x ∈Rn : ∥x∥2 ≤β(ρx, 0) + γ(ρ)
"
REFERENCES,0.4724576271186441,"with parameters ρx ≥∥x0∥2 and ρ ≥max(wmax, umax). Let Z = X × U, then zt ∈Z for all t ≥0.
The set Z is a compact subset of Rnx+nu."
REFERENCES,0.4745762711864407,"To show that the {Ft}t≥1-adapted process {ϕ(zt)}t≥1 satisfies the BMSB condition, it is sufficient
to demonstrate that there exist sϕ > 0 and pϕ ∈(0, 1) such that for all t ≥0 and for any v ∈Rnϕ
with ∥v∥2 = 1, the following holds:"
REFERENCES,0.4766949152542373,"P

|vT ϕ(zt+1)| ≥sϕ∥v∥2
 Ft"
REFERENCES,0.4788135593220339,"
≥pϕ.
(4)"
REFERENCES,0.4809322033898305,"To establish this, we apply the Paley-Zygmund inequality, which gives a lower bound on the tail
probability of a non-negative random variable:"
REFERENCES,0.4830508474576271,"Lemma 1. (Paley-Zygmund (Petrov, 2007)) Let x be a non-negative random variable. Then for any
r ∈(0, 1), the following holds:"
REFERENCES,0.4851694915254237,"P

x > r
p"
REFERENCES,0.4872881355932203,"E[x2]

≥(1 −r2)2 E[x2]2"
REFERENCES,0.4894067796610169,E[x4] .
REFERENCES,0.4915254237288136,"Based on this result, for any r ∈(0, 1), we have: P"
REFERENCES,0.4936440677966102,"v⊺ϕ(zt+1)
 > r s"
REFERENCES,0.4957627118644068,"E
 
v⊺ϕ(zt+1)
2  Ft"
REFERENCES,0.4978813559322034,  Ft !
REFERENCES,0.5,"≥(1 −r2)2
E
 
v⊺ϕ(zt+1)
2  Ft 2"
REFERENCES,0.5021186440677966,"E
 
v⊺ϕ(zt+1)
4  Ft"
REFERENCES,0.5042372881355932," .
(5)"
REFERENCES,0.5063559322033898,"Let V = {v ∈Rnϕ : ∥v∥2 = 1}. To show that the BMSB condition holds, it is sufficient to establish
the following two points:"
REFERENCES,0.5084745762711864,"•
inf
Ft, t≥0 inf
v∈V E
 
v⊺ϕ(zt+1)
2  Ft

> 0,"
REFERENCES,0.510593220338983,"• and
sup
Ft, t≥0
sup
v∈V
E
 
v⊺ϕ(zt+1)
4  Ft

< ∞."
REFERENCES,0.5127118644067796,"These conditions ensure that the {Ft}t≥1-adapted process {ϕ(zt)}t≥1 satisfies the BMSB condition
with some constants sϕ > 0 and pϕ ∈(0, 1). We will divide the proof into two parts:"
REFERENCES,0.5148305084745762,"Step 1. Showing that
inf
Ft, t≥0 inf
v∈V E
 
v⊺ϕ(zt+1)
2  Ft

> 0:"
REFERENCES,0.5169491525423728,We begin by noting the following:
REFERENCES,0.5190677966101694,"inf
Ft, t≥0 inf
v∈V E
 
v⊺ϕ(zt+1)
2  Ft"
REFERENCES,0.5211864406779662,"
=
inf
Ft, t≥0 inf
v∈V E
 
v⊺ϕ
 
xt+1, ut+1
2  Ft "
REFERENCES,0.5233050847457628,"=
inf
Ft, t≥0 inf
v∈V E
 
v⊺ϕ
 
θ∗ϕ(zt) + wt, ut+1
2  Ft 
."
REFERENCES,0.5254237288135594,"Since zt ∈Ft while wt, ut+1 ̸∈Ft, we can treat zt as a constant and wt, ut+1 = ηt+1 as random
variables. From the continuity of features ϕ(·), we can conclude that:"
REFERENCES,0.527542372881356,"inf
Ft, t≥0 inf
v∈V E
 
v⊺ϕ(zt+1)
2  Ft"
REFERENCES,0.5296610169491526,"
= inf
z∈Z inf
v∈V E
 
v⊺ϕ
 
θ∗ϕ(z) + w
|
{z
}
=: h(z,w)"
REFERENCES,0.5317796610169492,", η
2

,"
REFERENCES,0.5338983050847458,"where w, η are independent random variables, as assumed in Assumptions 2 and 3. Now, let
N z
v =

(w, η) ∈W × U : v⊺ϕ
 
h(z, w), η

= 0
	
, and we have:"
REFERENCES,0.5360169491525424,"E
 
v⊺ϕ
 
h(z, w), η
2

= E
 
v⊺ϕ
 
h(z, w), η
21

v⊺ϕ
 
h(z, w), η

= 0
	"
REFERENCES,0.538135593220339,"|
{z
}
=0"
REFERENCES,0.5402542372881356,"+ E
 
v⊺ϕ
 
h(z, w), η
21

v⊺ϕ
 
h(z, w), η

̸= 0
	"
REFERENCES,0.5423728813559322,"= E
 
v⊺ϕ
 
h(z, w), η
2  (w, η) ̸∈N z
v"
REFERENCES,0.5444915254237288,"
P

(w, η) ̸∈N z
v "
REFERENCES,0.5466101694915254,"= E
 
v⊺ϕ
 
h(z, w), η
2  (w, η) ̸∈N z
v"
REFERENCES,0.548728813559322,"
1 −P

(w, η) ∈N z
v 
."
REFERENCES,0.5508474576271186,"Therefore, we have:"
REFERENCES,0.5529661016949152,"inf
z∈Z inf
v∈V E
 
v⊺ϕ
 
h(z, w), η
2

= inf
z∈Z inf
v∈V E
 
v⊺ϕ
 
h(z, w), η
2  (w, η) ̸∈N z
v "
REFERENCES,0.5550847457627118,"×

1 −sup
z∈Z
sup
v∈V
P

(w, η) ∈N z
v"
REFERENCES,0.5572033898305084,"
.
(6)"
REFERENCES,0.559322033898305,"It is evident that if N z
v = ∅, then"
REFERENCES,0.5614406779661016,"inf
z∈Z inf
v∈V E
 
v⊺ϕ
 
h(z, w), η
2

̸= 0, and sup
z∈Z
sup
v∈V
P

(w, η) ∈N z
v"
REFERENCES,0.5635593220338984,"
= 0,"
REFERENCES,0.565677966101695,"leading to inf
z∈Z inf
v∈V E
 
v⊺ϕ
 
h(z, w), η
2

> 0. Now we proceed with the case where N z
v ̸= ∅."
REFERENCES,0.5677966101694916,"For this, we can use the following lemma concerning the zero set of real-analytic functions in terms
of Lebesgue measure."
REFERENCES,0.5699152542372882,"Lemma 2 (The zero set of real-analytic functions (Cr˘aciun and Ghoshdastidar, 2024)). The set of
zeros of a non-trivial real-analytic function f : Rn →R has a Lebesgue measure zero in Rn."
REFERENCES,0.5720338983050848,"This is a known result and can be proved using the identity theorem along with Fubini’s theorem. For
further information on this topic, see sources such as (Krantz and Parks, 2002; Bogachev and Ruas,
2007)."
REFERENCES,0.5741525423728814,"Recall that we defined h(z, w) = θ∗ϕ(z) + w. Notice that h(·, ·) is real-analytic. Now consider"
REFERENCES,0.576271186440678,"v⊺ϕ
 
h(z, w), η

= nϕ
X"
REFERENCES,0.5783898305084746,"i=1
viϕi 
h(z, w), η

,"
REFERENCES,0.5805084745762712,"where ϕi 
h(z, w), η

are linearly independent. Hence, the sum Pnϕ
i=1 viϕi 
h(z, w), η

̸≡0 for any
v ∈V. This implies that v⊺ϕ
 
h(z, w), η

is real-analytic and non-zero. Consequently, by Lemma 2,
λnx+nu(N z
v ) = 0 for any v ∈V."
REFERENCES,0.5826271186440678,"Under Assumptions 3 and 2, there cannot exist a set E ⊂Z of Lebesgue measure zero in Rnx+nu for
which the P
 
(w, η) ∈E

= 1. Taking this into account, along with the fact that λnx+nu(N z
v ) = 0
and that the sets V and Z are closed sets (implying they include all their limit points), we can conclude
that"
REFERENCES,0.5847457627118644,"sup
z∈Z
sup
v∈V
P

(w, η) ∈N z
v"
REFERENCES,0.586864406779661,"
̸= 1."
REFERENCES,0.5889830508474576,"Moreover, since λnx+nu(N z
v ) = 0 and λnx+nu(W × U) ̸= 0, it follows that (N z
v )c ̸= ∅. This
implies"
REFERENCES,0.5911016949152542,"inf
z∈Z inf
v∈V E
 
v⊺ϕ
 
h(z, w), η
2  (w, η) ̸∈N z
v"
REFERENCES,0.5932203389830508,"
̸= 0."
REFERENCES,0.5953389830508474,"Substituting these results into (6), we obtain:"
REFERENCES,0.597457627118644,"inf
Ft, t≥0 inf
v∈V E
 
v⊺ϕ(zt+1)
2  Ft

> 0."
REFERENCES,0.5995762711864406,"Step 2. Showing that
sup
Ft, t≥0
sup
v∈V
E
 
v⊺ϕ(zt+1)
4  Ft

< ∞:"
REFERENCES,0.6016949152542372,"Since zt ∈Z for t ≥0, and considering that the noise and disturbances are bounded while the
features are real-analytic, it follows that zt+1|Ft is a bounded random variable. Consequently,
v⊺ϕ(zt+1)|Ft is also bounded. Given that both Z and V are compact sets—meaning they contain
all their limit points—and that any random variable with bounded support has finite moments, we
conclude that
sup
Ft, t≥0
sup
v∈V
E
 
v⊺ϕ(zt+1)
4  Ft

< ∞."
REFERENCES,0.6038135593220338,We finalize the proof by combining the results from Step 1 and Step 2.
REFERENCES,0.6059322033898306,"B
Proofs for Theorem 2 and Corollary 1"
REFERENCES,0.6080508474576272,"B.1
Proof of Theorem 2"
REFERENCES,0.6101694915254238,Proof. The proof hinges on the following key meta-theorem about the LSE convergence rate:
REFERENCES,0.6122881355932204,"Theorem 4 (LSE meta-theorem (Simchowitz et al., 2018)). Fix δ ∈(0, 1), T ≥1, and 0 ≺Γsb ≺¯Γ.
Consider a random process {(yt, xt)}t≥1 ∈(Rny × Rnx)T , and a filtration {Ft}t≥1. Suppose the
following conditions hold:"
REFERENCES,0.614406779661017,"• xt = θ∗yt + wt, where wt|Ft is a zero mean σ2
w-sub-Gaussian,"
REFERENCES,0.6165254237288136,"• {yt}t≥1 is an {Ft}t≥1-adapted random process satisfying the (k, Γsb, p)-BMSB condition,"
REFERENCES,0.6186440677966102,"• P
  PT
t=1 yty⊺
t ̸⪯T ¯Γ

≤δ."
REFERENCES,0.6207627118644068,If the trajectory length T satisfies
REFERENCES,0.6228813559322034,T ≥10k p2 
REFERENCES,0.625,"log
1 δ"
REFERENCES,0.6271186440677966,"
+ log det

¯ΓΓ−1
sb"
REFERENCES,0.6292372881355932,"
+ 2ny log
10 p ! ,"
REFERENCES,0.6313559322033898,"then with probability at least 1 −3δ, LSE estimation error is bounded by:"
REFERENCES,0.6334745762711864,"ˆθT −θ∗

2 ≤90σw p"
REFERENCES,0.635593220338983,"v
u
u
u
tnx + log

1
δ"
REFERENCES,0.6377118644067796,"
+ log det

¯ΓΓ−1
sb"
REFERENCES,0.6398305084745762,"
+ ny log

10 p "
REFERENCES,0.6419491525423728,"Tσmin(Γsb)
."
REFERENCES,0.6440677966101694,"Since wt satisfies the Assumption 2), and wt /∈Ft, then σw|Ft is sub-Gaussian with parameter σw.
Additionally, system (1) is linear in unknown parameters θ∗. From Theorem 1, the {Ft}t≥1-adapted
process {ϕ(zt)}t≥1 satisfies the (1, s2
ϕInϕ, pϕ)-BMSB condition for some sϕ > 0 and pϕ ∈(0, 1]."
REFERENCES,0.6461864406779662,"To complete the proof, it is left to show that for any δ ∈(0, 1), there exists a ¯Γ ≻s2
ϕInϕ, such that"
REFERENCES,0.6483050847457628,"P

T
X"
REFERENCES,0.6504237288135594,"t=1
ϕ(zt)ϕ⊺(zt) ⪯̸ T ¯Γ

≤δ."
REFERENCES,0.652542372881356,"To see this, note that for ¯bϕ = supt≥0 E

∥ϕ(zt)∥2
2

, we have:"
REFERENCES,0.6546610169491526,"P

T
X"
REFERENCES,0.6567796610169492,"t=1
ϕ(zt)ϕ⊺(zt) ⪯̸
¯bϕT δ Inϕ 
= P  λmax 
T
X"
REFERENCES,0.6588983050847458,"t=1
ϕ(zt)ϕ⊺(zt)

≻λmax ¯bϕT δ Inϕ !"
REFERENCES,0.6610169491525424,"= P

T
X"
REFERENCES,0.663135593220339,"t=1
ϕ(zt)ϕ⊺(zt)

2 ≻
¯bϕT δ "
REFERENCES,0.6652542372881356,"≤
δE
 PT
t=1 ϕ(zt)ϕ⊺(zt)

2 "
REFERENCES,0.6673728813559322,"¯bϕT
."
REFERENCES,0.6694915254237288,"In addition, we have:"
REFERENCES,0.6716101694915254,"E

T
X"
REFERENCES,0.673728813559322,"t=1
ϕ(zt)ϕ⊺(zt)

2 
≤ T
X"
REFERENCES,0.6758474576271186,"t=1
E
ϕ(zt)ϕ⊺(zt)

2

≤ T
X"
REFERENCES,0.6779661016949152,"t=1
E

∥ϕ(zt)∥2
2

≤T sup
t≥0
E

∥ϕ(zt)∥2
2

,"
REFERENCES,0.6800847457627118,which implies that:
REFERENCES,0.6822033898305084,"P

T
X"
REFERENCES,0.684322033898305,"t=1
ϕ(zt)ϕ⊺(zt) ⪯̸ T ¯Γ

≤δ,
(7)"
REFERENCES,0.6864406779661016,"where ¯Γ =
¯bϕ"
REFERENCES,0.6885593220338984,"δ Inϕ. since zt ∈Z for all t ≥0, with Z being a compact set (due to the system’s LISS"
REFERENCES,0.690677966101695,"property and features ϕ(·) being real-analytic), such a bounded ¯bϕ exists, completing the proof."
REFERENCES,0.6927966101694916,"B.2
Proof of Corollary 1"
REFERENCES,0.6949152542372882,"Proof. We start the proof by stating the following lemma which is extension of Theorem 1 to the case
with ut = π(xt) + ηt."
REFERENCES,0.6970338983050848,"Lemma 3. Let ut = π(xt)+ηt, π(·) is real-analytic, ηt satisfies Assumption 3. Consider the filtration
Ft = F(w0, · · · , wt−1, x0, · · · , xt, π(x0), · · · , π(xt), η0, · · · , ηt). Suppose Assumptions 1, 2 hold
and that the closed-loop system xt+1 = θ∗ϕ(xt, π(xt) + ηt) + wt satisfies Assumption 4 for both
wt and ηt. Then there exist sϕ > 0, and pϕ ∈(0, 1) such that the {Ft}t≥1-adapted process

ϕ
 
xt, ut
"
REFERENCES,0.6991525423728814,"t≥1 satisfies the
 
1, s2
ϕInϕ, pϕ

-BMSB condition."
REFERENCES,0.701271186440678,"Proof of Lemma 3. The proof closely follows the steps of Theorem 1. First, observe that ut =
π(xt) + ηt. Since ηt satisfies the conditions outlined in Assumption 3, and the closed-loop system
xt+1 = θ∗ϕ(xt, π(xt) + ηt) + wt adheres to Assumption 4 with respect to both wt and ηt, there
exist functions γ ∈K and β ∈KL such that for all t ≥0 the following holds:"
REFERENCES,0.7033898305084746,"xt ∈X =

x ∈Rn : ∥x∥2 ≤β(ρx, 0) + γ(ρ)
"
REFERENCES,0.7055084745762712,"with parameters ρx ≥∥x0∥2 and ρ ≥max(wmax, umax). Let Z = X × U, where U is a compact set
containing ut for all t ≥0. Thus, zt ∈Z for all t ≥0. The set Z is a compact subset of Rnx+nu.
The remaining part of the proof, specifically to show that
sup
Ft, t≥0
sup
v∈V
E
 
v⊺ϕ(zt+1)
4  Ft

< ∞"
REFERENCES,0.7076271186440678,follows similarly to the proof in Theorem 1.
REFERENCES,0.7097457627118644,"It remains to show that
inf
Ft, t≥0 inf
v∈V E
 
v⊺ϕ(zt+1)
2  Ft

> 0. This can be shown as follows:"
REFERENCES,0.711864406779661,"inf
Ft, t≥0 inf
v∈V E
 
v⊺ϕ(zt+1)
2  Ft"
REFERENCES,0.7139830508474576,"
=
inf
Ft, t≥0 inf
v∈V E
 
v⊺ϕ
 
xt+1, ut+1
2  Ft "
REFERENCES,0.7161016949152542,"=
inf
Ft, t≥0 inf
v∈V E

v⊺ϕ
 
xt+1, π(xt+1) + ηt+1
2  Ft "
REFERENCES,0.7182203389830508,"=
inf
Ft, t≥0 inf
v∈V E

v⊺ϕ

θ∗ϕ(zt) + wt,"
REFERENCES,0.7203389830508474,"π
 
θ∗ϕ(zt) + wt

+ ηt+1"
REFERENCES,0.722457627118644,"2  Ft 
."
REFERENCES,0.7245762711864406,"Since zt ∈Ft and wt, ηt+1 ̸∈Ft then zt is treated as constant while wt, ηt+1 are considered random
variables. Then, by the continuity of ϕ we conclude that"
REFERENCES,0.7266949152542372,"inf
Ft, t≥0 inf
v∈V E
 
v⊺ϕ(zt+1)
2  Ft"
REFERENCES,0.7288135593220338,"
= inf
z∈Z inf
v∈V E

v⊺ϕ

θ∗ϕ(z) + w
|
{z
}
=: h(z,w)"
REFERENCES,0.7309322033898306,", π
 
θ∗ϕ(z) + w
|
{z
}
=: h(z,w)"
REFERENCES,0.7330508474576272,"
+ η
2"
REFERENCES,0.7351694915254238,"= inf
z∈Z inf
v∈V E

v⊺ϕ

h(z, w), π
 
h(z, w)

+ η
2"
REFERENCES,0.7372881355932204,"where w and η are independent random variables constrained as described in Assumptions 2 and 3.
By letting N z
v =

(w, η) ∈W × U : v⊺ϕ
 
h(z, w), π
 
h(z, w)

+ η

= 0
	
, similar to (6) we have:"
REFERENCES,0.739406779661017,"inf
z∈Z inf
v∈V E

v⊺ϕ

h(z, w),π
 
h(z, w)

+ η
2"
REFERENCES,0.7415254237288136,"= inf
z∈Z inf
v∈V E

v⊺ϕ

h(z, w), π
 
h(z, w)

+ η
2  (w, u) ̸∈N z
v "
REFERENCES,0.7436440677966102,"×

1 −sup
z∈Z
sup
v∈V
P

(w, η) ∈N z
v 
."
REFERENCES,0.7457627118644068,"We aim to show that λnx+nu(N z
v ) = 0 by applying Lemma 2. Note that ϕ(·), h(·), and π(·) are real-"
REFERENCES,0.7478813559322034,"analytic. To use the results of Lemma 2, we need to establish that v⊺ϕ

h(z, w), π
 
h(z, w)

+ η

is"
REFERENCES,0.75,"non-zero for any v ∈V. First, observe that:"
REFERENCES,0.7521186440677966,"v⊺ϕ
 
h(z, w), π(h(z, w)) + η

= nϕ
X"
REFERENCES,0.7542372881355932,"i=1
viϕi 
h(z, w), π(h(z, w)) + η)

."
REFERENCES,0.7563559322033898,Now consider two scenarios:
REFERENCES,0.7584745762711864,"• All components of π
 
h(z, w)

are linearly independent with any component of h(z, w)."
REFERENCES,0.760593220338983,"• At least one component of π
 
h(z, w)

is linearly dependent with one or more components
of h(z, w)."
REFERENCES,0.7627118644067796,"In both cases, due to the additive nature of η, all the functions ϕi 
h(z, w), π(h(z, w)) + η)

with
i = 1, · · · , nϕ are linearly independent, ensuring that v⊺ϕ
 
h(z, w), π(h(z, w)) + η

̸≡0 for any
v ∈V. The remainder of the proof follows similarly to the argument in Theorem 1."
REFERENCES,0.7648305084745762,"Using this Lemma, Theorem 4, and reasoning similar to that in the proof of Theorem 2, the proof can
be completed."
REFERENCES,0.7669491525423728,"C
Proofs for Theorem 3, Corollary 2, and Corollary 3"
REFERENCES,0.7690677966101694,"C.1
Proof of Theorem 3"
REFERENCES,0.7711864406779662,Proof. The proof follows from applying the following meta-theorem on the convergence rate of SME.
REFERENCES,0.7733050847457628,"Theorem 5 (SME meta-theorem (Li et al., 2024)). Consider a general time series model with linear
responses as follows:
xt = θ∗yt + wt,
t ≥0."
REFERENCES,0.7754237288135594,"Also, define the filtration Ft = F(w0, · · · , wt−1, y0, · · · , yt). Assume the following conditions are
met:"
REFERENCES,0.777542372881356,"• wt are i.i.d. with variance σ2
wInx, and box-constrained, i.e., wt ∈W = {w ∈Rnx :
∥w∥∞≤wmax} for some wmax > 0."
REFERENCES,0.7796610169491526,"• {yt}t≥1 is an {Ft}t≥1-adapted random process satisfying the (k, s2
yIny, py)-BMSB condi-
tion."
REFERENCES,0.7817796610169492,• There exists by > 0 such that ∥yt∥2 ≤by almost surely for all t ≥0.
REFERENCES,0.7838983050847458,"• For any ℓ> 0, there exists qw(ℓ) > 0, such that for any 1 ≤j ≤n and t ≥0, we have
P(wj
t + wmax ≤ℓ) ≥qw(ℓ) > 0, P(wmax −wj
t ≤ℓ) ≥qw(ℓ) > 0."
REFERENCES,0.7860169491525424,"Then for any m ≥1 and any δ ∈(0, 1), when T > m, the diameter of the uncertainty set ΘT ="
REFERENCES,0.788135593220339,"T −1
\ t=0"
REFERENCES,0.7902542372881356,"
ˆθ : xt −ˆθyt ∈W
"
REFERENCES,0.7923728813559322,satisfies:
REFERENCES,0.7944915254237288,"P

diam(ΘT ) > δ

≤544 T"
REFERENCES,0.7966101694915254,"mn2.5
y
log(a2ny)any
2 exp(−a3m)"
REFERENCES,0.798728813559322,"+ 544n2.5
x n2.5
y
log(a4nxny)anxny
4"
REFERENCES,0.8008474576271186,"
1 −qw  a1δ 4√nx"
REFERENCES,0.8029661016949152,"⌈T/m⌉
,"
REFERENCES,0.8050847457627118,where a1 = sypy
REFERENCES,0.8072033898305084,"4 , a2 =
64b2
y
s2yp2y , a3 =
p2
y
8 , a4 = max

4by√nx"
REFERENCES,0.809322033898305,"a1
, 1

."
REFERENCES,0.8114406779661016,"Observe that system (1) is linear in the unknown parameters θ∗, and we can prove Theorem 3
by showing that the {Ft}t≥1-adapted process {ϕ(zt)}t≥1 and wt meet the conditions of the meta-
theorem. By Assumptions 2 and 5, and since wt ̸∈Ft, the noise wt fulfills all the requirements of the
meta-theorem. Moreover, according to Theorem 1, the {Ft}t≥1-adapted process ϕ(zt)t≥1 satisfies
the (1, s2
ϕInϕ, pϕ)-BMSB condition for some sϕ > 0 and pϕ ∈(0, 1]. Lastly, since the system is
LISS, we have zt ∈Z for all t ≥0, where Z is the compact set defined in the proof of Theorem 1.
Therefore, there exists a constant bϕ > 0 such that supt≥0 ∥ϕ(zt)∥2 ≤bϕ, completing the proof of
the theorem."
REFERENCES,0.8135593220338984,"Explicitly, this means that for any m ≥1, for any δ ∈(0, 1), when T > m, we have:"
REFERENCES,0.815677966101695,"P

diam(ΘT ) > δ

≤544 T"
REFERENCES,0.8177966101694916,"mn2.5
ϕ log(a2nϕ)anϕ
2 exp(−a3m)"
REFERENCES,0.8199152542372882,"+ 544n2.5
x n2.5
ϕ log(a4nxnϕ)anxnϕ
4"
REFERENCES,0.8220338983050848,"
1 −qw  a1δ 4√nx"
REFERENCES,0.8241525423728814,"⌈T/m⌉
, (8)"
REFERENCES,0.826271186440678,where a1 = sϕpϕ
REFERENCES,0.8283898305084746,"4 , a2 =
64b2
ϕ
s2
ϕp2
ϕ , a3 =
p2
ϕ
8 , a4 = 16bϕ
√nx
sϕpϕ
."
REFERENCES,0.8305084745762712,"C.2
Proof of Corollary 2"
REFERENCES,0.8326271186440678,"Let us provide two example distributions, truncated Gaussian and uniform, along with their corre-
sponding qw(·) (from (Li et al., 2024)):"
REFERENCES,0.8347457627118644,"• If wt follows a uniform distribution on [−wmax, wmax]nx, then qw(ℓ) = cwℓwith cw =
1
2wmax ."
REFERENCES,0.836864406779661,"• If wt follows a truncated-Gaussian distribution on [−wmax, wmax]nx, generated by a Gaus-
sian distribution with zero mean and covariance matrix σ2
wInx, then qw(ℓ) = cwℓwith
cw =
1
min(
√"
REFERENCES,0.8389830508474576,"2πσw,2wmax) exp( −w2
max
2σ2w )."
REFERENCES,0.8411016949152542,"Now, fix ϵ ∈(0, 1). We want to show that if q
  a1δ"
REFERENCES,0.8432203389830508,"4√nϕ

= cw
a1δ
4√nϕ and we choose m such that m ≥1 a3"
REFERENCES,0.8453389830508474,"
log
T ϵ"
REFERENCES,0.847457627118644,"
+ nϕ log(a2) + 2.5 log(nϕ) + log log(a2nϕ) + log(544)

,
(9)"
REFERENCES,0.8495762711864406,"then for all T ≥m, we have δ ≤O"
REFERENCES,0.8516949152542372,"m√nx log
  1"
REFERENCES,0.8538135593220338,"ϵ

+ mn1.5
x nϕ log
  bϕ
√nx
sϕpϕ
"
REFERENCES,0.8559322033898306,cwsϕpϕT ! (10)
REFERENCES,0.8580508474576272,with probability at least 1 −2ϵ.
REFERENCES,0.8601694915254238,"Let the two terms in the right-hand side of (8) be denoted by ""term 1"" and ""term 2"". We proceed with
the proof in two steps as follows:"
REFERENCES,0.8622881355932204,"Step 1: showing that with the choice of m in (9), term 1 ≤ϵ :"
REFERENCES,0.864406779661017,"With this choice of m, it is straightforward to see that
544Tn2.5
ϕ log(a2nϕ)anϕ
2 exp(−a3m) ≤ϵ,
and thus term 1 ≤ϵ."
REFERENCES,0.8665254237288136,Step 2: letting term 2 = ϵ and showing that δ satisfies the inequality in (10):
REFERENCES,0.8686440677966102,Assuming without loss of generality that T
REFERENCES,0.8707627118644068,"m is an integer, note that term 2 = ϵ implies: qw  a1δ 4√nx"
REFERENCES,0.8728813559322034,"
=

1 −

ϵ
544n2.5
x n2.5
ϕ log(a4nxnϕ)anxnϕ
4  m T "
REFERENCES,0.875,"≤−log

ϵ
544n2.5
x n2.5
ϕ log(a4nxnϕ)anxnϕ
4  m T = −m"
REFERENCES,0.8771186440677966,"T log

ϵ
544n2.5
x n2.5
ϕ log(a4nxnϕ)anxnϕ
4  = m T"
REFERENCES,0.8792372881355932,"
log
1 ϵ"
REFERENCES,0.8813559322033898,"
+ log(a4)nxnϕ + 2.5 log(nxnϕ) + log log(a4nxnϕ) + log(544)

."
REFERENCES,0.8834745762711864,"If qw
  a1δ"
REFERENCES,0.885593220338983,"4√nx

= cw
a1δ
4√nx for some constant cw > 0, then:"
REFERENCES,0.8877118644067796,δ ≤4√nxm cwa1T
REFERENCES,0.8898305084745762,"
log
1 ϵ"
REFERENCES,0.8919491525423728,"
+ log(a4)nxnϕ + 2.5 log(nxnϕ) + log log(a4nxnϕ) + log(544)
"
REFERENCES,0.8940677966101694,≤16√nxm
REFERENCES,0.8961864406779662,cwsϕpϕT O 
REFERENCES,0.8983050847457628,"log
1 ϵ"
REFERENCES,0.9004237288135594,"
+ nxnϕ log
16bϕ√nx sϕpϕ ! ≤O"
REFERENCES,0.902542372881356,"m√nx log
  1"
REFERENCES,0.9046610169491526,"ϵ

+ mn1.5
x nϕ log
  bϕnx"
REFERENCES,0.9067796610169492,"sϕpϕ
"
REFERENCES,0.9088983050847458,cwsϕpϕT ! .
REFERENCES,0.9110169491525424,"Combining these two steps, we conclude that, with probability at least 1 −2ϵ,"
REFERENCES,0.913135593220339,diam(ΘT ) ≤O
REFERENCES,0.9152542372881356,"m√nx log
  1"
REFERENCES,0.9173728813559322,"ϵ

+ mn1.5
x nϕ log
  bϕnx"
REFERENCES,0.9194915254237288,"sϕpϕ
"
REFERENCES,0.9216101694915254,cwsϕpϕT ! .
REFERENCES,0.923728813559322,"C.3
Proof of Corollary 3"
REFERENCES,0.9258474576271186,"This corollary’s proof builds on Lemma 3 in Appendix B.2 and closely aligns with the proofs of
Theorem 3 and Corollary 2."
REFERENCES,0.9279661016949152,"D
Numerical Experiments"
REFERENCES,0.9300847457627118,This section provides details on the simulation experiments.
REFERENCES,0.9322033898305084,"D.1
Pendulum"
REFERENCES,0.934322033898305,The ground truth for the unknown parameters for pendulum example in Example 1 is set to be
REFERENCES,0.9364406779661016,"m = 0.1 (kg), l = 0.5 (m),"
REFERENCES,0.9385593220338984,"and discretization time step in our numerical experiments is dt = 0.01 (s). The control input is a
simple feedback controller ut = −k ˙αt +ηt. In Figures 1a and 1b we choose k = 2 and in Figures 2a,
2b and 3 we choose k = 0.1. Note there are two unknown parameters in this pendulum example as
follows:"
REFERENCES,0.940677966101695,θ1 = 1
REFERENCES,0.9427966101694916,"l , θ2 =
1
ml2 ."
REFERENCES,0.9449152542372882,"D.2
Quadrotor"
REFERENCES,0.9470338983050848,The ground truth for the unknown parameters for quadrotor example in Example 2 is set to be
REFERENCES,0.9491525423728814,"m = 0.468 (kg),"
REFERENCES,0.951271186440678,"Ixx = 4.856 × 10−3 (kg/m2), Iyy = 4.856 × 10−3 (kg/m2), Izz = 8.801 × 10−3 (kg/m2)."
REFERENCES,0.9533898305084746,"The discretization time step in our numerical experiments is dt = 0.01 (s). The control input is a
control policy plus i.i.d. noise. The control policy on altitude and the three Euler angles is borrowed
from (Alaimo et al., 2013). The controller gains in our numerical experiments are chosen as:"
REFERENCES,0.9555084745762712,"kpz = 0.75, kdz = 1.25,
kpϕ = 0.03, kdϕ = 0.00875,
kpθ = 0.03, kdθ = 0.00875,
kpψ = 0.03, kdψ = 0.00875."
REFERENCES,0.9576271186440678,"Note that there are seven unknown parameters in this quadrotor example, as follows:"
REFERENCES,0.9597457627118644,"θ1 = 1 m,"
REFERENCES,0.961864406779661,"θ2 =
1
Ixx
,
θ3 = Iyy −Izz"
REFERENCES,0.9639830508474576,"Ixx
, θ4 =
1
Iyy
,
θ5 = Izz −Ixx"
REFERENCES,0.9661016949152542,"Iyy
, θ6 =
1
Izz
,
θ7 = Ixx −Izz Izz
."
REFERENCES,0.9682203389830508,"Figure 4 displays the uncertainty set estimated by SME for the seven unknown parameters in the
quadrotor example for various trajectory lengths, with ηt and wt being i.i.d. samples from truncated-
Gaussian distributions. The uncertainty sets are observed to shrink as the trajectory length increases,
consistent with our theoretical results. Note that the ground truth value is contained within all the
uncertainty sets."
REFERENCES,0.9703389830508474,"E
Numerical Estimation of BMSB Parameters (sϕ, pϕ)"
REFERENCES,0.972457627118644,"We compare the empirical rates of LSE and SME with their theoretical counterparts in Section 4. The
theoretical results presented in Theorem 2 and Corollary 2 rely on the parameters bϕ, ¯bϕ, and the
BMSB parameters (sϕ, pϕ). However, the explicit relationship of these parameters with system, noise,
and disturbance characteristics such as nx, nu, nϕ, σu, and σw is not known and we will address
this in our future work. Consequently, we estimate these parameters numerically and utilize these"
REFERENCES,0.9745762711864406,"Figure 4: 2D projections of the uncertainty set estimated by SME for the unknown parameters of the quadrotor
example. The noises and disturbances are i.i.d generated from truncated-Gaussian(0, 0.5, [−1, 1])."
REFERENCES,0.9766949152542372,"estimates to calculate the theoretical rates discussed in Section 4. While bϕ and ¯bϕ are straightforward
to estimate, special attention is required to estimate the BMSB parameters. This section is dedicated
to describing this estimation process."
REFERENCES,0.9788135593220338,"For this, consider a system of the form (1). For this system, our goal is to estimate sϕ and pϕ, where"
REFERENCES,0.9809322033898306,"pϕ =
inf
Ft,t≥0
inf
∥v∥2=1 P

|vT ϕ(zt+1)| ≥sϕ
 Ft "
REFERENCES,0.9830508474576272,"numerically. First, observe that ϕ(zt+1) | Ft = ϕ(θT
∗ϕ(zt) + wt, ut+1), where zt ∈Ft. This implies
that ϕ(zt+1) | Ft is a random variable influenced by wt and ut+1. We proceed by fixing sϕ = ¯s (for
some ¯s > 0) and empirically estimate pϕ. To accomplish this, we first select a time horizon T and
generate several trajectories of length T for the system. Let DT represent the set of these trajectories,
while Dt denotes a subset containing all trajectories up to t ≤T. Additionally, we create multiple
vectors v ∈Rnϕ such that ∥v∥2 = 1; we refer to this collection as ¯V. These vectors are randomly
sampled from a Gaussian distribution and subsequently normalized."
REFERENCES,0.9851694915254238,We then estimate ¯p as:
REFERENCES,0.9872881355932204,"¯p = min
t∈[T ] min
z∈Dt min
v∈¯V P

|vT ϕ(θT
∗ϕ(z) + wt, ut+1)| ≥¯s

."
REFERENCES,0.989406779661017,"As T increases, along with the number of trajectories and vectors v, the minimum estimates will more"
REFERENCES,0.9915254237288136,"accurately reflect the infimums. In this context, ¯p represents the minimum of P

|vT ϕ(θT
∗ϕ(z) +"
REFERENCES,0.9936440677966102,"wt, ut+1)| ≥¯s

across all combinations in [T] × DT × ¯V. For each combination in this set, we"
REFERENCES,0.9957627118644068,"estimate the probability P

|vT ϕ(θT
∗ϕ(z) + wt, ut+1)| ≥¯s

using Monte Carlo simulations. This"
REFERENCES,0.9978813559322034,"process entails generating multiple random samples based on the distributions of wt and ut+1,
verifying whether each sample satisfies the condition |¯vT ϕ(z)| ≥¯s, and tallying how many samples
meet this criterion. We repeat this procedure for various values of ¯s until we identify a pair of (¯s, ¯p)
such that ¯p ∈(0, 1). The estimated probability is calculated as the ratio of the count of successful
samples to the total number of samples. According to the law of large numbers, this ratio converges
to the true probability as the number of samples increases. For our estimations, we select T = 50,
|¯V| = 1000, and |DT | = 20."
