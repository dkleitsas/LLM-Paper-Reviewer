Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.00303951367781155,"Catastrophic forgetting is one of the major challenges in continual learning. To ad-
dress this issue, some existing methods put restrictive constraints on the optimiza-
tion space of the new task for minimizing the interference to old tasks. However,
this may lead to unsatisfactory performance for the new task, especially when the
new task is strongly correlated with old tasks. To tackle this challenge, we propose
Trust Region Gradient Projection (TRGP) for continual learning to facilitate the
forward knowledge transfer based on an efﬁcient characterization of task correla-
tion. Particularly, we introduce a notion of ‘trust region’ to select the most related
old tasks for the new task in a layer-wise and single-shot manner, using the norm
of gradient projection onto the subspace spanned by task inputs. Then, a scaled
weight projection is proposed to cleverly reuse the frozen weights of the selected
old tasks in the trust region through a layer-wise scaling matrix. By jointly opti-
mizing the scaling matrices and the model, where the model is updated along the
directions orthogonal to the subspaces of old tasks, TRGP can effectively prompt
knowledge transfer without forgetting. Extensive experiments show that our ap-
proach achieves signiﬁcant improvement over related state-of-the-art methods."
INTRODUCTION,0.0060790273556231,"1
INTRODUCTION"
INTRODUCTION,0.00911854103343465,"Human beings can continuously learn different new tasks without forgetting the learnt knowledge of
old tasks in their lifespan. Aiming to achieve this remarkable capability for the deep neural networks
(DNNs), continual learning (CL) (Chen & Liu, 2018) has garnered much attention in recent years.
Nevertheless, many existing CL methods still leave the DNN vulnerable to forget the knowledge
of old tasks when learning new tasks. Such a phenomenon is known as ‘Catastrophic Forgetting’
(McCloskey & Cohen, 1989), which has become one of the major challenges for CL."
INTRODUCTION,0.0121580547112462,"Many approaches (e.g., (Rusu et al., 2016; Li & Hoiem, 2017; Dhar et al., 2019; Guo et al., 2020;
Zeng et al., 2019)) have been proposed to address the forgetting issue, which can be generally
divided into two classes depending on the network architecture, i.e., expansion methods and non-
expansion methods. In order to understand the fundamental limit of a ﬁxed capacity neural network,
we focus on non-expansion methods in this work. The basic idea for non-expansion methods is
to constrain the gradient update either explicitly or implicitly when learning the new task, so as to
minimize the introduced interference to old tasks. For example, the regularization-based methods
(e.g., (Kirkpatrick et al., 2017; Serra et al., 2018)) penalize the modiﬁcation on the most important
weights of old tasks through model regularizations; experience-replay based methods (e.g., (Shin
et al., 2017; Chaudhry et al., 2019)) constrain the gradient directions by replaying the data of old
tasks during learning of new tasks, in the format of either real data or synthetic data from generative
models; and orthogonal-projection based methods (e.g., (Farajtabar et al., 2020; Saha et al., 2021))
update the model with gradients in the orthogonal directions of old tasks, without the access to old
task data. In particular, the recently proposed Gradient Projection Memory (GPM) (Saha et al.,
2021) has demonstrated superior performance compared to other approaches."
INTRODUCTION,0.015197568389057751,"To sufﬁciently minimize the interference to old tasks, most existing non-expansion methods (partic-
ularly the orthogonal-projection based methods), often put restrictive constraints on the optimization
space of the new task, which may throttle the learning performance for the new task. A plausible
conjecture is that such a scenario is likely to occur when the new task is strongly correlated with"
INTRODUCTION,0.0182370820668693,Published as a conference paper at ICLR 2022
INTRODUCTION,0.02127659574468085,"old tasks, and in this study we provide evidence to support this conjecture. The underlying rationale
is as follows: The weights that are important to the new task are also important to the old tasks
strongly correlated with the new task, which are often frozen to address the forgetting in the existing
methods; however, they should be updated in the learning of the new task."
INTRODUCTION,0.0243161094224924,"To tackle this challenge, a key insight is that for a new task that is strongly correlated with old tasks,
although the model optimization space could be more restrictive, there should be better forward
knowledge transfer from the correlated old tasks to the new task. With this insight, we propose an
innovate continual learning approach to facilitate the forward knowledge transfer without forgetting.
The main contributions can be summarized as follows:"
INTRODUCTION,0.02735562310030395,"(1) Inspired by (Schulman et al., 2015), we introduce a novel notion of ‘trust region’ based on the
norm of gradient projection onto the subspace spanned by task inputs, which selects the old tasks
strongly correlated to the new task in a layer-wise and single-shot manner. Intuitively, the new task
and the selected old tasks in the trust region have similar input features for the corresponding layer."
INTRODUCTION,0.030395136778115502,"(2) We propose a novel approach for the new task to leverage the knowledge of the strongly corre-
lated old tasks in the trust region through a scaled weight projection. Particularly, a scaling matrix
is learnt in each layer for the new task to scale the weight projection onto the subspace of old tasks
in the trust region, in order to reuse the frozen weights of old tasks without modifying the model."
INTRODUCTION,0.03343465045592705,"(3) Building on the introduced trust region, scaled weight projection, and a module to construct task
input subspace, we develop a continual learning approach, trust region gradient projection (TRGP),
that jointly optimizes the scaling matrices and the model for the new task. To mitigate the forgetting
issue further, the model is updated along the directions orthogonal to the subspaces of old tasks."
INTRODUCTION,0.0364741641337386,"(4) We evaluate TRGP on standard CL benchmarks using various network architectures. Compared
to related state-of-the-art approaches, TRGP achieves substantial performance improvement on all
benchmarks, and demonstrates universal improvement on all tasks. The superior performance indi-
cates that TRGP can effectively promote the forward knowledge transfer while alleviating forgetting."
RELATED WORK,0.03951367781155015,"2
RELATED WORK"
RELATED WORK,0.0425531914893617,"Expansion-based methods. Expansion-based methods (e.g., (Rusu et al., 2016; Li & Hoiem, 2017;
Rosenfeld & Tsotsos, 2018; Hung et al., 2019; Yoon et al., 2017; Li et al., 2019; Veniat et al., 2020))
dynamically expand the network capacity to reduce the interference between the new tasks and the
old ones. Progressive Neural Network (PNN) (Rusu et al., 2016) expands the network architecture
for new tasks and preserves the weights of old tasks. Learning Without Forgetting (LWF) (Li &
Hoiem, 2017) splits the model layers into two parts, i.e., the shared part co-used by all tasks, and
the task-speciﬁc part which grows for new tasks. Dynamic-Expansion Net (DEN) (Yoon et al.,
2017) and Compacting-Picking-Growing (CPG) (Hung et al., 2019) combine the strategies of model
compression/pruning, weight selection and model expansion. In order to ﬁnd the optimal structure
for each of the sequential tasks, Reinforced Continual Learning (RCL) (Xu & Zhu, 2018) leverages
reinforcement learning and (Li et al., 2019) adapts architecture search. APD (Yoon et al., 2020) adds
additional task-speciﬁc parameters for each task and selectively learns the task-shared parameters."
RELATED WORK,0.04559270516717325,"Regularization-based methods. This category of methods (e.g., (Kirkpatrick et al., 2017; Lee et al.,
2017; Chaudhry et al., 2018a; Dhar et al., 2019; Ritter et al., 2018; Schwarz et al., 2018; Zenke et al.,
2017)) protect the old tasks by adding regularization terms in the loss function to penalize the model
change on their important weights. Notably, to determine the weight importance, Elastic Weight
Consolidation (EWC) (Kirkpatrick et al., 2017) leverages Fisher information matrix, HAT (Serra
et al., 2018) learns hard attention masks. MAS (Aljundi et al., 2018) evaluates the model outputs
sensitivity to the inputs in an unsupervised manner."
RELATED WORK,0.0486322188449848,"Memory-based methods. Depending on if data of old tasks is utilized when learning new tasks,
memory-based methods can be further divided into the following two categories. 1) Experience-
replay based methods. This class of methods replays the old tasks data along with the current task
data to mitigate catastrophic forgetting. Gradient Episodic Memory (GEM) (Lopez-Paz & Ranzato,
2017) and Averaged GEM (A-GEM) (Chaudhry et al., 2018b) alter the current gradient based on
the gradient computed with data in the memory. A uniﬁed view of episodic memory based methods
is proposed in (Guo et al., 2020), based on new approaches are developed to balance between old
tasks and the new task. Tiny episodic memory is considered in (Chaudhry et al., 2019) and meta-"
RELATED WORK,0.05167173252279635,Published as a conference paper at ICLR 2022
RELATED WORK,0.0547112462006079,"learning is leveraged in (Riemer et al., 2018). 2) Orthogonal-projection based method. To eliminate
the need of storing data of old tasks, recently a series work (Zeng et al., 2019; Farajtabar et al.,
2020; Saha et al., 2021) updates the model in the orthogonal direction of old tasks, and has shown
remarkable performance. Particularly, Orthogonal Weight Modulation (OWM) (Zeng et al., 2019)
learns a projector matrix to multiply with the new gradients. Orthogonal Gradient Descent (OGD)
(Farajtabar et al., 2020) stores the gradient directions of old tasks and projects the new gradients on
the directions orthogonal to the subspace spanned by the old gradients. Gradient Projection Memory
(GPM) (Saha et al., 2021) stores the bases of the subspaces spanned by old task data and projects
the new gradients on the directions orthogonal to these subspaces."
PROBLEM FORMULATION,0.057750759878419454,"3
PROBLEM FORMULATION"
PROBLEM FORMULATION,0.060790273556231005,"Continual learning. Consider the setting where a sequence of tasks T = {t}T
t=1 arrives sequentially.
Each task t has a dataset Dt = {(xt,i, yt,i)}Nt
i=1 with Nt sample pairs, where xt,i is the input vector
and yt,i is the label vector. Consider a ﬁxed capacity neural network with L layers, and the set of
weights is denoted as W = {W l}L
l=1, where W l is the layer-wise weight for layer l. Given the data
input xt,i for task t, denote xl
t,i as the input of layer l and x1
t,i = xt,i. The output xl+1
t,i for layer l is
computed as xl+1
t,i
= f(W l, xl
t,i), where f is the operation of the network layer. Following (Saha
et al., 2021), we denote xl
t,i as the representations of xt,i at layer l. When learning task t, we only
have access to dataset Dt. Let L(W, {(xt,i, yt,i)}) = Lt(W) denote the loss function for training,
e.g., mean squared and cross-entropy loss, and Wt denote the model after learning task t."
PROBLEM FORMULATION,0.06382978723404255,"Orthogonal-projection based methods. To minimize the interference to old tasks, recently a series
of studies (Zeng et al., 2019; Farajtabar et al., 2020; Saha et al., 2021) has been carried out to update
the model for the new task in the direction orthogonal to the subspace spanned by inputs of old tasks.
In what follows, we brieﬂy introduce the main ideas through a basic case with two tasks 1 and 2."
PROBLEM FORMULATION,0.0668693009118541,"Denote the subspace spanned by the inputs of task 1 for layer l as Sl
1 and the learnt model for task 1
as W1 = {W l
1}L
l=1. It is clear that xl
1,i ∈Sl
1. When learning task 2, the model W l
1 will be modiﬁed
in the direction orthogonal to Sl
1, by either multiplying the gradient ∇W lL2 with a projector matrix
(e.g, (Zeng et al., 2019)), or projecting the gradient ∇W lL2 onto the orthogonal direction to Sl
1 (e.g.,
(Saha et al., 2021)). Let ∆W l
1 denote the model change after learning task 2. It follows immediately
that ∆W l
1xl
1,i = 0, and the model W l
2 for task 2 is W l
2 = W l
1 + ∆W l
1. Therefore, for task 1:"
PROBLEM FORMULATION,0.06990881458966565,"W l
2xl
1,i = (W l
1 + ∆W l
1)xl
1,i = W l
1xl
1,i + ∆W l
1xl
1,i = W l
1xl
1,i,
(1)
which indicates that no interference is introduced to task 1 after learning task 2, thereby addressing
the forgetting issue. Such an analysis can be generalized to a sequence of tasks."
PROBLEM FORMULATION,0.0729483282674772,"When would orthogonal projection hinder the learning of a new task? Orthogonal projection
provides a promising solution to address the forgetting in continual learning. However, by modifying
the model only in the orthogonal direction to the input space of old tasks, the optimization space of
learning the new task could be more restrictive, resulting in compromised performance of the new
task. To get a more concrete sense, consider the following basic examples with two tasks 1 and 2."
PROBLEM FORMULATION,0.07598784194528875,"(Toy example 1) Suppose task 1 has dataset D1 = {(xi, yi)}N
i=1 and task 2 has dataset D2 =
{(−xi, yi)}N
i=1, where only the sign is changed for the input vectors. Consider the case where two
tasks share the same classiﬁer (Saha et al., 2021). It is clear that for the l-th layer, the subspace
spanned by {xl
i}N
i=1 of task 1 is same with the subspace spanned by {−xl
i}N
i=1 of task 2, i.e.,
Sl
1 = Sl
2, given the learnt model W l
1 for task 1. Based on the fact that stochastic gradient descent
updates lie in the subspace spanned by the data input (Zhang et al., 2021; Saha et al., 2021), it follows
that the gradient ∇W lL2 ∈Sl
2, such that ∇W lL2 ∈Sl
1. Therefore, the projection of ∇W lL2 onto
the orthogonal direction to Sl
1 is 0, which means that the model W l
1 will not be updated when
learning task 2, i.e., W l
2 = W l
1. However, the optimal model for task 2 should be W l
2 = −W l
1,
because W l
1xl
i achieves the minimum loss for the label yi after learning task 1."
PROBLEM FORMULATION,0.0790273556231003,"(Toy example 2) Suppose the input subspace of task 1 is orthogonal to that of task 2, i.e., Sl
1 ⊥Sl
2. It
follows that the projection of ∇W lL2 onto the orthogonal direction to Sl
1 is indeed equal to ∇W lL2.
Consequently, updating the model for task 2 based on orthogonal projection will not only introduce
no interference to task 1, but also move along the direction of steepest descent for task 2."
PROBLEM FORMULATION,0.08206686930091185,Published as a conference paper at ICLR 2022
PROBLEM FORMULATION,0.0851063829787234,"Figure 1: Layer-wise task correlation for the case where the subspace spanned by the representations
is a two-dimensional plane. The subspaces are weakly correlated if they are nearly orthogonal and
strongly correlated if they are nearly parallel."
PROBLEM FORMULATION,0.08814589665653495,"Motivated by these examples, a plausible conjecture is that naive orthogonal projection could possi-
bly compromise the learning performance of the new task that is strongly correlated with old tasks,
especially when the correlation is “negative” as in the toy example 1. In this study, we advocate to
characterize the task correlation through the correlation between the input subspaces for two tasks.
As illustrated in Fig. 1, when the subspace is 2-dimensional, two tasks are weakly correlated if their
input subspaces are nearly orthogonal, and strongly correlated if their subspaces are nearly parallel."
TRUST REGION GRADIENT PROJECTION FOR CONTINUAL LEARNING,0.0911854103343465,"4
TRUST REGION GRADIENT PROJECTION FOR CONTINUAL LEARNING"
TRUST REGION GRADIENT PROJECTION FOR CONTINUAL LEARNING,0.09422492401215805,"To tackle these challenges, a key insight is that for a new task that is strongly correlated with old
tasks, although the model optimization space could be more restrictive, there should be better for-
ward knowledge transfer from the correlated old tasks to the new task. With this insight, we propose
a novel approach to prompt forward knowledge transfer without forgetting, by 1) introducing a novel
notion of trust region to select the most related old tasks in a single-shot manner and 2) cleverly
reusing the frozen weights of the selected tasks in the trust region with a scaled weight projection."
TRUST REGION,0.0972644376899696,"4.1
TRUST REGION"
TRUST REGION,0.10030395136778116,"To facilitate forward knowledge transfer from the correlated old tasks to the new task, the ﬁrst
question is how to efﬁciently select the most correlated old tasks. Towards this end, we characterize
the correlation between the input subspaces for two tasks, through the lens of gradient projection."
TRUST REGION,0.1033434650455927,"Speciﬁcally, denote Sl
j = span{Bl
j} as the subspace spanned by the task j data for layer l, where
Bl
j = [ul
j,1, ..., ul
j,Mj,l] is the bases for Sl
j (totally Mj,l bases extracted from the input). For any
matrix A with a suitable dimension, denote its projection onto the subspace Sl
j as:"
TRUST REGION,0.10638297872340426,"ProjSl
j(A) = ABl
j(Bl
j)′
(2)"
TRUST REGION,0.1094224924012158,"where (·)′ is the matrix transpose. We next deﬁne a layer-wise trust region for a new task as a set of
its most related old tasks, based on the norm of projected gradient onto the subspaces of old tasks.
Deﬁnition 1 (Layer-Wise Trust Region). For any new task t ≥2 and layer l, we deﬁne a layer-wise
trust region T Rl
t = {j} for j ∈[1, t −1], where for any task j ∈T Rl
t the following holds:
∥ProjSl
j(∇W lLt(Wt−1))∥2 ≥ϵl∥∇W lLt(Wt−1)∥2,
(3)"
TRUST REGION,0.11246200607902736,"where ϵl ∈[0, 1] and Wt−1 is the model after learning task t −1."
TRUST REGION,0.11550151975683891,"Figure 2: Trust region for a 2-dimensional subspace can
be interpreted as: if the angle θ between ∇W lLt and
ProjSl
j(∇W lLt) is less than θl
th (larger projection on"
TRUST REGION,0.11854103343465046,"Sl
j), old task j is selected to T Rl
t; otherwise not. θl
th
can be set as a large value, and we can pick tasks with
top-K smallest θ to T Rl
t."
TRUST REGION,0.12158054711246201,"Intuitively, for the new task t, the norm
of its gradient projection onto the sub-
space of an old task j serves as a sur-
rogate for characterizing the correlation
between input subspaces for these two
tasks, due to the fact that the gradient
lies in the span of its input. When the
condition Eq. (3) is satisﬁed, the gradi-
ent ∇W lLt(Wt−1) has a large projec-
tion onto the subspace of an old task j,
which implies that the subspace Sl
t for
task t and the subspace Sl
j for task j may
have sufﬁcient common bases for layer
l. In this case, we trust that the old task"
TRUST REGION,0.12462006079027356,Published as a conference paper at ICLR 2022
TRUST REGION,0.1276595744680851,"j is strongly correlated with the new task t in layer l, and put it into task t’s trust region T Rl
t. A
simple illustration of trust region is shown in Figure 2. Note that the notion of trust region can also
be generalized to a task-wise deﬁnition, where the most correlated old tasks will be selected based
on the projection of the entire gradient ∇WLt(Wt−1). However, the layer-wise trust region could
select different tasks for different layers, which provides a more ﬁne-resolution characterization of
task correlations in terms of layer-level features."
TRUST REGION,0.13069908814589665,"Practical implementation. Besides the valuable functionality provided by the trust region for se-
lecting most correlated old tasks, another signiﬁcant beneﬁt is the simplicity of its practical imple-
mentation. Consider the implementation for learning a new task t."
TRUST REGION,0.1337386018237082,"(1) Single-shot manner. Given the learnt model Wt−1, we select a sample batch from dataset Dt, and
compute the gradient ∇W lLt(Wt−1) in one forward-backward pass for all layers at once. Given the
subspace Sl
j for an old task j, the condition Eq. (3) can be immediately evaluated for all old tasks."
TRUST REGION,0.13677811550151975,"(2) Top-K correlated tasks. It is clear that the choice of ϵl has a nontrivial impact on the selection
of the most correlated old tasks. To reduce the sensitivity of the performance on ϵl, we can set
a relatively small value of ϵl, and pick the top-K old tasks with the largest gradient projection
norm ∥ProjSl
j(∇W lLt(Wt−1))∥2 from the tasks satisfying Eq. (3). As demonstrated later in our
experiments, setting K = 1 is enough to achieve a signiﬁcant performance improvement."
SCALED WEIGHT PROJECTION,0.1398176291793313,"4.2
SCALED WEIGHT PROJECTION"
SCALED WEIGHT PROJECTION,0.14285714285714285,"Given the layer-wise trust region T Rl
t for the new task t, the next key question is how to efﬁciently
leverage the knowledge of the most correlated old tasks in T Rl
t for learning task t. To this end, we
propose a novel approach to reuse the frozen weights of the selected old tasks in T Rl
t through a
scaled weight projection with a scaling matrix."
SCALED WEIGHT PROJECTION,0.1458966565349544,"At the outset, it is of interest to understand what knowledge is preserved for old tasks during con-
tinual learning with orthogonal projection. Based on Eq. (1) for the simple case with two learning
tasks 1 and 2 as mentioned earlier, it can be shown that
ProjSl
1(W l
2) = ProjSl
1(W l
1 + ∆W l
1) = ProjSl
1(W l
1) + ProjSl
1(∆W l
1) = ProjSl
1(W l
1)
(4)"
SCALED WEIGHT PROJECTION,0.14893617021276595,"where the last equation holds because the model W l
1 is updated in the direction orthogonal to Sl
1
when learning task 2. By generalizing Eq. (4) to the case with a sequence of tasks, we can have that
for the model Wt−1 after learning task t −1 and any old task j < t:
ProjSl
j(W l
t−1) = ProjSl
j(W l
j),
(5)
which indicates that the model weight projection on the subspace of old tasks is actually “frozen”
during continual learning so as to overcome forgetting of the old tasks."
SCALED WEIGHT PROJECTION,0.1519756838905775,"Figure 3: [ul
j,1, ul
j,2] is the bases
of subspace Sl
j, and [cl
j,1, cl
j,2] is
the coordinate of Projsl
j(W l
t−1)."
SCALED WEIGHT PROJECTION,0.15501519756838905,"Any point ProjSl
j(W l) in Sl
j can
be obtained by scaling the coor-
dinate [cl
j,1, cl
j,2] with some scalar
s1 and s2."
SCALED WEIGHT PROJECTION,0.1580547112462006,"On the other hand, because the trust region T Rl
t is constructed
in a way that the subspace Sl
t of task t is strongly correlated
with the subspace Sl
j for any old task j ∈T Rl
t, the bases Bl
j
of Sl
j is very likely to contain important bases for task t. As a
result, the weight projection ProjSl
j(W l
t−1) is important for the
new task t and should be modiﬁed accordingly in order to guar-
antee the learning performance of task t, which however has to
be frozen to protect task j. To ﬁnd an efﬁcient way to lever-
age ProjSl
j(W l
t−1) without modifying it, note that the projec-"
SCALED WEIGHT PROJECTION,0.16109422492401215,"tion ProjSl
j(W l
t−1) is indeed a linear combination of the pro-"
SCALED WEIGHT PROJECTION,0.1641337386018237,"jection of W l
t−1 onto each basis in Bl
j, and every point in Sl
j
can be obtained by scaling the coordinates of ProjSl
j(W l
t−1).
Figure 3 shows a simple example for two-dimensional sub-
space.
Therefore, we propose a scaled weight projection to
ﬁnd the best point for task t in Sl
j by leveraging the projection
ProjSl
j(W l
t−1) through a square scaling matrix Ql
j,t:"
SCALED WEIGHT PROJECTION,0.16717325227963525,"ProjQ
Sl
j(W l
t−1) = W l
t−1Bl
jQl
j,t(Bl
j)′.
(6)"
SCALED WEIGHT PROJECTION,0.1702127659574468,Published as a conference paper at ICLR 2022
SCALED WEIGHT PROJECTION,0.17325227963525835,"The dimension of Ql
j,t depends on the number of bases in Bl
j (dimension of Sl
j), which is usually
small for each task. In this way, we explicitly transfer the knowledge of the selected old tasks in the
trust region T Rl
t to the new task t through a scaling matrix Ql
j,t."
TASK SUBSPACE CONSTRUCTION,0.1762917933130699,"4.3
TASK SUBSPACE CONSTRUCTION"
TASK SUBSPACE CONSTRUCTION,0.17933130699088146,"To successfully leverage the trust region, a missing ingredient is the construction of input subspaces
of old tasks. We next show how the subspace Sl
j can be constructed for task j at layer l."
TASK SUBSPACE CONSTRUCTION,0.182370820668693,"For task j = 1. As in (Saha et al., 2021), we obtain the bases Bl
1 after learning task 1 using Singular
Value Decomposition (SVD) on the representations. Speciﬁcally, given the model W1 after learning
task 1, we construct a representation matrix Rl
1 = [xl
1,1, ..., xl
1,n] ∈Rm×n with n samples, where
each xl
1,i ∈Rm, is the representation at layer l by forwarding the sample x1,i through the network.
Then, we apply SVD to the matrix Rl
1, i.e., Rl
1 = U l
1Σl
1(V l
1 )′, where U l
1 = [ul
1,1, ..., ul
1,m] ∈
Rm×m is an orthogonal matrix with left singular vector ul
1,i ∈Rm, V l
1 = [vl
1,1, ..., vl
1,n] ∈Rn×n"
TASK SUBSPACE CONSTRUCTION,0.18541033434650456,"is an orthogonal matrix with right singular vector vl
1,i ∈Rn, and Σl
1 ∈Rm×n is a rectangular"
TASK SUBSPACE CONSTRUCTION,0.1884498480243161,"diagonal matrix with non-negative singular values {σl
1,i}min{m,n}
i=1
on the diagonal in a descending
order. To obtain the bases for subspace Sl
1, we use kl
1-rank matrix approximation to pick the ﬁrst kl
1
left singular vectors in U l
1, such that the following condition is satisﬁed for a threshold ηl
th ∈(0, 1):
∥(Rl
1)kl
1∥2
F ≥ϵl
th∥Rl
1∥2
F
(7)"
TASK SUBSPACE CONSTRUCTION,0.19148936170212766,"where (Rl
1)kl
1 = Pkl
1
i=1 σl
1,iul
1,i(vl
1,i)′ is a kl
1-rank (kl
1 ≤r) approximation of the representation
matrix Rl
1 with rank r ≤min{m, n}, and ∥· ∥F is the Frobenius norm. Then the bases Bl
1 for
subspace Sl
1 can be constructed as Bl
1 = [ul
1,1, ..., ul
1,kl
1]."
TASK SUBSPACE CONSTRUCTION,0.1945288753799392,"For task j ∈[2, T]. We construct the bases Bl
j after learning task j given the learnt model Wj.
A representation matrix Rl
j will be ﬁrst obtained in the same manner as Rl
1. Note that the bases
{Bl
i}j−1
i=1 learnt for old tasks may include important bases for task j. Therefore, we learn the bases
Bl
j by selecting the most important bases from both bases of old tasks and newly constructed bases.
Speciﬁcally, (1) (old bases) we ﬁrst concatenate the bases {Bl
i}j−1
i=1 of old tasks together in M l
j and
eliminate the common bases. For each basis ul
i ∈M l
j, we compute the corresponding eigenvalue of
Rl
j(Rl
j)′, i.e., δl
i = (ul
i)′Rl
j(Rl
j)′ul
i, which is the square of the singular value of Rl
j with respect to
ul
i. (2) (new bases) We perform SVD on ˆRl
j = Rl
j −Rl
jM l
j(M l
j)′ to generate new bases beyond
M l
j, i.e., ˆRl
j = ˆU l
j ˆΣl
j( ˆV l
j )′ with singular values {ˆσl
j,h}h. (3) (select the most important bases
from both old and new bases) Next we concatenate {δl
i}i and {(ˆσl
j,h)2}h together in a vector δ,
and sort them in a descending order. We perform kl
j-rank matrix approximation of Rl
j, such that the
summation of the ﬁrst kl
j elements in δ is greater than ϵl
th∥Rl
j∥2
F . Then Bl
j can be constructed by
selecting the bases corresponding to the ﬁrst kl
j elements in δ."
CONTINUAL LEARNING WITH TRUST REGION GRADIENT PROJECTION,0.19756838905775076,"4.4
CONTINUAL LEARNING WITH TRUST REGION GRADIENT PROJECTION"
CONTINUAL LEARNING WITH TRUST REGION GRADIENT PROJECTION,0.2006079027355623,"Building on the three modules proposed earlier, i.e., task subspace construction, trust region and
scaled weight projection, we next present our approach TRGP for continual learning that efﬁciently
facilitate forward knowledge transfer without forgetting the old tasks."
CONTINUAL LEARNING WITH TRUST REGION GRADIENT PROJECTION,0.20364741641337386,"Learning task 1. The ﬁrst task is learnt using standard gradient descent. The subspace {Sl
1}L
l=1 is
constructed by following Section 4.3."
CONTINUAL LEARNING WITH TRUST REGION GRADIENT PROJECTION,0.2066869300911854,"Learning task 2, ..., T. For task t ∈[2, T], we ﬁrst determine the trust region T Rl
t with top-K
correlated old tasks selected for layer l. The optimization problem for task t is as follows:
min
{W l}l,{Ql
j,t}l,j∈T Rl
t
L({W l
eff}l, Dt),
(8)"
CONTINUAL LEARNING WITH TRUST REGION GRADIENT PROJECTION,0.20972644376899696,"s.t
W l
eff = W l +
X"
CONTINUAL LEARNING WITH TRUST REGION GRADIENT PROJECTION,0.2127659574468085,"j∈T Rl
t
[ProjQ
Sl
j(W l) −ProjSl
j(W l)],
(9)"
CONTINUAL LEARNING WITH TRUST REGION GRADIENT PROJECTION,0.21580547112462006,"where the gradient for updating W l is ∇W lL = ∇W lL −(∇W lL)M l
t(M l
t)′ and M l
t is the bases
of all old tasks as in Section 4.3. The subspace {Sl
t}L
l=1 is next obtained by following Section 4.3."
CONTINUAL LEARNING WITH TRUST REGION GRADIENT PROJECTION,0.2188449848024316,Published as a conference paper at ICLR 2022
CONTINUAL LEARNING WITH TRUST REGION GRADIENT PROJECTION,0.22188449848024316,"Table 1: The averaged accuracy (ACC) and backward transfer (BWT) over all the tasks on different
datasets. Note that, Multitask jointly learns all tasks only once in a single network by using the
whole dataset, which does not adhere to CL setup."
CONTINUAL LEARNING WITH TRUST REGION GRADIENT PROJECTION,0.22492401215805471,"Method
PMNIST
CIFAR-100 Split
5-Dataset
MiniImageNet"
CONTINUAL LEARNING WITH TRUST REGION GRADIENT PROJECTION,0.22796352583586627,"ACC(%)
BWT(%)
ACC(%)
BWT(%)
ACC(%)
BWT(%)
ACC(%)
BWT(%)"
CONTINUAL LEARNING WITH TRUST REGION GRADIENT PROJECTION,0.23100303951367782,"Multitask
96.70
-
79.58
-
91.54
-
69.46
-"
CONTINUAL LEARNING WITH TRUST REGION GRADIENT PROJECTION,0.23404255319148937,"OWM
90.71
-1
50.94
-30
-
-
-
-
EWC
89.97
-4
68.80
-2
88.64
-4
52.01
-12
HAT
-
-
72.06
0
91.32
-1
59.78
-3
A-GEM
83.56
-14
63.98
-15
84.04
-12
57.24
-12
ER Res
87.24
-11
71.73
-6
88.31
-4
58.94
-7
GPM
93.91
-3
72.48
-0.9
91.22
-1
60.41
-0.7"
CONTINUAL LEARNING WITH TRUST REGION GRADIENT PROJECTION,0.23708206686930092,"Ours (TRGP)
96.34
-0.8
74.46
-0.9
93.56
-0.04
61.78
-0.5"
EXPERIMENTAL RESULTS,0.24012158054711247,"5
EXPERIMENTAL RESULTS"
EXPERIMENTAL SETUP,0.24316109422492402,"5.1
EXPERIMENTAL SETUP"
EXPERIMENTAL SETUP,0.24620060790273557,"Datasets and training details. We evaluate our method on multiple datasets against state-of-the-art
CL methods. 1) PMNIST. Following (Lopez-Paz & Ranzato, 2017; Saha et al., 2021), we create
10 sequential tasks using different permutations where each task has 10 classes. We use a 3-layer
fully-connected network. 2) CIFAR-100 Split. We split the classes of CIFAR-100 (Krizhevsky
et al., 2009) into 10 group, and consider 10-way multi-class classiﬁcation in each group as a single
task. Similar with (Serra et al., 2018; Saha et al., 2021), we use a version of 5-layer AlexNet. 3)
CIFAR-100 Sup. We divide the CIFAR-100 dataset into 20 tasks where each task has 5 classes.
We use a modiﬁed version of LeNet-5. 4) 5-Datasets. We use a sequence of 5-Datasets which
includes CIFAR-10, MNIST, SVHN (Netzer et al., 2011), not-MNIST (Bulatov, 2011) and Fashion
MNIST (Xiao et al., 2017), where each dataset is set to be a task. We adapt a reduced ResNet18
network that is used in (Lopez-Paz & Ranzato, 2017). 5) MiniImageNet Split. We split the 100
classes of MiniImageNet (Vinyals et al., 2016) into 20 sequential tasks where each task has 5 classes,
and consider a reduced ResNet18 network. In addition, for all the experiments, the threshold ϵl is
set to 0.5, and we select top-2 tasks that satisfy condition Eq. (3). We use the same threshold ϵl
th as
GPM (Saha et al., 2021) for subspace construction. More details are in the appendix."
EXPERIMENTAL SETUP,0.24924012158054712,"Methods for comparison. To test the efﬁcacy of our method, we compare it with state-of-the-art
approaches in three categories: 1) Memory-based methods. We compare with Experience Replay
with reservoir sampling (ER Res) (Chaudhry et al., 2019), Averaged GEM (A-GEM) (Chaudhry
et al., 2018b), Orthogonal Weight Modulation (OWM) (Zeng et al., 2019) and Gradient Projection
Memory (GPM) (Saha et al., 2021). 2) Regularization-based methods. We compare with state-of-
the-art HAT (Serra et al., 2018) and Elastic Weight Consolidation (EWC) (Kirkpatrick et al., 2017).
3) Expansion-based methods. We further compare with Progressive Neural Network (PNN) (Rusu
et al., 2016), Learning Without Forgetting (LWF) (Li & Hoiem, 2017), Dynamic-Expansion Net
(DEN) (Yoon et al., 2017), and APD (Yoon et al., 2020), by using CIFAR-100 Sup dataset."
EXPERIMENTAL SETUP,0.25227963525835867,"Metrics. Following GPM (Saha et al., 2021), two metrics are used to evaluate the performance:
Accuracy (ACC), the average ﬁnal accuracy over all tasks, and Backward Transfer (BWT), which
measures the forgetting of old tasks when learning new tasks. ACC and BWT are deﬁned as:"
EXPERIMENTAL SETUP,0.2553191489361702,ACC = 1 T XT
EXPERIMENTAL SETUP,0.25835866261398177,"i=1 AT,i, BWT =
1
T −1 XT −1"
EXPERIMENTAL SETUP,0.2613981762917933,"i=1 AT,i −Ai,i
(10)"
EXPERIMENTAL SETUP,0.26443768996960487,"where T is the number of tasks, AT,i is the accuracy of the model on i-th task after learning the T-th
task sequentially."
MAIN RESULTS,0.2674772036474164,"5.2
MAIN RESULTS"
MAIN RESULTS,0.270516717325228,"ACC and BWT comparison. As shown in Table 1, TRGP achieves signiﬁcantly accuracy improve-
ment compared with prior works on all datasets. For example, in contrast to the best prior results,
TRGP achieve the accuracy gain of 2.43%, 1.98% and 1.37% over GPM on PMNIST, CIFAR-100
Split and MiniImageNet, respectively, and 2.34% over HAT on 5-Dataset. Surprisingly, we could
even achieve better accuracy than Multitask on 5-Datasets, which usually serves as an upper bound
for CL benchmarks. This superior performance of TRGP clearly shows its capability to effectively
facilitate forward knowledge transfer. In addition, TRGP also demonstrates strong performance with
the lowest BWT, reducing 0.2% than OWM and 0.6% than GPM, even with 5.63% and 2.34% ac-"
MAIN RESULTS,0.2735562310030395,Published as a conference paper at ICLR 2022
MAIN RESULTS,0.2765957446808511,"0
2
4
6
8
Number of tasks 94.5 95.0 95.5 96.0 96.5"
MAIN RESULTS,0.2796352583586626,Test Accuracy (%)
MAIN RESULTS,0.2826747720364742,Final accuracy for PMNIST
MAIN RESULTS,0.2857142857142857,"Ours
GPM"
MAIN RESULTS,0.2887537993920973,"0
2
4
6
8
Number of tasks 67.5 70.0 72.5 75.0 77.5"
MAIN RESULTS,0.2917933130699088,Test Accuracy (%)
MAIN RESULTS,0.2948328267477204,Final accuracy for CIFAR-100
MAIN RESULTS,0.2978723404255319,"Ours
GPM"
MAIN RESULTS,0.3009118541033435,"0
1
2
3
4
Number of tasks 80 90 100"
MAIN RESULTS,0.303951367781155,Test Accuracy (%)
MAIN RESULTS,0.3069908814589666,Final accuracy for 5-Datasets
MAIN RESULTS,0.3100303951367781,"Ours
GPM"
MAIN RESULTS,0.3130699088145897,Figure 4: The ﬁnal accuracy for all tasks on three datasets (GPM VS Ours).
MAIN RESULTS,0.3161094224924012,"Table 2: The performance for CIFAR-100 Sup dataset. Note that Single-task learning (STL) trains
a separate network for each task, which does not adhere to CL setup."
MAIN RESULTS,0.3191489361702128,"Metric
Methods"
MAIN RESULTS,0.3221884498480243,"STL
PNN
DEN
RCL
APD
GPM
Ours (TRGP)"
MAIN RESULTS,0.3252279635258359,"ACC(%)
61.00
50.76
51.10
51.99
56.81
57.72
58.25
Capacity(%)
2000
271
191
184
130
100
100"
MAIN RESULTS,0.3282674772036474,"curacy improvement on PMNIST and 5-Dataset, respectively. Compared with HAT on CIFAR-100
Split, TRGP has marginally worse BWT, but achieves 2.4% accuracy gain."
MAIN RESULTS,0.331306990881459,"Moreover, TRGP exhibits an universal dominance over GPM about the ﬁnal accuracy of all tasks on
all the three datasets. According to the apple to apple comparison with GPM in Fig. 4, one interesting
phenomenon is observed: TRGP has the similar accuracy on “easy” tasks, but signiﬁcantly improves
the accuracy on the “difﬁcult” tasks. For example, in the 5-Dataset setting, both TRGP and GPM
achieve good accuracy on Task 1 (MNIST) and 3 (Fashion MNIST), which can be easily trained
well, but TRGP signiﬁcantly outperforms GPM on the rest three more difﬁcult Tasks (CIFAR-10,
SVHN and NotMNIST). In the end, as shown in Table 2, we further compare with the expansion-
based methods by using CIFAR-100 Sup setting. It can be seen that TRGP outperforms all other CL
methods, with a ﬁxed capacity network."
MAIN RESULTS,0.3343465045592705,"Discussion. We next show the accuracy evolution of speciﬁc tasks during the training of all tasks
sequentially. We randomly select three tasks for each dataset to compare with GPM (we only show
results on PMNIST in Fig. 5 and relegate the rest to the appendix). There are two main obervations:
1) TRGP completely outperforms GPM during training for all the sequential tasks on the three
datasets; 2) For the PMNIST and 5-Dataset settings, TRGP could signiﬁcantly reduce forgetting. To
understand why, consider the case where GPM and TRGP learns a new task t given the same model
Wt−1, and denote {M l
t−1}l as the bases of all old tasks. Then we can have"
MAIN RESULTS,0.3373860182370821,"For GPM, the effective weight for layer l is
W l
eff = ProjMl
t−1(W l) + Proj⊥Ml
t−1(W l)
(11)"
MAIN RESULTS,0.3404255319148936,"where the weight projection on M l
t−1 is frozen to protect old tasks, and only the weight projection
orthogonal to M l
t−1 can be updated for learning task t."
MAIN RESULTS,0.3434650455927052,"For TRGP, the effective weight for layer l is
W l
eff = Proj{Sl
j}j /
∈T Rl
t
(W l) + ProjQ
{Sl
j}j∈T Rl
t
(W l) + Proj⊥Ml
t−1(W l)
(12)"
MAIN RESULTS,0.3465045592705167,"where only the ﬁrst term, i.e., weight projection on subspaces of old tasks that are not in the trust
region T Rl
t, is frozen for task t. In contrast to GPM, an additional and also important part of
weights, i.e., the scaled weight projection on subspaces of related old tasks in T Rl
t, can be learnt
in a favorable way for task t. As a result, TRGP can achieve better forward knowledge transfer
by explicitly and cleverly reusing the important knowledge of strongly correlated old tasks in the
trust region. More interestingly, beneﬁting from the task-unique information captured by the scaled
weight projection, the backward transfer can also be reduced."
MAIN RESULTS,0.3495440729483283,"2
4
6
8
Number of tasks 95 96 97"
MAIN RESULTS,0.3525835866261398,Test Accuracy (%)
MAIN RESULTS,0.3556231003039514,Accuracy envolution for Task 2
MAIN RESULTS,0.3586626139817629,"Ours
GPM"
MAIN RESULTS,0.3617021276595745,"4
6
8
Number of tasks 95.5 96.0 96.5 97.0"
MAIN RESULTS,0.364741641337386,Test Accuracy (%)
MAIN RESULTS,0.3677811550151976,Accuracy envolution for Task 4
MAIN RESULTS,0.3708206686930091,"Ours
GPM"
MAIN RESULTS,0.3738601823708207,"5
6
7
8
9
Number of tasks 96.0 96.5 97.0"
MAIN RESULTS,0.3768996960486322,Test Accuracy (%)
MAIN RESULTS,0.3799392097264438,Accuracy envolution for Task 6
MAIN RESULTS,0.3829787234042553,"Ours
GPM"
MAIN RESULTS,0.3860182370820669,Figure 5: Accuracy evolution for different tasks on PMNIST setting.
MAIN RESULTS,0.3890577507598784,Published as a conference paper at ICLR 2022
MAIN RESULTS,0.39209726443769,Table 3: Ablation study on CIFAR-100 Split and 5-Datasets settings.
MAIN RESULTS,0.3951367781155015,"Datasets
Impact of threshold ϵl
Layer-wise VS Task-wise
Number of selected tasks"
MAIN RESULTS,0.3981762917933131,"0.2
0.5
0.7
Layer-wise
Task-wise
Top-1
Top-2"
MAIN RESULTS,0.4012158054711246,"CIFAR-100
74.52
74.46
74.30
74.46
73.25
74.00
74.46
5-Datasets
93.28
93.56
93.43
93.56
92.85
92.94
93.56"
ABLATION STUDY AND ANALYSIS,0.40425531914893614,"5.3
ABLATION STUDY AND ANALYSIS"
ABLATION STUDY AND ANALYSIS,0.4072948328267477,"Impact of the threshold ϵl. To understand the impact of the threshold ϵl, we evaluate the learning
performance for three different values of ϵl (i.e., 0.2, 0.5, 0.7) as shown in Table 3. The results show
that the accuracy is very stable across the three threshold values, with ignoble accuracy difference on
both CIFAR-100 Split and 5-Dataset settings. The reason behind is because we only select top-2 old
tasks with largest gradient projection norm into the trust region, among all tasks satisfying condition
Eq. (3). Therefore, for a wide range of ϵl, the selected tasks in the trust region are actually ﬁxed.
The small accuracy ﬂuctuation is because with some possibility only one old task satisﬁes Eq. (3)
and is selected for some layers when ϵl increases. Overall, TRGP is very robust to the value of ϵl."
ABLATION STUDY AND ANALYSIS,0.41033434650455924,"0
2
4
6
8
Number of tasks 67.5 70.0 72.5 75.0 77.5"
ABLATION STUDY AND ANALYSIS,0.4133738601823708,Test Accuracy (%)
ABLATION STUDY AND ANALYSIS,0.41641337386018235,"Ours Layer-wise
Ours Task-wise GPM"
ABLATION STUDY AND ANALYSIS,0.4194528875379939,"Figure 6: The ﬁnal accuracy for
all tasks of Task-wise VS Layer-
wise on CIFAR-100 Split."
ABLATION STUDY AND ANALYSIS,0.42249240121580545,"Layer-wise vs. Task-wise trust region. To show the efﬁcacy of
layer-wise trust region, we compare it with the task-wise variant
which shares a ﬁxed trust region across all layers for each task.
First, as shown in Table 3, layer-wise could achieve 1.21% accu-
racy gain over task-wise on CIFAR-100 Split. Furthermore, we
illustrate the ﬁnal accuracy of all tasks for layer-wise and task-
wise of the proposed TRGP, and GPM on CIFAR-100 Split set-
ting in Fig. 6. First, the performance of layer-wise is better than
or comparable to task-wise for all tasks, because layer-wise pro-
vides a much ﬁner characterization of task correlations in terms
of layer-level features. Then, it is interesting to see that the learn-
ing behavior for the three cases follows the same trend. This observation further corroborates that
TRGP can improve the accuracy and mitigate forgetting on both “easy” and “difﬁcult” tasks."
ABLATION STUDY AND ANALYSIS,0.425531914893617,"Impact of selected tasks in trust region. We ﬁrst evaluate the accuracy of Top-1 and Top-2 selected
tasks as shown in Table 3. It shows that selecting the top-2 most correlated tasks could achieve better
accuracy on both CIFAR-100 Split and 5-Dataset settings. Note that good performance can also be
achieved even with the Top-1 case. Moreover, we illustrate the detailed task selection in the trust
region for both layer-wise and task-wise on 5-Dataset setting in Fig. 7. For the task-wise, current task
always selects the two adjacent previous tasks for all layers. Differently, the task selection varies for
layer-wise, leading to more accurate selection of related tasks for each layer. For example, the layer
wise trust region for Task 4 (Fashion MNIST) selects Task 1 (MNIST) or Task 3 (not-MNIST) as the
most related tasks almost for all layers, over Task 0 (CIFAR-10) and Task 2 (SVHN), which clearly
makes sense because Fashion MNIST shares more common features with MNIST and not-MNIST."
ABLATION STUDY AND ANALYSIS,0.42857142857142855,"0
2
4
Task Index 0 1 2 3"
ABLATION STUDY AND ANALYSIS,0.4316109422492401,Top-2 Seleted tasks
ABLATION STUDY AND ANALYSIS,0.43465045592705165,Task-wise
ST TASK,0.4376899696048632,"1st task
2ed task"
ST TASK,0.44072948328267475,"0
3
6
9
12
15
18
Layer Index 0 1 2"
ST TASK,0.44376899696048633,Top-2 Seleted tasks
ST TASK,0.44680851063829785,Layer-wise for Task 3
ST TASK,0.44984802431610943,"0
3
6
9
12
15
18
Layer Index 0 1 2 3"
ST TASK,0.45288753799392095,Layer-wise for Task 4
ST TASK,0.45592705167173253,Figure 7: The detailed selected tasks on 5-Datasets setting.
CONCLUSION,0.45896656534954405,"6
CONCLUSION"
CONCLUSION,0.46200607902735563,"In this work, we propose trust region gradient projection for continual learning to facilitate forward
knowledge transfer with forgetting, based on an efﬁcient characterization of task correlation. Par-
ticularly, our approach is built on two key blocks, i.e., the layer-wise trust region which effectively
select the old tasks strongly correlated to the new task in a single-shot manner, and scaled weight
projection which cleverly reuses the frozen weights of old tasks in the trust region without modifying
the model. Extensive experiments show that our approach signiﬁcantly improves over the related
state-of-the-art methods."
CONCLUSION,0.46504559270516715,Published as a conference paper at ICLR 2022
CONCLUSION,0.46808510638297873,ACKNOWLEDGEMENT
CONCLUSION,0.47112462006079026,"This work is supported in part by NSF Grants CNS-2003081, CNS-2203239, CPS-1739344, and
CCSS-2121222."
REPRODUCIBILITY STATEMENT,0.47416413373860183,REPRODUCIBILITY STATEMENT
REPRODUCIBILITY STATEMENT,0.47720364741641336,"For the experimental results presented in the main text, we include the code in the supplemental
material, and specify all the training details in Section 5.1 and Appendix A. For the datasets used in
the main text, we also give a clear explanation in Section 5.1."
REFERENCES,0.48024316109422494,REFERENCES
REFERENCES,0.48328267477203646,"Rahaf Aljundi, Francesca Babiloni, Mohamed Elhoseiny, Marcus Rohrbach, and Tinne Tuytelaars.
Memory aware synapses: Learning what (not) to forget. In Proceedings of the European Confer-
ence on Computer Vision (ECCV), pp. 139–154, 2018."
REFERENCES,0.48632218844984804,"Yaroslav Bulatov.
Notmnist dataset.
Google (Books/OCR), Tech. Rep.[Online]. Available:
http://yaroslavvb. blogspot. it/2011/09/notmnist-dataset. html, 2, 2011."
REFERENCES,0.48936170212765956,"Arslan Chaudhry, Puneet K Dokania, Thalaiyasingam Ajanthan, and Philip HS Torr. Riemannian
walk for incremental learning: Understanding forgetting and intransigence. In Proceedings of the
European Conference on Computer Vision (ECCV), pp. 532–547, 2018a."
REFERENCES,0.49240121580547114,"Arslan Chaudhry, Marc’Aurelio Ranzato, Marcus Rohrbach, and Mohamed Elhoseiny. Efﬁcient
lifelong learning with a-gem. arXiv preprint arXiv:1812.00420, 2018b."
REFERENCES,0.49544072948328266,"Arslan Chaudhry, Marcus Rohrbach, Mohamed Elhoseiny, Thalaiyasingam Ajanthan, Puneet K
Dokania, Philip HS Torr, and M Ranzato. Continual learning with tiny episodic memories. 2019."
REFERENCES,0.49848024316109424,"Zhiyuan Chen and Bing Liu. Lifelong machine learning. Synthesis Lectures on Artiﬁcial Intelligence
and Machine Learning, 12(3):1–207, 2018."
REFERENCES,0.5015197568389058,"Prithviraj Dhar, Rajat Vikram Singh, Kuan-Chuan Peng, Ziyan Wu, and Rama Chellappa. Learn-
ing without memorizing. In Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, pp. 5138–5146, 2019."
REFERENCES,0.5045592705167173,"Mehrdad Farajtabar, Navid Azizan, Alex Mott, and Ang Li. Orthogonal gradient descent for contin-
ual learning. In International Conference on Artiﬁcial Intelligence and Statistics, pp. 3762–3773.
PMLR, 2020."
REFERENCES,0.5075987841945289,"Yunhui Guo, Mingrui Liu, Tianbao Yang, and Tajana Rosing. Improved schemes for episodic mem-
ory based lifelong learning algorithm. In Conference on Neural Information Processing Systems,
2020."
REFERENCES,0.5106382978723404,"Steven CY Hung, Cheng-Hao Tu, Cheng-En Wu, Chien-Hung Chen, Yi-Ming Chan, and Chu-Song
Chen. Compacting, picking and growing for unforgetting continual learning. arXiv preprint
arXiv:1910.06562, 2019."
REFERENCES,0.513677811550152,"James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A
Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcom-
ing catastrophic forgetting in neural networks. Proceedings of the national academy of sciences,
114(13):3521–3526, 2017."
REFERENCES,0.5167173252279635,"Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.
2009."
REFERENCES,0.5197568389057751,"Sang-Woo Lee, Jin-Hwa Kim, Jaehyun Jun, Jung-Woo Ha, and Byoung-Tak Zhang. Overcom-
ing catastrophic forgetting by incremental moment matching. arXiv preprint arXiv:1703.08475,
2017."
REFERENCES,0.5227963525835866,Published as a conference paper at ICLR 2022
REFERENCES,0.5258358662613982,"Xilai Li, Yingbo Zhou, Tianfu Wu, Richard Socher, and Caiming Xiong. Learn to grow: A continual
structure learning framework for overcoming catastrophic forgetting. In International Conference
on Machine Learning, pp. 3925–3934. PMLR, 2019."
REFERENCES,0.5288753799392097,"Zhizhong Li and Derek Hoiem. Learning without forgetting. IEEE transactions on pattern analysis
and machine intelligence, 40(12):2935–2947, 2017."
REFERENCES,0.5319148936170213,"David Lopez-Paz and Marc’Aurelio Ranzato. Gradient episodic memory for continual learning.
Advances in neural information processing systems, 30:6467–6476, 2017."
REFERENCES,0.5349544072948328,"Michael McCloskey and Neal J Cohen. Catastrophic interference in connectionist networks: The
sequential learning problem. In Psychology of learning and motivation, volume 24, pp. 109–165.
Elsevier, 1989."
REFERENCES,0.5379939209726444,"Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading
digits in natural images with unsupervised feature learning. 2011."
REFERENCES,0.541033434650456,"Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina Rish, Yuhai Tu, and Gerald
Tesauro. Learning to learn without forgetting by maximizing transfer and minimizing interfer-
ence. arXiv preprint arXiv:1810.11910, 2018."
REFERENCES,0.5440729483282675,"Hippolyt Ritter, Aleksandar Botev, and David Barber. Online structured laplace approximations for
overcoming catastrophic forgetting. arXiv preprint arXiv:1805.07810, 2018."
REFERENCES,0.547112462006079,"Amir Rosenfeld and John K Tsotsos. Incremental learning through deep adaptation. IEEE transac-
tions on pattern analysis and machine intelligence, 42(3):651–663, 2018."
REFERENCES,0.5501519756838906,"Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray
Kavukcuoglu, Razvan Pascanu, and Raia Hadsell. Progressive neural networks. arXiv preprint
arXiv:1606.04671, 2016."
REFERENCES,0.5531914893617021,"Gobinda Saha, Isha Garg, and Kaushik Roy. Gradient projection memory for continual learning.
arXiv preprint arXiv:2103.09762, 2021."
REFERENCES,0.5562310030395137,"John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp Moritz. Trust region
policy optimization. In International conference on machine learning, pp. 1889–1897. PMLR,
2015."
REFERENCES,0.5592705167173252,"Jonathan Schwarz, Wojciech Czarnecki, Jelena Luketina, Agnieszka Grabska-Barwinska, Yee Whye
Teh, Razvan Pascanu, and Raia Hadsell. Progress & compress: A scalable framework for contin-
ual learning. In International Conference on Machine Learning, pp. 4528–4537. PMLR, 2018."
REFERENCES,0.5623100303951368,"Joan Serra, Didac Suris, Marius Miron, and Alexandros Karatzoglou. Overcoming catastrophic
forgetting with hard attention to the task. In International Conference on Machine Learning, pp.
4548–4557. PMLR, 2018."
REFERENCES,0.5653495440729484,"Hanul Shin, Jung Kwon Lee, Jaehong Kim, and Jiwon Kim. Continual learning with deep generative
replay. arXiv preprint arXiv:1705.08690, 2017."
REFERENCES,0.5683890577507599,"Tom Veniat, Ludovic Denoyer, and Marc’Aurelio Ranzato. Efﬁcient continual learning with modular
networks and task-driven priors. arXiv preprint arXiv:2012.12631, 2020."
REFERENCES,0.5714285714285714,"Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al. Matching networks for one
shot learning. Advances in neural information processing systems, 29:3630–3638, 2016."
REFERENCES,0.574468085106383,"Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmark-
ing machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017."
REFERENCES,0.5775075987841946,"Ju Xu and Zhanxing Zhu. Reinforced continual learning. arXiv preprint arXiv:1805.12369, 2018."
REFERENCES,0.5805471124620061,"Jaehong Yoon, Eunho Yang, Jeongtae Lee, and Sung Ju Hwang. Lifelong learning with dynamically
expandable networks. arXiv preprint arXiv:1708.01547, 2017."
REFERENCES,0.5835866261398176,Published as a conference paper at ICLR 2022
REFERENCES,0.5866261398176292,"Jaehong Yoon, Saehoon Kim, Eunho Yang, and Sung Ju Hwang. Scalable and order-robust continual
learning with additive parameter decomposition. In Eighth International Conference on Learning
Representations, ICLR 2020. ICLR, 2020."
REFERENCES,0.5896656534954408,"Guanxiong Zeng, Yang Chen, Bo Cui, and Shan Yu. Continual learning of context-dependent pro-
cessing in neural networks. Nature Machine Intelligence, 1(8):364–372, 2019."
REFERENCES,0.5927051671732523,"Friedemann Zenke, Ben Poole, and Surya Ganguli. Continual learning through synaptic intelligence.
In International Conference on Machine Learning, pp. 3987–3995. PMLR, 2017."
REFERENCES,0.5957446808510638,"Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding
deep learning (still) requires rethinking generalization. Communications of the ACM, 64(3):107–
115, 2021."
REFERENCES,0.5987841945288754,Published as a conference paper at ICLR 2022
REFERENCES,0.601823708206687,"A
EXPERIMENT SETUPS"
REFERENCES,0.6048632218844985,"Training hyper-parameters. We evaluate our method on multiple datasets against state-of-the-art
continual learning methods. 1) PMNIST. We use a 3-layer fully-connected network. with two
hidden layer of 100 units. and train the network for 5 epochs with batch size of 10 for each task. 2)
CIFAR-100 Split. CIFAR-100 (Krizhevsky et al., 2009) consists of images from 100 generic object
classes. We use a version of 5-layer AlexNet and train each task for maximum of 200 epochs with the
early termination strategy based on the validation loss value. The batch size is set to 64. 3) CIFAR-
100 Sup. We use a modiﬁed version of LeNet-5 with 20-50-800-500 neurons and train 50 epochs for
each task sequentially. The batch size is set to 64. 4) 5-Datasets. We train each task for maximum
of 200 epochs with the early termination strategy. The batch size is set to 64. 5) MiniImageNet
Split. Following GPM (Saha et al., 2021), we use the reduced ResNet18 architecture, where the
covolution with stride 2 in the ﬁrst layer. We train each task for maximum of 100 epochs with
the early termination strategy with 0.1 initial learning rate and 64 batchsize. In addition, for all the
experiments, the threshold ϵl is set to 0.5, and we select top-2 tasks that satisfy condition Eq. (3). We
use the same threshold ϵl
th as GPM (Saha et al., 2021) for subspace construction. We initialize the
scaling matrix with the identity matrix and train all models with plain stochastic gradient descent."
REFERENCES,0.60790273556231,"B
MORE EXPERIMENTAL RESULTS"
REFERENCES,0.6109422492401215,"B.1
ACCURACY EVOLUTION"
REFERENCES,0.6139817629179332,"2
4
6
8
Number of tasks 66 67 68 69"
REFERENCES,0.6170212765957447,Test Accuracy (%)
REFERENCES,0.6200607902735562,Accuracy envolution for Task 2
REFERENCES,0.6231003039513677,"Ours
GPM"
REFERENCES,0.6261398176291794,"4
6
8
Number of tasks 70 72 74"
REFERENCES,0.6291793313069909,Test Accuracy (%)
REFERENCES,0.6322188449848024,Accuracy envolution for Task 4
REFERENCES,0.6352583586626139,"Ours
GPM"
REFERENCES,0.6382978723404256,"5
6
7
8
9
Number of tasks 72 73 74 75 76"
REFERENCES,0.6413373860182371,Test Accuracy (%)
REFERENCES,0.6443768996960486,Accuracy envolution for Task 6
REFERENCES,0.6474164133738601,"Ours
GPM"
REFERENCES,0.6504559270516718,(a) CIFAR-100 Split
REFERENCES,0.6534954407294833,"0
1
2
3
4
Number of tasks 76 78 80"
REFERENCES,0.6565349544072948,Test Accuracy (%)
REFERENCES,0.6595744680851063,Accuracy envolution for Task 1
REFERENCES,0.662613981762918,"Ours
GPM"
REFERENCES,0.6656534954407295,"1
2
3
4
Number of tasks 98.8 99.0 99.2 99.4"
REFERENCES,0.668693009118541,Test Accuracy (%)
REFERENCES,0.6717325227963525,Accuracy envolution for Task 2
REFERENCES,0.6747720364741642,"Ours
GPM"
REFERENCES,0.6778115501519757,"2.0
2.5
3.0
3.5
4.0
Number of tasks 88 90 92"
REFERENCES,0.6808510638297872,Test Accuracy (%)
REFERENCES,0.6838905775075987,Accuracy envolution for Task 3
REFERENCES,0.6869300911854104,"Ours
GPM"
REFERENCES,0.6899696048632219,(b) 5-Datasets
REFERENCES,0.6930091185410334,Figure 8: Accuracy evolution for different tasks on CIFAR-100 Split and 5-Datasets settings.
REFERENCES,0.6960486322188449,"B.2
STANDARD DEVIATION"
REFERENCES,0.6990881458966566,"We have summarized the results on the standard deviation for the averaged accuracy and backward
transfer over 5 different runs on all datasets in Table 4."
REFERENCES,0.7021276595744681,"Table 4: The averaged accuracy (ACC) and backward transfer (BWT) with the standard deviation
values over 5 different runs on different datasets."
REFERENCES,0.7051671732522796,"Method
PMNIST
CIFAR-100 Split
5-Dataset
MiniImageNet"
REFERENCES,0.7082066869300911,"ACC(%)
BWT(%)
ACC(%)
BWT(%)
ACC(%)
BWT(%)
ACC(%)
BWT(%)"
REFERENCES,0.7112462006079028,"Multitask
96.70 ± 0.02
-
79.58 ± 0.54
-
91.54 ± 0.28
-
69.46 ± 0.62
-"
REFERENCES,0.7142857142857143,"OWM
90.71 ± 0.11
−1 ± 0
50.94 ± 0.60
−30 ± 1
-
-
-
-
EWC
89.97 ± 0.57
−4 ± 1
68.80 ± 0.88
−2 ± 1
88.64 ± 0.26
−4 ± 1
52.01 ± 2.53
−12 ± 3
HAT
-
-
72.06 ± 0.50
0 ± 0
91.32 ± 0.18
−1 ± 0
59.78 ± 0.57
−3 ± 0
A-GEM
83.56 ± 0.16
−14 ± 1
63.98 ± 1.22
−15 ± 2
84.04 ± 0.33
−12 ± 1
57.24 ± 0.72
−12 ± 1
ER Res
87.24 ± 0.53
−11 ± 1
71.73 ± 0.63
−6 ± 1
88.31 ± 0.22
−4 ± 0
58.94 ± 0.85
−7 ± 1
GPM
93.91 ± 0.16
−3 ± 0
72.48 ± 0.40
−0.9 ± 0
91.22 ± 0.20
−1 ± 0
60.41 ± 0.61
−0.7 ± 0.4"
REFERENCES,0.7173252279635258,"Ours (TRGP)
96.34 ± 0.11
96.34 ± 0.11
96.34 ± 0.11
−0.8 ± 0.1
−0.8 ± 0.1
−0.8 ± 0.1
74.46 ± 0.32
74.46 ± 0.32
74.46 ± 0.32
−0.9 ± 0.01
−0.9 ± 0.01
−0.9 ± 0.01
93.56 ± 0.10
93.56 ± 0.10
93.56 ± 0.10
−0.04 ± 0.01
−0.04 ± 0.01
−0.04 ± 0.01
61.78 ± 0.60
61.78 ± 0.60
61.78 ± 0.60
−0.5 ± 0.6
−0.5 ± 0.6
−0.5 ± 0.6"
REFERENCES,0.7203647416413373,Published as a conference paper at ICLR 2022
REFERENCES,0.723404255319149,"B.3
FORWARD TRANSFER"
REFERENCES,0.7264437689969605,"To evaluate the forward transfer, we follow the metric used in (Veniat et al., 2020) and consider the
accuracy of the model on i-th task after learning the i-th task sequentially, i.e., Ai,i as deﬁned in
Eq. (10). Tables 5 - 8 summarize the comparison of Ai,i for each task i between GPM and TRGP on
PMNIST, CIFAR-100 Split and 5-Dataset, respectively. As the same baseline (e.g., the accuracy of
the model learnt from scratch using the task’s own data) for each task will be used when evaluating
the forward transfer for GPM and TRGP, we can infer that TRGP achieves the forward transfer
gain of 0.17%, 2.01%, 2.00% and 2.36% over GPM on PMNIST, CIFAR-100 Split, 5-Datasets and
MiniImageNet respectively."
REFERENCES,0.729483282674772,"Table 5: The accuracy Ai,i of the model on i-th task after learning the i-th task sequentially on
PMNIST 10 tasks."
REFERENCES,0.7325227963525835,"Methods
1
2
3
4
5
6
7
8
9
10
Avg"
REFERENCES,0.7355623100303952,"GPM
97.5
97.5
97.3
97.1
97.0
96.9
96.8
96.4
96.5
96.5
96.95"
REFERENCES,0.7386018237082067,"Ours (TRGP)
97.5
97.5
97.5
97.3
97.1
97.1
96.9
96.7
96.9
96.7
97.12"
REFERENCES,0.7416413373860182,"Table 6: The accuracy Ai,i of the model on i-th task after learning the i-th task sequentially on
CIFAR-100 Split 10 tasks."
REFERENCES,0.7446808510638298,"Methods
1
2
3
4
5
6
7
8
9
10
Avg"
REFERENCES,0.7477203647416414,"GPM
76.8
68.5
72.4
69.9
74.8
72.3
70.3
71.9
73.2
75.1
72.52"
REFERENCES,0.7507598784194529,"Ours (TRGP)
76.9
69.5
75.1
74.1
75.3
75.8
72.8
73.8
73.9
78.1
74.53"
REFERENCES,0.7537993920972644,"Table 7: The accuracy Ai,i of the model on i-th task after learning the i-th task sequentially on
5-Dataset 5 tasks."
REFERENCES,0.756838905775076,"Methods
1
2
3
4
5
Avg"
REFERENCES,0.7598784194528876,"GPM
78.3
99.1
87.1
99.1
94.1
91.54"
REFERENCES,0.7629179331306991,"Ours (TRGP)
80.9
99.3
92.8
99.4
95.3
93.54"
REFERENCES,0.7659574468085106,"Table 8: The accuracy Ai,i of the model on i-th task after learning the i-th task sequentially on
MiniImageNet Split 20 tasks."
REFERENCES,0.7689969604863222,"Methods
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
Avg"
REFERENCES,0.7720364741641338,"GPM
58.6
63.6
57.2
59.0
53.6
78.0
63.0
66.0
74.0
83.8
43.0
60.4
55.6
57.8
59.6
53.0
56.0
47.6
66.0
56.8
60.63"
REFERENCES,0.7750759878419453,"Ours (TRGP)
58.7
66.1
59.2
59.3
57.1
81.4
67.3
70.1
75.7
85.2
43.2
61.8
58.0
60.1
60.0
54.8
61.4
48.4
69.8
62.2
62.99"
REFERENCES,0.7781155015197568,"B.4
COMPUTATIONAL COMPLEXITY"
REFERENCES,0.7811550151975684,"Memory: In terms of the memory, the major difference between TRGP and GPM is that TRGP
requires additional memory to store the scaling matrices for each task. However, since the dimension
of the scaling matrix is the same with the number of the extracted bases for the input subspace,
which is usually small and controllable by the matrix approximation accuracy ϵth in Eq. (7), the
memory increase is marginal and controllable. Particularly, the memory usage of TRGP can be
further reduced by only learning the scaling matrices for the convolutional layers."
REFERENCES,0.78419452887538,"Training time: We compare the training time between TRGP and other baselines on relatively com-
plex task sequences. As shown in Table 9, for CIFAR-100 Split, TRGP takes around 65% more
time than GPM, is comparable with HAT and ER Res, and takes less time than OWM and EWC; for
5-Datasets, TRGP takes around 21% more time than GPM, but is much faster than other baselines
including EWC, HAT, A-GEM and ER Res; for MiniImageNet, TRGP tasks around 34% more time
than GPM, is comparable with EWC, but is much faster than A-GEM."
REFERENCES,0.7872340425531915,Published as a conference paper at ICLR 2022
REFERENCES,0.790273556231003,"Table 9: Training time comparison on CIFAR-100 Split, 5-Datasets and MiniImageNet. Here the
training time is normalized with respect to the value of GPM. Please refer (Saha et al., 2021) for
more speciﬁc time."
REFERENCES,0.7933130699088146,"Dataset
Methods"
REFERENCES,0.7963525835866262,"OWM
EWC
HAT
A-GEM
ER Res
GPM
Ours (TRGP)"
REFERENCES,0.7993920972644377,"CIFAR-100
2.41
1.76
1.62
3.48
1.49
1
1.65
5-Datasets
-
1.52
1.47
2.41
1.40
1
1.21
MiniImageNet
-
1.22
0.91
1.79
0.82
1
1.34"
REFERENCES,0.8024316109422492,"B.5
ACCURACY VS LEARNING EPOCHS"
REFERENCES,0.8054711246200608,"The learning dynamics for each task are shown in Figure 9 and 10. Clearly, our approach can
perform signiﬁcantly better than GPM on some tasks, especially for the tasks in the tail of the task
sequence. This is because in GPM, with more tasks being learnt, the optimization space for new
tasks becomes more restrictive, leading to limited performance for new tasks. Note that the y-axis
is the validation accuracy with a split validate dataset that used during training, by following the
setup in (Saha et al., 2021). The validation accuracy varies because the size of the validate dataset
is relatively small (See (Saha et al., 2021) for the speciﬁc size). For the testing accuracy in all the
tables, we evaluate the accuracy with the testing dataset after training."
REFERENCES,0.8085106382978723,"0
20
40
60
80
Number of Epochs 50 60 70"
REFERENCES,0.8115501519756839,Valid Accuracy (%)
REFERENCES,0.8145896656534954,Task-1
REFERENCES,0.817629179331307,"GPM
Ours"
REFERENCES,0.8206686930091185,"0
20
40
60
80
Number of Epochs 55 60 65 70"
REFERENCES,0.8237082066869301,Valid Accuracy (%)
REFERENCES,0.8267477203647416,Task-2
REFERENCES,0.8297872340425532,"GPM
Ours"
REFERENCES,0.8328267477203647,"0
20
40
60
80
Number of Epochs 60 70"
REFERENCES,0.8358662613981763,Valid Accuracy (%)
REFERENCES,0.8389057750759878,Task-3
REFERENCES,0.8419452887537994,"GPM
Ours"
REFERENCES,0.8449848024316109,"0
20
40
60
80
100
Number of Epochs 50 60 70"
REFERENCES,0.8480243161094225,Valid Accuracy (%)
REFERENCES,0.851063829787234,Task-4
REFERENCES,0.8541033434650456,"GPM
Ours"
REFERENCES,0.8571428571428571,"0
20
40
60
80
Number of Epochs 60 65 70 75"
REFERENCES,0.8601823708206687,Valid Accuracy (%)
REFERENCES,0.8632218844984803,Task-5
REFERENCES,0.8662613981762918,"GPM
Ours"
REFERENCES,0.8693009118541033,"0
20
40
60
80
100
Number of Epochs 60 70 80"
REFERENCES,0.8723404255319149,Valid Accuracy (%)
REFERENCES,0.8753799392097265,Task-6
REFERENCES,0.878419452887538,"GPM
Ours"
REFERENCES,0.8814589665653495,"0
20
40
60
80
Number of Epochs 55 60 65 70"
REFERENCES,0.8844984802431611,valid Accuracy (%)
REFERENCES,0.8875379939209727,Task-7
REFERENCES,0.8905775075987842,"GPM
Ours"
REFERENCES,0.8936170212765957,"0
20
40
60
80
Number of Epochs 60 65 70"
REFERENCES,0.8966565349544073,Valid Accuracy (%)
REFERENCES,0.8996960486322189,Task-8
REFERENCES,0.9027355623100304,"GPM
Ours"
REFERENCES,0.9057750759878419,"0
20
40
60
80
Number of Epochs 60 65 70 75"
REFERENCES,0.9088145896656535,Valid Accuracy (%)
REFERENCES,0.9118541033434651,Task-9
REFERENCES,0.9148936170212766,"GPM
Ours"
REFERENCES,0.9179331306990881,"0
20
40
60
80
Number of Epochs 65 70 75 80"
REFERENCES,0.9209726443768997,Valid Accuracy (%)
REFERENCES,0.9240121580547113,Task-10
REFERENCES,0.9270516717325228,"GPM
Ours"
REFERENCES,0.9300911854103343,Figure 9: Accuracy vs learning epochs for different tasks on CIFAR-100 Split.
REFERENCES,0.9331306990881459,Published as a conference paper at ICLR 2022
REFERENCES,0.9361702127659575,"0
10
20
30
Number of Epochs 50 60 70 80"
REFERENCES,0.939209726443769,Valid Accuracy (%)
REFERENCES,0.9422492401215805,Task-1 CIFAR10
REFERENCES,0.9452887537993921,"GPM
Ours"
REFERENCES,0.9483282674772037,"0
10
20
30
Number of Epochs 98.4 98.6 98.8 99.0 99.2"
REFERENCES,0.9513677811550152,Valid Accuracy (%)
REFERENCES,0.9544072948328267,Task-2 MNIST
REFERENCES,0.9574468085106383,"GPM
Ours"
REFERENCES,0.9604863221884499,"0
10
20
Number of Epochs 82.5 85.0 87.5 90.0 92.5"
REFERENCES,0.9635258358662614,Valid Accuracy (%)
REFERENCES,0.9665653495440729,Task-3 SVHN
REFERENCES,0.9696048632218845,"GPM
Ours"
REFERENCES,0.9726443768996961,"0
10
20
30
Number of Epochs 98.6 98.8 99.0 99.2 99.4"
REFERENCES,0.9756838905775076,Valid Accuracy (%)
REFERENCES,0.9787234042553191,Task-4 Fashion-mnist
REFERENCES,0.9817629179331308,"GPM
Ours"
REFERENCES,0.9848024316109423,"0
10
20
30
Number of Epochs 90 92 94 96"
REFERENCES,0.9878419452887538,Valid Accuracy (%)
REFERENCES,0.9908814589665653,Task-5 Notmnist
REFERENCES,0.993920972644377,"GPM
Ours"
REFERENCES,0.9969604863221885,Figure 10: Accuracy vs learning epochs for ﬁve tasks on 5-Dataset.
