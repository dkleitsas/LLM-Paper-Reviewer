Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.001072961373390558,"Machine learning (ML) robustness and generalization are fundamentally corre-
lated: they essentially concern about data distribution shift under adversarial and
natural settings, respectively. Thus, it is critical to uncover their underlying con-
nections to tackle one based on the other. On one hand, recent studies show that
more robust (adversarially trained) models are more generalizable to other do-
mains. On the other hand, there lacks of theoretical understanding of such phe-
nomenon, and it is not clear whether there are counterexamples. In this paper, we
aim to provide sufﬁcient conditions for this phenomenon considering different fac-
tors that could affect both, such as norm of the last layer, Jacobian norm, and data
augmentations (DA). In particular, we propose a general theoretical framework
indicating factors that can be reformed as a function class regularization process,
which could lead to improvements of domain generalization. Our analysis, for the
ﬁrst time, shows that “robustness” is actually not the causation for domain gener-
alization; rather, robustness induced by adversarial training is a by-product of such
function class regularization. We then discuss in details about different properties
of DA and we prove that under certain conditions, DA can be viewed as regular-
ization and therefore improve generalization. We conduct extensive experiments
to verify our theoretical ﬁndings and show several counterexamples where robust-
ness and generalization are negatively correlated when the sufﬁcient conditions
are not satisﬁed."
INTRODUCTION,0.002145922746781116,"1
INTRODUCTION"
INTRODUCTION,0.003218884120171674,"Domain generalization (or transferability) is the task of training machine learning models with
data from one or more source domains that can be adapted to a target domain, often via low-
cost ﬁne-tuning.
Thus, domain generalization refers to approaches designed to address the
natural data distribution shift problem (Muandet et al., 2013; Rosenfeld et al., 2021). A wide array of
approaches have been proposed to address domain transferability, including ﬁne-tuning the last layer
of DNNs (Huang et al., 2018), invariant feature optimization (Muandet et al., 2013), efﬁcient model
selection for ﬁne-tuning (You et al., 2019), and optimal transport based domain adaptation (Courty
et al., 2016). Improving domain generalization has emerged as an important task in the machine
learning community: for instance, it is among the key technologies to enable an autonomous driving
vehicle trained in city scenarios to make correct decisions in the countryside as well."
INTRODUCTION,0.004291845493562232,"On
the
other
hand,
robust
machine
learning
aims
to
tackle
the
problem
of
adversarial data distribution shift.
Both empirical and certiﬁed robust learning approaches
have been proposed, such as empirical adversarial training (Madry et al., 2018) and certiﬁed
defenses based on deterministic and probabilistic approaches (Cohen et al., 2019)."
INTRODUCTION,0.00536480686695279,"As domain transferability and robust machine learning tackle different kinds of data distribution
shifts, this work seeks to uncover their underlying connections and tradeoffs. For instance, recent
studies suggest that adversarially robust models are more domain transferable (Salman et al., 2020),
which, in turn, provides new insights on improving domain generalization. However, a theoretical
analysis of their relationship is still lacking, and it is unclear whether such positive correlations al-"
INTRODUCTION,0.006437768240343348,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.0075107296137339056,(c) Last-Layer norm
INTRODUCTION,0.008583690987124463,"Adversarially robust models may
not transfer better"
INTRODUCTION,0.009656652360515022,Sufficient conditions for domain transferability
INTRODUCTION,0.01072961373390558,"(b) Jacobian norm
(a) Data augmentations"
INTRODUCTION,0.011802575107296138,"Source
Domain
Feature Extractor
Last Layer"
INTRODUCTION,0.012875536480686695,"(a)
(b)
(c) …"
INTRODUCTION,0.013948497854077254,Figure 1: Illustration of robustness and domain transferability in different conditions.
INTRODUCTION,0.015021459227467811,"ways hold. In this paper, we take the ﬁrst steps towards formally analyzing the relationship between
model robustness and domain transferability to answer the following questions: What are sufﬁcient
conditions for domain transferability? Is model robustness the cause of domain transferability? Can
robustness and domain transferability be negatively correlated?"
INTRODUCTION,0.016094420600858368,"To answer the above questions and uncover the underlying relationship between robustness and
domain transferability, we propose a general theoretical framework that characterizes sufﬁcient con-
ditions for domain transferability from the view of function class regularization. Our analysis shows
that if the function class of feature extractors is more regularized, the model based on a feature
extractor trained from the function class, composed with a ﬁne-tuned last layer, can be more trans-
ferable. Formally, we prove that there is a monotone relation between the regularization strength
and a tight upper bound on the relative domain transfer loss."
INTRODUCTION,0.017167381974248927,"Under the proposed framework, we analyze several common factors for model training, including
the Jacobian norm, the last layer norm, data augmentation, and adversarial training as shown in
Fig. 1. In particular, controlling the Jacobian norm and last layer norm can be viewed as function-
class regularization, thus can be analyzed in our framework. We also analyze how other common
regularization operations can be mapped to function class regularization. For instance, we consider
noise-dependent and independent data augmentation procedures based on feature average and loss
average aggregation algorithms."
INTRODUCTION,0.018240343347639486,"We conduct extensive experiments on ImageNet (CIFAR-10 as target domain) and CIFAR-10
(SVHN as target domain) based on different models to verify our analysis. We show that regulariza-
tion can control domain transferability, and robustness and domain transferability can be negatively
correlated, which are counter-examples against Salman et al. (2020). Taken together, this indicates
that robustness is not a cause of transferability."
INTRODUCTION,0.019313304721030045,"Technical Contributions. We aim to uncover the underlying relationship between robustness and
domain transferability and lay out the sufﬁcient conditions for transferability from the view of reg-
ularization. We make both theoretical and empirical contributions."
INTRODUCTION,0.0203862660944206,"• We propose a theoretical framework to analyze the sufﬁcient conditions for domain transferability
from the view of function class regularization. We provably show that stronger regularization
on the feature extractor implies a decreased tight upper bound on the relative transferability loss;
while model robustness could be arbitrary."
INTRODUCTION,0.02145922746781116,"• We prove the tightness of our transferability upper bound, and provide the generalization bound
of the relative transferability loss from the view of regularization."
INTRODUCTION,0.022532188841201718,"• We analyze several factors such as different data augmentations (e.g., rotation and Gaussian) under
the framework, and show how they can be mapped to function class regularization and therefore
affect transferability."
INTRODUCTION,0.023605150214592276,"• We conduct extensive experiments on different datasets and model architectures to verify our theo-
retical claims. We also show several counterexamples that indicate signiﬁcant negative correlation
between robustness and the relative domain transferability."
RELATED WORK,0.02467811158798283,"2
RELATED WORK"
RELATED WORK,0.02575107296137339,"Domain Transferability has been analyzed in different settings. Muandet et al. present a gener-
alization bound for classiﬁcation task based on the properties of the assumed prior over training
environments. Rosenfeld et al. model domain transferability/generalization as an online game and
show that generalizing beyond the convex hull of training environments is NP-hard, and Zhang et al.
provides a generalization bound for distributions with sufﬁciently small H-divergence. Given the"
RELATED WORK,0.02682403433476395,Under review as a conference paper at ICLR 2022
RELATED WORK,0.027896995708154508,"complexity of domain transferability analysis, recent empirical studies show that adversarially ro-
bust models transfer better (Salman et al., 2020). In this paper, we aim to relax the assumptions and
focus on understanding the domain transferability from the view of regularization and theoretically
show whether “robustness” is indeed a causation for transferability or not."
RELATED WORK,0.028969957081545063,"Model Robustness is an important topic given recent diverse adversarial attacks (Goodfellow et al.,
2014; Carlini & Wagner, 2017). These attacks may be launched without access to model param-
eters (Tu et al., 2019) or even with the model predicted label alone (Chen et al., 2020). Different
approaches have been proposed to improve model robustness against adversarial attack. Adversar-
ial training has been shown to be effective empirically (Madry et al., 2018; Zhang et al., 2019a;
Miyato et al., 2018). Some studies have shown that robustness is property related to other model
characteristics, such as transferability and invertibility (Engstrom et al., 2019)."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.030042918454935622,"3
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.03111587982832618,"In this section, we theoretically analyze the problem of domain transferability from the view of
regularization and discuss some sufﬁcient conditions for good transferability. All of the proofs are
provided in Section A in the appendix."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.032188841201716736,"Notations. We denote the input space as X; the feature space as Z and the output space as Y. Let
the ﬁne-tuning function class be g ∈G. Given a feature extractor f : X →Z and a ﬁne-tuning
function g : Z →Y, the full model is g ◦f : X →Y. We denote PX×Y as the set of distributions
on X × Y. The loss function is denoted by ℓ: Y × Y →R+, and the population loss based on data
distribution D ∈PX×Y and a model g ◦f is deﬁned as"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.033261802575107295,"ℓD(g ◦f) := E(x,y)∼D[ℓ(g ◦f(x), y)]."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.034334763948497854,"Before diving into the details, we ﬁrst provide the following example to illustrate why one might
investigate domain transferability from the view of regularization."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.03540772532188841,"3.1
EXAMPLE: ROBUSTNESS AND TRANSFERABILITY ARE INDEPENDENT"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.03648068669527897,"In this subsection, we construct a simple example where domain transferability depends on regular-
ization, yet domain transferability and robustness are independent. Moreover, this example serves
as motivation to consider domain transferability from the view of regularization."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.03755364806866953,"Given the source and target distributions DS, DT ∈PX×Y, we denote their marginal distributions
on the input space X as DX
S and DX
T , respectively. We consider the case that X ⊂Rm being a
low-dimensional manifold in Rm, and Y = Rd. Given an input x ∈X, the ground truth target for
the source domain is yS(x) generated by a function yS : Rm →Rd. Similarly, we deﬁne yT for
the target domain. In this example, for simplicity, we neglect the ﬁne-tuning process but directly
consider learning a function f : Rm →Rd with a norm ∥· ∥on Rd. For the source domain we have
the population loss:"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.03862660944206009,"ℓDS(f) = Ex∼DX
S [∥f(x) −yS(x)∥]."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.03969957081545064,"A distribution D ∈PX on the input space X, deﬁnes a norm of a function f : Rm →Rd as"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.0407725321888412,"∥f∥D := Ex∼D[∥f(x)∥],"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.04184549356223176,"where we view two functions f1, f2 as the same if ∥f1 −f2∥D = 0. Therefore, we can deﬁne the
source domain loss ℓDS(f) = ∥f −yS∥DX
S and the target domain loss ℓDT (f) = ∥f −yT ∥DX
T ."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.04291845493562232,"For the sake of illustration, we consider the simple case where the input distributions DX
S , DX
T are
the same, and hence we denote D = DX
S = DX
T . Note that yS and yT are different."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.043991416309012876,"Denoting a function space F = {f : Rm →Rd | ∥f∥D < ∞}, we assume that yS, yT ∈F and we
can compare f, yS, yT in the same space. Therefore, given c > 0 as a regularization parameter, the
domain transferability problem can be deﬁned as:"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.045064377682403435,"Learning a source model:
f DS
c
∈arg min
f∈F
ℓDS(f),
s.t. ∥f∥D ≤c;
(1)"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.046137339055793994,"Testing on a target domain:
ℓDT (f DS
c
),"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.04721030042918455,Under review as a conference paper at ICLR 2022
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.048283261802575105,"where the minimizer f DS
c
:= yS min{1,
c
∥yS∥D }, the source domain loss is ℓDS(f) = ∥f −yS∥D,
and the target domain loss is ℓDT (f) = ∥f −yT ∥D. We prove in Proposition 3.1 that f DS
c
is indeed
a minimizer of (1) and provide an intuitive illustration in Figure 2."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.04935622317596566,"We show that the robustness can be independent to domain transferability as follows. Consider the
adversarial robustness of f DS
c
on an input x ∈X (e.g., maxδ:∥δ∥2≤ϵ ℓ(f DS
c
(x + δ), yS(x))). Since
the transferred loss ℓDT (f DS
c
) only evaluates f DS
c
on X which is a low-dimensional manifold in
Rm, an adversarial perturbation δ ∈Rm could make x + δ ∈Rm\X when the loss function is
sufﬁciently big outside the manifold X. Therefore, the robustness could be arbitrarily bad without
changing the value of ℓDT (f DS
c
), i.e., the performance of the source model on the target domain."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.05042918454935622,"As we can see, the robustness is independent to domain transferability in this example. On the
contrary, if we change the perspective to consider the the regularization parameter c, we have the
following interesting ﬁnding. An illustration of the ﬁnding is shown in Figure 2, and a more formal
statement is provided in Proposition 3.1. ℱ"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.05150214592274678,"||𝑓||𝒟≤𝑐 𝑓𝑐 𝒟𝑆 𝑦𝑆
𝑦𝑇 0 𝑐"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.05257510729613734,ℓ𝒟𝑆(𝑓𝑐
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.0536480686695279,"𝒟𝑆)
ℓ𝒟𝑇(𝑓𝑐 𝒟𝑆)"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.05472103004291846,Source Training Function Class Size 𝑐
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.055793991416309016,Source Loss = ℓ𝒟𝑆(𝑓𝑐 𝒟𝑆)
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.05686695278969957,Transferred Loss = ℓ𝒟𝑇(𝑓𝑐
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.05793991416309013,"𝒟𝑆)
Relative Domain 
Transferability Loss = 
ℓ𝒟𝑇(𝑓𝑐"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.059012875536480686,𝒟𝑆) −ℓ𝒟𝑆(𝑓𝑐
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.060085836909871244,"𝒟𝑆)
Different 𝑐"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.0611587982832618,"Figure 2: The left ﬁgure illustrates the example in the function space F given a regularization parameter c.
The right ﬁgure shows the relations between domain transferability and the c. In this example, the weaker the
regularization effect (greater c) is, the greater the relative domain transferability loss (violet arrow becomes)."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.06223175965665236,"Proposition 3.1. Given the problem deﬁned above, f DS
c
is a minimizer of equation 1. If c ≥c′ ≥0,
then the relative domain transferability loss ℓDT (f DS
c
) −ℓDS(f DS
c
) ≥ℓDT (f DS
c′ ) −ℓDS(f DS
c′ )."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.06330472103004292,"We can see that robustness is not sufﬁcient to characterize domain transferability. However, there is
a monotone relation between the regularization strength and the relative transferability loss, where
adversarial robustness could be arbitrary. Similar behavior is also observed in our experiments, as
we will discuss in Section 4. Naturally, these ﬁndings motivate the study of the connections between
the regularization of the training process and domain transferability in general, as we consider next."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.06437768240343347,"3.2
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY"
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.06545064377682404,"In this subsection, we consider the general transferability problem with ﬁne-tuning. We prove that
there is a monotone relationship between the regularization strength and relative domain transfer-
ability loss. We also present a tight upper bound on the relative domain transferability loss. Denote
the training algorithm as A that takes a data distribution D and outputs a feature extractor f D
A ∈FA
chosen from a function class FA and a ﬁne-tuning function gD
A ∈G. Next we formally deﬁne
relative domain transferability.
Deﬁnition 1 (Relative Domain Transferability Loss). Given the training algorithm A and a pair of
distributions DS, DT ∈PX×Y, the relative domain transferability loss between DS, DT is deﬁned
to be the difference of ﬁne-tuned losses, i.e.,"
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.06652360515021459,"τ(A; DS, DT ) := inf
g∈G ℓDT (g ◦f DS
A ) −ℓDS(gDS
A
◦f DS
A )."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.06759656652360516,"Note that the training algorithm A is not required to be optimal, i.e., it could be the case that
ℓDS(gDS
A
◦f DS
A ) > infg∈G,f∈FA ℓDS(g ◦f). As we can see, the smaller τ(A; DS, DT ) is, the
better the model’s relative performance becomes on the target domain."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.06866952789699571,"Another perspective of Deﬁnition 1 is that infg∈G ℓDT (g◦f DS
A ) = ℓDS(gDS
A ◦f DS
A )+τ(A; DS, DT ).
From this perspective, the transferred loss is the source loss plus an additional term to be upper
bounded by a certain distance metric between the source and target distributions – as is common
in the literature of domain adaptation (e.g., Ben-David et al. (2007); Zhao et al. (2019)). The key
question of the “distance metric” remains unanswered. To this end, we propose the following."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.06974248927038626,Under review as a conference paper at ICLR 2022
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.07081545064377683,"Deﬁnition 2 ((G, F)-pseudometric). Given a ﬁne-tuning function class G, a feature extractor func-
tion class F and distributions DS, DT ∈PX×Y, the (G, F)-pseudometric between DS, DT is
dG,F(DS, DT ) := sup
f∈F
| inf
g∈G ℓDS(g ◦f) −inf
g∈G ℓDT (g ◦f)|."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.07188841201716738,"Since the ﬁne-tuning function class is usually simple and ﬁxed, we will use dF as an abbreviation in
the context where G is clear."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.07296137339055794,"It can be easily veriﬁed that dG,F is a pseudometric that measures the distance between two distri-
butions, as shown in the following proposition.
Proposition 3.2. dG,F(·, ·) : PX×Y × PX×Y →R+ satisﬁes the following properties; (Symme-
try) dG,F(DS, DT ) = dG,F(DT , DS); (Triangle Inequality) ∀D′ ∈PX×Y : dG,F(DS, DT ) ≤
dG,F(DS, D′) + dG,F(D′, DT ); (Weak Zero Property) ∀D ∈PX×Y : dG,F(D, D) = 0."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.0740343347639485,"In this section, we consider a ﬁxed ﬁne-tuning function class G and feature extractor function class
FA given by the training algorithm A. Thus, we denote dG,F as dFA for the remainder of the paper.
With the deﬁnition of dFA, we can derive the following result.
Theorem 3.1. Given a training algorithm A, for ∀DS, DT ∈PX×Y we have
τ(A; DS, DT ) ≤dFA(DS, DT ),"
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.07510729613733906,"or equivalently,
inf
g∈G ℓDT (g ◦f DS
A ) ≤ℓDS(gDS
A
◦f DS
A ) + dFA(DS, DT )."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.07618025751072961,"Interpretation: As we can see, the above theorem provides sufﬁcient conditions for good domain
transferability. There is a monotone relation between the regularization strength and dFA(DS, DT ),
i.e., the upper bound on the relative domain transferability loss τ(A; DS, DT ). More explicitly, if
a training algorithm A′ has FA′ ⊆FA, then dFA′(DS, DT ) ≤dFA(DS, DT ). Moreover, small
dFA(DS, DT ) implies good relative domain transferability. From this perspective, we can see that
we need both small dFA(DS, DT ) and small source loss ℓDS(gDS
A
◦f DS
A ) to guarantee good ab-
solute domain transferability. Note that there is a possible trade-off, i.e., with FA being smaller,
dFA(DS, DT ) decreases but possibly ℓDS(gDS
A
◦f DS
A ) increases due to the limited power of FA.
On the other hand, there may not be such trade-off if DS and DT are close enough such that
dFA(DS, DT ) is small."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.07725321888412018,"To make the upper bound more meaningful, we need to study the tightness of it.
Theorem 3.2. Given any source distribution DS ∈PX×Rd, any ﬁne-tuning function class G where
G includes the zero function, and any training algorithm A, denote"
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.07832618025751073,"ϵ := ℓDS(gDS
A
◦f DS
A ) −
inf
g∈G,f∈FA ℓDS(g ◦f)."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.07939914163090128,"We assume some properties of the loss function ℓ: Rd × Rd →R+: it is differentiable and strictly
convex w.r.t. its ﬁrst argument; ℓ(y, y) = 0 for any y ∈Rd; and limr→∞infy:∥y∥2=r ℓ(⃗0, y) = ∞,
where ⃗0 is the zero vector. Then, for any distribution DX on X, there exist some distributions
DT ∈PX×Rd with its marginal on X being DX such that
τ(A; DS, DT ) ≤dFA(DS, DT ) ≤τ(A; DS, DT ) + ϵ,
or equivalently dFA(DS, DT ) −ϵ ≤τ(A; DS, DT ) ≤dFA(DS, DT )."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.08047210300429185,"Interpretation: In the above theorem, we show that given any A, DS, and the marginal DX , there
exists some conditional distributions of y|x such that by composing it with the given DX we have
a distribution DT to make the bound in Theorem 3.1 ϵ-tight. Note that ϵ is the difference between
the source loss and the its inﬁmum, i.e., with a good enough algorithm A, the ϵ could be arbitrarily
small."
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.0815450643776824,"3.3
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY"
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.08261802575107297,"Here we investigate the proposed theory on relative transferability with ﬁnite samples. For a distri-
bution D ∈PX×Y, we denote its empirical distribution with n samples as bDn. That being said,"
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.08369098712446352,"ℓb
Dn(g ◦f) = E(x,y)∼b
Dn[ℓ(g ◦f(x), y)] = 1 n n
X"
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.08476394849785408,"i=1
ℓ(g ◦f(xi), yi),"
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.08583690987124463,Under review as a conference paper at ICLR 2022
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.08690987124463519,"where (xi, yi) are i.i.d. samples from D. Therefore, given two distributions DS, DT ∈PX×Y, the
empirical (G, F)-pseudometric between them is dG,F( bDn
S, bDn
T )."
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.08798283261802575,"Note that dG,F is not only a pseudometric of distributions, but also a complexity measure, and we
will ﬁrst connect it with the Rademacher complexity.
Deﬁnition 3 (Empirical Rademacher Complexity (Bartlett & Mendelson, 2002; Koltchinskii,
2001)). Denote the loss function class induced by G, F as"
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.0890557939914163,"LG,F := {hg,f : X × Y →R+ | g ∈G, f ∈F},
where hg,f(x, y) := ℓ(g ◦f(x), y)."
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.09012875536480687,"Given an empirical distribution bDn (i.e., n data samples), the Rademacher complexity of it is"
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.09120171673819742,"Rad b
Dn(LG,F) := 1 nEξ """
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.09227467811158799,"sup
h∈LG,F n
X"
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.09334763948497854,"i=1
ξih(xi, yi) # ,"
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.0944206008583691,"where ξ ∈Rn are Rademacher variables, i.e., each ξi is i.i.d. uniformly distributed on {−1, 1}."
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.09549356223175966,"We can see that if there is a F′ ⊆F, then Rad b
Dn(LG,F′) ≤Rad b
Dn(LG,F). With the above deﬁni-
tions, we have the following lemma connecting the (G, F)-pseudometric to Rademacher complexity.
Lemma 3.1. Assuming the individual loss function ℓ: Y × Y →[0, c], given any distribution
D ∈PX×Y and ∀δ > 0, with probability ≥1 −δ we have"
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.09656652360515021,"dG,F(D, bDn) ≤2Rad b
Dn(LG,F) + 3c r"
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.09763948497854077,ln(4/δ)
N,0.09871244635193133,"2n
."
N,0.09978540772532189,"Therefore, denoting again dFA as dG,FA, the empirical version of Theorem 3.1 is as follows.
Theorem 3.3. Assuming the individual loss function ℓ: Y × Y →[0, c], given ∀DS, DT ∈PX×Y,
for ∀δ > 0 with probability ≥1 −δ we have"
N,0.10085836909871244,"τ(A; bDn
S, DT ) ≤dFA( bDn
S, bDn
T ) + 2Rad b
Dn
T (LG,FA) + 4Rad b
Dn
S(LG,FA) + 9c r"
N,0.10193133047210301,ln(8/δ)
N,0.10300429184549356,"2n
."
N,0.10407725321888411,"We can see that a smaller feature extractor function class FA implies both a smaller dFA and the
Rademacher complexity. Therefore, the monotone relation between the regularization strength and
the upper bound on the relative domain transferability loss also holds for the empirical settings."
N,0.10515021459227468,"Other than direct regularization, empirically we ﬁnd that the transferability is also related to the use
of data augmentation. Can we explain such phenomena from the view of regularization again? We
discuss this question next."
N,0.10622317596566523,"3.4
WHEN CAN DATA AUGMENTATION BE VIEWED AS REGULARIZATION?"
N,0.1072961373390558,"In this subsection, we discuss the connections between data augmentation (DA) and regularization.
We present the results and their interpretation in this subsection, while deferring the detailed discus-
sion to the Section B in the appendix."
N,0.10836909871244635,"Empirical research has shown evidence of the regularization effect of DA (Hern´andez-Garc´ıa &
K¨onig, 2018a;b). However, there is a lack of theoretical understanding on when can data augmen-
tation be viewed as regularization in general. In an attempt to address this question, we consider a
general DA setting of afﬁne transformation (Perez & Wang, 2017) with parameters (W⋆, b⋆) whose
distribution represents speciﬁc DA."
N,0.10944206008583691,"General Settings. We consider the ﬁne-tuning function g : Rd →R as a linear layer, which will
be concatenated to the feature extractor f : Rm →Rd. Given a model g ◦f, we use the squared
loss ℓ(g ◦f(x), y) = (g ◦f(x) −y)2, and accordingly apply second-order Taylor expansion to the
objective function to study the effect of data augmentation."
N,0.11051502145922747,"DA categories. We discuss two categories of DA, feature-level DA and data-level DA. Feature-level
DA (Wong et al., 2016; DeVries & Taylor, 2017) requires the transformation to be performed in the
learned feature space: given a data sample x ∈Rm and a feature extractor f, the augmented feature
is W⋆f(x) + b⋆where W⋆∈Rd×d, b⋆∈Rd are sampled from a distribution. On the other hand,"
N,0.11158798283261803,Under review as a conference paper at ICLR 2022
N,0.11266094420600858,"data-level DA requires the transformation to be performed in the input space: given a data sample x,
the augmented sample is W⋆x + b⋆where W⋆∈Rm×m, b⋆∈Rm are sampled from a distribution."
N,0.11373390557939914,"Intuition on sufﬁcient conditions. For either the feature-level or the data-level DA, the intuitions
given by our analysis are similar. Our results (Theorem B.1&B.2) suggest that the following condi-
tions indicate the regularization effects of a data augmentation: 1) EW⋆[W⋆] = I; 2) Eb⋆[b⋆] = ⃗0;
3) W⋆and b⋆are independent, where I is the identity matrix and ⃗0 is the zero vector; 4) W⋆is not a
constant if it is the feature-level DA; 5) DA is of a small magnitude if it is the data-level DA."
N,0.1148068669527897,"Empirical veriﬁcation. Combining with Theorem 3.3, it suggests that DA satisfying the conditions
above may improve the relative domain transferability. In fact, it matches the empirical observa-
tions in Section 4. Concretely, 1) Gaussian noise satisﬁes the four conditions, and empirically the
Gaussian noise improves domain transferability while robustness decreases a bit (Figure 5); 2) Ro-
tation, which rotates input image with a predeﬁned ﬁxed angle with predeﬁned ﬁxed probability,
violates EW⋆[W⋆] = I, and empirically the rotation barely affects domain transferability (Figure 14
in Appendix D.3); 3) Translation, which moves the input image for a predeﬁned distance along a
pre-selected axis with ﬁxed probability, violates Eb⋆[b⋆] = ⃗0, and empirically the translation dis-
tance barely co-relates to the domain transferability (Figure 14 in Appendix D.3)."
EVALUATION,0.11587982832618025,"4
EVALUATION"
EXPERIMENTAL SETTING,0.11695278969957082,"4.1
EXPERIMENTAL SETTING"
EXPERIMENTAL SETTING,0.11802575107296137,"Source model training
We train our model on two source domains: CIFAR-10 and ImageNet.
Unless speciﬁed, we will use the training setting as follows1. For CIFAR-10, we train the model
with 200 epochs using the momentum SGD optimizer with momentum 0.9, weight decay 0.0005,
an initial learning rate 0.1 which decays by a factor of 10 at the 100-th and 150-th epoch. For
ImageNet, we train the model with 90 epochs using the momentum SGD optimizer with momentum
0.9, weight decay 0.0001, an initial learning rate 0.1 which decays by a factor of 10 at the 30-th and
60-th epoch. We use the standard cross entropy loss denote as LCE(hs, x, y), where hs = gs ◦f
is the trained model and x, y are the input and label respectively. To evaluate the robustness on the
source domain, we follow the evaluation setting in Ilyas et al. (2019) and perform the PGD attack
with 20 steps using ϵ = 0.25. We also evaluate the robustness using AutoAttack in Appendix D.4.
For both tasks we use ResNet-18 as the model structure. We provide results of other model structures
in appendix D.2."
EXPERIMENTAL SETTING,0.11909871244635194,"Domain Transferability
We evaluate the transferability from CIFAR-10 to SVHN and from Im-
ageNet to CIFAR-10. For the ImageNet transferability, we focus on CIFAR as the target domain,
since it is the domain that is the most positively correlated with robustness as shown in Salman et al.
(2020). We evaluate the ﬁxed-feature transfer where only the last fully-connected layer is ﬁne-tuned
following our theoretical framework. We ﬁne-tune the last layer with 40 epochs using momentum
SGD optimizer with momentum 0.9, weight decay 0.0005, an initial learning rate 0.01 which de-
cays by a factor of 10 at the 20-th and 30-th epoch. To mitigate the impact of benign accuracy,
we evaluate the relative domain transfer accuracy (DT Acc) as follows. Let accsrc and acctgt be
the accuracy of the a ﬁne-tuned model on source and target domain, and accv
src and accv
tgt be the
accuracy of vanilla model (i.e., models trained with standard setting) on source and target domain,
then the relative DT accuracy is deﬁned as:"
EXPERIMENTAL SETTING,0.12017167381974249,"DT Acc = (acctgt −accsrc) −(accv
tgt −accv
src)"
EXPERIMENTAL SETTING,0.12124463519313304,We also provide the results of absolute DT accuracy in Appendix D.1.
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1223175965665236,"4.2
RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.12339055793991416,"We train the model under different controllable conditions to validate our analysis. In particular,
we train the methods by controlling different regularization or data augmentations to evaluate the
change of model robustness and transferability."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.12446351931330472,"1These settings are inherited from the standard training algorithms for CIFAR-10 (https://github.
com/kuangliu/pytorch-cifar) and ImageNet (https://github.com/pytorch/examples/
tree/master/imagenet)."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1255364806866953,Under review as a conference paper at ICLR 2022
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.12660944206008584,"10
20
30
Robust Acc (%) 10 5 0 5"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1276824034334764,Relative DT Acc (%)
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.12875536480686695,R: -0.782
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1298283261802575,CIFAR10 -> SVHN
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.13090128755364808,"LLR(
l)
-0.1
0
0.1
1.0"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.13197424892703863,"18
20
22
24
Robust Acc (%) 3 0 3"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.13304721030042918,R: -0.918
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.13412017167381973,ImageNet -> CIFAR10
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1351931330472103,"LLR(
l)
-0.01
0
0.01
0.1"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.13626609442060086,"10
20
30
Robust Acc (%) 10 5 0"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.13733905579399142,R: -0.916
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.13841201716738197,CIFAR10 -> SVHN
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.13948497854077252,LLOT(||gs||2)
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1405579399141631,"0.01
0.1
1.0
10.0"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.14163090128755365,"20
30
40
Robust Acc (%) 2 0 2"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1427038626609442,R: -0.954
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.14377682403433475,ImageNet -> CIFAR10
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.14484978540772533,LLOT(||gs||2)
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1459227467811159,"0.5
1
2
5"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.14699570815450644,"Figure 3: Relationship between robustness and transferability under different norms of last layer,
via training with last-layer regularization (LLR) and last-layer orthogonalization (LLOT)."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.148068669527897,"Controlling the norm of last layer
As shown in our framework, domain transferability is related
with the regularization on the feature extractor. Here we regularize the transferability by controlling
the norm of last linear layer gs. Intuitively, when we force the norm of gs to be large during training,
the corresponding norm of f will be regularized to be small. We use two approaches to control the
last layer norm:"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.14914163090128754,"• Last-layer regularization (LLR): we impose a strong l2-regularizer with parameter λl speciﬁcally
on the weight of gs and therefore our training loss becomes: LLLR(hs, x, y) = LCE(hs, x, y) +
λl · ||gs||F , where ||gs||F is the frobenius norm of the weight matrix of gs.
• Last-layer orthogonal training (LLOT): we directly control the l2-norm of gs with orthogonal
training (Huang et al. (2020)). The orthogonal training will enforce the weight to become a 1-
norm matrix and we multiply a constant to obtain the desired norm ||gs||2."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.15021459227467812,"The result of LLR and LLOT are shown in Figure 3. We observe that when we regularize the norm
of last layer to be large (i.e. smaller λ in LLR and larger ||gs||2 in LLOT), the domain transferability
will increase while the model robustness will decrease (their negative correlation is signiﬁcant with
Pearson’s coefﬁcient around −0.9). This is because larger last layer norm will produce a feature
extractor f with smaller norm, which, according to our analysis, leads to a better domain transfer-
ability. On the other hand, the model gs ◦f will have a larger norm and therefore becomes less
robust under adversarial attacks."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.15128755364806867,"Controlling the norm of feature extractor
We directly regularize the feature extractor f and
check the impact on domain transferability. We implement two regularization as follows:"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.15236051502145923,"• Jacobian regularization (JR): we follow the approach in Hoffman et al. (2019) to apply JR on
the feature extractor. Given model hs = gs ◦f, the training loss becomes: LJR(hs, x, y) =
LCE(hs, x, y) + λj · ||J(f, x)||2
F , where J(f, x) denotes the Jacobian matrix of f on x and || · ||F
is the frobenius norm.
• Weight Decay (WD): we impose a strong weight decay with factor λw on the feature extractor
f during training. This is equivalent to imposing a strong l2-regularizer with factor λw on the
feature extractor (excluding the last layer)."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.15343347639484978,"The results under JR and WD are shown in Figure 4. We observe that with larger regularization on
the feature extractor, the model shows higher domain transferability, which matches our analysis.
Meanwhile, the robustness decreases signiﬁcantly with large regularizer. This is because a large
regularization will harm the model performance on source domain and lead to low model robustness."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.15450643776824036,"20
30
40
50
60
70
Robust Acc (%) 0 5 10 15"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1555793991416309,Relative DT Acc (%)
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.15665236051502146,R: 0.313
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.157725321888412,CIFAR10 -> SVHN
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.15879828326180256,"JR(
j)
0
100
1000"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.15987124463519314,"15
25
35
45
55
Robust Acc (%) 0 10 20 30 40"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1609442060085837,R: 0.105
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.16201716738197425,ImageNet -> CIFAR10
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1630901287553648,"JR(
j)
0
0.01
0.1
1.0"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.16416309012875535,"10
20
Robust Acc (%) 0 20 40"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.16523605150214593,R: -0.734
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.16630901287553648,CIFAR10 -> SVHN
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.16738197424892703,"WD(
w)
0.0005
0.001
0.005
0.01"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1684549356223176,"10
15
20
Robust Acc (%) 0 5 10 15"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.16952789699570817,R: -0.984
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.17060085836909872,ImageNet -> CIFAR10
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.17167381974248927,"WD(
w)
0.0001
0.0005
0.001"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.17274678111587982,"Figure 4: Relationship between robustness and transferability when we regularize the feature ex-
tractor with Jacobian Regularization (JR) and weight decay (WD)."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.17381974248927037,Under review as a conference paper at ICLR 2022
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.17489270386266095,"20
30
40
50
60
70
Robust Acc (%) 0 10 20 30 40"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1759656652360515,Relative DT Acc (%)
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.17703862660944206,R: 0.168
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1781115879828326,CIFAR10 -> SVHN
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1791845493562232,Gauss( )
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.18025751072961374,"0
0.05
0.25
1.0"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1813304721030043,"20
30
Robust Acc (%) 0 20 40 60"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.18240343347639484,R: -0.384
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1834763948497854,ImageNet -> CIFAR10
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.18454935622317598,Gauss( )
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.18562231759656653,"0
0.05
0.25"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.18669527896995708,"20
30
40
50
Robust Acc (%) 0 5 10"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.18776824034334763,R: 0.566
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1888412017167382,CIFAR10 -> SVHN
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.18991416309012876,"Pos(b) 1
4
8"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.19098712446351931,"20
25
30
Robust Acc (%) 0 2 4"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.19206008583690987,R: 0.880
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.19313304721030042,ImageNet -> CIFAR10
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.194206008583691,"Pos(b) 1
4
8"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.19527896995708155,"Figure 5: Relationship between robustness and transferability when we use Gaussian noise (Gauss)
and posterize (Pos) as data augmentations."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1963519313304721,"0
10
20
Robust Acc (%) 0 20 40 60 80"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.19742489270386265,Relative DT Acc (%)
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1984978540772532,R: -0.917
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.19957081545064378,ResNet18
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.20064377682403434,Rescale(m)
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.2017167381974249,"1
2
4
8"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.20278969957081544,"15
20
Robust Acc (%) 0 5 10 15"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.20386266094420602,R: -0.842
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.20493562231759657,ResNet18
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.20600858369098712,Blur(k)
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.20708154506437768,"1
5
11"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.20815450643776823,"0
10
20
Robust Acc (%) 0 20 40 60 80"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.2092274678111588,R: -0.931
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.21030042918454936,WideResNet-50
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.2113733905579399,Rescale(m)
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.21244635193133046,"1
2
4
8"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.21351931330472104,"22
24
Robust Acc (%) 0 5 10"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.2145922746781116,R: -0.852
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.21566523605150215,WideResNet-50
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.2167381974248927,Blur(k)
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.21781115879828325,"1
5
11"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.21888412017167383,"Figure 6: Relationship between robustness and transferability on ImageNet when we use rescale and
blur as data augmentations."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.21995708154506438,"Data augmentation
As shown in Section 3.4, data augmentation can be viewed as a type of reg-
ularization during training and thus affects the domain transferability. Here we consider both noise
dependent and independent data augmentations."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.22103004291845493,Noise-dependent data augmentation We include two noise-dependent augmentations:
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.22210300429184548,"• Gaussian Noise data augmentation (Gauss): we add zero-mean Gaussian noise with variance σ2
to the input image.
• Posterize (Pos): we truncate each channel of one pixel value into b bits (originally they are 8 bits)."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.22317596566523606,"The results of Gauss and Pos are shown in Figure 5. We observe that the domain transferability
of trained model keeps improving with larger data augmentation, which matches our theory. The
robustness also beneﬁts from a small data augmentation, but decreases when it becomes large."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.22424892703862662,"Resolution-related (noise-independent) data augmentation.
Speciﬁcally, for ImageNet to
CIFAR-10 transferability, we consider two resolution-related data augmentations. The intuition is
that when the target domain has a lower resolution than the source domain (ImageNet is 224 × 224
while CIFAR-10 is 32×32), the data augmentations that down-sample the inputs during the training
on source domain will help transferability. We consider the below resolution-related augmentations:"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.22532188841201717,"• Rescale: we rescale the input to be m times smaller (i.e., shape ImageNet as (224/m)×(224/m))
and then rescale them back to the original size."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.22639484978540772,"• Blur: we apply Gaussian blurring with kernel size k on the input. The Gaussian kernel is created
with a standard deviation randomly sampled from [0.1, 2.0]."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.22746781115879827,"We show the results of rescaling and blurring in Figure 6. The experiments are evaluated only
for ImageNet to CIFAR-10, and we include the results of both ResNet18 (the default model) and
WideResNet50. We can see that these data augmentations help with transferability to target domain,
although the robustness on the source domain decreases since these augmentations do not include
any robustness-related operations."
CONCLUSIONS,0.22854077253218885,"5
CONCLUSIONS"
CONCLUSIONS,0.2296137339055794,"In this work, we theoretically analyze the sufﬁcient conditions for domain transferability based on
the view of function class regularization. We also conduct experiments to verify our claims and
observe some counterexamples that shows a negative correlation between robustness and domain
transferability. These results are helpful in the domain generalization of machine learning models."
CONCLUSIONS,0.23068669527896996,Under review as a conference paper at ICLR 2022
ETHICS STATEMENT,0.2317596566523605,ETHICS STATEMENT
ETHICS STATEMENT,0.23283261802575106,"Our work focuses on theoretically and empirically studying the domain transferability of a machine
learning model. All the datasets and packages we use are open-sourced. We do not have ethical
concerns in our paper."
REPRODUCIBILITY STATEMENT,0.23390557939914164,REPRODUCIBILITY STATEMENT
REPRODUCIBILITY STATEMENT,0.2349785407725322,"We have tried our best to provide training details to facilitate reproducing our results. In Section 4.1
we provide detailed results on how to train the model and how to transfer the trained model to target
domain, as well as how we evaluate our model. We also upload the zip ﬁle of our code with the
submission. We will open-source our code once accepted."
REFERENCES,0.23605150214592274,REFERENCES
REFERENCES,0.2371244635193133,"Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and
structural results. Journal of Machine Learning Research, 3(Nov):463–482, 2002."
REFERENCES,0.23819742489270387,"Shai Ben-David, John Blitzer, Koby Crammer, Fernando Pereira, et al. Analysis of representations
for domain adaptation. Advances in neural information processing systems, 19:137, 2007."
REFERENCES,0.23927038626609443,"Nicholas Carlini and David Wagner. Towards evaluating the robustness of neural networks. In 2017
ieee symposium on security and privacy (sp), pp. 39–57. IEEE, 2017."
REFERENCES,0.24034334763948498,"Jianbo Chen, Michael I Jordan, and Martin J Wainwright. Hopskipjumpattack: A query-efﬁcient
decision-based attack. In 2020 ieee symposium on security and privacy (sp), pp. 1277–1294.
IEEE, 2020."
REFERENCES,0.24141630901287553,"Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. Certiﬁed adversarial robustness via randomized
smoothing. In International Conference on Machine Learning, pp. 1310–1320. PMLR, 2019."
REFERENCES,0.24248927038626608,"Nicolas Courty, R´emi Flamary, Devis Tuia, and Alain Rakotomamonjy. Optimal transport for do-
main adaptation. IEEE transactions on pattern analysis and machine intelligence, 39(9):1853–
1865, 2016."
REFERENCES,0.24356223175965666,"Terrance DeVries and Graham W Taylor. Dataset augmentation in feature space. arXiv preprint
arXiv:1702.05538, 2017."
REFERENCES,0.2446351931330472,"Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Brandon Tran, and Alek-
sander Madry.
Adversarial robustness as a prior for learned representations.
arXiv preprint
arXiv:1906.00945, 2019."
REFERENCES,0.24570815450643776,"Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. arXiv preprint arXiv:1412.6572, 2014."
REFERENCES,0.24678111587982832,"Alex Hern´andez-Garc´ıa and Peter K¨onig. Data augmentation instead of explicit regularization. arXiv
preprint arXiv:1806.03852, 2018a."
REFERENCES,0.2478540772532189,"Alex Hern´andez-Garc´ıa and Peter K¨onig. Further advantages of data augmentation on convolutional
neural networks. In International Conference on Artiﬁcial Neural Networks, pp. 95–103. Springer,
2018b."
REFERENCES,0.24892703862660945,"Judy Hoffman, Daniel A Roberts, and Sho Yaida. Robust learning with jacobian regularization.
arXiv preprint arXiv:1908.02729, 2019."
REFERENCES,0.25,"Haoshuo Huang, Qixing Huang, and Philipp Krahenbuhl. Domain transfer through deep activation
matching. In Proceedings of the European Conference on Computer Vision (ECCV), pp. 590–605,
2018."
REFERENCES,0.2510729613733906,"Lei Huang, Li Liu, Fan Zhu, Diwen Wan, Zehuan Yuan, Bo Li, and Ling Shao. Controllable orthog-
onalization in training dnns. In Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition, pp. 6429–6438, 2020."
REFERENCES,0.2521459227467811,Under review as a conference paper at ICLR 2022
REFERENCES,0.2532188841201717,"Andrew Ilyas, Shibani Santurkar, Logan Engstrom, Brandon Tran, and Aleksander Madry. Ad-
versarial examples are not bugs, they are features. Advances in neural information processing
systems, 32, 2019."
REFERENCES,0.2542918454935622,"Vladimir Koltchinskii. Rademacher penalties and structural risk minimization. IEEE Transactions
on Information Theory, 47(5):1902–1914, 2001."
REFERENCES,0.2553648068669528,"Clare Lyle, Marta Kwiatkowksa, and Yarin Gal. An analysis of the effect of invariance on gen-
eralization in neural networks. In International conference on machine learning Workshop on
Understanding and Improving Generalization in Deep Learning, volume 1, 2019."
REFERENCES,0.25643776824034337,"Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. In International Conference on
Learning Representations, 2018."
REFERENCES,0.2575107296137339,"Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial training: a
regularization method for supervised and semi-supervised learning. IEEE transactions on pattern
analysis and machine intelligence, 41(8):1979–1993, 2018."
REFERENCES,0.25858369098712447,"Krikamol Muandet, David Balduzzi, and Bernhard Sch¨olkopf. Domain generalization via invariant
feature representation. In International Conference on Machine Learning, pp. 10–18. PMLR,
2013."
REFERENCES,0.259656652360515,"Luis Perez and Jason Wang. The effectiveness of data augmentation in image classiﬁcation using
deep learning. arXiv preprint arXiv:1712.04621, 2017."
REFERENCES,0.2607296137339056,"Elan Rosenfeld, Pradeep Ravikumar, and Andrej Risteski. An online learning approach to interpo-
lation and extrapolation in domain generalization. arXiv preprint arXiv:2102.13128, 2021."
REFERENCES,0.26180257510729615,"Kevin Roth, Yannic Kilcher, and Thomas Hofmann. Adversarial training is a form of data-dependent
operator norm regularization. arXiv preprint arXiv:1906.01527, 2020."
REFERENCES,0.2628755364806867,"Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, and Aleksander Madry. Do adver-
sarially robust imagenet models transfer better? arXiv preprint arXiv:2007.08489, 2020."
REFERENCES,0.26394849785407726,"Chun-Chen Tu, Paishun Ting, Pin-Yu Chen, Sijia Liu, Huan Zhang, Jinfeng Yi, Cho-Jui Hsieh, and
Shin-Ming Cheng. Autozoom: Autoencoder-based zeroth order optimization method for attack-
ing black-box neural networks. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence,
volume 33, pp. 742–749, 2019."
REFERENCES,0.26502145922746784,"Sebastien C Wong, Adam Gatt, Victor Stamatescu, and Mark D McDonnell. Understanding data
augmentation for classiﬁcation: when to warp? In 2016 international conference on digital image
computing: techniques and applications (DICTA), pp. 1–6. IEEE, 2016."
REFERENCES,0.26609442060085836,"Kaichao You, Ximei Wang, Mingsheng Long, and Michael Jordan. Towards accurate model selec-
tion in deep unsupervised domain adaptation. In International Conference on Machine Learning,
pp. 7124–7133. PMLR, 2019."
REFERENCES,0.26716738197424894,"Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El Ghaoui, and Michael Jordan.
Theoretically principled trade-off between robustness and accuracy. In International Conference
on Machine Learning, pp. 7472–7482. PMLR, 2019a."
REFERENCES,0.26824034334763946,"Linjun Zhang, Zhun Deng, Kenji Kawaguchi, Amirata Ghorbani, and James Zou. How does mixup
help with robustness and generalization? arXiv preprint arXiv:2010.04819, 2020."
REFERENCES,0.26931330472103004,"Yuchen Zhang, Tianle Liu, Mingsheng Long, and Michael Jordan. Bridging theory and algorithm for
domain adaptation. In International Conference on Machine Learning, pp. 7404–7413. PMLR,
2019b."
REFERENCES,0.2703862660944206,"Han Zhao, Remi Tachet Des Combes, Kun Zhang, and Geoffrey Gordon. On learning invariant
representations for domain adaptation. In International Conference on Machine Learning, pp.
7523–7532. PMLR, 2019."
REFERENCES,0.27145922746781115,Under review as a conference paper at ICLR 2022
REFERENCES,0.27253218884120173,Appendix
REFERENCES,0.27360515021459225,"A
PROOFS"
REFERENCES,0.27467811158798283,"Proposition A.1 (Proposition 3.1 Restated). Given the problem deﬁned in subsection 3.1, f DS
c
is a
minimizer of equation 1. Moreover, if c ≥c′ ≥0, then the relative domain transfer loss ℓDT (f DS
c
)−
ℓDS(f DS
c
) ≥ℓDT (f DS
c′ ) −ℓDS(f DS
c′ )."
REFERENCES,0.2757510729613734,"Proof. Recall that ℓDS(f) = ∥f −yS∥D, ℓDT (f) = ∥f −yT ∥D and f DS
c
:= yS min{1,
c
∥yS∥D }.
First, let’s verify that"
REFERENCES,0.27682403433476394,"f DS
c
∈arg min
f∈F
ℓDS(f),
s.t. ∥f∥D ≤c."
REFERENCES,0.2778969957081545,"If c ≥∥yS∥D, then f DS
c
:= yS achieves the minimum. If c < ∥yS∥D, then for any f ∈F : ∥f∥D ≤
c, we have"
REFERENCES,0.27896995708154504,ℓDS(f) = ∥f −yS∥D ≥∥yS∥D −∥f∥D ≥∥yS∥D −c
REFERENCES,0.2800429184549356,"= ∥(1 −
c
∥yS∥D )yS∥D = ∥yS −
c
∥yS∥D yS∥D = ℓDS(f DS
c
)."
REFERENCES,0.2811158798283262,"Therefore, f DS
c
indeed achieves the minimum."
REFERENCES,0.2821888412017167,"Now, let’s prove the proposition. For any c ≥∥yS∥D, we have ℓDS(f DS
c
) = 0 and ℓDT (f DS
c
)
is a constant. Therefore, there is no difference for all c ≥∥yS∥D, and the proposition holds for
c ≥c′ ≥∥yS∥D. Then, We only need to verify the case for ∥yS∥≥c ≥c′:"
REFERENCES,0.2832618025751073,"ℓDS(f DS
c′ ) −ℓDS(f DS
c
) = c −c′ = ∥
c
∥yS∥D yS −
c′
∥yS∥D yS∥D"
REFERENCES,0.2843347639484979,"= ∥f DS
c′
−f DS
c
∥D = ∥f DS
c′
−yT + yT −f DS
c
∥D"
REFERENCES,0.2854077253218884,"≥|∥f DS
c′
−yT ∥D −∥yT −f DS
c
∥D|"
REFERENCES,0.286480686695279,"≥∥f DS
c′
−yT ∥D −∥yT −f DS
c
∥D"
REFERENCES,0.2875536480686695,"= ℓDT (f DS
c′ ) −ℓDT (f DS
c
)."
REFERENCES,0.2886266094420601,Rearranging the above inequality gives the proposition.
REFERENCES,0.28969957081545067,"Proposition A.2 (Proposition 3.2 Restated). dG,F(·, ·) : PX×Y ×PX×Y →R+ satisﬁes the follow-
ing three properties."
REFERENCES,0.2907725321888412,"1. (Symmetry) dG,F(DS, DT ) = dG,F(DT , DS)."
REFERENCES,0.2918454935622318,"2. (Triangle Inequality) For ∀D′ ∈PX×Y: dG,F(DS, DT ) ≤dG,F(DS, D′)+dG,F(D′, DT )."
REFERENCES,0.2929184549356223,"3. (Weak Zero Property) For ∀D ∈PX×Y: dG,F(D, D) = 0."
REFERENCES,0.2939914163090129,Proof. Recall that
REFERENCES,0.29506437768240346,"dG,F(DS, DT ) := sup
f∈F
| inf
g∈G ℓDS(g ◦f) −inf
g∈G ℓDT (g ◦f)|."
REFERENCES,0.296137339055794,"We can see that the symmetry and weak zero property are obvious. For triangle inequality, given
∀D′ ∈PX×Y:"
REFERENCES,0.29721030042918456,"dG,F(DS, DT ) = sup
f∈F
| inf
g∈G ℓDS(g ◦f) −inf
g∈G ℓDT (g ◦f)|"
REFERENCES,0.2982832618025751,"= sup
f∈F
| inf
g∈G ℓDS(g ◦f) −inf
g∈G ℓD′(g ◦f) + inf
g∈G ℓD′(g ◦f) −inf
g∈G ℓDT (g ◦f)|"
REFERENCES,0.29935622317596566,"≤sup
f∈F
(| inf
g∈G ℓDS(g ◦f) −inf
g∈G ℓD′(g ◦f)| + | inf
g∈G ℓD′(g ◦f) −inf
g∈G ℓDT (g ◦f)|)"
REFERENCES,0.30042918454935624,"≤sup
f∈F
| inf
g∈G ℓDS(g ◦f) −inf
g∈G ℓD′(g ◦f)| + sup
f∈F
| inf
g∈G ℓD′(g ◦f) −inf
g∈G ℓDT (g ◦f)|"
REFERENCES,0.30150214592274677,"= dG,F(DS, D′) + dG,F(D′, DT )."
REFERENCES,0.30257510729613735,Under review as a conference paper at ICLR 2022
REFERENCES,0.30364806866952787,Proposition A.3. Denote the function class
REFERENCES,0.30472103004291845,"LG,F := {hg,f : X × Y →R+ | g ∈G, f ∈F},
where hg,f(x, y) := ℓ(g ◦f(x), y)."
REFERENCES,0.30579399141630903,"Let d : X × Y →R+ be a metric on X × Y, and assume ∀h ∈LG,F is L-Lipschitz continuous with
respect to the metric d. Then, we have"
REFERENCES,0.30686695278969955,"dFA(DS, DT ) ≤L · W(DS, DT ),"
REFERENCES,0.30793991416309013,"where W(DS, DT ) is the Wasserstein distance:"
REFERENCES,0.3090128755364807,"W(DS, DT ) =
sup
φ:X×Y→R
E(x,y)∼DS[φ(x, y)] −E(x,y)∼DT [φ(x, y)]
s.t. φ is 1-Lipschitz."
REFERENCES,0.31008583690987124,Proof. Recall that
REFERENCES,0.3111587982832618,"dG,F(DS, DT ) := sup
f∈F
| inf
g∈G ℓDS(g ◦f) −inf
g∈G ℓDT (g ◦f)|."
REFERENCES,0.31223175965665234,"By the deﬁnition of inf, for ∀ϵ > 0 there exist gS,ϵ, gT,ϵ ∈G such that"
REFERENCES,0.3133047210300429,"inf
g∈G ℓDS(g ◦fϵ) ≥ℓDS(gS,ϵ ◦fϵ) −ϵ"
REFERENCES,0.3143776824034335,"inf
g∈G ℓDT (g ◦fϵ) ≥ℓDT (gT,ϵ ◦fϵ) −ϵ."
REFERENCES,0.315450643776824,"By the deﬁnition of sup, there exists fϵ ∈F such that"
REFERENCES,0.3165236051502146,"dG,F(DS, DT ) ≤| inf
g∈G ℓDS(g ◦fϵ) −inf
g∈G ℓDT (g ◦fϵ)| + ϵ"
REFERENCES,0.31759656652360513,"= max{inf
g∈G ℓDS(g ◦fϵ) −inf
g∈G ℓDT (g ◦fϵ), inf
g∈G ℓDT (g ◦fϵ) −inf
g∈G ℓDS(g ◦fϵ)} + ϵ"
REFERENCES,0.3186695278969957,"≤max{ℓDS(gT,ϵ ◦fϵ) −inf
g∈G ℓDT (g ◦fϵ), ℓDT (gS,ϵ ◦fϵ) −inf
g∈G ℓDS(g ◦fϵ)} + ϵ"
REFERENCES,0.3197424892703863,"≤max{ℓDS(gT,ϵ ◦fϵ) −ℓDT (gT,ϵ ◦fϵ), ℓDT (gS,ϵ ◦fϵ) −ℓDS(gS,ϵ ◦fϵ)} + 2ϵ.
(2)"
REFERENCES,0.3208154506437768,"Let’s ﬁrst consider the ﬁrst term in the max{·, ·} above."
REFERENCES,0.3218884120171674,"ℓDS(gT,ϵ ◦fϵ) −ℓDT (gT,ϵ ◦fϵ)"
REFERENCES,0.3229613733905579,= L · ( 1
REFERENCES,0.3240343347639485,"LℓDS(gT,ϵ ◦fϵ) −1"
REFERENCES,0.3251072961373391,"LℓDT (gT,ϵ ◦fϵ))"
REFERENCES,0.3261802575107296,"= L · (E(x,y)∼DS[ 1"
REFERENCES,0.3272532188841202,"Lℓ(gT,ϵ ◦fϵ(x), y)] −E(x,y)∼DT [ 1"
REFERENCES,0.3283261802575107,"Lℓ(gT,ϵ ◦fϵ(x), y)])"
REFERENCES,0.3293991416309013,"≤L · W(DS, DT ),"
REFERENCES,0.33047210300429186,where the inequality is due to that both 1
REFERENCES,0.3315450643776824,"Lℓ(gS,ϵ ◦fϵ(x), y) and 1"
REFERENCES,0.33261802575107297,"Lℓ(gT,ϵ ◦fϵ(x), y) are 1-Lipschitz
w.r.t. (x, y) and the metric d."
REFERENCES,0.33369098712446355,"Similarly, we also have"
REFERENCES,0.33476394849785407,"ℓDT (gS,ϵ ◦fϵ) −ℓDS(gS,ϵ ◦fϵ) ≤L · W(DS, DT )."
REFERENCES,0.33583690987124465,"Therefore, equation 2 implies"
REFERENCES,0.3369098712446352,"dG,F(DS, DT ) ≤L · W(DS, DT ) + 2ϵ."
REFERENCES,0.33798283261802575,Letting ϵ →0 completes the proof.
REFERENCES,0.33905579399141633,"Proposition A.4. Consider multi-class classiﬁcation where Y = [k] for some k ≥2. Deﬁne the
loss function ℓas"
REFERENCES,0.34012875536480686,"ℓ(g ◦f(x), y) = 1{arg max
j∈[k](g ◦f(x))j ̸= y}"
REFERENCES,0.34120171673819744,"Let δT V (DS, DT ) denote the total variation distance. Then we have"
REFERENCES,0.34227467811158796,"dFA(DS, DT ) ≤δT V (DS, DT )"
REFERENCES,0.34334763948497854,Under review as a conference paper at ICLR 2022
REFERENCES,0.3444206008583691,"Proof. Fix f ∈F. By the deﬁnition of inf, there exists gT,ϵ such that"
REFERENCES,0.34549356223175964,"| inf
g∈G ℓDS(g ◦f) −inf
g∈G ℓDT (g ◦f)|"
REFERENCES,0.3465665236051502,"≤| inf
g∈G ℓDS(g ◦f) −ℓDT (gT,ϵ ◦f)| + ϵ"
REFERENCES,0.34763948497854075,"≤|ℓDS(gT,ϵ ◦f) −ℓDT (gT,ϵ ◦f)| + ϵ
= |E(x,y)∼DS[ℓ(gT,ϵ ◦f(x), y)] −E(x,y)∼DT [ℓ(gT,ϵ ◦f(x), y)]| + ϵ"
REFERENCES,0.3487124463519313,"= |P(x,y)∼DS[1{arg max
j∈[k](gT,ϵ ◦f(x))j ̸= y}] −P(x,y)∼DT [1{arg max
j∈[k](gT,ϵ ◦f(x))j ̸= y}]| + ϵ (3)"
REFERENCES,0.3497854077253219,"Let A be the event such that A = {(x, y) : arg maxj∈[k](gT,ϵ ◦f(x))j ̸= y}. Then we can write
equation 3 as"
REFERENCES,0.35085836909871243,"(3) = |P(x,y)∼DS[A] −P(x,y)∼DT [A]| + ϵ"
REFERENCES,0.351931330472103,"≤sup
B
|P(x,y)∼DS[B] −P(x,y)∼DT [B]| + ϵ"
REFERENCES,0.3530042918454936,"= δT V (DS, DT ) + ϵ"
REFERENCES,0.3540772532188841,"Send ϵ →0. Noting that f ∈F was arbitrary, apply sup to both sides gives us the desired inequality."
REFERENCES,0.3551502145922747,"Theorem 3.1 can be proved easily by deﬁnition.
Theorem A.1 (Theorem 3.1 Restated). Given a training algorithm A, for ∀DS, DT ∈PX×Y we
have"
REFERENCES,0.3562231759656652,"τ(A; DS, DT ) ≤dFA(DS, DT ),"
REFERENCES,0.3572961373390558,"or equivalently,
inf
g∈G ℓDT (g ◦f DS
A ) ≤ℓDS(gDS
A
◦f DS
A ) + dFA(DS, DT )."
REFERENCES,0.3583690987124464,"Proof. By deﬁnition,"
REFERENCES,0.3594420600858369,"τ(A; DS, DT ) = inf
g∈G ℓDT (g ◦f DS
A ) −ℓDS(gDS
A
◦f DS
A )"
REFERENCES,0.3605150214592275,"≤inf
g∈G ℓDT (g ◦f DS
A ) −inf
g∈G ℓDS(g ◦f DS
A )"
REFERENCES,0.361587982832618,"≤| inf
g∈G ℓDT (g ◦f DS
A ) −inf
g∈G ℓDS(g ◦f DS
A )|"
REFERENCES,0.3626609442060086,"≤sup
f∈FA
| inf
g∈G ℓDT (g ◦f) −inf
g∈G ℓDS(g ◦f)|"
REFERENCES,0.36373390557939916,"= dFA(DS, DT )."
REFERENCES,0.3648068669527897,"To prove Theorem 3.2, we ﬁrst prove the following interesting lemma.
Lemma A.1. Let Sd−1
r
:= {y ∈Rd | ∥y∥2 = r} denotes the (d−1)-dimensional sphere in Rd with
radius r > 0. If a function h : Sd−1
r
→Rd satisﬁes"
REFERENCES,0.36587982832618027,"∀y ∈Sd−1
r
:
⟨h(y), y⟩< 0,
(4)"
REFERENCES,0.3669527896995708,"then we have
⃗0 ∈conv(h(Sd−1
r
)),"
REFERENCES,0.36802575107296137,"i.e., ⃗0 is in the convex hull of {h(y) | y ∈Sd−1
r
}."
REFERENCES,0.36909871244635195,"Proof. We assume that ⃗0 /∈conv(h(Sd−1
r
)) and prove by contradiction. Since ⃗0 /∈conv(h(Sd−1
r
)),
we can ﬁnd a hyperplane that separates ⃗0 and the convex set conv(h(Sd−1
r
)). By the separating
hyperplane theorem there exists a nonzero vector v ∈Rd and c ≥0 such that"
REFERENCES,0.3701716738197425,"∀z ∈conv(h(Sd−1
r
)) :
⟨z, v⟩≥c ≥0.
(5)"
REFERENCES,0.37124463519313305,Under review as a conference paper at ICLR 2022
REFERENCES,0.3723175965665236,"We choose y = rv/∥v∥2 and observe that h(y) ∈conv(h(Sd−1
r
)). Hence, by equation 5 we have"
REFERENCES,0.37339055793991416,"⟨h(y), y⟩≥0,"
REFERENCES,0.37446351931330474,"which contradicts to the condition of equation 4. Therefore, it must be that ⃗0 ∈conv(h(Sd−1
r
))."
REFERENCES,0.37553648068669526,"Theorem A.2 (Theorem 3.2 Restated). Given any source distribution DS ∈PX×Rd, any ﬁne-tuning
function class G where G includes the zero function, and any training algorithm A, denote"
REFERENCES,0.37660944206008584,"ϵ := ℓDS(gDS
A
◦f DS
A ) −
inf
g∈G,f∈FA ℓDS(g ◦f)."
REFERENCES,0.3776824034334764,"We assume some properties of the sample individual loss function ℓ: Rd × Rd →R+: it is
differentiable and strictly convex w.r.t.
its ﬁrst argument; ℓ(y, y) = 0 for any y ∈Rd; and
limr→∞infy:∥y∥2=r ℓ(⃗0, y) = ∞. Then, for any distribution DX on X, there exist some distri-
butions DT ∈PX×Y with its marginal on X being DX such that"
REFERENCES,0.37875536480686695,"τ(A; DS, DT ) ≤dFA(DS, DT ) ≤τ(A; DS, DT ) + ϵ."
REFERENCES,0.3798283261802575,"Proof. The τ(A; DS, DT ) ≤dFA(DS, DT ) is proved by Theorem 3.1, we only need to prove that
there exists some DT ∈PX×Y with its marginal on X being DX such that"
REFERENCES,0.38090128755364805,"dFA(DS, DT ) ≤τ(A; DS, DT ) + ϵ = inf
g∈G ℓDT (g ◦f DS
A ) −
inf
g∈G,f∈FA ℓDS(g ◦f)."
REFERENCES,0.38197424892703863,"We begin by observing that limr→∞infy:∥y∥2=r ℓ(⃗0, y) = ∞, and thus there exists r > 0 such that"
REFERENCES,0.3830472103004292,"∀y ∈Sd−1
r
:
ℓ(⃗0, y) ≥ℓDS(⃗0) = E(x,y)∼DS[ℓ(⃗0, y)],
(6)"
REFERENCES,0.38412017167381973,"where Sd−1
r
:= {y ∈Rd | ∥y∥2 = r} denotes the (d −1)-dimensional sphere with radius r. Note
the we abuse the notion a bit to let ⃗0 also denotes the zero function (i.e., maps all input to zero).
Now, let us deﬁne at the following set"
REFERENCES,0.3851931330472103,"V := {∇1ℓ(⃗0, y) | y ∈Sd−1
r
},"
REFERENCES,0.38626609442060084,"where ∇1 is taking the gradient w.r.t. the ﬁrst argument of ℓ(·, ·). By the strict convexity of ℓ(·, y),
we have"
REFERENCES,0.3873390557939914,"ℓ(y, y) −ℓ(⃗0, y) > ⟨∇1ℓ(⃗0, y), y⟩."
REFERENCES,0.388412017167382,"Noting that ℓ(y, y) = 0 is the unique minimum of ℓ(·, y), we have ℓ(⃗0, y) > 0. Accordingly,"
REFERENCES,0.3894849785407725,"∀y ∈Sd−1
r
:
0 > −ℓ(⃗0, y) > ⟨∇1ℓ(⃗0, y), y⟩."
REFERENCES,0.3905579399141631,"Having the above property, and noting that ∇1ℓ(⃗0, ·) : Sd−1
r
→Rd, we can invoke Lemma A.1 to
see that"
REFERENCES,0.3916309012875536,⃗0 ∈conv(V).
REFERENCES,0.3927038626609442,"Therefore, there exists n points {yi}n
i=1 ⊂Sd−1
r
such that ⃗0 = n
X"
REFERENCES,0.3937768240343348,"i=1
ci∇1ℓ(⃗0, yi),
(7)"
REFERENCES,0.3948497854077253,"where ci > 0 and Pn
i=1 ci = 1."
REFERENCES,0.3959227467811159,"Therefore, we can deﬁne the target distribution DT as the following. Given any x ∼DX , the
distribution of y conditioned on x is: y = yi with probability ci. Now we verify the distribution DT
indeed makes the bound ϵ-tight. Denote a strictly convex function h : Rd →R+ as the following"
REFERENCES,0.3969957081545064,"h(·) := n
X"
REFERENCES,0.398068669527897,"i=1
ciℓ(·, yi)."
REFERENCES,0.39914163090128757,Under review as a conference paper at ICLR 2022
REFERENCES,0.4002145922746781,"Since h is strictly convex and ∇h(⃗0) = ⃗0 (equation 7), we can see that h(⃗0) achieves the unique
global minimum of h on Rd."
REFERENCES,0.4012875536480687,"Therefore, given the DT , for any ∀f ∈FA we have
inf
g∈G ℓDT (g ◦f) = inf
g∈G E(x,y)∼DT [ℓ(g ◦f(x), y)]"
REFERENCES,0.40236051502145925,"= inf
g∈G Ex∼DX "" n
X"
REFERENCES,0.4034334763948498,"i=1
ciℓ(g ◦f(x), yi) #"
REFERENCES,0.40450643776824036,"= inf
g∈G Ex∼DX [h(g ◦f(x))]"
REFERENCES,0.4055793991416309,"= h(⃗0)
(G contains the zero function) = n
X"
REFERENCES,0.40665236051502146,"i=1
ciℓ(⃗0, yi).
(8)"
REFERENCES,0.40772532188841204,"Recall that dFA(DS, DT ) = supf∈FA | infg∈G ℓDT (g ◦f) −infg∈G ℓDS(g ◦f)|, we can see that"
REFERENCES,0.40879828326180256,"dFA(DS, DT ) = sup
f∈FA
| n
X"
REFERENCES,0.40987124463519314,"i=1
ciℓ(⃗0, yi) −inf
g∈G ℓDS(g ◦f)|
(9)"
REFERENCES,0.41094420600858367,"By equation 6, for ∀f ∈FA, we have
n
X"
REFERENCES,0.41201716738197425,"i=1
ciℓ(⃗0, yi) ≥ℓDS(⃗0) = ℓDS(⃗0 ◦f) ≥inf
g∈G ℓDS(g ◦f)."
REFERENCES,0.4130901287553648,"Hence, we can continue as"
REFERENCES,0.41416309012875535,"(9) = sup
f∈FA n
X"
REFERENCES,0.41523605150214593,"i=1
ciℓ(⃗0, yi) −inf
g∈G ℓDS(g ◦f) ! = n
X"
REFERENCES,0.41630901287553645,"i=1
ciℓ(⃗0, yi) −
inf
g∈G,f∈FA ℓDS(g ◦f)"
REFERENCES,0.41738197424892703,"= inf
g∈G ℓDT (g ◦f DS
A ) −
inf
g∈G,f∈FA ℓDS(g ◦f)
(by equation 8)"
REFERENCES,0.4184549356223176,"= inf
g∈G ℓDT (g ◦f DS
A ) −ℓDS(gDS
A
◦f DS
A ) + ℓDS(gDS
A
◦f DS
A ) −
inf
g∈G,f∈FA ℓDS(g ◦f)"
REFERENCES,0.41952789699570814,"= τ(A; DS, DT ) + ϵ.
Therefore, it holds that dFA(DS, DT ) ≤τ(A; DS, DT ) + ϵ, and thus the theorem."
REFERENCES,0.4206008583690987,"Lemma A.2 (Lemma 3.1 Restated). Assuming the individual loss function ℓ: Y ×Y →[0, c], given
any distribution D ∈PX×Y and ∀δ > 0, with probability ≥1 −δ we have"
REFERENCES,0.4216738197424893,"dG,F(D, bDn) ≤2Rad b
Dn(LG,F) + 3c r"
REFERENCES,0.4227467811158798,ln(4/δ)
N,0.4238197424892704,"2n
."
N,0.4248927038626609,"Proof. Given any δ > 0, f ∈F, g ∈G, D ∈PX×Y, and taking any hg,f ∈LG,F (Deﬁnition 3),
with probability ≥1 −δ we have"
N,0.4259656652360515,"ℓD(g ◦f) −ℓb
Dn(g ◦f) = E(x,y)∼D[hg,f(x, y)] −1 n n
X"
N,0.4270386266094421,"i=1
hg,f(xi, yi)"
N,0.4281115879828326,"≤2Rad b
Dn(LG,F) + 3c r"
N,0.4291845493562232,ln(2/δ)
N,0.4302575107296137,"2n
,
(10)"
N,0.4313304721030043,"where the inequality is by the well-known Rademacher complexity uniform bound. Similarly,"
N,0.43240343347639487,"ℓb
Dn(g ◦f) −ℓD(g ◦f) = E(x,y)∼D[−hg,f(x, y)] −1 n n
X"
N,0.4334763948497854,"i=1
−hg,f(xi, yi)"
N,0.434549356223176,"≤2Rad b
Dn(−LG,F) + 3c r"
N,0.4356223175965665,ln(2/δ)
N,0.4366952789699571,2n
N,0.43776824034334766,"= 2Rad b
Dn(LG,F) + 3c r"
N,0.4388412017167382,ln(2/δ)
N,0.43991416309012876,"2n
.
(11)"
N,0.4409871244635193,Under review as a conference paper at ICLR 2022
N,0.44206008583690987,"The probability that both events equation 10 and equation 11 happen can be upper bounded by union
bound, i.e.,"
N,0.44313304721030045,Pr((10) ∧(11)) = 1 −Pr((10)c ∨(11)c) ≥1 −(Pr((10)c) + Pr((11)c)) ≥1 −2δ.
N,0.44420600858369097,"Therefore, combining the above with probability ≥1 −δ we have"
N,0.44527896995708155,"|ℓD(g ◦f) −ℓb
Dn(g ◦f)| ≤2Rad b
Dn(LG,F) + 3c r"
N,0.44635193133047213,ln(4/δ)
N,0.44742489270386265,"2n
.
(12)"
N,0.44849785407725323,"With equation 12, we can prove the lemma as the following. Given ∀ϵ > 0, by the deﬁnition of
inﬁmum there exists a gϵ ∈G such that"
N,0.44957081545064376,"ℓD(gϵ ◦f) < inf
g∈G ℓD(g ◦f) + ϵ."
N,0.45064377682403434,"By equation 12, with probability ≥1 −δ we have"
N,0.4517167381974249,"ℓb
Dn(gϵ ◦f) ≤ℓD(gϵ ◦f) + 2Rad b
Dn(LG,F) + 3c r"
N,0.45278969957081544,ln(4/δ)
N,0.453862660944206,"2n
."
N,0.45493562231759654,"Moreover, by deﬁnition"
N,0.4560085836909871,"inf
g∈G ℓb
Dn(g ◦f) ≤ℓb
Dn(gϵ ◦f)."
N,0.4570815450643777,Combining the above three inequalities we have
N,0.4581545064377682,"inf
g∈G ℓb
Dn(g ◦f) < inf
g∈G ℓD(g ◦f) + ϵ + 2Rad b
Dn(LG,F) + 3c r"
N,0.4592274678111588,ln(4/δ)
N,0.46030042918454933,"2n
."
N,0.4613733905579399,"Letting ϵ →0, we can see that"
N,0.4624463519313305,"inf
g∈G ℓb
Dn(g ◦f) ≤inf
g∈G ℓD(g ◦f) + 2Rad b
Dn(LG,F) + 3c r"
N,0.463519313304721,ln(4/δ)
N,0.4645922746781116,"2n
."
N,0.4656652360515021,"Similarly, we can derive the above inequality again but with D and bDn switched. Therefore,"
N,0.4667381974248927,"| inf
g∈G ℓb
Dn(g ◦f) −inf
g∈G ℓD(g ◦f)| ≤2Rad b
Dn(LG,F) + 3c r"
N,0.4678111587982833,ln(4/δ)
N,0.4688841201716738,"2n
."
N,0.4699570815450644,"Since the above inequality holds for ∀f ∈F, taking the supremum over f ∈F gives the lemma."
N,0.47103004291845496,"Lemma A.3. Assuming the individual loss function ℓ: Y × Y →[0, c], given any distributions
DS, DT ∈PX×Y and ∀δ > 0, with probability ≥1 −δ we have"
N,0.4721030042918455,"dFA(DS, DT ) ≤dFA( bDn
S, bDn
T ) + 2(Rad b
Dn
S(LG,FA) + Rad b
Dn
T (LG,FA)) + 6c r"
N,0.47317596566523606,ln(8/δ)
N,0.4742489270386266,"2n
."
N,0.47532188841201717,"Proof. By Proposition 3.2, we apply the triangle inequality to derive"
N,0.47639484978540775,"dFA(DS, DT ) ≤dFA(DS, bDn
T ) + dFA( bDn
T , DT )"
N,0.47746781115879827,"≤dFA( bDn
S, bDn
T ) + dFA( bDn
T , DT ) + dFA( bDn
S, DS)."
N,0.47854077253218885,"By Lemma 3.1, we can apply the union bound argument (e.g., see the proof of Lemma 3.1) to bound
dFA( bDn
T , DT ) and dFA( bDn
S, DS). That being said, ∀δ′ > 0 with probability ≥1 −2δ′ we have"
N,0.4796137339055794,"dFA( bDn
S, DS) ≤2Rad b
Dn
S(LG,FA) + 3c r"
N,0.48068669527896996,ln(4/δ′)
N,0.48175965665236054,2n
N,0.48283261802575106,"dFA( bDn
T , DT ) ≤2Rad b
Dn
T (LG,FA) + 3c r"
N,0.48390557939914164,ln(4/δ′)
N,0.48497854077253216,"2n
."
N,0.48605150214592274,"Therefore,"
N,0.4871244635193133,"dFA( bDn
T , DT ) + dFA( bDn
S, DS) ≤2(Rad b
Dn
S(LG,FA) + Rad b
Dn
T (LG,FA)) + 6c r"
N,0.48819742489270385,ln(4/δ′)
N,0.4892703862660944,"2n
."
N,0.490343347639485,Denoting δ = 2δ′ gives the lemma.
N,0.49141630901287553,Under review as a conference paper at ICLR 2022
N,0.4924892703862661,"Theorem A.3 (Theorem 3.3 Restated). Given ∀DS, DT ∈PX×Y, for ∀δ > 0 with probability
≥1 −δ we have"
N,0.49356223175965663,"τ(A; bDn
S, DT ) ≤dFA( bDn
S, bDn
T ) + 2Rad b
Dn
T (LG,FA) + 4Rad b
Dn
S(LG,FA) + 9c r"
N,0.4946351931330472,ln(8/δ)
N,0.4957081545064378,"2n
."
N,0.4967811158798283,"Proof. For ∀δ > 0, from the proof of Lemma A.3 we can see that with probability ≥1 −δ:"
N,0.4978540772532189,"dFA( bDn
S, DS) ≤2Rad b
Dn
S(LG,FA) + 3c r"
N,0.4989270386266094,ln(8/δ)
N,0.5,"2n
(13)"
N,0.5010729613733905,"dFA( bDn
T , DT ) ≤2Rad b
Dn
T (LG,FA) + 3c r"
N,0.5021459227467812,ln(8/δ)
N,0.5032188841201717,"2n
,"
N,0.5042918454935622,and Lemma A.3 holds. Therefore
N,0.5053648068669528,"τ(A; bDn
S, DT ) = inf
g∈G ℓDT (g ◦f
b
Dn
S
A ) −ℓb
Dn
S(g
b
Dn
S
A
◦f
b
Dn
S
A )"
N,0.5064377682403434,"≤inf
g∈G ℓDT (g ◦f
b
Dn
S
A ) −inf
g∈G ℓb
Dn
S(g ◦f
b
Dn
S
A )"
N,0.5075107296137339,"= inf
g∈G ℓDT (g ◦f
b
Dn
S
A ) −inf
g∈G ℓDS(g ◦f
b
Dn
S
A ) + inf
g∈G ℓDS(g ◦f
b
Dn
S
A ) −inf
g∈G ℓb
Dn
S(g ◦f
b
Dn
S
A )"
N,0.5085836909871244,"≤dFA(DS, DT ) + dFA( bDn
S, DS)"
N,0.509656652360515,"≤dFA(DS, DT ) + 2Rad b
Dn
S(LG,FA) + 3c r"
N,0.5107296137339056,ln(8/δ)
N,0.5118025751072961,2n
N,0.5128755364806867,"≤dFA( bDn
S, bDn
T ) + 2Rad b
Dn
T (LG,FA) + 4Rad b
Dn
S(LG,FA) + 9c r"
N,0.5139484978540773,ln(8/δ)
N,0.5150214592274678,"2n
,"
N,0.5160944206008584,"where the ﬁrst inequality is by deﬁnition of inﬁmum, the second inequality is by the Deﬁnition 2,
the third inequality is by equation 13 and the last inequality is by Lemma A.3."
N,0.5171673819742489,"B
DATA AUGMENTATION (DA) AS REGULARIZATION"
N,0.5182403433476395,"In this section, we discuss data augmentation (DA) as a concrete example of regularization for train-
ing feature extractor f DS
A , and explore its impact on the function class FA discussed in Section 3."
N,0.51931330472103,"Empirical research has shown evidence of the regularization effect of DA (Hern´andez-Garc´ıa &
K¨onig, 2018a;b). However, there is a lack of theoretical analysis, and thus we aim to construct a
theoretical framework to understand under what sufﬁcient conditions DA can be viewed as regu-
larization on the feature extractor function class FA. We categorize DA into feature-level DA and
data-level DA, and for each category, we analyze different DA algorithms to characterize the suf-
ﬁcient conditions under which DA regularizes the function class FA. Combined with analysis in
Theorem 3.3, we also provide concrete sufﬁcient conditions to tighten the upper bound of relative
transferability τ(A; bDn, DT )."
N,0.5203862660944206,"General Settings. For the following discussion we apply a general DA setting of afﬁne transfor-
mation (Perez & Wang, 2017), taking the form of x⋆= W ⊤
⋆x + b⋆, where (x, x⋆) is a pair of the
original and augmented samples, (W⋆, b⋆) are parameters representing speciﬁc DA policies. We set
g : Rd →R as the linear layer corresponding to the weight matrix Wg, which will be composed with
the feature extractor f : Rm →Rd. We use squared loss for ℓ: R × R →R, and let ℓb
Dn,A(g ◦f)
be the objective function given by training algorithm A from Theorem 3.3."
N,0.5214592274678111,"B.1
FEATURE-LEVEL DA (AF L)"
N,0.5225321888412017,"Feature-level DA (Wong et al., 2016; DeVries & Taylor, 2017) requires the transformation to be
performed in the learned feature space, which gives us an augmented feature W⋆f(x) + b⋆. We
use Loss-Averaging algorithm where we take an average of the loss over augmented features for"
N,0.5236051502145923,Under review as a conference paper at ICLR 2022
N,0.5246781115879828,"training. Denote the training algorithm based on feature-level DA as AF L, the objective function is
as below."
N,0.5257510729613734,"ℓb
Dn,AF L(g ◦f) = 1 n n
X"
N,0.526824034334764,"i=1
EW⋆,b⋆ℓ

g ◦
 
W⋆f(xi) + b⋆

, yi

."
N,0.5278969957081545,"Theorem B.1. Apply feature-level DA with afﬁne transformation parameters (W⋆, b⋆) s.t.
1)
EW⋆[W⋆] = Im; 2) W⋆̸≡Im (i.e., W⋆is not an identity matrix); 3) Eb⋆[b⋆] = ⃗0m; 4) W⋆and
b⋆are independent. Set ℓ: R × R →R as squared loss; Deﬁne ∆W⋆:= W⋆−Im, then we have"
N,0.528969957081545,"ℓb
Dn,AF L(g ◦f) = ℓb
Dn,A(g ◦f) + ΩAF L,"
N,0.5300429184549357,where ΩAF L = 1
N,0.5311158798283262,"n
Pn
i=1 EW⋆
hf(xi)⊤∆W⋆Wg
2
2"
N,0.5321888412017167,"i
+ Eb⋆
hb⊤
⋆Wg
2
2 i
."
N,0.5332618025751072,"Proof. ℓ′′(W ⊤
g ◦f(xi)) = 2 for ℓas squared loss. Apply Taylor expansion to ℓ

g ◦
 
W⋆f(xi) +"
N,0.5343347639484979,"b⋆

, yi

around f(xi), all higher-than-two order terms will vanish:"
N,0.5354077253218884,"EW⋆,b⋆"
N,0.5364806866952789,"
ℓ

g ◦
 
W⋆f(xi) + b⋆

, yi
"
N,0.5375536480686696,"=EW⋆,b⋆"
N,0.5386266094420601,"
ℓ

W ⊤
g ◦f(xi), yi

+ W ⊤
g (∆W⋆f(xi) + b⋆)ℓ′(W ⊤
g ◦f(xi), yi)+"
N,0.5396995708154506,"1
2W ⊤
g (∆W⋆f(xi) + b⋆)(∆W⋆f(xi) + b⋆)⊤ℓ′′(W ⊤
g ◦f(xi), yi)Wg "
N,0.5407725321888412,"=ℓ

W ⊤
g ◦f(xi), yi

+ EW⋆,b⋆
h
W ⊤
g (∆W⋆f(xi) + b⋆)(∆W⋆f(xi) + b⋆)⊤Wg
i"
N,0.5418454935622318,"=ℓ

W ⊤
g ◦f(xi), yi

+ EW⋆
hf(xi)⊤∆W⋆Wg
2
2"
N,0.5429184549356223,"i
+ Eb⋆
hb⊤
⋆Wg
2
2 i
;"
N,0.5439914163090128,"The second equality holds since E∆W⋆= EW⋆[W⋆−Im] = 0(m,m) and Eb⋆= ⃗0m; The third"
N,0.5450643776824035,"equality holds since Wi and bi are independent. Therefore, ℓb
Dn,AF L(g◦f) := 1"
N,0.546137339055794,"n
Pn
i=1"
N,0.5472103004291845,"
EW⋆,b⋆ℓ

g◦"
N,0.5482832618025751," 
W⋆f(xi) + b⋆

, yi

= ℓb
Dn,A(g ◦f) + ΩAF L."
N,0.5493562231759657,"Interpretation. ΩAF L is composed of two segments: 1) l2 regularization to an f-dependent scalar
averaged over W⋆and xi; 2) l2 regularization to an f-independent scalar averaged over b⋆. Due to
the regularization effect on f from the ﬁrst segment of ΩAF L, we can reasonably expect the function
class FA′ enabled by AF L to be a subset of that enabled by a general training algorithm A."
N,0.5504291845493562,"Sufﬁcient conditions. Combined with Theorem 3.3, the sufﬁcient conditions to tighten the upper
bound dFA( bDn
S, bDn
T ) for the relative transferability τ(A; bDS, DT ) are: feature-level DA (AF L) with
parameters satisfying: 1) EW⋆[W⋆] = Im; 2) W⋆̸≡Im; 3) Eb⋆[b⋆] = ⃗0m; 4) W⋆and b⋆are
independent."
N,0.5515021459227468,"B.2
DATA-LEVEL DA (ADL)"
N,0.5525751072961373,"Data-level DA requires that the transformation to be performed in the input space to generate aug-
mented samples W⋆x + b⋆. We cover analysis on two ubiquitous algorithms for data-level DA
training: Prediction-Averaging (ADL
P ) (Lyle et al., 2019) and Loss-Averaging (ADL
L ) (Wong et al.,
2016). The difference between ADL
P
and ADL
L
lies in whether we take the average of the prediction
or the losses:"
N,0.5536480686695279,"ℓb
Dn,ADL
P (g ◦f) := 1 n n
X"
N,0.5547210300429185,"i=1
ℓ
 
EW⋆,b⋆

g ◦f(W⋆xi + b⋆)

, yi

;
(14)"
N,0.555793991416309,"ℓb
Dn,ADL
L (g ◦f) := 1 n n
X"
N,0.5568669527896996,"i=1
EW⋆,b⋆

ℓ
 
g ◦f(W⋆xi + b⋆), yi

."
N,0.5579399141630901,Under review as a conference paper at ICLR 2022
N,0.5590128755364807,"Theorem B.2. Deﬁne the data-level deviation caused by data-level DA ADL ∈{ADL
P , ADL
L } with
parameters (W⋆, b⋆) from the original data sample as ∆xi := (W⋆−Im)xi + b⋆, and deﬁne ∆3
x :="
N,0.5600858369098712,"Exi,W⋆,b⋆
h∆xi
3
2"
N,0.5611587982832618,"i
. Suppose we apply data-level DA s.t. 1) EW⋆[W⋆] = Im; 2) Eb⋆[b⋆] = ⃗0m; 3)"
N,0.5622317596566524,"O(∆j
x) ≈0, ∀j ∈N+, j ≥3; 4) W⋆and b⋆are independent. Deﬁne ∆W⋆:= W⋆−Im ∈Rm×m,
∆byi := W ⊤
g f(xi) −yi ∈R. Let W (k)
g
∈R be the kth dimension component of Wg and then deﬁne"
N,0.5633047210300429,"wi,(k) := W (k)
g
∆byi ∈R; Denote the Hessian matrix of the kth dimension component in f(xi) as"
N,0.5643776824034334,"H(k),i
f
; Let ∇f be the Jacobian matrix of f, then we have"
N,0.5654506437768241,"ℓb
Dn,ADL(g ◦f) = ℓb
Dn,A(g ◦f) + ΩADL + O(∆3
x),"
N,0.5665236051502146,"where ΩADL
P
= 1"
N,0.5675965665236051,"n
Pn
i=1
Pd
k=1 wi,(k)
h
tr

EW⋆[∆xi∆⊤
xi]H(k),i
f
i
, where ∆xi = (W⋆−I)⊤xi +b⋆;"
N,0.5686695278969958,"ΩADL
L
= ΩADL
P
+ 1"
N,0.5697424892703863,"n
Pn
i=1
h
EW⋆
x⊤
i ∆W⋆∇f(xi)Wg
2
2 + Eb⋆
b⊤
⋆∇f(xi)Wg
2
2 i
."
N,0.5708154506437768,"Proof. Let ∆fi,ADL
P
:= EW⋆,b⋆f(W ⊤
⋆xi + b⋆) −f(xi), then"
N,0.5718884120171673,"∆fi,ADL
P
:=EW⋆,b⋆f(W ⊤
⋆xi + b⋆) −f(xi)"
N,0.572961373390558,"=EW⋆,b⋆
h
∇f(xi)⊤(∆xi)
i
+ 1"
N,0.5740343347639485,"2EW⋆,b⋆
h
∆⊤
xiH(k),i
f
(xi)∆xi
i"
N,0.575107296137339,"d + O(EW⋆,b⋆∥∆xi∥3
2) =1"
N,0.5761802575107297,"2EW⋆,b⋆
h
∆⊤
xiH(k),i
f
(xi)∆xi
i"
N,0.5772532188841202,"d + O(EW⋆,b⋆∥∆xi∥3
2),
(15)"
N,0.5783261802575107,"where [·(k)]d denotes a d-dimensional vector and k denotes the kth dimension element. Since ℓ
is squared loss, the third-and-higher derivative are 0, therefore, the third-and-higher order terms in
Taylor expansion to ℓ
 
EW⋆,b⋆

g ◦f(W⋆xi + b⋆)

, yi

around f(xi) will vanish:"
N,0.5793991416309013,"ℓ
 
EW⋆,b⋆

g ◦f(W⋆xi + b⋆)

, yi
"
N,0.5804721030042919,"=ℓ
 
g ◦f(xi), yi

+ W ⊤
g (∆fi,ADL
P )ℓ′ 
g ◦f(xi), yi

+"
N,0.5815450643776824,"1
2W ⊤
g (∆fi,ADL
P )(∆fi,ADL
P )⊤Wgℓ′′ 
g ◦f(xi), yi
"
N,0.5826180257510729,"=ℓ
 
g ◦f(xi), yi

+ W ⊤
g (∆fi,ADL
P )ℓ′ 
g ◦f(xi), yi

+ O(EW⋆,b⋆∥∆xi∥4
2)
(16)"
N,0.5836909871244635,"Substitute Eq. (15) into the ﬁrst-order term in Eq. (16), we have"
N,0.5847639484978541,"W ⊤
g (∆fi,ADL
P )ℓ′ 
g ◦f(xi), yi

=W ⊤
g EW⋆,b⋆
h
∆⊤
xiH(k),i
f
∆xi
i"
N,0.5858369098712446,"d∆byi + O(EW⋆,b⋆∥∆xi∥3
2) =∆byi d
X"
N,0.5869098712446352,"k=1
W (k)
g
EW⋆,b⋆
h
∆⊤
xiH(k),i
f
∆xi
i
+ O(EW⋆,b⋆∥∆xi∥3
2) = d
X"
N,0.5879828326180258,"k=1
wi,(k)tr
 
EW⋆,b⋆[∆xi∆⊤
xi]H(k),i
f

+ O(EW⋆,b⋆∥∆xi∥3
2). (17)"
N,0.5890557939914163,"Substitute Eq. (17) into Eq. (16), we have"
N,0.5901287553648069,"ℓ
 
EW⋆,b⋆

g ◦f(W⋆xi + b⋆)

, yi

=ℓ
 
g ◦f(xi), yi

+ d
X"
N,0.5912017167381974,"k=1
wi,(k)tr
 
EW⋆,b⋆[∆xi∆⊤
xi]H(k),i
f

+"
N,0.592274678111588,"O(EW⋆,b⋆∥∆xi∥3
2).
(18)"
N,0.5933476394849786,"Substitute Eq. (18) into Eq. (14) which is the deﬁnition of ℓb
Dn,ADL
P (g ◦f), and recall that ∆3
x :="
N,0.5944206008583691,"Exi,W⋆,b⋆
h∆xi
3
2"
N,0.5954935622317596,"i
, we have"
N,0.5965665236051502,"ℓb
Dn,ADL
P (g ◦f) := 1 n n
X"
N,0.5976394849785408,"i=1
ℓ
 
EW⋆,b⋆

g ◦f(W⋆xi + b⋆)

, yi

= ℓb
Dn,A(g ◦f) + ΩADL
P
+ O(∆3
x). (19)"
N,0.5987124463519313,Under review as a conference paper at ICLR 2022
N,0.5997854077253219,"Let ∆fi,ADL
L
:= f(W ⊤
⋆xi + b⋆) −f(xi) = ∇f(xi)⊤(∆W⋆xi + b⋆) + O(∥∆xi∥2
2)."
N,0.6008583690987125,"Applying Taylor expansion to EW⋆,b⋆

ℓ
 
g ◦f(W⋆xi + b⋆), yi

around f(xi) will give us"
N,0.601931330472103,"EW⋆,b⋆

ℓ
 
g ◦f(W⋆xi + b⋆), yi

=ℓ
 
g ◦f(xi), yi

+ W ⊤
g EW⋆,b⋆

∆fi,ADL
L

ℓ′ 
g ◦f(xi), yi

+"
N,0.6030042918454935,"1
2W ⊤
g EW⋆,b⋆

(∆fi,ADL
L )(∆fi,ADL
L )⊤
Wgℓ′′ 
g ◦f(xi), yi
 (20)"
N,0.6040772532188842,"Since EW⋆,b⋆∆fi,ADL
L
= ∆fi,ADL
P , the ﬁrst-order term in Eq. (20) is exactly Eq. (17):"
N,0.6051502145922747,"W ⊤
g EW⋆,b⋆

∆fi,ADL
L

ℓ′ 
g ◦f(xi), yi
"
N,0.6062231759656652,"=W ⊤
g ∆fi,ADL
P ℓ′ 
g ◦f(xi), yi
 = d
X"
N,0.6072961373390557,"k=1
wi,(k)tr
 
EW⋆,b⋆[∆xi∆⊤
xi]H(k),i
f

+ O(EW⋆,b⋆∥∆xi∥3
2)
(21)"
N,0.6083690987124464,"The second-order term in Eq. (20) is
1
2W ⊤
g EW⋆,b⋆

(∆fi,ADL
L )(∆fi,ADL
L )⊤
Wgℓ′′ 
g ◦f(xi), yi
"
N,0.6094420600858369,"=W ⊤
g EW⋆,b⋆

(∇f(xi)⊤(∆W⋆xi + b⋆)(∆W⋆xi + b⋆)⊤∇f(xi)

Wg + O(EW⋆,b⋆∥∆xi∥4
2)"
N,0.6105150214592274,"=EW⋆
x⊤
i ∆⊤
W⋆∇f(xi)Wg
2
2 + Eb⋆
b⊤
⋆∇f(xi)Wg
2
2 + O(EW⋆,b⋆∥∆xi∥4
2)
(22)"
N,0.6115879828326181,"Substituting Eq. (21) and Eq. (22) into Eq. (20), we have
EW⋆,b⋆

ℓ
 
g ◦f(W⋆xi + b⋆), yi
"
N,0.6126609442060086,"=ℓ
 
g ◦f(xi), yi

+ d
X"
N,0.6137339055793991,"k=1
wi,(k)tr
 
EW⋆,b⋆[∆xi∆⊤
xi]H(k),i
f

+"
N,0.6148068669527897,"EW⋆
x⊤
i ∆W⋆∇f(xi)Wg
2
2 + Eb⋆
b⊤
⋆∇f(xi)Wg
2
2 + O(EW⋆,b⋆∥∆xi∥4
2)
(23)"
N,0.6158798283261803,"Substitute Eq. (23) into the deﬁnition of ℓb
Dn,ADL
L (g ◦f), then"
N,0.6169527896995708,"ℓb
Dn,ADL
L (g ◦f) := 1 n n
X"
N,0.6180257510729614,"i=1
EW⋆,b⋆

ℓ
 
g ◦f(W⋆xi + b⋆), yi

= ℓb
Dn,A(g ◦f) + ΩADL
L
+ O(∆3
x) (24)"
N,0.619098712446352,The proof is complete by Eq. (19) and Eq. (24).
N,0.6201716738197425,"Interpretation. ΩADL
P
and ΩADL
L
turn out to be: 1) ΩADL
P
is a weighted trace expectation dependent
on the Hessian matrix of f; 2) ΩADL
L
is equivalent to ΩADL
P
together with the summation of two
norm expectations dependent on ∇f. Therefore, the data-level DA algorithms ADL
P
and ADL
L
are
expected to regularize f so that the f function class FDL
A
enabled by ADL ∈{ADL
P , ADL
L } would
be reasonably expected as a subset of FA enabled by general training algorithm A."
N,0.621244635193133,"Sufﬁcient conditions.
Combined with Theorem 3.3, the sufﬁcient conditions indicated here to
tighten the upper bound dFA( bDn
S, bDn
T ) of the relative transferability τ(A; bDS, DT ) are: data-
level DA (ADL) with DA parameters satisfying that 1) EW⋆[W⋆] = Im; 2) Eb⋆[b⋆] = ⃗0m; 3)
O(∆j
x) ≈0, ∀j ∈N+, j ≥3; 4) W⋆and b⋆are independent."
N,0.6223175965665236,"Empirical veriﬁcation. We further provide empirical veriﬁcation in Section 4 for the sufﬁcient
conditions above, investigating the concrete cases of DA methods: 1) Gaussian noise satisﬁes the
sufﬁcient conditions, then we empirically show that Gaussian noise improves domain transferability
while robustness decreases a bit (Figure 5); 2) Rotation, which rotates input image with a predeﬁned
ﬁxed angle with predeﬁned ﬁxed probability, violates EW⋆[W⋆] = Im, and we empirically show that
rotation barely affect domain transferability (Figure 14 in Appendix D.3); Translation, which moves
the input image for a predeﬁned distance along a pre-selected axis with ﬁxed probability, violates
Eb⋆[b⋆] = ⃗0m (Figure 14 in Appendix D.3)."
N,0.6233905579399142,Under review as a conference paper at ICLR 2022
N,0.6244635193133047,"Corollary B.2.1. If the neural network in Theorem B.2 is activated by Relu or Max-pooling, then
Theorem B.2 becomes"
N,0.6255364806866953,"ℓb
Dn,ADL(g ◦f) = ℓb
Dn,A(g ◦f) + ΩADL + O(∆3
x),"
N,0.6266094420600858,"where ΩADL
P
= 0; ΩADL
L
= 1"
N,0.6276824034334764,"n
Pn
i=1
h
EW⋆
x⊤
i ∆W⋆∇f(xi)Wg
2
2 + Eb⋆
b⊤
⋆∇f(xi)Wg
2
2 i
."
N,0.628755364806867,"Proof. Denote an L−layer NN g ◦f(x) := W ⊤
g · z[L−1], where z[l] := σ[l−1](W ⊤
[l−1] · z[l−1]),
l = 1, 2, 3, ..., L −1; Deﬁne that σ[0](W ⊤
[0] · z[0]) := x, then ∇2 
g ◦f(x)

= 0 (B.2 of Zhang et al.
(2020)). Since ∇2 
g ◦f(x)

= W ⊤
g · ∇2f(x), we have ∇2f(x) = 0."
N,0.6298283261802575,"Combine this with Theorem B.2, we have"
N,0.630901287553648,"ΩADL
P
= 1 n n
X i=1 d
X"
N,0.6319742489270386,"k=1
wi,(k)
h
tr

EW⋆[∆xi∆⊤
xi]H(k),i
f
i
= 0;"
N,0.6330472103004292,"ΩADL
L
= ΩADL
P
+ 1 n n
X i=1"
N,0.6341201716738197,"h
EW⋆
x⊤
i ∆W⋆∇f(xi)Wg
2
2 + Eb⋆
b⊤
⋆∇f(xi)Wg
2
2 i = 1 n n
X i=1"
N,0.6351931330472103,"h
EW⋆
x⊤
i ∆W⋆∇f(xi)Wg
2
2 + Eb⋆
b⊤
⋆∇f(xi)Wg
2
2 i
."
N,0.6362660944206009,"Remark. Corollary B.2.1 analyzes special cases (Relu/ Max-pooling activation) of Theorem B.2,
giving notably different regularization effect: in these cases the ADL
P
(average the prediction) fails as
a regularizer, therefore, doesn’t fulﬁll our sufﬁcient conditions for improving domain transferability
(Theorem 3.3); ADL
L
(average the loss) only reserves the regularization on ∇f-dependent norms,
but no longer regularizes Hf(x). Since ADL
L
still induces regularization, the induced sufﬁcient
conditions analyzed after Theorem B.2 for promoting domain transferability won’t be affected."
N,0.6373390557939914,"C
ADVERSARIAL TRAINING AS A REGULARIZER"
N,0.6384120171673819,"In this section, we show, under certain conditions, why adversarial training may improve domain
generalization by viewing adversarial training as a function class regularizer."
N,0.6394849785407726,We ﬁrst provide some notation. Let
N,0.6405579399141631,F = {fθ(·) = W LφL−1(W L−1φL−2(. . . ) + bL−1) + bL}
N,0.6416309012875536,"where φj are activations, W j, bj are weight matrix and bias vector, θ is the collection of parameters
(i.e. θ = (W 1, b1, . . . , W L, bL). For the rest of the article, assume that φj are just ReLUs."
N,0.6427038626609443,Now ﬁx x ∈X. Deﬁne the preactivation as
N,0.6437768240343348,ex1 := W 1x + b1
N,0.6448497854077253,"exj := W jφj−1(exj−1) + bj , j ≥2"
N,0.6459227467811158,"Deﬁne the activation pattern φx := (φ1
x, . . . , φL−1
x
) ∈{0, 1}m such that for each j ∈[L −1]"
N,0.6469957081545065,"φj
x = 1(exj > 0)"
N,0.648068669527897,where 1 is applied elementwise.
N,0.6491416309012875,"Now, given an activation pattern φ ∈{0, 1}m, we deﬁne the preimage X(φ) := {x ∈Rd : φx = φ}
Theorem C.1. (In the proof of theorem 1 in (Roth et al., 2020))"
N,0.6502145922746781,"Let ϵ > 0 s.t. Bp
ϵ (x) ⊂X(φx) where Bp
ϵ (x) denotes the lp ball centered at x with radius ϵ. Let
p = {1, 2, ∞} and q be the Holder conjugate of p (i.e. 1 p + 1"
N,0.6512875536480687,q = 1). Then
N,0.6523605150214592,"E(x,y)∼P [l(y, f(x)) + λ
max
x∗∈Bp
ϵ (x) ∥f(x) −f(x∗)∥q] = E(x,y)∼P [l(y, f(x)) + λ · ϵ
max
v∗: ∥v∗∥p≤1"
N,0.6534334763948498,"Jf(x)v

q]"
N,0.6545064377682404,Under review as a conference paper at ICLR 2022
N,0.6555793991416309,"Interpretation: This theorem provides an equivalence between the objective functions for adversar-
ial training (left term) and jacobian regularization (right term). We give some intuition on the size of
ϵ. Let us ﬁrst consider a shallow 2 layer network f(x) = W 2φ(W 1x+b1). Suppose W 2 ∈Rm2×m1
and W 1 ∈Rm1×d. Given a matrix M, let Mj denote the jth row of M. We study the activation
pattern φx which equals"
N,0.6566523605150214,"φx = (φ1
x) =  
"
N,0.657725321888412,"1{W 1
1 x + b1
1}
...
1{W 1
m1x + b1
m1}  
"
N,0.6587982832618026,"We wish to compute the largest radius ϵ such that the activation pattern φx is constant within B2
ϵ (x).
This is simply the distance from x to the closest hyperplane of the form HW 1
j ,b1
j = {x ∈Rd :
W 1
j x + b1
j = 0} where j = 0, . . . , m1 (i.e. ϵ = minj dist(x, HW 1
j ,b1
j)). In particular, if W 1 = Id×d
and b1 = 0, ϵ = minj∈d|xj|."
N,0.6598712446351931,"Furthermore, we note that ϵ is nondecreasing as a function of the number of layers. However, it has
been observed empirically in (Roth et al., 2020) that approximate correspondence holds in a much
larger ball.
Deﬁnition 4. (source and target function class) Let GS, GT be ﬁne tuning function classes for source
and target domains, respectively. We deﬁne the class of source models as"
N,0.6609442060085837,"HS = GS ◦F = {gS ◦fθ : gS ∈GS, fθ ∈F}"
N,0.6620171673819742,and the class of target models as
N,0.6630901287553648,"HT = GT ◦F = {gT ◦fθ : gT ∈GT , fθ ∈F}"
N,0.6641630901287554,"Deﬁnition 5. (empirical training objective with jacobian regularization) Let λ, ϵ > 0. Take any
hypothesis hθ = gS ◦fθ ∈HS. Let ˆR(hθ) = 1"
N,0.6652360515021459,"n
Pn
i=1 ℓ(hθ(xi), yi) denote the empirical risk where
l(ˆy, y) = ∥ˆy −y∥2. We deﬁne the empirical training objective with jacobian regularization as"
N,0.6663090128755365,"ObjA
λ (hθ) = ˆR(hθ) + λ · ϵ n n
X"
N,0.6673819742489271,"i=1
∥Jhθ(xi)∥2"
N,0.6684549356223176,Theorem C.2. Fix regularization strength λ > 0. Deﬁne
N,0.6695278969957081,"FA
λ = {f A
θ ∈F : ∃gS ∈GS s.t. ObjA
λ (gS ◦f A
θ ) ≤ObjA
λ (0)}"
N,0.6706008583690987,"where 0 denotes the zero function (i.e. the class of feature extractors that outperform the zero
function). Suppose (x, y) ∈X × Y is bounded such that max (∥x∥∞, ∥y∥2) ≤R. Fix δ > 0.
Suppose we additionally restrict our ﬁne tuning class models to linear models where"
N,0.6716738197424893,"GS = {W : W ∈Rd×n, n ≥1, min
j
∥Wj∥2 ≥δ}"
N,0.6727467811158798,(where Wj is the jth column of W) and
N,0.6738197424892703,"GT = {W : W ∈Rd×n, n ≥1}"
N,0.674892703862661,"(Here we are abusing notation to let gS ∈GS to denote the last linear layer as well as the ﬁne
tuning function)."
N,0.6759656652360515,"Then for 0 ≤λ1 < λ2
FA
λ2 ⊊FA
λ1 ⊊F"
N,0.677038626609442,"(where ⊊denotes proper subset). In particular, if HA,T
λ
= GT ◦FA
λ , we have"
N,0.6781115879828327,"HA,T
λ2
⊊HA,T
λ1
⊊HT"
N,0.6791845493562232,Interpretation:
N,0.6802575107296137,"At the high level, this theorem captures the idea that minimizing the empirical risk with jacobian
regularization puts a constraint on the set of feature extractors. In particular, FA
λ1 represents the
potential class of feature extractors we select after training with jacobian regularization. Therefore,"
N,0.6813304721030042,Under review as a conference paper at ICLR 2022
N,0.6824034334763949,"the class of ﬁne tuned models HA,T
λ1
with feature extractors trained with jacobian regularization for
the target domain is smaller than the class of ﬁne tuned models H with feature extractors trained
without any regularization. Furthermore, we show that the space of feature extractors shrinks as we
increase the regularization stength λ. Since we showed in section 3.3 that smaller function classes
have smaller dFA, this theorem shows that jacobian regularization reduces dFA. To connect back to
adversarial training, if ϵ satisﬁes the hypothesis in theorem C.1, we have that
E(x,y)∼P [l(y, f(x)) + λ
max
x∗∈Bp
ϵ (x) ∥f(x) −f(x∗)∥q] = E(x,y)∼P [l(y, f(x)) + λ · ϵ
max
v∗: ∥v∗∥p≤1"
N,0.6834763948497854,"Jf(x)v

q]"
N,0.6845493562231759,"Therefore, minimizing the training objective with jacobian regularization is equivalent to minimizing
the adversarial training objective. Using this connection, this theorem essentially shows that, given
sufﬁcient number of samples, adversarial training reduces the class of feature extractors which in
turn reduces dFA."
N,0.6856223175965666,"Finally, we comment on the assumption that
gS > δ. Since δ > 0 is arbitrary, we can make it as
small as we like and thus we are essentially excluding the 0 last layer which is hardly a constraint on
the function class. This assumption is necessary as we are considering regularization on the whole
model g◦f as opposed to regularization on just the feature extractor. Thus, this assumption prevents
the scenario where only the last linear layer is regularized."
N,0.6866952789699571,"Proof. We ﬁrst show that if 0 ≤λ1 < λ2, we have that
FA
λ2 ⊊FA
λ1 ⊊F"
N,0.6877682403433476,We ﬁrst prove the following lemma
N,0.6888412017167382,"Lemma C.1. Suppose the conditions of theorem C.2 are satisﬁed. Suppose additionally we have
that y :=
1
n
Pd
i=1 yi ̸= 0 (note this occurs with probability 1 if marginal distribution over Y is
continuous). Then for every λ ≥0, there exists a function fθ ∈FA
λ and a ﬁne tuning layer g∗∈GS
such that
ObjA
λ (g∗◦fθ) = inf
g∈GS ObjA
λ (g ◦fθ) = ObjA
λ (0)"
N,0.6899141630901288,"Choose another λ′ ≥0 (can equal λ). Then there exists a g∗′ ∈GS be the ﬁne tuning layer such
that infg∈GS ObjA
λ′(g ◦fθ) = ObjA
λ′(g∗′ ◦fθ) and"
N,0.6909871244635193,"1
n n
X"
N,0.6920600858369099,"i=1
∥Jg∗′◦fθ(xi)∥2 > 0"
N,0.6931330472103004,"Proof. Fix α ≥0 and c > α · R. Set biases b1 =  

"
N,0.694206008583691,"c
0
...
0 "
N,0.6952789699570815,"

bj = 0 , j ≥2"
N,0.6963519313304721,"and weights W 1 =  

"
N,0.6974248927038627,"α
0
. . .
0
0
0
. . .
0
...
...
...
...
0
. . .
. . .
0 "
N,0.6984978540772532,"

W j =  

"
N,0.6995708154506438,"1
0
. . .
0
0
0
. . .
0
...
...
...
...
0
. . .
. . .
0 "
N,0.7006437768240343,"

, j ≥2"
N,0.7017167381974249,"Deﬁne xi,j be the jth entry of the data point xi. Deﬁne
αi := α · xi,1"
N,0.7027896995708155,"α := 1 n d
X"
N,0.703862660944206,"i=1
αi"
N,0.7049356223175965,"y := 1 n d
X"
N,0.7060085836909872,"i=1
yi"
N,0.7070815450643777,Under review as a conference paper at ICLR 2022
N,0.7081545064377682,"Now we observe that for a ﬁxed λ ≥0 and any g ∈GS, we have that"
N,0.7092274678111588,"ObjA
λ (g ◦fθ) = ˆR(g ◦fθ) + λ · ϵ 1 n n
X"
N,0.7103004291845494,"i=1
∥Jg◦fθ(xi)∥2 = 1 n n
X i=1"
N,0.7113733905579399,"(αxi,1 + c)  
"
N,0.7124463519313304,"g11
...
gd1 "
N,0.7135193133047211,"
−yi  2 2"
N,0.7145922746781116,"+ λ · ϵ 1 n n
X i=1  g  

"
N,0.7156652360515021,"α
0
. . .
0
0
0
. . .
0
...
...
...
...
0
. . .
. . .
0  

 2 = 1 n n
X"
N,0.7167381974248928,"i=1
∥(αi + c)g1 −yi∥2
2 + λ · ϵ 1 n n
X"
N,0.7178111587982833,"i=1
α ∥g1∥2 = 1 n n
X"
N,0.7188841201716738,"i=1
∥(αi + c)g1 −yi∥2
2 + λ · ϵα ∥g1∥2"
N,0.7199570815450643,"Therefore,"
N,0.721030042918455,"inf
g∈GS ObjA
λ (g ◦fθ)"
N,0.7221030042918455,is equivalent to solving
N,0.723175965665236,"inf
w∈Rd : ∥w∥2≥δ
1
n n
X"
N,0.7242489270386266,"i=1
∥(αi + c)w −yi∥2
2 + λ · ϵα ∥w∥2
(25)"
N,0.7253218884120172,"Utilizing lagrange multipliers, we ﬁnd the minimizer is"
N,0.7263948497854077,"w = δ ·
y
∥y∥
(26)"
N,0.7274678111587983,when c ≥∥y∥2 δ .
N,0.7285407725321889,Now consider the function
N,0.7296137339055794,"S(c, α) = 1 n n
X"
N,0.73068669527897,"i=1
∥(α · xi,1 + c)g1 −yi∥2
2 + λ · ϵα ∥g1∥2"
N,0.7317596566523605,"Note that this function is continuous with respect to the input (c, α). Now ﬁx α = 0, c = ∥y∥2"
N,0.7328326180257511,"δ . Set
w = δ ·
y
∥y∥. Then we have that"
N,0.7339055793991416,S(∥y∥2
N,0.7349785407725322,"δ
, 0) = 1 n n
X"
N,0.7360515021459227,"i=1
∥y −yi∥2
2 < 1 n n
X"
N,0.7371244635193133,"i=1
∥yi∥2
2 = ObjA
λ (0)"
N,0.7381974248927039,"The inequality comes from the fact that we assumed y ̸= 0 and noting that y is the minimizer of the
function p(z) = 1"
N,0.7392703862660944,"n ∥z −yi∥2
2. Continuity of S ensures that there exists α0 > 0 such that"
N,0.740343347639485,S(∥y∥2
N,0.7414163090128756,"δ
, α0) < 1 n n
X"
N,0.7424892703862661,"i=1
∥yi∥2
2 = ObjA
λ (0)"
N,0.7435622317596566,Now consider U(t) = S((1 + t) ∥y∥2
N,0.7446351931330472,"δ , (1 + t)α0) for t ≥0. Note that U is continuous with respect
to t. Furthermore, we note that t →∞implies U(t) →∞which implies there exists some time
t = Tf such that U(Tf) > ObjA
λ (0). Therefore, by the intermediate value theorem, there exists a
time t = T such that U(T) = ObjA
λ (0). Finally, set c = (T + 1) ∥y∥2"
N,0.7457081545064378,"δ , α = (T + 1)α0, and g∗as
the matrix where g∗
1 = δ ·
y
∥y∥and 0 for the other columns. By equation 25 and equation 26 we have"
N,0.7467811158798283,"ObjA
λ (g∗◦fθ) = inf
g∈GS ObjA
λ (g ◦fθ) = U(T) = ObjA
λ (0)"
N,0.7478540772532188,"Furthermore, if we choose another λ′ ≥0, since c = (T + 1) ∥y∥2"
N,0.7489270386266095,"δ
> ∥y∥2"
N,0.75,"δ
by equation 26, we have
that"
N,0.7510729613733905,"ObjA
λ′(g∗′ ◦fθ) = inf
g∈GS ObjA
λ′(g ◦fθ)"
N,0.7521459227467812,Under review as a conference paper at ICLR 2022 and
N,0.7532188841201717,"1
n n
X"
N,0.7542918454935622,"i=1
∥Jg∗′◦fθ(xi)∥2 = α
g∗′
2 = αδ"
N,0.7553648068669528,which is nonzero as δ > 0 and α = (T + 1)α0 > 0.
N,0.7564377682403434,"Clearly, we have FA
λ2 ⊂FA
λ1. If we can show that fθ1 ̸∈FA
λ2 then we have FA
λ2 ⊊FA
λ1."
N,0.7575107296137339,"Using lemma C.1 we can ﬁnd fθ1 ∈FA
λ1 such that"
N,0.7585836909871244,"inf
g∈GS ObjA
λ1(g ◦fθ1) = ObjA
λ1(0)"
N,0.759656652360515,"In addition lemma C.1 guarantees minimizers g∗
1 and g∗
2 such that"
N,0.7607296137339056,"ObjA
λ1(g∗
1 ◦fθ1) = inf
g∈GS ObjA
λ1(g ◦fθ1) and 1 n n
X i=1"
N,0.7618025751072961,"Jg∗
1◦fθ(xi)

2 > 0"
N,0.7628755364806867,"ObjA
λ2(g∗
2 ◦fθ1) = inf
g∈GS ObjA
λ2(g ◦fθ1) and 1 n n
X i=1"
N,0.7639484978540773,"Jg∗
2◦fθ1(xi)

2 > 0"
N,0.7650214592274678,"Thus, we have that"
N,0.7660944206008584,"ObjA
λ1(g∗
2 ◦fθ1) = ˆR(g∗
2 ◦fθ1) + λ2 · ϵ 1 n n
X i=1"
N,0.7671673819742489,"Jg∗
2◦fθ1(xi)

2"
N,0.7682403433476395,"> ˆR(g∗
2 ◦fθ1) + λ1 · ϵ 1 n n
X i=1"
N,0.76931330472103,"Jg∗
2◦fθ1(xi)

2
since λ2 > λ1"
N,0.7703862660944206,"≥ˆR(g∗
1 ◦fθ1) + λ1 · ϵ 1 n n
X i=1"
N,0.7714592274678111,"Jg∗
1◦fθ1(xi)

2
def of g∗
1"
N,0.7725321888412017,"= ObjA
λ1(0)
lemma C.1"
N,0.7736051502145923,"Thus fθ1 ̸∈FA
λ2 which implies FA
λ2 ⊊FA
λ1. It remains to show for λ1 ≥0, we have that FA
λ1 ⊊F."
N,0.7746781115879828,"Consider any g ∈GS. For j ∈[L], deﬁne W j as the weight matrix where W j = Id×d (identity
matrix) for j ∈[L −1] and let the ﬁnal weight W L = B · Id×d for some constant B > 0. Set the
bias vectors bj = 0 for j ≥2. Let the ﬁrst bias equal b1 = R · 1 where 1 is the vector of all 1’s and
R is the upper bound such that ∥x∥∞≤R. Set θ = (W 1, b1, . . . , W L, bL) and let hθ = g ◦fθ"
N,0.7757510729613734,We compute
N,0.776824034334764,"ObjA
λ1(hθ) = ˆR(hθ) + λ1 · ϵ 1 n n
X"
N,0.7778969957081545,"i=1
∥Jhθ(xi)∥2 = 1 n n
X"
N,0.778969957081545,"i=1
∥B(xi + R1) −yi∥2 + 1 n n
X"
N,0.7800429184549357,"i=1
∥Jhθ(xi)∥2 = 1 n n
X"
N,0.7811158798283262,"i=1
∥B(xi + R1) −yi∥2 + B ∥g∥2 ≥1 n n
X"
N,0.7821888412017167,"i=1
∥B(xi + R1) −yi∥2 + Bδ"
N,0.7832618025751072,"We note that sending B →∞we get ObjA
λ1(hθ) →∞which implies that there exists a B = B′"
N,0.7843347639484979,"such that ObjA
λ1(hθ) > ObjA
λ1(0). Setting B = B′ implies fθ ̸∈FA
λ1."
N,0.7854077253218884,Under review as a conference paper at ICLR 2022
N,0.7864806866952789,"D
EXTRA EXPERIMENT RESULTS"
N,0.7875536480686696,"D.1
ABSOLUTE TRANSFERABILITY"
N,0.7886266094420601,"We show the results with absolute transferability in Figure 7,8,9 and 10 respectively."
N,0.7896995708154506,"10
20
30
Robust Acc (%) 30 35 40"
N,0.7907725321888412,Domain Transfer Acc (%)
N,0.7918454935622318,R: -0.798
N,0.7929184549356223,CIFAR10 -> SVHN
N,0.7939914163090128,"LLR(
l)
-0.1
0
0.1
1.0"
N,0.7950643776824035,"18
20
22
24
Robust Acc (%) 70 72 74 76"
N,0.796137339055794,R: -0.922
N,0.7972103004291845,ImageNet -> CIFAR10
N,0.7982832618025751,"LLR(
l)
-0.01
0
0.01
0.1"
N,0.7993562231759657,"10
20
30
Robust Acc (%) 20 25 30 35 40"
N,0.8004291845493562,R: -0.904
N,0.8015021459227468,CIFAR10 -> SVHN
N,0.8025751072961373,LLOT(||gs||2)
N,0.8036480686695279,"0.01
0.1
1.0
10.0"
N,0.8047210300429185,"20
30
40
Robust Acc (%) 72 74 76"
N,0.805793991416309,R: -0.929
N,0.8068669527896996,ImageNet -> CIFAR10
N,0.8079399141630901,LLOT(||gs||2)
N,0.8090128755364807,"0.5
1
2
5"
N,0.8100858369098712,"Figure 7: Robustness and absolute transferability when we control the norm of last layer with last-
layer regularization (LLR) and last-layer orthogonal training (LLOT) with different parameters."
N,0.8111587982832618,"20
30
40
50
60
70
Robust Acc (%) 20 25 30 35"
N,0.8122317596566524,Domain Transfer Acc (%)
N,0.8133047210300429,R: -0.619
N,0.8143776824034334,CIFAR10 -> SVHN
N,0.8154506437768241,"JR(
j)
0
10
100
1000"
N,0.8165236051502146,"15
25
35
45
55
Robust Acc (%) 70 75 80 85 90"
N,0.8175965665236051,R: 0.902
N,0.8186695278969958,ImageNet -> CIFAR10
N,0.8197424892703863,"JR(
j)
0
0.001
0.01
1.0"
N,0.8208154506437768,"10
20
Robust Acc (%) 30 35"
N,0.8218884120171673,R: 0.889
N,0.822961373390558,CIFAR10 -> SVHN
N,0.8240343347639485,"WD(
w)
0.0005
0.001
0.005
0.01"
N,0.825107296137339,"10
15
20
Robust Acc (%) 65 70 75"
N,0.8261802575107297,R: 0.909
N,0.8272532188841202,ImageNet -> CIFAR10
N,0.8283261802575107,"WD(
w)
0.0001
0.0005
0.001"
N,0.8293991416309013,"Figure 8: Robustness and absolute transferability when we regularize the feature extractor with
Jacobian Regularization (JR) and weight decay (WD) with different parameters."
N,0.8304721030042919,"20
30
40
50
60
70
Robust Acc (%) 30 35 40 45"
N,0.8315450643776824,Domain Transfer Acc (%)
N,0.8326180257510729,R: 0.768
N,0.8336909871244635,CIFAR10 -> SVHN
N,0.8347639484978541,Gauss( )
N,0.8358369098712446,"0
0.05
0.25
1.0"
N,0.8369098712446352,"20
30
Robust Acc (%) 75 80"
N,0.8379828326180258,R: -0.306
N,0.8390557939914163,ImageNet -> CIFAR10
N,0.8401287553648069,Gauss( )
N,0.8412017167381974,"0
0.05
0.25"
N,0.842274678111588,"20
30
40
50
Robust Acc (%) 35 40 45"
N,0.8433476394849786,R: 0.629
N,0.8444206008583691,CIFAR10 -> SVHN
N,0.8454935622317596,"Pos(b) 1
4
8"
N,0.8465665236051502,"20
25
30
Robust Acc (%) 73 75 77"
N,0.8476394849785408,R: 0.963
N,0.8487124463519313,ImageNet -> CIFAR10
N,0.8497854077253219,"Pos(b) 1
4
8"
N,0.8508583690987125,"Figure 9: Robustness and absolute transferability when we use Gaussian noise (Gauss) and posterize
(Pos) as data augmentations with different parameters."
N,0.851931330472103,"D.2
RESULTS OF OTHER MODEL STRUCTURES"
N,0.8530042918454935,"To further validate our evaluation results, we evaluate the experiments on another model structure.
We use a simpler CNN model for CIFAR-10 to SVHN and a more complicated WideResNet-50 for
ImageNet to CIFAR-10. The CNN model consists of four convolutional layer with 3×3 kernels and
32,32,64,64 channels respectively, followed by two hidden layer with size 256. A 2×2 max pooling
is calculated after the second and fourth layer. Other settings are the same as in the main text. Note
that in some settings the new model cannot converge, and therefore we will omit the result. In
addition, Jacobian regularization cannot be applied on WideResNet-50 because of the large memory
cost, so we do not include it in the ﬁgures. The results are shown in Figure 11, 12 and 13."
N,0.8540772532188842,Under review as a conference paper at ICLR 2022
N,0.8551502145922747,"0
10
20
Robust Acc (%) 80 90"
N,0.8562231759656652,Domain Transfer Acc (%)
N,0.8572961373390557,R: -0.981
N,0.8583690987124464,ImageNet -> CIFAR10
N,0.8594420600858369,Rescale(m)
N,0.8605150214592274,"1
2
4
8"
N,0.8615879828326181,"15
20
Robust Acc (%) 75 80"
N,0.8626609442060086,R: -0.557
N,0.8637339055793991,ImageNet -> CIFAR10
N,0.8648068669527897,Blur(k)
N,0.8658798283261803,"1
5
11"
N,0.8669527896995708,"Figure 10: Robustness and absolute transferability when we use rescale and blur as data augmenta-
tions with different parameters."
N,0.8680257510729614,"16
18
20
22
Robust Acc (%) 5 0"
N,0.869098712446352,Relative DT Acc (%)
N,0.8701716738197425,R: -0.468
N,0.871244635193133,CIFAR10 -> SVHN
N,0.8723175965665236,"LLR(
l)
-0.1
0
0.1"
N,0.8733905579399142,"24
28
32
Robust Acc (%) 5 0"
N,0.8744635193133047,R: -0.890
N,0.8755364806866953,ImageNet -> CIFAR10
N,0.8766094420600858,"LLR(
l)
-0.01
0
0.01
0.1"
N,0.8776824034334764,"15
25
35
Robust Acc (%) 10 5 0 5"
N,0.878755364806867,R: -0.994
N,0.8798283261802575,CIFAR10 -> SVHN
N,0.880901287553648,LLOT(||gs||2)
N,0.8819742489270386,"0.01
0.1
1.0"
N,0.8830472103004292,"25
27
Robust Acc (%) 0 3"
N,0.8841201716738197,R: -0.977
N,0.8851931330472103,ImageNet -> CIFAR10
N,0.8862660944206009,"LLOT(||gs||2) 1
2
5"
N,0.8873390557939914,"Figure 11: Robustness and transferability for the other model structure when we control the norm
of last layer with last-layer regularization (LLR) and last-layer orthogonal training (LLOT) with
different parameters."
N,0.8884120171673819,"D.3
DATA AUGMENTATIONS THAT VIOLATE SUFFICIENT CONDITION"
N,0.8894849785407726,"We study rotation and translation, the two data augmentations that violate the sufﬁcient condition
for regularization. The result is shown in Figure 14. We observe that these augmentations do not
have an obvious impact on domain transferability."
N,0.8905579399141631,"D.4
ROBUSTNESS EVALUATION WITH AUTOATTACK"
N,0.8916309012875536,"Besides PGD attack, we also evaluate the model robustness using the stronger AutoAttack. We
use APGD-CE, APGD-T and FAB-T as the sub-attacks in AutoAttack with 100 steps. Since the
accuracy will decrease after the stronger attack, we use a slightly smaller ϵ = 0.2 to better visualize
the trend. The results are shown in Fig. 15. We can observe that the trend is similar with what we
observed before when we used the PGD attack - domain generalization is an effect of regularization
and data augmentation, and it is sometimes negatively correlated with model robustness. Also,"
N,0.8927038626609443,"20
40
60
Robust Acc (%) 20 10 0"
N,0.8937768240343348,Relative DT Acc (%)
N,0.8948497854077253,R: -0.832
N,0.8959227467811158,CIFAR10 -> SVHN
N,0.8969957081545065,"JR(
j)
0
10
100
1000"
N,0.898068669527897,"10
20
Robust Acc (%) 0 10 20 30"
N,0.8991416309012875,R: -0.607
N,0.9002145922746781,CIFAR10 -> SVHN
N,0.9012875536480687,"WD(
w)
0.0005
0.001
0.005
0.01"
N,0.9023605150214592,"10
15
20
25
Robust Acc (%) 0 5 10"
N,0.9034334763948498,R: -0.941
N,0.9045064377682404,ImageNet -> CIFAR10
N,0.9055793991416309,"WD(
w)
0.0001
0.0005
0.001"
N,0.9066523605150214,"Figure 12: Robustness and transferability for the other model structure when we regularize the fea-
ture extractor with Jacobian Regularization (JR) and weight decay (WD) with different parameters."
N,0.907725321888412,Under review as a conference paper at ICLR 2022
N,0.9087982832618026,"20
30
40
50
Robust Acc (%) 0 5 10 15"
N,0.9098712446351931,Relative DT Acc (%)
N,0.9109442060085837,R: 0.358
N,0.9120171673819742,CIFAR10 -> SVHN
N,0.9130901287553648,Gauss( )
N,0.9141630901287554,"0
0.05
0.25
1.0"
N,0.9152360515021459,"20
30
40
Robust Acc (%) 0 20 40 60"
N,0.9163090128755365,R: -0.505
N,0.9173819742489271,ImageNet -> CIFAR10
N,0.9184549356223176,Gauss( )
N,0.9195278969957081,"0
0.05
0.25"
N,0.9206008583690987,"20
30
40
Robust Acc (%) 5 0 5"
N,0.9216738197424893,R: 0.776
N,0.9227467811158798,CIFAR10 -> SVHN
N,0.9238197424892703,"Pos(b) 1
4
8"
N,0.924892703862661,"20
30
40
Robust Acc (%) 0 2 4"
N,0.9259656652360515,R: 0.472
N,0.927038626609442,ImageNet -> CIFAR10
N,0.9281115879828327,"Pos(b) 1
4
8"
N,0.9291845493562232,"Figure 13: Robustness and transferability for the other model structure when we use Gaussian noise
(Gauss) and posterize (Pos) as data augmentations with different parameters."
N,0.9302575107296137,"20
25
Robust Acc (%) 0 5"
N,0.9313304721030042,Relative DT Acc (%)
N,0.9324034334763949,R: 0.012
N,0.9334763948497854,CIFAR10 -> SVHN
N,0.9345493562231759,Rotate( )
N,0.9356223175965666,"0
15
45"
N,0.9366952789699571,"20
25
Robust Acc (%) 0 5"
N,0.9377682403433476,R: 0.978
N,0.9388412017167382,ImageNet -> CIFAR10
N,0.9399141630901288,Rotate( )
N,0.9409871244635193,"0
15
45"
N,0.9420600858369099,"10
15
20
Robust Acc (%) 6 3 0"
N,0.9431330472103004,R: 0.716
N,0.944206008583691,CIFAR10 -> SVHN
N,0.9452789699570815,Translate(d)
N,0.9463519313304721,"0
0.05
0.1
0.25"
N,0.9474248927038627,"17
20
23
Robust Acc (%) 3 0 3"
N,0.9484978540772532,R: 0.238
N,0.9495708154506438,ImageNet -> CIFAR10
N,0.9506437768240343,Translate(d)
N,0.9517167381974249,"0
0.05
0.1
0.25"
N,0.9527896995708155,"Figure 14: Relationship between robustness and transferability when we use rotation and translation
as data augmentations."
N,0.953862660944206,"augmentations like rotation and translation, which violates the sufﬁcient condition, do not improve
the domain generalization."
N,0.9549356223175965,Under review as a conference paper at ICLR 2022
N,0.9560085836909872,"10
15
20
Robust Acc (%) 10 5 0 5"
N,0.9570815450643777,Relative DT Acc (%)
N,0.9581545064377682,R: -0.846
N,0.9592274678111588,CIFAR10 -> SVHN
N,0.9603004291845494,"LLR(
l)
-0.1
0
0.1
1.0"
N,0.9613733905579399,"10
15
20
Robust Acc (%) 10 5 0"
N,0.9624463519313304,R: -0.947
N,0.9635193133047211,CIFAR10 -> SVHN
N,0.9645922746781116,LLOT(||gs||2)
N,0.9656652360515021,"0.01
0.1
1.0
10.0"
N,0.9667381974248928,20 30 40 50 60 70
N,0.9678111587982833,Robust Acc (%) 0 5 10 15
N,0.9688841201716738,R: 0.316
N,0.9699570815450643,CIFAR10 -> SVHN
N,0.971030042918455,"JR(
j)
0
100
1000"
N,0.9721030042918455,"5
10
Robust Acc (%) 0 20 40"
N,0.973175965665236,R: -0.724
N,0.9742489270386266,CIFAR10 -> SVHN
N,0.9753218884120172,"WD(
w)
0.0005
0.001
0.005
0.01"
N,0.9763948497854077,20 30 40 50 60 70
N,0.9774678111587983,Robust Acc (%) 0 10 20 30 40
N,0.9785407725321889,Relative DT Acc (%)
N,0.9796137339055794,R: 0.146
N,0.98068669527897,CIFAR10 -> SVHN
N,0.9817596566523605,Gauss( )
N,0.9828326180257511,"0
0.05
0.25
1.0"
N,0.9839055793991416,"20
30
40
50
Robust Acc (%) 0 5 10"
N,0.9849785407725322,R: 0.579
N,0.9860515021459227,CIFAR10 -> SVHN
N,0.9871244635193133,"Pos(b) 1
4
8"
N,0.9881974248927039,"15
20
Robust Acc (%) 0 5"
N,0.9892703862660944,R: 0.439
N,0.990343347639485,CIFAR10 -> SVHN
N,0.9914163090128756,Rotate( )
N,0.9924892703862661,"0
15
45"
N,0.9935622317596566,"8
10
12
Robust Acc (%) 6 3 0"
N,0.9946351931330472,R: 0.680
N,0.9957081545064378,CIFAR10 -> SVHN
N,0.9967811158798283,Translate(d)
N,0.9978540772532188,"0
0.05
0.1
0.25"
N,0.9989270386266095,"Figure 15: Relationship between robustness and transferability on CIFAR-10 when we use AutoAt-
tack to evaluate model robustness."
