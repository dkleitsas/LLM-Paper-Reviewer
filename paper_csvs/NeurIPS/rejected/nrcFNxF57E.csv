Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.00044365572315882877,"The Gromov-Wasserstein (GW) distance has gained increasing interest in the
1"
ABSTRACT,0.0008873114463176575,"machine learning community in recent years, as it allows for the comparison
2"
ABSTRACT,0.0013309671694764862,"of measures in different metric spaces. To overcome the limitations imposed
3"
ABSTRACT,0.001774622892635315,"by the equal mass requirements of the classical GW problem, researchers have
4"
ABSTRACT,0.0022182786157941437,"begun exploring its application in unbalanced settings. However, Unbalanced GW
5"
ABSTRACT,0.0026619343389529724,"(UGW) can only be regarded as a discrepancy rather than a rigorous metric/distance
6"
ABSTRACT,0.003105590062111801,"between two metric measure spaces (mm-spaces). In this paper, we propose a
7"
ABSTRACT,0.00354924578527063,"particular case of the UGW problem, termed Partial Gromov-Wasserstein (PGW).
8"
ABSTRACT,0.003992901508429458,"We establish that PGW is a well-defined metric between mm-spaces and discuss its
9"
ABSTRACT,0.0044365572315882874,"theoretical properties, including the existence of a minimizer for the PGW problem
10"
ABSTRACT,0.0048802129547471165,"and the relationship between PGW and GW, among others. We then propose two
11"
ABSTRACT,0.005323868677905945,"variants of the Frank-Wolfe algorithm for solving the PGW problem and show
12"
ABSTRACT,0.005767524401064774,"that they are mathematically and computationally equivalent. Moreover, based
13"
ABSTRACT,0.006211180124223602,"on our PGW metric, we introduce the analogous concept of barycenters for mm-
14"
ABSTRACT,0.006654835847382431,"spaces. Finally, we validate the effectiveness of our PGW metric and related solvers
15"
ABSTRACT,0.00709849157054126,"in applications such as shape matching, shape retrieval, and shape interpolation,
16"
ABSTRACT,0.0075421472937000885,"comparing them against existing baselines.
17"
INTRODUCTION,0.007985803016858917,"1
Introduction
18"
INTRODUCTION,0.008429458740017746,"The classical optimal transport (OT) problem [1] seeks to match two probability measures while
19"
INTRODUCTION,0.008873114463176575,"minimizing the expected transportation cost. At the heart of classical OT theory lies the principle of
20"
INTRODUCTION,0.009316770186335404,"mass conservation, which aims to optimize the transfer between two probability measures, assuming
21"
INTRODUCTION,0.009760425909494233,"they have the same total mass and strictly preserving it. Statistical distances that arise from OT,
22"
INTRODUCTION,0.01020408163265306,"such as Wasserstein distances, have been widely applied across various machine learning domains,
23"
INTRODUCTION,0.01064773735581189,"ranging from generative modeling [2, 3] to domain adaptation [4] and representation learning [5].
24"
INTRODUCTION,0.011091393078970719,"Recent advancements have extended the OT problem to address certain limitations within machine
25"
INTRODUCTION,0.011535048802129548,"learning applications. These advancements include: 1) facilitating the comparison of non-negative
26"
INTRODUCTION,0.011978704525288377,"measures that possess different total masses via unbalanced [6] and partial OT [7], and 2) enabling
27"
INTRODUCTION,0.012422360248447204,"the comparison of probability measures across distinct metric spaces through Gromov-Wasserstein
28"
INTRODUCTION,0.012866015971606033,"distances [8], with applications spanning from quantum chemistry [9] to natural language processing
29"
INTRODUCTION,0.013309671694764862,"[10].
30"
INTRODUCTION,0.013753327417923691,"Regarding the first aspect, many applications in machine learning involve comparing non-negative
31"
INTRODUCTION,0.01419698314108252,"measures (often empirical measures) with varying total amounts of mass, e.g., domain adaptation
32"
INTRODUCTION,0.014640638864241348,"[11]. Moreover, OT distances (or dissimilarity measures) are often not robust against outliers and
33"
INTRODUCTION,0.015084294587400177,"noise, resulting in potentially high transportation costs for outliers. Many recent publications have
34"
INTRODUCTION,0.015527950310559006,"focused on variants of the OT problem that allow for comparing non-negative measures with unequal
35"
INTRODUCTION,0.015971606033717833,"mass. For instance, the optimal partial transport problem [7, 12, 13, 14], Kantorovich–Rubinstein
36"
INTRODUCTION,0.016415261756876662,"norm [15, 16, 17], and the Hellinger–Kantorovich distance [18, 19]. These methods fall under the
37"
INTRODUCTION,0.01685891748003549,"broad category of “unbalanced optimal transport”. In this regard, we also highlight [20, 21, 22],
38"
INTRODUCTION,0.01730257320319432,"which enhance OT’s robustness in the presence of outliers.
39"
INTRODUCTION,0.01774622892635315,"Regarding the second aspect, comparing probability measures across different metric spaces is
40"
INTRODUCTION,0.01818988464951198,"essential in many machine learning applications, ranging from computer graphics, where shapes and
41"
INTRODUCTION,0.018633540372670808,"surfaces are compared [23, 24], to graph partitioning and matching problems [25]. Source and target
42"
INTRODUCTION,0.019077196095829637,"distributions often arise from varied conditions, such as different times, contexts, or measurement
43"
INTRODUCTION,0.019520851818988466,"techniques, creating substantial differences in intrinsic distances among data points. The conventional
44"
INTRODUCTION,0.019964507542147295,"OT framework necessitates a meaningful distance across diverse domains, a requirement that is not
45"
INTRODUCTION,0.02040816326530612,"always achievable. To circumvent this issue, the Gromov-Wasserstein (GW) distances were proposed
46"
INTRODUCTION,0.02085181898846495,"in [8, 24] as an adaptation of the Gromov-Hausdorff distance, which measures the discrepancy
47"
INTRODUCTION,0.02129547471162378,"between two metric spaces [26, 27, 28, 29]. The GW distance [8, 30] extends OT-based distances to
48"
INTRODUCTION,0.021739130434782608,"metric measure spaces (mm-spaces) up to isometries. Its invariance across isomorphic mm-spaces
49"
INTRODUCTION,0.022182786157941437,"makes the GW distance particularly valuable for applications like shape comparison and matching,
50"
INTRODUCTION,0.022626441881100266,"where invariance to rigid motion transformations is crucial.
51"
INTRODUCTION,0.023070097604259095,"The main computational challenge of the GW metric is the non-convexity of its formulation [8]. The
52"
INTRODUCTION,0.023513753327417924,"conventional computational approach relies on the Frank-Wolfe (FW) algorithm [31, 32]. Optimal
53"
INTRODUCTION,0.023957409050576754,"transport (OT) computational methods [15, 33, 34, 35, 36, 37, 38, 39, 40], such as the Sinkhorn
54"
INTRODUCTION,0.024401064773735583,"algorithm, can be incorporated into FW iterations, which yields the classical GW solvers [41, 42, 43].
55"
INTRODUCTION,0.024844720496894408,"Given that the GW distance is limited to the comparison of probability mm-spaces, recent works
56"
INTRODUCTION,0.025288376220053237,"have introduced unbalanced and partial variations [44, 45, 46]. These variations have been applied in
57"
INTRODUCTION,0.025732031943212066,"diverse contexts, including partial graph matching for social network analysis [47] and the alignment
58"
INTRODUCTION,0.026175687666370896,"of brain images [48]. Although solving these unbalanced variants of the GW problem yields notions
59"
INTRODUCTION,0.026619343389529725,"of discrepancies between mm-spaces, their metric properties remain unclear in the literature.
60"
INTRODUCTION,0.027062999112688554,"Motivated by the emerging applications of the GW problem in unbalanced settings, this paper focuses
61"
INTRODUCTION,0.027506654835847383,"on developing a metric between general (not necessarily probability) mm-spaces and providing
62"
INTRODUCTION,0.027950310559006212,"efficient solvers for its computation. Our proposed metric arises from formulating a variant of the GW
63"
INTRODUCTION,0.02839396628216504,"problem for unbalanced contexts, rooted in the framework provided by [44], which we named the
64"
INTRODUCTION,0.02883762200532387,"Partial Gromov-Wasserstein (PGW) problem. In contrast to [44], which introduces a KL-divergence
65"
INTRODUCTION,0.029281277728482696,"penalty and a Sinkhorn solver, we employ a total variation penalty, demonstrate the resulting metric
66"
INTRODUCTION,0.029724933451641525,"properties, and provide novel, efficient solvers for this problem. To the best of our knowledge, this
67"
INTRODUCTION,0.030168589174800354,"paper presents the first metric for non-probability mm-spaces based on the GW distance.
68"
INTRODUCTION,0.030612244897959183,"Contributions. Our specific contributions in this paper are:
69"
INTRODUCTION,0.031055900621118012,"• GW metric in unbalanced settings. We propose the Partial Gromov-Wasserstein (PGW)
70"
INTRODUCTION,0.03149955634427684,"problem and prove that it gives rise to a metric between arbitrary mm-spaces.
71"
INTRODUCTION,0.03194321206743567,"• PGW solver.Analogous to the technique presented in [12], we show that the PGW problem
72"
INTRODUCTION,0.0323868677905945,"can be turned into a variant of the GW problem. Based on this relation, we propose two
73"
INTRODUCTION,0.032830523513753325,"mathematically equivalent, but distinct in numerical implementation, Frank-Wolfe solvers
74"
INTRODUCTION,0.03327417923691216,"for the discrete PGW problem. Inspired by the results of [32], we prove that similar to the
75"
INTRODUCTION,0.03371783496007098,"Frank-Wolfe solver presented in [45], our proposed solvers for the PGW problem converge
76"
INTRODUCTION,0.034161490683229816,"linearly to a stationary point.
77"
INTRODUCTION,0.03460514640638864,"• Numerical experiments. We demonstrate the performance of our proposed algorithms in
78"
INTRODUCTION,0.035048802129547474,"terms of computation time and efficacy on a series of tasks: shape-matching with outliers
79"
INTRODUCTION,0.0354924578527063,"between 2D and 3D objects, shape retrieval between 2D shapes, and shape interpolation
80"
INTRODUCTION,0.03593611357586513,"using the concept of PGW barycenters. We compare the performance of our proposed
81"
INTRODUCTION,0.03637976929902396,"algorithms against existing baselines for each task.
82"
BACKGROUND,0.03682342502218278,"2
Background
83"
BACKGROUND,0.037267080745341616,"In this section, we review the basics of OT theory, one of its variants in unbalanced contexts called
84"
BACKGROUND,0.03771073646850044,"Partial OT (POT), and their connection as established in [12]. We then introduce the GW distance.
85"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.038154392191659274,"2.1
Optimal Transport and Partial Optimal Transport
86"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.0385980479148181,"Let Ω⊆Rd be, for simplicity, a compact subset of Rd, and P(Ω) be the space of probability measures
87"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.03904170363797693,"defined on the Borel σ-algebra of Ω.
88"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.03948535936113576,"The Optimal Transport (OT) problem for µ, ν ∈P(Ω), with transportation cost c(x, y) : Ω×Ω→
89"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.03992901508429459,"R+ being a lower-semi continuous function, is defined as:
90"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.040372670807453416,"OT(µ, ν) :=
min
γ∈Γ(µ,ν) γ(c),
where
γ(c) :=
Z"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.04081632653061224,"Ω2 c(x, y) dγ(x, y)
(1)"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.041259982253771074,"and where Γ(µ, ν) denotes the set of all joint probability measures on Ω2 := Ω× Ωwith marginals
91"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.0417036379769299,"µ, ν, i.e., γ1 := π1#γ = µ, γ2 := π2#γ = ν, where π1, π2 : Ω2 →Ωare the canonical projections
92"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.04214729370008873,"π1(x, y) := x, π2(x, y) := y. A minimizer for (1) always exists [1, 49] and when c(x, y) = ∥x−y∥p,
93"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.04259094942324756,"for p ≥1, it defines a metric on P(Ω), which is referred to as the “p-Wasserstein distance”:
94"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.04303460514640639,"W p
p (µ, ν) :=
min
γ∈Γ(µ,ν) Z"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.043478260869565216,"Ω2 ∥x −y∥pdγ(x, y).
(2)"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.04392191659272405,"The Partial Optimal Transport (POT) problem [6, 13, 50] extends the OT problem to the set of
95"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.044365572315882874,"Radon measures M+(Ω), i.e., non-negative and finite measures. For λ > 0 and µ, ν ∈M+(Ω), the
96"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.04480922803904171,"POT problem is defined as:
97"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.04525288376220053,"POT(µ, ν; λ) :=
inf
γ∈M+(Ω2) γ(c) + λ(|µ −γ1| + |ν −γ2|),
(3)"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.04569653948535936,"where, in general, |σ| denotes the total variation norm of a measure σ, i.e., |σ| := σ(Ω). The
constraint γ ∈M+(Ω2) in (3) can be further restricted to γ ∈Γ≤(µ, ν):"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.04614019520851819,"Γ≤(µ, ν) := {γ ∈M+(Ω2) : γ1 ≤µ, γ2 ≤ν},"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.046583850931677016,"denoting γ1 ≤µ if for any Borel set B ⊆Ω, γ1(B) ≤µ(B) (respectively, for γ2 ≤ν) [7]. Roughly
98"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.04702750665483585,"speaking, the linear penalization indicates that if the classical transportation cost exceeds 2λ, it is
99"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.047471162377994675,"better to create/destroy’ mass (see [40] for further details).
100"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.04791481810115351,"The relationship between POT and OT. By using the techniques in [12], the POT problem can be
101"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.04835847382431233,"transferred into an OT problem, and thus, OT solvers (e.g., network simplex) can be employed to
102"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.048802129547471165,"solve the POT problem.
103"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.04924578527062999,"Proposition 2.1. [12, 40] Given µ, ν ∈M+(Ω), construct the following measures on ˆΩ:= Ω∪{ ˆ∞},
104"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.049689440993788817,"for an auxiliary point ˆ∞:
105"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.05013309671694765,"ˆµ = µ + |ν|δ ˆ
∞
and
ˆν = ν + |µ|δ ˆ
∞.
(4)"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.050576752440106475,"Consider the following OT problem
106"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.05102040816326531,"OT(ˆµ, ˆν) =
min
ˆγ∈Γ(ˆµ,ˆν) ˆγ(ˆc),
where
ˆc(x, y) :=
c(x, y) −2λ
if x, y ∈Ω,
0
elsewhere.
(5)"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.05146406388642413,"Then, there exists a bijection F : Γ≤(µ, ν) →Γ(ˆµ, ˆν) given by
107"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.051907719609582965,"F(γ) := γ + (µ −γ1) ⊗δ ˆ
∞+ δ ˆ
∞⊗(ν −γ2) + |γ|δ ˆ
∞, ˆ
∞.
(6)"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.05235137533274179,"such that γ is optimal for the POT problem (3) if and only if F(γ) is optimal for the OT problem (5).
108"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.052795031055900624,"It is worth noting that instead of considering the same underlying space Ωfor both measures µ and ν,
109"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.05323868677905945,"the OT and POT problems can be formulated in the scenario where µ and ν are defined on different
110"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.05368234250221828,"metric spaces X and Y , respectively. In this setting, one needs a cost function c : X × Y →R+ to
111"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.05412599822537711,"formulate the OT and POT problems. However, in practice it is usually difficult to define reasonable
112"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.05456965394853593,"‘distance’ or ground cost c(·, ·) between the two spaces X and Y . In particular, the p-Wasserstein
113"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.055013309671694766,"distance cannot be adopted if µ, ν are defined on different spaces. To relax this requirement, in the
114"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.05545696539485359,"next section, we will review the fundamentals of the Gromov-Wasserstein problem [8].
115"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.055900621118012424,"2.2
The Gromov-Wasserstein (GW) Problem
116"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.05634427684117125,"A metric measure space (mm-space) consists of a set X endowed with a metric structure, that is, a
117"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.05678793256433008,"notion of distance dX between its elements, and equipped with a Borel measure µ. As in [8, Ch.
118"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.05723158828748891,"5], we will assume that X is compact and that supp(µ) = X. Given two probability mm-spaces
119"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.05767524401064774,"X = (X, dX, µ), Y = (Y, dY , ν), with µ ∈P(X) and ν ∈P(Y ), and a non-negative lower
120"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.058118899733806566,"semi-continuous cost function L : R2 →R+ (e.g., the Euclidean distance or the KL-loss), the
121"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.05856255545696539,"Gromov-Wasserstein (GW) matching problem is defined as:
122"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.059006211180124224,"GW L(X, Y) :=
inf
γ∈Γ(µ,ν) γ⊗2(L(dX(·, ·), dY (·, ·))),
(7)"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.05944986690328305,"where, for brevity, we employ the notation γ⊗2 for the product measure dγ⊗2((x, y), (x′, y′)) =
123"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.05989352262644188,"dγ(x, y)dγ(x′, y′). If L(a, b) = |a−b|p, for 1 ≤p < ∞, we denote GW L(·, ·) simply by GW p(·, ·).
124"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.06033717834960071,"In this case, the expression (7) defines an equivalence relation ∼among probability mm-spaces, i.e.,
125"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.06078083407275954,"X ∼Y if and only if GW p(X, Y) = 01. A minimizer of the GW problem (7) always exists, and thus,
126"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.061224489795918366,"we can replace inf by min. Moreover, similar to OT, the above GW problem defines a distance for
127"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.0616681455190772,"probability mm-spaces after taking the quotient under ∼. For details, we refer to [8, Ch. 5 and 10].
128"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.062111801242236024,"3
The Partial Gromov-Wasserstein (PGW) Problem
129"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.06255545696539486,"The Unbalanced Gromov-Wasserstein (UGW) problem for general (compact) mm-spaces X =
130"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.06299911268855368,"(X, dX, µ), Y = (Y, dY , ν), with µ ∈M+(X), ν ∈M+(Y ), studied in [44] is defined as:
131"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.06344276841171251,"UGW L
λ (X, Y) :=
inf
γ∈M+(X×Y ) γ⊗2(L(dX, dY )) + λ(Dϕ(γ⊗2
1
∥µ⊗2) + Dϕ(γ⊗2
2
∥ν⊗2)),
(8)"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.06388642413487133,"where λ > 0 is a fixed linear penalization parameter, and Dϕ is a Csiszár or ϕ-divergence. The above
132"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.06433007985803017,"formulation extends the classical GW problem (7) into the unbalanced setting (µ and ν are no longer
133"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.064773735581189,"necessarily probability measures but general Radon measures).
134"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.06521739130434782,"We underline two points: First, as discussed in [44], while the above quantity allows us to ‘compare’
135"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.06566104702750665,"the mm-spaces X and Y, its metric property is unclear. Secondly, when Dϕ is the KL divergence, a
136"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.06610470275066549,"Sinkhorn solver has been proposed in [44]. However, a solver for general ϕ-divergences has not yet
137"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.06654835847382432,"been proposed.
138"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.06699201419698314,"In this paper, we will analyze the case when Dϕ is the total variation norm. Specifically, for q ≥1,
139"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.06743566992014197,"we consider the following problem, which we refer to as the Partial Gromov-Wasserstein (PGW)
140"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.06787932564330079,"problem:
141"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.06832298136645963,"PGW L
λ,q(X, Y) :=
inf
γ∈M+(X×Y ) γ⊗2(L(dq
X, dq
Y )) + λ(|µ⊗2 −γ⊗2
1 | + |ν⊗2 −γ⊗2
2 |).
(9)"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.06876663708961846,"Remark 3.1. Given γ ∈Γ ≤(µ, ν), the above cost functional can be rewritten as
142"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.06921029281277728,"γ⊗2(L(dq
X, dq
Y )) + λ(|µ⊗2 −γ⊗2
1 | + |ν⊗2 −γ⊗2
2 |) = γ⊗2 (L(dq
X, dq
Y ) −2λ) + λ
 
|µ|2 + |ν|2"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.06965394853593611,"|
{z
}
does not depend on γ ."
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.07009760425909495,"Proposition 3.2. Given mm-spaces X = (X, dX, µ), Y = (Y, dY , ν), the minimization problem (9)
143"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.07054125998225377,"can be restricted to the set Γ≤(µ, ν) = {γ ∈M+(X × Y ) : γ1 ≤µ, γ2 ≤ν}. That is,
144"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.0709849157054126,"PGW L
λ,q(X, Y) =
inf
γ∈Γ≤(µ,ν) γ⊗2 (L(dq
X, dq
Y ) −2λ) + λ(|µ|2 + |ν|2).
(10)"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.07142857142857142,"For the proof, inspired by [50], we direct the reader to Appendix B.
145"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.07187222715173026,"We notice that a similar Partial Gromov-Wasserstein problem (and its solver) has been studied [45].
146"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.07231588287488909,"Indeed, in [45], the λ-penalization in the optimization problem (10) is avoided, but the constraint set
147"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.07275953859804792,"is replaced by the subset of all γ ∈Γ≤(µ, ν) such that |γ| = ρ for a fixed ρ ∈[0, min{|µ|, |ν|}]. We
148"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.07320319432120674,"will call this formulation the Mass-Constrained Partial Gromov-Wasserstein (MPGW) problem. In
149"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.07364685004436557,"Appendix L, we explore the relations between PGW and MPGW, and in Section 5 and Appendices N,
150"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.0740905057675244,"O, P, we analyze the performance of the different solvers through different experiments.
151"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.07453416149068323,"Proposition 3.3. If L(r1, r2) = |r1 −r2|p, for p ∈[1, ∞), we use PGW p
λ,q to denote PGW L
λ,q. In
152"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.07497781721384206,"this case, (9) and (10) admit a minimizer.
153"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.07542147293700088,"The proof is given in Appendix C: Its idea extends results from [8] from probability mm-spaces to
154"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.07586512866015972,"arbitrary mm-spaces.
155"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.07630878438331855,"Next, we state one of our main results: The PGW problem gives rise to a metric between mm-spaces.
156"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.07675244010647737,"The rigorous statement as well as its proof is given in Appendix D.
157"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.0771960958296362,"Proposition 3.4. Let λ > 0, 1 ≤q, p < ∞and L(r1, r2) = |r1 −r2|p. Then (PGW p
λ,q(·, ·))1/p
158"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.07763975155279502,"defines a metric between mm-spaces.
159"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.07808340727595386,"Finally, for consistency, we provide the following result when the penalization tends to infinity. Its
160"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.07852706299911269,"proof is given in Appendix E.
161"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.07897071872227152,"Proposition 3.5. Consider probability mm-spaces X = (X, dX, µ), Y = (Y, dY , ν), that is, |µ| =
162"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.07941437444543034,"|ν| = 1. Assume that L is a continuous funtion. Then limλ→∞PGW L
λ,1(X, Y) = GW L(X, Y).
163"
OPTIMAL TRANSPORT AND PARTIAL OPTIMAL TRANSPORT,0.07985803016858918,"1Moreover, given two probability mm-spaces X and Y, GW(X, Y) = 0 if and only if there exists a bijective
isometry ϕ : X →Y such that ϕ#µ = ν. In particular, the GW distance is invariant under rigid transformations
(translations and rotations) of a given probability mm-space."
COMPUTATION OF THE PARTIAL GW DISTANCE,0.080301685891748,"4
Computation of the Partial GW Distance
164"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.08074534161490683,"In the discrete setting, consider mm-spaces X = (X, dX, Pn
i=1 pX
i δxi), Y = (Y, dY , Pm
j=1 qY
j δyj),
165"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.08118899733806566,"where X = {x1, . . . , xn}, Y = {y1, . . . , ym}, the weights pX
i , qY
j are non-negative numbers, and
166"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.08163265306122448,"the distances dX, dY are determined by the matrices CX ∈Rn×n, CY ∈Rm×m defined by
167"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.08207630878438332,"CX
i,i′ := dq
X(xi, xi′)
∀i, i′ ∈[1 : n]
and
CY
j,j′ := dq
Y (yj, yj′)
∀j, j′ ∈[1 : m].
(11)"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.08251996450754215,"Let p := [qX
1 , . . . , qX
n ]⊤and q := [qY
1 , . . . , qY
m]⊤denote the weight vectors corresponding to the
168"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.08296362023070097,"given discrete measures. We view the sets of transportation plans Γ(p, q) and Γ≤(p, q) for the GW
169"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.0834072759538598,"and PGW problems, respectively, as the subsets of n × m matrices
170"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.08385093167701864,"Γ(p, q) := {γ ∈Rn×m
+
: γ1m = p, γ⊤1n = q},
if |p| = n
X"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.08429458740017746,"i=1
pX
i = 1 = m
X"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.08473824312333629,"j=1
qY
j = |q|;
(12) 171"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.08518189884649512,"Γ≤(p, q) := {γ ∈Rn×m
+
: γ1m ≤p, γ⊤1n ≤q},
(13)
for any pair of non-negative vectors p ∈Rn
+, q ∈Rm
+, where 1n is the vector with all ones in Rn
172"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.08562555456965394,"(resp. 1m), and γ1m ≤p means that component-wise the ≤relation holds.
173"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.08606921029281278,"Given by a non-negative function L : Rn×n × Rm×m →R+, he transportation cost M and the
174"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.0865128660159716,"‘partial’ transportation con ˜
M are represented by the n × m × n × m tensors:
175"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.08695652173913043,"Mi,j,i′,j′ = L(CX
i,i′, CY
j,j′)
and
˜
M := M −2λ := M −2λ1n,m,n,m,
(14)"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.08740017746228926,"where 1n,m,n,m is the tensor with ones in all its entries. For each n × m × n × m tensor M and each
n × m matrix γ, we define tensor-matrix multiplication M ◦γ ∈Rn×m by"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.0878438331854481,"(M ◦γ)ij =
X"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.08828748890860692,"i′,j′
(Mi,j,i′,j′)γi′,j′."
COMPUTATION OF THE PARTIAL GW DISTANCE,0.08873114463176575,"Then, the Partial GW problem in (10) can be written as
176"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.08917480035492457,"PGW L
λ (X, Y) =
min
γ∈Γ≤(p,q) L ˜
M(γ) + λ(|p|2 + |q|2),
where
(15) 177"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.08961845607808341,"L ˜
M(γ) := ˜
Mγ⊗2 :=
X"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09006211180124224,"i,j,i′,j′
˜
Mi,j,i′,j′γi,jγi′,j′ =
X"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09050576752440107,"ij
( ˜
M ◦γ)ijγij =: ⟨˜
M ◦γ, γ⟩F ,
(16)"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09094942324755989,"and ⟨·, ·⟩F stands for the Frobenius dot product. The constant term λ(|p|2 + |q|2) will be ignored in
178"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09139307897071872,"the rest of this paper since it does not depend on γ.
179"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09183673469387756,"4.1
Frank-Wolfe for the PGW Problem – Solver 1
180"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09228039041703638,"In this section, we discuss the Frank-Wolfe (FW) algorithm for the PGW problem (15). A second
181"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09272404614019521,"variant of the FW solver is provided in the Appendix G.
182"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09316770186335403,"As a summary, in our proposed method, we address the discrete PGW problem (15), highlighting
183"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09361135758651287,"that the direction-finding subproblem in the Frank-Wolfe (FW) algorithm is a POT problem for (15).
184"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.0940550133096717,"Specifically, (15) is treated as a discrete POT problem in our Solver 1, where we apply Proposition
185"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09449866903283052,"2.1 to solve a discrete OT problem.
186"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09494232475598935,"For each iteration k, the procedure is summarized in three steps detailed below.
187"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09538598047914817,"The convergence analysis, detailed in Appendix K, applies the results from [32] to our context,
188"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09582963620230701,"showing that the FW algorithm achieves a stationary point at a rate of O(1/
√"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09627329192546584,"k) for non-convex
189"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09671694764862467,"objectives with a Lipschitz continuous gradient in a convex and compact domain.
190"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09716060337178349,"Step 1. Computation of gradient and optimal direction.
191"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09760425909494233,"It is straightforward to verify that the gradient of the objective function (16) in (15) is given by
192"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09804791481810116,"∇L ˜
M(γ) = 2 ˜
M ◦γ.
(17)"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09849157054125998,"The classical method to compute M ◦γ is the following: First, convert M into an (n × m) × (n × m)
193"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09893522626441881,"matrix, denoted as v(M), and convert γ into an (n × m) × 1 vector v(γ). Then, the computation
194"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09937888198757763,"of M ◦γ is equivalent to the matrix multiplication v(M)v(γ). The computational cost and the
195"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.09982253771073647,"Algorithm 1: Frank-Wolfe Algorithm for PGW, ver 1"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.1002661934338953,"Input: µ = Pn
i=1 pX
i δxi, ν = Pm
j=1 qY
j δyj, γ(1)"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.10070984915705412,"Output: γ(final)
Compute CX, CY
for k = 1, 2, . . . do"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.10115350488021295,"G(k) ←2 ˜
M ◦γ(k) // Compute gradient
γ(k)′ ←arg minγ∈Γ≤(p,q)⟨G(k), γ⟩F // Solve the POT problem.
Compute α(k) ∈[0, 1] via (18) // Line search
γ(k+1) ←(1 −α(k))γ(k) + α(k)γ(k)′// Update γ
if convergence, break
end for
γ(final) ←γ(k)"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.10159716060337179,"required storage space are O(n2m2). In certain conditions, the above computation can be reduced to
196"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.10204081632653061,"O(n2 + m2). We refer to Appendices F and H for details.
197"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.10248447204968944,"Next, we aim to solve the following problem:
198"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.10292812777284827,"γ(k)′ ←arg
min
γ∈Γ≤(p,q)⟨∇L ˜
M(γ(k)), γ⟩F ,"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.1033717834960071,which is a discrete POT problem since it is equivalent to
COMPUTATION OF THE PARTIAL GW DISTANCE,0.10381543921916593,"min
γ∈Γ≤(p,q)⟨2M ◦γ(k), γ⟩F + λ|γ(k)|(|p| + |q| −2|γ|)."
COMPUTATION OF THE PARTIAL GW DISTANCE,0.10425909494232476,"The solver can be obtained by firstly converting the POT problem into an OT problem via Proposition
199"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.10470275066548358,"2.1 and then solving the proposed OT problem.
200"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.10514640638864241,"Step 2: Line search method.
201"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.10559006211180125,"In this step, at the k-th iteration, we need to determine the optimal step size:"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.10603371783496007,"α(k) = arg min
α∈[0,1]{L ˜
M((1 −α)γ(k) + αγ(k)′)}."
COMPUTATION OF THE PARTIAL GW DISTANCE,0.1064773735581189,"The optimal α(k) takes the following values (see Appendix I for details):
202"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.10692102928127772,"Let α(k) = 
 "
COMPUTATION OF THE PARTIAL GW DISTANCE,0.10736468500443656,"0
if a ≤0, a + b > 0,
1
if a ≤0, a + b ≤0,
clip( −b"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.10780834072759539,"2a , [0, 1])
if a > 0,
where 
 "
COMPUTATION OF THE PARTIAL GW DISTANCE,0.10825199645075421,"δγ(k) = γ(k)′ −γ(k),
a = ⟨˜
M ◦δγ(k), δγ(k)⟩F
b = 2⟨˜
M ◦γ(k), δγ(k)⟩F .
, (18)"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.10869565217391304,and clip( −b
COMPUTATION OF THE PARTIAL GW DISTANCE,0.10913930789707187,"2a , [0, 1]) = min{max{−b"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.1095829636202307,"2a, 0}, 1}.
203"
COMPUTATION OF THE PARTIAL GW DISTANCE,0.11002661934338953,"Step 3: Update γ(k+1) ←(1 −α(k))γ(k) + α(k)γ(k)′.
204"
NUMERICAL IMPLEMENTATION DETAILS,0.11047027506654836,"4.2
Numerical Implementation Details
205"
NUMERICAL IMPLEMENTATION DETAILS,0.11091393078970718,"The initial guess, γ(1). In the GW problem, the initial guess is simply set to γ(1) = pq⊤if there
206"
NUMERICAL IMPLEMENTATION DETAILS,0.11135758651286602,"is no prior knowledge. In PGW, however, as µ, ν may not necessarily be probability measures
207"
NUMERICAL IMPLEMENTATION DETAILS,0.11180124223602485,"(i.e., P
i pX
i , P
j qY
j ̸= 1 in general), we set γ(1) =
pq⊤"
NUMERICAL IMPLEMENTATION DETAILS,0.11224489795918367,"max(|p|,|q|). It is straightforward to verify that
208"
NUMERICAL IMPLEMENTATION DETAILS,0.1126885536823425,"γ(1) ∈Γ≤(p, q) as
209"
NUMERICAL IMPLEMENTATION DETAILS,0.11313220940550132,"γ(1)1m =
|q|p
max(|p|, |q|) ≤p, γ(1)⊤1n =
|p|q
max(|p|, |q|) ≤q."
NUMERICAL IMPLEMENTATION DETAILS,0.11357586512866016,"Column/Row-Reduction. According to the interpretation of the penalty weight parameter in the
210"
NUMERICAL IMPLEMENTATION DETAILS,0.11401952085181899,"Partial OT problem (e.g. see Lemma 3.2 in [40]), during the POT solving step, for each i ∈[1 : n]
211"
NUMERICAL IMPLEMENTATION DETAILS,0.11446317657497782,"(or j ∈[1 : m]), if the ith row (jth column) of ˜
M ◦γ(k) contains a non-negative entry, all the mass
212"
NUMERICAL IMPLEMENTATION DETAILS,0.11490683229813664,"of pX
i (qY
j ) will be destroyed (created). Thus, we can remove the corresponding row (column) to
213"
NUMERICAL IMPLEMENTATION DETAILS,0.11535048802129548,"improve the computational efficiency.
214"
EXPERIMENTS,0.1157941437444543,"5
Experiments
215"
EXPERIMENTS,0.11623779946761313,"In addition to the three experiments detailed here, we also perform a wall-clock time comparison
216"
EXPERIMENTS,0.11668145519077196,"of our proposed PGW solvers in Appendix O and a positive-unlabeled (PU) learning experiment in
217"
EXPERIMENTS,0.11712511091393078,"Appendix P.
218"
EXPERIMENTS,0.11756876663708962,"5.1
Toy Example: Shape Matching with Outliers
219"
EXPERIMENTS,0.11801242236024845,"We use the moon dataset and synthetic 2D/3D spherical data in this experiment. Let {xi}n
i=1, {yj}n
j=1
220"
EXPERIMENTS,0.11845607808340727,"denote the source and target point clouds. In addition, we add ηn (where η = 20%) outliers to the
221"
EXPERIMENTS,0.1188997338065661,"target point cloud. See Figure 1 for visualization.
222"
EXPERIMENTS,0.11934338952972494,"We visualize the transportation plans given by the GW [8], MPGW [45], UGW [44], and our proposed
223"
EXPERIMENTS,0.11978704525288376,"PGW problems. For MPGW, UGW, and PGW, we set the mass to be 1 for each point in the source
224"
EXPERIMENTS,0.12023070097604259,"and target point clouds. For GW, we normalize the mass of these points so that the source and target
225"
EXPERIMENTS,0.12067435669920142,"have the same total mass. From Figure 1, we observe that PGW and MPGW induce a one-by-one
226"
EXPERIMENTS,0.12111801242236025,"relation in both cases and no outlier points are matched to the source point cloud. Meanwhile, GW
227"
EXPERIMENTS,0.12156166814551908,"matches all of the outliers. For UGW, as it applies the Sinkhorn algorithm, we observe mass-splitting
228"
EXPERIMENTS,0.1220053238686779,"transportation plans in both cases. Moreover, we observe that some mass from the outliers has been
229"
EXPERIMENTS,0.12244897959183673,"matched, which is not desired.
230"
EXPERIMENTS,0.12289263531499556,"Figure 1: The set of red points comprises the source point cloud. The union of the dark blue (outliers)
and light blue points comprises the target point cloud. For UGW, MPGW, and PGW, we set the mass
for each point to be the same. For GW, we normalize the mass for the balanced mass constraint
setting."
SHAPE RETRIEVAL,0.1233362910381544,"5.2
Shape Retrieval
231"
SHAPE RETRIEVAL,0.12377994676131322,"Experiment setup. We now employ the PGW distance to distinguish between 2D shapes, as done
232"
SHAPE RETRIEVAL,0.12422360248447205,"in [51], and use GW, MPGW, and UGW as baselines for comparison. Given a series of 2D shapes,
233"
SHAPE RETRIEVAL,0.12466725820763087,"we represent the shapes as mm-spaces Xi = (R2, ∥· ∥2, µi), where µi = Pni"
SHAPE RETRIEVAL,0.1251109139307897,"k=1 αiδxi
k. For the GW
234"
SHAPE RETRIEVAL,0.12555456965394854,"method, we normalize the mass for the balanced mass constraint setting (i.e. αi =
1
ni ), and for the
235"
SHAPE RETRIEVAL,0.12599822537710736,"remaining methods we let αi = α for all the shapes, where α > 0 is a fixed constant. In this manner,
236"
SHAPE RETRIEVAL,0.1264418811002662,"we compute the pairwise distances between the shapes.
237"
SHAPE RETRIEVAL,0.12688553682342502,"We then use the computed distances for nearest neighbor classification. We do this by choosing a
238"
SHAPE RETRIEVAL,0.12732919254658384,"representative at random from each class in the dataset and then classifying each shape according to
239"
SHAPE RETRIEVAL,0.12777284826974267,"its nearest representative. This is repeated over 10,000 iterations, and we generate a confusion matrix
240"
SHAPE RETRIEVAL,0.12821650399290152,"for each distance used. Finally, using the approach given by [51, 52], we combine each distance with
241"
SHAPE RETRIEVAL,0.12866015971606035,"a support vector machine (SVM), applying stratified 10-fold cross validation. In each iteration of
242"
SHAPE RETRIEVAL,0.12910381543921917,"cross validation, we train an SVM using exp(−σD) as the kernel, where D is the matrix of pairwise
243"
SHAPE RETRIEVAL,0.129547471162378,"distances (w.r.t. one of the considered distances) restricted to 9 folds, and compute the accuracy of
244"
SHAPE RETRIEVAL,0.12999112688553682,"the model on the remaining fold. We report the accuracy averaged over all 10 folds for each model.
245"
SHAPE RETRIEVAL,0.13043478260869565,"Dataset setup. We test two datasets in this experiment, which we refer to as Dataset I and Dataset II.
246"
SHAPE RETRIEVAL,0.13087843833185447,"We construct Dataset I by adapting the 2D shape dataset given in [51], consisting of 20 shapes in
247"
SHAPE RETRIEVAL,0.1313220940550133,"bone
goblet
star
horseshoe"
SHAPE RETRIEVAL,0.13176574977817213,"rectangle
trapezoid
disk
annulus bone"
SHAPE RETRIEVAL,0.13220940550133098,rectangle
SHAPE RETRIEVAL,0.1326530612244898,goblet
SHAPE RETRIEVAL,0.13309671694764863,trapezoid star disk
SHAPE RETRIEVAL,0.13354037267080746,horseshoe
SHAPE RETRIEVAL,0.13398402839396628,annulus bone
SHAPE RETRIEVAL,0.1344276841171251,rectangle
SHAPE RETRIEVAL,0.13487133984028393,goblet
SHAPE RETRIEVAL,0.13531499556344276,trapezoid star disk
SHAPE RETRIEVAL,0.13575865128660158,horseshoe
SHAPE RETRIEVAL,0.13620230700976044,annulus GW bone
SHAPE RETRIEVAL,0.13664596273291926,rectangle
SHAPE RETRIEVAL,0.1370896184560781,goblet
SHAPE RETRIEVAL,0.13753327417923691,trapezoid star disk
SHAPE RETRIEVAL,0.13797692990239574,horseshoe
SHAPE RETRIEVAL,0.13842058562555457,annulus MPGW bone
SHAPE RETRIEVAL,0.1388642413487134,rectangle
SHAPE RETRIEVAL,0.13930789707187222,goblet
SHAPE RETRIEVAL,0.13975155279503104,trapezoid star disk
SHAPE RETRIEVAL,0.1401952085181899,horseshoe
SHAPE RETRIEVAL,0.14063886424134872,annulus UGW bone
SHAPE RETRIEVAL,0.14108251996450755,rectangle
SHAPE RETRIEVAL,0.14152617568766637,goblet
SHAPE RETRIEVAL,0.1419698314108252,trapezoid star disk
SHAPE RETRIEVAL,0.14241348713398402,horseshoe
SHAPE RETRIEVAL,0.14285714285714285,annulus
SHAPE RETRIEVAL,0.14330079858030167,PGW (ours) 0.0 0.2 0.4 0.6 0.8 1.0
SHAPE RETRIEVAL,0.14374445430346053,"rectangle
arrow
semicircle"
SHAPE RETRIEVAL,0.14418811002661935,"house
double arrow
circle"
SHAPE RETRIEVAL,0.14463176574977818,rectangle house arrow
SHAPE RETRIEVAL,0.145075421472937,double arrow
SHAPE RETRIEVAL,0.14551907719609583,semicircle
SHAPE RETRIEVAL,0.14596273291925466,circle
SHAPE RETRIEVAL,0.14640638864241348,rectangle house arrow
SHAPE RETRIEVAL,0.1468500443655723,double arrow
SHAPE RETRIEVAL,0.14729370008873113,semicircle
SHAPE RETRIEVAL,0.14773735581189,circle GW
SHAPE RETRIEVAL,0.1481810115350488,rectangle house arrow
SHAPE RETRIEVAL,0.14862466725820764,double arrow
SHAPE RETRIEVAL,0.14906832298136646,semicircle
SHAPE RETRIEVAL,0.1495119787045253,circle MPGW
SHAPE RETRIEVAL,0.14995563442768411,rectangle house arrow
SHAPE RETRIEVAL,0.15039929015084294,double arrow
SHAPE RETRIEVAL,0.15084294587400177,semicircle
SHAPE RETRIEVAL,0.1512866015971606,circle UGW
SHAPE RETRIEVAL,0.15173025732031944,rectangle house arrow
SHAPE RETRIEVAL,0.15217391304347827,double arrow
SHAPE RETRIEVAL,0.1526175687666371,semicircle
SHAPE RETRIEVAL,0.15306122448979592,circle
SHAPE RETRIEVAL,0.15350488021295475,PGW (ours) 0.0 0.2 0.4 0.6 0.8 1.0
SHAPE RETRIEVAL,0.15394853593611357,"Figure 2: In each row, the first figure visualizes an example shape from each class, and the second
figure visualizes the resulting pairwise distance matrices. The first row corresponds to Dataset I and
the second corresponds to Dataset II."
SHAPE RETRIEVAL,0.1543921916592724,"each of the classes bone, goblet, star, and horseshoe. For each class, we augment the dataset with an
248"
SHAPE RETRIEVAL,0.15483584738243122,"additional class by selecting either a subset of points from each shape of that class (rectangle/bone,
249"
SHAPE RETRIEVAL,0.15527950310559005,"trapezoid/goblet, disk/star) or adding additional points to each shape of that class (annulus/horseshoe).
250"
SHAPE RETRIEVAL,0.1557231588287489,"Hence, the final dataset consists of 160 shapes across 8 total classes. This dataset is visualized in
251"
SHAPE RETRIEVAL,0.15616681455190773,"Figure 6a.
252"
SHAPE RETRIEVAL,0.15661047027506655,"For Dataset II, we generate 20 shapes for each of the classes rectangle, house, arrow, double arrow,
253"
SHAPE RETRIEVAL,0.15705412599822538,"semicircle, and circle. These shapes were generated in pairs, such that each shape of class rectangle
254"
SHAPE RETRIEVAL,0.1574977817213842,"is a subset of the corresponding shape of class house, and similarly for arrow/double arrow and
255"
SHAPE RETRIEVAL,0.15794143744454303,"semicircle/circle. This dataset is visualized in Figure 6b.
256"
SHAPE RETRIEVAL,0.15838509316770186,"Performance analysis. We refer to Appendix N for full numerical details, parameter settings, and
257"
SHAPE RETRIEVAL,0.15882874889086068,"the visualization of the resulting confusion matrices. We visualize the two considered datasets and
258"
SHAPE RETRIEVAL,0.1592724046140195,"the resulting pairwise distance matrices in Figure 2. For the SVM experiments, GW achieves the
259"
SHAPE RETRIEVAL,0.15971606033717836,"highest accuracy on Dataset I, 98.13%, while the second best method is PGW, 96.25%. For Dataset
260"
SHAPE RETRIEVAL,0.1601597160603372,"II, PGW achieves the highest accuracy, correctly classifying 100% of the samples. The complete set
261"
SHAPE RETRIEVAL,0.160603371783496,"of accuracies for all considered distances on each dataset is reported in Table 1a.
262"
SHAPE RETRIEVAL,0.16104702750665484,"In addition, we report the wall-clock time required to compute all pairwise distances for each distance
263"
SHAPE RETRIEVAL,0.16149068322981366,"in Table 1b. We observe that GW, MPGW, and PGW have similar wall-clock times across both
264"
SHAPE RETRIEVAL,0.1619343389529725,"experiments (30-50 seconds for Dataset I, 80-140 seconds for Dataset II), with PGW admitting
265"
SHAPE RETRIEVAL,0.16237799467613132,"a slightly faster runtime in both cases. Meanwhile, UGW requires almost 1500 seconds on the
266"
SHAPE RETRIEVAL,0.16282165039929014,"experiment with Dataset I and over 500 seconds on the experiment with Dataset II.
267"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.16326530612244897,"5.3
Partial Gromov-Wasserstein Barycenter and Shape Interpolation
268"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.16370896184560782,"By [41], Gromov-Wasserstein can be applied to interpolate two shapes via the concept of Gromov-
269"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.16415261756876665,"Wasserstein Barycenters. In this paper, we introduce Partial Gromov-Wasserstein Barycenters by
270"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.16459627329192547,"extending the GW Barycenter to the setting of PGW as follows.
271"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.1650399290150843,"Distance
Dataset I
Dataset II"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.16548358473824312,"GW
0.9813
0.8083
MPGW
0.0813
0.0000
UGW
0.8938
0.7833
PGW (ours)
0.9625
1.0000"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.16592724046140195,"(a) Mean accuracy of SVM using each dis-
tance in kernel."
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.16637089618456077,"Distance
Dataset I
Dataset II"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.1668145519077196,"GW
49.02s
137.12s
MPGW
49.10s
93.90s
UGW
1484.49s
519.91s
PGW (ours)
35.92s
79.27s"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.16725820763087842,(b) Wall-clock time comparison.
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.16770186335403728,"GW,5%
PGW,5%
GW,10% data"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.1681455190771961,"PGW,10%"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.16858917480035493,"t = 0/7
t = 1/7
t = 2/7
t = 3/7
t = 4/7
t = 5/7
t = 6/7
t = 7/7"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.16903283052351376,"Figure 3: In the first column, the first and second figures are the source and target point clouds in the
first experiment (η = 5%); the third and fourth figures are the source and target point clouds in the
second experiment (η = 10%)."
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.16947648624667258,"Consider the discrete mm-spaces X1, . . . , XK, where Xk = (Xk, ∥· ∥Rdk , Pnk
i=1 pk
i δxk
i ), with Xk =
272"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.1699201419698314,"{xk
i }nk
i=1 ⊂Rdk. We denote Ck = [∥xk
i −xk
i′∥2]i,i′ and pk = [pk
1, . . . , pk
nk]. Given positive constants
273"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.17036379769299023,"λ1, . . . , λK > 0, the PGW Barycenter is defined by:
274"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.17080745341614906,"min
C,γk X"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.17125110913930788,"k
ξk⟨M(C, Ck) ◦γk, γk⟩−2λk|γk|2
(19)"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.17169476486246674,"where each γk ∈Γ≤(p, pk). We refer to Appendix M for the solver of (19) and details.
275"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.17213842058562556,"Experiment setup. We apply the PGW barycenter to the following problem: Given two shapes
276"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.1725820763087844,"X = {xi}n
i=1 ⊂Rd1 and Y = {yi}m
i=1 ⊂Rd2, modeled as mm-spaces X = (X, ∥· ∥Rd1, Pn
i=1 δxi)
277"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.1730257320319432,"and Y = (Y, ∥· ∥Rd2, Pm
i=1 δyi), we wish to find interpolations between them. In addition, we
278"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.17346938775510204,"assume Y is corrupted by noise, i.e., Y is redefined as Y = ( ˜Y , ∥· ∥Rd2, Pm
i=1 δyi + Pmη
i=1 δ˜yi)
279"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.17391304347826086,"with ˜Y = Y ∪{˜yi}m
i=1, where η ∈[0, 1] is the noise level and each ˜yi is randomly selected from a
280"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.1743566992014197,"particular region R ⊂Rd2.
281"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.17480035492457852,"Dataset setup. We adapt the dataset given in [41]. See Appendix M.1 for further details on the
282"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.17524401064773737,"dataset. In this experiment, we test η = 5%, 10%. We visualize the barycenter interpolation from
283"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.1756876663708962,"t = 0/7 to t = 7/7, where (1 −t), t are the weight of the source X and the target Y, respectively,
284"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.17613132209405502,"in the barycenter (19). The visualization given in Figure 3 is obtained by applying SMACOF MDS
285"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.17657497781721385,"(multidimensional scaling) of the minimizer C.
286"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.17701863354037267,"Performance analysis. From Figure 3, we observe that in this two scenarios, the interpolation
287"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.1774622892635315,"derived from GW is clearly disturbed by the noise data points. For example, in rows 1, 3, columns
288"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.17790594498669032,"t = 1/7, 2/7, 3/7, we see that the point clouds reconstructed by MDS have significantly different
289"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.17834960070984915,"width-height ratios from those of the source and target point clouds. In contrast, PGW is significantly
290"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.17879325643300797,"less disturbed, and the interpolation is more natural. The width-height ratio of the point clouds
291"
PARTIAL GROMOV-WASSERSTEIN BARYCENTER AND SHAPE INTERPOLATION,0.17923691215616683,"generated by the PGW barycenter is consistent with that of the source/target point clouds.
292"
SUMMARY,0.17968056787932565,"6
Summary
293"
SUMMARY,0.18012422360248448,"In this paper, we propose the Partial Gromov-Wasserstein (PGW) problem and introduce two Frank-
294"
SUMMARY,0.1805678793256433,"Wolfe solvers for it. As a byproduct, we provide pertinent theoretical results, including the relation
295"
SUMMARY,0.18101153504880213,"between PGW and GW, the metric property of PGW, and the PGW barycenter. Furthermore, we
296"
SUMMARY,0.18145519077196096,"demonstrate the efficacy of the PGW solver in solving shape-matching, shape retrieval, and shape
297"
SUMMARY,0.18189884649511978,"interpolation tasks. For the shape retrieval experiment, we observe that due to the metric property,
298"
SUMMARY,0.1823425022182786,"PGW and GW have similar accuracy and outperform the other methods evaluated. In the shape
299"
SUMMARY,0.18278615794143743,"matching and point cloud interpolation experiments, we demonstrate PGW admits a more robust
300"
SUMMARY,0.18322981366459629,"result when the data are corrupted by outliers/noisy data.
301"
REFERENCES,0.1836734693877551,"References
302"
REFERENCES,0.18411712511091394,"[1] Cedric Villani. Optimal transport: old and new. Springer, 2009.
303"
REFERENCES,0.18456078083407276,"[2] Martin Arjovsky, Soumith Chintala, and Léon Bottou. Wasserstein generative adversarial
304"
REFERENCES,0.1850044365572316,"networks. In International conference on machine learning, pages 214–223. PMLR, 2017.
305"
REFERENCES,0.18544809228039041,"[3] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville.
306"
REFERENCES,0.18589174800354924,"Improved training of wasserstein gans. Advances in neural information processing systems, 30,
307"
REFERENCES,0.18633540372670807,"2017.
308"
REFERENCES,0.1867790594498669,"[4] Nicolas Courty, Rémi Flamary, Amaury Habrard, and Alain Rakotomamonjy. Joint distribution
309"
REFERENCES,0.18722271517302574,"optimal transportation for domain adaptation. Advances in neural information processing
310"
REFERENCES,0.18766637089618457,"systems, 30, 2017.
311"
REFERENCES,0.1881100266193434,"[5] Soheil Kolouri, Navid Naderializadeh, Gustavo K Rohde, and Heiko Hoffmann. Wasserstein
312"
REFERENCES,0.18855368234250222,"embedding for graph learning. In International Conference on Learning Representations, 2020.
313"
REFERENCES,0.18899733806566105,"[6] Lenaic Chizat, Gabriel Peyré, Bernhard Schmitzer, and François-Xavier Vialard. Unbalanced
314"
REFERENCES,0.18944099378881987,"optimal transport: Dynamic and Kantorovich formulations. Journal of Functional Analysis,
315"
REFERENCES,0.1898846495119787,"274(11):3090–3123, 2018.
316"
REFERENCES,0.19032830523513752,"[7] Alessio Figalli. The optimal partial transport problem. Archive for rational mechanics and
317"
REFERENCES,0.19077196095829635,"analysis, 195(2):533–560, 2010.
318"
REFERENCES,0.1912156166814552,"[8] Facundo Mémoli. Gromov–wasserstein distances and the metric approach to object matching.
319"
REFERENCES,0.19165927240461403,"Foundations of computational mathematics, 11:417–487, 2011.
320"
REFERENCES,0.19210292812777285,"[9] Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural
321"
REFERENCES,0.19254658385093168,"message passing for quantum chemistry. In International conference on machine learning,
322"
REFERENCES,0.1929902395740905,"pages 1263–1272. PMLR, 2017.
323"
REFERENCES,0.19343389529724933,"[10] David Alvarez-Melis and Tommi Jaakkola. Gromov-wasserstein alignment of word embedding
324"
REFERENCES,0.19387755102040816,"spaces. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language
325"
REFERENCES,0.19432120674356698,"Processing, pages 1881–1890, 2018.
326"
REFERENCES,0.1947648624667258,"[11] Kilian Fatras, Thibault Séjourné, Rémi Flamary, and Nicolas Courty. Unbalanced minibatch
327"
REFERENCES,0.19520851818988466,"optimal transport; applications to domain adaptation. In International Conference on Machine
328"
REFERENCES,0.1956521739130435,"Learning, pages 3186–3197. PMLR, 2021.
329"
REFERENCES,0.1960958296362023,"[12] Luis A Caffarelli and Robert J McCann. Free boundaries in optimal transport and monge-ampere
330"
REFERENCES,0.19653948535936114,"obstacle problems. Annals of mathematics, pages 673–730, 2010.
331"
REFERENCES,0.19698314108251996,"[13] Alessio Figalli and Nicola Gigli. A new transportation distance between non-negative mea-
332"
REFERENCES,0.1974267968056788,"sures, with applications to gradients flows with dirichlet boundary conditions. Journal de
333"
REFERENCES,0.19787045252883761,"mathématiques pures et appliquées, 94(2):107–130, 2010.
334"
REFERENCES,0.19831410825199644,"[14] Anh Duc Nguyen, Tuan Dung Nguyen, Quang Nguyen, Hoang Nguyen, Lam M. Nguyen, and
335"
REFERENCES,0.19875776397515527,"Kim-Chuan Toh. On partial optimal transport: Revised sinkhorn and efficient gradient methods.
336"
REFERENCES,0.19920141969831412,"In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, 2024.
337"
REFERENCES,0.19964507542147295,"[15] Kevin Guittet. Extended Kantorovich norms: a tool for optimization. PhD thesis, INRIA, 2002.
338"
REFERENCES,0.20008873114463177,"[16] Florian Heinemann, Marcel Klatt, and Axel Munk. Kantorovich–rubinstein distance and
339"
REFERENCES,0.2005323868677906,"barycenter for finitely supported measures: Foundations and algorithms. Applied Mathematics
340"
REFERENCES,0.20097604259094942,"& Optimization, 87(1):4, 2023.
341"
REFERENCES,0.20141969831410825,"[17] Jan Lellmann, Dirk A Lorenz, Carola Schonlieb, and Tuomo Valkonen.
Imaging with
342"
REFERENCES,0.20186335403726707,"kantorovich–rubinstein discrepancy. SIAM Journal on Imaging Sciences, 7(4):2833–2859,
343"
REFERENCES,0.2023070097604259,"2014.
344"
REFERENCES,0.20275066548358472,"[18] Lenaic Chizat, Gabriel Peyré, Bernhard Schmitzer, and François-Xavier Vialard. An interpolat-
345"
REFERENCES,0.20319432120674358,"ing distance between optimal transport and Fisher–Rao metrics. Foundations of Computational
346"
REFERENCES,0.2036379769299024,"Mathematics, 18(1):1–44, 2018.
347"
REFERENCES,0.20408163265306123,"[19] Matthias Liero, Alexander Mielke, and Giuseppe Savare. Optimal entropy-transport problems
348"
REFERENCES,0.20452528837622005,"and a new Hellinger–Kantorovich distance between positive measures. Inventiones mathemati-
349"
REFERENCES,0.20496894409937888,"cae, 211(3):969–1117, 2018.
350"
REFERENCES,0.2054125998225377,"[20] Yogesh Balaji, Rama Chellappa, and Soheil Feizi. Robust optimal transport with applications
351"
REFERENCES,0.20585625554569653,"in generative modeling and domain adaptation. Advances in Neural Information Processing
352"
REFERENCES,0.20629991126885536,"Systems, 33:12934–12944, 2020.
353"
REFERENCES,0.2067435669920142,"[21] Quang Minh Nguyen, Hoang H Nguyen, Yi Zhou, and Lam M Nguyen. On unbalanced
354"
REFERENCES,0.20718722271517304,"optimal transport: Gradient methods, sparsity and approximation error. The Journal of Machine
355"
REFERENCES,0.20763087843833186,"Learning Research, 2023.
356"
REFERENCES,0.2080745341614907,"[22] Khang Le, Huy Nguyen, Quang M Nguyen, Tung Pham, Hung Bui, and Nhat Ho. On robust
357"
REFERENCES,0.2085181898846495,"optimal transport: Computational complexity and barycenter computation. Advances in Neural
358"
REFERENCES,0.20896184560780834,"Information Processing Systems, 34:21947–21959, 2021.
359"
REFERENCES,0.20940550133096716,"[23] Alexander M Bronstein, Michael M Bronstein, and Ron Kimmel. Generalized multidimensional
360"
REFERENCES,0.209849157054126,"scaling: a framework for isometry-invariant partial surface matching. Proceedings of the
361"
REFERENCES,0.21029281277728482,"National Academy of Sciences, 103(5):1168–1172, 2006.
362"
REFERENCES,0.21073646850044367,"[24] Facundo Mémoli. Spectral gromov-wasserstein distances for shape matching. In 2009 IEEE 12th
363"
REFERENCES,0.2111801242236025,"International Conference on Computer Vision Workshops, ICCV Workshops, pages 256–263.
364"
REFERENCES,0.21162377994676132,"IEEE, 2009.
365"
REFERENCES,0.21206743566992015,"[25] Hongteng Xu, Dixin Luo, and Lawrence Carin. Scalable gromov-wasserstein learning for graph
366"
REFERENCES,0.21251109139307897,"partitioning and matching. Advances in neural information processing systems, 32, 2019.
367"
REFERENCES,0.2129547471162378,"[26] David A Edwards. The structure of superspace. In Studies in topology, pages 121–133. Elsevier,
368"
REFERENCES,0.21339840283939662,"1975.
369"
REFERENCES,0.21384205856255545,"[27] Mikhael Gromov. Structures métriques pour les variétés riemanniennes. Textes Math., 1, 1981.
370"
REFERENCES,0.21428571428571427,"[28] Michael Gromov. Groups of polynomial growth and expanding maps (with an appendix by
371"
REFERENCES,0.21472937000887313,"jacques tits). Publications Mathématiques de l’IHÉS, 53:53–78, 1981.
372"
REFERENCES,0.21517302573203195,"[29] Dmitri Burago, Yuri Burago, Sergei Ivanov, et al. A course in metric geometry, volume 33.
373"
REFERENCES,0.21561668145519078,"American Mathematical Society Providence, 2001.
374"
REFERENCES,0.2160603371783496,"[30] Karl-Theodor Sturm. The space of spaces: curvature bounds and gradient flows on the space of
375"
REFERENCES,0.21650399290150843,"metric measure spaces, volume 290. American Mathematical Society, 2023.
376"
REFERENCES,0.21694764862466726,"[31] Marguerite Frank, Philip Wolfe, et al. An algorithm for quadratic programming. Naval research
377"
REFERENCES,0.21739130434782608,"logistics quarterly, 3(1-2):95–110, 1956.
378"
REFERENCES,0.2178349600709849,"[32] Simon Lacoste-Julien. Convergence rate of frank-wolfe for non-convex objectives. arXiv
379"
REFERENCES,0.21827861579414373,"preprint arXiv:1607.00345, 2016.
380"
REFERENCES,0.21872227151730259,"[33] Marco Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. Advances in
381"
REFERENCES,0.2191659272404614,"neural information processing systems, 26, 2013.
382"
REFERENCES,0.21960958296362024,"[34] Nicolas Papadakis, Gabriel Peyré, and Edouard Oudet. Optimal transport with proximal splitting.
383"
REFERENCES,0.22005323868677906,"SIAM Journal on Imaging Sciences, 7(1):212–238, 2014.
384"
REFERENCES,0.2204968944099379,"[35] Jean-David Benamou, Brittany D Froese, and Adam M Oberman. Numerical solution of the
385"
REFERENCES,0.2209405501330967,"optimal transportation problem using the monge–ampère equation. Journal of Computational
386"
REFERENCES,0.22138420585625554,"Physics, 260:107–126, 2014.
387"
REFERENCES,0.22182786157941436,"[36] Jean-David Benamou, Guillaume Carlier, Marco Cuturi, Luca Nenna, and Gabriel Peyré. Itera-
388"
REFERENCES,0.2222715173025732,"tive bregman projections for regularized transportation problems. SIAM Journal on Scientific
389"
REFERENCES,0.22271517302573204,"Computing, 37(2):A1111–A1138, 2015.
390"
REFERENCES,0.22315882874889087,"[37] Gabriel Peyré, Marco Cuturi, et al. Computational optimal transport: With applications to data
391"
REFERENCES,0.2236024844720497,"science. Foundations and Trends® in Machine Learning, 11(5-6):355–607, 2019.
392"
REFERENCES,0.22404614019520852,"[38] Lenaic Chizat, Gabriel Peyré, Bernhard Schmitzer, and François-Xavier Vialard. Scaling algo-
393"
REFERENCES,0.22448979591836735,"rithms for unbalanced optimal transport problems. Mathematics of Computation, 87(314):2563–
394"
REFERENCES,0.22493345164152617,"2609, 2018.
395"
REFERENCES,0.225377107364685,"[39] Nicolas Bonneel and David Coeurjolly. SPOT: sliced partial optimal transport. ACM Transac-
396"
REFERENCES,0.22582076308784382,"tions on Graphics, 38(4):1–13, 2019.
397"
REFERENCES,0.22626441881100265,"[40] Yikun Bai, Bernhard Schmitzer, Matthew Thorpe, and Soheil Kolouri. Sliced optimal partial
398"
REFERENCES,0.2267080745341615,"transport. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
399"
REFERENCES,0.22715173025732033,"Recognition, pages 13681–13690, 2023.
400"
REFERENCES,0.22759538598047915,"[41] Gabriel Peyré, Marco Cuturi, and Justin Solomon. Gromov-wasserstein averaging of kernel and
401"
REFERENCES,0.22803904170363798,"distance matrices. In International conference on machine learning, pages 2664–2672. PMLR,
402"
REFERENCES,0.2284826974267968,"2016.
403"
REFERENCES,0.22892635314995563,"[42] Hongteng Xu, Dixin Luo, Hongyuan Zha, and Lawrence Carin Duke. Gromov-wasserstein
404"
REFERENCES,0.22937000887311446,"learning for graph matching and node embedding. In International conference on machine
405"
REFERENCES,0.22981366459627328,"learning, pages 6932–6941. PMLR, 2019.
406"
REFERENCES,0.2302573203194321,"[43] Vayer Titouan, Nicolas Courty, Romain Tavenard, and Rémi Flamary. Optimal transport for
407"
REFERENCES,0.23070097604259096,"structured data with application on graphs. In International Conference on Machine Learning,
408"
REFERENCES,0.2311446317657498,"pages 6275–6284. PMLR, 2019.
409"
REFERENCES,0.2315882874889086,"[44] Thibault Séjourné, François-Xavier Vialard, and Gabriel Peyré. The unbalanced gromov
410"
REFERENCES,0.23203194321206744,"wasserstein distance: Conic formulation and relaxation. Advances in Neural Information
411"
REFERENCES,0.23247559893522626,"Processing Systems, 34:8766–8779, 2021.
412"
REFERENCES,0.2329192546583851,"[45] Laetitia Chapel, Mokhtar Z Alaya, and Gilles Gasso. Partial optimal tranport with applications
413"
REFERENCES,0.23336291038154391,"on positive-unlabeled learning. Advances in Neural Information Processing Systems, 33:2903–
414"
REFERENCES,0.23380656610470274,"2913, 2020.
415"
REFERENCES,0.23425022182786157,"[46] Nicolò De Ponti and Andrea Mondino. Entropy-transport distances between unbalanced metric
416"
REFERENCES,0.23469387755102042,"measure spaces. Probability Theory and Related Fields, 184(1-2):159–208, 2022.
417"
REFERENCES,0.23513753327417924,"[47] Weijie Liu, Chao Zhang, Jiahao Xie, Zebang Shen, Hui Qian, and Nenggan Zheng. Partial
418"
REFERENCES,0.23558118899733807,"gromov-wasserstein learning for partial graph matching. arXiv preprint arXiv:2012.01252,
419"
REFERENCES,0.2360248447204969,"2020.
420"
REFERENCES,0.23646850044365572,"[48] Alexis Thual, Quang Huy Tran, Tatiana Zemskova, Nicolas Courty, Rémi Flamary, Stanislas
421"
REFERENCES,0.23691215616681455,"Dehaene, and Bertrand Thirion. Aligning individual brains with fused unbalanced gromov
422"
REFERENCES,0.23735581188997337,"wasserstein. Advances in Neural Information Processing Systems, 35:21792–21804, 2022.
423"
REFERENCES,0.2377994676131322,"[49] Cédric Villani. Topics in optimal transportation, volume 58. American Mathematical Soc.,
424"
REFERENCES,0.23824312333629105,"2021.
425"
REFERENCES,0.23868677905944988,"[50] Benedetto Piccoli and Francesco Rossi. Generalized wasserstein distance and its application to
426"
REFERENCES,0.2391304347826087,"transport equations with source. Archive for Rational Mechanics and Analysis, 211(1):335–358,
427"
REFERENCES,0.23957409050576753,"2014.
428"
REFERENCES,0.24001774622892635,"[51] Florian Beier, Robert Beinert, and Gabriele Steidl. On a linear gromov–wasserstein distance.
429"
REFERENCES,0.24046140195208518,"IEEE Transactions on Image Processing, 31:7292–7305, 2022.
430"
REFERENCES,0.240905057675244,"[52] Vayer Titouan, Nicolas Courty, Romain Tavenard, Chapel Laetitia, and Rémi Flamary. Optimal
431"
REFERENCES,0.24134871339840283,"transport for structured data with application on graphs. In Kamalika Chaudhuri and Ruslan
432"
REFERENCES,0.24179236912156166,"Salakhutdinov, editors, Proceedings of the 36th International Conference on Machine Learning,
433"
REFERENCES,0.2422360248447205,"volume 97 of Proceedings of Machine Learning Research, pages 6275–6284, Long Beach,
434"
REFERENCES,0.24267968056787934,"California, USA, 09–15 Jun 2019. PMLR.
435"
REFERENCES,0.24312333629103816,"[53] Xinran Liu, Yikun Bai, Huy Tran, Zhanqi Zhu, Matthew Thorpe, and Soheil Kolouri. Ptlp:
436"
REFERENCES,0.243566992014197,"Partial transport lp distances. In NeurIPS 2023 Workshop Optimal Transport and Machine
437"
REFERENCES,0.2440106477373558,"Learning, 2023.
438"
REFERENCES,0.24445430346051464,"[54] Filippo Santambrogio. Optimal transport for applied mathematicians. Birkäuser, NY, 55(58-
439"
REFERENCES,0.24489795918367346,"63):94, 2015.
440"
REFERENCES,0.2453416149068323,"[55] Rémi Flamary, Nicolas Courty, Alexandre Gramfort, Mokhtar Z. Alaya, Aurélie Boisbunon,
441"
REFERENCES,0.24578527062999111,"Stanislas Chambon, Laetitia Chapel, Adrien Corenflos, Kilian Fatras, Nemo Fournier, Léo
442"
REFERENCES,0.24622892635314997,"Gautheron, Nathalie T.H. Gayraud, Hicham Janati, Alain Rakotomamonjy, Ievgen Redko,
443"
REFERENCES,0.2466725820763088,"Antoine Rolet, Antony Schutz, Vivien Seguy, Danica J. Sutherland, Romain Tavenard, Alexander
444"
REFERENCES,0.24711623779946762,"Tong, and Titouan Vayer. Pot: Python optimal transport. Journal of Machine Learning Research,
445"
REFERENCES,0.24755989352262645,"22(78):1–8, 2021.
446"
REFERENCES,0.24800354924578527,"[56] Jessa Bekker and Jesse Davis. Learning from positive and unlabeled data: A survey. Machine
447"
REFERENCES,0.2484472049689441,"Learning, 109:719–760, 2020.
448"
REFERENCES,0.24889086069210292,"[57] Charles Elkan and Keith Noto. Learning classifiers from only positive and unlabeled data. In
449"
REFERENCES,0.24933451641526175,"Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and
450"
REFERENCES,0.24977817213842057,"data mining, pages 213–220, 2008.
451"
REFERENCES,0.2502218278615794,"[58] Masahiro Kato, Takeshi Teshima, and Junya Honda. Learning from positive and unlabeled data
452"
REFERENCES,0.2506654835847382,"with a selection bias. In International conference on learning representations, 2018.
453"
REFERENCES,0.2511091393078971,"[59] Yu-Guan Hsieh, Gang Niu, and Masashi Sugiyama. Classification from positive, unlabeled
454"
REFERENCES,0.2515527950310559,"and biased negative data. In International Conference on Machine Learning, pages 2820–2829.
455"
REFERENCES,0.25199645075421473,"PMLR, 2019.
456"
REFERENCES,0.2524401064773736,"[60] Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Darrell. Adapting visual category models to
457"
REFERENCES,0.2528837622005324,"new domains. In Computer Vision–ECCV 2010: 11th European Conference on Computer Vision,
458"
REFERENCES,0.25332741792369123,"Heraklion, Crete, Greece, September 5-11, 2010, Proceedings, Part IV 11, pages 213–226.
459"
REFERENCES,0.25377107364685003,"Springer, 2010.
460"
REFERENCES,0.2542147293700089,"[61] Jeff Donahue, Yangqing Jia, Oriol Vinyals, Judy Hoffman, Ning Zhang, Eric Tzeng, and Trevor
461"
REFERENCES,0.2546583850931677,"Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. In
462"
REFERENCES,0.25510204081632654,"International conference on machine learning, pages 647–655. PMLR, 2014.
463"
REFERENCES,0.25554569653948533,"A
Notation and Abbreviations
464"
REFERENCES,0.2559893522626442,"• OT: Optimal Transport.
465"
REFERENCES,0.25643300798580304,"• POT: Partial Optimal Transport.
466"
REFERENCES,0.25687666370896184,"• GW: Gromov-Wasserstein.
467"
REFERENCES,0.2573203194321207,"• PGW: Partial Gromov-Wasserstein.
468"
REFERENCES,0.2577639751552795,"• FW: Frank-Wolfe.
469"
REFERENCES,0.25820763087843834,"• MPGW: Mass-Constrained Partial Gromov-Wasserstein.
470"
REFERENCES,0.25865128660159714,"• ∥· ∥: Euclidean norm.
471"
REFERENCES,0.259094942324756,"• X2 = X × X.
472"
REFERENCES,0.2595385980479148,"• M+(X): set of all positive (non-negative) Randon (finite) measures defined on X.
473"
REFERENCES,0.25998225377107365,"• P2(X): set of all probability measures defined on X, whose second moment is finite.
474"
REFERENCES,0.2604259094942325,"• R+: set of all non-negative real numbers.
475"
REFERENCES,0.2608695652173913,"• Rn×m: set of all n × m matrices with real coefficients.
476"
REFERENCES,0.26131322094055015,"• Rn×m
+
(resp. Rn
+): set of all n×m matrices (resp., n-vectors) with non-negative coefficients.
477"
REFERENCES,0.26175687666370895,"• Rn×m×n×m: set of all n × m × n × m tensors with real coefficients.
478"
REFERENCES,0.2622005323868678,"• 1n, 1n×m, 1n×m×n×m: vector, matrix, and tensor of all ones.
479"
REFERENCES,0.2626441881100266,"• 1E: characteristic function of a measurable set E
480"
REFERENCES,0.26308784383318545,"1E(z) =
1
if z ∈E,
0
otherwise."
REFERENCES,0.26353149955634425,"• X, Y: metric measure spaces (mm-spaces): X = (X, dX, µ), Y = (Y, dY , ν).
481"
REFERENCES,0.2639751552795031,"• CX: given a discrete mm-space X = (X, dX, µ), where X = {x1, . . . , xn}, the symmetric
482"
REFERENCES,0.26441881100266196,"matrix CX ∈Rn×n is defined as CX
i,i′ = dq
X(xi, x′
i).
483"
REFERENCES,0.26486246672582076,"• µ⊗2: product measure µ ⊗µ.
484"
REFERENCES,0.2653061224489796,"• T#σ: T : X →Y is a measurable function and σ is a measure on X. T#σ is the push-
485"
REFERENCES,0.2657497781721384,"forward measure of σ, i.e., its is the measure on Y such that for all Borel set A ⊂Y ,
486"
REFERENCES,0.26619343389529726,"T#σ(A) = σ(T −1(A)).
487"
REFERENCES,0.26663708961845606,"• γ, γ1, γ2: γ is a joint measure defined in a product space having γ1, γ2 as its first and second
488"
REFERENCES,0.2670807453416149,"marginals, respectively. In the discrete setting, they are viewed as matrices and vectors, i.e.,
489"
REFERENCES,0.2675244010647737,"γ ∈Rn×m
+
, and γ1 = γ1m ∈Rn
+, γ2 = γ⊤1n ∈Rm
+.
490"
REFERENCES,0.26796805678793256,"• π1 : X×Y →X, canonical projection mapping, with (x, y) 7→x. Similarly, π2 : X×Y →
491"
REFERENCES,0.2684117125110914,"Y is canonical projection mapping, with (x, y) 7→y.
492"
REFERENCES,0.2688553682342502,"• π1,2 : S × X × Y →X × Y , canonical projection mapping, with (s, x, y) →(x, y).
493"
REFERENCES,0.26929902395740907,"Similarly, π0,1 maps (s, x, y) to (s, x); π0,2 maps (s, x, y) to (s, y).
494"
REFERENCES,0.26974267968056787,"• Γ(µ, ν), where µ ∈P2(X), ν ∈P2(Y ) (where X, Y may not necessarily be the same set):
495"
REFERENCES,0.2701863354037267,"it is the set of all the couplings (transportation plans) between µ and ν, i.e., Γ(µ, ν) := {γ ∈
496"
REFERENCES,0.2706299911268855,"P2(X × Y ) : γ1 = µ, γ2 = ν}.
497"
REFERENCES,0.27107364685004437,"• Γ(p, q): set of all the couplings between the discrete probability measures µ = Pn
i=1 pX
i δxi
498"
REFERENCES,0.27151730257320317,"and ν = Pm
j=1 qY
j δyj with weight vectors
499"
REFERENCES,0.271960958296362,"p = [pX
1 , . . . , pX
n ]⊤
and
q = [qY
1 , . . . , qY
m]⊤.
(20)"
REFERENCES,0.2724046140195209,"That is, Γ(p, q) coincides with Γ(µ, ν), but it is viewed as a subset of n × m matrices
500"
REFERENCES,0.27284826974267967,"defined in (12).
501"
REFERENCES,0.2732919254658385,"• p, q: real numbers 1 ≤p, q < ∞.
502"
REFERENCES,0.2737355811889973,"• p, q: vectors of weights as in (20).
503"
REFERENCES,0.2741792369121562,"• p = [p1, . . . , pn] ≤p′ = [p′
1, . . . , p′
n] if pj ≤p′
j for all 1 ≤j ≤n.
504"
REFERENCES,0.274622892635315,"• |p| = Pn
i=1 pi for p = [p1, . . . , pn].
505"
REFERENCES,0.27506654835847383,"• c(x, y) : X × Y →R+ denotes the cost function used for classical and partial optimal
506"
REFERENCES,0.2755102040816326,"transport problems. lower-semi continuous function.
507"
REFERENCES,0.2759538598047915,"• OT(µ, ν): it is the classical optimal transport (OT) problem between the probability mea-
508"
REFERENCES,0.27639751552795033,"sures µ and ν defined in (1).
509"
REFERENCES,0.27684117125110913,"• Wp(µ, ν): it is the p-Wasserstein distance between the probability measures µ and ν defined
510"
REFERENCES,0.277284826974268,"in (2), for 1 ≤p < ∞.
511"
REFERENCES,0.2777284826974268,"• POT(µ, ν; λ): the Partial Optimal Transport (OPT) problem defined in (3).
512"
REFERENCES,0.27817213842058564,"• |µ|: total variation norm of the positive Randon (finite) measure µ defined on a measurable
513"
REFERENCES,0.27861579414374443,"space X, i.e., |µ| = µ(X).
514"
REFERENCES,0.2790594498669033,"• µ ≤σ: denotes that for all Borel set B ⊆X we have that the measures µ, σ ∈M+(X)
515"
REFERENCES,0.2795031055900621,"satisfy µ(B) ≤σ(B).
516"
REFERENCES,0.27994676131322094,"• Γ≤(µ, ν), where µ ∈M+(X), ν ∈M+(Y ): set of all “partial transportation plans”"
REFERENCES,0.2803904170363798,"Γ≤(µ, ν) := {γ ∈M+(X × Y ) : γ1 ≤µ, γ2 ≤ν}."
REFERENCES,0.2808340727595386,"• Γ≤(p, q): set of all the “partial transportation plans” between the discrete probability
517"
REFERENCES,0.28127772848269744,"measures µ = Pn
i=1 pX
i δxi and ν = Pm
j=1 qY
j δyj with weight vectors p = [pX
1 , . . . , pX
n ]
518"
REFERENCES,0.28172138420585624,"and q = [qY
1 , . . . , qY
m]. That is, Γ≤(p, q) coincides with Γ≤(µ, ν), but it is viewed as a
519"
REFERENCES,0.2821650399290151,"subset of n × m matrices defined in (13).
520"
REFERENCES,0.2826086956521739,"• λ > 0: positive real number.
521"
REFERENCES,0.28305235137533274,"• ˆ∞: auxiliary point.
522"
REFERENCES,0.2834960070984916,"• ˆX = X ∪{ ˆ∞}.
523"
REFERENCES,0.2839396628216504,"• ˆµ, ˆν: given in (4).
524"
REFERENCES,0.28438331854480925,"• ˆp, ˆq: given in (53).
525"
REFERENCES,0.28482697426796805,"• ˆγ: given in (6).
526"
REFERENCES,0.2852706299911269,"• ˆc(·, ·) : ˆX × ˆY →R+: cost as in (5).
527"
REFERENCES,0.2857142857142857,"• L : R × R →R: cost function for the GW problems.
528"
REFERENCES,0.28615794143744455,"• D : R × R →R: generic distance on R used for GW problems.
529"
REFERENCES,0.28660159716060335,"• GW L(·, ·): GW optimization problem given in (7).
530"
REFERENCES,0.2870452528837622,"• GW p(·, ·): GW optimization problem given in (7) when L(a, b) = |a −b|p.
531"
REFERENCES,0.28748890860692106,"• GW L
q (·, ·): general GW optimization problem for g ≥1 given in (33).
532"
REFERENCES,0.28793256433007985,"• GW p
q (·, ·): general GW optimization problem for q ≥1 and L(a, b) = |a −b|p given in
533"
REFERENCES,0.2883762200532387,"(34).
534"
REFERENCES,0.2888198757763975,"• GW p
λ,q(·, ·): generalized GW problem given in (39).
535"
REFERENCES,0.28926353149955636,"• d
GW: GW-variant problem given in (51) for the general case, and in (55) for the discrete
536"
REFERENCES,0.28970718722271516,"setting.
537"
REFERENCES,0.290150842945874,"• ˆL: cost given in (16) for the GW-variant problem.
538"
REFERENCES,0.2905944986690328,"• d : ˆX × ˆX →R+ ∪{∞}: “generalized” metric given in (50) for ˆX.
539"
REFERENCES,0.29103815439219166,"• X ∼Y: equivalence relation in for mm-spaces, X ∼Y if and only if they have the same
540"
REFERENCES,0.2914818101153505,"total mass and GW p
q (X, Y) = 0.
541"
REFERENCES,0.2919254658385093,"• PGW L
λ,q(·, ·): partial GW optimization problem given in (9) or, equivalently, in (10).
542"
REFERENCES,0.29236912156166817,"• PGW p
λ,q(·, ·): partial GW optimization problem given in (10) when L(a, b) = |a −b|p.
543"
REFERENCES,0.29281277728482696,"• PGWλ(·, ·): is is the PGW problem PGW p
λ,q(·, ·) for the case when p = 2 = q.
544"
REFERENCES,0.2932564330079858,"• µ(ϕ): given a measure µ and a function ϕ,"
REFERENCES,0.2937000887311446,"µ(ϕ) :=
Z
ϕ(x)dµ(x)."
REFERENCES,0.29414374445430347,"• C(γ; λ, µ, ν): the transportation cost induced by transportation plan γ ∈Γ≤(µ, ν) in the
Partial GW problem 10,"
REFERENCES,0.29458740017746227,"C(γ; λ, µ, ν) := γ⊗2(L(dq
X, dq
Y )) + λ(|µ|2 + |ν|2 −2|γ|2)."
REFERENCES,0.2950310559006211,"• L: functional for the optimization problem PGWλ(·, ·).
545"
REFERENCES,0.29547471162378,"• M, ˜
M, and ˆ
M: see (14), and (54). Notice that, (M −2λ)i,i′,j,j′ := Mi,i′,j,j′ −2λ.
546"
REFERENCES,0.29591836734693877,"• ⟨·, ·⟩F :
Frobenius inner product for matrices, i.e., ⟨A, B⟩F
=
trace(A⊤B)
=
547
Pn,m
i,j
Ai,jBi,j for all A, B ∈Rn×m.
548"
REFERENCES,0.2963620230700976,"• M ◦γ: product between the tensor M and the matrix γ.
549"
REFERENCES,0.2968056787932564,"• ∇: gradient.
550"
REFERENCES,0.2972493345164153,"• [1 : n] = {1, . . . , n}.
551"
REFERENCES,0.2976929902395741,"• α: step size based on the line search method.
552"
REFERENCES,0.2981366459627329,"• γ(1): initialization of the algorithm.
553"
REFERENCES,0.2985803016858917,"• γ(k), γ(k)′: previous and new transportation plans before and after step 1 in the k−th
554"
REFERENCES,0.2990239574090506,"iteration of version 1 of our proposed FW algorithm.
555"
REFERENCES,0.29946761313220943,"• ˆγ(k), ˆγ(k)′: previous and new transportation plans before and after step 1 in the k−th
556"
REFERENCES,0.29991126885536823,"iteration of version 2 of our proposed FW algorithm.
557"
REFERENCES,0.3003549245785271,"• G = 2 ˜
M ◦γ, ˆG = 2 ˆ
M ◦ˆγ: Gradient of the objective function in version 1 and version 2,
558"
REFERENCES,0.3007985803016859,"respectively, of our proposed FW algorithm for solving the discrete version of partial GW
559"
REFERENCES,0.30124223602484473,"problem.
560"
REFERENCES,0.30168589174800353,"• (δγ, a, b) and (δˆγ, a, b): given in (18) and (56) for versions 1 and 2 of the algorithm,
561"
REFERENCES,0.3021295474711624,"respectively.
562"
REFERENCES,0.3025732031943212,"• C1-function: continuous and with continuous derivatives.
563"
REFERENCES,0.30301685891748004,"• MPGWρ(·, ·): Mass-Constrained Partial Gromov-Wasserstein defined in (73)
564"
REFERENCES,0.3034605146406389,"• Γρ
≤(µ, ν): set transport plans defined in (74) for the Mass-Constrained Partial Gromov-
565"
REFERENCES,0.3039041703637977,"Wasserstein problem.
566"
REFERENCES,0.30434782608695654,"• ΓP U,π(p, q): defined in (87).
567"
REFERENCES,0.30479148181011534,"B
Proof of Proposition 3.2
568"
REFERENCES,0.3052351375332742,"The idea of the proof is inspired by the proof of Proposition 1 in [50].
569"
REFERENCES,0.305678793256433,"The goal is to verify that
570"
REFERENCES,0.30612244897959184,"PGW L
λ,q(X, Y)"
REFERENCES,0.30656610470275064,":=
inf
γ∈M+(X,Y ) Z"
REFERENCES,0.3070097604259095,"(X×Y )2 L(dq
X(x, x′), dq
Y (y, y′))dγ⊗2"
REFERENCES,0.30745341614906835,"|
{z
}
transport GW cost"
REFERENCES,0.30789707187222715,"+ λ
 
|µ⊗2 −γ⊗2
1 | + |ν⊗2 −γ⊗2
2 |
"
REFERENCES,0.308340727595386,"|
{z
}
mass penalty"
REFERENCES,0.3087843833185448,"=
inf
γ∈Γ≤(µ,ν) Z"
REFERENCES,0.30922803904170365,"(X×Y )2 L(dq
X(x, x′), dq
Y (y, y′))dγ⊗2 + λ
 
|µ⊗2 −γ⊗2
1 | + |ν⊗2 −γ⊗2
2 |

.
(21)"
REFERENCES,0.30967169476486245,"Consider γ ∈M+(X × Y ) such that γ1 ≤µ does not hold. Then we can write the Lebesgue
decomposition of γ1 with respect to µ:"
REFERENCES,0.3101153504880213,"γ1 = fµ + µ⊥,"
REFERENCES,0.3105590062111801,"where f ≥0 is the Radon-Nikodym derivative of γ1 with respect to µ, and µ⊥, µ are mutually singular,
that is, there exist measurable sets A, B such that A∩B = ∅, X = A∪B and µ⊥(A) = 0, µ(B) = 0.
Without loss of generality, we can assume that the support of f lies on A, since"
REFERENCES,0.31100266193433895,"γ1(E) =
Z"
REFERENCES,0.3114463176574978,"E∩A
f(x) dµ(x) + µ⊥(E ∩B)
∀E ⊆X measurable."
REFERENCES,0.3118899733806566,"Define A1 = {x ∈A : f(x) > 1}, A2 = {x ∈A : f(x) ≤1} (both are measurable, since f is
measurable), and define ¯µ = min{f, 1}µ. Then,"
REFERENCES,0.31233362910381546,"¯µ ≤µ
and
¯µ ≤fµ ≤fµ + µ⊥= γ1."
REFERENCES,0.31277728482697426,"There exists a ¯γ ∈M+(X × Y ) such that ¯γ1 = ¯µ, ¯γ ≤γ, and ¯γ2 ≤γ2. Indeed, we can construct ¯γ
in the following way: First, let {γx}x∈X be the set of conditional measures (disintegration) such that
for every measurable (test) function ψ : X × Y →R we have
Z
ψ(x, y) dγ(x, y) =
Z X Z"
REFERENCES,0.3132209405501331,"Y
ψ(x, y) dγx(y) dγ1(x)."
REFERENCES,0.3136645962732919,"Then, define ¯γ as"
REFERENCES,0.31410825199645076,"¯γ(U) :=
Z X Z"
REFERENCES,0.31455190771960956,"Y
1U(x, y) dγx(y) d¯µ(x)
∀U ⊆X × Y Borel."
REFERENCES,0.3149955634427684,"Then, ¯γ verifies that ¯γ1 = ¯µ, and since ¯µ ≤γ1, we also have that ¯γ ≤γ, which implies ¯γ2 ≤γ2.
571"
REFERENCES,0.31543921916592726,"Since |γ1| = |γ2| and |¯γ1| = |¯γ2|, then we have |γ⊗2
1
−¯γ⊗2
1 | = |γ⊗2
2
−¯γ⊗2
2 |.
572"
REFERENCES,0.31588287488908606,"We claim that
573"
REFERENCES,0.3163265306122449,"|µ⊗2 −γ⊗2
1 | ≥|µ⊗2 −¯γ⊗2
1 | + |γ⊗2
1
−¯γ⊗2
1 |.
(22)"
REFERENCES,0.3167701863354037,"• Left-hand side of (22): Since {A, B} is a partition of X, we first spit the left-hand side of
574"
REFERENCES,0.31721384205856257,"(22) as
575"
REFERENCES,0.31765749778172137,"|µ⊗2 −γ⊗2
1 | = (µ⊗2 −γ⊗2
1 )(A × A)
|
{z
}
(I)"
REFERENCES,0.3181011535048802,"+ (µ⊗2 −γ⊗2
1 )(A × B) + (µ⊗2 −γ⊗2
1 )(B × A)
|
{z
}
(II)"
REFERENCES,0.318544809228039,"+ (µ⊗2 −γ⊗2
1 )(B × B)
|
{z
}
(III) ."
REFERENCES,0.31898846495119787,"Then we have
576"
REFERENCES,0.3194321206743567,"(III) = (µ⊗2 −γ⊗2
1 )(B × B) = µ⊥⊗µ⊥(B × B) = |µ⊥|2,"
REFERENCES,0.3198757763975155,"(II) = (µ⊗2 −γ⊗2
1 )(A × B) + (µ⊗2 −γ⊗2
1 )(B × A) = 2|µ⊥|(µ −γ1)(A)."
REFERENCES,0.3203194321206744,"Since γ1 = fµ in A, then ¯γ1 = γ1 in A2 and ¯γ1 = µ in A1, so we have
577"
REFERENCES,0.3207630878438332,"(µ −γ1)(A) = (µ −γ1)(A1) + (µ −γ1)(A2) = (γ1 −¯γ1)(A1) + (µ −¯γ1)(A2)
= (γ1 −¯γ1)(A) + (µ −¯γ1)(A)."
REFERENCES,0.321206743566992,"Thus,
578"
REFERENCES,0.3216503992901508,"(II) = 2|µ⊥|((γ1 −¯γ1)(A) + (µ −¯γ1)(A)),"
REFERENCES,0.3220940550133097,"and we also get that
579"
REFERENCES,0.3225377107364685,"(I) = (µ⊗2 −γ⊗2
1 )(A × A)"
REFERENCES,0.32298136645962733,"= (µ⊗2 −γ⊗2
1 )(A1 × A1) + (µ⊗2 −γ⊗2
1 )(A2 × A2) + (µ⊗2 −γ⊗2
1 )(A1 × A2)"
REFERENCES,0.3234250221827862,"+ (µ⊗2 −γ⊗2
1 )(A2 × A1)"
REFERENCES,0.323868677905945,"= (γ⊗2
1
−¯γ⊗2
1 )(A1 × A1) + (µ⊗2 −¯γ⊗2
1 )(A2 × A2)+
+ |¯γ1 ⊗µ −γ1 ⊗¯γ1|(A1 × A2) + |µ ⊗¯γ1 −¯γ1 ⊗γ1|(A2 × A1)"
REFERENCES,0.32431233362910383,"= (γ⊗2
1
−¯γ⊗2
1 )(A1 × A1) + (µ⊗2 −¯γ⊗2
1 )(A2 × A2) + 2(¯γ1 −γ1)(A1)(µ −¯γ1)(A2)"
REFERENCES,0.32475598935226263,"= (γ⊗2
1
−¯γ⊗2
1 )(A × A) + (µ⊗2 −¯γ⊗2
1 )(A × A) + 2(¯γ1 −γ1)(A1)(µ −¯γ1)(A2)
|
{z
}
≥0 ."
REFERENCES,0.3251996450754215,"• Right-hand side of (22): First notice that
580"
REFERENCES,0.3256433007985803,"(γ1 −¯γ1)(B) = (γ1 −¯γ1)(B) ≤γ1(B) = |µ⊥|,"
REFERENCES,0.32608695652173914,"and since ¯γ1 ≤µ and µ(B) = 0, we have
581"
REFERENCES,0.32653061224489793,(µ −¯γ1)(B) = 0.
REFERENCES,0.3269742679680568,"Then,
582"
REFERENCES,0.32741792369121564,"|µ⊗2 −¯γ⊗2
1 | + |γ⊗2
1
−¯γ⊗2
1 | ="
REFERENCES,0.32786157941437444,"= (µ⊗2 −¯γ⊗2
1 )(A × A) + (γ⊗2
1
−¯γ⊗2
1 )(A × A) + (µ⊗2 −¯γ⊗2
1 )(B × B)"
REFERENCES,0.3283052351375333,"+ (γ⊗2
1
−¯γ⊗2
1 )(B × B) + (µ⊗2 −¯γ⊗2
1 )(A × B) + (γ⊗2
1
−¯γ⊗2
1 )(A × B)"
REFERENCES,0.3287488908606921,"+ (µ⊗2 −¯γ⊗2
1 )(B × A) + (γ⊗2
1
−¯γ⊗2
1 )(B × A)"
REFERENCES,0.32919254658385094,"≤(µ⊗2 −¯γ⊗2
1 )(A × A) + (γ⊗2
1
−¯γ⊗2
1 )(A × A)
|
{z
}
≤(I)"
REFERENCES,0.32963620230700974,"+ |µ⊥|2
| {z }
=(III)"
REFERENCES,0.3300798580301686,"+ 2|µ⊥|(γ1 −¯γ1)(A)
|
{z
}
=(II) ."
REFERENCES,0.3305235137533274,"Thus, (22) holds.
583"
REFERENCES,0.33096716947648624,"We finish the proof of the proposition by noting that
584"
REFERENCES,0.3314108251996451,"|µ⊗2 −¯γ⊗2
1 | + |ν⊗2 −¯γ⊗2
2 | ≤|µ⊗2 −γ⊗2
1 | −|γ⊗2
1
−¯γ⊗2
1 | + |ν⊗2 −¯γ⊗2
2 |"
REFERENCES,0.3318544809228039,"= |µ⊗2 −γ⊗2
1 | −|γ⊗2
2
−¯γ⊗2
2 | + |ν⊗2 −¯γ⊗2
2 |"
REFERENCES,0.33229813664596275,"≤|µ⊗2 −γ⊗2
1 | + |ν⊗2 −γ⊗2
2 |"
REFERENCES,0.33274179236912155,"where the first inequality follows from (22), and the second inequality holds from the fact the total
585"
REFERENCES,0.3331854480922804,"variation norm | · | satisfies triangular inequality. Therefore ¯γ induces a smaller transport GW cost
586"
REFERENCES,0.3336291038154392,"than γ (since ¯γ ≤γ), and also ¯γ decreases the mass penalty in comparison that corresponding to
587"
REFERENCES,0.33407275953859805,"γ. Thus, ¯γ is a better GW transportation plan, which satisfies ¯γ1 ≤µ. Similarly, we can further
588"
REFERENCES,0.33451641526175685,"construct ¯γ′ based on ¯γ such that ¯γ′
1 ≤µ, ¯γ′
2 ≤ν. Therefore, we can restrict the minimization in (9)
589"
REFERENCES,0.3349600709849157,"from M+(X × Y ) to Γ≤(µ, ν). Thus, the equality (21) is satisfied.
590"
REFERENCES,0.33540372670807456,"Proof of Remark 3.1. Given γ ∈Γ≤(µ, ν), since γ1 ≤µ, γ2 ≤ν, and γ1(X) = |γ1| = |γ| =
591"
REFERENCES,0.33584738243123335,"|γ2| = γ2(Y ), we have
592"
REFERENCES,0.3362910381543922,"|µ⊗2 −γ⊗2
1 | + |ν⊗2 −γ⊗2
2 | = µ⊗2(X2) −γ⊗2
1 (X2) + ν⊗2(Y 2) −γ⊗2
2 (Y 2)"
REFERENCES,0.336734693877551,"= |µ|2 + |ν|2 −2|γ|2,"
REFERENCES,0.33717834960070986,"and so the transportation cost in partial GW problem (10) becomes
593"
REFERENCES,0.33762200532386866,"C(γ; λ, µ, ν) :=
Z"
REFERENCES,0.3380656610470275,"(X×Y )2 L(dq
X(x, x′), dq
Y (y, y′)) dγ(x, y)dγ(x′, y′) + λ
 
|µ⊗2 −γ⊗2
1 | + |ν⊗2 −γ⊗2
2 |
 =
Z"
REFERENCES,0.3385093167701863,"(X×Y )2 L(dq
X(x, x′), dq
Y (y, y′)) dγ(x, y)dγ(x′, y′) + λ
 
|µ|2 + |ν|2 −2|γ|2 =
Z"
REFERENCES,0.33895297249334516,"(X×Y )2 (L(dq
X(x, x′), dq
Y (y, y′) −2λ) dγ(x, y)dγ(x′, y′) + λ
 
|µ|2 + |ν|2"
REFERENCES,0.339396628216504,"|
{z
}
does not depend on γ"
REFERENCES,0.3398402839396628,".
(23) 594"
REFERENCES,0.34028393966282167,"C
Proof of Proposition 3.3
595"
REFERENCES,0.34072759538598046,"In this section, we discuss the minimizer of the Partial GW problem (9). Trivially, Γ≤(µ, ν) ⊆
596"
REFERENCES,0.3411712511091393,"M+(X × Y ) and by using Proposition 3.2 it is enough to show that a minimizer for problem (10)
597"
REFERENCES,0.3416149068322981,"exists.
598"
REFERENCES,0.34205856255545697,"We refer the reader to [8, Chapters 5 and 10] for similar ideas.
599"
REFERENCES,0.34250221827861577,"C.1
Formal Statement of Proposition 3.3
600"
REFERENCES,0.3429458740017746,"Suppose X, Y are compact sets, then exists compact set [0, β] ⊂R, such that"
REFERENCES,0.3433895297249335,"d(x, x′), d(y, y′) ∈[0, β],
∀x, x′ ∈X, y, y′ ∈Y"
REFERENCES,0.34383318544809227,"Let A = [0, βq]. Let LA2 denote the restriction of L on A2, i.e. LA2 : A2 →R with LA2(r1, r2) =
601"
REFERENCES,0.3442768411712511,"L(r1, r2), ∀r1, r2 ∈A. Suppose L satisfies the following: there exists 0 < K < ∞such that for
602"
REFERENCES,0.3447204968944099,"every r1, r′
1, r2, r′
2 ∈A,
603"
REFERENCES,0.3451641526175688,"|LA2(r1, r2) −LA2(r′
1, r2)| ≤K|r1 −r′
1|, |LA2(r1, r2) −LA2(r1, r′
2)| ≤K|r2 −r′
2|
(24)"
REFERENCES,0.3456078083407276,"(i.e., LA2 is Lipschitz on each variable). Then PGW L
λ (·, ·) admits a minimizer.
604"
REFERENCES,0.3460514640638864,"Note, the condition (24) contains the case L(r1, r2) = |r1 −r2|p as a special case:
605"
REFERENCES,0.3464951197870453,"Lemma C.1. If L(r1, r2) = |r1 −r2|p, for 1 ≤p < ∞, then L satisfies the condition (24).
606"
REFERENCES,0.3469387755102041,"Proof. Assume that L is defined on an interval of the form [0, M], for some M > 0. Consider
607"
REFERENCES,0.34738243123336293,"r1, r′
1, r2, r′
2 ∈[0, M]. If p = 1, by triangle inequality we have
608"
REFERENCES,0.34782608695652173,"|L(r1, r2) −L(r′
1, r2)| = ||r1 −r2| −|r′
1 −r2|| ≤|r1 −r′
1|"
REFERENCES,0.3482697426796806,"and similarly,
609"
REFERENCES,0.3487133984028394,"|L(r1, r2) −L(r1, r′
2)| ≤|r2 −r′
2|."
REFERENCES,0.34915705412599823,"From [8, page 473], since for 1 ≤p < ∞, the function t 7→tp, for t ∈[0, M], is Lipschitz with
610"
REFERENCES,0.34960070984915703,"constant bounded by pM p−1, we have
611"
REFERENCES,0.3500443655723159,"|L(r1, r2) −L(r′
1, r2)| ≤pM p−1|r1 −r′
1|."
REFERENCES,0.35048802129547474,"and similarly,
612"
REFERENCES,0.35093167701863354,"|L(r1, r2) −L(r1, r′
2)| ≤pM p−1|r2 −r′
2|. 613"
REFERENCES,0.3513753327417924,"Lemma C.2. Given q ≥1, consider β > 0. Then [0, β] ∋c 7→cq ∈[0, βq] is a Lipschitz function.
614"
REFERENCES,0.3518189884649512,"Proof. Given c1, c2 ∈[0, β], we have
615"
REFERENCES,0.35226264418811004,"|cq
1 −cq
2| ≤qβq−1|c1 −c2|
(25)"
REFERENCES,0.35270629991126884,"Thus, c 7→cq is a Lipschitz function.
616"
REFERENCES,0.3531499556344277,"C.2
Convergence Auxiliary Result
617"
REFERENCES,0.3535936113575865,"If a sequence {γn} converges weakly to γ, we write γn w⇀γ. In this setting, if γn w⇀γ, it does not
618"
REFERENCES,0.35403726708074534,"imply that (γn)⊗2 w⇀γ⊗2. Thus, the technique used in classical OT for proving the existence of a
619"
REFERENCES,0.3544809228039042,"minimizer for the optimal transport optimization problem as a consequence of the Stone-Weierstrass
620"
REFERENCES,0.354924578527063,"theorem does not apply directly in the Gromov-Wasserstein context.
621"
REFERENCES,0.35536823425022185,"Inspired by [8], we introduce the following lemma.
622"
REFERENCES,0.35581188997338065,"Lemma C.3. Given metric space (Z, dZ), suppose ϕ : R2 →R is a Lipschitz continuous function
with respect to (Z2, d+
Z), where"
REFERENCES,0.3562555456965395,"d+
Z((z1, z2), (z′
1, z′
2)) := dZ(z1, z′
1) + dZ(z2, z′
2),
∀(z1, z2), (z′
1, z′
2) ∈Z2."
REFERENCES,0.3566992014196983,"Given γ ∈M+(Z), and a sequence {γn}n≥1 ∈M+(Z) such that converges weakly to γ,"
REFERENCES,0.35714285714285715,"γn w⇀γ
(n →∞)."
REFERENCES,0.35758651286601595,"Finally, consider the mapping"
REFERENCES,0.3580301685891748,"Z ∋z 7→γ(ϕ(z, ·)) :=
Z"
REFERENCES,0.35847382431233366,"Z
ϕ(z, z′)dγ(z′) ∈R."
REFERENCES,0.35891748003549245,"Then we have the following results:
623"
REFERENCES,0.3593611357586513,"(1) γn(ϕ(z, ·)) →γ(ϕ(z, ·)) uniformly (when n →∞).
624"
REFERENCES,0.3598047914818101,"(2) (γn)⊗2(ϕ(·, ·)) →γ⊗2(ϕ(·, ·)) (when n →∞).
625"
REFERENCES,0.36024844720496896,"(3) If M ⊂M+(Z) is compact for the weak convergence, then infγ∈M γ⊗2(ϕ(·, ·)) admits a
626"
REFERENCES,0.36069210292812776,"minimizer.
627"
REFERENCES,0.3611357586512866,"Proof. The main idea of the proof is similar to [8, Lemma 10.3]: we extend it from P+(Z) to
628"
REFERENCES,0.3615794143744454,"M+(Z).
629"
REFERENCES,0.36202307009760426,"(1) Since γn w⇀γ, and Z is compact, we have |γn| →|γ|. Then, given ϵ > 0, for n sufficiently
630"
REFERENCES,0.3624667258207631,"large we have |γn| ≤|γ| + ϵ.
631"
REFERENCES,0.3629103815439219,"Let us denote by ∥ϕ∥Lip the Lipschitz constant of ϕ. For any z1, z2 ∈Z, we have:
632"
REFERENCES,0.36335403726708076,"|γn(ϕ(z1, ·)) −γn(ϕ(z2, ·))| ≤
Z"
REFERENCES,0.36379769299023956,"Z
|ϕ(z1, z) −ϕ(z2, z)|γn(z)"
REFERENCES,0.3642413487133984,"≤max
z∈Z |ϕ(z1, z) −ϕ(z2, z)|(|γ| + ϵ)"
REFERENCES,0.3646850044365572,"≤(|γ| + ϵ)∥ϕ∥Lip dZ(z1, z2) = KdZ(z1, z2),"
REFERENCES,0.36512866015971607,"where K = (|γ| + ϵ)∥ϕ∥Lip is a finite positive value. Note that the above inequality also
633"
REFERENCES,0.36557231588287487,"holds if we replace γn by γ.
634"
REFERENCES,0.3660159716060337,"Since (Z, dZ) is compact, Z = SN
i=1 B(zi, ϵ/K) for some z1, . . . , zN ∈Z, where
B(zi, ϵ/3K) = {z ∈Z : dZ(z, zi) ≤ϵ/3K} is the closed ball centered at zi, with
radius ϵ/K. By definition of weak convergence, when n is sufficiently large,"
REFERENCES,0.36645962732919257,"|γn(ϕ(zi, ·)) −γ(ϕ(zi, ·))| < ϵ/3,
for each i ∈[1 : N]."
REFERENCES,0.36690328305235137,"Given z ∈Z, then z ∈B(zi) for some zi. For sufficiently large n, we have:
635"
REFERENCES,0.3673469387755102,"|γn(ϕ(z, ·)) −γ(ϕ(z, ·))|
≤|γn(ϕ(z, ·)) −γn(ϕ(zi, ·))| + |γn(ϕ(zi, ·)) −γ(ϕ(zi, ·))| + |γ(ϕ(zi, ·)) −γ(ϕ(z, ·))|
≤Kd(z, zi) + ϵ/3 + Kd(z, zi) = ϵ/3 + ϵ/3 + ϵ/3 = ϵ.
(26)"
REFERENCES,0.367790594498669,"Thus we prove the first statement.
636"
REFERENCES,0.3682342502218279,"(2) We recall that we do not have (γn)⊗2 w⇀γ⊗2.
637"
REFERENCES,0.3686779059449867,"Consider an arbitrary ϵ > 0. We have,
638"
REFERENCES,0.3691215616681455,"0 ≤lim sup
n→∞|(γn)⊗2(ϕ) −(γ)⊗2(ϕ)|
(27)"
REFERENCES,0.3695652173913043,"≤lim sup
n→∞|(γn ⊗γn)(ϕ) −(γ ⊗γn)(ϕ)|
|
{z
}
An"
REFERENCES,0.3700088731144632,"+ lim sup
n→∞|(γn ⊗γ)(ϕ) −(γ ⊗γ)(ϕ)|
|
{z
}
Bn ."
REFERENCES,0.37045252883762203,"For the first term, when n is sufficiently large, by statement (1), we have:
639"
REFERENCES,0.37089618456078083,"An =
Z
(γn(ϕ(z, ·)) −γ(ϕ(z, ·)) dγn(z)"
REFERENCES,0.3713398402839397,"≤max
z
|γn(ϕ(z, ·)) −γ(ϕ(z, ·)||γn|"
REFERENCES,0.3717834960070985,"≤ϵ(|γ| + ϵ)
(28)"
REFERENCES,0.37222715173025733,"Thus, lim supn A = limn A = 0.
640"
REFERENCES,0.37267080745341613,"Similarly, for the second term, when n is sufficiently large, we have
641"
REFERENCES,0.373114463176575,"Bn :=
Z
(γn(ϕ(z, ·)) −γ(ϕ(z, ·)))dγ(z) ≤ϵ|γ|.
(29)"
REFERENCES,0.3735581188997338,"Thus, lim supn Bn = limn Bn = 0.
642"
REFERENCES,0.37400177462289264,"Therefore, from (27), (28) and (29), we obtain
643"
REFERENCES,0.3744454303460515,"lim sup
n→∞|(γn)⊗2(ϕ) −(γ)⊗2(ϕ)| = lim
n→∞|(γn)⊗2(ϕ) −(γ)⊗2(ϕ)| = 0.
(30)"
REFERENCES,0.3748890860692103,"(3) Let γn ∈M be a sequence such that (γn)⊗2(ϕ) (weakly) converges to infγ∈M γ⊗2(ϕ).
Since M is compact, there exists a sub-sequence γnk
w⇀γ for some γ ∈M. Then, by
statement (2), we have:"
REFERENCES,0.37533274179236914,"γ⊗2(ϕ) = lim
k (γnk)⊗2(ϕ) = inf
γ∈M γ⊗2(ϕ),"
REFERENCES,0.37577639751552794,"and we complete the proof.
644 645"
REFERENCES,0.3762200532386868,"C.3
Proof of the Formal Statement for Proposition 3.3
646"
REFERENCES,0.3766637089618456,"The proof follows the ideas of [8, Corollary 10.1].
647"
REFERENCES,0.37710736468500444,"Define (Z, dZ) as Z := X × Y , with dZ((x, y), (x′, y′)) := dX(x, x′) + dY (y, y′).
648"
REFERENCES,0.37755102040816324,"We claim that the following mapping
649"
REFERENCES,0.3779946761313221,(X × Y )2 = Z2 →R
REFERENCES,0.37843833185448095,"((x, y), (x′, y′)) 7→ϕ((x, y), (x′, y′)) := L(dq
X(x, x′), dq
Y (y, y′)) −2λ"
REFERENCES,0.37888198757763975,"is a Lipschitz function with respect to d+
Z,
where L satisfies (24).
Indeed,
given
650"
REFERENCES,0.3793256433007986,"((x1, y1), (x′
1, y′
1)), ((x2, y2), (x′
2, y′
2)) ∈Z2, we have:
651"
REFERENCES,0.3797692990239574,"|ϕ((x1, y1), (x′
1, y′
1)) −ϕ((x2, y2), (x′
2, y′
2))|"
REFERENCES,0.38021295474711625,"= |L(dX(x1, x′
1), dY (y1, y′
1)) −L(dX(x2, x′
2), dY (y2, y′
2))|"
REFERENCES,0.38065661047027505,"≤|L(dX(x1, x′
1), dY (y1, y′
1)) −L(dX(x2, x′
2), dY (y1, y′
1))|"
REFERENCES,0.3811002661934339,"+ |L(dX(x2, x′
2), dY (y1, y′
1)) −L(dX(x2, x′
2), dY (y2, y′
2))|"
REFERENCES,0.3815439219165927,"≤K|dq
X(x1, x′
1) −dq
X(x2, x′
2)| + K|dq
Y (y1, y′
1) −dq
Y (y2, y′
2)|"
REFERENCES,0.38198757763975155,"≤K′|dX(x1, x′
1) −dX(x2, x′
2)| + K′|dY (y1, y′
1) −dY (y2, y′
2)|
(31)"
REFERENCES,0.3824312333629104,"≤K′(dX(x1, x′
2) + dX(x′
1, x′
2)) + K′(dY (y1, y2) + dY (y′
1, y′
2))
(32)"
REFERENCES,0.3828748890860692,"= K′ [((dX(x1, x2) + dY (y1, y2)) + ((dX(x′
1, x′
2) + dY (y′
1, y′
2))]"
REFERENCES,0.38331854480922806,"= K′ [dZ((x1, y1), (x2, y2)) + dZ((x′
1, y′
1), (x′
2, y′
2))]"
REFERENCES,0.38376220053238685,"= K′d+
Z(((x1, y1), (x2, y2)), ((x1, y1), (x2, y2)))"
REFERENCES,0.3842058562555457,"where in (31), K′ = qβq−1K; the inequality holds by lemma C.2; The inequality (32) follows from
652"
REFERENCES,0.3846495119787045,"the triangle inequality:
653"
REFERENCES,0.38509316770186336,"dX(x1, x′
1) −dX(x2, x′
2) ≤dX(x1, x2) + dX(x2, x′
2) + dX(x′
2, x′
1) −dX(x2, x′
2)"
REFERENCES,0.38553682342502216,"= dX(x1, x2) + dX(x′
1, x′
2),"
REFERENCES,0.385980479148181,"and similarly,
dX(x2, x′
2) −dX(x1, x′
1) ≤dX(x1, x2) + dX(x′
1, x′
2)."
REFERENCES,0.38642413487133986,"Let M = Γ≤(µ, ν). From [53, Proposition B.1], we have that Γ≤(µ, ν) is a compact set with respect
654"
REFERENCES,0.38686779059449866,"to the weak convergence topology.
655"
REFERENCES,0.3873114463176575,"By Lemma (C.3) part (3), we have the PGW problem, which can be written as
656"
REFERENCES,0.3877551020408163,"inf
γ∈Γ≤(µ,ν) γ⊗2(ϕ) + λ(|µ|2 + |ν|2)"
REFERENCES,0.38819875776397517,"admits a solution, i.e., a minimizer γ ∈Γ≤(µ, ν). Therefore, we end the proof of Proposition 3.3.
657"
REFERENCES,0.38864241348713396,"D
Proof of Proposition 3.4: Metric Property of Partial GW
658"
REFERENCES,0.3890860692102928,"Let L(r1, r2) = Dp(r1, r2) for a metric D on R, and since all the metrics in R are equivalent, for
659"
REFERENCES,0.3895297249334516,"simplicity, consider D(r1, r2) = |r1 −r2|. (Notice that this satisfies the hypothesis of Proposition
660"
REFERENCES,0.38997338065661047,"H.1 used in the experiments).
661"
REFERENCES,0.3904170363797693,"Consider the GW problem, for q ≥1,
662"
REFERENCES,0.3908606921029281,"GW L
q (X, Y) :=
inf
γ∈Γ(µ,ν) Z"
REFERENCES,0.391304347826087,"(X×Y )2 L(dq
X(x, x′), dq
Y (y, y′)) dγ⊗2,
(33)"
REFERENCES,0.39174800354924577,"or, in particular,
663"
REFERENCES,0.3921916592724046,"GW p
q (X, Y) :=
inf
γ∈Γ(µ,ν) Z"
REFERENCES,0.3926353149955634,"(X×Y )2 |dq
X(x, x′) −dq
Y (y, y′)|p dγ⊗2.
(34)"
REFERENCES,0.3930789707187223,"For probability mm-spaces we have the equivalence relation X ∼Y if and only if GW p
q (X, Y) = 0.
664"
REFERENCES,0.3935226264418811,"By [8, Chapter 5], X ∼Y is equivalent to the following: there exists a bijective isometry mapping
665"
REFERENCES,0.3939662821650399,"ϕ : X →Y , such that
666"
REFERENCES,0.3944099378881988,"dX(x, x′) −dY (ϕ(x), ϕ(x′)) = 0,
µ⊗2 −a.s.
ϕ#µ = ν."
REFERENCES,0.3948535936113576,"Remark D.1. In the literature, the case where q = 1 is the most frequently considered problem. In
667"
REFERENCES,0.39529724933451643,"particular, in [8] it is stated the equivalence relation X ∼Y if and only if there exists ϕ : X →Y
668"
REFERENCES,0.39574090505767523,"such that ϕ#µ = ν and dX(x, x′) = dY (ϕ(x), ϕ(x′)) µ⊗2 −a.s. if and only if GW p
1 (X, Y) = 0.
669"
REFERENCES,0.3961845607808341,"Thus, X ∼Y is also equivalent to have ϕ : X →Y such that ϕ#µ = ν and dX(x, x′) = dY (y, y′)
670"
REFERENCES,0.3966282165039929,"γ⊗2 −a.s. where γ is a minimizer for GW p
1 (X, Y). So, in this situation we also have dq
X(x, x′) =
671"
REFERENCES,0.39707187222715173,"dq
Y (y, y′) γ⊗2 −a.s. for any given q ≥1. Therefore, X ∼Y if and only if GW p
q (X, Y) = 0.
672"
REFERENCES,0.39751552795031053,"D.1
Formal Statement of Proposition 3.4
673"
REFERENCES,0.3979591836734694,"We first introduce the formal statement of Proposition 3.4. To do so, we extend the equivalence relation
674"
REFERENCES,0.39840283939662824,"∼to all mm-spaces (not only probability mm-spaces): Given arbitrary mm-spaces X = (X, dX, µ),
675"
REFERENCES,0.39884649511978704,"Y = (Y, dY , ν), where X, Y are compact and µ ∈M+(X), ν ∈M+(Y ), we write X ∼Y if and
676"
REFERENCES,0.3992901508429459,"only if they have the same total mass (i.e., |µ| = µ(X) = ν(Y ) = |ν|) and GW p
q (X, Y) = 0.
677"
REFERENCES,0.3997338065661047,"Formal statement of Proposition 3.4: Given λ > 0, 1 ≤p, q < ∞, then (PGW p
λ,q(·, ·))1/p defines
678"
REFERENCES,0.40017746228926354,"a metric among mm-spaces under taking quotient with respect to the equivalence relation ∼.
679"
REFERENCES,0.40062111801242234,"Next, we discuss its proof.
680"
REFERENCES,0.4010647737355812,"D.2
Non-Negativity and Symmetry Properties
681"
REFERENCES,0.40150842945874,"It is straightforward to verify PGW p
λ,q(X, Y) ≥0, and that PGW p
λ,q(X, Y) = PGW p
λ,q(Y, X). In
682"
REFERENCES,0.40195208518189884,"what follows, we will concentrate on proving PGW p
λ,q(X, Y) = 0 if and only if X ∼Y:
683"
REFERENCES,0.4023957409050577,"If X ∼Y, then |µ| = |ν|, and we have"
REFERENCES,0.4028393966282165,"0 ≤PGW p
λ,q(X, Y) ≤GW p
q (X, Y) = 0,"
REFERENCES,0.40328305235137535,"where the inequality follows from the fact Γ(µ, ν) ⊆Γ≤(µ, ν). Thus, PGW p
λ,q(X, Y) = 0.
684"
REFERENCES,0.40372670807453415,"For the other direction, suppose that PGW p
λ,q(X, Y) = 0. We claim that |µ| = |ν| and that there exist
685"
REFERENCES,0.404170363797693,"an optimal plan γ for PGW p
λ,q(X, Y) such that |µ| = |γ| = |ν|. Let us prove this by contradiction.
686"
REFERENCES,0.4046140195208518,"Assume |µ| < |ν|. For convenience, suppose |µ|2 ≤|ν|2 −ϵ, for some ϵ > 0. Then, for each
687"
REFERENCES,0.40505767524401065,"γ ∈Γ≤(µ, ν), we have |γ⊗2| ≤|µ|2 ≤|ν|2 −ϵ, and so
688"
REFERENCES,0.40550133096716945,"PGW p
λ,q(X, Y) ≥λ(|µ|2 + |ν|2 −2|γ|2) ≥λ(|ν2| −|γ|2) ≥λϵ > 0."
REFERENCES,0.4059449866903283,"Thus, PGW p
λ,q(X, Y) > 0, which is a contradiction. So, |µ| = |ν|. In addition, if γ ∈Γ≤(µ, ν)
689"
REFERENCES,0.40638864241348716,"is optimal for PGW p
λ,q(X, Y), we have |γ| = |µ| = |ν|, thus γ ∈Γ(µ, ν). Therefore, since
690"
REFERENCES,0.40683229813664595,"PGW p
λ,q(X, Y) = 0, and for such optimal γ we have |γ| = |µ| = |ν|, we obtain
691 Z"
REFERENCES,0.4072759538598048,"(X×Y )2 |dq
X(x, x′) −dq
Y (y, y′)|pdγ⊗2 = 0."
REFERENCES,0.4077196095829636,"As a result, dq
X(x, x′) = dq
Y (y, y′) γ⊗2 −a.s., which implies that GW p
q (X, Y) = 0, and so X ∼Y.
692"
REFERENCES,0.40816326530612246,"D.3
Triangle Inequality – Strategy: Convert the PGW Problem into a GW Problem
693"
REFERENCES,0.40860692102928126,"Consider three arbitrary mm-spaces S = (S, dS, σ), X = (X, dX, µ), Y = (Y, dY , ν). We define
694"
REFERENCES,0.4090505767524401,"ˆS = ( ˆS, d ˆS, ˆσ), ˆX = ( ˆX, d ˆ
X, ˆµ), ˆY = ( ˆY , d ˆY , ˆν) in a similar way to that of Proposition G.1 but now
695"
REFERENCES,0.40949423247559896,"aiming to have new spaces with equal total mass:
696"
REFERENCES,0.40993788819875776,"First, introduce auxiliary points ˆ∞0, ˆ∞1, ˆ∞2 and set
697 

 
"
REFERENCES,0.4103815439219166,"ˆS
= S ∪{ ˆ∞0, ˆ∞1, ˆ∞2},
ˆX
= X ∪{ ˆ∞0, ˆ∞1, ˆ∞2},
ˆY
= Y ∪{ ˆ∞0, ˆ∞1, ˆ∞2}."
REFERENCES,0.4108251996450754,"Define ˆσ, ˆµ, ˆν as follows:
698

 "
REFERENCES,0.41126885536823427,"ˆσ
= σ + |µ|δ ˆ
∞1 + |ν|δ ˆ
∞2,
ˆµ
= µ + |σ|δ ˆ
∞0 + |ν|δ ˆ
∞2,
ˆν
= ν + |σ|δ ˆ
∞0 + |µ|δ ˆ
∞1.
(35)"
REFERENCES,0.41171251109139306,"Note that ˆσ is not supported on point ˆ∞0, similarly, ˆµ is not supported on ˆ∞1, ˆν is not supported
699"
REFERENCES,0.4121561668145519,"on ˆ∞2. In addition, we have |ˆµ| = |ˆν| = |ˆσ| = |µ| + |ν| + |σ|. (For a similar idea in classical
700"
REFERENCES,0.4125998225377107,"unbalanced optimal transport see, for example, [16].)
701"
REFERENCES,0.41304347826086957,"Finally, define d ˆS : ˆS2 →R ∪{∞} as follows:
702"
REFERENCES,0.4134871339840284,"d ˆS(s, s′) =
dS(s, s′)
if (s, s′) ∈S2,
∞
elsewhere.
(36)"
REFERENCES,0.4139307897071872,"Note, d ˆS(·, ·) is not a rigorous metric in ˆS since we allow d ˆS = ∞. Similarly, define d ˆ
X, d ˆY . As a
703"
REFERENCES,0.4143744454303461,"result, we have constructed new spaces
704"
REFERENCES,0.41481810115350487,"ˆS = ( ˆS, d ˆS, ˆσ),
ˆX = ( ˆX, d ˆ
X, ˆµ),
ˆY = ( ˆY , d ˆY , ˆν).
(37)"
REFERENCES,0.4152617568766637,"We define the following mapping Dλ : (R ∪{∞}) × (R ∪{∞}) →R+:
705"
REFERENCES,0.4157054125998225,"Dp
λ(r1, r2) = 
 "
REFERENCES,0.4161490683229814,"|r1 −r2|p
if r1, r2 < ∞,
λ
if r1 = ∞, r2 < ∞or vice versa,
0
if r1 = r2 = ∞.
(38)"
REFERENCES,0.4165927240461402,"Note that Dλ is not a rigorous metric since it may sometimes violate triangle inequality. See the
706"
REFERENCES,0.417036379769299,"following lemma for a detailed and precise explanation.
707"
REFERENCES,0.4174800354924579,"Lemma D.2. Let Dλ(·, ·) denote the function defined in (38). For any r0, r1, r2 ∈R ∪{∞}, we
708"
REFERENCES,0.4179236912156167,"have the following:
709"
REFERENCES,0.41836734693877553,"• Dλ(r1, r2) ≥0. Dλ(r1, r2) = 0 if and only if r1 = r2, where r1 = r2 denotes that
710"
REFERENCES,0.41881100266193433,"r1 = r2 ∈R or r1 = r2 = ∞.
711"
REFERENCES,0.4192546583850932,"• Except the case r1, r2 ∈R, r0 = ∞, for all other cases, we have"
REFERENCES,0.419698314108252,"Dλ(r1, r2) ≤Dλ(r1, r0) + Dλ(r2, r0)."
REFERENCES,0.42014196983141083,"Proof of Lemma D.2. It is straightforward to verify Dλ(·, ·) ≥0.
712"
REFERENCES,0.42058562555456963,"Now, consider r0, r1, r2 ∈R ∪{∞}. If r1 = r2 ∈R or r1 = r2 = ∞, we have Dλ(r1, r2) = 0.
713"
REFERENCES,0.4210292812777285,"Otherwise, Dλ(r1, r2) > 0. So, Dλ(r1, r2) = 0 if and only if r1 = r2.
714"
REFERENCES,0.42147293700088734,"For the second item, we have the following cases:
715"
REFERENCES,0.42191659272404614,"Case 1: r1, r2, r0 ∈R,
716"
REFERENCES,0.422360248447205,"Dλ(r1, r2) = |r1 −r2|
≤|r1 −r2| + |r2 −r0|
= Dλ(r0, r1) + Dλ(r0, r2)"
REFERENCES,0.4228039041703638,"Case 2: r1, r2 ∈R, r0 = ∞. We do not need to verify the inequality in this case.
717"
REFERENCES,0.42324755989352264,"Case 3: r1 ∈R, r2, r0 = ∞, or r1 = ∞, r2 ∈R, r0 = ∞. In this case, we have
718"
REFERENCES,0.42369121561668144,"Dλ(r1, r2) = Dλ(r1, r0) =
√"
REFERENCES,0.4241348713398403,"λ, Dλ(r2, r0) = 0"
REFERENCES,0.4245785270629991,"and it is straightforward to verify the inequality.
719"
REFERENCES,0.42502218278615794,"Case 4: r1, r2 = ∞, r3 ∈R. In this case, we have Dλ(r1, r2) = 0 ≤Dλ(r0, r1) + Dλ(r0, r2).
720"
REFERENCES,0.4254658385093168,"Case 5: r1, r2, r0 = ∞. In this case, we have
721"
REFERENCES,0.4259094942324756,"Dλ(r1, r2) = Dλ(r1, r0) = Dλ(r2, r0) = 0"
REFERENCES,0.42635314995563445,"and it is straightforward to verify the inequality.
722"
REFERENCES,0.42679680567879325,"We construct the following generalized GW problem:
723"
REFERENCES,0.4272404614019521,"GW p
λ,q(ˆX, ˆY) :=
inf
ˆγ∈Γ(ˆµ,ˆν) Z"
REFERENCES,0.4276841171251109,"( ˆ
X× ˆY )2 Dp
λ(dq
ˆ
X(x, x′), dq
ˆY (y, y′)) dˆγ⊗2"
REFERENCES,0.42812777284826975,"|
{z
}
ˆ
C(ˆγ;λ,ˆµ,ˆν)"
REFERENCES,0.42857142857142855,".
(39)"
REFERENCES,0.4290150842945874,"Similarly, we define GW p
λ,q(ˆX, ˆS), and GW p
λ,q(ˆS, ˆY).
724"
REFERENCES,0.42945874001774625,"The mapping (6) is modified as:
725"
REFERENCES,0.42990239574090505,"Γ≤(σ, µ) ∋γ01 7→ˆγ01 ∈Γ(ˆσ, ˆµ),"
REFERENCES,0.4303460514640639,"ˆγ01 := γ01 + (σ −γ01
1 ) ⊗δ ˆ
∞0 + δ ˆ
∞1 ⊗(µ −γ01
2 ) + |γ|δ ˆ
∞1, ˆ
∞0 + |ν|δ ˆ
∞2, ˆ
∞2;"
REFERENCES,0.4307897071872227,"Γ≤(σ, ν) ∋γ02 7→ˆγ02 ∈Γ(ˆσ, ˆν),"
REFERENCES,0.43123336291038156,"ˆγ02 := γ02 + (σ −γ02
1 ) ⊗δ ˆ
∞0 + δ ˆ
∞2 ⊗(ν −γ02
2 ) + |γ|δ ˆ
∞2, ˆ
∞0 + |µ|δ ˆ
∞1, ˆ
∞1;"
REFERENCES,0.43167701863354035,"Γ≤(µ, ν) ∋γ12 7→ˆγ12 ∈Γ(ˆµ, ˆν),"
REFERENCES,0.4321206743566992,"ˆγ12 := γ12 + (µ −γ12
1 ) ⊗δ ˆ
∞1 + δ ˆ
∞2 ⊗(ν −γ12
2 ) + |γ|δ ˆ
∞2, ˆ
∞1 + |µ|δ ˆ
∞0, ˆ
∞0.
(40)"
REFERENCES,0.432564330079858,"It is straightforward to verify the above mappings are well-defined. In addition, we can observe that,
726"
REFERENCES,0.43300798580301686,"for each γ01 ∈Γ≤(σ, µ), γ02 ∈Γ≤(σ, ν), γ12 ∈Γ≤(µ, ν),
727"
REFERENCES,0.4334516415261757,"ˆγ01({ ˆ∞2} × X) = ˆγ01(S × { ˆ∞2}) = 0,
(41)"
REFERENCES,0.4338952972493345,"ˆγ02({ ˆ∞1} × Y ) = ˆγ02(S × { ˆ∞1}) = 0,
(42)"
REFERENCES,0.43433895297249336,ˆγ12({ ˆ∞0} × Y ) = ˆγ12(X × { ˆ∞0}) = 0.
REFERENCES,0.43478260869565216,"Proposition D.3. If γ12 ∈Γ≤(µ, ν) is optimal in PGW problem PGW p
λ,q(X, Y), then ˆγ12 defined
in (40) is optimal in generalized GW problem GW p
λ,q(ˆX, ˆY). Furthermore, ˆC(ˆγ12; λ, ˆµ, ˆν) =
C(γ12; λ, µ, ν), and thus,"
REFERENCES,0.435226264418811,"PGW p
λ,q(X, Y) = GW p
λ,q(ˆX, ˆY)."
REFERENCES,0.4356699201419698,"Proof of Proposition D.3. For each γ ∈Γ≤(µ, ν), define ˆγ by (40).
728"
REFERENCES,0.43611357586512867,"Note that if we merge the points ˆ∞1, ˆ∞2, ˆ∞3 as ˆ∞, i.e."
REFERENCES,0.43655723158828746,"ˆ∞= ˆ∞1 = ˆ∞2 = ˆ∞3,"
REFERENCES,0.4370008873114463,"the value ˆC(ˆγ; λ, ˆµ, ˆν) will not change. Thus, we merge these three auxiliary points.
729"
REFERENCES,0.43744454303460517,"We have:
730"
REFERENCES,0.43788819875776397,"ˆC(ˆγ; λ, ˆµ, ˆν) =
Z"
REFERENCES,0.4383318544809228,"( ˆ
X× ˆY )2 Dp
λ(dq
ˆ
X(x, x′), dq
ˆY (x, x′))dˆγ⊗2 =
Z"
REFERENCES,0.4387755102040816,"(X×Y )2 |dq
X(x, x′) −dq
Y (y, y′)|pdˆγ⊗2 +
Z"
REFERENCES,0.4392191659272405,"({ ˆ
∞}×Y )2 λdˆγ⊗2 +
Z"
REFERENCES,0.43966282165039927,"(X×{ ˆ
∞})2 λˆγ⊗2 + 2
Z"
REFERENCES,0.4401064773735581,"({ ˆ
∞}×Y )×(X×Y )
λdˆγ⊗2 + 2
Z"
REFERENCES,0.4405501330967169,"(X×{ ˆ
∞})×(X×Y )
λdˆγ⊗2 +
Z"
REFERENCES,0.4409937888198758,"({ ˆ
∞}×{ ˆ
∞})2 Dp
λ(∞, ∞)dˆγ⊗2 + 2
Z"
REFERENCES,0.44143744454303463,"({ ˆ
∞}×Y )×(X×{ ˆ
∞})
Dp
λ(∞, ∞)dˆγ⊗2 + 2
Z"
REFERENCES,0.4418811002661934,"({ ˆ
∞}×{ ˆ
∞})×(X×Y )
Dp
λ(∞, ∞)dˆγ⊗2 + 2
Z"
REFERENCES,0.4423247559893523,"({ ˆ
∞}×{Y })×{ ˆ
∞}2 Dp
λ(∞, ∞)dˆγ⊗2 + 2
Z"
REFERENCES,0.4427684117125111,"(X×{ ˆ
∞})×{ ˆ
∞}2 Dp
λ(∞, ∞)dˆγ⊗2 =
Z"
REFERENCES,0.44321206743566993,"(X×Y )2 |dq
X(x, x′) −dq
Y (y, y′)|pdγ⊗2"
REFERENCES,0.44365572315882873,"+ 2λ(|ν| −|γ|)|γ| + λ(|ν| −|γ|)2 + 2λ(|µ| −|γ|)|γ| + λ(|µ| −|γ|)2 =
Z"
REFERENCES,0.4440993788819876,"(X×Y )2 |dq
X(x, y′) −dq
Y (y, y′)|p dγ⊗2) + λ(|ν2| + |µ|2 −2|γ|2) = C(γ; λ, µ, ν)."
REFERENCES,0.4445430346051464,"As we merged the points ˆ∞1, ˆ∞2, ˆ∞3, by [40, Proposition B.1.], the mapping γ 7→ˆγ defined in (40)
is a bijection. Then, if γ ∈Γ≤(µ, ν) is optimal for the PGW problem PGW p
λ,q(X, Y) (defined in
(10)), ˆγ ∈Γ(ˆµ, ˆν) is optimal for generalized GW problem GW p
λ,q(ˆX, ˆY) (defined in (39)). Therefore,"
REFERENCES,0.44498669032830523,"GW p
λ,q(ˆX, ˆY) = PGW p
λ,q(X, Y). 731"
REFERENCES,0.4454303460514641,"Proposition D.4 (Triangle inequality for GW p
λ,q(·, ·)). Consider the generalized GW problem (39).
Then, for any p ∈[1, ∞), we have"
REFERENCES,0.4458740017746229,"GW p
λ,q(ˆX, ˆY) ≤GW p
λ,q(ˆS, ˆX) + GW p
λ,q(ˆS, ˆY)."
REFERENCES,0.44631765749778174,"Proof of Proposition D.4. We prove the case p = 2. For general p ≥1, it can be proved similarly.
732"
REFERENCES,0.44676131322094054,"Choose an optimal γ12
∈Γ≤(µ, ν) for PGW 2
λ,q(X, Y), an optimal γ01
∈Γ≤(σ, µ) for
733"
REFERENCES,0.4472049689440994,"PGW 2
λ,q(S, X), and an optimal γ02 ∈Γ≤(σ, ν) for PGW 2
λ,q(S, Y). Construct ˆγ12, ˆγ01, ˆγ02 by
734"
REFERENCES,0.4476486246672582,"(40).
735"
REFERENCES,0.44809228039041704,"By Proposition D.3, we have that ˆγ12, ˆγ01, ˆγ02 are optimal for GW 2
λ,q(ˆX, ˆY), GW 2
λ,q(ˆS, ˆX),
736"
REFERENCES,0.44853593611357584,"GW 2
λ,q(ˆS, ˆY), respectively.
737"
REFERENCES,0.4489795918367347,"Define canonical projection mapping
738"
REFERENCES,0.44942324755989355,"π0,1 :( ˆS × ˆX × ˆY ) →( ˆS × ˆX)
(s, x, y) 7→(s, x)."
REFERENCES,0.44986690328305234,"Similarly, we define π0,2, π1,2.
739"
REFERENCES,0.4503105590062112,"By gluing lemma (see Lemma 5.5 [54]), there exists ˆγ ∈M+( ˆS × ˆX × ˆY ), such that (π0,1)#ˆγ =
740"
REFERENCES,0.45075421472937,"ˆγ01, (π0,2)#ˆγ = ˆγ02. Thus, (π1,2)#ˆγ is a coupling between ˆµ, ˆν. We have
741"
REFERENCES,0.45119787045252885,"GW 2
λ,q(X, Y) =
Z"
REFERENCES,0.45164152617568765,"( ˆ
X× ˆY )2 D2
λ(dq
ˆ
X(x, x′), dq
ˆY (y, y′))d(ˆγ12)⊗2 ≤
Z"
REFERENCES,0.4520851818988465,"( ˆS× ˆ
X× ˆY )2 D2
λ(dq
ˆ
X(x, x′), dq
ˆY (y, y′))dˆγ⊗2.
(43)"
REFERENCES,0.4525288376220053,"The inequality holds since (π1,2)#ˆγ, ˆγ12 ∈Γ(ˆµ, ˆν), and ˆγ12 is optimal.
742"
REFERENCES,0.45297249334516415,"Next, we will show that
743 Z"
REFERENCES,0.453416149068323,"( ˆS× ˆ
X× ˆY )2 D2
λ(dq
ˆ
X(x, x′), dq
ˆY (y, y′))dˆγ⊗2 ≤
Z"
REFERENCES,0.4538598047914818,"( ˆS× ˆ
X× ˆY )2(Dλ(dq
ˆS(s, s′), dq
ˆ
X(x, x′)) + Dλ(dq
ˆS(s, s′), dq
ˆY (y, y′)))2dˆγ⊗2."
REFERENCES,0.45430346051464066,"Let ((s, x, y), (s′, x′, y′)) ∈( ˆS, ˆX, ˆY )2, and assume that
744"
REFERENCES,0.45474711623779945,"Dλ(d2
ˆ
X(x, x′), d2
ˆY (y, y′)) > Dλ(d2
ˆS(s, s′), d2
ˆ
X(x, x′)) + Dλ(d2
ˆS(s, s′), d2
ˆY (y, y′)).
(44)"
REFERENCES,0.4551907719609583,"By Lemma D.2, (44) implies d ˆ
X(x, x′), d ˆY (y, y′) ∈R, d ˆS(s, s′) = ∞. Thus, by definition (36), it
745"
REFERENCES,0.4556344276841171,"also implies
746"
REFERENCES,0.45607808340727596,"(x, x′) ∈X2, (y, y′) ∈Y 2, (s, s′) ∈ˆS2 \ S2.
(45)"
REFERENCES,0.45652173913043476,"Define the following sets:
747"
REFERENCES,0.4569653948535936,"Aα = ˆS × X × Y,
A0 = { ˆ∞0} × X × Y,
A1 = { ˆ∞1} × X × Y,
A2 = { ˆ∞2} × X × Y."
REFERENCES,0.45740905057675246,"Notice that, (44) =⇒(45) is equivalent to
748"
REFERENCES,0.45785270629991126,"(44) =⇒((s, x, y), (s, x′, y′)) ∈A := 2["
REFERENCES,0.4582963620230701,"i=0
(Ai × Aα) ∪ 2["
REFERENCES,0.4587400177462289,"i=0
(Aα × Ai).
(46)"
REFERENCES,0.45918367346938777,"Next, we will show ˆγ⊗2(A) = 0. Indeed,
749"
REFERENCES,0.45962732919254656,"ˆγ(A0) ≤ˆγ({∞0} × ˆX × ˆY ) = ˆσ({∞0}) = 0
by definition (35) of ˆσ ,"
REFERENCES,0.4600709849157054,"ˆγ(A1) ≤ˆγ({∞1} × ˆX × Y ) = ˆγ02({ ˆ∞1 × Y }) = 0
by (42),"
REFERENCES,0.4605146406388642,"ˆγ(A2) ≤ˆγ({∞2} × X × ˆY ) = ˆγ01({ ˆ∞2 × X}) = 0
by (41)."
REFERENCES,0.46095829636202307,"Thus, ˆγ⊗2(A) = 0. By considering B = ( ˆS × ˆX × Y )2 \ A, we obtain
750 Z"
REFERENCES,0.4614019520851819,"( ˆS× ˆ
X× ˆY )2 D2
λ(dq
ˆ
X(x, x′), dq
ˆY (y, y′))dγ⊗2 =
Z"
REFERENCES,0.4618456078083407,"B
D2
λ(dq
ˆ
X(x, x′), dq
ˆY (y, y′))dγ⊗2
since γ⊗2(A) = 0 ≤
Z B"
REFERENCES,0.4622892635314996,"
Dλ(dq
ˆS(s, s′), dq
ˆ
X(x, x′) + Dλ(dq
ˆS(s, s′), dq
ˆY (y, y′))
2
dγ⊗2
by (46) ≤
Z"
REFERENCES,0.46273291925465837,"( ˆS× ˆ
X× ˆY )2"
REFERENCES,0.4631765749778172,"
Dλ(dq
ˆS(s, s′), dq
ˆ
X(x, x′) + Dλ(dq
ˆS(s, s′), dq
ˆY (y, y′))
2
dγ⊗2.
(47)"
REFERENCES,0.463620230700976,"Following (43) and (47), we have
751"
REFERENCES,0.4640638864241349,"GW 2
λ,q(ˆX, ˆY) ≤ Z"
REFERENCES,0.4645075421472937,"( ˆS× ˆ
X× ˆY )2 D2
λ(dq
ˆ
X(x, x′), dq
ˆY (y, y′))dˆγ⊗2
!1/2 ≤ Z"
REFERENCES,0.4649511978704525,"( ˆS× ˆ
X× ˆY )2"
REFERENCES,0.4653948535936114,"
Dλ(dq
ˆS(s, s′), dq
ˆ
X(x, x′)) + Dλ(dq
ˆS(s, s′), dq
ˆY (y, y′))
2
dγ⊗2
!1/2 ≤ Z"
REFERENCES,0.4658385093167702,"( ˆS× ˆ
X× ˆY )2 D2
λ(dq
ˆS(s, s′), dq
ˆ
X(x, x′))dγ⊗2
!1/2 + Z"
REFERENCES,0.46628216503992903,"( ˆS× ˆ
X× ˆY )2 D2
λ(dq
ˆS(s, s′), dq
ˆY (y, y′))dγ⊗2
!1/2 (48) = Z"
REFERENCES,0.46672582076308783,"( ˆS× ˆ
X× ˆY )2 D2
λ(dq
ˆS(s, s′), dq
ˆ
X(x, x′))d(γ01)⊗2
!1/2 + Z"
REFERENCES,0.4671694764862467,"( ˆS× ˆ
X× ˆY )2 D2
λ(dq
ˆS(s, s′), dq
ˆY (y, y′))d(γ02)⊗2
!1/2"
REFERENCES,0.4676131322094055,"= GW 2
λ,q(ˆS, ˆX) + GW 2
λ,q(ˆS, ˆY),"
REFERENCES,0.46805678793256433,"where in the third inequality (48) we used the Minkowski inequality in L2(( ˆS × ˆX × ˆY )2, ˆγ⊗2).
752"
REFERENCES,0.46850044365572313,"Now, we can complete the proof of Proposition 3.4: By the Propositions D.3, we have"
REFERENCES,0.468944099378882,"PGW p
λ,q(X, Y) = GW p
λ,q(ˆX, ˆY)"
REFERENCES,0.46938775510204084,"and similarly for PGW p
λ,q and (S, X), PGW p
λ,q(S, Y). By the Proposition D.4, GW p
λ,q(·, ·) satisfies
753"
REFERENCES,0.46983141082519964,"the triangle inequality, thus we complete the proof:
754"
REFERENCES,0.4702750665483585,"PGW p
λ,q(X, Y) = GW p
λ,q(ˆX, ˆY)"
REFERENCES,0.4707187222715173,"≤GW p
λ,q(ˆS, ˆX) + GW p
λ,q(ˆS, ˆY)"
REFERENCES,0.47116237799467614,"= PGW p
λ,q(S, X) + PGW p
λ,q(S, Y)."
REFERENCES,0.47160603371783494,"E
Proof of Proposition 3.5: PGW converges to GW as λ →∞.
755"
REFERENCES,0.4720496894409938,"In the main text, we set λ ∈R. In this section, we discuss the limit case that when λ →∞.
756"
REFERENCES,0.47249334516415264,"Lemma E.1. Suppose |µ| ≤|ν|, for each γ ∈Γ≤(µ, ν), there exists γ′ ∈Γ≤(µ, ν) such that γ ≤γ′
757"
REFERENCES,0.47293700088731144,"and (π1)#γ′ = µ.
758"
REFERENCES,0.4733806566104703,"Proof. Let γ ∈Γ≤(µ, ν).
759"
REFERENCES,0.4738243123336291,"If |γ| = |µ|, then we have (π1)#γ = µ.
760"
REFERENCES,0.47426796805678795,"If |γ| < |µ|, let µr = µ−(π1)#γ, νr = ν −(π2)#γ. We have that µr, νr are non-negative measures,
761"
REFERENCES,0.47471162377994675,"with |µr| = |µ| −|γ| > 0. If we define
762"
REFERENCES,0.4751552795031056,"γ′ := γ +
1
|ν| −|γ|µr ⊗νr,"
REFERENCES,0.4755989352262644,"we obtain γ ≤γ′. In addition, we have:
763"
REFERENCES,0.47604259094942325,"(π1)#γ′ = (π1)#γ + µr
|νr|
|ν| −|γ| = (π1)#γ + µr = µ,"
REFERENCES,0.4764862466725821,"(π2)#γ′ = (π2)#γ + νr
|µr|
|ν| −|γ| ≤(π2)#γ + νr
|νr|
|ν| −|γ| = ν."
REFERENCES,0.4769299023957409,"Thus, γ′ ∈Γ≤(µ, ν) and (π1)#γ′ = µ.
764"
REFERENCES,0.47737355811889975,"Lemma E.2. Given general mm-spaces X = (X, dX, µ), Y = (Y, dY , ν), where µ, ν are supported
765"
REFERENCES,0.47781721384205855,"on bounded sets (in general, it is assumed that X and Y are compact, and that supp(µ) = X,
766"
REFERENCES,0.4782608695652174,"supp(ν) = Y ), consider the problem the problem PGW L
λ,q(X, Y) with L(r1, r2) a continuous
767"
REFERENCES,0.4787045252883762,"functions. If λ is sufficiently large, for all optimal γ ∈Γ≤(µ, ν) we have |γ| = min(|µ|, |ν|).
768"
REFERENCES,0.47914818101153506,"Proof. We prove it for q = 1, for a general q ≥1, it can be proved similarly.
769"
REFERENCES,0.47959183673469385,"Without loss of generality, suppose |µ| ≤|ν|.
770"
REFERENCES,0.4800354924578527,"Since µ, ν are supported on bounded sets, there exists A = [0, M] such that dX(x, x′), dY (y, y′) ∈A
771"
REFERENCES,0.48047914818101156,"for all x, x′ ∈supp(µ), y, y′ ∈supp(ν).
772"
REFERENCES,0.48092280390417036,"Thus, the restriction of L on A2, denoted as LA2, is continuous on A2, and thus it is bounded. So,
consider"
REFERENCES,0.4813664596273292,"m := max
r1,r2∈A(L(r1, r2)) ≥L(dX(x, x′), dY (y, y′)),
∀x, x′ ∈supp(µ), y, y′ ∈supp(ν)."
REFERENCES,0.481810115350488,"Suppose 2λ ≥m + 1, and assume that there exists a optimal γ ∈Γ≤(µ, ν) such that |γ| < |µ|. By
773"
REFERENCES,0.48225377107364686,"Lemma E.1, there exists γ′ such that γ ≤γ′, (π1)#γ′ = µ. Thus, we have
774"
REFERENCES,0.48269742679680566,"C(γ′; λ, µ, ν) −C(γ; λ, µ, ν) =
Z"
REFERENCES,0.4831410825199645,"(X×Y )
L(dX(x, x′), dY (y, y′)) −2λ d((γ′)⊗2 −(γ)⊗2) ≤
Z"
REFERENCES,0.4835847382431233,"(X×Y )
m −2λ d((γ′)⊗2 −(γ)⊗2)"
REFERENCES,0.48402839396628217,"= −(|γ′|2 −|γ|2) = −(|µ|2 −|γ|2) < 0,"
REFERENCES,0.484472049689441,"which is contradiction since γ is optimal, and so we have completed the proof.
775"
REFERENCES,0.4849157054125998,"Lemma E.3. Consider probability mm-spaces X = (X, dX, µ), Y = (Y, dY , ν), that is, with
776"
REFERENCES,0.48535936113575867,"|µ| = |ν| = 1. Then, for each λ > 0, we have
777"
REFERENCES,0.48580301685891747,"PGW L
λ,q(X, Y) ≤GW L
q (X, Y)."
REFERENCES,0.4862466725820763,"Proof. In this setting, we have Γ(µ, ν) ⊂Γ≤(µ, ν), and thus
778"
REFERENCES,0.4866903283052351,"PGW L
λ,q(X, Y)"
REFERENCES,0.487133984028394,"=
inf
Γ∈Γ≤(µ,ν) Z"
REFERENCES,0.48757763975155277,"(X×Y )2 L(dq
X(x, x′), dq
Y (y, y′))dγ⊗2 + λ(|µ|2 + |ν|2 −2|γ|2)"
REFERENCES,0.4880212954747116,"≤
inf
γ∈Γ(µ,ν) Z"
REFERENCES,0.4884649511978705,"(X×Y )2 L(dq
X(x, x′), dq
Y (y, y′)) + λ(|µ|2 + |ν|2 −2|γ|2)dγ⊗2"
REFERENCES,0.4889086069210293,"=
inf
γ∈Γ(µ,ν) Z"
REFERENCES,0.48935226264418813,"(X×Y )2 L(dq
X(x, x′), dq
Y (y, y′))dγ⊗2"
REFERENCES,0.4897959183673469,"= GW L
q (X, Y). 779"
REFERENCES,0.4902395740905058,"Based on the above properties, we can now prove Proposition 3.5:
780"
REFERENCES,0.4906832298136646,"Proposition E.4 (Generalization of Proposition 3.5). Consider general probability mm-spaces
X = (X, dX, µ), Y = (Y, dY , ν), that is, with |µ| = |ν| = 1, where X, Y are bounded. Assume that
L is continuous. Then
lim
λ→∞PGW L
λ,q(X, Y) = GW L
q (X, Y)."
REFERENCES,0.49112688553682343,"Proof. When λ is sufficiently large, by Lemma E.2, for each optimal γλ ∈Γ≤(µ, ν) of the minimiza-
781"
REFERENCES,0.49157054125998223,"tion problem PGW L
λ,q(X, Y), we have |γλ| = min(|µ|, |ν|) = 1. That is, γλ ∈Γ(µ, ν). Plugging
782"
REFERENCES,0.4920141969831411,"γλ into C(γλ; λ, µ, ν), we obtain:
783"
REFERENCES,0.49245785270629994,"PGW L
λ,q(X, Y) =
Z"
REFERENCES,0.49290150842945873,"(X×Y )2 L(dq
X(x, x′), dq
Y (y, y′))dγ⊗2
λ
+ λ(12 + 12 −2 · 12) =
Z"
REFERENCES,0.4933451641526176,"(X×Y )2 L(dq
X(x, x′), dq
Y (y, y′))dγ⊗2
λ
≥GW(X, Y)."
REFERENCES,0.4937888198757764,"By Lemma E.3, we also have PGW L
λ,q(X, Y) ≤GW L
q (X, Y) and we complete the proof.
784"
REFERENCES,0.49423247559893524,"F
Tensor Product Computation
785"
REFERENCES,0.49467613132209404,"Lemma F.1. Given a tensor M ∈Rn×m×n×n and γ, γ′ ∈Rn×m, the tensor product operator
786"
REFERENCES,0.4951197870452529,"M ◦γ satisfies the following:
787"
REFERENCES,0.4955634427684117,"(i) The mapping γ 7→M ◦γ is linear with respect to γ.
788"
REFERENCES,0.49600709849157054,"(ii) If M is symmetric, in particular, Mi,j,i′,j′ = Mi′,j′,i,j, ∀i, i′ ∈[1 : n], j, j′ ∈[1 : m], then"
REFERENCES,0.4964507542147294,"⟨M ◦γ, γ′⟩F = ⟨M ◦γ′, γ⟩F ."
REFERENCES,0.4968944099378882,"Proof.
789"
REFERENCES,0.49733806566104705,"(i) For the first part, consider γ, γ′ ∈Rn×m and k ∈R. For each i, j ∈[1 : n] × [1 : m], we
790"
REFERENCES,0.49778172138420584,"have we have
791"
REFERENCES,0.4982253771073647,"(M ◦(γ + γ′))ij =
X"
REFERENCES,0.4986690328305235,"i′,j′
Mi,j,i′,j′(γ + γ′)i′j′ =
X"
REFERENCES,0.49911268855368235,"i′,j′
Mi,j,i′,j′γi′j′ +
X"
REFERENCES,0.49955634427684115,"i′,j′
Mi,j,i′,j′γ′
i′j′"
REFERENCES,0.5,"= (M ◦γ)ij + (M ◦γ)i′j′,"
REFERENCES,0.5004436557231589,"(M ◦(kγ))ij =
X"
REFERENCES,0.5008873114463177,"i′,j′
Mi,j,i′,j′(kγ)ij = k
X"
REFERENCES,0.5013309671694764,"i′,j′
Mi,j,i′,j′γij"
REFERENCES,0.5017746228926353,= k(M ◦γ)ij.
REFERENCES,0.5022182786157942,"Thus, M ◦(γ + γ′) = M ◦γ + M ◦γ′ and M ◦(kγ) = kM ◦γ. Therefore, γ 7→M ◦γ is
792"
REFERENCES,0.502661934338953,"linear.
793"
REFERENCES,0.5031055900621118,"(ii) For the second part, we have
794"
REFERENCES,0.5035492457852706,"⟨M ◦γ, γ′⟩F =
X"
REFERENCES,0.5039929015084295,"iji′j′
Mi,j,i′,j′,γijγ′
i′j′ =
X"
REFERENCES,0.5044365572315883,"i,j,i′,j′
Mi′,j′,i,jγi′,j′γi,j
(49)"
REFERENCES,0.5048802129547472,"= ⟨Mγ′, γ⟩"
REFERENCES,0.5053238686779059,"where (49) follows from the fact that M is symmetric.
795 796"
REFERENCES,0.5057675244010648,"G
Another Algorithm for Computing PGW Distance – Solver 2
797"
REFERENCES,0.5062111801242236,"Our Algorithm 2 for solving the proposed PGW problem is based on a theoretical result that relates
798"
REFERENCES,0.5066548358473825,"GW and PGW. The details of our computational method, as well as the proof of Proposition G.1 stated
799"
REFERENCES,0.5070984915705412,"below, are provided in Appendix G.1. Based on such proposition, we extend the PGW problem to a
800"
REFERENCES,0.5075421472937001,"discrete GW-variant problem (55), leading to a solution for the original PGW problem by truncating
801"
REFERENCES,0.5079858030168589,"the GW-variant solution.
802"
REFERENCES,0.5084294587400178,"Proposition G.1. Let X = (X, dX, µ) be a mm-space. Consider an auxiliary point ˆ∞and let
803"
REFERENCES,0.5088731144631766,"ˆX = ( ˆX, d ˆ
X, ˆµ), where ˆX = X ∪{ ˆ∞}, ˆµ is constructed by (4), and considering ∞as an auxiliary
804"
REFERENCES,0.5093167701863354,"point to R such that x ≤∞for every x ∈R, we extend dX into d ˆ
X : ˆX2 →R ∪{∞} and define
805"
REFERENCES,0.5097604259094942,"Lλ : R ∪{∞} →R as follows:
806"
REFERENCES,0.5102040816326531,"d ˆ
X(x, x′) =
dX(x, x′)
if x, x′ ∈X
∞
otherwise
, Lλ(r1, r2) :=
L(r1, r2) −2λ
if r1, r2 ∈R
0
elsewhere
.
(50)"
REFERENCES,0.5106477373558119,"Consider the following GW-variant2 problem:
807"
REFERENCES,0.5110913930789707,"d
GW
Lλ(ˆX, ˆY) =
inf
ˆγ∈Γ(ˆµ,ˆν)ˆγ⊗2(Lλ(dq
ˆ
X, dq
ˆY ))
(51)"
REFERENCES,0.5115350488021295,"Then, when considering the bijection γ 7→ˆγ defined in (6) we have that γ is optimal for PGW
808"
REFERENCES,0.5119787045252884,"problem (10) if and only if ˆγ is optimal for the GW-variant problem (51).
809"
REFERENCES,0.5124223602484472,"Proof. The mapping F defined by (6) well-defined bijection, as shown in[40, 12].
810"
REFERENCES,0.5128660159716061,"Given γ ∈Γ≤(µ, ν), we have ˆγ = F(γ) ∈Γ(ˆµ, ˆν). Let ˆC(ˆγ; µ, ν) denote the transportation cost in
811"
REFERENCES,0.5133096716947648,"the GW-variant problem (51), that is,
812"
REFERENCES,0.5137533274179237,"ˆC(ˆγ; µ, ν) :=
Z"
REFERENCES,0.5141969831410825,"( ˆ
X× ˆY )2 Lλ(dq
ˆ
X(x, x′), dq
ˆY (y, y′)) dˆγ(x, y)dˆγ(x′, y′)"
REFERENCES,0.5146406388642414,"Then, we have
813"
REFERENCES,0.5150842945874001,"C(γ; λ, µ, ν) =
Z"
REFERENCES,0.515527950310559,"(X×Y )2(L(dq
X(x, x′), dq
Y (y, y′)) −2λ) dγ⊗2 +
λ(|µ| + |ν|)
|
{z
}
does not depend on γ =
Z"
REFERENCES,0.5159716060337178,"(X×Y )2(L(dq
X(x, x′), dq
Y (y, y′)) −2λ) dˆγ⊗2 + λ(|µ| + |ν|)
(since ˆγ|X×Y = γ) =
Z"
REFERENCES,0.5164152617568767,"(X×Y )2(L(dq
ˆ
X(x, x′), dq
ˆY (y, y′)) −2λ) dˆγ⊗2 + λ(|µ| + |ν|)
(as d ˆ
X|X×X = dX, d ˆY |Y ×Y = dY ) =
Z"
REFERENCES,0.5168589174800355,"(X×Y )2 Lλ(dq
ˆ
X(x, x′), dq
ˆY (y, y′)) dˆγ⊗2 + λ(|µ| + |ν|)
(since ˆL|R×R(·, ·) = (L(·, ·) −2λ)) =
Z"
REFERENCES,0.5173025732031943,"( ˆ
X× ˆY )2 Lλ(dq
ˆ
X(x, x′), dq
ˆY (y, y′)) dˆγ⊗2 +
λ(|µ| + |ν|)
|
{z
}
does not depend on ˆγ"
REFERENCES,0.5177462289263531,".
(since ˆL assigns 0 to ˆ∞)"
REFERENCES,0.518189884649512,"Combining this with the fact that F : γ 7→ˆγ is a bijection, we have that γ is optimal for (10) if
814"
REFERENCES,0.5186335403726708,"and only if ˆγ is optimal for (51). Under the assumptions of Proposition 3.3, there exists an optimal
815"
REFERENCES,0.5190771960958296,"γ ∈Γ≤(µ, ν) for the PGW problem exists, and so we have:
816"
REFERENCES,0.5195208518189884,"arg
min
ˆγ∈Γ(ˆµ,ˆν)
ˆC(ˆγ; µ, ν) = arg
min
γ∈Γ≤(µ,ν) C(γ; λ, µ, ν).
(52) 817"
REFERENCES,0.5199645075421473,"Remark G.2. Both algorithms (Algorithm 1, and 2) are mathematically and computationally
818"
REFERENCES,0.5204081632653061,"equivalent, owing to the equivalence between the POT problem in Solver 1 and the OT problem in
819"
REFERENCES,0.520851818988465,"Solver 2.
820"
REFERENCES,0.5212954747116237,"G.1
Frank-Wolfe for the PGW Problem – Solver 2
821"
REFERENCES,0.5217391304347826,"Similarly to the discrete PGW problem (15), consider the discrete version of (4):
822"
REFERENCES,0.5221827861579414,"ˆp = [p; |q|] ∈Rn+1,
ˆq = [q; |p|] ∈Rm+1,
(53)"
"D
GW",0.5226264418811003,"2 d
GW
Lλ(ˆX, ˆY) is not a rigorous GW problem since d ˆ
X = ∞is possible, thus it is not a metric. Also, X, Y
are not necessarily probability mm-spaces"
"D
GW",0.523070097604259,"Algorithm 2: Frank-Wolfe Algorithm for partial GW, ver 2"
"D
GW",0.5235137533274179,"Input: µ = Pn
i=1 pX
i δxi, ν = Pm
j=1 qY
j δyj, γ(1)"
"D
GW",0.5239574090505768,"Output: γ(final)
Compute CX, CY , ˆp, ˆq, ˆγ(1)
for k = 1, 2, . . . do"
"D
GW",0.5244010647737356,"ˆG(k) ←2 ˆ
M ◦ˆγ(k) // Compute gradient
ˆγ(k)′ ←arg minˆγ∈Γ(ˆp,ˆq)⟨ˆG(k), ˆγ⟩F // Solve the OT problem
Compute α(k) ∈[0, 1] via (56), (18) // Line search
ˆγ(k+1) ←(1 −α(k))ˆγ(k)′ + αˆγ(k)// Update ˆγ
if convergence, break
end for
γ(final) ←ˆγ(k)[1 : n, 1 : m]"
"D
GW",0.5248447204968945,"and, in a similar fashion, we define ˆ
M ∈R(n+1)×(m+1)×(n+1)×(m+1) as
823"
"D
GW",0.5252883762200532,"ˆ
Mi,j,i′,j′ =
 ˜
Mi,j,i′,j′
if i, i′ ∈[1 : n], j, j′ ∈[1 : m],
0
elsewhere.
(54)"
"D
GW",0.525732031943212,"Then, the GW-variant problem (51) can be written as
824"
"D
GW",0.5261756876663709,"d
GW(ˆX, ˆY) =
min
ˆγ∈Γ(ˆp,ˆq) L ˆ
M(ˆγ).
(55)"
"D
GW",0.5266193433895298,"Based on Proposition G.1 (which relates PGW L
λ (·, ·) with d
GW(·, ·)), we propose two versions of
825"
"D
GW",0.5270629991126885,"the Frank-Wolfe algorithm [31] that can solve the PGW problem (15). Apart from Algorithm 1 in
826"
"D
GW",0.5275066548358474,"[45], which solves a different formulation of partial GW, and Algorithm 1 in [44], which applies the
827"
"D
GW",0.5279503105590062,"Sinkhorn algorithm to solve an entropic regularized version of (8), to the best of our knowledge, a
828"
"D
GW",0.5283939662821651,"precise computational method for the discrete PGW problem (15) has not been studied.
829"
"D
GW",0.5288376220053239,"Here, we discuss another version of the FW Algorithm for solving the PGW problem (15). The main
830"
"D
GW",0.5292812777284827,"idea relies on solving first the GW-variant problem (51), and, at the end of the iterations, by using
831"
"D
GW",0.5297249334516415,"Proposition G.1, convert the solution of the GW-variant problem to a solution for the original partial
832"
"D
GW",0.5301685891748004,"GW problem (15).
833"
"D
GW",0.5306122448979592,"First, construct ˆp, ˆq, ˆM as described in Proposition G.1. Then, for each iteration k, perform the
834"
"D
GW",0.531055900621118,"following three steps.
835"
"D
GW",0.5314995563442768,"Step 1: Computation of gradient and optimal direction. Solve the OT problem:
836"
"D
GW",0.5319432120674357,"ˆγ(k)′ ←arg
min
ˆγ∈Γ(ˆp,ˆq)⟨L ˆ
M(ˆγ(k)), ˆγ⟩F ."
"D
GW",0.5323868677905945,"The gradient L ˆ
M(γ(k)) can be computed in a similar way as described in Lemma H.2. We refer to
837"
"D
GW",0.5328305235137534,"Section H for details.
838"
"D
GW",0.5332741792369121,Step 2: Line search method. Find optimal step size α(k):
"D
GW",0.533717834960071,"α(k) = arg min
α∈[0,1]{L ˆ
M((1 −α)ˆγ(k) + αˆγ(k)′)}."
"D
GW",0.5341614906832298,"Similar to Solver 1, let
839 

 
"
"D
GW",0.5346051464063887,"δˆγ(k) = ˆγ(k)′ −ˆγ(k),
a = ⟨ˆ
M ◦δˆγ(k), δˆγ(k)⟩F ,
b = 2⟨ˆ
M ◦δˆγ(k), ˆγ(k)⟩F .
(56)"
"D
GW",0.5350488021295474,"Then the optimal α(k) is given by formula (18). See Appendix J for a detailed discussion.
840"
"D
GW",0.5354924578527063,"Step 3. Update ˆγ(k+1) ←(1 −α(k))ˆγ(k) + α(k)ˆγ(k)′.
841"
"D
GW",0.5359361135758651,"H
Gradient Computation in Algorithms 1 and 2
842"
"D
GW",0.536379769299024,"In this section, we discuss the computation of Gradient ∇L ˜
M(γ) in Algorithm 1 and ∇L ˆ
M(ˆγ) in
843"
"D
GW",0.5368234250221828,"Algorithm 2.
844"
"D
GW",0.5372670807453416,"Proposition H.1 (Proposition 1 [41]). If the cost function can be written as
845"
"D
GW",0.5377107364685004,"L(r1, r2) = f1(r1) + f2(r2) −h1(r1)h2(r2)
(57)"
"D
GW",0.5381543921916593,"then
846"
"D
GW",0.5385980479148181,"M ◦γ = u(CX, CY , γ) −h1(CX)γh2(CY )⊤,
(58)"
"D
GW",0.5390417036379769,"where u(CX, CY , γ) := f1(CX)γ11⊤
m + 1nγ⊤
2 f2(CY ).
847"
"D
GW",0.5394853593611357,"Additionally, the following lemma builds the connection between ˜
M ◦γ and M ◦γ.
848"
"D
GW",0.5399290150842946,"Lemma H.2. For any γ ∈Rn×m, we have:
849"
"D
GW",0.5403726708074534,"˜
M ◦γ = M ◦γ −2λ|γ|1n,m.
(59)"
"D
GW",0.5408163265306123,"Proof. For any γ ∈Rn×m, we have
850"
"D
GW",0.541259982253771,"˜
M ◦γ = (M1n,n,m,m −2λ) ◦γ
= (M −2λ1n,n,m,m) ◦γ
= M ◦γ −2λ1n,m,n,m ◦γ
= M ◦γ −2(⟨1n,m, γ⟩F )1n,m
= M ◦γ −2λ|γ|1n,m"
"D
GW",0.5417036379769299,"where the second equality follows from Lemma F.1.
851"
"D
GW",0.5421472937000887,"Next, in the setting of Algorithm 2, for any ˆγ ∈R(n+1)×(m+1), we have
852"
"D
GW",0.5425909494232476,"∇L ˆ
M(ˆγ) = 2 ˆ
M ◦ˆγ
(60)"
"D
GW",0.5430346051464063,"and ˆ
M ◦ˆγ can be computed by the following lemma.
853"
"D
GW",0.5434782608695652,"Lemma H.3. For each ˆγ ∈R(n+1)×(m+1), we have ˆ
M ◦ˆγ ∈R(n+1)×(m+1) with the following:
854"
"D
GW",0.543921916592724,"( ˆ
M ◦ˆγ)ij =
( ˜
M ◦ˆγ[1 : n, 1 : m])ij
if i ∈[1 : n], j ∈[1 : m]
0
elsewhere
.
(61)"
"D
GW",0.5443655723158829,"Proof. Recall the definition of ˆ
M is given by (54), choose i ∈[1 : n], j ∈[1 : m], we have
855"
"D
GW",0.5448092280390417,"( ˆ
M ◦ˆγ)ij = n
X i′=1 m
X"
"D
GW",0.5452528837622005,"j′=1
ˆ
Mi,j,i′,j′ˆγi′,j′ + m
X"
"D
GW",0.5456965394853593,"j′=1
ˆ
Mi,j,n+1,jˆγn+1,j′ + n
X"
"D
GW",0.5461401952085182,"i′=1
ˆ
Mi,j,i′,m+1ˆγi,m+1"
"D
GW",0.546583850931677,"+ ˆ
Mi,j,n+1,m+1ˆγn+1,m+1 = n
X i′=1 m
X"
"D
GW",0.5470275066548358,"j′=1
ˆ
Mi,j,i′,j′ˆγi′,j′ + 0 + 0 + 0 = n
X i′=1 m
X"
"D
GW",0.5474711623779946,"j′=1
˜
Mi,j,i′,j′ˆγi′,j′"
"D
GW",0.5479148181011535,"= ( ˜
M ◦(ˆγ[1 : n, 1 : m]))ij"
"D
GW",0.5483584738243124,"If i = n + 1, we have
856"
"D
GW",0.5488021295474712,"( ˆ
M ◦ˆγ)n+1,j = n+1
X i′=1 m+1
X"
"D
GW",0.54924578527063,"j′=1
ˆ
Mn+1,j,i′,j′ˆγi′,j′ = 0"
"D
GW",0.5496894409937888,"Similarly, ( ˆ
M ◦ˆγ)i,m+1 = 0. Thus, we complete the proof.
857"
"D
GW",0.5501330967169477,"I
Line Search in Algorithm 1
858"
"D
GW",0.5505767524401065,"In this section, we discuss the derivation of the line search algorithm.
859"
"D
GW",0.5510204081632653,"We observe that in the partial GW setting, for each γ ∈Γ≤(µ, ν), the marginals of γ are not fixed.
860"
"D
GW",0.5514640638864241,"Thus, we can not directly apply the classical algorithm (e.g. [43]).
861"
"D
GW",0.551907719609583,"In iteration k, let γ(k), γ(k)′ be the previous and new transportation plans from step 1 of the algorithm.
862"
"D
GW",0.5523513753327418,"For convenience, we denote them as γ, γ′, respectively.
863"
"D
GW",0.5527950310559007,"The goal is to solve the following problem:
864"
"D
GW",0.5532386867790594,"min
α∈[0,1] L( ˜
M, (1 −α)γ + αγ′)
(62)"
"D
GW",0.5536823425022183,"where L( ˜
M, γ) = ⟨˜
M ◦γ, γ⟩F . By denoting δγ = γ′ −γ, we have"
"D
GW",0.5541259982253771,"L( ˜
M, (1 −α)γ + αγ′) = L( ˜
M, γ + αδγ).
Then,
865"
"D
GW",0.554569653948536,"⟨˜
M ◦(γ + αδγ), (γ + αδγ)⟩F"
"D
GW",0.5550133096716947,"= ⟨˜
M ◦γ, γ⟩F + α

⟨˜
M ◦γ, δγ⟩F + ⟨˜
M ◦δγ, γ⟩F

+ α2⟨˜
M ◦δγ, δγ⟩F"
"D
GW",0.5554569653948536,"Let
866"
"D
GW",0.5559006211180124,"a =⟨˜
M ◦δγ, δγ⟩F ,"
"D
GW",0.5563442768411713,"b =⟨˜
M ◦γ, δγ⟩F + ⟨˜
M ◦δγ, γ⟩F = 2⟨˜
M ◦γ, δγ⟩F ,
(63)"
"D
GW",0.5567879325643301,"c =⟨˜
M ◦γ, γ⟩F ,"
"D
GW",0.5572315882874889,"where the second identity in (63) follows from Lemma F.1 and the fact that ˜
M = M1n,n,m,m −
867"
"D
GW",0.5576752440106477,"2λ1n,m,n,m is symmetric.
868"
"D
GW",0.5581188997338066,"Therefore, the above problem (62) becomes
min
α∈[0,1] aα2 + bα + c."
"D
GW",0.5585625554569654,"The solution is the following:
869 α∗= 
 "
"D
GW",0.5590062111801242,"1
if a ≤0, a + b ≤0,
0
if a ≤0, a + b > 0,
clip( −b"
"D
GW",0.559449866903283,"2a , [0, 1])
if a > 0,
(64) where"
"D
GW",0.5598935226264419,clip(−b
"D
GW",0.5603371783496007,"2a , [0, 1]) = min

1, max{0, −b"
"D
GW",0.5607808340727596,"2a }

= 
  −b"
A,0.5612244897959183,"2a
if −b"
A,0.5616681455190772,"2a ∈[0, 1],
0
if −b"
A,0.562111801242236,"2a < 0,
1
if −b"
A,0.5625554569653949,2a > 1.
A,0.5629991126885537,"We can further discuss the difference in computation of a and b in PGW setting and the classical GW
870"
A,0.5634427684117125,"setting. If the assumption in Proposition H.1 holds, by (58) and (59), we have
871"
A,0.5638864241348713,"a = ⟨˜
M ◦δγ, δγ⟩F
= ⟨(M ◦δγ −2λ|δγ|In,m), δγ⟩F
= ⟨M ◦δγ, δγ⟩F −2λ|δγ|2
(65)"
A,0.5643300798580302,"=

u(CX, CY , δγ) −h1(CX)δγh2(CY )⊤, δγ"
A,0.564773735581189,"F −2λ|δγ|2,"
A,0.5652173913043478,"b = 2⟨˜
M ◦γ, δγ⟩F
= 2⟨M ◦γ −2λ|γ|In,m, δγ⟩
= 2(⟨M ◦γ, δγ⟩F −2λ|δγ||γ|)
(66)"
A,0.5656610470275066,"Note that in the classical GW setting [43], the term u(CX, CY , δγ) = 0n×m and |δγ| = 0. Therefore,
872"
A,0.5661047027506655,"in such line search algorithm (Algorithm 2 in [43]), the terms u(CX, CY , δγ), 2λ|δγ|1n×m are not
873"
A,0.5665483584738243,"required. In addition, in equation (66), M ◦γ, 2λ|γ| have been computed in the gradient computation
874"
A,0.5669920141969832,"step, thus these two terms can be directly applied in this step.
875"
A,0.5674356699201419,"J
Line Search in Algorithm 2
876"
A,0.5678793256433008,"Similar to the previous section, in iteration k, let ˆγ(k), ˆγ(k)′ denote the previous transportation plan
877"
A,0.5683229813664596,"and the updated transportation plan. For convenience, we denote them as ˆγ, ˆγ′, respectively.
878"
A,0.5687666370896185,"Let δˆγ = ˆγ −ˆγ′.
879"
A,0.5692102928127772,"The goal is to find the following optimal α:
880"
A,0.5696539485359361,"α = arg min
α∈[0,1] L( ˆ
M, (1 −α)ˆγ, αˆγ′) = arg min
α∈[0,1] L( ˆ
M, αδˆγ + ˆγ),
(67)"
A,0.570097604259095,"where ˆ
M ∈R(n+1)×(m+1)×(n+1)×(m+1), with ˆ
M[1 : n, 1 : m, 1 : n, 1 : m] =
˜
M = M −
881"
A,0.5705412599822538,"2λ1n×m×n×m.
882"
A,0.5709849157054127,"Similar to the previous section, let
883"
A,0.5714285714285714,"a = ⟨ˆ
M ◦δˆγ, δˆγ⟩F ,"
A,0.5718722271517303,"b = ⟨ˆ
M ◦δˆγ, ˆγ⟩F + ⟨ˆ
M ◦ˆγ, δˆγ⟩F = 2⟨ˆ
M ◦δˆγ, ˆγ⟩F ,
(68)"
A,0.5723158828748891,"c = ⟨ˆ
M ◦ˆγ, ˆγ⟩F ,"
A,0.572759538598048,"where (68) holds since ˆ
M is symmetric. Then, the optimal α is given by (64).
884"
A,0.5732031943212067,"It remains to discuss the computation. By Lemma F.1, we set γ = ˆγ[1 : n, 1 : m], δγ = δˆγ[1 : n, 1 :
885"
A,0.5736468500443656,"m]. Then,
886"
A,0.5740905057675244,"a = ⟨( ˆ
M ◦δˆγ)[1 : n, 1 : m], δγ⟩F = ⟨( ˜
M ◦δγ, δγ⟩F ,"
A,0.5745341614906833,"b = ⟨( ˆ
M ◦δˆγ)[1 : n, 1 : m], γ⟩F = ⟨( ˜
M ◦δγ, γ⟩F ."
A,0.5749778172138421,"Thus, we can apply (65), (66) to compute a, b in this setting by plugging in γ = ˆγ[1 : n, 1 : m] and
887"
A,0.5754214729370009,"δγ = δˆγ[1 : n, 1 : m].
888"
A,0.5758651286601597,"K
Convergence
889"
A,0.5763087843833186,"As in [45] we will use the results from [32] on the convergence of the Frank-Wolfe algorithm for
890"
A,0.5767524401064774,"non-convex objective functions.
891"
A,0.5771960958296362,"Consider the minimization problems
892"
A,0.577639751552795,"min
γ∈Γ≤(p,q) L ˜
M(γ)
and
min
ˆγ∈Γ(ˆp,ˆq) L ˆ
M(ˆγ)
(69)"
A,0.5780834072759539,"that corresponds to the discrete partial GW problem, and the discrete GW-variant problem (used in
893"
A,0.5785270629991127,"version 2), respectively. The objective functions γ 7→L ˆ
M(γ) = ˜
Mγ⊗2 (where ˜
M = M −2λ1n,m
894"
A,0.5789707187222716,"for a fixed matrix M ∈Rn×m and λ > 0), and ˆγ 7→L ˆ
M(ˆγ) =
ˆ
Mˆγ⊗2 (where ˆ
M is given by
895"
A,0.5794143744454303,"(54)) are non-convex in general (for λ > 0, the matrices ˜
M and ˆ
M symmetric but not positive
896"
A,0.5798580301685892,"semi-definite), but the constraint sets Γ≤(p, q) and Γ(ˆp, ˆq) are convex and compact on Rn×m (see
897"
A,0.580301685891748,"Proposition B.2 [53]) and on R(n+1)×(m+1), respectively.
898"
A,0.5807453416149069,"From now on we will concentrate on the first minimization problem in (69) and the convergence
899"
A,0.5811889973380656,"analysis for the second one will be analogous.
900"
A,0.5816326530612245,"Consider the Frank-Wolfe gap of L ˜
M at the approximation γ(k) of the optimal plan γ:
901"
A,0.5820763087843833,"gk =
min
γ∈Γ≤(p,q)⟨∇L ˜
M(γ(k)), γ(k) −γ⟩F .
(70)"
A,0.5825199645075422,"It provided a good criterion to measure the distance to a stationary point at iteration k. Indeed, a plan
902"
A,0.582963620230701,"γ(k) is a stationary transportation plan for the corresponding constrained optimization problem in
903"
A,0.5834072759538598,"(69) if and only if gk = 0. Moreover, gk is always non-negative (gk ≥0).
904"
A,0.5838509316770186,"From Theorem 1 in [32], after K iterations we have the following upper bound for the minimal
905"
A,0.5842945874001775,"Frank-Wolf gap:
906"
A,0.5847382431233363,"˜gK :=
min
1≤k≤K gk ≤max{2L1, DL}
√"
A,0.5851818988464951,"K
,
(71)"
A,0.5856255545696539,"where
L1 := L ˜
M(γ(1)) −
min
γ∈Γ≤(p,q) L ˜
M(γ)"
A,0.5860692102928128,"is the initial global suboptimal bound for the initialization γ(1) of the algorithm, and DL := Lip ·
907"
A,0.5865128660159716,"(diam(Γ≤(p, q)))2, where Lip is the Lipschitz constant of ∇L ˜
M and diam(Γ≤(p, q)) is the ∥· ∥F
908"
A,0.5869565217391305,"diameter of Γ≤(p, q) in Rn×m.
909"
A,0.5874001774622892,"The important thing to notice is that the constant max{2L1, DL} does not depend on the iteration
910"
A,0.5878438331854481,"step k. Thus, according to Theorem 1 in [32], the rate on ˜gK is O(1/
√"
A,0.5882874889086069,"K). That is, the algorithm
911"
A,0.5887311446317658,"takes at most O(1/ε2) iterations to find an approximate stationary point with a gap smaller than ε.
912"
A,0.5891748003549245,"Finally, we adapt Lemma 1 in Appendix B.2 in [45] to our case characterizing the convergence
913"
A,0.5896184560780834,"guarantee, precisely, determining such a constant max{2L1, DL} in (71). Essentially, we will
914"
A,0.5900621118012422,"estimate upper bounds for the Lipschitz constant Lip and for the diameter diam(Γ≤(p, q)).
915"
A,0.5905057675244011,"• Let us start by considering the diameter of the couplings of Γ≤(p, q) with respect to the
916"
A,0.59094942324756,"Frobenious norm ∥· ∥F . By definition,
917"
A,0.5913930789707187,"diam(Γ≤(p, q)) :=
sup
γ,γ′∈Γ≤(p,q)
∥γ −γ′∥F ."
A,0.5918367346938775,"For any γ ∈Γ≤(p, q), since γ1 ≤p and γ2 ≤q, we obtain that, in particular, |γ1| ≤|p|
and |γ2| ≤|q|. Thus, since |γ1| = |γ| = |γ2| (recall that γ1 = π1#γ and γ2 = π2#γ) we
have
|γ| ≤min{|p|, |q|} =: √s
∀γ ∈Γ≤(p, q).
Thus, given γ, γ′ ∈Γ≤(p, q), we obtain
918"
A,0.5922803904170364,"∥γ −γ′∥2
F ≤2∥γ∥2
F + 2∥γ′∥2
F = 2
X"
A,0.5927240461401952,"i,j
(γi,j)2 + 2
X"
A,0.593167701863354,"i,j
(γ′
i,j)2 ≤2  X"
A,0.5936113575865128,"i,j
|γi,j|   2 + 2  X"
A,0.5940550133096717,"i,j
|γ′
i,j|   2"
A,0.5944986690328306,= 2|γ|2 + 2|γ′|2 ≤4s
A,0.5949423247559894,"(essentially, we used that ∥· ∥F is the 2-norm for matrices viewed as vectors, that | · | is the
919"
A,0.5953859804791481,"1-norm for matrices viewed as vectors, and the fact that ∥· ∥2 ≤∥· ∥1). As a result,
920"
A,0.595829636202307,"diam(Γ≤(p, q)) ≤2√s,
(72)
where s only depends on p and q that are fixed weight vectors in Rn
+ and Rm
+, respectively.
921"
A,0.5962732919254659,"• Now, let us analyze the Lipschitz constant of ∇L ˆ
M with respect to ∥· ∥F . For any γ, γ′ ∈
922"
A,0.5967169476486247,"Γ≤(p, q) we have,
923"
A,0.5971606033717834,"∥∇L ˜
M(γ) −∇L ˜
M(γ′)∥2
F
= ∥˜
M ◦γ −˜
M ◦γ′∥2
F
= ∥[M −2λ] ◦(γ −γ′)∥2
F
= ⟨[M −2λ] ◦(γ −γ′), [M −2λ] ◦(γ −γ′)⟩F =
X i,j"
A,0.5976042590949423,"
[(M −2λ) ◦(γ −γ′)]i,j
2 =
X i,j  X"
A,0.5980479148181012,"i′,j′
(Mi,j,i′,j′ −2λ)(γi′,j′ −γ′
i′,j′)   2"
A,0.59849157054126,"≤

max
i,j,i′,j′{Mi,j,i′,j′ −2λ}
2
 
 n,m
X i,j   n,m
X"
A,0.5989352262644189,"i′,j′
(γi′,j′ −γ′
i′,j′)   2 
"
A,0.5993788819875776,"= (max(M) −2λ)2   n,m
X"
A,0.5998225377107365,"i,j
∥γ −γ′∥2
F  "
A,0.6002661934338953,"≤nm (max(M) −2λ)2 ∥γ −γ′∥2
F ."
A,0.6007098491570542,"Hence, the Lipschitz constant of the gradient of L ˜
M is by
924"
A,0.6011535048802129,"Lip ≤√nm
 max
i,j,i′,j′{Mi,j,i′,j′} −2λ
 ."
A,0.6015971606033718,"In the particular case where L(r1, r2) = |r1 −r2|2 we have Mi,j,i′,j′ = |CX
i,i′ −CY
j,j′|2 (as in (14))
925"
A,0.6020408163265306,"where CX, CY are given n × n and m × m non-negative symmetric matrices defined in (11), that
926"
A,0.6024844720496895,"depend on the given discrete mm-spaces X and Y. Here, we obtain
927"
A,0.6029281277728483,"max
i,j,i′,j′{Mi,j,i′,j′} = max
i,j,i′,j′{|CX
i,i′ −CY
j,j′|2} ≤

(max
i,i′ {CX
i,i′})2 + (max
j,j′ {CY
j,j′})2
"
A,0.6033717834960071,"and so the Lipschitz constant verifies
928"
A,0.6038154392191659,"Lip ≤√nm
((max(CX)2 + max(CY )2) −2λ"
A,0.6042590949423248,"Combining all together, we obtain that after K iterations, the minimal Frank-Wolf gap verifies
929"
A,0.6047027506654836,"˜gK =
min
1≤k≤K gk ≤max{2L1, 4s√nm |maxi,j,i′,j′{Mi,j,i′,j′} −2λ|}
√ K"
A,0.6051464063886424,"≤2max{L1, 2s√nm
(max(CX)2 + max(CY )2) −2λ
}
√"
A,0.6055900621118012,"K
(if M is as in (14))"
A,0.6060337178349601,"where L1 dependents on the initialization of the algorithm.
930"
A,0.6064773735581189,"Finally, we mention that there is a dependence in the constant max{2L1, DL} on the number of
931"
A,0.6069210292812778,"points (n and m) of our discrete spaces X = {x1, . . . xn} and Y = {y1, . . . , ym} which was not
932"
A,0.6073646850044365,"pointed out in [45].
933"
A,0.6078083407275954,"L
Related Work: Mass-Constrained Partial Gromov-Wasserstein
934"
A,0.6082519964507542,"Partial Gromov-Wasserstein is first introduced in [45]. To distinguish the PGW problem in [45] and
935"
A,0.6086956521739131,"the PGW problem in this paper, we call the former one the Mass-Constrained Gromov-Wasserstein
936"
A,0.6091393078970718,"problem (MPGW):
937"
A,0.6095829636202307,"MPGWρ(X, Y) :=
inf
γ∈Γρ
≤(µ,ν) γ⊗2(L(dq
X, dq
Y )),
(73)"
A,0.6100266193433895,"where ρ ∈[0, min{|µ|, |ν|}], and
938"
A,0.6104702750665484,"Γρ
≤(µ, ν) := {γ ∈M+(X × Y ) : γ1 ≤µ, γ2 ≤ν, |γ| = ρ}.
(74)"
A,0.6109139307897072,"Unlike the relation between Partial OT and OT, it is not rigorous to say that the PGW and the MPGW
939"
A,0.611357586512866,"problems are equivalent, since the objective function
940"
A,0.6118012422360248,"γ 7→
Z"
A,0.6122448979591837,"(X×Y )2 L(d2
X(x, x′), d2
Y (y, y′))dγ⊗2
(75)"
A,0.6126885536823425,"is not a convex function even if (r1, r2) 7→L(r1, r2) is convex [37]: (If the problems were convex,
941"
A,0.6131322094055013,"MPGW, as the ‘Lagrangian formulation’ of PGW—adding the constraint of PGW in the functional
942"
A,0.6135758651286601,"à la Lagrange Multipliers— would be equivalent to PGW. However, since these problems are not
943"
A,0.614019520851819,"convex, we cannot claim that they are equivalent in principle.)
944"
A,0.6144631765749778,"We can still investigate their relation by the following lemma, based on which we design the wall-clock
945"
A,0.6149068322981367,"time experiment in Section O.
946"
A,0.6153504880212954,"Proposition L.1. Suppose γ ∈Γ≤(µ, ν) is optimal for PGWλ(X, Y). Let ρ = |γ|, we have γ is
947"
A,0.6157941437444543,"also optimal in MPGWρ(X, Y).
948"
A,0.6162377994676131,"Proof. Pick γ′ ∈Γρ
≤(µ, ν) ⊂Γ≤(µ, ν), since γ is optimal in PGWλ(µ, ν), we have
949"
A,0.616681455190772,"0 ≤C(γ; λ, µ, ν) −C(γ′; λ, µ, ν) =
Z"
A,0.6171251109139307,"(X×Y )2 L(d2
X(x, x′), d2
Y (y, y′))d(γ⊗2 −γ′⊗2)"
A,0.6175687666370896,"Thus, γ is optimal in Γρ
≤(µ, ν) for MPGWρ(X, Y) and we complete the proof.
950"
A,0.6180124223602484,"At first glance, the formulations of the MPGW (73) and the PGW (10) problems could be thought to
951"
A,0.6184560780834073,"be equivalent since tuning the hyper-parameter λ for controlling the total mass in the PGW problem
952"
A,0.6188997338065662,"is quite similar in spirit to the approach in [45] (MPGW) which instead constrains the total mass of γ
953"
A,0.6193433895297249,"by the hyper-parameter ρ. However, since classical GW and its variants (e.g. UPGW, PGW, MPGW)
954"
A,0.6197870452528838,"are not convex problems, mathematically this equivalence relation is not verified.
955"
A,0.6202307009760426,"We first notice that the ""Lagrangian form"" of the MPGW problem (73) is our PGW formulation
956"
A,0.6206743566992015,"(10) by considering 2λ be the ""Lagrange variable"" of constraint −|γ|2 + ρ2 ≤0. However, as said
957"
A,0.6211180124223602,"before, the equivalence is not direct as the cost functional (75) is not convex. In fact, he MPGW
958"
A,0.621561668145519,"problem does not give rise to a metric, while our PGW formulation gives rise to a metric as shown in
959"
A,0.6220053238686779,"Proposition 3.4. We will show this through the following example. In fact, we will see that by using
960"
A,0.6224489795918368,"the MPGW formulation we cannot distinguish different mm-spaces, while with our PGW we can
961"
A,0.6228926353149956,"discriminate different mm-spaces.
962"
A,0.6233362910381544,Example: Consider the following three mm-spaces
A,0.6237799467613132,"X1 = (R3, ∥· ∥,"
X,0.6242236024844721,"1000
X"
X,0.6246672582076309,"i=1
αδxi),
X2 = (R3, ∥· ∥,"
X,0.6251109139307897,"800
X"
X,0.6255545696539485,"i=1
αδxi),
X3 = (R3, ∥· ∥,"
X,0.6259982253771074,"400
X"
X,0.6264418811002662,"i=1
αδxi),"
X,0.6268855368234251,"where α > 0 is the mass of each point. For numerical stability reasons, we set α = 1/1000. On the
963"
X,0.6273291925465838,"one hand, if we compute MPGW, the mass is fixed to be a value ρ ∈[0, 0.4], since the total mass in
964"
X,0.6277728482697427,"X3 is 0.4. For our experiment, we set ρ = 0.4, and we observe:
965"
X,0.6282165039929015,"MPGWρ(X1, X2; ρ = 0.4) = MPGWρ(X2, X3; ρ = 0.4) = MPGWρ(X1, X3; ρ = 0.4) = 0
On the other hand, if we compute our PGW, considering any λ > 0, (in particular, we set λ = 10),
966"
X,0.6286601597160604,"we obtain
967"
X,0.6291038154392191,"PGWλ(X1, X2; λ = 10) = 3.6
PGWλ(X2, X3; λ = 10) = 4.8
PGWλ(X1, X3; λ = 10) = 8.4
In particular, one can verify the triangular inequality.
968"
X,0.629547471162378,"As a conclusion, in this example, MPGW can not describe the dissimilarity of any two datasets taken
969"
X,0.6299911268855368,"from {X1, X2, X3}. They are three distinct datasets, but MPGW returns zero for each pair. On the
970"
X,0.6304347826086957,"contrary, our PGW can measure dissimilarity.
971"
X,0.6308784383318545,"In addition, the discrepancy provided by our PGW formulation is consistent with the follow-
972"
X,0.6313220940550133,"ing intuitive observation: One expects the dissimilarity between X1 and X3 to be larger than
973"
X,0.6317657497781721,"the difference X1 and X2, and than the difference between X1 and X2.
This is because we
974"
X,0.632209405501331,"are considering discrete measures, with the same mass at each point concentrated on the sets
975"
X,0.6326530612244898,"{x1, . . . , x400} ⊂{x1, . . . , x400, . . . , x800} ⊂{x1, . . . , x400, . . . , x800, . . . , x1000} for the datasets
976"
X,0.6330967169476486,"X3, X2, X1, respectively.
977"
X,0.6335403726708074,"M
Partial Gromov-Wasserstein Barycenter
978"
X,0.6339840283939663,"We first introduce the classical Gromov-Wasserstein problem [41]: Consider finite discrete probability
979"
X,0.6344276841171251,"measures µ1, . . . , µK, where µk = Pnk
i=1 pk
i δxk
i and each xk
i ∈Rdk for some dk ∈N. Let
980"
X,0.634871339840284,"Ck = [∥xk
i −xk
i′∥2]i,i′∈[1:nk] and pk = [pk
1, . . . , pk
nk]⊤. Given p ∈Rn
+ with |p| = 1 for some n ∈N
981"
X,0.6353149955634427,"and ξ1, . . . , ξK ≥0 with PK
k=1 ξk = 1, the GW barycenter problem is defined by:
982"
X,0.6357586512866016,"min
C,γk K
X"
X,0.6362023070097604,"k=1
ξk⟨L(C, Ck) ◦γk, γk⟩,
(76)"
X,0.6366459627329193,"where the minimization is over all matrices C ∈Rn×n, γk ∈Γ(p, pk), ∀k ∈[1 : K].
983"
X,0.637089618456078,"Similarly, we can extend the above definition into PGW setting. In particular, we relax the assumptions
984"
X,0.6375332741792369,"|p| = 1 and |pk| = 1 for each k ∈[1 : K]. Given λ1, . . . , λK > 0, the PGW barycenter is the follow
985"
X,0.6379769299023957,"problem:
986"
X,0.6384205856255546,"min
C,γk X"
X,0.6388642413487134,"k
ξk⟨M(C, Ck) ◦γk, γk⟩−2λk|γk|2
(77)"
X,0.6393078970718722,"where each γk ∈Γ≤(p, pk).
987"
X,0.639751552795031,"The problem (77) can be solved iterative by two steps:
988"
X,0.6401952085181899,"Minimization with respect to C: For each k, we solve the PGW problem"
X,0.6406388642413487,"min
γk∈Γ≤(p,pk)⟨M(C, Ck) ◦γk, γk⟩−2λk|γk|2"
X,0.6410825199645075,"via solver 1 or 2.
989"
X,0.6415261756876663,"Minimization with respect to {γk}k:
990 min
C X"
X,0.6419698314108252,"k
ξk⟨M(C, Ck) ◦γk, γk⟩
(78)"
X,0.642413487133984,"Note, we can ignore the −2λk|γk|2 terms as γk is fixed in this case.
991"
X,0.6428571428571429,"It has closed form solution due to the following lemma and proposition:
992"
X,0.6433007985803016,"Lemma M.1. Given matrices A ∈Rn,m, B ∈Rm,l, C ∈Rn,l, let"
X,0.6437444543034605,"L = ⟨AB, C⟩,"
X,0.6441881100266194,then dL
X,0.6446317657497782,"dA = CB⊤.
993"
X,0.645075421472937,"Proof. For any i ∈[1 : n], j ∈[1 : m], we have
994"
X,0.6455190771960958,"dL
dAij
:=
X i′,j′"
X,0.6459627329192547,"d
dAij
Ci′,j′(AB)i′,j′ =
X"
X,0.6464063886424135,"i′,j′
Ci′,j′ d(P"
X,0.6468500443655724,"k Ai′,kBk,j′) dAij =
X"
X,0.6472937000887311,"j′
Ci,j′Bk,j′ = (CB⊤)ij. 995"
X,0.64773735581189,"Proposition M.2. If L satisfies (57), and f ′
1/h′
1 is invertible, then (78) can be solved by
996"
X,0.6481810115350488,"C =
 f ′
1
h′
1"
X,0.6486246672582077,−1 P
X,0.6490683229813664,k ξkγkh2(Ck)(γk)⊤ P
X,0.6495119787045253,"k ξkγk
1(γk
1)⊤"
X,0.6499556344276841,"
,
(79)"
X,0.650399290150843,"where
A
B =
Aij Bij "
X,0.6508429458740018,"ij
, with convention 0"
X,0.6512866015971606,0 = 0.
X,0.6517302573203194,"Special case: if |p| ≤|pk|, ∀k, when λ is sufficiently large, (79) and [41, Proposition 3] coincide.
997"
X,0.6521739130434783,"Proof. From Proposition H.1, the objective in (78) becomes
998 L =
X"
X,0.6526175687666371,"k
ξk⟨f1(C)γ1
11⊤
nk + 1n(γk
2)⊤f2(Ck) −h1(C)γkh2(Ck)⊤, γk⟩ =
X"
X,0.6530612244897959,"k
ξk⟨f1(C)γ1
11⊤
nk, γk⟩+
X"
X,0.6535048802129547,"k
ξk⟨1n(γk
2)⊤f2(Ck), γk⟩"
X,0.6539485359361136,"|
{z
}
constant −
X"
X,0.6543921916592724,"k
ξk⟨h1(C)γkh2(Ck)⊤, γk⟩"
X,0.6548358473824313,We set dL
X,0.65527950310559,"dC = 0. From Lemma M.1, we have:
999"
X,0.6557231588287489,0 = dL
X,0.6561668145519077,"dC
=
X"
X,0.6566104702750666,"k
ξkf ′
1(C) ⊙γk1nk(γk
1)⊤−
X"
X,0.6570541259982253,"k
ξkh′
1(C) ⊙γkh2(Ck)(γk)⊤"
X,0.6574977817213842,"= f ′
1(C) ⊙
X"
X,0.657941437444543,"k
ξkγk1nk(γk
1)⊤−h′
1(C) ⊙
X"
X,0.6583850931677019,"k
ξkγkh2(Ck)(γk)⊤"
X,0.6588287488908607,"= f ′
1(C) ⊙
X"
X,0.6592724046140195,"k
ξkγk
1(γk
1)⊤"
X,0.6597160603371783,"|
{z
}
B"
X,0.6601597160603372,"−h′
1(C) ⊙
X"
X,0.660603371783496,"k
ξkγkh2(Ck)(γk)⊤"
X,0.6610470275066548,"|
{z
}
A"
X,0.6614906832298136,".
(80)"
X,0.6619343389529725,We claim A
X,0.6623779946761313,"B is well-defined, i.e., if Bij = 0, then Aij = 0.
1000"
X,0.6628216503992902,"For each i, j ∈[1 : n], if Bij = 0, we have two cases:
1001"
X,0.6632653061224489,"Case 1: ∀k ∈[1 : K], we have γk
1[i] = 0.
1002"
X,0.6637089618456078,"Thus, γk[i, :] = 0⊤
nk. So A[i, :] = (γkh2(Ck)(γk)⊤)[i, :] = 0⊤
nk.
1003"
X,0.6641526175687666,"Case 2: ∀k ∈[1 : K], we have γk
1[j] = 0.
1004"
X,0.6645962732919255,"It implies (γk)⊥[:, j] = 0n, thus A[:, j] = (γkh2(Ck))(γk)⊤[:, j] = 0nk. Therefore, Aij = 0.
1005"
X,0.6650399290150842,Thus A
X,0.6654835847382431,"B is well-defined.
1006"
X,0.665927240461402,"In addition, in these two cases, if we change the value Ck
ij, L will not change.
1007"
X,0.6663708961845608,"From (80), we have:
1008"
X,0.6668145519077197," f ′
1
h′
1
(C)
 ij
="
X,0.6672582076308784," P
k ξkγkh2(Ck)(γk)⊤ ij
 P"
X,0.6677018633540373,"k ξkγk
1(γk
1)⊤ ij"
X,0.6681455190771961,"if Bij > 0. In addition, if Bij = 0, there is no constraint for Cij.
1009"
X,0.668589174800355,"Combining it with the fact that if Bi,j = 0, then Ci,j has no effect on L. Thus,
1010"
X,0.6690328305235137,we have the following is a solution:
X,0.6694764862466726,"C =
 f ′
1
h′
1"
X,0.6699201419698314,−1 P
X,0.6703637976929903,k ξkγkh2(Ck)(γk)⊤ P
X,0.6708074534161491,"k ξkγk
1(γk
1)⊤ 
."
X,0.6712511091393079,"In particular case: |p| ≤|pk|, ∀k, suppose λ > max{c2 : c ∈S"
X,0.6716947648624667,"k Ck ∪C}, by lemma E.1, we have
1011"
X,0.6721384205856256,"for each k, |γk| = min(|p|, |p|k) = |p|, that is γk
1 = p.
1012"
X,0.6725820763087844,"Thus,
1013 X"
X,0.6730257320319432,"k
ξkγk
1(γ1
1)⊤=
X"
X,0.673469387755102,"k
ξkγk
1(γk
1)⊤=
X"
X,0.6739130434782609,"k
ξkpp⊤= pp⊤"
X,0.6743566992014197,"Thus, C =

f ′
1
h′
1"
X,0.6748003549245786,−1  P
X,0.6752440106477373,k ξkγkh2(Ck)(γk)⊤
X,0.6756876663708962,"pp⊤

.
1014"
X,0.676131322094055,"Remark M.3. In l2 loss case, i.e. L(r1, r2) = |r1 −r2|2, (79) becomes
1015 C =
P"
X,0.6765749778172139,"k ξkγkCk(γk)⊤
P"
X,0.6770186335403726,"k ξkγk
1(γk
1)⊤
.
(81)"
X,0.6774622892635315,"Since in this case, we can set"
X,0.6779059449866903,"f1(x) = x2, f2(y) = y2, h1(x) = 2x, h2(y) = y."
X,0.6783496007098492,"Thus f ′
1
h′
1 (x) = 2x"
X,0.678793256433008,"2 = x and

f ′
1
h′
1"
X,0.6792369121561668,"−1
(x) = x. Therefore, (79) becomes (81).
1016"
X,0.6796805678793256,Algorithm 3: Partial Gromov-Wasserstein Barycenter
X,0.6801242236024845,"Input: {Ck, pk, λk}K
k=1, p
Output: C
Initialize C.
for i = 1, 2, . . . do"
X,0.6805678793256433,"compute γk ←arg minγ∈Γ≤(p,pk)⟨L(C, Ck) −2λk, γ⟩, ∀k ∈[1 : K].
Update C by (79).
if convergence, break
end for"
X,0.6810115350488021,Algorithm 4: Mass-Constrained Partial Gromov-Wasserstein Barycenter
X,0.6814551907719609,"Input: {Ck, pk, λk}K
k=1, p
Output: C
Initialize C.
for i = 1, 2, . . . do"
X,0.6818988464951198,"compute γk ←arg minγ∈Γ
ρk
≤(p,pk)⟨L(C, Ck), γ⟩, ∀k ∈[1 : K].
Update C by (79).
if convergence, break
end for"
X,0.6823425022182786,"Similarly, we can also extend the above PGW Barycenter into the MPGW setting:"
X,0.6827861579414375,"min
C,γk K
X"
X,0.6832298136645962,"k=1
ξk⟨L(C, Ck) ◦γk, γk⟩,"
X,0.6836734693877551,"where, for each k ∈[1 : K], ρk ∈[0, min(|p|, |pk|)], and the optimization is over C ∈Rn and
1017"
X,0.6841171251109139,"γk ∈Γρk
≤(p, pk) for k ∈[1 : K].
1018"
X,0.6845607808340728,"It can be solved by the following algorithm 4.
1019"
X,0.6850044365572315,"Figure 4: We visualize the dataset in point cloud interpolation. The first row is the original images in
Link. The second row is the point clouds obtained by the k-mean method, where k = 1024."
X,0.6854480922803904,"Figure 5: We test interpolation tasks in 3 scenarios: source data is clean, target data is selected from
three cases as described in section dataset and data processing. In each scenario, we test η =
5%, 10% respectively. In the first column, we present the source and target point cloud visualization
in each task. In columns 2-9, we present GW, PGW barycenter for t = 0/7, 1/7, . . . , 7/7."
X,0.6858917480035492,"M.1
Details of Point Cloud Interpolation Experiment
1020"
X,0.6863354037267081,"Dataset and data processing. We apply the dataset in [41] with download link. The original data are
1021"
X,0.686779059449867,"images, which we convert into a point cloud using the k-mean algorithm, where k = 1024 (see the
1022"
X,0.6872227151730257,"second row of Figure 4).
1023"
X,0.6876663708961845,"Suppose D ⊂R2 is a region that contains these point clouds. Let R ⊂R2 denote another region. In
1024"
X,0.6881100266193434,"R, we randomly select and add nη noise points to these point clouds. In particular, we consider noise
1025"
X,0.6885536823425022,"corruption in the following three cases:
1026"
X,0.6889973380656611,"Case 1: R is a rectangle region which is disjoint to D. See the third row in Figure 4.
1027"
X,0.6894409937888198,"Case 2: R = R1 ∪R2, where R1, R2 are rectangles which are disjoint to D. See the fourth row in
1028"
X,0.6898846495119787,"Figure 4.
1029"
X,0.6903283052351376,"Case 3: R contains D. See the fifth row in Figure 4.
1030"
X,0.6907719609582964,"GW Barycenter and PGW Barycenter methods. We select t1, . . . , tK with 0 = t1 < t2 < . . . <
1031"
X,0.6912156166814551,"tK = 1. For each t ∈{t1, . . . , tK}, we compute the GW Barycenter
1032"
X,0.691659272404614,"arg min
C,γ1,γ2(1 −t)⟨L(C, C1) ◦γ1, γ1⟩+ t⟨L(C, C2) ◦γ2, γ2⟩,
(82)"
X,0.6921029281277729,"where γ1 ∈Γ(p, p1), γ2 ∈Γ(p, p2). Apply Smacof-MDS to the minimizer C, the resulting
1033"
X,0.6925465838509317,"embedding, denoted as Xt ∈Rn×2 (where n = 1024) is the GW-based interpolation.
1034"
X,0.6929902395740906,"Replacing the GW Barycenter with the PGW Barycenter
1035"
X,0.6934338952972493,"arg min
C,γ1,γ2(1 −t)(⟨L(C, C1) ◦γ1, γ1⟩+ λ1|γ1|2) + t(⟨L(C, C2) ◦γ2, γ2⟩+ λ2|γ2|),
(83)"
X,0.6938775510204082,"where λ1, λ2 > 0, γ1 ∈Γ≤(p, p1), γ2 ∈Γ≤(p, p2). Then we obtain PGW-based interpolation.
1036"
X,0.694321206743567,"Problem setup. We select one point cloud from the clean dataset denoted as X = {xi}n
i=1 (source
1037"
X,0.6947648624667259,"point cloud), n = 1024.
1038"
X,0.6952085181898846,"Next, we select one noise-corrupted point cloud, as described in Case 1, Case 2, and Case 3,
1039"
X,0.6956521739130435,"respectively. In these three scenarios, we test η = 0.5% and η = 10% where η is the noise level.
1040"
X,0.6960958296362023,"Therefore, we test 3 ∗2 = 6 different interpolation tasks for these two methods. The size of the target
1041"
X,0.6965394853593612,"point cloud is then m = n + nη. See Figure 5 for details.
1042"
X,0.69698314108252,"Numerical details. In the GW-barycenter method, because of the balanced mass setting, we set"
X,0.6974267968056788,p1 = 1
X,0.6978704525288376,"n1n, p2 = 1"
X,0.6983141082519965,"m1m, p = 1 n1n."
X,0.6987577639751553,"In PGW-barycenter, we set"
X,0.6992014196983141,p1 = 1
X,0.6996450754214729,"n1n, p2 = 1"
X,0.7000887311446318,"n1m, p = 1 n1n."
X,0.7005323868677906,"In addition, we set λ1, λ2 such that 2λ1, 2λ2 ≥max(max(C1)2, max(C2)2). We compute GW/PGW
1043"
X,0.7009760425909495,"barycenter for t = 0/7, 1/7, . . . , 7/7.
1044"
X,0.7014196983141082,"In both GW and PGW barycenter algorithms, we set the largest number of iterations to be 100. The
1045"
X,0.7018633540372671,"threshold for convergence is set to be 1e-5.
1046"
X,0.7023070097604259,"Performance analysis. Each interpolation task is essentially unbalanced: the source point cloud
1047"
X,0.7027506654835848,"contains clean data, while the target point cloud contains clean and noise points. We observe that in
1048"
X,0.7031943212067435,"the first two scenarios, the interpolation derived from GW is clearly disturbed by the noise data points.
1049"
X,0.7036379769299024,"For example, in rows 1, 3, 5, 7, columns t = 1/7, 2/7, 3/7, we see that the point clouds reconstructed
1050"
X,0.7040816326530612,"by MDS have significantly different width-height ratios from those of the source and target point
1051"
X,0.7045252883762201,"clouds.
1052"
X,0.7049689440993789,"In contrast, PGW is significantly less disturbed, and the interpolation is more natural. The width-
1053"
X,0.7054125998225377,"height ratio of the point clouds generated by the PGW barycenter is consistent with that of the
1054"
X,0.7058562555456965,"source/target point clouds.
1055"
X,0.7062999112688554,"In the third scenario, the noise data is uniformly selected from a large region that contains the domain
1056"
X,0.7067435669920142,"of all clean point clouds. In this case, we observe that the GW and PGW barycenters perform similarly.
1057"
X,0.707187222715173,"However, at t = 1/7, 2/7, 4/7, GW-barycenters present more noise points than PGW-barycenters in
1058"
X,0.7076308784383318,"the same truncated region.
1059"
X,0.7080745341614907,"Limitations and future work. The main issue of the above GW/PGW techniques arises from the
1060"
X,0.7085181898846495,"MDS method:
1061"
X,0.7089618456078084,"Given minimizer C ∈Rn×n of GW/PGW barycenter problem (82) (or (83)), MDS studies the
1062"
X,0.7094055013309671,"following problem:
1063"
X,0.709849157054126,"min
X∈Rn×d n
X"
X,0.7102928127772848,"i,i′=1"
X,0.7107364685004437,"C1/2
i,i′ −∥Xi −Xi′∥

2
(84)"
X,0.7111801242236024,"Let O(n) denote the set of all n × n orthonormal matrices. Suppose X∗is a minimizer, then RX∗is
1064"
X,0.7116237799467613,"also a minimizer for the above problem for all R ∈O(n).
1065"
X,0.7120674356699201,"In practice, this means manually setting suitable rotation and flipping matrices for each method at
1066"
X,0.712511091393079,"each step, especially for the GW method.
1067"
X,0.7129547471162379,"However, we understand that this issue stems from the inherent properties of the GW/PGW method.
1068"
X,0.7133984028393966,"GW can be seen as a tool that describes the similarity between two graphs, which are rotation-invariant
1069"
X,0.7138420585625554,"and flipping-invariant. Therefore, the GW/PGW barycenter essentially describes the interpolation
1070"
X,0.7142857142857143,"between two graphs rather than two point clouds.
1071"
X,0.7147293700088732,"M.2
Details of Point Cloud Matching
1072"
X,0.7151730257320319,"Dataset setup. In the Moon dataset (see link), we apply n = 200 and set Gaussian variance to be 0.2.
1073"
X,0.7156166814551908,"The outliers are sampled from region [[−2, −1.5] × [−3.5, −3]].
1074"
X,0.7160603371783496,"In the second experiment, the circle data is uniformly sampled from 2D circle"
X,0.7165039929015085,S1 = {s ∈R2 : ∥s∥2 = 1}
X,0.7169476486246673,and spherical data is uniformly sampled from 3D sphere
X,0.717391304347826,"S2 = {s + [0, 0, 4] ∈R2 : ∥s∥2 = 1},"
X,0.7178349600709849,"where the shift [0, 0, 4] is applied for visualization.
1075"
X,0.7182786157941438,"We set sample size n = 200 for both 2D and 3D samples.
1076"
X,0.7187222715173026,"In both experiment, the number of outliers is ηn = 0.2n = 40.
1077"
X,0.7191659272404614,"Numerical details. In GW, we normalize the two point clouds as"
X,0.7196095829636202,"X = (X, dX, n
X i=1"
X,0.7200532386867791,"1
nδxi), Y = (Y, dY ,"
X,0.7204968944099379,"n+nη
X j=1"
X,0.7209405501330968,"1
n + nη δyj)."
X,0.7213842058562555,"In PGW, MPGW, UGW, we define the point clouds as
1078"
X,0.7218278615794144,"X = (X, dX, n
X i=1"
X,0.7222715173025732,"1
nδxi), Y = (Y, dY ,"
X,0.7227151730257321,"n+nη
X j=1"
X,0.7231588287488908,"1
nδyj)."
X,0.7236024844720497,"In PGW, we choose λ such that λ ≥max(max((CX)2), max((CY )2)), in particular, λ = 10.0.
1079"
X,0.7240461401952085,"In MPGW, we set ρ = 1.0.
1080"
X,0.7244897959183674,"In UGW, we set ρ1 = ρ2 = 10.0, ϵ = 0.05.
1081"
X,0.7249334516415262,"N
Details of Shape Retrieval Experiment
1082"
X,0.725377107364685,"Dataset details. We test two datasets in this experiment, which we refer to as Dataset I and Dataset
1083"
X,0.7258207630878438,"II. We visualize Dataset I in Figure 6a and Dataset II in Figure 6b. The complete datasets can be
1084"
X,0.7262644188110027,"accessed from the supplementary materials.
1085"
X,0.7267080745341615,"bone
goblet
star
horseshoe"
X,0.7271517302573203,"rectangle
trapezoid
disk
annulus"
X,0.7275953859804791,(a) Dataset I
X,0.728039041703638,"rectangle
arrow
semicircle"
X,0.7284826974267968,"house
double arrow
circle"
X,0.7289263531499557,(b) Dataset II
X,0.7293700088731144,Figure 6: Visualization of a representative shape from each class of the two datasets.
X,0.7298136645962733,"Numerical details.
We represent the shapes in each dataset as mm-spaces Xi
=
1086

R2, ∥· ∥2, µi = Pni"
X,0.7302573203194321,"k=1 αiδxi
k"
X,0.730700976042591,"
. We use αi =
1
ni to compute the GW distances for the balanced
1087"
X,0.7311446317657497,"mass constraint setting. For the remaining distances, we set α = 1"
X,0.7315882874889086,"N , where N is the median number
1088"
X,0.7320319432120674,"of points across all shapes in the dataset. For the SVM experiments, we use exp(−σD) as the kernel
1089"
X,0.7324755989352263,"for the SVM model, and we set σ = 10 for all distances. Moreover, we normalize the matrix D to
1090"
X,0.7329192546583851,"facilitate a fair comparison of each distance used, since the considered distance may have different
1091"
X,0.7333629103815439,"scales. We note that the resulting kernel matrix is not necessarily positive semidefinite.
1092"
X,0.7338065661047027,"In computing the pairwise distances, for the PGW method, we set λ such that λ ≤λmax =
1093"
X,0.7342502218278616,"maxi (|Ci|2). In particular, we compute λmax for each dataset and use λ =
1
5λmax for each
1094"
X,0.7346938775510204,"experiment. For UGW, we use ε = 10−1 and ρ1 = ρ2 = 1 for both experiments. Finally, for MPGW,
1095"
X,0.7351375332741792,"we set the mass-constrained term to be ρ = min(|µi|, |µj|) when computing the similarity between
1096"
X,0.735581188997338,"shape Xi and Xj.
1097"
X,0.7360248447204969,"Performance analysis. The pairwise distance matrices are visualized for each dataset in Figure 7, and
1098"
X,0.7364685004436557,"the confusion matrices computed with each dataset are given in Figure 8. Finally, the classification
1099"
X,0.7369121561668146,"accuracy with the SVM experiments is reported in Table 1a. The results indicate that the PGW
1100"
X,0.7373558118899733,"distance is able to consistently obtain high performance across both datasets.
1101"
X,0.7377994676131322,"In addition, from Figure 7, we observe that PGW qualitatively admits a more reasonable similarity
1102"
X,0.738243123336291,"measure compared to other methods. For example, in Dataset I, class “bone” and “rectangle” should
1103"
X,0.7386867790594499,"have relatively smaller distance than “bone” and “annulus”. Ideally, a reasonable distance should
1104"
X,0.7391304347826086,"satisfy the following:
1105"
X,0.7395740905057675,"0 < d(bone, rectangle) < d(bone, anulus)."
X,0.7400177462289264,"However, we do not observe this relation in GW and UGW3, and for the MPGW method,
1106"
X,0.7404614019520852,"MPGW(bone, rectangle) ≈0, which is also undesirable. For PGW, however, we do observe
1107"
X,0.7409050576752441,"this relation. Additionally, we report the wall-clock time comparison in Table 1b.
1108"
X,0.7413487133984028,"3For UGW, this is due to the Sinkhorn regularization term. bone"
X,0.7417923691215617,rectangle
X,0.7422360248447205,goblet
X,0.7426796805678794,trapezoid star disk
X,0.7431233362910381,horseshoe
X,0.743566992014197,annulus bone
X,0.7440106477373558,rectangle
X,0.7444543034605147,goblet
X,0.7448979591836735,trapezoid star disk
X,0.7453416149068323,horseshoe
X,0.7457852706299911,annulus GW bone
X,0.74622892635315,rectangle
X,0.7466725820763088,goblet
X,0.7471162377994676,trapezoid star disk
X,0.7475598935226264,horseshoe
X,0.7480035492457853,annulus MPGW bone
X,0.7484472049689441,rectangle
X,0.748890860692103,goblet
X,0.7493345164152617,trapezoid star disk
X,0.7497781721384206,horseshoe
X,0.7502218278615794,annulus UGW bone
X,0.7506654835847383,rectangle
X,0.751109139307897,goblet
X,0.7515527950310559,trapezoid star disk
X,0.7519964507542147,horseshoe
X,0.7524401064773736,annulus
X,0.7528837622005324,PGW (ours) 0.0 0.2 0.4 0.6 0.8 1.0
X,0.7533274179236912,(a) Dataset I
X,0.75377107364685,rectangle house arrow
X,0.7542147293700089,double arrow
X,0.7546583850931677,semicircle
X,0.7551020408163265,circle
X,0.7555456965394853,rectangle house arrow
X,0.7559893522626442,double arrow
X,0.756433007985803,semicircle
X,0.7568766637089619,circle GW
X,0.7573203194321206,rectangle house arrow
X,0.7577639751552795,double arrow
X,0.7582076308784383,semicircle
X,0.7586512866015972,circle MPGW
X,0.7590949423247559,rectangle house arrow
X,0.7595385980479148,double arrow
X,0.7599822537710736,semicircle
X,0.7604259094942325,circle UGW
X,0.7608695652173914,rectangle house arrow
X,0.7613132209405501,double arrow
X,0.761756876663709,semicircle
X,0.7622005323868678,circle
X,0.7626441881100267,PGW (ours) 0.0 0.2 0.4 0.6 0.8 1.0
X,0.7630878438331854,(b) Dataset II
X,0.7635314995563443,Figure 7: Pairwise distance matrices computed for each dataset. bone
X,0.7639751552795031,rectangle
X,0.764418811002662,goblet
X,0.7648624667258208,trapezoid star disk
X,0.7653061224489796,horseshoe
X,0.7657497781721384,annulus bone
X,0.7661934338952973,rectangle
X,0.7666370896184561,goblet
X,0.7670807453416149,trapezoid star disk
X,0.7675244010647737,horseshoe
X,0.7679680567879326,annulus GW bone
X,0.7684117125110914,rectangle
X,0.7688553682342503,goblet
X,0.769299023957409,trapezoid star disk
X,0.7697426796805679,horseshoe
X,0.7701863354037267,annulus MPGW bone
X,0.7706299911268856,rectangle
X,0.7710736468500443,goblet
X,0.7715173025732032,trapezoid star disk
X,0.771960958296362,horseshoe
X,0.7724046140195209,annulus UGW bone
X,0.7728482697426797,rectangle
X,0.7732919254658385,goblet
X,0.7737355811889973,trapezoid star disk
X,0.7741792369121562,horseshoe
X,0.774622892635315,annulus
X,0.7750665483584738,PGW (ours) 0.0 0.2 0.4 0.6 0.8 1.0
X,0.7755102040816326,(a) Dataset I
X,0.7759538598047915,rectangle house arrow
X,0.7763975155279503,double arrow
X,0.7768411712511092,semicircle
X,0.7772848269742679,circle
X,0.7777284826974268,rectangle house arrow
X,0.7781721384205856,double arrow
X,0.7786157941437445,semicircle
X,0.7790594498669032,circle GW
X,0.7795031055900621,rectangle house arrow
X,0.7799467613132209,double arrow
X,0.7803904170363798,semicircle
X,0.7808340727595386,circle MPGW
X,0.7812777284826974,rectangle house arrow
X,0.7817213842058562,double arrow
X,0.7821650399290151,semicircle
X,0.782608695652174,circle UGW
X,0.7830523513753327,rectangle house arrow
X,0.7834960070984915,double arrow
X,0.7839396628216504,semicircle
X,0.7843833185448092,circle
X,0.7848269742679681,PGW (ours) 0.0 0.2 0.4 0.6 0.8 1.0
X,0.7852706299911268,(b) Dataset II
X,0.7857142857142857,Figure 8: Confusion matrices computed from nearest neighbor classification experiments.
X,0.7861579414374446,"O
Wall-Clock Time Comparison for Partial GW Solvers
1109"
X,0.7866015971606034,"In this section, we present the wall-clock time comparison between our method Algorithms 1, 2,
1110"
X,0.7870452528837621,"the Frank-Wolf algorithm proposed in [45], and its Sinkhorn version [41, 45]. Note that these two
1111"
X,0.787488908606921,"baselines solve a mass constraint version of the PGW problem, which we refer to as the “MPGW”
1112"
X,0.7879325643300799,"problem. The proposed PGW formulation in this paper can be regarded as a “Lagrangian formulation”
1113"
X,0.7883762200532387,"of MPGW4 formulation to the PGW problem defined in (10). In this paper, we call these two baselines
1114"
X,0.7888198757763976,"as “MPGW algorithm” and “Sinkhorn PGW algorithm”.
1115"
X,0.7892635314995563,"Numerical details.
The data is generated as follows:
let µ
=
Unif([0, 2]2) and ν
=
1116"
X,0.7897071872227152,"Unif([0, 2]3), we select i.i.d. samples {xi ∼µ}n
i=1, {yj ∼ν}m
j=1, where n is selected from
1117"
X,0.790150842945874,"[10, 50, 100, 150, ..., 10000] and m = n + 100, p = 1n/m, q = 1m/m. For each n, we set
1118"
X,0.7905944986690329,"λ = 0.2, 1.0, 10.0. The mass constraint parameter for the algorithm in [45], and Sinkhorn is com-
1119"
X,0.7910381543921916,"puted by the mass of the transportation plan obtained by Algorithm 1 or 2. The runtime results are
1120"
X,0.7914818101153505,"shown in Figure 9.
1121"
X,0.7919254658385093,"Regarding the acceleration technique, for the POT problem in step 1, our algorithms and the MPGW
1122"
X,0.7923691215616682,"algorithm apply the linear programming solver provided by Python OT package [55], which is written
1123"
X,0.792812777284827,"in C++. The Sinkhorn algorithm from Python OT does not have an acceleration technique. Thus, we
1124"
X,0.7932564330079858,"only test its wall-clock time for n ≤2000. The data type is 64-bit float number.
1125"
X,0.7937000887311446,"From Figure 9, we can observe the Algorithms 1, 2 and MPGW algorithm have a similar order of
1126"
X,0.7941437444543035,"time complexity. However, using the column/row-reduction technique for the POT computation
1127"
X,0.7945874001774623,"discussed in previous sections, and the fact the convergence behaviors of Algorithms 1 and 2 are
1128"
X,0.7950310559006211,"similar to the MPGW algorithm, we observe that the proposed algorithms 1, 2 admits a slightly faster
1129"
X,0.7954747116237799,"speed than MPGW solver.
1130"
X,0.7959183673469388,"0
2000
4000
6000
8000
10000
n: size of p 10
3 10
2 10
1 100 101 102"
X,0.7963620230700976,wall-clock time
X,0.7968056787932565,"v1, = 0.2
v1, = 10.0
v2, = 0.2
v2, = 10.0
m, = 0.2
m, = 10.0
s, = 0.2
s, = 10.0"
X,0.7972493345164152,"Figure 9: We test the wall-clock time of our Algorithm 1 and Algorithm 2, the MPGW solver
(Algorithm 1 in [45]) , and the Sinkhorn algorithm [41]. We denote these methods as v1, v2, m, s
respectively. The linear programming solver applied in the first three methods is from POT [55],
which is written in C++. The maximum number of iterations for all the methods is set to be 1000.
The maximum iteration for OT/OPT solvers is set to be 300n. The maximum Sinkhorn iteration is
set to be 1000. The convergence tolerance for the Frank-Wolfe algorithm and the Sinkhorn algorithm
are set to be 1e −5. To achieve their best performance, the number of dummy points is set to be 1 for
MPGW and PGW."
X,0.7976929902395741,"4Due to the non-convexity of GW, we do not have a strong duality in some of the GW representations. Thus,
the Lagrangian form is not a rigorous description."
X,0.7981366459627329,"P
Positive Unlabeled Learning Problem
1131"
X,0.7985803016858918,"P.1
Problem setup.
1132"
X,0.7990239574090505,"Positive unlabeled (PU) learning [56, 57, 58] is a semi-supervised binary classification problem for
1133"
X,0.7994676131322094,"which the training set only contains positive samples. In particular, suppose there exists a fixed
1134"
X,0.7999112688553682,"unknown overall distribution over triples (x, o, l), where x is data, l ∈{0, 1} is the label of x,
1135"
X,0.8003549245785271,"o ∈{0, 1} where o = 1, o = 0 denote that l is observed or not, respectively. In the PU task, the
1136"
X,0.8007985803016859,"assumption is that only positive samples’ labels can be observed, i.e., Prob(o = 1|x, l = 0) = 0.
1137"
X,0.8012422360248447,"Consider training labeled data Xpu = {(xpu
i , l)}n
i=1 ⊂{x : o = 1} and testing data Xun =
1138"
X,0.8016858917480035,"{xun
j }m
j=1 ⊂{x : o = 0}, where xipX
i
∈Rd1, xu
j ∈Rd2. In the classical PU learning setting,
1139"
X,0.8021295474711624,"d2 = d1. However, in [44] this assumption is relaxed. The goal is to leverage Xp to design a classifier
1140"
X,0.8025732031943212,"ˆl : xu →{0, 1} to predict l(xu) for all xu ∈Xu.5
1141"
X,0.80301685891748,"Following [57, 45, 44], in this experiment, we assume that the “select completely at random” (SCAR)
1142"
X,0.8034605146406388,"assumption holds: Prob(o = 1|x, l = 1) = Prob(o = 1|l = 1). In addition, we use π = Prob(l =
1143"
X,0.8039041703637977,"1) ∈[0, 1] to denote the ratio of positive samples in testing set6. Following the PU learning setting in
1144"
X,0.8043478260869565,"[58, 59, 45, 44], we assume π is known. In all the PU learning experiments, we fix π = 0.2.
1145"
X,0.8047914818101154,"P.2
Our method.
1146"
X,0.8052351375332741,"Similar to [45] our method is designed as follows: We set p ∈Rn, q ∈Rm as pX
i
= π"
X,0.805678793256433,"n, i ∈[1 :
1147"
X,0.8061224489795918,"n];
qY
j = 1"
X,0.8065661047027507,"m, j ∈[1 : m]. Let Xp = (Xp, ∥· ∥d1, Pn
i=1 pX
i δxi), Xu = (Xu, ∥· ∥d2, Pn
j=1 qY
j δyj).
1148"
X,0.8070097604259094,"We solve the partial GW problem PGWλ(Xp, Xu) and suppose γ is a solution. Let γ2 = γ⊤1n. The
1149"
X,0.8074534161490683,"classifier ˆl is defined by the indicator function
1150"
X,0.8078970718722271,"ˆlγ(xu) = 1{xu: γ2(xu)≥quantile},
(85)"
X,0.808340727595386,"where quantile is the quantile value of γ2 according to 1 −π.
1151"
X,0.8087843833185449,"Regarding the initial guess γ(1), [45] proposed a POT-based approach when X and Y are sampled
1152"
X,0.8092280390417036,"from the same domain, i.e., d1 = d2, which we refer to as “POT initialization.”
1153"
X,0.8096716947648624,"When X, Y are sampled from different spaces, that is, d1 ̸= d2, the above technique (86) is not
1154"
X,0.8101153504880213,"well-defined. Inspired by [8, 44], we propose the following “first lower bound-partial OT” (FLB-POT)
1155"
X,0.8105590062111802,"initialization:
1156"
X,0.8110026619343389,"γ(1) = arg
min
γ∈Γ≤(p,q) Z"
X,0.8114463176574978,"X×Y
|sX,2(x) −sY,2(y)|2dγ(x, y) + λ(|p −γ1| + |q −γ2|),"
X,0.8118899733806566,"where sX,2(x) =
R"
X,0.8123336291038155,"X |x −x′|2dµ(x) and sY,2 is defined similarly. The above formula is analog to
1157"
X,0.8127772848269743,"Eq. (7) in [44], which is designed for the unbalanced GW setting. To distinguish them, in this paper
1158"
X,0.813220940550133,"we call the Eq. (7) in [44] as “FLB-UOT initilization”.
1159"
X,0.8136645962732919,"P.3
Dataset.
1160"
X,0.8141082519964508,"The datasets include MNIST, EMNIST, and the following three domains of Caltech Office: Amazon
1161"
X,0.8145519077196096,"(A), Webcam (W), and DSLR (D) [60]. For each domain, we select the SURF features [60] and
1162"
X,0.8149955634427685,"DECAF features [61]. For MNIST and EMNIST, we train an auto-encoder, respectively, and the
1163"
X,0.8154392191659272,"embedding space dimension is 4 and 6, respectively. See Figure 10 for the TSNE visualization of
1164"
X,0.8158828748890861,"these datasets.
1165"
X,0.8163265306122449,"P.4
Initial methods.
1166"
X,0.8167701863354038,"In this experiment, we employ three distinct initial methods: “POT”, “FLB-UOT”, “FLB-POT”.
1167"
X,0.8172138420585625,"5In the classical setting, the goal is to learn a classifier for all x. In this experiment, we follow the setting in
[44].
6In the classical setting, the prior distribution π is the ratio of positive samples of the original dataset. For
convenience, we ignore the difference between this ratio in the original dataset and the test dataset."
X,0.8176574977817214,"(a) MNIST
(b) EMNIST"
X,0.8181011535048802,"(c) Surf(A)
(d) Decaf(A)"
X,0.8185448092280391,"(e) Surf(D)
(f) Decaf(D)"
X,0.8189884649511979,"(g) Surf(W)
(h) Decaf(w)"
X,0.8194321206743567,"Figure 10: TSNE visulization for datasets MNIST,EMNIST,Caltech Office."
X,0.8198757763975155,"“POT initialization” is firstly introduced in [45].When X1, X2 are in the same dimensional space,
1168"
X,0.8203194321206744,"i.e. d1 = d2. The initial guess, γ(1) is given by the following partial OT variant problem:
1169"
X,0.8207630878438332,"γ(1) = arg
min
γ∈ΓP U,π(p,q)⟨L(X, Y ), γ⟩F ,
(86)"
X,0.821206743566992,"where L(X, Y ) ∈Rn×m, (L(X, Y ))ij = ∥xi −yj∥2 and
1170"
X,0.8216503992901508,"ΓP U,π(p, q) := {γ ∈Rn×m
+
: (γ⊤1n)j ∈{qY
j , 0}, ∀j; γ1m ≤p, |γ| = π}.
(87)"
X,0.8220940550133097,"The above problem can be solved by a Lasso (L1 norm) regularized OT solver.
1171"
X,0.8225377107364685,"When d1 ̸= d2, the above technique can not be applied since the problem (86) (in particular L(X, Y ))
1172"
X,0.8229813664596274,"is not well-defined.
1173"
X,0.8234250221827861,"The second method “FLB-UOT” is induced in [44]:
1174"
X,0.823868677905945,"γ(1) = arg
min
γ∈Γ≤(p,q) Z"
X,0.8243123336291038,"X×Y
|sX,2(x) −sY,2(y)|2dγ(x, y) + λ(DKL(γ1, p) + DKL(γ2, q)), (88)"
X,0.8247559893522627,"where sX,2(x) =
R"
X,0.8251996450754214,"X |x −x′|2dµ(x) and sY,2 is defined similarly. The problem (88) is called
1175"
X,0.8256433007985803,"Hellinger Kantorovich, which is a classical unbalanced optimal transport problem. It can be solved
1176"
X,0.8260869565217391,"by the Sinkhorn solver [38].
1177"
X,0.826530612244898,"Analog to the above method, we propose the third method, called “FLB-POT” (first lower bound-
1178"
X,0.8269742679680568,"partial optimal transport)
1179"
X,0.8274179236912156,"γ(1) = arg
min
γ∈Γ≤(p,q) Z"
X,0.8278615794143744,"X×Y
|sX,2(x) −sY,2(y)|2dγ(x, y) + λ(|p −γ1| + |q −γ2|).
(89)"
X,0.8283052351375333,"The above problem is a partial OT problem and can be solved by classical linear programming [12].
1180"
X,0.8287488908606921,"P.5
Numerical details and performance.
1181"
X,0.8291925465838509,"Accuracy Comparison. In Table 2 and 4, we present the accuracy results for the MPGW, UGW, and
1182"
X,0.8296362023070097,"the proposed PGW methods when using three different initialization methods: POT, FLB-UOT, and
1183"
X,0.8300798580301686,"FLB-POT.
1184"
X,0.8305235137533274,"Following [45], in the MPGW and PGW methods, we incorporate the prior knowledge π into the
1185"
X,0.8309671694764863,"definition of p and q. Thus it is sufficient to set mass = π for MPGW and choose a sufficiently
1186"
X,0.831410825199645,"large value for λ in the PGW method. This configuration ensures that the mass matched in the target
1187"
X,0.8318544809228039,"domain Y is exactly equal to π. However, in the UGW method [44], the setting is p = 1"
X,0.8322981366459627,"n1n and
1188 q = 1"
X,0.8327417923691216,"m1m. Therefore, in each experiment, we test different parameters (ρ, ρ2, ϵ) and select the ones
1189"
X,0.8331854480922803,"that result in transported mass close to π.
1190"
X,0.8336291038154392,"Overall, all methods show improved performance in MNIST and EMNIST datasets. One possible
1191"
X,0.834072759538598,"reason for this could be the better separability of the embeddings in MNIST and EMNIST, as
1192"
X,0.8345164152617569,"DATASET
INIT METHOD
INIT ACCURACY
MPGW
UGW
PGW (OURS)"
X,0.8349600709849158,"M →M
POT
100%
100%
95%
100%
M →M
FLB-U
75%
96%
95%
96%
M →M
FLB-P
75%
99%
95%
99%
M →EM
FLB-U
78%
94%
95%
94%
M →EM
FLB-P
78%
94%
95%
94%
EM →M
FLB-U
75%
97%
96%
97%
EM →M
FLB-P
75%
97%
96%
97%
EM →EM
POT
100%
100%
95%
100%
EM →EM
FLB-U
78%
94%
95%
94%
EM →EM
FLB-P
78%
95%
95%
95%"
X,0.8354037267080745,"Table 2: Accuracy comparison of the MPGW, UGW, and the proposed PGW method on PU learning.
Here, ‘M’ denotes MNIST, and ‘EM’ denotes EMNIST."
X,0.8358473824312334,"illustrated in Figure 10. Additionally, since MPGW and PGW incorporate information from r into
1193"
X,0.8362910381543922,"their formulations, they exhibit slightly better accuracy in many experiments.
1194"
X,0.8367346938775511,"Numerical details. In this experiment, to prevent unexpected convergence to local minima in the
1195"
X,0.8371783496007098,"Frank-Wolf algorithms, we manually set α = 1 during the line search step for both MPGW and PGW
1196"
X,0.8376220053238687,"methods.
1197"
X,0.8380656610470275,"For the convergence criteria, we set the tolerance term for Frank-Wolfe convergence and the main
1198"
X,0.8385093167701864,"loop in the UGW algorithm to be 1e −5. Additionally, the tolerance for Sinkhorn convergence in
1199"
X,0.8389529724933452,"UGW was set to 1e −6. The maximum number of iterations for the POT solver in PGW and MPGW
1200"
X,0.839396628216504,"was set to 500n. In addition, for MPGW, we set mass = 0.2 and for PGW method, based on lemma
1201"
X,0.8398402839396628,"E.2, we set λ to be constant such that 2λ ≥(max(|CX|)2 + max(|CY |)2).
1202"
X,0.8402839396628217,"Regarding data types, we used 64-bit floating-point numbers for MPGW and PGW, and 32-bit
1203"
X,0.8407275953859805,"floating-point numbers for UGW.
1204"
X,0.8411712511091393,"For the MNIST and EMNIST datasets, we set n = 1000 and m = 5000. In the Surf(A) and Decaf(A)
1205"
X,0.8416149068322981,"datasets, each class contained an average of 100 samples. To ensure the SCAR assumption, we set
1206"
X,0.842058562555457,"n = 1/2 ∗100 = 50 and m = 250. Similarly, for the Surf(D) and Decaf(D) datasets, we set n = 15
1207"
X,0.8425022182786158,"and m = 75. Finally, for Surf(W) and Decaf(W), we used n = 20 and m = 100.
1208"
X,0.8429458740017747,"Wall-clock time In Table 3, we provide a comparison of wall-clock times for the MNIST and
1209"
X,0.8433895297249334,"EMNIST datasets.
1210"
X,0.8438331854480923,"SOURCE
TARGET
INIT METHOD
INIT TIME
MPGW
UGW
PGW (OURS)"
X,0.8442768411712511,"M(1000)
M(5000)
POT
0.5
7.2
152.0
7.4
M(1000)
M(5000)
FLB-U
0.02
30.5
152.6
27.8
M(1000)
M(5000)
FLB-P
0.5
27.8
144.9
26.9
EM(1000)
EM(5000)
POT
0.5
7.3
157.3
7.5
EM(1000)
EM(5000)
FLB-U
0.02
30.0
181.8
29.9
EM(1000)
EM(5000)
FLB-P
0.5
22.2
155.1
22.3
M(1000)
EM(5000)
FLB-U
0.02
34.0
157.9
34.4
M(1000)
EM(5000)
FLB-P
0.5
34.9
155.5
35.0
EM(1000)
M(5000)
FLB-U
0.02
24.3
139.3
22.2
EM(1000)
M(5000)
FLB-P
0.5
32.0
162.7
29.9"
X,0.84472049689441,"M(2000)
M(10000)
POT
1.7
31.1
1384.8
32.1
M(2000)
M(10000)
FLB-U
0.1
209.0
1525.8
192.5
M(2000)
M(10000)
FLB-P
1.7
208.0
1418.4
192.1
M(2000)
EM(10000)
FLB-U
0.1
165.1
1606.1
164.2
M(2000)
EM(10000)
FLB-P
1.7
224.1
1420.7
223.7
EM(2000)
M(10000)
FLB-U
0.1
149.1
1426.5
138.1
EM(2000)
M(10000)
FLB-P
1.7
113.9
1407.6
103.9
EM(2000)
EM(10000)
POT
1.6
32.4
1445.9
33.4
EM(2000)
EM(10000)
FLB-U
0.1
233.0
1586.3
233.9
EM(2000)
EM(10000)
FLB-P
1.8
142.1
1620.6
142.1"
X,0.8451641526175687,"Table 3: In this table, we present the wall-clock time for the MPGW, UGW, and the proposed PGW
method, as well as three different initialization methods (POT, FLB-UOT, FLB-POT). In the “Source”
(or “Target”) columm, M (or EM) denotes the MNIST (or EMNIST) dataset, the value 1000 (or 5000)
denotes the sample size of X (or Y ). The units of all reported wall-clock times is seconds."
X,0.8456078083407276,"DATASET
INIT METHOD
INIT ACCURACY
MPGW
UGW
PGW (OURS)"
X,0.8460514640638864,"SURF(A) →SURF(A)
POT
81.2%
74.7%
66.5%
74.7%
SURF(A) →SURF(A)
FLB-U
64.9%
65.7%
66.5%
65.7%
SURF(A) →SURF(A)
FLB-P
63.3%
66.5%
66.5%
66.5%
DECAF(A) →DECAF(A)
POT
95.1%
95.1%
60.8%
95.1%
DECAF(A) →DECAF(A)
FLB-U
78.0%
67.4%
83.7%
67.4%
DECAF(A) →DECAF(A)
FLB-P
78.0%
74.7%
88.6%
74.7%
SURF(D) →SURF(D)
POT
100%
100%
89.3%
100%
SURF(D) →SURF(D)
FLB-U
62.7%
73.3%
84.0%
73.3%
SURF(D) →SURF(D)
FLB-P
60.0%
60.0%
78.7%
60.0%
DECAF(D) →DECAF(D)
POT
100%
100%
100%
100%
DECAF(D) →DECAF(D)
FLB-U
76.0%
68.0%
70.7%
68.0%
DECAF(D) →DECAF(D)
FLB-P
73.3%
73.3%
86.7%
73.3%
SURF(W) →SURF(W)
POT
100.0%
100.0%
81.3%
100.0%
SURF(W) →SURF(W)
FLB-U
76.0%
70.7%
81.3%
70.7%
SURF(W) →SURF(W)
FLB-P
73.3%
68.0%
78.7%
68.0%
DECAF(W) →DECAF(W)
POT
100%
100%
100%
100%
DECAF(W) →DECAF(W)
FLB-U
73.3%
68.0%
62.7%
68.0%
DECAF(W) →DECAF(W)
FLB-P
70.7%
70.7%
73.3%
70.7%"
X,0.8464951197870453,"SURF(A) →DECAF(A)
FLB-U
73.9%
83.7%
91.8%
83.7%
SURF(A) →DECAF(A)
FLB-P
73.9%
83.7%
87.8%
83.7%
DECAF(A) →SURF(A)
FLB-U
67.3%
67.3%
69.0%
67.3%
DECAF(A) →SURF(A)
FLB-P
67.3%
68.2%
71.4%
68.2%
SURF(D) →DECAF(D)
FLB-U
76.0%
76.0%
65.3%
76.0%
SURF(D) →DECAF(D)
FLB-P
76.0%
76.0%
65.3%
76.0%
DECAF(D) →SURF(D)
FLB-U
73.3%
62.7%
73.3%
62.7%
DECAF(D) →SURF(D)
FLB-P
73.3%
73.3%
73.3%
73.3%
SURF(W) →DECAF(W)
FLB-U
70.7%
70.7%
76.0%
70.7%
SURF(W) →DECAF(W)
FLB-P
70.7%
70.7%
76.0%
70.7%
DECAF(W) →SURF(W)
FLB-U
68.0%
68.0%
65.3%
68.0%
DECAF(W) →SURF(W)
FLB-P
68.0%
68.0%
70.7%
68.0%"
X,0.8469387755102041,"Table 4: In this table, we present the accuracy comparison of the MPGW, UGW, and the proposed
PGW method. We report the initialization method and its accuracy, followed by the accuracy of each
of the methods MPGW, UGW, and PGW. The prior distribution π = p(l = 1) is set to be 0.2 in all
experiments. To guarantee the SCAR assumption, for Surf(A) and Decaf(A), we set n = 50, which is
the half of the total number of data in one single class. m is set to be 250. Similarly, we set suitable
n, m for Surf(D), Decaf(D), Surf(W), Decaf(W)."
X,0.8473824312333629,"DATASET
INIT METHOD
INIT TIME
MPGW
UGW
PGW (OURS)"
X,0.8478260869565217,"SURF(A) →SURF(A)
POT
1.4E-3
1.9E-2
3.8
2.0E-2
SURF(A) →SURF(A)
FLB-U
2.2E-3
1.8E-2
3.6
1.9E-2
SURF(A) →SURF(A)
FLB-P
1.7E-3
1.8E-2
3.8
1.5E-2
DECAF(A) →DECAF(A)
POT
1.7E-3
1.9E-2
7.3
1.9E-2
DECAF(A) →DECAF(A)
FLB-U
9.6E-3
1.8E-2
6.8
1.5E-2
DECAF(A) →DECAF(A)
FLB-P
2.0E-3
1.8E-2
6.7
1.6E-2
SURF(D) →SURF(D)
POT
2.9E-4
5.8E-4
3.1
3.8E-4
SURF(D) →SURF(D)
FLB-U
1.4E-3
3.0E-3
5.4
2.2E-3
SURF(D) →SURF(D)
FLB-P
3.1E-4
2.9E-3
5.4
2.1E-3
DECAF(D) →DECAF(D)
POT
3.1E-4
6.0E-4
3.3
3.6E-4
DECAF(D) →DECAF(D)
FLB-U
1.4E-3
2.9E-3
5.8
2.1E-3
DECAF(D) →DECAF(D)
FLB-P
3.4E-4
2.8E-3
5.3
2.0E-3
SURF(W) →SURF(W)
POT
3.0E-4
6.0E-4
5.2
3.6E-4
SURF(W) →SURF(W)
FLB-U
1.3E-3
2.9E-3
5.1
2.1E-3
SURF(W) →SURF(W)
FLB-P
3.3E-4
2.9E-3
5.1
2.1E-3
DECAF(W) →DECAF(W)
POT
3.3E-4
6.2E-4
3.3
3.4E-4
DECAF(W) →DECAF(W)
FLB-U
1.2E-3
2.9E-3
5.8
2.1E-3
DECAF(W) →DECAF(W)
FLB-P
3.3E-4
2.8E-3
5.4
2.0E-3"
X,0.8482697426796806,"SURF(A) →DECAF(A)
FLB-U
1.1E-1
2.8E-2
6.7
2.6E-2
SURF(A) →DECAF(A)
FLB-P
1.9E-3
2.2E-2
0.2
2.1E-2
DECAF(A) →SURF(A)
FLB-U
0.1
5E-2
6.7
4E-2
DECAF(A) →SURF(A)
FLB-P
2E-3
1.8
6.8
1.5
SURF(D) →DECAF(D)
FLB-U
1.8E-3
5.3E-3
6.0
2.3E-3
SURF(D) →DECAF(D)
FLB-P
3.5E-4
3.9E-4
5.9
3.8E-4
DECAF(D) →SURF(D)
FLB-U
1.8E-3
0.296
5.6
0.165
DECAF(D) →SURF(D)
FLB-P
3.3E-4
0.218
5.6
0.170
SURF(W) →DECAF(W)
FLB-U
1.8E-3
5.3E-3
5.0
2.3E-3
SURF(W) →DECAF(W)
FLB-P
3.4E-4
4.1E-4
5.0
3.9E-4
DECAF(W) →SURF(W)
FLB-U
1.8E-3
5.1E-3
5.8
2.1E-3
DECAF(W) →SURF(W)
FLB-P
3.4E-4
2.9E-3
5.6
2.2E-3"
X,0.8487133984028394,"Table 5: In this table, we present the wall-clock time comparison of the MPGW, UGW, and the
proposed PGW method. We report the initialization method and its wall-clock time, followed by the
wall-clock time of each of the methods MPGW, UGW, and PGW. The units of all reported wall-clock
times is seconds. The prior distribution π = p(l = 1) is set to be 0.2 in all experiments. To guarantee
the SCAR assumption, for Surf(A) and Decaf(A), we set n = 50, which is the half of the total number
of data in one single class. m is set to be 250. Similarly, we set suitable n, m for Surf(D), Decaf(D),
Surf(W), Decaf(W)."
X,0.8491570541259982,"Q
Limitations
1211"
X,0.849600709849157,"Compatibility Between Linear Search and Frank-Wolf Solver
1212"
X,0.8500443655723159,"In practice, we have found that in some experiments, the linear search algorithm (see Sections I, J)
1213"
X,0.8504880212954747,"may cause the Frank Wolfe algorithms (1, 2) to stop running earlier than expected. This may hurt the
1214"
X,0.8509316770186336,"performance observed in the PU learning experiments (see Appendix P). As such, we disable line
1215"
X,0.8513753327417923,"search in these experiments.
1216"
X,0.8518189884649512,"However, in other experiments, for example PGW barycenter (Appendix M.1), we do not find a
1217"
X,0.85226264418811,"significant effect of the linear search algorithm on the results.
1218"
X,0.8527062999112689,"MDS in Point Cloud Interpolation Experiment
1219"
X,0.8531499556344276,"In the point cloud interpolation experiment (see Appendix M), for the classical GW barycenter method
1220"
X,0.8535936113575865,"[41] or our PGW barycenter method, the last step is the same: applying MDS on the barycenter
1221"
X,0.8540372670807453,"minimizer C to construct interpolation point cloud Xt. However, such construction is not unique.
1222"
X,0.8544809228039042,"As a consequence, for each constructed Xt, we need to manually set up the rotation and flipping
1223"
X,0.854924578527063,"matrices.
1224"
X,0.8553682342502218,"This problem follows from the fact that the GW and PGW formulations cannot distinguish the data
1225"
X,0.8558118899733806,"from its rotated (and flipped) version. We refer to Section M.1 for details.
1226"
X,0.8562555456965395,"R
Compute Resources
1227"
X,0.8566992014196984,"All experiments presented in this paper are conducted on a computational machine with an AMD
1228"
X,0.8571428571428571,"EPYC 7713 64-Core Processor, 8 × 32GB DIMM DDR4, 3200 MHz, and a NVIDIA RTX A6000
1229"
X,0.857586512866016,"GPU.
1230"
X,0.8580301685891748,"S
Impact Statement
1231"
X,0.8584738243123337,"The work presented in this paper aims to advance the field of machine learning, particularly the
1232"
X,0.8589174800354925,"supplementary theoretical developments and explorations of computational optimal transport. There
1233"
X,0.8593611357586513,"are many potential societal consequences of our work, none of which we feel must be specifically
1234"
X,0.8598047914818101,"highlighted here.
1235"
X,0.860248447204969,"NeurIPS Paper Checklist
1236"
CLAIMS,0.8606921029281278,"1. Claims
1237"
CLAIMS,0.8611357586512866,"Question: Do the main claims made in the abstract and introduction accurately reflect the
1238"
CLAIMS,0.8615794143744454,"paper’s contributions and scope?
1239"
CLAIMS,0.8620230700976043,"Answer: [Yes]
1240"
CLAIMS,0.8624667258207631,"Justification: In the Abstract, we briefly introduce our main contributions, and in the
1241"
CLAIMS,0.862910381543922,"Introduction (Section 1) we explain our main contributions in detail. These contributions
1242"
CLAIMS,0.8633540372670807,"are reflected by the theoretical and experimental results provided in the remainder of the
1243"
CLAIMS,0.8637976929902396,"main text and appendices.
1244"
CLAIMS,0.8642413487133984,"Guidelines:
1245"
CLAIMS,0.8646850044365573,"• The answer NA means that the abstract and introduction do not include the claims
1246"
CLAIMS,0.865128660159716,"made in the paper.
1247"
CLAIMS,0.8655723158828749,"• The abstract and/or introduction should clearly state the claims made, including the
1248"
CLAIMS,0.8660159716060337,"contributions made in the paper and important assumptions and limitations. A No or
1249"
CLAIMS,0.8664596273291926,"NA answer to this question will not be perceived well by the reviewers.
1250"
CLAIMS,0.8669032830523514,"• The claims made should match theoretical and experimental results, and reflect how
1251"
CLAIMS,0.8673469387755102,"much the results can be expected to generalize to other settings.
1252"
CLAIMS,0.867790594498669,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
1253"
CLAIMS,0.8682342502218279,"are not attained by the paper.
1254"
LIMITATIONS,0.8686779059449867,"2. Limitations
1255"
LIMITATIONS,0.8691215616681455,"Question: Does the paper discuss the limitations of the work performed by the authors?
1256"
LIMITATIONS,0.8695652173913043,"Answer: [Yes]
1257"
LIMITATIONS,0.8700088731144632,"Justification: We explain the limitations in Appendix Q.
1258"
LIMITATIONS,0.870452528837622,"Guidelines:
1259"
LIMITATIONS,0.8708961845607809,"• The answer NA means that the paper has no limitation while the answer No means that
1260"
LIMITATIONS,0.8713398402839396,"the paper has limitations, but those are not discussed in the paper.
1261"
LIMITATIONS,0.8717834960070985,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
1262"
LIMITATIONS,0.8722271517302573,"• The paper should point out any strong assumptions and how robust the results are to
1263"
LIMITATIONS,0.8726708074534162,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
1264"
LIMITATIONS,0.8731144631765749,"model well-specification, asymptotic approximations only holding locally). The authors
1265"
LIMITATIONS,0.8735581188997338,"should reflect on how these assumptions might be violated in practice and what the
1266"
LIMITATIONS,0.8740017746228926,"implications would be.
1267"
LIMITATIONS,0.8744454303460515,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
1268"
LIMITATIONS,0.8748890860692103,"only tested on a few datasets or with a few runs. In general, empirical results often
1269"
LIMITATIONS,0.8753327417923691,"depend on implicit assumptions, which should be articulated.
1270"
LIMITATIONS,0.8757763975155279,"• The authors should reflect on the factors that influence the performance of the approach.
1271"
LIMITATIONS,0.8762200532386868,"For example, a facial recognition algorithm may perform poorly when image resolution
1272"
LIMITATIONS,0.8766637089618456,"is low or images are taken in low lighting. Or a speech-to-text system might not be
1273"
LIMITATIONS,0.8771073646850044,"used reliably to provide closed captions for online lectures because it fails to handle
1274"
LIMITATIONS,0.8775510204081632,"technical jargon.
1275"
LIMITATIONS,0.8779946761313221,"• The authors should discuss the computational efficiency of the proposed algorithms
1276"
LIMITATIONS,0.878438331854481,"and how they scale with dataset size.
1277"
LIMITATIONS,0.8788819875776398,"• If applicable, the authors should discuss possible limitations of their approach to
1278"
LIMITATIONS,0.8793256433007985,"address problems of privacy and fairness.
1279"
LIMITATIONS,0.8797692990239574,"• While the authors might fear that complete honesty about limitations might be used by
1280"
LIMITATIONS,0.8802129547471162,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
1281"
LIMITATIONS,0.8806566104702751,"limitations that aren’t acknowledged in the paper. The authors should use their best
1282"
LIMITATIONS,0.8811002661934338,"judgment and recognize that individual actions in favor of transparency play an impor-
1283"
LIMITATIONS,0.8815439219165927,"tant role in developing norms that preserve the integrity of the community. Reviewers
1284"
LIMITATIONS,0.8819875776397516,"will be specifically instructed to not penalize honesty concerning limitations.
1285"
THEORY ASSUMPTIONS AND PROOFS,0.8824312333629104,"3. Theory Assumptions and Proofs
1286"
THEORY ASSUMPTIONS AND PROOFS,0.8828748890860693,"Question: For each theoretical result, does the paper provide the full set of assumptions and
1287"
THEORY ASSUMPTIONS AND PROOFS,0.883318544809228,"a complete (and correct) proof?
1288"
THEORY ASSUMPTIONS AND PROOFS,0.8837622005323869,"Answer: [Yes]
1289"
THEORY ASSUMPTIONS AND PROOFS,0.8842058562555457,"Justification: In each theorem, we clearly specify the details of conditions and assumptions
1290"
THEORY ASSUMPTIONS AND PROOFS,0.8846495119787046,"along with complete proof.
1291"
THEORY ASSUMPTIONS AND PROOFS,0.8850931677018633,"Guidelines:
1292"
THEORY ASSUMPTIONS AND PROOFS,0.8855368234250222,"• The answer NA means that the paper does not include theoretical results.
1293"
THEORY ASSUMPTIONS AND PROOFS,0.885980479148181,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
1294"
THEORY ASSUMPTIONS AND PROOFS,0.8864241348713399,"referenced.
1295"
THEORY ASSUMPTIONS AND PROOFS,0.8868677905944987,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
1296"
THEORY ASSUMPTIONS AND PROOFS,0.8873114463176575,"• The proofs can either appear in the main paper or the supplemental material, but if
1297"
THEORY ASSUMPTIONS AND PROOFS,0.8877551020408163,"they appear in the supplemental material, the authors are encouraged to provide a short
1298"
THEORY ASSUMPTIONS AND PROOFS,0.8881987577639752,"proof sketch to provide intuition.
1299"
THEORY ASSUMPTIONS AND PROOFS,0.888642413487134,"• Inversely, any informal proof provided in the core of the paper should be complemented
1300"
THEORY ASSUMPTIONS AND PROOFS,0.8890860692102928,"by formal proofs provided in appendix or supplemental material.
1301"
THEORY ASSUMPTIONS AND PROOFS,0.8895297249334516,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
1302"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8899733806566105,"4. Experimental Result Reproducibility
1303"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8904170363797693,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
1304"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8908606921029282,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
1305"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8913043478260869,"of the paper (regardless of whether the code and data are provided or not)?
1306"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8917480035492458,"Answer: [Yes]
1307"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8921916592724046,"Justifications: In Sections M.1,M.2,N, subsection “numerical details”, we explain the
1308"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8926353149955635,"detailed parameter settings for each method in order to reproduce our results.
1309"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8930789707187222,"Guidelines:
1310"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8935226264418811,"• The answer NA means that the paper does not include experiments.
1311"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8939662821650399,"• If the paper includes experiments, a No answer to this question will not be perceived
1312"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8944099378881988,"well by the reviewers: Making the paper reproducible is important, regardless of
1313"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8948535936113576,"whether the code and data are provided or not.
1314"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8952972493345164,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
1315"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8957409050576752,"to make their results reproducible or verifiable.
1316"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8961845607808341,"• Depending on the contribution, reproducibility can be accomplished in various ways.
1317"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8966282165039929,"For example, if the contribution is a novel architecture, describing the architecture fully
1318"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8970718722271517,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
1319"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8975155279503105,"be necessary to either make it possible for others to replicate the model with the same
1320"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8979591836734694,"dataset, or provide access to the model. In general. releasing code and data is often
1321"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8984028393966282,"one good way to accomplish this, but reproducibility can also be provided via detailed
1322"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8988464951197871,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
1323"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8992901508429458,"of a large language model), releasing of a model checkpoint, or other means that are
1324"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8997338065661047,"appropriate to the research performed.
1325"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9001774622892635,"• While NeurIPS does not require releasing code, the conference does require all submis-
1326"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9006211180124224,"sions to provide some reasonable avenue for reproducibility, which may depend on the
1327"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9010647737355811,"nature of the contribution. For example
1328"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.90150842945874,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
1329"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9019520851818988,"to reproduce that algorithm.
1330"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9023957409050577,"(b) If the contribution is primarily a new model architecture, the paper should describe
1331"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9028393966282166,"the architecture clearly and fully.
1332"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9032830523513753,"(c) If the contribution is a new model (e.g., a large language model), then there should
1333"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9037267080745341,"either be a way to access this model for reproducing the results or a way to reproduce
1334"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.904170363797693,"the model (e.g., with an open-source dataset or instructions for how to construct
1335"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9046140195208519,"the dataset).
1336"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9050576752440106,"(d) We recognize that reproducibility may be tricky in some cases, in which case
1337"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9055013309671694,"authors are welcome to describe the particular way they provide for reproducibility.
1338"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9059449866903283,"In the case of closed-source models, it may be that access to the model is limited in
1339"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9063886424134872,"some way (e.g., to registered users), but it should be possible for other researchers
1340"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.906832298136646,"to have some path to reproducing or verifying the results.
1341"
OPEN ACCESS TO DATA AND CODE,0.9072759538598048,"5. Open access to data and code
1342"
OPEN ACCESS TO DATA AND CODE,0.9077196095829636,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
1343"
OPEN ACCESS TO DATA AND CODE,0.9081632653061225,"tions to faithfully reproduce the main experimental results, as described in supplemental
1344"
OPEN ACCESS TO DATA AND CODE,0.9086069210292813,"material?
1345"
OPEN ACCESS TO DATA AND CODE,0.90905057675244,"Answer: [Yes]
1346"
OPEN ACCESS TO DATA AND CODE,0.9094942324755989,"Justification: We provide the data and code as supplementary material.
1347"
OPEN ACCESS TO DATA AND CODE,0.9099378881987578,"Guidelines:
1348"
OPEN ACCESS TO DATA AND CODE,0.9103815439219166,"• The answer NA means that paper does not include experiments requiring code.
1349"
OPEN ACCESS TO DATA AND CODE,0.9108251996450755,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
1350"
OPEN ACCESS TO DATA AND CODE,0.9112688553682342,"public/guides/CodeSubmissionPolicy) for more details.
1351"
OPEN ACCESS TO DATA AND CODE,0.9117125110913931,"• While we encourage the release of code and data, we understand that this might not be
1352"
OPEN ACCESS TO DATA AND CODE,0.9121561668145519,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
1353"
OPEN ACCESS TO DATA AND CODE,0.9125998225377108,"including code, unless this is central to the contribution (e.g., for a new open-source
1354"
OPEN ACCESS TO DATA AND CODE,0.9130434782608695,"benchmark).
1355"
OPEN ACCESS TO DATA AND CODE,0.9134871339840284,"• The instructions should contain the exact command and environment needed to run to
1356"
OPEN ACCESS TO DATA AND CODE,0.9139307897071872,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
1357"
OPEN ACCESS TO DATA AND CODE,0.9143744454303461,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
1358"
OPEN ACCESS TO DATA AND CODE,0.9148181011535049,"• The authors should provide instructions on data access and preparation, including how
1359"
OPEN ACCESS TO DATA AND CODE,0.9152617568766637,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
1360"
OPEN ACCESS TO DATA AND CODE,0.9157054125998225,"• The authors should provide scripts to reproduce all experimental results for the new
1361"
OPEN ACCESS TO DATA AND CODE,0.9161490683229814,"proposed method and baselines. If only a subset of experiments are reproducible, they
1362"
OPEN ACCESS TO DATA AND CODE,0.9165927240461402,"should state which ones are omitted from the script and why.
1363"
OPEN ACCESS TO DATA AND CODE,0.917036379769299,"• At submission time, to preserve anonymity, the authors should release anonymized
1364"
OPEN ACCESS TO DATA AND CODE,0.9174800354924578,"versions (if applicable).
1365"
OPEN ACCESS TO DATA AND CODE,0.9179236912156167,"• Providing as much information as possible in supplemental material (appended to the
1366"
OPEN ACCESS TO DATA AND CODE,0.9183673469387755,"paper) is recommended, but including URLs to data and code is permitted.
1367"
OPEN ACCESS TO DATA AND CODE,0.9188110026619344,"6. Experimental Setting/Details
1368"
OPEN ACCESS TO DATA AND CODE,0.9192546583850931,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
1369"
OPEN ACCESS TO DATA AND CODE,0.919698314108252,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
1370"
OPEN ACCESS TO DATA AND CODE,0.9201419698314108,"results?
1371"
OPEN ACCESS TO DATA AND CODE,0.9205856255545697,"Answer: [Yes]
1372"
OPEN ACCESS TO DATA AND CODE,0.9210292812777284,"Justification: We refer to the subsections “experiment setup” in Sections 5, M.1, M.2, N, P.
1373"
OPEN ACCESS TO DATA AND CODE,0.9214729370008873,"Guidelines:
1374"
OPEN ACCESS TO DATA AND CODE,0.9219165927240461,"• The answer NA means that the paper does not include experiments.
1375"
OPEN ACCESS TO DATA AND CODE,0.922360248447205,"• The experimental setting should be presented in the core of the paper to a level of detail
1376"
OPEN ACCESS TO DATA AND CODE,0.9228039041703638,"that is necessary to appreciate the results and make sense of them.
1377"
OPEN ACCESS TO DATA AND CODE,0.9232475598935226,"• The full details can be provided either with the code, in appendix, or as supplemental
1378"
OPEN ACCESS TO DATA AND CODE,0.9236912156166814,"material.
1379"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9241348713398403,"7. Experiment Statistical Significance
1380"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9245785270629991,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
1381"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9250221827861579,"information about the statistical significance of the experiments?
1382"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9254658385093167,"Answer: [Yes]
1383"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9259094942324756,"Justification: We calculate accuracy in experiments N, P, which are the only statistics
1384"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9263531499556344,"reported in this paper. These values are classification accuracies for each tested dataset.
1385"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9267968056787933,"Thus, error bar/variance are not involved in this work.
1386"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.927240461401952,"Guidelines:
1387"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9276841171251109,"• The answer NA means that the paper does not include experiments.
1388"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9281277728482697,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
1389"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9285714285714286,"dence intervals, or statistical significance tests, at least for the experiments that support
1390"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9290150842945873,"the main claims of the paper.
1391"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9294587400177462,"• The factors of variability that the error bars are capturing should be clearly stated (for
1392"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.929902395740905,"example, train/test split, initialization, random drawing of some parameter, or overall
1393"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9303460514640639,"run with given experimental conditions).
1394"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9307897071872228,"• The method for calculating the error bars should be explained (closed form formula,
1395"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9312333629103815,"call to a library function, bootstrap, etc.)
1396"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9316770186335404,"• The assumptions made should be given (e.g., Normally distributed errors).
1397"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9321206743566992,"• It should be clear whether the error bar is the standard deviation or the standard error
1398"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9325643300798581,"of the mean.
1399"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9330079858030168,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
1400"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9334516415261757,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
1401"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9338952972493345,"of Normality of errors is not verified.
1402"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9343389529724934,"• For asymmetric distributions, the authors should be careful not to show in tables or
1403"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9347826086956522,"figures symmetric error bars that would yield results that are out of range (e.g. negative
1404"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.935226264418811,"error rates).
1405"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9356699201419698,"• If error bars are reported in tables or plots, The authors should explain in the text how
1406"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9361135758651287,"they were calculated and reference the corresponding figures or tables in the text.
1407"
EXPERIMENTS COMPUTE RESOURCES,0.9365572315882875,"8. Experiments Compute Resources
1408"
EXPERIMENTS COMPUTE RESOURCES,0.9370008873114463,"Question: For each experiment, does the paper provide sufficient information on the com-
1409"
EXPERIMENTS COMPUTE RESOURCES,0.9374445430346051,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
1410"
EXPERIMENTS COMPUTE RESOURCES,0.937888198757764,"the experiments?
1411"
EXPERIMENTS COMPUTE RESOURCES,0.9383318544809228,"Answer: [Yes]
1412"
EXPERIMENTS COMPUTE RESOURCES,0.9387755102040817,"Justification: See Appendix R.
1413"
EXPERIMENTS COMPUTE RESOURCES,0.9392191659272404,"Guidelines:
1414"
EXPERIMENTS COMPUTE RESOURCES,0.9396628216503993,"• The answer NA means that the paper does not include experiments.
1415"
EXPERIMENTS COMPUTE RESOURCES,0.9401064773735581,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
1416"
EXPERIMENTS COMPUTE RESOURCES,0.940550133096717,"or cloud provider, including relevant memory and storage.
1417"
EXPERIMENTS COMPUTE RESOURCES,0.9409937888198758,"• The paper should provide the amount of compute required for each of the individual
1418"
EXPERIMENTS COMPUTE RESOURCES,0.9414374445430346,"experimental runs as well as estimate the total compute.
1419"
EXPERIMENTS COMPUTE RESOURCES,0.9418811002661934,"• The paper should disclose whether the full research project required more compute
1420"
EXPERIMENTS COMPUTE RESOURCES,0.9423247559893523,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
1421"
EXPERIMENTS COMPUTE RESOURCES,0.9427684117125111,"didn’t make it into the paper).
1422"
CODE OF ETHICS,0.9432120674356699,"9. Code Of Ethics
1423"
CODE OF ETHICS,0.9436557231588287,"Question: Does the research conducted in the paper conform, in every respect, with the
1424"
CODE OF ETHICS,0.9440993788819876,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
1425"
CODE OF ETHICS,0.9445430346051464,"Answer: [Yes]
1426"
CODE OF ETHICS,0.9449866903283053,"Justification: The authors have reviewed the NeurIPS Code of Ethics and all the imported
1427"
CODE OF ETHICS,0.945430346051464,"code has been properly cited.
1428"
CODE OF ETHICS,0.9458740017746229,"Guidelines:
1429"
CODE OF ETHICS,0.9463176574977817,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
1430"
CODE OF ETHICS,0.9467613132209406,"• If the authors answer No, they should explain the special circumstances that require a
1431"
CODE OF ETHICS,0.9472049689440993,"deviation from the Code of Ethics.
1432"
CODE OF ETHICS,0.9476486246672582,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
1433"
CODE OF ETHICS,0.948092280390417,"eration due to laws or regulations in their jurisdiction).
1434"
BROADER IMPACTS,0.9485359361135759,"10. Broader Impacts
1435"
BROADER IMPACTS,0.9489795918367347,"Question: Does the paper discuss both potential positive societal impacts and negative
1436"
BROADER IMPACTS,0.9494232475598935,"societal impacts of the work performed?
1437"
BROADER IMPACTS,0.9498669032830523,"Answer: [Yes]
1438"
BROADER IMPACTS,0.9503105590062112,"Justification: See Appendix S.
1439"
BROADER IMPACTS,0.95075421472937,"Guidelines:
1440"
BROADER IMPACTS,0.9511978704525288,"• The answer NA means that there is no societal impact of the work performed.
1441"
BROADER IMPACTS,0.9516415261756876,"• If the authors answer NA or No, they should explain why their work has no societal
1442"
BROADER IMPACTS,0.9520851818988465,"impact or why the paper does not address societal impact.
1443"
BROADER IMPACTS,0.9525288376220054,"• Examples of negative societal impacts include potential malicious or unintended uses
1444"
BROADER IMPACTS,0.9529724933451642,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
1445"
BROADER IMPACTS,0.953416149068323,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
1446"
BROADER IMPACTS,0.9538598047914818,"groups), privacy considerations, and security considerations.
1447"
BROADER IMPACTS,0.9543034605146407,"• The conference expects that many papers will be foundational research and not tied
1448"
BROADER IMPACTS,0.9547471162377995,"to particular applications, let alone deployments. However, if there is a direct path to
1449"
BROADER IMPACTS,0.9551907719609583,"any negative applications, the authors should point it out. For example, it is legitimate
1450"
BROADER IMPACTS,0.9556344276841171,"to point out that an improvement in the quality of generative models could be used to
1451"
BROADER IMPACTS,0.956078083407276,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
1452"
BROADER IMPACTS,0.9565217391304348,"that a generic algorithm for optimizing neural networks could enable people to train
1453"
BROADER IMPACTS,0.9569653948535937,"models that generate Deepfakes faster.
1454"
BROADER IMPACTS,0.9574090505767524,"• The authors should consider possible harms that could arise when the technology is
1455"
BROADER IMPACTS,0.9578527062999113,"being used as intended and functioning correctly, harms that could arise when the
1456"
BROADER IMPACTS,0.9582963620230701,"technology is being used as intended but gives incorrect results, and harms following
1457"
BROADER IMPACTS,0.958740017746229,"from (intentional or unintentional) misuse of the technology.
1458"
BROADER IMPACTS,0.9591836734693877,"• If there are negative societal impacts, the authors could also discuss possible mitigation
1459"
BROADER IMPACTS,0.9596273291925466,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
1460"
BROADER IMPACTS,0.9600709849157054,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
1461"
BROADER IMPACTS,0.9605146406388643,"feedback over time, improving the efficiency and accessibility of ML).
1462"
SAFEGUARDS,0.9609582963620231,"11. Safeguards
1463"
SAFEGUARDS,0.9614019520851819,"Question: Does the paper describe safeguards that have been put in place for responsible
1464"
SAFEGUARDS,0.9618456078083407,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
1465"
SAFEGUARDS,0.9622892635314996,"image generators, or scraped datasets)?
1466"
SAFEGUARDS,0.9627329192546584,"Answer: [NA]
1467"
SAFEGUARDS,0.9631765749778172,"Justification: This paper does not pose such risks.
1468"
SAFEGUARDS,0.963620230700976,"Guidelines:
1469"
SAFEGUARDS,0.9640638864241349,"• The answer NA means that the paper poses no such risks.
1470"
SAFEGUARDS,0.9645075421472937,"• Released models that have a high risk for misuse or dual-use should be released with
1471"
SAFEGUARDS,0.9649511978704526,"necessary safeguards to allow for controlled use of the model, for example by requiring
1472"
SAFEGUARDS,0.9653948535936113,"that users adhere to usage guidelines or restrictions to access the model or implementing
1473"
SAFEGUARDS,0.9658385093167702,"safety filters.
1474"
SAFEGUARDS,0.966282165039929,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
1475"
SAFEGUARDS,0.9667258207630879,"should describe how they avoided releasing unsafe images.
1476"
SAFEGUARDS,0.9671694764862466,"• We recognize that providing effective safeguards is challenging, and many papers do
1477"
SAFEGUARDS,0.9676131322094055,"not require this, but we encourage authors to take this into account and make a best
1478"
SAFEGUARDS,0.9680567879325643,"faith effort.
1479"
LICENSES FOR EXISTING ASSETS,0.9685004436557232,"12. Licenses for existing assets
1480"
LICENSES FOR EXISTING ASSETS,0.968944099378882,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
1481"
LICENSES FOR EXISTING ASSETS,0.9693877551020408,"the paper, properly credited and are the license and terms of use explicitly mentioned and
1482"
LICENSES FOR EXISTING ASSETS,0.9698314108251996,"properly respected?
1483"
LICENSES FOR EXISTING ASSETS,0.9702750665483585,"Answer: [Yes]
1484"
LICENSES FOR EXISTING ASSETS,0.9707187222715173,"Justification: In Sections M.1, M.2, N, P, subsection “dataset”, we provide the citations of
1485"
LICENSES FOR EXISTING ASSETS,0.9711623779946761,"all datasets from other literature. We also cite all code adapted from other sources.
1486"
LICENSES FOR EXISTING ASSETS,0.9716060337178349,"Guidelines:
1487"
LICENSES FOR EXISTING ASSETS,0.9720496894409938,"• The answer NA means that the paper does not use existing assets.
1488"
LICENSES FOR EXISTING ASSETS,0.9724933451641526,"• The authors should cite the original paper that produced the code package or dataset.
1489"
LICENSES FOR EXISTING ASSETS,0.9729370008873115,"• The authors should state which version of the asset is used and, if possible, include a
1490"
LICENSES FOR EXISTING ASSETS,0.9733806566104702,"URL.
1491"
LICENSES FOR EXISTING ASSETS,0.9738243123336291,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
1492"
LICENSES FOR EXISTING ASSETS,0.974267968056788,"• For scraped data from a particular source (e.g., website), the copyright and terms of
1493"
LICENSES FOR EXISTING ASSETS,0.9747116237799468,"service of that source should be provided.
1494"
LICENSES FOR EXISTING ASSETS,0.9751552795031055,"• If assets are released, the license, copyright information, and terms of use in the
1495"
LICENSES FOR EXISTING ASSETS,0.9755989352262644,"package should be provided. For popular datasets, paperswithcode.com/datasets
1496"
LICENSES FOR EXISTING ASSETS,0.9760425909494232,"has curated licenses for some datasets. Their licensing guide can help determine the
1497"
LICENSES FOR EXISTING ASSETS,0.9764862466725821,"license of a dataset.
1498"
LICENSES FOR EXISTING ASSETS,0.976929902395741,"• For existing datasets that are re-packaged, both the original license and the license of
1499"
LICENSES FOR EXISTING ASSETS,0.9773735581188997,"the derived asset (if it has changed) should be provided.
1500"
LICENSES FOR EXISTING ASSETS,0.9778172138420586,"• If this information is not available online, the authors are encouraged to reach out to
1501"
LICENSES FOR EXISTING ASSETS,0.9782608695652174,"the asset’s creators.
1502"
NEW ASSETS,0.9787045252883763,"13. New Assets
1503"
NEW ASSETS,0.979148181011535,"Question: Are new assets introduced in the paper well documented and is the documentation
1504"
NEW ASSETS,0.9795918367346939,"provided alongside the assets?
1505"
NEW ASSETS,0.9800354924578527,"Answer: [NA]
1506"
NEW ASSETS,0.9804791481810116,"Justification: This paper does not release new assets.
1507"
NEW ASSETS,0.9809228039041704,"Guidelines:
1508"
NEW ASSETS,0.9813664596273292,"• The answer NA means that the paper does not release new assets.
1509"
NEW ASSETS,0.981810115350488,"• Researchers should communicate the details of the dataset/code/model as part of their
1510"
NEW ASSETS,0.9822537710736469,"submissions via structured templates. This includes details about training, license,
1511"
NEW ASSETS,0.9826974267968057,"limitations, etc.
1512"
NEW ASSETS,0.9831410825199645,"• The paper should discuss whether and how consent was obtained from people whose
1513"
NEW ASSETS,0.9835847382431233,"asset is used.
1514"
NEW ASSETS,0.9840283939662822,"• At submission time, remember to anonymize your assets (if applicable). You can either
1515"
NEW ASSETS,0.984472049689441,"create an anonymized URL or include an anonymized zip file.
1516"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9849157054125999,"14. Crowdsourcing and Research with Human Subjects
1517"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9853593611357586,"Question: For crowdsourcing experiments and research with human subjects, does the paper
1518"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9858030168589175,"include the full text of instructions given to participants and screenshots, if applicable, as
1519"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9862466725820763,"well as details about compensation (if any)?
1520"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9866903283052352,"Answer: [NA]
1521"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9871339840283939,"Justification: This paper does not involve crowdsourcing nor research with human subjects.
1522"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9875776397515528,"Guidelines:
1523"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9880212954747116,"• The answer NA means that the paper does not involve crowdsourcing nor research with
1524"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9884649511978705,"human subjects.
1525"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9889086069210293,"• Including this information in the supplemental material is fine, but if the main contribu-
1526"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9893522626441881,"tion of the paper involves human subjects, then as much detail as possible should be
1527"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9897959183673469,"included in the main paper.
1528"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9902395740905058,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
1529"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9906832298136646,"or other labor should be paid at least the minimum wage in the country of the data
1530"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9911268855368234,"collector.
1531"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9915705412599822,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
1532"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9920141969831411,"Subjects
1533"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9924578527062999,"Question: Does the paper describe potential risks incurred by study participants, whether
1534"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9929015084294588,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
1535"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9933451641526175,"approvals (or an equivalent approval/review based on the requirements of your country or
1536"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9937888198757764,"institution) were obtained?
1537"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9942324755989352,"Answer: [NA]
1538"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9946761313220941,"Justification: This paper does not involve crowdsourcing nor research with human subjects.
1539"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9951197870452528,"Guidelines:
1540"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9955634427684117,"• The answer NA means that the paper does not involve crowdsourcing nor research with
1541"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9960070984915705,"human subjects.
1542"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9964507542147294,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
1543"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9968944099378882,"may be required for any human subjects research. If you obtained IRB approval, you
1544"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.997338065661047,"should clearly state this in the paper.
1545"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9977817213842058,"• We recognize that the procedures for this may vary significantly between institutions
1546"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9982253771073647,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
1547"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9986690328305236,"guidelines for their institution.
1548"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9991126885536823,"• For initial submissions, do not include any information that would break anonymity (if
1549"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9995563442768411,"applicable), such as the institution conducting the review.
1550"
