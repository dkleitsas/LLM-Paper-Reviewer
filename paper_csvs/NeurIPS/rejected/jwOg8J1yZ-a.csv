Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0017452006980802793,"We initiate the study of tolerant adversarial PAC learning with respect to metric
1"
ABSTRACT,0.0034904013961605585,"perturbation sets. In adversarial PAC learning, an adversary is allowed to replace a
2"
ABSTRACT,0.005235602094240838,"test point x with an arbitrary point in a closed ball of radius r centered at x. In the
3"
ABSTRACT,0.006980802792321117,"tolerant version, the error of the learner is compared with the best achievable error
4"
ABSTRACT,0.008726003490401396,"with respect to a slightly larger perturbation radius (1 + γ)r. This simple tweak
5"
ABSTRACT,0.010471204188481676,"helps us bridge the gap between theory and practice and obtain the ﬁrst PAC-type
6"
ABSTRACT,0.012216404886561954,"guarantees for algorithmic techniques that are popular in practice. Furthermore, our
7"
ABSTRACT,0.013961605584642234,"sample complexity bounds improve exponentially over best known (non-tolerant)
8"
ABSTRACT,0.015706806282722512,"bounds in terms of the VC dimension of the hypothesis class. In particular, for
9"
ABSTRACT,0.017452006980802792,"perturbation sets with doubling dimension d, we show that a variant of the “perturb-
10"
ABSTRACT,0.019197207678883072,"and-smooth” algorithm PAC learns any hypothesis class H with VC dimension v in
11"
ABSTRACT,0.020942408376963352,"the γ-tolerant adversarial setting with O

v(1+1/γ)O(d)"
ABSTRACT,0.02268760907504363,"ε

samples. This guarantee
12"
ABSTRACT,0.02443280977312391,"holds in the tolerant robust realizable setting. We extend this to the agnostic case
13"
ABSTRACT,0.02617801047120419,"by designing a novel sample compression scheme based on the perturb-and-smooth
14"
ABSTRACT,0.027923211169284468,"approach. This compression-based algorithm has a linear dependence on the
15"
ABSTRACT,0.029668411867364748,"doubling dimension as well as the VC-dimension.
16"
INTRODUCTION,0.031413612565445025,"1
Introduction
17"
INTRODUCTION,0.03315881326352531,"Several empirical studies (Szegedy et al., 2014; Goodfellow et al., 2018) have demonstrated that
18"
INTRODUCTION,0.034904013961605584,"models trained to have a low accuracy on a data set often have the undesirable property that a small
19"
INTRODUCTION,0.03664921465968586,"perturbation to an input instance can change the label outputted by the model. For most domains this
20"
INTRODUCTION,0.038394415357766144,"does not align with human intuition and thus indicates that the learned models are not representing
21"
INTRODUCTION,0.04013961605584642,"the ground truth despite obtaining good accuracy on test sets.
22"
INTRODUCTION,0.041884816753926704,"The theory of PAC-learning characterizes the conditions under which learning is possible. For binary
23"
INTRODUCTION,0.04363001745200698,"classiﬁcation, the following conditions are sufﬁcient: a) unseen data should arrive from the same
24"
INTRODUCTION,0.04537521815008726,"distribution as training data, and b) the class of models should have a low capacity (as measured, for
25"
INTRODUCTION,0.04712041884816754,"example, by its VC dimension). If these conditions are met, an Empirical Risk Minimizer (ERM) that
26"
INTRODUCTION,0.04886561954624782,"simply optimizes model parameters to maximize accuracy on the training set learns successfully.
27"
INTRODUCTION,0.0506108202443281,"Recent work has studied test-time adversarial perturbations under the PAC-learning framework. If
28"
INTRODUCTION,0.05235602094240838,"an adversary is allowed to perturb data during test time then the conditions above do not hold, and
29"
INTRODUCTION,0.05410122164048865,"we cannot hope for the model to learn to be robust just by running ERM. Thus, the goal here is to
30"
INTRODUCTION,0.055846422338568937,"bias the learning process towards ﬁnding models where label-changing perturbations are rare. This is
31"
INTRODUCTION,0.05759162303664921,"achieved by deﬁning a loss function that combines both classiﬁcation error and the probability of
32"
INTRODUCTION,0.059336823734729496,"seeing label-changing perturbations, and learning models that minimize this loss on unseen data. It
33"
INTRODUCTION,0.06108202443280977,"has been shown that even though (robust) ERM can fail in this setting, PAC learning is still possible
34"
INTRODUCTION,0.06282722513089005,"as long as we know during training the kinds of perturbations we want to guard against at test
35"
INTRODUCTION,0.06457242582897033,"time (Montasser et al., 2019). This result holds for all perturbation sets. However, the learning
36"
INTRODUCTION,0.06631762652705062,"algorithm is signiﬁcantly more complex than robust ERM and requires a large number of samples
37"
INTRODUCTION,0.06806282722513089,"(with the best known sample complexity bounds potentially being exponential in the VC-dimension).
38"
INTRODUCTION,0.06980802792321117,"We study a tolerant version of the adversarially robust learning framework and restrict the perturba-
39"
INTRODUCTION,0.07155322862129145,"tions to balls in a general metric space with ﬁnite doubling dimension. We show this slight shift in
40"
INTRODUCTION,0.07329842931937172,"the learning objective yields signiﬁcantly improved sample complexity bounds through a simpler
41"
INTRODUCTION,0.07504363001745201,"learning paradigm than what was previously known. In fact, we show that a version of the common
42"
INTRODUCTION,0.07678883071553229,"“perturb-and-smooth” paradigm successfully PAC-learns any class of bounded VC dimension in this
43"
INTRODUCTION,0.07853403141361257,"setting.
44"
INTRODUCTION,0.08027923211169284,"Learning in general metric spaces. What kinds of perturbations should a learning algorithm guard
45"
INTRODUCTION,0.08202443280977312,"against? Any transformation of the input that we believe should not change its label could be a viable
46"
INTRODUCTION,0.08376963350785341,"perturbation for the adversary to use. The early works in this area considered perturbations contained
47"
INTRODUCTION,0.08551483420593368,"within a small ℓp-ball of the input. More recent work has considered other transformations such as
48"
INTRODUCTION,0.08726003490401396,"a small rotation, or translation of an input image (Engstrom et al., 2019; Fawzi & Frossard, 2015;
49"
INTRODUCTION,0.08900523560209424,"Kanbak et al., 2018; Xiao et al., 2018), or even adding small amounts of fog or snow (Kang et al.,
50"
INTRODUCTION,0.09075043630017451,"2019). It has also been argued that small perturbations in some feature space should be allowed as
51"
INTRODUCTION,0.0924956369982548,"opposed to the input space (Inkawhich et al., 2019; Sabour et al., 2016; Xu et al., 2020; Song et al.,
52"
INTRODUCTION,0.09424083769633508,"2018; Hosseini & Poovendran, 2018). This motivates the study of more general perturbations.
53"
INTRODUCTION,0.09598603839441536,"We consider a setting where the input comes from a domain that is equipped with a distance metric
54"
INTRODUCTION,0.09773123909249563,"and allows perturbations to be within a small metric ball around the input. Earlier work on general
55"
INTRODUCTION,0.09947643979057591,"perturbation sets (for example, (Montasser et al., 2019)) considered arbitrary perturbations. In this
56"
INTRODUCTION,0.1012216404886562,"setting one does not quantify the magnitude of a perturbation and thus cannot talk about small versus
57"
INTRODUCTION,0.10296684118673648,"large perturbations. Modeling perturbations using a metric space enables us to do that while also
58"
INTRODUCTION,0.10471204188481675,"keeping the setup general enough to be able to encode a large variety of perturbation sets by choosing
59"
INTRODUCTION,0.10645724258289703,"appropriate distance functions.
60"
INTRODUCTION,0.1082024432809773,"Learning with tolerance. In practice, we often believe that small perturbations of the input should
61"
INTRODUCTION,0.1099476439790576,"not change its label but we do not know precisely what small means. However, in the PAC-learning
62"
INTRODUCTION,0.11169284467713787,"framework for adversarially robust classiﬁcation, we are required to deﬁne a precise perturbation set
63"
INTRODUCTION,0.11343804537521815,"and learn a model that has error arbitrarily close to the smallest error that can be achieved with respect
64"
INTRODUCTION,0.11518324607329843,"to that perturbation set. In other words, we aim to be arbitrarily close to a target that was picked
65"
INTRODUCTION,0.1169284467713787,"somewhat arbitrarily to begin with. Due to the uncertainty about the correct perturbation size, it is
66"
INTRODUCTION,0.11867364746945899,"more meaningful to allow for a wider range of error values. To achieve this, we introduce the concept
67"
INTRODUCTION,0.12041884816753927,"of tolerance. In the tolerant setting, in addition to specifying a perturbation size r, we introduce a
68"
INTRODUCTION,0.12216404886561955,"tolerance parameter γ that encodes our uncertainty about the size of allowed perturbations. Then, for
69"
INTRODUCTION,0.12390924956369982,"any given ϵ > 0, we aim to learn a model whose error with respect to perturbations of size r is at
70"
INTRODUCTION,0.1256544502617801,"most ϵ more than the smallest error achievable with respect to perturbations of size r(1 + γ).
71"
OUR RESULTS,0.1273996509598604,"2
Our results
72"
OUR RESULTS,0.12914485165794065,"In this paper we formalize and initiate the study of the problem of adversarially robust learning in
73"
OUR RESULTS,0.13089005235602094,"the tolerant setting for general metric spaces and provide two algorithms for the task. Both of our
74"
OUR RESULTS,0.13263525305410123,"algorithms rely on: 1) modifying the training data by randomly sampling points from the perturbation
75"
OUR RESULTS,0.1343804537521815,"sets around each data point, and 2) smoothing the output of the model by taking a majority over the
76"
OUR RESULTS,0.13612565445026178,"labels returned by the model for nearby points.
77"
OUR RESULTS,0.13787085514834205,"Our ﬁrst algorithm starts by modifying the training set by randomly perturbing each training point
78"
OUR RESULTS,0.13961605584642234,"using a certain distribution (see Section 5 for details). It then trains a (non-robust) PAC learner (such
79"
OUR RESULTS,0.14136125654450263,"as ERM) on the perturbed training set to ﬁnd a hypothesis h. Finally, it outputs a smooth version
80"
OUR RESULTS,0.1431064572425829,"of h. The smoothing step replaces h(x) at each point x with the a majority label outputted by h on
81"
OUR RESULTS,0.14485165794066318,"the points around x. We show that for metric spaces of a ﬁxed doubling dimension, this algorithm
82"
OUR RESULTS,0.14659685863874344,"successfully learns in the (robustly realizable) tolerant setting.
83"
OUR RESULTS,0.14834205933682373,"Theorem 1 (Informal version of Theorem 10). Let (X, dist) be a metric space with doubling
84"
OUR RESULTS,0.15008726003490402,"dimension d and H a hypothesis class. Assuming robust realizability, H can be learned tolerantly in
85"
OUR RESULTS,0.1518324607329843,"the adversarially robust setting using O

(1+1/γ)O(d)VC(H)"
OUR RESULTS,0.15357766143106458,"ϵ

samples, where γ encodes the amount
86"
OUR RESULTS,0.15532286212914484,"of allowed tolerance, and ϵ is the desired accuracy.
87"
OUR RESULTS,0.15706806282722513,"An interesting feature of the above result is the linear dependence of the sample complexity with
88"
OUR RESULTS,0.15881326352530542,"respect to VC(H). This is in contrast to the best known upper bound for non-tolerant adversarial
89"
OUR RESULTS,0.16055846422338568,"setting (Montasser et al., 2019) which depends on the dual VC dimension of the hypothesis class
90"
OUR RESULTS,0.16230366492146597,"and in general is exponential in VC(H). Moreover, this is the ﬁrst PAC type guarantee for the
91"
OUR RESULTS,0.16404886561954624,"general perturb-and-smooth paradigm, indicating that the tolerant adversarial learning is the “right”
92"
OUR RESULTS,0.16579406631762653,"learning model for studying these approaches. While the above method enjoys simplicity and can
93"
OUR RESULTS,0.16753926701570682,"be computationally efﬁcient, one downside is that its sample complexity grows exponentially with
94"
OUR RESULTS,0.16928446771378708,"the doubling dimension. For instance, such algorithm cannot be used on high-dimensional data in
95"
OUR RESULTS,0.17102966841186737,"the Euclidean space. Another limitation is that the guarantee holds only in the (robustly) realizable
96"
OUR RESULTS,0.17277486910994763,"setting. We propose another algorithm that improves the dependence on doubling dimension, and
97"
OUR RESULTS,0.17452006980802792,"works in the general agnostic setting.
98"
OUR RESULTS,0.1762652705061082,"Theorem 2 (Informal version of Corollary 16). Let (X, dist) be a metric space with doubling
99"
OUR RESULTS,0.17801047120418848,"dimension d and H a hypothesis class. Then H can be learned tolerantly in the adversarially robust
100"
OUR RESULTS,0.17975567190226877,"setting using eO

O(d)VC(H) log(1+1/γ)"
OUR RESULTS,0.18150087260034903,"ϵ2

samples, where eO hides logarithmic factors, γ encodes the
101"
OUR RESULTS,0.18324607329842932,"amount of allowed tolerance, and ϵ is the desired accuracy.
102"
OUR RESULTS,0.1849912739965096,"This algorithm exploits the connection between sample compression and adversarially robust learn-
103"
OUR RESULTS,0.18673647469458987,"ing Montasser et al. (2019). However, unlike Montasser et al. (2019), our new compression scheme
104"
OUR RESULTS,0.18848167539267016,"sidesteps the dependence on the dual VC dimension. As a result, we get an exponential improvement
105"
OUR RESULTS,0.19022687609075042,"over the best known (nontolerant) sample complexity in terms of dependence on VC dimension.
106"
RELATED WORK,0.19197207678883071,"3
Related work
107"
RELATED WORK,0.193717277486911,"PAC-learning for adversarially robust classiﬁcation has been studied extensively in recent years (Cul-
108"
RELATED WORK,0.19546247818499127,"lina et al., 2018; Awasthi et al., 2019; Montasser et al., 2019; Feige et al., 2015; Attias et al., 2019;
109"
RELATED WORK,0.19720767888307156,"Montasser et al., 2020a; Ashtiani et al., 2020). These works provide learning algorithms that guaran-
110"
RELATED WORK,0.19895287958115182,"tee low generalization error in the presence of adversarial perturbations in various settings. The most
111"
RELATED WORK,0.2006980802792321,"general result is due to (Montasser et al., 2019) which is proved for general hypothesis classes and
112"
RELATED WORK,0.2024432809773124,"perturbation sets. All of the above results assume that the learner knows the kinds of perturbations
113"
RELATED WORK,0.20418848167539266,"allowed for the adversary. Some more recent papers have considered scenarios where the learner
114"
RELATED WORK,0.20593368237347295,"does not even need to know that. Goldwasser et al. (2020) allow the adversary to perturb test data in
115"
RELATED WORK,0.20767888307155322,"unrestricted ways and are still able to provide learning guarantees. The catch is that it only works
116"
RELATED WORK,0.2094240837696335,"in the transductive setting and only if the learner is allowed to abstain from making a prediction on
117"
RELATED WORK,0.2111692844677138,"some test points. Montasser et al. (2021a) consider the case where the learner needs to infer the set of
118"
RELATED WORK,0.21291448516579406,"allowed perturbations by observing the actions of the adversary.
119"
RELATED WORK,0.21465968586387435,"Tolerance was introduced by Ashtiani et al. (2020) but in the context of certiﬁcation. They provide
120"
RELATED WORK,0.2164048865619546,"examples where certiﬁcation is not possible unless we allow some tolerance. Montasser et al. (2021b)
121"
RELATED WORK,0.2181500872600349,"study transductive adversarial learning and provide a “tolerant” guarantee. Note that unlike our work,
122"
RELATED WORK,0.2198952879581152,"the main focus of this paper is on the transductive setting. Moreover, they do not speciﬁcally study
123"
RELATED WORK,0.22164048865619546,"tolerance with respect to metric perturbation sets. Without a metric, it is not meaningful to expand
124"
RELATED WORK,0.22338568935427575,"perturbation sets by a factor (1 + γ) (as we do in the our deﬁnition of tolerance). Instead, they expand
125"
RELATED WORK,0.225130890052356,"their perturbation sets by applying two perturbations in succession, which is akin to setting γ = 1. In
126"
RELATED WORK,0.2268760907504363,"contrast, our results hold in the more common inductive setting, and capture a more realistic setting
127"
RELATED WORK,0.2286212914485166,"where γ is any (small) real number larger than zero.
128"
RELATED WORK,0.23036649214659685,"Like many recent adversarially robust learning algorithms (Feige et al., 2015; Attias et al., 2019),
129"
RELATED WORK,0.23211169284467714,"our ﬁrst algorithm relies on calls to a non-robust PAC-learner. Montasser et al. (2020b) formalize the
130"
RELATED WORK,0.2338568935427574,"question of reducing adversarially robust learning to non-robust learning and study ﬁnite perturbation
131"
RELATED WORK,0.2356020942408377,"sets of size k. They show a reduction that makes O(log2 k) calls to the non-robust learner and also
132"
RELATED WORK,0.23734729493891799,"prove a lower bound of Ω(log k). It will be interesting to see if our algorithms can be used to obtain
133"
RELATED WORK,0.23909249563699825,"better bounds for the tolerant setting. Our ﬁrst algorithm makes one call to the non-robust PAC-learner
134"
RELATED WORK,0.24083769633507854,"at training time, but needs to perform potentially expensive smoothing for making actual predictions
135"
RELATED WORK,0.2425828970331588,"(see Theorem 10).
136"
RELATED WORK,0.2443280977312391,"The techniques of randomly perturbing the training data and smoothing the output classiﬁer has been
137"
RELATED WORK,0.24607329842931938,"extensively used in practice and has shown good empirical success. Augmenting the training data with
138"
RELATED WORK,0.24781849912739964,"some randomly perturbed samples was used for handwriting recognition as early as in (Yaeger et al.,
139"
RELATED WORK,0.24956369982547993,"1996). More recently, “stability training” was introduced in (Zheng et al., 2016) for state of the art
140"
RELATED WORK,0.2513089005235602,"image classiﬁers where training data is augmented with Gaussian perturbations. Empirical evidence
141"
RELATED WORK,0.2530541012216405,"was provided that the technique improved the accuracy against naturally occurring perturbations.
142"
RELATED WORK,0.2547993019197208,"Augmentations with non-Gaussian perturbations of a large variety were considered in (Hendrycks
143"
RELATED WORK,0.25654450261780104,"et al., 2019).
144"
RELATED WORK,0.2582897033158813,"Smoothing the output classiﬁer using random samples around the test point is a popular technique
145"
RELATED WORK,0.2600349040139616,"for producing certiﬁably robust classiﬁers. A certiﬁcation, in this context, is a guarantee that given a
146"
RELATED WORK,0.2617801047120419,"test point x, all points within a certain radius of x receive the same label as x. Several papers have
147"
RELATED WORK,0.26352530541012215,"provided theoretical analyses to show that smoothing produces certiﬁably robust classiﬁers (Cao &
148"
RELATED WORK,0.26527050610820246,"Gong, 2017; Cohen et al., 2019; Lecuyer et al., 2019; Li et al., 2019; Liu et al., 2018; Salman et al.,
149"
RELATED WORK,0.2670157068062827,"2019; Levine & Feizi, 2020).
150"
RELATED WORK,0.268760907504363,"However, to the best of our knowledge, a PAC-like guarantee has not been shown for any algorithm
151"
RELATED WORK,0.2705061082024433,"that employs training data perturbations or output classiﬁer smoothing, and our paper provides the
152"
RELATED WORK,0.27225130890052357,"ﬁrst such analysis.
153"
NOTATIONS AND SETUP,0.27399650959860383,"4
Notations and setup
154"
NOTATIONS AND SETUP,0.2757417102966841,"We denote by X the input domain and by Y = {0, 1} the binary label space. We assume that
155"
NOTATIONS AND SETUP,0.2774869109947644,"X is equipped with a metric dist. A hypothesis h : X →Y is a function that assigns a label
156"
NOTATIONS AND SETUP,0.2792321116928447,"to each point in the domain. A hypothesis class H is a set of such hypotheses. For a sample
157"
NOTATIONS AND SETUP,0.28097731239092494,"S = ((x1, y1), . . . , (xn, yn)) ∈(X × Y )n, we use the notation SX = {x1, x2, . . . , xn} to denote
158"
NOTATIONS AND SETUP,0.28272251308900526,"the collection of domain points xi occurring in S. The binary (also called 0-1) loss of h on data point
159"
NOTATIONS AND SETUP,0.2844677137870855,"(x, y) ∈X × Y is deﬁned by
160"
NOTATIONS AND SETUP,0.2862129144851658,"ℓ0/1(h, x, y) = 1 [h(x) ̸= y] ,
where 1 [.] is the indicator function. Let P by a probability distribution over X × Y . Then the
161"
NOTATIONS AND SETUP,0.2879581151832461,"expected binary loss of h with respect to P is deﬁned by
162"
NOTATIONS AND SETUP,0.28970331588132636,"L0/1
P (h) = E(x,y)∼P [ℓ0/1(h, x, y)]"
NOTATIONS AND SETUP,0.2914485165794066,"Similarly, the empirical binary loss of h on sample S = ((x1, y1), . . . , (xn, yn)) ∈(X × Y )n is
163"
NOTATIONS AND SETUP,0.2931937172774869,"deﬁned as L0/1
S (h) = 1"
NOTATIONS AND SETUP,0.2949389179755672,"n
Pn
i=1 ℓ0/1(h, xi, yi). We also deﬁne the approximation error of H with
164"
NOTATIONS AND SETUP,0.29668411867364747,"respect to P as L0/1
P (H) = infh∈H L0/1
P (h).
165"
NOTATIONS AND SETUP,0.29842931937172773,"A learner A is a function that takes in a ﬁnite sequence of labeled instances S
=
166"
NOTATIONS AND SETUP,0.30017452006980805,"((x1, y1), . . . , (xn, yn)) and outputs a hypothesis h = A(S). The following deﬁnition abstracts
167"
NOTATIONS AND SETUP,0.3019197207678883,"the notion of PAC learning Vapnik & Chervonenkis (1971); Valiant (1984).
168"
NOTATIONS AND SETUP,0.3036649214659686,"Deﬁnition 3 (PAC Learner). Let P be a set of distributions over X × Y and H a hypothesis class.
169"
NOTATIONS AND SETUP,0.3054101221640489,"We say A PAC learns (H, P) with mA : (0, 1)2 →N samples if the following holds: for every
170"
NOTATIONS AND SETUP,0.30715532286212915,"distribution P ∈P over X × Y , and every ϵ, δ ∈(0, 1), if S is an i.i.d. sample of size at least
171"
NOTATIONS AND SETUP,0.3089005235602094,"mA(ϵ, δ) from P, then with probability at least 1 −δ (over the randomness of S) we have
172"
NOTATIONS AND SETUP,0.3106457242582897,LP (A(S)) ≤LP (H) + ϵ.
NOTATIONS AND SETUP,0.31239092495637,"A is called an agnostic learner if P is the set of all distributions on X × Y , and a realizable learner if
173"
NOTATIONS AND SETUP,0.31413612565445026,"P = {P : LP (H) = 0}.
174"
NOTATIONS AND SETUP,0.3158813263525305,"The smallest function m : (0, 1)2 →N for which there exists a learner A that satisﬁes the above
175"
NOTATIONS AND SETUP,0.31762652705061084,"deﬁnition with mA = m is referred to as the (realizable or agnostic) sample complexity of learning
176"
NOTATIONS AND SETUP,0.3193717277486911,"H.
177"
NOTATIONS AND SETUP,0.32111692844677137,"The existence of sample-efﬁcient PAC learners for VC classes is a standard result Vapnik & Chervo-
178"
NOTATIONS AND SETUP,0.3228621291448517,"nenkis (1971). We state the results formally in Appendix A.
179"
TOLERANT ADVERSARIAL PAC LEARNING,0.32460732984293195,"4.1
Tolerant adversarial PAC learning
180"
TOLERANT ADVERSARIAL PAC LEARNING,0.3263525305410122,"Let U : X →2X be a function that maps each point in the domain to the set of its “admissible”
181"
TOLERANT ADVERSARIAL PAC LEARNING,0.32809773123909247,"perturbations. We call this function the perturbation type. The adversarial loss of h with respect to U
182"
TOLERANT ADVERSARIAL PAC LEARNING,0.3298429319371728,"on (x, y) ∈X × Y is deﬁned by
183"
TOLERANT ADVERSARIAL PAC LEARNING,0.33158813263525305,"ℓU(h, x, y) = max
z∈U(x){ℓ0/1(h, z, y)}"
TOLERANT ADVERSARIAL PAC LEARNING,0.3333333333333333,"The expected adversarial loss with respect to P is deﬁned by LU
P (h) = E(x,y)∼P ℓU(h, x, y). The
184"
TOLERANT ADVERSARIAL PAC LEARNING,0.33507853403141363,"empirical adversarial loss of h on sample S = ((x1, y1), . . . , (xn, yn)) ∈(X × Y )n is deﬁned by
185"
TOLERANT ADVERSARIAL PAC LEARNING,0.3368237347294939,"LU
S(h) = 1"
TOLERANT ADVERSARIAL PAC LEARNING,0.33856893542757416,"n
Pn
i=1 ℓU(h, xi, yi). Finally, the adversarial approximation error of H with respect to U
186"
TOLERANT ADVERSARIAL PAC LEARNING,0.3403141361256545,"and P is deﬁned by LU
P (H) = infh∈H LU
P (h).
187"
TOLERANT ADVERSARIAL PAC LEARNING,0.34205933682373474,"The following deﬁnition generalizes the setting of PAC adversarial learning to what we call the
188"
TOLERANT ADVERSARIAL PAC LEARNING,0.343804537521815,"tolerant setting, where we consider two perturbation types U and V. We say U is contained in V and
189"
TOLERANT ADVERSARIAL PAC LEARNING,0.34554973821989526,"and write it as U ≺V if U(x) ⊂V(x) for all x ∈X.
190"
TOLERANT ADVERSARIAL PAC LEARNING,0.3472949389179756,"Deﬁnition 4 (Tolerant Adversarial PAC Learner). Let P be a set of distributions over X × Y , H a
191"
TOLERANT ADVERSARIAL PAC LEARNING,0.34904013961605584,"hypothesis class, and U ≺V two perturbation types. We say A tolerantly PAC learns (H, P, U, V)
192"
TOLERANT ADVERSARIAL PAC LEARNING,0.3507853403141361,"with mA : (0, 1)2 →N samples if the following holds: for every distribution P ∈P and every
193"
TOLERANT ADVERSARIAL PAC LEARNING,0.3525305410122164,"ϵ, δ ∈(0, 1), if S is an i.i.d. sample of size at least mA(ϵ, δ) from P, then with probability at least
194"
TOLERANT ADVERSARIAL PAC LEARNING,0.3542757417102967,"1 −δ (over the randomness of S) we have
195"
TOLERANT ADVERSARIAL PAC LEARNING,0.35602094240837695,"LU
P (A(S)) ≤LV
P (H) + ϵ."
TOLERANT ADVERSARIAL PAC LEARNING,0.35776614310645727,"We say A is a tolerant PAC learner in the agnostic setting if P is the set of all distributions over
196"
TOLERANT ADVERSARIAL PAC LEARNING,0.35951134380453753,"X × Y , and in the tolerantly realizable setting if P = {P : LV
P (H) = 0}.
197"
TOLERANT ADVERSARIAL PAC LEARNING,0.3612565445026178,"In the above context, we refer to U as the actual perturbation type and to V as the reference
198"
TOLERANT ADVERSARIAL PAC LEARNING,0.36300174520069806,"perturbation type. The case where U(x) = V(x) for all x ∈X corresponds to the usual adversarial
199"
TOLERANT ADVERSARIAL PAC LEARNING,0.3647469458987784,"learning scenario (with no tolerance).
200"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.36649214659685864,"4.2
Tolerant adversarial PAC learning in metric spaces
201"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.3682373472949389,"If X is equipped with a metric dist(., .), then U(x) can be naturally deﬁned by a ball of radius r
202"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.3699825479930192,"around x, i.e., U(x) = Br(x) = {z ∈X | dist(x, z) ≤r}. To simplify the notation, we sometimes
203"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.3717277486910995,"use ℓr(h, x, y) instead of ℓBr(h, x, y) to denote the adversarial loss with respect to Br.
204"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.37347294938917974,"In the tolerant setting, we consider the perturbation sets U(x) = Br(x) and V(x) = B(1+γ)r(x),
205"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.37521815008726006,"where γ > 0 is called the tolerance parameter. Note that U ≺V. We now deﬁne PAC learning with
206"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.3769633507853403,"respect to the metric space.
207"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.3787085514834206,"Deﬁnition 5 (Tolerant Adversarial Learning in metric spaces). Let (X, dist) be a metric space, H
208"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.38045375218150085,"a hypothesis class, and P a set of distributions of X × Y . We say (H, P, dist) is tolerantly PAC
209"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.38219895287958117,"learnable with m : (0, 1)3 →N samples when for every r, γ > 0 there exist a PAC learner Ar,γ for
210"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.38394415357766143,"(H, P, Br, Br(1+γ)) that uses m(ϵ, δ, γ) samples.
211"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.3856893542757417,"Remark 6. In this deﬁnition the learner receives γ and r as input but its sample complexity does
212"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.387434554973822,"not depend on r (but can depend on γ). Also, as in Deﬁnition 4, the tolerantly realizable setting
213"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.38917975567190227,"corresponds to P = {P : Lr(1+γ)
P
(H) = 0} while in the agnostic setting P is the set of all
214"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.39092495636998253,"distributions over X × Y .
215"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.39267015706806285,"The doubling dimension and the doubling measure of the metric space will play important roles in
216"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.3944153577661431,"our analysis. We refer the reader to Appendix B for their deﬁnitions.
217"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.3961605584642234,"We will use the following lemma in our analysis, whose proof can be found in Appendix B:
218"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.39790575916230364,"Lemma 7. For any family M of complete, doubling metric spaces, there exist constants c1, c2 > 0
219"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.39965095986038396,"such that for any metric space (X, dist) ∈M with doubling dimension d, there exists a measure µ
220"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.4013961605584642,"such that if a ball Br of radius r > 0 is completely contained inside a ball Bαr of radius αr (with
221"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.4031413612565445,"potentially a different center) for any α > 1, then 0 < µ(Bαr) ≤(c1α)c2dµ(Br). Furthermore, if
222"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.4048865619546248,"we have a constant α0 > 1 such that we know that α ≥α0 then the bound can be simpliﬁed to
223"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.40663176265270506,"0 < µ(Bαr) ≤αζdµ(Br), where ζ depends on M and α0.
224"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.4083769633507853,"Later, we will set α = 1 + 1/γ where γ is the tolerance parameter. Since we are mostly interested in
225"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.41012216404886565,"small values of γ, suppose we decide on some loose upper bound Γ ≫γ. This corresponds to saying
226"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.4118673647469459,"that there exists some α0 > 1 such that α ≥α0.
227"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.41361256544502617,"It is worth noting that in the special case of Euclidean metric spaces, we can set both c1 and c2 to be
228"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.41535776614310643,"1. In the rest of the paper, we will assume we have a loose upper bound Γ ≫γ and use the simpler
229"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.41710296684118675,"bound from Lemma 24 extensively.
230"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.418848167539267,"Given a metric space (X, d) and a measure µ deﬁned over it, for any subset Z ⊆X for which µ(Z)
231"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.4205933682373473,"is non-zero and ﬁnite, µ induces a probability measure P µ
Z over Z as follows. For any set Z′ ⊆Z in
232"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.4223385689354276,"the σ-algebra over Z, we deﬁne P µ
Z(Z′) = µ(Z′)/µ(Z). With a slight abuse of notation, we write
233"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.42408376963350786,"z ∼Z to mean z ∼P µ
Z whenever we know µ from the context.
234"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.4258289703315881,"Our learners rely on being able to sample from P µ
Z. Thus we deﬁne the following oracle, which can
235"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.42757417102966844,"be implemented efﬁciently for ℓp spaces.
236"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.4293193717277487,"Deﬁnition 8 (Sampling Oracle). Given a metric space (X, dist) equipped with a doubling measure
237"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.43106457242582896,"µ, a sampling oracle is an algorithm that when queried with a Z ⊆X such that µ(Z) is ﬁnite, returns
238"
TOLERANT ADVERSARIAL PAC LEARNING IN METRIC SPACES,0.4328097731239092,"a sample drawn from P µ
Z. We will use the notation z ∼Z for queries to this oracle.
239"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.43455497382198954,"5
The perturb-and-smooth approach for tolerant adversarial learning
240"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.4363001745200698,"In this section we focus on tolerant adversarial PAC learning in metric spaces (Deﬁnition 5), and
241"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.43804537521815007,"show that VC classes are tolerantly PAC learnable in the tolerantly realizable setting. Interestingly,
242"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.4397905759162304,"we prove this result using an approach that resembles the “perturb-and-smooth” paradigm which is
243"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.44153577661431065,"used in practice (for example, (Cohen et al., 2019). The overall idea is to “perturb” each training
244"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.4432809773123909,"point x, train a classiﬁer on the “perturbed” points, and “smooth out” the ﬁnal hypothesis using a
245"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.44502617801047123,"certain majority rule.
246"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.4467713787085515,"For this, we employ three perturbation types: U and V play the role of the actual and the reference
247"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.44851657940663175,"perturbation type respectively. Additionally, we consider a perturbation type W : X →2X, which is
248"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.450261780104712,"used for smoothing. We assume U ≺V and W ≺V. For this section, we will use metric balls for the
249"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.45200698080279234,"three types. Speciﬁcally, if U consists of balls of radius r for some r > 0, then W will consists of
250"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.4537521815008726,"balls of radius γr and V will consist of balls of radius (1 + γ)r.
251"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.45549738219895286,"Deﬁnition 9 (Smoothed classiﬁer). For a hypothesis h : X →{0, 1}, we let ¯hW denote the classiﬁer
252"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.4572425828970332,"resulting from replacing the label h(x) with the average label over W(x), that is
253"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.45898778359511344,"¯hW(x) = 1

Ex′∼W(x)h(x′) ≥1/2
"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.4607329842931937,"For metric perturbation types, where W is a ball of some radius r, we also use the notation ¯hr and
254"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.462478184991274,"when the type W is clear from context, we may omit the subscript altogether and simply write ¯h for
255"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.4642233856893543,"the smoothed classiﬁer.
256"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.46596858638743455,"The tolerant perturb-and-smooth algorithm
We propose the following learning algorithm, TPaS,
257"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.4677137870855148,"for tolerant learning in metric spaces. Let the perturbation radius be r > 0 for the actual type U = Br,
258"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.4694589877835951,"and let S = ((x1, y1), . . . , (xm, ym)) be the training sample. For each xi ∈SX, the learner samples
259"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.4712041884816754,"a point x′
i ∼Br·(1+γ)(xi) (using the sampling oracle) from the expanded reference perturbation
260"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.47294938917975565,"set V(xi) = B(1+γ)r(xi). Let S′ = ((x′
1, y1), . . . , (x′
m, ym)). TPaS then invokes a (standard, non-
261"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.47469458987783597,"robust) PAC learner AH for the hypothesis class H on the perturbed data S′. We let ˆh = AH(S′)
262"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.47643979057591623,"denote the output of this PAC learner. Finally, TPaS outputs the W-smoothed version of ¯hγr for
263"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.4781849912739965,"W = Bγr. That is, ¯hγr(x) is simply the majority label in a ball of radius γr around x with respect to
264"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.4799301919720768,"the distribution deﬁned by µ, see also Deﬁnition 9. We will prove below that this ¯hγr has a small
265"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.4816753926701571,"U-adversarial loss. Algorithm 1 below summarizes our learning procedure.
266"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.48342059336823734,Algorithm 1 Tolerant Perturb and Smooth (TPaS)
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.4851657940663176,"Input: Radius r, tolerance parameter γ, data S = ((x1, y1), . . . , (xm, ym)), accesss to sampling
oracle O for µ and PAC learner AH.
Initialize S′ = ∅
for i = 1 to m do"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.4869109947643979,"Sample x′
i ∼B(1+γ)r(xi)
Add (x′
i, yi) to S′
end for
Set ˆh = AH(S′)
Output: ¯hγr deﬁned by"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.4886561954624782,"¯hγr(x) = 1
h
Ex′∼Bγr(x)ˆh(x′) ≥1/2
i"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.49040139616055844,"The following is the main result of this section.
267"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.49214659685863876,"Theorem 10. Let (X, dist) be an any metric space with doubling dimension d and doubling measure
268"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.493891797556719,"µ. Let O be a sampling oracle for µ. Let H be a hypothesis class and P a set of distributions over
269"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.4956369982547993,"X × Y . Assume AH PAC learns H with mH(ϵ, δ) samples in the realizable setting. Then there exists
270"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.4973821989528796,"a learner A, namely TPaS, that
271"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.49912739965095987,"• Tolerantly PAC learns (H, P, dist) in the tolerantly realizable setting with sample complexity
272"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5008726003490401,"bounded by m(ϵ, δ, γ) = O
 
mH(ϵ, δ) · (1 + 1/γ)ζd
= O

VC(H)+log 1/δ"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5026178010471204,"ϵ
· (1 + 1/γ)ζd
,
273"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5043630017452007,"where γ is the tolerance parameter and d is the doubling dimension.
274"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.506108202443281,"• Makes only one query to AH
275"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5078534031413613,"• Makes m(ϵ, δ, γ) queries to sampling oracle O
276"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5095986038394416,"The proof of this theorem uses the following key technical lemma (proof can be found in Appendix C):
277 278"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5113438045375218,"Lemma 11. Let r > 0 be a perturbation radius, γ > 0 a tolerance parameter, and g : X →Y a
classiﬁer. For x ∈X and y ∈Y = {0, 1}, we deﬁne"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5130890052356021,"Σg,y(x) = Ez∼Br(1+γ)(x)1 [g(z) ̸= y]
and
σg,y(x) = Ez∼Brγ(x)1 [g(z) ̸= y] ."
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5148342059336823,"Then Σg,y(x) ≤1"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5165794066317626,"3 ·

1+γ"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.518324607329843,"γ
−ζd
implies that σg,y(z) ≤1/3 for all z ∈Br(x).
279"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5200698080279232,"Proof of Theorem 10. Consider some ϵ0 > 0 and 0 < δ < 1 to be given (we will pick a suitable
280"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5218150087260035,"value of ϵ0 later), and assume the PAC learner AH was invoked on the perturbed sample S′ of size
281"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5235602094240838,"at least mA(ϵ0, δ). According to deﬁnition 3, this implies that with probability 1 −δ, the output
282"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.525305410122164,"ˆh = AH(S) has (binary) loss at most ϵ0 with respect to the data-generating distribution. Note that the
283"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5270506108202443,"relevant distribution here is the two-stage process of the original data generating distribution P and
284"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5287958115183246,"the perturbation sampling according to V = B(1+γ)r. Since P is V-robustly realizable, the two-stage
285"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5305410122164049,"process yields a realizable distribution with respect to the standard 0/1-loss. Thus, we have
286"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5322862129144852,"E(x,y)∼P Ez∼Br(1+γ)(x)1
h
ˆh(z) ̸= y
i
≤ϵ0."
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5340314136125655,"With Lemma 11, this becomes E(x,y)∼P Σˆh,y(x) ≤ϵ0. For λ > 0, Markov’s inequality then yields :
287"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5357766143106457,"E(x,y)∼P 1
h
Σˆh,y(x) ≤λ
i
> 1 −ϵ0/λ
(1)"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.537521815008726,Thus setting λ = 1
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5392670157068062,"3 ·

1+γ"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5410122164048866,"γ
−ζd
and plugging in the result of the Lemma 11 to equation (1), we get"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5427574171029669,"E(x,y)∼P 1
h
∀z ∈Br(x), σˆh,y(z) ≤1/3
i
> 1 −ϵ0/λ."
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5445026178010471,"Since σˆh,y(z) ≤1/3 implies that 1
h
Ez′∼Bγr(z)ˆh(z′) ≥1/2
i
= y, using the deﬁnition of the
288"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5462478184991274,"smoothed classiﬁer ¯hγr we get
289"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5479930191972077,"E(x,y)∼P 1

∃z ∈Br(x), ¯hγr(z) ̸= y

≤ϵ0/λ, (2)"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5497382198952879,"which implies Lr
P (¯hγr) ≤ϵ0/λ. Thus, for the robust learning problem, if we are given a desired
290"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5514834205933682,"accuracy ϵ and we want Lr
P (¯hγr) ≤ϵ, we can pick ϵ0 = λϵ. Putting it all together, we get
291"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5532286212914486,sample complexity m ≤O( VC(H)+log 1/δ
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5549738219895288,"ϵ0
) where ϵ0 = λϵ, and λ = 1"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5567190226876091,"3 ·

1+γ"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5584642233856894,"γ
−ζd
. Therefore,
292"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5602094240837696,"m ≤O

VC(H)+log 1/δ"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5619546247818499,"ϵ
· (1 + 1/γ)ζd
.
293"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5636998254799301,"Since the dependence on d is exponential, the algorithm becomes impractical for high dimensions if γ
294"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5654450261780105,"is very small. However, since γ represents our uncertainty in the value of the true perturbation radius,
295"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5671902268760908,"it is natural to assume that it is a small but positive number. We can therefore ask whether there
296"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.568935427574171,"exists a threshold for each dimension such that if γ is above the threshold we can learn efﬁciently. In
297"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5706806282722513,"particular, for any constant c > 0, we can ensure that (1 + 1/γ)ζd ≤1 + c if we set γ ≥ζd"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5724258289703316,"c . Thus the
298"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5741710296684118,sample complexity of our learner does not depend on the dimension as long as γ ≥ζd
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5759162303664922,"c . For example,
299"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5776614310645725,"for a Euclidean space with the ℓ∞metric, we have ζ = 1. Therefore setting c = 1000 would let us
300"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5794066317626527,"use a small γ for dimensions up to 1000.
301"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.581151832460733,"Computational complexity of the learner. Assuming we have access to O and an efﬁcient algorithm
302"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5828970331588132,"for non-robust PAC-learning in the realizable setting, we can compute ˆh efﬁciently. Therefore, the
303"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5846422338568935,"learning can be done efﬁciently in this case. However, at the prediction time, we need to compute
304"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5863874345549738,"¯h(x) on new test points which requires us to compute an expectation. We can instead estimate the
305"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5881326352530541,"expectations using random samples from the sampling oracle. For a single test point x, if the number
306"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5898778359511344,"of samples we draw is Ω(log 1/δ) then with probability at least 1 −δ we get the same result as that
307"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5916230366492147,"of the optimal ¯h(x). Using more samples we can boost this probability to guarantee a similar output
308"
THE PERTURB-AND-SMOOTH APPROACH FOR TOLERANT ADVERSARIAL LEARNING,0.5933682373472949,"to that of ¯h on a larger set of test points.
309"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.5951134380453752,"6
Improved tolerant learning guarantees through sample compression
310"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.5968586387434555,"The perturb-and-smooth approach discussed in the previous section offers a general method for
311"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.5986038394415357,"tolerant robust learning. However, one shortcoming of this approach is the exponential dependence
312"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6003490401396161,"of its sample complexity with respect to the doubling dimension of the metric space. Furthermore,
313"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6020942408376964,"the tolerant robust guarantee relied on the data generating distribution being tolerantly realizable.
314"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6038394415357766,"In this section, we propose another approach that addresses both of these issues. The idea is to
315"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6055846422338569,"adopt the perturb-and-smooth approach within a sample compression argument. We introduce the
316"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6073298429319371,"notion of a (U, V)-tolerant sample compression scheme and present a learning bound based on such
317"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6090750436300174,"a compression scheme, starting with the realizable case. We then show that this implies learnability
318"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6108202443280978,"in the agnostic case as well. Remarkably, this tolerant compression based analysis will yield bounds
319"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.612565445026178,"on the sample complexity that avoid the exponential dependence on the doubling dimension.
320"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6143106457242583,"For a compact representation, we will use the general notation U, V, and W for the three perturbation
321"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6160558464223386,"types (actual, reference and smoothing type) in this section and will assume that they satisfy the
322"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6178010471204188,"Property 1 below for some parameter β > 0. Lemma 11 implies that, in the metric setting, for any
323"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6195462478184991,"radius r and tolerance parameter γ the perturbation types U = Br, V = B(1+γ)r, and W = Bγr have
324"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6212914485165794,this property for β = 1
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6230366492146597,"3

1+γ"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.62478184991274,"γ
−ζd
.
325"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6265270506108203,"Property 1. For a ﬁxed 0 < β < 1/2, we assume that the perturbation types V, U and W are so
326"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6282722513089005,"that for any classiﬁer h and any x ∈X, any y ∈{0, 1} if
327"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6300174520069808,Ez∼V(x)[h(z) = y] ≥1 −β
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.631762652705061,"then W-smoothed class classiﬁer ¯hW satisﬁes ¯hW(z) = y for all z ∈U(x).
328"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6335078534031413,"A compression scheme of size k is a pair of functions (κ, ρ), where the compression function
329"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6352530541012217,"κ : S∞
i=1(X × Y )i →Sk
i=1(X × Y )i maps samples S = ((x1, y1), (x2, y2), . . . , (xm, ym)) of
330"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6369982547993019,"arbitrary size to sub-samples of S of size at most k, and ρ : Sk
i=1(X ×Y )i →Y X is a decompression
331"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6387434554973822,"function that maps samples to classiﬁers. The pair (κ, ρ) is a sample compression scheme for loss ℓ
332"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6404886561954625,"and class H, if for any samples S realizable by H, we recover the correct labels for all (x, y) ∈S,
333"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6422338568935427,"that is, LS(H) = 0 implies that LS(κ ◦ρ(S)) = 0.
334"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.643979057591623,"For tolerant learning, we introduce the following generalization of compression schemes:
335"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6457242582897034,"Deﬁnition 12 (Tolerant sample compression scheme). A sample compression scheme (κ, ρ) is a
336"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6474694589877836,"U, V-tolerant sample compression scheme for class H, if for any samples S that are ℓV realizable by
337"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6492146596858639,"H, that is LV
S(H) = 0, we have LU
S(κ ◦ρ(S)) = 0.
338"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6509598603839442,"The next lemma establishes that the existence of a sufﬁciently small tolerant compression scheme
339"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6527050610820244,"for the class H yields bounds on the sample complexity of tolerantly learning H. The proof of the
340"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6544502617801047,"lemma is based on a modiﬁcation of a standard compression based generalization bound. Appendix
341"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6561954624781849,"Section D provides more details.
342"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6579406631762653,"Lemma 13. Let H be a hypothesis class and U and V be perturbation types with U included in V. If
343"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6596858638743456,"the class H admits a (U, V)-tolerant compression scheme of size bounded by k ln(m) for sample of
344"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6614310645724258,"size m, then the class is (U, V)-tolerantly learnable in the realizable case with sample complexity
345"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6631762652705061,"bounded by m(ϵ, δ) = ˜O

k+ln(1/δ)"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6649214659685864,"ϵ

.
346"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6666666666666666,"We next establish a bound on the tolerant compression size for general VC-classes, which will then
347"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6684118673647469,"immediately yield the improved sample complexity bounds for tolerant learning in the realizable case.
348"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6701570680628273,"The proof is sketched here; its full version has been moved to the Appendix for lack of space.
349"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6719022687609075,"Lemma 14. Let H ⊆Y X be some hypothesis class with ﬁnite VC-dimension VC(H) < ∞, and
350"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6736474694589878,"let U, V, W satisfy the conditions in Property 1 for some β > 0. Then there exists a (U, V)-tolerant
351"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.675392670157068,"sample compression scheme for H of size ˜O

VC(H) ln( m"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6771378708551483,"β )

.
352"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6788830715532286,"Proof Sketch. We will employ a boosting-based approach to establish the claimed compression sizes.
353"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.680628272251309,"Let S = ((x1, y1), (x2, y2), . . . , (xm, ym)) be a data-set that is ℓV-realizable with respect to H. We
354"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6823734729493892,"let SV denote an “inﬂated data-set” that contains all domain points in the V-perturbation sets of
355"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6841186736474695,"the xi ∈SX, that is SX
V := Sm
i=1 V(xi). Every point z ∈SX
V is assigned the label y = yi of the
356"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6858638743455497,"minimally-indexed (xi, yi) ∈S with z ∈V(xi), and we set SV to be the resulting collection of
357"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.68760907504363,"labeled data-points.
358"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6893542757417103,"We then use the boost-by-majority method to encode a classiﬁer g that (roughly speaking) has error
359"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6910994764397905,"bounded by β/m over (a suitable measure over) SV. This boosting method outputs a T-majority
360"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6928446771378709,"vote g(x) = 1

ΣT
i=1hi(x)

≥1/2 over weak learners hi, which in our case will be hypotheses from
361"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6945898778359512,H. We prove that this error can be achieved with T = 18 ln( 2m
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6963350785340314,"β ) rounds of boosting. We prove that
362"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.6980802792321117,"each weak learner that is used in the boosting procedure can be encoded with n = ˜O(VC(H)) many
363"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.699825479930192,"sample points from S. The resulting compression size is thus n · T = ˜O

VC(H) ln( m"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7015706806282722,"β )

.
364"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7033158813263525,"Finally, the error bound β/m of g over SV implies that the error in each perturbation set V(xi) of a
365"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7050610820244329,"sample point (xi, yi) ∈S is at most β. Property 1 then implies LU
S(¯gW) = 0 for the W-smoothed
366"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7068062827225131,"classiﬁer ¯gW, establishing the (U, V)-tolerant correctness of the compression scheme.
367"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7085514834205934,"This yields the following result
368"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7102966841186736,"Theorem 15. Let H be a hypothesis class of ﬁnite VC-dimension and V, U, W be three perturbation
369"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7120418848167539,"types (actual, reference and smoothing) satisfying Property 1 for some β > 0. Then the sample
370"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7137870855148342,"complexity (omitting log-factors) of (U, V)-tolerantly learning H is bounded by
371"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7155322862129145,"m(ϵ, δ) = ˜O
VC(H) ln(1/β) + ln(1/δ) ϵ "
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7172774869109948,"in the realizable case, and in the agnostic case by
372"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7190226876090751,"m(ϵ, δ) = ˜O
VC(H) ln(1/β) + ln(1/δ) ϵ2 "
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7207678883071553,"Proof. The bound for the realizable case follows immediately from Lemma 14 and the subsequent
373"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7225130890052356,"discussion (in the Appendix). For the agnostic case, we employ a reduction from agnostic robust
374"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7242582897033158,"learnabilty to realizable robust learnability (Montasser et al., 2019; Moran & Yehudayoff, 2016).
375"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7260034904013961,"The reduction is analogous to the one presented in Appendix C of Montasser et al. (2019) for usual
376"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7277486910994765,"(non-tolerant) robust learnablity with some minor modiﬁcations. Namely, for a sample S, we choose
377"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7294938917975567,"the largest subsample S′ that is ℓV-realizable (this will result in competitiveness with a ℓV-optimal
378"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.731239092495637,"classiﬁer), and we will use the boosting procedure described there for the ℓU loss. For the sample sizes
379"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7329842931937173,"employed for the weak learners in that procedure, we can use the sample complexity for ϵ = δ = 1/3
380"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7347294938917975,"of an optimal (U, V)-tolerant learner in the realizable case (note that each learning problem during
381"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7364746945898778,"the boosting procedure is a realizable (U, V)-tolerant learning task). These modiﬁcations result in the
382"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7382198952879581,"stated sample complexity for agnostic tolerant learnability.
383"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7399650959860384,"In particular, for the doubling measure scenario (as considered in the previous section), we obtain
384"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7417102966841187,"Corollary 16. For metric tolerant learning with tolerance parameter γ in doubling di-
385"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.743455497382199,"mension d the sample complexity of learning in the realizable case is bounded by
386"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7452006980802792,"m(ϵ, δ)
=
˜O

VC(H)ζd ln(1+1/γ)+ln(1/δ)"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7469458987783595,"ϵ

and
in
the
agnostic
case
by
m(ϵ, δ)
=
387"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7486910994764397,"˜O

VC(H)ζd ln(1+1/γ)+ln(1/δ)"
IMPROVED TOLERANT LEARNING GUARANTEES THROUGH SAMPLE COMPRESSION,0.7504363001745201,"ϵ2

.
388"
REFERENCES,0.7521815008726004,"References
389"
REFERENCES,0.7539267015706806,"Ashtiani, H., Pathak, V., and Urner, R. Black-box certiﬁcation and learning under adversarial
390"
REFERENCES,0.7556719022687609,"perturbations. In International Conference on Machine Learning, pp. 388–398. PMLR, 2020.
391"
REFERENCES,0.7574171029668412,"Attias, I., Kontorovich, A., and Mansour, Y. Improved generalization bounds for robust learning. In
392"
REFERENCES,0.7591623036649214,"Algorithmic Learning Theory, ALT, pp. 162–183, 2019.
393"
REFERENCES,0.7609075043630017,"Awasthi, P., Dutta, A., and Vijayaraghavan, A. On robustness to adversarial examples and polynomial
394"
REFERENCES,0.7626527050610821,"optimization. In Advances in Neural Information Processing Systems, NeurIPS, pp. 13760–13770,
395"
REFERENCES,0.7643979057591623,"2019.
396"
REFERENCES,0.7661431064572426,"Blumer, A., Ehrenfeucht, A., Haussler, D., and Warmuth, M. K. Learnability and the vapnik-
397"
REFERENCES,0.7678883071553229,"chervonenkis dimension. Journal of the ACM (JACM), 36(4):929–965, 1989.
398"
REFERENCES,0.7696335078534031,"Cao, X. and Gong, N. Z. Mitigating evasion attacks to deep neural networks via region-based
399"
REFERENCES,0.7713787085514834,"classiﬁcation. In Proceedings of the 33rd Annual Computer Security Applications Conference, pp.
400"
REFERENCES,0.7731239092495636,"278–287, 2017.
401"
REFERENCES,0.774869109947644,"Cohen, J. M., Rosenfeld, E., and Kolter, J. Z. Certiﬁed adversarial robustness via randomized
402"
REFERENCES,0.7766143106457243,"smoothing. In Proceedings of the 36th International Conference on Machine Learning, ICML, pp.
403"
REFERENCES,0.7783595113438045,"1310–1320, 2019.
404"
REFERENCES,0.7801047120418848,"Cullina, D., Bhagoji, A. N., and Mittal, P. Pac-learning in the presence of adversaries. In Advances in
405"
REFERENCES,0.7818499127399651,"Neural Information Processing Systems, NeurIPS, pp. 230–241, 2018.
406"
REFERENCES,0.7835951134380453,"Engstrom, L., Tran, B., Tsipras, D., Schmidt, L., and Madry, A. Exploring the landscape of spatial
407"
REFERENCES,0.7853403141361257,"robustness. In International Conference on Machine Learning, pp. 1802–1811. PMLR, 2019.
408"
REFERENCES,0.787085514834206,"Fawzi, A. and Frossard, P. Manitest: Are classiﬁers really invariant? In British Machine Vision
409"
REFERENCES,0.7888307155322862,"Conference (BMVC), number CONF, 2015.
410"
REFERENCES,0.7905759162303665,"Feige, U., Mansour, Y., and Schapire, R. Learning and inference in the presence of corrupted inputs.
411"
REFERENCES,0.7923211169284468,"In Conference on Learning Theory, COLT, pp. 637–657, 2015.
412"
REFERENCES,0.794066317626527,"Goldwasser, S., Kalai, A. T., Kalai, Y. T., and Montasser, O. Beyond perturbations: Learning
413"
REFERENCES,0.7958115183246073,"guarantees with arbitrary adversarial test examples. arXiv preprint arXiv:2007.05145, 2020.
414"
REFERENCES,0.7975567190226877,"Goodfellow, I. J., McDaniel, P. D., and Papernot, N. Making machine learning robust against
415"
REFERENCES,0.7993019197207679,"adversarial inputs. Commun. ACM, 61(7):56–66, 2018.
416"
REFERENCES,0.8010471204188482,"Hanneke, S. The optimal sample complexity of pac learning. The Journal of Machine Learning
417"
REFERENCES,0.8027923211169284,"Research, 17(1):1319–1333, 2016.
418"
REFERENCES,0.8045375218150087,"Haussler, D. Decision theoretic generalizations of the pac model for neural net and other learning
419"
REFERENCES,0.806282722513089,"applications. Information and computation, 100(1):78–150, 1992.
420"
REFERENCES,0.8080279232111692,"Haussler, D. and Welzl, E. epsilon-nets and simplex range queries. Discret. Comput. Geom., 2:
421"
REFERENCES,0.8097731239092496,"127–151, 1987.
422"
REFERENCES,0.8115183246073299,"Hendrycks, D., Mu, N., Cubuk, E. D., Zoph, B., Gilmer, J., and Lakshminarayanan, B. Augmix: A
423"
REFERENCES,0.8132635253054101,"simple data processing method to improve robustness and uncertainty. In International Conference
424"
REFERENCES,0.8150087260034904,"on Learning Representations, 2019.
425"
REFERENCES,0.8167539267015707,"Hosseini, H. and Poovendran, R. Semantic adversarial examples. In Proceedings of the IEEE
426"
REFERENCES,0.8184991273996509,"Conference on Computer Vision and Pattern Recognition Workshops, pp. 1614–1619, 2018.
427"
REFERENCES,0.8202443280977313,"Inkawhich, N., Wen, W., Li, H. H., and Chen, Y. Feature space perturbations yield more transferable
428"
REFERENCES,0.8219895287958116,"adversarial examples. In Proceedings of the IEEE/CVF Conference on Computer Vision and
429"
REFERENCES,0.8237347294938918,"Pattern Recognition, pp. 7066–7074, 2019.
430"
REFERENCES,0.8254799301919721,"Kanbak, C., Moosavi-Dezfooli, S.-M., and Frossard, P. Geometric robustness of deep networks:
431"
REFERENCES,0.8272251308900523,"Analysis and improvement. In 2018 IEEE/CVF Conference on Computer Vision and Pattern
432"
REFERENCES,0.8289703315881326,"Recognition, pp. 4441–4449. IEEE, 2018.
433"
REFERENCES,0.8307155322862129,"Kang, D., Sun, Y., Hendrycks, D., Brown, T., and Steinhardt, J. Testing robustness against unforeseen
434"
REFERENCES,0.8324607329842932,"adversaries. arXiv preprint arXiv:1908.08016, 2019.
435"
REFERENCES,0.8342059336823735,"Lecuyer, M., Atlidakis, V., Geambasu, R., Hsu, D., and Jana, S. Certiﬁed robustness to adversarial
436"
REFERENCES,0.8359511343804538,"examples with differential privacy. In 2019 IEEE Symposium on Security and Privacy (SP), pp.
437"
REFERENCES,0.837696335078534,"656–672. IEEE, 2019.
438"
REFERENCES,0.8394415357766143,"Levine, A. and Feizi, S. Robustness certiﬁcates for sparse adversarial attacks by randomized ablation.
439"
REFERENCES,0.8411867364746946,"In Proceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 34, pp. 4585–4593, 2020.
440"
REFERENCES,0.8429319371727748,"Li, B., Chen, C., Wang, W., and Carin, L. Certiﬁed adversarial robustness with additive noise.
441"
REFERENCES,0.8446771378708552,"Advances in Neural Information Processing Systems, 32:9464–9474, 2019.
442"
REFERENCES,0.8464223385689355,"Liu, X., Cheng, M., Zhang, H., and Hsieh, C.-J. Towards robust neural networks via random self-
443"
REFERENCES,0.8481675392670157,"ensemble. In Proceedings of the European Conference on Computer Vision (ECCV), pp. 369–385,
444"
REFERENCES,0.849912739965096,"2018.
445"
REFERENCES,0.8516579406631762,"Luukkainen, J. and Saksman, E. Every complete doubling metric space carries a doubling measure.
446"
REFERENCES,0.8534031413612565,"Proceedings of the American Mathematical Society, 126(2):531–534, 1998.
447"
REFERENCES,0.8551483420593369,"Montasser, O., Hanneke, S., and Srebro, N. VC classes are adversarially robustly learnable, but only
448"
REFERENCES,0.8568935427574171,"improperly. In Conference on Learning Theory, COLT, pp. 2512–2530, 2019.
449"
REFERENCES,0.8586387434554974,"Montasser, O., Goel, S., Diakonikolas, I., and Srebro, N. Efﬁciently learning adversarially robust
450"
REFERENCES,0.8603839441535777,"halfspaces with noise. arXiv preprint arXiv:2005.07652, 2020a.
451"
REFERENCES,0.8621291448516579,"Montasser, O., Hanneke, S., and Srebro, N. Reducing adversarially robust learning to non-robust pac
452"
REFERENCES,0.8638743455497382,"learning. In NeurIPS, 2020b.
453"
REFERENCES,0.8656195462478184,"Montasser, O., Hanneke, S., and Srebro, N. Adversarially robust learning with unknown perturbation
454"
REFERENCES,0.8673647469458988,"sets. arXiv preprint arXiv:2102.02145, 2021a.
455"
REFERENCES,0.8691099476439791,"Montasser, O., Hanneke, S., and Srebro, N. Transductive robust learning guarantees. arXiv preprint
456"
REFERENCES,0.8708551483420593,"arXiv:2110.10602, 2021b.
457"
REFERENCES,0.8726003490401396,"Moran, S. and Yehudayoff, A. Sample compression schemes for vc classes. Journal of the ACM
458"
REFERENCES,0.8743455497382199,"(JACM), 63(3):1–10, 2016.
459"
REFERENCES,0.8760907504363001,"Sabour, S., Cao, Y., Faghri, F., and Fleet, D. J. Adversarial manipulation of deep representations. In
460"
REFERENCES,0.8778359511343804,"ICLR (Poster), 2016.
461"
REFERENCES,0.8795811518324608,"Salman, H., Li, J., Razenshteyn, I. P., Zhang, P., Zhang, H., Bubeck, S., and Yang, G. Provably robust
462"
REFERENCES,0.881326352530541,"deep learning via adversarially trained smoothed classiﬁers. In Advances in Neural Information
463"
REFERENCES,0.8830715532286213,"Processing Systems 32, NeurIPS, pp. 11289–11300, 2019.
464"
REFERENCES,0.8848167539267016,"Schapire, R. E. and Freund, Y. Boosting: Foundations and algorithms. Kybernetes, 2013.
465"
REFERENCES,0.8865619546247818,"Shalev-Shwartz, S. and Ben-David, S. Understanding Machine Learning: From Theory to Algorithms.
466"
REFERENCES,0.8883071553228621,"Cambridge University Press, 2014.
467"
REFERENCES,0.8900523560209425,"Simon, H. U. An almost optimal pac algorithm. In Conference on Learning Theory, pp. 1552–1563.
468"
REFERENCES,0.8917975567190227,"PMLR, 2015.
469"
REFERENCES,0.893542757417103,"Song, Y., Shu, R., Kushman, N., and Ermon, S. Constructing unrestricted adversarial examples with
470"
REFERENCES,0.8952879581151832,"generative models. In Proceedings of the 32nd International Conference on Neural Information
471"
REFERENCES,0.8970331588132635,"Processing Systems, pp. 8322–8333, 2018.
472"
REFERENCES,0.8987783595113438,"Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I. J., and Fergus, R. Intrigu-
473"
REFERENCES,0.900523560209424,"ing properties of neural networks. In 2nd International Conference on Learning Representations,
474"
REFERENCES,0.9022687609075044,"ICLR, 2014.
475"
REFERENCES,0.9040139616055847,"Valiant, L. G. A theory of the learnable. Commun. ACM, 27(11):1134–1142, 1984.
476"
REFERENCES,0.9057591623036649,"Vapnik, V. N. and Chervonenkis, A. Y. On the uniform convergence of relative frequencies of events
477"
REFERENCES,0.9075043630017452,"to their probabilities. Theory of Probability & Its Applications, 16(2):264–280, 1971.
478"
REFERENCES,0.9092495636998255,"Xiao, C., Zhu, J.-Y., Li, B., He, W., Liu, M., and Song, D. Spatially transformed adversarial examples.
479"
REFERENCES,0.9109947643979057,"In International Conference on Learning Representations, 2018.
480"
REFERENCES,0.912739965095986,"Xu, Q., Tao, G., Cheng, S., and Zhang, X. Towards feature space adversarial attack. arXiv preprint
481"
REFERENCES,0.9144851657940664,"arXiv:2004.12385, 2020.
482"
REFERENCES,0.9162303664921466,"Yaeger, L., Lyon, R., and Webb, B. Effective training of a neural network character classiﬁer for
483"
REFERENCES,0.9179755671902269,"word recognition. Advances in neural information processing systems, 9:807–816, 1996.
484"
REFERENCES,0.9197207678883071,"Zheng, S., Song, Y., Leung, T., and Goodfellow, I. Improving the robustness of deep neural networks
485"
REFERENCES,0.9214659685863874,"via stability training. In Proceedings of the ieee conference on computer vision and pattern
486"
REFERENCES,0.9232111692844677,"recognition, pp. 4480–4488, 2016.
487"
REFERENCES,0.924956369982548,"Checklist
488"
REFERENCES,0.9267015706806283,"1. For all authors...
489"
REFERENCES,0.9284467713787086,"(a) Do the main claims made in the abstract and introduction accurately reﬂect the paper’s
490"
REFERENCES,0.9301919720767888,"contributions and scope? [Yes] Yes, the claims are supported by actual theorems and
491"
REFERENCES,0.9319371727748691,"proofs in the main text.
492"
REFERENCES,0.9336823734729494,"(b) Did you describe the limitations of your work? [Yes] We have discussed the limitations
493"
REFERENCES,0.9354275741710296,"of our main two results (theorems), including the dependency of the sample complexity
494"
REFERENCES,0.93717277486911,"on each of the parameters and the computational costs.
495"
REFERENCES,0.9389179755671903,"(c) Did you discuss any potential negative societal impacts of your work? [N/A] This is a
496"
REFERENCES,0.9406631762652705,"theoretical paper and we do not foresee any immediate negative impacts.
497"
REFERENCES,0.9424083769633508,"(d) Have you read the ethics review guidelines and ensured that your paper conforms to
498"
REFERENCES,0.944153577661431,"them? [Yes]
499"
REFERENCES,0.9458987783595113,"2. If you are including theoretical results...
500"
REFERENCES,0.9476439790575916,"(a) Did you state the full set of assumptions of all theoretical results? [Yes] Yes, the
501"
REFERENCES,0.9493891797556719,"assumptions are clearly stated. Also, wherever we had an informal theorem, we
502"
REFERENCES,0.9511343804537522,"have linked the full version of the theorem too (with all the necessary details and
503"
REFERENCES,0.9528795811518325,"assumptions).
504"
REFERENCES,0.9546247818499127,"(b) Did you include complete proofs of all theoretical results? [Yes] Yes. Some of the
505"
REFERENCES,0.956369982547993,"proofs are deferred to the appendix for space constraints.
506"
REFERENCES,0.9581151832460733,"3. If you ran experiments...
507"
REFERENCES,0.9598603839441536,"(a) Did you include the code, data, and instructions needed to reproduce the main experi-
508"
REFERENCES,0.9616055846422339,"mental results (either in the supplemental material or as a URL)? [N/A]
509"
REFERENCES,0.9633507853403142,"(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they
510"
REFERENCES,0.9650959860383944,"were chosen)? [N/A]
511"
REFERENCES,0.9668411867364747,"(c) Did you report error bars (e.g., with respect to the random seed after running experi-
512"
REFERENCES,0.9685863874345549,"ments multiple times)? [N/A]
513"
REFERENCES,0.9703315881326352,"(d) Did you include the total amount of compute and the type of resources used (e.g., type
514"
REFERENCES,0.9720767888307156,"of GPUs, internal cluster, or cloud provider)? [N/A]
515"
REFERENCES,0.9738219895287958,"4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...
516"
REFERENCES,0.9755671902268761,"(a) If your work uses existing assets, did you cite the creators? [N/A]
517"
REFERENCES,0.9773123909249564,"(b) Did you mention the license of the assets? [N/A]
518"
REFERENCES,0.9790575916230366,"(c) Did you include any new assets either in the supplemental material or as a URL? [N/A]
519 520"
REFERENCES,0.9808027923211169,"(d) Did you discuss whether and how consent was obtained from people whose data you’re
521"
REFERENCES,0.9825479930191972,"using/curating? [N/A]
522"
REFERENCES,0.9842931937172775,"(e) Did you discuss whether the data you are using/curating contains personally identiﬁable
523"
REFERENCES,0.9860383944153578,"information or offensive content? [N/A]
524"
REFERENCES,0.987783595113438,"5. If you used crowdsourcing or conducted research with human subjects...
525"
REFERENCES,0.9895287958115183,"(a) Did you include the full text of instructions given to participants and screenshots, if
526"
REFERENCES,0.9912739965095986,"applicable? [N/A]
527"
REFERENCES,0.9930191972076788,"(b) Did you describe any potential participant risks, with links to Institutional Review
528"
REFERENCES,0.9947643979057592,"Board (IRB) approvals, if applicable? [N/A]
529"
REFERENCES,0.9965095986038395,"(c) Did you include the estimated hourly wage paid to participants and the total amount
530"
REFERENCES,0.9982547993019197,"spent on participant compensation? [N/A]
531"
