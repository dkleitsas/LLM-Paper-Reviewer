Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0020876826722338203,"Although deep neural networks have achieved super-human performance on many
1"
ABSTRACT,0.0041753653444676405,"classification tasks, they often exhibit a worrying lack of robustness towards ad-
2"
ABSTRACT,0.006263048016701462,"versarially generated examples. Thus, considerable effort has been invested into
3"
ABSTRACT,0.008350730688935281,"reformulating Empirical Risk Minimization (ERM) into an adversarially robust
4"
ABSTRACT,0.010438413361169102,"framework. Recently, attention has shifted towards approaches which interpolate
5"
ABSTRACT,0.012526096033402923,"between the robustness offered by adversarial training and the higher clean accu-
6"
ABSTRACT,0.014613778705636743,"racy and faster training times of ERM. In this paper, we take a fresh and geometric
7"
ABSTRACT,0.016701461377870562,"view on one such method—Probabilistically Robust Learning (PRL) [Robey et al.,
8"
ABSTRACT,0.018789144050104383,"2022]. We propose a geometric framework for understanding PRL, which allows
9"
ABSTRACT,0.020876826722338204,"us to identify a subtle flaw in its original formulation and to introduce a family of
10"
ABSTRACT,0.022964509394572025,"probabilistic nonlocal perimeter functionals to address this. We prove existence
11"
ABSTRACT,0.025052192066805846,"of solutions using novel relaxation methods and study properties as well as local
12"
ABSTRACT,0.027139874739039668,"limits of the introduced perimeters.
13"
INTRODUCTION,0.029227557411273485,"1
Introduction
14"
INTRODUCTION,0.031315240083507306,"The fragility of DNN-based classifiers in the face of adversarial examples [Goodfellow et al., 2014,
15"
INTRODUCTION,0.033402922755741124,"Chen et al., 2017, Qin et al., 2019, Cai et al., 2021] and distributional shifts [Quinoñero Candela
16"
INTRODUCTION,0.03549060542797495,"et al., 2008, Hendrycks et al., 2021] is by now nearly as familiar as their successes. In light of this,
17"
INTRODUCTION,0.037578288100208766,"a multitude of works (see Section 1.4) propose replacing standard Empirical Risk Minimization
18"
INTRODUCTION,0.03966597077244259,"(ERM) [Vapnik, 1999] with a more robust alternative (see, e.g., Madry et al. [2017]). Unfortunately
19"
INTRODUCTION,0.04175365344467641,"there is no free lunch: robust classifiers frequently exhibit degraded performance on clean data and
20"
INTRODUCTION,0.04384133611691023,"significantly longer training times [Tsipras et al., 2018]. Consequently, identifying frameworks which
21"
INTRODUCTION,0.04592901878914405,"balance performance and robustness is of pressing interest to the Machine Learning (ML) community,
22"
INTRODUCTION,0.04801670146137787,"and over the past several years many such frameworks have been proposed [Zhang et al., 2019, Wang
23"
INTRODUCTION,0.05010438413361169,"et al., 2020, Robey et al., 2022]. Moreover, it is crucial that the mechanism by which such frameworks
24"
INTRODUCTION,0.05219206680584551,"balance these competing aims be understood.
25"
INTRODUCTION,0.054279749478079335,"Beginning with the Probabilistically Robust Learning (PRL) of Robey et al. [2022] we analyze such
26"
INTRODUCTION,0.05636743215031315,"frameworks geometrically. This perspective reveals a subtle, paradoxical aspect of PRL: sometimes
27"
INTRODUCTION,0.05845511482254697,"the adversary modeled by this framework corrects, instead of exploits, the learner! Fortunately, the
28"
INTRODUCTION,0.060542797494780795,"geometric perspective we propose suggests a natural remedy which leads to an interpretation of the
29"
INTRODUCTION,0.06263048016701461,"corrected PRL as regularized ERM where a certain nonlocal notion of length (or perimeter) of the
30"
INTRODUCTION,0.06471816283924843,"decision boundary acts as a regularizer. We exemplify this correction in Figure 1. The interpretation
31"
INTRODUCTION,0.06680584551148225,"of PRL as perimeter-regularized ERM leads us to further generalizations, and we provide a novel
32"
INTRODUCTION,0.06889352818371608,"view of the Conditional Value at Risk (CVaR) relaxation of PRL proposed by Robey et al. [2022].
33"
INTRODUCTION,0.0709812108559499,A ≜class green
INTRODUCTION,0.07306889352818371,Ac ≜class red
INTRODUCTION,0.07515657620041753,"(a) Robey et al. [2022]: The probabilistically non-
robust region (magnified) reduces the loss."
INTRODUCTION,0.07724425887265135,A ≜class green
INTRODUCTION,0.07933194154488518,Ac ≜class red
INTRODUCTION,0.081419624217119,"(b) Our model: The probabilistically non-robust
region is correctly identified and penalized."
INTRODUCTION,0.08350730688935282,"Figure 1: Penalization effect of the original model [Robey et al., 2022] (left) and ours (right): The
solid black is the decision boundary of a non-robust classifier induced by the set A. Both models
penalize the numbers of green points in the yellow region and red points in the teal region. However,
the original model favors non-robust regions of A for which most perturbations correct the class. Our
model identifies this region as non-robust and penalizes it accordingly."
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.08559498956158663,"1.1
From empirical risk minimization to robustness
34"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.08768267223382047,"Given an input space X, an output space Y, a probability measure µ ∈P(X × Y), a loss function
35"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.08977035490605428,"ℓ: Y × Y →R, and a hypothesis class H, the standard risk minimization problem is
36"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.0918580375782881,"inf
h∈H E(x,y)∼µ [ℓ(h(x), y)] .
(1)"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.09394572025052192,"For training classifiers which are robust against adversarial attacks Goodfellow et al. [2014], Madry
37"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.09603340292275574,"et al. [2017] suggested adversarial training:
38"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.09812108559498957,"inf
h∈H E(x,y)∼µ """
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.10020876826722339,"sup
x′∈Bε(x)
ℓ(h(x′), y) # .
(2)"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.1022964509394572,"Here X is assumed to have the structure of a metric space and Bε(x) for ε ≥0 denotes the (open or
39"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.10438413361169102,"closed) ball of radius ε around x.
40"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.10647181628392484,"The recent work by Robey et al. [2022] offered an alternative to adversarial training in order to
41"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.10855949895615867,"reduce the (in general) large trade-off between accuracy and robustness inherent in (2), see Tsipras
42"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.11064718162839249,"et al. [2018], Robey et al. [2022] for discussion. Instead of requiring classifiers to be robust to all
43"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.1127348643006263,"available attacks around a point x—as enforced through the supremum in (2)—one may consider
44"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.11482254697286012,"a less stringent notion of robustness, only requiring classifiers to be robust to 100 × (1 −p)% of
45"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.11691022964509394,"possible attacks when attacks are drawn from a certain distribution px centered at x. For this, the
46"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.11899791231732777,"authors introduced the so-called p-ess sup operator for p ∈[0, 1) and suggested replacing (2) by
47"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.12108559498956159,"inf
h∈H E(x,y)∼µ"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.12317327766179541,"
p- ess sup
x′∼px
ℓ(h(x′), y)

,
(3)"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.12526096033402923,"where {px}x∈X is a family of probability distributions. The prototypical example to keep in mind
48"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.12734864300626306,"for X = Rd is the uniform distribution over the ε-ball around x, i.e., px := Unif(Bε(x)), which is
49"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.12943632567849686,"particularly relevant when dealing with adversarial attacks on image classifiers.
50"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.1315240083507307,"For a probability distribution p and a function f, the quantity p- ess supx′∼p f(x′) is defined as the
51"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.1336116910229645,"smallest value t ∈R such that the probability of a randomly chosen point x′ ∼p satisfying f(x′) > t
52"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.13569937369519833,"is smaller than p, which reduces to the usual essential supremum of f with respect to p if p = 0:
53"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.13778705636743216,"p- ess sup
x′∼p
f(x′) := inf {t ∈R : Px′∼p [f(x′) > t] ≤p}."
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.13987473903966596,"To better understand the model (3) we temporarily restrict our attention to binary classification (i.e.,
54"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.1419624217118998,"Y = {0, 1}) using indicator functions of admissible sets (i.e., H := {1A : A ∈A}). Note that we
55"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.1440501043841336,"identify the two expressions 1A(x) = 1x∈A. We focus on the 0-1 loss ℓ(˜y, y) = 1˜y̸=y which equals
56"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.14613778705636743,"one if y ̸= ˜y and zero otherwise. In this scenario (1) reduces to the geometric problem
57"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.14822546972860126,"inf
A∈A"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.15031315240083507,"n
Rstd(A) := E(x,y)∼µ [y1x∈Ac + (1 −y)1x∈A]
o
,
(4)"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.1524008350730689,"and minimizers are called Bayes classifiers. Similarly, adversarial training (2) can be rewritten as
58"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.1544885177453027,"inf
A∈A"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.15657620041753653,"
Radv(A) := E(x,y)∼µ
h
y1x∈(Ac)⊕ε + (1 −y)1x∈A⊕ε
i 
,
(5)"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.15866388308977036,where for a set A ∈A its fattening by ε-balls is defined as A⊕ε := S
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.16075156576200417,"x∈A Bε(x). Hence (5) enforces
59"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.162839248434238,"that all points with distance at most ε to the decision boundary be adversarially robust.
60"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.1649269311064718,"On the other hand the PRL model (3) reduces to
61"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.16701461377870563,"inf
A∈A"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.16910229645093947,"
Rprob(A) := E(x,y)∼µ
h
y1Px′∼px[x′∈Ac]>p + (1 −y)1Px′∼px[x′∈A]>p
i 
,
(6)"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.17118997912317327,"where A⊕ε is replaced by a “probabilistic fattening”, i.e., one considers the set of all x for which the
62"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.1732776617954071,"probability that a neighboring point sampled from px lies inside A is larger than p. To the best of our
63"
FROM EMPIRICAL RISK MINIMIZATION TO ROBUSTNESS,0.17536534446764093,"knowledge, existence of solutions for (6) or even (3) has not been proved so far.
64"
GEOMETRIC MODIFICATION OF PROBABILISTICALLY ROBUST LEARNING,0.17745302713987474,"1.2
Geometric modification of probabilistically robust learning
65"
GEOMETRIC MODIFICATION OF PROBABILISTICALLY ROBUST LEARNING,0.17954070981210857,"To motivate our geometric modification of the PRL model from Robey et al. [2022], it is insightful to
66"
GEOMETRIC MODIFICATION OF PROBABILISTICALLY ROBUST LEARNING,0.18162839248434237,"investigate the regularization effect that PRL has compared to standard risk minimization. We let
67"
GEOMETRIC MODIFICATION OF PROBABILISTICALLY ROBUST LEARNING,0.1837160751565762,"ρi(•) := µ(• × {i}) denote the non-normalized conditional distributions of the points with label i.
68"
GEOMETRIC MODIFICATION OF PROBABILISTICALLY ROBUST LEARNING,0.18580375782881003,"Subtracting the standard risk in (4) from the one in (6) and disintegrating using ρ0 and ρ1 we obtain
69"
GEOMETRIC MODIFICATION OF PROBABILISTICALLY ROBUST LEARNING,0.18789144050104384,"Rprob(A) −Rstd(A) =
Z"
GEOMETRIC MODIFICATION OF PROBABILISTICALLY ROBUST LEARNING,0.18997912317327767,"X
1Px′∼px[x′∈A]>p −1x∈A dρ0(x) +
Z"
GEOMETRIC MODIFICATION OF PROBABILISTICALLY ROBUST LEARNING,0.19206680584551147,"X
1Px′∼px[x′∈Ac]>p −1x∈Ac dρ1(x).
(7)"
GEOMETRIC MODIFICATION OF PROBABILISTICALLY ROBUST LEARNING,0.1941544885177453,"We highlight that this expression does not constitute a non-negative functional of A. Hence the loss
70"
GEOMETRIC MODIFICATION OF PROBABILISTICALLY ROBUST LEARNING,0.19624217118997914,"function in (6) is not a regularized version of the standard risk (4) and in fact can be strictly smaller.
71"
GEOMETRIC MODIFICATION OF PROBABILISTICALLY ROBUST LEARNING,0.19832985386221294,"This observation reveals a subtle flaw in the approach of Robey et al. [2022]: Points which lie in thin
72"
GEOMETRIC MODIFICATION OF PROBABILISTICALLY ROBUST LEARNING,0.20041753653444677,"or spike-like regions of A penetrating the other class and that are more likely to have the label zero
73"
GEOMETRIC MODIFICATION OF PROBABILISTICALLY ROBUST LEARNING,0.20250521920668058,"than the label one (meaning they lie in the set {ρ0 > ρ1}) yield negative contributions in (7) and
74"
GEOMETRIC MODIFICATION OF PROBABILISTICALLY ROBUST LEARNING,0.2045929018789144,"are hence favored. Such a scenario is visualized on the left side of Figure 1. From an adversarial
75"
GEOMETRIC MODIFICATION OF PROBABILISTICALLY ROBUST LEARNING,0.20668058455114824,"perspective this means that points which are already misclassified are attacked nevertheless, which
76"
GEOMETRIC MODIFICATION OF PROBABILISTICALLY ROBUST LEARNING,0.20876826722338204,"can lead to the bizarre situation that the adversary helps the learner by putting these points in the
77"
GEOMETRIC MODIFICATION OF PROBABILISTICALLY ROBUST LEARNING,0.21085594989561587,"correct class with high probability, thereby reducing both adversarial robustness and clean accuracy.
78"
GEOMETRIC MODIFICATION OF PROBABILISTICALLY ROBUST LEARNING,0.21294363256784968,"We fix this by designing a probabilistically robust risk as non-negative regularization of the standard
79"
GEOMETRIC MODIFICATION OF PROBABILISTICALLY ROBUST LEARNING,0.2150313152400835,"risk. For this we define probabilistic perimeter functionals which only penalize points which are
80"
GEOMETRIC MODIFICATION OF PROBABILISTICALLY ROBUST LEARNING,0.21711899791231734,"classified correctly and admit a large portion of attacks around them, see the right side of Figure 1.
81"
OUR CONTRIBUTIONS,0.21920668058455114,"1.3
Our contributions
82"
OUR CONTRIBUTIONS,0.22129436325678498,"Our main contributions are the following:
83"
OUR CONTRIBUTIONS,0.22338204592901878,"• We address the geometric limitation of the model by Robey et al. [2022] by introducing a
84"
OUR CONTRIBUTIONS,0.2254697286012526,"family of perimeter regularizations.
85"
OUR CONTRIBUTIONS,0.22755741127348644,"• We prove existence of soft and hard binary classifiers under weak conditions on the family
86"
OUR CONTRIBUTIONS,0.22964509394572025,"of perimeters and hypothesis classes, using novel relaxation techniques.
87"
OUR CONTRIBUTIONS,0.23173277661795408,"• We investigate the relationship between the introduced family of perimeters and local
88"
OUR CONTRIBUTIONS,0.23382045929018788,"perimeters in Euclidean space for small adversarial budgets.
89"
OUR CONTRIBUTIONS,0.2359081419624217,"• We extend our models to encompass general loss functions and hypothesis classes. Our
90"
OUR CONTRIBUTIONS,0.23799582463465555,"numerical experiments demonstrate that our geometric correction can enhance the adversarial
91"
OUR CONTRIBUTIONS,0.24008350730688935,"robustness of probabilistically robust classifiers without compromising clean accuracy.
92"
RELATED WORK,0.24217118997912318,"1.4
Related work
93"
RELATED WORK,0.24425887265135698,"Adversarial training was developed by Goodfellow et al. [2014], Madry et al. [2017] as an approach
94"
RELATED WORK,0.24634655532359082,"to train networks that are less sensitive to adversarial attacks. Shafahi et al. [2019] reduced its
95"
RELATED WORK,0.24843423799582465,"computational complexity by reusing gradients from the backpropagation when training neural
96"
RELATED WORK,0.25052192066805845,"networks. Wong et al. [2020] showed that training with noise perturbations followed by a single
97"
RELATED WORK,0.25260960334029225,"signed gradient ascent (FGSM) step can be on par with adversarial training while being much
98"
RELATED WORK,0.2546972860125261,"cheaper. This approach was picked up and improved upon by Andriushchenko and Flammarion
99"
RELATED WORK,0.2567849686847599,"[2020] based on gradient alignment. Different authors also investigated test-time robustification of
100"
RELATED WORK,0.2588726513569937,"pretrained classifiers using randomized smoothing [Cohen et al., 2019] or geometric / gradient-based
101"
RELATED WORK,0.2609603340292276,"approaches [Schwinn et al., 2021, 2022]. While some of the previous models use a combination
102"
RELATED WORK,0.2630480167014614,"of random perturbations and gradient-based adversarial attacks to robustify classifiers, Robey et al.
103"
RELATED WORK,0.2651356993736952,"[2022] proposed probabilistically robust learning, which is entirely based on random perturbations.
104"
RELATED WORK,0.267223382045929,"PRL aims to interpolate between clean and adversarial accuracy and enjoys the favorable sample
105"
RELATED WORK,0.26931106471816285,"complexity of vanilla empirical risk minimization; see also Raman et al. [2023] for more insights on
106"
RELATED WORK,0.27139874739039666,"this issue. Connections between adversarial training and local perimeter regularization of decision
107"
RELATED WORK,0.27348643006263046,"boundaries were explored by García Trillos and Murray [2022] and then rigorously tied by Bungert
108"
RELATED WORK,0.2755741127348643,"and Stinson [2022]. Our work is in line with a series of papers [Pydi and Jog, 2021, Awasthi et al.,
109"
RELATED WORK,0.2776617954070981,"2021a,b, Frank and Niles-Weed, 2022, Frank, 2022, Bungert et al., 2023, García Trillos et al., 2023]
110"
RELATED WORK,0.2797494780793319,"that explore the existence of solutions to adversarial training problems in different settings. These
111"
RELATED WORK,0.2818371607515658,"existence proofs involve dealing with different kinds of measurability issues, depending on whether
112"
RELATED WORK,0.2839248434237996,"open or closed balls Bε(x) are used in the attack model. For open balls one can work with the
113"
RELATED WORK,0.2860125260960334,"Borel σ-algebra A = B(X) [Bungert et al., 2023], whereas closed balls require the use of the
114"
RELATED WORK,0.2881002087682672,"universal σ-algebra to make sure that A⊕ε is measurable [Pydi and Jog, 2021, Awasthi et al., 2021a,b].
115"
RELATED WORK,0.29018789144050106,"Recently, these results were improved by García Trillos et al. [2023] who also proved for the case of
116"
RELATED WORK,0.29227557411273486,"multi-class classification that even for the closed ball model Borel measurable classifiers (albeit not
117"
RELATED WORK,0.29436325678496866,"necessarily indicator functions of measurable sets) exist and that for all but countably many values of
118"
RELATED WORK,0.2964509394572025,"the adversarial budget ε > 0 the open and the closed ball models have the same minimal value.
119"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.2985386221294363,"2
Geometry and existence of probabilistically robust classifiers
120"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.30062630480167013,"2.1
The binary classification setting with 0-1 loss
121"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.302713987473904,"In this section we shall introduce our baseline model, which is based on a suitable geometric
122"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.3048016701461378,"regularization of the standard risk. Later we shall embed it into a family of models. For clarity we
123"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.3068893528183716,"first discuss hard classifiers (characteristic functions of sets) and then soft classifiers (functions with
124"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.3089770354906054,"values in [0, 1]). The generalization to general models and loss functions is postponed to Section 3.
125"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.31106471816283926,"We start by defining the probabilistic perimeter for p ∈[0, 1) of an admissible set A ∈A as follows:
126"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.31315240083507306,ProbPer(A) := ρ0 ({x ∈Ac : Px′∼px [x′ ∈A] > p})
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.31524008350730687,"+ ρ1 ({x ∈A : Px′∼px [x′ ∈Ac] > p}) .
(8)"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.3173277661795407,"ProbPer(A) penalizes correctly classified points x for which more than 100×p % of their neighbors,
127"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.31941544885177453,"sampled from px, constitute an attack. The perimeter can be rewritten in integral form:
128"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.32150313152400833,"ProbPer(A) =
Z"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.3235908141962422,"X
1x∈A ∨Px′∼px[x′∈A]>p −1x∈A dρ0(x) +
Z"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.325678496868476,"X
1x∈Ac ∨Px′∼px[x′∈Ac]>p −1x∈Ac dρ1(x)
(9) =
Z"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.3277661795407098,"X
1x∈Ac1Px′∼px[x′∈A]>p dρ0(x) +
Z"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.3298538622129436,"X
1x∈A1Px′∼px[x′∈Ac]>p dρ1(x).
(10)"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.33194154488517746,"The first reformulation (9) should be compared to (7), while the one in (10) will be useful later
129"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.33402922755741127,"on. The use of the term perimeter to describe the functional ProbPer will become more apparent
130"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.33611691022964507,"shortly in Section 2.4, and at this point it is worth highlighting that ProbPer is always a non-negative
131"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.33820459290187893,"quantity. This motivates introducing the following regularized risk
132"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.34029227557411273,"ProbR(A) := Rstd(A) + ProbPer(A),
A ∈A.
(11)"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.34237995824634654,"Our first theorem states that ProbR equals the expected maximum of the sample-wise standard risk
133"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.3444676409185804,"and the probabilistically robust risk from Robey et al. [2022], cf. (4) and (6).
134"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.3465553235908142,"Theorem 1. For all A ∈A it holds that
135"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.348643006263048,"ProbR(A) = E(x,y)∼µ
h
max
n
1Px′∼px[1A(x′)̸=y]>p, 11A(x)̸=y
oi
.
(12)"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.35073068893528186,"The interpretation of the statement of this theorem in the light of Figure 1 is clear: Only if a point
136"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.35281837160751567,"x is correctly classified—meaning 11A(x)̸=y = 0—the probabilistically robust regularization kicks
137"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.35490605427974947,"in through the first term in the maximum. Points which are incorrectly classified will always be
138"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.3569937369519833,"penalized even if most attacks correct the label, i.e., if 1Px′∼px[1A(x′)̸=y]>p = 0. Thus, minimizing
139"
GEOMETRY AND EXISTENCE OF PROBABILISTICALLY ROBUST CLASSIFIERS,0.35908141962421714,"ProbR instead of Rprob corrects the pathology identified in Section 1.2.
140"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.36116910229645094,"2.2
Extensions in the binary classification setting
141"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.36325678496868474,"Given the formula of ProbPer in (10), several natural extensions suggest themselves. E.g., one may
142"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.3653444676409186,"replace the indicator function 1t>p with a different function Ψ(t) to define other notions of perimeter
143"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.3674321503131524,"ProbPerΨ(A) :=
Z"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.3695198329853862,"X
1x∈AcΨ (Px′∼px [x′ ∈A]) dρ0(x) +
Z"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.37160751565762007,"X
1x∈AΨ (Px′∼px [x′ ∈Ac]) dρ1(x)
(13)"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.3736951983298539,"as well as their corresponding probabilistically robust losses
144"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.3757828810020877,"ProbRΨ(A) := Rstd(A) + ProbPerΨ(A).
(14)"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.3778705636743215,"For Ψ(t) := 1t>p the perimeter ProbPerΨ reduces to ProbPer and so do the associated risks. Of
145"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.37995824634655534,"particular interest is Ψp(t) := min {t/p, 1}—the smallest concave function that lies above Ψ(t) =
146"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.38204592901878914,"1t>p—which will allow us to develop deep connections between the theoretical and computational
147"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.38413361169102295,"aspects of probabilistically robust learning. Our relaxation using the function Ψ is very similar to
148"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.3862212943632568,"the one by Raman et al. [2023] who proved PAC learnability if Ψ is Lipschitz, see Appendix A.6 for
149"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.3883089770354906,"more details. In order to rigorously study ProbRΨ we first make our setting precise.
150"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.3903966597077244,"Assumption 1. We let X be a set and A ⊂2X be a σ-algebra. We assume that:
151"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.3924843423799583,"• (X × Y, A ⊗2{0,1}, µ) is a probability space;
152"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.3945720250521921,"• (X, A, ρ) is a probability space, where we define ρ(•) := µ(• × {0, 1});
153"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.3966597077244259,"• {px}x∈X is a family such that (X, A, px) is a probability space for ρ-almost every x ∈X.
154"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.3987473903966597,"The following theorem establishes existence of minimizers of the risk ProbRΨ for concave and
155"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.40083507306889354,"non-decreasing functions Ψ. This existence result is astonishing since the standard method of
156"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.40292275574112735,"calculus of variations is not directly applicable, with the reason being that problem (15) does not
157"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.40501043841336115,"provide enough compactness for lower semicontinuity of the perimeter functional ProbPerΨ. Instead,
158"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.407098121085595,"the proof is based on convex relaxations to soft classifiers where we use a lower semicontinuous
159"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.4091858037578288,"surrogate functional and a total variation defined through a coarea formula which—if Ψ is concave
160"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.4112734864300626,"and non-decreasing—lower-bounds the surrogate.
161"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.4133611691022965,"Theorem 2. Suppose Ψ : [0, 1] →[0, 1] is concave and non-decreasing, and that Assumption 1
162"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.4154488517745303,"holds. Then, there exists a solution to the problem
163"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.4175365344467641,"inf
A∈A ProbRΨ(A).
(15)"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.4196242171189979,"Furthermore, ProbRΨ can also be interpreted as a sample-wise maximum, analogous to Theorem 1.
164"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.42171189979123175,"Theorem 3. For all A ∈A and measurable Ψ : [0, 1] →[0, 1] it holds
165"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.42379958246346555,ProbRΨ(A) = Rstd(A) + ProbPerΨ(A)
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.42588726513569936,"= E(x,y)∼µ

max

Ψ (Px′∼px [1A(x′) ̸= y]) , 11A(x)̸=y
	
."
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.4279749478079332,"Note that for the non-concave function Ψ(t) = 1t>p an existence proof along the lines of Theorem 2
166"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.430062630480167,"is not available since certain relaxation techniques therein rely on concavity of Ψ. However, in the
167"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.4321503131524008,"next section we shall provide an existence theorem for soft classifiers which is valid for very general
168"
EXTENSIONS IN THE BINARY CLASSIFICATION SETTING,0.4342379958246347,"functions Ψ, including Ψ(t) = 1t>p.
169"
EXTENSION TO SOFT CLASSIFIERS,0.4363256784968685,"2.3
Extension to soft classifiers
170"
EXTENSION TO SOFT CLASSIFIERS,0.4384133611691023,"Another natural extension features “soft classifiers” instead of indicator functions of admissible
171"
EXTENSION TO SOFT CLASSIFIERS,0.4405010438413361,"sets. Such classifiers are particularly relevant since they include the neural network based models
172"
EXTENSION TO SOFT CLASSIFIERS,0.44258872651356995,"with Softmax activation in the last layer which are used in practice. We start by defining a suitable
173"
EXTENSION TO SOFT CLASSIFIERS,0.44467640918580376,"regularization functional for soft classifiers. Given a A-measurable function u : X →[0, 1] we define
174"
EXTENSION TO SOFT CLASSIFIERS,0.44676409185803756,"JΨ(u) :=
Z"
EXTENSION TO SOFT CLASSIFIERS,0.4488517745302714,"X
(1 −u(x)) Ψ (Ex′∼px [u(x′)]) dρ0(x) +
Z"
EXTENSION TO SOFT CLASSIFIERS,0.4509394572025052,"X
u(x)Ψ (Ex′∼px [1 −u(x′)]) dρ1(x)
(16)"
EXTENSION TO SOFT CLASSIFIERS,0.453027139874739,"which satisfies JΨ(1A) = ProbPerΨ(A) for every choice of Ψ. Hence, it is a natural generalization
175"
EXTENSION TO SOFT CLASSIFIERS,0.4551148225469729,"of the perimeter to soft classifiers and one could call JΨ a total variation. However, it is neither
176"
EXTENSION TO SOFT CLASSIFIERS,0.4572025052192067,"positively homogeneous nor convex so this name would be misleading. Instead, for the proof of
177"
EXTENSION TO SOFT CLASSIFIERS,0.4592901878914405,"Theorem 2 we shall construct a suitable total variation functional ProbTVΨ which upper-bounds JΨ.
178"
EXTENSION TO SOFT CLASSIFIERS,0.4613778705636743,"The next theorem asserts existence of soft classifiers for the regularized risk minimization using JΨ for
179"
EXTENSION TO SOFT CLASSIFIERS,0.46346555323590816,"very general functions Ψ and hypothesis classes H, requiring only that Ψ be lower semicontinuous.
180"
EXTENSION TO SOFT CLASSIFIERS,0.46555323590814196,"For example, every continuous function and also Ψ(t) = 1t>p for p ∈[0, 1] satisfies this. The
181"
EXTENSION TO SOFT CLASSIFIERS,0.46764091858037576,"existence theorem is valid for all hypotheses classes which are closed in a suitable sense.
182"
EXTENSION TO SOFT CLASSIFIERS,0.4697286012526096,"Theorem 4. Under Assumption 1, for every lower semicontinuous function Ψ : [0, 1] →[0, 1], and
183"
EXTENSION TO SOFT CLASSIFIERS,0.4718162839248434,"whenever H is a weak-* closed hypothesis class of A-measurable functions u : X →[0, 1] in the
184"
EXTENSION TO SOFT CLASSIFIERS,0.47390396659707723,"sense of Definition 1 in the appendix, there exists a solution to the problem
185"
EXTENSION TO SOFT CLASSIFIERS,0.4759916492693111,"inf
u∈H E(x,y)∼µ [|u(x) −y|] + JΨ(u)."
EXTENSION TO SOFT CLASSIFIERS,0.4780793319415449,"Example 1. Let us consider three interesting hypothesis classes of weak-* closed classifiers for
186"
EXTENSION TO SOFT CLASSIFIERS,0.4801670146137787,"which Theorem 4 applies. More detailed explanations are given in Appendix A.8.
187"
EXTENSION TO SOFT CLASSIFIERS,0.4822546972860125,"1. The simplest such class H is the class of all A-measurable soft classifiers u : X →[0, 1]
188"
EXTENSION TO SOFT CLASSIFIERS,0.48434237995824636,"which could be referred to as agnostic classifiers since they are not parametrized.
189"
EXTENSION TO SOFT CLASSIFIERS,0.48643006263048016,"2. An example with more practical relevance is the class of (feedforward or residual) neural
190"
EXTENSION TO SOFT CLASSIFIERS,0.48851774530271397,"networks defined on the unit cube X := [−1, 1]d with uniformly bounded parameters
191"
EXTENSION TO SOFT CLASSIFIERS,0.4906054279749478,"H :=
n
ΦL ◦· · · ◦Φ1 : [−1, 1]d →[0, 1] : Φl(•) = Al • +σl(Wl • +bl),"
EXTENSION TO SOFT CLASSIFIERS,0.49269311064718163,"∥(Al, Wl, bl)∥≤C ∀l ∈{1, . . . , L}
o
,"
EXTENSION TO SOFT CLASSIFIERS,0.49478079331941544,"where we assume that the activations σl : R →R are continuous. Note that the boundedness
192"
EXTENSION TO SOFT CLASSIFIERS,0.4968684759916493,"of the weights cannot be relaxed. To see this, consider the (very simplistic) neural network
193"
EXTENSION TO SOFT CLASSIFIERS,0.4989561586638831,"un(x) = tanh(wnx) for x ∈[−1, 1] and wn ∈R. For wn →∞it is easy to see that un
194"
EXTENSION TO SOFT CLASSIFIERS,0.5010438413361169,"converges to u(x) := sign(x) which does not lie in the same hypothesis class.
195"
EXTENSION TO SOFT CLASSIFIERS,0.5031315240083507,"3. Finally, one can also consider the class of hard linear classifiers on Rd. Letting θ(t) := 1t>0
196"
EXTENSION TO SOFT CLASSIFIERS,0.5052192066805845,"denote the Heaviside function, this class is given by
197"
EXTENSION TO SOFT CLASSIFIERS,0.5073068893528184,"H :=

θ(w · x + b) : w ∈Rd, |w| = 1, b ∈[−∞, ∞]
	
,"
EXTENSION TO SOFT CLASSIFIERS,0.5093945720250522,"where one interprets u(x) := θ(w · x + b) as u ≡1 if b = ∞and u ≡0 if b = −∞. If the
198"
EXTENSION TO SOFT CLASSIFIERS,0.511482254697286,"distributions ρ0, ρ1, and px are sufficiently nice, then H has the desired closedness property.
199"
EXTENSION TO SOFT CLASSIFIERS,0.5135699373695198,"2.4
Properties and asymptotics of ProbPerΨ
200"
EXTENSION TO SOFT CLASSIFIERS,0.5156576200417536,"In this section we shall discuss the interpretation of the functional ProbPerΨ defined in (13) as a
201"
EXTENSION TO SOFT CLASSIFIERS,0.5177453027139874,"perimeter. We do this in two ways.
202"
EXTENSION TO SOFT CLASSIFIERS,0.5198329853862212,"First, we focus on the case where Ψ is concave and non-decreasing and prove that ProbPerΨ is a
203"
EXTENSION TO SOFT CLASSIFIERS,0.5219206680584552,"submodular functional. If, in addition, Ψ is assumed to satisfy Ψ(0) = 0, then ProbPerΨ(X) =
204"
EXTENSION TO SOFT CLASSIFIERS,0.524008350730689,"ProbPerΨ(∅) = 0. Following Chambolle et al. [2015], for Ψ satisfying these properties one can
205"
EXTENSION TO SOFT CLASSIFIERS,0.5260960334029228,"interpret ProbPerΨ as a generalized perimeter, i.e., a functional that can be used to measure the
206"
EXTENSION TO SOFT CLASSIFIERS,0.5281837160751566,"“size” of the boundary of a set. In Appendix A.3 we introduce ProbPerΨ’s induced (generalized)
207"
EXTENSION TO SOFT CLASSIFIERS,0.5302713987473904,"total variation and use it in the proof of Theorem 2; note that, as discussed by Bungert et al. [2023],
208"
EXTENSION TO SOFT CLASSIFIERS,0.5323590814196242,"the adversarial problem (5) also induces a generalized perimeter with associated total variation.
209"
EXTENSION TO SOFT CLASSIFIERS,0.534446764091858,"Theorem 5. If Ψ(0) = 0, then ProbPerΨ(X) = ProbPerΨ(∅) = 0. If Ψ is concave and non-
210"
EXTENSION TO SOFT CLASSIFIERS,0.5365344467640919,"decreasing, then the functional ProbPerΨ is submodular, meaning that
211"
EXTENSION TO SOFT CLASSIFIERS,0.5386221294363257,"ProbPerΨ(A ∪B) + ProbPerΨ(A ∩B) ≤ProbPerΨ(A) + ProbPerΨ(B)
∀A, B ∈A.
Example 2. For Ψ(t) = t our perimeter reduces to the perimeter on the random walk space (X, p),
212"
EXTENSION TO SOFT CLASSIFIERS,0.5407098121085595,"introduced by Mazón et al. [2020]: ProbPerΨ(A) =
R X\A
R"
EXTENSION TO SOFT CLASSIFIERS,0.5427974947807933,"A dpx dρ0(x) +
R A
R"
EXTENSION TO SOFT CLASSIFIERS,0.5448851774530271,"X\A dpx dρ1(x).
213"
EXTENSION TO SOFT CLASSIFIERS,0.5469728601252609,"Second, we consider more general Ψ and show that ProbPerΨ is related to a standard local perimeter
214"
EXTENSION TO SOFT CLASSIFIERS,0.5490605427974948,"when the adversarial budget approaches zero; for the case of adversarial training such a connection was
215"
EXTENSION TO SOFT CLASSIFIERS,0.5511482254697286,"proved by Bungert and Stinson [2022] where the authors utilized the notion of Gamma-convergence
216"
EXTENSION TO SOFT CLASSIFIERS,0.5532359081419624,"of functionals. We take a first step in this direction by proving that for sufficiently smooth sets the
217"
EXTENSION TO SOFT CLASSIFIERS,0.5553235908141962,"probabilistic perimeter converges to a local one if the family of probability distributions px localizes
218"
EXTENSION TO SOFT CLASSIFIERS,0.55741127348643,"suitably. For example, one could think of px := Unif(Bε(x)), which converges to a point mass at x
219"
EXTENSION TO SOFT CLASSIFIERS,0.5594989561586639,"if ε →0. To make our setting precise, we pose the following general assumption:
220"
EXTENSION TO SOFT CLASSIFIERS,0.5615866388308977,"Assumption 2. We assume that X = Rd, Ψ(0) = 0, Ψ is measurable and bounded, and ρ1, ρ0 have
221"
EXTENSION TO SOFT CLASSIFIERS,0.5636743215031316,"continuous densities with respect to the Lebesgue measure which we shall also denote as ρ1, ρ0.
222"
EXTENSION TO SOFT CLASSIFIERS,0.5657620041753654,"Furthermore, we assume that there is ε > 0 and a measurable function K : X × Rd →[0, ∞) such
223"
EXTENSION TO SOFT CLASSIFIERS,0.5678496868475992,"that for every x ∈Rd we have the representation
224"
EXTENSION TO SOFT CLASSIFIERS,0.569937369519833,"dpx(x′) = ε−dK

x, x′ −x ε"
EXTENSION TO SOFT CLASSIFIERS,0.5720250521920668,"
dx′."
EXTENSION TO SOFT CLASSIFIERS,0.5741127348643006,"We also assume that for every x ∈X we have K(x, •) ∈L1(Rd),
R"
EXTENSION TO SOFT CLASSIFIERS,0.5762004175365344,"Rd K(x, z) dz = 1, and
225"
EXTENSION TO SOFT CLASSIFIERS,0.5782881002087683,"K(x, z) = 0 if |z| > 1, and that for every z ∈Rd the mapping x 7→K(x, z) is C1.
226"
EXTENSION TO SOFT CLASSIFIERS,0.5803757828810021,"Proposition 1. Under Assumption 2, if A has a compact C1,1 boundary and either Ψ is continuous
227"
EXTENSION TO SOFT CLASSIFIERS,0.5824634655532359,"or there exists a constant c > 0 such that K(x, z) ≥c for all x ∈X and |z| ≤1, then
228"
EXTENSION TO SOFT CLASSIFIERS,0.5845511482254697,"lim
ε→0
1
ε ProbPerΨ(A) =
Z"
EXTENSION TO SOFT CLASSIFIERS,0.5866388308977035,"∂A
σ0,Ψ [x, n(x)] ρ0(x) + σ1,Ψ [x, n(x)] ρ1(x) dHd−1(x)
(17)"
EXTENSION TO SOFT CLASSIFIERS,0.5887265135699373,"where we let n(x) denote the normal to ∂A at a point x ∈∂A, and for any vector v ∈Rd we define
229"
EXTENSION TO SOFT CLASSIFIERS,0.5908141962421712,"σ0
Ψ [x, v] :=
Z 1 0
Ψ Z"
EXTENSION TO SOFT CLASSIFIERS,0.592901878914405,"{z·v≤−t}
K(x, z) dz !"
EXTENSION TO SOFT CLASSIFIERS,0.5949895615866388,"dt,
σ1
Ψ [x, v] :=
Z 1 0
Ψ Z"
EXTENSION TO SOFT CLASSIFIERS,0.5970772442588727,"{z·v≥t}
K(x, z) dz ! dt."
EXTENSION TO SOFT CLASSIFIERS,0.5991649269311065,"Remark 1. If K is radially symmetric and independent of x ∈X, then σ0
Ψ = σ1
Ψ =: σΨ is just a
230"
EXTENSION TO SOFT CLASSIFIERS,0.6012526096033403,"constant. E.g., for K(x, z) := |B1(0)|−1 1|z|≤1 and Ψ(t) = 1t>p it is trivial that for p = 0 we have
231"
EXTENSION TO SOFT CLASSIFIERS,0.6033402922755741,"σΨ = 1. However, for p ≥1"
EXTENSION TO SOFT CLASSIFIERS,0.605427974947808,"2 one easily sees σΨ = 0, hence the limiting perimeter equals zero and
232"
EXTENSION TO SOFT CLASSIFIERS,0.6075156576200418,"there is no regularization effect. Using the function Ψ(t) = min {t/p, 1} corrects this degeneracy.
233"
EXTENSION TO SOFT CLASSIFIERS,0.6096033402922756,"Notably, for radially symmetric K the limiting perimeter in (17) coincides, provided σΨ > 0, with
234"
EXTENSION TO SOFT CLASSIFIERS,0.6116910229645094,"the one derived for adversarial training (problem (5)) by Bungert and Stinson [2022], although they
235"
EXTENSION TO SOFT CLASSIFIERS,0.6137787056367432,"considered more general (potentially discontinuous) densities ρi. In particular, our result indicates
236"
EXTENSION TO SOFT CLASSIFIERS,0.615866388308977,"that for very small adversarial budgets the regularization effect of both probabilistically robust
237"
EXTENSION TO SOFT CLASSIFIERS,0.6179540709812108,"learning and adversarial training is dominated by the perimeter in (17). While Proposition 1 already
238"
EXTENSION TO SOFT CLASSIFIERS,0.6200417536534447,completes half of the proof (namely the limsup inequality) of Gamma-convergence of 1
EXTENSION TO SOFT CLASSIFIERS,0.6221294363256785,"ε ProbPerΨ
239"
EXTENSION TO SOFT CLASSIFIERS,0.6242171189979123,"to the limiting perimeter, the remaining liminf inequality is beyond the scope of this paper. Proving
240"
EXTENSION TO SOFT CLASSIFIERS,0.6263048016701461,"that the convergence (17) does not only hold for sufficiently smooth sets as assumed in Proposition 1
241"
EXTENSION TO SOFT CLASSIFIERS,0.6283924843423799,"but even in the sense of Gamma-convergence is an extremely important topic for future work since
242"
EXTENSION TO SOFT CLASSIFIERS,0.6304801670146137,"only Gamma-convergence allows to deduce from the convergence of the perimeters that also the
243"
EXTENSION TO SOFT CLASSIFIERS,0.6325678496868476,"solutions of probabilistically robust learning converge to certain regular Bayes classifiers as ε →0,
244"
EXTENSION TO SOFT CLASSIFIERS,0.6346555323590815,"see Bungert and Stinson [2022, Section 4.2].
245"
GENERAL MODELS,0.6367432150313153,"3
General models
246"
GENERAL MODELS,0.6388308977035491,"We now shift our attention to training general hypotheses h ∈H using general loss functions
247"
GENERAL MODELS,0.6409185803757829,"ℓ: Y × Y →R. Motivated by Theorems 1 and 3 we propose the following probabilistically robust
248"
GENERAL MODELS,0.6430062630480167,"optimization problem:
249"
GENERAL MODELS,0.6450939457202505,"inf
h∈H E(x,y)∼µ"
GENERAL MODELS,0.6471816283924844,"
max

p- ess sup
x′∼px
ℓ(h(x′), y), ℓ(h(x), y)

.
(18)"
GENERAL MODELS,0.6492693110647182,"In the mathematical finance or economics literature the p-ess sup operator is better known as the value
250"
GENERAL MODELS,0.651356993736952,"at risk (VaR) of a random variable at level p and it is notoriously hard to optimize. VaR is closely
251"
GENERAL MODELS,0.6534446764091858,"related to other risk measures like, for instance, the conditional value at risk (CVaR) which is convex
252"
GENERAL MODELS,0.6555323590814196,"and easier to optimize [Robey et al., 2022, Rockafellar et al., 2000]. For a function f : X →R and a
253"
GENERAL MODELS,0.6576200417536534,"probability distribution p the CVaR at level p is defined as
254"
GENERAL MODELS,0.6597077244258872,"CVaRp(f; p) := inf
α∈R α + Ex′∼px

(f(x′) −α)+
"
GENERAL MODELS,0.6617954070981211,"p
.
(19)"
GENERAL MODELS,0.6638830897703549,"It is easy to see that p- ess supx′∼p f(x′) ≤CVaRp(f; p). Using CVaR in place of the p- ess sup
255"
GENERAL MODELS,0.6659707724425887,"operator, a tractable version of (18) is
256"
GENERAL MODELS,0.6680584551148225,"inf
h∈H E(x,y)∼µ
h
max
n
CVaRp(ℓ(h(•), y); px), ℓ(h(x), y)
oi
.
(20)"
GENERAL MODELS,0.6701461377870563,"We emphasize that, if the loss function ℓ(•, •) is convex in its first argument, then (20) is a convex
257"
GENERAL MODELS,0.6722338204592901,"function of the hypothesis h. Furthermore, CVaR is positively homogeneous and hence also (20) is
258"
GENERAL MODELS,0.6743215031315241,"positively homogeneous in the loss function. So, taking the maximum of the samplewise CVaR and
259"
GENERAL MODELS,0.6764091858037579,"standard risk is meaningful as both terms scale in the same way.
260"
GENERAL MODELS,0.6784968684759917,"In the binary classification case we can prove the following interesting result that the CVaR relax-
261"
GENERAL MODELS,0.6805845511482255,"ation corresponds precisely to using the risk ProbRΨ with a special piecewise linear and concave
262"
GENERAL MODELS,0.6826722338204593,"function Ψ for which our theory from Section 2.2 applies. In Appendix A.5 we prove a more general
263"
GENERAL MODELS,0.6847599164926931,"version of the following statement, replacing the [ • ]+ operation in (19) with a Leaky ReLU.
264"
GENERAL MODELS,0.6868475991649269,"Theorem 6. Let the function Ψp : [0, 1] →[0, 1] be defined as Ψp(t) := min {t/p, 1}. Then it holds
265"
GENERAL MODELS,0.6889352818371608,"CVaRp
 
11A(•)̸=y; p

= Ψp (Px′∼p [1A(x′) ̸= y])"
GENERAL MODELS,0.6910229645093946,"and as a consequence for all A ∈A:
266"
GENERAL MODELS,0.6931106471816284,"E(x,y)∼µ
h
max
n
CVaRp(11A(•)̸=y; px), 11A(x)̸=y
oi
= ProbRΨp(A)."
GENERAL MODELS,0.6951983298538622,"An immediate consequence of Theorem 6 is that for binary classification (20) has a solution.
267"
GENERAL MODELS,0.697286012526096,"Corollary 1. Under Assumption 1 and in the setting of Theorem 6 problem (20) has a solution.
268"
GENERAL MODELS,0.6993736951983298,"In Appendix A.5 we collect a few more observations concerning the CVaR, especially focussing on
269"
GENERAL MODELS,0.7014613778705637,"its behavior for p > 1. These geometric properties, the homogeneity with respect to the loss function,
270"
GENERAL MODELS,0.7035490605427975,"its potentially favorable sample complexity (see the discussion in Appendix A.6), and its versatility
271"
GENERAL MODELS,0.7056367432150313,"for algorithmic implementation make (20) a notable generalization of the adversarial training problem
272"
GENERAL MODELS,0.7077244258872651,"(2). Notice that when p →0 one formally recovers (2) from (20).
273"
NUMERICAL RESULTS,0.7098121085594989,"4
Numerical results
274"
NUMERICAL RESULTS,0.7118997912317327,"We build upon the code of Robey et al. [2022]. The algorithmic realization of (20) is a straightforward
275"
NUMERICAL RESULTS,0.7139874739039666,"adaptation of their algorithm, which alternatingly minimizes the inner optimization problem that
276"
NUMERICAL RESULTS,0.7160751565762005,"defines CVaR and the outer optimization to find a suitable classifier, see Algorithm 1 in Appendix B.
277"
NUMERICAL RESULTS,0.7181628392484343,"In our experiments, we conduct a comparative analysis between their algorithm (denoted as “Original”
278"
NUMERICAL RESULTS,0.7202505219206681,"in Table 1) and Algorithm 1 in the appendix which is based on (20) (denoted as “Geometric”).
279"
NUMERICAL RESULTS,0.7223382045929019,"We report the clean, and adversarial accuracies (subject to PGD attacks), as well as accuracies on
280"
NUMERICAL RESULTS,0.7244258872651357,"noise-augmented data and quantile accuracies for different values of p (see [Robey et al., 2022,
281"
NUMERICAL RESULTS,0.7265135699373695,"(6.1)] for the definition) averaged over three runs; see Appendix B.2 for more training details. Our
282"
NUMERICAL RESULTS,0.7286012526096033,"experiments are conducted on MNIST and CIFAR-10 and to ensure a fair comparison we adhere to the
283"
NUMERICAL RESULTS,0.7306889352818372,"hyperparameter settings described by Robey et al. [2022], such that both the original and geometric
284"
NUMERICAL RESULTS,0.732776617954071,"algorithms utilize the same set of hyperparameters for each specified value of p. The corresponding
285"
NUMERICAL RESULTS,0.7348643006263048,"results for several baseline algorithms including empirical risk minimization and adversarial training
286"
NUMERICAL RESULTS,0.7369519832985386,"can be found in their paper. We perform model selection based on the best clean validation accuracy.
287"
NUMERICAL RESULTS,0.7390396659707724,"The results in Table 1 show that for moderate values of p our geometric modification induces higher
288"
NUMERICAL RESULTS,0.7411273486430062,"adversarial robustness than the original PRL without loss of clean accuracy (see, in particular, the
289"
NUMERICAL RESULTS,0.7432150313152401,"results for MNIST with p = 0.1 and for CIFAR-10 with p = 0.3). In the noise augmented metrics as
290"
NUMERICAL RESULTS,0.7453027139874739,"well as for extreme values of p close to 0 or equal to 0.5 both algorithms behave comparably. The
291"
NUMERICAL RESULTS,0.7473903966597077,"latter can be expected from out theoretical results, in particular Proposition 1.
292"
NUMERICAL RESULTS,0.7494780793319415,"Note that the original or the geometric version of PRL should not be expected to match the adversarial
293"
NUMERICAL RESULTS,0.7515657620041754,"robustness of classifiers trained with PGD attacks [Madry et al., 2017] or other worst-case optimization
294"
NUMERICAL RESULTS,0.7536534446764092,"techniques. Instead, they shine with superior clean accuracies and easier training while maintaining
295"
NUMERICAL RESULTS,0.755741127348643,"probabilistic and a certain degree of adversarial robustness, as also observed by Robey et al. [2022].
296"
NUMERICAL RESULTS,0.7578288100208769,"We also remark that our sweep over different values of p confirms that increasing this parameter
297"
NUMERICAL RESULTS,0.7599164926931107,"interpolates between low and high clean accuracies. However, it should be noted that it does not
298"
NUMERICAL RESULTS,0.7620041753653445,"necessarily result in a direct interpolation between high and low adversarial or probabilistic accuracy,
299"
NUMERICAL RESULTS,0.7640918580375783,"as claimed by Robey et al. [2022]. These observations hold true for both the original algorithm and
300"
NUMERICAL RESULTS,0.7661795407098121,"our geometric modification, and despite utilizing their code and hyperparameters, we were unable to
301"
NUMERICAL RESULTS,0.7682672233820459,"reproduce the exact results reported by Robey et al. [2022, Tables 1-4].
302"
NUMERICAL RESULTS,0.7703549060542797,"Table 1: Accuracies [%] of the geometric and original algorithm for different values of p.
Data
p
Algorithm
Clean
Adv
Aug
Aug-0.1
Aug-0.05
Aug-0.01 MNIST"
GEOMETRIC,0.7724425887265136,"0.01
Geometric
99.20
12.19
99.04
98.18
97.69
96.38
Original
99.19
10.76
98.90
97.94
97.38
95.67"
GEOMETRIC,0.7745302713987474,"0.1
Geometric
99.28
14.20
99.22
98.70
98.45
97.86
Original
99.32
8.94
99.22
98.70
98.46
97.80"
GEOMETRIC,0.7766179540709812,"0.3
Geometric
99.29
3.02
99.21
98.76
98.53
97.95
Original
99.27
3.02
99.22
98.77
98.55
98.01"
GEOMETRIC,0.778705636743215,"0.5
Geometric
99.27
1.80
99.21
98.72
98.44
97.93
Original
99.26
1.68
99.19
98.72
98.47
97.80"
GEOMETRIC,0.7807933194154488,CIFAR-10
GEOMETRIC,0.7828810020876826,"0.01
Geometric
80.65
0.15
78.13
73.44
72.13
68.80
Original
81.73
0.24
79.16
74.61
73.19
69.96"
GEOMETRIC,0.7849686847599165,"0.1
Geometric
88.15
0.14
85.96
82.55
81.46
78.81
Original
88.28
0.19
85.61
82.21
81.06
78.28"
GEOMETRIC,0.7870563674321504,"0.3
Geometric
90.43
11.80
88.70
85.17
83.93
80.93
Original
89.97
7.20
88.62
85.07
83.75
80.87"
GEOMETRIC,0.7891440501043842,"0.5
Geometric
91.51
1.93
88.94
85.53
84.18
81.21
Original
90.74
1.99
88.94
85.54
84.35
81.57"
DISCUSSION AND CONCLUSION,0.791231732776618,"5
Discussion and Conclusion
303"
DISCUSSION AND CONCLUSION,0.7933194154488518,"In this paper we considered probabilistically robust learning (PRL), originally proposed by Robey
304"
DISCUSSION AND CONCLUSION,0.7954070981210856,"et al. [2022]. We corrected a subtle but crucial theoretical flaw in the original formulation by
305"
DISCUSSION AND CONCLUSION,0.7974947807933194,"introducing a regularization of the standard risk with nonlocal perimeters measuring the susceptibility
306"
DISCUSSION AND CONCLUSION,0.7995824634655533,"of the decision boundary towards high-probability adversarial attacks. For binary classification we
307"
DISCUSSION AND CONCLUSION,0.8016701461377871,"proved existence of optimal hard classifiers and of very general classes of soft classifiers including
308"
DISCUSSION AND CONCLUSION,0.8037578288100209,"neural networks. We also provided an asymptotic expansion for smooth decision boundaries to
309"
DISCUSSION AND CONCLUSION,0.8058455114822547,"show that for small adversarial budgets the probabilistic perimeters discussed in the paper induce the
310"
DISCUSSION AND CONCLUSION,0.8079331941544885,"same regularization effect as adversarial training. For general (not necessarily binary) problems we
311"
DISCUSSION AND CONCLUSION,0.8100208768267223,"showed that the natural loss function to choose is the sample-wise maximum of the standard loss and
312"
DISCUSSION AND CONCLUSION,0.8121085594989561,"conditional value at risk (CVaR).
313"
DISCUSSION AND CONCLUSION,0.81419624217119,"One limitation of PRL is that it does not completely solve the accuracy vs. robustness trade-off,
314"
DISCUSSION AND CONCLUSION,0.8162839248434238,"which remains a challenging problem. Furthermore, while the formal limit of PRL as p →0 is the
315"
DISCUSSION AND CONCLUSION,0.8183716075156576,"worst-case adversarial problem, the algorithms for solving PRL exhibit limitations for very small
316"
DISCUSSION AND CONCLUSION,0.8204592901878914,"values of p (in the computation of CVaRp). Still, the results for moderately large values of p are
317"
DISCUSSION AND CONCLUSION,0.8225469728601252,"encouraging and future work should focus on understanding of this trade-off better.
318"
DISCUSSION AND CONCLUSION,0.824634655532359,"The rich mathematical theory developed in this paper opens up new avenues for research, such as the
319"
DISCUSSION AND CONCLUSION,0.826722338204593,"explicit design of probabilistic regularizers for algorithms and exploring the variational convergence
320"
DISCUSSION AND CONCLUSION,0.8288100208768268,"of the probabilistic perimeter and its implications for adversarial robustness.
321"
REFERENCES,0.8308977035490606,"References
322"
REFERENCES,0.8329853862212944,"Maksym Andriushchenko and Nicolas Flammarion. Understanding and improving fast adversarial
323"
REFERENCES,0.8350730688935282,"training. Advances in Neural Information Processing Systems, 33:16048–16059, 2020.
324"
REFERENCES,0.837160751565762,"Pranjal Awasthi, Natalie S Frank, and Mehryar Mohri. On the existence of the adversarial Bayes
325"
REFERENCES,0.8392484342379958,"classifier. Advances in Neural Information Processing Systems, 34:2978–2990, 2021a.
326"
REFERENCES,0.8413361169102297,"Pranjal Awasthi, Natalie S Frank, and Mehryar Mohri. On the existence of the adversarial Bayes
327"
REFERENCES,0.8434237995824635,"classifier (extended version). arXiv preprint arXiv:2112.01694, 2021b.
328"
REFERENCES,0.8455114822546973,"Leon Bungert and Kerrek Stinson. Gamma-convergence of a nonlocal perimeter arising in adversarial
329"
REFERENCES,0.8475991649269311,"machine learning. arXiv preprint arXiv:2211.15223, 2022.
330"
REFERENCES,0.8496868475991649,"Leon Bungert, Nicolás García Trillos, and Ryan Murray. The geometry of adversarial training in
331"
REFERENCES,0.8517745302713987,"binary classification. Information and Inference: A Journal of the IMA, 12(2):921–968, 06 2023.
332"
REFERENCES,0.8538622129436325,"ISSN 2049-8772. doi: 10.1093/imaiai/iaac029.
333"
REFERENCES,0.8559498956158664,"HanQin Cai, Yuchen Lou, Daniel McKenzie, and Wotao Yin. A zeroth-order block coordinate
334"
REFERENCES,0.8580375782881002,"descent algorithm for huge-scale black-box optimization. In International Conference on Machine
335"
REFERENCES,0.860125260960334,"Learning, pages 1193–1203. PMLR, 2021.
336"
REFERENCES,0.8622129436325678,"Antonin Chambolle, Massimiliano Morini, and Marcello Ponsiglione. Nonlocal curvature flows.
337"
REFERENCES,0.8643006263048016,"Archive for Rational Mechanics and Analysis, 218:1263–1329, 2015.
338"
REFERENCES,0.8663883089770354,"Pin-Yu Chen, Huan Zhang, Yash Sharma, Jinfeng Yi, and Cho-Jui Hsieh. ZOO: Zeroth order
339"
REFERENCES,0.8684759916492694,"optimization based black-box attacks to deep neural networks without training substitute models.
340"
REFERENCES,0.8705636743215032,"In Proceedings of the 10th ACM workshop on artificial intelligence and security, pages 15–26,
341"
REFERENCES,0.872651356993737,"2017.
342"
REFERENCES,0.8747390396659708,"Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. Certified adversarial robustness via randomized
343"
REFERENCES,0.8768267223382046,"smoothing. In international conference on machine learning, pages 1310–1320. PMLR, 2019.
344"
REFERENCES,0.8789144050104384,"Nelson Dunford and Jacob T Schwartz. Linear Operators: General theory. Linear Operators.
345"
REFERENCES,0.8810020876826722,"Interscience Publishers, 1958. ISBN 9780470226056.
346"
REFERENCES,0.8830897703549061,"Natalie S Frank. Existence and minimax theorems for adversarial surrogate risks in binary classifica-
347"
REFERENCES,0.8851774530271399,"tion. arXiv preprint arXiv:2206.09098, 2022.
348"
REFERENCES,0.8872651356993737,"Natalie S Frank and Jonathan Niles-Weed.
The consistency of adversarial training for binary
349"
REFERENCES,0.8893528183716075,"classification. arXiv preprint arXiv:2206.09099, 2022.
350"
REFERENCES,0.8914405010438413,"Nicolás García Trillos and Ryan Murray. Adversarial classification: Necessary conditions and
351"
REFERENCES,0.8935281837160751,"geometric flows. Journal of Machine Learning Research, 23(187):1–38, 2022.
352"
REFERENCES,0.8956158663883089,"Nicolás García Trillos, Matt Jacobs, and Jakwang Kim. On the existence of solutions to adversarial
353"
REFERENCES,0.8977035490605428,"training in multiclass classification. arXiv preprint arXiv:2305.00075, 2023.
354"
REFERENCES,0.8997912317327766,"Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
355"
REFERENCES,0.9018789144050104,"examples. arXiv preprint arXiv:1412.6572, 2014.
356"
REFERENCES,0.9039665970772442,"Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul
357"
REFERENCES,0.906054279749478,"Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et al. The many faces of robustness: A critical
358"
REFERENCES,0.9081419624217119,"analysis of out-of-distribution generalization. In Proceedings of the IEEE/CVF International
359"
REFERENCES,0.9102296450939458,"Conference on Computer Vision, pages 8340–8349, 2021.
360"
REFERENCES,0.9123173277661796,"Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
361"
REFERENCES,0.9144050104384134,"Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083,
362"
REFERENCES,0.9164926931106472,"2017.
363"
REFERENCES,0.918580375782881,"José M Mazón, Marcos Solera, and Julián Toledo. The total variation flow in metric random walk
364"
REFERENCES,0.9206680584551148,"spaces. Calculus of Variations and Partial Differential Equations, 59:1–64, 2020.
365"
REFERENCES,0.9227557411273486,"Muni Sreenivas Pydi and Varun Jog. The many faces of adversarial risk. Advances in Neural
366"
REFERENCES,0.9248434237995825,"Information Processing Systems, 34:10000–10012, 2021.
367"
REFERENCES,0.9269311064718163,"Yao Qin, Nicholas Carlini, Garrison Cottrell, Ian Goodfellow, and Colin Raffel. Imperceptible, robust,
368"
REFERENCES,0.9290187891440501,"and targeted adversarial examples for automatic speech recognition. In International conference
369"
REFERENCES,0.9311064718162839,"on machine learning, pages 5231–5240. PMLR, 2019.
370"
REFERENCES,0.9331941544885177,"Joaquin Quinoñero Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D Lawrence. Dataset
371"
REFERENCES,0.9352818371607515,"shift in machine learning. Mit Press, 2008.
372"
REFERENCES,0.9373695198329853,"Vinod Raman, Unique Subedi, and Ambuj Tewari. On proper learnability between average- and
373"
REFERENCES,0.9394572025052192,"worst-case robustness. arXiv preprint arXiv:2211.05656, 2023.
374"
REFERENCES,0.941544885177453,"Alexander Robey, Luiz Chamon, George J Pappas, and Hamed Hassani. Probabilistically robust
375"
REFERENCES,0.9436325678496869,"learning: Balancing average and worst-case performance. In International Conference on Machine
376"
REFERENCES,0.9457202505219207,"Learning, pages 18667–18686. PMLR, 2022.
377"
REFERENCES,0.9478079331941545,"R Tyrrell Rockafellar, Stanislav Uryasev, et al. Optimization of conditional value-at-risk. Journal of
378"
REFERENCES,0.9498956158663883,"risk, 2:21–42, 2000.
379"
REFERENCES,0.9519832985386222,"Leo Schwinn, An Nguyen, René Raab, Leon Bungert, Daniel Tenbrinck, Dario Zanca, Martin Burger,
380"
REFERENCES,0.954070981210856,"and Bjoern Eskofier. Identifying untrustworthy predictions in neural networks by geometric
381"
REFERENCES,0.9561586638830898,"gradient analysis. In Uncertainty in Artificial Intelligence, pages 854–864. PMLR, 2021.
382"
REFERENCES,0.9582463465553236,"Leo Schwinn, Leon Bungert, An Nguyen, René Raab, Falk Pulsmeyer, Doina Precup, Björn Eskofier,
383"
REFERENCES,0.9603340292275574,"and Dario Zanca. Improving robustness against real-world and worst-case distribution shifts
384"
REFERENCES,0.9624217118997912,"through decision region quantification. In International Conference on Machine Learning, pages
385"
REFERENCES,0.964509394572025,"19434–19449. PMLR, 2022.
386"
REFERENCES,0.9665970772442589,"Ali Shafahi, Mahyar Najibi, Mohammad Amin Ghiasi, Zheng Xu, John Dickerson, Christoph Studer,
387"
REFERENCES,0.9686847599164927,"Larry S Davis, Gavin Taylor, and Tom Goldstein. Adversarial training for free! Advances in
388"
REFERENCES,0.9707724425887265,"Neural Information Processing Systems, 32, 2019.
389"
REFERENCES,0.9728601252609603,"Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and Aleksander Madry.
390"
REFERENCES,0.9749478079331941,"Robustness may be at odds with accuracy. arXiv preprint arXiv:1805.12152, 2018.
391"
REFERENCES,0.9770354906054279,"Vladimir Vapnik. The nature of statistical learning theory. Springer science & business media, 1999.
392"
REFERENCES,0.9791231732776617,"Bao Wang, Binjie Yuan, Zuoqiang Shi, and Stanley J Osher. EnResNet: ResNets ensemble via the
393"
REFERENCES,0.9812108559498957,"Feynman–Kac formalism for adversarial defense and beyond. SIAM Journal on Mathematics of
394"
REFERENCES,0.9832985386221295,"Data Science, 2(3):559–582, 2020.
395"
REFERENCES,0.9853862212943633,"Eric Wong, Leslie Rice, and J Zico Kolter. Fast is better than free: Revisiting adversarial training.
396"
REFERENCES,0.9874739039665971,"arXiv preprint arXiv:2001.03994, 2020.
397"
REFERENCES,0.9895615866388309,"Matthew D Zeiler. Adadelta: an adaptive learning rate method. arXiv preprint arXiv:1212.5701,
398"
REFERENCES,0.9916492693110647,"2012.
399"
REFERENCES,0.9937369519832986,"Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El Ghaoui, and Michael Jordan.
400"
REFERENCES,0.9958246346555324,"Theoretically principled trade-off between robustness and accuracy. In International conference on
401"
REFERENCES,0.9979123173277662,"machine learning, pages 7472–7482. PMLR, 2019.
402"
