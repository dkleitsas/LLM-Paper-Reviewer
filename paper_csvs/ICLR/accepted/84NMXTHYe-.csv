Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0033333333333333335,"A probabilistic classiﬁer with reliable predictive uncertainties i) ﬁts successfully
to the target domain data, ii) provides calibrated class probabilities in difﬁcult
regions of the target domain (e.g. class overlap), and iii) accurately identiﬁes
queries coming out of the target domain and rejects them. We introduce an original
combination of Evidential Deep Learning, Neural Processes, and Neural Turing
Machines capable of providing all three essential properties mentioned above for
total uncertainty quantiﬁcation. We observe our method on ﬁve classiﬁcation tasks
to be the only one that can excel all three aspects of total calibration with a single
standalone predictor. Our uniﬁed solution delivers an implementation-friendly and
compute efﬁcient recipe for safety clearance and provides intellectual economy to
an investigation of algorithmic roots of epistemic awareness in deep neural nets."
INTRODUCTION,0.006666666666666667,"1
INTRODUCTION"
INTRODUCTION,0.01,"The applicability of deep neural nets to safety-critical use cases such as autonomous driving or
medical diagnostics is an active matter of fundamental research (Schwalbe & Schels, 2020). Key
challenges in the development of total safety in deep learning are at least three-fold: i) evaluation of
model ﬁt, ii) risk assessment in difﬁcult regions of the target domain (e.g. class overlap) based on
which safety-preserving fallback functions can be deployed, and iii) rejection of inputs that do not
belong to the target domain, such as an image of a cat presented to a character recognition system.
The attention of the machine learning community to each of these critical safety elements is in steady
increase (Naeini et al., 2015; Guo et al., 2017; Kuleshov et al., 2018). However, the developments
often follow isolated directions and the proposed solutions are largely fragmented. Calibration of
neural net probabilities focuses primarily on post-hoc adjustment algorithms trained on validation
sets from in-domain data (Guo et al., 2017), ignoring the out-of-domain detection and model ﬁt
evaluation aspects. On the other hand, recent advances in out-of-domain detection build on strong
penalization of divergence from the probability mass observed in the target domain (Sensoy et al.,
2018; Malinin & Gales, 2018), distorting the quality of class probability scores. Such fragmentation
of best practices not only hinders their accessibility by real-world applications but also complicates
the scientiﬁc inquiry of the underlying reasons behind the sub-optimality of neural net uncertainties."
INTRODUCTION,0.013333333333333334,"We aim to identify the guiding principles for Bayesian modeling that could deliver the most complete
set of uncertainty quantiﬁcation capabilities in one single model. We ﬁrst characterize Bayesian
models with respect to the relationship of their global and local variables: (a) Parametric Bayesian
Models comprise a likelihood function that maps inputs to outputs via probabilistic global param-
eters, (b) Evidential Bayesian Models apply an uninformative prior distribution on the parameters
of the likelihood function and infer the prior hyperparameters by amortizing on an input observa-
tion. Investigating the decomposition of the predictive distribution variance, we ﬁnd out that the"
INTRODUCTION,0.016666666666666666,"∗Work done while at Heidelberg University, Germany."
INTRODUCTION,0.02,"Published as a conference paper at ICLR 2022 x y
θ"
INTRODUCTION,0.023333333333333334,"(x, y) ∈D"
INTRODUCTION,0.02666666666666667,"(a) Parametric Bayesian Model x
π y"
INTRODUCTION,0.03,"(x, y) ∈D"
INTRODUCTION,0.03333333333333333,"(b) Evidential Bayesian Model x
π y θ"
INTRODUCTION,0.03666666666666667,"(x, y) ∈D"
INTRODUCTION,0.04,(c) Complete Bayesian Model
INTRODUCTION,0.043333333333333335,"Figure 1: Plate diagrams of three main Bayesian modeling approaches. Shaded nodes are observed
and unshaded ones are latent. The solid direct arrows denote conditional dependencies in the true
model, while the bent dashed arrows denote amortization in variational inference."
INTRODUCTION,0.04666666666666667,"uncertainty characteristics of these two approaches exhibit complementary strengths. We introduce a
third approach that employs a prior on the likelihood parameters that both conditions on the input
observations on the true model and amortizes on them during inference. The mapping from the input
observations to the prior hyperparameters is governed by a random set of global parameters. We refer
to the resulting approach as a (c) Complete Bayesian Model, since its predictive distribution variance
combines the favorable properties of Parametric and Evidential Bayesian Models. Figure 1 gives an
overview of the relationship between these three Bayesian modeling approaches."
INTRODUCTION,0.05,"The advantages of the Complete Bayesian Models come with the challenge of choosing an input-
dependent prior. We introduce a new stochastic process construction that addresses this problem by
accumulating observations from a context set during training time into the parameters of a global
hyperprior variable by an explicitly designed update rule. We design the input-speciﬁc prior on
the likelihood parameters by conditioning it on both the hyperprior and the input observation. As
conditioning via explicit parameter updates amounts to maintaining an external memory that can
be queried by the prior distribution, we refer to the eventual stochastic process as a Turing Process
with inspiration from the earlier work on Neural Turing Machines (Graves et al., 2014) and Neural
Processes (Garnelo et al., 2018b). We arrive at our target Bayesian design that is equipped with the
complete set of uncertainty quantiﬁcation capabilities by incorporating the Turing Process design into
a Complete Bayesian Model. We refer to the resulting approach as an Evidential Turing Process. We
observe on ﬁve real-world classiﬁcation tasks that the Evidential Turing Process is the only model
that excels simultaneously at model ﬁt, class overlap quantiﬁcation, and out-of-domain detection."
INTRODUCTION,0.05333333333333334,"2
PROBLEM STATEMENT: TOTAL CALIBRATION"
INTRODUCTION,0.056666666666666664,Consider the following data generating process with K modes
INTRODUCTION,0.06,"y|π ∼Cat(y|π),
x|y ∼ K
X"
INTRODUCTION,0.06333333333333334,"k=1
Iy=kp(x|y = k),
(1)"
INTRODUCTION,0.06666666666666667,"where Cat(y|·) is a categorical distribution, Iu is the indicator function for predicate u, and p(x|y)
is the class-conditional density function on input observation x. For any prior class distribution π,
the classiﬁcation problem can be cast as identifying the class probabilities for observed patterns
Pr[y|x, π] = Cat(y|f π
true(x)) where f π
true(x) is a K−dimensional vector with the k-th element"
INTRODUCTION,0.07,"f π,k
true(x) = πkp(x|y = k)
. K
X"
INTRODUCTION,0.07333333333333333,"κ=1
πκp(x|y = κ).
(2)"
INTRODUCTION,0.07666666666666666,"In many real-world cases f π
true is not known and should be identiﬁed from a hypothesis space
hπ ∈Hπ via inference given a set of samples D = {(xn, yn)|n = 1, . . . , N} obtained from the true
distribution. The risk of the Bayes classiﬁer arg maxy Cat(y|hπ(x)) for a given input x is"
INTRODUCTION,0.08,"R(hπ(x)) = K
X"
INTRODUCTION,0.08333333333333333,"κ=1
Iκ̸=arg max hπ(x)f π,κ
true(x).
(3)"
INTRODUCTION,0.08666666666666667,Published as a conference paper at ICLR 2022
INTRODUCTION,0.09,"For the whole data distribution, we have R(hπ) = Ex|π[R(hπ(x))]. The optimal case is when
hπ(x) = f π
true(x), which brings about the irreducible Bayes risk resulting from class overlap:"
INTRODUCTION,0.09333333333333334,"R∗(f π
true(x)) = min
n
1 −max f π
true(x), max f π
true(x)
o
.
(4)"
INTRODUCTION,0.09666666666666666,"Total Calibration.
Given a set of test samples Dts coming from the true data generating process in
Eq. 1, we deﬁne Total Calibration as the capability of a discriminative predictor hπ(x) to quantify
the following three types of uncertainty simultaneously:"
INTRODUCTION,0.1,"i) Model misﬁt evaluated by the similarity of hπ(x) and f π
true(x) measurable directly via"
INTRODUCTION,0.10333333333333333,"KL
 
Cat(y|f π
true(x))p(x) || Cat(y|hπ(x))p(x)

="
INTRODUCTION,0.10666666666666667,"Ep(x) [log Cat(y|f π
true(x)] + Ep(x) [−log Cat(y|hπ(x))]"
INTRODUCTION,0.11,"where KL(·||·) denotes the Kullback-Leibler divergence. Since Ep(x) [log Cat(y|f π
true(x))] is a
constant with respect to hπ(x), an unbiased estimator of the relative goodness of an inferred model is
the negative test log-likelihood NLL(hπ(x)) = −1/|Dts| P"
INTRODUCTION,0.11333333333333333,"(x,y)∈Dts log Cat(y|hπ(x))."
INTRODUCTION,0.11666666666666667,"ii) Class overlap evaluated by R∗(f π
true(x)). As there is no way to measure this quantity from Dts,
it is approximated indirectly via Expected Calibration Error (ECE)"
INTRODUCTION,0.12,"ECE[hπ] = M
X m=1 |Bm| N"
INTRODUCTION,0.12333333333333334,acc(Bm) −conf(Bm)
INTRODUCTION,0.12666666666666668,"where Bm = {(n|hπ(xn) ∈[(m −1)/M, m/M]} are M bins that partition the test set Dts into
Dts = B1 ∪· · · ∪BM and are characterized by their accuracy and conﬁdence scores"
INTRODUCTION,0.13,"acc(Bm) =
1
|Bm| X"
INTRODUCTION,0.13333333333333333,"n∈Bm
Iyn=arg max hπ(xn),
conf(Bm) =
1
|Bm| X"
INTRODUCTION,0.13666666666666666,"n∈Bm
hπ(xn).
(5)"
INTRODUCTION,0.14,"iii) Domain mismatch deﬁnes the rarity of an input pattern x∗for the target task, that is
Pr[p(x = x∗) < ϵ] for small ϵ. This quantity cannot be measured since p(x) is unknown. It is
approximated indirectly as the success of discriminating between samples x∗coming from a different
data distribution and those in Dts by calculating the Area Under ROC (AUROC) curve w.r.t. hπ(x)."
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.14333333333333334,"3
UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.14666666666666667,"Parametric Bayesian Models.
A commonplace design choice is to build the hypothesis space
by equipping the hypothesis function with a global parameter θ that takes values from a fea-
sible set Θ, that is Hπ = {hθ
π(x)|θ ∈Θ}.
Parametric Bayesian Models (PBMs) employ
a prior belief θ ∼p(θ), which is updated via Bayesian inference on a training set Dtr as
p(θ|Dtr) = Q"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.15,"(x,y)∈Dtr Cat(y|hθ
π(x))p(θ)/p(Dtr). Consider the update on the posterior belief"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.15333333333333332,"p(θ|Dtr ∪(x∗, y∗)) = Cat(y∗|hθ
π(x∗))p(θ|Dtr)/Z,
(6)"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.15666666666666668,"after a new observation (x∗, y∗) where the normalizer can be expressed as"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.16,"Z =
1
p(Dtr)"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.16333333333333333,"Z
Cat(y∗|hθ
π(x∗))L(θ)p(θ)dθ.
(7)"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.16666666666666666,with L(θ) = Q
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.17,"(x,y)∈Dtr Cat(y|hθ
π(x)). This can be seen as an inner product between the functions
Cat(y∗|hθ
π(x∗)) and L(θ) on an embedding space modulated by p(θ). As the sample size grows, the
high-density regions of Cat(y∗|hθ
π(x∗)) and L(θ) will superpose with higher probability, causing Z
to increase, making p(θ|Dtr ∪(x∗, y∗)) increasingly more peaked, and consequently we will have"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.17333333333333334,"lim
|Dtr|→+∞V ar[θ|Dtr] = 0.
(8)"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.17666666666666667,Published as a conference paper at ICLR 2022
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.18,"This conjecture depends on the assumption that a single random variable θ modulates all samples.
The variance of a prediction in favor of a class k decomposes according to the law of total variance"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.18333333333333332,"V ar[y∗= k|x∗, D] = V arθ∼p(θ|Dtr)[hθ
π,k(x∗)]
|
{z
}
Reducible model uncertainty"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.18666666666666668,"+ Eθ∼p(θ|Dtr)
h
(1 −hθ
π,k(x∗))hθ
π,k(x∗)
i"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.19,"|
{z
}
Data uncertainty .
(9)"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.19333333333333333,"Due to the Eq. 8, the ﬁrst term on the r.h.s. vanishes in the large sample regime and the second one
coincides with the asymptotic solution of the maximum likelihood estimator θMLE. In cases when
Hπ contains f π
true(x), an ideal inference scheme has the potential to recover it and we get"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.19666666666666666,"lim
N→+∞Eθ∼p(θ|Dtr)
h
(1 −hθ
π,k(x∗))hθ
π,k(x∗)
i
= (1 −hθMLE
π,k
(x∗))hθMLE
π,k
(x∗)"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.2,"= (1 −f π
true(x∗))f π
true(x∗)."
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.20333333333333334,"The simple proposition below sheds light on the meaning of this result. It points to the fact that the
Bayes risk of a classiﬁer (Eq. 4) and the second component of its predictive variance (Eq 9) are
proportional. This gives a mechanistic explanation for why the second term on the r.h.s. of Eq. 9
quantiﬁes class overlap. Despite the commonplace allocation of the wording data uncertainty for this
term, we are not aware of prior work that derives it formally from basic learning-theoretic concepts."
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.20666666666666667,"Proposition. The following inequality holds for any π, π′ ∈[0.5, 1] pair"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.21,"min(1 −π, π) ≥min(1 −π′, π′) ⇒(1 −π)π ≥(1 −π′)π′."
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.21333333333333335,"Proof. Deﬁne π = 0.5+ϵ and π′ = 0.5+ϵ′ for ϵ, ϵ′ > 0. As min(1−π, π) ≥min(1−π′, π′) ⇒ϵ ≤
ϵ′, we get (1−π)π = (1−0.5−ϵ)(0.5+ϵ) = 0.25−0.25ϵ−ϵ2 ≥0.25−0.25ϵ′−ϵ′2 = (1−π′)π′□"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.21666666666666667,"The conclusion is that (1 −f π
true(x))f π
true(x) ∝R∗(f π
true(x)). Hence, the second term on the r.h.s.
of Eq. 9 is caused by the class overlap and it can be used to approximate the Bayes risk. Put together,
the ﬁrst term of the decomposition reﬂects the missing knowledge on the optimal value of θ that can
be reduced by increasing the training set size, while the second reﬂects the uncertainty stemming
from the properties of the true data distribution. Hence we refer to the ﬁrst term as the reducible
model uncertainty and the second the data uncertainty."
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.22,"Evidential Bayesian Models.
In all the analysis above, we assumed a ﬁxed and unknown π
that modulates the whole process and cannot be identiﬁed by the learning scheme. When we
characterize the uncertainty on the class distribution by a prior belief π ∼p(π), we attain the joint
p(y, π|x) = Pr[y|x, π]p(π|x). The variance of the Bayes optimal classiﬁer that averages over this
uncertainty Pr[y|x] =
R
Pr[y|x, π]p(π|x)dπ decomposes as"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.22333333333333333,"V ar[y = k|x] = V arπ∼p(π|x)[f π,k
true(x)]
|
{z
}
Irreducible model uncertainty"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.22666666666666666,"+ Eπ∼p(π|x)
h
(1 −f π,k
true(x))f π,k
true(x)
i"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.23,"|
{z
}
Data uncertainty ."
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.23333333333333334,"The main source of uncertainty p(π|x) is not a posterior this time but an empirical prior on a single
observation x, hence its variance will not shrink as |Dtr| →+∞. Therefore, the ﬁrst term on the r.h.s.
reﬂects the irreducible model uncertainty caused by the missing knowledge about π. The second
term indicates data uncertainty as in PBMs, but accounts for the local uncertainty at x caused by π.
Evidential Bayesian Models (EBMs) (Sensoy et al., 2018; Malinin & Gales, 2018) suggest"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.23666666666666666,"p(y, π|x) = Pr[y|x, π]p(π|x) ≈Pr[y|π]qψ(π|x)"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.24,"where qψ(π|x) is a density function parameterized by ψ and the dependency of the class-conditional
on the input is dropped. Note that the resultant model employs uncertainty on individual data points
via π, but it does not have any global random variables. The standard evidential model training is
performed by maximizing the expected likelihood subject to a regularizer that penalizes the divergence
of qψ(π|x) from the prior belief"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.24333333333333335,"arg min
ψ
−
Z
log Pr[y|π]qψ(π|x)dπ + βKL(qψ(π|x)||p(π))."
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.24666666666666667,"Although presented in the original work as as-hoc design choices, such a training objective can
alternatively be viewed as β-regularized (Higgins et al., 2017) variational inference of Pr[y|π]p(π|x)
with the approximate posterior qψ(π|x) (Chen et al., 2019)."
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.25,Published as a conference paper at ICLR 2022
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.25333333333333335,"4
COMPLETE BAYESIAN MODELS: BEST OF BOTH WORLDS"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.25666666666666665,"The uncertainty decomposition characteristics of PBMs and EBMs provide complementary strengths
towards quantiﬁcation of the three uncertainty types that constitute total calibration."
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.26,"i) Model misﬁt:
The PBM is favorable since it provides shrinking posterior variance with growing
training set size (Eq. 8) and the recovery of θMLE which inherits the consistency guarantees the
frequentist approach. Since the uncertainty on the local variable π does not shrink for large samples,
NLL would measure how well ψ can capture the regularities of heteroscedastic noise across individual
samples, which is a more difﬁcult task than quantifying the ﬁt of a parametric model."
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.2633333333333333,"ii) Class overlap:
The EBM is favorable since its data uncertainty term Eπ∼p(π|x∗)[(1 −
hθ
π,k(x∗))hθ
π,k(x∗)] is likely to have less estimator variance than Eθ∼p(θ|Dtr)[(1−hθ
π,k(x∗))hθ
π,k(x∗)]
and calculating p(π|x∗) does not require approximate inference as for p(θ|Dtr)."
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.26666666666666666,"iii) Domain mismatch:
The PBM is favorable since the effect of the modulation of a global θ on
the variance of Z applies also to the posterior predictive distribution with the only difference that
x∗is a test sample. When the test sample is away from the training set, i.e. minx∈Dtr ||x∗−x|| is
large, then p(y∗|x∗, θ) is less likely to superpose with those regions of θ where L(θ) is pronounced,
hence will be ﬂattened out leading to a higher variance posterior predictive for samples coming from
another domain. Since EBM has only local random variables, the variance of its posterior is less
likely to build a similar discriminative property for domain detection."
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.27,"Main Hypothesis. A model that inherits the model uncertainty of PBM and data uncertainty of EBM
can simultaneously quantify: i) model misﬁt, ii) class overlap, and iii) domain mismatch."
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.2733333333333333,"Guided by our main hypothesis, we combine the PBM and EBM designs within a uniﬁed framework
that inherits the desirable uncertainty quantiﬁcation properties of each individual approach"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.27666666666666667,"Pr[y|π]p(π|θ, x)p(θ),
(10)"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.28,"which we refer to as a Complete Bayesian Model (CBM) hinting to its capability to solve the total
calibration problem. The model simply introduces a global random variable θ into the empirical prior
p(π|θ, x) of the EBM. The variance of the posterior predictive of the resultant model decomposes as"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.2833333333333333,"V ar[y|x] = V arp(θ|D)
h
Ep(π|x,θ)[E[y|π, x]]
i"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.2866666666666667,"|
{z
}
Reducible Model Uncertainty"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.29,"+ Ep(θ|D)
h
V arp(π|θ,x)[E[y|π]]
i"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.29333333333333333,"|
{z
}
Irreducible Model Uncertainty"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.2966666666666667,"+ Ep(θ|D)
h
Ep(π|x,θ)[V ar[y|π]]
i"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.3,"|
{z
}
Data Uncertainty (11)"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.30333333333333334,"where the r.h.s. of the decomposition has the following desirable properties: i) The ﬁrst term
recovers the form of the reducible model uncertainty term of PBM when π is marginalized
V arp(θ|D)[Ep(π|x,θ)[E[y|π, x]]] = V arp(θ|D)[E[y|θ, x]]; ii) The second term is the irreducible model
uncertainty term of EBM averaged over the uncertainty on the newly introduced global variable θ. It
quantiﬁes the portion of uncertainty stemming from heteroscedastic noise, which is not explicit in
the decomposition of PBM; iii) The third term recovers the data uncertainty term of EBM when θ is
marginalized: Ep(θ|D)[Ep(π|x,θ)[V ar[y|π]] = Ep(π|x)[V ar[y|π]]."
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.30666666666666664,"5
THE EVIDENTIAL TURING PROCESS: AN EFFECTIVE CBM REALIZATION"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.31,"Equipping the empirical prior p(π|θ, x) of CBM with the capability of learning to generate accurate
prior beliefs on individual samples is the key for total calibration. We adopt the following two guiding
principles to obtain highly expressive empirical priors: i) The existence of a global random variable
θ can be exploited to express complex reducible model uncertainties using the Neural Processes
(Garnelo et al., 2018b) framework, ii) The conditioning of p(π|θ, x) on a global variable θ and an
individual observation x can be exploited with an attention mechanism where θ is a memory and x is
a query. Dependency on a context set during test time can be lifted using the Neural Turing Machine"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.31333333333333335,Published as a conference paper at ICLR 2022
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.31666666666666665,"(Graves et al., 2014) design, which maintains an external memory that is updated by a rule detached
from the optimization scheme of the main loss function. We extend the stochastic process derivation
of the Neural Processes by marginalizing out a local variable from a PBM with an external memory
that follows the Neural Turing Machine design and arrive at a new family of stochastic processes
called a Turing Process, formally deﬁned as below."
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.32,"Deﬁnition 1.
A Turing Process is a collection of random variables Y = {yi|i ∈I} for an index
set I = {1, . . . , K} with arbitrary K ∈N+ that satisfy the two properties"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.3233333333333333,"(i) pM(Y ) =
Z
Y"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.32666666666666666,"yi∈Y
p(yi|θ)pM(θ)dθ,
(ii) pM ′(Y |Y ′) =
Z
Y"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.33,"yi∈Y
p(yi|θ)pM ′(θ|Y ′)dθ,"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.3333333333333333,"for another random variable collection Y ′ of arbitrary size that lives in the same probability space
as Y , a probability measure pM(θ) with free parameters M, and some function M ′ = r(M, Y ′)."
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.33666666666666667,"The Turing Process can express all stochastic processes since property (i) is sufﬁcient to satisfy
Kolmogorov’s Extension Theorem (Øksendal, 1992) and choosing r simply to be an identity mapping
would revert us back to the generic deﬁnition of a stochastic process. The Turing Process goes further
by permitting to explicitly specify how information accumulates within the prior. This is a different
approach from the Neural Process that performs conditioning p(Y |Y ′) by applying an amortized
posterior q(θ|Y ′) on a plain stochastic process that satisﬁes only Property (i), hence maintains a
data-agnostic prior p(θ) and depends on a context set also at the prediction time."
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.34,"Given a disjoint partitioning of the data D = DC ∪DT into a context set (x′, y′) ∈DC and a target
set (x, y) ∈DT , we propose the data generating process on the target set below"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.3433333333333333,"p(y, DT , π, θ) = p(w) pM(Z)
| {z }
External
memory Y"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.3466666666666667,"(x,y)∈DT"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.35,"h
p(y|π) p(π|Z, w, x)
|
{z
}
Input-speciﬁc
prior"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.35333333333333333,"i
.
(12)"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.3566666666666667,"We decouple the global parameters θ = {w, Z} into a w that parameterizes a map from the input to
the hyperparameter space and an external memory Z = {z1, . . . , zR} governed by the distribution
pM(Z) parameterized by M that embeds the context data during training. The memory variable
Z updates its belief conditioned on the context set DC by updating its parameters with an explicit
rule pM(Z|DC) ←pEZ∼pM (Z)[r(Z,DC)](Z). The hyperpriors of p(π|Z, w, x) are then determined by
querying the memory Z for each input observation x using an attention mechanism, for instance a
transformer network (Vaswani et al., 2017). Choosing the variational distribution as qλ(θ, π|x) =
qλ(w)pM(Z)q(π|Z, w, x), we attain the variational free energy formula for our target model
FET P (λ) =
(13)"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.36,"Eqλ(w)  −
X"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.36333333333333334,"(x,y)∈D
Eqλ(π|Z,w,x)"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.36666666666666664,"
EpM(Z)"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.37,"
log p(y|π) + log qλ(π|Z, w, x)"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.37333333333333335,"p(π|Z, w, x)"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.37666666666666665,"
+ log qλ(w) p(w)  ."
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.38,"The learning procedure will then alternate between updating the variational parameters λ via gradient-
descent on FET P (λ) and updating the parameters of the memory variable Z via an external update
rule as summarized in Figure 2b. ETP can predict a test sample (x∗, y∗) by only querying the input
x∗on the memory Z and evaluating the prior p(π∗|Z, w, x∗) without need for any context set as"
"UNCERTAINTY QUANTIFICATION WITH PARAMETRIC AND EVIDENTIAL
BAYESIAN MODELS",0.38333333333333336,"p(y∗|Dtr, x∗) ≈
ZZ
p(y∗|π∗)q(π∗|Z, w, x∗)pM(Z)qλ(w)dZdw.
(14)"
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.38666666666666666,"6
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS"
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.39,"As we build the design of the Evidential Turing Process (ETP) on the CBM framework that over-
arches the prevalent parametric and evidential approaches, its ablation amounts to recovering many
state-of-the-art modeling approaches as listed in Table 1 and detailed below."
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.3933333333333333,"Bayesian Neural Net (BNN)
(Neal, 1995; MacKay, 1992; 1995) is the most characteristic PBM
example that parameterize a likelihood p(y|θ, x) with a neural network fθ(·) whose weights follow
a distribution θ ∼p(θ). In the experiments we assume as a prior θ ∼N(θ|0, β−1I) and infer its
posterior by mean-ﬁeld variational posterior qλ(θ) applying the reparameterization trick (Kingma
et al., 2015; Molchanov et al., 2017)."
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.39666666666666667,"Published as a conference paper at ICLR 2022 M
Z
π w x y x′ y′ r"
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.4,"(x, y) ∈DT
(x′, y′) ∈DC"
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.4033333333333333,(a) ETP Plate diagram
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.4066666666666667,while Model not converged do
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.41,for Dbatch ⊂D do
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.41333333333333333,"Choose DC ⊂Dbatch
M ←
EZ∼pM(Z) [r(Z, DC)]
λ ←λ −∇λFET P (λ)
end
end"
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.4166666666666667,(b) ETP Training
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.42,"Figure 2: The Evidential Turing Process: (left) The essential design choice is how p(π|Z, w, x) is
constructed thanks to an external memory M that can be queried with respect to any input x without
needing to store context data at test time. The dashed arrow indicates that Z can condition on a
context DC by updates its parameters M with an explicit function r. (right) The ETP training routine."
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.42333333333333334,"Table 1: Ablation Table. Deactivating the components of ETP one at a time equates it to state-of-the-
art methods. We curate ENP as a surrogate for the Attentive NP (ANP) of (Kim et al., 2019), which
requires test-time context, and an improved NP variant with reduced estimator variance thanks to π."
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.4266666666666667,"Model
π
Z
M
r
D(test)
c
Compare"
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.43,"ETP (Target)
×
ANP (Kim et al., 2019)
×
No
ENP (Surrogate)
×
×
×
Yes
NP (Garnelo et al., 2018b)
×
×
×
×
No
EDL (Sensoy et al., 2018)
×
×
×
×
Yes
BNN (Molchanov et al., 2017)
×
×
×
×
×
Yes
: Component active
×: Component inactive
D(test)
c
: Demand for context data at test time"
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.43333333333333335,"Evidential Deep Learning (EDL)
(Sensoy et al., 2018) introduces the characteristic exam-
ple of EBMs.
EDL employs an uninformative Dirichlet prior on the class probabilities,
which then set the mean of a normal distribution on the one-hot-coded class labels y, π ∼
Dir(π|1, . . . , 1)N(y|π, 0.5IK).
EDL links the input observations to the distribution of class
probabilities by performing amortized variational inference with the approximate distribution
qλ(π; x) = Dir(π|αλ(x))."
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.43666666666666665,"Neural Processes (NP)
(Garnelo et al., 2018a;b) is a PBM used to generate stochastic processes
from neural networks by integrating out the global parameters θ as in Property (i) of Deﬁnition 1. NPs
differ from PBMs by amortizing an arbitrary sized context set DC on the global parameters q(θ|DC)
via an aggregator network during inference. NPs can be viewed as Turing Processes with an identity
map r. Follow-up work equipped NPs with attention (Kim et al., 2019), translation equivariance
(Gordon et al., 2020; Foong et al., 2020), and sequential prediction (Singh et al., 2019; Yoon et al.,
2020). All of these NP variants assume prediction-time access to context, making them suitable for
interpolation tasks such as image in-painting but not for generic prediction problems."
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.44,"Evidential Neural Process (ENP)
is the EBM variant of a neural process we introduce to bring
together best practices of EDL and NPs and make the strongest possible baseline for ETP, deﬁned as"
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.44333333333333336,"p(y, π, Z|DC) = Cat(y|π)Dir
 
π|αθ(Z)

N
 
Z|(µ, σ2) = r({hθ(xj, yj) | (xj, yj) ∈DC})

, (15)"
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.44666666666666666,"with an aggregation rule r(·), an encoder net hθ(·, ·), and a neural net αθ(·) mapping the global
variable Z to the class probability simplex. We further improve upon ENP with an attentive NP
approach (Kim et al., 2019) by replacing the ﬁxed aggregation rule r with an attention mechanism,
thereby allowing the model to switch focus depending on the target. At the prediction time, we use
Z ∼N(Z|1, κ2I) for small κ to induce an uninformative prior on π in the absence of a context set."
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.45,Published as a conference paper at ICLR 2022
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.4533333333333333,"7
CASE STUDY: CLASSIFICATION WITH EVIDENTIAL TURING PROCESSES"
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.45666666666666667,We demonstrate a realization of an Evidential Turing Process to a classiﬁcation problem below
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.46,"y, π, w, Z|M ∼Cat(y|π)Dir
 
π| exp(a(vw(x); Z))

N(w|0, β−1I) R
Y"
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.4633333333333333,"r=1
N(zr|mr, κ2I).
(16)"
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.4666666666666667,"The global variable Z is parameterized by the memory M = (m1, . . . , mR) consisting of R cells
mr ∈RK.1 The input data x is mapped to the same space via an encoding neural net vw(·)
parameterizing a Dirichlet distribution over the class probabilities π via an attention mechanism
a(vw, z) = P"
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.47,"z′∈Z φ(vw(x), z′)z, where φ(vw(x), z) = softmax({kψ(z)⊤vw(x)/
√"
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.47333333333333333,"K|z ∈Z}).
The function kψ(·) is the key generator network operating on the embedding space. We update the
memory cells as a weighted average between remembering and updating"
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.4766666666666667,m ←EZ∼p(Z|M) 
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.48,"tanh

γm + (1 −γ)
X"
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.48333333333333334,"(x,y)∈DC
φ(vw(x), z)[onehot(y) + soft(vw(x))]

 (17)"
MOST IMPORTANT SPECIAL CASES OF THE EVIDENTIAL TURING PROCESS,0.4866666666666667,"where γ ∈(0, 1) is a ﬁxed scaling factor controlling the relative importance. The second term adds
new information to the cell as a weighted sum over all pairs (x, y), taking both the true label (via
onehot(y)) as well as the uncertainty in the prediction (via soft(vw(x))) into account. The ﬁnal
tanh(·) transformation ensures that the memory content remains in a ﬁxed range across updates, as
practised in LSTMs (Hochreiter & Schmidhuber, 1997)."
EXPERIMENTS,0.49,"8
EXPERIMENTS"
EXPERIMENTS,0.49333333333333335,"We benchmark ETP against the state of the art as addressed in the ablation plan in Table 1 according
to the total calibration criteria developed in Sec. 2 on ﬁve real-world data sets. See the Appendix B
for full details on the experimental setup in each case and for the hyperparameters used throughout.
We provide a reference implementation of the proposed model and the experimental pipeline.2 11 13 15"
EXPERIMENTS,0.49666666666666665,Error (%)
EXPERIMENTS,0.5,FMNIST-C 20 30 40 50
EXPERIMENTS,0.5033333333333333,60 CIFAR10-C 8.5 9.5 10.5
EXPERIMENTS,0.5066666666666667,SVHN-C
EXPERIMENTS,0.51,"1
2
3
4
5
Severity 6 10"
EXPERIMENTS,0.5133333333333333,ECE (%)
EXPERIMENTS,0.5166666666666667,"1
2
3
4
5
Severity 7.5 12.5 17.5 22.5"
EXPERIMENTS,0.52,"1
2
3
4
5
Severity 6 10"
EXPERIMENTS,0.5233333333333333,"BNN
EDL
ENP
ETP"
EXPERIMENTS,0.5266666666666666,"Figure 3: Results averaged across 19 types of cor-
ruption (e.g. motion blur, fog, pixelation) applied
on the test splits of FMNIST, CIFAR10, and SVHN
at ﬁve severity levels."
EXPERIMENTS,0.53,"Total calibration.
Table 2 reports the predic-
tion error and the three performance scores intro-
duced in Sec. 2 that constitute total calibration.
We perform the out-of-domain detection task as
in Malinin & Gales (2018) and classify the test
split of the target domain and a data set from
another domain based on the predictive entropy.
ETP is the only method that consistently ranks
among top performers in all data sets with re-
spect to all performance scores, which supports
our main hypothesis that CBM should outper-
form PBM and EBM in total calibration."
EXPERIMENTS,0.5333333333333333,"Response to gradual domain shift.
In order
to assess how well models can cope with a grad-
ual transition from their native domain, we eval-
uate their ECE performance on data perturbed
by 19 types of corruption (Hendrycks & Diet-
terich, 2019) at ﬁve different severity levels. Figure 3 depicts the performance of models averaged
across all corruptions. ETP gives the best performance nearly in all data sets and distortion severity
levels (see Appendix B.3 Table 4 for a tabular version of these results)."
EXPERIMENTS,0.5366666666666666,"Computational cost.
We measured the average wall-clock time per epoch in CIFAR10 to be
10.8 ± 0.1 seconds for ETP, 8.2 ± 0.1 seconds for BNN, 8.6 ± 0.1 seconds for EDL, and 9.5 ± 0.2
seconds for ENP. The relative standings of the models remain unchanged in all the other data sets."
EXPERIMENTS,0.54,"1In the experiments we ﬁx κ2 = 0.1. Preliminary results showed stability as well for larger/smaller values.
2https://github.com/ituvisionlab/EvidentialTuringProcess"
EXPERIMENTS,0.5433333333333333,Published as a conference paper at ICLR 2022
EXPERIMENTS,0.5466666666666666,"Table 2: Quantitative results on ﬁve data sets showing mean ± standard deviation across 10 repetitions.
Best performing models that overlap within three standard deviations are highlighted in bold."
EXPERIMENTS,0.55,"Domain Data
IMDB
Fashion
SVHN
CIFAR10
CIFAR100
(Architecture)
(LSTM)
(LeNet5)
(LeNet5)
(LeNet5)
(ResNet18)
Prediction accuracy as % test error
BNN
16.4 ±0.6
7.9±0.1
7.9±0.1
15.3±0.3
30.2 ±0.3
EDL
38.3 ±13.3
8.6±0.1
7.3±0.1
18.5±0.2
45.2 ±0.4
ENP
50.0 ±0.0
7.9±0.2
6.7±0.1
14.8±0.2
39.0 ±0.3
ETP (Target)
15.8 ±1.3
7.9±0.2
6.9±0.1
15.3±0.2
29.2 ±0.3
In-domain calibration as % Expected Calibration Error (ECE)
BNN
14.4 ±0.4
6.7±0.
6.5±0.
5.5±0.3
15.2±0.0
EDL
41.1 ±2.6
3.7±0.2
4.0±0.1
9.0±0.2
5.3±0.4
ENP
0.8 ±1.6
6.0±0.2
10.7±0.2
7.2±0.3
39.7±0.4
ETP (Target)
3.1 ±0.4
2.6±0.2
2.6±0.1
2.7±0.1
6.6±0.1
Model ﬁt as negative test log-likelihood
BNN
0.47 ±0.0
0.65±0.0
0.71±0.0
0.50±0.0
1.78±0.0
EDL
0.66 ±0.1
0.37±0.0
0.34±0.0
0.72±0.0
2.24±0.0
ENP
0.69 ±0.0
0.34±0.0
0.33±0.0
0.50±0.0
2.52±0.0
ETP (Target)
0.37 ±0.0
0.29±0.0
0.26±0.0
0.46±0.0
1.36±0.0
Out-of-domain detection as % Area Under ROC Curve
OOD Data
Random
MNIST
CIFAR100
SVHN
TinyImageNet
BNN
60.9 ±4.2
75.9±2.3
86.2±0.5
84.1±1.3
97.2±0.5
EDL
55.1 ±5.1
77.5±2.0
90.9±0.3
79.2±0.7
89.6±0.3
ENP
53.7 ±5.7
88.9±1.0
92.4±0.4
81.4±0.8
100.0±0.1
ETP (Target)
59.1 ±5.1
90.0±0.9
90.0±0.4
82.1±0.6
99.6±0.1"
CONCLUSION,0.5533333333333333,"9
CONCLUSION"
CONCLUSION,0.5566666666666666,"Summary.
We initially develop the ﬁrst formal deﬁnition of total calibration. Then we analyze
how the design of two mainstream Bayesian modeling approaches affect their uncertainty charac-
teristics. Next we introduce Complete Bayesian Models as a unifying framework that inherits the
complementary strengths existing ones. We develop the Evidential Turing Process as an optimal
realization of Complete Bayesian Models. We derive an experiment setup from our formal deﬁnition
of total calibration and a systematic ablation of our target model into the strongest representatives of
the state of the art. We observe in ﬁve real-world tasks that the Evidential Turing Process is the only
model that can excel all three aspects of total calibration simulatenously."
CONCLUSION,0.56,"Broad impact.
Our work delivers evidence for the claim that epistemic awareness of a Bayesian
model is indeed a capability learnable only from in-domain data, as appears in biological intelligence
via closed-loop interactions of neuronal systems with stimuli. The implications of our work could
follow up in interdisciplinary venues, with focus on the relation of associative memory and attention
to the neuroscientiﬁc roots of epistemic awareness (Lorenz, 1978)."
CONCLUSION,0.5633333333333334,"Limitations and ethical concerns.
While we observed ETP to outperform BNN variants in our
experiments, whether BNNs could bridge the gap after further improvements in the approximate
inference remains an open question. The attention mechanism of ETP could also be improved, for
instance to transformer nets (Vaswani et al., 2017). The explainability of the memory content of ETP
deserves further investigation. The generalizeability of our results to very deep architectures, such as
ResNet 152 or DenseNet 161 could be a topic of a separate large-scale empirical study. ETP does not
improve the explainability and fairness of the decisions made by the underlying design choices, such
as the architecture of the used neural nets in the pipeline. Potential negative societal impacts of deep
neural net classiﬁers stemming from these two factors need to be circumvented separately before the
real-world deployment of our work."
CONCLUSION,0.5666666666666667,Published as a conference paper at ICLR 2022
REFERENCES,0.57,REFERENCES
REFERENCES,0.5733333333333334,"M. Abramowitz and I.A. Stegun. Handbook of Mathematical Functions. Dover, 1965."
REFERENCES,0.5766666666666667,"W. Chen, Y. Shen, H. Jin, and W. Wang. A Variational Dirichlet Framework for Out-of-Distribution
Detection. abs/1811.07308, 2019."
REFERENCES,0.58,"A. Foong, W. Bruinsma, J. Gordon, Y. Dubois, J. Requeima, and R. Turner. Meta-Learning Stationary
Stochastic Process Prediction with Convolutional Neural Processes. In NeurIPS, 2020."
REFERENCES,0.5833333333333334,"M. Garnelo, D. Rosenbaum, C. Maddison, T. Ramalho, D. Saxton, M. Shanahan, Y.W. Teh,
D. Rezende, and S.M.A. Eslami. Conditional Neural Processes. In ICML, 2018a."
REFERENCES,0.5866666666666667,"M. Garnelo, J. Schwarz, D. Rosenbaum, F. Viola, D.J. Rezende, S.M. Eslami, and Y.W. Teh. Neural
Processes. In ICML WS on Theoretical Foundations and Applications of Deep Generative Models,
2018b."
REFERENCES,0.59,"J. Gordon, W.P. Bruinsma, A.Y.K. Foong, J. Requeima, Y. Dubois, and R.E. Turner. Convolutional
Conditional Neural Processes. In ICLR, 2020."
REFERENCES,0.5933333333333334,"A. Graves, G. Wayne, and I. Danihelka. Neural Turing Machines. arXiv preprint arXiv:1410.5401,
2014."
REFERENCES,0.5966666666666667,"C. Guo, G. Pleiss, Y. Sun, and K.Q. Weinberger. On Calibration of Modern Neural Networks. In
ICML, 2017."
REFERENCES,0.6,"D. Hendrycks and T. Dietterich. Benchmarking Neural Network Robustness to Common Corruptions
and Perturbations. In ICML, 2019."
REFERENCES,0.6033333333333334,"I. Higgins, L. Matthey, A. Pal, C. Burgess, X. Glorot, M. Botvinick, S. Mohamed, and A. Lerchner.
β-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework. In ICLR,
2017."
REFERENCES,0.6066666666666667,"S. Hochreiter and J. Schmidhuber. Long Short-Term Memory. Neural Computation, 9(8):1735–1780,
1997."
REFERENCES,0.61,"H. Kim, A. Mnih, J. Schwarz, M. Garnelo, A. Eslami, D. Rosenbaum, O. Vinyals, and Y.W. Teh.
Attentive Neural Processes. In ICLR, 2019."
REFERENCES,0.6133333333333333,"D.P. Kingma and J. Ba. Adam: A Method for Stochastic Optimization. In ICLR, 2015."
REFERENCES,0.6166666666666667,"D.P. Kingma, T. Salimans, and M. Welling. Variational Dropout and the Local Reparameterization
Trick. NeurIPS, 2015."
REFERENCES,0.62,"V. Kuleshov, N. Fenner, and S. Ermon. Accurate Uncertainties for Deep Learning using Calibrated
Regression. In ICML, 2018."
REFERENCES,0.6233333333333333,"Y. LeCun, C. Cortes, and C.J. Burges. MNIST Handwritten Digit Database. ATT Labs [Online].
Available: http://yann.lecun.com/exdb/mnist, 2, 2010."
REFERENCES,0.6266666666666667,"Konrad Lorenz. Die Rückseite des Spiegels: Versuch einer Naturgeschichte menschlichen Erkennens.
Piper, 1978."
REFERENCES,0.63,"D.J.C. MacKay. A Practical Bayesian Framework for Backpropagation Networks. Neural Computa-
tion, 1992."
REFERENCES,0.6333333333333333,"D.J.C. MacKay. Probable Networks and Plausible Predictions – A Review of Practical Bayesian
Methods for Supervised Neural Networks. Network: Computation in Neural Systems, 1995."
REFERENCES,0.6366666666666667,"A. Malinin and M. Gales. Predictive Uncertainty Estimation via Prior Networks. In NeurIPS, 2018."
REFERENCES,0.64,"D. Molchanov, A. Ashukha, and D. Vetrov. Variational Dropout Sparsiﬁes Deep Neural Networks. In
ICML, 2017."
REFERENCES,0.6433333333333333,"M.P. Naeini, G. Cooper, and M. Hauskrecht. Obtaining Well Calibrated Probabilities using Bayesian
Binning. In AAAI, 2015."
REFERENCES,0.6466666666666666,Published as a conference paper at ICLR 2022
REFERENCES,0.65,"R. Neal. Bayesian Learning for Neural Networks. PhD thesis, 1995."
REFERENCES,0.6533333333333333,"Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, and A.Y. Ng. Reading Digits in Natural Images
with Unsupervised Feature Learning. In NeurIPS WS on Deep Learning and Unsupervised Feature
Learning, 2011."
REFERENCES,0.6566666666666666,"B. Øksendal. Stochastic Differential Equations: An Introduction with Applications. Springer-Verlag,
1992."
REFERENCES,0.66,"A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T..evor Killeen, Z. Lin,
N. Gimelshein, L. Antiga, A. Desmaison, A. Kopf, E. Yang, Z. DeVito, M. Raison, A. Te-
jani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, and S. Chintala. PyTorch: An Imperative Style,
High-Performance Deep Learning Library. In NeurIPS. 2019."
REFERENCES,0.6633333333333333,"H. Robbins and S. Monro. A Stochastic Approximation Method. The Annals of Mathematical
Statistics, 22(3):400 – 407, 1951."
REFERENCES,0.6666666666666666,"G. Schwalbe and M. Schels. A Survey on Methods for the Safety Assurance of Machine Learning
Based Systems. In European Congress on Embedded Real Time Software and Systems, 2020."
REFERENCES,0.67,"M. Sensoy, L. Kaplan, and M. Kandemir. Evidential Deep Learning to Quantify Classiﬁcation
Uncertainty. In NeurIPS, 2018."
REFERENCES,0.6733333333333333,"G. Singh, J. Yoon, Y. Son, and S. Ahn. Sequential Neural Processes. In NeurIPS, 2019."
REFERENCES,0.6766666666666666,"A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A.N. Gomez, L. Kaiser, and I. Polosukhin.
Attention is All You Need. In NeurIPS, 2017."
REFERENCES,0.68,"J. Yoon, G. Singh, and S. Ahn. Robustifying Sequential Neural Processes. In ICML, 2020."
REFERENCES,0.6833333333333333,Published as a conference paper at ICLR 2022
REFERENCES,0.6866666666666666,APPENDIX
REFERENCES,0.69,"A
FURTHER ANALYTICAL RESULTS AND DERIVATIONS"
REFERENCES,0.6933333333333334,"A.1
KULLBACK LEIBLER BETWEEN TWO DIRICHLET DISTRIBUTIONS"
REFERENCES,0.6966666666666667,"As both our ETP and and the EDL baseline use the Kullback-Leibler divergence between two
Dirichlet distributions, we give the full details of its calculation here. For two distributions over a
K-dimensional probability π, Dir(π|α) and Dir(π|β), parameterized by α, β ∈RK
+ , the following
identity holds"
REFERENCES,0.7,"KL
 
Dir(π|α) ∥Dir(π|β)

= log
Γ(P"
REFERENCES,0.7033333333333334,k αk) Q
REFERENCES,0.7066666666666667,"k Γ(βk)
Γ(P"
REFERENCES,0.71,k βk) Q
REFERENCES,0.7133333333333334,"k Γ(αk) 
+
X"
REFERENCES,0.7166666666666667,"k
(αk −βk)
 
ψ(αk) −ψ(P
k αk)

,"
REFERENCES,0.72,"where Γ(·) and ψ(a) :=
d
da log Γ(a) are the gamma and digamma functions (Abramowitz & Stegun,
1965)."
REFERENCES,0.7233333333333334,"A.2
THE EVIDENTIAL DEEP LEARNING OBJECTIVE"
REFERENCES,0.7266666666666667,"The analytical expression of the Evidential Deep Learning (Sensoy et al., 2018) loss as deﬁned in
the main paper can be computed as follows. For a single K-dimensional observation y, dropping
the n from the notation and instead using the index for the dimensionality throughout the following
equations, we have"
REFERENCES,0.73,"Ep(π|x)

||y −π||2
= Ep(π|x)

(y −π)⊤(y −π)
 = K
X"
REFERENCES,0.7333333333333333,"k=1
Ep(π|x)

(yk −πk)2 = K
X"
REFERENCES,0.7366666666666667,"k=1
Ep(π|x)

(yk −Ep(π|x) [πk] + Ep(π|x) [πk] −πk)2 = K
X"
REFERENCES,0.74,"k=1
(yk −Ep(π|x) [πk])2 + varp(π|x) [πk] ,"
REFERENCES,0.7433333333333333,"with the tractable expectation and variance of a Dirichlet distributed π. The Kullback-Leibler term is
between two Dirichlet distributions and given (see the general form in A.1) as"
REFERENCES,0.7466666666666667,"KL (Dir(π|αθ(x)) ∥Dir(π|1, . . . , 1)) = log Γ
  P"
REFERENCES,0.75,"k αθ(x)k
"
REFERENCES,0.7533333333333333,Γ(K) Q
REFERENCES,0.7566666666666667,"k Γ(αθ(x)k) ! + K
X"
REFERENCES,0.76,"k=1
(αθ(x)k −1)

ψ(αθ(x)k) −ψ
  P"
REFERENCES,0.7633333333333333,"k αθ(x)k

."
REFERENCES,0.7666666666666667,"A.3
EVIDENTIAL DEEP LEARNING AS A LATENT VARIABLE MODEL"
REFERENCES,0.77,"As discussed in the main paper for a set of N observations D = {(x1, y1), . . . , (xN, yN)}, the EDL
objective minimizes is given as"
REFERENCES,0.7733333333333333,"LEDL = N
X"
REFERENCES,0.7766666666666666,"n=1
Ep(πn|xn)

||yn −πn||2
2

+ λKL
 
p(πn|xn) ∥Dir(πn|1, . . . , 1)

,"
REFERENCES,0.78,where p(πn|xn) = Dir(π|αθ(xn)). We can instead assume the following generative model
REFERENCES,0.7833333333333333,"πn ∼Dir(πn|1, . . . , 1)
∀n
yn ∼N(yn|πn, 0.5IK)
∀n,"
REFERENCES,0.7866666666666666,"i.e. latent variables πn and K-dimensional observations yn following a multivariate normal prior.
Approximating the intractable posterior p(π|y), where π = (π1, . . . , πn), y = (y1, ..., yn), with an"
REFERENCES,0.79,Published as a conference paper at ICLR 2022
REFERENCES,0.7933333333333333,"amortized variational posterior q(πn; xn) = Dir(πn|αθ(xn)), where αθ(·) is the same architecture
as in the EDL model, we have as the evidence lower bound (ELBO) to be maximized N
X"
REFERENCES,0.7966666666666666,"n=1
Eq(πn;xn) [log p(yn|πn)] −KL
 
q(πn; xn) ∥p(πn)
 = N
X"
REFERENCES,0.8,"n=1
Eq(πn;xn) 
−1"
REFERENCES,0.8033333333333333,2 log(2π) + K
REFERENCES,0.8066666666666666,"2 log(2) −(yn −πn)⊤(yn −πn)

−KL
 
q(πn; xn) ∥p(πn)
"
REFERENCES,0.81,"= const − N
X"
REFERENCES,0.8133333333333334,"n=1
Eq(πn;xn)

(yn −πn)⊤(yn −πn)

−KL
 
q(πn; xn) ∥p(πn)
"
REFERENCES,0.8166666666666667,"= const −LEDL,"
REFERENCES,0.82,that is the negative ELBO is equal to the EDL loss up to an additive constant.
REFERENCES,0.8233333333333334,"A.4
POSTERIOR PREDICTIVE"
REFERENCES,0.8266666666666667,"For a new input observation x∗, the corresponding posterior predictive distribution on the output y∗
can be computed as"
REFERENCES,0.83,"p(y∗= k|x∗, D) ≈Ep(Z|M)

Eqλ(π|x∗,Z) [p(y∗= k|π)]

= Ep(Z|M)
h
hk
θ
 P"
REFERENCES,0.8333333333333334,"k′ hk′
θ
i
,"
REFERENCES,0.8366666666666667,"where hk
θ = hθ (vθ(x∗), a(vθ(x∗); Z))k. That is, we can compute it analytically up to a sampling-
based evaluation of the expectation over p(Z|M)."
REFERENCES,0.84,"B
EXPERIMENTAL DETAILS"
REFERENCES,0.8433333333333334,"B.1
SYNTHETIC 1D TWO-CLASS CLASSIFICATION"
REFERENCES,0.8466666666666667,"−2
−1
0
1
2
0.0 0.2 0.4"
REFERENCES,0.85,Density
REFERENCES,0.8533333333333334,"−2
−1
0
1
2
Input space 5 10 15"
REFERENCES,0.8566666666666667,Memory Evidence
REFERENCES,0.86,"Figure 4: 1D Classiﬁcation Task.
The upper plot
shows the underlying distributions of each of the two
classes, as well as the observed data. The lower shows
the regularizing evidence the generative model places
on each of the two classes depending on location in
space, that is, mean ± one standard deviation over ten
samples from p(Z|M)."
REFERENCES,0.8633333333333333,"We illustrate the qualitative behaviour of
ETP on a synthetic 1d two-class classiﬁ-
cation task. The data consist of observa-
tions (20 per class) from two highly over-
lapping Gaussian distributions. The neural
net, a simple one hidden layer architecture,
can learn the task with high accuracy. Fig-
ure 4 shows the raw data and underlying
distributions as well as the learned mem-
ory evidence. The model learns to place
more evidence on the correct class further
away from the decision boundary while
also becoming more varied with increasing
distance. Within the high-density region,
the asymmetry in how the speciﬁc observa-
tions are spread out leads to an asymmetry
in the memory evidence. Below zero, the
blue points are clearly separated, leading
to a quick emphasis on that class as we
move towards the left. Above zero, how-
ever, some blue observations in the orange
region prevent the model from rapidly de-
veloping over-conﬁdence."
REFERENCES,0.8666666666666667,"This synthetic data set consisting of two classes with 20 observations each sampled from standard
normal distributions centered at ±1 respectively. The encoding function vφ(·) consists of a multi-layer
perceptron with a single hidden layer consisting of 32 neurons and a ReLU activation function. It is
optimized for 400 epochs with the Adam optimizer (Kingma & Ba, 2015) using the PyTorch (Paszke
et al., 2019) default parameters and a learning rate of 0.001. In order to keep the model as simple"
REFERENCES,0.87,Published as a conference paper at ICLR 2022
REFERENCES,0.8733333333333333,"−4
−3
−2
−1
0
1
2
3
4
Input x1 (for x2 = 0) 5 10 15"
REFERENCES,0.8766666666666667,Memory Evidence
REFERENCES,0.88,"Figure 5: 2D Classiﬁcation Task. The three upper plots visualize the regularizing evidence that the
model places on the location in space as the average over ten samples from p(Z|M). The color scales
are different across the three plots and vary in overall intensity. The lower plot visualizes a horizontal
cut through the middle of these plots, putting them on a common scale. The solid lines in each
color indicate the mean memory evidence, and the corresponding shaded areas indicate one standard
deviation. Around the separable blue class, the memory strongly emphasizes the correct class with
large conﬁdence and suppresses the other two classes depicted in orange and green. While always
preferring the correct class, the memory regularizes against overconﬁdence around the overlapping
orange and green classes."
REFERENCES,0.8833333333333333,"as possible, the key generator function kλ(·) is constrained to being the identity function, while
hξ
 
v(x), a(v(x); Z)

= v(x) + tanh(a(v(x); Z). The memory update is simpliﬁed to dropping the
tanh(·) rescaling."
REFERENCES,0.8866666666666667,"B.2
IRIS 2D THREE-CLASS CLASSIFICATION"
REFERENCES,0.89,"The data set used in this experiment is the classical Iris data set3 consisting of 150 samples of three
iris species (50 per class), with four features measured per sample. We ﬁrst map the data to the ﬁrst
two principal components for visualization and also use this modiﬁed version as the training data.
This gives an interpretable toy learning setup where one class is clearly separated from the other two
overlapping classes. The encoding function vφ(·) consists of an MLP with two hidden layers of 32
neurons each and ReLU activation functions. We train it for 400 epochs with the Adam optimizer
using the PyTorch default parameters and a learning rate of 0.001. In order to keep the model as
simple as possible, we constrain the key generator function kλ(·) to the identity function while setting
hξ
 
v(x), a(v(x); Z)

= v(x) + tanh(a(v(x); Z). We simplify the memory update by dropping the
tanh(·) rescaling. Figure 5 shows the varying importance the model assigns to different parts of the
input space depending on the class under consideration. For the separate blue class, the model is
signiﬁcantly more conﬁdent in relative terms and absolute values."
REFERENCES,0.8933333333333333,"B.3
EXPERIMENTS ON REAL DATA"
REFERENCES,0.8966666666666666,"All experiments are implemented in PyTorch (Paszke et al., 2019) version 1.7.1 and trained on a
TITAN RTX. They have been replicated ten times over random initial seeds."
REFERENCES,0.9,"Fashion MNIST (FMNIST).
We use a LeNet5-sized architecture (see Table 3). The out-of-
distribution data is the MNIST (LeCun et al., 2010) data set. We z-score normalize all data sets with
the in-domain mean and standard deviations. We train each model for 50 epochs with the Adam
optimizer (Kingma & Ba, 2015) using a learning rate of 0.001."
REFERENCES,0.9033333333333333,"3Originally due to Fisher (1936) and Anderson (1935).
We rely on the version provided by the
scikit learn library, see https://scikit-learn.org/stable/modules/classes.html#
module-sklearn.datasets."
REFERENCES,0.9066666666666666,Published as a conference paper at ICLR 2022
REFERENCES,0.91,"Table 3: The neural network architectures used for the FMNIST, CIFAR10, and SVHN data set with
ReLU activations between the layers."
REFERENCES,0.9133333333333333,"FMNIST
CIFAR10/SVHN"
REFERENCES,0.9166666666666666,"Convolution (5 × 5) with 20 channels
Convolution (5 × 5) with 192 channels
MaxPooling (2 × 2) with stride 2
Convolution (5 × 5) with 50 channels
Convolution (5 × 5) with 192 channels
MaxPooling (2 × 2) with stride 2
Linear with 500 neurons
Linear with 1000 neurons
Linear with 10 neurons"
REFERENCES,0.92,"CIFAR100
Layer Name
ResNet-18"
REFERENCES,0.9233333333333333,"Conv1
7 × 7, 64, stride 2"
REFERENCES,0.9266666666666666,"Conv2_x
3 × 3 max pool, stride 2

3 × 3, 64
3 × 3, 64 
× 2"
REFERENCES,0.93,"Conv3_x

3 × 3, 128
3 × 3, 128 
× 2"
REFERENCES,0.9333333333333333,"Conv4_x

3 × 3, 256
3 × 3, 256 
× 2"
REFERENCES,0.9366666666666666,"Conv5_x

3 × 3, 512
3 × 3, 512 
× 2"
REFERENCES,0.94,"Average Pool
7 × 7 average pool
Linear
100 neurons"
REFERENCES,0.9433333333333334,"IMDB
Layer Name
LSTM"
REFERENCES,0.9466666666666667,"Embedding
1001 →64
LSTM
2 layers with 256 hidden size
Linear
2 neurons"
REFERENCES,0.95,"CIFAR10 (C10).
We use a LeNet5-sized architecture (see Table 3). The out-of-distribution data is
the SVHN (Netzer et al., 2011). We z-score normalize all data sets with the in-domain mean and
standard deviations. We further rely on data augmentation for the in domain data using random crops
with 32 pixels and four pixel padding as well as horizontal ﬂips. We train each model for 100 epochs
using the Adam optimizer (Kingma & Ba, 2015) with a learning rate of 0.0001."
REFERENCES,0.9533333333333334,"SVHN.
We use a LeNet5-sized architecture (see Table 3). The out-of-distribution data is the
CIFAR10 data set. We z-score normalize all data sets with the in-domain mean and standard
deviations. We train each model for 100 epochs using the Adam optimizer (Kingma & Ba, 2015)
with a learning rate of 0.0001."
REFERENCES,0.9566666666666667,"IMDB Sentiment Classiﬁcation.
We use a LSTM architecture with 64 embedding dimensions
and 2 layers with 256 hidden dimensions. We generate the out-of-distribution data by sampling
values from the [1, 1000]interval uniformly at random. We train each model for 20 epochs using the
SGD optimizer (Robbins & Monro, 1951) with a learning rate of 0.05 and 0.9 momentum. For data
preparation, we follow the source code of the original work 4."
REFERENCES,0.96,"Shared Details and Observations.
In all experiments, we train the BNN models with a cross-
entropy loss using softmax as the squashing function to calculate class probabilities. The EDL model
is trained with the original loss (Sensoy et al., 2018). We make our predictions with the mean of
the Dirichlet distribution as in the original work. For all models, we use entropy as the criterion for
detecting out-of-distribution instances."
REFERENCES,0.9633333333333334,4https://www.kaggle.com/arunmohan003/sentiment-analysis-using-lstm-pytorch
REFERENCES,0.9666666666666667,Published as a conference paper at ICLR 2022
REFERENCES,0.97,"Table 4: Quantitative results of models on the FMNIST-C, CIFAR10-C and SVHN-C test dataset
using the LeNet5. The table below reports mean ± three standard deviations."
REFERENCES,0.9733333333333334,"FMNIST-C
CIFAR10-C
SVHN-C"
REFERENCES,0.9766666666666667,"Severity
Method
Err (%) (↓)
ECE (%) (↓)
(↓)
ECE (%) (↓)
(↓)
ECE (%) (↓) 1"
REFERENCES,0.98,"BNN
9.4±2.8
8.0±2.4
21.9±4.5
7.6±2.9
8.8±1.2
7.3±1.0
EDL
9.9±2.6
4.3±1.0
25.1±4.6
10.4±1.3
8.1±1.2
4.6±0.6
ENP
9.3±2.7
5.9±0.5
35.9±6.0
4.3±1.7
8.1±1.3
11.4±1.0
ETP
9.5±2.8
3.0±1.0
21.9±4.6
3.6±2.2
8.0±1.2
3.0±0.4 2"
REFERENCES,0.9833333333333333,"BNN
9.9±2.3
8.3±1.9
26.1±5.3
10.0±3.7
8.9±1.2
7.3±0.9
EDL
10.5±2.1
4.5±0.8
29.1±5.1
10.1±1.6
8.2±1.1
4.6±0.6
ENP
9.9±2.3
6.1±1.0
41.1±6.6
5.2±2.1
7.8±1.2
11.7±1.1
ETP
10.1±2.4
3.1±0.8
26.1±5.3
5.2±2.8
7.7±1.1
3.0±0.5 3"
REFERENCES,0.9866666666666667,"BNN
10.7±2.3
9.0±1.9
30.0±7.6
12.3±5.3
9.2±1.6
7.5±1.2
EDL
11.4±2.1
4.9±0.9
32.6±7.0
9.8±1.5
8.5±1.5
4.7±0.7
ENP
10.8±2.3
6.4±1.6
44.8±9.0
7.0±3.4
8.5±1.7
11.8±1.5
ETP
11.1±2.4
3.5±0.9
29.8±7.2
6.8±3.8
8.2±1.5
3.2±0.6 4"
REFERENCES,0.99,"BNN
12.2±4.2
10.2±3.6
35.1±10.9
15.9±8.3
9.9±2.5
8.0±1.9
EDL
12.9±4.2
5.6±1.8
37.3±10.0
9.6±1.4
9.1±2.4
5.1±1.0
ENP
12.4±4.3
6.5±2.2
48.9±11.2
9.2±5.4
9.4±2.8
12.3±2.2
ETP
12.8±4.6
4.1±1.8
34.8±10.3
9.7±6.4
9.1±2.4
3.2±1.0 5"
REFERENCES,0.9933333333333333,"BNN
14.2±5.4
11.7±4.6
42.4±13.7
21.0±10.4
10.2±2.5
8.2±1.9
EDL
15.1±5.8
6.7±3.1
43.9±12.5
9.5±2.4
9.4±2.4
5.1±1.1
ENP
14.8±6.5
6.9±3.1
54.6±12.7
12.5±7.0
9.5±2.8
12.4±2.3
ETP
15.3±7.1
5.2±3.4
42.1±13.1
14.1±8.6
9.0±2.5
3.3±1.0"
REFERENCES,0.9966666666666667,"Robustness against perturbations.
We use the CIFAR10-C dataset in the same setup as in original
work tHendrycks & Dietterich (2019). As FMNIST-C and SVHN-C are not available, we create
them following the same procedure as in the original work. For FMNIST we adapt the procedure
to gray-scale images by replicating the image three times for each channel. After applying the
distortions, we map it back to the gray scale. Table 4 gives the numerical results used to create Figure
3 in the main paper."
