Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0009398496240601503,"Transformers have achieved extraordinary success in modern machine learning due
to their excellent ability to handle sequential data, especially in next-token predic-
tion (NTP) tasks. However, the theoretical understanding of their performance in
NTP is limited, with existing studies focusing mainly on asymptotic performance.
This paper provides a fine-grained non-asymptotic analysis of the training dynam-
ics of a one-layer transformer consisting of a self-attention module followed by
a feed-forward layer. We first characterize the essential structural properties of
training datasets for NTP using a mathematical framework based on partial orders.
Then, we design a two-stage training algorithm, where the pre-processing stage
for training the feed-forward layer and the main stage for training the attention
layer exhibit fast convergence performance. Specifically, both layers converge
sub-linearly to the direction of their corresponding max-margin solutions. We also
show that the cross-entropy loss enjoys a linear convergence rate. Furthermore,
we show that the trained transformer presents non-trivial prediction ability with
dataset shift, which sheds light on the remarkable generalization performance of
transformers. Our analysis technique involves the development of novel properties
on the attention gradient and further in-depth analysis of how these properties
contribute to the convergence of the training process. Our experiments further
validate our theoretical findings."
INTRODUCTION,0.0018796992481203006,"1
Introduction"
INTRODUCTION,0.002819548872180451,"The transformer architecture (Vaswani et al., 2017) has revolutionized the field of machine learning,
establishing itself as a foundation model for numerous applications, including natural language
processing (NLP) (Devlin et al., 2018), computer vision (Dosovitskiy et al., 2020), and multi-modal
signal processing (Tsai et al., 2019). In particular, transformers achieve tremendous empirical success
in large language models (LLMs) such as GPT-3 (Brown et al., 2020). Despite the empirical success,
limited theoretical understanding of transformers have caused a series of critical concerns about their
robustness, interpretability, and bias issues (Bommasani et al., 2021; Belkin, 2024)."
INTRODUCTION,0.0037593984962406013,"To overcome these issues, recent advances in transformer theory have investigated the convergence of
training transformers under theoretically amenable setting such as linear regression (Mahankali et al.,
2023; Zhang et al., 2023; Huang et al., 2023) and binary classification (Tarzanagh et al., 2023b,a;
Vasudeva et al., 2024; Li et al., 2023). Nevertheless, one of the fundamental task in LLMs and other
generative models is next-token prediction (NTP), which involves predicting the next word or token
in a sequence, given the previous tokens. In NTP, a few recent theoretical studies have started to
investigate the training dynamics of transformers (Tian et al., 2023a; Li et al., 2024). However, those
works lack of fine-grained non-asymptotic convergence analysis of the training process, posing the
following open questions for further investigation:"
INTRODUCTION,0.004699248120300752,How fast does the training of a transformer converge in NTP?
INTRODUCTION,0.005639097744360902,"In addition, a pre-trained transformer empirically exhibits non-trivial generalization ability. A
follow-up question from a theoretical point of view is that"
INTRODUCTION,0.006578947368421052,Can we show the generalization capability of a trained transformer on unseen data?
INTRODUCTION,0.007518796992481203,"In this paper, we take a first step towards addressing the aforementioned questions by studying the
training dynamics of a single layer transformer consisting of a self-attention layer and a feed-forward
layer for NTP. We summarize our contribution as follows."
INTRODUCTION,0.008458646616541353,"• We develop a mathematical framework based on partial order to formally characterize the essential
structural properties of the training dataset for next-token prediction. In particular, we introduce
a realizable setting for training datasets where the loss can be minimized to near zero, which
admits a collocation and query-dependent partial orders. A collocation is a set of token pairs
where each token is directly paired with its subsequent token. Query-dependent partial orders
is a set of partial orders where each partial order classifies tokens into three categories: optimal
tokens, non-optimal tokens and non-comparable tokens. These structural properties define favorable
max-margin problems on both the feed-forward layer and the self-attention layer.
• Second, we design a two-stage training algorithm based on normalized gradient descent. In
stage 1 of pre-processing, we use the collocation to train the feed-forward layer. In stage 2, we
use the entire dataset to train the self-attention layer. We show that the feed-forward layer and
the query-key attention matrix converge sublinearly in direction respectively to the max-margin
solution for classifying next token from all other tokens in the preprocessing dataset, and to the
max-margin solution for classifying the optimal from non-optimal tokens. In addition, the norm
of the transformer parameters grows linearly, which further yields a linear convergence rate of
the cross-entropy loss. Our two-stage algorithm decouples the training of the feed-forward and
attention layers without losing optimality, as stage 1’s max-margin solution is judiciously designed
to facilitate stage 2’s fine-grained classification for optimal token prediction.
• Third, we show that the trained transformer has generalization ability for making non-trivial
prediction on unseen data. In particular, the transformer is trained to learn an extended query-
dependent partial order, where the non-comparable tokens are inserted in between the optimal
tokens and non-optimal tokens. Thus, the trained transformer will attend to non-comparable tokens
if optimal tokens are not in a new sentence and further make desirable prediction."
RELATED WORK,0.009398496240601503,"2
Related Work"
RELATED WORK,0.010338345864661654,"Inspired by Brown et al. (2020), who demonstrated that pre-trained transformers can learn in-context
- i.e., learn new tasks during inference with only a few samples - a series of works focus on the
expressiveness power of transformers (Akyürek et al., 2022; Bai et al., 2023; Von Oswald et al., 2023;
Fu et al., 2023; Giannou et al., 2023; Lin et al., 2023). These studies have shown that there exist
parameter configurations such that transformers can perform various algorithms such as gradient
descent. Additionally, Edelman et al. (2022) showed that transformers can represent a sparse function."
RELATED WORK,0.011278195488721804,"Regarding the training dynamics and optimization of transformers under in-context learning, Ahn
et al. (2024); Mahankali et al. (2023); Zhang et al. (2023); Huang et al. (2023) studied the dynamics of
a single attention layer, single-head transformer for the in-context learning of linear regression tasks.
Cui et al. (2024) proved that multi-head attention outperforms single-head attention. Cheng et al.
(2023) showed that local optimal solutions in transformers can perform gradient descent in-context
for non-linear functions. Kim and Suzuki (2024) studied the nonconvex mean-field dynamics of
transformers, and Nichani et al. (2024) established a convergence rate of ˜O(1/t) for the training loss
in learning a causal graph. Additionally, Chen et al. (2024) investigated the gradient flow in training
multi-head attention. Chen and Li (2024) proposed a supervised training algorithm for multi-head
transformers."
RELATED WORK,0.012218045112781954,"Another line of research focuses on the training dynamics of transformers for binary classification
problems. Tarzanagh et al. (2023b,a) demonstrated an equivalence between the optimization dynamics
of a single attention layer and a certain SVM problem. While Tarzanagh et al. (2023b,a) only proved an
asymptotic convergence result, Vasudeva et al. (2024) improved the convergence rate to t−3/4. Li et al.
(2023) studied the training dynamics of vision transformers and showed that the generalization error"
RELATED WORK,0.013157894736842105,"can approach zero given sufficient training samples. Additionally, Deora et al. (2023) investigated the
training and generalization error under the neural tangent kernel (NTK) regime."
RELATED WORK,0.014097744360902255,"For transformers trained on next-token prediction (NTP), Tian et al. (2023a) analyzed the training
dynamics of a single-layer transformer, while Tian et al. (2023b) studied the joint training dynamics
of multi-layer transformers. Li et al. (2024) demonstrated the asymptotic convergence of transformers
trained with a logarithmic loss function for NTP. Although these works provided valuable insights
into the training dynamics of transformers for NTP, they did not provide the finite-time convergence
analysis, which is the focus of this paper. We remark that Thrampoulidis (2024) studied NTP without
transformer structure."
RELATED WORK,0.015037593984962405,"Our work is also related to the classical implicit bias framework for training neural networks (NNs).
In particular Soudry et al. (2018); Nacson et al. (2019); Ji and Telgarsky (2021); Ji et al. (2021)
established convergence rate of gradient descent-based optimization. Phuong and Lampert (2020);
Frei et al. (2022); Kou et al. (2024) studied the implicit bias of ReLU/Leaky-ReLU networks on
orthogonal data. A comprehensive survey is provided in Vardi (2023). However, these works focused
on classical neural networks, whereas we investigate the implicit bias of transformers for NTP."
PROBLEM SETUP,0.015977443609022556,"3
Problem Setup"
PROBLEM SETUP,0.016917293233082706,"Notations. All vectors considered in this paper are column vectors. We use 1{A} to denote the
indicator function of A, i.e., 1{A} = 1 if A holds, and 1{A} = 0 otherwise. ∥W∥represents the
Frobenious norm of the matrix W. For a vector v, we use [v]i to denote the i-th coordinate of v.
We use ϕ(v) to denote the softmax function, i.e., [ϕ(v)]i = exp(vi)/ P"
PROBLEM SETUP,0.017857142857142856,"j exp(e⊤
j v), which can be
applied to any vector with arbitrary dimension. We use {ei}i∈[|V|] to denote the canonical basis of
R|V|, i.e., [ei]j = 1{i = j}. The inner product ⟨A, B⟩of two matrices A, B equals to Trace(AB⊤)."
PROBLEM SETUP,0.018796992481203006,"Next-token prediction. We consider the task of next-token prediction, which aims to predict the
subsequent token in a token sequence given its preceding tokens. Formally, suppose that there exists
a finite vocabulary set V ⊂Rd that consists of all possible tokens, where d is the dimension of the
embedding. Each token x ∈V is associated with a unique index I(x) ∈{1, 2, . . . , |V|}, where I is the
index function. An L-length sentence X = [x1, . . . , xL] ∈VL ⊂Rd×L is a sequence of L tokens,
where L is an integer. We assume that the maximum length of sentences is Lmax. The subsequent
tokens in sentences are generated from a set of ground-truth model {p∗
L : VL →V}L<Lmax,
where p∗
L generates the next token xL+1 given the sentence X for any 1 ≤L < Lmax. The
task of next-token prediction requires us to learn all models {p∗
L}L<Lmax given a training dataset
D0 = {(X, xL+1)|L < Lmax, X ∈VL, xL+1 ∈V}. Notably, if X = [x1, . . . , xL] ∈D0, then for
any ℓ< L, ([x1, . . . , xℓ], xℓ+1) is also a training sample, since it follows p∗
ℓas well."
PROBLEM SETUP,0.019736842105263157,"Decoder-only transformer. A decoder-only transformer is a stack of blocks consisting of a self-
attention layer and a feed-forward layer. For simplicity, we consider one-layer transformer, where the
self-attention layer is determined by three matrices: Wk ∈Rd×d1, Wq ∈Rd1×d and Wv ∈Rd2×d,
namely key, query, and value matrices, and the feed-forward layer is determined by Wo ∈R|V|×d2.
Here d1, d2 are hidden dimensions. Mathematically, given the input X = [x1 . . . , xL], we write
the one-layer transformer as Tθ(X) := ϕ(WoWvXϕ(X⊤WkWqxL)) ∈[0, 1]|V|, where θ :=
(Wo, Wv, Wk, Wq), and ϕ is the softmax function. We note that the inner softmax function ϕ is part
of the attention model, and the outer softmax function ϕ is the decoder that generates a probability
distribution over V for token prediction."
PROBLEM SETUP,0.020676691729323307,"Reparameterization. We reparameterize the transformer architecture by consolidating the key and
query matrices into a unified matrix Wkq, such that Wkq = WkWq. Similarly, we reparameterize
the product of the feed-forward (Wo) and value (Wv) matrices as a single matrix Wov, defined as
Wov = WoWv. Such a reparameterization is commonly adopted in transformer theory works (Huang
et al., 2023; Tian et al., 2023a; Li et al., 2024; Nichani et al., 2024). Thus, the transformer under
those reparameterization is given by Tθ(X) := ϕ(WovXϕ(X⊤WkqxL)) ∈[0, 1]|V|."
PROBLEM SETUP,0.021616541353383457,"Cross-entropy loss. Given the training dataset D0 and the transformer model, we seek to learn p∗by
minimizing (training) the cross-entropy loss L(θ) defined as follows:"
PROBLEM SETUP,0.022556390977443608,L(θ) = −1 |D0| X
PROBLEM SETUP,0.023496240601503758,"(X,xL+1)∈D0
log e⊤
I(xL+1)Tθ(X),"
PROBLEM SETUP,0.02443609022556391,where I(xL+1) is the index of xL+1 in V.
REALIZABLE TRAINING DATASET AND TWO-STAGE ALGORITHM,0.02537593984962406,"4
Realizable Training Dataset and Two-Stage Algorithm"
REALIZABLE TRAINING DATASET AND TWO-STAGE ALGORITHM,0.02631578947368421,"In this section, we first provide a mathematical framework based on partial order to formally
characterize a realizable training dataset for next-token prediction. We will then describe a two-stage
algorithm for next-token prediction that we study."
REALIZABLE TRAINING DATASET,0.02725563909774436,"4.1
Realizable Training Dataset"
REALIZABLE TRAINING DATASET,0.02819548872180451,"We characterize a realizable training dataset via two structural properties, where the training loss can
be made arbitrarily close to zero. We first provide some intuitions about those two properties."
REALIZABLE TRAINING DATASET,0.02913533834586466,"Existence of “collocation”. First, we note that if a sentence X = [x1, . . . , xL] is a legal training
sample, ([x1], x2) is also in the training dataset. In addition, the output of a transformer given one
single input token only depends on Wov, i.e. the feed-forward layer. Since training loss can be
arbitrarily close to 0, there exists a sequence {Wt} such that limt→∞−P"
REALIZABLE TRAINING DATASET,0.03007518796992481,"x∈D0 log eι(x)⊤ϕ(Wtx) =
0, where ι(x) is the index of next token of x, and the summation is over the case when x is the first
token. Due to that ϕ(Wtx) is a probability distribution, the equality holds only when ι is injective,
since otherwise it is an entropy of some distribution which is strictly greater than 0. Therefore, there
exists an injective map n : V →V such that every sentence starts with x, must have a unique next
token n(x). We call the set of pairs {x, n(x)}x∈V a collocation. We remark that p∗
1 = n."
REALIZABLE TRAINING DATASET,0.03101503759398496,"Existence of “order”. Second, let us consider the output of a transformer Tθ given a legal sentence
X = [x1, . . . , xL] with the next token xL+1 = p∗
L(X). The transformer first calculates a convex
combination of x1, . . . , xL with corresponding weight φℓ∝exp(x⊤
ℓWkqxL) for each ℓ≤L. Then,
the transformer outputs ϕ(P"
REALIZABLE TRAINING DATASET,0.03195488721804511,"ℓWovxℓφℓ). Recall that the collocation forces xℓto map to n(xℓ), thus
ϕ(Wovxℓ) has a peak value at the coordinate equal to I(n(xℓ)) (the index of n(xℓ)). Hence, Tθ(X)
can only have peak value at the coordinates within the set {I(n(xℓ))}ℓ≤L. If the training loss can
be arbitrarily close to 0, it is desirable to have n−1(xL+1) ∈{xℓ}ℓ≤L. Therefore, for those xℓwith
n(xℓ) = xL+1, φℓmust be larger than φℓ′ with n(xℓ′) ̸= xL+1. Finally, it worth noting that φℓ
depends on the final token xL. This observation motivates us to define query-dependent partial orders
on V."
REALIZABLE TRAINING DATASET,0.03289473684210526,"Definition 1 (xq-partial order) Fix a token xq. An xq-partial order assigns an ordering relationship
>xq for certain pairs of tokens in V, and is created as follows. Let Dxq
0 be the set of all legal sentences
in the training dataset that has the final token (query) xq. Then, for any pair of tokens x, x′ ∈V, we
assign x >xq x′ if there exists a sentence X = [x1, . . . , xL] ∈Dxq
0 and x, x′ are tokens in X such
that n(x) = xL+1 ̸= n(x′), where xL+1 is the next token of X."
REALIZABLE TRAINING DATASET,0.03383458646616541,"Note that Definition 1 is a “constructive definition” which might not be well-defined. However, as
we are under the setting when the training loss can be arbitrarily close to 0, the aforementioned
discussion shows that if x >xq x′, then φℓ> φℓ′, where x = xℓand x′ = xℓ′ in some sentence.
Thus, exp(xWkqxq) > exp(x′Wkqxq), which indeed need to be well-defined. Otherwise, we will
have contradictions such as exp(xWkqxq) > exp(x′Wkqxq) < exp(xWkqxq). Mathematically, a
well-defined (strict) partial order > on a set V satisfies two axioms (Yannakakis, 1982): (i) there is no
x > x; (ii) if x > x′ and x′ > x′′, then x > x′′. Thus, xq-partial order created by D0 is well-defined
for every xq ∈V."
REALIZABLE TRAINING DATASET,0.03477443609022556,"Finally, let us discuss the impact of query-dependent partial orders on D0. For a given query xq, the
partial order >xq divides tokens in V into four disjoint types."
REALIZABLE TRAINING DATASET,0.03571428571428571,"• (Strict) optimal tokens. A token x is optimal, if there is no x′ such that x′ >xq x1.
• Confused tokens. A token x is confused, if there exists x′, x′′ such that x′ >xq x >xq x′′.
• (Strict) non-optimal tokens. A token x is non-optimal if there is no x′ such that x >xq x′2.
• Non-comparable tokens. A token x is non-comparable if there is no x′ such that x >xq x′ or
x′ >xq x."
REALIZABLE TRAINING DATASET,0.03665413533834586,"1This is also related to the maximal element in a partially ordered set.
2This is also related to the minimal element in a partially ordered set."
REALIZABLE TRAINING DATASET,0.03759398496240601,"In this work, we assume that there are no confused tokens. This assumption simplifies the problem,
making it tractable to provide explicit convergence in direction for training a transformer in Section 5.
In summary, we make the following structural assumption on the training dataset."
REALIZABLE TRAINING DATASET,0.03853383458646616,"Assumption 1 (Realizable training dataset) D0 admits (i) a collocation {x, n(x)}x∈V; (ii) well-
defined query-dependent partial orders, where every xq-partial order has no confused tokens."
REALIZABLE TRAINING DATASET,0.039473684210526314,"We remark that combining the collocation and query-dependent partial orders, we can regenerate the
training dataset as follows. For any sentence with only one token X = [x], the next token is n(x).
For other sentences X = [x1, . . . , xL], let xℓbe optimal under the partial order >xL, and then the
next token of X is n(xℓ). We next provide a simple example that justifies Assumption 1."
REALIZABLE TRAINING DATASET,0.040413533834586464,"Example 1 Consider a language system where the vocabulary consists of four tokens {S, V, O,
P}, where S,V,O,P respectively stand for subject, verb, object, and punctuation mark. This system
admits the commonly adopted word order (Dryer, 1991): S, V, O, P. Let the training dataset be
{SVOP, VOP, OPP, PSV}."
REALIZABLE TRAINING DATASET,0.041353383458646614,"Let us create the corresponding collocation and the query-dependent partial orders from the dataset.
The collocation is {(S, V), (V, O), (O, P), (P, S)}. That is, if a sentence starts with a subject, then the
next token is a verb. Similarly, if a sentence starts with a verb, then the next token is an object, and so
on. The query-dependent partial orders are created as follows:"
REALIZABLE TRAINING DATASET,0.042293233082706765,"Partial order under query S. S>SP.
Partial order under query O. O>OS, O>OV.
Partial order under query V. V>VS.
Partial order under query P. O>PP."
REALIZABLE TRAINING DATASET,0.043233082706766915,"Therefore, if a sentence starts with S (subject), the next token is V (verb) according to the collocation.
Then, for the sentence SV, since the query is V and V>VS, the next token of the sentence coincides
with the next token of V, which is exactly O (object). Finally, for the sentence SVO, following similar
argument, the next token is P (punctuation mark). This example satisfies Assumption 1 and aligns
with real-world scenarios. An illustration is provided in Figure 1."
REALIZABLE TRAINING DATASET,0.044172932330827065,"Figure 1: The left plot shows the mapping from sentence to the next token. The red rectangle indicates
the optimal token in the corresponding sentence. The right plot shows the collocation relationship."
REALIZABLE TRAINING DATASET,0.045112781954887216,"Additional notations of training data. It is worth noting that there are only finite number of distinct
sentences. For ease of presentation, we introduce the following notations. Suppose there are N
distinct sentences in the training dataset D0 indexed by n ∈{1, . . . , N}. For each distinct sentence"
REALIZABLE TRAINING DATASET,0.046052631578947366,"X(n), we calculate its frequency π(n) ∈[0, 1] in dataset D0 as π(n) = P"
REALIZABLE TRAINING DATASET,0.046992481203007516,"(X,xL+1)∈D0 1{X=X(n)}"
REALIZABLE TRAINING DATASET,0.047932330827067667,"|D0|
."
REALIZABLE TRAINING DATASET,0.04887218045112782,"Building upon this, with a little abuse of notation, we use n(X(n)) ∈V to denote the subsequent
token of the sentence X(n) and In(X(n)) to denote the index of n(X(n))."
REALIZABLE TRAINING DATASET,0.04981203007518797,"We further denote X(n)
−1 as the final token of X(n), and let ¯Tθ(X) = WovXϕ(X⊤WkqX(n)
−1 ). Then,
the loss function L(θ) can be rewritten as follows:"
REALIZABLE TRAINING DATASET,0.05075187969924812,"L(θ) =
X"
REALIZABLE TRAINING DATASET,0.05169172932330827,"n
π(n) log X"
REALIZABLE TRAINING DATASET,0.05263157894736842,"v
exp

e⊤
v ¯Tθ(X(n))
!"
REALIZABLE TRAINING DATASET,0.05357142857142857,"−e⊤
In(X(n)) ¯Tθ(X(n)) ! .
(1)"
TRAINING ALGORITHM,0.05451127819548872,"4.2
Training Algorithm"
TRAINING ALGORITHM,0.05545112781954887,"For the realizable dataset satisfying Assumption 1, we propose a two-stage training algorithm using
normalized gradient descent (NGD). The pseudo code of the algorithm is presented in Algorithm 1.
In Section 5, we show that the two-stage algorithm decouples the training of the feed-forward and"
TRAINING ALGORITHM,0.05639097744360902,"attention layers without losing the optimality. This is because the training in stage 1 is designed to
yield a suitable max-margin solution, which will enable the training of stage 2 to solve a fine-grained
classifcation problem and identify the optimal token for prediction."
TRAINING ALGORITHM,0.05733082706766917,"In the first stage of pre-processing, we use the collocation set to train the feed-forward layer Wov.
For simplicity, we introduce the following notation for the training loss of the feed-forward layer.
Given a collocation {x, n(x)}x∈V, which can be obtained through extracting all length-2 sentences
in the training dataset D03, we use normalized gradient descent to train Wov. Equivalently, the loss
function can be written as"
TRAINING ALGORITHM,0.05827067669172932,"L0(Wov) = −
X"
TRAINING ALGORITHM,0.05921052631578947,"x∈V
log
exp(e⊤
In(x)Wovx)
P"
TRAINING ALGORITHM,0.06015037593984962,"v≤|V| exp(e⊤
v Wovx),"
TRAINING ALGORITHM,0.06109022556390977,"where the self-attention elements are removed because the attention matrices are not trained here.
Based on the above loss function, we initialize W (0)
ov = 0 ∈R|V|×d, and subsequently take an update
at each time t by NGD as in line 4 of Algorithm 1."
TRAINING ALGORITHM,0.06203007518796992,"In the second stage, we fix the trained feed-forward layer and train the self-attention layer based on
the loss function given in Equation (1) and using the entire dataset D0. Specifically, we initialize
Wkq = 0 ∈Rd×d, and subsequently take an update at each time t by NGD as in line 7 of Algorithm 1."
TRAINING ALGORITHM,0.06296992481203008,Algorithm 1 Two-stage Normalized Gradient Descent
TRAINING ALGORITHM,0.06390977443609022,"1: Initialization: W (0)
ov = 0 ∈R|V|×d, Wkq = 0 ∈Rd×d.
2: Input: A collocation {x, n(x)}x∈V, and a training dataset D0, learning rate η0, η.
3: for t ∈{0, 1, ..., T −1} do"
TRAINING ALGORITHM,0.06484962406015038,"4:
Update W (t+1)
ov
as W (t+1)
ov
= W (t)
ov −η0
∇Wov L0(W (t)
ov )"
TRAINING ALGORITHM,0.06578947368421052,"∥∇Wov L0(W (t)
ov )∥."
TRAINING ALGORITHM,0.06672932330827068,"5: end for
6: for t ∈{0, . . . , T1 −1} do"
TRAINING ALGORITHM,0.06766917293233082,"7:
Update W (t+1)
kq
as W (t+1)
kq
= W (t)
kq −η
∇WkqL(θ(t))"
TRAINING ALGORITHM,0.06860902255639098,"∥∇WkqL(θ(t))∥, where θ(t) = (W (T )
ov , W (t)
kq )."
TRAINING ALGORITHM,0.06954887218045112,8: end for
TRAINING DYNAMICS OF THE TRANSFORMER,0.07048872180451128,"5
Training Dynamics of the Transformer"
TRAINING DYNAMICS OF THE TRANSFORMER,0.07142857142857142,"In this section, we present the convergence result for Algorithm 1. Before we proceed, we first
introduce the following technical assumption, which has been commonly adopted in the previous
theoretical studies of transformers (Huang et al., 2023; Li et al., 2024; Tian et al., 2023a)."
TRAINING DYNAMICS OF THE TRANSFORMER,0.07236842105263158,"Assumption 2 The vocabulary set is orthornormal. Namely, the embedding has unit norm, i.e.,
∥x∥= 1, and x⊤x′ = 0 holds for any distinct tokens x and x′."
CONVERGENCE OF TRAINING WOV,0.07330827067669173,"5.1
Convergence of Training Wov"
CONVERGENCE OF TRAINING WOV,0.07424812030075188,"To characterize the training dynamics of Wov, we observe that the collocation {(x, n(x))}x∈V defines
the following hard-margin problem:"
CONVERGENCE OF TRAINING WOV,0.07518796992481203,"W ∗
ov = arg min ∥W∥,
s.t.
(ev∗−ev)Wx ≥1,
∀v∗= In(x), v ̸= In(x).
(2)"
CONVERGENCE OF TRAINING WOV,0.07612781954887218,"It can be shown that limB→+∞L0(BW ∗
ov) = 0. Thus, the loss function L0 trains Wov to be the
max-margin solution with Wovx distinguishing the next token n(x) from all other tokens in V."
CONVERGENCE OF TRAINING WOV,0.07706766917293233,"Since L0(·) is convex, we have the following convergence result on the training of W (t)
ov ."
CONVERGENCE OF TRAINING WOV,0.07800751879699248,"Proposition 1 Let W ∗
ov be defined in Equation (2). Under Assumptions 1-2, let W (t)
ov be updated by
Algorithm 1. Then, for any t ≥2, we have
tη0
2∥W ∗
ov∥≤∥W (t)
ov ∥≤tη0 and the following bound holds:"
CONVERGENCE OF TRAINING WOV,0.07894736842105263,"3A more general way is to use various standard techniques developed in linguistic analysis (Lehecka, 2015)."
CONVERGENCE OF TRAINING WOV,0.07988721804511278,"*
W (t)
ov
∥W (t)
ov ∥
, W ∗
ov
∥W ∗ov∥ +"
CONVERGENCE OF TRAINING WOV,0.08082706766917293,"≥1 −5∥W ∗
ov∥3 log(2|V|) log t tη0
."
CONVERGENCE OF TRAINING WOV,0.08176691729323309,"Moreover, the loss function L0 satisfies that L0(W (t)
ov ) ≤O(exp(−η0t/(4∥W ∗
ov∥)))."
CONVERGENCE OF TRAINING WOV,0.08270676691729323,"Proposition 1 states that during the training stage 1, the feed-forward layer W (t)
ov converges in
direction to W ∗
ov/∥W ∗
ov∥at a rate of O(log t/t), which classifies the next token from all other tokens.
In addition, since the norm of W (t)
ov increases linearly, the loss L0(W (t)
ov ) converges linearly to zero,
i.e., L0(W (t)
ov ) = O(exp(−C0t)) for some constant C0."
CONVERGENCE OF TRAINING WKQ,0.08364661654135339,"5.2
Convergence of Training Wkq"
CONVERGENCE OF TRAINING WKQ,0.08458646616541353,"Recall that after the training stage 1 with T steps, we obtain a trained feed-forward layer W (T )
ov .
Then, we fix W (T )
ov
and use normalized gradient descent to train Wkq. To characterize the training
dynamics of the key-query matrix Wkq, we note that each query-dependent partial order also defines
a hard-margin problem. Let l(n) ⊂{1, . . . , L(n)} be the set of indices of the optimal tokens of X(n).
Recall that xℓis optimal if there is no xℓ′ such that xℓ′ >X(n)
−1 xℓand In(xℓ) = In(X(n)). That is,"
CONVERGENCE OF TRAINING WKQ,0.08552631578947369,"WkqX(n)
−1 should correctly classify optimal tokens xℓand non-optimal tokens xℓ′. This is formalized
in the following problem:"
CONVERGENCE OF TRAINING WKQ,0.08646616541353383,"W ∗
kq = arg min ∥W∥,
s.t.
(x(n)
ℓ∗−x(n)
ℓ
)WX(n)
−1 ≥1,
∀ℓ∗∈l(n), ℓ/∈l(n), ∀n.
(3)"
CONVERGENCE OF TRAINING WKQ,0.08740601503759399,"We will show that the loss function in Equation (1) given the well trained W (T )
ov
will train Wkq towards
the max-margin solution W ∗
kq in direction for classifying between the optimal and non-optimal token.
We further make the following technical assumption."
CONVERGENCE OF TRAINING WKQ,0.08834586466165413,"Assumption 3 For any sample X(n), the number of optimal tokens is not less than the number of
non-optimal tokens. Formally, for any non-optimal token x in X(n), we have |l(n)| ≥P
ℓ1{xℓ= x}."
CONVERGENCE OF TRAINING WKQ,0.08928571428571429,"Assumption 3 is consistent with practical and empirical observations, where optimal tokens often
demonstrate higher relevance, making them more frequent in subsequent outcomes."
CONVERGENCE OF TRAINING WKQ,0.09022556390977443,We now present the convergence result for the training of the key-query matrix in stage 2.
CONVERGENCE OF TRAINING WKQ,0.09116541353383459,"Theorem 1 Let Assumptions 1-3 hold. Let W ∗
kq be the solution of Equation (3). Let η < O(1) and"
CONVERGENCE OF TRAINING WKQ,0.09210526315789473,"W (t)
kq be updated by Algorithm 1. Then, for any t ≥2, we have that
tη
2∥W ∗
kq∥≤∥W (t)
kq ∥≤tη. In
addition, the following inequality holds.
*
W (t)
kq
∥W (t)
kq ∥
,
W ∗
kq
∥W ∗
kq∥ +"
CONVERGENCE OF TRAINING WKQ,0.09304511278195489,"≥1 −
54NL4
max∥W ∗
kq∥4 log2 t
tη
."
CONVERGENCE OF TRAINING WKQ,0.09398496240601503,"Theorem 1 states that the key-query matrix Wkq converges in direction to the max-margin solution
W ∗
kq/∥W ∗
kq∥at a convergence rate of O(log2 t/t). We further show that the norm of Wkq also grows
linearly in t, i.e., ∥Wkq∥= Ω(t). Combining these results, we have the following theorem on the
convergence of the loss function and the training accuracy."
CONVERGENCE OF TRAINING WKQ,0.09492481203007519,"Theorem 2 (Loss Convergence) For any training sentence X(n) = [x(n)
1 , . . . , x(n)
L ], let φ(n,t)
ℓ
∝
exp(x(n)
ℓ
W (t)
kq x(n)
L ) be the attention weight. Under the conditions in Theorem 1, there is an absolute
constant c0 such that when T ≥c0∥W ∗
ov∥5 log(|V|) log T/η0 and t ≥c0NL4
max∥W ∗
kq∥6 log2 t/η,"
CONVERGENCE OF TRAINING WKQ,0.09586466165413533,"the optimal token weight satisfies minn
P"
CONVERGENCE OF TRAINING WKQ,0.09680451127819549,"ℓ∗∈l(n) φ(n,t)
ℓ∗
≥(1 + Lmax exp (−tC1)))−1. In addition,
the loss function L converges linearly4 to its minimal value:"
CONVERGENCE OF TRAINING WKQ,0.09774436090225563,"L(θ(t)) = L(W (T )
ov , W (t)
kq ) ≤|V| exp

−TC0"
CONVERGENCE OF TRAINING WKQ,0.09868421052631579,"
1 −
2Lmax
Lmax + exp(C1t)"
CONVERGENCE OF TRAINING WKQ,0.09962406015037593,"
,
(4)"
CONVERGENCE OF TRAINING WKQ,0.10056390977443609,"4For fixed W (T )
ov , the minimum loss value L∗= |V| exp(−TC0). Then Equation (4) implies L(θ(t))−L∗≤
L∗TC0O(e−C1t) for sufficiently large t, which further implies the linear convergence in t."
CONVERGENCE OF TRAINING WKQ,0.10150375939849623,"where C0 =
η0
4∥W ∗
ov∥2 and C1 = η/(4Lmax∥W ∗
kq∥2)."
CONVERGENCE OF TRAINING WKQ,0.10244360902255639,"Theorem 2 shows that the training loss converges to its minimum value at a linear convergence rate.
Furtherm, for T = Ω(log(1/ϵ0)) t = Ω(log(1/ϵ)), the optimal token weight is given by 1/(1 + ϵ)
for any ϵ > 0, which is close to 1. This implies that the trained transformer attends to the optimal
token and thus outputs the correct next token n(x(n)
ℓ∗) with probability 1 −O(ϵ0)."
CONVERGENCE OF TRAINING WKQ,0.10338345864661654,"5.3
Proof Sketch of Theorem 1"
CONVERGENCE OF TRAINING WKQ,0.10432330827067669,"The proof consists of the following three main steps. The key proof step lies in carefully analyzing the
projection of gradient ∇WkqL(θ(t)) onto the token-query outer product x(n)
ℓ
(X(n)
−1 )⊤, max-margin
attention weight matrix W ∗
kq, and the trained attention weight matrix W (t)
kq ."
CONVERGENCE OF TRAINING WKQ,0.10526315789473684,"Step 1 (Lemma 5). By analyzing
D
∇WkqL(θ(t)), x(n)
ℓ
(X(n)
−1 )⊤E
, we characterize the dynamics of
attention weights. Using mathematical induction, we show that the lower bound of optimal token
weight is 1/Lmax."
CONVERGENCE OF TRAINING WKQ,0.106203007518797,"Step 2 (Lemma 6). Then, we show that the cosine similarity between the negative gradient and W ∗
kq
is strictly larger than the minimum optimal token weight. Utilizing step 1, due to the NGD update,
the norm of the key-query matrix W (t)
kq can be shown to grow linearly."
CONVERGENCE OF TRAINING WKQ,0.10714285714285714,"Step 3 (Lemma 7). Finally, we carefully compare the difference between the projections from
gradient to the trained attention matrix and max-margin attention matrix. By separately evaluating
the impact of the optimal and non-optimal tokens on those projections, we can show the following
inequality for some constant C0:"
CONVERGENCE OF TRAINING WKQ,0.1080827067669173,"D
∇WkqL(θ(t)), W (t)
kq
E
≥ "
CONVERGENCE OF TRAINING WKQ,0.10902255639097744,"1 +
C0 log ∥W (t)
kq ∥"
CONVERGENCE OF TRAINING WKQ,0.1099624060150376,"∥W (t)
kq ∥"
CONVERGENCE OF TRAINING WKQ,0.11090225563909774,"! D
∇WkqL(θ(t)), W ∗
kq
E ∥W (t)
kq ∥"
CONVERGENCE OF TRAINING WKQ,0.1118421052631579,"∥W ∗
kq∥."
CONVERGENCE OF TRAINING WKQ,0.11278195488721804,"Utilizing step 2’s result that ∥W (t)
kq ∥grows linearly, the dynamics of the attention layer can be shown
to converge in direction to the max-margin solution in Equation (3)."
GENERALIZATION ABILITY,0.1137218045112782,"6
Generalization Ability"
GENERALIZATION ABILITY,0.11466165413533834,"In this section, we prove the generalization ability of the trained transformers. Recall that Theorem 1
shows that W (t)
kq converges to W ∗
kq∥W (t)
kq ∥/∥W ∗
kq∥. To characterize the generalization ability, it is
desirable to use the property of W ∗
kq, which is given in the following result."
GENERALIZATION ABILITY,0.1156015037593985,"Proposition 2 Under Assumptions 1-2, fix a query token xq, let Oxq, Nxq, Mxq ⊂V be the set of
optimal tokens, the set of non-optimal tokens, and the set of non-comparable tokens, under xq-partial
order, respectively. Then, the solution W ∗
kq of Equation (3) satisfies x⊤
0 W ∗
kqxq = 0 for x0 ∈Mxq,
and"
GENERALIZATION ABILITY,0.11654135338345864,"x⊤
∗W ∗
kqxq =
|Nxq|
|Oxq| + |Nxq|,
x⊤W ∗
kqxq = −
|Oxq|
|Oxq| + |Nxq|,
∀x∗∈Oxq, x ∈Nxq."
GENERALIZATION ABILITY,0.1174812030075188,"Recall that non-comparable tokens (see Section 4) under a query xq never appears in any training
sentence data with the same query xq. Thus, Proposition 2 implies an interesting generalization
capability – each xq-partial order can automatically incorporate more relationships to expand the
query-dependent partial orders. Combining Proposition 2 with Theorem 1, we obtain the following
theorem on W (t)
kq ."
GENERALIZATION ABILITY,0.11842105263157894,"Theorem 3 Under the conditions and notations in Proposition 2, let T = Ω(log(1/ϵ)), and t =
Ω(log(1/ϵ)). Then there exists a constant C0 such that"
GENERALIZATION ABILITY,0.1193609022556391,"(x∗−x0)⊤W (t)
kq xq ≥C0t,
(x0 −x)⊤W (t)
kq xq ≥C0t,
∀x∗∈Oxq, x0 ∈Mxq, x ∈Nxq."
GENERALIZATION ABILITY,0.12030075187969924,"Moreover, if the trained transformer takes input X with query xq that consists of a non-comparable
token x0 and non-optimal tokens, then the prediction made by Tθ(t)(X) is n(x0) with high probability."
GENERALIZATION ABILITY,0.1212406015037594,"Theorem 3 suggests that a new partial order is created by the trained transformer. Specifically,
it inserts the non-comparable tokens between the optimal and non-optimal tokens. The trained
transformer can generalize the token prediction to such new sentences as given in Theorem 3."
GENERALIZATION ABILITY,0.12218045112781954,We use Example 1 to illustrate the generalization ability described above.
GENERALIZATION ABILITY,0.1231203007518797,"Example 2 (Generalization to unseen data in Example 1) Recall that in Example 1, the training
dataset consists of four sentences: SVOP, VOP, OPP, and PSV. Consider the partial order >P under
the punctuation mark P. We have that O>PP and O is an optimal token, P is a non-optimal token,
and S,V are non-comparable tokens. We then have the following non-trivial prediction by the trained
transformer."
GENERALIZATION ABILITY,0.12406015037593984,Case 1. Non-comparable tokens are learned to be “larger” than non-optimal tokens.
GENERALIZATION ABILITY,0.125,"Consider a new (unseen) input sentence SP. Since S is non-comparable before training, but is “larger”
than P under the trained key-query matrix W (t)
kq , the next predicted token is n(S) = V."
GENERALIZATION ABILITY,0.12593984962406016,Case 2. Optimal tokens remain optimal over all tokens after training.
GENERALIZATION ABILITY,0.12687969924812031,"Consider a new (unseen) input OSP. O is optimal and S is still “smaller” than O under the trained
P-partial order. The trained transformer will consistently predict P."
GENERALIZATION ABILITY,0.12781954887218044,"In both of the above cases, the trained transformer provides desirable prediction for the unseen
sentences. We further note that the effectiveness of both cases can vary during the inference time of
the trained transformer. For instance, if the input sequence is SP (subject-punctuation), the output is
SPV (subject-P-verb), which follows a logical subject-verb order and is desirable. However, in cases
where the input is VP (verb-punctuation), it may be preferable to terminate the sequence after the
verb, i.e., VPP, as the verb alone can suffice to convey the intended meaning."
EXPERIMENT,0.1287593984962406,"7
Experiment"
EXPERIMENT,0.12969924812030076,"In this section, we verify our theoretical findings via an experiment on a synthetic dataset. Specifically,
we randomly generate a realizable dataset as described in Assumption 1 with |V| = 20. Then, we
train Wov and Wkq by Algorithm 1, each with 900 iterations. The parameters are chosen as d = |V|,
η0 = 0.2/
√"
EXPERIMENT,0.13063909774436092,"d, and η = 0.05/
√"
EXPERIMENT,0.13157894736842105,"d. In Figure 2, the first three plots show the dynamics of the training
stage 1, which indicates the convergence of the loss L0(W (t)
ov ) to its minimum value, the convergence
of W (t)
ov in direction to W ∗
ov, and the linear increase of the norm ∥W (t)
ov ∥, respectively. These results
verify Proposition 1. The last three plots show the dynamics of the training stage 2, which indicates
the convergence of the loss L(θ(t)), the convergence of W (t)
kq in direction to W ∗
kq, and the linear"
EXPERIMENT,0.1325187969924812,"increase of the norm ∥W (t)
kq ∥. These results verify Theorem 1 and Theorem 2. All experiments are
conducted on a PC equipped with an i5-12400F processor and 16GB of memory."
EXPERIMENT,0.13345864661654136,Figure 2: Training dynamics of single-layer transformer for NTP.
CONCLUSION,0.13439849624060152,"8
Conclusion"
CONCLUSION,0.13533834586466165,"In this work, we investigated the training dynamics of a single-layer transformer for NTP. We first
characterized two structural properties of the training dataset under the realizable setting where
the training loss can be made arbitrarily close to zero. These properties allow us to define two
max-margin solutions for both the feed-forward layer and the self-attention layer. Then, we showed
that both layers converge in direction to their corresponding max-margin solutions sub-linearly, which
further yields a linear convergence of the training loss for NTP. We further showed that the well
trained transformer can have non-trivial prediction ability on unseen data, which sheds light on the
generalization capability of transformers. Our experiments verify our theoretical findings."
CONCLUSION,0.1362781954887218,Acknowledgments and Disclosure of Funding
CONCLUSION,0.13721804511278196,"The work of R. Huang and J. Yang was supported in part by the U.S. National Science Foundation
under grants NSF CNS-1956276 and ECCS-2133170. The work of Y. Liang was supported in part by
the U.S. National Science Foundation under grants ECCS- 2413528 and DMS-2134145."
REFERENCES,0.13815789473684212,References
REFERENCES,0.13909774436090225,"Ahn, K., Cheng, X., Daneshmand, H., and Sra, S. (2024). Transformers learn to implement pre-
conditioned gradient descent for in-context learning. Advances in Neural Information Processing
Systems, 36."
REFERENCES,0.1400375939849624,"Akyürek, E., Schuurmans, D., Andreas, J., Ma, T., and Zhou, D. (2022). What learning algorithm is
in-context learning? investigations with linear models. arXiv preprint arXiv:2211.15661."
REFERENCES,0.14097744360902256,"Bai, Y., Chen, F., Wang, H., Xiong, C., and Mei, S. (2023). Transformers as statisticians: Provable
in-context learning with in-context algorithm selection. arXiv preprint arXiv:2306.04637."
REFERENCES,0.14191729323308272,"Belkin, M. (2024). The necessity of machine learning theory in mitigating ai risk. ACM/JMS Journal
of Data Science."
REFERENCES,0.14285714285714285,"Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M. S., Bohg,
J., Bosselut, A., Brunskill, E., et al. (2021). On the opportunities and risks of foundation models.
arXiv preprint arXiv:2108.07258."
REFERENCES,0.143796992481203,"Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam,
P., Sastry, G., Askell, A., et al. (2020). Language models are few-shot learners. Advances in neural
information processing systems, 33:1877–1901."
REFERENCES,0.14473684210526316,"Chen, S. and Li, Y. (2024).
Provably learning a multi-head attention layer.
arXiv preprint
arXiv:2402.04084."
REFERENCES,0.14567669172932332,"Chen, S., Sheen, H., Wang, T., and Yang, Z. (2024). Training dynamics of multi-head softmax
attention for in-context learning: Emergence, convergence, and optimality.
arXiv preprint
arXiv:2402.19442."
REFERENCES,0.14661654135338345,"Cheng, X., Chen, Y., and Sra, S. (2023). Transformers implement functional gradient descent to learn
non-linear functions in context. arXiv preprint arXiv:2312.06528."
REFERENCES,0.1475563909774436,"Cui, Y., Ren, J., He, P., Tang, J., and Xing, Y. (2024). Superiority of multi-head attention in in-context
linear regression. arXiv preprint arXiv:2401.17426."
REFERENCES,0.14849624060150377,"Deora, P., Ghaderi, R., Taheri, H., and Thrampoulidis, C. (2023). On the optimization and generaliza-
tion of multi-head attention. arXiv preprint arXiv:2310.12680."
REFERENCES,0.14943609022556392,"Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2018). Bert: Pre-training of deep bidirectional
transformers for language understanding. arXiv preprint arXiv:1810.04805."
REFERENCES,0.15037593984962405,"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M.,
Minderer, M., Heigold, G., Gelly, S., et al. (2020). An image is worth 16x16 words: Transformers
for image recognition at scale. arXiv preprint arXiv:2010.11929."
REFERENCES,0.1513157894736842,"Dryer, M. S. (1991). Svo languages and the ov: Vo typology1. Journal of linguistics, 27(2):443–482."
REFERENCES,0.15225563909774437,"Edelman, B. L., Goel, S., Kakade, S., and Zhang, C. (2022). Inductive biases and variable creation in
self-attention mechanisms. In International Conference on Machine Learning, pages 5793–5831.
PMLR."
REFERENCES,0.15319548872180452,"Frei, S., Vardi, G., Bartlett, P. L., Srebro, N., and Hu, W. (2022). Implicit bias in leaky relu networks
trained on high-dimensional data. arXiv preprint arXiv:2210.07082."
REFERENCES,0.15413533834586465,"Fu, D., Chen, T.-Q., Jia, R., and Sharan, V. (2023). Transformers learn higher-order optimization
methods for in-context learning: A study with linear models. arXiv preprint arXiv:2310.17086."
REFERENCES,0.1550751879699248,"Giannou, A., Rajput, S., Sohn, J.-y., Lee, K., Lee, J. D., and Papailiopoulos, D. (2023). Looped
transformers as programmable computers. In International Conference on Machine Learning,
pages 11398–11442. PMLR."
REFERENCES,0.15601503759398497,"Huang, Y., Cheng, Y., and Liang, Y. (2023). In-context convergence of transformers. arXiv preprint
arXiv:2310.05249."
REFERENCES,0.15695488721804512,"Ji, Z., Srebro, N., and Telgarsky, M. (2021). Fast margin maximization via dual acceleration. In
International Conference on Machine Learning, pages 4860–4869. PMLR."
REFERENCES,0.15789473684210525,"Ji, Z. and Telgarsky, M. (2021). Characterizing the implicit bias via a primal-dual analysis. In
Algorithmic Learning Theory, pages 772–804. PMLR."
REFERENCES,0.1588345864661654,"Kim, J. and Suzuki, T. (2024). Transformers learn nonlinear features in context: Nonconvex mean-
field dynamics on the attention landscape. arXiv preprint arXiv:2402.01258."
REFERENCES,0.15977443609022557,"Kou, Y., Chen, Z., and Gu, Q. (2024). Implicit bias of gradient descent for two-layer relu and leaky
relu networks on nearly-orthogonal data. Advances in Neural Information Processing Systems, 36."
REFERENCES,0.16071428571428573,"Lehecka, T. (2015). Collocation and colligation. In Handbook of pragmatics online. Benjamins."
REFERENCES,0.16165413533834586,"Li, H., Wang, M., Liu, S., and Chen, P.-Y. (2023). A theoretical understanding of shallow vision
transformers: Learning, generalization, and sample complexity. arXiv preprint arXiv:2302.06015."
REFERENCES,0.162593984962406,"Li, Y., Huang, Y., Ildiz, M. E., Rawat, A. S., and Oymak, S. (2024). Mechanics of next token
prediction with self-attention. In International Conference on Artificial Intelligence and Statistics,
pages 685–693. PMLR."
REFERENCES,0.16353383458646617,"Lin, L., Bai, Y., and Mei, S. (2023). Transformers as decision makers: Provable in-context reinforce-
ment learning via supervised pretraining. arXiv preprint arXiv:2310.08566."
REFERENCES,0.16447368421052633,"Mahankali, A., Hashimoto, T. B., and Ma, T. (2023). One step of gradient descent is provably the
optimal in-context learner with one layer of linear self-attention. arXiv preprint arXiv:2307.03576."
REFERENCES,0.16541353383458646,"Nacson, M. S., Lee, J., Gunasekar, S., Savarese, P. H. P., Srebro, N., and Soudry, D. (2019).
Convergence of gradient descent on separable data. In The 22nd International Conference on
Artificial Intelligence and Statistics, pages 3420–3428. PMLR."
REFERENCES,0.16635338345864661,"Nichani, E., Damian, A., and Lee, J. D. (2024). How transformers learn causal structure with gradient
descent. arXiv preprint arXiv:2402.14735."
REFERENCES,0.16729323308270677,"Phuong, M. and Lampert, C. H. (2020). The inductive bias of relu networks on orthogonally separable
data. In International Conference on Learning Representations."
REFERENCES,0.16823308270676693,"Soudry, D., Hoffer, E., Nacson, M. S., Gunasekar, S., and Srebro, N. (2018). The implicit bias of
gradient descent on separable data. Journal of Machine Learning Research, 19(70):1–57."
REFERENCES,0.16917293233082706,"Tarzanagh, D. A., Li, Y., Thrampoulidis, C., and Oymak, S. (2023a). Transformers as support vector
machines. arXiv preprint arXiv:2308.16898."
REFERENCES,0.17011278195488722,"Tarzanagh, D. A., Li, Y., Zhang, X., and Oymak, S. (2023b). Max-margin token selection in attention
mechanism. In Thirty-seventh Conference on Neural Information Processing Systems."
REFERENCES,0.17105263157894737,"Thrampoulidis, C. (2024). Implicit bias of next-token prediction."
REFERENCES,0.17199248120300753,"Tian, Y., Wang, Y., Chen, B., and Du, S. S. (2023a). Scan and snap: Understanding training dynamics
and token composition in 1-layer transformer. Advances in Neural Information Processing Systems,
36:71911–71947."
REFERENCES,0.17293233082706766,"Tian, Y., Wang, Y., Zhang, Z., Chen, B., and Du, S. (2023b). Joma: Demystifying multilayer
transformers via joint dynamics of mlp and attention. arXiv preprint arXiv:2310.00535."
REFERENCES,0.17387218045112782,"Tsai, Y.-H. H., Bai, S., Liang, P. P., Kolter, J. Z., Morency, L.-P., and Salakhutdinov, R. (2019).
Multimodal transformer for unaligned multimodal language sequences. In Proceedings of the
conference. Association for computational linguistics. Meeting, volume 2019, page 6558. NIH
Public Access."
REFERENCES,0.17481203007518797,"Vardi, G. (2023). On the implicit bias in deep-learning algorithms. Communications of the ACM,
66(6):86–93."
REFERENCES,0.17575187969924813,"Vasudeva, B., Deora, P., and Thrampoulidis, C. (2024). Implicit bias and fast convergence rates for
self-attention. arXiv preprint arXiv:2402.05738."
REFERENCES,0.17669172932330826,"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., and
Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing
systems, 30."
REFERENCES,0.17763157894736842,"Von Oswald, J., Niklasson, E., Randazzo, E., Sacramento, J., Mordvintsev, A., Zhmoginov, A., and
Vladymyrov, M. (2023). Transformers learn in-context by gradient descent. In International
Conference on Machine Learning, pages 35151–35174. PMLR."
REFERENCES,0.17857142857142858,"Yannakakis, M. (1982). The complexity of the partial order dimension problem. SIAM Journal on
Algebraic Discrete Methods, 3(3):351–358."
REFERENCES,0.17951127819548873,"Zhang, R., Frei, S., and Bartlett, P. L. (2023). Trained transformers learn linear models in-context.
arXiv preprint arXiv:2306.09927."
REFERENCES,0.18045112781954886,Contents
INTRODUCTION,0.18139097744360902,"1
Introduction
1"
RELATED WORK,0.18233082706766918,"2
Related Work
2"
PROBLEM SETUP,0.18327067669172933,"3
Problem Setup
3"
REALIZABLE TRAINING DATASET AND TWO-STAGE ALGORITHM,0.18421052631578946,"4
Realizable Training Dataset and Two-Stage Algorithm
4"
REALIZABLE TRAINING DATASET AND TWO-STAGE ALGORITHM,0.18515037593984962,"4.1
Realizable Training Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4"
REALIZABLE TRAINING DATASET AND TWO-STAGE ALGORITHM,0.18609022556390978,"4.2
Training Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5"
TRAINING DYNAMICS OF THE TRANSFORMER,0.18703007518796994,"5
Training Dynamics of the Transformer
6"
CONVERGENCE OF TRAINING WOV,0.18796992481203006,"5.1
Convergence of Training Wov
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
6"
CONVERGENCE OF TRAINING WKQ,0.18890977443609022,"5.2
Convergence of Training Wkq
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
7"
CONVERGENCE OF TRAINING WKQ,0.18984962406015038,"5.3
Proof Sketch of Theorem 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8"
GENERALIZATION ABILITY,0.19078947368421054,"6
Generalization Ability
8"
EXPERIMENT,0.19172932330827067,"7
Experiment
9"
CONCLUSION,0.19266917293233082,"8
Conclusion
9"
CONCLUSION,0.19360902255639098,"A Expression of Gradients
14"
CONCLUSION,0.19454887218045114,"B
Proof of Proposition 1
14"
CONCLUSION,0.19548872180451127,"C Proof of Theorem 1 and Theorem 2
17"
CONCLUSION,0.19642857142857142,"C.1
Supporting Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17"
CONCLUSION,0.19736842105263158,"C.2
Step 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19"
CONCLUSION,0.19830827067669174,"C.3
Step 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21"
CONCLUSION,0.19924812030075187,"C.4
Step 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23"
CONCLUSION,0.20018796992481203,"C.5
Proof of Theorem 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28"
CONCLUSION,0.20112781954887218,"C.6
Proof of Theorem 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
30"
CONCLUSION,0.20206766917293234,"D Proof of Proposition 2 and Theorem 3
31"
CONCLUSION,0.20300751879699247,"D.1
Proof of Proposition 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31"
CONCLUSION,0.20394736842105263,"D.2
Proof of Theorem 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
33"
CONCLUSION,0.20488721804511278,"A
Expression of Gradients"
CONCLUSION,0.20582706766917294,We first provide the general formula for the gradients of both layers.
CONCLUSION,0.20676691729323307,"∇WovL0(Wov) =
X x∈V"
CONCLUSION,0.20770676691729323," 
T0(x) −eIn(x)

x⊤,
(5)"
CONCLUSION,0.20864661654135339,"∇WkqL(θ) =
X"
CONCLUSION,0.20958646616541354,"n
π(n)X(n) 
diag(ϕθ(X(n)) −ϕθ(X(n))ϕθ(X(n))⊤
(X(n))⊤W ⊤
ov

Tθ(X(n)) −p(n)
(X(n)
−1 )⊤. (6)"
CONCLUSION,0.21052631578947367,"B
Proof of Proposition 1"
CONCLUSION,0.21146616541353383,"Recall that we use the loss,"
CONCLUSION,0.212406015037594,"L0(Wov) = −
X"
CONCLUSION,0.21334586466165414,"x∈V
log
exp

e⊤
In(x)Wovx
 P"
CONCLUSION,0.21428571428571427,"i∈[|V|] exp
 
e⊤
i Wovx
."
CONCLUSION,0.21522556390977443,The updating rule of Wov is that
CONCLUSION,0.2161654135338346,"W (t+1)
ov
= W (t)
ov −η0
∇WovL0(W (t)
ov )"
CONCLUSION,0.21710526315789475,"∥∇WovL0(W (t)
ov )∥
.
(7)"
CONCLUSION,0.21804511278195488,"We know that L0 is convex respect to Wov. Therefore, we have"
CONCLUSION,0.21898496240601503,"D
W (t)
ov −W ′
ov, ∇WovL0(θ(t))
E
≥L0(θ(t)) −L0(θ′)."
CONCLUSION,0.2199248120300752,"It is clear that the loss function L reaches the minimum 0 when Wov = ∆W ∗
ov, as ∆→∞."
CONCLUSION,0.22086466165413535,"Lemma 1 Under the initialization W (0)
ov and the updating rule Equation (7) with step size η, the
following inequality holds."
CONCLUSION,0.22180451127819548,"tη0 + ∥W (0)
ov ∥≥∥W (t)
ov ∥≥
tη0
2∥W ∗ov∥−∥W (0)
ov ∥."
CONCLUSION,0.22274436090225563,"Proof. Using Equation (5), we have"
CONCLUSION,0.2236842105263158,"D
W ∗
ov, ∇WovL0(W (t)
ov )
E
=
X x∈V"
CONCLUSION,0.22462406015037595,"
T(t)
0 (x) −eIn(x)
⊤
W ∗
ovx =
X x∈V X"
CONCLUSION,0.22556390977443608,"i∈[|V|]
[T(t)
0 (x)]i(ei −eIn(x))⊤W ∗
ovx"
CONCLUSION,0.22650375939849623,"(a)
≤−
X x∈V X"
CONCLUSION,0.2274436090225564,"i̸=In(x)
[T(t)
0 (x)]i,
(8)"
CONCLUSION,0.22838345864661655,"where (a) is due the constraints that W ∗
ov satisfies. On the other hand,"
CONCLUSION,0.22932330827067668,"∥∇WovL(W (t)
ov )∥="
CONCLUSION,0.23026315789473684,"*
∇WovL(W (t)
ov )"
CONCLUSION,0.231203007518797,"∥∇WovL(W (t)
ov )∥
, ∇WovL0(W (t)
ov ) + =
X x∈V X"
CONCLUSION,0.23214285714285715,"i
[T(t)
0 (x)]i(ei −eIn(x))⊤∇WovL(θ(t))"
CONCLUSION,0.23308270676691728,∥∇WovL(θ(t))∥x
CONCLUSION,0.23402255639097744,"(a)
≤2
X x∈V X"
CONCLUSION,0.2349624060150376,"i̸=In(x)
[T(t)
0 (x)]i,"
CONCLUSION,0.23590225563909775,"where (a) follows from ∥AB∥≤∥A∥∥B∥for any matrices A and B. Thus, we obtain

W ∗
ov, ∇WovL(θ(t))"
CONCLUSION,0.23684210526315788,∥∇WovL(θ(t))∥ ≤−1/2
CONCLUSION,0.23778195488721804,"To lower bound the norm of Wov, we recall the updating rule (Equation (7))."
CONCLUSION,0.2387218045112782,"∥W (t)
ov ∥="
CONCLUSION,0.23966165413533835,"W (0)
ov −
X"
CONCLUSION,0.24060150375939848,"t′<t
η0
∇WovL0(W (t′)
ov )"
CONCLUSION,0.24154135338345864,"∥∇WovL0(W (t′)
ov )∥  ≥ *"
CONCLUSION,0.2424812030075188,"W (0)
ov −
X"
CONCLUSION,0.24342105263157895,"t′<t
η0
∇WovL0(W (t′)
ov )"
CONCLUSION,0.24436090225563908,"∥∇WovL0(W (t′)
ov )∥
, Wov"
CONCLUSION,0.24530075187969924,∥W ∗ov∥ +
CONCLUSION,0.2462406015037594,"≥
tη0
2∥W ∗ov∥−∥W (0)
ov ∥."
CONCLUSION,0.24718045112781956,"For the LHS of the inequality, it suffices to note that at each iteration, the norm ∥W (t)
ov ∥increases
most η0 due to normalized gradient descent."
CONCLUSION,0.24812030075187969,"Lemma 2 At each iteration t, the following inequality holds.
*
W (t)
ov
∥W (t)
ov ∥
, ∇WovL0(W (t)
ov ) + ≥ "
CONCLUSION,0.24906015037593984,"1 + 2∥W ∗
ov∥"
CONCLUSION,0.25,"∥W (t)
ov ∥
log(2|V|)"
CONCLUSION,0.25093984962406013,"!  W ∗
ov
∥W ∗ov∥, ∇WovL0(W (t)
ov )"
CONCLUSION,0.2518796992481203,"Proof. First, we consider the case when W (t)
ov = W ∗
ov
∥W (t)
ov ∥
∥W ∗
ov∥. Due to Equation (8) in Lemma 1, we
have"
CONCLUSION,0.25281954887218044,"W ∗
ov
∥W ∗ov∥, ∇WovL0(W (t)
ov )

< 0"
CONCLUSION,0.25375939849624063,"In this case, the result is trivial."
CONCLUSION,0.25469924812030076,"Then, we consider the case when W (t)
ov ̸= W ∗
ov
∥W (t)
ov ∥
∥W ∗
ov∥. Due the optimality of W ∗
ov, which achieves
the minimum norm satisfying the constraints in Equation (2), we must have that for some x0 ∈V,
there exists i0 ̸= In(x0) such that the following inequality holds"
CONCLUSION,0.2556390977443609,"(eIn(x0) −ei)⊤W (t)
ov x0 < ∥W (t)
ov ∥
∥W ∗ov∥."
CONCLUSION,0.2565789473684211,"Therefore, the loss on W (t)
ov can be lower bounded as follows."
CONCLUSION,0.2575187969924812,"L(W (t)
ov ) =
X"
CONCLUSION,0.25845864661654133,"x∈V
log  1 +
X"
CONCLUSION,0.2593984962406015,"i
exp

(ei −eIn(x))⊤W (t)
ov x
!"
CONCLUSION,0.26033834586466165,"> log

1 + exp

−∥W (t)
ov ∥/∥W ∗
ov∥
"
CONCLUSION,0.26127819548872183,"(a)
> 1"
EXP,0.26221804511278196,"2 exp

−∥W (t)
ov ∥/∥W ∗
ov∥

,"
EXP,0.2631578947368421,"where (a) is due to the fact that log(1 + x) ≥x/2 when 0 < x < 1. On the other hand, let"
EXP,0.2640977443609023,"W ′
ov =

∥W (t)
ov ∥
∥W ∗
ov∥+ 2 log(2|V|)

W ∗
ov. Then, the loss on W ′
ov has the following upper bound."
EXP,0.2650375939849624,"L(W ′
ov) =
X"
EXP,0.26597744360902253,"x∈V
log  1 +
X"
EXP,0.2669172932330827,"i
exp

(ei −eIn(x))⊤W (t)
ov x
! ≤
X"
EXP,0.26785714285714285,"x∈V
log

1 + (|V| −1) exp

−∥W (t)
ov ∥/∥W ∗
ov∥−log(2|V|)
"
EXP,0.26879699248120303,"(a)
≤
X"
EXP,0.26973684210526316,"x∈V
|V| exp

−∥W (t)
ov ∥/∥W ∗
ov∥−2 log(2|V|)
 ≤1"
EXP,0.2706766917293233,"2 exp(−∥W (t)
ov ∥/∥W ∗
ov∥),"
EXP,0.2716165413533835,"where (a) is due to the fact that log(1 + x) < x when x > 0. Thus, L(W (t)
ov ) > L(W ′
ov). Due to the
convextiy of L0, we have"
EXP,0.2725563909774436,"0 <
D
W (t)
ov −W ′
ov, ∇WovL0(W (t)
ov )
E"
EXP,0.27349624060150374,"=
D
W (t)
ov , ∇WovL0(W (t)
ov )
E
−"
EXP,0.2744360902255639,"∥W (t)
ov ∥
∥W ∗ov∥+ 2 log(2|V|)"
EXP,0.27537593984962405,"! D
W ∗
ov, ∇WovL0(W (t)
ov )
E
,"
EXP,0.27631578947368424,which finishes the proof.
EXP,0.27725563909774437,"Proposition 3 (Restatement of Proposition 1) Under the zero initialization W (0)
ov = 0 and updat-
ing rule Equation (7), for any t ≥2, the following inequality holds."
EXP,0.2781954887218045,"*
W (t)
ov
∥W (t)
ov ∥
, W ∗
ov
∥W ∗ov∥ +"
EXP,0.2791353383458647,"≥1 −12∥W ∗
ov∥3 log(2|V|) log t tη0
."
EXP,0.2800751879699248,"Moreover,
tη0
2∥W ∗
ov∥≤∥W (t)
ov ∥≤tη0."
EXP,0.28101503759398494,"Proof. The second argument about the norm of W (t)
ov follows directly from Lemma 1. We aim to
prove the first part as follows."
EXP,0.2819548872180451,"Let αt = 2∥W ∗
ov∥"
EXP,0.28289473684210525,"∥W (t)
ov ∥log(2|V|). By Lemma 2 and the updating rule Equation (7), we have"
EXP,0.28383458646616544,"W (t+1)
ov
−W (t)
ov , W ∗
ov
∥W ∗ov∥ = −η0"
EXP,0.28477443609022557,"∇WovL(W (t)
ov ), W ∗
ov
∥W ∗ov∥ "
EXP,0.2857142857142857,"≥−
η0
1 + αt *"
EXP,0.2866541353383459,"∇WovL(W (t)
ov ), W (t)
ov
∥W (t)
ov ∥ +"
EXP,0.287593984962406,"=
1
1 + αt *"
EXP,0.28853383458646614,"W (t+1)
ov
−W (t)
ov , W (t)
ov
∥W (t)
ov ∥ +"
EXP,0.2894736842105263,"=

1 −
αt
1 + αt  *"
EXP,0.29041353383458646,"W (t+1)
ov
−W (t)
ov , W (t)
ov
∥W (t)
ov ∥ + =
1"
EXP,0.29135338345864664,"2∥W (t)
ov ∥"
EXP,0.29229323308270677,"
∥W (t+1)
ov
∥2 −∥W (t+1)
ov
−W (t)
ov ∥2 −∥W (t)
ov ∥2"
EXP,0.2932330827067669,"−
αt
1 + αt *"
EXP,0.2941729323308271,"W (t+1)
ov
−W (t)
ov , W (t)
ov
∥W (t)
ov ∥ +"
EXP,0.2951127819548872,"(a)
= ∥W (t+1)
ov
∥2 −∥W (t)
ov ∥2"
EXP,0.29605263157894735,"2∥W (t)
ov ∥
−
η2"
EXP,0.29699248120300753,"2∥W (t)
ov ∥"
EXP,0.29793233082706766,+ η0αt
EXP,0.29887218045112784,1 + αt
EXP,0.299812030075188,"*
∇WovL(θ(t))
∥∇WovL(θ(t))∥, W (t)
ov
∥W (t)
ov ∥ +"
EXP,0.3007518796992481,"(b)
≥∥W (t+1)
ov
∥−∥W (t)
ov ∥−
η2
0
2∥W (t)
ov ∥
−η0αt"
EXP,0.3016917293233083,"1 + αt
,"
EXP,0.3026315789473684,"where (a) follows from that ∥W (t+1)
ov
−W (t)
ov ∥= η0, and (b) is due to the fact that x2−y2 ≥2y(x−y)
for any x, y ∈R."
EXP,0.30357142857142855,"Summing over t starting from 2, we have

W (t)
ov −W (2)
ov , W ∗
ov
∥W ∗ov∥"
EXP,0.30451127819548873,"≥∥W (t)
ov ∥−∥W (2)
ov ∥− t−1
X t′=2"
EXP,0.30545112781954886,"η2
0
2∥W (t′)
ov ∥
− t−1
X t′=2"
EXP,0.30639097744360905,"η0αt′
1 + αt′ ."
EXP,0.3073308270676692,"Furthermore, due to Lemma 1, t−1
X t′=2 1"
EXP,0.3082706766917293,"∥W (t′)
ov ∥
≤ t−1
X t′=2"
EXP,0.3092105263157895,"2∥W ∗
ov∥/η0 t"
EXP,0.3101503759398496,"≤2∥W ∗
ov∥
η0
log t."
EXP,0.31109022556390975,"Similarly, t−1
X t′=2"
EXP,0.31203007518796994,"αt′
1 + αt′ ≤ t−1
X t′=2"
EXP,0.31296992481203006,"2∥W ∗
ov∥log(2|V|)"
EXP,0.31390977443609025,"∥W (t′)
ov ∥"
EXP,0.3148496240601504,"≤4∥W ∗
ov∥2 log(2|V|)"
EXP,0.3157894736842105,"η0
log t"
EXP,0.3167293233082707,"Therefore,"
EXP,0.3176691729323308,"*
W (t)
ov
∥W (t)
ov ∥
, W ∗
ov
∥W ∗ov∥ +"
EXP,0.31860902255639095,"≥1 −∥W (2)
ov ∥+ 2η0∥W ∗
ov∥log t + 4∥W ∗
ov∥2 log(2|V|) log t"
EXP,0.31954887218045114,"∥W (t)
ov ∥"
EXP,0.32048872180451127,"(a)
≥1 −12∥W ∗
ov∥3 log(2|V|) log t tη0
,"
EXP,0.32142857142857145,"where (a) follows from Lemma 1 and ∥W (2)
ov ∥≤2η0 ≤∥W ∗
ov∥, and ∥W (t)
ov ∥≥tη0/(2∥W ∗
ov∥)"
EXP,0.3223684210526316,"C
Proof of Theorem 1 and Theorem 2"
EXP,0.3233082706766917,"C.1
Supporting Lemmas"
EXP,0.3242481203007519,"Lemma 3 With zero initialization, under the updating rule Equation (7), for any iteration t, W (t)
ov
satisfies that
(ei −ei′)⊤W (t)
ov x = 0,
∀i, i′ ̸= In(x)."
EXP,0.325187969924812,Proof. The proof follows directly from induction and the fact that
EXP,0.32612781954887216,"(ei −ei′)⊤W (t+1)
ov
x = (ei −ei′)⊤W (t)
ov x −η0([T(t)
0 ]i −[T(t)
0 ]i′)"
EXP,0.32706766917293234,"∥∇WovL0(W (t)
ov )∥
,
∀i, i′ ̸= In(x)."
EXP,0.32800751879699247,"Corollary 1 Under the settings in Proposition 1, let T ≥384∥W ∗
ov∥5 log(2|V|) log T/η0, and
∆= Tη0/(4∥W ∗
ov∥2)
(
(eIn(x) −ei)⊤Wovx ∈(∆, 3∆), ∀i ̸= In(x)"
EXP,0.32894736842105265,"(ei −ei′)⊤Wovx = 0, ∀i, i′ ̸= In(x)"
EXP,0.3298872180451128,Proof. The second equality follows directly from Lemma 3.
EXP,0.3308270676691729,"To show the first equation, we analyze"
EXP,0.3317669172932331,"(eIn(x) −ei)⊤W (T )
ov x"
EXP,0.33270676691729323,"= (eIn(x) −ei)⊤W ∗
ov∥W (T )
ov ∥
∥W ∗ov∥
x + ∥W (T )
ov ∥(eIn(x) −ei)⊤
 
W (T )
ov
∥W (T )
ov ∥
−
W ∗
ov
∥W ∗ov∥ !"
EXP,0.33364661654135336,"W (T )
ov x"
EXP,0.33458646616541354,"(a)
= ∥W (T )
ov ∥
∥W ∗ov∥−2
√"
EXP,0.3355263157894737,"2∥W (T )
ov ∥ s"
EXP,0.33646616541353386,12∥W ∗ov∥3 log(2|V|) log T Tη0
EXP,0.337406015037594,"(b)
≥
Tη0
2∥W ∗ov∥2 −
p"
EXP,0.3383458646616541,24Tη0∥W ∗ov∥log(2|V|) log T
EXP,0.3392857142857143,"≥
Tη0
4∥W ∗ov∥2 ,"
EXP,0.34022556390977443,"where (a) follows from Proposition 1, and (b) is due to Lemma 1. On the other hand, we also have"
EXP,0.34116541353383456,"(eIn(x) −ei)⊤W (T )
ov x ≤∥W (T )
ov ∥
∥W ∗ov∥+ 2
√"
EXP,0.34210526315789475,"2∥W (T )
ov ∥ s"
EXP,0.3430451127819549,12∥W ∗ov∥3 log(2|V|) log T Tη0
EXP,0.34398496240601506,"≤
3Tη0
4∥W ∗ov∥2"
EXP,0.3449248120300752,The proof is finished.
EXP,0.3458646616541353,"Thus, for simplicity, we further assume that (eIn(x) −ei)W (T )
ov x = ∆for all x, because (eIn(x) −
ei) ˆWovx = Θ(∆) for large enough iteration. Next, we provide the general form of the projection of
the gradient of Key-Query matrix Wkq follows from a notation for the token weight."
EXP,0.3468045112781955,"The token weight φ(n,t)
ℓ
of the token x(n)
ℓ
in the sentence X(n) = [x(n)
1 , . . . , x(n)
L ] under θ =
(W (T )
ov , Wkq) is calculated as"
EXP,0.34774436090225563,"φ(n,t)
ℓ
=
exp

(x(n)
ℓ
)⊤WkqX(n)
−1
"
EXP,0.34868421052631576,"PL
ℓ′=1 exp

(x(n)
ℓ′ )⊤WkqX(n)
−1

(9)"
EXP,0.34962406015037595,"Lemma 4 (Projection of gradient of Wkq) If Wov satisfies that
(
(eIn(x) −ei)⊤Wovx = ∆, ∀i ̸= In(x)"
EXP,0.3505639097744361,"(ei −ei′)⊤Wovx = 0, ∀i, i′ ̸= In(x)"
EXP,0.35150375939849626,"we have

∇WkqL(θ), W ′
kq = ∆
X"
EXP,0.3524436090225564,"n
π(n)([T(n)
θ ]In(X(n)) −1)
X"
EXP,0.3533834586466165,"ℓ∗∈l(n)
φ(n,θ)
ℓ∗ "
EXP,0.3543233082706767,"x(n)
ℓ∗−
X"
EXP,0.35526315789473684,"ℓ′
φ(n,θ)
ℓ′
x(n)
ℓ′ !⊤"
EXP,0.35620300751879697,"W ′
kqX(n)
−1 + ∆
X"
EXP,0.35714285714285715,"n
π(n) X"
EXP,0.3580827067669173,"ℓ/∈l(n)
[T(n)
θ ]In(x(n)
ℓ
)φ(n,θ)
ℓ "
EXP,0.35902255639097747,"x(n)
ℓ
−
X"
EXP,0.3599624060150376,"ℓ′
φ(n,θ)
ℓ′
x(n)
ℓ′ !⊤"
EXP,0.3609022556390977,"W ′
kqX(n)
−1 ."
EXP,0.3618421052631579,"Proof.
Recall that l(n) is the set of indices of the optimal tokens in the sample X(n). Thus, for
any ℓ∗∈l(n), In(x(n)
ℓ∗) = In(X(n)). In addition, we denote Tθ(X(n)) by T(n)
θ
for simplicity. From
Equation (6), we have

∇WkqL(θ), W ′
kq =
X"
EXP,0.36278195488721804,"n
π(n) X"
EXP,0.36372180451127817,"ℓ
(T(n)
θ
−p(n))⊤Wovx(n)
ℓ
φ(n,θ)
ℓ "
EXP,0.36466165413533835,"x(n)
ℓ
−
X"
EXP,0.3656015037593985,"ℓ′
φ(n,θ)
ℓ′
x(n)
ℓ′ !⊤"
EXP,0.36654135338345867,"W ′
kqX(n)
−1"
EXP,0.3674812030075188,"(a)
=
X"
EXP,0.3684210526315789,"n
π(n) X ℓ X"
EXP,0.3693609022556391,"i
[T(n)
θ ]i(ei −eIn(X(n)))⊤Wovx(n)
ℓ
φ(n,θ)
ℓ "
EXP,0.37030075187969924,"x(n)
ℓ
−
X"
EXP,0.37124060150375937,"ℓ′
φ(n,θ)
ℓ′
x(n)
ℓ′ !⊤"
EXP,0.37218045112781956,"W ′
kqX(n)
−1 =
X"
EXP,0.3731203007518797,"n
π(n) X"
EXP,0.37406015037593987,ℓ∈l(n) X
EXP,0.375,"i
[T(n)
θ ]i(ei −eIn(X(n)))⊤Wovx(n)
ℓ
φ(n,θ)
ℓ "
EXP,0.37593984962406013,"x(n)
ℓ
−
X"
EXP,0.3768796992481203,"ℓ′
φ(n,θ)
ℓ′
x(n)
ℓ′ !⊤"
EXP,0.37781954887218044,"W ′
kqX(n)
−1 +
X"
EXP,0.37875939849624063,"n
π(n) X"
EXP,0.37969924812030076,ℓ/∈l(n) X
EXP,0.3806390977443609,"i
[T(n)
θ ]i(ei −eIn(X(n)))⊤Wovx(n)
ℓ
φ(n,θ)
ℓ "
EXP,0.3815789473684211,"x(n)
ℓ
−
X"
EXP,0.3825187969924812,"ℓ′
φ(n,θ)
ℓ′
x(n)
ℓ′ !⊤"
EXP,0.38345864661654133,"W ′
kqX(n)
−1 =
X"
EXP,0.3843984962406015,"n
π(n) X"
EXP,0.38533834586466165,ℓ∈l(n) X
EXP,0.38627819548872183,"i̸=In(X(n))
[T(n)
θ ]i(−∆)φ(n,θ)
ℓ "
EXP,0.38721804511278196,"x(n)
ℓ
−
X"
EXP,0.3881578947368421,"ℓ′
φ(n,θ)
ℓ′
x(n)
ℓ′ !⊤"
EXP,0.3890977443609023,"W ′
kqX(n)
−1 +
X"
EXP,0.3900375939849624,"n
π(n) X"
EXP,0.39097744360902253,"ℓ/∈l(n)
[T(n)
θ ]In(x(n)
ℓ
)φ(n,θ)
ℓ "
EXP,0.3919172932330827,"x(n)
ℓ
−
X"
EXP,0.39285714285714285,"ℓ′
φ(n,θ)
ℓ′
x(n)
ℓ′ !⊤"
EXP,0.39379699248120303,"W ′
kqX(n)
−1 = ∆
X"
EXP,0.39473684210526316,"n
π(n)([T(n)
θ ]In(X(n)) −1)
X"
EXP,0.3956766917293233,"ℓ∗∈l(n)
φ(n,θ)
ℓ∗ "
EXP,0.3966165413533835,"x(n)
ℓ∗−
X"
EXP,0.3975563909774436,"ℓ′
φ(n,θ)
ℓ′
x(n)
ℓ′ !⊤"
EXP,0.39849624060150374,"W ′
kqX(n)
−1 + ∆
X"
EXP,0.3994360902255639,"n
π(n) X"
EXP,0.40037593984962405,"ℓ/∈l(n)
[T(n)
θ ]In(x(n)
ℓ
)φ(n,θ)
ℓ "
EXP,0.40131578947368424,"x(n)
ℓ
−
X"
EXP,0.40225563909774437,"ℓ′
φ(n,θ)
ℓ′
x(n)
ℓ′ !⊤"
EXP,0.4031954887218045,"W ′
kqX(n)
−1 ,"
EXP,0.4041353383458647,where (a) is due to the fact that P
EXP,0.4050751879699248,"i∈[|V|][T(n)
θ ]i = 1 for any θ, n."
EXP,0.40601503759398494,Main Steps
EXP,0.4069548872180451,"The proof consists of three main steps. First, we show that the optimal token weight has a lower
bound. Then, we show that the gradient aligns with the optimal direction. Third, we show that the
norm of Key-Query matrix grows linearly. Combining these three steps, we can prove the Theorem 1
and Theorem 2."
EXP,0.40789473684210525,"Recall that the updating rule for W (t)
kq is"
EXP,0.40883458646616544,"W (t+1)
kq
= W (t)
kq −η ∇WkqL(θ(t))"
EXP,0.40977443609022557,"∥∇WkqL(θ(t))∥.
(10)"
EXP,0.4107142857142857,"C.2
Step 1"
EXP,0.4116541353383459,We first show that the optiaml token weight has a lower bound during the training.
EXP,0.412593984962406,"Lemma 5 (Lower bound of optimal token weight) Under the zero initialization and updating rule
Equation (10), for any iteration t, and any sample X(n), if l(n) is the set of indices of the optimal
token in X(n), the following inequality holds."
EXP,0.41353383458646614,"φ(n,t)
ℓ
≥φ(n,0)
ℓ
≥1/Lmax,
∀ℓ∈l(n)"
EXP,0.4144736842105263,Proof.
EXP,0.41541353383458646,"First, we introduce the notation that φ(n,t)
+
= P"
EXP,0.41635338345864664,"ℓ∗∈l(n) φ(n,t)
ℓ∗
as the summation of optimal token"
EXP,0.41729323308270677,"weights, and φ(n,t)
−
= 1 −φ(n,t)
+
as the summation of non-optimal token weights."
EXP,0.4182330827067669,"At t = 0, due to zero initialization, we have φ(n,0)
ℓ
= 1/L(n). Moreover, by Assumption 3, for any
ℓ/∈l(n), we have φ(n,0)
+
≥qn(xℓ)φ(n,0)
ℓ
."
EXP,0.4191729323308271,"We perform induction the hypothesis: φ(n,t)
+
≥φ(n,t−1)
+
and φ(n,t)
ℓ∗
≥φ(n,t)
ℓ
for all ℓ∗∈l(n) and
ℓ/∈l(n)."
EXP,0.4201127819548872,"Suppose the hypothesis holds for iteration t. Let x(n)
ℓ∗be the optimal token in the sequence X(n)."
EXP,0.42105263157894735,Fix a sample X(n′). we have
EXP,0.42199248120300753,"(x(n′)
ℓ∗)⊤∇WkqL(t)(θ(t))X(n′)
−1 =
X"
EXP,0.42293233082706766,"n
π(n)([T(n)
θ ]In(X(n)) −1)φ(n,t)
+  X"
EXP,0.42387218045112784,"ℓ′ /∈l(n)
φ(n,t)
ℓ′
(x(n)
ℓ∗−x(n)
ℓ′ )⊤x(n′)
ℓ∗ "
EXP,0.424812030075188,"
D
X(n)
−1 , X(n′)
−1
E +
X"
EXP,0.4257518796992481,"n
π(n) X"
EXP,0.4266917293233083,"ℓ/∈l(n)
[T(n)
θ ]In(x(n)
ℓ
)φ(n,t)
ℓ X"
EXP,0.4276315789473684,"ℓ′
φ(n,t)
ℓ′
(x(n)
ℓ
−x(n)
ℓ′ )⊤x(n′)
ℓ∗"
EXP,0.42857142857142855,"! D
X(n)
−1 , X(n′)
−1
E"
EXP,0.42951127819548873,Because P
EXP,0.43045112781954886,"ℓ′ /∈l(n)(x(n)
ℓ′ )x(n′)
ℓ∗
= 0 due to Assumption 1, and (x(n)
ℓ∗)⊤x(n′)
ℓ∗
≥0, we immediately have"
EXP,0.43139097744360905,"(x(n′)
ℓ∗)⊤∇WkqL(t)(θ(t))X(n′)
−1 ≤0."
EXP,0.4323308270676692,"Let x(n′)
ℓ0
be any non-optiaml token in the sequence X(n′). Then, we have"
EXP,0.4332706766917293,"(x(n′)
ℓ0 )⊤∇WkqL(t)(θ(t))X(n′)
−1 =
X"
EXP,0.4342105263157895,"n
π(n)([T(n)
θ ]In(X(n)) −1)φ(n,t)
+  X"
EXP,0.4351503759398496,"ℓ′ /∈l(n)
φ(n,t)
ℓ′
(x(n)
ℓ∗−x(n)
ℓ′ )⊤x(n′)
ℓ0 "
EXP,0.43609022556390975,"
D
X(n)
−1 , X(n′)
−1
E +
X"
EXP,0.43703007518796994,"n
π(n) X"
EXP,0.43796992481203006,"ℓ/∈l(n)
[T(n)
θ ]In(x(n)
ℓ
)φ(n,t)
ℓ X"
EXP,0.43890977443609025,"ℓ′
φ(n,t)
ℓ′
(x(n)
ℓ
−x(n)
ℓ′ )⊤x(n′)
ℓ0"
EXP,0.4398496240601504,"! D
X(n)
−1 , X(n′)
−1
E =
X"
EXP,0.4407894736842105,"n
π(n)([T(n)
θ ]In(X(n)) −1)φ(n,t)
+  X"
EXP,0.4417293233082707,"ℓ′ /∈l(n)
φ(n,t)
ℓ′
(−x(n)
ℓ′ )⊤x(n′)
ℓ0 "
EXP,0.4426691729323308,"
D
X(n)
−1 , X(n′)
−1
E +
X"
EXP,0.44360902255639095,"n
π(n) X"
EXP,0.44454887218045114,"ℓ/∈l(n)
[T(n)
θ ]In(x(n)
ℓ
)φ(n,t)
ℓ  X"
EXP,0.44548872180451127,"ℓ′ /∈l(n)
φ(n,t)
ℓ′
(x(n)
ℓ
−x(n)
ℓ′ )⊤x(n′)
ℓ0 "
EXP,0.44642857142857145,"
D
X(n)
−1 , X(n′)
−1
E ≥
X"
EXP,0.4473684210526316,"n
π(n) "
EXP,0.4483082706766917,"(1 −[T(n)
θ ]In(X(n)))φ(n,t)
ℓ+
−
X"
EXP,0.4492481203007519,"ℓ/∈l(n)
[T(n)
θ ]In(x(n)
ℓ
)φ(n,t)
ℓ    X"
EXP,0.450187969924812,"ℓ′ /∈l(n)
φ(n,t)
ℓ′
(x(n)
ℓ′ )⊤x(n′)
ℓ0 "
EXP,0.45112781954887216,"
D
X(n)
−1 , X(n′)
−1
E ≥0,"
EXP,0.45206766917293234,"where the last inequality is due to Assumption 3, the induction hypothesis and P"
EXP,0.45300751879699247,"i∈[|V|][T(n)
θ ]i = 1"
EXP,0.45394736842105265,"Therefore, for any n, we have"
EXP,0.4548872180451128,"φ(n,t+1)
ℓ∗
=
exp

(x(n)
ℓ∗)⊤W (t+1)
kq
X(n)
−1
 P"
EXP,0.4558270676691729,"ℓexp

(x(n)
ℓ
)⊤W (t+1)
kq
X(n)
−1
"
EXP,0.4567669172932331,"=
exp

(x(n)
ℓ∗)⊤W (t)
kq X(n)
−1 −η(x(n)
ℓ∗)⊤∇WkqL(t)(θ(t))X(n)
−1 /∥∇WkqL(t)(θ(t))∥
 P"
EXP,0.45770676691729323,"ℓexp

(x(n)
ℓ
)⊤W (t)
kq X(n)
−1 −η(x(n)
ℓ
)⊤∇WkqL(t)(θ(t))X(n)
−1 /∥∇WkqL(t)(θ(t))∥
"
EXP,0.45864661654135336,"=
exp

(x(n)
ℓ∗)⊤W (t)
kq X(n)
−1
 P"
EXP,0.45958646616541354,"ℓexp

(x(n)
ℓ
)⊤W (t)
kq X(n)
−1 + η(x(n)
ℓ∗−x(n)
ℓ
)⊤∇WkqL(t)(θ(t))X(n)
−1 /∥∇WkqL(t)(θ(t))∥
"
EXP,0.4605263157894737,"≥
exp

(x(n)
ℓ∗)⊤W (t)
kq X(n)
−1
 P"
EXP,0.46146616541353386,"ℓexp

(x(n)
ℓ
)⊤W (t)
kq X(n)
−1
"
EXP,0.462406015037594,"= φ(n,t)
ℓ∗
,"
EXP,0.4633458646616541,"which implies that φ(n,t+1)
+
≥φ(n,t)
+
."
EXP,0.4642857142857143,"For the second argument in the hypothesis, we examine φ(n,t+1)
ℓ∗
/φ(n,t+1)
ℓ
for any ℓ/∈l(n). We have"
EXP,0.46522556390977443,"φ(n,t+1)
ℓ∗
φ(n,t+1)
ℓ
= exp

(x(n)
ℓ∗−x(n)
ℓ
)⊤W (t+1)
kq
X(n)
−1
"
EXP,0.46616541353383456,"= exp

(x(n)
ℓ∗−x(n)
ℓ
)⊤W (t)
kq X(n)
−1

exp

−
η
∥∇WkqL(t)(θ(t))∥(x(n)
ℓ∗−x(n)
ℓ
)⊤∇WkqL(t)(θ(t))X(n)
−1 "
EXP,0.46710526315789475,"≥φ(n,t)
ℓ∗
φ(n,t)
ℓ
≥1."
EXP,0.4680451127819549,The proof is finished.
EXP,0.46898496240601506,"C.3
Step 2"
EXP,0.4699248120300752,"The following lemma shows that the norm of the Key-Query Matrix increases linearly with the
number of iterations."
EXP,0.4708646616541353,"Lemma 6 Under the initialization W (0)
kq and the updating rule Equation (10), for each iteration t,
the following inequality holds."
EXP,0.4718045112781955,"tη + ∥W (0)
kq ∥≥∥W (t)
kq ∥≥
tη
2Lmax∥W ∗
kq∥−∥W (0)
kq ∥."
EXP,0.47274436090225563,Proof.
EXP,0.47368421052631576,"We examine the gradient ∇WkqL(θ) projected onto the optimal direction W ∗
kq/∥W ∗
kq∥.
D
∇WkqL(θ(t)), W ∗
kq
E =
X"
EXP,0.47462406015037595,"n
π(n)∆
X"
EXP,0.4755639097744361,"ℓ∗∈l(n)
([T(n)
θ(t)]In(x(n)
ℓ∗) −1)φ(n,t)
ℓ∗ "
EXP,0.47650375939849626,"a(n,∗)
ℓ∗
−
X"
EXP,0.4774436090225564,"ℓ′
φ(n,t)
ℓ′
a(n,∗)
ℓ′ ! +
X"
EXP,0.4783834586466165,"n
π(n)∆
X"
EXP,0.4793233082706767,"ℓ/∈l(n)
[T(n)
θ(t)]In(x(n)
ℓ
)φ(n,t)
ℓ "
EXP,0.48026315789473684,"a(n,∗)
ℓ
−
X"
EXP,0.48120300751879697,"ℓ′
φ(n,t)
ℓ′
a(n,∗)
ℓ′ ! =
X"
EXP,0.48214285714285715,"n
π(n)∆([T(n)
θ(t)]In(X(n)) −1)φ(n,t)
+  X"
EXP,0.4830827067669173,"ℓ′ /∈l(n)
φ(n,t)
ℓ′
(a(n,∗)
ℓ∗
−a(n,∗)
ℓ′
)   +
X"
EXP,0.48402255639097747,"n
π(n)∆
X"
EXP,0.4849624060150376,"ℓ/∈l(n)
[T(n)
θ(t)]In(x(n)
ℓ
)φ(n,t)
ℓ  X"
EXP,0.4859022556390977,"ℓ′∈l(n)
φ(n,t)
ℓ′
(a(n,∗)
ℓ
−a(n,∗)
ℓ′
)   ≤
X"
EXP,0.4868421052631579,"n
π(n)∆([T(n)
θ(t)]In(X(n)) −1)φ(n,t)
+
φ(n,t)
− +
X"
EXP,0.48778195488721804,"n
π(n)∆
X"
EXP,0.48872180451127817,"ℓ/∈l(n)
[T(n)
θ(t)]In(x(n)
ℓ
)φ(n,t)
ℓ
(−φ(n,t)
+
),"
EXP,0.48966165413533835,"where φ(n,t)
+
= P
ℓ∗∈l(n) φ(n,t)
ℓ∗
is the summation of optimal token weights, and φ(n,t)
−
= 1 −φ(n,t)
+
is the summation of non-optimal token weights."
EXP,0.4906015037593985,"On the other hand,"
EXP,0.49154135338345867,∥∇WkqL(θ(t))∥ = *
EXP,0.4924812030075188,"∇WkqL(θ(t)), ∇WkqL(θ(t))"
EXP,0.4934210526315789,"∥∇WkqL(θ(t))∥ + =
X"
EXP,0.4943609022556391,"n
π(n)∆
X"
EXP,0.49530075187969924,"ℓ∗∈l(n)
([T(n)
θ(t)]In(x(n)
ℓ∗) −1)φ(n,t)
ℓ∗ "
EXP,0.49624060150375937,"x(n)
ℓ∗−
X"
EXP,0.49718045112781956,"ℓ′
φ(n,t)
ℓ′
x(n)
ℓ′"
EXP,0.4981203007518797,"!⊤
∇WkqL(θ(t))
∥∇WkqL(θ(t))∥X(n)
−1 +
X"
EXP,0.49906015037593987,"n
π(n)∆
X"
EXP,0.5,"ℓ/∈l(n)
[T(n)
θ(t)]In(x(n)
ℓ
)φ(n,t)
ℓ "
EXP,0.5009398496240601,"x(n)
ℓ
−
X"
EXP,0.5018796992481203,"ℓ′
φ(n,t)
ℓ′
x(n)
ℓ′"
EXP,0.5028195488721805,"!⊤
∇WkqL(θ(t))
∥∇WkqL(θ(t))∥X(n)
−1 ≤2
X"
EXP,0.5037593984962406,"n
π(n)∆(1 −[T(n)
θ ]In(X(n)))φ(n,t)
+
φ(n,t)
−
+ 2
X"
EXP,0.5046992481203008,"n
π(n)∆
X"
EXP,0.5056390977443609,"ℓ/∈l(n)
[T(n)
θ ]In(x(n)
ℓ
)φ(n,t)
ℓ"
EXP,0.506578947368421,"Thus, we have"
EXP,0.5075187969924813,"*
∇WkqL(θ)
∇WkqL(θ)
,
W ∗
kq
∥W ∗
kq∥ +"
EXP,0.5084586466165414,"≤−minn φ(n,t)
+
2∥W ∗
kq∥
≤−
1
2Lmax∥W ∗
kq∥"
EXP,0.5093984962406015,"By the updating rule Equation (10), we have"
EXP,0.5103383458646616,"∥W (t)
kq ∥="
EXP,0.5112781954887218,"W (0)
kq − t−1
X"
EXP,0.5122180451127819,"t′=0
η ∇WkqL(θ(t′))
∇WkqL(θ(t′))  ≥ *"
EXP,0.5131578947368421,"W (0)
kq ,
W ∗
kq
∥W ∗
kq∥ + −
X"
EXP,0.5140977443609023,"t′≤t−1
η"
EXP,0.5150375939849624,"*
∇WkqL(θ(t′))
∇WkqL(θ(t′))
,
W ∗
kq
∥W ∗
kq∥ + ≥
X t′<t"
EXP,0.5159774436090225,"η
2Lmax∥W ∗
kq∥−∥W (0)
kq ∥"
EXP,0.5169172932330827,"=
tη
2Lmax∥W ∗
kq∥−∥W (0)
kq ∥."
EXP,0.5178571428571429,"In addition, by the triangle inequality,"
EXP,0.518796992481203,"∥W (t)
kq ∥="
EXP,0.5197368421052632,"W (0)
kq − t−1
X"
EXP,0.5206766917293233,"t′=0
η ∇WkqL(θ(t′))
∇WkqL(θ(t′)) "
EXP,0.5216165413533834,"≤tη + ∥W (0)
kq ∥."
EXP,0.5225563909774437,The proof is completed.
EXP,0.5234962406015038,"C.4
Step 3"
EXP,0.5244360902255639,"We next show that the gradient ∇WkqL(θ(t)) is close to the optimal direction W ∗
kq."
EXP,0.525375939849624,"Lemma 7 (Gradient aligns with the optimal direction) Let t0 = ⌈
8Lmax∥W ∗
kq∥2"
EXP,0.5263157894736842,"η
⌉. Then, for any
t ≥t0, we have"
EXP,0.5272556390977443,"D
∇WkqL(θ(t)), W (t)
kq
E
≥(1 + αt)
D
∇WkqL(θ(t)), W ∗
kq
E ∥W (t)
kq ∥"
EXP,0.5281954887218046,"∥W ∗
kq∥ where"
EXP,0.5291353383458647,"αt =
4NL2
max∥W ∗
kq∥2"
EXP,0.5300751879699248,"∥W (t)
kq ∥"
EXP,0.5310150375939849,"
1 + log

2Lmax∥W (t)
kq ∥
"
EXP,0.5319548872180451,"Proof. During the proof, we denote



 

"
EXP,0.5328947368421053,"a(n,t)
ℓ
= (x(n)
ℓ
)⊤W (t)
kq X(n)
−1"
EXP,0.5338345864661654,"a(n,∗)
ℓ
= (x(n)
ℓ
)⊤W ∗
kqX(n)
−1
∥W (t)
kq ∥"
EXP,0.5347744360902256,"∥W ∗
kq∥"
EXP,0.5357142857142857,"β0 =
2L2
max∥W ∗
kq∥2"
EXP,0.5366541353383458,"∥W (t)
kq ∥
(1 + log(2Lmax∥W (t)
kq ∥))."
EXP,0.5375939849624061,We point out a few facts that will be frequently used in the proof.
EXP,0.5385338345864662,"If a(n,t)
ℓ
≤a(n,t)
ℓ′
−C0, then we have"
EXP,0.5394736842105263,"φ(n,t)
ℓ
= φ(n,t)
ℓ′
exp

a(n,t)
ℓ
−a(n,t)
ℓ′

≤exp(−C0)
(11)"
EXP,0.5404135338345865,"The same result holds if a(n,t)
ℓ′
is replaced any convex combination of a set of a(n,t)
ℓ′
’s."
EXP,0.5413533834586466,"We start the proof by noting that W ∗
kq is the minimum unique solution to the problem"
EXP,0.5422932330827067,"W ∗
kq = arg min ∥W∥,
s.t.
(x(n)
ℓ∗−x(n)
ℓ
)WX(n)
−1 ≥1,
∀ℓ∗∈l(n), ℓ/∈l(n), ∀n.
(12)"
EXP,0.543233082706767,"Therefore, if W (t)
kq
∥W ∗
kq∥"
EXP,0.5441729323308271,"∥W (t)
kq ∥= W ∗
kq, the results is trivial since
D
∇WkqL(θ(t)), W ∗
kq
E
≤0."
EXP,0.5451127819548872,"In the following, we focus on the case when W (t)
kq
∥W ∗
kq∥"
EXP,0.5460526315789473,"∥W (t)
kq ∦= W ∗
kq. Then, there must be at least a"
EXP,0.5469924812030075,"sentence X(n), such that W (t)
kq
∥W ∗
kq∥"
EXP,0.5479323308270677,"∥W (t)
kq ∥violates the contraint on X(n). In other words, we must have"
EXP,0.5488721804511278,"a(n,t)
ℓ∗
−a(n,t)
ℓ
= (x(n)
ℓ∗−x(n)
ℓ
)W (t)
kq X(n)
−1 ≤
∥W (t)
kq ∥"
EXP,0.549812030075188,"∥W ∗
kq∥."
EXP,0.5507518796992481,"This implies that for those n, we must have φ(n,t)
ℓ
≥exp(−
∥W (t)
kq ∥
∥W ∗
kq∥)"
EXP,0.5516917293233082,"Thus, we consider two types of samples in the folloiwng."
EXP,0.5526315789473685,"Type 1. Let us consider X(n) such that φ(n,t)
−
≥exp(−(1 + β0/2)∥W (t)
kq ∥/∥W ∗
kq∥)."
EXP,0.5535714285714286,"Recall that the inner product between the gradient ∇WkqL(θ(t)) and any other Key-Query matrix
θ′ = W ′
kq has the following form (Lemma 4)."
EXP,0.5545112781954887,"D
∇WkqL(θ(t)), W ′
kq
E = ∆
X"
EXP,0.5554511278195489,"n
π(n)([T(n)
θ ]In(X(n)) −1)
X"
EXP,0.556390977443609,"ℓ∗∈l(n)
φ(n,θ)
ℓ∗ "
EXP,0.5573308270676691,"x(n)
ℓ∗−
X"
EXP,0.5582706766917294,"ℓ′
φ(n,θ)
ℓ′
x(n)
ℓ′ !⊤"
EXP,0.5592105263157895,"W ′
kqX(n)
−1 + ∆
X"
EXP,0.5601503759398496,"n
π(n) X"
EXP,0.5610902255639098,"ℓ/∈l(n)
[T(n)
θ ]In(x(n)
ℓ
)φ(n,θ)
ℓ "
EXP,0.5620300751879699,"x(n)
ℓ
−
X"
EXP,0.5629699248120301,"ℓ′
φ(n,θ)
ℓ′
x(n)
ℓ′ !⊤"
EXP,0.5639097744360902,"W ′
kqX(n)
−1"
EXP,0.5648496240601504,"Let Ln(θ) = −log e⊤
In(X(n))Tθ(X(n)) be the loss on sample X(n)."
EXP,0.5657894736842105,"To proceed, we examine the gradient on each sample X(n) with φ(n,t)
−
≥
exp(−(1 +
β0/2)∥W (t)
kq ∥/∥W ∗
kq∥), which can be divided into two parts.

∇WkqLn(θ(t)), Wkq

= ∆(A(n,t) +
B(n,t)), where






"
EXP,0.5667293233082706,"




"
EXP,0.5676691729323309,"A(n,t) =
X"
EXP,0.568609022556391,"ℓ∗∈l(n)
([T(n)
θ(t)]In(x(n)
ℓ∗) −1)φ(n,t)
ℓ∗ "
EXP,0.5695488721804511,"a(n,t)
ℓ∗
−
X"
EXP,0.5704887218045113,"ℓ′
φ(n,t)
ℓ′
a(n,t)
ℓ′ ! ,"
EXP,0.5714285714285714,"B(n,t) =
X"
EXP,0.5723684210526315,"ℓ/∈l(n)
[T(n)
θ(t)]In(x(n)
ℓ
)φ(n,t)
ℓ "
EXP,0.5733082706766918,"a(n,t)
ℓ
−
X"
EXP,0.5742481203007519,"ℓ′
φ(n,t)
ℓ′
a(n,t)
ℓ′ ! ."
EXP,0.575187969924812,We further let
EXP,0.5761278195488722,"A(n,∗) =
X"
EXP,0.5770676691729323,"ℓ∗∈l(n)
([T(n)
θ(t)]In(x(n)
ℓ
) −1)φ(n,t)
ℓ∗ "
EXP,0.5780075187969925,"a(n,∗)
ℓ∗
−
X"
EXP,0.5789473684210527,"ℓ′
φ(n,t)
ℓ′
a(n,∗)
ℓ′ ! , and"
EXP,0.5798872180451128,"B(n,∗) =
X"
EXP,0.5808270676691729,"ℓ/∈l(n)
[T(n)
θ(t)]In(x(n)
ℓ
)φ(n,t)
ℓ "
EXP,0.581766917293233,"a(n,∗)
ℓ
−
X"
EXP,0.5827067669172933,"ℓ′
φ(n,t)
ℓ′
a(n,∗)
ℓ′ ! ."
EXP,0.5836466165413534,"Thus, we aim to find the relationship A(n,t) + B(n,t) between A(n,∗) + B(n,∗)."
EXP,0.5845864661654135,"We first provide the upper bounds for A(n,∗) and B(n,∗)."
EXP,0.5855263157894737,"A(n,∗) =
X"
EXP,0.5864661654135338,"ℓ∗∈l(n)
([T(n)
θ(t)]In(x(n)
ℓ∗) −1)φ(n,t)
ℓ∗ "
EXP,0.5874060150375939,"a(n,∗)
ℓ∗
−
X"
EXP,0.5883458646616542,"ℓ′
φ(n,t)
ℓ′
a(n,∗)
ℓ′ ! =
X"
EXP,0.5892857142857143,"ℓ∗∈l(n)
([T(n)
θ(t)]In(x(n)
ℓ∗) −1)φ(n,t)
ℓ∗  X"
EXP,0.5902255639097744,"ℓ′ /∈l(n)
φ(n,t)
ℓ′
(a(n,∗)
ℓ∗
−a(n,∗)
ℓ′
)  "
EXP,0.5911654135338346,"(a)
≤([T(n)
θ(t)]In(X(n)) −1)φ(n,t)
+
φ(n,t)
−
∥W (t)
kq ∥"
EXP,0.5921052631578947,"∥W ∗
kq∥,"
EXP,0.5930451127819549,"where
(a)
is
due
to
the
fact
that
(x(n)
ℓ∗
−x(n)
ℓ
)W ∗
kqX(n)
−1
≥
1,
and
a(n,∗)
ℓ
="
EXP,0.5939849624060151,"(x(n)
ℓ
)⊤W ∗
kqX(n)
−1 ∥W (t)
kq ∥/∥W ∗
kq∥."
EXP,0.5949248120300752,On the other hand
EXP,0.5958646616541353,"A(n,t) =
X"
EXP,0.5968045112781954,"ℓ∈l(n)
([T(n)
θ(t)]In(x(n)
ℓ
) −1)φ(n,t)
ℓ "
EXP,0.5977443609022557,"a(n,t)
ℓ
−
X"
EXP,0.5986842105263158,"ℓ′
φ(n,t)
ℓ′
a(n,t)
ℓ′ ! =
X"
EXP,0.599624060150376,"ℓ∈l(n)
([T(n)
θ(t)]In(x(n)
ℓ
) −1)φ(n,t)
ℓ  X"
EXP,0.6005639097744361,"ℓ′ /∈l(n)
φ(n,t)
ℓ′
(a(n,t)
ℓ
−a(n,t)
ℓ′
)  "
EXP,0.6015037593984962,"= max
T 

 
 X"
EXP,0.6024436090225563,"ℓ∈l(n)
([T(n)
θ(t)]In(x(n)
ℓ
) −1)φ(n,t)
ℓ  

X"
EXP,0.6033834586466166,"ℓ′ /
∈l(n)
diff<T"
EXP,0.6043233082706767,"φ(n,t)
ℓ′
(a(n,t)
ℓ
−a(n,t)
ℓ′
)
|
{z
}
diff  
 +
X"
EXP,0.6052631578947368,"ℓ∈l(n)
([T(n)
θ(t)]In(x(n)
ℓ
) −1)φ(n,t)
ℓ  

X"
EXP,0.606203007518797,"ℓ′ /
∈l(n)
diff>T"
EXP,0.6071428571428571,"φ(n,t)
ℓ′
(a(n,t)
ℓ
−a(n,t)
ℓ′
)
|
{z
}
diff  
 

 

."
EXP,0.6080827067669173,"(a)
≥max
T 
  X"
EXP,0.6090225563909775,"ℓ∈l(n)
([T(n)
θ(t)]In(x(n)
ℓ
) −1)φ(n,t)
ℓ  X"
EXP,0.6099624060150376,"ℓ′ /∈l(n)
φ(n,t)
ℓ′
T   +
X"
EXP,0.6109022556390977,"ℓ∈l(n)
([T(n)
θ(t)]In(x(n)
ℓ
) −1)φ(n,t)
ℓ  2
X"
EXP,0.6118421052631579,"ℓ′ /∈l(n)
exp(−T)∥W (t)
kq ∥   
 "
EXP,0.6127819548872181,"≥max
T 
  X"
EXP,0.6137218045112782,"ℓ∈l(n)
([T(n)
θ(t)]In(x(n)
ℓ
) −1)φ(n,t)
ℓ

φ(n,t)
−
T + 2Lmax exp(−T)∥W (t)
kq ∥


 "
EXP,0.6146616541353384,"(b)
≥
X"
EXP,0.6156015037593985,"ℓ∈l(n)
([T(n)
θ(t)]In(x(n)
ℓ
) −1)φ(n,t)
ℓ
φ(n,t)
− "
EXP,0.6165413533834586,"1 + log
2Lmax∥W (t)
kq ∥"
EXP,0.6174812030075187,"φ(n,t)
− ! ,"
EXP,0.618421052631579,"where (a) is due to Equation (11), and (b) is obtained by choosing T = log
2Lmax∥W (t)
kq ∥"
EXP,0.6193609022556391,"φ(n,t)
−
."
EXP,0.6203007518796992,"Recall that φ(n,t)
−
≥exp

−(1 + β0/2)∥W (t)
kq ∥/∥W ∗
kq∥

and β0 ≥
2∥W ∗
kq∥(1+log(2Lmax∥W (t)
kq ∥))"
EXP,0.6212406015037594,"∥W (t)
kq ∥
."
EXP,0.6221804511278195,"Thus, we further have"
EXP,0.6231203007518797,"A(n,t) ≥([T(n)
θ(t)]In(X(n)) −1)φ(n,t)
+
φ(n,t)
− "
EXP,0.6240601503759399,"1 + log
2Lmax∥W (t)
kq ∥"
EXP,0.625,"φ(n,t)
− !"
EXP,0.6259398496240601,"≥([T(n)
θ(t)]In(X(n)) −1)φ(n,t)
+
φ(n,t)
− "
EXP,0.6268796992481203,"1 + log(2Lmax∥W (t)
kq ∥) + (1 + β0/2)
∥W (t)
kq ∥"
EXP,0.6278195488721805,"∥W ∗
kq∥ !"
EXP,0.6287593984962406,"≥([T(n)
θ(t)]In(X(n)) −1)φ(n,t)
+
φ(n,t)
−"
EXP,0.6296992481203008,"β0∥W (t)
kq ∥"
EXP,0.6306390977443609,"2∥W ∗
kq∥+ (1 + β0/2)
∥W (t)
kq ∥"
EXP,0.631578947368421,"∥W ∗
kq∥ !"
EXP,0.6325187969924813,"= (1 + β0)([T(n)
θ(t)]In(X(n)) −1)φ(n,t)
+
φ(n,t)
−
∥W (t)
kq ∥"
EXP,0.6334586466165414,"∥W ∗
kq∥"
EXP,0.6343984962406015,"≥(1 + β0)A(n,∗)"
EXP,0.6353383458646616,"Next, we analyze B(n,t), and further divide B(n,θ) into B(n,θ)
+
and B(n,θ)
−
:"
EXP,0.6362781954887218,"






"
EXP,0.6372180451127819,"





"
EXP,0.6381578947368421,"B(n,θ)
+
=
X"
EXP,0.6390977443609023,"ℓ/∈l(n)
[T(n)
θ(t)]In(x(n)
ℓ
)φ(n,t)
ℓ "
EXP,0.6400375939849624,"φ(n,t)
+
a(n,θ)
ℓ
−
X"
EXP,0.6409774436090225,"ℓ′∈l(n)
φ(n,t)
ℓ′
a(n,θ)
ℓ′  "
EXP,0.6419172932330827,"B(n,θ)
−
=
X"
EXP,0.6428571428571429,"ℓ/∈l(n)
[T(n)
θ(t)]In(x(n)
ℓ
)φ(n,t)
ℓ "
EXP,0.643796992481203,"φ(n,t)
−
a(n,θ)
ℓ
−
X"
EXP,0.6447368421052632,"ℓ′ /∈l(n)
φ(n,t)
ℓ′
a(n,θ)
ℓ′  "
EXP,0.6456766917293233,"Due to Proposition 4, we have B(n,∗)
−
= 0, and thus"
EXP,0.6466165413533834,"B(n,∗) = B(n,∗)
+
≤
X"
EXP,0.6475563909774437,"ℓ/∈l(n)
[T(n)
θ(t)]In(x(n)
ℓ
)φ(n,t)
ℓ
(−φ(n,t)
+
)
∥W (t)
kq ∥"
EXP,0.6484962406015038,"∥W ∗
kq∥≤0."
EXP,0.6494360902255639,We then analyze:
EXP,0.650375939849624,"B(n,t)
+
−(1 + β0)B(n,∗)
+ =
X"
EXP,0.6513157894736842,"ℓ/∈l(n)
[T(n)
θ(t)]In(x(n)
ℓ
)φ(n,t)
ℓ

φ(n,t)
+
a(n,t)
ℓ
−φ(n,t)
+
a(n,t)
ℓ∗
−(1 + β0)

φ(n,t)
+
a(n,∗)
ℓ
−φ(n,t)
+
a(n,∗)
ℓ∗  =
X"
EXP,0.6522556390977443,"ℓ/∈l(n)
[T(n)
θ(t)]In(x(n)
ℓ
)φ(n,t)
ℓ
φ(n,t)
+ "
EXP,0.6531954887218046,"

a(n,t)
ℓ
−a(n,t)
ℓ∗
|
{z
}
bt,ℓ"
EXP,0.6541353383458647,"−(1 + β0)

a(n,∗)
ℓ
−a(n,∗)
ℓ∗ "
EXP,0.6550751879699248,"|
{z
}
b∗,ℓ  

 ≥
X"
EXP,0.6560150375939849,"ℓ/
∈l(n)
bt,ℓ<b∗,ℓ"
EXP,0.6569548872180451,"[T(n)
θ(t)]In(x(n)
ℓ
)φ(n,t)
ℓ
φ(n,t)
+
(bt,ℓ−b∗,ℓ)"
EXP,0.6578947368421053,"(a)
≥
X"
EXP,0.6588345864661654,"ℓ/∈l(n)
[T(n)
θ(t)]In(x(n)
ℓ
)φ(n,t)
+
exp "
EXP,0.6597744360902256,"−(1 + β0)
∥W (t)
kq ∥"
EXP,0.6607142857142857,"∥W ∗
kq∥"
EXP,0.6616541353383458,"! 
−2∥W (t)
kq ∥
"
EXP,0.6625939849624061,"= −2
X"
EXP,0.6635338345864662,"ℓ/∈l(n)
[T(n)
θ(t)]In(x(n)
ℓ
)φ(n,t)
+
exp "
EXP,0.6644736842105263,"−(1 + β0/2)
∥W (t)
kq ∥"
EXP,0.6654135338345865,"∥W ∗
kq∥ !"
EXP,0.6663533834586466,"∥W (t)
kq ∥exp  −β0 2"
EXP,0.6672932330827067,"∥W (t)
kq ∥"
EXP,0.668233082706767,"∥W ∗
kq∥ !"
EXP,0.6691729323308271,"(b)
≥−2Lmax(1 −[T(n)
θ(t)]In(X(n)))φ(n,t)
+
φ(n,t)
−
∥W (t)
kq ∥"
EXP,0.6701127819548872,"∥W ∗
kq∥exp  −β0 2"
EXP,0.6710526315789473,"∥W (t)
kq ∥"
EXP,0.6719924812030075,"∥W ∗
kq∥ !"
EXP,0.6729323308270677,"∥W ∗
kq∥"
EXP,0.6738721804511278,≥2Lmax exp  −β0 2
EXP,0.674812030075188,"∥W (t)
kq ∥"
EXP,0.6757518796992481,"∥W ∗
kq∥ !"
EXP,0.6766917293233082,"∥W ∗
kq∥A(n,∗)"
EXP,0.6776315789473685,"(c)
≥
∥W ∗
kq∥"
EXP,0.6785714285714286,"∥W (t)
kq ∥
A(n,∗)"
EXP,0.6795112781954887,"≥β0A(n,∗),"
EXP,0.6804511278195489,"where (a) follows from that b∗,ℓ≤−(1+β0)∥W (t)
kq ∥/∥W ∗
kq∥and Equation (11), and (b) is due to the"
EXP,0.681390977443609,fact that P
EXP,0.6823308270676691,"i∈[|V|][T(n)
θ ]i = 1 for any θ, n, and (c) follows from β0/2 ≥
∥W ∗
kq∥"
EXP,0.6832706766917294,"∥W (t)
kq ∥log(2Lmax∥W (t)
kq ∥)"
EXP,0.6842105263157895,"For the term B(n,t)
−
, we have"
EXP,0.6851503759398496,"B(n,t)
−
=
X"
EXP,0.6860902255639098,"ℓ/∈l(n)
[T(n)
θ(t)]In(x(n)
ℓ
)φ(n,t)
ℓ "
EXP,0.6870300751879699,"φ(n,t)
−
a(n,t)
ℓ
−
X"
EXP,0.6879699248120301,"ℓ′ /∈l(n)
φ(n,t)
ℓ′
a(n,t)
ℓ′   =
X"
EXP,0.6889097744360902,"ℓ/∈l(n)
[T(n)
θ(t)]In(x(n)
ℓ
)φ(n,t)
ℓ
φ(n,t)
− "
EXP,0.6898496240601504,"a(n,t)
ℓ
−
X"
EXP,0.6907894736842105,ℓ′ /∈l(n)
EXP,0.6917293233082706,"φ(n,t)
ℓ′"
EXP,0.6926691729323309,"φ(n,t)
−
a(n,t)
ℓ′  "
EXP,0.693609022556391,"= max
T>0"
EXP,0.6945488721804511,"




"
EXP,0.6954887218045113,"



 X"
EXP,0.6964285714285714,"ℓ/
∈l(n)
diff>−T"
EXP,0.6973684210526315,"[T(n)
θ(t)]In(x(n)
ℓ
)φ(n,t)
ℓ
φ(n,t)
− "
EXP,0.6983082706766918,"




a(n,t)
ℓ
−
X"
EXP,0.6992481203007519,ℓ′ /∈l(n)
EXP,0.700187969924812,"φ(n,t)
ℓ′"
EXP,0.7011278195488722,"φ(n,t)
−
a(n,t)
ℓ′"
EXP,0.7020676691729323,"|
{z
}
diff "
EXP,0.7030075187969925,"



 +
X"
EXP,0.7039473684210527,"ℓ/
∈l(n)
diff<−T"
EXP,0.7048872180451128,"[T(n)
θ(t)]In(x(n)
ℓ
)φ(n,t)
ℓ
φ(n,t)
− "
EXP,0.7058270676691729,"




a(n,t)
ℓ
−
X"
EXP,0.706766917293233,ℓ′ /∈l(n)
EXP,0.7077067669172933,"φ(n,t)
ℓ′"
EXP,0.7086466165413534,"φ(n,t)
−
a(n,t)
ℓ′"
EXP,0.7095864661654135,"|
{z
}
diff "
EXP,0.7105263157894737,"



"
EXP,0.7114661654135338,"




"
EXP,0.7124060150375939,"



"
EXP,0.7133458646616542,"(a)
≥max
T>0 
  X"
EXP,0.7142857142857143,"ℓ/∈l(n)
[T(n)
θ(t)]In(x(n)
ℓ
)φ(n,t)
−

−φ(n,t)
ℓ
T −2∥W (t)
kq ∥exp(−T)


 "
EXP,0.7152255639097744,"(b)
≥−Lmax(1 −[T(n)
θ(t)]In(x(n)
ℓ∗))φ(n,t)
−

1 + log(2∥W (t)
kq ∥)
"
EXP,0.7161654135338346,"≥
Lmax∥W ∗
kq∥"
EXP,0.7171052631578947,"φ(n,t)
+
∥W (t)
kq ∥"
EXP,0.7180451127819549,"
1 + log(2∥W (t)
kq ∥)

A(n,∗)"
EXP,0.7189849624060151,"(c)
≥
L2
max∥W ∗
kq∥"
EXP,0.7199248120300752,"∥W (t)
kq ∥"
EXP,0.7208646616541353,"
1 + log(2∥W (t)
kq ∥)

A(n,∗)"
EXP,0.7218045112781954,"(d)
≥β0A(n,∗),"
EXP,0.7227443609022557,"where (a) follows from Equation (11), (b) is optained by choosing T = log(2∥W (t)
kq ∥), (c) follows"
EXP,0.7236842105263158,"from Lemma 5, and (d) is due to the fact that β0 ≥
L2
max∥W ∗
kq∥"
EXP,0.724624060150376,"∥W (t)
kq ∥
(1 + log(2∥W (t)
kq ∥))."
EXP,0.7255639097744361,"So far, we have shown that for if φ(n,t)
−
≥exp(−(1 + β0/2)∥W (t)
kq ∥/∥W ∗
kq∥), then"
EXP,0.7265037593984962,"A(n,t) + B(n,t) = A(n,t) + B(n,t)
+
+ B(n,t)
−"
EXP,0.7274436090225563,"≥(1 + β0)A(n,∗) +

(1 + β0)B(n,∗) + β0A(n,∗)
+ β0A(n,∗)"
EXP,0.7283834586466166,"= (1 + 3β0)A(n,∗) + (1 + β0)B(n,∗)"
EXP,0.7293233082706767,"≥(1 + 3β0)(A(n,∗) + B(n,∗))."
EXP,0.7302631578947368,"Type 2. Now consider sentence X(n) such that φ(n,t)
−
< exp(−(1 + β0/2)∥W (t)
kq ∥/∥W ∗
kq∥)."
EXP,0.731203007518797,"Let n0 be the type 1 sample such that φ(n0,t)
−
≥exp(−∥W (t)
kq ∥/∥W ∗
kq∥)"
EXP,0.7321428571428571,"Then, we aim to show that"
EXP,0.7330827067669173,"A(n,t) + B(n,t) ≥β0A(n0,∗)"
EXP,0.7340225563909775,Note that
EXP,0.7349624060150376,"A(n,t) ≥
X"
EXP,0.7359022556390977,"ℓ∗∈l(n)
([T(n)
θ(t)]In(x(n)
ℓ∗) −1)φ(n,t)
ℓ∗
φ(n,t)
− "
EXP,0.7368421052631579,"1 + log
Lmax∥W (t)
kq ∥"
EXP,0.7377819548872181,"φ(n,t)
− !"
EXP,0.7387218045112782,"≥([T(n)
θ(t)]In(x(n)
ℓ∗) −1) exp "
EXP,0.7396616541353384,"−(1 + β0/2)
∥W (t)
kq ∥"
EXP,0.7406015037593985,"∥W ∗
kq∥ !"
EXP,0.7415413533834586,"1 + (1 + β0/2)
∥W (t)
kq ∥"
EXP,0.7424812030075187,"∥W ∗
kq∥+ log(Lmax∥W (t)
kq ∥) !"
EXP,0.743421052631579,"≥(1 + β0)([T(n)
θ(t)]In(x(n)
ℓ∗) −1) exp "
EXP,0.7443609022556391,"−(1 + β0/2)
∥W (t)
kq ∥"
EXP,0.7453007518796992,"∥W ∗
kq∥"
EXP,0.7462406015037594,"!
∥W (t)
kq ∥"
EXP,0.7471804511278195,"∥W ∗
kq∥ and"
EXP,0.7481203007518797,"B(n,t) =
X"
EXP,0.7490601503759399,"ℓ/∈l(n)
[T(n)
θ(t)]In(x(n)
ℓ
)φ(n,t)
ℓ "
EXP,0.75,"a(n,t)
ℓ
−
X"
EXP,0.7509398496240601,"ℓ′
φ(n,t)
ℓ′
a(n,t)
ℓ′ !"
EXP,0.7518796992481203,"≥−2(1 −[T(n)
θ(t)]In(x(n)
ℓ∗)) exp "
EXP,0.7528195488721805,"−(1 + β0/2)
∥W (t)
kq ∥"
EXP,0.7537593984962406,"∥W ∗
kq∥ !"
EXP,0.7546992481203008,"∥W (t)
kq ∥ Since"
EXP,0.7556390977443609,"A(n0,∗) ≤([T(n0)
θ(t) ]In(x(n0)
ℓ∗
) −1)φ(n0,t)
+
φ(n0,t)
−
∥W (t)
kq ∥"
EXP,0.756578947368421,"∥W ∗
kq∥"
EXP,0.7575187969924813,"≤([T(n0)
θ(t) ]In(x(n0)
ℓ∗
) −1)φ(n0,t)
+
exp "
EXP,0.7584586466165414,"−
∥W (t)
kq ∥"
EXP,0.7593984962406015,"∥W ∗
kq∥"
EXP,0.7603383458646616,"!
∥W (t)
kq ∥"
EXP,0.7612781954887218,"∥W ∗
kq∥"
EXP,0.7622180451127819,"We further note that [T(n0)
θ(t) ]In(x(n0)
ℓ∗
) < [T(n)
θ(t)]In(x(n)
ℓ∗) due to φ(n0,t)
+
< φ(n,t)
+
. Thus,"
EXP,0.7631578947368421,"A(n,t) + B(n,t) ≥exp "
EXP,0.7640977443609023,"−β0/2
∥W (t)
kq ∥"
EXP,0.7650375939849624,"∥W ∗
kq∥ !"
EXP,0.7659774436090225,"(1 + β0 + 2∥Wkq∗∥) A(n0,∗)"
EXP,0.7669172932330827,"φ(n0,t)
+"
EXP,0.7678571428571429,"(a)
≥β0A(n0,∗),"
EXP,0.768796992481203,"where (a) is due to that β0 ≥
2∥W ∗
kq∥(1+2∥W ∗
kq∥)"
EXP,0.7697368421052632,"∥W (t)
kq ∥
log(1 +
∥W (t)
kq ∥
2∥W ∗
kq∥), ∥W (t)
kq ∥≥2(e −1)∥W ∗
kq∥, and"
EXP,0.7706766917293233,"β0 ≥
2∥W ∗
kq∥"
EXP,0.7716165413533834,"∥W (t)
kq ∥
log
1 + β0 + 2∥W ∗
kq∥
β0
."
EXP,0.7725563909774437,"In summary, we have that X"
EXP,0.7734962406015038,"n
π(n)(A(n,t) + B(n,t)) =
X"
EXP,0.7744360902255639,"n is type 2
π(n)(A(n,t) + B(n,t)) +
X"
EXP,0.775375939849624,"n is type 1
π(n)(A(n,t) + B(n,t))"
EXP,0.7763157894736842,"≥
max
n0 is type 1 β0A(n0,∗) +
X"
EXP,0.7772556390977443,"n is type 1
π(n)((1 + 3β0)A(n,∗) + (1 + β1)B(n,∗)) ≥
X"
EXP,0.7781954887218046,"n is type 1
Nπ(n)β0(A(n,∗) + B(n,∗)) + (1 + 3β0)
X"
EXP,0.7791353383458647,"n is type 1
π(n)(A(n,∗) + B(n,∗))"
EXP,0.7800751879699248,"≥(1 + (N + 3)β0)
X"
EXP,0.7810150375939849,"n is type 1
π(n)(A(n,∗) + B(n,∗))"
EXP,0.7819548872180451,"≥(1 + αt)
X"
EXP,0.7828947368421053,"n is type 2
π(n)(A(n,∗) + B(n,∗)) + (1 + αt)
X"
EXP,0.7838345864661654,"n is type 1
π(n)(A(n0,∗) + B(n0,∗))"
EXP,0.7847744360902256,"= (1 + αt)
X"
EXP,0.7857142857142857,"n
π(n)(A(n,∗) + B(n,∗)),"
EXP,0.7866541353383458,where αt ≥(N + 3)β0. The proof is finished.
EXP,0.7875939849624061,"Now, we are ready to prove Theorem 1."
EXP,0.7885338345864662,"C.5
Proof of Theorem 1"
EXP,0.7894736842105263,Proof of Theorem 1.
EXP,0.7904135338345865,"Recall that αt =
4NL2
max∥W ∗
kq∥2"
EXP,0.7913533834586466,"∥W (t)
kq ∥"
EXP,0.7922932330827067,"
1 + log

2Lmax∥W (t)
kq ∥

. By Lemma 7, we have *"
EXP,0.793233082706767,"W (t+1)
kq
−W (t)
kq ,
W ∗
kq
∥W ∗
kq∥ + = −η *"
EXP,0.7941729323308271,"∇WkqL(θ(t)),
W ∗
kq
∥W ∗
kq∥ +"
EXP,0.7951127819548872,"≥−
η
1 + αt *"
EXP,0.7960526315789473,"∇WkqL(θ(t)),
W (t)
kq
∥W (t)
kq ∥ +"
EXP,0.7969924812030075,"=
1
1 + αt *"
EXP,0.7979323308270677,"W (t+1)
kq
−W (t)
kq ,
W (t)
kq
∥W (t)
kq ∥ + =
1"
EXP,0.7988721804511278,"2∥W (t)
kq ∥"
EXP,0.799812030075188,"
∥W (t+1)
kq
∥2 −∥W (t+1)
kq
−W (t)
kq ∥2 −∥W (t)
kq ∥2
−
αt
1 + αt *"
EXP,0.8007518796992481,"W (t+1)
kq
−W (t)
kq ,
W (t)
kq
∥W (t)
kq ∥ +"
EXP,0.8016917293233082,"=
∥W (t)
kq ∥2 −∥W (t)
kq ∥2"
EXP,0.8026315789473685,"2∥W (t)
kq ∥
−
η2"
EXP,0.8035714285714286,"2∥W (t)
kq ∥
+
ηαt
1 + αt"
EXP,0.8045112781954887,"*
∇WkqL(θ(t))
∥∇WkqL(θ(t))∥,
W (t)
kq
∥W (t)
kq ∥ +"
EXP,0.8054511278195489,"≥∥W (t+1)
kq
∥−∥W (t)
kq ∥−
η2"
EXP,0.806390977443609,"2∥W (t)
kq ∥
−
ηαt
1 + αt"
EXP,0.8073308270676691,"Let t0 = ⌈
8Lmax∥W ∗
kq∥2"
EXP,0.8082706766917294,"η
⌉be defined in Lemma 7. Summing over t from t0, we have
*"
EXP,0.8092105263157895,"W (t)
kq −W (t0)
kq ,
W ∗
kq
∥W ∗
kq∥ +"
EXP,0.8101503759398496,"≥∥W (t)
kq ∥−∥W (t0)
kq ∥− t−1
X t′=t0 η2"
EXP,0.8110902255639098,"2∥W (t′)
kq ∥
− t−1
X t′=t0"
EXP,0.8120300751879699,"ηαt′
1 + αt′"
EXP,0.8129699248120301,"By Lemma 6, we have t−1
X t′=t0 1"
EXP,0.8139097744360902,"∥W (t′)
kq ∥
≤ t−1
X t′=t0"
EXP,0.8148496240601504,"2Lmax∥W ∗
kq∥/η
t′"
EXP,0.8157894736842105,"≤
2Lmax∥W ∗
kq∥
η
log t."
EXP,0.8167293233082706,"Furthermore, t−1
X t′=t0"
EXP,0.8176691729323309,"αt′
1 + αt′ ≤ t−1
X"
EXP,0.818609022556391,"t′=t0
αt′ = t−1
X t′=t0"
EXP,0.8195488721804511,"4NL2
max∥W ∗
kq∥2"
EXP,0.8204887218045113,"∥W (t′)
kq ∥"
EXP,0.8214285714285714,"
1 + log

2Lmax∥W (t′)
kq ∥
 = t−1
X t′=t0"
EXP,0.8223684210526315,"4NL2
max∥W ∗
kq∥2"
EXP,0.8233082706766918,"∥W (t′)
kq ∥
(1 + log (2Lmax)) + t−1
X t′=t0"
EXP,0.8242481203007519,"4NL2
max∥W ∗
kq∥2"
EXP,0.825187969924812,"∥W (t′)
kq ∥
log ∥W (t′)
kq ∥ ≤ t−1
X t′=t0"
EXP,0.8261278195488722,"8NL3
max∥W ∗
kq∥3/η
t′
log(2eLmax) + t−1
X t′=t0"
EXP,0.8270676691729323,"8NL3
max∥W ∗
kq∥3/η
t′
log
t′"
EXP,0.8280075187969925,"2Lmax∥W ∗
kq∥/η = t−1
X t′=t0"
EXP,0.8289473684210527,"8NL3
max∥W ∗
kq∥3/η
t′
log(eη/∥W ∗
kq∥) + t−1
X t′=t0"
EXP,0.8298872180451128,"8NL3
max∥W ∗
kq∥3/η
t′
log(t′)"
EXP,0.8308270676691729,"(a)
≤
8NL3
max∥W ∗
kq∥3"
EXP,0.831766917293233,"η
log2 t,"
EXP,0.8327067669172933,"where (a) follows from η ≤∥W ∗
kq∥/e."
EXP,0.8336466165413534,"Therefore, we have
*"
EXP,0.8345864661654135,"W (t)
kq −W (t0)
kq ,
W ∗
kq
∥W ∗
kq∥ +"
EXP,0.8355263157894737,"≥∥W (t)
kq ∥−∥W (t0)
kq ∥− t−1
X t′=t0 η2"
EXP,0.8364661654135338,"2∥W (t′)
kq ∥
− t−1
X t′=t0"
EXP,0.8374060150375939,"ηαt′
1 + αt′"
EXP,0.8383458646616542,"≥∥W (t)
kq ∥−∥W (t0)
kq ∥−Lmax∥W ∗
kq∥log t −8NL3
max∥W ∗
kq∥3 log2 t."
EXP,0.8392857142857143,"Finally, by Lemma 6, and t0 ≤1 + 8Lmax∥W ∗
kq∥2/η, we have ∥W (t0)
kq ∥≤9Lmax∥W ∗
kq∥2, and
*
W (t)
kq
∥W (t)
kq ∥
,
W ∗
kq
∥W ∗
kq∥ +"
EXP,0.8402255639097744,"≥1 −
2∥W (t0)
kq ∥+ Lmax∥W ∗
kq∥log t + 8NL3
max∥W ∗
kq∥3 log2 t"
EXP,0.8411654135338346,"∥W (t)
kq ∥"
EXP,0.8421052631578947,"≥1 −
54NL4
max∥W ∗
kq∥4 log2 t
tη
."
EXP,0.8430451127819549,The proof is finished.
EXP,0.8439849624060151,"C.6
Proof of Theorem 2"
EXP,0.8449248120300752,Proof of Theorem 2.
EXP,0.8458646616541353,"Recall that T ≥384∥W ∗
ov∥5 log(2|V|) log T/η0, and ∆= Tη0/(4∥W ∗
ov∥2) due to Corollary 1 and"
EXP,0.8468045112781954,"(eIn(x) −ev)⊤W (T )
ov x =
Tη0
4∥W ∗ov∥2"
EXP,0.8477443609022557,Note that for all ℓ∗∈l(n) and ℓ/∈l(n)
EXP,0.8486842105263158,"(x(n)
ℓ
−x(n)
ℓ∗)⊤W (t)
kq X(n)
−1"
EXP,0.849624060150376,"=
∥W (t)
kq ∥"
EXP,0.8505639097744361,"∥W ∗
kq∥(x(n)
ℓ
−x(n)
ℓ∗)⊤W ∗
kqX(n)
−1 + (x(n)
ℓ
−x(n)
ℓ∗)⊤"
EXP,0.8515037593984962,"W (t)
kq −
∥W (t)
kq ∥"
EXP,0.8524436090225563,"∥W ∗
kq∥Wkq∗ !"
EXP,0.8533834586466166,"X(n)
−1"
EXP,0.8543233082706767,"≤−
∥W (t)
kq ∥"
EXP,0.8552631578947368,"∥W ∗
kq∥+ 2∥W (t)
kq ∥"
EXP,0.856203007518797,"W (t)
kq
∥W (t)
kq ∥
−
W ∗
kq
∥W ∗
kq∥ (13)"
EXP,0.8571428571428571,"≤−
tη
2Lmax∥W ∗
kq∥2 + √"
EXP,0.8580827067669173,"2tη
Lmax∥W ∗
kq∥ s"
EXP,0.8590225563909775,"54NL4max∥W ∗
kq∥4 log2 t tη"
EXP,0.8599624060150376,"(a)
≤−
tη
4Lmax∥W ∗
kq∥2 ,"
EXP,0.8609022556390977,"where (a) follows from t ≥1696NL4
max∥W ∗
kq∥6 log2 t/η."
EXP,0.8618421052631579,"Therefore,
X"
EXP,0.8627819548872181,"ℓ∗∈l(n)
φ(n,t)
ℓ∗
=
|l(n)|"
EXP,0.8637218045112782,|l(n)| + P
EXP,0.8646616541353384,"ℓ′ /∈l(n) exp

(x(n)
ℓ
−x(n)
ℓ∗)⊤W (t)
kq X(n)
−1
"
EXP,0.8656015037593985,"≥
|l(n)|"
EXP,0.8665413533834586,"|l(n)| + (L(n) −|l(n)|) exp

−
tη
4Lmax∥W ∗
kq∥2
 ≥
1"
EXP,0.8674812030075187,"1 + Lmax exp

−
tη
4Lmax∥W ∗
kq∥2
"
EXP,0.868421052631579,"≥
1
1 + ϵ,"
EXP,0.8693609022556391,"where the last inequality follows from t ≥
4Lmax∥W ∗
kq∥
η
log Lmax ϵ
."
EXP,0.8703007518796992,"Hence, the loss on the sentence X(n) satisfies that"
EXP,0.8712406015037594,"−log

e⊤
In(X(n))Tθ(t)(X(n))
"
EXP,0.8721804511278195,"= −log
exp

e⊤
In(X(n))W (T )
ov
P"
EXP,0.8731203007518797,"ℓx(n)
ℓ
φ(n,t)
ℓ
 P"
EXP,0.8740601503759399,"v≤|V| exp

e⊤
v W (T )
ov
P"
EXP,0.875,"ℓx(n)
ℓ
φ(n,t)
ℓ
"
EXP,0.8759398496240601,"= −log
1"
EXP,0.8768796992481203,"1 + P
v̸=In(X(n)) exp

(ev −eIn(X(n)))⊤W (T )
ov
P
ℓx(n)
ℓ
φ(n,t)
ℓ
 = log "
EXP,0.8778195488721805,"1 +
X"
EXP,0.8787593984962406,"v̸=In(X(n))
exp "
EXP,0.8796992481203008,"(ev −eIn(X(n)))⊤W (T )
ov
X"
EXP,0.8806390977443609,"ℓ/∈l(n)
x(n)
ℓ
φ(n,t)
ℓ     = log "
EXP,0.881578947368421,"1 +
X"
EXP,0.8825187969924813,"v̸=In(X(n))
exp  −∆
X"
EXP,0.8834586466165414,"ℓ∗∈l(n)
φ(n,t)
ℓ∗
+ ∆
X"
EXP,0.8843984962406015,"ℓ/∈l(n)
φ(n,t)
ℓ    "
EXP,0.8853383458646616,"≤|V| exp

−∆(2φ(n,t)
+
−1)
"
EXP,0.8862781954887218,≤|V| exp 
EXP,0.8872180451127819,"−∆+
2∆Lmax"
EXP,0.8881578947368421,"Lmax + exp

tη
4Lmax∥W ∗
kq∥2
  ."
EXP,0.8890977443609023,"Thus, the average loss has upper bound, which is"
EXP,0.8900375939849624,"|V| exp

−∆+
2∆Lmax
Lmax + exp(C1t) 
,"
EXP,0.8909774436090225,"for C1 = η/(4Lmax∥W ∗
kq∥2), and ∆= C0T for C0 = η0/(4∥W ∗
ov∥2)."
EXP,0.8919172932330827,"D
Proof of Proposition 2 and Theorem 3"
EXP,0.8928571428571429,"D.1
Proof of Proposition 2"
EXP,0.893796992481203,"Proposition 4 (Restatement of Proposition 2) Under Assumption 2, if W ∗
kq satisfies Equation (3),
i.e.,"
EXP,0.8947368421052632,"W ∗
kq = arg min ∥W∥,
s.t.
(x(n)
ℓ∗−x(n)
ℓ
)⊤Wx ≥1,
∀ℓ/∈l(n), ∀n."
EXP,0.8956766917293233,"In addition, for each query xq, if there are k optimal tokens under a xq-partial order, m non-
optimal tokens under xq-partial order, then, for any optimal token x∗, non-optimal token x, and
non-comparable token x0, we have"
EXP,0.8966165413533834,"x⊤
∗W ∗
kqxq =
m
k + m,
x⊤W ∗
kqxq = −
k
k + m,
x⊤
0 W ∗
kqxq = 0."
EXP,0.8975563909774437,"A direct result is that
(x(n)
ℓ
−x(n)
ℓ′ )⊤W ∗
kqX(n)
−1 = 0,
∀ℓ, ℓ′ /∈l(n)."
EXP,0.8984962406015038,"Proof. Let U ∈Rd be the rotation matrix such that Ux = eI(x). Because U preserves Frobenius
norm, the optimization problem in Equation (3) can be written as"
EXP,0.8994360902255639,"˜W ∗= arg min ∥W∥,
s.t.(eI(x(n)
ℓ∗) −eI(x(n)
ℓ
))⊤WeI(X(n)
−1 ) ≥1.
(14)"
EXP,0.900375939849624,"Notably ˜W ∗= UW ∗
kqU ⊤."
EXP,0.9013157894736842,"Note that {eI(X(n)
−1 )}n forms a standard basis. It suffices to minimize the norm of each column of W"
EXP,0.9022556390977443,"subject to the constraint (eI(x(n)
ℓ∗) −eI(x(n)
ℓ
))⊤WeI(X(n)
−1 ) ≥1."
EXP,0.9031954887218046,"Let us consider any column c of W, denoted as [w1, . . . , wd]⊤. Without loss of generality, we assume
that, for all X(n) with I(X(n)
−1 ) = c, the set of indices of the optimal tokens of those samples are"
EXP,0.9041353383458647,"{1, . . . , k}, and the set of indices of the non-optimal tokens are {k + 1, . . . , k + m}. Then, the
optimization problem Equation (14) reduces to the following problem
min w2
1 + . . . + w2
d,
s.t.
wi −wj ≥1,
∀i ≤k, j ∈Ai ⊂{k + 1, . . . , k + m},
(15)
where Ai is the set of indices of the non-optimal tokens in some samples whose optimal token has
index i."
EXP,0.9050751879699248,"In other words, each column of the solution of Equation (14) is the solution of Equation (15)."
EXP,0.9060150375939849,Note that Equation (15) is a convex problem with linear constraints. The Lagrangian function is
EXP,0.9069548872180451,"L(λ) = k+m
X"
EXP,0.9078947368421053,"i=1
w2
i + 2 m
X i=1 X"
EXP,0.9088345864661654,"j∈Ai
λij(1 −wi + wj),"
EXP,0.9097744360902256,"where we directly set wj = 0 for all j ∈{k + m + 1, . . . , d}. That is, non-comparable tokens have
value 0."
EXP,0.9107142857142857,"By KKT-condition, we have"
EXP,0.9116541353383458,"




"
EXP,0.9125939849624061,"



"
EXP,0.9135338345864662,"wi =
X"
EXP,0.9144736842105263,"j∈Ai
λij,
∀i ≤k"
EXP,0.9154135338345865,"wj = − k
X"
EXP,0.9163533834586466,"i=1
λij1{j ∈Ai},
∀k + 1 ≤j ≤k + m"
EXP,0.9172932330827067,"Thus,
min w2
1 + . . . + w2
d"
EXP,0.918233082706767,"= max
λ 

 

− k
X i=1  X"
EXP,0.9191729323308271,"j∈Ai
λij   2 − k+m
X j=k+1 k
X"
EXP,0.9201127819548872,"i=1
λij1{j ∈Ai} !2 + 2 m
X i=1 X"
EXP,0.9210526315789473,"j∈Ai
λij 

 
 Let"
EXP,0.9219924812030075,"L∗(λ) = − k
X i=1  X"
EXP,0.9229323308270677,"j∈Ai
λij   2 − k+m
X j=k+1 k
X"
EXP,0.9238721804511278,"i=1
λij1{j ∈Ai} !2 + 2 m
X i=1 X"
EXP,0.924812030075188,"j∈Ai
λij,"
EXP,0.9257518796992481,where λ ≥0. The maximum of L∗is achieved when ∇λL∗= 0. This implies that X
EXP,0.9266917293233082,"j∈Ai0
λi0j + k
X"
EXP,0.9276315789473685,"i=1
λij1{j0 ∈Ai} = 1,
∀1 ≤i0 ≤k < j0 ≤k + m."
EXP,0.9285714285714286,"Hence, we have wi −wj = 1 for all 1 ≤i ≤k < j ≤k + m, which means the optimum of the
original problem is achieved on the boundary. Therefore, we reduce the original problem to
min
x k(x + 1)2 + mx2,"
EXP,0.9295112781954887,"where x = wk+1 = . . . = wk+m. Hence, the optimal solution is w1 = . . . = wk = m/(m + k), and
wk+1 = . . . = wk+m = −k/(k + m)."
EXP,0.9304511278195489,"Therefore, the solution of Equation (15) satisfies that the “optimal values” are the same and the
“non-optimal values” are the same as well. This fact proves that"
EXP,0.931390977443609,"(x(n)
ℓ
−x(n)
ℓ′ )W ∗
kqX(n)
−1 = 0, ∀ℓ, ℓ′ /∈l(n)."
EXP,0.9323308270676691,"And moreover, if there are k optimal tokens under a xq-partial order, m non-optimal tokens under
xq-partial order, then, for any optimal token x∗and non-optimal token x, we have"
EXP,0.9332706766917294,"x⊤
∗W ∗
kqxq =
m
k + m,
x⊤W ∗
kqxq = −
k
k + m."
EXP,0.9342105263157895,"D.2
Proof of Theorem 3"
EXP,0.9351503759398496,"Proof. The proof follows similar logic to Theorem 2. By Equation (13), we have for any x, x′ ∈V"
EXP,0.9360902255639098,"(x −x′)⊤W (t)
kq xq"
EXP,0.9370300751879699,"≥
∥W (t)
kq ∥"
EXP,0.9379699248120301,"∥W ∗
kq∥(x −x′)⊤W ∗
kqxq − √"
EXP,0.9389097744360902,"2tη
Lmax∥W ∗
kq∥ s"
EXP,0.9398496240601504,"54NL4max∥W ∗
kq∥4 log2 t tη"
EXP,0.9407894736842105,"(a)
≥
tη
2Lmax∥W ∗
kq∥2 (x −x′)⊤W ∗
kqxq −
q"
EXP,0.9417293233082706,"108tηNL2max∥W ∗
kq∥2 log2 t,"
EXP,0.9426691729323309,where (a) follows from Lemma 6. The first part of Theorem 3 follows from Theorem 3.
EXP,0.943609022556391,"For the second part of Theorem 3, Let X = [x1, . . . , xL] such that for ℓ0 ∈l0 ⊂{1, . . . , L}, xℓ0 = x
is a non-comparable token, and other tokens are non-optimal under the xL-partial order."
EXP,0.9445488721804511,"Let φℓ∝exp(xℓW (t)
kq xL) for sufficiently large t = Ω(log(1/ϵ)) such that P"
EXP,0.9454887218045113,ℓ0∈l0 φℓ0 ≥1 −ϵ.
EXP,0.9464285714285714,"Then, we have"
EXP,0.9473684210526315,"e⊤
In(x)Tθ(t)(X) =
exp

e⊤
In(x)W (T )
ov
P"
EXP,0.9483082706766918,"ℓxℓφℓ
 P"
EXP,0.9492481203007519,"v≤|V| exp

e⊤
v W (T )
ov
P"
EXP,0.950187969924812,"ℓxℓφℓ
 =
1 1 + P"
EXP,0.9511278195488722,"v̸=In(x) exp

(ev −eIn(x))⊤W (T )
ov
P
ℓxℓφℓ
"
EXP,0.9520676691729323,"=
1
1 + P"
EXP,0.9530075187969925,"v̸=In(x) exp
 
−∆P"
EXP,0.9539473684210527,ℓ0∈l0 φℓ0 + ∆P
EXP,0.9548872180451128,"ℓ/∈l0 φℓ
"
EXP,0.9558270676691729,"≥
1
1 + |V| exp (−∆(1 −2ϵ))
≥1 −ϵ0,"
EXP,0.956766917293233,"where the last inequality follows from T = O(log(1/ϵ0)). Therefore, the trained transformer will
predict n(x), the next token of the non-comparable token."
EXP,0.9577067669172933,NeurIPS Paper Checklist
CLAIMS,0.9586466165413534,1. Claims
CLAIMS,0.9595864661654135,"Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?"
CLAIMS,0.9605263157894737,Answer: [Yes]
CLAIMS,0.9614661654135338,"Justification: We provide details of our three main claims made in the abstract in Section 4,
Section 5, and Section 6, respectively."
CLAIMS,0.9624060150375939,Guidelines:
CLAIMS,0.9633458646616542,"• The answer NA means that the abstract and introduction do not include the claims
made in the paper.
• The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
• The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
• It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper."
LIMITATIONS,0.9642857142857143,2. Limitations
LIMITATIONS,0.9652255639097744,Question: Does the paper discuss the limitations of the work performed by the authors?
LIMITATIONS,0.9661654135338346,"Answer: [Yes]
Justification: Our paper has specified the assumptions (Assumption 1,Assumption 2, and
Assumption 3) under which our results hold."
LIMITATIONS,0.9671052631578947,Guidelines:
LIMITATIONS,0.9680451127819549,"• The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate ""Limitations"" section in their paper.
• The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
• The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
• The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
• The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
• If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
• While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations."
THEORY ASSUMPTIONS AND PROOFS,0.9689849624060151,3. Theory Assumptions and Proofs
THEORY ASSUMPTIONS AND PROOFS,0.9699248120300752,"Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?"
THEORY ASSUMPTIONS AND PROOFS,0.9708646616541353,"Answer: [Yes]
Justification: We provide the full proofs in the appendix and title them as the “proof of
lemmas, propositions, and theorems”. Each proof can be easily found from the table of
contents.
Guidelines:"
THEORY ASSUMPTIONS AND PROOFS,0.9718045112781954,"• The answer NA means that the paper does not include theoretical results.
• All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
• All assumptions should be clearly stated or referenced in the statement of any theorems.
• The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
• Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4. Experimental Result Reproducibility"
THEORY ASSUMPTIONS AND PROOFS,0.9727443609022557,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it aoects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: We provide our experiment details in Section 7, including the model dimension,
vocabulary size, the learning rate, and the iteration number. The experiment follows exactly
of Algorithm 1.
Guidelines:"
THEORY ASSUMPTIONS AND PROOFS,0.9736842105263158,"• The answer NA means that the paper does not include experiments.
• If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
• If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
• Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
• While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a) If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b) If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c) If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d) We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results."
OPEN ACCESS TO DATA AND CODE,0.974624060150376,5. Open access to data and code
OPEN ACCESS TO DATA AND CODE,0.9755639097744361,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: We provide our code in the supplemental. We do not use open source data.
Guidelines:"
OPEN ACCESS TO DATA AND CODE,0.9765037593984962,"• The answer NA means that paper does not include experiments requiring code.
• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
public/guides/CodeSubmissionPolicy) for more details.
• While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
• The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines (https:
//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
• The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
• The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
• At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
• Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6. Experimental Setting/Details"
OPEN ACCESS TO DATA AND CODE,0.9774436090225563,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: Our experiment details are provided in Section 7.
Guidelines:"
OPEN ACCESS TO DATA AND CODE,0.9783834586466166,"• The answer NA means that the paper does not include experiments.
• The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
• The full details can be provided either with the code, in appendix, or as supplemental
material.
7. Experiment Statistical Significance"
OPEN ACCESS TO DATA AND CODE,0.9793233082706767,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: As our synthetic dataset and training process is fixed, we do not foresee
significant errors.
Guidelines:"
OPEN ACCESS TO DATA AND CODE,0.9802631578947368,"• The answer NA means that the paper does not include experiments.
• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
• The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions)."
OPEN ACCESS TO DATA AND CODE,0.981203007518797,"• The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
• It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
• It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
• For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
• If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8. Experiments Compute Resources"
OPEN ACCESS TO DATA AND CODE,0.9821428571428571,"Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]"
OPEN ACCESS TO DATA AND CODE,0.9830827067669173,"Justification: Our experiment is on synthetic data and is computationally lightweight, which
does not require any GPU. The running time is also within a hour.
Guidelines:"
OPEN ACCESS TO DATA AND CODE,0.9840225563909775,"• The answer NA means that the paper does not include experiments.
• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
• The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
• The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9. Code Of Ethics"
OPEN ACCESS TO DATA AND CODE,0.9849624060150376,"Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
Answer: [Yes]
Justification: We follow exactly the code of ethics.
Guidelines:"
OPEN ACCESS TO DATA AND CODE,0.9859022556390977,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
• If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10. Broader Impacts"
OPEN ACCESS TO DATA AND CODE,0.9868421052631579,"Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: This paper presents work whose goal is to advance the field of Machine
Learning. There are many potential societal consequences of our work, none which we feel
must be specifically highlighted here.
Guidelines:"
OPEN ACCESS TO DATA AND CODE,0.9877819548872181,"• The answer NA means that there is no societal impact of the work performed.
• If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact."
OPEN ACCESS TO DATA AND CODE,0.9887218045112782,"• Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
• The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
• The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
• If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11. Safeguards"
OPEN ACCESS TO DATA AND CODE,0.9896616541353384,"Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: Our paper is primarily a theoretical work, and does not have such risk.
Guidelines:"
OPEN ACCESS TO DATA AND CODE,0.9906015037593985,"• The answer NA means that the paper poses no such risks.
• Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
• Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
• We recognize that providing eoective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith eoort.
12. Licenses for existing assets"
OPEN ACCESS TO DATA AND CODE,0.9915413533834586,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [NA]
Justification: Our paper is primarily a theoretical work, and does not use any assets.
Guidelines:"
OPEN ACCESS TO DATA AND CODE,0.9924812030075187,"• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
• The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
• For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
• If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset."
OPEN ACCESS TO DATA AND CODE,0.993421052631579,"• For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
• If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13. New Assets"
OPEN ACCESS TO DATA AND CODE,0.9943609022556391,"Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: Our paper is primarily a theoretical work, and does not release any assets.
Guidelines:"
OPEN ACCESS TO DATA AND CODE,0.9953007518796992,"• The answer NA means that the paper does not release new assets.
• Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
• The paper should discuss whether and how consent was obtained from people whose
asset is used.
• At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14. Crowdsourcing and Research with Human Subjects"
OPEN ACCESS TO DATA AND CODE,0.9962406015037594,"Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: Our paper is primarily a theoretical work, and does not involve crowdsourcing
nor research with human subjects.
Guidelines:"
OPEN ACCESS TO DATA AND CODE,0.9971804511278195,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: Our paper is primarily a theoretical work, and does not involve crowdsourcing
nor research with human subjects.
Guidelines:"
OPEN ACCESS TO DATA AND CODE,0.9981203007518797,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
• We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution."
OPEN ACCESS TO DATA AND CODE,0.9990601503759399,"• For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review."
