Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0010741138560687433,"A recent research has shown that an extreme interpretation of imperfect recall
1"
ABSTRACT,0.0021482277121374865,"abstraction – completely forgetting all past information – has led to excessive ab-
2"
ABSTRACT,0.00322234156820623,"straction issues. Currently, there are no hand abstraction algorithms that effectively
3"
ABSTRACT,0.004296455424274973,"integrate historical information. This paper aims to develop the first such algorithm.
4"
ABSTRACT,0.0053705692803437165,"Initially, we introduce the KRWI abstraction for Texas Hold’em-style games, which
5"
ABSTRACT,0.00644468313641246,"categorizes hands based on K-recall winrate features that incorporate historical
6"
ABSTRACT,0.007518796992481203,"information. Statistical results indicate that, in terms of the number of distinct
7"
ABSTRACT,0.008592910848549946,"infosets identified, KRWI significantly outperforms POI, an abstraction that identi-
8"
ABSTRACT,0.00966702470461869,"fies the most abstracted infosets that forget all historical information. Following
9"
ABSTRACT,0.010741138560687433,"this, we introduce the KrwEmd algorithm, the first hand abstraction algorithm to
10"
ABSTRACT,0.011815252416756176,"effectively use historical information by combining K-recall win rate features and
11"
ABSTRACT,0.01288936627282492,"earth mover’s distance for hand classification. Experimental studies conducted
12"
ABSTRACT,0.013963480128893663,"in the Numeral211 Hold’em environment show that under identical abstracted
13"
ABSTRACT,0.015037593984962405,"infoset sizes, KrwEmd not only surpasses POI but also outperforms state-of-the-art
14"
ABSTRACT,0.01611170784103115,"hand abstraction algorithms such as Ehs and PaEmd. These findings suggest that
15"
ABSTRACT,0.017185821697099892,"incorporating historical information can significantly enhance the performance of
16"
ABSTRACT,0.018259935553168637,"hand abstraction algorithms, positioning KrwEmd as a promising approach for
17"
ABSTRACT,0.01933404940923738,"advancing strategic computation in large-scale adversarial games.
18"
INTRODUCTION,0.02040816326530612,"1
Introduction
19"
INTRODUCTION,0.021482277121374866,"Imperfect recall abstraction has proven to be very important for solving large-scale computational
20"
INTRODUCTION,0.022556390977443608,"games, significantly reducing computational complexity. Recently, AI using imperfect recall abstrac-
21"
INTRODUCTION,0.023630504833512353,"tion has developed better-than-human strategies for Texas Hold’em testbed—even when using limited
22"
INTRODUCTION,0.024704618689581095,"computational resources [23, 7, 8].
23"
INTRODUCTION,0.02577873254564984,"A
B
A
B"
INTRODUCTION,0.02685284640171858,"Figure 1: In a 4-phase game hand ab-
straction task, the current goal is to
classify hands A and B."
INTRODUCTION,0.027926960257787327,"The task of hand abstraction in Texas Hold’em aims to re-
24"
INTRODUCTION,0.02900107411385607,"duce computational overhead by applying the same strategy
25"
INTRODUCTION,0.03007518796992481,"to similar hands. In an imperfect recall setting [29, 20], the
26"
INTRODUCTION,0.031149301825993556,"hand abstraction in the later phase does not strict depend
27"
INTRODUCTION,0.0322234156820623,"on the results of the hand abstraction in the earlier phase.
28"
INTRODUCTION,0.03329752953813104,"However, the term imperfect recall is often interpreted in
29"
INTRODUCTION,0.034371643394199784,"an extreme manner in practice. Researchers typically un-
30"
INTRODUCTION,0.03544575725026853,"derstand it as completely forgetting all past information—in
31"
INTRODUCTION,0.036519871106337275,"other words, considering only future information—and de-
32"
INTRODUCTION,0.03759398496240601,"sign abstraction algorithms based on this understanding
33"
INTRODUCTION,0.03866809881847476,"[16, 17, 19, 15, 14]. There are two major factors that mainly
34"
INTRODUCTION,0.0397422126745435,"affect the results of abstraction for each phase: the number
35"
INTRODUCTION,0.04081632653061224,"of clustering centers (i.e. centroids), which can be set man-
36"
INTRODUCTION,0.04189044038668099,"ually, and the number of distinct features that are used to categorize hands at each phase. Recent
37"
INTRODUCTION,0.04296455424274973,"research [12] has found that constructing hand features solely based on future information can lead
38"
INTRODUCTION,0.04403866809881848,"to excessive abstraction. For example, as shown in the Figure 1, two hands: A and B constructed
39"
INTRODUCTION,0.045112781954887216,"with only future information can have the same hand features. As the game progresses, the rate of
40"
INTRODUCTION,0.04618689581095596,"feature repetition among different hands gradually increases, while the distribution of distinct hand
41"
INTRODUCTION,0.047261009667024706,"features assumes a spindle-shaped pattern. Additionally, constructing hand features with historical
42"
INTRODUCTION,0.04833512352309345,"information in addition to the future may differentiate two hands sharing the same future information
43"
INTRODUCTION,0.04940923737916219,"and hence makes more features available for clustering as well as enhances the performance of hand
44"
ABSTRACT,0.050483351235230935,"abstraction.
45"
ABSTRACT,0.05155746509129968,"However, there still remain two unsolved issues. First, Fu et al. [12] have introduced a K-recall
46"
ABSTRACT,0.05263157894736842,"outcome feature, which incorporates historical information. This feature can only identify if elements
47"
ABSTRACT,0.05370569280343716,"are identical or not, but it lacks the capability to discern the extent of differences between features.
48"
ABSTRACT,0.05477980665950591,"Therefore, it is difficult to adjust the number of clusters appropriately, which makes it challenging to
49"
ABSTRACT,0.055853920515574654,"construct an effective hand abstraction algorithm that integrates historical information. Second, due to
50"
ABSTRACT,0.05692803437164339,"the inability to modify the number of clusters, Fu et al. [12] only compared the performance between
51"
ABSTRACT,0.05800214822771214,"the maximum clusters cases of integration of historical information (KROI) and no integration
52"
ABSTRACT,0.05907626208378088,"at all (POI). In this condition, although KROI significantly outperforms POI, the comparison is
53"
ABSTRACT,0.06015037593984962,"inconclusive because KROI recognizes more abstracted infosets than POI. Thus, it does not prove
54"
ABSTRACT,0.061224489795918366,"that the performance of abstraction algorithms that integrate historical information is necessarily
55"
ABSTRACT,0.06229860365198711,"superior under the condition of having the same number of abstracted infosets.
56"
ABSTRACT,0.06337271750805586,"This paper introduces a framework for constructing hand features based on winrates, with the K-
57"
ABSTRACT,0.0644468313641246,"recall winrate feature being the most crucial one. Based on this, we developed the K-recall winrate
58"
ABSTRACT,0.06552094522019335,"isomorphism (KRWI), an abstraction that integrates historical information. Across the same game
59"
ABSTRACT,0.06659505907626208,"phases, KRWI identifies slightly fewer hand features than KROI but significantly more than POI.
60"
ABSTRACT,0.06766917293233082,"Importantly, the K-recall winrate feature is capable of discerning the extent of differences between
61"
ABSTRACT,0.06874328678839957,"features. Therefore, by combining the earth mover’s distance with the K-recall winrate feature, we
62"
ABSTRACT,0.06981740064446831,"developed the first hand abstraction algorithm that integrates historical information, named KrwEmd,
63"
ABSTRACT,0.07089151450053706,"and designed an efficient computational method. We validated our approach in the Numeral211 game
64"
ABSTRACT,0.0719656283566058,"environment, where KrwEmd demonstrated superior performance to POI under the same infosets
65"
ABSTRACT,0.07303974221267455,"conditions. Additionally, in clustering settings, KrwEmd also outperformed the Ehs and PaEmd
66"
ABSTRACT,0.07411385606874328,"algorithms, with PaEmd being the current state-of-the-art hand abstraction algorithm.
67"
BACKGROUND AND NOTATION,0.07518796992481203,"2
Background and Notation
68"
BACKGROUND AND NOTATION,0.07626208378088077,"Generally, Texas Hold’em-style poker games are modeled as imperfect information games. However,
69"
BACKGROUND AND NOTATION,0.07733619763694952,"for the task of hand abstraction, games with ordered signals [18, 12] offer a better theoretical tool.
70"
BACKGROUND AND NOTATION,0.07841031149301826,"The game with ordered signals is a subclass of imperfect information games in that they further
71"
BACKGROUND AND NOTATION,0.079484425349087,"subdivide the nodes (also called histories, states, or trajectories) in imperfect information games into
72"
BACKGROUND AND NOTATION,0.08055853920515575,"mutually independent signals and public nodes. This allows for each aspect to be studied in isolation.
73"
BACKGROUND AND NOTATION,0.08163265306122448,"Under this framework, the hand abstraction task in Texas Hold’em-style games is modeled as signal
74"
ABSTRACT,0.08270676691729323,"abstraction.
75"
ABSTRACT,0.08378088077336197,"In a game with ordered signals ˜Γ =
D
˜
N, ˜H, ˜Z, ˜ρ, ˜A, ˜χ, ˜τ, γ, Θ, ς, O, ω, ⪰, ˜u
E
, there is a set of
76"
ABSTRACT,0.08485499462943072,"players ˜
N = N ∪{c, pub}, which includes not only the main participants N = {1, . . . , N} but
77"
ABSTRACT,0.08592910848549946,"also a special nature player c who controls the randomness and an observer player pub who can
78"
ABSTRACT,0.08700322234156821,"see everything but doesn’t take any actions. The game progresses through a series of public nodes
79"
ABSTRACT,0.08807733619763695,"˜X = ˜H ∪˜Z. Some of these public nodes are terminal public nodes ˜Z where the game ends and
80"
ABSTRACT,0.08915145005370569,"outcomes are determined, while the others are non-terminal public nodes ˜H. Among the non-terminal
81"
ABSTRACT,0.09022556390977443,"public nodes, some are where players make decisions within the action space ˜A, and the remaining
82"
ABSTRACT,0.09129967776584318,"are chance public nodes where the nature player reveals signals, with the special action Reveal
83"
ABSTRACT,0.09237379162191192,"within ˜A.
84"
ABSTRACT,0.09344790547798067,"At every non-terminal public node, ˜ρ : ˜H 7→Nc (i.e., N ∪{c}) specifies which player is responsible
85"
ABSTRACT,0.09452201933404941,"for making an action, and ˜χ : ˜H 7→2 ˜
A confines the possible actions they can take. When the nature
86"
ABSTRACT,0.09559613319011816,"player makes a move, it reveals signals θ ∈Θ that carry information relevant to the game. These
87"
ABSTRACT,0.0966702470461869,"signals are then observed by all players except c, O(θ) = (O1(θ), . . . , ON(θ), Opub(θ)), though
88"
ABSTRACT,0.09774436090225563,"what they can see might differ.
89"
ABSTRACT,0.09881847475832438,"The progression from one public node to another is clearly defined ˜τ : ˜H × ˜A 7→˜X, ensuring that
90"
ABSTRACT,0.09989258861439312,"the game’s structure is sequential and predictable. Similarly, the signals are revealed according to a
91"
ABSTRACT,0.10096670247046187,"probability distribution ς : Θ 7→∆(Θ), which specifies the likelihood of the next signal given the
92"
ABSTRACT,0.10204081632653061,"current one. We use ˜h ⊑˜h′ to indicate that ˜h is a predecessor of ˜h′, and θ ⊑θ′ to indicate that θ is a
93"
ABSTRACT,0.10311493018259936,"predecessor of θ′. Each phase of the game is the number of times nature player has revealed signals,
94"
ABSTRACT,0.1041890440386681,"denoted by γ : ˜X 7→N+. r = {γ(˜x) | ˜x ∈˜X} represents the phases that a game with ordered
95"
ABSTRACT,0.10526315789473684,"signals may go through. Since the root is a chance public node, we have min r = 1.
96"
ABSTRACT,0.10633727175080558,"At the end of the game, players receive their payoffs based on the signals and the terminal public
97"
ABSTRACT,0.10741138560687433,"node, represented by ˜u = (˜u1, . . . , ˜uN), where ˜ui : Θ × ˜Z 7→R. Additionally, each player’s
98"
ABSTRACT,0.10848549946294307,"survival status is determined at these terminal public nodes, denoted by ω = (ω1, . . . , ωN), where
99"
ABSTRACT,0.10955961331901182,"ωi : ˜Z 7→{true, false}. The signals possess a partial order within their subset, terminal signals
100"
ABSTRACT,0.11063372717508056,"˜Θ, indicated by ⪰: ˜Θ × N × N 7→{true, false}. It is required that for any terminal signal θ ∈˜Θ
101"
ABSTRACT,0.11170784103114931,"and terminal public nodes ˜z ∈{˜z′ ∈˜Z | ωi(˜z′) = ωj(˜z′) = true}, if ⪰(θ, i, j) = true, then
102"
ABSTRACT,0.11278195488721804,"˜ui(θ, ˜z) ≥˜uj(θ, ˜z).
103"
ABSTRACT,0.11385606874328678,"Players make decisions based on their observations of signals and the current non-terminal public
104"
ABSTRACT,0.11493018259935553,"node. A player may have the same observation for different signals, forming a signal infoset for
105"
ABSTRACT,0.11600429645542427,"signals they cannot distinguish. For a player i ∈N, the signal infoset for a signal θ is denoted as
106"
ABSTRACT,0.11707841031149302,"ϑi(θ) = {θ′ ∈Θ | Oi(θ) = Oi(θ′) ∧Opub(θ) = Opub(θ′)}. Specifically, for the nature player,
107"
ABSTRACT,0.11815252416756176,"ϑc(θ) = {θ′ ∈Θ | Opub(θ′) = Opub(θ)}. We abuse the notation ϑ ∈Θi to represent a signal infoset,
108"
ABSTRACT,0.11922663802363051,"where for any player i ∈N, Θi is a partition of Θ, representing the collection of player i’s signal
109"
ABSTRACT,0.12030075187969924,"infosets. Θ(1)
i
, . . . , Θ(|r|)
i
are the collections of player i’s signal infosets for each phase, and they
110"
ABSTRACT,0.12137486573576799,"form a partition of Θi. In games with ordered signals, the signals describe all private information.
111"
ABSTRACT,0.12244897959183673,"The signal infoset, combined with public nodes, can be transformed into the infoset of an imperfect
112"
ABSTRACT,0.12352309344790548,"information game. Fu et al. [12] detailed this transformation process.
113"
ABSTRACT,0.12459720730397422,"The game with ordered signals model allows us to study the issue of signal abstraction independently.
114"
ABSTRACT,0.12567132116004295,"For this purpose, we introduce a signal (infoset) abstraction profile, α = (α1, ., αN), where for each
115"
ABSTRACT,0.1267454350161117,"player i ∈N, αi is a partition of Θ called the signal (infoset) abstraction. Any ˆϑ ∈αi then is
116"
ABSTRACT,0.12781954887218044,"said to be an abstracted signal infoset for player i, and it can be further divided into several signal
117"
ABSTRACT,0.1288936627282492,"infosets within Θi. These finer signal infosets collectively form a partition of ˆϑ. In general, two signal
118"
ABSTRACT,0.12996777658431793,"abstractions cannot be directly compared in terms of performance, but in a few specific cases there
119"
ABSTRACT,0.1310418904403867,"does exist a special relationship between them, which is called refinement. Consider two abstractions
120"
ABSTRACT,0.13211600429645542,"αi and βi. If ∀ˆϑ ∈βi, there exists one or more abstracted signal infosets in αi such that the union
121"
ABSTRACT,0.13319011815252416,"of these forms a partition of ˆϑ, then we said that αi refines βi, symbolically αi ⊒βi. The signal
122"
ABSTRACT,0.13426423200859292,"abstracted game ˜Γα was derived by substituting Θi with αi across all ˜x ∈˜X.
123"
ABSTRACT,0.13533834586466165,"Perfect/imperfect recall originally describes a property of imperfect information games, indicating
124"
ABSTRACT,0.1364124597207304,"that players do not need to remember all the information they have observed throughout the game.
125"
ABSTRACT,0.13748657357679914,"Since games with ordered signals are a subset of imperfect information games, we derived the concept
126"
ABSTRACT,0.1385606874328679,"of signal perfect/imperfect recall from them. A player i in a game ˜Γ is said to have signal perfect
127"
ABSTRACT,0.13963480128893663,"recall if, for any θ′
1, θ′
2 ∈ϑ′, any predecessor θ1 of θ′
1 has a corresponding predecessor θ2 of θ′
2 such
128"
ABSTRACT,0.14070891514500536,"that θ2 ∈ϑ(θ1). If all players have signal perfect recall, the game ˜Γ is said to have signal perfect
129"
ABSTRACT,0.14178302900107412,"recall. For a game ˜Γ with signal perfect recall, if αi is the signal abstraction of player i ∈N, let
130"
ABSTRACT,0.14285714285714285,"(αi, Θ−i) denote the signal abstraction profile where player i adopts the signal abstraction αi while
131"
ABSTRACT,0.1439312567132116,"other players do not do abstraction. If ˜Γ(αi,Θ−i) retains signal perfect recall, then αi is considered a
132"
ABSTRACT,0.14500537056928034,"signal abstraction with perfect recall; otherwise, it is an signal abstraction with imperfect recall.
133"
ABSTRACT,0.1460794844253491,"In games with ordered signals, the strategy πi for player i maps from a non-terminal public node
134"
ABSTRACT,0.14715359828141783,"and a signal infoset to a probability distribution over actions, with the strategy profile denoted as
135"
ABSTRACT,0.14822771213748656,"π = (π1, . . . , πN). When all players adopt the strategy profile π, the expected sum of future rewards,
136"
ABSTRACT,0.14930182599355532,"also known as expected value, for player i at public node ˜x and signal θ is denoted as vπ
i (θ, ˜x),
137"
ABSTRACT,0.15037593984962405,"and the expected value for the entire game is denoted as vi(π). A Nash equilibrium is a strategy
138"
ABSTRACT,0.1514500537056928,"profile where no player can obtain a higher expected value by changing their strategy. Formally,
139"
ABSTRACT,0.15252416756176154,"π∗is a Nash equilibrium if for every player i, vi(π∗) = maxπi vi(πi, π∗
−i), where π−i denotes the
140"
ABSTRACT,0.1535982814178303,"strategies of all players except i. In two-player zero-sum scenarios, the exploitability of π is denoted
141"
ABSTRACT,0.15467239527389903,"as ϵ(π) =
maxπ′
1 vi(π′
1,π2)+maxπ′
2 vi(π1,π′
2)"
ABSTRACT,0.15574650912996776,"2
.
142"
RELATED WORK,0.15682062298603652,"3
Related Work
143"
RELATED WORK,0.15789473684210525,"Our research focuses on hand abstraction techniques in AI systems for Texas Hold’em-style games
144"
RELATED WORK,0.158968850698174,"(i.e. the signal abstraction in games with ordered signals), building on the initial works of Shi and
145"
RELATED WORK,0.16004296455424274,"Littman [25] and Billings et al. [4]. These seminal works introduced the concept of game abstraction,
146"
RELATED WORK,0.1611170784103115,"which aims to simplify games while preserving essential characteristics. The researchers started by
147"
RELATED WORK,0.16219119226638024,"manually forming hand buckets as a result of their expertise with game-playing strategy. The first
148"
RELATED WORK,0.16326530612244897,"automated hand abstraction was that of Gilpin and Sandholm [16]. Later, a model of games with
149"
RELATED WORK,0.16433941997851773,"ordered signals was given for Texas Hold’em by Gilpin and Sandholm [18]; lossless isomorphism
150"
RELATED WORK,0.16541353383458646,"(LI) was developed with signal rotation. Despite the elegance of LI, its low compression rates hinder
151"
RELATED WORK,0.16648764769065522,"its application in large-scale games, whereas lossy abstraction shows potential for such application.
152"
RELATED WORK,0.16756176154672395,"An expectation-based clustering method was proposed by Gilpin and Sandholm [17] in their work,
153"
RELATED WORK,0.1686358754027927,"and a histogram-based clustering method was introduced by Gilpin et al. [19]. The former is known
154"
RELATED WORK,0.16970998925886144,"as Ehs, while the latter is referred to as the potential-aware method. Subsequent studies by Gilpin
155"
RELATED WORK,0.17078410311493017,"and Sandholm [15] and Johanson et al. [20] compared Ehs and potential-aware methods, concluding
156"
RELATED WORK,0.17185821697099893,"that the latter holds an advantage in large-scale games. Johanson et al. [20] also introduced the
157"
RELATED WORK,0.17293233082706766,"use of earth mover’s distance1 (EMD) in potential-aware methods. Ganzfried and Sandholm [14]
158"
RELATED WORK,0.17400644468313642,"introduced a more efficient approximation algorithm for earth mover’s distance in potential-aware
159"
RELATED WORK,0.17508055853920515,"methods (PaEmd). Brown et al. [9] further applied PaEmd to distributed environments for solving
160"
RELATED WORK,0.1761546723952739,"large-scale imperfect-information games. This paradigm has found success in Texas Hold’em AI
161"
RELATED WORK,0.17722878625134264,"systems and is considered state-of-the-art in hand abstraction. Very recently, Fu et al. [12] proposed
162"
RELATED WORK,0.17830290010741137,"several novel tools, such as abstraction resolution and common refinement. They introduced two
163"
RELATED WORK,0.17937701396348013,"signal abstraction: one is the potential outcome isomorphism (POI), which identifies the maximum
164"
RELATED WORK,0.18045112781954886,"number of abstracted signal infosets considering future information only; The other is the K-recall
165"
RELATED WORK,0.18152524167561762,"outcome isomorphism (KROI), which identifies the maximum number of abstracted signal infosets
166"
RELATED WORK,0.18259935553168635,"considering historical information. They emphasized that current imperfect recall signal abstraction
167"
RELATED WORK,0.1836734693877551,"algorithms, which consider only future information, are prone to excessive abstraction. However,
168"
RELATED WORK,0.18474758324382384,"they did not provide practical signal abstraction algorithms.
169"
RELATED WORK,0.1858216970998926,"Other abstraction techniques for decision-making problems include action abstraction [13, 6, 21] and
170"
RELATED WORK,0.18689581095596133,"general imperfect recall abstraction [10, 11] in extensive-form games, as well as state abstraction and
171"
RELATED WORK,0.18796992481203006,"action abstraction in reinforcement learning [1, 2].
172"
WINRATE ISOMORPHISM,0.18904403866809882,"4
Winrate Isomorphism
173"
WINRATE ISOMORPHISM,0.19011815252416756,"The first contribution of this paper is an isomorphism framework of winrate-based features, including
174"
WINRATE ISOMORPHISM,0.19119226638023631,"the potential winrate isomorphism (PWI) and the k-recall winrate Isomorphism (KRWI). Compared
175"
WINRATE ISOMORPHISM,0.19226638023630505,"with outcome-based features, winrate-based features offer a streamlined approach, focusing exclu-
176"
WINRATE ISOMORPHISM,0.1933404940923738,"sively on the distribution of loss, draw, and win outcomes of signals emanating from a signal infoset
177"
WINRATE ISOMORPHISM,0.19441460794844254,"(and its predecessors) as it evolves towards the terminal signals. Winrate-based features are numerical
178"
WINRATE ISOMORPHISM,0.19548872180451127,"vectors of consistent length. In this section, an identical Winrate-based feature uniquely determines
179"
WINRATE ISOMORPHISM,0.19656283566058003,"an abstracted signal infoset. It is worth noting that the similarity of Winrate-based features reflects
180"
WINRATE ISOMORPHISM,0.19763694951664876,"the similarity among signal infosets, allowing for clustering based on these features (see Section 5).
181"
WINRATE ISOMORPHISM,0.19871106337271752,"Both PWI and KRWI share the similar isomorphism construction process for player i in phase r, as
182"
WINRATE ISOMORPHISM,0.19978517722878625,"illustrated in algorithm 1. The difference lies only in the construction operator for the winrate-based
183"
WINRATE ISOMORPHISM,0.200859291084855,"features, FEATURE, used in lines 5 and 12. The isomorphism construction process starts by iterating
184"
WINRATE ISOMORPHISM,0.20193340494092374,"through all signal infosets of Θ(r)
i
and collecting their features. Next, these features are deduplicated
185"
WINRATE ISOMORPHISM,0.20300751879699247,"and stored in lexicographical order within set C(r)
i
, which is implemented as a vector data structure.
186"
WINRATE ISOMORPHISM,0.20408163265306123,"Within C(r)
i
, the index of a feature serves as an identifier for an abstracted signal infoset. Then,
187"
WINRATE ISOMORPHISM,0.20515574650912996,"by utilizing a hash table CI(r)
i , we can identify an abstracted signal infoset’s identifier based on
188"
WINRATE ISOMORPHISM,0.20622986036519872,"its feature. In the final step, we traverse Θ(r)
i
again, associating the identifier of a signal infoset
189"
WINRATE ISOMORPHISM,0.20730397422126745,"with the identifier of its corresponding abstracted signal infoset, and this relationship is recorded in
190"
WINRATE ISOMORPHISM,0.2083780880773362,"D(r)
i
, an isomorphism map. The function Indexi(r, ·) is a domain-specific mapping that assigns a
191"
WINRATE ISOMORPHISM,0.20945220193340494,"unique identifier to each signal infoset at phase r, within the numeric range of 0 to |Θ(r)
i
| −1. In
192"
WINRATE ISOMORPHISM,0.21052631578947367,1https://en.wikipedia.org/wiki/Earth_mover%27s_distance
WINRATE ISOMORPHISM,0.21160042964554243,"Algorithm 1 Isomorphism Constructor
Require:"
WINRATE ISOMORPHISM,0.21267454350161116,"r = 1, . . . , R. Phases.
Θ(r)
i
. Signal infoset space for player i.
Indexi(r, ·) : Θ(r)
i
7→N. Signal infoset index function for player i."
WINRATE ISOMORPHISM,0.21374865735767992,"1: procedure ISOMORPHISMCONSTRUCTOR(r, Θ(r)
i
, FEATURE(·))"
WINRATE ISOMORPHISM,0.21482277121374865,"2:
Initialize C(r)
i
vector as empty."
WINRATE ISOMORPHISM,0.2158968850698174,"3:
Initialize D(r)
i
array arbitrarily with length |Θ(r)
i
|."
WINRATE ISOMORPHISM,0.21697099892588614,"4:
for ϑ ∈Θ(r)
i
do
5:
feature ←FEATURE(ϑ).
6:
Append feature to C(r)
i
.
7:
end for
8:
Eliminate duplicates from C(r)
i
."
WINRATE ISOMORPHISM,0.21804511278195488,"9:
Sort the elements of C(r)
i
in lexicographical order."
WINRATE ISOMORPHISM,0.21911922663802363,"10:
Construct hash table CI(r)
i
from C(r)
i
. Store the index lexid and value feature of C(r)
i
in
CI(r)
i
as key-value pairs (feature, lexid)."
WINRATE ISOMORPHISM,0.22019334049409237,"11:
for ϑ ∈Θ(r)
i
do
12:
feature ←FEATURE(ϑ), idx ←Indexi(r, ϑ)."
WINRATE ISOMORPHISM,0.22126745435016112,"13:
Update D(r)
i
[idx] with CI(r)
i [feature].
14:
end for
15:
return (C(r)
i
, D(r)
i
).
16: end procedure"
WINRATE ISOMORPHISM,0.22234156820622986,"Texas Hold’em-style games, one optional approach for implementing this function is through lossless
193"
WINRATE ISOMORPHISM,0.22341568206229862,"isomorphism [18, 27].
194"
POTENTIAL WINRATE ISOMORPHISM,0.22448979591836735,"4.1
Potential Winrate Isomorphism
195"
POTENTIAL WINRATE ISOMORPHISM,0.22556390977443608,"Potential winrate isomorphism (PWI) is a signal abstraction that classify signal infosets based on its
196"
POTENTIAL WINRATE ISOMORPHISM,0.22663802363050484,"potential winrate features. These features focus on the distribution of a player’s winrate over terminal
197"
POTENTIAL WINRATE ISOMORPHISM,0.22771213748657357,"signals after passing through a given signal infoset, without considering the history of how the player
198"
POTENTIAL WINRATE ISOMORPHISM,0.22878625134264233,"reached the signal infoset. Specifically, for player i in phase r, the potential winrate feature associated
199"
POTENTIAL WINRATE ISOMORPHISM,0.22986036519871106,"with ϑ ∈Θ(r)
i
is defined as
200"
POTENTIAL WINRATE ISOMORPHISM,0.23093447905477982,"pf (r)
i
(ϑ) = (pf (r),0
i
(ϑ), pf (r),1
i
(ϑ), . . . , pf (r),N
i
(ϑ)),
(1)"
POTENTIAL WINRATE ISOMORPHISM,0.23200859291084855,"where
201"
POTENTIAL WINRATE ISOMORPHISM,0.23308270676691728,"• pf (r),0
i
(ϑ) denotes the probability that player i ranks lower than least one other player in
202"
POTENTIAL WINRATE ISOMORPHISM,0.23415682062298604,"the terminal signals, after passing through ϑ.
203"
POTENTIAL WINRATE ISOMORPHISM,0.23523093447905477,"• pf (r),l
i
(ϑ), for l > 0, denotes the probability that player i ranks no lower than any other
204"
POTENTIAL WINRATE ISOMORPHISM,0.23630504833512353,"player and ranks higher than exactly l −1 other players in the terminal signals, after passing
205"
POTENTIAL WINRATE ISOMORPHISM,0.23737916219119226,"through ϑ.
206"
POTENTIAL WINRATE ISOMORPHISM,0.23845327604726102,"In the terminal phase, the winrate feature is calculated by directly statisticing the game outcomes for
207"
POTENTIAL WINRATE ISOMORPHISM,0.23952738990332975,"players in the given signal infoset. Moreover, in the non-terminal phases, we use a recursive approach
208"
POTENTIAL WINRATE ISOMORPHISM,0.24060150375939848,"to simplify the computation of the winrate feature, thereby avoiding the need to enumerate every
209"
POTENTIAL WINRATE ISOMORPHISM,0.24167561761546724,"signal infoset down to the terminal phase. The recursive formula is
210"
POTENTIAL WINRATE ISOMORPHISM,0.24274973147153597,"pf (r),l
i
(ϑ) =
X"
POTENTIAL WINRATE ISOMORPHISM,0.24382384532760473,"ϑ(r+1)∈Θ(r+1)
i
ϑ⊑ϑ(r+1)"
POTENTIAL WINRATE ISOMORPHISM,0.24489795918367346,"pf (r+1),l
i
(ϑ(r+1))Pr{ϑ(r+1)|ϑ}
(2)"
POTENTIAL WINRATE ISOMORPHISM,0.24597207303974222,"Preflop
Flop
Turn
River"
POTENTIAL WINRATE ISOMORPHISM,0.24704618689581095,"Recall
0
0
1
0
1
2
0
1
2
3
KRWI
169
1028325
1123442
1850624
34845952
37659309
20687
33117469
529890863
577366243
KROI
100
1137132
1241210
2337912
38938975
42040233
20687
39792212
586622784
638585633
W/O (%)
100.0
90.43
90.51
79.16
89.49
89.58
100.0
83.23
90.33
90.41
Table 1: The number of abstracted signal infosets identified by KRWI, and KROI in each phase and k
of HUNL&HUNLE, with W/O indicating the ratio identified by PWI and POI."
POTENTIAL WINRATE ISOMORPHISM,0.24812030075187969,"Preflop
Flop
Turn
River
LI
169
1286792
55190538
2428287420
PWI
169
1028325
1850624
20687
POI
169
1137132
2337912
20687
W/O (%)
100.0
90.43
79.16
100.0"
POTENTIAL WINRATE ISOMORPHISM,0.24919441460794844,"Figure 2: The number of abstracted signal infosets
identified by LI, PWI, and POI in each phase of
HUNL&HUNLE, with W/O indicating the ratio iden-
tified by PWI and POI."
POTENTIAL WINRATE ISOMORPHISM,0.2502685284640172,"The PWI algorithm is derived from the
211"
POTENTIAL WINRATE ISOMORPHISM,0.2513426423200859,"POI algorithm [12], and the details of
212"
POTENTIAL WINRATE ISOMORPHISM,0.25241675617615467,"the PWI algorithm are elaborated in Ap-
213"
POTENTIAL WINRATE ISOMORPHISM,0.2534908700322234,"pendix A.1. Both algorithms use the po-
214"
POTENTIAL WINRATE ISOMORPHISM,0.2545649838882922,"tential winrate feature to distinguish be-
215"
POTENTIAL WINRATE ISOMORPHISM,0.2556390977443609,"tween different abstracted signal infosets
216"
POTENTIAL WINRATE ISOMORPHISM,0.25671321160042965,"in the terminal phase. However, unlike
217"
POTENTIAL WINRATE ISOMORPHISM,0.2577873254564984,"POI, PWI also uses the potential winrate
218"
POTENTIAL WINRATE ISOMORPHISM,0.2588614393125671,"feature in non-terminal phases to identify
219"
POTENTIAL WINRATE ISOMORPHISM,0.25993555316863587,"different abstracted signal infoset classes,
220"
POTENTIAL WINRATE ISOMORPHISM,0.26100966702470463,"while POI relies on the potential outcome
221"
POTENTIAL WINRATE ISOMORPHISM,0.2620837808807734,"feature (which captures the distribution of the abstracted signal infoset class for future signal infoset).
222"
POTENTIAL WINRATE ISOMORPHISM,0.2631578947368421,"In non-terminal phases, the potential winrate feature is a simplified version of the potential outcome
223"
POTENTIAL WINRATE ISOMORPHISM,0.26423200859291085,"feature. Unsurprisingly, PWI also results in excessive abstraction similar to POI. As shown in Table
224"
POTENTIAL WINRATE ISOMORPHISM,0.2653061224489796,"2, in heads-up limit hold’em (HULHE) and heads-up no-limit hold’em (HUNL), the number of
225"
ABSTRACT,0.2663802363050483,"abstracted signal infosets identifiable by lossless isomorphism increases with each phase, indicating
226"
ABSTRACT,0.26745435016111707,"that the game becomes increasingly complex. However, the number of abstracted signal infosets
227"
ABSTRACT,0.26852846401718583,"identifiable by PWI and POI first increases and then decreases, showing a spindle-shaped pattern.
228"
ABSTRACT,0.2696025778732546,"And we observed that when only future information is considered, winrate-based features may lead
229"
ABSTRACT,0.2706766917293233,"to greater information loss compared to outcome-based features. For instance, in the River phase, the
230"
ABSTRACT,0.27175080558539205,"number of abstracted signal infosets identified by PWI is only 79.16% of that identified by POI.
231"
K-RECALL WINRATE ISOMORPHISM,0.2728249194414608,"4.2
K-Recall Winrate Isomorphism
232"
K-RECALL WINRATE ISOMORPHISM,0.2738990332975295,"As Fu et al. [12] mentioned, supplementing historical information can enhance the ability of signal
233"
ABSTRACT,0.2749731471535983,"abstraction to identify abstracted signal infosets. Inspired by KROI’s construction approach, we
234"
ABSTRACT,0.27604726100966703,"developed the k-recall winrate isomorphism (KRWI). The key difference is that instead of using
235"
ABSTRACT,0.2771213748657358,"k-recall outcome features to distinguish between different signal infosets, KRWI utilizes k-recall
236"
ABSTRACT,0.2781954887218045,"winrate features.
237"
ABSTRACT,0.27926960257787325,"In a game with signal perfect recall, all signals within the signal infoset ϑ have their predecessors at
238"
ABSTRACT,0.280343716433942,"phase r′, which belong to the identical signal infoset ϑ′. For player i at phase r, the signal infoset
239"
ABSTRACT,0.2814178302900107,"ϑ ∈Θ(r)
i
has a k-recall winrate feature (k < r) represented as a numerical array with a dimension of
240"
ABSTRACT,0.2824919441460795,"(k + 1)(N + 1):
241"
ABSTRACT,0.28356605800214824,"rf (r,k)
i
(ϑ) = (pf (r)
i
(ϑ); pf (r−1)
i
(ϑ); . . . ; pf (r−k)
i
(ϑ))
(3)"
ABSTRACT,0.284640171858217,"When r′ is less than r, pf (r′)
i
(ϑ) denotes the potential winrate feature for the predecessor signal
242"
ABSTRACT,0.2857142857142857,"infoset ϑ′ of ϑ at phase r′. Since we have stored all the potential winrate features of ϑ ∈Θ(r)
i
through
243"
ABSTRACT,0.28678839957035446,"PC(r)
i , PD(r)
i
and assigned them unique identifiers in Algorithm A1. To save storage space and
244"
ABSTRACT,0.2878625134264232,"facilitate retrieval, what we actually store is
245"
ABSTRACT,0.2889366272824919,"rfi(r,k)
i
(ϑ) = (PD(r)
i [ϑ], PD(r−1)
i
[ϑ], . . . , PD(r−k)
i
[ϑ))
(4)"
ABSTRACT,0.2900107411385607,"PD(r′)
i
[ϑ] is the identifier for the potential winrate feature of the predecessor ϑ′ of ϑ in the r′ phase,
246"
ABSTRACT,0.29108485499462944,"r′ ≤r. For algorithm details, please refer to Appendix A.2.
247"
ABSTRACT,0.2921589688506982,"Just as the potential winrate feature is a simplified version of the potential outcome feature, the
248"
ABSTRACT,0.2932330827067669,"k-recall winrate feature is a simplified version of the k-recall outcome feature. Table 1 shows the
249"
ABSTRACT,0.29430719656283566,"number of signal infosets that KRWI and KROI can identify and their ratio in HUNL&HULHE. We
250"
ABSTRACT,0.2953813104189044,"were pleasantly surprised to find that while the ratio of PWI to POI resolution can drop below 80%,
251"
ABSTRACT,0.2964554242749731,"when k is set to its maximum value, i.e. r −1, the ratio of KRWI to KROI resolution can reach nearly
252"
ABSTRACT,0.2975295381310419,"90% at a minimum, with most of the information preserved. Also, we can easily observe that the
253"
ABSTRACT,0.29860365198711064,"number of abstracted signal infosets identified by KRWI is much higher than that identified by POI.
254"
ABSTRACT,0.2996777658431794,"5
K-Recall Winrate Abstraction with Earth Mover’s Distance
255"
ABSTRACT,0.3007518796992481,"Fu et al. [12] introduced potential and k-recall outcome features, referred to as outcome-based features,
256"
ABSTRACT,0.30182599355531686,"to distinguish different abstracted signal infosets. In the previous section, we developed potential and
257"
ABSTRACT,0.3029001074113856,"k-recall winrate features, termed winrate-based features, for the same purpose. In these two methods,
258"
ABSTRACT,0.3039742212674543,"Each unique feature corresponds to a single abstracted signal infoset. Intuitively, we can infer that
259"
ABSTRACT,0.3050483351235231,"feature similarity might reflect the similarity among abstracted signal infosets, enabling further
260"
ABSTRACT,0.30612244897959184,"abstraction and compression for application in large-scale games. However, assessing similarity with
261"
ABSTRACT,0.3071965628356606,"outcome-based features is challenging because the identification code indicates only the category,
262"
ABSTRACT,0.3082706766917293,"without reflecting the degree of similarity. In contrast, winrate-based features represent winrates,
263"
ABSTRACT,0.30934479054779807,"which are inherently comparable, allowing for an easy definition of distances between them.
264"
ABSTRACT,0.3104189044038668,"For the signal information sets ϑ, ϑ′ of player i at phase r, we can define the distance of their k-recall
265"
ABSTRACT,0.31149301825993553,"winrate feature as
266"
ABSTRACT,0.3125671321160043,"d(rf (r,k)
i
(ϑ), rf (r,k)
i
(ϑ′)) = k
X"
ABSTRACT,0.31364124597207305,"j=0
wj · Emd(pf (r−j)
i
(ϑ), pf (r−j)
i
(ϑ′))
(5)"
ABSTRACT,0.3147153598281418,"Among Equation (5), Emd is the operator used to calculate the earth mover’s distance (EMD) [24].
267"
ABSTRACT,0.3157894736842105,"The EMD calculates the distance between two histograms using optimal transport theory. Since it
268"
ABSTRACT,0.31686358754027927,"requires solving linear programming equations, the computational complexity of the EMD is sensitive
269"
ABSTRACT,0.317937701396348,"to the dimensionality of the histograms, and approximate algorithms are usually used for larger-scale
270"
ABSTRACT,0.31901181525241673,"problems. However, the dimensionality of winrate-based features is small, with a dimension of 3 in a
271"
ABSTRACT,0.3200859291084855,"two-player scenario, so we attempt to use a fast algorithm for accurately computing the EMD [5].
272"
ABSTRACT,0.32116004296455425,"w0, . . . , wk are hyperparameters used to control the importance of EMD at each phase r, . . . , r −k.
273"
ABSTRACT,0.322234156820623,"We use the KMeans++ algorithm [3], combined with the distance of their k-recall winrate feature, to
274"
ABSTRACT,0.3233082706766917,"cluster the abstracted signal infosets of KRWI. We named this algorithm KrwEmd.
275"
ABSTRACT,0.32438238453276047,"Although calculating EMD on small-dimensional histograms is already very fast, clustering ac-
276"
ABSTRACT,0.32545649838882923,"tual Texas Hold’em still faces a significant computation. For example, for the River phase of
277"
ABSTRACT,0.32653061224489793,"HUNL&HULHE, the clustering input size of the KRWI abstracted signal infoset is approximately
278"
ABSTRACT,0.3276047261009667,"5.8 × 108. When we set the number of centroids to 20000, a single Kmeans++ iteration takes about
279"
ABSTRACT,0.32867883995703545,"19000 core hours on a computer with a 2.40GHz clock frequency, which is a significant time cost.
280"
ABSTRACT,0.3297529538131042,"Therefore, we need to find ways to reduce this time cost. We have developed an accelerated algorithm,
281"
ABSTRACT,0.3308270676691729,"please refer to Appendix A.3 for details.
282"
EXPERIMENTAL SETUP,0.3319011815252417,"6
Experimental Setup
283"
EXPERIMENTAL SETUP,0.33297529538131043,"Preflop
Flop
Turn"
EXPERIMENTAL SETUP,0.33404940923737914,"LI
100
2260
62020"
EXPERIMENTAL SETUP,0.3351235230934479,"Recall
0
0
1
0
1
2
KRWI
100
2234
2248
3957
51000
51070
KROI
100
2250
2260
3957
51176
51228
W/O (%)
100.0
99.29
99.47
100.0
99.67
99.69"
EXPERIMENTAL SETUP,0.33619763694951665,"Figure 3: The number of abstracted signal infosets
identified by LI, PWI, and POI in each phase of
HUNL&HUNLE, with W/O indicating the ratio iden-
tified by PWI and POI."
EXPERIMENTAL SETUP,0.3372717508055854,"We conducted experiments on the Nu-
284"
EXPERIMENTAL SETUP,0.3383458646616541,"meral211 Hold’em [12] testbed.
Nu-
285"
EXPERIMENTAL SETUP,0.3394199785177229,"meral211 is a two-player three-phase
286"
EXPERIMENTAL SETUP,0.34049409237379163,"Taxes Hold’em-style game with more
287"
EXPERIMENTAL SETUP,0.34156820622986034,"complex hand systems than the Leduc
288"
EXPERIMENTAL SETUP,0.3426423200859291,"Hold’em [26] and Rhode Island Hold’em
289"
EXPERIMENTAL SETUP,0.34371643394199786,"[25] test environments, making it suitable
290"
EXPERIMENTAL SETUP,0.3447905477980666,"for studying hand abstraction issues. De-
291"
EXPERIMENTAL SETUP,0.3458646616541353,"tailed rules are included in Appendix B.
292"
EXPERIMENTAL SETUP,0.3469387755102041,"Table 3 shows the number of abstracted
293"
EXPERIMENTAL SETUP,0.34801288936627284,"signal infosets recognized by KRWI and
294"
EXPERIMENTAL SETUP,0.34908700322234154,"KROI, along with lossless isomorphism,
295"
EXPERIMENTAL SETUP,0.3501611170784103,"in Numeral211 Hold’em.
296"
EXPERIMENTAL SETUP,0.35123523093447906,"Let α = (α1, α2) be the signal abstraction we would like to assess. We will test the strength of
297"
EXPERIMENTAL SETUP,0.3523093447905478,"the signal abstraction by measuring exploitability of the approximate equilibrium derived using the
298"
EXPERIMENTAL SETUP,0.3533834586466165,"CSMCCFR algorithm [30, 22] in different abstracted signal infoset scales. We gauge the performance
299"
EXPERIMENTAL SETUP,0.3544575725026853,"over exploitability. For doing that, we consider both symmetric and asymmetric abstraction scenarios.
300"
EXPERIMENTAL SETUP,0.35553168635875404,"In this symmetric abstraction setting, we measure the exploitability of approximate equilibrium
301"
EXPERIMENTAL SETUP,0.35660580021482274,"that is yielded when both the players in the game employ signal abstraction in the original game.
302"
EXPERIMENTAL SETUP,0.3576799140708915,"However, it may lead to the abstraction pathology [28]. To avoid such problems, we illustrate the
303"
EXPERIMENTAL SETUP,0.35875402792696026,"theoretical performance of the signal abstraction under evaluation through asymmetric abstraction.
304"
EXPERIMENTAL SETUP,0.359828141783029,"The approximate equilibrium in the signal abstracted games ˜Γ(α1,Θ2) and ˜Γ(Θ1,α2) is obtained to
305"
EXPERIMENTAL SETUP,0.3609022556390977,"obtain π∗,1 and π∗,2, respectively. Finally, we concat the two strategies to get π′ = (π∗,1
1 , π∗,2
2 ) and
306"
EXPERIMENTAL SETUP,0.3619763694951665,"check the exploitability of π′.
307"
EXPERIMENT,0.36305048335123524,"7
Experiment
308   ✁"
EXPERIMENT,0.364124597207304,"✂✄
☎✆
✁"
EXPERIMENT,0.3651987110633727,"✂✄
☎
✝
✁ ✞
✆
✁"
EXPERIMENT,0.36627282491944146,"✟
✠
✡
☛
☞
✌
✄
✍
✄
✎
✄
✏"
EXPERIMENT,0.3673469387755102,"✟
✠
✡
☛
☞
✌
✄
✏
✄
✎
✄
✍ ✥ ✦✧ ✧
✥ ★✧ ✩✥
✥ ✩
✦✧"
EXPERIMENT,0.3684210526315789,"✪
✫✬
✭✮
✯✰✱
✫✬✰
✭✲
✮
✳ ✩✥ ✴ ✩✥ ✵✶ (a)   ✁"
EXPERIMENT,0.3694951664876477,"✂✄
☎✆
✁"
EXPERIMENT,0.37056928034371645,"✂✄
☎
✝
✁ ✞
✆
✁"
EXPERIMENT,0.3716433941997852,"✟
✠
✡
☛
☞
✌
✄
✍
✄
✎
✄
✏"
EXPERIMENT,0.3727175080558539,"✟
✠
✡
☛
☞
✌
✄
✏
✄
✎
✄
✍ ✥ ✦✥ ✧
✥ ★✥ ✩✥"
EXPERIMENT,0.37379162191192267,"✪
✫✬
✭✮
✯✰✱
✫✬✰
✭✲
✮
✳ ✦✥ ✴ ✦✥ ✵✶ (b)"
EXPERIMENT,0.3748657357679914,"Figure 4: Full abstraction setting experiment, trained for 5.5 × 1010 iterations."
EXPERIMENT,0.37593984962406013,"Firstly, we provide an evaluation of the performance of KRWI (2-RWI) compared with KROI (2-ROI)
309"
EXPERIMENT,0.3770139634801289,"and POI (0-ROI) approaches and lossless isomorphism. We keep the most abstracted signal infosets
310"
EXPERIMENT,0.37808807733619765,"identified under the full abstraction setting. Note that POI is the common refinement of existing
311"
EXPERIMENT,0.3791621911922664,"signal abstraction algorithms that only consider future information. And, since previous works cannot
312"
EXPERIMENT,0.3802363050483351,"control the number of abstracted infoset, they cannot justify their performance in that considering
313"
EXPERIMENT,0.38131041890440387,"historical information in signal abstraction was better than that in signal abstraction with the same
314"
EXPERIMENT,0.38238453276047263,"number of abstracted infoset. To investigate this issue, we included KrwEmd and set the clustering
315"
EXPERIMENT,0.38345864661654133,"scale to be consistent with POI. Note here, that 2-RWI and 2-ROI share the same capability of infoset
316"
EXPERIMENT,0.3845327604726101,"recognition in Preflop and Flop, while POI is only a little bit worse than 2-RWI and 2-ROI in Flop.
317"
EXPERIMENT,0.38560687432867885,"Thus, we can directly allow clustering of KrwEmd abstraction use the abstracted signal infosets
318"
EXPERIMENT,0.3866809881847476,"identified by POI in Preflop and Flop, and only perform clustering in River. Here, we design four
319"
EXPERIMENT,0.3877551020408163,"sets of hyper-parameters: (w0, w1, w2), i.e., exponentially decreasing: (16, 4, 1), linearly decreasing:
320"
EXPERIMENT,0.38882921589688507,"(7, 5, 3), constant: (1, 1, 1), and increasing: (3, 5, 7) in the importance of historical information. We
321"
EXPERIMENT,0.38990332975295383,"only show the result of best- and worst-performing parameters (to make the figure neat). The full
322"
EXPERIMENT,0.39097744360902253,"figures appear in the Appendix C. Figure 4a shows the result of symmetric abstraction, while Figure
323"
EXPERIMENT,0.3920515574650913,"4b shows the result of asymmetric abstraction. We observed that both symmetric and asymmetric
324"
ABSTRACT,0.39312567132116005,"abstractions maintained consistent abstraction performance without abstraction pathologies. As
325"
ABSTRACT,0.3941997851772288,"expected, overfitting was observed in the symmetric abstraction scenario while in the asymmetric
326"
ABSTRACT,0.3952738990332975,"scenario overfitting was significant only for POI. The performance difference between 2-RWI and
327"
ABSTRACT,0.3963480128893663,"2-ROI is small, which means that under the full abstraction setting, using simple winrate-based
328"
ABSTRACT,0.39742212674543503,"features instead of complex outcome-based features can achieve nearly the same performance. Even
329"
ABSTRACT,0.39849624060150374,"with the worst parameter configuration (increasing importance), KrwEmd with the same number of
330"
ABSTRACT,0.3995703544575725,"abstracted signal inforsets as POI still outperforms POI.
331  
✁✂"
ABSTRACT,0.40064446831364126,"✄
☎
 
✆
✝"
ABSTRACT,0.40171858216971,"✞
✟
✠
 
✆
✝
✡
☛☞✡
✌✡
☛"
ABSTRACT,0.4027926960257787,"✞
✟
✠
 
✆
✝
✡
✍
✡
✎
✡
✏"
ABSTRACT,0.4038668098818475,"✞
✟
✠
 
✆
✝
✡
☛✡
☛✡
☛"
ABSTRACT,0.40494092373791624,"✞
✟
✠
 
✆
✝
✡
✏
✡
✎
✡
✍ ✥
✦
✦ ✧
★
✦ ✩
✦
✦"
ABSTRACT,0.40601503759398494,"✪
✫✬
✭✮
✯✰✱
✫✬✰
✭✲
✮
✳ ✴
✦ ✵ ✴✦ ✶ ✴
✦ ✷✸ (a)  
✁✂"
ABSTRACT,0.4070891514500537,"✄
☎
 
✆
✝"
ABSTRACT,0.40816326530612246,"✞
✟
✠
 
✆
✝
✡
☛☞✡
✌✡
☛"
ABSTRACT,0.4092373791621912,"✞
✟
✠
 
✆
✝
✡
✍
✡
✎
✡
✏"
ABSTRACT,0.4103114930182599,"✞
✟
✠
 
✆
✝
✡
☛✡
☛✡
☛"
ABSTRACT,0.4113856068743287,"✞
✟
✠
 
✆
✝
✡
✏
✡
✎
✡
✍ ✥✦ ✧✦ ★
✩
✦"
ABSTRACT,0.41245972073039744,"✪
✫✬
✭✮
✯✰✱
✫✬✰
✭✲
✮
✳ ★
✦ ✴ ★
✦ ✵✶ (b)"
ABSTRACT,0.41353383458646614,"Figure 5: Performance comparison of KrwEmd versus other imperfect recall signal abstraction
algorithms considering only future information, trained for 3.7 × 1010 iterations."
ABSTRACT,0.4146079484425349,"Next, we compared the performance of KrwEmd with the currently applied signal abstraction
332"
ABSTRACT,0.41568206229860366,"algorithms Ehs and PaEmd. It should be noted that POI is the common refinement both for Ehs and
333"
ABSTRACT,0.4167561761546724,"PaEmd, meaning that the maximum number of abstracted signal infosets they can recognize will not
334"
ABSTRACT,0.4178302900107411,"exceed that of POI. Thus, we set a compression rate that is 10 times lower than that of POI, while not
335"
ABSTRACT,0.4189044038668099,"performing abstraction for Preflop. The final number of abstracted infosets is set to (100, 225, 396).
336"
ABSTRACT,0.41997851772287864,"To exclude the influence of random events on performance, we generated 3 sets of abstractions
337"
ABSTRACT,0.42105263157894735,"for Ehs and PaEmd each. KrwEmd used hyperparameters (w3,0, w3,1, w3,2; w2,0, w2,1) in Flop and
338"
ABSTRACT,0.4221267454350161,"River, which are exponentially decreasing (16, 4, 1; 4, 1), linearly decreasing (7, 5, 3; 5, 3), constant
339"
ABSTRACT,0.42320085929108486,"(1, 1, 1; 1, 1), and increasing (3, 5, 7; 5, 7) in the importance of historical information. Additionally,
340"
ABSTRACT,0.4242749731471536,"since PaEmd uses approximate EMD calculations, its approximate distance is asymmetric, making it
341"
ABSTRACT,0.4253490870032223,"difficult for the algorithm to converge. We truncated after 1000 iterations on a single core, with an
342"
ABSTRACT,0.4264232008592911,"average cost of 1427.7s, while Ehs and KrwEmd both achieved convergent clustering results, requiring
343"
ABSTRACT,0.42749731471535984,"an average of 12.3 and 96.7 iterations, with average time costs of 11.2s and 341.4s, respectively.
344"
ABSTRACT,0.42857142857142855,"Figure 5a shows the results of symmetric abstraction experiments, while Figure 5b shows the results of
345"
ABSTRACT,0.4296455424274973,"asymmetric abstraction experiments. We observed that both symmetric and asymmetric abstractions
346"
ABSTRACT,0.43071965628356607,"maintained consistent abstraction performance, similar to the full abstraction scenario, without
347"
ABSTRACT,0.4317937701396348,"significant abstraction pathologies. The experimental results show that KrwEmd’s performance is
348"
ABSTRACT,0.43286788399570353,"far superior to that of Ehs and PaEmd under all parameter settings. Our experiments also confirmed
349"
ABSTRACT,0.4339419978517723,"that, despite PaEmd’s convergence issues, it is indeed a more effective abstraction algorithm than
350"
ABSTRACT,0.43501611170784105,"Ehs. Additionally, we further validated that the importance of historical information decreases
351"
ABSTRACT,0.43609022556390975,"progressively from bottom to top, although this time the best-performing parameter was exponentially
352"
ABSTRACT,0.4371643394199785,"decreasing rather than linearly decreasing as in the previous experiment.
353"
ABSTRACT,0.43823845327604727,"These two experiments validate that considering historical information is indeed more effective than
354"
ABSTRACT,0.439312567132116,"considering future information only in signal abstraction even in imperfect recall setting.
355"
CONCLUSION,0.44038668098818473,"8
Conclusion
356"
CONCLUSION,0.4414607948442535,"This research introduces the first imperfect recall signal abstraction algorithm that considers historical
357"
CONCLUSION,0.44253490870032225,"information. This algorithm has the ability to adjust the scale of the abstracted signal infosets. Based
358"
CONCLUSION,0.44360902255639095,"on this, we fully verified that the imperfect recall signal abstraction and abstraction algorithms
359"
CONCLUSION,0.4446831364124597,"considering historical information is superior to that only considering future information. Therefore,
360"
CONCLUSION,0.44575725026852847,"the KrwEmd algorithm has replaced the PaEmd algorithm and become the SOTA in this field. Based
361"
CONCLUSION,0.44683136412459723,"on the KrwEmd algorithm, we are expected to build a stronger Texas Hold’em AI.
362"
REFERENCES,0.44790547798066593,"References
363"
REFERENCES,0.4489795918367347,"[1] David Abel. A theory of state abstraction for reinforcement learning. In AAAI conference on
364"
REFERENCES,0.45005370569280345,"artificial intelligence, volume 33, pages 9876–9877, 2019.
365"
REFERENCES,0.45112781954887216,"[2] David Abel, Nate Umbanhowar, Khimya Khetarpal, Dilip Arumugam, Doina Precup, and
366"
REFERENCES,0.4522019334049409,"Michael Littman. Value preserving state-action abstractions. In International Conference on
367"
REFERENCES,0.4532760472610097,"Artificial Intelligence and Statistics (AISTATS), pages 1639–1650, 2020.
368"
REFERENCES,0.45435016111707843,"[3] David Arthur and Sergei Vassilvitskii. k-means++ the advantages of careful seeding. In
369"
REFERENCES,0.45542427497314714,"ACM-SIAM symposium on Discrete algorithms (SODA), pages 1027–1035, 2007.
370"
REFERENCES,0.4564983888292159,"[4] D Billings, N Burch, A Davidson, R Holte, J Schaeffer, T Schauenberg, and D Szafron.
371"
REFERENCES,0.45757250268528465,"Approximating game-theoretic optimal strategies for full-scale poker. In International Joint
372"
REFERENCES,0.45864661654135336,"Conference on Artificial Intelligence (IJCAI), volume 3, pages 661–668, 2003.
373"
REFERENCES,0.4597207303974221,"[5] Nicolas Bonneel, Michiel van de Panne, Sylvain Paris, and Wolfgang Heidrich. Displacement
374"
REFERENCES,0.4607948442534909,"Interpolation Using Lagrangian Mass Transport. ACM Transactions on Graphics (SIGGRAPH
375"
REFERENCES,0.46186895810955964,"ASIA 2011), 30(6), 2011.
376"
REFERENCES,0.46294307196562834,"[6] Noam Brown and Tuomas Sandholm. Regret transfer and parameter optimization. In AAAI
377"
REFERENCES,0.4640171858216971,"Conference on Artificial Intelligence, volume 28, 2014.
378"
REFERENCES,0.46509129967776586,"[7] Noam Brown and Tuomas Sandholm. Superhuman ai for heads-up no-limit poker: Libratus
379"
REFERENCES,0.46616541353383456,"beats top professionals. Science, 359(6374):418–424, 2018.
380"
REFERENCES,0.4672395273899033,"[8] Noam Brown and Tuomas Sandholm. Superhuman ai for multiplayer poker. Science, 365
381"
REFERENCES,0.4683136412459721,"(6456):885–890, 2019.
382"
REFERENCES,0.46938775510204084,"[9] Noam Brown, Sam Ganzfried, and Tuomas Sandholm. Hierarchical abstraction, distributed
383"
REFERENCES,0.47046186895810954,"equilibrium computation, and post-processing, with application to a champion no-limit texas
384"
REFERENCES,0.4715359828141783,"hold’em agent. In International Conference on Autonomous Agents and Multiagent Systems
385"
REFERENCES,0.47261009667024706,"(AAMAS), pages 7–15, 2015.
386"
REFERENCES,0.47368421052631576,"[10] Jiˇrí ˇCermák, Branislav Bošansky, and Viliam Lisy. An algorithm for constructing and solving
387"
REFERENCES,0.4747583243823845,"imperfect recall abstractions of large extensive-form games. In International Joint Conference
388"
REFERENCES,0.4758324382384533,"on Artificial Intelligence (IJCAI), pages 936–942, 2017.
389"
REFERENCES,0.47690655209452204,"[11] Jiˇrí ˇCermák, Viliam Lis`y, and Branislav Bošansk`y. Automated construction of bounded-loss
390"
REFERENCES,0.47798066595059074,"imperfect-recall abstractions in extensive-form games. Artificial Intelligence, 282:103248,
391"
REFERENCES,0.4790547798066595,"2020.
392"
REFERENCES,0.48012889366272826,"[12] Yanchang Fu, Junge Zhang, Dongdong Bai, Lingyun Zhao, Jialu Song, and Kaiqi Huang.
393"
REFERENCES,0.48120300751879697,"Expanding the resolution boundary of outcome-based imperfect-recall abstraction in games
394"
REFERENCES,0.4822771213748657,"with ordered signals. arXiv preprint arXiv:2403.11486, 2024.
395"
REFERENCES,0.4833512352309345,"[13] Sam Ganzfried and Tuomas Sandholm. Action translation in extensive-form games with large
396"
REFERENCES,0.48442534908700324,"action spaces: axioms, paradoxes, and the pseudo-harmonic mapping. In International Joint
397"
REFERENCES,0.48549946294307195,"Conference on Artificial Intelligence (IJCAI), pages 120–128, 2013.
398"
REFERENCES,0.4865735767991407,"[14] Sam Ganzfried and Tuomas Sandholm. Potential-aware imperfect-recall abstraction with earth
399"
REFERENCES,0.48764769065520946,"mover’s distance in imperfect-information games. In AAAI Conference on Artificial Intelligence,
400"
REFERENCES,0.48872180451127817,"volume 28, 2014.
401"
REFERENCES,0.4897959183673469,"[15] Andrew Gilpin and Thomas Sandholm. Expectation-based versus potential-aware automated
402"
ABSTRACT,0.4908700322234157,"abstraction in imperfect information games: An experimental comparison using poker. In
403"
ABSTRACT,0.49194414607948445,"National Conference on Artificial Intelligence (NCAI), volume 3, pages 1454–1457, 2008.
404"
ABSTRACT,0.49301825993555315,"[16] Andrew Gilpin and Tuomas Sandholm. A competitive texas hold’em poker player via auto-
405"
ABSTRACT,0.4940923737916219,"mated abstraction and real-time equilibrium computation. In National Conference on Artificial
406"
ABSTRACT,0.49516648764769067,"Intelligence (NCAI), volume 21, page 1007. Menlo Park, CA; Cambridge, MA; London; AAAI
407"
ABSTRACT,0.49624060150375937,"Press; MIT Press; 1999, 2006.
408"
ABSTRACT,0.49731471535982813,"[17] Andrew Gilpin and Tuomas Sandholm. Better automated abstraction techniques for imperfect
409"
ABSTRACT,0.4983888292158969,"information games, with application to texas hold’em poker. In International Joint Conference
410"
ABSTRACT,0.49946294307196565,"on Artificial Intelligence (IJCAI), pages 1–8, 2007.
411"
ABSTRACT,0.5005370569280344,"[18] Andrew Gilpin and Tuomas Sandholm. Lossless abstraction of imperfect information games.
412"
ABSTRACT,0.5016111707841031,"Journal of the ACM (JACM), 54(5):25–es, 2007.
413"
ABSTRACT,0.5026852846401718,"[19] Andrew Gilpin, Tuomas Sandholm, and Troels Bjerre Sørensen. Potential-aware automated
414"
ABSTRACT,0.5037593984962406,"abstraction of sequential games, and holistic equilibrium analysis of texas hold’em poker. In
415"
ABSTRACT,0.5048335123523093,"National Conference on Artificial Intelligence (NCAI), volume 22, page 50. Menlo Park, CA;
416"
ABSTRACT,0.505907626208378,"Cambridge, MA; London; AAAI Press; MIT Press; 1999, 2007.
417"
ABSTRACT,0.5069817400644469,"[20] Michael Johanson, Neil Burch, Richard Valenzano, and Michael Bowling. Evaluating state-
418"
ABSTRACT,0.5080558539205156,"space abstractions in extensive-form games. In International Conference on Autonomous Agents
419"
ABSTRACT,0.5091299677765844,"and Multiagent Systems (AAMAS), pages 271–278, 2013.
420"
ABSTRACT,0.5102040816326531,"[21] Christian Kroer and Tuomas Sandholm. Discretization of continuous action spaces in extensive-
421"
ABSTRACT,0.5112781954887218,"form games. In International Conference on Autonomous Agents and Multiagent Systems
422"
ABSTRACT,0.5123523093447906,"(AAMAS), pages 47–56, 2015.
423"
ABSTRACT,0.5134264232008593,"[22] Marc Lanctot, Kevin Waugh, Martin Zinkevich, and Michael Bowling. Monte carlo sampling
424"
ABSTRACT,0.514500537056928,"for regret minimization in extensive games. International Conference on Neural Information
425"
ABSTRACT,0.5155746509129968,"Processing Systems (NeurIPS), 22, 2009.
426"
ABSTRACT,0.5166487647690655,"[23] Matej Moravˇcík, Martin Schmid, Neil Burch, Viliam Lis`y, Dustin Morrill, Nolan Bard, Trevor
427"
ABSTRACT,0.5177228786251342,"Davis, Kevin Waugh, Michael Johanson, and Michael Bowling. Deepstack: Expert-level
428"
ABSTRACT,0.518796992481203,"artificial intelligence in heads-up no-limit poker. Science, 356(6337):508–513, 2017.
429"
ABSTRACT,0.5198711063372717,"[24] Yossi Rubner, Carlo Tomasi, and Leonidas J Guibas. The earth mover’s distance as a metric for
430"
ABSTRACT,0.5209452201933404,"image retrieval. International journal of computer vision, 40:99–121, 2000.
431"
ABSTRACT,0.5220193340494093,"[25] Jiefu Shi and Michael L Littman. Abstraction methods for game theoretic poker. In Computers
432"
ABSTRACT,0.523093447905478,"and Games: Second International Conference, CG 2000 Hamamatsu, Japan, October 26–28,
433"
ABSTRACT,0.5241675617615468,"2000 Revised Papers 2, pages 333–345. Springer, 2001.
434"
ABSTRACT,0.5252416756176155,"[26] Finnegan Southey, Michael Bowling, Bryce Larson, Carmelo Piccione, Neil Burch, Darse
435"
ABSTRACT,0.5263157894736842,"Billings, and Chris Rayner. Bayes’ bluff: opponent modelling in poker. In Proceedings of the
436"
ABSTRACT,0.527389903329753,"Twenty-First Conference on Uncertainty in Artificial Intelligence, pages 550–558, 2005.
437"
ABSTRACT,0.5284640171858217,"[27] Kevin Waugh. A fast and optimal hand isomorphism algorithm. In AAAI Workshop on Computer
438"
ABSTRACT,0.5295381310418904,"Poker and Incomplete Information, 2013.
439"
ABSTRACT,0.5306122448979592,"[28] Kevin Waugh, David Schnizlein, Michael Bowling, and Duane Szafron. Abstraction pathologies
440"
ABSTRACT,0.5316863587540279,"in extensive games. In International Conference on Autonomous Agents and Multiagent Systems
441"
ABSTRACT,0.5327604726100966,"(AAMAS), volume 2, pages 781–788, 2009.
442"
ABSTRACT,0.5338345864661654,"[29] Kevin Waugh, Martin Zinkevich, Michael Johanson, Morgan Kan, David Schnizlein, and
443"
ABSTRACT,0.5349087003222341,"Michael Bowling. A practical use of imperfect recall. In Symposium on Abstraction, Reformu-
444"
ABSTRACT,0.5359828141783028,"lation and Approximation (SARA), 01 2009.
445"
ABSTRACT,0.5370569280343717,"[30] Martin Zinkevich, Michael Johanson, Michael Bowling, and Carmelo Piccione. Regret min-
446"
ABSTRACT,0.5381310418904404,"imization in games with incomplete information. In International Conference on Neural
447"
ABSTRACT,0.5392051557465092,"Information Processing Systems (NeurIPS), pages 1729–1736, 2007.
448"
ABSTRACT,0.5402792696025779,"Algorithm A1 Potential Winrate Isomorphism
Require:"
ABSTRACT,0.5413533834586466,"r = 1, . . . , R. Phases.
Θi = SR
r=1 Θ(r)
i
. Signal infoset space for player i.
Indexi(r, ·) : Θ(r)
i
7→N. Signal infoset index function for player i.
1: procedure POTENTIALWINRATEISOMORPHISM(Θi)
2:
for r = R to 1 do
3:
if r == R then
4:
FEATUREFUNC ←POTENTIALWINRATEFEATURELASTPHASE(·).
5:
else
6:
FEATUREFUNC ←POTENTIALWINRATEFEATURE(·, r, PC(r+1)
i
, PD(r+1)
i
).
7:
end if
8:
(PC(r)
i , PD(r)
i ) ←ISOMORPHISMCONSTRUCTOR(r, Θ(r)
i
, FEATUREFUNC).
9:
end for
10:
return (PC(1)
i , PD(1)
i ), . . . , (PC(R)
i
, PD(R)
i
).
11: end procedure
12: procedure POTENTIALWINRATESFEATURELASTPHASE(ϑ)
13:
return pf (R)
i
(ϑ)
▷compute according Equation (1)
14: end procedure
15: procedure POTENTIALWINRATEFEATURE(ϑ, r, PC(r+1)
i
, PD(r+1)
i
)
16:
featureϑ ←zero array with length N + 1"
ABSTRACT,0.5424274973147154,"17:
for ϑ′ ∈Θ(r+1)
i
, such that ∃θ′ ∈ϑ′, ∃θ ∈ϑ: ς(θ′|θ) > 0 do"
ABSTRACT,0.5435016111707841,"18:
idx ←Indexi(r + 1, ϑ′), abs ←PD(r+1)
i
[idx], featureϑ′ ←PC(r+1)
i
[abs].
19:
for j = 0 to N do
20:
featureϑ[j] ←featureϑ[j] + featureϑ′[j]Pr{ϑ′|ϑ}
21:
end for
22:
end for
23: end procedure"
ABSTRACT,0.5445757250268528,"A
Algorithm Details
449"
ABSTRACT,0.5456498388829216,"A.1
Potential Winrate Isomorphism
450"
ABSTRACT,0.5467239527389903,"Algorithm A1 describes the computation process for potential winrate isomorphism. This algorithm
451"
ABSTRACT,0.547798066595059,"operates in reverse, starting from the game’s final phase R.
452"
ABSTRACT,0.5488721804511278,"A.2
K-Recall Winrate Isomorphism
453"
ABSTRACT,0.5499462943071965,"Algorithm A2 constructs the k-recall winrate isomorphism using the k-recall winrate feature. This
454"
ABSTRACT,0.5510204081632653,"process requires the prior construction of the potential winrate isomorphism map PD(r)
i
using
455"
ABSTRACT,0.5520945220193341,"Algorithm A1.
456"
ABSTRACT,0.5531686358754028,"A.3
Accelerating Distance Computing for K-Recall Winrate Features
457"
ABSTRACT,0.5542427497314716,"According to Equation (5), we note that the distance calculation between a k-recall winrate isomor-
458"
ABSTRACT,0.5553168635875403,"phism class and a centroid’s k-recall winrate feature can be decomposed into k+1 pairs of potential
459"
ABSTRACT,0.556390977443609,"winrate feature EMD calculations. The potential winrate feature of the hand remains unchanged,
460"
ABSTRACT,0.5574650912996778,"while only the potential winrate feature of the centroid changes. Decomposing the calculation into the
461"
ABSTRACT,0.5585392051557465,"EMDs of potential winrate features involves significantly fewer computations than directly calculating
462"
ABSTRACT,0.5596133190118152,"the EMD of two k-recall winrate features. Specifically, for the River phase of HUNL&HULHE, we
463"
ABSTRACT,0.560687432867884,have the compression ratio as 169+1028325+1850624+20687
ABSTRACT,0.5617615467239527,"529890863
=
2899805
529890863 = 0.0054725.
464"
ABSTRACT,0.5628356605800214,"Algorithm A3 describes how we accelerate the batch EMD computation between a centroid and all
465"
ABSTRACT,0.5639097744360902,"KRWI classes’ k-recall winrate features. It should be noted that the K-recall winrate feature involved
466"
ABSTRACT,0.564983888292159,"in the calculation of the centroid in the algorithm is in the form of Equation (3), while the K-recall
467"
ABSTRACT,0.5660580021482277,"winrate feature in RC(r,k) is in the form of Equation (4). This method reduced the computational
468"
ABSTRACT,0.5671321160042965,"Algorithm A2 K-Recall Winrate Isomorphism
Require:"
ABSTRACT,0.5682062298603652,"r = 1, . . . , R. Phases.
Θ(r)
i
. Signal infoset space for player i.
Indexi(r, ·) : Θ(r)
i
7→N. Signal infoset index function for player i.
PD(r)
i
: N 7→N. Potential winrate isomporphism map.
1: procedure KRECALLWINRATEISOMORPHISM(Θi, k)
2:
for r = 1 to R do
3:
k′ ←MIN(r −1, k).
4:
FEATUREFUNC ←KRECALLWINRATEFEATURE(·, r, k′)."
ABSTRACT,0.569280343716434,"5:
(RC(r,k′)
i
, RD(r,k′)
i
) ←ISOMORPHISMCONSTRUCTOR(r, Θ(r)
i
, FEATUREFUNC).
6:
end for
7:
return (RC(1,0)
i
, RD(1,0)
i
), . . . , (RC(k+1,k)
i
, RD(k+1,k)
i
), . . . , (RC(R,k)
i
, RD(R,k)
i
).
8: end procedure
9: procedure KRECALLWINRATESFEATURE(ϑ, r, k)
10:
initial a empty vector feature.
11:
for s = r to r −k do
12:
ϑ′ ←the predecessor signal infoset of ϑ in the s phase for player i."
ABSTRACT,0.5703544575725027,"13:
idx ←Indexi(s, ϑ′), abs ←PD(s)
i [idx].
14:
Append feature with abs.
15:
end for
16:
return feature
17: end procedure"
ABSTRACT,0.5714285714285714,"cost of EMD from 19000 core hours to approximately 104 core hours, which is significantly lower
469"
ABSTRACT,0.5725026852846402,"than the time cost of summarizing the distance for each KRWI class, which is about 524 core hours
470"
ABSTRACT,0.5735767991407089,"and is an unavoidable O(1) cost.
471"
ABSTRACT,0.5746509129967776,"The distance batch calculation for each centroid can be processed independently and distributed
472"
ABSTRACT,0.5757250268528464,"across tens of multi-core computer (e.g. 96-core computers), with each computer responsible for
473"
ABSTRACT,0.5767991407089151,"calculating the features of some centroids in one iteration, which are then aggregated. Using this
474"
ABSTRACT,0.5778732545649838,"technique, we can reduce an iteration to a few hours, which is acceptable for Texas Hold’em AI
475"
ABSTRACT,0.5789473684210527,"training.
476"
ABSTRACT,0.5800214822771214,"B
Numerall211 Hold’em Rules
477"
ABSTRACT,0.5810955961331902,"Numeral211 Hold’em is played according to the following rule:
478"
ABSTRACT,0.5821697099892589,"1. Ante: Each player antes 5 chip into the pot at the start of the hand.
479"
ABSTRACT,0.5832438238453276,"2. Hole Card: Both players are dealt one private card face down, known as the hole card.
480"
ABSTRACT,0.5843179377013964,"3. Deck: The deck consists of a standard poker deck, excluding the Jokers, Kings, Queens,
481"
ABSTRACT,0.5853920515574651,"and Jacks, resulting in a total of 40 cards. There are four suits: spades (♠), hearts (♡), clubs
482"
ABSTRACT,0.5864661654135338,"(♣), and diamonds (♢), each containing ten cards numbered 2 through 9, and including the
483"
ABSTRACT,0.5875402792696026,"ten (T) and ace (A).
484"
ABSTRACT,0.5886143931256713,"4. First Betting Phase: Following the distribution of hole cards, a phase of betting occurs.
485"
ABSTRACT,0.58968850698174,"Players can choose to check or bet, with the bet size set at 10 chips.
486"
ABSTRACT,0.5907626208378088,"5. Flop: After the initial betting phase, a single community card, termed the flop, is revealed
487"
ABSTRACT,0.5918367346938775,"from the deck.
488"
ABSTRACT,0.5929108485499462,"6. Second Betting Phase: Another phase of betting takes place after the flop, with the bet size
489"
ABSTRACT,0.5939849624060151,"increasing to 20 chips.
490"
ABSTRACT,0.5950590762620838,"7. Turn: After the Second betting phase, another community card, termed the turn, is revealed
491"
ABSTRACT,0.5961331901181526,"from the deck.
492"
ABSTRACT,0.5972073039742213,"8. Third Betting Phase: Another phase of betting takes place after the turn, with the bet size
493"
ABSTRACT,0.59828141783029,"still set at 20 chips.
494"
ABSTRACT,0.5993555316863588,"Algorithm A3 Distance Batch
Require:"
ABSTRACT,0.6004296455424275,"r = 1, . . . , R. Phases.
RC(r,k)
i
: N 7→Nk+1. K-recall winrate feature set.
PC(r)
i
: N 7→[0, 1]N+1. Potential winrate feature set.
PD(r)
i
: N 7→N. Potential winrate isomporphism map.
rc = (pc(r), . . . , pc(r−k)). K-recall winrate feature of the input centroid.
Ensure:"
ABSTRACT,0.6015037593984962,"Distances of all k-recall winrate feature with centroid.
1: procedure DISTANCEBATCH(w0, . . . , wk, rc, r, k)"
ABSTRACT,0.602577873254565,"Initial phase s empty earth mover’s distance vector EmdDis(s) for s = r, . . . , r −k.
Initial empty output distance vector Dis.
2:
for t = 0 to k do
3:
for pf in PC(s)
i
do
4:
Append EmdDis(r−t) with Emd(pf, rc[t])
5:
end for
6:
end for
7:
for rfi in RC(r,k)
i
do
8:
dis ←0.
9:
for t = 0 to k do
10:
dis ←dis + wt ∗EmdDis(r−t)[PD(r−t)
i
[rfi[t]]].
11:
end for
12:
Append Dis with dis.
13:
end for
return Dis.
14: end procedure"
ABSTRACT,0.6036519871106337,"9. Showdown: If neither player folds, a showdown occurs. Players reveal their cards, aiming
495"
ABSTRACT,0.6047261009667024,"to form the best possible hand. The player with the highest-ranked hand wins the pot. In
496"
ABSTRACT,0.6058002148227712,"the case of a tie, the pot is split evenly. The Table 2 show the hand ranks of Numeral211
497"
ABSTRACT,0.60687432867884,"Hold’em.
498"
ABSTRACT,0.6079484425349087,"10. Betting Options: Throughout the game, players have options to fold, call, or raise. In each
499"
ABSTRACT,0.6090225563909775,"betting phase, the total sum of bets and raises is limited to a maximum of 4, with fixed bet
500"
ABSTRACT,0.6100966702470462,"sizes of 10 chips in the first phase and 20 chips in the last two betting phases.
501"
ABSTRACT,0.611170784103115,"C
Supplementary Data for Experiment 1
502"
ABSTRACT,0.6122448979591837,"Figure 6 show all of the result in experiment 1.
503"
ABSTRACT,0.6133190118152524,"Rank
Hand
Prob.
Description
Example
1
Straight flush
0.00321
3 of cards with consecutive rank and
same suit. Ties are broken by high-
est card."
ABSTRACT,0.6143931256713212,T♠9♠8♠2♣
THREE OF A KIND,0.6154672395273899,"2
Three of a kind
0.01587
3 of cards with the same rank. Ties
are broken by the card’s rank.
T♠T♡T♣2♣"
STRAIGHT,0.6165413533834586,"3
Straight
0.04347
3 of cards with consecutive rank.
Ties are broken by the highest card
rank."
STRAIGHT,0.6176154672395274,T♠9♡8♣2♢
FLUSH,0.6186895810955961,"4
Flush
0.15799
3 of cards with the same suit. Ties
are broken by the highest card rank,
then second highest card rank, then
third highest card rank."
FLUSH,0.6197636949516648,T♠8♠6♠2♣
PAIR,0.6208378088077336,"5
Pair
0.34065
2 of cards with the same rank. Ties
are broken by the rank of the pair,
then by the rank of the third card."
PAIR,0.6219119226638024,T♠T♡8♣2♢
HIGH CARD,0.6229860365198711,"6
High card
0.43881
None of the above. Ties are bro-
ken by comparing the highest ranked
card, then the second highest ranked
card, and then the third highest
ranked card"
HIGH CARD,0.6240601503759399,T♠8♡6♣2♢
HIGH CARD,0.6251342642320086,Table 2: Hand ranks of Numeral211 Hold’em   ✁
HIGH CARD,0.6262083780880774,"✂✄
☎✆✁"
HIGH CARD,0.6272824919441461,"✂✄
☎
✝
✁ ✞
✆✁"
HIGH CARD,0.6283566058002148,"✟
✠
✡
☛
☞
✌
✄
✍
✄
✍
✄
✍"
HIGH CARD,0.6294307196562836,"✟
✠
✡
☛
☞
✌
✄
✍
✎✄
✏✄
✍"
HIGH CARD,0.6305048335123523,"✟
✠
✡
☛
☞
✌
✄
✑✄
✒✄
✓"
HIGH CARD,0.631578947368421,"✟
✠
✡
☛
☞
✌
✄
✓✄
✒✄
✑ ★ ✩✪ ✪
★ ✫✪ ✬★
★ ✬
✩✪"
HIGH CARD,0.6326530612244898,"✭
✮✯
✰✱
✲✳✴
✮✯✳
✰✵
✱
✶ ✬★ ✷ ✬★ ✸✹ (a)   ✁"
HIGH CARD,0.6337271750805585,"✂✄
☎✆✁"
HIGH CARD,0.6348012889366272,"✂✄
☎
✝
✁ ✞
✆✁"
HIGH CARD,0.635875402792696,"✟
✠
✡
☛
☞
✌✍
✍
✍"
HIGH CARD,0.6369495166487648,"✟
✠
✡
☛
☞
✌✍
✎✏
✍"
HIGH CARD,0.6380236305048335,"✟
✠
✡
☛
☞
✌
✄
✑✄
✒✄
✓"
HIGH CARD,0.6390977443609023,"✟
✠
✡
☛
☞
✌
✄
✓✄
✒✄
✑ ★ ✩★ ✪
★ ✫★ ✬★"
HIGH CARD,0.640171858216971,"✭
✮✯
✰✱
✲✳✴
✮✯✳
✰✵
✱
✶ ✩★ ✷ ✩★ ✸✹ (b)"
HIGH CARD,0.6412459720730398,Figure 6: All data within experiment 1
HIGH CARD,0.6423200859291085,"NeurIPS Paper Checklist
504"
CLAIMS,0.6433941997851772,"1. Claims
505"
CLAIMS,0.644468313641246,"Question: Do the main claims made in the abstract and introduction accurately reflect the
506"
CLAIMS,0.6455424274973147,"paper’s contributions and scope?
507"
CLAIMS,0.6466165413533834,"Answer: [Yes]
508"
CLAIMS,0.6476906552094522,"Justification: We have clearly defined our scope and contributions in both the abstract and
509"
CLAIMS,0.6487647690655209,"introduction sections.
510"
CLAIMS,0.6498388829215896,"Guidelines:
511"
CLAIMS,0.6509129967776585,"• The answer NA means that the abstract and introduction do not include the claims
512"
CLAIMS,0.6519871106337272,"made in the paper.
513"
CLAIMS,0.6530612244897959,"• The abstract and/or introduction should clearly state the claims made, including the
514"
CLAIMS,0.6541353383458647,"contributions made in the paper and important assumptions and limitations. A No or
515"
CLAIMS,0.6552094522019334,"NA answer to this question will not be perceived well by the reviewers.
516"
CLAIMS,0.6562835660580022,"• The claims made should match theoretical and experimental results, and reflect how
517"
CLAIMS,0.6573576799140709,"much the results can be expected to generalize to other settings.
518"
CLAIMS,0.6584317937701396,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
519"
CLAIMS,0.6595059076262084,"are not attained by the paper.
520"
LIMITATIONS,0.6605800214822771,"2. Limitations
521"
LIMITATIONS,0.6616541353383458,"Question: Does the paper discuss the limitations of the work performed by the authors?
522"
LIMITATIONS,0.6627282491944146,"Answer: [NA]
523"
LIMITATIONS,0.6638023630504833,"Justification: This paper introduces a novel hand abstraction algorithm that has been experi-
524"
LIMITATIONS,0.664876476906552,"mentally validated to outperform the previous state-of-the-art (SOTA) algorithm, PaEmd,
525"
LIMITATIONS,0.6659505907626209,"and no significant flaws have been identified thus far.
526"
LIMITATIONS,0.6670247046186896,"Guidelines:
527"
LIMITATIONS,0.6680988184747583,"• The answer NA means that the paper has no limitation while the answer No means that
528"
LIMITATIONS,0.6691729323308271,"the paper has limitations, but those are not discussed in the paper.
529"
LIMITATIONS,0.6702470461868958,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
530"
LIMITATIONS,0.6713211600429646,"• The paper should point out any strong assumptions and how robust the results are to
531"
LIMITATIONS,0.6723952738990333,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
532"
LIMITATIONS,0.673469387755102,"model well-specification, asymptotic approximations only holding locally). The authors
533"
LIMITATIONS,0.6745435016111708,"should reflect on how these assumptions might be violated in practice and what the
534"
LIMITATIONS,0.6756176154672395,"implications would be.
535"
LIMITATIONS,0.6766917293233082,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
536"
LIMITATIONS,0.677765843179377,"only tested on a few datasets or with a few runs. In general, empirical results often
537"
LIMITATIONS,0.6788399570354458,"depend on implicit assumptions, which should be articulated.
538"
LIMITATIONS,0.6799140708915145,"• The authors should reflect on the factors that influence the performance of the approach.
539"
LIMITATIONS,0.6809881847475833,"For example, a facial recognition algorithm may perform poorly when image resolution
540"
LIMITATIONS,0.682062298603652,"is low or images are taken in low lighting. Or a speech-to-text system might not be
541"
LIMITATIONS,0.6831364124597207,"used reliably to provide closed captions for online lectures because it fails to handle
542"
LIMITATIONS,0.6842105263157895,"technical jargon.
543"
LIMITATIONS,0.6852846401718582,"• The authors should discuss the computational efficiency of the proposed algorithms
544"
LIMITATIONS,0.686358754027927,"and how they scale with dataset size.
545"
LIMITATIONS,0.6874328678839957,"• If applicable, the authors should discuss possible limitations of their approach to
546"
LIMITATIONS,0.6885069817400644,"address problems of privacy and fairness.
547"
LIMITATIONS,0.6895810955961332,"• While the authors might fear that complete honesty about limitations might be used by
548"
LIMITATIONS,0.6906552094522019,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
549"
LIMITATIONS,0.6917293233082706,"limitations that aren’t acknowledged in the paper. The authors should use their best
550"
LIMITATIONS,0.6928034371643395,"judgment and recognize that individual actions in favor of transparency play an impor-
551"
LIMITATIONS,0.6938775510204082,"tant role in developing norms that preserve the integrity of the community. Reviewers
552"
LIMITATIONS,0.6949516648764769,"will be specifically instructed to not penalize honesty concerning limitations.
553"
THEORY ASSUMPTIONS AND PROOFS,0.6960257787325457,"3. Theory Assumptions and Proofs
554"
THEORY ASSUMPTIONS AND PROOFS,0.6970998925886144,"Question: For each theoretical result, does the paper provide the full set of assumptions and
555"
THEORY ASSUMPTIONS AND PROOFS,0.6981740064446831,"a complete (and correct) proof?
556"
THEORY ASSUMPTIONS AND PROOFS,0.6992481203007519,"Answer: [NA]
557"
THEORY ASSUMPTIONS AND PROOFS,0.7003222341568206,"Justification: This paper introduces a novel algorithm and validates its effectiveness through
558"
THEORY ASSUMPTIONS AND PROOFS,0.7013963480128894,"experiments, without involving theory or proofs.
559"
THEORY ASSUMPTIONS AND PROOFS,0.7024704618689581,"Guidelines:
560"
THEORY ASSUMPTIONS AND PROOFS,0.7035445757250268,"• The answer NA means that the paper does not include theoretical results.
561"
THEORY ASSUMPTIONS AND PROOFS,0.7046186895810956,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
562"
THEORY ASSUMPTIONS AND PROOFS,0.7056928034371643,"referenced.
563"
THEORY ASSUMPTIONS AND PROOFS,0.706766917293233,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
564"
THEORY ASSUMPTIONS AND PROOFS,0.7078410311493019,"• The proofs can either appear in the main paper or the supplemental material, but if
565"
THEORY ASSUMPTIONS AND PROOFS,0.7089151450053706,"they appear in the supplemental material, the authors are encouraged to provide a short
566"
THEORY ASSUMPTIONS AND PROOFS,0.7099892588614393,"proof sketch to provide intuition.
567"
THEORY ASSUMPTIONS AND PROOFS,0.7110633727175081,"• Inversely, any informal proof provided in the core of the paper should be complemented
568"
THEORY ASSUMPTIONS AND PROOFS,0.7121374865735768,"by formal proofs provided in appendix or supplemental material.
569"
THEORY ASSUMPTIONS AND PROOFS,0.7132116004296455,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
570"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7142857142857143,"4. Experimental Result Reproducibility
571"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.715359828141783,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
572"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7164339419978518,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
573"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7175080558539205,"of the paper (regardless of whether the code and data are provided or not)?
574"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7185821697099892,"Answer: [Yes]
575"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.719656283566058,"Justification: We have provided detailed information on the testbed, evaluation metrics, and
576"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7207303974221267,"experimental scenarios in Section 6. Additionally, specific experimental parameters and
577"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7218045112781954,"equipment are given in Section 7. Therefore, we have included sufficient details in the paper
578"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7228786251342643,"to reproduce the experiments.
579"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.723952738990333,"Guidelines:
580"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7250268528464017,"• The answer NA means that the paper does not include experiments.
581"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7261009667024705,"• If the paper includes experiments, a No answer to this question will not be perceived
582"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7271750805585392,"well by the reviewers: Making the paper reproducible is important, regardless of
583"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.728249194414608,"whether the code and data are provided or not.
584"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7293233082706767,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
585"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7303974221267454,"to make their results reproducible or verifiable.
586"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7314715359828142,"• Depending on the contribution, reproducibility can be accomplished in various ways.
587"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7325456498388829,"For example, if the contribution is a novel architecture, describing the architecture fully
588"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7336197636949516,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
589"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7346938775510204,"be necessary to either make it possible for others to replicate the model with the same
590"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7357679914070892,"dataset, or provide access to the model. In general. releasing code and data is often
591"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7368421052631579,"one good way to accomplish this, but reproducibility can also be provided via detailed
592"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7379162191192267,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
593"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7389903329752954,"of a large language model), releasing of a model checkpoint, or other means that are
594"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7400644468313641,"appropriate to the research performed.
595"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7411385606874329,"• While NeurIPS does not require releasing code, the conference does require all submis-
596"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7422126745435016,"sions to provide some reasonable avenue for reproducibility, which may depend on the
597"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7432867883995704,"nature of the contribution. For example
598"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7443609022556391,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
599"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7454350161117078,"to reproduce that algorithm.
600"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7465091299677766,"(b) If the contribution is primarily a new model architecture, the paper should describe
601"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7475832438238453,"the architecture clearly and fully.
602"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.748657357679914,"(c) If the contribution is a new model (e.g., a large language model), then there should
603"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7497314715359829,"either be a way to access this model for reproducing the results or a way to reproduce
604"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7508055853920516,"the model (e.g., with an open-source dataset or instructions for how to construct
605"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7518796992481203,"the dataset).
606"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7529538131041891,"(d) We recognize that reproducibility may be tricky in some cases, in which case
607"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7540279269602578,"authors are welcome to describe the particular way they provide for reproducibility.
608"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7551020408163265,"In the case of closed-source models, it may be that access to the model is limited in
609"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7561761546723953,"some way (e.g., to registered users), but it should be possible for other researchers
610"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.757250268528464,"to have some path to reproducing or verifying the results.
611"
OPEN ACCESS TO DATA AND CODE,0.7583243823845328,"5. Open access to data and code
612"
OPEN ACCESS TO DATA AND CODE,0.7593984962406015,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
613"
OPEN ACCESS TO DATA AND CODE,0.7604726100966702,"tions to faithfully reproduce the main experimental results, as described in supplemental
614"
OPEN ACCESS TO DATA AND CODE,0.761546723952739,"material?
615"
OPEN ACCESS TO DATA AND CODE,0.7626208378088077,"Answer: [No]
616"
OPEN ACCESS TO DATA AND CODE,0.7636949516648764,"Justification: The experiments in this paper are time-consuming, and we utilized a large
617"
OPEN ACCESS TO DATA AND CODE,0.7647690655209453,"number of machines to simultaneously conduct various parts of the experiments. Currently,
618"
OPEN ACCESS TO DATA AND CODE,0.765843179377014,"we do not have a ready-to-use script for one-click deployment of the experiments (the time
619"
OPEN ACCESS TO DATA AND CODE,0.7669172932330827,"required to run on a single computer is unacceptable). In the future, we will open-source
620"
OPEN ACCESS TO DATA AND CODE,0.7679914070891515,"this work and provide the code to reproduce these experiments.
621"
OPEN ACCESS TO DATA AND CODE,0.7690655209452202,"Guidelines:
622"
OPEN ACCESS TO DATA AND CODE,0.7701396348012889,"• The answer NA means that paper does not include experiments requiring code.
623"
OPEN ACCESS TO DATA AND CODE,0.7712137486573577,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
624"
OPEN ACCESS TO DATA AND CODE,0.7722878625134264,"public/guides/CodeSubmissionPolicy) for more details.
625"
OPEN ACCESS TO DATA AND CODE,0.7733619763694952,"• While we encourage the release of code and data, we understand that this might not be
626"
OPEN ACCESS TO DATA AND CODE,0.7744360902255639,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
627"
OPEN ACCESS TO DATA AND CODE,0.7755102040816326,"including code, unless this is central to the contribution (e.g., for a new open-source
628"
OPEN ACCESS TO DATA AND CODE,0.7765843179377014,"benchmark).
629"
OPEN ACCESS TO DATA AND CODE,0.7776584317937701,"• The instructions should contain the exact command and environment needed to run to
630"
OPEN ACCESS TO DATA AND CODE,0.7787325456498388,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
631"
OPEN ACCESS TO DATA AND CODE,0.7798066595059077,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
632"
OPEN ACCESS TO DATA AND CODE,0.7808807733619764,"• The authors should provide instructions on data access and preparation, including how
633"
OPEN ACCESS TO DATA AND CODE,0.7819548872180451,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
634"
OPEN ACCESS TO DATA AND CODE,0.7830290010741139,"• The authors should provide scripts to reproduce all experimental results for the new
635"
OPEN ACCESS TO DATA AND CODE,0.7841031149301826,"proposed method and baselines. If only a subset of experiments are reproducible, they
636"
OPEN ACCESS TO DATA AND CODE,0.7851772287862513,"should state which ones are omitted from the script and why.
637"
OPEN ACCESS TO DATA AND CODE,0.7862513426423201,"• At submission time, to preserve anonymity, the authors should release anonymized
638"
OPEN ACCESS TO DATA AND CODE,0.7873254564983888,"versions (if applicable).
639"
OPEN ACCESS TO DATA AND CODE,0.7883995703544576,"• Providing as much information as possible in supplemental material (appended to the
640"
OPEN ACCESS TO DATA AND CODE,0.7894736842105263,"paper) is recommended, but including URLs to data and code is permitted.
641"
OPEN ACCESS TO DATA AND CODE,0.790547798066595,"6. Experimental Setting/Details
642"
OPEN ACCESS TO DATA AND CODE,0.7916219119226638,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
643"
OPEN ACCESS TO DATA AND CODE,0.7926960257787325,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
644"
OPEN ACCESS TO DATA AND CODE,0.7937701396348013,"results?
645"
OPEN ACCESS TO DATA AND CODE,0.7948442534908701,"Answer: [Yes]
646"
OPEN ACCESS TO DATA AND CODE,0.7959183673469388,"Justification: As stated in the reproducibility statement, we have provided detailed informa-
647"
OPEN ACCESS TO DATA AND CODE,0.7969924812030075,"tion on the testbed, evaluation metrics, and experimental scenarios in Section 6. Additionally,
648"
OPEN ACCESS TO DATA AND CODE,0.7980665950590763,"specific experimental parameters and equipment are given in Section 7.
649"
OPEN ACCESS TO DATA AND CODE,0.799140708915145,"Guidelines:
650"
OPEN ACCESS TO DATA AND CODE,0.8002148227712137,"• The answer NA means that the paper does not include experiments.
651"
OPEN ACCESS TO DATA AND CODE,0.8012889366272825,"• The experimental setting should be presented in the core of the paper to a level of detail
652"
OPEN ACCESS TO DATA AND CODE,0.8023630504833512,"that is necessary to appreciate the results and make sense of them.
653"
OPEN ACCESS TO DATA AND CODE,0.80343716433942,"• The full details can be provided either with the code, in appendix, or as supplemental
654"
OPEN ACCESS TO DATA AND CODE,0.8045112781954887,"material.
655"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8055853920515574,"7. Experiment Statistical Significance
656"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8066595059076263,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
657"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.807733619763695,"information about the statistical significance of the experiments?
658"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8088077336197637,"Answer: [No]
659"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8098818474758325,"Justification: Due to the long experimental time and limited sample size, error bars cannot
660"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8109559613319012,"be provided. In the first experiment (Figure 4), the baseline settings adopt fixed abstraction
661"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8120300751879699,"settings and have a large performance gap, so the performance of strategies solved by
662"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8131041890440387,"CSMCCFR is stable and not easily affected by random factors. In the second experiment
663"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8141783029001074,"(Figure 5), random factors may indeed affect individual experimental data. Therefore, we
664"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8152524167561761,"sampled the control group multiple times and drew the performance range, which is far
665"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8163265306122449,"lower than the performance of our algorithm under the worst parameters, which also proves
666"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8174006444683136,"the effectiveness of the algorithm.
667"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8184747583243824,"Guidelines:
668"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8195488721804511,"• The answer NA means that the paper does not include experiments.
669"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8206229860365198,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
670"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8216970998925887,"dence intervals, or statistical significance tests, at least for the experiments that support
671"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8227712137486574,"the main claims of the paper.
672"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8238453276047261,"• The factors of variability that the error bars are capturing should be clearly stated (for
673"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8249194414607949,"example, train/test split, initialization, random drawing of some parameter, or overall
674"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8259935553168636,"run with given experimental conditions).
675"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8270676691729323,"• The method for calculating the error bars should be explained (closed form formula,
676"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8281417830290011,"call to a library function, bootstrap, etc.)
677"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8292158968850698,"• The assumptions made should be given (e.g., Normally distributed errors).
678"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8302900107411385,"• It should be clear whether the error bar is the standard deviation or the standard error
679"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8313641245972073,"of the mean.
680"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.832438238453276,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
681"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8335123523093448,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
682"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8345864661654135,"of Normality of errors is not verified.
683"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8356605800214822,"• For asymmetric distributions, the authors should be careful not to show in tables or
684"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8367346938775511,"figures symmetric error bars that would yield results that are out of range (e.g. negative
685"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8378088077336198,"error rates).
686"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8388829215896885,"• If error bars are reported in tables or plots, The authors should explain in the text how
687"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8399570354457573,"they were calculated and reference the corresponding figures or tables in the text.
688"
EXPERIMENTS COMPUTE RESOURCES,0.841031149301826,"8. Experiments Compute Resources
689"
EXPERIMENTS COMPUTE RESOURCES,0.8421052631578947,"Question: For each experiment, does the paper provide sufficient information on the com-
690"
EXPERIMENTS COMPUTE RESOURCES,0.8431793770139635,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
691"
EXPERIMENTS COMPUTE RESOURCES,0.8442534908700322,"the experiments?
692"
EXPERIMENTS COMPUTE RESOURCES,0.8453276047261009,"Answer: [Yes]
693"
EXPERIMENTS COMPUTE RESOURCES,0.8464017185821697,"Justification: We discuss the computational resources and time cost of the experiments in
694"
EXPERIMENTS COMPUTE RESOURCES,0.8474758324382384,"Sections 5, 7, and Appendix A.3.
695"
EXPERIMENTS COMPUTE RESOURCES,0.8485499462943072,"Guidelines:
696"
EXPERIMENTS COMPUTE RESOURCES,0.849624060150376,"• The answer NA means that the paper does not include experiments.
697"
EXPERIMENTS COMPUTE RESOURCES,0.8506981740064447,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
698"
EXPERIMENTS COMPUTE RESOURCES,0.8517722878625135,"or cloud provider, including relevant memory and storage.
699"
EXPERIMENTS COMPUTE RESOURCES,0.8528464017185822,"• The paper should provide the amount of compute required for each of the individual
700"
EXPERIMENTS COMPUTE RESOURCES,0.8539205155746509,"experimental runs as well as estimate the total compute.
701"
EXPERIMENTS COMPUTE RESOURCES,0.8549946294307197,"• The paper should disclose whether the full research project required more compute
702"
EXPERIMENTS COMPUTE RESOURCES,0.8560687432867884,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
703"
EXPERIMENTS COMPUTE RESOURCES,0.8571428571428571,"didn’t make it into the paper).
704"
CODE OF ETHICS,0.8582169709989259,"9. Code Of Ethics
705"
CODE OF ETHICS,0.8592910848549946,"Question: Does the research conducted in the paper conform, in every respect, with the
706"
CODE OF ETHICS,0.8603651987110634,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
707"
CODE OF ETHICS,0.8614393125671321,"Answer: [Yes]
708"
CODE OF ETHICS,0.8625134264232008,"Justification: We carefully review the NeurIPS Code of Ethics and ensure that the research
709"
CODE OF ETHICS,0.8635875402792696,"aligns with it in all aspects.
710"
CODE OF ETHICS,0.8646616541353384,"Guidelines:
711"
CODE OF ETHICS,0.8657357679914071,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
712"
CODE OF ETHICS,0.8668098818474759,"• If the authors answer No, they should explain the special circumstances that require a
713"
CODE OF ETHICS,0.8678839957035446,"deviation from the Code of Ethics.
714"
CODE OF ETHICS,0.8689581095596133,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
715"
CODE OF ETHICS,0.8700322234156821,"eration due to laws or regulations in their jurisdiction).
716"
BROADER IMPACTS,0.8711063372717508,"10. Broader Impacts
717"
BROADER IMPACTS,0.8721804511278195,"Question: Does the paper discuss both potential positive societal impacts and negative
718"
BROADER IMPACTS,0.8732545649838883,"societal impacts of the work performed?
719"
BROADER IMPACTS,0.874328678839957,"Answer: [Yes]
720"
BROADER IMPACTS,0.8754027926960258,"Justification: We discuss the impact of this work in Section 8. As noted, this work represents
721"
BROADER IMPACTS,0.8764769065520945,"the SOTA in hand abstraction algorithms and could be used to create more powerful Texas
722"
BROADER IMPACTS,0.8775510204081632,"Hold’em AI.
723"
BROADER IMPACTS,0.878625134264232,"Guidelines:
724"
BROADER IMPACTS,0.8796992481203008,"• The answer NA means that there is no societal impact of the work performed.
725"
BROADER IMPACTS,0.8807733619763695,"• If the authors answer NA or No, they should explain why their work has no societal
726"
BROADER IMPACTS,0.8818474758324383,"impact or why the paper does not address societal impact.
727"
BROADER IMPACTS,0.882921589688507,"• Examples of negative societal impacts include potential malicious or unintended uses
728"
BROADER IMPACTS,0.8839957035445757,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
729"
BROADER IMPACTS,0.8850698174006445,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
730"
BROADER IMPACTS,0.8861439312567132,"groups), privacy considerations, and security considerations.
731"
BROADER IMPACTS,0.8872180451127819,"• The conference expects that many papers will be foundational research and not tied
732"
BROADER IMPACTS,0.8882921589688507,"to particular applications, let alone deployments. However, if there is a direct path to
733"
BROADER IMPACTS,0.8893662728249194,"any negative applications, the authors should point it out. For example, it is legitimate
734"
BROADER IMPACTS,0.8904403866809882,"to point out that an improvement in the quality of generative models could be used to
735"
BROADER IMPACTS,0.8915145005370569,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
736"
BROADER IMPACTS,0.8925886143931256,"that a generic algorithm for optimizing neural networks could enable people to train
737"
BROADER IMPACTS,0.8936627282491945,"models that generate Deepfakes faster.
738"
BROADER IMPACTS,0.8947368421052632,"• The authors should consider possible harms that could arise when the technology is
739"
BROADER IMPACTS,0.8958109559613319,"being used as intended and functioning correctly, harms that could arise when the
740"
BROADER IMPACTS,0.8968850698174007,"technology is being used as intended but gives incorrect results, and harms following
741"
BROADER IMPACTS,0.8979591836734694,"from (intentional or unintentional) misuse of the technology.
742"
BROADER IMPACTS,0.8990332975295381,"• If there are negative societal impacts, the authors could also discuss possible mitigation
743"
BROADER IMPACTS,0.9001074113856069,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
744"
BROADER IMPACTS,0.9011815252416756,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
745"
BROADER IMPACTS,0.9022556390977443,"feedback over time, improving the efficiency and accessibility of ML).
746"
SAFEGUARDS,0.9033297529538131,"11. Safeguards
747"
SAFEGUARDS,0.9044038668098818,"Question: Does the paper describe safeguards that have been put in place for responsible
748"
SAFEGUARDS,0.9054779806659506,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
749"
SAFEGUARDS,0.9065520945220193,"image generators, or scraped datasets)?
750"
SAFEGUARDS,0.907626208378088,"Answer: [NA]
751"
SAFEGUARDS,0.9087003222341569,"Justification: Our work focuses solely on introducing a more efficient algorithm for hand
752"
ABSTRACT,0.9097744360902256,"abstraction and does not involve the release of data or models.
753"
ABSTRACT,0.9108485499462943,"Guidelines:
754"
ABSTRACT,0.9119226638023631,"• The answer NA means that the paper poses no such risks.
755"
ABSTRACT,0.9129967776584318,"• Released models that have a high risk for misuse or dual-use should be released with
756"
ABSTRACT,0.9140708915145005,"necessary safeguards to allow for controlled use of the model, for example by requiring
757"
ABSTRACT,0.9151450053705693,"that users adhere to usage guidelines or restrictions to access the model or implementing
758"
ABSTRACT,0.916219119226638,"safety filters.
759"
ABSTRACT,0.9172932330827067,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
760"
ABSTRACT,0.9183673469387755,"should describe how they avoided releasing unsafe images.
761"
ABSTRACT,0.9194414607948442,"• We recognize that providing effective safeguards is challenging, and many papers do
762"
ABSTRACT,0.920515574650913,"not require this, but we encourage authors to take this into account and make a best
763"
ABSTRACT,0.9215896885069818,"faith effort.
764"
LICENSES FOR EXISTING ASSETS,0.9226638023630505,"12. Licenses for existing assets
765"
LICENSES FOR EXISTING ASSETS,0.9237379162191193,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
766"
LICENSES FOR EXISTING ASSETS,0.924812030075188,"the paper, properly credited and are the license and terms of use explicitly mentioned and
767"
LICENSES FOR EXISTING ASSETS,0.9258861439312567,"properly respected?
768"
LICENSES FOR EXISTING ASSETS,0.9269602577873255,"Answer: [Yes]
769"
LICENSES FOR EXISTING ASSETS,0.9280343716433942,"Justification: This paper provides comprehensive citations for all comparative methods
770"
LICENSES FOR EXISTING ASSETS,0.9291084854994629,"involved, and all comparison experiments were re-implemented without using existing tools
771"
LICENSES FOR EXISTING ASSETS,0.9301825993555317,"or code.
772"
LICENSES FOR EXISTING ASSETS,0.9312567132116004,"Guidelines:
773"
LICENSES FOR EXISTING ASSETS,0.9323308270676691,"• The answer NA means that the paper does not use existing assets.
774"
LICENSES FOR EXISTING ASSETS,0.9334049409237379,"• The authors should cite the original paper that produced the code package or dataset.
775"
LICENSES FOR EXISTING ASSETS,0.9344790547798066,"• The authors should state which version of the asset is used and, if possible, include a
776"
LICENSES FOR EXISTING ASSETS,0.9355531686358755,"URL.
777"
LICENSES FOR EXISTING ASSETS,0.9366272824919442,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
778"
LICENSES FOR EXISTING ASSETS,0.9377013963480129,"• For scraped data from a particular source (e.g., website), the copyright and terms of
779"
LICENSES FOR EXISTING ASSETS,0.9387755102040817,"service of that source should be provided.
780"
LICENSES FOR EXISTING ASSETS,0.9398496240601504,"• If assets are released, the license, copyright information, and terms of use in the
781"
LICENSES FOR EXISTING ASSETS,0.9409237379162191,"package should be provided. For popular datasets, paperswithcode.com/datasets
782"
LICENSES FOR EXISTING ASSETS,0.9419978517722879,"has curated licenses for some datasets. Their licensing guide can help determine the
783"
LICENSES FOR EXISTING ASSETS,0.9430719656283566,"license of a dataset.
784"
LICENSES FOR EXISTING ASSETS,0.9441460794844253,"• For existing datasets that are re-packaged, both the original license and the license of
785"
LICENSES FOR EXISTING ASSETS,0.9452201933404941,"the derived asset (if it has changed) should be provided.
786"
LICENSES FOR EXISTING ASSETS,0.9462943071965628,"• If this information is not available online, the authors are encouraged to reach out to
787"
LICENSES FOR EXISTING ASSETS,0.9473684210526315,"the asset’s creators.
788"
NEW ASSETS,0.9484425349087003,"13. New Assets
789"
NEW ASSETS,0.949516648764769,"Question: Are new assets introduced in the paper well documented and is the documentation
790"
NEW ASSETS,0.9505907626208379,"provided alongside the assets?
791"
NEW ASSETS,0.9516648764769066,"Answer: [NA]
792"
NEW ASSETS,0.9527389903329753,"Justification: This paper does not release any new assets.
793"
NEW ASSETS,0.9538131041890441,"Guidelines:
794"
NEW ASSETS,0.9548872180451128,"• The answer NA means that the paper does not release new assets.
795"
NEW ASSETS,0.9559613319011815,"• Researchers should communicate the details of the dataset/code/model as part of their
796"
NEW ASSETS,0.9570354457572503,"submissions via structured templates. This includes details about training, license,
797"
NEW ASSETS,0.958109559613319,"limitations, etc.
798"
NEW ASSETS,0.9591836734693877,"• The paper should discuss whether and how consent was obtained from people whose
799"
NEW ASSETS,0.9602577873254565,"asset is used.
800"
NEW ASSETS,0.9613319011815252,"• At submission time, remember to anonymize your assets (if applicable). You can either
801"
NEW ASSETS,0.9624060150375939,"create an anonymized URL or include an anonymized zip file.
802"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9634801288936627,"14. Crowdsourcing and Research with Human Subjects
803"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9645542427497314,"Question: For crowdsourcing experiments and research with human subjects, does the paper
804"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9656283566058003,"include the full text of instructions given to participants and screenshots, if applicable, as
805"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.966702470461869,"well as details about compensation (if any)?
806"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9677765843179377,"Answer: [NA]
807"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9688506981740065,"Justification: This paper does not involve human subjects.
808"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9699248120300752,"Guidelines:
809"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9709989258861439,"• The answer NA means that the paper does not involve crowdsourcing nor research with
810"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9720730397422127,"human subjects.
811"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9731471535982814,"• Including this information in the supplemental material is fine, but if the main contribu-
812"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9742212674543501,"tion of the paper involves human subjects, then as much detail as possible should be
813"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9752953813104189,"included in the main paper.
814"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9763694951664876,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
815"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9774436090225563,"or other labor should be paid at least the minimum wage in the country of the data
816"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9785177228786252,"collector.
817"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9795918367346939,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
818"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9806659505907627,"Subjects
819"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9817400644468314,"Question: Does the paper describe potential risks incurred by study participants, whether
820"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9828141783029001,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
821"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9838882921589689,"approvals (or an equivalent approval/review based on the requirements of your country or
822"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9849624060150376,"institution) were obtained?
823"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9860365198711063,"Answer: [NA]
824"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9871106337271751,"Justification: This paper does not involve human subjects.
825"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9881847475832438,"Guidelines:
826"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9892588614393125,"• The answer NA means that the paper does not involve crowdsourcing nor research with
827"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9903329752953813,"human subjects.
828"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.99140708915145,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
829"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9924812030075187,"may be required for any human subjects research. If you obtained IRB approval, you
830"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9935553168635876,"should clearly state this in the paper.
831"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9946294307196563,"• We recognize that the procedures for this may vary significantly between institutions
832"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9957035445757251,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
833"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9967776584317938,"guidelines for their institution.
834"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9978517722878625,"• For initial submissions, do not include any information that would break anonymity (if
835"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9989258861439313,"applicable), such as the institution conducting the review.
836"
