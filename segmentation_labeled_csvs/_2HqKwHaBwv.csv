Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0023094688221709007,"We introduce graph-time convolutional autoencoder (GTConvAE), a novel spa-
tiotemporal architecture tailored to unsupervised learning for multivariate time
series on networks. The GTConvAE leverages product graphs to represent the
time series and a principled joint spatiotemporal convolution over this product
graph. Instead of ﬁxing the product graph at the outset, we make it parametric
to attend to the spatiotemporal coupling for the task at hand. On top of this, we
propose temporal downsampling for the encoder to improve the spatiotemporal
receptive ﬁeld without affecting the network structure; respectively, in the decoder,
we consider the opposite upsampling operator. We prove that the GTConvAEs
with graph integral Lipschitz ﬁlters are stable to relative network perturbations,
ultimately showing the role of the different components in the encoder and decoder.
Numerical experiments for denoising and anomaly detection in solar and water net-
works corroborate our ﬁndings and showcase the effectiveness of the GTConvAE
compared with state-of-the-art alternatives."
INTRODUCTION,0.004618937644341801,"1
Introduction"
INTRODUCTION,0.006928406466512702,"Learning unsupervised representations from spatiotemporal network data is commonly encountered in
multivariate data denoising [1], anomaly detection [2], missing data imputation [3], and forecasting [4,
5], to name just a few application areas. The challenge is to develop models that jointly capture the
spatiotemporal dependencies in a computation- and data-efﬁcient manner yet being tractable so that
to understand the role played by the network structure and the dynamics over it. The autoencoder
family of functions is of interest in this setting, but vanilla spatiotemporal forms [6–8] that ignore
the network structure suffer the well-known curse of dimensionality and lack inductive learning
capabilities [9]."
INTRODUCTION,0.009237875288683603,"Upon leveraging the network as an inductive bias [10], graph-time autoencoders have been recently
developed. These approaches are typically composed of two interleaving modules: one capturing
the spatial dependencies via graph neural networks (GNNs) [11] and one capturing the temporal
dependencies via temporal CNN or LSTM networks. For example, the work in [1] uses an edge-
varying GNN [12] followed by a temporal convolution for motion denoising. The work in [13]
considers LSTMs and graph convolutions for variational spatiotemporal autoencoders, which have
been further investigated in [3, 14], respectively, for spatiotemporal data imputation as a graph-
based matrix completion problem and dynamic topologies. Graph-time autoencoders over dynamic
topologies have also been investigated in [15, 16]. Lastly, [4] embeds the temporal information into
the edges of a graph and develops an autoencoder over this graph for forecasting purposes."
INTRODUCTION,0.011547344110854504,"By working disjointly ﬁrst on the graph and then on the temporal dimension of the graph embeddings,
these approaches fail to capture the joint spatiotemporal dependencies present in the raw data. It is
also challenging to analyze their theoretical properties and to attribute to what extent the beneﬁt comes
from one module over the other. These aspects have been investigated for supervised spatiotemporal
learning via GNNs [17–23] but not for autoencoders. The two works elaborating on spatiotemporal
autoencoders are [2] and [24]. The work in [2] replicates the graph over time via the Cartesian product
principle [25] and uses an order one graph convolution [26] to learn spatiotemporal embeddings that"
INTRODUCTION,0.013856812933025405,Graph-Time Convolutional Autoencoders A
INTRODUCTION,0.016166281755196306,"C
S⋄
S⋄ +
+
+ x⋄"
INTRODUCTION,0.018475750577367205,"S1
⋄x⋄
S2
⋄x⋄"
INTRODUCTION,0.020785219399538105,"h0
h1
h2 y⋄ B"
INTRODUCTION,0.023094688221709007,He(S⋄)
INTRODUCTION,0.025404157043879907,Downsampling
INTRODUCTION,0.02771362586605081,"σ(·)
Upsampling"
INTRODUCTION,0.03002309468822171,Hd(S⋄) σ(·) x⋄ Z⋄
INTRODUCTION,0.03233256351039261,"ˆx⋄
ENC
DEC"
INTRODUCTION,0.03464203233256351,"Figure 1: Graph-time convolution autoencoder components. (A) Parametric product graph represen-
tation of time series [cf. (1)]: red edges represent spatial connections and are related to s01, green
and gray edges represent temporal connections and are ruled by s10 and s11, respectively. (B) A
single layer GTConvAE. The encoder and decoder are mirrored versions of each other containing: i)
a graph convolutional ﬁlter H(S⋄) [cf. (2)] operating w.r.t. the product graph shift operator S⋄for
the time series x⋄; ii) a temporal downsampling [cf. (4)] respectively upsampling [cf. (8)] module;
and iii) a pointwise nonlinearity σ(·). (C) A second order graph-time convolutional ﬁlter. The shifted
variants of input x⋄are linearly combined with weights h0, h1, h2 to generate the ﬁltred output y⋄."
INTRODUCTION,0.03695150115473441,"are fed into an LSTM module to improve the temporal memory, ultimately giving more importance
to the temporal dimension of the latent representation. Differently, [27] proposed a variational
graph-time autoencoder that its encoder is based on [18] and its decoder is a multi-layer perceptron;
hence, being suitable only for topological tasks such as dynamic link prediction but not for tasks
concerning time series over networks such as denoising or anomaly detection."
INTRODUCTION,0.03926096997690531,"In this paper, we propose a GTConvAE that, differently from [2], captures jointly the spatiotemporal
coupling both in the raw data and the intermediate higher-level representations. The GTConvAE
operates over a parametric product graph [28] to attend to the spatiotemporal coupling for the task
at hand rather than ﬁxing it at the outset. Differently from [18], the GTConvAE has a symmetric
structure with graph-time convolutions in both encoder and decoder, making it suitable for tasks
concerning network time series. We also study the capability of the GTConvAE to transfer learning
across different networks, which is of importance as practical topologies differ from the models used
during training (e.g., because of model uncertainness, perturbations, or dynamics). The latter has
been studied for traditional [29–31] and graph-time GNN models [21, 28, 32] but not for graph-time
autoencoders."
INTRODUCTION,0.04157043879907621,"Our contribution in this paper is twofold. First, we propose a symmetric graph-time convolutional
autoencoder that jointly captures the spatiotemporal coupling in the data suited for tasks concerning
multivariate time series over networks. The GTConvAE represents the time series as a graph signal
over product graphs and uses the latter as an inductive bias to learn unsupervised representations.
The product graph is parametric to attend to the coupling for the speciﬁc task, and it generalizes
the popular choices of product graphs [33]. We also propose a temporal downsampling/upsampling
in the encoder/decoder to increase the spatiotemporal receptive ﬁeld without affecting the network
structure; hence, preserving the inductive bias. Second, we prove GTConvAE is stable to relative
perturbations on the spatial graph; highlighting the role played by the encoder, decoder, parametric
product graph, convolutional ﬁlters, and downsampling/upsampling rate. Numerical experiments
about denoising and anomaly detection over solar and water networks corroborate our ﬁndings and
show a competitive performance compared with the more involved state-of-the-art alternatives."
INTRODUCTION,0.04387990762124711,"The rest of this paper is organized as follows. Section 2 formulates the GTConvAE model and
Section 3 analyzes its theoretical properties. Numerical experiments are presented in Section 4 and
conclusions in Section 5. The proofs are collected in the appendix."
INTRODUCTION,0.046189376443418015,Graph-Time Convolutional Autoencoders
IMPLEMENTATION/METHODS,0.04849884526558892,"2
Graph-Time Convolutional Autoencoders"
IMPLEMENTATION/METHODS,0.050808314087759814,"GTconvAE learns representations from N−dimensional multivariate time series xt ∈RN, t =
1, . . . , T, collected in matrix X ∈RN×T . These time series have a spatial network structure
represented by a graph G = (V, E) composed of N nodes V = {v1, . . . , vN} and M edges. The
n-th row of X contains the time series xn = [x1(n), . . . , xT (n)]⊤on node vn and the t-th column a
graph signal xt = [xt(1), . . . , xt(N)]⊤at timestamp t [34, 35]. For example, the time series could
be nodal pressures measured over junction nodes in a water distribution network, while the pipe
connections rule the spatial structure. The representations learned from the tuple {G, X} can then be
used, among others, for anomaly detection [6], denoising dynamic data over graphs [1], and missing
data completion [3]."
IMPLEMENTATION/METHODS,0.053117782909930716,"The GTconvAE follows the standard encoder-decoder structure [36], but in each module, it jointly
captures the spatiotemporal dependencies in the data. We denote the GTconvAE as"
IMPLEMENTATION/METHODS,0.05542725173210162,"ˆX = GTConvAE(X, G; H) := DEC

Z := ENC(X, G; He), G; Hd
"
IMPLEMENTATION/METHODS,0.057736720554272515,"where the encoder ENC(·, ·; He) and decoder DEC

·, ·; Hd

are non-linear parametric functions and
where set H = He ∪Hd collects all parameters. The encoder takes as input the graph G and the time
series X and produces higher-level representations Z ∈RN×Te. These representations are built in
a layered manner where each layer comprises: i) a joint graph-time convolutional ﬁlter to capture
the spatiotemporal dependencies in a principled manner; ii) a temporal downsampling module to
increase the receptive ﬁeld without affecting the network structure; and iii) a pointwise nonlinearity
to have more complex representations. The decoder has a mirrored structure w.r.t. the encoder by
taking as input Z and outputting an estimate of the input ˆX. The model parameters are estimated
end-to-end by minimizing a spatiotemporal regularized reconstruction loss L(X, ˆX, G, H)."
IMPLEMENTATION/METHODS,0.06004618937644342,"2.1
Product Graph Representation of Network Time Series"
IMPLEMENTATION/METHODS,0.06235565819861432,"GTConvAE uses product graphs to represent the spatiotemporal dependencies in X [25]. Product
graphs have been proven successful for processing multivariate time series, such as imputing missing
values [37, 38], denoising [39], providing a spatiotemporal Fourier analysis [35], as well as building
vector autoregressive models [40], spatiotemporal scattering transforms [41], and graph-time neural
networks [28]. Speciﬁcally, denote by S ∈RN×N the graph shift operator (GSO) of the spatial graph
G, e.g., adjacency, Laplacian. Consider also a temporal graph GT = (VT , ET , ST ), where the node
set VT = {1, . . . , T} comprises the discrete-time instants, the edge set ET ⊆VT × VT captures the
temporal dependencies; e.g., a directed line or a cyclic graph, and ST ∈RN×N is the respective
GSO [42, 43]. The time series xn now can be deﬁned as a graph signal over temporal graph ST
where xt(n) is a scalar value assigned to the t-th node of GT ."
IMPLEMENTATION/METHODS,0.06466512702078522,"The product graph representing the spatiotemporal patterns in X is denoted by G⋄= GT ⋄G =
(V⋄, E⋄, S⋄). The node set V⋄is the Cartesian product between VT and V which leads to NT
distinct spatiotemporal nodes i⋄= (n, t). The edge set E⋄connects these nodes and the GSO
S⋄∈RNT ×NT is dictated by the product graph. Fixing the product graph implies ﬁxing the
spatiotemporal dependencies in the data, which may lead to wrong inductive biases. To avoid this
and improve ﬂexibility, we consider a parametric product graph whose GSO is of the form S⋄="
IMPLEMENTATION/METHODS,0.06697459584295612,"1
X i=0"
IMPLEMENTATION/METHODS,0.06928406466512702,"1
X"
IMPLEMENTATION/METHODS,0.07159353348729793,"j=0
sij(Si
T ⊗Sj) = s00IT ⊗IN
|
{z
}
self-loops
+ s01IT ⊗S + s10ST ⊗IN
|
{z
}
Cartesian
+ s11ST ⊗S
|
{z
}
Kronecker
|
{z
}
Strong ,
(1)"
IMPLEMENTATION/METHODS,0.07390300230946882,"where the scalar parameters {sij} attend the spatiotemporal connections and encompass the typical
product graph choices such as the Kronecker, the Cartesian, and the strong product. By column-
vectorizing X into x⋄= vec(X) ∈RNT , we obtain a product graph signal assigning a real value to
each spacetime node i⋄. i.e., the dynamic data xt over G is now a static signal x⋄over the product
graph G⋄."
IMPLEMENTATION/METHODS,0.07621247113163972,"2.2
Encoder"
IMPLEMENTATION/METHODS,0.07852193995381063,"The encoder is an Le-layered architecture in which each layer comprises a bank of product graph
convolutional ﬁlters, temporal downsampling, and pointwise nonlinearities."
IMPLEMENTATION/METHODS,0.08083140877598152,Graph-Time Convolutional Autoencoders
IMPLEMENTATION/METHODS,0.08314087759815242,"GTConv ﬁlter captures the spatiotemporal patterns in the data matrix X. Given the parametric
product graph representation G⋄= (V⋄, E⋄, S⋄) [cf. (1)] and the product graph signal x⋄= vec(X)
as input, the output of a graph-time convolutional ﬁlter of order K is"
IMPLEMENTATION/METHODS,0.08545034642032333,"y⋄= H(S⋄)x⋄= K
X"
IMPLEMENTATION/METHODS,0.08775981524249422,"k=0
hkSk
⋄x⋄
(2)"
IMPLEMENTATION/METHODS,0.09006928406466513,"where h = [h0, . . . , hK]⊤are the ﬁlter parameters and H(S⋄) := PK
k=0 hkSk
⋄is the ﬁltering matrix.
The ﬁlter in (2) is called convolutional as the output y⋄is a weighted linear combination of shifted
graph signals over the product graph up to K times [44]. Hence, the ﬁlter is spatiotemporally local in
a neighborhood of radius K. The ﬁlter locality does not only depend on the order K but also on the
type of product graph. For example, for a ﬁxed K, the Cartesian product is more localized than the
strong product, which can be considered to have a longer spatiotemporal memory [28]. Consequently,
learning parameters {sij} in (1) implies learning the multi-hop resolution radius."
IMPLEMENTATION/METHODS,0.09237875288683603,"In the ℓ−th layer, the encoder has Fℓ−1 product graph signal features x1
⋄,ℓ−1, . . . , xg
⋄,ℓ−1, . . . xFℓ−1
⋄,ℓ−1,
processes these with a bank of FℓFℓ−1 ﬁlters and outputs Fℓproduct graph signal features as"
IMPLEMENTATION/METHODS,0.09468822170900693,"yf
⋄,ℓ="
IMPLEMENTATION/METHODS,0.09699769053117784,"Fℓ−1
X"
IMPLEMENTATION/METHODS,0.09930715935334873,"g=1
Hfg(S⋄)xg
⋄,ℓ−1,
f = 1, . . . Fℓ,
(3)"
IMPLEMENTATION/METHODS,0.10161662817551963,which are the higher-level linear representation of the layer.
IMPLEMENTATION/METHODS,0.10392609699769054,"Temporal downsampling reduces the temporal dimension in each output {yf
⋄,ℓ}f in (3) by down-
sampling the latter along the temporal dimension with a rate r. More speciﬁcally, we ﬁrst transform
the f−th output yf
⋄,ℓ∈RNT e
ℓ−1 into a matrix Yf
1 = vec−1(yf
⋄,1) ∈RN×T e
ℓ−1 and then summarize"
IMPLEMENTATION/METHODS,0.10623556581986143,"every r consecutive columns without overlap to obtain the downsampled matrix Xf
d,ℓ∈RNT e
ℓwith"
IMPLEMENTATION/METHODS,0.10854503464203233,"T e
ℓ< T e
ℓ−1. The (n, t)−th entry of Xf
d,ℓis computed as"
IMPLEMENTATION/METHODS,0.11085450346420324,"Xf
d,ℓ(n, t) = SUM

Yf
ℓ(n, r(t −1) + 1 : rt)

,
f = 1, . . . Fℓ,
(4)"
IMPLEMENTATION/METHODS,0.11316397228637413,"where SUM(·) is a summary function over the temporal indices r(t −1) + 1 to rt. This summary
function could be a simple downsampling (i.e., output the ﬁrst column in the block Yf
ℓ(n, r(t−1)+1 :
rt)) or an aggregation function (i.e., mean/max/min per spatial node)."
IMPLEMENTATION/METHODS,0.11547344110854503,"This temporal downsampling increases the encoder spatiotemporal memory without affecting the
spatial structure. I.e., nodes with the temporal indices t, rt, (r + 1)t, . . . become neighbors, which
brings in a longer memory in the next layer and increases the encoder receptive ﬁeld. Temporal skip
connections can be an alternative to increase the receptive ﬁeld, however, the downsampling reduces
the computational memory by shrinking the product graph and allows for a theoretical analysis. While
also spatial graph pooling can be added [45], we do not advocate it for two reasons. First, the spatial
graph acts as an inductive bias for the GTConvAE [10]; hence, changing the graph in the layers via
graph reduction, coarsening, or alternatives will affect the spatial structure, ultimately changing the
inductive bias. Second, the spatial graph often represents the communication channels for distributed
implementation of GTConv [21, 46, 47], and changing it may be physically impossible as sensor
nodes have a limited transmission radius. An option in the latter setting may be a zero-pad spatial
pooling [48, 49] but it requires memorizing the indices where the zero-padding is applied, which may
be challenging for large graphs."
IMPLEMENTATION/METHODS,0.11778290993071594,"Activation functions nonlinearize the downsampled features to increase the representational capacity.
We consider an entry-wise nonlinear function σ(·) such as ReLU and produce layer ℓ−th output as"
IMPLEMENTATION/METHODS,0.12009237875288684,"Xf
ℓ+1 = σ(Xf
d,ℓ),
f = 1, . . . Fℓ.
(5)"
IMPLEMENTATION/METHODS,0.12240184757505773,The encoder performs operations (3)-(4)-(5) for all the Le layers to yield the encoded output
IMPLEMENTATION/METHODS,0.12471131639722864,"Z⋄:= X⋄,L = ENC(x⋄,0, S, ST ; He, s),
(6)"
IMPLEMENTATION/METHODS,0.12702078521939955,"where x⋄,0 := x⋄∈RNT , Z⋄= [z1
⋄, . . . , zFL
⋄] ∈RNTLe×FL, and we made explicit the dependence
from the product graph parameters s = [s00, s01, s10, s11]⊤[cf. (1)]."
IMPLEMENTATION/METHODS,0.12933025404157045,Graph-Time Convolutional Autoencoders
IMPLEMENTATION/METHODS,0.13163972286374134,"2.3
Decoder"
IMPLEMENTATION/METHODS,0.13394919168591224,"Mirroring the encoder, the decoder reconstructs the input from the latent representations in (6). At the
generic layer ℓ, graph-time convolutional ﬁltering is performed, subsequently a temporal upsampling,
and a pointwise nonlinearity."
IMPLEMENTATION/METHODS,0.13625866050808313,"GTConv ﬁltering decodes the spatiotemporal latent representations from the encoder. Considering
again Fℓ−1 input features z1
⋄,ℓ−1, . . . , zg
⋄,ℓ−1, . . . , zFℓ−1
⋄,ℓ−1 and a ﬁlter bank of FℓFℓ−1 GTConv ﬁlters
as per (2), the outputs are"
IMPLEMENTATION/METHODS,0.13856812933025403,"yf
⋄,ℓ="
IMPLEMENTATION/METHODS,0.14087759815242495,"Fℓ−1
X"
IMPLEMENTATION/METHODS,0.14318706697459585,"g=1
Hfg(S⋄)zg
⋄,ℓ−1,
f = 1, . . . Fℓ.
(7)"
IMPLEMENTATION/METHODS,0.14549653579676675,"Upsampling zero-pads the removed temporal values during downsampling [cf. (4)] so that the ﬁnal
GTConvAE output matches the dimension of X. Speciﬁcally, given the f−th feature yf
⋄,ℓ∈RNT d
ℓ−1"
IMPLEMENTATION/METHODS,0.14780600461893764,"from (7), we again transform it into a matrix Yf
1 = vec−1(yf
⋄,1) ∈RN×T d
ℓ−1 and obtain the"
IMPLEMENTATION/METHODS,0.15011547344110854,"upsampled matrix Zf
u,ℓ∈RN×T d
ℓwhose (n, t)−th entry is computed as"
IMPLEMENTATION/METHODS,0.15242494226327943,"Zf
u,ℓ(n, t) ="
IMPLEMENTATION/METHODS,0.15473441108545036,"(
Yf
ℓ(n, ⌈t/r⌉);
if
∃k ∈Z : t = kr
0;
o/w
(8)"
IMPLEMENTATION/METHODS,0.15704387990762125,"where ⌈·⌉is the ceiling function.1 The GTConv ﬁlter bank in the next layer interpolates these
zero-padded values from the downsampled ones. This implies that the downsampling rate in the
encoder cannot be too harsh to lose information, and also, the ﬁlter orders in the decoder cannot be
too small to have a high interpolatory capacity."
IMPLEMENTATION/METHODS,0.15935334872979215,Activation functions again nonlinzearize the upsampled features in (8) and yield
IMPLEMENTATION/METHODS,0.16166281755196305,"Zf
ℓ= σ(Zf
u,ℓ),
f = 1, . . . Fℓ.
(9)"
IMPLEMENTATION/METHODS,0.16397228637413394,"The decoder performs operations (7)-(8)-(9) for all Ld layers to yield the decoded output ˆx⋄=
z⋄,Ld ∈RNT , which also corresponds to the GTConvAE output
ˆx⋄= z⋄,Ld = DEC(Z⋄, S, ST ; Hd, s),
(10)
where we match the dimensions by setting FLd = 1."
IMPLEMENTATION/METHODS,0.16628175519630484,"2.4
Loss Function"
IMPLEMENTATION/METHODS,0.16859122401847576,"Given (6) and (10), the GTConvAE in (1) can be detailed as
ˆx⋄= GTConvAE(x⋄, S, ST ; H, s) = DEC

ENC(x⋄, S, ST ; He, s), S, ST ; Hd, s

.
(11)
The GTConv ﬁlter parameters in H and the product graph parameters in s are estimated by minimizing
the loss function
L(X, ˆX, G, H) = ED [∥x⋄−ˆx⋄∥2] + ρ∥s∥1.
(12)
where the ﬁrst term measures the reconstruction error over the probabilistic distribution D of the
training set, whereas the second term imposes sparsity in the spatiotemporal dependencies of the
product graph. Scalar ρ > 0 controls the trade-off between ﬁtting and regularization, and a higher
value implies a stronger spatiotemporal sparsity (from the norm one ∥·∥1); i.e., sparser spatiotemporal
attention."
IMPLEMENTATION/METHODS,0.17090069284064666,"Complexity analysis: Denoting the maximum number of features in all layers by Fmax = max{Fℓ}
the GTConvAE has |H| = (Le + Ld)(K + 1)F 2
max parameters. This is because each GTConv ﬁlter
(2) has K + 1 parameters and in each layer a ﬁlter bank of at most F 2
max ﬁlters is used. Despite the
product graphs are of large dimensions, the latter is highly sparse and the computation complexity of
the GTConvAE is of order O(M⋄|H|), where M⋄= NT + NMT + MT + 2MMT is the number
of edges of the product graph (M edges in the spatial graph and MT edges in the temporal graph).
This is because each graph-time ﬁlter has a computational complexity of order O((K + 1)M⋄) [28]
and the GTConvAE consists of (Le + Ld)F 2
max graph-time ﬁlters. We consider r = 1 sampling rate
to provide the worst case analysis, but the computational complexity reduces further for r > 1."
IMPLEMENTATION/METHODS,0.17321016166281755,"1We considered the same down/up-sampling rate in each layer of the decoder and encoder; hence, because of
the mirrored structure T e
ℓin (5) equals T d
ℓ−1 in (8)."
IMPLEMENTATION/METHODS,0.17551963048498845,Graph-Time Convolutional Autoencoders
IMPLEMENTATION/METHODS,0.17782909930715934,"3
Stability Analysis"
IMPLEMENTATION/METHODS,0.18013856812933027,"In this section, we conduct a stability analysis of the GTConvAE w.r.t. relative perturbations in the
spatial graph. This stability analysis is motivated by the fact that we do not always have access to
the ground truth spatial graph due to modeling issues or when the physical network undergoes slight
changes over time. Hence, the spatial graph used for training differs from that used for testing; thus,
having a stable GTConvAE is desirable to perform the tasks reliably."
IMPLEMENTATION/METHODS,0.18244803695150116,"We consider the relative perturbation model
ˆS = S + (SE + ES)
(13)"
IMPLEMENTATION/METHODS,0.18475750577367206,"where ˆS is the perturbed GSO and E is the perturbation matrix with bounded operator norm
∥E∥≤ϵ [29]. This model accounts for graph perturbation depending on its structure, i.e., a higher
degree node (a node with higher-weighted connected edges) is relatively prone to more perturbation."
IMPLEMENTATION/METHODS,0.18706697459584296,"3.1
Spatiotemporal integral Lipschitz ﬁlters"
IMPLEMENTATION/METHODS,0.18937644341801385,"To investigate the stability of GTConvAE, we ﬁrst characterize the graph-time convolutional ﬁlters
in the spectral domain. Consider the eigendecompositions of the spatial GSO S = VΛVH and of
the temporal GSO ST = VT ΛT VH
T . Matrices V = [v1, . . . , vN]⊤and VT = [vT,1, . . . , vT,T ]⊤
collect the spatial and the temporal eigenvectors, respectively, and Λ = diag(λ1, . . . , λN) and
ΛT = diag(λT,1, . . . , λT,T ) the corresponding eigenvalues. From (1), the eigendecomposition of
the product graph GSO is S⋄= V⋄Λ⋄VH
⋄with eigenvectors V⋄= VT ⊗V being the Kronecker
product ⊗of the respective GSOs and the eigenvalues Λ⋄= ΛT ⋄Λ are deﬁned by the product graph
rule. As in graph signal processing [34], it is possible to characterize the joint graph-time Fourier
transform of product graph signals. Speciﬁcally, the graph-time Fourier transform of signal x⋄is
deﬁned as ˜x = (VT ⊗V)Hx⋄and the eigenvalues in Λ⋄now collect the graph-time frequencies of
the product graph [35]. Applying this Fourier transform on the input and output of the GTConv ﬁlter
in (2), we can write the ﬁlter input-output as ˜y⋄= H(Λ⋄)˜y, where ˜y⋄is the Fourier transform of the
output and H(Λ⋄) is an NT × NT diagonal matrix containing the ﬁlter frequency response on the
main diagonal. This frequency response is of the form"
IMPLEMENTATION/METHODS,0.19168591224018475,"h(λ⋄,(n,t)) = K
X"
IMPLEMENTATION/METHODS,0.19399538106235567,"k=0
hkλk
⋄,(n,t)
(14)"
IMPLEMENTATION/METHODS,0.19630484988452657,"where λ⋄,(n,t) = λT,t ⋄λn indicates the eigenvalue of S⋄corresponding to the spatial index n ∈[N]
and temporal index t ∈[T] of the product graph."
IMPLEMENTATION/METHODS,0.19861431870669746,"The eigenvalues λ⋄,(n,t) can be considered as the frequencies of the product graph and can be ordered
in ascending order of magnitude. We can then characterize the variation of the ﬁlter frequency
response for two different spatial eigenvalues.
Deﬁnition 1. A GTConv ﬁlter with a frequency response h(λ⋄,(n,t)) is graph integral Lipschitz if
there exists constant C > 0 such that for all frequencies λ⋄,(n,t), λ⋄,(n′,t′) ∈Λ⋄, it holds that"
IMPLEMENTATION/METHODS,0.20092378752886836,"|h(λ⋄,(n,t)) −h(λ⋄,(n′,t′))| ≤C |λn −λn′|"
IMPLEMENTATION/METHODS,0.20323325635103925,"|λn + λn′|/2
for all
{λn, λn′} ∈Λ.
(15)"
IMPLEMENTATION/METHODS,0.20554272517321015,"Expression (15) states that the frequency response of a GTConv ﬁlter should vary sub-linearly while
the Lipschitz coefﬁcient C depends on the gap |λ⋄,(n,t) + λ⋄,(n′,t′)|/2. This implies
λn
∂h(λ⋄,(n,t)) ∂λn"
IMPLEMENTATION/METHODS,0.20785219399538107,"≤C
for all
λn ∈Λ
and
λ⋄,(n,t) ∈Λ⋄
(16)"
IMPLEMENTATION/METHODS,0.21016166281755197,"which means the integral Lipschitz ﬁlter cannot vary drastically in high graph frequencies. Hence,
such a ﬁlter can discriminate low frequency content but not high frequency ones.
Deﬁnition 2. A GTConv ﬁlter has normalized frequency response if |h(λ⋄,(n,t))| ≤1 for all λ⋄,(n,t)."
IMPLEMENTATION/METHODS,0.21247113163972287,"This deﬁnition is a direct consequence of normalizing the ﬁlters’ frequency response by their
maximum value. We shall show next that GTConvAE with ﬁlters satisfying Def. 1 and 2 are stable to
perturbations in the form (13)."
IMPLEMENTATION/METHODS,0.21478060046189376,Graph-Time Convolutional Autoencoders
IMPLEMENTATION/METHODS,0.21709006928406466,"3.2
Stability result"
IMPLEMENTATION/METHODS,0.21939953810623555,"The following theorem with proof in Appendix A provides the main result.
Theorem 1. Consider a GTConvAE with an Le-layer encoder and an Ld-layer decoder having
Fℓ≤Fmax and Fd,ℓ≤Fmax features per layer in encoder and decoder, respectively, and a summary
function SUM(·) performing pure downsampling with rate r. Consider also the ﬁlters are integral
Lipschitz [cf. Def. 1] with a normalized frequency response [cf. Def. 2] and that the nonlinearities
are 1−Lipschitz (e.g., ReLU, absolute value). Let this GTConvAE be trained over the product graph
(1) and deployed over its perturbed version whose spatial GSO is given in (13) with a perturbation of
at most ∥E∥≤ϵ. The distance between the two models is upper bounded by"
IMPLEMENTATION/METHODS,0.22170900692840648,"∥GTConvAE(x⋄, S, ST ) −GTConvAE(x⋄, ˆS, ST )∥2 ≤(Ld + Le)r−Le/2ϵ∆F Le+Ld−1
max
∥x⋄∥2.
(17)
where ∆= 2C(s01 + s11λT,max)(1 + δ
√"
IMPLEMENTATION/METHODS,0.22401847575057737,"NT), and δ = (∥U −V∥2 + 1)2 −1 with eigenvectors
U from E = UMUH and V from S = VΛVH."
IMPLEMENTATION/METHODS,0.22632794457274827,"The result (17) states that GTConvAE is stable against relative perturbations. It also suggests that
GTConvAE is less stable for larger product graphs (
√"
IMPLEMENTATION/METHODS,0.22863741339491916,"NT) since more nodes pass information over
the perturbed edges. Moreover, making the model more complex by increasing the number of features
or layers compromises stability as more graph-time convolutional ﬁlters work on a perturbed graph
(F Le+Ld−1
max
). We also see the stability improves with the sampling rate r > 1 because fewer nodes
operate over the perturbed graph after downsampling. Furthermore, for a deeper encoder we have
more downsampling hence the stability improves; yet there is a tradeoff between improving the bound
imposed by the terms r−Le/2, F Le+Ld−1
max
, and Le + Ld. Finally, parameters s01 and s11 appear in
the stability bound because they are the only ones composing the spatial edges; thus, minimizing
∥s∥1 in (12) leads to improved stability."
RESULTS/EXPERIMENTS,0.23094688221709006,"4
Numerical Results"
RESULTS/EXPERIMENTS,0.23325635103926096,"This section compares the GTConvAE with baseline solutions and competitive alternatives for time
series denoising as well as anomaly detection with real data from solar irradiance and water networks.
In all experiments, the ADAM optimizer with the standard hyperparameters is used and an unweighted
directed line graph is considered for the temporal graph in (1)."
RESULTS/EXPERIMENTS,0.23556581986143188,"4.1
Denoising of solar irradiance time series"
RESULTS/EXPERIMENTS,0.23787528868360278,"Figure 2: Denoising performance of the proposed
GTConvAE and alternatives. The standard devia-
tion for all the models is of order 10−2."
RESULTS/EXPERIMENTS,0.24018475750577367,"We consider the task of denoising solar irradi-
ance time series over N = 75 solar stations
around the northern region of the U.S. measured
in GHI (W/m2) [4]. Each solar station is a ver-
tex and an undirected edge is set using the phys-
ical distances between the stations via Gaussian
threshold kernel with σ = 0.25 and th = 0.1 af-
ter normalizing maximum weight to 1 [34]. The
noise is generated via a zero-mean Gaussian dis-
tribution with a covariance matrix corresponding
to the pseudo-inverse of the normalized graph
Laplacian. More information about the noise
model is provided in Appendix B."
RESULTS/EXPERIMENTS,0.24249422632794457,"Experimental setup. We considered the ﬁrst
2000 samples for training and validation (2000-
2014) and the subsequent 200 (2014-2016) for testing. The input data is a single feature corresponding
to the GHI measurement and the product graph has N = 75 spatial nodes and T = 8 temporal nodes.
The GTConvAE has three layers with {8, 4, 2} features in the encoder and reversely in the decoder;
all ﬁlters are 4th-order and normalized Laplacian is used as GSO; a downsampling rate of r = 2; a
max function in (4); and ReLU activation functions. The regularizer weight in (12) is ρ = 0.2 and
the learning rate is 25 × 10−4. We compared the GTConvAE with the following alternatives:"
RESULTS/EXPERIMENTS,0.24480369515011546,• C3D [6]: non-graph spatiotemporal autoencoder using three-dimensional CNNs.
RESULTS/EXPERIMENTS,0.2471131639722864,Graph-Time Convolutional Autoencoders
RESULTS/EXPERIMENTS,0.24942263279445728,"• ConvLSTMAE [8]: A non-graph spatiotemporal autoencoder using two-dimensional CNNs
followed by LSTMs.
• STGAE [1]: A modular spatiotemporal graph autoencoder that uses an edge varying ﬁlter for
the graph dimension followed by temporal convolution.
• Baseline GCNN [46]: An autoencoder built with a conventional graph convolutional neural
network using the time series as features over the nodes. The shift operator is the normalized
Laplacian matrix."
RESULTS/EXPERIMENTS,0.2517321016166282,"The ﬁrst two methods are considered to show the role of using a distance graph as an inductive bias.
The third method is considered to compare the joint GTConvAE over disjoint alternatives, whereas
the last model is considered to show the role of the sparse product graphs rather than treating time
series as node features. The parameters for all models are chosen via grid search from the ranges
reported in Appendix B."
RESULTS/EXPERIMENTS,0.2540415704387991,"Results. Fig. 2 shows the reconstruction normalized mean squared error (NMSE) for different
signal-to-noise ratios (SNRs). The proposed GTConvAE compares well with STGAE for low SNRs
but better for high SNRs. We attribute this improvement to the ability of the GTConvAE to capture
jointly the spatiotemporal patterns in the data while STGAE operates disjointly. We also see that in
comparison with the baseline GCNN, the GTConvAE performs consistently better, highlighting the
importance of the sparser product graphs and temporal downsampling. Finally, we also observe a
superior performance compared with the non-graph alternatives C3D and ConvLSTMAE."
RESULTS/EXPERIMENTS,0.25635103926096997,"4.2
Anomaly detection in water networks"
RESULTS/EXPERIMENTS,0.2586605080831409,"We now consider the task of detecting cyber-physical attacks on a water network. We considered the
C-town network from the Battle of ATtack Detection ALgorithms (BATADAL) dataset comprising
N = 388 nodes (demand junctions, storage tanks, and reservoirs) and 8762 hourly measurements
of 43 different node feature signals for a period of 12 months. We used the same setup as in [50]
and considered a correlation graph from the data. The dataset provides a normal operating condition
comprising recordings for the ﬁrst 12 months and an anomalous event operating condition comprising
7 attacks over the successive 3 months. Refer to [51, 52] for more detail about the BATADAL dataset."
RESULTS/EXPERIMENTS,0.26096997690531176,"Experimental setup. The normal operating condition data are used to train the model for one-step
forecasting to be used for detecting anomalies. The anomalous event operating condition data are
used for testing and an anomaly is ﬂagged if the prediction error exceeds a threshold. We set the
threshold intuitively to three times the error variance during training. The inputs are the 43 time
series over the N = 388 nodes and we considered T = 6 for the temporal graph dimension. The
GTConvAE has two layers with {8, 2} features in the encoder and reversely in the decoder; all
ﬁlters are of order K = 4; a downsampling rate r = 2; a max function in (4); and ReLU activation
functions. The regularizer weight in (12) is ρ = 0.14 and learning rate is 5 × 10−4. We compared
the performance against two graph-based alternatives:"
RESULTS/EXPERIMENTS,0.2632794457274827,"• STGCAE-LSTM [2]: A related solution to our method that uses a Cartesian spatiotemporal graph
with graph convolutions followed by an LSTM in the latent domain.
• TGCN [50]: A modular graph-based autoencoder using cascades of temporal convolutions and
message passing."
RESULTS/EXPERIMENTS,0.26558891454965355,"The parameters for all models are obtained via grid search from the ranges reported in Appendix C.
We measure the performance via the S-score present in the BATADAL dataset, which contains STTD
for the timing in detecting anomalies and SCM for the classiﬁcation accuracy. The S-score is"
RESULTS/EXPERIMENTS,0.2678983833718245,S = 0.5(STTD + SCM) = 0.5 
RESULTS/EXPERIMENTS,0.2702078521939954,"(1 −
1
NA NA
X i=1 TTDi"
RESULTS/EXPERIMENTS,0.27251732101616627,"∆Ti
) + TPR+TNR 2 !"
RESULTS/EXPERIMENTS,0.2748267898383372,",
(18)"
RESULTS/EXPERIMENTS,0.27713625866050806,"where NA is the number of attacks, TTD is the detection time of the attack, ∆Ti is the duration of
the i−th attack, TPR is the true positive rate, and TNR is the true negative rate."
RESULTS/EXPERIMENTS,0.279445727482679,"Results: Table 1 shows that all the models managed to detect all of the attacks, however, the TGCN
has a better performance in timing STTD. This is due to the calibration of the threshold in their work
with a validation dataset while we used a ﬁxed intuitive threshold only based on training. In the"
RESULTS/EXPERIMENTS,0.2817551963048499,Graph-Time Convolutional Autoencoders
RESULTS/EXPERIMENTS,0.2840646651270208,"Table 1: Comparison of different models in the BATADAL dataset. All metrics are the higher the
better."
RESULTS/EXPERIMENTS,0.2863741339491917,"Model
NA
S
STTD
SCM
TPR
TNR"
RESULTS/EXPERIMENTS,0.28868360277136257,"STGCAE-LSTM [2]
7
0.924
0.920
0.928
0.892
0.964"
RESULTS/EXPERIMENTS,0.2909930715935335,"TGCN [50]
7
0.931
0.934
0.928
0.885
0.971"
RESULTS/EXPERIMENTS,0.29330254041570436,"GTConvAE (ours)
7
0.940
0.928
0.952
0.922
0.981"
RESULTS/EXPERIMENTS,0.2956120092378753,"(a)
(b)
(c)"
RESULTS/EXPERIMENTS,0.2979214780600462,"Figure 3: Stability results for different scenarios of the GTConvAE and ﬁxed product graphs. (a)
Different SNRs in the topology. (b) Different graph sizes in 4dB perturbation. (c) Different sampling
rates r. The standard deviation for all models is of order O(10−3) and it is neglected to avoid
overcrowded plots."
RESULTS/EXPERIMENTS,0.3002309468822171,"accuracy of anomaly detection SCM, the GTConvAE outperforms the other two models as the product
graphs alongside downsampling enable it to learn spatiotemporal patterns in the data effectively.
Overall, the GTConvAE performs better than other models by a small margin."
RESULTS/EXPERIMENTS,0.302540415704388,"4.3
Stability analysis"
RESULTS/EXPERIMENTS,0.30484988452655887,"To investigate the stability of the GTConvAE, we trained the model over a synthesized dataset
so we could control all the setting such as the spatial graph size N. The graph is an undirected
stochastic block model with 5 communities among N = {50, 100, . . . , 500}. The edges are drawn
independently with probability 0.8 for nodes in the same community and 0.2 otherwise. Each data
sample is a diffused signal over the graph X = [Sx, . . . , ST x] with T = 6 and x having a random
non-zero entry. The autoencoder is used to reconstruct this data."
RESULTS/EXPERIMENTS,0.3071593533487298,"Experimental setup The model has two layers of encoder and decoder with sampling rate r = 2.
Each layer of the encoder has {8, 4} features and reversely in the decoder. All ﬁlters are of order
four and the normalized graph Laplacian is used as GSO. The activation functions are ReLU and
pure donwsampling is considered. The regularizer weight is 0.25 and learning rate is 25 × 10−3.
The model is trained over the graph with different sizes and tested with a perturbed graph following
the relative perturbation model in (13) for different SNR scenarios in the topology. We compare the
stability of the GTConvAE with learned graphs with the same autoencoder having ﬁxed Cartesian
and strong product graphs."
RESULTS/EXPERIMENTS,0.3094688221709007,"Results Fig. 3a indicates that the GTConvAE in different noisy scenarios. GTConvAE is the most
stable in medium and high SNRs as it leverages sparsity in the spatiotemporal coupling. However,
GTConvAE performance drops more rapidly in low SNR scenarios as its parameters are trained for
the data and task. Fig. 3b shows the results for reconstruction error over graphs with different sizes.
The GTConvAE is more stable than the other models, even in graphs with the larger sizes for the
same reason as before. All models loose performance similarly as the size of the graph grows. This is
consistent with the theoretical result in (17)."
RESULTS/EXPERIMENTS,0.3117782909930716,Graph-Time Convolutional Autoencoders
RESULTS/EXPERIMENTS,0.3140877598152425,"Table 2: Ablation study of GTConvAE over different tasks of denoising, anomaly detection, and data
reconstruction."
RESULTS/EXPERIMENTS,0.3163972286374134,"model
Denoising
Anomaly detection
Reconstruction
Run time"
RESULTS/EXPERIMENTS,0.3187066974595843,"(NMSE)
(S)
(NMSE)
(s/epoch)"
RESULTS/EXPERIMENTS,0.3210161662817552,"GTConvAE
0.28
0.940
0.24
177"
RESULTS/EXPERIMENTS,0.3233256351039261,"Baseline GCNN
0.36
0.889
0.35
132"
RESULTS/EXPERIMENTS,0.325635103926097,"Cartesian
0.31
0.913
0.29
169"
RESULTS/EXPERIMENTS,0.3279445727482679,"Kronecker
0.32
0.908
0.28
168"
RESULTS/EXPERIMENTS,0.3302540415704388,"Strong
0.31
0.912
0.30
194"
RESULTS/EXPERIMENTS,0.3325635103926097,"w/o Downsampling
0.30
0.915
0.25
211"
RESULTS/EXPERIMENTS,0.3348729792147806,"4.4
Ablation study"
RESULTS/EXPERIMENTS,0.3371824480369515,"To accent the role of each component in GTConvAE, an ablation study has been performed for all
previous experiments. The reduced variants of GTConvAE are:"
RESULTS/EXPERIMENTS,0.3394919168591224,"• Baseline GCNN: The product graph is removed and time series are represented as distinct
features over the nodes of spatial graph.
• Fixed GTConvAE: The product graph type is ﬁxed as Cartesian, Kronecker, and Strong product.
• without Downsampling: The downsampling module in the encoder and the upsampling module
in the decoder are eliminated."
RESULTS/EXPERIMENTS,0.3418013856812933,"The same experimental setup is considered in each application while the SNR is set to 5 dB in
denoising solar irradiance time series. The number of nodes is 250 and sampling rate is 2 for
the reconstruction task on synthetic data, and the average run time is provided over 100 different
realizations and 100 epochs per experiment. The hardware used to exploit the rune time numbers is a
GeForce RTX 3060 GPU, and the code is not optimized for a faster implementation point of view;
however, the numbers are used to better comprehend the components’ roles."
RESULTS/EXPERIMENTS,0.3441108545034642,"Table 2 presents the performed ablation study. For all the experiments, GTConvAE outperforms
Baseline GCNN due to the product graph and considering time dependencies in the data alongside
spatial dependencies. However, the performance improvement comes with increased model complex-
ity as GTConvAE deals with larger graphs while baseline GCNN beneﬁts from a parallel scheme.
It is not conclusive which ﬁxed product graph performs better as the optimum product graph may
vary depending on the task. Hence, using a parametric product graph in the model can improve the
performance, as suggested by these results. Learning through the product graph increases slightly the
model complexity compared with the Cartesian and Kronecker models. The downsampling module
does not contribute to the performance as long as the data contains smooth time series with short-term
patterns; however, it plays a role when it comes to data with longer-term patterns, such as anomaly
detection in the water networks. Moreover, it reduces the model complexity signiﬁcantly and enables
GTConvAE to engage on larger datasets."
CONCLUSION/DISCUSSION,0.3464203233256351,"5
Conclusion"
CONCLUSION/DISCUSSION,0.34872979214780603,"We introduced GTConvAE as an unsupervised model for learning representations from multivariate
time series over networks. The GTConvAE uses parametric product graphs to aggregate information
from a spatiotemporal neighborhood while it still learns spatiotemporal couplings in the product
graph. We proposed a spectral analysis for GTConvAE due to its convolutional nature which led to
stability analysis. The stability analysis states that GTConvAE is stable against relative perturbations
in the spatial graph as long as graph-time ﬁlters vary smoothly over high spatiotemporal frequencies.
Finally, numerical results showed that the GTConvAE compares well with the state-of-the-art models
on benchmark datasets and corroborated the stability results. For further researches, dynamic graphs
can be accommodated in the model where the product graph consists of dynamic spatial structures
and spatiotemporal edges to tackle more complicated real-world problems."
CONCLUSION/DISCUSSION,0.3510392609699769,Graph-Time Convolutional Autoencoders
REFERENCES,0.3533487297921478,References
REFERENCES,0.3556581986143187,"[1] Kanglei Zhou, Zhiyuan Cheng, Hubert P. H. Shum, Frederick W. B. Li, and Xiaohui Liang. Stgae:
Spatial-temporal graph auto-encoder for hand motion denoising. In 2021 IEEE International
Symposium on Mixed and Augmented Reality (ISMAR), pages 41–49, 2021. doi: 10.1109/
ISMAR52148.2021.00018. 1, 3, 8, 19"
REFERENCES,0.3579676674364896,"[2] Nanjun Li, Faliang Chang, and Chunsheng Liu. Human-related anomalous event detection
via spatial-temporal graph convolutional autoencoder with embedded long short-term memory
network. Neurocomputing, 490:482–494, 2022. ISSN 0925-2312. doi: https://doi.org/10.1016/
j.neucom.2021.12.023. 1, 2, 8, 9, 20"
REFERENCES,0.36027713625866054,"[3] Tien Huu Do, Duc Minh Nguyen, Evaggelia Tsiligianni, Angel Lopez Aguirre, Valerio Panzica
La Manna, Frank Pasveer, Wilfried Philips, and Nikos Deligiannis. Matrix completion with
variational graph autoencoders: Application in hyperlocal air quality inference. In ICASSP 2019
- 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),
pages 7535–7539, 2019. 1, 3"
REFERENCES,0.3625866050808314,"[4] Manajit Sengupta, Yu Xie, Anthony Lopez, Aron Habte, Galen Maclaurin, and James Shelby.
The national solar radiation data base (nsrdb). Renewable and Sustainable Energy Reviews, 89:
51–60, 2018. ISSN 1364-0321. 1, 7"
REFERENCES,0.3648960739030023,"[5] Weiwei Jiang and Jiayun Luo. Graph neural network for trafﬁc forecasting: A survey. Expert
Systems with Applications, 207:117921, 2022. ISSN 0957-4174. doi: https://doi.org/10.1016/j.
eswa.2022.117921. 1"
REFERENCES,0.3672055427251732,"[6] Shifu Zhou, Wei Shen, Dan Zeng, Mei Fang, Yuanwang Wei, and Zhijiang Zhang. Spa-
tial–temporal convolutional neural networks for anomaly detection and localization in crowded
scenes. Signal Processing: Image Communication, 47:358–368, 2016. ISSN 0923-5965. 1, 3,
7, 19"
REFERENCES,0.3695150115473441,"[7] Yong Shean Chong and Yong Haur Tay. Abnormal event detection in videos using spatiotemporal
autoencoder. In International symposium on neural networks, pages 189–196. Springer, 2017."
REFERENCES,0.371824480369515,"[8] Weixin Luo, Wen Liu, and Shenghua Gao. Remembering history with convolutional lstm for
anomaly detection. In 2017 IEEE International Conference on Multimedia and Expo (ICME),
pages 439–444, 2017. doi: 10.1109/ICME.2017.8019325. 1, 8, 19"
REFERENCES,0.3741339491916859,"[9] Michael M Bronstein, Joan Bruna, Taco Cohen, and Petar Veliˇckovi´c. Geometric deep learning:
Grids, groups, graphs, geodesics, and gauges. arXiv preprint arXiv:2104.13478, 2021. 1"
REFERENCES,0.37644341801385683,"[10] P. W. Battaglia, J. B. Hamrick, V. Bapst, A. Sanchez-Gonzalez, V. Zambaldi, M. Malinowski,
A. Tacchetti, D. Raposo, A. Santoro, R. Faulkner, et al. Relational inductive biases, deep
learning, and graph networks. arXiv preprint arXiv:1806.01261, 2018. 1, 4"
REFERENCES,0.3787528868360277,"[11] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S. Yu. A
comprehensive survey on graph neural networks. IEEE Transactions on Neural Networks and
Learning Systems, 32(1):4–24, 2021. doi: 10.1109/TNNLS.2020.2978386. 1"
REFERENCES,0.3810623556581986,"[12] Elvin Isuﬁ, Fernando Gama, and Alejandro Ribeiro. Edgenets:edge varying graph neural
networks. IEEE Transactions on Pattern Analysis and Machine Intelligence, pages 1–1, 2021.
doi: 10.1109/TPAMI.2021.3111054. 1"
REFERENCES,0.3833718244803695,"[13] Wenchao Chen, Long Tian, Bo Chen, Liang Dai, Zhibin Duan, and Mingyuan Zhou. Deep
variational graph convolutional recurrent network for multivariate time series anomaly detection.
In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan
Sabato, editors, Proceedings of the 39th International Conference on Machine Learning, volume
162 of Proceedings of Machine Learning Research, pages 3621–3633. PMLR, 17–23 Jul 2022.
1"
REFERENCES,0.3856812933025404,"[14] Sedigheh Mahdavi, Shima Khoshraftar, and Aijun An. Dynamic joint variational graph au-
toencoders. In Peggy Cellier and Kurt Driessens, editors, Machine Learning and Knowledge
Discovery in Databases, pages 385–401, Cham, 2020. Springer International Publishing. ISBN
978-3-030-43823-4. 1"
REFERENCES,0.38799076212471134,"[15] Yue Hu, Ao Qu, and Dan Work. Detecting extreme trafﬁc events via a context augmented graph
autoencoder. ACM Transactions on Intelligent Systems and Technology (TIST), 2022. 1"
REFERENCES,0.3903002309468822,Graph-Time Convolutional Autoencoders
REFERENCES,0.39260969976905313,"[16] Mounir Haddad, Cécile Bothorel, Philippe Lenca, and Dominique Bedart. Temporalizing static
graph autoencoders to handle temporal networks. In Proceedings of the 2021 IEEE/ACM
International Conference on Advances in Social Networks Analysis and Mining, pages 201–208,
2021. 1"
REFERENCES,0.394919168591224,"[17] C. Si, W. Chen, W. Wang, L. Wang, and T. Tan. An attention enhanced graph convolutional lstm
network for skeleton-based action recognition. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, pages 1227–1236, 2019. 1"
REFERENCES,0.3972286374133949,"[18] Y. Seo, M. Defferrard, P. Vandergheynst, and X. Bresson. Structured sequence modeling with
graph convolutional recurrent networks. In International Conference on Neural Information
Processing, pages 362–373. Springer, 2018. 2"
REFERENCES,0.3995381062355658,"[19] L. Ruiz, F. Gamao, and A. Ribeiro. Gated graph recurrent neural networks. IEEE Transactions
on Signal Processing, 68:6303–6318, 2020."
REFERENCES,0.4018475750577367,"[20] S. Yan, Y. Xiong, and D. Lin. Spatial temporal graph convolutional networks for skeleton-based
action recognition. In Proceedings of the AAAI conference on artiﬁcial intelligence, volume 32,
2018."
REFERENCES,0.40415704387990764,"[21] Samar Hadou, Charilaos I Kanatsoulis, and Alejandro Ribeiro. Space-time graph neural
networks. arXiv preprint arXiv:2110.02880, 2021. 2, 4"
REFERENCES,0.4064665127020785,"[22] Aldo Pareja, Giacomo Domeniconi, Jie Chen, Tengfei Ma, Toyotaro Suzumura, Hiroki Kaneza-
shi, Tim Kaler, Tao Schardl, and Charles Leiserson. Evolvegcn: Evolving graph convolutional
networks for dynamic graphs. 34:5363–5370, Apr. 2020. doi: 10.1609/aaai.v34i04.5984."
REFERENCES,0.40877598152424943,"[23] Yibin Shen, Cheqing Jin, Jiaxun Hua, and Dingjiang Huang. Ttpnet: A neural network for travel
time prediction based on tensor decomposition and graph embedding. IEEE Transactions on
Knowledge and Data Engineering, 34(9):4514–4526, 2022. doi: 10.1109/TKDE.2020.3038259.
1"
REFERENCES,0.4110854503464203,"[24] Yanbang Wang, Pan Li, Chongyang Bai, and Jure Leskovec. Tedic: Neural modeling of behav-
ioral patterns in dynamic social interaction networks. In Proceedings of the Web Conference
2021, WWW ’21, page 693–705, New York, NY, USA, 2021. Association for Computing
Machinery. ISBN 9781450383127. 1"
REFERENCES,0.4133949191685912,"[25] Richard H Hammack, Wilfried Imrich, Sandi Klavžar, Wilfried Imrich, and Sandi Klavžar.
Handbook of product graphs, volume 2. CRC press Boca Raton, 2011. 1, 3"
REFERENCES,0.41570438799076215,"[26] Thomas N Kipf and Max Welling.
Variational graph auto-encoders.
arXiv preprint
arXiv:1611.07308, 2016. 1"
REFERENCES,0.418013856812933,"[27] Ehsan Hajiramezanali, Arman Hasanzadeh, Krishna Narayanan, Nick Dufﬁeld, Mingyuan Zhou,
and Xiaoning Qian. Variational graph recurrent neural networks. In H. Wallach, H. Larochelle,
A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information
Processing Systems, volume 32. Curran Associates, Inc., 2019. 2"
REFERENCES,0.42032332563510394,"[28] Mohammad Sabbaqi and Elvin Isuﬁ. Graph-time convolutional neural networks: Architecture
and theoretical analysis. arXiv preprint arXiv:2206.15174, 2022. 2, 3, 4, 5"
REFERENCES,0.4226327944572748,"[29] Fernando Gama, Joan Bruna, and Alejandro Ribeiro. Stability properties of graph neural
networks. IEEE Transactions on Signal Processing, 68:5680–5695, 2020. doi: 10.1109/TSP.
2020.3026980. 2, 6, 14"
REFERENCES,0.42494226327944573,"[30] Zhan Gao, Elvin Isuﬁ, and Alejandro Ribeiro. Stability of graph convolutional neural networks
to stochastic perturbations. Signal Processing, 188:108216, 2021. ISSN 0165-1684."
REFERENCES,0.42725173210161665,"[31] Henry Kenlay, Dorina Thano, and Xiaowen Dong. On the stability of graph convolutional
neural networks under edge rewiring. In ICASSP 2021 - 2021 IEEE International Conference
on Acoustics, Speech and Signal Processing (ICASSP), pages 8513–8517, 2021. doi: 10.1109/
ICASSP39728.2021.9413474. 2"
REFERENCES,0.4295612009237875,"[32] Luana Ruiz, Fernando Gama, and Alejandro Ribeiro. Gated graph recurrent neural networks.
IEEE Transactions on Signal Processing, 68:6303–6318, 2020. doi: 10.1109/TSP.2020.3033962.
2"
REFERENCES,0.43187066974595845,"[33] Aliaksei Sandryhaila and Jose M.F. Moura. Big data analysis with signal processing on graphs:
Representation and processing of massive data sets with irregular structure. IEEE Signal
Processing Magazine, 31(5):80–90, 2014. 2"
REFERENCES,0.4341801385681293,Graph-Time Convolutional Autoencoders
REFERENCES,0.43648960739030024,"[34] David I Shuman, Sunil K. Narang, Pascal Frossard, Antonio Ortega, and Pierre Vandergheynst.
The emerging ﬁeld of signal processing on graphs: Extending high-dimensional data analysis to
networks and other irregular domains. IEEE Signal Processing Magazine, 30(3):83–98, 2013.
doi: 10.1109/MSP.2012.2235192. 3, 6, 7
[35] Francesco Grassi, Andreas Loukas, Nathanaël Perraudin, and Benjamin Ricaud. A time-vertex
signal processing framework: Scalable processing and meaningful representations for time-
series on graphs. IEEE Transactions on Signal Processing, 66(3):817–829, 2017. 3, 6
[36] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep learning. MIT press, 2016. 3
[37] Kai Qiu, Xianghui Mao, Xinyue Shen, Xiaohan Wang, Tiejian Li, and Yuantao Gu. Time-
varying graph signal reconstruction. IEEE Journal of Selected Topics in Signal Processing, 11
(6):870–883, 2017. doi: 10.1109/JSTSP.2017.2726969. 3
[38] Vassilis N. Ioannidis, Daniel Romero, and Georgios B. Giannakis. Inference of spatio-temporal
functions over graphs via multikernel kriged kalman ﬁltering. IEEE Transactions on Signal
Processing, 66(12):3228–3239, 2018. doi: 10.1109/TSP.2018.2827328. 3
[39] Jhony H. Giraldo, Arif Mahmood, Belmar Garcia-Garcia, Dorina Thanou, and Thierry
Bouwmans. Reconstruction of time-varying graph signals via sobolev smoothness. IEEE
Transactions on Signal and Information Processing over Networks, 8:201–214, 2022. doi:
10.1109/TSIPN.2022.3156886. 3
[40] Alberto Natali, Elvin Isuﬁ, Mario Coutino, and Geert Leus. Learning time-varying graphs from
online data. IEEE Open Journal of Signal Processing, 3:212–228, 2022. doi: 10.1109/OJSP.
2022.3178901. 3
[41] Chao Pan, Siheng Chen, and Antonio Ortega. Spatio-temporal graph scattering transform. arXiv
preprint arXiv:2012.03363, 2020. 3
[42] Aliaksei Sandryhaila and José M. F. Moura. Discrete signal processing on graphs. IEEE
Transactions on Signal Processing, 61(7):1644–1656, 2013. doi: 10.1109/TSP.2013.2238935. 3
[43] Antonio Ortega, Pascal Frossard, Jelena Kovaˇcevi´c, José M. F. Moura, and Pierre Vandergheynst.
Graph signal processing: Overview, challenges, and applications. Proceedings of the IEEE, 106
(5):808–828, 2018. 3
[44] Elvin Isuﬁ, Fernando Gama, David I Shuman, and Santiago Segarra. Graph ﬁlters for signal
processing and machine learning on graphs. arXiv preprint arXiv:2211.08854, 2022. 4
[45] Chuang Liu, Yibing Zhan, Chang Li, Bo Du, Jia Wu, Wenbin Hu, Tongliang Liu, and Dacheng
Tao. Graph pooling for graph neural networks: Progress, challenges, and opportunities. arXiv
preprint arXiv:2204.07321, 2022. 4
[46] Fernando Gama, Elvin Isuﬁ, Geert Leus, and Alejandro Ribeiro. Graphs, convolutions, and
neural networks: From graph ﬁlters to graph neural networks. IEEE Signal Processing Magazine,
37(6):128–138, 2020. doi: 10.1109/MSP.2020.3016143. 4, 8
[47] Arbaaz Khan, Ekaterina Tolstaya, Alejandro Ribeiro, and Vijay Kumar. Graph policy gradients
for large scale robot control. In Leslie Pack Kaelbling, Danica Kragic, and Komei Sugiura,
editors, Proceedings of the Conference on Robot Learning, volume 100 of Proceedings of
Machine Learning Research, pages 823–834. PMLR, 30 Oct–01 Nov 2020. 4
[48] Fernando Gama, Antonio G. Marques, Geert Leus, and Alejandro Ribeiro. Convolutional neural
network architectures for signals supported on graphs. IEEE Transactions on Signal Processing,
67(4):1034–1049, 2019. doi: 10.1109/TSP.2018.2887403. 4
[49] E. Isuﬁand G. Mazzola. Graph-time convolutional neural networks. IEEE Data Science and
Learning Workshop, 2021. 4
[50] Lydia Tsiami and Christos Makropoulos. Cyber—physical attack detection in water distribution
systems with temporal graph convolutional neural networks. Water, 13(9):1247, 2021. 8, 9, 20
[51] Riccardo Taormina, Stefano Galelli, Nils Ole Tippenhauer, Elad Salomons, and Avi Ostfeld.
Characterizing cyber-physical attacks on water distribution systems. Journal of Water Resources
Planning and Management, 143(5):04017009, 2017. 8
[52] Riccardo Taormina, Stefano Galelli, Nils Ole Tippenhauer, Elad Salomons, Avi Ostfeld,
Demetrios G Eliades, Mohsen Aghashahi, Raanju Sundararajan, Mohsen Pourahmadi, M Kather-
ine Banks, et al. Battle of the attack detection algorithms: Disclosing cyber attacks on water
distribution networks. Journal of Water Resources Planning and Management, 144(8), 2018. 8"
OTHER,0.4387990762124711,Graph-Time Convolutional Autoencoders
OTHER,0.44110854503464203,"A
Stability proof"
OTHER,0.44341801385681295,"The proof is structured in three components. First we prove the graph-time convolutional ﬁlter
is stable to perturbations. Then, we prove stability for the encoder and ﬁnally for the decoder.
Throughout the proof we will use the following lemmas."
OTHER,0.4457274826789838,"Lemma 1. [29] Let S = VΛVH and E = UMUH such that ∥E∥≤ϵ. Assume that EV = VMVH
is the projection of perturbation E over graph eigenspace of S, and E = EV + EU. For any
eigenvector vn of S it holds that
Evn = mnvn + EUvn
(19)"
OTHER,0.44803695150115475,"with ∥EU∥≤ϵδ, where δ = (∥U −V∥2 + 1)2 −1 and mn is the n-th eigenvalue of M. Recall that
∥· ∥represents the operator norm of a matrix."
OTHER,0.4503464203233256,"Lemma 2. Given the frequency response of a graph-time convolutional ﬁlter as h(λ⋄) = PK
k=1 hkλk
⋄,
the partial derivation w.r.t. graph frequency λ is"
OTHER,0.45265588914549654,∂h(λ⋄)
OTHER,0.45496535796766746,"∂λ
= (s01 + s11λT ) K
X"
OTHER,0.45727482678983833,"k=1
khkλk−1
⋄
.
(20)"
OTHER,0.45958429561200925,Proof. Using the product graph deﬁnition (1) we have ∂λ⋄
OTHER,0.4618937644341801,∂λ = ∂(s00 + s01λ + s10λT + s11λT λ)
OTHER,0.46420323325635104,"∂λ
= s01 + s11λT .
(21)"
OTHER,0.4665127020785219,"Then,
∂h(λ⋄)"
OTHER,0.46882217090069284,"∂λ
= ∂h(λ⋄)"
OTHER,0.47113163972286376,"∂λ⋄
× ∂λ⋄"
OTHER,0.47344110854503463,"∂λ = ( K
X"
OTHER,0.47575057736720555,"k=1
khkλk−1
⋄
)(s01 + s11λT )
(22)"
OTHER,0.4780600461893764,completes the proof.
OTHER,0.48036951501154734,"To ease notation, let us also rearrange the parametric product graph GSO as"
OTHER,0.48267898383371827,"S⋄= (s00IT + s10ST ) ⊗IN + (s01IT + s11ST ) ⊗S = ST 0 ⊗IN + ST 1 ⊗S
(23)"
OTHER,0.48498845265588914,"where ST 0 = s00IT + s10ST collects the fully temporal edges and ST 1 = s01IT + s11ST the edges
ruled by the spatial graph."
OTHER,0.48729792147806006,GTConv ﬁlter stability.
OTHER,0.4896073903002309,The difference of the ﬁlter operating on the perturbed and nominal graph is
OTHER,0.49191685912240185,"H(S⋄) −H(ˆS⋄) = K
X"
OTHER,0.4942263279445728,"k=0
hk(ˆSk
⋄−Sk
⋄)
(24)"
OTHER,0.49653579676674364,"Leveraging the product GSO expansion (23) and the perturbation model ˆS = S + (SE + ES) [cf.
(13)] we can write the k−th power of the perturbed product graph GSO as"
OTHER,0.49884526558891457,"ˆSk
⋄= (ST 0 ⊗IN + ST 1 ⊗(S + (SE + ES)))k"
OTHER,0.5011547344110855,= (S⋄+ (ST 1 ⊗(SE + ES)))k
OTHER,0.5034642032332564,"= Sk
⋄+ k−1
X"
OTHER,0.5057736720554272,"r=0
Sr
⋄(ST 1 ⊗(SE + ES))Sk−r−1
⋄
+ D, (25)"
OTHER,0.5080831408775982,"where we applied the ﬁrst-order Taylor expansion in the third line. Matrix D contains all terms of
order O(ϵ2) and can be ignored."
OTHER,0.5103926096997691,"Substituting then (25) into (24), we get"
OTHER,0.5127020785219399,"H(S⋄) −H(ˆS⋄) = K
X"
OTHER,0.5150115473441108,"k=0
hk k−1
X"
OTHER,0.5173210161662818,"r=0
Sr
⋄(ST 1 ⊗(SE + ES))Sk−r−1
⋄
.
(26)"
OTHER,0.5196304849884527,Graph-Time Convolutional Autoencoders
OTHER,0.5219399538106235,"Upon applying the ﬁlters to an input x⋄we get the output difference y⋄−ˆy⋄= (H(S⋄)−H(ˆS⋄))x⋄.
Substituting into this the graph-time Fourier expansion of the input x⋄= T
X t=1 N
X"
OTHER,0.5242494226327945,"n=1
˜x(n,t)(vT,t ⊗vn)
(27)"
OTHER,0.5265588914549654,"with ˜x(n,t) the (n, t)−th Fourier coefﬁcients and (vT,t, vn) the eigenvector pair for the temporal and
spatial GSOs [cf. Sec. 3.1], we can write the output difference as"
OTHER,0.5288683602771362,"y⋄−ˆy⋄= T
X t=1 N
X"
OTHER,0.5311778290993071,"n=1
˜x(n,t) K
X"
OTHER,0.5334872979214781,"k=0
hk k−1
X"
OTHER,0.535796766743649,"r=0
Sr
⋄(ST 1 ⊗(SE + ES))Sk−r−1
⋄
(vT,t ⊗vn).
(28)"
OTHER,0.5381062355658198,"Since (vT,t ⊗vn) is an eigenvector of S⋄, we have"
OTHER,0.5404157043879908,"Sk−r−1
⋄
(vT,t ⊗vn) = λk−r−1
⋄,(n,t) (vT,t ⊗vn)
(29)"
OTHER,0.5427251732101617,which by substituting to (28) yields
OTHER,0.5450346420323325,"y⋄−ˆy⋄= T
X t=1 N
X"
OTHER,0.5473441108545035,"n=1
˜x(n,t) K
X"
OTHER,0.5496535796766744,"k=0
hk k−1
X"
OTHER,0.5519630484988453,"r=0
λk−r−1
⋄,(n,t) Sr
⋄(ST 1 ⊗(SE + ES))(vT,t ⊗vn)
(30)"
OTHER,0.5542725173210161,"where λ⋄,(n,t) is the eigenvalue of the product graph GSO S⋄for indices (n, t). Leveraging mixed
product property of Kronecker product2 allows us to rewrite (30) as"
OTHER,0.5565819861431871,"y⋄−ˆy⋄= T
X t=1 N
X"
OTHER,0.558891454965358,"n=1
˜x(n,t) K
X"
OTHER,0.5612009237875288,"k=0
hk k−1
X"
OTHER,0.5635103926096998,"r=0
λk−r−1
⋄,(n,t) Sr
⋄(ST 1vT,t ⊗(SE + ES)vn).
(31)"
OTHER,0.5658198614318707,Replacing ST 1 = s01IT + s11ST leads to
OTHER,0.5681293302540416,"ˆy⋄−y⋄= T
X t=1 N
X"
OTHER,0.5704387990762124,"n=1
(s01 + s11λT,t)˜x(n,t) K
X"
OTHER,0.5727482678983834,"k=0
hk k−1
X"
OTHER,0.5750577367205543,"r=0
λk−r−1
⋄,(n,t) Sr
⋄(vT,t ⊗(SE + ES)vn).
(32)"
OTHER,0.5773672055427251,Applying Lemma 1 results in
OTHER,0.5796766743648961,"ˆy⋄−y⋄= T
X t=1 N
X"
OTHER,0.581986143187067,"n=1
(s01+s11λT,t)˜x(n,t) K
X"
OTHER,0.5842956120092379,"k=0
hk k−1
X"
OTHER,0.5866050808314087,"r=0
λk−r−1
⋄,(n,t) Sr
⋄(vT,t⊗(S+λnIN)(mnvn
| {z }
term 1
+ EUvn
| {z }
term 2
)),"
OTHER,0.5889145496535797,"(33)
which leaves us with two terms that shall be discussed separately."
OTHER,0.5912240184757506,"For the ﬁrst term, we have t1 = T
X t=1 N
X"
OTHER,0.5935334872979214,"n=1
2λnmn(s01 + s11λT,t)˜x(n,t) K
X"
OTHER,0.5958429561200924,"k=0
hk k−1
X"
OTHER,0.5981524249422633,"r=0
λk−r−1
⋄,(n,t) Sr
⋄(vT,t ⊗vn).
(34)"
OTHER,0.6004618937644342,"By exploiting eigenvector property Sr
⋄(vT,t ⊗vn) = λr
⋄,(n,t)(vT,t ⊗vn) we can rewrite (34) into t1 = T
X t=1 N
X"
OTHER,0.6027713625866051,"n=1
2λnmn(s01 + s11λT,t)˜x(n,t) K
X"
OTHER,0.605080831408776,"k=0
khkλk−1
⋄,(n,t)(vT,t ⊗vn).
(35)"
OTHER,0.6073903002309469,"Applying Lemma 2 leads to t1 = T
X t=1 N
X"
OTHER,0.6096997690531177,"n=1
2mn˜x(n,t)λn
∂h(λ⋄,(n,t))"
OTHER,0.6120092378752887,"∂λn
(vT,t ⊗vn).
(36)"
OTHER,0.6143187066974596,"For the second term, we have t2 = T
X t=1 N
X"
OTHER,0.6166281755196305,"n=1
(s01 + s11λT,t)˜x(n,t) K
X"
OTHER,0.6189376443418014,"k=0
hk k−1
X"
OTHER,0.6212471131639723,"r=0
λk−r−1
⋄,(n,t) Sr
⋄(vT,t ⊗(S + λnIN)EUvn).
(37)"
OTHER,0.6235565819861432,2(A ⊗B)(C ⊗D) = AC ⊗BD
OTHER,0.625866050808314,Graph-Time Convolutional Autoencoders
OTHER,0.628175519630485,"By substituting the eigendecomposition Sr
⋄= (VT ⊗V)Λr
⋄(VT ⊗V)H we get t2 = T
X t=1 N
X"
OTHER,0.6304849884526559,"n=1
˜x(n,t)(VT ⊗V)diag(g(n,t))(VT ⊗V)H(vT,t ⊗EUvn).
(38)"
OTHER,0.6327944572748267,"where the entries of vectors g(n,t) ∈RNT for n ∈[N] and t ∈[T] are deﬁned as"
OTHER,0.6351039260969977,"g(n,t)(n′, t′) = (s01 + s11λT,t)(λn + λn′) k
X"
OTHER,0.6374133949191686,"k=0
hk k−1
X"
OTHER,0.6397228637413395,"r=0
λk−r−1
⋄,(n,t) λr
⋄,(n′,t′) = 

 
"
OTHER,0.6420323325635104,"2λn
∂h(λ⋄,(n,t))"
OTHER,0.6443418013856813,"∂λn
;
(n, t) = (n′, t′)"
OTHER,0.6466512702078522,"(s01 + s11λT,t)(h(λ⋄,(n,t)) −h(λ⋄,(n′,t′))) λn+λn′"
OTHER,0.648960739030023,"λn−λn′ ;
(n, t) ̸= (n′, t′)
(39)"
OTHER,0.651270207852194,"With this in place, we now upper bound the two-norm of the difference y⋄−ˆy⋄= t1 + t2 by
bounding each of the terms t1 and t2 separately. From ∥E∥≤ϵ, we have that |mn| ≤ϵ. Also from
the integral Lipschitz property of the ﬁlter [cf. Def. 1]. Using these two into (36), we can upper
bound the norm of term t1 as"
OTHER,0.6535796766743649,"∥t1∥2 ≤2ϵC T
X t=1 N
X"
OTHER,0.6558891454965358,"n=1
˜x(n,t)(vT,t ⊗vn) ≤2ϵC∥x⋄∥2,
(40)"
OTHER,0.6581986143187067,where the second inequality holds due to Fourier transform deﬁnition (27).
OTHER,0.6605080831408776,"Moving on to t2, we use mixed product property as vT,t ⊗EUvn = (IT ⊗EU)(vT,t ⊗vn) and
operator norms in (38) to obtain an upper bound as"
OTHER,0.6628175519630485,"∥t2∥2 ≤ T
X t=1 N
X"
OTHER,0.6651270207852193,"n=1
|˜x(n,t)|∥(VT ⊗V)∥∥diag(g(n,t))∥∥(VT ⊗V)H∥∥IT ⊗EU∥∥vT,t ⊗vn∥2. (41)"
OTHER,0.6674364896073903,"From the integral Lipschitz property we can bound ∥diag(g(n,t))∥≤2C(s01 + s11λT,max) in (39)
where λT,max is a temporal eigenvalue with the largest absolute value. As VT ⊗V is an orthonormal
bases, its operator norm is ∥VT ⊗V∥= 1, and l2-norm of the eigenvectors is ∥vT,t ⊗vn∥2 = 1.
Lemma 1 states that ∥E∥≤ϵδ which leads to ∥IT ⊗EU∥≤ϵδ. Finally, l1-norm can be bounded
by PT
t=1
PN
n=1 |˜x(n,t)| = ∥˜x∥1 ≤
√"
OTHER,0.6697459584295612,"NT∥˜x∥2 =
√"
OTHER,0.6720554272517321,"NT∥x⋄∥2. Considering all the abovementioned
bounds and replacing them in (41) yields"
OTHER,0.674364896073903,"∥t2∥2 ≤2(s01 + s11λT,max)ϵCδ
√"
OTHER,0.6766743648960739,"NT∥x⋄∥2.
(42)"
OTHER,0.6789838337182448,"Finally, based on the triangle inequality the GTConv ﬁlter difference is"
OTHER,0.6812933025404158,"∥H(S⋄) −H(ˆS⋄)∥≤2(s01 + s11λT,max)ϵC(1 + δ
√"
OTHER,0.6836027713625866,"NT) = ϵ∆.
(43)"
OTHER,0.6859122401847575,Encoder stability.
OTHER,0.6882217090069284,"Consider the encoder contains Le layer each having Fℓfeatures and r sampling rate. We are interested
in the output difference of the encoder"
OTHER,0.6905311778290993,"∥ENC(x⋄, S, ST ) −ENC(x⋄, ˆS, ST )∥2
2 = FLe
X"
OTHER,0.6928406466512702,"f=1
∥xf
⋄,Le −ˆxf
⋄,Le∥2
2.
(44)"
OTHER,0.6951501154734411,"To ease exposition, we denote H := H(S) and ˆH := H(ˆS). For the f−th output encoder feature we
have"
OTHER,0.6974595842956121,"∥xf
⋄,Le −ˆxf
⋄,Le∥2 = σ  "
OTHER,0.6997690531177829,"FLe−1
X"
OTHER,0.7020785219399538,"g=1
Sr(Hfg
Lexg
⋄,Le−1)  −σ  "
OTHER,0.7043879907621247,"FLe−1
X"
OTHER,0.7066974595842956,"g=1
Sr( ˆHfg
Le ˆxg
⋄,Le−1)   2 (45)"
OTHER,0.7090069284064665,"where Sr(·) is the sampling operator with rate r, i.e., simple SUM(·) function without any aggrega-
tion. The downsampling reduces the norm of each time series by a factor 1/√r, so ∥y⋄,Le∥2 will be"
OTHER,0.7113163972286374,Graph-Time Convolutional Autoencoders
OTHER,0.7136258660508084,"reduced by 1/√r. As non-linearity is 1-Lipschitz, i.e., |σ(a) −σ(b)| ≤|a −b|, we can conclude the
following inequality from (45) by use of triangular inequality"
OTHER,0.7159353348729792,"∥xf
⋄,Le −ˆxf
⋄,Le∥2 ≤
1
√r"
OTHER,0.7182448036951501,"FLe−1
X g=1"
OTHER,0.7205542725173211,"Hfg
Lexg
⋄,Le−1 −ˆHfg
Le ˆxg
⋄,Le−1


2 .
(46)"
OTHER,0.7228637413394919,"We add and subtract ˆHfg
L xg
⋄,L−1 inside the l2-norm and use the triangular inequality once again for
each of the input features g to get


Hfg
Lexg
⋄,Le−1 −ˆHfg
Le ˆxg
⋄,Le−1


2 ≤∥(Hfg
Le −ˆHfg
Le)xg
⋄,Le−1∥2 + ∥ˆHfg
Le(xg
⋄,Le−1 −ˆxg
⋄,Le−1)∥2"
OTHER,0.7251732101616628,"≤∥Hfg
Le −ˆHfg
Le∥∥xg
⋄,Le−1∥2 + ∥ˆHfg
Le∥∥xg
⋄,Le−1 −ˆxg
⋄,Le−1∥2
(47)"
OTHER,0.7274826789838337,"The stability of GTConv ﬁlter in (43) provides an upper bound for the ﬁrst term as ∥Hfg
Le−ˆHfg
Le∥≤ϵ∆
which is applicable for all the layers. Note that ∆depends on temporal graph size, so it is different
in each layer due to the downsampling. However, we assume the largest temporal size T so the
inequality holds for all the layers 3. The second term is bounded by spectral normalization assumption
∥Hfg
Le∥≤1 [cf. Def. 2]. Leveraging these bounds and replacing in (46) we get"
OTHER,0.7297921478060047,"∥xf
⋄,Le −ˆxf
⋄,Le∥2 ≤
1
√r"
OTHER,0.7321016166281755,"FLe−1
X"
OTHER,0.7344110854503464,"g=1
ϵ∆∥xg
⋄,Le−1∥2 + ∥xg
⋄,Le−1 −ˆxg
⋄,Le−1∥2.
(48)"
OTHER,0.7367205542725174,"This equation deﬁnes a recursion among the encoder layers with initial condition xg
⋄,0 = ˆxg
⋄,0 := xg
⋄
for all the input features. So for the ℓ−th layer, we can write"
OTHER,0.7390300230946882,"∥xf
⋄,ℓ−ˆxf
⋄,ℓ∥2 ≤
1
√r"
OTHER,0.7413394919168591,"Fℓ−1
X"
OTHER,0.74364896073903,"g=1
ϵ∆∥xg
⋄,ℓ−1∥2 + ∥xg
⋄,ℓ−1 −ˆxg
⋄,ℓ−1∥2.
(49)"
OTHER,0.745958429561201,"To solve this recursive inequality, we ﬁrst upper bound ∥xf
⋄,ℓ∥2 as"
OTHER,0.7482678983833718,"∥xf
⋄,ℓ∥2 ≤
1
√r"
OTHER,0.7505773672055427,"Fℓ−1
X"
OTHER,0.7528868360277137,"g=1
∥Hfg
ℓxg
⋄,ℓ−1∥2 ≤
1
√r"
OTHER,0.7551963048498845,"Fℓ−1
X"
OTHER,0.7575057736720554,"g=1
∥xg
⋄,ℓ−1∥2,
(50)"
OTHER,0.7598152424942263,"where the last inequality is due to the assumption ∥Hfg
ℓ∥≤1 [Def. 2]. Solving this recursion leads to"
OTHER,0.7621247113163973,"∥xf
⋄,ℓ∥2 ≤
1
rl/2 ℓ−1
Y"
OTHER,0.7644341801385681,"i=1
Fi F0
X"
OTHER,0.766743648960739,"g=1
∥xg
⋄∥2 = r−ℓ/2
ℓ−1
Y"
OTHER,0.76905311778291,"i=1
Fi F0
X"
OTHER,0.7713625866050808,"g=1
∥xg
⋄∥2.
(51)"
OTHER,0.7736720554272517,Replacing (51) in (49) and solving the recursion considering the initial conditions we get
OTHER,0.7759815242494227,"∥xf
⋄,ℓ−ˆxf
⋄,ℓ∥2 ≤r−ℓ/2ϵ∆ℓ ℓ−1
Y"
OTHER,0.7782909930715936,"i=1
Fi F0
X"
OTHER,0.7806004618937644,"g=1
∥xg
⋄∥2.
(52)"
OTHER,0.7829099307159353,Setting ℓ= Le in (52) and replacing it in (44) yields to
OTHER,0.7852193995381063,"∥ENC(x⋄, S, ST ) −ENC(x⋄, ˆS, ST )∥F ≤Ler−Le/2ϵ∆
p FLe"
OTHER,0.7875288683602771,"Le−1
Y"
OTHER,0.789838337182448,"n=1
Fn F0
X"
OTHER,0.792147806004619,"g=1
∥xg
⋄∥2.
(53)"
OTHER,0.7944572748267898,GTConv-AE stability.
OTHER,0.7967667436489607,"Let Z⋄= ENC(x⋄, S, ST ) be the input of the decoder and z⋄,Ld = DEC(Z⋄, S, ST ) its output. To
prove GTConvAE stability, we need to bound"
OTHER,0.7990762124711316,"∥DEC(Z⋄, S, ST ) −DEC(Z⋄, ˆS, ST )∥2
2 ="
OTHER,0.8013856812933026,"Fd,Ld
X"
OTHER,0.8036951501154734,"f=1
∥zf
⋄,Ld −ˆzf
⋄,Ld∥2
2.
(54)"
OTHER,0.8060046189376443,"3It is possible to solve the recursive equation with ∆T as a variable, but it leads to overcrowded multipliers
in inequalities without carrying important information on the bound."
OTHER,0.8083140877598153,Graph-Time Convolutional Autoencoders
OTHER,0.8106235565819861,For each feature in the output we have
OTHER,0.812933025404157,"∥zf
⋄,Ld −ˆzf
⋄,Ld∥2 = σ  "
OTHER,0.815242494226328,"Fd,Ld−1
X"
OTHER,0.8175519630484989,"g=1
Ur(Hfg
Ldzg
⋄,Ld−1)  −σ  "
OTHER,0.8198614318706697,"Fd,Ld−1
X"
OTHER,0.8221709006928406,"g=1
Ur( ˆHfg
Ldˆzg
⋄,Ld−1)   2 (55)"
OTHER,0.8244803695150116,"where Ur(·) is an upsampling operator with rate r which insert zeros among the samples. The
upsampling module leaves the l2-norm per time series unaffected and can be ignored. Given 1-
Lipschitz continuity of activation function σ(·), the following inequality can be concluded from (55)
using the triangular inequality"
OTHER,0.8267898383371824,"∥zf
⋄,Ld −ˆzf
⋄,Ld∥2 ≤"
OTHER,0.8290993071593533,"Fd,Ld−1
X g=1"
OTHER,0.8314087759815243,"Hfg
Ldzg
⋄,Ld−1 −ˆHfg
Ldˆzg
⋄,Ld−1


2 .
(56)"
OTHER,0.8337182448036952,"Adding and subtracting ˆHfg
Ldzg
⋄,Ld−1 in the norm and leveraging again the triangular inequality yields


Hfg
Ldzg
⋄,Ld−1 −ˆHfg
Ldˆzg
⋄,Ld−1


2 ≤∥(Hfg
Ld −ˆHfg
Ld)zg
⋄,Ld−1∥2 + ∥ˆHfg
Ld(zg
⋄,Ld−1 −ˆzg
⋄,Ld−1)∥2"
OTHER,0.836027713625866,"≤∥Hfg
Ld −ˆHfg
Ld∥∥zg
⋄,Ld−1∥2 + ∥ˆHfg
Ld∥∥xg
⋄,Ld−1 −ˆzg
⋄,Ld−1∥2,
(57)
for g = 1, . . . , Fd,Ld−1. The ﬁrst term is bounded by GTConv ﬁlters stability in (43) and the second
term is upper-bounded because ﬁlters are normalized ∥Hfg
ℓ∥≤1 [cf. Def. 2]. Given these two
bounds, (57) can be upper-bounded as"
OTHER,0.8383371824480369,"∥zf
⋄,Ld −ˆzf
⋄,Ld∥2 ≤"
OTHER,0.8406466512702079,"Fd,Ld−1
X"
OTHER,0.8429561200923787,"g=1
ϵ∆∥zg
⋄,Ld−1∥2 + ∥zg
⋄,Ld−1 −ˆzg
⋄,Ld−1∥2.
(58)"
OTHER,0.8452655889145496,This allows deﬁning a recursion for the generic layer ℓas
OTHER,0.8475750577367206,"∥zf
⋄,ℓ−ˆzf
⋄,ℓ∥2 ≤"
OTHER,0.8498845265588915,"Fd,ℓ−1
X"
OTHER,0.8521939953810623,"g=1
ϵ∆∥zg
⋄,ℓ−1∥2 + ∥zg
⋄,ℓ−1 −ˆzg
⋄,ℓ−1∥2.
(59)"
OTHER,0.8545034642032333,"For the ﬁrst term on the right hand-side of (59), we have"
OTHER,0.8568129330254042,"∥zf
⋄,ℓ∥2 ≤"
OTHER,0.859122401847575,"Fd,ℓ−1
X"
OTHER,0.8614318706697459,"g=1
∥Hfg
ℓzg
⋄,ℓ−1∥2 ≤"
OTHER,0.8637413394919169,"Fd,ℓ−1
X"
OTHER,0.8660508083140878,"g=1
∥zg
⋄,ℓ−1∥2 = ℓ−1
Y"
OTHER,0.8683602771362586,"j=1
Fd,j"
OTHER,0.8706697459584296,"Fd,0
X"
OTHER,0.8729792147806005,"g=1
∥zg
⋄,0∥2
(60)"
OTHER,0.8752886836027713,"because ∥Hfg
ℓ∥≤1 [cf. Def. 2]. Replacing (60) into (59) and evaluating it at ℓ= Ld brings the
recursion to its initial conditions"
OTHER,0.8775981524249422,"∥zf
⋄,Ld −ˆzf
⋄,Ld∥2 ≤ϵ∆Ld"
OTHER,0.8799076212471132,"Ld−1
Y"
OTHER,0.8822170900692841,"j=1
Fd,j"
OTHER,0.8845265588914549,"Fd,0
X"
OTHER,0.8868360277136259,"g=1
∥zg
⋄,0∥2 +"
OTHER,0.8891454965357968,"Ld−1
Y"
OTHER,0.8914549653579676,"j=1
Fd,j"
OTHER,0.8937644341801386,"Fd,0
X"
OTHER,0.8960739030023095,"g=1
∥zg
⋄,0 −ˆzg
⋄,0∥2.
(61)"
OTHER,0.8983833718244804,"For initial conditions we have Z⋄,0 = Z⋄, however, the error caused by spatial graph perturbation in
the encoder appears here as an initial condition where ∥zf
⋄,0 −ˆzf
⋄,0∥2 is bounded by the result in (53)
for f ∈[Fd,0]."
OTHER,0.9006928406466512,"As the initial condition of the decoder states Z⋄,0 = Z⋄= X⋄,L, we can set ℓ= L in (51) to obtain"
OTHER,0.9030023094688222,"∥zf
⋄∥2 ≤r−Le/2
Le−1
Y"
OTHER,0.9053117782909931,"i=1
Fi F0
X"
OTHER,0.9076212471131639,"g=1
∥xg
⋄∥2.
(62)"
OTHER,0.9099307159353349,"Substituting encoder stability bound (53), to enforce the initial condition for PFd,0
g=1 ∥zg
⋄,0 −ˆzg
⋄,0∥2,
and (62) into (61) results in"
OTHER,0.9122401847575058,"∥zf
⋄,Ld −ˆzf
⋄,Ld∥2 ≤Ldr−Le/2ϵ∆Fd,0"
OTHER,0.9145496535796767,"Le−1
Y"
OTHER,0.9168591224018475,"i=1
Fi"
OTHER,0.9191685912240185,"Ld−1
Y"
OTHER,0.9214780600461894,"j=1
Fd,j F0
X"
OTHER,0.9237875288683602,"g=1
∥xg
⋄∥2"
OTHER,0.9260969976905312,"+ Ler−Le/2ϵ∆Fd,0"
OTHER,0.9284064665127021,"Le−1
Y"
OTHER,0.930715935334873,"i=1
Fi"
OTHER,0.9330254041570438,"Ld−1
Y"
OTHER,0.9353348729792148,"j=1
Fd,j F0
X"
OTHER,0.9376443418013857,"g=1
∥xg
⋄∥2.
(63)"
OTHER,0.9399538106235565,Graph-Time Convolutional Autoencoders
OTHER,0.9422632794457275,Calculating over all the output features completes the upper-bound as
OTHER,0.9445727482678984,"∥GTConvAE(x⋄,S, ST ) −GTConvAE(x⋄, ˆS, ST )∥2 ≤"
OTHER,0.9468822170900693,"(Ld + Le)r−Le/2ϵ∆
p Fd,Ld"
OTHER,0.9491916859122402,"Le−1
Y"
OTHER,0.9515011547344111,"i=1
Fi"
OTHER,0.953810623556582,"Ld−1
Y"
OTHER,0.9561200923787528,"j=0
Fd,j F0
X"
OTHER,0.9584295612009238,"g=1
∥xg
⋄∥2.
(64)"
OTHER,0.9607390300230947,"Assuming F0 = Fd,Ld = 1 and {Fd, F} ≤Fmax completes the proof."
OTHER,0.9630484988452656,"B
Denoising solar irradiance time series"
OTHER,0.9653579676674365,"In this appendix we provide extra information on numerical experiment for denoising solar irradiance
time series."
OTHER,0.9676674364896074,"SNR: An error vector et ∼N(0, L†) is generated independently for each timestamp t ∈[T].
Matrix L represents normalized Laplacian and † stands for pseudo-inverse operation. This noise
varies smoothly over spatial graph which makes it more difﬁcult to detect. Assume noise matrix
σE = σ[e1, . . . , eT ] ∈RN×T , we deﬁne SNR as follow:"
OTHER,0.9699769053117783,SNR = 20 log ∥X∥F
OTHER,0.9722863741339491,"σ∥E∥F
,
(65)"
OTHER,0.9745958429561201,where σ is used to control SNR for the experiments.
OTHER,0.976905311778291,"GTConvAE parameters: The time window is searched over T ∈{2, . . . , 8}. The number of layers
for both encoder and decoder are selected from Le = Ld ∈{2, 3}. The number of features for every
layer are chosen from F ∈{32, 16, 8, 4, 2}. The ﬁlter order is evaluated on K ∈{2, 3, 4, 5}. The
sampling is searched over r ∈{1, 2, 3, 4}. All the aggregation function have been tested. Finally, the
regularizer weight initially selected from logarithmic interval ρ ∈{10−2, . . . , 102} and ﬁne-tuned
around optimum value."
OTHER,0.9792147806004619,"C3D parameters: As proposed in [6], 4 convolutional layer, 2 subsampling layer, and 2 fully
connected layer are considered for both encoder and decoder. The time window is searched over
T ∈{4, . . . , 6}. The number of features for every layer are chosen from F ∈{32, 16, 8, 4, 2}. So,
the size of 3D convolution in each layer is 75 × F × T. The number of channels are selected from
C = {12, 24, 48} in each layer. Fully connected layers have 128 and 64 features, respectively. The
learning rate is set to 0.01."
OTHER,0.9815242494226328,"ConvLSTM-AE parameters: The time window T = 10 as it advised in [8]. Both encoder and
decoder have 3 convolutional layer connected in series with ConvLSTM modules. The number of
features for every layer are chosen from F ∈{32, 16, 8, 4, 2}. The design is symmetrically identical
in the decoder. The learning rate is set to 0.01."
OTHER,0.9838337182448037,"STGAE: The learning rate is reducing from 0.01 as the loss function declines. An early stopping
mechanism is used to avoid overﬁtting. Temporal convolution size is selected from T = {4, 5, 6}.
Each graph-based attention convolution holds F ∈{32, 16, 8, 4, 2} chosen via grid search. Minor
parameters are the same as [1]."
OTHER,0.9861431870669746,"C
Anomaly detection in water networks"
OTHER,0.9884526558891455,"In this appendix we provide extra information on numerical experiments for anomaly detection in
water networks."
OTHER,0.9907621247113164,"GTConvAE parameters: The model parameters are evaluated and ﬁne-tuned by sliding window
backtesting. The time window is searched over T ∈{2, . . . , 8}. The number of layers for both
encoder and decoder are selected from Le = Ld ∈{2, 3}. The number of features for every layer
are chosen from F ∈128, 64, 32, 16, 8, 4, 2. The ﬁlter order is evaluated on K ∈{2, 3, 4, 5}. The
sampling is searched over r ∈{1, 2, 3}. All the aggregation functions have been tested. Finally, the
regularizer weight initially selected from logarithmic interval ρ ∈{10−2, . . . , 102} and ﬁne-tuned
around optimum value."
OTHER,0.9930715935334873,Graph-Time Convolutional Autoencoders
OTHER,0.9953810623556582,"STGCAE-LSTM: The time window is set to 12 with stride 1 in temporal convolution units similar
to [2]. The inner LSTM network has 12 layers with features selected from F ∈128, 64, 32, 16, 8, 4, 2.
The regularization parameter is 0.05. The learning rate is 10−3."
OTHER,0.9976905311778291,TGCN: For the complete experimental setup refer to [50].
