Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0007662835249042146,"We address the problem of active online assortment optimization problem
1"
ABSTRACT,0.0015325670498084292,"with preference feedback, which is a framework for modeling user choices
2"
ABSTRACT,0.0022988505747126436,"and subsetwise utility maximization. The framework is useful in various
3"
ABSTRACT,0.0030651340996168583,"real-world applications including ad placement, online retail, recommender
4"
ABSTRACT,0.0038314176245210726,"systems, and fine-tuning language models, amongst many others. The prob-
5"
ABSTRACT,0.004597701149425287,"lem, although has been studied in the past, lacks an intuitive and practical
6"
ABSTRACT,0.0053639846743295016,"solution approach with simultaneously efficient algorithm and optimal re-
7"
ABSTRACT,0.006130268199233717,"gret guarantee. E.g., popularly used assortment selection algorithms often
8"
ABSTRACT,0.006896551724137931,"require the presence of a ‘strong reference’ which is always included in the
9"
ABSTRACT,0.007662835249042145,"choice sets, further they are also designed to offer the same assortments
10"
ABSTRACT,0.00842911877394636,"repeatedly until the reference item gets selected—all such requirements
11"
ABSTRACT,0.009195402298850575,"are quite unrealistic for practical applications. In this paper, we designed
12"
ABSTRACT,0.00996168582375479,"efficient algorithms for the problem of regret minimization in assortment
13"
ABSTRACT,0.010727969348659003,"selection with Plackett Luce (PL) based user choices. We designed a novel
14"
ABSTRACT,0.011494252873563218,"concentration guarantee for estimating the score parameters of the PL model
15"
ABSTRACT,0.012260536398467433,"using ‘Pairwise Rank-Breaking’, which builds the foundation of our proposed
16"
ABSTRACT,0.013026819923371647,"algorithms. Moreover, our methods are practical, provably optimal, and
17"
ABSTRACT,0.013793103448275862,"devoid of the aforementioned limitations of the existing methods. Empirical
18"
ABSTRACT,0.014559386973180077,"evaluations corroborate our findings and outperform the existing baselines.
19"
INTRODUCTION,0.01532567049808429,"1
Introduction
20"
INTRODUCTION,0.016091954022988506,"Studies have shown that it is often easier, faster and less expensive to collect feedback on a
21"
INTRODUCTION,0.01685823754789272,"relative scale rather than asking ratings on an absolute scale. E.g., to understand the liking
22"
INTRODUCTION,0.017624521072796936,"for a given pair of items, say (A,B), it is easier for the users to answer preference-based
23"
INTRODUCTION,0.01839080459770115,"queries like: “Do you prefer Item A over B?"", rather than their absolute counterparts: “How
24"
INTRODUCTION,0.019157088122605363,"much do you score items A and B in a scale of [0-10]?"". Due to the widespread applicability
25"
INTRODUCTION,0.01992337164750958,"and ease of data collection with relative feedback, learning from preferences has gained much
26"
INTRODUCTION,0.020689655172413793,"popularity in the machine-learning community, especially the active learning literature which
27"
INTRODUCTION,0.021455938697318006,"has applications in Medical surveys, AI tutoring systems, Multi-player sports/games, or any
28"
INTRODUCTION,0.022222222222222223,"real-world systems that have ways to collect feedback in terms of preferences. The problem
29"
INTRODUCTION,0.022988505747126436,"is famously studied as the Dueling-Bandit (DB) problem in the active learning community
30"
INTRODUCTION,0.02375478927203065,"[41, 3, 45, 46, 44], which is an online learning framework for identifying a set of ‘good’ items
31"
INTRODUCTION,0.024521072796934867,"from a fixed decision-space (set of items) by querying preference feedback of actively chosen
32"
INTRODUCTION,0.02528735632183908,"item-pairs. Consequently, the generalization of Dueling-Bandits, with subset-wise preferences
33"
INTRODUCTION,0.026053639846743294,"has also been developed into an active field of research. For instance, applications like
34"
INTRODUCTION,0.02681992337164751,"Web search (e.g. Google, Bing, or even in some versions of ChatGPT), online shopping
35"
INTRODUCTION,0.027586206896551724,"(Amazon, App stores, Google Flights), recommender systems (e.g. Youtube, Netflix, Google
36"
INTRODUCTION,0.028352490421455937,"News/Maps, Spotify) typically involve users expressing preferences by choosing one result (or
37"
INTRODUCTION,0.029118773946360154,"a handful of results) from a subset of offered items and often the objective of the system is to
38"
INTRODUCTION,0.029885057471264367,"identify the ‘most-profitable’ subset to offer to their users. The problem, popularly termed
39"
INTRODUCTION,0.03065134099616858,"as ‘Assortment Optimization’ is studied in many interdisciplinary literature, e.g. Online
40"
INTRODUCTION,0.031417624521072794,"learning and bandits [10], Operations research [40, 2], Game theory [15], RLHF [20, 30], to
41"
INTRODUCTION,0.03218390804597701,"name a few.
42"
INTRODUCTION,0.03295019157088123,"Problem (Informal): Active Optimal Assortment (AOA) Active Assortment Opti-
43"
INTRODUCTION,0.03371647509578544,"mization (a.k.a. Utility Maximization with Subset Choices) [13, 2, 23, 22] is an active
44"
INTRODUCTION,0.034482758620689655,"learning framework for finding the ‘optimal’ profit-maximizing subset. Formally, assume
45"
INTRODUCTION,0.03524904214559387,"we have a decision set of [K] := {1, 2, . . . K} of K items, with each item being associated
46"
INTRODUCTION,0.03601532567049808,"with the score (or utility) parameters θ := (θ1, θ2, . . . , θK) (without loss of generality assume
47"
INTRODUCTION,0.0367816091954023,"θ1 ≥θ2 ≥. . . ≥θK ≥0). At each round t = 1, 2, . . ., the learner or the algorithm gets to
48"
INTRODUCTION,0.037547892720306515,"query an assortment (typically subsets containing up to m-items) St ⊆[K], upon which
49"
INTRODUCTION,0.038314176245210725,"it gets to see some (noisy) relative preferences across the items in St, typically generated
50"
INTRODUCTION,0.03908045977011494,"according to an underlying Plackett-Luce (PL) choice model with parameters θ (1). Further,
51"
INTRODUCTION,0.03984674329501916,"to allow the event where no items are selected, we also model a No-Choice (NC) item, indexed
52"
INTRODUCTION,0.04061302681992337,"by item-0, with PL parameter θ0 ∈R+.
53"
INTRODUCTION,0.041379310344827586,"(Objective 1.) Top-m: identify the top-m item-set: {θ1, . . . , θm}, for some m ∈[1, K].
54"
INTRODUCTION,0.0421455938697318,"(Objective 2.) Wtd-Top-m: A more general objective could also consider a weight (or
55"
INTRODUCTION,0.04291187739463601,"price) ri ∈R+ associated with the item i ∈[K], and the goal could be to identify the
56"
INTRODUCTION,0.04367816091954023,"assortment (subset) with maximum weighted utility 1, as detailed in Sec. 2.
57"
INTRODUCTION,0.044444444444444446,"Related Works and Limitations:
As stated above, the problem of AOA is fundamental
58"
INTRODUCTION,0.045210727969348656,"in many practical scenarios, and thus widely studied in multiple research areas, including
59"
INTRODUCTION,0.04597701149425287,"Online ML/learning theory and operations research.
60"
INTRODUCTION,0.04674329501915709,"• In the Online ML literature, the problem is well-studied as Multi-Dueling Bandits [39, 14],
61"
INTRODUCTION,0.0475095785440613,"or Battling Bandits [35, 34, 11], which is an extension of the famous Dueling Bandit problem
62"
INTRODUCTION,0.04827586206896552,"[46, 45]. The main limitation of this line of work is the lack of practical objectives, which either
63"
INTRODUCTION,0.04904214559386973,"aim to identify the ‘best-item’ 1(= arg maxi∈[K] θi) within a PAC (probably approximately
64"
INTRODUCTION,0.04980842911877394,"correct) framework [36, 16, 17, 31] or quantifying regret against the best items [35, 12]. Note
65"
INTRODUCTION,0.05057471264367816,"the latter actually leads to the optimal subset choice of repeatedly selecting the optimal item,
66"
INTRODUCTION,0.05134099616858238,"arg maxi θi, m times, i.e. (1, 1, . . . 1), which is unrealistic from the viewpoint of real-world
67"
INTRODUCTION,0.05210727969348659,"system design. Selecting an assortment of distinct top-m items (Top-m-AOA) or maximum
68"
INTRODUCTION,0.052873563218390804,"expected utility (Wtd-Top-m-AOA) makes more sense.
69"
INTRODUCTION,0.05363984674329502,"• On the other hand, a similar line of the problem has been studied in operations research
70"
INTRODUCTION,0.05440613026819923,"and dynamic assortment selection literature, where the goal is to offer a subset of items to
71"
INTRODUCTION,0.05517241379310345,"the customers in order to maximize expected revenue. The problem has been studied under
72"
INTRODUCTION,0.055938697318007664,"different user choice models, e.g. PL or Multinomial-Logit models [2], Mallows and mixture of
73"
INTRODUCTION,0.056704980842911874,"Mallows [22], Markov chain-based choice models [23], single transition model [27] etc. While
74"
INTRODUCTION,0.05747126436781609,"these works indeed consider a more practical objective of finding the best assortment (subset)
75"
INTRODUCTION,0.05823754789272031,"with the highest expected utility for a regret minimization objective, (1) a major drawback
76"
INTRODUCTION,0.05900383141762452,"in their approach lies in the algorithm design which requires to keep on querying the same set
77"
INTRODUCTION,0.059770114942528735,"multiple times, e.g. [2, 29, 18, 1]. Such design techniques could be impractical to be deployed
78"
INTRODUCTION,0.06053639846743295,"in real systems where users could easily get annoyed if the same items are shown again and
79"
INTRODUCTION,0.06130268199233716,"again. For example, in ad-placement, music/movies/news/tweets/reels recommendations,
80"
INTRODUCTION,0.06206896551724138,"offering the same assortment could increase user dissatisfaction and disengagement.
81"
INTRODUCTION,0.06283524904214559,"(2) The second major drawback of this line of work lies in the structural assumption of
82"
INTRODUCTION,0.06360153256704981,"their underlying choice models which requires the existence of a reference/default item, that
83"
INTRODUCTION,0.06436781609195402,"needs to be part of every assortment St. This leads to assuming a No-Choice item, typically
84"
INTRODUCTION,0.06513409961685823,"denoted as item-0, which is a default choice of any assortment St. Further a stronger and
85"
INTRODUCTION,0.06590038314176246,"more unrealistic assumption lies in the fact that they require to assume that the above pivot
86"
INTRODUCTION,0.06666666666666667,"is stronger than the rest of the K items, i.e. θ0 ≥maxi∈[K] θi, i.e. the No-Choice (NC)
87"
INTRODUCTION,0.06743295019157088,"action is the most likely outcome of any assortment St. This is often unrealistic, e.g., during
88"
INTRODUCTION,0.0681992337164751,"user interactions with language models, or online shopping, or Route recommendation in
89"
INTRODUCTION,0.06896551724137931,"GPS navigation, a NC action is highly improbable. Consequently, such assumption limits the
90"
INTRODUCTION,0.06973180076628352,"use in real-systems. In the existing literature [2, 28, 1, 24], such assumptions are primarily
91"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.07049808429118774,"1This is equivalent to finding the set with maximum expected revenue when ris represents the
price of item i [2]"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.07126436781609195,"adapted solely for theoretical needs, precisely for maintaining concentration bounds of the
92"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.07203065134099616,"PL parameters θ, and hence not well justified from a practical viewpoint. Some recent
93"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.07279693486590039,"developments also generalized the AOA problem to linear MNL scores to incorporate large
94"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.0735632183908046,"actions embedded in d-dimension [43, 42, 28], however, their approaches are either limited
95"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.0743295019157088,"to the above restrictions or suffer sub-optimal regret guarantees without those assumptions
96"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.07509578544061303,(e.g. the regret bound of [28] is O(d3/2√
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.07586206896551724,"T) which is suboptimal by a d-factor). Considering
97"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.07662835249042145,"the above limitations of the AOA literature, we set to answer two questions:
98"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.07739463601532567,"(1) Can we consider a general AOA model where the default item, like the NC item defined
99"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.07816091954022988,"above, is not necessarily the strongest one, i.e. θ0 ≥maxi∈[K] θi?
100"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.0789272030651341,"(2) Can we design a practical and regret optimal algorithm for the AOA framework, without
101"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.07969348659003832,"needing to play the same repetitive actions and yet converge to the optimal assortment?
102"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.08045977011494253,"Contributions
We answer these questions in the affirmative and present best of all
103"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.08122605363984674,"scenarios. We design practical algorithms on practical AOA framework with practical
104"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.08199233716475096,"objectives–Unlike the existing approaches of the AOA, literature [2, 18], we do not have to
105"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.08275862068965517,"keep playing the same assortment multiple times, neither require a strongest default item
106"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.08352490421455938,"(like NC satisfying θ0 ≥maxi∈[K] θi). Moreover, our objectives do not require us to converge
107"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.0842911877394636,"to a multiset of replicated arms like (1, 1, . . . 1), but converge to the utility-maximizing set of
108"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.08505747126436781,"distinct items. We list our contributions below:
109"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.08582375478927202,"1. A General AOA Setup: We work with a general problem of AOA for PL model,
110"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.08659003831417625,"which requires no additional structural assumption of the θ parameters such as θ0 ≥maxi θi,
111"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.08735632183908046,"unlike the existing works. We designed algorithms for two separate objectives Top-m and
112"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.08812260536398467,"Wtd-Top-m as discussed above (Sec. 2).
113"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.08888888888888889,"2. Practical, Efficient and Optimal Algorithm:
In Sec. 3, we give a practical,
114"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.0896551724137931,"efficient and optimal algorithm for MNL Assortment (up to log factors and the magnitude of
115"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.09042145593869731,"θmax). The regret bound of our algorithm AOA-RBPL (Alg. 1) yields ˜O(
√"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.09118773946360154,"KT) regret for
116"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.09195402298850575,"both Top-m and Wtd-Top-m objective. Our algorithms use a novel parameter estimation
117"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.09272030651340996,"technique for discrete choice models based on the concept of Rank-Breaking (RB) which is
118"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.09348659003831418,"one of our key contributions towards designing the efficient and optimal algorithm. This
119"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.09425287356321839,"enables our algorithm to perform optimally without requiring the No-Choice item to be
120"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.0950191570881226,"the strongest. Appendix A details the key concept of our parameter estimation technique
121"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.09578544061302682,"exploiting the concept of RB. Our resulting algorithm plays optimistically based on the UCB
122"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.09655172413793103,"estimates of PL parameters and does not require repeating the same subset multiple times,
123"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.09731800766283524,"justifying our title.
124"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.09808429118773947,"3. Improvement with Adaptive Pivots:
In Sec. 4, we refine the performance of
125"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.09885057471264368,"our algorithm by employing the novel idea of ‘adaptive pivots’ (a reference item) and
126"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.09961685823754789,"proposed AOA-RBPL-Adaptive. Performance-wise this removes the asymptotic dependence
127"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.10038314176245211,"on θmax = maxi θi/θ0 in the regret analysis. This enables the algorithm to work effectively
128"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.10114942528735632,"in scenarios where the No-Choice item is less likely to be selected, i.e., θmax ≫1. This
129"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.10191570881226053,"leads to a huge improvement in our experiments, especially in the range of low θ0, where
130"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.10268199233716475,"AOA-RBPL-Adaptive drastically outperforms over the existing baseline. Comparison of our
131"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.10344827586206896,"regret bound with existing work is detailed in Table 1.
132"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.10421455938697317,"4. Emperical Analysis.
Finally, we corroborate our theoretical results with empirical
133"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.1049808429118774,"evaluations (Sec. 5), which certify our superior performance in the general AOA setups.
134"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.10574712643678161,"Work
Framework
Assume θ0 = θmax = 1
Regret
Our (Alg. 1)
MNL model (Obj. 2)
No p"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.10651340996168582,"min{θmax, K}KT log T
[2] (Thm 1)
MNL model (Obj. 2)
Yes
√KT log T
[2] (Thm 4)
MNL model (Obj. 2)
No
√θmaxKT log T
[1]
MNL model (Obj. 2)
Yes p"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.10727969348659004,KT log(mT) + K log2(mT)
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.10804597701149425,"[24]
MNL model with
No q"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.10881226053639846,"KT
mini ri log T
constraints (Obj. 2)"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.10957854406130269,Table 1: Our Contribution vs the Existing Results in the K-armed MNL-Assortment literature
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.1103448275862069,"It is also worth mentioning that our proposed algorithm and their respective regret analysis
135"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.1111111111111111,"could be extended to any general random utility (RUM) based preference models [38, 37],
136"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.11187739463601533,"as explained in Rem. 1. However, to keep the focus on the AOA problem and ease the
137"
THIS IS EQUIVALENT TO FINDING THE SET WITH MAXIMUM EXPECTED REVENUE WHEN RIS REPRESENTS THE,0.11264367816091954,"presentation, we stick to the special case of MNL choice model based preferences.
138"
PROBLEM SETUP,0.11340996168582375,"2
Problem Setup
139"
PROBLEM SETUP,0.11417624521072797,"We write [n] = {1, 2, ..., n} and 1{·} denotes the indicator function. The symbol ≲, employed
140"
PROBLEM SETUP,0.11494252873563218,"in the proof sketches, represents a coarse inequality.
141"
PROBLEM SETUP,0.11570881226053639,"We consider the sequential decision-making problem of Active Optimal Assortment (AOA),
142"
PROBLEM SETUP,0.11647509578544062,"with preference/choice feedback. Formally, the learner is given [K], a finite set of K items
143"
PROBLEM SETUP,0.11724137931034483,"(K > 2). At each decision round t = 1, 2, . . ., the learner selects a subset St ⊆[K] of up to
144"
PROBLEM SETUP,0.11800766283524904,"m items, and receives some (stochastic) feedback about the item preferences of St, drawn
145"
PROBLEM SETUP,0.11877394636015326,"according to some unknown underlying Plackett-Luce (PL) choice model (1) with parameters
146"
PROBLEM SETUP,0.11954022988505747,"θ = (θ1, θ2, . . . , θK) ∈RK
+ . We assume θ1 ≥θ2 ≥. . . ≥θK without loss of generality. An
147"
PROBLEM SETUP,0.12030651340996168,"interested reader may check App. A.1 for a detailed discussion on PL models. Given any
148"
PROBLEM SETUP,0.1210727969348659,"assortment St we also consider the possibility of ‘no-selection’ of any items given an St.
149"
PROBLEM SETUP,0.12183908045977011,"Following the literature of [2], we model this mathematically as a No-Choice (NC) item,
150"
PROBLEM SETUP,0.12260536398467432,"indexed by item-0, and its corresponding PL utility parameter θ0. Unlike most existing
151"
PROBLEM SETUP,0.12337164750957855,"literature on assortment selection, we are not assuming θ0 ̸≥maxi∈[K] θi. Further, since the
152"
PROBLEM SETUP,0.12413793103448276,"PL model is scale independent, we set θ0 = 1 and scale the rest of the PL parameters.
153"
PROBLEM SETUP,0.12490421455938697,"Feedback model
The feedback model formulates the information received (from the
154"
PROBLEM SETUP,0.12567049808429118,"‘environment’) once the learner plays a subset St ⊆[K] of at most m items. Given St we
155"
PROBLEM SETUP,0.12643678160919541,"consider the algorithm receives a winner feedback (or index of an item) it ∈St ∪{0}, drawn
156"
PROBLEM SETUP,0.12720306513409962,"according to the underlying PL choice model as:
157"
PROBLEM SETUP,0.12796934865900383,"P(it = i|St) = θi/
 
θ0 + P"
PROBLEM SETUP,0.12873563218390804,"j∈St θj

,
∀i ∈St.
(1)"
PROBLEM SETUP,0.12950191570881225,"We consider the following two objectives for the learner:
158"
PROBLEM SETUP,0.13026819923371646,"1.
Top-m-Ojective.
One simple objective could be to identify the top-m item-set:
159"
PROBLEM SETUP,0.1310344827586207,"{θ1, . . . , θm}, for some m ∈[1, K]. The performance of the learner can be captured by
160"
PROBLEM SETUP,0.1318007662835249,"minimizing the following regret:
161"
PROBLEM SETUP,0.13256704980842912,"Regtop
T
:= T
X t=1"
PROBLEM SETUP,0.13333333333333333,ΘS∗−ΘSt
PROBLEM SETUP,0.13409961685823754,"m
,
where
S∗:=
argmax
S⊆[K]:|S|=m"
PROBLEM SETUP,0.13486590038314175,"n
ΘS :=
X"
PROBLEM SETUP,0.135632183908046,"i∈S
θi
o
."
PROBLEM SETUP,0.1363984674329502,"2. Wtd-Top-m-Objective.
Here, each item-i is associated with a weight (for example
162"
PROBLEM SETUP,0.1371647509578544,"price) ri ∈R+, and the goal is to identify the set of size at most m with maximum weighted
163"
PROBLEM SETUP,0.13793103448275862,"utility. One could measure the regret of the learner as:
164"
PROBLEM SETUP,0.13869731800766283,"Regwtd
T
:= T
X"
PROBLEM SETUP,0.13946360153256704,"t=1
(R(S∗, θ) −R(St, θ)), where R(S, θ) :=
X i∈S"
PROBLEM SETUP,0.14022988505747128,"riθi
θ0 + P"
PROBLEM SETUP,0.1409961685823755,"j∈S θj
, ∀S ⊆[K],
(2)"
PROBLEM SETUP,0.1417624521072797,"denotes S∗:= argmaxS⊆[K]||S|≤m R(S, θ) is the optimal utility-maximizing subset. This
165"
PROBLEM SETUP,0.1425287356321839,"objective corresponds to the standard objective in the MNL litterature [2].
166"
A PRACTICAL AND EFFICIENT ALGORITHM FOR AOA WITH PL,0.14329501915708812,"3
A Practical and Efficient Algorithm for AOA with PL
167"
A PRACTICAL AND EFFICIENT ALGORITHM FOR AOA WITH PL,0.14406130268199233,"In this section, we introduce our first algorithm, which works for both objectives.
168"
ALGORITHM DESIGN,0.14482758620689656,"3.1
Algorithm Design
169"
ALGORITHM DESIGN,0.14559386973180077,"At each time t, our algorithm (Alg. 1) maintains a pairwise preference matrix bPt ∈[0, 1]n×n,
170"
ALGORITHM DESIGN,0.14636015325670498,"whose (i, j)-th entry bpij,t records the empirical probability of i having beaten j in a pairwise
171"
ALGORITHM DESIGN,0.1471264367816092,"duel, and a corresponding upper confidence bound pucb
ij,t. Let [ ˜K] := [K] ∪{0}. We define for
172"
ALGORITHM DESIGN,0.1478927203065134,"each pair (i, j) ∈[ ˜K] × [ ˜K],
173"
ALGORITHM DESIGN,0.1486590038314176,"pucb
ij,t := bpij,t + s"
ALGORITHM DESIGN,0.14942528735632185,"2bpij,t(1 −bpij,t)x"
ALGORITHM DESIGN,0.15019157088122606,"nij,t
+ 3x"
ALGORITHM DESIGN,0.15095785440613027,"nij,t
,
where
bpij,t := wij,t"
ALGORITHM DESIGN,0.15172413793103448,"nij,t
,
(3)"
ALGORITHM DESIGN,0.1524904214559387,"where wij,t = Pt−1
s=1 1{is = i, j ∈Ss} denotes the number of pairwise wins of item-i over j
174"
ALGORITHM DESIGN,0.1532567049808429,"and nij,t = wij,t +wji,t being the number of times (i, j) has been compared. The above UCB
175"
ALGORITHM DESIGN,0.15402298850574714,"estimates pucb
ij,t are further used to design UCB estimates of the PL parameters θi as follows
176"
ALGORITHM DESIGN,0.15478927203065135,"θucb
i,t = pucb
i0,t/(1 −pucb
i0,t)+."
ALGORITHM DESIGN,0.15555555555555556,"The estimates θucb
i,t s are then used to select the set St, that maximizes the underlying objective.
177"
ALGORITHM DESIGN,0.15632183908045977,"This optimization problem transforms into a static assortment optimization problem with
178"
ALGORITHM DESIGN,0.15708812260536398,"upper confidence bounds θucb
i,t as the parameters, and efficient solution methods for this case
179"
ALGORITHM DESIGN,0.1578544061302682,"are available (see e.g., [7, 21, 32]).
180"
ALGORITHM DESIGN,0.15862068965517243,Algorithm 1 AOA for PL model with RB (AOA-RBPL)
ALGORITHM DESIGN,0.15938697318007664,"1: input: x > 0
2: init: ˜K ←K + 1, [ ˜K] = [K] ∪{0}, W1 ←[0] ˜
K× ˜
K
3: for t = 1, 2, 3, . . . , T do
4:
Set Nt = Wt + W⊤
t , and bPt = Wt"
ALGORITHM DESIGN,0.16015325670498085,"Nt . Denote Nt = [nij,t] ˜
K× ˜
K and bPt = [bpij,t] ˜
K× ˜
K."
ALGORITHM DESIGN,0.16091954022988506,"5:
Define for all i, pucb
ii,t = 1"
ALGORITHM DESIGN,0.16168582375478927,"2 and for all i, j ∈[ ˜K], i ̸= j"
ALGORITHM DESIGN,0.16245210727969348,"pucb
ij,t = bpij,t +

2bpij,t(1−bpij,t)x nij,t"
ALGORITHM DESIGN,0.1632183908045977,"1/2
+
3x
nij,t"
ALGORITHM DESIGN,0.16398467432950192,"6:
θucb
i,t := pucb
i0,t/(1 −pucb
i0,t)+"
ALGORITHM DESIGN,0.16475095785440613,"7:
St ←"
ALGORITHM DESIGN,0.16551724137931034,"


 

"
ALGORITHM DESIGN,0.16628352490421455,"Top-m items from argsort({θucb
1,t , . . . , θucb
K,t}),
for Top-m objective
argmaxS⊆[K]||S|≤m R(S, θucb
t
),
for Wtd-Top-m objective
8:
Play St
9:
Receive the winner it ∈[ ˜K] (drawn as per (1))
10:
Update: Wt+1 = [wij,t+1] ˜
K× ˜
K s.t. witj,t+1 ←witj,t + 1 ∀j ∈St ∪{0}
11: end for"
ALGORITHM DESIGN,0.16704980842911876,"3.2
Analysis: Concentration Lemmas
181"
ALGORITHM DESIGN,0.167816091954023,"We start the analysis by providing two technical lemmas, whose proofs are deferred to the
182"
ALGORITHM DESIGN,0.1685823754789272,"appendix and that provide confidence bounds for the θi.
183"
ALGORITHM DESIGN,0.16934865900383142,"Lemma 1. Let T ≥1 and x > 0. Then, with probability at least 1 −3KTe−x, for all t ∈[T]
184"
ALGORITHM DESIGN,0.17011494252873563,"and i ∈[K]: θi ≤θucb
i,t
atleast one of the following two inequalities is satisfied
185"
ALGORITHM DESIGN,0.17088122605363984,"ni0,t < 69x(θ0 + θi)
or
θucb
i,t ≤θi + 4(θ0 + θi) s"
ALGORITHM DESIGN,0.17164750957854405,2θ0θix
ALGORITHM DESIGN,0.1724137931034483,"ni0,t
+ 22x(θ0 + θi)2"
ALGORITHM DESIGN,0.1731800766283525,"ni0,t
."
ALGORITHM DESIGN,0.1739463601532567,"The above lemma depends on ni0,t the number of times items i have been compared with
186"
ALGORITHM DESIGN,0.17471264367816092,"item 0 up to round t. The latter is controlled using the following lemma:
187"
ALGORITHM DESIGN,0.17547892720306513,"Lemma 2. Let T ≥1 and x > 0. Then, with probability at least 1 −KTe−x: simultaneously
188"
ALGORITHM DESIGN,0.17624521072796934,"for all t ∈[T] and i ∈[K]
189"
ALGORITHM DESIGN,0.17701149425287357,"τi,t < 2x(θ0 + ΘS∗)2 or ni0,t ≥(θ0 + θi)τi,t"
ALGORITHM DESIGN,0.17777777777777778,"2(θ0 + ΘS∗) ,
(4)"
ALGORITHM DESIGN,0.178544061302682,"where τi,t = Pt−1
s=1 1{i ∈Ss} denotes the number of rounds item i got selected before round t.
190"
ALGORITHM DESIGN,0.1793103448275862,"3.3
Analysis: Top-m Objective:
191"
ALGORITHM DESIGN,0.18007662835249041,"We are now ready to provide the regret upper bound for Algorithm 1 with Top-m objective.
192"
ALGORITHM DESIGN,0.18084291187739462,"Theorem 3 (Top-m Objective). Let θmax ≥1. Consider any instance of PL model on K
193"
ALGORITHM DESIGN,0.18160919540229886,"items with parameters θ ∈[0, θmax]K, θ0 = 1. The regret of Alg. 1 with parameter x = 2 log T
194"
ALGORITHM DESIGN,0.18237547892720307,"is bounded as
195"
ALGORITHM DESIGN,0.18314176245210728,"Regtop
T
= O
 
θ3/2
max
p"
ALGORITHM DESIGN,0.1839080459770115,"KT log T

when T →∞."
ALGORITHM DESIGN,0.1846743295019157,"The above rate of ˜O(KT) is optimal (up to log-factors), as a lower bound can be derived from
196"
ALGORITHM DESIGN,0.1854406130268199,"standard multi-armed bandits [5, 6]. We only state here a sketch of the proof of Theorem 3.
197"
ALGORITHM DESIGN,0.18620689655172415,"The detailed proof is deferred to the App. B.
198"
ALGORITHM DESIGN,0.18697318007662836,"Proof Sketch of Theorem 3. Let us define for any S ⊆[K],
199"
ALGORITHM DESIGN,0.18773946360153257,"ΘS =
X"
ALGORITHM DESIGN,0.18850574712643678,"i∈S
θi,
and
Θucb
S
:=
X"
ALGORITHM DESIGN,0.189272030651341,"i∈S
θucb
i
."
ALGORITHM DESIGN,0.1900383141762452,"Let E be the high-probability event such that both Lemma 1 and 2 holds true. Then, P(E) ≥
200"
ALGORITHM DESIGN,0.19080459770114944,"1 −4TKe−x. Let us first assume that E holds true. Then, by Lemma 1, ΘS∗≤Θucb
S∗≤Θucb
St ,
201"
ALGORITHM DESIGN,0.19157088122605365,"which yields
202"
ALGORITHM DESIGN,0.19233716475095786,"Regtop
T
= 1 m T
X"
ALGORITHM DESIGN,0.19310344827586207,"t=1
ΘS∗−ΘSt ≤1 m T
X"
ALGORITHM DESIGN,0.19386973180076628,"t=1
Θucb
St −ΘSt ≲τ0 + 1 m T
X t=1 X"
ALGORITHM DESIGN,0.1946360153256705,"i∈St
(θucb
i,t −θi)1

τi,t ≥τ0
	
,"
ALGORITHM DESIGN,0.19540229885057472,"where τ0 = 138x(m + 1)2θ2
max corresponds to an exploration phase needed for the confidence
203"
ALGORITHM DESIGN,0.19616858237547893,"upper bounds of Lem 1 and 2 to be satisfied. Then, noting that if E holds true, we can show
204"
ALGORITHM DESIGN,0.19693486590038314,"by Lemma 2, that 1{τi,t ≥τ0} ≤1{ni0,t ≥69x(θ0 + θi)}. Therefore, we can apply Lemma 1
205"
ALGORITHM DESIGN,0.19770114942528735,"that entails,
206"
M,0.19846743295019156,"1
m T
X t=1 X"
M,0.19923371647509577,"i∈St
(θucb
i,t −θi)1

τi,t ≥¯ni0
	
≲1 m T
X t=1 X i∈St"
M,0.2,"
(θ0 + θi) s θ0θix"
M,0.20076628352490422,"ni0,t
1

τi,t ≥τ0
	"
M,0.20153256704980843,"Lem. 2
≲
1
m T
X t=1 X"
M,0.20229885057471264,"i∈St
θ3/2
max rmx"
M,0.20306513409961685,"τi,t
≲1 m K
X"
M,0.20383141762452106,"i=1
θ3/2
max
√mxτi,t ≲θ3/2
max
√ xKT ."
M,0.2045977011494253,"where we used Pn
i=1 1/
√"
M,0.2053639846743295,i ≤2√n and P
M,0.20613026819923372,"i τi,t = mT together with Jensen’s inequality in the
207"
M,0.20689655172413793,"last inequality. We thus have under the event E that Regtop
T
≤O(θ3/2
max
√"
M,0.20766283524904214,"xKT) and the proof
208"
M,0.20842911877394635,"is concluded by taking the expectation with x = 2 log T to control P(Ec).
209"
M,0.20919540229885059,"3.4
Analysis: Wtd-Top-m Objective
210"
M,0.2099616858237548,"We turn now to the analysis of the Wtd-Top-m objective (2). We start by stating a lemma
211"
M,0.210727969348659,"from [2] that shows that the expected utility R(S∗, θ) that corresponds to the optimal
212"
M,0.21149425287356322,"assortment S∗= argmaxS⊂[K],|S|≤m R(S, θ) is non-decreasing in the parameters θ.
213"
M,0.21226053639846743,"Lemma 4 (Lemma A.3 of [2]). Assume θucb
i
≥θi for all i ∈[K], then R(S∗, θ) ≤R(S∗, θucb).
214"
M,0.21302681992337164,"Theorem 5 (Wtd-Top-m Objective). Let θmax ≥1. Then, for any θ ∈[0, θmax]K and
215"
M,0.21379310344827587,"weights r ∈[0, 1]K, the weighted regret of AOA-RBPL (Alg. 1) with x = 2 log T
216"
M,0.21455938697318008,"Regwtd
T
= O(
p"
M,0.2153256704980843,"θmaxKT log T)
when
T →∞."
M,0.2160919540229885,"The complete proof is postponed to App. B. The rate Ω(
√"
M,0.2168582375478927,"KT) is optimal as proved by the
217"
M,0.21762452107279692,"lower bound in [19] for MNL bandit problems for θmax = 1. Our result recovers (up to a factor
218
√log T) the one of [2] when θmax = 1. However, their algorithm relies on more sophisticated
219"
M,0.21839080459770116,"estimators that necessitate epochs repeating the same assortment until the No-Choice item
220"
M,0.21915708812260537,"is selected. Note for our problem setting, where it is possible to have θmax ≫θ0 = 1, the
221"
M,0.21992337164750958,"length of these epochs could be of O(Kθmax), which could be potentially very large when
222"
M,0.2206896551724138,"θmax ≫1. This reduces the number of effective epochs, leading to poor estimation of the PL
223"
M,0.221455938697318,"parameters. We see this tradeoff in our experiments (Sec. 5) where the MNL-UCB algorithm
224"
M,0.2222222222222222,"of [2] yields linear O(T) regret for such choice of the problem parameters.
225"
M,0.22298850574712645,"Remark 1 (Beyond MNL Models). Although, in this paper, we primarily focused on MNL
226"
M,0.22375478927203066,"based choice models, it is worth mentioning that our proposed algorithms can be generalized
227"
M,0.22452107279693487,"to more general random utility based models (RUMs) [9, 33] pursuing the ideas from [36]
228"
M,0.22528735632183908,"that extends the RB based parameter estimation technique to any RUM(θ) choice models.
229"
M,0.2260536398467433,"Our algorithms and analyses thus apply to any general RUM(θ) based choice models; we stick
230"
M,0.2268199233716475,"to the special case of MNL models in this paper for brevity and keep the main focus on the
231"
M,0.22758620689655173,"AOA problem and the related algorithmic novelties.
232"
M,0.22835249042145594,"Proof sketch of Thm. 5. Let E be the high-probability event such that both Lemma 1 and 2
233"
M,0.22911877394636015,"are satisfied. Then,
234"
M,0.22988505747126436,"Regwtd
T
= T
X"
M,0.23065134099616857,"t=1
E

R(S∗, θ) −R(St, θ)

≲ T
X"
M,0.23141762452107278,"t=1
E

(R(S∗, θ) −R(St, θ))1{E}

+ TP(Ec) ≲ T
X"
M,0.23218390804597702,"t=1
E

(R(St, θucb
t
) −R(St, θ))1{E}

+ TP(Ec)
(5)"
M,0.23295019157088123,"because R(St, θucb
t
) ≥R(S∗, θucb
t
) ≥R(S∗, θ) under the event E by Lemma 4. We now
235"
M,0.23371647509578544,"upper-bound the first term of the right-hand-side
236 T
X"
M,0.23448275862068965,"t=1
E
h 
R(St, θucb
t
) −R(St, θ)

1{E}
i
= T
X"
M,0.23524904214559386,"t=1
E
 X i∈St"
M,0.23601532567049807,"riθucb
i,t
θ0 + Θucb
St,t
−
riθi
θ0 + ΘSt"
M,0.2367816091954023,"
1{E}
 ≤ T
X"
M,0.23754789272030652,"t=1
E
 X i∈St"
M,0.23831417624521073,"ri(θucb
i,t −θi)
θ0 + ΘSt"
M,0.23908045977011494,"
1{E}"
M,0.23984674329501915,"Because Θucb
St,t ≥ΘSt under the event E by Lemma 1. Then, using ri ≤1, we further upper-
237"
M,0.24061302681992336,"bound using an exploration parameter τ0 = O(log(T)) so that the upper-confidence-bounds
238"
M,0.2413793103448276,"in Lemmas 1 and 2 are satisfied
239 T
X"
M,0.2421455938697318,"t=1
E
h 
R(St, θucb
t
) −R(St, θ)

1{E}
i
≤ K
X i=1
E ""
T
X t=1"
M,0.24291187739463602,"|θucb
i,t −θi|
θ0 + ΘSt"
M,0.24367816091954023,"
1{i ∈St, E} #"
M,0.24444444444444444,"≲O(τ0) + K
X i=1
E ""
T
X t=1"
M,0.24521072796934865,"|θucb
i,t −θi|
θ0 + ΘSt
1{i ∈St, τi,t ≥τ0, E} #"
M,0.24597701149425288,"≲O(τ0) + K
X i=1"
M,0.2467432950191571,"v
u
u
t T
X t=1
E"
M,0.2475095785440613,"""
θi1{i ∈St}"
M,0.2482758620689655,θ0 + ΘSt # ×
M,0.24904214559386972,"v
u
u
t T
X t=1
E"
M,0.24980842911877393,""" θucb
i,t −θi
θ0 + ΘSt"
M,0.25057471264367814,2 θ0 + ΘSt
M,0.25134099616858235,"θi
1{i ∈St, τi,t ≥τ0, E} #"
M,0.25210727969348656,"|
{z
}
=:AT (i)
(6)"
M,0.25287356321839083,"where the last inequality is by Cauchy-Schwarz inequality. Now, the term AT (i) above may
240"
M,0.25363984674329504,"be upper-bounded using Lemmas 1 and 2,
241"
M,0.25440613026819925,AT (i) = E
M,0.25517241379310346,"""
(θucb
i,t −θi)2"
M,0.25593869731800767,"θi(θ0 + ΘSt)1{i ∈St, τi,t ≥τ0, E} # ≲ T
X t=1
E"
M,0.2567049808429119,"""
(θ0 + θi)2x
ni0,t(θ0 + ΘSt)1{i ∈St} #"
M,0.2574712643678161,"≲θmaxx T
X t=1
E"
M,0.2582375478927203,"""
(θ0 + θi)1{i ∈St}"
M,0.2590038314176245,"(θ0 + ΘSt)ni0,t #"
M,0.2597701149425287,"= θmaxxE ""
T
X t=1"
M,0.26053639846743293,"1{it ∈{i, 0}, i ∈St} ni0,t #"
M,0.26130268199233714,≲θmaxx log T
M,0.2620689655172414,"where in the last inequality we used that PT
n=1 n−1 ≤1 + log T. Substituting into (6),
242"
M,0.2628352490421456,"Jensen’s inequality entails,
243 T
X"
M,0.2636015325670498,"t=1
E
h 
R(St, θucb
t
)−R(St, θ)

1{E}
i
≲O(τ0)+E ""
p"
M,0.26436781609195403,"θmaxx log T K
X i=1"
M,0.26513409961685824,"v
u
u
t T
X t=1"
M,0.26590038314176245,θi1{i ∈St}
M,0.26666666666666666,θ0 + ΘSt # . (7)
M,0.2674329501915709,"The proof is finally concluded by applying Cauchy-Schwarz inequality which yields:
244 K
X i=1"
M,0.2681992337164751,"v
u
u
t T
X t=1"
M,0.2689655172413793,θi1{i ∈St}
M,0.2697318007662835,"θ0 + ΘSt
≤"
M,0.2704980842911877,"v
u
u
tK T
X t=1"
M,0.271264367816092,"PK
i=1 θi1{i ∈St}"
M,0.2720306513409962,"θ0 + ΘSt
≤
√ KT ."
M,0.2727969348659004,"Finally, combining the above result with (5) and (7) concludes the proof
245"
M,0.2735632183908046,"Regwtd
T
≲TP(Ec) + O(τ0) +
p"
M,0.2743295019157088,θmaxxKT log T .
M,0.275095785440613,"Choosing x = 2 log T ensures TP(Ec) ≤O(1) and τ0 ≤O(log T).
246"
M,0.27586206896551724,"4
Improved dependance on θmax with Adaptive Pivot Selection
247"
M,0.27662835249042145,"A problem with Algorithm 1 stems from estimating all θi based on pairwise comparisons with
248"
M,0.27739463601532566,"item 0. When θmax ≫θ0 = 1, item 0 may not be sampled enough as the winner, leading to
249"
M,0.27816091954022987,"poor estimators. This deficiency contributes to the suboptimal dependence on θmax observed
250"
M,0.2789272030651341,"in Theorems 3 and 5 and in prior work, such as [2]. We propose the following fix to optimize
251"
M,0.2796934865900383,"the pivot. For all i, j ∈[K] ∪{0} we define γij = θi"
M,0.28045977011494255,"θj , and the estimators:
252"
M,0.28122605363984676,"γucb
ij,t = pucb
ij,t/(1 −pucb
ij,t)+
and
γucb
ii,t = 1 ,"
M,0.281992337164751,"where pucb
ij,t are defined in (3). For all rounds t, the algorithm AOA-RBPL-Adaptive selects
253"
M,0.2827586206896552,"St = argmax
|S|≤m
R(S, bθucb
t
)
where
bθucb
i,t :=
min
j∈[K]∪{0} γucb
ij,tγucb
j0,t ."
M,0.2835249042145594,"We offer below a regret bound that underscores the value of optimizing the pivot when
254"
M,0.2842911877394636,"θmax ≫K. Note that while the algorithm and analysis are presented for the weighted
255"
M,0.2850574712643678,"objective with winner feedback only, it can be adapted to other objectives by replacing
256"
M,0.285823754789272,"R(S, θ) with the new objective in the analysis, as long as Lemma 4 remains valid.
257"
M,0.28659003831417623,"Theorem 6. Let θmax ≥1. For any θ ∈[0, θmax]K and weights r ∈[0, 1]K, the weighted
258"
M,0.28735632183908044,"regret of AOA-RBPL-Adaptive is upper-bounded as
259"
M,0.28812260536398465,"Regwtd
T
= O
 p"
M,0.28888888888888886,"min{θmax, K}KT log T
"
M,0.2896551724137931,"as T →∞for the choice x = 2 log T (when definining pucb
ij,t).
260"
M,0.29042145593869734,"Asymptotically, when θmax is constant, the regret is O(K
√"
M,0.29118773946360155,"T log T), eliminating any depen-
261"
M,0.29195402298850576,"dence on θmax. This allows for handling scenarios where the No-Choice item is highly unlikely,
262"
M,0.29272030651340997,"which is not achievable in previous works such as [2, 1]. [2] did attempt in their Thm. 4 to
263"
M,0.2934865900383142,"relax the assumption of θmax = θ0 and shows a bound of order O
 
max{θmax/θ0, 1}1/2√"
M,0.2942528735632184,"KT

,
264"
M,0.2950191570881226,"which unfortunately blows to ∞as θ0 →0 or equivalently θmax →∞, leading to a vac-
265"
M,0.2957854406130268,"uous bound. Here, lies the stark improvement and one of the key contributions, as also
266"
M,0.296551724137931,"corroborated in our experimental evaluation Sec. 5 (Fig. 2).
267"
M,0.2973180076628352,"The proof is deferred to the App. B, with a key step relying on selecting the pivot
268"
M,0.29808429118773944,"jt = argmaxj∈St∪{0} θj.
The use of |bθucb
i,t −θi| ≤|γucb
ijt,t −θi| provides confidence upper-
269"
M,0.2988505747126437,"bounds with an improved dependence on θmax , leveraging the fact that θjt ≥θi. Due
270"
M,0.2996168582375479,"to the varying pivot over time, a telescoping argument introduces an additive factor
√"
M,0.3003831417624521,"K.
271"
EXPERIMENTS,0.30114942528735633,"5
Experiments
272"
EXPERIMENTS,0.30191570881226054,"We provide here a synthetic experiments. All results are averaged across 100 runs. We
273"
EXPERIMENTS,0.30268199233716475,"evaluate the performance of our main algorithm AOA-RBPL-Adaptive (Sec. 4), referred
274"
EXPERIMENTS,0.30344827586206896,"as “Our Alg-1 (Adaptive Pivot)"", with the following two algorithms: AOA-RBPL (Sec. 3)
275"
EXPERIMENTS,0.30421455938697317,"referred as “Our Alg-2 (No-Choice Pivot)"", and MNL-UCB, the state-of-the-art algorithm
276"
EXPERIMENTS,0.3049808429118774,"for AOA ([2], Alg. 1).
277"
EXPERIMENTS,0.3057471264367816,"Different PL (θ) Environments. We report our experiment results on two datasets with
278"
EXPERIMENTS,0.3065134099616858,"K = 50 items: (1) Arith50 with PL parameters θi = 1 −(i −1)0.2, ∀i ∈[50]. (2) Bad50
279"
EXPERIMENTS,0.30727969348659,"with PL parameters θi = 0.6, ∀i ∈[50] \ {25} and θ25 = 0.8. For simplicity of computing
280"
EXPERIMENTS,0.3080459770114943,"the assortment choices St, we assume ri = 1, ∀i ∈[K].
281"
EXPERIMENTS,0.3088122605363985,"(1). Averaged Regret with weak NC (θmax/θ0 ≫1) (Fig. 1): In our first experiment,
282"
EXPERIMENTS,0.3095785440613027,"we set set m = 5 and θ0/θmax = 0.01 and report the average regret of the above three
283"
EXPERIMENTS,0.3103448275862069,algorithms for our two objectives.
EXPERIMENTS,0.3111111111111111,"Figure 1: Averaged Regret for m = 5, θ0 = 0.01
284"
EXPERIMENTS,0.3118773946360153,"Fig. 1 shows that our algorithm AOA-RBPL-Adaptive (with adaptive pivot) significantly
285"
EXPERIMENTS,0.31264367816091954,"outperforms the other two algorithms, while our algorithm AOA-RBPL with no-choice (NC)
286"
EXPERIMENTS,0.31340996168582375,"pivot still outperforms MNL-UCB.
287"
EXPERIMENTS,0.31417624521072796,"(2). Averaged Regret vs No-Choice PL Parameter (θmax/θ0) (Fig. 2): In this
288"
EXPERIMENTS,0.31494252873563217,"experiment, we evaluate the regret performance of our algorithm AOA-RBPL-Adaptive. We
289"
EXPERIMENTS,0.3157088122605364,"report the experiment on Artith50 PL dataset and set the subsetsize m = 5, θmax/θ0 =
290"
EXPERIMENTS,0.3164750957854406,"{1, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001}. Fig. 2 shows the increase in the performance gap between
291"
EXPERIMENTS,0.31724137931034485,"our algorithm AOA-RBPL-Adaptive (with adaptive pivot) with decreasing θ0/θmax.
292"
EXPERIMENTS,0.31800766283524906,"Figure 2: Comparative performance
for varying θ0/θmax, m = 5"
EXPERIMENTS,0.31877394636015327,"Figure 3: Tradofff: Averaged Regret vs
length of the k rank-ordered feedback 293"
EXPERIMENTS,0.3195402298850575,"(3). Averaged Regret vs Length of the rank-ordered feedback (k) (Fig. 3): We
294"
EXPERIMENTS,0.3203065134099617,"also run a thought experiment to understand the tradeoff between learning rate with k-length
295"
EXPERIMENTS,0.3210727969348659,"rank-ordered feedback, where given any assortment St ⊆[K] of size m, the learner gets to
296"
EXPERIMENTS,0.3218390804597701,"see the top-k draws (k ≤m) from the PL model without replacement. This is a stronger
297"
EXPERIMENTS,0.3226053639846743,"feedback than the winner (i.e. top-1 for k = 1) feedback and, as expected, we see in Fig. 3
298"
EXPERIMENTS,0.32337164750957853,"an improved regret (for both notions) when increasing k. The experiment are run on the
299"
EXPERIMENTS,0.32413793103448274,"Artith50 dataset with m = 30 and k ∈{1, 2, 4, 8}.
300"
CONCLUSION,0.32490421455938695,"6
Conclusion
301"
CONCLUSION,0.32567049808429116,"We address the Active Optimal Assortment Selection problem with PL choice models, in-
302"
CONCLUSION,0.3264367816091954,"troducing a versatile framework (AOA) that eliminates the need for a strong default item,
303"
CONCLUSION,0.32720306513409964,"typically assumed as the No-Choice (NC) item in the existing literature. Our proposed
304"
CONCLUSION,0.32796934865900385,"algorithms employ a novel ’Rank-Breaking’ technique to establish tight concentration guar-
305"
CONCLUSION,0.32873563218390806,"antees for estimating the score parameters of the PL model. Our approach stands out for
306"
CONCLUSION,0.32950191570881227,"its practicality and avoids the suboptimal practice of repeatedly selecting the same set of
307"
CONCLUSION,0.3302681992337165,"items until the default item prevails. This is beneficial when the default item’s quality
308"
CONCLUSION,0.3310344827586207,"(θ0) is significantly lower than the quality of the best item (θmax). Our algorithms are
309"
CONCLUSION,0.3318007662835249,"computationally efficient, optimal (up to log factors), and free from restrictive assumptions
310"
CONCLUSION,0.3325670498084291,"on the default item.
311"
CONCLUSION,0.3333333333333333,"Future Works.
Among many interesting questions to address in the future, it will be
312"
CONCLUSION,0.3340996168582375,"interesting to understand the role of the No-Choice (NC) item in the algorithm design,
313"
CONCLUSION,0.3348659003831418,"precisely, can we design efficient algorithms without the existence of NC items with a regret
314"
CONCLUSION,0.335632183908046,"rate still linear in θmax? Further, it will be interesting to extend our results to more general
315"
CONCLUSION,0.3363984674329502,"choice models beyond the PL model [18, 22, 23]. What is the tradeoff between the subsetsize
316"
CONCLUSION,0.3371647509578544,"m and the regret for such general choice models? Extending our results to large (potentially
317"
CONCLUSION,0.33793103448275863,"infinite) decision spaces and contextual settings would also be a very useful and practical
318"
CONCLUSION,0.33869731800766284,"contribution to the literature of assortment optimization.
319"
REFERENCES,0.33946360153256705,"References
320"
REFERENCES,0.34022988505747126,"[1] Shipra Agrawal, Vashist Avadhanula, Vineet Goyal, and Assaf Zeevi. Thompson sampling for
321"
REFERENCES,0.34099616858237547,"the mnl-bandit. In Conference on learning theory, pages 76–78. PMLR, 2017.
322"
REFERENCES,0.3417624521072797,"[2] Shipra Agrawal, Vashist Avadhanula, Vineet Goyal, and Assaf Zeevi. Mnl-bandit: A dynamic
323"
REFERENCES,0.3425287356321839,"learning approach to assortment selection. Operations Research, 67(5):1453–1485, 2019.
324"
REFERENCES,0.3432950191570881,"[3] Nir Ailon, Zohar Karnin, and Thorsten Joachims. Reducing dueling bandits to cardinal bandits.
325"
REFERENCES,0.34406130268199236,"In International Conference on Machine Learning, pages 856–864. PMLR, 2014.
326"
REFERENCES,0.3448275862068966,"[4] Jean-Yves Audibert, Rémi Munos, and Csaba Szepesvári. Exploration–exploitation tradeoff
327"
REFERENCES,0.3455938697318008,"using variance estimates in multi-armed bandits. Theoretical Computer Science, 410(19):1876–
328"
REFERENCES,0.346360153256705,"1902, 2009.
329"
REFERENCES,0.3471264367816092,"[5] Peter Auer. Using upper confidence bounds for online learning. In Foundations of Computer
330"
REFERENCES,0.3478927203065134,"Science, 2000. Proceedings. 41st Annual Symposium on, pages 270–279. IEEE, 2000.
331"
REFERENCES,0.3486590038314176,"[6] Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed
332"
REFERENCES,0.34942528735632183,"bandit problem. Machine learning, 47(2-3):235–256, 2002.
333"
REFERENCES,0.35019157088122604,"[7] Vashist Avadhanula, Jalaj Bhandari, Vineet Goyal, and Assaf Zeevi. On the tightness of
334"
REFERENCES,0.35095785440613025,"an lp relaxation for rational optimization and its applications. Operations Research Letters,
335"
REFERENCES,0.35172413793103446,"44(5):612–617, 2016.
336"
REFERENCES,0.3524904214559387,"[8] Hossein Azari, David Parkes, and Lirong Xia. Random utility theory for social choice. In
337"
REFERENCES,0.35325670498084294,"Advances in Neural Information Processing Systems, pages 126–134, 2012.
338"
REFERENCES,0.35402298850574715,"[9] Hossein Azari, David Parks, and Lirong Xia. Random utility theory for social choice. Advances
339"
REFERENCES,0.35478927203065136,"in Neural Information Processing Systems, 25, 2012.
340"
REFERENCES,0.35555555555555557,"[10] Viktor Bengs, Róbert Busa-Fekete, Adil El Mesaoudi-Paul, and Eyke Hüllermeier. Preference-
341"
REFERENCES,0.3563218390804598,"based online learning with dueling bandits: A survey. Journal of Machine Learning Research,
342"
REFERENCES,0.357088122605364,"2021.
343"
REFERENCES,0.3578544061302682,"[11] Viktor Bengs, Róbert Busa-Fekete, Adil El Mesaoudi-Paul, and Eyke Hüllermeier. Preference-
344"
REFERENCES,0.3586206896551724,"based online learning with dueling bandits: A survey. J. Mach. Learn. Res., 22:7–1, 2021.
345"
REFERENCES,0.3593869731800766,"[12] Viktor Bengs, Aadirupa Saha, and Eyke Hüllermeier. Stochastic contextual dueling bandits
346"
REFERENCES,0.36015325670498083,"under linear stochastic transitivity models. In International Conference on Machine Learning,
347"
REFERENCES,0.36091954022988504,"pages 1764–1786. PMLR, 2022.
348"
REFERENCES,0.36168582375478925,"[13] Gerardo Berbeglia and Gwenaël Joret. Assortment optimisation under a general discrete choice
349"
REFERENCES,0.3624521072796935,"model: A tight analysis of revenue-ordered assortments. arXiv preprint arXiv:1606.01371, 2016.
350"
REFERENCES,0.3632183908045977,"[14] Brian Brost, Yevgeny Seldin, Ingemar J. Cox, and Christina Lioma. Multi-dueling bandits and
351"
REFERENCES,0.36398467432950193,"their application to online ranker evaluation. CoRR, abs/1608.06253, 2016.
352"
REFERENCES,0.36475095785440614,"[15] Niladri S Chatterji, Aldo Pacchiano, Peter L Bartlett, and Michael I Jordan. On the theory of
353"
REFERENCES,0.36551724137931035,"reinforcement learning with once-per-episode feedback. arXiv preprint arXiv:2105.14363, 2021.
354"
REFERENCES,0.36628352490421456,"[16] Xi Chen, Sivakanth Gopi, Jieming Mao, and Jon Schneider. Competitive analysis of the top-k
355"
REFERENCES,0.3670498084291188,"ranking problem. In Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on
356"
REFERENCES,0.367816091954023,"Discrete Algorithms, pages 1245–1264. SIAM, 2017.
357"
REFERENCES,0.3685823754789272,"[17] Xi Chen, Yuanzhi Li, and Jieming Mao. A nearly instance optimal algorithm for top-k ranking
358"
REFERENCES,0.3693486590038314,"under the multinomial logit model. In Proceedings of the Twenty-Ninth Annual ACM-SIAM
359"
REFERENCES,0.3701149425287356,"Symposium on Discrete Algorithms, pages 2504–2522. SIAM, 2018.
360"
REFERENCES,0.3708812260536398,"[18] Xi Chen, Chao Shi, Yining Wang, and Yuan Zhou. Dynamic assortment planning under nested
361"
REFERENCES,0.3716475095785441,"logit models. Production and Operations Management, 30(1):85–102, 2021.
362"
REFERENCES,0.3724137931034483,"[19] Xi Chen and Yining Wang. A note on a tight lower bound for mnl-bandit assortment selection
363"
REFERENCES,0.3731800766283525,"models. arXiv preprint arXiv:1709.06109, 2017.
364"
REFERENCES,0.3739463601532567,"[20] Paul F Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario Amodei. Deep
365"
REFERENCES,0.37471264367816093,"reinforcement learning from human preferences. Advances in neural information processing
366"
REFERENCES,0.37547892720306514,"systems, 30, 2017.
367"
REFERENCES,0.37624521072796935,"[21] James Davis, Guillermo Gallego, and Huseyin Topaloglu. Assortment planning under the
368"
REFERENCES,0.37701149425287356,"multinomial logit model with totally unimodular constraint structures. Work in Progress, 2013.
369"
REFERENCES,0.37777777777777777,"[22] Antoine Désir, Vineet Goyal, Srikanth Jagabathula, and Danny Segev. Assortment optimization
370"
REFERENCES,0.378544061302682,"under the mallows model. In Advances in Neural Information Processing Systems, pages
371"
REFERENCES,0.3793103448275862,"4700–4708, 2016.
372"
REFERENCES,0.3800766283524904,"[23] Antoine Désir, Vineet Goyal, Danny Segev, and Chun Ye. Capacity constrained assortment
373"
REFERENCES,0.38084291187739466,"optimization under the markov chain based choice model. Operations Research, 2016.
374"
REFERENCES,0.3816091954022989,"[24] James A Grant and David S Leslie. Learning to rank under multinomial logit choice. Journal
375"
REFERENCES,0.3823754789272031,"of Machine Learning Research, 24(260):1–49, 2023.
376"
REFERENCES,0.3831417624521073,"[25] Minje Jang, Sunghyun Kim, Changho Suh, and Sewoong Oh. Optimal sample complexity of
377"
REFERENCES,0.3839080459770115,"m-wise data for top-k ranking. In Advances in Neural Information Processing Systems, pages
378"
REFERENCES,0.3846743295019157,"1685–1695, 2017.
379"
REFERENCES,0.3854406130268199,"[26] Ashish Khetan and Sewoong Oh. Data-driven rank breaking for efficient rank aggregation.
380"
REFERENCES,0.38620689655172413,"Journal of Machine Learning Research, 17(193):1–54, 2016.
381"
REFERENCES,0.38697318007662834,"[27] Kameng Nip, Zhenbo Wang, and Zizhuo Wang.
Assortment optimization under a single
382"
REFERENCES,0.38773946360153255,"transition model. 2017.
383"
REFERENCES,0.38850574712643676,"[28] Min-hwan Oh and Garud Iyengar. Thompson sampling for multinomial logit contextual bandits.
384"
REFERENCES,0.389272030651341,"Advances in Neural Information Processing Systems, 32, 2019.
385"
REFERENCES,0.39003831417624524,"[29] Mingdong Ou, Nan Li, Shenghuo Zhu, and Rong Jin. Multinomial logit bandit with linear
386"
REFERENCES,0.39080459770114945,"utility functions. arXiv preprint arXiv:1805.02971, 2018.
387"
REFERENCES,0.39157088122605366,"[30] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin,
388"
REFERENCES,0.39233716475095787,"Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to
389"
REFERENCES,0.3931034482758621,"follow instructions with human feedback. Advances in Neural Information Processing Systems,
390"
REFERENCES,0.3938697318007663,"35:27730–27744, 2022.
391"
REFERENCES,0.3946360153256705,"[31] Wenbo Ren, Jia Liu, and Ness B Shroff. PAC ranking from pairwise and listwise queries: Lower
392"
REFERENCES,0.3954022988505747,"bounds and upper bounds. arXiv preprint arXiv:1806.02970, 2018.
393"
REFERENCES,0.3961685823754789,"[32] Paat Rusmevichientong, Zuo-Jun Max Shen, and David B Shmoys. Dynamic assortment
394"
REFERENCES,0.3969348659003831,"optimization with a multinomial logit choice model and capacity constraint.
Operations
395"
REFERENCES,0.39770114942528734,"research, 58(6):1666–1680, 2010.
396"
REFERENCES,0.39846743295019155,"[33] Aadirupa Saha and Suprovat Ghoshal. Exploiting correlation to achieve faster learning rates in
397"
REFERENCES,0.3992337164750958,"low-rank preference bandits. In International Conference on Artificial Intelligence and Statistics,
398"
REFERENCES,0.4,"pages 456–482. PMLR, 2022.
399"
REFERENCES,0.40076628352490423,"[34] Aadirupa Saha and Aditya Gopalan. Active ranking with subset-wise preferences. International
400"
REFERENCES,0.40153256704980844,"Conference on Artificial Intelligence and Statistics (AISTATS), 2018.
401"
REFERENCES,0.40229885057471265,"[35] Aadirupa Saha and Aditya Gopalan. Combinatorial bandits with relative feedback. In Advances
402"
REFERENCES,0.40306513409961686,"in Neural Information Processing Systems, 2019.
403"
REFERENCES,0.40383141762452107,"[36] Aadirupa Saha and Aditya Gopalan. PAC Battling Bandits in the Plackett-Luce Model. In
404"
REFERENCES,0.4045977011494253,"Algorithmic Learning Theory, pages 700–737, 2019.
405"
REFERENCES,0.4053639846743295,"[37] Aadirupa Saha and Aditya Gopalan. Best-item learning in random utility models with subset
406"
REFERENCES,0.4061302681992337,"choices. In International Conference on Artificial Intelligence and Statistics, pages 4281–4291.
407"
REFERENCES,0.4068965517241379,"PMLR, 2020.
408"
REFERENCES,0.4076628352490421,"[38] Hossein Azari Soufiani, David C Parkes, and Lirong Xia. Computing parametric ranking models
409"
REFERENCES,0.4084291187739464,"via rank-breaking. In ICML, pages 360–368, 2014.
410"
REFERENCES,0.4091954022988506,"[39] Yanan Sui, Vincent Zhuang, Joel Burdick, and Yisong Yue.
Multi-dueling bandits with
411"
REFERENCES,0.4099616858237548,"dependent arms. In Conference on Uncertainty in Artificial Intelligence, UAI’17, 2017.
412"
REFERENCES,0.410727969348659,"[40] Kalyan Talluri and Garrett Van Ryzin. Revenue management under a general discrete choice
413"
REFERENCES,0.4114942528735632,"model of consumer behavior. Management Science, 50(1):15–33, 2004.
414"
REFERENCES,0.41226053639846744,"[41] Yisong Yue, Josef Broder, Robert Kleinberg, and Thorsten Joachims. The k-armed dueling
415"
REFERENCES,0.41302681992337165,"bandits problem. Journal of Computer and System Sciences, 78(5):1538–1556, 2012.
416"
REFERENCES,0.41379310344827586,"[42] Yu-Jie Zhang and Masashi Sugiyama. Online (multinomial) logistic bandit: Improved regret
417"
REFERENCES,0.41455938697318007,"and constant computation cost. Advances in Neural Information Processing Systems, 36, 2024.
418"
REFERENCES,0.4153256704980843,"[43] Zihan Zhang and Xiangyang Ji. Regret minimization for reinforcement learning by evaluating
419"
REFERENCES,0.4160919540229885,"the optimal bias function. In Advances in Neural Information Processing Systems, pages
420"
REFERENCES,0.4168582375478927,"2827–2836, 2019.
421"
REFERENCES,0.41762452107279696,"[44] Masrour Zoghi, Zohar S Karnin, Shimon Whiteson, and Maarten De Rijke. Copeland dueling
422"
REFERENCES,0.41839080459770117,"bandits. In Advances in Neural Information Processing Systems, pages 307–315, 2015.
423"
REFERENCES,0.4191570881226054,"[45] Masrour Zoghi, Shimon Whiteson, Remi Munos, Maarten de Rijke, et al. Relative upper
424"
REFERENCES,0.4199233716475096,"confidence bound for the k-armed dueling bandit problem. In JMLR Workshop and Conference
425"
REFERENCES,0.4206896551724138,"Proceedings, number 32, pages 10–18. JMLR, 2014.
426"
REFERENCES,0.421455938697318,"[46] Masrour Zoghi, Shimon A Whiteson, Maarten De Rijke, and Remi Munos. Relative confidence
427"
REFERENCES,0.4222222222222222,"sampling for efficient on-line ranker evaluation. In Proceedings of the 7th ACM international
428"
REFERENCES,0.42298850574712643,"conference on Web search and data mining, pages 73–82. ACM, 2014.
429"
REFERENCES,0.42375478927203064,"NeurIPS Paper Checklist
430"
CLAIMS,0.42452107279693485,"1. Claims
431"
CLAIMS,0.42528735632183906,"Question: Do the main claims made in the abstract and introduction accurately
432"
CLAIMS,0.42605363984674327,"reflect the paper’s contributions and scope?
433"
CLAIMS,0.42681992337164754,"Answer: [Yes]
434"
CLAIMS,0.42758620689655175,"Justification: In the abstract, we list the main claims of this paper in a general
435"
CLAIMS,0.42835249042145596,"fashion. Then, in the introduction we state them in more detail. They accurately
436"
CLAIMS,0.42911877394636017,"reflect the paper’s contribution and scope.
437"
CLAIMS,0.4298850574712644,"Guidelines:
438"
CLAIMS,0.4306513409961686,"• The answer NA means that the abstract and introduction do not include the
439"
CLAIMS,0.4314176245210728,"claims made in the paper.
440"
CLAIMS,0.432183908045977,"• The abstract and/or introduction should clearly state the claims made, including
441"
CLAIMS,0.4329501915708812,"the contributions made in the paper and important assumptions and limitations.
442"
CLAIMS,0.4337164750957854,"A No or NA answer to this question will not be perceived well by the reviewers.
443"
CLAIMS,0.43448275862068964,"• The claims made should match theoretical and experimental results, and reflect
444"
CLAIMS,0.43524904214559385,"how much the results can be expected to generalize to other settings.
445"
CLAIMS,0.4360153256704981,"• It is fine to include aspirational goals as motivation as long as it is clear that
446"
CLAIMS,0.4367816091954023,"these goals are not attained by the paper.
447"
LIMITATIONS,0.43754789272030653,"2. Limitations
448"
LIMITATIONS,0.43831417624521074,"Question: Does the paper discuss the limitations of the work performed by the
449"
LIMITATIONS,0.43908045977011495,"authors?
450"
LIMITATIONS,0.43984674329501916,"Answer: [Yes]
451"
LIMITATIONS,0.44061302681992337,"Justification: We discuss the limitations and assumptions of our work throughout
452"
LIMITATIONS,0.4413793103448276,"the paper. Additional limitations are highlighted in the discussion.
453"
LIMITATIONS,0.4421455938697318,"Guidelines:
454"
LIMITATIONS,0.442911877394636,"• The answer NA means that the paper has no limitation while the answer No
455"
LIMITATIONS,0.4436781609195402,"means that the paper has limitations, but those are not discussed in the paper.
456"
LIMITATIONS,0.4444444444444444,"• The authors are encouraged to create a separate ""Limitations"" section in their
457"
LIMITATIONS,0.4452107279693487,"paper.
458"
LIMITATIONS,0.4459770114942529,"• The paper should point out any strong assumptions and how robust the results
459"
LIMITATIONS,0.4467432950191571,"are to violations of these assumptions (e.g., independence assumptions, noiseless
460"
LIMITATIONS,0.4475095785440613,"settings, model well-specification, asymptotic approximations only holding
461"
LIMITATIONS,0.4482758620689655,"locally). The authors should reflect on how these assumptions might be violated
462"
LIMITATIONS,0.44904214559386973,"in practice and what the implications would be.
463"
LIMITATIONS,0.44980842911877394,"• The authors should reflect on the scope of the claims made, e.g., if the approach
464"
LIMITATIONS,0.45057471264367815,"was only tested on a few datasets or with a few runs. In general, empirical
465"
LIMITATIONS,0.45134099616858236,"results often depend on implicit assumptions, which should be articulated.
466"
LIMITATIONS,0.4521072796934866,"• The authors should reflect on the factors that influence the performance of the
467"
LIMITATIONS,0.4528735632183908,"approach. For example, a facial recognition algorithm may perform poorly when
468"
LIMITATIONS,0.453639846743295,"image resolution is low or images are taken in low lighting. Or a speech-to-text
469"
LIMITATIONS,0.45440613026819926,"system might not be used reliably to provide closed captions for online lectures
470"
LIMITATIONS,0.45517241379310347,"because it fails to handle technical jargon.
471"
LIMITATIONS,0.4559386973180077,"• The authors should discuss the computational efficiency of the proposed algo-
472"
LIMITATIONS,0.4567049808429119,"rithms and how they scale with dataset size.
473"
LIMITATIONS,0.4574712643678161,"• If applicable, the authors should discuss possible limitations of their approach
474"
LIMITATIONS,0.4582375478927203,"to address problems of privacy and fairness.
475"
LIMITATIONS,0.4590038314176245,"• While the authors might fear that complete honesty about limitations might
476"
LIMITATIONS,0.45977011494252873,"be used by reviewers as grounds for rejection, a worse outcome might be that
477"
LIMITATIONS,0.46053639846743294,"reviewers discover limitations that aren’t acknowledged in the paper. The
478"
LIMITATIONS,0.46130268199233715,"authors should use their best judgment and recognize that individual actions in
479"
LIMITATIONS,0.46206896551724136,"favor of transparency play an important role in developing norms that preserve
480"
LIMITATIONS,0.46283524904214557,"the integrity of the community. Reviewers will be specifically instructed to not
481"
LIMITATIONS,0.46360153256704983,"penalize honesty concerning limitations.
482"
THEORY ASSUMPTIONS AND PROOFS,0.46436781609195404,"3. Theory Assumptions and Proofs
483"
THEORY ASSUMPTIONS AND PROOFS,0.46513409961685825,"Question: For each theoretical result, does the paper provide the full set of assump-
484"
THEORY ASSUMPTIONS AND PROOFS,0.46590038314176246,"tions and a complete (and correct) proof?
485"
THEORY ASSUMPTIONS AND PROOFS,0.4666666666666667,"Answer: [Yes]
486"
THEORY ASSUMPTIONS AND PROOFS,0.4674329501915709,"Justification: The assumptions can be found in the Problem Setup section and in
487"
THEORY ASSUMPTIONS AND PROOFS,0.4681992337164751,"the paragraphs before the theorems and remarks. We provide proof sketches in the
488"
THEORY ASSUMPTIONS AND PROOFS,0.4689655172413793,"main text and complete proofs in the appendix.
489"
THEORY ASSUMPTIONS AND PROOFS,0.4697318007662835,"Guidelines:
490"
THEORY ASSUMPTIONS AND PROOFS,0.4704980842911877,"• The answer NA means that the paper does not include theoretical results.
491"
THEORY ASSUMPTIONS AND PROOFS,0.47126436781609193,"• All the theorems, formulas, and proofs in the paper should be numbered and
492"
THEORY ASSUMPTIONS AND PROOFS,0.47203065134099614,"cross-referenced.
493"
THEORY ASSUMPTIONS AND PROOFS,0.4727969348659004,"• All assumptions should be clearly stated or referenced in the statement of any
494"
THEORY ASSUMPTIONS AND PROOFS,0.4735632183908046,"theorems.
495"
THEORY ASSUMPTIONS AND PROOFS,0.47432950191570883,"• The proofs can either appear in the main paper or the supplemental material,
496"
THEORY ASSUMPTIONS AND PROOFS,0.47509578544061304,"but if they appear in the supplemental material, the authors are encouraged to
497"
THEORY ASSUMPTIONS AND PROOFS,0.47586206896551725,"provide a short proof sketch to provide intuition.
498"
THEORY ASSUMPTIONS AND PROOFS,0.47662835249042146,"• Inversely, any informal proof provided in the core of the paper should be
499"
THEORY ASSUMPTIONS AND PROOFS,0.47739463601532567,"complemented by formal proofs provided in appendix or supplemental material.
500"
THEORY ASSUMPTIONS AND PROOFS,0.4781609195402299,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
501"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.4789272030651341,"4. Experimental Result Reproducibility
502"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.4796934865900383,"Question: Does the paper fully disclose all the information needed to reproduce
503"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.4804597701149425,"the main experimental results of the paper to the extent that it affects the main
504"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.4812260536398467,"claims and/or conclusions of the paper (regardless of whether the code and data are
505"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.481992337164751,"provided or not)?
506"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.4827586206896552,"Answer: [Yes]
507"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.4835249042145594,"Justification: experimental details including algorithms and setups are clearly pro-
508"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.4842911877394636,"vided. In addition, the main contribution of the paper is theoretical and synthetic
509"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.4850574712643678,"experiments are mostly provided as an illustration.
510"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.48582375478927203,"Guidelines:
511"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.48659003831417624,"• The answer NA means that the paper does not include experiments.
512"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.48735632183908045,"• If the paper includes experiments, a No answer to this question will not be
513"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.48812260536398466,"perceived well by the reviewers: Making the paper reproducible is important,
514"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.4888888888888889,"regardless of whether the code and data are provided or not.
515"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.4896551724137931,"• If the contribution is a dataset and/or model, the authors should describe the
516"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.4904214559386973,"steps taken to make their results reproducible or verifiable.
517"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.49118773946360156,"• Depending on the contribution, reproducibility can be accomplished in various
518"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.49195402298850577,"ways. For example, if the contribution is a novel architecture, describing the
519"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.49272030651341,"architecture fully might suffice, or if the contribution is a specific model and
520"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.4934865900383142,"empirical evaluation, it may be necessary to either make it possible for others
521"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.4942528735632184,"to replicate the model with the same dataset, or provide access to the model. In
522"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.4950191570881226,"general. releasing code and data is often one good way to accomplish this, but
523"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.4957854406130268,"reproducibility can also be provided via detailed instructions for how to replicate
524"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.496551724137931,"the results, access to a hosted model (e.g., in the case of a large language model),
525"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.49731800766283524,"releasing of a model checkpoint, or other means that are appropriate to the
526"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.49808429118773945,"research performed.
527"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.49885057471264366,"• While NeurIPS does not require releasing code, the conference does require all
528"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.49961685823754787,"submissions to provide some reasonable avenue for reproducibility, which may
529"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5003831417624521,"depend on the nature of the contribution. For example
530"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5011494252873563,"(a) If the contribution is primarily a new algorithm, the paper should make it
531"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5019157088122606,"clear how to reproduce that algorithm.
532"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5026819923371647,"(b) If the contribution is primarily a new model architecture, the paper should
533"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.503448275862069,"describe the architecture clearly and fully.
534"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5042145593869731,"(c) If the contribution is a new model (e.g., a large language model), then there
535"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5049808429118774,"should either be a way to access this model for reproducing the results or a
536"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5057471264367817,"way to reproduce the model (e.g., with an open-source dataset or instructions
537"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5065134099616858,"for how to construct the dataset).
538"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5072796934865901,"(d) We recognize that reproducibility may be tricky in some cases, in which
539"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5080459770114942,"case authors are welcome to describe the particular way they provide for
540"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5088122605363985,"reproducibility. In the case of closed-source models, it may be that access to
541"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5095785440613027,"the model is limited in some way (e.g., to registered users), but it should be
542"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5103448275862069,"possible for other researchers to have some path to reproducing or verifying
543"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5111111111111111,"the results.
544"
OPEN ACCESS TO DATA AND CODE,0.5118773946360153,"5. Open access to data and code
545"
OPEN ACCESS TO DATA AND CODE,0.5126436781609195,"Question: Does the paper provide open access to the data and code, with sufficient
546"
OPEN ACCESS TO DATA AND CODE,0.5134099616858238,"instructions to faithfully reproduce the main experimental results, as described in
547"
OPEN ACCESS TO DATA AND CODE,0.514176245210728,"supplemental material?
548"
OPEN ACCESS TO DATA AND CODE,0.5149425287356322,"Answer: [No]
549"
OPEN ACCESS TO DATA AND CODE,0.5157088122605364,"Justification: experimental setups are synthetic and can easily be reproduced.
550"
OPEN ACCESS TO DATA AND CODE,0.5164750957854406,"Guidelines:
551"
OPEN ACCESS TO DATA AND CODE,0.5172413793103449,"• The answer NA means that paper does not include experiments requiring code.
552"
OPEN ACCESS TO DATA AND CODE,0.518007662835249,"• Please see the NeurIPS code and data submission guidelines (https://nips.
553"
OPEN ACCESS TO DATA AND CODE,0.5187739463601533,"cc/public/guides/CodeSubmissionPolicy) for more details.
554"
OPEN ACCESS TO DATA AND CODE,0.5195402298850574,"• While we encourage the release of code and data, we understand that this might
555"
OPEN ACCESS TO DATA AND CODE,0.5203065134099617,"not be possible, so “No” is an acceptable answer. Papers cannot be rejected
556"
OPEN ACCESS TO DATA AND CODE,0.5210727969348659,"simply for not including code, unless this is central to the contribution (e.g., for
557"
OPEN ACCESS TO DATA AND CODE,0.5218390804597701,"a new open-source benchmark).
558"
OPEN ACCESS TO DATA AND CODE,0.5226053639846743,"• The instructions should contain the exact command and environment needed
559"
OPEN ACCESS TO DATA AND CODE,0.5233716475095785,"to run to reproduce the results.
See the NeurIPS code and data submis-
560"
OPEN ACCESS TO DATA AND CODE,0.5241379310344828,"sion guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy)
561"
OPEN ACCESS TO DATA AND CODE,0.524904214559387,"for more details.
562"
OPEN ACCESS TO DATA AND CODE,0.5256704980842912,"• The authors should provide instructions on data access and preparation, in-
563"
OPEN ACCESS TO DATA AND CODE,0.5264367816091954,"cluding how to access the raw data, preprocessed data, intermediate data, and
564"
OPEN ACCESS TO DATA AND CODE,0.5272030651340996,"generated data, etc.
565"
OPEN ACCESS TO DATA AND CODE,0.5279693486590038,"• The authors should provide scripts to reproduce all experimental results for
566"
OPEN ACCESS TO DATA AND CODE,0.5287356321839081,"the new proposed method and baselines. If only a subset of experiments are
567"
OPEN ACCESS TO DATA AND CODE,0.5295019157088122,"reproducible, they should state which ones are omitted from the script and why.
568"
OPEN ACCESS TO DATA AND CODE,0.5302681992337165,"• At submission time, to preserve anonymity, the authors should release
569"
OPEN ACCESS TO DATA AND CODE,0.5310344827586206,"anonymized versions (if applicable).
570"
OPEN ACCESS TO DATA AND CODE,0.5318007662835249,"• Providing as much information as possible in supplemental material (appended
571"
OPEN ACCESS TO DATA AND CODE,0.5325670498084292,"to the paper) is recommended, but including URLs to data and code is permitted.
572"
OPEN ACCESS TO DATA AND CODE,0.5333333333333333,"6. Experimental Setting/Details
573"
OPEN ACCESS TO DATA AND CODE,0.5340996168582376,"Question: Does the paper specify all the training and test details (e.g., data splits,
574"
OPEN ACCESS TO DATA AND CODE,0.5348659003831417,"hyperparameters, how they were chosen, type of optimizer, etc.)
necessary to
575"
OPEN ACCESS TO DATA AND CODE,0.535632183908046,"understand the results?
576"
OPEN ACCESS TO DATA AND CODE,0.5363984674329502,"Answer: [Yes]
577"
OPEN ACCESS TO DATA AND CODE,0.5371647509578544,"Justification: All details are provided to reproduce the experiments.
578"
OPEN ACCESS TO DATA AND CODE,0.5379310344827586,"Guidelines:
579"
OPEN ACCESS TO DATA AND CODE,0.5386973180076629,"• The answer NA means that the paper does not include experiments.
580"
OPEN ACCESS TO DATA AND CODE,0.539463601532567,"• The experimental setting should be presented in the core of the paper to a level
581"
OPEN ACCESS TO DATA AND CODE,0.5402298850574713,"of detail that is necessary to appreciate the results and make sense of them.
582"
OPEN ACCESS TO DATA AND CODE,0.5409961685823754,"• The full details can be provided either with the code, in appendix, or as
583"
OPEN ACCESS TO DATA AND CODE,0.5417624521072797,"supplemental material.
584"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.542528735632184,"7. Experiment Statistical Significance
585"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5432950191570881,"Question: Does the paper report error bars suitably and correctly defined or other
586"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5440613026819924,"appropriate information about the statistical significance of the experiments?
587"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5448275862068965,"Answer: [Yes]
588"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5455938697318008,"Justification: [Yes]
589"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.546360153256705,"Guidelines:
590"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5471264367816092,"• The answer NA means that the paper does not include experiments.
591"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5478927203065134,"• The authors should answer ""Yes"" if the results are accompanied by error bars,
592"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5486590038314176,"confidence intervals, or statistical significance tests, at least for the experiments
593"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5494252873563218,"that support the main claims of the paper.
594"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.550191570881226,"• The factors of variability that the error bars are capturing should be clearly
595"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5509578544061303,"stated (for example, train/test split, initialization, random drawing of some
596"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5517241379310345,"parameter, or overall run with given experimental conditions).
597"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5524904214559387,"• The method for calculating the error bars should be explained (closed form
598"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5532567049808429,"formula, call to a library function, bootstrap, etc.)
599"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5540229885057472,"• The assumptions made should be given (e.g., Normally distributed errors).
600"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5547892720306513,"• It should be clear whether the error bar is the standard deviation or the standard
601"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5555555555555556,"error of the mean.
602"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5563218390804597,"• It is OK to report 1-sigma error bars, but one should state it. The authors
603"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.557088122605364,"should preferably report a 2-sigma error bar than state that they have a 96%
604"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5578544061302682,"CI, if the hypothesis of Normality of errors is not verified.
605"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5586206896551724,"• For asymmetric distributions, the authors should be careful not to show in
606"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5593869731800766,"tables or figures symmetric error bars that would yield results that are out of
607"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5601532567049808,"range (e.g. negative error rates).
608"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5609195402298851,"• If error bars are reported in tables or plots, The authors should explain in the
609"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5616858237547893,"text how they were calculated and reference the corresponding figures or tables
610"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5624521072796935,"in the text.
611"
EXPERIMENTS COMPUTE RESOURCES,0.5632183908045977,"8. Experiments Compute Resources
612"
EXPERIMENTS COMPUTE RESOURCES,0.563984674329502,"Question: For each experiment, does the paper provide sufficient information on the
613"
EXPERIMENTS COMPUTE RESOURCES,0.5647509578544061,"computer resources (type of compute workers, memory, time of execution) needed
614"
EXPERIMENTS COMPUTE RESOURCES,0.5655172413793104,"to reproduce the experiments?
615"
EXPERIMENTS COMPUTE RESOURCES,0.5662835249042145,"Answer: [NA]
616"
EXPERIMENTS COMPUTE RESOURCES,0.5670498084291188,"Justification: [NA]
617"
EXPERIMENTS COMPUTE RESOURCES,0.5678160919540229,"Guidelines:
618"
EXPERIMENTS COMPUTE RESOURCES,0.5685823754789272,"• The answer NA means that the paper does not include experiments.
619"
EXPERIMENTS COMPUTE RESOURCES,0.5693486590038315,"• The paper should indicate the type of compute workers CPU or GPU, internal
620"
EXPERIMENTS COMPUTE RESOURCES,0.5701149425287356,"cluster, or cloud provider, including relevant memory and storage.
621"
EXPERIMENTS COMPUTE RESOURCES,0.5708812260536399,"• The paper should provide the amount of compute required for each of the
622"
EXPERIMENTS COMPUTE RESOURCES,0.571647509578544,"individual experimental runs as well as estimate the total compute.
623"
EXPERIMENTS COMPUTE RESOURCES,0.5724137931034483,"• The paper should disclose whether the full research project required more
624"
EXPERIMENTS COMPUTE RESOURCES,0.5731800766283525,"compute than the experiments reported in the paper (e.g., preliminary or failed
625"
EXPERIMENTS COMPUTE RESOURCES,0.5739463601532567,"experiments that didn’t make it into the paper).
626"
CODE OF ETHICS,0.5747126436781609,"9. Code Of Ethics
627"
CODE OF ETHICS,0.5754789272030651,"Question: Does the research conducted in the paper conform, in every respect, with
628"
CODE OF ETHICS,0.5762452107279693,"the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
629"
CODE OF ETHICS,0.5770114942528736,"Answer: [Yes]
630"
CODE OF ETHICS,0.5777777777777777,"Justification: We do not see any potential negative social impact of this work and it
631"
CODE OF ETHICS,0.578544061302682,"follows the NeurIPS code of ethics.
632"
CODE OF ETHICS,0.5793103448275863,"Guidelines:
633"
CODE OF ETHICS,0.5800766283524904,"• The answer NA means that the authors have not reviewed the NeurIPS Code
634"
CODE OF ETHICS,0.5808429118773947,"of Ethics.
635"
CODE OF ETHICS,0.5816091954022988,"• If the authors answer No, they should explain the special circumstances that
636"
CODE OF ETHICS,0.5823754789272031,"require a deviation from the Code of Ethics.
637"
CODE OF ETHICS,0.5831417624521072,"• The authors should make sure to preserve anonymity (e.g., if there is a special
638"
CODE OF ETHICS,0.5839080459770115,"consideration due to laws or regulations in their jurisdiction).
639"
BROADER IMPACTS,0.5846743295019157,"10. Broader Impacts
640"
BROADER IMPACTS,0.5854406130268199,"Question: Does the paper discuss both potential positive societal impacts and
641"
BROADER IMPACTS,0.5862068965517241,"negative societal impacts of the work performed?
642"
BROADER IMPACTS,0.5869731800766284,"Answer: [NA]
643"
BROADER IMPACTS,0.5877394636015326,"Justification: This work addresses the problem of designing efficient and optimal
644"
BROADER IMPACTS,0.5885057471264368,"algorithms for different assortment selection problems with MNL models. Our
645"
BROADER IMPACTS,0.589272030651341,"work is purely theoretical and studies a fundamental mathematical optimization
646"
BROADER IMPACTS,0.5900383141762452,"framework that is unrelated to societal considerations
647"
BROADER IMPACTS,0.5908045977011495,"Guidelines:
648"
BROADER IMPACTS,0.5915708812260536,"• The answer NA means that there is no societal impact of the work performed.
649"
BROADER IMPACTS,0.5923371647509579,"• If the authors answer NA or No, they should explain why their work has no
650"
BROADER IMPACTS,0.593103448275862,"societal impact or why the paper does not address societal impact.
651"
BROADER IMPACTS,0.5938697318007663,"• Examples of negative societal impacts include potential malicious or unintended
652"
BROADER IMPACTS,0.5946360153256705,"uses (e.g., disinformation, generating fake profiles, surveillance), fairness consid-
653"
BROADER IMPACTS,0.5954022988505747,"erations (e.g., deployment of technologies that could make decisions that unfairly
654"
BROADER IMPACTS,0.5961685823754789,"impact specific groups), privacy considerations, and security considerations.
655"
BROADER IMPACTS,0.5969348659003831,"• The conference expects that many papers will be foundational research and
656"
BROADER IMPACTS,0.5977011494252874,"not tied to particular applications, let alone deployments. However, if there
657"
BROADER IMPACTS,0.5984674329501916,"is a direct path to any negative applications, the authors should point it out.
658"
BROADER IMPACTS,0.5992337164750958,"For example, it is legitimate to point out that an improvement in the quality
659"
BROADER IMPACTS,0.6,"of generative models could be used to generate deepfakes for disinformation.
660"
BROADER IMPACTS,0.6007662835249042,"On the other hand, it is not needed to point out that a generic algorithm for
661"
BROADER IMPACTS,0.6015325670498084,"optimizing neural networks could enable people to train models that generate
662"
BROADER IMPACTS,0.6022988505747127,"Deepfakes faster.
663"
BROADER IMPACTS,0.6030651340996168,"• The authors should consider possible harms that could arise when the technology
664"
BROADER IMPACTS,0.6038314176245211,"is being used as intended and functioning correctly, harms that could arise when
665"
BROADER IMPACTS,0.6045977011494252,"the technology is being used as intended but gives incorrect results, and harms
666"
BROADER IMPACTS,0.6053639846743295,"following from (intentional or unintentional) misuse of the technology.
667"
BROADER IMPACTS,0.6061302681992338,"• If there are negative societal impacts, the authors could also discuss possible
668"
BROADER IMPACTS,0.6068965517241379,"mitigation strategies (e.g., gated release of models, providing defenses in addition
669"
BROADER IMPACTS,0.6076628352490422,"to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a
670"
BROADER IMPACTS,0.6084291187739463,"system learns from feedback over time, improving the efficiency and accessibility
671"
BROADER IMPACTS,0.6091954022988506,"of ML).
672"
SAFEGUARDS,0.6099616858237548,"11. Safeguards
673"
SAFEGUARDS,0.610727969348659,"Question: Does the paper describe safeguards that have been put in place for
674"
SAFEGUARDS,0.6114942528735632,"responsible release of data or models that have a high risk for misuse (e.g., pretrained
675"
SAFEGUARDS,0.6122605363984674,"language models, image generators, or scraped datasets)?
676"
SAFEGUARDS,0.6130268199233716,"Answer: [NA]
677"
SAFEGUARDS,0.6137931034482759,"Justification: [NA]
678"
SAFEGUARDS,0.61455938697318,"Guidelines:
679"
SAFEGUARDS,0.6153256704980843,"• The answer NA means that the paper poses no such risks.
680"
SAFEGUARDS,0.6160919540229886,"• Released models that have a high risk for misuse or dual-use should be released
681"
SAFEGUARDS,0.6168582375478927,"with necessary safeguards to allow for controlled use of the model, for example
682"
SAFEGUARDS,0.617624521072797,"by requiring that users adhere to usage guidelines or restrictions to access the
683"
SAFEGUARDS,0.6183908045977011,"model or implementing safety filters.
684"
SAFEGUARDS,0.6191570881226054,"• Datasets that have been scraped from the Internet could pose safety risks. The
685"
SAFEGUARDS,0.6199233716475095,"authors should describe how they avoided releasing unsafe images.
686"
SAFEGUARDS,0.6206896551724138,"• We recognize that providing effective safeguards is challenging, and many papers
687"
SAFEGUARDS,0.621455938697318,"do not require this, but we encourage authors to take this into account and
688"
SAFEGUARDS,0.6222222222222222,"make a best faith effort.
689"
LICENSES FOR EXISTING ASSETS,0.6229885057471264,"12. Licenses for existing assets
690"
LICENSES FOR EXISTING ASSETS,0.6237547892720307,"Question: Are the creators or original owners of assets (e.g., code, data, models),
691"
LICENSES FOR EXISTING ASSETS,0.6245210727969349,"used in the paper, properly credited and are the license and terms of use explicitly
692"
LICENSES FOR EXISTING ASSETS,0.6252873563218391,"mentioned and properly respected?
693"
LICENSES FOR EXISTING ASSETS,0.6260536398467433,"Answer: [NA]
694"
LICENSES FOR EXISTING ASSETS,0.6268199233716475,"Justification: [NA]
695"
LICENSES FOR EXISTING ASSETS,0.6275862068965518,"Guidelines:
696"
LICENSES FOR EXISTING ASSETS,0.6283524904214559,"• The answer NA means that the paper does not use existing assets.
697"
LICENSES FOR EXISTING ASSETS,0.6291187739463602,"• The authors should cite the original paper that produced the code package or
698"
LICENSES FOR EXISTING ASSETS,0.6298850574712643,"dataset.
699"
LICENSES FOR EXISTING ASSETS,0.6306513409961686,"• The authors should state which version of the asset is used and, if possible,
700"
LICENSES FOR EXISTING ASSETS,0.6314176245210728,"include a URL.
701"
LICENSES FOR EXISTING ASSETS,0.632183908045977,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
702"
LICENSES FOR EXISTING ASSETS,0.6329501915708812,"• For scraped data from a particular source (e.g., website), the copyright and
703"
LICENSES FOR EXISTING ASSETS,0.6337164750957854,"terms of service of that source should be provided.
704"
LICENSES FOR EXISTING ASSETS,0.6344827586206897,"• If assets are released, the license, copyright information, and terms of use in
705"
LICENSES FOR EXISTING ASSETS,0.6352490421455939,"the package should be provided. For popular datasets, paperswithcode.com/
706"
LICENSES FOR EXISTING ASSETS,0.6360153256704981,"datasets has curated licenses for some datasets. Their licensing guide can help
707"
LICENSES FOR EXISTING ASSETS,0.6367816091954023,"determine the license of a dataset.
708"
LICENSES FOR EXISTING ASSETS,0.6375478927203065,"• For existing datasets that are re-packaged, both the original license and the
709"
LICENSES FOR EXISTING ASSETS,0.6383141762452107,"license of the derived asset (if it has changed) should be provided.
710"
LICENSES FOR EXISTING ASSETS,0.639080459770115,"• If this information is not available online, the authors are encouraged to reach
711"
LICENSES FOR EXISTING ASSETS,0.6398467432950191,"out to the asset’s creators.
712"
NEW ASSETS,0.6406130268199234,"13. New Assets
713"
NEW ASSETS,0.6413793103448275,"Question: Are new assets introduced in the paper well documented and is the
714"
NEW ASSETS,0.6421455938697318,"documentation provided alongside the assets?
715"
NEW ASSETS,0.6429118773946361,"Answer: [NA]
716"
NEW ASSETS,0.6436781609195402,"Justification: [NA]
717"
NEW ASSETS,0.6444444444444445,"Guidelines:
718"
NEW ASSETS,0.6452107279693486,"• The answer NA means that the paper does not release new assets.
719"
NEW ASSETS,0.6459770114942529,"• Researchers should communicate the details of the dataset/code/model as part
720"
NEW ASSETS,0.6467432950191571,"of their submissions via structured templates.
This includes details about
721"
NEW ASSETS,0.6475095785440613,"training, license, limitations, etc.
722"
NEW ASSETS,0.6482758620689655,"• The paper should discuss whether and how consent was obtained from people
723"
NEW ASSETS,0.6490421455938697,"whose asset is used.
724"
NEW ASSETS,0.6498084291187739,"• At submission time, remember to anonymize your assets (if applicable). You
725"
NEW ASSETS,0.6505747126436782,"can either create an anonymized URL or include an anonymized zip file.
726"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6513409961685823,"14. Crowdsourcing and Research with Human Subjects
727"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6521072796934866,"Question: For crowdsourcing experiments and research with human subjects, does
728"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6528735632183909,"the paper include the full text of instructions given to participants and screenshots,
729"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.653639846743295,"if applicable, as well as details about compensation (if any)?
730"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6544061302681993,"Answer: [NA]
731"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6551724137931034,"Justification: [NA]
732"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6559386973180077,"Guidelines:
733"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6567049808429118,"• The answer NA means that the paper does not involve crowdsourcing nor
734"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6574712643678161,"research with human subjects.
735"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6582375478927203,"• Including this information in the supplemental material is fine, but if the main
736"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6590038314176245,"contribution of the paper involves human subjects, then as much detail as
737"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6597701149425287,"possible should be included in the main paper.
738"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.660536398467433,"• According to the NeurIPS Code of Ethics, workers involved in data collection,
739"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6613026819923372,"curation, or other labor should be paid at least the minimum wage in the
740"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6620689655172414,"country of the data collector.
741"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6628352490421456,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research
742"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6636015325670498,"with Human Subjects
743"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.664367816091954,"Question: Does the paper describe potential risks incurred by study participants,
744"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6651340996168582,"whether such risks were disclosed to the subjects, and whether Institutional Review
745"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6659003831417625,"Board (IRB) approvals (or an equivalent approval/review based on the requirements
746"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6666666666666666,"of your country or institution) were obtained?
747"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6674329501915709,"Answer: [NA]
748"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.668199233716475,"Justification: [NA]
749"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6689655172413793,"Guidelines:
750"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6697318007662836,"• The answer NA means that the paper does not involve crowdsourcing nor
751"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6704980842911877,"research with human subjects.
752"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.671264367816092,"• Depending on the country in which research is conducted, IRB approval (or
753"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6720306513409962,"equivalent) may be required for any human subjects research. If you obtained
754"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6727969348659004,"IRB approval, you should clearly state this in the paper.
755"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6735632183908046,"• We recognize that the procedures for this may vary significantly between insti-
756"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6743295019157088,"tutions and locations, and we expect authors to adhere to the NeurIPS Code of
757"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.675095785440613,"Ethics and the guidelines for their institution.
758"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6758620689655173,"• For initial submissions, do not include any information that would break
759"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6766283524904214,"anonymity (if applicable), such as the institution conducting the review.
760"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6773946360153257,"Supplementary: Optimal, Efficient and Practical
761"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6781609195402298,"Algorithms for Assortment Optimization
762"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6789272030651341,"A
Preliminaries: Some Useful Concepts for PL choice models
763"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6796934865900384,"A.1
Plackett-Luce (PL): A Discrete Choice Model
764"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6804597701149425,"A discrete choice model specifies the relative preferences of two or more discrete alternatives
765"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6812260536398468,"in a given set. A widely studied class of discrete choice models is the class of Random
766"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6819923371647509,"Utility Models (RUMs), which assume a ground-truth utility score θi ∈R for each alternative
767"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6827586206896552,"i ∈[n], and assign a conditional distribution Di(·|θi) for scoring item i. To model a winning
768"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6835249042145594,"alternative given any set S ⊆[n], one first draws a random utility score Xi ∼Di(·|θi) for
769"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6842911877394636,"each alternative in S, and selects an item with the highest random score.
770"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6850574712643678,"One widely used RUM is the Multinomial-Logit (MNL) or Plackett-Luce model (PL), where
the Dis are taken to be independent Gumbel distributions with parameters θ′
i [8], i.e., with
probability densities"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.685823754789272,"Di(xi|θ′
i) = e−(xj−θ′
j)e−e
−(xj −θ′
j )
,
θ′
i ∈R, ∀i ∈[n] ."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6865900383141762,"Moreover assuming θ′
i = ln θi, θi > 0 ∀i ∈[n], it can be shown in this case the probability
771"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6873563218390805,"that an alternative i emerges as the winner in the set S ∋i becomes: P(i|S) =
θi
P"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6881226053639847,"j∈S θj .
772"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6888888888888889,"Other families of discrete choice models can be obtained by imposing different probability
773"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6896551724137931,"distributions over the utility scores Xi, e.g. if (X1, . . . Xn) ∼N(θ, Λ) are jointly normal
774"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6904214559386973,"with mean θ = (θ1, . . . θn) and covariance Λ ∈Rn×n, then the corresponding RUM-based
775"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6911877394636016,"choice model reduces to the Multinomial Probit (MNP).
776"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6919540229885057,"A.2
Rank Breaking
777"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.69272030651341,"Rank breaking (RB) is a well-understood idea involving the extraction of pairwise comparisons
778"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6934865900383141,"from (partial) ranking data, and then building pairwise estimators on the obtained pairs by
779"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6942528735632184,"treating each comparison independently [26, 25], e.g., a winner a sampled from among a, b, c is
780"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6950191570881226,"rank-broken into the pairwise preferences a ≻b, a ≻c. We use this idea to devise estimators
781"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6957854406130268,"for the pairwise win probabilities pij = P(i|{i, j}) = θi/(θi + θj) for our problem setting.
782"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.696551724137931,"We used the idea of RB in both our algorithms (AOA-RBPL and AOA-RBPL-Adaptive) to
783"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6973180076628352,"update the pairwise win-count estimates wi,j,t for all the item pairs (i, j) ∈[K] × [K], which
784"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6980842911877395,"is further used for deriving the empirical pairwise preference estimates bpij,t, at any time t.
785"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6988505747126437,"A.3
Parameter Estimation with PL based preference data
786"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6996168582375479,"Lemma 7 (Pairwise win-probability estimates for the PL model [34]). Consider a Plackett-
787"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7003831417624521,"Luce choice model with parameters θ = (θ1, θ2, . . . , θn), and fix two items i, j ∈[n]. Let
788"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7011494252873564,"S1, . . . , ST be a sequence of (possibly random) subsets of [n] of size at least 2, where T is
789"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7019157088122605,"a positive integer, and i1, . . . , iT a sequence of random items with each it ∈St, 1 ≤t ≤T,
790"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7026819923371648,"such that for each 1 ≤t ≤T, (a) St depends only on S1, . . . , St−1, and (b) it is distributed
791"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7034482758620689,"as the Plackett-Luce winner of the subset St, given S1, i1, . . . , St−1, it−1 and St, and (c)
792"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7042145593869732,"∀t : {i, j} ⊆St with probability 1. Let ni(T) = PT
t=1 P(it = i) and nij(T) = PT
t=1 P({it ∈
793"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7049808429118773,"{i, j}}). Then, for any positive integer v, and η ∈(0, 1),
794"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7057471264367816,"P
 ni(T)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7065134099616859,"nij(T) −
θi
θi + θj
≥η, nij(T) ≥v

≤e−2vη2,"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.70727969348659,"P
 ni(T)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7080459770114943,"nij(T) −
θi
θi + θj
≤−η, nij(T) ≥v

≤e−2vη2."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7088122605363985,"B
Omitted Proofs from Sec. 3 and Sec. 4
795"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7095785440613027,"B.1
A concentration bounds for the pij,t
796"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7103448275862069,"We first prove below a concentration inequality based on Bernstein’s inequality for the
797"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7111111111111111,"estimators pij,t.
798"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7118773946360153,"Lemma 8. Let (i, j) ∈[K] × [K]. Let T ≥1 and x > 0. Then, with probability at least
799"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7126436781609196,"1 −3Te−x,
800"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7134099616858237,"pij ≤pucb
ij,t ≤pij + 2 s"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.714176245210728,2pij(1 −pij)x
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7149425287356321,"nij,t
+ 11x"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7157088122605364,"nij,t
,
(8)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7164750957854407,"simultaneously for all t ∈[T].
801"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7172413793103448,"Proof of Lemma 8. Let T ≥1, x > 0 and i, j ∈[K]. Applying Thm. 1 of [4], with probability
802"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7180076628352491,"at least 1 −β(x, T), we get simultaneously for all t ∈[T],
803"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7187739463601532,"bpij,t −pij
 ≤ s"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7195402298850575,"2bpij,t(1 −bpij,t)x"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7203065134099617,"nij,t
+ 3x"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7210727969348659,"nij,t
,
(9)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7218390804597701,"where β(x, T) = 3 inf1<α≤3 min
 log T"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7226053639846743,"log α, T
	
e−x/α ≤3Te−x. Note that the inequality holds
804"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7233716475095785,"true although nij,t is a random variable. This, shows the first inequality
805"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7241379310344828,"pij ≤pucb
ij,t ."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.724904214559387,"For the second inequality, (9) implies
806"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7256704980842912,"pucb
ij,t = bpij,t + s"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7264367816091954,"2bpij,t(1 −bpij,t)x"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7272030651340996,"nij,t
+ 3x nij,t"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7279693486590039,≤pij + 2 s
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.728735632183908,"2bpij,t(1 −bpij,t)x"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7295019157088123,"nij,t
+ 6x"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7302681992337164,"nij,t
.
(10)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7310344827586207,"Furthermore, because x 7→x(1 −x) is 1-Lipschitz on [0, 1], we have
807"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7318007662835249,"bpij,t(1 −bpij,t) −pij(1 −pij)
 ≤
bpij,t −pij (9)
≤ s"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7325670498084291,"2bpij,t(1 −bpij,t)x"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7333333333333333,"nij,t
+ 3x"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7340996168582375,"nij,t
."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7348659003831418,"Therefore,
808"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.735632183908046,"bpij,t(1 −bpij,t) ≤pij(1 −pij) + s"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7363984674329502,"2bpij,t(1 −bpij,t)x"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7371647509578544,"nij,t
+ 3x nij,t ≤
q"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7379310344827587,pij(1 −pij) + s
X,0.7386973180076628,"3x
nij,t 2
,"
X,0.7394636015325671,"which yields
809 q"
X,0.7402298850574712,"bpij,t(1 −bpij,t) ≤
q"
X,0.7409961685823755,pij(1 −pij) + s
X,0.7417624521072796,"3x
nij,t
.
(11)"
X,0.7425287356321839,"Plugging back into (10), we get
810"
X,0.7432950191570882,"pucb
ij,t ≤2 s"
X,0.7440613026819923,2pij(1 −pij)x
X,0.7448275862068966,"nij,t
+ 11x"
X,0.7455938697318008,"nij,t
. 811"
X,0.746360153256705,"B.2
Proof of Lemma 1
812"
X,0.7471264367816092,"Proof. Let i ∈[K] and x > 0. Then, by a union bound on Lemma 8 and 2, with probability
813"
X,0.7478927203065134,"at least 1 −4Te−x, (8) and (4) hold true for all t ∈[T]. We consider this high-probability
814"
X,0.7486590038314176,"event in the rest of the proof. Define the function f : x 7→x/(1 −x)+ on [0, 1] (with the
815"
X,0.7494252873563219,"convention f(1) = +∞), so that θucb
i,t = f(pucb
i0,t) and θi = f(pi0). Because f is non-decreasing,
816"
X,0.750191570881226,"and pucb
i0,t ≥pi0 by (8), we have
817"
X,0.7509578544061303,"θucb
i,t ≥θi .
(12)
Furthermore, denote
818"
X,0.7517241379310344,"∆i,t := 2 s"
X,0.7524904214559387,2pij(1 −pij)x
X,0.753256704980843,"ni0,t
+ 11x"
X,0.7540229885057471,"ni0,t
= 2 s"
X,0.7547892720306514,"2θ0θix
(θ0 + θi)2ni0,t
+ 11x"
X,0.7555555555555555,"ni0,t
.
(13)"
X,0.7563218390804598,"In the rest of the proof we assume, ni0,t ≥69x(θ0 + θi). Then, using that θ0θi ≤θ0 + θi
819"
X,0.757088122605364,"since θ0 = 1, it implies
820"
X,0.7578544061302682,"(θ0 + θi)∆i,t ≤2 s"
X,0.7586206896551724,2θ0θix
X,0.7593869731800766,"ni0,t
+ 11x(θ0 + θi)"
X,0.7601532567049808,"ni0,t
≤1 2 ,"
X,0.7609195402298851,"and
821"
X,0.7616858237547893,"pi0 + ∆i,t =
θi
θ0 + θi
+ ∆i,t ≤θi + 1/2"
X,0.7624521072796935,"θi + 1
< 1."
X,0.7632183908045977,"Thus, because f is non-decreasing
822"
X,0.7639846743295019,"θucb
i,t −θi = f(pucb
i0,t) −f(pi0)"
X,0.7647509578544062,"(8)
≤f
 
pi0 + ∆i,t

−f(pi0)"
X,0.7655172413793103,"=
pi0 + ∆i,t
1 −pi0 −∆i,t
−
pi0
1 −pi0"
X,0.7662835249042146,"=
∆i,t
(1 −pi0)(1 −pi0 −∆i,t)"
X,0.7670498084291187,"=
(θ0 + θi)2∆i,t
1 −(θ0 + θi)∆i,t
≤2(θ0 + θi)2∆i,t"
X,0.767816091954023,"(13)
≤4(θ0 + θi) s"
X,0.7685823754789272,2θ0θix
X,0.7693486590038314,"ni0,t
+ 22x(θ0 + θi)2"
X,0.7701149425287356,"ni0,t
,"
X,0.7708812260536398,"which concludes the proof.
823"
X,0.7716475095785441,"B.3
Proof of Lemma 2
824"
X,0.7724137931034483,"Proof. Let T ≥1 and i ∈[K]. Recall that τi,t = Pt−1
s=1 1{i ∈Ss} is the number of times i
825"
X,0.7731800766283525,"was played at the start of round t and ni0,t = Pt−1
s=1 1{it ∈{i, 0}, i ∈St} is the number of
826"
X,0.7739463601532567,"times i or 0 won up to round t when played together. When i is played the probability of 0
827"
X,0.774712643678161,"or i to win is
828"
X,0.7754789272030651,"P(it ∈{i, 0}|St) =
θ0 + θi
θ0 + ΘSt
≥
θ0 + θi
θ0 + ΘS∗."
X,0.7762452107279694,"Therefore, applying Chernoff-Hoeffding inequality together with a union bound (to deal with
829"
X,0.7770114942528735,"the fact that τi,t is random), we have with probability at least 1 −Te−x
830"
X,0.7777777777777778,"ni0,t ≥
θ0 + θi
θ0 + ΘS∗τi,t −
rτi,tx"
X,0.778544061302682,"2
simultaneously for all t ∈[T]. Noting that
831"
X,0.7793103448275862,"θ0 + θi
θ0 + ΘS∗τi,t −
rτi,tx"
X,0.7800766283524905,"2
≥
θ0 + θi
2(θ0 + ΘS∗)τi,t"
X,0.7808429118773946,"if τi,t ≥2x(θ0 + ΘS∗)2 ≥2x(θ0+ΘS∗)2"
X,0.7816091954022989,"(θ0+θi)2
concludes the proof.
832"
X,0.782375478927203,"B.4
Proof of Theorem 3
833"
X,0.7831417624521073,"Proof. Let us define for any S ⊆[K],
834"
X,0.7839080459770115,"ΘS =
X"
X,0.7846743295019157,"i∈S
θi,
and
Θucb
S
:=
X"
X,0.7854406130268199,"i∈S
θucb
i
."
X,0.7862068965517242,"Let E be the high-probabality event such that both Lemma 1 and 2 holds true. Then,
835"
X,0.7869731800766283,"P(E) ≥1 −4TKe−x. Let us first assume that E holds true. Then, by Lemma 1,
836"
X,0.7877394636015326,"Regtop
T
= 1 m T
X"
X,0.7885057471264367,"t=1
ΘS∗−ΘSt ≤1 m T
X"
X,0.789272030651341,"t=1
min
n
ΘS∗, Θucb
St −ΘSt
o
←because ΘS∗≤Θucb
S∗≤Θucb
St under the event E = 1 m T
X"
X,0.7900383141762453,"t=1
min
n
ΘS∗,
X"
X,0.7908045977011494,"i∈St
θucb
i,t −θi
o ≤1 mΘS∗ K
X"
X,0.7915708812260537,"i=1
¯τi0 + 1 m T
X t=1 X"
X,0.7923371647509578,"i∈St
(θucb
i,t −θi)1

τi,t ≥¯τi0"
X,0.7931034482758621,"where ¯τi0 = 2x(θ0 + ΘS∗) max{θ0 + ΘS∗, 69} ≤138x(m + 1)2θ2
max, where θmax := maxi θi.
837"
X,0.7938697318007663,"Then, noting that if E holds true, by Lemma 2, we also have ni0,t ≥
1
2(θ0+ΘS∗)(θ0 + θi)τi,t,
838"
X,0.7946360153256705,"which yields
839"
X,0.7954022988505747,"1{τi,t ≥¯τi0} ≤1{ni0,t ≥69x(θ0 + θi)}.
Therefore, we can apply Lemma 1 that entails,
840"
M,0.7961685823754789,"1
m T
X t=1 X"
M,0.7969348659003831,"i∈St
(θucb
i,t −θi)1

τi,t ≥¯τi0"
M,0.7977011494252874,"Lem. 1
≤
1
m T
X t=1 X i∈St"
M,0.7984674329501916,"
4(θ0 + θi) s"
M,0.7992337164750958,2θ0θix
M,0.8,"ni0,t
+ 22x(θ0 + θi)2 ni0,t"
M,0.8007662835249042,"
1

ni0,t ≥69x(θ0 + θi)"
M,0.8015325670498085,"Lem 2
≤
1
m T
X t=1 X i∈St 
8 s"
M,0.8022988505747126,(θ0 + ΘS∗)(θ0 + θi)θ0θix
M,0.8030651340996169,"τi,t
+ 44x(θ0 + ΘS∗)(θ0 + θi) τi,t  ≤1 m K
X"
M,0.803831417624521,"i=1
16
q"
M,0.8045977011494253,"(θ0 + ΘS∗)(θ0 + θi)θ0θixτi,T + 44x(θ0 + ΘS∗) K
X"
M,0.8053639846743295,"i=1
(θ0 + θi)(1 + log(τi,T )) ,"
M,0.8061302681992337,"where we used Pn
i=1 1/
√"
M,0.8068965517241379,"i ≤2√n and Pn
i=1 i−1 ≤1 + log n. We thus have
841"
M,0.8076628352490421,"Regtop
T
≤138x(m + 1)2Kθ3
max + 1 m K
X"
M,0.8084291187739464,"i=1
16θ3/2
max
q"
M,0.8091954022988506,"(m + 1)xτi,T"
M,0.8099616858237548,"+ 44x(m + 1)(1 + θmax)2
K
X"
M,0.810727969348659,"i=1
(1 + log(τi,T ))"
M,0.8114942528735632,"≤138x(m + 1)2Kθ3
max + 16θ3/2
max
√"
M,0.8122605363984674,"2xKT + 88x(m + 1)Kθ2
max

1 + log
mT K 
."
M,0.8130268199233717,"Therefore,
842"
M,0.8137931034482758,"E[Regtop
T ] ≤12
√"
M,0.8145593869731801,"2xmKθ3
max + 16θ3/2
max
√"
M,0.8153256704980842,"2xKT + 88xmKθ2
max

1 + log
mT K "
M,0.8160919540229885,+ 4mKT 2e−xθmax .
M,0.8168582375478928,"Choosing x = 2 log T concludes the proof.
843"
M,0.8176245210727969,"B.5
Proof of Theorem 5
844"
M,0.8183908045977012,"Proof. Let E be the high-probabality event such that Lemma 1 and 2 are satisfied, so that
845"
M,0.8191570881226053,"P(E) ≥1 −4KTe−x. Then, denoting x ∧y := min{x, y},
846"
M,0.8199233716475096,"Regwtd
T
= T
X"
M,0.8206896551724138,"t=1
E

R(S∗, θ) −R(St, θ)

(14) = T
X"
M,0.821455938697318,"t=1
E

(R(S∗, θ) −R(St, θ))1{E} + (R(S∗, θ) −R(St, θ))1{Ec}
 ≤ T
X"
M,0.8222222222222222,"t=1
E
h 
(R(St, θucb
t
) −R(St, θ)) ∧R(S∗, θ)

1{E} + R(S∗, θ)1{Ec}
i"
M,0.8229885057471265,"because R(St, θucb
t
) ≥R(S∗, θucb
t
) ≥R(S∗, θ) under the event E by Lemma 4. Then, using
847"
M,0.8237547892720306,"R(S∗, θ) ≤maxi ri ≤1, we get
848"
M,0.8245210727969349,"Regwtd
T
≤ T
X"
M,0.825287356321839,"t=1
E
h 
(R(St, θucb
t
) −R(St, θ)) ∧1

1{E} + 1{Ec}
i"
M,0.8260536398467433,"≤4T 2Ke−x + T
X"
M,0.8268199233716476,"t=1
E
h 
R(St, θucb
t
) −R(St, θ)

∧1

1{E}
i
."
M,0.8275862068965517,"Let us upper-bound the second term of the right-hand-side
849 T
X"
M,0.828352490421456,"t=1
E
h 
R(St, θucb
t
) −R(St, θ)

∧1

1{E}
i
(15) = T
X"
M,0.8291187739463601,"t=1
E
 X i∈St"
M,0.8298850574712644,"riθucb
i,t
θ0 + Θucb
St,t
−
riθi
θ0 + ΘSt"
M,0.8306513409961686,"
∧1

1{E}
 ≤ T
X"
M,0.8314176245210728,"t=1
E
 X i∈St"
M,0.832183908045977,"ri(θucb
i,t −θi)
θ0 + ΘSt"
M,0.8329501915708812,"
∧1

1{E}

because Θucb
St,t ≥ΘSt under E ≤ T
X"
M,0.8337164750957854,"t=1
E
 X i∈St"
M,0.8344827586206897,"|θucb
i,t −θi|
θ0 + ΘSt"
M,0.8352490421455939,"
∧1

1{E}

because ri ≤1 ≤ K
X i=1
E ""
T
X t=1"
M,0.8360153256704981,"|θucb
i,t −θi|
θ0 + ΘSt
∧1

1{i ∈St}1{E} #"
M,0.8367816091954023,"≤138xm2Kθ2
max + K
X i=1
E ""
T
X t=1"
M,0.8375478927203065,"|θucb
i,t −θi|
θ0 + ΘSt
1{i ∈St, τi,t ≥138x(m + 1)2θ2
max}1{E} #"
M,0.8383141762452108,"≤138xm2Kθ2
max + K
X i=1"
M,0.8390804597701149,"v
u
u
t T
X t=1
E ""  θ0"
M,0.8398467432950192,"m + θi

1{i ∈St}
θ0 + ΘSt # ×"
M,0.8406130268199233,"v
u
u
t T
X t=1
E"
M,0.8413793103448276,"""|θucb
i,t −θi|
θ0 + ΘSt"
M,0.8421455938697318,2 θ0 + ΘSt
M,0.842911877394636,"θ0
m + θi
1{i ∈St, τi,t ≥138x(m + 1)2θ2
max}1{E} #"
M,0.8436781609195402,"|
{z
}
=:AT (i)
(16)"
M,0.8444444444444444,"where the last inequality is by Cauchy-Schwarz inequality. Now, the term AT (i) above may
850"
M,0.8452107279693487,"be upper-bounded as follows
851"
M,0.8459770114942529,"AT (i) := T
X t=1
E"
M,0.8467432950191571,"""|θucb
i,t −θi|
θ0 + ΘSt"
M,0.8475095785440613,2 θ0 + ΘSt
M,0.8482758620689655,"θ0
m + θi
1{i ∈St, τi,t ≥138x(m + 1)2θ2
max}1{E} # = E"
M,0.8490421455938697,"""
(θucb
i,t −θi)2
  θ0"
M,0.849808429118774,"m + θi

θ0 + ΘSt
1{i ∈St, τi,t ≥138x(m + 1)2θ2
max}1{E} # ."
M,0.8505747126436781,"Now, since under the event E by Lemma 2, τi,t ≥138x(m + 1)2θ2
max implies
852"
M,0.8513409961685824,"ni0,t ≥69x(θ0 + θi)(m + 1)θmax ≥69x(θ0 + θi) ."
M,0.8521072796934865,"Therefore, we can apply Lemma 1, which further upper-bounds
853"
M,0.8528735632183908,"AT (i) ≤ T
X t=1
E"
M,0.8536398467432951,"""26(θ0 + θi)2x"
M,0.8544061302681992,"ni0,t
+ 2(22x)2(θ0 + θi)4"
M,0.8551724137931035,"n2
i0,t( θ0"
M,0.8559386973180076,m + θi) 
M,0.8567049808429119,"× 1{i ∈St, τi,t ≥138x(m + 1)2θ2
max}
θ0 + ΘSt
1{E} # ≤ T
X t=1
E"
M,0.8574712643678161,"""26(θ0 + θi)2x"
M,0.8582375478927203,"ni0,t
+
15x(θ0 + θi)3"
M,0.8590038314176245,"ni0,tθmax(θ0 + mθi)"
M,0.8597701149425288,"
× 1{i ∈St}"
M,0.8605363984674329,"θ0 + ΘSt
1{E} #"
M,0.8613026819923372,"where we used ni0,t ≥69x(θ0 + θi)mθmax in the last inequality. Then, we get
854"
M,0.8620689655172413,"AT (i) ≤ T
X t=1
E"
M,0.8628352490421456,"""(θ0 + θi)2x"
M,0.8636015325670499,"ni0,t
+ 30x(θ0 + θi) ni0,t"
M,0.864367816091954,"
× 1{i ∈St}"
M,0.8651340996168583,"θ0 + ΘSt
1{E} #"
M,0.8659003831417624,"≤(94 + 64θi)x T
X t=1
E"
M,0.8666666666666667,"""
(θ0 + θi)1{i ∈St}"
M,0.8674329501915709,"(θ0 + ΘSt)ni0,t #"
M,0.8681992337164751,"= (94 + 64θi)xE ""
T
X t=1"
M,0.8689655172413793,"1{it ∈{i, 0}, i ∈St} ni0,t #"
M,0.8697318007662835,"= (94 + 64θi)xE
h
1 + log
 
ni0(T)
i"
M,0.8704980842911877,≤158θmaxx(1 + log T) .
M,0.871264367816092,"Substituting into (16), we then obtain using Cauchy-Schwarz inequality,
855 T
X"
M,0.8720306513409962,"t=1
E
h 
R(St, θucb
t
) −R(St, θ)

∧1

1{E}
i"
M,0.8727969348659004,"≤138xm2Kθ2
max + 13
p"
M,0.8735632183908046,"θmaxx(1 + log T) K
X i=1"
M,0.8743295019157088,"v
u
u
t T
X t=1
E ""  θ0"
M,0.8750957854406131,"m + θi

1{i ∈St}
θ0 + ΘSt #"
M,0.8758620689655172,"≤138xm2Kθ2
max + 13
p"
M,0.8766283524904215,θmaxx(1 + log T)
M,0.8773946360153256,"v
u
u
tE "" K T
X t=1"
M,0.8781609195402299,"PK
i=1
  θ0"
M,0.878927203065134,"m + θi

1{i ∈St}
θ0 + ΘSt #"
M,0.8796934865900383,"= 138xm2Kθ2
max + 13
p"
M,0.8804597701149425,θmaxx(1 + log T)KT .
M,0.8812260536398467,"Finally, replacing into Inequality (15) yields
856"
M,0.881992337164751,"Regwtd
T
≤4T 2Ke−x + 138xm2Kθ2
max + 13
p"
M,0.8827586206896552,θmaxx(1 + log T)KT .
M,0.8835249042145594,"Choosing x = 2 log T concludes the proof.
857"
M,0.8842911877394636,"B.6
Proof of Theorem 6
858"
M,0.8850574712643678,"The proof follows the one of Theorem 5, except that the concentration lemmas should be
859"
M,0.885823754789272,"generalized to any pairs (i, j) instead of only with respect to item 0, whose proofs are left
860"
M,0.8865900383141763,"to the reader and closely follows the one of Lemma 1 and 2. For simplicity, this proof is
861"
M,0.8873563218390804,"performed up to universal multiplicative constants, using the rough inequality ≲.
862"
M,0.8881226053639847,"Lemma 9. Let T ≥1 and x > 0. Then, with probability at least 1 −3K(K + 1)Te−x,
863"
M,0.8888888888888888,simultaneously for all t ∈[T] and i ̸= j in [ ˜K]: γij := θi
M,0.8896551724137931,"θj ≤γucb
ij,t and one of the following
864"
M,0.8904214559386974,"two inequalities is satisfied
865"
M,0.8911877394636015,"nij,t < 69x(1 + γij)
or
γucb
ij,t ≤γij + 4(γij + 1) s 2γijx"
M,0.8919540229885058,"nij,t
+ 22x(γij + 1)2"
M,0.89272030651341,"nij,t
."
M,0.8934865900383142,"Lemma 10. Let T ≥1 and x > 0. Then, with probability at least 1 −3K(K + 1)Te−x,
866"
M,0.8942528735632184,"simultaneously for all t ∈[T] and i ∈[K]: bθucb
i,t := minj γucb
ij,tγucb
j0,t ≥θi and for all j one of
867"
M,0.8950191570881226,"the following two inequalities is satisfied
868"
M,0.8957854406130268,"nij,t ≲x(1 + γij)
or
nj0,t ≲x(1 + θj)2θ−1
j"
M,0.896551724137931,"or
869"
M,0.8973180076628352,"γucb
ij,tγucb
j0,t−θi ≲
q"
M,0.8980842911877395,"(γij + 1)θix
s"
M,0.8988505747126436,(θi + θj)
M,0.8996168582375479,"nij,t
+ s"
M,0.9003831417624522,"(1 + θj) nj0,t"
M,0.9011494252873563,"
+(γij+1)(θi + θj)x"
M,0.9019157088122606,"nij,t
+γij(1 + θj)2x"
M,0.9026819923371647,"nj0,t
."
M,0.903448275862069,"Proof of Lemma 10. The proof follows from Lemma 9. If nij,t > Cx(1 + γij) and nj0,t >
870"
M,0.9042145593869731,"Cx(1 + θj) for some large enough constant C, we have
871"
M,0.9049808429118774,"γucb
ij,t ≤γij + 4(γij + 1) s 2γijx"
M,0.9057471264367816,"nij,t
+ 22x(γij + 1)2 nij,t"
M,0.9065134099616858,"and
872"
M,0.90727969348659,"γucb
j0,t ≤γj0 + 4(γj0 + 1) s 2γj0x"
M,0.9080459770114943,"nj0,t
+ 22x(γj0 + 1)2"
M,0.9088122605363985,"nj0,t
≤2γj0 ."
M,0.9095785440613027,"This implies,
873"
M,0.9103448275862069,"γucb
ij,tγucb
j0,t −θi = γucb
ij,tγucb
j0,t −γijγj0 = (γucb
ij,t −γij)γucb
j0,t + γij(γucb
j0,t −γj0)"
M,0.9111111111111111,"≤2(γucb
ij,t −γij)γj0 + γij(γucb
j0,t −γj0)"
M,0.9118773946360154,≤8γj0(γij + 1) s 2γijx
M,0.9126436781609195,"nij,t
+ 44xγj0(γij + 1)2 nij,t"
M,0.9134099616858238,+ 4γij(γj0 + 1) s 2γj0x
M,0.9141762452107279,"nj0,t
+ 22xγij(γj0 + 1)2"
M,0.9149425287356322,"nj0,t
."
M,0.9157088122605364,"Replacing γij = θi/θj and γj0 = θj concludes the proof.
874"
M,0.9164750957854406,"Lemma 11. Let T ≥1 and x > 0. Then, with probability at least 1 −K(K + 1)Te−x
875"
M,0.9172413793103448,"τij,t < 2x(θ0 + ΘS∗)2"
M,0.918007662835249,"θi + θj
or nij,t ≥(θi + θj)τij,t"
M,0.9187739463601533,"2(θ0 + ΘS∗) ,
(17)"
M,0.9195402298850575,"where τij,t := Pt−1
s=1 1{{i, j} ⊆Ss} simultaneously for all t ∈[T] and i ̸= j ∈[K].
876"
M,0.9203065134099617,"Proof of Theorem 6. Let E be the high-probabality event of Lemmas 10 and 11 are satisfied,
877"
M,0.9210727969348659,"so that P(E) ≥1 −4K2Te−x. First, note that since we have under the event E, bθucb
t
≤θucb
t
,
878"
M,0.9218390804597701,"our procedure also satisfies the regret upper-bound
879"
M,0.9226053639846743,"Regwtd
T
≤O(
p"
M,0.9233716475095786,θmaxKT log T)
M,0.9241379310344827,"of Theorem 5. Indeed, all upper-bounds of the proof of Theorem 5 remain valid upper-bounds
880"
M,0.924904214559387,"except the probability of the event Ec which is O(T −1) for x = 2 log T.
881"
M,0.9256704980842911,"Let us now prove that we also have RT ≤O(K
√"
M,0.9264367816091954,"T log T) with no asymptotic dependence on
882"
M,0.9272030651340997,"θmax when T →∞.
883"
M,0.9279693486590038,"Then,
884"
M,0.9287356321839081,"Regwtd
T
= T
X"
M,0.9295019157088122,"t=1
E

R(S∗, θ) −R(St, θ)

(18) = T
X"
M,0.9302681992337165,"t=1
E

(R(S∗, θ) −R(St, θ))1{E} + (R(S∗, θ) −R(St, θ))1{Ec}
 ≤ T
X"
M,0.9310344827586207,"t=1
E
h 
(R(St, bθucb
t
) −R(St, θ)) ∧R(S∗, θ)

1{E} + R(S∗, θ)1{Ec}
i
."
M,0.9318007662835249,"Then, using R(S∗, θ) ≤maxi ri ≤1, we get
885"
M,0.9325670498084291,"Regwtd
T
≤ T
X"
M,0.9333333333333333,"t=1
E
h 
(R(St, bθucb
t
) −R(St, θ)) ∧1

1{E} + 1{Ec}
i"
M,0.9340996168582375,"≤4T 2K(K + 1)2e−x + T
X"
M,0.9348659003831418,"t=1
E
h 
R(St, bθucb
t
) −R(St, θ)

∧1

1{E}
i
.
(19)"
M,0.9356321839080459,"Follow the proof of Theorem 5, we upper-bound the second term of the right-hand-side
886"
M,0.9363984674329502,"of (19):
887 T
X"
M,0.9371647509578545,"t=1
E
h 
R(St, bθucb
t
) −R(St, θ)

∧1

1{E}
i
(20) = T
X"
M,0.9379310344827586,"t=1
E

min
j∈[K] X i∈St"
M,0.9386973180076629,"ribθucb
i,t
1 + P"
M,0.939463601532567,"j∈St bθucb
j,t
−
riθi
1 + P
j∈St θj"
M,0.9402298850574713,"
∧1

1{E}
 ≤ T
X"
M,0.9409961685823754,"t=1
E
 X i∈St"
M,0.9417624521072797,"ri(bθucb
i,t −θi)
θ0 + ΘSt"
M,0.9425287356321839,"
∧1

1{E}

because
X i∈St"
M,0.9432950191570881,"bθucb
i,t ≥ΘSt under E ≤ T
X"
M,0.9440613026819923,"t=1
E
 X i∈St"
M,0.9448275862068966,"|bθucb
i,t −θi|
θ0 + ΘSt"
M,0.9455938697318008,"
∧1

1{E}

because ri ≤1 ≤ K
X i=1
E ""
T
X t=1"
M,0.946360153256705,"|bθucb
i,t −θi|
θ0 + ΘSt
∧1

1{i ∈St}1{E} # ≤ K
X i=1
E ""
T
X t=1"
M,0.9471264367816092,"|γucb
ijt,tγucb
jt0,t −θi|
θ0 + ΘSt
∧1

1{i ∈St}1{E} #"
M,0.9478927203065134,"where jt = argmaxj∈St∪{0} θj, where the last inequality is by definition of bθucb
i,t .
Now,
888"
M,0.9486590038314177,"from Lemma 10, paying an additive exploration cost to ensure that nij,t ≳x(1 + γij) and
889"
M,0.9494252873563218,"nj0,t ≳x(1 + θj)2θj for all j ∈St such that θj ≥θ0. From Lemma 11, this is satisfied if for
890"
M,0.9501915708812261,"some constant C > 0
891"
M,0.9509578544061302,"τij,t > Cm2θ2
maxx ."
M,0.9517241379310345,"Such a condidtion can be wrong for a couple (i, j) ∈S2
t at most during CK2m2θ2
maxx =
892"
M,0.9524904214559387,"O(log T) rounds (since τij,t increases then). Thus, for C large enough,
893 T
X"
M,0.9532567049808429,"t=1
E
h 
R(St, bθucb
t
) −R(St, θ)

∧1

1{E}
i"
M,0.9540229885057471,"≤O(log T) + K
X i=1
E ""
T
X t=1"
M,0.9547892720306513,"|γucb
ijt,tγucb
jt0,t −θi|
θ0 + ΘSt
1{i ∈St, τijt,t ∧τjt,t ≥Cxm2θ2
max}1{E} #"
M,0.9555555555555556,"≲O(log T) + K
X i=1
E ""
T
X t=1 q"
M,0.9563218390804598,"(γijt + 1)θix
s"
M,0.957088122605364,(θi + θjt)
M,0.9578544061302682,"nijt,t
+ s"
M,0.9586206896551724,(1 + θj)
M,0.9593869731800766,"njt0,t "
M,0.9601532567049809,+ (γijt + 1)(θi + θjt)x
M,0.960919540229885,"nijt,t
+ γijt(1 + θjt)2x"
M,0.9616858237547893,"njt0,t"
M,0.9624521072796934,1{i ∈St}
M,0.9632183908045977,θ0 + ΘSt #
M,0.963984674329502,"≤O(log T) + K
X i=1
E ""
T
X t=1 q"
M,0.9647509578544061,"(γijt + 1)θix
s"
M,0.9655172413793104,(θi + θjt)
M,0.9662835249042145,"nijt,t
+ s"
M,0.9670498084291188,(1 + θjt)
M,0.967816091954023,"njt0,t"
M,0.9685823754789272,1{i ∈St}
M,0.9693486590038314,θ0 + ΘSt #
M,0.9701149425287356,"where the last inequality is because using that {i, jt, 0} ⊆St, we have
894"
M,0.9708812260536398,"E

T
X t=1"
M,0.9716475095785441,"1 + θjt
(1 + ΘSt)njt0,t"
M,0.9724137931034482,"
= E

T
X t=1 K
X j=1"
M,0.9731800766283525,"1{it ∈{j, 0}}"
M,0.9739463601532568,"nj0,t
1{j = jt}

≤K(1 + log T)."
M,0.9747126436781609,"and
895"
M,0.9754789272030652,"E

T
X t=1"
M,0.9762452107279693,"θi + θjt
(1 + ΘSt)nijt,t"
M,0.9770114942528736,"
= E

T
X t=1 K
X j=1"
M,0.9777777777777777,"1{it ∈{j, i}}"
M,0.978544061302682,"nj0,t
1{j = jt}

≤K(1 + log T)."
M,0.9793103448275862,"Then, by Cauchy-Schwarz inequality we further get
896 T
X"
M,0.9800766283524904,"t=1
E
h 
R(St, bθucb
t
) −R(St, θ)

∧1

1{E}
i"
M,0.9808429118773946,"≲O(log T) + K
X i=1"
M,0.9816091954022989,"v
u
u
tE ""
T
X t=1"
M,0.9823754789272031,(γijt + 1)θi1{i ∈St}x
M,0.9831417624521073,θ0 + ΘSt # (21) ×
M,0.9839080459770115,"v
u
u
tE ""
T
X t=1"
M,0.9846743295019157,(θi + θjt)
M,0.98544061302682,"nijt,t
+ (1 + θjt)"
M,0.9862068965517241,"njt0,t"
M,0.9869731800766284,1{i ∈St}
M,0.9877394636015325,θ0 + ΘSt #
M,0.9885057471264368,"≲O(log T) + K
X i=1"
M,0.989272030651341,"v
u
u
tE ""
T
X t=1"
M,0.9900383141762452,(γijt + 1)θi1{i ∈St}x
M,0.9908045977011494,"θ0 + ΘSt #
p"
M,0.9915708812260536,K log T
M,0.9923371647509579,"≲O(log T) + K
X i=1"
M,0.993103448275862,"v
u
u
tE ""
T
X t=1"
M,0.9938697318007663,θi1{i ∈St}x
M,0.9946360153256705,"θ0 + ΘSt #
p"
M,0.9954022988505747,K log T (because γijt ≤1 by definition of jt)
M,0.9961685823754789,"≤O(K
p"
M,0.9969348659003832,"Tx log T) = O(K
√"
M,0.9977011494252873,"T log T) ,
(22)"
M,0.9984674329501916,"where the last inequality is by Jensen’s inequality and the equality by setting x = 2 log T to
897"
M,0.9992337164750957,"control the probability that Ec occurs. This concludes the proof.
898"
