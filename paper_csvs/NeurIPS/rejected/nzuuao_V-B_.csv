Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0019120458891013384,"Recent works proposed server-side input recovery attacks in federated learning
1"
ABSTRACT,0.0038240917782026767,"(FL), in which an honest-but-curious server can recover clients’ data (e.g., images)
2"
ABSTRACT,0.0057361376673040155,"using shared model gradients, thus raising doubts regarding the safety of FL.
3"
ABSTRACT,0.0076481835564053535,"However, the attack methods are typically demonstrated on only a few models or
4"
ABSTRACT,0.009560229445506692,"focus heavily on the reconstruction of a single image, which is easier than that of a
5"
ABSTRACT,0.011472275334608031,"batch (multiple images). Thus, in this study, we systematically re-evaluated state-
6"
ABSTRACT,0.01338432122370937,"of-the-art (SOTA) attack methods on a variety of models in the context of batch
7"
ABSTRACT,0.015296367112810707,"reconstruction. For a broad spectrum of models, we considered two types of model
8"
ABSTRACT,0.017208413001912046,"variations: implicit (i.e., without any change in architecture) and explicit (i.e., with
9"
ABSTRACT,0.019120458891013385,"architectural changes). Motivated by the re-evaluation results that the quality of
10"
ABSTRACT,0.021032504780114723,"reconstructed image batch differs per model, we propose angular Lipschitz constant
11"
ABSTRACT,0.022944550669216062,"of a model gradient function with respect to an input as a measure that explains
12"
ABSTRACT,0.0248565965583174,"the vulnerability of a model against input recovery attacks. The prototype of the
13"
ABSTRACT,0.02676864244741874,"proposed measure is derived from our theorem on the convergence of attackers’
14"
ABSTRACT,0.028680688336520075,"gradient matching optimization, and re-designed into the scale-invariant form to
15"
ABSTRACT,0.030592734225621414,"prevent trivial server-side loss scaling trick. We demonstrated the predictability of
16"
ABSTRACT,0.032504780114722756,"the proposed measure on the vulnerability under recovery attacks by empirically
17"
ABSTRACT,0.03441682600382409,"showing its strong monotonic correlation with not only loss drop during gradient-
18"
ABSTRACT,0.036328871892925434,"matching optimization but also the quality of the reconstructed image batch. We
19"
ABSTRACT,0.03824091778202677,"expect our measure to be a key factor for developing client-side defensive strategies
20"
ABSTRACT,0.040152963671128104,"against privacy threats in our proposed realistic FL setting called black-box setting,
21"
ABSTRACT,0.04206500956022945,"where the server deliberately conceals global model information from clients
22"
ABSTRACT,0.04397705544933078,"excluding model gradients.
23"
INTRODUCTION,0.045889101338432124,"1
Introduction
24"
INTRODUCTION,0.04780114722753346,"Federated learning (FL) is a cooperative machine learning between clients as local trainers and
25"
INTRODUCTION,0.0497131931166348,"a central server as a global aggregator [14, 21]. Participants in FL cannot access raw data from
26"
INTRODUCTION,0.05162523900573614,"others and only communicate with one another through gradients, which were believed to leak little
27"
INTRODUCTION,0.05353728489483748,"information of the original data in the past.
28"
INTRODUCTION,0.055449330783938815,"However, recent studies [31, 30, 6, 26, 12] challenge inverting gradients back to original data,
29"
INTRODUCTION,0.05736137667304015,"suggesting that there is potential for an honest-but-curious server to attack by sneakily recovering
30"
INTRODUCTION,0.05927342256214149,"clients’ data from gradients in FL. Their algorithms, so-called gradient inversion attacks, aim at
31"
INTRODUCTION,0.06118546845124283,"optimizing input variables (e.g., images) to match the given gradients under the condition of fixed
32"
INTRODUCTION,0.06309751434034416,"model weights. For better reconstruction quality, state-of-the-art (SOTA) attacks assume that both
33"
INTRODUCTION,0.06500956022944551,"batch normalization (BN) [11] layers’ statistics and private labels are known [6, 26, 12, 8]. However,
34"
INTRODUCTION,0.06692160611854685,"they are demonstrated on a limited range of global models. Thus, we systematically re-evaluated
35"
INTRODUCTION,0.06883365200764818,"SOTA gradient inversion attacks on a variety of models in the context of batch (or multiple images)
36"
INTRODUCTION,0.07074569789674952,"reconstruction, the recovery of input batch from the averaged gradients over itself, which is more
37"
INTRODUCTION,0.07265774378585087,"difficult to solve than single image reconstruction, the recovery of single image from its gradient. In
38"
INTRODUCTION,0.0745697896749522,"this paper, two kinds of model variations are considered, namely implicit and explicit.
39"
INTRODUCTION,0.07648183556405354,"Implicit model variations refer to a collection of different models with the same architecture. In this
40"
INTRODUCTION,0.07839388145315487,"paper, we consider two types of implicit model variations: BN modes and training epochs.
41"
INTRODUCTION,0.08030592734225621,"• As mentioned previously, SOTA gradient inversion attack methods are demonstrated on models
42"
INTRODUCTION,0.08221797323135756,"with BN layers to assume shared BN statistics. Note that there are two modes of a BN layer,
43"
INTRODUCTION,0.0841300191204589,"namely, train mode and eval mode. In the reality of FL, the server can choose any mode among
44"
INTRODUCTION,0.08604206500956023,"them. Therefore, we re-evaluated SOTA attacks by considering both modes of BN. This paper is
45"
INTRODUCTION,0.08795411089866156,"the first to consider BN modes for the evaluation of gradient inversion attacks. We empirically
46"
INTRODUCTION,0.08986615678776291,"found that the quality of reconstructed batch significantly changes by switching BN modes even
47"
INTRODUCTION,0.09177820267686425,"for the same model weights.
48"
INTRODUCTION,0.09369024856596558,"• By reflecting the reality that clients can encounter global model from the server at any time, we
49"
INTRODUCTION,0.09560229445506692,"consider models with different training epochs for the re-evaluation. This scheme extends the
50"
INTRODUCTION,0.09751434034416825,"scope of previous works’ training epoch choices of black-and-white manner: zero training epoch
51"
INTRODUCTION,0.0994263862332696,"(untrained) and maximum training epochs (fully trained). We empirically found that the best
52"
INTRODUCTION,0.10133843212237094,"reconstruction result was usually found at earlier training epochs, not untrained nor fully trained,
53"
INTRODUCTION,0.10325047801147227,"thus raising the need to expand the evaluation criterion for attack methods.
54"
INTRODUCTION,0.10516252390057361,"Meanwhile, explicit model variations are more straightforward than implicit model variations as they
55"
INTRODUCTION,0.10707456978967496,"only involve architectural changes. In this study, we consider two types of explicit model variations:
56"
INTRODUCTION,0.1089866156787763,"skip connections and channel size.
57"
INTRODUCTION,0.11089866156787763,"• Residual networks (ResNets) [9] are frequently employed in previous works [26, 6, 31, 12] even
58"
INTRODUCTION,0.11281070745697896,"for batch reconstruction, while networks without skip connection are introduced for only for the
59"
INTRODUCTION,0.1147227533460803,"recovery of single image from its gradient [6]. Therefore, we explored how a skip connection
60"
INTRODUCTION,0.11663479923518165,"affects the quality of SOTA gradient inversion attacks in the context of batch reconstruction. Our
61"
INTRODUCTION,0.11854684512428298,"empirical findings suggest that models without skip connection are more robust against the gradient
62"
INTRODUCTION,0.12045889101338432,"inversion attack than residual networks.
63"
INTRODUCTION,0.12237093690248566,"• The reconstruction quality is known to increase with the number of channels, but this property is
64"
INTRODUCTION,0.124282982791587,"demonstrated on single image reconstruction [30, 6]. Thus, we recap how the number of channels
65"
INTRODUCTION,0.12619502868068833,"affects the attack quality in the context of batch reconstruction.
66"
INTRODUCTION,0.12810707456978968,"By re-evaluating SOTA attacks in a variety of models, we found that the vulnerability against gradient
67"
INTRODUCTION,0.13001912045889102,"inversion attack significantly differs per model, implying the need of more strict evaluation criteria
68"
INTRODUCTION,0.13193116634799235,"for attack methods. Then, clients are required to judge whether a shared model from the server is safe
69"
INTRODUCTION,0.1338432122370937,"or not before sending locally computed gradients back for their privacy. In this study, we consider
70"
INTRODUCTION,0.13575525812619502,"two settings on the transparency of global model information to clients: white-box and black-box.
71"
INTRODUCTION,0.13766730401529637,"In a white-box setting, clients have an absolute control over global model such as the server; thus,
72"
INTRODUCTION,0.13957934990439771,"clients can directly apply SOTA attacks to the model to assess its vulnerability.
73"
INTRODUCTION,0.14149139579349904,"On the other hand, a black-box setting only allows clients control over model gradients to restrict
74"
INTRODUCTION,0.14340344168260039,"access to the global model possibly due to companies’ secrets. For the client-side measurement of
75"
INTRODUCTION,0.14531548757170173,"privacy leakage in this practical and difficult setting, we propose angular Lipschitz constant of model
76"
INTRODUCTION,0.14722753346080306,"gradients with respect to an input as a predictive measure for the quality of reconstructed samples
77"
INTRODUCTION,0.1491395793499044,"inverted from model gradients.
78"
INTRODUCTION,0.15105162523900573,"This measure is derived from our theorem in Sec. 4 that an attacker’s gradient matching loss function
79"
INTRODUCTION,0.15296367112810708,"drops more abruptly with a smaller L in a particular range, where L is Lipschitz constant of model
80"
INTRODUCTION,0.15487571701720843,"gradients with respect to an input. However, using L as a measure for privacy leakage would be
81"
INTRODUCTION,0.15678776290630975,"inappropriate as L can be any nonnegative value by loss function scaling. Therefore, inspired by
82"
INTRODUCTION,0.1586998087954111,"scale-invariant cosine similarity loss function, we propose the angular Lipschitz constant, a loss
83"
INTRODUCTION,0.16061185468451242,"scaling-invariant alternative to L. We experimentally found that both measure motonically correlates
84"
INTRODUCTION,0.16252390057361377,"with not only total loss drop during an attacker’s optimization but also the reconstruction quality
85"
INTRODUCTION,0.16443594646271512,"than the norm of gradients. These findings are expected to support the construction of client-side
86"
INTRODUCTION,0.16634799235181644,"defense algorithms particularly for black-box setting, where only model gradients are given to clients
87"
INTRODUCTION,0.1682600382409178,"as minimal information of the model as described in Fig. 5.
88"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.1701720841300191,"2
Prior Art in the Gradient Inversion Attack
89"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.17208413001912046,"Given the neural network function fw : Rb×d →Rb×c (w, b, d, c being the model weights, batch size,
90"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.1739961759082218,"image size, and the number of classes, respectively), and the gradient g∗= ∂L(fw(x∗),y∗)"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.17590822179732313,"∂w
computed
91"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.17782026768642448,"with ground truth input batch (x∗, y∗) ∈Rb×d×Rb (x∗, y∗being the image batch, and corresponding
92"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.17973231357552583,"label batch) and the loss function L : Rb×c × Rb →R (e.g., cross-entropy loss), the goal of gradient
93"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.18164435946462715,"inversion attack is to reconstruct an image batch x ∈Rb×d, a resemblance of ground truth image
94"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.1835564053537285,"batch x∗. In the context of federated learning (FL), fw is the global model, and g∗is the gradient
95"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.18546845124282982,"computed from a client. Then, a honest-but-curious server aims to recover the client’s private data x∗.
96"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.18738049713193117,"A general method to tackle the problem of inverting gradients is to solve an optimization problem
97"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.18929254302103252,"formulated as follows:
98"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.19120458891013384,"arg min
x,y
Lgrad(∂L(fw(x), y)"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.1931166347992352,"∂w
, ∂L(fw(x∗), y∗)"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.1950286806883365,"∂w
) + αpriorRprior(x),
(1)"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.19694072657743786,"where Lgrad : RN × RN →R (N is the size of weights w) is the loss function for gradient matching
99"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.1988527724665392,"(which closes the distance between current gradients and target gradients), Rprior : Rb×d →R is the
100"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.20076481835564053,"regularization loss for image prior, with αprior being its coefficient.
101"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.20267686424474188,"Prior to the advent of packages for automatic differentiation, the gradient term g = ∂L(fw(x),y)"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.2045889101338432,"∂w
was
102"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.20650095602294455,"computed as a function of (x, y) in a closed form. For the computation to be tractable, Lgrad was
103"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.2084130019120459,"set to a squared loss (L(g, g∗) = ||g −g∗||2
2), and fw was also slightly modified from the original
104"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.21032504780114722,"design of contemporary neural networks. For example, ReLU activation functions were replaced with
105"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.21223709369024857,"Sigmoid, and all the strides in convolution modules were excluded from the original ResNet in [31].
106"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.21414913957934992,"Consequently, the choice of fw was limited.
107"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.21606118546845124,"Currently, with the advantages of automatic differentiation [22] and advanced deep learning opti-
108"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.2179732313575526,"mization algorithms [13, 23, 5], solving for optimization problem in (1) becomes tractable for most
109"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.2198852772466539,"contemporary deep neural networks without the need for modification. Further, the gradient matching
110"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.22179732313575526,"loss is selected in a broad range from cosine similarity loss (L(g, g∗) = 1 −<g,g∗>"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.2237093690248566,"||g||||g∗||) [6, 12, 10, 26]
111"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.22562141491395793,"to L2 loss (L(g, g∗) = ||g −g∗||2
2) [31, 29, 26]. The liberation from the limited choice of loss
112"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.22753346080305928,"functions and neural network architectures became the trigger of state-of-the-art attack methods.
113"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.2294455066921606,"State-of-the-art attack methods provide several assumptions which enable the baseline, which is only
114"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.23135755258126195,"gradient-based, to be expanded.
115"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.2332695984703633,"First, the server is supposed to know the private labels of clients’ images. Currently, estimating x
116"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.23518164435946462,"and y becomes a sequential process, in which y is estimated first, after which x is approximated with
117"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.23709369024856597,"the estimated y = y∗
approx given. Rather than jointly learning x and y in (1), prior works suggest
118"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.2390057361376673,"estimating y directly by seeing the gradients from ground truth data g∗before optimization [26, 29].
119"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.24091778202676864,"Therefore, the problem of estimating labels from gradients is separated from the original optimization
120"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.24282982791587,"problem in (1) [3, 25, 16] and some works, which focus on reconstruction of images rather than
121"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.2447418738049713,"labels, assume that private labels are known [6, 12].
122"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.24665391969407266,"Second, the local batch statistics {µl(x∗; w), σl2(x∗; w)}M
l=1 (µl(x∗; w), σl(x∗; w), and M being
123"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.248565965583174,"the batch mean of the lth batch normalization layer, batch standard deviation of the lth batch
124"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.25047801147227533,"normalization (BN) layer, and number of the BN layers, respectively), computed with client’s data
125"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.25239005736137665,"batch, is given to the server. This assumption reflects a naive approach of a FL algorithm called
126"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.25430210325047803,"FedAvg [21] on the global model with BN layers [19, 17]. When {µl(x∗; w), σl(x∗; w)2}M
l=1 is
127"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.25621414913957935,"shared from a client to the server for the update of population statistics in the global model’s BN
128"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.25812619502868067,"layers, the server as an honest-but-curious adversary would work to add up the batch statistics
129"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.26003824091778205,"matching loss term to (1) to ensure a stronger attack.
130"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.26195028680688337,"Then, optimization problem in (1) can be rewritten by considering both assumptions mentioned
131"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.2638623326959847,"previously as follows:
132"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.26577437858508607,"arg min
x
Lgrad(∂L(fw(x), y∗)"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.2676864244741874,"∂w
, ∂L(fw(x∗), y∗)"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.2695984703632887,"∂w
)+αpriorRprior(x)+αBN M
X"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.27151051625239003,"l=1
RBN((µl, σl
2), (µ∗
l , σ∗
l
2))"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.2734225621414914,"(2)
, where RBN is the BN statistics matching loss and αBN being its coefficient with (µl, σl) =
133"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.27533460803059273,"(µl(x; w), σl2(x; w)) and (µ∗
l , σ∗
l ) = (µl(x∗; w), σl2(x∗; w)).
134"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.27724665391969405,"By solving the optimization problem in (2), high resolution images (e.g. ImageNet [4]) with a
135"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.27915869980879543,"batch size of up to 40 can be constructed in [26]. However, fw is only considered for three models:
136"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.28107074569789675,"ImageNet pre-trained ResNet18 model, ImageNet pre-trained ResNet50 model, and MOCO v2 [2]
137"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.2829827915869981,"pre-trained ResNet50 model fine-tuned with ImageNet. However, there are various choices of fw.
138"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.28489483747609945,"Although a broad spectrum of fw choices is introduced in [6] (e.g., increasing channel size, models
139"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.28680688336520077,"with or without skip connection), the authors of the work verified the effect from model variations on
140"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.2887189292543021,"single image reconstruction as well as considered the optimization problem of the form (1) rather
141"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.29063097514340347,"than (2). Thus, in this paper, we recap how model variations considered in [6] affect reconstruction
142"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.2925430210325048,"of multiple images in a batch by solving optimization problem of the form (2) to achieve a better
143"
PRIOR ART IN THE GRADIENT INVERSION ATTACK,0.2944550669216061,"quality of reconstructed samples.
144"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.29636711281070743,"3
Re-evaluation of SOTA Gradient Attacks on a Broad Spectrum of Models
145"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.2982791586998088,"Prior works in gradient inversion attacks properly select limited range of models with vulnerability
146"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.30019120458891013,"under the proposed attack methods to demonstrate their effectiveness [26, 12, 30, 6]. Therefore, this
147"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.30210325047801145,"study aims to re-evaluate state-of-the-art attack methods on a broad spectrum of models. The target
148"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.30401529636711283,"of our evaluation is attack methods that can solve the optimization problem of the form (2) assuming
149"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.30592734225621415,"that the server as an honest-but-curious attacker desires to reconstruct multiple private images from
150"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3078393881453155,"batch gradients given, which is rarely studied previously. The model variations we considered are
151"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.30975143403441685,"twofold: implicit and explicit.
152"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.31166347992351817,Original
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3135755258126195,"BN with 
eval mode"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3154875717017208,"Untrained
e=5
Fully-trained
e=10
e=25
e=50
e=150
e=225"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3173996175908222,"BN with 
train mode"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3193116634799235,"Figure 1: Visualization of reconstructed images from implicit model variations of ResNet18.
Here e denotes training epochs. Then, “Untrained” means e = 0, and “Fully-trained” means e = 300
as the ResNet18 model is trained on CIFAR100 training set up to 300 epochs. Reconstructed images
in the red dotted line box come from our choices of e. Original images (a woman image, an apple
image, a beetle image) were randomly sampled from the CIFAR100 validation set."
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.32122370936902483,"3.1
Implicit model variation: BN modes and training epochs
153"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3231357552581262,"While explicit model variation refers to an architectural change such as increasing channel sizes of
154"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.32504780114722753,"the model, as suggested in [6], implicit model variation is invisible in the architectural level. However,
155"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.32695984703632885,"changes arise internally within the same architecture such as applying different weights with different
156"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.32887189292543023,"training epochs or switching the mode of normalization layers (e.g., switching between train and
157"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.33078393881453155,"eval modes for BN). This is the first work to introduce the concept of implicit model variation. More
158"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3326959847036329,"0  
5  
10 
25 
50 
150
225
300
Epoch MSE"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.33460803059273425,"BN eval mode
BN train mode"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3365200764818356,"0  
5  
10 
25 
50 
150
225
300
Epoch 0 0.05 0.1 0.15 0.2 0.25 LPIPS"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3384321223709369,"BN eval mode
BN train mode"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3403441682600382,"Figure 2: Plotting the quality of reconstructed samples from implicit model variations of
ResNet18 in terms of MSE (↓, left) and LPIPS (↓, right)."
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3422562141491396,"specifically, this is the first time implicit model variation is considered for the evaluation of gradient
159"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3441682600382409,"inversion attacks. Interestingly, we experimentally found that the reconstruction quality ranges in a
160"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.34608030592734224,"broad spectrum over implicit model variations.
161"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3479923518164436,"3.1.1
BN modes: motivation
162"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.34990439770554493,"State-of-the-art gradient inversion attack methods elevate the quality of reconstructed samples by
163"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.35181644359464626,"introducing batch statistics matching loss to the original problem of gradient matching as in (2).
164"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.35372848948374763,"Therefore, we adopt a global model with BN layers to realize shared batch statistics in FL. BN
165"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.35564053537284895,"layer has two modes of operation: train mode and eval mode [11]. However, recent works have
166"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3575525812619503,"not specified which mode is set for their demonstration while the malicious server, at least as an
167"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.35946462715105165,"honest-but-curious attacker, can send a global model with BN layers set to any mode. Therefore,
168"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.361376673040153,"this study considers both BN train mode and BN eval mode for the re-evaluation of SOTA gradient
169"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3632887189292543,"attacks. Our re-evaluation results show that reconstruction results from different BN modes can be
170"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3652007648183556,"significantly different from each other even in terms of the same model weights as in Tab. 1.
171"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.367112810707457,"Epoch (e)
MSE ↓
PSNR ↑
LPIPS ↓"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3690248565965583,"0
0.8499 ± 0.1996
12.8833 ± 1.241
0.1233 ± 0.0227"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.37093690248565964,"5
1.5033 ± 0.1157
10.4366 ± 0.43
0.0915 ± 0.0081"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.372848948374761,"10
1.7985 ± 0.1766
9.87 ± 0.2749
0.1037 ± 0.0099"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.37476099426386233,"25
1.8072 ± 0.1042
10.02 ± 0.5716
0.1362 ± 0.0263"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.37667304015296366,"50
1.7941 ± 0.3291
9.8666 ± 0.5507
0.1451 ± 0.0153"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.37858508604206503,"150
1.7361 ± 0.0783
10.34 ± 0.3732
0.1307 ± 0.0167"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.38049713193116635,"225
1.8495 ± 0.2759
10.1866 ± 0.4878
0.1393 ± 0.0214"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3824091778202677,"300
1.8899 ± 0.1575
9.75 ± 0.4313
0.1459 ± 0.0038"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.384321223709369,(a) BN with eval mode
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3862332695984704,"Epoch (e)
MSE ↓
PSNR ↑
LPIPS ↓"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3881453154875717,"0
1.9045 ± 0.0195
8.9265 ± 0.0665
0.2362 ± 0.0113"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.390057361376673,"5
0.6921 ± 0.1601
14.9733 ± 0.9168
0.0459 ± 0.0164"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3919694072657744,"10
1.1367 ± 0.0434
12.5 ± 0.2861
0.0624 ± 0.0035"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3938814531548757,"25
1.3015 ± 0.3402
11.6733 ± 1.4027
0.097 ± 0.04"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.39579349904397704,"50
1.66 ± 0.1831
10.0433 ± 0.6354
0.1601 ± 0.041"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.3977055449330784,"150
1.6581 ± 0.3138
10.2066 ± 1.1074
0.1444 ± 0.0279"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.39961759082217974,"225
1.8497 ± 0.315
9.49 ± 1.008
0.174 ± 0.0151"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.40152963671128106,"300
1.8353 ± 0.3703
9.4333 ± 0.8832
0.1812 ± 0.0342"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.40344168260038243,(b) BN with train mode
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.40535372848948376,"Table 1: Quantitative comparison between reconstruction results for 50 CIFAR100 images from
ResNet18 model with BN set to (a) eval mode and (b) train mode. MSE (↓), PSNR (↑), and LPIPS
(↓) are used as evaluation metrics. We highlight the best performance for each column in bold."
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4072657743785851,"3.1.2
Training epochs: motivation
172"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4091778202676864,"In a scenario of FL, a client can participate at any time during training. Then, a client can encounter
173"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4110898661567878,"the global model with arbitrary performance. This fact contradicts previous works’ experimental
174"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4130019120458891,"setup, where the global model is chosen in a dichotomous manner: an untrained (or initialized) model
175"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4149139579349904,"or a model fully trained on the training set [6, 26]. Therefore, we re-evaluated SOTA inversion
176"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4168260038240918,"attacks on models with a broad spectrum of training epochs. We empirically found that the best
177"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4187380497131931,"reconstruction quality is usually obtained at earlier training epochs.
178"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.42065009560229444,"3.1.3
BN modes and training epochs: experimental results
179"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4225621414913958,"Setup
We trained a ResNet18 model on CIFAR100 [15] training set for 300 epochs using SGD
180"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.42447418738049714,"optimizer with initial learning rate 0.1, momentum 0.9, and learning rate decay 0.1 applied when
181"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.42638623326959846,"e = 150 and e = 225 for the training epoch e. During training, we saved checkpoints of model
182"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.42829827915869984,"weights when e ∈{0, 5, 10, 25, 50, 150, 225, 300} to consider the models from different training
183"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.43021032504780116,"epochs. We oversampled model weights before the first learning decay (0 < e < 150) to cover the
184"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4321223709369025,"whole set of dynamically changing model weights in the beginning of training. On the other hand,
185"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4340344168260038,"hyperparameters and loss function choices for input reconstruction attacks are borrowed from [10].
186"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4359464627151052,"Results
As expected from their difference in batch statistics computation, BN with train mode
187"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4378585086042065,"and BN with eval mode show different reconstruction results both qualitatively (see Fig. 1.) and
188"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4397705544933078,"quantitatively (see Fig. 2 and Tab. 1.). When BN is set to eval mode, partial information (e.g. colors
189"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4416826003824092,"or shapes) is barely leaked in reconstructed images only for the cases e = 0 and e = 5 as described
190"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4435946462715105,"in Fig. 1 and Fig. 2. On the other hand, for BN with train mode, the quality of reconstructed images
191"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.44550669216061184,"were sufficient enough to identify the object in each image only for the cases e = 5, 10, 25. Unlike
192"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4474187380497132,"the BN mode set to eval mode, it is remarkable that reconstructed images from BN with train mode
193"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.44933078393881454,"in Fig. 1 are noisy images for e = 0. For the cases e ≥50, input reconstruction failed for both BN
194"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.45124282982791586,"modes and reconstructed images even from the same target gradients look significantly different
195"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.45315487571701724,"for different BN modes. However, both BN with train mode and BN with eval mode have similar
196"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.45506692160611856,"reconstruction quality in terms of both mean squared error (MSE) and Learned Perceptual Image
197"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4569789674952199,"Patch Similarity (LPIPS) [28] in Fig. 2 and Tab. 1. Therefore, in the early stage of training, a global
198"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4588910133843212,"model would be privacy threatening with high probability.
199"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4608030592734226,"3.2
Explicit model variation: skip connection and channel size
200"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4627151051625239,"Explicit model variations involve change in architecture level like removing skip connections in
201"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4646271510516252,"residual blocks or increasing the number of channels in convolution module, which are the kinds
202"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4665391969407266,"considered in previous works but on single image reconstruction. Therefore, we re-explore the effect
203"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4684512428298279,"of skip connection and channel size on the model’s vulnerability against gradient inversion attack
204"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.47036328871892924,"but in the context of batch reconstruction. Skip connection helps information flow both forward
205"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4722753346080306,"and backward through the network, thus input reconstruction is expected to be easier for residual
206"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.47418738049713194,"networks but harder for models without skip connection [9]. On the other hand, increasing channel
207"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.47609942638623326,"size implies increasing dimension of gradients, which is the capacity of gradients to store information.
208"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4780114722753346,"Therefore, we expect that more information about input would be compressed in gradients when the
209"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.47992351816443596,"number of channels increase.
210"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4818355640535373,"Figure 3: Visualization of reconstructed images
from ConvNet on CIFAR100. In each image
block, the images at the positions of the red, pink,
and green borders denote the original image, the
reconstruction with BN (eval mode), and the re-
construction with BN (train mode), respectively.
Original images were randomly sampled from CI-
FAR100 validation set."
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4837476099426386,"ResNet18
ResNet18-2
ResNet18-4
# channel 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1 LPIPS"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.48565965583174,"BN eval mode
BN train mode"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4875717017208413,"Figure 4: Plotting the best reconstruction quality in terms of LPIPS
(↓) among model variations through training epochs for ResNet18,
ResNet18-2, ResNet18-4 models with BN eval (orange) and train
(blue) modes. e = 5 or e = 10 usually result in the best reconstruction
quality. As channel size increases, the reconstruction quality increases
for BN eval but decreases for BN train."
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4894837476099426,"3.2.1
Skip connection and channel size: experimental results
211"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.491395793499044,"Setup
Instead of ResNet18, we trained a ConvNet model, ResNet18-2 model, and ResNet18-4
212"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.4933078393881453,"model for explicit model variations. ConvNet, which is introduced in [6] for the first time, is a
213"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.49521988527724664,"convolutional neural network without skip connection and ResNet18-2 and ResNet18-4 being ResNet
214"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.497131931166348,"with channel size doubled and quadrupled, respectively. Note that we apply implicit variations
215"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.49904397705544934,"considered in the Sec. 3.1 to the models. Training conditions and hyperparameters for both model
216"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5009560229445507,"training and attack methods are kept the same with the setup in the previous section.
217"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.502868068833652,Figure 5: White-box (left) and black-box (right) FL settings.
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5047801147227533,"0
2
4
6
8
10
12
14
Linit ! Lfinal 0 10 20 30 40 50 60 ~
Lx$"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5066921606118547,"ConvNet train
ResNet18 train
ResNet18-2 train
ResNet18-4 train
ConvNet eval
ResNet18 eval
ResNet18-2 eval
ResNet18-4 eval"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5086042065009561,(a) All models (rs = −0.78)
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5105162523900574,"0
2
4
6
8
10
Linit ! Lfinal 0 5 10 15 20 25 ~
Lx$"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5124282982791587,"ResNet18 train
ResNet18-2 train
ResNet18-4 train"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.51434034416826,"(b) ResNets, BN train (rs = −0.87)"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5162523900573613,"0
2
4
6
8
10
12
14
Linit ! Lfinal 0 5 10 15 20 25 ~
Lx$"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5181644359464627,"ResNet18 eval
ResNet18-2 eval
ResNet18-4 eval"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5200764818355641,"(c) ResNets, BN eval (rs = −0.66)"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5219885277246654,"Figure 6: Proposed measure ˜
Lx∗is approximately a monotonic decreasing function with respect
to Linit −Lfinal, the difference between initial (Linit) and final losses (Lfinal) among (a) all
models, (b) ResNet models with BN train mode, and (c) ResNet models with BN eval mode
considered in Sec. 3."
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5239005736137667,"Results
Reconstructed images from ConvNet models with the best quality, in terms of LPIPS,
218"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5258126195028681,"are listed in Fig. 3. For ConvNet models, reconstructed images, even with the best quality, are
219"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5277246653919694,"far from original images visually due to severe artifacts. Therefore, as expected from the role of
220"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5296367112810707,"skip connection in residual networks, a network without skip connection like ConvNet seems to be
221"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5315487571701721,"robust against input recovery attacks. Then, ConvNet models would be considered as global model
222"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5334608030592735,"candidates for privacy protection in FL despite of their worse performance than that of residual
223"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5353728489483748,"networks.
224"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5372848948374761,"By contrast, the best averaged reconstruction results among the sampled training epochs e ∈
225"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5391969407265774,"{0, 5, 10, 25, 50, 150, 225, 300} are plotted in Fig. 4 for ResNet18, ResNet18-2, and ResNet18-
226"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5411089866156787,"4 models with varied BN modes. When BN is set to the eval mode, the reconstruction quality
227"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5430210325047801,"increases as the number of channels increases as expected. However, the reconstruction quality
228"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5449330783938815,"worsens as the number of channels increases for BN set to the train mode, which breaks the belief
229"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5468451242829828,"from previous works that increasing channel size makes input recovery attack easier [6, 30]. However,
230"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5487571701720841,"the reconstruction quality obtained with BN train mode is better than that with BN eval mode for all
231"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5506692160611855,"models considered except ResNet18-4, where their LPIPS range overlaps, implying that BN train
232"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5525812619502868,"mode is vulnerable against input recovery attacks than BN eval mode. The quantitative results for
233"
RE-EVALUATION OF SOTA GRADIENT ATTACKS ON A BROAD SPECTRUM OF MODELS,0.5544933078393881,"ConvNet, ResNet18-2, and ResNet18-4 are provided in Appendix A1.
234"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5564053537284895,"4
Lipschitz Smoothness for Client-Side Privacy Leakage Detection
235"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5583173996175909,"For privacy-preserving FL, choosing global model robust against any server-side input reconstruction
236"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5602294455066922,"attack method would be important. At the least, global model should be robust against well-known
237"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5621414913957935,"SOTA gradient inversion attack methods to alleviate clients’ anxiety about any potential leakage from
238"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5640535372848948,"gradient sharing with the server. If clients can access the global model with the same level of a central
239"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5659655831739961,"server (white-box), applying SOTA attack methods directly to the global model with private images
240"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5678776290630975,"would be the best way for assessing whether or not the global model presents a risk to the client’s
241"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5697896749521989,"privacy. However, in general, global model information would be opaque to clients due to company
242"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5717017208413002,"secrets. As clients should communicate with the server via locally computed gradients, we suppose
243"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5736137667304015,"the black-box setting, where model gradients are given to clients as minimal information of the global
244"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5755258126195029,"model. Therefore, we provide a helpful measure for developing the system for clients to examine
245"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5774378585086042,"whether the given global model is safe in terms of privacy by using gradients computed with their
246"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5793499043977055,"self-controlled inputs. Note that white-box and black-box are described in Fig. 5.
247"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5812619502868069,"4.1
Angular Lipschitz smoothness: motivation
248"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5831739961759083,"If a function f : Rn →Rm is Lipschitz smooth (or the derivative of f is Lipschitz continuous) with
249"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5850860420650096,"constant L, then the following holds: ||∇f(x) −∇f(y)|| ≤L||x −y|| ∀x, y ∈Rn. The concept of
250"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5869980879541109,"Lipschitz smoothness or Lipschitz continuity is frequently employed to prove convergence theorem
251"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5889101338432122,"of gradient descent methods for optimization [24, 7, 27, 20, 18, 1]. This study employs the concept
252"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5908221797323135,"of Lipschitz smoothness to prove the following theorem in the context of gradient matching problem.
253"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5927342256214149,"Theorem 1 (Monotonic decreasing loss function). Suppose ∇wL(f(x), y) is Lipschitz continuous
254"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5946462715105163,"with respect to x with constant L and Lx
grad = ||∇wL(f(x), y)−g∗||2
2 is given as a gradient matching
255"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5965583173996176,"loss. Then, when gradient descent △x is applied with step size µ > 0 and L > ϵ for some ϵ > 0, the
256"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.5984703632887189,"following holds:
257"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6003824091778203,"Lx+△x
grad
≤Lx
grad −1"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6022944550669216,"L2 ||
∂Lx
grad
∂x
||2
2.
(3) 258"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6042065009560229,"Inequality (3) implies that gradient matching loss strictly decreases as the gradient descent steps
259"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6061185468451242,"unless the gradient term
∂Lx
grad
∂x
is zero (i.e. gradient matching loss already converges). Furthermore,
260"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6080305927342257,"a gradient descent with a small L (or large
1
L2 ) can accelerate the convergence of gradient matching
261"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.609942638623327,"optimization but with the premise that L > ϵ for ϵ > 0. This premise is required to ensure the
262"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6118546845124283,"first-order Taylor approximation for ∇wL(f(x + △x), y) in the proof in Appendix A2. Therefore, in
263"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6137667304015296,"a particular range of L (i.e., L > ϵ), we hypothesize that a global model with smaller L experiences a
264"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.615678776290631,"sharper loss drop in gradient matching optimization. We empirically found that L is not too small for
265"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6175908221797323,"most models, thus meeting the premise in reality.
266"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6195028680688337,"For
the
empirical
verification
of
the
hypothesis
in
the
context
of
input
reconstruc-
267"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.621414913957935,"tion, we desire to compute Lipschitz smoothness constant locally around x∗, Lx∗,ϵ
=
268"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6233269598470363,"sup||x−x∗||<ϵ,x̸=x∗||∇wL(f(x),y)−∇wL(f(x∗),y)||"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6252390057361377,"||x−x∗||
, with small ϵ, for the models considered in Sec-
269"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.627151051625239,"tions 3.1 and 3.2. Recent works on computing precise upper bound of L only focus on multi-layer
270"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6290630975143403,"perceptrons (MLP) due to the difficulty of computing L for normalization layers or residual layers.
271"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6309751434034416,"Therefore, Lx∗,ϵ is estimated as ˜
Lx∗= maxn̸=0
||∇wL(f(x∗+n),y)−∇wL(f(x∗),y)||"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6328871892925431,"||n||
by sampling 1,000
272"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6347992351816444,"noises (n) from the Gaussian distribution N(0, 0.0012) in our experiments.
273"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6367112810707457,"However, ˜
Lx∗can be any nonnegative value by scaling loss function L. If L is scaled by nonnegative
274"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.638623326959847,"scalar k, then
˜
Lx∗is scaled by k too, allowing
˜
Lx∗to be manipulated by the server using simple
275"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6405353728489483,"loss scaling. Therefore, inspired by the cosine similarity loss function, which is scale-invariant,
276"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6424474187380497,"we propose the angular Lipschitz constant
˜
Lcos
x∗= maxn̸=0
1−cs(∇wL(f(x∗+n),y),∇wL(f(x∗),y))"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6443594646271511,"1−cs(x∗,x∗+n)
(cs
277"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6462715105162524,"being the cosine similarity loss) as a loss scaling-invariant alternative to ˜
Lx∗. We find hat
˜
Lcos
x∗shows
278"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6481835564053537,"a strong monotonic correlation with the quality of reconstructed samples, demonstrating the potential
279"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6500956022944551,"of
˜
Lcos
x∗to be imperative for client-side defense methods.
280"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6520076481835564,"4.2
Angular Lipschitz smoothness: experimental results
281"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6539196940726577,"We computed
˜
Lx∗and the attacker’s loss drop Linit −Lfinal (Linit and Lfinal being the initial and
282"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.655831739961759,"final losses, respectively) for the models and input batches considered in Sec. 3 (Fig. 6a). We also
283"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6577437858508605,"quantified their correlation using the Spearman’s rank correlation coefficient rs, which quantifies
284"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6596558317399618,"how two variables are in a monotonic relationship. rs = 1 (rs = −1) means that one variable is
285"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6615678776290631,"a completely monotonic increasing (decreasing) function with respect to the other one. Then,
˜
Lx∗
286"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6634799235181644,"is almost a monotonic decreasing function with respect to Linit −Lfinal with rs = −0.78, thus
287"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6653919694072657,"validating our hypothesis. For ResNet models with BN train (Fig. 6b),
˜
Lx∗and Linit −Lfinal
288"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6673040152963671,"show a stronger monotonic correlation than that for ResNet models with BN eval (Fig. 6c) with
289"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6692160611854685,"0
0.05
0.1
0.15
0.2
0.25
LPIPS 0 5 10 15 20 25"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6711281070745698,jjg$jj2
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6730401529636711,"ResNet18 train
ResNet18-2 train
ResNet18-4 train"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6749521988527725,"(a) ||g∗||2, BN train (rs = 0.55)"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6768642447418738,"0
0.05
0.1
0.15
0.2
0.25
LPIPS 0 5 10 15 20 25 ~
Lx$"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6787762906309751,"ResNet18 train
ResNet18-2 train
ResNet18-4 train"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6806883365200764,"(b)
˜
Lx∗, BN train (rs = 0.79)"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6826003824091779,"0
0.05
0.1
0.15
0.2
0.25
LPIPS 0 50 100 150 200 250 300"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6845124282982792,"~
Lcos x$"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6864244741873805,"ResNet18 train
ResNet18-2 train
ResNet18-4 train"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6883365200764818,"(c)
˜
Lcos
x∗, BN train (rs = 0.72)"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6902485659655831,"0.05
0.1
0.15
0.2
0.25
LPIPS 0 5 10 15 20 25 30 35"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6921606118546845,jjg$jj2
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6940726577437859,"ResNet18 eval
ResNet18-2 eval
ResNet18-4 eval"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6959847036328872,"(d) ||g∗||2, BN eval (rs = 0.4)"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6978967495219885,"0.05
0.1
0.15
0.2
0.25
LPIPS 0 5 10 15 20 25 30 ~
Lx$"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.6998087954110899,"ResNet18 eval
ResNet18-2 eval
ResNet18-4 eval"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.7017208413001912,"(e)
˜
Lx∗, BN eval (rs = 0.71)"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.7036328871892925,"0.05
0.1
0.15
0.2
0.25
LPIPS 0 50 100 150 200 250 300"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.7055449330783938,"~
Lcos x$"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.7074569789674953,"ResNet18 eval
ResNet18-2 eval
ResNet18-4 eval"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.7093690248565966,"(f)
˜
Lcos
x∗, BN eval (rs = 0.6)"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.7112810707456979,"Figure 7: Comparison of ||g∗||2,
˜
Lx∗, and
˜
Lcos
x∗in terms of the correlation between LPIPS of
reconstructed samples for ResNet models with BN train (top) and BN eval (bottom)"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.7131931166347992,"rs = −0.85. As in Tab. 1 and Fig. 1, reconstructed samples are closer to their original images in BN
290"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.7151051625239006,"train mode, thus
˜
Lx∗, which is computed around the ground truth x∗, seems to fit more to BN train
291"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.7170172084130019,"while L should be estimated around the solution from the attack method rather than x∗for the case of
292"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.7189292543021033,"BN eval. However, clients cannot access to the solution from the the attack method in the black-box
293"
LIPSCHITZ SMOOTHNESS FOR CLIENT-SIDE PRIVACY LEAKAGE DETECTION,0.7208413001912046,"setting. The plot of
˜
Lx∗and Linit −Lfinal for the ConvNet models is provided in Appendix A3.
294"
LIMITATIONS AND FUTURE WORK,0.722753346080306,"5
Limitations and Future Work
295"
LIMITATIONS AND FUTURE WORK,0.7246653919694073,"Our hypothesis can be extended to the correlation between Lipschitz constant and the quality of
296"
LIMITATIONS AND FUTURE WORK,0.7265774378585086,"reconstructed samples, rather than loss drop. Zero gradient matching loss does not mean complete
297"
LIMITATIONS AND FUTURE WORK,0.7284894837476099,"recovery of original images due to the existence of twin data [30], two different data input with
298"
LIMITATIONS AND FUTURE WORK,0.7304015296367112,"identical model gradients. However, we empirically found that both
˜
Lx∗and
˜
Lcos
x∗show positive
299"
LIMITATIONS AND FUTURE WORK,0.7323135755258127,"monotonic correlations with the quality of reconstructed samples, in terms of LPIPS (lower value is
300"
LIMITATIONS AND FUTURE WORK,0.734225621414914,"better) (Fig. 7). In particular, they beat the baseline measure, the norm of given gradients (||g∗||2),
301"
LIMITATIONS AND FUTURE WORK,0.7361376673040153,"which was implicitly believed to be the amount of information within the gradients in previous works,
302"
LIMITATIONS AND FUTURE WORK,0.7380497131931166,"by a wide margin, in terms of rs. Therefore, we expect
˜
Lx∗and
˜
Lcos
x∗to be the key factors for
303"
LIMITATIONS AND FUTURE WORK,0.739961759082218,"developing future client-side defense strategies.
304"
CONCLUSIONS,0.7418738049713193,"6
Conclusions
305"
CONCLUSIONS,0.7437858508604207,"Here, we re-evaluated the SOTA attack method on a broad spectrum of models in the context of
306"
CONCLUSIONS,0.745697896749522,"batch reconstruction, which is rarely studied in previous works. We considered model variations
307"
CONCLUSIONS,0.7476099426386233,"of two types: implicit, which changes in model weights or BN modes within the same architecture,
308"
CONCLUSIONS,0.7495219885277247,"and explicit, with changes in architecture. The re-evaluation results indicate that the quality of the
309"
CONCLUSIONS,0.751434034416826,"reconstruction attack varies depending on the implicit or explicit model changes. Therefore, inspired
310"
CONCLUSIONS,0.7533460803059273,"by our theorem related to the convergence of gradient matching optimization and scale-invariance
311"
CONCLUSIONS,0.7552581261950286,"of the cosine similarity loss function, we propose an explainable and predictive measure for privacy
312"
CONCLUSIONS,0.7571701720841301,"leakage, an angular Lipschitz constant Lcos, which is invariant to trivial loss scaling attacks from
313"
CONCLUSIONS,0.7590822179732314,"malicious servers. We empirically find that Lcos shows a strong monotonic correlation with the
314"
CONCLUSIONS,0.7609942638623327,"quality of reconstructed samples, thus expecting the potential of Lcos to be a key factor for clients’
315"
CONCLUSIONS,0.762906309751434,"defense strategies in a black-box setting, where only model gradients are given as minimal information
316"
CONCLUSIONS,0.7648183556405354,"about the global model to clients.
317"
REFERENCES,0.7667304015296367,"References
318"
REFERENCES,0.768642447418738,"[1] H. H. Bauschke, J. Bolte, and M. Teboulle. A descent lemma beyond lipschitz gradient continuity:
319"
REFERENCES,0.7705544933078394,"first-order methods revisited and applications. Mathematics of Operations Research, 42(2):330–348, 2017.
320"
REFERENCES,0.7724665391969407,"[2] X. Chen, H. Fan, R. Girshick, and K. He. Improved baselines with momentum contrastive learning. arXiv
321"
REFERENCES,0.7743785850860421,"preprint arXiv:2003.04297, 2020.
322"
REFERENCES,0.7762906309751434,"[3] T. Dang, O. Thakkar, S. Ramaswamy, R. Mathews, P. Chin, and F. Beaufays. Revealing and protecting
323"
REFERENCES,0.7782026768642447,"labels in distributed training. Advances in Neural Information Processing Systems, 34, 2021.
324"
REFERENCES,0.780114722753346,"[4] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image
325"
REFERENCES,0.7820267686424475,"database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248–255. Ieee,
326"
REFERENCES,0.7839388145315488,"2009.
327"
REFERENCES,0.7858508604206501,"[5] J. Duchi, E. Hazan, and Y. Singer. Adaptive subgradient methods for online learning and stochastic
328"
REFERENCES,0.7877629063097514,"optimization. Journal of machine learning research, 12(7), 2011.
329"
REFERENCES,0.7896749521988528,"[6] J. Geiping, H. Bauermeister, H. Dröge, and M. Moeller. Inverting gradients-how easy is it to break privacy
330"
REFERENCES,0.7915869980879541,"in federated learning? Advances in Neural Information Processing Systems, 33:16937–16947, 2020.
331"
REFERENCES,0.7934990439770554,"[7] H. Gouk, E. Frank, B. Pfahringer, and M. J. Cree. Regularisation of neural networks by enforcing lipschitz
332"
REFERENCES,0.7954110898661568,"continuity. Machine Learning, 110(2):393–416, 2021.
333"
REFERENCES,0.7973231357552581,"[8] A. Hatamizadeh, H. Yin, P. Molchanov, A. Myronenko, W. Li, P. Dogra, A. Feng, M. G. Flores,
334"
REFERENCES,0.7992351816443595,"J. Kautz, D. Xu, et al. Do gradient inversion attacks make federated learning unsafe? arXiv preprint
335"
REFERENCES,0.8011472275334608,"arXiv:2202.06924, 2022.
336"
REFERENCES,0.8030592734225621,"[9] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the
337"
REFERENCES,0.8049713193116634,"IEEE conference on computer vision and pattern recognition, pages 770–778, 2016.
338"
REFERENCES,0.8068833652007649,"[10] Y. Huang, S. Gupta, Z. Song, K. Li, and S. Arora. Evaluating gradient inversion attacks and defenses in
339"
REFERENCES,0.8087954110898662,"federated learning. Advances in Neural Information Processing Systems, 34, 2021.
340"
REFERENCES,0.8107074569789675,"[11] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal
341"
REFERENCES,0.8126195028680688,"covariate shift. In International conference on machine learning, pages 448–456. PMLR, 2015.
342"
REFERENCES,0.8145315487571702,"[12] J. Jeon, K. Lee, S. Oh, J. Ok, et al. Gradient inversion with generative image prior. Advances in Neural
343"
REFERENCES,0.8164435946462715,"Information Processing Systems, 34:29898–29908, 2021.
344"
REFERENCES,0.8183556405353728,"[13] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. In ICLR (Poster), 2015.
345"
REFERENCES,0.8202676864244742,"[14] J. Koneˇcn`y, H. B. McMahan, F. X. Yu, P. Richtárik, A. T. Suresh, and D. Bacon. Federated learning:
346"
REFERENCES,0.8221797323135756,"Strategies for improving communication efficiency. arXiv preprint arXiv:1610.05492, 2016.
347"
REFERENCES,0.8240917782026769,"[15] A. Krizhevsky. Learning multiple layers of features from tiny images. 2009.
348"
REFERENCES,0.8260038240917782,"[16] O. Li, J. Sun, X. Yang, W. Gao, H. Zhang, J. Xie, V. Smith, and C. Wang. Label leakage and protection in
349"
REFERENCES,0.8279158699808795,"two-party split learning. 2022.
350"
REFERENCES,0.8298279158699808,"[17] Q. Li, Y. Diao, Q. Chen, and B. He. Federated learning on non-iid data silos: An experimental study. 2021.
351"
REFERENCES,0.8317399617590823,"[18] X. Li and F. Orabona. On the convergence of stochastic gradient descent with adaptive stepsizes. In The
352"
REFERENCES,0.8336520076481836,"22nd International Conference on Artificial Intelligence and Statistics, pages 983–992. PMLR, 2019.
353"
REFERENCES,0.8355640535372849,"[19] X. Li, M. JIANG, X. Zhang, M. Kamp, and Q. Dou. Fedbn: Federated learning on non-iid features via
354"
REFERENCES,0.8374760994263862,"local batch normalization. In International Conference on Learning Representations, 2020.
355"
REFERENCES,0.8393881453154876,"[20] V. V. Mai and M. Johansson. Stability and convergence of stochastic gradient clipping: Beyond lipschitz
356"
REFERENCES,0.8413001912045889,"continuity and smoothness. In International Conference on Machine Learning, pages 7325–7335. PMLR,
357"
REFERENCES,0.8432122370936902,"2021.
358"
REFERENCES,0.8451242829827916,"[21] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas. Communication-efficient learning of
359"
REFERENCES,0.847036328871893,"deep networks from decentralized data. In Artificial intelligence and statistics, pages 1273–1282. PMLR,
360"
REFERENCES,0.8489483747609943,"2017.
361"
REFERENCES,0.8508604206500956,"[22] A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. DeVito, Z. Lin, A. Desmaison, L. Antiga, and
362"
REFERENCES,0.8527724665391969,"A. Lerer. Automatic differentiation in pytorch. 2017.
363"
REFERENCES,0.8546845124282982,"[23] S. Ruder. An overview of gradient descent optimization algorithms. arXiv preprint arXiv:1609.04747,
364"
REFERENCES,0.8565965583173997,"2016.
365"
REFERENCES,0.858508604206501,"[24] S. Santurkar, D. Tsipras, A. Ilyas, and A. Madry. How does batch normalization help optimization?
366"
REFERENCES,0.8604206500956023,"Advances in neural information processing systems, 31, 2018.
367"
REFERENCES,0.8623326959847036,"[25] D. Ye, T. Zhu, S. Zhou, B. Liu, and W. Zhou. Label-only model inversion attack: The attack that requires
368"
REFERENCES,0.864244741873805,"the least information. arXiv preprint arXiv:2203.06555, 2022.
369"
REFERENCES,0.8661567877629063,"[26] H. Yin, A. Mallya, A. Vahdat, J. M. Alvarez, J. Kautz, and P. Molchanov. See through gradients: Image
370"
REFERENCES,0.8680688336520076,"batch recovery via gradinversion. In Proceedings of the IEEE/CVF Conference on Computer Vision and
371"
REFERENCES,0.869980879541109,"Pattern Recognition, pages 16337–16346, 2021.
372"
REFERENCES,0.8718929254302104,"[27] J. Zeng, T. T.-K. Lau, S. Lin, and Y. Yao. Global convergence of block coordinate descent in deep learning.
373"
REFERENCES,0.8738049713193117,"In International conference on machine learning, pages 7313–7323. PMLR, 2019.
374"
REFERENCES,0.875717017208413,"[28] R. Zhang, P. Isola, A. A. Efros, E. Shechtman, and O. Wang. The unreasonable effectiveness of deep
375"
REFERENCES,0.8776290630975143,"features as a perceptual metric. In Proceedings of the IEEE conference on computer vision and pattern
376"
REFERENCES,0.8795411089866156,"recognition, pages 586–595, 2018.
377"
REFERENCES,0.8814531548757171,"[29] B. Zhao, K. R. Mopuri, and H. Bilen. idlg: Improved deep leakage from gradients. arXiv preprint
378"
REFERENCES,0.8833652007648184,"arXiv:2001.02610, 2020.
379"
REFERENCES,0.8852772466539197,"[30] J. Zhu and M. B. Blaschko. R-gap: Recursive gradient attack on privacy. In International Conference on
380"
REFERENCES,0.887189292543021,"Learning Representations, 2020.
381"
REFERENCES,0.8891013384321224,"[31] L. Zhu, Z. Liu, and S. Han. Deep leakage from gradients. Advances in Neural Information Processing
382"
REFERENCES,0.8910133843212237,"Systems, 32, 2019.
383"
REFERENCES,0.892925430210325,"Checklist
384"
REFERENCES,0.8948374760994264,"The checklist follows the references. Please read the checklist guidelines carefully for information on
385"
REFERENCES,0.8967495219885278,"how to answer these questions. For each question, change the default [TODO] to [Yes] , [No] , or
386"
REFERENCES,0.8986615678776291,"[N/A] . You are strongly encouraged to include a justification to your answer, either by referencing
387"
REFERENCES,0.9005736137667304,"the appropriate section of your paper or providing a brief inline description. For example:
388"
REFERENCES,0.9024856596558317,"• Did you include the license to the code and datasets? [Yes] See Section ??.
389"
REFERENCES,0.904397705544933,"• Did you include the license to the code and datasets? [No] The code and the data are
390"
REFERENCES,0.9063097514340345,"proprietary.
391"
REFERENCES,0.9082217973231358,"• Did you include the license to the code and datasets? [N/A]
392"
REFERENCES,0.9101338432122371,"Please do not modify the questions and only use the provided macros for your answers. Note that the
393"
REFERENCES,0.9120458891013384,"Checklist section does not count towards the page limit. In your paper, please delete this instructions
394"
REFERENCES,0.9139579349904398,"block and only keep the Checklist section heading above along with the questions/answers below.
395"
REFERENCES,0.9158699808795411,"1. For all authors...
396"
REFERENCES,0.9177820267686424,"(a) Do the main claims made in the abstract and introduction accurately reflect the paper’s
397"
REFERENCES,0.9196940726577438,"contributions and scope? [Yes] We thoroughly listed the contributions of our work in
398"
REFERENCES,0.9216061185468452,"both abstract and introduction.
399"
REFERENCES,0.9235181644359465,"(b) Did you describe the limitations of your work? [Yes] See Sec. 5 for limitations of our
400"
REFERENCES,0.9254302103250478,"work and future research direction.
401"
REFERENCES,0.9273422562141491,"(c) Did you discuss any potential negative societal impacts of your work? [N/A]
402"
REFERENCES,0.9292543021032504,"(d) Have you read the ethics review guidelines and ensured that your paper conforms to
403"
REFERENCES,0.9311663479923518,"them? [Yes]
404"
REFERENCES,0.9330783938814532,"2. If you are including theoretical results...
405"
REFERENCES,0.9349904397705545,"(a) Did you state the full set of assumptions of all theoretical results? [Yes] In Theorem 1,
406"
REFERENCES,0.9369024856596558,"all the assumptions are included in the statement. The details are described in Appendix
407"
REFERENCES,0.9388145315487572,"A2.
408"
REFERENCES,0.9407265774378585,"(b) Did you include complete proofs of all theoretical results? [Yes] We include complete
409"
REFERENCES,0.9426386233269598,"proofs in Appendix A2.
410"
REFERENCES,0.9445506692160612,"3. If you ran experiments...
411"
REFERENCES,0.9464627151051626,"(a) Did you include the code, data, and instructions needed to reproduce the main experi-
412"
REFERENCES,0.9483747609942639,"mental results (either in the supplemental material or as a URL)? [Yes] The details for
413"
REFERENCES,0.9502868068833652,"experiments are partially described in Results section in Sec. 3 including Appendix.
414"
REFERENCES,0.9521988527724665,"(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they
415"
REFERENCES,0.9541108986615678,"were chosen)? [Yes] All the training details for experiments are described in Results
416"
REFERENCES,0.9560229445506692,"section in Sec. 3.
417"
REFERENCES,0.9579349904397706,"(c) Did you report error bars (e.g., with respect to the random seed after running experi-
418"
REFERENCES,0.9598470363288719,"ments multiple times)? [Yes] We report standard deviation of our results in Tab. 1 and
419"
REFERENCES,0.9617590822179732,"Fig. 2.
420"
REFERENCES,0.9636711281070746,"(d) Did you include the total amount of compute and the type of resources used (e.g., type
421"
REFERENCES,0.9655831739961759,"of GPUs, internal cluster, or cloud provider)? [Yes] We report them in Appendix A4.
422"
REFERENCES,0.9674952198852772,"4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...
423"
REFERENCES,0.9694072657743786,"(a) If your work uses existing assets, did you cite the creators? [Yes] We cited the creators
424"
REFERENCES,0.97131931166348,"for CIFAR100, ImageNet, ConvNet, and ResNet18.
425"
REFERENCES,0.9732313575525813,"(b) Did you mention the license of the assets? [N/A]
426"
REFERENCES,0.9751434034416826,"(c) Did you include any new assets either in the supplemental material or as a URL? [No]
427"
REFERENCES,0.9770554493307839,"(d) Did you discuss whether and how consent was obtained from people whose data you’re
428"
REFERENCES,0.9789674952198852,"using/curating? [Yes] We use data widely used in the field of research related to our
429"
REFERENCES,0.9808795411089866,"work
430"
REFERENCES,0.982791586998088,"(e) Did you discuss whether the data you are using/curating contains personally identifiable
431"
REFERENCES,0.9847036328871893,"information or offensive content? [N/A]
432"
REFERENCES,0.9866156787762906,"5. If you used crowdsourcing or conducted research with human subjects...
433"
REFERENCES,0.988527724665392,"(a) Did you include the full text of instructions given to participants and screenshots, if
434"
REFERENCES,0.9904397705544933,"applicable? [N/A]
435"
REFERENCES,0.9923518164435946,"(b) Did you describe any potential participant risks, with links to Institutional Review
436"
REFERENCES,0.994263862332696,"Board (IRB) approvals, if applicable? [N/A]
437"
REFERENCES,0.9961759082217974,"(c) Did you include the estimated hourly wage paid to participants and the total amount
438"
REFERENCES,0.9980879541108987,"spent on participant compensation? [N/A]
439"
