Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.001160092807424594,"Many modern machine learning applications, such as multi-task learning, require ﬁnding
1"
ABSTRACT,0.002320185614849188,"optimal model parameters to trade-off multiple objective functions that may conﬂict with
2"
ABSTRACT,0.0034802784222737818,"each other. The notion of the Pareto set allows us to focus on the set of (often inﬁnite number
3"
ABSTRACT,0.004640371229698376,"of) models that cannot be strictly improved. But it does not provide an actionable procedure
4"
ABSTRACT,0.00580046403712297,"for picking one or a few special models to return to practical users. In this paper, we
5"
ABSTRACT,0.0069605568445475635,"consider optimization in Pareto set (OPT-in-Pareto), the problem of ﬁnding Pareto models
6"
ABSTRACT,0.008120649651972157,"that optimize an extra reference criterion function within the Pareto set. This function can
7"
ABSTRACT,0.009280742459396751,"either encode a speciﬁc preference from the users, or represent a generic diversity measure
8"
ABSTRACT,0.010440835266821345,"for obtaining a set of diversiﬁed Pareto models that are representative of the whole Pareto
9"
ABSTRACT,0.01160092807424594,"set. Unfortunately, despite being a highly useful framework, efﬁcient algorithms for OPT-
10"
ABSTRACT,0.012761020881670533,"in-Pareto have been largely missing, especially for large-scale, non-convex, and non-linear
11"
ABSTRACT,0.013921113689095127,"objectives in deep learning. A naive approach is to apply Riemannian manifold gradient
12"
ABSTRACT,0.015081206496519721,"descent on the Pareto set, which yields a high computational cost due to the need for eigen-
13"
ABSTRACT,0.016241299303944315,"calculation of Hessian matrices. We propose a ﬁrst-order algorithm that approximately
14"
ABSTRACT,0.01740139211136891,"solves OPT-in-Pareto using only gradient information, with both high practical efﬁciency
15"
ABSTRACT,0.018561484918793503,"and theoretically guaranteed convergence property. Empirically, we demonstrate that our
16"
ABSTRACT,0.019721577726218097,"method works efﬁciently for a variety of challenging multi-task-related problems.
17"
INTRODUCTION,0.02088167053364269,"1
INTRODUCTION
18"
INTRODUCTION,0.022041763341067284,"Although machine learning tasks are traditionally framed as optimizing a single objective. Many modern
19"
INTRODUCTION,0.02320185614849188,"applications, especially in areas like multitask learning, require ﬁnding optimal model parameters to minimize
20"
INTRODUCTION,0.024361948955916472,"multiple objectives (or tasks) simultaneously. As the different objective functions may inevitably conﬂict
21"
INTRODUCTION,0.025522041763341066,"with each other, the notion of optimality in multi-objective optimization (MOO) needs to be characterized by
22"
INTRODUCTION,0.02668213457076566,"the Pareto set: the set of model parameters whose performance of all tasks cannot be jointly improved.
23"
INTRODUCTION,0.027842227378190254,"Focusing on the Pareto set allows us to ﬁlter out models that can be strictly improved. However, the Pareto
24"
INTRODUCTION,0.029002320185614848,"set typically contains an inﬁnite number of parameters that represent different trade-offs of the objectives.
25"
INTRODUCTION,0.030162412993039442,"For m objectives ℓ1, . . . , ℓm, the Pareto set is often an (m −1) dimensional manifold. It is both intractable
26"
INTRODUCTION,0.031322505800464036,"and unnecessary to give practical users the whole exact Pareto set. A more practical demand is to ﬁnd some
27"
INTRODUCTION,0.03248259860788863,"user-speciﬁed special parameters in the Pareto set, which can be framed into the following optimization in
28"
INTRODUCTION,0.033642691415313224,"Pareto set (OPT-in-Pareto) problem:
29"
INTRODUCTION,0.03480278422273782,"Finding one or a set of parameters inside the Pareto set of ℓ1, . . . , ℓm that minimize a reference criterion F.
30"
INTRODUCTION,0.03596287703016241,"Here the criterion function F can be used to encode an informative user-speciﬁc preference on the objectives
31"
INTRODUCTION,0.037122969837587005,"ℓ1, . . . , ℓm, which allows us to provide the best models customized for different users. F can also be an
32"
INTRODUCTION,0.0382830626450116,"non-informative measure that encourages, for example, the diversity of a set of model parameters. In this
33"
INTRODUCTION,0.03944315545243619,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.04060324825986079,"case, optimizing F in Pareto set gives a set of diversiﬁed Pareto models that are representative of the whole
34"
INTRODUCTION,0.04176334106728538,"Pareto set, from which different users can pick their favorite models during the testing time.
35"
INTRODUCTION,0.042923433874709975,"OPT-in-Pareto provides a highly generic and actionable framework for multi-objective learning and opti-
36"
INTRODUCTION,0.04408352668213457,"mization. However, efﬁcient algorithms for solving OPT-in-Pareto have been largely lagging behind in deep
37"
INTRODUCTION,0.04524361948955916,"learning where the objective functions are non-convex and non-linear. Although has not been formally studied,
38"
INTRODUCTION,0.04640371229698376,"a straightforward approach is to apply manifold gradient descent on F in the Riemannian manifold formed by
39"
INTRODUCTION,0.04756380510440835,"the Pareto set (Hillermeier, 2001; Bonnabel, 2013). However, this casts prohibitive computational cost due
40"
INTRODUCTION,0.048723897911832945,"to the need for eigen-computation of Hessian matrices of {ℓi}. In the optimization and operation research
41"
INTRODUCTION,0.04988399071925754,"literature, there has been a body of work on OPT-in-Pareto viewing it as a special bi-level optimization
42"
INTRODUCTION,0.05104408352668213,"problem (Dempe, 2018). However, these works often heavily rely on the linearity and convexity assumptions
43"
INTRODUCTION,0.052204176334106726,"and are not applicable to the non-linear and non-convex problems in deep learning; see for examples in Ecker
44"
INTRODUCTION,0.05336426914153132,"& Song (1994); Jorge (2005); Thach & Thang (2014); Liu & Ehrgott (2018); Sadeghi & Mohebi (2021) (just
45"
INTRODUCTION,0.054524361948955914,"to name a few). In comparison, the OPT-in-Pareto problem seems to be much less known and under-explored
46"
INTRODUCTION,0.05568445475638051,"in the deep learning literature.
47"
INTRODUCTION,0.0568445475638051,"In this work, we provide a practically efﬁcient ﬁrst-order algorithm for OPT-in-Pareto, using only gradient
48"
INTRODUCTION,0.058004640371229696,"information of the criterion F and objectives {ℓi}. Our method, named Pareto navigation gradient descent
49"
INTRODUCTION,0.05916473317865429,"(PNG), iteratively updates the parameters following a direction that carefully balances the descent on F and
50"
INTRODUCTION,0.060324825986078884,"{ℓi}, such that it guarantees to move towards the Pareto set of {ℓi} when it is far away, and optimize F in a
51"
INTRODUCTION,0.06148491879350348,"neighborhood of the Pareto set. Our method is simple, practically efﬁcient and has theoretical guarantees.
52"
INTRODUCTION,0.06264501160092807,"In empirical studies, we demonstrate that our method works efﬁciently for both optimizing user-speciﬁc
53"
INTRODUCTION,0.06380510440835267,"criteria and diversity measures. In particular, for ﬁnding representative Pareto solutions, we propose an
54"
INTRODUCTION,0.06496519721577726,"energy distance criterion whose minimizers distribute uniformly on the Pareto set asymptotically (Hardin
55"
INTRODUCTION,0.06612529002320186,"& Saff, 2004), yielding a principled and efﬁcient Pareto set approximation method that compares favorably
56"
INTRODUCTION,0.06728538283062645,"with recent works such as Lin et al. (2019); Mahapatra & Rajan (2020). We also apply PNG to improve the
57"
INTRODUCTION,0.06844547563805105,"performance of JiGen (Carlucci et al., 2019b), a multi-task learning approach for domain generalization, by
58"
INTRODUCTION,0.06960556844547564,"using the adversarial feature discrepancy as the criterion objective.
59"
INTRODUCTION,0.07076566125290024,"Related Work There has been a rising interest in MOO in deep learning, mostly in the context of multi-task
60"
INTRODUCTION,0.07192575406032482,"learning. But most existing methods can not be applied to the general OPT-in-Pareto problem. A large body
61"
INTRODUCTION,0.07308584686774942,"of recent works focus on improving non-convex optimization for ﬁnding some model in the Pareto set, but
62"
INTRODUCTION,0.07424593967517401,"cannot search for a special model satisfying a speciﬁc criterion (Chen et al., 2018; Kendall et al., 2018; Sener
63"
INTRODUCTION,0.07540603248259861,"& Koltun, 2018; Yu et al., 2020; Chen et al., 2020; Wu et al., 2020; Fifty et al., 2020; Javaloy & Valera, 2021).
64"
INTRODUCTION,0.0765661252900232,"One exception is Mahapatra & Rajan (2020); Kamani et al. (2021), which searches for models in the Pareto
65"
INTRODUCTION,0.0777262180974478,"set that satisfy a constraint on the ratio between the different objectives. The problem they study can be
66"
INTRODUCTION,0.07888631090487239,"viewed as a special instance of OPT-in-Pareto. However, their approaches are tied with special properties of
67"
INTRODUCTION,0.08004640371229699,"the ratio constraint and do not apply to the general OPT-in-Pareto problem.
68"
INTRODUCTION,0.08120649651972157,"There has also been increasing interest in ﬁnding a compact approximation of the Pareto set. Navon et al.
69"
INTRODUCTION,0.08236658932714618,"(2020); Lin et al. (2020) use hypernetworks to approximate the map from linear scalarization weights to
70"
INTRODUCTION,0.08352668213457076,"the corresponding Pareto solutions; these methods could not fully proﬁle non-convex Pareto fronts due
71"
INTRODUCTION,0.08468677494199536,"to the limitation of linear scalarization (Boyd et al., 2004), and the use of hypernetwork introduces extra
72"
INTRODUCTION,0.08584686774941995,"optimization difﬁculty. Another line of works (Lin et al., 2019; Mahapatra & Rajan, 2020) approximate
73"
INTRODUCTION,0.08700696055684455,"the Pareto set by training models with different user preference vectors that rank the relative importance
74"
INTRODUCTION,0.08816705336426914,"of different tasks; these methods need a good heuristic design of preference vectors, which requires prior
75"
INTRODUCTION,0.08932714617169374,"knowledge of the Pareto front. Ma et al. (2020) leverages manifold gradient to conduct a local random walk
76"
INTRODUCTION,0.09048723897911833,"on the Pareto set but suffers from the high computational cost. Deist et al. (2021) approximates the Pareto set
77"
INTRODUCTION,0.09164733178654293,"by maximizing hypervolume, which requires prior knowledge for choosing a good reference vector.
78"
INTRODUCTION,0.09280742459396751,"Multi-task learning can also be applied to improve the learning in many other domains including domain
79"
INTRODUCTION,0.09396751740139211,"generalization (Dou et al., 2019; Carlucci et al., 2019a; Albuquerque et al., 2020), domain adaption (Sun
80"
INTRODUCTION,0.0951276102088167,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.0962877030162413,"et al., 2019; Luo et al., 2021), model uncertainty (Hendrycks et al., 2019; Zhang et al., 2020; Xie et al., 2021),
81"
INTRODUCTION,0.09744779582366589,"adversarial robustness (Yang & Vondrick, 2020) and semi-supervised learning (Sohn et al., 2020). All of
82"
INTRODUCTION,0.09860788863109049,"those applications utilize a linear scalarization to combine the multiple objectives and it is thus interesting to
83"
INTRODUCTION,0.09976798143851508,"apply the proposed OPT-in-Pareto framework, which we leave for future work.
84"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.10092807424593968,"2
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION
85"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.10208816705336426,"We introduce the background on multi-objective optimization (MOO) and Pareto optimality. For notation,
86"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.10324825986078887,"we denote by [m] the integer set {1, 2, ...., m}, and R+ the set of non-negative real numbers. Let Cm =
87

ω ∈Rm
+,
Pm
i=1 ωi = 1
	
be the probability simplex. We denote by ∥·∥the Euclidean norm.
88"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.10440835266821345,"Let θ ∈Rn be a parameter of interest (e.g., the weights in a deep neural network).
Let ℓ(θ) =
89"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.10556844547563805,"[ℓ1(θ), . . . , ℓm(θ)] be a set of objective functions that we want to minimize. For two parameters θ, θ′ ∈Rn,
90"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.10672853828306264,"we write ℓ(θ) ⪰ℓ(θ′) if ℓi(θ) ≥ℓi(θ′) for all i ∈[m]; and write ℓ(θ) ≻ℓ(θ′) if ℓ(θ) ⪰ℓ(θ′) and
91"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.10788863109048724,"ℓ(θ) ̸= ℓ(θ′). We say that θ is Pareto dominated (or Pareto improved) by θ′ if ℓ(θ) ≻ℓ(θ′). We say that θ is
92"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.10904872389791183,"Pareto optimal on a set Θ ⊆Rn, denoted as θ ∈Pareto(Θ), if there exists no θ′ ∈Θ such that ℓ(θ) ≻ℓ(θ′).
93"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.11020881670533643,"The Pareto global optimal set P∗∗:= Pareto(Rn) is the set of points (i.e., θ) which are Pareto optimal on
94"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.11136890951276102,"the whole domain Rn. The Pareto local optimal set of ℓ, denoted by P∗, is the set of points which are Pareto
95"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.11252900232018562,"optimal on a neighborhood of itself:
96"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.1136890951276102,"P∗:= {θ ∈Rn : there exists a neighborhood Nθ of θ, such that θ ∈Pareto(Nθ)} ."
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.1148491879350348,"The (local or global) Pareto front is the set of objective vectors achieved by the Pareto optimal points, e.g.,
97"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.11600928074245939,"the local Pareto front is F∗= {ℓ(θ) : θ ∈P∗}. Because ﬁnding global Pareto optimum is intractable for
98"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.11716937354988399,"non-convex objectives in deep learning, we focus on Pareto local optimal sets in this work; in the rest of the
99"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.11832946635730858,"paper, terms like “Pareto set” and “Pareto optimum” refer to Pareto local optimum by default.
100"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.11948955916473318,"Pareto Stationary Points Similar to the case of single-objective optimization, Pareto local optimum implies
a notion of Pareto stationarity deﬁned as follows. Assume ℓis differentiable on Rn. A point θ is called Pareto
stationary if there must exists a set of non-negative weights ω1, . . . , ωm with Pm
i=1 ωi = 1, such that θ is a
stationary point of the ω-weighted linear combination of the objectives: ℓω(θ) := Pm
i=1 ωiℓi(θ). Therefore,
the set of Pareto stationary points, denoted by P, can be characterized by"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.12064965197215777,"P := {θ ∈Θ : g(θ) = 0} ,
g(θ) := min
ω∈Cm || m
X"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.12180974477958237,"i=1
ωi∇ℓi(θ)||2,
(1)"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.12296983758700696,"where g(θ) is the minimum squared gradient norm of ℓω among all ω in the probability simplex Cm on [m].
101"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.12412993039443156,"Because g(θ) can be calculated in practice, it provides an essential way to access Pareto local optimality.
102"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.12529002320185614,"Finding Pareto Optimal Points A main focus of the MOO literature is to ﬁnd a (set of) Pareto optimal
103"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.12645011600928074,"points. The simplest approach is linear scalarization, which minimizes ℓω for some weight ω (decided, e.g.,
104"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.12761020881670534,"by the users) in Cm. However, linear scalarization can only ﬁnd Pareto points that lie on the convex envelop
105"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.12877030162412992,"of the Pareto front (see e.g., Boyd et al., 2004), and hence does not give a complete proﬁling of the Pareto
106"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.12993039443155452,"front when the objective functions (and hence their Pareto front) are non-convex.
107"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.13109048723897912,"Multiple gradient descent (MGD) (Désidéri, 2012) is an gradient-based algorithm that can converge to a
Pareto local optimum that lies on either the convex or non-convex parts of the Pareto front, depending on the
initialization. MGD starts from some initialization θ0 and updates θ at the t-th iteration by"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.13225058004640372,"θt+1 ←θt −ξvt,
vt := arg max
v∈Rn"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.1334106728538283,"
min
i∈[m] ∇ℓi(θt)⊤v −1"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.1345707656612529,"2 ∥v∥2

,
(2)"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.1357308584686775,Under review as a conference paper at ICLR 2022
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.1368909512761021,"where ξ is the step size and vt is an update direction that maximizes the worst descent rate among all
108"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.13805104408352667,"objectives, since ∇ℓi(θt)⊤v ≈(ℓi(θt) −ℓi(θt −ξv))/ξ approximates the descent rate of objective ℓi when
109"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.13921113689095127,"following direction v. When using a sufﬁciently small step size ξ, MGD ensures to yield a Pareto improvement
110"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.14037122969837587,"(i.e, decreasing all the objectives) on θt unless θt is Pareto (local) optimal; this is because the optimization in
111"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.14153132250580047,"Equation (2) always yields mini∈[m] ∇ℓi(θt)⊤vt ≤0 (otherwise we can simply ﬂip the sign of vt).
112"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.14269141531322505,"Using Lagrange strong duality, the solution of Equation (2) can be framed into vt = m
X"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.14385150812064965,"i=1
ωi,t∇ℓi(θt),
where
{ωi,t}m
i=1 = arg min
ω∈Cm ∥∇θℓω(θt)∥.
(3)"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.14501160092807425,"It is easy to see from Equation (3) that the set of ﬁxed points of MDG (which satisfy vt = 0) coincides with
113"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.14617169373549885,"the Pareto stationary set P∗.
114"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.14733178654292342,"A key disadvantage of MGD, however, is that the Pareto point that it converges to depends on the initialization
115"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.14849187935034802,"and other algorithm conﬁgurations in a rather implicated and complicated way. It is difﬁcult to explicitly
116"
BACKGROUND ON MULTI-OBJECTIVE OPTIMIZATION,0.14965197215777262,"control MGD to make it converge to points with speciﬁc properties.
117"
OPTIMIZATION IN PARETO SET,0.15081206496519722,"3
OPTIMIZATION IN PARETO SET
118"
OPTIMIZATION IN PARETO SET,0.1519721577726218,"The Pareto set typically contains an inﬁnite number of points. In the optimization in Pareto set (OPT-in-
119"
OPTIMIZATION IN PARETO SET,0.1531322505800464,"Pareto) problem, we are given an extra criterion function F(θ) in addition to the objectives ℓ, and we want to
120"
OPTIMIZATION IN PARETO SET,0.154292343387471,"minimize F in the Pareto set of ℓ, that is,
121"
OPTIMIZATION IN PARETO SET,0.1554524361948956,"min
θ∈P∗F(θ).
(4)"
OPTIMIZATION IN PARETO SET,0.15661252900232017,"For example, one can ﬁnd the Pareto point whose loss vector ℓ(θ) is the closest to a given reference point
122"
OPTIMIZATION IN PARETO SET,0.15777262180974477,"r ∈Rm by choosing F(θ) = ∥ℓ(θ) −r∥2. We can also design F to encourages ℓ(θ) to be proportional to r,
123"
OPTIMIZATION IN PARETO SET,0.15893271461716937,"i.e., ℓ(θ) ∝r; a constraint variant of this problem was considered in Mahapatra & Rajan (2020).
124"
OPTIMIZATION IN PARETO SET,0.16009280742459397,"We can further generalize OPT-in-Pareto to allow the criterion F to depend on an ensemble of Pareto points
125"
OPTIMIZATION IN PARETO SET,0.16125290023201855,"{θ1, ..., θN} jointly, that is,
126"
OPTIMIZATION IN PARETO SET,0.16241299303944315,"min
θ1,...,θN∈P∗F(θ1, ..., θN).
(5)"
OPTIMIZATION IN PARETO SET,0.16357308584686775,"For example, if F(θ1, . . . , θN) measures the diversity among {θi}N
i=1, then optimizing it provides a set of
diversiﬁed points inside the Pareto set P∗. An example of diversity measure is"
OPTIMIZATION IN PARETO SET,0.16473317865429235,"F(θ1, . . . , θN) = E(ℓ(θ1), . . . , ℓ(θN)),
with
E(ℓ1, . . . , ℓN) =
X"
OPTIMIZATION IN PARETO SET,0.16589327146171692,"i̸=j
∥ℓi −ℓj∥−2 ,
(6)"
OPTIMIZATION IN PARETO SET,0.16705336426914152,"where E is known as an energy distance in computational geometry, whose minimizer can be shown to give
127"
OPTIMIZATION IN PARETO SET,0.16821345707656613,"an uniform distribution asymptotically when N →∞(Hardin & Saff, 2004). This formulation is particularly
128"
OPTIMIZATION IN PARETO SET,0.16937354988399073,"useful when the users’ preference is unknown during the training time, and we want to return an ensemble of
129"
OPTIMIZATION IN PARETO SET,0.17053364269141533,"models that well cover the different areas of the Pareto set to allow the users to pick up a model that ﬁts their
130"
OPTIMIZATION IN PARETO SET,0.1716937354988399,"needs regardless of their preference. The problem of proﬁling Pareto set has attracted a line of recent works
131"
OPTIMIZATION IN PARETO SET,0.1728538283062645,"(e.g., Lin et al., 2019; Mahapatra & Rajan, 2020; Ma et al., 2020; Deist et al., 2021), but they rely on speciﬁc
132"
OPTIMIZATION IN PARETO SET,0.1740139211136891,"criterion or heuristics and do not address the general optimization of form Equation (5).
133"
OPTIMIZATION IN PARETO SET,0.1751740139211137,"Manifold Gradient Descent One straightforward approach to OPT-in-Pareto is to deploy manifold gradient
134"
OPTIMIZATION IN PARETO SET,0.17633410672853828,"descent (Hillermeier, 2001; Bonnabel, 2013), which conducts steepest descent of F(θ) in the Riemannian
135"
OPTIMIZATION IN PARETO SET,0.17749419953596288,"manifold formed by the Pareto set P∗. Initialized at θ0 ∈P∗, manifold gradient descent updates θt at the t-th
136"
OPTIMIZATION IN PARETO SET,0.17865429234338748,"iteration along the direction of the projection of ∇F(θt) on the tangent space T (θt) at θt in P∗,
137"
OPTIMIZATION IN PARETO SET,0.17981438515081208,θt+1 = θt −ξProjT (θt)(∇F(θt)).
OPTIMIZATION IN PARETO SET,0.18097447795823665,Under review as a conference paper at ICLR 2022
OPTIMIZATION IN PARETO SET,0.18213457076566125,"By using the stationarity characterization in Equation (1), under proper regularity conditions, one can
138"
OPTIMIZATION IN PARETO SET,0.18329466357308585,"show that the tangent space T (θt) equals the null space of the Hessian matrix ∇2
θℓωt(θt), where ωt =
139"
OPTIMIZATION IN PARETO SET,0.18445475638051045,"arg minω∈Cm ∥∇θℓω(θt)∥. However, the key issue of manifold gradient descent is the high cost for calculating
140"
OPTIMIZATION IN PARETO SET,0.18561484918793503,"this null space of Hessian matrix. Although numerical techniques such as Krylov subspace iteration (Ma
141"
OPTIMIZATION IN PARETO SET,0.18677494199535963,"et al., 2020) or conjugate gradient descent (Koh & Liang, 2017) can be applied, the high computational cost
142"
OPTIMIZATION IN PARETO SET,0.18793503480278423,"(and the complicated implementation) still impedes its application in large scale deep learning problems. See
143"
OPTIMIZATION IN PARETO SET,0.18909512761020883,"Section 1 for discussions on other related works.
144"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.1902552204176334,"4
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO
145"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.191415313225058,"We now introduce our main algorithm, Pareto Navigating Gradient Descent (PNG), which provides a practical
146"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.1925754060324826,"approach to OPT-in-Pareto. For convenience, we focus on the single point problem in Equation (4) in the
147"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.1937354988399072,"presentation. The generalization to the multi-point problem in Equation (5) is straightforward. We ﬁrst
148"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.19489559164733178,"introduce the main idea and then present theoretical analysis in Section 4.1.
149"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.19605568445475638,Main Idea We consider the general incremental updating rule of form
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.19721577726218098,"θt+1 ←θt −ξvt,"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.19837587006960558,"where ξ is the step size and vt is an update direction that we shall choose to achieve the following desiderata
150"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.19953596287703015,"in balancing the decent of {ℓi} and F:
151"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.20069605568445475,"i) When θt is far away from the Pareto set, we want to choose vt to give Pareto improvement to θt, moving it
152"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.20185614849187936,"towards the Pareto set. The amount of Pareto improvement might depend on how far θt is to the Pareto set.
153"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.20301624129930396,"ii) If the directions that yield Pareto improvement are not unique, we want to choose the Pareto improvement
154"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.20417633410672853,"direction that decreases F(θ) most.
155"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.20533642691415313,"iii) When θt is very close to the Pareto set, e.g., having a small g(θ), we want to fully optimize F(θ).
156"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.20649651972157773,We achieve the desiderata above by using the vt that solves the following optimization:
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.20765661252900233,"vt = arg min
v∈Rn 1"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.2088167053364269,"2 ∥∇F(θt) −v∥2
s.t.
∇θℓi(θt)⊤v ≥φt,
∀i ∈[m]

,
(7)"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.2099767981438515,"where we want vt to be as close to ∇F(θt) as possible (hence decrease F most), conditional on that the
157"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.2111368909512761,"decreasing rate ∇θℓi(θt)⊤vt of all losses ℓi are lower bounded by a control parameter φt. A positive φt
158"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.2122969837587007,"enforces that ∇θtℓi(θ)⊤vt is positive for all ℓi, hence ensuring a Pareto improvement when the step size is
159"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.21345707656612528,"sufﬁciently small. The magnitude of φt controls how much Pareto improvement we want to enforce, so we
160"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.21461716937354988,"may want to gradually decrease φt when we move closer to the Pareto set. In fact, varying φt provides an
161"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.21577726218097448,"intermediate updating direction between the vanilla gradient descent on F and MGD on {ℓi}:
162"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.21693735498839908,"i) If φt = −∞, we have vt = ∇F(θt) and it conducts a pure gradient descent on F without considering {ℓi}.
163"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.21809744779582366,"ii) If φt →+∞, then vt approaches to the MGD direction of {ℓi} in Equation (2) without considering F.
164"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.21925754060324826,"In this work, we propose to choose φt based on the minimum gradient norm g(θt) in Equation (1) as a
surrogate indication of Pareto local optimality. In particular, we consider the following simple design:"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.22041763341067286,"φt =
−∞
if g(θt) ≤e,
αtg(θt)
if g(θt) > e,
(8)"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.22157772621809746,"where e is a small tolerance parameter and αt is a positive hyper-parameter. When g(θt) > e, we set φt to be
165"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.22273781902552203,"proportional to g(θt), to ensure Pareto improvement based on how far θt is to Pareto set. When g(θt) ≤e,
166"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.22389791183294663,"we set φt = −∞which “turns off” the control and hence fully optimizes F(θ).
167"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.22505800464037123,"In practice, the optimization in Equation (7) can be solved efﬁciently by its dual form as follows.
168"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.22621809744779584,Under review as a conference paper at ICLR 2022
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.2273781902552204,"Theorem 1. The solution vt of Equation (7), if it exists, has a form of"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.228538283062645,"vt = ∇F(θt) + m
X"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.2296983758700696,"t=1
λi,t∇ℓi(θt),
(9)"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.2308584686774942,"with {λi,t}m
t=1 the solution of the following dual problem"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.23201856148491878,"max
λ∈Rm
+
−1"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.23317865429234338,"2||∇F(θt) + m
X"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.23433874709976799,"i=1
λt∇ℓi(θt)||2 + m
X"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.2354988399071926,"i=1
λiφt.
(10)"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.23665893271461716,"The optimization in Equation (10) can be solved efﬁciently for a small m (e..g, m ≤10), which is the case
169"
PARETO NAVIGATION GRADIENT DESCENT FOR OPT-IN-PARETO,0.23781902552204176,"for typical applications. We include the details of the practical implementation in Appendix B.
170"
THEORETICAL PROPERTIES,0.23897911832946636,"4.1
THEORETICAL PROPERTIES
171"
THEORETICAL PROPERTIES,0.24013921113689096,"We provide a theoretical quantiﬁcation on how PNG guarantees to i) move the solution towards the Pareto
172"
THEORETICAL PROPERTIES,0.24129930394431554,"set (Theorem 2); and ii) optimize F in a neighborhood of Pareto set (Theorem 3). To simplify the result and
173"
THEORETICAL PROPERTIES,0.24245939675174014,"highlight the intuition, we focus on the continuous time limit of PNG, which yields a differentiation equation
174"
THEORETICAL PROPERTIES,0.24361948955916474,"dθt = −vtdt with vt deﬁned in Equation (7), where t ∈R+ is a continuous integration time.
175"
THEORETICAL PROPERTIES,0.24477958236658934,"Assumption 1. Let {θt : t ∈R+} be a solution of dθt = −vtdt with vt in Equation (7); φk in Equation (8);
176"
THEORETICAL PROPERTIES,0.2459396751740139,"e > 0; and αt ≥0,∀t ∈R+. Assume F and ℓare continuously differentiable on Rn, and lower bounded
177"
THEORETICAL PROPERTIES,0.2470997679814385,"with F ∗:= infθ∈Rn F(θ) > −∞and ℓ∗
i := infθ∈Rn ℓi(θ) > −∞. Assume supθ∈Rn ∥∇F(θ)∥≤c.
178"
THEORETICAL PROPERTIES,0.2482598607888631,"Technically, dθt = −vtdt is a piecewise smooth dynamical system whose solution should be taken in the
179"
THEORETICAL PROPERTIES,0.2494199535962877,"Filippov sense using the notion of differential inclusion (Bernardo et al., 2008). The solution always exists
180"
THEORETICAL PROPERTIES,0.2505800464037123,"under mild regularity conditions although it may not be unique. Our results below apply to all solutions.
181"
THEORETICAL PROPERTIES,0.2517401392111369,"Pareto Optimization on ℓWe now show that the algorithm converges to the vicinity of Pareto set quantiﬁed
by a notion of Pareto closure. For ϵ ≥0, let Pϵ be the set of Pareto ϵ-stationary points: Pϵ = {θ ∈
Rn : g(θ) ≤ϵ}. The Pareto closure of a set Pϵ, denoted by Pϵ is the set of points that perform no worse than
at least one point in Pϵ, that is,"
THEORETICAL PROPERTIES,0.2529002320185615,"Pϵ := ∪θ∈Pϵ{θ},
{θ} = {θ′ ∈Rn :
ℓ(θ′) ⪯ℓ(θ)}."
THEORETICAL PROPERTIES,0.25406032482598606,"Therefore, Pϵ is better than or at least as good as Pϵ in terms of Pareto efﬁciency.
182"
THEORETICAL PROPERTIES,0.2552204176334107,"Theorem 2 (Pareto Improvement on ℓ). Under Assumption 1, assume θ0 ̸∈Pe, and te is the ﬁrst time when
θte ∈Pe, then for any time t < te,"
THEORETICAL PROPERTIES,0.25638051044083526,"d
dtℓi(θt) ≤−αtg(θt),
min
s∈[0,t] g(θs) ≤mini∈[m](ℓi(θ0) −ℓ∗
i )
R t
0 αsds
."
THEORETICAL PROPERTIES,0.25754060324825984,"Therefore, the update yields Pareto improvement on ℓwhen θt ̸∈Pe and αtg(θt) > 0.
183"
THEORETICAL PROPERTIES,0.25870069605568446,"Further, if
R t
0 αsds = +∞, then for any ϵ > e, there exists a ﬁnite time tϵ ∈R+ on which the solution enters
184"
THEORETICAL PROPERTIES,0.25986078886310904,"Pϵ and stays within Pϵ afterwards, that is, we have θtϵ ∈Pϵ and θt ∈Pϵ for any t ≥tϵ.
185"
THEORETICAL PROPERTIES,0.26102088167053367,"Here we guarantee that θt must enter Pϵ for some time (in fact inﬁnitely often), but it is not conﬁned in Pϵ.
186"
THEORETICAL PROPERTIES,0.26218097447795824,"On the other hand, θt does not leave Pϵ after it ﬁrst enters Pϵ thanks to the Pareto improvement property.
187"
THEORETICAL PROPERTIES,0.2633410672853828,"Optimization on F We now show that PNG ﬁnds a local optimum of F inside the Pareto closure Pϵ in an
188"
THEORETICAL PROPERTIES,0.26450116009280744,"approximate sense. We ﬁrst show that a ﬁxed point θ of the algorithm that is locally convex on F and ℓmust
189"
THEORETICAL PROPERTIES,0.265661252900232,"be a local optimum of F in the Pareto closure of {θ}, and then quantify the convergence of the algorithm.
190"
THEORETICAL PROPERTIES,0.2668213457076566,Under review as a conference paper at ICLR 2022
THEORETICAL PROPERTIES,0.2679814385150812,"Lemma 1. Under Assumption 1, assume θt ̸∈Pe is a ﬁxed point of the algorithm, that is, dθt"
THEORETICAL PROPERTIES,0.2691415313225058,"dt = −vt = 0,
191"
THEORETICAL PROPERTIES,0.2703016241299304,"and F, ℓare convex in a neighborhood θt, then θt is a local minimum of F in the Pareto closure {θt}, that is,
192"
THEORETICAL PROPERTIES,0.271461716937355,"there exists a neighborhood of θt in which there exists no point θ′ such that F(θ′) < F(θt) and ℓ(θ′) ⪯ℓ(θt).
193"
THEORETICAL PROPERTIES,0.27262180974477956,"On the other hand, if θt ∈Pe, we have vt = ∇F(θt), and hence a ﬁxed point with dθt"
THEORETICAL PROPERTIES,0.2737819025522042,"dt = −vt = 0 is an
194"
THEORETICAL PROPERTIES,0.27494199535962877,"unconstrained local minimum of F when F is locally convex on θt.
195"
THEORETICAL PROPERTIES,0.27610208816705334,"Theorem 3. Let ϵ > e and assume gϵ := supθ{g(θ): θ ∈Pϵ} < +∞and supt≥0 αt < ∞. Under
Assumption 1, when we initialize from θ0 ∈Pϵ, we have"
THEORETICAL PROPERTIES,0.27726218097447797,"min
s∈[0,t] dθs ds "
THEORETICAL PROPERTIES,0.27842227378190254,"2
≤F(θ0) −F ∗ t
+ 1 t Z t"
THEORETICAL PROPERTIES,0.27958236658932717,"0
αs (αsgϵ + c√gϵ) ds."
THEORETICAL PROPERTIES,0.28074245939675174,"In particular, if we have αt = α = const, then mins∈[0,t] ∥dθs/ds∥2 = O
 
1/t + α√gϵ

.
196"
THEORETICAL PROPERTIES,0.2819025522041763,"If
R ∞
0
αγ
t dt < +∞for some γ ≥1, we have mins∈[0,t] ∥dθs/ds∥2 = O(1/t + √gϵ/t1/γ).
197"
THEORETICAL PROPERTIES,0.28306264501160094,"Combining the results in Theorem 2 and 3, we can see that the choice of sequence {αt : t ∈R+} controls how
198"
THEORETICAL PROPERTIES,0.2842227378190255,"fast we want to decrease ℓvs. F. Large αt yields faster descent on ℓ, but slower descent on F. Theoretically,
199"
THEORETICAL PROPERTIES,0.2853828306264501,"using a sequence that satisﬁes
R
αtdt = +∞and
R
αγ
t dt < +∞for some γ > 1 allows us to ensure that
200"
THEORETICAL PROPERTIES,0.2865429234338747,"both mins∈[0,t] g(θs) and mins∈[0,t] ∥dθ/ds∥2 converge to zero. If we use a constant sequence αt = α, it
201"
THEORETICAL PROPERTIES,0.2877030162412993,"introduces an O(α√gϵ) term that does not vanish as t →+∞. However, we can expect that gϵ is small when
202"
THEORETICAL PROPERTIES,0.2888631090487239,"ϵ is small for well-behaved functions. In practice, we ﬁnd that constant αt works sufﬁciently well.
203"
EMPIRICAL RESULTS,0.2900232018561485,"5
EMPIRICAL RESULTS
204"
EMPIRICAL RESULTS,0.29118329466357307,"We introduce three applications of OPT-in-Pareto with PNG: Singleton Preference, Pareto approximation and
205"
EMPIRICAL RESULTS,0.2923433874709977,"improving multi-task based domain generalization method. We also conduct additional study on how the
206"
EMPIRICAL RESULTS,0.29350348027842227,"learning dynamics of PNG changes with different initialization and hyper-parameters (αt and e), which are
207"
EMPIRICAL RESULTS,0.29466357308584684,"included in Appendix C.3. Other additional results that are related to the experiments in Section 5.1 and 5.2
208"
EMPIRICAL RESULTS,0.29582366589327147,"and are included in the Appendix will be introduced later in their corresponding sections.
209"
FINDING PREFERRED PARETO MODELS,0.29698375870069604,"5.1
FINDING PREFERRED PARETO MODELS
210"
FINDING PREFERRED PARETO MODELS,0.29814385150812067,"We consider the synthetic example used in Lin et al. (2019); Mahapatra & Rajan (2020), which consists of
211"
FINDING PREFERRED PARETO MODELS,0.29930394431554525,"two losses: ℓ1(θ) = 1 −exp(−∥θ −η∥2) and ℓ2(θ) = 1 −exp(−∥θ + η∥2), where η = n−1/2 and n = 10
212"
FINDING PREFERRED PARETO MODELS,0.3004640371229698,"is dimension of the parameter θ.
213"
FINDING PREFERRED PARETO MODELS,0.30162412993039445,"Ratio-based Criterion We ﬁrst show that PNG can solve the search problem under the ratio constraint of
214"
FINDING PREFERRED PARETO MODELS,0.302784222737819,"objectives in Mahapatra & Rajan (2020), i.e., ﬁnding a point θ ∈P∗∩Ωwith Ω= {θ : r1ℓ1(θ) = r2ℓ2(θ) =
215"
FINDING PREFERRED PARETO MODELS,0.3039443155452436,"... = rmℓm(θ)}, given some preference vector r = [r1, ..., rm]. We apply PNG with the non-uniformity
216"
FINDING PREFERRED PARETO MODELS,0.3051044083526682,"score deﬁned in Mahapatra & Rajan (2020) as the criterion, and compare with their algorithm called exact
217"
FINDING PREFERRED PARETO MODELS,0.3062645011600928,"Pareto optimization (EPO). We show in Figure 1(a)-(b) the trajectory of PNG and EPO for searching models
218"
FINDING PREFERRED PARETO MODELS,0.3074245939675174,"with different preference vector r, starting from the same randomly initialized point. Both PNG and EPO
219"
FINDING PREFERRED PARETO MODELS,0.308584686774942,"converge to the correct solutions but with different trajectories. This suggests that PNG is able to achieve
220"
FINDING PREFERRED PARETO MODELS,0.30974477958236657,"the same functionality of ﬁnding ratio-constraint Pareto models as Mahapatra & Rajan (2020); Kamani et al.
221"
FINDING PREFERRED PARETO MODELS,0.3109048723897912,"(2021) do but being versatile to handle general criteria. We refer readers to Appendix C.1.1 for more results
222"
FINDING PREFERRED PARETO MODELS,0.31206496519721577,"with different choices of hyper-parameters and the experiment details.
223"
FINDING PREFERRED PARETO MODELS,0.31322505800464034,"Other Criteria We demonstrate that PNG is able to ﬁnd solutions for general choices of F. We consider
224"
FINDING PREFERRED PARETO MODELS,0.314385150812065,"the following designs of F: 1) weighted ℓ2 distance w.r.t. a reference vector r ∈Rm
+, that is, Fwd(θ) =
225"
FINDING PREFERRED PARETO MODELS,0.31554524361948955,Under review as a conference paper at ICLR 2022
FINDING PREFERRED PARETO MODELS,0.3167053364269142,"0.0
0.2
0.4
0.6
0.8
1.0
l1 0.0 0.2 0.4 0.6 0.8 1.0 l2"
FINDING PREFERRED PARETO MODELS,0.31786542923433875,task preference
FINDING PREFERRED PARETO MODELS,0.3190255220417633,"Pareto Front
EPO"
FINDING PREFERRED PARETO MODELS,0.32018561484918795,"0.0
0.2
0.4
0.6
0.8
1.0
l1 0.0 0.2 0.4 0.6 0.8 1.0 l2"
FINDING PREFERRED PARETO MODELS,0.3213457076566125,task preference
FINDING PREFERRED PARETO MODELS,0.3225058004640371,"Pareto Front
PNG"
FINDING PREFERRED PARETO MODELS,0.3236658932714617,"0.0
0.2
0.4
0.6
0.8
1.0 l1 0.0 0.2 0.4 0.6 0.8 1.0 l2"
FINDING PREFERRED PARETO MODELS,0.3248259860788863,weighted distance
FINDING PREFERRED PARETO MODELS,0.3259860788863109,"Pareto Front
PNG
Target"
FINDING PREFERRED PARETO MODELS,0.3271461716937355,"0.0
0.2
0.4
0.6
0.8
1.0 l1 0.0 0.2 0.4 0.6 0.8 1.0 l2"
FINDING PREFERRED PARETO MODELS,0.32830626450116007,complex cosine
FINDING PREFERRED PARETO MODELS,0.3294663573085847,"Pareto Front
PNG
Target"
FINDING PREFERRED PARETO MODELS,0.3306264501160093,"(a)
(b)
(c)
(d)"
FINDING PREFERRED PARETO MODELS,0.33178654292343385,"Figure 1: (a)-(b): the trajectory of ﬁnding Pareto models that satisfy different ratio constraints (shown in
different colors) on the two objectives ℓ1, ℓ2 using EPO and PNG; we can see that PNG can achieve the
same goal as EPO (with different trajectories) while being a more general approach. (c)-(d): the trajectory of
ﬁnding Pareto models that minimize the weighted distance and complex cosine criterion using PNG. The
green dots indicate the converged models. We can see that PNG can successfully locate the correct Pareto
models that minimize different criteria.
Pm
i=1(ℓi(θ) −ri)2/ri; and 2) complex cosine: in which F is a complicated function related to the cosine
226"
FINDING PREFERRED PARETO MODELS,0.3329466357308585,"of task objectives, i.e., Fcs = −cos (π(ℓ1(θ) −r1)/2) + (cos(π(ℓ(θ2) −r2)) + 1)2. Here the weighted ℓ2
227"
FINDING PREFERRED PARETO MODELS,0.33410672853828305,"distance can be viewed as ﬁnding a Pareto model that has the losses close to some target value r, which can be
228"
FINDING PREFERRED PARETO MODELS,0.3352668213457077,"viewed as an alternative approach to partition the Pareto set. The design of complex cosine aims to test whether
229"
FINDING PREFERRED PARETO MODELS,0.33642691415313225,"PNG is able to handle a very non-linear criterion function. In both cases, we take r1 = [0.2, 0.4, 0.6, 0.8] and
230"
FINDING PREFERRED PARETO MODELS,0.3375870069605568,"r2 = 1 −r1. We show in Fig 1(c)-(d) the trajectory of PNG. As we can see, PNG is able to correctly ﬁnd the
231"
FINDING PREFERRED PARETO MODELS,0.33874709976798145,"optimal solutions of OPT-in-Pareto. We also test PNG on a more challenging ZDT2-variant used in Ma et al.
232"
FINDING PREFERRED PARETO MODELS,0.339907192575406,"(2020) and a larger scale MTL problem (Liu et al., 2019). We refer readers to Appendix C.1.2 and C.1.3 for
233"
FINDING PREFERRED PARETO MODELS,0.34106728538283065,"the setting and results.
234"
FINDING DIVERSE PARETO MODELS,0.3422273781902552,"5.2
FINDING DIVERSE PARETO MODELS
235"
FINDING DIVERSE PARETO MODELS,0.3433874709976798,"Setup We consider the problem of ﬁnding diversiﬁed points from the Pareto set by minimizing the energy
236"
FINDING DIVERSE PARETO MODELS,0.34454756380510443,"distance criterion in Equation (6). We use the same setting as Lin et al. (2019); Mahapatra & Rajan (2020).
237"
FINDING DIVERSE PARETO MODELS,0.345707656612529,"We consider three benchmark datasets: (1) MultiMNIST, (2) MultiFashion, and (3) MultiFashion+MNIST.
238"
FINDING DIVERSE PARETO MODELS,0.3468677494199536,"For each dataset, there are two tasks (classifying the top-left and bottom-right images). We consider LeNet
239"
FINDING DIVERSE PARETO MODELS,0.3480278422273782,"with multihead and train N = 5 models to approximate the Pareto set. For baselines, we compare with linear
240"
FINDING DIVERSE PARETO MODELS,0.3491879350348028,"scalarization, MGD (Sener & Koltun, 2018), and EPO (Mahapatra & Rajan, 2020). For the MGD baseline,
241"
FINDING DIVERSE PARETO MODELS,0.3503480278422274,"we ﬁnd that naively running it leads to poor performance as the learned models are not diversiﬁed and thus we
242"
FINDING DIVERSE PARETO MODELS,0.351508120649652,"initialize the MGD with 60-epoch runs of linear scalarization with equally distributed preference weights and
243"
FINDING DIVERSE PARETO MODELS,0.35266821345707655,"runs MGD for the later 40 epoch. We refer the reader to Appendix C.2.1 for more details of the experiments.
244"
FINDING DIVERSE PARETO MODELS,0.3538283062645012,"Metric and Result We measure the quality of how well the found models {θ1, . . . , θN} approximate the
245"
FINDING DIVERSE PARETO MODELS,0.35498839907192575,"Pareto set using two standard metrics: Inverted Generational Distance Plus (IGD+) (Ishibuchi et al., 2015)
246"
FINDING DIVERSE PARETO MODELS,0.3561484918793503,"and hypervolume (HV) (Zitzler & Thiele, 1999); see Appendix C.2.2 for their deﬁnitions. We run all the
247"
FINDING DIVERSE PARETO MODELS,0.35730858468677495,"methods with 5 independent trials and report the averaged value and its standard deviation in Table 1. We
248"
FINDING DIVERSE PARETO MODELS,0.35846867749419953,"report the scores calculated based on loss (cross-entropy) and accuracy on the test set. The bolded values
249"
FINDING DIVERSE PARETO MODELS,0.35962877030162416,"indicate the best result with p-value less than 0.05 (using matched pair t-test). In most cases, PNG improves
250"
FINDING DIVERSE PARETO MODELS,0.36078886310904873,"the baselines by a large margin. We include ablation studies in Appendix C.2.3 and additional comparisons
251"
FINDING DIVERSE PARETO MODELS,0.3619489559164733,"with the second-order approach proposed by Ma et al. (2020) in Appendix C.2.4.
252"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.36310904872389793,"5.3
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM
253"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.3642691415313225,"JiGen (Carlucci et al., 2019b) learns a domain generalizable model by learning two tasks based on linear
254"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.3654292343387471,"scalarization, which essentially searches for a model in the Pareto set and requires choosing the weight of
255"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.3665893271461717,Under review as a conference paper at ICLR 2022
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.3677494199535963,"Data
Method
Loss
Acc
HV↑(10−2)
IGD+↓(10−2)
HV↑(10−2)
IGD+↓(10−2)"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.3689095127610209,Multi-MNIST
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.3700696055684455,"Linear
7.48 ± 0.11
0.14 ± 0.034
9.27 ± 0.024
0.036 ± 0.0084
MGD
7.69 ± 0.10
0.051 ± 0.011
9.27 ± 0.023
0.0078 ± 0.0010
EPO
7.87±0.16
0.069 ± 0.028
9.17 ± 0.032
0.065 ± 0.018
PNG
7.86±0.11
0.042±0.012
9.39±0.036
0.0056±0.0022"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.37122969837587005,Multi-Fashion
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.3723897911832947,"Linear
0.38 ± 0.059
0.13 ± 0.013
4.76 ± 0.019
0.064 ± 0.012
MGD
0.42 ± 0.064
0.046 ± 0.016
4.77 ± 0.019
0.023±0.0030
EPO
0.36 ± 0.058
0.31 ± 0.11
4.78 ± 0.030
0.21 ± 0.020
PNG
0.47±0.066
0.016±0.0022
4.81±0.021
0.023±0.0031"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.37354988399071926,Fashion-MNIST
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.37470997679814383,"Linear
5.01 ± 0.057
0.167 ± 0.054
8.46 ± 0.046
0.110 ± 0.035
MGD
5.09 ± 0.069
0.060 ± 0.029
8.40 ± 0.045
0.049±0.011
EPO
4.60 ± 0.166
0.233 ± 0.054
8.12 ± 0.041
0.385 ± 0.077
PNG
5.27±0.054
0.048±0.027
8.53±0.047
0.046±0.022"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.37587006960556846,"Table 1: Results of approximating the Pareto set by different methods on three MNIST benchmark datasets.
The numbers in the table are the averaged value and the standard deviation. Bolded values indicate the
statistically signiﬁcant best result with p-value less than 0.5 based on matched pair t-test."
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.37703016241299303,"PACS
art paint
cartoon
sketches
photo
Avg
D-SAM
0.7733
0.7243
0.7783
0.9530
0.8072
DeepAll
0.7785
0.7486
0.6774
0.9573
0.7905
JiGen
0.8009 ± 0.004
0.7363 ± 0.007
0.7046 ± 0.013
0.9629±0.002
0.8012 ± 0.002
JiGen+adv
0.7923 ± 0.006
0.7402 ± 0.004
0.7188 ± 0.005
0.9617 ± 0.001
0.8033 ± 0.001
JiGen+PNG
0.8014±0.005
0.7538±0.001
0.7222±0.006
0.9627±0.002
0.8100±0.005"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.37819025522041766,"Table 2: Comparing different methods for domain generalization on PACS using ResNet-18. The values in
table are the testing accuracy with its standard deviation. The bolded values are the best models with p-value
less than 0.1 based on match-pair t-test."
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.37935034802784223,"linear scalarization carefully. It is thus natural to study whether there is a better mechanism that dynamically
256"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.3805104408352668,"adjusts the weights of the two losses so that we eventually learn a better model. Motivated by the adversarial
257"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.38167053364269143,"feature learning (Ganin et al., 2016), we propose to improve JiGen such that the latent feature representations
258"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.382830626450116,"of the two tasks are well aligned. This can be framed into an OPT-in-Pareto problem where the criterion is
259"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.3839907192575406,"the discrepancy of the latent representations (implemented using an adversarial discrepancy module in the
260"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.3851508120649652,"network) of the two tasks. PNG is applied to solve the optimization. We evaluate the methods on PACS (Li
261"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.3863109048723898,"et al., 2017), which covers 7 object categories and 4 domains (Photo, Art Paintings, Cartoon, and Sketches).
262"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.3874709976798144,"The model is trained on three domains and tested on the rest of them. Our approach is denoted as JiGen+PNG
263"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.388631090487239,"and we also include JiGen + adv, which simply adds the adversarial loss as regularization and two other
264"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.38979118329466356,"baseline methods (D-SAM (D’Innocente & Caputo, 2018) and DeepAll (Carlucci et al., 2019b)). For the three
265"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.3909512761020882,"JiGen based approaches, we run 3 independent trials and for the other two baselines, we report the results in
266"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.39211136890951276,"their original papers. Table 2 shows the result using ResNet-18, which demonstrates the improvement by the
267"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.39327146171693733,"application of the OPT-in-Pareto framework. We also include the results using AlexNet in the Appendix. We
268"
APPLICATION TO MULTI-TASK BASED DOMAIN GENERALIZATION ALGORITHM,0.39443155452436196,"refer readers to Appendix C.4 for the additional results and more experiment details.
269"
CONCLUSION,0.39559164733178653,"6
CONCLUSION
270"
CONCLUSION,0.39675174013921116,"This paper studies the OPT-in-Pareto, a problem that has been studied in operation research with restrictive
271"
CONCLUSION,0.39791183294663574,"linear or convexity assumption but largely under-explored in deep learning literature, in which the objectives
272"
CONCLUSION,0.3990719257540603,"are non-linear and non-convex. Applying algorithms such as manifold gradient descent requires eigen-
273"
CONCLUSION,0.40023201856148494,"computation of the Hessian matrix at each iteration and thus can be expensive. We propose a ﬁrst-order
274"
CONCLUSION,0.4013921113689095,"approximation algorithm called Pareto Navigation Gradient Descent (PNG) with theoretically guaranteed
275"
CONCLUSION,0.4025522041763341,"descent and convergence property to solve OPT-in-Pareto.
276"
CONCLUSION,0.4037122969837587,Under review as a conference paper at ICLR 2022
REFERENCES,0.4048723897911833,"REFERENCES
277"
REFERENCES,0.4060324825986079,"Isabela Albuquerque, Nikhil Naik, Junnan Li, Nitish Keskar, and Richard Socher.
Improving out-of-
278"
REFERENCES,0.4071925754060325,"distribution generalization via multi-task self-supervised pretraining. arXiv preprint arXiv:2003.13525,
279"
REFERENCES,0.40835266821345706,"2020.
280"
REFERENCES,0.4095127610208817,"Mario Bernardo, Chris Budd, Alan Richard Champneys, and Piotr Kowalczyk. Piecewise-smooth dynamical
281"
REFERENCES,0.41067285382830626,"systems: theory and applications, volume 163. Springer Science & Business Media, 2008.
282"
REFERENCES,0.41183294663573083,"Silvere Bonnabel. Stochastic gradient descent on riemannian manifolds. IEEE Transactions on Automatic
283"
REFERENCES,0.41299303944315546,"Control, 58(9):2217–2229, 2013.
284"
REFERENCES,0.41415313225058004,"Stephen Boyd, Stephen P Boyd, and Lieven Vandenberghe. Convex optimization. Cambridge university press,
285"
REFERENCES,0.41531322505800466,"2004.
286"
REFERENCES,0.41647331786542924,"Fabio M. Carlucci, Antonio D’Innocente, Silvia Bucci, Barbara Caputo, and Tatiana Tommasi. Domain
287"
REFERENCES,0.4176334106728538,"generalization by solving jigsaw puzzles. In Proceedings of the IEEE/CVF Conference on Computer Vision
288"
REFERENCES,0.41879350348027844,"and Pattern Recognition (CVPR), June 2019a.
289"
REFERENCES,0.419953596287703,"Fabio M Carlucci, Antonio D’Innocente, Silvia Bucci, Barbara Caputo, and Tatiana Tommasi. Domain
290"
REFERENCES,0.4211136890951276,"generalization by solving jigsaw puzzles. In Proceedings of the IEEE/CVF Conference on Computer Vision
291"
REFERENCES,0.4222737819025522,"and Pattern Recognition, pp. 2229–2238, 2019b.
292"
REFERENCES,0.4234338747099768,"Zhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, and Andrew Rabinovich. Gradnorm: Gradient normalization
293"
REFERENCES,0.4245939675174014,"for adaptive loss balancing in deep multitask networks. In International Conference on Machine Learning,
294"
REFERENCES,0.425754060324826,"pp. 794–803. PMLR, 2018.
295"
REFERENCES,0.42691415313225056,"Zhao Chen, Jiquan Ngiam, Yanping Huang, Thang Luong, Henrik Kretzschmar, Yuning Chai, and Dragomir
296"
REFERENCES,0.4280742459396752,"Anguelov. Just pick a sign: Optimizing deep multitask models with gradient sign dropout. In H. Larochelle,
297"
REFERENCES,0.42923433874709976,"M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin (eds.), Advances in Neural Information Processing
298"
REFERENCES,0.43039443155452434,"Systems, volume 33, pp. 2039–2050. Curran Associates, Inc., 2020. URL https://proceedings.
299"
REFERENCES,0.43155452436194897,"neurips.cc/paper/2020/file/16002f7a455a94aa4e91cc34ebdb9f2d-Paper.pdf.
300"
REFERENCES,0.43271461716937354,"Timo M Deist, Monika Grewal, Frank JWM Dankers, Tanja Alderliesten, and Peter AN Bosman.
301"
REFERENCES,0.43387470997679817,"Multi-objective learning to predict pareto fronts using hypervolume maximization.
arXiv preprint
302"
REFERENCES,0.43503480278422274,"arXiv:2102.04523, 2021.
303"
REFERENCES,0.4361948955916473,"Stephan Dempe. Bilevel optimization: theory, algorithms and applications. TU Bergakademie Freiberg,
304"
REFERENCES,0.43735498839907194,"Fakultät für Mathematik und Informatik, 2018.
305"
REFERENCES,0.4385150812064965,"Jean-Antoine Désidéri. Multiple-gradient descent algorithm (mgda) for multiobjective optimization. Comptes
306"
REFERENCES,0.4396751740139211,"Rendus Mathematique, 350(5-6):313–318, 2012.
307"
REFERENCES,0.4408352668213457,"Qi Dou, Daniel C Castro, Konstantinos Kamnitsas, and Ben Glocker. Domain generalization via model-
308"
REFERENCES,0.4419953596287703,"agnostic learning of semantic features. arXiv preprint arXiv:1910.13580, 2019.
309"
REFERENCES,0.4431554524361949,"Antonio D’Innocente and Barbara Caputo. Domain generalization with domain-speciﬁc aggregation modules.
310"
REFERENCES,0.4443155452436195,"In German Conference on Pattern Recognition, pp. 187–198. Springer, 2018.
311"
REFERENCES,0.44547563805104406,"Joseph G Ecker and Jung Hwan Song. Optimizing a linear function over an efﬁcient set. Journal of
312"
REFERENCES,0.4466357308584687,"Optimization Theory and Applications, 83(3):541–563, 1994.
313"
REFERENCES,0.44779582366589327,"Christopher Fifty, Ehsan Amid, Zhe Zhao, Tianhe Yu, Rohan Anil, and Chelsea Finn. Measuring and
314"
REFERENCES,0.44895591647331784,"harnessing transference in multi-task learning. arXiv preprint arXiv:2010.15413, 2020.
315"
REFERENCES,0.45011600928074247,Under review as a conference paper at ICLR 2022
REFERENCES,0.45127610208816704,"Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In International
316"
REFERENCES,0.45243619489559167,"conference on machine learning, pp. 1180–1189. PMLR, 2015.
317"
REFERENCES,0.45359628770301624,"Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, François Laviolette,
318"
REFERENCES,0.4547563805104408,"Mario March, and Victor Lempitsky. Domain-adversarial training of neural networks. Journal of Machine
319"
REFERENCES,0.45591647331786544,"Learning Research, 17(59):1–35, 2016. URL http://jmlr.org/papers/v17/15-239.html.
320"
REFERENCES,0.45707656612529,"DP Hardin and EB Saff. Discretizing manifolds via minimum energy points. Notices of the AMS, 51(10):
321"
REFERENCES,0.4582366589327146,"1186–1194, 2004.
322"
REFERENCES,0.4593967517401392,"Dan Hendrycks, Mantas Mazeika, Saurav Kadavath, and Dawn Song. Using self-supervised learning can
323"
REFERENCES,0.4605568445475638,"improve model robustness and uncertainty. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc,
324"
REFERENCES,0.4617169373549884,"E. Fox, and R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 32. Cur-
325"
REFERENCES,0.462877030162413,"ran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper/2019/file/
326"
REFERENCES,0.46403712296983757,"a2b15837edac15df90721968986f7f8e-Paper.pdf.
327"
REFERENCES,0.4651972157772622,"Claus Hillermeier. Generalized homotopy approach to multiobjective optimization. Journal of Optimization
328"
REFERENCES,0.46635730858468677,"Theory and Applications, 110(3):557–583, 2001.
329"
REFERENCES,0.46751740139211134,"Hisao Ishibuchi, Hiroyuki Masuda, Yuki Tanigaki, and Yusuke Nojima. Modiﬁed distance calculation in
330"
REFERENCES,0.46867749419953597,"generational distance and inverted generational distance. In International conference on evolutionary
331"
REFERENCES,0.46983758700696054,"multi-criterion optimization, pp. 110–125. Springer, 2015.
332"
REFERENCES,0.4709976798143852,"Adrián Javaloy and Isabel Valera. Rotograd: Dynamic gradient homogenization for multi-task learning. arXiv
333"
REFERENCES,0.47215777262180975,"preprint arXiv:2103.02631, 2021.
334"
REFERENCES,0.4733178654292343,"Jesús M Jorge. A bilinear algorithm for optimizing a linear function over the efﬁcient set of a multiple
335"
REFERENCES,0.47447795823665895,"objective linear programming problem. Journal of Global Optimization, 31(1):1–16, 2005.
336"
REFERENCES,0.4756380510440835,"Mohammad Mahdi Kamani, Rana Forsati, James Z Wang, and Mehrdad Mahdavi. Pareto efﬁcient fairness in
337"
REFERENCES,0.4767981438515081,"supervised learning: From extraction to tracing. arXiv preprint arXiv:2104.01634, 2021.
338"
REFERENCES,0.4779582366589327,"Alex Kendall, Yarin Gal, and Roberto Cipolla. Multi-task learning using uncertainty to weigh losses for
339"
REFERENCES,0.4791183294663573,"scene geometry and semantics. In Proceedings of the IEEE conference on computer vision and pattern
340"
REFERENCES,0.4802784222737819,"recognition, pp. 7482–7491, 2018.
341"
REFERENCES,0.4814385150812065,"Pang Wei Koh and Percy Liang. Understanding black-box predictions via inﬂuence functions. In International
342"
REFERENCES,0.48259860788863107,"Conference on Machine Learning, pp. 1885–1894. PMLR, 2017.
343"
REFERENCES,0.4837587006960557,"Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M. Hospedales. Deeper, broader and artier domain
344"
REFERENCES,0.48491879350348027,"generalization. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), Oct
345"
REFERENCES,0.48607888631090485,"2017.
346"
REFERENCES,0.4872389791183295,"Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy Hospedales. Learning to generalize: Meta-learning for
347"
REFERENCES,0.48839907192575405,"domain generalization. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 32,
348"
REFERENCES,0.4895591647331787,"2018a.
349"
REFERENCES,0.49071925754060325,"Ya Li, Xinmei Tian, Mingming Gong, Yajing Liu, Tongliang Liu, Kun Zhang, and Dacheng Tao. Deep
350"
REFERENCES,0.4918793503480278,"domain generalization via conditional invariant adversarial networks. In Proceedings of the European
351"
REFERENCES,0.49303944315545245,"Conference on Computer Vision (ECCV), pp. 624–639, 2018b.
352"
REFERENCES,0.494199535962877,"Xi Lin, Hui-Ling Zhen, Zhenhua Li, Qingfu Zhang, and Sam Kwong. Pareto multi-task learning. arXiv
353"
REFERENCES,0.4953596287703016,"preprint arXiv:1912.12854, 2019.
354"
REFERENCES,0.4965197215777262,Under review as a conference paper at ICLR 2022
REFERENCES,0.4976798143851508,"Xi Lin, Zhiyuan Yang, Qingfu Zhang, and Sam Kwong. Controllable pareto multi-task learning. arXiv
355"
REFERENCES,0.4988399071925754,"preprint arXiv:2010.06313, 2020.
356"
REFERENCES,0.5,"Shikun Liu, Edward Johns, and Andrew J Davison. End-to-end multi-task learning with attention. In
357"
REFERENCES,0.5011600928074246,"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1871–1880,
358"
REFERENCES,0.5023201856148491,"2019.
359"
REFERENCES,0.5034802784222738,"Zhengliang Liu and Matthias Ehrgott. Primal and dual algorithms for optimization over the efﬁcient set.
360"
REFERENCES,0.5046403712296984,"Optimization, 67(10):1661–1686, 2018.
361"
REFERENCES,0.505800464037123,"Xiaoyuan Luo, Shaolei Liu, Kexue Fu, Manning Wang, and Zhijian Song. A learnable self-supervised task
362"
REFERENCES,0.5069605568445475,"for unsupervised domain adaptation on point clouds. arXiv preprint arXiv:2104.05164, 2021.
363"
REFERENCES,0.5081206496519721,"Pingchuan Ma, Tao Du, and Wojciech Matusik. Efﬁcient continuous pareto exploration in multi-task learning.
364"
REFERENCES,0.5092807424593968,"In International Conference on Machine Learning, pp. 6522–6531. PMLR, 2020.
365"
REFERENCES,0.5104408352668214,"Debabrata Mahapatra and Vaibhav Rajan. Multi-task learning with user preferences: Gradient descent with
366"
REFERENCES,0.511600928074246,"controlled ascent in pareto optimization. In International Conference on Machine Learning, pp. 6597–6607.
367"
REFERENCES,0.5127610208816705,"PMLR, 2020.
368"
REFERENCES,0.5139211136890951,"Aviv Navon, Aviv Shamsian, Gal Chechik, and Ethan Fetaya. Learning the pareto front with hypernetworks.
369"
REFERENCES,0.5150812064965197,"arXiv preprint arXiv:2010.04104, 2020.
370"
REFERENCES,0.5162412993039444,"Javad Sadeghi and Hossein Mohebi. Solving optimization problems over the weakly efﬁcient set. Numerical
371"
REFERENCES,0.5174013921113689,"Functional Analysis and Optimization, pp. 1–33, 2021.
372"
REFERENCES,0.5185614849187935,"Ozan Sener and Vladlen Koltun. Multi-task learning as multi-objective optimization. In S. Bengio, H. Wallach,
373"
REFERENCES,0.5197215777262181,"H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural Information Pro-
374"
REFERENCES,0.5208816705336426,"cessing Systems, volume 31. Curran Associates, Inc., 2018. URL https://proceedings.neurips.
375"
REFERENCES,0.5220417633410673,"cc/paper/2018/file/432aca3a1e345e339f35a30c8f65edce-Paper.pdf.
376"
REFERENCES,0.5232018561484919,"Nathan Silberman, Derek Hoiem, Pushmeet Kohli, and Rob Fergus. Indoor segmentation and support
377"
REFERENCES,0.5243619489559165,"inference from rgbd images. In European conference on computer vision, pp. 746–760. Springer, 2012.
378"
REFERENCES,0.525522041763341,"Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao Zhang, Han Zhang, Colin A Raffel, Ekin Do-
379"
REFERENCES,0.5266821345707656,"gus Cubuk, Alexey Kurakin, and Chun-Liang Li.
Fixmatch: Simplifying semi-supervised learning
380"
REFERENCES,0.5278422273781903,"with consistency and conﬁdence.
In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and
381"
REFERENCES,0.5290023201856149,"H. Lin (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 596–608. Cur-
382"
REFERENCES,0.5301624129930395,"ran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/file/
383"
REFERENCES,0.531322505800464,"06964dce9addb1c5cb5d6e3d9838f733-Paper.pdf.
384"
REFERENCES,0.5324825986078886,"Yu Sun, Eric Tzeng, Trevor Darrell, and Alexei A Efros. Unsupervised domain adaptation through self-
385"
REFERENCES,0.5336426914153132,"supervision. arXiv preprint arXiv:1909.11825, 2019.
386"
REFERENCES,0.5348027842227379,"Phan Thien Thach and TV Thang. Problems with resource allocation constraints and optimization over the
387"
REFERENCES,0.5359628770301624,"efﬁcient set. Journal of Global Optimization, 58(3):481–495, 2014.
388"
REFERENCES,0.537122969837587,"Sen Wu, Hongyang R. Zhang, and Christopher Ré. Understanding and improving information transfer
389"
REFERENCES,0.5382830626450116,"in multi-task learning. In International Conference on Learning Representations, 2020. URL https:
390"
REFERENCES,0.5394431554524362,"//openreview.net/forum?id=SylzhkBtDB.
391"
REFERENCES,0.5406032482598608,"Sang Michael Xie, Ananya Kumar, Robbie Jones, Fereshte Khani, Tengyu Ma, and Percy Liang. In-n-out: Pre-
392"
REFERENCES,0.5417633410672854,"training and self-training using auxiliary information for out-of-distribution robustness. In International
393"
REFERENCES,0.54292343387471,"Conference on Learning Representations, 2021. URL https://openreview.net/forum?id=
394"
REFERENCES,0.5440835266821346,"jznizqvr15J.
395"
REFERENCES,0.5452436194895591,Under review as a conference paper at ICLR 2022
REFERENCES,0.5464037122969838,"Junfeng Yang and Carl Vondrick. Multitask learning strengthens adversarial robustness. 2020.
396"
REFERENCES,0.5475638051044084,"Tianhe Yu, Saurabh Kumar, Abhishek Gupta, Sergey Levine, Karol Hausman, and Chelsea Finn. Gra-
397"
REFERENCES,0.548723897911833,"dient surgery for multi-task learning. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and
398"
REFERENCES,0.5498839907192575,"H. Lin (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 5824–5836. Cur-
399"
REFERENCES,0.5510440835266821,"ran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/file/
400"
REFERENCES,0.5522041763341067,"3fe78a8acf5fda99de95303940a2420c-Paper.pdf.
401"
REFERENCES,0.5533642691415314,"Linfeng Zhang, Muzhou Yu, Tong Chen, Zuoqiang Shi, Chenglong Bao, and Kaisheng Ma. Auxiliary training:
402"
REFERENCES,0.5545243619489559,"Towards accurate and robust models. In Proceedings of the IEEE/CVF Conference on Computer Vision
403"
REFERENCES,0.5556844547563805,"and Pattern Recognition, pp. 372–381, 2020.
404"
REFERENCES,0.5568445475638051,"Eckart Zitzler and Lothar Thiele. Multiobjective evolutionary algorithms: a comparative case study and the
405"
REFERENCES,0.5580046403712297,"strength pareto approach. IEEE transactions on Evolutionary Computation, 3(4):257–271, 1999.
406"
REFERENCES,0.5591647331786543,Under review as a conference paper at ICLR 2022
REFERENCES,0.5603248259860789,"A
THEORETICAL ANALYSIS
407"
REFERENCES,0.5614849187935035,"Theorem 1 [Dual of Equation (7)]
The solution vt of Equation (7), if it exists, has a form of"
REFERENCES,0.5626450116009281,"vt = ∇F(θt) + m
X"
REFERENCES,0.5638051044083526,"i=1
λi,t∇ℓi(θt),"
REFERENCES,0.5649651972157773,"with {λi,t}m
i=1 the solution of the following dual problem"
REFERENCES,0.5661252900232019,"max
λ∈Rm
+
−1 2"
REFERENCES,0.5672853828306265,"∇F(θt) + m
X"
REFERENCES,0.568445475638051,"i=1
λt∇ℓi(θt)  2 + m
X"
REFERENCES,0.5696055684454756,"i=1
λiφt,"
REFERENCES,0.5707656612529002,"where Rm
+ is the set of nonnegative m-dimensional vectors, that is, Rm
+ = {λ ∈Rm : λi ≥0, ∀i ∈[m]}.
408"
REFERENCES,0.5719257540603249,"Proof. By introducing Lagrange multipliers, the optimization in Equation (7) is equivalent to the following
409"
REFERENCES,0.5730858468677494,"minimax problem:
410"
REFERENCES,0.574245939675174,"min
v∈Rn max
λ∈Rm
+"
REFERENCES,0.5754060324825986,"1
2 ∥∇F(θt) −v∥2 + m
X"
REFERENCES,0.5765661252900232,"i=1
λi
 
φt −∇ℓi(θt)⊤v

."
REFERENCES,0.5777262180974478,"With strong duality of convex quadratic programming (assuming the primal problem is feasible), we can
exchange the order of min and max, yielding"
REFERENCES,0.5788863109048724,"max
λ∈Rm
+ ("
REFERENCES,0.580046403712297,"Φ(λ) := min
v∈Rn
1
2 ∥∇F(θt) −v∥2 + m
X"
REFERENCES,0.5812064965197216,"i=1
λi
 
φt −∇ℓi(θt)⊤v

) ."
REFERENCES,0.5823665893271461,"It is easy to see that the minimization w.r.t. v is achieved when v = ∇F(θt) + Pm
i=1 λi∇ℓi(θt). Correspond-
411"
REFERENCES,0.5835266821345708,"ingly, the Φ(λ) has the following dual form:
412"
REFERENCES,0.5846867749419954,"max
λ∈Rm
+
−1 2"
REFERENCES,0.58584686774942,"∇F(θt) + m
X"
REFERENCES,0.5870069605568445,"i=1
λi∇ℓi(θt)  2 + m
X"
REFERENCES,0.5881670533642691,"i=1
λiφt."
REFERENCES,0.5893271461716937,"This concludes the proof.
413"
REFERENCES,0.5904872389791184,"Theorem 2 [Pareto Improvement on ℓ]
Under Assumption 1, assume θ0 ̸∈Pe, and te is the ﬁrst time
when θte ∈Pe, then for any time t < te,"
REFERENCES,0.5916473317865429,"d
dtℓi(θt) ≤−αtg(θt),
min
s∈[0,t] g(θt) ≤mini∈[m](ℓi(θ0) −ℓ∗
i )
R t
0 αsds
."
REFERENCES,0.5928074245939675,"Therefore, the update yields Pareto improvement on ℓwhen θt ̸∈Pe and αtg(θt) > 0.
414"
REFERENCES,0.5939675174013921,"Further, if
R t
0 αsds = +∞, then for any ϵ > e, there exists a ﬁnite time tϵ ∈R+ on which the solution enters
415"
REFERENCES,0.5951276102088167,"Pϵ and stays within Pϵ afterwards, that is, we have θtϵ ∈Pϵ and θt ∈Pϵ for any t ≥tϵ.
416"
REFERENCES,0.5962877030162413,"Proof. i) When t < te, we have g(θt) > e and hence"
REFERENCES,0.5974477958236659,"d
dtℓi(θt) = −∇ℓi(θt)⊤vt ≤−φt = −αtg(θt),
(11)"
REFERENCES,0.5986078886310905,"where we used the constraint of ∇ℓi(θt)⊤vt ≥φt in Equation (7). Therefore, we yield strict decent on all the
417"
REFERENCES,0.5997679814385151,"losses {ℓi} when αtg(θt) > 0.
418"
REFERENCES,0.6009280742459396,Under review as a conference paper at ICLR 2022
REFERENCES,0.6020881670533643,ii) Integrating both sides of Equation (11):
REFERENCES,0.6032482598607889,"min
s∈[0,t] g(θs) ≤"
REFERENCES,0.6044083526682135,"R t
0 αsg(θs)ds"
REFERENCES,0.605568445475638,"R t
0 αsds
≤ℓi(θ0) −ℓi(θt)
R t
0 αsds
≤ℓi(θ0) −ℓ∗"
REFERENCES,0.6067285382830626,"R t
0 αsds
."
REFERENCES,0.6078886310904872,"This yields the result since it holds for every i ∈[m].
419"
REFERENCES,0.6090487238979119,"If
R ∞
0
αtdt = +∞, then we have mins∈[0,t] g(θs) →0 when t →+∞. Assume there exists an ϵ > e,
420"
REFERENCES,0.6102088167053364,"such that θt never enters Pϵ at ﬁnite t. Then we have g(θt) ≥ϵ for t ∈R+, which contradicts with
421"
REFERENCES,0.611368909512761,"mins∈[0,t] g(θs) →0.
422"
REFERENCES,0.6125290023201856,"iii) Assume there exists a ﬁnite time t′ ∈(tϵ, +∞) such that θt′ ̸∈Pϵ. Because ϵ > e and g is continuous, Pe
423"
REFERENCES,0.6136890951276102,"is in the interior of Pϵ ⊆Pϵ. Therefore, the trajectory leading to θt′ ̸∈Pϵ must pass through Pϵ \ Pe at some
424"
REFERENCES,0.6148491879350348,"point, that is, there exists a point t′′ ∈[tϵ, t′), such that {θt : t ∈[t′′, t′]} ̸∈Pe. But because the algorithm can
425"
REFERENCES,0.6160092807424594,"not increase any objective ℓi outside of Pe, we must have ℓ(θt′) ⪯ℓ(θt′′), yielding that θt′ ∈{θt′′} ⊆Pϵ,
426"
REFERENCES,0.617169373549884,"where {θt′′} is the Pareto closure of {θt′′}; this contradicts with the assumption.
427"
REFERENCES,0.6183294663573086,"Lemma 1
Under Assumption 1, assume θt ̸∈Pe is a ﬁxed point of the algorithm, that is, dθt"
REFERENCES,0.6194895591647331,"dt = −vt = 0,
428"
REFERENCES,0.6206496519721578,"and F, ℓare convex in a neighborhood θt, then θt is a local minimum of F in the Pareto closure {θt},
429"
REFERENCES,0.6218097447795824,"that is, there exists a neighborhood of θt in which there exists no point θ′ such that F(θ′) < F(θt) and
430"
REFERENCES,0.622969837587007,"ℓ(θ′) ⪯ℓ(θt).
431"
REFERENCES,0.6241299303944315,Proof. Note that minimizing F in {θt} can be framed into a constrained optimization problem:
REFERENCES,0.6252900232018561,"min
θ
F(θ)
s.t.
ℓi(θ) ≤ℓi(θt), ∀i ∈[m]."
REFERENCES,0.6264501160092807,"In addition, by assumption, θ = θt satisﬁes vt = ∇F(θt) + Pm
i=1 λi,t∇ℓi(θt) = 0, which is the KKT
432"
REFERENCES,0.6276102088167054,"stationarity condition of the constrained optimization. It is also obvious to check that θ = θt satisﬁes the
433"
REFERENCES,0.62877030162413,"feasibility and slack condition trivially. Combining this with the local convexity assumption yields the
434"
REFERENCES,0.6299303944315545,"result.
435"
REFERENCES,0.6310904872389791,"Theorem 3 [Optimization of F]
Let ϵ > e and assume gϵ := supθ{g(θ): θ ∈Pϵ} < +∞and
supt≥0 αt < ∞. Under Assumption 1, when we initialize from θ0 ∈Pϵ, we have"
REFERENCES,0.6322505800464037,"min
s∈[0,t] dθs ds "
REFERENCES,0.6334106728538283,"2
≤F(θ0) −F ∗ t
+ 1 t Z t"
REFERENCES,0.6345707656612529,"0
αs (αsgϵ + c√gϵ) ds."
REFERENCES,0.6357308584686775,"In particular, if we have αt = α = const, then mins∈[0,t] ∥dθs/ds∥2 = O
 
1/t + α√gϵ

.
436"
REFERENCES,0.6368909512761021,"If
R ∞
0
αγ
t dt < +∞for some γ ≥1, we have mins∈[0,t] ∥dθs/ds∥2 = O(1/t + √gϵ/t1/γ).
437"
REFERENCES,0.6380510440835266,Proof. i) The slack condition of the constrained optimization in Equation (7) says that
REFERENCES,0.6392111368909513,"λi,t
 
∇ℓi(θt)⊤vt −φt

= 0, ∀i ∈[m].
(12)"
REFERENCES,0.6403712296983759,This gives that
REFERENCES,0.6415313225058005,∥vt∥2 = 
REFERENCES,0.642691415313225,"∇F(θt) + m
X"
REFERENCES,0.6438515081206496,"i=1
λi,t∇ℓi(θt) !⊤ vt"
REFERENCES,0.6450116009280742,"= ∇F(θt)⊤vt + m
X"
REFERENCES,0.6461716937354989,"i=1
λi,tφt
//plugging Equation (12).
(13)"
REFERENCES,0.6473317865429234,Under review as a conference paper at ICLR 2022
REFERENCES,0.648491879350348,"If θt ̸∈Pe, we have φt = αtg(θt) and this gives"
REFERENCES,0.6496519721577726,"d
dtF(θt) = −∇F(θt)⊤vt = −∥vt∥2 + m
X"
REFERENCES,0.6508120649651972,"i=1
λi,tφt = −

dθt dt  2
+ m
X"
REFERENCES,0.6519721577726219,"i=1
λi,tαtg(θt)"
REFERENCES,0.6531322505800464,"If θt is in the interior of Pe, then we run typical gradient descent of F and hence has"
REFERENCES,0.654292343387471,"d
dtF(θt) = −∥vt∥2 = −

dθt dt  2
."
REFERENCES,0.6554524361948956,"If θt is on the boundary of Pe, then by the deﬁnition of differential inclusion, dθ/dt belongs to the convex
hull of the velocities that it receives from either side of the boundary, yielding that"
REFERENCES,0.6566125290023201,"d
dtF(θt) = −

dθt dt  2
+ β m
X"
REFERENCES,0.6577726218097448,"i=1
λi,tαtg(θt) ≤−

dθt dt  2
+ m
X"
REFERENCES,0.6589327146171694,"i=1
λi,tαtg(θt),"
REFERENCES,0.660092807424594,"where β ∈[0, 1]. Combining all the cases gives"
REFERENCES,0.6612529002320185,"d
dtF(θt) ≤−

dθt dt  2
+ m
X"
REFERENCES,0.6624129930394431,"i=1
λi,tαtg(θt)."
REFERENCES,0.6635730858468677,Integrating this yields
REFERENCES,0.6647331786542924,"min
s∈[0,t] dθs ds  2
≤1 t Z t 0 dθs ds "
REFERENCES,0.665893271461717,"2
ds ≤F(θ0) −F ∗ t
+ 1 t Z t 0 m
X"
REFERENCES,0.6670533642691415,"i=1
λi,sαsg(θs)ds"
REFERENCES,0.6682134570765661,"≤F(θ0) −F ∗ t
+ 1 t Z t"
REFERENCES,0.6693735498839907,"0
αs (αsgϵ + c√gϵ) ds,"
REFERENCES,0.6705336426914154,"where the last step used Lemma 2 with φt = αtg(θt): m
X"
REFERENCES,0.6716937354988399,"i=1
λi,tαtg(θt) ≤α2
tg(θt) + cαt
p"
REFERENCES,0.6728538283062645,"g(θt) ≤α2
tgϵ + cαt
√gϵ,"
REFERENCES,0.6740139211136891,"and here we used g(θt) ≤gϵ because the trajectory is contained in Pϵ following Theorem 2.
438"
REFERENCES,0.6751740139211136,"The remaining results follow Lemma 4.
439"
REFERENCES,0.6763341067285383,"A.0.1
TECHNICAL LEMMAS
440"
REFERENCES,0.6774941995359629,"Lemma 2. Assume Assumption 1 holds. Deﬁne g(θ) = minω∈Cm ∥Pm
i=1 ωi∇ℓi(θ)∥2, where Cm is the
probability simplex on [m]. Then for the vt and λi,t deﬁned in Equation (7) and Equation (10), we have m
X"
REFERENCES,0.6786542923433875,"i=1
λi,tg(θt) ≤max

φt + c
p"
REFERENCES,0.679814385150812,"g(θt), 0

."
REFERENCES,0.6809744779582366,"Proof. The slack condition of the constrained optimization in Equation (7) says that
441"
REFERENCES,0.6821345707656613,"λi,t
 
∇ℓi(θ)⊤vt −φt

= 0,
∀i ∈[m]."
REFERENCES,0.6832946635730859,"Sum the equation over i ∈[m] and note that vt = ∇F(θt) + Pm
i=1 λi,t∇ℓi(θt). We get m
X"
REFERENCES,0.6844547563805105,"i=1
λi,t∇ℓi(θt)  2 + m
X"
REFERENCES,0.685614849187935,"i=1
λi,t∇ℓi(θt) !⊤"
REFERENCES,0.6867749419953596,"∇F(θ) − m
X"
REFERENCES,0.6879350348027842,"i=1
λi,tφt = 0.
(14)"
REFERENCES,0.6890951276102089,"Under review as a conference paper at ICLR 2022 Deﬁne xt =  m
X"
REFERENCES,0.6902552204176334,"i=1
λi,t∇ℓi(θt)  2"
REFERENCES,0.691415313225058,",
¯λt = m
X"
REFERENCES,0.6925754060324826,"i=1
λi,t,
gt = g(θt) = min
ω∈Cm  m
X"
REFERENCES,0.6937354988399071,"i=1
ωi∇ℓi(θt)  2 ."
REFERENCES,0.6948955916473318,"Then it is easy to see that xt ≥¯λ2
tgt. Using Cauchy-Schwarz inequality, m
X"
REFERENCES,0.6960556844547564,"i=1
λi,t∇ℓi(θ) !⊤"
REFERENCES,0.697215777262181,∇F(θt)
REFERENCES,0.6983758700696056,"≤∥∇F(θt)∥  m
X"
REFERENCES,0.6995359628770301,"i=1
λi,t∇ℓi(θ)"
REFERENCES,0.7006960556844548,"≤c√xt,"
REFERENCES,0.7018561484918794,"where we used ∥∇F(θt)∥≤c by Assumption 1. Combining this with Equation (14), we have
xt −¯λtφt
 ≤c√xt."
REFERENCES,0.703016241299304,"Applying Lemma 3 yields the result.
442"
REFERENCES,0.7041763341067285,"Lemma 3. Assume φ ∈R, and x, λ, c, g ∈R+ are non-negative real numbers and they satisfy"
REFERENCES,0.7053364269141531,"|x −λφ| ≤c√x,
x ≥λ2g."
REFERENCES,0.7064965197215777,"Then we have λg ≤max(0, φ + c√g).
443"
REFERENCES,0.7076566125290024,"Proof. Square the ﬁrst equation, we get"
REFERENCES,0.7088167053364269,"f(x) := (x −λφ)2 −c2x ≤0,"
REFERENCES,0.7099767981438515,"where f is a quadratic function. To ensure that f(x) ≤0 has a solution that satisﬁes x ≥λ2g, we need to
have f(λ2g) ≤0, that is,
f(λ2g) = (λ2g −λφ)2 −c2λ2g ≤0.
This can hold under two cases:
444"
REFERENCES,0.7111368909512761,"Case 1: λ = 0;
445"
REFERENCES,0.7122969837587007,"Case 2: |λg −φ| ≤c√g, and hence φ −c√g ≤λg ≤φ + c√g.
446"
REFERENCES,0.7134570765661253,"Under both case, we have
λg ≤max(0, φ + c√g). 447"
REFERENCES,0.7146171693735499,"Lemma 4. Let {αt : t ∈R+} ⊆R+ be a non-negative sequence with A :=
 R ∞
0
αγ
t dt
1/γ < ∞, where
γ ≥1, and B = supt αt < ∞. Then we have 1 t Z t 0"
REFERENCES,0.7157772621809745," 
α2
s + αs

ds ≤(B + 1)At−1/γ."
REFERENCES,0.7169373549883991,"Proof. Let η =
γ
γ−1, so that 1/η + 1/γ = 1. We have by Holder’s inequality, Z t"
REFERENCES,0.7180974477958236,"0
αsds ≤
Z t"
REFERENCES,0.7192575406032483,"0
αγ
sds
1/γ Z t"
REFERENCES,0.7204176334106729,"0
1ηds
1/η
≤At1/η = At1−1/γ."
REFERENCES,0.7215777262180975,"and hence
1 t Z t 0"
REFERENCES,0.722737819025522," 
α2
s + αs

ds ≤B + 1 t Z t"
REFERENCES,0.7238979118329466,"0
αsds ≤(B + 1)At−1/γ. 448"
REFERENCES,0.7250580046403712,Under review as a conference paper at ICLR 2022
REFERENCES,0.7262180974477959,Algorithm 1 Pareto Navigating Gradient Descent
REFERENCES,0.7273781902552204,"1: Initialize θ0; decide the step size ξ, and the control function φ in Equation (8) (including the threshold
e > 0 and the descending rate {αt}).
2: for iteration t do"
REFERENCES,0.728538283062645,"θt+1 ←θt −ξvt,
vt = ∇F(θt) + m
X"
REFERENCES,0.7296983758700696,"i=1
λi,t∇ℓi(θt),
(15)"
REFERENCES,0.7308584686774942,"where λi,t = 0, ∀i ∈[m] if g(θt) ≤e, and {λi,t}m
t=1 is the solution of Equation (10) with φ(θt) =
αtg(θt) when g(θt) > e.
3: end for"
REFERENCES,0.7320185614849188,"B
PRACTICAL IMPLEMENTATION
449"
REFERENCES,0.7331786542923434,"Hyper-parameters
Our algorithm introduces two hyperparameters {αt} and e over vanilla gradient descent.
450"
REFERENCES,0.734338747099768,"We use constant sequence αt = α and we take α = 0.5 unless otherwise speciﬁed. We choose e by
451"
REFERENCES,0.7354988399071926,"e = γe0, where e0 is an exponentially discounted average of 1"
REFERENCES,0.7366589327146171,"m
Pm
i=1 ∥∇ℓi(θt)∥2 over the trajectory so that
452"
REFERENCES,0.7378190255220418,"it automatically scales with the magnitude of the gradients of the problem at hand. In the experiments of this
453"
REFERENCES,0.7389791183294664,"paper, we simply ﬁx γ = 0.1 unless speciﬁed.
454"
REFERENCES,0.740139211136891,"Solving the Dual Problem
Our method requires to calculate {λi,t}m
t=1 with the dual optimization problem
455"
REFERENCES,0.7412993039443155,"in Equation (10), which can be solved with any off-the-shelf convex quadratic programming tool. In this
456"
REFERENCES,0.7424593967517401,"work, we use a very simple projected gradient descent to approximately solve Equation (10). We initialize
457"
REFERENCES,0.7436194895591647,"{λi,t}m
t=1 with a zero vector and terminate when the difference between the last two iterations is smaller than
458"
REFERENCES,0.7447795823665894,"a threshold or the algorithm reaches the maximum number of iterations (we use 100 in all experiments).
459"
REFERENCES,0.7459396751740139,"The whole algorithm procedure is summarized in Algorithm 1.
460"
REFERENCES,0.7470997679814385,"C
EXPERIMENTS
461"
REFERENCES,0.7482598607888631,"C.1
FINDING PREFERRED PARETO MODELS
462"
REFERENCES,0.7494199535962877,"C.1.1
RATIO-BASED CRITERION
463"
REFERENCES,0.7505800464037123,"The non-uniformity score from (Mahapatra & Rajan, 2020) that we use in Figure 1 is deﬁned as"
REFERENCES,0.7517401392111369,"FNU(θ) = m
X"
REFERENCES,0.7529002320185615,"t=1
ˆℓt(θ) log"
REFERENCES,0.7540603248259861,ˆℓt(θ) 1/m !
REFERENCES,0.7552204176334106,",
ˆℓt(θ) =
rtℓt(θ)
P"
REFERENCES,0.7563805104408353,"s∈[m] rsℓs(θ).
(16)"
REFERENCES,0.7575406032482599,"We ﬁx the other experiment settings the same as Mahapatra & Rajan (2020) and use γ = 0.01 and α = 0.25
464"
REFERENCES,0.7587006960556845,"for this experiment reported in the main text. We defer the ablation studies on the hyper-parameter α and γ to
465"
REFERENCES,0.759860788863109,"Section C.3.
466"
REFERENCES,0.7610208816705336,"C.1.2
ZDT2-VARIANT
467"
REFERENCES,0.7621809744779582,"We consider the ZDT2-Variant example used in Ma et al. (2020) with the same experiment setting, in
468"
REFERENCES,0.7633410672853829,"which the Pareto set is a cylindrical surface, making the problem more challenging. We consider the
469"
REFERENCES,0.7645011600928074,"same criteria, e.g. weighted distance and complex cosine used in the main context with different choices
470"
REFERENCES,0.765661252900232,"of r1 = [0.2, 0.4, 0.6, 0.8]. We use the default hyper-parameter set up, choosing α = 0.5 and r = 0.1.
471"
REFERENCES,0.7668213457076566,Under review as a conference paper at ICLR 2022
REFERENCES,0.7679814385150812,"0.0
0.2
0.4
0.6
0.8
1.0
l1 0 2 4 6 8 l2"
REFERENCES,0.7691415313225058,weighted distance
REFERENCES,0.7703016241299304,"Pareto Front
PNG
Target"
REFERENCES,0.771461716937355,"0.0
0.2
0.4
0.6
0.8
1.0
l1 0 2 4 6 8 l2"
REFERENCES,0.7726218097447796,complex cosine
REFERENCES,0.7737819025522041,"Pareto Front
PNG
Target"
REFERENCES,0.7749419953596288,"Figure 2: Trajectories of solving OPT-in-Pareto with weighted distance and complex cosine as criterion using
PNG. The green dots are the ﬁnal converged models. PNG is able to successfully locate the correct models in
the Pareto set."
REFERENCES,0.7761020881670534,"For complex cosine, we use MGD updating for the ﬁrst 150 iterations. Figure 2 shows the trajectories,
472"
REFERENCES,0.777262180974478,"demonstrating that PNG works pretty well for the more challenging ZDT2-Variant tasks.
473"
REFERENCES,0.7784222737819025,"C.1.3
GENERAL CRITERIA: THREE-TASK LEARNING ON THE NYUV2 DATASET
474"
REFERENCES,0.7795823665893271,"We show that PNG is able to handle large-scale multitask learning problems by deploying it on a three-
475"
REFERENCES,0.7807424593967517,"task learning problem (segmentation, depth estimation, and surface normal prediction) on NYUv2 dataset
476"
REFERENCES,0.7819025522041764,"(Silberman et al., 2012). The main goal of this experiment is to show that: 1. PNG is able to handle
477"
REFERENCES,0.7830626450116009,"OPT-in-Pareto in a large-scale neural network; 2. With a proper design of criteria, PNG enables to do
478"
REFERENCES,0.7842227378190255,"targeted ﬁne-tuning that pushes the model to move towards a certain direction. We consider the same
479"
REFERENCES,0.7853828306264501,"training protocol as Liu et al. (2019) and use the MTAN network architecture. Start with a model trained
480"
REFERENCES,0.7865429234338747,"with equally weighted linear scalarization and our goal is to further improve the model’s performance
481"
REFERENCES,0.7877030162412993,"on segmentation and surface normal estimation while allowing some sacriﬁce on depth estimation. This
482"
REFERENCES,0.7888631090487239,"can be achieved by many different choices of criterion and in this experiment, we consider the following
483"
REFERENCES,0.7900232018561485,"design: F(θ) = (ℓseg(θ) × ℓsurface(θ))/(0.001 + ℓdepth(θ)). Here ℓseg, ℓsurface and ℓdepth are the loss functions
484"
REFERENCES,0.7911832946635731,"for segmentation, surface normal prediction and depth estimation, respectively. The constant 0.001 in the
485"
REFERENCES,0.7923433874709976,"denominator is for numeric stability. We point out that our design of criterion is a simple heuristic and might
486"
REFERENCES,0.7935034802784223,"not be an optimal choice and the key question we study here is to verify the functionality of the proposed
487"
REFERENCES,0.7946635730858469,"PNG. As suggested by the open-source repository of Liu et al. (2019), we reproduce the result based on the
488"
REFERENCES,0.7958236658932715,"provided conﬁguration. To show that PNG is able to move the model along the Pareto front, we show the
489"
REFERENCES,0.796983758700696,"evolution of the criterion function and the norm of the MGD gradient during the training in Figure 3. As we
490"
REFERENCES,0.7981438515081206,"can see, PNG effectively decreases the value of criterion function while the norm of MGD gradient remains
491"
REFERENCES,0.7993039443155452,"the same. This demonstrates that PNG is able to minimize the criterion by searching the model in the Pareto
492"
REFERENCES,0.8004640371229699,"set. Table 3 compares the performances on the three tasks using standard training and PNG, showing that
493"
REFERENCES,0.8016241299303944,"PNG is able to improve the model’s performance on segmentation and surface normal prediction tasks while
494"
REFERENCES,0.802784222737819,"satisfying a bit of the performance in depth estimation based on the criterion.
495"
REFERENCES,0.8039443155452436,"C.2
FINDING DIVERSE PARETO MODELS
496"
REFERENCES,0.8051044083526682,"C.2.1
EXPERIMENT DETAILS
497"
REFERENCES,0.8062645011600929,Under review as a conference paper at ICLR 2022
REFERENCES,0.8074245939675174,Algorithm
REFERENCES,0.808584686774942,"Segmentation
Depth
Surface Normal"
REFERENCES,0.8097447795823666,"(Higher Better)
(Lower Better)
Angle Distance
(Lower Better)
Within t◦"
REFERENCES,0.8109048723897911,"mIoU
Pix Acc
Abs Err
Rel Err
Mean
Median
11.25
22.5
30
Standard
27.09
56.36
0.6143
0.2618
31.46
27.37
19.51
41.71
54.61
PNG
28.23
56.66
0.6161
0.2632
31.06
26.50
21.06
43.41
55.93"
REFERENCES,0.8120649651972158,"Table 3: Comparing the multitask performance of standard training using linear scalarization with equally
weighted losses and the targeted ﬁne-tuning based on PNG."
REFERENCES,0.8132250580046404,Itertions
REFERENCES,0.814385150812065,Values
REFERENCES,0.8155452436194895,"Criterion
Norm of MGD Grad"
REFERENCES,0.8167053364269141,"Figure 3: The evolution of Criterion F and the norm
of MGD gradient when trained using PNG on NYUv2
dataset with MTAN network. PNG effectively de-
creases the criterion while ensuring the model is within
the Pareto set, since the norm of MGD gradient remains
unchanged."
REFERENCES,0.8178654292343387,"We train the model for 100 epochs using Adam op-
498"
REFERENCES,0.8190255220417634,"timizer with batch size 256 and 0.001 learning rate.
499"
REFERENCES,0.820185614849188,"To encourage diversity of the models, following the
500"
REFERENCES,0.8213457076566125,"setting in Mahapatra & Rajan (2020), we use equally
501"
REFERENCES,0.8225058004640371,"distributed preference vectors for linear scalarization
502"
REFERENCES,0.8236658932714617,"and EPO. Note that the stochasticity of using mini-
503"
REFERENCES,0.8248259860788864,"batches is able to improve the performance of Pareto
504"
REFERENCES,0.8259860788863109,"approximation for free by also using the intermedi-
505"
REFERENCES,0.8271461716937355,"ate checkpoints to approximate P. To fully exploit
506"
REFERENCES,0.8283062645011601,"this advantage, for all the methods, we collect check-
507"
REFERENCES,0.8294663573085846,"points every epoch to approximate P, starting from
508"
REFERENCES,0.8306264501160093,"epoch 60.
509"
REFERENCES,0.8317865429234339,"C.2.2
EVALUATION METRIC DETAILS
510"
REFERENCES,0.8329466357308585,"We introduce the deﬁnition of the used metric for
511"
REFERENCES,0.834106728538283,"evaluation. Given a set ˆP = {θ1, . . . , θN} that we
512"
REFERENCES,0.8352668213457076,"use to approximate P, its IGD+ score is deﬁned as:
513"
REFERENCES,0.8364269141531323,"IGD+( ˆP) =
Z"
REFERENCES,0.8375870069605569,"P∗q(θ, ˆP)dµ(θ),
q(θ, ˆP) = min
ˆθ∈ˆ
P"
REFERENCES,0.8387470997679815,"
ℓ(ˆθ) −ℓ(θ)
 + ,"
REFERENCES,0.839907192575406,"where µ is some base measure that measures the importance of θ ∈P and (t)+ := max(t, 0), applied on
514"
REFERENCES,0.8410672853828306,"each element of a vector. Intuitively, for each θ, we ﬁnd a nearest ˆθ ∈ˆP that approximates θ best. Here
515"
REFERENCES,0.8422273781902552,"the (·)+ is applied as we only care the tasks that ˆθ is worse than θ. In practice, a common choice of µ can
516"
REFERENCES,0.8433874709976799,"be a uniform counting measure with uniformly sampled (or selected) models from P. In our experiments,
517"
REFERENCES,0.8445475638051044,"since we can not sample models from P, we approximate P by combining ˆP from all the methods, i.e.,
518"
REFERENCES,0.845707656612529,"P ≈∪m∈{Linear,MGD,EPO,PNG} ˆPm, where ˆPm is the approximation set produced by algorithm m.
519"
REFERENCES,0.8468677494199536,"This approximation might not be accurate but is sufﬁcient to compare the different methods,
520"
REFERENCES,0.8480278422273781,"The Hypervolume score of ˆP, w.r.t. a reference point ℓr ∈Rm
+, is deﬁned as
521"
REFERENCES,0.8491879350348028,"HV( ˆP) = µ
n
ℓ= [ℓ1, ..., ℓm] ∈Rm | ∃θ ∈ˆP, s.t. ℓt(θ) ≤ℓt ≤ℓr
t ∀t ∈[m]
o
,"
REFERENCES,0.8503480278422274,"where µ is again some measure. We use ℓr = [0.6, 0.6] for calculating the Hypervolume based on loss and
522"
REFERENCES,0.851508120649652,"set µ to be the common Lebesgue measure. Here we choose 0.6 as we observe that the losses of the two tasks
523"
REFERENCES,0.8526682134570766,"are higher than 0.6 and 0.6 is roughly the worst case. When calculating Hypervolume based on accuracy, we
524"
REFERENCES,0.8538283062645011,"simply ﬂip the sign.
525"
REFERENCES,0.8549883990719258,Under review as a conference paper at ICLR 2022
REFERENCES,0.8561484918793504,"Loss
Acc
Hv↑(10−2)
IGD↓(10−2)
Hv↑(10−2)
IGD↓(10−2)"
REFERENCES,0.857308584686775,γ = 0.1
REFERENCES,0.8584686774941995,"α = 0.25
7.89 ± 0.11
0.041 ± 0.012
9.39 ± 0.038
0.0056 ± 0.002
α = 0.5
7.86 ± 0.12
0.043 ± 0.012
9.39 ± 0.038
0.0056 ± 0.002
α = 0.75
7.84 ± 0.11
0.045 ± 0.013
9.38 ± 0.037
0.0057 ± 0.002"
REFERENCES,0.8596287703016241,α = 0.5
REFERENCES,0.8607888631090487,"γ = 0.01
7.86 ± 0.12
0.042 ± 0.012
9.39 ± 0.038
0.0056 ± 0.002
γ = 0.1
7.86 ± 0.12
0.043 ± 0.012
9.39 ± 0.038
0.0056 ± 0.002
γ = 0.25
7.85 ± 0.11
0.042 ± 0.012
9.39 ± 0.036
0.0056 ± 0.002"
REFERENCES,0.8619489559164734,Table 4: Ablation study based on Multi-Mnist dataset with different choice of α and γ.
REFERENCES,0.8631090487238979,"C.2.3
ABLATION STUDY
526"
REFERENCES,0.8642691415313225,"We conduct ablation study to understand the effect of α and γ using the Pareto approximation task on
527"
REFERENCES,0.8654292343387471,"Multi-Mnist. We compare PNG with α = 0.25, 0.5, 0.75 and γ = 0.01, 0.1, 0.25. Figure 4 summarizes the
528"
REFERENCES,0.8665893271461717,"result. Overall, we observe that PNG is not sensitive to the choice of hyper-parameter.
529"
REFERENCES,0.8677494199535963,"C.2.4
COMPARING WITH THE SECOND ORDER APPROACH
530"
REFERENCES,0.8689095127610209,"We give a discussion on comparing our approach with the second order approaches proposed by Ma et al.
531"
REFERENCES,0.8700696055684455,"(2020). In terms of algorithm, Ma et al. (2020) is a local expansion approach. To apply Ma et al. (2020),
532"
REFERENCES,0.87122969837587,"in the ﬁrst stage, we need to start with several well distributed models (i.e., the ones obtained by linear
533"
REFERENCES,0.8723897911832946,"scalarization with different preference weights) and Ma et al. (2020) is only applied in the second stage to
534"
REFERENCES,0.8735498839907193,"ﬁnd the neighborhood of each model. The performance gain comes from the local neighbor search of each
535"
REFERENCES,0.8747099767981439,"model (i.e. the second stage).
536"
REFERENCES,0.8758700696055685,"In comparison, PNG with energy distance is a global search approach. It improves the well-distributedness
537"
REFERENCES,0.877030162412993,"of models in the ﬁrst stage (i.e. it’s a better approach than simply using linear scalarization with different
538"
REFERENCES,0.8781902552204176,"weights). And thus the performance gain comes from the ﬁrst stage. Notice that we can also apply Ma et al.
539"
REFERENCES,0.8793503480278422,"(2020) to PNG with energy distance to add extra local search to further improve the approximation.
540"
REFERENCES,0.8805104408352669,"In terms of run time comparison. We compare the wall clock run time of each step of updating the 5 models
541"
REFERENCES,0.8816705336426914,"using PNG and the second order approach in Ma et al. (2020). We calculate the run time based on the
542"
REFERENCES,0.882830626450116,"multi-MNIST dataset using the average of 100 steps. PNG uses 0.3s for each step while Ma et al. 2020 uses
543"
REFERENCES,0.8839907192575406,"16.8s. PNG is 56x faster than the second order approach. And we further argue that, based on time complexity
544"
REFERENCES,0.8851508120649652,"theory, the gap will be even larger when the size of the network increases.
545"
REFERENCES,0.8863109048723898,"C.3
UNDERSTANDING PNG DYNAMICS
546"
REFERENCES,0.8874709976798144,"We draw more analysis to understand the training dynamics of PNG.
547"
REFERENCES,0.888631090487239,"Different Staring Points
We give analysis on PNG with different initializations showing that PNG is
548"
REFERENCES,0.8897911832946636,"more robust to the initialization than other approaches such as Lin et al. (2019). We consider the Pareto set
549"
REFERENCES,0.8909512761020881,"approximation tasks and reuse synthetic example introduced in Section 5.1. We consider learning 5 models to
550"
REFERENCES,0.8921113689095128,"approximate the Pareto front staring from two different bad starting points. Speciﬁcally, in the upper row of
551"
REFERENCES,0.8932714617169374,"Figure 4, we consider initializing the models using linear scalarization. Due to the concavity of the Pareto
552"
REFERENCES,0.894431554524362,"front, linear scalarization can only learns models at the two extreme end of the Pareto front. The second row
553"
REFERENCES,0.8955916473317865,"uses MGD for initialization and the models is scattered at an small region of the Pareto front. Different from
554"
REFERENCES,0.8967517401392111,"the algorithm proposed by Lin et al. (2019) which relies on a good initialization, using the proposed energy
555"
REFERENCES,0.8979118329466357,Under review as a conference paper at ICLR 2022
REFERENCES,0.8990719257540604,"0.0
0.2
0.4
0.6
0.8
1.0
l1 0.0 0.2 0.4 0.6 0.8 1.0 l2"
REFERENCES,0.9002320185614849,"Pareto Front
Models"
REFERENCES,0.9013921113689095,"0.0
0.2
0.4
0.6
0.8
1.0
l1 0.0 0.2 0.4 0.6 0.8 1.0 l2"
REFERENCES,0.9025522041763341,"0.0
0.2
0.4
0.6
0.8
1.0
l1 0.0 0.2 0.4 0.6 0.8 1.0 l2"
REFERENCES,0.9037122969837587,"0.0
0.2
0.4
0.6
0.8
1.0
l1 0.0 0.2 0.4 0.6 0.8 1.0 l2"
REFERENCES,0.9048723897911833,"0.0
0.2
0.4
0.6
0.8
1.0 l1 0.0 0.2 0.4 0.6 0.8 1.0 l2"
REFERENCES,0.9060324825986079,"0.0
0.2
0.4
0.6
0.8
1.0 l1 0.0 0.2 0.4 0.6 0.8 1.0 l2"
REFERENCES,0.9071925754060325,"0.0
0.2
0.4
0.6
0.8
1.0 l1 0.0 0.2 0.4 0.6 0.8 1.0 l2"
REFERENCES,0.9083526682134571,"0.0
0.2
0.4
0.6
0.8
1.0
l1 0.0 0.2 0.4 0.6 0.8 1.0 l2"
REFERENCES,0.9095127610208816,"Figure 4: Evolution of models from different initialization. Upper row uses initialization with linear
scalarization and lower row uses initialization from MDG. From left to right: the evolution of models during
training. PNG is robust to initializations. In both two cases of very poor initialization, PNG is still able to
move the models so that they are eventually well distributed on the Pareto set."
REFERENCES,0.9106728538283063,"distance function, PNG pushes the models to be equally distributed on the Pareto Front without the need of
556"
REFERENCES,0.9118329466357309,"any prior information of the Pareto front even with extremely bad starting point.
557"
REFERENCES,0.9129930394431555,"Trajectory Visualization with Different Hyper-parameters
We also give more visualization on the PNG
558"
REFERENCES,0.91415313225058,"trajectory when using different hyper-parameters. We reuse synthetic example introduced in Section 5.1
559"
REFERENCES,0.9153132250580046,"for studying the hyper-parameters α and γ. We ﬁx α = 0.25 and vary γ = 0.1, 0.05, 0.01, 0.1; and ﬁx
560"
REFERENCES,0.9164733178654292,"γ = 0.01 and vary α = 0.1, 0.25, 0.5, 0.75. Figure 5 plots the trajectories. As we can see, when γ is properly
561"
REFERENCES,0.9176334106728539,"chosen, with different α, PNG ﬁnds the correct models with different trajectories. Different α determines the
562"
REFERENCES,0.9187935034802784,"algorithm’s behavior of balancing the descent of task losses or criterion objectives. On the other hand, with
563"
REFERENCES,0.919953596287703,"too large γ, the algorithm fails to ﬁnd a model that is close to P∗, which is expected.
564"
REFERENCES,0.9211136890951276,"C.4
IMPROVING MULTITASK BASED DOMAIN GENERALIZATION
565"
REFERENCES,0.9222737819025522,"We argue that many other deep learning problems also have the structure of multitask learning when multiple
566"
REFERENCES,0.9234338747099768,"losses presents and thus optimization techniques in multitask learning can also be applied to those domains.
567"
REFERENCES,0.9245939675174014,"In this paper we consider the JiGen (Carlucci et al., 2019b). JiGen learns a model that can be generalized to
568"
REFERENCES,0.925754060324826,"unseen domain by minimizing a standard cross-entropy loss ℓclass for classiﬁcation and an unsupervised loss
569"
REFERENCES,0.9269141531322506,"ℓjig based on Jigsaw Puzzles:
570"
REFERENCES,0.9280742459396751,ℓ(θ) = (1 −ω)ℓclass(θ) + ωℓjig(θ).
REFERENCES,0.9292343387470998,"The ratio between two losses, i.e. ω, is important to the ﬁnal performance of the model and requires a
571"
REFERENCES,0.9303944315545244,"careful grid search. Notice that JiGen is essentially searching for a model on the Pareto front using the linear
572"
REFERENCES,0.931554524361949,"scalarization. Instead of using a ﬁxed linear scalarization to learn a model, one natural questions is that
573"
REFERENCES,0.9327146171693735,Under review as a conference paper at ICLR 2022
REFERENCES,0.9338747099767981,"0.0
0.2
0.4
0.6
0.8
1.0
l1 0.0 0.2 0.4 0.6 0.8 1.0 l2"
REFERENCES,0.9350348027842227,task preference
REFERENCES,0.9361948955916474,"Pareto Front
PNG"
REFERENCES,0.9373549883990719,"0.0
0.2
0.4
0.6
0.8
1.0
l1 0.0 0.2 0.4 0.6 0.8 1.0 l2"
REFERENCES,0.9385150812064965,task preference
REFERENCES,0.9396751740139211,"0.0
0.2
0.4
0.6
0.8
1.0
l1 0.0 0.2 0.4 0.6 0.8 1.0 l2"
REFERENCES,0.9408352668213457,task preference
REFERENCES,0.9419953596287703,"0.0
0.2
0.4
0.6
0.8
1.0
l1 0.0 0.2 0.4 0.6 0.8 1.0 l2"
REFERENCES,0.9431554524361949,task preference
REFERENCES,0.9443155452436195,"0.0
0.2
0.4
0.6
0.8
1.0
l1 0.0 0.2 0.4 0.6 0.8 1.0 l2"
REFERENCES,0.9454756380510441,task preference
REFERENCES,0.9466357308584686,"0.0
0.2
0.4
0.6
0.8
1.0
l1 0.0 0.2 0.4 0.6 0.8 1.0 l2"
REFERENCES,0.9477958236658933,task preference
REFERENCES,0.9489559164733179,"0.0
0.2
0.4
0.6
0.8
1.0
l1 0.0 0.2 0.4 0.6 0.8 1.0 l2"
REFERENCES,0.9501160092807425,task preference
REFERENCES,0.951276102088167,"0.0
0.2
0.4
0.6
0.8
1.0
l1 0.0 0.2 0.4 0.6 0.8 1.0 l2"
REFERENCES,0.9524361948955916,task preference
REFERENCES,0.9535962877030162,"Figure 5: Ablation study on OPT-in-Pareto with different ratio constraint of objectives. Upper row, from
left to right: ﬁxing α = 0.25, γ = 0.1, 0.05, 0.01, 0.001; Lower row, from left to right: ﬁxing γ = 0.01,
α = 0.1, 0.25, 0.5, 0.75. By comparing the ﬁgures in the ﬁrst row, we ﬁnd that choosing a too large γ make
the ﬁnal converged model be far away from the Pareto set, which is as expected. By comparing the ﬁgures in
the second row, we ﬁnd that changing α make PNG give different priority in making Pareto improvement or
descent on F. When α is larger (the right ﬁgures), PNG will ﬁrst move the model to Pareto set and start to
decrease F after that."
REFERENCES,0.9547563805104409,Under review as a conference paper at ICLR 2022
REFERENCES,0.9559164733178654,"whether it is possible to design a mechanism that dynamically adjusts the ratio of the losses so that we can
574"
REFERENCES,0.95707656612529,"achieve to learn a better model.
575"
REFERENCES,0.9582366589327146,"We give a case study here. Motivated by the adversarial feature learning (Ganin et al., 2016), we propose
576"
REFERENCES,0.9593967517401392,"to improve JiGen such that the latent feature representations of the two tasks are well aligned. Speciﬁcally,
577"
REFERENCES,0.9605568445475638,"suppose that Φclass(θ) = {φclass(xi, θ)}n
i=1 and Φjig(θ) = {φjig(xi, θ)}n
i=1 is the distribution of latent feature
578"
REFERENCES,0.9617169373549884,"representation of the two tasks, where xi is the i-th training data. We consider FPD as some probability metric
579"
REFERENCES,0.962877030162413,"that measures the distance between two distributions, we consider the following problem:
580"
REFERENCES,0.9640371229698376,"min
θ∈P∗FPD[Φclass(θ), Φjig(θ)]."
REFERENCES,0.9651972157772621,"With PD as the criterion function, our algorithm automatically reweights the ratio of the two tasks such that
581"
REFERENCES,0.9663573085846868,"their latent space is well aligned.
582"
REFERENCES,0.9675174013921114,"Setup We ﬁx all the experiment setting the same as Carlucci et al. (2019b). We use the Alexnet and Resnet-18
583"
REFERENCES,0.968677494199536,"with multihead pretrained on ImageNet as the multitask network. We evaluate the methods on PACS (Li et al.,
584"
REFERENCES,0.9698375870069605,"2017), which covers 7 object categories and 4 domains (Photo, Art Paintings, Cartoon and Sketches). Same to
585"
REFERENCES,0.9709976798143851,"Carlucci et al. (2019b), we trained our model considering three domains as source datasets and the remaining
586"
REFERENCES,0.9721577726218097,"one as target. We implement FPD that measures the discrepancy of the feature space of the two tasks using
587"
REFERENCES,0.9733178654292344,"the idea of Domain Adversarial Neural Networks (Ganin & Lempitsky, 2015) by adding an extra prediction
588"
REFERENCES,0.974477958236659,"head on the shared feature space to predict the whether the input is for the classiﬁcation task or Jigsaw task.
589"
REFERENCES,0.9756380510440835,"Speciﬁcally, we add an extra linear layer on the shared latent feature representations that is trained to predict
590"
REFERENCES,0.9767981438515081,"the task that the latent space belongs to, i.e.,
591"
REFERENCES,0.9779582366589327,"FPD(Φclass(θ), Φjig(θ)) = min
w,b
1
n n
X"
REFERENCES,0.9791183294663574,"i=1
log(σ(w⊤φclass(xi, θ))) + log(1 −σ(w⊤φclass(xi, θ)))."
REFERENCES,0.9802784222737819,"Notice that the optimal weight and bias for the linear layer depends on the model parameter θ, during the
592"
REFERENCES,0.9814385150812065,"training, both w, b and θ are jointly updated using stochastic gradient descent. We follow the default training
593"
REFERENCES,0.9825986078886311,"protocol provided by the source code of Carlucci et al. (2019b).
594"
REFERENCES,0.9837587006960556,"Baselines Our main baselines are JiGen (Carlucci et al., 2019b); JiGen + adv, which adds an extra domain
595"
REFERENCES,0.9849187935034803,"adversarial loss on JiGen; and our PNG with domain adversarial loss as criterion function. In order to run
596"
REFERENCES,0.9860788863109049,"statistical test for comparing the methods, we run all the main baselines using 3 random trials. We use the
597"
REFERENCES,0.9872389791183295,"released source code by Carlucci et al. (2019b) to obtained the performance of JiGen. For JiGen+adv, we use
598"
REFERENCES,0.988399071925754,"an extra run to tune the weight for the domain adversarial loss. Besides the main baselines, we also includes
599"
REFERENCES,0.9895591647331786,"TF (Li et al., 2017), CIDDG (Li et al., 2018b), MLDG (Li et al., 2018a) , D-SAM (D’Innocente & Caputo,
600"
REFERENCES,0.9907192575406032,"2018) and DeepAll (Carlucci et al., 2019b) as baselines with the author reported performance for reference.
601"
REFERENCES,0.9918793503480279,"Result The result is summarized in Table 5 with bolded value indicating the statistical signiﬁcant best methods
602"
REFERENCES,0.9930394431554525,"with p-value based on matched-pair t-test less than 0.1. Combining Jigen and PNG to dynamically reweight
603"
REFERENCES,0.994199535962877,"the task weights is able to implicitly regularizes the latent space without adding an actual regularizer which
604"
REFERENCES,0.9953596287703016,"might hurt the performance on the tasks and thus improves the overall result.
605"
REFERENCES,0.9965197215777262,Under review as a conference paper at ICLR 2022
REFERENCES,0.9976798143851509,"Method
Art paint
Cartoon
Sketches
Photo
Avg
AlexNet
TF
0.6268
0.6697
0.5751
0.8950
0.6921
CIDDG
0.6270
0.6973
0.6445
0.7865
0.6888
MLDG
0.6623
0.6688
0.5896
0.8800
0.7001
D-SAM
0.6387
0.7070
0.6466
0.8555
0.7120
DeepAll
0.6668
0.6941
0.6002
0.8998
0.7152
JiGen
0.6855 ± 0.004
0.6889±0.002
0.6831±0.011
0.8946 ± 0.008
0.7380 ± 0.002
JiGen + adv
0.6857 ± 0.004
0.6837 ± 0.003
0.6753 ± 0.008
0.8980 ± 0.001
0.7357 ± 0.003
Jigen + PNG
0.6914±0.005
0.6903±0.002
0.6855±0.007
0.9044±0.003
0.7429±0.002
ResNet-18
D-SAM
0.7733
0.7243
0.7783
0.9530
0.8072
DeepAll
0.7785
0.7486
0.6774
0.9573
0.7905
JiGen
0.8009 ± 0.004
0.7363 ± 0.007
0.7046 ± 0.013
0.9629±0.002
0.8012 ± 0.002
JiGen + adv
0.7923 ± 0.006
0.7402 ± 0.004
0.7188 ± 0.005
0.9617 ± 0.001
0.8033 ± 0.001
JiGen + PNG
0.8014±0.005
0.7538±0.001
0.7222±0.006
0.9627±0.002
0.8100±0.005"
REFERENCES,0.9988399071925754,"Table 5: Comparing different algorithms for domain generalization using dataset PACS and two network
architectures."
