Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.002145922746781116,"Current deep learning models for dynamics forecasting struggle with generalization.
They can only forecast in a speciÔ¨Åc domain and fail when applied to systems
with different parameters, external forces, or boundary conditions. We propose
a model-based meta-learning method called DyAd which can generalize across
heterogeneous domains by partitioning them into different tasks. DyAd has two
parts: an encoder which infers the time-invariant hidden features of the task with
weak supervision, and a forecaster which learns the shared dynamics of the entire
domain. The encoder adapts and controls the forecaster during inference using
adaptive instance normalization and adaptive padding. Theoretically, we prove
that the generalization error of such procedure is related to the task relatedness
in the source domain, as well as the domain differences between source and
target. Experimentally, we demonstrate that our model outperforms state-of-the-art
approaches on both turbulent Ô¨Çow and real-world ocean data forecasting tasks."
INTRODUCTION,0.004291845493562232,"1
INTRODUCTION"
INTRODUCTION,0.006437768240343348,"Modeling dynamical systems with deep learning has shown great success in a wide range of systems
from Ô¨Çuid mechanics to neural dynamics (Tompson et al., 2017; Chen et al., 2018; Kolter & Manek,
2019; Zoltowski et al., 2020; Li et al., 2021). However, the main limitation of previous works is
very limited generalizability. Most approaches only focus on a speciÔ¨Åc system and train on past data
in order to predict the future. Thus a new model must be trained to predict a system with different
dynamics. Consider, for example, learning Ô¨Çuid dynamics; shown in Fig. 1are two Ô¨Çuid Ô¨Çows with
different degrees of turbulence. Even though the Ô¨Çows are governed by the same equations, the
difference in buoyant forces would require two separate deep learning models to forecast. Therefore,
it is imperative to develop generalizable deep learning models for dynamical systems that can learn
and predict well over a large heterogeneous domain. ... ... time ?"
INTRODUCTION,0.008583690987124463,"Figure 1: Meta-learning dynamic forecasting on
turbulent Ô¨Çow. The model needs to generalize to a
Ô¨Çow with a very different buoyant force."
INTRODUCTION,0.01072961373390558,"Meta-learning (Thrun & Pratt, 1998; Baxter,
1998; Finn et al., 2017), or learning to learn,
improves generalization by learning multiple
tasks from the environment. Recent develop-
ments in meta-learning have been successfully
applied to few-shot classiÔ¨Åcation (Munkhdalai
& Yu, 2017), active learning (Yoon et al., 2018),
and reinforcement learning (Gupta et al., 2018).
However, meta-learning in the context of fore-
casting high-dimensional physical dynamics has
not been studied before. The challenges with
meta-learning dynamical systems are unique in
that (1) we need to efÔ¨Åciently infer the latent
representation of the dynamical system given observed time series data, (2) we need to account
for changes in unknown initial and boundary conditions, and (3) we need to model the temporal
dynamics across heterogeneous domains."
INTRODUCTION,0.012875536480686695,"Our approach is inspired by the fact that similar dynamical systems may share time-invariant hidden
features. Even the slightest change in these features may lead to vastly different phenomena. For
example, in climate science, Ô¨Çuids are governed by a set of differential equations called Navier-"
INTRODUCTION,0.015021459227467811,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.017167381974248927,"Stokes equations. Some features such as kinematic viscosity and external forces (e.g. gravity), are
time-invariant and determine the Ô¨Çow characteristics. By inferring this latent representation, we can
model diverse system behaviors from smoothly Ô¨Çowing water to atmospheric turbulence."
INTRODUCTION,0.019313304721030045,"Inspired by neural style transfer (Karras et al., 2019), we propose a model-based meta-learning
method, called DyAd, which can rapidly adapt to systems with varying dynamics. DyAd has two
parts, an encoder g and a forecaster f. The encoder maps different dynamical systems to time-
invariant hidden features representing constants of motion, boundary conditions, and external forces
which characterize the system. The forecaster f then takes the hidden representations and the past
system states to forecast the future system state. Controlled by the time-invariant hidden features, the
forecaster has the Ô¨Çexibility to adapt to a wide range of systems with heterogeneous dynamics."
INTRODUCTION,0.02145922746781116,"Unlike gradient-based meta-learning techniques such as MAML (Finn et al., 2017), DyAd auto-
matically adapts during inference using an encoder and does not require any retraining. Similar
to model-based meta-learning methods such as MetaNets (Munkhdalai & Yu, 2017), we employ a
two-part design with an adaptable learner which receives task-speciÔ¨Åc weights. However, for time
series forecasting, since input and output come from the same domain, a support set of labeled data is
unnecessary to deÔ¨Åne the task. The encoder can infer the task directly from query input."
INTRODUCTION,0.023605150214592276,Our contributions include:
INTRODUCTION,0.02575107296137339,"‚Ä¢ A novel model-based meta-learning method (DyAd) for dynamic forecasting in large hetero-
geneous domains.
‚Ä¢ An encoder capable of extracting the time-invariant hidden features of a dynamical system
using time-shift invariant model structure and weak supervision.
‚Ä¢ A new adaptive padding layer (AdaPad), designed for adapting to boundary conditions.
‚Ä¢ Theoretical guarantees for DyAd on the generalization error of task inference in the source
domain as well as domain adaptation to the target domain.
‚Ä¢ Improved generalization performance on heterogeneous domains such as Ô¨Çuid Ô¨Çow and sea
temperature forecasting, even to new tasks outside the training distribution."
METHODS,0.027896995708154508,"2
METHODS"
META-LEARNING IN DYNAMICS FORECASTING,0.030042918454935622,"2.1
META-LEARNING IN DYNAMICS FORECASTING"
META-LEARNING IN DYNAMICS FORECASTING,0.032188841201716736,"Let x ‚ààRd be a d-dimensional state of a dynamical system governed by parameters œà. The problem
of dynamics forecasting is that given a sequence of past states (xt‚àíl+1, . . . , xt), we want to learn a
map f such that:
f : (xt‚àíl+1, . . . , xt) 7‚àí‚Üí(xt+1, . . . xt+h).
(1)
Here l is the length of the input series, and h is the forecasting horizon in the output."
META-LEARNING IN DYNAMICS FORECASTING,0.034334763948497854,"Existing approaches for dynamics forecasting only predict future data for a speciÔ¨Åc system as a
single task. Here a task refers to forecasting for a speciÔ¨Åc system with a given set of parameters. The
resulting models often generalize poorly to different system dynamics. Thus a new model must be
trained to predict for each speciÔ¨Åc system."
META-LEARNING IN DYNAMICS FORECASTING,0.03648068669527897,"To perform meta-learning, we identify each forecasting task by some parameters c ‚äÇœà, such as
constants of motion, external forces, and boundary conditions. We learn multiple tasks simultaneously
and infer the task from data. Here we use c for a subset of system parameters œà, because we usually
do not have the full knowledge of the system dynamics. In the turbulent Ô¨Çow example, the state xt is
the velocity Ô¨Åeld at time t. Parameters c can represent Reynolds number, average vorticity, average
magnitude, or a vector of all three."
META-LEARNING IN DYNAMICS FORECASTING,0.03862660944206009,"Formally, let ¬µ be the data distribution over X √ó Y representing the function f : X ‚ÜíY where
X = Rd√ól and Y = Rd√óh. Our main assumption is that the domain X can be partitioned into
separate tasks X = ‚à™c‚ààCXc, where Xc is the domain for task c and C is the set of all tasks. The data
in the same task share the same set of parameters. Let ¬µc be the conditional distribution over Xc √ó Y
for task c."
META-LEARNING IN DYNAMICS FORECASTING,0.0407725321888412,"During training, the model is presented with data drawn from a subset of tasks {(x, y) : (x, y) ‚àº
¬µc, c ‚àºC}. Our goal is to learn the function f : X ‚ÜíY over the whole domain X which can thus"
META-LEARNING IN DYNAMICS FORECASTING,0.04291845493562232,Under review as a conference paper at ICLR 2022
META-LEARNING IN DYNAMICS FORECASTING,0.045064377682403435,"Figure 2: Overview of DyAd applied to two inputs of Ô¨Çuid turbulence, one with small external forcing
and one with larger external forces. The encoder infers the time-shift invariant characteristic variable
z which is used to adapt the forecaster network."
META-LEARNING IN DYNAMICS FORECASTING,0.04721030042918455,"generalize across all tasks c ‚ààC. To do so, we need to learn the map g: X ‚ÜíC taking x ‚ààXc to c
in order to infer the task with minimal supervision."
META-LEARNING IN DYNAMICS FORECASTING,0.04935622317596566,"2.2
DYAD: DYNAMIC ADAPTATION NETWORK"
META-LEARNING IN DYNAMICS FORECASTING,0.05150214592274678,"We propose a model-based meta-learning approach for dynamics forecasting. Given multiple fore-
casting tasks, we propose to learn the function f in two stages, that is, by Ô¨Årst inferring the task c
from the input x, and then adapting to a specialized forecaster fc : Xc ‚ÜíY for each task."
META-LEARNING IN DYNAMICS FORECASTING,0.0536480686695279,"An alternative is to use a single deep neural network to directly model f in one step over the whole
domain. But this requires the training set to have good and uniform coverage of the different tasks. If
the data distribution ¬µ is highly heterogeneous or the training set is not sampled i.i.d. from the whole
domain, then a single model may struggle with generalization."
META-LEARNING IN DYNAMICS FORECASTING,0.055793991416309016,"We hypothesize that by partitioning the domain into different tasks, the model would learn to pick
up task-speciÔ¨Åc features without requiring uniform coverage of the training data. Furthermore, by
separating task inference and forecasting into two stages, we allow the forecaster to rapidly adapt to
new tasks that never appeared in the training set."
META-LEARNING IN DYNAMICS FORECASTING,0.05793991416309013,"As shown in Fig. 2, our model consists of two parts: an encoder g and a forecaster f. We introduce
zc as a time-invariant hidden feature for task c. We assume that c depends linearly on the hidden
feature for simplicity and easy interpretation. We design the encoder to infer the hidden feature zc
given the input x. We then use zc to adapt the forecaster f to the speciÔ¨Åc task, i.e., model y = fc(x)
as y = f(x, zc). As the system dynamics are encoded in the input sequence x, we can feed the same
input sequence x to a forecaster and generate predictions ÀÜy = fc(x)."
ENCODER NETWORK,0.060085836909871244,"2.3
ENCODER NETWORK"
ENCODER NETWORK,0.06223175965665236,"The encoder maps the input x to the hidden features zc that are time-invariant. To enforce this
inductive bias, we encode time-invariance both in the architecture and in the training objective."
ENCODER NETWORK,0.06437768240343347,"Time-Invariant Encoder. The encoder is implemented using 4 Conv 3D layers, each followed by
BatchNorm, LeakyReLU, and max-pooling. Note that theoretically, max-pooling is not perfectly
shift invariant since 2x2x2 max-pooling is equivariant to shifts of size 2 and only approximately
invariant to shifts of size 1. But standard convolutional architectures often include max-pooling layers
to boost performance. We convolve across spatial and temporal dimensions."
ENCODER NETWORK,0.06652360515021459,"After that, we use a global mean-pooling layer and a fully connected layer to estimate the hidden
feature ÀÜzc. The task parameter depends linearly on the hidden feature. We use a fully connected layer
to compute the parameter estimate ÀÜc. Since convolutions are equivariant to shift (up to boundary
frames) and mean pooling is invariant to shift, the encoder is shift-invariant. In practice, shifting the
time sequence one frame forward will add one new frame at the beginning and drop one frame at the"
ENCODER NETWORK,0.06866952789699571,Under review as a conference paper at ICLR 2022
ENCODER NETWORK,0.07081545064377683,"end. This creates some change in output value of the encoder. Thus, practically, the encoder is only
approximately shift-invariant."
ENCODER NETWORK,0.07296137339055794,"Encoder Training. The encoder network g is trained Ô¨Årst. To combat the loss of shift invariance
from the change from the boundary frames, we train the encoder using a time-invariant loss. Given
two training samples (x(i), y(i)) and (x(j), y(j)) and their task parameters c, we have loss"
ENCODER NETWORK,0.07510729613733906,"Lenc =
X"
ENCODER NETWORK,0.07725321888412018,"c‚àºC
‚à•ÀÜc ‚àíc‚à•2 + Œ±
X"
ENCODER NETWORK,0.07939914163090128,"i,j,c
‚à•ÀÜz(i)
c
‚àíÀÜz(j)
c ‚à•2 + Œ≤
X"
ENCODER NETWORK,0.0815450643776824,"i,c
‚à•‚à•ÀÜz(i)
c ‚à•2 ‚àím‚à•2
(2)"
ENCODER NETWORK,0.08369098712446352,", where ÀÜz(i) = g(x(i)) and ÀÜz(j) = g(x(j)) and ÀÜc(i) = W ÀÜz(i)
c
+ b is an afÔ¨Åne transformation of zc."
ENCODER NETWORK,0.08583690987124463,"The Ô¨Årst term ‚à•ÀÜc ‚àíc‚à•2 uses weak supervision of the task parameters whenever they are available.
Such weak supervision helps guide the learning of hidden feature zc for each task. While not all
parameters of the dynamical system are known, we can compute approximate values in the datum
c(i) based on our domain knowledge. For example, instead of the Reynolds number of the Ô¨Çuid Ô¨Çow,
we can use the average velocity as a surrogate for task parameters."
ENCODER NETWORK,0.08798283261802575,"The second term ‚à•ÀÜz(i)
c
‚àíÀÜz(j)
c ‚à•2 is the time-shift invariance loss, which penalizes the changes in latent
variables between samples from different time steps. Since the time-shift invariance of convolution is
only approximate, this loss term drives the time-shift error even lower. The third term |‚à•ÀÜz(i)
c ‚à•‚àím|2"
ENCODER NETWORK,0.09012875536480687,"(m is a positive value) prevents the encoder from generating small ÀÜz(i)
c
due to time-shift invariance
loss. It also helps the encoder to learn more interesting z, even in the absence of weak supervision."
ENCODER NETWORK,0.09227467811158799,"Hidden Features. The encoder learns time-invariant hidden features. These hidden features resemble
the time-invariant dimensionless parameters (Kunes, 2012) in physical modeling, such as Reynolds
number in Ô¨Çuid mechanics. The hidden features may also be viewed as partial disentanglement of
the system state. As suggested by Locatello et al. (2019); Nie et al. (2020), our disentanglement
method is guided by inductive bias and training objectives. Unlike complete disentanglement, as in
e.g. Massague et al. (2020), in which the latent representation is factored into time-invariant and
time-varying components, we focus only on time-shift-invariance. Nonetheless, the hidden features
can control the forecaster which is useful for generalization."
FORECASTER NETWORK,0.0944206008583691,"2.4
FORECASTER NETWORK ùíô FC z ùíö"
FORECASTER NETWORK,0.09656652360515021,"Figure 3: Illustration of the
AdaPad operation."
FORECASTER NETWORK,0.09871244635193133,"The forecaster incorporates the hidden feature zc from the encoder and
adapts to the speciÔ¨Åc forecasting task fc = f(¬∑, zc). In what follows,
we use z for zc. We use two specialized layers, adaptive instance
normalization (AdaIN) and adaptive padding (AdaPad)."
FORECASTER NETWORK,0.10085836909871244,"AdaIN has been used in neural style transfer (Karras et al., 2019; Huang
& Belongie, 2017) to control generative networks. Here, AdaIN may
adapt for speciÔ¨Åc coefÔ¨Åcients and external forces. We also introduce a
new layer, AdaPad(x, z), which is designed for encoding the boundary
conditions of dynamical systems. In principle, the backbone of the
forecaster network can be any sequence prediction model. We use a
design that is similar to ResNet for spatiotemporal sequences."
FORECASTER NETWORK,0.10300429184549356,"AdaIN. We employ AdaIN to adapt the forecaster network. Denote
the channels of input x by xi and let ¬µ(xi) and œÉ(xi) be the mean and
standard deviation of channel i. For each AdaIN layer, a particular
style is computed s = (¬µi, œÉi)i = Az + b, where the linear map A
and bias b are learned weights. Adaptive instance normalization is
then deÔ¨Åned as yi = œÉi
xi‚àí¬µ(xi)"
FORECASTER NETWORK,0.10515021459227468,"œÉ(xi)
+ ¬µi. In essence, the channels are
renormalized to the style s."
FORECASTER NETWORK,0.1072961373390558,"For dynamics forecasting, the hidden feature z encodes data analogous to the various coefÔ¨Åcients of
a differential equation and external forces on the system. In numerical simulation of a differential
equation these coefÔ¨Åcients enter as scalings of different terms in the equation and the external forces
are added to the combined force equation (J.C.Butcher, 1996). Thus in our context AdaIN, which
scales channels and adds a global vector, is well-suited to injecting this information."
FORECASTER NETWORK,0.10944206008583691,Under review as a conference paper at ICLR 2022
FORECASTER NETWORK,0.11158798283261803,"AdaPad. To complement AdaIN, we introduce AdaPad, which encodes the boundary conditions of
each speciÔ¨Åc dynamical system. Generally when predicting dynamical systems, error is introduced
along the boundaries since it is unknown how the dynamics interact with the boundary of the domain,
and there may be unknown inÔ¨Çows or outÔ¨Çows. In our method, the inferred hidden feature z may
contain the boundary information. AdaPad uses the hidden features to compute the boundary
conditions via a linear layer. Then it applies the boundary conditions as padding immediately outside
the spatial domain in each layer, as shown in Fig. 3."
FORECASTER NETWORK,0.11373390557939914,"Forecaster Training. The forecaster network is trained separately after the encoder. The kernels of
the convolutions and the mappings of the AdaIN and AdaPad layers are all trained simultaneously as
the forecaster network is trained. Denote the true state as y and the predicted state as ÀÜy, we compute
the loss per time step ‚à•ÀÜy ‚àíy‚à•2 for each example. We accumulate the loss over different time steps
and generate multi-step forecasts in an autoregressive fashion."
THEORETICAL ANALYSIS,0.11587982832618025,"3
THEORETICAL ANALYSIS"
THEORETICAL ANALYSIS,0.11802575107296137,"The high-level idea of our method is to learn a good representation of the dynamics that generalizes
well across a heterogeneous domain, and then adapt this representation to make predictions on new
tasks. Our model achieves this by learning on multiple tasks simultaneously and then adapting
to new tasks with domain transfer. We prove that learning the tasks simultaneously as opposed
to independently results in better generalization. We also Ô¨Ånd theoretical support for training the
encoder and forecaster separately. See Appendix B for a longer treatment with proofs."
THEORETICAL ANALYSIS,0.12017167381974249,"Suppose we have K tasks {ck}K
k=1 ‚àºC, each of which is sampled from a continuous parameter
space C. Here ck are the parameters of the task, which can be inferred by the encoder. For each task
ck, we have a collection of data ÀÜ¬µck of size n, sampled from ¬µk, a shorthand for ¬µck."
THEORETICAL ANALYSIS,0.1223175965665236,"Multi-task Learning Error. Our model performs multi-task representation learning (Maurer et al.,
2016) with joint risk œµ = (1/K) P
k œµk, which is the average risk of each task œµk deÔ¨Åned separately.
Denote the corresponding empirical risks ÀÜœµ and ÀÜœµk. We can bound the true risk œµ using the empirical
risk ÀÜœµ and Rademacher complexity R(F) of the hypothesis class F. The following theorem restates
the main result in Ando et al. (2005) with simpliÔ¨Åed notations."
THEORETICAL ANALYSIS,0.12446351931330472,"Theorem 3.1. (Ando et al. (2005)) Assume the loss is bounded l ‚â§1/2. Given n samples each from
K different forecasting tasks ¬µ1, ¬∑ ¬∑ ¬∑ , ¬µk, then with probability at least 1 ‚àíŒ¥, the following inequality
holds for each f ‚ààF in the hypothesis class:"
THEORETICAL ANALYSIS,0.12660944206008584,"œµ(f) ‚â§ÀÜœµ(f) + 2R(F) +
p"
THEORETICAL ANALYSIS,0.12875536480686695,log (1/Œ¥)/(2nK)
THEORETICAL ANALYSIS,0.13090128755364808,"The following inequality compares the performance for multi-task learning to learning individual
tasks. Let Rk(F) be the Rademacher complexity for F over ¬µk."
THEORETICAL ANALYSIS,0.13304721030042918,Lemma 3.2. The Rademacher complexity for multi-task learning is bounded as
THEORETICAL ANALYSIS,0.1351931330472103,"R(F) ‚â§(1/K) K
X"
THEORETICAL ANALYSIS,0.13733905579399142,"k=1
Rk(F)."
THEORETICAL ANALYSIS,0.13948497854077252,We can now compare Theorem 3.1 to the bound obtained by considering each task individually.
THEORETICAL ANALYSIS,0.14163090128755365,"Proposition 3.3. Assume the loss is bounded l ‚â§1/2, then the generalization bound given by
considering each task individually is"
THEORETICAL ANALYSIS,0.14377682403433475,"œµ(f) ‚â§ÀÜœµ(f) + 2(1/K) K
X"
THEORETICAL ANALYSIS,0.1459227467811159,"k=1
Rk(F) +
p"
THEORETICAL ANALYSIS,0.148068669527897,"log (1/Œ¥)/(2nK).
(3)"
THEORETICAL ANALYSIS,0.15021459227467812,"The upper bound in Theorem 3.1 is strictly tighter than that of Proposition 3.3 as the Ô¨Årst terms ÀÜœµ(f)
are equal, the second term is smaller by Lemma 3.2 and the third is smaller since 1/
‚àö"
THEORETICAL ANALYSIS,0.15236051502145923,"2nK ‚â§1/
‚àö"
THEORETICAL ANALYSIS,0.15450643776824036,"2n.
This helps explain why our multitask learning forecaster has better generalization than learning each
task independently. The shared data tightens the generalization bound. Ultimately, though a tighter
upper bound suggests lower error, it does not strictly imply it. We further verify this theory in our
experiments by comparison to baselines which learn each task independently."
THEORETICAL ANALYSIS,0.15665236051502146,Under review as a conference paper at ICLR 2022
THEORETICAL ANALYSIS,0.15879828326180256,"Encoder versus Forecaster Error. Error from DyAd may result from either the encoder gœÜ or the
forecaster fŒ∏. Using (Redko et al., 2017) , we can bound the generalization error in terms of: (1) the
empirical error of the encoder, (2) the empirical forecaster error on the source domains, and (3) the
Wasserstein distance W1 between the source and target domains. We use Wasserstein distance since
different tasks may have disjoint support and thus inÔ¨Ånite KL divergence, however, samples from
tasks c, c‚Ä≤ close in C may be close in W1(¬µc, ¬µc‚Ä≤) (see Appendix Fig. 11). Our two-stage training
scheme is motivated by this decomposition for achieving generalization."
THEORETICAL ANALYSIS,0.1609442060085837,"Our hypothesis space has the form {x 7‚ÜífŒ∏(x, gœÜ(x))} where œÜ and Œ∏ are the weights of the encoder
and forecaster respectively. Let œµX be the error over the entire domain X, that is, for all c. Let
œµenc(gœÜ) = Ex‚àºX (L1(g(x), gœÜ(x)) be the encoder error where g: X ‚ÜíC is the ground truth. Let
G = {gœÜ : X ‚ÜíC} be the task encoder hypothesis space. Denote the empirical risk of gœÜ by ÀÜœµenc(gœÜ)."
THEORETICAL ANALYSIS,0.1630901287553648,"Proposition 3.4. Assume c 7‚ÜífŒ∏(¬∑, c) is Lipschitz continuous with Lipschitz constant Œ≥ uniformly in
Œ∏ and l ‚â§1/2. Let Œªc = minf‚ààF(œµc(f) + 1/K PK
k=1 œµck(f)). For large n and probability ‚â•1 ‚àíŒ¥,"
THEORETICAL ANALYSIS,0.16523605150214593,"œµX (fŒ∏(¬∑, gœÜ(¬∑))) ‚â§Œ≥ÀÜœµenc(gœÜ) + 1 K K
X"
THEORETICAL ANALYSIS,0.16738197424892703,"k=1
ÀÜœµck(fŒ∏(¬∑, ck)) + Ec‚àºC "" W1 "
THEORETICAL ANALYSIS,0.16952789699570817,"ÀÜ¬µc, 1 K K
X"
THEORETICAL ANALYSIS,0.17167381974248927,"k=1
ÀÜ¬µck ! + Œªc #"
THEORETICAL ANALYSIS,0.17381974248927037,"+2Œ≥R(G)+2R(F) + (Œ≥ + 1)
p"
THEORETICAL ANALYSIS,0.1759656652360515,"log(1/Œ¥)/(2nK) +
p"
THEORETICAL ANALYSIS,0.1781115879828326,"2 log(1/Œ¥)
p"
THEORETICAL ANALYSIS,0.18025751072961374,"1/n +
p"
THEORETICAL ANALYSIS,0.18240343347639484,"1/(nK)

."
THEORETICAL ANALYSIS,0.18454935622317598,"Although this result does not settle either the question of end-to-end versus pre-training or encoder-
forecaster versus monolithic model, it quantiÔ¨Åes the trade-offs these choices depend on. We empiri-
cally consider both questions in the experiments section."
RELATED WORK,0.18669527896995708,"4
RELATED WORK"
RELATED WORK,0.1888412017167382,"Learning Dynamical Systems. Deep learning models are gaining popularity for learning dynamical
systems (Shi et al., 2017; Chen et al., 2018; Kolter & Manek, 2019; Azencot et al., 2020a; Xie et al.,
2018; Tompson et al., 2017; Pfaff et al., 2021). An emerging topic is physics-informed deep learning
(Raissi et al., 2017; Lutter et al., 2018; Azencot et al., 2020b; de Bezenac et al., 2018; Wang et al.,
2020b; Ayed et al., 2019b;a; Li et al., 2021; Don√† et al., 2021) which integrates inductive biases from
physical systems to improve learning. For example, Lutter et al. (2018) encoded Euler-Lagrange
equation into the deep neural nets but focus on learning low-dimensional trajectories. Morton et al.
(2018); Azencot et al. (2020b) incorporated Koopman theory into the architecture. Maziar Raissi
(2019) used deep neural networks to solve PDEs with physical laws enforced in the loss functions.
Wang et al. (2020a) proposed a hybrid approach by marrying two well-established turbulent Ô¨Çow
simulation techniques with deep learning to produce better prediction of turbulence. However, these
approaches deal with a speciÔ¨Åc system dynamics instead of the meta-learning problem in this work."
RELATED WORK,0.19098712446351931,"Multi-task learning and Meta-learning Multi-task learning (Vandenhende et al., 2021) focuses on
learning shared representations from multiple related tasks. Architecture-based MTL methods can be
categorized into encoder-focused (Liu et al., 2019) and decoder-focused (Xu et al., 2018). There are
also optimization-based MTL methods, such as task balancing methods (Kendall et al., 2018). But
MTL assumes tasks are known a priori instead of inferring the task from data. On the other hand, the
aim of meta-learning (Thrun & Pratt, 1998) is to leverage the shared representation to fast adapt to
unseen tasks. Based on how the meta-level knowledge is extracted and used, meta-learning methods
are classiÔ¨Åed into model-based (Munkhdalai & Yu, 2017; Alet et al., 2018; Oreshkin et al., 2019;
Seo et al., 2020; Zhou et al., 2021; Li et al., 2017), metric-based (Vinyals et al., 2016; Snell et al.,
2017) and gradient-based (Finn et al., 2017; Andrychowicz et al., 2016; Rusu et al., 2019; Grant et al.,
2018; Yao et al., 2019). Most meta-learning approaches are not designed for forecasting with a few
exceptions. Oreshkin et al. (2019) designed a residual architecture for time series forecasting with a
meta-learning parallel. Alet et al. (2018) proposed a modular meta-learning approach for continuous
control. But forecasting physical dynamics poses unique challenges to meta-learning as we seek
ways to encode physical knowledge into our model."
RELATED WORK,0.19313304721030042,"Style Transfer. Our approach is inspired by neural style transfer techniques. In style-transfer, a
generative network is controlled by an external style vector though adaptive instance normalization
between convolutional layers. Our hidden representation bears afÔ¨Ånity with the ‚Äústyle‚Äù vector in"
RELATED WORK,0.19527896995708155,Under review as a conference paper at ICLR 2022
RELATED WORK,0.19742489270386265,"style transfer techniques. Rather than aesthetic style in images, our hidden representation encodes
time-invariant features. Style transfer initially appear in non-photorealistic rendering (Kyprianidis
et al., 2012). Recently, neural style transfer (Jing et al., 2019) has been applied to image synthesis
(Gatys et al., 2016; Liu et al., 2021), videos generation (Ruder et al., 2016), and language translation
(Prabhumoye et al., 2018). For dynamical systems, Sato et al. (2018) adapts texture synthesis to
transfer the style of turbulence for animation. Kim & Lee (2019) studies unsupervised generative
modeling of turbulent Ô¨Çows but for super-resolution reconstruction rather than forecasting."
RELATED WORK,0.19957081545064378,"Video Prediction. Our work is also related to video prediction. Conditioning on the historic observed
frames, video prediction models are trained to predict future frames, e.g., (Mathieu et al., 2015; Finn
et al., 2016; Xue et al., 2016; Villegas et al., 2017; Oprea et al., 2020; Finn et al., 2016; Wang et al.,
2017; 2021; Le Guen & Thome, 2020; Massague et al.). There is also conditional video prediction
(Oh et al., 2015) which achieves controlled synthesis. Many of these models are trained on natural
videos from unknown physical processes. Our work is substantially different because we do not
attempt to predict object or camera motions. However, our method can be potentially combined with
video prediction models to improve generalization."
EXPERIMENTS,0.2017167381974249,"5
EXPERIMENTS"
EXPERIMENTS,0.20386266094420602,"We compare our model with a series of baselines on the multi-step forecasting with different dynamics.
We consider two testing scenarios: (1) dynamics with different initial conditions (test-future) and (2)
dynamics with different parameters such as external force (test-domain). The Ô¨Årst scenario evaluates
the models‚Äô ability to extrapolate into the future for the same task. The second scenario estimates the
capability of the models to generalize across different tasks."
EXPERIMENTS,0.20600858369098712,"We experiment on three datasets: synthetic turbulent Ô¨Çows, real-world sea surface temperature and
ocean currents data. These are difÔ¨Åcult to forecast using numerical methods due to unknown external
forces and complex dynamics not fully captured by simpliÔ¨Åed mathematical models. For the weak
supervision c, we use the mean vorticity for turbulence and ocean currents, and mean temperature for
sea surface temperature. We defer the details of the datasets and experiments to Appendix A.2."
EXPERIMENTS,0.20815450643776823,"Table 1: Prediction RMSE on the turbulent Ô¨Çow and sea surface temperature datasets. Prediction
RMSE and ESE (energy spectrum errors) on the future and domain test sets of ocean currents dataset."
EXPERIMENTS,0.21030042918454936,"Model
Turbulent Flows
Sea Temperature
Ocean Currents"
EXPERIMENTS,0.21244635193133046,"future
domain
future
domain
future
domain"
EXPERIMENTS,0.2145922746781116,"ResNet
0.94¬±0.10 0.65¬±0.02 0.73¬±0.14
0.71¬±0.16
9.44¬±1.55 | 0.99¬±0.15
9.65¬±0.16 | 0.90¬±0.16
ResNet-c
0.88¬±0.03 0.64¬±0.01 0.70¬±0.08
0.71¬±0.06
9.71¬±0.01 | 0.81¬±0.03
9.15¬±0.01 | 0.73¬±0.03
U-Net
0.92¬±0.02 0.68¬±0.02 0.57¬±0.05
0.63¬±0.05
7.64¬±0.05 | 0.83¬±0.02
7.61¬±0.14 | 0.86¬±0.03
Unet-c
0.86¬±0.07 0.68¬±0.03 0.47¬±0.02
0.45¬±0.06
7.26¬±0.01 | 0.94¬±0.02
7.51¬±0.03 | 0.87¬±0.04
PredRNN
0.75¬±0.02 0.75¬±0.01 0.67¬±0.12
0.99¬±0.07
8.49¬±0.01 | 1.27¬±0.02
8.99¬±0.03 | 1.69¬±0.01
VarSepNet
0.67¬±0.05 0.63¬±0.06 0.63¬±0.14
0.49¬±0.09
9.36¬±0.02 | 0.63¬±0.04
7.10¬±0.01 | 0.58¬±0.02
Mod-attn
0.63¬±0.12 0.92¬±0.03 0.89¬±0.22
0.98¬±0.17
8.08¬±0.07 | 0.76¬±0.11
8.31¬±0.19 | 0.88¬±0.14
Mod-wt
0.58¬±0.03 0.60¬±0.07 0.65¬±0.08
0.64¬±0.09
10.1¬±0.12 | 1.19¬±0.72
8.11¬±0.19 | 0.82¬±0.19
MetaNet
0.76¬±0.13 0.76¬±0.08 0.84¬±0.16
0.82¬±0.09
10.9¬±0.52 | 1.15¬±0.18
11.2¬±0.16 | 1.08¬±0.21
MAML
0.63¬±0.01 0.68¬±0.02 0.90¬±0.17
0.67¬±0.04
10.1¬±0.21 | 0.85¬±0.06
10.9¬±0.79 | 0.99¬±0.14"
EXPERIMENTS,0.2167381974248927,"DyAd+ResNet0.42¬±0.01 0.51¬±0.02 0.42¬±0.03
0.44¬±0.04
7.28¬±0.09 | 0.58¬±0.02
7.04¬±0.04 | 0.54¬±0.03
DyAd+Unet
0.58¬±0.01 0.59¬±0.01 0.35¬±0.03
0.42¬±0.05
7.38¬±0.01 | 0.70¬±0.04
7.46¬±0.02 | 0.70¬±0.07"
EXPERIMENTS,0.21888412017167383,"Baselines. We include several SoTA baselines from meta-learning, as well as common methods for
dynamics forecasting."
EXPERIMENTS,0.22103004291845493,"‚Ä¢ ResNet (He et al., 2016): A widely adopted video prediction model (Wang et al., 2020b).
‚Ä¢ U-net (Ronneberger et al., 2015): Originally developed for biomedical image segmentation.
‚Ä¢ ResNet/Unet-c: Above ResNet and Unet with an additional Ô¨Ånal layer that generates task
parameter c and trained with weak-supervision and forecasting loss altogether.
‚Ä¢ PredRNN (Wang et al., 2017): A state-of-the-art RNN-based spatiotemporal forecasting model.
‚Ä¢ VarSepNet (Don√† et al., 2021): A convolutional dynamics forecasting model based on spatiotem-
poral disentanglement."
EXPERIMENTS,0.22317596566523606,Under review as a conference paper at ICLR 2022
EXPERIMENTS,0.22532188841201717,"Figure 4: Target and predictions by Unet-c, Modular-wt and DyAd at time 1, 5, 10 for turbulent
Ô¨Çows with buoyancy factors 9 (left) and 21 (right) respectively. DyAd can easily generate predictions
for various Ô¨Çows while baselines have trouble understanding and disentangling buoyancy factors."
EXPERIMENTS,0.22746781115879827,"‚Ä¢ Mod-attn: A modular meta-learning method which combines modules to generalize to new tasks
(Alet et al., 2018) using attention.
‚Ä¢ Mod-wt: A modular meta-learning variant which uses attention weights to combine the parameters
of the convolutional kernels for new tasks.
‚Ä¢ MetaNet (Munkhdalai & Yu, 2017): A model-based meta-learning method which requires a few
labels from test tasks as a support set to adapt.
‚Ä¢ MAML (Finn et al., 2017): A popular optimization-based meta-learning approach. We replaced the
classiÔ¨Åer in the original model with a ResNet for regression."
EXPERIMENTS,0.2296137339055794,"Note that both ResNet-c and Unet-c have access to task parameters c, but cannot adapt.
Mod-attn and Mod-wt also use a convolutional encoder to generate attention weights. MetaNet
requires samples from test tasks as a support set and MAML needs adaptation retraining on test tasks,
while other models do not need any information from the test domains. VarSepNet employs sepa-
ration of variables through different loss terms but it is difÔ¨Åcult to Ô¨Ånd the optimal hyperparameters
for these terms. To demonstrate the generality of DyAd, we experimented with both ResNet and
U-net as our forecaster. See details about baselines in Appendix A.2."
EXPERIMENTS,0.2317596566523605,"Experiment Setup. For all datasets, we use a sliding window approach to generate samples of
sequences. For test-future, we train and test on the same tasks but different time steps. For test-
domain, we train and test on different tasks with an 80-20 split. All models are trained to make next
step prediction given the previous steps as input. We forecast in an autoregressive manner to generate
multi-step ahead predictions. All results are averaged over 3 runs with random initialization."
EXPERIMENTS,0.23390557939914164,"Apart from the root mean square error (RMSE), we also report the energy spectrum error (ESE)
for ocean current prediction which quantiÔ¨Åes the physical consistency. ESE indicates whether the
predictions preserve the correct statistical distribution and obey the energy conservation law, which is
a critical metric for physical consistency. See details about energy spectrum in Appendix A.3."
EXPERIMENT RESULTS,0.23605150214592274,"5.1
EXPERIMENT RESULTS"
EXPERIMENT RESULTS,0.23819742489270387,"Prediction Performance. Table 1 shows the RMSE of multi-step predictions on Turbulent Flows
(20 steps), Sea Surface Temperature (10 steps), and Ocean Currents (10 step) in two testing scenarios.
We observe that DyAd makes the most accurate predictions in both scenarios across all datasets.
Comparing ResNet/Unet-c with DyAd, we observe the clear advantage of task inference with
separate training. VarSepNet achieves competitive performances on Ocean Currents (second best)
through spatiotemporal disentanglement but cannot adapt to future tasks. Table 1 also reports ESE on
Ocean Currents. DyAd not only has small RMSE but also obtains the smallest ESE, suggesting it
captures the statistical distribution of ocean currents well."
EXPERIMENT RESULTS,0.24034334763948498,"Figure 4 shows the target and the predicted velocity norm (
‚àö"
EXPERIMENT RESULTS,0.24248927038626608,"u2 + v2) by Unet-c, Modular-wt
and DyAd at time step 1, 5, 10 for Turbulent Flows with buoyancy factors 9 and 21 respectively.
We can see that DyAd can generate realistic Ô¨Çows with the corresponding characteristics while the
baselines have trouble understanding and disentangling the buoyancy factor."
EXPERIMENT RESULTS,0.2446351931330472,Under review as a conference paper at ICLR 2022
EXPERIMENT RESULTS,0.24678111587982832,"Model
future
domain"
EXPERIMENT RESULTS,0.24892703862660945,"DyAd(ours)
0.42¬±0.01
0.51¬±0.02
No_enc
0.63¬±0.03
0.60¬±0.02
No_AdaPad
0.47¬±0.01
0.54¬±0.02
Wrong_enc
0.66¬±0.02
0.62¬±0.03
End2End
0.45¬±0.01
0.54¬±0.01"
EXPERIMENT RESULTS,0.2510729613733906,"Table 2: Ablation study: prediction RMSE of
DyAd and its variations with different compo-
nents removed from DyAd."
EXPERIMENT RESULTS,0.2532188841201717,"Figure 5: DyAd, ResNet, U-net, PredRNN veloc-
ity norm (
‚àö"
EXPERIMENT RESULTS,0.2553648068669528,"u2 + v2) predictions on an ocean current
sample in the future test set."
EXPERIMENT RESULTS,0.2575107296137339,"Figure 5 shows DyAd, ResNet, U-net, PredRNN predictions on an ocean current sample in the
future test set, and we see the shape of predictions by DyAd is closest to the target. These results
demonstrate that DyAd not only forecasts well but also accurately captures the physical characteristics
of the system. We also visualize the energy spectrum of target and predictions by ResNet, U-net
and DyAd on two test sets of ocean currents in Figure 10, with DyAd being the closest to the target."
EXPERIMENT RESULTS,0.259656652360515,"Figure 6: Outputs from DyAd while we
vary encoder input but keep the forecaster
input Ô¨Åxed. From left to right, the encoder
is fed with Ô¨Çow with different buoyancy
factor c = 5, 15, 25. the forecaster net-
work input has Ô¨Åxed buoyancy c = 15."
EXPERIMENT RESULTS,0.26180257510729615,"Ablation Study. We performed an ablation study of
DyAd on the turbulence dataset to understand the contri-
bution of each component, shown in Table 2. We Ô¨Årst
remove the encoder from DyAd while keeping the same
forecaster network (No_enc). The resulting model de-
grades but still outperforms ResNet. This demonstrates
the effectiveness of AdaIN and AdaPad for forecasting.
We also tested DyAd with AdaIN only (No_AdaPad),
and the performance without AdaPad was slightly worse."
EXPERIMENT RESULTS,0.26394849785407726,"Another notable feature of our model is the ability to infer
tasks with weakly supervised signals c. It is important
to have a c that is related to the task domain. As an
ablative study, we fed the encoder in DyAd with a random
c, leading to Wrong_enc. We can see that having the
wrong supervision may hurt the forecasting performance.
We also trained the encoder and the forecaster in DyAd
altogether (End2End) but observed worse performance.
This validates our hypothesis about the signiÔ¨Åcance of
domain partitioning and separate training strategy. We
also tested 5 different alternatives to AdaIN for injecting the hidden feature zc into the forecaster, and
reported the results in Table 5 of Appendix A.4."
EXPERIMENT RESULTS,0.26609442060085836,"Controllable Forecast. DyAd infers the hidden features from data, which allows direct control of
the latent space in the forecaster. We tried varying the encoder input while keeping the forecaster
input Ô¨Åxed. Figure 6 shows the forecasts from DyAd when the encoder is fed with Ô¨Çows having
different buoyancy factors c = 5, 15, 25. As expected, with higher buoyancy factors, the predictions
from the forecaster become more turbulent. This demonstrates that the encoder can successfully
disentangle the latent representation of difference tasks, and control the predictions of the forecaster."
CONCLUSION,0.26824034334763946,"6
CONCLUSION"
CONCLUSION,0.2703862660944206,"We propose a model-based meta-learning method, DyAd to forecast physical dynamics. DyAd uses
an encoder to infer the parameters of the task and a prediction network to adapt and forecast giving
the inferred task. Our model can also leverage any weak supervision signals that can help distinguish
different tasks, allowing the incorporation of additional domain knowledge. On challenging turbulent
Ô¨Çow prediction and real-world ocean temperature and currents forecasting tasks, we observe superior
performance of our model across heterogeneous dynamics. Future work would consider non-grid
data such as Ô¨Çows on a graph or a sphere."
CONCLUSION,0.27253218884120173,Under review as a conference paper at ICLR 2022
ETHICS STATEMENT,0.27467811158798283,ETHICS STATEMENT
ETHICS STATEMENT,0.27682403433476394,"Our model allows for generalizable predictions of dynamical systems. One example domain we
apply it to is turbulent Ô¨Çow predictions. While there are many peaceful applications of turbulent Ô¨Çow
prediction, our method could also potentially be helpful for researching explosive weapons or for
designing aircraft or missiles."
REPRODUCIBILITY STATEMENT,0.27896995708154504,REPRODUCIBILITY STATEMENT
REPRODUCIBILITY STATEMENT,0.2811158798283262,"The implementation code of DyAd and baselines are included in the supplementary material. The
readme Ô¨Åle includes the instructions of downloading PhiFlow and generating the turbulent Ô¨Çow
dataset. The ocean currents and sea temperature can be downloaded manually from the link provided
in the Appendix A.2. The full proofs of the theorems in Section 3 can be found in Appendix B."
REFERENCES,0.2832618025751073,REFERENCES
REFERENCES,0.2854077253218884,"Ferran Alet, Tomas Lozano-Perez, and L. Kaelbling. Modular meta-learning. ArXiv, abs/1806.10166,
2018."
REFERENCES,0.2875536480686695,"Rie Kubota Ando, Tong Zhang, and Peter Bartlett. A framework for learning predictive structures
from multiple tasks and unlabeled data. Journal of Machine Learning Research, 6(11), 2005."
REFERENCES,0.28969957081545067,"Marcin Andrychowicz, Misha Denil, Sergio Gomez Colmenarejo, M. W. Hoffman, D. Pfau, T. Schaul,
and N. D. Freitas. Learning to learn by gradient descent by gradient descent. In Advances in
Neural Information Processing Systems, 2016."
REFERENCES,0.2918454935622318,"I. Ayed, Emmanuel de B√©zenac, A. Pajot, J. Brajard, and P. Gallinari. Learning dynamical systems
from partial observations. ArXiv, abs/1902.11136, 2019a."
REFERENCES,0.2939914163090129,"Ibrahim Ayed, Emmanuel De B√©zenac, Arthur Pajot, and Patrick Gallinari. Learning partially
observed PDE dynamics with neural networks, 2019b. URL https://openreview.net/
forum?id=HyefgnCqFm."
REFERENCES,0.296137339055794,"Omri Azencot, N. Erichson, V. Lin, and Michael W. Mahoney. Forecasting sequential data using
consistent koopman autoencoders. In International Conference on Machine Learning, 2020a."
REFERENCES,0.2982832618025751,"Omri Azencot, N Benjamin Erichson, Vanessa Lin, and Michael Mahoney. Forecasting sequential
data using consistent koopman autoencoders. In International Conference on Machine Learning,
pp. 475‚Äì485. PMLR, 2020b."
REFERENCES,0.30042918454935624,"Jonathan Baxter. Theoretical models of learning to learn. In Learning to learn, pp. 71‚Äì94. Springer,
1998."
REFERENCES,0.30257510729613735,"Ricky TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. Neural ordinary differential
equations. In Proceedings of the 32nd International Conference on Neural Information Processing
Systems, pp. 6572‚Äì6583, 2018."
REFERENCES,0.30472103004291845,"Emmanuel de Bezenac, Arthur Pajot, and Patrick Gallinari. Deep learning for physical processes:
Incorporating prior scientiÔ¨Åc knowledge. In International Conference on Learning Representations,
2018. URL https://openreview.net/forum?id=By4HsfWAZ."
REFERENCES,0.30686695278969955,"J√©r√©mie Don√†, Jean-Yves Franceschi, sylvain lamprier, and patrick gallinari. {PDE}-driven spa-
tiotemporal disentanglement. In International Conference on Learning Representations, 2021.
URL https://openreview.net/forum?id=vLaHRtHvfFp."
REFERENCES,0.3090128755364807,"Chelsea Finn, Ian Goodfellow, and Sergey Leine. Unsupervised learning for physical interaction
through video prediction. In Advances in neural information processing systems, pp. 64‚Äì72, 2016."
REFERENCES,0.3111587982832618,"Chelsea Finn, P. Abbeel, and S. Levine. Model-agnostic meta-learning for fast adaptation of deep
networks. In International Conference of Machine Learning, 2017."
REFERENCES,0.3133047210300429,Under review as a conference paper at ICLR 2022
REFERENCES,0.315450643776824,"Leon A Gatys, Alexander S Ecker, and Matthias Bethge. Image style transfer using convolutional
neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pp. 2414‚Äì2423, 2016."
REFERENCES,0.31759656652360513,"E. Grant, Chelsea Finn, S. Levine, Trevor Darrell, and T. GrifÔ¨Åths. Recasting gradient-based meta-
learning as hierarchical bayes. ArXiv Preprint, abs/1801.08930, 2018."
REFERENCES,0.3197424892703863,"Abhishek Gupta, Russell Mendonca, YuXuan Liu, Pieter Abbeel, and Sergey Levine.
Meta-
reinforcement learning of structured exploration strategies. In Proceedings of the 32nd Inter-
national Conference on Neural Information Processing Systems, pp. 5307‚Äì5316, 2018."
REFERENCES,0.3218884120171674,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pp. 770‚Äì778, 2016."
REFERENCES,0.3240343347639485,"Xun Huang and Serge Belongie. Arbitrary style transfer in real-time with adaptive instance normal-
ization. In Proceedings of the IEEE International Conference on Computer Vision, pp. 1501‚Äì1510,
2017."
REFERENCES,0.3261802575107296,"J.C.Butcher. Applied Numerical Mathematics, volume 20. Elsevier B.V., 1996."
REFERENCES,0.3283261802575107,"Yongcheng Jing, Yezhou Yang, Zunlei Feng, Jingwen Ye, Yizhou Yu, and Mingli Song. Neural style
transfer: A review. IEEE transactions on visualization and computer graphics, 26(11):3365‚Äì3385,
2019."
REFERENCES,0.33047210300429186,"Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative
adversarial networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, pp. 4401‚Äì4410, 2019."
REFERENCES,0.33261802575107297,"Alex Kendall, Yarin Gal, and Roberto Cipolla. Multi-task learning using uncertainty to weigh losses
for scene geometry and semantics. 2018 IEEE/CVF Conference on Computer Vision and Pattern
Recognition, pp. 7482‚Äì7491, 2018."
REFERENCES,0.33476394849785407,"Junhyuk Kim and Changhoon Lee. Deep unsupervised learning of turbulence for inÔ¨Çow generation
at various reynolds numbers. arXiv:1908.10515, 2019."
REFERENCES,0.3369098712446352,"J. Zico Kolter and Gaurav Manek. Learning stable deep dynamics models. In Advances in Neural
Information Processing Systems (NeurIPS), volume 32, pp. 11128‚Äì11136, 2019."
REFERENCES,0.33905579399141633,"Josef Kunes. Dimensionless physical quantities in science and engineering. Elsevier, 2012."
REFERENCES,0.34120171673819744,"Jan Eric Kyprianidis, John Collomosse, Tinghuai Wang, and Tobias Isenberg. State of the"" art‚Äù: A
taxonomy of artistic stylization techniques for images and video. IEEE transactions on visualization
and computer graphics, 19(5):866‚Äì885, 2012."
REFERENCES,0.34334763948497854,"Vincent Le Guen and Nicolas Thome. Disentangling physical dynamics from unknown factors for
unsupervised video prediction. In Computer Vision and Pattern Recognition (CVPR). 2020."
REFERENCES,0.34549356223175964,"Zhenguo Li, Fengwei Zhou, Fei Chen, and Hang Li. Meta-sgd: Learning to learn quickly for few
shot learning. arXiv preprint arXiv: 1707.09835, 2017."
REFERENCES,0.34763948497854075,"Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew
Stuart, and Anima Anandkumar. Fourier neural operator for parametric partial differential equations.
International Conference on Learning Representations, 2021."
REFERENCES,0.3497854077253219,"Shikun Liu, Edward Johns, and Andrew J. Davison. End-to-end multi-task learning with attention.
2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1871‚Äì1880,
2019."
REFERENCES,0.351931330472103,"Xiao Liu, Spyridon Thermos, Alison Q. O‚ÄôNeil, and Sotirios A. Tsaftaris. Semi-supervised meta-
learning with disentanglement for domain-generalised medical image segmentation. In MICCAI,
2021."
REFERENCES,0.3540772532188841,Under review as a conference paper at ICLR 2022
REFERENCES,0.3562231759656652,"Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly, Bernhard Sch√∂lkopf,
and Olivier Bachem. Challenging common assumptions in the unsupervised learning of disentan-
gled representations. In international conference on machine learning, pp. 4114‚Äì4124. PMLR,
2019."
REFERENCES,0.3583690987124464,"Michael Lutter, Christian Ritter, and Jan Peters. Deep lagrangian networks: Using physics as model
prior for deep learning. In International Conference on Learning Representations, 2018."
REFERENCES,0.3605150214592275,"Gurvan Madec et al. NEMO ocean engine, 2015. Technical Note. Institut Pierre-Simon Laplace
(IPSL), France. https://epic.awi.de/id/eprint/39698/1/NEMO_book_v6039.
pdf."
REFERENCES,0.3626609442060086,"Armand Comas Massague, Chi Zhang, Zlatan Feric, Octavia I. Camps, and Rose Yu. Learning
disentangled representations of video with missing data. arXiv preprint arXiv: 2006.13391."
REFERENCES,0.3648068669527897,"Armand Comas Massague, Chi Zhang, Zlatan Feric, Octavia Camps, and Rose Yu. Learning
disentangled representations of video with missing data. arXiv preprint arXiv:2006.13391, 2020."
REFERENCES,0.3669527896995708,"Michael Mathieu, Camille Couprie, and Yann LeCun. Deep multi-scale video prediction beyond
mean square error. arXiv preprint arXiv:1511.05440, 2015."
REFERENCES,0.36909871244635195,"Andreas Maurer, Massimiliano Pontil, and Bernardino Romera-Paredes. The beneÔ¨Åt of multitask
representation learning. Journal of Machine Learning Research, 17(81):1‚Äì32, 2016."
REFERENCES,0.37124463519313305,"George E Karniadakis Maziar Raissi, Paris Perdikaris. Physics-informed neural networks: A deep
learning framework for solving forward and inverse problems involving nonlinear partial differen-
tial equations. Journal of Computational Physics, 378:686‚Äì707, 2019."
REFERENCES,0.37339055793991416,"Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. Foundations of machine learning. MIT
press, 2018."
REFERENCES,0.37553648068669526,"Jeremy Morton, Antony Jameson, Mykel J. Kochenderfer, and Freddie Witherden. Deep dynamical
modeling and control of unsteady Ô¨Çuid Ô¨Çows. In Advances in Neural Information Processing
Systems (NeurIPS), 2018."
REFERENCES,0.3776824034334764,"Tsendsuren Munkhdalai and Hong Yu. Meta networks. Proceedings of machine learning research,
70:2554‚Äì2563, 2017."
REFERENCES,0.3798283261802575,"Weili Nie, Tero Karras, Animesh Garg, Shoubhik Debhath, A. Patney, Ankit B. Patel, and Anima
Anandkumar. Semi-supervised stylegan for disentanglement learning. In International Conference
on Machine Learning, 2020."
REFERENCES,0.38197424892703863,"Junhyuk Oh, Xiaoxiao Guo, Honglak Lee, Richard Lewis, and Satinder Singh. Action-conditional
video prediction using deep networks in atari games. In Proceedings of the 28th International
Conference on Neural Information Processing Systems-Volume 2, pp. 2863‚Äì2871, 2015."
REFERENCES,0.38412017167381973,"Sergiu Oprea, P. Martinez-Gonzalez, A. Garcia-Garcia, John Alejandro Castro-Vargas, S. Orts-
Escolano, J. Garcia-Rodriguez, and Antonis A. Argyros. A review on deep learning techniques for
video prediction. ArXiv, abs/2004.05214, 2020."
REFERENCES,0.38626609442060084,"Boris N Oreshkin, Dmitri Carpov, Nicolas Chapados, and Yoshua Bengio. N-beats: Neural basis
expansion analysis for interpretable time series forecasting. In International Conference on
Learning Representations, 2019."
REFERENCES,0.388412017167382,"Tobias Pfaff, Meire Fortunato, Alvaro Sanchez-Gonzalez, and Peter Battaglia. Learning mesh-based
simulation with graph networks. In International Conference on Learning Representations, 2021.
URL https://openreview.net/forum?id=roNqYL0_XP."
REFERENCES,0.3905579399141631,"Shrimai Prabhumoye, Yulia Tsvetkov, Ruslan Salakhutdinov, and Alan W Black. Style transfer
through back-translation. In Proceedings of the 56th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers), pp. 866‚Äì876, 2018."
REFERENCES,0.3927038626609442,"Maziar Raissi, Paris Perdikaris, and George Em Karniadakis. Physics informed deep learning (part i):
Data-driven solutions of nonlinear partial differential equations. arXiv preprint arXiv:1711.10561,
2017."
REFERENCES,0.3948497854077253,Under review as a conference paper at ICLR 2022
REFERENCES,0.3969957081545064,"Ievgen Redko, Amaury Habrard, and Marc Sebban. Theoretical analysis of domain adaptation with
optimal transport. In Joint European Conference on Machine Learning and Knowledge Discovery
in Databases, pp. 737‚Äì753. Springer, 2017."
REFERENCES,0.39914163090128757,"Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical
image segmentation. In International Conference on Medical image computing and computer-
assisted intervention, pp. 234‚Äì241. Springer, 2015."
REFERENCES,0.4012875536480687,"Manuel Ruder, Alexey Dosovitskiy, and Thomas Brox. Artistic style transfer for videos. In German
conference on pattern recognition, pp. 26‚Äì36. Springer, 2016."
REFERENCES,0.4034334763948498,"Andrei A. Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan Pascanu, Simon Osindero,
and Raia Hadsell. Meta-learning with latent embedding optimization. In International Confer-
ence on Learning Representations, 2019. URL https://openreview.net/forum?id=
BJgklhAcK7."
REFERENCES,0.4055793991416309,"Syuhei Sato, Yoshinori Dobashi, Theodore Kim, and Tomoyuki Nishita. Example-based turbulence
style transfer. ACM Transactions on Graphics (TOG), 37(4):1‚Äì9, 2018."
REFERENCES,0.40772532188841204,"Sungyong Seo, Chuizheng Meng, Sirisha Rambhatla, and Y. Liu. Physics-aware spatiotemporal
modules with auxiliary tasks for meta-learning. arXiv preprint arXiv: 2006.08831, 2020."
REFERENCES,0.40987124463519314,"Xingjian Shi, Zhihan Gao, Leonard Lausen, Hao Wang, D. Yeung, W. Wong, and Wang chun Woo.
Deep learning for precipitation nowcasting: A benchmark and a new model. In Advances in neural
information processing systems, 2017."
REFERENCES,0.41201716738197425,"J. Snell, Kevin Swersky, and R. Zemel. Prototypical networks for few-shot learning. In Advances in
Neural Information Processing Systems, 2017."
REFERENCES,0.41416309012875535,"Sebastian Thrun and Lorien Pratt. Learning to learn: Introduction and overview. In Learning to learn,
pp. 3‚Äì17. Springer, 1998."
REFERENCES,0.41630901287553645,"Jonathan Tompson, Kristofer Schlachter, Pablo Sprechmann, and Ken Perlin. Accelerating Eulerian
Ô¨Çuid simulation with convolutional networks. In ICML‚Äô17 Proceedings of the 34th International
Conference on Machine Learning, volume 70, pp. 3424‚Äì3433, 2017."
REFERENCES,0.4184549356223176,"Simon Vandenhende, Stamatios Georgoulis, Wouter Van Gansbeke, Marc Proesmans, Dengxin Dai,
and Luc Van Gool. Multi-task learning for dense prediction tasks: A survey. IEEE transactions on
pattern analysis and machine intelligence, PP, 2021."
REFERENCES,0.4206008583690987,"Ruben Villegas, Jimei Yang, Seunghoon Hong, Xunyu Lin, and Honglak Lee. Decomposing motion
and content for natural video sequence prediction. In International Conference on Learning
Representations (ICLR), 2017."
REFERENCES,0.4227467811158798,"Oriol Vinyals, Charles Blundell, T. Lillicrap, K. Kavukcuoglu, and Daan Wierstra. Matching networks
for one shot learning. In NIPS, 2016."
REFERENCES,0.4248927038626609,"Rui Wang, Karthik Kashinath, Mustafa Mustafa, Adrian Albert, and Rose Yu. Towards physics-
informed deep learning for turbulent Ô¨Çow prediction. In Proceedings of the 26th ACM SIGKDD
International Conference on Knowledge Discovery & Data Mining, pp. 1457‚Äì1466, 2020a."
REFERENCES,0.4270386266094421,"Rui Wang, Robin Walters, and Rose Yu. Incorporating symmetry into deep dynamics models for
improved generalization. arXiv preprint arXiv:2002.03061, 2020b."
REFERENCES,0.4291845493562232,"Yunbo Wang, Mingsheng Long, Jianmin Wang, Zhifeng Gao, and Philip S Yu. PredRNN: Recurrent
neural networks for predictive learning using spatiotemporal LSTMs. In Advances in Neural
Information Processing Systems, pp. 879‚Äì888, 2017."
REFERENCES,0.4313304721030043,"Yunbo Wang, Haixu Wu, Jianjin Zhang, Zhifeng Gao, Jianmin Wang, Philip S Yu, and Mingsheng
Long. PredRNN: A recurrent neural network for spatiotemporal predictive learning, 2021."
REFERENCES,0.4334763948497854,"You Xie, Erik Franz, Mengyu Chu, and Nils Thuerey. tempoGAN: A temporally coherent, volumetric
GAN for super-resolution Ô¨Çuid Ô¨Çow. ACM Transactions on Graphics (TOG), 37(4):95, 2018."
REFERENCES,0.4356223175965665,Under review as a conference paper at ICLR 2022
REFERENCES,0.43776824034334766,"Dan Xu, Wanli Ouyang, Xiaogang Wang, and N. Sebe. Pad-net: Multi-tasks guided prediction-
and-distillation network for simultaneous depth estimation and scene parsing. 2018 IEEE/CVF
Conference on Computer Vision and Pattern Recognition, pp. 675‚Äì684, 2018."
REFERENCES,0.43991416309012876,"Tianfan Xue, Jiajun Wu, Katherine Bouman, and Bill Freeman. Visual dynamics: Probabilistic future
frame synthesis via cross convolutional networks. In Advances in neural information processing
systems (NeurIPS), pp. 91‚Äì99, 2016."
REFERENCES,0.44206008583690987,"Huaxiu Yao, Ying Wei, Junzhou Huang, and Zhenhui Li. Hierarchically structured meta-learning. In
International Conference on Machine Learning, pp. 7045‚Äì7054. PMLR, 2019."
REFERENCES,0.44420600858369097,"Jaesik Yoon, Taesup Kim, Ousmane Dia, Sungwoong Kim, Yoshua Bengio, and Sungjin Ahn.
Bayesian model-agnostic meta-learning. In Proceedings of the 32nd International Conference on
Neural Information Processing Systems, pp. 7343‚Äì7353, 2018."
REFERENCES,0.44635193133047213,"Allan Zhou, Tom Knowles, and Chelsea Finn. Meta-learning symmetries by reparameterization. In
International Conference on Learning Representations, 2021. URL https://openreview.
net/forum?id=-QxT4mJdijq."
REFERENCES,0.44849785407725323,"David Zoltowski, Jonathan Pillow, and Scott Linderman. A general recurrent state space framework
for modeling neural dynamics during decision-making. In International Conference on Machine
Learning, pp. 11680‚Äì11691. PMLR, 2020."
REFERENCES,0.45064377682403434,Under review as a conference paper at ICLR 2022
REFERENCES,0.45278969957081544,"A
IMPLEMENTATION DETAILS"
REFERENCES,0.45493562231759654,"A.1
MODEL DESIGN"
REFERENCES,0.4570815450643777,"The prediction network ÀÜy = f(x, z) is composed of 8 blocks. Each block operates on a hidden state
h(i) of shape B √óH √óW √óCin and yields a new hidden state h(i+1) of the shape B √óH √óW √óCout.
The Ô¨Årst input is h0 = x and the Ô¨Ånal output is computed from the Ô¨Ånal hidden state as ÀÜy =
Conv2D(h(8)). We deÔ¨Åne each block as"
REFERENCES,0.4592274678111588,"a(i) = œÉ(Conv2D(AdaPad(h(i), z)))"
REFERENCES,0.4613733905579399,"b(i) = œÉ(Conv2D(AdaPad(a(i), z))) + h(i)"
REFERENCES,0.463519313304721,"hi+1 = AdaIN(b(i), z)"
REFERENCES,0.4656652360515021,as illustrated in Figure 3. ùíÑ ùëøùüè:ùíï
REFERENCES,0.4678111587982833,Conv3D 3x3x3
REFERENCES,0.4699570815450644,64x64x128
REFERENCES,0.4721030042918455,BatchNorm
REFERENCES,0.4742489270386266,LeakyReLU
REFERENCES,0.47639484978540775,MaxPool
REFERENCES,0.47854077253218885,Conv3D 3x3x3
REFERENCES,0.48068669527896996,32x32x256
REFERENCES,0.48283261802575106,BatchNorm
REFERENCES,0.48497854077253216,LeakyReLU
REFERENCES,0.4871244635193133,MaxPool
REFERENCES,0.4892703862660944,Conv3D 3x3x3
REFERENCES,0.49141630901287553,16x16x512
REFERENCES,0.49356223175965663,BatchNorm
REFERENCES,0.4957081545064378,LeakyReLU
REFERENCES,0.4978540772532189,MaxPool
REFERENCES,0.5,Conv3D 3x3x3
REFERENCES,0.5021459227467812,8x8x1024
REFERENCES,0.5042918454935622,BatchNorm
REFERENCES,0.5064377682403434,LeakyReLU
REFERENCES,0.5085836909871244,Global MeanPool FC FC
REFERENCES,0.5107296137339056,"To forecaster
z"
REFERENCES,0.5128755364806867,"Figure 7: Detail of the DyAd encoder. The conv3D layers are shift equivariant and global mean
pooling is shift invariant. The network is approximately invariant to spatial and temporal shifts."
REFERENCES,0.5150214592274678,Conv2D 3x3
REFERENCES,0.5171673819742489,"LeakyReLU z
ùíâùíä"
REFERENCES,0.51931330472103,"FC
AdaPad"
REFERENCES,0.5214592274678111,Conv2D 3x3
REFERENCES,0.5236051502145923,LeakyReLU
REFERENCES,0.5257510729613734,AdaPad FC
REFERENCES,0.5278969957081545,"+
AdaIN ùíâùíä+ùüè"
REFERENCES,0.5300429184549357,Figure 8: Detail of one block of the forecaster network.
REFERENCES,0.5321888412017167,Under review as a conference paper at ICLR 2022
REFERENCES,0.5343347639484979,"A.2
EXPERIMENT DETAILS"
REFERENCES,0.5364806866952789,"A.2.1
DATASETS"
REFERENCES,0.5386266094420601,"Turbulent Flow with Varying Buoyancy. We generate a synthetic dataset of turbulent Ô¨Çows with a
numerical simulator, PhiFlow1. It contains 64√ó64 velocity Ô¨Åelds of turbulent Ô¨Çows in which we vary
the buoyant force acting on the Ô¨Çuid from 1 to 25. Each buoyant force corresponds to a forecasting
task and there are 25 tasks in total. We use the mean vorticity of each task as partial supervision c as
we can directly calculate it from the data. Vorticity can characterize formation and circular motion of
turbulent Ô¨Çows."
REFERENCES,0.5407725321888412,"Sea Surface Temperature. We evaluate on a real-world sea surface temperature data generated by
the NEMO ocean engine (Madec et al., 2015)2. We select an area from PaciÔ¨Åc ocean range from
01/01/2018 to 12/31/2020. The corresponding latitude and longitude are (-150‚àº-120, -20‚àº-50). This
area is then divided into 25 64√ó64 subregions, each is a task since the mean temperature varies a lot
along longitude and latitude. For the encoder training, we use season as an additional supervision
signal besides the mean temperature of each subregion. In other words, the encoder should be able to
infer the mean temperature of the subregion as well as to classify four seasons given the temperature
series."
REFERENCES,0.5429184549356223,"Ocean Currents. We also experiment with the velocity Ô¨Åelds of ocean currents from the same region
and use the same task division as the sea surface temperature data set. Similar to the turbulent Ô¨Çow
data set, we use the mean vorticity of each subregion as the weak-supervision signal."
REFERENCES,0.5450643776824035,"A.2.2
BASELINES."
REFERENCES,0.5472103004291845,"For fair comparison, we set these models to have equal capacity as DyAd in terms of number
of parameters. Hyperparameters including learning rate, input length and the number of steps
of accumulated loss for training are tuned on validation sets. Modular-attn has a convolu-
tional encoder f that takes the same input x as each module M to generate attention weights,
Pm
l=1
exp[f(x)(l)]
Pm
k=1 exp[f(x)(k)]Ml(x). Modular-wt also has the same encoder but to generate weights for
combining the convolution parameters of all modules. We use additional samples of up to 20% of the
test set from test tasks. MetaNet uses these as a support set. MAML is retrained on these samples for
10 epoch for adaptation."
REFERENCES,0.5493562231759657,"A.2.3
HYPERPARAMETER TUNING."
REFERENCES,0.5515021459227468,"We tuned learning rate (1e-3‚àº1e-5), batch size (16‚àº64), the number of accumulated errors for
backpropogation (2‚àº5), and hidden size (64‚àº512) of Modular Networks and Meta-Nets. We Ô¨Åxed
the number of historic input frames as 20. When we trained the encoder on turbulent Ô¨Çows and sea
surface temperature, we used Œ± = 1 and Œ≤ = 1. For ocean currents, we used Œ± = 0.2 and Œ≤ = 0.2.
We performed all our experiments on 4 V100 GPUs."
REFERENCES,0.5536480686695279,"A.2.4
MODEL CAPACITY."
REFERENCES,0.555793991416309,Table 3 displays the number of parameters of each tuned model on the turbulent Ô¨Çow dataset.
REFERENCES,0.5579399141630901,Table 3: The number of parameters of the best model of each architecture
REFERENCES,0.5600858369098712,"ResNet
U-net
PredRNN
VarSepNetMod-attn Mod-wt
MetaNets MAML
DyAd"
REFERENCES,0.5622317596566524,"20.32
9.69
27.83
9.85
13.19
13.19
9.63
20.32
15.60"
REFERENCES,0.5643776824034334,"1https://github.com/tum-pbs/PhiFlow
2The data are available at https://resources.marine.copernicus.eu/?option=com_
csw&view=details&product_id=GLOBAL_ANALYSIS_FORECAST_PHY_001_024"
REFERENCES,0.5665236051502146,Under review as a conference paper at ICLR 2022
REFERENCES,0.5686695278969958,"A.3
TURBULENCE KINETIC ENERGY SPECTRUM"
REFERENCES,0.5708154506437768,"The turbulence kinetic energy spectrum E(k) is related to the mean turbulence kinetic energy as
Z ‚àû"
REFERENCES,0.572961373390558,"0
E(k)dk = ((u
‚Ä≤)2 + (v
‚Ä≤)2)/2,"
REFERENCES,0.575107296137339,"(u
‚Ä≤)2 = 1 T T
X"
REFERENCES,0.5772532188841202,"t=0
(u(t) ‚àí¬Øu)2,"
REFERENCES,0.5793991416309013,"where the k is the wavenumber and t is the time step. Figure 9 shows a theoretical turbulence
kinetic energy spectrum plot. The spectrum can describe the transfer of energy from large scales of
motion to the small scales and provides a representation of the dependence of energy on frequency.
Thus, the Energy Spectrum Error can indicate whether the predictions preserve the correct statistical
distribution and obey the energy conservation law. A trivial example that can illustrate why we need
ESE is that if a model simply outputs moving averages of input frames, the accumulated RMSE of
predictions might not be high but the ESE would be really big because all the small or even medium
eddies are smoothed out."
REFERENCES,0.5815450643776824,Figure 9: Spectrum plot
REFERENCES,0.5836909871244635,"A.4
ADDITIONAL RESULTS"
REFERENCES,0.5858369098712446,"Figure 10: The energy spectrum of target and predictions by ResNet, U-net and DyAd on future
test set (left) and domain test set (right) of ocean currents."
REFERENCES,0.5879828326180258,"B
THEORETICAL ANALYSIS"
REFERENCES,0.5901287553648069,"The high-level idea of our method is to learn a good representation of the underlying dynamics from
multiple tasks, and then transfer this representation to a target task (domain adaptation)."
REFERENCES,0.592274678111588,Under review as a conference paper at ICLR 2022
REFERENCES,0.5944206008583691,"Figure 11: Left: Pairwise RMSEs between the averaged samples of different tasks in the turbulent
Ô¨Çow dataset. RMSE between the averaged samples is a lower bound of Wasserstein distance between
tasks. Right: DyAd+ResNet prediction RMSE breakdown on Ô¨Åve tasks in the domain test set."
REFERENCES,0.5965665236051502,"Table 4: We test that our design results in time-invariance (low time-shift error). The scaled time-shift
errors with and without time-shift invariant loss on the turbulent Ô¨Çow dataset are shown in the table."
REFERENCES,0.5987124463519313,"With time-shift loss
Without time-shift loss"
REFERENCES,0.6008583690987125,"Scaled Time Shift Error
6.67e-10
1.56e-05"
REFERENCES,0.6030042918454935,"Table 5: We tested concatenating zc to the input of the forecaster (concat input), using zc as the
kernels of the forecaster (Kernel Gen), concatenating zc to the hidden states (concat hidden), adding
zc to the hidden states(Sum), using zc as the biases in the convolutional layers (Bias). AdaIN worked
better than any alternative we tested."
REFERENCES,0.6051502145922747,"RMSE
AdaIN
Concat Input
Kernel Gen
Concat Hidden
Sum
Bias"
REFERENCES,0.6072961373390557,"future
0.423
1.085
0.782
0.746
0.804
0.843
domain
0.513
0.826
0.777
0.735
0.800
0.778"
REFERENCES,0.6094420600858369,"DeÔ¨Ånition 1 (Forecasting task). Each forecasting task xt+1 = f(xt, . . . ) is to learn a conditional
distribution ¬µ over the system states ¬µ : p(xt+1|xt, . . . ) conditioned on the sequence of previous
states where ¬µ is a probability measure."
REFERENCES,0.6115879828326181,"In our setting, we have K tasks, each of which is sampled from a continuous, Ô¨Ånite space {ck} ‚àºC.
Let ¬µk be the corresponding conditional probability measure p(xt, . . . , x1|ck). For each task ck, we
have a collection of n series as realizations from the dynamical system Xk = {(xt, . . . , x1; ck)(i)}n
i=1
sampled from ¬µk. The semicolon here represents the system behavior in a speciÔ¨Åc domain ck. Let
X = S"
REFERENCES,0.6137339055793991,"k
Xk be the union of samples over all tasks."
REFERENCES,0.6158798283261803,"In practice, we often have some intuition of the variables that dictate the domain. Therefore, we have
two possible scenarios for the role of c in dynamical systems:"
REFERENCES,0.6180257510729614,"1. c fully distinguishes the task: the differences in Xk can be completely explained by the
differences in ck;"
REFERENCES,0.6201716738197425,"2. c partially distinguishes the task: a more realistic scenario where we only have partial
knowledge of the domain. There exist latent variables z‚Ä≤ that need to be inferred from raw
data. Together z = [c, z‚Ä≤] can describe the behavior of the system in a domain."
REFERENCES,0.6223175965665236,Under review as a conference paper at ICLR 2022
REFERENCES,0.6244635193133047,"We assume Scenario 1, which resembles the multi-task representation learning setting (Maurer et al.,
2016) with joint true risk over all tasks œµ and individual task true risk œµk deÔ¨Åned respectively"
REFERENCES,0.6266094420600858,"œµ(f) = 1 K K
X"
REFERENCES,0.628755364806867,"k=1
œµk(f),
œµk(f) = Ex(i)
k ‚àº¬µk"
REFERENCES,0.630901287553648,"h
l

f

x(i)
k
i
(4)"
REFERENCES,0.6330472103004292,and corresponding empirical risks
REFERENCES,0.6351931330472103,"ÀÜœµ(f, X) = 1 K K
X"
REFERENCES,0.6373390557939914,"k=1
ÀÜœµk(f, Xk),
ÀÜœµk(f, Xk) = l(f(Xk)),"
REFERENCES,0.6394849785407726,where l is a loss function.
REFERENCES,0.6416309012875536,"B.1
MULTI-TASK LEARNING ERROR"
REFERENCES,0.6437768240343348,"We want to bound the true loss œµ using the empirical loss ÀÜœµ and Rademacher complexity of the
hypothesis class F. We can use the classic results from Ando et al. (2005). DeÔ¨Åne empirical
Rademacher complexity for samples from all tasks as"
REFERENCES,0.6459227467811158,"ÀÜRX(F) = EœÉ """
REFERENCES,0.648068669527897,"sup
f‚ààF"
NK,0.6502145922746781,"1
nK K
X k=1 n
X"
NK,0.6523605150214592,"i=1
œÉ(i)
k l(f(x(i)
k )) !# (5)"
NK,0.6545064377682404,"where {œÉ(i)
k } are independent binary variables œÉ(i)
k
‚àà{‚àí1, 1}. The true Rademacher complexity is
then deÔ¨Åned R(F) = EX( ÀÜRX(F))."
NK,0.6566523605150214,"The following theorem restates the main result from Ando et al. (2005). We simplify the statement by
using Rademacher complexity rather than the set cover number argument used in the original proof.
Theorem B.1. Ando et al. (2005) Given data from K different forecasting tasks ¬µ1, ¬∑ ¬∑ ¬∑ , ¬µk and f
in hypothesis class F, for some constant C with probability at least 1 ‚àíŒ¥, the following inequality
holds:"
K,0.6587982832618026,"1
K X"
K,0.6609442060085837,"k
œµk(f) ‚â§1 K X"
K,0.6630901287553648,"k
ÀÜœµk(f) + 2R(F) + C r"
K,0.6652360515021459,log 1/Œ¥
K,0.6673819742489271,"nK
.
(6)"
K,0.6695278969957081,"If we assume the loss is bounded l ‚â§1/2, then we may take C = 1/
‚àö 2."
K,0.6716738197424893,"Proof. Consider {x(i)
k } as independent random variables. For a function œÜ that satisÔ¨Åes"
K,0.6738197424892703,"|œÜ(x(1), ¬∑ ¬∑ ¬∑ , x(i), ¬∑ ¬∑ ¬∑ x(n)) ‚àíœÜ(x(1), ¬∑ ¬∑ ¬∑ , Àúx(i), ¬∑ ¬∑ ¬∑ x(n))| ‚â§ci"
K,0.6759656652360515,"by McDiarmid‚Äôs inequality, we have"
K,0.6781115879828327,"p

œÜ(x(1), ¬∑ ¬∑ ¬∑ , x(n)) ‚àíE[œÜ] ‚â•t

‚â§exp

‚àí2t2 P"
K,0.6802575107296137,"i c2
i 
."
K,0.6824034334763949,"Applying this inequality to the max difference Q(X) = supf‚ààF[œµ(f)‚àíÀÜœµ(f, X)], then with probability
at least 1 ‚àíŒ¥, we have"
K,0.6845493562231759,Q(X) ‚àíEX[Q(X)] ‚â§C r
K,0.6866952789699571,log 1/Œ¥
K,0.6888412017167382,"nK
where C is a constant depending on the bounds ci. If the loss l ‚â§1/2, then |Q| ‚â§1/2 and so we can
take ci = 1 leading to C = 1/
‚àö"
K,0.6909871244635193,"2. A standard computation (see Mohri et al. (2018), Theorem 3.3)
using the law of total expectation shows EX[Q(X)] ‚â§2R(F), which Ô¨Ånishes the proof."
K,0.6931330472103004,"We can use this to compare the generalization error of multi-task learning versus that of learning
the individual tasks. The following inequality compares the Rademacher complexity for multi-task
learning to that of individual task learning. Denote ÀÜRXk and Rk the empirical and true Rademacher
complexity for F over ¬µk."
K,0.6952789699570815,Under review as a conference paper at ICLR 2022
K,0.6974248927038627,"Lemma B.2. The Rademacher complexity for multi-task learning is bounded R(F)
‚â§
(1/K) PK
k=1 Rk(F)."
K,0.6995708154506438,"Proof. We compute the empirical Rademacher complexity,"
K,0.7017167381974249,"ÀÜRX(F) = EœÉ """
K,0.703862660944206,"sup
f‚ààF"
NK,0.7060085836909872,"1
nK K
X k=1 n
X"
NK,0.7081545064377682,"i=1
œÉ(i)
k l

f

x(i)
k
!# ‚â§EœÉ "" K
X"
NK,0.7103004291845494,"k=1
sup
f‚ààF"
NK,0.7124463519313304,"1
nK n
X"
NK,0.7145922746781116,"i=1
œÉ(i)
k l

f

x(i)
k
!# = 1 K K
X"
NK,0.7167381974248928,"k=1
EœÉ """
NK,0.7188841201716738,"sup
f‚ààF"
N,0.721030042918455,"1
n n
X"
N,0.723175965665236,"i=1
œÉ(i)
k l

f

x(i)
k
!# = 1 K K
X"
N,0.7253218884120172,"k=1
EœÉk """
N,0.7274678111587983,"sup
f‚ààF"
N,0.7296137339055794,"1
n n
X"
N,0.7317596566523605,"i=1
œÉ(i)
k l

f

x(i)
k
!# = 1 K K
X"
N,0.7339055793991416,"k=1
ÀÜRXk(F)"
N,0.7360515021459227,"The Ô¨Årst inequality follows from the sub-additivity of the supremum function. The next equality is
due to the fact positive scalars commute with supremum, and by the linearity of expectation. The
expectation EœÉ reduces to the expectation EœÉk over only those Rademacher variables appearing
inside the expectation. Rk(F) is the Rademacher complexity of the function on the individual task k.
Taking expectation over all samples X gives the result."
N,0.7381974248927039,"It is instructive to compare the bound from Theorem B.1 with the generalization error bound obtained
by considering each task individually.
Proposition B.3. Assume n = nk for all tasks k and the loss l is bounded l ‚â§1/2, then the
generalization bound given by considering each task individually is"
N,0.740343347639485,œµ(f) ‚â§ÀÜœµ(f) + 2
K,0.7424892703862661,"1
K K
X"
K,0.7446351931330472,"k=1
Rk(F) ! + r"
K,0.7467811158798283,log 1/Œ¥
N,0.7489270386266095,"2n
.
(7)"
N,0.7510729613733905,which is strictly looser than the bound from Theorem B.1 under the same assumptions.
N,0.7532188841201717,"This result helps to explain why our multitask learning framework has better generalization than
learning each task independently. The shared data tightens the generalization bound."
N,0.7553648068669528,"Proof. Applying the classical analog of Theorem B.1 to a single task, we Ô¨Ånd with probability greater
than 1 ‚àíŒ¥,"
N,0.7575107296137339,œµk(f) ‚â§ÀÜœµk(f) + 2Rk(F) + Ck r
N,0.759656652360515,"log 1/Œ¥ n
."
N,0.7618025751072961,Averaging over all tasks yields
K,0.7639484978540773,"1
K K
X"
K,0.7660944206008584,"k=1
œµk(f) ‚â§1 K K
X"
K,0.7682403433476395,"k=1
ÀÜœµk(f) + 2 1 K K
X"
K,0.7703862660944206,"k=1
Rk(F) + 1 K K
X"
K,0.7725321888412017,"k=1
Ck r"
K,0.7746781115879828,"log 1/Œ¥ n
."
K,0.776824034334764,"Since the loss l is bounded l ‚â§1/2, we can take C = Ck = 1/
‚àö"
K,0.778969957081545,"2, giving the generalization upper
bound for the joint error of Equation 7."
K,0.7811158798283262,"By Lemma B.2 and the fact 1/
‚àö"
K,0.7832618025751072,"2nK ‚â§1/
‚àö"
K,0.7854077253218884,"2n, the bound in Theorem B.1 is strictly tighter."
K,0.7875536480686696,"Gap Between Bounds. To quantify how much tighter the bound of Theorem B.1 is relative to
Proposition B.3, we compute the difference in upper bounds. Assuming l ‚â§1/2, the gap between
the bounds is,"
K,0.7896995708154506,ÀÜœµ(f) + 2
K,0.7918454935622318,"1
K K
X"
K,0.7939914163090128,"k=1
Rk(F) ! + r"
K,0.796137339055794,log 1/Œ¥
N,0.7982832618025751,2n ! ‚àí 
N,0.8004291845493562,ÀÜœµ(f) + 2R(F) + r
N,0.8025751072961373,log 1/Œ¥
NK,0.8047210300429185,2nK ! =2
K,0.8068669527896996,"1
K K
X"
K,0.8090128755364807,"k=1
Rk(F) ‚àíR(F) !"
K,0.8111587982832618,"+

1 ‚àí1/
‚àö K
 r"
K,0.8133047210300429,log 1/Œ¥
N,0.8154506437768241,"2n
."
N,0.8175965665236051,Under review as a conference paper at ICLR 2022
N,0.8197424892703863,Simplifying gives 2
K,0.8218884120171673,"1
K K
X"
K,0.8240343347639485,"k=1
Rk(F) ‚àíR(F) ! + ‚àö"
K,0.8261802575107297,"K ‚àí1
‚àö K ! r"
K,0.8283261802575107,log 1/Œ¥
N,0.8304721030042919,"2n
."
N,0.8326180257510729,"The Ô¨Årst term is positive by Lemma B.2 and second term is positive since
‚àö K ‚â•1."
N,0.8347639484978541,"B.2
DOMAIN ADAPTATION ERROR"
N,0.8369098712446352,"Since we test on c ‚àºC outside the training set {ck}, we incur error due to domain adaptation from
the source domains ¬µc1, . . . , ¬µcK to target domain ¬µc with ¬µ being the true distribution. Denote the
corresponding empirical distributions of n samples per task by ÀÜ¬µc =
1
nc
Pnc
i=1 Œ¥x(i)
c . For different c
and c‚Ä≤, the domains ¬µc and ¬µc‚Ä≤ may have largely disjoint support, leading to very high KL divergence.
However, if c and c‚Ä≤ are close, samples xc ‚àº¬µc and xc‚Ä≤ ‚àº¬µc‚Ä≤ may be close in the domain X with
respect to the metric ‚à•¬∑ ‚à•X . For example, if the external forces c and c‚Ä≤ are close, given xc ‚àº¬µc there
is likely xc‚Ä≤ ‚àº¬µc‚Ä≤ such that the distance between the velocity Ô¨Åelds ‚à•xc ‚àíxc‚Ä≤‚à•is small. This implies
the distributions ¬µc and ¬µc‚Ä≤ may be be close in Wasserstein distance W1(¬µc, ¬µc‚Ä≤). The bound from
Redko et al. (2017) applies well to our setting as such:"
N,0.8390557939914163,"Theorem B.4 (Redko et al. (2017), Theorem 2). Let Œªc = minf‚ààF

œµc(f) + 1/K PK
k=1 œµck(f)

."
N,0.8412017167381974,"There is N = N(dim(X)) such that for n > N, for any hypothesis f, with probability at least 1 ‚àíŒ¥,"
N,0.8433476394849786,"œµc(f) ‚â§1 K K
X"
N,0.8454935622317596,"k=1
œµck(f) + W1 "
N,0.8476394849785408,"ÀÜ¬µc, 1 K K
X"
N,0.8497854077253219,"k=1
ÀÜ¬µck ! +
p"
N,0.851931330472103,"2 log(1/Œ¥)
p"
N,0.8540772532188842,"1/n +
p"
N,0.8562231759656652,"1/(nK)

+ Œªc."
N,0.8583690987124464,"Proof. We apply Redko et al. (2017) Theorem 2 to target domain ¬µT = ¬µc and joint source domain
¬µS = 1/K PK
k=1 ¬µck with empirical samples ÀÜ¬µT = ÀÜ¬µc and ÀÜ¬µS = 1/K PK
k=1 ÀÜ¬µck."
N,0.8605150214592274,"B.3
ENCODER VERSUS PREDICTION NETWORK ERROR"
N,0.8626609442060086,"Our goal is to learn a joint hypothesis h over the entire domain X in two steps, Ô¨Årst inferring the task
c and then inferring xt+1 conditioned on c. Error from DyAd may result from either the encoder gœÜ
or the prediction network fŒ∏. Our hypothesis space has the form {x 7‚ÜífŒ∏(x, gœÜ(x))} where œÜ and
Œ∏ are the weights of the encoder and prediction network respectively. Let œµX be the error over the
entire domain X, that is, for all c. Let œµenc(gœÜ) = Ex‚àºX (L1(g(x), gœÜ(x)) be the encoder error where
g: X ‚ÜíC is the ground truth. We state a result that decomposes the Ô¨Ånal error into that attributable
to the encoder and that to the prediction network.
Proposition B.5. Assume c 7‚ÜífŒ∏(¬∑, c) is Lipschitz continuous with Lipschitz constant Œ≥ uniformly in
Œ∏. Then we bound
œµX (fŒ∏(¬∑, gœÜ(¬∑))) ‚â§Œ≥œµenc(gœÜ) + Ec‚àºC [œµc(fŒ∏(x, c))]
(8)
where the Ô¨Årst term is the error due to the encoder incorrectly identifying the task and the second
term is the error due the prediction network alone."
N,0.8648068669527897,"The hypothesis in the second term consists of the prediction network combined with the ground truth
task label x 7‚ÜífŒ∏(x, g(x))."
N,0.8669527896995708,"Proof. By the triangle inequality and linearity of expectation,"
N,0.869098712446352,"œµX (fŒ∏(¬∑, gœÜ(¬∑))) = Ec‚àºC [Ex‚àº¬µc [‚à•fŒ∏(x, gœÜ(x)) ‚àíf(x)‚à•Y]]
‚â§Ec‚àºC [Ex‚àº¬µc [‚à•fŒ∏(x, gœÜ(x)) ‚àífŒ∏(x, c)‚à•Y]] + Ec‚àºC [Ex‚àº¬µc [‚à•fŒ∏(x, c)‚à•Y ‚àí‚à•f(x)‚à•Y]] ."
N,0.871244635193133,"By Lipschitz continuity,"
N,0.8733905579399142,"‚â§Ec‚àºC [Ex‚àº¬µc [Œ≥‚à•gœÜ(x) ‚àíc‚à•C]] + Ec‚àºC [Ex‚àº¬µc [‚à•fŒ∏(x, c)‚à•Y ‚àí‚à•f(x)‚à•Y]] ,"
N,0.8755364806866953,"which, since g(x) = c and by linearity of expectation,"
N,0.8776824034334764,"= Œ≥Ec‚àºC [Ex‚àº¬µc [‚à•gœÜ(x) ‚àíg(x)‚à•C]] + Ec‚àºC [Ex‚àº¬µc [‚à•fŒ∏(x, c)‚à•Y ‚àí‚à•f(x)‚à•Y]]"
N,0.8798283261802575,Under review as a conference paper at ICLR 2022
N,0.8819742489270386,"and by deÔ¨Ånition of œµenc and œµc,"
N,0.8841201716738197,"= Œ≥œµenc(gœÜ) + Ec‚àºC [œµc(fŒ∏(x, c))]"
N,0.8862660944206009,as desired.
N,0.8884120171673819,"By combining Theorem B.1, Proposition B.5, and Theorem B.4, we can bound the generalization
error in terms of the empirical error of the prediction network on the source domains, the Wasserstein
distance between the source and target domains, and the empirical error of the encoder."
N,0.8905579399141631,"Let G = {gœÜ : X ‚ÜíC} be the task encoder hypothesis space. Denote the empirical risk of the
encoder gœÜ with respect to X by ÀÜœµenc(gœÜ)."
N,0.8927038626609443,"Proposition B.6. Assuming the hypotheses of Theorem B.1, Proposition B.5, and Theorem B.4,"
N,0.8948497854077253,"œµX (fŒ∏(¬∑, gœÜ(¬∑))) ‚â§Œ≥ÀÜœµenc(gœÜ) + 1 K K
X"
N,0.8969957081545065,"k=1
ÀÜœµck(fŒ∏(¬∑, ck)) + 2Œ≥R(G) + 2R(F)"
N,0.8991416309012875,+ (Œ≥ + 1) r
N,0.9012875536480687,log(1/Œ¥)
NK,0.9034334763948498,"2nK
+
p"
NK,0.9055793991416309,"2 log(1/Œ¥)
p"
NK,0.907725321888412,"1/n +
p"
NK,0.9098712446351931,"1/(nK)
"
NK,0.9120171673819742,"+ Ec‚àºC "" W1 "
NK,0.9141630901287554,"ÀÜ¬µc, 1 K K
X"
NK,0.9163090128755365,"k=1
ÀÜ¬µck ! + Œªc # ."
NK,0.9184549356223176,"Proof. We start with the bound of Proposition B.5,"
NK,0.9206008583690987,"œµX (fŒ∏(¬∑, gœÜ(¬∑))) ‚â§Œ≥œµenc(gœÜ) + Ec‚àºC [œµc(fŒ∏(x, c))] .
(9)"
NK,0.9227467811158798,"By Theorem B.1 or Mohri et al. (2018), Theorem 3.3, we can bound"
NK,0.924892703862661,œµenc(gœÜ) ‚â§ÀÜœµenc(gœÜ) + 2R(G) + r
NK,0.927038626609442,log(1/Œ¥)
NK,0.9291845493562232,"2nK
.
(10)"
NK,0.9313304721030042,"In order to apply Theorem B.1 to the risk œµc and relate it to the empirical risk, we need to Ô¨Årst relate
the error on the target domain back to the source domain of our empirical samples. By Theorem B.4,"
NK,0.9334763948497854,"œµc(fŒ∏(¬∑, c)) ‚â§1 K K
X"
NK,0.9356223175965666,"k=1
œµck(fŒ∏(¬∑, ck))+W1 "
NK,0.9377682403433476,"ÀÜ¬µc, 1 K K
X"
NK,0.9399141630901288,"k=1
ÀÜ¬µck ! +
p"
NK,0.9420600858369099,"2 log(1/Œ¥)
p"
NK,0.944206008583691,"1/n +
p"
NK,0.9463519313304721,"1/(nK)

+Œªc."
NK,0.9484978540772532,"(11)
Applying Theorem B.1, this is ‚â§1 K K
X"
NK,0.9506437768240343,"k=1
ÀÜœµck(fŒ∏(¬∑, ck))+2R(F)+ r"
NK,0.9527896995708155,log 1/Œ¥
NK,0.9549356223175965,2nK +W1 
NK,0.9570815450643777,"ÀÜ¬µc, 1 K K
X"
NK,0.9592274678111588,"k=1
ÀÜ¬µck ! +
p"
NK,0.9613733905579399,"2 log(1/Œ¥)
p"
NK,0.9635193133047211,"1/n +
p"
NK,0.9656652360515021,"1/(nK)

+Œªc."
NK,0.9678111587982833,"(12)
Substituting equation 10 and equation 12 into equation 9 gives"
NK,0.9699570815450643,"œµX (fŒ∏(¬∑, gœÜ(¬∑))) ‚â§Œ≥ "
NK,0.9721030042918455,ÀÜœµenc(gœÜ) + 2R(G) + r
NK,0.9742489270386266,log(1/Œ¥)
NK,0.9763948497854077,2nK !
NK,0.9785407725321889,"+ Ec‚àºC ""
1
K K
X"
NK,0.98068669527897,"k=1
ÀÜœµck(fŒ∏(¬∑, ck)) + 2R(F) + r"
NK,0.9828326180257511,log 1/Œ¥
NK,0.9849785407725322,2nK + W1 
NK,0.9871244635193133,"ÀÜ¬µc, 1 K K
X"
NK,0.9892703862660944,"k=1
ÀÜ¬µck ! +
p"
NK,0.9914163090128756,"2 log(1/Œ¥)
p"
NK,0.9935622317596566,"1/n +
p"
NK,0.9957081545064378,"1/(nK)

+ Œªc # ."
NK,0.9978540772532188,"Finally using linearity of the expectation over c ‚àºC, removing it where there is no dependence on c,
and rearranging terms gives the result."
