Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0006784260515603799,"We present adaptive gradient methods (both basic and accelerated) for solving
convex composite optimization problems in which the main part is approximately
smooth (a.k.a. (δ, L)-smooth) and can be accessed only via a (potentially biased)
stochastic gradient oracle. This setting covers many interesting examples including
Hölder smooth problems and various inexact computations of the stochastic gradi-
ent. Our methods use AdaGrad stepsizes and are adaptive in the sense that they do
not require knowing any problem-dependent constants except an estimate of the
diameter of the feasible set but nevertheless achieve the best possible convergence
rates as if they knew the corresponding constants. We demonstrate that AdaGrad
stepsizes work in a variety of situations by proving, in a unified manner, three
types of new results. First, we establish efficiency guarantees for our methods in
the classical setting where the oracle’s variance is uniformly bounded. We then
show that, under more refined assumptions on the variance, the same methods
without any modifications enjoy implicit variance reduction properties allowing us
to express their complexity estimates in terms of the variance only at the minimizer.
Finally, we show how to incorporate explicit SVRG-type variance reduction into
our methods and obtain even faster algorithms. In all three cases, we present both
basic and accelerated algorithms achieving state-of-the-art complexity bounds. As
a direct corollary of our results, we obtain universal stochastic gradient methods
for Hölder smooth problems which can be used in all situations."
INTRODUCTION,0.0013568521031207597,"1
Introduction"
INTRODUCTION,0.0020352781546811396,"Motivation.
Gradient methods are among the most popular and efficient optimization algorithms
for solving machine learning problems. To achieve the best convergence speed for these algorithms,
their stepsizes needs to be chosen properly. While there exist various theoretical recommendations,
dictated by the convergence analysis, on how to select stepsizes based on various problem-dependent
parameters, they are usually impractical because the corresponding constants may be unknown or their
worst-case estimates might be too pessimistic. Furthermore, every applied problem usually belongs
to multiple problem classes at the same time, and it is not always evident in advance which of them
better suits the concrete problem instance one works with. For classical optimization algorithms, this
problem is typically resolved by using a line search. This is a simple yet powerful mechanism which
automatically chooses the best stepsize by checking at each iteration a certain condition involving the
objective value, its gradient, etc."
INTRODUCTION,0.0027137042062415195,"However, the line-search approach is usually unsuitable for problems of stochastic optimization,
where gradients are observed with random noise (unless some extra assumptions are made, see [57]).
For these problems, it is common instead to apply so-called adaptive methods which set up their"
INTRODUCTION,0.0033921302578018998,"∗CISPA Helmholtz Center for Information Security, Saarbrücken, Germany"
INTRODUCTION,0.004070556309362279,"stepsizes by simply accumulating on-the-fly certain information about observed stochastic gradients.
The first such an algorithm, AdaGrad [17, 39], was obtained from theoretical considerations but
quickly inspired several other heuristic methods like RMSProp [56] and Adam [32] that are now at
the forefront of training machine learning models."
INTRODUCTION,0.0047489823609226595,"Excellent practical performance of adaptive methods on various applied problems naturally sparked a
lot of theoretical interest in these algorithms. An important observation was done by Levy, Yurtsever,
and Cevher [34] who showed that AdaGrad possesses a certain universality property, in the sense
that it works for several problem classes simultaneously. Specifically, they showed that AdaGrad
converges both for nonsmooth problems with bounded gradient and also for smooth problems with
Lipschitz gradient, without needing to know neither the corresponding Lipschitz constants, nor
the oracle’s variance but enjoying the rates which are characteristic for algorithms which have the
knowledge of these constants. They also presented an accelerated version of AdaGrad with similar
properties. An independent version of the accelerated AdaGrad including diagonal scaling was
proposed by Deng, Cheng, and Lan [12]. Further improvements and generalization of these ideas
were considered in [18, 28, 30]."
INTRODUCTION,0.005427408412483039,"Nonsmooth and smooth problems are the extremes of the more general Hölder class of problems.
The fact that AdaGrad methods simultaneously work for these two extreme cases does not seem to be
a coincidence and suggests that these algorithms should work more generally for any problem with
intermediate level of smoothness. Some further confirmations to this were recently provided in [48]
although in a rather restricted setting of deterministic problems and only for the basic AdaGrad
method. The stochastic case and acceleration were constituting an open problem which was recently
resolved in [49] for a slightly modified AdaGrad stepsize (see (4))."
INTRODUCTION,0.006105834464043419,"All the previously discussed results were proved only for the classical stochastic optimization setting
where the variance of stochastic gradients is assumed to be uniformly bounded. In a recent work,
Attia and Koren [2] showed that the basic AdaGrad method for smooth problems works under the
more general assumption when the variance is bounded by a constant plus a multiple of the squared
gradient norm. On a related note, it was also shown recently that AdaGrad stepsizes can be used inside
gradient methods with SVRG-type variance-reduction. The first such an algorithm was proposed
in [16]. The accelerated SVRG method enjoying optimal worst-case oracle complexity for smooth
finite-sum optimization problems was later presented in [36]."
INTRODUCTION,0.0067842605156037995,"Contributions.
In this work, we further extend the results mentioned above by demonstrating that
AdaGrad stepsizes are even more universal than was shown previously in the literature. Specifically,
we consider the composite optimization problem where the main part is approximately smooth
(a.k.a. (δ, L)-smooth) and can be accessed only via a (potentially biased) stochastic gradient oracle.
This setting is more general than typically considered in the literature on adaptive methods and
covers many interesting examples, including smooth, nonsmooth and, more generally, Hölder smooth
problems, problems in which the objective function is given itself as another optimization problem
whose solution can be computed only approximately, etc."
INTRODUCTION,0.007462686567164179,Our contributions can be summarized as follows:
INTRODUCTION,0.008141112618724558,"1. We start, in Section 3, with identifying the key property of AdaGrad stepsizes, which allows us to
apply these stepsizes, in a unified manner, in a variety of situations we consider later. We present
our two mains algorithms, UniSgd and UniFastSgd which are the classical stochastic gradient
method (SGD) and its accelerated version, respectively, equipped with AdaGrad stepsizes.
2. We then establish, in Section 4, efficiency guarantees for these methods in the classical setting
where the oracle’s variance is assumed to be uniformly bounded.
3. In Section 5, we complement these results by showing that, under additional assumptions that
the variance is itself approximately smooth w.r.t. the objective function, the same UniSgd and
UniFastSgd without any modifications enjoy implicit variance reduction properties allowing us
to express their complexity estimates in terms of the variance only at the minimizer.
4. Under the additional assumption that one can periodically compute the full (inexact) gradient of
the objective function, we show, in Section 6, how to incorporate explicit SVRG-type variance
reduction into our methods, obtaining new UniSvrg and UniFastSvrg algorithms which enjoy
even faster convergence rates by completely eliminating the variance."
INTRODUCTION,0.008819538670284939,"Our results are summarized in Table 1 (in the BigO-notation). In all the situations, we present both
basic and accelerated algorithms whose only essential parameter is an estimate D of the diameter"
INTRODUCTION,0.009497964721845319,"Table 1: Summary of main results for solving problem (1) with our methods. “Convergence rate” is expressed in
terms of the expected function residual at iteration k (or t, depending on the method). “SO complexity” denotes
the cumulative stochastic-oracle complexity of the method since its start and up to iteration k (or t), which is
defined as the number of queries to the stochastic oracle pg; for SVRG methods, we assume that querying the
(inexact) full-gradient oracle sg is n times more expensive than pg, and define the SO complexity as Npg + nNsg,
where Npg and Nsg are the number of queries to pg and sg, respectively. The second and third columns should be
understood in terms of the BigO-notation which we omit for brevity."
INTRODUCTION,0.0101763907734057,"Method
Convergence rate
SO complexity
Assumptions
Reference"
INTRODUCTION,0.010854816824966078,UniSgd (Alg. 1) Lf D2
INTRODUCTION,0.011533242876526458,"k
+ σD
√"
INTRODUCTION,0.012211668928086838,"k + δf
k
1, 2, 3
Thm. 4"
INTRODUCTION,0.012890094979647219,(Lf +Lpg)D2
INTRODUCTION,0.013568521031207599,"k
+ σ∗D
√"
INTRODUCTION,0.014246947082767978,"k + δf + δpg
1, 2, 6
Thm. 7"
INTRODUCTION,0.014925373134328358,UniFastSgd (Alg. 2) Lf D2
INTRODUCTION,0.015603799185888738,"k2
+ σD
√"
INTRODUCTION,0.016282225237449117,"k + kδf
k
1, 2, 3
Thm. 5 Lf D2"
INTRODUCTION,0.016960651289009497,"k2
+
LpgD2"
INTRODUCTION,0.017639077340569877,"k
+ σ∗D
√"
INTRODUCTION,0.018317503392130258,"k + kδf + δpg
1, 2, 6
Thm. 8"
INTRODUCTION,0.018995929443690638,"UniSvrg (Alg. 3)
(Lf +Lpg)D2"
T,0.01967435549525102,"2t
+ δf + δpg
2t + n log t
1, 2, 6, 9
Thm. 10"
T,0.0203527815468114,"UniFastSvrg (Alg. 4)
(Lf +Lpg)D2"
T,0.02103120759837178,"n(t−log log n)2 + t(δf + δpg)
nt
1, 2, 6
Thm. 11"
T,0.021709633649932156,"of the feasible set; the methods automatically adapt to all other problem-dependent constants. In
a number of special cases, our algorithms achieve known state-of-the-art complexity bounds, but
not restricted to those special cases. In Section 7, we illustrate the significance of our results by
demonstrating that complexities for our methods on stochastic optimization problems with Hölder
smooth components can be obtained as simple corollaries from our main results."
PRELIMINARIES,0.022388059701492536,"2
Preliminaries"
PRELIMINARIES,0.023066485753052916,"Notation.
We work in the space Rd equipped with the standard inner product ⟨·, ·⟩and a certain
Euclidean norm: ∥x∥:= ⟨Bx, x⟩1/2, where B is a fixed positive definite matrix. The dual norm is
defined in the standard way: ∥s∥∗:= max∥x∥=1⟨s, x⟩= ⟨s, B−1s⟩1/2."
PRELIMINARIES,0.023744911804613297,"For a convex function ψ: Rd →R ∪{+∞}, its (effective) domain is the following set: dom ψ :=
{x ∈Rd : ψ(x) < +∞}. By ∂ψ(x), we denote the subdifferential of ψ at a point x ∈dom ψ; the
specific subgradients are typically denoted by ∇ψ(x)."
PRELIMINARIES,0.024423337856173677,"A convex function f : Rd →R is called (ν, H)-Hölder smooth for some ν ∈[0, 1] and H ≥0 iff
∥∇f(x) −∇f(y)∥∗≤H∥x −y∥ν for all x, y ∈Rd and all ∇f(x) ∈∂f(x), ∇f(y) ∈∂f(y).
Apart from the special case of ν = 0, such a function f is differentiable at every point, i.e., ∂f(x) is
a singleton. A (1, L)-Hölder smooth function is usually called L-smooth."
PRELIMINARIES,0.025101763907734057,"For a convex function ψ: Rd →R∪{+∞}, point x ∈Rd, vector g ∈Rd, and coefficient M ≥0, by
Proxψ(x, g, M) := argminy∈dom ψ{⟨g, y⟩+ψ(y)+ M"
PRELIMINARIES,0.025780189959294438,"2 ∥y −x∥2}, we denote the proximal mapping.
When M = 0, we allow the solution to be chosen arbitrarily."
PRELIMINARIES,0.026458616010854818,"For a convex function f : Rd →R, points x, y ∈Rd and ∇f(x) ∈∂f(x), we denote the Bregman
distance by β∇f(x)
f
(x, y) := f(y) −f(x) −⟨∇f(x), y −x⟩(≥0). When the specific subgradient
∇f(x) is clear from the context, we use the simplified notation βf(x, y)."
PRELIMINARIES,0.027137042062415198,"The positive part of t ∈R is [t]+ := max{t, 0}. For τ > 0, we also use log+ τ := max{1, log τ}."
PRELIMINARIES,0.027815468113975575,"Problem Formulation.
In this paper, we consider the composite optimization problem"
PRELIMINARIES,0.028493894165535955,"F ∗:=
min
x∈dom ψ

F(x) := f(x) + ψ(x)

,
(1)"
PRELIMINARIES,0.029172320217096336,"where f : Rd →R is a convex function, and ψ: Rd →R ∪{+∞} is a proper closed convex function
which is assumed to be sufficiently simple in the sense that the proximal mapping Proxψ can be
easily computed. We assume that this problem has a solution which we denote by x∗."
PRELIMINARIES,0.029850746268656716,"To quantify the smoothness level of the objective function, we use the following assumption:"
PRELIMINARIES,0.030529172320217096,"Algorithm 1 (sxN, xN, MN) ∼= UniSgdpg,ψ(x0, M0, N; D)"
PRELIMINARIES,0.031207598371777476,"Input: Oracle pg, comp. part ψ, point x0 ∈dom ψ, coefficient M0, iteration limit N, diameter D."
PRELIMINARIES,0.03188602442333786,"1: g0 ∼= pg(x0).
2: for k = 0, . . . , N −1 do
3:
xk+1 = Proxψ(xk, gk, Mk), gk+1 ∼= pg(xk+1).
4:
Mk+1 = M+(Mk, D2, xk, xk+1, gk, gk+1)
▷e.g.,
(3)
=
q"
PRELIMINARIES,0.032564450474898234,"M 2
k +
1
D2 ∥gk+1 −gk∥2∗."
PRELIMINARIES,0.03324287652645862,"5: return (sxN, xN, MN), where sxN :=
1
N
PN
i=1 xi."
PRELIMINARIES,0.033921302578018994,"Assumption 1. The function f in problem (1) is approximately smooth: there exist constants
Lf, δf ≥0 and sf : Rd →R, sg: Rd →Rd such that, for any x, y ∈Rd, βf, sf,sg(x, y) := f(y) −
sf(x) −⟨sg(x), y −x⟩satisfies the following inequality: 0 ≤βf, sf,sg(x, y) ≤Lf"
PRELIMINARIES,0.03459972862957938,2 ∥x −y∥2 + δf.
PRELIMINARIES,0.035278154681139755,"Assumption 1 is well-known in the literature under the name (δ, L)-oracle and was originally
introduced in [15]. It covers many interesting examples. For instance, if f is L-smooth, then
Assumption 1 is satisfied with sf = f, sg = ∇f, δf = 0 and Lf = L. More generally, if the function f
is (ν, Hf(ν))-Hölder smooth, then Assumption 1 is satisfied with sf = f, sg = ∇f (arbitrary selection
of subgradients), any δf > 0 and Lf := [
1−ν
2(1+ν)δf ]
1−ν
1+ν [Hf(ν)]
2
1+ν (see Theorem 13). If f can be
uniformly approximated by an L-smooth function ϕ, i.e., ϕ(x) ≤f(x) ≤ϕ(x)+δ, then Assumption 1
is satisfied with sf = ϕ, sg = ∇ϕ and δf = δ. If f represents another auxiliary optimization problem
with a strongly concave objective, e.g., f(x) = maxu Ψ(x, u), whose solution su(x) can only be found
with accuracy δ, then f satisfies Assumption 1 with sf(x) = Ψ(x, su(x)), sg(x) = ∇uΨ(x, su(x)) and
δf = δ. For more details and other interesting examples, we refer the reader to [15]."
PRELIMINARIES,0.03595658073270014,"In what follows, we assume that we have access to an unbiased stochastic oracle pg for sg. Formally,
this is a pair pg = (g, ξ) consisting of a random variable ξ and a mapping g: Rd × Im ξ →Rd
(with Im ξ being the image of ξ). When queried at a point x, the oracle automatically generates an
independent copy ξ of its randomness and then returns pgx = g(x, ξ) (notation: pgx ∼= pg(x)). We call
g and ξ the function component and the random variable component of pg, respectively. At this point,
we only assume that our stochastic oracle pg is un unbiased estimator of sg, and later make various
assumptions on its variance."
PRELIMINARIES,0.036635006784260515,"Another important assumption on problem (1), that we need in our analysis, is the boundedness of
the feasible set dom ψ.
Assumption 2. There exists D > 0 such that ∥x −y∥≤D for any x, y ∈dom ψ."
PRELIMINARIES,0.03731343283582089,"Assumption 2 is rather standard in the literature on adaptive methods for stochastic convex op-
timization (see [16, 18, 30, 34, 36, 49]) and can always be ensured with D = 2R0 whenever
one has the knowledge of an upper bound R0 on the distance from the initial point x0 to the so-
lution x∗. To that end, it suffices to rewrite the problem (1) in the following equivalent form:
minx∈dom ψD[f(x) + ψD(x)], where ψD is the sum of ψ and the indicator function of the ball
B0 := {x ∈Rd : ∥x −x0∥≤R0}. Note that this transformation keeps the function ψD reasonably
simple as its proximal mapping can be computed via that of ψ by solving a certain one-dimensional
nonlinear equation, which can be done very efficiently by Newton’s method (at no extra queries to the
stochastic oracle); in some special cases, the corresponding nonlinear equation can even be solved
analytically, e.g., when ψ = 0, the proximal mapping of ψD is simply the projection on B0."
PRELIMINARIES,0.037991858887381276,"Throughout this paper, we refer to D from Assumption 2 as the diameter of the feasible set, and
assume that its value is known to us. This will be the only essential parameter in our methods."
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.03867028493894165,"3
Main Algorithms and Stepsize Update Rules"
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.03934871099050204,"We now present our two main algorithms for solving problem (1): UniSgd (Algorithm 1), and
its accelerated version, UniFastSgd (Algorithm 2). Except the specific choice of the stepsize
coefficients Mk, both algorithms are rather standard: the first one is the classical SGD method, and
the second one is the classical accelerated gradient method for stochastic optimization [33], also
known as the Method of Similar Triangles (see, e.g., Section 6.1.3 in [46])."
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.04002713704206241,"Both methods are expressed in terms of a certain abstract stepsize update rule M+(·) defined as
follows. Given the current stepsize coefficient M ≥0, constant Ω> 0 (the scaled squared diameter),"
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.0407055630936228,"Algorithm 2 UniFastSgdpg,ψ(x0; D)"
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.041383989145183174,"Input: Stochastic oracle pg, composite part ψ, point x0 ∈dom ψ, diameter D."
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.04206241519674356,"1: v0 = x0, M0 = A0 = 0.
2: for k = 0, 1, . . . do
3:
ak+1 = 1"
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.042740841248303935,"2(k + 1), Ak+1 = Ak + ak+1.
4:
yk =
Ak
Ak+1 xk +
ak+1
Ak+1 vk, gyk ∼= pg(yk)."
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.04341926729986431,"5:
vk+1 = Proxψ(vk, gyk,
Mk
ak+1 )."
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.044097693351424695,"6:
xk+1 =
Ak
Ak+1 xk +
ak+1
Ak+1 vk+1, gxk+1 ∼= pg(xk+1)."
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.04477611940298507,"7:
Mk+1 =
a2
k+1
Ak+1 M+
  Ak+1"
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.045454545454545456,"a2
k+1 Mk,
a2
k+1
A2
k+1 D2, yk, xk+1, gyk, gxk+1

▷e.g.,
(3)
= r"
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.04613297150610583,"M 2
k +
a2
k+1
D2 ∥gxk+1 −gyk ∥2∗."
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.046811397557666216,"current point x ∈dom ψ with the stochastic gradient pgx ∼= pg(x), next iterate px+ = x+(pgx) ∈dom ψ
(which is the result of the deterministic function applied to pgx), and the corresponding stochastic
gradient pgx+ ∼= pg(px+), the update rule computes x
M+ = M+(M, Ω, x, px+, pgx, pgx+) (deterministic
function of its arguments) such that x
M+ ≥M and the following inequality holds for any Ď
M > c2Lf:"
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.04748982360922659,"E[p∆(x
M+) + (x
M+ −M)Ω+ βf, sf,sg(px+, x)]"
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.04816824966078698,"≤
c1
Ď
M −c2Lf
E[Varpg(px+) + Varpg(x)] + c3δf + c4 E

[min{x
M+, Ď
M} −M]+Ω
	
,
(2)"
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.048846675712347354,"where p∆(x
M+) := βf, sf,sg(x, px+)+⟨sg(x)−pgx, px+ −x⟩−
x
M+"
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.04952510176390773,"2 ∥px+ −x∥2, c1, c2, c3, c4 > 0 are some
absolute constants, and Varpg(x) := Eξ[∥g(x, ξ) −sg(x)∥2
∗] is the variance of pg. The expectations
in (2) are taken w.r.t. the randomness (ξ, ξ+) coming from pgx ≡g(x, ξ), pgx+ ≡g(px+, ξ+)."
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.050203527815468114,The main example is the following AdaGrad rule:
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.05088195386702849,"x
M+ = r"
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.051560379918588875,M 2 + 1
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.05223880597014925,"Ω∥pgx+ −pgx∥2∗.
(3)"
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.052917232021709636,"For this rule, we have c1 = 5"
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.05359565807327001,"2, c2 = 4, c3 = 6, c4 = 2 (see Lemma 20). Another interesting example
recently suggested in [49] is x
M+ found from the equation"
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.054274084124830396,"(x
M+ −M)Ω=
h
⟨pgx+ −pgx, px+ −x⟩−
x
M+"
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.05495251017639077,2 ∥px+ −x∥2i
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.05563093622795115,"+.
(4)"
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.056309362279511534,"This equation admits a unique solution which can be easily written down in closed form (see
Lemma E.1 in [49]). For this rule, we have c1 = 1, c2 = 2, c3 = 6, c4 = 2 (see Lemma 21)."
MAIN ALGORITHMS AND STEPSIZE UPDATE RULES,0.05698778833107191,"Inequality (2) is the only property we need from the stepsize update rule to establish all forthcoming
results. This inequality is exactly what is typically used inside the convergence proofs for stochastic
gradient methods with predefined stepsizes Mk ≡Ď
M (in which case M = x
M+ = Ď
M), where
Ď
M depends on problem-dependent constants. The key property of AdaGrad stepsizes (either (3)
or (4)) is that they ensure the same inequality but now Ď
M is the virtual stepsize existing only
in the theoretical analysis. The price for this is the extra error term [min{x
M+, Ď
M} −M]+Ω
appearing in the right-hand side of (2). The crucial property of this error term is that it is telescopic,
Pk
i=0[min{Mi+1, Ď
M} −Mi]+Ω= [min{Mk+1, Ď
M} −M0]+Ω(see Lemma 18) and therefore its
total cumulative impact is always bounded by the controllable constant Ď
MΩ. Although a number of
other works on theoretical analysis of AdaGrad methods for smooth optimization use some similar
ideas about the virtual stepsize (e.g., [30, 34, 36]), this is the first time one has abstracted away all the
technical details and identified the specific inequality (2) responsible for the universality of AdaGrad."
UNIFORMLY BOUNDED VARIANCE,0.057666214382632294,"4
Uniformly Bounded Variance"
UNIFORMLY BOUNDED VARIANCE,0.05834464043419267,"In this section, we assume that the variance of our stochastic oracle is uniformly bounded.
Assumption 3. For the stochastic oracle pg, we have σ2 := supx∈dom ψ Varpg(x) < +∞, where
Varpg(x) := Eξ[∥g(x, ξ) −sg(x)∥2
∗]."
UNIFORMLY BOUNDED VARIANCE,0.059023066485753055,"Under this assumption, we can establish the following efficiency estimates for our UniSgd and
UniFastSgd methods (the proofs are deferred to Appendix C).
Theorem 4. Let Algorithm 1 with M0 = 0 be applied to problem (1) under Assumptions 1–3. Then,
for the point sxN generated by the algorithm, we have"
UNIFORMLY BOUNDED VARIANCE,0.05970149253731343,E[F(sxN)] −F ∗≤c2c4LfD2
UNIFORMLY BOUNDED VARIANCE,0.060379918588873815,"N
+ 2σD r 2c1c4"
UNIFORMLY BOUNDED VARIANCE,0.06105834464043419,"N
+ c3δf."
UNIFORMLY BOUNDED VARIANCE,0.06173677069199457,"Theorem 5. Let Algorithm 2 be applied to problem (1) under Assumptions 1–3. Then, for any k ≥1,"
UNIFORMLY BOUNDED VARIANCE,0.06241519674355495,E[F(xk)] −F ∗≤4c2c4LfD2
UNIFORMLY BOUNDED VARIANCE,0.06309362279511534,"k(k + 1)
+ 4σD r 2c1c4"
K,0.06377204884667571,"3k
+ c3"
K,0.06445047489823609,3 (k + 2)δf.
K,0.06512890094979647,"We see that, in contrast to UniSgd, the accelerated algorithm UniFastSgd is not robust to the
oracle’s errors: it accumulates them with time at the rate of O(kδ). This is not surprising since the
same phenomenon also occurs in the classical accelerated gradient method, even when the oracle is
deterministic and the algorithm has the knowledge about all constants (see [15])."
K,0.06580732700135686,"The complexity results from Theorems 4 and 5 are similar to those from [13]. However, it is important
that our methods are adaptive and do not require knowing the constants Lf and σ."
K,0.06648575305291723,"In the specific case when δf = 0, we recover the same convergence rates as in [30, 34], although our
methods work for the more general composite optimization problem and, in contrast to [34], do not
require that ∇f(x∗) = 0."
IMPLICIT VARIANCE REDUCTION,0.06716417910447761,"5
Implicit Variance Reduction"
IMPLICIT VARIANCE REDUCTION,0.06784260515603799,"The assumption of uniformly bounded variance may not hold for some problems, or the corresponding
constant σ2 might be quite large, which is why there has recently been a growing interest in various
alternative variance bound assumptions [5, 22, 24, 29, 42, 54, 59]. One interesting option is expressing
complexity bounds via the variance at the minimizer, σ2
∗:= Varpg(x∗), assuming that the stochastic
oracle pg satisfies some extra smoothness conditions. Let us show that, for our Algorithms 1 and 2,
we can also establish such bounds, moreover, this can be done without any modifications to the
algorithms."
IMPLICIT VARIANCE REDUCTION,0.06852103120759837,"In this section, we study problem (1) under Assumptions 1 and 2 and also under the following
additional smoothness assumption on the variance:
Assumption 6. There exist δpg, Lpg ≥0 such that Varpg(x, y) ≤2Lpg[βf, sf,sg(x, y) + δpg] for any
x, y ∈Rd, where Varpg(x, y) := Eξ[∥[g(x, ξ) −g(y, ξ)] −[sg(x) −sg(y)]∥2
∗]."
IMPLICIT VARIANCE REDUCTION,0.06919945725915876,"Note that Varpg(x, y) is the usual variance of the estimator g(x, ξ) −g(y, ξ) which uses the same
randomness ξ for both arguments. Hence, Varpg(x, y) ≤E[∥g(x, ξ) −g(y, ξ)∥2
∗] for any x, y.
Furthermore, if pgb is the mini-batch version of pg of size b (i.e., the average of b i.i.d. samples of pg(x)
at any point x), then Varpgb(x, y) = 1"
IMPLICIT VARIANCE REDUCTION,0.06987788331071913,"b Varpg(x, y) for any x, y."
IMPLICIT VARIANCE REDUCTION,0.07055630936227951,"For instance, if f(x) = Eξ[fξ(x)], where each function fξ is convex and (δξ, Lξ)-approximately
smooth with components ( sfξ, sgξ), then, the stochastic gradient oracle pg, defined by g(x, ξ) := sgξ(x)
satisfies Assumption 6 with sf(x) = Eξ[ sfξ(x)], sg(x) = Eξ[sgξ(x)], and δpg =
1
Lmax Eξ[Lξδξ] (≤
Eξ[δξ]), Lpg = Lmax, where Lmax := supξ Lξ (see Lemma 16). Furthermore, if pgb is the mini-batch
version of pg of size b, then pgb satisfies Assumption 6 with the same δpgb = δpg but Lpgb = 1"
IMPLICIT VARIANCE REDUCTION,0.07123473541383989,bLpg = 1
IMPLICIT VARIANCE REDUCTION,0.07191316146540028,"bLmax
which can be much smaller than Lmax when b is large enough."
IMPLICIT VARIANCE REDUCTION,0.07259158751696065,"Under the new assumption on the variance, UniSgd enjoys the following convergence rate (see
Appendix D.1 for the proof).
Theorem 7. Let Algorithm 1 with M0 = 0 be applied to problem (1) under Assumptions 1, 2 and 6,
and let σ2
∗:= Varpg(x∗). Then, for the point sxN produced by the method, we have"
IMPLICIT VARIANCE REDUCTION,0.07327001356852103,E[F(sxN)] −F ∗≤c4(c2Lf + 12c1Lpg)D2
IMPLICIT VARIANCE REDUCTION,0.07394843962008141,"N
+ 2σ∗D r 6c1c4"
IMPLICIT VARIANCE REDUCTION,0.07462686567164178,"N
+ c3δf + 4 3δpg."
IMPLICIT VARIANCE REDUCTION,0.07530529172320218,"Comparing the above result with Theorem 4, we see that we have essentially replaced the uniform
bound σ with the more refined one σ∗at the cost of replacing Lf with Lf + Lpg and δf with δf + δpg."
IMPLICIT VARIANCE REDUCTION,0.07598371777476255,"Algorithm 3 UniSvrgpg,sg,ψ(x0; D)"
IMPLICIT VARIANCE REDUCTION,0.07666214382632293,"Input: Oracles pg, sg, composite part ψ, point x0 ∈dom ψ, diameter D."
IMPLICIT VARIANCE REDUCTION,0.0773405698778833,"1: ˜x0 = x0, M0 = 0.
2: for t = 0, 1, . . . do
3:
(˜xt+1, xt+1, Mt+1) ∼= UniSgd p
Gt,ψ(xt, Mt, 2t+1; D) with pGt = SvrgOracpg,sg(˜xt)."
IMPLICIT VARIANCE REDUCTION,0.0780189959294437,"This corresponds to classical results on the usual SGD for which we know all problem dependent-
constants. However, our method is universal and works automatically under both assumptions from
the previous section and the current one, and therefore enjoys the best among the rates given by
Theorems 4 and 7."
IMPLICIT VARIANCE REDUCTION,0.07869742198100407,"For the accelerated algorithm, we have the following result (whose proof is located in Appendix D.2).
Theorem 8. Let Algorithm 2 be applied to problem (1) under Assumptions 1, 2 and 6, and let
σ2
∗:= Varpg(x∗). Then, for any k ≥1, we have"
IMPLICIT VARIANCE REDUCTION,0.07937584803256445,E[F(xk)] −F ∗≤4c2c4LfD2
IMPLICIT VARIANCE REDUCTION,0.08005427408412483,"k(k + 1)
+ 24c1c4LpgD2"
IMPLICIT VARIANCE REDUCTION,0.0807327001356852,"k + 1
+ 4σ∗D r 2c1c4"
IMPLICIT VARIANCE REDUCTION,0.0814111261872456,"k
+ c3"
IMPLICIT VARIANCE REDUCTION,0.08208955223880597,3 (k + 2)δf + 4 3δpg.
IMPLICIT VARIANCE REDUCTION,0.08276797829036635,"Comparing our previous complexity bound for UniFastSgd under the assumption on uniformly
bounded variance (Theorem 5) with the bound from Theorem 8, we see that, instead of simply
replacing σ with σ∗, Lf with Lf + Lpg and δf with δf + δpg, which was the case for the basic method,
the situation is now not that simple. Specifically, the Lf and Lpg terms now converge at different
rates: O( 1"
IMPLICIT VARIANCE REDUCTION,0.08344640434192672,k2 ) and O( 1
IMPLICIT VARIANCE REDUCTION,0.08412483039348712,"k), respectively. While this may seem strange at first, this behavior is actually
unavoidable, at least in the case when δf = δpg = 0 (see, e.g., Section E in [59]). For the case when
δf = δpg = 0, the complexity result from Theorem 8 is similar to the results for the Accelerated SGD
algorithm from [59]. However, the latter paper studies a specific setting where f(x) = E[fξ(x)],
where each component fξ is Lmax-smooth and then assumes that f is also Lmax-smooth, instead of
working with the constant Lf which can be much smaller than Lmax. A similar separation of the
constants Lf and Lpg, which we do, was recently considered in [24], where the authors obtained some
similar rates to our Theorem 8. However, it is important that, unlike the algorithms considered in [24,
59], our UniFastSgd is universal and does not require knowing any problem-dependent constants
except D. Furthermore, our results are more general because we allow the oracle to be inexact.
6
Explicit Variance Reduction with SVRG"
IMPLICIT VARIANCE REDUCTION,0.08480325644504749,"Let us now show that we can also incorporate explicit SVRG-type variance reduction into our methods.
In this section, we consider problem (1) under Assumptions 1, 2 and 6. All the proofs are deferred to
Appendix E."
IMPLICIT VARIANCE REDUCTION,0.08548168249660787,"In addition to the stochastic oracle pg, we now assume that we can also compute the (approximate)
full-gradient oracle sg. This allows us to define the following auxiliary SVRG oracle induced by pg
with center ˜x ∈Rd (notation pG = SvrgOracpg,sg(˜x)) as the oracle with the same random variable
component ξ as pg and the function component given by G(x, ξ) = g(x, ξ) −g(˜x, ξ) + sg(˜x)."
IMPLICIT VARIANCE REDUCTION,0.08616010854816825,"Our UniSvrg method is presented in Algorithm 3. This is the classical epoch-based SVRG algorithm
which can be seen as the adaptive version of the SVRG++ method from [1]. A similar scheme was
suggested in [16], however, instead of accumulating gradient differences as in (3), their method
accumulates gradients and therefore does not work without the additional assumption of ∇f(x∗) = 0
(which may not hold for constrained optimization)."
IMPLICIT VARIANCE REDUCTION,0.08683853459972862,"Let us now present the complexity guarantees. To do so, we first need to introduce, one more
assumption we need in our analysis."
IMPLICIT VARIANCE REDUCTION,0.08751696065128901,"Assumption 9. The variance of pg satisfies Varpg(x, y) ≤4Lpg[β∇f(x)
f
(x, y) + 2δpg] for any x, y ∈Rd"
IMPLICIT VARIANCE REDUCTION,0.08819538670284939,and any ∇f(x) ∈∂f(x).
IMPLICIT VARIANCE REDUCTION,0.08887381275440977,"Assumption 9 is very similar to Assumption 6. The only difference between them is that the
former contains the standard Bregman distance in the right-hand side, while the latter contains
its approximation βf, sf,sg(x, y) involving the approximate function value sf(x) and the approximate
gradient sg(x). Nevertheless, both assumptions are actually satisfied for the main examples we
discussed after introducing Assumption 6 (see Lemma 16)."
IMPLICIT VARIANCE REDUCTION,0.08955223880597014,"Algorithm 4 UniFastSvrgpg,sg,ψ(x0, N; D)"
IMPLICIT VARIANCE REDUCTION,0.09023066485753053,"Input: Oracles pg, sg, composite part ψ, point x0 ∈dom ψ, epoch length N, diameter D."
IMPLICIT VARIANCE REDUCTION,0.09090909090909091,"1: ˜x0 = Proxψ(x0, sg(x0), 0), v0 = x0, M0 = 0, A0 =
1
N .
2: for t = 0, 1, . . . do
3:
at+1 = √At, At+1 = At + at+1.
4:
(˜xt+1, vt+1, Mt+1) ∼= UniTriSvrgEpochpg,sg,ψ(˜xt, vt, Mt, At, at+1, N; D)."
IMPLICIT VARIANCE REDUCTION,0.09158751696065129,"Algorithm 5 (˜x+, v+, M+) ∼= UniTriSvrgEpochpg,sg,ψ(˜x, v0, M0, A, a, N; D)"
IMPLICIT VARIANCE REDUCTION,0.09226594301221167,"Input: Oracles pg, sg, comp. part ψ, points ˜x, v0, coefficients M0, A, a, epoch length N, diameter D."
IMPLICIT VARIANCE REDUCTION,0.09294436906377204,"1: A+ = A + a, x0 =
A
A+ ˜x +
a
A+ v0, pG = SvrgOracpg,sg(˜x), Gx0 ∼= pG(x0).
2: for k = 0, . . . , N −1 do
3:
vk+1 = Proxψ(vk, Gxk, Mk"
IMPLICIT VARIANCE REDUCTION,0.09362279511533243,"a ).
4:
xk+1 =
A
A+ ˜x +
a
A+ vk+1, Gxk+1 ∼= pG(xk+1)."
IMPLICIT VARIANCE REDUCTION,0.09430122116689281,"5:
Mk+1 =
a2"
IMPLICIT VARIANCE REDUCTION,0.09497964721845319,"A+ M+
  A+"
IMPLICIT VARIANCE REDUCTION,0.09565807327001356,"a2 Mk, a2"
IMPLICIT VARIANCE REDUCTION,0.09633649932157395,"A2
+ D2, xk, xk+1, Gxk, Gxk+1

▷e.g.,
(3)
=
q"
IMPLICIT VARIANCE REDUCTION,0.09701492537313433,"M 2
k + a2"
IMPLICIT VARIANCE REDUCTION,0.09769335142469471,D2 ∥Gxk+1 −Gxk ∥2∗.
IMPLICIT VARIANCE REDUCTION,0.09837177747625508,"6: return (sxN, vN, MN), where sxN :=
1
N
PN
k=1 xk."
IMPLICIT VARIANCE REDUCTION,0.09905020352781546,"Theorem 10. Let UniSvrg (as defined by Algorithm 3) be applied to problem (1) under Assumptions 1,
2, 6 and 9. Then, for any t ≥1 and sc3 := max{c3, 1}, we have"
IMPLICIT VARIANCE REDUCTION,0.09972862957937585,E[F(˜xt)] −F ∗≤[(c2c4 + 1)Lf + 48c1c4Lpg]D2
T,0.10040705563093623,"2t
+ 2sc3δf + 8 3δpg."
T,0.1010854816824966,"To construct ˜xt, the algorithm needs to make O(2t) queries to pg and O(t) queries to sg."
T,0.10176390773405698,"We now present an accelerated version of UniSvrg, see Algorithm 4. As UniSvrg, this method
is also epoch-based, and its epoch is very similar to UniFastSgd (Algorithm 4) in the sense that
it also iterates similar-triangle steps. However, the triangles in UniTriSvrgEpoch are of the form
(˜x, vk, vk+1), i.e., they always share the common vertex ˜x, in contrast to the triangles (xk, vk, vk+1)
in UniFastSgd (in UniTriSvrgEpoch, the role of the average points yk is played by xk). We note
that our UniFastSvrg is essentially the primal version of the VRADA method from [53], but equipped
with AdaGrad stepsizes. Alternative accelerated SVRG schemes with AdaGrad stepsizes (3) were
recently proposed in [36]; however, they seem to be much more complicated."
T,0.10244233378561737,"The special choice of the initial reference point ˜x0 at Line 1 is rather standard and motivated by the
desire to keep the initial function residual appropriately bounded: F(˜x0) −F ∗≤1"
T,0.10312075983717775,"2LfD2 + δf; the
simplest way to achieve this is to make the full gradient step from any feasible point (see Lemma 34).
Theorem 11. Let UniFastSvrg (Algorithm 4) be applied to problem (1) under Assumptions 1, 2
and 6, and let N ≥9. Then, for any t ≥t0 := ⌈log2 log3 N⌉−1 (≥0), it holds that"
T,0.10379918588873813,E[F(˜xt)] −F ∗≤9[(c2c4 + 1
T,0.1044776119402985,2)Lf + 6c1c4Lpg]D2
T,0.10515603799185888,"N(t −t0 + 1)2
+ (c3t + 1)δf + 5"
T,0.10583446404341927,3tδpg.
T,0.10651289009497965,"To construct ˜xt, the algorithm needs to make O(Nt) queries to pg and O(t) queries to sg. Assuming
that the complexity of querying sg is n times bigger than that of querying pg and choosing N = Θ(n),
we get the total stochastic-oracle complexity of O(nt)."
T,0.10719131614654002,"Note that Theorem 11, unlike Theorem 10, does not require the extra Assumption 9. This suggests
that Assumption 9 might be somewhat artificial and could potentially be removed from Theorem 10
as well. However, we do not know how to do it, even in the simplest case when δf = δpg = 0 and the
algorithm has the knowledge of the constants Lf and Lpg from Assumptions 1 and 6."
T,0.1078697421981004,"7
Application to Hölder Smooth Problems"
T,0.10854816824966079,"To illustrate how powerful our results are, let us quickly consider the specific example of solving the
stochastic optimization problem with Hölder smooth components.
Example 12. Suppose that the function f in problem (1) is the expectation of other functions,
f(x) = Eξ[fξ(x)], where each function fξ is convex and (ν, Hξ(ν))-Hölder smooth. Consider the"
T,0.10922659430122117,"Table 2: Corollaries of our results for the case when problem (1) has Hölder smooth components, as defined
in Example 12. “SO complexity” is the stochastic-oracle complexity for reaching accuracy ϵ in terms of the
expected function residual, defined as in Table 1 but with pg = pgb, sg = ∇f, n = nb."
T,0.10990502035278155,"Method
SO complexity
Reference"
T,0.11058344640434192,"UniSgd (Alg. 1)
  Hf (ν)"
T,0.1112618724559023,"ϵ

2
1+ν D2 + 1"
T,0.11194029850746269,"b min
 σ2D2"
T,0.11261872455902307,"ϵ2
,
  Hmax(ν)"
T,0.11329715061058344,"ϵ

2
1+ν D2 +
σ2
∗D2"
T,0.11397557666214382,"ϵ2
	
Cors. 37, 40"
T,0.11465400271370421,"UniFastSgd (Alg. 2)
  Hf (ν)D1+ν"
T,0.11533242876526459,"ϵ

2
1+3ν + 1"
T,0.11601085481682497,"b min
 σ2D2"
T,0.11668928086838534,"ϵ2
,
  Hmax(ν)"
T,0.11736770691994572,"ϵ

2
1+ν D2 +
σ2
∗D2"
T,0.11804613297150611,"ϵ2
	
Cors. 38, 41"
T,0.11872455902306649,"UniSvrg (Alg. 3)

Nν(ϵ) :=
  Hf (ν)"
T,0.11940298507462686,"ϵ

2
1+ν D2 + 1"
T,0.12008141112618724,"b
  Hmax(ν)"
T,0.12075983717774763,"ϵ

2
1+ν D2
+ nb log+ Nν(ϵ)
Cor. 43"
T,0.12143826322930801,"UniFastSvrg (Alg. 4)
[
nν
b Hf (ν)D1+ν"
T,0.12211668928086838,"ϵ
]
2
1+3ν + [
nν
b Hmax(ν)D1+ν"
T,0.12279511533242876,"b(1+ν)/2ϵ
]
2
1+3ν + nb log log nb
Cor. 44"
T,0.12347354138398914,"standard mini-batch stochastic gradient oracle pgb of size b, defined by gb(x, ξ[b]) = 1"
T,0.12415196743554953,"b
Pb
j=1 ∇fξj(x),
where ξ[b] := (ξ1, . . . , ξb) with b i.i.d. copies of ξ, and ∇fξ(x) ∈∂fξ(x) is an arbitrary selection of
subgradients for each ξ. We define Hf(ν) as the Hölder constant for the function f and Hmax(ν) :=
supξ Hξ(ν) as the worst among Hölder constants for each fξ. Note that we always have Hf(ν) ≤
Eξ[Hξ(ν)] but Hf(ν) can, in principle, be much smaller than the right-hand side. Also, define
σ2 := supx∈dom ψ Varpg1(x) ≡supx∈dom ψ Eξ[∥∇fξ(x) −∇f(x)∥2
∗] and σ2
∗:= Varpg1(x∗) ≡
Eξ[∥∇fξ(x∗) −∇f(x∗)∥2
∗]. We assume that the computation of pgb can be parallelized and the
computation of ∇f is nb times more expensive than that of pgb."
T,0.1248303934871099,"To solve the above problem, we can apply any of the methods we presented before. The resulting
oracle complexities (in terms of the BigO-notation) are summarized in Table 2; the precise statements
the corresponding results and their proofs are deferred to Appendix F."
T,0.1255088195386703,"Note that our problem is characterized by a large number of parameters, ν, Hf(ν), Hmax(ν), σ, σ∗.
For each combination of these parameters, we get a certain complexity guarantee for each of our
methods, and it is impossible to say in advance which combination results in the smaller complexity
bound. However, it is not important for our methods since none of them needs to know any of these
constants to ensure the corresponding bound. This means that our algorithms are universal: they
automatically figure out the best problem class for a specific problem given to them."
EXPERIMENTS,0.12618724559023067,"8
Experiments"
EXPERIMENTS,0.12686567164179105,Let us illustrate the performance of our methods in preliminary numerical experiments2 on solving
EXPERIMENTS,0.12754409769335143,"f ∗:= min
∥x∥≤R"
EXPERIMENTS,0.1282225237449118,"n
f(x) := 1 n n
X"
EXPERIMENTS,0.12890094979647218,"i=1
[⟨ai, x⟩−bi]q
+
o
,
(5)"
EXPERIMENTS,0.12957937584803256,"where ai, bi ∈Rd, q ∈[1, 2] and R > 0."
EXPERIMENTS,0.13025780189959293,"This test problem covers several interesting applications. Indeed, if q = 2, we get the classical Least
squares problem. If q = 1, this is the well-known Support-Vector Machines (SVM) problem. In both
cases, the ball-constraint ∥x∥≤R acts as a regularizer, and problem (5) is, in fact, equivalent to
minx∈Rd[f(x) + µ"
EXPERIMENTS,0.1309362279511533,"2 ∥x∥2] for a certain µ ≥0 (this follows, e.g., from the KKT optimality conditions)
such that µ decreases when R increases."
EXPERIMENTS,0.13161465400271372,"Another interesting application of (5), which we consider in this section, is the polyhedron feasibility
problem: find x∗∈Rd, ∥x∗∥≤R, inside the polyhedron P = {x : ⟨ai, x⟩≤bi, i = 1, . . . , n}.
Such a point exists iff f ∗= 0. Note that (5) is a problem with Hölder smooth components of degree
ν = q −1. By varying q in (5), we can therefore check the adaptivity of different methods to the
unknown to them Hölder characteristics of the objective function."
EXPERIMENTS,0.1322930800542741,"The data for our problem is generated randomly. First, we generate x∗uniformly from the sphere of
radius 0.95R centered at the origin. Then, we generate i.i.d. vectors ai with components uniformly
distributed on [−1, 1]. We then make sure that ⟨an, x∗⟩< 0 by inverting the sign of an if necessary.
Next, we generate positive reals si uniformly in [0, −0.1cmin], where cmin := mini⟨ai, x∗⟩< 0,
and set bi = ⟨ai, x∗⟩+ si. By construction, x∗is a solution of our problem with f ∗= 0, and the
origin x0 = 0 lies outside the polyhedron since there exists j (corresponding to cmin) such that
bj = cmin + sj ≤0.9cmin < 0."
EXPERIMENTS,0.13297150610583447,2The corresponding source code is available at https://github.com/mlolab/universal-adagrad-experiments.
EXPERIMENTS,0.13364993215739485,"0
50000 100000 150000 200000 250000
number of stochastic oracle calls 10
1 100 101 102 103 104 105"
EXPERIMENTS,0.13432835820895522,f(x)-f q = 1
EXPERIMENTS,0.1350067842605156,"0
25000 50000 75000 100000125000150000"
EXPERIMENTS,0.13568521031207598,number of stochastic oracle calls 100 101 102 103 104 105 106 107
EXPERIMENTS,0.13636363636363635,f(x)-f
EXPERIMENTS,0.13704206241519673,q = 1.3
EXPERIMENTS,0.13772048846675713,"0
20000
40000
60000
number of stochastic oracle calls 102 104 106 108"
EXPERIMENTS,0.1383989145183175,f(x)-f
EXPERIMENTS,0.1390773405698779,q = 1.6
EXPERIMENTS,0.13975576662143827,"0
5000
10000
15000
number of stochastic oracle calls 10
6 10
3 100 103 106 109 1012"
EXPERIMENTS,0.14043419267299864,f(x)-f q = 2
EXPERIMENTS,0.14111261872455902,"UniSgd (ours)
UniFastSgd (ours)
AdaSVRG
UniSvrg (ours)
AdaVRAG
AdaVRAE
FastSvrg
UniFastSvrg (ours)
Figure 1: Comparison of different methods on the polyhedron feasibility problem (5)."
EXPERIMENTS,0.1417910447761194,"0
5000
10000
15000
20000
number of stochastic oracle calls 105 106 107 108"
EXPERIMENTS,0.14246947082767977,f(x)-f
EXPERIMENTS,0.14314789687924015,UniSgd
EXPERIMENTS,0.14382632293080055,"batchsize=64
batchsize=512
batchsize=4096"
EXPERIMENTS,0.14450474898236093,"0
2000
4000
6000
8000
10000
12000
14000
number of stochastic oracle calls 101 103 105 107"
EXPERIMENTS,0.1451831750339213,f(x)-f
EXPERIMENTS,0.14586160108548168,UniFastSgd
EXPERIMENTS,0.14654002713704206,"batchsize=64
batchsize=512
batchsize=4096"
EXPERIMENTS,0.14721845318860244,"0
5000
10000
15000
20000
25000
30000
35000
number of stochastic oracle calls 104 105 106 107 108"
EXPERIMENTS,0.14789687924016282,f(x)-f
EXPERIMENTS,0.1485753052917232,UniSvrg
EXPERIMENTS,0.14925373134328357,"batchsize=64
batchsize=512
batchsize=4096"
EXPERIMENTS,0.14993215739484397,"0
2500
5000
7500
10000
12500
15000
17500
20000
number of stochastic oracle calls 101 103 105 107"
EXPERIMENTS,0.15061058344640435,f(x)-f
EXPERIMENTS,0.15128900949796473,UniFastSvrg
EXPERIMENTS,0.1519674355495251,"batchsize=64
batchsize=512
batchsize=4096"
EXPERIMENTS,0.15264586160108548,Figure 2: Impact of mini-batch size on performance of our methods.
EXPERIMENTS,0.15332428765264586,"We compare UniSvrg (Algorithm 3) against AdaSVRG [16] (with parameters K = 3 and η = D =
2R). We next compare UniFastSvrg (Algorithm 4) against AdaVRAE and AdaVRAG [36]. We
also compare it with the FastSvrg method with constant stepsize, which is the primal version of the
VRADA method from [53]; the stepsize is selected by doing a grid search over {10j : j = −3, . . . , 4}
and choosing the best value in the sense that the algorithm is neither too slow nor has a large error.
We report UniSgd (Algorithm 1) and UniFastSgd (Algorithm 2) together with these methods. For
UniFastSvrg, contrary to the theoretical recommendation of choosing ˜x0 as the result of the full
gradient step, we found it slightly more useful to simply set ˜x0 = x0. For all our methods, we use the
AdaGrad stepsize (3); the other stepsize (4) works very similarly (see Appendix H.2 for a detailed
comparison). For all methods, we use the standard mini-batch stochastic oracle of size b = 256."
EXPERIMENTS,0.15400271370420623,"The results are shown in Fig. 1, where we fix n = 104, d = 103, R = 106 and consider different
values of q ∈{1, 1.3, 1.6, 2}. We plot the total number of stochastic oracle calls against the function
residual. We treat one mini-batch oracle computation as one stochastic oracle call. If we compute the
full gradient, we count this as n/b stochastic oracle calls where n is the total number of samples and
b denotes the mini-batch size."
EXPERIMENTS,0.1546811397557666,"We see that, except the AdaSVRG method, all SVRG algorithms typically converge much faster
than the usual SGD methods without explicit variance reduction, at least after a few computations
of the full gradient. Among the non-accelerated SVRG methods, UniSvrg converges consistently
faster than AdaSVRG, while UniFastSvrg performs the best across the accelerated ones. Note that
FastSvrg with constant stepsize is not converging when the problem is not Lipschitz smooth (q < 2),
in contrast to our universal methods."
EXPERIMENTS,0.155359565807327,"In Fig. 2, we also illustrate the impact of the mini-batch size b on the convergence of our methods.
We consider the same values of n, d, R as before and fix q = 1.5. As we can see, in the idealized
situation, when one can implement the mini-batch oracle computations by perfect parallelism, there is
a significant speedup in convergence when increasing the mini-batch size, as predicted by our theory."
EXPERIMENTS,0.1560379918588874,"For additional experiments, including the discussion of implicit variance reduction, see Appendix H."
CONCLUSIONS,0.15671641791044777,"9
Conclusions"
CONCLUSIONS,0.15739484396200815,"In this paper, we showed that AdaGrad stepsizes can be applied, in a unified manner, in a large variety
of situations, leading to universal methods suitable for multiple problem classes at the same time.
Note that this does not come for free. We still need to know one parameter, the diameter D of the
feasible set. While it is not necessary to know this parameter precisely, the cost of underestimating
or overestimating it, can be high (all complexity bounds would be multiplied by the ratio between
our guess and the true D). At the same time, there already exist some parameter-free methods
which are based on AdaGrad and aim to solve precisely this problem [6, 11, 25, 31, 41]. It is
therefore interesting to consider extensions of our results to these more advanced algorithms. Another
interesting direction is, of course, nonconvex problems."
CONCLUSIONS,0.15807327001356852,Acknowledgements
CONCLUSIONS,0.1587516960651289,"The authors are thankful to the anonymous reviewers for their comments and suggestions. Sebastian
Stich acknowledges funding support from the Meta Research Award and the Google Research Award."
REFERENCES,0.15943012211668928,References
REFERENCES,0.16010854816824965,"[1]
Z. Allen-Zhu and Y. Yuan. Improved SVRG for Non-Strongly-Convex or Sum-of-Non-Convex
Objectives. In International Conference on Machine Learning, pages 1080–1089, 2016.
[2]
A. Attia and T. Koren. SGD with AdaGrad Stepsizes: Full Adaptivity with High Probability to
Unknown Parameters, Unbounded Gradients and Affine Variance. In International Conference
on Machine Learning, pages 1147–1171, 2023.
[3]
R. Babanezhad Harikandeh, M. O. Ahmed, A. Virani, M. Schmidt, J. Koneˇcn`y, and S. Sallinen.
StopWasting My Gradients: Practical SVRG. Advances in Neural Information Processing
Systems, 28, 2015.
[4]
D. P. Bertsekas. Stochastic optimization problems with nondifferentiable cost functionals.
Journal of Optimization Theory and Applications, 12(2):218–231, 1973.
[5]
L. Bottou, F. E. Curtis, and J. Nocedal. Optimization Methods for Large-Scale Machine
Learning. SIAM Review, 60(2):223–311, 2018.
[6]
Y. Carmon and O. Hinder. Making SGD Parameter-Free. In Conference on Learning Theory,
pages 2360–2389, 2022.
[7]
C.-C. Chang and C.-J. Lin. LIBSVM: a library for support vector machines. ACM Transactions
on Intelligent Systems and Technology, 2:27:1–27:27, 3, 2011.
[8]
A. Cotter, O. Shamir, N. Srebro, and K. Sridharan. Better mini-batch algorithms via accelerated
gradient methods. Advances in Neural Information Processing Systems, 24, 2011.
[9]
A. Cutkosky and K. Boahen. Online Learning Without Prior Information. In Conference on
Learning Theory, pages 643–677, 2017.
[10]
A. Cutkosky and F. Orabona. Black-Box Reductions for Parameter-free Online Learning in
Banach Spaces. In Conference On Learning Theory, pages 1493–1529, 2018.
[11]
A. Defazio and K. Mishchenko. Learning-Rate-Free Learning by D-Adaptation. In Interna-
tional Conference on Machine Learning, pages 7449–7479, 2023.
[12]
Q. Deng, Y. Cheng, and G. Lan. Optimal Adaptive and Accelerated Stochastic Gradient
Descent. arXiv preprint arXiv:1810.00553, 2018.
[13]
O. Devolder. Stochastic first order methods in smooth convex optimization. CORE Discussion
Papers, 2011/70, 2011.
[14]
O. Devolder. Exactness, Inexactness and Stochasticity in First-Order Methods for Large-Scale
Convex Optimization. PhD thesis, Université catholique de Louvain (UCL), 2013.
[15]
O. Devolder, F. Glineur, and Y. Nesterov. First-order methods of smooth convex optimization
with inexact oracle. Mathematical Programming, 146:37–75, 2013. DOI: 10.1007/s10107-
013-0677-5.
[16]
B. Dubois-Taine, S. Vaswani, R. Babanezhad, M. Schmidt, and S. Lacoste-Julien. SVRG meets
AdaGrad: painless variance reduction. Machine Learning, 111(12):4359–4409, 2022.
[17]
J. Duchi, E. Hazan, and Y. Singer. Adaptive Subgradient Methods for Online Learning and
Stochastic Optimization. Journal of Machine Learning Research, 12(7), 2011.
[18]
A. Ene, H. L. Nguyen, and A. Vladu. Adaptive Gradient Methods for Constrained Convex
Optimization and Variational Enequalities. In Proceedings of the AAAI Conference on Artificial
Intelligence, volume 35 of number 8, pages 7314–7321, 2021.
[19]
E. Gorbunov, F. Hanzely, and P. Richtárik. A Unified Theory of SGD: Variance Reduction,
Sampling, Quantization and Coordinate Descent. In International Conference on Artificial
Intelligence and Statistics, pages 680–690, 2020.
[20]
R. M. Gower, P. Richtárik, and F. Bach. Stochastic quasi-gradient methods: variance reduction
via Jacobian sketching. Mathematical Programming, 188(1):135–192, 2021.
[21]
R. M. Gower, M. Schmidt, F. Bach, and P. Richtárik. Variance-Reduced Methods for Machine
Learning. Proceedings of the IEEE, 108(11):1968–1983, 2020."
REFERENCES,0.16078697421981003,"[22]
R. M. Gower, N. Loizou, X. Qian, A. Sailanbayev, E. Shulgin, and P. Richtárik. SGD: General
Analysis and Improved Rates. In International Conference on Machine Learning, pages 5200–
5209, 2019.
[23]
G. N. Grapiglia and Y. Nesterov. Regularized Newton Methods for Minimizing Functions with
Hölder Continuous Hessians. SIAM Journal on Optimization, 27(1):478–506. DOI: 10.1137/
16M1087801.
[24]
S. Ilandarideva, A. Juditsky, G. Lan, and T. Li. Accelerated stochastic approximation with
state-dependent noise. arXiv preprint arXiv:2307.01497, 2023.
[25]
M. Ivgi, O. Hinder, and Y. Carmon. DoG is SGD’s Best Friend: A Parameter-Free Dynamic
Step Size Schedule. In International Conference on Machine Learning, pages 14465–14499,
2023.
[26]
A. Jacobsen and A. Cutkosky. Unconstrained Online Learning with Unbounded Losses. In
International Conference on Machine Learning, pages 14590–14630, 2023.
[27]
R. Johnson and T. Zhang. Accelerating Stochastic Gradient Descent using Predictive Variance
Reduction. Advances in Neural Information Processing Systems, 26, 2013.
[28]
P. Joulani, A. Raj, A. Gyorgy, and C. Szepesvári. A Simpler Approach to Accelerated Op-
timization: Iterative Averaging Meets Optimism. In International Conference on Machine
Learning, pages 4984–4993, 2020.
[29]
A. Juditsky, A. Kulunchakov, and H. Tsyntseus. Sparse recovery by reduced variance stochastic
approximation. Information and Inference: A Journal of the IMA, 12(2):851–896, 2023.
[30]
A. Kavis, K. Y. Levy, F. Bach, and V. Cevher. UniXGrad: A Universal, Adaptive Algorithm
with Optimal Guarantees for Constrained Optimization. Advances in Neural Information
Processing Systems, 32, 2019.
[31]
A. Khaled, K. Mishchenko, and C. Jin. DoWG Unleashed: An Efficient Universal Parameter-
Free Gradient Descent Method. Advances in Neural Information Processing Systems, 36:6748–
6769, 2023.
[32]
D. P. Kingma and J. Ba. Adam: A Method for Stochastic Optimization. International Confer-
ence on Learning Representations (ICLR), 2015.
[33]
G. Lan. An optimal method for stochastic composite optimization. Mathematical Programming,
133(1):365–397, 2012.
[34]
K. Y. Levy, A. Yurtsever, and V. Cevher. Online Adaptive Methods, Universality and Accelera-
tion. Advances in Neural Information Processing Systems, 31, 2018.
[35]
C. Liu and M. Belkin. Accelerating SGD with momentum for over-parameterized learning.
arXiv preprint arXiv:1810.13395, 2018.
[36]
Z. Liu, T. D. Nguyen, A. Ene, and H. Nguyen. Adaptive Accelerated (Extra-)Gradient Methods
with Variance Reduction. In International Conference on Machine Learning, pages 13947–
13994, 2022.
[37]
S. Ma, R. Bassily, and M. Belkin. The Power of Interpolation: Understanding the Effectiveness
of SGD in Modern Over-parametrized Learning. In International Conference on Machine
Learning, pages 3325–3334, 2018.
[38]
M. Mahdavi, L. Zhang, and R. Jin. Mixed Optimization for Smooth Functions. Advances in
Neural Information Processing Systems, 26, 2013.
[39]
H. B. McMahan and M. Streeter. Adaptive Bound Optimization for Online Convex Optimiza-
tion. arXiv preprint arXiv:1002.4908, 2010.
[40]
Z. Mhammedi and W. M. Koolen. Lipschitz and Comparator-Norm Adaptivity in Online
Learning. In Conference on Learning Theory, pages 2858–2887, 2020.
[41]
K. Mishchenko and A. Defazio. Prodigy: An Expeditiously Adaptive Parameter-Free Learner.
arXiv preprint arXiv:2306.06101, 2023.
[42]
E. Moulines and F. Bach. Non-Asymptotic Analysis of Stochastic Approximation Algorithms
for Machine Learning. Advances in Neural Information Processing Systems, 24, 2011.
[43]
I. Necoara, Y. Nesterov, and F. Glineur. Linear convergence of first order methods for non-
strongly convex optimization. Mathematical Programming, 175:69–107, 2019.
[44]
D. Needell, R. Ward, and N. Srebro. Stochastic Gradient Descent, Weighted Sampling, and the
Randomized Kaczmarz Algorithm. Advances in Neural Information Processing Systems, 27,
2014."
REFERENCES,0.1614654002713704,"[45]
Y. Nesterov. Universal gradient methods for convex optimization problems. Mathematical
Programming, 152:381–404, 2015. DOI: 10.1007/s10107-014-0790-0.
[46]
Y. Nesterov. Lectures on Convex Optimization, volume 137. Springer, 2nd edition, 2018.
[47]
F. Orabona. Simultaneous Model Selection and Optimization through Parameter-free Stochastic
Learning. Advances in Neural Information Processing Systems, 27, 2014.
[48]
F. Orabona. Normalized Gradients for All. arXiv preprint arXiv:2308.05621, 2023.
[49]
A. Rodomanov, A. Kavis, Y. Wu, K. Antonakopoulos, and V. Cevher. Universal Gradient
Methods for Stochastic Convex Optimization. arXiv preprint arXiv:2402.03210, 2024.
[50]
M. Schmidt, N. Le Roux, and F. Bach. Minimizing finite sums with the stochastic average
gradient. Mathematical Programming, 162:83–112, 2017.
[51]
M. Schmidt and N. L. Roux. Fast Convergence of Stochastic Gradient Descent under a Strong
Growth Condition. arXiv preprint arXiv:1308.6370, 2013.
[52]
S. Shalev-Shwartz and T. Zhang. Stochastic Dual Coordinate Ascent Methods for Regularized
Loss Minimization. Journal of Machine Learning Research, 14(1), 2013.
[53]
C. Song, Y. Jiang, and Y. Ma. Variance Reduction via Accelerated Dual Averaging for
Finite-Sum Optimization. In Advances in Neural Information Processing Systems, volume 33,
pages 833–844, 2020.
[54]
S. U. Stich. Unified Optimal Analysis of the (Stochastic) Gradient Method. arXiv preprint
arXiv:1907.04232, 2019.
[55]
M. Streeter and H. B. McMahan. No-Regret Algorithms for Unconstrained Online Convex
Optimization. In Proceedings of the 25th International Conference on Neural Information
Processing Systems, volume 2, pages 2402–2410, 2012.
[56]
T. Tieleman. Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent
magnitude. Coursera: Neural Networks for Machine Learning, 4(2):26, 2012.
[57]
S. Vaswani, A. Mishkin, I. Laradji, M. Schmidt, G. Gidel, and S. Lacoste-Julien. Painless
Stochastic Gradient: Interpolation, Line-Search, and Convergence Rates. Advances in Neural
Information Processing Systems, 32, 2019.
[58]
C. Wang, X. Chen, A. J. Smola, and E. P. Xing. Variance Reduction for Stochastic Gradient
Optimization. Advances in Neural Information Processing Systems, 26, 2013.
[59]
B. E. Woodworth and N. Srebro. An Even More Optimal Stochastic Optimization Algorithm:
Minibatching and Interpolation Learning. Advances in Neural Information Processing Systems,
34:7333–7345, 2021.
[60]
L. Zhang, M. Mahdavi, and R. Jin. Linear Convergence with Condition Number Independent
Access of Full Gradients. Advances in Neural Information Processing Systems, 26, 2013."
REFERENCES,0.1621438263229308,"A
General Auxiliary Results"
REFERENCES,0.1628222523744912,"A.1
Approximately Smooth Functions"
REFERENCES,0.16350067842605157,"Theorem 13 (Lemma 2 in [45]). Let f : Rd →R be a convex (ν, H)-Hölder smooth function for
some ν ∈[0, 1] and H ≥0. Then, for any δ > 0, any x, y ∈Rd and any ∇f(x) ∈∂f(x), it holds
that β∇f(x)
f
(x, y) ≤L"
REFERENCES,0.16417910447761194,"2 ∥x −y∥2 + δ with L = [
1−ν
2(1+ν)δ]
1−ν
1+ν H
2
1+ν (with the convention that 00 = 1)."
REFERENCES,0.16485753052917232,"Theorem 14. Let f : Rd →R be a (δ, L)-approximately smooth convex function with components
( sf, sg), i.e., for any x, y ∈Rd and βf, sf,sg(x, y) := f(y) −sf(x) −⟨sg(x), y −x⟩, we have"
REFERENCES,0.1655359565807327,"0 ≤βf, sf,sg(x, y) ≤L"
REFERENCES,0.16621438263229307,"2 ∥x −y∥2 + δ.
(6)"
REFERENCES,0.16689280868385345,"Then, for any x, y ∈Rd and any ∇f(x) ∈∂f(x), the following inequalities hold:"
REFERENCES,0.16757123473541383,"sf(x) ≤f(x) ≤sf(x) + δ,
(7)
⟨sg(x) −sg(y), x −y⟩≤βf, sf,sg(x, y) + βf, sf,sg(y, x) ≤⟨sg(x) −sg(y), x −y⟩+ 2δ,
(8)"
REFERENCES,0.16824966078697423,"⟨sg(x) −sg(y), x −y⟩≤L∥x −y∥2 + 2δ,
(9)"
REFERENCES,0.1689280868385346,"∥sg(x) −sg(y)∥2
∗≤2L(βf, sf,sg(x, y) + δ),
(10)"
REFERENCES,0.16960651289009498,"∥∇f(x) −sg(y)∥2
∗≤2L(β∇f(x)
f
(x, y) + δ),
(11)"
REFERENCES,0.17028493894165536,"∥sg(x) −sg(y)∥2
∗≤L2∥x −y∥2 + 4Lδ,
(12)"
REFERENCES,0.17096336499321574,"∥sg(x) −sg(y)∥2
∗≤4L(β∇f(x)
f
(x, y) + 2δ),
(13)"
REFERENCES,0.17164179104477612,"β∇f(x)
f
(x, y) ≤L∥x −y∥2 + 2δ.
(14)"
REFERENCES,0.1723202170963365,Proof. Inequality (7) follows immediately from (6) by substituting y = x.
REFERENCES,0.17299864314789687,"To prove (8), we rewrite"
REFERENCES,0.17367706919945725,"βf, sf,sg(x, y) + βf, sf,sg(y, x) = ⟨sg(x) −sg(y), x −y⟩+ [f(x) −sf(x)] + [f(y) −sf(y)],"
REFERENCES,0.17435549525101765,and then apply (7).
REFERENCES,0.17503392130257803,"Using the first part of (8) and applying (6) twice, we obtain (9)."
REFERENCES,0.1757123473541384,"To prove (10) and (11), let us fix some sf1(x) ∈R and sg1(x) ∈Rd such that βf, sf1,sg1(z) :=
f(z) −sf1(x) −⟨sg1(x), z −x⟩≥0 for any z ∈Rd. Note that we can choose either ( sf1, sg1) = ( sf, sg)
or ( sf1, sg1) = (f, ∇f). In view of (6), for any z ∈Rd, we can write the following inequalities:"
REFERENCES,0.17639077340569878,"0 ≤βf, sf1,sg1(z) ≤sf(y) −sf1(x) −⟨sg1(x), y −x⟩+ ⟨sg(y) −sg1(x), z −y⟩+ L"
REFERENCES,0.17706919945725916,2 ∥z −y∥2 + δ.
REFERENCES,0.17774762550881953,"Minimizing the right-hand side in z ∈Rd and rearranging, we conclude that"
REFERENCES,0.1784260515603799,"1
2L∥sg(y) −sg1(x)∥2
∗≤sf(y) −sf1(x) −⟨sg1(x), y −x⟩+ δ ≤βf, sf1,sg1(x, y) + δ,"
REFERENCES,0.1791044776119403,"where the final inequality is due to (7). Substituting now either ( sf1, sg1) = ( sf, sg) or ( sf1, sg1) =
(f, ∇f), we obtain either (10) or (11), respectively."
REFERENCES,0.17978290366350066,Inequality (12) follows immediately from (6) and (10).
REFERENCES,0.18046132971506107,Inequality (13) follows from (11):
REFERENCES,0.18113975576662145,"∥sg(x) −sg(y)∥2
∗≤2∥∇f(x) −sg(y)∥2
∗+ 2∥sg(x) −∇f(x)∥2
∗"
REFERENCES,0.18181818181818182,"≤4L(β∇f(x)
f
(x, y) + δ) + 4Lδ = 4L(β∇f(x)
f
(x, y) + 2δ)."
REFERENCES,0.1824966078697422,"To prove (14), we proceed as follows using first (6), then (7), and then (11):"
REFERENCES,0.18317503392130258,"β∇f(x)
f
(x, y) ≡f(y) −f(x) −⟨∇f(x), y −x⟩"
REFERENCES,0.18385345997286295,"≤sf(x) −f(x) + ⟨sg(x) −∇f(x), y −x⟩+ L"
REFERENCES,0.18453188602442333,2 ∥y −x∥2 + δ
REFERENCES,0.1852103120759837,"≤⟨sg(x) −∇f(x), y −x⟩+ L"
REFERENCES,0.18588873812754408,"2 ∥y −x∥2 + δ ≤
√"
REFERENCES,0.1865671641791045,2Lδ∥y −x∥+ L
REFERENCES,0.18724559023066487,"2 ∥y −x∥2 + δ =
r L"
REFERENCES,0.18792401628222524,"2 ∥y −x∥+
√"
REFERENCES,0.18860244233378562,"δ
2
≤L∥y −x∥2 + 2δ,"
REFERENCES,0.189280868385346,"where the final inequality is (a + b)2 ≤2a2 + 2b2, a, b ≥0."
REFERENCES,0.18995929443690637,"Remark 15. Some of the inequalities from Theorem 14, namely, (7), (10) and (12), were established
already in [15]. We nevertheless prefer to present the corresponding proofs since they are rather
simple, and we use the associated ideas for proving the other new inequalities."
REFERENCES,0.19063772048846675,"Lemma 16. Let f : Rd →R be the function f(x) := Eξ[fξ(x)], where each fξ : Rd →R is convex
and (δξ, Lξ)-approximately smooth with components ( sfξ, sgξ). Further, let pg be the stochastic oracle
defined by g(x, ξ) := sgξ(x), and let sf(x) := Eξ[ sfξ(x)], sg(x) := Eξ[sgξ(x)]. Then, pg is an unbiased
oracle for sg and, for any x, y ∈Rd, Lmax := supξ Lξ and sδ :=
1
Lmax Eξ[Lξδξ], it holds that"
REFERENCES,0.19131614654002713,"Varpg(x, y) ≤2Lmax[βf, sf,sg(x, y) + sδ].
(15)"
REFERENCES,0.1919945725915875,"Furthermore, for any x, y ∈Rd and any ∇f(x) ∈∂f(x), it also holds that"
REFERENCES,0.1926729986431479,"Varpg(x, y) ≤4Lmax[β∇f(x)
f
(x, y) + 2sδ].
(16)"
REFERENCES,0.19335142469470828,"Proof. According to our definition of sg, we have Eξ[sgξ(x)] = sg(x) for any x, so pg is indeed an
unbiased oracle for sg. Further, for any x, y ∈Rd, we can estimate"
REFERENCES,0.19402985074626866,"Varpg(x, y) ≡Eξ

∥[sgξ(x) −sgξ(y)] −[sg(x) −sg(y)]∥2
∗
"
REFERENCES,0.19470827679782904,"≤Eξ

∥sgξ(x) −sgξ(y)∥2
∗

≤Eξ

2Lξ
 
βfξ, sfξ,sgξ(x, y) + δξ
"
REFERENCES,0.19538670284938942,"≤2Lmax
 
Eξ[βfξ, sfξ,sgξ(x, y)] + sδ

= 2Lmax[βf, sf,sg(x, y) + sδ],"
REFERENCES,0.1960651289009498,"where sδ is as defined in the statement; the second inequality follows from Theorem 14 (inequal-
ity (10)), and the final identity is due to the linearity of βf, sf,sg(x, y) in (f, sf, sg) and the fact that, by
our definitions, Eξ[fξ(x)] = f(x), Eξ[ sfξ(x)] = sf(x), Eξ[sgξ(x)] = sg(x) for any x. This proves (15)."
REFERENCES,0.19674355495251017,The proof of (16) is similar but now we apply (13) instead of (10):
REFERENCES,0.19742198100407055,"Varpg(x, y) ≤Eξ

∥sgξ(x) −sgξ(y)∥2
∗

≤Eξ

4Lξ
 
β∇fξ(x)
fξ
(x, y) + 2δξ
"
REFERENCES,0.19810040705563092,"≤4Lmax
 
Eξ[β∇fξ(x)
fξ
(x, y)] + 2sδ

= 4Lmax[β∇f(x)
f
(x, y) + 2sδ],"
REFERENCES,0.19877883310719133,"where we have used the fact that ∂f(x) = Eξ[∂fξ(x)] (see Proposition 2.2 in [4]), meaning that, for
any ∇f(x) ∈∂f(x), we can find a selection of ∇fξ(x) ∈∂fξ(x) such that ∇f(x) = Eξ[∇fξ(x)]."
REFERENCES,0.1994572591587517,"A.2
Miscellaneous"
REFERENCES,0.20013568521031208,"Lemma 17. Let ψ: Rd →R ∪{+∞} be a proper closed convex function, x ∈dom ψ, g ∈Rd,
M ≥0, and let
x+ := Proxψ(x, g, M)."
REFERENCES,0.20081411126187246,"Then, for any y ∈dom ψ, we have"
REFERENCES,0.20149253731343283,"⟨g, y −x+⟩+ ψ(y) + M"
REFERENCES,0.2021709633649932,2 ∥x −y∥2 ≥ψ(x+) + M
REFERENCES,0.2028493894165536,2 ∥x −x+∥2 + M
REFERENCES,0.20352781546811397,2 ∥x+ −y∥2.
REFERENCES,0.20420624151967434,"Proof. Indeed, by definition, x+ is the minimizer of the function h: Rd →R ∪{+∞} given by
h(y) := ⟨g, y⟩+ ψ(y) + M"
REFERENCES,0.20488466757123475,"2 ∥x −y∥2, which is strongly convex with parameter M (or simply convex
if M = 0). Hence, for any y ∈dom ψ (= dom h), we have h(y) ≥h(x+) + M"
REFERENCES,0.20556309362279512,"2 ∥y −x+∥2, which
is exactly the claimed inequality."
REFERENCES,0.2062415196743555,"Lemma 18. Let N ≥1 be an integer, (Mk)N
k=0 be a nondecreasing nonnegative sequence of reals,
and let Ď
M ≥0. Then, N−1
X"
REFERENCES,0.20691994572591588,"k=0
[min{Mk+1, Ď
M} −Mk]+ = [min{MN, Ď
M} −M0]+."
REFERENCES,0.20759837177747625,"Proof. It suffices to prove the identity only in the special case when N = 2, i.e., to show that γ0+γ1 =
Γ, where γ0 := [min{M1, Ď
M}−M0]+, γ1 := [min{M2, Ď
M}−M1]+, Γ := [min{M2, Ď
M}−M0]+.
The general case then easily follows by induction."
REFERENCES,0.20827679782903663,"To prove the identity, we use our assumption that M0 ≤M1 ≤M2 and consider three possible
cases. If M1 ≥Ď
M, then γ0 + γ1 = [Ď
M −M0]+ + 0 = [Ď
M −M0]+ = Γ. If M1 < Ď
M ≤M2,
then γ0 + γ1 = (M1 −M0) + (Ď
M −M1) = Ď
M −M0 = Γ. Finally, if M2 < Ď
M, then γ0 + γ1 =
(M1 −M0) + (M2 −M1) = M2 −M0 = Γ."
REFERENCES,0.208955223880597,"Lemma 19. Let pg be a stochastic oracle in Rd. Then, for any x, y, z ∈Rd and any τ > 0, we have"
REFERENCES,0.20963364993215738,"Varpg(x) ≤(1 + τ) Varpg(y) + (1 + τ −1) Varpg(x, y),"
REFERENCES,0.21031207598371776,"Varpg(x, y) ≤(1 + τ) Varpg(x, z) + (1 + τ −1) Varpg(y, z)."
REFERENCES,0.21099050203527817,"Proof. Both inequalities are direct consequences of the standard inequality ∥s1 + s2∥2
∗≤(1 +
τ)∥s1∥2
∗+ (1 + τ −1)∥s2∥2
∗which is valid for any s1, s2 ∈Rd and any τ > 0. Indeed, let g
and ξ be, respectively, the function and the random variable components of pg, and let ∆(x, ξ) :=
g(x, ξ) −E[g(x, ξ)] for any x ∈Rd. Then, for any x, y, z ∈Rd and τ > 0, we can estimate"
REFERENCES,0.21166892808683854,"Varpg(x) ≡E[∥∆(x, ξ)∥2
∗] = E[∥∆(y, ξ) + [∆(x, ξ) −∆(y, ξ)]∥2
∗]"
REFERENCES,0.21234735413839892,"≤(1 + τ) E[∥∆(y, ξ)∥2
∗] + (1 + τ −1) E[∥∆(x, ξ) −∆(y, ξ)∥2
∗]"
REFERENCES,0.2130257801899593,"≡(1 + τ) Varpg(y) + (1 + τ −1) Varpg(x, y)."
REFERENCES,0.21370420624151967,"Similarly,"
REFERENCES,0.21438263229308005,"Varpg(x, y) ≡E

∥∆(x, ξ) −∆(y, ξ)∥2
∗

= E

∥[∆(x, ξ) −∆(z, ξ)] −[∆(y, ξ) −∆(z, ξ)]∥2
∗
"
REFERENCES,0.21506105834464043,"≤(1 + τ) E

∥∆(x, ξ) −∆(z, ξ)∥2
∗

+ (1 + τ −1) E

∥∆(y, ξ) −∆(z, ξ)∥2
∗
"
REFERENCES,0.2157394843962008,"≡(1 + τ) Varpg(x, z) + (1 + τ −1) Varpg(y, z)."
REFERENCES,0.21641791044776118,"B
Omitted Proofs for Section 3"
REFERENCES,0.21709633649932158,"Lemma 20 (AdaGrad stepsize). Let function f satisfy Assumption 1. Consider the stepsize update
rule x
M+ = M+(M, Ω, x, px+, pgx, pgx+) defined by"
REFERENCES,0.21777476255088196,"x
M+ := r"
REFERENCES,0.21845318860244234,M 2 + 1
REFERENCES,0.21913161465400272,Ω∥pgx+ −pgx∥2∗.
REFERENCES,0.2198100407055631,"Then, this stepsize update rules satisfies (2) with c1 = 5"
REFERENCES,0.22048846675712347,"2, c2 = 4, c3 = 6, c4 = 2."
REFERENCES,0.22116689280868385,"Proof. Let p∆(Ď
M) := βf, sf,sg(x, px+) + ⟨sg(x) −pgx, px+ −x⟩−
Ď
M"
REFERENCES,0.22184531886024422,"2 ∥px+ −x∥2. From our Assumption 1
and Theorem 14 (inequality (8)), it follows that βf, sf,sg(x, px+)+βf, sf,sg(px+, x) ≤⟨sg(px+)−sg(x), px+−
x⟩+ 2δf. Hence,"
REFERENCES,0.2225237449118046,"E[p∆(x
M+)+βf, sf,sg(px+, x)] ≤E
h
⟨sg(px+)−pgx, px+−x⟩−
x
M+"
REFERENCES,0.223202170963365,"2 ∥px+−x∥2i
+2δf = E[p∆1(x
M+)]+2δf,"
REFERENCES,0.22388059701492538,"where p∆1(x
M+) := ⟨pgx+ −pgx, px+ −x⟩−
x
M+"
REFERENCES,0.22455902306648576,"2 ∥px+ −x∥2. Hence,"
REFERENCES,0.22523744911804613,"Γ := E[p∆(x
M+) + (x
M+ −M)Ω+ βf, sf,sg(px+, x)] ≤E[p∆1(x
M+) + (x
M+ −M)Ω] + 2δf."
REFERENCES,0.2259158751696065,"From the definition of x
M+, it follows that ∥pgx+ −pgx∥2
∗= (x
M 2
+ −M 2)Ω= (x
M+ +M)(x
M+ −M)Ω.
Since x
M+ ≥M, this means that 1"
X,0.2265943012211669,"2x
M+
∥pgx+ −pgx∥2
∗≤(x
M+ −M)Ω≤
1
x
M+
∥pgx+ −pgx∥2
∗"
X,0.22727272727272727,"Let us now upper bound pΓ := p∆1(x
M+) + (x
M+ −M)Ω. For this, let us fix an arbitrary constant
Ď
M ≥0 and consider two cases. If x
M+ ≥Ď
M, we can bound"
X,0.22795115332428764,"pΓ ≤p∆1(x
M+) +
1
x
M+
∥pgx+ −pgx∥2
∗≤p∆1(Ď
M) + 1"
X,0.22862957937584802,"Ď
M ∥pgx+ −pgx∥2
∗=: pΓ(Ď
M)."
X,0.22930800542740842,"If x
M+ ≤Ď
M, we can bound"
X,0.2299864314789688,"pΓ ≤
1"
X,0.23066485753052918,"2x
M+
∥pgx+ −pgx∥2
∗+ (x
M+ −M)Ω≤2(x
M+ −M)Ω= 2[min{x
M+, Ď
M} −M]+Ω."
X,0.23134328358208955,"Combining the two cases, we get pΓ ≤[pΓ(Ď
M)]+ + 2[min{x
M+, Ď
M} −M]+Ω. Thus,"
X,0.23202170963364993,"Γ ≤E[pΓ] + 2δf ≤E

[pΓ(Ď
M)]+
	
+ 2 E

[min{x
M+, Ď
M} −M]+Ω
	
+ 2δf."
X,0.2327001356852103,"Let us now estimate the first term. Denote pS := pgx −sg(x) and pS+ := pgx+ −sg(px+). Then,"
X,0.23337856173677068,"pΓ(Ď
M) ≡⟨pgx+ −pgx, px+ −x⟩−
Ď
M"
X,0.23405698778833106,2 ∥px+ −x∥2 + 1
X,0.23473541383989144,"Ď
M ∥pgx+ −pgx∥2
∗"
X,0.23541383989145184,"≤⟨sg(px+) −sg(x), px+ −x⟩+ 2"
X,0.23609226594301222,"Ď
M ∥sg(px+) −sg(x)∥2
∗"
X,0.2367706919945726,"+ ⟨pS+ −pS, px+ −x⟩+ 2"
X,0.23744911804613297,"Ď
M ∥pS+ −pS∥2
∗−
Ď
M"
X,0.23812754409769335,2 ∥px+ −x∥2
X,0.23880597014925373,"Using now our Assumption 1 and Theorem 14 (inequalities (9) and (12)), we can continue as follows:"
X,0.2394843962008141,"pΓ(Ď
M) ≤Lf∥px+ −x∥2 + 2δf + 2"
X,0.24016282225237448,"Ď
M (L2
f∥px+ −x∥2 + 4Lfδf)"
X,0.24084124830393486,"+ ⟨pS+ −pS, px+ −x⟩+ 2"
X,0.24151967435549526,"Ď
M ∥pS+ −pS∥2
∗−
Ď
M"
X,0.24219810040705564,2 ∥px+ −x∥2
X,0.24287652645861602,"≤⟨pS+ −pS, px+ −x⟩+ 2"
X,0.2435549525101764,"Ď
M ∥pS+ −pS∥2
∗−
Ď
M −2Lf(1 + 2Lf"
X,0.24423337856173677,"Ď
M )
2
∥px+ −x∥2 + 2

1 + 4Lf Ď
M 
δf ≤
 2"
X,0.24491180461329715,"Ď
M +
1"
X,0.24559023066485752,"2[Ď
M −2Lf(1 + 2Lf"
X,0.2462686567164179,"Ď
M )]"
X,0.24694708276797828,"
∥pS+ −pS∥2
∗+ 2

1 + 4Lf Ď
M 
δf."
X,0.24762550881953868,"Consequently,"
X,0.24830393487109906,"E

[pΓ(Ď
M)]+
	
≤
 2"
X,0.24898236092265943,"Ď
M +
1"
X,0.2496607869742198,"2[Ď
M −2Lf(1 + 2Lf"
X,0.2503392130257802,"Ď
M )]"
X,0.2510176390773406,"
E[∥pS+ −pS∥2
∗] + 2

1 + 4Lf Ď
M 
δf."
X,0.25169606512890097,"In particular, for Ď
M > 4Lf, we can estimate 2"
X,0.25237449118046135,"Ď
M +
1
2[ Ď
M−2Lf (1+
2Lf"
X,0.2530529172320217,"Ď
M )] ≤
2
Ď
M +
1
2( Ď
M−4Lf ) ≤
5
2( Ď
M−4Lf )."
X,0.2537313432835821,"Therefore, for any Ď
M > 4Lf,"
X,0.2544097693351425,"E

[pΓ(Ď
M)]+
	
≤
5
2(Ď
M −4Lf) E[∥pS+−pS∥2
∗]+4δf =
5
2(Ď
M −4Lf) E[Varpg(px+)+Varpg(x)]+4δf,"
X,0.25508819538670285,"where the final identity follows from the fact that E[∥pS+ −pS∥2
∗] = E[∥pS+∥2
∗] + E[∥pS∥2
∗] =
E[Varpg(px+)] + Varpg(x) (because pS+, conditioned on the randomness ξ defining pgx ≡g(x, ξ),
has zero mean)."
X,0.25576662143826323,"Combining everything together, we get"
X,0.2564450474898236,"Γ ≤
5
2(Ď
M −4Lf) E[Varpg(px+) + Varpg(x)] + 6δf + 2 E

[min{x
M+, Ď
M} −M]+Ω
	
."
X,0.257123473541384,This is exactly (2) with c1 = 5
X,0.25780189959294436,"2, c2 = 4, c3 = 6, c4 = 2."
X,0.25848032564450474,"Lemma 21. Let function f satisfy Assumption 1.
Consider the stepsize update rule x
M+ =
M+(M, Ω, x, px+, pgx, pgx+) defined as the solution of the following equation:"
X,0.2591587516960651,"(x
M+ −M)Ω= [p∆1(x
M+)]+,
p∆1(x
M+) := ⟨pgx+ −pgx, px+ −x⟩−
x
M+"
X,0.2598371777476255,2 ∥px+ −x∥2.
X,0.26051560379918587,"Then, this stepsize update rules satisfies (2) with c1 = 1, c2 = 2, c3 = 6, c4 = 2."
X,0.26119402985074625,"Proof. Let us define p∆(Ď
M) := βf, sf,sg(x, px+) + ⟨sg(x) −pgx, px+ −x⟩−
Ď
M"
X,0.2618724559023066,"2 ∥px+ −x∥2. Starting as in
the proof of Lemma 20, we see that"
X,0.26255088195386705,"Γ := E[p∆(x
M+) + (x
M+ −M)Ω+ βf, sf,sg(px+, x)] ≤E[p∆1(x
M+) + (x
M+ −M)Ω] + 2δf,"
X,0.26322930800542743,with the same p∆1(·) as defined in the statement.
X,0.2639077340569878,"Let us now upper bound pΓ := p∆1(x
M+) + (x
M+ −M)Ω. For this, let us fix an arbitrary constant
Ď
M ≥0 and consider two cases. If x
M+ ≥Ď
M, we can bound, using the monotonicity of p∆1(·),"
X,0.2645861601085482,"pΓ = p∆1(x
M+) + [p∆1(x
M+)]+ ≤p∆1(Ď
M) + [p∆1(Ď
M)]+ ≤2[p∆1(Ď
M)]+."
X,0.26526458616010856,"If x
M+ ≤Ď
M, we can bound"
X,0.26594301221166894,"pΓ ≤[p∆1(x
M+)]+ + (x
M+ −M)Ω= 2(x
M+ −M)Ω= 2[min{x
M+, Ď
M} −M]+Ω."
X,0.2666214382632293,"Combining the two cases, we get pΓ ≤2[p∆1(Ď
M)]+ + 2[min{x
M+, Ď
M} −M]+Ω, and hence"
X,0.2672998643147897,"Γ ≤E[pΓ] + 2δf ≤2 E

[p∆1(Ď
M)]+
	
+ 2 E

[min{x
M+, Ď
M} −M]+Ω
	
+ 2δf."
X,0.26797829036635007,"Let us now estimate the first term. According to our Assumption 1 and Theorem 14 (inequality (9)),
we have ⟨sg(px+) −sg(x), px+ −x⟩≤Lf∥px+ −x∥2 + 2δf. Hence, denoting pS := pgx −sg(x) and
pS+ := pgx+ −sg(px+), we can estimate, for any Ď
M > 2Lf,"
X,0.26865671641791045,"p∆1(Ď
M) = ⟨sg(px+) −sg(x), px+ −x⟩+ ⟨pS+ −pS, px+ −x⟩−
Ď
M"
X,0.2693351424694708,2 ∥px+ −x∥2
X,0.2700135685210312,"≤⟨pS+ −pS, px+ −x⟩−
Ď
M −2Lf"
X,0.2706919945725916,"2
∥px+ −x∥2 + 2δf ≤
1
2(Ď
M −2Lf)∥pS+ −pS∥2
∗+ 2δf."
X,0.27137042062415195,"Hence,"
X,0.27204884667571233,"E

[p∆1(Ď
M)]+
	
≤
1
2(Ď
M −2Lf) E[∥pS+−pS∥2
∗]+2δf =
1
2(Ď
M −2Lf) E[Varpg(px+)+Varpg(x)]+2δf,"
X,0.2727272727272727,"where the final identity follows from the fact that E[∥pS+ −pS∥2
∗] = E[∥pS+∥2
∗] + E[∥pS∥2
∗] =
E[Varpg(px+)] + Varpg(x) (because pS+, conditioned on the randomness ξ defining pgx ≡g(x, ξ),
has zero mean). Thus,"
X,0.2734056987788331,"Γ ≤
1
Ď
M −2Lf
E[Varpg(px+) + Varpg(x)] + 6δf + 2 E

[min{x
M+, Ď
M} −M]+Ω
	
,"
X,0.27408412483039346,"which is exactly (2) with c1 = 1, c2 = 2, c3 = 6, c4 = 2."
X,0.2747625508819539,"C
Omitted Proofs for Section 4"
X,0.27544097693351427,"C.1
Universal SGD"
X,0.27611940298507465,"Lemma 22 (Stochastic Gradient Step). Consider problem (1) under Assumption 1. Let pg be an
unbiased oracle for sg. Let x ∈dom ψ be a point, M ≥0 be a coefficient, pgx ∼= pg(x), and let"
X,0.276797829036635,"px+ = Proxψ(x, pgx, M)."
X,0.2774762550881954,"Denote p∆(M) := βf, sf,sg(x, px+) + ⟨sg(x) −pgx, px+ −x⟩−M"
X,0.2781546811397558,"2 ∥px+ −x∥2. Then,"
X,0.27883310719131615,"E
h
F(px+) −F ∗+ M"
X,0.27951153324287653,"2 ∥px+ −x∗∥2i
+ βf, sf,sg(x, x∗) ≤M"
X,0.2801899592944369,2 ∥x −x∗∥2 + E[p∆(M)].
X,0.2808683853459973,"If further Assumption 2 is satisfied, and x
M+ ≥M is a random coefficient (possibly dependent on pgx),
then, we also have"
X,0.28154681139755766,"E
h
F(px+)−F ∗+
x
M+"
X,0.28222523744911804,"2 ∥px+−x∗∥2i
+βf, sf,sg(x, x∗) ≤M"
X,0.2829036635006784,"2 ∥x−x∗∥2+E
p∆(x
M+)+(x
M+−M)D2
."
X,0.2835820895522388,"Proof. From Lemma 17, it follows that"
X,0.28426051560379917,"sf(x) + ⟨pgx, px+ −x⟩+ ψ(px+) + M"
X,0.28493894165535955,2 ∥px+ −x∗∥2 + M
X,0.2856173677069199,2 ∥px+ −x∥2
X,0.2862957937584803,"≤sf(x) + ⟨pgx, x∗−x⟩+ ψ(x∗) + M"
X,0.28697421981004073,2 ∥x −x∗∥2.
X,0.2876526458616011,Passing to expectations and rewriting
X,0.2883310719131615,"E[ sf(x) + ⟨pgx, x∗−x⟩+ ψ(x∗)] = sf(x) + ⟨sg(x), x∗−x⟩+ ψ(x∗) = F(x∗) −βf, sf,sg(x, x∗),"
X,0.28900949796472186,"and
sf(x) + ⟨pgx, px+ −x⟩+ ψ(px+) = F(px+) −[f(px+) −sf(x) −⟨pgx, px+ −x⟩]
= F(px+) −[βf, sf,sg(x, px+) + ⟨sg(x) −pgx, px+ −x⟩],"
X,0.28968792401628224,we obtain the first of the claimed inequalities.
X,0.2903663500678426,"To prove the second one, we simply add to both sides of the already proved first inequality the
expected value of"
X,0.291044776119403,"x
M+ −M"
X,0.29172320217096337,"2
∥px+ −x∗∥2 + p∆(M) −p∆(x
M+) =
x
M+ −M"
X,0.29240162822252375,"2
 
∥px+ −x∗∥2 + ∥px+ −x∥2"
X,0.2930800542740841,"and then bound ∥px+ −x∗∥≤D, ∥px+ −x∥≤D using our Assumption 2 and the fact that
x, px+, x∗∈dom ψ."
X,0.2937584803256445,"Lemma 23 (Universal Stochastic Gradient Step). Consider problem (1) under Assumptions 1 and 2.
Let pg be an unbiased oracle for sg. Further, let x ∈dom ψ be a point, M ≥0 be a coefficient,
pgx ∼= pg(x), and let"
X,0.2944369063772049,"px+ = Proxψ(x, pgx, M),
pgx+ ∼= pg(px+),
x
M+ = M+(M, D2, x, px+, pgx, pgx+)."
X,0.29511533242876525,"Then, for any Ď
M > c2Lf, it holds that"
X,0.29579375848032563,"E
h
F(px+) −F ∗+
x
M+"
X,0.296472184531886,"2 ∥px+ −x∗∥2 + βf, sf,sg(px+, x)
i
+ βf, sf,sg(x, x∗) ≤M"
X,0.2971506105834464,"2 ∥x−x∗∥2+
c1
Ď
M −c2Lf
E[Varpg(px+)+Varpg(x)]+c3δf +c4 E

[min{x
M+, Ď
M}−M]+D2	
."
X,0.29782903663500676,"Proof. According to Lemma 22,"
X,0.29850746268656714,"E
h
F(px+)−F ∗+
x
M+"
X,0.29918588873812757,"2 ∥px+−x∗∥2i
+βf, sf,sg(x, x∗) ≤M"
X,0.29986431478968795,"2 ∥x−x∗∥2+E
p∆(x
M+)+(x
M+−M)D2
,"
X,0.3005427408412483,"where p∆(x
M+) := βf, sf,sg(x, px+)+⟨sg(x)−pgx, px+−x⟩−
x
M+"
X,0.3012211668928087,"2 ∥px+−x∥2. At the same time, according
to the main requirement (2) on the stepsize update rule, for any Ď
M > c2Lf,"
X,0.3018995929443691,"E
p∆(x
M+) + (x
M+ −M)D2 + βf, sf,sg(px+, x)
"
X,0.30257801899592945,"≤
c1
Ď
M −c2Lf
E[Varpg(px+) + Varpg(x)] + c3δf + c4 E

[min{x
M+, Ď
M} −M]+D2	
."
X,0.30325644504748983,"Combining the two displays, we get the claim."
X,0.3039348710990502,"Lemma 24 (Universal SGD: General Guarantee). Consider problem (1) under Assumptions 1 and 2.
Let pg be an unbiased oracle for sg. Further, let x ∈dom ψ be a point, M ≥0 be a coefficient, N ≥1
be an integer, and let
(sxN, xN, MN) ∼= UniSgdpg,ψ(x0, M0, N; D),
as defined by Algorithm 1, and let x0, . . . , xN be the corresponding points generated inside the
algorithm. Then, for any Ď
M > c2Lf, it holds that"
X,0.3046132971506106,"E
h
N[F(sxN) −F ∗] + MN"
X,0.30529172320217096,"2 ∥xN −x∗∥2 + N−1
X"
X,0.30597014925373134,"k=0
[βf, sf,sg(xk+1, xk) + βf, sf,sg(xk, x∗)]
i ≤M0"
X,0.3066485753052917,"2 ∥x0 −x∗∥2 +
c1
Ď
M −c2Lf N−1
X"
X,0.3073270013568521,"k=0
E[Varpg(xk+1) + Varpg(xk)] + c3Nδf"
X,0.30800542740841247,"+ c4 E

[min{MN, Ď
M} −M0]+D2	
."
X,0.30868385345997285,"Proof. Each iteration k of the algorithm, when conditioned on xk, follows the construction from
Lemma 23 (with x = xk, pgx = gk, M = Mk, px+ = xk+1, pgx+ = gk+1, x
M+ = Mk+1). Hence, we
can write, after passing to full expectations, that, for each k = 0, . . . , N −1,"
X,0.3093622795115332,"E
h
F(xk+1) −F ∗+ Mk+1"
X,0.3100407055630936,"2
∥xk+1 −x∗∥2 + βf, sf,sg(xk+1, xk) + βf, sf,sg(xk, x∗)
i"
X,0.310719131614654,"≤E
hMk"
X,0.3113975576662144,"2 ∥xk−x∗∥2+
c1
Ď
M −c2Lf
[Varpg(xk+1)+Varpg(xk)]+c4[min{Mk+1, Ď
M}−Mk]+D2i
+c3δf,"
X,0.3120759837177748,"where Ď
M > 2Lf is an arbitrary constant. Telescoping the above inequalities (using Lemma 18) and
then bounding N[F(sxN) −F ∗] ≤PN
k=1[F(xk) −F ∗] (using the convexity of F and our choice of
sxN = 1"
X,0.31275440976933516,"N
PN
k=1 xk), we get the claim."
X,0.31343283582089554,"Theorem 4. Let Algorithm 1 with M0 = 0 be applied to problem (1) under Assumptions 1–3. Then,
for the point sxN generated by the algorithm, we have"
X,0.3141112618724559,E[F(sxN)] −F ∗≤c2c4LfD2
X,0.3147896879240163,"N
+ 2σD r 2c1c4"
X,0.31546811397557667,"N
+ c3δf."
X,0.31614654002713705,"Proof. Applying Lemma 24, substituting our choice of M0 = 0, estimating Varpg(·) ≤σ2 and
dropping the nonnegative βf, sf,sg(·, ·) terms, we obtain"
X,0.3168249660786974,E[F(sxN)] −F ∗≤1 N
X,0.3175033921302578,"
c4 Ď
MD2 +
2c1σ2N
Ď
M −c2Lf
+ c3Nδf

= c4 Ď
MD2"
X,0.3181818181818182,"N
+
2c1σ2"
X,0.31886024423337855,"Ď
M −c2Lf
+ c3δf,"
X,0.31953867028493893,"where Ď
M > 2Lf is an arbitrary constant. The optimal Ď
M which minimizes the right-hand side is
Ď
M = c2Lf + σ D
q 2c1"
X,0.3202170963364993,"c4 N. Substituting this choice into the above display, we get"
X,0.3208955223880597,E[F(sxN)] −F ∗≤c4D2 N
X,0.32157394843962006,"
c2Lf + σ D r 2c1"
X,0.32225237449118044,"c4
N

+
2c1σ2 σ
D
q 2c1"
X,0.3229308005427408,"c4 N
+ c3δf"
X,0.32360922659430125,= c2c4LfD2
X,0.3242876526458616,"N
+ 2σD r 2c1c4"
X,0.324966078697422,"N
+ c3δf."
X,0.3256445047489824,"C.2
Universal Fast SGD"
X,0.32632293080054275,"Lemma 25 (Stochastic Triangle Step). Consider problem (1) under Assumption 1. Let pg be an
unbiased oracle for sg, let x, v ∈dom ψ be points and M, A ≥0, a > 0 be coefficients. Further, for
A+ := A + a, let"
X,0.32700135685210313,y = Ax + av
X,0.3276797829036635,"A+
,
pgy ∼= pg(y),
pv+ = Proxψ(v, pgy, M/a),
px+ = Ax + apv+ A+
."
X,0.3283582089552239,"Denote p∆(M) := βf, sf,sg(y, px+) + ⟨sg(y) −pgy, px+ −y⟩−MA+"
X,0.32903663500678426,"2a2 ∥px+ −y∥2. Then,"
X,0.32971506105834464,"E
h
A+[F(px+) −F ∗] + M"
X,0.330393487109905,"2 ∥pv+ −x∗∥2i
+ Aβf, sf,sg(y, x) + aβf, sf,sg(y, x∗)"
X,0.3310719131614654,≤A[F(x) −F ∗] + M
X,0.33175033921302577,2 ∥v −x∗∥2 + A+ E[p∆(M)].
X,0.33242876526458615,"If further Assumption 2 is satisfied, and x
M+ ≥M is a random coefficient (possibly dependent on pgy),
then we also have"
X,0.3331071913161465,"E
h
A+[F(px+) −F ∗] +
x
M+"
X,0.3337856173677069,"2 ∥pv+ −x∗∥2i
+ Aβf, sf,sg(y, x) + aβf, sf,sg(y, x∗)"
X,0.3344640434192673,≤A[F(x) −F ∗] + M
X,0.33514246947082765,"2 ∥v −x∗∥2 + E[A+ p∆(x
M+) + (x
M+ −M)D2],"
X,0.3358208955223881,"Proof. Denoting θ := Aβf, sf,sg(y, x) + aβf, sf,sg(y, x∗) and using the fact that E[pgy] = sg(y), we can
rewrite"
X,0.33649932157394846,AF(x) + aF(x∗) + M
X,0.33717774762550884,2 ∥v −x∗∥2
X,0.3378561736770692,"= A[ sf(y) + ⟨sg(y), x −y⟩+ βf, sf,sg(y, x) + ψ(x)]"
X,0.3385345997286296,"+ a[ sf(y) + ⟨sg(y), x∗−y⟩+ βf, sf,sg(y, x∗) + ψ(x∗)] + M"
X,0.33921302578018997,2 ∥v −x∗∥2
X,0.33989145183175035,"= A+ sf(y) + ⟨sg(y), Ax + ax∗−A+y⟩+ Aψ(x) + aψ(x∗) + M"
X,0.3405698778833107,2 ∥v −x∗∥2 + θ
X,0.3412483039348711,"= E
h
A+ sf(y) + ⟨pgy, Ax + ax∗−A+y⟩+ Aψ(x) + aψ(x∗) + M"
X,0.3419267299864315,"2 ∥v −x∗∥2i
+ θ."
X,0.34260515603799185,"Further, by the definition of pv+ and Lemma 17,"
X,0.34328358208955223,"⟨pgy, x∗−pv+⟩+ ψ(x∗) + M"
X,0.3439620081411126,2a∥v −x∗∥2 ≥ψ(pv+) + M
X,0.344640434192673,2a∥v −pv+∥2 + M
X,0.34531886024423336,2a∥pv+ −x∗∥2.
X,0.34599728629579374,This means that
X,0.3466757123473541,"A+ sf(y) + ⟨pgy, Ax + ax∗−A+y⟩+ Aψ(x) + aψ(x∗) + M"
X,0.3473541383989145,2 ∥v −x∗∥2
X,0.3480325644504749,"≥A+ sf(y) + ⟨pgy, Ax + apv+ −A+y⟩+ Aψ(x) + aψ(pv+) + M"
X,0.3487109905020353,2 ∥v −pv+∥2 + M
X,0.3493894165535957,2 ∥pv+ −x∗∥2
X,0.35006784260515605,"≥A+[ sf(y) + ⟨pgy, px+ −y⟩+ ψ(px+)] + M"
X,0.35074626865671643,2 ∥v −pv+∥2 + M
X,0.3514246947082768,2 ∥pv+ −x∗∥2
X,0.3521031207598372,= A+F(px+) + M
X,0.35278154681139756,"2 ∥pv+ −x∗∥2 −A+ p∆(M),"
X,0.35345997286295794,"where the second inequality is due to the definition of px+ and the convexity of ψ, and"
X,0.3541383989145183,"p∆(M) := f(px+) −sf(y) −⟨pgy, px+ −y⟩−M"
X,0.3548168249660787,"2A+
∥v −pv+∥2"
X,0.35549525101763907,"= βf, sf,sg(y, px+) + ⟨sg(y) −pgy, px+ −y⟩−MA+"
X,0.35617367706919945,2a2 ∥px+ −y∥2
X,0.3568521031207598,"since px+ −y =
a
A+ (pv+ −v) (by the definitions of y and px+). Substituting the above inequality into
the first display and rearranging, we get the first of the claimed inequalities."
X,0.3575305291723202,"To prove the second one, we simply add to both sides of the already proved first inequality the
expected value of"
X,0.3582089552238806,"x
M+ −M"
X,0.35888738127544095,"2
∥pv+ −x∗∥2 + A+[p∆(M) −p∆(x
M+)] =
x
M+ −M 2"
X,0.35956580732700133,"
∥pv+ −x∗∥2 + A2
+
a2 ∥px+ −y∥2"
X,0.36024423337856176,"and then bound, using the fact that px+ −y =
a
A+ (pv+ −v) together with our Assumption 2,"
X,0.36092265943012214,"∥pv+ −x∗∥2 + A2
+
a2 ∥px+ −y∥2 = ∥pv+ −x∗∥2 + ∥pv+ −v∥2 ≤2D2."
X,0.3616010854816825,"Lemma 26 (Universal Stochastic Triangle Step). Consider problem (1) under Assumptions 1 and 2,
and let pg be an unbiased oracle for sg. Let x, v ∈dom ψ be points, M, A ≥0, a > 0 be coefficients.
Further, for A+ := A + a, let"
X,0.3622795115332429,y = Ax + av
X,0.36295793758480327,"A+
,
pgy ∼= pg(y),
pv+ = Proxψ(v, pgy, M/a),
px+ = Ax + apv+ A+
,"
X,0.36363636363636365,"pgx+ ∼= pg(px+),
x
M+ = a2"
X,0.364314789687924,"A+
M+
A+"
X,0.3649932157394844,"a2 M, a2"
X,0.3656716417910448,"A2
+
D2, y, px+, pgy, pgx+

."
X,0.36635006784260515,"Then, for any Ď
M > c2Lf a2"
X,0.36702849389416553,"A+ , it holds that"
X,0.3677069199457259,"E
h
A+[F(px+) −F ∗] +
x
M+"
X,0.3683853459972863,"2 ∥pv+ −x∗∥2 + A+βf, sf,sg(px+, y)
i
+ Aβf, sf,sg(y, x) + aβf, sf,sg(y, x∗)"
X,0.36906377204884666,≤A[F(x) −F ∗] + M
X,0.36974219810040704,"2 ∥v −x∗∥2 +
c1a2"
X,0.3704206241519674,"Ď
M −c2Lf a2"
X,0.3710990502035278,"A+
E[Varpg(px+) + Varpg(y)]"
X,0.37177747625508817,"+ c3A+δf + c4 E

[min{x
M+, Ď
M} −M]+D2	
."
X,0.3724559023066486,"Proof. According to Lemma 25 (together with the fact that x
M+ ≥M which is guaranteed by the
requirement on the stepsize update rule), we have"
X,0.373134328358209,"E
h
A+[F(px+) −F ∗] +
x
M+"
X,0.37381275440976935,"2 ∥pv+ −x∗∥2i
+ Aβf, sf,sg(y, x) + aβf, sf,sg(y, x∗)"
X,0.37449118046132973,≤A[F(x) −F ∗] + M
X,0.3751696065128901,"2 ∥v −x∗∥2 + E

A+ p∆(x
M+) + (x
M+ −M)D2
,"
X,0.3758480325644505,"where p∆(x
M+) := βf, sf,sg(y, px+)+⟨sg(y)−pgy, px+ −y⟩−
x
M+A+"
X,0.37652645861601086,"2a2
∥px+ −y∥2. Further, according to the"
X,0.37720488466757124,main requirement (2) on the stepsize update rule (applied in the variables M ′ := A+
X,0.3778833107191316,"a2 M, Ω:=
a2"
X,0.378561736770692,"A2
+ D2,"
X,0.37924016282225237,"x
M ′
+ := A+"
X,0.37991858887381275,"a2 x
M+, Ď
M ′ := A+"
X,0.3805970149253731,"a2 Ď
M for which we have M ′Ω= M D2"
X,0.3812754409769335,"A+ , x
M ′
+Ω= x
M+ D2"
X,0.3819538670284939,"A+ , Ď
M ′Ω= Ď
M D2"
X,0.38263229308005425,"A+ ),
it holds that"
X,0.38331071913161463,"E
h
p∆(x
M+) + (x
M+ −M) D2"
X,0.383989145183175,"A+
+ βf, sf,sg(px+, y)
i"
X,0.38466757123473544,"≤
c1
A+"
X,0.3853459972862958,"a2 Ď
M −c2Lf
E[Varpg(px+) + Varpg(y)] + c3δf + c4 E
n
[min{x
M+, Ď
M} −M]+
D2 A+ o
,"
X,0.3860244233378562,"where Ď
M > c2Lf a2"
X,0.38670284938941657,"A+ is an arbitrary constant. Multiplying both sides of the above display by A+ and
adding the result to the first display, we obtain the claim."
X,0.38738127544097695,"Lemma 27 (Universal Fast SGD: General Guarantee). Consider Algorithm 2 applied to problem (1)
under Assumptions 1 and 2. Then, for any k ≥1 and any Ď
M > c2Lf, it holds that"
X,0.3880597014925373,"E
h
Ak[F(xk) −F ∗] + k−1
X"
X,0.3887381275440977,"i=0
[Ai+1βf, sf,sg(xi+1, yi) + ai+1βf, sf,sg(yi, x∗)]
i"
X,0.3894165535956581,"≤c4 Ď
MD2 +
c1
Ď
M −c2Lf k−1
X"
X,0.39009497964721845,"i=0
a2
i+1 E[Varpg(xi+1) + Varpg(yi)] + c3δf k
X"
X,0.39077340569877883,"i=1
Ai,"
X,0.3914518317503392,where ak = 1
X,0.3921302578018996,"2k, Ak = 1"
X,0.39280868385345996,"4k(k + 1), Pk
i=1 a2
i =
1
24k(k + 1)(2k + 1), Pk
i=1 Ai =
1
12k(k + 1)(k + 2)
for each k ≥1."
X,0.39348710990502034,"Proof. Each iteration k of the algorithm, when conditioned on (xk, vk), follows the construction
from Lemma 26 (with x = xk, v = vk, M = Mk, A = Ak, a = ak+1, A+ = Ak+1, y = yk,
pgy = gyk, pv+ = vk+1, px+ = xk+1, pgx+ = gxk+1, x
M+ = Mk+1), where Ak and ak are the following
coefficients: ak = 1"
X,0.3941655359565807,"2k, Ak = Pk
i=1 ai = 1"
X,0.3948439620081411,"4k(k + 1). Applying Lemma 26 (dropping the nonnegative
βf, sf,sg(y, x) term) and passing to full expectations, we therefore obtain, for each k ≥0,"
X,0.39552238805970147,"E
h
Ak+1[F(xk+1) −F ∗] + Mk+1"
X,0.39620081411126185,"2
∥vk+1 −x∗∥2 + Ak+1βf, sf,sg(xk+1, yk) + ak+1βf, sf,sg(yk, x∗)
i"
X,0.3968792401628223,"≤E
h
Ak[F(xk) −F ∗] + Mk"
X,0.39755766621438265,"2 ∥vk −x∗∥2 +
c1a2
k+1
Ď
M −c2Lf
a2
k+1
Ak+1"
X,0.39823609226594303,"[Varpg(xk+1) + Varpg(yk)]
i"
X,0.3989145183175034,"+ c3Ak+1δf + c4 E

[min{Mk+1, Ď
M} −Mk]+D2	
,"
X,0.3995929443690638,"where Ď
M is an arbitrary constant such that Ď
M > c2Lf
a2
k+1
Ak+1 . Note however that, for our sequences ak"
X,0.40027137042062416,"and Ak, we have a2
k
Ak ="
X,0.40094979647218454,"1
4 k2"
X,0.4016282225237449,"1
4 k(k+1) =
k
k+1 ≤1. Therefore, we can replace
c1a2
k+1"
X,0.4023066485753053,"Ď
M−c2Lf
a2
k+1
Ak+1
in the above"
X,0.40298507462686567,"display with
c1a2
k+1
Ď
M−c2Lf under the requirement that Ď
M > c2Lf. Doing this and then telescoping the
above inequalities (applying Lemma 18), and using the fact that M0 = A0 = 0, we get the claimed
inequality."
X,0.40366350067842605,"It remains to do some standard computations to see that Pk
i=1 a2
i ≡1"
PK,0.4043419267299864,"4
Pk
i=1 i2 =
1
24k(k+1)(2k+1)
and Pk
i=1 Ai ≡1"
PK,0.4050203527815468,"4
Pk
i=1 i(i + 1) = 1 4( 1"
PK,0.4056987788331072,6k(k + 1)(2k + 1) + 1
PK,0.40637720488466755,"2k(k + 1)) =
1
12k(k + 1)(k + 2)."
PK,0.40705563093622793,"Theorem 5. Let Algorithm 2 be applied to problem (1) under Assumptions 1–3. Then, for any k ≥1,"
PK,0.4077340569877883,E[F(xk)] −F ∗≤4c2c4LfD2
PK,0.4084124830393487,"k(k + 1)
+ 4σD r 2c1c4"
K,0.4090909090909091,"3k
+ c3"
K,0.4097693351424695,3 (k + 2)δf.
K,0.41044776119402987,"Proof. Let k ≥1 be arbitrary and Fk := E[F(xk)] −F ∗. Applying Lemma 27, dropping the
nonnegative βf, sf,sg(·, ·) terms and bounding Varpg(·) ≤σ2, we obtain, for an arbitrary constant
Ď
M > c2Lf, Fk ≤1 Ak"
K,0.41112618724559025,"
c4 Ď
MD2 +
2c1σ2"
K,0.4118046132971506,"Ď
M −c2Lf k
X"
K,0.412483039348711,"i=1
a2
i + c3δf k
X"
K,0.4131614654002714,"i=1
Ai
"
K,0.41383989145183175,"=
4
k(k + 1)"
K,0.41451831750339213,"
c4 Ď
MD2 + c1k(k + 1)(2k + 1)σ2"
K,0.4151967435549525,"12(Ď
M −c2Lf)
+ c3"
K,0.4158751696065129,"12k(k + 1)(k + 2)δf
"
K,0.41655359565807326,"= 4c4 Ď
MD2"
K,0.41723202170963364,k(k + 1) + c1(2k + 1)σ2
K,0.417910447761194,"3(Ď
M −c2Lf) + δk,"
K,0.4185888738127544,where δk := c3
K,0.41926729986431477,"3 (k + 2)δf. We now choose Ď
M > c2Lf which minimizes the right-hand side. This is
Ď
M = c2Lf +
σ
2D
q"
K,0.41994572591587515,"c1
3c4 k(k + 1)(2k + 1), for which we get"
K,0.4206241519674355,"Fk ≤
4c4D2"
K,0.42130257801899595,k(k + 1)
K,0.42198100407055633,"
c2Lf + σ"
D,0.4226594301221167,2D r c1
D,0.4233378561736771,"3c4
k(k + 1)(2k + 1)

+
c1(2k + 1)σ2 3 σ"
"D
Q",0.42401628222523746,"2D
q"
"D
Q",0.42469470827679784,"c1
3c4 k(k + 1)(2k + 1)
+ δk"
"D
Q",0.4253731343283582,= 4c2c4LfD2
"D
Q",0.4260515603799186,"k(k + 1)
+ 4σD s"
"D
Q",0.42672998643147897,c1c4(2k + 1)
"D
Q",0.42740841248303935,"3k(k + 1)
+ δk ≤4c2c4LfD2"
"D
Q",0.4280868385345997,"k(k + 1)
+ 4σD r 2c1c4"
K,0.4287652645861601,"3k
+ δk."
K,0.4294436906377205,"D
Omitted Proofs for Section 5"
K,0.43012211668928085,"D.1
Universal SGD"
K,0.43080054274084123,"Theorem 7. Let Algorithm 1 with M0 = 0 be applied to problem (1) under Assumptions 1, 2 and 6,
and let σ2
∗:= Varpg(x∗). Then, for the point sxN produced by the method, we have"
K,0.4314789687924016,E[F(sxN)] −F ∗≤c4(c2Lf + 12c1Lpg)D2
K,0.432157394843962,"N
+ 2σ∗D r 6c1c4"
K,0.43283582089552236,"N
+ c3δf + 4 3δpg."
K,0.4335142469470828,"Proof. Let x0, . . . , xN be the points generated inside the method and let FN := E[F(sxN)] −F ∗.
Using Lemma 19 and Assumption 6, we can estimate, for any 0 ≤k ≤N −1,
Varpg(xk+1) + Varpg(xk) ≤3 Varpg(xk) + 2 Varpg(xk+1, xk)"
K,0.43419267299864317,"≤6σ2
∗+ 6 Varpg(xk, x∗) + 2 Varpg(xk+1, xk)"
K,0.43487109905020355,"≤6σ2
∗+ 12Lpg[βf, sf,sg(xk, x∗) + δpg] + 4Lpg[βf, sf,sg(xk+1, xk) + δpg]"
K,0.4355495251017639,"= 6σ2
∗+ 4Lpg[3βf, sf,sg(xk, x∗) + βf, sf,sg(xk+1, xk) + 4δpg].
Substituting this bound into the general guarantee given by Lemma 24 (and taking into account the
fact that M0 = 0), we obtain NFN + N−1
X"
K,0.4362279511533243,"k=0
E[βf, sf,sg(xk+1, xk) + βf, sf,sg(xk, x∗)]"
K,0.4369063772048847,"≤c4 Ď
MD2 +
6c1σ2
∗N
Ď
M −c2Lf
+ α N−1
X"
K,0.43758480325644505,"k=0
E[βf, sf,sg(xk+1, xk) + 3βf, sf,sg(xk, x∗)] + N(c3δf + 4αδpg),"
K,0.43826322930800543,"where Ď
M > c2Lf is an arbitrary constant and α :=
4c1Lpg
Ď
M−c2Lf . Requiring now that 3α ≤1 or,"
K,0.4389416553595658,"equivalently, that Ď
M ≥c2Lf + 12c1Lpg =: Ď
Mmin, we can cancel the nonnegative βf, sf,sg(·, ·) terms
on both sides and obtain"
K,0.4396200814111262,"FN ≤c4 Ď
MD2"
K,0.44029850746268656,"N
+
6c1σ2
∗
Ď
M −c2Lf
+ δ,"
K,0.44097693351424694,where δ := c3δf + 4
K,0.4416553595658073,"3δpg. The optimal coefficient Ď
M∗minimizing the right-hand side is Ď
M∗="
K,0.4423337856173677,"c2Lf + σ∗ D
q 6c1N"
K,0.44301221166892807,"c4 . However, we still need to respect the constraint Ď
M ≥Ď
Mmin. Choosing Ď
M ="
K,0.44369063772048845,"c2Lf + 12c1Lpg + σ∗ D
q 6c1N"
K,0.4443690637720488,"c4 , we conclude that"
K,0.4450474898236092,FN ≤c4D2 N
K,0.44572591587516963,"
c2Lf + 12c1Lpg + σ∗ D r 6c1N c4"
K,0.44640434192673,"
+
6c1σ2
∗ σ∗ D
q 6c1N c4 + δ"
K,0.4470827679782904,= c4(c2Lf + 12c1Lpg)D2
K,0.44776119402985076,"N
+ 2σ∗D r 6c1c4"
K,0.44843962008141114,"N
+ δ."
K,0.4491180461329715,"D.2
Universal Fast SGD"
K,0.4497964721845319,"Theorem 8. Let Algorithm 2 be applied to problem (1) under Assumptions 1, 2 and 6, and let
σ2
∗:= Varpg(x∗). Then, for any k ≥1, we have"
K,0.45047489823609227,E[F(xk)] −F ∗≤4c2c4LfD2
K,0.45115332428765265,"k(k + 1)
+ 24c1c4LpgD2"
K,0.451831750339213,"k + 1
+ 4σ∗D r 2c1c4"
K,0.4525101763907734,"k
+ c3"
K,0.4531886024423338,3 (k + 2)δf + 4 3δpg.
K,0.45386702849389415,"Proof. Let k ≥1 be arbitrary and Fk := E[F(xk)] −F ∗. Using Lemma 19 and Assumption 6, we
can estimate, for each i,
Varpg(xi+1) + Varpg(yi) ≤3 Varpg(yi) + 2 Varpg(xi+1, yi)"
K,0.45454545454545453,"≤6σ2
∗+ 6 Varpg(yi, x∗) + 2 Varpg(xi+1, yi)"
K,0.4552238805970149,"≤6σ2
∗+ 12Lpg[βf, sf,sg(yi, x∗) + δpg] + 4Lpg[βf, sf,sg(xi+1, yi) + δpg]"
K,0.4559023066485753,"= 6σ2
∗+ 4Lpg[3βf, sf,sg(yi, x∗) + βf, sf,sg(xi+1, yi) + 4δpg]."
K,0.45658073270013566,"Substituting this bound into the guarantee given by Lemma 27, we obtain"
K,0.45725915875169604,"AkFk + k−1
X"
K,0.45793758480325647,"i=0
E[Ai+1βf, sf,sg(xi+1, yi) + ai+1βf, sf,sg(yi, x∗)]"
K,0.45861601085481685,"≤c4 Ď
MD2+ k−1
X"
K,0.4592944369063772,"i=0
αi+1 E[βf, sf,sg(xi+1, yi)+3βf, sf,sg(yi, x∗)+4δpg]+
6c1σ2
∗
Ď
M −c2Lf k
X"
K,0.4599728629579376,"i=1
a2
i +c3δf k
X"
K,0.460651289009498,"i=1
Ai,"
K,0.46132971506105835,"where αi+1 :=
4c1Lpga2
i+1
Ď
M−c2Lf , ai = 1"
K,0.46200814111261873,"2i, Ak = 1"
K,0.4626865671641791,"4k(k + 1), Pk
i=1 a2
i =
1
24k(k + 1)(2k + 1), Pk
i=1 Ai ="
K,0.4633649932157395,"1
12k(k + 1)(k + 2). Requiring now that 3αi+1 ≤ai+1 for all i = 0, . . . , k −1 or, equivalently, that
Ď
M ≥c2Lf + 12c1Lpgak ≡c2Lf + 6c1Lpgk, we can cancel the nonnegative βf, sf,sg(·, ·) terms on both
sides and obtain Fk ≤1 Ak"
K,0.46404341926729986,"
c4 Ď
MD2 +
6c1σ2
∗
Ď
M −c2Lf k
X"
K,0.46472184531886024,"i=1
a2
i + c3δf k
X"
K,0.4654002713704206,"i=1
Ai + 4"
K,0.466078697421981,"3Akδpg
"
K,0.46675712347354137,"=
4
k(k + 1)"
K,0.46743554952510175,"
c4 Ď
MD2 + c1σ2
∗k(k + 1)(2k + 1)"
K,0.4681139755766621,"4(Ď
M −c2Lf)
+ c3"
K,0.4687924016282225,"12δfk(k + 1)(k + 2)

+ 4 3δpg"
K,0.4694708276797829,"= 4c4 Ď
MD2"
K,0.4701492537313433,"k(k + 1) + c1σ2
∗(2k + 1)
Ď
M −c2Lf
+ δk,"
K,0.4708276797829037,where δk := c3
K,0.47150610583446406,3 (k + 2)δf + 4 3δpg.
K,0.47218453188602444,"The minimizer of the right-hand side is Ď
M∗= c2Lf + σ∗"
"D
Q",0.4728629579375848,"2D
q"
"D
Q",0.4735413839891452,"c1
c4 k(k + 1)(2k + 1). However, recall"
"D
Q",0.47421981004070557,"that we also need to satisfy the constraint Ď
M ≥c2Lf + 6c1Lpgk. Choosing Ď
M = c2Lf + 6c1Lpgk +"
"D
Q",0.47489823609226595,"σ∗
2D
q"
"D
Q",0.4755766621438263,"c1
c4 k(k + 1)(2k + 1), we obtain"
"D
Q",0.4762550881953867,"Fk ≤
4c4D2"
"D
Q",0.4769335142469471,k(k + 1)
"D
Q",0.47761194029850745,"
c2Lf + 6c1Lpgk + σ∗"
D,0.47829036635006783,2D rc1
D,0.4789687924016282,"c4
k(k + 1)(2k + 1)

+
c1σ2
∗(2k + 1)"
D,0.4796472184531886,"σ∗
2D
q"
D,0.48032564450474896,"c1
c4 k(k + 1)(2k + 1)
+ δk"
D,0.48100407055630934,= 4c2c4LfD2
D,0.4816824966078697,"k(k + 1)
+ 24c1c4LpgD2"
D,0.48236092265943015,"k + 1
+ 4σ∗D s"
D,0.4830393487109905,c1c4(2k + 1)
D,0.4837177747625509,"k(k + 1)
+ δk"
D,0.4843962008141113,≤4c2c4LfD2
D,0.48507462686567165,"k(k + 1)
+ 24c1c4LpgD2"
D,0.48575305291723203,"k + 1
+ 4σ∗D r 2c1c4"
D,0.4864314789687924,"k
+ δk."
D,0.4871099050203528,"E
Omitted Proofs for Section 6"
D,0.48778833107191316,"Lemma 28 (Basic property of SVRG oracle). Let pg be a stochastic oracle in Rd, and let pG =
SvrgOracpg(˜x) for some ˜x ∈Rd. Then, for any x ∈Rd, the mean value of pG at x is the same as that
of pg at x, while Var p
G(x) = Varpg(x, ˜x)."
D,0.48846675712347354,"Proof. Let g and ξ be, respectively, the function and the random variable components of pg, and let
g(x) := Eξ[g(x, ξ)], g(˜x) := Eξ[g(˜x, ξ)]. Then, by definition, pG is the oracle with the same random
variable component ξ and the function component G defined by G(x, ξ) = g(x, ξ) −g(˜x, ξ) + g(˜x).
Consequently, Eξ[G(x, ξ)] = g(x), and"
D,0.4891451831750339,"Var p
G(x) = Eξ

∥G(x, ξ) −g(x)]∥2
∗
"
D,0.4898236092265943,"= Eξ

∥[g(x, ξ) −g(˜x, ξ)] −[g(x) −g(˜x)]∥2
∗

= Varpg(x, ˜x)."
D,0.49050203527815467,"E.1
Universal SVRG"
D,0.49118046132971505,"Lemma 29 (Universal SVRG Epoch). Consider problem (1) under Assumptions 1, 2, 6 and 9. Let
x, ˜x ∈dom ψ be points, M ≥0 be a coefficient, N ≥1 be an integer, pG = SvrgOracpg(˜x), and let"
D,0.4918588873812754,"(˜x+, x+, M+) ∼= UniSgd p
G,ψ(x, M, N; D),"
D,0.4925373134328358,"as defined by Algorithm 1. Then, for any Ď
M ≥c2Lf + 12c1Lpg, α :=
4c1Lpg
Ď
M−c2Lf , and any ∇f(x∗) ∈
∂f(x∗), it holds that"
D,0.4932157394843962,"E
h
N[F(˜x+) −F ∗] + M+"
D,0.49389416553595655,2 ∥x+ −x∗∥2i
D,0.494572591587517,"≤6αNβ∇f(x∗)
f
(x∗, ˜x)+ M"
D,0.49525101763907736,"2 ∥x−x∗∥2 +N(c3δf +16αδpg)+c4D2 E

[min{M+, Ď
M}−M]+
	
."
D,0.49592944369063774,"Proof. Since pg is an unbiased oracle for sg, so is pG (Lemma 28). Therefore, we can apply Lemma 24
to get"
D,0.4966078697421981,"E
h
N[F(˜x+) −F ∗] + M+"
D,0.4972862957937585,"2 ∥x+ −x∗∥2 + N−1
X"
D,0.49796472184531887,"k=0
[βf, sf,sg(xk+1, xk) + βf, sf,sg(xk, x∗)]
i ≤M"
D,0.49864314789687925,"2 ∥x −x∗∥2 +
c1
Ď
M −c2Lf N−1
X"
D,0.4993215739484396,"k=0
E[Var p
G(xk+1) + Var p
G(xk)] + c3Nδf"
D,0.5,"+ c4 E

[min{M+, Ď
M} −M]+D2	
,"
D,0.5006784260515604,"where Ď
M > c2Lf is an arbitrary constant and xk are the points generated inside UniSgd."
D,0.5013568521031208,"Applying now Lemmas 19 and 28 and Assumptions 6 and 9, we can estimate, for each k,"
D,0.5020352781546812,"Var p
G(xk+1) + Var p
G(xk) = Varpg(xk+1, ˜x) + Varpg(xk, ˜x) ≤2 Varpg(xk+1, xk) + 3 Varpg(xk, ˜x)"
D,0.5027137042062415,"≤2 Varpg(xk+1, xk) + 6 Varpg(xk, x∗) + 6 Varpg(x∗, ˜x)"
D,0.5033921302578019,"≤4Lpg[βf, sf,sg(xk+1, xk) + δpg] + 12Lpg[βf, sf,sg(xk, x∗) + δpg] + 24Lpg[β∇f(x∗)
f
(x∗, ˜x) + 2δpg]"
D,0.5040705563093623,"= 4Lpg[βf, sf,sg(xk+1, xk) + 3βf, sf,sg(xk, x∗) + 6β∇f(x∗)
f
(x∗, ˜x) + 16δpg],"
D,0.5047489823609227,"where ∇f(x∗) ∈∂f(x∗) is arbitrary. Denoting α :=
4c1Lpg
Ď
M−c2Lf , we thus obtain"
D,0.505427408412483,"E
h
N[F(˜x+) −F ∗] + M+"
D,0.5061058344640434,"2 ∥x+ −x∗∥2 + N−1
X"
D,0.5067842605156038,"k=0
[βf, sf,sg(xk+1, xk) + βf, sf,sg(xk, x∗)]
i"
D,0.5074626865671642,"≤6αNβ∇f(x∗)
f
(x∗, ˜x) + M"
D,0.5081411126187245,"2 ∥x −x∗∥2 + N(c3δf + 16αδpg) + c4 E

[min{M+, Ď
M} −M]+D2 + α N−1
X"
D,0.508819538670285,"k=0
E[βf, sf,sg(xk+1, xk) + 3βf, sf,sg(xk, x∗)]."
D,0.5094979647218453,"Requiring now Ď
M ≥c2Lf + 12c1Lpg, we get α ≤1"
WHICH ALLOWS US TO CANCEL THE NONNEGATIVE,0.5101763907734057,"3 which allows us to cancel the nonnegative
βf, sf,sg(·, ·) terms on both sides. The claim now follows."
WHICH ALLOWS US TO CANCEL THE NONNEGATIVE,0.510854816824966,"Theorem 10. Let UniSvrg (as defined by Algorithm 3) be applied to problem (1) under Assumptions 1,
2, 6 and 9. Then, for any t ≥1 and sc3 := max{c3, 1}, we have"
WHICH ALLOWS US TO CANCEL THE NONNEGATIVE,0.5115332428765265,E[F(˜xt)] −F ∗≤[(c2c4 + 1)Lf + 48c1c4Lpg]D2
T,0.5122116689280869,"2t
+ 2sc3δf + 8 3δpg."
T,0.5128900949796472,"To construct ˜xt, the algorithm needs to make O(2t) queries to pg and O(t) queries to sg."
T,0.5135685210312076,"Proof. The algorithm iterates (˜xt+1, xt+1, Mt+1) ∼= UniSgd p
Gt,ψ(xt, Mt, 2t+1; D) for t ≥0, where
pGt = SvrgOracpg(˜xt). Applying Lemma 29 with Ď
M := c2Lf + 48c1Lpg (for which α =
1
12 so that
6α2t+1 = 2t) and passing to full expectations, we obtain, for any t ≥0,"
T,0.514246947082768,"E
h
2t+1[F(˜xt+1) −F ∗] + Mt+1"
T,0.5149253731343284,"2
∥xt+1 −x∗∥2i"
T,0.5156037991858887,"≤E
h
2tβt + Mt"
T,0.5162822252374492,"2 ∥xt −x∗∥2 + c4[min{Mt+1, Ď
M} −Mt]+D2i
+ 2t+1
c3δf + 4"
T,0.5169606512890095,"3δpg

,"
T,0.5176390773405699,"where βt := β∇f(x∗)
f
(x∗, ˜xt) and ∇f(x∗) ∈∂f(x∗) can be chosen arbitrarily. Rewriting Ft+1 :=
F(˜xt+1) −F ∗as Ft+1 = βt+1 + (Ft+1 −βt+1) and telescoping the above inequalities (using,
Lemma 18), we get, for any t ≥1,"
T,0.5183175033921302,"E
h
2tβt + t
X"
T,0.5189959294436907,"i=1
2i(Fi −βi) + Mt"
T,0.519674355495251,2 ∥xt −x∗∥2i
T,0.5203527815468114,≤β0 + M0
T,0.5210312075983717,"2 ∥x0 −x∗∥2 +

c3δf + 4"
T,0.5217096336499322,"3δpg

t
X"
T,0.5223880597014925,"i=1
2i + c4 E

[min{Mt, Ď
M} −M0]+D2"
T,0.5230664857530529,"≤β0 + 2(2t −1)

c3δf + 4"
T,0.5237449118046132,"3δpg

+ c4 Ď
MD2 =: Φ0,"
T,0.5244233378561737,"where the final inequality is due to the fact that M0 = 0, while Pt
i=1 2i = 2(2t −1). According to
Lemma 30, we can choose ∇f(x∗) ∈∂f(x∗) such that βi ≤F(˜xi) −F ∗for all i ≥0. Dropping
now various nonnegative terms from the left-hand side of the above display, we conclude that"
T,0.5251017639077341,2t E[Ft] ≤Φ0.
T,0.5257801899592944,"Let us estimate Φ0. Using our Assumptions 1 and 2 and Theorem 14 (inequality (14)), we can bound
β0 ≤Lf∥˜x0 −x∗∥2 + 2δf ≤LfD2 + 2δf. Therefore,"
T,0.5264586160108549,"Φ0 ≤LfD2 + 2δf + c4 Ď
MD2 + 2(2t −1)(c3δf + 4"
T,0.5271370420624152,3δpg) ≤LD2 + 2(sc3δf + 4
T,0.5278154681139756,3δpg) · 2t
T,0.5284938941655359,"where L := Lf + c4 Ď
M ≡(c2c4 + 1)Lf + 48c1c4Lpg and sc3 := max{c3, 1}. Thus,"
T,0.5291723202170964,E[Ft] ≤Φ0
T,0.5298507462686567,2t ≤LD2
T,0.5305291723202171,"2t
+ 2sc3δf + 8 3δpg,"
T,0.5312075983717774,which proves the claimed convergence rate.
T,0.5318860244233379,"Let us now estimate the number of oracle queries. At each iteration t, the algorithm first queries sg
to construct the SVRG oracle pGt (by precomputing sg(˜xt)). All other queries are then done only
to pGt or, equivalently, to pg inside UniSgd p
Gt,ψ which is run for Nt+1 = 2t+1 iterations and thus
requiring O(Nt+1) queries to pg. Summing up, after T iterations, we obtain the total number of
PT
t=1 O(Nt) = PT
t=1 O(2t) = O(2T ) queries to pg, and T queries to sg."
T,0.5325644504748982,Helper Lemmas
T,0.5332428765264586,"Lemma 30. Let F : Rd →R∪{+∞} be the function F(x) := f(x)+ψ(x), where f : Rd →R is a
convex function, and ψ: Rd →R ∪{+∞} is a proper closed convex function. Let x∗be a minimizer
of F and let F ∗:= F(x∗). Then, there exists ∇f(x∗) ∈∂f(x∗) such that, for any x ∈dom ψ,"
T,0.533921302578019,"F(x) −F ∗≥β∇f(x∗)
f
(x∗, x)."
T,0.5345997286295794,"Proof. Since x∗is a minimizer of F, we have 0 ∈∂F(x∗) = ∂f(x∗) + ∂ψ(x∗). In other words,
there exists ∇f(x∗) ∈∂f(x∗) such that ∇ψ(x∗) := −∇f(x∗) ∈∂ψ(x∗). Consequently, for any
x ∈dom ψ,"
T,0.5352781546811397,"F(x) −F ∗= f(x) −f(x∗) + [ψ(x) −ψ(x∗)] ≥f(x) −f(x∗) + ⟨∇ψ(x∗), x −x∗⟩"
T,0.5359565807327001,"= f(x) −f(x∗) −⟨∇f(x∗), x −x∗⟩= β∇f(x∗)
f
(x∗, x)."
T,0.5366350067842606,"E.2
Universal Fast SVRG"
T,0.5373134328358209,"Lemma 31 (Universal Triangle SVRG Step). Consider problem (1) under Assumptions 1, 2 and 6.
Let ˜x, v ∈dom ψ be points, M ≥0 and A, a > 0 be coefficients, pG := SvrgOracpg(˜x). Further, let,
for A+ := A + a,"
T,0.5379918588873813,x := A˜x + av
T,0.5386702849389416,"A+
,
pGx ∼= pG(x),
pv+ = Proxψ(v, pGx, M/a),
px+ = A˜x + apv+ A+
,"
T,0.5393487109905021,"pGx+ ∼= pG(px+),
x
M+ = a2"
T,0.5400271370420624,"A+
M+
A+"
T,0.5407055630936228,"a2 M, a2"
T,0.5413839891451832,"A2
+
D2, x, px+, pGx, pGx+

."
T,0.5420624151967436,"Then, for Ď
M := c2Lf a2"
T,0.5427408412483039,A+ + 6c1Lpg a2
T,0.5434192672998643,"A , it holds that"
T,0.5440976933514247,"E
h
A+[F(px+) −F ∗] +
x
M+"
T,0.5447761194029851,2 ∥pv+ −x∗∥2i
T,0.5454545454545454,≤A[F(˜x) −F ∗] + M
T,0.5461329715061058,"2 ∥v −x∗∥2 + c4D2 E

[min{x
M+, Ď
M} −M]+
	
+ c3A+δf + 5"
T,0.5468113975576662,3Aδpg.
T,0.5474898236092266,"Proof. Since pg is an unbiased oracle for sg, so is pG (Lemma 28). Therefore, we can apply Lemma 26
to obtain"
T,0.5481682496607869,"E
h
A+[F(px+) −F ∗] +
x
M+"
T,0.5488466757123474,"2 ∥pv+ −x∗∥2 + A+βf, sf,sg(px+, x)
i
+ Aβf, sf,sg(x, ˜x)"
T,0.5495251017639078,≤A[F(˜x) −F ∗] + M
T,0.5502035278154681,"2 ∥v −x∗∥2 +
c1a2"
T,0.5508819538670285,"Ď
M −c2Lf a2"
T,0.5515603799185889,"A+
E[Var p
G(px+) + Var p
G(x)]"
T,0.5522388059701493,"+ c3A+δf + c4 E

[min{x
M+, Ď
M} −M]+D2	
,"
T,0.5529172320217096,"where Ď
M > c2Lf a2"
T,0.55359565807327,"A+ is an arbitrary coefficient. Using Lemmas 19 and 28 and Assumption 6, we can
further bound"
T,0.5542740841248304,"Var p
G(px+) + Var p
G(x) = Varpg(px+, ˜x) + Varpg(x, ˜x) ≤2 Varpg(px+, x) + 3 Varpg(x, ˜x)"
T,0.5549525101763908,"≤2Lpg[2βf, sf,sg(px+, x) + 3βf, sf,sg(x, ˜x) + 5δpg]."
T,0.5556309362279511,"Denoting α :=
2c1Lpga2"
T,0.5563093622795116,"Ď
M−c2Lf a2"
T,0.5569877883310719,"A+
, we thus obtain"
T,0.5576662143826323,"E
h
A+[F(px+) −F ∗] +
x
M+"
T,0.5583446404341926,"2 ∥pv+ −x∗∥2 + A+βf, sf,sg(px+, x)
i
+ Aβf, sf,sg(x, ˜x)"
T,0.5590230664857531,≤A[F(˜x) −F ∗] + M
T,0.5597014925373134,"2 ∥v −x∗∥2 + c3A+δf + 5αδpg + c4 E

[min{x
M+, Ď
M} −M]+D2"
T,0.5603799185888738,"+ 2α E[βf, sf,sg(px+, x)] + 3αβf, sf,sg(x, ˜x)."
T,0.5610583446404342,"Choosing now Ď
M = c2Lf a2"
T,0.5617367706919946,A+ + 6c1Lpg a2
T,0.562415196743555,"A , we get α = 1"
T,0.5630936227951153,3A (≤1
T,0.5637720488466758,"3A+), which allows us to drop the
nonnegative βf, sf,sg(·, ·) terms from both sides. The claim now follows."
T,0.5644504748982361,"Lemma 32 (Universal Triangle SVRG Epoch). Consider problem (1) under Assumptions 1, 2 and 6.
Let ˜x, v ∈dom ψ be points, M ≥0 and A, a > 0 be coefficients, N ≥1 be an integer, and let"
T,0.5651289009497965,"(˜x+, v+, M+) ∼= UniTriSvrgEpochpg,ψ(˜x, v, M, A, a, N; D),"
T,0.5658073270013568,"as defined by Algorithm 5. Then, for A+ := A + a and Ď
M := c2Lf a2"
T,0.5664857530529173,A+ + 6c1Lpg a2
T,0.5671641791044776,"A , it holds that"
T,0.567842605156038,"E
h
A+N[F(˜x+) −F ∗] + M+"
T,0.5685210312075983,2 ∥v+ −x∗∥2i
T,0.5691994572591588,≤AN[F(˜x)−F ∗]+ M
T,0.5698778833107191,"2 ∥v −x∗∥2 +c4D2 E

[min{M+, Ď
M}−M]+
	
+N

c3A+δf + 5"
T,0.5705563093622795,"3Aδpg

."
T,0.5712347354138398,"Proof. Each iteration k of the algorithm, when conditioned on vk, follows the construction from
Lemma 31 (with v = vk, M = Mk, A = Ak, a = ak+1, A+ = Ak+1, x = xk, pGx = Gxk,
pv+ = vk+1, px+ = xk+1, pGx+ = Gxk+1, x
M+ = Mk+1). Hence, we can write, after passing to full
expectations, for each k = 0, . . . , N −1,"
T,0.5719131614654003,"E
h
A+[F(xk+1) −F ∗] + Mk+1"
T,0.5725915875169606,"2
∥vk+1 −x∗∥2i"
T,0.573270013568521,"≤A[F(˜x) −F ∗] + E
hMk"
T,0.5739484396200815,"2 ∥vk −x∗∥2 + c4[min{Mk+1, Ď
M} −Mk]+D2i
+ δ,"
T,0.5746268656716418,where δ := c3A+δf + 5
T,0.5753052917232022,"3Aδpg. Telescoping the above inequalities (using Lemma 18), we get"
T,0.5759837177747625,"E
h
A+ N
X"
T,0.576662143826323,"k=1
[F(xk) −F ∗] + MN"
T,0.5773405698778833,2 ∥vN −x∗∥2i
T,0.5780189959294437,≤AN[F(˜x) −F ∗] + M0
T,0.578697421981004,"2 ∥v0 −x∗∥2 + c4D2 E

[min{MN, Ď
M} −M0]+
	
+ Nδ."
T,0.5793758480325645,"The claim now follows from the convexity of F and our definitions ˜x+ = sxN =
1
N
PN
k=1 xk,
v+ = vN, M+ = MN, M0 = M, v0 = v."
T,0.5800542740841248,"Theorem 11. Let UniFastSvrg (Algorithm 4) be applied to problem (1) under Assumptions 1, 2
and 6, and let N ≥9. Then, for any t ≥t0 := ⌈log2 log3 N⌉−1 (≥0), it holds that"
T,0.5807327001356852,E[F(˜xt)] −F ∗≤9[(c2c4 + 1
T,0.5814111261872456,2)Lf + 6c1c4Lpg]D2
T,0.582089552238806,"N(t −t0 + 1)2
+ (c3t + 1)δf + 5"
T,0.5827679782903663,3tδpg.
T,0.5834464043419267,"To construct ˜xt, the algorithm needs to make O(Nt) queries to pg and O(t) queries to sg. Assuming
that the complexity of querying sg is n times bigger than that of querying pg and choosing N = Θ(n),
we get the total stochastic-oracle complexity of O(nt)."
T,0.5841248303934871,"Proof. By our definition, the algorithm iterates for t ≥0:"
T,0.5848032564450475,"(˜xt+1, vt+1, Mt+1) ∼= UniTriSvrgEpochpg,sg,ψ(˜xt, vt, Mt, At, at+1, N; D),"
T,0.5854816824966079,where At and at+1 are deterministic coefficients satisfying the following equations:
T,0.5861601085481682,"At+1 = At + at+1,
at+1 =
p"
T,0.5868385345997287,"At.
(17)"
T,0.587516960651289,"In particular, for any t ≥0, we have Ď
M ′
t := c2Lf
a2
t+1
At+1 + 6c1Lpg
a2
t+1
At
≤c2Lf + 6c1Lpg =: Ď
M, and
hence [min{Mt+1, Ď
M ′
t} −Mt]+ ≤[min{Mt+1, Ď
M} −Mt]+ (because, for any fixed a and b, the
function [min{a, ·} −b]+ is nondecreasing as the composition of two nondecreasing functions).
Applying now Lemma 32 and passing to full expectations, we therefore obtain, for any t ≥0,"
T,0.5881953867028494,"E
h
At+1N[F(˜xt+1) −F ∗] + Mt+1"
T,0.5888738127544098,"2
∥vt+1 −x∗∥2i"
T,0.5895522388059702,"≤E
h
AtN[F(˜xt)−F ∗]+Mt"
T,0.5902306648575305,"2 ∥vt−x∗∥2+c4[min{Mt+1, Ď
M}−Mt]+D2i
+N

c3At+1δf+5"
T,0.5909090909090909,"3Atδpg

."
T,0.5915875169606513,"Telescoping the above inequalities (using, in particular, Lemma 18), we obtain, for any t ≥1,"
T,0.5922659430122117,AtN E[F(˜xt) −F ∗] ≤A0N[F(˜x0) −F ∗] + M0
T,0.592944369063772,2 ∥v0 −x∗∥2
T,0.5936227951153324,"+ c4 E

[min{Mt, Ď
M} −M0]+D2	
+ N

c3δf t
X"
T,0.5943012211668928,"i=1
Ai + 5 3δpg t−1
X"
T,0.5949796472184532,"i=0
Ai
"
T,0.5956580732700135,"≤A0N[F(˜x0) −F ∗] + c4 Ď
MD2 + NSt(c3δf + 5"
T,0.596336499321574,"3δpg),"
T,0.5970149253731343,"where, for the last inequality, we have used the fact that M0 = 0 and denoted St := Pt
i=1 Ai. Thus,
for any t ≥1,"
T,0.5976933514246947,E[F(˜xt)] −F ∗≤1 At
T,0.5983717774762551,"
A0[F(˜x0) −F ∗] + c4 Ď
MD2 N"
T,0.5990502035278155,"
+ St At"
T,0.5997286295793759,"
c3δf + 5"
T,0.6004070556309362,"3δpg

."
T,0.6010854816824966,"At the same time, according to (17), At+1 −At = √At for any t ≥0. Hence, by Lemma 33 (and our
assumption on A0), we can estimate At ≥1"
T,0.601763907734057,"9(t−t0 +1)2 for any t ≥t0 := ⌈log2 log3
1
A0 ⌉−1 (≥0).
Further, since the sequence At is increasing, we can estimate St ≡Pt
i=1 Ai ≤tAt, so that St"
T,0.6024423337856174,At ≤t.
T,0.6031207598371777,"Substituting these bounds into the above display and using our formula for A0, we obtain, for any
t ≥t0,
E[F(˜xt)] −F ∗≤ρt[F(˜x0) −F ∗+ c4 Ď
MD2] + t(c3δf + 5"
T,0.6037991858887382,"3δpg),"
T,0.6044776119402985,"where ρt :=
9
N(t−t0+1)2 ≤1. By our choice of ˜x0, it holds that F(˜x0) −F ∗≤1"
T,0.6051560379918589,"2LfD2 + δf (see
Lemma 34). Denoting L := 1"
T,0.6058344640434192,"2Lf + c4 Ď
M ≡(c2c4 + 1"
T,0.6065128900949797,"2)Lf + 6c1c4Lpg, we get"
T,0.60719131614654,E[F(˜xt)] −F ∗≤ρt(LD2 + δf) + t(c3δf + 5
T,0.6078697421981004,3δpg) ≤ρtLD2 + (c3t + 1)δf + 5
T,0.6085481682496607,"3tδpg,"
T,0.6092265943012212,which is exactly the claimed convergence rate bound.
T,0.6099050203527816,"Let us now estimate the number of oracle queries. At the beginning, the algorithm makes 1 query
to sg to compute ˜x0. All other queries to the oracles are then done, at each iteration t, only inside the
call to UniTriSvrgEpoch (Algorithm 5). Each such a call needs only one query to sg to construct
the SVRG oracle pG (by precomputing sg(˜x)), and O(N) queries to pg (which implements each query
to pG). Summing up, we get, after t iterations, the total number of O(Nt) queries to pg and O(t)
queries to sg."
T,0.6105834464043419,Helper Lemmas
T,0.6112618724559024,Lemma 33 (c.f. Lemma 1.1 in [23]). Let At be a positive sequence such that
T,0.6119402985074627,"At+1 −At ≥
p γAt"
T,0.6126187245590231,"for all t ≥0, where γ > 0, and let A0 ≤1"
T,0.6132971506105834,"9γ. Then, for any t ≥0, we have At ≥"
T,0.6139755766621439,"(
γ( A0"
T,0.6146540027137042,"γ )1/2t,
if t < t0,
γ
9 (t −t0 + 1)2,
if t ≥t0,"
T,0.6153324287652646,"where t0 := ⌈log2 log3
γ
A0 ⌉−1 (≥0)."
T,0.6160108548168249,"Proof. By replacing At with A′
t = At/γ, we can assume w.l.o.g. that γ = 1."
T,0.6166892808683854,"For any t ≥0, we have At+1 ≥√At, and hence"
T,0.6173677069199457,"At ≥A1/2t 0
."
T,0.6180461329715061,"In particular, for t0 (as defined in the statement), we get t0 ≥log2 log3
1
A0 −1, so 2t0 ≥1"
T,0.6187245590230664,"2 log3
1
A0 ,
and hence"
T,0.6194029850746269,"At0 ≥A2/ log3(1/A0)
0
=
 
3−log3(1/A0)2/ log3(1/A0) = 3−2 = 1"
T,0.6200814111261872,"9
(recall that A0 ≤1"
T,0.6207598371777476,9 ≤1).
T,0.621438263229308,"On the other hand, for any t ≥t0, we have p"
T,0.6221166892808684,"At+1 −
p"
T,0.6227951153324288,"At ≥
q"
T,0.6234735413839891,"At +
p"
T,0.6241519674355496,"At −
p"
T,0.6248303934871099,"At =
√At
p"
T,0.6255088195386703,"At + √At + √At =
1
q"
T,0.6261872455902306,"1 +
1
√At + 1
≥
1
√1 + 3 + 1 = 1 3,"
T,0.6268656716417911,where we have used the fact that At ≥At0 ≥1
T,0.6275440976933514,"9 since At is monotonically increasing. Telescoping
these inequalities and rearranging, we get, for any t ≥t0,"
T,0.6282225237449118,"At ≥
1"
T,0.6289009497964722,"3(t −t0) +
p At0"
T,0.6295793758480326,"2
≥
1"
T,0.6302578018995929,3(t −t0) + 1 3
T,0.6309362279511533,"2
= 1"
T,0.6316146540027137,9(t −t0 + 1)2.
T,0.6322930800542741,"Lemma 34. Consider problem (1) under Assumptions 1 and 2. Let x ∈dom ψ, and let x+ :=
Proxψ(x, sg(x), 0). Then, F(x+) −F ∗≤1"
T,0.6329715061058344,2LfD2 + δf.
T,0.6336499321573948,"Proof. From the first-order optimality condition for the point x+ (see Lemma 17), it follows that"
T,0.6343283582089553,"⟨sg(x), x∗−x+⟩+ ψ(x∗) ≥ψ(x+)."
T,0.6350067842605156,"Combining the above inequality first with f(x+) ≤sf(x) + ⟨sg(x), x+ −x⟩+ Lf"
T,0.635685210312076,"2 ∥x+ −x∥2 + δf
and then with sf(x) + ⟨sg(x), x∗−x⟩≤f(x∗) (which are both due to our Assumption 1), we obtain"
T,0.6363636363636364,"F(x+) = f(x+) + ψ(x+) ≤f(x+) + ⟨sg(x), x∗−x+⟩+ ψ(x∗)"
T,0.6370420624151968,"≤sf(x) + ⟨sg(x), x∗−x⟩+ ψ(x∗) + Lf"
T,0.6377204884667571,2 ∥x+ −x∥2 + δf
T,0.6383989145183175,≤F ∗+ Lf
T,0.6390773405698779,2 ∥x+ −x∥2 + δf.
T,0.6397557666214383,It remains to bound ∥x+ −x∥≤D.
T,0.6404341926729986,"F
Omitted Proofs for Section 7"
T,0.641112618724559,"We start with the observation that for our specific example all our main assumptions are satisfied.
Remark 35. Under the setting from Example 12, Assumptions 1, 6 and 9 are satisfied with sf = f,
sg(x) = ∇f(x) := Eξ[∇fξ(x)], any δf, δpg > 0 and"
T,0.6417910447761194,"Lf =

1 −ν
2(1 + ν)δf  1−ν"
T,0.6424694708276798,"1+ν
[Hf(ν)]
2
1+ν ,
Lpg = 1 b"
T,0.6431478968792401,"
1 −ν
2(1 + ν)δpg  1−ν"
T,0.6438263229308006,"1+ν
[Hmax(ν)]
2
1+ν ."
T,0.6445047489823609,"Further, the oracle pgb satisfies Assumption 3 with σ2
b := supx∈dom ψ Varpgb(x) = 1"
T,0.6451831750339213,"bσ2, and σ2
∗,b :=
Varpgb(x∗) = 1"
T,0.6458616010854816,"bσ2
∗."
T,0.6465400271370421,"Proof. For b = 1, this follows from Theorem 13 and Lemma 16 and our definitions of σ2 and σ∗.
The general case b ≥1 follows from the fact that the standard mini-batching of size b reduces each of
the variances Varpg1(·) and Varpg1(·, ·) in b times."
T,0.6472184531886025,"The following auxiliary result will be useful throughout this section:
Lemma 36. Let a, b, p > 0 be real. Then,"
T,0.6478968792401628,"min
t>0 n a"
T,0.6485753052917232,"tp + bt
o
= (p + 1)a
1
p+1
 b p"
T,0.6492537313432836,"
p
p+1
."
T,0.649932157394844,"Proof. The expression inside the min is a convex function in t > 0. Differentiating and setting its
derivative to zero, we see that the minimum is attained at t∗= ( ap"
T,0.6506105834464043,"b )
1
p+1 . Hence,"
T,0.6512890094979648,"min
t>0 n a"
T,0.6519674355495251,"tp + bt
o
= a
 b ap"
T,0.6526458616010855,"
p
p+1
+ b
ap b"
T,0.6533242876526458,"
1
p+1
= (p + 1)a
1
p+1
 b p"
T,0.6540027137042063,"
p
p+1
."
T,0.6546811397557666,"F.1
Uniformly Bounded Variance"
T,0.655359565807327,"Corollary 37. Consider problem (1) under the setting from Example 12 and also under Assumption 2.
Let Algorithm 1 be applied to this problem with the oracle pg = pgb and initial coefficient M0 = 0.
Then, for the point sxN generated by the algorithm, we have"
T,0.6560379918588873,"E[F(sxN)] −F ∗≤(2c2c4)
1+ν"
C,0.6567164179104478,2 c 1−ν
C,0.6573948439620081,"2
3
1 + ν
Hf(ν)D1+ν N
1+ν"
C,0.6580732700135685,"2
+ 2σD r 2c1c4 bN ."
C,0.658751696065129,"To reach E[F(sxN)] −F ∗≤ϵ for any ϵ > 0, it suffices to make O
 
[ Hf (ν)"
C,0.6594301221166893,"ϵ
]
2
1+ν D2 + σ2D2"
C,0.6601085481682497,"bϵ2

queries
to pgb."
C,0.66078697421981,"Proof. Denote for brevity Hf := Hf(ν). Taking into account Remark 35 and applying Theorem 4,
we get, for any δf > 0,"
C,0.6614654002713705,"FN := E[F(sxN)] −F ∗≤
c2c4H"
C,0.6621438263229308,"2
1+ν
f
D2 N"
C,0.6628222523744912,"
1 −ν
2(1 + ν)δf  1−ν"
C,0.6635006784260515,"1+ν
+ c3δf + σN,"
C,0.664179104477612,"where σN := 2σbD
q 2c1c4"
C,0.6648575305291723,"N
= 2σD
q 2c1c4"
C,0.6655359565807327,bN . Minimizing the right-hand side in δf (using Lemma 36
C,0.666214382632293,with p = 1−ν
C,0.6668928086838535,"1+ν for which p + 1 =
2
1+ν ), we obtain"
C,0.6675712347354138,"FN ≤
2
1 + ν"
C,0.6682496607869742,c2c4H
C,0.6689280868385346,"2
1+ν
f
D2 N"
C,0.669606512890095, 1 −ν
C,0.6702849389416553,2(1 + ν)  1−ν
C,0.6709633649932157,1+ν  1+ν
C,0.6716417910447762,2 1 + ν
C,0.6723202170963365,1 −ν c3  1−ν
C,0.6729986431478969,"2
+ σN"
C,0.6736770691994572,"= (2c2c4)
1+ν"
C,0.6743554952510177,2 c 1−ν
C,0.675033921302578,"2
3
1 + ν
HfD1+ν N
1+ν"
C,0.6757123473541384,"2
+ σN."
C,0.6763907734056988,"This proves the claimed convergence rate, and the oracle complexity bound easily follows since each
iteration of the algorithm requires only 1 query to pgb."
C,0.6770691994572592,"Corollary 38. Consider problem (1) under the setting from Example 12 and also under Assumption 2.
Let Algorithm 2 be applied to this problem with the oracle pg = pgb. Then, for any k ≥1, we have"
C,0.6777476255088195,"E[F(xk)] −F ∗≤22+ν(c2c4)
1+ν"
C,0.6784260515603799,2 ( c3
C,0.6791044776119403,"3 )
1−ν 2"
C,0.6797829036635007,"1 + ν
Hf(ν)D1+ν"
C,0.680461329715061,"k
1+3ν"
C,0.6811397557666214,"2
+ 4σD r 2c1c4 3bk ."
C,0.6818181818181818,"To reach E[F(xk)] −F ∗≤ϵ for any ϵ > 0, it suffices to make O
 
[ Hf (ν)D1+ν"
C,0.6824966078697422,"ϵ
]
2
1+3ν + σ2D2"
C,0.6831750339213026,"bϵ2

queries
to pgb."
C,0.683853459972863,"Proof. Let k ≥1 be arbitrary and denote for brevity Hf := Hf(ν). Taking into account Remark 35
and applying Theorem 5, we get, for any δf > 0,"
C,0.6845318860244234,"Fk := E[F(xk)] −F ∗≤
4c2c4H"
C,0.6852103120759837,"2
1+ν
f
D2"
C,0.6858887381275441,k(k + 1)
C,0.6865671641791045,"
1 −ν
2(1 + ν)δf  1−ν"
C,0.6872455902306649,"1+ν
+ c3"
C,0.6879240162822252,"3 (k + 2)δf + σk,"
C,0.6886024423337856,"where σk := 4σbD
q 2c1c4"
K,0.689280868385346,"3k
= 4σD
q 2c1c4"
K,0.6899592944369064,"3bk . Minimizing the right-hand side in δf (using Lemma 36)
and estimating k + 2 ≤2(k + 1), we obtain"
K,0.6906377204884667,"Fk ≤
2
1 + ν"
K,0.6913161465400272,4c2c4H
K,0.6919945725915875,"2
1+ν
f
D2"
K,0.6926729986431479,k(k + 1)
K,0.6933514246947082, 1 −ν
K,0.6940298507462687,2(1 + ν)  1−ν
K,0.694708276797829,1+ν  1+ν
K,0.6953867028493894,2 1 + ν
K,0.6960651289009498,"1 −ν
2c3(k + 1) 3  1−ν"
K,0.6967435549525102,"2
+ σk"
K,0.6974219810040706,"= 2(4c2c4)
1+ν"
K,0.6981004070556309,2 ( c3
K,0.6987788331071914,"3 )
1−ν 2"
K,0.6994572591587517,"1 + ν
HfD1+ν k
1+ν"
K,0.7001356852103121,2 (k + 1)ν + σk.
K,0.7008141112618724,"This proves the claimed convergence rate, and the oracle complexity bound easily follows since each
iteration of the algorithm requires only O(1) queries to pgb."
K,0.7014925373134329,"Remark 39. The efficiency guarantees given by Corollaries 37 and 38 are exactly the same as those
from [49], up to absolute constants."
K,0.7021709633649932,"F.2
Implicit Variance Reduction"
K,0.7028493894165536,"Corollary 40. Consider problem (1) under the setting from Example 12 and also under Assumption 2.
Let Algorithm 1 be applied to this problem with the oracle pg = pgb and initial coefficient M0 = 0.
Then, for the point sxN generated by the algorithm, we have"
K,0.7035278154681139,"E[F(sxN)] −F ∗≤cf(ν)Hf(ν)D1+ν N
1+ν"
K,0.7042062415196744,"2
+ cpg(ν)Hmax(ν)D1+ν"
K,0.7048846675712347,"(bN)
1+ν"
K,0.7055630936227951,"2
+ 2σ∗D r 6c1c4 bN ,"
K,0.7062415196743554,"where cf(ν) :=
(2c2c4)
1+ν"
C,0.7069199457259159,"2
c 1−ν"
C,0.7075983717774763,"2
3
1+ν
= O(1) and cpg(ν) :=
(24c4)
1+ν 2
( 4"
C,0.7082767978290366,"3 )
1−ν"
C,0.7089552238805971,"2
1+ν
= O(1). To reach"
C,0.7096336499321574,"E[F(sxN)] −F ∗≤ϵ for any ϵ > 0, it suffices to make O
 
[ Hf (ν)"
C,0.7103120759837178,"ϵ
]
2
1+ν D2 + 1"
C,0.7109905020352781,b[ Hpg(ν)
C,0.7116689280868386,"ϵ
]
2
1+ν D2 + σ2
∗D2 bϵ2
"
C,0.7123473541383989,queries to pgb.
C,0.7130257801899593,"Proof. Denote for brevity FN := E[F(sxN)] −F ∗, Hf := Hf(ν) and Hmax := Hmax(ν). Taking
into account Remark 35 and applying Theorem 7, we get, for any δf, δpg > 0,"
C,0.7137042062415196,"FN ≤
c2c4H"
C,0.7143826322930801,"2
1+ν
f
D2 N"
C,0.7150610583446404,"
1 −ν
2(1 + ν)δf  1−ν"
C,0.7157394843962008,"1+ν
+ 12c4H"
C,0.7164179104477612,"2
1+ν
maxD2 bN"
C,0.7170963364993216,"
1 −ν
2(1 + ν)δpg  1−ν"
C,0.7177747625508819,"1+ν
+ c3δf + 4"
C,0.7184531886024423,"3δpg + σN,"
C,0.7191316146540027,"where σN := 2σ∗,bD
q 6c1c4"
C,0.7198100407055631,"N
= 2σ∗D
q 6c1c4"
C,0.7204884667571235,"bN . Minimizing the right-hand side in δf and δpg (using
Lemma 36 twice), we get"
C,0.7211668928086838,"FN ≤
2
1 + ν"
C,0.7218453188602443,c2c4H
C,0.7225237449118046,"2
1+ν
f
D2 N"
C,0.723202170963365, 1 −ν
C,0.7238805970149254,2(1 + ν)  1−ν
C,0.7245590230664858,1+ν  1+ν
C,0.7252374491180461,2 (1 + ν)c3 1 −ν  1−ν 2
C,0.7259158751696065,"+
2
1 + ν"
C,0.7265943012211669,12c4H
C,0.7272727272727273,"2
1+ν
maxD2 bN"
C,0.7279511533242876, 1 −ν
C,0.728629579375848,2(1 + ν)  1−ν
C,0.7293080054274084,1+ν  1+ν
C,0.7299864314789688,2 (1 + ν) 4
C,0.7306648575305291,"3
1 −ν  1−ν"
C,0.7313432835820896,"2
+ σN"
C,0.73202170963365,"= (2c2c4)
1+ν"
C,0.7327001356852103,2 c 1−ν
C,0.7333785617367707,"2
3
1 + ν
HfD1+ν N
1+ν"
C,0.7340569877883311,"2
+ (24c4)
1+ν 2 ( 4"
C,0.7347354138398915,"3)
1−ν 2"
C,0.7354138398914518,"1 + ν
HmaxD1+ν"
C,0.7360922659430122,"(bN)
1+ν"
C,0.7367706919945726,"2
+ σN."
C,0.737449118046133,"This proves the claimed convergence rate, and the oracle complexity bound easily follows since each
iteration of the algorithm requires only 1 query to pgb."
C,0.7381275440976933,"Corollary 41. Consider problem (1) under the setting from Example 12 and also under Assumption 2.
Let Algorithm 2 be applied to this problem with the oracle pg = pgb. Then, for any k ≥1, we have"
C,0.7388059701492538,E[F(xk)] −F ∗≤cf(ν)Hf(ν)D1+ν
C,0.7394843962008141,"k
1+3ν"
C,0.7401628222523745,"2
+ cpg(ν)Hmax(ν)D1+ν"
C,0.7408412483039348,"(bk)
1+ν"
C,0.7415196743554953,"2
+ 4σ∗D r 2c1c4 bk ,"
C,0.7421981004070556,"where cf(ν) := (8c2c4)
1+ν 2
( 2"
C,0.742876526458616,"3 c3)
1−ν"
C,0.7435549525101763,"2
1+ν
= O(1) and cpg(ν) := (48c1c4)
1+ν 2
( 4"
C,0.7442333785617368,"3 )
1−ν"
C,0.7449118046132972,"2
1+ν
= O(1). To reach"
C,0.7455902306648575,"E[F(xk)] −F ∗≤ϵ for any ϵ > 0, it suffices to make O
 
[ Hf (ν)D1+ν"
C,0.746268656716418,"ϵ
]
2
1+3ν + 1"
C,0.7469470827679783,b[ Hmax(ν)
C,0.7476255088195387,"ϵ
]
2
1+ν D2 +"
C,0.748303934871099,"σ2
∗D2"
C,0.7489823609226595,"bϵ2

queries to pgb."
C,0.7496607869742198,"Proof. Let k ≥1 be arbitrary and denote for brevity Fk := E[F(xk)] −F ∗, Hf := Hf(ν) and
Hmax := Hmax(ν). Taking into account Remark 35 and applying Theorem 8, we get, for any
δf, δpg > 0,"
C,0.7503392130257802,"Fk ≤
4c2c4H"
C,0.7510176390773405,"2
1+ν
f
D2"
C,0.751696065128901,k(k + 1)
C,0.7523744911804613,"
1 −ν
2(1 + ν)δf  1−ν"
C,0.7530529172320217,"1+ν
+ 24c1c4H"
C,0.753731343283582,"2
1+ν
maxD2 bk"
C,0.7544097693351425,"
1 −ν
2(1 + ν)δpg  1−ν 1+ν + c3"
C,0.7550881953867028,3 (k + 2)δf + 4
C,0.7557666214382632,"3δpg + σk,"
C,0.7564450474898237,"where σk := 4σ∗,bD
q 2c1c4"
C,0.757123473541384,"k
= 4σ∗D
q 2c1c4"
C,0.7578018995929444,bk . Minimizing the right-hand side in δf and δpg (using
C,0.7584803256445047,Lemma 36 twice) and estimating 1
C,0.7591587516960652,3(k + 2) ≤2
C,0.7598371777476255,"3(k + 1), we obtain"
C,0.7605156037991859,"Fk ≤
2
1 + ν"
C,0.7611940298507462,4c2c4H
C,0.7618724559023067,"2
1+ν
f
D2"
C,0.762550881953867,k(k + 1)
C,0.7632293080054274, 1 −ν
C,0.7639077340569878,2(1 + ν)  1−ν
C,0.7645861601085482,1+ν  1+ν
C,0.7652645861601085,2 (1 + ν) 2c3
C,0.7659430122116689,"3 (k + 1)
1 −ν  1−ν 2"
C,0.7666214382632293,"+
2
1 + ν"
C,0.7672998643147897,24c1c4H
C,0.76797829036635,"2
1+ν
maxD2 bk"
C,0.7686567164179104, 1 −ν
C,0.7693351424694709,2(1 + ν)  1−ν
C,0.7700135685210312,1+ν  1+ν
C,0.7706919945725916,2 (1 + ν) 4
C,0.771370420624152,"3
1 −ν  1−ν"
C,0.7720488466757124,"2
+ σk"
C,0.7727272727272727,"= (8c2c4)
1+ν 2 ( 2"
C,0.7734056987788331,"3c3)
1−ν 2"
C,0.7740841248303935,"1 + ν
HfD1+ν k
1+ν"
C,0.7747625508819539,"2 (k + 1)ν + (48c1c4)
1+ν 2 ( 4"
C,0.7754409769335142,"3)
1−ν 2"
C,0.7761194029850746,"1 + ν
HmaxD1+ν"
C,0.776797829036635,"(bk)
1+ν"
C,0.7774762550881954,"2
+ σk."
C,0.7781546811397557,"This proves the claimed convergence rate, and the oracle complexity bound easily follows since each
iteration of the algorithm requires only O(1) queries to pgb."
C,0.7788331071913162,"Remark 42. In the proof of Corollary 41, it was important that δf and δpg were allowed to be two
separate constants. If we were not paying attention to such a separation and simply used the same δ
everywhere, we would end up with the much weaker rate of O( Hmax(ν)D1+ν b
1+ν"
C,0.7795115332428765,"2
kν
) for the second term."
C,0.7801899592944369,"F.3
Explicit Variance Reduction with SVRG"
C,0.7808683853459973,"Corollary 43. Consider problem (1) under the setting from Example 12 and also under Assumption 2.
Let UniSvrg (as defined by Algorithm 3) be applied to this problem with the stochastic oracle pg = pgb
and the full-gradient oracle sg = ∇f. Then, for any t ≥1,"
C,0.7815468113975577,E[F(˜xt)] −F ∗≤cf(ν)Hf(ν)D1+ν
C,0.7822252374491181,"(2t)
1+ν"
C,0.7829036635006784,"2
+ cpg(ν)Hmax(ν)D1+ν"
C,0.7835820895522388,"(b2t)
1+ν 2
,"
C,0.7842605156037992,"where cf(ν) :=
[2(c2c4+1)]
1+ν"
C,0.7849389416553596,"2
(2sc3)
1−ν"
C,0.7856173677069199,"2
1+ν
= O(1), cpg(ν) :=
(96c1c4)
1+ν 2
( 8"
C,0.7862957937584804,"3 )
1−ν"
C,0.7869742198100407,"2
1+ν
= O(1), sc3 :=
max{c3, 1}. To get E[F(˜xt)]−F ∗≤ϵ, it suffices to make O(Nν(ϵ)) queries to pgb and O(log+ Nν(ϵ))
queries to ∇f, where Nν(ϵ) := [ Hf (ν)"
C,0.7876526458616011,"ϵ
]
2
1+ν D2 + 1"
C,0.7883310719131614,b[ Hmax(ν)
C,0.7890094979647219,"ϵ
]
2
1+ν D2. Assuming that the complexity of
querying sgb is nb times bigger than that of querying ∇f, we get the total stochastic-oracle complexity
of O(Nν(ϵ) + nb log+ Nν(ϵ))."
C,0.7896879240162822,"Proof. Let t ≥1 be arbitrary and denote for brevity Ft := E[F(˜xt)] −F ∗, Hf := Hf(ν) and
Hmax := Hmax(ν). Taking into account Remark 35 and applying Theorem 10, we get, for any
δf, δpg > 0,"
C,0.7903663500678426,"Ft ≤
(c2c4 + 1)H"
C,0.7910447761194029,"2
1+ν
f
D2"
T,0.7917232021709634,2t
T,0.7924016282225237,"
1 −ν
2(1 + ν)δf  1−ν"
T,0.7930800542740841,"1+ν
+ 48c1c4H"
T,0.7937584803256446,"2
1+ν
maxD2 b2t"
T,0.7944369063772049,"
1 −ν
2(1 + ν)δpg  1−ν"
T,0.7951153324287653,"1+ν
+ 2sc3δf + 8 3δpg."
T,0.7957937584803256,"Minimizing the right-hand side in δf, δpg (using Lemma 36 twice), we obtain"
T,0.7964721845318861,"Ft ≤
2
1 + ν"
T,0.7971506105834464,(c2c4 + 1)H
T,0.7978290366350068,"2
1+ν
f
D2"
T,0.7985074626865671,2t
T,0.7991858887381276, 1 −ν
T,0.7998643147896879,2(1 + ν)  1−ν
T,0.8005427408412483,1+ν  1+ν
T,0.8012211668928086,2 (1 + ν)2sc3 1 −ν  1−ν 2
T,0.8018995929443691,"+
2
1 + ν"
T,0.8025780189959294,48c1c4H
T,0.8032564450474898,"2
1+ν
maxD2 b2t"
T,0.8039348710990502, 1 −ν
T,0.8046132971506106,2(1 + ν)  1−ν
T,0.805291723202171,1+ν  1+ν
T,0.8059701492537313,2 (1 + ν) 8
T,0.8066485753052918,"3
1 −ν  1−ν 2"
T,0.8073270013568521,= cfHfD1+ν
T,0.8080054274084125,"(2t)
1+ν"
T,0.8086838534599728,"2
+ cpgHmaxD1+ν"
T,0.8093622795115333,"(b2t)
1+ν 2
,"
T,0.8100407055630936,"where cf := [2(c2c4+1)]
1+ν"
T,0.810719131614654,"2
(2sc3)
1−ν"
T,0.8113975576662144,"2
1+ν
and cpg := (96c1c4)
1+ν 2
( 8"
T,0.8120759837177748,"3 )
1−ν"
T,0.8127544097693351,"2
1+ν
. This proves the claimed conver-
gence rate."
T,0.8134328358208955,"Let us now estimate the oracle complexity. From the already proved convergence rate bound, we
see that Ft ≤ϵ once 2t ≥O(1)N(ϵ), where N(ϵ) := [ Hf"
T,0.8141112618724559,"ϵ ]
2
1+ν D2 + 1"
T,0.8147896879240163,b[ Hmax
T,0.8154681139755766,"ϵ
]
2
1+ν D2. At the same
time, according to Theorem 10, to generate the corresponding ˜xt, the algorithm needs to make O(2t)
queries to pgb and O(t) queries to ∇f. Combining these two facts together, we get the claimed
O(N(ϵ)) queries to pgb and O(log2 N(ϵ) + 1) = O(log+ N(ϵ)) queries to ∇f."
T,0.816146540027137,"Corollary 44. Consider problem (1) under the setting from Example 12 and also under Assumption 2.
Let UniFastSvrg (Algorithm 4) be applied to this problem with the stochastic oracle pg = pgb,
the full-gradient oracle sg = ∇f, and the epoch length N ≥9. Then, for any t ≥2t0, where
t0 := ⌈log2 log3 N⌉−1 (≥0), it holds that"
T,0.8168249660786974,"E[F(˜xt)] −F ∗≤cf(ν)Hf(ν)D1+ν N
1+ν"
T,0.8175033921302578,"2 (t + 1)
1+3ν"
T,0.8181818181818182,"2
+ cpg(ν)Hmax(ν)D1+ν"
T,0.8188602442333786,"(bN)
1+ν"
T,0.819538670284939,"2 (t + 1)
1+3ν 2
,"
T,0.8202170963364993,"where cf(ν) :=
[72(c2c4+ 1"
T,0.8208955223880597,"2 )]
1+ν"
SC,0.8215739484396201,"2
sc 1−ν"
SC,0.8222523744911805,"2
3
1+ν
= O(1), cpg(ν) :=
(432c1c4)
1+ν 2
( 5"
SC,0.8229308005427408,"3 )
1−ν"
SC,0.8236092265943012,"2
1+ν
= O(1), sc3 :=
max{c3, 1}. To get E[F(˜xt)] −F ∗≤ϵ, it suffices to make O(NTν(ϵ)) queries to pgb and O(Tν(ϵ))"
SC,0.8242876526458616,"queries to ∇f, where Tν(ϵ) := [ Hf (ν)D1+ν N
1+ν"
SC,0.824966078697422,"2
ϵ
]
2
1+3ν +[ Hmax(ν)D1+ν"
SC,0.8256445047489823,"(bN)
1+ν"
SC,0.8263229308005428,"2
ϵ
]
2
1+3ν +log2 log3 N. Assuming that"
SC,0.8270013568521031,"the complexity of querying sgb is nb times bigger than that of querying ∇f and choosing N = Θ(nb),
we get the total stochastic-oracle complexity of O
 
[ nν
b Hf (ν)D1+ν"
SC,0.8276797829036635,"ϵ
]
2
1+3ν + [ nν
b Hmax(ν)D1+ν"
SC,0.8283582089552238,"b(1+ν)/2ϵ
]
2
1+3ν +
nb log log nb
"
SC,0.8290366350067843,"Proof. Let t ≥2t0 be arbitrary, Ft := E[F(˜xt)] −F ∗, Hf := Hf(ν), Hmax := Hmax(ν). Taking
into account Remark 35 and applying Theorem 11, we get, for any δf, δpg > 0,"
SC,0.8297150610583447,"Ft ≤
9(c2c4 + 1 2)H"
SC,0.830393487109905,"2
1+ν
f
D2"
SC,0.8310719131614654,N(t −t0 + 1)2
SC,0.8317503392130258,"
1 −ν
2(1 + ν)δf  1−ν"
SC,0.8324287652645862,"1+ν
+ 54c1c4H"
SC,0.8331071913161465,"2
1+ν
maxD2"
SC,0.833785617367707,bN(t −t0 + 1)2
SC,0.8344640434192673,"
1 −ν
2(1 + ν)δpg  1−ν 1+ν"
SC,0.8351424694708277,+ (c3t + 1)δf + 5
SC,0.835820895522388,3tδpg.
SC,0.8364993215739485,"Since t ≥2t0, we can estimate t −t0 + 1 = 1"
SC,0.8371777476255088,2t + 1
SC,0.8378561736770692,2t −t0 + 1 ≥1
SC,0.8385345997286295,"2(t + 1), which gives us"
SC,0.83921302578019,"Ft ≤
36(c2c4 + 1 2)H"
SC,0.8398914518317503,"2
1+ν
f
D2"
SC,0.8405698778833107,N(t + 1)2
SC,0.841248303934871,"
1 −ν
2(1 + ν)δf  1−ν"
SC,0.8419267299864315,"1+ν
+ 216c1c4H"
SC,0.8426051560379919,"2
1+ν
maxD2"
SC,0.8432835820895522,bN(t + 1)2
SC,0.8439620081411127,"
1 −ν
2(1 + ν)δpg  1−ν 1+ν"
SC,0.844640434192673,+ sc3(t + 1)δf + 5
SC,0.8453188602442334,3(t + 1)δpg.
SC,0.8459972862957937,"Minimizing the right-hand side in δf, δpg (using Lemma 36 twice), we obtain"
SC,0.8466757123473542,"Ft ≤
2
1 + ν"
SC,0.8473541383989145,36(c2c4 + 1 2)H
SC,0.8480325644504749,"2
1+ν
f
D2"
SC,0.8487109905020352,N(t + 1)2
SC,0.8493894165535957, 1 −ν
SC,0.850067842605156,2(1 + ν)  1−ν
SC,0.8507462686567164,1+ν  1+ν
SC,0.8514246947082768,2 (1 + ν)sc3(t + 1) 1 −ν  1−ν 2
SC,0.8521031207598372,"+
2
1 + ν"
SC,0.8527815468113975,216c1c4H
SC,0.8534599728629579,"2
1+ν
maxD2"
SC,0.8541383989145184,bN(t + 1)2
SC,0.8548168249660787, 1 −ν
SC,0.8554952510176391,2(1 + ν)  1−ν
SC,0.8561736770691994,1+ν  1+ν
SC,0.8568521031207599,2 (1 + ν) 5
SC,0.8575305291723202,"3(t + 1)
1 −ν  1−ν 2"
SC,0.8582089552238806,"=
cfHfD1+ν N
1+ν"
SC,0.858887381275441,"2 (t + 1)
1+3ν"
SC,0.8595658073270014,"2
+
cpgHmaxD1+ν"
SC,0.8602442333785617,"(bN)
1+ν"
SC,0.8609226594301221,"2 (t + 1)
1+3ν 2
,"
SC,0.8616010854816825,where cf := [72(c2c4+ 1
SC,0.8622795115332429,"2 )]
1+ν"
SC,0.8629579375848032,"2
sc 1−ν"
SC,0.8636363636363636,"2
3
1+ν
and cpg := (432c1c4)
1+ν 2
( 5"
SC,0.864314789687924,"3 )
1−ν"
SC,0.8649932157394844,"2
1+ν
. This proves the claimed conver-
gence rate."
SC,0.8656716417910447,"Let us now estimate the number of oracle queries. In view of the above convergence rate bound,
we have Ft ≤ϵ once t ≥T(ϵ) := T1(ϵ) + 2t0 = O
 
T1(ϵ) + log log N

, where T1(ϵ) :="
SC,0.8663500678426052,[ Hf D1+ν
SC,0.8670284938941656,"N(1+ν)/2ϵ]
2
1+3ν + [ HmaxD1+ν"
SC,0.8677069199457259,"(bN)(1+ν)/2ϵ]
2
1+3ν =
T2(ϵ)"
SC,0.8683853459972863,"N
1+ν
1+3ν , where T2(ϵ) := [ Hf D1+ν"
SC,0.8690637720488467,"ϵ
]
2
1+3ν + [ HmaxD1+ν"
SC,0.8697421981004071,"b(1+ν)/2ϵ ]
2
1+3ν"
SC,0.8704206241519674,"does not depend on N. Combining this with Theorem 11 saying that, to generate the correspond-
ing ˜xt, the algorithm needs to make O(Nt) queries to pgb and O(t) queries to ∇f, we get the claimed
O(NT(ϵ)) queries to pgb and O(T(ϵ)) queries to ∇f."
SC,0.8710990502035278,"Assuming now that the complexity of querying ∇f is nb times bigger than that of querying pgb, we
get the total stochastic-oracle complexity of O
 
(N + nb)T(ϵ)

= O
 
(N + nb)

T2(ϵ)
N(1+ν)/(1+3ν) +
log log N

. Ignoring the doubly-logarithmic term, we get the expression of the form (N +nb) 1"
SC,0.8717774762550882,"Nq =
N 1−q + nb"
SC,0.8724559023066486,"Nq with q :=
1+ν
1+3ν ∈[0, 1], whose minimal value is achieved at N = Θ(nb). Substituting"
SC,0.8731343283582089,"this value into our complexity bound, we get the stochastic-oracle complexity of O
 
nb(
T2(ϵ)
n(1+ν)/(1+3ν)
b
+"
SC,0.8738127544097694,"log log nb)

= O
 
n"
SC,0.8744911804613297,"2ν
1+3ν
b
T2(ϵ) + nb log log nb

."
SC,0.8751696065128901,"G
Additional Discussion of Related Work"
SC,0.8758480325644504,"Inexact Oracle and Approximate Smoothness.
Devolder, Glineur, and Nesterov [15] introduced
the notion of the inexact first-order oracle and analyzed the behaviour of several first-order methods
for smooth convex optimization using such an oracle. Although their work was motivated by the
desire to present the general definition of an inexact oracle covering many different applications,
it was also observed that this oracle model is suitable for studying weakly smooth problems. This
insight was later used in [45] to develop universal gradient methods for Hölder smooth problems. First
stochastic gradient methods for approximately smooth functions with inexact oracle were proposed
in [13]. These algorithms however are not adaptive and require the knowledge of problem-dependent
constants. For more details on the subject, see [14]."
SC,0.8765264586160109,"0
20000
40000
60000
number of stochastic oracle calls 10
13 10
10 10
7 10
4 10
1"
SC,0.8772048846675712,f(x)-f
SC,0.8778833107191316,mushrooms
SC,0.878561736770692,"0
5000
10000
15000
20000
number of stochastic oracle calls 10
13 10
10 10
7 10
4 10
1"
SC,0.8792401628222524,f(x)-f w8a
SC,0.8799185888738128,"0
20000
40000
60000
number of stochastic oracle calls 10
5 10
4 10
3 10
2 10
1 100"
SC,0.8805970149253731,f(x)-f leu
SC,0.8812754409769336,"0
25000
50000
75000 100000
number of stochastic oracle calls 10
7 10
5 10
3 10
1"
SC,0.8819538670284939,f(x)-f
SC,0.8826322930800543,colon-cancer
SC,0.8833107191316146,"0
20000
40000
number of stochastic oracle calls 10
6 10
5 10
4 10
3 10
2 10
1"
SC,0.8839891451831751,f(x)-f
SC,0.8846675712347354,"0
100000
200000
number of stochastic oracle calls 10
6 10
5 10
4 10
3 10
2 10
1"
SC,0.8853459972862958,f(x)-f
SC,0.8860244233378561,"0
50000 100000150000200000
number of stochastic oracle calls 10
6 10
5 10
4 10
3 10
2 10
1 100"
SC,0.8867028493894166,f(x)-f
SC,0.8873812754409769,"0
100000 200000 300000
number of stochastic oracle calls 10
6 10
4 10
2 100"
SC,0.8880597014925373,f(x)-f
SC,0.8887381275440976,"UniSgd (ours)
UniFastSgd (ours)
AdaSVRG
UniSvrg (ours)
AdaVRAG
AdaVRAE
UniFastSvrg (ours)"
SC,0.8894165535956581,Figure 3: Comparison of various methods on the logistic regression problem with real-world data.
SC,0.8900949796472184,"Parameter-Free Methods.
Parameter-free algorithms originating from the literature on online
learning [9, 10, 26, 40, 47, 55] is another popular type of adaptive methods. They are usually endowed
with mechanisms helping achieving efficiency bounds that are almost insensitive (typically, with
logarithmic dependency) to the error of estimating certain problem parameters, such as the diameter
of the feasible set [6, 11, 25, 31, 41]."
SC,0.8907734056987788,"Variance Reduction.
Variance reduction techniques encompass a set of strategies that enhance
the convergence speed of SGD when multiple passes are possible over the training dataset. Various
researchers simultaneously introduced methods to reduce variance around the same period [27, 38,
50, 52, 58, 60]. The consideration of mini-batching in the context of these methods is documented
in [3], while, in [20], it is shown that the convergence rate is influenced by both the average and the
maximum smoothness of individual components. For further details, see [21] and the references
therein."
SC,0.8914518317503393,"Sometimes, it is even not necessary to use an explicit variance reduction mechanism. SGD may
converge fast in the so-called over-parameterized regime, or when the stochastic noise is small at the
optimal solution [8, 35, 37, 43, 44, 51]. In this work, we call this effect implicit variance reduction.
Such a situation is also considered in [19, 54] and, more recently, Woodworth and Srebro [59]
proposed an accelerated SGD algorithm for this setting, under the assumption that the smoothness
and noise constants are known."
SC,0.8921302578018996,"H
Additional Experiments"
SC,0.89280868385346,"H.1
Logistic Regression with Real-World Data"
SC,0.8934871099050203,"In this section, we present experiments on the logistic regression problem:"
SC,0.8941655359565808,"f ∗= min
∥x∥≤R"
SC,0.8948439620081411,"n
f(x) := 1 n n
X"
SC,0.8955223880597015,"i=1
log(1 + e−bi⟨ai,x⟩)
o
,"
SC,0.8962008141112618,"where ai ∈Rd and bi ∈{−1, 1} are features and labels taken from diverse real-world datasets from
LIBSVM [7]: mushrooms (d ≪n), w8a (d ≪n), leu (d ≫n) and colon-cancer (d ≫n). The
dataset leu is quite special because it satisfies the so-called interpolation condition, meaning that the
variance at the optimum is zero. We fix R = 1 and use the mini-batch size of b = 32 for the first two
datasets and b = 1 for the last two."
SC,0.8968792401628223,"Figure 3 shows the results of our experiments. The solid lines and the shaded area for each method
represent, respectively, the mean and the region between the minimum and the maximum values after
three independent runs of the algorithm. We see that, on the leu dataset, UniSgd and UniFastSgd
converge as fast as the best non-accelerated and accelerated SVRG methods, respectively, which"
SC,0.8975576662143826,"0
50000 100000 150000 200000 250000
number of stochastic oracle calls 103 104 105"
SC,0.898236092265943,f(x)-f q = 1
SC,0.8989145183175034,"0
25000 50000 75000 100000125000150000"
SC,0.8995929443690638,number of stochastic oracle calls 104 105 106 107
SC,0.9002713704206241,f(x)-f
SC,0.9009497964721845,q = 1.3
SC,0.9016282225237449,"0
20000
40000
60000
number of stochastic oracle calls 105 106 107 108 109"
SC,0.9023066485753053,f(x)-f
SC,0.9029850746268657,q = 1.6
SC,0.903663500678426,"0
5000
10000
15000
number of stochastic oracle calls 10
1 101 103 105 107 109 1011"
SC,0.9043419267299865,f(x)-f q = 2
SC,0.9050203527815468,"0
50000 100000 150000 200000 250000
number of stochastic oracle calls 104 105 106"
SC,0.9056987788331072,Step size
SC,0.9063772048846676,"0
25000 50000 75000 100000125000150000"
SC,0.907055630936228,number of stochastic oracle calls 103 104
SC,0.9077340569877883,Step size
SC,0.9084124830393487,"0
20000
40000
60000
number of stochastic oracle calls 102"
SC,0.9090909090909091,Step size
SC,0.9097693351424695,"0
5000
10000
15000
number of stochastic oracle calls 100"
SC,0.9104477611940298,"4 × 10
1"
SC,0.9111261872455902,"6 × 10
1"
SC,0.9118046132971506,2 × 100
SC,0.912483039348711,Step size
SC,0.9131614654002713,"UniSgd-AdaGrad
UniSgd-Other
UniSvrg-AdaGrad
UniSvrg-Other"
SC,0.9138398914518318,"0
50000 100000 150000 200000 250000
number of stochastic oracle calls 100 101 102 103 104 105"
SC,0.9145183175033921,f(x)-f q = 1
SC,0.9151967435549525,"0
25000 50000 75000 100000125000150000"
SC,0.9158751696065129,number of stochastic oracle calls 100 101 102 103 104 105 106 107
SC,0.9165535956580733,f(x)-f
SC,0.9172320217096337,q = 1.3
SC,0.917910447761194,"0
20000
40000
60000
number of stochastic oracle calls 102 104 106 108"
SC,0.9185888738127544,f(x)-f
SC,0.9192672998643148,q = 1.6
SC,0.9199457259158752,"0
5000
10000
15000
number of stochastic oracle calls 10
6 10
3 100 103 106 109 1012"
SC,0.9206241519674355,f(x)-f q = 2
SC,0.921302578018996,"0
50000 100000 150000 200000 250000
number of stochastic oracle calls 10
1 100 101 102 103 104 105 106"
SC,0.9219810040705563,Step size
SC,0.9226594301221167,"0
25000 50000 75000 100000125000150000"
SC,0.923337856173677,"number of stochastic oracle calls 10
1 100 101 102 103 104 105"
SC,0.9240162822252375,Step size
SC,0.9246947082767978,"0
20000
40000
60000
number of stochastic oracle calls 10
2 10
1 100 101 102 103"
SC,0.9253731343283582,Step size
SC,0.9260515603799185,"0
5000
10000
15000
number of stochastic oracle calls 10
2 10
1 100"
SC,0.926729986431479,Step size
SC,0.9274084124830394,"UniFastSgd-AdaGrad
UniFastSgd-Other
UniFastSvrg-AdaGrad
UniFastSvrg-Other"
SC,0.9280868385345997,"Figure 4: Comparison of our methods for different stepsize update rules on the polyhedron feasibility
problem."
SC,0.9287652645861602,"confirms our theory on implicit variance reduction. Otherwise, these two SGD methods are typically
much slower than the SVRG algorithms. Our UniSvrg method performs consistently better than
AdaSVRG across all the datasets. Overall, all adaptive accelerated SVRG methods demonstrate
comparable performance for solving these smooth problems."
SC,0.9294436906377205,"H.2
Comparison between Stepsize Update Rules"
SC,0.9301221166892809,"In this section, we compare the AdaGrad stepsize rule (3) with the other rule (4) for UniSgd
(Algorithm 1), UniFastSgd (Algorithm 2), UniSvrg (Algorithm 3), and UniFastSvrg (Algorithm 4).
We consider the polyhedron feasibility and logistic regression problems under the same setups as in
Section 8 and Appendix H.1."
SC,0.9308005427408412,"The results are shown in Figs. 4 and 5, where we plot the function residual and the stepsize (inverse
of M) against stochastic oracle calls. We see that the two stepsize rules work very similarly across
all test cases, which was not evident from the theory alone."
SC,0.9314789687924017,"0
10000
20000
30000
40000
50000
number of stochastic oracle calls 10
14 10
12 10
10 10
8 10
6 10
4 10
2 100"
SC,0.932157394843962,f(x)-f q = 1
SC,0.9328358208955224,"0
20000
40000
60000
80000
number of stochastic oracle calls 10
14 10
12 10
10 10
8 10
6 10
4 10
2 100"
SC,0.9335142469470827,f(x)-f
SC,0.9341926729986432,q = 1.3
SC,0.9348710990502035,"0
20000
40000
60000
number of stochastic oracle calls 10
5 10
4 10
3 10
2 10
1 100 101"
SC,0.9355495251017639,f(x)-f
SC,0.9362279511533242,q = 1.6
SC,0.9369063772048847,"0
20000
40000
60000
80000
100000
number of stochastic oracle calls 10
7 10
6 10
5 10
4 10
3 10
2 10
1 100"
SC,0.937584803256445,f(x)-f q = 2
SC,0.9382632293080054,"0
10000
20000
30000
40000
50000
number of stochastic oracle calls 10
1 100 101"
SC,0.9389416553595658,Step size
SC,0.9396200814111262,"0
20000
40000
60000
80000
number of stochastic oracle calls 10
1 100 101"
SC,0.9402985074626866,Step size
SC,0.9409769335142469,"0
20000
40000
60000
number of stochastic oracle calls 10
2 10
1"
SC,0.9416553595658074,Step size
SC,0.9423337856173677,"0
20000
40000
60000
80000
100000
number of stochastic oracle calls 10
2 10
1"
SC,0.9430122116689281,Step size
SC,0.9436906377204884,"UniSgd-AdaGrad
UniSgd-Other
UniSvrg-AdaGrad
UniSvrg-Other"
SC,0.9443690637720489,"0
10000
20000
30000
40000
50000
number of stochastic oracle calls 10
6 10
5 10
4 10
3 10
2 10
1"
SC,0.9450474898236092,f(x)-f q = 1
SC,0.9457259158751696,"0
50000
100000 150000 200000 250000
number of stochastic oracle calls 10
6 10
5 10
4 10
3 10
2 10
1"
SC,0.94640434192673,f(x)-f
SC,0.9470827679782904,q = 1.3
SC,0.9477611940298507,"0
25000 50000 75000 100000125000150000
number of stochastic oracle calls 10
6 10
5 10
4 10
3 10
2 10
1 100"
SC,0.9484396200814111,f(x)-f
SC,0.9491180461329715,q = 1.6
SC,0.9497964721845319,"0
50000100000150000200000250000300000"
SC,0.9504748982360922,"number of stochastic oracle calls 10
7 10
6 10
5 10
4 10
3 10
2 10
1 100"
SC,0.9511533242876526,f(x)-f q = 2
SC,0.9518317503392131,"0
10000
20000
30000
40000
50000
number of stochastic oracle calls 10
5 10
4 10
3 10
2 10
1 100 101"
SC,0.9525101763907734,Step size
SC,0.9531886024423338,"0
50000
100000 150000 200000 250000
number of stochastic oracle calls 10
6 10
5 10
4 10
3 10
2 10
1 100 101"
SC,0.9538670284938942,Step size
SC,0.9545454545454546,"0
25000 50000 75000 100000125000150000
number of stochastic oracle calls 10
4 10
3 10
2"
SC,0.9552238805970149,Step size
SC,0.9559023066485753,"0
50000100000150000200000250000300000"
SC,0.9565807327001357,"number of stochastic oracle calls 10
7 10
6 10
5 10
4 10
3 10
2 10
1"
SC,0.9572591587516961,Step size
SC,0.9579375848032564,"UniFastSgd-AdaGrad
UniFastSgd-Other
UniFastSvrg-AdaGrad
UniFastSvrg-Other"
SC,0.9586160108548168,"Figure 5: Comparison of our methods for different stepsize update rules on the logistic regression
problem with real-world data."
SC,0.9592944369063772,NeurIPS Paper Checklist
CLAIMS,0.9599728629579376,1. Claims
CLAIMS,0.9606512890094979,"Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: Each claim is justified by a theorem.
Guidelines:"
CLAIMS,0.9613297150610584,"• The answer NA means that the abstract and introduction do not include the claims
made in the paper.
• The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
• The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
• It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper."
LIMITATIONS,0.9620081411126187,2. Limitations
LIMITATIONS,0.9626865671641791,"Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: Each theorem is followed by a discussion. For the numerical experiments in
Section 8 we carefully discuss the performance of the method. Additional experiments are
presented in Appendix H.
Guidelines:"
LIMITATIONS,0.9633649932157394,"• The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate “Limitations” section in their paper.
• The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
• The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
• The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
• The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
• If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
• While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3. Theory Assumptions and Proofs"
LIMITATIONS,0.9640434192672999,"Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: Yes. This is a theory paper. All proofs are provided in the appendix.
Guidelines:"
LIMITATIONS,0.9647218453188603,"• The answer NA means that the paper does not include theoretical results.
• All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
• All assumptions should be clearly stated or referenced in the statement of any theorems.
• The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
• Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4. Experimental Result Reproducibility"
LIMITATIONS,0.9654002713704206,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?"
LIMITATIONS,0.966078697421981,Answer: [Yes]
LIMITATIONS,0.9667571234735414,Justification: We provide the pseudocode and the hyperparameter settings for all algorithms.
LIMITATIONS,0.9674355495251018,Guidelines:
LIMITATIONS,0.9681139755766621,"• The answer NA means that the paper does not include experiments.
• If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
• If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
• Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
• While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a) If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b) If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c) If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d) We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results."
OPEN ACCESS TO DATA AND CODE,0.9687924016282226,5. Open access to data and code
OPEN ACCESS TO DATA AND CODE,0.9694708276797829,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?"
OPEN ACCESS TO DATA AND CODE,0.9701492537313433,Answer: [Yes]
OPEN ACCESS TO DATA AND CODE,0.9708276797829036,Justification: We provide the GitHub link to our code.
OPEN ACCESS TO DATA AND CODE,0.9715061058344641,Guidelines:
OPEN ACCESS TO DATA AND CODE,0.9721845318860244,"• The answer NA means that paper does not include experiments requiring code.
• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
public/guides/CodeSubmissionPolicy) for more details.
• While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
• The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines (https:
//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
• The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc."
OPEN ACCESS TO DATA AND CODE,0.9728629579375848,"• The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
• At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
• Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted."
OPEN ACCESS TO DATA AND CODE,0.9735413839891451,6. Experimental Setting/Details
OPEN ACCESS TO DATA AND CODE,0.9742198100407056,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?"
OPEN ACCESS TO DATA AND CODE,0.9748982360922659,Answer: [Yes]
OPEN ACCESS TO DATA AND CODE,0.9755766621438263,Justification: Everything is carefully described in Section 8 and Appendix H.
OPEN ACCESS TO DATA AND CODE,0.9762550881953868,Guidelines:
OPEN ACCESS TO DATA AND CODE,0.9769335142469471,"• The answer NA means that the paper does not include experiments.
• The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
• The full details can be provided either with the code, in appendix, or as supplemental
material."
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9776119402985075,7. Experiment Statistical Significance
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9782903663500678,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9789687924016283,"Answer: [No]
Justification: Different runs of the same algorithm for the same hyperparameter settings
result in almost the same performance in our experiments. Therefore, we plot only one
curve for each method, focusing more on highlighting the (more significant) differences
between various methods."
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9796472184531886,Guidelines:
EXPERIMENT STATISTICAL SIGNIFICANCE,0.980325644504749,"• The answer NA means that the paper does not include experiments.
• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
• The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
• The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
• It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
• It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
• For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
• If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text."
EXPERIMENTS COMPUTE RESOURCES,0.9810040705563093,8. Experiments Compute Resources
EXPERIMENTS COMPUTE RESOURCES,0.9816824966078698,"Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?"
EXPERIMENTS COMPUTE RESOURCES,0.9823609226594301,"Answer: [No]
Justification: This is not important for the results we present since the algorithms are
compared in terms of oracle calls and not the actual time of execution. All experiments are
run on a standard MacBook Pro laptop and do not require a lot of computational power."
EXPERIMENTS COMPUTE RESOURCES,0.9830393487109905,Guidelines:
EXPERIMENTS COMPUTE RESOURCES,0.9837177747625508,"• The answer NA means that the paper does not include experiments.
• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
• The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
• The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper)."
CODE OF ETHICS,0.9843962008141113,9. Code Of Ethics
CODE OF ETHICS,0.9850746268656716,"Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?"
CODE OF ETHICS,0.985753052917232,Answer: [Yes]
CODE OF ETHICS,0.9864314789687924,Justification: This is a theory paper.
CODE OF ETHICS,0.9871099050203528,Guidelines:
CODE OF ETHICS,0.9877883310719131,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
• If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction)."
BROADER IMPACTS,0.9884667571234735,10. Broader Impacts
BROADER IMPACTS,0.989145183175034,"Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?"
BROADER IMPACTS,0.9898236092265943,Answer: [No]
BROADER IMPACTS,0.9905020352781547,Justification: This is a theory paper. We do not expect immediate societal impact.
BROADER IMPACTS,0.991180461329715,Guidelines:
BROADER IMPACTS,0.9918588873812755,"• The answer NA means that there is no societal impact of the work performed.
• If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
• Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
• The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
• The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
• If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML)."
SAFEGUARDS,0.9925373134328358,11. Safeguards
SAFEGUARDS,0.9932157394843962,"Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: Does not apply.
Guidelines:"
SAFEGUARDS,0.9938941655359566,"• The answer NA means that the paper poses no such risks.
• Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
• Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
• We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12. Licenses for existing assets"
SAFEGUARDS,0.994572591587517,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: We cite the LIBSVM dataset.
Guidelines:"
SAFEGUARDS,0.9952510176390773,"• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
• The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
• For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
• If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
• For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
• If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13. New Assets"
SAFEGUARDS,0.9959294436906377,"Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: We do not release any new assets in this paper.
Guidelines:"
SAFEGUARDS,0.9966078697421981,"• The answer NA means that the paper does not release new assets.
• Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
• The paper should discuss whether and how consent was obtained from people whose
asset is used."
SAFEGUARDS,0.9972862957937585,"• At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14. Crowdsourcing and Research with Human Subjects"
SAFEGUARDS,0.9979647218453188,"Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: No such experiments or research.
Guidelines:"
SAFEGUARDS,0.9986431478968792,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: Does not apply.
Guidelines:"
SAFEGUARDS,0.9993215739484396,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
• We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
• For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review."
