Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0021551724137931034,"We demonstrate that, through appropriate prompting, GPT-3 can be triggered
1"
ABSTRACT,0.004310344827586207,"to perform iterative behaviours necessary to execute (rather than just write or
2"
ABSTRACT,0.00646551724137931,"recall) programs that involve loops, including several popular algorithms found in
3"
ABSTRACT,0.008620689655172414,"computer science curricula or software developer interviews. We trigger execution
4"
ABSTRACT,0.010775862068965518,"and description of iterations by regimenting self-attention (IRSA) in one (or a
5"
ABSTRACT,0.01293103448275862,"combination) of three ways: 1) Using strong repetitive structure in an example
6"
ABSTRACT,0.015086206896551725,"of an execution path of a target program for one particular input, 2) Prompting
7"
ABSTRACT,0.017241379310344827,"with fragments of execution paths, and 3) Explicitly forbidding (skipping) self-
8"
ABSTRACT,0.01939655172413793,"attention to parts of the generated text. On a dynamic program execution, IRSA
9"
ABSTRACT,0.021551724137931036,"leads to larger accuracy gains than replacing the model with the much more
10"
ABSTRACT,0.023706896551724137,"powerful GPT-4. IRSA has promising applications in education, as the prompts
11"
ABSTRACT,0.02586206896551724,"and responses resemble student assignments in data structures and algorithms
12"
ABSTRACT,0.028017241379310345,"classes. Our ﬁndings hold implications for evaluating LLMs, which typically target
13"
ABSTRACT,0.03017241379310345,"the in-context learning: We show that prompts that may not even cover one full task
14"
ABSTRACT,0.032327586206896554,"example can trigger algorithmic behaviour, allowing solving problems previously
15"
ABSTRACT,0.034482758620689655,"thought of as hard for LLMs, such as logical puzzles. Consequently, prompt design
16"
ABSTRACT,0.036637931034482756,"plays an even more critical role in LLM performance than previously recognized.
17"
INTRODUCTION,0.03879310344827586,"1
Introduction
18"
INTRODUCTION,0.040948275862068964,"Large language models (LLMs) [2, 27, 5, 21] are trained on large text datasets, which typically
19"
INTRODUCTION,0.04310344827586207,"include descriptions of procedures and even computer programs [4]. However, their performance
20"
INTRODUCTION,0.04525862068965517,"on complex reasoning tasks remains limited despite using advanced prompting methods, such as
21"
INTRODUCTION,0.04741379310344827,"Chain-of-Thought (CoT) [31, 40, 20, 38, 37, 42, 6, 36, 15, 11, 12]. This implies that despite the
22"
INTRODUCTION,0.04956896551724138,"massive number of parameters and self-attention to all previous tokens, current LLMs are unlikely to
23"
INTRODUCTION,0.05172413793103448,"solve problems that require many (or iterated) reasoning steps in a direct, savant-like manner. New
24"
INTRODUCTION,0.05387931034482758,"benchmarks target these more complex tasks, such as logical deduction and logical grid puzzles
25"
INTRODUCTION,0.05603448275862069,"in BIG-bench Lite [32], and in-context learning of these problems is typically poor. Practical
26"
INTRODUCTION,0.05818965517241379,"applications like GitHub Copilot show a mix of promise and limitations: Copilot can auto-generate
27"
INTRODUCTION,0.0603448275862069,"substantial amounts of code [25, 4], but falls short of expert programmers, lacking execution, state
28"
INTRODUCTION,0.0625,"tracking, and debugging abilities (apart from anecdotal evidence, e.g. Fig. 3.7 in [3]; see Section A.3).
29"
INTRODUCTION,0.06465517241379311,"LLMs generate tokens in order, each based on many previous tokens in the sequence, whether these
30"
INTRODUCTION,0.0668103448275862,"tokens were part of the prompt or had just been generated by the LLM itself. Such self-attention
31"
INTRODUCTION,0.06896551724137931,"could allow an LLM to use all previously generated tokens as the scratchpad for tracking reasoning
32"
INTRODUCTION,0.07112068965517242,"steps, states, etc.1. Such use of generated tokens would resemble a classical Turing Machine with its
33"
INTRODUCTION,0.07327586206896551,"memory tape [34]. In principle, a non-trivial recurrent transformer model with inﬁnite attention could
34"
INTRODUCTION,0.07543103448275862,1This is likely to be one of the reasons for the increased performance of CoT prompting.
INTRODUCTION,0.07758620689655173,"be Turing-complete and capable of executing arbitrary routines, as long as the attention mechanism
35"
INTRODUCTION,0.07974137931034483,"can be controlled stringently enough. But, even in relatively simple settings, LLMs appear to resist
36"
INTRODUCTION,0.08189655172413793,"strict controls, e.g., slight changes in prompts can yield dramatically different responses [14, 17, 30],
37"
INTRODUCTION,0.08405172413793104,"because many recurrent patterns in the training data are encoded into a single model, and learned
38"
INTRODUCTION,0.08620689655172414,"patterns overlap and vary in the context size. Thus it is easy to mislead with a prompt with accidental
39"
INTRODUCTION,0.08836206896551724,"alphabetical or numerical ordering, or some undetectable semantic bias [41, 16, 19].
40"
INTRODUCTION,0.09051724137931035,"In Section 2, we introduce much stricter attention controls that instruct LLMs to unroll reasoning
41"
INTRODUCTION,0.09267241379310345,"steps of a procedure with the initially undetermined length, and decide when the solution is found:
42"
INTRODUCTION,0.09482758620689655,"Iteration by Regimenting Self-Attention (IRSA). The basic way to achieve such deliberate self-
43"
INTRODUCTION,0.09698275862068965,"attention control is through highly structured prompting with an example of execution path for one
44"
INTRODUCTION,0.09913793103448276,"example, as illustrated for Bubble Sort algorithm in Prompt 1, which encourages an LLM to output
45"
INTRODUCTION,0.10129310344827586,"not just the sorted sequence but also the swap count (response in Prompt A.1 in Appendix), which is
46"
INTRODUCTION,0.10344827586206896,"a challenging task to solve in a savant manner. We further explore fragmented prompting which
47"
INTRODUCTION,0.10560344827586207,"combines multiple fragments of execution paths, as well as the strategy of skipping parts of generated
48"
INTRODUCTION,0.10775862068965517,"text when performing self-attention. We also discuss interpreter/compiler prompts that can translate
49"
INTRODUCTION,0.10991379310344827,"an algorithm in a high-level programming language into an IRSA prompt that GPT-3 can execute
50"
INTRODUCTION,0.11206896551724138,"(with details in Section 2.4 in the Appendix).
51"
INTRODUCTION,0.11422413793103449,"We present results on a wide range of algorithms taught in computer science curricula and used to test
52"
INTRODUCTION,0.11637931034482758,"software engineers in coding interviews, including string manipulations, dynamic programming, and
53"
INTRODUCTION,0.11853448275862069,"stack operations in Section 3. Our ﬁndings point to broader applications for LLMs beyond existing
54"
INTRODUCTION,0.1206896551724138,"uses like Copilot in areas like software engineering and education [7, 24, 28, 18]. More pressingly,
55"
INTRODUCTION,0.12284482758620689,"they point out a critical issue in evaluating in-context learning of LLMs, suggesting that current
56"
INTRODUCTION,0.125,"evaluations may underestimate LLMs’ abilities if prompts can combine natural language instructions
57"
INTRODUCTION,0.1271551724137931,"with algorithmic iterative reasoning. The sensitivity of the performance to prompt design may be
58"
INTRODUCTION,0.12931034482758622,"ampliﬁed by the iterative reasoning triggered by the prompt, which will then beg the question: If
59"
INTRODUCTION,0.1314655172413793,"one LLM beats the other on a task, is it simply because we have not found the right prompt for
60"
INTRODUCTION,0.1336206896551724,"the second model? For example, IRSA prompting increases the performance of GPT-3 family on
61"
INTRODUCTION,0.13577586206896552,"logical deduction puzzles from 32% to 76% (Table 1. The discussion in the Appendix also includes
62"
INTRODUCTION,0.13793103448275862,"an experiment with GPT-4 [21] on a well-known dynamic programming task showing that even the
63"
INTRODUCTION,0.1400862068965517,"latest member in the family cannot consistently execute code without prompting in IRSA style.
64"
INTRODUCTION,0.14224137931034483,"2
Iteration by Regimenting Self Attention (IRSA)
65"
INTRODUCTION,0.14439655172413793,"Prompt 1, as well as the prompts 2, A.4, A.5, and A.6 in the Appendix, illustrate the basic IRSA. In
66"
INTRODUCTION,0.14655172413793102,"each of these examples, a single prompt is provided for a task, which, when combined with a new
67"
INTRODUCTION,0.14870689655172414,"instance of the task, trigger the execution of an iterative algorithm. The algorithms are single loop
68"
INTRODUCTION,0.15086206896551724,"(Prompts A.5 and A.6) or double loop (Prompts 1, A.4, and 2); and may have a known or unknown
69"
INTRODUCTION,0.15301724137931033,"number of iterations until termination.
70"
INTRODUCTION,0.15517241379310345,"Crucially, the prompts show all state changes and explain each change before it occurs. Although
71"
INTRODUCTION,0.15732758620689655,"the explanation is colloquial, the structure of it is both rigid and repetitive, strictly regimenting the
72"
INTRODUCTION,0.15948275862068967,"attention to the rules (corresponding to program instructions) and state changes. In all these examples,
73"
INTRODUCTION,0.16163793103448276,"this strategy hardens the attention sufﬁciently to facilitate disciplined procedural reasoning, while
74"
INTRODUCTION,0.16379310344827586,"leaving non-regimented content open to interpretation. For example, Prompt 1 shows how a sequence
75"
INTRODUCTION,0.16594827586206898,"of 4 integers can be sorted in some detail, but the same prompt can also be used to sort characters
76"
INTRODUCTION,0.16810344827586207,"alphabetically or animals by size, and the procedure typically works for both shorter and longer lists.
77"
INTRODUCTION,0.17025862068965517,"These prompts could be thought of as an instance of Chain-of-Thought prompting [38, 37, 42, 6, 36,
78"
INTRODUCTION,0.1724137931034483,"15, 11]. However, a signiﬁcant distinction lies in the number of reasoning steps, which is limited
79"
INTRODUCTION,0.17456896551724138,"and ﬁxed in usual CoT applications. In contrast, the algorithms explored here require an unspeciﬁed
80"
INTRODUCTION,0.17672413793103448,"number of iterations required to complete the execution, and may even incorporate double loops. The
81"
INTRODUCTION,0.1788793103448276,"prompt contains the condition for declaring the end of execution.
82"
INTRODUCTION,0.1810344827586207,"2.1
Using IRSA to reason over logical puzzles.
83"
INTRODUCTION,0.18318965517241378,"Iterative reasoning is required in solving a number of NLP word prolems, (e.g., [32]), not just in
84"
INTRODUCTION,0.1853448275862069,"execution of standard algorithms, as these algorithms can be employed after parsing the world
85"
INTRODUCTION,0.1875,"problem. The BIG-bench Logical Deduction task asks for the ordering of several objects given
86"
INTRODUCTION,0.1896551724137931,"their pairwise relationships described in natural language (e.g., a robin is standing on a branch to
87"
INTRODUCTION,0.19181034482758622,"Prompt 1. Bubble Sort: The prompt describes iterative state evolution, including counting swaps,
and making the determination when to stop. Playground link (use with 0 temperature)
Problem: 2, 3, 1, 5
EXECUTION"
INTRODUCTION,0.1939655172413793,"Prep
Length of the list: 4
Number of consecutive pairs: 3
a=[2 3 1 5]
set n_swaps=0
EndPrep
Iteration:"
INTRODUCTION,0.1961206896551724,"set swap_flag=false. The state is:
State: a=[2 3 1 5], n_swaps=0, swap_flag=false EndState
Pair a[1,2] = [2 3] Check if 2<3. Is it true? Yes."
INTRODUCTION,0.19827586206896552,"Because of that, we leave state as is
State: a=[2 3 1 5], n_swaps=0, swap_flag=false
Pair a[2,3]= [3
1] Check if 3<1.
Is it true? No.
Thus, we swap_flag=true, increase n_swaps by one,
and in the latest a=[2 3 1 5]
swap 3 and 1 to get into state:
State: a=[2 1 3 5], n_swaps=1, swap_flag=true EndState
Pair a[3,4]= [3 5]
Check if 3<5. Is it true? Yes.
Because of that, we leave state as is
State: a=[2 1 3 5], n_swaps=1, swap_flag=true EndState
swap_flag is true, so do another iteration
Iteration:"
INTRODUCTION,0.20043103448275862,"set swap_flag=false. The state is:
State: a=[2 1 3 5], n_swaps=1, swap_flag=false EndState
Pair a[1,2] = [2 1] Check if 2<1. Is it true? No."
INTRODUCTION,0.2025862068965517,"Thus, we set swap_flag=true, increase n_swaps by one,
and in the latest a=[2, 1, 3, 5]
swap 2 and 1 to get into state:
State: a=[1 2 3 5], n_swaps=2, swap_flag=true EndState
Pair a[2,3] = [2 3] Check if 2<3. Is it true? Yes."
INTRODUCTION,0.20474137931034483,"Because of that, we leave state as is
State: a=[1 2 3 5], n_swaps=2, swap_flag=true EndState
Pair a[3,4] = [3 5] Check if 3<5. Is it true? Yes."
INTRODUCTION,0.20689655172413793,"Because of that, we leave state as is
State: a=[1 2 3 5], n_swaps=2, swap_flag=true EndState
swap_flag is true, so do another iteration
Iteration:"
INTRODUCTION,0.20905172413793102,"set swap_flag=false. The state is:
State: a=[1 2 3 5], n_swaps=2, swap_flag=false EndState
Pair a[1,2] = [1 2] Check if 1<2. Is it true? Yes."
INTRODUCTION,0.21120689655172414,"Because of that, we leave state as is
State: a=[1 2 3 5], n_swaps=2, swap_flag=false EndState
Pair a[2,3] = [2 3] Check if 2<3. Is it true? Yes."
INTRODUCTION,0.21336206896551724,"Because of that, we leave state as is
State: a=[1 2 3 5], n_swaps=2, swap_flag=false EndState
Pair a[3,4] = [3 5] Check if 3<5. Is it true? Yes."
INTRODUCTION,0.21551724137931033,"Because of that, we leave state as is
State: a=[1 2 3 5], n_swaps=2, swap_flag=false EndState
swap_flag is false, so stop the iteration
Final List: 1, 2, 3, 5
Number of swaps: 2
END OF EXECUTION"
INTRODUCTION,0.21767241379310345,"Problem: 0, 3, 8, 5, 6
EXECUTION"
INTRODUCTION,0.21982758620689655,Prompt 2. Logical deduction puzzle IRSA prompt. Playground link (use with 0 temperature)
INTRODUCTION,0.22198275862068967,"PUZZLE: The following objects need to be ordered. obj1 is the biggest. obj2 is smaller than obj3.
obj1 is bigger than obj2. QUESTION: Which object is the biggest?
START
Parsing step:"
INTRODUCTION,0.22413793103448276,"Items: obj1, obj2, obj3
Numbe of items: 3
Statement 1: obj1 is the biggest.
Statement 2: obj2 is smaller than obj3.
Statement 3: obj1 is bigger than obj2.
Scoring identification step:"
INTRODUCTION,0.22629310344827586,"Scores will refer to size.
Since we have 3 items, let’s assume that the biggest gets a score
of 3 pounds
and the smallest gets the score of 1 pound.
Translation step:"
INTRODUCTION,0.22844827586206898,"Available variable names: x, y, z, a, b, c
Map item scores of ’obj1’, ’obj2’, ’obj3’ to variable names x, y, z
obj1 score is x; obj2 score is y; obj3 is z;
Statement 1: ’x’ is the biggest.
Statement 2: ’y’ is smaller than ’z’.
Statement 3:
’x’ is bigger than ’y’.
Initialization step:"
INTRODUCTION,0.23060344827586207,"Words used to qualify the realtionsips: smaller, bigger, biggest
Orientation step:"
INTRODUCTION,0.23275862068965517,"the biggest: refers to the score of 3
smaller: refers to smaller score
bigger:
refers to larger score
Initialize so that all scores are
different numbers between 1 and 3
Score_assignment_A:
x=2, y=3, z=1
Iterative reasoning
Iteration 1:"
INTRODUCTION,0.2349137931034483,"update_flag=false
Statement 1:
’x’ is the biggest, meaning: x should be 3
In Score_assignment_A, x is 2
x is not what it should be, so we need to make a change, so we set update_flag=true and we need to make a swap.
In the statement there is only one variable and it is
x. We need
to find another. We want x to be 3,
but we see that in Score_assignment_A that 3 is assigned to y, so we swap
values of x and y to make
Score_assignment_B:
x=3, y=2, z=1
Statement 2: ’y’ is smaller than ’z’, meaning: y<z
In Score_assignment_B, y is 2 and z is 1,
so y<z maps to 2<1
2<1 is false, so we need to make a change, so we set update_flag=true and we
need
ot make a swap.
In the statement there are two variables and those are y and z so we swap in Score_assignment_B to make
Score_assignment_C:
x=3, y=1, z=2
Statement 3: ’ x’ is bigger than ’y’, meaning x>y
In Score_assignment_C, x is 3 and y is 1,
so x>y maps to 3>1
3>1 is true, so we don’t need to make a change.
End of iteration. Since update_flag is true, we need more iterations.
Iteration 2:"
INTRODUCTION,0.23706896551724138,"update_flag=false
Statement 1:
’x’ is the biggest, meaning: x=3
In Score_assignment_C, x is 3,
so x=3 maps to 3=3
3=3
is true, so we don’t need to make a change.
Statement 2: ’y’ is smaller than z, meaning: y<z
In Score_assignment_C, y is 1 and z is 2, so y<z maps to 1<2
1<2 is true, so we don’t need to make a change.
Statement 3: ’x’ is bigger than y, meaning x>y
In Score_assignment_C, x is 3 and y is 1,
so x>y maps to 3>1
3>1 is true, so we don’t need to make a change.
End of iteration. Since update_flag is false, we have finished all iterations and found the correct order.
The correct score assignment is the last (Score_assignment_C):
x=3, y=1, z=2
Reverse translation step:
Map items ’obj1’, ’obj2’, ’obj3’ to variable names x, y, z
so we replace x by obj1, y by obj2, and z by obj3 to get size scores:
obj1 has the score 3; obj2 has the score 1; obj3 has the score 2"
INTRODUCTION,0.23922413793103448,"Question: Which object is the biggest?
Answer: obj1
Sorting all by score starting with obj1:
with score 3, obj1
with score 2, obj3
with score 1, obj2
END"
INTRODUCTION,0.2413793103448276,"PUZZLE: On a shelf, there are five books: a gray book, a red book, a purple book, a blue book, and a black book.
The red book is to the right of the gray book. The black book is to the left of the blue book.
The blue book is to the left of the gray book. The purple book is the second from the right.
QUESTION: Which is leftmost?
START"
INTRODUCTION,0.2435344827586207,"the right of a raven, but a sparrow is the left-most). Despite the low number of objects (e.g., ﬁve)
88"
INTRODUCTION,0.24568965517241378,"in these puzzles, LLMs struggle to solve them in zero- or few-shot settings, much like how human
89"
INTRODUCTION,0.2478448275862069,"solvers typically cannot just see the correct answer instantly without scratch paper. This task is not
90"
INTRODUCTION,0.25,"solved well by LLMs without external search/reasoning/inference algorithms, such as ThinkSum [22].
91"
INTRODUCTION,0.2521551724137931,"However, a variant of BubbleSort algorithm adapted to this problem and shown in Prompt 2 can be
92"
INTRODUCTION,0.2543103448275862,"used to solve 76% of these puzzles. The prompt has a CoT structure that translates the problem into a
93"
INTRODUCTION,0.25646551724137934,"canonical form, and then, in IRSA style, describes an iterative swapping procedure that rearranges
94"
INTRODUCTION,0.25862068965517243,"the objects.
95"
INTRODUCTION,0.2607758620689655,"2.2
Fragmented prompting.
96"
INTRODUCTION,0.2629310344827586,"Another way to trigger iterative behaviour is through fragmented prompting, illustrated in Prompt 3),
97"
INTRODUCTION,0.2650862068965517,"which relies on:
98"
INTRODUCTION,0.2672413793103448,"• Complete state speciﬁcation. In contrast to Prompt 1 where iterative behaviour is induced indirectly
99"
INTRODUCTION,0.26939655172413796,"through worked-out examples of multiple full loops, Prompt 3 explicitly describes state content in
100"
INTRODUCTION,0.27155172413793105,"state-to-state transitions, including the iterator i.
101"
INTRODUCTION,0.27370689655172414,"• Fragmentation. Prompt 3 does not fully cover the entire execution path of any single example.
102"
INTRODUCTION,0.27586206896551724,"Instead, it follows the ﬁrst three state changes2 for the sequence 2, 3, 1, 5, and then stops in the
103"
INTRODUCTION,0.27801724137931033,"middle of a sentence. Then it shows 6 additional fragments of execution paths for different problems.
104"
INTRODUCTION,0.2801724137931034,"Interestingly, fragmented prompting can also trigger iterative behaviour, where the language model
105"
INTRODUCTION,0.2823275862068966,"accurately executes the algorithm on a given input and outputs END OF EXECUTION when the
106"
INTRODUCTION,0.28448275862068967,"termination condition (no new updates on the sequence) is met. Viewing this prompt as an instance
107"
INTRODUCTION,0.28663793103448276,"of in-context learning, it is challenging to classify it in usual terms. It goes beyond 0-shot learning
108"
INTRODUCTION,0.28879310344827586,"as it contains explanations speciﬁc to the algorithmic sorting task. Yet, as opposed to what the
109"
INTRODUCTION,0.29094827586206895,"few-shot CoT prompting might do, it does not work out any single example of array sorting. Instead,
110"
INTRODUCTION,0.29310344827586204,"it provides fragments of patterns that can be stitched together to execute the algorithm (and GPT-3
111"
INTRODUCTION,0.2952586206896552,"CODE-DAVINCI-002 does execute it correctly for new inputs).
112"
INTRODUCTION,0.2974137931034483,"The potential advantage of such fragmented prompting is that the prompt can be shorter and include a
113"
INTRODUCTION,0.2995689655172414,"greater variety of situations that may be encountered in new problems. A potential disadvantage is that
114"
INTRODUCTION,0.3017241379310345,"the language model may get confused by the fragmentation and start hallucinating new independent
115"
INTRODUCTION,0.30387931034482757,"fragments. In this case, we managed to avoid that by having the ﬁrst fragment starting from the start
116"
INTRODUCTION,0.30603448275862066,"of execution, going through several state transitions, and ending mid-sentence. Because of this, when
117"
INTRODUCTION,0.3081896551724138,"a new problem is given, the language model starts running the execution path from the beginning,
118"
INTRODUCTION,0.3103448275862069,"and later refers to various cases in the prompt for guidance on how to proceed.
119"
INTRODUCTION,0.3125,"2.3
Skip attention.
120"
INTRODUCTION,0.3146551724137931,"Prompt 3 also illustrates the idea of attention skipping. Whether using a single-execution or a
121"
INTRODUCTION,0.3168103448275862,"fragmented prompt, if the state in the <state>*</state> structure is complete, the attention
122"
INTRODUCTION,0.31896551724137934,"mechanism can generate the next token without attending to all the generated text. It is sufﬁcient to
123"
INTRODUCTION,0.32112068965517243,"attend to the prompt and the text generated after and including the last state.
124"
INTRODUCTION,0.3232758620689655,"If the skipping is implemented on the server side, akin to stop word functionality, then skipping
125"
INTRODUCTION,0.3254310344827586,"unnecessary attention saves computation: The state of the model at the end of the prompt is cached and
126"
INTRODUCTION,0.3275862068965517,"used to continue processing from the latest generated <state> marker, ignoring the text generated
127"
INTRODUCTION,0.3297413793103448,"in-between. Skip-to-state can also be implemented on the client side, iteratively updating the original
128"
INTRODUCTION,0.33189655172413796,"prompt by concatenating the latest <state>*</state> structure to the original prompt and calling
129"
INTRODUCTION,0.33405172413793105,"the generative model with </state> as a stop sequence (We did the latter in our experiments). In
130"
INTRODUCTION,0.33620689655172414,"both cases, the skip-to-state strategy should increase the number of tokens that can be generated,
131"
INTRODUCTION,0.33836206896551724,"as self-attention, which grows linearly with the generated text, is the primary cause for the token
132"
INTRODUCTION,0.34051724137931033,"limitations. Skip-to-state strategy keeps the self-attention cost constant. As IRSA requires the
133"
INTRODUCTION,0.3426724137931034,"unrolling of potentially long iterative algorithms, these savings are important. For example, running
134"
INTRODUCTION,0.3448275862068966,"a dynamic program that keeps track of 2D matrices is only practical in this manner. (See also [29]
135"
INTRODUCTION,0.34698275862068967,"on an external memory approach to dealing with limited attention length. Here we deal with it by
136"
INTRODUCTION,0.34913793103448276,"skipping parts of generated text, instead). Another advantage of skip-to-state attention is that by
137"
INTRODUCTION,0.35129310344827586,"only attending to the necessary information, the generative model is less likely to get confused by
138"
INTRODUCTION,0.35344827586206895,"accidental patterns created in its own generated text. (See more in Section A.3 and Figure A.1.)
139"
INTRODUCTION,0.35560344827586204,2The full execution path in this style is shown in Prompt A.4.
INTRODUCTION,0.3577586206896552,"Prompt 3. Fragments: An incomplete path for the ﬁrst few Buble Sort state transitions for one
sequence is followed by state transitions involving different sequences at different execution points.
Initial part of the response is marked green. Skip attention: The part of the response up to the last
state is not needed to continue the generation. Only the prompt, the last <state>*</state>, and
the text after it are necessary to generate the next token. Playground link (use with 0 temperature)"
INTRODUCTION,0.3599137931034483,Attend
INTRODUCTION,0.3620689655172414,"Problem: 2, 3, 1, 5
EXECUTION"
INTRODUCTION,0.3642241379310345,"Length of the list: L=4
Number of pairs: P=3
a=[2 3 1 5]
set n_swaps=0. set i=P=3. set swap_flag=true."
INTRODUCTION,0.36637931034482757,"<state> a=[2 3 1 5] i=3 P=3 n_swaps=0 swap_flag=true </state>
Since i=3 and P=3, i and P are equal, so this iteration is done, but swap_flag is true,
so we need another iteration
Iteration:"
INTRODUCTION,0.36853448275862066,"set swap_flag=false.
set i=0. The state is:
<state> a=[2 3 1 5] i=0 P=3 n_swaps=0 swap_flag=false </state>
Since i=0 and P=3, these two are different, so we continue
a[i]=a[0]=2 a[i+1]=a[1]=3
Because 2<3 is true we keep state as is and move on by increasing i
<state> a=[2 3 1 5] i=1 P=3 n_swaps=0 swap_flag=false </state>
Since i=1 and P=3, these two are different, so we continue
a[i]=a[1]=3 a[i+1]=a[2]=1
Because 3<1 is false we set swap_flag=true,increase n_swaps by one, and in a=[2 3 1 5]
swap 3 and 1, and increase i, and keep P as is to get
<state> a=[2 1 3 5] i=2 P=3 n_swaps=1 swap_flag=true </state>
Since i=2 and"
INTRODUCTION,0.3706896551724138,"<state> a=[6 5 8 9 1 2] i=2 P=5 n_swaps=5 swap_flag=false </state>
Since i=2 and P=5 i and P are different, so we continue
a[i]=a[2]=8 a[i+1]=a[3]=9
Because 8<9 is true we we keep state as is and move on by increasing i
<state> a=[6 5 8 9 1 2] i=3 P=5 n_swaps=5 swap_flag=false </state>"
INTRODUCTION,0.3728448275862069,"<state> a=[9 1] i=0 P=1 n_swaps=2 swap_flag=true
</state>
Since i=0 and P=1 i and P are different, so we continue
a[i]=a[0]=9 a[i+1]=a[1]=1
Because 9<1 is false we set swap_flag=true,increase n_swaps by one, and in a=[9 1] swap 9 and 1
and increase i, and keep P as is to get
<state> a=[1 9] i=1 P=1 n_swaps=3 swap_flag=true
</state>"
INTRODUCTION,0.375,"<state> a=[6 7 3 5] i=3 P=3 n_swaps=7 swap_flag=false </state>
Since i=3 and P=3 i and P are equal, so this iteration is done, swap_flag is false, so stop
Final List: 6, 7, 3, 5
Number of swaps: 7
END OF EXECUTION"
INTRODUCTION,0.3771551724137931,"<state> a=[3 5 6 8] i=3 P=3 n_swaps=1 swap_flag=true
</state>
Since i=3 and P=3 i and P are equal, so this iteration is done, but swap_flag is true,
so we need another iteration
Iteration:"
INTRODUCTION,0.3793103448275862,"sset swap_flag=false.
set i=0. The state is:
<state> a=[3 5 6 8] i=0 P=3 n_swaps=1 swap_flag=false </state>"
INTRODUCTION,0.38146551724137934,"<state> a=[2 8 1 3 5 7 4] i=1 P=6 n_swaps=5 swap_flag=false </state>
Since i=1 and P=6 i and P are different, so we continue
a[i]=a[1]=8 a[i+1]=a[2]=1
Because 8<1 is false we set swap_flag=true,increase n_swaps by one, and in a=[2 8 1 3 5 7 4]
swap 8 and 1 and increase i, and keep P as is to get
<state> a=[2 1 8 3 5 7 4] i=2 P=6 n_swaps=6 swap_flag=true
</state>"
INTRODUCTION,0.38362068965517243,"<state> a=[4 8] i=0 P=1 n_swaps=7 swap_flag=true
</state>
Since i=0 and P=1 i and P are different, so we continue
a[i]=a[0]=4 a[i+1]=a[1]=8
Because 4<8 is true we we keep state as is and move on by increasing i
<state> a=[4 8] i=1 P=1 n_swaps=7 swap_flag=true
</state>
Problem: 3, 1, 8, 9, 6
EXECUTION"
INTRODUCTION,0.3857758620689655,Don’t attend
INTRODUCTION,0.3879310344827586,"Length of the list: L=5
Number of pairs: P=4
a=[3 1 8 9 6]
set n_swaps=0. set i=P=4. set swap_flag=true."
INTRODUCTION,0.3900862068965517,"<state> a=[3 1 8 9 6] i=4 P=4 n_swaps=0 swap_flag=true </state>
Since i=4 and P=4 i and P are equal, so this iteration is done, but swap_flag is true,
so we need another iteration
Iteration:"
INTRODUCTION,0.3922413793103448,"set swap_flag=false.
set i=0. The state is:"
INTRODUCTION,0.39439655172413796,Attend
INTRODUCTION,0.39655172413793105,"<state> a=[3 1 8 9 6] i=0 P=4 n_swaps=0 swap_flag=false </state>
Since i="
INTRODUCTION,0.39870689655172414,"2.4
GPT as a machine language: Prompting to interpret/compile a program.
140"
INTRODUCTION,0.40086206896551724,"A general-purpose computer can execute algorithms that convert the text of a program into its machine
141"
INTRODUCTION,0.40301724137931033,"code. Analogously, we can design prompts with instructions on how to turn code in some language
142"
INTRODUCTION,0.4051724137931034,"into execution paths that can then be used in prompting. The details are given in Section A.1 in the
143"
INTRODUCTION,0.4073275862068966,"Appendix. In fact, we used a “GPT compiler” in Prompt A.2 to create an execution path for the
144"
INTRODUCTION,0.40948275862068967,"double loop DP algorithm for ﬁnding the longest common subsequence (LCS) which we used in our
145"
INTRODUCTION,0.41163793103448276,"experiments.
146"
EXPERIMENTS,0.41379310344827586,"3
Experiments
147"
EXPERIMENTS,0.41594827586206895,"We evaluated two versions of iteration by regimenting self-attention (IRSA):
148"
EXPERIMENTS,0.41810344827586204,"•Basic IRSA: Prompting with highly structured single execution path examples (Table 1). Although
149"
EXPERIMENTS,0.4202586206896552,"similar to CoT prompting, there are notable differences. CoT prompts typically provide multiple
150"
EXPERIMENTS,0.4224137931034483,"steps of reasoning shown for a few examples and have the LLM perform the same steps on a new
151"
EXPERIMENTS,0.4245689655172414,"example. Conversely, IRSA prompts are designed to trigger iterative reasoning that is repeated until
152"
EXPERIMENTS,0.4267241379310345,"the stop condition is reached and the solution is found. Furthermore, the execution path example
153"
EXPERIMENTS,0.42887931034482757,"for each task is deliberately chosen to be out-of-distribution (e.g., the Bubble Sort prompt features
154"
EXPERIMENTS,0.43103448275862066,"a worked-out example of sorting a four-number sequence in just three passes, while the dataset
155"
EXPERIMENTS,0.4331896551724138,"consists of ﬁve-number sequences requiring 2 to 5 iterations and up to 20 state transitions, with
156"
EXPERIMENTS,0.4353448275862069,"varying complexity across problems). Thus in terms of information they provide, these prompts can
157"
EXPERIMENTS,0.4375,"be seen as somewhere between single-shot and zero-shot prompts.
158"
EXPERIMENTS,0.4396551724137931,"•Skip-to-state IRSA: Prompting as above, but with additional forced attention skipping. In this
159"
EXPERIMENTS,0.4418103448275862,"approach, the LLM is forced to attend only to the prompt and the last generated state as it iterates
160"
EXPERIMENTS,0.44396551724137934,"through the input to ﬁnd the solution (illustrated at the end of Prompt 3). We also evaluate fragmented
161"
EXPERIMENTS,0.44612068965517243,"prompts (Table 2), where the prompt does not consist of a single complete execution path for an
162"
EXPERIMENTS,0.4482758620689655,"example, but instead shows several state-to-state transitions for different inputs.
163"
EXPERIMENTS,0.4504310344827586,"Baselines. To make fair comparisons and avoid unnecessary recomputation, we reused existing
164"
EXPERIMENTS,0.4525862068965517,"baselines from [32] wherever possible, denoted by an asterisk (*) (especially considering that these
165"
EXPERIMENTS,0.4547413793103448,"baselines typically perform close to random guessing on certain tasks). We reused these datasets and
166"
EXPERIMENTS,0.45689655172413796,"baselines for the following tasks: Logical deduction, Balanced parenthesis, and Longest common
167"
EXPERIMENTS,0.45905172413793105,"subsequences for long sequences. We created our own datasets and ran baselines for the following
168"
EXPERIMENTS,0.46120689655172414,"tasks: Bubble sort, Longest substring without repeating characters, and Longest common subsequence
169"
EXPERIMENTS,0.46336206896551724,"for short sequences. We include the best result from [32] for the GPT family, as our experiments
170"
EXPERIMENTS,0.46551724137931033,"were mainly conducted using GPT-3. Our baselines included zero or few (5) shot prompting with or
171"
EXPERIMENTS,0.4676724137931034,"without relevant code added to the description of the task in the prompt (e.g. Prompt A.9). Few shot
172"
EXPERIMENTS,0.4698275862068966,"baselines were made with 5 different random choices of examples to be included in the prompt. The
173"
EXPERIMENTS,0.47198275862068967,"’Guessing’ strategy refers to picking the most frequently correct answer for a given task as a guess
174"
EXPERIMENTS,0.47413793103448276,"for each problem in the task, which is different from truly random guessing. Few-shot prompting
175"
EXPERIMENTS,0.47629310344827586,"could prime the answers to pick the most frequently seen answer, even when no understanding of the
176"
EXPERIMENTS,0.47844827586206895,"problem occurs, which makes our ’Guessing’ strategy more reﬂective of the task difﬁculty.
177"
EXPERIMENTS,0.48060344827586204,"Models. We have brieﬂy experimented with different members of the GPT-3 family, but ran complete
178"
EXPERIMENTS,0.4827586206896552,"experiments with CODE-DAVINCI-002 for two reasons: TEXT-DAVINICI-002 and 003 often produced
179"
EXPERIMENTS,0.4849137931034483,"qualitatively similar results, and experimentation with the CODE-DAVINCI-002 was easier due to
180"
EXPERIMENTS,0.4870689655172414,"better combination of token quota and availability. Having been tuned on code, this model may have
181"
EXPERIMENTS,0.4892241379310345,"slight advantages over models tuned for more natural language tasks. Nevertheless, as we show
182"
EXPERIMENTS,0.49137931034482757,"in the experiments and discuss in Section A.3, without IRSA, CODE-DAVINCI-002 cannot solve
183"
EXPERIMENTS,0.49353448275862066,"the problems discussed here, even when it can generate the code that could. To induce iterative
184"
EXPERIMENTS,0.4956896551724138,"reasoning in LLMs, it appears that attention needs to be highly regimented through strong structure,
185"
EXPERIMENTS,0.4978448275862069,"and possibly additional attention control, such as the skip-to-state strategy we described in Section
186"
EXPERIMENTS,0.5,"2.3. This also applies to GPT-4 [21]: In Section A.3.3 in Appendix, we show that prompting GPT-4
187"
EXPERIMENTS,0.5021551724137931,"with straight-forward Prompts A.10, A.11, A.12 does not match the performance of IRSA in GPT-3.
188"
EXPERIMENTS,0.5043103448275862,"Datasets. To test our proposed methods with various prompting baselines, we focus on challenging
189"
EXPERIMENTS,0.5064655172413793,"programming tasks including computer science algorithms from the school curricula and coding
190"
EXPERIMENTS,0.5086206896551724,"interviews for software engineers as follows.
191"
EXPERIMENTS,0.5107758620689655,"Bubble sort. We created a dataset of 100 random non-repeating digit sequences of length 5. For each
192"
EXPERIMENTS,0.5129310344827587,"sequence, we ran the bubble sort algorithm to establish the total number of element swaps it requires.
193"
EXPERIMENTS,0.5150862068965517,"The task is to predict the number of swaps for a given sequence.
194"
EXPERIMENTS,0.5172413793103449,"Table 1: Iteration through Regimented Self-Attention (IRSA) compared with standard in-context
learning baselines, and with the strategy of always guessing the most frequent answer. (*) denotes
the best result for GPT-3 from the BIG-bench [32]."
EXPERIMENTS,0.5193965517241379,"Task
IRSA
Baseline
Guessing"
EXPERIMENTS,0.521551724137931,Bubble sort
EXPERIMENTS,0.5237068965517241,"- Prompt 1
0.74
0.27
0.23
- Prompt A.4
1.00
0.27
0.23
Longest substring
1.00
0.60
0.59
Logical deduction
0.76
0.32⇤
0.2
Parentheses
0.96
0.56⇤
0.5"
EXPERIMENTS,0.5258620689655172,"Longest substring without repeating characters. A classical coding interview question: Given
195"
EXPERIMENTS,0.5280172413793104,"a string of letters, ﬁnd the longest contiguous substring such that no letter appears more than once.
196"
EXPERIMENTS,0.5301724137931034,"We created a dataset of 100 random strings of length 7, and for each found the length of the longest
197"
EXPERIMENTS,0.5323275862068966,"subsequence without repeating characters. The task is to predict that length for a given sequence.
198"
EXPERIMENTS,0.5344827586206896,"Logical deduction [32]. We include this task (Section 2.1) in experiments to emphasize the broad
199"
EXPERIMENTS,0.5366379310344828,"importance of triggering iteration in LLMs responses. Enabling LLMs to execute iterative algorithms
200"
EXPERIMENTS,0.5387931034482759,"through effective prompting could help solve numerous reasoning problems. In particualr, this task
201"
EXPERIMENTS,0.540948275862069,"that involves solving a puzzle about an order of items/objects/persons, such as books on the shelf,
202"
EXPERIMENTS,0.5431034482758621,"birds on a branch, cars, golfers, etc., given several clues, such as “minivan is more expensive than
203"
EXPERIMENTS,0.5452586206896551,"the car”, or “the robin is to the left of the ﬁnch.” We focus on a subtask involving 5 items, with
204"
EXPERIMENTS,0.5474137931034483,"varying sets of items and the types of ordering across the puzzles. While in-context learning with
205"
EXPERIMENTS,0.5495689655172413,"LLMs consistently solves less than 35% of puzzles, a recent combination of GPT-3 and probabilistic
206"
EXPERIMENTS,0.5517241379310345,"reasoning [22] was able to solve 77% of the puzzles. We reach a similar performance through IRSA,
207"
EXPERIMENTS,0.5538793103448276,"without an additional external reasoning mechanism.
208"
EXPERIMENTS,0.5560344827586207,"Valid parentheses [32]. The task is the ﬁrst of the two in the cs-algorithms challenge in BIG-
209"
EXPERIMENTS,0.5581896551724138,"bench. The goal is to evaluate LLMs ability to perform reasoning equivalent to the classical stack
210"
EXPERIMENTS,0.5603448275862069,"manipulations needed to check if a sequence of parentheses of different types is balanced. LLMs
211"
EXPERIMENTS,0.5625,"(including GPT) tend to do about the same as chance (50%), except for PaLM with 3 shots, which
212"
EXPERIMENTS,0.5646551724137931,"gets around 75% accuracy.
213"
EXPERIMENTS,0.5668103448275862,"Longest common subsequence (long) [32]. The second task in BIG-bench cs-algorithms involves
214"
EXPERIMENTS,0.5689655172413793,"solving the classical dynamic programming problem. Deﬁning a subsequence of a sequence to be a
215"
EXPERIMENTS,0.5711206896551724,"sequence of symbols one could get by skipping arbitrary stretches in the original sequence, the task is
216"
EXPERIMENTS,0.5732758620689655,"to ﬁnd the length of the longest subsequence common to two given sequences. LLMs do not do much
217"
EXPERIMENTS,0.5754310344827587,"better than chance on this task (⇠10%).
218"
EXPERIMENTS,0.5775862068965517,"Longest common subsequence (short). We created this dataset in the same manner as the above one
219"
EXPERIMENTS,0.5797413793103449,"from the BIG-bench, but with the constraint on the sequence lengths, limiting them to a maximum of
220"
EXPERIMENTS,0.5818965517241379,"6 characters. This allows us to evaluate IRSA on more cases, ensuring it does not run out-of-memory
221"
EXPERIMENTS,0.584051724137931,"(tokens) in generation3.
222"
EXPERIMENTS,0.5862068965517241,"Basic IRSA results.
The basic IRSA results are summarized in Table 1. For Bubble Sort evaluations,
223"
EXPERIMENTS,0.5883620689655172,"we show the results using both Prompt 1, and Prompt A.4. The latter is a single execution path for
224"
EXPERIMENTS,0.5905172413793104,"the same problem (2, 3, 1, 5), but in the style of Fragmented Prompt 3 by continuing the execution
225"
EXPERIMENTS,0.5926724137931034,"path initiated by Prompt 3, without incorporating fragments from other paths. The former had an
226"
EXPERIMENTS,0.5948275862068966,"accuracy of 74% for inferring the numbers of swaps necessary to sort different sequences, while the
227"
EXPERIMENTS,0.5969827586206896,"latter achieved 100%. Note that while the execution path for the example 2, 3, 1, 5 requires three
228"
EXPERIMENTS,0.5991379310344828,"iterations of the outer loop and three iterations in each inner loop, the dataset contains sequences of
229"
EXPERIMENTS,0.6012931034482759,"length 5 and thus requires four iterations in the inner loop and a variable number of iterations of the
230"
EXPERIMENTS,0.603448275862069,"outside loop – anywhere from 2 to 5 – and yet the model can execute the correct number of iterations
231"
EXPERIMENTS,0.6056034482758621,"based on the stoppage criterion (that in the inner loop, no changes were made to the sequence).
232"
EXPERIMENTS,0.6077586206896551,"For the logical deduction puzzles, we used the Prompt 2 Appendix. Note that the logic of the
233"
EXPERIMENTS,0.6099137931034483,"iterative reasoning there is faulty as it may enter an inﬁnite loop. When that happens, the generation
234"
EXPERIMENTS,0.6120689655172413,"runs out of tokens and we simply used the answer after the 4th iteration in evaluation. Further
235"
EXPERIMENTS,0.6142241379310345,"3Buble sort, Longest substring, and LCS (short) datasets: https://github.com/anajojic/gpt-coding"
EXPERIMENTS,0.6163793103448276,"Table 2: IRSA with skip-attention, Bubble Sort and Longest Common Subsequence problems.
Fragmented prompting, Bubble Sort problems. (*) denotes the best GPT result in [32]"
EXPERIMENTS,0.6185344827586207,"Baselines
Bubble Sort
LCS-S
LCS-L"
-SHOT,0.6206896551724138,"0-shot
0.20
0.09
0.14⇤"
-SHOT,0.6228448275862069,"0-shot + code
0.20
0.11
-
few shot
0.25±0.05
0.07±0.01
0.16⇤"
-SHOT,0.625,"few shot + code
0.23±0.03
0.06±0.02
-
Guessing
0.23
0.44
0.10"
-SHOT,0.6271551724137931,IRSA skip-to-state
-SHOT,0.6293103448275862,"single path
0.95
0.93
0.28
7 fragments
0.99±0.02
-
-
13 fragments
0.97±0.03
-
-
19 fragments
0.99±0.02
-
-
25 fragments
0.97±0.03
-
-"
-SHOT,0.6314655172413793,"discussion in Section A.3 suggests the potential for creating more effective prompts. Nevertheless,
236"
-SHOT,0.6336206896551724,"with this prompt to induce iterative reasoning, we still reach the state-of-the-art results, comparable
237"
-SHOT,0.6357758620689655,"only with [22], which uses an external reasoning mechanism in conjunction with prompting. To
238"
-SHOT,0.6379310344827587,"solve the longest substring without repeating characters problems, we developed Prompt A.5 based
239"
-SHOT,0.6400862068965517,"on asingle-pass algorithm (Section A.2), which, interestingly, trades computation for memory. To
240"
-SHOT,0.6422413793103449,"address the parentheses problem, we used the single execution path that demonstrates stack operations
241"
-SHOT,0.6443965517241379,"for determining whether the sequence is balanced or not. The beginning and the end are shown in
242"
-SHOT,0.646551724137931,"Prompt A.6 and discussed in Section A.2.1 in the Appendix.
243"
-SHOT,0.6487068965517241,"Skip-to-state attention results.
The dynamic programming solution to the longest common subse-
244"
-SHOT,0.6508620689655172,"quence (LCS) problem requires its state including a (M +1)⇥(N +1) matrix storing the solution for
245"
-SHOT,0.6530172413793104,"all preﬁxes of the two sequences of lengths M and N. Without skip-to-state attention (Section 2.3),
246"
-SHOT,0.6551724137931034,"the API calls run out of tokens before reaching the end for all but the shortest problems. Using the
247"
-SHOT,0.6573275862068966,"approach described in Section 2.4, A.1, we compiled an execution path in Prompt A.3, and then used
248"
-SHOT,0.6594827586206896,"it to induce IRSA on LCS short (LCS-S) and LCS long (LCS-L) problems. Even with skip attention,
249"
-SHOT,0.6616379310344828,"the state was too large to ﬁt the token limit for most of the problems in LCS-L from BIG-bench. Yet,
250"
-SHOT,0.6637931034482759,"IRSA with skip attention still beats the state-of-the-art signiﬁcantly (Table 2). On shorter problems in
251"
-SHOT,0.665948275862069,"LCS-S, where IRSA with skip-attention does not run out of tokens, the performance was a respectable
252"
-SHOT,0.6681034482758621,"93%. Note that even GPT-4, without IRSA, can only reach 69% accuracy on LCS-S (Section A.3.3).
253"
-SHOT,0.6702586206896551,"We tested fragmented prompting of Bubble Sort execution (Table 2). For each selected number of
254"
-SHOT,0.6724137931034483,"fragments – 7, 13, 19, 25 – at least one of ﬁve randomly generated prompts achieved 100% accuracy.
255"
-SHOT,0.6745689655172413,"These prompts followed the format in Prompt 3, starting with the few state transitions from the
256"
-SHOT,0.6767241379310345,"beginning for the sequence [2, 3, 1, 5] and then listing additional 6, 12, 18, or 24 fragments. Bubble
257"
-SHOT,0.6788793103448276,"Sort has 6 different transitions, and fully balanced instruction listing one, two, three, or four of
258"
-SHOT,0.6810344827586207,"each type, with a random sequence in the state, leads to a slightly better performance than having
259"
-SHOT,0.6831896551724138,"a completely randomly chosen execution path fragments. These six basic transitions, illustrated in
260"
-SHOT,0.6853448275862069,"Prompt 3, involve two ways of ending an iteration depending on the swap ﬂag and four ways of
261"
-SHOT,0.6875,"changing the state: two possibilities for inequality being true or not, combined with two possible
262"
-SHOT,0.6896551724137931,"previous values of the swap ﬂag. We found that the prompt sensitivity causes different prompts to fail
263"
-SHOT,0.6918103448275862,"for different test cases: Each of the fragmented prompt collections yields 100% as an ensemble.
264"
CONCLUSION,0.6939655172413793,"4
Conclusion
265"
CONCLUSION,0.6961206896551724,"We demonstrated that GPT-3 can be triggered to execute iterative algorithms, including double loops,
266"
CONCLUSION,0.6982758620689655,"with variable termination conditions. This has several consequences discussed in Appendix (Section
267"
CONCLUSION,0.7004310344827587,"A.3). For example, IRSA may ﬁnd applications in sofware engineering and education. If LLMs are
268"
CONCLUSION,0.7025862068965517,"Turing Machines (in addition to being natural language translators and analyzers), their evaluation
269"
CONCLUSION,0.7047413793103449,"probably needs to be rethought, esp. in cases where models are expected to make inferences for
270"
CONCLUSION,0.7068965517241379,"which we have algorithms, because in-context learning would cover prompts designed to execute
271"
CONCLUSION,0.709051724137931,"them (Section A.3). Regimenting self-attention for a given task may require a different level of effort
272"
CONCLUSION,0.7112068965517241,"(Section A.3.2, but even GPT-4 cannot execute programs consistently without IRSA (Section A.3.3).
273"
REFERENCES,0.7133620689655172,"References
274"
REFERENCES,0.7155172413793104,"[1] Yoshua Bengio. The consciousness prior. arXiv preprint arXiv:1709.08568, 2017.
275"
REFERENCES,0.7176724137931034,"[2] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,
276"
REFERENCES,0.7198275862068966,"Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel
277"
REFERENCES,0.7219827586206896,"Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler,
278"
REFERENCES,0.7241379310344828,"Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott
279"
REFERENCES,0.7262931034482759,"Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya
280"
REFERENCES,0.728448275862069,"Sutskever, and Dario Amodei. Language models are few-shot learners. Neural Information
281"
REFERENCES,0.7306034482758621,"Processing Systems (NeurIPS), 2020.
282"
REFERENCES,0.7327586206896551,"[3] Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece
283"
REFERENCES,0.7349137931034483,"Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, Harsha Nori, Hamid Palangi,
284"
REFERENCES,0.7370689655172413,"Marco Tulio Ribeiro, and Yi Zhang. Sparks of artiﬁcial general intelligence: Early experiments
285"
REFERENCES,0.7392241379310345,"with gpt-4, 2023.
286"
REFERENCES,0.7413793103448276,"[4] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto,
287"
REFERENCES,0.7435344827586207,"Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul
288"
REFERENCES,0.7456896551724138,"Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke
289"
REFERENCES,0.7478448275862069,"Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad
290"
REFERENCES,0.75,"Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias
291"
REFERENCES,0.7521551724137931,"Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex
292"
REFERENCES,0.7543103448275862,"Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain,
293"
REFERENCES,0.7564655172413793,"William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra,
294"
REFERENCES,0.7586206896551724,"Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer,
295"
REFERENCES,0.7607758620689655,"Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech
296"
REFERENCES,0.7629310344827587,"Zaremba. Evaluating large language models trained on code, 2021.
297"
REFERENCES,0.7650862068965517,"[5] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam
298"
REFERENCES,0.7672413793103449,"Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. PaLM:
299"
REFERENCES,0.7693965517241379,"Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022.
300"
REFERENCES,0.771551724137931,"[6] Antonia Creswell, Murray Shanahan, and Irina Higgins. Selection-inference: Exploiting large
301"
REFERENCES,0.7737068965517241,"language models for interpretable logical reasoning. arXiv preprint arXiv:2205.09712, 2022.
302"
REFERENCES,0.7758620689655172,"[7] Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan,
303"
REFERENCES,0.7780172413793104,"and Graham Neubig. Pal: Program-aided language models. arXiv preprint arXiv:2211.10435,
304"
REFERENCES,0.7801724137931034,"2022.
305"
REFERENCES,0.7823275862068966,"[8] Anirudh Goyal and Yoshua Bengio. Inductive biases for deep learning of human cognition.
306"
REFERENCES,0.7844827586206896,"arXiv preprint arXiv:2011.15091, 2020.
307"
REFERENCES,0.7866379310344828,"[9] Daniel Kahneman. Thinking, fast and slow. Macmillan, 2011.
308"
REFERENCES,0.7887931034482759,"[10] Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and
309"
REFERENCES,0.790948275862069,"Ashish Sabharwal. Decomposed prompting: A modular approach for solving complex tasks.
310"
REFERENCES,0.7931034482758621,"arXiv preprint arXiv:2210.02406, 2022.
311"
REFERENCES,0.7952586206896551,"[11] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large
312"
REFERENCES,0.7974137931034483,"language models are zero-shot reasoners. arXiv preprint arXiv:2205.11916, 2022.
313"
REFERENCES,0.7995689655172413,"[12] Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, and Weizhu Chen.
314"
REFERENCES,0.8017241379310345,"On the advance of making language models better reasoners. arXiv preprint arXiv:2206.02336,
315"
REFERENCES,0.8038793103448276,"2022.
316"
REFERENCES,0.8060344827586207,"[13] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond,
317"
REFERENCES,0.8081896551724138,"Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code
318"
REFERENCES,0.8103448275862069,"generation with alphacode. Science, 378(6624):1092–1097, 2022.
319"
REFERENCES,0.8125,"[14] Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen.
320"
REFERENCES,0.8146551724137931,"What makes good in-context examples for gpt-3? arXiv preprint arXiv:2101.06804, 2021.
321"
REFERENCES,0.8168103448275862,"[15] Zihan Liu, Mostofa Patwary, Ryan Prenger, Shrimai Prabhumoye, Wei Ping, Mohammad
322"
REFERENCES,0.8189655172413793,"Shoeybi, and Bryan Catanzaro. Multi-stage prompting for knowledgeable dialogue generation.
323"
REFERENCES,0.8211206896551724,"In Findings of the Association for Computational Linguistics: ACL 2022, pages 1317–1337,
324"
REFERENCES,0.8232758620689655,"Dublin, Ireland, May 2022. Association for Computational Linguistics.
325"
REFERENCES,0.8254310344827587,"[16] Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. Fantastically
326"
REFERENCES,0.8275862068965517,"ordered prompts and where to ﬁnd them: Overcoming few-shot prompt order sensitivity. In
327"
REFERENCES,0.8297413793103449,"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics
328"
REFERENCES,0.8318965517241379,"(Volume 1: Long Papers), pages 8086–8098, Dublin, Ireland, May 2022. Association for
329"
REFERENCES,0.834051724137931,"Computational Linguistics.
330"
REFERENCES,0.8362068965517241,"[17] Nikolay Malkin, Zhen Wang, and Nebojsa Jojic. Coherence boosting: When your pretrained
331"
REFERENCES,0.8383620689655172,"language model is not paying enough attention. In Proceedings of the 60th Annual Meeting
332"
REFERENCES,0.8405172413793104,"of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8214–8236,
333"
REFERENCES,0.8426724137931034,"2022.
334"
REFERENCES,0.8448275862068966,"[18] Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru,
335"
REFERENCES,0.8469827586206896,"Roberta Raileanu, Baptiste Rozière, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, et al.
336"
REFERENCES,0.8491379310344828,"Augmented language models: a survey. arXiv preprint arXiv:2302.07842, 2023.
337"
REFERENCES,0.8512931034482759,"[19] Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and
338"
REFERENCES,0.853448275862069,"Luke Zettlemoyer. Rethinking the role of demonstrations: What makes in-context learning
339"
REFERENCES,0.8556034482758621,"work? arXiv preprint arXiv:2202.12837, 2022.
340"
REFERENCES,0.8577586206896551,"[20] Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin,
341"
REFERENCES,0.8599137931034483,"David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. Show
342"
REFERENCES,0.8620689655172413,"your work: Scratchpads for intermediate computation with language models. arXiv preprint
343"
REFERENCES,0.8642241379310345,"arXiv:2112.00114, 2021.
344"
REFERENCES,0.8663793103448276,"[21] OpenAI. Gpt-4 technical report, 2023.
345"
REFERENCES,0.8685344827586207,"[22] Batu Ozturkler, Nikolay Malkin, Zhen Wang, and Nebojsa Jojic. Thinksum: Probabilistic
346"
REFERENCES,0.8706896551724138,"reasoning over sets using large language models. In Proceedings of the 61st Annual Meeting of
347"
REFERENCES,0.8728448275862069,"the Association for Computational Linguistics, 2023.
348"
REFERENCES,0.875,"[23] Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh Hajishirzi, Luke Zettlemoyer,
349"
REFERENCES,0.8771551724137931,"and Marco Tulio Ribeiro. Art: Automatic multi-step reasoning and tool-use for large language
350"
REFERENCES,0.8793103448275862,"models. arXiv preprint arXiv:2303.09014, 2023.
351"
REFERENCES,0.8814655172413793,"[24] Aaron Parisi, Yao Zhao, and Noah Fiedel. Talm: Tool augmented language models. arXiv
352"
REFERENCES,0.8836206896551724,"preprint arXiv:2205.12255, 2022.
353"
REFERENCES,0.8857758620689655,"[25] Sida Peng, Eirini Kalliamvakou, Peter Cihon, and Mert Demirer. The impact of ai on developer
354"
REFERENCES,0.8879310344827587,"productivity: Evidence from github copilot, 2023.
355"
REFERENCES,0.8900862068965517,"[26] Oﬁr Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A Smith, and Mike Lewis.
356"
REFERENCES,0.8922413793103449,"Measuring and narrowing the compositionality gap in language models.
arXiv preprint
357"
REFERENCES,0.8943965517241379,"arXiv:2210.03350, 2022.
358"
REFERENCES,0.896551724137931,"[27] Jack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song,
359"
REFERENCES,0.8987068965517241,"John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. Scaling language
360"
REFERENCES,0.9008620689655172,"models: Methods, analysis & insights from training Gopher. arXiv preprint arXiv:2112.11446,
361"
REFERENCES,0.9030172413793104,"2021.
362"
REFERENCES,0.9051724137931034,"[28] Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettle-
363"
REFERENCES,0.9073275862068966,"moyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach
364"
REFERENCES,0.9094827586206896,"themselves to use tools. arXiv preprint arXiv:2302.04761, 2023.
365"
REFERENCES,0.9116379310344828,"[29] Dale Schuurmans. Memory augmented large language models are computationally universal.
366"
REFERENCES,0.9137931034482759,"arXiv preprint arXiv:2301.04589, 2023.
367"
REFERENCES,0.915948275862069,"[30] Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed Chi, Nathanael
368"
REFERENCES,0.9181034482758621,"Schärli, and Denny Zhou. Large language models can be easily distracted by irrelevant context.
369"
REFERENCES,0.9202586206896551,"arXiv preprint arXiv:2302.00093, 2023.
370"
REFERENCES,0.9224137931034483,"[31] Vered Shwartz, Peter West, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. Unsupervised
371"
REFERENCES,0.9245689655172413,"commonsense question answering with self-talk. In Proceedings of the 2020 Conference on
372"
REFERENCES,0.9267241379310345,"Empirical Methods in Natural Language Processing (EMNLP), pages 4615–4629, Online,
373"
REFERENCES,0.9288793103448276,"November 2020. Association for Computational Linguistics.
374"
REFERENCES,0.9310344827586207,"[32] Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid,
375"
REFERENCES,0.9331896551724138,"Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, et al.
376"
REFERENCES,0.9353448275862069,"Beyond the imitation game: Quantifying and extrapolating the capabilities of language models.
377"
REFERENCES,0.9375,"arXiv preprint arXiv:2206.04615, 2022.
378"
REFERENCES,0.9396551724137931,"[33] Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian Gehrmann, Yi Tay, Hyung Won
379"
REFERENCES,0.9418103448275862,"Chung, Aakanksha Chowdhery, Quoc V Le, Ed H Chi, Denny Zhou, et al. Challenging big-
380"
REFERENCES,0.9439655172413793,"bench tasks and whether chain-of-thought can solve them. arXiv preprint arXiv:2210.09261,
381"
REFERENCES,0.9461206896551724,"2022.
382"
REFERENCES,0.9482758620689655,"[34] Alan M. Turing. On computable numbers, with an application to the Entscheidungsproblem.
383"
REFERENCES,0.9504310344827587,"Proceedings of the London Mathematical Society, 2(42):230–265, 1936.
384"
REFERENCES,0.9525862068965517,"[35] Amos Tversky and Daniel Kahneman. Judgment under uncertainty: Heuristics and biases: Bi-
385"
REFERENCES,0.9547413793103449,"ases in judgments reveal some heuristics of thinking under uncertainty. Science, 185(4157):1124–
386"
REFERENCES,0.9568965517241379,"1131, 1974.
387"
REFERENCES,0.959051724137931,"[36] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. Rationale-
388"
REFERENCES,0.9612068965517241,"augmented ensembles in language models. arXiv preprint arXiv:2207.00747, 2022.
389"
REFERENCES,0.9633620689655172,"[37] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou.
Self-
390"
REFERENCES,0.9655172413793104,"consistency improves chain of thought reasoning in language models.
arXiv preprint
391"
REFERENCES,0.9676724137931034,"arXiv:2203.11171, 2022.
392"
REFERENCES,0.9698275862068966,"[38] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny
393"
REFERENCES,0.9719827586206896,"Zhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint
394"
REFERENCES,0.9741379310344828,"arXiv:2201.11903, 2022.
395"
REFERENCES,0.9762931034482759,"[39] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.
396"
REFERENCES,0.978448275862069,"React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629,
397"
REFERENCES,0.9806034482758621,"2022.
398"
REFERENCES,0.9827586206896551,"[40] Eric Zelikman, Yuhuai Wu, and Noah D Goodman. STaR: Bootstrapping reasoning with
399"
REFERENCES,0.9849137931034483,"reasoning. arXiv preprint arXiv:2203.14465, 2022.
400"
REFERENCES,0.9870689655172413,"[41] Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. Calibrate before use:
401"
REFERENCES,0.9892241379310345,"Improving few-shot performance of language models. In International Conference on Machine
402"
REFERENCES,0.9913793103448276,"Learning, pages 12697–12706. PMLR, 2021.
403"
REFERENCES,0.9935344827586207,"[42] Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale
404"
REFERENCES,0.9956896551724138,"Schuurmans, Olivier Bousquet, Quoc Le, and Ed Chi.
Least-to-most prompting enables
405"
REFERENCES,0.9978448275862069,"complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022.
406"
