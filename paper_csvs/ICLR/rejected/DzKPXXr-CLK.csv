Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.002544529262086514,"In several domains such as natural language processing, it has been empirically
reported that simple addition and subtraction in a somehow learned embedding
space capture analogical relations. However, there is no guarantee that such rela-
tion holds for a new embedding space acquired by some training strategies. To
tackle this issue, we propose to explicitly model analogical structure with an
Abelian group. We construct an Abelian group network using invertible neu-
ral networks and show its universal approximation property. In experiments, our
model successfully learns to capture word analogies from word2vec representa-
tions and shows better performance than other learning-based strategies. As a
byproduct of modeling Abelian group operations, we furthermore obtain its natu-
ral extension to permutation invariant models with theoretical size-generalization
capability."
INTRODUCTION,0.005089058524173028,"1
INTRODUCTION"
INTRODUCTION,0.007633587786259542,"The vector representations of words called word2vec (Mikolov et al., 2013a;b) trained only on
large unlabeled text data are known to capture linear regularities between words. For example,
vec(“king”)−vec(“man”)+vec(“woman”) results in the most similar vector to vec(“queen”). Sim-
ilar results have been observed not only in other word embeddings (Mnih & Kavukcuoglu, 2013;
Pennington et al., 2014) but also in various embedding spaces, such as combined embeddings of text
and image (Kiros et al., 2014), emoji embeddings (Eisner et al., 2016), latent representation of deep
convolutional generative adversarial networks (Radford et al., 2016), and feature space of pretrained
image models (Upchurch et al., 2017)."
INTRODUCTION,0.010178117048346057,"Although the reports are interesting and attractive, such approaches have shortcomings. Since those
methods of learning from unlabelled data usually do not explicitly incorporate learning analogical
structure, there is no guarantee that the acquired embedding space has linear relations between
instance pairs even if training itself works well. Even when an embedding space captures some kinds
of analogies, it might not work for other kinds of analogies. Indeed, word2vec representation works
well for inﬂectional analogies (68.22% accuracy) but poorly for encyclopedic analogies (7.11%
accuracy) in our preliminary experiments (see Table 3 in Section 4.2). In such a case, it is quite
difﬁcult to tune the training algorithm for certain kinds of analogies you want to use."
INTRODUCTION,0.01272264631043257,"To alleviate these issues, we propose to directly learn analogical relations on the embedding space
from labeled data. One challenge in learning analogy in a supervised manner is how to model
analogical functions. A naive way to do this is to train two separate models corresponding to addition
and subtraction, respectively; however, it does not reﬂect the analogical structure and might be
inefﬁcient. In this work, we propose an Abelian group network to incorporate an analogical inductive
bias into a neural network. The proposed network is designed to satisfy the Abelian group condition
by using an invertible neural network. We also show that the Abelian group network is a universal
approximator of smooth Abelian group operations. Since the inverse element in the Abelian group
network and its gradient are analytically computable, we can train it for analogy tasks by common
techniques for deep learning, such as stochastic gradient descent."
INTRODUCTION,0.015267175572519083,"As a side effect of the algebraic structure, we can construct a permutation invariant function, i.e.,
a function for multisets, by repeatedly composing an Abelian group operation for multiple inputs.
Multiset models can handle inputs of different sizes, and it is important for the models to auto-
matically generalize between different size inputs, especially from small to large ones. However,
existing multiset models (Zaheer et al., 2017; Qi et al., 2017) have no such theoretical guarantee. On"
INTRODUCTION,0.017811704834605598,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.020356234096692113,"the other hand, our multiset models naturally induce the size-generalization capability because the
output for larger inputs can be written as the composition of small elements. Further, we show that
a necessary and sufﬁcient condition for the composed function being permutation invariant is that
the binary operation forms an Abelian semigroup, and we propose an Abelian semigroup network,
by using the characterization of associative symmetric polynomials."
PRELIMINARIES,0.022900763358778626,"2
PRELIMINARIES"
DEFINITIONS,0.02544529262086514,"2.1
DEFINITIONS"
DEFINITIONS,0.027989821882951654,"In this section, let us introduce some basic notations and important deﬁnitions that will play a key
role in this work."
BASIC NOTATIONS,0.030534351145038167,"2.1.1
BASIC NOTATIONS"
BASIC NOTATIONS,0.03307888040712468,"By N, we represent the set of the natural numbers including 0. We denote a vector by a bold symbol,
e.g., x. Let x ∈Rd be a d-dimensional vector. We represent the i-th element (1 ≤i ≤d) of x
by xi. For 1 ≤k ≤d, x≤k ∈Rk is the k-dimensional vector (x1, . . . xk) and x<k ∈Rk−1 is
the (k −1)-dimensional vector (x1, . . . xk−1). We denote the elementwise product of two vectors
x, y ∈Rd by x ⊗y, such that (x ⊗y)i = xiyi and the elementwise division of two vectors
x ∈Rd, y ∈(R \ {0})d by x ⊘y, such that (x ⊘y)i = xi/yi. By ∥· ∥, we represent the L2
(Euclidean) norm."
MULTISET AND PERMUTATION INVARIANCE,0.035623409669211195,"2.1.2
MULTISET AND PERMUTATION INVARIANCE"
MULTISET AND PERMUTATION INVARIANCE,0.03816793893129771,"Here, we use X and Y to describe some domains, which are typically Euclidean spaces, i.e., X =
Rd1 and Y = Rd2. We denote the set of multisets over X by NX . We use {x1, . . . xn} ∈NX to
describe a multiset composed of x1, . . . , xn ∈X (any confusion with sets is not problematic in this
paper). The cardinality of a multiset is the number of elements with multiplicity and is expressed by
| · |, e.g., |{1, 2, 2, 3}| = 4."
MULTISET AND PERMUTATION INVARIANCE,0.04071246819338423,"For n ∈N, a symmetric group Sn is the set of all n! bijective functions σ: {1, 2, . . . , n} →
{1, 2, . . . , n}. For a permutation σ ∈Sn and X ∈X, σ·X is deﬁned such that (σ·X)i = Xσ(i) for
all i ∈{1, . . . , n}. A function f : X n →Y is said to be permutation invariant if for any X ∈X n
and for any permutation σ ∈Sn, f(σ·X) = f(X) holds. This concept can be extended to functions
that take vectors of different dimensions. Namely, a function f : S"
MULTISET AND PERMUTATION INVARIANCE,0.043256997455470736,"k∈N X k →Y is called permuta-
tion invariant if for any k ∈N, for any X ∈X k and for any permutation σ ∈Sk, f(σ ·X) = f(X)
holds. When f : S"
MULTISET AND PERMUTATION INVARIANCE,0.04580152671755725,"k∈N X k →Y is permutation invariant, it can be also viewed as a function that
takes multisets as input. For notation simplicity, we sometimes use the same symbol to express the
multiset function: f : NX →Y."
UNIVERSALITY,0.04834605597964377,"2.1.3
UNIVERSALITY"
UNIVERSALITY,0.05089058524173028,"Universality is an important theoretical property of neural networks’ expressive power. Let X and
Y be an input domain and an output domain, respectively. We consider a model M and a class of
target functions F, both of which are sets of functions X →Y. The model M is a sup-universal
approximator of F if for any target function f ∗∈F, for any ϵ > 0, and for any compact subset
K ⊂X, there exists a function f ∈M such that"
UNIVERSALITY,0.05343511450381679,"sup
x∈K
∥f(x) −f ∗(x)∥< ϵ.
(1)"
UNIVERSALITY,0.05597964376590331,"If not noted otherwise, universality refers to the sup-universal property."
BASIC ALGEBRA,0.058524173027989825,"2.1.4
BASIC ALGEBRA"
BASIC ALGEBRA,0.061068702290076333,"Here, we introduce the basic deﬁnition of important algebraic structures in this study. Let G be a
set and ◦: G × G →G be a binary operation. Below, we review four properties to deﬁne Abelian
semigroups and groups."
BASIC ALGEBRA,0.06361323155216285,"Associativity For any x, y, z ∈G, (x ◦y) ◦z = x ◦(y ◦z)."
BASIC ALGEBRA,0.06615776081424936,Under review as a conference paper at ICLR 2022
BASIC ALGEBRA,0.06870229007633588,"Identity Element There exists an element e ∈G, called the identity element, such that for any
x ∈G, x ◦e = e ◦x = x."
BASIC ALGEBRA,0.07124681933842239,"Inverse Element For any x ∈G, there exists an element x−1 ∈G, called the inverse element of x,
such that x ◦x−1 = x−1 ◦x = e."
BASIC ALGEBRA,0.0737913486005089,"Commutativity For any x, y ∈G, x ◦y = y ◦x."
BASIC ALGEBRA,0.07633587786259542,"Table 1 shows which properties are required in each algebraic structure. A semigroup only requires
associativity to the binary operation. A group is a semigroup with an identity element and inverse
elements. An Abelian (semi)group is a (semi)group with commutativity."
BASIC ALGEBRA,0.07888040712468193,Table 1: Properties required for each algebraic structure.
BASIC ALGEBRA,0.08142493638676845,"Associativity
Identity
Inverse
Commutativity
Semigroup
✓
-
-
-
Group
✓
✓
✓
-
Abelian Semigroup
✓
-
-
✓
Abelian Group
✓
✓
✓
✓"
INVERTIBLE NEURAL NETWORKS,0.08396946564885496,"2.2
INVERTIBLE NEURAL NETWORKS"
INVERTIBLE NEURAL NETWORKS,0.08651399491094147,"Invertible neural networks are neural networks that approximate invertible functions Rd →Rd.
Here, we review some existing studies for multi-dimensional case, i.e., d ≥2, and single-
dimensional case, i.e., d = 1."
NORMALIZING FLOWS,0.089058524173028,"2.2.1
NORMALIZING FLOWS"
NORMALIZING FLOWS,0.0916030534351145,"Multi-dimensional invertible neural networks have been studied mainly in the context of normaliz-
ing ﬂows (Tabak & Vanden-Eijnden, 2010), which iteratively apply invertible functions to a sim-
ple original probability distribution to express complex probability distributions (Kobyzev et al.,
2020; Papamakarios et al., 2019). There have been many variants proposed including residual ﬂows
(Behrmann et al., 2019), neural ODEs (Chen et al., 2018), and autoregressive ﬂows (Kingma et al.,
2017). Here we review afﬁne coupling ﬂows (Dinh et al., 2015), one of the most popular mod-
els with parallelizable efﬁcient inverse computation. Each layer of the afﬁne coupling ﬂows maps
x = (x1, . . . , xd) ∈Rd to y = (y1, . . . , yd) ∈Rd such that
(
y≤k = x≤k,"
NORMALIZING FLOWS,0.09414758269720101,"y>k = x>k ⊗exp(α(x≤k)) + β(x≤k),
(2)"
NORMALIZING FLOWS,0.09669211195928754,"where exp is applied elementwise and α, β : Rk →Rd−k are trainable functions. The inverse is
computed as follows:
(
x≤k = y≤k,"
NORMALIZING FLOWS,0.09923664122137404,"x>k = (y>k −β(y≤k)) ⊗exp(−α(y≤k)).
(3)"
NORMALIZING FLOWS,0.10178117048346055,"They are used in many successful applications such as NICE (Dinh et al., 2015), Real NVP (Dinh
et al., 2017), and Glow (Kingma & Dhariwal, 2018)."
NORMALIZING FLOWS,0.10432569974554708,"Although the normalizing ﬂows have a limited form of transform, they still admit universalities
on certain classes of functions (Teshima et al., 2020). The afﬁne coupling ﬂows are Lp-universal
(weaker condition of universality) for C2-diffeomorphisms. Some more complex models, including
deep sigmoidal ﬂows (Huang et al., 2018) and sum-of-squares polynomial ﬂows (Jaini et al., 2019),
are universal for C2-diffeomorphisms."
SINGLE-DIMENSIONAL INVERTIBLE NEURAL NETWORKS,0.10687022900763359,"2.2.2
SINGLE-DIMENSIONAL INVERTIBLE NEURAL NETWORKS"
SINGLE-DIMENSIONAL INVERTIBLE NEURAL NETWORKS,0.10941475826972011,"For single-dimensional functions, invertibility is equivalent to strict monotonicity. Monotonic net-
works (Sill, 1997) model strictly monotonic functions. The monotonically increasing version with"
SINGLE-DIMENSIONAL INVERTIBLE NEURAL NETWORKS,0.11195928753180662,Under review as a conference paper at ICLR 2022
SINGLE-DIMENSIONAL INVERTIBLE NEURAL NETWORKS,0.11450381679389313,K groups and Jk units for k-th group is as follows:
SINGLE-DIMENSIONAL INVERTIBLE NEURAL NETWORKS,0.11704834605597965,"f(x) =
min
1≤k≤K max
1≤j≤Jk exp( ˜w(k,j)) · x + b(k,j),
(4)"
SINGLE-DIMENSIONAL INVERTIBLE NEURAL NETWORKS,0.11959287531806616,"where ˜w(k,j), b(k,j) ∈R are trainable parameters. The monotonic networks are a universal ap-
proximator for strictly monotonic differentiable functions. Monotonic rational-quadratic transforms
(Durkan et al., 2019) are another universal model for the single-dimensional case."
PROPOSED METHODS,0.12213740458015267,"3
PROPOSED METHODS"
PROPOSED METHODS,0.12468193384223919,"Here, we introduce the proposed methods. First, we propose a model for Abelian group operations
and show its universality. Next, we explain how to model analogical relations by our model. Finally,
we present architectures for multiset input and show the size-generalization ability."
ABELIAN GROUP NETWORK,0.1272264631043257,"3.1
ABELIAN GROUP NETWORK"
ABELIAN GROUP NETWORK,0.1297709923664122,"Let X be a Euclidean space, i.e., X = Rd (d ∈N). We present the Abelian group network that
models Abelian group operations as follows:"
ABELIAN GROUP NETWORK,0.13231552162849872,"x ◦y = φ−1(φ(x) + φ(y)),
(5)"
ABELIAN GROUP NETWORK,0.13486005089058525,"where φ: X →X is a trainable invertible function, typically modeled by an invertible neural net-
work."
ABELIAN GROUP NETWORK,0.13740458015267176,"First, we check that this binary operation satisﬁes the four conditions of the Abelian group described
in Section 2.1.4."
ABELIAN GROUP NETWORK,0.13994910941475827,"Proposition 1 (Semigroup Conservation). Let ρ: X
→
X be a bijective function.
When
∗: X × X →X is associative, x ◦y = ρ−1(ρ(x) ∗ρ(y)) is also associative. Similarly, when
∗is commutative, ◦is also commutative."
ABELIAN GROUP NETWORK,0.14249363867684478,Proof. Associativity:
ABELIAN GROUP NETWORK,0.1450381679389313,(x ◦y) ◦z = ρ−1(ρ(ρ−1(ρ(x) ∗ρ(y))) ∗ρ(z))
ABELIAN GROUP NETWORK,0.1475826972010178,= ρ−1((ρ(x) ∗ρ(y)) ∗ρ(z))
ABELIAN GROUP NETWORK,0.15012722646310434,= ρ−1(ρ(x) ∗(ρ(y) ∗ρ(z))) (∵Associativity of ∗)
ABELIAN GROUP NETWORK,0.15267175572519084,= ρ−1(ρ(x) ∗ρ(ρ−1(ρ(y) ∗ρ(z)))) = x ◦(y ◦z). (6)
ABELIAN GROUP NETWORK,0.15521628498727735,Commutativity:
ABELIAN GROUP NETWORK,0.15776081424936386,y ◦x = ρ−1(ρ(y) ∗ρ(x))
ABELIAN GROUP NETWORK,0.16030534351145037,"= ρ−1(ρ(x) ∗ρ(y)) (∵Commutativity of ∗)
= x ◦y. (7)"
ABELIAN GROUP NETWORK,0.1628498727735369,"By this proposition, since + is associative and commutative, the Abelian group network is also
associative and commutative. The identity element is"
ABELIAN GROUP NETWORK,0.16539440203562342,"e = φ−1(0),
(8)"
ABELIAN GROUP NETWORK,0.16793893129770993,which satisﬁes
ABELIAN GROUP NETWORK,0.17048346055979643,x ◦e = x ◦(φ−1(0))
ABELIAN GROUP NETWORK,0.17302798982188294,"= φ−1(φ(x) + 0) = x
(9)"
ABELIAN GROUP NETWORK,0.17557251908396945,for all x ∈X. The inverse element of x ∈X is
ABELIAN GROUP NETWORK,0.178117048346056,"x−1 = φ−1(−φ(x)),
(10)"
ABELIAN GROUP NETWORK,0.1806615776081425,Under review as a conference paper at ICLR 2022
ABELIAN GROUP NETWORK,0.183206106870229,"which satisﬁes
x ◦x−1 = x ◦(φ−1(−φ(x)))"
ABELIAN GROUP NETWORK,0.18575063613231552,= φ−1(φ(x) −φ(x))
ABELIAN GROUP NETWORK,0.18829516539440203,= φ−1(0) = e. (11)
ABELIAN GROUP NETWORK,0.19083969465648856,It is worth noting that we can analytically compute the inverse function (Equation 10).
ABELIAN GROUP NETWORK,0.19338422391857507,"Next, we check the expressive power of the Abelian group network. An Abelian Lie group is an
Abelian group over a manifold in which the group operation (x, y) 7→x ◦y and the inverse function
x 7→x−1 are both differentiable. The following theorem states that the Abelian group network can
approximate any Abelian Lie group operation with arbitrary precision.
Theorem 1 (Universality of Abelian group networks). Let X be a Euclidean space. Abelian group
networks are a universal approximator of Abelian Lie group operations over X. In other words,
for any Abelian Lie group operation ∗: X × X →X, for any ϵ > 0, and for any compact subset
K ⊂X, there exists a binary operation function ◦: X × X →X represented by an Abelian group
network such that
sup
x∈K,y∈K
∥(x ∗y) −(x ◦y)∥< ϵ.
(12)"
ABELIAN GROUP NETWORK,0.19592875318066158,"We provide the proof in Appendix C.1. It is based on the theory of the Abelian Lie group and the
universality of invertible neural networks."
MODELING ANALOGY BY ABELIAN GROUP NETWORK,0.1984732824427481,"3.2
MODELING ANALOGY BY ABELIAN GROUP NETWORK"
MODELING ANALOGY BY ABELIAN GROUP NETWORK,0.2010178117048346,"Now we consider an analogical task of predicting an element d in a relation a : b = c : d. Let
a, b, c, d ∈X be embedded vectors of corresponding elements. We need to deﬁne a model f : X ×
X × X →X that predicts d from a, b, and c. Then, if the set of candidate elements are ﬁnite as
in word embedding, we can search the nearest vector to f(a, b, c). We explained in Section 1 that
several studies heuristically use f(a, b, c) = b −a + c."
MODELING ANALOGY BY ABELIAN GROUP NETWORK,0.2035623409669211,"Analogical relations have two natural laws: when a = b, then c = d holds; a : b = c : d is equivalent
to a : c = b : d. when a = c, then b = d holds. Therefore, we would like to design f to satisfy
the two condition that f(a, b, c) = c when a = b, and f(a, b, c) = f(a, c, b). These conditions
hold in f(a, b, c) = b −a + c. However, when we try to parametrize f by neural networks, it is
not trivial to reﬂect these inductive biases using existing architectures. By using the Abelian group
network, we can model f so that it reﬂects the conditions as follows:"
MODELING ANALOGY BY ABELIAN GROUP NETWORK,0.20610687022900764,"f(a, b, c) = b ◦a−1 ◦c"
MODELING ANALOGY BY ABELIAN GROUP NETWORK,0.20865139949109415,= φ−1(φ(b) + φ(φ−1(−φ(a)))) ◦c.
MODELING ANALOGY BY ABELIAN GROUP NETWORK,0.21119592875318066,= φ−1(φ(b) −φ(a)) ◦c.
MODELING ANALOGY BY ABELIAN GROUP NETWORK,0.21374045801526717,= φ−1(φ(b) −φ(a) + φ(c)). (13)
MODELING ANALOGY BY ABELIAN GROUP NETWORK,0.21628498727735368,"Also, this is strictly more expressive than the simple arithmetic operations because when φ is the
identity, φ(a, b, c) = b −a + c. We can train this model by minimizing the loss: l(f(a, b, c), d),
where l: X →R can typically be an L2 loss or negative cosine similarity."
MULTISET ARCHITECTURE AND SIZE GENERALIZATION,0.21882951653944022,"3.3
MULTISET ARCHITECTURE AND SIZE GENERALIZATION"
MULTISET ARCHITECTURE AND SIZE GENERALIZATION,0.22137404580152673,"Here, we construct a multiset architecture by combining the Abelian group networks and show
it naturally generalizes in sizes. It is easy to check that if ◦: X × X →X is associative and
commutative, f : X k →X deﬁned by"
MULTISET ARCHITECTURE AND SIZE GENERALIZATION,0.22391857506361323,"f(x1, . . . , xk) = x1 ◦x2 ◦· · · ◦xk
(14)"
MULTISET ARCHITECTURE AND SIZE GENERALIZATION,0.22646310432569974,"is permutation invariant. When this condition holds, we represent the multiset version of f : NX →
X as follows by denoting a composition of ◦by ⃝: f(X) = ⃝x∈X x, where X ∈NX is a multiset
of X. By modeling ◦by the Abelian group network, we can construct a multiset architecture of the
Abelian group network:"
MULTISET ARCHITECTURE AND SIZE GENERALIZATION,0.22900763358778625,"f(X) = φ−1
 X"
MULTISET ARCHITECTURE AND SIZE GENERALIZATION,0.23155216284987276,"x∈X
φ(x) !"
MULTISET ARCHITECTURE AND SIZE GENERALIZATION,0.2340966921119593,",
(15)"
MULTISET ARCHITECTURE AND SIZE GENERALIZATION,0.2366412213740458,Under review as a conference paper at ICLR 2022
MULTISET ARCHITECTURE AND SIZE GENERALIZATION,0.23918575063613232,where the invertible function φ: X →X is typically modeled by an invertible neural network.
MULTISET ARCHITECTURE AND SIZE GENERALIZATION,0.24173027989821882,"Now, we consider the size-generalization ability of the multiset architectures. An intuitive explana-
tion is as follows. As an extreme case, even if trained only on multisets of two elements, our models
can learn the correct binary operation. Therefore, they generalize to multisets of larger sizes. In
general, we can derive the following theorem. Appendix C.2 provides the proof.
Theorem 2 (Size Generalization of Abelian Group Networks). Let f ∗: NX →X be a target func-
tion expressed by a composition of Abelian semigroup (X, ◦): f ∗(X) = ⃝
x∈X
x. Let f : NX →X"
MULTISET ARCHITECTURE AND SIZE GENERALIZATION,0.24427480916030533,be a multiset architecture of the Abelian group network: f(X) = φ−1  P
MULTISET ARCHITECTURE AND SIZE GENERALIZATION,0.24681933842239187,"x∈X φ(x)

. When"
MULTISET ARCHITECTURE AND SIZE GENERALIZATION,0.24936386768447838,"∥f(X) −f ∗(X)∥< ϵ
(16)"
MULTISET ARCHITECTURE AND SIZE GENERALIZATION,0.25190839694656486,"holds for any X (∈NX ) whose size is smaller than a (≥2), then"
MULTISET ARCHITECTURE AND SIZE GENERALIZATION,0.2544529262086514,"∥f(X) −f ∗(X)∥< ϵ
 
(aK1K2)⌈loga b⌉−1
"
MULTISET ARCHITECTURE AND SIZE GENERALIZATION,0.25699745547073793,"aK1K2 −1
(17)"
MULTISET ARCHITECTURE AND SIZE GENERALIZATION,0.2595419847328244,"holds for any X (∈NX ) whose size is b (≥a), under the condition that the Lipschitz constants of φ
and φ−1 are K1 and K2, respectively."
MULTISET ARCHITECTURE AND SIZE GENERALIZATION,0.26208651399491095,"A necessary and sufﬁcient condition of f in Equation 14 being permutation invariant is that ◦is
an Abelian semigroup operation. In Appendix A, we provide the proof and propose an Abelian
semigroup network by using the characterization of associative symmetric polynomials."
EXPERIMENTS,0.26463104325699743,"4
EXPERIMENTS"
EXPERIMENTS,0.26717557251908397,"Here, we summarize the main experiment of learning word analogies. In addition to this section, we
provide the experiments of size generalization on learning multiset functions in Appendix B."
COMMON SETTINGS,0.2697201017811705,"4.1
COMMON SETTINGS"
COMMON SETTINGS,0.272264631043257,"We implemented the neural networks in the PyTorch framework (Paszke et al., 2019) and optimized
them using the Adam algorithm (Kingma & Ba, 2015). The hyperparameters for each model in
each problem were tuned with validation datasets using the Bayesian optimization of the Optuna
framework (Akiba et al., 2019). The experiments were run on Intel Xeon E5-2695 v4 with NVIDIA
Tesla P100 GPU. See Appendix D for the detailed settings, such as the model architecture and the
range of hyperparameters."
WORD ANALOGIES,0.2748091603053435,"4.2
WORD ANALOGIES"
WORD ANALOGIES,0.27735368956743,"In Section 1, We discussed the general motivation of training analogical functions over an embed-
ding space. In addition, here, we explain the speciﬁc issue in word2vec (Mikolov et al., 2013a;b)
and justify the motivation of using the Abelian group network. In word2vec, for predicting a word
d in a relation a : b = c : d, the word with the most similar vector to b −a + c (we denote
the corresponding vector for each word by using a bold symbol) is selected in terms of the cosine
similarity:
cos(v1, v2) =
v1 · v2
∥v1∥∥v2∥.
(18)"
WORD ANALOGIES,0.27989821882951654,"Usually, the words a, b, c are excluded from the candidate vocabulary under the assumption that
a common word does not appear in one analogy example. Although this assumption is reason-
able in many cases, it prevents us from solving certain problems such as a past tense verb analogy
“do”:“did” = “split”:“split” or a plural noun analogy “apple”:“apples” = “deer”:“deer”. On the
other hand, if we do not exclude the words a, b, c from the candidates, word2vec suffers from severe
performance degradation e.g., falling from 73.59% to 20.64% in our preliminary experiment on the
Google analogy test set. This is due to the nature of the word2vec algorithm: the result of the simple
arithmetic calculation b −a + c has a high probability of being close to b or c in the cosine similar-
ity, especially in a high dimensional space. We mitigate this issue by learning richer functions than
addition and subtraction. In this experiment, we trained the Abelian group network from a labeled
dataset and compared it with the original word2vec and other learning-based approaches."
WORD ANALOGIES,0.2824427480916031,Under review as a conference paper at ICLR 2022
WORD ANALOGIES,0.28498727735368956,"Word Embedding
We used a 300-dimensional word2vec model for 3 billion words trained on
Google News corpus of about 100 billion words1. We normalized each word embedding by L2"
WORD ANALOGIES,0.2875318066157761,"norm, following the implementation of the Gensim framework ( ˇReh˚uˇrek & Sojka, 2010)."
WORD ANALOGIES,0.2900763358778626,"Word Analogy Models
We compared different models for a word analogy function f : R300 ×
R300×R300 →R300 that takes the vectors of words a, b, c and predicts the vector of a word d. In the
proposed method (WV + AGN), we modeled f by Equation 13. For the invertible neural network
φ : R300 →R300, we implemented a model based on the afﬁne coupling ﬂows described in Section
2.2.1. In addition to the original word2vec (WV): f(a, b, c) = b−a+c, we prepared two trainable
baselines based on a multilayer perceptron (WV + MLP and WV + MLP C, respectively):"
WORD ANALOGIES,0.2926208651399491,"f(a, b, c) = MLP(b −a + c),
(19)
f(a, b, c) = MLPC(CONCAT(a, b, c)),
(20)"
WORD ANALOGIES,0.2951653944020356,where we trained MLP : R300 →R300 or MLPC : R900 →R300.
WORD ANALOGIES,0.29770992366412213,"Setup
Except for WV, we trained f by minimizing the loss function:
lossf(a, b, c, d) =
−cos(f(a, b, c), d) on the training set. We measured the accuracy on the test set by calculating
the most similar vector to the model output for each word:"
WORD ANALOGIES,0.30025445292620867,"arg max
d∈V
cos(f(a, b, c), d),
(21)"
WORD ANALOGIES,0.30279898218829515,"where V is the set of all word embeddings in the word2vec model. For reference, we also tested the
setting where we removed the words a, b, c from the candidates:"
WORD ANALOGIES,0.3053435114503817,"arg max
d∈V\{a,b,c}
cos(f(a, b, c), d).
(22)"
WORD ANALOGIES,0.30788804071246817,"Datasets
We trained our models on the bigger analogy test set (Rogers et al., 2016), which con-
sists of 4 categories, each of which has 10 smaller subcategories of 50 unique relations. First, we
extracted the pairs included in the word2vec vocabularies. Then for each subcategory, randomly
split them into a training set (60%), validation set (20%), and test set (20%). Finally, for each set,
we generated all the combinations of the pairs for each subcategory and concatenated them among
all subcategories. For some relations that contain multiple acceptable candidates, such as mammal
and canine for hypernyms of dog, we used the ﬁrst candidate for training and accepted any for the
test. To check the transferability to another dataset, we also tested our models by the Google analogy
test set (Mikolov et al., 2013a). It includes 19,544 question pairs (8,869 semantic and 10,675 syn-
tactic), and all the words were included in the word2vec vocabulary. Tables 9 and 10 in Appendix
D.2 summarize the explanation and the number of extracted pairs for all subcategories."
WORD ANALOGIES,0.3104325699745547,Table 2: Accuracy on bigger analogy test set when we selected from the whole words.
WORD ANALOGIES,0.31297709923664124,"num
WV
WV + MLP
WV + MLP C
WV + AGN"
WORD ANALOGIES,0.3155216284987277,"Overall
3314
177 (5.34%)
565 (17.05%)
674 (20.34%)
690 (20.82%)
Inﬂectional
900
100 (11.11%)
317 (35.22%)
340 (37.78%)
435 (48.33%)
Derivational
882
4 (0.45%)
15 (1.70%)
40 (4.54%)
20 (2.27%)
Lexicographic
632
52 (8.23%)
154 (24.37%)
202 (31.96%)
172 (27.22%)
Encyclopedic
900
21 (2.33%)
79 (8.78%)
92 (10.22%)
63 (7.00%)"
WORD ANALOGIES,0.31806615776081426,"Results
In Table 2, we summarized the results on the bigger analogy test set when we selected
from the whole vocabulary. In this setting, WV performed extremely poorly. WV + AGN achieved
the best accuracy in overall, while the three trainable models all outperformed WV. Table 3 shows
the accuracy comparison when we excluded a, b, c from the candidates. While the proposed method
outperformed WV again, interestingly, the other learning-based models degraded their performance
compared to the original WV."
WORD ANALOGIES,0.32061068702290074,"We summarized the results on the Google analogy test set in Tables 4 and 5 for each test setting.
Here, MLP-based models signiﬁcantly dropped performance while the proposed model did not."
WORD ANALOGIES,0.3231552162849873,1https://code.google.com/archive/p/word2vec/
WORD ANALOGIES,0.3256997455470738,Under review as a conference paper at ICLR 2022
WORD ANALOGIES,0.3282442748091603,"Table 3: Accuracy on bigger analogy test set when we excluded a, b, c from the candidates."
WORD ANALOGIES,0.33078880407124683,"num
WV
WV + MLP
WV + MLP C
WV + AGN"
WORD ANALOGIES,0.3333333333333333,"Overall
3314
864 (26.07%)
569 (17.17%)
686 (20.70%)
1065 (32.14%)
Inﬂectional
900
614 (68.22%)
324 (36.00%)
369 (41.00%)
656 (72.89%)
Derivational
882
103 (11.68%)
17 (1.93%)
43 (4.88%)
98 (11.11%)
Lexicographic
632
83 (13.13%)
151 (23.89%)
188 (29.75%)
205 (32.44%)
Encyclopedic
900
64 (7.11%)
77 (8.56%)
86 (9.56%)
106 (11.78%)"
WORD ANALOGIES,0.33587786259541985,"Table 4: Accuracy of transfer test to Google analogy test set when we selected from the whole
words."
WORD ANALOGIES,0.3384223918575064,"num
WV
WV + MLP
WV + MLP C
WV + AGN"
WORD ANALOGIES,0.34096692111959287,"Overall
19544
4033 (20.64%)
1346 (6.89%)
2222 (11.37%)
5676 (29.04%)
Semantic
8869
1995 (22.49%)
161 (1.82%)
256 (2.89%)
2260 (25.48%)
Syntactic
10675
2038 (19.09%)
1185 (11.10%)
1966 (18.42%)
3416 (32.00%)"
WORD ANALOGIES,0.3435114503816794,"Only in the setting where we excluded a, b, c from the candidates in the Google analogy test set, the
proposed method did not outperform WV. This is possibly because the word2vec model was highly
tuned for the Google analogy test set for this evaluation method. Indeed, it has been pointed out
that word embedding algorithms are quite dependent on system design choices and hyperparameter
tuning Levy et al. (2015). We show the full results of all subcategories on each dataset in each
evaluation setting in Tables 11, 12, 13, and 14 in Appendix D.2."
WORD ANALOGIES,0.3460559796437659,"Finally, we enumerated the answers of each model for some toy example relations in Table 6. The
ﬁrst four relations are the cases where a = b or a = c. Thanks to the inductive bias incorporated in
the Abelian group network, WV + AGN answered all the questions correctly as well as WV. WV +
AGN also predicted the correct words for the last ﬁve relations, where we need to predict the words
that appeared as c. On the other hand, the MLP-based models failed in most cases, which indicates
that they are not good at the type of examples different from the training dataset."
WORD ANALOGIES,0.3486005089058524,"Overall, while the naive learning approach overﬁtted to the certain dataset and evaluation criteria,
the inductive biases incorporated in the Abelian group network successfully prevented the model
from overﬁtting."
RELATED WORK,0.3511450381679389,"5
RELATED WORK"
ALGEBRAIC STRUCTURES IN NEURAL NETWORKS,0.35368956743002544,"5.1
ALGEBRAIC STRUCTURES IN NEURAL NETWORKS"
ALGEBRAIC STRUCTURES IN NEURAL NETWORKS,0.356234096692112,"In the literature of deep learning, algebraic structures mainly appear in the context of group invari-
ant/equivariant neural networks. For image input, some studies tried to incorporate reﬂection and ro-
tation invariance into convolutional neural networks (Cohen & Welling, 2016; Worrall et al., 2017).
Neural networks for (multi)sets (Zaheer et al., 2017; Qi et al., 2017) adopted invariance/equivariance
to symmetric group actions. Recent studies have investigated symmetries invariant/equivariant to
more general group actions, such as a subgroup of the symmetric group (Maron et al., 2019b) and
sets of symmetric elements (Maron et al., 2020)."
ALGEBRAIC STRUCTURES IN NEURAL NETWORKS,0.35877862595419846,"Our work differs from the above studies since we try to model an Abelian group/semigroup operation
itself."
INDUCTIVE BIAS AND EXPRESSIVE POWER OF NEURAL NETWORKS,0.361323155216285,"5.2
INDUCTIVE BIAS AND EXPRESSIVE POWER OF NEURAL NETWORKS"
INDUCTIVE BIAS AND EXPRESSIVE POWER OF NEURAL NETWORKS,0.3638676844783715,"Inductive biases are assumptions on the nature of the data-generating process or the space of so-
lutions in machine learning (Battaglia et al., 2018). Many studies have constructed special neural
networks that reﬂect the inductive biases of a given problem setting. At the same time, since those
networks are often composed of limited forms of neural operations, expressive power including
universal approximation properties has been studied."
INDUCTIVE BIAS AND EXPRESSIVE POWER OF NEURAL NETWORKS,0.366412213740458,Under review as a conference paper at ICLR 2022
INDUCTIVE BIAS AND EXPRESSIVE POWER OF NEURAL NETWORKS,0.36895674300254455,"Table 5: Accuracy of transfer test to Google analogy test set when we excluded a, b, c from the
candidates."
INDUCTIVE BIAS AND EXPRESSIVE POWER OF NEURAL NETWORKS,0.37150127226463103,"num
WV
WV + MLP
WV + MLP C
WV + AGN"
INDUCTIVE BIAS AND EXPRESSIVE POWER OF NEURAL NETWORKS,0.37404580152671757,"Overall
19544
14382 (73.59%)
1427 (7.30%)
2414 (12.35%)
11857 (60.67%)
Semantic
8869
6482 (73.09%)
163 (1.84%)
256 (2.89%)
4918 (55.45%)
Syntactic
10675
7900 (74.00%)
1264 (11.84%)
2158 (20.22%)
6939 (65.00%)"
INDUCTIVE BIAS AND EXPRESSIVE POWER OF NEURAL NETWORKS,0.37659033078880405,Table 6: Answers of each model for relations that include identical words.
INDUCTIVE BIAS AND EXPRESSIVE POWER OF NEURAL NETWORKS,0.3791348600508906,"WV
WV + MLP
WV + MLP C
WV + AGN"
INDUCTIVE BIAS AND EXPRESSIVE POWER OF NEURAL NETWORKS,0.3816793893129771,"do:do = make:?
make
realize
ensuring
make
apple:apple = pen:?
pen
retractable leash
dustcover
pen
do:did = do:?
did
failed
seemed
did
apple:apples = apple:?
apples
parsley sprig
fruit
apples
do:did = split:?
split
failed
split
split
do:did = set:?
set
decided
established
set
do:did = put:?
put
allowed
Serge Audate
put
apple:apples = deer:?
deer
raptor
fawn
deer
apple:apples = dice:?
dice
ethnic heritages
Proximex C###
dice"
INDUCTIVE BIAS AND EXPRESSIVE POWER OF NEURAL NETWORKS,0.3842239185750636,"Convolutional layers of convolutional neural networks (CNN) (LeCun et al., 1989) are designed
to reﬂect spacial structures in images. CNN without fully connected layers has been shown to be
universal (Zhou, 2018). Invertible neural networks incorporate the inductive bias of being bijec-
tive, which we summarized in Section 2.2. Message passing graph neural networks (Gilmer et al.,
2017) such as graph convolutional networks (Kipf & Welling, 2017) and graph attention networks
(Vaswani et al., 2017) are designed under the assumption that neighboring nodes have similar prop-
erties. They have been shown to have limited expressive power in terms of graph isomorphism (Xu
et al., 2019; Morris et al., 2019) More expressive models have also been studied (Sato et al., 2019;
Maron et al., 2019a; Keriven & Peyr´e, 2019; Maehara & Hoang, 2019). For a (multi)set learning
problem, DeepSets (Zaheer et al., 2017) are one of the most popular models with universal approxi-
mation property."
SIZE GENERALIZATION,0.38676844783715014,"5.3
SIZE GENERALIZATION"
SIZE GENERALIZATION,0.3893129770992366,"Graph neural networks and neural networks for (multi)sets can handle graphs and sets of different
sizes, and their size-generalization ability has been empirically shown in some applications such as
physical systems (Battaglia et al., 2016) and combinatorial optimization (Khalil et al., 2017; Abe
et al., 2019; Veliˇckovi´c et al., 2020). However, from a theoretical perspective, there exist simple
tasks on which graph neural networks do not naturally generalize to larger graphs (Yehudai et al.,
2020). Recent work has analyzed the extrapolation of graph neural networks trained by gradient
descent (Xu et al., 2021). There have been few studies on size generalization of (multi)sets probably
because of difﬁculty in analyzing DeepSets for inputs of different sizes."
CONCLUSION AND FUTURE WORK,0.39185750636132316,"6
CONCLUSION AND FUTURE WORK"
CONCLUSION AND FUTURE WORK,0.3944020356234097,"In this work, we presented a novel neural network architecture to model an Abelian group with
universality. In the experiment of learning word analogies, we conﬁrmed that the inductive bias
of our model that reﬂects analogical structure successfully enhanced the performance. This brings
up the possibility of solving other analogical tasks such as image generation by image analogies
(Hertzmann et al., 2001), which is left as future work. Moreover, as an application other than
analogies, we constructed a permutation invariant architecture (i.e., multiset model) by combining
the Abelian group models, which has the theoretical capability of size generalization. We hope that
our attempt to model algebraic structure by neural networks gives a new insight into the ﬁeld of
machine learning."
CONCLUSION AND FUTURE WORK,0.3969465648854962,Under review as a conference paper at ICLR 2022
REFERENCES,0.3994910941475827,REFERENCES
REFERENCES,0.4020356234096692,"Kenshin Abe, Zijian Xu, Issei Sato, and Masashi Sugiyama. Solving np-hard problems on graphs
with extended alphago zero. arXiv: Learning, 2019."
REFERENCES,0.40458015267175573,"Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama. Optuna: A
next-generation hyperparameter optimization framework. Proceedings of the 25th ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining, 2019."
REFERENCES,0.4071246819338422,"Peter Battaglia, Razvan Pascanu, Matthew Lai, Danilo Jimenez Rezende, and Koray Kavukcuoglu.
Interaction networks for learning about objects, relations and physics. In Proceedings of the 30th
International Conference on Neural Information Processing Systems, 2016."
REFERENCES,0.40966921119592875,"Peter Battaglia, Jessica B. Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi,
Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, C¸ aglar
G¨ulc¸ehre, Francis Song, Andrew Ballard, Justin Gilmer, George Dahl, Ashish Vaswani, Kelsey R.
Allen, Charles Nash, Victoria Langston, Chris Dyer, Nicolas Heess, Daan Wierstra, Pushmeet
Kohli, Matt Botvinick, Oriol Vinyals, Yujia Li, and Razvan Pascanu. Relational inductive biases,
deep learning, and graph networks. ArXiv, abs/1806.01261, 2018."
REFERENCES,0.4122137404580153,"Jens Behrmann, Will Grathwohl, Ricky TQ Chen, David Duvenaud, and J¨orn-Henrik Jacobsen.
Invertible residual networks. In International Conference on Machine Learning, pp. 573–582,
2019."
REFERENCES,0.41475826972010177,"Ricky TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. Neural ordinary dif-
ferential equations. In Proceedings of the 32nd International Conference on Neural Information
Processing Systems, pp. 6572–6583, 2018."
REFERENCES,0.4173027989821883,"Taco Cohen and Max Welling. Group equivariant convolutional networks. In Maria Florina Balcan
and Kilian Q. Weinberger (eds.), Proceedings of The 33rd International Conference on Machine
Learning, volume 48 of Proceedings of Machine Learning Research, pp. 2990–2999, New York,
New York, USA, Jun 2016. PMLR."
REFERENCES,0.4198473282442748,"Laurent Dinh, David Krueger, and Yoshua Bengio. Nice: Non-linear independent components esti-
mation. Workshop of International Conference on Learning Representations, 2015."
REFERENCES,0.4223918575063613,"Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using real nvp. Inter-
national Conference on Learning Representations, 2017."
REFERENCES,0.42493638676844786,"Conor Durkan, Artur Bekasov, Iain Murray, and George Papamakarios. Neural spline ﬂows. In
Conference on Neural Information Processing Systems, 2019."
REFERENCES,0.42748091603053434,"Ben Eisner, Tim Rockt¨aschel, Isabelle Augenstein, Matko Bosnjak, and Sebastian Riedel.
emoji2vec: Learning emoji representations from their description. ArXiv, abs/1609.08359, 2016."
REFERENCES,0.4300254452926209,"J. Gilmer, S. Schoenholz, P. Riley, Oriol Vinyals, and G. Dahl. Neural message passing for quantum
chemistry. In Proceedings of the 34th International Conference on Machine Learning, 2017."
REFERENCES,0.43256997455470736,"Aaron Hertzmann, Charles E. Jacobs, Nuria Oliver, Brian Curless, and D. Salesin. Image analogies.
Proceedings of the 28th annual conference on Computer graphics and interactive techniques,
2001."
REFERENCES,0.4351145038167939,"C. Huang, David Krueger, Alexandre Lacoste, and Aaron C. Courville. Neural autoregressive ﬂows.
In International Conference on Machine Learning, 2018."
REFERENCES,0.43765903307888043,"Priyank Jaini, Kira A. Selby, and Yaoliang Yu. Sum-of-squares polynomial ﬂow. In Kamalika
Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of the 36th International Conference on
Machine Learning, volume 97 of Proceedings of Machine Learning Research, pp. 3009–3018.
PMLR, 09–15 Jun 2019."
REFERENCES,0.4402035623409669,"N. Keriven and G. Peyr´e. Universal invariant and equivariant graph neural networks. In Advances
in Neural Information Processing Systems 32, 2019."
REFERENCES,0.44274809160305345,Under review as a conference paper at ICLR 2022
REFERENCES,0.44529262086513993,"Elias Boutros Khalil, Hanjun Dai, Yuyu Zhang, B. Dilkina, and L. Song. Learning combinatorial
optimization algorithms over graphs. In Conference on Neural Information Processing Systems,
2017."
REFERENCES,0.44783715012722647,"Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International
Conference on Learning Representations, 2015."
REFERENCES,0.45038167938931295,"Diederik P. Kingma and Prafulla Dhariwal. Glow: Generative ﬂow with invertible 1x1 convolutions.
Conference in Neural Information Processing Systems, 2018."
REFERENCES,0.4529262086513995,"Diederik P. Kingma, Tim Salimans, and M. Welling. Improved variational inference with inverse
autoregressive ﬂow. In Advances in Neural Information Processing Systems, 2017."
REFERENCES,0.455470737913486,"Thomas Kipf and M. Welling. Semi-supervised classiﬁcation with graph convolutional networks.
In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April
24-26, 2017, Conference Track Proceedings, 2017."
REFERENCES,0.4580152671755725,"Ryan Kiros, Ruslan Salakhutdinov, and Richard S. Zemel. Unifying visual-semantic embeddings
with multimodal neural language models. ArXiv, abs/1411.2539, 2014."
REFERENCES,0.46055979643765904,"I. Kobyzev, S. Prince, and M. Brubaker. Normalizing ﬂows: An introduction and review of current
methods. IEEE transactions on pattern analysis and machine intelligence, 2020."
REFERENCES,0.4631043256997455,"Y. LeCun, B. Boser, J. Denker, D. Henderson, R. Howard, W. Hubbard, and L. Jackel. Backpropa-
gation applied to handwritten zip code recognition. Neural Computation, 1:541–551, 1989."
REFERENCES,0.46564885496183206,"Omer Levy, Yoav Goldberg, and Ido Dagan. Improving distributional similarity with lessons learned
from word embeddings. Transactions of the Association for Computational Linguistics, 2015."
REFERENCES,0.4681933842239186,"T. Maehara and NT Hoang. A simple proof of the universality of invariant/equivariant graph neural
networks. ArXiv, 2019."
REFERENCES,0.4707379134860051,"Haggai Maron, Ethan Fetaya, Nimrod Segol, and Y. Lipman. On the universality of invariant net-
works. In Proceedings of the 36th International Conference on Machine Learning, 2019a."
REFERENCES,0.4732824427480916,"Haggai Maron, Ethan Fetaya, Nimrod Segol, and Yaron Lipman. On the universality of invariant
networks. In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of the 36th
International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning
Research, pp. 4363–4371. PMLR, 09–15 Jun 2019b."
REFERENCES,0.4758269720101781,"Haggai Maron, Or Litany, Gal Chechik, and Ethan Fetaya. On learning sets of symmetric elements.
In Hal Daum´e III and Aarti Singh (eds.), Proceedings of the 37th International Conference on
Machine Learning, volume 119 of Proceedings of Machine Learning Research, pp. 6734–6744.
PMLR, 13–18 Jul 2020."
REFERENCES,0.47837150127226463,"Tomas Mikolov, Kai Chen, G. S. Corrado, and J. Dean. Efﬁcient estimation of word representations
in vector space. In Workshop of International Conference on Learning Representations, 2013a."
REFERENCES,0.48091603053435117,"Tomas Mikolov, Ilya Sutskever, Kai Chen, G. S. Corrado, and J. Dean. Distributed representations
of words and phrases and their compositionality. Conference on Neural Information Processing
Systems, 2013b."
REFERENCES,0.48346055979643765,"Andriy Mnih and Koray Kavukcuoglu. Learning word embeddings efﬁciently with noise-contrastive
estimation. In NIPS, 2013."
REFERENCES,0.4860050890585242,"C. Morris, Martin Ritzert, M. Fey, William L. Hamilton, J. E. Lenssen, Gaurav Rattan, and
M. Grohe. Weisfeiler and leman go neural: Higher-order graph neural networks. In Conference
on Artiﬁcial Intelligence, 2019."
REFERENCES,0.48854961832061067,"George Papamakarios, Eric T. Nalisnick, Danilo Jimenez Rezende, Shakir Mohamed, and Bal-
aji Lakshminarayanan.
Normalizing ﬂows for probabilistic modeling and inference.
ArXiv,
abs/1912.02762, 2019."
REFERENCES,0.4910941475826972,Under review as a conference paper at ICLR 2022
REFERENCES,0.49363867684478374,"Adam Paszke, S. Gross, Francisco Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin,
N. Gimelshein, L. Antiga, Alban Desmaison, Andreas K¨opf, E. Yang, Zach DeVito, Martin Rai-
son, Alykhan Tejani, Sasank Chilamkurthy, B. Steiner, Lu Fang, Junjie Bai, and Soumith Chin-
tala. Pytorch: An imperative style, high-performance deep learning library. In Advances in Neural
Information Processing Systems 32, 2019."
REFERENCES,0.4961832061068702,"Jeffrey Pennington, R. Socher, and Christopher D. Manning. Glove: Global vectors for word repre-
sentation. In Conference on Empirical Methods in Natural Language Processing, 2014."
REFERENCES,0.49872773536895676,"Claudio Procesi. Lie groups. an approach through invariants and representations. Bull. Amer. Math.
Soc, 2007."
REFERENCES,0.5012722646310432,"C. R. Qi, H. Su, Kaichun Mo, and L. Guibas. Pointnet: Deep learning on point sets for 3d classi-
ﬁcation and segmentation. 2017 IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), pp. 77–85, 2017."
REFERENCES,0.5038167938931297,"Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep
convolutional generative adversarial networks. CoRR, abs/1511.06434, 2016."
REFERENCES,0.5063613231552163,"Radim ˇReh˚uˇrek and Petr Sojka. Software Framework for Topic Modelling with Large Corpora. In
Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks, pp. 45–50,
Valletta, Malta, May 2010. ELRA."
REFERENCES,0.5089058524173028,"Anna Rogers, Aleksandr Drozd, and S. Matsuoka. Analogy-based detection of morphological and
semantic relations with word embeddings: what works and what doesn’t. In SRW@HLT-NAACL,
2016."
REFERENCES,0.5114503816793893,"R. Sato, M. Yamada, and H. Kashima. Approximation ratios of graph neural networks for combina-
torial problems. In Advances in Neural Information Processing Systems 32: Annual Conference
on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancou-
ver, BC, Canada, 2019."
REFERENCES,0.5139949109414759,"J. Sill. Monotonic networks. In Conference on Neural Information Processing Systems, 1997."
REFERENCES,0.5165394402035624,"E. Tabak and E. Vanden-Eijnden. Density estimation by dual ascent of the log-likelihood. Commu-
nications in Mathematical Sciences, 8:217–233, 2010."
REFERENCES,0.5190839694656488,"Takeshi Teshima, I. Ishikawa, Koichi Tojo, Kenta Oono, M. Ikeda, and M. Sugiyama. Coupling-
based invertible neural networks are universal diffeomorphism approximators. Conference on
Neural Information Processing Systems, 2020."
REFERENCES,0.5216284987277354,"Paul Upchurch, Jacob V. Gardner, Geoff Pleiss, Kavita Bala, Robert Pless, Noah Snavely, and Kil-
ian Q. Weinberger. Deep feature interpolation for image content changes. 2017 IEEE Conference
on Computer Vision and Pattern Recognition (CVPR), pp. 6090–6099, 2017."
REFERENCES,0.5241730279898219,"Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez,
L. Kaiser, and Illia Polosukhin. Attention is all you need. In Conference on Neural Informa-
tion Processing Systems, 2017."
REFERENCES,0.5267175572519084,"Petar Veliˇckovi´c, Rex Ying, Matilde Padovano, Raia Hadsell, and Charles Blundell. Neural execu-
tion of graph algorithms. In International Conference on Learning Representations, 2020."
REFERENCES,0.5292620865139949,"Daniel E. Worrall, Stephan J. Garbin, Daniyar Turmukhambetov, and Gabriel J. Brostow. Harmonic
networks: Deep translation and rotation equivariance. In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition (CVPR), July 2017."
REFERENCES,0.5318066157760815,"Keyulu Xu, Weihua Hu, J. Leskovec, and S. Jegelka. How powerful are graph neural networks? In
7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA,
May 6-9, 2019, 2019."
REFERENCES,0.5343511450381679,"Keyulu Xu, Mozhi Zhang, Jingling Li, Simon Shaolei Du, Ken-Ichi Kawarabayashi, and Stefanie
Jegelka.
How neural networks extrapolate: From feedforward to graph neural networks.
In
International Conference on Learning Representations, 2021."
REFERENCES,0.5368956743002544,Under review as a conference paper at ICLR 2022
REFERENCES,0.539440203562341,"Gilad Yehudai, Ethan Fetaya, E. Meirom, Gal Chechik, and Haggai Maron. On size generalization
in graph neural networks. ArXiv, abs/2010.08853, 2020."
REFERENCES,0.5419847328244275,"Reikichi Yoshida. On some semi-groups. Bulletin of the American Mathematical Society, 69(3):
369–371, 1963."
REFERENCES,0.544529262086514,"M. Zaheer, S. Kottur, Siamak Ravanbakhsh, B. P´oczos, R. Salakhutdinov, and Alex Smola. Deep
sets. Conference on Neural Information Processing Systems, 2017."
REFERENCES,0.5470737913486005,"Ding-Xuan Zhou. Universality of deep convolutional neural networks. ArXiv, abs/1805.10769,
2018."
REFERENCES,0.549618320610687,Under review as a conference paper at ICLR 2022
REFERENCES,0.5521628498727735,"A
ABELIAN SEMIGROUP NETWORK"
REFERENCES,0.55470737913486,"A.1
MOTIVATION"
REFERENCES,0.5572519083969466,"Below, we present a necessary and sufﬁcient condition for multiset functions that are represented by
the composition of binary operations to be well-deﬁned.
Proposition 2 (Permutation Invariant Conditions for Binary Operation). Let f : S"
REFERENCES,0.5597964376590331,"k∈N X k →X be
a function represented as
f(X) = x1 ◦· · · ◦xn,
(23)
where X = (x1, . . . , xn) ∈X n and ◦: X × X →X is a binary operation (left-associative). The
function f is invariant if and only if ◦forms an Abelian semigroup, namely, ◦is commutative and
associative."
REFERENCES,0.5623409669211196,"Proof. It is obvious that when ◦is commutative and associative, f is permutation invariant. Let us
consider the case when f is permutation invariant. f((x1, x2)) = f((x2, x1)) leads to x1 ◦x2 =
x2 ◦x1 (commutativity). From f((x1, x2, x3)) = f((x2, x3, x1)), we have (x1 ◦x2) ◦x3 =
(x2 ◦x3) ◦x1 and commutativity leads to (x1 ◦x2) ◦x3 = x1 ◦(x2 ◦x3) (associativity)."
REFERENCES,0.5648854961832062,"On the basis of this proposition, our goal decomposes into learning Abelian semigroup operations
over X. In Section A.2, we propose neural network architectures for Abelian semigroups."
REFERENCES,0.5674300254452926,"A.2
ARCHITECTURE"
REFERENCES,0.5699745547073791,"Although the Abelian group network proposed in Section 3.1 is universal for smooth group opera-
tions, it is not sufﬁcient for approximating an Abelian semigroup operation such as the product over
R, i.e., x ◦y = xy. Now we extend the Abelian group network and propose the Abelian semigroup
network. Our idea is to extend + of Equation 5 to a polynomial. From Proposition 1, Equation 5 is
still a semigroup after we replace + by a polynomial of x and y as long as the polynomial is asso-
ciative and symmetric as a binary operation. We call the polynomials with this property associative
symmetric polynomials, which are characterized by the following theorem. Since the original paper
only gives a brief explanation, we give detailed proof in Appendix C.3.
Theorem 3 (Characterization of Associative Symmetric Polynomials, Commutative Case of
(Yoshida, 1963)). An associative symmetric polynomial of x and y is one of the following three
forms:"
REFERENCES,0.5725190839694656,"x ∗y = 

 
"
REFERENCES,0.5750636132315522,"α
α + x + y
β(β−1)"
REFERENCES,0.5776081424936387,"γ
+ β(x + y) + γxy
(γ ̸= 0),
(24)"
REFERENCES,0.5801526717557252,"where α, β, γ are coefﬁcients."
REFERENCES,0.5826972010178118,"By applying this theorem to Proposition 1 for X with elementwise product and division, we obtain
the following three kinds of Abelian semigroup operations:"
REFERENCES,0.5852417302798982,"x ◦y = 

 
"
REFERENCES,0.5877862595419847,"ρ−1(α)
(25)"
REFERENCES,0.5903307888040712,"ρ−1 (ρ(x) + ρ(y) + α)
(26)"
REFERENCES,0.5928753180661578,"ρ−1(β ⊗(β −1) ⊘γ + β ⊗(ρ(x) + ρ(y)) + γ ⊗ρ(x) ⊗ρ(y)),
(27)
where ρ : X →X is an invertible function and α, β, γ ∈X are parameters (γ is nonzero for all
elements in Equation 27). Equation 25 is a constant case, on which we do not put a focus due to
its trivialness. Equation 26 forms a group where e = ρ−1(−α), x−1 = ρ−1(−ρ(x) −2α). It can
be expressed by the Abelian group network with φ(x) = ρ(x) + α and φ−1(x) = ρ−1(x −α)
in Equation 5. Equation 27 is a semigroup but not a group. Just using this equation is ﬁne, but we
propose a simpler form, as the Abelian semigroup network:
x ◦y = φ−1(φ(x) ⊗φ(y)),
(28)
where φ : X →X is a trainable invertible function typically modeled by an invertible neural
network. This is a special case of Equation 27 when β = 0, γ = 1 and therefore is a semigroup.
Conversely, the Abelian semigroup network can express Equation 27 by
φ(x) = γ ⊗ρ(x) + β, φ−1(x) = ρ−1((x −β) ⊘γ).
(29)"
REFERENCES,0.5954198473282443,Under review as a conference paper at ICLR 2022
REFERENCES,0.5979643765903307,"Moreover,
the Abelian semigroup network can approximate the Abelian group network:
φ′−1(φ′(x) + φ′(y)). Let X>0 = Rd
>0, where X = Rd. One construction is approximating a
bijective function π : X →X>0,"
REFERENCES,0.6005089058524173,"π(x) = exp(φ′(x)), π−1(x) = φ′−1(log(x))
(30)"
REFERENCES,0.6030534351145038,"by φ, where exp and log act elementwise. This is possible in any compact subset of X. From
the previous discussions so far, the Abelian semigroup network can approximate any binary oper-
ation which is homeomorphic to an associative symmetric polynomial. We conﬁrm this fact in the
experiments."
REFERENCES,0.6055979643765903,"By calculating Equation 14, we can write the model for multiset input X = {x1, . . . xn} ∈X in a
simple form:
f(X) = φ−1(φ(x1) ⊗· · · ⊗φ(xn)),
(31)"
REFERENCES,0.6081424936386769,where the invertible function φ : X →X is typically modeled by an invertible neural network.
REFERENCES,0.6106870229007634,"For the Abelian semigroup network, the error bound for small multiset propagates in the form of
the product with the values φ(xi), which prevents us from inducing the bound like Theorem 2.
However, it still has the size-generalization ability in most real applications where the values are not
too large. We conﬁrm this by an experiment in Section B."
REFERENCES,0.6132315521628499,"B
EXPERIMENTS OF SIZE GENERALIZATION"
REFERENCES,0.6157760814249363,"To check the size generalization over semigroup and group operations on multisets, we trained
the models on synthetic data. The binary operation forms of the examined functions are x ◦y =
x + y, x + y + 1,
3p"
REFERENCES,0.6183206106870229,"x3 + y3 (group cases) and x ◦y = xy, x + y + xy"
REFERENCES,0.6208651399491094,2 (semigroup cases).
REFERENCES,0.6234096692111959,"Setup
For the single-dimensional invertible neural network of the Abelian group network and
Abelian semigroup network, we used monotonic networks (Sill, 1997). We tuned the hyperparame-
ters, the number of groups and the number of units for each group. As a baseline, we used DeepSets
(Zaheer et al., 2017), one of the most popular models for (multi)set learning. It incorporates two
multilayer perceptrons (MLP). We used the same number of hidden layers for the two MLPs and
tuned the hyperparameters, the number of layers in each MLP, the middle dimension, and the hidden
dimension. Each model was trained to minimize the mean squared error on a training set."
REFERENCES,0.6259541984732825,"Data Generation
As training data, we generated 500 multisets of size {2, 3, 4} (chosen uni-
formly random). All the elements were single-dimensional and selected uniformly at random from
[−5.0, 5.0]. A validation data of 100 multisets were generated from the same distribution. We pre-
pared two kinds of test data. One consisted of 100 multisets drawn from the same distribution as the
training and validation data, which we refer to by small. To see the size-generalization ability, the
other consisted of 100 multisets of size {10, 11, 12} (chosen uniformly at random) with the same
element distribution, which we refer to by large."
REFERENCES,0.628498727735369,"Results
Table 7 summarizes the results. For the group functions, all models including the Abelian
semigroup network performed well. This is consistent with the fact that group operations can be ap-
proximated by the Abelian semigroup network, as discussed in Section A. While the Abelian group
network was better on the other two cases, DeepSets outperformed the Abelian group network on
3p"
REFERENCES,0.6310432569974554,"x3 + y3. This is possibly due to the optimization of MLPs in DeepSets being easier than mono-
tonic networks in the Abelian group network and Abelian semigroup network. Invertible neural
networks for the single-dimensional case that are easy to optimize are important for future work.
For the semigroup operations, as well as DeepSets, the Abelian group network did not work well.
This is reasonable because these semigroup operations can not be expressed by the Abelian group
network."
REFERENCES,0.6335877862595419,"On the size generalization, although DeepSets worked fairly well, our models worked better. For
example, the Abelian semigroup network was better than DeepSets on large of x + y despite being
worse on small; The Abelian group network had similar results on xy and x + y + xy 2 ."
REFERENCES,0.6361323155216285,Under review as a conference paper at ICLR 2022
REFERENCES,0.638676844783715,"Table 7: Mean squared error comparison between the models for each function. The upper three
operations are groups and the lower two equations are semigroups. Square root of the values are
presented. Smaller is better."
REFERENCES,0.6412213740458015,"x ◦y
DeepSets
AGN
ASN"
REFERENCES,0.6437659033078881,"x + y
small
0.00226
3.63e-7
0.0832
large
0.908
0.0366
0.309
x + y + 1
small
0.00772
4.17e-7
0.136
large
0.0335
0.0132
0.956
3p"
REFERENCES,0.6463104325699746,"x3 + y3
small
0.0844
0.284
0.427
large
0.229
0.636
1.26
xy
small
13.0
36.7
0.00000295
large
28500
28390
31.5
x + y + xy"
SMALL,0.648854961832061,"2
small
0.965
7.08
0.000660
large
194
193
1.22"
SMALL,0.6513994910941476,"C
PROOFS"
SMALL,0.6539440203562341,"C.1
PROOF OF THEOREM 1"
SMALL,0.6564885496183206,"First, we review a theorem of the Abelian Lie group, which is important in our proof. The real
numbers R with the addition + forms a Lie group, which we denote by (R, +). Also, the torus
T = R/2πZ with the addition + modulo 2πZ forms a Lie group, which we denote by (T, +). It is
known that any connected Abelian Lie group is isomorphic to (R, +)k × (T, +)h for some k, h ∈N
(Section 4.4.2 of (Procesi, 2007))."
SMALL,0.6590330788804071,"Now, we give the proof of Theorem 1."
SMALL,0.6615776081424937,"Proof. We use the fact that any connected Abelian Lie group is isomorphic to (R, +)k × (T, +)h
for some k, h ∈N. Since there is no homeomorphic function R (which is not compact) to T (which
is compact), Abelian Lie groups over a Euclidean space has the form of only (R, +)k. Therefore,
any ∗can be represented as
x ∗y = π−1(π(x) + π(y)),
(32)"
SMALL,0.6641221374045801,"where π : X →X is a homeomorphic function in terms of Lie groups, i.e., π(·) and π−1(·) are
analytic. Take any ϵ > 0 and a compact subset K ⊂X. We denote the image of K × K through the
function (x, y) 7→π(x) + π(y) by S′ = {π(x) + π(y) | x, y ∈K}. Let"
SMALL,0.6666666666666666,"S = {s | ∃s′ ∈S′ s.t. ∥s −s′∥≤2ϵ}
(33)"
SMALL,0.6692111959287532,"and
K′ = K ∪π−1(S).
(34)"
SMALL,0.6717557251908397,"Then, we have a Lipschitz constant L > 0 of π−1 over S since π−1 is continuous and S is compact.
Also, from the universality of invertible neural networks (Teshima et al., 2020) for the compact set
K′, there exists an invertible neural network φ : X →X such that for any x ∈K′"
SMALL,0.6743002544529262,"∥π(x) −φ(x)∥<
ϵ
2L + 1
(35)"
SMALL,0.6768447837150128,and for any x′ ∈π(K′)
SMALL,0.6793893129770993,"∥π−1(x′) −φ−1(x′)∥<
ϵ
2L + 1.
(36)"
SMALL,0.6819338422391857,"Then, for any x, y ∈K, φ(x) + φ(y) ∈S(⊂π(K′)) because"
SMALL,0.6844783715012722,∥(π(x) + π(y)) −(φ(x) + φ(y))∥≤∥π(x) −φ(x)∥+ ∥π(y) + φ(y)∥
SMALL,0.6870229007633588,"<
2ϵ
2L + 1
< 2ϵ. (37)"
SMALL,0.6895674300254453,Under review as a conference paper at ICLR 2022
SMALL,0.6921119592875318,"Therefore, for any x, y ∈X, we have from the Lipshitz continuity of π−1"
SMALL,0.6946564885496184,∥π−1(π(x) + π(y)) −π−1(φ(x) + φ(y))∥≤L∥(π(x) + π(y)) −(φ(x) + φ(y))∥
SMALL,0.6972010178117048,"< L ·
2ϵ
2L + 1"
SMALL,0.6997455470737913,"=
2Lϵ
2L + 1 (38)"
SMALL,0.7022900763358778,and from Equation 36
SMALL,0.7048346055979644,"∥π−1(φ(x) + φ(y)) −φ−1(φ(x) + φ(y))∥<
ϵ
2L + 1.
(39)"
SMALL,0.7073791348600509,"From Equation 38 and 39, for any x, y ∈K, we obtain"
SMALL,0.7099236641221374,∥(x ∗y) −(x ◦y)∥= ∥π−1(π(x) + π(y)) −φ−1(φ(x) + φ(y))∥
SMALL,0.712468193384224,≤∥π−1(π(x) + π(y)) −π−1(φ(x) + φ(y))∥
SMALL,0.7150127226463104,+ ∥π−1(φ(x) + φ(y)) −φ−1(φ(x) + φ(y))∥
SMALL,0.7175572519083969,"≤
2Lϵ
2L + 1 +
ϵ
2L + 1
= ϵ. (40)"
SMALL,0.7201017811704835,This concludes that Abelian group networks are universal.
SMALL,0.72264631043257,"C.2
PROOF OF THEOREM 2"
SMALL,0.7251908396946565,"Proof. We prove that for any X ∈NX of size smaller than b ≥a,"
SMALL,0.727735368956743,"∥f(X) −f ∗(X)∥< ϵ
 
(aK1K2)⌈loga b⌉−1
"
SMALL,0.7302798982188295,"aK1K2 −1
(41)"
SMALL,0.732824427480916,"by induction on size b. Note that K1K2 > 1 because they are the Lipschitz constants of inverse
functions."
SMALL,0.7353689567430025,"Base Case
When b = a, Inequality 41 holds."
SMALL,0.7379134860050891,"Inductive Step
We assume Inequality 41 holds for size b′ = 1, . . . , b −1. We divide X of size b
into balanced a subsets X1, . . . , Xa so that X = X1+· · · Xa and each |Xi| ≤⌈b"
SMALL,0.7404580152671756,"a⌉(Addition over
multisets is deﬁned as follows: {x1, . . . , xn} + {xn+1, . . . , xN} = {x1, . . . , xn, xn+1, . . . , xN})."
SMALL,0.7430025445292621,"Under review as a conference paper at ICLR 2022 Then,"
SMALL,0.7455470737913485,∥f(X) −f ∗(X)∥=
SMALL,0.7480916030534351,"φ−1
 X"
SMALL,0.7506361323155216,"x∈X
φ(x) !"
SMALL,0.7531806615776081,"−⃝
x∈X
x  ="
SMALL,0.7557251908396947,"φ−1
 a
X i=1 X"
SMALL,0.7582697201017812,"x∈Xi
φ(x) !"
SMALL,0.7608142493638677,"−
a
⃝
i=1"
SMALL,0.7633587786259542,"
⃝
x∈Xi
x
 ="
SMALL,0.7659033078880407,"φ−1
 a
X"
SMALL,0.7684478371501272,"i=1
φ(f(Xi)) !"
SMALL,0.7709923664122137,"−f ∗({f ∗(X1), . . . , f ∗(Xa)})  ≤"
SMALL,0.7735368956743003,"φ−1
 a
X"
SMALL,0.7760814249363868,"i=1
φ(f(Xi)) !"
SMALL,0.7786259541984732,"−φ−1
 a
X"
SMALL,0.7811704834605598,"i=1
φ(f ∗(Xi))"
SMALL,0.7837150127226463,"! +"
SMALL,0.7862595419847328,"φ−1
 a
X"
SMALL,0.7888040712468194,"i=1
φ(f ∗(Xi)) !"
SMALL,0.7913486005089059,"−f ∗({f ∗(X1), . . . , f ∗(Xa)})  ≤K2  a
X"
SMALL,0.7938931297709924,"i=1
φ(f(Xi)) −φ(f ∗(Xi)) +"
SMALL,0.7964376590330788,"∥f ({f ∗(X1), . . . , f ∗(Xa)}) −f ∗({f ∗(X1), . . . , f ∗(Xa)})∥ < K2 a
X"
SMALL,0.7989821882951654,"i=1
∥φ(f(Xi)) −φ(f ∗(Xi))∥ ! + ϵ ≤K2 a
X"
SMALL,0.8015267175572519,"i=1
K1 ∥f(Xi) −f ∗(Xi)∥ ! + ϵ"
SMALL,0.8040712468193384,"= K1K2 a
X"
SMALL,0.806615776081425,"i=1
∥f(Xi) −f ∗(Xi)∥ ! + ϵ. (42)"
SMALL,0.8091603053435115,From the assumption on size ⌈b
SMALL,0.811704834605598,"a⌉, we obtain"
SMALL,0.8142493638676844,∥f(X) −f ∗(X)∥< aK1K2 · ϵ((aK1K2)⌈loga⌈b
SMALL,0.816793893129771,"a ⌉⌉−1)
aK1K2 −1
+ ϵ"
SMALL,0.8193384223918575,"< aK1K2 · ϵ((aK1K2)⌈loga
b
a ⌉−1)
aK1K2 −1
+ ϵ"
SMALL,0.821882951653944,"< ϵ
 
(aK1K2)⌈loga b⌉−1
"
SMALL,0.8244274809160306,"aK1K2 −1
, (43)"
SMALL,0.8269720101781171,which establishes the inductive step.
SMALL,0.8295165394402035,"C.3
PROOF OF THEOREM 3"
SMALL,0.8320610687022901,"Proof. First, we prove that associative polynomials are at most ﬁrst-order for each variable. Assume
that we have a n-order (n ≥2) associative polynomial"
SMALL,0.8346055979643766,"x ∗y = n
X i=0 n
X"
SMALL,0.8371501272264631,"j=0
αi,jxiyj,
(44)"
SMALL,0.8396946564885496,"where αi,j ∈R for 0 ≤i, j ≤n. Then, we have"
SMALL,0.8422391857506362,"(x ∗y) ∗z = n
X i=0 n
X"
SMALL,0.8447837150127226,"j=0
αi,j( n
X k=0 n
X"
SMALL,0.8473282442748091,"l=0
αk,lxkyl)izj
(45) and"
SMALL,0.8498727735368957,"x ∗(y ∗z) = n
X i=0 n
X"
SMALL,0.8524173027989822,"j=0
αi,jxi( n
X k=0 n
X"
SMALL,0.8549618320610687,"l=0
αk,lykzl)i.
(46)"
SMALL,0.8575063613231552,Under review as a conference paper at ICLR 2022
SMALL,0.8600508905852418,"Since ∗is associative, these two must form an identity. By comparing a coefﬁcient of xn2, we obtain n
X"
SMALL,0.8625954198473282,"j=0
αn,j( n
X"
SMALL,0.8651399491094147,"l=0
αn,lyl)nzj = 0.
(47)"
SMALL,0.8676844783715013,"If we have 0 ≤j′ ≤n such that αn,j′ ̸= 0, from the coefﬁcient of zj′, ( n
X"
SMALL,0.8702290076335878,"l=0
αn,lyl)n = 0.
(48)"
SMALL,0.8727735368956743,"Recursively, we get αn,0 = αn,1 = · · · = αn,n = 0, which leads to contradiction. Therefore, we
now have
αn,0 = αn,1 = · · · = αn,n = 0.
(49)"
SMALL,0.8753180661577609,"In the same way, we can also prove"
SMALL,0.8778625954198473,"α0,n = α1,n = · · · = αn,n = 0.
(50)"
SMALL,0.8804071246819338,"From Equation 49 and 50 for n ≥2, now we know that associative polynomials are at most ﬁrst-
order for each variable. Therefore, symmetric associative polynomials have the form:"
SMALL,0.8829516539440203,"x ∗y = α + β(x + y) + γxy.
(51)"
SMALL,0.8854961832061069,Then we have
SMALL,0.8880407124681934,"(x ∗y) ∗z = α + β((α + β(x + y) + γxy) + z) + γ(α + β(x + y) + γxy)z
(52)"
SMALL,0.8905852417302799,"and
x ∗(y ∗z) = α + β((α + β(x + y) + γxy) + z) + γ(α + β(x + y) + γxy)z.
(53)"
SMALL,0.8931297709923665,"By solving this identity, we obtain
αγ = β(β −1).
(54)"
SMALL,0.8956743002544529,"This condition is equivalent to the associativity of ∗. It decomposes into three cases: (γ = 0, β = 0),
(γ = 0, β = 1), and γ ̸= 0. For each case, we obtain"
SMALL,0.8982188295165394,"x ∗y = 

 
"
SMALL,0.9007633587786259,"α
α + x + y
β(β−1)"
SMALL,0.9033078880407125,"γ
+ β(x + y) + γxy
(γ ̸= 0).
(55)"
SMALL,0.905852417302799,"D
EXPERIMENTAL DETAILS"
SMALL,0.9083969465648855,"Here, we explain the detailed setting and further discussion of the experiments that we did not cover
in the main part."
SMALL,0.910941475826972,"D.1
EXPERIMENTS OF SIZE GENERALIZATION"
SMALL,0.9134860050890585,"Model Architecture
For the implementation of the monotonic networks, we followed the Equa-
tion 4, except that we added a coefﬁcient term s ∈R which automatically learn the sign of the
weights:
f(x) =
min
1≤k≤K max
1≤j≤Jk s · exp( ˜w(k,j)) · x + b(k,j).
(56)"
SMALL,0.916030534351145,"Hyperparameters
All networks were trained by the Adam algorithm of lr = 10−3, beta =
(0.9, 0.999) for 1000 epochs with the batch size of 32. Hyperparameters of each model were tuned
with the validation dataset using the Optuna framework for each function. For DeepSets, the number
of layers for each MLP was selected from [2, 8] and the middle dimension and hidden dimension
were selected from [2, 32]. For the Abelian group network and Abelian semigroup network, the
number of groups and the number of units in each group were selected from [2, 32]."
SMALL,0.9185750636132316,Under review as a conference paper at ICLR 2022
SMALL,0.9211195928753181,"D.2
WORD ANALOGIES"
SMALL,0.9236641221374046,"Model architecture
For the invertible neural network for the Abelian group network and Abelian
semigroup network, we implemented a model based on the afﬁne coupling ﬂows using the FrEIA
framework 2. We stacked Glow coupling layers and random permutation layers of the dimensions
in turn. For each Glow coupling layer, we used three layer feedforward neural networks with a
hyperparameter of hidden dim as a sub network. For MLP and MLP C, we implemented multilayer
perceptrons with the ReLU activation function."
SMALL,0.926208651399491,"Hyperparameters
All networks were trained by the Adam algorithm of lr = 10−3, beta =
(0.9, 0.999) for 100 epochs with the batch size of 32. The hyperparameters of each model were
tuned with the validation dataset using the Optuna framework. For MLP, the number of layers was
selected from [2, 6] and the hidden dimension was selected from [8, 256]. For the Abelian group
network, the number of layers was selected from [2, 6] and the hidden dimension was selected from
[8, 256]. Weight decay was selected from [0, 10−3] for all models."
SMALL,0.9287531806615776,Table 8 summarizes the selected hyperparameters for each model.
SMALL,0.9312977099236641,Table 8: Selected hyperparameters in word analogy task.
SMALL,0.9338422391857506,"layer num
hidden dim
W2V
-
-
W2V + MLP
4
223
W2V + MLP C
2
516
W2V + AGN
5
151"
SMALL,0.9363867684478372,"Detailed Results
In Table 9 and 10, we explained all the subcategories of the bigger analogy test
set and the Google analogy test set. We summarized the full results for each subcategory in Table
11, 12, 13, and 14."
SMALL,0.9389312977099237,2https://github.com/VLL-HD/FrEIA
SMALL,0.9414758269720102,Under review as a conference paper at ICLR 2022
SMALL,0.9440203562340967,"Table 9: Detailed explanation of bigger analogy test set. pair refers to the whole relation size, used
refers to the number included in the word2vec model, and identical refers to the number of used
relations that include identical words."
SMALL,0.9465648854961832,"category
subcategory
example
pair
used
identical"
SMALL,0.9491094147582697,"Inﬂectional
I01 noun - plural reg
album:albums
50
50
1
Inﬂectional
I02 noun - plural irreg
ability:abilities
50
48
2
Inﬂectional
I03 adj - comparative
angry:angrier
50
49
0
Inﬂectional
I04 adj - superlative
able:ablest
50
49
0
Inﬂectional
I05 verb inf - 3pSg
accept:accepts
50
50
1
Inﬂectional
I06 verb inf - Ving
achieve:achieving
50
49
0
Inﬂectional
I07 verb inf - Ved
accept:accepted
50
50
1
Inﬂectional
I08 verb Ving - 3pSg
adding:adds
50
50
0
Inﬂectional
I09 verb Ving - Ved
adding:added
50
50
0
Inﬂectional
I10 verb 3pSg - Ved
adds:added
50
50
0
Derivational
D01 noun+less reg
arm:armless
50
48
0
Derivational
D02 un+adj reg
able:unable
50
49
0
Derivational
D03 adj+ly reg
according:accordingl...
50
49
0
Derivational
D04 over+adj reg
ambitious:overambiti...
50
50
0
Derivational
D05 adj+ness reg
amazing:amazingness
50
45
0
Derivational
D06 re+verb reg
acquire:reacquire
50
48
0
Derivational
D07 verb+able reg
accept:acceptable
50
49
0
Derivational
D08 verb+er irreg
achieve:achiever
50
49
1
Derivational
D09 verb+tion irreg
accuse:accusation
50
48
0
Derivational
D10 verb+ment irreg
accomplish:accomplis...
50
47
0
Encyclopedic
E01 country - capital
abuja:nigeria
50
37
0
Encyclopedic
E02 country - language
andorra:catalan
50
36
0
Encyclopedic
E03 UK city - county
aberdeen:aberdeenshi...
50
24
0
Encyclopedic
E04 name - nationality
aristotle:greek
50
23
0
Encyclopedic
E05 name - occupation
andersen:writer/poet...
50
27
0
Encyclopedic
E06 animal - young
ape:baby/infant
50
50
0
Encyclopedic
E07 animal - sound
alpaca:bray
50
50
0
Encyclopedic
E08 animal - shelter
ant:anthill/insectar...
50
50
0
Encyclopedic
E09 things - color
ant:black/brown/red
50
50
0
Encyclopedic
E10 male - female
actor:actress
50
48
0
Lexicographic
L01 hypernyms - animals
allosaurus:dinosaur/...
50
50
0
Lexicographic
L02 hypernyms - misc
armchair:chair/seat/...
50
50
0
Lexicographic
L03 hyponyms - misc
backpack:daypack/kit...
50
50
0
Lexicographic
L04 meronyms - substance
atmosphere:gas/oxyge...
50
50
1
Lexicographic
L05 meronyms - member
acrobat:troupe
50
50
0
Lexicographic
L06 meronyms - part
academia:college/uni...
50
47
4
Lexicographic
L07 synonyms - intensity
afraid:terriﬁed/hor...
50
50
1
Lexicographic
L08 synonyms - exact
airplane:aeroplane/p...
50
50
0
Lexicographic
L09 antonyms - gradable
able:unable/incapabl...
50
50
0
Lexicographic
L10 antonyms - binary
after:before/earlier...
50
50
0"
SMALL,0.9516539440203562,Under review as a conference paper at ICLR 2022
SMALL,0.9541984732824428,"Table 10: Detailed explanation of Google analogy test set. num refers to the whole relation size and
used refers to the number included in the word2vec model."
SMALL,0.9567430025445293,"category
subcategory
example
num
used"
SMALL,0.9592875318066157,"Semantic
capital-common-countries
Athens:Greece
506
506
Semantic
capital-world
Abuja:Nigeria
4524
4524
Semantic
currency
Algeria:dinar
866
866
Semantic
city-in-state
Chicago:Illinois
2467
2467
Semantic
family
boy:girl
506
506
Syntactic
gram1-adjective-to-adverb
amazing:amazingly
992
992
Syntactic
gram2-opposite
acceptable:unacceptable
812
812
Syntactic
gram3-comparative
bad:worse
1332
1332
Syntactic
gram4-superlative
bad:worst
1122
1122
Syntactic
gram5-present-participle
code:coding
1056
1056
Syntactic
gram6-nationality-adjective
Albania:Albanian
1599
1599
Syntactic
gram7-past-tense
dancing:danced
1560
1560
Syntactic
gram8-plural
banana:bananas
1332
1332
Syntactic
gram9-plural-verbs
decrease:decreases
870
870"
SMALL,0.9618320610687023,Under review as a conference paper at ICLR 2022
SMALL,0.9643765903307888,Table 11: Model comparison for each subcategory of bigger analogy test set.
SMALL,0.9669211195928753,"num
WV
WV + MLP
WV + MLP C
WV + AGN"
SMALL,0.9694656488549618,"I01
90
2(2.22%)
5(5.56%)
10(11.11%)
7(7.78%)
I02
90
0(0.00%)
0(0.00%)
8(8.89%)
0(0.00%)
I03
90
13(14.44%)
22(24.44%)
20(22.22%)
41(45.56%)
I04
90
10(11.11%)
18(20.00%)
25(27.78%)
39(43.33%)
I05
90
26(28.89%)
58(64.44%)
52(57.78%)
60(66.67%)
I06
90
14(15.56%)
13(14.44%)
19(21.11%)
57(63.33%)
I07
90
3(3.33%)
54(60.00%)
42(46.67%)
42(46.67%)
I08
90
11(12.22%)
40(44.44%)
51(56.67%)
54(60.00%)
I09
90
8(8.89%)
49(54.44%)
53(58.89%)
62(68.89%)
I10
90
13(14.44%)
58(64.44%)
60(66.67%)
73(81.11%)
D01
90
0(0.00%)
0(0.00%)
0(0.00%)
0(0.00%)
D02
90
0(0.00%)
1(1.11%)
0(0.00%)
0(0.00%)
D03
90
1(1.11%)
2(2.22%)
9(10.00%)
5(5.56%)
D04
90
0(0.00%)
0(0.00%)
0(0.00%)
0(0.00%)
D05
72
0(0.00%)
2(2.78%)
13(18.06%)
5(6.94%)
D06
90
0(0.00%)
2(2.22%)
8(8.89%)
0(0.00%)
D07
90
0(0.00%)
0(0.00%)
0(0.00%)
0(0.00%)
D08
90
0(0.00%)
4(4.44%)
1(1.11%)
0(0.00%)
D09
90
3(3.33%)
0(0.00%)
8(8.89%)
7(7.78%)
D10
90
0(0.00%)
4(4.44%)
1(1.11%)
3(3.33%)
E01
56
0(0.00%)
0(0.00%)
1(1.79%)
2(3.57%)
E02
56
4(7.14%)
14(25.00%)
21(37.50%)
4(7.14%)
E03
20
6(30.00%)
0(0.00%)
0(0.00%)
3(15.00%)
E04
20
2(10.00%)
3(15.00%)
0(0.00%)
4(20.00%)
E05
30
5(16.67%)
6(20.00%)
8(26.67%)
5(16.67%)
E06
90
4(4.44%)
36(40.00%)
54(60.00%)
42(46.67%)
E07
90
3(3.33%)
18(20.00%)
13(14.44%)
7(7.78%)
E08
90
12(13.33%)
39(43.33%)
37(41.11%)
56(62.22%)
E09
90
10(11.11%)
38(42.22%)
61(67.78%)
35(38.89%)
E10
90
6(6.67%)
0(0.00%)
7(7.78%)
14(15.56%)
L01
90
0(0.00%)
52(57.78%)
55(61.11%)
38(42.22%)
L02
90
1(1.11%)
15(16.67%)
25(27.78%)
8(8.89%)
L03
90
0(0.00%)
0(0.00%)
0(0.00%)
0(0.00%)
L04
90
0(0.00%)
4(4.44%)
10(11.11%)
4(4.44%)
L05
90
0(0.00%)
1(1.11%)
2(2.22%)
0(0.00%)
L06
90
9(10.00%)
0(0.00%)
0(0.00%)
6(6.67%)
L07
90
11(12.22%)
5(5.56%)
0(0.00%)
7(7.78%)
L08
90
0(0.00%)
0(0.00%)
0(0.00%)
0(0.00%)
L09
90
0(0.00%)
2(2.22%)
0(0.00%)
0(0.00%)
L10
90
0(0.00%)
0(0.00%)
0(0.00%)
0(0.00%)"
SMALL,0.9720101781170484,Under review as a conference paper at ICLR 2022
SMALL,0.9745547073791349,Table 12: Model comparison for each subcategory of bigger analogy test set.
SMALL,0.9770992366412213,"num
WV
WV + MLP
WV + MLP C
WV + AGN"
SMALL,0.9796437659033079,"I01
90
53(58.89%)
5(5.56%)
11(12.22%)
55(61.11%)
I02
90
42(46.67%)
0(0.00%)
9(10.00%)
30(33.33%)
I03
90
86(95.56%)
22(24.44%)
20(22.22%)
73(81.11%)
I04
90
68(75.56%)
18(20.00%)
26(28.89%)
64(71.11%)
I05
90
61(67.78%)
58(64.44%)
55(61.11%)
61(67.78%)
I06
90
69(76.67%)
13(14.44%)
26(28.89%)
71(78.89%)
I07
90
52(57.78%)
55(61.11%)
42(46.67%)
68(75.56%)
I08
90
56(62.22%)
42(46.67%)
51(56.67%)
69(76.67%)
I09
90
58(64.44%)
50(55.56%)
63(70.00%)
85(94.44%)
I10
90
69(76.67%)
61(67.78%)
66(73.33%)
80(88.89%)
D01
90
0(0.00%)
0(0.00%)
0(0.00%)
0(0.00%)
D02
90
3(3.33%)
3(3.33%)
0(0.00%)
2(2.22%)
D03
90
26(28.89%)
2(2.22%)
9(10.00%)
15(16.67%)
D04
90
11(12.22%)
0(0.00%)
0(0.00%)
3(3.33%)
D05
72
21(29.17%)
2(2.78%)
13(18.06%)
17(23.61%)
D06
90
13(14.44%)
2(2.22%)
10(11.11%)
19(21.11%)
D07
90
1(1.11%)
0(0.00%)
0(0.00%)
4(4.44%)
D08
90
1(1.11%)
4(4.44%)
1(1.11%)
2(2.22%)
D09
90
21(23.33%)
0(0.00%)
9(10.00%)
24(26.67%)
D10
90
6(6.67%)
4(4.44%)
1(1.11%)
12(13.33%)
E01
56
18(32.14%)
0(0.00%)
1(1.79%)
5(8.93%)
E02
56
0(0.00%)
14(25.00%)
19(33.93%)
4(7.14%)
E03
20
0(0.00%)
0(0.00%)
0(0.00%)
0(0.00%)
E04
20
0(0.00%)
3(15.00%)
0(0.00%)
4(20.00%)
E05
30
0(0.00%)
6(20.00%)
6(20.00%)
2(6.67%)
E06
90
5(5.56%)
33(36.67%)
51(56.67%)
47(52.22%)
E07
90
3(3.33%)
17(18.89%)
12(13.33%)
19(21.11%)
E08
90
2(2.22%)
40(44.44%)
35(38.89%)
53(58.89%)
E09
90
12(13.33%)
38(42.22%)
57(63.33%)
33(36.67%)
E10
90
43(47.78%)
0(0.00%)
7(7.78%)
38(42.22%)
L01
90
7(7.78%)
48(53.33%)
50(55.56%)
51(56.67%)
L02
90
3(3.33%)
15(16.67%)
25(27.78%)
17(18.89%)
L03
90
3(3.33%)
0(0.00%)
0(0.00%)
2(2.22%)
L04
90
1(1.11%)
3(3.33%)
9(10.00%)
5(5.56%)
L05
90
1(1.11%)
1(1.11%)
2(2.22%)
1(1.11%)
L06
90
0(0.00%)
0(0.00%)
0(0.00%)
1(1.11%)
L07
90
12(13.33%)
4(4.44%)
0(0.00%)
2(2.22%)
L08
90
27(30.00%)
0(0.00%)
0(0.00%)
17(18.89%)
L09
90
2(2.22%)
5(5.56%)
0(0.00%)
5(5.56%)
L10
90
8(8.89%)
1(1.11%)
0(0.00%)
5(5.56%)"
SMALL,0.9821882951653944,Under review as a conference paper at ICLR 2022
SMALL,0.9847328244274809,Table 13: Model comparison for each subcategory of Google analogy test set.
SMALL,0.9872773536895675,"num
WV
WV + MLP
WV + MLP C
WV + AGN"
SMALL,0.989821882951654,"capital-common-...
506
225(44.47%)
0(0.00%)
0(0.00%)
227(44.86%)
capital-world
4524
1168(25.82%)
0(0.00%)
0(0.00%)
1223(27.03%)
currency
866
185(21.36%)
0(0.00%)
0(0.00%)
119(13.74%)
city-in-state
2467
252(10.21%)
0(0.00%)
0(0.00%)
350(14.19%)
family
506
165(32.61%)
161(31.82%)
256(50.59%)
341(67.39%)
gram1-adjective...
992
15(1.51%)
86(8.67%)
156(15.73%)
84(8.47%)
gram2-opposite
812
14(1.72%)
200(24.63%)
286(35.22%)
235(28.94%)
gram3-comparati...
1332
329(24.70%)
242(18.17%)
433(32.51%)
713(53.53%)
gram4-superlati...
1122
124(11.05%)
244(21.75%)
311(27.72%)
406(36.19%)
gram5-present-p...
1056
73(6.91%)
71(6.72%)
219(20.74%)
160(15.15%)
gram6-nationali...
1599
1180(73.80%)
0(0.00%)
0(0.00%)
996(62.29%)
gram7-past-tens...
1560
134(8.59%)
127(8.14%)
252(16.15%)
353(22.63%)
gram8-plural
1332
63(4.73%)
82(6.16%)
92(6.91%)
176(13.21%)
gram9-plural-ve...
870
106(12.18%)
133(15.29%)
217(24.94%)
293(33.68%)"
SMALL,0.9923664122137404,Table 14: Model comparison for each subcategory of Google analogy test set.
SMALL,0.9949109414758269,"num
WV
WV + MLP
WV + MLP C
WV + AGN"
SMALL,0.9974554707379135,"capital-common-...
506
421(83.20%)
0(0.00%)
0(0.00%)
378(74.70%)
capital-world
4524
3580(79.13%)
0(0.00%)
0(0.00%)
2689(59.44%)
currency
866
304(35.10%)
0(0.00%)
0(0.00%)
180(20.79%)
city-in-state
2467
1749(70.90%)
0(0.00%)
0(0.00%)
1223(49.57%)
family
506
428(84.58%)
163(32.21%)
256(50.59%)
448(88.54%)
gram1-adjective...
992
283(28.53%)
93(9.38%)
162(16.33%)
283(28.53%)
gram2-opposite
812
347(42.73%)
201(24.75%)
299(36.82%)
419(51.60%)
gram3-comparati...
1332
1210(90.84%)
248(18.62%)
437(32.81%)
1044(78.38%)
gram4-superlati...
1122
980(87.34%)
246(21.93%)
319(28.43%)
777(69.25%)
gram5-present-p...
1056
825(78.12%)
78(7.39%)
298(28.22%)
729(69.03%)
gram6-nationali...
1599
1438(89.93%)
0(0.00%)
0(0.00%)
1158(72.42%)
gram7-past-tens...
1560
1029(65.96%)
157(10.06%)
283(18.14%)
1061(68.01%)
gram8-plural
1332
1197(89.86%)
103(7.73%)
122(9.16%)
826(62.01%)
gram9-plural-ve...
870
591(67.93%)
138(15.86%)
238(27.36%)
642(73.79%)"
