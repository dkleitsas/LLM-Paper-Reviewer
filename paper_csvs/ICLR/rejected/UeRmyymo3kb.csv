Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.003125,"Graph neural networks (GNNs) have been increasingly deployed in various appli-
cations that involve learning on non-Euclidean data. However, recent studies show
that GNNs are vulnerable to graph adversarial attacks. Although there are several
defense methods to improve GNN adversarial robustness, they fail to perform well
on low homophily graphs. In addition, few of those defense models can scale to
large graphs due to their high computational complexity and memory usage. In
this paper, we propose GARNET, a scalable spectral method to boost the adver-
sarial robustness of GNN models for both homophilic and heterophilic graphs.
GARNET first computes a reduced-rank yet sparse approximation of the adver-
sarial graph by exploiting an efficient spectral graph embedding and sparsification
scheme. Next, GARNET trains an adaptive graph filter on the reduced-rank graph
for node representation refinement, which is subsequently leveraged to guide la-
bel propagation for further enhancing the quality of node embeddings. GARNET
has been evaluated on both homophilic and heterophilic datasets, including a large
graph with millions of nodes. Our extensive experiment results show that GAR-
NET increases adversarial accuracy over state-of-the-art GNN (defense) models
by up to 9.96% and 18.06% on homophilic and heterophilic graphs, respectively."
INTRODUCTION,0.00625,"1
INTRODUCTION"
INTRODUCTION,0.009375,"Recent years have witnessed a surge of interest in graph neural networks (GNNs), which incorporate
both graph structure and node/edge attributes to produce low-dimensional embedding vectors that
maximally preserve graph structural information (Hamilton, 2020). GNNs have achieved promis-
ing results in various real-world applications, such as recommendation systems (Ying et al., 2018),
self-driving car (Casas et al., 2020), protein structure predictions (Senior et al., 2020), and chip
placements (Mirhoseini et al., 2021). However, recent studies have shown that adversarial attacks
on graph structure accomplished by inserting, deleting, or rewiring edges in an unnoticeable way,
can easily fool GNN models and drastically degrade their accuracy in downstream tasks (e.g., node
classification) (Z¨ugner et al., 2018; Z¨ugner & G¨unnemann, 2019)."
INTRODUCTION,0.0125,"In literature, there are several attempts to defend GNNs against graph adversarial attacks. Entezari
et al. (2020) first observed that graph adversarial attacks mainly affect high-rank properties of the
graph; consequently, a low-rank graph should be first constructed by performing truncated singular
value decomposition (SVD) on the graph adjacency matrix, which can then be exploited for training
a robust GNN model. Later, Jin et al. (2020) proposed Pro-GNN to jointly learn a new graph and
its robust GNN model with the low-rank constraints imposed by the graph structure. However, such
low-rank approximation methods involve dense adjacency matrices during the GNN training stage,
which will lead to quadratic time and space complexity, prohibiting their applications in large-scale
graph learning tasks. Another line of research aims at enhancing GNN robustness based on the graph
homophily assumption, i.e., adjacent nodes in a natural graph tend to have similar attributes, while
the graph attacks essentially insert adversarial edges by connecting nodes with dissimilar attributes.
As a result, researchers proposed to compute attribute similarity scores between adjacent nodes as
edge weights, and drop edges with small weights to increase graph homophily (Wu et al., 2019;
Zhang & Zitnik, 2020). Although such approaches can successfully improve GNN robustness on
high-homophily graphs, they may fail on low-homophily (i.e., heterophily) graphs (Zhu et al., 2020)."
INTRODUCTION,0.015625,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.01875,"In this paper, we propose GARNET, a spectral method for constructing GNN models that are robust
to graph adversarial attacks for both homophilic and heterophilic graphs. In addition, GARNET
scales comfortably to large graphs due to its nearly-linear algorithm complexity. More concretely,
GARNET consists of three major kernels: (1) reduced-rank approximation, (2) adaptive filter learn-
ing, and (3) adaptive label propagation. The reduced-rank approximation kernel first performs trun-
cated SVD on graph adjacency matrix to obtain a few dominant singular values and their correspond-
ing singular vectors that are further leveraged to construct a sparse yet reduced-rank graph adjacency
matrix; the reduced-rank adjacency matrix can effectively mitigate the effects of adversarial attacks
via connecting (disconnecting) nodes that are spectrally similar (dissimilar). The adaptive filter
learning kernel aims to learn a polynomial graph filter whose coefficients are trainable; the learned
graph filter can adapt to the homophilic/heterophilic properties of the underlying graph and thus will
work effectively for both homophilic and heterophilic graphs. The adaptive label propagation stage
will leverage the learned adaptive graph filter to guide the label propagation phase, which can further
improve the adversarial accuracy by enhancing the quality of node representations."
INTRODUCTION,0.021875,"We evaluate the proposed GARNET model on three high-homophily datasets: Cora, Citeseer, and
Pubmed as well as two low-homophily datasets: Chameleon and Squirrel, under strong graph ad-
versarial attacks such as Nettack (Z¨ugner et al., 2018) and Metattack (Z¨ugner & G¨unnemann, 2019)
with various perturbation settings. Moreover, we further show the nearly-linear scalability of our
approach on the ogbn-products dataset that consists of millions of nodes (Hu et al., 2020). Our
experimental results indicate that GARNET largely improves adversarial accuracy over baselines in
most cases. The major advantages of GARNET are summarized as follows:"
INTRODUCTION,0.025,"• GARNET is robust to graph adversarial attacks. Exploiting the proposed reduced-rank approx-
imation scheme allows GARNET to effectively filter out the noises potentially caused by adversarial
attacks in the spectral domain. This immediately leads to substantial improvement (up to 18.06%)
of adversarial accuracy when comparing with the state-of-the-art baselines under the strong graph
attacks on various datasets.
• GARNET is agnostic to graph homophily. Unlike most existing defense models that do not work
well on low-homophily adversarial graphs, GARNET leverages a trainable graph filter that can adapt
to adversarial graphs with diverse levels of homophily. In addition, we theoretically demonstrate that
the performance of the adaptive graph filter applied to an adversarial graph will be similar to the per-
formance achieved on a clean graph.
• GARNET is scalable to large graphs. GARNET has a nearly-linear runtime/space complexity
and thus can scale comfortably to very large graph data sets with millions of nodes. We have con-
ducted experiments on the ogbn-products dataset that contains 2 million nodes and 60 million edges,
which is over 100× larger than the largest adversarial graph ever considered in the prior arts."
RELATED WORK,0.028125,"2
RELATED WORK"
RELATED WORK,0.03125,"GNNs have received an increasing amount of attention in recent years due to its ability of learning on
non-Euclidean (graph) data. In contrast to developing powerful GNN models on natural graph data,
there is an active body of research focusing on adversarial attacks as well as defenses for GNNs. We
summarize some of the recent efforts for graph adversarial attacks and defenses as follows."
RELATED WORK,0.034375,"Graph adversarial attacks aim at degrading the accuracy of GNN models by perturbing the graph
structure in an unnoticeable way. For instance, most existing graph adversarial attacks insert/delete
edges while maintaining node degree distribution (Sun et al., 2018). The most popular graph adver-
sarial attacks fall into the following two categories: (1) targeted attack, (2) untargeted attack. The
targeted attacks attempt to mislead a GNN model to produce a wrong prediction on a target sample
(e.g., node), while the untargeted attacks strive to degrade the overall accuracy of a GNN model for
the whole graph data set. Dai et al. (2018) first formulate the targeted attack as a combinatorial op-
timization problem and leverages reinforcement learning to insert/delete edges such that the target
node is misclassified. Z¨ugner et al. (2018) propose another targeted attack called Nettack, which
produces an adversarial graph by maximizing the training loss of GNNs. Z¨ugner & G¨unnemann
(2019) further introduce Metattack, an untargeted attack that treats the graph as a hyperparameter
and uses meta-gradients to perturb the graph structure. It is worth noting that graph adversarial
attacks have two different settings: poison (perturb a graph prior to GNN training) and evasion (per-
turb a graph after GNN training). As shown by Zhu et al. (2021), the poison setting is typically"
RELATED WORK,0.0375,Under review as a conference paper at ICLR 2022
RELATED WORK,0.040625,"more challenging to defend, as it changes graph structure that fools GNN training. Thus, in this
work, we evaluate our model against both targeted and untargeted attacks under the poison setting."
RELATED WORK,0.04375,"Graph adversarial defenses attempt to enhance GNN performance on the perturbed graphs gener-
ated by adversarial attacks. Entezari et al. (2020) first observe that Nettack, a strong targeted attack,
only changes the high-rank information of the adjacency matrix after graph perturbation. Thus, they
propose to construct a low-rank graph by performing truncated SVD to undermine the effects of ad-
versarial attacks. Jin et al. (2020) propose Pro-GNN that adopts a similar idea yet jointly learns the
low-rank graph and GNN model. However, such low-rank approximation based methods produce
dense adjacency matrices that correspond to complete graphs, which would limit their applications
for large graphs. Another line of research strives to purify the adversarial graph by assigning edge
weights. Specifically, Wu et al. (2019) propose to modify the edge weights by computing the Jaccard
similarity score per edge based on node attributes, which is followed by Zhang & Zitnik (2020) that
propose GNNGuard to learn node attribute similarity score per edge through a trainable linear layer.
Nonetheless, such approaches assume that nearby nodes should have similar attributes (i.e., graph
homophily assumption), which is not valid for heterophilic graphs that have adjacent nodes with
dissimilar attributes (Zhu et al., 2020). In contrast to the prior arts, GARNET achieves highly robust
yet scalable performance on both homophilic and heterophilic graphs under adversarial attacks by
leveraging novel reduced-rank approximation and adaptive graph filtering schemes."
OUR APPROACH,0.046875,"3
OUR APPROACH"
OUR APPROACH,0.05,"Figure 1 gives an overview of our proposed approach, GARNET, which consists of three major
phases. The first phase (reduced-rank approximation) constructs a reduced-rank yet sparse graph
model by exploiting scalable truncated SVD and nearest-neighbor graph algorithms (Baglama &
Reichel, 2005; Malkov & Yashunin, 2018).
The second phase (adaptive filter learning) is the
only phase that involves training, which outputs a learned graph filter that can adapt to the ho-
mophilic/heterophilic properties of the underlying graph. The last phase (adaptive label propaga-
tion) leverages the learned adaptive graph filter to guide the subsequent label propagation process.
In the rest of this section, we will describe each of these three phases in more detail. ! = # !""# $ $!%!"
OUR APPROACH,0.053125,"Learned 
Adaptive Filter"
OUR APPROACH,0.05625,Truncated SVD
OUR APPROACH,0.059375,"Spectral 
Embeddings"
OUR APPROACH,0.0625,",
: Node w/ train label
: Adversarial edge"
OUR APPROACH,0.065625,"Phase 1: Reduced-Rank Approximation
Phase 2: Adaptive Filter Learning"
OUR APPROACH,0.06875,"Phase 3: Adaptive Label Propagation 2 3 4 5 6
1
7 1
4
7 2 3 5 6 2 3 4 5 6
1
7"
OUR APPROACH,0.071875,"!!,#
!!,$ !%,$
!%,&"
OUR APPROACH,0.075,"!',&
!(,# !(,$ 2 3 4 5 6
1
7 2 3 4 5 6 1
7"
OUR APPROACH,0.078125,Node w/ Learned
OUR APPROACH,0.08125,Embedding
OUR APPROACH,0.084375,"kNN
Graph 2 3 4 5 6
1
7 2 3 4 5 6 1
7"
OUR APPROACH,0.0875,Figure 1: An overview of the three major phases of GARNET.
OUR APPROACH,0.090625,"3.1
REDUCED-RANK APPROXIMATION (PHASE 1)"
OUR APPROACH,0.09375,"The adjacency matrices of many real-world graphs (e.g., social network and biological network) are
naturally low rank and sparse, as the nodes typically tend to form communities and have a small
number of neighbors (Zhou et al., 2013). As a result, graph adversarial attacks can be viewed
as compromising these properties by inserting edges that connect nodes from different communi-
ties (Z¨ugner et al., 2018; Z¨ugner & G¨unnemann, 2019). Recently, Entezari et al. (2020) and Jin
et al. (2020) have shown that the well-known graph adversarial attacks (e.g., Nettack and Metat-
tack) are essentially high-rank attacks, which mainly change the high-rank spectrum of the graph
when perturbing the graph structure, while the low-rank spectrum remains almost the same. We
empirically confirm that the graph rank indeed increases under adversarial attacks in Appendix A.7."
OUR APPROACH,0.096875,Under review as a conference paper at ICLR 2022
OUR APPROACH,0.1,"Consequently, a natural way for improving GNN robustness is to purify an adversarial graph by
eliminating the high-rank components of its spectrum."
OUR APPROACH,0.103125,"To enhance GNN robustness, Entezari et al. (2020) and Jin et al. (2020) reconstruct a graph that only
preserves the low-rank components of its spectrum to mitigate the effects of adversarial attacks, via
performing truncated SVD on the adjacency matrix. Specifically, given a graph adjacency matrix
A ∈Rn×n, the rank-r approximated adjacency matrix can be obtained via truncated SVD: ˆ
A =
UΣV T , where Σ ∈Rr×r is a diagonal matrix consisting of r largest singular values of A. U ∈
Rn×r and V ∈Rn×r contain the corresponding left and right singular vectors, respectively."
OUR APPROACH,0.10625,"However, the reconstructed low-rank adjacency matrix ˆ
A has two key issues: (1) ˆ
A is typically a
dense matrix with O(n2) nonzero elements, which may result in prohibitively expensive storage as
well as GNN training, where n represents number of nodes (Entezari et al., 2020; Jin et al., 2020).
Thus, existing low-rank approximation methods are not scalable to large graphs; (2) Due to the high
computational cost of SVD, ˆ
A is typically obtained by only leveraging top r singular values and
singular vectors, where r is a relatively small number (e.g., r = 50). Consequently, the rank of ˆ
A is
only r = 50, which loses too much important spectrum information and thus limits the performance
of GNN training."
OUR APPROACH,0.109375,"Reduced-rank approximation via sparsification. To avoid the quadratic space complexity for
obtaining ˆ
A, one simple solution is to sparsify ˆ
A on the fly. More concretely, instead of directly
computing ˆ
A = UΣV T , we can compute ˆ
A row by row:
ˆ
Ai,: = Ui,:ΣV T . Once we obtain
ˆ
Ai,:, we can sparsify it by setting ˜
Ai,j = 0 if ˆ
Ai,j < δ and ˜
Ai,j = ˆ
Ai,j otherwise, where δ is
a hyperparameter to control the sparsity. In this way, we only need to store a dense vector ˆ
Ai,:
at a time and the final adjacency matrix ˜
A is sparse. Although the space complexity is reduced
to O(m), where m denotes the number of non-zero elements in ˜
A, this sparsification method still
has quadratic time complexity for computing ˜
A. To tackle this issue, in this work a nearly-linear
complexity algorithm for constructing a reduced-rank yet sparse matrix ˜
A is proposed by exploiting
the following connection between matrix sparsification and spectral graph embedding.
Definition 1. Given the top r smallest eigenvalues λ1, λ2, ..., λr and their corresponding eigenvec-
tors v1, v2, ..., vr of normalized graph Laplacian matrix Lnorm = I −D−1"
OUR APPROACH,0.1125,2 AD−1
OUR APPROACH,0.115625,"2 , where I and
A are the identity matrix and graph adjacency matrix, respectively, and D is a diagonal matrix of
node degrees, the weighted spectral embedding matrix is defined as:"
OUR APPROACH,0.11875,"V
def
=
hp"
OUR APPROACH,0.121875,"|1 −λ1|v1, ...,
p"
OUR APPROACH,0.125,"|1 −λr|vr
i
,
(1)"
OUR APPROACH,0.128125,"whose i-th row Vi,: is the weighted spectral embedding of the corresponding i-th node in the graph."
OUR APPROACH,0.13125,Theorem 1. Given a normalized graph adjacency matrix Anorm = D−1
OUR APPROACH,0.134375,2 AD−1
OF AN UNDIRECTED,0.1375,"2 of an undirected
graph, let ˆ
A be the rank-r approximation of Anorm via truncated SVD. If the top r dominant
eigenvalues of Anorm are non-negative, then ˆ
Ai,j corresponds to the dot product score between the
weighted spectral embeddings of node i and j."
OF AN UNDIRECTED,0.140625,"Theorem 1 indicates that the reduced-rank approximation of the normalized adjacency matrix via
truncated SVD captures the spectral similarity between nodes, which motivates us to leverage
weighted spectral embeddings to capture graph spectral (low-rank) information, thereby identify-
ing edges to be pruned (sparsified) from the graph. Unlike traditional spectral graph embedding
methods that utilize the first r Laplacian eigenpairs to construct spectral embedding matrix, we ex-
ploit the top r largest singular values and their singular vectors of Anorm that may include both
the smallest and largest Laplacian eigenpairs for capturing global and local structural information,
respectively (Shuman et al., 2013). More specifically, given a graph G = (V, E) and its normalized
adjacency matrix Anorm, our approach first computes the r largest singular values (e.g., r = 50)
and the corresponding singular vectors of Anorm leveraging efficient eigensolvers in O(r|E|) time
to construct the weighted spectral embeddings (Baglama & Reichel, 2005); next, the embedding
results are then used to construct a nearest neighbor (NN) graph, where each node will be connected
to its k most spectrally similar nodes. Afterwards, we compute the dot product similarity scores
between adjacent nodes in the NN graph. If the similarity score is less than a threshold δ, we prune
the corresponding edge from the NN graph to further sparsify the graph. In this work, we exploit an
approximate k-nearest neighbor algorithm for constructing the NN graph, which has O(|V| log |V|)"
OF AN UNDIRECTED,0.14375,Under review as a conference paper at ICLR 2022
OF AN UNDIRECTED,0.146875,"complexity and thus can scale to very large graphs (Malkov & Yashunin, 2018). We say a graph is a
reduced-rank graph if its adjacency matrix is obtained via the proposed reduced-rank approximation
method. As a result, we can obtain a reduced-rank and sparse graph in O(r|E| + |V| log |V|) time."
OF AN UNDIRECTED,0.15,"Apart from the advantage of scalability, our kNN-based reduced-rank graph also preserves much
more important spectrum information than the truncated SVD-based low-rank graph. As shown
by Entezari et al. (2020), adversarial attacks only perturb the top few highest singular components in
the graph spectrum, while the rest of spectral information corresponds to the clean graph structure in
the spatial domain. Nonetheless, Figure 5 in Appendix A.8 shows the truncated SVD-based method
aggressively reduces graph rank to 50, which is two orders of magnitude smaller than the rank of
input graph. In contrast, our reduced-rank method only removes the highest singular components,
while retaining most of important spectral information. As a result, our reduced-rank approximation
kernel leads to a significant accuracy improvement over the SVD-based low-rank approximation.
More details are available in Appendices A.11."
OF AN UNDIRECTED,0.153125,"3.2
ADAPTIVE FILTER LEARNING (PHASE 2)"
OF AN UNDIRECTED,0.15625,"Most existing GNN defense models (implicitly) assume the underlying graph is homophilic, im-
plying that nearby nodes will share similar attributes; however, this assumption is not valid for
heterophilic graphs in which adjacent nodes may have dissimilar attributes (Ma et al., 2021). As
a consequence, existing defense methods may not be robust against graph adversarial attacks on
heterophilic graphs. To address this limitation, we adopt the concept of learning a polynomial graph
filter that can adapt to graph homo/heterophily (NT et al., 2020; Chien et al., 2021), and apply it on
the adversarial graphs. Specifically, given a graph and its node attribute matrix X, our graph filter
learning process works as follows:
ˆ
X = MLP(X)
(2)"
OF AN UNDIRECTED,0.159375,"Z = softmax( P
X"
OF AN UNDIRECTED,0.1625,"p=0
cpF p ˆ
X)
(3)"
OF AN UNDIRECTED,0.165625,where F can be either a normalized adjacency matrix Anorm = D−1
OF AN UNDIRECTED,0.16875,2 AD−1
OR NORMALIZED LAPLA-,0.171875,"2 or normalized Lapla-
cian matrix Lnorm = I −Anorm, c0, c1, ..., cP are P + 1 learnable polynomial coefficients. We
use the output node embedding matrix Z and node training labels to calculate training loss. The
weights of MLP as well as learnable polynomial coefficients are then updated via backpropagation."
OR NORMALIZED LAPLA-,0.175,"Next, we are going to show that the learnable coefficients c0, c1, ..., cP enable the polynomial graph
filter gP (F ) = PP
p=0 cpF p in Equation 3 to adapt to a homo/heterophilic graph."
OR NORMALIZED LAPLA-,0.178125,"Lemma 1 (Chien et al. (2021)). Assume the graph G is connected and |cp| ≤1 ∀p ∈{0, 1, ..., P}.
Let F to be the normalized adjacency matrix F = D−1"
OR NORMALIZED LAPLA-,0.18125,2 AD−1
OR NORMALIZED LAPLA-,0.184375,"2 . If cp ≥0
∀p ∈{0, 1, ..., P},
PP
p=0cp = 1, and ∃p′ > 0 such that cp′ > 0, then gp(F ) is a low-pass filter. Also, if cp =
(−α)k, α ∈(0, 1) and P is large enough, then gp(F ) is a high-pass filter."
OR NORMALIZED LAPLA-,0.1875,"Intuitively, Lemma 1 indicates that for a homophilic graph the filter coefficients tend to be positive,
whereas for a heterophilic graph both positive and negative coefficients can be observed. Conse-
quently, gP (F ) can be learned to serve as a low-pass (high-pass) graph filter to filter node inter-
mediate embeddings ˆ
X over the homophilic (heterophilic) graph, such that nearby nodes will have
similar (dissimilar) output embeddings. Thus, a natural idea for developing a robust GNN model
on both homophilic and heterophilic graphs is to exploit both the reduced-rank graph in Section 3.1
and the aforementioned adaptive polynomial graph filter."
OR NORMALIZED LAPLA-,0.190625,"However, adaptive polynomial graph filters typically perform well on clean graphs that are entirely
homophilic or heterophilic, while the adversarial graphs can be globally homophilic yet locally
heterophilic (Zhu et al., 2021). Another important question is whether the polynomial filters can
still be effective when combined with reduced-rank approximation of the adversarial graph. Next,
we answer this question by showing the upper bound of the performance difference between the
polynomial graph filter on a clean graph and that on the corresponding reduced-rank graph."
OR NORMALIZED LAPLA-,0.19375,"Theorem 2. Let Aclean, Aadv, and Ar represent the normalized adjacency matrices of a clean
graph, the corresponding adversarial graph, and the rank-r approximated adversarial graph, re-
spectively. Also let σr+1 denote the (r + 1)-th largest singular value of Aadv. Assume the spectral"
OR NORMALIZED LAPLA-,0.196875,Under review as a conference paper at ICLR 2022
OR NORMALIZED LAPLA-,0.2,"norm of graph adversarial perturbation is upper bounded by a constant ϵ, i.e., ∥Aclean −Aadv∥2 ≤
ϵ. Given a polynomial graph filter gP (F ) = PP
p=0 cpF p , we have:"
OR NORMALIZED LAPLA-,0.203125,"∥gP (Aclean) −gP (Ar)∥2 ≤ P
X"
OR NORMALIZED LAPLA-,0.20625,"p=1
p |cp| (ϵ + σr+1)
(4)"
OR NORMALIZED LAPLA-,0.209375,"Note that the graph attacking algorithms are typically designed to perturb the graph structure in an
unnoticeable way, which means that ϵ is a small value. Moreover, σr+1 is within the range of [0, 1]
since Aadv is normalized. We further set P ≤10 and enforce PP
p=0 |cp| = 1 when learning the
adaptive filter to tighten the upper bound. As a result, Theorem 2 indicates that the performance of
a polynomial filter on the reduced-rank graph will be similar to its performance on the clean graph.
Hence, applying the adaptive graph filter on the reduced-rank graph constructed in Section 3.1 allows
GARNET to work effectively for both homophilic and heterophilic graphs under adversarial attacks."
OR NORMALIZED LAPLA-,0.2125,"Scalability of adaptive filter learning. To scale the adaptive filter learning process to large graphs,
we do not explicitly form the graph filter gP (F ) = PP
p=0 cpF p. Instead, we iteratively left-multiply
ˆ
X by F in Equation 3 to leverage the sparsity of F . Thus, the time complexity is linear to the
graph size. Besides, we can effectively exploit model parallelism (Castell´o et al., 2019) , where
the computation of a graph filter gP (F ) is distributed onto multiple GPUs based on the index p that
indicates the p-th term in gP (F ). This way, we can dramatically reduce the memory usage per GPU,
thereby allowing the adaptive filter learning process to scale to large graphs with millions of nodes."
OR NORMALIZED LAPLA-,0.215625,"3.3
ADAPTIVE LABEL PROPAGATION (PHASE 3)"
OR NORMALIZED LAPLA-,0.21875,"Once the trained graph filter g∗
P (F ) = PP
p=0 c∗
pF p is obtained, we further leverage it to enhance the
quality of node embeddings Z in Equation 3 by correlating residue errors and propagating node la-
bels, which is partly inspired by the correct and smooth (C&S) method recently proposed in (Huang
et al., 2020). The key idea of C&S is to smooth the residue errors and node labels over the graph
leveraging a low-pass graph filter, which assumes the underlying graph to be homophilic. In con-
trast, our approach works effectively for both homophilic and heterophilic graphs by exploiting
adaptive filter learning. Specifically, let NL and NU be the set of nodes that are labelled and unla-
belled, respectively. Given the one-hot label matrix Y ∈Rn×c, where n and c denote the numbers
of nodes and classes, respectively, we define the residue error matrix by R ∈Rn×c such that
RNL = ZNL −YNL and RNU = 0. Our goal is to optimize the following objective:"
OR NORMALIZED LAPLA-,0.221875,"ˆR = arg min
H
∥H −R∥2
F + λ Tr(HT (I −1"
OR NORMALIZED LAPLA-,0.225,"P g∗
P (F ))H)
(5)"
OR NORMALIZED LAPLA-,0.228125,"where λ is a regularization parameter. The first term in Equation 5 enforces the solution to be close
to the initial residue error R that contains the label information. The key difference between our
approach and the prior C&S method lies in the second term: our method spreads the error over
the graph guided by the trained adaptive filter g∗
P (F ), whereas the C&S method adopts a simple
(non-adaptive) smoothing scheme. Note that there is no training involved in this phase and ˆR can
be iteratively computed by ˆRt+1 = α 1"
OR NORMALIZED LAPLA-,0.23125,"P g∗
P (F ) ˆRt + (1 −α)R in O(m) time due to the sparsity
of F , where α =
λ
1+λ and m is the number of edges in graph. After obtaining ˆR, we update the
node embeddings ˜Z by ˜ZNL = YNL and ˜ZNU = ZNU + β ˆRNU , where β is a hyperparameter.
As suggested in Huang et al. (2020), we further refine ˜Z by substituting ˜Z for R in Equation 5
to diffuse the label information over the graph, thereby obtaining the corresponding optimizer ˆZ.
Subsequently, ˆZ will be utilized as the final node embeddings in the following label prediction step."
EXPERIMENTS,0.234375,"4
EXPERIMENTS"
EXPERIMENTS,0.2375,"We have conducted comparative evaluation of GARNET against state-of-the-art defense GNN mod-
els on both homophilic and heterophilic datasets, under targeted attack (Nettack) (Z¨ugner et al.,
2018) and non-targeted attack (Mettack) (Z¨ugner & G¨unnemann, 2019) with different perturbation
budgets. Besides, we further evaluate the scalability of GARNET on ogbn-products, which is over
100× larger than the datasets used in Entezari et al. (2020); Zhang & Zitnik (2020); Jin et al. (2020).
Finally, we perform ablation studies to understand the effectiveness of each kernel in GARNET."
EXPERIMENTS,0.240625,Under review as a conference paper at ICLR 2022
EXPERIMENTS,0.24375,"Table 1: Averaged node classification accuracy (%) ± std under targeted attack (Nettack) with
different perturbation ratio — We denote the evaluated dataset by its name with the number of
perturbations (e.g., Cora-0 means the clean Cora graph and Cora-1 denotes there is 1 adversarial
edge perturbation per target node). We bold and underline the first and second highest accuracy,
respectively. OOM means out of memory."
EXPERIMENTS,0.246875,"Dataset
GCN
GPRGNN
GPRSVD-CS
GCNSVD
GNNGuard
Pro-GNN
GARNET"
EXPERIMENTS,0.25,"Cora-0
80.96 ± 0.95
84.33 ± 2.05
81.68 ± 1.78
72.65 ± 2.29
83.37 ± 2.46
81.54 ± 1.21
82.77 ± 1.89
Cora-1
75.06 ± 0.81
81.68 ± 2.18
79.36 ± 2.23
70.36 ± 1.63
78.31 ± 1.60
82.65 ± 0.59
82.17 ± 1.95
Cora-2
70.60 ± 1.81
74.34 ± 2.41
76.26 ± 2.34
65.66 ± 2.76
72.77 ± 2.06
77.83 ± 1.10
78.55 ± 2.11
Cora-3
69.04 ± 3.31
70.96 ± 2.00
70.90 ± 3.89
61.20 ± 1.93
68.19 ± 2.48
71.08 ± 1.20
79.40 ± 1.35
Cora-4
61.69 ± 1.48
65.90 ± 1.61
65.51 ± 3.27
57.34 ± 3.46
62.41 ± 2.65
67.83 ± 1.87
72.77 ± 2.16
Cora-5
55.66 ± 1.95
62.89 ± 1.95
63.52 ± 3.27
55.30 ± 2.25
57.59 ± 2.46
65.38 ± 1.65
71.45 ± 2.73"
EXPERIMENTS,0.253125,"Citeseer-0
81.59 ± 0.82
82.38 ± 0.82
82.38 ± 0.50
80.95 ± 1.23
80.32 ± 1.34
82.89 ± 1.53
83.86 ± 1.07
Citeseer-1
79.04 ± 1.80
80.15 ± 0.84
81.38 ± 0.50
75.23 ± 2.67
78.57 ± 2.14
81.74 ± 0.79
83.49 ± 1.14
Citeseer-2
76.19 ± 3.89
80.32 ± 0.82
80.27 ± 0.67
60.15 ± 2.29
73.18 ± 4.56
80.15 ± 0.71
80.63 ± 1.46
Citeseer-3
62.54 ± 4.50
77.46 ± 1.46
78.95 ± 0.74
58.89 ± 5.28
64.38 ± 5.89
78.36 ± 2.56
76.67 ± 2.25
Citeseer-4
57.30 ± 3.62
73.33 ± 3.16
73.95 ± 0.75
51.74 ± 7.96
59.05 ± 5.96
73.98 ± 1.28
72.22 ± 2.28
Citeseer-5
51.75 ± 2.50
67.89 ± 3.74
67.95 ± 1.98
45.07 ± 2.77
54.13 ± 8.05
67.46 ± 6.36
68.19 ± 4.03"
EXPERIMENTS,0.25625,"Pubmed-0
87.26 ± 0.51
90.05 ± 0.73
OOM
87.03 ± 0.48
89.57 ± 0.28
OOM
90.99 ± 0.52
Pubmed-1
86.29 ± 0.68
89.30 ± 0.54
OOM
84.46 ± 0.28
87.84 ± 0.51
OOM
90.91 ± 0.47
Pubmed-2
83.17 ± 0.67
87.42 ± 0.28
OOM
82.68 ± 0.46
85.00 ± 0.59
OOM
90.75 ± 0.55
Pubmed-3
81.13 ± 0.53
84.46 ± 0.53
OOM
81.34 ± 0.68
81.29 ± 0.90
OOM
90.70 ± 0.37
Pubmed-4
75.48 ± 0.52
81.72 ± 0.72
OOM
82.41 ± 0.54
76.07 ± 0.77
OOM
90.11 ± 0.57
Pubmed-5
66.67 ± 1.34
76.99 ± 1.16
OOM
79.56 ± 0.48
69.89 ± 1.18
OOM
89.52 ± 0.45"
EXPERIMENTS,0.259375,"Experimental Setup. The details of datasets are available in Appendix A.9.2. We evaluate unvacci-
nated GCN (Kipf & Welling, 2016) and GPRGNN (Chien et al., 2021). Moreover, we choose as the
defense baselines three state-of-the-art vaccinated GNN models: GCNSVD (Entezari et al., 2020),
GNNGuard (Zhang & Zitnik, 2020), and Pro-GNN Jin et al. (2020). Besides, we further evaluate a
strong defense baseline GPRSVD-CS by combining truncated SVD (for low-rank approximation),
GPRGNN (for adaptive filter learning), and C&S (for label propagation). For all baselines, we
tune their hyperparameters against adversarial attacks with a small perturbation, and keep the same
hyperparameters for larger adversarial perturbations. We further show hyperparameter settings of
GARNET and hardware information in Appendix A.9."
DEFENSE ON HOMOPHILIC GRAPHS,0.2625,"4.1
DEFENSE ON HOMOPHILIC GRAPHS"
DEFENSE ON HOMOPHILIC GRAPHS,0.265625,"Defense against targeted attack. We first evaluate the model robustness against Nettack, a strong
attack method to fool a GNN model to misclassify some target nodes with a few structure (edge)
perturbations. We choose the same set of target nodes as in (Jin et al., 2020). We report the averaged
accuracy over 10 runs on Cora, Citeseer, and Pubmed datasets with adversarial perturbations varying
from 0 to 5 per target node. Table 1 shows that GARNET outperforms all the baselines in most
cases, with the accuracy improvement up to 9.96% over existing defense methods. Note that the
accuracy degradation of GARNET when increasing perturbation budget is much smaller than that
of baselines. For instance, the accuracy drop of GARNET is only 1.39% with perturbations varying
from 1 to 5 on Pubmed, while the accuracy of baseline defense methods drops 4.9% ∼17.95%,
indicating that GARNET is indeed more robust to strong targeted attack on homophilic graphs.
Moreover, GARNET gains up to 8.5% accuracy improvement over GPRSVD-CS, which reveals
that our reduced-rank approximation kernel produces a much higher quality of low-rank graph than
the SVD-based graph by preserving more useful spectrum information as explained in Section 3.1."
DEFENSE ON HOMOPHILIC GRAPHS,0.26875,"Defense against non-targeted attack. We further evaluate model robustness against a strong non-
targeted attack, i.e., Metattack, whose goal is to drop the overall accuracy of the whole test set
with a given perturbation ratio budget (i.e., the number of adversarial edges over the number of
total edges). We report the averaged accuracy over 10 runs on Cora, Citeseer, and Pubmed with
perturbation ratio in {0%, 10%, 20%}. As shown in Table 2, GARNET consistently achieves the
highest adversarial accuracy across all datasets under different attack perturbation ratios, which
verifies that GARNET can also successfully defend against the non-targeted attack on homophilic
graphs. It is worth mentioning that both GPRSVD-CS and Pro-GNN run out of memory even on
Pubmed, a graph with only 20k nodes. In contrast, GARNET is not only robust to adversarial
attacks, but also scalable to large graphs, as empirically shown in Section 4.3."
DEFENSE ON HOMOPHILIC GRAPHS,0.271875,Under review as a conference paper at ICLR 2022
DEFENSE ON HOMOPHILIC GRAPHS,0.275,"Table 2: Averaged node classification accuracy (%) ± std under non-targeted attack (Metattack) with
different perturbation ratio — We denote the evaluated dataset by its name with the perturbation ratio
(e.g., Cora-0 means the clean Cora graph and Cora-10 denotes there are 10% adversarial edges). We
bold and underline the first and second highest accuracy, respectively. OOM means out of memory."
DEFENSE ON HOMOPHILIC GRAPHS,0.278125,"Dataset
GCN
GPRGNN
GPRSVD-CS
GCNSVD
GNNGuard
Pro-GNN
GARNET"
DEFENSE ON HOMOPHILIC GRAPHS,0.28125,"Cora-0
83.35 ± 0.66
85.05 ± 0.42
82.61 ± 0.54
73.86 ± 0.53
84.45 ± 0.63
85.56 ± 0.36
82.67 ± 1.89
Cora-10
69.50 ± 1.46
80.37 ± 0.65
81.08 ± 0.52
69.45 ± 0.69
69.35 ± 2.29
77.90 ± 0.69
82.17 ± 0.69
Cora-20
56.28 ± 1.19
74.27 ± 2.11
78.50 ± 2.20
62.44 ± 1.16
64.17 ± 2.00
72.28 ± 1.67
81.34 ± 0.79"
DEFENSE ON HOMOPHILIC GRAPHS,0.284375,"Citeseer-0
72.15 ± 0.75
74.18 ± 0.55
73.09 ± 0.89
68.33 ± 1.17
72.09 ± 1.09
73.29 ± 1.49
74.82 ± 1.07
Citeseer-10
67.38 ± 1.56
72.13 ± 0.61
71.75 ± 0.85
68.29 ± 0.70
67.22 ± 2.60
72.50 ± 0.53
74.25 ± 0.63
Citeseer-20
57.21 ± 1.26
68.44 ± 0.90
62.33 ± 1.08
68.47 ± 0.72
55.30 ± 2.23
71.10 ± 0.72
72.03 ± 0.50"
DEFENSE ON HOMOPHILIC GRAPHS,0.2875,"Pubmed-0
87.16 ± 0.09
87.35 ± 0.13
OOM
84.53 ± 0.08
85.38 ± 0.17
OOM
86.86 ± 0.57
Pubmed-10
81.16 ± 0.13
85.52 ± 0.14
OOM
84.56 ± 0.10
77.45 ± 0.20
OOM
86.24 ± 0.20
Pubmed-20
77.20 ± 0.27
84.18 ± 0.15
OOM
84.30 ± 0.08
71.73 ± 0.32
OOM
85.69 ± 0.26"
DEFENSE ON HETEROPHILIC GRAPHS,0.290625,"4.2
DEFENSE ON HETEROPHILIC GRAPHS"
DEFENSE ON HETEROPHILIC GRAPHS,0.29375,"To evaluate the robustness on heterophilic graphs, we apply both targeted (Nettack) and non-targeted
(Metattack) attacks on Chameleon and Squirrel datasets. Due to the space limitation, we only re-
port the adversarial accuracy under Metattack in Table 3. The results under Nettack are available
in Appendix A.4. As shown in Table 3, all defense baselines are not robust to graph adversarial
attacks on heterophilic graphs. Moreover, the performance of those vaccinated models is in fact
drastically worse than that of the unvaccinated model GPRGNN, a model designed to handle het-
erophilic graphs. Our approach, on the other hand, consistently outperforms all defense baselines
by a large margin. For instance, GARNET achieves 18.06% accuracy improvement over the best
vaccinated model (i.e., GPRSVD-CS) on Chameleon with a 20% perturbation ratio. Moreover,
GARNET also consistently increases adversarial accuracy over GPRGNN. Apart from achieving
the highest accuracy, the accuracy drop of GARNET is much smaller compared to that of base-
lines when increasing the perturbation ratio. Specifically, the accuracy of GARNET drops 1.15%
on Chameleon when increasing the perturbation ratio from 0% to 20%, while the accuracy of base-
lines drops 2.10% ∼18.12%. Thus, GARNET is also robust against graph adversarial attacks on
heterophilic graphs."
DEFENSE ON HETEROPHILIC GRAPHS,0.296875,"Table 3: Averaged node classification accuracy (%) ± std under non-targeted attack (Metattack) with
different perturbation ratio — We denote the evaluated dataset by its name with the perturbation
ratio (e.g., Chameleon-0 means the clean Chameleon graph and Chameleon-10 denotes there are
10% adversarial edges). We bold and underline the first and second highest accuracy, respectively."
DEFENSE ON HETEROPHILIC GRAPHS,0.3,"Dataset
GCN
GPRGNN
GPRSVD-CS
GCNSVD
GNNGuard
Pro-GNN
GARNET"
DEFENSE ON HETEROPHILIC GRAPHS,0.303125,"Chameleon-0
58.16 ± 1.29
61.36 ± 1.00
47.29 ± 1.63
45.08 ± 0.70
58.01 ± 1.57
47.37 ± 1.93
61.11 ± 2.46
Chameleon-10
43.47 ± 0.78
57.55 ± 1.26
47.07 ± 1.21
41.95 ± 0.39
41.75 ± 0.93
38.39 ± 1.35
60.96 ± 1.22
Chameleon-20
39.58 ± 1.56
53.20 ± 0.88
45.12 ± 1.34
40.90 ± 0.77
39.89 ± 1.34
32.24 ± 1.53
59.96 ± 0.84"
DEFENSE ON HETEROPHILIC GRAPHS,0.30625,"Squirrel-0
37.45 ± 0.76
39.51 ± 1.64
31.36 ± 1.87
31.17 ± 0.47
37.46 ± 0.56
32.02 ± 2.11
43.43 ± 1.14
Squirrel-10
26.96 ± 0.30
38.27 ± 0.83
28.25 ± 1.66
25.83 ± 0.32
27.03 ± 0.54
26.03 ± 1.23
42.62 ± 1.09
Squirrel-20
23.94 ± 0.45
35.22 ± 1.20
23.91 ± 1.40
14.90 ± 0.60
23.69 ± 0.59
20.09 ± 3.55
41.97 ± 1.02"
DEFENSE ON LARGE GRAPHS,0.309375,"4.3
DEFENSE ON LARGE GRAPHS"
DEFENSE ON LARGE GRAPHS,0.3125,"Table 4: Averaged accuracy (%) ± std and run time under non-targeted attack (DICE) with 60%
perturbation ratio — We bold the highest accuracy. OOM indicates out of memory."
DEFENSE ON LARGE GRAPHS,0.315625,"ogbn-arxiv
ogbn-products"
DEFENSE ON LARGE GRAPHS,0.31875,"Method
Clean
Adversarial
Time (mins)
Clean
Adversarial
Time (mins)"
DEFENSE ON LARGE GRAPHS,0.321875,"GNNGuard
68.22 ± 1.80
60.46 ± 2.71
22.21
74.82 ± 0.11
66.69 ± 0.12
567.11
GARNET
70.23 ± 0.45
62.89 ± 0.22
1.08 (20×)
81.65 ± 0.11
75.61 ± 0.14
31.27 (18×)"
DEFENSE ON LARGE GRAPHS,0.325,"To demonstrate the scalability of GARNET on large graphs, we evaluate the robustness of GARNET
on the attacked ogbn-arxiv and ogbn-products. Given that existing strongest attacks (Nettack and
Metattack) are not scalable to large graphs, we leverage a less powerful yet more scalable attacking
algorithm called DICE (Waniek et al., 2018), which randomly connects (disconnects) nodes from"
DEFENSE ON LARGE GRAPHS,0.328125,Under review as a conference paper at ICLR 2022
DEFENSE ON LARGE GRAPHS,0.33125,"1
2
3
4
5
Perturbations per Target Node 65 70 75 80"
DEFENSE ON LARGE GRAPHS,0.334375,Adversarial Accuracy Cora
DEFENSE ON LARGE GRAPHS,0.3375,"1
2
3
4
5
Perturbations per Target Node 75 80 85 90"
DEFENSE ON LARGE GRAPHS,0.340625,Adversarial Accuracy
DEFENSE ON LARGE GRAPHS,0.34375,Pubmed
DEFENSE ON LARGE GRAPHS,0.346875,"1
2
3
4
5
Perturbations per Target Node 20 30 40"
DEFENSE ON LARGE GRAPHS,0.35,Adversarial Accuracy
DEFENSE ON LARGE GRAPHS,0.353125,Squirrel
DEFENSE ON LARGE GRAPHS,0.35625,"Pro-GNN
Reduced_Rank + Ada_Filter"
DEFENSE ON LARGE GRAPHS,0.359375,"GPRSVD-CS
Reduced_Rank + Ada_Filter + Ada_Label_Prop (GARNET)"
DEFENSE ON LARGE GRAPHS,0.3625,Ada_Filter
DEFENSE ON LARGE GRAPHS,0.365625,"Figure 2: Comparisons of different kernel combinations in GARNET on Cora, Pubmed, and Squirrel
datasets under Nettack — We denote the reduced-rank approximation kernel, adaptive filter learning
kernel, and adaptive label propagation kernel by Reduced Rank, Ada Filter, and Ada Label Prop,
respectively. Besides, we choose ProGNN and GPRSVD-CS (GPRGNN + SVD + C&S) as strong
baselines, whose curves on Pubmed are missing due to out-of-memory."
DEFENSE ON LARGE GRAPHS,0.36875,"different (same) classes, to perturb the graph structure. To have a challenging defense scenario,
we consider a large perturbation budget for DICE while keeping the overall graph size the same.
Specifically, we use DICE to first randomly delete 30% edges linking nodes from the same class
and then randomly insert 30% edges linking nodes from different classes. We evaluate GNNGuard
as a defense baseline, since all other defense baselines (i.e., GPRSVD-CS, GCNSVD, and Pro-
GNN) run out of memory on these two datasets. Table 4 reports the accuracy and run time on large
graphs under DICE attack, which shows GARNET outperforms GNNGuard by a margin of 2.43%
and 8.92% on ogbn-arxiv and ogbn-products, respectively, with around 20× runtime speedup. We
further show the run time per kernel of GARNET in Appendix A.5."
ABALATION ANALYSIS ON GARNET KERNELS,0.371875,"4.4
ABALATION ANALYSIS ON GARNET KERNELS"
ABALATION ANALYSIS ON GARNET KERNELS,0.375,"To study the effectiveness of our proposed GARNET kernels separately, we conduct experiments by
adding three kernels one by one to see how each kernel affects the adversarial accuracy. Specifically,
we evaluate the model robustness against Nettack with the number of perturbations varying from 1
to 5 per target node. We show results on three datasets (two homophilic datasets Cora & Pubmed
and one heterophilic dataset Squirrel) in Figure 2. When we only train an adaptive graph filter for
node prediction, the adversarial accuracy is comparable to the accuracy of Pro-GNN on homophilic
datasets, while it largely outperforms Pro-GNN on the heterophilic dataset, which shows the adap-
tive filter works effectively on both homophilic and heterophilic graphs. Figure 2 further shows that
adding the reduced-rank approximation kernel results in a much more graceful accuracy degrada-
tion when increasing the budget of adversarial perturbations. For instance, the accuracy achieved by
combining reduced-rank approximation and adaptive filter remains almost the same when increasing
the perturbation from 1 to 5 per target node on Pubmed. This implies that our reduced-rank approx-
imation kernel can effectively remove the high-rank adversarial properties from the input graph,
allowing GARNET to be more resistant to graph adversarial attacks. It is worth noting that exist-
ing SVD-based low-rank methods (e.g., GPRSVD-CS) performs much worse than our reduced-rank
method, which lies in the fact that our reduced-rank kernel preserves much more important spec-
trum information than SVD-based method as analyzed in Section 3.1. Furthermore, incorporating
the adaptive label propagation kernel also helps improve the adversarial accuracy, implying that
propagating node labels by using the adaptive filter can effectively exploit the label information for
further enhancing the quality of node representations under adversarial attacks."
CONCLUSIONS,0.378125,"5
CONCLUSIONS"
CONCLUSIONS,0.38125,"This work introduces GARNET, a spectral approach to robust and scalable graph neural networks.
GARNET first construct a reduced-rank yet sparse approximation of the adversarial graph; then it
trains an adaptive graph filter to obtain refined node representations as well as the learned adaptive
filter that will subsequently guide the process of label propagation to further enhance the quality of
node representations. Results show that GARNET outperforms state-of-the-art defense models on
homophilic and heterophilic graphs under both targeted and non-targeted adversarial attacks."
CONCLUSIONS,0.384375,Under review as a conference paper at ICLR 2022
REPRODUCIBILITY STATEMENT,0.3875,REPRODUCIBILITY STATEMENT
REPRODUCIBILITY STATEMENT,0.390625,"The GARNET source code is available at github.com/gnngarnet/garnet. Besides, we provide our
proofs for Theorems 1 and 2 in Appendices A.1 and A.2, respectively. Moreover, the proof for
Lemma 1 is available in Chien et al. (2021). Finally, the details of all datasets used in our experi-
ments are available in Appendix A.9."
REFERENCES,0.39375,REFERENCES
REFERENCES,0.396875,"Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama. Optuna:
A next-generation hyperparameter optimization framework. In Proceedings of the 25th ACM
SIGKDD international conference on knowledge discovery & data mining, pp. 2623–2631, 2019."
REFERENCES,0.4,"James Baglama and Lothar Reichel. Augmented implicitly restarted lanczos bidiagonalization meth-
ods. SIAM Journal on Scientific Computing, 27(1):19–42, 2005."
REFERENCES,0.403125,"Sergio Casas, Cole Gulino, Renjie Liao, and Raquel Urtasun. Spagnn: Spatially-aware graph neu-
ral networks for relational behavior forecasting from sensor data. In 2020 IEEE International
Conference on Robotics and Automation (ICRA), pp. 9491–9497. IEEE, 2020."
REFERENCES,0.40625,"Adri´an Castell´o, Manuel F Dolz, Enrique S Quintana-Ort´ı, and Jos´e Duato. Analysis of model
parallelism for distributed neural networks. In Proceedings of the 26th European MPI Users’
Group Meeting, pp. 1–10, 2019."
REFERENCES,0.409375,"Eli Chien, Jianhao Peng, Pan Li, and Olgica Milenkovic. Adaptive universal generalized pagerank
graph neural network. In International Conference on Learning Representations, 2021. URL
https://openreview.net/forum?id=n6jl7fLxrP."
REFERENCES,0.4125,"F. R. K. Chung. Spectral Graph Theory. American Mathematical Society, 1997."
REFERENCES,0.415625,"Hanjun Dai, Hui Li, Tian Tian, Xin Huang, Lin Wang, Jun Zhu, and Le Song. Adversarial attack on
graph structured data. In International conference on machine learning, pp. 1115–1124. PMLR,
2018."
REFERENCES,0.41875,"Negin Entezari, Saba A Al-Sayouri, Amirali Darvishzadeh, and Evangelos E Papalexakis. All you
need is low (rank) defending against adversarial attacks on graphs. In Proceedings of the 13th
International Conference on Web Search and Data Mining, pp. 169–177, 2020."
REFERENCES,0.421875,"William L Hamilton. Graph representation learning. Synthesis Lectures on Artifical Intelligence and
Machine Learning, 14(3):1–159, 2020."
REFERENCES,0.425,"Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta,
and Jure Leskovec. Open graph benchmark: Datasets for machine learning on graphs. arXiv
preprint arXiv:2005.00687, 2020."
REFERENCES,0.428125,"Qian Huang, Horace He, Abhay Singh, Ser-Nam Lim, and Austin R Benson.
Combining
label propagation and simple models out-performs graph neural networks.
arXiv preprint
arXiv:2010.13993, 2020."
REFERENCES,0.43125,"Wei Jin, Yao Ma, Xiaorui Liu, Xianfeng Tang, Suhang Wang, and Jiliang Tang. Graph structure
learning for robust graph neural networks. In Proceedings of the 26th ACM SIGKDD International
Conference on Knowledge Discovery & Data Mining, pp. 66–74, 2020."
REFERENCES,0.434375,"Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional net-
works. arXiv preprint arXiv:1609.02907, 2016."
REFERENCES,0.4375,"Ron Levie, Elvin Isufi, and Gitta Kutyniok. On the transferability of spectral graph filters. In 2019
13th International conference on Sampling Theory and Applications (SampTA), pp. 1–5. IEEE,
2019."
REFERENCES,0.440625,"Yao Ma, Xiaorui Liu, Neil Shah, and Jiliang Tang.
Is homophily a necessity for graph neural
networks? arXiv preprint arXiv:2106.06134, 2021."
REFERENCES,0.44375,Under review as a conference paper at ICLR 2022
REFERENCES,0.446875,"Yu A Malkov and Dmitry A Yashunin. Efficient and robust approximate nearest neighbor search
using hierarchical navigable small world graphs.
IEEE transactions on pattern analysis and
machine intelligence, 42(4):824–836, 2018."
REFERENCES,0.45,"Azalia Mirhoseini, Anna Goldie, Mustafa Yazgan, Joe Wenjie Jiang, Ebrahim Songhori, Shen Wang,
Young-Joon Lee, Eric Johnson, Omkar Pathak, Azade Nazi, et al. A graph placement methodol-
ogy for fast chip design. Nature, 594(7862):207–212, 2021."
REFERENCES,0.453125,"Hoang NT, Takanori Maehara, and Tsuyoshi Murata.
Stacked graph filter.
arXiv preprint
arXiv:2011.10988, 2020."
REFERENCES,0.45625,"Benedek Rozemberczki, Carl Allen, and Rik Sarkar. Multi-scale attributed node embedding. Journal
of Complex Networks, 9(2):cnab014, 2021."
REFERENCES,0.459375,"Andrew W Senior, Richard Evans, John Jumper, James Kirkpatrick, Laurent Sifre, Tim Green,
Chongli Qin, Augustin ˇZ´ıdek, Alexander WR Nelson, Alex Bridgland, et al. Improved protein
structure prediction using potentials from deep learning. Nature, 577(7792):706–710, 2020."
REFERENCES,0.4625,"David I Shuman, Sunil K. Narang, Pascal Frossard, Antonio Ortega, and Pierre Vandergheynst.
The emerging field of signal processing on graphs: Extending high-dimensional data analysis to
networks and other irregular domains. IEEE Signal Processing Magazine, 30(3):83–98, 2013.
doi: 10.1109/MSP.2012.2235192."
REFERENCES,0.465625,"Lichao Sun, Yingtong Dou, Carl Yang, Ji Wang, Philip S Yu, Lifang He, and Bo Li. Adversarial
attack and defense on graph data: A survey. arXiv preprint arXiv:1812.10528, 2018."
REFERENCES,0.46875,"Marcin Waniek, Tomasz P Michalak, Michael J Wooldridge, and Talal Rahwan. Hiding individuals
and communities in a social network. Nature Human Behaviour, 2(2):139–147, 2018."
REFERENCES,0.471875,"Huijun Wu, Chen Wang, Yuriy Tyshetskiy, Andrew Docherty, Kai Lu, and Liming Zhu. Adversarial
examples on graph data: Deep insights into attack and defense. arXiv preprint arXiv:1903.01610,
2019."
REFERENCES,0.475,"Zhilin Yang, William Cohen, and Ruslan Salakhudinov. Revisiting semi-supervised learning with
graph embeddings. In International conference on machine learning, pp. 40–48. PMLR, 2016."
REFERENCES,0.478125,"Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec.
Graph convolutional neural networks for web-scale recommender systems. In Proceedings of the
24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 974–
983, 2018."
REFERENCES,0.48125,"Xiang Zhang and Marinka Zitnik. Gnnguard: Defending graph neural networks against adversarial
attacks. arXiv preprint arXiv:2006.08149, 2020."
REFERENCES,0.484375,"Ke Zhou, Hongyuan Zha, and Le Song. Learning social infectivity in sparse low-rank networks
using multi-dimensional hawkes processes. In Artificial Intelligence and Statistics, pp. 641–649.
PMLR, 2013."
REFERENCES,0.4875,"Jiong Zhu, Yujun Yan, Lingxiao Zhao, Mark Heimann, Leman Akoglu, and Danai Koutra. Beyond
homophily in graph neural networks: Current limitations and effective designs. arXiv preprint
arXiv:2006.11468, 2020."
REFERENCES,0.490625,"Jiong Zhu, Junchen Jin, Michael T Schaub, and Danai Koutra. Improving robustness of graph neural
networks with heterophily-inspired designs. arXiv preprint arXiv:2106.07767, 2021."
REFERENCES,0.49375,"Daniel Z¨ugner and Stephan G¨unnemann. Adversarial attacks on graph neural networks via meta
learning. arXiv preprint arXiv:1902.08412, 2019."
REFERENCES,0.496875,"Daniel Z¨ugner, Amir Akbarnejad, and Stephan G¨unnemann. Adversarial attacks on neural networks
for graph data. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge
Discovery & Data Mining, pp. 2847–2856, 2018."
REFERENCES,0.5,Under review as a conference paper at ICLR 2022
REFERENCES,0.503125,"A
APPENDIX"
REFERENCES,0.50625,"A.1
PROOF FOR THEOREM 1"
REFERENCES,0.509375,"Proof. As the graph is undirected, we can perform eigendecomposition on both Anorm and Lnorm.
Let λi, ˆλi, and σi, i = 1, 2, ..., r denote the r smallest eigenvalues of Lnorm, r largest eigenvalues of
Anorm, and r largest singular values of Anorm, respectively. Since Anorm = I −Lnorm, Anorm
and Lnorm share the same set of eigenvectors while their eigenvalues satisfy: ˆλi = 1 −λi, i =
1, 2, ..., r. Moreover, since we assume that the r largest magnitude eigenvalues of Anorm are non-
negative, we have σi =
ˆλi
 = ˆλi, i = 1, 2, ..., r. Thus, we have:"
REFERENCES,0.5125,"V V T = [v1, ..., vr]  "
REFERENCES,0.515625,"|1 −λ1|
...
|1 −λr| "
REFERENCES,0.51875,"[v1, ..., vr]T"
REFERENCES,0.521875,"= [v1, ..., vr]  "
REFERENCES,0.525,"ˆλ1

...
 ˆλr "
REFERENCES,0.528125,"[v1, ..., vr]T"
REFERENCES,0.53125,"= [v1, ..., vr]  "
REFERENCES,0.534375,"σ1
...
σr "
REFERENCES,0.5375,"[v1, ..., vr]T = ˆ
A"
REFERENCES,0.540625,"Since Vi,: is defined as the weighted spectral embedding of node i and ˆ
Ai,j = Vi,:V T
j,:, ˆ
Ai,j corre-
sponds to the dot product score between the weighted spectral embeddings of node i and j, which
completes the proof of the theorem."
REFERENCES,0.54375,"A.2
PROOF FOR THEOREM 2"
REFERENCES,0.546875,"To prove Theorem 2, we first give two Lemmas below:"
REFERENCES,0.55,"Lemma 2. Given a graph adjacency matrix A and degree matrix D, let Anorm = D−1"
REFERENCES,0.553125,2 AD−1
REFERENCES,0.55625,"2 ,
and ˆ
Anorm is the low-rank approximation of Anorm via truncated SVD, we have ∥Anorm∥2 ≤1
and ∥ˆ
Anorm∥2 ≤1"
REFERENCES,0.559375,"The proof for Lamma 2 is trivial since the spectrum of Anorm and ˆ
Anorm lies in [−1, 1] (Chung,
1997).
Lemma 3. Given two matricies M and N such that ∥M∥2 ≤1 and ∥N∥2 ≤1, we have ∥M p −
N p∥2 ≤p∥M −N∥2 for every p ≥0."
REFERENCES,0.5625,The proof for Lamma 3 is available in Levie et al. (2019).
REFERENCES,0.565625,"Next, we formally prove Theorem 2 in the following:"
REFERENCES,0.56875,Proof.
REFERENCES,0.571875,"∥gP (Aclean) −gP (Ar)∥2 = ∥ P
X"
REFERENCES,0.575,"p=0
cpAp
clean − P
X"
REFERENCES,0.578125,"p=0
cpAp
r∥2 = P
X"
REFERENCES,0.58125,"p=1
∥cp(Ap
clean −Ap
r)∥2 ≤ P
X"
REFERENCES,0.584375,"p=1
|cp| ∥Ap
clean −Ap
r∥2"
REFERENCES,0.5875,"Under review as a conference paper at ICLR 2022 ≤ P
X"
REFERENCES,0.590625,"p=1
p |cp| ∥Aclean −Ar∥2 ≤ P
X"
REFERENCES,0.59375,"p=1
p |cp| (∥Aclean −Aadv∥2 + ∥Aadv −Ar∥2) ≤ P
X"
REFERENCES,0.596875,"p=1
p |cp| (ϵ + σr+1)"
REFERENCES,0.6,"The second inequality above is based on Lemmas 2 and 3, while the third inequality is derived by
using the triangle inequality."
REFERENCES,0.603125,"A.3
GARNET ALGORITHM AND COMPLEXITY ANALYSIS"
REFERENCES,0.60625,Algorithm 1: GARNET algorithm
REFERENCES,0.609375,"Input: Adjacency matrix A ∈Rn×n; node feature matrix X ∈Rn×d; node
label matrix Y ∈Rn×c; truncated svd rank r; kNN graph k;
polynomial filter degree P; error correction scale β; train node set
NL; test node set NU; label propagation iteration s; regularization
parameter α
Output: Node embedding matrix ˆZ ∈Rn×c"
REFERENCES,0.6125,"/* Phase1:reduced-rank approximation
*/"
REFERENCES,0.615625,"1 U, S, V T = truncated svd(A, rank = r);"
REFERENCES,0.61875,"2 ˜
A = kNN graph(U
√"
REFERENCES,0.621875,"S, k);
/* Phase2:adaptive filter learning
*/"
REFERENCES,0.625,3 for 1...epochs do
REFERENCES,0.628125,"4
ˆ
X = MLP(X);"
REFERENCES,0.63125,"5
Z = Softmax(PP
p=0 cp ˜
Ap ˆ
X);"
REFERENCES,0.634375,"6
loss = CrossEntropyLoss(Z, Y );"
REFERENCES,0.6375,"7
loss.backward();"
END,0.640625,8 end
END,0.64375,"/* Phase3:adaptive label propagation
*/"
END,0.646875,9 RNL = ZNL −YNL;
END,0.65,10 RNU = 0;
END,0.653125,11 ˆR0 = R;
END,0.65625,12 for i = 0...s do
END,0.659375,"13
ˆRi+1 = α"
END,0.6625,"P
PP
p=0 c∗
p ˜
Ap ˆRi + (1 −α)R;"
END,0.665625,14 end
END,0.66875,15 ˜ZNL = YNL;
END,0.671875,16 ˜ZNU = ZNU + β ˆRNU;
END,0.675,17 ˆZ0 = ˜Z;
END,0.678125,18 for i = 0...s do
END,0.68125,"19
ˆZi+1 = α"
END,0.684375,"P
PP
p=0 c∗
p ˜
Ap ˆZi + (1 −α) ˜Z;"
END,0.6875,20 end
END,0.690625,Under review as a conference paper at ICLR 2022
END,0.69375,"The algorithm of GARNET is shown in Algorithm 1. We further analyze the total complexity
of GARNET on a graph G = (V, E). Specifically, as we mention in Section 3.1, the complex-
ity of the truncated SVD with rank r and approximate kNN graph construction is O(r |E|) and
O(|V| log |V|), respectively. Thus, the complexity of the reduced-rank approximation kernel is
O(r |E| + |V| log |V|). Moreover, the complexity of computing adaptive filter is O(c |E|), where
c is the column dimension of ˆ
X, since we can leverage the sparsity of the graph for computing
˜
A ˆ
X. Similarly, the complexity of adaptive label propagation kernel is O(sP |E|), where s is the
number of steps to iteratively compute ˆR and ˆZ, and P denotes the polynomial degree. Conse-
quently, the overall complexity of GARNET is O((r + c + sP) |E| + |V| log |V|). For the space
complexity of GARNET, the reduced-rank kernel involves forming a sparse kNN graph by building
hierarchical navigable small world (HNSW) graphs that contain O(|V| log |V|) nodes in total and
each node connects to a fixed number of neighbors. Thus, it has O(|V| log |V| + |E|) space com-
plexity, where |V| log |V| represents the space usage of storing the HNSW graphs and |E| denotes
the space usage of the constructed kNN graph. In regard to the adaptive filter learning and label
propagation kernels, we do not explicitly form the graph filter gP (F ) = PP
p=0 cpF p. Instead, we
iteratively left-multiply node embedding matrix ˆ
X and H by F in Equations 3 and 5, respectively,
to leverage the sparsity of F . Since the nonzero elements in F correspond to edges in the reduced-
rank (kNN) graph and the node embedding matrix is in the shape of |V| × d, both adaptive filter
learning and label propagation kernels have O(|E|+d |V|) space complexity. As a result, the overall
space complexity of GARNET is O(|E| + (d + log |V|) |V|)."
END,0.696875,"A.4
ACCURACY ON HETEROPHILIC DATASETS UNDER NETTACK"
END,0.7,"Table 5: Averaged node classification accuracy (%) ± std under targeted attack (Nettack) with
different perturbation ratio — We denote the evaluated dataset by its name with the number of
perturbations (e.g., Chameleon-0 means the clean Chameleon graph and Chameleon-1 denotes there
is 1 adversarial edge perturbation per target node). We bold and underline the first and second
highest accuracy, respectively."
END,0.703125,"Dataset
GCN
GPRGNN
GPRSVD-CS
GCNSVD
GNNGuard
Pro-GNN
GARNET"
END,0.70625,"Chameleon-0
70.66 ± 1.65
71.46 ± 1.92
62.12 ± 3.04
68.29 ± 0.54
74.15 ± 1.26
60.66 ± 3.11
72.89 ± 2.65
Chameleon-1
69.81 ± 1.34
71.02 ± 1.57
61.34 ± 2.93
67.93 ± 0.56
71.82 ± 1.86
59.44 ± 3.13
72.68 ± 1.89
Chameleon-2
68.51 ± 2.37
70.71 ± 1.12
61.09 ± 2.80
68.29 ± 0.77
67.32 ± 2.36
56.44 ± 3.13
72.20 ± 2.31
Chameleon-3
65.73 ± 2.78
70.30 ± 1.28
60.98 ± 2.82
69.15 ± 0.95
66.22 ± 2.37
52.56 ± 3.28
72.17 ± 2.07
Chameleon-4
63.04 ± 3.98
69.87 ± 1.29
60.85 ± 3.31
70.24 ± 0.60
65.73 ± 2.72
51.95 ± 2.59
72.06 ± 2.94
Chameleon-5
57.92 ± 3.69
66.26 ± 1.71
60.37 ± 2.86
67.44 ± 0.78
63.42 ± 3.45
51.10 ± 2.58
71.83 ± 2.11"
END,0.709375,"Squirrel-0
25.46 ± 1.96
41.36 ± 2.87
32.98 ± 2.36
31.73 ± 1.18
26.09 ± 2.35
20.45 ± 4.52
44.91 ± 1.53
Squirrel-1
25.09 ± 2.97
41.27 ± 3.16
32.63 ± 0.87
31.00 ± 1.11
23.46 ± 2.53
19.82 ± 4.23
43.55 ± 1.79
Squirrel-2
25.00 ± 2.20
41.09 ± 2.14
32.05 ± 1.05
30.99 ± 1.03
22.09 ± 1.36
18.82 ± 4.17
44.09 ± 2.35
Squirrel-3
24.73 ± 1.76
40.98 ± 2.72
32.00 ± 1.66
30.18 ± 1.67
22.00 ± 1.36
17.36 ± 4.06
44.18 ± 2.26
Squirrel-4
24.09 ± 1.15
40.25 ± 2.82
31.45 ± 1.38
30.00 ± 0.91
21.18 ± 1.91
16.36 ± 4.16
43.73 ± 1.62
Squirrel-5
23.72 ± 1.09
39.45 ± 2.36
31.20 ± 1.84
29.54 ± 2.51
21.09 ± 1.86
16.27 ± 3.78
43.64 ± 1.53"
END,0.7125,"As shown in Table 5, the four vaccinated baseline models, i.e., GPRSVD-CS, GCNSVD, GN-
NGuard, and Pro-GNN, only achieve comparable or even worse accuracy than the unvaccinated
model GPRGNN in most cases, which indicates that those defense models lose its robustness on
heterophilic graphs. In contrast, GARNET largely outperforms all baselines in most scenarios. For
instance, the accuracy of GARNET is 12.18% higher than the accuracy of the best baseline (i.e.,
GPRSVD-CS) on Squirrel with 3 perturbations per target node. Moreover, the accuracy drop of
GARNET when increasing the number of perturbations per target node is only 1.06% and 1.27% on
Chameleon and Squirrel, respectively, which indicates that GARNET is also resistant to the targeted
attack on heterophilic graphs."
END,0.715625,"A.5
RUN TIME PER KERNEL IN GARNET"
END,0.71875,"Table 6 reports the run time of each sub-kernel in GARNET on Cora, Pubmed, ogbn-arxiv, and
ogbn-products. It shows that training the adaptive graph filter is the most time consuming kernel in
GARNET. It is also worth mentioning that the run time of truncated SVD and approximate kNN"
END,0.721875,Under review as a conference paper at ICLR 2022
END,0.725,"Table 6: Run time (secs) of each kernel in GARNET— We decompose the reduced-rank approxima-
tion kernel into truncated SVD (TSVD) and approximate kNN graph construction (AKNN) steps.
In addition, we denote the adaptive filter learning kernel and adaptive label propagation kernel by
Ada Filter, and Ada Label Prop, respectively."
END,0.728125,"Dataset
TSVD
AKNN
Ada Filter
Ada Label Prop
Total"
END,0.73125,"Cora
0.09
0.10
0.76
0.05
1.00
Pubmed
0.25
0.72
1.60
0.05
2.62
ogbn-arxiv
6.04
17.92
40.49
0.23
64.68
ogbn-products
368.37
363.32
1139.46
5.21
1876.36"
END,0.734375,"graph construction is less than 7 minutes on ogbn-products, which contains 2 million of nodes and
60 million edges. This is consistent with their near-linear complexity analyzed in Section 3.1."
END,0.7375,"A.6
ABLATION STUDY ON KNN GRAPH CONSTRUCTION"
END,0.740625,10 20 30 40 50 60 70 80 90100 k 75 80 85
END,0.74375,Adversarial Accuracy
END,0.746875,Metattack w/ 10% Perturbation
END,0.75,10 20 30 40 50 60 70 80 90100 k 70 75 80 85
END,0.753125,Adversarial Accuracy
END,0.75625,Mettack w/ 20% Perturbation
END,0.759375,"Cora
Citeseer
Pubmed"
END,0.7625,Figure 3: Ablation Study on kNN Graph.
END,0.765625,"To evaluate the sensitivity of GARNET to approximate kNN (AKNN) graph construction, we show
the adversarial accuracy of GARNET with different k values for constructing AKNN graphs in
Figure 3, which indicates that the accuracy of GARNET does not change too much when varying
k value within the range of [30, 100], especially on the Cora and Pubmed datasets. Hence, we
recommend choosing k = 50 ∼80 for the AKNN graph construction."
END,0.76875,"A.7
GRAPH RANK UNDER ADVERSARIAL ATTACKS"
END,0.771875,"To verify that applying adversarial attacks on a graph indeed increases its rank, we evaluate how the
graph rank changes when increasing the perturbation ratio of Metattack. Specifically, we evaluate
the graph rank growth rate on three homophilic graphs Cora, Citeseer, and Pubmed, as well as one
heterophilic graph Chameleon. Figure 4 shows that the graph ranks grow with increasing perturba-
tion ratios (0% to 25%). For the results showing that other graph adversarial attacks increase graph
ranks, we refer to Figure 3 in Entezari et al. (2020) and Figure 1 in Jin et al. (2020)."
END,0.775,"A.8
GRAPH RANK COMPARISON"
END,0.778125,"We compute the rank of each adversarial graph under Metattack with the perturbation ratio vary-
ing from 5% to 25%, and compare the result with its corresponding two low-rank graphs obtained
via our reduced-rank approximation and truncated SVD (TSVD) respectively. Note that we use the"
END,0.78125,Under review as a conference paper at ICLR 2022
END,0.784375,"0
5
10
15
20
25
Perturbations Ratio (%) 0 5 10 15 20 25 30"
END,0.7875,Rank Growth Rate (%)
END,0.790625,Graph Rank under Metattack
END,0.79375,"Cora
Citeseer
Pubmed
Chameleon"
END,0.796875,Figure 4: Graph rank growth under Metattack.
END,0.8,"5
10
15
20
25
Perturbation Ratio (%) 0 1000 2000"
END,0.803125,Rank of Adjacency Matrix Cora
END,0.80625,"5
10
15
20
25
Perturbation Ratio (%) 0 500 1000 1500"
END,0.809375,Rank of Adjacency Matrix
END,0.8125,Chameleon
END,0.815625,"Input Adversarial Graph
Reduced-Rank Graph
TSVD Graph"
END,0.81875,"Figure 5: Comparisons of the ranks on input adversarial graph, our reduced-rank graph, and TSVD-
based low-rank graph on Cora and Chameleon datasets."
END,0.821875,"same r = 50 largest singular values and their corresponding singular vectors for our reduced-rank
kernel and TSVD. Figure 5 shows that the TSVD-based method aggressively reduces the graph rank
to 50 and thus loses lots of useful spectral information. In contrast, our reduced-rank graph only re-
moves high-rank adversarial graph properties while keeping rest of meaningful spectral information,
demonstrating the effectiveness of the proposed reduced-rank approximation scheme."
END,0.825,"A.9
EXPERIMENTAL SETUP"
END,0.828125,"A.9.1
HYPERPARAMETER SETTINGS OF GARNET"
END,0.83125,"We show the hyperparameters of the reduced-rank approximation kernel and the adaptive filter learn-
ing kernel on different datasets under Nettack (1 perturbation per node), Metattack (10% perturba-
tion ratio), and DICE (60% perturbation ratio) in Table 7. For the adaptive label propagation kernel,
we do not manually tune hyperparameters but instead leverage Optuna (Akiba et al., 2019) to opti-
mize the hyperparameters such as the scale β for error correction based on the validation set, since
this kernel is fast to compute. We refer to github.com/gnngarnet/garnet for details of hyperparame-
ters used in the adaptive label propagation kernel. We run all GNN training with full batch."
END,0.834375,"A.9.2
DATASET DETAILS"
END,0.8375,"Table 8 shows the statistics of the datasets used in our experiments. We follow Zhu et al. (2020)
to compute the homophily score per dataset (lower score means more heterophilic). As in Jin et al."
END,0.840625,Under review as a conference paper at ICLR 2022
END,0.84375,"Table 7: Summary of hyperparameters in GARNET— Apart from the notations r, k, and δ men-
tioned in Section 3.1, we denote polynomial degree, learning rate, number of epochs, weight decay,
dropout, and coefficient initialization in the adaptive filter learning kernel by P, lr, epochs, wd, dp,
and c, respectively."
END,0.846875,"Reduced-Rank Approximation
Adaptive Filter Learning"
END,0.85,"Dataset
r
k
δ
P
lr
epochs
wd
dp
c"
END,0.853125,"Cora-Nettack
50
50
0.05
10
0.01
50
0.0005
0.5
0.9
Cora-Metattack
50
50
0.05
10
0.01
50
0.0005
0.5
0.9
Citeseer-Nettack
50
30
0.003
10
0.01
50
0.0005
0.5
0.9
Citeseer-Metattack
50
60
0.05
10
0.01
50
0.0005
0.5
0.9
Pubmed-Nettack
50
80
0.05
10
0.01
150
0.0005
0.5
0.9
Pubmed-Metattack
50
80
0.05
10
0.01
150
0.0005
0.5
0.9
Chameleon-Nettack
50
60
0.003
10
0.05
300
0.0
0.5
0.9
Chameleon-Metattack
50
60
0.003
10
0.05
300
0.0
0.5
0.9
Squirrel-Nettack
50
50
0.003
10
0.1
300
0.0
0.5
0.3
Squirrel-Metattack
50
50
0.003
10
0.1
300
0.0
0.5
0.3
ogbn-arxiv-DICE
50
50
0.00003
10
0.01
500
0.0
0.0
0.9
ogbn-products-DICE
50
50
0.00003
5
0.01
300
0.0
0.0
0.9"
END,0.85625,Table 8: Statistics of datasets used in our experiments.
END,0.859375,"Dataset
Type
Homophily Score
Nodes
Edges
Classes
Features"
END,0.8625,"Cora
Homophily
0.80
2, 485
5, 069
7
1, 433
Citeseer
Homophily
0.74
2, 110
3, 668
6
3, 703
Pubmed
Homophily
0.80
19, 717
44, 324
3
500
Chameleon
Heterophily
0.23
2, 277
62, 792
5
2, 325
Squirrel
Heterophily
0.22
5, 201
396, 846
5
2, 089
ogbn-arxiv
Homophily
0.66
169, 343
1, 166, 243
40
128
ogbn-products
Homophily
0.81
2, 449, 029
61, 859, 140
47
100"
END,0.865625,"(2020), we extract the largest connected components of the original Cora, Citeseer, and Pubmed
datasets (Yang et al., 2016) for the adversarial evaluation, with the same train/validation/test split.
For Chameleon and Squirrel (Rozemberczki et al., 2021), we keep the same split setting as Chien
et al. (2021). Finally, we follow the split setting of Open Graph Benchmark (OGB) (Hu et al., 2020)
on ogbn-arxiv and ogbn-products."
END,0.86875,"In addition, we follow Jin et al. (2020) for the selection of target nodes on Cora, Citeseer, and
Pubmed under Nettack. For the Chameleon and Squirrel datasets under Nettack, we choose target
nodes that have degrees within the range of [20, 50] and [20, 140], respectively. In regard to non-
targeted attacks (i.e., Metattack and DICE), we choose nodes in the test set as target nodes for all
datasets."
END,0.871875,"A.9.3
HARDWARE INFORMATION"
END,0.875,"For ogbn-arxiv and ogbn-products, we run experiments on a Linux machine with an Intel Xeon
Silver 4214 CPU (8 cores @ 2.20GHz) and 4 NVIDIA RTX A6000 GPUs (48 GB memory per
GPU). For the rest of the datasets, we conduct all experiments on a Linux machine with an Intel
Xeon Gold 5218 CPU (8 cores @ 2.30GHz) CPU and an NVIDIA RTX 2080 Ti GPU (11 GB
memory per GPU)."
END,0.878125,"A.10
ABLATION STUDY ON SPECTRAL EMBEDDING"
END,0.88125,"To show that the spectral embedding used in our reduced-rank approximation kernel not only con-
tributes to low-rank approximation but also captures key structural information per node, we com-
pare our spectral embedding method, which uses top 50 largest singular values and corresponding
singular vectors of adjacency matrix, with the vanilla spectral embedding method that leverages the
top 50 smallest eigenvalues and eigenvectors of Laplacian matrix. As shown in Figure 6, the singu-"
END,0.884375,Under review as a conference paper at ICLR 2022
END,0.8875,"1
2
3
4
5
Perturbations per Target Node 65 70 75 80"
END,0.890625,Adversarial Accuracy Cora
END,0.89375,"1
2
3
4
5
Perturbations per Target Node 65 70 75 80"
END,0.896875,Adversarial Accuracy
END,0.9,Citeseer
END,0.903125,"1
2
3
4
5
Perturbations per Target Node 88 89 90 91"
END,0.90625,Adversarial Accuracy
END,0.909375,Pubmed
END,0.9125,"Vanilla Spectral Embedding
SC-based Spectral Embedding (ours)"
END,0.915625,"Figure 6: GARNET accuracy comparisons of using vanilla spectral embedding and singular com-
ponents (SC) based spectral embedding in the reduced-rank approximation kernel."
END,0.91875,"lar component (SC) based spectral embedding outperforms the vanilla spectral embedding in most
cases. The underlying reason is that the largest singular components of adjacency matrix correspond
to both smallest and largest eigenvalues and their corresponding eigenvectors of Laplacian matrix,
which capture global and local information, respectively (Shuman et al., 2013)."
END,0.921875,"A.11
REDUCED-RANK APPROXIMATION VS. TRUNCATED SVD"
END,0.925,Algorithm 2: Reduced-rank approximation algorithm (Ours)
END,0.928125,"Input: Adjacency matrix A ∈Rn×n; kNN graph k; sparsification
threshold δ
Output: Reduced-rank adjacency matrix ˜
A ∈Rn×n"
END,0.93125,"/* Obtain singular components via TSVD
*/"
END,0.934375,"21 U, S, V T = truncated svd(A, rank = 50);"
END,0.9375,"/* Node spectral embedding
*/"
END,0.940625,"22 X = U
√"
END,0.94375,"S;
/* Approximate kNN graph construction
*/"
END,0.946875,"23 ˆ
A = kNN graph(X, k);
/* Drop edges with node similarity scores lower
than δ
*/"
END,0.95,"24 ˜
A = sparsification( ˆ
A, δ);"
END,0.953125,Algorithm 3: Truncated SVD based low-rank approximation algorithm
END,0.95625,Input: Adjacency matrix A ∈Rn×n
END,0.959375,"Output: Reduced-rank adjacency matrix ˜
A ∈Rn×n"
END,0.9625,"25 U, S, V T = truncated svd(A, rank = 50);"
END,0.965625,"26 ˜
A = USV T;"
END,0.96875,"Algorithms 2 and 3 show the difference between our reduced-rank approximation (RRA) method and
truncated SVD (TSVD) low-rank approximation method. Note that the low-rank adjacency matrix
˜
A produced by TSVD method has two issues: (1) ˜
A is typically a dense matrix corresponding to a
(nearly) complete graph, which cannot scale to large graphs; (2) ˜
A is an extremely low-rank matrix
(e.g., rank = 50) that is two orders of magnitude smaller than the rank of input graph, as shown in
Figure 5, which loses too much important spectral information."
END,0.971875,"In contrast, our RRA algorithm only involves a sparse adjacency matrix, whose density is roughly
k
n with k ≪n, where k is the number of neighbors per node in kNN graph and n is the number of"
END,0.975,Under review as a conference paper at ICLR 2022
END,0.978125,"nodes in the graph. Moreover, the RRA algorithm produces a graph that only removes the highest
singular components and preserves most of the important spectral information, as empirically shown
in Figure 5."
END,0.98125,"Table 9: Averaged node classification accuracy (%) ± std under targeted attack (Nettack) with
different perturbation ratio — We denote the evaluated dataset by its name with the number of
perturbations (e.g., Cora-1 denotes there is 1 adversarial edge perturbation per target node)."
END,0.984375,"Dataset
GCN-SVD
GCN-RRA"
END,0.9875,"Cora-1
70.36 ± 1.63
79.75 ± 2.35
Cora-2
65.66 ± 2.76
79.69 ± 1.50
Cora-3
61.20 ± 1.93
74.42 ± 2.06
Cora-4
57.34 ± 3.46
60.60 ± 2.67
Cora-5
55.30 ± 2.25
59.04 ± 2.05"
END,0.990625,"Citeseer-1
75.23 ± 2.67
77.30 ± 2.80
Citeseer-2
60.15 ± 2.29
75.23 ± 2.14
Citeseer-3
58.89 ± 5.28
59.84 ± 3.43
Citeseer-4
51.74 ± 7.96
57.94 ± 5.66
Citeseer-5
45.07 ± 2.77
53.18 ± 3.61"
END,0.99375,"Pubmed-1
84.46 ± 0.28
89.03 ± 0.68
Pubmed-2
82.68 ± 0.46
88.92 ± 0.45
Pubmed-3
81.34 ± 0.68
88.50 ± 0.45
Pubmed-4
82.41 ± 0.54
88.44 ± 0.64
Pubmed-5
79.56 ± 0.48
88.12 ± 0.86"
END,0.996875,"To further confirm that our RRA method produces a graph with much higher quality than the low-
rank graph generated by truncated SVD, we compare the accuracy of GCN-SVD with that of GCN-
RRA. As shown in Table 9, GCN-RRA consistently outperforms GCN-SVD with accuracy improve-
ment up to 15.08%, which indicates that the important spectral information that RRA preserves
indeed largely improves the adversarial accuracy."
