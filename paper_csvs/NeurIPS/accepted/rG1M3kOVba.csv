Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0037174721189591076,"Federated Learning (FL) allows machine learning models to train locally on in-
dividual mobile devices, synchronizing model updates via a shared server. This
approach safeguards user privacy; however, it generates a heterogeneous training
environment due to the varying performance capabilities of devices. As a result,
“straggler” devices with lower performance often dictate the overall training time.
In this work, we aim to alleviate this performance bottleneck due to stragglers by
dynamically load balancing the training across the system. We introduce Invariant
Dropout, a method that extracts a sub-model based on the weight update thresh-
old, thereby minimizing potential impacts on accuracy. Building on this dropout
technique, we develop an adaptive training framework, Federated Learning using
Invariant Dropout (FLuID). FLuID offers a lightweight framework for sub-model
extraction to regulate the computational intensity, thereby reducing the load on
straggler devices without affecting model quality. Our method leverages neuron
updates from non-straggler devices to construct a tailored sub-model for each
straggler based on client performance profiling. Unlike prior work, FLuID can
dynamically adapt to changes in stragglers as runtime conditions shift. We evaluate
FLuID using five real-world mobile clients. The evaluations show that Invariant
Dropout maintains baseline model efficiency while alleviating the performance
bottleneck of stragglers through a dynamic and lightweight runtime approach. 1"
INTRODUCTION,0.007434944237918215,"1
Introduction"
INTRODUCTION,0.011152416356877323,"Federated Learning (FL) enables machine learning models to train on edge and mobile devices,
synchronizing the model updates via a common server [SB09, SVHN10, LSTS20, ZBW+22]. This
method ensures user privacy as local data remains on the device, minimizing the risk of data
breaches, leaks, or unauthorized access to sensitive information in the cloud [MMR+17]. However,
FL introduces heterogeneity due to varying performance capabilities of the participating devices.
Consequently, straggler devices with lower computational and network performance often dictate the
overall training latency and throughput, as shown in Figure 1."
INTRODUCTION,0.01486988847583643,"Previous research mitigates the impact of stragglers through asynchronous aggregation, where
clients can communicate and update the server model independently and asynchronously [CCA+21,
CNSR20, XKG19]. While this approach alleviates some of the detrimental effects of stragglers, it
can introduce staleness into the global model. This occurs because the gradients used to update the
server model may rely on outdated parameters, resulting in inaccuracies that have the potential to
slow down convergence and reduce overall accuracy [BHS20, CCA+21, WUH+21, HBGS19]."
INTRODUCTION,0.01858736059479554,"Other research proposes eliminating updates from slower devices entirely. [KMA+19]. However, this
approach can introduce training bias, as it effectively excludes certain clients and their respective data."
INTRODUCTION,0.022304832713754646,1Source code is available at https://github.com/iwang05/FLuID
INTRODUCTION,0.026022304832713755,"Figure 1: Straggler’s impact on FL performance. In synchronous FL, all clients, including stragglers,
participate in global model aggregation."
INTRODUCTION,0.02973977695167286,"To ensure the contribution of all devices, recent works in this area employ a dropout technique where
the stragglers only train a subset of the global model [HLA+21, MGZP22]. The overall accuracy
of the model is determined by the subset of neurons that are dropped from the global model. Thus,
previous work alleviates the training load on stragglers by either incurring training bias, creating
performance-centric sub-models, or entirely reconstructing the sub-model."
INTRODUCTION,0.03345724907063197,"Our paper proposes a novel dropout technique called Invariant Dropout, which identifies ""invariant""
neurons—those that train quickly and show little variation during training. We observe that the
training (computational load) and transfer (communication load) of these invariant neurons to and
from the straggler devices contribute minimally to the efficiency of the global model. Thus, they can be
dropped. We observe that after only 30% of the training iterations, 15%-30% of the neurons become
invariant across CIFAR10 [Kri09], and LEAF datasets FEMNIST, and Shakespeare [CDW+18].
Building on this insight, we develop a dynamic framework called Federated Learning using Invariant
Dropout (FLuID), which adjusts the sub-model size based on both the magnitude of neuron updates
and the computational capabilities of the client devices. In addition to introducing a new dropout
technique, FLuID, unlike prior work, periodically calibrates the sub-model size during runtime to
account for changes in stragglers due to factors like low battery or network issues."
INTRODUCTION,0.03717472118959108,"Overall, we face two challenges in building FLuID — identifying invariant neurons and establishing a
dynamic lightweight method for straggler identification and sub-model size determination at runtime.
FLuID addresses the first challenge by leveraging the non-straggler clients, which typically outnumber
stragglers and train on the entire model, to identify invariant neurons. The server is not used for this
purpose as it receives updates from stragglers running a sub-model. For the second challenge, FLuID
uses a drop-threshold, below which neurons are dropped, allowing dynamic sub-model determination
for each straggler. By profiling client training times and identifying stragglers during the initial
epochs of each calibration step, FLuID can incrementally adjust the drop-threshold until the number
of selected neurons matches the target sub-model size for stragglers."
INTRODUCTION,0.040892193308550186,"Our evaluation of FLuID on various models, datasets, and real-world mobile devices shows an up
to 18% speedup in performance. Additionally, it improves training accuracy by a maximum of 1.4
percentage points over the state-of-the-art Ordered Dropout, all while mitigating the computational
performance overheads caused by straggler devices."
RELATED WORK,0.04460966542750929,"2
Related Work"
RELATED WORK,0.048327137546468404,"In the domain of heterogeneous client optimization, several prior work have tried to mitigate the
effects of stragglers."
RELATED WORK,0.05204460966542751,"Dropout techniques. Federated Dropout [CKMT18, RKPH22] randomly drops portions of the global
model, sending a sub-model to the slower devices. However, this can potentially impact accuracy.
Subsequent work, Ordered Dropout [HLA+21, DDT21], mitigates this accuracy loss by regulating
which neurons are dropped, either from the left or right portions of the global model. Other methods,
such as those outlined in [MGZP22], use a low-rank approximation to identify over-parameterized
neurons and generate tailored sub-models. Despite these advancements, none of these works consider
the individual contribution of each neuron while creating a sub-model. In contrast, our work not only
introduces a novel dropout technique that takes into account the contribution of each neuron but also"
RELATED WORK,0.055762081784386616,"provides a framework capable of dynamically identifying slower devices and adjusting the dropout
rate accordingly."
RELATED WORK,0.05947955390334572,"Server offloading strategies using split learning. The approach proposed by [WUH+21] employs
split learning to offload part of the model to the server, while [HAA20] transfers their knowledge
to a larger server-side CNN. [UWH+21] focuses on device mobility during Federated Learning,
offloading training to edge servers. Finally, [WQR+22] introduces a compression method for split
learning. However, unlike these methods, Invariant Dropout does not require data transfer out of
the device and into the server, instead conducts all training on client devices. Nonetheless, if data
movement was a possibility, Invariant Dropout can be stacked on top of these techniques to determine
which part of the model needs to be offloaded to the server."
RELATED WORK,0.06319702602230483,"Communication Optimizations. To reduce learning time, [HWL20] proposes an online learning
approach that reduces the communication overheads of Federated Learning by adaptively sparsifying
gradients. [CSP+21] introduces a Federated Learning framework utilizing a probabilistic device
selection method to improve FL convergence time. [XFD+21] proposes a framework incorporating
overhead reduction techniques for efficient training on resource-limited edge devices, including
pruning and quantization. Unlike these works, Invariant Dropout avoids both communication and
computation overhead by dropping the least contributing ""invariant"" neurons, presenting a new insight
compared to these prior works."
RELATED WORK,0.06691449814126393,"Model Pruning. PruneFL [JWK+22] introduces an approach to dynamically select model sizes
during FL and reduce communication and computation overhead, thereby minimizing training time.
Work in [MSA+21] prunes the global model for slower clients by excluding neurons with no or
small activations. These approaches either generate a single sub-model for all clients, including
non-stragglers, to train on or generate a static sub-model for the entire training process which can
result in the stragglers permanently losing the opportunity to contribute to certain parts of the model.
In contrast, Invariant Dropout enables the generation of multiple sub-models with various resource
budgets and dynamically chooses a sub-model for each round based on current neuron contribution."
RELATED WORK,0.07063197026022305,"Coded Federated Learning. CodedPaddedFL and CodedSecAgg [SKRA21] utilize coding strategies
to mitigate the impact of slower devices. By sharing an encoded version of their data with other
clients, both schemes introduce redundancy in the client’s local data. Therefore, during training, the
computation of a subset of clients is sufficient to train the global model and the computations of
straggling clients can be discarded without loss of information. While CodedPaddedFL combines
one-time padding with gradient codes, codedSecAgg is based on Shamir’s secret sharing. Unlike
these methods, Invariant Dropout allows each client to keep their data local."
RELATED WORK,0.07434944237918216,"Training a Global Family of Models. SuperFed [KALT23] proposes co-training of multiple models
to reduce training costs. It achieves this by sending subnetworks of different sizes to all clients. In
contrast, FLuID focuses on optimizing the performance of stragglers by mostly training clients on the
full global model and a smaller percentage (stragglers) on sub-models tailored to their capabilities."
BACKGROUND AND MOTIVATION,0.07806691449814127,"3
Background and Motivation"
CHALLENGES IN FEDERATED LEARNING,0.08178438661710037,"3.1
Challenges in Federated Learning"
CHALLENGES IN FEDERATED LEARNING,0.08550185873605948,"In Federated learning’s synchronous aggregation protocols, the server hosts a global model and
regularly aggregates updates from clients, which are then redistributed to clients [CCA+21]. Thus,
system heterogeneity remains a significant challenge in FL [DTS+22, HLA+21, LSTS20]. As shown
in Figure 2a, we observe significant differences in training times across five Android-based mobile
phones, from 2018 to 2020, engaged in Federated Learning without any dropout mechanism in
place. Depending on the dataset and machine learning model, training time can vary significantly,
with differences of up to twofold across datasets such as CIFAR10, FEMNIST, and Shakespeare.
The standard deviation between the training times of each client is 0.5, 22, and 21 seconds for
FEMNIST, CIFAR10, and Shakespeare, respectively. This highlights the real-world challenge of
system heterogeneity, where different devices, even if they are of a similar class (e.g., Android-based
mobile phones) with just a few years’ difference, can offer dramatically different computational
performance. Furthermore, we find the performance of mobile devices can fluctuate over time due to
varying network bandwidth and resource availability. In response to these observations, we develop"
CHALLENGES IN FEDERATED LEARNING,0.08921933085501858,"LG
Velvet 5G"
CHALLENGES IN FEDERATED LEARNING,0.09293680297397769,Google
CHALLENGES IN FEDERATED LEARNING,0.09665427509293681,Pixel 3
CHALLENGES IN FEDERATED LEARNING,0.10037174721189591,"Samsung
Galaxy S9"
CHALLENGES IN FEDERATED LEARNING,0.10408921933085502,"Samsung
Galaxy S10"
CHALLENGES IN FEDERATED LEARNING,0.10780669144981413,Google
CHALLENGES IN FEDERATED LEARNING,0.11152416356877323,Pixel 4 100 101 102
CHALLENGES IN FEDERATED LEARNING,0.11524163568773234,Per Epoch Training Time in Seconds
CHALLENGES IN FEDERATED LEARNING,0.11895910780669144,(log scale)
CHALLENGES IN FEDERATED LEARNING,0.12267657992565056,"Shakespeare
CIFAR10
FEMNIST"
CHALLENGES IN FEDERATED LEARNING,0.12639405204460966,"(a) The per-epoch training time of client devices in
log scale."
CHALLENGES IN FEDERATED LEARNING,0.13011152416356878,"(b) Compared accuracy of Ordered Dropout with base-
line implementation of Federated Learning."
CHALLENGES IN FEDERATED LEARNING,0.13382899628252787,"Figure 2: (a) Performance variation across mobile devices (in log scale), (b) accuracy implications of
prior dropout (static) techniques."
CHALLENGES IN FEDERATED LEARNING,0.137546468401487,"FLuID, a system designed to dynamically identify stragglers and adjust the training load to balance
performance with non-straggler devices."
DROPOUT TECHNIQUES,0.1412639405204461,"3.2
Dropout Techniques"
DROPOUT TECHNIQUES,0.1449814126394052,"Model dropout is a technique that involves sending a subset of the global model, known as a sub-
model, to stragglers for load balancing. There are two state-of-the-art proposals in this space:
Federated Dropout [CKMT18] and Ordered Dropout from FjORD [HLA+21]. Federated Dropout
randomly drops neurons, simplifying the selection of sub-models, but reducing the global model’s
accuracy. In contrast, Ordered Dropout systematically drops neurons by maintaining order within
the sub-model. These works demonstrate that the sub-model’s neuron selection is crucial for the
global model’s accuracy. In the context of this work, ""neurons"" refer to filters in convolutional (CONV)
layers, activations in fully-connected (FC) layers, and hidden units in Long Short-Term Memory
(LSTM) [HS97] layers."
DROPOUT TECHNIQUES,0.14869888475836432,"Accuracy Implications with dropout: Figure 2b compares the testing accuracy of a non-dropout
vanilla Federated Learning (FL) implementation with Ordered Dropout. This comparison is per-
formed using five mobile devices, one of which is a straggler, across three different datasets: CI-
FAR10 [Kri09], FEMNIST, and Shakespeare [CDW+18]. As the sub-model size decreases, we
observe that across all three datasets and machine learning models, Ordered Dropout experiences up
to a 2.5 percentage point drop in accuracy. We vary the sub-model size from 0.5 (representing 50%
of the global model) to 1 (the entire model). The results with 50-100 clients and 20% of them being
stragglers are provided in Section 6.1."
INVARIANT DROPOUT,0.1524163568773234,"4
Invariant Dropout"
INVARIANT DROPOUT,0.15613382899628253,"Invariant Dropout enables stragglers to only train on a sub-model consisting of neurons that ‘vary’
over time and contribute to the global model. Invariant dropout achieves this by selecting a subset
(i) of sub-models (si) from a total sub-model distribution (S), where each sub-model represents a
different number of neurons and thus varies in compute and memory requirements. Appendix A.1
illustrates the temporal variation in the percentage of invariant neurons in the evaluated models. Note
that all clients including the straggler still perform inference on the full model."
PROPOSED DROPOUT MECHANISM,0.15985130111524162,"4.1
Proposed dropout mechanism"
PROPOSED DROPOUT MECHANISM,0.16356877323420074,"Invariant Dropout selects a sub-model from a set of sub-models, S, composed of m total sub-models,
denoted as S = s1, s2, ..., sm. Each sub-model si contains neuron layers a1, a2, ..., ak. The size
of the sub-model corresponds to a dropout rate r that is based on the drop-threshold th for the
dropout mechanism. Given a change in neuron value, g = ∆a, we can select the sub-model si =
{a1, a2, ..., ak} where the updates in neurons within the sub-model satisfy g ≥th ∀aj ∈si and 1 ≤
j ≤k. FLuID, which we describe below, selects si such that the compute utilization and memory
footprint can effectively mitigate the inefficiency of the straggler."
PROPOSED DROPOUT MECHANISM,0.16728624535315986,"Next, we assume that the system includes C clients with T stragglers and N non-stragglers. T and
N are exclusive and independent subsets of C, where T ∪N = C and T ∩N = ϕ. Invariant Dropout
maintains a dropout rate r ∈(0, 1] per layer across the T stragglers. However, the complexity of
selecting aj(t + 1) will vary with each sub-model si. To reduce the computational overhead of
selecting the appropriate sub-model, ID leverages non-straggler clients to provide directions on the
set of aj(t + 1). The server computes over a subset of potential sub-models si to select the one with
the maximum updates to the neurons."
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.17100371747211895,"4.2
Variance in Gradients with Invariant Dropout"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.17472118959107807,"Consider C clients participating in Federated Learning. The training data is represented as xcc = 1C,
where c denotes one client, and each client has a corresponding loss function fcC
c=1. Learning
minimizes the loss function using the following optimization: f(w) := 1"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.17843866171003717,"C
P c = 1Cfc(w), where
wt+1 = wt −ηt(g(wt))."
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.1821561338289963,"Invariant Dropout can be viewed as a sparse stochastic gradient vector, where each gradient has a
certain probability of being dropped. The gradient vector is denoted as G = [g1, g2, ..., gk] where
g ∈R and each gradient has a probability of being retained and transmitted across the network,
represented as [p1, p2, ..., pk]. The sparse vector for the stragglers is represented as Gs. The variance
of the ID-based gradient vector can be represented as E(G2
s) = Pk
i=1(g2
i pi) [WWLZ18, XYXC21].
The variance of the dropout vector is a small factor deviation from the non-dropout gradient vector
represented as follows: min k
X"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.18587360594795538,"i=1
pi : k
X"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.1895910780669145,"i=1
(g2
i pi) = (1 + ϵ) k
X"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.19330855018587362,"i=1
g2
i
(1)"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.1970260223048327,"Invariant Dropout drops weights based on the g = ∆a gradient across epochs. Thus, the probability
of a gradient not getting dropped (pi) is inversely proportional to the dropout rate r. This implies if
|gi| > |gj| then pi > pj. Let’s assume that the top-k magnitude of gradients are not dropped. Hence if
G = [g1, g2, ..., gm] is sorted, then G = [g1, g2, ..., gk] has a p = 1, whereas G = [gk+1, gk+2, ..., gd]
has a probability of pi = |gi|"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.20074349442379183,"r . This modifies the optimization problem in Equation 1 to: k
X"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.20446096654275092,"i=1
g2
i + m
X i=k+1 |gi|"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.20817843866171004,"r
−(1 + ϵ) m
X"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.21189591078066913,"i=1
g2
i = 0, |gi|"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.21561338289962825,"r
≤1
(2)"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.21933085501858737,Which implies that r =
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.22304832713754646,"Pm
i=k+1 |gi|"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.22676579925650558,"(1 + ϵ) Pm
i=1 g2
i −Pk
i=1 g2
i (3)"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.23048327137546468,"As per the constraint |gi| r
≤1: |gi|( m
X"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.2342007434944238,"i=k+1
|gi|) ≤(1 + ϵ) m
X"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.2379182156133829,"i=1
g2
i − k
X"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.241635687732342,"i=1
g2
i
(4)"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.24535315985130113,"Invariant Dropout retains the gradients with the greatest magnitude. As a result, the boundedness of
the expected value from Equation 1 can be represented as follows: m
X"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.24907063197026022,"i=1
pi = k
X"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.2527881040892193,"i=1
pi + m
X"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.25650557620817843,"i=k+1
pi
(5) m
X"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.26022304832713755,"i=1
pi = k + |gi| m
X"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.26394052044609667,"i=k+1
("
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.26765799256505574,"Pm
i=k+1 |gi|"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.27137546468401486,"(1 + ϵ) Pm
i=1 g2
i −Pk
i=1 g2
i
)
(6) m
X"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.275092936802974,"i=1
pi ≤k(1 + ϵ)
(7)"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.2788104089219331,"As such, the variance of the gradient in ID is bounded by Equation 7."
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.2825278810408922,"Global Model
Clients"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.2862453531598513,"Start
Identify 
Stragglers"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.2899628252788104,Estimate
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.2936802973977695,"target 
Speedup"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.29739776951672864,Determine r
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.30111524163568776,(drop rate)
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.3048327137546468,Initialize th
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.30855018587360594,"(drop 
threshold)"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.31226765799256506,Aggregate
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.3159851301115242,Updates
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.31970260223048325,Broadcast sub-
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.32342007434944237,"model to 
Stragglers"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.3271375464684015,"Re-Calibrate 
stragglers, r, th 
and sub-models YES"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.3308550185873606,"Check ∆g from non-
stragglers for invariant"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.3345724907063197,neurons
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.3382899628252788,Broadcast global
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.3420074349442379,model to non-
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.34572490706319703,stragglers NO
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.34944237918215615,Performance
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.35315985130111527,Overhead
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.35687732342007433,Client-0
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.36059479553903345,Client-N
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.3643122676579926,Straggler
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.3680297397769517,"Global Model
Non-Straggler"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.37174721189591076,Clients
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.3754646840148699,"∆∆
∆g < th"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.379182156133829,"Sub-Model
Straggler"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.3828996282527881,Clients
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.38661710037174724,"Global Model
Non-Straggler"
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.3903345724907063,Clients
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.3940520446096654,Training done? Stop
VARIANCE IN GRADIENTS WITH INVARIANT DROPOUT,0.39776951672862454,"Figure 3: The workflow of FLuID. The non-stragglers are used to determine the neurons that are not
updated within a set threshold. Thereafter, sub-models are dynamically created by dropping invariant
neurons. These sub-models are sent to the straggler devices."
FLUID FRAMEWORK,0.40148698884758366,"5
FLuID Framework"
FLUID FRAMEWORK,0.4052044609665427,"Figure 3 shows the workflow of Federated Learning using Invariant Dropout (FLuID). In FLuID, each
calibration step includes straggler determination (T), discovering invariant neurons(IN) and drop
threshold (th), and sub-model extraction(si). Currently, the calibration occurs per epoch, i.e., one
training run over the complete client dataset. However, the frequency of calibration can be reduced if
the invariant neurons and stragglers do not significantly change over steps."
FLUID FRAMEWORK,0.40892193308550184,"Algorithm 1 outlines the FLuID framework. At the onset of training, FLuID identifies the stragglers.
To achieve this, FLuID runs the global model on all clients, including stragglers, and measures the
performance delay between the end-to-end training time of the slowest client (Tstraggler) and the
target time (Ttarget).End-to-end training includes upload/download latency and communication time."
FLUID FRAMEWORK,0.41263940520446096,"Ttarget is the desired training time FLuID aims to achieve for stragglers. FLuID assigns Ttarget
as the next slowest client’s training time. This choice optimizes non-straggler idle time reduction.
Note, FLuID can support any Ttarget value. Setting Ttarget lower than the next-slowest client’s time
offers no gain as non-stragglers cannot accelerate. Conversely, setting Ttarget above the next-slowest
client’s training time leads to longer idleness and suboptimal performance. The required speedup for
stragglers is calculated as Speedup = Tstraggler"
FLUID FRAMEWORK,0.4163568773234201,"Ttarget . The initial calibration is carried out in lines 6-9 and
18-22 of the algorithm. Note, it takes a few epochs to calibrate the initial threshold, stragglers, and
submodel. In subsequent calibration steps, the global server continues to measure the training time of
clients and thereby identifies if there is any change in the straggler cohort."
FLUID FRAMEWORK,0.4200743494423792,"Tuning the performance of stragglers. The sub-model size is determined by calculating the dropout
rate r as detailed in lines 18-21 of Algorithm 1. The value of r is selected to ensure that the updated
straggler training time, denoted as Tstragglernew, is close to the target training time (Ttarget). Figure 7
in Appendix A.3 demonstrates that across all evaluated datasets, the training time of all five mobile
clients decreases linearly as the sub-model size decreases, and falls within 10% of the sub-model size.
Using this insight, FLuID chooses an r that is closest to the inverse of the speedup."
FLUID FRAMEWORK,0.42379182156133827,"Determining the drop threshold at runtime. Once FLuID has identified the stragglers and the
dropout rate, it iteratively adjusts the threshold to drop as many invariant neurons as possible. The
design of FLuID is inspired by the preliminary results regarding the characteristics of invariant
neurons and their impact on the model accuracy. In Appendix A.2, we present results to quantify the
impact of the threshold value on the number of invariant neurons during training. We observe that, in
order to obtain the desired accuracy, it is critical to select a threshold that yields a number of invariant
neurons as close as possible to the number of neurons to be dropped for the sub-model."
FLUID FRAMEWORK,0.4275092936802974,"Lets assume wijc(t) represents the set of weights of the ith neuron in the jth layer for client c after
the training epoch t. The percent difference g of the neuron, for each client c, is the minimum value
of g as denoted by: g ≥wijc(t)−wij(t−1)"
FLUID FRAMEWORK,0.4312267657992565,"wij(t−1)
. Neurons that are potential candidates for dropping are
those whose weight updates are within the threshold (th) compared to the previous calibration point.
Unfortunately, determining the appropriate th poses a few challenges."
FLUID FRAMEWORK,0.4349442379182156,Algorithm 1 FLuID executing on Centralized Server
FLUID FRAMEWORK,0.43866171003717475,"1: Input: M(w)
# Model. M(wt)ismodelatstept
2: Output: S(w)
# Sub-models for stragglers
3: N →All Clients, T →∅
# T stragglers, N non-stragglers
4: IN →∅
# invariant neurons
5: while not done do
6:
if T is ∅then {# Straggler and dropout threshold intialization}
7:
Broadcast M(w0) to each C
8:
Receive M(w1) from every C
9:
th = min (
wijct−wij(t−1)"
FLUID FRAMEWORK,0.4423791821561338,"wij(t−1)
) # threshold for Invariant dropout
10:
else {# Straggler and dropout threshold recalibration}
11:
S(wt) = sub_model_generation(IN, M(wt))
12:
Broadcast S(wti) all i ∈T
13:
Broadcast M(wt) all i ∧/∈T
14:
Receive ∆(wt+1) from every C
15:
M(wt+1) = aggregate(M(wt), ∆(wt+1))
16:
IN = identify_invariant_neurons(th,∆(wt+1), N)
17:
end if
18:
T, N,L = determine_stragglers(C) # L = train latencies
19:
Ttarget = identify_next_slowest_client(L)
20:
Speedupi =
Tstraggleri"
FLUID FRAMEWORK,0.44609665427509293,"Ttarget
21:
ri, Si = calculate_submodel_size(Speedupi) # ri dropout rate
22:
th = increment_threshold(ri)
23:
done = check_training_done(M(wt))
24: end while"
FLUID FRAMEWORK,0.44981412639405205,"In order to identify neuron drop candidates, the global server cannot rely on updates from all clients
since stragglers only train on and update the sub-model. Instead, the server takes advantage of the fact
that non-stragglers train on the complete model and can identify neurons whose weight updates fall
within the threshold (th) for each calibration step. FLuID prioritizes dropping neurons on stragglers
whose weight updates fall within the threshold (th) for the majority of non-stragglers."
FLUID FRAMEWORK,0.45353159851301117,"The initial threshold value (th) in the FLuID framework is set as the average of the minimum percent
update of all neurons in the initial few training epochs. The threshold is incrementally increased after
each epoch until the number of neurons below the threshold is greater than or equal to the number of
neurons to be left out of the sub-model. FLuID can have a different drop threshold for each layer.
The algorithm targets neurons for dropping whose gradients consistently fall below the threshold over
multiple epochs, prioritizing the elimination of non-critical neurons."
FLUID FRAMEWORK,0.45724907063197023,"This entire process is repeated to recalibrate the stragglers, the drop rate (r), and the threshold (th)."
EVALUATION SETUP,0.46096654275092935,"6
Evaluation Setup"
EVALUATION SETUP,0.4646840148698885,"Models and datasets. We evaluate FLuID on three models and datasets as used by the prior works in
the federated learning space [MGZP22, JWK+22, HLA+21, CKMT18]."
EVALUATION SETUP,0.4684014869888476,"The FEMNIST datasets consist of images of numbers and letters, partitioned based on the writer
of the character in non-IID setting. We train a CNN with two 5x5 CONV layers with 16 and 64
channels respectively, each of them followed with 2×2 max-pooling. The model also includes a fully
connected dense layer with 120 units and a softmax output layer. The model is trained using a batch
size of 10 and a learning rate of 0.004."
EVALUATION SETUP,0.4721189591078067,"The Shakespeare dataset partitions data based on roles in Shakespeares’ plays in non-IID setting. We
train a two-layer LSTM classifier containing 128 hidden units. We train the model with a batch size
of 128 and a learning rate of 0.001."
EVALUATION SETUP,0.4758364312267658,"The CIFAR10 dataset consists of images, partitioned using the same strategy as FjORD [HLA+21]
and the IID partition provided by the Flower [BTM+20]. For the real-world mobile devices, we train
on the VGG-9 model due to its ability to fit within the resource constraints of all the mobile phones
we tested. VGG-9 [SZ15] model architecture consists 6 3x3 CONV layers (the first 2 have 32 channels,"
EVALUATION SETUP,0.4795539033457249,Table 1: Software-Hardware specifications of clients
EVALUATION SETUP,0.483271375464684,"Device
Year
Android Version
CPU (Cores)"
EVALUATION SETUP,0.48698884758364314,"LG Velvet 5G
2020
10
1×2.4 GHz Kryo 475 Prime + 1×2.2 GHz Kryo 475 Gold + 6×1.8 GHz Kryo 475 Silver"
EVALUATION SETUP,0.49070631970260226,"Google Pixel 3
2018
9
4×2.5 GHz Kryo 385 Gold + 4×1.6 GHz Kryo 385 Silver"
EVALUATION SETUP,0.4944237918215613,"Samsung Galaxy S9
2018
10
4×2.8 GHz Kryo 385 Gold + 4×1.7 GHz Kryo 385 Silver"
EVALUATION SETUP,0.49814126394052044,"Samsung Galaxy S10
2019
11
2×2.73 GHz Mongoose M4 + 2×2.31 GHz Cortex-A75 + 4×1.95 GHz Cortex-A55"
EVALUATION SETUP,0.5018587360594795,"Google Pixel 4
2019
12
1×2.84 GHz Kryo 485 + 3×2.42 GHz Kryo 485 + 4×1.78 GHz Kryo 485"
EVALUATION SETUP,0.5055762081784386,"Table 2: Accuracy comparison of Random Dropout, Ordered Dropout, and Invariant Dropout. The
text in bold indicates instances when Invariant Dropout showcases the highest accuracy. (µ = mean,
σ = standard deviation, and r = sub-model as a fraction of global model)."
EVALUATION SETUP,0.5092936802973977,"Dataset
Dropout Method
r = 0.95
r = 0.85
r = 0.75
r = 0.65
r = 0.5"
EVALUATION SETUP,0.5130111524163569,"Accuracy (µ)
σ
Accuracy (µ)
σ
Accuracy (µ)
σ
Accuracy (µ)
σ
Accuracy (µ)
σ"
EVALUATION SETUP,0.516728624535316,"Shakespeare
Random
43.3
0.1
42.5
0.1
42.4
0.1
41.8
0.2
41.3
0.1"
EVALUATION SETUP,0.5204460966542751,"Ordered
42.9
0.1
42.3
0.1
42.2
0.2
41.9
0.1
41.4
0.1"
EVALUATION SETUP,0.5241635687732342,"Invariant
43.6
0.1
42.5
0.1
42.6
0.2
42.2
0.2
41.7
0.1"
EVALUATION SETUP,0.5278810408921933,"CIFAR10
Random
57.5
0.1
56.8
0.2
57.0
0.2
57.2
0.2
57.2
0.3"
EVALUATION SETUP,0.5315985130111525,"(VGG-9)
Ordered
57.7
0.1
57.0
0.2
57.6
0.2
57.3
0.1
57.1
0.1"
EVALUATION SETUP,0.5353159851301115,"Invariant
58.2
0.1
58.4
0.3
57.1
0.1
57.5
0.2
57.4
0.2"
EVALUATION SETUP,0.5390334572490706,"FEMNIST
Random
80.6
0.1
80.5
0.2
80.3
0.2
79.3
0.5
79.2
0.3"
EVALUATION SETUP,0.5427509293680297,"Ordered
80.6
0.2
80.5
0.2
80.4
0.2
80.3
0.1
79.7
0.3"
EVALUATION SETUP,0.5464684014869888,"Invariant
81.1
0.3
80.9
0.1
80.8
0.2
80.3
0.4
80.1
0.3"
EVALUATION SETUP,0.550185873605948,"followed by two 64-channel layers, and lastly two 128-channel layers), two FC dense layers with
512 and 256 units and a final softmax output layer. We train the model with a batch size of 20 and a
learning rate of 0.01. We conduct scalability experiments using the ResNet-18 model, and the results
are presented in section 6.1. All the baseline dropout methods and Invariant Dropout are evaluated
using the same setup."
EVALUATION SETUP,0.5539033457249071,"System Configuration. Table 1 provides the details of the phones used for the experiments. We
evaluate five clients and identify one straggler per training epoch. We connect all our client devices
and our server over the same network. All the clients run on Android mobile phones from the years
2018 to 2020."
EVALUATION SETUP,0.5576208178438662,"FLuID is implemented on top of the Flower (v0.18.0) [BTM+20] framework and TensorFlow
Lite [Goo] from TensorFlow v2.8.0 [ABC+16]. Models are defined using TensorFlow’s Sequential
API, and then converted into .tflite formats."
EVALUATION SETUP,0.5613382899628253,"Evaluation metrics and baselines. We compare the average training performance (wall-clock time)
and accuracy for all workloads and experiments. In each evaluation round, clients receive the global
model and report their evaluation accuracy and loss on local data to the server. The server calculates
the distributed accuracy and loss by performing a weighted average based on the number of testing
examples for each client. We compare FLuID with two established baselines: 1) Random Federated
Dropout [CKMT18] and 2) Ordered Dropout from FjORD [HLA+21]."
RESULTS AND ANALYSIS,0.5650557620817844,"6.1
Results and Analysis"
RESULTS AND ANALYSIS,0.5687732342007435,"Accuracy Evaluation We compare accuracy of Invariant Dropout with two baselines, using different
sub-model sizes. We trained the models for 100, 250, and 65 epochs for CIFAR10, FEMNIST, and
Shakespeare datasets, respectively. Table 2 presents the average achieved accuracy (µ) along with the
standard deviation (σ) for the three datasets. Specifically, Invariant Dropout outperforms Random
Dropout across all three datasets. Compared to Random Dropout, our work achieves a maximum
accuracy gain of 1.6% points and on average 0.7% point higher accuracy for FEMNIST, 0.6% point
higher accuracy for CIFAR10, and 0.3% point higher accuracy for Shakespeare datasets."
RESULTS AND ANALYSIS,0.5724907063197026,"Invariant Dropout also achieves a higher accuracy against Ordered Dropout across all three datasets,
with a maximum increase in accuracy of 1.4% and an average increase of 0.3% for FEMNIST, 0.4%"
RESULTS AND ANALYSIS,0.5762081784386617,"(a) Training time for stragglers before and after FLuID.
(b) Training time reduction with varying stragglers."
RESULTS AND ANALYSIS,0.5799256505576208,Figure 4: Performance evaluation of FLuID
RESULTS AND ANALYSIS,0.5836431226765799,"for CIFAR10, and 0.4% for Shakespeare. The accuracy improvements of Invariant Dropout are
statistically significant (α < 0.05). Moreover, Invariant Dropout shows less variation in accuracy
between runs of the same sub-model size and across all sub-model sizes. This is because invariant
Dropout eliminates only invariant neurons, which have little impact on the final model efficiency."
RESULTS AND ANALYSIS,0.587360594795539,"Computational Performance Evaluation Figure 4a shows FLuID’s capability to effectively select
the sub-model, resulting in a significant reduction in the straggler’s training time that almost matches
the next slowest client. In the absence of FLuID, the straggler’s training time is typically 10% to 32%
longer than the target time. However, after applying FLuID, the straggler’s training time is within
10% of the target time. Furthermore, it is observed that the overall accuracy of the global model
tends to be higher when stragglers train with larger sub-models. Consequently, FLuID selects the
largest possible sub-model size that minimizes training time variance across clients. Notably, the
performance improvement, unlike accuracy, is influenced by the size of the sub-model and not the
specific dropout technique employed. For a more detailed analysis of the impact of sub-model size
on training time, please refer to Appendix A.3."
RESULTS AND ANALYSIS,0.5910780669144982,"Varying stragglers at runtime. FLuID can recalibrate stragglers. During the experiments in Table 2,
we observe that the performance of our mobile clients remained relatively stable, without significant
changes in the straggler. However, to evaluate the impact of varying conditions at runtime, we
randomly executed certain clients at different points in the training process (25%, 50%, and 75%
marks). This was achieved by enabling a client to run the training program as a background process
between the specified periods. We observed that FLuID successfully adapted to the variation in
stragglers during runtime. Figure 4b demonstrates the overall training time for this experiment. On
average, the FLuID framework achieved 18% to 26% faster training time compared to the baseline,
and 14% to 18% faster training time compared to selecting a static straggler throughout the entire
training process. All results include the overhead of FLuID, which, importantly, is not significant. We
observe, FLuID calibration process takes significantly less time (less than 5%) compared to the actual
training time. This is because the additional computations required for threshold and sub-model
calibration are performed centrally on the server, rather than being distributed to edge devices."
RESULTS AND ANALYSIS,0.5947955390334573,"Scalability study. To assess the scalability of FLuID, we conducted experiments using simulated
clients ranging from 50 to 100. Each machine runs 10 to 20 clients in parallel. Among all clients,
we identified the slowest 20% as stragglers. We further extend the experiment to run CIFAR10
with ResNet-18 as these are emulated clients on a server and can support relatively larger models
than mobile devices. Figure 5 shows the accuracy performance across all three datasets. Overall,
Invariant Dropout consistently outperforms Ordered and Random Dropout and maintains a better
accuracy profile similar to Table 2. In addition, our dropout technique performs significantly better
than completely excluding stragglers from the training process."
RESULTS AND ANALYSIS,0.5985130111524164,"We further extended the experiment to assess the scalability of FLuID by 1) clustering stragglers into
multiple sub-model sizes (Appendix A.4), 2) Exploring the impact of varying ratios of stragglers in the
system (Appendix A.5), and 3) a scalability study with 1000 clients where client sampling is employed
as we cannot check for stragglers across 1000 devices individually (Appendix A.6). We demonstrate
that FLuID can scale to scenarios involving multiple stragglers with varying computational capabilities
by tailoring sub-model sizes for each client. Moreover, when compared to state-of-the-art dropout
techniques, Invariant Dropout achieves high accuracies, even as the percentage of stragglers in the
system scales up."
RESULTS AND ANALYSIS,0.6022304832713755,"0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Sub-model size 53.0 53.5 54.0 54.5"
RESULTS AND ANALYSIS,0.6059479553903345,Accuracy (%)
RESULTS AND ANALYSIS,0.6096654275092936,FedAvg
RESULTS AND ANALYSIS,0.6133828996282528,FedAvg (40 Clients)
RESULTS AND ANALYSIS,0.6171003717472119,Invariant
RESULTS AND ANALYSIS,0.620817843866171,Ordered
RESULTS AND ANALYSIS,0.6245353159851301,Random
RESULTS AND ANALYSIS,0.6282527881040892,"(a) Shakespeare - LSTM (50 Clients, 10 stragglers)"
RESULTS AND ANALYSIS,0.6319702602230484,"0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Sub-model size 70 71 72 73 74"
RESULTS AND ANALYSIS,0.6356877323420075,Accuracy (%)
RESULTS AND ANALYSIS,0.6394052044609665,"FedAvg
FedAvg (80 Clients)
Invariant
Ordered
Random"
RESULTS AND ANALYSIS,0.6431226765799256,"(b) CIFAR10 - VGG9 (100 Clients, 20 stragglers)"
RESULTS AND ANALYSIS,0.6468401486988847,"0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Sub-model size 78.0 78.5 79.0 79.5 80.0 80.5 81.0"
RESULTS AND ANALYSIS,0.6505576208178439,Accuracy (%)
RESULTS AND ANALYSIS,0.654275092936803,"FedAvg
FedAvg (80 Clients)
Invariant
Ordered
Random"
RESULTS AND ANALYSIS,0.6579925650557621,"(c) CIFAR10 - ResNet18 (100 Clients, 20 stragglers)"
RESULTS AND ANALYSIS,0.6617100371747212,"0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Sub-model size 74 75 76 77 78 79"
RESULTS AND ANALYSIS,0.6654275092936803,Accuracy (%)
RESULTS AND ANALYSIS,0.6691449814126395,"FedAvg
FedAvg (80 Clients)
Invariant
Ordered
Random"
RESULTS AND ANALYSIS,0.6728624535315985,"(d) FEMNIST - CNN (100 Clients, 20 stragglers)"
RESULTS AND ANALYSIS,0.6765799256505576,"Figure 5: The accuracy comparison of Invariant Dropout with Ordered and Random Dropout as we
scale to 50-100 clients with 20% of the slowest clients being stragglers."
LIMITATIONS AND FUTURE WORK,0.6802973977695167,"7
Limitations and Future Work"
LIMITATIONS AND FUTURE WORK,0.6840148698884758,"Although FLuID is able to mitigate some impact of the stragglers, it does incur minimal overhead to
handle stragglers and maintain system performance. Our evaluation takes this into account but this
overhead may increase if straggler performance constantly changes."
LIMITATIONS AND FUTURE WORK,0.6877323420074349,"FLuID currently only uses pre-defined sub-model sizes mapped to straggler performance, which
keeps the framework lightweight and avoids high overhead. However, for future works with varied
edge devices, fine-grained sub-model determination may further enhance the work."
CONCLUSIONS,0.6914498141263941,"8
Conclusions"
CONCLUSIONS,0.6951672862453532,"Due to rapid technological advancements and device variability in handheld devices, system het-
erogeneity is prevalent in federated learning. Straggler devices, which exhibit low computational
performance, act as the bottleneck. In this paper, we address these issues by introducing a novel
dropout technique called Invariant Dropout. Invariant Dropout dynamically creates customized
sub-models that include only the neurons exhibiting significant changes above a certain threshold.
We build a framework, FLuID, which adapts to changes in stragglers as runtime conditions shift.
FLuID effectively mitigates the performance overheads caused by stragglers while also achieving a
higher accuracy compared to state-of-the-art techniques."
ACKNOWLEDGEMENTS,0.6988847583643123,"9
Acknowledgements"
ACKNOWLEDGEMENTS,0.7026022304832714,"We thank the anonymous reviewers for their insightful comments. This research was supported in
part through computational resources provided by Advanced Research Computing at the University
of British Columbia (UBC) [soc]. This work was partially supported by Gift from Google and the
Natural Sciences and Engineering Research Council of Canada (NSERC) [funding reference number
RGPIN-2019-05059]. The work, in part, was supported by Georgia Tech School of Electrical and
Computer Engineering and School of Computer Science. The views and conclusions contained
herein are those of the authors. They should not be interpreted as necessarily representing the official
policies or endorsements, either expressed or implied, of Georgia Tech, Microsoft, and UBC."
REFERENCES,0.7063197026022305,References
REFERENCES,0.7100371747211895,"[ABC+16] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean,
Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, Manjunath Kudlur,
Josh Levenberg, Rajat Monga, Sherry Moore, Derek G. Murray, Benoit Steiner, Paul
Tucker, Vijay Vasudevan, Pete Warden, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng.
Tensorflow: A system for large-scale machine learning. In Proceedings of the 12th
USENIX Conference on Operating Systems Design and Implementation, OSDI’16, page
265–283, USA, 2016. USENIX Association."
REFERENCES,0.7137546468401487,"[BHS20] Saar Barkai, Ido Hakimi, and Assaf Schuster. Gap-aware mitigation of gradient staleness.
In International Conference on Learning Representations, 2020."
REFERENCES,0.7174721189591078,"[BTM+20] Daniel J. Beutel, Taner Topal, Akhil Mathur, Xinchi Qiu, Javier Fernandez-Marques,
Yan Gao, Lorenzo Sani, Kwing Hei Li, Titouan Parcollet, Pedro Porto Buarque de Gus-
mão, and Nicholas D. Lane. Flower: A friendly federated learning research framework,
2020."
REFERENCES,0.7211895910780669,"[CCA+21] Zheng Chai, Yujing Chen, Ali Anwar, Liang Zhao, Yue Cheng, and Huzefa Rangwala.
Fedat: A high-performance and communication-efficient federated learning system
with asynchronous tiers. In Proceedings of the International Conference for High
Performance Computing, Networking, Storage and Analysis, SC ’21, New York, NY,
USA, 2021. Association for Computing Machinery."
REFERENCES,0.724907063197026,"[CDW+18] Sebastian Caldas, Sai Meher Karthik Duddu, Peter Wu, Tian Li, Jakub Koneˇcný,
H. Brendan McMahan, Virginia Smith, and Ameet Talwalkar. Leaf: A benchmark for
federated settings, 2018."
REFERENCES,0.7286245353159851,"[CKMT18] Sebastian Caldas, Jakub Koneˇcny, H. Brendan McMahan, and Ameet Talwalkar. Ex-
panding the reach of federated learning by reducing client resource requirements, 2018."
REFERENCES,0.7323420074349443,"[CNSR20] Yujing Chen, Yue Ning, Martin Slawski, and Huzefa Rangwala. Asynchronous online
federated learning for edge devices with non-iid data. In 2020 IEEE International
Conference on Big Data (Big Data), pages 15–24, 2020."
REFERENCES,0.7360594795539034,"[CSP+21] Mingzhe Chen, Nir Shlezinger, H. Vincent Poor, Yonina C. Eldar, and Shuguang Cui.
Communication-efficient federated learning. Proceedings of the National Academy of
Sciences, 118(17):e2024789118, 2021."
REFERENCES,0.7397769516728625,"[DDT21] Enmao Diao, Jie Ding, and Vahid Tarokh. Heterofl: Computation and communication
efficient federated learning for heterogeneous clients. In 9th International Confer-
ence on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021.
OpenReview.net, 2021."
REFERENCES,0.7434944237918215,"[DTS+22] Jie Ding, Eric Tramel, Anit Kumar Sahu, Shuang Wu, Salman Avestimehr, and Tao
Zhang. Federated learning challenges and opportunities: An outlook, 2022."
REFERENCES,0.7472118959107806,"[Goo] Google. Tensorflow lite | ml for mobile and edge devices. https://www.tensorflow.
org/lite. Accessed: 2022-08-14."
REFERENCES,0.7509293680297398,"[HAA20] Chaoyang He, Murali Annavaram, and Salman Avestimehr. Group knowledge transfer:
Federated learning of large cnns at the edge. In H. Larochelle, M. Ranzato, R. Hadsell,
M.F. Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems,
volume 33, pages 14068–14080. Curran Associates, Inc., 2020."
REFERENCES,0.7546468401486989,"[HBGS19] Ido Hakimi, Saar Barkai, Moshe Gabel, and Assaf Schuster. Taming momentum in a
distributed asynchronous environment, 2019."
REFERENCES,0.758364312267658,"[HLA+21] Samuel Horváth, Stefanos Laskaridis, Mario Almeida, Ilias Leontiadis, Stylianos Ve-
nieris, and Nicholas Donald Lane. FjORD: Fair and accurate federated learning under
heterogeneous targets with ordered dropout. In A. Beygelzimer, Y. Dauphin, P. Liang,
and J. Wortman Vaughan, editors, Advances in Neural Information Processing Systems,
2021."
REFERENCES,0.7620817843866171,"[HS97] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computa-
tion, 9(8):1735–1780, 1997."
REFERENCES,0.7657992565055762,"[HWL20] Pengchao Han, Shiqiang Wang, and Kin Kwong Leung. Adaptive gradient sparsifi-
cation for efficient federated learning: An online learning approach. 2020 IEEE 40th
International Conference on Distributed Computing Systems (ICDCS), pages 300–310,
2020."
REFERENCES,0.7695167286245354,"[JWK+22] Yuang Jiang, Shiqiang Wang, Bongjun Ko, Wei-Han Lee, and Leandros Tassiulas.
Model pruning enables efficient federated learning on edge devices. IEEE transactions
on neural networks and learning systems, PP, 2022."
REFERENCES,0.7732342007434945,"[KALT23] Alind Khare, Animesh Agrawal, Myungjin Lee, and Alexey Tumanov. Superfed: Weight
shared federated learning, 2023."
REFERENCES,0.7769516728624535,"[KMA+19] Peter Kairouz, H. Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis,
Arjun Nitin Bhagoji, Kallista A. Bonawitz, Zachary Charles, Graham Cormode, Rachel
Cummings, Rafael G. L. D’Oliveira, Salim El Rouayheb, David Evans, Josh Gardner,
Zachary Garrett, Adrià Gascón, Badih Ghazi, Phillip B. Gibbons, Marco Gruteser,
Zaïd Harchaoui, Chaoyang He, Lie He, Zhouyuan Huo, Ben Hutchinson, Justin Hsu,
Martin Jaggi, Tara Javidi, Gauri Joshi, Mikhail Khodak, Jakub Koneˇcný, Aleksandra
Korolova, Farinaz Koushanfar, Sanmi Koyejo, Tancrède Lepoint, Yang Liu, Prateek
Mittal, Mehryar Mohri, Richard Nock, Ayfer Özgür, Rasmus Pagh, Mariana Raykova,
Hang Qi, Daniel Ramage, Ramesh Raskar, Dawn Song, Weikang Song, Sebastian U.
Stich, Ziteng Sun, Ananda Theertha Suresh, Florian Tramèr, Praneeth Vepakomma,
Jianyu Wang, Li Xiong, Zheng Xu, Qiang Yang, Felix X. Yu, Han Yu, and Sen Zhao.
Advances and open problems in federated learning. CoRR, abs/1912.04977, 2019."
REFERENCES,0.7806691449814126,[Kri09] Alex Krizhevsky. Learning multiple layers of features from tiny images. 2009.
REFERENCES,0.7843866171003717,"[LSTS20] Tian Li, Anit Kumar Sahu, Ameet S. Talwalkar, and Virginia Smith. Federated learning:
Challenges, methods, and future directions. IEEE Signal Processing Magazine, 37:50–
60, 2020."
REFERENCES,0.7881040892193308,"[MGZP22] Yiqun Mei, Pengfei Guo, Mo Zhou, and Vishal Patel. Resource-adaptive federated learn-
ing with all-in-one neural composition. In Advances in Neural Information Processing
Systems, 2022."
REFERENCES,0.79182156133829,"[MMR+17] H. B. McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Agüera
y Arcas. Communication-efficient learning of deep networks from decentralized data.
In AISTATS, 2017."
REFERENCES,0.7955390334572491,"[MSA+21] Muhammad Tahir Munir, Muhammad Mustansar Saeed, Mahad Ali, Zafar Ayyub Qazi,
and Ihsan Ayyub Qazi. Fedprune: Towards inclusive federated learning, 2021."
REFERENCES,0.7992565055762082,"[RKPH22] Martin Rapp, Ramin Khalili, Kilian Pfeiffer, and Jörg Henkel. Distreal: Distributed
resource-aware learning in heterogeneous systems. In Proceedings of the AAAI Confer-
ence on Artificial Intelligence, volume 36, pages 8062–8071, 2022."
REFERENCES,0.8029739776951673,"[SB09] Venkatesh Shankar and Sridhar Balasubramanian. Mobile marketing: A synthesis and
prognosis. Journal of interactive marketing, 23(2):118–129, 2009."
REFERENCES,0.8066914498141264,"[SKRA21] Reent Schlegel, Siddhartha Kumar, Eirik Rosnes, and Alexandre Graell i Amat. Cod-
edpaddedfl and codedsecagg: Straggler mitigation and secure aggregation in federated
learning, 2021."
REFERENCES,0.8104089219330854,"[soc] UBC Advanced Research Computing, ""UBC ARC Sockeye."" UBC Advanced Research
Computing, 2023, doi: 10.14288/SOCKEYE."
REFERENCES,0.8141263940520446,"[SVHN10] Venkatesh Shankar, Alladi Venkatesh, Charles Hofacker, and Prasad Naik. Mobile
marketing in the retailing environment: current insights and future research avenues.
Journal of interactive marketing, 24(2):111–120, 2010."
REFERENCES,0.8178438661710037,"[SZ15] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-
scale image recognition. In Yoshua Bengio and Yann LeCun, editors, 3rd International
Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9,
2015, Conference Track Proceedings, 2015."
REFERENCES,0.8215613382899628,"[UWH+21] Rehmat Ullah, Di Wu, Paul Harvey, Peter Kilpatrick, Ivor Spence, and Blesson Varghese.
Fedfly: Towards migration in edge-based distributed federated learning, 2021."
REFERENCES,0.8252788104089219,"[WQR+22] Jianyu Wang, Hang Qi, Ankit Singh Rawat, Sashank Reddi, Sagar Waghmare, Felix X.
Yu, and Gauri Joshi. Fedlite: A scalable approach for federated learning on resource-
constrained clients, 2022."
REFERENCES,0.828996282527881,"[WUH+21] Di Wu, Rehmat Ullah, Paul Harvey, Peter Kilpatrick, Ivor Spence, and Blesson Varghese.
Fedadapt: Adaptive offloading for iot devices in federated learning, 2021."
REFERENCES,0.8327137546468402,"[WWLZ18] Jianqiao Wangni, Jialei Wang, Ji Liu, and Tong Zhang. Gradient sparsification for
communication-efficient distributed optimization. In NeurIPS, 2018."
REFERENCES,0.8364312267657993,"[XFD+21] Wenyuan Xu, Weiwei Fang, Yi Ding, Meixia Zou, and Naixue N. Xiong. Accelerating
federated learning for iot in big data analytics with pruning, quantization and selective
updating. IEEE Access, 9:38457–38466, 2021."
REFERENCES,0.8401486988847584,"[XKG19] Cong Xie, Sanmi Koyejo, and Indranil Gupta. Asynchronous federated optimization,
2019."
REFERENCES,0.8438661710037175,"[XYXC21] Zirui Xu, Fuxun Yu, Jinjun Xiong, and Xiang Chen. Helios: Heterogeneity-aware
federated learning with dynamically balanced collaboration. In 2021 58th ACM/IEEE
Design Automation Conference (DAC), pages 997–1002, 2021."
REFERENCES,0.8475836431226765,"[ZBW+22] Zhengyi Zhong, Weidong Bao, Ji Wang, Xiaomin Zhu, and Xiongtao Zhang. Flee:
A hierarchical federated learning framework for distributed deep neural network over
cloud, edge and end device. ACM Trans. Intell. Syst. Technol., jan 2022. Just Accepted."
REFERENCES,0.8513011152416357,"A
Appendix"
REFERENCES,0.8550185873605948,"A.1
Evolution of Invariant Neurons"
REFERENCES,0.8587360594795539,"0%
20%
40%
60%
80%
100%
Percent of Training Epochs 0% 5% 10% 15% 20% 25% 30% 35%"
REFERENCES,0.862453531598513,Percent of Invariant Neurons
REFERENCES,0.8661710037174721,"Shakespeare
CIFAR10
FEMNIST"
REFERENCES,0.8698884758364313,Figure 6: The percentage of ‘invariant’ neurons as the number of training rounds vary
REFERENCES,0.8736059479553904,"In this section, we provide an example that some neurons in the server are trained quickly and vary
only below a threshold in later iterations. Figure 6 shows the percentages of invariant neurons as
the number of training epochs increases. Even after only 30% of the training rounds are completed,
15%-30% of the neurons become invariant across CIFAR10, FEMNIST, and Shakespeare datasets For
this example, we choose thresholds of 180%, 10%, and 500%, respectively, for these three datasets
and compute their invariant neurons. Sending invariant neurons over to the straggler provides no
utility; therefore, these neurons can be dropped. Our work FLuID builds upon this insight."
REFERENCES,0.8773234200743495,"A.2
Choosing Suitable Threshold"
REFERENCES,0.8810408921933085,"Each model has different characteristics in terms of the magnitude of neuron updates. Therefore,
choosing different threshold values results in a different number of neurons classified as invariant. We
expanded on our initial findings and studied the effect of threshold value on the number of invariant
neurons during training. As expected, a higher threshold value leads to a higher percentage of
invariant neurons. Table 3 presents the percentage of invariant neurons observed at different threshold
values, and the overall training accuracy of the FEMNIST model, using a sub-model size of 0.75 for
the stragglers."
REFERENCES,0.8847583643122676,Table 3: Threshold vs accuracy results
REFERENCES,0.8884758364312267,"Threshold value (%)
Percentage of Invariant Neurons (%)
Accuracy (%)"
REFERENCES,0.8921933085501859,"1
3
80.1
3
6
80.3
5
13
80.5
7
18
80.7
8
22
80.7
10
31
80.5"
REFERENCES,0.895910780669145,"We observe that to obtain the desired accuracy and mitigate performance bottlenecks of stragglers, it
is critical to choose the threshold that has the closest number of invariant neurons as the number of
neurons to be dropped for the sub-model. The FLuID framework can automatically tune the threshold
for the desired model based on the straggler performance, as described in Section 5."
REFERENCES,0.8996282527881041,"A.3
Impact of Sub-Model Size on Training Time"
REFERENCES,0.9033457249070632,"In this section, we present evidence that there is a linear relationship between client training time
and sub-model size. We evaluated the training time of 5 Android-based mobile phones from 2018 to
2020 outlined in Table 1. The training time is expressed in the percentage of the training time for the"
REFERENCES,0.9070631970260223,Figure 7: Linear relationship between training time and model size across all three datasets
REFERENCES,0.9107806691449815,"full model size (r = 1.0). Across CIFAR10, FEMNIST, and Shakespeare, the training time of all
five mobile clients decreases linearly as the sub-model size decreases and falls within 10% of the
sub-model size. Using this insight, FLuID selects a sub-model size r as the available sub-model, the
size that’s closest to the inverse of Speedup."
REFERENCES,0.9144981412639405,"A.4
Additional Experiments with Scalability Studies."
REFERENCES,0.9182156133828996,"In this section, we show that in the case that the network has multiple stragglers, FLuID does not
assume that all stragglers have similar capabilities or select a sub-model for all stragglers based
on the slowest device. FLuID can select sub-model sizes for each straggler client based on each
client’s own capabilities. In this experiment, we cluster devices of similar capabilities into four groups
of sub-model sizes. Table 4 presents the accuracy when stragglers are assigned to 4 equal-sized
clusters (sub-model size 0.65, 0.75, 0.85, 0.95). The overall accuracy generally lies between assigning
sub-model sizes of 0.75 and 0.85 for all stragglers. This way, FLuID can achieve a higher training
accuracy with a shorter training time, even with stragglers that are initially more than 35% slower
than non-straggler devices."
REFERENCES,0.9219330855018587,"Table 4: Accuracy comparison of Random Dropout, Ordered Dropout, and Invariant Dropout as we
cluster stragglers into different sub-model size groups."
REFERENCES,0.9256505576208178,"Random
Ordered
Invariant
CIFAR10
71.7
72.3
72.7
FEMNIST
77.5
77.4
78.2
Shakespeare
53.8
53.9
54.1"
REFERENCES,0.929368029739777,"A.5
Additional Experiments with Varying Straggler Percentages"
REFERENCES,0.9330855018587361,"In this section, we show that FLuID is capable of handling multiple ratios of stragglers. We have
run additional experiments to explore the impact of different ratios of stragglers. One common
trend we observed across state-of-the-art techniques and FLuID is that accuracy decreases as the
ratio of stragglers is increased as more of the devices are now being trained only on the sub-model.
Nonetheless, in all the cases, Invariant Dropout offers the highest accuracy because it is aware of the
neuron gradient changes and only drops the least changing neurons. The accuracy results of varying
the straggler ratios while using 0.75-sized sub-models are summarized in Figure 8."
REFERENCES,0.9368029739776952,"10%
15%
20%
25%
30%
35%
40%
Percentage of Straggler 51.5 52.0 52.5 53.0 53.5 54.0 54.5"
REFERENCES,0.9405204460966543,Accuracy (%)
REFERENCES,0.9442379182156134,"Invariant
Ordered
Random"
REFERENCES,0.9479553903345725,(a) Shakespeare - LSTM (50 Clients)
REFERENCES,0.9516728624535316,"10%
15%
20%
25%
30%
35%
40%
Percentage of Straggler 69.0 69.5 70.0 70.5 71.0 71.5 72.0 72.5 73.0"
REFERENCES,0.9553903345724907,Accuracy (%)
REFERENCES,0.9591078066914498,"Invariant
Ordered
Random"
REFERENCES,0.9628252788104089,(b) CIFAR10 - VGG9 (100 Clients)
REFERENCES,0.966542750929368,"10%
15%
20%
25%
30%
35%
40%
Percentage of Straggler 76.0 76.5 77.0 77.5 78.0 78.5"
REFERENCES,0.9702602230483272,Accuracy (%)
REFERENCES,0.9739776951672863,"Invariant
Ordered
Random"
REFERENCES,0.9776951672862454,(c) FEMNIST - CNN (100 Clients)
REFERENCES,0.9814126394052045,Figure 8: Accuracy of varying the straggler ratios from 10% to 40% with 0.75 sub-model size
REFERENCES,0.9851301115241635,"A.6
Scalability of FLuID with Client Sampling"
REFERENCES,0.9888475836431226,"As the federated learning system scales, FL servers sample a subset of clients participating in each
training round. At any point in training, FLuID is capable of recalibrating stragglers and supports
dynamic changes during runtime. The ability to adjust to a different set of clients and identify
stragglers in every training round enables FLuID to easily incorporate client sampling into its process.
We scaled FLuID to 1,000 clients with the FEMNIST dataset for 500 global training rounds. We run
with a client sampling ratio of 10%, as used by the prior works in federated learning spaces such
as FjORD [HLA+21]. We present the accuracy results in Table 5 against each sub-model size for
Invariant Dropout and the baseline techniques. Invariant Dropout maintains a better accuracy profile
than the baselines even when scaled up to 1000 clients while incorporating client sampling."
REFERENCES,0.9925650557620818,"Table 5: Accuracy comparison of Random Dropout, Ordered Dropout, and Invariant Dropout as for
FEMNIST with 1000 clients and client sampling of 10%."
REFERENCES,0.9962825278810409,"r=0.95
r=0.85
r=0.75
r=0.65
r=0.40
Random
87.9
87.5
87.5
86.9
85.7
Ordered
87.8
88.0
87.5
87.3
87.0
Invariant
88.1
88.2
88.0
87.7
87.2"
