Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0006207324643078833,"Label differential privacy (DP) is designed for learning problems with private labels
1"
ABSTRACT,0.0012414649286157666,"and public features. Although various methods have been proposed for learning
2"
ABSTRACT,0.00186219739292365,"under label DP, the theoretical limits remain unknown. The main challenge is to
3"
ABSTRACT,0.002482929857231533,"take infimum over all possible learners with arbitrary model complexity. In this
4"
ABSTRACT,0.0031036623215394167,"paper, we investigate the fundamental limits of learning with label DP under both
5"
ABSTRACT,0.0037243947858473,"central and local models. To overcome the challenge above, we derive new lower
6"
ABSTRACT,0.004345127250155183,"bounds on testing errors that are adaptive to the model complexity. Our analyses
7"
ABSTRACT,0.004965859714463066,"indicate that ϵ-local label DP only enlarges the sample complexity with respect to
8"
ABSTRACT,0.00558659217877095,"ϵ, without affecting the convergence rate over the sample size N, except the case
9"
ABSTRACT,0.006207324643078833,"with heavy-tailed label. Under the central model, the performance loss due to the
10"
ABSTRACT,0.006828057107386716,"privacy mechanism is further weakened, such that the additional sample complexity
11"
ABSTRACT,0.0074487895716946,"becomes negligible. Overall, our analysis validates the promise of learning under
12"
ABSTRACT,0.008069522036002483,"the label DP from a theoretical perspective and shows that the learning performance
13"
ABSTRACT,0.008690254500310366,"can be significantly improved by weakening the DP definition to only labels.
14"
INTRODUCTION,0.00931098696461825,"1
Introduction
15"
INTRODUCTION,0.009931719428926133,"Many modern machine learning tasks require sensitive training samples that need to be protected
16"
INTRODUCTION,0.010552451893234015,"from leakage [1]. As a standard approach for privacy protection, differential privacy (DP) [2] has
17"
INTRODUCTION,0.0111731843575419,"been extensively studied [3–9]. However, the learning performances under original DP definition
18"
INTRODUCTION,0.011793916821849782,"are usually far from satisfactory [10–13]. Therefore, researchers attempt to design weakened DP
19"
INTRODUCTION,0.012414649286157667,"requirements, under which the performances can be significantly improved, while still securing
20"
INTRODUCTION,0.01303538175046555,"sensitive information. Under such background, label DP has emerged in recent years [14], which
21"
INTRODUCTION,0.013656114214773432,"regards features as public, while only labels are sensitive and need to be protected. Such setting is
22"
INTRODUCTION,0.014276846679081317,"realistic in many applications, such as computational advertising [15], recommendation systems [16]
23"
INTRODUCTION,0.0148975791433892,"and medical diagnosis [17]. These tasks usually use some basic demographic information as features,
24"
INTRODUCTION,0.015518311607697082,"which can be far less sensitive.
25"
INTRODUCTION,0.016139044072004966,"Despite various approaches for learning with label DP [14, 18–21], the fundamental limits are
26"
INTRODUCTION,0.01675977653631285,"still unknown. An interesting question is: By weakening the DP definitions to only labels, how
27"
INTRODUCTION,0.01738050900062073,"much accuracy improvement is possible? From an information-theoretic perspective [22], the
28"
INTRODUCTION,0.018001241464928614,"underlying limits of statistical problems are characterized by the minimax lower bound, which takes
29"
INTRODUCTION,0.0186219739292365,"the supremum over all possible distributions from a general class, and infimum over all learners.
30"
INTRODUCTION,0.019242706393544383,"Deriving minimax lower bounds for learning under the label DP is challenging in two aspects. Firstly,
31"
INTRODUCTION,0.019863438857852266,"under label DP, each sample has both public (i.e. the feature) and private (i.e. the label) components.
32"
INTRODUCTION,0.020484171322160148,"Directly applying the methods for original DP [23–27] treats all components as private, and thus does
33"
INTRODUCTION,0.02110490378646803,"not yield tight results. Secondly, the classical packing method [47] is only suitable for fixed model
34"
INTRODUCTION,0.021725636250775917,"structures with fixed dimensionality. However, to establish lower bounds, one needs to take infimum
35"
INTRODUCTION,0.0223463687150838,"over all possible learners with arbitrary model complexity.
36"
INTRODUCTION,0.022967101179391682,"Classification
Regression
Regression
Bounded label noise
Unbounded label noise"
INTRODUCTION,0.023587833643699565,"Local
˜O((N(ϵ2 ∧1))−β(γ+1)"
INTRODUCTION,0.024208566108007448,"2β+d )
˜O

(N(ϵ2 ∧1)−
2β
d+2β )

O

(Nϵ2)
−
2β(p−1)
2pβ+d(p−1) ∨N −
2β
2β+d
"
INTRODUCTION,0.024829298572315334,"Central ˜O

N −β(γ+1)"
INTRODUCTION,0.025450031036623216,2β+d + (ϵN)−β(γ+1)
INTRODUCTION,0.0260707635009311,"β+d

O

N −
2β
2β+d + (ϵN)−2β"
INTRODUCTION,0.02669149596523898,"d+β

O

N −
2β
2β+d + (ϵN)
−
2β(p−1)
pβ+d(p−1)
"
INTRODUCTION,0.027312228429546864,"Local full
O((N(ϵ2 ∧1))−β(γ+1)"
INTRODUCTION,0.027932960893854747,"2β+2d )
O((N(ϵ2 ∧1))−
β
β+d )
O((N(ϵ2 ∧1))
−
β(p−1)
pβ+d(p−1) )"
INTRODUCTION,0.028553693358162633,"Non-priv.
O(N −β(γ+1)"
INTRODUCTION,0.029174425822470516,"2β+d )
O(N −
2β
2β+d )
O(N −
2β
2β+d )"
INTRODUCTION,0.0297951582867784,Table 1: Minimax rate of convergence under label differential privacy. d is the dimension of features.
INTRODUCTION,0.03041589075108628,"In this paper, we investigate the theoretical limits of classification and regression problems under label
37"
INTRODUCTION,0.031036623215394164,"DP. Our analysis involves both central and local models. For each problem, we derive the information-
38"
INTRODUCTION,0.03165735567970205,"theoretic minimax lower bound of the risk function over a wide class of distributions satisfying the
39"
INTRODUCTION,0.03227808814400993,"β-Hölder smoothness and the γ-Tsybakov margin assumption [28] (see Assumption 1 for details).
40"
INTRODUCTION,0.032898820608317815,"The general idea is to convert the problem to multiple hypothesis testing. To overcome the challenges
41"
INTRODUCTION,0.0335195530726257,"above, we provide a bound of Kullback-Leibler divergence over joint distributions of private and
42"
INTRODUCTION,0.03414028553693358,"public random variables, which is tighter than the bound between fully private variables. Moreover,
43"
INTRODUCTION,0.03476101800124146,"under the central model, instead of using the packing method, we develop a new lower bound on the
44"
INTRODUCTION,0.035381750465549346,"minimum testing error for each pair of hypotheses based on the group privacy property [4], which
45"
INTRODUCTION,0.03600248292985723,"is suitable for arbitrary model complexity. After deriving minimax lower bounds, we also propose
46"
INTRODUCTION,0.03662321539416512,"algorithms with matching upper bounds to validate the tightness of our results.
47"
INTRODUCTION,0.037243947858473,"The results are shown in Table 1, in which the third row refers to the bounds under the original local
48"
INTRODUCTION,0.03786468032278088,"DP definition, while the fourth row lists the non-private baselines. To the best of our knowledge,
49"
INTRODUCTION,0.038485412787088766,"minimax rates under central DP have not been established, and are thus not listed here. The main
50"
INTRODUCTION,0.03910614525139665,"findings are summarized as follows.
51"
INTRODUCTION,0.03972687771570453,"• Under ϵ-local label DP, for classification and regression with bounded label noise, the
52"
INTRODUCTION,0.040347610180012414,"sample complexity is larger by a factor of O(1/ϵ2). However, the convergence rate remains
53"
INTRODUCTION,0.040968342644320296,"unaffected, which is in clear contrast with the original DP, under which the convergence rate
54"
INTRODUCTION,0.04158907510862818,"is slower.
55"
INTRODUCTION,0.04220980757293606,"• Under ϵ-local label DP constraint, for regression with heavy-tailed label noise, the conver-
56"
INTRODUCTION,0.04283054003724395,"gence rate of risk over N becomes slower, indicating that heavy-tailed labels increase the
57"
INTRODUCTION,0.043451272501551834,"difficulty of privacy protection.
58"
INTRODUCTION,0.04407200496585972,"• Under ϵ-central label DP constraint, the performance loss caused by the privacy mechanism
59"
INTRODUCTION,0.0446927374301676,"becomes further weakened. The risk only increases by a term that decays faster than the
60"
INTRODUCTION,0.04531346989447548,"non-private rate, indicating that the additional sample complexity caused by the privacy
61"
INTRODUCTION,0.045934202358783364,"mechanism becomes negligible with large N.
62"
INTRODUCTION,0.04655493482309125,"In general, our analysis provides a theoretical perspective of understanding label DP. The result
63"
INTRODUCTION,0.04717566728739913,"shows that by weakening the DP definition to protecting labels only, the learning performances can
64"
INTRODUCTION,0.04779639975170701,"be significantly improved.
65"
RELATED WORK,0.048417132216014895,"2
Related Work
66"
RELATED WORK,0.04903786468032278,"Label DP. Under the local model, labels are randomized before training. The simplest method is
67"
RELATED WORK,0.04965859714463067,"randomized response [30]. An important improvement is proposed in [14], called RRWithPrior,
68"
RELATED WORK,0.05027932960893855,"which incorporates prior distribution. [19] proposes ALIBI, which further improves randomized
69"
RELATED WORK,0.05090006207324643,"response by generating soft labels through Bayesian inference. There are also several methods for
70"
RELATED WORK,0.051520794537554315,"regression under label DP [18,31]. Under central label DP, [20] proposes a clustering approach. [19]
71"
RELATED WORK,0.0521415270018622,"proposes private aggregation of teacher ensembles (PATE), which is then further improved in [21].
72"
RELATED WORK,0.05276225946617008,"Minimax analysis for public data. Minimax theory provides a rigorous framework for the best
73"
RELATED WORK,0.05338299193047796,"possible performance of an algorithm given some assumptions. Classical methods include Le
74"
RELATED WORK,0.054003724394785846,"Cam [32], Fano [33] and Assouad [34]. Using these methods, minimax lower bounds have been
75"
RELATED WORK,0.05462445685909373,"widely established for both classification and regression problems [28, 29, 35–41]. If the feature
76"
RELATED WORK,0.05524518932340161,"vector has bounded support, then the minimax rate of classification and regression are O(N −β(γ+1)"
RELATED WORK,0.055865921787709494,"2β+d )
77"
RELATED WORK,0.05648665425201738,"and O(N −
2β
2β+d ), respectively.
78"
RELATED WORK,0.057107386716325266,"Minimax analysis for private data. Under the local model, [42] finds the relation between label DP
79"
RELATED WORK,0.05772811918063315,"and stochastic query. [23] and [24] develop the variants of Le Cam, Fano, and Assouad’s method
80"
RELATED WORK,0.05834885164494103,"under local DP. Lower bounds are then established for various statistical problems, such as mean
81"
RELATED WORK,0.058969584109248914,"estimation [43–46], classification [26] and regression [27]. Under central model, for pure DP, the
82"
RELATED WORK,0.0595903165735568,"standard approach is the packing method [47], which is then used in hypothesis testing [48], mean
83"
RELATED WORK,0.06021104903786468,"estimation [49,50], and learning of distributions [51–53]. There are also several works on approximate
84"
RELATED WORK,0.06083178150217256,"DP, such as [54,55].
85"
RELATED WORK,0.061452513966480445,"This work studies the theoretical limits of label DP, under which each sample is a mixture of public
86"
RELATED WORK,0.06207324643078833,"feature and private labels, thus existing methods can not be directly applied here. Under the central
87"
RELATED WORK,0.06269397889509622,"model, the minimax analysis becomes more challenging, since the packing method is only suitable
88"
RELATED WORK,0.0633147113594041,"for fixed model structures (i.e. the dimensionality of model output is fixed), while we need to find the
89"
RELATED WORK,0.06393544382371198,"minimum possible error over all possible learners with arbitrary output dimensions. As a result, the
90"
RELATED WORK,0.06455617628801986,"lower bounds of general classification and regression problems have not been established even under
91"
RELATED WORK,0.06517690875232775,"the original DP definition. To overcome such challenge, we develop a new approach to bound the
92"
RELATED WORK,0.06579764121663563,"error of hypothesis testing (see Lemma 1 in Appendix D).
93"
PRELIMINARIES,0.06641837368094351,"3
Preliminaries
94"
PRELIMINARIES,0.0670391061452514,"In this section, we show some necessary definitions, background information, and notations.
95"
LABEL DP,0.06765983860955928,"3.1
Label DP
96"
LABEL DP,0.06828057107386716,"To begin with, we review the definition of DP. Suppose the dataset consists of N samples (xi, yi),
97"
LABEL DP,0.06890130353817504,"i = 1, . . . , N, in which xi ∈X is the feature vector, while yi ∈Y ⊂Rd is the label.
98"
LABEL DP,0.06952203600248293,"Definition 1. (Differential Privacy (DP) [2]) Let ϵ ≥0. A randomized function A : (X, Y)N →Θ
99"
LABEL DP,0.07014276846679081,"is ϵ-DP if for any two adjacent datasets D, D′ ∈(X, Y)N and any S ⊆Θ,
100"
LABEL DP,0.07076350093109869,"P(A(D) ∈S) ≤eϵP(A(D′) ∈S),
(1)
in which D and D′ are adjacent if they differ only on a single sample, including both the feature
101"
LABEL DP,0.07138423339540657,"vector and the label.
102"
LABEL DP,0.07200496585971446,"In machine learning tasks, the output of A is the model parameters, while the input is the training
103"
LABEL DP,0.07262569832402235,"dataset. Definition 1 requires that both features and labels are privatized. Consider that in some
104"
LABEL DP,0.07324643078833024,"applications, the features may be much less sensitive, the notion of label DP is defined as follows.
105"
LABEL DP,0.07386716325263812,"Definition 2. (Central label DP) A randomized function A is ϵ-label DP if for any two datasets D
106"
LABEL DP,0.074487895716946,"and D′ that differ on the label of only one training sample and any S ⊆Θ, (1) holds.
107"
LABEL DP,0.07510862818125388,"Compared with Definition 1, Definition 2 only requires the output to be insensitive to the replacement
108"
LABEL DP,0.07572936064556177,"of a label. Therefore label DP is a weaker requirement. Correspondingly, the local label DP is defined
109"
LABEL DP,0.07635009310986965,"as follows.
110"
LABEL DP,0.07697082557417753,"Definition 3. (Local label DP) A randomized function M : (X, Y) →Z is ϵ-local label DP if
111"
LABEL DP,0.07759155803848541,"sup
y,y′∈Y
sup
S⊆Z
ln P(M(x, y) ∈S)"
LABEL DP,0.0782122905027933,"P(M(x, y′) ∈S) ≤ϵ.
(2)"
LABEL DP,0.07883302296710118,"Definition 3 requires that each label is privatized locally before running any machine learning
112"
LABEL DP,0.07945375543140906,"algorithms. It is straightforward to show that local label DP ensures central label DP. To be more
113"
LABEL DP,0.08007448789571694,"precise, we have the following proposition.
114"
LABEL DP,0.08069522036002483,"Proposition 1. Let zi = M(xi, yi) for i = 1, . . . , N. If A is a function of (xi, zi), i = 1, . . . , N,
115"
LABEL DP,0.08131595282433271,"then A is ϵ-label DP.
116"
RISK OF CLASSIFICATION AND REGRESSION,0.08193668528864059,"3.2
Risk of Classification and Regression
117"
RISK OF CLASSIFICATION AND REGRESSION,0.08255741775294848,"In supervised learning problems, given N samples (Xi, Yi), i = 1, . . . , N drawn from a common
118"
RISK OF CLASSIFICATION AND REGRESSION,0.08317815021725636,"distribution, the task is to learn a function g : X →Y. For a loss function l : Y × Y →R, the goal
119"
RISK OF CLASSIFICATION AND REGRESSION,0.08379888268156424,"is to minimize the risk function, which is defined as the expectation of loss function between the
120"
RISK OF CLASSIFICATION AND REGRESSION,0.08441961514587212,"predicted value and the ground truth:
121"
RISK OF CLASSIFICATION AND REGRESSION,0.08504034761018,"R = E[l( ˆY , Y )].
(3)"
RISK OF CLASSIFICATION AND REGRESSION,0.0856610800744879,"The minimum risk among all function g is called Bayes risk, i.e. R∗= ming E[l(g(X, Y ))]. In
122"
RISK OF CLASSIFICATION AND REGRESSION,0.08628181253879579,"practice, the sample distribution is unknown, and we need to learn g from samples. Therefore, the
123"
RISK OF CLASSIFICATION AND REGRESSION,0.08690254500310367,"risk of any practical classifiers is larger than Bayes risk. The gap R −R∗is called excess risk, and we
124"
RISK OF CLASSIFICATION AND REGRESSION,0.08752327746741155,"hope that R −R∗to be as small as possible. Now we discuss classification and regression problems
125"
RISK OF CLASSIFICATION AND REGRESSION,0.08814400993171943,"separately.
126"
RISK OF CLASSIFICATION AND REGRESSION,0.08876474239602732,"1) Classification. For classification problems, the size of Y is finite. For convenience, we denote
127"
RISK OF CLASSIFICATION AND REGRESSION,0.0893854748603352,"Y = [K], in which [K] := {1, . . . , K}. In this paper, we use 0 −1 loss, i.e. l( ˆY , Y ) = 1( ˆY ̸= Y ),
128"
RISK OF CLASSIFICATION AND REGRESSION,0.09000620732464308,"then R = P( ˆY ̸= Y ). Define K functions η1, . . . , ηK as the conditional class probabilities:
129"
RISK OF CLASSIFICATION AND REGRESSION,0.09062693978895096,"ηk(x) = P(Y = k|X = x), k = 1, . . . , K.
(4)"
RISK OF CLASSIFICATION AND REGRESSION,0.09124767225325885,"Under this setting, the Bayes optimal classifier and the corresponding Bayes risk is
130"
RISK OF CLASSIFICATION AND REGRESSION,0.09186840471756673,"c∗(x)
=
arg max
j∈[K]
ηj(x),
(5)"
RISK OF CLASSIFICATION AND REGRESSION,0.09248913718187461,"R∗
cls
=
P(c∗(X) ̸= Y ).
(6)"
RISK OF CLASSIFICATION AND REGRESSION,0.0931098696461825,"2) Regression. Now we consider the case with Y having infinite size. We use ℓ2 loss in this paper, i.e.
131"
RISK OF CLASSIFICATION AND REGRESSION,0.09373060211049038,"l( ˆY , Y ) = ( ˆY −Y )2. Then the Bayes risk is
132"
RISK OF CLASSIFICATION AND REGRESSION,0.09435133457479826,"R∗
reg = E[(Y −η(X))2].
(7)"
RISK OF CLASSIFICATION AND REGRESSION,0.09497206703910614,"Then the following proposition gives a bound of the excess risk for classification and regression
133"
RISK OF CLASSIFICATION AND REGRESSION,0.09559279950341402,"problems.
134"
RISK OF CLASSIFICATION AND REGRESSION,0.09621353196772191,"Proposition 2. For any classifier c : X →[K], the excess risk of classification is bounded by
135"
RISK OF CLASSIFICATION AND REGRESSION,0.09683426443202979,"Rcls −R∗
cls =
Z
(η∗(x) −E[ηc(x)(x)])f(x)dx.
(8)"
RISK OF CLASSIFICATION AND REGRESSION,0.09745499689633767,"For any regression estimate ˆη : X →Y, the excess risk of regression is bounded by
136"
RISK OF CLASSIFICATION AND REGRESSION,0.09807572936064556,"Rreg −R∗
reg = E[(ˆη(X) −η(X))2].
(9)"
RISK OF CLASSIFICATION AND REGRESSION,0.09869646182495345,"The proof of Proposition 2 is shown in Appendix A. Finally, we state some basic assumptions that
137"
RISK OF CLASSIFICATION AND REGRESSION,0.09931719428926133,"will be used throughout this paper.
138"
RISK OF CLASSIFICATION AND REGRESSION,0.09993792675356922,"Assumption 1. There exists some constants L, β, CT , γ, c, D and θ ∈(0, 1] such that
139"
RISK OF CLASSIFICATION AND REGRESSION,0.1005586592178771,"(a) For all j ∈[K] and any x, x′, |ηj(x) −ηj(x′)| ≤L ∥x −x′∥β;
140"
RISK OF CLASSIFICATION AND REGRESSION,0.10117939168218498,"(b) For any t > 0, P (0 < η∗(X) −ηs(X) < t) ≤CT tγ, in which ηs(x) is the second largest one
141"
RISK OF CLASSIFICATION AND REGRESSION,0.10180012414649287,"among {η1(x), . . . , ηK(x)};
142"
RISK OF CLASSIFICATION AND REGRESSION,0.10242085661080075,"(c) The feature vector X has a probability density function (pdf) f which is bounded from below, i.e.
143"
RISK OF CLASSIFICATION AND REGRESSION,0.10304158907510863,"f(x) ≥c;
144"
RISK OF CLASSIFICATION AND REGRESSION,0.10366232153941651,"(d) For all r < D, Vr(x) ≥θvdrd, in which Vr(x) is the volume (Lebesgue measure) of B(x, r) ∩X,
145"
RISK OF CLASSIFICATION AND REGRESSION,0.1042830540037244,"vd is the volume of a unit ball.
146"
RISK OF CLASSIFICATION AND REGRESSION,0.10490378646803228,"Assumption 1 (a) requires that all ηj are Hölder continuous. This condition is common in literatures
147"
RISK OF CLASSIFICATION AND REGRESSION,0.10552451893234016,"about nonparametric statistics [28]. (b) is generalized from the Tsybakov noise assumption for binary
148"
RISK OF CLASSIFICATION AND REGRESSION,0.10614525139664804,"classification, which is commonly used in many existing works in the field of both nonparametric
149"
RISK OF CLASSIFICATION AND REGRESSION,0.10676598386095593,"classification [29,37,40,41] and differential privacy [26,27]. If K = 2, then η∗and ηs refer to the
150"
RISK OF CLASSIFICATION AND REGRESSION,0.10738671632526381,"larger and smaller class conditional probability, respectively. An intuitive understanding of (b) is that
151"
RISK OF CLASSIFICATION AND REGRESSION,0.10800744878957169,"in the majority of the support, the maximum value among {η1(x), . . . , ηK(x)} should have some
152"
RISK OF CLASSIFICATION AND REGRESSION,0.10862818125387957,"gap to the second largest one. With sufficiently large sample size and model complexity, assumption
153"
RISK OF CLASSIFICATION AND REGRESSION,0.10924891371818746,"(b) ensures that for test samples within the majority of the support X, the algorithm is highly likely to
154"
RISK OF CLASSIFICATION AND REGRESSION,0.10986964618249534,"correctly identify the class with the maximum conditional probability. Therefore, in (b), we only care
155"
RISK OF CLASSIFICATION AND REGRESSION,0.11049037864680322,"about η∗(x) and ηs(x), while other classes with small conditional probabilities can be ignored. (c)
156"
RISK OF CLASSIFICATION AND REGRESSION,0.1111111111111111,"is usually called ""strong density assumption"" in existing works [39,40], which is quite strong. It is
157"
RISK OF CLASSIFICATION AND REGRESSION,0.11173184357541899,"possible to relax this assumption so that the theoretical analysis becomes suitable for general cases.
158"
RISK OF CLASSIFICATION AND REGRESSION,0.11235257603972688,"However, we do not focus on such generalization in this paper. Assumption (d) prevents the corner of
159"
RISK OF CLASSIFICATION AND REGRESSION,0.11297330850403477,"the support X from being too sharp. In the remainder of this section, denote Fcls as the set of all
160"
RISK OF CLASSIFICATION AND REGRESSION,0.11359404096834265,"pairs (f, η) satisfying Assumption 1.
161"
CLASSIFICATION,0.11421477343265053,"4
Classification
162"
CLASSIFICATION,0.11483550589695841,"In this section, we derive the upper and lower bounds of learning under central and local label DP,
163"
CLASSIFICATION,0.1154562383612663,"respectively.
164"
LOCAL LABEL DP,0.11607697082557418,"4.1
Local Label DP
165"
LOCAL LABEL DP,0.11669770328988206,"1) Lower bound. The following theorem shows the minimax lower bound, which characterizes the
166"
LOCAL LABEL DP,0.11731843575418995,"theoretical limit.
167"
LOCAL LABEL DP,0.11793916821849783,"Theorem 1. Denote Mϵ as the set of all privacy mechanisms satisfying ϵ-local label DP (Definition
168"
LOCAL LABEL DP,0.11855990068280571,"3). Then
169"
LOCAL LABEL DP,0.1191806331471136,"inf
ˆY
inf
M∈Mϵ
sup
(f,η)∈Fcls
(Rcls −R∗
cls) ≳

N
 
ϵ2 ∧1
−β(γ+1)"
LOCAL LABEL DP,0.11980136561142148,"2β+d .
(10)"
LOCAL LABEL DP,0.12042209807572936,"Proof. (Outline) It suffices to derive (10) with K = 2. We convert the problem into multiple binary
170"
LOCAL LABEL DP,0.12104283054003724,"hypothesis testing problems. In particular, we divide the support into G bins. For some of them, we
171"
LOCAL LABEL DP,0.12166356300434512,"construct two opposite hypotheses such that they are statistically not distinguishable. Our proof uses
172"
LOCAL LABEL DP,0.122284295468653,"some techniques in local DP [24] and some classical minimax theory [28]. The detailed proof is
173"
LOCAL LABEL DP,0.12290502793296089,"shown in Appendix B.
174"
LOCAL LABEL DP,0.12352576039726877,"In Theorem 1, (10) takes supremum over all joint distributions of (X, Y ), and infimum over all
175"
LOCAL LABEL DP,0.12414649286157665,"classifiers and privacy mechanisms satisfying ϵ-local label DP.
176"
LOCAL LABEL DP,0.12476722532588454,"2) Upper bound. We then show that the bound (10) is achievable. Let the privacy mechanism M(x, y)
177"
LOCAL LABEL DP,0.12538795779019243,"outputs a K dimensional vector, with each component being either 0 or 1, such that
178"
LOCAL LABEL DP,0.12600869025450032,"P(M(x, y)(j) = 1) ="
LOCAL LABEL DP,0.1266294227188082,"(
e
ϵ
2
e
ϵ
2 +1
if
y = j"
E,0.12725015518311608,"1
e
ϵ
2 +1
if
y ̸= j,
(11)"
E,0.12787088764742396,"and P(M(x, y)(j) = 0) = 1 −P(M(x, y)(j) = 1), in which M(x, y)(j) is the j-th component of
179"
E,0.12849162011173185,"M(x, y). For N random training samples (Xi, Yi), let Zi = M(Xi, Yi), and correspondingly, Zi(j)
180"
E,0.12911235257603973,"is the j-th component of Zi.
181"
E,0.1297330850403476,"Divide the support X into G bins, named B1, . . . , BG, such that the length of each bin is h.
182"
E,0.1303538175046555,"B1, . . . , BG are disjoint, and these bins form a covering of X, i.e. X ⊂∪G
l=1Bl. Then calcu-
183"
E,0.13097454996896338,"late
184"
E,0.13159528243327126,"Slj =
X"
E,0.13221601489757914,"i:Xi∈Bl
Zi(j), l = 1, . . . , G, j = 1, . . . , K,
(12)"
E,0.13283674736188703,"The classification within the l-th bin is
185"
E,0.1334574798261949,"cl = arg max
j
Slj,
(13)"
E,0.1340782122905028,"such that the the prediction given x is c(x) = cl for all x ∈Bl. The next theorem shows the privacy
186"
E,0.13469894475481067,"guarantee, as well as the bound of the excess risk.
187"
E,0.13531967721911856,"Theorem 2. The privacy mechanism M is ϵ-local label DP. Moreover, under Assumption 1, with
188"
E,0.13594040968342644,"h ∼
 
N(ϵ2 ∧1)/ ln K
−
1
2β+d , the excess risk of the classifier described above can be upper bounded
189"
E,0.13656114214773432,"as follows:
190"
E,0.1371818746120422,"Rcls −R∗
cls ≲
N(ϵ2 ∧1) ln K"
E,0.1378026070763501,−β(γ+1)
E,0.13842333954065797,"2β+d
.
(14)"
E,0.13904407200496585,"Proof. (Outline) For privacy guarantee, we need to show that (11) is ϵ-local label DP:
191"
E,0.13966480446927373,"P(M(x, y) = z)
P(M(x, y′) = z)
=
ΠK
j=1
P(M(x, y)(j) = z(j))
P(M(x, y′)(j) = z(j))"
E,0.14028553693358162,"=
P(M(x, y)(y) = z(y))
P(M(x, y′)(y) = z(y))
P(M(x, y)(y′) = z(y′))
P(M(x, y′)(y′) = z(y′))"
E,0.1409062693978895,"≤
e
ϵ
2 e
ϵ
2 = eϵ.
(15)"
E,0.14152700186219738,"According to Definition 3, M is ϵ-local label DP. For the performance guarantee (14), according to
192"
E,0.14214773432650527,"Proposition 2, we need to bound η∗(x) −E[ηc(x)(x)] for each x. If η∗(x) −ηs(x) is large, then with
193"
E,0.14276846679081315,"high probability, c(x) = c∗(x), and then η∗(x) = ηc(x)(x). Thus we mainly consider the case with
194"
E,0.14338919925512103,"small η∗(x) −ηs(x). The details of proof are shown in Appendix C.
195"
E,0.1440099317194289,"The lower bound (10) and the upper bound (14) match up to a logarithm factor, indicating that the
196"
E,0.1446306641837368,"results are tight. Now we comment on the results.
197"
E,0.1452513966480447,"Remark 1. 1) Comparison with non-private bound. The classical minimax lower bound for non-
198"
E,0.1458721291123526,private classification problem is N −β(γ+1)
E,0.14649286157666047,"2β+d . Therefore, the lower bound (10) reaches the non-private
199"
E,0.14711359404096835,"bound with ϵ ≳1. With small ϵ, N training samples with privatized labels roughly equals Nϵ2
200"
E,0.14773432650527624,"non-privatized samples in terms of performance.
201"
E,0.14835505896958412,"2) Comparison with local DP that protects both features and labels. In this case, the optimal
202"
E,0.148975791433892,"excess risk is (Nϵ2)−β(γ+1)/(2β+2d) ∨N −β(γ+1)/(2β+d), which is worse than the right hand side of
203"
E,0.14959652389819988,"(10). Such result indicates that compared with classical DP, label DP incurs significantly weaker
204"
E,0.15021725636250777,"performance loss.
205"
E,0.15083798882681565,"3) Comparison with other baseline methods. If we use the randomized response method instead
206"
E,0.15145872129112353,"of the privacy mechanism (11), then the performance decreases sharply with the number of classes
207"
E,0.15207945375543142,"K. Several methods have been proposed to improve the randomized response method, such as
208"
E,0.1527001862197393,"RRWithPrior [14] and ALIBI [19]. However, these methods are not guaranteed in theory.
209"
CENTRAL LABEL DP,0.15332091868404718,"4.2
Central Label DP
210"
CENTRAL LABEL DP,0.15394165114835506,"1) Lower bound. The following theorem shows the minimax lower bound under the central label DP.
211"
CENTRAL LABEL DP,0.15456238361266295,"Theorem 3. Denote Aϵ as the set of all learning algorithms satisfying ϵ-label DP (Definition 2).
212"
CENTRAL LABEL DP,0.15518311607697083,"Then
213"
CENTRAL LABEL DP,0.1558038485412787,"inf
A∈Aϵ
sup
(f,η)∈Fcls
(Rcls −R∗
cls) ≳N −β(γ+1)"
CENTRAL LABEL DP,0.1564245810055866,2β+d + (ϵN)−β(γ+1)
CENTRAL LABEL DP,0.15704531346989448,"β+d .
(16)"
CENTRAL LABEL DP,0.15766604593420236,"Proof. (Outline) Lower bounds under central DP are usually constructed by packing method [47],
214"
CENTRAL LABEL DP,0.15828677839851024,"which works for fixed output dimensions. However, to achieve a desirable bias and variance tradeoff,
215"
CENTRAL LABEL DP,0.15890751086281812,"the model complexity needs to increase with N. In our proof, we still divide the support into G bins
216"
CENTRAL LABEL DP,0.159528243327126,"and construct two hypotheses for each bin, but we develop a new tool (see Lemma 1) to give a lower
217"
CENTRAL LABEL DP,0.1601489757914339,"bound of the minimum error of hypothesis testing. We then use the group privacy property [4] to get
218"
CENTRAL LABEL DP,0.16076970825574177,"the overall lower bound. The details can be found in Appendix D.
219"
CENTRAL LABEL DP,0.16139044072004965,"2) Upper bound. Now we show that (16) is achievable. Similar to the local label DP problem, now
220"
CENTRAL LABEL DP,0.16201117318435754,"divide the support into G bins, such that the length of each bin is h. Now the classification within the
221"
CENTRAL LABEL DP,0.16263190564866542,"l-th bin follows a exponential mechanism [56]:
222"
CENTRAL LABEL DP,0.1632526381129733,"P(cl = j|X1:N, Y1:N) =
eϵnlj/2
PK
k=1 eϵnlk/2 ,
(17)"
CENTRAL LABEL DP,0.16387337057728119,"in which nlj = PN
i=1 1(Xi ∈Bl, Yi = j). Then let c(x) = cl for x ∈Bl. The excess risk is
223"
CENTRAL LABEL DP,0.16449410304158907,"bounded in the next theorem.
224"
CENTRAL LABEL DP,0.16511483550589695,"Theorem 4. The privacy mechanism (17) is ϵ-label DP. Moreover, under Assumption 1, if h scales as
225"
CENTRAL LABEL DP,0.16573556797020483,h ∼(ln K/ϵN)
CENTRAL LABEL DP,0.16635630043451272,"1
β+d + (ln K/N)
1
2β+d , then the excess risk can be bounded as follows:
226"
CENTRAL LABEL DP,0.1669770328988206,"R −R∗≲
 N ln K"
CENTRAL LABEL DP,0.16759776536312848,−β(γ+1)
CENTRAL LABEL DP,0.16821849782743636,"2β+d
+
 ϵN ln K"
CENTRAL LABEL DP,0.16883923029174425,−β(γ+1)
CENTRAL LABEL DP,0.16945996275605213,"β+d
.
(18)"
CENTRAL LABEL DP,0.17008069522036,"Proof. (Outline) The privacy guarantee of the exponential mechanism has been analyzed in [4].
227"
CENTRAL LABEL DP,0.1707014276846679,"Following these existing analyses, it can be shown that (17) is ϵ-label DP. It remains to show (18).
228"
CENTRAL LABEL DP,0.1713221601489758,"Note that if η∗(x) −ηs(x) is large, then the difference between the largest and the second largest
229"
CENTRAL LABEL DP,0.1719428926132837,"one from {nlj|j = 1, . . . , K} will also be large. From (17), the following inequality holds with high
230"
CENTRAL LABEL DP,0.17256362507759157,"probability: cl = arg maxjnlj = arg maxjηj(x) = c∗(x), which means that the classifier makes
231"
CENTRAL LABEL DP,0.17318435754189945,"optimal prediction. Hence we mainly consider the case with small η∗(x) −ηs(x). The details of the
232"
CENTRAL LABEL DP,0.17380509000620734,"proof can be found in Appendix E.
233"
CENTRAL LABEL DP,0.17442582247051522,"The upper and lower bounds match up to logarithmic factors. In (18), the first term is just the
234"
CENTRAL LABEL DP,0.1750465549348231,"non-private convergence rate, while the second term (ϵN)−β(γ+1)"
CENTRAL LABEL DP,0.17566728739913098,"β+d
can be regarded as the additional
235"
CENTRAL LABEL DP,0.17628801986343887,"risk caused by the privacy mechanism. It decays faster with N compared with the first term, thus the
236"
CENTRAL LABEL DP,0.17690875232774675,"additional performance loss caused by the privacy mechanism becomes negligible as N increases.
237"
CENTRAL LABEL DP,0.17752948479205463,"This result is crucially different from the local model, under which the privacy mechanism always
238"
CENTRAL LABEL DP,0.17815021725636251,"induces higher sample complexity by a factor of O(1/(ϵ2 ∧1)).
239"
REGRESSION WITH BOUNDED NOISE,0.1787709497206704,"5
Regression with Bounded Noise
240"
REGRESSION WITH BOUNDED NOISE,0.17939168218497828,"Now we analyze the theoretical limits of regression problems under local and central label DP.
241"
REGRESSION WITH BOUNDED NOISE,0.18001241464928616,"Throughout this section, we assume that the label is restricted within a bounded interval.
242"
REGRESSION WITH BOUNDED NOISE,0.18063314711359404,"Assumption 2. Given any x ∈X, P(|Y | < T|X = x) = 1.
243"
REGRESSION WITH BOUNDED NOISE,0.18125387957790193,"Assumption 1 remains the same here. In the remainder of this section, denote Freg1 as the set of
244"
REGRESSION WITH BOUNDED NOISE,0.1818746120422098,"(f, η) that satisfies Assumption 1 and 2.
245"
LOCAL LABEL DP,0.1824953445065177,"5.1
Local Label DP
246"
LOCAL LABEL DP,0.18311607697082558,"1) Lower bound. Theorem 5 shows the minimax lower bound.
247"
LOCAL LABEL DP,0.18373680943513346,"Theorem 5. Denote Mϵ as the set of all privacy mechanisms satisfying ϵ-label DP. Then
248"
LOCAL LABEL DP,0.18435754189944134,"inf
ˆη
inf
M∈Mϵ
sup
(f,η)∈Freg1
(Rreg −R∗
reg) ≳(N(ϵ2 ∧1))−
2β
d+2β .
(19)"
LOCAL LABEL DP,0.18497827436374922,"The proof of Theorem 5 is similar to that of Theorem 1, except for some details in hypotheses
249"
LOCAL LABEL DP,0.1855990068280571,"construction and the final bound of excess risk. The details are shown in Appendix F.
250"
LOCAL LABEL DP,0.186219739292365,"2) Upper bound. The privacy mechanism is Z = Y + W, in which W ∼Lap(2T/ϵ). Then the
251"
LOCAL LABEL DP,0.18684047175667287,"privacy mechanism satisfies ϵ-label DP. In this case, the real regression function η(x) can be estimated
252"
LOCAL LABEL DP,0.18746120422098075,"using the nearest neighbor approach. Let
253"
LOCAL LABEL DP,0.18808193668528864,ˆη(x) = 1 k X
LOCAL LABEL DP,0.18870266914959652,"i∈Nk(x)
Zi,
(20)"
LOCAL LABEL DP,0.1893234016139044,"in which Nk(x) is the set of k nearest neighbors of x among X1, . . . , XN.
254"
LOCAL LABEL DP,0.18994413407821228,"Theorem 6. The method described above is ϵ-local label DP. Moreover, with k ∼N"
LOCAL LABEL DP,0.19056486654252017,"2β
d+2β (ϵ∧1)−
2d
d+2β ,
255"
LOCAL LABEL DP,0.19118559900682805,"then under Assumption 1 and 2,
256"
LOCAL LABEL DP,0.19180633147113593,"Rreg −R∗
reg ≲(N(ϵ2 ∧1))−
2β
d+2β .
(21)"
LOCAL LABEL DP,0.19242706393544382,"Proof. (Outline) Since |Y | < T, W ∼Lap(2T/ϵ), it is obvious that Z = Y + W is ϵ-local label
257"
LOCAL LABEL DP,0.1930477963997517,"DP. For the performance (21), the bias can be bounded by the k nearest neighbor distances based on
258"
LOCAL LABEL DP,0.19366852886405958,"Assumption 1(a). The variance of ˆη(x) scales inversely with k. An appropriate k can be selected to
259"
LOCAL LABEL DP,0.19428926132836746,"achieve a good tradeoff between bias and variance. The details are shown in Appendix G.
260"
LOCAL LABEL DP,0.19490999379267535,"From standard minimax analysis on regression problems, the non-private convergence rate is
261"
LOCAL LABEL DP,0.19553072625698323,"N −2β/(d+2β). From Theorem 5 and 6, the privatization process makes sample complexity larger by
262"
LOCAL LABEL DP,0.1961514587212911,"a O(1/ϵ2) factor.
263"
CENTRAL LABEL DP,0.196772191185599,"5.2
Central Label DP
264"
CENTRAL LABEL DP,0.1973929236499069,"1) Lower bound. The following theorem shows the minimax lower bound.
265"
CENTRAL LABEL DP,0.1980136561142148,"Theorem 7. Let Aϵ be the set of all algorithms satisfying ϵ-central DP. Then
266"
CENTRAL LABEL DP,0.19863438857852267,"inf
A∈Aϵ
sup
(f,η)∈Freg1
(Rreg −R∗
reg) ≳N −
2β
2β+d + (ϵN)−2β"
CENTRAL LABEL DP,0.19925512104283055,"d+β .
(22)"
CENTRAL LABEL DP,0.19987585350713843,"2) Upper bound. For each bin Bl, let nl = PN
i=1 1(Xi ∈Bl) be the number of samples in Bl. If
267"
CENTRAL LABEL DP,0.20049658597144632,"nl > 0, then
268"
CENTRAL LABEL DP,0.2011173184357542,"ˆηl = 1 nl N
X"
CENTRAL LABEL DP,0.20173805090006208,"i=1
1(Xi ∈Bl)Yi + Wl,
(23)"
CENTRAL LABEL DP,0.20235878336436997,"in which Wl ∼Lap(2/(nlϵ)). If nl = 0, i.e. no sample falls in Bl, then just let ˆηl = 0. For all
269"
CENTRAL LABEL DP,0.20297951582867785,"x ∈Bl, let ˆη(x) = ˆηl. The excess risk can be bounded with the following theorem.
270"
CENTRAL LABEL DP,0.20360024829298573,"Theorem 8. (23) is ϵ-label DP. Moreover, under Assumption 1 and 2, if h scales as h ∼N −
1
2β+d +
271"
CENTRAL LABEL DP,0.2042209807572936,"(ϵN)−
1
d+β , then the excess risk is bounded by
272"
CENTRAL LABEL DP,0.2048417132216015,"R −R∗≲N −
2β
2β+d + (ϵN)−2β"
CENTRAL LABEL DP,0.20546244568590938,"d+β .
(24)"
CENTRAL LABEL DP,0.20608317815021726,"The upper and lower bounds match, indicating that the results are tight. Again, the second term in
273"
CENTRAL LABEL DP,0.20670391061452514,"(24) converges faster than the first one with respect to N, the performance loss caused by privacy
274"
CENTRAL LABEL DP,0.20732464307883303,"constraints becomes negligible as N increases.
275"
REGRESSION WITH HEAVY-TAILED NOISE,0.2079453755431409,"6
Regression with Heavy-tailed Noise
276"
REGRESSION WITH HEAVY-TAILED NOISE,0.2085661080074488,"In this section, we consider the case such that the noise has tails. We make the following assumption.
277"
REGRESSION WITH HEAVY-TAILED NOISE,0.20918684047175667,"Assumption 3. For all x ∈X, E[|Y |p|X = x] ≤Mp for some p ≥2.
278"
REGRESSION WITH HEAVY-TAILED NOISE,0.20980757293606456,"Instead of requiring |Y | < T for some T, now we only assume that the p-th order moment is bounded.
279"
REGRESSION WITH HEAVY-TAILED NOISE,0.21042830540037244,"For non-private cases, given fixed noise variance, the tail does not affect the mean squared error of
280"
REGRESSION WITH HEAVY-TAILED NOISE,0.21104903786468032,"regression. As a result, as long as p ≥2, the convergence rate of regression risk is the same as the
281"
REGRESSION WITH HEAVY-TAILED NOISE,0.2116697703289882,"case with bounded noise. However, the label DP requires the output to be insensitive to the worst
282"
REGRESSION WITH HEAVY-TAILED NOISE,0.2122905027932961,"case replacement of labels, which can be harder if the noise has tails. To achieve ϵ-DP, the clipping
283"
REGRESSION WITH HEAVY-TAILED NOISE,0.21291123525760397,"radius decreases with ϵ, thus the noise strength needs to grow faster than O(1/ϵ). As a result, the
284"
REGRESSION WITH HEAVY-TAILED NOISE,0.21353196772191185,"convergence rate becomes slower than the non-private case. In the remainder of this section, denote
285"
REGRESSION WITH HEAVY-TAILED NOISE,0.21415270018621974,"Freg2 as the set of (f, η) that satisfies Assumption 1 and 3.
286"
LOCAL LABEL DP,0.21477343265052762,"6.1
Local Label DP
287"
LOCAL LABEL DP,0.2153941651148355,"1) Lower bound. In earlier sections about classification and regression with bounded noise, the impact
288"
LOCAL LABEL DP,0.21601489757914338,"of privacy mechanisms is only a polynomial factor on ϵ, while the convergence rate of excess risk
289"
LOCAL LABEL DP,0.21663563004345127,"with respect to N is not changed. However, this rule no longer holds when the noise has heavy tails.
290"
LOCAL LABEL DP,0.21725636250775915,"Theorem 9. Denote Mϵ as the set of all privacy mechanisms satisfying ϵ-label DP. Then for small ϵ,
291"
LOCAL LABEL DP,0.21787709497206703,"inf
ˆη
inf
M∈Mϵ sup
(f,η)∈F
(Rreg −R∗
reg) ≳(N(eϵ −1)2)−
2β(p−1)
2pβ+d(p−1) + N −
2β
2β+d .
(25)"
LOCAL LABEL DP,0.21849782743637491,"2) Upper bound. Since now the noise has unbounded distribution, without preprocessing, the
292"
LOCAL LABEL DP,0.2191185599006828,"sensitivity is unbounded, thus simply adding noise to Y can no longer protect the privacy. Therefore,
293"
LOCAL LABEL DP,0.21973929236499068,"a solution is to clip Y into [−T, T], and add noise proportional to T/ϵ to achieve ϵ-local label DP.
294"
LOCAL LABEL DP,0.22036002482929856,"Such truncation will inevitably introduce some bias. To achieve a tradeoff between clipping bias and
295"
LOCAL LABEL DP,0.22098075729360644,"sensitivity, the value of T needs to be tuned carefully. Based on such intuition, the method is precisely
296"
LOCAL LABEL DP,0.22160148975791433,"stated as follows. Let Zi = YT i+Wi, in which YT i is the truncation of Yi, i.e. YT i = (Yi∧T)∨(−T),
297"
LOCAL LABEL DP,0.2222222222222222,"and W ∼Lap(2T/ϵ). The result is shown in the next theorem.
298"
LOCAL LABEL DP,0.2228429546865301,"Theorem 10. The method above is ϵ-local label DP. Moreover, with k ∼(Nϵ2)"
LOCAL LABEL DP,0.22346368715083798,"2pβ
2pβ+d(p−1) ∨N"
LOCAL LABEL DP,0.22408441961514589,"2β
2β+d ,
299"
LOCAL LABEL DP,0.22470515207945377,"and T ∼(kϵ2)
1
2p , the risk is bounded by
300"
LOCAL LABEL DP,0.22532588454376165,"Rreg −R∗
reg ≲(Nϵ2)−
2β(p−1)
2pβ+d(p−1) + N −
2β
2β+d .
(26)"
LOCAL LABEL DP,0.22594661700806953,"Proof. (Outline) It can be shown that the clipping bias scales as T 2(1−p). To meet the ϵ-label DP, an
301"
LOCAL LABEL DP,0.22656734947237742,"additional error that scales as T/ϵ is needed. By averaging over k nearest neighbors, the variance
302"
LOCAL LABEL DP,0.2271880819366853,"caused by noise W scales with T 2/(kϵ2). From standard analysis on nearest neighbor methods [29],
303"
LOCAL LABEL DP,0.22780881440099318,"the non-private mean squared error scales as 1/k + (k/N)2β/d. Put all these terms together, Theorem
304"
LOCAL LABEL DP,0.22842954686530106,"10 can be proved. Details can be found in Appendix K.
305"
LOCAL LABEL DP,0.22905027932960895,"With the limit of p →∞, the problem reduces to the case with bounded noise, and the growth rate of
306"
LOCAL LABEL DP,0.22967101179391683,"k and the convergence rate of risk are the same as those in Theorem 6. For finite p, 2β(p −1)/(2pβ +
307"
LOCAL LABEL DP,0.2302917442582247,"d(p −1)) < 2β/(2β + d), thus the convergence rate becomes slower due to the privacy mechanism.
308"
CENTRAL LABEL DP,0.2309124767225326,"6.2
Central Label DP
309"
CENTRAL LABEL DP,0.23153320918684048,"1) Lower bound. The minimax lower bound is shown in Theorem 11.
310"
CENTRAL LABEL DP,0.23215394165114836,"Theorem 11. The minimax lower bound is
311"
CENTRAL LABEL DP,0.23277467411545624,"inf
A∈Aϵ
sup
(f,η)∈Freg2
(Rreg −R∗
reg) ≳N −
2β
2β+d + (ϵN)−
2β(p−1)
pβ+d(p−1)
(27)"
CENTRAL LABEL DP,0.23339540657976413,"2) Upper bound. Now we derive the upper bound. To restrict the sensitivity, instead of estimating
312"
CENTRAL LABEL DP,0.234016139044072,"with (23) directly, now we calculate an average of clipped label values:
313"
CENTRAL LABEL DP,0.2346368715083799,"ˆηl = 1 nl N
X"
CENTRAL LABEL DP,0.23525760397268777,"i=1
1(Xi ∈Bl) Clip(Yi, T) + Wl,
(28)"
CENTRAL LABEL DP,0.23587833643699566,"in which Wl ∼Lap(2T/(nlϵ)). Then for all x ∈Bl, let ˆη(x) = ˆηl. The following theorem bounds
314"
CENTRAL LABEL DP,0.23649906890130354,"the excess risk.
315"
CENTRAL LABEL DP,0.23711980136561142,"Theorem 12. (28) is ϵ-label DP. Moreover, under Assumption 1 and 3, if h and T scales as h ∼
316"
CENTRAL LABEL DP,0.2377405338299193,"N −
1
2β+d + (ϵN)−
1
pβ+d(p−1) , and T ∼(ϵNhd)1/p, then the excess risk can be bounded by
317"
CENTRAL LABEL DP,0.2383612662942272,"Rreg −R∗
reg ≲N −
2β
2β+d + (ϵN)−
2β(p−1)
pβ+d(p−1) .
(29)"
CENTRAL LABEL DP,0.23898199875853507,"The proof of Theorem 11 and 12 follow that of Theorem 7 and 8. The details are shown in Appendix
318"
CENTRAL LABEL DP,0.23960273122284295,"L and M respectively. With p = 2, the right hand side of (29) becomes (ϵ ∧1)−
2β
2β+d , indicating that
319"
CENTRAL LABEL DP,0.24022346368715083,"the privacy constraint blows up the sample complexity by a constant factor. With larger p, the second
320"
CENTRAL LABEL DP,0.24084419615145872,"term in (29) becomes negligible compared with the first one.
321"
CENTRAL LABEL DP,0.2414649286157666,"The theoretical analyses in this section are summarized as follows. In general, with fixed noise
322"
CENTRAL LABEL DP,0.24208566108007448,"variance, if the label noise is heavy-tailed, while the non-private convergence rates remain unaffected,
323"
CENTRAL LABEL DP,0.24270639354438237,"the additional risk caused by privacy mechanisms becomes significantly higher, indicating the
324"
CENTRAL LABEL DP,0.24332712600869025,"difficulty of privacy protection for heavy-tailed distributions.
325"
CONCLUSION,0.24394785847299813,"7
Conclusion
326"
CONCLUSION,0.244568590937306,"In this paper, we have derived the minimax lower bounds of learning under label DP for both central
327"
CONCLUSION,0.2451893234016139,"and local models. Furthermore, we propose methods whose upper bounds match these lower bounds.
328"
CONCLUSION,0.24581005586592178,"The results indicate the theoretical limits of learning under the label DP. From these results, it is
329"
CONCLUSION,0.24643078833022966,"discovered that under local label DP constraints, the sample complexity blows up by a factor of at least
330"
CONCLUSION,0.24705152079453754,"O(1/ϵ2). Under central label DP requirements, the additional error caused by privacy mechanisms
331"
CONCLUSION,0.24767225325884543,"is significantly smaller. Finally, it is shown that for regression problem with heavy-tailed label
332"
CONCLUSION,0.2482929857231533,"distribution, the additional risk induced by privacy requirement becomes inevitably higher.
333"
CONCLUSION,0.2489137181874612,"Limitations: The limitations of our work include the following aspects. Some assumptions can
334"
CONCLUSION,0.24953445065176907,"be weakened. For example, current analysis assumes that feature distributions have bounded sup-
335"
CONCLUSION,0.250155183116077,"ports, which may be extended to the unbounded case. One can let the bin splitting and nearest
336"
CONCLUSION,0.25077591558038487,"neighbor method be adaptive in the tails of features, such as [41]. Moreover, the bounds derived in
337"
CONCLUSION,0.25139664804469275,"this paper require that samples increase exponentially with dimensionality. However, in practice,
338"
CONCLUSION,0.25201738050900063,"the performance of learning under the label DP can be quite well even in high dimensions. The
339"
CONCLUSION,0.2526381129733085,"discrepancy can be explained by the fact that the minimax lower bound considers the worst-case
340"
CONCLUSION,0.2532588454376164,"distribution over a wide range of distributions. However, in most realistic cases, the distributions
341"
CONCLUSION,0.2538795779019243,"satisfy significantly better properties. A better modeling is to assume that these samples lie on a low
342"
CONCLUSION,0.25450031036623216,"dimensional manifold [57,58]. In this case, it is possible to achieve a much better convergence rate.
343"
CONCLUSION,0.25512104283054005,"Finally, it is not sure whether approximate DP (i.e. (ϵ, δ)-DP) can improve the convergence rates.
344"
REFERENCES,0.25574177529484793,"References
345"
REFERENCES,0.2563625077591558,"[1] Rao, B., J. Zhang, D. Wu, et al. Privacy inference attack and defense in centralized and federated
346"
REFERENCES,0.2569832402234637,"learning: A comprehensive survey. IEEE Transactions on Artificial Intelligence, 2024.
347"
REFERENCES,0.2576039726877716,"[2] Dwork, C., F. McSherry, K. Nissim, et al. Calibrating noise to sensitivity in private data analysis.
348"
REFERENCES,0.25822470515207946,"In Theory of Cryptography: Third Theory of Cryptography Conference, TCC 2006, New York,
349"
REFERENCES,0.25884543761638734,"NY, USA, March 4-7, 2006. Proceedings 3, pages 265–284. Springer, 2006.
350"
REFERENCES,0.2594661700806952,"[3] Abadi, M., A. Chu, I. Goodfellow, et al. Deep learning with differential privacy. In Proceedings
351"
REFERENCES,0.2600869025450031,"of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pages
352"
REFERENCES,0.260707635009311,"308–318. 2016.
353"
REFERENCES,0.26132836747361887,"[4] Dwork, C., A. Roth, et al. The algorithmic foundations of differential privacy. Foundations and
354"
REFERENCES,0.26194909993792675,"Trends® in Theoretical Computer Science, 9(3–4):211–407, 2014.
355"
REFERENCES,0.26256983240223464,"[5] Bassily, R., A. Smith, A. Thakurta. Private empirical risk minimization: Efficient algorithms
356"
REFERENCES,0.2631905648665425,"and tight error bounds. In 2014 IEEE 55th Annual Symposium on Foundations of Computer
357"
REFERENCES,0.2638112973308504,"Science, pages 464–473. IEEE, 2014.
358"
REFERENCES,0.2644320297951583,"[6] Bassily, R., V. Feldman, K. Talwar, et al. Private stochastic convex optimization with optimal
359"
REFERENCES,0.26505276225946617,"rates. Advances in Neural Information Processing Systems, 32, 2019.
360"
REFERENCES,0.26567349472377405,"[7] Wang, D., H. Xiao, S. Devadas, et al. On differentially private stochastic convex optimization
361"
REFERENCES,0.26629422718808193,"with heavy-tailed data. In International Conference on Machine Learning, pages 10081–10091.
362"
REFERENCES,0.2669149596523898,"PMLR, 2020.
363"
REFERENCES,0.2675356921166977,"[8] Asi, H., V. Feldman, T. Koren, et al. Private stochastic convex optimization: Optimal rates in l1
364"
REFERENCES,0.2681564245810056,"geometry. In International Conference on Machine Learning, pages 393–403. PMLR, 2021.
365"
REFERENCES,0.26877715704531346,"[9] Das, R., S. Kale, Z. Xu, et al. Beyond uniform lipschitz condition in differentially private
366"
REFERENCES,0.26939788950962135,"optimization. In International Conference on Machine Learning, pages 7066–7101. PMLR,
367"
REFERENCES,0.27001862197392923,"2023.
368"
REFERENCES,0.2706393544382371,"[10] Tramer, F., D. Boneh. Differentially private learning needs better features (or much more data).
369"
REFERENCES,0.271260086902545,"In International Conference on Learning Representations. 2021.
370"
REFERENCES,0.2718808193668529,"[11] Bu, Z., J. Mao, S. Xu. Scalable and efficient training of large convolutional neural networks
371"
REFERENCES,0.27250155183116076,"with differential privacy. Advances in Neural Information Processing Systems, 35:38305–38318,
372"
REFERENCES,0.27312228429546864,"2022.
373"
REFERENCES,0.2737430167597765,"[12] De, S., L. Berrada, J. Hayes, et al. Unlocking high-accuracy differentially private image
374"
REFERENCES,0.2743637492240844,"classification through scale. arXiv preprint arXiv:2204.13650, 2022.
375"
REFERENCES,0.2749844816883923,"[13] Wei, J., E. Bao, X. Xiao, et al. Dpis: An enhanced mechanism for differentially private sgd with
376"
REFERENCES,0.2756052141527002,"importance sampling. In Proceedings of the 2022 ACM SIGSAC Conference on Computer and
377"
REFERENCES,0.27622594661700806,"Communications Security, pages 2885–2899. 2022.
378"
REFERENCES,0.27684667908131594,"[14] Ghazi, B., N. Golowich, R. Kumar, et al. Deep learning with label differential privacy. Advances
379"
REFERENCES,0.2774674115456238,"in Neural Information Processing Systems, 34:27131–27145, 2021.
380"
REFERENCES,0.2780881440099317,"[15] McMahan, H. B., G. Holt, D. Sculley, et al. Ad click prediction: a view from the trenches. In
381"
REFERENCES,0.2787088764742396,"Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and
382"
REFERENCES,0.27932960893854747,"data mining, pages 1222–1230. 2013.
383"
REFERENCES,0.27995034140285535,"[16] McSherry, F., I. Mironov. Differentially private recommender systems: Building privacy into
384"
REFERENCES,0.28057107386716323,"the netflix prize contenders. In Proceedings of the 15th ACM SIGKDD international conference
385"
REFERENCES,0.2811918063314711,"on Knowledge discovery and data mining, pages 627–636. 2009.
386"
REFERENCES,0.281812538795779,"[17] Bussone, A., B. Kasadha, S. Stumpf, et al. Trust, identity, privacy, and security considerations
387"
REFERENCES,0.2824332712600869,"for designing a peer data sharing platform between people living with hiv. Proceedings of the
388"
REFERENCES,0.28305400372439476,"ACM on Human-Computer Interaction, 4(CSCW2):1–27, 2020.
389"
REFERENCES,0.28367473618870265,"[18] Ghazi, B., P. Kamath, R. Kumar, et al. Regression with label differential privacy. In The
390"
REFERENCES,0.28429546865301053,"Eleventh International Conference on Learning Representations. 2022.
391"
REFERENCES,0.2849162011173184,"[19] Malek Esmaeili, M., I. Mironov, K. Prasad, et al. Antipodes of label differential privacy: Pate
392"
REFERENCES,0.2855369335816263,"and alibi. Advances in Neural Information Processing Systems, 34:6934–6945, 2021.
393"
REFERENCES,0.2861576660459342,"[20] Esfandiari, H., V. Mirrokni, U. Syed, et al. Label differential privacy via clustering. In
394"
REFERENCES,0.28677839851024206,"International Conference on Artificial Intelligence and Statistics, pages 7055–7075. PMLR,
395"
REFERENCES,0.28739913097454994,"2022.
396"
REFERENCES,0.2880198634388578,"[21] Tang, X., M. Nasr, S. Mahloujifar, et al. Machine learning with differentially private labels:
397"
REFERENCES,0.2886405959031657,"Mechanisms and frameworks. Proceedings on Privacy Enhancing Technologies, 2022.
398"
REFERENCES,0.2892613283674736,"[22] Cover, T. M. Elements of information theory. John Wiley & Sons, 1999.
399"
REFERENCES,0.28988206083178153,"[23] Duchi, J. C., M. I. Jordan, M. J. Wainwright. Local privacy and statistical minimax rates. In
400"
REFERENCES,0.2905027932960894,"2013 IEEE 54th Annual Symposium on Foundations of Computer Science, pages 429–438.
401"
REFERENCES,0.2911235257603973,"IEEE, 2013.
402"
REFERENCES,0.2917442582247052,"[24] —. Minimax optimal procedures for locally private estimation. Journal of the American
403"
REFERENCES,0.29236499068901306,"Statistical Association, 113(521):182–201, 2018.
404"
REFERENCES,0.29298572315332094,"[25] Gopi, S., G. Kamath, J. Kulkarni, et al. Locally private hypothesis selection. In Conference on
405"
REFERENCES,0.2936064556176288,"Learning Theory, pages 1785–1816. PMLR, 2020.
406"
REFERENCES,0.2942271880819367,"[26] Berrett, T., C. Butucea.
Classification under local differential privacy.
arXiv preprint
407"
REFERENCES,0.2948479205462446,"arXiv:1912.04629, 2019.
408"
REFERENCES,0.2954686530105525,"[27] Berrett, T. B., L. Györfi, H. Walk. Strongly universally consistent nonparametric regression and
409"
REFERENCES,0.29608938547486036,"classification with privatised data. Electronic Journal of Statistics, 15:2430–2453, 2021.
410"
REFERENCES,0.29671011793916824,"[28] Tsybakov, A. B. Introduction to Nonparametric Estimation. 2009.
411"
REFERENCES,0.2973308504034761,"[29] Audibert, J.-Y., A. B. Tsybakov. Fast learning rates for plug-in classifiers. Annals of Statistics,
412"
REFERENCES,0.297951582867784,"2007.
413"
REFERENCES,0.2985723153320919,"[30] Warner, S. L. Randomized response: A survey technique for eliminating evasive answer bias.
414"
REFERENCES,0.29919304779639977,"Journal of the American Statistical Association, 60(309):63–69, 1965.
415"
REFERENCES,0.29981378026070765,"[31] Badanidiyuru Varadaraja, A., B. Ghazi, P. Kamath, et al. Optimal unbiased randomizers for
416"
REFERENCES,0.30043451272501553,"regression with label differential privacy. Advances in Neural Information Processing Systems,
417"
REFERENCES,0.3010552451893234,"36, 2023.
418"
REFERENCES,0.3016759776536313,"[32] LeCam, L. Convergence of estimates under dimensionality restrictions. The Annals of Statistics,
419"
REFERENCES,0.3022967101179392,"pages 38–53, 1973.
420"
REFERENCES,0.30291744258224707,"[33] Verdú, S., et al. Generalizing the fano inequality. IEEE Transactions on Information Theory,
421"
REFERENCES,0.30353817504655495,"40(4):1247–1251, 1994.
422"
REFERENCES,0.30415890751086283,"[34] Assouad, P. Deux remarques sur l’estimation. Comptes rendus des séances de l’Académie des
423"
REFERENCES,0.3047796399751707,"sciences. Série 1, Mathématique, 296(23):1021–1024, 1983.
424"
REFERENCES,0.3054003724394786,"[35] Yang, Y. Minimax nonparametric classification. i. rates of convergence. IEEE Transactions on
425"
REFERENCES,0.3060211049037865,"Information Theory, 45(7):2271–2284, 1999.
426"
REFERENCES,0.30664183736809436,"[36] —. Minimax nonparametric classification. ii. model selection for adaptation. IEEE Transactions
427"
REFERENCES,0.30726256983240224,"on Information Theory, 45(7):2285–2292, 1999.
428"
REFERENCES,0.3078833022967101,"[37] Chaudhuri, K., S. Dasgupta. Rates of convergence for nearest neighbor classification. Advances
429"
REFERENCES,0.308504034761018,"in Neural Information Processing Systems, 27, 2014.
430"
REFERENCES,0.3091247672253259,"[38] Yang, Y., S. T. Tokdar. Minimax-optimal nonparametric regression in high dimensions. The
431"
REFERENCES,0.3097454996896338,"Annals of Statistics, pages 652–674, 2015.
432"
REFERENCES,0.31036623215394166,"[39] Döring, M., L. Györfi, H. Walk. Rate of convergence of k-nearest-neighbor classification rule.
433"
REFERENCES,0.31098696461824954,"Journal of Machine Learning Research, 18(227):1–16, 2018.
434"
REFERENCES,0.3116076970825574,"[40] Gadat, S., T. Klein, C. Marteau. Classification in general finite dimensional spaces with the
435"
REFERENCES,0.3122284295468653,"k-nearest neighbor rule. Annals of Statistics, 2016.
436"
REFERENCES,0.3128491620111732,"[41] Zhao, P., L. Lai. Minimax rate optimal adaptive nearest neighbor classification and regression.
437"
REFERENCES,0.31346989447548107,"IEEE Transactions on Information Theory, 67(5):3155–3182, 2021.
438"
REFERENCES,0.31409062693978895,"[42] Kasiviswanathan, S. P., H. K. Lee, K. Nissim, et al. What can we learn privately? SIAM Journal
439"
REFERENCES,0.31471135940409684,"on Computing, 40(3):793–826, 2011.
440"
REFERENCES,0.3153320918684047,"[43] Li, M., T. B. Berrett, Y. Yu. On robustness and local differential privacy. The Annals of Statistics,
441"
REFERENCES,0.3159528243327126,"51(2):717–737, 2023.
442"
REFERENCES,0.3165735567970205,"[44] Feldman, V., T. Koren, K. Talwar. Private stochastic convex optimization: optimal rates in linear
443"
REFERENCES,0.31719428926132837,"time. In Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing,
444"
REFERENCES,0.31781502172563625,"pages 439–449. 2020.
445"
REFERENCES,0.31843575418994413,"[45] Duchi, J., R. Rogers. Lower bounds for locally private estimation via communication complexity.
446"
REFERENCES,0.319056486654252,"In Conference on Learning Theory, pages 1161–1191. PMLR, 2019.
447"
REFERENCES,0.3196772191185599,"[46] Huang, Z., Y. Liang, K. Yi. Instance-optimal mean estimation under differential privacy.
448"
REFERENCES,0.3202979515828678,"Advances in Neural Information Processing Systems, 34:25993–26004, 2021.
449"
REFERENCES,0.32091868404717566,"[47] Hardt, M., K. Talwar. On the geometry of differential privacy. In Proceedings of the forty-second
450"
REFERENCES,0.32153941651148354,"ACM symposium on Theory of computing, pages 705–714. 2010.
451"
REFERENCES,0.3221601489757914,"[48] Bun, M., G. Kamath, T. Steinke, et al. Private hypothesis selection. Advances in Neural
452"
REFERENCES,0.3227808814400993,"Information Processing Systems, 32, 2019.
453"
REFERENCES,0.3234016139044072,"[49] Narayanan, S. Better and simpler lower bounds for differentially private statistical estimation.
454"
REFERENCES,0.3240223463687151,"arXiv preprint arXiv:2310.06289, 2023.
455"
REFERENCES,0.32464307883302296,"[50] Kamath, G., V. Singhal, J. Ullman. Private mean estimation of heavy-tailed distributions. In
456"
REFERENCES,0.32526381129733084,"Conference on Learning Theory, pages 2204–2235. PMLR, 2020.
457"
REFERENCES,0.3258845437616387,"[51] Kamath, G., J. Li, V. Singhal, et al. Privately learning high-dimensional distributions. In
458"
REFERENCES,0.3265052762259466,"Conference on Learning Theory, pages 1853–1902. PMLR, 2019.
459"
REFERENCES,0.3271260086902545,"[52] Alabi, D., P. K. Kothari, P. Tankala, et al. Privately estimating a gaussian: Efficient, robust, and
460"
REFERENCES,0.32774674115456237,"optimal. In Proceedings of the 55th Annual ACM Symposium on Theory of Computing, pages
461"
REFERENCES,0.32836747361887025,"483–496. 2023.
462"
REFERENCES,0.32898820608317814,"[53] Arbas, J., H. Ashtiani, C. Liaw. Polynomial time and private learning of unbounded gaussian
463"
REFERENCES,0.329608938547486,"mixture models. In International Conference on Machine Learning, pages 1018–1040. 2023.
464"
REFERENCES,0.3302296710117939,"[54] Bun, M., J. Ullman, S. Vadhan. Fingerprinting codes and the price of approximate differential
465"
REFERENCES,0.3308504034761018,"privacy. In Proceedings of the forty-sixth annual ACM symposium on Theory of computing,
466"
REFERENCES,0.33147113594040967,"pages 1–10. 2014.
467"
REFERENCES,0.33209186840471755,"[55] Kamath, G., A. Mouzakis, V. Singhal. New lower bounds for private estimation and a generalized
468"
REFERENCES,0.33271260086902543,"fingerprinting lemma. Advances in neural information processing systems, 35:24405–24418,
469"
REFERENCES,0.3333333333333333,"2022.
470"
REFERENCES,0.3339540657976412,"[56] McSherry, F., K. Talwar. Mechanism design via differential privacy. In 48th Annual IEEE
471"
REFERENCES,0.3345747982619491,"Symposium on Foundations of Computer Science (FOCS’07), pages 94–103. IEEE, 2007.
472"
REFERENCES,0.33519553072625696,"[57] Kpotufe, S. k-nn regression adapts to local intrinsic dimension. Advances in neural information
473"
REFERENCES,0.33581626319056485,"processing systems, 24, 2011.
474"
REFERENCES,0.33643699565487273,"[58] Carter, K. M., R. Raich, A. O. Hero III. On local intrinsic dimension estimation and its
475"
REFERENCES,0.3370577281191806,"applications. IEEE Transactions on Signal Processing, 58(2):650–663, 2009.
476"
REFERENCES,0.3376784605834885,"A
Proof of Proposition 2
477"
REFERENCES,0.3382991930477964,"From (5) and (6), the Bayes risk is
478"
REFERENCES,0.33891992551210426,"R∗
cls = P(Y ̸= c∗(X)) =
Z
P(Y ̸= c∗(x)|X = x)f(x)dx =
Z
(1 −η∗(x))f(x)dx.
(30)"
REFERENCES,0.33954065797641214,"The risk of classifier c is
479"
REFERENCES,0.34016139044072,"Rcls = P(Y ̸= c(X)) = E
Z  
1 −ηc(x)(x)

f(x)dx

.
(31)"
REFERENCES,0.3407821229050279,"From (31) and (6),
480"
REFERENCES,0.3414028553693358,"Rcls −R∗
cls =
Z
(η∗(x) −E[ηc(x)(x)])f(x)dx.
(32)"
REFERENCES,0.34202358783364367,"The proof is complete.
481"
REFERENCES,0.3426443202979516,"B
Proof of Theorem 1
482"
REFERENCES,0.3432650527622595,"In this section, we prove the minimax lower bound of multi-class classification. The problem with K
483"
REFERENCES,0.3438857852265674,"classes with K > 2 is inherently harder than that with K = 2. Therefore, we just need to prove the
484"
REFERENCES,0.34450651769087526,"lower bound for binary classification, in which Y = {1, 2}. Let
485"
REFERENCES,0.34512725015518314,"η(x) = η2(x) −η1(x).
(33)"
REFERENCES,0.345747982619491,"Since η1(x) + η2(x) = 1 always holds, we have
486"
REFERENCES,0.3463687150837989,η1(x) = 1 −η(x)
REFERENCES,0.3469894475481068,"2
, η2(x) = 1 + η(x)"
REFERENCES,0.34761018001241467,"2
.
(34)"
REFERENCES,0.34823091247672255,"Therefore, η(x) captures the conditional distribution of Y given x.
487"
REFERENCES,0.34885164494103044,"Find G disjoint cubes B1, . . . , BG ⊂X, such that the length of each cube is h. Denote c1, . . . , cG
488"
REFERENCES,0.3494723774053383,"as the centers of these cubes. Let ϕ(u) be some function supported at [−1/2, 1/2]d, such that
489"
REFERENCES,0.3500931098696462,"0 ≤ϕ(u) ≤1.
(35)"
REFERENCES,0.3507138423339541,"Let f(x) = c over x ∈X. For v ∈V := {−1, 1}m, let
490"
REFERENCES,0.35133457479826197,"ηv(x) = m
X"
REFERENCES,0.35195530726256985,"k=1
vkϕ
x −ck h"
REFERENCES,0.35257603972687773,"
hβ.
(36)"
REFERENCES,0.3531967721911856,"It can be proved that if for some constant CM,
491"
REFERENCES,0.3538175046554935,"m ≤CMhγβ−d,
(37)"
REFERENCES,0.3544382371198014,"then for any η = ηv, η1 and η2 satisfies Assumption 1(b). Denote
492"
REFERENCES,0.35505896958410926,"ˆvk = arg max
s∈{−1,1} Z"
REFERENCES,0.35567970204841715,"Bk
ϕ
x −ck h"
REFERENCES,0.35630043451272503,"
1(sign(ˆη(x)) = s)f(x)dx.
(38)"
REFERENCES,0.3569211669770329,"Then the excess risk is bounded by
493"
REFERENCES,0.3575418994413408,"R −R∗
=
Z
|ηv(x)|P(sign(ˆη(x)) ̸= sign(ηv(x)))f(x)dx ≥ m
X k=1 Z"
REFERENCES,0.3581626319056487,"Bk
|ηv(x)|P(sign(ˆη(x)) ̸= sign(ηv(x)))f(x)dx = m
X"
REFERENCES,0.35878336436995656,"k=1
hβ
Z"
REFERENCES,0.35940409683426444,"Bk
ϕ
x −ck h"
REFERENCES,0.3600248292985723,"
P(sign(ˆη(x)))f(x)dx.
(39)"
REFERENCES,0.3606455617628802,"If ˆvk ̸= vk, then from (38),
494 Z"
REFERENCES,0.3612662942271881,"Bk
ϕ
x −ck h"
REFERENCES,0.36188702669149597,"
1(sign(ˆη(x)))f(x)dx ≥
Z"
REFERENCES,0.36250775915580385,"Bk
ϕ
x −ck h"
REFERENCES,0.36312849162011174,"
1(sign(ˆη(x)) = vk)f(x)dx.
(40)"
REFERENCES,0.3637492240844196,"Therefore
495
Z"
REFERENCES,0.3643699565487275,"Bk
ϕ
x −ck h"
REFERENCES,0.3649906890130354,"
1(sign(ˆη(x)) ̸= vk)f(x)dx ≥1 2 Z"
REFERENCES,0.36561142147734327,"Bk
ϕ
x −ck h"
REFERENCES,0.36623215394165115,"
f(x)dx ≥1"
REFERENCES,0.36685288640595903,2chd ∥ϕ∥1 . (41)
REFERENCES,0.3674736188702669,"Hence
496"
REFERENCES,0.3680943513345748,"R −R∗
≥
1
2chβ+d ∥ϕ∥1 m
X"
REFERENCES,0.3687150837988827,"k=1
P(ˆvk ̸= vk)"
REFERENCES,0.36933581626319056,"=
1
2chβ+d ∥ϕ∥1 E[ρH(ˆv, v)],
(42)"
REFERENCES,0.36995654872749845,"in which ρH denotes the Hamming distance. Then
497"
REFERENCES,0.37057728119180633,"inf
ˆY
inf
M∈Mϵ sup
(f,η)∈P
(R −R∗) ≥1"
REFERENCES,0.3711980136561142,"2hβ+d ∥ϕ∥1 inf
ˆv
inf
M∈Mϵmax
v∈V E[ρH(ˆv, v)].
(43)"
REFERENCES,0.3718187461204221,"Define
498"
REFERENCES,0.37243947858473,"δ =
sup
M∈Mϵ
max
v,v′:ρH(v,v′)=1DKL(P(X,Z)1:N|v||P(X,Z)1:N|v′),
(44)"
REFERENCES,0.37306021104903786,"in which P(X,Z)1:N|v denotes the distribution of (X1, Z1), . . . , (XN, ZN) with η = ηv. DKL
499"
REFERENCES,0.37368094351334574,"denotes the Kullback-Leibler divergence. Then from [28], Theorem 2.12(iv),
500"
REFERENCES,0.3743016759776536,"inf
ˆv inf
M max
v∈V E[ρH(ˆv, v)] ≥m 2"
REFERENCES,0.3749224084419615,"1
2e−δ, 1 − r δ
2 !"
REFERENCES,0.3755431409062694,".
(45)"
REFERENCES,0.3761638733705773,"It remains to bound δ. Without loss of generality, suppose v1 ̸= v′
1, and vi = v′
i for i ̸= 1. Then
501"
REFERENCES,0.37678460583488516,"DKL(P(X,Z)1:N|v||P(X,Z)1:N|v′)
(a)
=
NDKL(PX,Z|v||PX,Z|v′)"
REFERENCES,0.37740533829919304,"(b)
=
N
Z"
REFERENCES,0.3780260707635009,"B1
f(x)DKL(PZ|X=x,v||PZ|X=x,v′)dx"
REFERENCES,0.3786468032278088,"(c)
≤
N
Z"
REFERENCES,0.3792675356921167,"B1
f(x)(eϵ −1)2TV2(PZ|X=x,v, PZ|X=x,v′)dx =
N
Z"
REFERENCES,0.37988826815642457,"B1
f(x)(eϵ −1)2η2
v(x)dx"
REFERENCES,0.38050900062073245,"=
N(eϵ −1)2
Z"
REFERENCES,0.38112973308504033,"B1
f(x)ϕ2
x −c1 h"
REFERENCES,0.3817504655493482,"
h2βdx"
REFERENCES,0.3823711980136561,"(d)
=
N(eϵ −1)2h2β+d ∥ϕ∥2
2 .
(46)"
REFERENCES,0.382991930477964,"In (a), PX,Z|v denotes the distribution of a single sample with privatized label (X, Z), with η = ηv.
502"
REFERENCES,0.38361266294227186,"In (b), PZ|X=x,v denotes the conditional distribution of Z given X = x, with η = ηv. (c) uses [24],
503"
REFERENCES,0.38423339540657975,"Theorem 1. In (d), ∥ϕ∥2
2 =
R
ϕ2(u)du, which is a constant. Moreover,
504"
REFERENCES,0.38485412787088763,"DKL(PX,Z|v||PX,Z|v′)
(a)
≤
DKL(PX,Y |v||PX,Y |v′) =
Z"
REFERENCES,0.3854748603351955,"B1
f(x)

P(Y = 1|v) ln P(Y = 1|v)"
REFERENCES,0.3860955927995034,P(Y = 1|v′) + P(Y = −1|v) ln P(Y = −1|v)
REFERENCES,0.3867163252638113,"P(Y = −1|v′) 
dx =
Z"
REFERENCES,0.38733705772811916,"B1
f(x)
1 + ηv(x)"
REFERENCES,0.38795779019242704,"2
ln 1 + ηv(x)"
REFERENCES,0.3885785226567349,1 −ηv(x) + 1 −ηv(x)
REFERENCES,0.3891992551210428,"2
ln 1 −ηv(x)"
REFERENCES,0.3898199875853507,"1 + ηv(x) 
dx"
REFERENCES,0.3904407200496586,"(b)
≤
3
Z"
REFERENCES,0.39106145251396646,"B1
f(x)η2
v(x)dx"
REFERENCES,0.39168218497827434,"≤
3h2β+d ∥ϕ∥2
2 .
(47)"
REFERENCES,0.3923029174425822,"For (a), note that Z is generated from Y . From data processing inequality, (a) holds. For (b), without
505"
REFERENCES,0.3929236499068901,"loss of generality, suppose that v1 = 1, thus ηv(x) ≥0 in B1. Then ln(1 + ηv(x)) ≤ηv(x). From
506"
REFERENCES,0.393544382371198,"(35) and (36), |ηv(x)| ≤1/2. Therefore, −ln(1 −ηv(x)) ≤2ηv(x). Therefore (b) holds.
507"
REFERENCES,0.39416511483550587,"From (46) and (47),
508"
REFERENCES,0.3947858472998138,"δ ≤N

(eϵ −1)2 ∧3

h2β+d ∥ϕ∥2
2 .
(48)"
REFERENCES,0.3954065797641217,"Let
509"
REFERENCES,0.3960273122284296,"h ∼
 
N
 
ϵ2 ∧1
−
1
2β+d .
(49)"
REFERENCES,0.39664804469273746,"Then δ ≲1. From (45), with m ∼hγβ−d,
510"
REFERENCES,0.39726877715704534,"inf
ˆv
inf
M∈Mϵmax
v∈V E[ρH(ˆv, v)] ≳hγβ−d.
(50)"
REFERENCES,0.3978895096213532,"Hence
511"
REFERENCES,0.3985102420856611,"inf
ˆY
inf
M∈Mϵ sup
(f,η)∈P
(R −R∗) ≳hβ+dhγβ−d ∼hβ(γ+1) ∼

N
 
ϵ2 ∧1
−β(γ+1)"
REFERENCES,0.399130974549969,"2β+d .
(51)"
REFERENCES,0.39975170701427687,"The proof is complete.
512"
REFERENCES,0.40037243947858475,"C
Proof of Theorem 2
513"
REFERENCES,0.40099317194289263,"Denote
514 nl = N
X"
REFERENCES,0.4016139044072005,"i=1
1(Xi ∈Bl),
(52)"
REFERENCES,0.4022346368715084,"and for Z = M(X, Y ), let
515"
REFERENCES,0.4028553693358163,"˜ηj(x)
:=
E[Z(j)|X = x]"
REFERENCES,0.40347610180012417,"=
e
ϵ
2"
REFERENCES,0.40409683426443205,"e
ϵ
2 + 1ηj(x) +
1
e
ϵ
2 + 1(1 −ηj(x))
(53)"
REFERENCES,0.40471756672873993,"as the number of training samples whose feature vectors fall in Bl, and
516"
REFERENCES,0.4053382991930478,vlj := 1 nl X
REFERENCES,0.4059590316573557,"i:Xi∈Bl
˜ηj(Xi).
(54)"
REFERENCES,0.4065797641216636,"Recall (12) that defines Slj. From Hoeffding’s inequality,
517"
REFERENCES,0.40720049658597146,"P (|Slj −nlvlj| > t|X1:N) ≤2 exp

−2t2 nl"
REFERENCES,0.40782122905027934,"
,
(55)"
REFERENCES,0.4084419615145872,"in which X1:N denotes X1, . . . , XN.
518"
REFERENCES,0.4090626939788951,"Define
519"
REFERENCES,0.409683426443203,"v∗
l := max
j vlj,
(56)"
REFERENCES,0.4103041589075109,"and
520"
REFERENCES,0.41092489137181876,"c∗
l := arg max
j
vlj.
(57)"
REFERENCES,0.41154562383612664,"Now we bound P(v∗
l −vlcl > t), in which cl is defined in (13). cl can be viewed as the prediction at
521"
REFERENCES,0.4121663563004345,"the l-th bin. We would like to show that the even if the prediction is wrong, the value (i.e. conditional
522"
REFERENCES,0.4127870887647424,"probability) of the predicted class is close to the ground truth. v∗
l −vlcl > t only if ∃j, v∗
l −vlj > t,
523"
REFERENCES,0.4134078212290503,"and Slj > Slc∗
l . Therefore either Slj −nlvlj > t/2 or Slc∗
l −nlv∗
l > t/2 holds. Hence
524"
REFERENCES,0.41402855369335817,"P (v∗
l −vlcl ≥t) ≤P

∃j, |Slj −nlvlj| ≥1"
NLT,0.41464928615766605,"2nlt

≤2K exp

−1"
NLT,0.41527001862197394,"2nlt2

.
(58)"
NLT,0.4158907510862818,"Define
525 t0 = s"
NLT,0.4165114835505897,2 ln(2K)
NLT,0.4171322160148976,"nl
.
(59)"
NLT,0.41775294847920547,"Then
526"
NLT,0.41837368094351335,"v∗
l −E[vlcl|X1:N]
=
Z 1"
NLT,0.41899441340782123,"0
P(v∗
l −vlcl > t)dt"
NLT,0.4196151458721291,"≤
t0 +
Z ∞"
NLT,0.420235878336437,"t0
2K exp

−1"
NLT,0.4208566108007449,"2nlt2

dt"
NLT,0.42147734326505276,"(a)
≤
t0 + 2
r 2π"
NLT,0.42209807572936064,"nl
K exp

−1"
NLT,0.4227188081936685,"2nlt2
0  = s"
NLT,0.4233395406579764,2 ln(2K)
NLT,0.4239602731222843,"nl
+
r 2π nl ≤
3 s"
NLT,0.4245810055865922,ln(2K)
NLT,0.42520173805090006,"nl
.
(60)"
NLT,0.42582247051520794,"In (a), we use the inequality
527
Z ∞"
NLT,0.4264432029795158,"t
e−u2"
NLT,0.4270639354438237,"2σ2 du ≤
√"
NLT,0.4276846679081316,2πσe−t2
NLT,0.42830540037243947,"2σ2 .
(61)"
NLT,0.42892613283674735,"Now we bound the excess risk.
528"
NLT,0.42954686530105524,"R −R∗
=
Z  
η∗(x) −E[ηc(x)(x)]

f(x)dx = G
X l=1 Z Bl"
NLT,0.4301675977653631," 
η∗(x) −E[ηc(x)(x)]

f(x)dx.
(62)"
NLT,0.430788330229671,"We need to bound
R"
NLT,0.4314090626939789,"Bl
 
η∗(x) −E[ηc(x)(x)]

f(x)dx for each l. From Assumption 1(a), for any
529"
NLT,0.43202979515828677,"x, x′ ∈Bl, the distance is bounded by ∥x −x′∥≤
√"
NLT,0.43265052762259465,"dL. Thus
530"
NLT,0.43327126008690253,"|ηj(x) −ηj(x′)| ≤Ldhβ,
(63)"
NLT,0.4338919925512104,"in which Ld is defined as Ld := L
√"
NLT,0.4345127250155183,"d. From (63) and (53),
531"
NLT,0.4351334574798262,"|˜ηj(x) −˜ηj(x′)| ≤e
ϵ
2 −1
e
ϵ
2 + 1Ldhβ.
(64)"
NLT,0.43575418994413406,"Define
532"
NLT,0.43637492240844195,"˜η∗(x) = max
j
˜ηj(x),
(65)"
NLT,0.43699565487274983,"then
533"
NLT,0.4376163873370577,"η∗(x) −E[ηcl(x)|X1:N]
≤
e
ϵ
2 + 1
e
ϵ
2 −1 (˜η∗(x) −E[˜ηcl(x)|X1:N])"
NLT,0.4382371198013656,"≤
e
ϵ
2 + 1
e
ϵ
2 −1 (v∗
l −E[vlcl|X1:N]) + 2Ldhβ"
NLT,0.4388578522656735,"≤
3e
ϵ
2 + 1
e
ϵ
2 −1 s"
NLT,0.43947858472998136,2 ln(2K)
NLT,0.44009931719428924,"nl
+ 2Ldhβ.
(66)"
NLT,0.4407200496585971,"Take integration over cube Bl, we get
534
Z"
NLT,0.441340782122905,"Bl
(η∗(x) −E[ηcl(x)]) f(x)dx"
NLT,0.4419615145872129,"≤
P

nl < 1"
NLT,0.44258224705152077,"2Np(Bl)
 Z Bl"
NLT,0.44320297951582865,"
η∗(x) −E[ηcl(x)|nl < 1"
NLT,0.44382371198013654,"N p(Bl)]

f(x)dx +
Z Bl"
NLT,0.4444444444444444,"
η∗(x) −E[ηcl(x)|nl ≥1"
NLT,0.4450651769087523,"N p(Bl)]

f(x)dx"
NLT,0.4456859093730602,"≤
p(Bl)e−1"
NLT,0.44630664183736807,"2 (1−ln 2)Np(Bl) + """
E,0.44692737430167595,"3e
ϵ
2 + 1
e
ϵ
2 −1 s"
E,0.4475481067659839,2 ln(2K)
E,0.44816883923029177,"Np(Bl) + 2Ldhβ
#"
E,0.44878957169459965,"p(Bl),
(67)"
E,0.44941030415890754,"in which p(Bl) = P(X ∈Bl) is the probability mass of Bl. Moreover, define
535"
E,0.4500310366232154,"∆l = inf
x∈Bl (η∗(x) −ηs(x)) ,
(68)"
E,0.4506517690875233,"and
536"
E,0.4512725015518312,"˜∆l = inf
x∈Bl (˜η∗(x) −˜ηs(x)) = e
ϵ
2 −1
e
ϵ
2 + 1∆l,
(69)"
E,0.45189323401613907,"in which the ˜ηs is the second largest value of ˜ηj among j = 1, . . . , K, which follows the definition
537"
E,0.45251396648044695,"of ηs.
538"
E,0.45313469894475483,"If ∆l > 0, then c∗(x) is the same over Bl. Then either v∗
l −vlcl = 0 or v∗
l −vlcl ≥∆l holds. Hence
539"
E,0.4537554314090627,"˜η∗(x) −E[˜ηcl(x)|X1:N] =
Z 1"
E,0.4543761638733706,"0
P (˜η∗(x) −˜ηcl(x) > t|X1:N) dt ≤
Z 1"
P,0.4549968963376785,"0
P

v∗
l −vlcl > t −2Ldhβ e
ϵ
2 + 1
e
ϵ
2 −1|X1:N 
dt"
P,0.45561762880198636,"≤
Z
˜∆l+2Ldhβ"
P,0.45623836126629425,"0
P(v∗
l −vlcl ≥∆l)dt +
Z ∞"
P,0.45685909373060213,"˜∆l+2Ldhβ 2K exp

−1"
P,0.45747982619491,"2nl(t −2Ldhβ)2

dt"
P,0.4581005586592179,"≤
2K exp

−1"
P,0.4587212911235258,"2nl ˜∆2
l"
P,0.45934202358783366,"
( ˜∆l + 2Ldhβ e
ϵ
2 + 1
e
ϵ
2 −1) + 2K
r 2π"
P,0.45996275605214154,"nl
exp

−1"
P,0.4605834885164494,"2nl ˜∆2
l "
P,0.4612042209807573,"=

2K

˜∆l + 2Ldhβ e
ϵ
2 + 1
e
ϵ
2 −1"
P,0.4618249534450652,"
+ 2K
r 2π nl"
P,0.46244568590937307,"
exp

−1"
P,0.46306641837368095,"2nl ˜∆2
l"
P,0.46368715083798884,"
.
(70)"
P,0.4643078833022967,"Take expectation over X1:N, we get
540 Z"
P,0.4649286157666046,"Bl
(η∗(x) −E[ηcl(x)])f(x)dx ≤p(Bl)e−1"
P,0.4655493482309125,2 (1−ln 2)Np(Bl)
P,0.46617008069522037,+2Kp(Bl) 
P,0.46679081315952825,"∆l + 2Ldhβ + e
ϵ
2 + 1
e
ϵ
2 −1 s"
P,0.46741154562383613,"2π
Np(Bl) ! exp "" −1"
P,0.468032278088144,"2Np(Bl)∆2
l"
P,0.4686530105524519,"e
ϵ
2 −1
e
ϵ
2 + 1 2# .(71)"
P,0.4692737430167598,"Define
541 al = """
E,0.46989447548106766,"3e
ϵ
2 + 1
e
ϵ
2 −1 r"
E,0.47051520794537555,2 ln(2K)
E,0.47113594040968343,"cNhd
+ 2Ldhβ
#"
E,0.4717566728739913,"p(Bl),
(72)"
E,0.4723774053382992,"and
542"
E,0.4729981378026071,bl = 2Kp(Bl) 
E,0.47361887026691496,"∆l + 2Ldhβ + e
ϵ
2 + 1
e
ϵ
2 −1 r"
E,0.47423960273122284,"2π
cNhd ! exp "" −1"
E,0.4748603351955307,"2cNhd∆2
l"
E,0.4754810676598386,"e
ϵ
2 −1
e
ϵ
2 + 1 2#"
E,0.4761018001241465,".
(73)"
E,0.4767225325884544,"From Assumption 1(c), p(Bl) ≥cNhd. Therefore, from (67) and (71)
543"
E,0.47734326505276226,"R −R∗
≤ G
X l=1"
E,0.47796399751707014,"h
p(Bl)e−1"
E,0.478584729981378,"2 (1−ln 2)Np(Bl) + min{al, bl}
i ≤
e−1"
E,0.4792054624456859,"2 (1−ln 2)cNhd + G
X"
E,0.4798261949099938,"l=1
min{al, bl}.
(74)"
E,0.48044692737430167,"It remains to bound PG
l=1 min{al, bl}. Note that for all x ∈Bl, η∗(x) −ηs(x) ≤∆l + 2Ldhβ.
544"
E,0.48106765983860955,"Thus
545 X"
E,0.48168839230291743,"l:∆l≤u
p(Bl) ≤P
 
η∗(X) −ηs(X) ≤u + 2Ldhβ
≤M(u + 2Ldhβ)γ.
(75)"
E,0.4823091247672253,"Let
546"
E,0.4829298572315332,"∆0 = e
ϵ
2 + 1
e
ϵ
2 −1 r"
E,0.4835505896958411,2 ln(2K)
E,0.48417132216014896,"cNhd
,
(76)"
E,0.48479205462445685,"and
547"
E,0.48541278708876473,"I0
=
{l|∆l ≤∆0},
(77)"
E,0.4860335195530726,"Ik
=
{l|2k−1∆0 < ∆l ≤2k∆0}, k = 1, 2, . . .
(78)"
E,0.4866542520173805,"Then
548"
E,0.4872749844816884,"min
l∈I0{al, bl}
≤
X"
E,0.48789571694599626,"l∈I0
al ≤  
X"
E,0.48851644941030414,"l:∆l≤∆0
p(Bl)   """
E,0.489137181874612,"3e
ϵ
2 + 1
e
ϵ
2 −1 r"
E,0.4897579143389199,2 ln(2K)
E,0.4903786468032278,"cNhd
+ 2Ldhβ
#"
E,0.4909993792675357,"≤
M(∆0 + 2Ldhβ)γ
"""
E,0.49162011173184356,"3e
ϵ
2 + 1
e
ϵ
2 −1 r"
E,0.49224084419615144,2 ln(2K)
E,0.4928615766604593,"cNhd
+ 2Ldhβ
#"
E,0.4934823091247672,"≲

1
ϵ2 ∧1
ln K
Nhd  γ+1"
E,0.4941030415890751,"2
+ hβ(γ+1).
(79)"
E,0.49472377405338297,"For Ik with k ≥1,
549"
E,0.49534450651769085,"min
l∈Ik{al, bl}
≤
X"
E,0.49596523898199874,"l∈Ik
bl ≤  
X"
E,0.4965859714463066,"l:∆l≤2k∆0
p(Bl) "
E,0.4972067039106145,"· 2K
 
2k∆0 + 2Ldhβ + ∆0

exp "" −1 2"
E,0.4978274363749224,"e
ϵ
2 −1
e
ϵ
2 + 1"
E,0.49844816883923027,"2
cNhd22k−2∆2
0 #"
E,0.49906890130353815,"≤
M(2k∆0 + 2Ldhβ)γ  
(2k + 1)∆0 + 2Ldhβ
(2K)−22k−2+1"
E,0.49968963376784603,"≤
M(∆0 + 2Ldhβ)γ+12kγ+k−22k−2+2.
(80)"
E,0.500310366232154,"It is obvious that there exists a finite constant C′ < ∞that depends on γ, such that
550 ∞
X"
E,0.5009310986964618,"k=1
2kγ+k−22k−2+2 ≤C′.
(81)"
E,0.5015518311607697,"Therefore
551 ∞
X k=1 X"
E,0.5021725636250776,"l∈Ik
min{al, bl} ≲

1
ϵ2 ∧1
ln K
Nhd  γ+1"
E,0.5027932960893855,"2
+ hβ(γ+1).
(82)"
E,0.5034140285536933,"Combine (74), (79) and (82),
552"
E,0.5040347610180013,"R −R∗≲

1
ϵ2 ∧1
ln K
Nhd  γ+1"
E,0.5046554934823091,"2
+ hβ(γ+1).
(83)"
E,0.505276225946617,"To minimize the overall excess risk, let
553"
E,0.5058969584109249,"h ∼
N(ϵ2 ∧1) ln K"
E,0.5065176908752328,"−
1
2β+d
,
(84)"
E,0.5071384233395406,"then
554"
E,0.5077591558038486,"R −R∗≲
N(ϵ2 ∧1) ln K"
E,0.5083798882681564,−β(γ+1)
E,0.5090006207324643,"2β+d
.
(85)"
E,0.5096213531967722,"Compare to the simple random response method, the bin splitting avoids the polynomial decrease
555"
E,0.5102420856610801,"over K.
556"
E,0.5108628181253879,"D
Proof of Theorem 3
557"
E,0.5114835505896959,"We still divide the support as the local label DP setting, except that the value of h is different, which
558"
E,0.5121042830540037,"will be specified later in this section. Note that (42) still holds here. Let V takes values from
559"
E,0.5127250155183116,"{−1, 1}m randomly with equal probability, and Vk is the k-th element. Then ηV(x) is a random
560"
E,0.5133457479826194,"function. The corresponding random output of hypothesis testing is denoted as ˆVk, which is calculated
561"
E,0.5139664804469274,"by (38). Then
562"
E,0.5145872129112352,"inf
A∈Aϵ
sup
(f,η)∈Fcls
(R −R∗)
≥
1
2chβ+d ∥ϕ∥1 inf
A∈Aϵmax
v∈V m
X"
E,0.5152079453755432,"k=1
P(ˆvk ̸= vk)"
E,0.515828677839851,"≥
1
2hβ+d ∥ϕ∥1 inf
A∈Aϵ m
X"
E,0.5164494103041589,"k=1
P( ˆVk ̸= Vk)"
E,0.5170701427684667,"=
1
2hβ+d ∥ϕ∥1 m
X"
E,0.5176908752327747,"k=1
inf
A∈AϵP( ˆVk ̸= Vk),
(86)"
E,0.5183116076970825,"in which the last step holds since ˆVk for different k are calculated independently.
563"
E,0.5189323401613904,"It remains to give a lower bound of P( ˆVk ̸= Vk). Denote nk as the number of samples falling in Bk,
564"
E,0.5195530726256983,"¯Yk as the average label values in Bk:
565 nk
:= N
X"
E,0.5201738050900062,"i=1
1(Xi ∈Bk),
(87)"
E,0.520794537554314,"¯Yk
:=
1
nk N
X"
E,0.521415270018622,"i=1
Yi1(Xi ∈Bk).
(88)"
E,0.5220360024829298,"Moreover, define
566"
E,0.5226567349472377,"ak
:=
1
nk N
X"
E,0.5232774674115456,"i=1
|η(Xi)|1(Xi ∈Bk) =
hβ nk N
X"
E,0.5238981998758535,"i=1
ϕ
Xi −ck h"
E,0.5245189323401613,"
1(Xi ∈Bk),
(89)"
E,0.5251396648044693,"in which the last step comes from (36). Then
567"
E,0.5257603972687771,"E[ ¯Yk|X1:N, Vk] = Vkak,
(90)"
E,0.526381129733085,"in which X1:N means X1, . . . , XN. We then show the following lemma.
568"
E,0.527001862197393,"Lemma 1. If 0 ≤t ≤ln 2/(ϵnk), and nkt is an integer, then
569"
E,0.5276225946617008,"P( ˆVk = 1|X1:N, ¯Yk = −t) + P( ˆVk = −1|X1:N, ¯Yk = t) ≥2"
E,0.5282433271260087,"3.
(91)"
E,0.5288640595903166,"Proof. Construct D′ by changing the label values of l = nkt items from these nk samples falling in
570"
E,0.5294847920546245,"Bk, from −1 to 1. Then the average label values in Bk is denoted as ¯Y ′
k after such replacement. ˆVk
571"
E,0.5301055245189323,"also becomes ˆV ′
k. Then from the ϵ-label DP requirement,
572"
E,0.5307262569832403,"P( ˆVk = 1|X1:N, ¯Yk = −t)
(a)
≥
e−lϵP

ˆV ′
k = 1|X1:N, ¯Y ′
k = −t + 2l nk "
E,0.5313469894475481,"(b)
≥
e−lϵP

ˆVk = 1|X1:N, ¯Yk = −t + 2l nk "
E,0.531967721911856,"≥
e−nktϵ

1 −P

ˆVk = −1|X1:N, ¯Yk = −t + 2l nk  ≥
1
2"
E,0.5325884543761639,"h
1 −P

ˆVk = −1|X1:N, ¯Yk = t
i
.
(92)"
E,0.5332091868404718,"in which (a) uses the group privacy property. The Hamming distance between D and D′ is l, thus the
573"
E,0.5338299193047796,"ratio of probability between D and D′ is within [e−lϵ, elϵ]. (b) holds because the algorithm does not
574"
E,0.5344506517690876,"change after changing D to D′. Similarly,
575"
E,0.5350713842333954,"P( ˆVk = −1|X1:N, ¯Yk = t) ≥1 2"
E,0.5356921166977033,"h
1 −P

ˆVk = 1|X1:N, ¯Yk = −t
i
.
(93)"
E,0.5363128491620112,"Then (91) can be shown by adding up (92) and (93).
576"
E,0.5369335816263191,"Now we use Lemma 1 to bound the excess risk. With sufficiently large nk, ˆYk will be close to
577"
E,0.5375543140906269,"Gaussian distribution with mean ak. To be more rigorous, by Berry-Esseen theorem [?], for some
578"
E,0.5381750465549349,"absolute constant CE,
579"
E,0.5387957790192427,"P
  ¯Yk ≤ak|X1:N, Vk = 1

≥1"
E,0.5394165114835506,"2 −CE
√nk
.
(94)"
E,0.5400372439478585,"Similarly,
580"
E,0.5406579764121664,"P
  ¯Yk ≥−ak|X1:N, Vk = −1

≥1"
E,0.5412787088764742,"2 −CE
√nk
.
(95)"
E,0.5418994413407822,"We first analyze cubes with
581"
E,0.54252017380509,"nk > 16C2
E, ak < ln 2"
E,0.5431409062693979,"ϵnk
.
(96)"
E,0.5437616387337058,"Under condition (96), the right hand side of (94) and (95) are at least 1/4. Therefore
582"
E,0.5443823711980137,"P( ˆVk ̸= Vk|X1:N)
=
1
2P( ˆVk = 1|X1:N, Vk = −1) + 1"
E,0.5450031036623215,"2P( ˆVk = −1|X1:N, Vk = 1)"
E,0.5456238361266295,"≥
1
8P

ˆVk = 1|X1:N, ¯Yk ≥−ln 2 ϵnk 
+ 1"
P,0.5462445685909373,"8P

ˆVk = −1|X1:N, ¯Yk ≤ln 2 ϵnk "
P,0.5468653010552452,"≥
1
12.
(97)"
P,0.547486033519553,"From (86),
583"
P,0.548106765983861,"inf
A∈Aϵ
sup
(f,η)∈Fcls
(R −R∗) ≥1"
P,0.5487274984481688,"2hβ+d ∥ϕ∥1 m
X k=1"
P,0.5493482309124768,"1
12P

ak < ln 2"
P,0.5499689633767846,"ϵnk
, nk > 16C2
E  (98)"
P,0.5505896958410925,"From (35), (89) and (87), ak ≤hβ. Therefore
584"
P,0.5512104283054003,"inf
A∈Aϵ
sup
(f,η)∈Fcls
(R −R∗) ≥1"
P,0.5518311607697083,"24hβ+d ∥ϕ∥1 m
X"
P,0.5524518932340161,"k=1
P

16C2
E < nk < ln 2 ϵhβ"
P,0.553072625698324,"
.
(99)"
P,0.5536933581626319,"Recall that each cube has probability mass chd. Select h such that
585"
P,0.5543140906269398,2Nchd = ln 2
P,0.5549348230912476,"ϵhβ .
(100)"
P,0.5555555555555556,"From Chernoff inequality, 16C2
E < nk < ln 2/(ϵhβ) holds with high probability. (100) yields
586"
P,0.5561762880198634,"h ∼(ϵN)−
1
d+β .
(101)"
P,0.5567970204841713,"Recall the bound of m in (37). Let m ∼hγβ−d, then (99) becomes
587"
P,0.5574177529484792,"inf
A∈Aϵ
sup
(f,η)∈Fcls
(R −R∗)
≳
hβ(γ+1)"
P,0.5580384854127871,"≳
(ϵN)−β(γ+1)"
P,0.5586592178770949,"d+β .
(102)"
P,0.5592799503414029,"Moreover, the standard lower bound for classification [28] is
588"
P,0.5599006828057107,"inf
A∈Aϵ
sup
(f,η)∈Fcls
(R −R∗) ≳N −β(γ+1)"
P,0.5605214152700186,"2β+d .
(103)"
P,0.5611421477343265,"Therefore
589"
P,0.5617628801986344,"inf
A∈Aϵ
sup
(f,η)∈Fcls
(R −R∗)
≳
N −β(γ+1)"
P,0.5623836126629422,2β+d + (ϵN)−β(γ+1)
P,0.5630043451272502,"d+β .
(104)"
P,0.563625077591558,"E
Proof of Theorem 4
590"
P,0.5642458100558659,"Denote
591"
P,0.5648665425201738,"n∗
l = max
j
nlj,
(105) 592 nl := K
X"
P,0.5654872749844817,"j=1
nlj = N
X"
P,0.5661080074487895,"i=1
1(Xi ∈Bl).
(106)"
P,0.5667287399130975,"For all j such that n∗
l −nlj > t,
593"
P,0.5673494723774053,"P(cl = j|X1:N, Y1:N)
=
eϵnlj/2
PK
k=1 eϵnlk/2"
P,0.5679702048417132,"≤
eϵn∗
l /2
PK
k=1 eϵnlk/2 e−1 2 ϵt ≤
e−1"
P,0.5685909373060211,"2 ϵt.
(107)
Therefore
594"
P,0.569211669770329,"P(n∗
l −nlcl > t) =
X"
P,0.5698324022346368,"j:n∗
l −nlj>t
P(cl = j|X1:N, Y1:N) ≤Ke−1"
P,0.5704531346989448,"2 ϵt.
(108)"
P,0.5710738671632526,"Hence
595"
P,0.5716945996275605,"E[n∗
l −nlcl]
=
Z ∞"
P,0.5723153320918684,"0
P(n∗
l −nlj > t)dt"
P,0.5729360645561763,"≤
Z 2 ln K/ϵ"
P,0.5735567970204841,"0
1dt +
Z ∞"
P,0.5741775294847921,"2 ln K/ϵ
Ke−1"
P,0.5747982619490999,2 ϵtdt
P,0.5754189944134078,"=
2
ϵ (ln K + 1).
(109)"
P,0.5760397268777157,"Define
596"
P,0.5766604593420236,"vlj = 1 nl N
X"
P,0.5772811918063314,"i=1
1(Xi ∈Bl)ηj(Xi),
(110)"
P,0.5779019242706394,"then
597"
P,0.5785226567349472,"E[nlj|X1:N] = nlvlj.
(111)
From Hoeffding’s inequality,
598"
P,0.5791433891992551,"P(|nlj −nlvlj| > t) ≤2e−
1
2nl t2
.
(112)
Thus
599"
P,0.5797641216635631,"E

max
j
|nlj −nlvlj|

=
Z ∞"
P,0.5803848541278709,"0
P
 
∪K
j=1 {|nlj −nlvlj| > t}

dt ≤
Z ∞"
MIN,0.5810055865921788,"0
min

1, 2Ke−
1
2nl t2
dt =
p"
MIN,0.5816263190564867,"2nl ln(2K) +
Z ∞
√"
MIN,0.5822470515207946,"2nl ln(2K)
2Ke−
1
2nl t2
dt <
2
p"
MIN,0.5828677839851024,"2nl ln(2K),
(113)"
MIN,0.5834885164494104,"in which the last step uses the inequalit
R ∞
t
e−u2/(2σ2)du ≤
√"
MIN,0.5841092489137182,"2πσe−t2/(2σ2). Then
600"
MIN,0.5847299813780261,"E[v∗
l −vlcl|X1:N]
=
1
nl
E[nlv∗
l −nlvlcl]"
MIN,0.585350713842334,"=
1
nl
E [n∗
l −nlcl + nlv∗
l −n∗
l + nlcl −nlvlcl]"
MIN,0.5859714463066419,"≤
1
nl
E[n∗
l −nlcl] + 2"
MIN,0.5865921787709497,"nl
E

max
j
|nlj −nlvlj|
"
MIN,0.5872129112352577,"≤
2
ϵnl
(ln K + 1) + 4 s"
MIN,0.5878336436995655,2 ln(2K)
MIN,0.5884543761638734,"nl
.
(114)"
MIN,0.5890751086281812,"By Hölder continuity assumption (Assumption 1(a)), for x ∈Bl,
601"
MIN,0.5896958410924892,"|vlj −ηj(x)| ≤1 nl N
X"
MIN,0.590316573556797,"i=1
1(Xi ∈Bl)|ηj(Xi) −ηj(x)| ≤Ldhβ,
(115)"
MIN,0.590937306021105,"in which Ld = L
√"
MIN,0.5915580384854128,"d, L is the constant in Assumption 1(a). Thus
602"
MIN,0.5921787709497207,"E[η∗(x) −ηcl(x)|X1:N] ≤
2
ϵnl
(ln K + 1) + 4 s"
MIN,0.5927995034140285,2 ln(2K)
MIN,0.5934202358783365,"nl
+ 2Ldhβ.
(116)"
MIN,0.5940409683426443,"Now take integration over Bl.
603 Z"
MIN,0.5946617008069522,"Bl
(η∗(x) −E[ηcl(x)]) f(x)dx"
MIN,0.5952824332712601,"≤
P

nl < 1"
MIN,0.595903165735568,"2Np(Bl)
 Z Bl"
MIN,0.5965238981998758,"
η∗(x) −E

ηcl(x)|nl < 1"
MIN,0.5971446306641838,"2Np(Bl)

f(x)dx +
Z Bl"
MIN,0.5977653631284916,"
η∗(x) −E

ηcl(x)|nl ≥1"
MIN,0.5983860955927995,"2Np(Bl)

f(x)dx"
MIN,0.5990068280571074,"≤
p(Bl) exp

−1"
MIN,0.5996275605214153,"2(1 −ln 2)Np(Bl)

+"
MIN,0.6002482929857231,"""
2(ln K + 1)"
MIN,0.6008690254500311,"ϵNp(Bl)
+ 4 s"
MIN,0.6014897579143389,2 ln(2K)
MIN,0.6021104903786468,"Np(Bl) + 2Ldhβ
#"
MIN,0.6027312228429547,"p(Bl), (117)"
MIN,0.6033519553072626,"in which p(Bl) = P(X ∈Bl) =
R"
MIN,0.6039726877715704,"Bl f(x)dx. (117) is the central label DP counterpart of (67). The
604"
MIN,0.6045934202358784,"remainder of the proof follows arguments of the local label DP. We omit detailed steps. The result is
605"
MIN,0.6052141527001862,R −R∗≲
MIN,0.6058348851644941,"ln K
ϵNhd + r"
MIN,0.606455617628802,"ln K
Nhd + hβ
!γ+1"
MIN,0.6070763500931099,".
(118)"
MIN,0.6076970825574177,"Let
606"
MIN,0.6083178150217257,"h ∼
ln K ϵN"
MIN,0.6089385474860335,"
1
β+d
+
ln K N"
MIN,0.6095592799503414,"
1
2β+d
,
(119)"
MIN,0.6101800124146493,"then
607"
MIN,0.6108007448789572,"R −R∗≲
ln K ϵN"
MIN,0.611421477343265, β(γ+1)
MIN,0.612042209807573,"β+d
+
ln K N"
MIN,0.6126629422718808, β(γ+1)
MIN,0.6132836747361887,"2β+d
.
(120)"
MIN,0.6139044072004965,"The proof is complete.
608"
MIN,0.6145251396648045,"F
Proof of Theorem 5
609"
MIN,0.6151458721291123,"Find G cubes in the support and the length of each cube is h. Let ϕ(u) be the same as the classification
610"
MIN,0.6157666045934203,"case shown in appendix B. For v ∈V := {−1, 1}G, let
611"
MIN,0.6163873370577281,"ηv(x) = K
X"
MIN,0.617008069522036,"k=1
vkϕ
x −ck h"
MIN,0.6176288019863438,"
hβ.
(121)"
MIN,0.6182495344506518,"Let P(Y = 1|x) = (1 + ηv(x))/2, P(Y = −1|x) = (1 −ηv(x)), then η(x) = E[Y |x] = ηv(x).
612"
MIN,0.6188702669149596,"The overall volume of the support is bounded. Thus, we have
613"
MIN,0.6194909993792675,"G ≤CGh−d
(122)"
MIN,0.6201117318435754,"for some constant CG.
614"
MIN,0.6207324643078833,"Denote
615"
MIN,0.6213531967721911,"ˆvk = sign
Z"
MIN,0.6219739292364991,"Bk
ˆη(x)ϕ
x −ck h"
MIN,0.6225946617008069,"
f(x)dx

,
(123)"
MIN,0.6232153941651148,"then the excess risk is bounded by
616"
MIN,0.6238361266294227,"R
=
E
h
(ˆη(X) −ηv(X))2i = K
X k=1 Z"
MIN,0.6244568590937306,"Bk
E

(ˆη(x) −ηv(x))2
f(x)dx.
(124)"
MIN,0.6250775915580384,"If ˆvk ̸= vk, from (123),
617 Z Bk"
MIN,0.6256983240223464,"
ˆη(x) −vkϕ
x −ck h"
MIN,0.6263190564866542,"
hβ
2
f(x)dx ≥
Z Bk"
MIN,0.6269397889509621,"
ˆη(x) + vkϕ
x −ck h"
MIN,0.62756052141527,"
hβ
2
f(x)dx. (125)"
MIN,0.6281812538795779,"Therefore, if ˆvk ̸= vk, then
618 Z"
MIN,0.6288019863438857,"Bk
(ˆη(x) −ηv(x))2 dx ≥1 2 Z"
MIN,0.6294227188081937,"Bk
ϕ2
x −ck h"
MIN,0.6300434512725015,"
h2βf(x)dx = 1"
MIN,0.6306641837368094,"2ch2β+d ∥ϕ∥2
2 .
(126)"
MIN,0.6312849162011173,"Therefore
619"
MIN,0.6319056486654252,"R −R∗
≥
E
1"
MIN,0.6325263811297331,"2ch2β+d ∥ϕ∥2
2 1(ˆvk ̸= vk)
"
MIN,0.633147113594041,"=
1
2ch2β+d ∥ϕ∥2
2 E[ρH(ˆv, v)].
(127)"
MIN,0.6337678460583489,"Similar to the classification problem analyzed in Appendix B, let
620"
MIN,0.6343885785226567,"h ∼
 
N(ϵ ∧1)2−
1
2β+d ,
(128)"
MIN,0.6350093109869647,"then δ ≲1, and
621"
MIN,0.6356300434512725,"inf
ˆv
sup
M∈Mϵ
max
v∈V E[ρH(ˆv, v)] ≳G ∼h−d.
(129)"
MIN,0.6362507759155804,"Thus
622"
MIN,0.6368715083798883,"inf
ˆη
inf
M∈Mϵ
sup
PX,Y ∈Freg1
R ≳h2η+dh−d ∼h2β ∼(N(ϵ ∧1)2)−
2β
2β+d .
(130)"
MIN,0.6374922408441962,"G
Proof of Theorem 6
623"
MIN,0.638112973308504,"According to Assumption 2, |Y | < T with probability 1, thus Var[Y |x] ≤T 2 for any x. A Laplacian
624"
MIN,0.638733705772812,"distribution with parameter λ has variance 2λ2, thus
625"
MIN,0.6393544382371198,"Var[W] = 2λ2 = 2
2T ϵ"
MIN,0.6399751707014277,"2
= 8T 2"
MIN,0.6405959031657356,"ϵ2 .
(131)"
MIN,0.6412166356300435,"Hence
626"
MIN,0.6418373680943513,"Var[Z] = Var[Y ] + Var[W] ≤T 2

1 + 8 ϵ2"
MIN,0.6424581005586593,"
.
(132)"
MIN,0.6430788330229671,"Now we analyze the bias first.
627"
MIN,0.643699565487275,E[ˆη(x)] = E  1 k X
MIN,0.6443202979515829,"i∈Nk(x)
Zi  = E  1 k X"
MIN,0.6449410304158908,"i∈Nk(x)
η(Xi) "
MIN,0.6455617628801986,".
(133)"
MIN,0.6461824953445066,"Thus
628"
MIN,0.6468032278088144,"|E[ˆη(x)] −η(x)|
≤
E  1 k X"
MIN,0.6474239602731223,"i∈Nk(x)
|η(Xi) −η(x)|   ≤
E  1 k X"
MIN,0.6480446927374302,"i∈Nk(x)
min
n
L ∥Xi −x∥β , 2T
o
  ≤
E  1 k X"
MIN,0.6486654252017381,"i∈Nk(x)
min

Lρβ(x), 2T
	
 "
MIN,0.6492861576660459,"≤
2TP(ρ(x) > r0) + Lrβ
0"
MIN,0.6499068901303539,"≤
2Te−(1−ln 2)k + L

2k
Ncvdθ  β d ≤
C1  k N  β"
MIN,0.6505276225946617,"d
,
(134)"
MIN,0.6511483550589696,"for some constant C1.
629"
MIN,0.6517690875232774,"It remains to bound the variance.
630"
MIN,0.6523898199875854,"Var[ˆη(x)] = E [Var [ˆη(x)|X1, . . . , XN]] + Var[E[ˆη(x)]|X1, . . . , XN].
(135)"
MIN,0.6530105524518932,"For the first term in (135),
631"
MIN,0.6536312849162011,"Var[ˆη(x)|X1, . . . , XN]
=
Var  1 k X"
MIN,0.654252017380509,"i∈Nk(x)
Zi|X1, . . . , XN  "
MIN,0.6548727498448169,"=
1
k2
X"
MIN,0.6554934823091247,"i∈Nk(x)
Var[Zi|X1, . . . , XN]"
MIN,0.6561142147734327,"≤
1
k T 2

1 + 8 ϵ2"
MIN,0.6567349472377405,"
.
(136)"
MIN,0.6573556797020484,"For the second term in (135),
632"
MIN,0.6579764121663563,"Var[E[ˆη(x)|X1, . . . , XN]]
=
Var  1 k X"
MIN,0.6585971446306642,"i∈Nk(x)
η(Xi)   ≤
E    1 k X"
MIN,0.659217877094972,"i∈Nk(x)
η(Xi) −η(x)   2  =
1
k X"
MIN,0.65983860955928,"i∈Nk(x)
E

(η(Xi) −η(x))2 ≤
1
k X"
MIN,0.6604593420235878,"i∈Nk(x)
E
h
min
n
L2 ∥Xi −x∥2β , 4T 2oi"
MIN,0.6610800744878957,"≤
4T 2e−(1−ln 2)k + L2r2β
0"
MIN,0.6617008069522036,"≤
C2
1  k N  2β"
MIN,0.6623215394165115,"d
.
(137)"
MIN,0.6629422718808193,"Therefore (135) becomes
633"
MIN,0.6635630043451273,Var[ˆη(x)] ≤1
MIN,0.6641837368094351,"k T 2

1 + 8 ϵ2"
MIN,0.664804469273743,"
+ C2
1  k N  2β"
MIN,0.6654252017380509,"d
.
(138)"
MIN,0.6660459342023588,"Combine the analysis of bias and variance,
634"
MIN,0.6666666666666666,E[(ˆη(x) −η(x))2] ≤1
MIN,0.6672873991309746,"k T 2

1 + 8 ϵ2"
MIN,0.6679081315952824,"
+ 2C2
1  k N  2β"
MIN,0.6685288640595903,"d
.
(139)"
MIN,0.6691495965238982,"Therefore the overall risk is bounded by
635"
MIN,0.6697703289882061,R = E[(ˆη(X) −η(X))2] ≲1
MIN,0.6703910614525139,"k T 2

1 + 8 ϵ2"
MIN,0.6710117939168219,"
+ 2C2
1  k N  2β"
MIN,0.6716325263811297,"d
.
(140)"
MIN,0.6722532588454376,"The optimal growth rate of k over N is
636 k ∼N"
MIN,0.6728739913097455,"2β
d+2β (ϵ ∧1)−
2d
d+2β .
(141)"
MIN,0.6734947237740534,"Then the convergence rate of the overall risk becomes
637"
MIN,0.6741154562383612,"R ≲(N(ϵ ∧1)2)−
2β
d+2β .
(142)"
MIN,0.6747361887026692,"H
Proof of Theorem 7
638"
MIN,0.675356921166977,"From (127),
639"
MIN,0.6759776536312849,"R −R∗
≥
1
2ch2β+d ∥ϕ∥2
2 E[ρH( ˆV, V)]"
MIN,0.6765983860955928,"=
1
2ch2β+d ∥ϕ∥2
2 G
X"
MIN,0.6772191185599007,"k=1
P( ˆVk ̸= Vk).
(143)"
MIN,0.6778398510242085,"Follow the analysis of lower bounds of classification in Appendix D, let h scales as (101), then
640"
MIN,0.6784605834885165,"P( ˆVk ̸= Vk) ≳1. Moreover, G ∼h−d. Hence
641"
MIN,0.6790813159528243,"inf
A∈Aϵ
sup
(f,η)∈Freg1
(R −R∗) ≳h2β ∼(ϵN)−2β"
MIN,0.6797020484171322,"d+β .
(144)"
MIN,0.68032278088144,"Moreover, note that the non-private lower bound of regression is
642"
MIN,0.680943513345748,"inf
A∈Aϵ
sup
(f,η)∈Freg1
(R −R∗) ≳N −
2β
2β+d .
(145)"
MIN,0.6815642458100558,"Combine (144) and (145),
643"
MIN,0.6821849782743638,"inf
A∈Aϵ
sup
(f,η)∈Freg1
(R −R∗) ≳N −
2β
2β+d + (ϵN)−2β"
MIN,0.6828057107386716,"d+β .
(146)"
MIN,0.6834264432029795,"I
Proof of Theorem 8
644"
MIN,0.6840471756672873,"1) Analysis of bias. Note that
645"
MIN,0.6846679081315953,"E[ˆηl|X1:N] = E[Y |X ∈Bl] =
1
p(Bl)"
MIN,0.6852886405959032,"Z
η(u)f(u)du.
(147)"
MIN,0.685909373060211,"Therefore, for all x ∈Bl,
646"
MIN,0.686530105524519,"|E[ˆηl|X1:N] −η(x)|
≤
1
p(Bl)"
MIN,0.6871508379888268,"Z
|η(u) −η(x)|f(u)du"
MIN,0.6877715704531348,"≤
Ldhβ.
(148)"
MIN,0.6883923029174426,"Therefore for all x ∈Bl,
647"
MIN,0.6890130353817505,"|E[ˆηl] −η(x)| ≤Ldhβ.
(149)"
MIN,0.6896337678460583,"2) Analysis of variance. If nl > 0,
648 Var"
MIN,0.6902545003103663,"""
1
nl N
X"
MIN,0.6908752327746741,"i=1
1(Xi ∈Bl)Yi|X1:N # = 1"
MIN,0.691495965238982,"nl
Var[Y |X ∈Bl] ≤1"
MIN,0.6921166977032899,"nl
.
(150)"
MIN,0.6927374301675978,"Therefore
649 Var"
MIN,0.6933581626319056,"""
1
nl N
X"
MIN,0.6939788950962136,"i=1
1(Xi ∈Bl)Yi #"
MIN,0.6945996275605214,"≤
P

nl < 1"
MIN,0.6952203600248293,"2Np(Bl)

+ P

nl ≥1"
MIN,0.6958410924891372,"2Np(Bl)

2
Np(Bl)"
MIN,0.6964618249534451,"≤
exp

−1"
MIN,0.6970825574177529,"2(1 −ln 2)Np(Bl)

+
2
Nchd .
(151)"
MIN,0.6977032898820609,"Similarly,
650"
MIN,0.6983240223463687,"Var[Wl]
≤
P

nl < 1"
MIN,0.6989447548106766,"2Np(Bl)
 1"
MIN,0.6995654872749845,"ϵ2 + P

nl ≥1"
MIN,0.7001862197392924,"2Np(Bl)

8
  1"
MIN,0.7008069522036002,"2Np(Bl)
2 ϵ2"
MIN,0.7014276846679082,"≲
1
N 2h2dϵ2 .
(152)"
MIN,0.702048417132216,"The mean squared error can then be bounded by the bounds of bias and variance.
651"
MIN,0.7026691495965239,"E

(ˆη(x) −η(x))2
≲h2β +
1
Nhd +
1
N 2h2dϵ2 .
(153)"
MIN,0.7032898820608318,"Let
652"
MIN,0.7039106145251397,"h ∼N −
1
2β+d + (ϵN)−
1
d+β .
(154)"
MIN,0.7045313469894475,"Then
653"
MIN,0.7051520794537555,"R −R∗≲N −
2β
2β+d + (ϵN)−2β"
MIN,0.7057728119180633,"d+β .
(155)"
MIN,0.7063935443823712,"J
Proof of Theorem 9
654"
MIN,0.7070142768466791,"Now we prove the minimax lower bound of nonparametric regression under label DP constraint. We
655"
MIN,0.707635009310987,"focus on the case in which ϵ is small.
656"
MIN,0.7082557417752948,"Similar to the steps of the proof of Theorem 5 in Appendix F, we find B cubes in the support. The
657"
MIN,0.7088764742396028,"definition of ηv, ˆvk are also the same as (121) and (123). Compared with the case with bounded
658"
MIN,0.7094972067039106,"noise, now Y can take values in R.
659"
MIN,0.7101179391682185,"For given x, let
660 Y ="
MIN,0.7107386716325264,"


 

"
MIN,0.7113594040968343,"T
with probability
1
2

Mp"
MIN,0.7119801365611421,"T p + ηv(x) T
"
WITH PROBABILITY,0.7126008690254501,"0
with probability
1 −Mp"
WITH PROBABILITY,0.7132216014897579,"T p
−T
with probability
1
2

Mp"
WITH PROBABILITY,0.7138423339540658,"T p −ηv(x) T

. (156)"
WITH PROBABILITY,0.7144630664183736,"In Appendix F about the case with bounded noise, T is a fixed constant. However, here T is not fixed
661"
WITH PROBABILITY,0.7150837988826816,"and will change over N. It is straightforward to show that the distribution of Y in (156) satisfies
662"
WITH PROBABILITY,0.7157045313469894,"Assumption 3:
663"
WITH PROBABILITY,0.7163252638112974,"E[|Y |p|x] = Mp.
(157)"
WITH PROBABILITY,0.7169459962756052,"Moreover, by taking expectation over Y , it can be shown that ηv is still the regression function:
664"
WITH PROBABILITY,0.7175667287399131,"E[Y |x] = ηv(x).
(158)"
WITH PROBABILITY,0.718187461204221,"Let
665"
WITH PROBABILITY,0.7188081936685289,"T =
1"
WITH PROBABILITY,0.7194289261328367,"2Mph−β

1
p−1
.
(159)"
WITH PROBABILITY,0.7200496585971446,"Here we still define
666"
WITH PROBABILITY,0.7206703910614525,"δ =
sup
M∈Mϵ
max
v,v′:ρH(v,v′)=1D(P(X,Z)1:N|v||P(X,Z)1:N|v′).
(160)"
WITH PROBABILITY,0.7212911235257604,"Without loss of generality, suppose that v1 = v′
1 for i ̸= 1. Then
667"
WITH PROBABILITY,0.7219118559900682,"D(P(X,Z)1:N|v||P(X,Z)1:N|v′)
=
ND(PX,Z|v||PX,Z|v′) =
N
Z"
WITH PROBABILITY,0.7225325884543762,"B1
f(x)D(PZ|X,v||PZ|X,v′)dx ≤
N
Z"
WITH PROBABILITY,0.723153320918684,"B1
f(x)(eϵ −1)2TV2  
PZ|X,v, PZ|X,v′
dx =
N
Z"
WITH PROBABILITY,0.7237740533829919,"B1
f(x)(eϵ −1)2η2
v(x) 1"
WITH PROBABILITY,0.7243947858472998,T 2 dx
WITH PROBABILITY,0.7250155183116077,"=
N(eϵ −1)2 h2β T 2 Z"
WITH PROBABILITY,0.7256362507759155,"B1
f(x)ϕ2
x −c1 h 
dx"
WITH PROBABILITY,0.7262569832402235,"=
N(eϵ −1)2h2β+d ∥ϕ∥2
2 T −2"
WITH PROBABILITY,0.7268777157045313,"=
N(eϵ −1)2 ∥ϕ∥2
2 1"
MP,0.7274984481688392,2Mp
MP,0.7281191806331471,"−
2
p−1
h2β+d+ 2β"
MP,0.728739913097455,"p−1 .
(161)"
MP,0.7293606455617628,"Let
668"
MP,0.7299813780260708,"h ∼(N(eϵ −1)2)−
p−1
2pβ+d(p−1) ,
(162)"
MP,0.7306021104903786,"then δ ≲1. Hence
669"
MP,0.7312228429546865,"inf
ˆη
inf
M∈Mϵ sup
(f,η)∈F
R ≳h2β ∼(N(eϵ −1)2)−
2β(p−1)
2pβ+d(p−1) .
(163)"
MP,0.7318435754189944,"K
Proof of Theorem 10
670"
MP,0.7324643078833023,"Define
671"
MP,0.7330850403476101,"ηT (x) := E[YT |x].
(164)"
MP,0.7337057728119181,"Then
672"
MP,0.7343265052762259,"ˆη(x) −η(x) = ηT (x) −η(x) + E[ˆη(x)] −ηT (x) + ˆη(x) −E[ˆη(x)].
(165)"
MP,0.7349472377405338,"Therefore
673"
MP,0.7355679702048417,"E
h
(ˆη(x) −η(x))2i
≤
3(ηT (x) −η(x))2 + 3(E[ˆη(x)] −ηT (x))2 + 3 Var[ˆη(x)]"
MP,0.7361887026691496,":=
3(I1 + I2 + I3).
(166)"
MP,0.7368094351334574,"Now we bound I1, I2 and I3 separately.
674"
MP,0.7374301675977654,"Bound of I1. We show the following lemma (which will also be used later).
675"
MP,0.7380509000620733,Lemma 2.
MP,0.7386716325263811,|ηT (x) −η(x)| ≤Mp
MP,0.7392923649906891,"p −1T 1−p.
(167)"
MP,0.7399130974549969,"Proof. Firstly, we decompose ηT (x) and η(x):
676"
MP,0.7405338299193048,"ηT (x) = E[YT |x] = E[Y 1(−T ≤Y ≤T)|x] + TP(Y > T|x) −TP(Y < T|x),
(168)
677"
MP,0.7411545623836127,"η(x) = E[Y |x] = E[Y 1(−T ≤Y ≤T)|x] + E[Y 1(Y > T)|x] −E[Y 1(Y < T)|x].
(169)"
MP,0.7417752948479206,"The first term is the same between (168) and (169). Therefore we only need to compare the second
678"
MP,0.7423960273122284,"and the third term.
679"
MP,0.7430167597765364,"E[Y 1(Y > T)|x]
=
Z T"
MP,0.7436374922408442,"0
P(Y > T|x)dt +
Z ∞"
MP,0.7442582247051521,"T
P(Y > T|x)dt"
MP,0.74487895716946,"≤
TP(Y > T|x) +
Z ∞"
MP,0.7454996896337679,"T
Mpt−pdt"
MP,0.7461204220980757,"=
TP(Y > T|x) + Mp"
MP,0.7467411545623837,"p −1T 1−p.
(170)"
MP,0.7473618870266915,"Therefore
680"
MP,0.7479826194909994,E[Y 1(Y > T)|x] −TP(Y > T|x) ≤Mp
MP,0.7486033519553073,"p −1T 1−p.
(171)"
MP,0.7492240844196152,"Similarly,
681"
MP,0.749844816883923,TP(Y < T|x) −E[Y 1(Y < T)|x] ≤Mp
MP,0.750465549348231,"p −1T 1−p.
(172)"
MP,0.7510862818125388,"A Combination of these two inequalities yields the (167).
682"
MP,0.7517070142768467,"With Lemma 2,
683"
MP,0.7523277467411545,"I1 ≤
M 2
p
(p −1)2 T 2(1−p).
(173)"
MP,0.7529484792054625,"Bound of I2. Follow the steps in (134),
684"
MP,0.7535692116697703,"I2 ≤C2
1  k N  2β"
MP,0.7541899441340782,"d
.
(174)"
MP,0.7548106765983861,"Bound of I3. We decompose Var[ˆη(x)] as following:
685"
MP,0.755431409062694,"Var[ˆη(x)] = E[Var[ˆη(x)|X1, . . . , XN]] + Var[E[ˆη(x)|X1, . . . , XN]].
(175)"
MP,0.7560521415270018,"For the first term in (175), from Assumption 3, E[|Y |p|x] ≤Mp. Since p ≥2, we have E[Y 2|x] =
686 M"
P,0.7566728739913098,"2
p
p . Therefore
687"
P,0.7572936064556176,"Var[Zi|X1, . . . , XN] = Var[YT ] + Var[W] ≤M"
P,0.7579143389199255,"2
p
p + 8T 2"
P,0.7585350713842334,"ϵ2 .
(176)"
P,0.7591558038485413,"Recall (20), we have
688"
P,0.7597765363128491,"Var[ˆη(x)|X1, . . . , XN]
=
1
k2
X"
P,0.7603972687771571,"i∈Nk(x)
Var[Zi|X1, . . . , XN] ≤
1
k 
M"
P,0.7610180012414649,"2
p
p + 8T 2 ϵ2"
P,0.7616387337057728,"
.
(177)"
P,0.7622594661700807,"For the second term in (175), (137) still holds, thus
689"
P,0.7628801986343886,"Var[E[ˆη(x)|X1, . . . , XN]] ≤C2
1  k N  2β"
P,0.7635009310986964,"d
,
(178)"
P,0.7641216635630044,"and
690 I3 ≤1 k 
M"
P,0.7647423960273122,"2
p
p + 8T 2 ϵ2"
P,0.7653631284916201,"
+ C2
1  k N  2β"
P,0.765983860955928,"d
.
(179)"
P,0.7666045934202359,"Plug (173), (174) and (179) into (166), and take expectations, we get
691"
P,0.7672253258845437,"R
=
E[(ˆη(X) −η(X))2]"
P,0.7678460583488517,"≲
T 2(1−p) + 1"
P,0.7684667908131595,k + T 2
P,0.7690875232774674,"kϵ2 +
 k N  2β"
P,0.7697082557417753,"d
.
(180)"
P,0.7703289882060832,"Let
692"
P,0.770949720670391,"T ∼(kϵ2)
1
2p , k ∼(Nϵ2)"
P,0.771570453134699,"2pβ
d(p−1)+2pβ ∨N"
P,0.7721911855990068,"2β
2β+d ,
(181)"
P,0.7728119180633147,"then
693"
P,0.7734326505276226,"R ≲(Nϵ2)−
2β(p−1)
d(p−1)+2pβ ∨N −
2β
2β+d .
(182)"
P,0.7740533829919305,"L
Proof of Theorem 11
694"
P,0.7746741154562383,"Let Y be distributed as (156). Recall Lemma 1 for the problem of classification and regression with
695"
P,0.7752948479205463,"bounded noise.
696"
P,0.7759155803848541,"Now we show the corresponding lemma for regression with unbounded noise.
697"
P,0.776536312849162,"Lemma 3. If 0 ≤t ≤T ln 2/(ϵnk), and nkt/T is an integer, then
698"
P,0.7771570453134699,"P( ˆVk = 1|X1:N, ¯Yk = −t) + P( ˆVk = −1|X1:N, ¯Yk = t) ≥2"
P,0.7777777777777778,"3.
(183)"
P,0.7783985102420856,"Here we briefly explain the condition nkt is an integer. Recall the definition of ¯Yk in (88). Now since
699"
P,0.7790192427063936,"Y take values in {−T, 0, T}, nk ¯Yk/T must be an integer. Therefore, in Lemma 3, we only need to
700"
P,0.7796399751707014,"consider the case such that nkt/T is an integer.
701"
P,0.7802607076350093,"Proof. The proof follows the proof of Lemma 1 closely. We provide the proof here for completeness.
702"
P,0.7808814400993171,"Construct D′ by changing the label values of l = nkt/T items from these nk samples falling in Bk,
703"
P,0.7815021725636251,"from −T to T. Then the average label values in Bk is denoted as ¯Y ′
k after such replacement. ˆVk also
704"
P,0.7821229050279329,"becomes ˆV ′
k. Then from the ϵ-label DP requirement,
705"
P,0.7827436374922409,"P( ˆVk = 1|X1:N, ¯Yk = −t)
(a)
≥
e−lϵP

ˆV ′
k = 1|X1:N, ¯Y ′
k = −t + 2l nk "
P,0.7833643699565487,"(b)
≥
e−lϵP

ˆVk = 1|X1:N, ¯Yk = −t + 2l nk "
P,0.7839851024208566,"≥
e−nktϵ

1 −P

ˆVk = −1|X1:N, ¯Yk = −t + 2l nk  ≥
1
2"
P,0.7846058348851644,"h
1 −P

ˆVk = −1|X1:N, ¯Yk = t
i
.
(184)"
P,0.7852265673494724,"in which (a) uses the group privacy property. The Hamming distance between D and D′ is l, thus the
706"
P,0.7858472998137802,"ratio of probability between D and D′ is within [e−lϵ, elϵ]. (b) holds because the algorithm does not
707"
P,0.7864680322780881,"change after changing D to D′. Similarly,
708"
P,0.787088764742396,"P( ˆVk = −1|X1:N, ¯Yk = t) ≥1 2"
P,0.7877094972067039,"h
1 −P

ˆVk = 1|X1:N, ¯Yk = −t
i
.
(185)"
P,0.7883302296710117,"Then (183) can be shown by adding up (184) and (185).
709"
P,0.7889509621353197,"We then follow the proof of Theorem 3 in Appendix D. (101) becomes
710"
P,0.7895716945996276,"h ∼
ϵN T"
P,0.7901924270639354,"−
1
d+β
.
(186)"
P,0.7908131595282434,"In (156), note that P(Y = T) ≥0 and P(Y = −T) ≥0. Therefore Mp/T p ≥ηv(x)/T. This
711"
P,0.7914338919925512,"requires hβT p−1 ≤Mp. Let T ∼h−
β
p−1 , then
712"
P,0.7920546244568591,"h ∼(ϵN)−
1
d+β h"
P,0.792675356921167,"β
(d+β)(p−1) ,
(187)"
P,0.7932960893854749,"i.e.
713"
P,0.7939168218497827,"h ∼(ϵN)−
p−1
pβ+d(p−1) .
(188)"
P,0.7945375543140907,"Combine with standard minimax rate, the lower bound of regression with unbounded noise is
714"
P,0.7951582867783985,"inf
A∈Aϵ
sup
(f,η)∈Freg2
(R −R∗) ≳N −
2β
2β+d + (ϵN)−
2β(p−1)
pβ+d(p−1) .
(189)"
P,0.7957790192427064,"M
Proof of Theorem 12
715"
P,0.7963997517070143,"1) Analysis of bias. Note that Lemma 2 still holds here. Moreover, recall (149). Therefore
716"
P,0.7970204841713222,|E[ˆηl] −η(x)| ≤|E[ˆηl −ηT (x)]| + |ηT (x) −η(x)| ≤Ldhβ + Mp
P,0.79764121663563,"p −1T 1−p.
(190)"
P,0.798261949099938,"2) Analysis of variance. Similar to (151), it can be shown that
717 Var"
P,0.7988826815642458,"""
1
nl N
X"
P,0.7995034140285537,"i=1
1(Xi ∈Bl)Yi #"
P,0.8001241464928616,"≲
1
Nhd .
(191)"
P,0.8007448789571695,"Moreover, the noise variance can be bounded by
718"
P,0.8013656114214773,"Var[Wl] ≲
T 2"
P,0.8019863438857853,"N 2h2dϵ2 .
(192)"
P,0.8026070763500931,"The mean squared error is then bounded by
719"
P,0.803227808814401,"E
h
(ˆη(x) −η(x))2i
≲h2β + T 2(1−p) +
T 2"
P,0.8038485412787089,"N 2h2dϵ2 +
1
Nhd .
(193)"
P,0.8044692737430168,"Let T ∼(ϵNhd)1/p, then
720"
P,0.8050900062073246,"R −R∗= E

(ˆη(X) −η(X))2
≲h2β +
1
Nhd + (ϵNhd)−2(1−1/p).
(194)"
P,0.8057107386716326,"To minimize (194), let
721"
P,0.8063314711359404,"h ∼N −
1
2β+d + (ϵN)−
p−1
pβ+d(p−1) ,
(195)"
P,0.8069522036002483,"then
722"
P,0.8075729360645562,"R −R∗≲N −
2β
2β+d + (ϵN)−
2β(p−1)
pβ+d(p−1) .
(196)"
P,0.8081936685288641,"NeurIPS Paper Checklist
723"
CLAIMS,0.8088144009931719,"1. Claims
724"
CLAIMS,0.8094351334574799,"Question: Do the main claims made in the abstract and introduction accurately reflect the
725"
CLAIMS,0.8100558659217877,"paper’s contributions and scope?
726"
CLAIMS,0.8106765983860956,"Answer: [Yes]
727"
CLAIMS,0.8112973308504035,"Justification: The main contribution (i.e. proposing a new Huber loss minimization approach
728"
CLAIMS,0.8119180633147114,"which is more suitable to realistic cases, and providing theoretical analysis) has been made
729"
CLAIMS,0.8125387957790192,"clear in the abstract and introduction.
730"
CLAIMS,0.8131595282433272,"Guidelines:
731"
CLAIMS,0.813780260707635,"• The answer NA means that the abstract and introduction do not include the claims
732"
CLAIMS,0.8144009931719429,"made in the paper.
733"
CLAIMS,0.8150217256362507,"• The abstract and/or introduction should clearly state the claims made, including the
734"
CLAIMS,0.8156424581005587,"contributions made in the paper and important assumptions and limitations. A No or
735"
CLAIMS,0.8162631905648665,"NA answer to this question will not be perceived well by the reviewers.
736"
CLAIMS,0.8168839230291745,"• The claims made should match theoretical and experimental results, and reflect how
737"
CLAIMS,0.8175046554934823,"much the results can be expected to generalize to other settings.
738"
CLAIMS,0.8181253879577902,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
739"
CLAIMS,0.818746120422098,"are not attained by the paper.
740"
LIMITATIONS,0.819366852886406,"2. Limitations
741"
LIMITATIONS,0.8199875853507138,"Question: Does the paper discuss the limitations of the work performed by the authors?
742"
LIMITATIONS,0.8206083178150217,"Answer: [Yes]
743"
LIMITATIONS,0.8212290502793296,"Justification: It is explained at the end of conclusion section.
744"
LIMITATIONS,0.8218497827436375,"Guidelines:
745"
LIMITATIONS,0.8224705152079453,"• The answer NA means that the paper has no limitation while the answer No means that
746"
LIMITATIONS,0.8230912476722533,"the paper has limitations, but those are not discussed in the paper.
747"
LIMITATIONS,0.8237119801365611,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
748"
LIMITATIONS,0.824332712600869,"• The paper should point out any strong assumptions and how robust the results are to
749"
LIMITATIONS,0.8249534450651769,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
750"
LIMITATIONS,0.8255741775294848,"model well-specification, asymptotic approximations only holding locally). The authors
751"
LIMITATIONS,0.8261949099937926,"should reflect on how these assumptions might be violated in practice and what the
752"
LIMITATIONS,0.8268156424581006,"implications would be.
753"
LIMITATIONS,0.8274363749224084,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
754"
LIMITATIONS,0.8280571073867163,"only tested on a few datasets or with a few runs. In general, empirical results often
755"
LIMITATIONS,0.8286778398510242,"depend on implicit assumptions, which should be articulated.
756"
LIMITATIONS,0.8292985723153321,"• The authors should reflect on the factors that influence the performance of the approach.
757"
LIMITATIONS,0.8299193047796399,"For example, a facial recognition algorithm may perform poorly when image resolution
758"
LIMITATIONS,0.8305400372439479,"is low or images are taken in low lighting. Or a speech-to-text system might not be
759"
LIMITATIONS,0.8311607697082557,"used reliably to provide closed captions for online lectures because it fails to handle
760"
LIMITATIONS,0.8317815021725636,"technical jargon.
761"
LIMITATIONS,0.8324022346368715,"• The authors should discuss the computational efficiency of the proposed algorithms
762"
LIMITATIONS,0.8330229671011794,"and how they scale with dataset size.
763"
LIMITATIONS,0.8336436995654872,"• If applicable, the authors should discuss possible limitations of their approach to
764"
LIMITATIONS,0.8342644320297952,"address problems of privacy and fairness.
765"
LIMITATIONS,0.834885164494103,"• While the authors might fear that complete honesty about limitations might be used by
766"
LIMITATIONS,0.8355058969584109,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
767"
LIMITATIONS,0.8361266294227188,"limitations that aren’t acknowledged in the paper. The authors should use their best
768"
LIMITATIONS,0.8367473618870267,"judgment and recognize that individual actions in favor of transparency play an impor-
769"
LIMITATIONS,0.8373680943513345,"tant role in developing norms that preserve the integrity of the community. Reviewers
770"
LIMITATIONS,0.8379888268156425,"will be specifically instructed to not penalize honesty concerning limitations.
771"
THEORY ASSUMPTIONS AND PROOFS,0.8386095592799503,"3. Theory Assumptions and Proofs
772"
THEORY ASSUMPTIONS AND PROOFS,0.8392302917442582,"Question: For each theoretical result, does the paper provide the full set of assumptions and
773"
THEORY ASSUMPTIONS AND PROOFS,0.839851024208566,"a complete (and correct) proof?
774"
THEORY ASSUMPTIONS AND PROOFS,0.840471756672874,"Answer: [Yes]
775"
THEORY ASSUMPTIONS AND PROOFS,0.8410924891371818,"Justification: Proofs are shown in the appendix, and intuition is provided in the paper.
776"
THEORY ASSUMPTIONS AND PROOFS,0.8417132216014898,"Guidelines:
777"
THEORY ASSUMPTIONS AND PROOFS,0.8423339540657977,"• The answer NA means that the paper does not include theoretical results.
778"
THEORY ASSUMPTIONS AND PROOFS,0.8429546865301055,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
779"
THEORY ASSUMPTIONS AND PROOFS,0.8435754189944135,"referenced.
780"
THEORY ASSUMPTIONS AND PROOFS,0.8441961514587213,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
781"
THEORY ASSUMPTIONS AND PROOFS,0.8448168839230292,"• The proofs can either appear in the main paper or the supplemental material, but if
782"
THEORY ASSUMPTIONS AND PROOFS,0.845437616387337,"they appear in the supplemental material, the authors are encouraged to provide a short
783"
THEORY ASSUMPTIONS AND PROOFS,0.846058348851645,"proof sketch to provide intuition.
784"
THEORY ASSUMPTIONS AND PROOFS,0.8466790813159528,"• Inversely, any informal proof provided in the core of the paper should be complemented
785"
THEORY ASSUMPTIONS AND PROOFS,0.8472998137802608,"by formal proofs provided in appendix or supplemental material.
786"
THEORY ASSUMPTIONS AND PROOFS,0.8479205462445686,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
787"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8485412787088765,"4. Experimental Result Reproducibility
788"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8491620111731844,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
789"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8497827436374923,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
790"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8504034761018001,"of the paper (regardless of whether the code and data are provided or not)?
791"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.851024208566108,"Answer: [NA]
792"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8516449410304159,"Justification: This is a theoretical paper without experiments.
793"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8522656734947238,"Guidelines:
794"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8528864059590316,"• The answer NA means that the paper does not include experiments.
795"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8535071384233396,"• If the paper includes experiments, a No answer to this question will not be perceived
796"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8541278708876474,"well by the reviewers: Making the paper reproducible is important, regardless of
797"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8547486033519553,"whether the code and data are provided or not.
798"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8553693358162632,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
799"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8559900682805711,"to make their results reproducible or verifiable.
800"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8566108007448789,"• Depending on the contribution, reproducibility can be accomplished in various ways.
801"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8572315332091869,"For example, if the contribution is a novel architecture, describing the architecture fully
802"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8578522656734947,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
803"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8584729981378026,"be necessary to either make it possible for others to replicate the model with the same
804"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8590937306021105,"dataset, or provide access to the model. In general. releasing code and data is often
805"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8597144630664184,"one good way to accomplish this, but reproducibility can also be provided via detailed
806"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8603351955307262,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
807"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8609559279950342,"of a large language model), releasing of a model checkpoint, or other means that are
808"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.861576660459342,"appropriate to the research performed.
809"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8621973929236499,"• While NeurIPS does not require releasing code, the conference does require all submis-
810"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8628181253879578,"sions to provide some reasonable avenue for reproducibility, which may depend on the
811"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8634388578522657,"nature of the contribution. For example
812"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8640595903165735,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
813"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8646803227808815,"to reproduce that algorithm.
814"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8653010552451893,"(b) If the contribution is primarily a new model architecture, the paper should describe
815"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8659217877094972,"the architecture clearly and fully.
816"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8665425201738051,"(c) If the contribution is a new model (e.g., a large language model), then there should
817"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.867163252638113,"either be a way to access this model for reproducing the results or a way to reproduce
818"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8677839851024208,"the model (e.g., with an open-source dataset or instructions for how to construct
819"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8684047175667288,"the dataset).
820"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8690254500310366,"(d) We recognize that reproducibility may be tricky in some cases, in which case
821"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8696461824953445,"authors are welcome to describe the particular way they provide for reproducibility.
822"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8702669149596524,"In the case of closed-source models, it may be that access to the model is limited in
823"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8708876474239603,"some way (e.g., to registered users), but it should be possible for other researchers
824"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8715083798882681,"to have some path to reproducing or verifying the results.
825"
OPEN ACCESS TO DATA AND CODE,0.8721291123525761,"5. Open access to data and code
826"
OPEN ACCESS TO DATA AND CODE,0.8727498448168839,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
827"
OPEN ACCESS TO DATA AND CODE,0.8733705772811918,"tions to faithfully reproduce the main experimental results, as described in supplemental
828"
OPEN ACCESS TO DATA AND CODE,0.8739913097454997,"material?
829"
OPEN ACCESS TO DATA AND CODE,0.8746120422098076,"Answer: [NA]
830"
OPEN ACCESS TO DATA AND CODE,0.8752327746741154,"Justification: This is a theoretical paper without experiments.
831"
OPEN ACCESS TO DATA AND CODE,0.8758535071384234,"Guidelines:
832"
OPEN ACCESS TO DATA AND CODE,0.8764742396027312,"• The answer NA means that paper does not include experiments requiring code.
833"
OPEN ACCESS TO DATA AND CODE,0.8770949720670391,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
834"
OPEN ACCESS TO DATA AND CODE,0.877715704531347,"public/guides/CodeSubmissionPolicy) for more details.
835"
OPEN ACCESS TO DATA AND CODE,0.8783364369956549,"• While we encourage the release of code and data, we understand that this might not be
836"
OPEN ACCESS TO DATA AND CODE,0.8789571694599627,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
837"
OPEN ACCESS TO DATA AND CODE,0.8795779019242707,"including code, unless this is central to the contribution (e.g., for a new open-source
838"
OPEN ACCESS TO DATA AND CODE,0.8801986343885785,"benchmark).
839"
OPEN ACCESS TO DATA AND CODE,0.8808193668528864,"• The instructions should contain the exact command and environment needed to run to
840"
OPEN ACCESS TO DATA AND CODE,0.8814400993171942,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
841"
OPEN ACCESS TO DATA AND CODE,0.8820608317815022,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
842"
OPEN ACCESS TO DATA AND CODE,0.88268156424581,"• The authors should provide instructions on data access and preparation, including how
843"
OPEN ACCESS TO DATA AND CODE,0.883302296710118,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
844"
OPEN ACCESS TO DATA AND CODE,0.8839230291744258,"• The authors should provide scripts to reproduce all experimental results for the new
845"
OPEN ACCESS TO DATA AND CODE,0.8845437616387337,"proposed method and baselines. If only a subset of experiments are reproducible, they
846"
OPEN ACCESS TO DATA AND CODE,0.8851644941030415,"should state which ones are omitted from the script and why.
847"
OPEN ACCESS TO DATA AND CODE,0.8857852265673495,"• At submission time, to preserve anonymity, the authors should release anonymized
848"
OPEN ACCESS TO DATA AND CODE,0.8864059590316573,"versions (if applicable).
849"
OPEN ACCESS TO DATA AND CODE,0.8870266914959652,"• Providing as much information as possible in supplemental material (appended to the
850"
OPEN ACCESS TO DATA AND CODE,0.8876474239602731,"paper) is recommended, but including URLs to data and code is permitted.
851"
OPEN ACCESS TO DATA AND CODE,0.888268156424581,"6. Experimental Setting/Details
852"
OPEN ACCESS TO DATA AND CODE,0.8888888888888888,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
853"
OPEN ACCESS TO DATA AND CODE,0.8895096213531968,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
854"
OPEN ACCESS TO DATA AND CODE,0.8901303538175046,"results?
855"
OPEN ACCESS TO DATA AND CODE,0.8907510862818125,"Answer: [NA]
856"
OPEN ACCESS TO DATA AND CODE,0.8913718187461204,"Justification: This is a theoretical paper without experiments.
857"
OPEN ACCESS TO DATA AND CODE,0.8919925512104283,"Guidelines:
858"
OPEN ACCESS TO DATA AND CODE,0.8926132836747361,"• The answer NA means that the paper does not include experiments.
859"
OPEN ACCESS TO DATA AND CODE,0.8932340161390441,"• The experimental setting should be presented in the core of the paper to a level of detail
860"
OPEN ACCESS TO DATA AND CODE,0.8938547486033519,"that is necessary to appreciate the results and make sense of them.
861"
OPEN ACCESS TO DATA AND CODE,0.8944754810676598,"• The full details can be provided either with the code, in appendix, or as supplemental
862"
OPEN ACCESS TO DATA AND CODE,0.8950962135319678,"material.
863"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8957169459962756,"7. Experiment Statistical Significance
864"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8963376784605835,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
865"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8969584109248914,"information about the statistical significance of the experiments?
866"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8975791433891993,"Answer: [NA]
867"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8981998758535071,"Justification: No experiments.
868"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8988206083178151,"Guidelines:
869"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8994413407821229,"• The answer NA means that the paper does not include experiments.
870"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9000620732464308,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
871"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9006828057107387,"dence intervals, or statistical significance tests, at least for the experiments that support
872"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9013035381750466,"the main claims of the paper.
873"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9019242706393544,"• The factors of variability that the error bars are capturing should be clearly stated (for
874"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9025450031036624,"example, train/test split, initialization, random drawing of some parameter, or overall
875"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9031657355679702,"run with given experimental conditions).
876"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9037864680322781,"• The method for calculating the error bars should be explained (closed form formula,
877"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.904407200496586,"call to a library function, bootstrap, etc.)
878"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9050279329608939,"• The assumptions made should be given (e.g., Normally distributed errors).
879"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9056486654252017,"• It should be clear whether the error bar is the standard deviation or the standard error
880"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9062693978895097,"of the mean.
881"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9068901303538175,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
882"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9075108628181254,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
883"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9081315952824333,"of Normality of errors is not verified.
884"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9087523277467412,"• For asymmetric distributions, the authors should be careful not to show in tables or
885"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.909373060211049,"figures symmetric error bars that would yield results that are out of range (e.g. negative
886"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.909993792675357,"error rates).
887"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9106145251396648,"• If error bars are reported in tables or plots, The authors should explain in the text how
888"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9112352576039727,"they were calculated and reference the corresponding figures or tables in the text.
889"
EXPERIMENTS COMPUTE RESOURCES,0.9118559900682806,"8. Experiments Compute Resources
890"
EXPERIMENTS COMPUTE RESOURCES,0.9124767225325885,"Question: For each experiment, does the paper provide sufficient information on the com-
891"
EXPERIMENTS COMPUTE RESOURCES,0.9130974549968963,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
892"
EXPERIMENTS COMPUTE RESOURCES,0.9137181874612043,"the experiments?
893"
EXPERIMENTS COMPUTE RESOURCES,0.9143389199255121,"Answer: [NA]
894"
EXPERIMENTS COMPUTE RESOURCES,0.91495965238982,"Justification: No experiments.
895"
EXPERIMENTS COMPUTE RESOURCES,0.9155803848541278,"Guidelines:
896"
EXPERIMENTS COMPUTE RESOURCES,0.9162011173184358,"• The answer NA means that the paper does not include experiments.
897"
EXPERIMENTS COMPUTE RESOURCES,0.9168218497827436,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
898"
EXPERIMENTS COMPUTE RESOURCES,0.9174425822470516,"or cloud provider, including relevant memory and storage.
899"
EXPERIMENTS COMPUTE RESOURCES,0.9180633147113594,"• The paper should provide the amount of compute required for each of the individual
900"
EXPERIMENTS COMPUTE RESOURCES,0.9186840471756673,"experimental runs as well as estimate the total compute.
901"
EXPERIMENTS COMPUTE RESOURCES,0.9193047796399751,"• The paper should disclose whether the full research project required more compute
902"
EXPERIMENTS COMPUTE RESOURCES,0.9199255121042831,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
903"
EXPERIMENTS COMPUTE RESOURCES,0.9205462445685909,"didn’t make it into the paper).
904"
CODE OF ETHICS,0.9211669770328988,"9. Code Of Ethics
905"
CODE OF ETHICS,0.9217877094972067,"Question: Does the research conducted in the paper conform, in every respect, with the
906"
CODE OF ETHICS,0.9224084419615146,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
907"
CODE OF ETHICS,0.9230291744258224,"Answer: [Yes]
908"
CODE OF ETHICS,0.9236499068901304,"Justification: Our paper does not violate code of ethics.
909"
CODE OF ETHICS,0.9242706393544382,"Guidelines:
910"
CODE OF ETHICS,0.9248913718187461,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
911"
CODE OF ETHICS,0.925512104283054,"• If the authors answer No, they should explain the special circumstances that require a
912"
CODE OF ETHICS,0.9261328367473619,"deviation from the Code of Ethics.
913"
CODE OF ETHICS,0.9267535692116697,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
914"
CODE OF ETHICS,0.9273743016759777,"eration due to laws or regulations in their jurisdiction).
915"
BROADER IMPACTS,0.9279950341402855,"10. Broader Impacts
916"
BROADER IMPACTS,0.9286157666045934,"Question: Does the paper discuss both potential positive societal impacts and negative
917"
BROADER IMPACTS,0.9292364990689013,"societal impacts of the work performed?
918"
BROADER IMPACTS,0.9298572315332092,"Answer: [NA]
919"
BROADER IMPACTS,0.930477963997517,"Justification: This paper is foundational and theoretical research and not tied to particular
920"
BROADER IMPACTS,0.931098696461825,"applications.
921"
BROADER IMPACTS,0.9317194289261328,"Guidelines:
922"
BROADER IMPACTS,0.9323401613904407,"• The answer NA means that there is no societal impact of the work performed.
923"
BROADER IMPACTS,0.9329608938547486,"• If the authors answer NA or No, they should explain why their work has no societal
924"
BROADER IMPACTS,0.9335816263190565,"impact or why the paper does not address societal impact.
925"
BROADER IMPACTS,0.9342023587833643,"• Examples of negative societal impacts include potential malicious or unintended uses
926"
BROADER IMPACTS,0.9348230912476723,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
927"
BROADER IMPACTS,0.9354438237119801,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
928"
BROADER IMPACTS,0.936064556176288,"groups), privacy considerations, and security considerations.
929"
BROADER IMPACTS,0.9366852886405959,"• The conference expects that many papers will be foundational research and not tied
930"
BROADER IMPACTS,0.9373060211049038,"to particular applications, let alone deployments. However, if there is a direct path to
931"
BROADER IMPACTS,0.9379267535692116,"any negative applications, the authors should point it out. For example, it is legitimate
932"
BROADER IMPACTS,0.9385474860335196,"to point out that an improvement in the quality of generative models could be used to
933"
BROADER IMPACTS,0.9391682184978274,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
934"
BROADER IMPACTS,0.9397889509621353,"that a generic algorithm for optimizing neural networks could enable people to train
935"
BROADER IMPACTS,0.9404096834264432,"models that generate Deepfakes faster.
936"
BROADER IMPACTS,0.9410304158907511,"• The authors should consider possible harms that could arise when the technology is
937"
BROADER IMPACTS,0.9416511483550589,"being used as intended and functioning correctly, harms that could arise when the
938"
BROADER IMPACTS,0.9422718808193669,"technology is being used as intended but gives incorrect results, and harms following
939"
BROADER IMPACTS,0.9428926132836747,"from (intentional or unintentional) misuse of the technology.
940"
BROADER IMPACTS,0.9435133457479826,"• If there are negative societal impacts, the authors could also discuss possible mitigation
941"
BROADER IMPACTS,0.9441340782122905,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
942"
BROADER IMPACTS,0.9447548106765984,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
943"
BROADER IMPACTS,0.9453755431409062,"feedback over time, improving the efficiency and accessibility of ML).
944"
SAFEGUARDS,0.9459962756052142,"11. Safeguards
945"
SAFEGUARDS,0.946617008069522,"Question: Does the paper describe safeguards that have been put in place for responsible
946"
SAFEGUARDS,0.9472377405338299,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
947"
SAFEGUARDS,0.9478584729981379,"image generators, or scraped datasets)?
948"
SAFEGUARDS,0.9484792054624457,"Answer: [NA]
949"
SAFEGUARDS,0.9490999379267536,"Justification: This paper has no such risks.
950"
SAFEGUARDS,0.9497206703910615,"Guidelines:
951"
SAFEGUARDS,0.9503414028553694,"• The answer NA means that the paper poses no such risks.
952"
SAFEGUARDS,0.9509621353196772,"• Released models that have a high risk for misuse or dual-use should be released with
953"
SAFEGUARDS,0.9515828677839852,"necessary safeguards to allow for controlled use of the model, for example by requiring
954"
SAFEGUARDS,0.952203600248293,"that users adhere to usage guidelines or restrictions to access the model or implementing
955"
SAFEGUARDS,0.9528243327126009,"safety filters.
956"
SAFEGUARDS,0.9534450651769087,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
957"
SAFEGUARDS,0.9540657976412167,"should describe how they avoided releasing unsafe images.
958"
SAFEGUARDS,0.9546865301055245,"• We recognize that providing effective safeguards is challenging, and many papers do
959"
SAFEGUARDS,0.9553072625698324,"not require this, but we encourage authors to take this into account and make a best
960"
SAFEGUARDS,0.9559279950341403,"faith effort.
961"
LICENSES FOR EXISTING ASSETS,0.9565487274984482,"12. Licenses for existing assets
962"
LICENSES FOR EXISTING ASSETS,0.957169459962756,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
963"
LICENSES FOR EXISTING ASSETS,0.957790192427064,"the paper, properly credited and are the license and terms of use explicitly mentioned and
964"
LICENSES FOR EXISTING ASSETS,0.9584109248913718,"properly respected?
965"
LICENSES FOR EXISTING ASSETS,0.9590316573556797,"Answer: [NA]
966"
LICENSES FOR EXISTING ASSETS,0.9596523898199876,"Justification: This paper does not use existing assets.
967"
LICENSES FOR EXISTING ASSETS,0.9602731222842955,"Guidelines:
968"
LICENSES FOR EXISTING ASSETS,0.9608938547486033,"• The answer NA means that the paper does not use existing assets.
969"
LICENSES FOR EXISTING ASSETS,0.9615145872129113,"• The authors should cite the original paper that produced the code package or dataset.
970"
LICENSES FOR EXISTING ASSETS,0.9621353196772191,"• The authors should state which version of the asset is used and, if possible, include a
971"
LICENSES FOR EXISTING ASSETS,0.962756052141527,"URL.
972"
LICENSES FOR EXISTING ASSETS,0.9633767846058349,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
973"
LICENSES FOR EXISTING ASSETS,0.9639975170701428,"• For scraped data from a particular source (e.g., website), the copyright and terms of
974"
LICENSES FOR EXISTING ASSETS,0.9646182495344506,"service of that source should be provided.
975"
LICENSES FOR EXISTING ASSETS,0.9652389819987586,"• If assets are released, the license, copyright information, and terms of use in the
976"
LICENSES FOR EXISTING ASSETS,0.9658597144630664,"package should be provided. For popular datasets, paperswithcode.com/datasets
977"
LICENSES FOR EXISTING ASSETS,0.9664804469273743,"has curated licenses for some datasets. Their licensing guide can help determine the
978"
LICENSES FOR EXISTING ASSETS,0.9671011793916822,"license of a dataset.
979"
LICENSES FOR EXISTING ASSETS,0.9677219118559901,"• For existing datasets that are re-packaged, both the original license and the license of
980"
LICENSES FOR EXISTING ASSETS,0.9683426443202979,"the derived asset (if it has changed) should be provided.
981"
LICENSES FOR EXISTING ASSETS,0.9689633767846059,"• If this information is not available online, the authors are encouraged to reach out to
982"
LICENSES FOR EXISTING ASSETS,0.9695841092489137,"the asset’s creators.
983"
NEW ASSETS,0.9702048417132216,"13. New Assets
984"
NEW ASSETS,0.9708255741775295,"Question: Are new assets introduced in the paper well documented and is the documentation
985"
NEW ASSETS,0.9714463066418374,"provided alongside the assets?
986"
NEW ASSETS,0.9720670391061452,"Answer: [NA]
987"
NEW ASSETS,0.9726877715704532,"Justification: This paper does not release new assets
988"
NEW ASSETS,0.973308504034761,"Guidelines:
989"
NEW ASSETS,0.9739292364990689,"• The answer NA means that the paper does not release new assets.
990"
NEW ASSETS,0.9745499689633768,"• Researchers should communicate the details of the dataset/code/model as part of their
991"
NEW ASSETS,0.9751707014276847,"submissions via structured templates. This includes details about training, license,
992"
NEW ASSETS,0.9757914338919925,"limitations, etc.
993"
NEW ASSETS,0.9764121663563005,"• The paper should discuss whether and how consent was obtained from people whose
994"
NEW ASSETS,0.9770328988206083,"asset is used.
995"
NEW ASSETS,0.9776536312849162,"• At submission time, remember to anonymize your assets (if applicable). You can either
996"
NEW ASSETS,0.978274363749224,"create an anonymized URL or include an anonymized zip file.
997"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.978895096213532,"14. Crowdsourcing and Research with Human Subjects
998"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9795158286778398,"Question: For crowdsourcing experiments and research with human subjects, does the paper
999"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9801365611421478,"include the full text of instructions given to participants and screenshots, if applicable, as
1000"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9807572936064556,"well as details about compensation (if any)?
1001"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9813780260707635,"Answer: [NA]
1002"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9819987585350713,"Justification: This paper does not involve crowdsourcing.
1003"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9826194909993793,"Guidelines:
1004"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9832402234636871,"• The answer NA means that the paper does not involve crowdsourcing nor research with
1005"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.983860955927995,"human subjects.
1006"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9844816883923029,"• Including this information in the supplemental material is fine, but if the main contribu-
1007"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9851024208566108,"tion of the paper involves human subjects, then as much detail as possible should be
1008"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9857231533209186,"included in the main paper.
1009"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9863438857852266,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
1010"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9869646182495344,"or other labor should be paid at least the minimum wage in the country of the data
1011"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9875853507138423,"collector.
1012"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9882060831781502,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
1013"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9888268156424581,"Subjects
1014"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9894475481067659,"Question: Does the paper describe potential risks incurred by study participants, whether
1015"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9900682805710739,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
1016"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9906890130353817,"approvals (or an equivalent approval/review based on the requirements of your country or
1017"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9913097454996896,"institution) were obtained?
1018"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9919304779639975,"Answer: [NA]
1019"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9925512104283054,"Justification: This paper does not involve crowdsourcing.
1020"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9931719428926132,"Guidelines:
1021"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9937926753569212,"• The answer NA means that the paper does not involve crowdsourcing nor research with
1022"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.994413407821229,"human subjects.
1023"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9950341402855369,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
1024"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9956548727498448,"may be required for any human subjects research. If you obtained IRB approval, you
1025"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9962756052141527,"should clearly state this in the paper.
1026"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9968963376784605,"• We recognize that the procedures for this may vary significantly between institutions
1027"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9975170701427685,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
1028"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9981378026070763,"guidelines for their institution.
1029"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9987585350713842,"• For initial submissions, do not include any information that would break anonymity (if
1030"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9993792675356921,"applicable), such as the institution conducting the review.
1031"
