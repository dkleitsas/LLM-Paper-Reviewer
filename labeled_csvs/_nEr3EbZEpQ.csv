Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0033003300330033004,"We consider black-box optimization with a limited number of function evalua-
tions. This is a typical scenario when optimizing variable settings that are expen-
sive to evaluate.
The traditional designs of optimization methods are theory-driven, so they obtain
performance guarantees over the classes of problems specified by the theory. In
sharp contrast, the concept of Learning to Optimize (L2O) represents a novel strat-
egy that employs machine learning techniques to create optimization algorithms.
This approach automates the design of an optimization algorithm for a class of
optimization problems. This data-driven procedure generates methods that can
efficiently solve problems similar to those in the training set."
INTRODUCTION,0.006600660066006601,"1
INTRODUCTION"
INTRODUCTION,0.009900990099009901,"Black box optimization (BBO) refers to optimization techniques used when the objective function
is complex, expensive to evaluate, or lacks a known analytical form. Here, the term “black box”
indicates that the internal workings of the function are unknown or not utilized. Instead, the function
is treated as an oracle that provides output values (or performance measures) for given input values
without revealing the underlying process."
INTRODUCTION,0.013201320132013201,"Given an objective function f : Rn →R, black box optimization aims to find the input x∗∈Rn
that minimizes f(x). Mathematically, the optimization problem can be stated as:
x∗= arg min
x∈Rn f(x),
(1)"
INTRODUCTION,0.0165016501650165,"where f is the black box function whose internal structure is unknown and only its input-output
behavior can be observed."
INTRODUCTION,0.019801980198019802,"Classic optimization algorithms such as Covariance Matrix Adaptation Evolution Strategy (CMA-
ES) (Hansen & Ostermeier, 2001), Particle Swarm Optimization (PSO) Kennedy & Eberhart (1995),
Differential Evolution (DE) Storn & Price (1997), and Bayesian Optimization (Pelikan & Pe-
likan, 2005) have been extensively used for black box optimization. These methods rely on hand-
engineered rules and heuristics to explore and exploit the search space. They are effective for a
broad range of problems but often require significant manual tuning to achieve optimal performance
for specific tasks."
INTRODUCTION,0.0231023102310231,"In contrast, a promising data-driven approach, Learning to Optimize (L2O), seeks to replace tradi-
tional human-tuned optimization algorithms with neural network-parameterized optimizers trained
to learn update rules from data. This method leverages machine learning to automate the optimiza-
tion process, reducing the need for extensive manual adjustments. While classical algorithms are
theory-driven and provide performance guarantees based on theoretical analysis, L2O algorithms
are designed through empirical training on a set of problems, aiming to generalize and perform well
on new, similar tasks."
INTRODUCTION,0.026402640264026403,"In this work, we consider the optimization of unimodal noise-free real-parameter black box functions
with a single objective under a limited evaluation budget. Unimodal functions are characterized by
having a single local minimum."
INTRODUCTION,0.0297029702970297,"Let f : Rn →R be a unimodal black box function that needs to be optimized. Our goal is to find
x∗∈Rn that minimizes f(x) within the constraints of a limited number of function evaluations."
INTRODUCTION,0.033003300330033,"By employing L2O, we aim to develop optimization methods that can adaptively learn from data
and improve performance over time, providing a significant advantage over traditional optimization"
INTRODUCTION,0.036303630363036306,Under review as a conference paper at ICOMP 2024
INTRODUCTION,0.039603960396039604,"techniques in scenarios where the objective function evaluations are costly and the problem-specific
tuning is impractical."
LIT REVIEW,0.0429042904290429,"2
RELATED WORK"
LIT REVIEW,0.0462046204620462,"Li and Malik (Li & Malik, 2017) introduced an alternative approach using reinforcement learning to
optimize, where the gradient history and objective values are used as observations and step vectors
as actions.This method demonstrated the potential of reinforcement learning in optimization tasks,
particularly in leveraging historical data to make informed decisions."
LIT REVIEW,0.04950495049504951,"L2O represents a paradigm shift from these traditional methods by leveraging machine learning to
automate the design of optimization algorithms. The first significant contribution to L2O was by
Andrychowicz (Andrychowicz et al., 2016), who formulated the update rules of optimizers as the
input and output features for a Recurrent Neural Network (RNN) optimizer. This foundational work
paved the way for subsequent advancements in the field."
LIT REVIEW,0.052805280528052806,"In the work Chen et al. (2017) proposed a gradient-free optimization method that employs Gaus-
sian Processes (GP) for training. This approach is particularly useful in scenarios where gradient
information is unavailable or expensive to compute. Similarly, in the work TV et al. (2019) uti-
lized Gaussian Mixture Models (GMM) for training optimization algorithms, focusing on global
optimization tasks. This work highlighted the effectiveness of probabilistic models in capturing the
underlying distribution of optimization landscapes. In contrast, our focus is on local optimization
where the training and testing functions belong to the same family, characterized by random. This
approach requires the training function to have a gradient, allowing for efficient use of gradient-
based training methods. This ensures that the optimization algorithm is well-suited for the specific
family of functions encountered during testing, providing a consistent and relevant optimization
process."
LIT REVIEW,0.056105610561056105,"Recent advancements in genetic programming have further expanded the L2O framework. Stanovov
et al. (2022) demonstrated the use of genetic programming to develop symbolic expressions for
parameter adaptation in differential evolution algorithms. This method automates the search for
optimal parameter control strategies, leading to enhanced performance and the extraction of novel
algorithmic insights. Such techniques complement our local optimization approach by offering
adaptive mechanisms that can be integrated into gradient-based methods, enhancing their efficiency
and adaptability."
LIT REVIEW,0.0594059405940594,"Furthermore, Exploratory Landscape Analysis (ELA) (Mersmann et al., 2011) subsumes a number
of techniques employed to obtain knowledge about the properties of an unknown optimization prob-
lem, particularly those that impact the performance of optimization algorithms. These features are
not only relatively cheap to compute but also highly effective in distinguishing problem groups and
relating them to high-level features. This capability paves the way for automatic algorithm selec-
tion, enhancing the L2O approach by providing a deeper understanding of optimization landscapes
and guiding the selection of the most suitable algorithms for specific problem classes. However,
a significant challenge with ELA is that among all features, the Y-values have been found to be
the most significant. These Y-values correspond to specific types of functions, which can limit the
generalization and adaptability of these features across diverse optimization problems. Despite this
limitation, the low-level features generated through ELA remain valuable for L2O."
IMPLEMENTATION/METHODS,0.0627062706270627,"3
LEARNING TO OPTIMIZE BLACK BOX"
IMPLEMENTATION/METHODS,0.066006600660066,"A black box optimization algorithm can be described through an iterative loop consisting of the
following steps:"
IMPLEMENTATION/METHODS,0.06930693069306931,"1. Based on the current state of knowledge ht, propose a next query point xt."
IMPLEMENTATION/METHODS,0.07260726072607261,2. Observe the resultant response yt = f (xt).
IMPLEMENTATION/METHODS,0.07590759075907591,3. Update the internal state to obtain ht+1.
IMPLEMENTATION/METHODS,0.07920792079207921,Under review as a conference paper at ICOMP 2024
IMPLEMENTATION/METHODS,0.08250825082508251,"Here, a recurrent neural network (RNN), parameterized by θ, updates its hidden state using data
from the previous time step, and a simple linear layer derives the new query point xt from the
hidden state. The first query x1 is generated by initializing the parameters to ones."
IMPLEMENTATION/METHODS,0.0858085808580858,The combined update and query operations can be formulated as follows:
IMPLEMENTATION/METHODS,0.0891089108910891,"ht = RNNθ(ht−1, xt−1, yt−1),
(2)
xt = MLPω(ht, features)
(3)"
IMPLEMENTATION/METHODS,0.0924092409240924,"Here, ht is the hidden state at time step t, and MLPω is a multi-layer perceptron parameterized by
ω."
IMPLEMENTATION/METHODS,0.09570957095709572,"In our approach, the linear layer is structured with hidden dimensions 256 →128 →output size,
using LeakyReLU activation functions between each linear transformation."
IMPLEMENTATION/METHODS,0.09900990099009901,"The feature vectors xfeat and yfeat are constructed by concatenating the last four observed values
and the best-known values. To ensure the values are within a comparable range and to improve
numerical stability, we apply L2 normalization."
IMPLEMENTATION/METHODS,0.10231023102310231,"xfeat = [xbest, xi, xi−1, xi−2, xi−3] ,
(4)
yfeat = [ybest, yi, yi−1, yi−2, yi−3] ,
(5)"
IMPLEMENTATION/METHODS,0.10561056105610561,"yfeat =
yfeat
∥yfeat∥2
(6)"
IMPLEMENTATION/METHODS,0.10891089108910891,"This ensures that the feature vector yfeat is scaled appropriately, making it more suitable for further
processing in algorithms sensitive to varying scales of input data."
IMPLEMENTATION/METHODS,0.11221122112211221,The combined features to the linear layer is then given by:
IMPLEMENTATION/METHODS,0.11551155115511551,"features = [xfeat, yfeat]
(7)"
IMPLEMENTATION/METHODS,0.1188118811881188,Under review as a conference paper at ICOMP 2024
IMPLEMENTATION/METHODS,0.12211221122112212,"3.1
OPTIMIZING WEIGHS"
IMPLEMENTATION/METHODS,0.1254125412541254,"Lion (Evolved Sign Momentum) is a unique optimizer that uses the sign of the gradient to determine
the update direction of the momentum (Chen et al., 2024). This makes Lion more memory-efficient
and faster than AdamW which tracks and store the first and second-order moments."
IMPLEMENTATION/METHODS,0.12871287128712872,"3.2
INCORPORATING LSTM FOR ENHANCED MEMORY"
IMPLEMENTATION/METHODS,0.132013201320132,"To further enhance the optimization process, we incorporate Long Short-Term Memory (LSTM)
networks (Hochreiter & Schmidhuber, 1997). LSTMs are a type of RNN specifically designed to
capture long-term dependencies and mitigate the vanishing gradient problem."
IMPLEMENTATION/METHODS,0.1353135313531353,The LSTM equations are as follows:
IMPLEMENTATION/METHODS,0.13861386138613863,"ft = σ(Wf[ht−1, xt−1] + bf),
(8)
it = σ(Wi[ht−1, xt−1] + bi),
(9)
ot = σ(Wo[ht−1, xt−1] + bo),
(10)
˜ct = tanh(Wc[ht−1, xt−1] + bc),
(11)
ct = ft ⊙ct−1 + it ⊙˜ct,
(12)
ht = ot ⊙tanh(ct).
(13)"
IMPLEMENTATION/METHODS,0.1419141914191419,"Here, ft, it, ot, and ˜ct represent forget, input, output gates, and candidate cell state, respectively.
The LSTM cell state ct allows the network to retain long-term information."
IMPLEMENTATION/METHODS,0.14521452145214522,"3.3
ORTHOGONAL INITIALIZATION OF HIDDEN STATES"
IMPLEMENTATION/METHODS,0.1485148514851485,"For stable and efficient training of RNNs, it is crucial to properly initialize the hidden states. Or-
thogonal initialization is a widely adopted technique that ensures the initial states are mutually or-
thogonal, which helps in preserving the gradient flow across many time steps (Vorontsov et al.,
2017)."
IMPLEMENTATION/METHODS,0.15181518151815182,"3.4
VALIDATION"
IMPLEMENTATION/METHODS,0.1551155115511551,"The validation process is crucial for assessing the generalization capability of the model. Validation
data, which is a subset of the dataset not used in training, is employed to evaluate the model’s
performance after each epoch. This helps in ensuring that the model generalizes well to unseen
data."
IMPLEMENTATION/METHODS,0.15841584158415842,"3.5
ITERATION-WEIGHTED LOSS"
IMPLEMENTATION/METHODS,0.1617161716171617,"To address the exploration-exploitation trade-off in black box optimization, we introduce a novel
loss function termed Iteration-Weighted Loss. This function dynamically adjusts the weight of each
iteration, thereby balancing the focus between exploring new areas and exploiting known promising
regions."
IMPLEMENTATION/METHODS,0.16501650165016502,The Iteration-Weighted Loss can be mathematically described as follows:
IMPLEMENTATION/METHODS,0.16831683168316833,Given:
IMPLEMENTATION/METHODS,0.1716171617161716,• ybest: the best observed value at each iteration.
IMPLEMENTATION/METHODS,0.17491749174917492,• yfound: the value found at the current iteration.
IMPLEMENTATION/METHODS,0.1782178217821782,"• w: the weight vector for iterations, with only the last n iterations having non-zero weights."
IMPLEMENTATION/METHODS,0.18151815181518152,The loss for iteration t is defined as:
IMPLEMENTATION/METHODS,0.1848184818481848,Lt = wt ·
IMPLEMENTATION/METHODS,0.18811881188118812,"1
N N
X"
IMPLEMENTATION/METHODS,0.19141914191419143,"i=1
(yfound,i −ybest,i) ! (14)"
IMPLEMENTATION/METHODS,0.19471947194719472,Under review as a conference paper at ICOMP 2024
IMPLEMENTATION/METHODS,0.19801980198019803,"Where wt is the weight at iteration t, given by: wt ="
IMPLEMENTATION/METHODS,0.20132013201320131,"(
αt
PT
j=T −n+1 αj
for T −n < t,"
IMPLEMENTATION/METHODS,0.20462046204620463,"0
otherwise.
(15)"
IMPLEMENTATION/METHODS,0.2079207920792079,"Here, T is the total number of iterations, n is the number of last iterations to consider, and α is a
scaling coefficient where α ≥1."
IMPLEMENTATION/METHODS,0.21122112211221122,"The weight distribution wt follows an exponentially increasing pattern for the last n iterations, with
more recent iterations receiving higher weights. This ensures that the most recent observations have
a larger influence on the optimization process, promoting better exploitation of recent findings while
still allowing for exploration."
IMPLEMENTATION/METHODS,0.2145214521452145,"3.6
ADVANTAGES"
IMPLEMENTATION/METHODS,0.21782178217821782,"• Balancing Exploration and Exploitation: By assigning higher weights to recent itera-
tions, the loss function effectively balances the exploration of new regions and the ex-
ploitation of known good regions.
• Dynamic Adjustment: The weights are dynamically adjusted based on the progress of the
optimization, allowing more flexible and responsive search behavior.
• Enhanced Memory with LSTM: Incorporating LSTM networks enables the optimization
process to better handle long-term dependencies and improves overall performance.
• Stable Training with Orthogonal Initialization: Orthogonal initialization of hidden
states ensures stable gradient flow, facilitating more effective training of RNNs."
RESULTS/EXPERIMENTS,0.22112211221122113,"4
NUMERICAL EXPERIMENTS"
RESULTS/EXPERIMENTS,0.22442244224422442,"For the experiments conducted in this study, we select unimodal functions from the Black-Box
Optimization Benchmarking (BBOB) suite (Hansen et al., 2021). These functions are designed to
evaluate the performance of optimization algorithms on single-objective, continuous optimization
problems. The choice of unimodal functions provides a controlled environment to test the algo-
rithms’ efficiency in converging to the local optimum."
RESULTS/EXPERIMENTS,0.22772277227722773,"We compare our approach with various algorithms available in the Nevergrad optimization plat-
form (Bennet et al., 2021). Nevergrad offers a wide range of algorithms, allowing a comprehensive
evaluation and comparison of algorithms’ performance."
RESULTS/EXPERIMENTS,0.23102310231023102,"4.1
SELECTION OF BENCHMARK FUNCTIONS"
RESULTS/EXPERIMENTS,0.23432343234323433,"The unimodal functions from BBOB include F2, F6, F8, F11, F12, F13, F14. Each function is
subjected to a random shift x. See details in Appendix B."
RESULTS/EXPERIMENTS,0.2376237623762376,"4.2
BLACK BOX OPTIMIZERS"
RESULTS/EXPERIMENTS,0.24092409240924093,"The algorithms selected from Nevergrad include Random Search, BOBYQA, Bayesian Optimiza-
tion (implemented as “BayesOptimBO” and “BO” classes), CMA-ES, PSO, and DE, see details in
Appendix A."
RESULTS/EXPERIMENTS,0.24422442244224424,"4.3
ITERATION SCHEME"
RESULTS/EXPERIMENTS,0.24752475247524752,"The first 10 × D (where D is the dimensionality of the function) iterations are conducted under the
algorithm’s architecture. The subsequent 5×D iterations are not. This is done to test the algorithm’s
ability to predict independently of the iteration size."
RESULTS/EXPERIMENTS,0.2508250825082508,"4.4
PERFORMANCE METRIC"
RESULTS/EXPERIMENTS,0.25412541254125415,"We use a logarithmic transformation to assess the performance more precisely. Specifically, the
metric −log10(y −ymin) is used, where y is the current solution value and ymin is the global"
RESULTS/EXPERIMENTS,0.25742574257425743,Under review as a conference paper at ICOMP 2024
RESULTS/EXPERIMENTS,0.2607260726072607,"optimum. This transformation helps in distinguishing small differences in performance, making it
easier to compare algorithms that converge very close to the optimal solution. The x-axis represents
the iteration number, while the y-axis shows the median −log10(y −ymin), where y is the solution
value at a given iteration and ymin is the known optimal value."
RESULTS/EXPERIMENTS,0.264026402640264,"In the loss function, all iterations were considered significant (since the tasks are unimodal) and
alpha = 1.5."
RESULTS/EXPERIMENTS,0.26732673267326734,"1
5
10
15
20
25
30"
RESULTS/EXPERIMENTS,0.2706270627062706,Iteration −1.5 −1.0 −0.5 0.0 0.5
RESULTS/EXPERIMENTS,0.2739273927392739,median −log 10
RESULTS/EXPERIMENTS,0.27722772277227725,"(y
−
y min +
ε)"
RESULTS/EXPERIMENTS,0.28052805280528054,A((rac( )e Sec(or 2 d m
RESULTS/EXPERIMENTS,0.2838283828382838,L2O -BB
RESULTS/EXPERIMENTS,0.2871287128712871,Bayesian Optimization
RESULTS/EXPERIMENTS,0.29042904290429045,Random Search
RESULTS/EXPERIMENTS,0.29372937293729373,Bayes Optim
RESULTS/EXPERIMENTS,0.297029702970297,CMA-ES PSO DE
RESULTS/EXPERIMENTS,0.30033003300330036,BOBYQA
RESULTS/EXPERIMENTS,0.30363036303630364,"1
5
10
15
20
25
30"
RESULTS/EXPERIMENTS,0.3069306930693069,Iteration −6 −4 −2 0 2 4 6
RESULTS/EXPERIMENTS,0.3102310231023102,median −log 10
RESULTS/EXPERIMENTS,0.31353135313531355,"(y
−
y min +
ε)"
RESULTS/EXPERIMENTS,0.31683168316831684,Bent Cigar 2 dim
RESULTS/EXPERIMENTS,0.3201320132013201,L2O -BB
RESULTS/EXPERIMENTS,0.3234323432343234,Bayesian Optimization
RESULTS/EXPERIMENTS,0.32673267326732675,Random Search
RESULTS/EXPERIMENTS,0.33003300330033003,Bayes Optim
RESULTS/EXPERIMENTS,0.3333333333333333,CMA-ES PSO DE
RESULTS/EXPERIMENTS,0.33663366336633666,BOBYQA
RESULTS/EXPERIMENTS,0.33993399339933994,"1
5
10
15
20
25
30"
RESULTS/EXPERIMENTS,0.3432343234323432,Iteration −1.5 −1.0 −0.5 0.0 0.5 1.0 1.5
RESULTS/EXPERIMENTS,0.3465346534653465,median −log 10
RESULTS/EXPERIMENTS,0.34983498349834985,"(y
−
y min +
ε)"
RESULTS/EXPERIMENTS,0.35313531353135313,Different Powers 2 dim
RESULTS/EXPERIMENTS,0.3564356435643564,L2O -BB
RESULTS/EXPERIMENTS,0.35973597359735976,Bayesian Optimization
RESULTS/EXPERIMENTS,0.36303630363036304,Random Search
RESULTS/EXPERIMENTS,0.36633663366336633,Bayes Optim
RESULTS/EXPERIMENTS,0.3696369636963696,CMA-ES PSO DE
RESULTS/EXPERIMENTS,0.37293729372937295,BOBYQA
RESULTS/EXPERIMENTS,0.37623762376237624,"1
5
10
15
20
25
30"
RESULTS/EXPERIMENTS,0.3795379537953795,Iteration −7 −6 −5 −4 −3 −2 −1
RESULTS/EXPERIMENTS,0.38283828382838286,median −lo 10
RESULTS/EXPERIMENTS,0.38613861386138615,"(y
−
y min +
ε)"
RESULTS/EXPERIMENTS,0.38943894389438943,Di)c+) 2 dim
RESULTS/EXPERIMENTS,0.3927392739273927,L2O -BB
RESULTS/EXPERIMENTS,0.39603960396039606,Bayesian Optimization
RESULTS/EXPERIMENTS,0.39933993399339934,Random Search
RESULTS/EXPERIMENTS,0.40264026402640263,Bayes Optim
RESULTS/EXPERIMENTS,0.40594059405940597,CMA-ES PSO DE
RESULTS/EXPERIMENTS,0.40924092409240925,BOBYQA
RESULTS/EXPERIMENTS,0.41254125412541254,"1
5
10
15
20
25
30"
RESULTS/EXPERIMENTS,0.4158415841584158,Iteration −7 −6 −5 −4 −3 −2 −1
RESULTS/EXPERIMENTS,0.41914191419141916,median −lo 10
RESULTS/EXPERIMENTS,0.42244224422442245,"(y
−
y min +
ε)"
RESULTS/EXPERIMENTS,0.42574257425742573,Ellip)oidal 2 dim
RESULTS/EXPERIMENTS,0.429042904290429,L2O -BB
RESULTS/EXPERIMENTS,0.43234323432343236,Bayesian Optimization
RESULTS/EXPERIMENTS,0.43564356435643564,Random Search
RESULTS/EXPERIMENTS,0.4389438943894389,Bayes Optim
RESULTS/EXPERIMENTS,0.44224422442244227,CMA-ES PSO DE
RESULTS/EXPERIMENTS,0.44554455445544555,BOBYQA
RESULTS/EXPERIMENTS,0.44884488448844884,"1
5
10
15
20
25
30"
RESULTS/EXPERIMENTS,0.4521452145214521,Iteration −4.0 −3.5 −3.0 −2.5 −2.0 −1.5 −1.0 −0.5
RESULTS/EXPERIMENTS,0.45544554455445546,median −lo 10
RESULTS/EXPERIMENTS,0.45874587458745875,"(y
−
y min +
ε)"
RESULTS/EXPERIMENTS,0.46204620462046203,Rosenbrock 2 dim
RESULTS/EXPERIMENTS,0.46534653465346537,L2O -BB
RESULTS/EXPERIMENTS,0.46864686468646866,Bayesian Optimization
RESULTS/EXPERIMENTS,0.47194719471947194,Random Search
RESULTS/EXPERIMENTS,0.4752475247524752,Bayes Optim
RESULTS/EXPERIMENTS,0.47854785478547857,CMA-ES PSO DE
RESULTS/EXPERIMENTS,0.48184818481848185,BOBYQA
RESULTS/EXPERIMENTS,0.48514851485148514,"1
5
10
15
20
25
30"
RESULTS/EXPERIMENTS,0.4884488448844885,Iteration −2.50 −2.25 −2.00 −1.75 −1.50 −1.25 −1.00 −0.75
RESULTS/EXPERIMENTS,0.49174917491749176,median −log 10
RESULTS/EXPERIMENTS,0.49504950495049505,"(y
−
y min +
ε)"
RESULTS/EXPERIMENTS,0.49834983498349833,Sharp Ridge 2 dim
RESULTS/EXPERIMENTS,0.5016501650165016,L2O -BB
RESULTS/EXPERIMENTS,0.504950495049505,Bayesian Optimization
RESULTS/EXPERIMENTS,0.5082508250825083,Random Search
RESULTS/EXPERIMENTS,0.5115511551155115,Bayes Optim
RESULTS/EXPERIMENTS,0.5148514851485149,CMA-ES PSO DE
RESULTS/EXPERIMENTS,0.5181518151815182,BOBYQA
RESULTS/EXPERIMENTS,0.5214521452145214,"1
5
10
15
20
25
30
35
40
45
50
55
60
65
70
75
80
85
90"
RESULTS/EXPERIMENTS,0.5247524752475248,Iteration −4.0 −3.5 −3.0 −2.5 −2.0 −1.5 −1.0 −0.5
RESULTS/EXPERIMENTS,0.528052805280528,median −log 10
RESULTS/EXPERIMENTS,0.5313531353135313,"(y
−
y min +
ε)"
RESULTS/EXPERIMENTS,0.5346534653465347,A−−+ac−ive Sector 6 dim
RESULTS/EXPERIMENTS,0.5379537953795379,L2O -BB
RESULTS/EXPERIMENTS,0.5412541254125413,Bayesian Optimization
RESULTS/EXPERIMENTS,0.5445544554455446,Random Search
RESULTS/EXPERIMENTS,0.5478547854785478,Bayes Optim
RESULTS/EXPERIMENTS,0.5511551155115512,CMA-ES PSO DE
RESULTS/EXPERIMENTS,0.5544554455445545,BOBYQA
RESULTS/EXPERIMENTS,0.5577557755775577,Under review as a conference paper at ICOMP 2024
RESULTS/EXPERIMENTS,0.5610561056105611,"1
5
10
15
20
25
30
35
40
45
50
55
60
65
70
75
80
85
90"
RESULTS/EXPERIMENTS,0.5643564356435643,Iteration −6 −4 −2 0 2
RESULTS/EXPERIMENTS,0.5676567656765676,median −log 10
RESULTS/EXPERIMENTS,0.570957095709571,"(y
−
y min +
ε)"
RESULTS/EXPERIMENTS,0.5742574257425742,Bent Cigar 6  im
RESULTS/EXPERIMENTS,0.5775577557755776,L2O -BB
RESULTS/EXPERIMENTS,0.5808580858085809,Bayesian Optimization
RESULTS/EXPERIMENTS,0.5841584158415841,Random Search
RESULTS/EXPERIMENTS,0.5874587458745875,Bayes Optim
RESULTS/EXPERIMENTS,0.5907590759075908,CMA-ES PSO DE
RESULTS/EXPERIMENTS,0.594059405940594,BOBYQA
RESULTS/EXPERIMENTS,0.5973597359735974,"1
5
10
15
20
25
30
35
40
45
50
55
60
65
70
75
80
85
90"
RESULTS/EXPERIMENTS,0.6006600660066007,Iteration −2.0 −1.5 −1.0 −0.5 0.0 0.5 1.0 1.5
RESULTS/EXPERIMENTS,0.6039603960396039,median −log 10
RESULTS/EXPERIMENTS,0.6072607260726073,"(y
−
y min +
ε)"
RESULTS/EXPERIMENTS,0.6105610561056105,Differe)t Power− 6 di(
RESULTS/EXPERIMENTS,0.6138613861386139,L2O -BB
RESULTS/EXPERIMENTS,0.6171617161716172,Bayesian Optimization
RESULTS/EXPERIMENTS,0.6204620462046204,Random Search
RESULTS/EXPERIMENTS,0.6237623762376238,Bayes Optim
RESULTS/EXPERIMENTS,0.6270627062706271,CMA-ES PSO DE
RESULTS/EXPERIMENTS,0.6303630363036303,BOBYQA
RESULTS/EXPERIMENTS,0.6336633663366337,"1
5
10
15
20
25
30
35
40
45
50
55
60
65
70
75
80
85
90"
RESULTS/EXPERIMENTS,0.636963696369637,Iteration −7 −6 −5 −4 −3 −2
RESULTS/EXPERIMENTS,0.6402640264026402,median −log 10
RESULTS/EXPERIMENTS,0.6435643564356436,"(y
−
y min +
ε)"
RESULTS/EXPERIMENTS,0.6468646864686468,Di+c−+ 6  im
RESULTS/EXPERIMENTS,0.6501650165016502,L2O -BB
RESULTS/EXPERIMENTS,0.6534653465346535,Bayesian Optimization
RESULTS/EXPERIMENTS,0.6567656765676567,Random Search
RESULTS/EXPERIMENTS,0.6600660066006601,Bayes Optim
RESULTS/EXPERIMENTS,0.6633663366336634,CMA-ES PSO DE
RESULTS/EXPERIMENTS,0.6666666666666666,BOBYQA
RESULTS/EXPERIMENTS,0.66996699669967,"1
5
10
15
20
25
30
35
40
45
50
55
60
65
70
75
80
85
90"
RESULTS/EXPERIMENTS,0.6732673267326733,Iteration −7.0 −6.5 −6.0 −5.5 −5.0 −4.5 −4.0 −3.5
RESULTS/EXPERIMENTS,0.6765676567656765,median −log 10
RESULTS/EXPERIMENTS,0.6798679867986799,"(y
−
y min +
ε)"
RESULTS/EXPERIMENTS,0.6831683168316832,Ellips)idal 6 dim
RESULTS/EXPERIMENTS,0.6864686468646864,L2O -BB
RESULTS/EXPERIMENTS,0.6897689768976898,Bayesian Optimization
RESULTS/EXPERIMENTS,0.693069306930693,Random Search
RESULTS/EXPERIMENTS,0.6963696369636964,Bayes Optim
RESULTS/EXPERIMENTS,0.6996699669966997,CMA-ES PSO DE
RESULTS/EXPERIMENTS,0.7029702970297029,BOBYQA
RESULTS/EXPERIMENTS,0.7062706270627063,"1
5
10
15
20
25
30
35
40
45
50
55
60
65
70
75
80
85
90"
RESULTS/EXPERIMENTS,0.7095709570957096,Iteration −5.5 −5.0 −4.5 −4.0 −3.5 −3.0 −2.5 −2.0
RESULTS/EXPERIMENTS,0.7128712871287128,median −log 10
RESULTS/EXPERIMENTS,0.7161716171617162,"(y
−
y min +
ε)"
RESULTS/EXPERIMENTS,0.7194719471947195,R+senb−+ck 6 dim
RESULTS/EXPERIMENTS,0.7227722772277227,L2O -BB
RESULTS/EXPERIMENTS,0.7260726072607261,Bayesian Optimization
RESULTS/EXPERIMENTS,0.7293729372937293,Random Search
RESULTS/EXPERIMENTS,0.7326732673267327,Bayes Optim
RESULTS/EXPERIMENTS,0.735973597359736,CMA-ES PSO DE
RESULTS/EXPERIMENTS,0.7392739273927392,BOBYQA
RESULTS/EXPERIMENTS,0.7425742574257426,"1
5
10
15
20
25
30
35
40
45
50
55
60
65
70
75
80
85
90"
RESULTS/EXPERIMENTS,0.7458745874587459,Iteration −3.0 −2.5 −2.0 −1.5 −1.0 −0.5
RESULTS/EXPERIMENTS,0.7491749174917491,median −log 10
RESULTS/EXPERIMENTS,0.7524752475247525,"(y
−
y min +
ε)"
RESULTS/EXPERIMENTS,0.7557755775577558,Sha+p Ridge 6 dim
RESULTS/EXPERIMENTS,0.759075907590759,L2O -BB
RESULTS/EXPERIMENTS,0.7623762376237624,Bayesian Optimization
RESULTS/EXPERIMENTS,0.7656765676567657,Random Search
RESULTS/EXPERIMENTS,0.768976897689769,Bayes Optim
RESULTS/EXPERIMENTS,0.7722772277227723,CMA-ES PSO DE
RESULTS/EXPERIMENTS,0.7755775577557755,BOBYQA
CONCLUSION/DISCUSSION,0.7788778877887789,"5
DISCUSSION AND LIMITATIONS"
CONCLUSION/DISCUSSION,0.7821782178217822,Our experiments revealed several important insights:
CONCLUSION/DISCUSSION,0.7854785478547854,"1. Random search, as expected, does not perform well due to its lack of guided exploration."
CONCLUSION/DISCUSSION,0.7887788778877888,"2. The performance variation in Bayesian optimization models is due to differences in imple-
mentation and hyperparameters, demonstrating a limitation of theory-driven approaches."
CONCLUSION/DISCUSSION,0.7920792079207921,"3. BOBYQA excels on unimodal functions, likely due to its utilization of quadratic approxi-
mations to efficiently model the local search space."
CONCLUSION/DISCUSSION,0.7953795379537953,"When training Learning to Optimize (L2O) models, having gradients of the black box functions
is essential. These gradients are crucial for the optimization process within the L2O framework.
However, obtaining gradients directly from black box functions is challenging. The solutions to this
problem lie in function approximation or gradient approximation."
CONCLUSION/DISCUSSION,0.7986798679867987,"6
FUTURE WORKS"
CONCLUSION/DISCUSSION,0.801980198019802,"In this section, we discuss potential future research directions to further enhance Learning to Opti-
mize (L2O) methods, particularly focusing on global optimization and the generalization problem."
CONCLUSION/DISCUSSION,0.8052805280528053,Under review as a conference paper at ICOMP 2024
CONCLUSION/DISCUSSION,0.8085808580858086,"• Gradient Approximation in Black Box Optimization: Developing effective methods
for approximating gradients in black box functions remains a critical challenge. Future
research could explore advanced techniques for gradient approximation, such as using sur-
rogate models or leveraging ensemble methods to estimate gradients more accurately.
• Global Optimization Variants: Enhancing L2O models for global optimization could
involve designing different strategies for the initial and final stages of the optimization
process. For instance, an adaptive approach that employs more exploratory methods at the
beginning and more exploitative methods towards the end could be beneficial.
• Generalization and Transfer Learning: Improving the generalization capabilities of L2O
algorithms is essential for their application to a wider range of problems. Research could
focus on transfer learning techniques that allow models trained on certain types of optimiza-
tion problems to be effectively adapted to new, unseen problems (Wolpert & Macready,
1997).
• Exploiting Exploratory Landscape Analysis (ELA) Features: Incorporating ELA fea-
tures into the L2O framework can provide valuable insights into the structure of optimiza-
tion problems. This could guide the learning process and improve the efficiency and ro-
bustness of the optimization algorithms.
• Learning from Optimization Trajectories: Analyzing and learning from optimization
trajectories can offer insights into the optimization process and help in refining L2O mod-
els. Future work could involve creating methods that leverage historical optimization data
to inform and improve current optimization strategies."
CONCLUSION/DISCUSSION,0.8118811881188119,"These research directions highlight the potential for further advancements in the field of Learning to
Optimize, aiming to make optimization algorithms more efficient, robust, and generalizable across
diverse optimization problems."
REFERENCES,0.8151815181518152,REFERENCES
REFERENCES,0.8184818481848185,"Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoffman, David Pfau, Tom Schaul,
Brendan Shillingford, and Nando De Freitas. Learning to learn by gradient descent by gradient
descent. Advances in neural information processing systems, 29, 2016."
REFERENCES,0.8217821782178217,"Pauline Bennet, Carola Doerr, Antoine Moreau, Jeremy Rapin, Fabien Teytaud, and Olivier Teytaud.
Nevergrad: black-box optimization platform. ACM SIGEVOlution, 14(1):8–15, 2021."
REFERENCES,0.8250825082508251,"Xiangning Chen, Chen Liang, Da Huang, Esteban Real, Kaiyuan Wang, Hieu Pham, Xuanyi Dong,
Thang Luong, Cho-Jui Hsieh, Yifeng Lu, et al. Symbolic discovery of optimization algorithms.
Advances in neural information processing systems, 36, 2024."
REFERENCES,0.8283828382838284,"Yutian Chen, Matthew W Hoffman, Sergio G´omez Colmenarejo, Misha Denil, Timothy P Lilli-
crap, Matt Botvinick, and Nando Freitas. Learning to learn without gradient descent by gradient
descent. In International Conference on Machine Learning, pp. 748–756. PMLR, 2017."
REFERENCES,0.8316831683168316,"Nikolaus Hansen and Andreas Ostermeier. Completely derandomized self-adaptation in evolution
strategies. Evolutionary computation, 9(2):159–195, 2001."
REFERENCES,0.834983498349835,"Nikolaus Hansen, Anne Auger, Raymond Ros, Olaf Mersmann, Tea Tuˇsar, and Dimo Brockhoff.
Coco: A platform for comparing continuous optimizers in a black-box setting. Optimization
Methods and Software, 36(1):114–144, 2021."
REFERENCES,0.8382838283828383,"Sepp Hochreiter and J¨urgen Schmidhuber. Long short-term memory. Neural computation, 9(8):
1735–1780, 1997."
REFERENCES,0.8415841584158416,"James Kennedy and Russell Eberhart. Particle swarm optimization. In Proceedings of ICNN’95-
international conference on neural networks, volume 4, pp. 1942–1948. ieee, 1995."
REFERENCES,0.8448844884488449,"Ke Li and Jitendra Malik. Learning to optimize neural nets. arXiv preprint arXiv:1703.00441, 2017."
REFERENCES,0.8481848184818482,"Olaf Mersmann, Bernd Bischl, Heike Trautmann, Mike Preuss, Claus Weihs, and G¨unter Rudolph.
Exploratory landscape analysis. In Proceedings of the 13th annual conference on Genetic and
evolutionary computation, pp. 829–836, 2011."
REFERENCES,0.8514851485148515,Under review as a conference paper at ICOMP 2024
REFERENCES,0.8547854785478548,"Martin Pelikan and Martin Pelikan. Bayesian optimization algorithm. Hierarchical Bayesian opti-
mization algorithm: toward a new generation of evolutionary algorithms, pp. 31–48, 2005."
REFERENCES,0.858085808580858,"Vladimir Stanovov, Shakhnaz Akhmedova, and Eugene Semenkin. The automatic design of parame-
ter adaptation techniques for differential evolution with genetic programming. Knowledge-Based
Systems, 239:108070, 2022."
REFERENCES,0.8613861386138614,"Rainer Storn and Kenneth Price. Differential evolution–a simple and efficient heuristic for global
optimization over continuous spaces. Journal of global optimization, 11:341–359, 1997."
REFERENCES,0.8646864686468647,"Vishnu TV, Pankaj Malhotra, Jyoti Narwariya, Lovekesh Vig, and Gautam Shroff. Meta-learning
for black-box optimization. In Joint European Conference on Machine Learning and Knowledge
Discovery in Databases, pp. 366–381. Springer, 2019."
REFERENCES,0.8679867986798679,"Eugene Vorontsov, Chiheb Trabelsi, Samuel Kadoury, and Chris Pal. On orthogonality and learn-
ing recurrent networks with long term dependencies. In International Conference on Machine
Learning, pp. 3570–3578. PMLR, 2017."
REFERENCES,0.8712871287128713,"David H Wolpert and William G Macready. No free lunch theorems for optimization. IEEE trans-
actions on evolutionary computation, 1(1):67–82, 1997."
OTHER,0.8745874587458746,"A
NEVERGRAD OPTIMIZERS"
OTHER,0.8778877887788779,"• Random Search: ng.optimizers.RandomSearch
• BOBYQA: ng.optimizers.BOBYQA
• Covariance matrix adaptation evolution strategy (CMA): ng.optimizers.CMAbounded
• Bayesian Optimization (BayesOptimBO): ng.optimizers.BayesOptimBO
• Bayesian Optimization (BO): ng.optimizers.BO
• Differential Evolution (DE): ng.optimizers.DE
• Particle Swarm Optimization (PSO): ng.optimizers.PSO"
OTHER,0.8811881188118812,"B
FUNCTIONS"
OTHER,0.8844884488448845,"B.1
DEFINITIONS"
OTHER,0.8877887788778878,"xopt ∼U(−5, 5)
c1 ∼10 × U(0, 1)"
OTHER,0.8910891089108911,Tosz(x) = sign(x) exp (log(|x|) + 0.049 (sin(c1 log(|x|)) + sin(c2 log(|x|))))
OTHER,0.8943894389438944,where:
OTHER,0.8976897689768977,"• c1 = 10 if x > 0, else 5.5
• c2 = 7.9 if x > 0, else 3.1"
OTHER,0.900990099009901,"Tasy(x) = x + β

i
D −1"
OTHER,0.9042904290429042,"
1
D−1 p"
OTHER,0.9075907590759076,"max(x, 0)"
OTHER,0.9108910891089109,where β is a hyperparameter and i is the index of the element in x.
OTHER,0.9141914191419142,"B.2
ELLIPSOIDAL"
OTHER,0.9174917491749175,"f(x) = D
X"
OTHER,0.9207920792079208,"i=1
106(
i
D−1) (Tosz(xi −xopt,i))2"
OTHER,0.9240924092409241,Under review as a conference paper at ICOMP 2024
OTHER,0.9273927392739274,"B.3
DISCUS"
OTHER,0.9306930693069307,"f(x) = 106(Tosz(x1 −xopt,1))2 + D
X"
OTHER,0.933993399339934,"i=2
(Tosz(xi −xopt,i))2"
OTHER,0.9372937293729373,"B.4
BENT SIGAR"
OTHER,0.9405940594059405,"f(x) = 106(Tasy(x1 −xopt,1))2 + D
X"
OTHER,0.9438943894389439,"i=2
(Tasy(xi −xopt,i))2"
OTHER,0.9471947194719472,"B.5
ATTRACTIVE"
OTHER,0.9504950495049505,"f(x) = D
X"
OTHER,0.9537953795379538,"i=1
si(xi −xopt,i)2
!0.9"
OTHER,0.9570957095709571,where:
OTHER,0.9603960396039604,"• si = 100 if xixopt,i > 0, else si = 1"
OTHER,0.9636963696369637,"B.6
ROSENBROCK"
OTHER,0.966996699669967,"f(x) = D−1
X i=1"
OTHER,0.9702970297029703,"
100(xi+1 −x2
i )2 + (xi −1)2"
OTHER,0.9735973597359736,"B.7
DIFFERENT POWERS"
OTHER,0.976897689768977,f(x) =
OTHER,0.9801980198019802,"v
u
u
t D
X"
OTHER,0.9834983498349835,"i=1
|xi|2+4 i−1 D−1"
OTHER,0.9867986798679867,"B.8
SHARP RIDGE"
OTHER,0.9900990099009901,"f(x) = x2
1 + 100"
OTHER,0.9933993399339934,"v
u
u
t D
X"
OTHER,0.9966996699669967,"i=2
x2
i"
