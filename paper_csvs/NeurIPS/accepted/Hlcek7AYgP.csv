Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.003205128205128205,"Aligning neural dynamics with movements is a fundamental goal in neuroscience
and brain-machine interfaces. However, there is still a lack of dimensionality
reduction methods that can effectively align low-dimensional latent dynamics with
movements. To address this gap, we propose Neural Embeddings Rank (NER), a
technique that embeds neural dynamics into a 3D latent space and contrasts the
embeddings based on movement ranks. NER learns to regress continuous represen-
tations of neural dynamics (i.e., embeddings) on continuous movements. We apply
NER and six other dimensionality reduction techniques to neurons in the primary
motor cortex (M1), dorsal premotor cortex (PMd), and primary somatosensory
cortex (S1) as monkeys perform reaching tasks. Only NER aligns latent dynamics
with both hand position and direction, visualizable in 3D. NER reveals consistent
latent dynamics in M1 and PMd across sixteen sessions over a year. Using a linear
regression decoder, NER explains 86% and 97% of the variance in velocity and
position, respectively. Linear models trained on data from one session successfully
decode velocity, position, and direction in held-out test data from different dates
and cortical areas (64%, 88%, and 90%). NER also reveals distinct latent dynamics
in S1 during consistent movements and in M1 during curved reaching tasks. The
code is available at https://github.com/NeuroscienceAI/NER."
INTRODUCTION,0.00641025641025641,"1
Introduction"
INTRODUCTION,0.009615384615384616,"It has long been thought that individual neurons in the motor and premotor cortex, similar to those
in the sensory cortex, are tuned to specific movement parameters such as direction. However, this
static and receptive field-based neural representation fails to explain movement trajectories during
simple tasks like reaching. Recent studies have found that the activities of multiple simultaneously
recorded neurons, which fire spikes in a time-dependent manner, encode reaching movements [10].
Unlike the one-dimensional dynamics from a single neuron, understanding how movements are
represented by these high-dimensional neural dynamics is challenging. In systems neuroscience and
brain-machine interfaces, there is significant motivation to reduce these high-dimensional neural
dynamics to low-dimensional latent dynamics for at least three reasons:"
INTRODUCTION,0.01282051282051282,"First, visualizing neural dynamics. This involves a trade-off between dimensionality and explained
variance. To explain a complex reaching task, at least six dimensions are typically required. For
example, in an eight-direction center-out reaching task, [11][9][12] selects fifteen dimensions for the
PMd, ten for the M1, and eight for the S1. Therefore, we need to further reduce the dimensionality of
these “low-dimensional” latent dynamics. Currently, we still lack a method that can directly explain
enough variance within three dimensions. Second, comparing movements-related latent dynamics.
After dimensionality reduction, we can visualize the trajectories of latent dynamics over time. For
instance, [5] reveals rotational latent dynamics during reaching tasks using principal component
analysis (PCA). [25] found that animals performing similar tasks exhibit similar latent dynamics."
INTRODUCTION,0.016025641025641024,"However, these trajectories do not align precisely with the reaching movements: when the hand
reaches in eight directions, the trajectories of latent dynamics are neither in eight distinct directions
nor well-separated, often appearing entangled. Third, decoding movements using latent dynamics.
Decoders trained on individual neural activities are commonly used to predict movements [13].
However, a drawback of using individual neural activities is that when the identities of neurons
change during long-term recordings, the decoding performance deteriorates [9]. Additionally, it is
infeasible to decode movements from different brain areas or animals. Decoders trained on latent
dynamics facilitate long-term and cross-animal decoding [9, 25]. Since latent dynamics do not
fully capture neural dynamics, decoding performance is often suboptimal with linear decoders,
necessitating the use of nonlinear decoders or deep neural networks [25]. Thus, decoding movements
using a linear decoder without hyperparameters remains a significant challenge."
INTRODUCTION,0.019230769230769232,"As our goal is to extract latent dynamics that are most informative about movements, we chose to
train the latent dynamics using movements as the target. Several recent studies have trained latent
dynamics to classify different movement directions or positions using variational autoencoders (VAE)
[32][14][18] or contrastive learning [27][1]. In this paper, we are inspired by the fact that many
features, including movements, are continuous, and that the function of many biological neurons is
not classification but regression. For example, neurons exhibit monotonic tuning to light intensity and
sound levels [2][24]. Even for discrete features like faces, face cells exhibit ramp-shaped tuning to
different features[8]. Additionally, 75% of faces could be correctly decoded using a linear regression
decoder[4]. Thus, we trained latent dynamics to regress movement by minimizing the ranking loss."
INTRODUCTION,0.022435897435897436,"We are motivated by the fact that CEBRA treats continuous labels as many discrete classes, which
cannot be well separated in low-dimensional space. These classes are also highly imbalanced,
with many more near-zero classes (Fig. 1a)."
INTRODUCTION,0.02564102564102564,Our two main contributions are as follows:
INTRODUCTION,0.028846153846153848,"We introduce Neural Embeddings Rank (NER), a dimensionality reduction method that contrasts
paired samples in the embedding space and ranks neural embeddings to align them with continuous
movement labels (Fig. 1b). Without introducing additional hyperparameters and using the same
inputs, NER addresses the high dimensionality and class imbalance issues present in CEBRA."
INTRODUCTION,0.03205128205128205,"We demonstrate that NER reveals behavior-aligned latent dynamics in all twenty sessions from three
different brain areas in three monkeys. The trajectories of latent dynamics vary across different
behaviors. We show that all movement parameters (directions, velocities, and positions) can be
decoded using linear decoders trained on data from one session, tested on data from different dates
over one year, and across different brain areas and hemispheres."
INTRODUCTION,0.035256410256410256,"Δt ≈ “augmentation” Y X
a
b"
INTRODUCTION,0.038461538461538464,vel. (cm/s)
INTRODUCTION,0.041666666666666664,pred. (cm/s) 0 200 -200 CEBRA NER
ST,0.04487179487179487,"1st
2nd
3rd
label dist. w.r.t. anchor"
ST,0.04807692307692308,continuous label
ST,0.05128205128205128,rank emb. w.r.t. label
ST,0.05448717948717949,1 P. Pair    4 N. Pair
ST,0.057692307692307696,1 P. Pair    3 N. Pair
ST,0.060897435897435896,1 P. Pair    3 N. Pair
ST,0.0641025641025641,1 P. Pair    2 N. Pair
ST,0.0673076923076923,1 P. Pair    1 N. Pair
ST,0.07051282051282051,1 P. Pair    0 N. Pair
ST,0.07371794871794872,vel. (cm/s)
ST,0.07692307692307693,"-200
200"
ST,0.08012820512820513,anchor vi
ST,0.08333333333333333,"negative vk 
positive vj 
t
same label t+Δt"
ST,0.08653846153846154,"positive vj 
negative vn CEBRA NER 0 200 -200 0 200 -200"
ST,0.08974358974358974,"Figure 1: a Top: Hand velocities of X-Y coordinates across three trials. Note that the distribution of
velocities is highly imbalanced, with many near-zero values. Bottom: Real (X-axis) versus predicted
(Y-axis) Y-coordinate hand velocities using a linear regressor. The predicted velocities in CEBRA are
much smaller than those in NER, as CEBRA mispredicts infrequent large velocities as frequent small
velocities. b Batch size is three (in real experiments, it is 512), with two batches (one for vi and one
for vj and vk) combined in NER. Both models use embeddings within a specific time offset (e.g., 10
ms) of the anchor as the augmented embedding, which shares the same label/color as the anchor."
ST,0.09294871794871795,Ours: NER
ST,0.09615384615384616,"Hand positions/
velocities & directions"
ST,0.09935897435897435,Aligned latent
ST,0.10256410256410256,dynamics
ST,0.10576923076923077,"Decoder
Decoded velocities/
positions & directions
Neural to latent"
ST,0.10897435897435898,dynamics
ST,0.11217948717948718,Train 80%
ST,0.11538461538461539,M1 same day
YEAR LATER,0.11858974358974358,1 year later
YEAR LATER,0.12179487179487179,contra. M1
YEAR LATER,0.125,ipsi. PMd
YEAR LATER,0.1282051282051282,Test 20% Time 1 2 199 200 S1
YEAR LATER,0.13141025641025642,"M1 M1
PMd"
YEAR LATER,0.1346153846153846,neuron
YEAR LATER,0.13782051282051283,"latent 1
2
3 same day high low 0 90 180 270"
YEAR LATER,0.14102564102564102,"a
b
c
d
e"
YEAR LATER,0.14423076923076922,Latent dynamics
YEAR LATER,0.14743589743589744,"velocities
directions 1 2 3"
YEAR LATER,0.15064102564102563,CEBRA & piVAE
YEAR LATER,0.15384615384615385,"Figure 2: NER aligns 3D latent dynamics with movements and enabling cross sessions movement
decoding. a Top: The monkey performs a center-out reaching task in eight directions using a planar
manipulandum. Hand velocity is computed from hand position. Bottom: The monkey moves the
cursor to outer targets to receive rewards (image from [23]). b Top: Neural dynamics are recorded
using a 96-channel Utah array in two monkeys. Monkey C has implants in the M1 of the right
hemisphere first and in M1 and PMd of the left hemisphere second. Monkey L has an implant
in area 2 of the S1 of the left hemisphere (image from brainmuseum.org). During the task, all
monkeys use the hand contralateral to the implanted hemisphere. Bottom: Spiking activities from
multiple neurons (44 to 211) are recorded during multiple trials (168 to 1038) of the behavioral task.
Dimensionality reduction reduces 200-dimensional neural dynamics to 3D latent dynamics. c Top:
Neural dynamics from 190 dimensions (neurons) in the PMd are reduced to 3D latent dynamics.
Bottom: Trial-averaged latent dynamics. Data is from Monkey C (date: 2016-10-14). d Top: Linear
and logistic regression decoders are trained on the same independent variables (latent dynamics)
but different dependent variables (hand velocities and directions) using 80% of train data. Bottom:
The trained decoder from 80% of train data is used to predict movements on the 20% held-out test
data. The model trained on one day predicts movements across one year, in the contralateral M1, and
ipsilateral PMd. e Top: Two linear decoders trained from c decode hand velocities (positions) and
directions with R-squared accuracy of 86% (96%) and peak accuracy of 97%, respectively, on the 20%
held-out test data. Bottom: Decoders trained on the same day (diagonal) have much better decoding
performance than models trained on different conditions (off-diagonal) using previous dimensionality
reduction methods, whereas our method has higher and consistent decoding performance."
RELATED WORK,0.15705128205128205,"2
Related work"
RELATED WORK,0.16025641025641027,"There are at least five categories of dimensionality reduction methods: Linear methods, such as PCA,
jPCA [5], demixed PCA (dPCA) [16], and preferential subspace identification (PSID) [26]. PCA
captures the majority of variance in the data, jPCA reveals rotational dynamics in monkey reaching,
dPCA highlights task-related components, and PSID extracts latent dynamics that predict motion
during reach versus return epochs. Nonlinear methods like uniform manifold approximation and
projection (UMAP) [19] and t-distributed stochastic neighbor embedding (tSNE) [28] are extensively
used in biological data, such as for identifying neuron cell types [17]. These methods reveal identities
but often collapse temporal dynamics that resemble neural trajectories. UMAP with labels has been
applied for dimensionality reduction in recent studies [27, 32]. Generative methods using recurrent
neural networks or Transformers, such as latent factor analysis via dynamical systems (LFADS)
[21], AutoLFADS [15], RADICaL [33], and Neural Data Transformer (NDT) [30]. These methods
model single-trial variability in neural spiking activity better than PCA, though they often require
explicit assumptions about underlying data statistics. Label-guided generative methods using VAEs,
including Poisson identifiable VAE (piVAE) [32], SwapVAE [18], and targeted neural dynamical
modeling (TNDM) [14]. For example, piVAE uses both discrete and continuous labels to shape
embeddings, revealing well-separated but less movement-aligned embeddings. Contrastive learning
methods, introduced to learn robust, generalizable representations of neural population dynamics,"
RELATED WORK,0.16346153846153846,"such as CEBRA [27] and Mine Your Own view (MYOW) [1]. Compared to piVAE, AutoLFADS,
and UMAP, CEBRA provides more identifiable latent dynamics corresponding to different hand
directions in S1, although these latent dynamics trajectories do not correlate well with movements."
MODEL,0.16666666666666666,"3
Model"
MODEL,0.16987179487179488,"NER is inspired by previous studies [31] and uses the same data sampling and neural feature encoder
as CEBRA [27] to extract neural embeddings. Fig. 1b illustrates the difference between NER and
CEBRA. CEBRA treats each embedding in a batch as a discrete class. For an anchor, it contrasts
with its augmented embedding as a positive pair and three randomly sampled embeddings as negative
pairs. NER, on the other hand, ranks six embeddings according to their continuous labels. It contrasts
an anchor with its augmented or first embedding as a positive pair and the remaining four embeddings
as negative pairs. NER continues by contrasting the second embedding as a positive pair and the
remaining three embeddings as negative pairs. This process repeats until all embeddings have been
positively contrasted with the anchor. NER learns a regression-aware representation that orders all
embeddings in a batch."
MODEL,0.17307692307692307,"Mathematically, we define x as the high-dimensional neural dynamics, f as the feature encoder,
and v = f(x) as the low-dimensional neural embeddings. The batch size N is set to 512, and the
temperature τ is fixed at 1. Data augmentation in both CEBRA and NER is achieved by selecting
embeddings whose labels fall within a specific offset (e.g., 10 ms) of the anchor’s label. Note that we
did not fine-tune the temperature and offset, as the only difference between CEBRA and NER is the
loss function. The selection of these hyperparameters will have a similar effect on both models."
MODEL,0.1762820512820513,"In each iteration, CEBRA receives one batch of anchors vi, one batch of embeddings vj that will
positively contrast with the anchors, and a third batch of randomly sampled embeddings vn that will
negatively contrast with the anchors. The anchor loss l in CEBRA is:"
MODEL,0.1794871794871795,"l(i)
CEBRA = −log
exp(sim(vi, vj)/τ)
P Nn=1exp(sim(vi, vn)/τ)"
MODEL,0.18269230769230768,"where sim(·, ·) represents the similarity between two neural embeddings (e.g., negative L2)."
MODEL,0.1858974358974359,"In each iteration, NER receives one batch of anchors vi, one batch of augmented embeddings vj, vk
that will either positively or negatively contrast with an anchor, and a third batch of labels y. The
anchor loss l in NER is:"
MODEL,0.1891025641025641,"l(i)
NER =
1
2N −1"
MODEL,0.19230769230769232,"X
2N j=1,j̸=i −log
exp(sim(vi, vj)/τ)
P
vk∈Si,j exp(sim(vi, vk)/τ)"
MODEL,0.1955128205128205,"There are two key differences from CEBRA. First, batches of vi and vj, vk are merged, and labels
y are duplicated, resulting in a batch of 2N for both embeddings and labels. This ensures that
each anchor and its augmented embedding exist within the same batch. Second, we introduce
Si,j := {vk | k ̸= i, d(yi, yk) ≥d(yi, yj)} to denote the set of embeddings vk that are of lower
ranks than vj in terms of label distance relative to vi, where d(·, ·) is the distance measure between
two labels (e.g., L1). Intuitively, for an anchor vi, any other embedding vj in the batch is positively
contrasted with it, enforcing the similarity between vi and vj to be greater than that between vi and
any other embedding vk in the batch if the label distance between yi and yk is larger than that of
yi and yj. Minimizing l(i)
NER aligns the order of embeddings with their corresponding label orders
relative to the anchor."
MODEL,0.1987179487179487,"By ranking all the embeddings within a batch, NER also addresses the class imbalance issue and
effectively represents infrequent classes (Fig. 1a). In each batch, a small percentage (e.g., 5%) of
embeddings may come from infrequent classes, such as large velocities. In CEBRA, only a single
augmented embedding is positively contrasted with its anchor, so only 5% of anchors have access to
these infrequent embeddings. In NER, all 2N −1 embeddings can contrast with an anchor, allowing
100% of anchors to access the 5% of infrequent embeddings."
RESULTS,0.20192307692307693,"4
Results"
RESULTS,0.20512820512820512,"To fairly evaluate our dimensionality reduction method against related approaches, we selected six
representative methods from various categories: PCA, dPCA, UMAP (with and without labels),"
RESULTS,0.20833333333333334,"piVAE, and CEBRA. To avoid bias from a single session in a specific brain area, where piVAE and
CEBRA were previously tested, we conducted experiments across M1, PMd, and S1, covering a total
of twenty sessions (Table 1). Statistical results for each comparison are provided (Table 2). Figure 2
illustrates the pipeline of this study. We primarily used linear decoders, and additionally included
nonlinear k-nearest neighbors (kNN) decoder. To maintain consistency with movement decoding in
the original CEBRA paper, we used a 16-dimensional (16D) CEBRA model, which has a stronger
representation capacity and demonstrates better performance than the 3D model in kNN decoder."
RESULTS,0.21153846153846154,"4.1
Movement-aligned latent dynamics were consistent over years in M1"
RESULTS,0.21474358974358973,"Across all ten sessions in the left and right hemispheres of M1, NER consistently revealed neural
embeddings that aligned with movement (Fig.3a, Fig.9a). Notably, during the initial movement stage,
the latent dynamics converged on the same starting points, forming a pinwheel structure resembling
the ground truth movements. Furthermore, we observed nearly identical neural embeddings in both
hemispheres, even when data collection was separated by over a year."
RESULTS,0.21794871794871795,"a
2016-09-29
2016-10-06
2016-10-14
2016-10-21 NER CEBRA piVAE c b"
RESULTS,0.22115384615384615,"2015-03-13
2015-03-19"
RESULTS,0.22435897435897437,"M1 in Left Hemisphere
M1 in Right Hemisphere"
RESULTS,0.22756410256410256,"Figure 3: NER reveals consistent, movement-aligned latent dynamics in M1. a Single-trial (top) and
averaged (bottom) latent dynamics from six sessions across one year in two hemispheres. Latent
dynamics are rotated with reference to the 2016-10-14 session, using one of the eight reaching
directions. b-c Similar to a but using CEBRA and piVAE. Fig. 9 shows the latent dynamics from the
remaining four sessions for the same monkey. Fig. 10 displays single-trial and/or averaged latent
dynamics revealed by five other methods. Fig. 11 shows trial-averaged latent dynamics before rotation.
Fig. 12 presents the entangled neural embeddings using PCA and the time-stimulus components
revealed by dPCA."
RESULTS,0.23076923076923078,"CEBRA was the second-best method, uncovering comparable latent dynamics with both directions
and positions roughly aligned with movements for both single and averaged embeddings (Fig.3b,
Fig.9b). However, CEBRA had two limitations: the movement starting points were widely separated,"
RESULTS,0.23397435897435898,"differing from ground truth movements, and its latent dynamics were less consistent across sessions.
For example, it only revealed connected latent dynamics at movement starting points in two sessions."
RESULTS,0.23717948717948717,"piVAE ranked third, displaying direction-aligned latent dynamics in different directions with relatively
separated single-trial neural embeddings (Fig.3c, Fig.9c). However, while correlated with movements,
the latent dynamics were not aligned with them and were less consistent across sessions. UMAP with
labels showed clearly clustered neural embeddings corresponding to different angles, while UMAP
without labels produced extended, less clustered latent dynamics (Fig. 10). Both methods failed to
generate aligned and consistent latent dynamics. PCA and dPCA also generated identifiable latent
dynamics (Fig.10), with dPCA revealing both time and stimulus components. However, a major
limitation of both methods was the mixing of single-trial neural embeddings (Fig.10)."
RESULTS,0.2403846153846154,"In summary, NER proved to be the best method for revealing movement-aligned latent dynamics. We
further evaluated its performance in PMd and S1, leveraging these aligned latent dynamics to decode
movements within and across sessions and to explore movement-specific latent dynamics."
RESULTS,0.24358974358974358,"4.2
Explained variance of movements using linear decoders in M1, PMd, and S1"
RESULTS,0.2467948717948718,"Five dimensionality reduction methods were used to reveal single-trial latent dynamics that depended
on movements. We then used these latent dynamics as independent variables to explain the variance
of dependent variables, namely, hand velocities, directions, and positions."
RESULTS,0.25,"Fig. 4a shows the ground truth and predicted hand movement trajectories using latent dynamics
revealed by NER in PMd. A linear regression decoder explained 90% and 98% of the variance in
hand velocities and positions, respectively. a
b c
d NER"
RESULTS,0.2532051282051282,Directions and X-Y velocities
RESULTS,0.2564102564102564,"Velocities
Positions"
RESULTS,0.25961538461538464,"Hand movements
Explained movements"
RESULTS,0.26282051282051283,"piVAE
UMAP w/ label"
RESULTS,0.266025641025641,"X-vel
UMAP w/o label CEBRA Y-vel"
RESULTS,0.2692307692307692,"M1
M1
PMd
PMd
S1
S1"
RESULTS,0.2724358974358974,"Figure 4: Explained variance of movements in M1, PMd, and S1. a Left: Hand movement trajectories.
Right: Predicted trajectories by two decoders. Data collected from PMd on 2016-10-14. The
explained variance for velocities and positions is 90% and 98%, respectively. b Hand direction
classification accuracy using a logistic regression decoder. Shaded areas represent the standard
deviation across six sessions from M1. c Explained variance of hand velocities using a linear
regression decoder on latent dynamics revealed by five dimensionality reduction methods (indicated
by different colors and shapes). The X-axis shows session dates. Left: Ten sessions from the M1
of Monkey C. Right: Six sessions from PMd of Monkey C and four sessions from S1 of Monkey
H. d Similar to c but for hand positions. Fig. 13 provides the direction tuning curve in PMd, the
correlation between tuning curves and velocities, and explained variance for directions."
RESULTS,0.27564102564102566,"In both M1 and PMd (Fig.4b, Fig.13a), a logistic regression decoder revealed the tuning of directional
accuracy from the start of the go cue to the end of the animal’s reach. This tuning curve was highly"
RESULTS,0.27884615384615385,"correlated with hand velocities in the latent dynamics extracted by NER but not by CEBRA (M1:
0.93 vs. 0.28, PMd: 0.93 vs. 0.13; Fig. 13b)."
RESULTS,0.28205128205128205,"NER outperformed the four other methods in all sessions for explaining the variance of both hand
velocities and positions (Fig. 4c, d). For example, across ten sessions in M1, NER explained 86% of
the variance in velocities, while the next best model, piVAE, explained only 35%. Similar findings
were observed in PMd (89% vs. 32%) and S1 (86% vs. 47%)."
RESULTS,0.28525641025641024,"In summary, combined with linear decoders, NER demonstrated the clearest velocity-dependent
direction tuning and explained the largest variance in velocities and positions."
RESULTS,0.28846153846153844,"4.3
Long-term and cross-hemisphere decoding in M1"
RESULTS,0.2916666666666667,"NER explains the largest variance in both hand velocities and positions in the 80% training data.
Next, we tested the trained model on the remaining 20% of test data. In addition to decoding test
data from the same session on a single day, we also evaluated its performance on data from different
sessions. We first conducted comparisons in M1 (Fig.5), followed by PMd (Fig.6) and S1 (Fig. 7)."
RESULTS,0.2948717948717949,"Velocities
Positions"
RESULTS,0.2980769230769231,"Linear & logistic regression
k-nearest neighbors"
RESULTS,0.30128205128205127,Directions
RESULTS,0.30448717948717946,"piVAE
CEBRA
NER
piVAE
CEBRA 16D
NER
a
b c
d e
f"
RESULTS,0.3076923076923077,"dia: 0.71 off: 0.64
dia: -3.1 off: -3.2
dia: -1.2 off: -2.1"
RESULTS,0.3108974358974359,"dia: 0.94 off: 0.88
dia: 0.74 off: 0.71
dia: 0.67 off: 0.23"
RESULTS,0.3141025641025641,"dia: 93% off: 90%
dia: 90% off: 79%
dia: 81% off: 44%"
RESULTS,0.3173076923076923,"dia: 0.76 off: 0.7
dia: 0.75 off: -1.1
dia: 0.87 off: -1.1"
RESULTS,0.32051282051282054,"dia: 0.93 off: 0.89
dia: 0.93 off: 0.18
dia: 0.97 off: 0.13"
RESULTS,0.32371794871794873,"dia: 92% off: 89%
dia: 93% off: 57%
dia: 99% off: 44%"
RESULTS,0.3269230769230769,"0
1 or 100%"
RESULTS,0.3301282051282051,"Figure 5: Decoding within and across time and brain hemispheres over years in M1. a-d Three
methods are applied to neural dynamics from ten sessions. Linear and logistic regression decoders
(a, c, e) or a nonlinear k-nearest neighbors (kNN) decoder (b, d, f) are trained on 80% of the
data and used to decode velocities, positions, and directions on the remaining 20% within-session
(diagonal) and cross-session (off-diagonal). Brighter colors indicate higher decoding performance.
a Same-session, cross-session, and cross-hemisphere velocity decoding using a linear regression
decoder. b Similar to a but using the nonlinear kNN decoder. Note that CEBRA’s latent dynamics are
represented in sixteen dimensions instead of three. c-d Similar to a-b but with hand positions as the
decoding variable. e-f Similar to a-b but with hand directions as the decoding variable."
RESULTS,0.3333333333333333,"Fig.5a shows velocity decoding performance using a linear regression decoder across three dimen-
sionality reduction methods. Interestingly, the linear decoder could not decode hand velocities from
latent dynamics generated by CEBRA (all variances were negative) and piVAE (only four positive).
In contrast, all variances with NER were positive (minimum: 0.24), with performance across different
sessions comparable to within-session performance (0.64 vs. 0.71). A kNN decoder (Fig.5b) achieved
high performance for CEBRA and piVAE only with within-session latent dynamics."
RESULTS,0.33653846153846156,"NER outperformed CEBRA and piVAE by a substantial margin in position decoding across all
conditions (Fig.5c). While the kNN decoder did not improve NER’s performance relative to the
linear decoder, it enhanced within-session performance for CEBRA and piVAE over NER (Fig.5d).
However, this came at the cost of cross-session decoding performance (0.89 vs. 0.18 and 0.13). Fig.5e
shows direction decoding accuracy, where NER still outperformed CEBRA and piVAE. Similar
results were observed using a kNN decoder (Fig.5f)."
RESULTS,0.33974358974358976,"In summary, compared to CEBRA and piVAE, NER consistently achieved higher performance across
all sessions with a linear decoder and outperformed in cross-session decoding with the nonlinear
decoder."
RESULTS,0.34294871794871795,"4.4
Latent dynamics in PMd and decoding between M1 and PMd"
RESULTS,0.34615384615384615,"Next, we turned our attention to PMd. Surprisingly, NER revealed similar latent dynamics in
this higher-order motor area (Fig.6a). Two other dimensionality reduction methods also identified
comparable latent dynamics, but these were less consistent and did not align well with movements
(Fig.14). Fig. 6b shows within- and cross-session velocity decoding using a linear regression decoder
(left) and a kNN decoder (right). Consistent with M1, in PMd, we observed that (1) both CEBRA
and piVAE underperformed with linear regression, while NER achieved stable performance across all
conditions, regardless of within- or cross-session contexts; (2) NER demonstrated robustness across
decoders, whereas the performance of CEBRA and piVAE varied substantially, ranging from very
low to occasionally outperforming NER in within-session decoding with the kNN decoder; and (3)
even with the kNN decoder, CEBRA and piVAE failed in cross-session decoding, whereas NER
maintained similar performance."
RESULTS,0.34935897435897434,"We also evaluated position and direction decoding and found that NER continued to outperform the
other two methods (Fig.6c, Fig.15). Overall, NER reveals consistent latent dynamics in PMd and can
effectively decode movements across PMd and M1."
RESULTS,0.3525641025641026,"Velocities
Positions"
RESULTS,0.3557692307692308,"Linear regression
k-nearest neighbors 
piVAE
CEBRA
NER
piVAE
CEBRA 16D
NER
b c"
RESULTS,0.358974358974359,"dia: 0.75 off: 0.74
dia: -3.1 off: -3.1
dia: -1.6 off: -2.8"
RESULTS,0.36217948717948717,"dia: 0.94 off: 0.93
dia: 0.75 off: 0.74
dia: 0.58 off: 0.21"
RESULTS,0.36538461538461536,"dia: 0.78 off: 0.76
dia: 0.78 off: -0.72
dia: 0.84 off: -0.62"
RESULTS,0.3685897435897436,"dia: 0.94 off: 0.92
dia: 0.94 off: 0.25
dia: 0.95 off: 0.19"
RESULTS,0.3717948717948718,"a
2016-09-29
10-05
10-06
10-07
10-14
10-21 0
1"
RESULTS,0.375,"Figure 6: Latent dynamics in PMd and decoding across brain areas. a Trial-averaged latent dynamics
in PMd revealed by NER, with the rotation reference set to the same session as in Fig. 3 (i.e.,
2016-10-14). b Previously used latent dynamics from M1 are added. Same-date, cross-date, and
cross-brain area velocity decoding using a linear regression decoder (left) and a kNN decoder (right)
on latent dynamics revealed by the three methods. c Similar to b. Fig. 14 shows the single-trial and
averaged latent dynamics revealed by CEBRA and piVAE. Fig. 15 shows hand direction decoding
performance using a logistic regression decoder."
RESULTS,0.3782051282051282,"4.5
Same movements but different latent dynamics in S1"
RESULTS,0.3814102564102564,"Lastly, we examined the latent dynamics and movement decoding in S1. NER revealed consistent
latent dynamics in S1 (Fig.7a, b). After rotating the latent dynamics with reference to the target
shown in Fig.3, they exhibit a consistent yet distinct shape compared to the latent dynamics observed
in M1 and PMd. Velocity decoding using a linear regression decoder was only successful when the
latent dynamics were extracted by NER (Fig.7c, d). While all three methods performed adequately for
position decoding, NER outperformed both CEBRA and piVAE across all nine conditions (Fig.7e).
Although S1 displays different latent dynamics than M1 and PMd, NER remains the most effective
method for decoding movement both within and across sessions in S1."
RESULTS,0.38461538461538464,"piVAE
CEBRA
NER"
RESULTS,0.38782051282051283,"dia: 0.9 off: 0.77
dia: 0.6 off: 0.45
dia: 0.73 off: 0.51"
RESULTS,0.391025641025641,"Velocities
Positions d e a b c"
RESULTS,0.3942307692307692,"dia: 0.67 off: 0.56
dia: -4.6 off: -4.8
dia: -0.38 off: -0.75
17-12-01
12-04
12-07 0 1"
RESULTS,0.3974358974358974,"Explained
Decoded"
RESULTS,0.40064102564102566,"Figure 7: Distinct latent dynamics with the same movement in S1. a Trial-averaged latent dynamics
revealed by NER, using the same reference target session as in Fig. 3. b Latent dynamics with the
reference target set to the first session in S1. c Left: On 80% held-in trials, the explained variance by
linear and logistic regression decoders is 91% and 97%, respectively. Right: On 20% held-out test
trials, the trained linear decoder predicts velocities and positions with performances of 71% and 90%,
respectively. Data collected on 2017-12-01. d Same- and cross-date velocity decoding performance
using the linear regression decoder with three dimensionality reduction methods. e Similar to d but
for positions. Fig. 16 shows latent dynamics revealed by CEBRA and piVAE."
RESULTS,0.40384615384615385,"4.6
Straight and curved hand movements have different latent dynamics in M1"
RESULTS,0.40705128205128205,"Lastly, we applied both NER and CEBRA in a new experiment where a monkey performed both
straight and curved hand movements in different directions while neural recordings were simultane-
ously collected in M1 (Fig. 8a)."
RESULTS,0.41025641025641024,"We first examined the latent dynamics when the monkey performed straight hand movements in
six different directions (Fig.8b). Surprisingly, both single and averaged latent dynamics aligned
well with the movements (Fig.8c) and displayed a shape similar to the previously observed latent
dynamics in M1. Next, we selected three hand directions, each involving both straight and curved
hand movements (Fig.8e). When we trained both NER and CEBRA on individual directions, only
NER revealed clearly separated latent dynamics corresponding to straight and curved movements
(Fig.8f). The difference between the two methods became even more pronounced when they were
trained on all three directions combined: NER displayed latent dynamics for straight movements
that were surrounded by those formed by curved movements. The explained variance achieved by
NER was also higher than that of CEBRA across all three angles, especially on the combined angles
(Fig. 17c). Finally, we tested a more challenging condition where all six reaching movements were
curved (Fig.8g). In the latent space, two curved movements in the same direction produced close
but distinct latent dynamics (Fig.8h). While CEBRA performed comparably on single directions, it
struggled with combined directions (Fig.17e). NER consistently achieved higher explained variance
than CEBRA (Fig.17f)."
RESULTS,0.41346153846153844,"Overall, NER not only aligns latent dynamics with straight movements but also effectively differ-
entiates curved hand movements from straight ones, demonstrating its robustness across various
movement types."
DISCUSSION,0.4166666666666667,"5
Discussion"
DISCUSSION,0.4198717948717949,"A benchmark comparison of NER and six other dimensionality reduction methods across multiple
brain areas and two movement tasks highlights NER’s superior performance in uncovering latent
dynamics. We believe the primary advantage of our method is its ability to extract nearly identical
latent dynamics across brain areas and over extended time periods. This capability opens new avenues
for both fundamental neuroscience research and brain-machine interfaces (BMI). Previous studies
[9, 25] used PCA to discover preserved latent dynamics across time and in animals performing similar
behaviors. In contrast, the latent dynamics revealed by NER are significantly more informative than
those uncovered by PCA. We believe NER will aid neuroscientists in probing the stability of latent d e a
b
c g f h"
"STRAIGHT 
MOVE",0.4230769230769231,"6 straight 
move"
"PAIRS OF 
STRAIGHT-CURVE 
MOVE",0.42628205128205127,"3 pairs of 
straight-curve 
move"
"PAIRS OF 
CURVE-CURVE 
MOVE",0.42948717948717946,"3 pairs of 
curve-curve 
move"
"PAIRS OF 
CURVE-CURVE 
MOVE",0.4326923076923077,"Figure 8: Distinct latent dynamics align with different movements in M1. a A monkey performs a
curved reaching task through a virtual maze while neural activity from M1 is recorded simultaneously.
The task includes multiple reaching directions, and the monkey makes curved movements when
encountering a barrier on the trajectory (reproduced from [22]). b Hand positions for six target
directions without barriers (i.e., straight movements). c Latent dynamics from a single trial (left) and
averaged across trials (right). d Explained variance of hand movements (velocity: 0.79, position:
0.92). Hand directions (represented by colors) are assigned manually. e Hand movements for three
target directions, both without barriers (straight movements) and with barriers (curved movements).
f Latent dynamics of curved (stars) and straight (dots with black line) hand movements shown
separately and combined across directions. g Hand movements for three target directions, all with
barriers (curved movements). h Latent dynamics trained on one pair (1st) or three pairs (3rd) of
curved movements, with decoder-explained hand movements (2nd and 4th). Fig. 17 provides a
comparison of results with CEBRA."
"PAIRS OF 
CURVE-CURVE 
MOVE",0.4358974358974359,"dynamics under various conditions. For BMI applications, we demonstrate that NER, combined with
a simple linear decoder, can predict hand movements across years, brain areas, and hemispheres. This
capability enables training on latent dynamics within and between subjects, allowing for movement
prediction in different subjects. The linear decoder’s lack of hyperparameters is also an advantage."
"PAIRS OF 
CURVE-CURVE 
MOVE",0.4391025641025641,"The application of NER is not limited to hand movements using neurophysiological recordings.
This includes latent dynamics in the hippocampus representing the body position of running rats
and latent dynamics in the visual cortex representing embedded video features [27]. Similarly,
recording modalities are not limited to single-neuron electrophysiology; other methods, such as
calcium imaging, local-field potentials, and EEG, can also be used."
"PAIRS OF 
CURVE-CURVE 
MOVE",0.4423076923076923,"In our final experiments with curved movements, we manually selected three pairs of reaching tasks
that involved curved trajectories. Both NER and CEBRA failed when all 108 movement conditions
were trained simultaneously. Furthermore, beyond the straight and curved movements examined here
in macaque monkeys, more complex movements, such as handwriting [29] and speech [29, 20], exist
primarily in humans. These movements are also continuous but may require more than a 3D latent
space for effective representation, and ranking the distances of complex movements adds further
challenges. Nevertheless, uncovering the latent dynamics underlying these complex movements,
which has yet to be achieved[7], could greatly advance BMI applications [3, 6]."
"PAIRS OF 
CURVE-CURVE 
MOVE",0.44551282051282054,Acknowledgments and Disclosure of Funding
"PAIRS OF 
CURVE-CURVE 
MOVE",0.44871794871794873,"We greatly appreciate the Miller and Shenoy labs for publicly releasing their experimental data on
macaque monkeys. We also thank the Mathis lab for the CEBRA code, which served as the basis for
our NER. This work was supported by National Institute of Deafness and Other Communications
Disorders grant DC003180 (X.W.). No conflicts of interest are declared by the authors."
REFERENCES,0.4519230769230769,References
REFERENCES,0.4551282051282051,"[1] Mehdi Azabou, Mohammad Gheshlaghi Azar, Ran Liu, Chi-Heng Lin, Erik C Johnson, Kiran
Bhaskaran-Nair, Max Dabagia, Bernardo Avila-Pires, Lindsey Kitchell, Keith B Hengen, et al.
Mine your own view: Self-supervised learning through across-sample prediction. arXiv preprint
arXiv:2102.10106, 2021."
REFERENCES,0.4583333333333333,"[2] Matteo Carandini and David J Heeger. Normalization as a canonical neural computation. Nature
reviews neuroscience, 13(1):51–62, 2012."
REFERENCES,0.46153846153846156,"[3] Nicholas S Card, Maitreyee Wairagkar, Carrina Iacobacci, Xianda Hou, Tyler Singer-Clark,
Francis R Willett, Erin M Kunz, Chaofei Fan, Maryam Vahdati Nia, Darrel R Deo, et al. An
accurate and rapidly calibrating speech neuroprosthesis. New England Journal of Medicine,
391(7):609–618, 2024."
REFERENCES,0.46474358974358976,"[4] Le Chang and Doris Y Tsao. The code for facial identity in the primate brain. Cell, 169(6):1013–
1028, 2017."
REFERENCES,0.46794871794871795,"[5] Mark M Churchland, John P Cunningham, Matthew T Kaufman, Justin D Foster, Paul Nuyu-
jukian, Stephen I Ryu, and Krishna V Shenoy. Neural population dynamics during reaching.
Nature, 487(7405):51–56, 2012."
REFERENCES,0.47115384615384615,"[6] Chaofei Fan, Nick Hahn, Foram Kamdar, Donald Avansino, Guy Wilson, Leigh Hochberg, Kr-
ishna V Shenoy, Jaimie Henderson, and Francis Willett. Plug-and-play stability for intracortical
brain-computer interfaces: a one-year demonstration of seamless brain-to-text communication.
Advances in neural information processing systems, 36, 2024."
REFERENCES,0.47435897435897434,"[7] Cátia Fortunato, Jorge Bennasar-Vázquez, Junchol Park, Joanna C Chang, Lee E Miller,
Joshua T Dudman, Matthew G Perich, and Juan A Gallego. Nonlinear manifolds underlie neural
population activity during behaviour. bioRxiv, 2023."
REFERENCES,0.4775641025641026,"[8] Winrich A Freiwald, Doris Y Tsao, and Margaret S Livingstone. A face feature space in the
macaque temporal lobe. Nature neuroscience, 12(9):1187, 2009."
REFERENCES,0.4807692307692308,"[9] Juan A Gallego, Matthew G Perich, Raeed H Chowdhury, Sara A Solla, and Lee E Miller.
Long-term stability of cortical population dynamics underlying consistent behavior. Nature
neuroscience, 23(2):260–270, 2020."
REFERENCES,0.483974358974359,"[10] Juan A Gallego, Matthew G Perich, Lee E Miller, and Sara A Solla. Neural manifolds for the
control of movement. Neuron, 94(5):978–984, 2017."
REFERENCES,0.48717948717948717,"[11] Juan A Gallego, Matthew G Perich, Stephanie N Naufel, Christian Ethier, Sara A Solla, and
Lee E Miller. Cortical population activity within a preserved neural manifold underlies multiple
motor behaviors. Nature communications, 9(1):4233, 2018."
REFERENCES,0.49038461538461536,"[12] Cecilia Gallego-Carracedo, Matthew G Perich, Raeed H Chowdhury, Lee E Miller, and Juan Ál-
varo Gallego. Local field potentials reflect cortical population dynamics in a region-specific and
frequency-dependent manner. Elife, 11:e73155, 2022."
REFERENCES,0.4935897435897436,"[13] Joshua I Glaser, Ari S Benjamin, Raeed H Chowdhury, Matthew G Perich, Lee E Miller, and
Konrad P Kording. Machine learning for neural decoding. Eneuro, 7(4), 2020."
REFERENCES,0.4967948717948718,"[14] Cole Hurwitz, Akash Srivastava, Kai Xu, Justin Jude, Matthew Perich, Lee Miller, and Matthias
Hennig. Targeted neural dynamical modeling. Advances in Neural Information Processing
Systems, 34:29379–29392, 2021."
REFERENCES,0.5,"[15] Mohammad Reza Keshtkaran, Andrew R Sedler, Raeed H Chowdhury, Raghav Tandon, Diya
Basrai, Sarah L Nguyen, Hansem Sohn, Mehrdad Jazayeri, Lee E Miller, and Chethan Pandari-
nath. A large-scale neural network training framework for generalized estimation of single-trial
population dynamics. Nature Methods, 19(12):1572–1577, 2022."
REFERENCES,0.5032051282051282,"[16] Dmitry Kobak, Wieland Brendel, Christos Constantinidis, Claudia E Feierstein, Adam Kepecs,
Zachary F Mainen, Xue-Lian Qi, Ranulfo Romo, Naoshige Uchida, and Christian K Machens.
Demixed principal component analysis of neural population data. elife, 5:e10989, 2016."
REFERENCES,0.5064102564102564,"[17] Eric Kenji Lee, Hymavathy Balasubramanian, Alexandra Tsolias, Stephanie Udochukwu
Anakwe, Maria Medalla, Krishna V Shenoy, and Chandramouli Chandrasekaran. Non-linear
dimensionality reduction on extracellular waveforms reveals cell type diversity in premotor
cortex. Elife, 10:e67490, 2021."
REFERENCES,0.5096153846153846,"[18] Ran Liu, Mehdi Azabou, Max Dabagia, Chi-Heng Lin, Mohammad Gheshlaghi Azar, Keith
Hengen, Michal Valko, and Eva Dyer. Drop, swap, and generate: A self-supervised approach for
generating neural activity. Advances in neural information processing systems, 34:10587–10599,
2021."
REFERENCES,0.5128205128205128,"[19] Leland McInnes, John Healy, and James Melville. Umap: Uniform manifold approximation
and projection for dimension reduction. arXiv preprint arXiv:1802.03426, 2018."
REFERENCES,0.5160256410256411,"[20] Sean L Metzger, Kaylo T Littlejohn, Alexander B Silva, David A Moses, Margaret P Seaton,
Ran Wang, Maximilian E Dougherty, Jessie R Liu, Peter Wu, Michael A Berger, et al. A high-
performance neuroprosthesis for speech decoding and avatar control. Nature, 620(7976):1037–
1046, 2023."
REFERENCES,0.5192307692307693,"[21] Chethan Pandarinath, Daniel J O’Shea, Jasmine Collins, Rafal Jozefowicz, Sergey D Stavisky,
Jonathan C Kao, Eric M Trautmann, Matthew T Kaufman, Stephen I Ryu, Leigh R Hochberg,
et al. Inferring single-trial neural population dynamics using sequential auto-encoders. Nature
methods, 15(10):805–815, 2018."
REFERENCES,0.5224358974358975,"[22] Felix Pei, Joel Ye, David Zoltowski, Anqi Wu, Raeed H Chowdhury, Hansem Sohn, Joseph E
O’Doherty, Krishna V Shenoy, Matthew T Kaufman, Mark Churchland, et al. Neural latents
benchmark’21: evaluating latent variable models of neural population activity. arXiv preprint
arXiv:2109.04463, 2021."
REFERENCES,0.5256410256410257,"[23] Matthew G Perich, Juan A Gallego, and Lee E Miller. A neural population mechanism for rapid
learning. Neuron, 100(4):964–976, 2018."
REFERENCES,0.5288461538461539,"[24] Neil C Rabinowitz, Ben DB Willmore, Jan WH Schnupp, and Andrew J King. Contrast gain
control in auditory cortex. Neuron, 70(6):1178–1191, 2011."
REFERENCES,0.532051282051282,"[25] Mostafa Safaie, Joanna C Chang, Junchol Park, Lee E Miller, Joshua T Dudman, Matthew G
Perich, and Juan A Gallego. Preserved neural dynamics across animals performing similar
behaviour. Nature, 623(7988):765–771, 2023."
REFERENCES,0.5352564102564102,"[26] Omid G Sani, Hamidreza Abbaspourazad, Yan T Wong, Bijan Pesaran, and Maryam M Shanechi.
Modeling behaviorally relevant neural dynamics enabled by preferential subspace identification.
Nature Neuroscience, 24(1):140–149, 2021."
REFERENCES,0.5384615384615384,"[27] Steffen Schneider, Jin Hwa Lee, and Mackenzie Weygandt Mathis. Learnable latent embeddings
for joint behavioural and neural analysis. Nature, 617(7960):360–368, 2023."
REFERENCES,0.5416666666666666,"[28] Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine
learning research, 9(11), 2008."
REFERENCES,0.5448717948717948,"[29] Francis R Willett, Donald T Avansino, Leigh R Hochberg, Jaimie M Henderson, and Kr-
ishna V Shenoy. High-performance brain-to-text communication via handwriting. Nature,
593(7858):249–254, 2021."
REFERENCES,0.5480769230769231,"[30] Joel Ye and Chethan Pandarinath. Representation learning for neural population activity with
neural data transformers. arXiv preprint arXiv:2108.01210, 2021."
REFERENCES,0.5512820512820513,"[31] Kaiwen Zha, Peng Cao, Jeany Son, Yuzhe Yang, and Dina Katabi. Rank-n-contrast: Learning
continuous representations for regression. Advances in Neural Information Processing Systems,
36, 2024."
REFERENCES,0.5544871794871795,"[32] Ding Zhou and Xue-Xin Wei. Learning identifiable and interpretable latent models of high-
dimensional neural activity using pi-vae. Advances in Neural Information Processing Systems,
33:7234–7247, 2020."
REFERENCES,0.5576923076923077,"[33] Feng Zhu, Harrison A Grier, Raghav Tandon, Changjia Cai, Anjali Agarwal, Andrea Gio-
vannucci, Matthew T Kaufman, and Chethan Pandarinath. A deep learning framework for
inference of single-trial neural population dynamics from calcium imaging with subframe
temporal resolution. Nature neuroscience, 25(12):1724–1734, 2022."
REFERENCES,0.5608974358974359,"A
Appendix / supplemental material"
REFERENCES,0.5641025641025641,"A.1
Computer"
REFERENCES,0.5673076923076923,"Operating System is Ubuntu 22.04.3 LTS, computer memory is 42 GB, CPU is Intel Xeon W-2225,
and GPU is NVIDIA RTX A5000."
REFERENCES,0.5705128205128205,"A.2
Center-out reaching experiments in M1, PMd, and S1"
REFERENCES,0.5737179487179487,"A.2.1
Behavior"
REFERENCES,0.5769230769230769,"The dataset comprises behavioral task data from two male Macaca mulatta monkeys (Monkeys H and
C). These monkeys were trained to sit in a primate chair and perform a center-out reaching task using
a planar manipulandum with the hand contralateral to the implanted hemisphere. During each trial,
the monkey started by moving a cursor to a central target. After a variable waiting period, one of
eight outer targets (equally spaced along a circle of 6–8 cm radius) was presented. Monkeys C and H
differed in the task protocols:"
REFERENCES,0.5801282051282052,"Monkey C: Trained to wait for an auditory go cue during a delay period of 0.5–1.5 seconds while
the target remained visible. Upon receiving the cue, the monkey had to move the cursor to the outer
target within 1 second and hold it there for 0.5 seconds to receive a liquid reward."
REFERENCES,0.5833333333333334,"Monkey H: No delay period; the monkey had to move the cursor to the outer target within 1 second
and hold it there for 0.1 seconds."
REFERENCES,0.5865384615384616,"For both monkeys, the trial restarted by returning the cursor to the central target. Endpoint positions
of the manipulandum were recorded at 1 kHz, and task event timings were digitally logged. Hand
velocity was computed as the derivative of hand position. The dataset includes 6 sessions for Monkey
C and 5 sessions for Monkey H, considering only successful trials (an average of 307±221 trials per
session, mean ± s.d.)"
REFERENCES,0.5897435897435898,Neural recordings
REFERENCES,0.592948717948718,"The dataset consists of neural recordings from two male Macaque monkeys. These recordings were
obtained using 96-channel Utah electrode arrays implanted in specific cortical regions."
REFERENCES,0.5961538461538461,"Monkey C: Initially implanted in the right primary motor cortex (M1) and later received implants in
the left M1 and dorsal premotor cortex (PMd) (denoted as CR and CL, respectively)."
REFERENCES,0.5993589743589743,Monkey H: Implanted in area 2 of the primary somatosensory cortex of the left hemisphere.
REFERENCES,0.6025641025641025,"Neural activity was recorded using a Cerebus system (Blackrock Microsystems, Salt Lake City, UT)
at a sampling frequency of 30 kHz. The recorded signals underwent band-pass filtering (250–5000
Hz) and were converted to spike times based on threshold crossings. Spike sorting was performed
using specialized software (Offline Sorter v3, Plexon, Inc, Dallas, TX) to identify putative neurons."
REFERENCES,0.6057692307692307,"Date
Monkey
Hemisphere
Trial
M1
PMd
S1"
"CHEWIE
RIGHT",0.6089743589743589,"150313
Chewie
Right
1038
86
n/a
n/a
150309
Chewie
Right
1026
72
n/a
n/a
150629
Chewie
Right
179
49
n/a
n/a
150630
Chewie
Right
178
44
n/a
n/a
160929
Chewie
Left
208
74
114
n/a
161005
Chewie
Left
202
82
167
n/a
161006
Chewie
Left
209
63
192
n/a
161007
Chewie
Left
168
70
137
n/a
161014
Chewie
Left
740
88
190
n/a
161021
Chewie
Left
286
84
211
n/a
171201
Han
Left
292
n/a
n/a
70
171204
Han
Left
255
n/a
n/a
83
171207
Han
Left
245
n/a
n/a
72
Table 1: Datasets for the center-out reaching experiments."
"CHEWIE
RIGHT",0.6121794871794872,Datasets
"CHEWIE
RIGHT",0.6153846153846154,"All the center-out reaching experiments using the open source data from: https://datadryad.
org/stash/dataset/doi:10.5061/dryad.xd2547dkt This data is released accompanying this
paper:https://elifesciences.org/articles/73155#data We used all sessions from Monkey
Chewie and Monkey Han. We chose these Monkeys because one session in Chewie is used by piVAE
paper[32] and one session in Monkey Han is used by CEBRA paper[27]. Although the datasets come
from same session in same Monkey, the temporal resolution is much higher for the datasets used
by piVAE and CEBRA papers. The data is Matlab format and we extract following information:
tgtDir (Target direction, radians for Monkey Chewie and degrees for Monkey Han), idx-goCueTime
(The time go Cue is one), vel(XY velocities), M1-spikes for both Chewie 2015 and Chewie 2016,
and PMd-spikes only for Chewie 2016. The time bin is 30ms and we extract all the spikes after
each go Cue. We extracted 40 bins for Monkey Chewie and 35 bins for Monkey Han, because
most trial in Monkey Han has short acquisition window than 40 bins (afte go Cue). We smoothed
the discrete spike count in the Matlab using a Gaussian kernel. The standard deviation is 1.5 and
kernel size is six standard deviations. We keep all the trials and neurons. The number of trials and
neurons are shown in Table 1. Our NER is just a modification of the loss function used by CEBRA:
https://github.com/AdaptiveMotorControlLab/CEBRA The RNC loss could be downloaded
from: https://github.com/kaiwenzha/Rank-N-Contrast The iterations is 20000, learning
rate is 1e-4, and batch size 512. The temperature is fixed to 1 for both NER and CEBRA. The output
dimension of NER is fixed to 3. For CEBRA, we used output dimension of 3 for visualizing the latent
dynamics and linear models decoding. We only used 16 dimensional embeddings for k-NN decoders.
For the piVAE, we did not use the original version which is based on older version of Tensorflow.
https://github.com/zhd96/pi-vae Instead, we used the modified conv-pi-VAE that is already
included into the CEBRA package. We fixed the random seed to 42, and using batch size of 200 and
iterations of 300."
"CHEWIE
RIGHT",0.6185897435897436,"A.2.2
Curved hand movements experiments in M1 Fig 8 17"
"CHEWIE
RIGHT",0.6217948717948718,"The MC_Maze dataset includes recordings from the primary motor and dorsal premotor cortices of a
monkey performing reaches to visual targets in a virtual maze with an instructed delay. This dataset
comprises 108 different task configurations, each varying in target positions, barrier numbers, and
barrier positions. The monkey repeated each task configuration multiple times in random order, result-
ing in 2,869 trials recorded in a single session with 182 neurons and simultaneous hand kinematics
monitoring. This datasets could be downloaded from: https://dandiarchive.org/dandiset/
000128, https://github.com/dandisets/000128.
In our works, we used the NLB21
package[22] to download the data from DANDI: https://github.com/neurallatents Our code
(Jupyter Notebook) is modified from: https://github.com/neurallatents/neurallatents.
github.io/blob/master/notebooks/mc_maze.ipynb We used a time bin of 5ms (raw resolu-
tion is 1ms) and Gaussian window of 50ms. For six straight movements, we only use version 0 and
trial type of 13, 29, 17, 38, 6, 18. For the straight-curved and curved-curved movements, we keep all
three versions of task (one straight and two curved). We removed the target angle during training. We
used trial type of 13, 38, 18 for straight-curved and 37,1, 31,38, 34,18 for curved-curved movements.
The iterations is 5000, learning rate is 1e-4, and batch size 512."
"CHEWIE
RIGHT",0.625,"A.3
Decoders"
"CHEWIE
RIGHT",0.6282051282051282,"We rotate the latent dynamics with reference to same target before decoding. We used orthogo-
nal Procrustes from scipy for this purpose: https://docs.scipy.org/doc/scipy/reference/
generated/scipy.linalg.orthogonal_procrustes.html. We picked on target angle and ro-
tate the whole 3D latent dynamics using the computed orthogonal matrix. This rotation will not
modify local detail or the relative positions of each reaching direction. For the linear decoders
using linear and logistic regression, both are imported from ""linear_model"" of sklearn. There is no
parameter or hyperparameter for the linear regression model. For the logistic regression model, we
used the following parameters: max_iter=500, multi_class=’multinomial’, solver=’lbfgs’ For the
k-nearest neighbors Regressor and Classifier, they are both imported from ""neighbors"" in sklearn. We
used ""GridSearchCV"" in sklearn to searach the best ""n_neighbors"" range from 2 to 1024."
"CHEWIE
RIGHT",0.6314102564102564,"a
2015-06-29
2015-06-30 NER Cebra piVAE c b"
"CHEWIE
RIGHT",0.6346153846153846,"2016-10-05
2016-10-07
M1 in Left Hemisphere
M1 in Right Hemisphere"
"CHEWIE
RIGHT",0.6378205128205128,"Figure 9: NER reveals consistent and movements aligned latent dynamics in M1 for the remaining
four sessions. Extra four sessions’ latent dynamics at left and right hemisphere of Monkey C after
rotating relative to target session in Fig 3 (2016-10-14). piVAE"
"CHEWIE
RIGHT",0.6410256410256411,"UMAP
w/o
label"
"CHEWIE
RIGHT",0.6442307692307693,"UMAP
w/
label dPCA PCA"
"CHEWIE
RIGHT",0.6474358974358975,"2016-09-29
10-05
10-06
10-07
10-14
10-21
2015-03-13
2015
06-29
06-30"
"CHEWIE
RIGHT",0.6506410256410257,"Figure 10: Neural embeddings revealed by five other dimensionality reduction methods. Single trial
(top) and trial averaged (bottom) latent dynamics revealed by five other dimensionality reduction
methods. NER Cebra piVAE"
"CHEWIE
RIGHT",0.6538461538461539,"UMAP
w/o
label"
"CHEWIE
RIGHT",0.657051282051282,"UMAP
w/
label"
"CHEWIE
RIGHT",0.6602564102564102,"Figure 11: Latent dynamics without rotation. Trial-averaged latent dynamics revealed by five
dimensionality reduction methods without rotation."
"CHEWIE
RIGHT",0.6634615384615384,"Monkey C 2015-03-13
a b"
"CHEWIE
RIGHT",0.6666666666666666,Monkey C 2015-03-13
"CHEWIE
RIGHT",0.6698717948717948,"Monkey C 2016-10-05
Monkey C 2016-09-29"
"CHEWIE
RIGHT",0.6730769230769231,"Figure 12: Mixed single trial latent dynamics in PCA and time-stimulus components revealed by
dPCA. a Unlike other five dimensionality reduction methods, single trial latent dynamics revealed
by principal component analysis (PCA) and demixed PCA (dPCA) is mixed and latency dynamics
are only identifiable after averaging. b In the trial-averaged latent dynamics, dPCA reveals three
components (left, middle, right) at eight directions (different colors): time component aligned with go
cue regardless of directions, separated stimulus component varied across time, and mixed component
aligned with go cue and different for each direction."
"CHEWIE
RIGHT",0.6762820512820513,"Table 2: Statistical analysis and quantitative comparisons of the presented results. Figs. 3 and 6a
show the correlation coefficients between each pair of averaged latent dynamics. Here, ""d."" refers
to values on the diagonal, ""o."" refers to values off the diagonal, ""L"" denotes the left panel, and ""R""
denotes the right panel. The 2nd to 4th columns display the mean and standard deviation, while the
5th to 7th columns provide the t-statistics and p-values."
"CHEWIE
RIGHT",0.6794871794871795,"Fig.
NER
CEBRA
piVAE
NER vs CE
NER vs pi
CE vs pi"
"CHEWIE
RIGHT",0.6826923076923077,"3
0.95, 0.03
0.92, 0.05
0.43, 0.25
7.9, 5.5e-10
15.3, 2.9e-19
14.8, 1.0e-18
5a-d
0.71, 0.1
-3.08, 0.6
-1.21, 1.4
16.8, 4.3e-08
4.1, 2.5e-03
-5.8, 2.8e-04
5a-o
0.64, 0.1
-3.22, 1.0
-2.05, 1.6
40.9, 1.7e-59
16.3, 1.7e-28
-9.5, 3.9e-15
5b-d
0.76, 0.1
0.75, 0.1
0.87, 0.1
0.4, 7.0e-01
-3.5, 7.2e-03
-3.2, 1.1e-02
5b-o
0.70, 0.1
-1.07, 1.5
-1.05, 1.1
11.5, 3.3e-19
15.4, 6.4e-27
-0.1, 8.9e-01
5c-d
0.94, 0.0
0.74, 0.0
0.67, 0.2
11.6, 9.9e-07
4.4, 1.8e-03
1.4, 1.9e-01
5c-o
0.88, 0.1
0.71, 0.1
0.23, 0.4
19.2, 2.5e-33
17.9, 3.0e-31
12.6, 1.4e-21
5d-d
0.93, 0.0
0.93, 0.0
0.96, 0.0
0.5, 6.6e-01
-3.7, 5.0e-03
-3.1, 1.2e-02
5d-o
0.89, 0.0
0.18, 0.5
0.13, 0.4
13.1, 2.0e-22
16.5, 8.0e-29
0.7, 4.8e-01
5e-d
93, 4.4
90, 4.6
81, 11.9
2.5, 3.6e-02
2.4, 4.0e-02
1.9, 9.5e-02
5e-o
90, 5.9
79, 9.0
43, 15.2
13.6, 1.7e-23
26.0, 2.6e-43
17.5, 1.2e-30
5f-d
92, 4.1
93, 4.2
98, 1.5
-0.3, 7.5e-01
-4.9, 8.3e-04
-3.4, 7.5e-03
5f-o
89, 5.8
57, 16.3
44, 15.9
19.1, 3.2e-33
25.7, 5.4e-43
5.6, 2.5e-07
6a
0.87, 0.08
0.81, 0.10
0.56, 0.09
14.8, 1.1e-18
29.3, 1.6e-30
20.7, 2.8e-24
6bL-d
0.75, 0.0
-3.06, 0.4
-1.56, 1.1
35.2, 1.2e-12
7.2, 1.8e-05
-4.8, 5.8e-04
6bL-o
0.74, 0.0
-3.10, 0.3
-2.78, 2.2
124.6, 5.7e-138
18.2, 9.7e-38
-1.6, 1.1e-01
6cL-d
0.78, 0.1
0.78, 0.1
0.84, 0.1
-0.0, 9.8e-01
-2.4, 3.3e-02
-1.9, 7.7e-02
6cL-o
0.76, 0.1
-0.72, 1.0
-0.62, 0.8
17.7, 1.8e-36
19.8, 3.5e-41
-0.9, 3.7e-01
6bR-d
0.94, 0.0
0.75, 0.0
0.58, 0.1
36.3, 8.4e-13
9.5, 1.3e-06
4.5, 9.7e-04
6bR-o
0.93, 0.0
0.74, 0.0
0.21, 0.3
77.2, 4.3e-111
24.3, 2.6e-50
18.2, 1.1e-37
6cR-d
0.93, 0.0
0.94, 0.0
0.95, 0.0
-0.1, 9.3e-01
-1.2, 2.4e-01
-1.0, 3.4e-01
6cR-o
0.92, 0.0
0.25, 0.5
0.18, 0.5
15.3, 5.6e-31
17.2, 2.6e-35
1.1, 2.8e-01
7d-d
0.67, 0.0
-4.59, 1.3
-0.38, 0.3
5.6, 3.0e-02
5.9, 2.8e-02
-5.5, 3.2e-02
7d-o
0.56, 0.1
-4.79, 1.1
-0.75, 0.1
11.4, 9.0e-05
19.4, 6.7e-06
-8.3, 4.1e-04
7e-d
0.90, 0.0
0.60, 0.0
0.73, 0.1
18.5, 2.9e-03
3.1, 8.9e-02
-1.8, 2.2e-01
7e-o
0.77, 0.1
0.45, 0.1
0.51, 0.1
5.9, 1.9e-03
3.3, 2.1e-02
-0.9, 4.1e-01 a"
"CHEWIE
RIGHT",0.6858974358974359,"b
Correlation matrix among four direction tuning curves and X-Y velocities"
"CHEWIE
RIGHT",0.6891025641025641,"M1
PMd NER"
"CHEWIE
RIGHT",0.6923076923076923,"piVAE
UMAP w/ label"
"CHEWIE
RIGHT",0.6955128205128205,"X-vel
UMAP w/o label Cebra Y-vel"
"CHEWIE
RIGHT",0.6987179487179487,"M1
PMd & S1
c"
"CHEWIE
RIGHT",0.7019230769230769,Explained directions in PMd and X-Y velocities
"CHEWIE
RIGHT",0.7051282051282052,Explained peak classification accuracy by logistic regression
"CHEWIE
RIGHT",0.7083333333333334,"Figure 13: Hand directions tunings and explained peak classification accuracy of hand directions in
M1, PMd, and S1. a Hand directions explained accuracy using a logistic regression models trained
on the latent dynamics revealed by five dimensionality reduction methods. Shaded areas are standard
deviation over six sessions from PMd in the Monkey C. Notice the only NER reveal hand velocities
dependent direction tuning curves that peak around 500 ms. b Correlation coefficients matrix between
direction tuning curves and velocities in M1 (left) and PMd (right). c Explained variance on hand
directions using logistic regression decoder."
"CHEWIE
RIGHT",0.7115384615384616,"2016-09-29
10-05
10-06
10-07
10-14
10-21
a Cebra piVAE b"
"CHEWIE
RIGHT",0.7147435897435898,"Figure 14: Latent dynamics in PMd revealed by CEBRA and piVAE. Single trial and trial averaged
latent dynamics revealed by CEBRA and piVAE. All the figures are rotated with reference with the
one session shown in Fig 3 (2016-10-14)."
"CHEWIE
RIGHT",0.717948717948718,Directions
"CHEWIE
RIGHT",0.7211538461538461,"Logistic regression
k-nearest neighbors"
"CHEWIE
RIGHT",0.7243589743589743,"piVAE
CEBRA
NER
piVAE
CEBRA 16D
NER
dia: 94% off: 93%
dia: 92% off: 85%
dia: 73% off: 40%
dia: 94% off: 92%
dia: 95% off: 59%
dia: 97% off: 44%"
"CHEWIE
RIGHT",0.7275641025641025,"0
100%"
"CHEWIE
RIGHT",0.7307692307692307,"Figure 15: Direction decoding accuracy. Same date, cross date, and cross brain areas decoding of
hand directions using linear regression (left) and k-nearest neighbors decoder trained on the latent
dynamics revealed by three methods. Notice the range of color bars is 0-100 for all six figures. a Cebra piVAE b"
"CHEWIE
RIGHT",0.7339743589743589,"Rotate 
with 
reference 
to M1"
"CHEWIE
RIGHT",0.7371794871794872,"Rotate 
with 
reference 
to S1"
"CHEWIE
RIGHT",0.7403846153846154,"Rotate 
with 
reference 
to S1"
"CHEWIE
RIGHT",0.7435897435897436,"Rotate 
with 
reference 
to S1"
"CHEWIE
RIGHT",0.7467948717948718,"2017-12-01
12-04
12-07 c"
"CHEWIE
RIGHT",0.75,"Figure 16: Latent dynamics in S1 revealed by CEBRA and piVAE. a Top, single trial latent dynamics
revealed by CEBRA are rotated with reference to the one session in M1. Bottom, latent dynamis are
rotated with reference to the first session in S1. b Similar to the bottom figure of a but using CEBRA
dimensionality reduction method. c Similar to c but using piVAE dimensionality reduction method. a d"
"PAIRS OF 
STRAIGHT-CURVE 
MOVE",0.7532051282051282,"3 pairs of 
straight-curve 
move"
"PAIRS OF 
CURVE-CURVE 
MOVE",0.7564102564102564,"3 pairs of 
curve-curve 
move b c f e"
"PAIRS OF 
CURVE-CURVE 
MOVE",0.7596153846153846,"Figure 17: Distinct latent dynamics revealed by CEBRA. Similar to Fig 7 but using the latent
dynamics revealed by CEBRA. a Ground truth motion trajectories at three directions for straight-
curve movements. b Latency dynamics trained on three directions separately and combined. Notice
the latent dynamics of straight hand movements (dots and black line) are either mixed (1st) with
curved movements or squeezed (3rd). Latent dynamics trained by three directions combined are
overlapped. c Linear models predicted hand trajectories. The directions are manually assigned. The
explained variance for hand velocities (directions) are 87% (94%), 83% (93%), 82% (94%), and
66% (86%). Notice all the values are lower than NER which are 92% (95%), 89% (96%), 90%
(96%), and 81% (91%), especially for the combined directions. d Ground truth motion trajectories at
four directions for paired curve-curve movements. e Latency dynamics trained on three directions
separately and combined. Notice latent dynamics trained by three directions combined are overlapped.
f Linear models predicted hand trajectories. The directions are manually assigned. The explained
variance for hand velocities (directions) are 85% (93%), 81% (92%), 85% (94%), and 61% (80%).
Notice all the values are lower than NER which are 87% (95%), 89% (95%), 91% (96%), and 81%
(91%), especially for the combined directions."
"PAIRS OF 
CURVE-CURVE 
MOVE",0.7628205128205128,NeurIPS Paper Checklist
CLAIMS,0.7660256410256411,1. Claims
CLAIMS,0.7692307692307693,"Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: The claims we made in the abstract and introduction are based on our extensive
experiments over multiple dataset and a benchmark comparisons of our method with six
other methods.
Guidelines:"
CLAIMS,0.7724358974358975,"• The answer NA means that the abstract and introduction do not include the claims
made in the paper.
• The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
• The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
• It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2. Limitations"
CLAIMS,0.7756410256410257,"Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: In the last part of Discussion, we mentioned two limitations of this work
clearly
Guidelines:"
CLAIMS,0.7788461538461539,"• The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate ""Limitations"" section in their paper.
• The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
• The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
• The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
• The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
• If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
• While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3. Theory Assumptions and Proofs"
CLAIMS,0.782051282051282,"Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?"
CLAIMS,0.7852564102564102,"Answer: [NA]
Justification: There is no theoretical analysis. This work an application of contrastive
learning and deep regression on Neuroscience. We do not make or claim any theoretical
contribution."
CLAIMS,0.7884615384615384,Guidelines:
CLAIMS,0.7916666666666666,"• The answer NA means that the paper does not include theoretical results.
• All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
• All assumptions should be clearly stated or referenced in the statement of any theorems.
• The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
• Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced."
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7948717948717948,4. Experimental Result Reproducibility
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7980769230769231,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8012820512820513,"Answer: [Yes]
Justification: Our works use the public dataset, and our code adds the loss function from
one paper into the code of the other paper. Both codes are available online. There is not
hyperparameter turnings. We mentioned the GPU, iterations, and batch size we used in the
Appendix. We also upload our codes that generate all the Figures."
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8044871794871795,Guidelines:
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8076923076923077,"• The answer NA means that the paper does not include experiments.
• If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
• If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
• Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
• While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a) If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b) If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c) If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d) We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8108974358974359,"some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5. Open access to data and code"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8141025641025641,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: Also the data and code are already available online. We just combine two
codes.
Guidelines:"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8173076923076923,"• The answer NA means that paper does not include experiments requiring code.
• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
public/guides/CodeSubmissionPolicy) for more details.
• While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
• The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines (https:
//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
• The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
• The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
• At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
• Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6. Experimental Setting/Details"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8205128205128205,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: We gave those details in the Appendix.
Guidelines:"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8237179487179487,"• The answer NA means that the paper does not include experiments.
• The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
• The full details can be provided either with the code, in appendix, or as supplemental
material.
7. Experiment Statistical Significance"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8269230769230769,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [NA]
Justification: We just show the raw, mean and median values without using any statistical
metrics.
Guidelines:"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8301282051282052,"• The answer NA means that the paper does not include experiments.
• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper."
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8333333333333334,"• The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
• The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
• It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
• It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
• For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
• If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text."
EXPERIMENTS COMPUTE RESOURCES,0.8365384615384616,8. Experiments Compute Resources
EXPERIMENTS COMPUTE RESOURCES,0.8397435897435898,"Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?"
EXPERIMENTS COMPUTE RESOURCES,0.842948717948718,Answer: [Yes]
EXPERIMENTS COMPUTE RESOURCES,0.8461538461538461,Justification: We provide the details of our computer that used to run those experiments.
EXPERIMENTS COMPUTE RESOURCES,0.8493589743589743,Guidelines:
EXPERIMENTS COMPUTE RESOURCES,0.8525641025641025,"• The answer NA means that the paper does not include experiments.
• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
• The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
• The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper)."
CODE OF ETHICS,0.8557692307692307,9. Code Of Ethics
CODE OF ETHICS,0.8589743589743589,"Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?"
CODE OF ETHICS,0.8621794871794872,Answer: [Yes]
CODE OF ETHICS,0.8653846153846154,Justification: We used open-source neural spiking data from animals.
CODE OF ETHICS,0.8685897435897436,Guidelines:
CODE OF ETHICS,0.8717948717948718,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
• If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction)."
BROADER IMPACTS,0.875,10. Broader Impacts
BROADER IMPACTS,0.8782051282051282,"Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?"
BROADER IMPACTS,0.8814102564102564,Answer: [NA]
BROADER IMPACTS,0.8846153846153846,"Justification: The data we used came from neuron activities in the brains. Nothing is related
to humans."
BROADER IMPACTS,0.8878205128205128,Guidelines:
BROADER IMPACTS,0.8910256410256411,• The answer NA means that there is no societal impact of the work performed.
BROADER IMPACTS,0.8942307692307693,"• If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
• Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
• The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
• The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
• If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML)."
SAFEGUARDS,0.8974358974358975,11. Safeguards
SAFEGUARDS,0.9006410256410257,"Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?"
SAFEGUARDS,0.9038461538461539,Answer: [NA]
SAFEGUARDS,0.907051282051282,Justification: The codes have been released by others already.
SAFEGUARDS,0.9102564102564102,Guidelines:
SAFEGUARDS,0.9134615384615384,"• The answer NA means that the paper poses no such risks.
• Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
• Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
• We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort."
LICENSES FOR EXISTING ASSETS,0.9166666666666666,12. Licenses for existing assets
LICENSES FOR EXISTING ASSETS,0.9198717948717948,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?"
LICENSES FOR EXISTING ASSETS,0.9230769230769231,Answer: [NA]
LICENSES FOR EXISTING ASSETS,0.9262820512820513,Justification: All the data and codes are open source
LICENSES FOR EXISTING ASSETS,0.9294871794871795,Guidelines:
LICENSES FOR EXISTING ASSETS,0.9326923076923077,"• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
• The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
• For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided."
LICENSES FOR EXISTING ASSETS,0.9358974358974359,"• If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
• For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
• If this information is not available online, the authors are encouraged to reach out to
the asset’s creators."
NEW ASSETS,0.9391025641025641,13. New Assets
NEW ASSETS,0.9423076923076923,"Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?"
NEW ASSETS,0.9455128205128205,Answer: [NA]
NEW ASSETS,0.9487179487179487,Justification: Everything is open source already.
NEW ASSETS,0.9519230769230769,Guidelines:
NEW ASSETS,0.9551282051282052,"• The answer NA means that the paper does not release new assets.
• Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
• The paper should discuss whether and how consent was obtained from people whose
asset is used.
• At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9583333333333334,14. Crowdsourcing and Research with Human Subjects
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9615384615384616,"Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9647435897435898,Answer: [NA]
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.967948717948718,Justification: Only authors do the experiments.
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9711538461538461,Guidelines:
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9743589743589743,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9775641025641025,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9807692307692307,"Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9839743589743589,Answer: [NA]
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9871794871794872,Justification: We used open source data.
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9903846153846154,Guidelines:
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9935897435897436,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9967948717948718,"• We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
• For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review."
