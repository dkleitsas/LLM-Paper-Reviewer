Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0024937655860349127,"Although Shapley values are theoretically appealing for explaining black-box
models, they are costly to calculate and thus impractical in settings that involve
large, high-dimensional models. To remedy this issue, we introduce FastSHAP,
a new method for estimating Shapley values in a single forward pass using a
learned explainer model. To enable efﬁcient training without requiring ground
truth Shapley values, we develop an approach to train FastSHAP via stochastic
gradient descent using a weighted least squares objective function. In our experi-
ments with tabular and image datasets, we compare FastSHAP to existing estima-
tion approaches and ﬁnd that it generates accurate explanations with an orders-of-
magnitude speedup."
INTRODUCTION,0.004987531172069825,"1
INTRODUCTION"
INTRODUCTION,0.007481296758104738,"With the proliferation of black-box models, Shapley values (Shapley, 1953) have emerged as a
popular explanation approach due to their strong theoretical properties (Lipovetsky and Conklin,
2001; Štrumbelj and Kononenko, 2014; Datta et al., 2016; Lundberg and Lee, 2017). In practice,
however, Shapley value-based explanations are known to have high computational complexity, with
an exact calculation requiring an exponential number of model evaluations (Van den Broeck et al.,
2021). Speed becomes a critical issue as models increase in size and dimensionality, and for the
largest models in ﬁelds such as computer vision and natural language processing, there is an unmet
need for signiﬁcantly faster Shapley value approximations that maintain high accuracy."
INTRODUCTION,0.00997506234413965,"Recent work has addressed the computational challenges with Shapley values using two main ap-
proaches. First, many works have proposed stochastic estimators (Castro et al., 2009; Štrumbelj
and Kononenko, 2014; Lundberg and Lee, 2017; Covert et al., 2020) that rely on sampling either
feature subsets or permutations; though often consistent, these estimators require many model eval-
uations and impose an undesirable trade-off between run-time and accuracy. Second, some works
have proposed model-speciﬁc approximations, e.g., for trees (Lundberg et al., 2020) or neural net-
works (Shrikumar et al., 2017; Chen et al., 2018b; Ancona et al., 2019; Wang et al., 2021); while
generally faster, these approaches can still require many model evaluations, often induce bias, and
typically lack ﬂexibility regarding the handling held-out features—a subject of ongoing debate in
the ﬁeld (Aas et al., 2019; Janzing et al., 2020; Frye et al., 2020; Covert et al., 2021)."
INTRODUCTION,0.012468827930174564,"Here, we introduce a new approach for efﬁcient Shapley value estimation: to achieve the fastest
possible run-time, we propose learning a separate explainer model that outputs precise Shapley value
estimates in a single forward pass. Naïvely, such a learning-based approach would seem to require
a large training set of ground truth Shapley values, which would be computationally intractable.
Instead, our approach trains an explainer model by minimizing an objective function inspired by
the Shapley value’s weighted least squares characterization (Charnes et al., 1988), which enables
efﬁcient gradient-based optimization."
INTRODUCTION,0.014962593516209476,"Our contributions. We introduce FastSHAP, an amortized approach for generating real-time Shap-
ley value explanations.1 We derive an objective function from the Shapley value’s weighted least"
INTRODUCTION,0.017456359102244388,"∗Equal contribution
1https://git.io/JCqFV (PyTorch), https://git.io/JCqbP (TensorFlow)"
INTRODUCTION,0.0199501246882793,Published as a conference paper at ICLR 2022
INTRODUCTION,0.022443890274314215,English
INTRODUCTION,0.02493765586034913,Springer
INTRODUCTION,0.02743142144638404,"FastSHAP
KernelSHAP
KernelSHAP-S
GradCAM"
INTRODUCTION,0.029925187032418952,"Integrated
 Gradients
SmoothGrad
DeepSHAP
CXPlain"
INTRODUCTION,0.032418952618453865,"Gas Pump
Tench"
INTRODUCTION,0.034912718204488775,Figure 1: Explanations generated by each method for Imagenette images.
INTRODUCTION,0.03740648379052369,"squares characterization and investigate several ways to reduce gradient variance during training.
Our experiments show that FastSHAP provides accurate Shapley value estimates with an orders-
of-magnitude speedup relative to non-amortized estimation approaches. Finally, we also ﬁnd that
FastSHAP generates high-quality image explanations (ﬁg. 1) that outperform gradient-based meth-
ods (e.g., IntGrad and GradCAM) on quantitative inclusion and exclusion metrics."
BACKGROUND,0.0399002493765586,"2
BACKGROUND"
BACKGROUND,0.04239401496259352,"In this section, we introduce notation used throughout the paper and provide an overview of Shapley
values and their weighted least squares characterization. Let x ∈X be a random vector consisting
of d features, or x = (x1, . . . , xd), and let y ∈Y = {1, . . . , K} be the response variable for a
classiﬁcation problem. We use s ∈{0, 1}d to denote subsets of the indices {1, . . . , d} and deﬁne
xs := {xi}i:si=1. The symbols x, y, s are random variables and x, y, s denote possible values. We
use 1 and 0 to denote vectors of ones and zeros in Rd, so that 1⊤s is a subset’s cardinality, and we
use ei to denote the ith standard basis vector. Finally, f(x; η) : X 7→∆K−1 is a model that outputs
a probability distribution over y given x, and fy(x; η) is the probability for the yth class."
"SHAPLEY VALUES
SHAPLEY VALUES WERE ORIGINALLY DEVELOPED AS A CREDIT ALLOCATION TECHNIQUE IN COOPERATIVE GAME THE-",0.04488778054862843,"2.1
SHAPLEY VALUES
Shapley values were originally developed as a credit allocation technique in cooperative game the-
ory (Shapley, 1953), but they have since been adopted to explain predictions from black-box ma-
chine learning models (Štrumbelj and Kononenko, 2014; Datta et al., 2016; Lundberg and Lee,
2017). For any value function (or set function) v : 2d 7→R, the Shapley values ϕ(v) ∈Rd, or
ϕi(v) ∈R for each feature i = 1, . . . , d, are given by the formula"
"SHAPLEY VALUES
SHAPLEY VALUES WERE ORIGINALLY DEVELOPED AS A CREDIT ALLOCATION TECHNIQUE IN COOPERATIVE GAME THE-",0.04738154613466334,ϕi(v) = 1 d X si̸=1
"SHAPLEY VALUES
SHAPLEY VALUES WERE ORIGINALLY DEVELOPED AS A CREDIT ALLOCATION TECHNIQUE IN COOPERATIVE GAME THE-",0.04987531172069826,"d −1
1⊤s"
"SHAPLEY VALUES
SHAPLEY VALUES WERE ORIGINALLY DEVELOPED AS A CREDIT ALLOCATION TECHNIQUE IN COOPERATIVE GAME THE-",0.05236907730673317,"−1
v(s + ei) −v(s)

.
(1)"
"SHAPLEY VALUES
SHAPLEY VALUES WERE ORIGINALLY DEVELOPED AS A CREDIT ALLOCATION TECHNIQUE IN COOPERATIVE GAME THE-",0.05486284289276808,"The difference v(s + ei) −v(s) represents the ith feature’s contribution to the subset s, and the
summation represents a weighted average across all subsets that do not include i. In the model
explanation context, the value function is chosen to represent how an individual prediction varies
as different subsets of features are removed. For example, given an input-output pair (x, y), the
prediction for the yth class can be represented by a value function vx,y deﬁned as"
"SHAPLEY VALUES
SHAPLEY VALUES WERE ORIGINALLY DEVELOPED AS A CREDIT ALLOCATION TECHNIQUE IN COOPERATIVE GAME THE-",0.057356608478802994,"vx,y(s) = link

E
p(x1−s) [fy (xs, x1−s; η)]

,
(2)"
"SHAPLEY VALUES
SHAPLEY VALUES WERE ORIGINALLY DEVELOPED AS A CREDIT ALLOCATION TECHNIQUE IN COOPERATIVE GAME THE-",0.059850374064837904,"where the held out features x1−s are marginalized out using their joint marginal distribution
p(x1−s), and a link function (e.g., logit) is applied to the model output. Recent work has debated
the properties of different value function formulations, particularly the choice of how to remove
features (Aas et al., 2019; Janzing et al., 2020; Frye et al., 2020; Covert et al., 2021). However,
regardless of the formulation, this approach to model explanation enjoys several useful theoretical
properties due to its use of Shapley values: for example, the attributions are zero for irrelevant fea-
tures, and they are guaranteed to sum to the model’s prediction. We direct readers to prior work for
a detailed discussion of these properties (Lundberg and Lee, 2017; Covert et al., 2021)."
"SHAPLEY VALUES
SHAPLEY VALUES WERE ORIGINALLY DEVELOPED AS A CREDIT ALLOCATION TECHNIQUE IN COOPERATIVE GAME THE-",0.06234413965087282,"Unfortunately, Shapley values also introduce computational challenges: the summation in eq. (1)
involves an exponential number of subsets, which makes it infeasible to calculate for large d. Fast
approximations are therefore required in practice, as we discuss next."
"SHAPLEY VALUES
SHAPLEY VALUES WERE ORIGINALLY DEVELOPED AS A CREDIT ALLOCATION TECHNIQUE IN COOPERATIVE GAME THE-",0.06483790523690773,Published as a conference paper at ICLR 2022
KERNELSHAP,0.06733167082294264,"2.2
KERNELSHAP
KernelSHAP (Lundberg and Lee, 2017) is a popular Shapley value implementation that relies on
an alternative Shapley value interpretation. Given a value function vx,y(s), eq. (1) shows that the
values ϕ(vx,y) are the features’ weighted average contributions; equivalently, their weighted least
squares characterization says that they are the solution to an optimization problem over ϕx,y ∈Rd,"
KERNELSHAP,0.06982543640897755,"ϕ(vx,y) = arg min
ϕx,y
E
p(s)"
KERNELSHAP,0.07231920199501247,"h 
vx,y(s) −vx,y(0) −s⊤ϕx,y
2i (3)"
KERNELSHAP,0.07481296758104738,"s.t.
1⊤ϕx,y = vx,y(1) −vx,y(0),
(Efﬁciency constraint)"
KERNELSHAP,0.0773067331670823,where the distribution p(s) is deﬁned as
KERNELSHAP,0.0798004987531172,"p(s) ∝
d −1
  d
1⊤s

· 1⊤s · (d −1⊤s)
(Shapley kernel)"
KERNELSHAP,0.08229426433915212,"for s such that 0 < 1⊤s < d (Charnes et al., 1988). Based on this view of the Shapley value,
Lundberg and Lee (2017) introduced KernelSHAP, a stochastic estimator that solves an approxi-
mate version of eq. (3) given some number of subsets sampled from p(s). Although the estimator
is consistent and empirically unbiased (Covert and Lee, 2021), KernelSHAP often requires many
samples to achieve an accurate estimate, and it must solve eq. (3) separately for each input-output
pair (x, y). As a result, it is unacceptably slow for some use cases, particularly in settings with large,
high-dimensional models. Our approach builds on KernelSHAP, leveraging the Shapley value’s
weighted least squares characterization to design a faster, amortized estimation approach."
FASTSHAP,0.08478802992518704,"3
FASTSHAP"
FASTSHAP,0.08728179551122195,"We now introduce FastSHAP, a method that amortizes the cost of generating Shapley values across
many data samples. FastSHAP has two main advantages over existing approaches: (1) it avoids
solving separate optimization problems for each input to be explained, and (2) it can use similar
data points to efﬁciently learn the Shapley value function ϕ(vx,y)."
AMORTIZING SHAPLEY VALUES,0.08977556109725686,"3.1
AMORTIZING SHAPLEY VALUES
In our approach, we propose generating Shapley value explanations using a learned parametric func-
tion ϕfast(x, y; θ) : X × Y 7→Rd. Once trained, the parametric function can generate explanations
in a single forward pass, providing a signiﬁcant speedup over methods that approximate Shapley val-
ues separately for each sample (x, y). Rather than using a dataset of ground truth Shapley values for
training, we train ϕfast(x, y; θ) by penalizing its predictions according to the weighted least squares
objective in eq. (3), or by minimizing the following loss,"
AMORTIZING SHAPLEY VALUES,0.09226932668329177,"L(θ) = E
p(x)
E
Unif(y) E
p(s)"
AMORTIZING SHAPLEY VALUES,0.09476309226932668,"h 
vx,y(s) −vx,y(0) −s⊤ϕfast(x, y; θ)
2i
,
(4)"
AMORTIZING SHAPLEY VALUES,0.09725685785536159,"where Unif(y) represents a uniform distribution over classes. If the model’s predictions are forced
to satisfy the Efﬁciency constraint, then given a large enough dataset and a sufﬁciently expressive
model class for ϕfast, the global optimizer ϕfast(x, y; θ∗) is a function that outputs exact Shapley
values (see proof in appendix A). Formally, the global optimizer satisﬁes the following:"
AMORTIZING SHAPLEY VALUES,0.09975062344139651,"ϕfast(x, y; θ∗) = ϕ(vx,y) almost surely in p(x, y).
(5)
We explore two approaches to address the efﬁciency requirement. First, we can enforce efﬁciency
by adjusting the Shapley value predictions using their additive efﬁcient normalization (Ruiz et al.,
1998), which applies the following operation to the model’s outputs:"
AMORTIZING SHAPLEY VALUES,0.10224438902743142,"ϕeff
fast(x, y; θ) = ϕfast(x, y; θ) + 1 d"
AMORTIZING SHAPLEY VALUES,0.10473815461346633,"
vx,y(1) −vx,y(0) −1⊤ϕfast(x, y; θ)
"
AMORTIZING SHAPLEY VALUES,0.10723192019950124,"|
{z
}
Efﬁciency gap .
(6)"
AMORTIZING SHAPLEY VALUES,0.10972568578553615,"The normalization step can be applied at inference time and optionally during training; in ap-
pendix B, we show that this step is guaranteed to make the estimates closer to the true Shapley values.
Second, we can relax the efﬁciency property by augmenting L(θ) with a penalty on the efﬁciency
gap (see eq. (6)); the penalty requires a parameter γ > 0, and as we set γ →∞we can guarantee
that efﬁciency holds (see appendix A). Algorithm 1 summarizes our training approach."
AMORTIZING SHAPLEY VALUES,0.11221945137157108,Published as a conference paper at ICLR 2022
AMORTIZING SHAPLEY VALUES,0.11471321695760599,"Empirical considerations.
Optimizing L(θ) using a single set of samples (x, y, s) is problematic
because of high variance in the gradients, which can lead to poor optimization. We therefore consider
several steps to reduce gradient variance. First, as is conventional in deep learning, we minibatch
across multiple samples from p(x). Next, when possible, we calculate the loss jointly across all
classes y ∈{1, . . . , K}. Then, we experiment with using multiple samples s ∼p(s) for each input
sample x. Finally, we explore paired sampling, where each sample s is paired with its complement
1−s, which has been shown to reduce KernelSHAP’s variance (Covert and Lee, 2021). Appendix C"
AMORTIZING SHAPLEY VALUES,0.1172069825436409,"shows proofs that these steps are guaranteed to reduce gradient variance, and ablation experiments
in appendix D demonstrate their improvement on FastSHAP’s accuracy."
A DEFAULT VALUE FUNCTION FOR FASTSHAP,0.11970074812967581,"3.2
A DEFAULT VALUE FUNCTION FOR FASTSHAP"
A DEFAULT VALUE FUNCTION FOR FASTSHAP,0.12219451371571072,"Algorithm 1: FastSHAP training
Input: Value function vx,y, learning rate α
Output: FastSHAP explainer ϕfast(x, y; θ)
initialize ϕfast(x, y; θ)
while not converged do"
A DEFAULT VALUE FUNCTION FOR FASTSHAP,0.12468827930174564,"sample x ∼p(x), y ∼Unif(y), s ∼p(s)
predict ˆϕ ←ϕfast(x, y; θ)
if normalize then"
A DEFAULT VALUE FUNCTION FOR FASTSHAP,0.12718204488778054,"set ˆϕ ←
ˆϕ+d−1 
vx,y(1) −vx,y(0) −1T ˆϕ
"
A DEFAULT VALUE FUNCTION FOR FASTSHAP,0.12967581047381546,"end
calculate
L ←

vx,y(s) −vx,y(0) −sT ˆϕ
2"
A DEFAULT VALUE FUNCTION FOR FASTSHAP,0.13216957605985039,"update θ ←θ −α∇θL
end"
A DEFAULT VALUE FUNCTION FOR FASTSHAP,0.13466334164588528,"FastSHAP has the ﬂexibility to work with
any value function vx,y(s).
Here, we de-
scribe a default value function that is useful
for explaining predictions from a classiﬁca-
tion model."
A DEFAULT VALUE FUNCTION FOR FASTSHAP,0.1371571072319202,"The value function’s aim is to assess, for
each subset s, the classiﬁcation probability
when only the features xs are observed. Be-
cause most models f(x; η) do not support
making predictions without all the features,
we require an approximation that simulates
the inclusion of only xs (Covert et al., 2021).
To this end, we use a supervised surrogate
model (Frye et al., 2020; Jethani et al., 2021)
to approximate marginalizing out the remain-
ing features x1−s using their conditional dis-
tribution."
A DEFAULT VALUE FUNCTION FOR FASTSHAP,0.1396508728179551,"Separate from the original model f(x; η), the surrogate model psurr(y | m(x, s); β) takes as input
a vector of masked features m(x, s), where the masking function m replaces features xi such that
si = 0 with a [mask] value that is not in the support of X. Similar to prior work (Frye et al., 2020;
Jethani et al., 2021), the parameters β are learned by minimizing the following loss function:"
A DEFAULT VALUE FUNCTION FOR FASTSHAP,0.14214463840399003,"L(β) = E
p(x) E
p(s)"
A DEFAULT VALUE FUNCTION FOR FASTSHAP,0.14463840399002495,"h
DKL
 
f(x; η) || psurr(y | m(x, s); β)
i
.
(7)"
A DEFAULT VALUE FUNCTION FOR FASTSHAP,0.14713216957605985,"It has been shown that the global optimizer to eq. (7), or psurr(y | m(x, s); β∗), is equiva-
lent to marginalizing out features from f(x; η) with their conditional distribution (Covert et al.,
2021):"
A DEFAULT VALUE FUNCTION FOR FASTSHAP,0.14962593516209477,"psurr(y | m(x, s); β∗) = E[fy(x; η) | xs = xs].
(8)"
A DEFAULT VALUE FUNCTION FOR FASTSHAP,0.15211970074812967,"The choice of distribution over p(s) does not affect the global optimizer of eq. (7), but we use the
Shapley kernel to put more weight on subsets likely to be encountered when training FastSHAP. We
use the surrogate model as a default choice for two reasons. First, it requires a single prediction for
each evaluation of vx,y(s), which permits faster training than the common approach of averaging
across many background samples (Lundberg and Lee, 2017; Janzing et al., 2020). Second, it yields
explanations that reﬂect the model’s dependence on the information communicated by each feature,
rather than its algebraic dependence (Frye et al., 2020; Covert et al., 2021)."
RELATED WORK,0.1546134663341646,"4
RELATED WORK"
RELATED WORK,0.1571072319201995,"Recent work on Shapley value explanations has largely focused on how to remove features (Aas
et al., 2019; Frye et al., 2020; Covert et al., 2021) and how to approximate Shapley values efﬁ-
ciently (Chen et al., 2018b; Ancona et al., 2019; Lundberg et al., 2020; Covert and Lee, 2021).
Model-speciﬁc approximations are relatively fast, but they often introduce bias and are entangled
with speciﬁc feature removal approaches (Shrikumar et al., 2017; Ancona et al., 2019; Lundberg
et al., 2020). In contrast, model-agnostic stochastic approximations are more ﬂexible, but they must
trade off run-time and accuracy in the explanation. For example, KernelSHAP samples subsets to
approximate the solution to a weighted least squares problem (Lundberg and Lee, 2017), while other"
RELATED WORK,0.1596009975062344,Published as a conference paper at ICLR 2022
RELATED WORK,0.16209476309226933,"0
250
500
750
1000 1250 1500
# Evals 0.00 0.05 0.10 0.15 0.20 0.25"
RELATED WORK,0.16458852867830423,Mean 2 distance News
RELATED WORK,0.16708229426433915,"KernelSHAP
KernelSHAP (Paired)
Permutation Sampling
Permutation Sampling (Antithetical)
FastSHAP"
RELATED WORK,0.16957605985037408,"0
200
400
600
800
1000
1200
# Evals 0.00 0.05 0.10 0.15"
CENSUS,0.17206982543640897,"0.20
Census"
CENSUS,0.1745635910224439,"0
500
1000
1500
2000
# Evals 0.000 0.025 0.050 0.075 0.100 0.125 0.150"
CENSUS,0.1770573566084788,Bankruptcy
CENSUS,0.17955112219451372,"Figure 2: Comparison of Shapley value approximation accuracy across methods. Using three datasets,
we measure the distance of each method’s estimates to the ground truth as a function of the number of model
evaluations. FastSHAP is represented by a horizontal line since it requires only a single forward pass. The
baselines require 200−2000× model evaluations to achieve FastSHAP’s level of accuracy."
CENSUS,0.18204488778054864,"approaches sample marginal contributions (Castro et al., 2009; Štrumbelj and Kononenko, 2014) or
feature permutations (Illés and Kerényi, 2019; Mitchell et al., 2021). FastSHAP trains an explainer
model to output an estimate that would otherwise require orders of magnitude more model evalu-
ations, and, unlike other fast approximations, it is agnostic to the model class and feature removal
approach."
CENSUS,0.18453865336658354,"Other methods have been proposed to generate explanations using learned explainer models. These
are referred to as amortized explanation methods (Covert et al., 2021; Jethani et al., 2021), and
they include several approaches that are comparable to gradient-based methods in terms of compute
time (Dabkowski and Gal, 2017; Chen et al., 2018a; Yoon et al., 2018; Schwab and Karlen, 2019;
Schulz et al., 2020; Jethani et al., 2021). Notably, one approach generates a training dataset of ground
truth explanations and then learns an explainer model to output explanations directly (Schwab and
Karlen, 2019)—a principle that can be applied with any attribution method, at least in theory. How-
ever, for Shapley values, generating a large training set would be very costly, so FastSHAP sidesteps
the need for a training set using a custom loss function based on the Shapley value’s weighted least
squares characterization (Charnes et al., 1988)."
STRUCTURED DATA EXPERIMENTS,0.18703241895261846,"5
STRUCTURED DATA EXPERIMENTS"
STRUCTURED DATA EXPERIMENTS,0.18952618453865336,"We analyze FastSHAP’s performance by comparing it to several well-understood baselines. First,
we evaluate its accuracy on tabular (structured) datasets by comparing its outputs to the ground
truth Shapley values. Then, to disentangle the beneﬁts of amortization from the in-distribution
value function, we make the same comparisons using different value function formulations vx,y(s).
Unless otherwise stated, we use the surrogate model value function introduced in section 3.2. Later,
in section 6, we test FastSHAP’s ability to generate image explanations."
STRUCTURED DATA EXPERIMENTS,0.19201995012468828,"Baseline methods.
To contextualize FastSHAP’s accuracy, we compare it to several non-
amortized stochastic estimators. First, we compare to KernelSHAP (Lundberg and Lee, 2017) and
its acceleration that uses paired sampling (Covert and Lee, 2021). Next, we compare to a permu-
tation sampling approach and its acceleration that uses antithetical sampling (Mitchell et al., 2021).
As a performance metric, we calculate the proximity to Shapley values that were obtained by run-
ning KernelSHAP to convergence; we use these values as our ground truth because KernelSHAP is
known to converge to the true Shapley values given inﬁnite samples (Covert and Lee, 2021). These
baselines were all run using an open-source implementation.2"
STRUCTURED DATA EXPERIMENTS,0.19451371571072318,"Implementation details.
We use either neural networks or tree-based models for each of f(x; η)
and psurr(y | m(x, s); β). The FastSHAP explainer model ϕfast(x, y; θ) is implemented with a
network g(x; θ) : X →Rd ×Y that outputs a vector of Shapley values for every y ∈Y; deep neural
networks are ideal for FastSHAP because they have high representation capacity, they can provide
many-to-many mappings, and they can be trained by stochastic gradient descent. Appendix D con-
tains more details about our implementation, including model classes, network architectures and
training hyperparameters."
STRUCTURED DATA EXPERIMENTS,0.1970074812967581,2https://github.com/iancovert/shapley-regression/ (License: MIT)
STRUCTURED DATA EXPERIMENTS,0.19950124688279303,Published as a conference paper at ICLR 2022
STRUCTURED DATA EXPERIMENTS,0.20199501246882792,"0
200
400
600
# Evals 0.00 0.02 0.04 0.06 0.08 0.10"
STRUCTURED DATA EXPERIMENTS,0.20448877805486285,Mean 2 distance
STRUCTURED DATA EXPERIMENTS,0.20698254364089774,Surrogate
STRUCTURED DATA EXPERIMENTS,0.20947630922693267,"KernelSHAP
KernelSHAP (Paired)
Permutation Sampling
Permutation Sampling (Antithetical)
FastSHAP"
STRUCTURED DATA EXPERIMENTS,0.2119700748129676,"0
200
400
600
# Evals 0.00 0.02 0.04 0.06 0.08"
BASELINE,0.2144638403990025,"0.10
Baseline"
BASELINE,0.2169576059850374,"0
250
500
750
1000 1250 1500
# Evals 0.00 0.02 0.04 0.06 0.08"
BASELINE,0.2194513715710723,Marginal
BASELINE,0.22194513715710723,"Figure 3: FastSHAP approximation accuracy for different value functions.
Using the marketing
dataset, we ﬁnd that FastSHAP provides accurate Shapley value estimates regardless of the value function
(surrogate, marginal, baseline), with the baselines requiring 200−1000× model evaluations to achieve Fast-
SHAP’s level of accuracy. Error bars represent 95% conﬁdence intervals."
BASELINE,0.22443890274314215,"We also perform a series of experiments to determine several training hyperparameters for FastSHAP,
exploring (1) whether or not to use paired sampling, (2) the number of subset samples to use, and
(3) how to best enforce the efﬁciency constraint. Based on the results (see appendix D), we use the
following settings for our tabular data experiments: we use paired sampling, between 32 and 64
samples of s per x sample, additive efﬁcient normalization during both training and inference, and
we set γ = 0 (since the normalization step is sufﬁcient to enforce efﬁciency)."
ACCURACY OF FASTSHAP EXPLANATIONS,0.22693266832917705,"5.1
ACCURACY OF FASTSHAP EXPLANATIONS"
ACCURACY OF FASTSHAP EXPLANATIONS,0.22942643391521197,"Here, we test whether FastSHAP’s estimates are close to the ground truth Shapley values. Our exper-
iments use data from a 1994 United States census, a bank marketing campaign, bankruptcy
statistics, and online news articles (Dua and Graff, 2017). The census data contains 12 input fea-
tures, and the binary label indicates whether a person makes over $50K a year (Kohavi et al., 1996).
The marketing dataset contains 17 input features, and the label indicates whether the customer
subscribed to a term deposit (Moro et al., 2014). The bankruptcy dataset contains 96 features de-
scribing various companies and whether they went bankrupt (Liang et al., 2016). The news dataset
contains 60 numerical features about articles published on Mashable, and our label indicates whether
the share count exceeds the median number (1400) (Fernandes et al., 2015). The datasets were each
split 80/10/10 for training, validation and testing."
ACCURACY OF FASTSHAP EXPLANATIONS,0.23192019950124687,"In ﬁg. 2, we show the distance of each method’s estimates to the ground truth as a function of the
number of model evaluations for the news, census and bankruptcy datasets. Figure 3 shows
results for the marketing dataset with three different value functions (see section 5.2). For the
baselines, each sample s requires evaluating the model given a subset of features, but since Fast-
SHAP requires only a single forward pass of ϕfast(x, y; θ), we show it as a horizontal line."
ACCURACY OF FASTSHAP EXPLANATIONS,0.2344139650872818,"To reach FastSHAP’s level of accuracy on the news, census and bankruptcy datasets, Ker-
nelSHAP requires between 1,200-2,000 model evaluations; like prior work (Covert and Lee, 2021),
we ﬁnd that paired sampling improves KernelSHAP’s rate of convergence, helping reach Fast-
SHAP’s accuracy in 250-1,000 model evaluations. The permutation sampling baselines tend to be
faster: the original version requires between 300-1,000 evaluations, and antithetical sampling takes
200-500 evaluations to reach an accuracy equivalent to FastSHAP. Across all four datasets, however,
FastSHAP achieves its level of accuracy at least at least 600× faster than the original version of
KernelSHAP, and 200× faster than the best non-amortized baseline."
DISENTANGLING AMORTIZATION AND THE CHOICE OF VALUE FUNCTION,0.23690773067331672,"5.2
DISENTANGLING AMORTIZATION AND THE CHOICE OF VALUE FUNCTION"
DISENTANGLING AMORTIZATION AND THE CHOICE OF VALUE FUNCTION,0.23940149625935161,"In this experiment, we verify that FastSHAP produces accurate Shapley value estimates regardless
of the choice of value function. We use the marketing dataset for this experiment and test the
following value functions:"
DISENTANGLING AMORTIZATION AND THE CHOICE OF VALUE FUNCTION,0.24189526184538654,"1. (Surrogate/In-distribution) vx,y(s) = psurr(y | m(x, s); β)"
DISENTANGLING AMORTIZATION AND THE CHOICE OF VALUE FUNCTION,0.24438902743142144,"2. (Marginal/Out-of-distribution) vx,y(s) = Ep(x1−s) [fy (xs, x1−s; η)]"
DISENTANGLING AMORTIZATION AND THE CHOICE OF VALUE FUNCTION,0.24688279301745636,"3. (Baseline removal) vx,y(s) = fy(xs, xb
1−s; η), where xb ∈X are ﬁxed baseline values (the
mean for continuous features and mode for discrete ones)"
DISENTANGLING AMORTIZATION AND THE CHOICE OF VALUE FUNCTION,0.24937655860349128,Published as a conference paper at ICLR 2022 Horse
DISENTANGLING AMORTIZATION AND THE CHOICE OF VALUE FUNCTION,0.2518703241895262,"FastSHAP
KernelSHAP
KernelSHAP-S
GradCAM"
DISENTANGLING AMORTIZATION AND THE CHOICE OF VALUE FUNCTION,0.2543640897755611,"Integrated
 Gradients
SmoothGrad
DeepSHAP
CXPlain"
DISENTANGLING AMORTIZATION AND THE CHOICE OF VALUE FUNCTION,0.256857855361596,"Bird
Airplane"
DISENTANGLING AMORTIZATION AND THE CHOICE OF VALUE FUNCTION,0.2593516209476309,Figure 4: Explanations generated by each method for CIFAR-10 images.
DISENTANGLING AMORTIZATION AND THE CHOICE OF VALUE FUNCTION,0.26184538653366585,"In ﬁg. 3 we compare FastSHAP to the same non-amortized baseline methods, where each method
generates Shapley value estimates using the value functions listed above. The results show that
FastSHAP maintains the same computational advantage across all three cases: to achieve the same
accuracy as FastSHAP’s single forward pass, the baseline methods require at least 200 model evalu-
ations, but in some cases up to nearly 1,000."
IMAGE EXPERIMENTS,0.26433915211970077,"6
IMAGE EXPERIMENTS"
IMAGE EXPERIMENTS,0.26683291770573564,"Images represent a challenging setting for Shapley values due to their high dimensionality and the
computational cost of model evaluation. We therefore compare FastSHAP to KernelSHAP on two
image datasets. We also consider several widely used gradient-based explanation methods, because
they are the most commonly used methods for explaining image classiﬁers."
DATASETS,0.26932668329177056,"6.1
DATASETS
We consider two popular image datasets for our experiments. CIFAR-10 (Krizhevsky et al., 2009)
contains 60,000 32 × 32 images across 10 classes, and we use 50,000 samples for training and
5,000 samples each for validation and testing. Each image is resized to 224 × 224 using bilinear
interpolation to interface with the ResNet-50 architecture (He et al., 2016). Figure 4 shows example
CIFAR-10 explanations generated by each method. The Imagenette dataset (Howard and Gugger,
2020), a subset of 10 classes from the ImageNet dataset, contains 13,394 total images. Each image
is cropped to keep the 224 × 224 central region, and the data is split 9,469/1,963/1,962. Example
Imagenette explanations are shown in ﬁg. 1."
EXPLANATION METHODS,0.2718204488778055,"6.2
EXPLANATION METHODS
We test three Shapley value estimators, FastSHAP, KernelSHAP, and DeepSHAP (Lundberg and
Lee, 2017), where the last is an existing approximation designed for neural networks. We test Ker-
nelSHAP with the zeros baseline value function, which we refer to simply as KernelSHAP, and
with the in-distribution surrogate value function, which we refer to as KernelSHAP-S. We also com-
pare these methods to the gradient-based explanation methods GradCAM (Selvaraju et al., 2017),
SmoothGrad (Smilkov et al., 2017) and IntGrad (Sundararajan et al., 2017). Gradient-based methods
are relatively fast and have therefore been widely adopted for explaining image classiﬁers. Finally,
we also compare to CXPlain (Schwab and Karlen, 2019), an amortized explanation method that
generates attributions that are not based on Shapley values."
EXPLANATION METHODS,0.2743142144638404,"Implementation details.
The models f(x; η) and psurr(y | m(x, s); β) are both ResNet-50 net-
works (He et al., 2016) pretrained on ImageNet and ﬁne-tuned on the corresponding imaging dataset.
FastSHAP, CXPlain, and KernelSHAP are all implemented to output 14×14 superpixel attributions
for each class. For FastSHAP, we parameterize ϕfast(x, y; θ) to output superpixel attributions: we
use an identical pretrained ResNet-50 but replace the ﬁnal layers with a 1 × 1 convolutional layer
so that the output is 14 × 14 × K (see details appendix D). We use an identical network to produce
attributions for CXPlain. For FastSHAP, we do not use additive efﬁcient normalization, and we
set γ = 0; we ﬁnd that this relaxation of the Shapley value’s efﬁciency property does not inhibit
FastSHAP’s ability to produce high-quality image explanations. KernelSHAP and KernelSHAP-S
are implemented using the shap3 package’s default parameters, and GradCAM, SmoothGrad, and
IntGrad are implemented using the tf-explain4 package’s default parameters."
EXPLANATION METHODS,0.27680798004987534,"3https://shap.readthedocs.io/en/latest/ (License: MIT)
4https://tf-explain.readthedocs.io/en/latest/ (License: MIT)"
EXPLANATION METHODS,0.2793017456359102,Published as a conference paper at ICLR 2022
QUALITATIVE REMARKS,0.2817955112219451,"6.3
QUALITATIVE REMARKS"
QUALITATIVE REMARKS,0.28428927680798005,"Explanations generated by each method are shown in ﬁg. 4 for CIFAR-10 and ﬁg. 1 for Imagenette
(see appendix E for more examples). While a qualitative evaluation is insufﬁcient to draw conclu-
sions about each method, we offer several remarks on these examples. FastSHAP, and to some extent
GradCAM, appear to reliably highlight the important objects, while the KernelSHAP explanations
are noisy and fail to localize important regions. To a lesser extent, CXPlain occasionally highlights
important regions. In comparison, the remaining methods (SmoothGrad, IntGrad and DeepSHAP)
are granulated and highlight only small parts of the key objects. Next, we consider quantitative
metrics that test these observations more systematically."
QUANTITATIVE EVALUATION,0.286783042394015,"6.4
QUANTITATIVE EVALUATION"
QUANTITATIVE EVALUATION,0.2892768079800499,"0
20
40
60
80
100
Exclusion % 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8"
QUANTITATIVE EVALUATION,0.29177057356608477,Top 1 Accuracy
QUANTITATIVE EVALUATION,0.2942643391521197,Exclusion Curve
QUANTITATIVE EVALUATION,0.2967581047381546,"0
20
40
60
80
100
Inclusion % 0.0 0.2 0.4 0.6 0.8"
QUANTITATIVE EVALUATION,0.29925187032418954,Top 1 Accuracy
QUANTITATIVE EVALUATION,0.30174563591022446,Inclusion Curve
QUANTITATIVE EVALUATION,0.30423940149625933,"KernelSHAP
KernelSHAP-S
GradCAM
Integrated Gradients
SmoothGrad
DeepSHAP
CXPlain
FastSHAP"
QUANTITATIVE EVALUATION,0.30673316708229426,"Figure 5: Imagenette inclusion and exclusion
curves. The change in top-1 accuracy as an in-
creasing percentage of the pixels estimated to be
important are excluded (top) or included (bottom)."
QUANTITATIVE EVALUATION,0.3092269326683292,"Evaluating the quality of Shapley value estimates
requires access to ground truth Shapley values,
which is computationally infeasible for images. In-
stead, we use two metrics that evaluate an expla-
nation’s ability to identify informative image re-
gions. These metrics build on several recent pro-
posals (Petsiuk et al., 2018; Hooker et al., 2018;
Jethani et al., 2021) and evaluate the model’s clas-
siﬁcation accuracy after including or excluding pix-
els according to their estimated importance."
QUANTITATIVE EVALUATION,0.3117206982543641,"Similar to Jethani et al. (2021), we begin by train-
ing a single evaluation model peval to approximate
the f(x; η) model’s output given a subset of fea-
tures; this serves as an alternative to training sepa-
rate models on each set of features (Hooker et al.,
2018) and offers a more realistic option than mask-
ing features with zeros (Schwab and Karlen, 2019).
This procedure is analogous to the psurr training
procedure in section 3.2, except it sets the subset
distribution to p(s) = Uniform({0, 1}d) to ensure
all subsets are equally weighted."
QUANTITATIVE EVALUATION,0.314214463840399,"Next, we analyze how the model’s predictions
change as we remove either important or unimpor-
tant features according to each explanation. Using
a set of 1,000 images, each image is ﬁrst labeled by
the original model f(x; η) using the most likely pre-
dicted class. We then use explanations generated by
each method to produce feature rankings and com-
pute the top-1 accuracy (a measure of agreement
with the original model) as we either include or ex-
clude the most important features, ranging from 0-
100%. The area under each curve (AUC) is termed the Inclusion AUC or Exclusion AUC."
QUANTITATIVE EVALUATION,0.3167082294264339,"These metrics match the idea that an accurate image explanation should (1) maximally degrade the
performance of peval when important features are excluded, and (2) maximally improve the perfor-
mance of peval when important features are included (Petsiuk et al., 2018; Hooker et al., 2018). The
explanations are evaluated by removing superpixels; for gradient-based methods, we coarsen the ex-
planations using the sum total importance within each superpixel. In appendix E, we replicate these
metrics using log-odds rather than top-1 accuracy, ﬁnding a similar ordering among methods."
QUANTITATIVE EVALUATION,0.3192019950124688,"Results.
Table 1 shows the Inclusion and Exclusion AUC achieved by each method for both
CIFAR-10 and Imagenette. In ﬁg. 5, we also present the curves used to generate these AUCs for
Imagenette. Lower Exclusion AUCs and higher Inclusion AUCs are better. These results show that
FastSHAP outperforms all baseline methods when evaluated with Exclusion AUC: when the pixels
identiﬁed as important by FastSHAP are removed from the images, the sharpest decline in top-1 ac-
curacy is observed. Additionally, FastSHAP performs well when evaluated on the basis of Inclusion
AUC, second only to KernelSHAP-S."
QUANTITATIVE EVALUATION,0.32169576059850374,Published as a conference paper at ICLR 2022
QUANTITATIVE EVALUATION,0.32418952618453867,"Table 1: Exclusion and Inclusion AUCs. Evaluation of each method on the basis of Exclusion AUC (lower
is better) and Inclusion AUC (higher is better) calculated using top-1 accuracy. Parentheses indicate 95%
conﬁdence intervals, and the best methods are bolded in each column."
QUANTITATIVE EVALUATION,0.3266832917705736,"CIFAR-10
Imagenette"
QUANTITATIVE EVALUATION,0.32917705735660846,"Exclusion AUC
Inclusion AUC
Exclusion AUC
Inclusion AUC"
QUANTITATIVE EVALUATION,0.3316708229426434,"FastSHAP
0.42 (0.41, 0.43)
0.78 (0.77, 0.79)
0.51 (0.49, 0.52)
0.79 (0.78, 0.80)
KernelSHAP
0.64 (0.63, 0.65)
0.78 (0.77, 0.79)
0.68 (0.67, 0.70)
0.77 (0.75, 0.78)
KernelSHAP-S
0.54 (0.52, 0.55)
0.86 (0.85, 0.87)
0.61 (0.60, 0.62)
0.82 (0.80, 0.83)
GradCAM
0.52 (0.51, 0.53)
0.76 (0.75, 0.77)
0.52 (0.50, 0.53)
0.74 (0.73, 0.76)
Integrated Gradients
0.55 (0.54, 0.56)
0.74 (0.73, 0.75)
0.65 (0.64, 0.67)
0.73 (0.71, 0.74)
SmoothGrad
0.70 (0.69, 0.71)
0.72 (0.71, 0.73)
0.72 (0.71, 0.73)
0.73 (0.72, 0.75)
DeepSHAP
0.65 (0.64, 0.66)
0.79 (0.78, 0.80)
0.69 (0.68, 0.71)
0.74 (0.73, 0.75)
CXPlain
0.56 (0.55, 0.57)
0.71 (0.70, 0.72)
0.60 (0.58, 0.61)
0.72 (0.71, 0.74)"
QUANTITATIVE EVALUATION,0.3341645885286783,"For Imagenette, GradCAM performs competitively with FastSHAP on Exclusion AUC and
KernelSHAP-S marginally beats FastSHAP on Inclusion AUC. KernelSHAP-S also outperforms
on Inclusion AUC with CIFAR-10, which is perhaps surprising given its high level of noise (ﬁg. 4).
However, KernelSHAP-S does not do as well when evaluated using Exclusion AUC, and GradCAM
does not do as well on Inclusion AUC. The remaining methods are, by and large, not competitive
on either metric (except DeepSHAP on CIFAR-10 Inclusion AUC). An accurate explanation should
perform well on both metrics, so these results show that FastSHAP provides the most versatile ex-
planations, because it is the only approach to excel at both Inclusion and Exclusion AUC."
QUANTITATIVE EVALUATION,0.33665835411471323,"Finally, we also test FastSHAP’s robustness to limited training data. In appendix E, we ﬁnd that
FastSHAP outperforms most baseline methods on Inclusion and Exclusion AUC when using just
25% of the Imagenette data, and that it remains competitive when using just 10%."
SPEED EVALUATION,0.33915211970074816,"6.5
SPEED EVALUATION
Table 2: Training and explanation run-times for
1,000 images (in minutes)."
SPEED EVALUATION,0.341645885286783,"CIFAR-10
Imagenette"
SPEED EVALUATION,0.34413965087281795,Explain
SPEED EVALUATION,0.34663341645885287,"FastSHAP
0.04
0.04
KernelSHAP
453.69
1089.50
KernelSHAP-S
460.10
586.12
GradCAM
0.38
0.30
IntGrad
0.91
0.92
SmoothGrad
1.00
1.05
DeepSHAP
5.39
6.01
CXPlain
0.04
0.04 Train"
SPEED EVALUATION,0.3491271820448878,"FastSHAP
693.57
146.49
KernelSHAP-S
362.03
73.22
CXPlain
538.49
93.00"
SPEED EVALUATION,0.3516209476309227,"The image experiments were run using 8 cores
of an Intel Xeon Gold 6148 processor and a sin-
gle NVIDIA Tesla V100. Table 2 records the
time required to explain 1,000 images. For Fast-
SHAP, KernelSHAP-S and CXPlain, we also
report the time required to train the surrogate
and/or explainer models."
SPEED EVALUATION,0.3541147132169576,"The amortized explanation methods, FastSHAP
and CXPlain, incur a ﬁxed training cost but very
low marginal cost for each explanation.
The
gradient-based methods are slightly slower, but
KernelSHAP requires signiﬁcantly more time.
These results suggest that FastSHAP is well
suited for real-time applications where it is cru-
cial to keep explanation times as low as possible. Further, when users need to explain a large quantity
of data, FastSHAP’s low explanation cost can quickly compensate for its training time."
DISCUSSION,0.3566084788029925,"7
DISCUSSION"
DISCUSSION,0.35910224438902744,"In this work, we introduced FastSHAP, a method for estimating Shapley values in a single for-
ward pass using a learned explainer model. To enable efﬁcient training, we sidestepped the need
for a training set and derived a learning approach from the Shapley value’s weighted least squares
characterization. Our experiments demonstrate that FastSHAP can produce accurate Shapley value
estimates while achieving a signiﬁcant speedup over non-amortized approaches, as well as more
accurate image explanations than popular gradient-based methods."
DISCUSSION,0.36159600997506236,"While Shapley values provide a strong theoretical grounding for model explanation, they have not
been widely adopted for explaining large-scale models due to their high computational cost. Fast-
SHAP can solve this problem, making fast and high-quality explanations possible in ﬁelds such as
computer vision and natural language processing. By casting model explanation as a learning prob-
lem, FastSHAP stands to beneﬁt as the state of deep learning advances, and it opens a new direction
of research for efﬁcient Shapley value estimation."
DISCUSSION,0.3640897755610973,Published as a conference paper at ICLR 2022
REPRODUCIBILITY,0.36658354114713215,"8
REPRODUCIBILITY"
REPRODUCIBILITY,0.3690773067331671,"Code to implement FastSHAP is available online in two separate repositories: https://github.
com/iancovert/fastshap contains a PyTorch implementation and https://github.
com/neiljethani/fastshap/ a TensorFlow implementation, both with examples of tabu-
lar and image data experiments. The complete code for our experiments is available at https:
//github.com/iclr1814/fastshap, and details are described throughout section 5 and"
REPRODUCIBILITY,0.371571072319202,"section 6, with model architectures and hyperparameters reported in appendix D. Proofs for our
theoretical claims are provided in appendix A, appendix B, and appendix C."
ACKNOWLEDGEMENTS,0.3740648379052369,"9
ACKNOWLEDGEMENTS"
ACKNOWLEDGEMENTS,0.3765586034912718,"We thank the reviewers for their thoughtful feedback, and we thank the Lee Lab for helpful dis-
cussions.
Neil Jethani was partially supported by NIH T32 GM136573.
Mukund Sudarshan
was partially supported by a PhRMA Foundation Predoctoral Fellowship.
Mukund Sudarshan
and Rajesh Ranganath were partly supported by NIH/NHLBI Award R01HL148248, and by NSF
Award 1922658 NRT-HDR: FUTURE Foundations, Translation, and Responsibility for Data Sci-
ence. Ian Covert and Su-In Lee were supported by the NSF Awards CAREER DBI-1552309 and
DBI-1759487; the NIH Awards R35GM128638 and R01NIAAG061132; and the American Cancer
Society Award 127332-RSG-15-097-01-TBG."
REFERENCES,0.3790523690773067,REFERENCES
REFERENCES,0.38154613466334164,"Aas, K., Jullum, M., and Løland, A. (2019). Explaining individual predictions when features are
dependent: More accurate approximations to Shapley values. arXiv preprint arXiv:1903.10464."
REFERENCES,0.38403990024937656,"Ancona, M., Oztireli, C., and Gross, M. (2019). Explaining deep neural networks with a polyno-
mial time algorithm for Shapley value approximation. In International Conference on Machine
Learning, pages 272–281. PMLR."
REFERENCES,0.3865336658354115,"Castro, J., Gómez, D., and Tejada, J. (2009). Polynomial calculation of the Shapley value based on
sampling. Computers & Operations Research, 36(5):1726–1730."
REFERENCES,0.38902743142144636,"Charnes, A., Golany, B., Keane, M., and Rousseau, J. (1988).
Extremal principle solutions of
games in characteristic function form: core, Chebychev and Shapley value generalizations. In
Econometrics of Planning and Efﬁciency, pages 123–133. Springer."
REFERENCES,0.3915211970074813,"Chen, J., Song, L., Wainwright, M., and Jordan, M. (2018a). Learning to explain: An information-
theoretic perspective on model interpretation. In International Conference on Machine Learning,
pages 883–892. PMLR."
REFERENCES,0.3940149625935162,"Chen, J., Song, L., Wainwright, M. J., and Jordan, M. I. (2018b). L-Shapley and C-Shapley: Efﬁcient
model interpretation for structured data. arXiv preprint arXiv:1808.02610."
REFERENCES,0.39650872817955113,"Chen, T. and Guestrin, C. (2016). XGBoost: A scalable tree boosting system. In Proceedings of the
22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages
785–794."
REFERENCES,0.39900249376558605,"Covert, I. and Lee, S.-I. (2021). Improving KernelSHAP: Practical Shapley value estimation using
linear regression. In International Conference on Artiﬁcial Intelligence and Statistics, pages 3457–
3465. PMLR."
REFERENCES,0.4014962593516209,"Covert, I., Lundberg, S., and Lee, S.-I. (2020). Understanding global feature contributions with
additive importance measures. Advances in Neural Information Processing Systems, 33."
REFERENCES,0.40399002493765584,"Covert, I., Lundberg, S., and Lee, S.-I. (2021). Explaining by removing: A uniﬁed framework for
model explanation. Journal of Machine Learning Research, 22(209):1–90."
REFERENCES,0.40648379052369077,"Cybenko, G. (1989). Approximation by superpositions of a sigmoidal function. Mathematics of
Control, Signals and Systems, 2(4):303–314."
REFERENCES,0.4089775561097257,"Dabkowski, P. and Gal, Y. (2017). Real time image saliency for black box classiﬁers. In Advances
in Neural Information Processing Systems, pages 6967–6976."
REFERENCES,0.4114713216957606,Published as a conference paper at ICLR 2022
REFERENCES,0.4139650872817955,"Datta, A., Sen, S., and Zick, Y. (2016). Algorithmic Transparency via Quantitative Input Inﬂuence:
Theory and Experiments with Learning Systems. In Proceedings - 2016 IEEE Symposium on
Security and Privacy, SP 2016, pages 598–617. Institute of Electrical and Electronics Engineers
Inc."
REFERENCES,0.4164588528678304,"Dua, D. and Graff, C. (2017). UCI machine learning repository."
REFERENCES,0.41895261845386533,"Fernandes, K., Vinagre, P., and Cortez, P. (2015). A proactive intelligent decision support system
for predicting the popularity of online news. In Portuguese Conference on Artiﬁcial Intelligence,
pages 535–546. Springer."
REFERENCES,0.42144638403990026,"Frye, C., de Mijolla, D., Begley, T., Cowton, L., Stanley, M., and Feige, I. (2020). Shapley explain-
ability on the data manifold. In International Conference on Learning Representations."
REFERENCES,0.4239401496259352,"He, K., Zhang, X., Ren, S., and Sun, J. (2016). Deep residual learning for image recognition. In
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 770–
778."
REFERENCES,0.42643391521197005,"Hooker, S., Erhan, D., Kindermans, P.-J., and Kim, B. (2018). A benchmark for interpretability
methods in deep neural networks. arXiv preprint arXiv:1806.10758."
REFERENCES,0.428927680798005,"Hornik, K. (1991). Approximation capabilities of multilayer feedforward networks. Neural Net-
works, 4(2):251–257."
REFERENCES,0.4314214463840399,"Howard, J. and Gugger, S. (2020). FastAI: A layered API for deep learning. Information, 11(2):108."
REFERENCES,0.4339152119700748,"Illés, F. and Kerényi, P. (2019). Estimation of the Shapley value by ergodic sampling. arXiv preprint
arXiv:1906.05224."
REFERENCES,0.43640897755610975,"Janzing, D., Minorics, L., and Blöbaum, P. (2020). Feature relevance quantiﬁcation in explainable
AI: A causal problem. In International Conference on Artiﬁcial Intelligence and Statistics, pages
2907–2916. PMLR."
REFERENCES,0.4389027431421446,"Jethani, N., Sudarshan, M., Aphinyanaphongs, Y., and Ranganath, R. (2021). Have we learned to
explain?: How interpretability methods can learn to encode predictions in their interpretations. In
International Conference on Artiﬁcial Intelligence and Statistics, pages 1459–1467. PMLR."
REFERENCES,0.44139650872817954,"Ke, G., Meng, Q., Finley, T., Wang, T., Chen, W., Ma, W., Ye, Q., and Liu, T.-Y. (2017). LightGBM:
A highly efﬁcient gradient boosting decision tree. Advances in Neural Information Processing
Systems, 30:3146–3154."
REFERENCES,0.44389027431421446,"Kohavi, R. et al. (1996). Scaling up the accuracy of naive-bayes classiﬁers: A decision-tree hybrid.
In Knowledge Discovery and Data Mining, volume 96, pages 202–207."
REFERENCES,0.4463840399002494,"Krizhevsky, A., Hinton, G., et al. (2009). Learning multiple layers of features from tiny images."
REFERENCES,0.4488778054862843,"Liang, D., Lu, C.-C., Tsai, C.-F., and Shih, G.-A. (2016). Financial ratios and corporate governance
indicators in bankruptcy prediction: A comprehensive study. European Journal of Operational
Research, 252(2):561–572."
REFERENCES,0.4513715710723192,"Lipovetsky, S. and Conklin, M. (2001). Analysis of regression in game theory approach. Applied
Stochastic Models in Business and Industry, 17(4):319–330."
REFERENCES,0.4538653366583541,"Lundberg, S. M., Erion, G., Chen, H., DeGrave, A., Prutkin, J. M., Nair, B., Katz, R., Himmel-
farb, J., Bansal, N., and Lee, S.-I. (2020). From local explanations to global understanding with
explainable AI for trees. Nature Machine Intelligence, 2(1):56–67."
REFERENCES,0.456359102244389,"Lundberg, S. M. and Lee, S.-I. (2017). A uniﬁed approach to interpreting model predictions. Ad-
vances in Neural Information Processing Systems, 30:4765–4774."
REFERENCES,0.45885286783042395,"Mitchell, R., Cooper, J., Frank, E., and Holmes, G. (2021). Sampling permutations for Shapley
value estimation. arXiv preprint arXiv:2104.12199."
REFERENCES,0.4613466334164589,"Moro, S., Cortez, P., and Rita, P. (2014). A data-driven approach to predict the success of bank
telemarketing. Decision Support Systems, 62:22–31."
REFERENCES,0.46384039900249374,Published as a conference paper at ICLR 2022
REFERENCES,0.46633416458852867,"Petsiuk, V., Das, A., and Saenko, K. (2018). RISE: Randomized input sampling for explanation of
black-box models. arXiv preprint arXiv:1806.07421."
REFERENCES,0.4688279301745636,"Ruiz, L. M., Valenciano, F., and Zarzuelo, J. M. (1998). The family of least square values for
transferable utility games. Games and Economic Behavior, 24(1-2):109–130."
REFERENCES,0.4713216957605985,"Schulz, K., Sixt, L., Tombari, F., and Landgraf, T. (2020). Restricting the ﬂow: Information bottle-
necks for attribution. arXiv preprint arXiv:2001.00396."
REFERENCES,0.47381546134663344,"Schwab, P. and Karlen, W. (2019). CXPlain: Causal explanations for model interpretation under
uncertainty. In Advances in Neural Information Processing Systems, pages 10220–10230."
REFERENCES,0.4763092269326683,"Selvaraju, R. R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., and Batra, D. (2017). Grad-
CAM: Visual explanations from deep networks via gradient-based localization. In Proceedings
of the IEEE International Conference on Computer Vision, pages 618–626."
REFERENCES,0.47880299251870323,"Shapley, L. S. (1953). A value for n-person games. Contributions to the Theory of Games, 2(28):307–
317."
REFERENCES,0.48129675810473815,"Shrikumar, A., Greenside, P., and Kundaje, A. (2017). Learning important features through propagat-
ing activation differences. In International Conference on Machine Learning, pages 3145–3153.
PMLR."
REFERENCES,0.4837905236907731,"Smilkov, D., Thorat, N., Kim, B., Viégas, F., and Wattenberg, M. (2017). Smoothgrad: removing
noise by adding noise. arXiv preprint arXiv:1706.03825."
REFERENCES,0.486284289276808,"Štrumbelj, E. and Kononenko, I. (2014). Explaining prediction models and individual predictions
with feature contributions. Knowledge and Information Systems, 41(3):647–665."
REFERENCES,0.48877805486284287,"Sundararajan, M., Taly, A., and Yan, Q. (2017). Axiomatic attribution for deep networks. In Inter-
national Conference on Machine Learning, pages 3319–3328. PMLR."
REFERENCES,0.4912718204488778,"Van den Broeck, G., Lykov, A., Schleich, M., and Suciu, D. (2021). On the tractability of SHAP
explanations. In Proceedings of the 35th Conference on Artiﬁcial Intelligence (AAAI)."
REFERENCES,0.4937655860349127,"Wang, R., Wang, X., and Inouye, D. I. (2021). Shapley explanation networks. In International
Conference on Learning Representations."
REFERENCES,0.49625935162094764,"Yoon, J., Jordon, J., and van der Schaar, M. (2018). INVASE: Instance-wise variable selection using
neural networks. In International Conference on Learning Representations."
REFERENCES,0.49875311720698257,Published as a conference paper at ICLR 2022
REFERENCES,0.5012468827930174,"A
FASTSHAP GLOBAL OPTIMIZER"
REFERENCES,0.5037406483790524,"Here, we prove that FastSHAP is trained using an objective function whose global optimizer outputs
the true Shapley values. Recall that the loss function for the explainer model ϕfast(x, y; θ) is"
REFERENCES,0.5062344139650873,"L(θ) = E
p(x)
E
Unif(y) E
p(s)"
REFERENCES,0.5087281795511222,"h 
vx,y(s) −vx,y(0) −s⊤ϕfast(x, y; θ)
2i
."
REFERENCES,0.5112219451371571,"As mentioned in the main text, it is necessary to force the model to satisfy the Efﬁciency constraint,
or the property that the predictions from ϕfast(x, y; θ) satisfy"
REFERENCES,0.513715710723192,"1⊤ϕfast(x, y; θ) = vx,y(1) −vx,y(0)
∀x ∈X, y ∈Y."
REFERENCES,0.516209476309227,"One option for guaranteeing the efﬁciency property is to adjust the model outputs using their additive
efﬁcient normalization (see section 3.1). Incorporating this constraint on the predictions, we can then
view the loss function as an expectation across (x, y) and write the expected loss for each sample
(x, y) as a separate optimization problem over the variable ϕx,y ∈Rd:"
REFERENCES,0.5187032418952618,"min
ϕx,y
E
p(s)"
REFERENCES,0.5211970074812967,"h 
vx,y(s) −vx,y(0) −s⊤ϕx,y
2i (9)"
REFERENCES,0.5236907730673317,"s.t.
ϕx,y = vx,y(1) −vx,y(0)."
REFERENCES,0.5261845386533666,"This is a constrained weighted least squares problem with a unique global minimizer, and it is
precisely the Shapley value’s weighted least squares characterization (see eq. (3)). We can therefore
conclude that the optimal prediction for each pair (x, y) is the true Shapley values, or that ϕ∗
x,y =
ϕ(vx,y). As a result, the global optimizer for our objective is a model ϕfast(x, y; θ∗) that outputs the
true Shapley values almost everywhere in the data distribution p(x, y)."
REFERENCES,0.5286783042394015,"Achieving the global optimum requires the ability to sample from p(x) (or a sufﬁciently large
dataset), perfect optimization, and a function class for ϕfast(x, y; θ) that is expressive enough to
contain the global optimizer. The universal approximation theorem (Cybenko, 1989; Hornik, 1991)
implies that a sufﬁciently large neural network can represent the Shapley value function to arbitrary
accuracy as long as it is a continuous function. Speciﬁcally, we require the function hy(x) = ϕ(vx,y)
to be continuous in x for all y. This holds in practice when we use a surrogate model parameterized
by a continuous neural network, because vx,y(s) is continuous in x for all (s, y), and the Shapley
value is a linear combination of vx,y(s) across different values of s (see eq. (1))."
REFERENCES,0.5311720698254364,"Another approach to enforce the efﬁciency property is by using efﬁciency regularization, or penal-
izing the efﬁciency gap in the explainer model’s predictions (section 3.1). If we incorporate this
regularization term with parameter γ > 0, then our objective yields the following optimization
problem for each (x, y) pair:"
REFERENCES,0.5336658354114713,"min
ϕx,y
E
p(s)"
REFERENCES,0.5361596009975063,"h 
vx,y(s) −vx,y(0) −s⊤ϕx,y
2i
+ γ
 
vx,y(1) −vx,y(0) −1⊤ϕx,y
2."
REFERENCES,0.5386533665835411,"For ﬁnite hyperparameter values γ ∈[0, ∞), this problem relaxes the Shapley value’s efﬁciency
property and eliminates the requirement that predictions must sum to the grand coalition’s value.
However, as we let γ →∞, the penalty term becomes closer to the hard constraint in eq. (9). Note
that in practice, we use ﬁnite values for γ and observe sufﬁciently accurate results, whereas using
excessively large γ values would render gradient-based optimization ineffective."
REFERENCES,0.5411471321695761,"B
ADDITIVE EFFICIENT NORMALIZATION"
REFERENCES,0.543640897755611,"Here, we provide a geometric interpretation for the additive efﬁcient normalization step and prove
that it is guaranteed to yield Shapley value estimates closer to their true values. Consider a game
v with Shapley values ϕ(v) ∈Rd, and assume that we have Shapley values estimates ˆϕ ∈Rd that
do not satisfy the efﬁciency property. To force this property to hold, we can project these estimates"
REFERENCES,0.5461346633416458,Published as a conference paper at ICLR 2022
REFERENCES,0.5486284289276808,"onto the efﬁcient hyperplane, or the subset of Rd where the efﬁciency property is satisﬁed. This
corresponds to solving the following optimization problem over ϕeﬀ∈Rd:"
REFERENCES,0.5511221945137157,"min
ϕeff ||ϕeﬀ−ˆϕ||2
s.t.
1⊤ϕeﬀ= v(1) −v(0)."
REFERENCES,0.5536159600997507,"We can solve the problem via its Lagrangian, denoted by L(ϕeﬀ, ν), with the Lagrange multiplier
ν ∈R as follows:"
REFERENCES,0.5561097256857855,"L(ϕeﬀ, ν) = ||ϕeﬀ−ˆϕ||2 + ν

v(1) −v(0) −1⊤ϕeﬀ
"
REFERENCES,0.5586034912718204,"⇒ϕ∗
eﬀ= ˆϕ −1v(1) −v(0) −1⊤ˆϕ d
."
REFERENCES,0.5610972568578554,"This transformation, where the efﬁciency gap is split evenly and added to each estimate, is known
as additive efﬁcient normalization (Ruiz et al., 1998). We implement it as an output layer for Fast-
SHAP’s predictions to ensure that they satisfy the efﬁciency property (section 3). This step can
therefore be understood as a projection of the network’s output onto the efﬁcient hyperplane."
REFERENCES,0.5635910224438903,"The normalization step is guaranteed to produce corrected estimates ϕ∗
eﬀthat are closer to the true
Shapley values ϕ(v) than the original estimates ˆϕ. To see this, note that the projection step guar-
antees that ˆϕ −ϕ∗
eﬀand ϕ∗
eﬀ−ϕ(v) are orthogonal vectors, so the Pythagorean theorem yields the
following inequality:"
REFERENCES,0.5660847880299252,"||ϕ(v) −ˆϕ||2 = ||ϕ(v) −ϕ∗
eﬀ||2 + ||ϕ∗
eﬀ−ˆϕ||2"
REFERENCES,0.5685785536159601,"≥||ϕ(v) −ϕ∗
eﬀ||2."
REFERENCES,0.571072319201995,"C
REDUCING GRADIENT VARIANCE"
REFERENCES,0.57356608478803,Recall that our objective function L(θ) is deﬁned as follows:
REFERENCES,0.5760598503740648,"L(θ) = E
p(x)
E
Unif(y) E
p(s)"
REFERENCES,0.5785536159600998,"h 
vx,y(s) −vx,y(0) −s⊤ϕfast(x, y; θ)
2i
."
REFERENCES,0.5810473815461347,The objective’s gradient is given by
REFERENCES,0.5835411471321695,"∇θL(θ) = E
p(x)
E
Unif(y) E
p(s)"
REFERENCES,0.5860349127182045,"h
∇(x, y, s; θ)
i
,
(10)"
REFERENCES,0.5885286783042394,where we deﬁne
REFERENCES,0.5910224438902744,"∇(x, y, s; θ) := ∇θ
 
vx,y(s) −vx,y(0) −s⊤ϕfast(x, y; θ)
2."
REFERENCES,0.5935162094763092,"When FastSHAP is trained with a single sample (x, y, s), the gradient covariance is given by
Cov
 
∇(x, y, s; θ)

, which may be too large for effective optimization. We use several strategies to
reduce gradient variance. First, given a model that outputs estimates for all classes y ∈{1, . . . , K},
we calculate the loss jointly for all classes. This yields gradients that we denote as ∇(x, s; θ), deﬁned
as"
REFERENCES,0.5960099750623441,"∇(x, s; θ) :=
E
Unif(y)[∇(x, y, s; θ)],"
REFERENCES,0.5985037406483791,where we have the relationship
REFERENCES,0.600997506234414,Published as a conference paper at ICLR 2022
REFERENCES,0.6034912718204489,"Cov
 
∇(x, s; θ)

⪯Cov
 
∇(x, y, s; θ)
"
REFERENCES,0.6059850374064838,"due to the law of total covariance. Next, we consider minibatches of b independent x samples, which
yields gradients ∇b(x, s; θ) with covariance given by"
REFERENCES,0.6084788029925187,"Cov
 
∇b(x, s; θ)

= 1"
REFERENCES,0.6109725685785536,"b Cov
 
∇(x, s; θ)

."
REFERENCES,0.6134663341645885,"We then consider sampling m independent coalitions s for each input x, resulting in the gradients
∇m
b (x, s; θ) with covariance given by"
REFERENCES,0.6159600997506235,"Cov
 
∇m
b (x, s; θ)

=
1
mbCov
 
∇(x, s; θ)

."
REFERENCES,0.6184538653366584,"Finally, we consider a paired sampling approach, where each sample s ∼p(s) is paired with its com-
plement 1 −s. Paired sampling has been shown to reduce KernelSHAP’s variance (Covert and Lee,
2021), and our experiments show that it helps improve FastSHAP’s accuracy (appendix D)."
REFERENCES,0.6209476309226932,"The training algorithm in the main text is simpliﬁed by omitting these gradient variance reduc-
tion techniques, so we also provide algorithm 2 below, which includes minibatching, multiple
coalition samples, paired sampling, efﬁciency regularization and parallelization over all output
classes."
REFERENCES,0.6234413965087282,"Algorithm 2: Full FastSHAP training
Input: Value function vx,y, learning rate α, batch size b, samples m, penalty parameter γ
Output: FastSHAP explainer ϕfast(x, y; θ)
initialize ϕfast(x, y; θ)
while not converged do"
REFERENCES,0.6259351620947631,"set R ←0, L ←0
for i = 1, . . . , b do"
REFERENCES,0.628428927680798,"sample x ∼p(x)
for y = 1, . . . , K do"
REFERENCES,0.6309226932668329,"predict ˆϕ ←ϕfast(x, y; θ)"
REFERENCES,0.6334164588528678,"calculate R ←R +

vx,y(1) −vx,y(0) −1⊤ˆϕ
2"
REFERENCES,0.6359102244389028,// Pre-normalization
REFERENCES,0.6384039900249376,if normalize then
REFERENCES,0.6408977556109726,"set ˆϕ ←ˆϕ + d−1 
vx,y(1) −vx,y(0) −1⊤ˆϕ
"
REFERENCES,0.6433915211970075,"end
for j = 1, . . . , m do"
REFERENCES,0.6458852867830424,if paired sampling and i mod 2 = 0 then
REFERENCES,0.6483790523690773,"set s ←1 −s
// Invert previous subset
else"
REFERENCES,0.6508728179551122,"sample s ∼p(s)
end"
REFERENCES,0.6533665835411472,"calculate L ←L +

vx,y(s) −vx,y(0) −s⊤ˆϕ
2"
REFERENCES,0.655860349127182,"end
end
end
update θ ←θ −α∇θ
 
L
bmK + γ R bK
 end"
REFERENCES,0.6583541147132169,Published as a conference paper at ICLR 2022
REFERENCES,0.6608478802992519,"0
20
40
60
# Training samples 0.05 0.10"
REFERENCES,0.6633416458852868,Mean 2 dist
REFERENCES,0.6658354114713217,Bankruptcy
REFERENCES,0.6683291770573566,"FastSHAP
FastSHAP (Paired Sampling)"
REFERENCES,0.6708229426433915,"0
20
40
60
# Training samples"
REFERENCES,0.6733167082294265,Census
REFERENCES,0.6758104738154613,"0
20
40
60
# Training samples"
REFERENCES,0.6783042394014963,Marketing
REFERENCES,0.6807980049875312,"0
20
40
60
# Training samples News"
REFERENCES,0.683291770573566,"Figure 6: FastSHAP accuracy as a function of the number of training samples. The results show that
using more s samples per x improves FastSHAP’s closeness to the ground truth Shapley values, as does the use
of paired sampling."
REFERENCES,0.685785536159601,"D
FASTSHAP MODELS AND HYPERPARAMETERS"
REFERENCES,0.6882793017456359,"In this section, we describe the models and architectures used for each dataset, as well as the hyper-
parameters used when training FastSHAP."
REFERENCES,0.6907730673316709,"D.1
MODELS
Tabular datasets.
For the original model f(x; η), we use neural networks for the news and
marketing datasets and gradient boosted trees for the census (LightGBM (Ke et al., 2017)) and
bankruptcy (XGBoost (Chen and Guestrin, 2016)) datasets. The FastSHAP model ϕfast(x, y; θ)
and the surrogate model psurr(y | m(x, s); β) are implemented using neural networks that consist of
2-3 fully connected layers with 128 units and ReLU activations. The psurr models use a softmax out-
put layer, while ϕfast has no output activation. The models are trained using Adam with a learning
rate of 10−3, and we use a learning rate scheduler that multiplies the learning rate by a factor of 0.5
after 3 epochs of no validation loss improvement. Early stopping was triggered after the validation
loss ceased to improve for 10 epochs."
REFERENCES,0.6932668329177057,"Image datasets. The models f(x; η) and psurr are ResNet-50 models pretrained on Imagenet. We
use these without modiﬁcation to the architecture and ﬁne-tune them on each image dataset. To
create the ϕfast(x, y; θ) model, we modify the architecture to return a tensor of size 14 × 14 × K.
First, the layers after the 4th convolutional block are removed; the output of this block is 14 × 14 ×
256. We then append a 2D convolutional layer with K ﬁlters, each of size 1 × 1, so that the output
is 14×14×K and the yth 14×14 slice corresponds to the superpixel-level Shapley values for each
class y ∈Y. Each model is trained using Adam with a learning rate of 10−3, and we use a learning
rate scheduler that multiplies the learning rate by a factor of 0.8 after 3 epochs of no validation
loss improvement. Early stopping was triggered after the validation loss ceased to improve for 20
epochs."
REFERENCES,0.6957605985037406,"D.2
FASTSHAP HYPERPARAMETERS
We now explore various settings of FastSHAP’s hyperparameters and observe their impact on Fast-
SHAP’s performance. There are two types of hyperparameters: sampling hyperparameters, which
affect the number of samples of s taken during training, and efﬁciency hyperparameters, which con-
trol how we enforce the Efﬁciency constraint. Sampling hyperparameters include: (1) whether to
use paired sampling, and (2) the number of samples of s per x to take during training. Efﬁciency
hyperparameters include: (1) the choice of γ in eq. (4), and (2) whether to perform the additive
efﬁcient normalization during training, inference or both."
REFERENCES,0.6982543640897756,"To understand the effect of sampling hyperparameters, we perform experiments using the same
tabular datasets from the main text. We use the in-distribution value function psurr and compute
the ground truth SHAP values the same way as in our previous experiments (i.e., by running Ker-
nelSHAP to convergence)."
REFERENCES,0.7007481296758105,"Figure 6 shows the mean ℓ2 distance between FastSHAP’s estimates and the ground truth. We ﬁnd
that across all four datasets, increasing the number of training samples of s generally improves the
mean ℓ2 distance to ground truth. We also ﬁnd that for any ﬁxed number of samples (greater than 1),
using paired sampling improves FastSHAP’s accuracy."
REFERENCES,0.7032418952618454,"Table 3 shows the results of an ablation study for the efﬁciency hyperparameters. Normalization
(or Norm.) refers to the additive efﬁcient normalization step (applied during training and inference,"
REFERENCES,0.7057356608478803,Published as a conference paper at ICLR 2022
REFERENCES,0.7082294264339152,"Table 3: FastSHAP ablation results. The distance to the ground truth Shapley values is displayed for several
FastSHAP variations, showing that normalization helps and that the penalty is unnecessary."
REFERENCES,0.7107231920199502,"Census
Bankruptcy"
REFERENCES,0.713216957605985,"ℓ2
ℓ1
ℓ2
ℓ1"
REFERENCES,0.71571072319202,"Normalization
0.0229
0.0863
0.0295
0.2436
Normalization + Penalty
0.0261
0.0971
0.0320
0.2740
Inference Norm.
0.0406
0.1512
0.0407
0.3450
Inference Norm. + Penalty
0.0452
0.1671
0.0473
0.4471
No Norm.
0.0501
0.1933
0.0408
0.3474
No Norm. + Penalty
0.0513
0.1926
0.0474
0.4490"
REFERENCES,0.7182044887780549,"or only during inference), and penalty refers to the efﬁciency regularization technique with the
parameter set to γ = 0.1. We ﬁnd that using normalization during training uniformly achieves
better results than without normalization or with normalization only during inference. The efﬁciency
regularization approach proves to be less effective, generally leading to less accurate Shapley value
estimates. Based on these results, we opt to use additive efﬁcient normalization in our tabular data
experiments."
REFERENCES,0.7206982543640897,"E
ADDITIONAL RESULTS FOR IMAGE EXPERIMENTS"
REFERENCES,0.7231920199501247,"In this section, we provide additional results for the FastSHAP image experiments."
REFERENCES,0.7256857855361596,"E.1
INCLUSION AND EXCLUSION METRICS
Table 4 shows our inclusion and exclusion metrics when replicated using log-odds rather than accu-
racy. Similar to our metrics described in the main text, we choose the class predicted by the original
model for each image, and we measure the average log-odds for that class as we include or exclude
important features according to the explanations generated by each method. The results conﬁrm
roughly the same ordering between methods, with FastSHAP being the only method to achieve
strong results on both metrics for both datasets. Figure 7 shows the raw inclusion and exclusion
curves for both the accuracy and log-odds-derived metrics."
REFERENCES,0.7281795511221946,Table 4: Exclusion and Inclusion AUCs calculated using the average log-odds of the predicted class.
REFERENCES,0.7306733167082294,"CIFAR-10
Imagenette"
REFERENCES,0.7331670822942643,"Exclusion AUC
Inclusion AUC
Exclusion AUC
Inclusion AUC"
REFERENCES,0.7356608478802993,"FastSHAP
5.92 (5.62, 6.14)
5.36 (5.16, 5.63)
7.98 (7.68, 8.33)
5.40 (5.16, 5.60)
KernelSHAP
9.88 (9.55, 10.20)
5.36 (5.14, 5.63)
10.68 (10.36, 11.00)
5.07 (4.81, 5.31)
KernelSHAP-S
8.01 (7.68, 8.34)
6.80 (6.65, 6.96)
9.39 (9.11, 9.66)
6.01 (5.78, 6.26)
GradCAM
7.75 (7.44, 8.09)
4.99 (4.81, 5.26)
7.77 (7.49, 8.05)
4.65 (4.40, 4.89)
Integrated Gradients
8.34 (8.03, 8.61)
4.58 (4.37, 4.85)
10.14 (9.79, 10.46)
4.34 (4.10, 4.58)
SmoothGrad
10.99 (10.67, 11.29)
4.30 (4.08, 4.58)
11.19 (10.84, 11.48)
4.47 (4.24, 4.70)
DeepSHAP
9.96 (9.61, 10.24)
5.47 (5.28, 5.76)
10.93 (10.61, 11.20)
4.63 (4.38, 4.85)
CXPlain
8.34 (8.00, 8.58)
4.02 (3.80, 4.31)
9.13 (8.83, 9.41)
4.33 (4.11, 4.57)"
REFERENCES,0.7381546134663342,Published as a conference paper at ICLR 2022
REFERENCES,0.7406483790523691,"0
20
40
60
80
100
Exclusion % 8 6 4 2 0 2 4 6"
REFERENCES,0.743142144638404,Log Odds
REFERENCES,0.7456359102244389,Exclusion Curve
REFERENCES,0.7481296758104738,"0
20
40
60
80
100
Inclusion % 6 4 2 0 2 4 6"
REFERENCES,0.7506234413965087,Log Odds
REFERENCES,0.7531172069825436,Inclusion Curve
REFERENCES,0.7556109725685786,"KernelSHAP
KernelSHAP-S
GradCAM
Integrated Gradients
SmoothGrad
DeepSHAP
CXPlain
FastSHAP"
REFERENCES,0.7581047381546134,(a) Imagenette: Log-odds derived inclusion and exclusion curves.
REFERENCES,0.7605985037406484,"0
20
40
60
80
100
Exclusion % 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9"
REFERENCES,0.7630922693266833,Top 1 Accuracy
REFERENCES,0.7655860349127181,Exclusion Curve
REFERENCES,0.7680798004987531,"0
20
40
60
80
100
Inclusion % 0.0 0.2 0.4 0.6 0.8"
REFERENCES,0.770573566084788,Top 1 Accuracy
REFERENCES,0.773067331670823,Inclusion Curve
REFERENCES,0.7755610972568578,"KernelSHAP
KernelSHAP-S
GradCAM
Integrated Gradients
SmoothGrad
DeepSHAP
CXPlain
FastSHAP"
REFERENCES,0.7780548628428927,(b) CIFAR-10: Accuracy derived inclusion and exclusion curves.
REFERENCES,0.7805486284289277,"0
20
40
60
80
100
Exclusion % 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9"
REFERENCES,0.7830423940149626,Top 1 Accuracy
REFERENCES,0.7855361596009975,Exclusion Curve
REFERENCES,0.7880299251870324,"0
20
40
60
80
100
Inclusion % 0.0 0.2 0.4 0.6 0.8"
REFERENCES,0.7905236907730673,Top 1 Accuracy
REFERENCES,0.7930174563591023,Inclusion Curve
REFERENCES,0.7955112219451371,"KernelSHAP
KernelSHAP-S
GradCAM
Integrated Gradients
SmoothGrad
DeepSHAP
CXPlain
FastSHAP"
REFERENCES,0.7980049875311721,(c) CIFAR-10: Log-odds derived inclusion and exclusion curves.
REFERENCES,0.800498753117207,"Figure 7:
Additional inclusion and exclusion curves. The change in top-1 accuracy or average log-odds
of the predicted class as an increasing percentage of the pixels estimated to be important are excluded (left) or
included (right) from the set of 1,000 images."
REFERENCES,0.8029925187032418,Published as a conference paper at ICLR 2022
REFERENCES,0.8054862842892768,"20
40
60
80
100
Percent of Dataset 0.525 0.550 0.575 0.600 0.625 0.650 0.675 0.700 0.725"
REFERENCES,0.8079800498753117,Exclusion AUC
REFERENCES,0.8104738154613467,Exclusion AUC Learning Curve
REFERENCES,0.8129675810473815,"20
40
60
80
100
Percent of Dataset 0.72 0.74 0.76 0.78 0.80 0.82"
REFERENCES,0.8154613466334164,Inclusion AUC
REFERENCES,0.8179551122194514,Inclusion AUC Learning Curve
REFERENCES,0.8204488778054863,"FastSHAP
KernelSHAP"
REFERENCES,0.8229426433915212,"KernelSHAP-S
GradCAM"
REFERENCES,0.8254364089775561,"Integrated Gradients
SmoothGrad"
REFERENCES,0.827930174563591,"DeepSHAP
CXPlain"
REFERENCES,0.830423940149626,"Figure 8: FastSHAP robustness to limited data. The curves are generated by training FastSHAP with
varying portions of the Imagenette dataset and evaluating the Inclusion and Exclusion AUC. Horizontal lines
show the Exclusion and Inclusion AUCs for each of the baseline methods, as reported in table 1."
REFERENCES,0.8329177057356608,"E.2
FASTSHAP ROBUSTNESS TO LIMITED DATA
To test FastSHAP’s robustness to the size of the training data, we compare its performance when
trained with varying amounts of the Imagenette dataset. Figure 8 plots the change in inclusion
and exclusion AUC, calculated using top-1 accuracy, achieved when training FastSHAP with 95%,
85%, 75%, 50%, 25%, 15%, 10%, and 5% of the training dataset. We ﬁnd that FastSHAP remains
competitive when using just 10% of the data, and that it outperforms most baseline methods by a
large margin when using just 25%."
REFERENCES,0.8354114713216958,Published as a conference paper at ICLR 2022
REFERENCES,0.8379052369077307,"E.3
EXAMPLE FASTSHAP IMAGE EXPLANATIONS
Finally, we show additional explanations generated by FastSHAP and the baseline methods for both
CIFAR-10 and Imagenette. -16.1"
REFERENCES,0.8403990024937655,Airplane -16.1
REFERENCES,0.8428927680798005,Automobile -11.9 Bird 11.4 Cat -16.1 Deer -12.9 Dog -13.3 Frog -16.1 Horse -16.1 Ship -16.1 Truck
REFERENCES,0.8453865336658354,"-16.1
-16.1
14.0
-16.1
-14.0
-16.1
-16.1
-16.1
-16.1
-16.1"
REFERENCES,0.8478802992518704,"-16.1
-16.1
-16.1
-13.9
-16.1
-16.1
13.9
-16.1
-16.1
-16.1"
REFERENCES,0.8503740648379052,"2.2
-16.1
-16.1
-13.0
-13.1
-16.1
-16.1
-12.5
-2.2
-13.7"
REFERENCES,0.8528678304239401,"-16.1
-16.1
-15.5
1.6
-9.6
-8.1
-1.6
-16.1
-16.1
-16.1"
REFERENCES,0.8553615960099751,"-16.1
-16.1
-16.1
9.6
-16.1
-9.7
-14.7
-16.1
-16.1
-11.5"
REFERENCES,0.85785536159601,"-16.1
-16.1
-16.1
-10.5
-16.0
-16.1
10.5
-16.1
-16.1
-16.1"
REFERENCES,0.8603491271820449,"-2.1
-9.4
2.1
-8.0
-9.5
-16.1
-8.5
-9.7
-9.4
-10.2"
REFERENCES,0.8628428927680798,"-12.5
2.4
-15.1
-10.0
-16.1
-16.1
-13.0
-13.9
-9.9
-2.4"
REFERENCES,0.8653366583541147,"-16.1
-11.3
-12.6
-8.1
-16.1
5.5
-5.7
-16.1
-16.1
-7.6"
REFERENCES,0.8678304239401496,"-3.3
-6.4
-11.2
-9.0
-15.7
-7.6
-9.4
-5.9
2.3
-2.9"
REFERENCES,0.8703241895261845,"12.1
-16.1
-12.3
-16.1
-14.1
-16.1
-16.1
-16.1
-16.1
-16.1"
REFERENCES,0.8728179551122195,"-12.2
-16.1
-13.4
7.0
-16.1
-15.1
-7.2
-10.3
-13.6
-9.5"
REFERENCES,0.8753117206982544,"-16.1
-16.1
-16.1
-16.1
-15.3
-16.1
-16.1
15.2
-16.1
-16.1"
REFERENCES,0.8778054862842892,"-15.8
10.1
-16.1
-16.1
-16.1
-16.1
-16.1
-16.1
-16.1
-10.1"
REFERENCES,0.8802992518703242,"-16.1
-16.1
-16.1
-16.1
-16.1
-16.1
-16.1
-16.1
-16.1
15.9"
REFERENCES,0.8827930174563591,"-16.1
-16.1
8.1
-8.1
-16.1
-12.5
-16.1
-13.3
-16.1
-16.1"
REFERENCES,0.885286783042394,"1.7
-1.9
-16.1
-16.1
-16.1
-16.1
-16.1
-14.8
-9.9
-3.7"
REFERENCES,0.8877805486284289,"Figure 9: Explanations generated by FastSHAP for 18 randomly selected CIFAR-10 images. Each col-
umn corresponds to a CIFAR-10 class, and the model’s prediction (in logits) is provided below each image."
REFERENCES,0.8902743142144638,Published as a conference paper at ICLR 2022 -7.4 Tench 5.2
REFERENCES,0.8927680798004988,"English
 Springer -7.4"
REFERENCES,0.8952618453865336,Cassette
REFERENCES,0.8977556109725686,Player -7.9
REFERENCES,0.9002493765586035,Chain Saw -7.2
REFERENCES,0.9027431421446384,Church -7.7
REFERENCES,0.9052369077306733,French Horn -7.3
REFERENCES,0.9077306733167082,Garbage Truck -7.4
REFERENCES,0.9102244389027432,Gas Pump -7.2
REFERENCES,0.912718204488778,Golf Ball -7.8
REFERENCES,0.9152119700748129,Parachute
REFERENCES,0.9177057356608479,"-8.9
-8.8
-8.5
-9.3
6.7
-9.0
-9.0
-9.3
-9.0
-8.5"
REFERENCES,0.9201995012468828,"-9.8
-9.8
-12.4
-11.4
-8.6
-10.2
-10.1
7.7
-10.2
-10.1"
REFERENCES,0.9226932668329177,"-8.1
-8.0
-7.3
-8.3
5.4
-8.1
-7.9
-7.8
-7.9
-6.7"
REFERENCES,0.9251870324189526,"-7.5
-7.2
3.5
-6.1
-6.8
-6.2
-4.7
-4.6
-7.5
-5.9"
REFERENCES,0.9276807980049875,"-9.4
-9.2
-9.7
-10.2
-8.7
7.1
-9.4
-9.5
-9.4
-9.3"
REFERENCES,0.9301745635910225,"-9.5
-9.3
-9.3
-9.7
7.2
-9.6
-9.6
-9.8
-9.6
-8.9"
REFERENCES,0.9326683291770573,"-9.8
-9.8
-12.4
-11.4
-8.6
-10.2
-10.1
7.7
-10.2
-10.1"
REFERENCES,0.9351620947630923,"-9.5
-9.3
-9.9
6.5
-9.3
-9.9
-8.3
-10.1
-7.9
-7.7"
REFERENCES,0.9376558603491272,"-9.4
-9.2
-9.7
-10.2
-8.7
7.1
-9.4
-9.5
-9.4
-9.3"
REFERENCES,0.940149625935162,"-9.5
-9.4
-9.8
-10.1
-9.4
-9.4
-9.3
-9.6
7.4
-9.8"
REFERENCES,0.942643391521197,"-7.2
-7.1
-5.2
-7.4
-4.3
-7.2
-5.9
3.6
-6.8
-7.1"
REFERENCES,0.9451371571072319,"7.0
-9.1
-9.2
-9.8
-9.0
-9.1
-9.0
-9.1
-9.2
-9.0"
REFERENCES,0.9476309226932669,"6.7
-8.9
-9.0
-9.5
-8.8
-8.9
-8.8
-8.9
-9.0
-8.7"
REFERENCES,0.9501246882793017,"-9.5
-9.4
-9.8
-10.1
-9.4
-9.4
-9.3
-9.6
7.4
-9.8"
REFERENCES,0.9526184538653366,"-9.3
7.2
-9.5
-9.6
-9.2
-9.3
-9.4
-9.3
-9.4
-9.4"
REFERENCES,0.9551122194513716,"-9.5
-9.4
-9.5
-10.2
-9.1
-9.7
-9.6
-9.7
-9.2
7.3"
REFERENCES,0.9576059850374065,"-7.5
-7.1
3.7
-4.2
-7.2
-6.0
-6.9
-6.2
-7.4
-6.8"
REFERENCES,0.9600997506234414,"Figure 10: Explanations generated by FastSHAP for 18 randomly selected Imagenette images. Each
column corresponds to an Imagenette class, and the model’s prediction (in logits) is provided below each
image."
REFERENCES,0.9625935162094763,Published as a conference paper at ICLR 2022 Cat
REFERENCES,0.9650872817955112,"FastSHAP
KernelSHAP
KernelSHAP-S
GradCAM"
REFERENCES,0.9675810473815462,"Integrated
 Gradients
SmoothGrad
DeepSHAP
CXPlain"
REFERENCES,0.970074812967581,"Bird
Frog
Ship
Frog
Cat
Frog
Bird
Truck
Dog
Ship
Airplane
Cat
Horse
Automobile"
REFERENCES,0.972568578553616,"Figure 11: Explanations generated for the predicted class for 15 randomly selected CIFAR-10 images.
Each column corresponds to an explanation method, and each row is labeled with the image’s corresponding
class."
REFERENCES,0.9750623441396509,Published as a conference paper at ICLR 2022
REFERENCES,0.9775561097256857,English
REFERENCES,0.9800498753117207,Springer
REFERENCES,0.9825436408977556,"FastSHAP
KernelSHAP
KernelSHAP-S
GradCAM"
REFERENCES,0.9850374064837906,"Integrated
 Gradients
SmoothGrad
DeepSHAP
CXPlain"
REFERENCES,0.9875311720698254,"Church
Gas Pump
Church
Cassette"
REFERENCES,0.9900249376558603,"Player
French"
REFERENCES,0.9925187032418953,"Horn
Church
Gas Pump
Chain Saw
French"
REFERENCES,0.9950124688279302,"Horn
Golf Ball
Gas Pump
Tench
Tench
Golf Ball"
REFERENCES,0.9975062344139651,"Figure 12: Explanations generated for the predicted class for 15 randomly selected Imagenette images.
Each column corresponds to an explanation method, and each row is labeled with the image’s corresponding
class."
