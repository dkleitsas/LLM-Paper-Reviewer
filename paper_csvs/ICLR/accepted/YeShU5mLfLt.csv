Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.00205761316872428,"Interval Bound Propagation (IBP) is so far the base of state-of-the-art methods
for training neural networks with certiÔ¨Åable robustness guarantees when potential
adversarial perturbations present, while the convergence of IBP training remains
unknown in existing literature. In this paper, we present a theoretical analysis
on the convergence of IBP training. With an overparameterized assumption, we
analyze the convergence of IBP robust training. We show that when using IBP
training to train a randomly initialized two-layer ReLU neural network with lo-
gistic loss, gradient descent can linearly converge to zero robust training error
with a high probability if we have sufÔ¨Åciently small perturbation radius and large
network width."
INTRODUCTION,0.00411522633744856,"1
INTRODUCTION"
INTRODUCTION,0.006172839506172839,"It has been shown that deep neural networks are vulnerable against adversarial examples (Szegedy
et al., 2014; Goodfellow et al., 2015), where a human imperceptible adversarial perturbation can
easily alter the prediction by neural networks. This poses concerns to safety-critical applications
such as autonomous vehicles, healthcare or Ô¨Ånance systems. To combat adversarial examples, many
defense mechanisms have been proposed in the past few years (Kurakin et al., 2016; Madry et al.,
2018; Zhang et al., 2019; Guo et al., 2018; Song et al., 2018; Xiao et al., 2020). However, due to the
lack of reliable measurement on adversarial robustness, many defense methods are later broken by
stronger attacks (Carlini & Wagner, 2017; Athalye et al., 2018; Tramer et al., 2020)."
INTRODUCTION,0.00823045267489712,"There are recently a line of robust training works, known as certiÔ¨Åed robust training (certiÔ¨Åed de-
fense), focusing on training neural networks with certiÔ¨Åed and provable robustness ‚Äì the network is
considered robust on an example if and only if the prediction is provably correct for any perturbation
in a predeÔ¨Åned set (e.g., a small ‚Ñì‚àûball) (Wang et al., 2018b; Bunel et al., 2018; Zhang et al., 2018;
Wang et al., 2018c; Wong & Kolter, 2018; Singh et al., 2018; 2019; Weng et al., 2018; Xu et al.,
2020). CertiÔ¨Åed defense methods provide provable robustness guarantees without referring to any
speciÔ¨Åc attack and thus do not rely on the strength of attack algorithms."
INTRODUCTION,0.0102880658436214,"To obtain a neural network with certiÔ¨Åed robustness, a common practice is to derive a neural network
veriÔ¨Åcation method that computes the upper and lower bounds of output neurons given an input
region under perturbation, and then train the model by optimizing the loss deÔ¨Åned on the worst-
case output from veriÔ¨Åcation w.r.t. any possible perturbation. Many methods along this line have
been proposed (Wong & Kolter, 2018; Wong et al., 2018; Mirman et al., 2018; Gowal et al., 2018;
Raghunathan et al., 2018a; Zhang et al., 2020a). Among these methods, Interval Bound Propagation
(IBP) (Mirman et al., 2018; Gowal et al., 2018) is a simple but effective and efÔ¨Åcient method so
far, which propagates the interval bounds of each neuron through the network to obtain the output
bounds of the network. Most of the latest state-of-the-art certiÔ¨Åed defense works are at least partly
based on IBP training (Zhang et al., 2020a; Shi et al., 2021; Lyu et al., 2021; Zhang et al., 2021)."
INTRODUCTION,0.012345679012345678,"However, the convergence properties of IBP training remained unknown. For standard neural net-
work training (without considering adversarial perturbation, aka natural training), it has been shown
that gradient descent for overparameterized networks can provably converge to a global minimizer
with random initialization (Li & Liang, 2018; Du et al., 2019b;a; Jacot et al., 2018; Allen-Zhu
et al., 2019; Zou et al., 2018). Compared to standard training, IBP-based robust training has a very"
INTRODUCTION,0.01440329218106996,Published as a conference paper at ICLR 2022
INTRODUCTION,0.01646090534979424,"different training scheme which requires a different convergence analysis. First, in the robust train-
ing problem, input can contain perturbations and the training objective is deÔ¨Åned differently from
standard training. Second, IBP training essentially optimizes a different network augmented with
IBP computation, as illustrated in Zhang et al. (2020a). Third, in IBP training, the activation state
of each neuron depends on the certiÔ¨Åed bounds rather than the values in standard neural network
computation, which introduces special perturbation-related terms in our analysis."
INTRODUCTION,0.018518518518518517,"In this paper, we conduct a theoretical analysis to study the convergence of IBP training. Follow-
ing recent convergence analysis on Stochastic Gradient Descent (SGD) for standard training, we
consider IBP robust training with gradient Ô¨Çow (gradient descent with inÔ¨Ånitesimal step size) for a
two-layer overparameterized neural network on a classiÔ¨Åcation task. We summarize our contribu-
tions below:"
INTRODUCTION,0.0205761316872428,"‚Ä¢ We provide the Ô¨Årst convergence analysis for IBP-based certiÔ¨Åed robust training. On a
two-layer overparameterized ReLU network with logistic loss, with sufÔ¨Åciently small per-
turbation radius and large network width, gradient Ô¨Çow with IBP has a linear convergence
rate, and is guaranteed to converge to zero training error with high probability."
INTRODUCTION,0.02263374485596708,"‚Ä¢ This result also implies that IBP converges to a state where the certiÔ¨Åed robust accuracy
measured by IBP bounds tightly reÔ¨Çects the true robustness of the network."
INTRODUCTION,0.024691358024691357,"‚Ä¢ We show additional perturbation-related conditions required to guarantee the convergence
of IBP training and identify particular challenges in the convergence analysis for IBP train-
ing compared to standard training."
INTRODUCTION,0.026748971193415638,"Notation
We use lowercase letters to denote scalars, and use lower and upper case boldface let-
ters to denote vectors and matrices respectively. 1(¬∑) stand for the indicator function. For a d-
dimensional vector x ‚ààRd, ‚à•x‚à•p is its ‚Ñìp-norm. For two sequences {an} and {bn}, n > 0, we have
an = O(bn) if and only if ‚àÉC > 0, ‚àÉN > 0, ‚àÄn > N, an ‚â§Cbn,. And we have an = ‚Ñ¶(bn) if and
only if ‚àÉC > 0, ‚àÉN > 0, ‚àÄn > N, an ‚â•Cbn."
RELATED WORK,0.02880658436213992,"2
RELATED WORK"
CERTIFIED ROBUST TRAINING,0.030864197530864196,"2.1
CERTIFIED ROBUST TRAINING"
CERTIFIED ROBUST TRAINING,0.03292181069958848,"The goal of certiÔ¨Åed robust training is to maximize the certiÔ¨Åed robust accuracy of a model evalu-
ated by provable robustness veriÔ¨Åers. Some works added heuristic regularizations during adversarial
training to improve certiÔ¨Åed robustness (Xiao et al., 2019; Balunovic & Vechev, 2020). More ef-
fectively, certiÔ¨Åed defense works typically optimize a certiÔ¨Åed robust loss which is a certiÔ¨Åed upper
bound of the loss w.r.t. all considered perturbations. Among them, Wong & Kolter (2018); Mirman
et al. (2018); Dvijotham et al. (2018); Wong et al. (2018); Wang et al. (2018a) used veriÔ¨Åcation
with linear relaxation for nonlinear activations, and Raghunathan et al. (2018b) used semi-deÔ¨Ånite
relaxation. However, IBP (Mirman et al., 2018; Gowal et al., 2018), which computes and propagates
interval lower and bounds for each neuron, has been shown as efÔ¨Åcient and effective and can even
outperform methods using more complicated relaxation (Lee et al., 2021; Jovanovi¬¥c et al., 2021).
Most of the effective certiÔ¨Åed defense methods are at least partly based on IBP. For example, Zhang
et al. (2020a) combined IBP with linear relaxation bounds; Lyu et al. (2021) designed a parameter-
ized activation; Zhang et al. (2021) designed a 1-Lipschitz layer with ‚Ñì‚àû-norm computation before
layers using IBP; Shi et al. (2021) accelerated IBP training with shortened training schedules. As
most state-of-the-art methods so far contain IBP as an important part, we focus on analyzing the
convergence of IBP training in this paper."
CERTIFIED ROBUST TRAINING,0.03497942386831276,"On the theoretical analysis for IBP bounds, Baader et al. (2020) analyzed the universal approxima-
tion of IBP veriÔ¨Åcation bounds, and Wang et al. (2020) extended the analysis to other activation
functions beyond ReLU. However, to the best of our knowledge, there is still no existing work
analyzing the convergence of IBP training."
CERTIFIED ROBUST TRAINING,0.037037037037037035,"The aforementioned methods for certiÔ¨Åed robustness target at robustness with deterministic certiÔ¨Å-
cation. There are also some other works on probabilistic certiÔ¨Åcation such as randomized smooth-
ing (Cohen et al., 2019; Li et al., 2019; Salman et al., 2019) which is out of our scope."
CERTIFIED ROBUST TRAINING,0.03909465020576132,Published as a conference paper at ICLR 2022
CONVERGENCE OF STANDARD NEURAL NETWORK TRAINING,0.0411522633744856,"2.2
CONVERGENCE OF STANDARD NEURAL NETWORK TRAINING"
CONVERGENCE OF STANDARD NEURAL NETWORK TRAINING,0.043209876543209874,"There have been many works analyzing the convergence of standard neural network training. For
randomly initialized two-layer ReLU networks with quadratic loss, Du et al. (2019b) proved that
gradient descent can converge to a globally optimum with a large enough network width polynomial
in the data size. Ji & Telgarsky (2019) pushed the requirement of network width to a polylogarithmic
function. For deep neural networks, Allen-Zhu et al. (2019) proved that for deep ReLU networks,
gradient descent has a linear convergence rate for various loss functions with width polynomial in
network depth and data size. Chen et al. (2019) proved that a polylogarithmic width is also sufÔ¨Åcient
for deep neural networks to converge. However, they only focus on standard training and cannot be
directly adapted to the robust training settings."
CONVERGENCE OF EMPIRICAL ADVERSARIAL TRAINING,0.04526748971193416,"2.3
CONVERGENCE OF EMPIRICAL ADVERSARIAL TRAINING"
CONVERGENCE OF EMPIRICAL ADVERSARIAL TRAINING,0.047325102880658436,"Robust training is essentially a min-max optimization. For a training data distribution X, the objec-
tive for learning a model fŒ∏ parameterized by Œ∏ can be written as1:"
CONVERGENCE OF EMPIRICAL ADVERSARIAL TRAINING,0.04938271604938271,"arg min
Œ∏
E(x,y)‚àºX max
‚àÜ‚ààS ‚Ñì(fŒ∏(x + ‚àÜ), y),"
CONVERGENCE OF EMPIRICAL ADVERSARIAL TRAINING,0.051440329218107,"where (x, y) is a sample, ‚Ñì(¬∑, y) is the loss function, S is the space of perturbations. Empirical
adversarial training approximates the inner minimization by adversarial attacks, and some works
analyzed the convergence of adversarial training: Wang et al. (2019) considered a Ô¨Årst-order station-
ary condition for the inner maximization problem; Gao et al. (2019); Zhang et al. (2020b) showed
that overparameterized networks with projected gradient descent can converge to a state with robust
loss close to 0 and the the inner maximization by adversarial attack is nearly optimal; and Zou et al.
(2021) showed that adversarial training provably learns robust halfspaces in the presence of noise."
CONVERGENCE OF EMPIRICAL ADVERSARIAL TRAINING,0.053497942386831275,"However, there is a signiÔ¨Åcant difference between empirical adversarial training and certiÔ¨Åed robust
training such as IBP. Adversarial training involves a concrete perturbation ‚àÜ, which is an approx-
imate solution for the inner maximization and could lead to a concrete adversarial input x + ‚àÜ.
However, in IBP-based training, the inner maximization is computed from certiÔ¨Åed bounds, where
for each layer, the certiÔ¨Åed bounds of each neuron are computed independently, and thereby the cer-
tiÔ¨Åed bounds of the network generally do not correspond to any speciÔ¨Åc ‚àÜ. Due to this signiÔ¨Åcant
difference, prior theoretical analysis on adversarial training, which requires a concrete ‚àÜfor inner
maximization, is not applicable to IBP."
PRELIMINARIES,0.05555555555555555,"3
PRELIMINARIES"
NEURAL NETWORKS,0.05761316872427984,"3.1
NEURAL NETWORKS"
NEURAL NETWORKS,0.059670781893004114,"Following Du et al. (2019b), we consider a similar two-layer ReLU network. Unlike Du et al.
(2019b) which considered a regression task with the square loss, we consider a classiÔ¨Åcation task
where IBP is usually used, and we consider binary classiÔ¨Åcation for simplicity. On a training dataset
{(xi, yi)}n
i=1, for every i ‚àà[n], (xi, yi) is a training example with d-dimensional input xi(xi ‚ààRd)
and label yi(yi ‚àà{¬±1}), and the network output is:"
NEURAL NETWORKS,0.06172839506172839,"f(W, a, xi) =
1
‚àöm m
X"
NEURAL NETWORKS,0.06378600823045268,"r=1
arœÉ(w‚ä§
r xi),
(1)"
NEURAL NETWORKS,0.06584362139917696,"where m is the width of hidden layer (the Ô¨Årst layer) in the network, W ‚ààRm√ód is the weight ma-
trix of the hidden layer, wr(r‚àà[m]) is the r-th row of W, a ‚ààRm is the weight vector of the second
layer (output layer) with elements a1, ¬∑ ¬∑ ¬∑ , am, and œÉ(¬∑) is the activation function. We assume the ac-
tivation is ReLU as IBP is typically used with ReLU. For initialization, we set ar ‚àºunif[{1, ‚àí1}] and
wr ‚àºN(0, I). Only the Ô¨Årst layer is trained after initialization. Since we consider binary classiÔ¨Åca-
tion, we use a logistic loss. For training example (xi, yi), we deÔ¨Åne ui(W, a, xi) := yif(W, a, xi),"
NEURAL NETWORKS,0.06790123456790123,"1Here we use notations to denote the general robust training problem, but in our later analysis, we will have
different notations for a simpliÔ¨Åed problem setting."
NEURAL NETWORKS,0.06995884773662552,Published as a conference paper at ICLR 2022
NEURAL NETWORKS,0.0720164609053498,"the loss on this example is computed as l(ui(W, a, xi)) = log(1 + exp(‚àíui(W, a, xi))), and the
standard training loss on the whole training set is L = n
X"
NEURAL NETWORKS,0.07407407407407407,"i=1
l(ui(W, a, xi)) = n
X"
NEURAL NETWORKS,0.07613168724279835,"i=1
log

1 + exp(‚àíui(W, a, xi))

."
CERTIFIED ROBUST TRAINING,0.07818930041152264,"3.2
CERTIFIED ROBUST TRAINING"
CERTIFIED ROBUST TRAINING,0.08024691358024691,"In the robust training setting, for original input xi (‚àÄi ‚àà[n]), we consider that the actual input
may be perturbed into xi + ‚àÜi by perturbation ‚àÜi. For a widely adopted setting, we consider ‚Ñì‚àû
perturbations, where ‚àÜi is bounded by an ‚Ñì‚àûball with radius œµ(0 ‚â§œµ ‚â§1), i.e., ‚à•‚àÜi‚à•‚àû‚â§œµ.
For the convenience of subsequent analysis and without loss of generality, we make the following
assumption on each xi, which can be easily satisÔ¨Åed by normalizing the training data:
Assumption 1. ‚àÄi ‚àà[n], we assume there exists some Œæ > 0, such that xi ‚àà[œµ, 1]d, ‚à•xi‚à•2 ‚â•Œæ."
CERTIFIED ROBUST TRAINING,0.0823045267489712,"In Du et al. (2019b), they also assume there are no parallel data points, and in our case we assume
this holds under any possible perturbation, formulated as:
Assumption 2. For perturbation radius œµ, we assume that"
CERTIFIED ROBUST TRAINING,0.08436213991769548,"‚àÄi, j ‚àà[n], i Ã∏= j, ‚àÄx‚Ä≤
i ‚ààB‚àû(xi, œµ), ‚àÄx‚Ä≤
j ‚ààB‚àû(xj, œµ),
x‚Ä≤
i ‚à¶x‚Ä≤
j,"
CERTIFIED ROBUST TRAINING,0.08641975308641975,"where B‚àû(xi, œµ) stands for the ‚Ñì‚àû-ball with radius œµ centered at xi."
CERTIFIED ROBUST TRAINING,0.08847736625514403,"IBP training computes and optimizes a robust loss L, which is an upper bound of the standard loss
for any possible perturbation ‚àÜi (‚àÄi ‚àà[n]): L ‚â• n
X"
CERTIFIED ROBUST TRAINING,0.09053497942386832,"i=1
max
‚àÜi"
CERTIFIED ROBUST TRAINING,0.09259259259259259,"
log

1 + exp(‚àíyif(W, a, xi + ‚àÜi))

| ‚à•‚àÜi‚à•‚àû‚â§œµ

."
CERTIFIED ROBUST TRAINING,0.09465020576131687,"To compute L, since log(¬∑) and exp(¬∑) are both monotonic, for every i ‚àà[n], IBP Ô¨Årst computes the
lower bound of ui(W, a, xi + ‚àÜi) for ‚à•‚àÜi‚à•‚àû‚â§œµ, denoted as ui. Then the IBP robust loss is: L = n
X"
CERTIFIED ROBUST TRAINING,0.09670781893004116,"i=1
log(1 + exp(‚àíui)),
where ui ‚â§min
‚àÜi ui(W, a, xi + ‚àÜi) (i ‚àà[n]).
(2)"
CERTIFIED ROBUST TRAINING,0.09876543209876543,"IBP computes and propagates an interval lower and upper bound for each neuron in the network,
and then ui is equivalent to the lower bound of the Ô¨Ånal output neuron. Initially, the interval bound
of the input is [xi ‚àíœµ ¬∑ 1, x + œµ ¬∑ 1] given ‚à•‚àÜi‚à•‚àû‚â§œµ, since xi ‚àíœµ ¬∑ 1 ‚â§xi + ‚àÜi ‚â§xi + œµ ¬∑ 1
element-wisely holds. Then this interval bound is propagated to the Ô¨Årst hidden layer, and we have
the interval bound for each neuron in the Ô¨Årst layer:"
CERTIFIED ROBUST TRAINING,0.10082304526748971,"‚àÄr ‚àà[m], œÉ
 
w‚ä§
r xi ‚àíœµ‚à•wr‚à•1

‚â§œÉ
 
w‚ä§
r (xi + ‚àÜi)

‚â§œÉ
 
w‚ä§
r xi + œµ‚à•wr‚à•1

."
CERTIFIED ROBUST TRAINING,0.102880658436214,"These bounds are further propagated to the second layer. We focus on the lower bound of ui, which
can be computed from the bounds of the Ô¨Årst layer by considering the sign of multiplier yiar:"
CERTIFIED ROBUST TRAINING,0.10493827160493827,"ui(W, a, xi + ‚àÜi) = yi
1
‚àöm m
X"
CERTIFIED ROBUST TRAINING,0.10699588477366255,"r=1
arœÉ(w‚ä§
r (xi + ‚àÜi))"
CERTIFIED ROBUST TRAINING,0.10905349794238683,"‚â•
1
‚àöm m
X r=1"
CERTIFIED ROBUST TRAINING,0.1111111111111111,"
1(yiar = 1)œÉ
 
w‚ä§
r xi ‚àíœµ‚à•wr‚à•1
"
CERTIFIED ROBUST TRAINING,0.11316872427983539,"+ 1(yiar = ‚àí1)œÉ
 
w‚ä§
r xi + œµ‚à•wr‚à•1

:= ui.
(3)"
CERTIFIED ROBUST TRAINING,0.11522633744855967,"Then the IBP robust loss can be obtained as Eq. (2). And we deÔ¨Åne u := (u1, u2, ¬∑ ¬∑ ¬∑ , un)."
CERTIFIED ROBUST TRAINING,0.11728395061728394,"We deÔ¨Åne certiÔ¨Åed robust accuracy in IBP training as the percentage of examples that IBP bounds
can successfully certify that the prediction is correct for any concerned perturbation. An example
i(i ‚àà[n]) is considered as robustly classiÔ¨Åed under IBP veriÔ¨Åcation if and only if ui > 0. Let Àúui be
the exact solution of the minimization in Eq. (2) rather than relaxed IBP bounds, we also deÔ¨Åne the
true robust accuracy, where the robustness requires Àúui > 0. The certiÔ¨Åed robust accuracy by IBP
is a provable lower bound of the true robust accuracy."
CERTIFIED ROBUST TRAINING,0.11934156378600823,Published as a conference paper at ICLR 2022
GRADIENT FLOW,0.12139917695473251,"3.3
GRADIENT FLOW"
GRADIENT FLOW,0.12345679012345678,"Gradient Ô¨Çow is gradient descent with inÔ¨Ånitesimal step size for a continuous time analysis, and it
is adopted in prior works analyzing standard training (Arora et al., 2018; Du et al., 2019a;b). In IBP
training, gradient Ô¨Çow is deÔ¨Åned as:"
GRADIENT FLOW,0.12551440329218108,"‚àÄr ‚àà[m], dwr(t)"
GRADIENT FLOW,0.12757201646090535,"dt
= ‚àí‚àÇL(t)"
GRADIENT FLOW,0.12962962962962962,"‚àÇwr(t),
(4)"
GRADIENT FLOW,0.13168724279835392,"where w1(t), w2(t), ¬∑ ¬∑ ¬∑ , wm(t) are rows of the weight matrix at time t, and L(t) is the IBP robust
loss deÔ¨Åned as Eq. (2) using weights at time t."
GRAM MATRIX,0.1337448559670782,"3.4
GRAM MATRIX"
GRAM MATRIX,0.13580246913580246,"Under the gradient Ô¨Çow setting as Eq. (4), for all i ‚àà[n], we analyze the dynamics of ui during IBP
training, and we use ui(t) to denote its value at time t:"
GRAM MATRIX,0.13786008230452676,"d
dtui(t) = m
X r=1"
GRAM MATRIX,0.13991769547325103,‚àÇui(t)
GRAM MATRIX,0.1419753086419753,"‚àÇwr(t), dwr(t) dt = n
X"
GRAM MATRIX,0.1440329218106996,"j=1
‚àíl‚Ä≤(uj)Hij(t),
(5)"
GRAM MATRIX,0.14609053497942387,"where l‚Ä≤(uj) is the derivative of the loss, H(t) is a Gram matrix and deÔ¨Åned as Hij(t) =
Pm
r=1"
GRAM MATRIX,0.14814814814814814,"‚àÇui(t)
‚àÇwr(t),
‚àÇuj(t)
‚àÇwr(t)"
GRAM MATRIX,0.15020576131687244,"(‚àÄ1 ‚â§i, j ‚â§n). We provide a detailed derivation in Appendix B.1."
GRAM MATRIX,0.1522633744855967,The dynamic of ui can be described using H.
GRAM MATRIX,0.15432098765432098,"From Eq. (3), ‚àÄi ‚àà[n], r ‚àà[m], derivative ‚àÇui(t)"
GRAM MATRIX,0.15637860082304528,‚àÇwr(t) can be computed as follows:
GRAM MATRIX,0.15843621399176955,"‚àÇui(t)
‚àÇwr(t) =
1
‚àömyiar"
GRAM MATRIX,0.16049382716049382,"
A+
ri(t)

xi ‚àíœµ sign(wr(t))

+ A‚àí
ri(t)

xi + œµ sign(wr(t))

,"
GRAM MATRIX,0.16255144032921812,"where sign(wr(t)) is element-wise for wr(t), and we deÔ¨Åne indicators"
GRAM MATRIX,0.1646090534979424,"A+
ri(t) := 1(yiar = 1, wr(t)‚ä§xi ‚àíœµ‚à•wr(t)‚à•1 > 0),"
GRAM MATRIX,0.16666666666666666,"A‚àí
ri(t) := 1(yiar = ‚àí1, wr(t)‚ä§xi + œµ‚à•wr(t)‚à•1 > 0)."
GRAM MATRIX,0.16872427983539096,Then elements in H can be written as:
GRAM MATRIX,0.17078189300411523,"Hij(t) = 1 myiyj m
X"
GRAM MATRIX,0.1728395061728395,"r=1
a2
r"
GRAM MATRIX,0.1748971193415638,"
A+
ri(t)

xi ‚àíœµ sign(wr(t))

+ A‚àí
ri(t)

xi + œµ sign(wr(t))
‚ä§"
GRAM MATRIX,0.17695473251028807,"
A+
rj(t)

xj ‚àíœµ sign(wr(t))

+ A‚àí
rj(t)

xj + œµ sign(wr(t))
 = 1 myiyj"
GRAM MATRIX,0.17901234567901234,"
x‚ä§
i xj m
X"
GRAM MATRIX,0.18106995884773663,"r=1
Œ±rij(t) ‚àíœµ
 m
X"
GRAM MATRIX,0.1831275720164609,"r=1
(Œ≤rij(t)xi + Œ≤rji(t)xj)‚ä§sign(wr(t))

+ œµ2d m
X"
GRAM MATRIX,0.18518518518518517,"r=1
Œ≥rij(t)

, (6)"
GRAM MATRIX,0.18724279835390947,"where Œ±rij(t), Œ≤rij(t), Œ≥rij(t) are deÔ¨Åned as follows"
GRAM MATRIX,0.18930041152263374,"Œ±rij(t) = (A+
ri(t) + A‚àí
ri(t))(A+
rj(t) + A‚àí
rj(t)),"
GRAM MATRIX,0.19135802469135801,"Œ≤rij(t) = (A+
ri(t) + A‚àí
ri(t))(A+
rj(t) ‚àíA‚àí
rj(t)),"
GRAM MATRIX,0.1934156378600823,"Œ≥rij(t) = (A+
ri(t) ‚àíA‚àí
ri(t))(A+
rj(t) ‚àíA‚àí
rj(t))."
GRAM MATRIX,0.19547325102880658,"Further, we deÔ¨Åne H‚àûwhich is the elementwise expectation of H(0), to characterize H(0) on the
random initialization basis:"
GRAM MATRIX,0.19753086419753085,"‚àÄ1 ‚â§i, j ‚â§n, H‚àû
ij := E‚àÄ1‚â§r‚â§m,wr‚àºN(0,I),ar‚àºunif[{‚àí1,1}]Hij(0),"
GRAM MATRIX,0.19958847736625515,"where Hij(0) depends on the initialization of weights wr and ar. We also deÔ¨Åne Œª0 := Œªmin(H‚àû)
as the least eigenvalue of H‚àû. We will prove that H(0) is positive deÔ¨Ånite with high probability, by
showing that H‚àûis positive deÔ¨Ånite and bounding the difference between H(0) and H‚àû."
GRAM MATRIX,0.20164609053497942,Published as a conference paper at ICLR 2022
CONVERGENCE ANALYSIS FOR IBP TRAINING,0.2037037037037037,"4
CONVERGENCE ANALYSIS FOR IBP TRAINING"
CONVERGENCE ANALYSIS FOR IBP TRAINING,0.205761316872428,"We present the following main theorem which shows the convergence of IBP training under certain
conditions on perturbation radius and network width:
Theorem 1 (Convergence of IBP Training). Suppose Assumptions 1 and 2 hold for the train-"
CONVERGENCE ANALYSIS FOR IBP TRAINING,0.20781893004115226,"ing data, and the ‚Ñì‚àûperturbation radius satisÔ¨Åes œµ ‚â§O

min

Œ¥2Œª2
0
d2.5n3 ,
‚àö"
DR,0.20987654320987653,"2dR
log(‚àö 2œÄd R Œæ)"
DR,0.21193415637860083,"
, where"
DR,0.2139917695473251,"R =
cŒ¥Œª0
d1.5n2 , c =
‚àö"
DR,0.21604938271604937,"2œÄŒæ
384 . For a two-layer ReLU network (Eq. (1)), suppose its width for the"
DR,0.21810699588477367,"Ô¨Årst hidden layer satisÔ¨Åes m ‚â•‚Ñ¶

d1.5n4Œ¥Œª0
Œ¥2Œª2
0‚àíœµd2.5n4
2
, and the network is randomly initialized"
DR,0.22016460905349794,"as ar ‚àºunif[{1, ‚àí1}], wr ‚àºN(0, I), with the second layer Ô¨Åxed during training. Then for any
conÔ¨Ådence Œ¥(0<Œ¥<1), with probability at least 1‚àíŒ¥, IBP training with gradient Ô¨Çow can converge
to zero training error."
DR,0.2222222222222222,"The theorem contains two Ô¨Åndings: First, for a given œµ, as long as it satisÔ¨Åes the upper bound on œµ
speciÔ¨Åed in the theorem, with a sufÔ¨Åciently large width m, convergence of IBP training is guaranteed
with high probability; Second, when œµ is larger than the upper bound, IBP training is not guaranteed
to converge under our analysis even with arbitrarily large m, which is essentially different from
analysis on standard training and implies a possible limitation of IBP training."
DR,0.2242798353909465,"In the following part of this section, we provide the proof sketch for the main theorem."
STABILITY OF THE GRAM MATRIX DURING IBP TRAINING,0.22633744855967078,"4.1
STABILITY OF THE GRAM MATRIX DURING IBP TRAINING"
STABILITY OF THE GRAM MATRIX DURING IBP TRAINING,0.22839506172839505,"We Ô¨Årst analyze the stability of H during training since H can characterize the dynamic of the
training as deÔ¨Åned in Eq. (5). We show that when there exists some R such that the change of
wr(‚àÄr ‚àà[m]) is restricted to ‚à•wr(t) ‚àíwr(0)‚à•2 ‚â§R during training, we can guarantee that
Œªmin(H(t)) remains positive with high probability. This property will be later used to reach the
conclusion on the convergence. We defer the derivation for the constraint on R to a later part."
STABILITY OF THE GRAM MATRIX DURING IBP TRAINING,0.23045267489711935,"For all r ‚àà[m], with the aforementioned constraint on wr(t), we Ô¨Årst show that during the IBP
training, most of Œ±rij(t), Œ≤rij(t), Œ≥rij(t) terms in Eq. (6) remain the same as their initialized values
(t = 0). This is because for for each of Œ±rij(t), Œ≤rij(t), Œ≥rij(t), the probability that its value changes
during training can be upper bounded by a polynomial in R, and thereby the probability can be made
sufÔ¨Åciently small for a sufÔ¨Åciently small R, as the following lemma shows:
Lemma 1. ‚àÄr ‚àà[m], at some time t > 0, suppose ‚à•wr(t) ‚àíwr(0)‚à•2 ‚â§R holds for some R, and
œµ ‚â§
‚àö"
DR,0.23251028806584362,"2dR
log(‚àö 2œÄd"
DR,0.2345679012345679,"R Œæ) holds, then for all 1‚â§i, j ‚â§n, we have"
DR,0.2366255144032922,"Pr(Œ±rij(t) Ã∏= Œ±rij(0)), Pr(Œ≤rij(t) Ã∏= Œ≤rij(0)), Pr(Œ≥rij(t) Ã∏= Œ≥rij(0)) ‚â§
12
‚àö"
DR,0.23868312757201646,"2œÄŒæ (1 + œµ)
‚àö"
DR,0.24074074074074073,dR := ÀúR.
DR,0.24279835390946503,"We provide the full proof in Appendix A.1. Probabilities in Lemma 1 can be bounded as long as the
probability that each of indicator A+
ri(t), A‚àí
ri(t), A+
rj(t), A‚àí
rj(t) changes is upper bounded respec-
tively. When the change of wr(t) is bounded, the indicators can change during the training only if at
initialization |wr(0)‚ä§xi¬±œµ‚à•wr(0)‚à•1| is sufÔ¨Åciently small, whose probability can be upper bounded
(notation ¬± here means the analysis is consistent for both + and ‚àícases). To bound this probability,
while Du et al. (2019b) simply used the anti-concentration of standard Gaussian distribution in their
standard training setting, here our analysis is different due to additional perturbation-related terms
œµ‚à•wr(0)‚à•1, and we combine anti-concentration and the tail bound of standard Gaussian in our proof."
DR,0.2448559670781893,"We can then bound the change of the Gram matrix, i.e., ‚à•H(t) ‚àíH(0)‚à•2:
Lemma 2. ‚àÄr ‚àà[m], at some time t > 0, suppose ‚à•wr(t) ‚àíwr(0)‚à•2 ‚â§R holds for some constant
R, for any conÔ¨Ådence Œ¥(0 < Œ¥ < 1), with probability at least 1 ‚àíŒ¥, it holds that"
DR,0.24691358024691357,‚à•H(t) ‚àíH(0)‚à•2 ‚â§12(1 + œµ)(1 + 2œµ + œµ2)d1.5n2 ‚àö
DR,0.24897119341563786,"2œÄŒæŒ¥
R.
(7)"
DR,0.25102880658436216,"This can be proved by Ô¨Årst upper bounding E[|Hij(t) ‚àíHij(0)|] (‚àÄ1 ‚â§i, j ‚â§n) using Lemma 1,
and then by Markov‚Äôs inequality, we can upper bound ‚à•H(t) ‚àíH(0)‚à•2 with high probability."
DR,0.25308641975308643,Published as a conference paper at ICLR 2022
DR,0.2551440329218107,"We provide the proof in Appendix A.2.
And by triangle inequality, we can also lower bound
Œªmin(H(t)):
Corollary 1. ‚àÄr ‚àà[m], at some time t > 0, suppose ‚à•wr(t) ‚àíwr(0)‚à•2 ‚â§R holds for some
constant R, for any conÔ¨Ådence Œ¥(0 < Œ¥ < 1), with probability at least 1 ‚àíŒ¥, it holds that"
DR,0.257201646090535,Œªmin(H(t)) ‚â•Œªmin(H(0)) ‚àí12(1 + œµ)(1 + 2œµ + œµ2)d1.5n2 ‚àö
DR,0.25925925925925924,"2œÄŒæŒ¥
R,
(8)"
DR,0.2613168724279835,where Œªmin(¬∑) stands for the minimum eigenvalue.
DR,0.26337448559670784,"We also need to lower bound Œªmin(H(0)) in order to lower bound Œªmin(H(t)). Given Assumption 2,
we show that the minimum eigenvalue of H‚àûis positive:
Lemma 3. When the dataset satisÔ¨Åes Assumption 2, Œª0 := Œªmin(H‚àû) > 0 holds true."
DR,0.2654320987654321,"The lemma can be similarly proved as Theorem 3.1 in Du et al. (2019b), but we have a different
Assumption 2 considering perturbations. We discuss in more detail in Appendix A.3. Then we can
lower bound Œªmin(H(0)) by Lemma 3.1 from Du et al. (2019b):
Lemma 4 (Lemma 3.1 from Du et al. (2019b)). If Œª0 > 0, for any conÔ¨Ådence Œ¥(0 < Œ¥ < 1), take
m = ‚Ñ¶( n2"
DR,0.2674897119341564,"Œª2
0 log( n"
DR,0.26954732510288065,"Œ¥ )), then with probability at least 1 ‚àíŒ¥, it holds true that Œªmin(H(0)) ‚â•3 4Œª0."
DR,0.2716049382716049,"Although we have different values in H(0) for IBP training, we can still adopt their original lemma
because their proof by Hoeffding‚Äôs inequality is general regardless of values in H(0). We then
plug in Œªmin(H(0)) ‚â•3"
DR,0.2736625514403292,"4Œª0 to Eq. (8), and we solve the inequality to Ô¨Ånd a proper R such that
Œªmin(H)(t) ‚â•Œª0"
DR,0.2757201646090535,"2 , as shown in the following lemma (proved in Appendix A.4):
Lemma 5. For any conÔ¨Ådence Œ¥(0 < Œ¥ < 1), ‚àÄr ‚àà[m], suppose ‚à•wr(t) ‚àíwr(0)‚à•2 ‚â§R holds,
where R =
cŒ¥Œª0
d1.5n2 with c =
‚àö"
DR,0.2777777777777778,"2œÄŒæ
384 , then probability at least 1 ‚àíŒ¥, Œªmin(H(t)) ‚â•Œª0"
DR,0.27983539094650206,2 holds.
DR,0.28189300411522633,"Therefore, we have shown that with overparameterization (required by Lemma 4), when wr is rel-
atively stable during training for all r ‚àà[m], i.e., the maximum change on wr(t) is upper bounded
during training (characterized by the ‚Ñì2-norm of weight change restricted by R), H(t) is also rela-
tively stable and remains positive deÔ¨Ånite with high probability."
CONVERGENCE OF THE IBP ROBUST LOSS,0.2839506172839506,"4.2
CONVERGENCE OF THE IBP ROBUST LOSS"
CONVERGENCE OF THE IBP ROBUST LOSS,0.28600823045267487,"Next, we can derive the upper bound of the IBP loss during training. In the following lemma, we
show that when H(t) remains positive deÔ¨Ånite, the IBP loss L(t) descends in a linear convergence
rate, and meanwhile we have an upper bound on the change of wr(t) w.r.t. time t:"
CONVERGENCE OF THE IBP ROBUST LOSS,0.2880658436213992,"Lemma 6. Suppose for 0 ‚â§s ‚â§t, Œªmin(H(t)) ‚â•Œª0"
CONVERGENCE OF THE IBP ROBUST LOSS,0.29012345679012347,"2 , we have"
CONVERGENCE OF THE IBP ROBUST LOSS,0.29218106995884774,"L(t) ‚â§exp

2L(0)
"
CONVERGENCE OF THE IBP ROBUST LOSS,0.294238683127572,"L(0) exp

‚àíŒª0t 2"
CONVERGENCE OF THE IBP ROBUST LOSS,0.2962962962962963,"
,
‚à•wr(t) ‚àíwr(0)‚à•2 ‚â§nt
‚àöm."
CONVERGENCE OF THE IBP ROBUST LOSS,0.29835390946502055,"This lemma is proved in Appendix A.5, which follows the proof of Lemma 5.4 in Zou et al. (2018).
To guarantee that Œªmin(H(s)) ‚â•Œª0"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3004115226337449,"2 for 0 ‚â§s ‚â§t, by Lemma 5, we only require
nt
‚àöm ‚â§R ="
CONVERGENCE OF THE IBP ROBUST LOSS,0.30246913580246915,"cŒ¥Œª0
d1.5n2 , which holds sufÔ¨Åciently by"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3045267489711934,"t ‚â§cŒ¥Œª0
‚àöm
d1.5n3 .
(9)"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3065843621399177,"Meanwhile, for each example i, the model can be certiÔ¨Åed by IBP on example i with any ‚Ñì‚àûper-
turbation within radius œµ, if and only if ui > 0, and this condition is equivalent to l(ui) < Œ∫, where
Œ∫ := log(1 + exp(0)). Therefore, to reach zero training error on the whole training set at time t, we
can require L(t) < Œ∫, which implies that ‚àÄ1 ‚â§i ‚â§n, l(ui) < Œ∫. Then with Lemma 6, we want the
upper bound of L(t) to be less than Œ∫:"
CONVERGENCE OF THE IBP ROBUST LOSS,0.30864197530864196,"L(t) ‚â§exp

2L(0)
"
CONVERGENCE OF THE IBP ROBUST LOSS,0.31069958847736623,"L(0) exp

‚àíŒª0t 2"
CONVERGENCE OF THE IBP ROBUST LOSS,0.31275720164609055,"
< Œ∫,"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3148148148148148,Published as a conference paper at ICLR 2022
CONVERGENCE OF THE IBP ROBUST LOSS,0.3168724279835391,which holds sufÔ¨Åciently by t > 4 Œª0
CONVERGENCE OF THE IBP ROBUST LOSS,0.31893004115226337,"
log
L(0) Œ∫"
CONVERGENCE OF THE IBP ROBUST LOSS,0.32098765432098764,"
+ L(0)

.
(10)"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3230452674897119,"To make Eq. (10) reachable at some t, with the constraint in Eq. (9) we require: 4
Œª0"
CONVERGENCE OF THE IBP ROBUST LOSS,0.32510288065843623,"
log
L(0) Œ∫"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3271604938271605,"
+ L(0)

< cŒ¥Œª0
‚àöm
d1.5n3 .
(11)"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3292181069958848,"The left-hand-side of Eq. (11) can be upper bounded by 4
Œª0"
CONVERGENCE OF THE IBP ROBUST LOSS,0.33127572016460904,"
log
L(0) Œ∫"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3333333333333333,"
+ L(0)

= 4"
CONVERGENCE OF THE IBP ROBUST LOSS,0.33539094650205764,"Œª0
(L(0) + log(L(0)) ‚àílog(Œ∫)) ‚â§4"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3374485596707819,"Œª0
(2L(0) ‚àílog(Œ∫))."
CONVERGENCE OF THE IBP ROBUST LOSS,0.3395061728395062,"Therefore, in order to have Eq. (11) hold, it sufÔ¨Åces to have"
CONVERGENCE OF THE IBP ROBUST LOSS,0.34156378600823045,"4
Œª0
(2L(0) ‚àílog(Œ∫)) < cŒ¥Œª0
‚àöm
d1.5n3
=‚áíL(0) + c0 < c‚Ä≤Œ¥Œª2
0
‚àöm
d1.5n3
,
(12)"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3436213991769547,where c‚Ä≤ := c
CONVERGENCE OF THE IBP ROBUST LOSS,0.345679012345679,8 and c0 are positive constants.
CONVERGENCE OF THE IBP ROBUST LOSS,0.3477366255144033,"Since L(0) has randomness from the randomly initialized weight W, we need to upper bound the
value of L(0) as we show in the following lemma (proved in Appendix A.6 by concentration):
Lemma 7. In natural training, for any conÔ¨Ådence Œ¥(0 < Œ¥ < 1), with probability at least 1 ‚àíŒ¥,
L(0) = O( n"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3497942386831276,"Œ¥ ) holds. In IBP training, for any conÔ¨Ådence Œ¥(0 < Œ¥ < 1), with probability at least
1 ‚àíŒ¥, L(0) = O( n‚àömdœµ Œ¥
+ n"
CONVERGENCE OF THE IBP ROBUST LOSS,0.35185185185185186,Œ¥ ) holds.
CONVERGENCE OF THE IBP ROBUST LOSS,0.35390946502057613,"And this lemma implies that with large n and m, there exist constants c1, c2, c3 such that"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3559670781893004,L(0) ‚â§c1n‚àömdœµ
CONVERGENCE OF THE IBP ROBUST LOSS,0.35802469135802467,"Œ¥
+ c2n"
CONVERGENCE OF THE IBP ROBUST LOSS,0.360082304526749,"Œ¥
+ c3.
(13)"
CONVERGENCE OF THE IBP ROBUST LOSS,0.36213991769547327,"Plug Eq. (13) into Eq. (12), then the requirement in Eq. (12) can be relaxed into:"
CONVERGENCE OF THE IBP ROBUST LOSS,0.36419753086419754,"c‚Ä≤Œ¥Œª2
0
‚àöm
d1.5n3
> c1n‚àömdœµ"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3662551440329218,"Œ¥
+ c2n"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3683127572016461,"Œ¥
+ c3 + c0 =‚áí
 c‚Ä≤Œ¥Œª2
0
d1.5n3 ‚àíc1ndœµ Œ¥"
CONVERGENCE OF THE IBP ROBUST LOSS,0.37037037037037035,‚àöm > c2n
CONVERGENCE OF THE IBP ROBUST LOSS,0.3724279835390947,"Œ¥
+ c4,
(14)"
CONVERGENCE OF THE IBP ROBUST LOSS,0.37448559670781895,"where c4 := c3 + c0 is a constant. As long as Eq. (14) holds, Eq. (11) also holds, and thereby IBP
training is guaranteed to converge to zero IBP robust error on the training set."
PROVING THE MAIN THEOREM,0.3765432098765432,"4.3
PROVING THE MAIN THEOREM"
PROVING THE MAIN THEOREM,0.3786008230452675,"Finally, we are ready to prove the main theorem. To make Eq. (11) satisÔ¨Åed, we want to make its
relaxed version, Eq. (14) hold by sufÔ¨Åciently enlarging m. This requires that the coefÔ¨Åcient of ‚àöm
in Eq. (14) , c‚Ä≤Œ¥Œª2
0
d1.5n3 ‚àíc1ndœµ"
PROVING THE MAIN THEOREM,0.38065843621399176,"Œ¥
to be positive, and we also plug in the constraint on œµ in Lemma 1:"
PROVING THE MAIN THEOREM,0.38271604938271603,"c‚Ä≤Œ¥Œª2
0
d1.5n3 ‚àíc1ndœµ"
PROVING THE MAIN THEOREM,0.38477366255144035,"Œ¥
> 0, œµ ‚â§ ‚àö"
DR,0.3868312757201646,2dR
DR,0.3888888888888889,"log(
q 2œÄd"
DR,0.39094650205761317,"R Œæ)
."
DR,0.39300411522633744,"Combining these two constraints, we can obtain the constraint for œµ in the main theorem:"
DR,0.3950617283950617,"œµ < min
 c‚Ä≤Œ¥2Œª2
0
c1d2.5n3 , ‚àö"
DR,0.39711934156378603,2dR
DR,0.3991769547325103,"log(
q 2œÄd R Œæ) 
."
DR,0.4012345679012346,"Then by Eq. (14), our requirement on width m is"
DR,0.40329218106995884,"m ‚â•‚Ñ¶

d1.5n4Œ¥Œª0
Œ¥2Œª2
0 ‚àíœµd2.5n4 2
."
DR,0.4053497942386831,"This completes the proof of the main theorem.s In our analysis, we focus on IBP training with œµ > 0.
But IBP with œµ = 0 can also be viewed as standard training. By setting œµ = 0, if m ‚â•‚Ñ¶( n8d3"
DR,0.4074074074074074,"Œª4
0Œ¥4 ),
our result implies that for any conÔ¨Ådence Œ¥ (0 < Œ¥ < 1), standard training with logistic loss also
converges to zero training error with probability at least 1 ‚àíŒ¥. And as œµ gets larger, the required m
for convergence also becomes larger."
DR,0.4094650205761317,Published as a conference paper at ICLR 2022
DR,0.411522633744856,"500
2000
5000
10000
80000
Model width m 0.00 0.01 0.02 0.03 0.04 Error"
DR,0.41358024691358025,"standard training
IBP training with = 0.04"
DR,0.4156378600823045,IBP training with = 0.001
DR,0.4176954732510288,"(a) Final training error of standard training and
IBP (with œµ ‚àà{0.001, 0.04}) respectively, when
the width m of the model is varied."
DR,0.41975308641975306,"0.04
0.05
0.1
0.2
 perutbration radius 0.1 0.2 0.3 0.4 Error"
DR,0.4218106995884774,"hidden layer width=2000
hidden layer width=5000"
DR,0.42386831275720166,"(b) Final training error of IBP training (on models
with width 2000 and 5000 respectively), when the
perturbation radius œµ is varied."
DR,0.42592592592592593,Figure 1: Experimental results.
EXPERIMENTS,0.4279835390946502,"5
EXPERIMENTS"
EXPERIMENTS,0.43004115226337447,"We further conduct experiments to compare the convergence of networks with different widths m for
natural training and IBP training respectively. We use the MNIST (LeCun et al., 2010) dataset and
take digit images with label 2 and 5 for binary classiÔ¨Åcation. And we use a two-layer fully-connected
ReLU network with a variable width. We train the model for 70 epochs with SGD, and we keep œµ
Ô¨Åxed throughout the whole training process. We present results in Figure 1. First, compared with
standard training, for the same width m, IBP has higher training errors (Figure 1a). Second, for
relatively large œµ (œµ = 0.04), even if we enlarge m up to 80,000 limited by the memory of a single
GeForce RTX 2080 GPU, IBP error is still far away from 0 (Figure 1a). This is consistent with
our main theorem that when œµ is too large, simply enlarging m cannot guarantee the convergence.
Moreover, when œµ is even larger, IBP training falls into a local minimum of random guess (with
errors close to 50%) (Figure 1b). We conjecture that this is partly because Œª0 can be very small
with a large perturbation, and then the training can be much more difÔ¨Åcult, and this difÔ¨Åculty cannot
be alleviated by simply enlarging the network width m. Existing works with IBP-based training
typically use a scheduling on œµ and gradually increase œµ from 0 until the target value for more stable
training. Overall, the empirical observations match our theoretical results."
CONCLUSION,0.43209876543209874,"6
CONCLUSION"
CONCLUSION,0.43415637860082307,"In this paper, we present the Ô¨Årst theoretical analysis of IBP-based certiÔ¨Åed robust training, and
we show that IBP training can converge to zero training error with high probability, under certain
conditions on perturbation radius and network width. Meanwhile, since the IBP robust accuracy
is a lower bound of the true robust accuracy (see Section 3.2), upon convergence the true robust
accuracy also converges to 100% on training data and the certiÔ¨Åcation by IBP accurately reÔ¨Çects
the true robustness. Our results have a condition requiring a small upper bound on œµ, and it will be
interesting for future work to study how to relax this condition, take the effect of œµ scheduling into
consideration, and extend the analysis to deeper networks."
CONCLUSION,0.43621399176954734,ACKNOWLEDGEMENTS
CONCLUSION,0.4382716049382716,"We thank the anonymous reviewers for their helpful comments. This work is partially supported
by NSF under IIS-2008173, IIS-2048280 and by Army Research Laboratory under agreement num-
ber W911NF-20-2-0158; QG is partially supported by the National Science Foundation CAREER
Award 1906169 and IIS-2008981. The views and conclusions contained in this paper are those of
the authors and should not be interpreted as representing any funding agencies."
CONCLUSION,0.4403292181069959,Published as a conference paper at ICLR 2022
REFERENCES,0.44238683127572015,REFERENCES
REFERENCES,0.4444444444444444,"Zeyuan Allen-Zhu, Yuanzhi Li, and Zhao Song. A convergence theory for deep learning via over-
parameterization. In International Conference on Machine Learning, volume 97 of Proceed-
ings of Machine Learning Research, pp. 242‚Äì252, 2019. URL http://proceedings.mlr.
press/v97/allen-zhu19a.html."
REFERENCES,0.44650205761316875,"Sanjeev Arora, Nadav Cohen, and Elad Hazan.
On the optimization of deep networks: Im-
plicit acceleration by overparameterization.
In International Conference on Machine Learn-
ing, volume 80 of Proceedings of Machine Learning Research, pp. 244‚Äì253, 2018.
URL
http://proceedings.mlr.press/v80/arora18a.html."
REFERENCES,0.448559670781893,"Anish Athalye, Nicholas Carlini, and David A. Wagner. Obfuscated gradients give a false sense
of security: Circumventing defenses to adversarial examples. In International Conference on
Machine Learning, volume 80 of Proceedings of Machine Learning Research, pp. 274‚Äì283, 2018.
URL http://proceedings.mlr.press/v80/athalye18a.html."
REFERENCES,0.4506172839506173,"Maximilian Baader, Matthew Mirman, and Martin T. Vechev. Universal approximation with certiÔ¨Åed
networks. In International Conference on Learning Representations, 2020. URL https://
openreview.net/forum?id=B1gX8kBtPr."
REFERENCES,0.45267489711934156,"Mislav Balunovic and Martin T. Vechev.
Adversarial training and provable defenses: Bridging
the gap.
In International Conference on Learning Representations, 2020.
URL https://
openreview.net/forum?id=SJxSDxrKDr."
REFERENCES,0.4547325102880658,"Rudy Bunel, Ilker Turkaslan, Philip H. S. Torr, Pushmeet Kohli, and Pawan Kumar Mudigonda. A
uniÔ¨Åed view of piecewise linear neural network veriÔ¨Åcation. In Advances in Neural Information
Processing Systems, pp. 4795‚Äì4804, 2018. URL https://proceedings.neurips.cc/
paper/2018/hash/be53d253d6bc3258a8160556dda3e9b2-Abstract.html."
REFERENCES,0.4567901234567901,"Nicholas Carlini and David Wagner. Adversarial examples are not easily detected: Bypassing ten
detection methods.
In Proceedings of the 10th ACM Workshop on ArtiÔ¨Åcial Intelligence and
Security, pp. 3‚Äì14, 2017."
REFERENCES,0.4588477366255144,"Zixiang Chen, Yuan Cao, Difan Zou, and Quanquan Gu. How much over-parameterization is sufÔ¨Å-
cient to learn deep relu networks? CoRR, abs/1911.12360, 2019. URL http://arxiv.org/
abs/1911.12360."
REFERENCES,0.4609053497942387,"Jeremy M. Cohen, Elan Rosenfeld, and J. Zico Kolter. CertiÔ¨Åed adversarial robustness via random-
ized smoothing. In International Conference on Machine Learning, volume 97 of Proceedings
of Machine Learning Research, pp. 1310‚Äì1320, 2019. URL http://proceedings.mlr.
press/v97/cohen19c.html."
REFERENCES,0.46296296296296297,"Simon S. Du, Jason D. Lee, Haochuan Li, Liwei Wang, and Xiyu Zhai.
Gradient descent
Ô¨Ånds global minima of deep neural networks. In International Conference on Machine Learn-
ing, volume 97 of Proceedings of Machine Learning Research, pp. 1675‚Äì1685, 2019a. URL
http://proceedings.mlr.press/v97/du19c.html."
REFERENCES,0.46502057613168724,"Simon S. Du, Xiyu Zhai, Barnab¬¥as P¬¥oczos, and Aarti Singh. Gradient descent provably optimizes
over-parameterized neural networks. In International Conference on Learning Representations,
2019b. URL https://openreview.net/forum?id=S1eK3i09YQ."
REFERENCES,0.4670781893004115,"Krishnamurthy Dvijotham,
Sven Gowal,
Robert Stanforth,
Relja Arandjelovic,
Brendan
O‚ÄôDonoghue, Jonathan Uesato, and Pushmeet Kohli. Training veriÔ¨Åed learners with learned ver-
iÔ¨Åers. arXiv preprint arXiv:1805.10265, 2018."
REFERENCES,0.4691358024691358,"Ruiqi Gao, Tianle Cai, Haochuan Li, Cho-Jui Hsieh, Liwei Wang, and Jason D. Lee. Convergence of
adversarial training in overparametrized neural networks. In Advances in Neural Information Pro-
cessing Systems, pp. 13009‚Äì13020, 2019. URL https://proceedings.neurips.cc/
paper/2019/hash/348a38cd25abeab0e440f37510e9b1fa-Abstract.html."
REFERENCES,0.4711934156378601,"Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. In International Conference on Learning Representations, 2015. URL http://
arxiv.org/abs/1412.6572."
REFERENCES,0.4732510288065844,Published as a conference paper at ICLR 2022
REFERENCES,0.47530864197530864,"Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin, Jonathan Ue-
sato, Timothy Mann, and Pushmeet Kohli. On the effectiveness of interval bound propagation for
training veriÔ¨Åably robust models. arXiv preprint arXiv:1810.12715, 2018."
REFERENCES,0.4773662551440329,"Chuan Guo, Mayank Rana, Moustapha Ciss¬¥e, and Laurens van der Maaten. Countering adversarial
images using input transformations. In International Conference on Learning Representations,
2018. URL https://openreview.net/forum?id=SyJ7ClWCb."
REFERENCES,0.4794238683127572,"Arthur Jacot, Cl¬¥ement Hongler, and Franck Gabriel.
Neural tangent kernel: Convergence and
generalization in neural networks. In Advances in Neural Information Processing Systems, pp.
8580‚Äì8589, 2018. URL https://proceedings.neurips.cc/paper/2018/hash/
5a4be1fa34e62bb8a6ec6b91d2462f5a-Abstract.html."
REFERENCES,0.48148148148148145,"Ziwei Ji and Matus Telgarsky.
Polylogarithmic width sufÔ¨Åces for gradient descent to achieve
arbitrarily small test error with shallow relu networks.
CoRR, abs/1909.12292, 2019.
URL
http://arxiv.org/abs/1909.12292."
REFERENCES,0.4835390946502058,"Nikola Jovanovi¬¥c, Mislav Balunovi¬¥c, Maximilian Baader, and Martin Vechev. CertiÔ¨Åed defenses:
Why tighter relaxations may hurt training? arXiv preprint arXiv:2102.06700, 2021."
REFERENCES,0.48559670781893005,"Alexey Kurakin, Ian Goodfellow, and Samy Bengio. Adversarial examples in the physical world.
arXiv preprint arXiv:1607.02533, 2016."
REFERENCES,0.4876543209876543,"Yann LeCun, Corinna Cortes, and CJ Burges. Mnist handwritten digit database. ATT Labs [Online].
Available: http://yann.lecun.com/exdb/mnist, 2, 2010."
REFERENCES,0.4897119341563786,"Sungyoon Lee, Woojin Lee, Jinseong Park, and Jaewook Lee. Loss landscape matters: Training
certiÔ¨Åably robust models with favorable loss landscape. OpenReview, 2021."
REFERENCES,0.49176954732510286,"Bai Li, Changyou Chen, Wenlin Wang, and Lawrence Carin. CertiÔ¨Åed adversarial robustness with
additive noise. In Advances in Neural Information Processing Systems, pp. 9464‚Äì9474, 2019."
REFERENCES,0.49382716049382713,"Yuanzhi Li and Yingyu Liang. Learning overparameterized neural networks via stochastic gra-
dient descent on structured data. In Advances in Neural Information Processing Systems, pp.
8168‚Äì8177, 2018. URL https://proceedings.neurips.cc/paper/2018/hash/
54fe976ba170c19ebae453679b362263-Abstract.html."
REFERENCES,0.49588477366255146,"Zhaoyang Lyu, Minghao Guo, Tong Wu, Guodong Xu, Kehuan Zhang, and Dahua Lin. Towards
evaluating and training veriÔ¨Åably robust neural networks. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition, pp. 4308‚Äì4317, 2021."
REFERENCES,0.49794238683127573,"Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. To-
wards deep learning models resistant to adversarial attacks. In International Conference on Learn-
ing Representations, 2018. URL https://openreview.net/forum?id=rJzIBfZAb."
REFERENCES,0.5,"Matthew Mirman, Timon Gehr, and Martin T. Vechev. Differentiable abstract interpretation for
provably robust neural networks.
In International Conference on Machine Learning, vol-
ume 80 of Proceedings of Machine Learning Research, pp. 3575‚Äì3583, 2018.
URL http:
//proceedings.mlr.press/v80/mirman18b.html."
REFERENCES,0.5020576131687243,"Aditi Raghunathan, Jacob Steinhardt, and Percy Liang.
CertiÔ¨Åed defenses against adversarial
examples.
In International Conference on Learning Representations, 2018a.
URL https:
//openreview.net/forum?id=Bys4ob-Rb."
REFERENCES,0.5041152263374485,"Aditi Raghunathan, Jacob Steinhardt, and Percy Liang.
SemideÔ¨Ånite relaxations for certifying
robustness to adversarial examples.
In Advances in Neural Information Processing Systems,
pp. 10900‚Äì10910, 2018b. URL https://proceedings.neurips.cc/paper/2018/
hash/29c0605a3bab4229e46723f89cf59d83-Abstract.html."
REFERENCES,0.5061728395061729,"Hadi Salman, Jerry Li, Ilya P. Razenshteyn, Pengchuan Zhang, Huan Zhang, S¬¥ebastien
Bubeck,
and Greg Yang.
Provably robust deep learning via adversarially trained
smoothed classiÔ¨Åers.
In Advances in Neural Information Processing Systems, pp. 11289‚Äì
11300,
2019.
URL https://proceedings.neurips.cc/paper/2019/hash/
3a24b25a7b092a252166a1641ae953e7-Abstract.html."
REFERENCES,0.5082304526748971,Published as a conference paper at ICLR 2022
REFERENCES,0.5102880658436214,"Zhouxing Shi, Yihan Wang, Huan Zhang, Jinfeng Yi, and Cho-Jui Hsieh.
Fast certiÔ¨Åed robust
training via better initialization and shorter warmup. arXiv preprint arXiv:2103.17268, 2021."
REFERENCES,0.5123456790123457,"Gagandeep Singh, Timon Gehr, Matthew Mirman, Markus P¬®uschel, and Martin T. Vechev. Fast
and effective robustness certiÔ¨Åcation. In Advances in Neural Information Processing Systems,
pp. 10825‚Äì10836, 2018.
URL https://proceedings.neurips.cc/paper/2018/
hash/f2f446980d8e971ef3da97af089481c3-Abstract.html."
REFERENCES,0.51440329218107,"Gagandeep Singh, Timon Gehr, Markus P¬®uschel, and Martin Vechev. An abstract domain for certi-
fying neural networks. Proceedings of the ACM on Programming Languages, 3(POPL):41, 2019."
REFERENCES,0.5164609053497943,"Yang Song, Taesup Kim, Sebastian Nowozin, Stefano Ermon, and Nate Kushman. Pixeldefend:
Leveraging generative models to understand and defend against adversarial examples. In Interna-
tional Conference on Learning Representations, 2018. URL https://openreview.net/
forum?id=rJUYGxbCW."
REFERENCES,0.5185185185185185,"Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J. Goodfel-
low, and Rob Fergus. Intriguing properties of neural networks. In International Conference on
Learning Representations, 2014. URL http://arxiv.org/abs/1312.6199."
REFERENCES,0.5205761316872428,"Florian Tramer, Nicholas Carlini, Wieland Brendel, and Aleksander Madry. On adaptive attacks to
adversarial example defenses. arXiv preprint arXiv:2002.08347, 2020."
REFERENCES,0.522633744855967,"Shiqi Wang, Yizheng Chen, Ahmed Abdou, and Suman Jana. Mixtrain: Scalable training of formally
robust neural networks. arXiv preprint arXiv:1811.02625, 2018a."
REFERENCES,0.5246913580246914,"Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana.
EfÔ¨Åcient formal
safety analysis of neural networks. In Advances in Neural Information Processing Systems, pp.
6369‚Äì6379, 2018b. URL https://proceedings.neurips.cc/paper/2018/hash/
2ecd2bd94734e5dd392d8678bc64cdab-Abstract.html."
REFERENCES,0.5267489711934157,"Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana. Formal security analysis
of neural networks using symbolic intervals. In 27th {USENIX} Security Symposium ({USENIX}
Security 18), pp. 1599‚Äì1614, 2018c."
REFERENCES,0.5288065843621399,"Yisen Wang, Xingjun Ma, James Bailey, Jinfeng Yi, Bowen Zhou, and Quanquan Gu.
On the
convergence and robustness of adversarial training.
In International Conference on Machine
Learning, volume 97 of Proceedings of Machine Learning Research, pp. 6586‚Äì6595, 2019. URL
http://proceedings.mlr.press/v97/wang19i.html."
REFERENCES,0.5308641975308642,"Zi Wang, Aws Albarghouthi, Gautam Prakriya, and Somesh Jha. Interval universal approximation
for neural networks. arXiv preprint arXiv:2007.06093, 2020."
REFERENCES,0.5329218106995884,"Tsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Luca Daniel, Duane S.
Boning, and Inderjit S. Dhillon. Towards fast computation of certiÔ¨Åed robustness for relu net-
works. In International Conference on Machine Learning, volume 80 of Proceedings of Machine
Learning Research, pp. 5273‚Äì5282, 2018.
URL http://proceedings.mlr.press/
v80/weng18a.html."
REFERENCES,0.5349794238683128,"Eric Wong and J. Zico Kolter. Provable defenses against adversarial examples via the convex outer
adversarial polytope. In International Conference on Machine Learning, volume 80 of Proceed-
ings of Machine Learning Research, pp. 5283‚Äì5292, 2018. URL http://proceedings.
mlr.press/v80/wong18a.html."
REFERENCES,0.5370370370370371,"Eric Wong, Frank R. Schmidt, Jan Hendrik Metzen, and J. Zico Kolter.
Scaling prov-
able adversarial defenses.
In Advances in Neural Information Processing Systems, pp.
8410‚Äì8419, 2018. URL https://proceedings.neurips.cc/paper/2018/hash/
358f9e7be09177c17d0d17ff73584307-Abstract.html."
REFERENCES,0.5390946502057613,"Chang Xiao, Peilin Zhong, and Changxi Zheng.
Enhancing adversarial defense by k-winners-
take-all.
In International Conference on Learning Representations, 2020.
URL https:
//openreview.net/forum?id=Skgvy64tvr."
REFERENCES,0.5411522633744856,Published as a conference paper at ICLR 2022
REFERENCES,0.5432098765432098,"Kai Y. Xiao, Vincent Tjeng, Nur Muhammad (Mahi) ShaÔ¨Åullah, and Aleksander Madry. Training
for faster adversarial robustness veriÔ¨Åcation via inducing relu stability. In International Confer-
ence on Learning Representations, 2019. URL https://openreview.net/forum?id=
BJfIVjAcKm."
REFERENCES,0.5452674897119342,"Kaidi Xu, Zhouxing Shi, Huan Zhang, Yihan Wang, Kai-Wei Chang, Minlie Huang, Bhavya
Kailkhura, Xue Lin, and Cho-Jui Hsieh. Automatic perturbation analysis for scalable certiÔ¨Åed
robustness and beyond. Advances in Neural Information Processing Systems, 33, 2020."
REFERENCES,0.5473251028806584,"Bohang Zhang, Tianle Cai, Zhou Lu, Di He, and Liwei Wang. Towards certifying l-inÔ¨Ånity ro-
bustness using neural networks with l-inf-dist neurons. In International Conference on Machine
Learning, pp. 12368‚Äì12379. PMLR, 2021."
REFERENCES,0.5493827160493827,"Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric P. Xing, Laurent El Ghaoui, and Michael I. Jordan.
Theoretically principled trade-off between robustness and accuracy. In International Conference
on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pp. 7472‚Äì7482,
2019. URL http://proceedings.mlr.press/v97/zhang19p.html."
REFERENCES,0.551440329218107,"Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel. EfÔ¨Åcient neural net-
work robustness certiÔ¨Åcation with general activation functions. In Advances in Neural Information
Processing Systems, pp. 4944‚Äì4953, 2018. URL https://proceedings.neurips.cc/
paper/2018/hash/d04863f100d59b3eb688a11f95b0ae60-Abstract.html."
REFERENCES,0.5534979423868313,"Huan Zhang, Hongge Chen, Chaowei Xiao, Sven Gowal, Robert Stanforth, Bo Li, Duane S. Boning,
and Cho-Jui Hsieh. Towards stable and efÔ¨Åcient training of veriÔ¨Åably robust neural networks. In
International Conference on Learning Representations, 2020a. URL https://openreview.
net/forum?id=Skxuk1rFwB."
REFERENCES,0.5555555555555556,"Yi Zhang, Orestis Plevrakis, Simon S Du, Xingguo Li, Zhao Song, and Sanjeev Arora.
Over-
parameterized adversarial training: An analysis overcoming the curse of dimensionality. arXiv
preprint arXiv:2002.06668, 2020b."
REFERENCES,0.5576131687242798,"Difan Zou, Yuan Cao, Dongruo Zhou, and Quanquan Gu. Stochastic gradient descent optimizes
over-parameterized deep relu networks. arXiv preprint arXiv:1811.08888, 2018."
REFERENCES,0.5596707818930041,"Difan Zou, Spencer Frei, and Quanquan Gu. Provable robustness of adversarial training for learning
halfspaces with noise. arXiv preprint arXiv:2104.09437, 2021."
REFERENCES,0.5617283950617284,Published as a conference paper at ICLR 2022
REFERENCES,0.5637860082304527,"A
PROOF OF LEMMAS"
REFERENCES,0.565843621399177,"A.1
PROOF OF LEMMA 1"
REFERENCES,0.5679012345679012,"Proof. For all i ‚àà[n], r ‚àà[m], we Ô¨Årst consider the change of indicator 1(wr(t)‚ä§xi¬±œµ‚à•wr(t)‚à•1 >
0) during training compared to the value at t = 0 (the notation ¬± here means the analysis is consis-
tent for both + and ‚àícases). Under the constraint that ‚à•wr(t)¬±wr(0)‚à•2 ‚â§R and ‚à•xi‚à•‚àû‚àà[0, 1]d,
we have (see Appendix B.2 for details):
wr(t)‚ä§xi ¬± œµ‚à•wr(t)‚à•1 ‚àí(wr(0)‚ä§xi ¬± œµ‚à•wr(0)‚à•1)
 ‚â§(1 + œµ)
‚àö"
REFERENCES,0.5699588477366255,"dR.
(15)"
REFERENCES,0.5720164609053497,"Thereby, if sign(wr(t)‚ä§xi ¬± œµ‚à•wr(t)‚à•1) Ã∏= sign(wr(0)‚ä§xi ¬± œµ‚à•wr(0)‚à•1), then at initialization,
we must have"
REFERENCES,0.5740740740740741,"|wr(0)‚ä§xi ¬± œµ‚à•wr(0)‚à•1| ‚â§(1 + œµ)
‚àö"
REFERENCES,0.5761316872427984,"dR.
(16)"
REFERENCES,0.5781893004115226,"We want to upper bound the probability that Eq. (16) holds. It is easy to show that if the following
two inequalities hold, then Eq. (16) does not hold for sure:"
REFERENCES,0.5802469135802469,"|wr(0)‚ä§xi| ‚â•2(1 + œµ)
‚àö"
REFERENCES,0.5823045267489712,"dR,
(17)"
REFERENCES,0.5843621399176955,"œµ‚à•wr(0)‚à•1 ‚â§(1 + œµ)
‚àö"
REFERENCES,0.5864197530864198,"dR.
(18)"
REFERENCES,0.588477366255144,"Therefore,"
REFERENCES,0.5905349794238683,"Pr

|wr(0)‚ä§xi ¬± œµ‚à•wr(0)‚à•1| ‚â§(1 + œµ)
‚àö dR
"
REFERENCES,0.5925925925925926,"‚â§1 ‚àíPr

|wr(0)‚ä§xi| ‚â•2(1 + œµ)
‚àö"
REFERENCES,0.5946502057613169,"dR and ‚à•wr(0)‚à•1 ‚â§(1 + œµ)
‚àö"
REFERENCES,0.5967078189300411,"dR

."
REFERENCES,0.5987654320987654,"For Eq. (17), by anti-concentration inequality for Gaussian, we have"
REFERENCES,0.6008230452674898,"Pr(|wr(0)‚ä§xi| ‚â§2(1 + œµ)
‚àö"
REFERENCES,0.602880658436214,"dR) ‚â§4(1 + œµ)
‚àö dR
‚àö"
REFERENCES,0.6049382716049383,"2œÄŒæ
.
(19)"
REFERENCES,0.6069958847736625,"In other words, with probability at least 1 ‚àí4(1 + œµ)
‚àö"
REFERENCES,0.6090534979423868,"dR/(
‚àö"
REFERENCES,0.6111111111111112,"2œÄŒæ), Eq. (17) holds. And for Eq.
(18), by the tail bound of standard Gaussian and union bound, we have"
REFERENCES,0.6131687242798354,"Pr(œµ‚à•wr(0)‚à•1 ‚â§(1 + œµ)
‚àö"
REFERENCES,0.6152263374485597,"dR) ‚â•1 ‚àí2d exp

‚àí2(1 + œµ)2dR2 œµ2"
REFERENCES,0.6172839506172839,"
.
(20)"
REFERENCES,0.6193415637860082,"Combining Eq. (19) and Eq. (20), Eq. (16) holds with at most the following probability"
REFERENCES,0.6213991769547325,"4(1 + œµ)
‚àö dR
‚àö"
REFERENCES,0.6234567901234568,"2œÄŒæ
+ 2d exp

‚àí2(1 + œµ)2dR2 œµ2"
REFERENCES,0.6255144032921811,"
.
(21)"
REFERENCES,0.6275720164609053,Here we require œµ to be sufÔ¨Åciently small such that
REFERENCES,0.6296296296296297,"(1 + œµ)
‚àö dR
‚àö"
REFERENCES,0.6316872427983539,"2œÄŒæ
‚â•d exp

‚àí2(1 + œµ)2dR2 œµ2"
REFERENCES,0.6337448559670782,"
(22)"
REFERENCES,0.6358024691358025,and we can solve the inequality to obtain an upper bound for œµ (detailed in Appendix B.3): œµ ‚â§ ‚àö
DR,0.6378600823045267,2dR
DR,0.6399176954732511,"log(
q 2œÄd"
DR,0.6419753086419753,"R Œæ)
,
(23)"
DR,0.6440329218106996,"and in this case Eq. (21) holds with probability at least 6
‚àö"
DR,0.6460905349794238,"2œÄŒæ (1 + œµ)
‚àö dR."
DR,0.6481481481481481,Published as a conference paper at ICLR 2022
DR,0.6502057613168725,"Therefore, we upper bound the probability:"
DR,0.6522633744855967,"Pr

sign(wr(t)‚ä§xi ¬± œµ‚à•wr(t)‚à•1) Ã∏= sign(wr(0)‚ä§xi ¬± œµ‚à•wr(0)‚à•1)

‚â§
6
‚àö"
DR,0.654320987654321,"2œÄŒæ (1 + œµ)
‚àö dR."
DR,0.6563786008230452,Thereby
DR,0.6584362139917695,"‚àÄi ‚àà[n], r ‚àà[m], Pr(A+
ri(t) Ã∏= A+
ri(0)), Pr(A‚àí
ri(t) Ã∏= A‚àí
ri(0)) ‚â§
6
‚àö"
DR,0.6604938271604939,"2œÄŒæ (1 + œµ)
‚àö dR."
DR,0.6625514403292181,"Note that at least one of A+
ri(t) and A‚àí
ri(t) always remains zero during training, because condition
yiar = 1 in A+
ri(t) and condition yiar = ‚àí1 in A‚àí
ri(t) are mutually exclusive. Then"
DR,0.6646090534979424,"Pr(A+
ri(t) + A‚àí
ri(t) Ã∏= A+
ri(0) + A‚àí
ri(0)) ‚â§
6
‚àö"
DR,0.6666666666666666,"2œÄŒæ (1 + œµ)
‚àö dR,"
DR,0.668724279835391,"Pr(A+
ri(t) ‚àíA‚àí
ri(t) Ã∏= A+
ri(0) ‚àíA‚àí
ri(0)) ‚â§
6
‚àö"
DR,0.6707818930041153,"2œÄŒæ (1 + œµ)
‚àö dR."
DR,0.6728395061728395,"Next we can upper bound the probability that each of Œ±rij(t), Œ≤rij(t), Œ≥rij(t) (‚àÄi, j ‚àà[n], r ‚àà[m])
changes respectively:"
DR,0.6748971193415638,"Pr(Œ±rij(t) Ã∏= Œ±rij(0)), Pr(Œ≤rij(t) Ã∏= Œ≤rij(0)), Pr(Œ≥rij(t) Ã∏= Œ≥rij(0)) ‚â§
12
‚àö"
DR,0.676954732510288,"2œÄŒæ (1 + œµ)
‚àö dR."
DR,0.6790123456790124,"A.2
PROOF OF LEMMA 2"
DR,0.6810699588477366,"Proof. With Lemma 1, we can bound the expectation of the change for each element in H(t) (Eq.
(6)) as:"
DR,0.6831275720164609,E[|Hij(t) ‚àíHij(0)|] ‚â§1
DR,0.6851851851851852,"mE

m ÀúR‚à•xi‚à•2‚à•xj‚à•2 + œµm ÀúR
 
(‚à•xi‚à•2 + ‚à•xj‚à•2)‚à•sign(wr(t))‚à•2

+ œµ2dm ÀúR
"
DR,0.6872427983539094,‚â§ÀúRd(1 + 2œµ + œµ2)
DR,0.6893004115226338,= 12(1 + œµ)(1 + 2œµ + œµ2)d1.5 ‚àö
DR,0.691358024691358,"2œÄ
(‚àÄi, j ‚àà[n])"
DR,0.6934156378600823,"Then by Markov‚Äôs inequality, we have that with probability at least 1 ‚àíŒ¥,"
DR,0.6954732510288066,"‚à•H(t) ‚àíH(0)‚à•2 ‚â§
X"
DR,0.6975308641975309,"i‚àà[n],j‚àà[n]
|Hij(t) ‚àíHij(0)| ‚â§12(1 + œµ)(1 + 2œµ + œµ2)d1.5n2 ‚àö"
DR,0.6995884773662552,"2œÄŒæŒ¥
R."
DR,0.7016460905349794,"A.3
PROOF OF LEMMA 3"
DR,0.7037037037037037,"Proof. First for simplicity, we deÔ¨Åne œÅi = ‚àíA+
ri(0) + A‚àí
ri(0) (œÅi ‚àà{‚àí1, 0, 1}), and"
DR,0.7057613168724279,"œÜ(xi)(wr(0)) = yi

xi + œµœÅi sign(wr(0)

1

wr(0)‚ä§
xi + œµœÅi sign(wr(0))

> 0

."
DR,0.7078189300411523,"To prove that Œª0 > 0, similar as Theorem 3.1 in Du et al. (2019b), we need to prove that for any
r ‚àà[m], if Œ∑1, Œ∑2, ..., Œ∑n (‚àÄi ‚àà[n], Œ∑i ‚ààR) satisfy Pn
i=1 Œ∑iœÜ(xi)(wr(0)) = 0 almost everywhere
(a.e.) for any wr(0), we have ‚àÄi ‚àà[n], Œ∑i = 0."
DR,0.7098765432098766,"In Theorem 3.1 in Du et al. (2019b), it is proved that for œÜ‚Ä≤(xi)(w) = xi1(w‚ä§xi) (i ‚àà[n]), when
‚àÄi Ã∏= j, xi ‚à¶xj holds, for any Œ∑1, Œ∑2, ..., Œ∑n(‚àÄi ‚àà[n], Œ∑i ‚ààR), if n
X"
DR,0.7119341563786008,"i=1
Œ∑iœÜ‚Ä≤(xi)(wr(0)) = 0,"
DR,0.7139917695473251,Published as a conference paper at ICLR 2022
DR,0.7160493827160493,"then ‚àÄi ‚àà[n], Œ∑i = 0. For any r ‚àà[m], by taking ‚àÄi ‚àà[n], x‚Ä≤
i = xi + œµœÅi sign(wr(0)), we
have œÜ(xi)(wr(0)) = œÜ‚Ä≤(x‚Ä≤
i)(wr(0)), and it holds that x‚Ä≤
i ‚ààB‚àû(xi, œµ), x‚Ä≤
j ‚ààB‚àû(xj, œµ). Then if
xi ‚à¶xj, ‚àÄi, j, Œ∑1, Œ∑2, ..., Œ∑n satisfy Pn
i=1 Œ∑iœÜ‚Ä≤(x‚Ä≤
i)(wr(0)) = 0 a.e., we have ‚àÄi ‚àà[n], Œ∑i = 0."
DR,0.7181069958847737,"Therefore if ‚àÄi, j ‚àà[n], i Ã∏= j, ‚àÄx‚Ä≤
i ‚ààB‚àû(xi, œµ), ‚àÄx‚Ä≤
j ‚ààB‚àû(xj, œµ), x‚Ä≤
i ‚à¶x‚Ä≤
j, if Œ∑1, ..., Œ∑n satisfy X"
DR,0.720164609053498,"i
Œ∑iœÜ(xi)(wr(0)) = 0, then X"
DR,0.7222222222222222,"i
Œ∑iœÜ‚Ä≤(x‚Ä≤
i)(wr(0)) = 0"
DR,0.7242798353909465,"also holds, and then ‚àÄi ‚àà[n], Œ∑i = 0."
DR,0.7263374485596708,"A.4
PROOF OF LEMMA 5"
DR,0.7283950617283951,Proof. The lemma can be proved by solving inequality
DR,0.7304526748971193,Œªmin(H(t)) ‚â•Œªmin(H(0)) ‚àí12(1 + œµ)(1 + 2œµ + œµ2)d1.5n2 ‚àö
DR,0.7325102880658436,"2œÄŒæŒ¥
R ‚â•Œª0"
DR,0.7345679012345679,"2 .
(24)"
DR,0.7366255144032922,"According to Lemma 4, Œªmin(H(0)) ‚â•3"
DR,0.7386831275720165,"4Œª0. And with Eq. (8), in order to ensure Œªmin(H(t)) ‚â•Œª0"
DR,0.7407407407407407,"2 ,
we can make"
DR,0.742798353909465,12(1 + œµ)(1 + 2œµ + œµ2)d1.5n2 ‚àö
DR,0.7448559670781894,"2œÄŒæŒ¥
R ‚â§Œª0 4 ."
DR,0.7469135802469136,This yields R ‚â§ ‚àö
DR,0.7489711934156379,"2œÄŒæŒ¥Œª0
48(1 + œµ)(1 + 2œµ + œµ2)d1.5n2 ."
DR,0.7510288065843621,"Note that 0 ‚â§œµ ‚â§1, and thus 1 + œµ ‚â§2 and 1 + 2œµ + œµ2 ‚â§4 can be upper bounded by constants
respectively. Then we can take R ‚â§ ‚àö"
DR,0.7530864197530864,"2œÄŒæŒ¥Œª0
384d1.5n2 = cŒ¥Œª0"
DR,0.7551440329218106,"d1.5n2 ,
where c = ‚àö"
DR,0.757201646090535,"2œÄŒæ
384 ,"
DR,0.7592592592592593,and in this case Œªmin(H(t)) ‚â•Œª0
DR,0.7613168724279835,2 w.p. at least 1 ‚àíŒ¥ probability.
DR,0.7633744855967078,"A.5
PROOF OF LEMMA 6"
DR,0.7654320987654321,"Proof. The proof of this lemma is inspired by the proof of Lemma 5.4 in Zou et al. (2018). In our
proof, we deÔ¨Åne f(x) = (f(x1), f(x2), ..., f(xn)), where f(x) is a scalar function and x is a vector
of length n. When Œªmin(H)(s) ‚â•Œª0"
DR,0.7674897119341564,"2 holds for 0 ‚â§s ‚â§t, we can bound the derivative of L(t):"
DR,0.7695473251028807,"Published as a conference paper at ICLR 2022 dL(u) dt
= n
X"
DR,0.7716049382716049,"i=1
l‚Ä≤(ui)‚àÇui ‚àÇt = ‚àí n
X"
DR,0.7736625514403292,"i=1
l‚Ä≤(ui) n
X"
DR,0.7757201646090535,"j=1
l‚Ä≤(uj)Hij"
DR,0.7777777777777778,= ‚àíl‚Ä≤(u)‚ä§Hl‚Ä≤(u)
DR,0.779835390946502,"(i)
‚â§‚àíŒª0 2 n
X"
DR,0.7818930041152263,"i=1
l‚Ä≤(ui)2"
DR,0.7839506172839507,"(ii)
‚â§Œª0 2 n
X"
DR,0.7860082304526749,"i=1
l‚Ä≤(ui)"
DR,0.7880658436213992,"(iii)
‚â§‚àíŒª0 2 n
X"
DR,0.7901234567901234,"i=1
min(1/2, l(ui) 2
)"
DR,0.7921810699588477,"(iv)
‚â§‚àíŒª0"
MIN,0.7942386831275721,"2 min

1/2, n
X i=1 l(ui) 2  = ‚àíŒª0"
MIN,0.7962962962962963,"2 min(1/2, L(u) 2
)"
MIN,0.7983539094650206,"(v)
‚â§‚àíŒª0"
MIN,0.8004115226337448,"2
1
2 + 2/L(u),"
MIN,0.8024691358024691,"where (i) is due to Œªmin(H) ‚â•Œª0, (ii) is due to ‚àíl‚Ä≤(u) ‚â§1, (iii) holds due to the following property
of cross entropy loss ‚àíl‚Ä≤(u) ‚â•min(1/2, l(u)"
MIN,0.8045267489711934,"2 ), (iv) holds due to the function min(1/2, x) is a
concave function and Jenson‚Äôs inequality, (v) holds due to min(a, b) ‚â•
1
1/a+1/b"
MIN,0.8065843621399177,"Therefore, we have"
MIN,0.808641975308642,2dL(u)
MIN,0.8106995884773662,"dt
+
2
L(u)
dL(u)"
MIN,0.8127572016460906,"dt
‚â§‚àíŒª0 2 ."
MIN,0.8148148148148148,"By integration on both sides from 0 to t, we have"
MIN,0.8168724279835391,"L(u(t)) ‚àíL(u(0)) + log
"
MIN,0.8189300411522634,"L(u(t))

‚àílog
"
MIN,0.8209876543209876,"L(u(0))

‚â§‚àíŒª0t 4 ."
MIN,0.823045267489712,"Therefore, we have log
"
MIN,0.8251028806584362,"L(u(t))

‚â§‚àíŒª0t"
MIN,0.8271604938271605,"4 + L(u(0)) + log
"
MIN,0.8292181069958847,"L(u(0))

,"
MIN,0.831275720164609,which yields
MIN,0.8333333333333334,"L(u(t)) ‚â§exp

‚àíŒª0t 4"
MIN,0.8353909465020576,"
exp
"
MIN,0.8374485596707819,"L(u(0))
"
MIN,0.8395061728395061,L(u(0)).
MIN,0.8415637860082305,"And we can bound the change of wr.

dwr(t) dt"
MIN,0.8436213991769548,"2
=

dL(t) dwr 2 = n
X"
MIN,0.845679012345679,"i=1
l‚Ä≤(ui) 1
‚àömaryiœÉ‚Ä≤(‚ü®wr, xi ¬± œµ‚à•wr‚à•1‚ü©)(xi ¬± œµ‚à•wr‚à•1)

2"
MIN,0.8477366255144033,"‚â§
1
‚àöm n
X"
MIN,0.8497942386831275,"i=1
‚à•l‚Ä≤(ui)‚à•2"
MIN,0.8518518518518519,"‚â§
n
‚àöm,"
MIN,0.8539094650205762,Published as a conference paper at ICLR 2022
MIN,0.8559670781893004,where œÉ‚Ä≤(¬∑) stands for the derivative of the ReLU activation. Thus
MIN,0.8580246913580247,"‚à•wr(t) ‚àíwr(0)‚à•2 ‚â§nt
‚àöm."
MIN,0.8600823045267489,"A.6
PROOF OF LEMMA 7"
MIN,0.8621399176954733,Proof. We Ô¨Årst prove the standard training part. As we have deÔ¨Åned previously that
MIN,0.8641975308641975,"L(0) = n
X"
MIN,0.8662551440329218,"i=1
log(1 + exp(‚àíui(0))), where"
MIN,0.8683127572016461,"ui(0) = yi
1
‚àöm m
X"
MIN,0.8703703703703703,"r=1
arœÉ(wr(0)‚ä§xi)."
MIN,0.8724279835390947,"For each arœÉ(wr(0)‚ä§xi), r ‚àà[m], i ‚àà[n], note that the randomness only comes from random
initialization for wr, there is 1"
MIN,0.8744855967078189,"2 possibility that it is equal to 0, and another 1"
POSSIBILITY THAT IT,0.8765432098765432,"2 possibility that it
follows a normal distribution N(0, œÉ2
i ), where œÉi = ‚à•xi‚à•2
2. Therefore, we have"
POSSIBILITY THAT IT,0.8786008230452675,"E(arœÉ(wr(0)‚ä§xi)) = 0,"
POSSIBILITY THAT IT,0.8806584362139918,"Var(arœÉ(wr(0)‚ä§xi)) = œÉ2
i
2 ,"
POSSIBILITY THAT IT,0.8827160493827161,"E
 1
‚àöm m
X"
POSSIBILITY THAT IT,0.8847736625514403,"r=1
arœÉ(wr(0)‚ä§xi)

= 0,"
POSSIBILITY THAT IT,0.8868312757201646,"Var
 1
‚àöm m
X"
POSSIBILITY THAT IT,0.8888888888888888,"r=1
arœÉ(wr(0)‚ä§xi)

= œÉ2
i
2 ."
POSSIBILITY THAT IT,0.8909465020576132,"Therefore, by Chebyshev‚Äôs inequality, we can bound"
POSSIBILITY THAT IT,0.8930041152263375,"Pr(|ui(0)| ‚â§œÉ2
i
2Œ¥ ) ‚â•1 ‚àíŒ¥."
POSSIBILITY THAT IT,0.8950617283950617,"And we can bound L(0) = O( n maxn
i=1 œÉ2
i
2Œ¥
) = O( n"
POSSIBILITY THAT IT,0.897119341563786,Œ¥ ) with probability at least 1 ‚àíŒ¥.
POSSIBILITY THAT IT,0.8991769547325102,"For IBP training,"
POSSIBILITY THAT IT,0.9012345679012346,"ui(0) =
1
‚àöm m
X"
POSSIBILITY THAT IT,0.9032921810699589,"r=1
1(yiar = 1)œÉ
 
wr(0)‚ä§xi ‚àíœµ‚à•wr(0)‚à•1

+ 1(yiar = ‚àí1)œÉ
 
wr(0)‚ä§xi + œµ‚à•wr(0)‚à•1

. Thus"
POSSIBILITY THAT IT,0.9053497942386831,"|ui(0) ‚àíui(0)| ‚â§
1
‚àömmœµ‚à•wr(0)‚à•1 = ‚àömœµ‚à•wr(0)‚à•1."
POSSIBILITY THAT IT,0.9074074074074074,"By E(‚à•wr‚à•1) = O(d) and Markov‚Äôs inequality, with probability at least 1 ‚àíŒ¥,"
POSSIBILITY THAT IT,0.9094650205761317,"|ui(0) ‚àíui(0)| ‚â§O(
‚àömdœµ Œ¥
)."
POSSIBILITY THAT IT,0.911522633744856,"And we can bound L(0) = O( n‚àömdœµ Œ¥
+ n"
POSSIBILITY THAT IT,0.9135802469135802,Œ¥ ) with probability at least 1 ‚àíŒ¥.
POSSIBILITY THAT IT,0.9156378600823045,Published as a conference paper at ICLR 2022
POSSIBILITY THAT IT,0.9176954732510288,"B
DETAILED DERIVATION FOR OTHER EQUATIONS OR INEQUALITIES"
POSSIBILITY THAT IT,0.9197530864197531,"B.1
DERIVATION ON THE DYNAMICS OF ui(t)"
POSSIBILITY THAT IT,0.9218106995884774,"We provide a detailed derivation on the dynamics of ui(t) presented in Eq. (5), which we use Hi(t)
to describe d"
POSSIBILITY THAT IT,0.9238683127572016,dtui(t):
POSSIBILITY THAT IT,0.9259259259259259,"d
dtui(t) = m
X r=1"
POSSIBILITY THAT IT,0.9279835390946503,‚àÇui(t)
POSSIBILITY THAT IT,0.9300411522633745,"‚àÇwr(t), dwr(t) dt  = m
X r=1"
POSSIBILITY THAT IT,0.9320987654320988,‚àÇui(t)
POSSIBILITY THAT IT,0.934156378600823,"‚àÇwr(t), ‚àí‚àÇL(W(t), a)"
POSSIBILITY THAT IT,0.9362139917695473,"‚àÇwr(t)  = m
X r=1"
POSSIBILITY THAT IT,0.9382716049382716,‚àÇui(t)
POSSIBILITY THAT IT,0.9403292181069959,"‚àÇwr(t), ‚àí n
X"
POSSIBILITY THAT IT,0.9423868312757202,"j=1
l‚Ä≤(uj) ‚àÇuj(t)"
POSSIBILITY THAT IT,0.9444444444444444,"‚àÇwr(t)  = n
X"
POSSIBILITY THAT IT,0.9465020576131687,"j=1
‚àíl‚Ä≤(uj) m
X r=1"
POSSIBILITY THAT IT,0.948559670781893,‚àÇui(t)
POSSIBILITY THAT IT,0.9506172839506173,"‚àÇwr(t), ‚àÇuj(t)"
POSSIBILITY THAT IT,0.9526748971193416,"‚àÇwr(t)  = n
X"
POSSIBILITY THAT IT,0.9547325102880658,"j=1
‚àíl‚Ä≤(uj)Hij(t),"
POSSIBILITY THAT IT,0.9567901234567902,"B.2
DERIVATION FOR EQ. (15)"
POSSIBILITY THAT IT,0.9588477366255144,"Eq. (15) basically comes by triangle inequality:
wr(t)‚ä§xi ‚àíœµ‚à•wr(t)‚à•1 ‚àí(wr(0)‚ä§xi ‚àíœµ‚à•wr(0)‚à•1)"
POSSIBILITY THAT IT,0.9609053497942387,"=
(wr(t) ‚àíwr(0))‚ä§xi ‚àíœµ‚à•wr(t)‚à•1 + œµ‚à•wr(0)‚à•1"
POSSIBILITY THAT IT,0.9629629629629629,"‚â§|(wr(t) ‚àíwr(0))‚ä§xi| + œµ
‚à•wr(t)‚à•1 ‚àí‚à•wr(0)‚à•1"
POSSIBILITY THAT IT,0.9650205761316872,"‚â§|(wr(t) ‚àíwr(0))‚ä§xi| + œµ
wr(t) ‚àíwr(0)

1
‚â§(1 + œµ)
‚àö dR."
POSSIBILITY THAT IT,0.9670781893004116,"B.3
DERIVATION FOR EQ. (23)"
POSSIBILITY THAT IT,0.9691358024691358,"We solve the inequality in Eq. (22) to derive an upper bound for œµ in Eq. (23): 1
‚àö"
POSSIBILITY THAT IT,0.9711934156378601,"2œÄŒæ (1 + œµ)
‚àö"
POSSIBILITY THAT IT,0.9732510288065843,"dR ‚â•
1
‚àö 2œÄŒæ ‚àö"
POSSIBILITY THAT IT,0.9753086419753086,"dR ‚â•d exp

‚àí2(1 + œµ)2dR2 œµ2 
, R
‚àö"
POSSIBILITY THAT IT,0.977366255144033,"2œÄdŒæ
‚â•exp

‚àí2(1 + œµ)2dR2 œµ2 
,"
POSSIBILITY THAT IT,0.9794238683127572,"log

R
‚àö 2œÄdŒæ"
POSSIBILITY THAT IT,0.9814814814814815,"
‚â•‚àí2(1 + œµ)2dR2 œµ2
,"
POSSIBILITY THAT IT,0.9835390946502057,and then we can require
POSSIBILITY THAT IT,0.98559670781893,"log

R
‚àö 2œÄdŒæ"
POSSIBILITY THAT IT,0.9876543209876543,"
‚â•‚àí2dR2"
POSSIBILITY THAT IT,0.9897119341563786,"œµ2
‚â•‚àí2(1 + œµ)2dR2"
POSSIBILITY THAT IT,0.9917695473251029,"œµ2
‚áíœµ ‚â§ ‚àö"
DR,0.9938271604938271,2dR
DR,0.9958847736625515,"log(
q 2œÄd"
DR,0.9979423868312757,"R Œæ)
."
