Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0015748031496062992,"Discrete black-box optimization problems are challenging for model-based opti-
mization (MBO) algorithms, such as Bayesian optimization, due to the size of
the search space and the need to satisfy combinatorial constraints.
In partic-
ular, these methods require repeatedly solving a complex discrete global opti-
mization problem in the inner loop, where popular heuristic inner-loop solvers
introduce approximations and are difﬁcult to adapt to combinatorial constraints.
In response, we propose NN+MILP, a general discrete MBO framework using
piecewise-linear neural networks as surrogate models and mixed-integer linear
programming (MILP) to optimize the acquisition function. MILP provides op-
timality guarantees and a versatile declarative language for domain-speciﬁc con-
straints. We test our approach on a range of unconstrained and constrained prob-
lems, including DNA binding and the NAS-Bench-101 neural architecture search
benchmark. NN+MILP surpasses or matches the performance of algorithms tai-
lored to the domain at hand, with global optimization of the acquisition problem
running in a few minutes using only standard software packages and hardware."
INTRODUCTION,0.0031496062992125984,"1
INTRODUCTION"
INTRODUCTION,0.004724409448818898,"The problem of optimizing an expensive black-box function f : Ω7→R over a discrete, constrained
domain arises in numerous application domains, e.g. neural architecture search (Zoph & Le, 2017),
program synthesis (Summers, 1977; Biermann, 1978), small-molecule design (Elton et al., 2019),
and protein design (Yang et al., 2019). In such resource-constrained settings, it is desirable to de-
velop algorithms that exploit known combinatorial structure in Ωto search the space more efﬁciently."
INTRODUCTION,0.006299212598425197,"Model-based Black-box Optimization (MBO), a popular paradigm that includes Bayesian Optimiza-
tion as a special case, iteratively reﬁnes a function approximator ˆf(x) ≈f(x) and selects new points
to query by optimizing an acquisition function a(x) derived from a point estimate or posterior dis-
tribution over ˆf (Section 2.1). This inner-loop optimization problem is assumed to be easier than
the original, since, for example, a(x) is less expensive to query than f(x) or provides “white-box”
properties such as gradients."
INTRODUCTION,0.007874015748031496,"There is a vast literature addressing the challenges of applying MBO in practice. We focus on two of
these: ﬁrst, optimizing a(x) may itself be a computationally-difﬁcult optimization problem; second,
in many applications, practitioners are confronted by additional constraints on x. For example, in
neural architecture search, x might represent a computation graph that must be both connected and
acyclic. Due to the difﬁculty in optimizing the acquisition function over a combinatorial domain,
most approaches resort to heuristic inner-loop solvers, which often need to be specialized to the
problem at hand to ensure feasibility, e.g. evolutionary solvers with custom mutation operators."
INTRODUCTION,0.009448818897637795,"To address the challenge of inner-loop optimization, we introduce a new MBO framework,
NN+MILP, that exactly solves the acquisition problem using mixed-integer linear programming
(MILP). Crucially, by framing the inner-loop optimization as an MILP, our approach can ﬂexibly
incorporate a wide variety of logical, combinatorial, and polyhedral constraints, which need only be
provided in a declarative sense. Using MILP in the inner loop does restrict the functional form of ˆf
(or the acquisition function based on it), but it supports any piecewise linear function. In particular,
we employ the class of neural network (NN) approximators with ReLU activation functions due to
their scalability and accuracy in practice, and because we can draw on recent work improving the"
INTRODUCTION,0.011023622047244094,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.012598425196850394,"performance of MILP for optimizing such NNs with respect to their inputs (Anderson et al., 2020).
For us, MILP is practical to use in the inner loop because the dimensionality of typical black-box op-
timization problems is orders of magnitude smaller than those usually considered by MILP solvers.
Our contributions are as follows:
• We introduce NN+MILP, an MBO framework for discrete black-box problems with NN surro-
gates and exact optimality guarantees for solving the acquisition problem.
• We observe in our experiments that the runtime of MILP is practical for use with black-box prob-
lems of real-world scale, often solving the inner acquisition problem in seconds using standard
packages and hardware. Moreover, MILP provides a simple declarative language for problem-
speciﬁc constraints.
• We show that NN+MILP matches or surpasses the performance of strong MBO baselines based
on problem-speciﬁc evolutionary algorithms on a wide range of synthetic and real-world discrete
black-box problems.
• We use the NAS-Bench-101 neural architecture search benchmark as a case study, presenting a
novel MILP formulation of its graph-structured domain."
BACKGROUND AND RELATED WORK,0.014173228346456693,"2
BACKGROUND AND RELATED WORK"
MODEL-BASED BLACK-BOX OPTIMIZATION,0.015748031496062992,"2.1
MODEL-BASED BLACK-BOX OPTIMIZATION"
MODEL-BASED BLACK-BOX OPTIMIZATION,0.01732283464566929,"Model-based Black-box Optimization (MBO) is a broad family of methods that includes Bayesian
optimization as a special case (Mockus et al., 1978; Jones et al., 1998; Hutter et al., 2011; Snoek
et al., 2012; Shahriari et al., 2015). As depicted in Algorithm 1, the method proposes xt at iteration t
using three steps. First, the user performs inference over a surrogate model ˆf to approximate f using
the data previously collected from the black-box function. Here, fit() may return a point estimate
for ˆf, a posterior distribution over ˆf, or a posterior predictive distribution. Next, an acquisition
function a(x) based on ˆf(x) is posed that quantiﬁes the quality of new points to query. Finally, xt
is selected as the best point found by solving the acquisition problem, where an inner-loop solver
(approximately) optimizes a(x). The acquisition problem is typically designed such that it is more
approachable than directly solving the original problem. For example, a(x) may be orders of mag-
nitude less expensive to evaluate or have a tractable functional form. Practitioners can encode prior
knowledge about the structure of f via a choice of inductive bias for ˆf, e.g. a suitable Gaussian
Process kernel or neural-network architecture."
MODEL-BASED BLACK-BOX OPTIMIZATION,0.01889763779527559,"Bayesian optimization performs Bayesian inference over ˆf and employs an acquisition function that
accounts for uncertainty in ˆf. Doing so provides principled mechanisms for balancing exploration
and exploitation (Mockus et al., 1978; Srinivas et al., 2010) and is particularly important in early
rounds of optimization when models are ﬁt on limited data. We refer to our method as an instance
of MBO, not Bayesian optimization, because it does not assume formal Bayesian inference for ˆf.
Gaussian processes (GPs) are often used for ˆf in Bayesian optimization, since they provide closed-
form posterior inference, naturally adjust their expressivity as the dataset grows, and users can inject
domain knowledge via a choice of kernel (Rasmussen & Williams, 2006; Oh et al., 2019). On the
other hand, neural networks provide a practical alternative (Snoek et al., 2015; Hern´andez-Lobato
et al., 2017), since they often scale more gracefully, either computationally or statistically, to large
datasets or high-dimensional domains."
SOLVING THE DISCRETE MBO ACQUISITION PROBLEM,0.02047244094488189,"2.2
SOLVING THE DISCRETE MBO ACQUISITION PROBLEM"
SOLVING THE DISCRETE MBO ACQUISITION PROBLEM,0.02204724409448819,"In general, the inner-loop problem is itself a non-trivial global optimization problem. Prior work
on discrete MBO has mainly employed local search solvers, such as evolutionary search, with lim-
ited guarantees (Hutter et al., 2011; M¨uller, 2016; Oh et al., 2019; Kandasamy et al., 2020). A
key advantage of such solvers is that they treat a(x) as a black box, which provides practitioners
with freedom when designing application-speciﬁc surrogate models. On the other hand, particular
choices of surrogate model and acquisition function lead to acquisition problems that can be (ap-
proximately) solved using specialized combinatorial solvers (Baptista & Poloczek, 2018; Deshwal
et al., 2020), mixed-integer nonlinear programming (MINLP) solvers (Costa & Nannicini, 2018;
Kim & Boukouvala, 2020), or continuous optimization solvers (Bliek et al., 2021)."
SOLVING THE DISCRETE MBO ACQUISITION PROBLEM,0.023622047244094488,Under review as a conference paper at ICLR 2022
SOLVING THE DISCRETE MBO ACQUISITION PROBLEM,0.025196850393700787,Algorithm 1 MBO
SOLVING THE DISCRETE MBO ACQUISITION PROBLEM,0.026771653543307086,"Input: hypothesis class F, budget N,
initial dataset Dn = {xi, f(xi)}n
i=1, op-
timization domain Ω
for t = n + 1 to t = N do"
SOLVING THE DISCRETE MBO ACQUISITION PROBLEM,0.028346456692913385,"P( ˆft) ←fit(F, Dt−1)
a(x) ←get acquis func(P( ˆft))
xt ←inner solver(a(x), Ω)
Dt ←Dt−1 ∪{xt, f(xt)}
end for
return arg max(xt,yt)∈DN yt"
SOLVING THE DISCRETE MBO ACQUISITION PROBLEM,0.029921259842519685,Algorithm 2 NN+MILP
SOLVING THE DISCRETE MBO ACQUISITION PROBLEM,0.031496062992125984,"Input: hypothesis class F, budget N, initial dataset
Dn = {xi, f(xi)}n
i=1, MILP domain formulation
MΩ
for t = n + 1 to t = N do"
SOLVING THE DISCRETE MBO ACQUISITION PROBLEM,0.03307086614173228,"ˆft ←fit(F, Dt−1)
(3.2)
Mt ←build milp( ˆft, MΩ, Dt−1)
(3.3)
xt ←optimize(Mt) (generic MILP solver)
Dt ←Dt−1 ∪{xt, f(xt)}
end for
return arg max(xt,yt)∈DN yt"
SOLVING THE DISCRETE MBO ACQUISITION PROBLEM,0.03464566929133858,"Therefore, practitioners must decide between either introducing difﬁcult-to-analyze approximations
due to inexact heuristic solvers or using tractable surrogate models that may be mis-speciﬁed for
the application domain. This serves as a key motivation for our work: we seek to enable practition-
ers to employ broad families of surrogate models and exactly solve the acquisition problem with
reasonable computational overhead in practice."
CONSTRAINED MBO,0.03622047244094488,"2.3
CONSTRAINED MBO"
CONSTRAINED MBO,0.03779527559055118,"In many applications, x is subject to non-trivial structural constraints. Prior work has largely focused
on the case where determining whether x is feasible requires evaluating an expensive, perhaps noisy,
black-box function h(x) with cost comparable to f(x) (Schonlau et al., 1998; Gelbart et al., 2014;
Hern´andez-Lobato et al., 2016; Ariafar et al., 2019; Letham et al., 2019). Here, standard acquisition
functions can be extended to account for an additional classiﬁer ˆh(x) trained to predict h(x)."
CONSTRAINED MBO,0.03937007874015748,"Problems with inexpensive white-box h(x) can be tackled using these approaches for black-box con-
straints, but doing so may lead to slower optimization and may query f(x) at invalid x, which can
be unsafe when performing physical experiments (Berkenkamp et al., 2016). Instead, the inner-loop
solver can be modiﬁed directly to guarantee feasibility, e.g., by using rejection sampling (Shi et al.,
2020; Kandasamy et al., 2020). If using local search algorithms, the solver would need to be cus-
tomized for each family of constraints, a task usually left to the user. Prior work employing MINLP
solvers addresses white-box constraints either by adding a penalty for constraint violation (Costa &
Nannicini, 2018) or in small-scale settings (Kim & Boukouvala, 2020)."
MIXED INTEGER LINEAR PROGRAMMING,0.04094488188976378,"2.4
MIXED INTEGER LINEAR PROGRAMMING"
MIXED INTEGER LINEAR PROGRAMMING,0.04251968503937008,"Mixed Integer Linear Programming (MILP) seeks to maximize a linear function over a set of deci-
sion variables, some of which may be integral, subject to linear inequality constraints. Decades of
development have allowed MILP to have a signiﬁcant impact in a wide range of applications due to
its better-than-expected computational performance (J¨unger et al., 2010). Indeed, while MILP prob-
lems are computationally hard (NP-complete), they are routinely solved (to global or near-global
optimality) in production environments thanks to state-of-the-art solvers that nearly double their
machine-independent performance every year (Achterberg & Wunderling, 2013; Bixby, 2012)."
MIXED INTEGER LINEAR PROGRAMMING,0.04409448818897638,"A notable aspect of MILP is that it provides a simple yet extremely versatile declarative language
for white-box constraints. It is well known that linear inequalities over integer variables can be
used to easily build pure-integer formulations for logical constraints and combinatorial optimization
problems (Williams, 2013; Schrijver, 2003; Wolsey & Nemhauser, 1999). In addition, using both
integer and continuous variables leads to mixed-integer formulations that can combine polyhedral
and logical constraints (Jeroslow, 1989; Pochet & Wolsey, 2006; Vielma, 2015)."
MIXED INTEGER LINEAR PROGRAMMING,0.04566929133858268,"Particularly interesting to our proposed approach are MILP formulations for piecewise-linear func-
tions (Huchette & Vielma, 2019; Vielma et al., 2010). Speciﬁcally, our work leverages MILP formu-
lations for trained neural networks with piecewise-linear activation functions such as ReLUs (An-
derson et al., 2020). Optimizing over trained ReLU networks with MILP has been done in contexts
such as neural network veriﬁcation (Cheng et al., 2017; Lomuscio & Maganti, 2017; Tjeng et al.,
2019), reinforcement learning (Ryu et al., 2020; Delarue et al., 2020), and analysis and exact com-"
MIXED INTEGER LINEAR PROGRAMMING,0.047244094488188976,Under review as a conference paper at ICLR 2022
MIXED INTEGER LINEAR PROGRAMMING,0.048818897637795275,"pression of neural networks (Serra et al., 2018; 2021). In particular, MILP has also been used to
optimize ReLU network surrogates of simulation-based constraints (Grimstad & Andersson, 2019),
although their approach optimizes a single surrogate model once, unlike in ours."
MILP FOR MBO,0.050393700787401574,"3
MILP FOR MBO"
MILP FOR MBO,0.05196850393700787,"We propose the NN+MILP framework (Algorithm 2), which uses neural network surrogate models
and solves the acquisition problem using MILP at every step. This provides practitioners with the
ﬂexibility to use a wide variety of models and leverage MILP’s versatile declarative language to in-
corporate constraints. This section describes various design choices to make the approach practical."
PROBLEM SETTING,0.05354330708661417,"3.1
PROBLEM SETTING"
PROBLEM SETTING,0.05511811023622047,"Our goal is to ﬁnd:
x∗= arg max
x∈Ωf(x),
(1)"
PROBLEM SETTING,0.05669291338582677,"where f : Ω7→R is an expensive, noiseless black-box reward function and Ω⊆Ω1 × . . . × Ωn is a
domain on n decision variables. We assume Ωcan be described by an inexpensive function hΩ(x)
indicating whether x is in Ω. Algorithms are allowed a ﬁxed budget of N sequential queries to f.
Xt := {xi}t
i=1 refers to the set of sampled points by iteration t, and Dt := {xi, yi = f(xi)}t
i=1
includes corresponding rewards. An algorithm’s performance is measured as the best reward in DN.
Since f is noiseless, it is advantageous for algorithms to avoid repeated evaluations of the same x."
PROBLEM SETTING,0.05826771653543307,"We choose to focus on ﬁnite discrete sets Ωas we believe this is the area where MILP can pro-
vide the greatest beneﬁt. As noted in Section 2.4, there are many well-studied formulation tech-
niques for Ωwith combinatorial structure, such as directed graphs. More generally, such sets have
a polynomially-sized MILP formulation whenever hΩ(x) can be evaluated in polynomial time (e.g.,
Yannakakis (1991)). Continuous and mixed-integer domains could be incorporated in our approach
with some modiﬁcations (Section 6), although they are outside the scope of this paper."
SURROGATE MODEL AND ACQUISITION FUNCTION,0.05984251968503937,"3.2
SURROGATE MODEL AND ACQUISITION FUNCTION"
SURROGATE MODEL AND ACQUISITION FUNCTION,0.06141732283464567,"For surrogate model ˆf, we allow any feedforward neural network with piecewise-linear activation
functions, as they can be represented by MILP (Section 3.3). Though we focus on fully-connected
networks using ReLUs, we note that a wide range of architectures (e.g., those including convolu-
tional and max-pooling layers) are piecewise-linear and may place suitable inductive bias on ˆf."
SURROGATE MODEL AND ACQUISITION FUNCTION,0.06299212598425197,"Our experiments employ a simple acquisition function loosely motivated by Thompson sam-
pling (Thompson, 1933; Hern´andez-Lobato et al., 2017; Kandasamy et al., 2018). At each opti-
mization step, we train a new regressor ˆf(x) from scratch and set a(x) = ˆf(x). This relies on
stochastic gradient descent training and random parameter initialization to increase the variability
in surrogate models across iterations (Lakshminarayanan et al., 2017). We discuss extensions to
alternative acquisition functions in Section 6. We use a ﬂattened one-hot encoding of x for the input
layer, and train each network ˆft ∈F on Dt−1 using ℓ2 loss. Finally, we re-scale the observed
rewards in Dt−1 before training models, to aid both in training and optimization. Poorly-scaled data
may result in slower performance or small inaccuracies in MILP solvers (Miltenberger et al., 2018)."
MILP FORMULATION OF THE ACQUISITION PROBLEM,0.06456692913385827,"3.3
MILP FORMULATION OF THE ACQUISITION PROBLEM"
MILP FORMULATION OF THE ACQUISITION PROBLEM,0.06614173228346457,The inner-loop solver then seeks to ﬁnd
MILP FORMULATION OF THE ACQUISITION PROBLEM,0.06771653543307087,"xt = arg
max
x∈Ω\Xt−1
ˆft(x),
(2)"
MILP FORMULATION OF THE ACQUISITION PROBLEM,0.06929133858267716,"where Ωis the feasible set for (1) and Xt−1 is the set of points where the noiseless f(x) has been
queried already. The MILP formulation of (2) is denoted by Mt and has the following three com-
ponents:"
MILP FORMULATION OF THE ACQUISITION PROBLEM,0.07086614173228346,"Domain We use a one-hot encoding of decision variables x (unless they are already binary), deﬁn-
ing the binary decision vector z with zij ≡I{xi = j} for i ∈[n], j ∈Ωi, and subject to linear"
MILP FORMULATION OF THE ACQUISITION PROBLEM,0.07244094488188976,Under review as a conference paper at ICLR 2022
MILP FORMULATION OF THE ACQUISITION PROBLEM,0.07401574803149606,constraints P
MILP FORMULATION OF THE ACQUISITION PROBLEM,0.07559055118110236,"j∈Ωi zij = 1 ∀i. Integer domains with small range may be one-hot encoded; see
Appendix D for a comparison between integer and one-hot encodings. Additional constraints due
to Ωare added as necessary, with form dependent on the application at hand. We assume that these
are MILP-representable, which as noted in Section 2.4 could include a wide range of combinatorial,
logical, and polyhedral constraints. We use MΩto denote the domain formulation itself."
MILP FORMULATION OF THE ACQUISITION PROBLEM,0.07716535433070866,"No-good Constraints A no-good constraint is one that eliminates one or more undesirable solutions
from the domain. Here, we leverage the binary nature of z to exactly eliminate the set Xt−1 from
Mt. For illustrative purposes, consider a single point ¯x ∈Ωwe wish to exclude from the acquisition
problem’s domain, and let ¯z denote its one-hot encoding (or ¯x itself if the problem is binary). Then
the constraint:
X"
MILP FORMULATION OF THE ACQUISITION PROBLEM,0.07874015748031496,"i,j : ¯zij=0
zij +
X"
MILP FORMULATION OF THE ACQUISITION PROBLEM,0.08031496062992126,"i,j : ¯zij=1
(1 −zij) ≥1
(3)"
MILP FORMULATION OF THE ACQUISITION PROBLEM,0.08188976377952756,"enforces that any feasible z has a Hamming distance of at least 1 from ¯z. As z are binary, this effec-
tively eliminates just the single point ¯z from the feasible region. We therefore formulate Ω\ Xt−1 by
including one such constraint for each ¯x ∈Xt−1. Note that the right-hand side can be tightened to 2
for one-hot encodings, and these compact no-good constraints do not extend naturally to continuous
x (Section 6)."
MILP FORMULATION OF THE ACQUISITION PROBLEM,0.08346456692913386,"Neural Network We formulate the neural network by introducing auxiliary decision variables en-
coding the activation of each neuron for a given z. We present here the formulation for a single
ReLU, commonly used throughout the literature (Section 2.4), while noting that the full formulation
is obtained by combining all ReLU formulations and matching their input and output variables ac-
cording to the structure of the network. The overall MILP objective is the activation corresponding
to the regressor’s output neuron."
MILP FORMULATION OF THE ACQUISITION PROBLEM,0.08503937007874016,"A ReLU neuron with vector input x and scalar output y has the piecewise-linear form y =
max(0, w⊤x + b), where w and b are its weights and bias respectively. At optimization time, w
and b are ﬁxed, while x and y are represented by decision variables (also used as the inputs and
outputs of other ReLUs according to the feedforward structure). To handle the non-linearity, we add
a binary decision variable α that indicates whether the ReLU is active or not. We then write the
following set of constraints to enforce that y = 0 when α = 0 and y = w⊤x + b when α = 1:"
MILP FORMULATION OF THE ACQUISITION PROBLEM,0.08661417322834646,"0 ≤y ≤Mα
(4)"
MILP FORMULATION OF THE ACQUISITION PROBLEM,0.08818897637795275,"w⊤x + b ≤y ≤w⊤x + b + M(1 −α)
(5)"
MILP FORMULATION OF THE ACQUISITION PROBLEM,0.08976377952755905,"where M is a sufﬁciently large ﬁxed value, such as an upper bound on the range of y. As w and b
are ﬁxed, values for M can be computed in advance of the optimization, e.g. by propagating bounds
from Ω. Our experiments use a more advanced method to compute M, detailed in Appendix A."
OPTIMALITY GUARANTEES FOR MILP,0.09133858267716535,"3.4
OPTIMALITY GUARANTEES FOR MILP"
OPTIMALITY GUARANTEES FOR MILP,0.09291338582677165,"The full acquisition problem formulation, denoted by Mt, is passed to a generic MILP solver with
ﬁxed time limit. If the solver does not time out, it is guaranteed to have produced a global optimum
of (2), and in Section 4.4 we ﬁnd that our solver typically terminates within a practical time budget.
Even if the solver times out, it will return the best feasible solution it found, plus an upper bound on
the global optimal value. This bound can be used to evaluate the level of potential sub-optimality
of the feasible solution. Note that solvers often ﬁnd an optimal solution before ﬁnding the upper
bound that guarantees its optimality, so timing out do not imply sub-optimality. Finally, inner-
loop optimality guarantees do not translate into guarantees for the overall black-box optimization,
particularly when f(x) does not belong to F. However, they do provide a useful empirical tool for
understanding the impact of exact inner-loop optimization (Section 4)."
EXPERIMENTS,0.09448818897637795,"4
EXPERIMENTS"
EXPERIMENTS,0.09606299212598425,"This section presents experimental results on a wide range of discrete black-box problems, with and
without combinatorial constraints. We focus primarily on analyzing the effect of global optimization
of the acquisition function, by including controlled ablations of NN+MILP where the inner-loop
solver is replaced by an inexact evolutionary alternative. Depending on the problem, we also include
independent baselines tailored to the application domain."
EXPERIMENTS,0.09763779527559055,Under review as a conference paper at ICLR 2022
EXPERIMENTS,0.09921259842519685,Ensemble+RegEvo
EXPERIMENTS,0.10078740157480315,NN+MILP
EXPERIMENTS,0.10236220472440945,NN+RegEvo
EXPERIMENTS,0.10393700787401575,RegEvo 0.00 0.25 0.50 0.75 1.00
EXPERIMENTS,0.10551181102362205,Normalized Score
EXPERIMENTS,0.10708661417322834,"BBOB(10,10)"
EXPERIMENTS,0.10866141732283464,NN+MILP
EXPERIMENTS,0.11023622047244094,NN+RegEvo
EXPERIMENTS,0.11181102362204724,RBFOpt
EXPERIMENTS,0.11338582677165354,Ensemble+RegEvo
EXPERIMENTS,0.11496062992125984,RegEvo 0.00 0.25 0.50 0.75 1.00
EXPERIMENTS,0.11653543307086614,Normalized Score
EXPERIMENTS,0.11811023622047244,"RandomMLP(25,5)"
EXPERIMENTS,0.11968503937007874,Ensemble+RegEvo
EXPERIMENTS,0.12125984251968504,NN+MILP
EXPERIMENTS,0.12283464566929134,NN+RegEvo
EXPERIMENTS,0.12440944881889764,RBFOpt
EXPERIMENTS,0.12598425196850394,RegEvo 0.00 0.25 0.50 0.75 1.00
EXPERIMENTS,0.12755905511811025,Normalized Score
EXPERIMENTS,0.12913385826771653,"TfBind(8,4)"
EXPERIMENTS,0.13070866141732285,"0
200
400
600
800
1000
Step 4 3 2 1 0"
EXPERIMENTS,0.13228346456692913,Best Observed Reward
EXPERIMENTS,0.13385826771653545,"BBOB(10,10) Example"
EXPERIMENTS,0.13543307086614173,"NN+MILP
NN+RegEvo
RegEvo
Ensemble+RegEvo"
EXPERIMENTS,0.13700787401574804,"0
200
400
600
800
1000
Step 0.5 1.0 1.5 2.0 2.5"
EXPERIMENTS,0.13858267716535433,Best Observed Reward
EXPERIMENTS,0.14015748031496064,"RandomMLP(25,5) Example"
EXPERIMENTS,0.14173228346456693,"NN+MILP
NN+RegEvo
RegEvo
Ensemble+RegEvo
RBFOpt"
EXPERIMENTS,0.14330708661417324,"0
200
400
600
800
1000
Step 0.00 0.25 0.50 0.75 1.00"
EXPERIMENTS,0.14488188976377953,Best Observed Reward
EXPERIMENTS,0.14645669291338584,"TfBind(8,4) Example"
EXPERIMENTS,0.14803149606299212,"NN+MILP
NN+RegEvo
RegEvo
Ensemble+RegEvo
RBFOpt"
EXPERIMENTS,0.14960629921259844,"Figure 1: (Top) Distribution of algorithms’ normalized scores (Section 4.1) on all unconstrained
problems split by objective class. Higher is better. NN+MILP matches or outperforms NN+RegEvo
on 22/30 problems. An alternate plot where scores correspond to area under the best-observed
reward curve (AUC) can be found in Appendix H. (Bottom) Best observed reward as a function
of iteration for an example problem in each class, averaged over 20 trials (bands indicate ±1sd).
Dashed grey lines in the ﬁrst 50 steps indicate the initial randomly sampled dataset, common to all
methods except RBFOpt, which performs its own initialization."
EXPERIMENTS,0.15118110236220472,"In all experiments, we ﬁx the surrogate model hypothesis class F to networks with a single, fully-
connected hidden layer of 16 neurons. Models are trained with TensorFlow (Abadi et al., 2016),
using the ADAM optimizer. No hyper-parameter tuning is performed across problems. The MILP
acquisition problem is solved with the Mixed-Integer Programming solver SCIP 7.0.1 (Gamrath
et al., 2020) using default settings and a time limit of 500 seconds. We use standard CPU machines
with ∼1G RAM and ≤10 cores."
BENCHMARKING TASKS,0.15275590551181104,"4.1
BENCHMARKING TASKS"
BENCHMARKING TASKS,0.15433070866141732,"Unless otherwise stated, tasks’ domains consist of discrete decision vectors of length n, with a
common alphabet A for all elements. We consider three families of black-box objectives:"
BENCHMARKING TASKS,0.15590551181102363,"• RandomMLP The output of a multi-layer perceptron operating on a one-hot encoding of the in-
put. Notably, architectures have signiﬁcantly more layers/parameters than the 16-neuron networks
used as surrogates by NN+MILP.
• TfBind Binding strength of a length-8 DNA sequence to a given transcription factor (Barrera
et al., 2016).
• BBOB Non-linear function from the continuous Black-Box Optimization Benchmarking library
(Hansen et al., 2009), where each coordinate has been uniformly discretized along its range.
Despite the underlying continuous structure, inputs are treated as unordered and categorical."
BENCHMARKING TASKS,0.15748031496062992,"We use parentheses after the family name to denote dimensionality of a problem, e.g. Ran-
domMLP(10,5) refers to a RandomMLP objective over a discrete domain with n = 10 and |A| = 5.
Appendix B lists all functions considered, and provides further details on the BBOB discretization."
BENCHMARKING TASKS,0.15905511811023623,"Algorithms are evaluated in terms of the best reward observed after 1000 queries, averaged over
20 trials per problem. Algorithms’ performance is signiﬁcantly inﬂuenced by the set of x that are
proposed in early iterations. Therefore, to reduce variance when comparing algorithms, we initialize
each of the 20 trials with a different ﬁxed dataset of 50 random points. To facilitate comparison
across problems with different reward scales, the algorithms’ average ﬁnal rewards are min/max
normalized within each problem. That is, the best (resp. worst) on-average algorithm for a given
problem is assigned a score of one (resp. zero), and intermediate values express relative distance
from these extremes. No hyper-parameter tuning was performed across problems for any algorithm."
BENCHMARKING TASKS,0.16062992125984252,Under review as a conference paper at ICLR 2022
UNCONSTRAINED OPTIMIZATION,0.16220472440944883,"4.2
UNCONSTRAINED OPTIMIZATION"
UNCONSTRAINED OPTIMIZATION,0.16377952755905512,"Before considering problems with combinatorial white-box constraints, we ﬁrst tackle simple prob-
lems with no additional constraints on the discrete domain, i.e., Ω= An. This allows us to compare
against general-purpose algorithms for unconstrained discrete black-box optimization. We vary
the problem sizes over 30 functions, consisting of eight RandomMLP(25,5), ten BBOB(10,10) and
twelve TfBind(8,4) targets (Appendix B)."
UNCONSTRAINED OPTIMIZATION,0.16535433070866143,"NN-MILP provides an analytical tool for understanding the relative impacts of the choice of surro-
gate model and whether the acquisition problem is solved to optimality. Doing so requires ablations
that vary along two axes: the family of surrogate models and the inner-loop solver. Further conﬁgu-
ration details are provided in Appendix C."
UNCONSTRAINED OPTIMIZATION,0.16692913385826771,"• RegEvo Local evolutionary search (Real et al., 2019) using pointwise mutations of single parent
sequences and crossover recombination of two parent sequences.
• NN + RegEvo An ablation of NN+MILP, with the only difference being the use of RegEvo in lieu
of MILP for solving the acquisition problem. Here, the inner-loop solver is allowed 10k queries
of the acquisition function batched over 100 rounds, and proposes the point it has visited with the
highest acquisition function value. The surrogate model is ﬁt exactly as in NN+MILP.
• Ensemble + RegEvo A re-implementation of the ‘MBO’ baseline from Angermueller et al.
(2020), using an ensemble of linear and random forest regressors as the surrogate, where hyper-
parameters are dynamically selected at each iteration. The acquisition function is the ensemble
mean and inner-loop optimization uses RegEvo.
• RBFOpt A competitive mixed-integer black-box optimization solver that uses the ‘Radial Basis
Function method’ as a surrogate model (Costa & Nannicini, 2018)."
UNCONSTRAINED OPTIMIZATION,0.16850393700787403,"Figure 1 plots the distribution of algorithms’ scores for all unconstrained problems and an example
reward curve from each class. We omit RBFOpt from the BBOB problems since it proposes the
integer midpoint (rounded down) as part of its initialization, which is close to optimal by design (see
Appendix B.3). We observe that relative performance of algorithms varies signiﬁcantly by objective
family, with NN+MILP performing well across the board. In particular, we wish to highlight the
empirical beneﬁts of global optimization of the acquisition function, as illustrated by the improved
performance of NN+MILP vs. NN+RegEvo. The only difference between the two is the former’s
stronger optimality guarantees when solving the acquisition problem. We observe that NN+MILP
obtains a greater or equal score than its evolution-based counterpart in 22 of the 30 problems con-
sidered, and variance in its normalized scores is lower within a given objective family."
UNCONSTRAINED OPTIMIZATION,0.1700787401574803,"The comparison of NN+MILP and Ensemble+RegEvo solver is also instructive. Here, the primary
difference is the hypothesis class F. The strong performance of Ensemble+RegEvo on TfBind, and
to a lesser extent BBOB, suggests that ensembles of linear and tree-based regressors are better suited
to approximate those black-box objectives. However, the combination of a single neural network
surrogate and exact optimization is able to achieve comparable performance."
CONSTRAINED OPTIMIZATION,0.17165354330708663,"4.3
CONSTRAINED OPTIMIZATION"
CONSTRAINED OPTIMIZATION,0.1732283464566929,"Next, problems are augmented with combinatorial constraints on the domain. We simulate ﬁne-
balance constraints in observational studies (Zubizarreta et al., 2018; Bennett et al., 2020), where
the same number of items must be selected from given sub-populations (e.g., groups sharing a com-
mon attribute). These simple, yet highly combinatorial, constraints allow for fair comparison with
evolutionary algorithms that are designed to maintain feasibility with every mutation. Appendix F
includes additional results on binary quadratic optimization problems with more complex constraints
(e.g. graph partitioning or quadratic assignment) from the MINLPLib benchmark (Vigerske, 2021)."
CONSTRAINED OPTIMIZATION,0.17480314960629922,"We use a binary alphabet A = {0, 1} to indicate whether each of n = 100 items is selected.
These have been partitioned into given subsets S1, ..., S2k for some integer k and constraints enforce
that the number of selected items is equal in pairs of subsets: P"
CONSTRAINED OPTIMIZATION,0.1763779527559055,i∈S2j−1 zi1 = P
CONSTRAINED OPTIMIZATION,0.17795275590551182,"i∈S2j zi1 for
j ∈[k]. We use equally-sized subsets, each of cardinality
n
2k, creating 30 problems over a grid of
ten objectives and three values of k ∈{5, 10, 25}. Further details can be found in Appendix B.
RandomMLP(100,2) functions then simulate non-linear reward structures for a given selection. A
different objective class based on the Ising model is also considered in Appendix E."
CONSTRAINED OPTIMIZATION,0.1795275590551181,Under review as a conference paper at ICLR 2022
CONSTRAINED OPTIMIZATION,0.18110236220472442,"200
400
600
800
1000
Step 2 3 4 5"
CONSTRAINED OPTIMIZATION,0.1826771653543307,Best Observed Reward
CONSTRAINED OPTIMIZATION,0.18425196850393702,"NN+MILP
NN+ConEvo
NN+RejSample
ConEvo
Ensemble+RegEvo (a)"
CONSTRAINED OPTIMIZATION,0.1858267716535433,"0
200
400
600
800
Step 0 5 10 15 20"
CONSTRAINED OPTIMIZATION,0.18740157480314962,MILP solver runtime (s) (b)
CONSTRAINED OPTIMIZATION,0.1889763779527559,"0
1e6
2e6
3e6
4e6
5e6
Cumulative Architecture Training Time (s) 93.6% 93.8% 94.0% 94.2% 94.4%"
CONSTRAINED OPTIMIZATION,0.19055118110236222,CIFAR-10 Test Accuracy
CONSTRAINED OPTIMIZATION,0.1921259842519685,"RE
RS
Linear+MILP
NN+MILP
NN+MILP (w/ symmetry)"
CONSTRAINED OPTIMIZATION,0.19370078740157481,"(c)
Figure 2: (a) Best observed reward as a function of iteration for typical constrained problem (Sec-
tion 4.3), averaged over 20 trials (bands indicate ±1sd). Initial randomly sampled set of 50 points
is omitted. Distribution of normalized ﬁnal scores and more examples can be found in Appendix H.
(b) Distribution of MILP acquisition problem solve times as a function of iteration. Line and bands
show the median and 5th/95th percentile range over all trials of all TfBind(8,4) problems. (c) Test
accuracy of algorithms’ incumbent architecture as a function of cumulative training time on NAS-
Bench-101, averaged over 100 trials. Bands indicate 95% conﬁdence interval for the mean."
CONSTRAINED OPTIMIZATION,0.1952755905511811,"The following optimization approaches provide ablations to contrast declarative vs. procedural ap-
proaches to handling the constraints. Further conﬁguration details are given in Appendix C."
CONSTRAINED OPTIMIZATION,0.1968503937007874,"• ConEvo RegEvo with a custom mutator that procedurally maintains feasibility. Paired subsets are
mutated jointly, ensuring that the number of changes in each pair is the same.
• NN+ConEvo An ablation of NN+MILP where ConEvo replaces MILP as the inner-loop solver.
The inner-loop solver is allowed 10k queries of the acquisition function, batched over 100 rounds.
• NN+RejSample An ablation of NN+MILP where the inner-loop solver samples 10k feasible
points uniformly-at-random from the domain. By using rejection sampling, the solver can lever-
age the same declarative deﬁnition of the constraints as in NN+MILP.
• Ensemble+RegEvo Same as Section 4.2, using the constraint deﬁnition to assign negative re-
wards to infeasible proposed points, which in turn affect the surrogate model."
CONSTRAINED OPTIMIZATION,0.1984251968503937,"Figure 2a plots algorithms’ best observed reward as a function of iteration for a typical problem.
Here, we observe that NN+MILP and NN+ConEvo perform similarly, both beneﬁting from the abil-
ity to model the objective with a surrogate, unlike ConEvo. The poor performance of NN+RejSample
and Ensemble+RegEvo highlight the importance of exploiting combinatorial structure. Moreover,
we obtain qualitatively similar results for an objective based on the Ising model (Appendix E)."
CONSTRAINED OPTIMIZATION,0.2,"Finally, while we did not ﬁnd the difference of NN+MILP and NN+ConEvo to be statistically sig-
niﬁcant in terms of optimization performance, they differ considerably in terms of ease of imple-
mentation. In particular, NN+MILP required very few lines of extra code to add subset-equality
constraints to the existing MILP formulation, and could have just as easily been extended to other,
possibly interacting, MILP-representable constraints. Conversely, NN+ConEvo relied on the imple-
mentation of a custom mutator, tailored to the constraint structure at hand, and would likely require
signiﬁcant reworking if other constraints were added."
PRACTICALITY OF MILP,0.2015748031496063,"4.4
PRACTICALITY OF MILP"
PRACTICALITY OF MILP,0.2031496062992126,"Figure 2b plots the distribution of MILP solve times for inner-loop optimization as function of iter-
ation over all trials of all TfBind problems. Despite the computational complexity of the acquisition
problem, MILP ﬁnds globally optimal solutions in seconds. Averaging across all unconstrained ex-
periments (Section 4.2), the inner-loop optimization took 7.92 ± 4.23s for NN+MILP compared to
9.00±1.94s for NN+RegEvo (avg. ± sd). We observed no MILP solves that exceeded the 500s time
budget, and thus they were all provably optimal. As is often the case with MILP, the relationship
between problem size and runtime can be unpredictable. For example, we encountered higher aver-
age solve times for lower-dimensional TfBind problems than for RandomMLP and BBOB. We also
explore the impact of surrogate model network size on solve time in Appendix H. Solve times tend
to increase over time, possibly due to the increasing number of no-good constraints and the nature
of surrogate models that have been ﬁt on more data."
PRACTICALITY OF MILP,0.2047244094488189,Under review as a conference paper at ICLR 2022
PRACTICALITY OF MILP,0.2062992125984252,"5
NAS-BENCH-101 CASE STUDY"
PRACTICALITY OF MILP,0.2078740157480315,"Finally, we use the NAS-Bench-101 (Ying et al., 2019) neural architecture search (NAS) benchmark
to illustrate the power of MILP’s declarative constraint language in formulating complex combinato-
rial domains. The optimization domain consists of directed acyclic graphs (DAGs) representing the
cell in a neural architecture. Two nodes represent the input and output, and must be connected by a
directed path, while the remaining nodes are each assigned to be 1x1 convolution, 3x3 convolution,
or 3x3 max-pooling. Edges specify the ﬂow of activations between nodes. The objective f(x) is
out-of-sample image classiﬁcation accuracy. More details can be found in Appendix G."
MILP FORMULATIONS FOR GRAPH SEARCH,0.2094488188976378,"5.1
MILP FORMULATIONS FOR GRAPH SEARCH"
MILP FORMULATIONS FOR GRAPH SEARCH,0.2110236220472441,"We next introduce a novel MILP formulation that precisely characterizes the set of valid NAS-
Bench-101 cells. We use two sets of decision variables; the ﬁrst set are binary and encode the
upper-triangular adjacency matrix of a DAG with exactly V nodes. The second set are a one-hot
binary encoding of nodes’ operations. Crucially, we introduce a new “null” operation, allowing
the MILP to represent DAGs with fewer than V nodes. Constraints enforce that all non-null nodes
appear on a path from the input to output node, and that there exists at least one such path. A full
formulation in terms of linear constraints appears in Appendix G."
MILP FORMULATIONS FOR GRAPH SEARCH,0.2125984251968504,"A second formulation, nearly identical but enforcing so-called symmetry-breaking constraints, seeks
to address isomorphisms in our representation. The ﬁxed ordering of nodes above results in distinct
representations for isomorphic graphs, which may be redundantly proposed despite the no-good
constraints. In response, we add constraints to the MILP enforcing that null nodes must occur after
any non-null nodes in the linear ordering of x, which removes some, but not all, isomorphisms. An
alternative approach uses an isomorphism-invariant surrogate (Wen et al., 2020), but MBO based on
such a model is still vulnerable to proposing isomorphic x."
RESULTS,0.2141732283464567,"5.2
RESULTS"
RESULTS,0.215748031496063,"We refer to an optimizer using the ﬁrst formulation as NN+MILP and the second as NN+MILP
(w/ symmetry). Otherwise, we use the same conﬁguration as in Section 4. Linear+MILP replaces
the neural network surrogate with a linear model trained on Dt−1 with randomization provided by
bootstrapping that training data. Regularized evolution (RE) and random search (RS) baselines are
from Ying et al. (2019)."
RESULTS,0.2173228346456693,"Figure 2c plots the out-of-sample accuracy of the proposed architecture with the highest observed
validation accuracy (the “incumbent” architecture) vs. the cumulative architecture training time.
NN+MILP, despite its more general design, signiﬁcantly outperforms RE. Surprisingly, we observe
that both methods using no symmetry constraints, NN+MILP and Linear+MILP, perform better
than NN+MILP (w/ symmetry), despite optimizing over a larger search space. Finally, note that
Linear+MILP outperforms NN+MILP in early iterations, but is eventually overtaken. Future work
could select among MILP-compatible models at each iteration."
CONCLUSION AND FUTURE WORK,0.2188976377952756,"6
CONCLUSION AND FUTURE WORK"
CONCLUSION AND FUTURE WORK,0.2204724409448819,"In this work we propose the NN+MILP framework for discrete MBO, using neural networks with
ReLU activations for surrogate modeling and MILP to solve the acquisition problem. A major
advantage of our method is its generality, using MILP’s versatile declarative constraint language
to address domains that might otherwise require specialized search algorithms for inner-loop op-
timization. Our experiments show that NN+MILP performs well on a range of discrete black-box
problems with practical computational overhead using standard packages and hardware."
CONCLUSION AND FUTURE WORK,0.2220472440944882,"For future applications to continuous or mixed-integer domains, the question arises as to how to
best avoid redundant proposals and encourage exploration given that no-good constraints cannot
be applied as stated. More complex acquisition functions could also be considered, as long as
they remain MILP-representable. For example, Expected Improvement deﬁned over the posterior
predictive distribution of an ensemble of neural networks is piecewise-linear."
CONCLUSION AND FUTURE WORK,0.22362204724409449,Under review as a conference paper at ICLR 2022
ETHICS STATEMENT,0.2251968503937008,ETHICS STATEMENT
ETHICS STATEMENT,0.22677165354330708,"In this paper, we introduce a general algorithm for constrained discrete black-box optimization that
could be applied in any number of application domains, e.g. engineering system design, neural
architecture search, or drug design. As with any optimization problem, it is crucial to formulate the
objective and constraints of the problem to ensure they reﬂect ethical design principles. Users should
understand whether optimizing for a given objective might implicitly result in biased/discriminatory
solutions, or have unintended consequences for some unmodeled objective. For example, in the NAS
case study of Section 5 we follow common practice by maximizing out-of-sample accuracy, which
might result in larger networks that are environmentally costly to train. To address this, users of
our algorithm might want to incorporate environmental or ethical considerations in the (black-box)
objective or constraints."
ETHICS STATEMENT,0.2283464566929134,The authors do not have any conﬂicts of interest to disclose.
REPRODUCIBILITY STATEMENT,0.22992125984251968,REPRODUCIBILITY STATEMENT
REPRODUCIBILITY STATEMENT,0.231496062992126,"We include detailed implementation sections in the Appendix to accompany all of our experiments.
In particular, Appendix A describes the MILP formulation and solution techniques used for solving
the NN+MILP acquisition problem. Appendix B contains descriptions of the RandomMLP, TfBind
and BBOB benchmarks we consider in Sections 4.2 and 4.3, including how we selected problems
and what hyper-parameters we used. Appendix C lists implementation details and hyper-parameter
settings for NN+MILP, as well as all baseline algorithms from Sections 4.2 and 4.3 (RegEvo,
NN+RegEvo, Ensemble+RegEvo, RBFOpt, ConEvo, NN+ConEvo, NN+RejSample). Finally, Ap-
pendix G contains the full MILP formulation for the NAS-Bench-101 graph search domain, as well
as relevant details on the problem setting and algorithm evaluation."
REFERENCES,0.23307086614173228,REFERENCES
REFERENCES,0.2346456692913386,"Mart´ın Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu
Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al. Tensorﬂow: A system for large-
scale machine learning. In 12th USENIX symposium on operating systems design and implemen-
tation (OSDI 16), pp. 265–283, 2016."
REFERENCES,0.23622047244094488,"T. Achterberg and R. Wunderling. Mixed integer programming: Analyzing 12 years of progress.
In M. J¨unger and G. Reinelt (eds.), Facets of Combinatorial Optimization: Festschrift for Martin
Gr¨otschel, pp. 449–481. Springer Berlin Heidelberg, Berlin, Heidelberg, 2013."
REFERENCES,0.2377952755905512,"Ross Anderson, Joey Huchette, Will Ma, Christian Tjandraatmadja, and Juan Pablo Vielma. Strong
mixed-integer programming formulations for trained neural networks. Mathematical Program-
ming, pp. 1–37, 2020."
REFERENCES,0.23937007874015748,"Christof Angermueller, David Belanger, Andreea Gane, Zelda Mariet, David Dohan, Kevin Murphy,
Lucy Colwell, and D Sculley. Population-based black-box optimization for biological sequence
design. In International Conference on Machine Learning, pp. 324–334. PMLR, 2020."
REFERENCES,0.2409448818897638,"Setareh Ariafar, Jaume Coll-Font, Dana H Brooks, and Jennifer G Dy. ADMMBO: Bayesian op-
timization with unknown constraints using ADMM. Journal of Machine Learning Research, 20
(123):1–26, 2019."
REFERENCES,0.24251968503937008,"Ricardo Baptista and Matthias Poloczek. Bayesian optimization of combinatorial structures. In
International Conference on Machine Learning, pp. 462–471. PMLR, 2018."
REFERENCES,0.2440944881889764,"Luis A Barrera, Anastasia Vedenko, Jesse V Kurland, Julia M Rogers, Stephen S Gisselbrecht,
Elizabeth J Rossin, Jaie Woodard, Luca Mariani, Kian Hong Kock, Sachi Inukai, et al. Survey
of variation in human transcription factors reveals prevalent DNA binding changes. Science, 351
(6280):1450–1454, 2016."
REFERENCES,0.24566929133858267,"Magdalena Bennett, Juan-Pablo Vielma, and Jose R. Zubizarreta. Building representative matched
samples with multi-valued treatments in large observational studies. Journal of Computational
and Graphical Statistics, 29:744–757, 2020."
REFERENCES,0.247244094488189,Under review as a conference paper at ICLR 2022
REFERENCES,0.24881889763779527,"Felix Berkenkamp, Angela P Schoellig, and Andreas Krause.
Safe controller optimization for
quadrotors with gaussian processes. In 2016 IEEE International Conference on Robotics and
Automation (ICRA), pp. 491–496. IEEE, 2016."
REFERENCES,0.2503937007874016,"Timo Berthold. Measuring the impact of primal heuristics. Operations Research Letters, 41(6):
611–614, 2013."
REFERENCES,0.25196850393700787,"Alan W Biermann. The inference of regular LISP programs from examples. IEEE Transactions on
Systems, Man, and Cybernetics, 8(8):585–600, 1978."
REFERENCES,0.25354330708661416,"Robert E Bixby. A brief history of linear and mixed-integer programming computation. Documenta
Mathematica, pp. 107–121, 2012."
REFERENCES,0.2551181102362205,"Laurens Bliek, Sicco Verwer, and Mathijs de Weerdt. Black-box combinatorial optimization using
models with integer-valued minima. Annals of Mathematics and Artiﬁcial Intelligence, 89(7):
639–653, 2021."
REFERENCES,0.2566929133858268,"Pierre Bonami, Lorenz T Biegler, Andrew R Conn, G´erard Cornu´ejols, Ignacio E Grossmann, Carl D
Laird, Jon Lee, Andrea Lodi, Franc¸ois Margot, Nicolas Sawaya, et al. An algorithmic framework
for convex mixed integer nonlinear programs. Discrete Optimization, 5(2):186–204, 2008."
REFERENCES,0.25826771653543307,"Chih-Hong Cheng, Georg N¨uhrenberg, and Harald Ruess. Maximum resilience of artiﬁcial neural
networks. In International Symposium on Automated Technology for Veriﬁcation and Analysis,
pp. 251–268. Springer, 2017."
REFERENCES,0.25984251968503935,"Alberto Costa and Giacomo Nannicini. RBFOpt: an open-source library for black-box optimiza-
tion with costly function evaluations. Mathematical Programming Computation, 10(4):597–629,
2018."
REFERENCES,0.2614173228346457,"Arthur Delarue, Ross Anderson, and Christian Tjandraatmadja. Reinforcement learning with combi-
natorial actions: An application to vehicle routing. Proceedings of the 34th Conference on Neural
Information Processing Systems (NeurIPS 2020), arXiv:2010.12001, 2020."
REFERENCES,0.262992125984252,"Aryan Deshwal, Syrine Belakaria, and Janardhan Rao Doppa. Mercer features for efﬁcient combi-
natorial Bayesian optimization. arXiv preprint arXiv:2012.07762, 2020."
REFERENCES,0.26456692913385826,"Daniel C Elton, Zois Boukouvalas, Mark D Fuge, and Peter W Chung. Deep learning for molecular
design—a review of the state of the art. Molecular Systems Design & Engineering, 4(4):828–849,
2019."
REFERENCES,0.26614173228346455,"Gerald Gamrath, Daniel Anderson, Ksenia Bestuzheva, Wei-Kun Chen, Leon Eiﬂer, Maxime Gasse,
Patrick Gemander, Ambros Gleixner, Leona Gottwald, Katrin Halbig, Gregor Hendel, Christo-
pher Hojny, Thorsten Koch, Pierre Le Bodic, Stephen J. Maher, Frederic Matter, Matthias Mil-
tenberger, Erik M¨uhmer, Benjamin M¨uller, Marc E. Pfetsch, Franziska Schl¨osser, Felipe Serrano,
Yuji Shinano, Christine Tawﬁk, Stefan Vigerske, Fabian Wegscheider, Dieter Weninger, and Jakob
Witzig. The SCIP Optimization Suite 7.0. ZIB-Report. Zuse Institut Berlin, 2020."
REFERENCES,0.2677165354330709,"Michael A Gelbart, Jasper Snoek, and Ryan P Adams. Bayesian optimization with unknown con-
straints. In Proceedings of the Thirtieth Conference on Uncertainty in Artiﬁcial Intelligence, pp.
250–259, 2014."
REFERENCES,0.2692913385826772,"Bjarne Grimstad and Henrik Andersson. ReLU networks as surrogate models in mixed-integer linear
programs. Computers & Chemical Engineering, 131:106580, 2019."
REFERENCES,0.27086614173228346,"Nikolaus Hansen, Steffen Finck, Raymond Ros, and Anne Auger. Real-parameter black-box opti-
mization benchmarking 2009: Noiseless functions deﬁnitions. Research Report RR-6829, INRIA,
2009."
REFERENCES,0.27244094488188975,"Jos´e Miguel Hern´andez-Lobato, Michael A Gelbart, Ryan P Adams, Matthew W Hoffman,
and Zoubin Ghahramani.
A general framework for constrained Bayesian optimization using
information-based search. Journal of Machine Learning Research, 17:5549–5601, 2016."
REFERENCES,0.2740157480314961,Under review as a conference paper at ICLR 2022
REFERENCES,0.2755905511811024,"Jos´e Miguel Hern´andez-Lobato, James Requeima, Edward O Pyzer-Knapp, and Al´an Aspuru-Guzik.
Parallel and distributed Thompson sampling for large-scale accelerated exploration of chemical
space. In International Conference on Machine Learning, pp. 1470–1479. PMLR, 2017."
REFERENCES,0.27716535433070866,"Joey Huchette and Juan Pablo Vielma. Nonconvex piecewise linear functions: Advanced formula-
tions and simple modeling tools. To appear in Operations Research, arXiv:1708.00050, 2019."
REFERENCES,0.27874015748031494,"Frank Hutter, Holger H Hoos, and Kevin Leyton-Brown. Sequential model-based optimization for
general algorithm conﬁguration. In International conference on learning and intelligent optimiza-
tion, pp. 507–523. Springer, 2011."
REFERENCES,0.2803149606299213,"Robert G Jeroslow. Logic-based decision support: Mixed integer model formulation. Elsevier, 1989."
REFERENCES,0.28188976377952757,"Donald R Jones, Matthias Schonlau, and William J Welch. Efﬁcient global optimization of expensive
black-box functions. Journal of Global optimization, 13(4):455–492, 1998."
REFERENCES,0.28346456692913385,"Michael J¨unger, Thomas M. Liebling, Denis Naddef, George L. Nemhauser, William R. Pulley-
blank, Gerhard Reinelt, Giovanni Rinaldi, and Laurence A. Wolsey (eds.). 50 Years of Integer
Programming 1958-2008 - From the Early Years to the State-of-the-Art. Springer, 2010. ISBN
978-3-540-68274-5."
REFERENCES,0.28503937007874014,"Kirthevasan Kandasamy, Akshay Krishnamurthy, Jeff Schneider, and Barnab´as P´oczos. Parallelised
Bayesian optimisation via Thompson sampling. In International Conference on Artiﬁcial Intelli-
gence and Statistics, pp. 133–142. PMLR, 2018."
REFERENCES,0.2866141732283465,"Kirthevasan Kandasamy, Karun Raju Vysyaraju, Willie Neiswanger, Biswajit Paria, Christopher R
Collins, Jeff Schneider, Barnabas Poczos, and Eric P Xing. Tuning hyperparameters without
grad students: Scalable and robust Bayesian optimisation with Dragonﬂy. Journal of Machine
Learning Research, 21(81):1–27, 2020."
REFERENCES,0.28818897637795277,"Rickard Karlsson, Laurens Bliek, Sicco Verwer, and Mathijs de Weerdt. Continuous surrogate-based
optimization algorithms are well-suited for expensive discrete problems. In Benelux Conference
on Artiﬁcial Intelligence, pp. 48–63. Springer, 2020."
REFERENCES,0.28976377952755905,"Sun Hye Kim and Fani Boukouvala.
Surrogate-based optimization for mixed-integer nonlinear
problems. Computers & Chemical Engineering, 140:106847, 2020."
REFERENCES,0.29133858267716534,"Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive
uncertainty estimation using deep ensembles. In Proceedings of the 31st International Conference
on Neural Information Processing Systems, pp. 6405–6416, 2017."
REFERENCES,0.2929133858267717,"Benjamin Letham, Brian Karrer, Guilherme Ottoni, Eytan Bakshy, et al. Constrained Bayesian
optimization with noisy experiments. Bayesian Analysis, 14(2):495–519, 2019."
REFERENCES,0.29448818897637796,"Alessio Lomuscio and Lalit Maganti. An approach to reachability analysis for feed-forward ReLU
neural networks. arXiv preprint arXiv:1706.07351, 2017."
REFERENCES,0.29606299212598425,"Matthias Miltenberger, Ted Ralphs, and Daniel E Steffy. Exploring the numerics of branch-and-cut
for mixed integer linear optimization. In Operations Research Proceedings 2017, pp. 151–157.
Springer, 2018."
REFERENCES,0.29763779527559053,"Jonas Mockus, Vytautas Tiesis, and Antanas Zilinskas. The application of bayesian methods for
seeking the extremum. Towards global optimization, 2(117-129):2, 1978."
REFERENCES,0.2992125984251969,"Juliane M¨uller. Miso: mixed-integer surrogate optimization framework. Optimization and Engi-
neering, 17(1):177–203, 2016."
REFERENCES,0.30078740157480316,"Changyong Oh, Jakub M Tomczak, Efstratios Gavves, and Max Welling. Combinatorial Bayesian
optimization using the graph Cartesian product. In Neural Information Processing Systems, 2019."
REFERENCES,0.30236220472440944,"Fabian Pedregosa, Ga¨el Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier
Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. Scikit-learn:
Machine learning in python. the Journal of machine Learning research, 12:2825–2830, 2011."
REFERENCES,0.30393700787401573,Under review as a conference paper at ICLR 2022
REFERENCES,0.30551181102362207,"Yves Pochet and Laurence A Wolsey. Production planning by mixed integer programming. Springer
Science & Business Media, 2006."
REFERENCES,0.30708661417322836,"Carl E. Rasmussen and Christopher K.I. Williams.
Gaussian Processes for Machine Learning.
Adaptive Computation and Machine Learning. MIT Press, Cambridge, MA, USA, January 2006."
REFERENCES,0.30866141732283464,"Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc V Le. Regularized evolution for image
classiﬁer architecture search. In Proceedings of the AAAI conference on artiﬁcial intelligence,
volume 33, pp. 4780–4789, 2019."
REFERENCES,0.3102362204724409,"Moonkyung Ryu, Yinlam Chow, Ross Michael Anderson, Christian Tjandraatmadja, and Craig
Boutilier. CAQL: Continuous Action Q-Learning. In Proceedings of the Eighth International
Conference on Learning Representations (ICLR-20), Addis Ababa, Ethiopia, 2020."
REFERENCES,0.31181102362204727,"Matthias Schonlau, William J Welch, Donald R Jones, et al. Global versus local search in constrained
optimization of computer models. In New developments and applications in experimental design,
pp. 11–25. Institute of Mathematical Statistics, 1998."
REFERENCES,0.31338582677165355,"Alexander Schrijver. Combinatorial optimization: polyhedra and efﬁciency. Springer Science &
Business Media, 2003."
REFERENCES,0.31496062992125984,"Thiago Serra, Christian Tjandraatmadja, and Srikumar Ramalingam. Bounding and counting linear
regions of deep neural networks. In International Conference on Machine Learning, pp. 4558–
4566. PMLR, 2018."
REFERENCES,0.3165354330708661,"Thiago Serra, Abhinav Kumar, and Srikumar Ramalingam. Scaling up exact neural network com-
pression by ReLU stability. arXiv preprint arXiv:2102.07804, 2021."
REFERENCES,0.31811023622047246,"Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P Adams, and Nando De Freitas. Taking the
human out of the loop: A review of Bayesian optimization. Proceedings of the IEEE, 104(1):
148–175, 2015."
REFERENCES,0.31968503937007875,"Zhan Shi, Chirag Sakhuja, Milad Hashemi, Kevin Swersky, and Calvin Lin.
Learned hard-
ware/software co-design of neural accelerators. arXiv preprint arXiv:2010.02075, 2020."
REFERENCES,0.32125984251968503,"Jasper Snoek, Hugo Larochelle, and Ryan Prescott Adams. Practical bayesian optimization of ma-
chine learning algorithms. Advances in Neural Information Processing Systems, 2012."
REFERENCES,0.3228346456692913,"Jasper Snoek, Oren Rippel, Kevin Swersky, Ryan Kiros, Nadathur Satish, Narayanan Sundaram,
Mostofa Patwary, Mr Prabhat, and Ryan Adams. Scalable Bayesian optimization using deep
neural networks. In International Conference on Machine Learning, pp. 2171–2180. PMLR,
2015."
REFERENCES,0.32440944881889766,"Niranjan Srinivas, Andreas Krause, Sham M Kakade, and Matthias Seeger. Gaussian process opti-
mization in the bandit setting: No regret and experimental design. In Proceedings of the Interna-
tional Conference on Machine Learning, 2010, 2010."
REFERENCES,0.32598425196850395,"Phillip D Summers. A methodology for LISP program construction from examples. Journal of the
ACM (JACM), 24(1):161–175, 1977."
REFERENCES,0.32755905511811023,"William R Thompson. On the likelihood that one unknown probability exceeds another in view of
the evidence of two samples. Biometrika, 25(3/4):285–294, 1933."
REFERENCES,0.3291338582677165,"Vincent Tjeng, Kai Xiao, and Russ Tedrake. Evaluating robustness of neural networks with mixed
integer programming. In International Conference on Learning Representations, 2019."
REFERENCES,0.33070866141732286,"Juan Pablo Vielma. Mixed integer linear programming formulation techniques. SIAM Review, 57:
3–57, 2015."
REFERENCES,0.33228346456692914,"Juan Pablo Vielma, Shabbir Ahmed, and George L Nemhauser. Mixed-integer models for nonsep-
arable piecewise linear optimization: unifying framework and extensions. Operations Research,
58:303–315, 2010."
REFERENCES,0.33385826771653543,Under review as a conference paper at ICLR 2022
REFERENCES,0.3354330708661417,"Stefan Vigerske. MINLPLib: A library of mixed-integer and continuous nonlinear programming
instances, 2021. URL https://www.minlplib.org. Accessed October 1, 2021 (git hash:
827f1a2d)."
REFERENCES,0.33700787401574805,"Wei Wen, Hanxiao Liu, Yiran Chen, Hai Li, Gabriel Bender, and Pieter-Jan Kindermans. Neural
predictor for neural architecture search. In European Conference on Computer Vision, pp. 660–
676. Springer, 2020."
REFERENCES,0.33858267716535434,"H. Paul Williams. Model building in mathematical programming. John Wiley & Sons, 2013."
REFERENCES,0.3401574803149606,"Laurence A Wolsey and George L Nemhauser. Integer and combinatorial optimization, volume 55.
John Wiley & Sons, 1999."
REFERENCES,0.3417322834645669,"Keyulu Xu, Mozhi Zhang, Jingling Li, Simon S Du, Ken-ichi Kawarabayashi, and Stefanie Jegelka.
How neural networks extrapolate: From feedforward to graph neural networks. In International
Conference on Learning Representations, 2021."
REFERENCES,0.34330708661417325,"Kevin K Yang, Zachary Wu, and Frances H Arnold. Machine-learning-guided directed evolution for
protein engineering. Nature methods, 16(8):687–694, 2019."
REFERENCES,0.34488188976377954,"Mihalis Yannakakis. Expressing combinatorial optimization problems by linear programs. Journal
of Computer and System Sciences, 43(3):441–466, 1991."
REFERENCES,0.3464566929133858,"Chris Ying, Aaron Klein, Eric Christiansen, Esteban Real, Kevin Murphy, and Frank Hutter. NAS-
Bench-101: Towards reproducible neural architecture search. In International Conference on
Machine Learning, pp. 7105–7114. PMLR, 2019."
REFERENCES,0.3480314960629921,"Barret Zoph and Quoc V Le. Neural architecture search with reinforcement learning. In Interna-
tional Conference on Learning Representations, 2017."
REFERENCES,0.34960629921259845,"Jose R. Zubizarreta, Cinar Kilcioglu, and Juan Pablo Vielma. designmatch: Matched samples that
are balanced and representative by design. R package version 0.3, 1, 2018."
REFERENCES,0.35118110236220473,Under review as a conference paper at ICLR 2022
REFERENCES,0.352755905511811,"A
STRENGTHENING THE MILP FORMULATION FOR NEURAL NETWORKS"
REFERENCES,0.3543307086614173,"Here we discuss more advanced techniques for formulating the neural network surrogate model in
the MILP problem. Recall the ReLU formulation constraints (4) and (5) from Section 3.3, except
that we consider M separately for each constraint:"
REFERENCES,0.35590551181102364,"0 ≤y ≤M0α
(4’)"
REFERENCES,0.35748031496062993,"w⊤x + b ≤y ≤w⊤x + b + M1(1 −α),
(5’)"
REFERENCES,0.3590551181102362,"Here, we require a nonnegative value M0 such that the right-hand side of (4’) is greater or equal
than a valid upper bound on y when α = 1. Similarly, M1 must be a nonnegative value such that the
right-hand side of (5’) is greater or equal than zero when α = 0. Therefore, we may choose M0 to
be any upper bound of maxx∈Ω′ w⊤x + b and M1 to be any upper bound of maxx∈Ω′ −(w⊤x + b),
where Ω′ is the domain of the inputs of this ReLU, which depends on Ω. The tighter these bounds
are, the better the MILP performs."
REFERENCES,0.3606299212598425,"Moreover, if we ﬁnd negative M0 or M1, then we may (in fact, must) replace the formulation by
y = 0 or y = w⊤x + b respectively, since in these cases the ReLU is always inactive or active for
any x ∈Ω′. This replacement must be done because the formulation assumes nonnegative M0 and
M1 for feasibility."
REFERENCES,0.36220472440944884,"The simplest way to compute M0 and M1 is to start from bounds in Ωand propagate them via inter-
val arithmetic. For example, if x ∈[L, U], then M0 can be set to P"
REFERENCES,0.3637795275590551,i:wi>0 wiUi +P
REFERENCES,0.3653543307086614,"i:wi<0 wiLi +b
and M1 to −(P"
REFERENCES,0.3669291338582677,i:wi>0 wiLi + P
REFERENCES,0.36850393700787404,"i:wi<0 wiUi + b). However, despite being fast, the drawback of
this simple approach is that it does not take into account constraints on Ωor one-hot and no-good
constraints."
REFERENCES,0.3700787401574803,"In our experiments, we compute M0 and M1 by solving the linear programming (LP) relaxations
of maxx∈Ω′ w⊤x + b and maxx∈Ω′ −(w⊤x + b) respectively (i.e. without integrality constraints).
We remark that for neurons in the same layer these LPs have the same constraints but different
objectives, and thus we may take advantage of the warm starting functionality in LP solvers. While
this requires solving two LPs per neuron, taking into account the constraints from Ωinto the bounds
often enable the overall MILP to be solved much faster."
REFERENCES,0.3716535433070866,"The formulation can also be strengthened with cutting plane techniques (Anderson et al., 2020), but
they are not particularly beneﬁcial for the small network sizes considered in this paper (at most a
single layer with 16 ReLUs) and thus we do not add them. Future work could explore warm-starting
the MILP solver using results from earlier MBO iterations."
REFERENCES,0.3732283464566929,"B
BENCHMARKING TASKS"
REFERENCES,0.37480314960629924,"This section details the black-box objective functions considered in both unconstrained (Section 4.2)
and constrained (Section 4.3) experiments. Recall that all objective functions are deﬁned over ﬁxed-
length discrete vectors of length n, with each element drawn from an alphabet A of ﬁxed size."
REFERENCES,0.3763779527559055,"B.1
TFBIND"
REFERENCES,0.3779527559055118,"The objective function is given by the binding afﬁnity of a length-8 DNA sequence to a particular
transcription factor, characterized experimentally in the dataset described by Barrera et al. (2016).
The problem size is thus ﬁxed by the application at hand, with n = 8 and |A| = 4 (each input
element corresponding to a given DNA nucleotide). We min/max-normalize the binding afﬁnity
values for each factor to the zero-one interval. We create 12 unconstrained problems (Section 4.2)
using the following datasets: CRX R90W R1, CRX REF R1, FOXC1 REF R1, GFI1B REF R1,
HOXD13 Q325R R1, HOXD13 REF R1, NR1H4 C144R R1, NR1H4 REF R1, PAX4 REF R1,
PAX4 REF R2, POU6F2 REF R1, SIX6 REF R1. Here, the 3 ﬁelds separated by underscores rep-
resent the transcription factor id, any mutations that have been made to the transcription factor, and
the id of the experimental replicate used when collecting data."
REFERENCES,0.3795275590551181,Under review as a conference paper at ICLR 2022
REFERENCES,0.38110236220472443,"B.2
RANDOMMLP"
REFERENCES,0.3826771653543307,"The objective function is given by the output of a multi-layer perceptron (MLP) with randomly-
sampled weights. Different functions are generated by varying the architecture type (described
below) and random seed. All architectures employ a one-hot encoding of the inputs as the ﬁrst layer.
Weights are sampled using the default behavior of tf.keras.layers.Dense (glorot uniform)."
REFERENCES,0.384251968503937,"We consider two architecture types, both utilizing more layers/parameters than the 16-neuron net-
works used by NN+MILP (Section 4). The RandomFCC architecture uses two fully-connected lay-
ers with 128 hidden units each, while the RandomCNN architecture uses two convolutional layers
each with 64 hidden units each, a kernel width of 13 and stride size of 1. We use a linear activation
function for the output and ReLU activations for all intermediate layers."
REFERENCES,0.3858267716535433,"Unconstrained RandomMLP problems (Section 4.2) all have size n = 25 and |A| = 5 . Eight
objective functions are created by varying the architecture type (FCC or CNN) and random seed (0,
13, 42, 77). Constrained RandomMLP problems (Section 4.3) all have size n = 100 and |A| = 2.
Thirty problems are created by varying the architecture type (FCC or CNN), random seed (0, 13,
42, 77, 100) and the number of paired subsets (5, 10, 15) in the subset-equality constraints (deﬁned
in Section 4.3)."
REFERENCES,0.38740157480314963,"B.3
BBOB"
REFERENCES,0.3889763779527559,"The objective is given by a function from the continuous Black-Box Optimization Benchmarking
library (Hansen et al., 2009). All BBOB functions are deﬁned for a variable number of dimensions n
and the search domain is given as [−5, 5]n, with the global optimum centered at zero. We normalize
each function’s output range by evaluating it at 30 ﬁxed points and dividing outputs by the median
absolute deviation in those points’ values."
REFERENCES,0.3905511811023622,"We discretize functions for our setting (Section 3.1) by deﬁning a grid over the continuous search
domain, adjusted so that the optimal solution exactly corresponds to a point in the grid. Concretely,
we use a ﬁxed alphabet A = {1, . . . , m} for all coordinates, denoting the index of one of m allowed
values for that coordinate. Allowed values for each coordinate are m equally-spaced points in the
range [−5, 5], except for a point lying closest to zero which is overwritten to exactly equal that
value. In this way, the optimum is guaranteed to lie on the discretized grid. Note that, despite the
underlying continuous structure, all algorithms treat each dimension as an unordered, categorical
variable."
REFERENCES,0.3921259842519685,"For unconstrained BBOB problems (Section 4.2), we select a diverse set of objectives by taking two
functions from each of the ﬁve categories deﬁned by the BBOB library:"
REFERENCES,0.3937007874015748,"1. Separable functions: Sphere (SPHERE) and Ellipsoidal (ELLIPSOID SEPARABLE).
2. Functions
with
low
or
moderate
conditioning:
Attractive
Sector
(ATTRAC-
TIVE SECTOR) and Step Ellipsoidal (STEP ELLIPSOID).
3. Functions with high conditioning and unimodal:
Discus (DISCUS) and Bent Cigar
(BENT CIGAR).
4. Multi-modal functions with adequate global structure: Weierstrass (WEIERSTRASS) and
Schaffers F7 (SCHAFFERS F7).
5. Multi-model functions with weak global structure: Schwefel (SCHWEFEL) and Gal-
lagher’s Gaussian 21-hi Peaks (GALLAGHER 21ME)."
REFERENCES,0.3952755905511811,"We set the dimension for all of these to n = 10 and discretize as described above, using an alphabet
of size |A| = 10 for all coordinates. We purposefully use a relatively large alphabet to ensure that
the discretization does not obscure any inherent variance across a given coordinate."
REFERENCES,0.3968503937007874,"C
BASELINE OPTIMIZATION ALGORITHMS"
REFERENCES,0.3984251968503937,"In this section we describe implementation and conﬁguration details for all baseline optimization
algorithms described in Section 4."
REFERENCES,0.4,Under review as a conference paper at ICLR 2022
REFERENCES,0.4015748031496063,"C.1
NN+MILP"
REFERENCES,0.4031496062992126,"For our experiments, we implement our main algorithm (Section 3) as follows: we use a ﬁxed
surrogate model hypothesis class F of networks with a single, fully-connected hidden layer of 16
neurons. Models are trained with TensorFlow (Abadi et al., 2016), using the ADAM optimizer for
25K epochs with a batch size of 64 and no explicit regularization. We use a constant learning rate
of α = 0.01 and default decay parameters (β1, β2) = (0.9, 0.999). No hyper-parameter tuning is
performed across problems. Model training is randomized due to the random example ordering of
SGD training and random parameter initialization. The MILP acquisition problem is solved with
the Mixed-Integer Programming solver SCIP 7.0.1 (Gamrath et al., 2020) using default settings and
a time limit of 500 seconds. In order to increase the diversity of trained models, we train each model
from scratch at each iteration of optimization instead of ﬁne-tuning a model from an earlier iteration."
REFERENCES,0.4047244094488189,"C.2
REGEVO"
REFERENCES,0.4062992125984252,"We re-implement the local evolutionary search algorithm of Real et al. (2019), and extend the set
of mutation operators from just pointwise mutators to also include a crossover operation that re-
combines two parent sequences. The algorithm proposes xt+1 by selecting two parent sequences
from the existing population, recombining them and mutating them. Parents are chosen by tourna-
ment selection, taking the two best samples from a randomly-selected subset of size T of previously
sampled points. The pool from which parents can be selected is limited to the D most recently-
proposed points (referred to as the “alive population”), to avoid high-reward points from early
rounds dominating the process. The selected parent sequences are recombined by copying them
left-to-right, starting a pointer at one parent at switching reading to the other parent with a ﬁxed
cross-over probability pc after each copy. The resulting sequence is ﬁnally mutated by changing
each position to a different token from A with a ﬁxed probability pm."
REFERENCES,0.4078740157480315,"In the unconstrained experiments (Section 4.2), we use RegEvo as the outer-loop optimization al-
gorithm and set the tournament size to T = 10, the alive population size to D = 100, and the
crossover/mutation probabilities to (pc, pm) = (0.1, 0.1)."
REFERENCES,0.4094488188976378,"C.3
NN+REGEVO"
REFERENCES,0.4110236220472441,"This algorithm is an ablation of NN+MILP, with the only difference being the use of RegEvo in lieu
of MILP to solve the acquisition problem at every iteration. A surrogate neural network ˆft ∈F is
trained as in NN+MILP, and the acquisition function is a(x) = ˆft(x). The problem of selecting
xt+1 is posed as a batched optimization problem and solved by RegEvo."
REFERENCES,0.4125984251968504,"More concretely, at iteration t, the acquisition function is evaluated for all points in the existing
population Dt to generate the initial inner-loop population ˆDt := {xi, a(xi)}. This population is
iteratively extended by generating candidate proposals with RegEvo in batches of size b, and with
rewards now corresponding to the value of the acquisition function rather than the original black-
box function. That is, RegEvo generates b points by recombination/mutation of parents from ˆDt,
which are evaluated on the acquisition function and added to the inner-loop population. The process
repeats until a total of B candidates have been generated, at which point the one with the highest
acquisition function value (excluding any points already proposed) is proposed as xt+1."
REFERENCES,0.4141732283464567,"In the unconstrained experiments (Section 4.2), we use NN+RegEvo and set surrogate model hyper-
parameters exactly as in NN+MILP (Section C.1). For the inner-loop optimizer, we set the total
number of acquisition function evaluations to B = 10, 000 and batch size to b = 100. The RegEvo
optimizer’s hyper-parameters, deﬁned in Section C.2, are set to T = 20, D = 1, 000 and (pc, pm) =
(0.2, 0.01)."
REFERENCES,0.415748031496063,"C.4
ENSEMBLE+REGEVO"
REFERENCES,0.41732283464566927,"We recreate the MBO baseline of Angermueller et al. (2020). Here, surrogate modeling proceeds
by optimizing the hyper-parameters of a diverse set of regressor models through randomized search.
Regressors are trained using the scikit-learn libary (Pedregosa et al., 2011), drawing from the
following model classes (randomized search parameters are listed in parentheses):"
REFERENCES,0.4188976377952756,Under review as a conference paper at ICLR 2022
REFERENCES,0.4204724409448819,"• LassoRegressor (alpha)
• RidgeRegressor (alpha)
• RandomForestRegressor (max depth, max features, n estimators)
• LGBMRegressor (learning rate, n estimators)"
REFERENCES,0.4220472440944882,"Each model is evaluated by an explained variance score using ﬁve-fold cross validation on the train-
ing set. All models with a score ≥0.4 are used as an ensemble for the surrogate model, with
their average prediction serving as the acquisition function. The acquisition problem is solved by
batched RegEvo with a total of B = 12, 500 acquisition function evaluations and a batch size of
b = 25. The optimizer’s hyper-parameters, deﬁned in Section C.2, are set to T = 20, D = 1, 000
and (pc, pm) = (0.2, 0.01)."
REFERENCES,0.42362204724409447,"We use Ensemble+RegEvo in both the unconstrained (Section 4.2) and constrained (Section 4.3)
experiments. In the latter case, we use the algorithm as a baseline that makes use of the declarative
deﬁnition of constraints; during training of the ensemble, infeasible points are assigned a highly
negative reward (worse than any observed). In this way, the surrogate model might be expected
to implicitly model infeasibility with low predictions which should be avoided by the inner-loop
optimizer."
REFERENCES,0.4251968503937008,"C.5
RBFOPT"
REFERENCES,0.4267716535433071,"RBFOpt (Costa & Nannicini, 2018) is a black-box optimization solver for mixed-integer uncon-
strained problems (i.e. with only bound constraints) that performs competitively with respect to
other solvers of its type. It uses a Radial Basis Function as a surrogate model and includes a number
of practical enhancements. It relies on a mixed-integer nonlinear programming (MINLP) solver,
BONMIN (Bonami et al., 2008), to optimize the inner loop problems. The MINLP solver could in
theory incorporate constraints in a similar fashion as in our work, although this is not offered by the
open-source implementation (aside from manually penalizing the objective function) and we expect
it to not scale as well as a MILP solver in practice since MINLP is a signiﬁcantly more difﬁcult
problem class than MILP."
REFERENCES,0.4283464566929134,"We use RBFOpt for our unconstrained experiments (Section 4.2), using the open-source implemen-
tation available at https://github.com/coin-or/rbfopt. We leave all settings at their
defaults, including building the initial set of points. We note in particular that the API for this imple-
mentation uses an integer encoding for categorical variables (constraints are not supported, which
precludes a one-hot representation). As we note in the main text, we omit the RBFOpt results for
BBOB because RBFOpt proposes the midpoint of this integer representation (rounded down) as part
of its initialization, which is close to the optimal solution."
REFERENCES,0.42992125984251967,"C.6
CONEVO"
REFERENCES,0.431496062992126,"In Section 4.3 we introduce ConEvo, a local evolutionary search algorithm that exploits the known
combinatorial structure of the subset-equality constraints considered therein. The method selects just
a single parent sequence (using the same tournament procedure as RegEvo) and mutates it in a way
that guarantees feasibility of the child sequence. We do not implement recombination of multiple
parent sequences since they are not likely to maintain feasibility. We described the application-
speciﬁc mutator below."
REFERENCES,0.4330708661417323,"Recall that the domain encodes the selection or not of each of n items using a binary alphabet
A = {0, 1}. The items’ indices are partitioned into disjoint, equally-sized subsets S1, . . . , S2k for
some k and the constraints enforce that the number of selected items should be the same in pairs of
subsets; that is: X"
REFERENCES,0.4346456692913386,"i∈S2j−1
I{xi = 1} =
X"
REFERENCES,0.43622047244094486,"i∈S2j
I{xi = 1}
∀j ∈[k]"
REFERENCES,0.4377952755905512,"where we have used indicator notation and the original decision variables x rather the one-hot en-
coding."
REFERENCES,0.4393700787401575,Under review as a conference paper at ICLR 2022
REFERENCES,0.4409448818897638,"The mutator begins with a single parent sequence x, assumed feasible, and is given access to the item
subsets S1, . . . , S2k. Each pair of subsets (S2j−1, S2j) is mutated concurrently to create the child
sequence y, ensuring that mutations to one subset are counter-balanced by mutations to the second.
Concretely, one of the two subsets is chosen randomly to be the “independent” mutatee with equal
probability. We denote the selected subset I+, and the other subset in the pair by I−. Each position
i ∈I+ of the child sequence is ﬂipped from its parent value with some ﬁxed probability pm. We
compute c, the net number of 0-to-1 conversions in positions I+. If c is positive (i.e. there were
more 0-to-1 conversions than 1-to-0 conversions) then exactly c indices are chosen randomly from
{i ∈I−: xi = 0}, and also ﬂipped in the child. If c is negative, then −c indices are selected
randomly from {i ∈I−: xi = 1} and ﬂipped in the child. If c is zero, the positions in I−are left
unchanged in the child. As a result, the subsets S2j−1 and S2j retain exactly the same number of
selected items in the mutated sequence."
REFERENCES,0.44251968503937006,"In the constrained experiments (Section 4.3), we use ConEvo as the outer-loop optimization al-
gorithm setting the tournament size for selecting parent sequences to T = 20 and the mutation
probability to pm = 0.05."
REFERENCES,0.4440944881889764,"C.7
NN+CONEVO"
REFERENCES,0.4456692913385827,"This algorithm is an ablation of NN+MILP used in Section 4.3, with the only difference being the
use of ConEvo in lieu of MILP to solve the constrained acquisition problem at every iteration.
A surrogate neural network ˆft ∈F is trained as in NN+MILP, and the acquisition function is
a(x) = ˆft(x). Selecting xt+1 is posed as a batched optimization problem and solved by ConEvo.
The batched optimization procedure is exactly as described for NN+RegEvo (Section C.3)."
REFERENCES,0.44724409448818897,"In the constrained experiments (Section 4.3), we use NN+ConEvo and set surrogate model hyper-
parameters exactly as in NN+MILP (Section C.1). For the inner-loop optimizer, we set the total
number of acquisition function evaluations to B = 10, 000 and batch size to b = 100. The ConEvo
optimizer’s hyper-parameters, deﬁned in Section C.6, are set to T = 20 and pm = 0.05."
REFERENCES,0.44881889763779526,"C.8
NN+REJSAMPLE"
REFERENCES,0.4503937007874016,"This algorithm is an ablation of NN+MILP used in Section 4.3, with the only difference being the use
of random search in lieu of MILP to solve the constrained acquisition problem at every iteration.
A surrogate neural network ˆft ∈F is trained as in NN+MILP, and the acquisition function is
a(x) = ˆft(x)."
REFERENCES,0.4519685039370079,"To select xt+1, we ﬁrst generate B points uniformly-at-random from the constrained domain via
rejection sampling. That is, candidates are drawn uniformly at random from An and rejected if
they do no satisfy the subset equality constraints (Section 4.3). The process continues until B
feasible points have been generated, and the one with the highest observed acquisition function
value (excluding any points already proposed) is proposed as xt+1."
REFERENCES,0.45354330708661417,"In the constrained experiments (Section 4.3) we use NN+RejSample and set surrogate model hyper-
parameters exactly as in NN+MILP (Section 4). We set the number of points to generate at each
optimization step to B = 10, 000. Empirically, we observe a rejection rate of ≈91% for the subset-
equality constraints in our experiments."
REFERENCES,0.45511811023622045,"D
BINARY VS INTEGER VARIABLES"
REFERENCES,0.4566929133858268,"In this work, we focus on problems with binary domain formulations (e.g. one-hot encoding of
categorical domains), and even problems with integer variables such as the discretized BBOB are
binarized. Part of the reason is to allow no-good constraints as described in Section 3.3, but in
addition we have experimentally observed that the method performs better when using a binary
encoding instead of an integer one."
REFERENCES,0.4582677165354331,"When running this algorithm for unconstrained (bounded) integer or continuous problems, we have
informally observed that our method frequently proposes solutions where several variable values are
at either their lower bound or upper bound. As a result, our method would underexplore solutions
away from the boundary. A possible explanation for this is that feedforward ReLU networks tend"
REFERENCES,0.45984251968503936,Under review as a conference paper at ICLR 2022
REFERENCES,0.46141732283464565,"to extrapolate linearly, and thus their optima may often lie on the boundary (Xu et al., 2021). In
contrast, every feasible point of a binary problem lies on a corner of the 0-1 hypercube. A sim-
ilar observation has been made in the context of IDONE (Bliek et al., 2021), which also uses a
ReLU-based surrogate model: encoding the Rosenbrock problem using binary variables improves
the performance of the IDONE algorithm, although the opposite happens for a Bayesian optimiza-
tion algorithm (Karlsson et al., 2020)."
REFERENCES,0.462992125984252,"We provide computational evidence of this behavior in Figure 3 for TfBind and BBOB instances.
The binary variables are encoded as one-hot variables, whereas the integer variables follow an arbi-
trary ordering for TfBind and the problem ordering for BBOB."
REFERENCES,0.4645669291338583,"200
400
600
800
1000
Step 0.2 0.4 0.6 0.8 1.0"
REFERENCES,0.46614173228346456,Best Reward
REFERENCES,0.46771653543307085,"TfBind(8,4)"
REFERENCES,0.4692913385826772,"NN+MILP Binary
NN+MILP Integer"
REFERENCES,0.47086614173228347,"200
400
600
800
1000
Step 3 2 1 0"
REFERENCES,0.47244094488188976,Best Reward
REFERENCES,0.47401574803149604,"BBOB(10,10)"
REFERENCES,0.4755905511811024,"NN+MILP Binary
NN+MILP Integer"
REFERENCES,0.47716535433070867,"Figure 3: Best observed reward as a function of iteration for all TfBind (left) and BBOB (right)
instances, comparing the use of binary and integer variables. For TfBind, the categorical variables
are transformed to integer with an arbitrary ordering, and for BBOB, we use the given ordering of
the problem. Note that the error region is large here since we aggregate all of the instances of each
class."
REFERENCES,0.47874015748031495,"E
CONSTRAINED OPTIMIZATION WITH AN ISING PROBLEM"
REFERENCES,0.48031496062992124,"To provide further evidence that the results from Section 4.3 can generalize beyond the RandomMLP
function, Figure 4 shows the result for the same set of constrained experiments with the only dif-
ference that we switch the RandomMLP objective by another random function based on the Ising
model. Here, the Ising model represents a fully-connected graph with nodes that can take binary
values. Each edge is deﬁned by a 2 × 2 table of scores for each possible conﬁguration of the nodes
that are connected by the edge. Each value in the tables is drawn from a normal distribution and the
overall function is the sum of the scores over all edges. We aggregate over 10 random instances and
20 replications with different random seeds. We omit Ensemble+RegEvo with penalty as described
in Section 4.3 since it does not perform well with these constraints. We observe that the results are
qualitatively similar to those of Section 4.3: NN+MILP continues to perform signiﬁcantly better
than ConEvo, while NN+MILP and NN+ConEvo have similar performance."
REFERENCES,0.4818897637795276,"We also experiment with the same class of constrained problems but deﬁned over larger domains
(n = 200 and 400 binary decision variables). Given the larger scale, we set a single value for
the number of paired subsets in the constraints, namely k = 20 when n = 200 or k = 40 when
n = 400 (in other experiments, different values of k resulted in qualitatively similar results), and
we do not run NN+RejSample. We aggregate over 10 random instances and 10 replications for each
problem size. In Figure 5, we observe that NN+MILP signiﬁcantly outperforms NN+ConEvo for
the n = 400 instances, suggesting that it is beneﬁcial to solve the acquisition problem to optimality
at larger scales."
REFERENCES,0.48346456692913387,"Finally, in Figure 6 we examine the impact the surrogate model’s capacity in this larger-scale setting.
We include ablations of both NN+MILP and NN+ConEvo where the surrogate model has 32 neurons
in the hidden layer, instead of the 16 used before. Despite optimizing over a larger domain, neither
NN+MILP nor NN+ConEvo show substantial improvements in performance when using a larger"
REFERENCES,0.48503937007874015,Under review as a conference paper at ICLR 2022
REFERENCES,0.48661417322834644,"200
400
600
800
1000
Step 200 400 600"
REFERENCES,0.4881889763779528,Best Reward
REFERENCES,0.48976377952755906,"IsingModel(100,2)"
REFERENCES,0.49133858267716535,"NN+MILP
NN+ConEvo
NN+RejSample
ConEvo"
REFERENCES,0.49291338582677163,NN+MILP
REFERENCES,0.494488188976378,NN+ConEvo
REFERENCES,0.49606299212598426,ConEvo
REFERENCES,0.49763779527559054,NN+RejSample 0.0 0.2 0.4 0.6 0.8 1.0
REFERENCES,0.49921259842519683,Normalized Score
REFERENCES,0.5007874015748032,"Figure 4: (Left) Best observed reward as a function of iteration for random instances based on the
Ising model with the subset equality constraints described in Section 4.3. (Right) Distribution of the
algorithms’ normalized scores on the same constrained Ising model problems. Higher is better."
REFERENCES,0.5023622047244094,"surrogate network. This suggests that, in this case at least, the relatively small number of training
points is a more signiﬁcant bottleneck for approximation than the capacity of the surrogate."
REFERENCES,0.5039370078740157,"200
400
600
800
1000
Step 500 1000 1500 2000"
REFERENCES,0.5055118110236221,Best Reward
REFERENCES,0.5070866141732283,"IsingModel(200,2)"
REFERENCES,0.5086614173228347,"NN+MILP
NN+ConEvo
ConEvo"
REFERENCES,0.510236220472441,"200
400
600
800
1000
Step 1000 2000 3000 4000 5000"
REFERENCES,0.5118110236220472,Best Reward
REFERENCES,0.5133858267716536,"IsingModel(400,2)"
REFERENCES,0.5149606299212598,"NN+MILP
NN+ConEvo
ConEvo"
REFERENCES,0.5165354330708661,"Figure 5: Best observed reward as a function of iteration for random instances based on the Ising
model with 200 (left) and 400 (right) binary variables and the subset equality constraints described
in Section 4.3, except that the number of pairs of subsets is k = 20 (left) and k = 40 (right)."
REFERENCES,0.5181102362204725,"F
CONSTRAINED BINARY QUADRATIC PROBLEMS FROM MINLPLIB"
REFERENCES,0.5196850393700787,"We study the performance of our method for linearly-constrained binary quadratic problems from
the MINLPLib benchmark library (Vigerske, 2021). In practice, one would use a specialized mixed-
integer quadratic programming solver to tackle these problems, but they serve well as a bench-
mark for our black-box optimization method since they are still harder to solve than MILP and
include practically-motivated constraints, along with offering good feasible solutions to compare
with. Many of these instances are of a slightly larger scale than typical black-box optimization
problems (i.e. a few hundreds of variables), which helps us evaluate the method at larger scale and
observe its scalability limitations."
REFERENCES,0.521259842519685,"We select the instances of type “BQP” from MINLPLib with at least one constraint. We discard the
11 instances preﬁxed by celar6-sub0, color lab, and max csp, which are large instances
for which our method was unable to ﬁnd a solution with primal gap at most 10% (see below). This"
REFERENCES,0.5228346456692914,Under review as a conference paper at ICLR 2022
REFERENCES,0.5244094488188976,"200
400
600
800
1000
Step 500 1000 1500 2000"
REFERENCES,0.525984251968504,Best Reward
REFERENCES,0.5275590551181102,"IsingModel(200,2)"
REFERENCES,0.5291338582677165,"NN+MILP - FC(16)
NN+ConEvo - FC(16)
NN+MILP - FC(32)
NN+ConEvo - FC(32)
ConEvo"
REFERENCES,0.5307086614173229,"200
400
600
800
1000
Step 1000 2000 3000 4000 5000"
REFERENCES,0.5322834645669291,Best Reward
REFERENCES,0.5338582677165354,"IsingModel(400,2)"
REFERENCES,0.5354330708661418,"NN+MILP - FC(16)
NN+ConEvo - FC(16)
NN+MILP - FC(32)
NN+ConEvo - FC(32)
ConEvo"
REFERENCES,0.537007874015748,"Figure 6: Best observed reward as a function of iteration for random instances based on the Ising
model with 200 (left) and 400 (right) binary variables and the subset equality constraints described
in Section 4.3, except that the number of pairs of subsets is restricted to k = 10. FC(16) and
FC(32) represent the runs where the surrogate neural network has a single layer of 16 and 32 ReLUs
respectively."
REFERENCES,0.5385826771653544,"leaves us with the 50 instances listed in Table 1. For consistency with the remainder of the paper,
we turn the problems into maximization problems by negating the objective function."
REFERENCES,0.5401574803149606,"We run NN+MILP with the same settings as previous experiments (see Appendix C.1). One dif-
ference here is that the feasible set may be too small to sample from using rejection sampling.
Therefore, we build our initial set of 50 points by randomly choosing an objective direction and
solving an MILP under the constraints of the problem, which is practically feasible since the scale
of these problems is small in the context of MILP. In our experiments, we compare with the best
known primal feasible solution from the MINLPLib benchmark itself (as of October 1, 2021)."
REFERENCES,0.5417322834645669,"Out of the 20 runs for each instance, we show in Table 1 the number of runs that found a solution
in 1000 steps with value equal to the best known value from MINLPLib, or with a primal gap of
at most 1% or 10% with respect to that value. We use the deﬁnition of primal gap from Berthold
(2013): if v∗is the best known value and v is the objective value given by our method, then the
primal gap is
|v−v∗|
max(|v|,|v∗|), or 0 if |v| = |v∗| = 0, or 1 if v and v∗have different signs."
REFERENCES,0.5433070866141733,"Interestingly, in 20 out of the 50 instances, we match the best known objective value in at least
one of the runs. This includes a number of instances that are considered to be large for black-
box optimization, such as the general quadratic assignment problem pb302095 which has 600
variables."
REFERENCES,0.5448818897637795,"On the other hand, we also observe that the method has difﬁculties in ﬁnding a good solution for
larger instances. This is more clearly illustrated by Figure 7, in which we observe how the method
scales with the graph partitioning problems denoted by graphpart clique. For the smaller
instance (with 60 variables), our method ﬁnds an optimal solution in relatively few steps, but it has
difﬁculties in reaching the best known solution for the larger instance (with 180 variables) with the
same constraint structure. That said, this does not mean that this method cannot be extended to scale
further (e.g. we have not attempted to tune the parameters or change the architecture of the surrogate
model for larger instances)."
REFERENCES,0.5464566929133858,"G
NAS-BENCH-101 CASE STUDY"
REFERENCES,0.5480314960629922,"G.1
BACKGROUND"
REFERENCES,0.5496062992125984,"In Section 5 we consider the NAS-Bench-101 (Ying et al., 2019) neural architecture search (NAS)
benchmark as a case study, to illustrate the power of MILP’s declarative constraint language in
modeling complex combinatorial domains. The optimization domain consists of directed acyclic"
REFERENCES,0.5511811023622047,Under review as a conference paper at ICLR 2022
REFERENCES,0.552755905511811,"Table 1: Results for a subset of binary quadratic problems from the MINLPLib benchmark, indi-
cating the number of runs out of 20 for which the primal gap with respect to the best known primal
feasible solution is at most 0%, 1%, and 10%."
REFERENCES,0.5543307086614173,"Number of runs with solution at
Instance name
# variables
0% gap
≤1% gap
≤10% gap
cardqp inlp
50
5
14
20
cardqp iqp
50
5
14
20
crossdock 15x7
210
0
0
20
crossdock 15x8
240
0
0
20
graphpart 2g-0044-1601
48
17
17
20
graphpart 2g-0055-0062
75
0
2
19
graphpart 2g-0066-0066
108
0
0
17
graphpart 2g-0077-0077
147
0
0
7
graphpart 2g-0088-0088
192
0
0
7
graphpart 2g-0099-9211
243
0
0
2
graphpart 2g-1010-0824
300
0
0
0
graphpart 2pm-0044-0044
48
20
20
20
graphpart 2pm-0055-0055
75
13
13
20
graphpart 2pm-0066-0066
108
6
6
15
graphpart 2pm-0077-0777
147
0
0
7
graphpart 2pm-0088-0888
192
0
0
5
graphpart 2pm-0099-0999
243
0
0
3
graphpart 3g-0234-0234
72
0
4
18
graphpart 3g-0244-0244
96
0
1
17
graphpart 3g-0333-0333
81
4
4
19
graphpart 3g-0334-0334
108
0
0
16
graphpart 3g-0344-0344
144
0
1
8
graphpart 3g-0444-0444
192
0
0
8
graphpart 3pm-0234-0234
72
7
7
19
graphpart 3pm-0244-0244
96
0
0
17
graphpart 3pm-0333-0333
81
1
1
15
graphpart 3pm-0334-0334
108
0
0
11
graphpart 3pm-0344-0344
144
0
0
5
graphpart 3pm-0444-0444
192
0
0
6
graphpart clique-20
60
20
20
20
graphpart clique-30
90
20
20
20
graphpart clique-40
120
13
13
18
graphpart clique-50
150
0
0
0
graphpart clique-60
180
0
0
0
graphpart clique-70
210
0
0
0
pb302035
600
0
0
0
pb302055
600
0
0
20
pb302075
600
5
5
20
pb302095
600
13
20
20
pb351535
525
0
0
15
pb351555
525
1
3
20
pb351575
525
0
10
20
pb351595
525
6
19
20
qap
225
0
0
7
qspp 0 10 0 1 10 1
180
5
5
20
qspp 0 11 0 1 10 1
220
9
20
20
qspp 0 12 0 1 10 1
264
13
13
20
qspp 0 13 0 1 10 1
312
0
19
20
qspp 0 14 0 1 10 1
364
0
16
20
qspp 0 15 0 1 10 1
420
12
13
20"
REFERENCES,0.5559055118110237,Under review as a conference paper at ICLR 2022
REFERENCES,0.5574803149606299,"0
200
400
600
800
1000
Step 350 300 250 200 150"
REFERENCES,0.5590551181102362,Best Observed Reward
REFERENCES,0.5606299212598426,graphpart_clique-20
REFERENCES,0.5622047244094488,"NN+MILP
Optimal Value"
REFERENCES,0.5637795275590551,"0
200
400
600
800
1000
Step 3000 2500 2000 1500 1000"
REFERENCES,0.5653543307086614,Best Observed Reward
REFERENCES,0.5669291338582677,graphpart_clique-40
REFERENCES,0.568503937007874,"NN+MILP
Optimal Value"
REFERENCES,0.5700787401574803,"0
200
400
600
800
1000
Step 10000 8000 6000 4000"
REFERENCES,0.5716535433070866,Best Observed Reward
REFERENCES,0.573228346456693,graphpart_clique-60
REFERENCES,0.5748031496062992,"NN+MILP
Best Known Value"
REFERENCES,0.5763779527559055,"Figure 7: Best observed reward as function of iteration for three graph partitioning instances from
MINLPLib (negated for maximization), with 60, 120, and 180 binary variables respectively. Black
lines show the best known feasible solution to the problem (as of October 1, 2021). Colored lines
show the average over 20 trials, while bands indicate ±1 sd. Note that bands that exceed the black
line are an artifact of the symmetric nature of standard deviation, and do not necessarily mean a trial
found an improved solution."
REFERENCES,0.5779527559055118,"graphs (DAGs) with a maximum of V = 7 nodes and M = 9 edges, representing the cell in a neural
architecture. The overall model is obtained by stacking multiple copies of the cell. Two nodes
represent the input and output, and must be connected by a directed path, while the remaining nodes
are each assigned to be 1x1 convolution, 3x3 convolution, or 3x3 max-pooling. Edges specify the
ﬂow of activations between nodes. The goal is to ﬁnd the cell architecture that maximizes out-of-
sample accuracy on a given image classiﬁcation task."
REFERENCES,0.5795275590551181,"NAS differs from the problem setting in Section 3.1 in three key ways. First, algorithms do not
have access to the true objective (out-of-sample accuracy), but instead a correlated proxy (validation
accuracy). Second, f(x) is noisy due to the stochasticity of classiﬁer training, and thus algorithms
may beneﬁt from repeated queries of the same point. Finally, algorithms may beneﬁt by leveraging
the validation accuracy at early epochs as a proxy to halt unpromising evaluations."
REFERENCES,0.5811023622047244,"Despite these differences, we apply NN+MILP exactly as described in Section 3/Appendix C.1
(including no-good constraints which prevent repeated queries). We reimplement the Regularized
Evolution (RE) and random search (RS) baselines from the original NAS-Bench-101 paper (Ying
et al., 2019), using the same hyper-parameters settings speciﬁed therein."
REFERENCES,0.5826771653543307,"The NAS-Bench-101 dataset contains pre-computed validation and test accuracies for three inde-
pendently trained replications of each architecture, as well as the training time of each. To simulate
NAS, algorithms’ observed reward after proposing an architecture is the validation accuracy of a
randomly sampled replication from said architecture. This deﬁnes the notion of an “incumbent”
proposal, namely the proposed architecture with the highest (observed) validation accuracy, which
may not in fact be the best (unobserved) test accuracy. Instead of allowing algorithms a ﬁxed bud-
get of evaluations, we use a ﬁxed budget of T = 5 × 106 seconds, and allow algorithms to query
the objective until cumulative training time exceeds the budget. For evaluation purposes (e.g. Fig-
ure 2c) we plot the out-of-sample accuracy of the incumbent architecture as a function of cumulative
architecture training time."
REFERENCES,0.584251968503937,"G.2
DOMAIN FORMULATION"
REFERENCES,0.5858267716535434,"To formulate the NAS-Bench-101 domain, we ﬁrst deﬁne a representation of cell architectures as
ﬁxed-length binary vectors. We split the representation into two components; one set of variables
encodes the presence or absence of each graph edge, while the second is a one-hot encoding of
nodes’ assigned operations. As all valid cell graphs are directed and acyclic, we limit the edge
variables to the strict upper triangle of the adjacency matrix, which implicitly enforces a topological
ordering of the nodes in any feasible solution and ensures acyclicity. The ﬁrst- and last-indexed
nodes are always assigned the input and output operations respectively, while intermediates
nodes can be assigned any operation from the set S = {conv1x1, conv3x3, maxpool3x3}."
REFERENCES,0.5874015748031496,"To ensure a ﬁxed-length set of decision variables while allowing for graphs with a variable number
of nodes, we introduce a new null operation. Nodes assigned the null operation are not considered
part of the computational graph of the cell. The algorithm then searches over the space of binary"
REFERENCES,0.5889763779527559,Under review as a conference paper at ICLR 2022
REFERENCES,0.5905511811023622,"representations, constrained to yield feasible cell architectures. Denoting by V and M the maximum
number of allowable nodes and edges respectively, the decision variables (all binary) are:"
REFERENCES,0.5921259842519685,"• mi,j for 1 ≤i < j ≤V , 1 if there is an edge from node i to node j, 0 otherwise."
REFERENCES,0.5937007874015748,"• wi,k for 1 ≤i ≤V, 1 ≤k ≤|S|, 1 if node i is assigned the k’th operation in S, 0
otherwise."
REFERENCES,0.5952755905511811,"• zi for 1 < i < V , 1 if node i is assigned the null operation,0 otherwise."
REFERENCES,0.5968503937007874,The feasible set of cell architectures can then be given in terms of linear constraints as follows:
REFERENCES,0.5984251968503937,"w1,k = wV,k = z1 = zV = 0
for 1 ≤k ≤|S|
(1) zi + S
X"
REFERENCES,0.6,"k=1
wi,k = 1
for 1 < i < V
(2) V
X i=1 V
X"
REFERENCES,0.6015748031496063,"j=i+1
mi,j ≤M
(3)"
REFERENCES,0.6031496062992125,"mi,j ≤1 −zj
for 1 ≤i < j ≤V
(4)
mi,j ≤1 −zi
for 1 ≤i < j ≤V
(5) j−1
X"
REFERENCES,0.6047244094488189,"i=1
mi,j ≥1 −zj
for 1 ≤j ≤V
(6) V
X"
REFERENCES,0.6062992125984252,"j=i+1
mi,j ≥1 −zi
for 1 ≤i ≤V
(7)"
REFERENCES,0.6078740157480315,"zi ≤zi+1
for 1 < i < V −1
(8)"
REFERENCES,0.6094488188976378,"Constraints 1 ensure that the input and output nodes are not assigned any operation from S or null,
while 2 enforces the one-hot encoding of operations for intermediate nodes (including the possibility
of a null operation). Constraint 3 imposes a limit on the number of edges in the graph, per the NAS-
Bench-101 speciﬁcations. Constraints 4 & 5 assert that null nodes have no incoming or outgoing
edges respectively, effectively disconnecting them from the remaining graph. Conversely, 6 & 7
assert that non-null nodes have at least one ingoing and one outgoing edge. Crucially, due to the
implicit topological sorting of nodes by the upper-triangular adjacency matrix, these also ensure that
there is always a path from the input to the output node using only non-null nodes. Intuitively, all
non-null nodes (including the input) have at least one outgoing edge – which necessarily leads to
a higher-indexed non-null node – and all non-null nodes (including the output) have at least one-
incoming edge – which necessarily comes from a lower-indexed non-null node. The ﬂow exiting the
input node, must eventually enter the output node."
REFERENCES,0.6110236220472441,"Finally, we focus on Constraints 8, which we refer to as symmetry-breaking constraints. These assert
that a node can only be assigned the null operation if its topological successor has also been assigned
it. While not necessary for feasibility, this constraint serves to eliminate symmetry by ensuring
that all null nodes are topologically sorted after any non-null nodes. In essence, it introduces a
“canonical” labeling of null vs. non-null nodes, whose isomorphic representations are excluded
from the feasible region."
REFERENCES,0.6125984251968504,"In our experiments, we found that including symmetry-breaking constraints actually resulted in
worse overall performance for the outer optimization problem (Figure 2c). We hypothesize that this
is due to a reduction in the exploration behaviour of NN+MILP, as the surrogate’s predictive distri-
bution was more uncertain in the larger search space and the inner-loop optimizer thus more likely
to propose points in unexplored areas. One possible future line of work could be to augment Dt with
isomorphic representations before training, e.g. by random reordering of nodes in the representations
of sampled points."
REFERENCES,0.6141732283464567,Under review as a conference paper at ICLR 2022
REFERENCES,0.6157480314960629,"H
ADDITIONAL PLOTS"
REFERENCES,0.6173228346456693,We present in this section additional ﬁgures related to the experiments in the main text.
REFERENCES,0.6188976377952756,"H.1
UNCONSTRAINED OPTIMIZATION"
REFERENCES,0.6204724409448819,NN+RegEvo
REFERENCES,0.6220472440944882,NN+MILP
REFERENCES,0.6236220472440945,Ensemble+RegEvo
REFERENCES,0.6251968503937008,RegEvo 0.00 0.25 0.50 0.75 1.00
REFERENCES,0.6267716535433071,Normalized Score
REFERENCES,0.6283464566929133,"BBOB(10,10)"
REFERENCES,0.6299212598425197,NN+MILP
REFERENCES,0.631496062992126,NN+RegEvo
REFERENCES,0.6330708661417322,Ensemble+RegEvo
REFERENCES,0.6346456692913386,RegEvo 0.00 0.25 0.50 0.75 1.00
REFERENCES,0.6362204724409449,Normalized Score
REFERENCES,0.6377952755905512,"RandomMLP(25,5)"
REFERENCES,0.6393700787401575,Ensemble+RegEvo
REFERENCES,0.6409448818897637,NN+MILP
REFERENCES,0.6425196850393701,NN+RegEvo
REFERENCES,0.6440944881889764,RegEvo 0.00 0.25 0.50 0.75 1.00
REFERENCES,0.6456692913385826,Normalized Score
REFERENCES,0.647244094488189,"TfBind(8,4)"
REFERENCES,0.6488188976377953,"Figure 8: Distribution of algorithms’ normalized AUC scores (Section H.1) on unconstrained prob-
lems split by objective function class. Higher is better. Relative performance of algorithms in terms
of AUC is similar as best-observed reward (Figure 1)."
REFERENCES,0.6503937007874016,"While the best observed reward in DN (i.e. after all evaluations) is the primary metric of comparison
for algorithms per Section 3.1, it is also instructive to consider a measure of how fast algorithms
converge to their best observed reward. To this end, we deﬁne an AUC metric that computes the area
under the best observed reward curve; higher values indicate that an algorithm found better points
in earlier iterations. To faciliate comparison across problems, we min/max normalize algorithms’
AUC scores within each problem exactly as we did for the best observed reward (Section 4.1). That
is, the best (resp. worst) on-average algorithm in terms of AUC is assigned a score of one (resp.
zero) and intermediate values express relative distance from these extremes."
REFERENCES,0.6519685039370079,"Figure 8 plots the distribution of algorithms’ AUC scores over all unconstrained problems, split
by objective function class. The relative performance of algorithms in terms of this new AUC
metric does not differ signiﬁcantly from what we found for ﬁnal reward (Section 4.2, Figure 1).
Figures 11 and 12 plot the individual reward curves as function of outer-loop iteration for each
unconstrained problem."
REFERENCES,0.6535433070866141,"H.2
CONSTRAINED OPTIMIZATION"
REFERENCES,0.6551181102362205,"In Figure 9 we plot the distribution of algorithms’ normalized ﬁnal reward scores across all con-
strained problems from Section 4.3 (paralleling Figure 1, top). The individual reward curves for all
such problems can be found in Figures 13 and 14, which did not differ signiﬁcantly."
REFERENCES,0.6566929133858268,NN+MILP
REFERENCES,0.658267716535433,NN+ConEvo
REFERENCES,0.6598425196850394,ConEvo
REFERENCES,0.6614173228346457,NN+RejSample 0.0 0.2 0.4 0.6 0.8 1.0
REFERENCES,0.662992125984252,Normalized Score
REFERENCES,0.6645669291338583,"Figure 9: Distribution of algorithms’ normalized scores (Section 4.1) on constrained problems.
Higher is better. NN+MILP and NN+ConEvo perform similarly across all problems. Reward pro-
gression on individual problems can be found in Figure 13 and 14."
REFERENCES,0.6661417322834645,Under review as a conference paper at ICLR 2022
REFERENCES,0.6677165354330709,"H.3
PRACTICALITY OF MILP"
REFERENCES,0.6692913385826772,"Table 2: Distribution of per-step MILP inner-optimization solve times in seconds for TfBind8 bench-
marks when using different surrogate network architectures. The Network column denotes the num-
ber of ReLUs in each fully-connected hidden layer. Runs were given a time limit (TL) of 300s. (*)
means that the time limit was hit."
REFERENCES,0.6708661417322834,"Network
min
med
95%
99%
max
%TL
Linear
0.004
0.4
1.4
2.9
16.9
0%
FC(16)
0.02
2.2
8.0
15.5
60.8
0%
FC(32)
0.04
11.7
49.2
85.5
300*
0.1%
FC(16,16)
0.40
12.2
55.6
109.1
300*
2.1%"
REFERENCES,0.6724409448818898,"Here we present experiments to explore the impact of surrogate network size on MILP solve times.
We varied NN+MILP’s surrogate network architecture using fully-connected networks with different
numbers of hidden layers and neurons, FC(16), FC(32), FC(16,16), as well as a simple Linear model
(no hidden layer). Note that the ﬁrst architecture, FC(16), was what was presented in the main
results. Otherwise, we used the same training and optimization hyper-parameters for NN+MILP as
described in Section C.1. We ran this experiment on all 12 unconstrained TfBind problems from
Section 4.2, with 20 trials using different random initial data sets."
REFERENCES,0.6740157480314961,"Table 2 shows aggregate distribution statistics of inner-loop optimization runtime for the different
architectures, across all steps of all trials of all problems. We note that solve times increase as
the network size increases, but even for the largest network (two layers with 16 neurons each), the
solver rarely times out and almost always terminates within a practical time limit. Furthermore, for
larger networks we can improve scaling using advanced formulation techniques (e.g. Appendix A).
We also note that, in these experiments, there was no single architecture that consistently produced
better optimization across different instances (though Linear was almost always outperformed by
the rest)."
REFERENCES,0.6755905511811023,"We also include Figure 10 which plots the distribution of MILP inner-loop solver runtimes for all
constrained and unconstrained problems as a function of outer-loop iteration (paralleling Figure 2b
which included only TfBind). As noted in Section 4.4, the relationship between problem size and
runtime can be unpredictable. For example, the lower-dimensional TfBind problems showed the
highest mean and variance in MILP inner-loop solve times among all constrained and unconstrained
objective classes. Encouragingly, across all problem classes we observe only a linear (roughly)
increase in solve time per iteration, presumably due to the increasing number of no-good constraints."
REFERENCES,0.6771653543307087,"0
200
400
600
800
Step 0 5 10 15 20"
REFERENCES,0.6787401574803149,MILP Solve Time (s)
REFERENCES,0.6803149606299213,"BBOB(10,10)"
REFERENCES,0.6818897637795276,"0
200
400
600
800
Step 0 5 10 15 20"
REFERENCES,0.6834645669291338,MILP Solve Time (s)
REFERENCES,0.6850393700787402,"RandomMLP(25,5)"
REFERENCES,0.6866141732283465,"0
200
400
600
800
Step 0 5 10 15 20"
REFERENCES,0.6881889763779527,MILP Solve Time (s)
REFERENCES,0.6897637795275591,"TfBind(8,4)"
REFERENCES,0.6913385826771653,"0
200
400
600
800
Step 0 5 10 15 20"
REFERENCES,0.6929133858267716,MILP solver runtime (s)
REFERENCES,0.694488188976378,"ConstrainedRandomMLP(100,2)"
REFERENCES,0.6960629921259842,"Figure 10: Distribution of MILP acquisition problem solve times as a function of iteration split
by objective class for unconstrained problems (Section 4.2) and for all constrained problems (Sec-
tion 4.3). Line and bands show the median and 5th/95th percentile range over all trials of all prob-
lems in a class."
REFERENCES,0.6976377952755906,Under review as a conference paper at ICLR 2022
REFERENCES,0.6992125984251969,"0
200
400
600
800
1000
Step 0.15 0.10 0.05 0.00"
REFERENCES,0.7007874015748031,Best Reward
REFERENCES,0.7023622047244095,"BBOB(10,10)_ATTRACTIVE_SECTOR"
REFERENCES,0.7039370078740157,"0
200
400
600
800
1000
Step 0.6 0.4 0.2 0.0"
REFERENCES,0.705511811023622,Best Reward
REFERENCES,0.7070866141732284,"BBOB(10,10)_BENT_CIGAR"
REFERENCES,0.7086614173228346,"0
200
400
600
800
1000
Step 1.5 1.0 0.5 0.0"
REFERENCES,0.710236220472441,Best Reward
E,0.7118110236220473,"1e
5 BBOB(10,10)_DISCUS"
E,0.7133858267716535,"0
250
500
750
1000
Step 0.100 0.075 0.050 0.025 0.000 0.025"
E,0.7149606299212599,Best Reward
E,0.7165354330708661,"BBOB(10,10)_ELLIPSOID_SEPARABLE"
E,0.7181102362204724,"0
200
400
600
800
1000
Step 4 3 2 1 0"
E,0.7196850393700788,Best Reward
E,0.721259842519685,"BBOB(10,10)_GALLAGHER_21ME"
E,0.7228346456692913,"0
200
400
600
800
1000
Step 1.00 0.75 0.50 0.25 0.00"
E,0.7244094488188977,Best Reward
E,0.7259842519685039,"BBOB(10,10)_SCHAFFERS_F7"
E,0.7275590551181103,"0
200
400
600
800
1000
Step 0.6 0.4 0.2 0.0"
E,0.7291338582677165,Best Reward
E,0.7307086614173228,"BBOB(10,10)_SCHWEFEL"
E,0.7322834645669292,"0
200
400
600
800
1000
Step 0.8 0.6 0.4 0.2 0.0"
E,0.7338582677165354,Best Reward
E,0.7354330708661417,"BBOB(10,10)_SPHERE"
E,0.7370078740157481,"0
200
400
600
800
1000
Step 0.3 0.2 0.1 0.0"
E,0.7385826771653543,Best Reward
E,0.7401574803149606,"BBOB(10,10)_STEP_ELLIPSOID"
E,0.7417322834645669,"0
200
400
600
800
1000
Step 4 3 2 1 0"
E,0.7433070866141732,Best Reward
E,0.7448818897637796,"BBOB(10,10)_WEIERSTRASS"
E,0.7464566929133858,"0
200
400
600
800
1000
Step 0.0 0.5 1.0 1.5"
E,0.7480314960629921,Best Reward
E,0.7496062992125985,"RandomCNN(25,5)_seed=0"
E,0.7511811023622047,"0
200
400
600
800
1000
Step 2.0 2.5 3.0 3.5"
E,0.752755905511811,Best Reward
E,0.7543307086614173,"RandomCNN(25,5)_seed=13"
E,0.7559055118110236,"0
200
400
600
800
1000
Step 1.0 1.5 2.0 2.5"
E,0.75748031496063,Best Reward
E,0.7590551181102362,"RandomCNN(25,5)_seed=42"
E,0.7606299212598425,"0
200
400
600
800
1000
Step 1.0 1.5 2.0 2.5 3.0"
E,0.7622047244094489,Best Reward
E,0.7637795275590551,"RandomCNN(25,5)_seed=77"
E,0.7653543307086614,"0
200
400
600
800
1000
Step 0.5 1.0 1.5 2.0 2.5"
E,0.7669291338582677,Best Reward
E,0.768503937007874,"RandomFCN(25,5)_seed=0"
E,0.7700787401574803,"NN+MILP
NN+RegEvo
RegEvo
Ensemble+RegEvo
RBFOpt"
E,0.7716535433070866,"Figure 11: Best observed reward as a function of iteration for the ﬁrst half of all unconstrained
problems (Section 4.2), averaged over 20 iterations (bands indicate ±1sd). Dashed grey lines in the
ﬁrst 50 steps indicate the initial randomly sampled dataset, common to all methods except RBFOpt,
which performs its own initialization."
E,0.7732283464566929,Under review as a conference paper at ICLR 2022
E,0.7748031496062993,"0
200
400
600
800
1000
Step 1 2 3 4"
E,0.7763779527559055,Best Reward
E,0.7779527559055118,"RandomFCN(25,5)_seed=13"
E,0.7795275590551181,"0
200
400
600
800
1000
Step 0.5 1.0 1.5 2.0 2.5 3.0"
E,0.7811023622047244,Best Reward
E,0.7826771653543307,"RandomFCN(25,5)_seed=42"
E,0.784251968503937,"0
200
400
600
800
1000
Step 1.0 1.5 2.0 2.5 3.0"
E,0.7858267716535433,Best Reward
E,0.7874015748031497,"RandomFCN(25,5)_seed=77"
E,0.7889763779527559,"0
200
400
600
800
1000
Step 0.6 0.7 0.8 0.9 1.0"
E,0.7905511811023622,Best Reward
E,0.7921259842519685,"TfBind(8,4)_CRX_R90W_R1"
E,0.7937007874015748,"0
200
400
600
800
1000
Step 0.2 0.4 0.6 0.8 1.0"
E,0.7952755905511811,Best Reward
E,0.7968503937007874,"TfBind(8,4)_CRX_REF_R1"
E,0.7984251968503937,"0
200
400
600
800
1000
Step 0.5 0.6 0.7 0.8 0.9 1.0"
E,0.8,Best Reward
E,0.8015748031496063,"TfBind(8,4)_FOXC1_REF_R1"
E,0.8031496062992126,"0
200
400
600
800
1000
Step 0.7 0.8 0.9 1.0"
E,0.8047244094488188,Best Reward
E,0.8062992125984252,"TfBind(8,4)_GFI1B_REF_R1"
E,0.8078740157480315,"0
200
400
600
800
1000
Step 0.4 0.6 0.8 1.0"
E,0.8094488188976378,Best Reward
E,0.8110236220472441,"TfBind(8,4)_HOXD13_Q325R_R1"
E,0.8125984251968504,"0
200
400
600
800
1000
Step 0.4 0.6 0.8 1.0"
E,0.8141732283464567,Best Reward
E,0.815748031496063,"TfBind(8,4)_HOXD13_REF_R1"
E,0.8173228346456692,"0
200
400
600
800
1000
Step 0.7 0.8 0.9 1.0"
E,0.8188976377952756,Best Reward
E,0.8204724409448819,"TfBind(8,4)_NR1H4_C144R_R1"
E,0.8220472440944881,"0
200
400
600
800
1000
Step 0.00 0.25 0.50 0.75 1.00"
E,0.8236220472440945,Best Reward
E,0.8251968503937008,"TfBind(8,4)_NR1H4_REF_R1"
E,0.8267716535433071,"0
200
400
600
800
1000
Step 0.2 0.4 0.6 0.8 1.0"
E,0.8283464566929134,Best Reward
E,0.8299212598425196,"TfBind(8,4)_PAX4_REF_R1"
E,0.831496062992126,"0
200
400
600
800
1000
Step 0.2 0.4 0.6 0.8 1.0"
E,0.8330708661417323,Best Reward
E,0.8346456692913385,"TfBind(8,4)_PAX4_REF_R2"
E,0.8362204724409449,"0
200
400
600
800
1000
Step 0.4 0.6 0.8 1.0"
E,0.8377952755905512,Best Reward
E,0.8393700787401575,"TfBind(8,4)_POU6F2_REF_R1"
E,0.8409448818897638,"0
200
400
600
800
1000
Step 0.2 0.4 0.6 0.8 1.0"
E,0.84251968503937,Best Reward
E,0.8440944881889764,"TfBind(8,4)_SIX6_REF_R1"
E,0.8456692913385827,"NN+MILP
NN+RegEvo
RegEvo
Ensemble+RegEvo
RBFOpt"
E,0.8472440944881889,"Figure 12: Best observed reward as a function of iteration for the second half of all unconstrained
problems (Section 4.2), averaged over 20 iterations (bands indicate ±1sd). Dashed grey lines in the
ﬁrst 50 steps indicate the initial randomly sampled dataset, common to all methods except RBFOpt,
which performs its own initialization."
E,0.8488188976377953,Under review as a conference paper at ICLR 2022
E,0.8503937007874016,"200
400
600
800
1000
Step 0 1 2 3"
E,0.8519685039370078,Best Reward
E,0.8535433070866142,"RandomCNN(100,2)_seed=0_k=5"
E,0.8551181102362204,"200
400
600
800
1000
Step 0 1 2 3"
E,0.8566929133858268,Best Reward
E,0.8582677165354331,"RandomCNN(100,2)_seed=0_k=10"
E,0.8598425196850393,"200
400
600
800
1000
Step 0 1 2 3"
E,0.8614173228346457,Best Reward
E,0.862992125984252,"RandomCNN(100,2)_seed=0_k=25"
E,0.8645669291338582,"200
400
600
800
1000
Step 3 4 5 6"
E,0.8661417322834646,Best Reward
E,0.8677165354330708,"RandomCNN(100,2)_seed=13_k=5"
E,0.8692913385826772,"200
400
600
800
1000
Step 3 4 5 6"
E,0.8708661417322835,Best Reward
E,0.8724409448818897,"RandomCNN(100,2)_seed=13_k=10"
E,0.8740157480314961,"200
400
600
800
1000
Step 3 4 5"
E,0.8755905511811024,Best Reward
E,0.8771653543307086,"RandomCNN(100,2)_seed=13_k=25"
E,0.878740157480315,"200
400
600
800
1000
Step 1 2 3 4"
E,0.8803149606299212,Best Reward
E,0.8818897637795275,"RandomCNN(100,2)_seed=42_k=5"
E,0.8834645669291339,"200
400
600
800
1000
Step 1 2 3 4"
E,0.8850393700787401,Best Reward
E,0.8866141732283465,"RandomCNN(100,2)_seed=42_k=10"
E,0.8881889763779528,"200
400
600
800
1000
Step 1 2 3"
E,0.889763779527559,Best Reward
E,0.8913385826771654,"RandomCNN(100,2)_seed=42_k=25"
E,0.8929133858267716,"200
400
600
800
1000
Step 1 2 3 4"
E,0.8944881889763779,Best Reward
E,0.8960629921259843,"RandomCNN(100,2)_seed=77_k=5"
E,0.8976377952755905,"200
400
600
800
1000
Step 2 3 4"
E,0.8992125984251969,Best Reward
E,0.9007874015748032,"RandomCNN(100,2)_seed=77_k=10"
E,0.9023622047244094,"200
400
600
800
1000
Step 2 3 4"
E,0.9039370078740158,Best Reward
E,0.905511811023622,"RandomCNN(100,2)_seed=77_k=25"
E,0.9070866141732283,"200
400
600
800
1000
Step 1 2 3 4 5"
E,0.9086614173228347,Best Reward
E,0.9102362204724409,"RandomCNN(100,2)_seed=100_k=5"
E,0.9118110236220472,"200
400
600
800
1000
Step 1 2 3 4 5"
E,0.9133858267716536,Best Reward
E,0.9149606299212598,"RandomCNN(100,2)_seed=100_k=10"
E,0.9165354330708662,"200
400
600
800
1000
Step 1 2 3 4"
E,0.9181102362204724,Best Reward
E,0.9196850393700787,"RandomCNN(100,2)_seed=100_k=25"
E,0.9212598425196851,"NN+MILP
NN+ConEvo
NN+RejSample
ConEvo
Ensemble+RegEvo"
E,0.9228346456692913,"Figure 13: Best observed reward as a function of iteration for the ﬁrst half of all constrained prob-
lems (Section 4.3), averaged over 20 iterations (bands indicate ±1sd). Initial randomly sampled set
of 50 points is omitted."
E,0.9244094488188976,Under review as a conference paper at ICLR 2022
E,0.925984251968504,"200
400
600
800
1000
Step 1 2 3"
E,0.9275590551181102,Best Reward
E,0.9291338582677166,"RandomFCN(100,2)_seed=0_k=5"
E,0.9307086614173228,"200
400
600
800
1000
Step 1 2 3"
E,0.9322834645669291,Best Reward
E,0.9338582677165355,"RandomFCN(100,2)_seed=0_k=10"
E,0.9354330708661417,"200
400
600
800
1000
Step 0.5 1.0 1.5 2.0 2.5 3.0"
E,0.937007874015748,Best Reward
E,0.9385826771653544,"RandomFCN(100,2)_seed=0_k=25"
E,0.9401574803149606,"200
400
600
800
1000
Step 2 3 4 5"
E,0.9417322834645669,Best Reward
E,0.9433070866141732,"RandomFCN(100,2)_seed=13_k=5"
E,0.9448818897637795,"200
400
600
800
1000
Step 2 3 4 5"
E,0.9464566929133859,Best Reward
E,0.9480314960629921,"RandomFCN(100,2)_seed=13_k=10"
E,0.9496062992125984,"200
400
600
800
1000
Step 2 3 4"
E,0.9511811023622048,Best Reward
E,0.952755905511811,"RandomFCN(100,2)_seed=13_k=25"
E,0.9543307086614173,"200
400
600
800
1000
Step 1 2 3 4"
E,0.9559055118110236,Best Reward
E,0.9574803149606299,"RandomFCN(100,2)_seed=42_k=5"
E,0.9590551181102362,"200
400
600
800
1000
Step 1 2 3 4"
E,0.9606299212598425,Best Reward
E,0.9622047244094488,"RandomFCN(100,2)_seed=42_k=10"
E,0.9637795275590552,"200
400
600
800
1000
Step 1 2 3 4"
E,0.9653543307086614,Best Reward
E,0.9669291338582677,"RandomFCN(100,2)_seed=42_k=25"
E,0.968503937007874,"200
400
600
800
1000
Step 2 3 4 5"
E,0.9700787401574803,Best Reward
E,0.9716535433070866,"RandomFCN(100,2)_seed=77_k=5"
E,0.9732283464566929,"200
400
600
800
1000
Step 2 3 4 5"
E,0.9748031496062992,Best Reward
E,0.9763779527559056,"RandomFCN(100,2)_seed=77_k=10"
E,0.9779527559055118,"200
400
600
800
1000
Step 2 3 4"
E,0.9795275590551181,Best Reward
E,0.9811023622047244,"RandomFCN(100,2)_seed=77_k=25"
E,0.9826771653543307,"200
400
600
800
1000
Step 2 1 0 1 2"
E,0.984251968503937,Best Reward
E,0.9858267716535433,"RandomFCN(100,2)_seed=100_k=5"
E,0.9874015748031496,"200
400
600
800
1000
Step 2 1 0 1"
E,0.988976377952756,Best Reward
E,0.9905511811023622,"RandomFCN(100,2)_seed=100_k=10"
E,0.9921259842519685,"200
400
600
800
1000
Step 2 1 0 1"
E,0.9937007874015747,Best Reward
E,0.9952755905511811,"RandomFCN(100,2)_seed=100_k=25"
E,0.9968503937007874,"NN+MILP
NN+ConEvo
NN+RejSample
ConEvo
Ensemble+RegEvo"
E,0.9984251968503937,"Figure 14: Best observed reward as a function of iteration for the second half of all constrained
problems (Section 4.3), averaged over 20 iterations (bands indicate ±1sd). Initial randomly sampled
set of 50 points is omitted."
