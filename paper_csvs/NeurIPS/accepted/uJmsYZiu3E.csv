Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0029585798816568047,"We study the maximin share (MMS) fair allocation of m indivisible chores to n
agents who have costs for completing the assigned chores. It is known that exact
MMS fairness cannot be guaranteed, and so far the best-known approximation
for additive cost functions is 13"
ABSTRACT,0.005917159763313609,"11 by Huang and Segal-Halevi [EC, 2023]; however,
beyond additivity, very little is known. In this work, we first prove that no algorithm
can ensure better than min{n,
log m
log log m}-approximation if the cost functions are
submodular. This result also shows a sharp contrast with the allocation of goods
where constant approximations exist as shown by Barman and Krishnamurthy
[TEAC, 2020] and Ghodsi et al. [AIJ, 2022]. We then prove that for subadditive
costs, there always exists an allocation that is min{n, ⌈log m⌉}-approximation,
and thus the approximation ratio is asymptotically tight. Besides multiplicative
approximation, we also consider the ordinal relaxation, 1-out-of-d MMS, which
was recently proposed by Hosseini et al. [JAIR and AAMAS, 2022]. Our im-
possibility result implies that for any d ≥2, a 1-out-of-d MMS allocation may
not exist. Due to these hardness results for general subadditive costs, we turn to
studying two specific subadditive costs, namely, bin packing and job scheduling.
For both settings, we show that constant approximate allocations exist for both
multiplicative and ordinal relaxations of MMS."
INTRODUCTION,0.008875739644970414,"1
Introduction"
BACKGROUND AND RELATED RESEARCH,0.011834319526627219,"1.1
Background and related research"
BACKGROUND AND RELATED RESEARCH,0.014792899408284023,"Although fair resource allocation has been widely studied in the past decade, the research is centered
around additive functions [3]. However, in many real-world scenarios, the functions are more
complicated. Particularly, the functions appear in machine learning and artificial intelligence (e.g,
clustering [37], Sketches [18], Coresets [36], data distillation [41]) are often submodular, and we refer
the readers to a recent survey that reviews some major problems within machine learning that have
been touched by submodularity [12]. Therefore, in this work, we study the fair allocation problem
when the agents have beyond additive cost functions. The mainly studied solution concept is maximin
share (MMS) fairness [14], which is traditionally defined for the allocation of goods as a relaxation
of proportionality (PROP). A PROP allocation requires that the utility of each agent is no smaller
than the average utility when all items are allocated to her. PROP is too demanding in the sense that
such an allocation does not exist even when there is a single item and two agents. Due to this strong
impossibility result, the maximin share (MMS) of an agent is proposed to relax the average utility by
the maximum utility the agent can guarantee herself if she is to partition the items into n bundles but
is to receive the least favorite bundle."
BACKGROUND AND RELATED RESEARCH,0.01775147928994083,"For the allocation of goods, although MMS significantly weakens the fairness requirement, it was first
shown by Kurokawa et al. [31, 32] that there are instances where no allocation is MMS fair for all
agents. Accordingly, designing (efficient) algorithms to compute approximately MMS fair allocations
steps into the center of the field of algorithmic fair allocation. Kurokawa et al. [32] first proved that
there exists a 2"
BACKGROUND AND RELATED RESEARCH,0.020710059171597635,"3-approximate MMS fair allocation for additive utilities, and then Amanatidis et al.
[1] designed a polynomial time algorithm with the same approximation guarantee. Later, Ghodsi
et al. [23] improved the approximation ratio to 3"
BACKGROUND AND RELATED RESEARCH,0.023668639053254437,"4, and Garg and Taki [22] further improved it to
3
4 + o(1). On the negative side, Feige et al. [20] proved that no algorithm can ensure better than
39
40 approximation. Beyond additive utilities, Barman and Krishnamurthy [6] initiated the study of
approximately MMS fair allocation with submodular utilities, and proved that a 0.21-approximate
MMS fair allocation can be computed by the round-robin algorithm. Ghodsi et al. [24] improved the
approximation ratio to 1"
BACKGROUND AND RELATED RESEARCH,0.026627218934911243,"3, and moreover, they gave constant and logarithmic approximation guarantees
for XOS and subadditive utilities, respectively. The approximations for XOS and subadditive utilities
are recently improved by Seddighin and Seddighin [40]. There are also several works that delve
into concrete combinatorial problems and seek to improve approximation ratios compared to more
general functions. Li et al. [33] and Hummel and Hetland [30] introduced interval scheduling and
independent set structures, respectively, into MMS fair allocation problems. In both cases, the induced
utility functions correspond to special cases of XoS functions. Both of these two works enhanced the
approximation ratios for their specific utility functions. Some other combinatorial problems that have
been studied for goods include the knapsack problem [21, 9, 8] and matroid constraints [19]."
BACKGROUND AND RELATED RESEARCH,0.029585798816568046,"For the parallel problem of chores, where agents need to spend costs on completing the assigned
chores, less effort has been devoted. Aziz et al. [4] first proved that the round-robin algorithm ensures
2-approximation for additive costs. Barman and Krishnamurthy [6], Huang and Lu [28] and Huang
and Segal-Halevi [29] respectively improved the approximation ratio to 4 3, 11"
BACKGROUND AND RELATED RESEARCH,0.03254437869822485,9 and 13
BACKGROUND AND RELATED RESEARCH,0.03550295857988166,"11. Recently,
Feige et al. [20] proved that with additive costs, no algorithm can be better than 44"
BACKGROUND AND RELATED RESEARCH,0.038461538461538464,"43-approximate.
However, except a recent work that studies binary supermodular costs [10], very little is known
beyond additivity."
BACKGROUND AND RELATED RESEARCH,0.04142011834319527,"Besides multiplicative approximations, we also consider the ordinal approximation of MMS, namely,
1-out-of-d MMS fairness which is recently studied in [5, 26, 27], and proportionality up to any
item (PROPX) which is an alternative way to relax proportionality [38, 34]. For indivisible chores,
Hosseini et al. [26] and Li et al. [34] respectively proved the existence of 1-out-of-⌈3n"
BACKGROUND AND RELATED RESEARCH,0.04437869822485207,"4 ⌉MMS fair
and exact PROPX allocations. All the above works also assume additive costs. More works related to
this paper in the literature can be seen in Appendix A."
MAIN RESULTS,0.047337278106508875,"1.2
Main results"
MAIN RESULTS,0.05029585798816568,"In this work, we aim at understanding the extent to which MMS fairness can be satisfied when the
cost functions are beyond additive. In a sharp contrast to the allocation of goods, we first show that
no algorithm can ensure better than min{n,
log m
log log m}-approximation when the cost functions are
submodular.1 Further, we show that for general subadditive cost functions, there always exists an
allocation that is min{n, log m}-approximate MMS, and thus the approximation ratio is asymptot-
ically tight. Next, we consider the ordinal relaxation, 1-out-of-d MMS. It is trivial that 1-out-of-1
MMS is satisfied no matter how the items are allocated, and somewhat surprisingly, our impossibility
result implies that for any d ≥2, there is an instance for which no allocation is 1-out-of-d MMS."
MAIN RESULTS,0.05325443786982249,"Result 1 For general subadditive cost functions, the asymptotically tight multiplicative approximation
ratio of MMS is min{n, log m}. Further, for any d ≥2, a 1-out-of-d MMS allocation may not exist."
MAIN RESULTS,0.05621301775147929,"Result 1 combines Theorems 1, 2 and Corollary 1. The strong impossibility in Result 1 does not rule
out the possibility of constant multiplicative or ordinal approximation of MMS fair allocations for
specific subadditive costs. For this reason, we turn to studying two concrete settings with subadditive
costs. The first setting encodes a bin packing problem, which has applications in many areas (e.g.,
semiconductor chip design, loading vehicles with weight capacity limits, and filling containers [17]).
In the first setting, the items have sizes which can be different to different agents. The agents have
bins that can be used to pack the items allocated to them with the goal of using as few bins as
possible. The second setting encodes a job scheduling problem, which appears in many research"
MAIN RESULTS,0.05917159763313609,1In this paper we use log(·) to denote log2(·).
MAIN RESULTS,0.0621301775147929,"areas, including data science, big data, high-performance computing, and cloud computing [25]. In
the second setting, the items are jobs that need to be processed by the agents. Each job may be of
different lengths to different agents and each agent controls a set of machines with possibly different
speeds. Upon receiving a set of jobs, an agent’s cost is determined by the corresponding minimum
completion time when processing the jobs using her own machines (i.e., makespan). As will be
clear, job scheduling setting is more general than the additive cost setting. Besides, it uncovers new
research directions for group-wise fairness."
MAIN RESULTS,0.0650887573964497,"Result 2 For the bin packing and job scheduling settings, a 1-out-of-⌊n"
MAIN RESULTS,0.06804733727810651,"2 ⌋MMS allocation and a
2-approximate MMS allocation always exist."
MAIN RESULTS,0.07100591715976332,"Result 2 combines Theorems 3, 4 and Corollaries 2, 3. Besides studying MMS fairness, in Appendix
F, we also prove hardness results for two other relaxations of proportionality, i.e., PROP1 and PROPX."
PRELIMINARIES,0.07396449704142012,"2
Preliminaries"
PRELIMINARIES,0.07692307692307693,"For any integer k ≥1, let [k] = {1, . . . , k}. In a fair allocation instance I = (N, M, {vi}i∈N), there
are n agents denoted by N = [n] and m items denoted by M = {e1, . . . , em}. Each agent i ∈N
has a cost function over the items, vi : 2M →R+ ∪{0}. Note that for simplicity, we abuse vi(·) to
denote a cost function. The items are chores, and particularly, upon receiving a set of items S ⊆M,
vi(S) represents the effort or cost agent i needs to spend on completing the chores in S. The cost
functions are normalized and monotone, i.e., vi(∅) = 0 and vi(S1) ≤vi(S2) for any S1 ⊆S2 ⊆M.
Note that no bounded approximation can be achieved for general cost functions, and we provide one
such example in Appendix B.1. Thus we restrict our attention to the following three classes. A cost
function vi is subadditive if for any S1, S2 ⊆M, vi(S1 ∪S2) ≤vi(S1) + vi(S2). It is submodular
if for any S1 ⊆S2 ⊆M and any e ∈M \ S2, vi(S2 ∪{e}) −vi(S2) ≤vi(S1 ∪{e}) −vi(S1). It is
additive if for any S ⊆M, vi(S) = P"
PRELIMINARIES,0.07988165680473373,"e∈S vi({e}). It is widely known that any additive function is
also submodular, and any submodular function is also subadditive."
PRELIMINARIES,0.08284023668639054,"An allocation A = (A1, . . . , An) is an n-partition of the items where Ai contains the items allocated
to agent i such that Ai ∩Aj = ∅for any i ̸= j and S"
PRELIMINARIES,0.08579881656804733,"i∈N Ai = M. For any set S and integer d, let
Πd(S) be the set of all d-partitions of S. The maximin share (MMS) of agent i is"
PRELIMINARIES,0.08875739644970414,"MMSn
i (I) =
min
(X1,...,Xn)∈Πn(M) max
j∈[n] vi(Xj)."
PRELIMINARIES,0.09171597633136094,"Note that we may neglect n and I in MMSn
i (I) when there is no ambiguity. Note that the computation
of MMS is NP-hard even when the costs are additive, which can be verified by a reduction from
the Partition problem. Given an n-partition of M, X = (X1, . . . , Xn), if vi(Xj) ≤MMSi for any
j ∈[n], then X is called an MMS defining partition for agent i. Note that the original definition
of MMSi for chores is defined with non-positive values, where the minimum value of the bundles
is maximized. In this work, to simplify the notions, we choose to use non-negative numbers
(representing costs), and thus the definition is equivalently changed to be the maximum cost of the
bundles being minimized. To be consistent with the literature, we still call it maximin share."
PRELIMINARIES,0.09467455621301775,"Definition 1 (α-MMS) An allocation A = (A1, . . . , An) is α-approximate maximin share (α-MMS)
fair if vi(Ai) ≤α · MMSi for all i ∈N. The allocation is MMS fair if α = 1."
PRELIMINARIES,0.09763313609467456,"Given the definition of MMS, for any agent i with subadditive cost vi(·), we have the following
bounds for MMSi,"
PRELIMINARIES,0.10059171597633136,"MMSi ≥max

max
e∈M vi({e}), 1"
PRELIMINARIES,0.10355029585798817,"n · vi(M)
	
.
(1)"
PRELIMINARIES,0.10650887573964497,"Following recent works [5, 27, 26], we also consider the ordinal approximation of MMS, namely,
1-out-of-d MMS fairness. Intuitively, MMS fairness can be regarded as 1-out-of-n MMS (i.e.,
partitioning the items into n bundles but receiving the largest bundle). Since 1-out-of-n MMS
allocations may not exist, we can instead find a maximum integer d ≤n such that a 1-out-of-d MMS
allocation is guaranteed to exist. Given a d-partition of M, X = (X1, . . . , Xd), if vi(Xj) ≤MMSd
i
for any j ∈[d], then X is called a 1-out-of-d MMS defining partition for agent i. An allocation A is
1-out-of-d MMS fair if for every agent i ∈N, vi(Ai) ≤MMSd
i . More generally, given any α ≥1,
we have the bi-factor approximation, α-approximate 1-out-of-d MMS, if vi(Ai) ≤α · MMSd
i for"
PRELIMINARIES,0.10946745562130178,"every i ∈N. By the definition, we have the following simple observation, whose proof is deferred to
Appendix B.2."
PRELIMINARIES,0.11242603550295859,"Observation 1 For any instance with subadditive costs, given any integer 1 ≤d ≤n, a 1-out-of-d
MMS allocation is ⌈n"
PRELIMINARIES,0.11538461538461539,d ⌉-MMS fair.
GENERAL SUBADDITIVE COST SETTING,0.11834319526627218,"3
General subadditive cost setting"
GENERAL SUBADDITIVE COST SETTING,0.12130177514792899,"By Inequality 1, if the costs are subadditive, allocating all items to a single agent ensures an
approximation of n, which is the most unfair algorithm. Surprisingly, such an unfair algorithm
achieves the optimal approximation ratio of MMS even if the costs are submodular."
GENERAL SUBADDITIVE COST SETTING,0.1242603550295858,"Theorem 1 For any n ≥2, there is an instance with submodular costs for which no allocation is
better than n-MMS or
log m
log log m-MMS."
GENERAL SUBADDITIVE COST SETTING,0.12721893491124261,"Proof. For any fixed n ≥2, we construct an instance that contains n agents and m = nn items. By
taking logarithm of m = nn twice, it is easy to obtain"
GENERAL SUBADDITIVE COST SETTING,0.1301775147928994,"n =
log m
log log m −log log n ≥
log m
log log m."
GENERAL SUBADDITIVE COST SETTING,0.13313609467455623,"Thus, in the following, it suffices to show that no allocation can be better than n-MMS. Let each item
correspond to a point in an n-dimensional coordinate system, i.e.,"
GENERAL SUBADDITIVE COST SETTING,0.13609467455621302,"M = {(x1, x2, . . . , xn) | xi ∈[n] for all i ∈[n]}."
GENERAL SUBADDITIVE COST SETTING,0.1390532544378698,"For each agent i ∈N, we define n covering planes {Cil}l∈[n] and for each l ∈[n],"
GENERAL SUBADDITIVE COST SETTING,0.14201183431952663,"Cil = {(x1, x2, . . . , xn) | xi = l and xj ∈[n] for all j ∈[n] \ {i}}.
(2)"
GENERAL SUBADDITIVE COST SETTING,0.14497041420118342,"Note that {Cil}l∈[n] forms an exact cover of the points in M, i.e., S"
GENERAL SUBADDITIVE COST SETTING,0.14792899408284024,"l Cil = M and Cil ∩Ciz = ∅
for all l ̸= z. For any set of items S ⊆M, vi(S) equals the minimum number of planes in {Cil}l∈[n]
that can cover S. Therefore, vi(S) ∈[n] for all S. We first show vi(·) is submodular for every i. For
any S ⊆T ⊆M and any e ∈M \ T, if e is not in the same covering plane as any point in T, e is
not in the same covering plane as any point in S, either. Thus, vi(T ∪{e}) −vi(T) = 1 implies
vi(S ∪{e}) −vi(S) = 1, and accordingly,"
GENERAL SUBADDITIVE COST SETTING,0.15088757396449703,vi(T ∪{e}) −vi(T) ≤vi(S ∪{e}) −vi(S).
GENERAL SUBADDITIVE COST SETTING,0.15384615384615385,"Since {Cil}l∈[n] is an exact cover of M, MMSi = 1 for every i, where the MMS defining partition is
simply {Cil}l∈[n]. Then to prove the theorem, it suffices to show that for any allocation of M, there
is at least one agent whose cost is n. For the sake of contradiction, we assume there is an allocation
A = (A1, . . . , An) where every agent has cost at most n −1. This means that for every i ∈N,
there exists a plane Cili such that Ai ∩Cili = ∅. Consider the point b = (l1, . . . , ln), it is clear that
b ∈Cili and thus b /∈Ai for all i. This means that b is not allocated to any agent, a contradiction.
Therefore, such an allocation A does not exist which completes the proof of the theorem."
GENERAL SUBADDITIVE COST SETTING,0.15680473372781065,"To facilitate the understanding of Theorem 1, in Appendix C.1, we visualize an instance with 3 agents
and 27 items where no allocation is better than 3-MMS. The hard instance in Theorem 1 also implies
the following lower bound for 1-out-of-d MMS, whose proof is in Appendix C.2."
GENERAL SUBADDITIVE COST SETTING,0.15976331360946747,"Corollary 1 For any 2 ≤d ≤n, there is an instance with submodular cost functions for which no
allocation is 1-out-of-d MMS."
GENERAL SUBADDITIVE COST SETTING,0.16272189349112426,"Theorem 2 For any instance with subadditive cost functions, there always exists a min{n, ⌈log m⌉}-
MMS allocation."
GENERAL SUBADDITIVE COST SETTING,0.16568047337278108,"Proof. We describe the algorithm that computes a min{n, ⌈log m⌉}-MMS allocation in Algorithm
1. First, if log m ≥n, we are safe to arbitrarily allocate the items to the agents, which ensures
n-approximation."
GENERAL SUBADDITIVE COST SETTING,0.16863905325443787,"The tricky case is when log m < n, where we cannot allocate too many items to a single agent. For this
case, we first look at agent 1’s MMS defining partition D1 = (D1
1, . . . , D1
n), where v1(D1
j) ≤MMS1"
GENERAL SUBADDITIVE COST SETTING,0.17159763313609466,"Algorithm 1 Computing a min{n, ⌈log m⌉}-MMS allocation for subadditive costs
Input: An instance (N, M, {vi}i∈N) with general subadditive costs.
Output: An allocation A = (A1, . . . , An) such that vi(Ai) ≤⌈log m⌉· MMSi for all i ∈N."
GENERAL SUBADDITIVE COST SETTING,0.17455621301775148,"1: Initialize Ai ←∅for every i ∈N.
2: if log m ≥n then
3:
A1 ←M.
4: else
5:
i ←1 and M0 ←M.
6: end if
7: while Mi−1 ̸= ∅and i ≤n do
8:
Let (Di
1, . . . , Di
n) be one of i’s MMS defining partitions over M.
9:
Let Ri
j = Di
j ∩Mi−1 for all j ∈[n]. Re-index the bundles such that |Ri
1| ≥· · · ≥|Ri
n|.
10:
Ai ←S
j∈[⌈log m⌉] Ri
j and Mi ←Mi−1 \ Ai.
11:
i ←i + 1.
12: end while"
GENERAL SUBADDITIVE COST SETTING,0.17751479289940827,"for all j ∈[n] and we assume that they are ordered by the number of items, i.e., |D1
1| ≥· · · ≥|D1
n|.
In order to ensure that agent 1’s cost is no more than ⌈log m⌉times her MMS, we ask her to take
away ⌈log m⌉largest bundles (in terms of number of items) in D1, i.e., A1 = S"
GENERAL SUBADDITIVE COST SETTING,0.1804733727810651,"j∈[⌈log m⌉] D1
j. Since
the cost function is subadditive,"
GENERAL SUBADDITIVE COST SETTING,0.1834319526627219,"v1(A1) ≤
X"
GENERAL SUBADDITIVE COST SETTING,0.1863905325443787,"j∈[⌈log m⌉]
v1(D1
j) ≤⌈log m⌉· MMS1."
GENERAL SUBADDITIVE COST SETTING,0.1893491124260355,"Moreover, since on average each bundle in D1 contains m"
GENERAL SUBADDITIVE COST SETTING,0.19230769230769232,"n items and A1 contains the bundles with
largest number of items, |A1| ≥⌈log m⌉· m"
GENERAL SUBADDITIVE COST SETTING,0.1952662721893491,n ≥log m
GENERAL SUBADDITIVE COST SETTING,0.19822485207100593,"n
· m. That is, at least log m"
GENERAL SUBADDITIVE COST SETTING,0.20118343195266272,"n
fraction of the items
are taken away by agent 1. Let M1 = M \ A1 be the set of remaining items, and we have"
GENERAL SUBADDITIVE COST SETTING,0.20414201183431951,"|M1| ≤

1 −log m n"
GENERAL SUBADDITIVE COST SETTING,0.20710059171597633,"
· m."
GENERAL SUBADDITIVE COST SETTING,0.21005917159763313,"We next ask agent 2 to take away items in a similar way to agent 1. Let D2 = (D2
1, . . . , D2
n) be
one of agent 2’s MMS defining partitions, and R2 = (R2
1, . . . , R2
n) be the remaining items in these
bundles, i.e., R2
j = D2
j ∩M1. Again, we assume |R2
1| ≥· · · ≥|R2
n|. Letting A2 = S"
GENERAL SUBADDITIVE COST SETTING,0.21301775147928995,"j∈[⌈log m⌉] R2
j
and M2 = M1 \ A2, we have v2(A2) ≤⌈log m⌉· MMS2. Moreover, since on average each bundle
in R2 contains |M1|"
GENERAL SUBADDITIVE COST SETTING,0.21597633136094674,"n
items and A2 contains the bundles with largest number of items,"
GENERAL SUBADDITIVE COST SETTING,0.21893491124260356,|A2| ≥⌈log m⌉· |M1|
GENERAL SUBADDITIVE COST SETTING,0.22189349112426035,"n
≥log m"
GENERAL SUBADDITIVE COST SETTING,0.22485207100591717,"n
· |M1|,"
GENERAL SUBADDITIVE COST SETTING,0.22781065088757396,which gives
GENERAL SUBADDITIVE COST SETTING,0.23076923076923078,"|M2| ≤

1 −log m n"
GENERAL SUBADDITIVE COST SETTING,0.23372781065088757,"
· |M1| ≤

1 −log m n"
GENERAL SUBADDITIVE COST SETTING,0.23668639053254437,"2
· m.
(3)"
GENERAL SUBADDITIVE COST SETTING,0.23964497041420119,"We continue with the above procedure for agents i = 3, . . . , n with the formal description shown
in Algorithm 1. It is straightforward that every agent i who gets a bundle Ai has cost at most
⌈log m⌉· MMSi. Further, by induction, Equation 3 holds for all agents i ≤n, i.e.,"
GENERAL SUBADDITIVE COST SETTING,0.24260355029585798,"|Mi| ≤

1 −log m n"
GENERAL SUBADDITIVE COST SETTING,0.2455621301775148,"
· |Mi−1| ≤

1 −log m n"
GENERAL SUBADDITIVE COST SETTING,0.2485207100591716,"i
· m."
GENERAL SUBADDITIVE COST SETTING,0.2514792899408284,"To show the validity of the Algorithm, it remains to show that the algorithm can allocate all items,
i.e., Mn = ∅. This can be seen from the following inequalities,"
GENERAL SUBADDITIVE COST SETTING,0.25443786982248523,"|Mn| ≤

1 −log m n"
GENERAL SUBADDITIVE COST SETTING,0.257396449704142,"n
· m =

1 −log m n"
GENERAL SUBADDITIVE COST SETTING,0.2603550295857988,"
n
log m ·log m
· m <
1 e"
GENERAL SUBADDITIVE COST SETTING,0.26331360946745563,"log m
· m < 1"
GENERAL SUBADDITIVE COST SETTING,0.26627218934911245,m · m = 1.
GENERAL SUBADDITIVE COST SETTING,0.2692307692307692,"Since |Mn| < 1, Mn must be empty, which completes the proof of the theorem."
GENERAL SUBADDITIVE COST SETTING,0.27218934911242604,"Note that Theorem 1 does not rule out the possibility of beating the approximation ratio for specific
subadditive costs. In the next two sections, we turn to studying two specific settings, where we
are able to beat the lower bounds in Theorem 1 and Corollary 1 by designing algorithms that can
guarantee constant ordinal and multiplicative approximations of MMS. We will mostly consider the
ordinal approximation of MMS. By Observation 1, the ordinal approximation gives a result of the
multiplicative one, which can be improved by slightly modifying the designed algorithms."
BIN PACKING SETTING,0.27514792899408286,"4
Bin packing setting"
MODEL,0.2781065088757396,"4.1
Model"
MODEL,0.28106508875739644,"The first setting encodes a bin packing problem where the items have sizes and need to be packed
into bins by the agents. The items may be of different sizes to different agents. Specifically, each
item ej ∈M has size si,j ≥0 to each agent i ∈N. For a set of items S, si(S) = P"
MODEL,0.28402366863905326,"ej∈S si,j. Each
agent i ∈N has unlimited number of bins with the same capacity ci. Without loss of generality, we
assume that c1 ≥· · · ≥cn and ci ≥maxej∈M si,j for all i ∈N."
MODEL,0.2869822485207101,"Upon receiving a set of items S ⊆M, agent i’s cost vi(S)2 is determined by the minimum number
of bins (with capacity ci) that can pack all items in S. Note that the calculation of vi(S) involves
solving a classic bin packing problem which is NP-hard. For any two sets S1 and S2, vi(S1 ∪S2) ≤
vi(S1) + vi(S2) since the optimal packing of S1 ∪S2 is no worse than packing S1 and S2 separately
and thus vi(·) is subadditive. Accordingly, MMSd
i is essentially the minimum number ki such that
the items can be partitioned into d bundles and the items in each bundle can be packed into no more
than ki bins. The definition of MMSd
i gives MMSd
i · ci ≥si(M)"
MODEL,0.28994082840236685,"d
for all i ∈N."
MODEL,0.29289940828402367,"We say an item ej ∈M is large for an agent i if the size of ej to i exceeds half of the capacity
of i’s bins, i.e., si,j > ci"
MODEL,0.2958579881656805,"2 ; otherwise, we say ej is small for i. Let Hi denote the set of i’s large
items in M, and Li denote the set of i’s small items; that is, Hi = {ej ∈M : si,j > ci"
MODEL,0.2988165680473373,"2 } and
Li = {ej ∈M : si,j ≤ci"
MODEL,0.30177514792899407,"2 }. Since two large items cannot be put together into the same bin, the
number of each agent i’s large items is at most MMSd
i · d; that is, |Hi| ≤MMSd
i · d."
MODEL,0.3047337278106509,"We apply a widely-used reduction [13, 28] to restrict our attention on identical ordering (IDO)
instances where si,1 ≥· · · ≥si,m for all i. Specifically, it means that any algorithm that ensures
α-approximate 1-out-of-d MMS allocations for IDO instances can be converted to compute α-
approximate 1-out-of-d MMS allocations for general instances. The reduction may not work for
all subadditive costs, but we prove in Appendix D.1 that it does work for the bin packing and job
scheduling settings. Therefore, for these two settings, we only consider IDO instances."
ALGORITHM,0.3076923076923077,"4.2
Algorithm"
ALGORITHM,0.3106508875739645,"Next, we elaborate on the algorithm that proves Theorem 3."
ALGORITHM,0.3136094674556213,Theorem 3 A 1-out-of-⌊n
ALGORITHM,0.3165680473372781,2 ⌋MMS allocation always exists for any bin packing instance.
ALGORITHM,0.31952662721893493,Let d = ⌊n
ALGORITHM,0.3224852071005917,"2 ⌋. In a nutshell, our algorithm consists of two parts: in the first part, we partition the
items into d bundles in a bag-filling fashion and select one or two agents for each bundle. In the
second part, for each of the d bundles and each of the agents selected for it, we present an imaginary
assignment of the items in the bundle to the bins of the agent. These imaginary assignments are used
to guide the allocation of the items to the agents, such that each agent receives cost no more than her
1-out-of-d MMS."
ALGORITHM,0.3254437869822485,"4.2.1
Part 1: partitioning the items into d bundles"
ALGORITHM,0.32840236686390534,"The algorithm in the first part is formally presented in Algorithm 2, which runs in d rounds of bag
initialization (Steps 5 to 8) and bag filling (Steps 12 to 18). For each round j ∈[d], we define
candidate agents - those who think the size of the bag Bj is not large enough and have unallocated
small items (Step 4). Note that the set of candidate agents changes with the items in the bag and the"
ALGORITHM,0.33136094674556216,"2Note that although the value of vi(S) also depends on ci, to simplify the notations, we let the subscript i
absorb ci and neglect an extra parameter in vi(·)."
ALGORITHM,0.3343195266272189,"unallocated items. In the bag initialization procedure, we put into the bag the item ej and the items
every d items after ej (i.e., ej+d, ej+2d, . . .), as long as they have not been allocated and are large for
at least one remaining agent. We select one such agent. After the bag initialization procedure, if there
is at most one candidate agent, the round ends and the candidate agent (if exists and has not been
selected) is added as another selected agent. Otherwise, we enter the bag filling procedure."
ALGORITHM,0.33727810650887574,"In the bag filling procedure, as long as there exist at least two candidate agents, we let two of them
be the selected agents and put the smallest unallocated item into the bag. If there is at most one
candidate agent after the smallest item is put into the bag, the round ends and the only candidate
agent (if exists and has not been selected) replaces one of the selected agents."
ALGORITHM,0.34023668639053256,"Algorithm 2 Partitioning the items into d bundles.
Input: An IDO bin packing instance (N, M, {vi}i∈N, {si}i∈N).
Output: A d-partition of the items B = (B1, . . . , Bd) and disjoint sets of selected agents G =
(G1, . . . , Gd)."
ALGORITHM,0.3431952662721893,"1: Initialize Li ←{ej ∈M : si,j ≤ci"
ALGORITHM,0.34615384615384615,"2 } for each i ∈N, and R ←M.
2: for j = 1 to d do
3:
Initialize Bj ←∅, Gj ←∅, t ←j."
ALGORITHM,0.34911242603550297,"4:
N(Bj) ←{i ∈N : si(Bj) ≤si(M)"
ALGORITHM,0.3520710059171598,"d
and Li ∩R ̸= ∅}. // Candidate agents
5:
while et ∈R and there exists an agent i ∈N who thinks et is large do
6:
Bj ←Bj ∪{et}, R ←R \ {et}, t ←t + d.
7:
Gj ←{i}.
8:
end while
9:
if |N(Bj)| = 1 and N(Bj) ̸= Gj then
10:
Pick i ∈N(Bj), Gj ←Gj ∪{i}.
11:
end if
12:
while |N(Bj)| ≥2 do
13:
Pick i1, i2 ∈N(Bj), Gj ←{i1, i2}.
14:
Pick the smallest item e ∈R, Bj ←Bj ∪{e}, R ←R \ {e}.
15:
if |N(Bj)| = 1 and N(Bj) ⊈Gj then
16:
Pick i ∈N(Bj) and replace one arbitrary agent in Gj with agent i.
17:
end if
18:
end while
19:
N ←N \ Gj.
20: end for"
ALGORITHM,0.35502958579881655,"The way we establish the bag and select the agents makes the following two important properties
satisfied for every round j ∈[d]."
ALGORITHM,0.35798816568047337,"• Property 1: for each selected agent i ∈Gj, there are at most MMSd
i items in Bj that are
large for i. Besides, letting e∗
j be the item lastly added to Bj, if e∗
j is small for i, then"
ALGORITHM,0.3609467455621302,"si(Bj \ {e∗
j}) ≤si(M) d
."
ALGORITHM,0.363905325443787,"• Property 2: for each remaining agent i′ (i.e., i′ /∈S"
ALGORITHM,0.3668639053254438,"l∈[j] Gl), either si′(Bj) > si′(M)"
ALGORITHM,0.3698224852071006,"d
or no
unallocated item is small for i at the end of round j. Besides, no item in {ej, ej+d, . . .} that
is large for i′ remains unallocated at the end of round j."
ALGORITHM,0.3727810650887574,"Proof. For the first property, observe that large items are added into the bag only in the bag
initialization procedure, where one out of every d items is picked. Since there are at most d · MMSd
i
large items for every agent i, the bag contains at most MMSd
i of i’s large items. There are two cases
where e∗
j is small for an agent i ∈Gj. First, i is the only candidate agent after e∗
j is added, for which
case, we have si(Bj) ≤si(M)"
ALGORITHM,0.3757396449704142,"d
. Second, i is one of the two selected candidate agents before e∗
j is"
ALGORITHM,0.378698224852071,"added, for which case, we have si(Bj \ {e∗
j}) ≤si(M)"
ALGORITHM,0.3816568047337278,"d
. In both cases, si(Bj \ {e∗
j}) ≤si(M)"
ALGORITHM,0.38461538461538464,"d
holds.
The second property is quite direct by the algorithm, since there is no candidate agent outside Gj at
the end of round j (i.e., N(Bj) \ Gj = ∅), and all unallocated large items in {ej, ej+d, . . .} are put
into the bag in the bag initialization procedure."
ALGORITHM,0.3875739644970414,"Property 1 ensures that the items in each bundle Bj ∈B can be allocated to the selected agents in
Gj, such that each agent i ∈Gj can use no more than MMSd
i bins to pack all the items allocated to
her, which will be shown in the following part. Property 2 ensures the following claim."
ALGORITHM,0.3905325443786982,Claim 1 All the items can be allocated in Algorithm 2.
ALGORITHM,0.39349112426035504,"Proof. Observe that when the last round begins, there are at least n−(d−1)·2 ≥2 remaining agents.
If all the unallocated items are large for some remaining agent, all of them are added into the bag
during the bag initialization procedure of the last round and thus no item remains unallocated. Now
consider the case where some unallocated item is small for any remaining agent. By Property 2, for
any j ∈[d −1] and any remaining agent i′, we have si′(Bj) > si′(M)"
ALGORITHM,0.39644970414201186,"d
. This gives that the total size
of the unallocated items to i′ is smaller than si′(M)"
ALGORITHM,0.3994082840236686,"d
. Besides, after the bag initialization procedure
of the last round, no large item remains and every remaining item is small for any remaining agent.
Combining these two facts, we know that there are always at least 2 candidate agents and thus all
small items can be allocated in the bag filling procedure, which completes the proof."
ALGORITHM,0.40236686390532544,"4.2.2
Part 2: Allocating the items to the agents"
ALGORITHM,0.40532544378698226,"Next, we allocate the items in each bundle Bj ∈B to the selected agents in Gj. Let i be any agent in
Gj and B′
j = Bj \ {e∗
j} where e∗
j is the item lastly added to Bj. We first imaginatively assign the
items in B′
j to i’s bins as illustrated by Figure 1. We first put i’s large items in B′
j into individual
empty bins. Then we greedily put into the bins the remaining small items in B′
j in decreasing order
of their sizes, as long as the total size of the assigned items does not exceed the bin’s capacity. The
first time when the total size exceeds the capacity, we move to the next bin and so on (if all the bins
with large items are filled, we move to an empty bin). We call the item lastly added to each bin that
makes the total size exceed the capacity an extra item. Denote by Ji(B′
j) the set of extra items and
by Wi(B′
j) = B′
j \ Ji(B′
j) the other items in B′
j."
ALGORITHM,0.40828402366863903,"Figure 1: Imaginary assignment of B′
j to agent i’s bins"
ALGORITHM,0.41124260355029585,"If all items in Bj are large for some agent i ∈Gj, we allocate all of them to i. Otherwise, we know
that round j enters the bag filling procedure, thus there are two agents in Gj and the last item e∗
j is
small for both of them. Letting i1 be the agent who has more large items in Bj and i2 be the other
agent, we allocate i1 the items in Wi1(B′
j) and allocate i2 the items in Ji1(B′
j) ∪{e∗
j}."
ALGORITHM,0.41420118343195267,Now we are ready to prove Theorem 3.
ALGORITHM,0.4171597633136095,"Proof of Theorem 3. Consider any round j ∈[d]. If all items in Bj are large for some agent i ∈Gj,
by Property 1, we know that there are at most MMSd
i items in Bj. Thus i can pack all items in Bj
using no more than MMSd
i bins."
ALGORITHM,0.42011834319526625,"For the other case, recall that the agent i1 ∈Gj who has more large items in Bj receives the items
in Wi1(B′
j), and the other agent i2 receives the items in Ji1(B′
j) ∪{e∗
j}. We first discuss agent i1.
By Property 1, we know that for each agent i ∈{i1, i2}, there are at most MMSd
i large items in
B′
j and si(B′
j) ≤si(M)"
ALGORITHM,0.4230769230769231,"d
. These two facts imply that in the imaginative assignment of B′
j to i1, no"
ALGORITHM,0.4260355029585799,"more than MMSd
i1 bins are used. Since otherwise, si1(B′
j) > MMSd
i1 · ci1 ≥si1(M)"
ALGORITHM,0.4289940828402367,"d
, a contradiction.
Therefore, i1 can pack all items in Wi1(B′
j) using no more than MMSd
i1 bins."
ALGORITHM,0.4319526627218935,"Next we discuss agent i2. Observe that in the imaginary assignment of B′
j to i1, for each extra
item in Ji1(B′
j), there exists another item in the same bin with a larger size. Therefore, we have"
ALGORITHM,0.4349112426035503,"Algorithm 3 Computing 2-MMS allocations for the bin packing setting
Input: An IDO bin packing instance (N, M, {vi}i∈N, {si}i∈N).
Output: An allocation A = (A1, . . . , An) such that vi(Ai) ≤2 · MMSi for all i ∈N."
ALGORITHM,0.4378698224852071,"1: Initialize R ←M.
2: for j = 1 to n do
3:
Initialize Bj ←∅, t ←j, k ←an arbitrary agent in N.
4:
while et ∈R and there exists an agent i ∈N who thinks et is large do
5:
Bj ←Bj ∪{et}, R ←R \ {et}, t ←t + n.
6:
k ←i.
7:
end while
8:
while there exists an agent i ∈N that satisfies si(Bj) ≤si(M)"
ALGORITHM,0.4408284023668639,"n
and Li ∩R ̸= ∅do
9:
k ←i.
10:
Pick the smallest item e ∈R, Bj ←Bj ∪{e}, R ←R \ {e}.
11:
end while
12:
Ak ←Bj, N ←N \ {k}.
13: end for"
ALGORITHM,0.4437869822485207,"si2(Ji1(B′
j)) ≤
si2(B′
j)
2
≤si2(M)"
D,0.4467455621301775,"2d
. Combining with the fact that there are at most MMSd
i2 large items
in B′
j for i2, we know that i2 can use no more than MMSd
i2 bins to pack all items in Ji1(B′
j) and
there exists one bin with at least half the capacity not occupied. Since otherwise, si2(Ji1(B′
j)) >"
D,0.44970414201183434,"MMSd
i2 ·
ci2"
D,0.4526627218934911,2 ≥si2(M)
D,0.4556213017751479,"2d
, a contradiction. Recall that the last item e∗
j is small for i2, it can be put into
the bin that has enough unoccupied capacity. Therefore, i2 can also pack all items in Ji1(B′
j) ∪{e∗
j}
using at most MMSd
i2 bins, which completes the proof."
D,0.45857988165680474,"For the multiplicative relaxation of MMS, by Theorem 3 and Observation 1, a ⌈
n
⌊n"
D,0.46153846153846156,"2 ⌋⌉-MMS allocation
is guaranteed. Actually, we can slightly modify Algorithm 2 to compute a 2-MMS allocation."
D,0.46449704142011833,Corollary 2 A 2-MMS allocation always exists for any bin packing instance.
D,0.46745562130177515,"Proof. To compute a 2-MMS allocation, we replace the value of d with n in Algorithm 2 and select
only one agent in each round who receives the bag in that round. The modified algorithm is formally
presented in Algorithm 3. Following the same reasonings in Parts 1 and 2 (i.e., Subsubsections
4.2.1 and 4.2.2), it is not hard to see that all items can be allocated in Algorithm 3 and for any
i ∈N, there are at most MMSi large items in Ai. Besides, if the last item e∗
i is small for i, we
have si(Ai \ {e∗
i }) ≤si(M)"
D,0.47041420118343197,"n
. Again, in the imaginary assignment of Ai \ {e∗
i } to i, no more than
MMSi bins are used and at least one of them does not have an extra item. Therefore, agent i can
use MMSi bins to pack all items in Wi(Ai \ {e∗
i }) and another MMSi bins to pack all items in
Ji(Ai \ {e∗
i }) ∪{e∗
i }, which completes the proof."
D,0.47337278106508873,"In Appendix D.2, we show that the above multiplicative ratio is actually tight in the sense that there
exists an instance where no allocation is better than 2-MMS. Besides, in Appendix D.3, we show that
the algorithm that proves Corollary 2 actually computes an allocation where every agent i can use at
most 3"
D,0.47633136094674555,2MMSi + 1 bins to pack all the items allocated to her.
JOB SCHEDULING SETTING,0.47928994082840237,"5
Job scheduling setting"
JOB SCHEDULING SETTING,0.4822485207100592,"The second setting encodes a job scheduling problem where the items are jobs that need to be
processed by the agents. Each item ej ∈M has a size si,j ≥0 to each agent i ∈N, and for a set
of items S ⊆M, si(S) = P"
JOB SCHEDULING SETTING,0.48520710059171596,"ej∈S si,j. As the bin packing setting, we only consider IDO instances
where si,1 ≥· · · ≥si,m for all i. Each agent i ∈N exclusively controls a set of ki machines
Pi = [ki] with possibly different speed ρi,l for each l ∈Pi. Without loss of generality, we assume
ρi,1 ≥· · · ≥ρi,ki. Upon receiving a set of items S ⊆M, agent i’s cost vi(S) is the minimum
completion time of processing S using her own machines Pi (i.e., the makespan of Pi). Formally,"
JOB SCHEDULING SETTING,0.4881656804733728,"vi(S) =
min
(T1,...,Tki)∈Πki(S) max
l∈[ki] P"
JOB SCHEDULING SETTING,0.4911242603550296,"et∈Tl si,t"
JOB SCHEDULING SETTING,0.4940828402366864,"ρi,l
."
JOB SCHEDULING SETTING,0.4970414201183432,"Note that the computation of vi(S) is NP-hard if ki ≥2. For any two sets S1 and S2, vi(S1 ∪S2) ≤
vi(S1)+vi(S2) since the makespan of scheduling S1 ∪S2 is no larger than the sum of the makespans
of scheduling S1 and S2 separately, thus vi(·) is subadditive."
JOB SCHEDULING SETTING,0.5,"Regarding the value of MMSd
i , intuitively, it is obtained by partitioning the items into d · ki bundles,
and allocating them to ki different types of machines (with possibly different speeds) where each type
has d identical machines so that the makespan is minimized.3 Note that when each agent controls a
single machine, i.e., ki = 1 for all i, the problem degenerates to the additive cost case, and thus the
job scheduling setting strictly generalizes the additive setting."
JOB SCHEDULING SETTING,0.5029585798816568,"For the job scheduling setting, we have the following two main results."
JOB SCHEDULING SETTING,0.5059171597633136,Theorem 4 A 1-out-of-⌊n
JOB SCHEDULING SETTING,0.5088757396449705,2 ⌋MMS allocation always exists for any job scheduling instance.
JOB SCHEDULING SETTING,0.5118343195266272,Corollary 3 A 2-MMS allocation always exists for any job scheduling instance.
JOB SCHEDULING SETTING,0.514792899408284,"Note that simply partitioning the items into n bundles in a round-robin fashion does not guarantee
1-out-of-⌊n"
JOB SCHEDULING SETTING,0.5177514792899408,"2 ⌋MMS even for the simpler additive cost setting. Consider an instance where there are
four identical agents and five items with costs 4, 1, 1, 1, 1, respectively. For this instance, the value of
1-out-of-⌊n"
JOB SCHEDULING SETTING,0.5207100591715976,"2 ⌋MMS for each agent is 4 as the 1-out-of-2 MMS defining partition is {{4}, {1, 1, 1, 1}}.
However, the round-robin algorithm allocates two items with costs 4 and 1 to one agent, who receives
a cost more than her 1-out-of-d MMS. Our algorithm overcomes this problem by first partitioning the
items into ⌊n"
JOB SCHEDULING SETTING,0.5236686390532544,2 ⌋bundles and then carefully allocating the items in each bundle to two agents.
JOB SCHEDULING SETTING,0.5266272189349113,Let d = ⌊n
JOB SCHEDULING SETTING,0.5295857988165681,"2 ⌋. For each agent i ∈N and each machine l ∈Pi, let ci,l = ρi,l · MMSd
i denote l’s
capacity. In a nutshell, our algorithm consists of three parts: in the first part, we partition all items into
d bundles in a round-robin fashion. In the second part, for each of the d bundles and each agent, we
present an imaginary assignment of the items in the bundle to the agent’s machines. These imaginary
assignments are used in the third part to guide the allocation of the items in each of the d bundles to
two agents, such that each agent can assign her allocated items to her machines in a way that the total
workload on each machine does not exceed its capacity (in other words, each agent’s cost is no more
than her 1-out-of-d MMS). We defer the detailed algorithms and proofs to Appendix E."
CONCLUSION,0.5325443786982249,"6
Conclusion"
CONCLUSION,0.5355029585798816,"In this work, we study fair allocation of indivisible chores when the costs are beyond additive and the
fairness is measured by MMS. There are many open problems and further directions. First, there are
only existential results for min{n, ⌈log m⌉}-MMS allocations in the general subadditive cost setting
and 1-out-of-⌊n"
CONCLUSION,0.5384615384615384,"2 ⌋MMS allocations in the job scheduling setting. Polynomial-time algorithms that
achieve the same results remain as open problems. Second, for the general subadditive cost setting
and the bin packing setting, we provide the tight approximation ratios, but for the job scheduling
setting, we only have a lower bound of 44"
CONCLUSION,0.5414201183431953,"43, which is inherited from the additive cost setting [20]. One
immediate direction is to design better approximation algorithms or lower bound instances for the
job scheduling setting. Third, in the appendix, we show that for the bin packing setting, there exists
an allocation where every agent’s cost is no more than 3"
CONCLUSION,0.5443786982248521,"2 times her MMS plus 1. We suspect that the
multiplicative factor can be improved to 1. Fourth, for the job scheduling setting, we restrict us on
the case of related machines in the current work, it is interesting to consider the general model of
unrelated machines. As we have mentioned, the notion of collective maximin share fairness in the
job scheduling setting can be viewed as a group-wise fairness notion, which could be of independent
interest. Finally, we can investigate other combinatorial costs that can better characterize real-world
problems."
CONCLUSION,0.5473372781065089,Acknowledgement
CONCLUSION,0.5502958579881657,"The authors are ordered alphabetically. This work is funded by NSFC under Grant No. 62102333,
HKSAR RGC under Grant No. PolyU 25211321, and CCF-Huawei Populus Grove Fund."
CONCLUSION,0.5532544378698225,"3We provide another interpretation in Appendix E.1, which shows that the job scheduling setting uncovers
new research directions for group-wise fairness."
REFERENCES,0.5562130177514792,References
REFERENCES,0.5591715976331361,"[1] Georgios Amanatidis, Evangelos Markakis, Afshin Nikzad, and Amin Saberi. Approximation
algorithms for computing maximin share allocations. ACM Trans. Algorithms, 13(4):52:1–52:28,
2017."
REFERENCES,0.5621301775147929,"[2] Georgios Amanatidis, Evangelos Markakis, and Apostolos Ntokos. Multiple birds with one
stone: Beating 1/2 for EFX and GMMS via envy cycle elimination. Theor. Comput. Sci., 841:
94–109, 2020."
REFERENCES,0.5650887573964497,"[3] Georgios Amanatidis, Haris Aziz, Georgios Birmpas, Aris Filos-Ratsikas, Bo Li, Hervé Moulin,
Alexandros A. Voudouris, and Xiaowei Wu. Fair division of indivisible goods: A survey. CoRR,
abs/2208.08782, 2022."
REFERENCES,0.5680473372781065,"[4] Haris Aziz, Gerhard Rauchecker, Guido Schryen, and Toby Walsh. Algorithms for max-min
share fair allocation of indivisible chores. In AAAI, pages 335–341. AAAI Press, 2017."
REFERENCES,0.5710059171597633,"[5] Moshe Babaioff, Noam Nisan, and Inbal Talgam-Cohen. Fair allocation through competitive
equilibrium from generic incomes. In FAT, page 180. ACM, 2019."
REFERENCES,0.5739644970414202,"[6] Siddharth Barman and Sanath Kumar Krishnamurthy. Approximation algorithms for maximin
fair division. ACM Trans. Economics and Comput., 8(1):5:1–5:28, 2020."
REFERENCES,0.5769230769230769,"[7] Siddharth Barman, Arpita Biswas, Sanath Kumar Krishna Murthy, and Yadati Narahari. Group-
wise maximin fair allocation of indivisible goods. In AAAI, pages 917–924. AAAI Press,
2018."
REFERENCES,0.5798816568047337,"[8] Siddharth Barman, Arindam Khan, Sudarshan Shyam, and K. V. N. Sreenivas. Finding fair
allocations under budget constraints. In AAAI, pages 5481–5489. AAAI Press, 2023."
REFERENCES,0.5828402366863905,"[9] Siddharth Barman, Arindam Khan, Sudarshan Shyam, and K. V. N. Sreenivas. Guaranteeing
envy-freeness under generalized assignment constraints. In EC, pages 242–269. ACM, 2023."
REFERENCES,0.5857988165680473,"[10] Siddharth Barman, Vishnu V. Narayan, and Paritosh Verma. Fair chore division under binary
supermodular costs. CoRR, abs/2302.11530, 2023."
REFERENCES,0.5887573964497042,"[11] Umang Bhaskar, A. R. Sricharan, and Rohit Vaish. On approximate envy-freeness for indivisible
chores and mixed resources. In APPROX-RANDOM, volume 207 of LIPIcs, pages 1:1–1:23.
Schloss Dagstuhl - Leibniz-Zentrum für Informatik, 2021."
REFERENCES,0.591715976331361,"[12] Jeff A. Bilmes.
Submodularity in machine learning and artificial intelligence.
CoRR,
abs/2202.00132, 2022."
REFERENCES,0.5946745562130178,"[13] Sylvain Bouveret and Michel Lemaître. Characterizing conflicts in fair division of indivisible
goods using a scale of criteria. Auton. Agents Multi Agent Syst., 30(2):259–290, 2016."
REFERENCES,0.5976331360946746,"[14] Eric Budish. The combinatorial assignment problem: Approximate competitive equilibrium
from equal incomes. Journal of Political Economy, 119(6):1061–1103, 2011."
REFERENCES,0.6005917159763313,"[15] Ioannis Caragiannis, David Kurokawa, Hervé Moulin, Ariel D. Procaccia, Nisarg Shah, and
Junxing Wang. The unreasonable fairness of maximum nash welfare. ACM Trans. Economics
and Comput., 7(3):12:1–12:32, 2019."
REFERENCES,0.6035502958579881,"[16] Hau Chan, Jing Chen, Bo Li, and Xiaowei Wu. Maximin-aware allocations of indivisible goods.
In IJCAI, pages 137–143. ijcai.org, 2019."
REFERENCES,0.606508875739645,"[17] Edward G Coffman, János Csirik, Gábor Galambos, Silvano Martello, and Daniele Vigo. Bin
packing approximation algorithms: survey and classification. In Handbook of combinatorial
optimization, pages 455–531. 2013."
REFERENCES,0.6094674556213018,"[18] Graham Cormode. Data sketching. Commun. ACM, 60(9):48–55, 2017."
REFERENCES,0.6124260355029586,"[19] Amitay Dror, Michal Feldman, and Erel Segal-Halevi. On fair division under heterogeneous
matroid constraints. J. Artif. Intell. Res., 76:567–611, 2023."
REFERENCES,0.6153846153846154,"[20] Uriel Feige, Ariel Sapir, and Laliv Tauber. A tight negative example for MMS fair allocations.
In WINE, volume 13112 of Lecture Notes in Computer Science, pages 355–372. Springer, 2021."
REFERENCES,0.6183431952662722,"[21] Jiarui Gan, Bo Li, and Xiaowei Wu. Approximation algorithm for computing budget-feasible
EF1 allocations. In AAMAS, pages 170–178. ACM, 2023."
REFERENCES,0.621301775147929,"[22] Jugal Garg and Setareh Taki. An improved approximation algorithm for maximin shares. Artif.
Intell., 300:103547, 2021."
REFERENCES,0.6242603550295858,"[23] Mohammad Ghodsi, Mohammad Taghi Hajiaghayi, Masoud Seddighin, Saeed Seddighin, and
Hadi Yami. Fair allocation of indivisible goods: Improvement. Math. Oper. Res., 46(3):
1038–1053, 2021."
REFERENCES,0.6272189349112426,"[24] Mohammad Ghodsi, Mohammad Taghi Hajiaghayi, Masoud Seddighin, Saeed Seddighin, and
Hadi Yami. Fair allocation of indivisible goods: Beyond additive valuations. Artif. Intell., 303:
103633, 2022."
REFERENCES,0.6301775147928994,"[25] Sönke Hartmann and Dirk Briskorn. An updated survey of variants and extensions of the
resource-constrained project scheduling problem. European Journal of operational research,
297(1):1–14, 2022."
REFERENCES,0.6331360946745562,"[26] Hadi Hosseini, Andrew Searns, and Erel Segal-Halevi. Ordinal maximin share approximation
for chores. In AAMAS, pages 597–605. International Foundation for Autonomous Agents and
Multiagent Systems (IFAAMAS), 2022."
REFERENCES,0.636094674556213,"[27] Hadi Hosseini, Andrew Searns, and Erel Segal-Halevi. Ordinal maximin share approximation
for goods. J. Artif. Intell. Res., 74, 2022."
REFERENCES,0.6390532544378699,"[28] Xin Huang and Pinyan Lu. An algorithmic framework for approximating maximin share
allocation of chores. In EC, pages 630–631. ACM, 2021."
REFERENCES,0.6420118343195266,"[29] Xin Huang and Erel Segal-Halevi. A reduction from chores allocation to job scheduling. CoRR,
abs/2302.04581, 2023."
REFERENCES,0.6449704142011834,"[30] Halvard Hummel and Magnus Lie Hetland. Fair allocation of conflicting items. Auton. Agents
Multi Agent Syst., 36(1):8, 2022."
REFERENCES,0.6479289940828402,"[31] David Kurokawa, Ariel D. Procaccia, and Junxing Wang. When can the maximin share guarantee
be guaranteed? In AAAI, pages 523–529. AAAI Press, 2016."
REFERENCES,0.650887573964497,"[32] David Kurokawa, Ariel D. Procaccia, and Junxing Wang. Fair enough: Guaranteeing approxi-
mate maximin shares. J. ACM, 65(2):8:1–8:27, 2018."
REFERENCES,0.6538461538461539,"[33] Bo Li, Minming Li, and Ruilong Zhang. Fair scheduling for time-dependent resources. In
NeurIPS, pages 21744–21756, 2021."
REFERENCES,0.6568047337278107,"[34] Bo Li, Yingkai Li, and Xiaowei Wu. Almost (weighted) proportional allocations for indivisible
chores. In WWW, pages 122–131. ACM, 2022."
REFERENCES,0.6597633136094675,"[35] Richard J. Lipton, Evangelos Markakis, Elchanan Mossel, and Amin Saberi. On approximately
fair allocations of indivisible goods. In EC, pages 125–131. ACM, 2004."
REFERENCES,0.6627218934911243,"[36] Gaëlle Loosli and Stéphane Canu. Comments on the ""core vector machines: Fast SVM training
on very large data sets"". J. Mach. Learn. Res., 8:291–301, 2007."
REFERENCES,0.665680473372781,"[37] Baharan Mirzasoleiman, Amin Karbasi, Rik Sarkar, and Andreas Krause. Distributed sub-
modular maximization: Identifying representative elements in massive data. In NIPS, pages
2049–2057, 2013."
REFERENCES,0.6686390532544378,"[38] Hervé Moulin. Fair division in the age of internet. Annu. Rev. Econ., 2018."
REFERENCES,0.6715976331360947,"[39] Benjamin Plaut and Tim Roughgarden. Almost envy-freeness with general valuations. SIAM J.
Discret. Math., 34(2):1039–1068, 2020."
REFERENCES,0.6745562130177515,"[40] Masoud Seddighin and Saeed Seddighin. Improved maximin guarantees for subadditive and
fractionally subadditive fair allocation problem. In AAAI, pages 5183–5190. AAAI Press, 2022."
REFERENCES,0.6775147928994083,"[41] Edward Lloyd Snelson and Zoubin Ghahramani. Sparse gaussian processes using pseudo-inputs.
In NIPS, pages 1257–1264, 2005."
REFERENCES,0.6804733727810651,"[42] Shengwei Zhou and Xiaowei Wu. Approximately EFX allocations for indivisible chores. CoRR,
abs/2109.07313, 2021."
REFERENCES,0.6834319526627219,Appendix
REFERENCES,0.6863905325443787,"A
More related works"
REFERENCES,0.6893491124260355,"Besides proportionality, in another parallel line of research, envy-freeness and its relaxations, namely
envy-free up to one item (EF1) and envy-free up to any item (EFX), are also widely studied. It
was shown in [35] and [11] for goods and chores, respectively, that an EF1 allocation exists for the
monotone combinatorial functions. However, the existence of EFX allocations is still unknown even
with additive functions. Therefore, approximation algorithms were proposed in [2, 42] for additive
functions and in [39, 16] for subadditive functions. We refer the readers to [3] for a detailed survey
on fair allocation of indivisible items."
REFERENCES,0.6923076923076923,"B
Missing materials in preliminaries"
REFERENCES,0.6952662721893491,"B.1
Impossibility result for general cost functions"
REFERENCES,0.6982248520710059,"We provide an example to show that no bounded approximation ratio can be achieved for general
cost functions. Note that there exist simpler examples, but we choose the following one because it
represents a particular combinatorial structure – minimum spanning tree. Let G = (V, E) be a graph
shown in the left sub-figure of Figure 2, where the vertices V are the items that are to be allocated,
i.e., M = V . There are two agents N = {1, 2} who have different weights on the edges as shown
in the middle and right sub-figures of Figure 2. The cost functions are measured by the minimum
spanning tree in their received subgraphs. Particularly, for any S ⊆V , vi(S) equals the weight of
the minimum spanning tree on G[S] – the induced subgraph of S in G – under agent i’s weights.
Thus, MMSi = 0, for both i = 1, 2, where an MMS defining partition for agent 1 is {v1, v2} and
{v3, v4} and that for agent 2 is {v1, v4} and {v2, v3}. However, it can be verified that no matter how
the vertices are allocated to the agents, there is one agent whose cost is at least 1, which implies that
no bounded approximation is possible for general costs."
REFERENCES,0.7011834319526628,Figure 2: An instance with unbounded approximation ratio
REFERENCES,0.7041420118343196,"B.2
Proof of Observation 1"
REFERENCES,0.7071005917159763,"To prove the observation, it suffices to show MMSd
i ≤⌈n"
REFERENCES,0.7100591715976331,"d ⌉· MMSn
i for any agent i ∈N. Let
X = (X1, . . . , Xn) be an MMS defining partition for agent i, which satisfies vi(Xj) ≤MMSn
i for
every j ∈[n]. Consider a d-partition X′ = (X′
1, . . . , X′
d) built by evenly distributing the n bundles
in X to the d bundles in X′; that is, the number of bundles distributed to the bundles in X′ differs
by at most one. Clearly, X′ satisfies vi(X′
j) ≤⌈n"
REFERENCES,0.7130177514792899,"d ⌉· MMSn
i for every j ∈[d]. By the definition of
1-out-of-d MMS, it follows that"
REFERENCES,0.7159763313609467,"MMSd
i ≤max
j∈[d] vi(X′
j) ≤⌈n"
REFERENCES,0.7189349112426036,"d ⌉· MMSn
i ,"
REFERENCES,0.7218934911242604,thus completing the proof. x z
REFERENCES,0.7248520710059172,"y
1
2
3 2 2 3 3"
REFERENCES,0.727810650887574,Agent 1 x z
REFERENCES,0.7307692307692307,"y
1
2
3 2 2 3 3"
REFERENCES,0.7337278106508875,Agent 2 x z
REFERENCES,0.7366863905325444,"y
1
2
3 2 2 3 3"
REFERENCES,0.7396449704142012,Agent 3
REFERENCES,0.742603550295858,Figure 3: An instance with 3 agents and 27 items
REFERENCES,0.7455621301775148,"C
Missing materials in general subadditive cost setting"
REFERENCES,0.7485207100591716,"C.1
An example that helps understand Theorem 1"
REFERENCES,0.7514792899408284,"The example is illustrated in Figure 3 where each agent has three covering planes. Take agent 1 for
example, her three covering planes contain the items whose x coordinates are 1, 2, 3, respectively.
If there exists an allocation that is better than 3-MMS, then each agent is allocated items from at
most 2 of her covering planes. Without loss of generality, we assume that agent 1 (or agents 2 and 3
respectively) is not allocated any item whose x (or y and z respectively) coordinate is 1. Then, the
item (1, 1, 1) is not allocated to any agent, a contradiction."
REFERENCES,0.7544378698224852,"C.2
Proof of Corollary 1"
REFERENCES,0.757396449704142,"We consider the same instance that is designed in Theorem 1. In this instance, we have proved that no
matter how the items are allocated among the agents, there is at least one agent, say i, whose cost is n.
Moreover, by the design of the cost functions, for any integer d, it can be observed that MMSd
i = ⌈n"
REFERENCES,0.7603550295857988,"d ⌉.
Note that ⌈n"
REFERENCES,0.7633136094674556,"d ⌉is always smaller than n for all d ≥2, thus the allocation is not 1-out-of-d MMS to i."
REFERENCES,0.7662721893491125,"D
Missing materials in bin packing setting"
REFERENCES,0.7692307692307693,"D.1
The IDO reduction"
REFERENCES,0.772189349112426,"For a bin packing or job scheduling instance I, the IDO instance I′ is constructed by setting the size
of each item ej ∈M to each agent i ∈N in I′ to the j-th largest size of the items to i in I. Then the
IDO reduction is formally presented in the following lemma."
REFERENCES,0.7751479289940828,"Lemma 1 For the bin packing or job scheduling setting, if there exists an allocation A′ =
(A′
1, . . . , A′
n) in the IDO instance I′ such that v′
i(A′
i) ≤α · MMSd
i (I′) for all i ∈N, then there
exists an allocation A = (A1, . . . , An) in the original instance I such that vi(Ai) ≤α · MMSd
i (I)
for all i ∈N."
REFERENCES,0.7781065088757396,"Proof. We design Algorithm 4 that given I, I′ and A′, computes the desired allocation A. In the
algorithm, we look at the items from em to e1. For each item, we let the agent who receives it in I′
pick her smallest unallocated item in I."
REFERENCES,0.7810650887573964,"To prove the lemma, we first show that vi(Ai) ≤v′
i(A′
i) for all i ∈N. Consider the iteration where
we look at the item eg. We suppose that in this iteration agent i picks item eg′; that is, eg ∈A′
i,
eg′ ∈Ai and eg′ is the smallest unallocated item for i. Since an item is removed from the set R
after it is allocated, exactly m −g items have been allocated before eg′ is allocated. Therefore, eg′
is among the top m −g + 1 smallest items for agent i. Recall that eg is the item with the exactly
(m−g +1)-th smallest size to i, hence si,g′ ≤s′
i,g. The same reasoning can be applied to other items
in A′
i and Ai, and to other agents. It follows that for any i ∈N, any eg ∈A′
i and the corresponding
eg′ ∈Ai, si,g′ ≤s′
i,g. For the bin packing or job scheduling setting, this implies vi(Ai) ≤v′
i(A′
i).
Since the maximin share depends on the sizes of the items but not on the order, the maximin share"
REFERENCES,0.7840236686390533,"of agent i in I′ is the same as that in I, i.e., MMSd
i (I′) = MMSd
i (I). Hence, the condition that
v′
i(A′
i) ≤α · MMSd
i (I′) gives vi(Ai) ≤α · MMSd
i (I), which completes the proof."
REFERENCES,0.7869822485207101,"Algorithm 4 IDO reduction for the bin packing and job scheduling settings
Input: A general instance I, the IDO instance I′ and an allocation A′ = (A′
1, ..., A′
n) for the IDO
instance such that v′
i(A′
i) ≤α · MMSd
i (I′) for all i ∈N.
Output: An allocation A = (A1, ..., An) such that vi(Ai) ≤α · MMSd
i (I) for all i ∈N.
1: For all i ∈N and eg ∈A′
i, set pg ←i.
2: Initialize Ai ←∅for all i ∈N, and R ←M.
3: for g = m to 1 do
4:
Pick eg′ ∈arg minek∈R{spg,k}.
5:
Apg ←Apg ∪{eg′}, R ←R \ {eg′}.
6: end for"
REFERENCES,0.7899408284023669,"D.2
Lower bound instance"
REFERENCES,0.7928994082840237,"We present an instance for the bin packing setting where no allocation can be better than 2-MMS.
We first recall the impossibility instance given by Feige et al. [20]. In this instance there are three
agents and nine items as arranged in a three by three matrix. The three agents’ costs are shown in the
matrices V1, V2 and V3. V1 ="
REFERENCES,0.7958579881656804,"6
15
22
26
10
7
12
19
12 ! V2 ="
REFERENCES,0.7988165680473372,"6
15
23
26
10
8
11
18
12 ! V3 ="
REFERENCES,0.8017751479289941,"6
16
22
27
10
7
11
18
12 !"
REFERENCES,0.8047337278106509,"Feige et al. [20] proved that for this instance the MMS value of every agent is 43, however, in any
allocation, at least one of the three agents gets cost no smaller than 44."
REFERENCES,0.8076923076923077,"We can adapt this instance to the bin packing setting and obtain a lower bound of 2. In particular, we
also have three agents and nine items. The numbers in matrices V1, V2 and V3 are the sizes of the
items to agents 1, 2 and 3, respectively. Let the capacities of the bins be ci = 43 for all i ∈{1, 2, 3}.
Accordingly, we have MMSi = 1 for all i ∈{1, 2, 3}. Since in any allocation, there is at least one
agent who gets items with total size no smaller than 44, for this agent, she has to use two bins to pack
the assigned items, which means that no allocation can be better than 2-MMS."
REFERENCES,0.8106508875739645,"D.3
Computing 3"
REFERENCES,0.8136094674556213,2MMS + 1 allocations
REFERENCES,0.8165680473372781,"Recall that in the proof of Corollary 2, it has been shown that each agent i ∈N can use MMSi bins
to pack all items in Wi(Ai \ {e∗
i }) and another MMSi bins to pack all items in Ji(Ai \ {e∗
i }) ∪{e∗
i }.
Actually, since all items in Ji(Ai \ {e∗
i }) ∪{e∗
i } are small for i and at least two small items can be
put into one bin, i only needs ⌈MMSi"
REFERENCES,0.8195266272189349,"2
⌉bins to pack all items in Ji(Ai \ {e∗
i }) ∪{e∗
i }. Therefore, each
agent i can use no more than 3"
REFERENCES,0.8224852071005917,2MMSi + 1 bins to pack all the items allocated to her.
REFERENCES,0.8254437869822485,"E
Missing materials in job scheduling setting"
REFERENCES,0.8284023668639053,"E.1
Another interpretation to the job scheduling setting"
REFERENCES,0.8313609467455622,"An alternative way to explain the job scheduling setting is to view each agent i as a group of ki small
agents and MMSd
i as the collective maximin share for these ki small agents. We believe this notion
of collective maximin share is of independent interest as a group-wise fairness notion. We remark
that this notion is different from the group-wise (and pair-wise) maximin share defined in [7] and
[15], where the max-min value is defined for each single agent. In our definition, however, a set of
agents share the same value for the items allocated to them."
REFERENCES,0.834319526627219,"E.2
Algorithm"
REFERENCES,0.8372781065088757,"E.2.1
Part 1: partitioning the items into d bundles"
REFERENCES,0.8402366863905325,"We first partition the items into d bundles B = (B1, . . . , Bd) in a round-robin fashion. Specifically,
we allocate the items in descending order of their sizes to the bundles by turns, from the first bundle
to the last one. Each time, we allocate one item to one bundle, and when every bundle receives an
item, we start over from the first bundle and so on. For any set of items S, let S[l] be the l-th largest
item in S, then the algorithm is formally presented in Algorithm 5."
REFERENCES,0.8431952662721893,"Algorithm 5 Partitioning the items into d bundles
Input: An IDO job scheduling instance (N, M, {vi}i∈N, {si}i∈N).
Output: A d-partition of M: B = (B1, . . . , Bd)."
REFERENCES,0.8461538461538461,"1: Initialize Bj ←∅for every j ∈[d], and r ←1.
2: while r ≤m do
3:
for j = 1 to d do
4:
if r ≤m then
5:
Bj ←Bj ∪{M[r]}.
6:
r ←r + 1.
7:
end if
8:
end for
9: end while"
REFERENCES,0.849112426035503,"By the characteristic of the round-robin fashion, we have the following important observation."
REFERENCES,0.8520710059171598,"Observation 2 For each bundle Bj ∈B and each item ek ∈Bj \ {Bj[1]} (if exists), the d −1 items
before ek (i.e., items ek−1, ek−2, . . . , ek−d+1) have at least the same sizes as ek."
REFERENCES,0.8550295857988166,"E.2.2
Part 2: imaginary assignment"
REFERENCES,0.8579881656804734,"Next, for each bundle Bj ∈B computed in the first part and each agent i ∈N, we imaginatively
assign the items in Bj \ Bj[1] to i’s machines as follows. We greedily assign the items with larger
sizes to i’s machines with faster speeds (in other words, with larger capacities), as long as the
total workload on one machine does not exceed the its capacity. The first time when the workload
exceeds the capacity, we move to the next machine and so on. The algorithm is formally presented
in Algorithm 6 and illustrated in Figure 4. For each l ∈Pi, CI
i,l contains the items imaginatively
assigned to machine l that do not make the total workload exceed l’s capacity, and ti,l is the last item
assigned to l that makes the total workload exceed the capacity. Note that CI
i,l may be empty and
ti,l may be null. For simplicity, let ti,0 = Bj[1]; that is, Bj[1] is assigned to an imaginary machine
0. The items in S
l∈[ki] CI
i,l are called internal items (as shown by the dark boxes in Figure 4), and
{ti,0, . . . , ti,ki} are called external items (as shown by the light boxes)."
REFERENCES,0.8609467455621301,"Algorithm 6 Imaginary assignment
Input: A bundle Bj ∈B computed in the first part and an agent i ∈N.
Output: Sets of internal items {CI
i,1, . . . , CI
i,ki} and external items {ti,0, . . . , ti,ki}."
REFERENCES,0.863905325443787,"1: Initialize CI
i,l ←∅, ti,l ←null for every l ∈[ki], and r ←1.
2: while r ≤|Bj| do
3:
for l = 1 to ki do
4:
ti,l−1 ←Bj[r], r ←r + 1.
5:
while r ≤|Bj| and si(CI
i,l ∪{Bj[r]}) ≤ci,l do"
REFERENCES,0.8668639053254438,"6:
CI
i,l ←CI
i,l ∪{Bj[r]}, r ←r + 1.
7:
end while
8:
end for
9: end while"
REFERENCES,0.8698224852071006,"For each bundle Bj ∈B and each agent i ∈N, the imaginary assignment has the following important
properties."
REFERENCES,0.8727810650887574,Figure 4: The imaginary assignment of Bj to agent i
REFERENCES,0.8757396449704142,"• Property 1: all items in Bj \ {Bj[1]} can be assigned to agent i’s machines. Besides, the
last machine ki does not have an external item; that is, ti,ki is null."
REFERENCES,0.878698224852071,"• Property 2: for any 1 ≤l ≤ki, the total size of the internal items CI
i,l does not exceed the
capacity of machine l, i.e., si(CI
i,l) ≤ci,l"
REFERENCES,0.8816568047337278,"• Property 3: for any 1 ≤l ≤ki, the external item ti,l−1 (if not null) has size no larger than
the capacity of machine l, i.e., si(ti,l−1) ≤ci,l."
REFERENCES,0.8846153846153846,"Proof. The first property holds since otherwise, si(Bj \ {Bj[1]}) > P"
REFERENCES,0.8875739644970414,"l∈[ki] ci,l. By Observation 2,
it follows that
si(M) > d · si(Bj \ {Bj[1]}) > d ·
X"
REFERENCES,0.8905325443786982,"l∈[ki]
ci,l."
REFERENCES,0.893491124260355,"However, since all items can be assigned to i’s machines in i’s 1-out-of-d MMS defining partition,
we have si(M) ≤d · P"
REFERENCES,0.8964497041420119,"l∈[ki] ci,l, a contradiction."
REFERENCES,0.8994082840236687,"The second property directly follows the algorithm. For the third property, si(ti,0) ≤ci,1 follows
two facts that ti,0 is assigned to some machine in i’s 1-out-of-d MMS defining partition and ci,1
is the largest capacity of the machines. We then consider l ∈[ki −1] and show si(ti,l) ≤ci,l+1
(if ti,l is not null). The same reasoning can be applied to any other l′ ∈[ki −1]. Let S1 =
S"
REFERENCES,0.9023668639053254,"p∈[l](CI
i,p ∪{ti,p}). From the algorithm, we know that si(S1) > P"
REFERENCES,0.9053254437869822,"p∈[l] ci,p and ti,l is the smallest
item in S1. By Observation 2, there exist another d −1 disjoint sets of items {S2, . . . , Sd} such
that si(Sk) ≥si(S1) for every k ∈[2, d] and ti,l is also the smallest item in S"
REFERENCES,0.908284023668639,"k∈[d] Sk. Hence,
P"
REFERENCES,0.9112426035502958,k∈[d] si(Sk) > d · P
REFERENCES,0.9142011834319527,"p∈[l] ci,p. This implies that in i’s 1-out-of-d MMS defining partition, at least
one item in S
k∈[d] Sk is assigned to machine p ≥l + 1. Combining with the fact that ti,l is the
smallest item in S"
REFERENCES,0.9171597633136095,"k∈[d] Sk, we have si(ti,l) ≤ci,l+1."
REFERENCES,0.9201183431952663,"By these properties, for each machine l ∈Pi, we can assign either the internal items CI
i,l or the
external item ti,l−1 to l, such that its completion time does not exceed MMSd
i . This intuition guides
the allocation of the items to the agents in the following part."
REFERENCES,0.9230769230769231,"E.2.3
Part 3: allocating the items to the agents"
REFERENCES,0.9260355029585798,"Lastly, for any bundle Bj ∈B, we arbitrarily choose two agents i1, i2 ∈N and allocate them the
items in Bj as formally described in Algorithm 7. Recall that in the imaginary assignment of Bj
to each agent i ∈{i1, i2}, the items in Bj are divided into internal items S"
REFERENCES,0.9289940828402367,"l∈[ki] CI
i,l and external
items {ti,0, . . . , ti,ki}. Let E = {e∗
1, . . . , e∗
|E|} contain all external items shared by i1 and i2. Note
that e∗
1 = ti1,0 = ti2,0. We allocate the items in Bj to agents i1 and i2 in |E| rounds. In each round
q ∈[|E|], we first find the machines of i1 and i2 to which the shared external items e∗
q and e∗
q+1 are
assigned (denoted by l1, l2, l′
1 and l′
2, respectively. If q = |E|, simply let l′
1 = ki1 and l′
2 = ki2). We
then find the agent ik ∈{i1, i2} whose machine lk + 1 has more internal items. We allocate ik her
internal items from machine lk + 1 to machine l′
k, and allocate the other agent ik’s external items
from machine lk to machine l′
k −1."
REFERENCES,0.9319526627218935,Since 2 · d = 2 · ⌊n
REFERENCES,0.9349112426035503,"2 ⌋≤n, no more than n agents are needed to allocate all items. Thus to prove
Theorem 4, it remains to show that each agent can assign her allocated items to her machines such
that the total workload on each of the machines does not exceed its capacity."
REFERENCES,0.9378698224852071,"Algorithm 7 Allocating the items to the agents
Input: A d-partition of the items B = (B1, . . . , Bd) returned by Algorithm 5.
Output: An allocation A = (A1, . . . , An) such that vi(Ai) ≤MMSd
i for all i ∈N.
1: Initialize Ai ←∅for every i ∈N.
2: for j = 1 to d do
3:
Arbitrarily choose 2 agents i1, i2 ∈N, N ←N \ {i1, i2}.
4:
{CI
i1,1, . . . , CI
i1,ki1}, {ti1,0, . . . , ti1,ki1} ←Algorithm 6(Bj, i1)."
REFERENCES,0.9408284023668639,"5:
{CI
i2,1, . . . , CI
i2,ki2}, {ti2,0, . . . , ti2,ki2} ←Algorithm 6(Bj, i2)."
REFERENCES,0.9437869822485208,"6:
E ←{ti1,0, . . . , ti1,ki1} ∩{ti2,0, . . . , ti2,ki2}. Re-label E ←{e∗
1, . . . , e∗
|E|}. // Shared
external items by i1 and i2
7:
for q = 1 to |E| do
8:
Find l1 ∈[0, ki1] and l2 ∈[0, ki2] such that e∗
q = ti1,l1 = ti2,l2.
9:
if q < |E| then
10:
Find l′
1 ∈[0, ki1] and l′
2 ∈[0, ki2] such that e∗
q+1 = ti1,l′
1 = ti2,l′
2.
11:
else
12:
l′
1 = ki1 and l′
2 = ki2.
13:
end if
14:
if |CI
i1,l1+1| ≥|CI
i2,l2+1| then"
REFERENCES,0.9467455621301775,"15:
Ai1 ←Sl′
1
l=l1+1 CI
i1,l, Ai2 ←Sl′
1−1
l=l1 ti1,l.
16:
else
17:
Ai2 ←Sl′
2
l=l2+1 CI
i2,l, Ai1 ←Sl′
2−1
l=l2 ti2,l.
18:
end if
19:
end for
20: end for"
REFERENCES,0.9497041420118343,"Proof of Theorem 4. Consider any bundle Bj ∈B and assume the two chosen agents are i1, i2 ∈N.
We first look at the first round of the process of allocating the items in Bj to i1 and i2. Without
loss of generality, assume that the first machine of i1 contains more internal items than that of i2,
i.e., CI
i1,1 ≥CI
i2,1. From the algorithm, the items i1 takes are Sl′
1
l=1 CI
i1,l. By the second property
of the imaginary assignment, these items can be assigned to the first l′
1 machines of i1 such that
the total workload on each machine does not exceed its capacity. Besides, the items i2 takes are
Sl′
1−1
l=0 ti1,l, which are e∗
1 and a subset of Sl′
2
l=2 CI
i2,l. By the second and third properties of the
imaginary assignment, these items can be assigned to the first l′
2 machines of i2 such that the total
workload on each machine does not exceed its capacity. The same reasoning can be applied to all
following rounds. By induction, it follows that both i1 and i2 can assign their allocated items to their
machines such that the total workload on each machine does not exceed its capacity. This means that
both i1 and i2 receive costs no more than their 1-out-of-d MMS, which completes the proof."
REFERENCES,0.9526627218934911,"For the multiplicative relaxation of MMS, by Theorem 4 and Observation 1, a ⌈
n
⌊n"
REFERENCES,0.9556213017751479,"2 ⌋⌉-MMS allocation
is guaranteed. As the bin packing setting, after a slight modification, Algorithm 5 computes a 2-MMS
allocation, which is better than ⌈
n
⌊n"
REFERENCES,0.9585798816568047,2 ⌋⌉-MMS.
REFERENCES,0.9615384615384616,"Proof of Corollary 3. We show that by replacing the value of d with n, Algorithm 5 computes a
2-MMS allocation. Particularly, in the new version of Algorithm 5, we partition the items in M into
n bundles in a round-robin fashion and allocate each of the n bundles to one agent in N. By the
properties of the imaginary assignment, for each agent, the makespan of processing either the internal
items or the external items in her bundle using her machines does not exceed MMSn
i . This implies
that for each agent, the cost of her bundle does not exceed 2 · MMSn
i , which completes the proof."
REFERENCES,0.9644970414201184,"F
Proportionality up to one or any item"
REFERENCES,0.9674556213017751,"We now discuss two other relaxations for proportionality, i.e., proportional up to one item (PROP1)
and proportional up to any item (PROPX), which are also widely studied for additive costs."
REFERENCES,0.9704142011834319,"Definition 2 (α-PROP1 and α-PROPX) An allocation A = (A1, . . . , An) is α-approximate pro-
portional up to one item (α-PROP1) if vi(Ai\{e}) ≤α · vi(M)"
REFERENCES,0.9733727810650887,"n
for all agents i ∈N and some item
e ∈Ai. It is α-approximate proportional up to any item (α-PROPX) if vi(Ai\{e}) ≤α · vi(M)"
REFERENCES,0.9763313609467456,"n
for
all agents i ∈N and any item e ∈Ai. The allocation is PROP1 or PROPX if α = 1."
REFERENCES,0.9792899408284024,"It is easy to see that a PROPX allocation is also PROP1. Although exact PROPX or PROP1 allocations
are guaranteed to exist for additive costs, when the costs are subadditive, no algorithm can be better
than n-PROP1 or n-PROPX. Consider an instance with n agents and n + 1 items. The cost function
is vi(S) = 1 for all agents i ∈N and any non-empty subset S ⊆M. Clearly, the cost function
is subadditive since vi(S) + vi(T) ≥vi(S ∪T) for any S, T ⊆M. By the pigeonhole principle,
at least one agent i receives two or more items in any allocation of M. After removing any item
e ∈Ai, Ai is still not empty. That is, vi(Ai\{e}) = 1 = n · vi(M)"
REFERENCES,0.9822485207100592,"n
for any e ∈Ai. This example can
be easily extended to the bin packing and job scheduling settings, and thus we have the following
theorem."
REFERENCES,0.985207100591716,"Theorem 5 For the bin packing and job scheduling settings, no algorithm performs better than
n-PROP1 or n-PROPX."
REFERENCES,0.9881656804733728,"Proof. For the bin packing setting, consider an instance with n agents and n + 1 items. The capacity
of each agent’s bins is 1, i.e, ci = 1 for all i ∈N. Each item is very tiny so that every agent can pack
all items in just one bin, e.g., si,j =
1
n+1 for any i ∈N and ej ∈M. Therefore, we have vi(M) = 1
and PROPi = 1"
REFERENCES,0.9911242603550295,"n for each agent i ∈N. By the pigeonhole principle, at least one agent i receives two
or more items in any allocation of M. After removing any item e ∈Ai, agent i still needs one bin to
pack the remaining items. Hence, we have vi(Ai\{e}) = 1 = n · PROPi for any e ∈Ai."
REFERENCES,0.9940828402366864,"For the job scheduling setting, consider an instance with 2n agents and 2n + 1 items where each
agent possesses 2n machines with the same speed of 1, and the size of each item is 1 for every agent.
It can be easily seen that for every agent i ∈N, the maximum completion time of her machines is
minimized when assigning two items to one machine and one item to each of the remaining 2n −1
machines. Therefore, we have vi(M) = 2 and PROPi =
2
2n = 1"
REFERENCES,0.9970414201183432,"n for any i ∈N. Similarly, by the
pigeonhole principle, at least one agent i receives two or more items in any allocation of M. This
implies that vi(Ai\{e}) = 1 = n · PROPi for any e ∈Ai, thus completing the proof."
