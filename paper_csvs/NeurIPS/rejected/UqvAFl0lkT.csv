Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.000757002271006813,"Instruction-following from prompts in Natural Languages (NLs) is an impor-
1"
ABSTRACT,0.001514004542013626,"tant benchmark for Human-AI collaboration. Training Embodied AI agents for
2"
ABSTRACT,0.002271006813020439,"instruction-following with Reinforcement Learning (RL) poses a strong explo-
3"
ABSTRACT,0.003028009084027252,"ration challenge. Previous works have shown that NL-based state abstractions can
4"
ABSTRACT,0.003785011355034065,"help address the exploitation versus exploration trade-off in RL. However, NLs
5"
ABSTRACT,0.004542013626040878,"descriptions are not always readily available and are expensive to collect. We
6"
ABSTRACT,0.005299015897047691,"therefore propose to use the Emergent Communication paradigm, where artificial
7"
ABSTRACT,0.006056018168054504,"agents are free to learn an emergent language (EL) via referential games, to bridge
8"
ABSTRACT,0.006813020439061317,"this gap. ELs constitute cheap and readily-available abstractions, as they are the
9"
ABSTRACT,0.00757002271006813,"result of an unsupervised learning approach. In this paper, we investigate (i) how
10"
ABSTRACT,0.008327024981074944,"EL-based state abstractions compare to NL-based ones for RL in hard-exploration,
11"
ABSTRACT,0.009084027252081756,"procedurally-generated environments, and (ii) how properties of the referential
12"
ABSTRACT,0.00984102952308857,"games used to learn ELs impact the quality of the RL exploration and learning.
13"
ABSTRACT,0.010598031794095382,"Results indicate that the EL-guided agent, namely EReLELA, achieves similar
14"
ABSTRACT,0.011355034065102196,"performance as its NL-based counterparts without its limitations. Our work shows
15"
ABSTRACT,0.012112036336109008,"that Embodied RL agents can leverage unsupervised emergent abstractions to
16"
ABSTRACT,0.012869038607115822,"greatly improve their exploration skills in sparse reward settings, thus opening new
17"
ABSTRACT,0.013626040878122634,"research avenues between Embodied AI and Emergent Communication.
18"
INTRODUCTION,0.014383043149129448,"1
Introduction
19"
INTRODUCTION,0.01514004542013626,"Natural Languages (NLs) have some properties, such as compositionality and recursive syntax, that
20"
INTRODUCTION,0.015897047691143074,"allow us to talk about infinite meanings while only using a finite number of words (or even letters,
21"
INTRODUCTION,0.016654049962149888,"or phonemes...). In other words, it enables us to be as expressive as one might needs. However,
22"
INTRODUCTION,0.0174110522331567,"it may be interesting sometimes to use language to abstract away from the details and only focus
23"
INTRODUCTION,0.018168054504163512,"on the essence of a specific experience, or a specific sensory stimulus. Thus, even though NLs can
24"
INTRODUCTION,0.018925056775170326,"sometimes be used with high expressiveness, they also can work as abstractions. For instance, using a
25"
INTRODUCTION,0.01968205904617714,"unique utterance to refer to a lot of semantically-similar but (visually) different situations, such as the
26"
INTRODUCTION,0.02043906131718395,"one presented in Figure 1 where the utterance ‘one can see a purple key and a green ball’ can refer
27"
INTRODUCTION,0.021196063588190765,"to many of the first-person perspective of the embodied agent, irrespective of the actual perspective
28"
INTRODUCTION,0.02195306585919758,"under which each object is seen.
29"
INTRODUCTION,0.022710068130204392,"Tam et al. [61] referred to that aspect as compacting/clustering a state/observation space, which is
30"
INTRODUCTION,0.023467070401211203,"in effect segmenting it into a set of less-detailed but more-meaningful sub-spaces. We employ the
31"
INTRODUCTION,0.024224072672218017,"term meaningful with respect the task that the embodied agent is possibly trained for. For instance,
32"
INTRODUCTION,0.02498107494322483,"if the task consists of picking and placing objects, then it is meaningful for utterances to contain
33"
INTRODUCTION,0.025738077214231644,"information about objects and places, but not so much to contain information about other agents in
34"
INTRODUCTION,0.026495079485238455,"the environment, if any. In this paradigm, Tam et al. [61] and Mu et al. [51] provided some arguments
35"
INTRODUCTION,0.02725208175624527,"towards the compacting/clustering assumption of NLs, as they used NLs oracle to build an abstraction
36"
INTRODUCTION,0.028009084027252083,"over a 3D and 2D environments. They relied upon state-of-the-art exploration algorithms, such as
37"
INTRODUCTION,0.028766086298258896,"Random Network Distillation (RND - Burda et al. [9]) and Never-Give-Up (NGU - Badia et al. [1]),
38"
INTRODUCTION,0.029523088569265707,"which can be difficult to deploy.
39"
INTRODUCTION,0.03028009084027252,"Figure 1: Top-view visualization
of a wall-free 3D environment with
different objects (e.g.
red and
blue cubes, purple and green keys,
and green ball) showing the trajec-
tory (from blue to red dots) of a
randomly-walking embodied agent,
with first-person perspectives high-
lighted at relevant timesteps using
colored cones - showing the agent’s
viewpoint direction when a new ut-
terance is used to describe the first-
person perspective using an oracle
speaking in NL."
INTRODUCTION,0.031037093111279335,"Thus, in this work, we aim to simplify the process of using
40"
INTRODUCTION,0.03179409538228615,"languages as abstractions and address the limitation of using
41"
INTRODUCTION,0.03255109765329296,"NLs, as they are expensive to harvest and not necessarily the
42"
INTRODUCTION,0.033308099924299776,"most meaningful abstraction for any given task. Indeed, instead
43"
INTRODUCTION,0.03406510219530658,"of state-of-the-art exploration algorithms, we show that simpler
44"
INTRODUCTION,0.0348221044663134,"count-based approaches combined with language abstraction
45"
INTRODUCTION,0.03557910673732021,"can be leveraged for hard-exploration tasks. And, in order to
46"
INTRODUCTION,0.036336109008327025,"remove the reliance on NLs, we look at the field of Emergent
47"
INTRODUCTION,0.03709311127933384,"Communication (EC) [41, 7] which have shown that artificial
48"
INTRODUCTION,0.03785011355034065,"languages, that we refer to as emergent languages (ELs), can
49"
INTRODUCTION,0.03860711582134747,"emerge through unsupervised learning algorithms, such as Ref-
50"
INTRODUCTION,0.03936411809235428,"erential Games and variants [19], with structure and properties
51"
INTRODUCTION,0.04012112036336109,"similar to NLs. Our experimental evidences show that ELs,
52"
INTRODUCTION,0.0408781226343679,"acquired over an embodied agent’s observations in an online
53"
INTRODUCTION,0.041635124905374715,"fashion and in parallel of its training, can be leveraged for hard-
54"
INTRODUCTION,0.04239212717638153,"exploration tasks. We investigate what are the properties of
55"
INTRODUCTION,0.04314912944738834,"NLs and ELs in terms of their abstraction building abilities
56"
INTRODUCTION,0.04390613171839516,"by proposing a novel metric entitled Compactness Ambigu-
57"
INTRODUCTION,0.04466313398940197,"ity Metric (CAM). Measures show that ELs abstractions are
58"
INTRODUCTION,0.045420136260408785,"aligned but not similar to NLs in terms of the abstractions they
59"
INTRODUCTION,0.04617713853141559,"perform, as the Emergent Communication context successfully
60"
INTRODUCTION,0.046934140802422405,"picks up on the meaningful features of the environment. Indeed,
61"
INTRODUCTION,0.04769114307342922,"EReLELA’s abstractions reflect colors in the MultiRoom-N7-S4
62"
INTRODUCTION,0.04844814534443603,"environment which only features coloured, unlocked doors, but no distracting objects, or shapes in
63"
INTRODUCTION,0.04920514761544285,"the KeyCorridor-S3-R2 environment where it is important to pickup a relevant key, among other
64"
INTRODUCTION,0.04996214988644966,"distractingly-shaped objects, and to open the locked door-shaped object.
65"
INTRODUCTION,0.050719152157456475,"We continue by reviewing EC and RL backgrounds and notations in Section 2. After detailing our
66"
INTRODUCTION,0.05147615442846329,"method in Section 3, we present experimental results on procedurally-generated, hard-exploration
67"
INTRODUCTION,0.052233156699470096,"task from the MiniGrid [15] benchmarks in Section 4. Finally, we discuss in Section 5 the results
68"
INTRODUCTION,0.05299015897047691,"presented in light of some related works and highlight possible future works.
69"
BACKGROUND & NOTATION,0.053747161241483724,"2
Background & Notation
70"
BACKGROUND & NOTATION,0.05450416351249054,"We provide details on our Reinforcement Learning (RL) settings and count-based exploration methods
71"
BACKGROUND & NOTATION,0.05526116578349735,"in Section 2.1.Then, we review Emergent Communication in Section 2.2.
72"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.056018168054504165,"2.1
Exploration vs Exploitation in Reinforcement Learning
73"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.05677517032551098,"An RL agent interacts with an environment in order to learn a mapping from states to actions that
74"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.05753217259651779,"maximises its reward signal. Initially, both the reward signal and the dynamics of the environment,
75"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.0582891748675246,"i.e. the impact that the agent actions may have on the environment, are unknown to the agent. It must
76"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.059046177138531414,"explore the environment and gather information, but, all the while it is exploring, it cannot exploit the
77"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.05980317940953823,"best strategy that it has found so far to maximise the currently-known reward signal. This dilemma is
78"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.06056018168054504,"known as the Exploration-vs-Exploitation trade-off of RL.This dilemma is only the start of the rabbit
79"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.061317183951551855,"hole, as it can even get worse. Indeed, in sparse reward environments, the reward signal is mainly
80"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.06207418622255867,"zero most of the time. This context makes it very difficult for RL agents to learn anything, because RL
81"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.06283118849356548,"algorithms derive feedback (i.e. gradients to update their parameters) from the reward signal that they
82"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.0635881907645723,"observe from the environment.It is usually referred to as extrinsic, in order to differentiate it from an
83"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.0643451930355791,"intrinsic reward signal. As the extrinsic reward is mostly zero, RL agents must exploit another signal
84"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.06510219530658592,"to derive information about the currently-unknown environment. This other signal can be found in
85"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.06585919757759273,"relation to the observation/state space, as RL agents can learn to seek novelty or surprise around the
86"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.06661619984859955,"observation/state space and attempt to manipulate it efficiently by choosing relevant actions. Focusing
87"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.06737320211960636,"on this novelty, RL agents can harvest an intrinsic reward signal, in the sense that RL agents are
88"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.06813020439061317,"building it and giving it to themself. Note that this intrinsic reward signal is very different from the
89"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.06888720666161999,"extrinsic reward signal, because it does not inform about the task that RL agents need to perform
90"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.0696442089326268,"in the environment. Ideally, though, it provides a graded and dense signal that the RL agent can
91"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.07040121120363362,"use to start learning anything about the environment. This is inspired by intrinsic motivation in
92"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.07115821347464042,"psychology [53]. Exploration driven by curiosity/novelty might be an important way for children
93"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.07191521574564724,"to grow and learn. Here, we focus on novelty, but the intrinsic rewards could be correlated with e.g.
94"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.07267221801665405,"impact [54], surprise [9] or familiarity of the state. The intrinsic reward signal is only a proxy for
95"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.07342922028766086,"RL agents to start to make progress into learning about the environment and eventually, hopefully
96"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.07418622255866768,"encounter some non-zero extrinsic reward signal along the way. It provides a denser reward signal
97"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.07494322482967448,"that can guide RL agents into learning internal representations about the environment’s dynamic so
98"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.0757002271006813,"that, whenever some extrinsic reward are encountered along the way, then they can efficiently bind
99"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.07645722937168811,"their previously-learned representations to those recently-encountered extrinsic rewards.
100"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.07721423164269493,"Rt = Est+k+1∼T (st+k,at+k)
at+k+1∼π(st+k+1)
[ T
X"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.07797123391370174,"k=0
γkR(st+k+1, at+k+1)]
(1)"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.07872823618470856,"Formally, we study a single agent in a Markov Decision Pro-
101"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.07948523845571537,"cess (MDP) defined by the tuple (S, A, T, R, γ), referring to,
102"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.08024224072672217,"respectively, the set of states, the set of actions, the transition
103"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.080999242997729,"function T : S × A →P(S) which provides the probability
104"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.0817562452687358,"distribution of the next state given a current state and action,
105"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.08251324753974262,"the reward function R : S × A →r, and the discount fac-
106"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.08327024981074943,"tor γ ∈[0, 1]. The agent is modelled with a stochastic policy
107"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.08402725208175625,"π : S →P(A) from which actions are sampled at every time step of an episode of finite time horizon
108"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.08478425435276306,"T. The agent’s goal is to learn a policy which maximises its discounted expected return at time t,
109"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.08554125662376987,"defined in equation 1. We further define R = λextRext + λintRint as the weighted sum of the extrinsic
110"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.08629825889477669,"and intrinsic reward functions, respectively, Rext, Rint, with weights λext, λint. Indeed, while the
111"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.08705526116578349,"extrinsic reward is provided by the environment, we assume that for any tuple (st, at, st+1) we can
112"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.08781226343679031,"compute an intrinsic reward.
113"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.08856926570779712,"Stanton and Clune [58] identifies two categories of exploration strategies, to wit across-training,
114"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.08932626797880394,"where novelty of states, for instance, is evaluated in relation to all prior training RL episodes, and
115"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.09008327024981075,"intra-life, where it is evaluated solely in relation of the current RL episode. And, historically, we
116"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.09084027252081757,"can identify two types of intrinsic motivation exploration depending on how the intrinsic reward is
117"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.09159727479182438,"computed, either relying on count-based or prediction-based methods. Prediction-based methods fit
118"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.09235427706283118,"into the across-training category and count-based methods can actually fit in both categories but they
119"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.093111279333838,"have mainly been instantiated in the literature as across-training methods after extension of intra-life
120"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.09386828160484481,"core mechanisms. As our proposed architecture EReLELA fit into the category of count-based
121"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.09462528387585163,"methods, we detail them further.In the context of an intrinsic reward signal correlated with surprise,
122"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.09538228614685844,"then it is necessary to quantify how much of surprise each observation/state provides. Intuitively, we
123"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.09613928841786526,"can count how many times a given observation/state has been encountered and derive from that count
124"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.09689629068887207,"our intrinsic reward. The reward would guide the RL agent to prefer rarely visited/observed states
125"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.09765329295987887,"compared to common states. This is referred to as the count-based exploration method. Count-based
126"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.0984102952308857,"exploration method were originally only applicable to tabular RL where the state space is discrete
127"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.0991672975018925,"and it is easy to compare states together. When dealing with continuous or high-dimensional state
128"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.09992429977289932,"spaces, such method is not practical. Thus, Bellemare et al. [3] proposed (and extended in Ostrovski
129"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.10068130204390613,"et al. [52]) a pseudo-count approach which was derived from increasingly more efficient density
130"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.10143830431491295,"models, and they showed success in applying it to image-based exploration environments from Atari
131"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.10219530658591976,"2600 benchmark, such as Montezuma’s Revenge, Private Eye, and Venture. We provide more relevant
132"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.10295230885692658,"details in Appendix B.
133"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.10370931112793338,"Nevertheless, hard-exploration task involving procedurally-generated environments are notoriously
134"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.10446631339894019,"difficult for count-based exploration methods. Indeed, when states are procedurally-generated, almost
135"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.10522331566994701,"all states will be showing ‘novel’ features, most times irrespectively of whether it is relevant to the
136"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.10598031794095382,"task or not. It will follow that their state (pseudo-)count will always be low and therefore the RL
137"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.10673732021196064,"agent will get feedback towards reaching all of them indefinitely, but if every state is ‘novel’ then
138"
EXPLORATION VS EXPLOITATION IN REINFORCEMENT LEARNING,0.10749432248296745,"there is nothing to guide the agent in any specific direction that would entail to good exploration.
139"
EMERGENT COMMUNICATION,0.10825132475397427,"2.2
Emergent Communication
140"
EMERGENT COMMUNICATION,0.10900832702498107,"Emergent Communication is at the interface of language grounding and language emergence. While
141"
EMERGENT COMMUNICATION,0.10976532929598788,"language emergence raises the question of how to make artificial languages emerge, possibly with
142"
EMERGENT COMMUNICATION,0.1105223315669947,"similar properties to NLs, such as compositionality [2, 24, 45, 55], language grounding is concerned
143"
EMERGENT COMMUNICATION,0.11127933383800151,"with the ability to ground the meaning of (natural) language utterances into some sensory processes,
144"
EMERGENT COMMUNICATION,0.11203633610900833,"e.g. the visual modality. On one hand, the compositionality of ELs has been shown to further
145"
EMERGENT COMMUNICATION,0.11279333838001514,"the learnability of said languages [38, 57, 8, 45] and, on the other hand, the compositionality of
146"
EMERGENT COMMUNICATION,0.11355034065102196,"NLs promises to increase the generalisation ability of the artificial agent that would be able to
147"
EMERGENT COMMUNICATION,0.11430734292202877,"rely on them as a grounding signal, as it has been found to produce learned representations that
148"
EMERGENT COMMUNICATION,0.11506434519303559,"generalise, when measured in terms of the data-efficiency of subsequent transfer and/or curriculum
149"
EMERGENT COMMUNICATION,0.11582134746404239,"learning [27, 49, 50, 33]. Yet, emerging languages are far from being ‘natural-like’ protolanguages
150"
EMERGENT COMMUNICATION,0.1165783497350492,"[40, 10, 11], and the questions of how to constraint them to a specific semantic or a specific syntax
151"
EMERGENT COMMUNICATION,0.11733535200605602,"remain open problems. Nevertheless, some sufficient conditions can be found to further the emergence
152"
EMERGENT COMMUNICATION,0.11809235427706283,"of compositional languages and generalising learned representations [40, 43, 17, 5, 24, 39, 12, 21].
153"
EMERGENT COMMUNICATION,0.11884935654806965,"The backbone of the field rests on games that emphasise the functionality of languages, namely,
154"
EMERGENT COMMUNICATION,0.11960635881907646,"the ability to efficiently communicate and coordinate between agents. The first instance of such
155"
EMERGENT COMMUNICATION,0.12036336109008328,"an environment is the Signaling Game or Referential Game (RG) by Lewis [44], where a speaker
156"
EMERGENT COMMUNICATION,0.12112036336109008,"agent is asked to send a message to the listener agent, based on the state/stimulus of the world that it
157"
EMERGENT COMMUNICATION,0.12187736563209689,"observed. The listener agent then acts upon the observation of the message by choosing one of the
158"
EMERGENT COMMUNICATION,0.12263436790310371,"actions available to it in order to perform the ‘best’ action given the observed state depending on the
159"
EMERGENT COMMUNICATION,0.12339137017411052,"notion of ‘best’ action being defined by the interests common to both players. In RGs, typically, the
160"
EMERGENT COMMUNICATION,0.12414837244511734,"listener action is to discriminate between a target stimulus, observed by the speaker and prompting
161"
EMERGENT COMMUNICATION,0.12490537471612415,"its message generation, and some other distractor stimuli. Distractor stimuli are selected using a
162"
EMERGENT COMMUNICATION,0.12566237698713095,"distractor sampling scheme, which has been shown to impact the resulting EL [42, 43]. The listener
163"
EMERGENT COMMUNICATION,0.1264193792581378,"must discriminate correctly while relying solely on the speaker’s message. The latter defined the
164"
EMERGENT COMMUNICATION,0.1271763815291446,"discriminative variant, as opposed to the generative variant where the listener agent must reconstruct/-
165"
EMERGENT COMMUNICATION,0.1279333838001514,"generate the whole target stimulus (usually played with symbolic stimuli). Visual (discriminative)
166"
EMERGENT COMMUNICATION,0.1286903860711582,"RGs have been shown to be well-suited for unsupervised representation learning, either by competing
167"
EMERGENT COMMUNICATION,0.12944738834216502,"with state-of-the-art self-supervised learning approaches on downstream classification tasks [22], or
168"
EMERGENT COMMUNICATION,0.13020439061317185,"because they have been found to further some forms of disentanglement [28, 35, 14, 46] in learned
169"
EMERGENT COMMUNICATION,0.13096139288417866,"representations [65, 18]. Such properties can enable “better up-stream performance”[63], greater
170"
EMERGENT COMMUNICATION,0.13171839515518546,"sample-efficiency, and some form of (systematic) generalization [48, 26, 59]. Thus, this paper aims
171"
EMERGENT COMMUNICATION,0.13247539742619227,"to investigate visual discriminative RGs as auxiliary tasks for RL agents.
172"
METHOD,0.1332323996971991,"3
Method
173"
METHOD,0.1339894019682059,"In this section, following the acknowledgement of a gap in terms of evaluating the abstractions
174"
METHOD,0.13474640423921272,"that different languages perform over different state/observation space, we start by introducing in
175"
METHOD,0.13550340651021953,"Section 3.1 our Compactness Ambiguity Metric (CAM) that attempts to fill in that gap.Then, in
176"
METHOD,0.13626040878122633,"Section 3.2, we present the EReLELA architecture that leverages EL abstractions in an intra-life
177"
METHOD,0.13701741105223317,"count-based exploration scheme for RL agents.
178"
COMPACTNESS AMBIGUITY METRIC,0.13777441332323997,"3.1
Compactness Ambiguity Metric
179"
COMPACTNESS AMBIGUITY METRIC,0.13853141559424678,"In order to measure qualities related to the kind of abstraction that a language performs over stimuli,
180"
COMPACTNESS AMBIGUITY METRIC,0.1392884178652536,"we propose to rely on the temporal aspects of embodied agent’s trajectories in a given environment.
181"
COMPACTNESS AMBIGUITY METRIC,0.1400454201362604,"We build over the following intuition, represented in Figure 2: we consider two possible languages
182"
COMPACTNESS AMBIGUITY METRIC,0.14080242240726723,"grounded into the first-person viewpoint of an embodied agent situated in a 3D environment populated
183"
COMPACTNESS AMBIGUITY METRIC,0.14155942467827404,"with objects of different shapes and colors. On one hand, we have the Blue language, which is only
184"
COMPACTNESS AMBIGUITY METRIC,0.14231642694928084,"concerned about blue objects and its utterances only describe that they are of color blue when they
185"
COMPACTNESS AMBIGUITY METRIC,0.14307342922028765,"are, while, on the other hand, we have the Color language, which is describing the color of all
186"
COMPACTNESS AMBIGUITY METRIC,0.14383043149129449,"visible objects. Inherently, those two languages expose different semantics about the world, and
187"
COMPACTNESS AMBIGUITY METRIC,0.1445874337623013,"therefore they perform different abstractions. We aim to build a metric that captures how different the
188"
COMPACTNESS AMBIGUITY METRIC,0.1453444360333081,"semantics they expose are. To do so, we propose to arrange their respective utterances when prompted
189"
COMPACTNESS AMBIGUITY METRIC,0.1461014383043149,"with the very same agent’s trajectories into different timespan-focused buckets towards building
190"
COMPACTNESS AMBIGUITY METRIC,0.1468584405753217,"an histogram. These timespan-focused buckets reflect δ(u) the number of consecutive timesteps
191"
COMPACTNESS AMBIGUITY METRIC,0.14761544284632855,"(tk)k∈[kstart,kstart+δ(u)] for which a specific utterance u would be uttered by a speaker of each language
192"
COMPACTNESS AMBIGUITY METRIC,0.14837244511733536,"when prompted with the stimuli in those timesteps. We will refer to these are compactness counts. For
193"
COMPACTNESS AMBIGUITY METRIC,0.14912944738834216,"instance the Blue language’s utterance ‘I see a blue object’ at the beginning of the trajectory occupies
194"
COMPACTNESS AMBIGUITY METRIC,0.14988644965934897,"twice as more consecutive timesteps as the same utterance coming from a Color language speaker (or,
195"
COMPACTNESS AMBIGUITY METRIC,0.1506434519303558,"its compactness count in the Blue language is twice its compactness count in the Color language).
196"
COMPACTNESS AMBIGUITY METRIC,0.1514004542013626,"Therefore, in the case of the Blue language, this utterance would increment the medium-length bucket,
197"
COMPACTNESS AMBIGUITY METRIC,0.15215745647236942,"while it would increment the short-length bucket in the case of Color language histogram. It ensues
198"
COMPACTNESS AMBIGUITY METRIC,0.15291445874337622,"that the histograms of timespan-focused buckets captures semantics exposed by each language, and
199"
COMPACTNESS AMBIGUITY METRIC,0.15367146101438303,"we will therefore refer to the resulting histogram as the histogram of semantic-clustering timespans.
200"
COMPACTNESS AMBIGUITY METRIC,0.15442846328538987,"As the toy example highlights, the histograms of semantic-clustering timespans will differ from one
201"
COMPACTNESS AMBIGUITY METRIC,0.15518546555639667,"language to another depending on the semantics each language expose or, in other words, depending
202"
COMPACTNESS AMBIGUITY METRIC,0.15594246782740348,"on the abstractions they perform. This is the first intuition on which the Compactness Ambiguity
203"
COMPACTNESS AMBIGUITY METRIC,0.1566994700984103,"metric is built.
204"
COMPACTNESS AMBIGUITY METRIC,0.15745647236941712,"Figure 2: Toy example illustration of how dif-
ferent languages expose different semantics
over the same observed trajectory of stimuli,
and that the discrepancy in exposed semantics
can be captured by an histogram of semantic-
clustering timespans."
COMPACTNESS AMBIGUITY METRIC,0.15821347464042393,"Formally, we define L as the set of all possible lan-
205"
COMPACTNESS AMBIGUITY METRIC,0.15897047691143074,"guages over vocabulary V with maximum sentence
206"
COMPACTNESS AMBIGUITY METRIC,0.15972747918243754,"length L, such that for any language l ∈L we denote
207"
COMPACTNESS AMBIGUITY METRIC,0.16048448145344435,"Spl : S →l as a speaker agent or oracle that maps
208"
COMPACTNESS AMBIGUITY METRIC,0.16124148372445118,"any state/observation s ∈S to a caption or utterance
209"
COMPACTNESS AMBIGUITY METRIC,0.161998485995458,"u ∈l. Thus, we can now consider N buckets whose
210"
COMPACTNESS AMBIGUITY METRIC,0.1627554882664648,"related timespans (Ti)i∈[1,N] are sampled relative to
211"
COMPACTNESS AMBIGUITY METRIC,0.1635124905374716,"the maximal length T of a trajectory in the given en-
212"
COMPACTNESS AMBIGUITY METRIC,0.1642694928084784,"vironment, and the histogram of semantic-clustering
213"
COMPACTNESS AMBIGUITY METRIC,0.16502649507948525,"timespans that they induce.
214"
COMPACTNESS AMBIGUITY METRIC,0.16578349735049205,"Then, the other intuition on which the metric is built
215"
COMPACTNESS AMBIGUITY METRIC,0.16654049962149886,"is made evident by considering the expressivity or, its
216"
COMPACTNESS AMBIGUITY METRIC,0.16729750189250567,"inverse, the ambiguity, of a given language l, defined
217"
COMPACTNESS AMBIGUITY METRIC,0.1680545041635125,"as El =
#unique utterances"
COMPACTNESS AMBIGUITY METRIC,0.1688115064345193,"#unique stimuli
with # the set cardinality
218"
COMPACTNESS AMBIGUITY METRIC,0.16956850870552612,"operator. Dealing with stimuli being states/observations of a (randomly walking) embodied agent,
219"
COMPACTNESS AMBIGUITY METRIC,0.17032551097653292,"gathered into a dataset D, the number of unique stimuli cannot be estimated reliably when dealing
220"
COMPACTNESS AMBIGUITY METRIC,0.17108251324753973,"with complex, continuous stimuli. Thus, the best we can rely on is a measure of relative expressivity
221"
COMPACTNESS AMBIGUITY METRIC,0.17183951551854657,"over a dataset, that we define as REl(D) = #unique utterrances"
COMPACTNESS AMBIGUITY METRIC,0.17259651778955337,"#stimuli
= #Spl(D)"
COMPACTNESS AMBIGUITY METRIC,0.17335352006056018,"|D|
, with | · | being the size
222"
COMPACTNESS AMBIGUITY METRIC,0.17411052233156699,"operator over collections (differing from sets in the sense that they allow duplicates). In those terms,
223"
COMPACTNESS AMBIGUITY METRIC,0.17486752460257382,"the relative expressivity is maximised if and only if (i) #D = |D|, and (ii) Spl is a bijection over
224"
COMPACTNESS AMBIGUITY METRIC,0.17562452687358063,"D. On the other hand, considering that a language l performs an abstraction over D is tantamount
225"
COMPACTNESS AMBIGUITY METRIC,0.17638152914458743,"to some stimuli (s, s′) ∈D2 sharing the same utterance u = Spl(s) = Spl(s′), i.e. consisting of
226"
COMPACTNESS AMBIGUITY METRIC,0.17713853141559424,"a hash collision, meaning that the mapping Spl from D to l woud not be injective (and therefore
227"
COMPACTNESS AMBIGUITY METRIC,0.17789553368660105,"not bijective). Incidentally, the relative expressivity REl(D) cannot be maximised, leading to the
228"
COMPACTNESS AMBIGUITY METRIC,0.17865253595760788,"language l being ambiguous over D. In this consideration, we can see that the ambiguity of a
229"
COMPACTNESS AMBIGUITY METRIC,0.1794095382286147,"language (over a given dataset) can be impacted by either the extent to which an abstraction is
230"
COMPACTNESS AMBIGUITY METRIC,0.1801665404996215,"performed (meaning that most colliding states/observations are of consecutive timesteps) or the
231"
COMPACTNESS AMBIGUITY METRIC,0.1809235427706283,"extent to which the dataset is redundant (meaning #D << |D|). Therefore it is important that our
232"
COMPACTNESS AMBIGUITY METRIC,0.18168054504163514,"proposed Compactness Ambiguity Metric is built to focus on sources of ambiguities that are the
233"
COMPACTNESS AMBIGUITY METRIC,0.18243754731264195,"result of consecutive-timesteps states colliding, more than sources of ambiguities that are the result
234"
COMPACTNESS AMBIGUITY METRIC,0.18319454958364875,"of redundancy in the given dataset.
235"
COMPACTNESS AMBIGUITY METRIC,0.18395155185465556,"∀i ∈[1, N], Ti = 1 + ⌈λi · RAl(D)⌉
(2)
∀i ∈[1, N], T ′
i = 1 + ⌈λi · T⌉
(3)"
COMPACTNESS AMBIGUITY METRIC,0.18470855412566237,"∀i ∈[1, N], CA(D)Ti =
X u∈l"
COMPACTNESS AMBIGUITY METRIC,0.1854655563966692,"#δ≥Ti
D
(u)
#δD(u)
(4)"
COMPACTNESS AMBIGUITY METRIC,0.186222558667676,"Yet, in its currently proposed form, it is impacted
236"
COMPACTNESS AMBIGUITY METRIC,0.18697956093868282,"by the amount of redundancy in the dataset. In
237"
COMPACTNESS AMBIGUITY METRIC,0.18773656320968962,"order to reduce this dependence, we propose
238"
COMPACTNESS AMBIGUITY METRIC,0.18849356548069643,"to bake some invariance to redudancy-induced
239"
COMPACTNESS AMBIGUITY METRIC,0.18925056775170326,"ambiguity into the timespan-focused buckets.
240"
COMPACTNESS AMBIGUITY METRIC,0.19000757002271007,"To this end, for a given language l and dataset
241"
COMPACTNESS AMBIGUITY METRIC,0.19076457229371688,"D, we define the buckets’ related timespans in relation to the relative ambiguity RAl(D) =
1
REl(D) =
242"
COMPACTNESS AMBIGUITY METRIC,0.19152157456472368,"|D|
#Spl(D), as shown in equation 2 with λi ∈[0, 1] s.t. ∀(j, k), j < k =⇒λj < λk, and ⌈·⌉being
243"
COMPACTNESS AMBIGUITY METRIC,0.19227857683573052,"the ceiling operator. This is in lieu of defining them in relation to the maximal length T of an agent’s
244"
COMPACTNESS AMBIGUITY METRIC,0.19303557910673733,"trajectory in the environment, as shown in equation 3. More specifically, let us first acknowledge
245"
COMPACTNESS AMBIGUITY METRIC,0.19379258137774413,"decomposition of relative ambiguity over two independent quantities, one for each of its sources
246"
COMPACTNESS AMBIGUITY METRIC,0.19454958364875094,"being either abstraction or redundancy, such that RAl = RAredundancy
l
+ RAabstract
l
. Then note that
247"
COMPACTNESS AMBIGUITY METRIC,0.19530658591975775,"the relative ambiguity is equal to the mean number of consecutive timesteps, or compactness count,
248"
COMPACTNESS AMBIGUITY METRIC,0.19606358819076458,"for which a given utterance would be used when the unique utterances are uniformly distributed
249"
COMPACTNESS AMBIGUITY METRIC,0.1968205904617714,"over the dataset D. Thus, in the metric, we propose to absorb variations of relative ambiguity due to
250"
COMPACTNESS AMBIGUITY METRIC,0.1975775927327782,"redundancy by changing the metric’s bucket setup, from Equation 3 to Equation 2. Doing so, it is true
251"
COMPACTNESS AMBIGUITY METRIC,0.198334595003785,"that the metric’s bucket setup will also vary when the abstraction-induced relative ambiguity varies,
252"
COMPACTNESS AMBIGUITY METRIC,0.19909159727479184,"we remark that the metric would not build invariance to this source of relative ambiguity since it is
253"
COMPACTNESS AMBIGUITY METRIC,0.19984859954579864,"taken into accounts when sorting out the different unique utterances into their relevant bucket, based
254"
COMPACTNESS AMBIGUITY METRIC,0.20060560181680545,"on the maximal number of consecutive timesteps in which they occur, as shown in equation 4 with
255"
COMPACTNESS AMBIGUITY METRIC,0.20136260408781226,"δD : l →2N is the compactness count function that associates each utterances u ∈l to its related set
256"
COMPACTNESS AMBIGUITY METRIC,0.20211960635881907,"of compactness counts over dataset D, i.e. the set that contains numbers of consecutive timesteps
257"
COMPACTNESS AMBIGUITY METRIC,0.2028766086298259,"for which u ∈l was uttered by Spl, each time it was uttered without being uttered in the previous
258"
COMPACTNESS AMBIGUITY METRIC,0.2036336109008327,"timestep. For instance, if we consider u ∈l such that Sp−1
l
(u) = {st1, st1+1, st1+2, st2}, with
259"
COMPACTNESS AMBIGUITY METRIC,0.2043906131718395,"(t1, t2) ∈[0, T]2 such that t2 > t1 + 3, then δD(u) = {3, 1} because u occurred 2 non-consecutive
260"
COMPACTNESS AMBIGUITY METRIC,0.20514761544284632,"times over D and those occurrences lasted for, respectively, 3 and 1 consecutive timesteps, i.e. for
261"
COMPACTNESS AMBIGUITY METRIC,0.20590461771385316,"compactness counts of 3 and 1. The superscript ≥Ti in δ≥Ti
D
implies filtering of the output set based
262"
COMPACTNESS AMBIGUITY METRIC,0.20666161998485996,"on compactness counts being greater or equal to Ti. We provide in appendix C an analysis of the
263"
COMPACTNESS AMBIGUITY METRIC,0.20741862225586677,"sensitivity of our proposed metric, and in appendix E.1 experimental results that ascertain the internal
264"
COMPACTNESS AMBIGUITY METRIC,0.20817562452687358,"validity of our proposed metric, we consider a 3D room environment of MiniWorld [15], filled with 5
265"
COMPACTNESS AMBIGUITY METRIC,0.20893262679788038,"different, randomly-placed objects, as shown in a top-view perspective in Figure 1.
266"
ERELELA ARCHITECTURE,0.20968962906888722,"3.2
EReLELA Architecture
267"
ERELELA ARCHITECTURE,0.21044663133989402,"Figure 3: EReLELA architecture consisting of a stimulus/ob-
servation encoder shared between an RL agent and the speaker
and listener agents of a RG, framed as an unsupervised auxil-
iary task [31]. The language utterances outputted by the RG
speaker agent are used in a count-based exploration method
to generate intrinsic rewards for the RL agent."
ERELELA ARCHITECTURE,0.21120363361090083,"This section details the EReLELA
268"
ERELELA ARCHITECTURE,0.21196063588190764,"architecture, which stands for Ex-
269"
ERELELA ARCHITECTURE,0.21271763815291445,"ploration in Reinforcement Learning
270"
ERELELA ARCHITECTURE,0.21347464042392128,"via Emergent Language Abstractions.
271"
ERELELA ARCHITECTURE,0.2142316426949281,"As a count-based exploration method,
272"
ERELELA ARCHITECTURE,0.2149886449659349,"we present here its intra-life core
273"
ERELELA ARCHITECTURE,0.2157456472369417,"mechanism, where intrinsic reward
274"
ERELELA ARCHITECTURE,0.21650264950794854,"signals are derived from novelty at
275"
ERELELA ARCHITECTURE,0.21725965177895534,"the level of language utterances de-
276"
ERELELA ARCHITECTURE,0.21801665404996215,"scribing the current observation/state.
277"
ERELELA ARCHITECTURE,0.21877365632096896,"It relies on a hashing-like function
278"
ERELELA ARCHITECTURE,0.21953065859197576,"(cf. Appendix B), which takes the
279"
ERELELA ARCHITECTURE,0.2202876608629826,"form of the speaker agent of a refer-
280"
ERELELA ARCHITECTURE,0.2210446631339894,"ential game (RG), to turn continuous
281"
ERELELA ARCHITECTURE,0.2218016654049962,"and high-dimensional observations/s-
282"
ERELELA ARCHITECTURE,0.22255866767600302,"tates into discrete, variable-length sequences of tokens. EReLELA is built around an RL agent
283"
ERELELA ARCHITECTURE,0.22331566994700985,"augmented with an unsupervised auxiliary task, a (discriminative, here, or generative) RG, following
284"
ERELELA ARCHITECTURE,0.22407267221801666,"the UNREAL architecture from Jaderberg et al. [31], as shown in Figure 3.
285"
ERELELA ARCHITECTURE,0.22482967448902347,"We train the RG agents in a descriptive, discriminative RG with K = 256 distractors, every TRG =
286"
ERELELA ARCHITECTURE,0.22558667676003027,"32768 gathered RL observations, on a dataset DRG consisting of the most recent |DRG| = 8192
287"
ERELELA ARCHITECTURE,0.22634367903103708,"observations, among which 2048 are held-out for validation/testing-purpose, over a maximum of
288"
ERELELA ARCHITECTURE,0.22710068130204392,"NRG−epoch = 32 epochs or until they reach a validation/testing RG accuracy greater than a given
289"
ERELELA ARCHITECTURE,0.22785768357305072,"threshold accRG−thresh = 90%. Our preliminary experiments in Appendices D.1 and D.2 show,
290"
ERELELA ARCHITECTURE,0.22861468584405753,"respectively, that increasing the RG accuracy threshold accRG−thresh increases the sample-efficiency
291"
ERELELA ARCHITECTURE,0.22937168811506434,"of the EL-guided RL agent, and that the number of distractors K ∈[15, 128, 256] is critical (even
292"
ERELELA ARCHITECTURE,0.23012869038607117,"more so than the distractor sampling scheme - which we set to be uniform unless specified otherwise),
293"
ERELELA ARCHITECTURE,0.23088569265707798,"and that it correlates positively with the performance of the RL agent. More specific details about
294"
ERELELA ARCHITECTURE,0.23164269492808479,"the RG and its agents’ architectures can be found in Appendices F and G and our open-source
295"
ERELELA ARCHITECTURE,0.2323996971990916,"implementation1.
296"
EXPERIMENTS,0.2331566994700984,"4
Experiments
297"
EXPERIMENTS,0.23391370174110523,"Agents Our RL agent is optimized using the R2D2 algorithm from [34] with the Adam opti-
298"
EXPERIMENTS,0.23467070401211204,"mizer Kingma and Ba [36]. Importantly, as it aims to maximise the weighted sum of the extrinsic
299"
EXPERIMENTS,0.23542770628311885,"and intrinsic reward functions following equation 1, throughout this paper, we use λint = 0.1 and
300"
EXPERIMENTS,0.23618470855412566,"λext = 10.0 in order to make sure that the agent pursues the external goal once the exploration of
301"
EXPERIMENTS,0.23694171082513246,"the environment has highlighted it. Further details about the RL agent can be found in Appendix F.
302"
EXPERIMENTS,0.2376987130961393,"For our RG agents, we consider optimization using either the Impatient-Only or the LazImpa loss
303"
EXPERIMENTS,0.2384557153671461,"function from Rita et al. [56], but the latter is adapted to the context of a Straight-Through Gumbel-
304"
EXPERIMENTS,0.2392127176381529,"Softmax (STGS) communication channel [25, 21], as detailed in Appendix G.1, and we refer to
305"
EXPERIMENTS,0.23996971990915972,"it as STGS-LazImpa. Indeed, the LazImpa loss function has been shown to induce Zipf’s Law of
306"
EXPERIMENTS,0.24072672218016655,1HIDDEN_FOR_REVIEW_PURPOSE
EXPERIMENTS,0.24148372445117336,"Abbreviation (ZLA) in the ELs. Thus, we can investigate in the following experiments how does
307"
EXPERIMENTS,0.24224072672218017,"structural similarity between NLs and ELs affect the kind of abstractions they perform, as well as
308"
EXPERIMENTS,0.24299772899318697,"the resulting RL agent. Further details about the RG in EReLELA can be found in Appendix G.
309"
EXPERIMENTS,0.24375473126419378,"Environments. After having considered in our preliminary experiments (cf. Appendix E.4) the 2D
310"
EXPERIMENTS,0.24451173353520061,"environment MultiRoom-N7-S4, we propose below experiments in the more challenging KeyCorridor-
311"
EXPERIMENTS,0.24526873580620742,"S3-R2 environment from MiniGrid [15]. Indeed, it involves complex object manipulations, such as
312"
EXPERIMENTS,0.24602573807721423,"(distractors) object pickup/drop and door unlocking, which requires first picking up the relevantly-
313"
EXPERIMENTS,0.24678274034822104,"colored key object.
314"
EXPERIMENTS,0.24753974261922787,"Natural Language Oracles. Our implementation of a NL oracle is simply describing the visible
315"
EXPERIMENTS,0.24829674489023468,"objects in terms of their colour and shape attributes, from left to right on the agent’s perspective,
316"
EXPERIMENTS,0.24905374716124148,"whilst also taking into account object occlusions. For instance, around the end of the trajectory
317"
EXPERIMENTS,0.2498107494322483,"presented in Figure 1, the green key would be occluded by the blue cube, therefore the NL oracle
318"
EXPERIMENTS,0.2505677517032551,"would provide the description ‘blue cube red cube’ alone. We also implement colour-specific and
319"
EXPERIMENTS,0.2513247539742619,"shape-specific language oracles, which consists of filtering out from the NL oracle’s utterance the
320"
EXPERIMENTS,0.25208175624526874,"information that each of those language abstract away, i.e. removing any shape-related word in the
321"
EXPERIMENTS,0.2528387585162756,"case of the colour-specific language, and vice-versa.
322"
EXPERIMENTS,0.25359576078728235,"Hypotheses. We seek to validate the following hypotheses. Firstly, we consider whether NL
323"
ABSTRACT,0.2543527630582892,"abstractions can help for hard-exploration in RL with a simple count-based approach (H1), and refer
324"
ABSTRACT,0.25510976532929597,"to the relevant agent using NL abstractions to compute intrinsic rewards as NLA. We carry on with
325"
ABSTRACT,0.2558667676003028,"the hypothesis that ELs can be used similarly (H2), and we investigate to what extent do ELs compare
326"
ABSTRACT,0.25662376987130964,"to NLs in terms of abstraction. We would expect ELs to perform more meaningful abstractions than
327"
ABSTRACT,0.2573807721423164,"NLs (H3), in the sense that their abstractions would be more aligned with the relevant features of a
328"
ABSTRACT,0.25813777441332325,"given environment.
329"
ABSTRACT,0.25889477668433003,"Evaluation. We employ 3 random seeds for each agent. We evaluate (H1) and (H2) using both the
330"
ABSTRACT,0.25965177895533686,"success rate and the manipulation count, in the hard-exploration task of KeyCorridor-S3-R2. The
331"
ABSTRACT,0.2604087812263437,"manipulation count is a per-episode counter incremented each time an object is successfully picked
332"
ABSTRACT,0.2611657834973505,"up or dropped by the RL agent over the course of each episode. In order to evaluate both (H3.1)
333"
ABSTRACT,0.2619227857683573,"and (H3.2), we use the CAM to measure the kind of abstractions performed by ELs, and compare
334"
ABSTRACT,0.2626797880393641,"those measures with those of the oracles’ languages that we previously studied. We report the CAM
335"
ABSTRACT,0.2634367903103709,"distances between ELs and the NL, Color language, and Shape language oracles, which is computed
336"
ABSTRACT,0.26419379258137776,"as an euclidean distance in R6 by considering the N = 6 CAM scores for each timespans/thresholds
337"
ABSTRACT,0.26495079485238454,"as vectors in this space. As we remarked that an agent’s skillfullness at the task would induce very
338"
ABSTRACT,0.2657077971233914,"different trajectories (e.g. in MultiRoom-N7-S4, staying in the first room and only ever seeing the
339"
ABSTRACT,0.2664647993943982,"first door, for an unskillfull agent, as opposed to visiting multiple rooms and observing multiple
340"
ABSTRACT,0.267221801665405,"colored-doors, for a skillfull agent), we compute the oracle languages CAM scores on the exact same
341"
ABSTRACT,0.2679788039364118,"trajectories than used to compute each EL’s CAM scores.
342"
ABSTRACT,0.2687358062074186,"Figure 4: Success rate learning curve (left), computed as running averages over 1024 episodes each
time (i.e. 32 in parallel, as there are 32 actors, over 32 running average steps), and barplot (right),
along with per-episode manipulation count (middle) in KeyCorridor-S3-R2 from MiniGrid [15], for
different agents: (i) the Natural Language Abstraction agent (NLA) refers to using the NL oracle to
compute intrinsic reward, (ii) the STGS-LazImpa-β1-β2 EReLELA agents with β1 = 5 (agnostic only)
or β1 = 10 (shared and agnostic), and β2 = 1, (iii) the Impatient-Only EReLELA agents (shared and
agnostic), and (iv) the RANDOM agent referring to an ablated version of EReLELA without RG
training."
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.26949280847842544,"4.1
EReLELA learns Systematic Navigational & Manipulative Exploration Skills from
343"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.2702498107494323,"Scratch
344"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.27100681302043905,"We present in Figure 4 both the success rate of the different agents (as line plot through learning -left-,
345"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.2717638152914459,"or barplot at the end of learning -right-), and the per-episode manipulation count (middle). From
346"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.27252081756245267,"the fact that both the NLA and EReLELA agent performance converges higher or close to 80% of
347"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.2732778198334595,"success rate (except the STGS-LazImpa-10-1), we validate hypotheses (H1) and (H2), meaning that
348"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.27403482210446634,"it is possible to learn systematic exploration skills from both NL or EL abstractions with a simple
349"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.2747918243754731,"count-based exploration method, in 2D environments (cf. further evidence in Appendix D.1 with the
350"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.27554882664647995,"MultiRoom-S7-R4 environment). This result puts into perspective the directions of previous literature
351"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.27630582891748673,"designing complex exploration algorithms [9, 1].
352"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.27706283118849356,"The sample-efficiency is better for NLA than it is for most EL-based agents, except the Agnostic
353"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.2778198334595004,"STGS-LazImpa-10-1 agent, possibly because of the fact that ELs are learned online in parallel of the
354"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.2785768357305072,"RL training, as opposed to the case of NLA which makes use of a ready-to-use oracle. Concerning
355"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.279333838001514,"the most-sample-efficient Agnostic STGS-LazImpa-10-1 agent, we interpret its success to be the
356"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.2800908402725208,"result of benefiting from both a language structure ascribing to the ZLA and a performed abstraction
357"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.2808478425435276,"that is more optimal than NL oracle’s ones, because it is learned from the stimuli themselves.
358"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.28160484481453446,"Among the different Agnostic EReLELA agents, the final performance are not statistically-
359"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.28236184708554124,"significantly distinguishable, meaning that learning systematic exploration skills with EReLELA can
360"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.2831188493565481,"be done with some robustness to the anecdotical differences in qualities of the different ELs. On the
361"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.2838758516275549,"other hand, the shared/non-agnostic EReLELA agents’s performance are statistically-significantly
362"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.2846328538985617,"distinguishable from each other and from their agnostic versions, achieving lower performance or
363"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.2853898561695685,"even failing to learn anything in the case of the STGS-LazImpa-10-1 EReLELA agent. We interpret
364"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.2861468584405753,"these results as being caused by some kind of interference between the RG training and the RL
365"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.28690386071158214,"training, preventing any valuable representations from being learned in the shared observation encoder
366"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.28766086298258897,"(cf. Figure 3), thus warranting the need for future works to investigate whether a synergy can be
367"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.28841786525359575,"achieved.
368"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.2891748675246026,"Finally, acknowledging the RANDOM agent, which is the ablated version of EReLELA without
369"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.28993186979560936,"RG training, enabling still a median performance around 70% of success rate, we recall the Random
370"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.2906888720666162,"Network Distillation approach from Burda et al. [9], for they both share a randomly initialised
371"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.29144587433762303,"networked from which feedback is harvested to guide an RL agent. Thus, even more so in a 2D
372"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.2922028766086298,"environment, this ablated version is not to be confused with a lower-bound baseline but rather an
373"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.29295987887963665,"interesting ablation that enables us to show the impact of the RG training, increasing the sample-
374"
ERELELA LEARNS SYSTEMATIC NAVIGATIONAL & MANIPULATIVE EXPLORATION SKILLS FROM,0.2937168811506434,"efficiency and final performance of the resulting RL agent.
375"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.29447388342165026,"4.2
EReLELA learns Meaningful Abstractions
376"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.2952308856926571,"Regarding hypothesis (H3), we show in Figure 5 the CAM distances between the different agent’s
377"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.2959878879636639,"ELs and the natural, colour-specific, and shape-specific languages. We recall that in the KeyCorridor-
378"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.2967448902346707,"S3-R2 environment, the most important feature is object shape as the agent must pickup a key from
379"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.2975018925056775,"Figure 5: CAM distances to NL (left), Color language (middle), and Shape language (right), for
ELs brought about in KeyCorridor-S3-R2 from MiniGrid [15], with different agents: (i) the STGS-
LazImpa-β1-β2 EReLELA agents with β1 = 5 (agnostic only) or β1 = 10 (shared and agnostic), and
β2 = 1, (ii) the Impatient-Only EReLELA agents (shared and agnostic), and (iii) the RANDOM agent
referring to an ablated version of EReLELA without RG training."
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.2982588947766843,"all other distractor objects and then use it to unlock the locked door. Thus, as we observe that
380"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.29901589704769116,"most ELs’ abstractions are closer to the shape-specific language than the others, we conclude that
381"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.29977289931869794,"EReLELA learns meaningful abstractions, thus validating hypothesis (H3) (cf. Appendix E.3 for
382"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.3005299015897048,"further evidence in the context of MultiRoom-N7-S4). Further, we remark that the failing STGS-
383"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.3012869038607116,"LazImpa-10-1 EReLELA agent is indeed failing because its EL’s abstractions are not highlighting
384"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.3020439061317184,"shape features. When considering the shared/non-agnostic agents only, we can see that they require
385"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.3028009084027252,"many more RG training epochs, meaning that they reach the accuracy threshold less often than their
386"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.303557910673732,"agnostic counterparts. We take this as further evidence for our interpretation that there might be
387"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.30431491294473884,"interference between the RL objective and the RG objective.
388"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.30507191521574567,"We note that abstractions from ELs brought about in the contexts of the Agnostic STGS-LazImpa
389"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.30582891748675245,"agents and the Agnostic Impatient-Only agents are the closest to that of the shape-specific language
390"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.3065859197577593,"ones, and their evolution throughout learning are similar. Yet, the Agnostic STGS-LazImpa agents
391"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.30734292202876606,"achieves statistically-significantly better sample-efficiency (cf. Figure 7). We interpret this as being
392"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.3080999242997729,"caused by the ZLA structure of the ELs in the context of the Agnostic STGS-LazImpa agents, thus
393"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.30885692657077973,"showing that NL-like structure is impacting the kind of abstractions being performed in ways that are
394"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.3096139288417865,"yet to be unveiled by future works.
395"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.31037093111279335,"Limitations. With regards to the external validity of EReLELA, we acknowledge that the current
396"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.3111279333838001,"work only addresses a 2D environment and therefore, despite being procedurally-generated, it presents
397"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.31188493565480696,"less challenges to count-based exploration methods than in the context of 3D procedurally-generated
398"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.3126419379258138,"environments. Although we provide some results in Appendix E.3 showing that EReLELA is able
399"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.3133989401968206,"to learn meaningful abstractions in a 3D environment, we leave it to future work to ascertain the
400"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.3141559424678274,"external validity of EReLELA by testing it in a procedurally-generated 3D environment that pose
401"
ERELELA LEARNS MEANINGFUL ABSTRACTIONS,0.31491294473883424,"purely-navigational or navigational and manipulative exploration challenges.
402"
DISCUSSION,0.315669947009841,"5
Discussion
403"
DISCUSSION,0.31642694928084786,"We investigated the compacting/clustering hypothesis for ELs, questioning how do NLs and ELs
404"
DISCUSSION,0.31718395155185464,"compare in terms of the abstractions they perform over state/observation spaces. To answer this
405"
DISCUSSION,0.31794095382286147,"question, we proposed a novel metric entitled Compactness Ambiguity Metric (CAM), for which we
406"
DISCUSSION,0.3186979560938683,"analysed the sensitivity and performed internal validation.
407"
DISCUSSION,0.3194549583648751,"We then leveraged this metric to show that ELs abstractions are more meaningful than NLs ones,
408"
DISCUSSION,0.3202119606358819,"as the Emergent Communication context successfully picks up on the meaningful features of the
409"
DISCUSSION,0.3209689629068887,"environment.
410"
DISCUSSION,0.32172596517789553,"Then, we have proposed the Exploration in Reinforcement Learning via Emergent Languages
411"
ABSTRACT,0.32248296744890237,"Abstractions (EReLELA) agent, which leverages ELs abstractions to generate intrinsic motivation
412"
ABSTRACT,0.32323996971990915,"rewards for an RL agent to learn systematic exploration skills. Our experimental evidences showed
413"
ABSTRACT,0.323996971990916,"the performance of EReLELA in procedurally-generated, hard-exploration 2D environments from
414"
ABSTRACT,0.32475397426192276,"MiniGrid [15].
415"
ABSTRACT,0.3255109765329296,"Moreover, in the parallel optimization of the RG players, we evidenced how the STGS-LazImpa loss
416"
ABSTRACT,0.32626797880393643,"function, which induces EL to abide by ZLA like most NLs, impacts the kind of abstraction being
417"
ABSTRACT,0.3270249810749432,"performed compared to baseline Impatient-Only loss function, and yields better sample-efficiency for
418"
ABSTRACT,0.32778198334595005,"the RL agent training.
419"
ABSTRACT,0.3285389856169568,"Future work ought to investigate different loss functions and distractor sampling schemes, especially
420"
ABSTRACT,0.32929598788796366,"if playing discriminative RGs like here, as we expect, for instance, that sampling distractors more
421"
ABSTRACT,0.3300529901589705,"contrastively, e.g. like in Choi et al. [17], may induce the emergence of more complete, and therefore
422"
ABSTRACT,0.3308099924299773,"more meaningful ELs. By complete, we mean that the ELs would still be abstracting away details but
423"
ABSTRACT,0.3315669947009841,"also capturing more information about the underlying structure of the stimuli space, e.g. capturing
424"
ABSTRACT,0.33232399697199094,"both colour- and shape-related information of visible objects. In this light, we would also expect
425"
ABSTRACT,0.3330809992429977,"generative RGs to propose a possibly different picture that is worth investigating.
426"
ABSTRACT,0.33383800151400456,"While we leave it to subsequent work to investigate the external validity of EReLELA and whether
427"
ABSTRACT,0.33459500378501134,"it transfers similarly well to 3D environments, our results open the door to a new application
428"
ABSTRACT,0.33535200605601817,"of the principles of Emergent Communication and ELs towards influencing/shaping the learned
429"
ABSTRACT,0.336109008327025,"representations and behaviours of Embodied AI agents trained with RL.
430"
REFERENCES,0.3368660105980318,"References
431"
REFERENCES,0.3376230128690386,"[1] A. P. Badia, P. Sprechmann, A. Vitvitskyi, D. Guo, B. Piot, S. Kapturowski, O. Tieleman,
432"
REFERENCES,0.3383800151400454,"M. Arjovsky, A. Pritzel, A. Bolt, et al. Never give up: Learning directed exploration strategies.
433"
REFERENCES,0.33913701741105223,"In International Conference on Learning Representations, 2019.
434"
REFERENCES,0.33989401968205907,"[2] M. Baroni. Linguistic generalization and compositionality in modern artificial neural networks.
435"
REFERENCES,0.34065102195306585,"mar 2019. URL http://arxiv.org/abs/1904.00157.
436"
REFERENCES,0.3414080242240727,"[3] M. Bellemare, S. Srinivasan, G. Ostrovski, T. Schaul, D. Saxton, and R. Munos. Unifying
437"
REFERENCES,0.34216502649507946,"count-based exploration and intrinsic motivation. Advances in neural information processing
438"
REFERENCES,0.3429220287660863,"systems, 29, 2016.
439"
REFERENCES,0.34367903103709313,"[4] L. Biewald. Experiment tracking with weights and biases, 2020. URL https://www.wandb.
440"
REFERENCES,0.3444360333080999,"com/. Software available from wandb.com.
441"
REFERENCES,0.34519303557910674,"[5] B. Bogin, M. Geva, and J. Berant. Emergence of Communication in an Interactive World with
442"
REFERENCES,0.3459500378501135,"Consistent Speakers. sep 2018. URL http://arxiv.org/abs/1809.00549.
443"
REFERENCES,0.34670704012112036,"[6] D. Bouchacourt and M. Baroni. How agents see things: On visual representations in an emergent
444"
REFERENCES,0.3474640423921272,"language game. aug 2018. URL http://arxiv.org/abs/1808.10696.
445"
REFERENCES,0.34822104466313397,"[7] N. Brandizzi. Towards more human-like AI communication: A review of emergent communica-
446"
REFERENCES,0.3489780469341408,"tion research. Aug. 2023.
447"
REFERENCES,0.34973504920514764,"[8] H. Brighton. Compositional syntax from cultural transmission. MIT Press, Artificial, 2002.
448"
REFERENCES,0.3504920514761544,"URL https://www.mitpressjournals.org/doi/abs/10.1162/106454602753694756.
449"
REFERENCES,0.35124905374716126,"[9] Y. Burda, H. Edwards, D. Pathak, A. Storkey, T. Darrell, and A. A. Efros. Large-Scale Study of
450"
REFERENCES,0.35200605601816803,"Curiosity-Driven Learning. aug 2018. URL http://arxiv.org/abs/1808.04355.
451"
REFERENCES,0.35276305828917487,"[10] R. Chaabouni, E. Kharitonov, E. Dupoux, and M. Baroni. Anti-efficient encoding in emergent
452"
REFERENCES,0.3535200605601817,"communication. NeurIPS, may 2019. URL http://arxiv.org/abs/1905.12561.
453"
REFERENCES,0.3542770628311885,"[11] R. Chaabouni, E. Kharitonov, A. Lazaric, E. Dupoux, and M. Baroni. Word-order biases in deep-
454"
REFERENCES,0.3550340651021953,"agent emergent communication. may 2019. URL http://arxiv.org/abs/1905.12330.
455"
REFERENCES,0.3557910673732021,"[12] R. Chaabouni, E. Kharitonov, D. Bouchacourt, E. Dupoux, and M. Baroni. Compositionality
456"
REFERENCES,0.35654806964420893,"and Generalization in Emergent Languages. apr 2020. URL http://arxiv.org/abs/2004.
457"
REFERENCES,0.35730507191521577,"09124.
458"
REFERENCES,0.35806207418622255,"[13] M. S. Charikar. Similarity estimation techniques from rounding algorithms. In Proceedings of
459"
REFERENCES,0.3588190764572294,"the thiry-fourth annual ACM symposium on Theory of computing, pages 380–388, 2002.
460"
REFERENCES,0.35957607872823616,"[14] R. T. Q. Chen, X. Li, R. Grosse, and D. Duvenaud. Isolating sources of disentanglement in
461"
REFERENCES,0.360333080999243,"VAEs, 2018.
462"
REFERENCES,0.36109008327024983,"[15] M. Chevalier-Boisvert, B. Dai, M. Towers, R. de Lazcano, L. Willems, S. Lahlou, S. Pal, P. S.
463"
REFERENCES,0.3618470855412566,"Castro, and J. Terry. Minigrid & miniworld: Modular & customizable reinforcement learning
464"
REFERENCES,0.36260408781226344,"environments for goal-oriented tasks. CoRR, abs/2306.13831, 2023.
465"
REFERENCES,0.3633610900832703,"[16] K. Cho, B. Van Merriënboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, and
466"
REFERENCES,0.36411809235427706,"Y. Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine
467"
REFERENCES,0.3648750946252839,"translation. arXiv preprint arXiv:1406.1078, 2014.
468"
REFERENCES,0.36563209689629067,"[17] E. Choi, A. Lazaridou, and N. de Freitas. Compositional Obverter Communication Learning
469"
REFERENCES,0.3663890991672975,"From Raw Visual Input. apr 2018. URL http://arxiv.org/abs/1804.02341.
470"
REFERENCES,0.36714610143830434,"[18] K. Denamganaï, S. Missaoui, and J. A. Walker. Visual referential games further the emergence
471"
REFERENCES,0.3679031037093111,"of disentangled representations. arXiv preprint arXiv:2304.14511, 2023.
472"
REFERENCES,0.36866010598031795,"[19] K. Denamganaï and J. A. Walker. Referentialgym: A nomenclature and framework for language
473"
REFERENCES,0.36941710825132473,"emergence & grounding in (visual) referential games. 4th NeurIPS Workshop on Emergent
474"
REFERENCES,0.37017411052233157,"Communication, 2020.
475"
REFERENCES,0.3709311127933384,"[20] K. Denamganaï and J. A. Walker. Referentialgym: A framework for language emergence &
476"
REFERENCES,0.3716881150643452,"grounding in (visual) referential games. 4th NeurIPS Workshop on Emergent Communication,
477"
REFERENCES,0.372445117335352,"2020.
478"
REFERENCES,0.3732021196063588,"[21] K. Denamganaï and J. A. Walker. On (emergent) systematic generalisation and compositionality
479"
REFERENCES,0.37395912187736563,"in visual referential games with straight-through gumbel-softmax estimator. 4th NeurIPS
480"
REFERENCES,0.37471612414837246,"Workshop on Emergent Communication, 2020.
481"
REFERENCES,0.37547312641937924,"[22] R. Dessi, E. Kharitonov, and M. Baroni. Interpretable agent communication from scratch (with
482"
REFERENCES,0.3762301286903861,"a generic visual processor emerging on the side). May 2021.
483"
REFERENCES,0.37698713096139286,"[23] T. Eccles, Y. Bachrach, G. Lever, A. Lazaridou, and T. Graepel. Biases for emergent communi-
484"
REFERENCES,0.3777441332323997,"cation in multi-agent reinforcement learning. Dec. 2019.
485"
REFERENCES,0.3785011355034065,"[24] S. Guo, Y. Ren, S. Havrylov, S. Frank, I. Titov, and K. Smith. The emergence of compositional
486"
REFERENCES,0.3792581377744133,"languages for numeric concepts through iterated learning in neural agents. arXiv preprint
487"
REFERENCES,0.38001514004542014,"arXiv:1910.05291, 2019.
488"
REFERENCES,0.380772142316427,"[25] S. Havrylov and I. Titov. Emergence of Language with Multi-agent Games: Learning to
489"
REFERENCES,0.38152914458743376,"Communicate with Sequences of Symbols. may 2017. URL http://arxiv.org/abs/1705.
490"
REFERENCES,0.3822861468584406,"11192.
491"
REFERENCES,0.38304314912944737,"[26] I. Higgins, A. Pal, A. Rusu, L. Matthey, C. Burgess, A. Pritzel, M. Botvinick, C. Blundell,
492"
REFERENCES,0.3838001514004542,"and A. Lerchner. DARLA: Improving Zero-Shot Transfer in Reinforcement Learning. URL
493"
REFERENCES,0.38455715367146104,"https://arxiv.org/pdf/1707.08475.pdf.
494"
REFERENCES,0.3853141559424678,"[27] I. Higgins, N. Sonnerat, L. Matthey, A. Pal, C. P. Burgess, M. Botvinick, D. Hassabis, and
495"
REFERENCES,0.38607115821347465,"A. Lerchner. SCAN: Learning Abstract Hierarchical Compositional Visual Concepts. jul 2017.
496"
REFERENCES,0.38682816048448143,"URL http://arxiv.org/abs/1707.03389.
497"
REFERENCES,0.38758516275548827,"[28] I. Higgins, D. Amos, D. Pfau, S. Racaniere, L. Matthey, D. Rezende, and A. Lerchner. Towards
498"
REFERENCES,0.3883421650264951,"a Definition of Disentangled Representations. dec 2018. URL http://arxiv.org/abs/1812.
499"
REFERENCES,0.3890991672975019,"02230.
500"
REFERENCES,0.3898561695685087,"[29] S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural computation, 9(8):
501"
REFERENCES,0.3906131718395155,"1735–1780, 1997.
502"
REFERENCES,0.39137017411052233,"[30] D. Horgan, J. Quan, D. Budden, G. Barth-Maron, M. Hessel, H. Van Hasselt, and D. Silver.
503"
REFERENCES,0.39212717638152916,"Distributed prioritized experience replay. arXiv preprint arXiv:1803.00933, 2018.
504"
REFERENCES,0.39288417865253594,"[31] M. Jaderberg, V. Mnih, W. M. Czarnecki, T. Schaul, J. Z. Leibo, D. Silver, and K. Kavukcuoglu.
505"
REFERENCES,0.3936411809235428,"Reinforcement learning with unsupervised auxiliary tasks. In International Conference on
506"
REFERENCES,0.39439818319454956,"Learning Representations, 2016.
507"
REFERENCES,0.3951551854655564,"[32] N. Jaques, A. Lazaridou, E. Hughes, C. Gulcehre, P. A. Ortega, D. Strouse, J. Z. Leibo, and
508"
REFERENCES,0.3959121877365632,"N. De Freitas. Social influence as intrinsic motivation for multi-agent deep reinforcement
509"
REFERENCES,0.39666919000757,"learning. arXiv preprint arXiv:1810.08647, 2018.
510"
REFERENCES,0.39742619227857684,"[33] Y. Jiang, S. Gu, K. Murphy, and C. Finn. Language as an Abstraction for Hierarchical Deep
511"
REFERENCES,0.3981831945495837,"Reinforcement Learning. jun 2019. URL http://arxiv.org/abs/1906.07343.
512"
REFERENCES,0.39894019682059045,"[34] S. Kapturowski, G. Ostrovski, J. Quan, R. Munos, and W. Dabney. Recurrent experience replay
513"
REFERENCES,0.3996971990915973,"in distributed reinforcement learning. In International conference on learning representations,
514"
REFERENCES,0.40045420136260407,"2018.
515"
REFERENCES,0.4012112036336109,"[35] H. Kim and A. Mnih. Disentangling by factorising. arXiv preprint arXiv:1802.05983, 2018.
516"
REFERENCES,0.40196820590461774,"[36] D. P. Kingma and J. Ba.
Adam: A method for stochastic optimization.
arXiv preprint
517"
REFERENCES,0.4027252081756245,"arXiv:1412.6980, 2014.
518"
REFERENCES,0.40348221044663135,"[37] D. P. Kingma and M. Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114,
519"
REFERENCES,0.40423921271763813,"2013.
520"
REFERENCES,0.40499621498864496,"[38] S. Kirby. Learning, bottlenecks and the evolution of recursive syntax. 2002.
521"
REFERENCES,0.4057532172596518,"[39] T. Korbak, J. Zubek, Ł. Kuci´nski, P. Miło´s, and J. Ra¸czaszek-Leonardi. Developmentally
522"
REFERENCES,0.4065102195306586,"motivated emergence of compositional communication via template transfer. oct 2019. URL
523"
REFERENCES,0.4072672218016654,"http://arxiv.org/abs/1910.06079.
524"
REFERENCES,0.4080242240726722,"[40] S. Kottur, J. M. F. Moura, S. Lee, and D. Batra. Natural Language Does Not Emerge ’Naturally’
525"
REFERENCES,0.408781226343679,"in Multi-Agent Dialog. jun 2017. URL http://arxiv.org/abs/1706.08502.
526"
REFERENCES,0.40953822861468586,"[41] A. Lazaridou and M. Baroni. Emergent Multi-Agent communication in the deep learning era.
527"
REFERENCES,0.41029523088569264,"June 2020.
528"
REFERENCES,0.4110522331566995,"[42] A. Lazaridou, A. Peysakhovich, and M. Baroni. Multi-Agent Cooperation and the Emergence
529"
REFERENCES,0.4118092354277063,"of (Natural) Language. dec 2016. URL http://arxiv.org/abs/1612.07182.
530"
REFERENCES,0.4125662376987131,"[43] A. Lazaridou, K. M. Hermann, K. Tuyls, and S. Clark. Emergence of Linguistic Communication
531"
REFERENCES,0.4133232399697199,"from Referential Games with Symbolic and Pixel Input. apr 2018. URL http://arxiv.org/
532"
REFERENCES,0.4140802422407267,"abs/1804.03984.
533"
REFERENCES,0.41483724451173354,"[44] D. Lewis. Convention: A philosophical study. 1969.
534"
REFERENCES,0.4155942467827404,"[45] F. Li and M. Bowling. Ease-of-Teaching and Language Structure from Emergent Communica-
535"
REFERENCES,0.41635124905374715,"tion. jun 2019. URL http://arxiv.org/abs/1906.02403.
536"
REFERENCES,0.417108251324754,"[46] F. Locatello, S. Bauer, M. Lucic, G. Rätsch, S. Gelly, B. Schölkopf, and O. Bachem. A sober
537"
REFERENCES,0.41786525359576077,"look at the unsupervised learning of disentangled representations and their evaluation. Oct.
538"
REFERENCES,0.4186222558667676,"2020.
539"
REFERENCES,0.41937925813777444,"[47] R. Lowe, J. Foerster, Y.-L. Boureau, J. Pineau, and Y. Dauphin. On the Pitfalls of Measuring
540"
REFERENCES,0.4201362604087812,"Emergent Communication. mar 2019. URL http://arxiv.org/abs/1903.05168.
541"
REFERENCES,0.42089326267978805,"[48] M. L. Montero, C. J. Ludwig, R. P. Costa, G. Malhotra, and J. Bowers. The role of disentangle-
542"
REFERENCES,0.42165026495079483,"ment in generalisation. In International Conference on Learning Representations, 2021. URL
543"
REFERENCES,0.42240726722180166,"https://openreview.net/forum?id=qbH974jKUVy.
544"
REFERENCES,0.4231642694928085,"[49] I. Mordatch and P. Abbeel. Emergence of Grounded Compositional Language in Multi-Agent
545"
REFERENCES,0.4239212717638153,"Populations. URL https://arxiv.org/pdf/1703.04908.pdf.
546"
REFERENCES,0.4246782740348221,"[50] K. Moritz Hermann, F. Hill, S. Green, F. Wang, R. Faulkner, H. Soyer, D. Szepesvari, W. M.
547"
REFERENCES,0.4254352763058289,"Czarnecki, M. Jaderberg, D. Teplyashin, M. Wainwright, C. Apps, D. Hassabis, P. Blunsom,
548"
REFERENCES,0.4261922785768357,"and D. London.
Grounded Language Learning in a Simulated 3D World.
URL https:
549"
REFERENCES,0.42694928084784256,"//arxiv.org/pdf/1706.06551.pdf.
550"
REFERENCES,0.42770628311884934,"[51] J. Mu, V. Zhong, R. Raileanu, M. Jiang, N. Goodman, T. Rocktäschel, and E. Grefenstette.
551"
REFERENCES,0.4284632853898562,"Improving intrinsic exploration with language abstractions. Advances in Neural Information
552"
REFERENCES,0.429220287660863,"Processing Systems, 35:33947–33960, 2022.
553"
REFERENCES,0.4299772899318698,"[52] G. Ostrovski, M. G. Bellemare, A. Oord, and R. Munos. Count-based exploration with neural
554"
REFERENCES,0.4307342922028766,"density models. In International conference on machine learning, pages 2721–2730. PMLR,
555"
REFERENCES,0.4314912944738834,"2017.
556"
REFERENCES,0.43224829674489024,"[53] P.-Y. Oudeyer and F. Kaplan. How can we define intrinsic motivation? In the 8th International
557"
REFERENCES,0.43300529901589707,"Conference on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems. Lund
558"
REFERENCES,0.43376230128690385,"University Cognitive Studies, Lund: LUCS, Brighton, 2008.
559"
REFERENCES,0.4345193035579107,"[54] R. Raileanu and T. Rocktäschel. Ride: Rewarding impact-driven exploration for procedurally-
560"
REFERENCES,0.43527630582891746,"generated environments. In International Conference on Learning Representations, 2019.
561"
REFERENCES,0.4360333080999243,"[55] Y. Ren, S. Guo, M. Labeau, S. B. Cohen, and S. Kirby. Compositional Languages Emerge in a
562"
REFERENCES,0.43679031037093113,"Neural Iterated Learning Model. feb 2020. URL http://arxiv.org/abs/2002.01365.
563"
REFERENCES,0.4375473126419379,"[56] M. Rita, R. Chaabouni, and E. Dupoux. "" lazimpa"": Lazy and impatient neural agents learn to
564"
REFERENCES,0.43830431491294475,"communicate efficiently. arXiv preprint arXiv:2010.01878, 2020.
565"
REFERENCES,0.4390613171839515,"[57] K. Smith, S. Kirby, H. B. A. Life, and U. 2003. Iterated learning: A framework for the emergence
566"
REFERENCES,0.43981831945495836,"of language. Artificial Life, 9(4):371–389, 2003. URL https://www.mitpressjournals.
567"
REFERENCES,0.4405753217259652,"org/doi/abs/10.1162/106454603322694825.
568"
REFERENCES,0.441332323996972,"[58] C. Stanton and J. Clune. Deep curiosity search: Intra-life exploration can improve performance
569"
REFERENCES,0.4420893262679788,"on challenging deep reinforcement learning problems. arXiv preprint arXiv:1806.00553, 2018.
570"
REFERENCES,0.4428463285389856,"[59] X. Steenbrugge, S. Leroux, T. Verbelen, and B. Dhoedt. Improving generalization for abstract
571"
REFERENCES,0.4436033308099924,"reasoning tasks using disentangled feature representations. Nov. 2018.
572"
REFERENCES,0.44436033308099926,"[60] U. Strauss, P. Grzybek, and G. Altmann. Word length and word frequency. Springer, 2007.
573"
REFERENCES,0.44511733535200604,"[61] A. Tam, N. Rabinowitz, A. Lampinen, N. A. Roy, S. Chan, D. Strouse, J. Wang, A. Banino,
574"
REFERENCES,0.4458743376230129,"and F. Hill. Semantic exploration from language abstractions and pretrained representations.
575"
REFERENCES,0.4466313398940197,"Advances in Neural Information Processing Systems, 35:25377–25389, 2022.
576"
REFERENCES,0.4473883421650265,"[62] H. Tang, R. Houthooft, D. Foote, A. Stooke, X. Chen, Y. Duan, J. Schulman, F. De Turck, and
577"
REFERENCES,0.4481453444360333,"P. Abbeel. Exploration: A study of count-based exploration for deep reinforcement learning.
578"
REFERENCES,0.4489023467070401,"arxiv e-prints, page. arXiv preprint arXiv:1611.04717, 2016.
579"
REFERENCES,0.44965934897804694,"[63] S. van Steenkiste, F. Locatello, J. Schmidhuber, and O. Bachem. Are disentangled representa-
580"
REFERENCES,0.45041635124905377,"tions helpful for abstract visual reasoning? May 2019.
581"
REFERENCES,0.45117335352006055,"[64] Z. Wang, T. Schaul, M. Hessel, H. Hasselt, M. Lanctot, and N. Freitas. Dueling network
582"
REFERENCES,0.4519303557910674,"architectures for deep reinforcement learning. In International conference on machine learning,
583"
REFERENCES,0.45268735806207416,"pages 1995–2003. PMLR, 2016.
584"
REFERENCES,0.453444360333081,"[65] Z. Xu, M. Niethammer, and C. Raffel. Compositional generalization in unsupervised com-
585"
REFERENCES,0.45420136260408783,"positional representation learning: A study on disentanglement and emergent language. Oct.
586"
REFERENCES,0.4549583648750946,"2022.
587"
REFERENCES,0.45571536714610145,"[66] G. K. Zipf. Human behavior and the principle of least effort: An introduction to human ecology.
588"
REFERENCES,0.4564723694171082,"Ravenio Books, 2016.
589"
REFERENCES,0.45722937168811506,"NeurIPS Paper Checklist
590"
CLAIMS,0.4579863739591219,"1. Claims
591"
CLAIMS,0.4587433762301287,"Question: Do the main claims made in the abstract and introduction accurately reflect the
592"
CLAIMS,0.4595003785011355,"paper’s contributions and scope?
593"
CLAIMS,0.46025738077214234,"Answer: [Yes]
594"
CLAIMS,0.4610143830431491,"Justification: Contribution/Claim # 1, i.e. a comparison between emergent and natural lan-
595"
CLAIMS,0.46177138531415596,"guages with respect to the kind of abstractions they perform, is substantiated in Section E.1,
596"
CLAIMS,0.46252838758516274,"where we verify the internal validity of the metric we propose for quantitative compari-
597"
CLAIMS,0.46328538985616957,"son, and Section E.2 where measures using our proposed metrics on different natural or
598"
CLAIMS,0.4640423921271764,"emergent languages are presented and discussed. Contribution/Claim # 2, i.e. simple count-
599"
CLAIMS,0.4647993943981832,"based exploration methods guided by natural or emergent language abstractions are helpful
600"
CLAIMS,0.46555639666919,"for exploration in reinforcement learning over hard-exploration, procedurally-generated
601"
CLAIMS,0.4663133989401968,"environments, is substantiated in Section E.3.
602"
CLAIMS,0.46707040121120363,"Guidelines:
603"
CLAIMS,0.46782740348221047,"• The answer NA means that the abstract and introduction do not include the claims
604"
CLAIMS,0.46858440575321725,"made in the paper.
605"
CLAIMS,0.4693414080242241,"• The abstract and/or introduction should clearly state the claims made, including the
606"
CLAIMS,0.47009841029523086,"contributions made in the paper and important assumptions and limitations. A No or
607"
CLAIMS,0.4708554125662377,"NA answer to this question will not be perceived well by the reviewers.
608"
CLAIMS,0.47161241483724453,"• The claims made should match theoretical and experimental results, and reflect how
609"
CLAIMS,0.4723694171082513,"much the results can be expected to generalize to other settings.
610"
CLAIMS,0.47312641937925815,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
611"
CLAIMS,0.4738834216502649,"are not attained by the paper.
612"
LIMITATIONS,0.47464042392127176,"2. Limitations
613"
LIMITATIONS,0.4753974261922786,"Question: Does the paper discuss the limitations of the work performed by the authors?
614"
LIMITATIONS,0.4761544284632854,"Answer: [Yes]
615"
LIMITATIONS,0.4769114307342922,"Justification: We discuss limitations at the end of Section 4.
616"
LIMITATIONS,0.47766843300529904,"Guidelines:
617"
LIMITATIONS,0.4784254352763058,"• The answer NA means that the paper has no limitation while the answer No means that
618"
LIMITATIONS,0.47918243754731266,"the paper has limitations, but those are not discussed in the paper.
619"
LIMITATIONS,0.47993943981831944,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
620"
LIMITATIONS,0.48069644208932627,"• The paper should point out any strong assumptions and how robust the results are to
621"
LIMITATIONS,0.4814534443603331,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
622"
LIMITATIONS,0.4822104466313399,"model well-specification, asymptotic approximations only holding locally). The authors
623"
LIMITATIONS,0.4829674489023467,"should reflect on how these assumptions might be violated in practice and what the
624"
LIMITATIONS,0.4837244511733535,"implications would be.
625"
LIMITATIONS,0.48448145344436033,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
626"
LIMITATIONS,0.48523845571536717,"only tested on a few datasets or with a few runs. In general, empirical results often
627"
LIMITATIONS,0.48599545798637395,"depend on implicit assumptions, which should be articulated.
628"
LIMITATIONS,0.4867524602573808,"• The authors should reflect on the factors that influence the performance of the approach.
629"
LIMITATIONS,0.48750946252838756,"For example, a facial recognition algorithm may perform poorly when image resolution
630"
LIMITATIONS,0.4882664647993944,"is low or images are taken in low lighting. Or a speech-to-text system might not be
631"
LIMITATIONS,0.48902346707040123,"used reliably to provide closed captions for online lectures because it fails to handle
632"
LIMITATIONS,0.489780469341408,"technical jargon.
633"
LIMITATIONS,0.49053747161241484,"• The authors should discuss the computational efficiency of the proposed algorithms
634"
LIMITATIONS,0.4912944738834216,"and how they scale with dataset size.
635"
LIMITATIONS,0.49205147615442846,"• If applicable, the authors should discuss possible limitations of their approach to
636"
LIMITATIONS,0.4928084784254353,"address problems of privacy and fairness.
637"
LIMITATIONS,0.49356548069644207,"• While the authors might fear that complete honesty about limitations might be used by
638"
LIMITATIONS,0.4943224829674489,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
639"
LIMITATIONS,0.49507948523845574,"limitations that aren’t acknowledged in the paper. The authors should use their best
640"
LIMITATIONS,0.4958364875094625,"judgment and recognize that individual actions in favor of transparency play an impor-
641"
LIMITATIONS,0.49659348978046935,"tant role in developing norms that preserve the integrity of the community. Reviewers
642"
LIMITATIONS,0.49735049205147613,"will be specifically instructed to not penalize honesty concerning limitations.
643"
THEORY ASSUMPTIONS AND PROOFS,0.49810749432248297,"3. Theory Assumptions and Proofs
644"
THEORY ASSUMPTIONS AND PROOFS,0.4988644965934898,"Question: For each theoretical result, does the paper provide the full set of assumptions and
645"
THEORY ASSUMPTIONS AND PROOFS,0.4996214988644966,"a complete (and correct) proof?
646"
THEORY ASSUMPTIONS AND PROOFS,0.5003785011355034,"Answer: [Yes]
647"
THEORY ASSUMPTIONS AND PROOFS,0.5011355034065103,"Justification: Our only theoretical results is found in Appendix C with the full set of
648"
THEORY ASSUMPTIONS AND PROOFS,0.5018925056775171,"assumptions and a complete and correct proof.
649"
THEORY ASSUMPTIONS AND PROOFS,0.5026495079485238,"Guidelines:
650"
THEORY ASSUMPTIONS AND PROOFS,0.5034065102195306,"• The answer NA means that the paper does not include theoretical results.
651"
THEORY ASSUMPTIONS AND PROOFS,0.5041635124905375,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
652"
THEORY ASSUMPTIONS AND PROOFS,0.5049205147615443,"referenced.
653"
THEORY ASSUMPTIONS AND PROOFS,0.5056775170325511,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
654"
THEORY ASSUMPTIONS AND PROOFS,0.5064345193035579,"• The proofs can either appear in the main paper or the supplemental material, but if
655"
THEORY ASSUMPTIONS AND PROOFS,0.5071915215745647,"they appear in the supplemental material, the authors are encouraged to provide a short
656"
THEORY ASSUMPTIONS AND PROOFS,0.5079485238455715,"proof sketch to provide intuition.
657"
THEORY ASSUMPTIONS AND PROOFS,0.5087055261165784,"• Inversely, any informal proof provided in the core of the paper should be complemented
658"
THEORY ASSUMPTIONS AND PROOFS,0.5094625283875852,"by formal proofs provided in appendix or supplemental material.
659"
THEORY ASSUMPTIONS AND PROOFS,0.5102195306585919,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
660"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5109765329295988,"4. Experimental Result Reproducibility
661"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5117335352006056,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
662"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5124905374716124,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
663"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5132475397426193,"of the paper (regardless of whether the code and data are provided or not)?
664"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.514004542013626,"Answer: [Yes]
665"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5147615442846328,"Justification: All the information needed to reproduce the main experimental results and
666"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5155185465556397,"appendices experimental results are discussed both in Sections 3 or 4 for critical (and new)
667"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5162755488266465,"hyperparameters, and in Appendices G and F for hyperparameters introduced in previous
668"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5170325510976533,"works.
669"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5177895533686601,"Guidelines:
670"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5185465556396669,"• The answer NA means that the paper does not include experiments.
671"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5193035579106737,"• If the paper includes experiments, a No answer to this question will not be perceived
672"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5200605601816806,"well by the reviewers: Making the paper reproducible is important, regardless of
673"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5208175624526874,"whether the code and data are provided or not.
674"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5215745647236941,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
675"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.522331566994701,"to make their results reproducible or verifiable.
676"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5230885692657078,"• Depending on the contribution, reproducibility can be accomplished in various ways.
677"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5238455715367146,"For example, if the contribution is a novel architecture, describing the architecture fully
678"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5246025738077215,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
679"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5253595760787282,"be necessary to either make it possible for others to replicate the model with the same
680"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.526116578349735,"dataset, or provide access to the model. In general. releasing code and data is often
681"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5268735806207419,"one good way to accomplish this, but reproducibility can also be provided via detailed
682"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5276305828917487,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
683"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5283875851627555,"of a large language model), releasing of a model checkpoint, or other means that are
684"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5291445874337622,"appropriate to the research performed.
685"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5299015897047691,"• While NeurIPS does not require releasing code, the conference does require all submis-
686"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5306585919757759,"sions to provide some reasonable avenue for reproducibility, which may depend on the
687"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5314155942467828,"nature of the contribution. For example
688"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5321725965177896,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
689"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5329295987887964,"to reproduce that algorithm.
690"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5336866010598031,"(b) If the contribution is primarily a new model architecture, the paper should describe
691"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.53444360333081,"the architecture clearly and fully.
692"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5352006056018168,"(c) If the contribution is a new model (e.g., a large language model), then there should
693"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5359576078728236,"either be a way to access this model for reproducing the results or a way to reproduce
694"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5367146101438305,"the model (e.g., with an open-source dataset or instructions for how to construct
695"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5374716124148372,"the dataset).
696"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.538228614685844,"(d) We recognize that reproducibility may be tricky in some cases, in which case
697"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5389856169568509,"authors are welcome to describe the particular way they provide for reproducibility.
698"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5397426192278577,"In the case of closed-source models, it may be that access to the model is limited in
699"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5404996214988645,"some way (e.g., to registered users), but it should be possible for other researchers
700"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.5412566237698713,"to have some path to reproducing or verifying the results.
701"
OPEN ACCESS TO DATA AND CODE,0.5420136260408781,"5. Open access to data and code
702"
OPEN ACCESS TO DATA AND CODE,0.5427706283118849,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
703"
OPEN ACCESS TO DATA AND CODE,0.5435276305828918,"tions to faithfully reproduce the main experimental results, as described in supplemental
704"
OPEN ACCESS TO DATA AND CODE,0.5442846328538986,"material?
705"
OPEN ACCESS TO DATA AND CODE,0.5450416351249053,"Answer: [Yes]
706"
OPEN ACCESS TO DATA AND CODE,0.5457986373959122,"Justification: The open-access code contains a README.md file with sufficient instructions
707"
OPEN ACCESS TO DATA AND CODE,0.546555639666919,"to faithfully reproduce the main experimental results.
708"
OPEN ACCESS TO DATA AND CODE,0.5473126419379258,"Guidelines:
709"
OPEN ACCESS TO DATA AND CODE,0.5480696442089327,"• The answer NA means that paper does not include experiments requiring code.
710"
OPEN ACCESS TO DATA AND CODE,0.5488266464799394,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
711"
OPEN ACCESS TO DATA AND CODE,0.5495836487509462,"public/guides/CodeSubmissionPolicy) for more details.
712"
OPEN ACCESS TO DATA AND CODE,0.5503406510219531,"• While we encourage the release of code and data, we understand that this might not be
713"
OPEN ACCESS TO DATA AND CODE,0.5510976532929599,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
714"
OPEN ACCESS TO DATA AND CODE,0.5518546555639667,"including code, unless this is central to the contribution (e.g., for a new open-source
715"
OPEN ACCESS TO DATA AND CODE,0.5526116578349735,"benchmark).
716"
OPEN ACCESS TO DATA AND CODE,0.5533686601059803,"• The instructions should contain the exact command and environment needed to run to
717"
OPEN ACCESS TO DATA AND CODE,0.5541256623769871,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
718"
OPEN ACCESS TO DATA AND CODE,0.554882664647994,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
719"
OPEN ACCESS TO DATA AND CODE,0.5556396669190008,"• The authors should provide instructions on data access and preparation, including how
720"
OPEN ACCESS TO DATA AND CODE,0.5563966691900075,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
721"
OPEN ACCESS TO DATA AND CODE,0.5571536714610144,"• The authors should provide scripts to reproduce all experimental results for the new
722"
OPEN ACCESS TO DATA AND CODE,0.5579106737320212,"proposed method and baselines. If only a subset of experiments are reproducible, they
723"
OPEN ACCESS TO DATA AND CODE,0.558667676003028,"should state which ones are omitted from the script and why.
724"
OPEN ACCESS TO DATA AND CODE,0.5594246782740349,"• At submission time, to preserve anonymity, the authors should release anonymized
725"
OPEN ACCESS TO DATA AND CODE,0.5601816805450416,"versions (if applicable).
726"
OPEN ACCESS TO DATA AND CODE,0.5609386828160484,"• Providing as much information as possible in supplemental material (appended to the
727"
OPEN ACCESS TO DATA AND CODE,0.5616956850870553,"paper) is recommended, but including URLs to data and code is permitted.
728"
OPEN ACCESS TO DATA AND CODE,0.5624526873580621,"6. Experimental Setting/Details
729"
OPEN ACCESS TO DATA AND CODE,0.5632096896290689,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
730"
OPEN ACCESS TO DATA AND CODE,0.5639666919000756,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
731"
OPEN ACCESS TO DATA AND CODE,0.5647236941710825,"results?
732"
OPEN ACCESS TO DATA AND CODE,0.5654806964420893,"Answer: [Yes]
733"
OPEN ACCESS TO DATA AND CODE,0.5662376987130961,"Justification: All the information needed to reproduce the main experimental results and
734"
OPEN ACCESS TO DATA AND CODE,0.566994700984103,"appendices experimental results are discussed both in Sections 3 or 4 for critical (and newly-
735"
OPEN ACCESS TO DATA AND CODE,0.5677517032551098,"introduced) hyperparameters, and in Appendices G and F for hyperparameters introduced
736"
OPEN ACCESS TO DATA AND CODE,0.5685087055261165,"in previous works.
737"
OPEN ACCESS TO DATA AND CODE,0.5692657077971234,"Guidelines:
738"
OPEN ACCESS TO DATA AND CODE,0.5700227100681302,"• The answer NA means that the paper does not include experiments.
739"
OPEN ACCESS TO DATA AND CODE,0.570779712339137,"• The experimental setting should be presented in the core of the paper to a level of detail
740"
OPEN ACCESS TO DATA AND CODE,0.5715367146101439,"that is necessary to appreciate the results and make sense of them.
741"
OPEN ACCESS TO DATA AND CODE,0.5722937168811506,"• The full details can be provided either with the code, in appendix, or as supplemental
742"
OPEN ACCESS TO DATA AND CODE,0.5730507191521574,"material.
743"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5738077214231643,"7. Experiment Statistical Significance
744"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5745647236941711,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
745"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5753217259651779,"information about the statistical significance of the experiments?
746"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5760787282361847,"Answer: [Yes]
747"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5768357305071915,"Justification: All plots (barplots or line plots) contains in the title the type of information
748"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5775927327781983,"about the statistical significance of the experiments (i.e. min/median/max, meaning that the
749"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5783497350492052,"shaded area reflect the min and max values of the distribution while the bar or line reflects
750"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.579106737320212,"the median of the distribution).
751"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5798637395912187,"Guidelines:
752"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5806207418622256,"• The answer NA means that the paper does not include experiments.
753"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5813777441332324,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
754"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5821347464042392,"dence intervals, or statistical significance tests, at least for the experiments that support
755"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5828917486752461,"the main claims of the paper.
756"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5836487509462528,"• The factors of variability that the error bars are capturing should be clearly stated (for
757"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5844057532172596,"example, train/test split, initialization, random drawing of some parameter, or overall
758"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5851627554882665,"run with given experimental conditions).
759"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5859197577592733,"• The method for calculating the error bars should be explained (closed form formula,
760"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5866767600302801,"call to a library function, bootstrap, etc.)
761"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5874337623012869,"• The assumptions made should be given (e.g., Normally distributed errors).
762"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5881907645722937,"• It should be clear whether the error bar is the standard deviation or the standard error
763"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5889477668433005,"of the mean.
764"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5897047691143074,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
765"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5904617713853142,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
766"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5912187736563209,"of Normality of errors is not verified.
767"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5919757759273278,"• For asymmetric distributions, the authors should be careful not to show in tables or
768"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5927327781983346,"figures symmetric error bars that would yield results that are out of range (e.g. negative
769"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5934897804693414,"error rates).
770"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.5942467827403483,"• If error bars are reported in tables or plots, The authors should explain in the text how
771"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.595003785011355,"they were calculated and reference the corresponding figures or tables in the text.
772"
EXPERIMENTS COMPUTE RESOURCES,0.5957607872823618,"8. Experiments Compute Resources
773"
EXPERIMENTS COMPUTE RESOURCES,0.5965177895533686,"Question: For each experiment, does the paper provide sufficient information on the com-
774"
EXPERIMENTS COMPUTE RESOURCES,0.5972747918243755,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
775"
EXPERIMENTS COMPUTE RESOURCES,0.5980317940953823,"the experiments?
776"
EXPERIMENTS COMPUTE RESOURCES,0.5987887963663892,"Answer: [Yes]
777"
EXPERIMENTS COMPUTE RESOURCES,0.5995457986373959,"Justification: Section F contains sufficient information on the computer resources needed to
778"
EXPERIMENTS COMPUTE RESOURCES,0.6003028009084027,"reproduce the experiments.
779"
EXPERIMENTS COMPUTE RESOURCES,0.6010598031794095,"Guidelines:
780"
EXPERIMENTS COMPUTE RESOURCES,0.6018168054504164,"• The answer NA means that the paper does not include experiments.
781"
EXPERIMENTS COMPUTE RESOURCES,0.6025738077214232,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
782"
EXPERIMENTS COMPUTE RESOURCES,0.6033308099924299,"or cloud provider, including relevant memory and storage.
783"
EXPERIMENTS COMPUTE RESOURCES,0.6040878122634368,"• The paper should provide the amount of compute required for each of the individual
784"
EXPERIMENTS COMPUTE RESOURCES,0.6048448145344436,"experimental runs as well as estimate the total compute.
785"
EXPERIMENTS COMPUTE RESOURCES,0.6056018168054504,"• The paper should disclose whether the full research project required more compute
786"
EXPERIMENTS COMPUTE RESOURCES,0.6063588190764573,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
787"
EXPERIMENTS COMPUTE RESOURCES,0.607115821347464,"didn’t make it into the paper).
788"
CODE OF ETHICS,0.6078728236184708,"9. Code Of Ethics
789"
CODE OF ETHICS,0.6086298258894777,"Question: Does the research conducted in the paper conform, in every respect, with the
790"
CODE OF ETHICS,0.6093868281604845,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
791"
CODE OF ETHICS,0.6101438304314913,"Answer: [Yes]
792"
CODE OF ETHICS,0.6109008327024981,"Justification: The research conducted in the paper conform in every respect with the NeurIPS
793"
CODE OF ETHICS,0.6116578349735049,"Code of Ethics.
794"
CODE OF ETHICS,0.6124148372445117,"Guidelines:
795"
CODE OF ETHICS,0.6131718395155186,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
796"
CODE OF ETHICS,0.6139288417865254,"• If the authors answer No, they should explain the special circumstances that require a
797"
CODE OF ETHICS,0.6146858440575321,"deviation from the Code of Ethics.
798"
CODE OF ETHICS,0.615442846328539,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
799"
CODE OF ETHICS,0.6161998485995458,"eration due to laws or regulations in their jurisdiction).
800"
BROADER IMPACTS,0.6169568508705526,"10. Broader Impacts
801"
BROADER IMPACTS,0.6177138531415595,"Question: Does the paper discuss both potential positive societal impacts and negative
802"
BROADER IMPACTS,0.6184708554125662,"societal impacts of the work performed?
803"
BROADER IMPACTS,0.619227857683573,"Answer: [Yes]
804"
BROADER IMPACTS,0.6199848599545799,"Justification: The paper contains a Broader Impact discussion in Appendix A.
805"
BROADER IMPACTS,0.6207418622255867,"Guidelines:
806"
BROADER IMPACTS,0.6214988644965935,"• The answer NA means that there is no societal impact of the work performed.
807"
BROADER IMPACTS,0.6222558667676003,"• If the authors answer NA or No, they should explain why their work has no societal
808"
BROADER IMPACTS,0.6230128690386071,"impact or why the paper does not address societal impact.
809"
BROADER IMPACTS,0.6237698713096139,"• Examples of negative societal impacts include potential malicious or unintended uses
810"
BROADER IMPACTS,0.6245268735806208,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
811"
BROADER IMPACTS,0.6252838758516276,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
812"
BROADER IMPACTS,0.6260408781226343,"groups), privacy considerations, and security considerations.
813"
BROADER IMPACTS,0.6267978803936411,"• The conference expects that many papers will be foundational research and not tied
814"
BROADER IMPACTS,0.627554882664648,"to particular applications, let alone deployments. However, if there is a direct path to
815"
BROADER IMPACTS,0.6283118849356548,"any negative applications, the authors should point it out. For example, it is legitimate
816"
BROADER IMPACTS,0.6290688872066617,"to point out that an improvement in the quality of generative models could be used to
817"
BROADER IMPACTS,0.6298258894776685,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
818"
BROADER IMPACTS,0.6305828917486752,"that a generic algorithm for optimizing neural networks could enable people to train
819"
BROADER IMPACTS,0.631339894019682,"models that generate Deepfakes faster.
820"
BROADER IMPACTS,0.6320968962906889,"• The authors should consider possible harms that could arise when the technology is
821"
BROADER IMPACTS,0.6328538985616957,"being used as intended and functioning correctly, harms that could arise when the
822"
BROADER IMPACTS,0.6336109008327026,"technology is being used as intended but gives incorrect results, and harms following
823"
BROADER IMPACTS,0.6343679031037093,"from (intentional or unintentional) misuse of the technology.
824"
BROADER IMPACTS,0.6351249053747161,"• If there are negative societal impacts, the authors could also discuss possible mitigation
825"
BROADER IMPACTS,0.6358819076457229,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
826"
BROADER IMPACTS,0.6366389099167298,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
827"
BROADER IMPACTS,0.6373959121877366,"feedback over time, improving the efficiency and accessibility of ML).
828"
SAFEGUARDS,0.6381529144587433,"11. Safeguards
829"
SAFEGUARDS,0.6389099167297502,"Question: Does the paper describe safeguards that have been put in place for responsible
830"
SAFEGUARDS,0.639666919000757,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
831"
SAFEGUARDS,0.6404239212717638,"image generators, or scraped datasets)?
832"
SAFEGUARDS,0.6411809235427707,"Answer: [NA]
833"
SAFEGUARDS,0.6419379258137774,"Justification: The paper does release data or models that have any risk for misuses.
834"
SAFEGUARDS,0.6426949280847842,"Guidelines:
835"
SAFEGUARDS,0.6434519303557911,"• The answer NA means that the paper poses no such risks.
836"
SAFEGUARDS,0.6442089326267979,"• Released models that have a high risk for misuse or dual-use should be released with
837"
SAFEGUARDS,0.6449659348978047,"necessary safeguards to allow for controlled use of the model, for example by requiring
838"
SAFEGUARDS,0.6457229371688115,"that users adhere to usage guidelines or restrictions to access the model or implementing
839"
SAFEGUARDS,0.6464799394398183,"safety filters.
840"
SAFEGUARDS,0.6472369417108251,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
841"
SAFEGUARDS,0.647993943981832,"should describe how they avoided releasing unsafe images.
842"
SAFEGUARDS,0.6487509462528388,"• We recognize that providing effective safeguards is challenging, and many papers do
843"
SAFEGUARDS,0.6495079485238455,"not require this, but we encourage authors to take this into account and make a best
844"
SAFEGUARDS,0.6502649507948524,"faith effort.
845"
LICENSES FOR EXISTING ASSETS,0.6510219530658592,"12. Licenses for existing assets
846"
LICENSES FOR EXISTING ASSETS,0.651778955336866,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
847"
LICENSES FOR EXISTING ASSETS,0.6525359576078729,"the paper, properly credited and are the license and terms of use explicitly mentioned and
848"
LICENSES FOR EXISTING ASSETS,0.6532929598788796,"properly respected?
849"
LICENSES FOR EXISTING ASSETS,0.6540499621498864,"Answer: [NA]
850"
LICENSES FOR EXISTING ASSETS,0.6548069644208933,"Justification: Apart from the environments from MiniGrid [15], the paper does not use
851"
LICENSES FOR EXISTING ASSETS,0.6555639666919001,"existing assets.
852"
LICENSES FOR EXISTING ASSETS,0.6563209689629069,"Guidelines:
853"
LICENSES FOR EXISTING ASSETS,0.6570779712339136,"• The answer NA means that the paper does not use existing assets.
854"
LICENSES FOR EXISTING ASSETS,0.6578349735049205,"• The authors should cite the original paper that produced the code package or dataset.
855"
LICENSES FOR EXISTING ASSETS,0.6585919757759273,"• The authors should state which version of the asset is used and, if possible, include a
856"
LICENSES FOR EXISTING ASSETS,0.6593489780469342,"URL.
857"
LICENSES FOR EXISTING ASSETS,0.660105980317941,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
858"
LICENSES FOR EXISTING ASSETS,0.6608629825889477,"• For scraped data from a particular source (e.g., website), the copyright and terms of
859"
LICENSES FOR EXISTING ASSETS,0.6616199848599545,"service of that source should be provided.
860"
LICENSES FOR EXISTING ASSETS,0.6623769871309614,"• If assets are released, the license, copyright information, and terms of use in the
861"
LICENSES FOR EXISTING ASSETS,0.6631339894019682,"package should be provided. For popular datasets, paperswithcode.com/datasets
862"
LICENSES FOR EXISTING ASSETS,0.663890991672975,"has curated licenses for some datasets. Their licensing guide can help determine the
863"
LICENSES FOR EXISTING ASSETS,0.6646479939439819,"license of a dataset.
864"
LICENSES FOR EXISTING ASSETS,0.6654049962149886,"• For existing datasets that are re-packaged, both the original license and the license of
865"
LICENSES FOR EXISTING ASSETS,0.6661619984859954,"the derived asset (if it has changed) should be provided.
866"
LICENSES FOR EXISTING ASSETS,0.6669190007570023,"• If this information is not available online, the authors are encouraged to reach out to
867"
LICENSES FOR EXISTING ASSETS,0.6676760030280091,"the asset’s creators.
868"
NEW ASSETS,0.668433005299016,"13. New Assets
869"
NEW ASSETS,0.6691900075700227,"Question: Are new assets introduced in the paper well documented and is the documentation
870"
NEW ASSETS,0.6699470098410295,"provided alongside the assets?
871"
NEW ASSETS,0.6707040121120363,"Answer: [NA]
872"
NEW ASSETS,0.6714610143830432,"Justification: The paper does not release new assets.
873"
NEW ASSETS,0.67221801665405,"Guidelines:
874"
NEW ASSETS,0.6729750189250567,"• The answer NA means that the paper does not release new assets.
875"
NEW ASSETS,0.6737320211960636,"• Researchers should communicate the details of the dataset/code/model as part of their
876"
NEW ASSETS,0.6744890234670704,"submissions via structured templates. This includes details about training, license,
877"
NEW ASSETS,0.6752460257380772,"limitations, etc.
878"
NEW ASSETS,0.6760030280090841,"• The paper should discuss whether and how consent was obtained from people whose
879"
NEW ASSETS,0.6767600302800908,"asset is used.
880"
NEW ASSETS,0.6775170325510976,"• At submission time, remember to anonymize your assets (if applicable). You can either
881"
NEW ASSETS,0.6782740348221045,"create an anonymized URL or include an anonymized zip file.
882"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6790310370931113,"14. Crowdsourcing and Research with Human Subjects
883"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6797880393641181,"Question: For crowdsourcing experiments and research with human subjects, does the paper
884"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6805450416351249,"include the full text of instructions given to participants and screenshots, if applicable, as
885"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6813020439061317,"well as details about compensation (if any)?
886"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6820590461771385,"Answer: [NA]
887"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6828160484481454,"Justification: The paper does not involve experiments with human subjects nor crowdsourc-
888"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6835730507191522,"ing.
889"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6843300529901589,"Guidelines:
890"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6850870552611658,"• The answer NA means that the paper does not involve crowdsourcing nor research with
891"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6858440575321726,"human subjects.
892"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6866010598031794,"• Including this information in the supplemental material is fine, but if the main contribu-
893"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6873580620741863,"tion of the paper involves human subjects, then as much detail as possible should be
894"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.688115064345193,"included in the main paper.
895"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6888720666161998,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
896"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6896290688872067,"or other labor should be paid at least the minimum wage in the country of the data
897"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6903860711582135,"collector.
898"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6911430734292203,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
899"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.691900075700227,"Subjects
900"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6926570779712339,"Question: Does the paper describe potential risks incurred by study participants, whether
901"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6934140802422407,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
902"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6941710825132476,"approvals (or an equivalent approval/review based on the requirements of your country or
903"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6949280847842544,"institution) were obtained?
904"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6956850870552612,"Answer: [NA]
905"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6964420893262679,"Justification: The paper does not involve crowdsourcing nor research with human subjects.
906"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6971990915972748,"Guidelines:
907"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6979560938682816,"• The answer NA means that the paper does not involve crowdsourcing nor research with
908"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6987130961392884,"human subjects.
909"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6994700984102953,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
910"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.700227100681302,"may be required for any human subjects research. If you obtained IRB approval, you
911"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7009841029523088,"should clearly state this in the paper.
912"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7017411052233157,"• We recognize that the procedures for this may vary significantly between institutions
913"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7024981074943225,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
914"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7032551097653293,"guidelines for their institution.
915"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7040121120363361,"• For initial submissions, do not include any information that would break anonymity (if
916"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7047691143073429,"applicable), such as the institution conducting the review.
917"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7055261165783497,"A
Broader impact
918"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7062831188493566,"No technology is safe from being used for malicious purposes, which equally applies to our research.
919"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7070401211203634,"However, we view many of the ethical concerns surrounding research to be mitigated in the present
920"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7077971233913701,"case. These include data-related concerns such as fair use or issues surrounding use of human subjects,
921"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.708554125662377,"given that our data consists solely of simulations.
922"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7093111279333838,"With regards to the ethical aspects related to its inclusion in the field of Artificial Intelligence, we argue
923"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7100681302043906,"that our work aims to have positive outcomes on the development of human-machine interfaces since
924"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7108251324753975,"we investigate, among other things, alignment of emergent languages with natural-like languages.
925"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7115821347464042,"The current state of our work does not allow extrapolation towards negative outcomes. We believe
926"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.712339137017411,"that this work is of benefit to the research community of reinforcement learning, language emergence
927"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7130961392884179,"and grounding, in their current state.
928"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7138531415594247,"B
Further details on Count-Based Exploration
929"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7146101438304315,"Another approach to counting states from continuous and/or high-dimensional state spaces is by
930"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7153671461014383,"relying on hashing functions, so that states become tractable. Indeed, Tang et al. [62] have shown that
931"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7161241483724451,"a generalisation of classical counting techniques through hashing can provide an appropriate signal
932"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7168811506434519,"for exploration in continuous and/or high-dimensional environments where informed exploration is
933"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7176381529144588,"required. In effect, they proposed to discretise the state space S with a hash function ϕ : S →Zk,
934"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7183951551854656,"with k ∈N \ {0}, to derive an exploration bonus of the form r+(s) =
β
√"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7191521574564723,"n(ϕ(s)) where β ∈R+ is a
935"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7199091597274792,"bonus coefficient and n(.) is a count initialised at zero for the whole range of ϕ and updated at each
936"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.720666161998486,"step t of the RL loop by increasing by 1 the count n(ϕ(st)) related to the current observation/state
937"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7214231642694928,"st. Performance is dependent on the hash function ϕ, and especially in terms of granularity of the
938"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7221801665404997,"discretisation it induces. Indeed, it would be desirable that the ‘similar’ states result in hashing
939"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7229371688115064,"collisions while the ‘distant’ states would not. To this end, they propose to use locality-sensitive
940"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7236941710825132,"hashing (LSH) such as SimHash [13], resulting in the following:
941"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.72445117335352,"ϕ(s) = sgn(Ag(s)) ∈{−1, 1}k,
(5)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7252081756245269,"where sgn is the sign function, A ∈Rk×D is a matrix with each entry drawn i.i.d. from a standard
942"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7259651778955337,"Gaussian distribution, and g : S →RD is an optional preprocessing function. Note that increasing
943"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7267221801665406,"k leads to higher granularity and therefore decreases the number of hashing collisions. Tang et al.
944"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7274791824375473,"[62] reports great results on the Atari 2600 benchmarks, both with and without a learnable g that is
945"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7282361847085541,"modelled as the encoder of an autoencoder (AE).
946"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.728993186979561,"C
Sensitivity Analisys of the Compactness Ambiguity Metric
947"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7297501892505678,"Based on derivative-based local sensitivity analysis, we propose an intuitive proof of our claim that
948"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7305071915215746,"defining timespans in relation to the relative ambiguity reduces the sensibility to variations induced
949"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7312641937925813,"by redundancy-based ambiguity in the resulting metric, compared to defining timespans in relation to
950"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7320211960635882,"the the maximal length T of an agent’s trajectory in the environment. To do so, we assume:
951"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.732778198334595,"(i) that there exists two differentiable function fi.f ′
i such that for all i ∈[1, N], we have
952"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7335352006056018,"CA(D)Ti = fi(D, RAredundancy
l
, RAabstract
l
) when Ti is defined according to Equation 2,
953"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7342922028766087,"and respectively with f ′
i when using T ′
i from Equation 3, and
954"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7350492051476154,"(ii) that their partial derivatives with respect to Ti or T ′
i are negative. Indeed, Ti and T ′
i are
955"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7358062074186222,"involved into filtering operations reducing the value of the numerator in Equation 4, therefore
956"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7365632096896291,"any increase of their values would result in decreasing the overall metric output, which
957"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7373202119606359,"implies that their partial derivatives with fi and f ′
i must be negative.
958"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7380772142316427,"With those assumptions, we show that fi’s sensitivity to redundancy-induced ambiguity RAredundancy
l
959"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7388342165026495,"is less than that of f ′
i:
960"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7395912187736563,Proof.
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7403482210446631,"∂fi
∂RAredundancy
l
=
∂fi
∂CCD
·
∂CCD
∂RAredundancy
l
+ ∂fi"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.74110522331567,"∂Ti
·
∂Ti
∂RAredundancy
l"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7418622255866768,(from Assump. (i) about fi)
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7426192278576835,"⇐⇒
∂fi
∂RAredundancy
l
=
∂f ′
i
∂RAredundancy
l
+ ∂fi"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7433762301286904,"∂Ti
·
∂Ti
∂RAredundancy
l
(from Assump. (i) about f ′
i)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7441332323996972,"⇐⇒
∂fi
∂RAredundancy
l
=
∂f ′
i
∂RAredundancy
l
+ ∂fi"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.744890234670704,"∂Ti
· λi"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7456472369417109,"=⇒|
∂fi
∂RAredundancy
l
| ≤|
∂f ′
i
∂RAredundancy
l
|
(since ∂fi"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7464042392127176,∂Ti · λi ≤0 from Assump. (ii)) 961
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7471612414837244,"D
Preliminary Experiments
962"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7479182437547313,"D.1
Impact of Referential Game Accuracy
963"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7486752460257381,"In this experiments, we investigate whether the RG accuracy impacts the RL agent training, in the
964"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7494322482967449,"context of the MultiRoom-N7-S4 environment from MiniGrid [15], with an RL sampling budget of
965"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7501892505677517,"1M observations.
966"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7509462528387585,"Hypothesis. We seek to validate the following hypotheses, (PH1) : the sample-efficiency of the
967"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7517032551097653,"RL agent is dependant on the quality of the RG players, as parameterised by the accRG−thresh
968"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7524602573807722,"hyperparameter.
969"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.753217259651779,"Evaluation. We report both the success rate and the coverage count in the hard-exploration task of
970"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7539742619227857,"MultiRoom-N7-S4. To compute the coverage count, we overlay a grid of tiles over the environment’s
971"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7547312641937926,"possible locations/cells of the agents and we count the number of different tiles visited by the RL
972"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7554882664647994,"agent over the course of each episode. We use 3 random seeds for each agent. In order to evaluate the
973"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7562452687358062,"impact of the RG accuracy strictly in terms of the kind of abstractions that are being performed by the
974"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.757002271006813,"resulting EL, we use the Impatient-Only loss function (removing the impact of the hyperparameter of
975"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7577592732778198,"the scheduling function α(·) from the Lazy term of the STGS-LazImpa loss function), and we employ
976"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7585162755488266,"an agnostic version of our proposed EReLELA agent, i.e. without sharing the observation encoder
977"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7592732778198334,"between the RG players and the RL agent. We present results for two different RG accuracy
978"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7600302800908403,"threshold accRG−thresh = 60% (green) or accRG−thresh = 80% (red), and compare against, as an
979"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7607872823618471,"upper bound the Natural Language Abstraction agent (blue), which refers to using the NL oracle to
980"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.761544284632854,"compute intrinsic reward, and, as a lower bound an ablated version of EReLELA without RG training
981"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7623012869038607,"(orange).
982"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7630582891748675,"Results. We present results in Figure 6. We observe statistically significant differences between
983"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7638152914458743,"the performances (in terms of success rate, cf. Figure 6(left)) of the two EReLELA agents with
984"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7645722937168812,"accRG−thresh = 60% or accRG−thresh = 80%, thus validating hypothesis (PH1). We observe that
985"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.765329295987888,"higher RG accuracy threshold lead to higher sample-efficiency.
986"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7660862982588947,"As a sanity check, we plot the results of the ablated EReLELA agent without RG training, and we were
987"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7668433005299016,"expecting it to perform poorer than any other agent since the quality of its RG players is the lowest, at
988"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7676003028009084,"chance level. Yet, we observe that it performs on par with the best accRG−thresh = 80%-EReLELA
989"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7683573050719152,"agent. While puzzling, we propose a possible explanation in the observation that the test-time relative
990"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7691143073429221,"expressivity of the ablated agent is higher than that of the least-performing, accRG−thresh = 60%-
991"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7698713096139288,"EReLELA agent, and on par with that of the best-performing, accRG−thresh = 80%-EReLELA
992"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7706283118849356,"agent, at the beginning of the RL agent training process. Thus, we interpret this as follows: the
993"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7713853141559425,"randomly-initialised ablated agent’s EL is possibly performing an abstraction over the observation
994"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7721423164269493,"Figure 6: Success rate (left), test-time relative expressivity (middle), and per-episode coverage
count (right) in MultiRoom-N7-S4 from MiniGrid [15], computed as running averages over 256
episodes each time (i.e. 32 in parallel, as there are 32 actors, over 8 running average steps), for
different agents: (i) the Natural Language Abstraction agent (blue) refers to using the NL oracle
to compute intrinsic reward, the Agnostic Impatient-Only EReLELA agent refers to our proposed
architecture without sharing the observation encoder between the RG players and the RL agent,
using the Impatient-Only loss function to optimize the RG players, with an RG accuracy threshold
accRG−thresh = 60% (ii - green) or accRG−thresh = 80% (iii - red), and (iv) an ablated version
without RG training (orange)."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7728993186979561,"space that is good-enough for the RL agent to start learning exploration skills, the same way the
995"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7736563209689629,"random network in the context of the RND agent from Burda et al. [9] probably does, and increasing
996"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7744133232399697,"the quality of the RG players may only be a sufficient condition to increasing the sample-efficiency
997"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7751703255109765,"of the EL-guided RL agent.
998"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7759273277819834,"D.2
Impact of Referential Game Distractors
999"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7766843300529902,"In this experiments, we investigate whether the RG’s number of distractors K and distractor sampling
1000"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7774413323239969,"scheme impacts the RL agent training, in the context of the KeyCorridor-S3-R2 environment from
1001"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7781983345950038,"MiniGrid [15], with an RL sampling budget of 1M observations.
1002"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7789553368660106,"Hypothesis. We seek to validate the following hypotheses, (PH2) : the sample-efficiency of the RL
1003"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7797123391370174,"agent is dependant on the number of distractors K and the distractor sampling scheme.
1004"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7804693414080243,"Evaluation. We report the success rate in the hard-exploration task of KeyCorridor-S3-R2. We
1005"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.781226343679031,"use 3 random seeds for each agent. Like previously, we use the Impatient-Only loss function (to
1006"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7819833459500378,"remove the impact of the hyperparameter of the scheduling function α(·) from the Lazy term of
1007"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7827403482210447,"the STGS-LazImpa loss function), and we employ an agnostic version of our proposed EReLELA
1008"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7834973504920515,"agent, i.e. without sharing the observation encoder between the RG players and the RL agent.
1009"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7842543527630583,"We present results for three different number of distractors K ∈[15, 128, 256] and two different
1010"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.785011355034065,"sampling scheme between UnifDSS corresponding to uniformly sampling distractors over the whole
1011"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7857683573050719,"training dataset, or Sim50DSS corresponding to sampling distractors 50% of the time from the same
1012"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7865253595760787,"RL episode than the current target stimulus is from and, the rest of the time following UnifDSS.
1013"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7872823618470856,"Following results in Appendix D.1, we set the RG accuracy threshold accRG−thresh ∈[80%, 90%].
1014"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7880393641180924,"Results. We present results in Figure 7. We observe statistically significant differences between the
1015"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7887963663890991,"performances of the different EReLELA agents, thus validating hypothesis (PH2). Our results show
1016"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.789553368660106,"that (i) the number of distractors K is the most impactful parameter and it correlates positively with
1017"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7903103709311128,"the resulting performance, irrespective of the distractor sampling scheme used, and, indeed, (ii) while
1018"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7910673732021196,"the Sim50DSS seems to provide better performance than UnifDSS for low numbers of distractors
1019"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7918243754731265,"K = 15, although not statistically-significantly, the table is turned when considering high number of
1020"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7925813777441333,"distractors K = 256 where the UnifDSS yields statistically significantly better performance than the
1021"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.79333838001514,"Sim50DSS.
1022"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7940953822861468,"Figure 7: Final success rate barplot (left) and success rate throughout learning (right) in KeyCorridor-
S3-R2 from MiniGrid [15], computed as running averages over 1024 episodes each time (i.e. 32
in parallel, as there are 32 actors, over 32 running average steps), for the Agnostic Impatient-Only
EReLELA agent, which refers to our proposed architecture without sharing the observation encoder
between the RG players and the RL agent, using the Impatient-Only loss function to optimize
the RG players, with different number of distractors K and distractors sampling schemes: with RG
accuracy threshold accRG−thresh = 80%, (i) K = 15 and UnifDSS or Sim50DSS, (ii) K = 1128
and UnifDSS or Sim50DSS, or with RG accuracy threshold accRG−thresh = 90%, (iii) K = 256
and UnifDSS or Sim50DSS."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7948523845571537,"E
Further Experiments
1023"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7956093868281605,"E.1
Experiment #1: CAM Metric Internal Validity
1024"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7963663890991673,"Environment. We consider a 3D room environment of MiniWorld [15], where the agent’s observation
1025"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7971233913701741,"is egocentric, as a first-person viewpoint. The room is filled with 5 different, randomly-placed objects,
1026"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7978803936411809,"with different shapes (among ball, box or key) and colours (among). The dimensions simulate a 12
1027"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7986373959121877,"by 5 meters room, like shown in a top-view perspective in Figure 1.
1028"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7993943981831946,"Hypothesis. In this experiments, we seek to validate two hypotheses, (H1.1) : the Compactness
1029"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8001514004542014,"Ambiguity Metric captures something that is related to the kind of abstraction a language performs,
1030"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8009084027252081,"and (H1.2) : the Compactness Ambiguity Metric allows a graduated comparison of different kind
1031"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.801665404996215,"of abstractions being performed, meaning that it allows discrimination between different kind of
1032"
ABSTRACT,0.8024224072672218,"abstractions.
1033"
ABSTRACT,0.8031794095382286,"Evaluation. In order to compute the metric, we use 5 seeds to gather random walk trajectories in our
1034"
ABSTRACT,0.8039364118092355,"environment, for each language. In order to evaluate (H1.1), we propose to measure a language that
1035"
ABSTRACT,0.8046934140802422,"is built to present no meaningful abstractions and we expect the measure to be close to null. We build
1036"
ABSTRACT,0.805450416351249,"a language that performs no meaningful abstraction from the natural language oracles by shuffling
1037"
ABSTRACT,0.8062074186222559,"its utterances over the set of agent trajectories that are used to compute the metric, meaning that
1038"
ABSTRACT,0.8069644208932627,"the mapping between temporally-sensitive stimuli and linguistic utterances is rendered completely
1039"
ABSTRACT,0.8077214231642695,"random.
1040"
ABSTRACT,0.8084784254352763,"Then, in order to evaluate (H1.2), we show experimental evidences that the metric allows qualitative
1041"
ABSTRACT,0.8092354277062831,"discrimination between the different languages built above from the natural language oracles, which
1042"
ABSTRACT,0.8099924299772899,"are build to perform different kind of abstractions.
1043"
ABSTRACT,0.8107494322482968,"Results. We present results of the metric with N = 6 timespans in Figure 8, for λ0 = 0.0306125,
1044"
ABSTRACT,0.8115064345193036,"λ1 = 0.06125, λ2 = 0.125, λ3 = 0.25, λ4 = 0.5 and λ5 = 0.75. As the shuffled (natural) language
1045"
ABSTRACT,0.8122634367903103,"measure is almost null on all timespans/thresholds, we validate hypothesis (H1.1).
1046"
ABSTRACT,0.8130204390613172,"We observe that we can qualitatively discriminate between each evaluated language’s measures since
1047"
ABSTRACT,0.813777441332324,"the histograms are statistically different. Moreover, language abstractions scores are inversely corre-
1048"
ABSTRACT,0.8145344436033308,"lated with the amount of information being abstracted away, i.e. attribute-value-specific languages’
1049"
ABSTRACT,0.8152914458743377,"abstraction score lower than colour/shape-specific languages abstraction, which score lower than
1050"
ABSTRACT,0.8160484481453444,"natural language abstractions. Thus, we can see that the metric is graduated and that the graduation
1051"
ABSTRACT,0.8168054504163512,"follows the amount of abstraction being performed by each language. This allows us to validate
1052"
ABSTRACT,0.817562452687358,"hypothesis (H1.2).
1053"
ABSTRACT,0.8183194549583649,"Figure 8: Interval validity measures of Compactness Ambiguity Metric for N = 6 timespans/thresh-
olds, with λ0 = 0.0306125, λ1 = 0.06125, λ2 = 0.125, λ3 = 0.25, λ4 = 0.5 and λ5 = 0.75, for
different languages built to perform different kind of abstraction. We can qualitatively discriminate
between each languages, and validate that the shuffled (natural) language’s meaningless abstraction
scores almost null."
ABSTRACT,0.8190764572293717,"E.2
Experiment #2: Qualities of Emergent Languages Abstractions in 3D environment
1054"
ABSTRACT,0.8198334595003784,"In this experiment, we investigate what kind of abstractions do ELs perform over a 3D environment,
1055"
ABSTRACT,0.8205904617713853,"in comparison to some natural languages abstractions, as detailed at the beginning of Section 4. For
1056"
ABSTRACT,0.8213474640423921,"further precision, we also implement attribute-value-specific language oracles with the same filtering
1057"
ABSTRACT,0.822104466313399,"approach. For instance, for the green value on the colour attribute, we would obtain a green-only
1058"
ABSTRACT,0.8228614685844058,"language oracle whose utterances could be ‘EoS’ if no visible object is green, or ‘green green’ if there
1059"
ABSTRACT,0.8236184708554126,"are two green objects visible in the agent’s observation. We consider the same 3D room environment
1060"
ABSTRACT,0.8243754731264193,"of MiniWorld [15] as in Section E.1, i.e. the agent’s observation is egocentric, as a first-person
1061"
ABSTRACT,0.8251324753974262,"viewpoint and the room is filled with 5 different, randomly-placed objects, with different shapes
1062"
ABSTRACT,0.825889477668433,"(among ball, box or key) and colours (among). The dimensions simulate a 12 by 5 meters room, like
1063"
ABSTRACT,0.8266464799394398,"shown in a top-view perspective in Figure 1.
1064"
ABSTRACT,0.8274034822104467,"Hypothesis. We seek to validate the following hypotheses, (H2.1) : ELs build meaningful abstractions,
1065"
ABSTRACT,0.8281604844814534,"and (H2.2) : ELs brought about using the STGS-LazImpa loss function (type II) perform more
1066"
ABSTRACT,0.8289174867524602,"meaningful abstractions than Impatient-Only baseline (type I).
1067"
ABSTRACT,0.8296744890234671,"Evaluation. In order to make the CAM measures, we use 5 seeds to gather random walk trajectories
1068"
ABSTRACT,0.8304314912944739,"in our environment, for each language. In order to evaluate both (H2.1) and (H2.2), we use the CAM
1069"
ABSTRACT,0.8311884935654807,"to measure the kind of abstractions performed by ELs brought about in the two different EReLELA
1070"
ABSTRACT,0.8319454958364875,"settings, with Impatient-Only or STGS-LazImpa losses, and compare those measures with those of
1071"
ABSTRACT,0.8327024981074943,"the oracles’ languages that we previously studied.
1072"
ABSTRACT,0.8334595003785011,"Results. We present results of the metric with N = 6 timespans in Figure 9. We observe statistically
1073"
ABSTRACT,0.834216502649508,"significant differences between ELs of type I and II, with type I’s abstraction being similar to a Blue-
1074"
ABSTRACT,0.8349735049205148,"specific language’s abstraction (timespans 0 −4) or a Ball-specific language’s abstraction (timespans
1075"
ABSTRACT,0.8357305071915215,"1 −3), and type II’s abstraction not really resembling any of the oracle languages’ abstractions, but
1076"
ABSTRACT,0.8364875094625284,"still being meaningful with scores increasing along with the length of the considered timespans. Thus,
1077"
ABSTRACT,0.8372445117335352,"we validate hypothesis (H2.1), but cannot conclude on hypothesis (H2.2), unless we consider that
1078"
ABSTRACT,0.838001514004542,"CAM scores related to longer timespans are more meaningful, for instance.
1079"
ABSTRACT,0.8387585162755489,"E.3
Experiment #3: Learning Purely-Navigational Systematic Exploration Skills from
1080"
ABSTRACT,0.8395155185465556,"Scratch
1081"
ABSTRACT,0.8402725208175624,"In the following, we present an experiment in the MultiRoom-N7-S4 environment from MiniGrid [15],
1082"
ABSTRACT,0.8410295230885693,"which is possibly less challenging than KeyCorridor-S3-R2, presented in the Section 4, for it does
1083"
ABSTRACT,0.8417865253595761,"not involve as many complex object manipulation (e.g. only open/close doors, no unlocking of
1084"
ABSTRACT,0.8425435276305829,"doors – which requires the corresponding key to be firstly picked up – nor pickup/drop keys or
1085"
ABSTRACT,0.8433005299015897,"other objects as distractors), but still poses a purely-navigational hard-exploration challenge. We
1086"
ABSTRACT,0.8440575321725965,"report results on the agnostic version of our proposed EReLELA architecture, that is to say without
1087"
ABSTRACT,0.8448145344436033,"sharing the observation encoder between both RG players and the RL agent, in order to guard
1088"
ABSTRACT,0.8455715367146102,"ourselves against the impact of possible confounders found in multi-task optimization, such as possible
1089"
ABSTRACT,0.846328538985617,"Figure 9: Measures of Compactness Ambiguity Metric for N = 6 timespans/thresholds, with
λ0 = 0.0306125, λ1 = 0.06125, λ2 = 0.125, λ3 = 0.25, λ4 = 0.5 and λ5 = 0.75, comparing ELs
(Type I and II) with different oracles’ languages built to perform different kind of abstraction."
ABSTRACT,0.8470855412566237,"Figure 10: Success rate (left) and per-episode coverage count (right) in MultiRoom-N7-S4 from
MiniGrid [15], computed as running averages over 1024 episodes each time (i.e. 32 in parallel, as
there are 32 actors, over 32 running average steps), for different agents: (i) the Natural Language
Abstraction agent (NLA) refers to using the NL oracle to compute intrinsic reward, (ii) the STGS-
LazImpa EReLELA agent refers to our proposed architecture, EReLELA, using the STGS-LazImpa
loss function to optimize the RG players, and (iii) the Impatient-Only EReLELA agent refers to the
same architecture without the lazy-speaker loss to optimize the RG players."
ABSTRACT,0.8478425435276306,"interference between the RL-objective-induced gradients and the RG-training-induced gradients. We
1090"
ABSTRACT,0.8485995457986374,"use an RG accuracy threshold accRG−thresh = 65% and a number of training distractors K = 3
1091"
ABSTRACT,0.8493565480696442,"(like at testing/validation time).
1092"
ABSTRACT,0.8501135503406511,"Hypotheses.
We consider whether NL abstractions can help for a purely-navigational hard-
1093"
ABSTRACT,0.8508705526116578,"exploration task in RL with a count-based approach (H3.0), and refer to the relevant agent using
1094"
ABSTRACT,0.8516275548826646,"NL abstractions to compute intrinsic rewards as NLA. Then, we make the hypothesis that ELs can
1095"
ABSTRACT,0.8523845571536715,"be used similarly (H3.1), and we investigate to what extent do ELs compare to NLs in terms of
1096"
ABSTRACT,0.8531415594246783,"abstraction performed, in this purely-navigational task. In the case of (H3.1) being verified, we would
1097"
ABSTRACT,0.8538985616956851,"expect ELs to perform similar abstractions as NLs (H3.2).
1098"
ABSTRACT,0.8546555639666918,"Evaluation. We evaluate (H3.0) and (H3.1) using both the success rate and the coverage count.To
1099"
ABSTRACT,0.8554125662376987,"compute the coverage count, we overlay a grid of tiles over the environment’s possible locations/cells
1100"
ABSTRACT,0.8561695685087055,"of the agents and we count the number of different tiles visited by the RL agent over the course of
1101"
ABSTRACT,0.8569265707797123,"each episode. To evaluate (H3.2), we compute the CAM scores of both the ELs and the oracles’
1102"
ABSTRACT,0.8576835730507192,"natural, color-specific, and shape-specific languages. As we remarked that an agent’s skillfullness at
1103"
ABSTRACT,0.858440575321726,"the task would induce very different trajectories (e.g. in MultiRoom-N7-S4, staying in the first room
1104"
ABSTRACT,0.8591975775927327,"and only ever seeing the first door, for an unskillfull agent, as opposed to visiting multiple rooms
1105"
ABSTRACT,0.8599545798637396,"and observing multiple colored-doors, for a skillfull agent), we compute the oracle languages CAM
1106"
ABSTRACT,0.8607115821347464,"scores on the exact same trajectories than used to compute each EL’s CAM scores.
1107"
ABSTRACT,0.8614685844057532,"Results. We present in Figure 10(left) the success rate of the different agents, and the per-episode
1108"
ABSTRACT,0.8622255866767601,"coverage count in Figure 10(right).From the fact that both the NLA and EReLELA agent performance
1109"
ABSTRACT,0.8629825889477668,"converges higher or close to 80% of success rate, we validate hypotheses (H0) and (H3.1), in the
1110"
ABSTRACT,0.8637395912187736,"context of the MultiRoom-N7-S4 environment. We remark that the sample-efficiency is slightly better
1111"
ABSTRACT,0.8644965934897805,"for NLA than it is for EL-based agents, possibly because of the fact that ELs are learned online
1112"
ABSTRACT,0.8652535957607873,"in parallel of the RL training, as opposed to the case of NLA which makes use of a ready-to-use
1113"
ABSTRACT,0.8660105980317941,"oracle. Among the two EReLELA agents, the learning curves are not statistically-significantly
1114"
ABSTRACT,0.8667676003028009,"Figure 11: Performance and qualities of the ELs brought about in the context of both (i) the
STGS-LazImpa EReLELA agent, and (ii) the Impatient-Only EReLELA agent, with respect to both
the training- and validation/testing-time RG accuracy (left), the validation/test-time Instantaneous
Coordination [32, 47, 23](middle), and the validation/testing-time length of the speaker’s messages
(as a ratio over the max sentence length L = 128 - right)."
ABSTRACT,0.8675246025738077,"Figure 12: Comparison of Compactness Ambiguity Metric scores for N = 6 timespans/thresholds,
with λ0 = 0.0306125, λ1 = 0.06125, λ2 = 0.125, λ3 = 0.25, λ4 = 0.5 and λ5 = 0.75, between the
abstractions performed by ELs brought about in the context of both (i) the STGS-LazImpa EReLELA
agent (in green, first rows) and (ii) the Impatient-Only EReLELA agent (in purple, bottom rows), and
the abstractions performed by the natural, colour-specific, and shape-specific languages, computed
on the very same agent trajectories."
ABSTRACT,0.8682816048448145,"distinguishable, meaning that learning systematic exploration skills with EReLELA can be done with
1115"
ABSTRACT,0.8690386071158214,"some robustness to the anecdotical differences in qualities of the different ELs due to using different
1116"
ABSTRACT,0.8697956093868282,"optimization losses. Indeed, we also report in Figure 11 both the training- and validation/testing-time
1117"
ABSTRACT,0.8705526116578349,"RG accuracies (on the left), the validation/testing-time Instantaneous Coordination (in the middle –
1118"
ABSTRACT,0.8713096139288418,"Jaques et al. [32], Lowe et al. [47], Eccles et al. [23]), and the validation/testing-time length of the RG
1119"
ABSTRACT,0.8720666161998486,"speaker’s messages (on the right), showing that the ELs brought about in the two different contexts
1120"
ABSTRACT,0.8728236184708554,"perform differently in terms of their RG objective and have different qualities, but these discrepancies
1121"
ABSTRACT,0.8735806207418623,"do not seem to impact the RL agents learning equally well from the different abstractions they
1122"
ABSTRACT,0.874337623012869,"perform (as evidenced in the next paragraph).
1123"
ABSTRACT,0.8750946252838758,"Next, with regards to hypothesis (H3.2), we investigate whether the two contexts bring about ELs
1124"
ABSTRACT,0.8758516275548827,"that perform different abstractions, and how do these relate to the abstractions performed by natural,
1125"
ABSTRACT,0.8766086298258895,"colour-specific, and shape-specific languages, by showing in Figure 12 their CAM scores. We
1126"
ABSTRACT,0.8773656320968963,"observe that both contexts result in ELs performing abstractions similar or better than colour-specific
1127"
ABSTRACT,0.878122634367903,"languages, which is to be expected as (door) colours are the most salient features of the environment.
1128"
ABSTRACT,0.8788796366389099,"Indeed, the only two shapes or objects visible are ‘wall’ and ‘door’, whereas there are more than
1129"
ABSTRACT,0.8796366389099167,"7 different colours of interest. In the context of the Impatient-Only EReLELA agent, the EL’s
1130"
ABSTRACT,0.8803936411809236,"abstractions are scoring very similarly to NL abstractions, as we consider longer timespans (from
1131"
ABSTRACT,0.8811506434519304,"timespans #2 to #5). We could hypothesise that without the lazy-ness constraint the speaker agent
1132"
ABSTRACT,0.8819076457229371,"may be given enough capacity to compress/express information pertaining to the location of visible
1133"
ABSTRACT,0.882664647993944,"objects, as this information is the only one that is captured by the NL oracle but not captured by the
1134"
ABSTRACT,0.8834216502649508,"shape- and colour-specific languages.
1135"
ABSTRACT,0.8841786525359576,"E.4
Experiment #4: Quantifying RL Agents’ Learning Progress?
1136"
ABSTRACT,0.8849356548069645,"In the context of RGs, the speed at which a language emerges (in terms of sampled observations, or
1137"
ABSTRACT,0.8856926570779712,"number of games played) may possibly remain constant, when the data and the player architectures
1138"
ABSTRACT,0.886449659348978,"are fixed. Thus, when the data changes, the rate of language emergence may change too. Incidentally,
1139"
ABSTRACT,0.8872066616199848,"we are entitled to ponder whether some properties of the data, which here are RL trajectories, would
1140"
ABSTRACT,0.8879636638909917,"influence the rate of language emergence and how?
1141"
ABSTRACT,0.8887206661619985,"Figure 13: Relative expressivity of the EL as a function of the per-episode coverage of the RL agent,
at the end of training, over multiple runs with different hyperparameters during a W&B Sweep [4]."
ABSTRACT,0.8894776684330054,"Hypothesis. We hypothesise that as the RL agent gets more skillful, the expressivity of the emergent
1142"
ABSTRACT,0.8902346707040121,"language increases (H4.1). Indeed, at each RG training epoch, the size of the dataset is fixed, and as
1143"
ABSTRACT,0.8909916729750189,"the stimuli gets more diverse when the RL agent gets more skillful at exploring, the RG training will
1144"
ABSTRACT,0.8917486752460257,"prompt the EL to increase its expressivity.
1145"
ABSTRACT,0.8925056775170326,"Evaluation. To verify our hypothesis, we propose to measure the skillfullness of the RL agent in
1146"
ABSTRACT,0.8932626797880394,"terms of exploration using the per-episode coverage count metric, and we measure the expressivity of
1147"
ABSTRACT,0.8940196820590461,"the EL via the test-time (Relative) Expressivity after each RG training epoch.
1148"
ABSTRACT,0.894776684330053,"Results. We present results in Figure 13, that show the (relative) expressivity of the ELs does exhibit
1149"
ABSTRACT,0.8955336866010598,"variations throughout the learning process of the RL agent. And, if we perform a regression analysis
1150"
ABSTRACT,0.8962906888720666,"with each runs in terms of the per-episode coverage count of the RL agent on the x-axis and the
1151"
ABSTRACT,0.8970476911430735,"expressivity of the ELs on the y-axis, we obtain a high coefficient of determination between the two
1152"
ABSTRACT,0.8978046934140802,"metrics, R2 = 0.4642. Thus, we conclude that the (relative) expressivity of the ELs in EReLELA can
1153"
ABSTRACT,0.898561695685087,"provide a way to quantify the progress of the RL agent, at least when it comes to exploration skills.
1154"
ABSTRACT,0.8993186979560939,"Limitations. Exploration skills translates directly into diversity of the stimuli being observed, and
1155"
ABSTRACT,0.9000757002271007,"therefore it prompts any RG players to increase the expressivity of their communication protocol,
1156"
ABSTRACT,0.9008327024981075,"but it is remains to be seen whether this effect is valid in any environment. For instance, it is unclear
1157"
ABSTRACT,0.9015897047691143,"whether a skillfull player in any other video game would induce the same effect on the diversity of
1158"
ABSTRACT,0.9023467070401211,"the stimuli encountered. Thus, it is worth investigating whether this correlation holds for other genre
1159"
ABSTRACT,0.9031037093111279,"of environments and skills, which we leave to future works.
1160"
ABSTRACT,0.9038607115821348,"F
Agent Architecture
1161"
ABSTRACT,0.9046177138531416,"The ERELELA architecture is made up of three differentiable agents, the language-conditioned RL
1162"
ABSTRACT,0.9053747161241483,"agent and the two RG agents (speaker and listener). Each agent contains at least a visual/observation
1163"
ABSTRACT,0.9061317183951552,"encoder module that can be shared between agents.Both RG agents contain a language module that is
1164"
ABSTRACT,0.906888720666162,"not shared. The listener agent additionally incorporates a third decision module that combines the
1165"
ABSTRACT,0.9076457229371688,"outputs of the other two modules. The RL agent similarly incorporates a third decision module with
1166"
ABSTRACT,0.9084027252081757,"the addition that this third module contains a recurrent network, acting as core memory module for
1167"
ABSTRACT,0.9091597274791824,"the agent. Using the Straight-Through Gumbel-Softmax (STGS) approach in the communication
1168"
ABSTRACT,0.9099167297501892,"channel of the RG, the speaker agent is prompted to produce the output string of symbols with a
1169"
ABSTRACT,0.9106737320211961,"Start-of-Sentence symbol and the visual module’s output as an initial hidden state while the listener
1170"
ABSTRACT,0.9114307342922029,"agent consumes the string of symbols with the null vector as the initial hidden state. In the following
1171"
ABSTRACT,0.9121877365632097,"subsections, we detail each module architecture in depth.
1172"
ABSTRACT,0.9129447388342165,"Visual Module. The visual module f(·) consists of the Shared Observation Encoder, which can be
1173"
ABSTRACT,0.9137017411052233,"shared between all the different agents.The former consists of three blocks of convolutional layers
1174"
ABSTRACT,0.9144587433762301,"of sizes 8, 4, 3 with strides 4, 3, 1, each followed by a 2D batch normalization layer and a ReLU
1175"
ABSTRACT,0.915215745647237,"non-linear activation function. The two first convolutional layers have 32 filters, whilst the last one
1176"
ABSTRACT,0.9159727479182438,"has 64. The bias parameters of the convolutional layers are not used, as it is common when using
1177"
ABSTRACT,0.9167297501892505,"batch normalisation layers. Inputs are stimuli consisting of RGB frames of the environment resized
1178"
ABSTRACT,0.9174867524602573,"to 64 × 64.
1179"
ABSTRACT,0.9182437547312642,"Language Module. The language module g(·) consists of some learned Embedding followed by
1180"
ABSTRACT,0.919000757002271,"either a one-layer GRU network [16] in the case of the RL agent, or a one-layer LSTM network [29]
1181"
ABSTRACT,0.9197577592732779,"in the case of the RG agents. In the context of the listener agent, the input message m = (mi)i∈[1,L]
1182"
ABSTRACT,0.9205147615442847,"(produced by the speaker agent) is represented as a string of one-hot encoded vectors of dimension
1183"
ABSTRACT,0.9212717638152914,"|V | and embedded in an embedding space of dimension 64 via a learned Embedding. The output
1184"
ABSTRACT,0.9220287660862982,"of the listener agent’s language module, gl(·), is the last hidden state of the RNN layer, hl
L =
1185"
ABSTRACT,0.9227857683573051,"gL(mL, hl
L−1). In the context of the speaker agent’s language module gS(·), the output is the
1186"
ABSTRACT,0.9235427706283119,"message m = (mi)i∈[1,L] consisting of one-hot encoded vectors of dimension |V |, which are sampled
1187"
ABSTRACT,0.9242997728993188,"using the STGS approach from a categorical distribution Cat(pi) where pi = Softmax(ν(hs
i)),
1188"
ABSTRACT,0.9250567751703255,"provided ν is an affine transformation and hs
i = gs(mi−1, hs
i−1). hs
0 = f(st) is the output of the
1189"
ABSTRACT,0.9258137774413323,"visual module, given the target stimulus st.
1190"
ABSTRACT,0.9265707797123391,"Decision Module. From the RL agent to the RG’s listener agent, the decision module are very
1191"
ABSTRACT,0.927327781983346,"different since their outputs are either, respectively, in the action space A or the space of distributions
1192"
ABSTRACT,0.9280847842543528,"over K + 1 stimuli (i.e. discriminating between distractors and target stimuli). For the RL agent, the
1193"
ABSTRACT,0.9288417865253595,"decision module takes as input a concatenated vector comprising the output of visual module, after
1194"
ABSTRACT,0.9295987887963664,"it has been procesed by a 3-layer fully-connected network with 256, 128 and 64 hidden units with
1195"
ABSTRACT,0.9303557910673732,"ReLU non-linear activation functions, and some other information relevant to the RL context (e.g.
1196"
ABSTRACT,0.93111279333838,"previous reward and previous action selected, following the recipe in Kapturowski et al. [34]). The
1197"
ABSTRACT,0.9318697956093869,"resulting concatenated vector is then fed to the core memory module, a one-layer LSTM network [29]
1198"
ABSTRACT,0.9326267978803936,"with 1024 hidden units, which feeds into the advantage and value heads of a 1-layer dueling network
1199"
ABSTRACT,0.9333838001514004,"[64].
1200"
ABSTRACT,0.9341408024224073,"In the case of the RG’s listener agent, similarly to Havrylov and Titov [25], the decision module
1201"
ABSTRACT,0.9348978046934141,"builds a probability distribution over a set of K + 1 stimuli/images (s0, ..., sK), consisting of K
1202"
ABSTRACT,0.9356548069644209,"distractor stimuli and the target stimulus, provided in a random order, given a message m using the
1203"
ABSTRACT,0.9364118092354277,"scalar product:
1204"
ABSTRACT,0.9371688115064345,"p((di)i∈[0,K]|(si)i∈[0,K]; m) = Softmax

(hl
L · f(si)T )i∈[0,K]

.
(6)"
ABSTRACT,0.9379258137774413,"Regarding optimization of the RL agent, table 1 highlights the hyperparameters used for the off-policy
1205"
ABSTRACT,0.9386828160484482,"RL algorithm, R2D2[34]. More details can be found, for reproducibility purposes, in our open-source
1206"
ABSTRACT,0.939439818319455,"implementation at HIDDEN-FOR-REVIEW-PURPOSES.
1207"
ABSTRACT,0.9401968205904617,"Each run can be done on less than 2Gb of VRAM, and the amount of training time for a run, with e.g.
1208"
ABSTRACT,0.9409538228614686,"one NVIDIA GTX1080 Ti, is between 24 and 48 hours depending on the architecture (e.g. shared or
1209"
ABSTRACT,0.9417108251324754,"agnostic).
1210"
ABSTRACT,0.9424678274034822,"Table 1: Hyper-parameter values relevant to R2D2 in the EReLELA architecture presented. All
missing parameters follow the ones in Ape-X [30]. R2D2"
ABSTRACT,0.9432248296744891,"Number of actors
32
Actor update interval
1 env. step
Sequence unroll length
20
Sequence length overlap
10
Sequence burn-in length
10
N-steps return
3
Replay buffer size
1 × 104 obs.
Priority exponent
0.9"
ABSTRACT,0.9439818319454958,"Importance sampling exponent
0.6"
ABSTRACT,0.9447388342165026,"Discount γ
0.98
Minibatch size
64
Optimizer
Adam [36]
Learning rate
6.25 × 10−5"
ABSTRACT,0.9454958364875095,"Adam ϵ
10−12"
ABSTRACT,0.9462528387585163,"Target network update interval
2500
updates
Value function rescaling
None"
ABSTRACT,0.9470098410295231,"G
On the Referential Game in EReLELA
1211"
ABSTRACT,0.9477668433005298,"We follow the nomenclature proposed in Denamganaï and Walker [20] and focus on a descrip-
1212"
ABSTRACT,0.9485238455715367,"tive object-centric (partially-observable) 2-players/L = 10-signal/N = 0-round/K-distractor RG
1213"
ABSTRACT,0.9492808478425435,"variant.
1214"
ABSTRACT,0.9500378501135504,"The descriptiveness implies that the target stimulus may not be passed to the listener agent, but
1215"
ABSTRACT,0.9507948523845572,"instead replaced with a descriptive distractor. In effect, the listener agent’s decision module therefore
1216"
ABSTRACT,0.9515518546555639,"outputs a K + 2-logit distribution where the K + 2-th logit represents the meaning/prediction that a
1217"
ABSTRACT,0.9523088569265707,"descriptive distractor has been introduced and none of the K + 1 stimuli is the target stimulus that
1218"
ABSTRACT,0.9530658591975776,"the speaker agent was ‘talking’ about. The addition is made following Denamganaï et al. [18] as a
1219"
ABSTRACT,0.9538228614685844,"learnable logit value, logitno−target, it is an extra parameter of the model. In this case the decision
1220"
ABSTRACT,0.9545798637395913,"module output is no longer as specified in Equation 6, but rather as follows:
1221"
ABSTRACT,0.9553368660105981,"p((di)i∈[0,K+1]|(si)i∈[0,K]; m) = Softmax

(hl
L · f(si)T )i∈[0,K] ∪{logitno−target}

.
(7)"
ABSTRACT,0.9560938682816048,"The descriptiveneness is ideal but not necessary in order to employ the listener agent as a predicate
1222"
ABSTRACT,0.9568508705526116,"function for the hindsight experience replay scheme. Thus, in the main results of the paper, we
1223"
ABSTRACT,0.9576078728236185,"present the version without descriptiveness.
1224"
ABSTRACT,0.9583648750946253,"The object-centrism is achieved via application of data augmentation schemes before feeding stimuli
1225"
ABSTRACT,0.9591218773656321,"to any RG agent, following Dessi et al. [22] but using Gaussian Blur transformation alone, as it was
1226"
ABSTRACT,0.9598788796366389,"found sufficient in practice.
1227"
ABSTRACT,0.9606358819076457,"We optimize the RG agents with either the Impatient-Only STGS loss and the STGS-LazImpa loss.
1228"
ABSTRACT,0.9613928841786525,"In the remainder of this section, we detail the STGS-LazImpa loss that we employed to optimize the
1229"
ABSTRACT,0.9621498864496594,"referential game agents.
1230"
ABSTRACT,0.9629068887206662,"G.1
STGS-LazImpa Loss
1231"
ABSTRACT,0.9636638909916729,"Emergent languages rarely bears the core properties of natural languages [40, 6, 43, 12], such as
1232"
ABSTRACT,0.9644208932626798,"Zipf’s law of Abbreviation (ZLA). In the context of natural languages, this is an empirical law which
1233"
ABSTRACT,0.9651778955336866,"states that the more frequent a word is, the shorter it tends to be [66, 60]. Rita et al. [56] proposed
1234"
ABSTRACT,0.9659348978046934,"LazImpa in order to make emergent languages follow ZLA.
1235"
ABSTRACT,0.9666919000757003,"To do so, Lazimpa adds to the speaker and listener agents some constraints to make the speaker
1236"
ABSTRACT,0.967448902346707,"lazy and the listener impatient. Thus, denoting those constraints as LST GS−lazy and Limpatient, we
1237"
ABSTRACT,0.9682059046177138,"obtain the STGS-LazImpa loss as follows:
1238"
ABSTRACT,0.9689629068887207,"LST GS−LazImpa(m, (si)i∈[0,K]) = LST GS−lazy(m) + Limpatient(m, (si)i∈[0,K]).
(8)"
ABSTRACT,0.9697199091597275,"In the following, we detail those two constraints.
1239"
ABSTRACT,0.9704769114307343,"Lazy Speaker. The Lazy Speaker agent has the same architecture as common speakers. The
1240"
ABSTRACT,0.9712339137017411,"‘Laziness’ is originally implemented as a cost on the length of the message m directly applied to the
1241"
ABSTRACT,0.9719909159727479,"loss, of the following form:
1242"
ABSTRACT,0.9727479182437547,"Llazy(m) = α(acc) · |m|
(9)
where acc represents the current accuracy estimates of the referential games being played, and α
1243"
ABSTRACT,0.9735049205147616,"is a scheduling function as follows: α : accuracy ∈[0, 1] 7→accuracyβ1"
ABSTRACT,0.9742619227857684,"β2
, with (β1, β2) = (45, 10).
1244"
ABSTRACT,0.9750189250567751,"It is aimed to adaptively penalize depending on the message length. Since the lazyness loss is
1245"
ABSTRACT,0.975775927327782,"not differentiable, they ought to employ a REINFORCE-based algorithm for the purpose of credit
1246"
ABSTRACT,0.9765329295987888,"assignement of the speaker agent.
1247"
ABSTRACT,0.9772899318697956,"In this work, we use the STGS communication channel, which has been shown to be more sample-
1248"
ABSTRACT,0.9780469341408025,"efficient than REINFORCE-based algorithms [25], but it requires the loss functions to be differen-
1249"
ABSTRACT,0.9788039364118092,"tiable. Therefore, we modify the lazyness loss by taking inspiration from the variational autoencoders
1250"
ABSTRACT,0.979560938682816,"(VAE) literature [37].
1251"
ABSTRACT,0.9803179409538229,"The length of the speaker’s message is controlled by the appearance of the EoS token, wherever
1252"
ABSTRACT,0.9810749432248297,"it appears during the message generation process that is where the message is complete and its
1253"
ABSTRACT,0.9818319454958365,"length is fixed. Symbols of the message at each position are sampled from a distribution over all
1254"
ABSTRACT,0.9825889477668432,"the tokens in the vocabulary that the listener agent outputs. Let (Wl) be this distribution over all
1255"
ABSTRACT,0.9833459500378501,"tokens w ∈V at position l ∈[1, L], such that ∀l ∈[1, L], ml ∼(Wl). We devise the lazyness loss
1256"
ABSTRACT,0.9841029523088569,"as a Kullbach-Leibler divergence DKL(·|·) between these distribution and the distribution (WEoS)
1257"
ABSTRACT,0.9848599545798638,"which attributes all its weight on the EoS token. Thus, we dissuade the listener agent from outputting
1258"
ABSTRACT,0.9856169568508706,"distributions over tokens that deviate too much from the EoS-focused distribution (WEoS), at each
1259"
ABSTRACT,0.9863739591218774,"position l with varying coefficients β(l). The coefficient function β : [1, L] →R must be monotically
1260"
ABSTRACT,0.9871309613928841,"increasing. We obtain our STGS-lazyness loss as follows:
1261"
ABSTRACT,0.987887963663891,"LST GS−lazy(m) = α(acc) ·
X"
ABSTRACT,0.9886449659348978,"l∈[1,L]
β(l)DKL

(WEoS)|(Wl)

(10)"
ABSTRACT,0.9894019682059046,"Impatient Listener. Our implementation of the Impatient Listener agent follows the original work
1262"
ABSTRACT,0.9901589704769115,"of Rita et al. [56]: it is designed to guess the target stimulus as soon as possible, rather than solely
1263"
ABSTRACT,0.9909159727479182,"upon reading the EoS token at the end of the speaker’s message m. Thus, following Equation 6, the
1264"
ABSTRACT,0.991672975018925,"Impatient Listener agent outputs a probability distribution over a set of K + 1 stimuli (s0, ..., sK) for
1265"
ABSTRACT,0.9924299772899319,"all sub-parts/prefixes of the message m = (m1, ..., ml)l∈[1,L] = (m≤l)l∈[1,L] :
1266"
ABSTRACT,0.9931869795609387,"∀l ∈[1, L], p((d≤l
i )i∈[0,K]|(si)i∈[0,K]; m≤l) = Softmax

(h≤l · f(si)T )i∈[0,K]

,
(11)"
ABSTRACT,0.9939439818319455,"where h≤l is the hidden state/output of the recurrent network in the language module after consuming
1267"
ABSTRACT,0.9947009841029523,"tokens of the message from position 1 to position l included.
1268"
ABSTRACT,0.9954579863739591,"Thus, we obtain a sequence of L probability distributions, which can each be contrasted, using the
1269"
ABSTRACT,0.9962149886449659,"loss of the user’s choice, against the target distribution (Dtarget) attributing all its weights on the
1270"
ABSTRACT,0.9969719909159728,"decision dtarget where the target stimulus was presented to the listener agent. Here, we employ
1271"
ABSTRACT,0.9977289931869796,"Havrylov and Titov [25]’s Hinge loss. Denoting it as L(·), we obtain the impatient loss as follows:
1272"
ABSTRACT,0.9984859954579863,"Limpatient/L(m, (si)i∈[0,K]) = 1 L X"
ABSTRACT,0.9992429977289932,"l∈[1,L]
L((d≤l
i∈[0,K], (Dtarget)).
(12)"
