Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0019342359767891683,"Numerous scientific and technological challenges arise in the context of optimiza-
1"
ABSTRACT,0.0038684719535783366,"tion, particularly, black-box optimization within high-dimensional spaces presents
2"
ABSTRACT,0.005802707930367505,"significant challenges. Recent investigations into neural network-based black-box
3"
ABSTRACT,0.007736943907156673,"optimization have shown promising results. However, the effectiveness of these
4"
ABSTRACT,0.009671179883945842,"methods in navigating high-dimensional search spaces remains limited. In this
5"
ABSTRACT,0.01160541586073501,"study, we propose a black-box optimization method that combines an evolution-
6"
ABSTRACT,0.013539651837524178,"ary strategy (ES) with a generative surrogate neural network (GSN) model. This
7"
ABSTRACT,0.015473887814313346,"integrated model is designed to function in a complementary manner, where ES
8"
ABSTRACT,0.017408123791102514,"addresses the instability inherent in surrogate neural network learning associated
9"
ABSTRACT,0.019342359767891684,"with GSN models, and GSN improves the mutation efficiency of ES. Based on
10"
ABSTRACT,0.02127659574468085,"our experimental findings, this approach outperforms both classical optimization
11"
ABSTRACT,0.02321083172147002,"techniques and standalone GSN models.
12"
INTRODUCTION,0.025145067698259187,"1
Introduction
13"
INTRODUCTION,0.027079303675048357,"Black-box optimization plays a vital role in both science and technology; however, it has long been
14"
INTRODUCTION,0.029013539651837523,"an unresolved problem particularly for high dimensional problems. While low-dimensional problems,
15"
INTRODUCTION,0.030947775628626693,"which have dimensions lesser than 100, can be optimized easily, high-dimensional optimization
16"
INTRODUCTION,0.03288201160541586,"problems pose more significant challenges. In specific cases, such as convex functions, classical
17"
INTRODUCTION,0.03481624758220503,"algorithms such as Evolution Strategies (ES) [7–20] and others [4–6] can efficiently tackle high-
18"
INTRODUCTION,0.0367504835589942,"dimensional optimization problems. However, their efficiency tends to decline rapidly when faced
19"
INTRODUCTION,0.03868471953578337,"with general black-box problems characterized by high dimensionality and non-convexity.
20"
INTRODUCTION,0.04061895551257253,"Furthermore, in high-dimensional optimization problems, the number of function calls inevitably
21"
INTRODUCTION,0.0425531914893617,"grows proportionally with the dimension size. Consequently, maintaining O(N) time complexity is
22"
INTRODUCTION,0.04448742746615087,"crucial in preventing the optimization process from failing owing to rapidly increasing computation
23"
INTRODUCTION,0.04642166344294004,"time. In this context, algorithms such as the Bayesian optimization [1–3], which exhibit non-linear
24"
INTRODUCTION,0.048355899419729204,"complexity, are at a significant disadvantage. Conversely, neural networks offer a promising solution
25"
INTRODUCTION,0.05029013539651837,"to this problem. The field of artificial intelligence has demonstrated their considerable benefits in
26"
INTRODUCTION,0.05222437137330754,"managing data within high-dimensional spaces, such as images or language models, while preserving
27"
INTRODUCTION,0.05415860735009671,"linear time complexity.
28"
INTRODUCTION,0.05609284332688588,"Recently, GSN-based approaches, inspired by Generative Adversarial Networks (GANs) [30–32],
29"
INTRODUCTION,0.058027079303675046,"have emerged to tackle the black-box optimization problem, offering a novel solution for high-
30"
INTRODUCTION,0.059961315280464215,"dimensional, non-convex problems. However, in contrast to GANs, Generative Surrogate Neural
31"
INTRODUCTION,0.061895551257253385,"networks (GSNs) face a significant challenge with learning stability in the surrogate model, and the
32"
INTRODUCTION,0.06382978723404255,"performance of GSN-like algorithms remains limited to just hundreds of dimensions.
33"
INTRODUCTION,0.06576402321083172,"Hence, addressing the training instability problem is crucial for enhancing the performance of GSN-
34"
INTRODUCTION,0.06769825918762089,"based algorithms[21, 29]. Our research aligns with this perspective, and in this work, we introduce
35"
INTRODUCTION,0.06963249516441006,"a method called Generative Evolutionary Optimization (GEO). GEO arises from the cooperative
36"
INTRODUCTION,0.07156673114119923,"interaction between two linear complexity algorithms, ES and GSN. Furthermore, ES contributes to
37"
INTRODUCTION,0.0735009671179884,"the stability of the surrogate network training for GSN while GSN enhances the mutation efficiency
38"
INTRODUCTION,0.07543520309477757,"of ES, leading to their complementary functioning.
39"
INTRODUCTION,0.07736943907156674,"In this study, we designed an algorithm to accomplish five goals: optimizing non-convex, high-
40"
INTRODUCTION,0.07930367504835589,"dimensional, multi-objective, and stochastic target functions, while preserving O(N) complexity.
41"
INTRODUCTION,0.08123791102514506,"In the following chapters, we explore GEO’s design and the methodologies used in addressing its most
42"
INTRODUCTION,0.08317214700193423,"significant challenge: training instability. The Related works chapter discusses two prior works, Local
43"
INTRODUCTION,0.0851063829787234,"Generative Surrogate Optimization (L-GSO) [21] and Evolutionary Generative Adversarial Network
44"
INTRODUCTION,0.08704061895551257,"(EGAN) [22], which serve as the foundation for GEO’s core concepts. In addition, emphasis on the
45"
INTRODUCTION,0.08897485493230174,"importance of the generator network is also discussed. The Methods chapter, we combines ideas from
46"
INTRODUCTION,0.09090909090909091,"L-GSO and EGAN studies to clarify the aspects of GSN that require improvement and how they can
47"
INTRODUCTION,0.09284332688588008,"be addressed. The Results chapter presents the findings from the test function experiments. Because
48"
INTRODUCTION,0.09477756286266925,"GEO is a combination of ES and GSN, we assume a close relationship with ES, and therefore compare
49"
INTRODUCTION,0.09671179883945841,"it against non-convex test functions commonly used in ES, such as ZDT [42], Styblinski-Tang [41],
50"
INTRODUCTION,0.09864603481624758,"Rosenbrock [39, 40], Rastrigin [35–37], and Ackley [38] test functions. The experimental results
51"
INTRODUCTION,0.10058027079303675,"show that GEO outperforms traditional ES and GSN as dimensionality increases, thus enabling
52"
INTRODUCTION,0.10251450676982592,"optimizations of approximately 10,000 dimensions.
53"
INTRODUCTION,0.10444874274661509,"As mentioned earlier, we excluded non-linear algorithms from the comparison because our aim is to
54"
INTRODUCTION,0.10638297872340426,"maintain O(N) complexity. This makes a direct comparison with Bayesian optimization, another
55"
INTRODUCTION,0.10831721470019343,"significant branch of black-box optimization, difficult. Consequently, the issue is revisited in the
56"
INTRODUCTION,0.1102514506769826,"Conclusion chapter.
57"
RELATED WORKS,0.11218568665377177,"2
Related works
58"
RELATED WORKS,0.11411992263056092,"Before delving into the structure of GEO, we will first introduce some related works, focusing
59"
RELATED WORKS,0.11605415860735009,"on GSN and GAN algorithms. By examining earlier optimization approaches that utilized neural
60"
RELATED WORKS,0.11798839458413926,"networks, we can gain valuable insights. As GEO is inspired by an L-GSO study (a type of GSN) and
61"
RELATED WORKS,0.11992263056092843,"an EGAN study (a type of GAN), we will provide a brief overview of both algorithms, discussing
62"
RELATED WORKS,0.1218568665377176,"their strengths and weaknesses for a better understanding.
63"
L-GSO,0.12379110251450677,"2.1
L-GSO
64"
L-GSO,0.12572533849129594,"Local Generative Surrogate Optimization (L-GSO) is a type of GSN that approaches the problem
65"
L-GSO,0.1276595744680851,"using a local surrogate network and a local gradient. To better understand this, let’s think of a situation
66"
L-GSO,0.12959381044487428,"where we need to optimize a target function F(x) within an optimization space x ∈X and find the
67"
L-GSO,0.13152804642166344,"best point x. If we identify x0 as the optimal point at some stage, L-GSO samples the local space
68"
L-GSO,0.13346228239845262,"around x0 and calculates pairs [x′, F(x′)], where x′ = x0 + ϵ and |ϵ| << 1. It is important that ϵ is
69"
L-GSO,0.13539651837524178,"sufficiently small so that we only sample within a space close to x0. From this data, L-GSO trains
70"
L-GSO,0.13733075435203096,"a surrogate network, C, which acts as a local surrogate model with information around x0 and can
71"
L-GSO,0.13926499032882012,"generate a local gradient. After training the surrogate network, the generator network G is trained
72"
L-GSO,0.14119922630560927,"using C. Let p = C(G(z)), where x = G(z) and z is an input seed. G is trained with a loss function
73"
L-GSO,0.14313346228239845,"∓p that either increases or decreases the prediction p. Finally, the trained generator suggests a search
74"
L-GSO,0.1450676982591876,"point x, and the iterative process continues.
75"
L-GSO,0.1470019342359768,"This way, G is trained to be a generator that produces optimal (or near-optimal) points x, assuming
76"
L-GSO,0.14893617021276595,"that C simulates the local distribution accurately enough. Meanwhile, as the data points are focused
77"
L-GSO,0.15087040618955513,"within a localized area, the surrogate network can benefit from a stable training data region, which
78"
L-GSO,0.1528046421663443,"enables accurate gradient prediction. Another advantage is that the data information is retained in the
79"
L-GSO,0.15473887814313347,"surrogate network C, allowing lesser amount of data generation required when predicting the local
80"
L-GSO,0.15667311411992263,"gradient at new points.
81"
L-GSO,0.15860735009671179,"Although the approach of utilizing GSNs in L-GSO is quite innovative, it does have some limitations.
82"
L-GSO,0.16054158607350097,"The primary constraint is that it is only applicable to single-objective function problems. The optimal
83"
L-GSO,0.16247582205029013,"point x0 mentioned earlier is just a single point. However, if the optimal points (the Pareto front)
84"
L-GSO,0.1644100580270793,"consist of multiple points, the distance between these optimal points and the data sampling space
85"
L-GSO,0.16634429400386846,"(which the surrogate network must learn) will no longer be local. This undermines the fundamental
86"
L-GSO,0.16827852998065765,"premise of L-GSO. Hence, the challenge is that the optimal point of an n-objective function features
87"
L-GSO,0.1702127659574468,"a Pareto front in n −1 dimensions. For example, in a two-objective function, the Pareto front
88"
L-GSO,0.172147001934236,"forms a line, typically containing infinitely many non-dominated points that are distant from one
89"
L-GSO,0.17408123791102514,"another. Consequently, the locality of L-GSO becomes unsuitable for n-objective problems that
90"
L-GSO,0.1760154738878143,"require non-dominated sorting [58, 59].
91"
L-GSO,0.17794970986460348,"The second problem with this algorithm is that its performance may be significantly influenced by
92"
L-GSO,0.17988394584139264,"the interaction between the hyperparameters and the test function. Specifically, the combination
93"
L-GSO,0.18181818181818182,"of the sampling hypercube size ϵ and the test function characteristics can significantly impact the
94"
L-GSO,0.18375241779497098,"algorithm’s optimization performance. For instance, if the test function is convex, estimating the
95"
L-GSO,0.18568665377176016,"local gradient with any ϵ is generally not a problem; however, this can often be challenging for
96"
L-GSO,0.18762088974854932,"non-convex functions. Around the local optimum, if ϵ is smaller than the size of the localized well,
97"
L-GSO,0.1895551257253385,"the algorithm can hardly escape the local optimum. Conversely, if ϵ is too large, the local gradient
98"
L-GSO,0.19148936170212766,"cannot be accurately estimated. The interplay among the type of test function, the location of the
99"
L-GSO,0.19342359767891681,"local optimum point, and ϵ is substantial, making it difficult to determine the appropriate value of ϵ
100"
L-GSO,0.195357833655706,"for the test function in advance; thus posing a disadvantage for black-box problems.
101"
L-GSO,0.19729206963249515,"Conclusively, L-GSO effectively handles high-dimensional spaces using surrogate networks and
102"
L-GSO,0.19922630560928434,"improves the stability of surrogate network training through locality. However, it is clear that non-
103"
L-GSO,0.2011605415860735,"dominated sorting for multi-objective problems is not feasible, and the relationship between the
104"
L-GSO,0.20309477756286268,"hyperparameter ϵ and the test function might be too strong.
105"
EGAN,0.20502901353965183,"2.2
EGAN
106"
EGAN,0.20696324951644102,"The Evolutionary Generative Adversarial Network (EGAN) integrates ES to improve GAN perfor-
107"
EGAN,0.20889748549323017,"mance. Although this method does not focus on black-box optimization, its algorithmic structure is
108"
EGAN,0.21083172147001933,"similar to GEO.
109"
EGAN,0.2127659574468085,"Usually, GANs are trained with one generator and one discriminator (critic) network, which alternate.
110"
EGAN,0.21470019342359767,"In EGAN, a scenario is considered where there is only one discriminator network; however, with
111"
EGAN,0.21663442940038685,"multiple generator networks. The main idea of this study is to rank the generator networks using an
112"
EGAN,0.218568665377176,"evolutionary strategy and keep only the suitable networks. By using the prediction of discriminator
113"
EGAN,0.2205029013539652,"C as the fitness score, the generators G that can increase C(G(z)) at each iteration survive. This
114"
EGAN,0.22243713733075435,"process incorporates ES into the GAN, and it has been established that the introduction of ES reduces
115"
EGAN,0.22437137330754353,"mode collapsing, which is a common issue in GANs.
116"
EGAN,0.2263056092843327,"Although EGAN is not directly related to optimization problems, we can gain valuable insights into
117"
EGAN,0.22823984526112184,"improving GSN based on EGAN’s concepts. Because the generator and surrogate network structure
118"
EGAN,0.23017408123791103,"in GSN is similar to the generator and discriminator network structure in GAN, we can adopt EGAN’s
119"
EGAN,0.23210831721470018,"strategy in GSN. This forms the core basis of our research, GEO. However, the main difference
120"
EGAN,0.23404255319148937,"between the two algorithms is that GAN operates without evolution, whereas GSN typically diverges
121"
EGAN,0.23597678916827852,"and fails when it consists only of a single generator and a surrogate network. In the Methods section,
122"
EGAN,0.2379110251450677,"we discuss how the working mechanism of GSN can change owing to the introduction of ES.
123"
GLONET,0.23984526112185686,"2.3
GLOnet
124"
GLONET,0.24177949709864605,"Global Optimization of dielectric metasurfaces using a physics-driven neural network (GLOnet) [23–
125"
GLONET,0.2437137330754352,"27] is a study to optimize devices in electromagnetic systems. The study investigates the optimization
126"
GLONET,0.24564796905222436,"of device structures within a specific electromagnetic system using neural network techniques.
127"
GLONET,0.24758220502901354,"In this study, x serves as device design parameters, and the goal is to find the optimal value of x that
128"
GLONET,0.2495164410058027,"maximizes the objective value F(x) of the simulator F. The algorithm finds x = G(z), where z is
129"
GLONET,0.2514506769825919,"the input seed, and the generator G is trained by backpropagating the gradient from the simulator.
130"
GLONET,0.25338491295938104,"Technically, this is not a black-box optimization, as it receives the analytic gradient information
131"
GLONET,0.2553191489361702,"directly from the simulator. Therefore, a surrogate network is not required.
132"
GLONET,0.2572533849129594,"An important implication of the GLOnet study is the necessity for a deep generator network. One
133"
GLONET,0.25918762088974856,"might assume that since we have a gradient, we can optimize x through direct gradient descent.
134"
GLONET,0.2611218568665377,"However, this study demonstrates that employing a generator network is more advantageous than
135"
GLONET,0.26305609284332687,"updating x directly without a generator. In fact, this also holds true for GSN studies. The importance
136"
GLONET,0.26499032882011603,"of deep generators is not emphasized in many GSN studies; however, it can be argued that it is
137"
GLONET,0.26692456479690524,"omitted because they are inspired by GANs, and the significance of a deep generator is implicitly
138"
GLONET,0.2688588007736944,"understood.
139 a) b)"
GLONET,0.27079303675048355,"GAN
GSN"
GLONET,0.2727272727272727,Generator
GLONET,0.2746615087040619,"True
data Fake data"
GLONET,0.2765957446808511,"Critic
Generator
Search"
GLONET,0.27852998065764023,"points
Critic
Black box"
GLONET,0.2804642166344294,Near-optimal region
GLONET,0.28239845261121854,Suboptimal region
GLONET,0.28433268858800775,Divergence direction
GLONET,0.2862669245647969,"Generator
Critic"
GLONET,0.28820116054158607,Next search points
GLONET,0.2901353965183752,(Suboptimal)
GLONET,0.29206963249516443,"Gradients 
(Divergence direction) c)"
GLONET,0.2940038684719536,(Fixed)
GLONET,0.29593810444874274,"Figure 1: a) Structural differences between GAN and GSN. b) A schematic figure illustrating the
training instability of GSN. The suboptimal point does not converge towards the near-optimal region,
but rather diverges in the opposite direction. c) The vicious cycle between the generator and critic,
which is the origin of divergence."
METHODS,0.2978723404255319,"3
Methods
140"
METHODS,0.29980657640232106,"In the previous chapters, we examined L-GSO, EGAN, and GLOnet. Our goal is to adopt the
141"
METHODS,0.30174081237911027,"surrogate network training strategy of L-GSO while enabling multi-objective optimization, which
142"
METHODS,0.3036750483558994,"cannot be implemented in the local surrogate model, and also reducing the excessive dependency
143"
METHODS,0.3056092843326886,"between the hyperparameters and the test functions. Meanwhile, we adopt the evolution strategy of
144"
METHODS,0.30754352030947774,"EGAN; however, unlike GAN, GSN has an inherently unstable structure; hence, we need to consider
145"
METHODS,0.30947775628626695,"how to address this instability. Additionally, EGAN assumes a single-objective fitness score; hence,
146"
METHODS,0.3114119922630561,"we need to modify it to work with multi-objective functions.
147"
A TRAINING INSTABILITY,0.31334622823984526,"3.1
A training instability
148"
A TRAINING INSTABILITY,0.3152804642166344,"First, let’s explain why surrogate training in GSNs is particularly unstable. The structure of GSNs is
149"
A TRAINING INSTABILITY,0.31721470019342357,"almost identical to GANs, hence it might seem that, just as GANs are highly successful in the fake
150"
A TRAINING INSTABILITY,0.3191489361702128,"data generation task, GSNs should also be successful. However, in practice, when we run a GSN
151"
A TRAINING INSTABILITY,0.32108317214700194,"model with just one generator network and one surrogate network, without employing any special
152"
A TRAINING INSTABILITY,0.3230174081237911,"tricks, we encounter a situation where they diverge to infinity almost immediately after starting, in
153"
A TRAINING INSTABILITY,0.32495164410058025,"most test cases. This is neither the desired result nor can we consider it being optimized. This is why
154"
A TRAINING INSTABILITY,0.32688588007736946,"GSN studies incorporate some kind of special trick.
155"
A TRAINING INSTABILITY,0.3288201160541586,"In addition, the crucial difference between GANs and GSNs lies in the presence or absence of true
156"
A TRAINING INSTABILITY,0.3307543520309478,"data. GANs rely on fixed true data; for instance, if the task is to generate images of human faces,
157"
A TRAINING INSTABILITY,0.33268858800773693,"a large dataset of real human face photos is required. Discriminator networks possess a significant
158"
A TRAINING INSTABILITY,0.3346228239845261,"amount of fixed true data initially and learn additional fake data during training, providing a stable
159"
A TRAINING INSTABILITY,0.3365570599613153,"training region. Conversely, GSNs, which are used for black-box optimization, do not have true data.
160"
A TRAINING INSTABILITY,0.33849129593810445,"Consequently, we must start from scratch, with no prior information. The first Pareto front points that
161"
A TRAINING INSTABILITY,0.3404255319148936,"have been explored, and the surrounding points, might correspond to true data. However, the amount
162"
A TRAINING INSTABILITY,0.34235976789168276,"of data near the first Pareto front is insufficient because the first Pareto front in the objective problem
163"
A TRAINING INSTABILITY,0.344294003868472,"is constantly changing and data is collected on-the-fly. To draw an analogy, the GAN represents a
164"
A TRAINING INSTABILITY,0.34622823984526113,"situation in which the target is anchored by true data, whereas the GSN represents a situation where
165"
A TRAINING INSTABILITY,0.3481624758220503,"the target is floating without an anchor.
166"
A TRAINING INSTABILITY,0.35009671179883944,"This is why the critic network (discriminator network) in GANs and the critic network (surrogate
167"
A TRAINING INSTABILITY,0.3520309477756286,"network) in GSNs have similar learning structures; however, they yield completely different results.
168"
A TRAINING INSTABILITY,0.3539651837524178,"To summarize the erroneous learning process of GSN’s critic network, we describe its workings as
169"
A TRAINING INSTABILITY,0.35589941972920697,"follows:
170"
A TRAINING INSTABILITY,0.3578336557059961,"1. The critic network begins training with insufficient data.
171"
A TRAINING INSTABILITY,0.3597678916827853,"2. The training data has minimal information about the Pareto front, which prevents the network
172"
A TRAINING INSTABILITY,0.3617021276595745,"from learning anything meaningful.
173"
A TRAINING INSTABILITY,0.36363636363636365,"3. As the critic network is trained improperly, the gradient it provides fails to guide x towards
174"
A TRAINING INSTABILITY,0.3655705996131528,"the Pareto front.
175"
A TRAINING INSTABILITY,0.36750483558994196,"4. The generator, using incorrect gradient information, produces a point unrelated to the Pareto
176"
A TRAINING INSTABILITY,0.3694390715667311,"front when suggesting the next x.
177"
A TRAINING INSTABILITY,0.3713733075435203,"5. The critic network is then retrained using the poorly generated x.
178"
A TRAINING INSTABILITY,0.3733075435203095,"This leads to a vicious cycle between the generator and the critic network, a situation that does not
179"
A TRAINING INSTABILITY,0.37524177949709864,"occur in GANs owing to the presence of true data.
180"
A TRAINING INSTABILITY,0.3771760154738878,"One solution to this problem is to create a data region that corresponds to the true data region found
181"
A TRAINING INSTABILITY,0.379110251450677,"in GANs. In optimization problems, the most crucial information is concentrated at the first Pareto
182"
A TRAINING INSTABILITY,0.38104448742746616,"front. Hence, it is necessary to sample the area around the first Pareto front and use it as training
183"
A TRAINING INSTABILITY,0.3829787234042553,"data for the critic network. L-GSO addresses this issue by intensively sampling only the local region
184"
A TRAINING INSTABILITY,0.3849129593810445,"around x0, representing the zero-dimensional first Pareto front, and supplying that data to the critic
185"
A TRAINING INSTABILITY,0.38684719535783363,"network. However, as mentioned in the related works section, the local sampling method cannot be
186"
A TRAINING INSTABILITY,0.38878143133462284,"applied to n-objective functions with n > 1. Consequently, we need an approach that is similar to the
187"
A TRAINING INSTABILITY,0.390715667311412,"local sampling method and can also accommodate the multi-objective target functions.
188"
A TRAINING INSTABILITY,0.39264990328820115,"Hence, we suggest using ES. The idea is to keep generators G that produce x values close to the first
189"
A TRAINING INSTABILITY,0.3945841392649903,"Pareto front and discard those that are farther away. By selecting G through a non-dominated sorting
190"
A TRAINING INSTABILITY,0.3965183752417795,"process, we ensure that only [x, G] pairs generating search points near the Pareto front survive at
191"
A TRAINING INSTABILITY,0.3984526112185687,"each iteration. Even if the critic network initially learns the incorrect region, as iterations progress,
192"
A TRAINING INSTABILITY,0.40038684719535783,"the probability of generating a search point x near the Pareto front increases. Eventually, the critic
193"
A TRAINING INSTABILITY,0.402321083172147,"network will have a stable training data region near the Pareto front; thus breaking the vicious cycle
194"
A TRAINING INSTABILITY,0.40425531914893614,"and achieving our desired outcome: stability in critic network training for multi-objective targets.
195"
A TRAINING INSTABILITY,0.40618955512572535,"GEO was developed with the notion that ES complements GSN; however, this idea can also be
196"
A TRAINING INSTABILITY,0.4081237911025145,"reversed. As previously mentioned, from the ES perspective, the algorithm consists of mutation
197"
A TRAINING INSTABILITY,0.41005802707930367,"and (non-dominated) sorting based on fitness scores, with generator networks being the targets of
198"
A TRAINING INSTABILITY,0.4119922630560928,"mutation. In this case, mutation occurs through backpropagation from the critic network, which
199"
A TRAINING INSTABILITY,0.41392649903288203,"can be more efficient because the neural network has learned information about the Pareto front.
200"
A TRAINING INSTABILITY,0.4158607350096712,"Therefore, from the ES perspective, GSN serves as an auxiliary means to enhance the mutation
201"
A TRAINING INSTABILITY,0.41779497098646035,"efficiency of ES.
202"
A TRAINING INSTABILITY,0.4197292069632495,"Conclusively, GEO functions in such a way that GSN complements ES, and ES complements GSN.
203"
A TRAINING INSTABILITY,0.42166344294003866,"By doing so, it integrates the strengths of both GSN and ES while mitigating their weaknesses,
204"
A TRAINING INSTABILITY,0.42359767891682787,"particularly effectively addressing the instability problem of GSN. Moreover, since both GSN and ES
205"
A TRAINING INSTABILITY,0.425531914893617,"are O(N) algorithms, GEO is able to maintain O(N) complexity.
206"
A TRAINING INSTABILITY,0.4274661508704062,"However, it is important to emphasize that both GSN and ES are exploitation-oriented algorithms
207"
A TRAINING INSTABILITY,0.42940038684719534,"in terms of exploit and explore strategies. Bayesian optimization, another significant branch of
208"
A TRAINING INSTABILITY,0.43133462282398455,"black-box optimization, offers a powerful feature by estimating uncertainty and incorporating it into
209"
A TRAINING INSTABILITY,0.4332688588007737,"the next step search. From that perspective, both ES and GSN lack the uncertainty estimation aspect,
210"
A TRAINING INSTABILITY,0.43520309477756286,"and even with the addition of supplementary exploration strategies, they may not reach the same
211"
A TRAINING INSTABILITY,0.437137330754352,"level of robust exploration performance as the Bayesian optimization. Consequently, GEO, similar
212"
A TRAINING INSTABILITY,0.43907156673114117,"to GSN and ES, cannot guarantee global optimization even though the number of function calls
213"
A TRAINING INSTABILITY,0.4410058027079304,"N approaches infinity. Nevertheless, GSN, ES, and GEO are free from the non-linear complexity
214"
A TRAINING INSTABILITY,0.44294003868471954,"problem that Bayesian optimization encounters. Hence, it is clear that Bayesian optimization and
215"
A TRAINING INSTABILITY,0.4448742746615087,"GEO have distinctly different optimization goals and conditions in which they are best applied.
216"
OPERATION STEPS,0.44680851063829785,"3.2
Operation steps
217"
OPERATION STEPS,0.44874274661508706,"The following are the operation sequences for GEO in the context of n-objective black-box opti-
218"
OPERATION STEPS,0.4506769825918762,"mization F = (f1, f2, ..., fi, ..., fn). G: generator network, Ci: ith Critic network, z: input seed of
219"
OPERATION STEPS,0.4526112185686654,"generator, x: search point of search space X.
220"
OPERATION STEPS,0.45454545454545453,"Pretraining steps:
221"
OPERATION STEPS,0.4564796905222437,"1. Prepare a set of generators and n critic networks. Each critic network predicts one corre-
222"
OPERATION STEPS,0.4584139264990329,"sponding objective. The networks have not been trained yet.
223"
OPERATION STEPS,0.46034816247582205,"Generator 1
Score 1"
OPERATION STEPS,0.4622823984526112,"Generator 2
Score 2"
OPERATION STEPS,0.46421663442940037,"Generator 3
Score 3"
OPERATION STEPS,0.4661508704061896,"Generator i
Score i"
OPERATION STEPS,0.46808510638297873,"Generator N
Score N"
OPERATION STEPS,0.4700193423597679,"Sampled 
Generator (G)"
OPERATION STEPS,0.47195357833655704,"Trained 
Generator (Gʹ)"
OPERATION STEPS,0.4738878143133462,"Input 
variable"
OPERATION STEPS,0.4758220502901354,x=Gʹ(z)
OPERATION STEPS,0.47775628626692457,"x
Score"
OPERATION STEPS,0.4796905222437137,Generator Pool Score
OPERATION STEPS,0.4816247582205029,"Buﬀer 
memory
Critic 
Network (C)"
OPERATION STEPS,0.4835589941972921,"Trained 
Generator"
OPERATION STEPS,0.48549323017408125,"Black 
Box (F)"
OPERATION STEPS,0.4874274661508704,"Score 
s=F(x) 1 2 3 4 5
6 7 8"
OPERATION STEPS,0.48936170212765956,Evolution
OPERATION STEPS,0.4912959381044487,Strategy
OPERATION STEPS,0.4932301740812379,"Generative 
N.N. model"
OPERATION STEPS,0.4951644100580271,Stable training region
OPERATION STEPS,0.49709864603481624,"Eﬃcient mutation a)
b)"
OPERATION STEPS,0.4990328820116054,ES cycle
OPERATION STEPS,0.5009671179883946,GSN cycle
OPERATION STEPS,0.5029013539651838,"Figure 2: a) The overall algorithm of GEO. b) ES contributes to GSN by ensuring a stable training
region, while GSN aids ES in carrying out efficient mutations. This creates a virtuous cycle where
both algorithms complement each other’s weaknesses."
OPERATION STEPS,0.504835589941973,"2. Prepare the [x, F(x)] training set for initializing the critic network. The Latin Hypercube
224"
OPERATION STEPS,0.5067698259187621,"method[52] is generally recommended as the initial sampling method for search point x.
225"
OPERATION STEPS,0.5087040618955513,"However, the generator network can also be initialized using weight initialization techniques
226"
OPERATION STEPS,0.5106382978723404,"for neural networks, such as Xavier or He initialization.
227"
OPERATION STEPS,0.5125725338491296,"3. Store the initialized [x, F(x)] in buffer memory, which has a maximum length.
228"
OPERATION STEPS,0.5145067698259188,"4. Pretrain the critic network using the data stored in buffer memory. For example, Ci is trained
229"
OPERATION STEPS,0.5164410058027079,"with [x, fi(x)] pairs.
230"
OPERATION STEPS,0.5183752417794971,"Main iteration steps:
231"
OPERATION STEPS,0.5203094777562862,"1. Randomly sample a few generators from the generator set (evolution pool).
232"
OPERATION STEPS,0.5222437137330754,"2. Train the generators through backpropagation with the critic network Ci. The loss function
233"
OPERATION STEPS,0.5241779497098646,"is −Ci(G(z)) for the maximization problem. The training of the generators also serves as
234"
OPERATION STEPS,0.5261121856866537,"mutation from the ES perspective. Because there are n critic networks, the single-objective
235"
OPERATION STEPS,0.528046421663443,"mutation is repeated n times; thus implying that for each sampled G, we make n mutants.
236"
OPERATION STEPS,0.5299806576402321,"3. Generate new x′ = G′(z) points from the mutated generators G′.
237"
OPERATION STEPS,0.5319148936170213,"4. Evaluate F(x′) from the new x′ and store the pair [x′, F(x′)] in the buffer memory. If the
238"
OPERATION STEPS,0.5338491295938105,"buffer memory’s maximum length is exceeded, delete the previously stored data.
239"
OPERATION STEPS,0.5357833655705996,"5. Train the critic networks using the data in the buffer memory.
240"
OPERATION STEPS,0.5377176015473888,"6. Save the [G′, F(x′)] pair back to the generator set. F(x′) corresponds to the multi-objective
241"
OPERATION STEPS,0.539651837524178,"fitness score.
242"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5415860735009671,"7. The number of generators in the evolution pool has increased with the newly stored mutated
243"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5435203094777563,"G′. Perform a non-dominated sort on them based on their fitness scores. Predetermine a
244"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5454545454545454,"maximum number for the generator set and retain only the generators with high fitness (top
245"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5473887814313346,"Pareto-front data).
246"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5493230174081238,"8. Repeat the iteration.
247"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5512572533849129,"The configuration of the critic network might have been designed to allow a single critic network
248"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5531914893617021,"to predict multiple target objectives. However, we separated the critic network independently for
249"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5551257253384912,"each objective to minimize correlation, under the assumption that it is more common for black-box
250"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5570599613152805,"problems to have independent objective targets. By dividing the critic network into n parts and
251"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5589941972920697,"applying backpropagation separately, it behaves as if the single-objective problem is being run n
252"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5609284332688588,"times independently. Nevertheless, it can be used for multi-objective optimization because the results
253"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.562862669245648,"are combined and ranked using non-dominated sorting.
254"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5647969052224371,"In addition, if the target function is stochastic, age evolution can be incorporated into the non-
255"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5667311411992263,"dominated sorting step. In age evolution, we can store the time order information of generators
256"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5686653771760155,"together and remove a few of the oldest generators before performing non-dominated sorting.
257 a) b)"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5705996131528046,"GEO
BO
GA
GEO single layer
CMAES"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5725338491295938,"GEO
BO
GA
GEO single layer
CMAES"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.574468085106383,"GEO
BO
GA
GEO single layer
CMAES"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5764023210831721,"GEO
BO
GA
GEO single layer
CMAES"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5783365570599613,"Figure 3: a) Comparison of GEO with baseline algorithms such as BO (Bayesian Optimization), GA
(Genetic Algorithm), CMA-ES, and GEO with a single-layer generator. b) Comparison with LSM, a
modified version of L-GSO."
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5802707930367504,"The provided explanation outlines the basic algorithmic structure of GEO. As described, the operation
258"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5822050290135397,"of GEO is achieved when both the ES-direction cycle and the GSN-direction cycle work together
259"
THE NUMBER OF GENERATORS IN THE EVOLUTION POOL HAS INCREASED WITH THE NEWLY STORED MUTATED,0.5841392649903289,"simultaneously.
260"
RESULTS,0.586073500967118,"4
Results
261"
RESULTS,0.5880077369439072,"Previously, we mentioned that L-GSO has a particularly strong correlation with the hyperparameter
262"
RESULTS,0.5899419729206963,"set and test function. However, all black-box optimization problems exhibit a significant correlation
263"
RESULTS,0.5918762088974855,"between the algorithm type, hyperparameter set, and target function, thus leading to entirely different
264"
RESULTS,0.5938104448742747,"results with even slight changes. Comparing the performance of optimization algorithms can be
265"
RESULTS,0.5957446808510638,"challenging precisely because of this reason. It is impossible to prove which hyperparameter set
266"
RESULTS,0.597678916827853,"is optimal for a specific test function. Even if the optimal hyperparameter set for a particular test
267"
RESULTS,0.5996131528046421,"function is found through repeated experimentation, it would constitute overfitting to that specific test
268"
RESULTS,0.6015473887814313,"function and would no longer be considered black-box optimization. Therefore, a straightforward
269"
RESULTS,0.6034816247582205,"performance comparison between algorithms for the final results is susceptible to cherry-picking
270"
RESULTS,0.6054158607350096,"problems. Therefore, this study focuses on describing how the trend of optimization performance
271"
RESULTS,0.6073500967117988,"depends on the dimension, rather than simply comparing the values of the final results.
272"
RESULTS,0.6092843326885881,"In the single-objective function, it is crucial to compare GEO with L-GSO. To ensure a fair comparison,
273"
RESULTS,0.6112185686653772,"we matched L-GSO’s network configuration with GEO’s, referring to it as Local Surrogate Model
274"
RESULTS,0.6131528046421664,"(LSM). Examining the performance changes of LSM and GEO as dimensions increase, LSM is more
275"
RESULTS,0.6150870406189555,"efficient at smaller dimensions. However, its performance declines significantly as the dimensions
276"
RESULTS,0.6170212765957447,"grow larger. This situation is also evident in classical ES and Bayesian optimization (based on
277"
RESULTS,0.6189555125725339,"Gaussian process). Although GEO is less efficient at lower dimensions, its efficiency increases as the
278"
RESULTS,0.620889748549323,"dimensions grow, outperforming the other methods.
279"
RESULTS,0.6228239845261122,"In the related works chapter, we discussed the importance of deep generators. To investigate this
280"
RESULTS,0.6247582205029013,"further, we conducted an experiment with GEO using a single-layer FC network as the generator.
281"
RESULTS,0.6266924564796905,"(However, the critic network remains a deep neural network.) The experiment demonstrated that the
282"
RESULTS,0.6286266924564797,"shallow layer GEO experienced a significant decrease in optimization performance.
283 a) b)"
RESULTS,0.6305609284332688,"Figure 4:
a) Optimization results after 100,000 function calls in two-objective function with
8192 dimensions. To investigate the influence of the initial condition, we conducted experiments
differentiating between Latin Hyper Cube (LHC) initialization and point initialization (I) that is the
same as the GEO neural network initial state. The results show that the influence of the initial states
is insignificant. b) Optimization results in a stochastic environment with random noise added to the
ZDT function, after 100,000 function calls in 8192 dimensions."
RESULTS,0.632495164410058,"We also conducted high-dimensional experiments in multi-objective functions. According to the
284"
RESULTS,0.6344294003868471,"experimental results, as the dimension increases, the performance of the comparison group declines
285"
RESULTS,0.6363636363636364,"rapidly, whereas the performance of GEO is relatively well maintained. By the time it reaches 8192
286"
RESULTS,0.6382978723404256,"dimensions, there is a significant difference in the final results. The comparison group tends to get
287"
RESULTS,0.6402321083172147,"trapped in local optima easily; however, GEO manages to escape local optima and makes considerable
288"
RESULTS,0.6421663442940039,"progress.
289"
RESULTS,0.6441005802707931,"However, a limitation of GEO can be identified in one of the experimental results. The ZDT2 function
290"
RESULTS,0.6460348162475822,"has a concave Pareto-front shape. In this case, although GEO succeeds in optimization, it fails to find
291"
RESULTS,0.6479690522243714,"the entire shape of the Pareto-front and tends to collapse toward one side. We also experimented the
292"
RESULTS,0.6499032882011605,"stochastic functions by adding normal random noise to the ZDT test functions. The results for the
293"
RESULTS,0.6518375241779497,"stochastic multi-objective functions exhibit similar characteristics. Here, the performance of GEO
294"
RESULTS,0.6537717601547389,"appears to be better compared to the baseline methods; however, it also shows a similar tendency
295"
RESULTS,0.655705996131528,"to collapse toward one side while optimizing the ZDT2 function. In the case of ZDT1 and ZDT3,
296"
RESULTS,0.6576402321083172,"although some lines of the Pareto-front are found, the collapsing tendency is stronger compared to
297"
RESULTS,0.6595744680851063,"non-stochastic functions.
298"
RESULTS,0.6615087040618955,"Summarily, as we intended, GEO successfully overcomes the difficulties of critic network training
299"
RESULTS,0.6634429400386848,"in GSN and demonstrates stable performance. Because it does not assume locality, it shows excel-
300"
RESULTS,0.6653771760154739,"lent performance in multi-objective functions and operates effectively in stochastic environments.
301"
RESULTS,0.6673114119922631,"Figure 5: Changes in the optimization results of each algorithm as the dimension increases, using
the ZDT3 test function after 100,000 function calls."
RESULTS,0.6692456479690522,"Although in cases with low dimensions, GEO’s performance is lower compared to traditional algo-
302"
RESULTS,0.6711798839458414,"rithms, possibly due to too large neural network size we used; however, as the number of dimensions
303"
RESULTS,0.6731141199226306,"increases, it shows better performance than other algorithms.
304"
CONCLUSION,0.6750483558994197,"5
Conclusion
305"
CONCLUSION,0.6769825918762089,"We can observe that GEO successfully accomplishes our five primary objectives: optimizing non-
306"
CONCLUSION,0.6789168278529981,"convex, high-dimensional, multi-objective, and stochastic target functions while maintaining O(N)
307"
CONCLUSION,0.6808510638297872,"complexity.
308"
CONCLUSION,0.6827852998065764,"In the Related works chapter, we examined insights into L-GSO and EGAN and combined them
309"
CONCLUSION,0.6847195357833655,"to create the foundational concept behind GEO. GSN has problems with unstable critic network
310"
CONCLUSION,0.6866537717601547,"training, and to address this, methods that focus on sampling around optimal values can be considered.
311"
CONCLUSION,0.688588007736944,"Although L-GSO employs such an approach, introducing locality to implement it limits the algorithm
312"
CONCLUSION,0.690522243713733,"to single-objective functions and results in excessive sensitivity to hyperparameters. Hence, we
313"
CONCLUSION,0.6924564796905223,"introduced ES combination strategy to create a stable training data region near the Pareto-front. This
314"
CONCLUSION,0.6943907156673114,"method can be used for multi-objective problems and also resolves the hyperparameter sensitivity
315"
CONCLUSION,0.6963249516441006,"problem because it does not assume a separate local ϵ size. Moreover, GSN and ES work comple-
316"
CONCLUSION,0.6982591876208898,"mentarily, enhancing each other’s strengths and compensating for weaknesses, leading to improved
317"
CONCLUSION,0.7001934235976789,"efficiency.
318"
CONCLUSION,0.7021276595744681,"As indicated in the Results chapter, GEO appears to be more effective in high dimensions rather
319"
CONCLUSION,0.7040618955512572,"than low dimensions. For instance, ES is an algorithm that is advantageous in low dimensions when
320"
CONCLUSION,0.7059961315280464,"a large number of function calls is available, whereas Bayesian optimization is favorable in low
321"
CONCLUSION,0.7079303675048356,"dimensions with limited number of function calls. Conversely, GEO might have an advantage when
322"
CONCLUSION,0.7098646034816247,"many function calls are possible in high dimensions. This observation suggests that GEO has the
323"
CONCLUSION,0.7117988394584139,"potential to address optimization areas not covered by existing algorithms.
324"
CONCLUSION,0.7137330754352031,"Because GEO is specialized for high-dimensional non-convex functions, it is worth considering its
325"
CONCLUSION,0.7156673114119922,"potential applications in other areas of machine learning. For example, some research trains reinforce-
326"
CONCLUSION,0.7176015473887815,"ment learning (RL) neural networks through black-box optimization [60]. As these techniques require
327"
CONCLUSION,0.7195357833655706,"high-dimensional black-box optimization, GEO, which specializes in high-dimensional optimization,
328"
CONCLUSION,0.7214700193423598,"could be a viable option.
329"
CONCLUSION,0.723404255319149,"As previously mentioned in the Results section, one difficulty in black-box optimization research
330"
CONCLUSION,0.7253384912959381,"could be the variability in the performance of algorithms. The performance can vary greatly depending
331"
CONCLUSION,0.7272727272727273,"on the combination of algorithm type, hyperparameters, and test function type. A certain algorithm
332"
CONCLUSION,0.7292069632495164,"and hyperparameter set might be highly effective when targeting a specific test function; however,
333"
CONCLUSION,0.7311411992263056,"it may yield poor results for a different test function. Hence, this can lead to biased preparation
334"
CONCLUSION,0.7330754352030948,"toward specific test functions, making it easier to cherry-pick results. In the worst-case scenario, one
335"
CONCLUSION,0.7350096711798839,"could develop an algorithm specialized for a target test function and fine-tune the algorithm through
336"
CONCLUSION,0.7369439071566731,"repeated experiments to obtain good results. Consequently, these results would not be considered
337"
CONCLUSION,0.7388781431334622,"genuine black-box optimization outcomes because they utilize prior knowledge gained through the
338"
CONCLUSION,0.7408123791102514,"iterative experiments. Therefore, it is challenging to determine the state-of-the-art (SOTA) status in
339"
CONCLUSION,0.7427466150870407,"black-box optimization research. Hence, although GEO demonstrates outstanding performance in
340"
CONCLUSION,0.7446808510638298,"this study, further research is necessary to determine its performance across various environments
341"
CONCLUSION,0.746615087040619,"and to identify its limitations.
342"
REFERENCES,0.7485493230174082,"References
343"
REFERENCES,0.7504835589941973,"[1] Snoek, J., Larochelle, H., & Adams, R. P. (2012). Practical bayesian optimization of machine learning
344"
REFERENCES,0.7524177949709865,"algorithms. Advances in neural information processing systems, 25.
345"
REFERENCES,0.7543520309477756,"[2] Frazier, P. I. (2018). A tutorial on Bayesian optimization. arXiv preprint arXiv:1807.02811.
346"
REFERENCES,0.7562862669245648,"[3] Lan, G., Tomczak, J. M., Roijers, D. M., & Eiben, A. E. (2022). Time efficiency in optimization with a
347"
REFERENCES,0.758220502901354,"bayesian-evolutionary algorithm. Swarm and Evolutionary Computation, 69, 100970.
348"
REFERENCES,0.7601547388781431,"[4] Nelder, J. A., & Mead, R. (1965). A simplex method for function minimization. The computer journal,
349"
REFERENCES,0.7620889748549323,"7(4), 308-313.
350"
REFERENCES,0.7640232108317214,"[5] Kennedy, J., & Eberhart, R. (1995, November). Particle swarm optimization. In Proceedings of ICNN’95-
351"
REFERENCES,0.7659574468085106,"international conference on neural networks (Vol. 4, pp. 1942-1948). IEEE.
352"
REFERENCES,0.7678916827852998,"[6] Hooke, R., & Jeeves, T. A. (1961). “Direct Search”Solution of Numerical and Statistical Problems. Journal
353"
REFERENCES,0.769825918762089,"of the ACM (JACM), 8(2), 212-229.
354"
REFERENCES,0.7717601547388782,"[7] Deb, K., Pratap, A., Agarwal, S., & Meyarivan, T. A. M. T. (2002). A fast and elitist multiobjective genetic
355"
REFERENCES,0.7736943907156673,"algorithm: NSGA-II. IEEE transactions on evolutionary computation, 6(2), 182-197.
356"
REFERENCES,0.7756286266924565,"[8] Deb, K., & Sundar, J. (2006, July). Reference point based multi-objective optimization using evolutionary
357"
REFERENCES,0.7775628626692457,"algorithms. In Proceedings of the 8th annual conference on Genetic and evolutionary computation (pp.
358"
REFERENCES,0.7794970986460348,"635-642).
359"
REFERENCES,0.781431334622824,"[9] Hansen, N., & Ostermeier, A. (2001). Completely derandomized self-adaptation in evolution strategies.
360"
REFERENCES,0.7833655705996132,"Evolutionary computation, 9(2), 159-195.
361"
REFERENCES,0.7852998065764023,"[10] Hansen, N. (2006). The CMA evolution strategy: a comparing review. Towards a new evolutionary
362"
REFERENCES,0.7872340425531915,"computation, 75-102.
363"
REFERENCES,0.7891682785299806,"[11] Price, K., Storn, R. M., & Lampinen, J. A. (2006). Differential evolution: a practical approach to global
364"
REFERENCES,0.7911025145067698,"optimization. Springer Science & Business Media.
365"
REFERENCES,0.793036750483559,"[12] Runarsson, T. P., & Yao, X. (2000). Stochastic ranking for constrained evolutionary optimization. IEEE
366"
REFERENCES,0.7949709864603481,"Transactions on evolutionary computation, 4(3), 284-294.
367"
REFERENCES,0.7969052224371374,"[13] Runarsson, T. P., & Yao, X. (2005). Search biases in constrained evolutionary optimization. IEEE Transac-
368"
REFERENCES,0.7988394584139265,"tions on Systems, Man, and Cybernetics, Part C (Applications and Reviews), 35(2), 233-243.
369"
REFERENCES,0.8007736943907157,"[14] Deb, K., & Jain, H. (2013). An evolutionary many-objective optimization algorithm using reference-point-
370"
REFERENCES,0.8027079303675049,"based nondominated sorting approach, part I: solving problems with box constraints. IEEE transactions
371"
REFERENCES,0.804642166344294,"on evolutionary computation, 18(4), 577-601.
372"
REFERENCES,0.8065764023210832,"[15] Blank, J., Deb, K., & Roy, P. C. (2019, March). Investigating the normalization procedure of NSGA-III. In
373"
REFERENCES,0.8085106382978723,"International Conference on Evolutionary Multi-Criterion Optimization (pp. 229-240). Springer, Cham.
374"
REFERENCES,0.8104448742746615,"[16] Seada, H., & Deb, K. (2015). A unified evolutionary optimization procedure for single, multiple, and many
375"
REFERENCES,0.8123791102514507,"objectives. IEEE Transactions on Evolutionary Computation, 20(3), 358-369.
376"
REFERENCES,0.8143133462282398,"[17] Vesikar, Y., Deb, K., & Blank, J. (2018, November). Reference point based NSGA-III for preferred
377"
REFERENCES,0.816247582205029,"solutions. In 2018 IEEE symposium series on computational intelligence (SSCI) (pp. 1587-1594). IEEE.
378"
REFERENCES,0.8181818181818182,"[18] Carvalho, R. D., Saldanha, R. R., Gomes, B. N., Lisboa, A. C., & Martins, A. X. (2012). A multi-
379"
REFERENCES,0.8201160541586073,"objective evolutionary algorithm based on decomposition for optimal design of Yagi-Uda antennas. IEEE
380"
REFERENCES,0.8220502901353965,"Transactions on Magnetics, 48(2), 803-806.
381"
REFERENCES,0.8239845261121856,"[19] Li, K., Chen, R., Fu, G., & Yao, X. (2018). Two-archive evolutionary algorithm for constrained multiob-
382"
REFERENCES,0.8259187620889749,"jective optimization. IEEE Transactions on Evolutionary Computation, 23(2), 303-315.
383"
REFERENCES,0.8278529980657641,"[20] Panichella, A. (2019, July). An adaptive evolutionary algorithm based on non-Euclidean geometry for
384"
REFERENCES,0.8297872340425532,"many-objective optimization. In Proceedings of the Genetic and Evolutionary Computation Conference
385"
REFERENCES,0.8317214700193424,"(pp. 595-603).
386"
REFERENCES,0.8336557059961315,"[21] Shirobokov, S., Belavin, V., Kagan, M., Ustyuzhanin, A., & Baydin, A. G. (2020). Black-box optimization
387"
REFERENCES,0.8355899419729207,"with local generative surrogates. Advances in Neural Information Processing Systems, 33, 14650-14662.
388"
REFERENCES,0.8375241779497099,"[22] Wang, C., Xu, C., Yao, X., & Tao, D. (2019). Evolutionary generative adversarial networks. IEEE
389"
REFERENCES,0.839458413926499,"Transactions on Evolutionary Computation, 23(6), 921-934.
390"
REFERENCES,0.8413926499032882,"[23] Jiang, J., & Fan, J. A. (2019). Global optimization of dielectric metasurfaces using a physics-driven neural
391"
REFERENCES,0.8433268858800773,"network. Nano letters, 19(8), 5366-5372.
392"
REFERENCES,0.8452611218568665,"[24] Yang, J., Sell, D., & Fan, J. A. (2018). Freeform metagratings based on complex light scattering dynamics
393"
REFERENCES,0.8471953578336557,"for extreme, high efficiency beam steering. Annalen der Physik, 530(1), 1700302.
394"
REFERENCES,0.8491295938104448,"[25] Hughes, T. W., Minkov, M., Williamson, I. A., & Fan, S. (2018). Adjoint method and inverse design for
395"
REFERENCES,0.851063829787234,"nonlinear nanophotonic devices. ACS Photonics, 5(12), 4781-4787.
396"
REFERENCES,0.8529980657640233,"[26] Jensen, J. S., & Sigmund, O. (2011). Topology optimization for nano-photonics. Laser & Photonics
397"
REFERENCES,0.8549323017408124,"Reviews, 5(2), 308-321.
398"
REFERENCES,0.8568665377176016,"[27] Molesky, S., Lin, Z., Piggott, A. Y., Jin, W., Vuckovi´c, J., & Rodriguez, A. W. (2018). Inverse design in
399"
REFERENCES,0.8588007736943907,"nanophotonics. Nature Photonics, 12(11), 659-670.
400"
REFERENCES,0.8607350096711799,"[28] Faury, L., Calauzenes, C., Fercoq, O., & Krichen, S. (2019). Improving evolutionary strategies with
401"
REFERENCES,0.8626692456479691,"generative neural networks. arXiv preprint arXiv:1901.11271.
402"
REFERENCES,0.8646034816247582,"[29] Trabucco, B., Kumar, A., Geng, X., & Levine, S. (2021, July). Conservative objective models for effective
403"
REFERENCES,0.8665377176015474,"offline model-based optimization. In International Conference on Machine Learning (pp. 10358-10368).
404"
REFERENCES,0.8684719535783365,"PMLR.
405"
REFERENCES,0.8704061895551257,"[30] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014).
406"
REFERENCES,0.8723404255319149,"Generative adversarial nets. Advances in neural information processing systems, 27.
407"
REFERENCES,0.874274661508704,"[31] Karras, T., Aila, T., Laine, S., & Lehtinen, J. (2017). Progressive growing of gans for improved quality,
408"
REFERENCES,0.8762088974854932,"stability, and variation. arXiv preprint arXiv:1710.10196.
409"
REFERENCES,0.8781431334622823,"[32] Karras, T., Laine, S., & Aila, T. (2019). A style-based generator architecture for generative adversarial
410"
REFERENCES,0.8800773694390716,"networks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp.
411"
REFERENCES,0.8820116054158608,"4401-4410).
412"
REFERENCES,0.8839458413926499,"[33] Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., & Riedmiller, M. (2013).
413"
REFERENCES,0.8858800773694391,"Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602.
414"
REFERENCES,0.8878143133462283,"[34] Mnih, V., Badia, A. P., Mirza, M., Graves, A., Lillicrap, T., Harley, T., ... & Kavukcuoglu, K. (2016, June).
415"
REFERENCES,0.8897485493230174,"Asynchronous methods for deep reinforcement learning. In International conference on machine learning
416"
REFERENCES,0.8916827852998066,"(pp. 1928-1937). PMLR.
417"
REFERENCES,0.8936170212765957,"[35] Rastrigin, L. A. (1974) Systems of extremal control. Mir, Moscow.
418"
REFERENCES,0.8955512572533849,"[36] Hoffmeister, F., & Bäck, T. (1990, October). Genetic algorithms and evolution strategies: Similarities and
419"
REFERENCES,0.8974854932301741,"differences. In International Conference on Parallel Problem Solving from Nature (pp. 455-469). Springer,
420"
REFERENCES,0.8994197292069632,"Berlin, Heidelberg.
421"
REFERENCES,0.9013539651837524,"[37] Mühlenbein, H., Schomisch, M., & Born, J. (1991). The parallel genetic algorithm as function optimizer.
422"
REFERENCES,0.9032882011605415,"Parallel computing, 17(6-7), 619-632.
423"
REFERENCES,0.9052224371373307,"[38] Ackley, D. (2012). A connectionist machine for genetic hillclimbing (Vol. 28). Springer Science & Business
424"
REFERENCES,0.90715667311412,"Media.
425"
REFERENCES,0.9090909090909091,"[39] Rosenbrock, H. (1960). An automatic method for finding the greatest or least value of a function. The
426"
REFERENCES,0.9110251450676983,"Computer Journal, 3(3), 175-184.
427"
REFERENCES,0.9129593810444874,"[40] Dixon, L. C. W., & Mills, D. J. (1994). Effect of rounding errors on the variable metric method. Journal of
428"
REFERENCES,0.9148936170212766,"Optimization Theory and Applications, 80(1), 175-179.
429"
REFERENCES,0.9168278529980658,"[41] Styblinski, M. A., & Tang, T. S. (1990). Experiments in nonconvex optimization: stochastic approximation
430"
REFERENCES,0.9187620889748549,"with function smoothing and simulated annealing. Neural Networks, 3(4), 467-483.
431"
REFERENCES,0.9206963249516441,"[42] Deb, K., Thiele, L., Laumanns, M., & Zitzler, E. (2002, May). Scalable multi-objective optimization
432"
REFERENCES,0.9226305609284333,"test problems. In Proceedings of the 2002 Congress on Evolutionary Computation. CEC’02 (Cat. No.
433"
REFERENCES,0.9245647969052224,"02TH8600) (Vol. 1, pp. 825-830). IEEE.
434"
REFERENCES,0.9264990328820116,"[43] Kumar, S. (2020). Balancing a CartPole System with Reinforcement Learning–A Tutorial. arXiv preprint
435"
REFERENCES,0.9284332688588007,"arXiv:2006.04938.
436"
REFERENCES,0.9303675048355899,"[44] LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document
437"
REFERENCES,0.9323017408123792,"recognition. Proceedings of the IEEE, 86(11), 2278-2324.
438"
REFERENCES,0.9342359767891683,"[45] LeCun, Y., Boser, B., Denker, J. S., Henderson, D., Howard, R. E., Hubbard, W., & Jackel, L. D. (1989).
439"
REFERENCES,0.9361702127659575,"Backpropagation applied to handwritten zip code recognition. Neural computation, 1(4), 541-551.
440"
REFERENCES,0.9381044487427466,"[46] Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning representations by back-propagating
441"
REFERENCES,0.9400386847195358,"errors. nature, 323(6088), 533-536.
442"
REFERENCES,0.941972920696325,"[47] Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural computation, 9(8), 1735-1780.
443"
REFERENCES,0.9439071566731141,"[48] Cho, K., Van Merriënboer, B., Bahdanau, D., & Bengio, Y. (2014). On the properties of neural machine
444"
REFERENCES,0.9458413926499033,"translation: Encoder-decoder approaches. arXiv preprint arXiv:1409.1259.
445"
REFERENCES,0.9477756286266924,"[49] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017).
446"
REFERENCES,0.9497098646034816,"Attention is all you need. Advances in neural information processing systems, 30.
447"
REFERENCES,0.9516441005802708,"[50] Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: a simple
448"
REFERENCES,0.9535783365570599,"way to prevent neural networks from overfitting. The journal of machine learning research, 15(1), 1929-
449"
REFERENCES,0.9555125725338491,"1958.
450"
REFERENCES,0.9574468085106383,"[51] Blank, J., & Deb, K. (2020). Pymoo: Multi-objective optimization in python. IEEE Access, 8, 89497-
451"
REFERENCES,0.9593810444874274,"89509.
452"
REFERENCES,0.9613152804642167,"[52] Iman, R. L., Davenport, J. M., & Zeigler, D. K. (1980). Latin hypercube sampling (program user’s
453"
REFERENCES,0.9632495164410058,"guide).[LHC, in FORTRAN] (No. SAND-79-1473). Sandia Labs., Albuquerque, NM (USA).
454"
REFERENCES,0.965183752417795,"[53] Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang, J., & Zaremba, W. (2016).
455"
REFERENCES,0.9671179883945842,"Openai gym. arXiv preprint arXiv:1606.01540.
456"
REFERENCES,0.9690522243713733,"[54] Ros, R., & Hansen, N. (2008, September). A simple modification in CMA-ES achieving linear time and
457"
REFERENCES,0.9709864603481625,"space complexity. In International conference on parallel problem solving from nature (pp. 296-305).
458"
REFERENCES,0.9729206963249516,"Springer, Berlin, Heidelberg.
459"
REFERENCES,0.9748549323017408,"[55] Akimoto, Y., Auger, A., & Hansen, N. (2014, July). Comparison-based natural gradient optimization in
460"
REFERENCES,0.97678916827853,"high dimension. In Proceedings of the 2014 Annual Conference on Genetic and Evolutionary Computation
461"
REFERENCES,0.9787234042553191,"(pp. 373-380).
462"
REFERENCES,0.9806576402321083,"[56] Loshchilov, I. (2017). LM-CMA: An alternative to L-BFGS for large-scale black box optimization.
463"
REFERENCES,0.9825918762088974,"Evolutionary computation, 25(1), 143-171.
464"
REFERENCES,0.9845261121856866,"[57] Blank, J., & Deb, K. (2022). pysamoo: Surrogate-Assisted Multi-Objective Optimization in Python. arXiv
465"
REFERENCES,0.9864603481624759,"preprint arXiv:2204.05855.
466"
REFERENCES,0.988394584139265,"[58] Tian, Y., Wang, H., Zhang, X., & Jin, Y. (2017). Effectiveness and efficiency of non-dominated sorting for
467"
REFERENCES,0.9903288201160542,"evolutionary multi-and many-objective optimization. Complex & Intelligent Systems, 3(4), 247-263.
468"
REFERENCES,0.9922630560928434,"[59] Long, Q., Wu, X., & Wu, C. (2021). Non-dominated sorting methods for multi-objective optimization:
469"
REFERENCES,0.9941972920696325,"review and numerical comparison. Journal of Industrial & Management Optimization, 17(2), 1001.
470"
REFERENCES,0.9961315280464217,"[60] Salimans, T., Ho, J., Chen, X., Sidor, S., & Sutskever, I. (2017). Evolution strategies as a scalable
471"
REFERENCES,0.9980657640232108,"alternative to reinforcement learning. arXiv preprint arXiv:1703.03864.
472"
