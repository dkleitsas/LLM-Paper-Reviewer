Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0009025270758122744,"Topological Data Analysis (TDA) allows us to extract powerful topological, and
1"
ABSTRACT,0.0018050541516245488,"higher-order information on the global shape of a data set or point cloud. Tools
2"
ABSTRACT,0.002707581227436823,"like Persistent Homology or the Euler Transform give a single complex description
3"
ABSTRACT,0.0036101083032490976,"of the global structure of the point cloud. However, common machine learning
4"
ABSTRACT,0.004512635379061372,"applications like classification require point-level information and features to be
5"
ABSTRACT,0.005415162454873646,"available. In this paper, we bridge this gap and propose a novel method to extract
6"
ABSTRACT,0.00631768953068592,"node-level topological features from complex point clouds using discrete variants
7"
ABSTRACT,0.007220216606498195,"of concepts from algebraic topology and differential geometry. We verify the
8"
ABSTRACT,0.008122743682310469,"effectiveness of these topological point features (TOPF) on both synthetic and
9"
ABSTRACT,0.009025270758122744,"real-world data and study their robustness under noise.
10 1 Input"
ABSTRACT,0.009927797833935019,"2
3
4
Compute persistent"
ABSTRACT,0.010830324909747292,homology
ABSTRACT,0.011732851985559567,Pick significant
ABSTRACT,0.01263537906137184,generators
ABSTRACT,0.013537906137184115,Weighted harmonic
ABSTRACT,0.01444043321299639,representatives
ABSTRACT,0.015342960288808664,"Average over 
incident simplices"
ABSTRACT,0.016245487364620937,Topological Node Embeddings in
ABSTRACT,0.017148014440433214,"Biology, Machine Learning,"
ABSTRACT,0.018050541516245487,"Computer Vision, etc."
ABSTRACT,0.01895306859205776,Feature vectors
ABSTRACT,0.019855595667870037,"1
2
3
4"
ABSTRACT,0.02075812274368231,"1
2
3
4"
ABSTRACT,0.021660649819494584,"1
2
3
4"
ABSTRACT,0.02256317689530686,"1
2
3
4"
ABSTRACT,0.023465703971119134,"Feature vectors
Output"
ABSTRACT,0.024368231046931407,Applications
ABSTRACT,0.02527075812274368,"Figure 1: Schematic of Computing Topological Point Features (TOPF). Input. A point cloud X
in n-dimensional space. Step 1. To extract global topological information, the persistent homology
is computed on an α/VR-filtration. The most significant topological features F across all specified
dimensions are selected. Step 2. k-homology generators associated to all features fi,k ∈F are
computed. For every feature, a simplicial complex is built at a step of the filtration where fi,k is
alive. Step 3. The homology generators are projected to the harmonic space of the simplices. Step 4.
The vectors are normalised to obtain vectors ei
k indexed over the k-simplices. For every point x and
feature f ∈F, we compute the mean of the entries of ei
k corresponding to simplices containing x.
The output is a |X| × |F| matrix which can be used for downstream ML tasks. Optional. We weigh
the simplicial complexes resulting in a topologically more faithful harmonic representative in Step 3."
INTRODUCTION,0.026173285198555957,"1
Introduction
11"
INTRODUCTION,0.02707581227436823,"In modern machine learning [39], objects are described by feature vectors within a high-dimensional
12"
INTRODUCTION,0.027978339350180504,"space. However, the coordinates of a single vector can often only be understood in relation to the
13"
INTRODUCTION,0.02888086642599278,"entire data set: if the value x is small, average, large, or even an outlier depends on the remaining
14"
INTRODUCTION,0.029783393501805054,"data. In a 1-dimensional (or low-dimensional) case this issue can be addressed simply by normalising
15"
INTRODUCTION,0.030685920577617327,"the data points according to the global mean and standard deviation or similar procedures. We can
16"
INTRODUCTION,0.0315884476534296,"interpret this as the most straight-forward way to construct local features informed by the global
17"
INTRODUCTION,0.032490974729241874,"structure of the data set.
18"
INTRODUCTION,0.033393501805054154,"In the case where not all data dimensions are equally relevant, or contain correlated and redundant
19"
INTRODUCTION,0.03429602888086643,"information, we can apply (sparse) PCA to project the data points to a lower dimensional space
20"
INTRODUCTION,0.0351985559566787,"using information about the global structure of the point cloud [51]. For even more complex data,
21"
INTRODUCTION,0.036101083032490974,"we may first have to learn the encoded structure itself: indeed, a typical assumption underpinning
22"
INTRODUCTION,0.03700361010830325,"many unsupervised learning methods is the so-called “manifold hypothesis” which posits that
23"
INTRODUCTION,0.03790613718411552,"real world data can be described well via submanifolds of n-dimensional space [36, 21]. Using
24"
INTRODUCTION,0.0388086642599278,"eigenvectors of some Laplacian, we can then obtain a coordinate system intrinsic to the point cloud
25"
INTRODUCTION,0.039711191335740074,"(see e.g. [47, 4, 15]). Common to all these above examples is the goal is to construct locally
26"
INTRODUCTION,0.04061371841155235,"interpretable point-level features that encode globally meaningful positional information robust to
27"
INTRODUCTION,0.04151624548736462,"local perturbations of the data. However, none of these approaches is able to represent higher-order
28"
INTRODUCTION,0.042418772563176894,"topological information, making point clouds with these kind of structure inaccessible to point-level
29"
INTRODUCTION,0.04332129963898917,"machine learning algorithms.
30"
INTRODUCTION,0.04422382671480144,"Instead of focussing on the interpretation of individual points, topological data analysis (TDA), [9],
31"
INTRODUCTION,0.04512635379061372,"follows a different approach. TDA extracts a global description of the shape of data, which is typically
32"
INTRODUCTION,0.046028880866425995,"considered in the form of a high-dimensional point cloud. This is done measuring topological features
33"
INTRODUCTION,0.04693140794223827,"like persistence homology, which counts the number of generalised “holes” in the point cloud on
34"
INTRODUCTION,0.04783393501805054,"multiple scales. Due to their flexibility and robustness these global topological features have been
35"
INTRODUCTION,0.048736462093862815,"shown to contain relevant information in a broad range of application scenarios: In medicine, TDA
36"
INTRODUCTION,0.04963898916967509,"has provided methods to analyse cancer progression [33]. In biology, persistent homology has been
37"
INTRODUCTION,0.05054151624548736,"used to analyse knotted protein structures [5], and the spectrum of the Hodge Laplacian has been
38"
INTRODUCTION,0.05144404332129964,"used for predicting protein behaviour [50].
39"
INTRODUCTION,0.052346570397111915,"This success of topological data analysis is a testament to the fact that relevant information is encoded
40"
INTRODUCTION,0.05324909747292419,"in the global topological structure of point cloud data. Such higher-order topological information is
41"
INTRODUCTION,0.05415162454873646,"however invisible to standard tools of data analysis like PCA or k-means clustering, and can also not
42"
INTRODUCTION,0.055054151624548735,"be captured by graph models of the point cloud. We are now faced by a situation where (i) important
43"
INTRODUCTION,0.05595667870036101,"parts of the global structure of a complex point cloud can only be described by the language of
44"
INTRODUCTION,0.05685920577617329,"applied topology, however (ii) most standard methods to obtain positional point-level information are
45"
INTRODUCTION,0.05776173285198556,"not sensitive to the higher-order topology of the point cloud.
46"
INTRODUCTION,0.058664259927797835,"Contributions
We introduce TOPF (Figure 1), a novel method to compute node-level topological
47"
INTRODUCTION,0.05956678700361011,"features relating individual points to global topological structures of point clouds. TOPF (i) outper-
48"
INTRODUCTION,0.06046931407942238,"forms other methods and embeddings for clustering downstream tasks on topologically structured data,
49"
INTRODUCTION,0.061371841155234655,"returns (ii) provably meaningful representations, and is (iii) robust to noise. Finally, we introduce the
50"
INTRODUCTION,0.06227436823104693,"topological clustering benchmark suite, the first benchmark for topological clustering.
51"
INTRODUCTION,0.0631768953068592,"Related Work
The intersection of topological data analysis, topological signal processing and
52"
INTRODUCTION,0.06407942238267147,"geometry processing has many interesting related developments in the past few years. On the side
53"
INTRODUCTION,0.06498194945848375,"of homology and TDA, the authors in [16] and [41] use harmonic cohomology representatives to
54"
INTRODUCTION,0.06588447653429604,"reparametrise point clouds based on circular coordinates. This implicitly assumes that the underlying
55"
INTRODUCTION,0.06678700361010831,"structure of the point cloud is amenable to such a characterization. In [2, 26], the authors develop and
56"
INTRODUCTION,0.06768953068592058,"use harmonic persistent homology for data analysis. However, among other differences their focus
57"
INTRODUCTION,0.06859205776173286,"is not on providing robust topological point features. [24] uses the harmonic space of the Hodge
58"
INTRODUCTION,0.06949458483754513,"Laplacians to cluster point clouds respecting topology, but is unstable against some form of noise,
59"
INTRODUCTION,0.0703971119133574,"has no possibility for features selection across scales and is computationally far more expensive than
60"
INTRODUCTION,0.07129963898916968,"TOPF. For a more in-depth review of related work, see Appendix A
61"
INTRODUCTION,0.07220216606498195,"Organisation of the paper
In Section 2, we give an overview over the main ideas and concepts
62"
INTRODUCTION,0.07310469314079422,"behind of TOPF. In Section 3, we describe how to compute TOPF. In Section 4, we give a theoretical
63"
INTRODUCTION,0.0740072202166065,"result guaranteeing the correctness of TOPF. Finally, we will apply TOPF on synthetic and real-world
64"
INTRODUCTION,0.07490974729241877,"data in Section 5. Furthermore, Appendix A contains a brief history of topology and a detailed
65"
INTRODUCTION,0.07581227436823104,"discussion of related work. Appendix B contains additional theoretical considerations, Appendix C
66"
INTRODUCTION,0.07671480144404332,"describes the novel topological clustering benchmark suite, Appendix D contains details on the
67"
INTRODUCTION,0.0776173285198556,"implementation and the choice of hyperparameters, Appendix E gives a detailed treatment of feature
68"
INTRODUCTION,0.07851985559566788,"selection, Appendix F discusses simplicial weights, and Appendix G discusses limitations in detail.
69"
MAIN IDEAS OF TOPF,0.07942238267148015,"2
Main Ideas of TOPF
70"
MAIN IDEAS OF TOPF,0.08032490974729242,"A main goal of algebraic topology is to capture the shape of spaces. Techniques from topology
71"
MAIN IDEAS OF TOPF,0.0812274368231047,"describe globally meaningful structures that are indifferent to local perturbations and deformations.
72"
MAIN IDEAS OF TOPF,0.08212996389891697,"This robustness of topological features to local perturbations is particularly useful for the analysis
73"
MAIN IDEAS OF TOPF,0.08303249097472924,"of large-scale noisy datasets. To apply the ideas of algebraic topology in our TOPF pipeline, we
74"
MAIN IDEAS OF TOPF,0.08393501805054152,"need to formalise and explain the notion of topological features. An important observation for
75"
MAIN IDEAS OF TOPF,0.08483754512635379,"this is that high-dimensional point clouds and data may be seen as being sampled from topological
76"
MAIN IDEAS OF TOPF,0.08574007220216606,"spaces — most of the time, even low-dimensional submanifolds of Rn [21].
77"
MAIN IDEAS OF TOPF,0.08664259927797834,"In this section we provide a broad overview over the most important concepts of topology and TDA
78"
MAIN IDEAS OF TOPF,0.08754512635379061,"for our context, prioritising intuition over technical formalities. The interested reader is referred
79"
MAIN IDEAS OF TOPF,0.08844765342960288,"to [7, 27, 49] for a complete technical account of topology and [38] for an overview over TDA.
80"
MAIN IDEAS OF TOPF,0.08935018050541517,"Simplicial Complexes
Spaces in topology are continuous, consist of infinitely many points, and
81"
MAIN IDEAS OF TOPF,0.09025270758122744,"often live in abstract space. Our input data sets however consist of finitely many points embedded
82"
MAIN IDEAS OF TOPF,0.09115523465703972,"in real space Rn. In order to bridge this gap and open up topology to computational methods, we
83"
MAIN IDEAS OF TOPF,0.09205776173285199,"need a notion of discretised topological spaces consisting of finitely many base points with finite
84"
MAIN IDEAS OF TOPF,0.09296028880866426,"description length. A Simplicial Complex is the simplest discrete model that can still approximate
85"
MAIN IDEAS OF TOPF,0.09386281588447654,"any topological space occuring in practice [43]:
86"
MAIN IDEAS OF TOPF,0.09476534296028881,"Definition 2.1 (Simplicial complexes). A simplicial complex (SC) S consists of a set of vertices V
87"
MAIN IDEAS OF TOPF,0.09566787003610108,"and a set of finite non-empty subsets (simplices, S) of V closed under taking non-empty subsets, such
88"
MAIN IDEAS OF TOPF,0.09657039711191336,that the union over all simplices S
MAIN IDEAS OF TOPF,0.09747292418772563,"σ∈S σ is V . In the following, we will often identify S with its set
89"
MAIN IDEAS OF TOPF,0.0983754512635379,"of simplicies S and denote by Sk the set of simplices σ ∈S with |σ| = k + 1, called k-simplices. We
90"
MAIN IDEAS OF TOPF,0.09927797833935018,"say that S is n-dimensional, where n is the largest k such that the set of k-simplices Sk is non-empty.
91"
MAIN IDEAS OF TOPF,0.10018050541516245,"The k-skeleton of SC contains the simplices of dimension at most k. If the vertices V lie in real space
92"
MAIN IDEAS OF TOPF,0.10108303249097472,"Rn, we call the convex hull in Rn of a simplex σ its geometric realisation |σ|. When doing this for
93"
MAIN IDEAS OF TOPF,0.10198555956678701,"every simplex of S, we call this the geometric realisation of S, |S| ⊂Rn.
94"
MAIN IDEAS OF TOPF,0.10288808664259928,"Concretely, we can construct an n-dimensional SC S in n + 1 steps: First, we start with a set of
95"
MAIN IDEAS OF TOPF,0.10379061371841156,"vertices V which we can identify with the 0-simplices S0. Second, we connect certain pairs of
96"
MAIN IDEAS OF TOPF,0.10469314079422383,"vertices with edges, which constitute the set of 1-simplices. We can then choose to fill in some triples
97"
MAIN IDEAS OF TOPF,0.1055956678700361,"of vertices which are fully connected by 1-simplices with triangles, i.e. 2-simplices. More generally,
98"
MAIN IDEAS OF TOPF,0.10649819494584838,"in the kth step, we can add a k-simplex for every set σk of k + 1 vertices such that every k-element
99"
MAIN IDEAS OF TOPF,0.10740072202166065,"subset σk−1 of σk is already a (k −1)-simplex.
100"
MAIN IDEAS OF TOPF,0.10830324909747292,"Vietoris–Rips and α-complexes
We now need a way to construct a simplicial complex that
101"
MAIN IDEAS OF TOPF,0.1092057761732852,"approximates the topological structure inherent in our data set X ⊂Rn. Such a construction will
102"
MAIN IDEAS OF TOPF,0.11010830324909747,"always depend on the scale of the structures we are interested in. When looking from a very large
103"
MAIN IDEAS OF TOPF,0.11101083032490974,"distance, the point cloud will appear as a singular connected blob in the otherwise empty and infinite
104"
MAIN IDEAS OF TOPF,0.11191335740072202,"real space, on the other hand when we continue to zoom in, the point cloud will at some point appear
105"
MAIN IDEAS OF TOPF,0.11281588447653429,"as a collection of individual points separated by empty continuous space; all interesting information
106"
MAIN IDEAS OF TOPF,0.11371841155234658,"can be found in-between these two extreme scales where some vertices are joined by simplices and
107"
MAIN IDEAS OF TOPF,0.11462093862815885,"others are not. Instead of having to pick a single scale, the Vietoris–Rips (VR) filtration and the
108"
MAIN IDEAS OF TOPF,0.11552346570397112,"α-filtration take as input a point cloud and return a nested sequence of simplicial complexes indexed
109"
MAIN IDEAS OF TOPF,0.1164259927797834,"by a scale parameter ε approximating the topology of the data across all possible scales.
110"
MAIN IDEAS OF TOPF,0.11732851985559567,"Definition 2.2 (VR complex). Given a finite point cloud X in a metric space (M, d) and a non-
111"
MAIN IDEAS OF TOPF,0.11823104693140794,"negative real number ε ∈R≥0, the associated VR complex V Rε(X) is given by the vertex set X and
112"
MAIN IDEAS OF TOPF,0.11913357400722022,"the set of simplices S = {σ ⊂X | σ ̸= ∅, ∀x, y ∈σ : d(x, y) ≤ε}
113"
MAIN IDEAS OF TOPF,0.12003610108303249,"Intuitively, a VR complex with parameter ε consists of all simplices σ where all vertices x ∈σ have a
114"
MAIN IDEAS OF TOPF,0.12093862815884476,"pair-wise distance of at most ε. For r ≤r′, we obtain the canonical inclusions ir,r′(X): V Rr(X) ,→
115"
MAIN IDEAS OF TOPF,0.12184115523465704,"V Rr′(X). The set of VR complexes on X for all possible r ∈R≥0 together with the inclusions then
116"
MAIN IDEAS OF TOPF,0.12274368231046931,"form the VR filtration on X. For large point clouds, using the VR complex for computations becomes
117"
MAIN IDEAS OF TOPF,0.12364620938628158,"expensive due to its large number of simplices. In contrast, the more sophisticated α-complex
118"
MAIN IDEAS OF TOPF,0.12454873646209386,"approximates the topology of a point cloud using far fewer simplices and thus we will make use of it.
119"
MAIN IDEAS OF TOPF,0.12545126353790614,"For a complete account and definition of α-complexes and our reason to use them, see Appendix B.
120"
MAIN IDEAS OF TOPF,0.1263537906137184,"Boundary matrices
So far, we have discussed a discretised version of topological spaces in the
121"
MAIN IDEAS OF TOPF,0.1272563176895307,"form of SCs and a way to turn point clouds into a sequence of SCs indexed by a scale parameter.
122"
MAIN IDEAS OF TOPF,0.12815884476534295,"However, we still need an algebraic representation of simplicial complexes that is capable of encoding
123"
MAIN IDEAS OF TOPF,0.12906137184115524,"the structure of the SC and enables extraction of the topological features: The boundary matrices
124"
MAIN IDEAS OF TOPF,0.1299638989169675,"Bk associated to an SC S store all structural information of SC. The rows of Bk are indexed by the
125"
MAIN IDEAS OF TOPF,0.13086642599277978,"k-simplices of S and the columns are indexed by the (k + 1)-simplices.
126"
MAIN IDEAS OF TOPF,0.13176895306859207,"Definition 2.3 (Boundary matrices). Let S be a simplicial complex and ⪯a total order on its vertices
127"
MAIN IDEAS OF TOPF,0.13267148014440433,"V . Then, the i-th face map in dimension n f n
i : Sn →Sn−1 is given by
128"
MAIN IDEAS OF TOPF,0.13357400722021662,"f n
i : {v0, v1, . . . , vn} 7→{v0, v1, . . . , bvi, . . . , vn}"
MAIN IDEAS OF TOPF,0.13447653429602888,"with v0 ⪯v1 ⪯· · · ⪯vn and bvi denoting the omission of vi. Now, the n-th boundary operator
129"
MAIN IDEAS OF TOPF,0.13537906137184116,"Bn : R[Sn+1] →R[Sn] with R[Sn] being the real vector space over the basis Sn is given by
130"
MAIN IDEAS OF TOPF,0.13628158844765342,"Bn : σ 7→ n+1
X"
MAIN IDEAS OF TOPF,0.1371841155234657,"i=0
(−1)if n+1
i
(σ)."
MAIN IDEAS OF TOPF,0.13808664259927797,"When lexicographically ordering the simplex basis, we can view Bn as a matrix. We call R[Sn] the
131"
MAIN IDEAS OF TOPF,0.13898916967509026,"space of n-chains. Now, B0 is the vertex-edge incidence matrix of the associated graph consisting of
132"
MAIN IDEAS OF TOPF,0.13989169675090252,"the 0- and 1-simplices of S and B1 is the edge-triangle incidence matrix of S
133"
MAIN IDEAS OF TOPF,0.1407942238267148,"Figure 2: Sketch of Per-
sistent Homology, [23]"
MAIN IDEAS OF TOPF,0.14169675090252706,"Betti Numbers and Persistent Homology
We now turn to the notion of
134"
MAIN IDEAS OF TOPF,0.14259927797833935,"topological features and how to extract them. Homology is one of the main
135"
MAIN IDEAS OF TOPF,0.14350180505415164,"algebraic invariants to capture the shape of topological spaces and SC. From
136"
MAIN IDEAS OF TOPF,0.1444043321299639,"a technical point of view, the k-th homology module Hk(S) of an SC S
137"
MAIN IDEAS OF TOPF,0.14530685920577618,"with boundary operators Bk is defined as Hk(S) := ker Bk−1/ Im Bk. The
138"
MAIN IDEAS OF TOPF,0.14620938628158844,"generator or representative of a homology class is an element of the kernel
139"
MAIN IDEAS OF TOPF,0.14711191335740073,"ker Bk−1. In dimension 1, these are given by formal sums of 1-simplices
140"
MAIN IDEAS OF TOPF,0.148014440433213,"forming closed loops in the SC. Importantly, the rank rk Hk(S) is called
141"
MAIN IDEAS OF TOPF,0.14891696750902528,"the k-th Betti number Bk of S. In dimension 0, B0 counts the number of
142"
MAIN IDEAS OF TOPF,0.14981949458483754,"connected components, B1 counts the number of loops around ‘holes’ of
143"
MAIN IDEAS OF TOPF,0.15072202166064982,"the space, B2 counts the number of 3-dimensional voids with 2-dimensional
144"
MAIN IDEAS OF TOPF,0.15162454873646208,"boundary, and so on.
145"
MAIN IDEAS OF TOPF,0.15252707581227437,"If we are now given a filtration of simplicial complexes instead of a single
146"
MAIN IDEAS OF TOPF,0.15342960288808663,"SC, we can track how the homology modules evolve as the simplicial
147"
MAIN IDEAS OF TOPF,0.15433212996389892,"complex grows. The mathematical formalisation, persistent homology, thus
148"
MAIN IDEAS OF TOPF,0.1552346570397112,"turns a point cloud via a simplicial filtration into an algebraic object summarising the topological
149"
MAIN IDEAS OF TOPF,0.15613718411552346,"feature of the point cloud. For better computational performance, the computations are usually done
150"
MAIN IDEAS OF TOPF,0.15703971119133575,"in one of the small finite fields Z/pZ. Because we will later be interested in the sign of numbers
151"
MAIN IDEAS OF TOPF,0.157942238267148,"to distinguish different simplex orientations, we will use Z/3Z-coefficients, with Z/3Z being the
152"
MAIN IDEAS OF TOPF,0.1588447653429603,"smallest field being able to distinguish 1 and −1.
153"
MAIN IDEAS OF TOPF,0.15974729241877256,"The Hodge Laplacian and the Harmonic Space
In the previous part, we have introduced a
154"
MAIN IDEAS OF TOPF,0.16064981949458484,"language to characterise the global shape of spaces and point clouds. However, we still need to find
155"
MAIN IDEAS OF TOPF,0.1615523465703971,"a way to relate these global characterisations back to local properties of the point cloud. We will
156"
MAIN IDEAS OF TOPF,0.1624548736462094,"do so by using ideas and concepts from differential geometry and topology: The simplicial Hodge
157"
MAIN IDEAS OF TOPF,0.16335740072202165,"Laplacian is a discretisation of the Hodge–Laplace operator acting on differential forms of manifolds:
158"
MAIN IDEAS OF TOPF,0.16425992779783394,"Definition 2.4 (Hodge Laplacian). Given a simplicial complex S with boundary operators Bk, we
159"
MAIN IDEAS OF TOPF,0.1651624548736462,"define the n-th Hodge Laplacian Ln : R[Sn] →R[Sn] by setting
160"
MAIN IDEAS OF TOPF,0.16606498194945848,"Ln := B⊤
n−1Bn−1 + BnB⊤
n ."
MAIN IDEAS OF TOPF,0.16696750902527077,"The Hodge Laplacian gives rise to the Hodge decomposition theorem:
161"
MAIN IDEAS OF TOPF,0.16787003610108303,Algorithm 1 Topological Point Features (TOPF)
MAIN IDEAS OF TOPF,0.16877256317689532,"Input: Point cloud X ∈Rn, maximum homology dimension d ∈N, interpolation coeff. λ.
1. Compute persistent homology with generators in dimension k ≤d.
2. Select set of significant features (bi, di, gi) with birth, death, and generator in F3 coordinates.
3. Embed gi into real space and project into harmonic subspace of SC at step t = λbi + (1 −λ)di.
4. Normalise projections to ek
i and compute F i
k(x) := avgx∈σ(ek
i l(σ)) for all points x ∈X.
Output: Features of x ∈X"
MAIN IDEAS OF TOPF,0.16967509025270758,"2
4
6
8
10
12
14
Birth 2 4 6 8 10 12 14 Death"
MAIN IDEAS OF TOPF,0.17057761732851986,Persistence diagram 1
MAIN IDEAS OF TOPF,0.17148014440433212,selected features
MAIN IDEAS OF TOPF,0.1723826714801444,"Figure 3: TOPF pipeline applied to NALCN channelosome, a membran protein [32]. Left: Steps
1&2a, when computing persistent 1-homology, three classes are more prominent than the rest. Centre:
Step 2b: The selected homology generators. Right: Step 3: The projections of the generators into
(weighted) harmonic are now each supported on one of the three rings."
MAIN IDEAS OF TOPF,0.17328519855595667,"Theorem 2.5 (Hodge Decomposition [34, 46, 44]). For an SC S with boundary matrices (Bi) and
162"
MAIN IDEAS OF TOPF,0.17418772563176896,"Hodge Laplacians (Li), we have in every dimension k
163"
MAIN IDEAS OF TOPF,0.17509025270758122,"R[Sk] = Im B⊤
k−1
|
{z
}
gradient space"
MAIN IDEAS OF TOPF,0.1759927797833935,"⊕
ker Lk
| {z }
harmonic space
⊕Im Bk
| {z }
curl space
."
MAIN IDEAS OF TOPF,0.17689530685920576,"This, together with the fact that the k-th harmonic space is isomorphic to the k-th real-valued
164"
MAIN IDEAS OF TOPF,0.17779783393501805,"homology group ker Lk ∼= Hk(R) means that we can associate a unique harmonic representative
165"
MAIN IDEAS OF TOPF,0.17870036101083034,"to every homology class. The harmonic space encodes higher-order generalisations of smooth flow
166"
MAIN IDEAS OF TOPF,0.1796028880866426,"around the holes of the simplicial complex. Intuitively, this means that for every abstract global
167"
MAIN IDEAS OF TOPF,0.18050541516245489,"homology class of persistent homology from above we can now compute one unique harmonic
168"
MAIN IDEAS OF TOPF,0.18140794223826714,"representative in ker Lk that assigns every simplex a value based on how much it contributes to the
169"
MAIN IDEAS OF TOPF,0.18231046931407943,"homology class. Thus, the Hodge Laplacian is a gateway between the global topological features
170"
MAIN IDEAS OF TOPF,0.1832129963898917,"and the local properties of our SC. It is easy to show that the kernel of the Hodge Laplacian is the
171"
MAIN IDEAS OF TOPF,0.18411552346570398,"intersection of the kernel of the boundary and the coboundary map ker Lk = ker Bn−1 ∩ker B⊤
n .
172"
MAIN IDEAS OF TOPF,0.18501805054151624,"Because we have finite SCs we can identify the spaces of chains and cochains. This leads to another
173"
MAIN IDEAS OF TOPF,0.18592057761732853,"characterisation of the harmonic space: The space of chains that are simultaneously homology and
174"
MAIN IDEAS OF TOPF,0.18682310469314078,"cohomology representatives.
175"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.18772563176895307,"3
How to Compute Topological Point Features
176"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.18862815884476533,"In this section, we will combine the ideas and insights of the previous section to give a complete
177"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.18953068592057762,"account of how to compute Topological point features (TOPF). A pseudo-code version can be found
178"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.19043321299638988,"in Algorithm 1 and an overview in Figure 1. We start with a finite point cloud X ⊂Rn.
179"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.19133574007220217,"Step 1: Computing the persistent homology
First, we need to determine the most significant
180"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.19223826714801445,"persistent homology classes which determine the shape of the point cloud. By doing this, we can
181"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.1931407942238267,"also extract the “interesting” scales of the data set. We will later use this to construct SCs to derive
182"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.194043321299639,"local variants of the global homology features. Thus we first compute the persistent k-homology
183"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.19494584837545126,"modules Pk including a set of homology representatives Rk of X using an α-filtration for n ≤3 and
184"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.19584837545126355,"a VR filtration for n > 3. We use Z/3Z coefficients to be sensitive to simplex orientations. In case we
185"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.1967509025270758,"have prior knowledge on the data set, we can choose a real number R ∈R>0 and only compute the
186"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.1976534296028881,"filtration and persistent homology connecting points up to a distance of at most R. In data sets like
187"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.19855595667870035,"protein atom coordinates, this might be useful as we have prior knowledge on what constitutes the
188"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.19945848375451264,"“interesting” scale, reducing computational complexity. See Figure 3 left for a persistent homology
189"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.2003610108303249,"diagram.
190"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.20126353790613719,"Step 2: Selecting the relevant topological features
We now need to select the relevant homology
191"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.20216606498194944,"classes which carry the most important global information. The persistent homology Pk module in
192"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.20306859205776173,"dimension k is given to us as a list of pairs of birth and death times (bk
i , dk
i ). We can assume these
193"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.20397111913357402,"pairs are ordered in non-increasing order of the durations lk
i = dk
i −bk
i . This list is typically very
194"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.20487364620938628,"long and consists to a large part of noisy homological features which vanish right after they appear.
195"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.20577617328519857,"In contrast, we are interested in connected components, loops, cavities, etc. that persist over a long
196"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.20667870036101083,"time, indicating that they are important for the shape of the point cloud. Distinguishing between the
197"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.2075812274368231,"relevant and the irrelevant features is in general difficult and may depend on additional insights on
198"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.20848375451263537,"the domain of application. In order to provide a heuristic which does not depend on any a-priori
199"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.20938628158844766,"assumptions on the number of relevant features we pick the smallest quotient qk
i := lk
i+1/lk
i > 0
200"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.21028880866425992,"as the point of cut-off Nk := arg mini qk
i . The only underlying assumption of this approach is that
201"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.2111913357400722,"the band of “relevant” features is separated from the “noisy” homological features by a drop in
202"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.21209386281588447,"persistence. If this assumption is violated, the only possible way to do meaningful feature selection
203"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.21299638989169675,"depends on application-specific domain knowledge. We found that our proposed heuristics work well
204"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.213898916967509,"across a large scale of applications. See Figure 3 left and centre for an illustration and Appendix E
205"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.2148014440433213,"for more technical details and ways to improve and adapt the feature selection module of TOPF. We
206"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.2157039711191336,"call the chosen k-homology classes including k-homology generators in dimension f i
k.
207"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.21660649819494585,"Step 3: Projecting the features into harmonic space and normalising
In this step, we need to
208"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.21750902527075813,"relate the global topology extracted in the previous step to the simplices which we will use to compute
209"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.2184115523465704,"the local topological point feature. Every selected feature f i
k of the previous step comes with a birth
210"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.21931407942238268,"time bi,k and a death time di,k. This means that the homology class f i
k is present in every SC of
211"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.22021660649819494,"the filtration between step ε = bi,k and ε = di,k and we could choose any of the SCs for the next
212"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.22111913357400723,"step. Picking a small ε will lead to fewer simplices in the SC and thus to a very localised harmonic
213"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.22202166064981949,"representative. Picking a large ε will lead to many simplices in the SC and thus to a very smooth
214"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.22292418772563177,"and “blurry” harmonic representative with large support. Finding a middle ground between these
215"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.22382671480144403,"regimes returns optimal results. For the interpolation parameter γ ∈(0, 1), we will thus consider the
216"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.22472924187725632,"simplicial complex Sti,k(X) at step ti,k := b1−γ
i,k dγ
i,k for k > 0 and at step ti,k := γdi,k for k = 0
217"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.22563176895306858,"of the simplicial filtration. At this point, the homology class f i
k is still alive. We then consider the
218"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.22653429602888087,"real vector space R[Sti,k
k
(X)] with formal basis consisting of the k-simplices of the SC Sti,k. From
219"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.22743682310469315,"the persistent homology computation of the first step, we also obtain a generator of the feature f i
k,
220"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.2283393501805054,"consisting of a list Σi
k of simplices ˆσj ∈Sbi,k
k
and coefficients cj ∈Z/3Z. We need to turn this
221"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.2292418772563177,"formal sum of simplices with Z/3Z-coefficients into a vector in the real vector space R[Sti,k
k
(X)]:
222"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.23014440433212996,"Let ι: Z/3Z be the map induced by the canonical inclusion of {−1, 0, 1} ,→R. We can now define
223"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.23104693140794225,"an indicator vector ei
k ∈R[Sti,k
k
(X)] associated to the feature f i
k.
224"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.2319494584837545,"ei
k(σ) :=
ι(cj)
∃ˆσj ∈Σi
k : σ = ˆσj
0
else
."
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.2328519855595668,"While this homology representative lives in a real vector space, it is not unique, has a small support,
225"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.23375451263537905,"and can differ largely between close simplices. All of these problems can be solved by projecting
226"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.23465703971119134,"the homology representative to the harmonic subspace ker Lk of R[Sti,k
k
(X)]. Rather than directly
227"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.2355595667870036,"projecting ei
k to the harmonic subspace, we make use of the Hodge decomposition theorem (The-
228"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.2364620938628159,"orem 2.5) which allows us to compute the gradient and curl projections solving computationally
229"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.23736462093862815,"efficient least square problems:
230"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.23826714801444043,"ei
k,grad := B⊤
k−1 arg min
x∈R[Sk−1]"
HOW TO COMPUTE TOPOLOGICAL POINT FEATURES,0.23916967509025272,"ei
k −B⊤
k−1x
2"
"AND
EI",0.24007220216606498,"2
and
ei
k,curl := Bk arg min
x∈R[Sk+1]"
"AND
EI",0.24097472924187727,"ei
k −ei
k,grad −Bkx
2 2"
"AND
EI",0.24187725631768953,"and then setting ˆei
k := ei
k −ei
k,grad −ei
k,curl. (Cf. Figure 3 right for a visualisation.) Because homology
231"
"AND
EI",0.2427797833935018,"representatives are gradient-free, we only need to consider the projection of ei
k into the curl space.
232"
"AND
EI",0.24368231046931407,"Step 4: Processing and aggregation at a point level
In the previous step, we have computed
233"
"AND
EI",0.24458483754512636,"a set of simplex-valued harmonic representatives of homology classes. However, these simplices
234"
"AND
EI",0.24548736462093862,"likely have no real-world meaning and the underlying simplicical complexes differ depending
235"
"AND
EI",0.2463898916967509,"on the birth and death times of the homology classes. Hence in this step, we will collect the
236"
"AND
EI",0.24729241877256317,"features on the point-level after performing some necessary preprocessing. Given a simplex-valued
237"
"AND
EI",0.24819494584837545,"vector ˆei
k and a hyperparameter δ, we now construct ei
k : Sti,k
k
(X) →[0, 1] by setting ei
k : σ 7→∈
238"
"AND
EI",0.2490974729241877,"{|ˆei
k(σ)|/(δ maxσ′∈S
ti,k
k
(X) |ˆei
k(σ′)|), 1} such that ˆei
k is normalised to [0, 1], the values of [0, δ] are
239"
"AND
EI",0.25,"mapped linearly to [0, 1] and everything above is sent to 1. We found empirically that a thresholding
240"
"AND
EI",0.2509025270758123,"parameter of δ = 0.07 works best across at the range of applications considered below. However,
241"
"AND
EI",0.2518050541516246,"TOPF is not sensitive to small changes to δ because entries of ˆei
k are concentrated around 0.
242"
"AND
EI",0.2527075812274368,"For every feature f i
k in dimension k with processed simplicial feature vector ei
k and simplicial
243"
"AND
EI",0.2536101083032491,"complex Sti,k, we define the point-level feature map F k
i : X →R mapping from the initial point
244"
"AND
EI",0.2545126353790614,"cloud X to R by setting
245"
"AND
EI",0.25541516245487367,"F k
i : v 7→ P"
"AND
EI",0.2563176895306859,"σk∈S
ti,k
k
: v∈σk ei
k(σk)"
"AND
EI",0.2572202166064982,"max(1, |{σk ∈St
k : v ∈σk}|)."
"AND
EI",0.2581227436823105,"For every point v, we can thus view the vector (F k
i (v): f k
i ∈F) as a feature vector for v. We call
246"
"AND
EI",0.25902527075812276,"this collection of features Topological Point Features (TOPF). (Cf. Figure 4 for an example).
247"
"AND
EI",0.259927797833935,"Choosing Simplicial Weights
By default, the simplicial complexes of α- and VR filtrations are
248"
"AND
EI",0.2608303249097473,"unweighted. However, the weights determine the entries of the harmonic representatives, increasing
249"
"AND
EI",0.26173285198555957,"and decreasing the influence of certain simplices and parts of the simplicial complex. We can use this
250"
"AND
EI",0.26263537906137185,"observation to increase the robustness of TOPF against the influence of heterogeneous point cloud
251"
"AND
EI",0.26353790613718414,"structure, which is present in virtually all real-world data sets. For a complete technical account of
252"
"AND
EI",0.2644404332129964,"how and why we do this, see Appendix F.
253"
THEORETICAL GUARANTEES,0.26534296028880866,"4
Theoretical guarantees
254"
THEORETICAL GUARANTEES,0.26624548736462095,"In this section, we prove the relationship between TOPF and actual topological structure in datasets:
255"
THEORETICAL GUARANTEES,0.26714801444043323,"Theorem 4.1 (Topological Point Features of Spheres). Let X consist of at least (n + 2) points
256"
THEORETICAL GUARANTEES,0.26805054151624547,"(denoted by S) sampled uniformly at random from a unit n-sphere in Rn+1 and an arbitrary number
257"
THEORETICAL GUARANTEES,0.26895306859205775,"of points with distance of at least 2 to S. When we now consider the α-filtration on this point
258"
THEORETICAL GUARANTEES,0.26985559566787004,"cloud, with probability 1 we have that (i) there exists an n-th persistent homology class generated
259"
THEORETICAL GUARANTEES,0.27075812274368233,"by the 2-simplices on the convex hull hull of S, (ii) the associated unweighted harmonic homology
260"
THEORETICAL GUARANTEES,0.27166064981949456,"representative takes values in {0, ±1} where the 2-simplices on the boundary of the convex hull are
261"
THEORETICAL GUARANTEES,0.27256317689530685,"assigned a value of ±1, and (iii) the support of the associated topological point feature (TOPF) F∗
n
262"
THEORETICAL GUARANTEES,0.27346570397111913,"is precisely S: supp(F∗
n) = S. (iv) The same holds true for point clouds sampled from multiple
263"
THEORETICAL GUARANTEES,0.2743682310469314,"ni-spheres if the above conditions are met on each individual sphere.
264"
THEORETICAL GUARANTEES,0.2752707581227437,"We will give a proof of this theorem in Appendix B.
265"
THEORETICAL GUARANTEES,0.27617328519855594,"Remark 4.2. In practice, datasets with topological structure consist in a majority of cases of points
266"
THEORETICAL GUARANTEES,0.2770758122743682,"sampled with noise from deformed n-spheres. The theorem thus guarantees that TOPF will recover
267"
THEORETICAL GUARANTEES,0.2779783393501805,"these structural information in an idealised setting. Experimental evidence suggests that this holds
268"
THEORETICAL GUARANTEES,0.2788808664259928,"under the addition of noise as well which is plausible as harmonic persistent homology is robust
269"
THEORETICAL GUARANTEES,0.27978339350180503,"against some noise [2].
270"
EXPERIMENTS,0.2806859205776173,"5
Experiments
271"
EXPERIMENTS,0.2815884476534296,"In this section, we conduct experiments on real world and synthetic data, compare the clustering
272"
EXPERIMENTS,0.2824909747292419,"results with clustering by TPCC, other classical clustering algorithms, and other point features, and
273"
EXPERIMENTS,0.2833935018050541,"demonstrate the robustness of TOPF against noise.
274"
EXPERIMENTS,0.2842960288808664,"Topological Point Cloud Clustering Benchmark
We introduce the topological clustering bench-
275"
EXPERIMENTS,0.2851985559566787,"mark suite (Appendix C) and report running times and the accuracies of clustering based on TOPF
276"
EXPERIMENTS,0.286101083032491,"and other methods and point embeddings, see Table 1. We see that TOPF outperforms all classical
277"
EXPERIMENTS,0.2870036101083033,"clustering algorithms on all but one dataset by a wide margin. We also see that TOPF closely matches
278"
EXPERIMENTS,0.2879061371841155,"the performance of the only other higher-order topological clustering algorithm, TPCC on two datasets
279"
EXPERIMENTS,0.2888086642599278,"with clear topological features, whereas TOPF outperforms TPCC on datasets with more complex
280"
EXPERIMENTS,0.2897111913357401,"structure. In addition, TOPF has a consistently lower running time with better scaling for the more
281"
EXPERIMENTS,0.29061371841155237,"Table 1: Quantitative performance comparison of clustering with TOPF and other fea-
tures/clustering algorithms. Four 2D and three 3D data sets of the topological clustering benchmark
suite (Appendix C, cf. Figure 6 for ground truth labels and Figure 7 for clustering results of TOPF).
We ran each algorithm 20 times and list the mean adjusted rand index (ARI) with standard deviation
σ and mean running time. We omit σ for algorithms with σ = 0 on every dataset. TOPF consistently
outperforms or almost matches the other algorithms while having significantly better run time than
the second best performing algorithm TPCC. Spectral Clustering (SC), DBSCAN, and Agglomerative
Clustering (AgC) are standard clustering algorithms, ToMATo is a topological clustering algorithm
[11], Geo clusters using 12-dimensional point geometric features extracted by pgeof and the normal
point coordinates, whereas node2vec [25] produces node embeddings on a k-nearest neighbour graph
built upon an affinity matrix. We highlight all ARI scores within ±0.05 of the best ARI score."
EXPERIMENTS,0.2915162454873646,"TOPF (ours)
TPCC
SC
DBSCAN
AgC
ToMATo
Geo
node2vec"
"SPHERES
ARI",0.2924187725631769,"4spheres
ARI
0.81
0.52±0.17
0.37
0.00
0.45
0.32
0.20
0.00±0.00
time (s)
14.5
23.3
0.2
0.0
0.0
0.0
0.2
48.4"
"SPHERES
ARI",0.2933212996389892,"Ellipses
ARI
0.95
0.47±0.04
0.25
0.19
0.52
0.29
0.81
0.02±0.00
time (s)
12.7
14.4
0.1
0.0
0.0
0.0
0.1
11.2"
"SPHERES
ARI",0.29422382671480146,"Spheres+Grid
ARI
0.70
0.39±0.04
0.90
0.92
0.89
0.82
0.41
0.01±0.00
time (s)
13.0
28.5
0.5
0.0
0.0
0.0
0.3
63.8"
"SPHERES
ARI",0.2951263537906137,"Halved Circle
ARI
0.71
0.18±0.12
0.24
0.00
0.20
0.16
0.08
0.00±0.01
time (s)
12.2
14.3
0.1
0.0
0.0
0.0
0.1
18.2"
"SPHERES
ARI",0.296028880866426,"2Spheres2Circles
ARI
0.94
0.97±0.01
0.70
0.00
0.51
0.87
0.12
0.00±0.00
time (s)
38.9
1662.2
1.6
0.0
0.3
0.0
0.9
348.6"
"SPHERES
ARI",0.29693140794223827,"SphereinCircle
ARI
0.97
0.98±0.0
0.34
0.00
0.29
0.06
0.69
0.13±0.03
time (s)
14.5
8.0
0.0
0.0
0.0
0.0
0.08
20.1"
"SPHERES
ARI",0.29783393501805056,"Spaceship
ARI
0.92
0.56±0.03
0.28
0.26
0.47
0.30
0.87
0.07±0.00
time (s)
16.3
341.8
16.7
0.0
0.0
0.0
0.2
49.8"
"SPHERES
ARI",0.29873646209386284,"mean
ARI
0.86
0.58
0.44
0.16
0.48
0.40
0.45
0.03
time (s)
17.5
298.9
0.4
0.0
0.0
0.0
0.3
80.0"
"SPHERES
ARI",0.2996389891696751,"Figure 4: TOPF on 3D real-world and synthetic point clouds. For every point, we highlight the
largest corresponding topological feature, where colour stands for the different features and saturation
for the value of the feature. (a): Atoms of mutated Cys123 of E. coli [29]. We added auxiliary
points on the convex hull and considered 2-homology, to detect the protein pockets which are crucial
for protein-environment interactions (Cf. [40]). (b): Atoms of NALCN Channelosome [32] display
three distinct loops. (c): Points sampled in the state space of a Lorentz attractor. The two features
correspond to the two lobes of the attractor. (d): Point cloud spaceship of our newly introduced
topological clustering benchmark suite (See Appendix C)."
"SPHERES
ARI",0.30054151624548736,"0.0
0.2
0.4
0.6
0.8
1.0
noise 0.0 0.2 0.4 0.6 0.8 1.0 ARI"
"SPHERES
ARI",0.30144404332129965,Method
"SPHERES
ARI",0.30234657039711194,"TOPF untuned
TOPF tuned
KMeans
Spectral Clustering
TPCC
Spectral on SC"
"SPHERES
ARI",0.30324909747292417,"0
100 200 300 400 500 600
No. Outliers 0.0 0.2 0.4 0.6 0.8 1.0 ARI"
"SPHERES
ARI",0.30415162454873645,"Figure 5: Performance of Clustering based on TOPF features in increasing noise/outlier levels
with 95% CI. Left: We add i.i.d. Gaussian noise to every point with standard deviation indicated by
the noise parameter. We see that even when compared with TPCC on a data set specifically crafted
for TPCC, TOPF requires significantly less information and delivers almost equal performance. When
tuned for datasets with a high noise level, the TOPF even outperform TPCC and drastically outperform
all classical clustering algorithms. Right: We add outliers with the same standard deviation as the
point cloud to the data set. We then measure the adjusted rand index obtained restricted on the
original points. We see that even when compared with TPCC on a data set specifically crafted for
TPCC, TOPF requires significantly less information and delivers matching to superior performance,
significantly outperforming all other classical clustering algorithms."
"SPHERES
ARI",0.30505415162454874,"complex datasets, while also not requiring prior knowledge on the best topological scale. As for the
282"
"SPHERES
ARI",0.30595667870036103,"other point embeddings, Node2Vec is not able to capture any meaningful topological information,
283"
"SPHERES
ARI",0.30685920577617326,"whereas the performance of clustering using geometric features depends on the data set.
284"
"SPHERES
ARI",0.30776173285198555,"Feature Generation
In Figure 4, we show qualitatively that TOPF constructs meaningful topological
285"
"SPHERES
ARI",0.30866425992779783,"features on data sets from Biology and Physics, and synthetic data, corresponding to for example
286"
"SPHERES
ARI",0.3095667870036101,"rings and pockets in proteins or trajectories around different attractors in dynamical systems. (For
287"
"SPHERES
ARI",0.3104693140794224,"individual heatmaps see Figure 8)
288"
"SPHERES
ARI",0.31137184115523464,"Robustness against noise
We have evaluated the robustness of TOPF against Gaussian noise on
289"
"SPHERES
ARI",0.31227436823104693,"the dataset introduced in [24] and compared the results against TPCC, Spectral Clustering, Graph
290"
"SPHERES
ARI",0.3131768953068592,"Spectral Clustering on the graph constructed by TPCC, and against k-means in Figure 5 Left. We have
291"
"SPHERES
ARI",0.3140794223826715,"also analysed the robustness of TOPF against the addition of outliers in Figure 5 Right. We see that
292"
"SPHERES
ARI",0.31498194945848373,"TOPF performs well in both cases, underlining our claim of robustness.
293"
DISCUSSION,0.315884476534296,"6
Discussion
294"
DISCUSSION,0.3167870036101083,"Limitations
TOPF can — by design — only produce meaningful output on point clouds with a
295"
DISCUSSION,0.3176895306859206,"topological structure quantifiable by persistent homology. In practice it is thus desirable to combine
296"
DISCUSSION,0.3185920577617328,"TOPF with some geometric or other point-level feature extractor. As TOPF relies on the computation of
297"
DISCUSSION,0.3194945848375451,"persistent homology, its runtime increases on very large point clouds, especially in higher dimensions
298"
DISCUSSION,0.3203971119133574,"where α-filtrations are computationally infeasible. However, subsampling, either randomly or using
299"
DISCUSSION,0.3212996389891697,"landmarks, usually preserves relevant topological features while improving run time [41]. Finally,
300"
DISCUSSION,0.322202166064982,"selection of the relevant features is a very hard problem. While our proposed heuristics work well
301"
DISCUSSION,0.3231046931407942,"across a variety of domains and application scenarios, only domain- and problem-specific knowledge
302"
DISCUSSION,0.3240072202166065,"makes correct feature selection feasible.
303"
DISCUSSION,0.3249097472924188,"Future Work
The integration of higher-order TOPF features into ML pipelines that require point-
304"
DISCUSSION,0.32581227436823107,"level features potentially leads to many new interesting insights across the domains of biology, drug
305"
DISCUSSION,0.3267148014440433,"design, graph learning and computer vision. Furthermore, efficient computation of simplicial weights
306"
DISCUSSION,0.3276173285198556,"leading to the provably most faithful topological point features is an exciting open problem.
307"
DISCUSSION,0.3285198555956679,"Conclusion
We introduced point-level features TOPF founded on algebraic topology relating global
308"
DISCUSSION,0.32942238267148016,"structural features to local information. We gave theoretical guarantees for the correctness of their
309"
DISCUSSION,0.3303249097472924,"construction and evaluated them quantitatively and qualitatively on synthetic and real-world data sets.
310"
DISCUSSION,0.3312274368231047,"Finally, we introduced the novel topological clustering benchmark suite and showed that clustering
311"
DISCUSSION,0.33212996389891697,"using TOPF outperforms other available clustering methods and features extractors.
312"
REFERENCES,0.33303249097472926,"References
313"
REFERENCES,0.33393501805054154,"[1] Michael Atiyah. K-theory. CRC press, 1989.
314"
REFERENCES,0.3348375451263538,"[2] Saugata Basu and Nathanael Cox. Harmonic persistent homology. In 2021 IEEE 62nd Annual
315"
REFERENCES,0.33574007220216606,"Symposium on Foundations of Computer Science (FOCS), pages 1112–1123. IEEE, 2022.
316"
REFERENCES,0.33664259927797835,"[3] Ulrich Bauer. Ripser: efficient computation of vietoris–rips persistence barcodes. Journal of
317"
REFERENCES,0.33754512635379064,"Applied and Computational Topology, 5(3):391–423, 2021.
318"
REFERENCES,0.33844765342960287,"[4] Mikhail Belkin and Partha Niyogi. Laplacian eigenmaps for dimensionality reduction and data
319"
REFERENCES,0.33935018050541516,"representation. Neural computation, 15(6):1373–1396, 2003.
320"
REFERENCES,0.34025270758122744,"[5] Katherine Benjamin, Lamisah Mukta, Gabriel Moryoussef, Christopher Uren, Heather A
321"
REFERENCES,0.34115523465703973,"Harrington, Ulrike Tillmann, and Agnese Barbensi. Homology of homologous knotted proteins.
322"
REFERENCES,0.34205776173285196,"Journal of the Royal Society Interface, 20(201):20220727, 2023.
323"
REFERENCES,0.34296028880866425,"[6] A. K. Bousfield. The localization of spaces with respect to homology. Topology, 14(2):133–150,
324"
REFERENCES,0.34386281588447654,"1975.
325"
REFERENCES,0.3447653429602888,"[7] G.E. Bredon, J.H. Ewing, F.W. Gehring, and P.R. Halmos. Topology and Geometry. Graduate
326"
REFERENCES,0.3456678700361011,"Texts in Mathematics. Springer, New York, 1993.
327"
REFERENCES,0.34657039711191334,"[8] Peter Bubenik et al. Statistical topological data analysis using persistence landscapes. J. Mach.
328"
REFERENCES,0.34747292418772563,"Learn. Res., 16(1):77–102, 2015.
329"
REFERENCES,0.3483754512635379,"[9] Gunnar Carlsson and Mikael Vejdemo-Johansson. Topological Data Analysis with Applications.
330"
REFERENCES,0.3492779783393502,"Cambridge University Press, 2021.
331"
REFERENCES,0.35018050541516244,"[10] Charu Chaudhry, Arthur L Horwich, Axel T Brunger, and Paul D Adams. Exploring the struc-
332"
REFERENCES,0.3510830324909747,"tural dynamics of the e. coli chaperonin groel using translation-libration-screw crystallographic
333"
REFERENCES,0.351985559566787,"refinement of intermediate states. Journal of molecular biology, 342(1):229–245, 2004.
334"
REFERENCES,0.3528880866425993,"[11] Frédéric Chazal, Leonidas J. Guibas, Steve Y. Oudot, and Primoz Skraba. Persistence-based
335"
REFERENCES,0.35379061371841153,"clustering in riemannian manifolds. J. ACM, 60(6), nov 2013.
336"
REFERENCES,0.3546931407942238,"[12] Frédéric Chazal and Bertrand Michel. An introduction to topological data analysis: fundamental
337"
REFERENCES,0.3555956678700361,"and practical aspects for data scientists. Frontiers in artificial intelligence, 4:108, 2021.
338"
REFERENCES,0.3564981949458484,"[13] Yu-Chia Chen and Marina Meil˘a. The decomposition of the higher-order homology embedding
339"
REFERENCES,0.3574007220216607,"constructed from the k-laplacian. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and
340"
REFERENCES,0.3583032490974729,"J. Wortman Vaughan, editors, Advances in Neural Information Processing Systems, volume 34,
341"
REFERENCES,0.3592057761732852,"pages 15695–15709. Curran Associates, Inc., 2021.
342"
REFERENCES,0.3601083032490975,"[14] Yu-Chia Chen, Marina Meil˘a, and Ioannis G Kevrekidis. Helmholtzian eigenmap: Topological
343"
REFERENCES,0.36101083032490977,"feature discovery & edge flow learning from point cloud data. arXiv preprint arXiv:2103.07626,
344"
REFERENCES,0.361913357400722,"2021.
345"
REFERENCES,0.3628158844765343,"[15] Ronald R Coifman and Stéphane Lafon. Diffusion maps. Applied and computational harmonic
346"
REFERENCES,0.3637184115523466,"analysis, 21(1):5–30, 2006.
347"
REFERENCES,0.36462093862815886,"[16] Vin De Silva and Mikael Vejdemo-Johansson. Persistent cohomology and circular coordinates.
348"
REFERENCES,0.3655234657039711,"In Proceedings of the twenty-fifth annual symposium on Computational geometry, pages 227–
349"
REFERENCES,0.3664259927797834,"236, 2009.
350"
REFERENCES,0.36732851985559567,"[17] Richard Dedekind. Was sind und was sollen die Zahlen? Verlag Friedrich Vieweg und Sohn,
351"
REFERENCES,0.36823104693140796,"Braunschweig, 1888.
352"
REFERENCES,0.36913357400722024,"[18] Boris Delaunay et al. Sur la sphere vide. Izv. Akad. Nauk SSSR, Otdelenie Matematicheskii i
353"
REFERENCES,0.3700361010830325,"Estestvennyka Nauk, 7(793-800):1–2, 1934.
354"
REFERENCES,0.37093862815884476,"[19] Stefania Ebli and Gard Spreemann. A notion of harmonic clustering in simplicial complexes.
355"
REFERENCES,0.37184115523465705,"In 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA),
356"
REFERENCES,0.37274368231046934,"pages 1083–1090, 2019.
357"
REFERENCES,0.37364620938628157,"[20] Samuel Eilenberg and Saunders MacLane. General theory of natural equivalences. Transactions
358"
REFERENCES,0.37454873646209386,"of the American Mathematical Society, 58:231–294, 1945.
359"
REFERENCES,0.37545126353790614,"[21] Charles Fefferman, Sanjoy Mitter, and Hariharan Narayanan. Testing the manifold hypothesis.
360"
REFERENCES,0.37635379061371843,"Journal of the American Mathematical Society, 29(4):983–1049, Oct 2016.
361"
REFERENCES,0.37725631768953066,"[22] David Chin-Lung Fong and Michael Saunders. Lsmr: An iterative algorithm for sparse least-
362"
REFERENCES,0.37815884476534295,"squares problems. SIAM Journal on Scientific Computing, 33(5):2950–2971, 2011.
363"
REFERENCES,0.37906137184115524,"[23] Vincent P. Grande and Michael T Schaub. Non-isotropic persistent homology: Leveraging the
364"
REFERENCES,0.3799638989169675,"metric dependency of ph. In Learning on Graphs Conference, pages 17–1. PMLR, 2023.
365"
REFERENCES,0.38086642599277976,"[24] Vincent P. Grande and Michael T. Schaub. Topological point cloud clustering. In Proceedings
366"
REFERENCES,0.38176895306859204,"of the 40th International Coference on Machine Learning, ICML’23, 2023.
367"
REFERENCES,0.38267148014440433,"[25] Aditya Grover and Jure Leskovec. node2vec: Scalable feature learning for networks. In
368"
REFERENCES,0.3835740072202166,"Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and
369"
REFERENCES,0.3844765342960289,"data mining, pages 855–864, 2016.
370"
REFERENCES,0.38537906137184114,"[26] Davide Gurnari, Aldo Guzmán-Sáenz, Filippo Utro, Aritra Bose, Saugata Basu, and Laxmi
371"
REFERENCES,0.3862815884476534,"Parida. Probing omics data via harmonic persistent homology. arXiv preprint arXiv:2311.06357,
372"
REFERENCES,0.3871841155234657,"2023.
373"
REFERENCES,0.388086642599278,"[27] Allen Hatcher. Algebraic Topology. Cambridge University Press, Cambridge, 2002.
374"
REFERENCES,0.38898916967509023,"[28] Felix Hausdorff. Grundzüge einer theorie der geordneten mengen. Mathematische Annalen,
375"
REFERENCES,0.3898916967509025,"65:435–505, 1908.
376"
REFERENCES,0.3907942238267148,"[29] Esther Hidber, Edward R Brownie, Koto Hayakawa, and Marie E Fraser. Participation of
377"
REFERENCES,0.3916967509025271,"cys123α of escherichia coli succinyl-coa synthetase in catalysis. Acta Crystallographica
378"
REFERENCES,0.3925992779783393,"Section D: Biological Crystallography, 63(8):876–884, 2007.
379"
REFERENCES,0.3935018050541516,"[30] David Hilbert. Grundlagen der Geometrie. Wissenschaft und Hypothese. B. G. Teubner,
380"
REFERENCES,0.3944043321299639,"Leipzig, 1899.
381"
REFERENCES,0.3953068592057762,"[31] Sze-tsen Hu. Homotopy theory. Academic press, 1959.
382"
REFERENCES,0.39620938628158847,"[32] Marc Kschonsak, Han Chow Chua, Claudia Weidling, Nourdine Chakouri, Cameron L. Noland,
383"
REFERENCES,0.3971119133574007,"Katharina Schott, Timothy Chang, Christine Tam, Nidhi Patel, Christopher P. Arthur, Alexan-
384"
REFERENCES,0.398014440433213,"der Leitner, Manu Ben-Johny, Claudio Ciferri, Stephan Alexander Pless, and Jian Payandeh.
385"
REFERENCES,0.3989169675090253,"Structural architecture of the human nalcn channelosome. Nature, 603(7899):180–186, Mar
386"
REFERENCES,0.39981949458483756,"2022.
387"
REFERENCES,0.4007220216606498,"[33] Peter Lawson, Andrew B Sholl, J Quincy Brown, Brittany Terese Fasy, and Carola Wenk.
388"
REFERENCES,0.4016245487364621,"Persistent homology for the quantitative evaluation of architectural features in prostate cancer
389"
REFERENCES,0.40252707581227437,"histology. Scientific reports, 9(1):1139, 2019.
390"
REFERENCES,0.40342960288808666,"[34] Lek-Heng Lim. Hodge laplacians on graphs. SIAM Review, 62(3):685–715, 2020.
391"
REFERENCES,0.4043321299638989,"[35] Jacob Lurie. Stable infinity categories. arXiv preprint math/0608228, 2006.
392"
REFERENCES,0.4052346570397112,"[36] Yunqian Ma and Yun Fu. Manifold learning theory and applications, volume 434. CRC press
393"
REFERENCES,0.40613718411552346,"Boca Raton, 2012.
394"
REFERENCES,0.40703971119133575,"[37] Facundo Mémoli, Zhengchao Wan, and Yusu Wang. Persistent laplacians: Properties, algorithms
395"
REFERENCES,0.40794223826714804,"and implications. SIAM Journal on Mathematics of Data Science, 4(2):858–884, 2022.
396"
REFERENCES,0.40884476534296027,"[38] Elizabeth Munch. A user’s guide to topological data analysis. Journal of Learning Analytics,
397"
REFERENCES,0.40974729241877256,"4(2):47–61, 2017.
398"
REFERENCES,0.41064981949458484,"[39] Kevin P. Murphy. Probabilistic Machine Learning: An introduction. MIT Press, 2022.
399"
REFERENCES,0.41155234657039713,"[40] Haruhisa Oda, Mayuko Kida, Yoichi Nakata, and Hiroki Kurihara. Novel definition and quantita-
400"
REFERENCES,0.41245487364620936,"tive analysis of branch structure with topological data analysis. arXiv preprint arXiv:2402.07436,
401"
REFERENCES,0.41335740072202165,"2024.
402"
REFERENCES,0.41425992779783394,"[41] Jose A. Perea. Sparse circular coordinates via principal Z-bundles. In Nils A. Baas, Gunnar E.
403"
REFERENCES,0.4151624548736462,"Carlsson, Gereon Quick, Markus Szymik, and Marius Thaule, editors, Topological Data
404"
REFERENCES,0.41606498194945846,"Analysis, pages 435–458, Cham, 2020. Springer International Publishing.
405"
REFERENCES,0.41696750902527074,"[42] Henri Poincaré. Analysis situs. J. de l’Ecole Poly., 1, 1895.
406"
REFERENCES,0.41787003610108303,"[43] Daniel G. Quillen. Homotopical Algebra, volume 43 of Lecture Notes in Mathematics. Springer,
407"
REFERENCES,0.4187725631768953,"Berlin, 1967.
408"
REFERENCES,0.4196750902527076,"[44] T Mitchell Roddenberry, Nicholas Glaze, and Santiago Segarra. Principled simplicial neural
409"
REFERENCES,0.42057761732851984,"networks for trajectory prediction. In International Conference on Machine Learning, pages
410"
REFERENCES,0.4214801444043321,"9020–9029. PMLR, 2021.
411"
REFERENCES,0.4223826714801444,"[45] Michael T Schaub, Austin R Benson, Paul Horn, Gabor Lippner, and Ali Jadbabaie. Random
412"
REFERENCES,0.4232851985559567,"walks on simplicial complexes and the normalized hodge 1-laplacian. SIAM Review, 62(2):353–
413"
REFERENCES,0.42418772563176893,"391, 2020.
414"
REFERENCES,0.4250902527075812,"[46] Michael T. Schaub, Yu Zhu, Jean-Baptiste Seby, T. Mitchell Roddenberry, and Santiago Segarra.
415"
REFERENCES,0.4259927797833935,"Signal processing on higher-order networks: Livin’ on the edge... and beyond. Signal Processing,
416"
REFERENCES,0.4268953068592058,"187:108149, 2021.
417"
REFERENCES,0.427797833935018,"[47] Jianbo Shi and Jitendra Malik. Normalized cuts and image segmentation. IEEE Transactions
418"
REFERENCES,0.4287003610108303,"on pattern analysis and machine intelligence, 22(8):888–905, 2000.
419"
REFERENCES,0.4296028880866426,"[48] The GUDHI Project. GUDHI User and Reference Manual. GUDHI Editorial Board, 2015.
420"
REFERENCES,0.4305054151624549,"[49] Tammo tom Dieck. Algebraic topology, volume 8. European Mathematical Society, Zürich,
421"
REFERENCES,0.4314079422382672,"2008.
422"
REFERENCES,0.4323104693140794,"[50] JunJie Wee, Jiahui Chen, Kelin Xia, and Guo-Wei Wei. Integration of persistent laplacian and
423"
REFERENCES,0.4332129963898917,"pre-trained transformer for protein solubility changes upon mutation. Computers in Biology
424"
REFERENCES,0.434115523465704,"and Medicine, page 107918, 2024.
425"
REFERENCES,0.43501805054151627,"[51] Hui Zou, Trevor Hastie, and Robert Tibshirani. Sparse principal component analysis. Journal
426"
REFERENCES,0.4359205776173285,"of computational and graphical statistics, 15(2):265–286, 2006.
427"
REFERENCES,0.4368231046931408,"[52] Matija ˇCufar. Ripserer.jl: flexible and efficient persistent homology computation in julia.
428"
REFERENCES,0.43772563176895307,"Journal of Open Source Software, 5(54):2614, 2020.
429"
REFERENCES,0.43862815884476536,"A
Extended Background
430"
REFERENCES,0.4395306859205776,"A brief history of topology and machine learning
Algebraic topology is a discipline of Mathe-
431"
REFERENCES,0.4404332129963899,"matics dating back roughly to the late 19th century [42]. Starting with Henri Poincaré and continuing
432"
REFERENCES,0.44133574007220217,"in the early 20th century, the mathematical community became interested in developing a framework
433"
REFERENCES,0.44223826714801445,"to capture the global shapes of manifolds and topological spaces in concise algebraic terms. This de-
434"
REFERENCES,0.44314079422382674,"velopment was partly made possible by the push towards a formalisation of mathematics and analysis,
435"
REFERENCES,0.44404332129963897,"in particular, which took place inside the mathematical community in the 1800’s and early 1900’s (e.g.
436"
REFERENCES,0.44494584837545126,"[17, 30, 28]). The axiomatisation of analysis in the early 20th century is an important result of this
437"
REFERENCES,0.44584837545126355,"process. These abstract ideas made it possible for Topologists to talk about the now common notions
438"
REFERENCES,0.44675090252707583,"of Euler characteristics, Betti number, simplicial homology of manifolds, topological spaces, and
439"
REFERENCES,0.44765342960288806,"simplicial and CW complexes. Over the course of the last 100 years, branching into many sub-areas
440"
REFERENCES,0.44855595667870035,"like low-dimensional topology, differential topology, K-theory or homotopy theory [1, 31], algebraic
441"
REFERENCES,0.44945848375451264,"topology has resolved many of the important questions and provides a comprehensive tool-box for
442"
REFERENCES,0.4503610108303249,"the study of topological spaces. These achievements were tied to an abstraction and generalisation of
443"
REFERENCES,0.45126353790613716,"concepts: topological spaces turned into spectra, diffeomorphism to homotopy equvialences and later
444"
REFERENCES,0.45216606498194944,"weak equivalences, and Topologists turned to category theory [20], model categories [6] and recently
445"
REFERENCES,0.45306859205776173,"∞-categories [35] as the language of choice.
446"
REFERENCES,0.453971119133574,"The 21st century saw the advent and rise of topological data analysis (TDA, [8, 12]). In short,
447"
REFERENCES,0.4548736462093863,"mathematicians realised that the same notions of shape and topology that their predecessors carefully
448"
REFERENCES,0.45577617328519854,"defined a century earlier were now characterising the difference between healthy and unhealthy
449"
REFERENCES,0.4566787003610108,"tissue, between normal and abnormal behaviour protein behaviour, or more general between different
450"
REFERENCES,0.4575812274368231,"categories in their complex data sets.
451"
REFERENCES,0.4584837545126354,"Related Work
The intersection of topological data analysis, topological signal processing and
452"
REFERENCES,0.45938628158844763,"geometry processing has many interesting related developments in the past few years. On the side
453"
REFERENCES,0.4602888086642599,"of homology and TDA, the authors in [16] and [41] use harmonic cohomology representatives to
454"
REFERENCES,0.4611913357400722,"reparametrise point clouds based on circular coordinates. This implicitly assumes that the underlying
455"
REFERENCES,0.4620938628158845,"structure of the point cloud is amenable to such a characterization. Although circular coordinates are
456"
REFERENCES,0.4629963898916967,"orthogonal to the core goal of TOPF, the approaches share many key ideas and insights. In [2, 26],
457"
REFERENCES,0.463898916967509,"the authors develop and use harmonic persistent homology and provide a way to pool features to
458"
REFERENCES,0.4648014440433213,"the point-level. However, their focus is not on providing robust topological point features and their
459"
REFERENCES,0.4657039711191336,"approach includes no tunable homology feature selection across dimensions, no support for weighted
460"
REFERENCES,0.4666064981949459,"simplicial complexes, and they only construct the simplicial complex at birth. In their paper on
461"
REFERENCES,0.4675090252707581,"topological mode analysis, [11] use persistent homology to cluster point clouds. However, they only
462"
REFERENCES,0.4684115523465704,"consider 0-dimensional homology to base the clustering on densities and there is no clear way to
463"
REFERENCES,0.4693140794223827,"generalise this to higher dimensions.
464"
REFERENCES,0.47021660649819497,"On the more geometric-centred side, [19] already provide a notion of harmonic clustering on simplices,
465"
REFERENCES,0.4711191335740072,"[13, 14] analyse the notion of geometry and topology encoded in the Hodge Laplacian and its relation
466"
REFERENCES,0.4720216606498195,"to homology decompositions, [45] study the normalised and weighted Hodge Laplacian in the context
467"
REFERENCES,0.4729241877256318,"of random walks, and [24] use the harmonic space of the Hodge Laplacians to cluster point clouds
468"
REFERENCES,0.47382671480144406,"respecting topology. Finally, a persistent variant of the Hodge Laplacian is used to study filtrations of
469"
REFERENCES,0.4747292418772563,"simplicial complexes [37].
470"
REFERENCES,0.4756317689530686,"In [24], the authors have introduced TPCC, the first method to cluster a point cloud based on the
471"
REFERENCES,0.47653429602888087,"higher-order topological features encoded in the data set. However, TPCC is (i) computationally
472"
REFERENCES,0.47743682310469315,"expensive due to extensive eigenvector computations, (ii) depending on high-dimensional subspace
473"
REFERENCES,0.47833935018050544,"clustering algorithms, which are prone to instabilities and errors, (iii) sensitive to the correct choice
474"
REFERENCES,0.47924187725631767,"of hyperparameters, (iv) requiring the topological true features and noise to occur in different steps
475"
REFERENCES,0.48014440433212996,"of the simplicial filtration, and it (v) solely focussed on clustering the points rather than extracting
476"
REFERENCES,0.48104693140794225,"relevant node-level features. This paper solves all the above by completely revamping the TPCC
477"
REFERENCES,0.48194945848375453,"pipeline, introducing several new ideas from applied algebraic topology and differential geometry.
478"
REFERENCES,0.48285198555956677,"The core insight is: When you have the time to compute persistent homology with generators on a
479"
REFERENCES,0.48375451263537905,"data set, you get the topological node features with similar computational effort.
480"
REFERENCES,0.48465703971119134,"B
Theoretical Considerations
481"
REFERENCES,0.4855595667870036,"More details on VR and α-filtrations
Vietoris–Rips complexes are easy to define, approximate
482"
REFERENCES,0.48646209386281586,"the topological properties of a point cloud across all scales and computationally easy to implement.
483"
REFERENCES,0.48736462093862815,"However for moderately large r, the associated VR complex contains a large number of simplices —
484"
REFERENCES,0.48826714801444043,"up to
 |X|
n

n-simplices for large enough r — leading to poor computational performance for any
485"
REFERENCES,0.4891696750902527,"downstream task on some large point clouds. One way to see this is the following: After adding the
486"
REFERENCES,0.490072202166065,"first edge that connects two components or the final simplex that fills a hole in the simplicial complex
487"
REFERENCES,0.49097472924187724,"the VR complex keeps adding more and more simplices in the same area that keep the topology
488"
REFERENCES,0.4918772563176895,"unchanged. One way to mitigate this problem is to pre-compute a set of simplices that are able to
489"
REFERENCES,0.4927797833935018,"express the entire topology of the point cloud. For a point cloud X ⊂Rn, the α-filtration consists of
490"
REFERENCES,0.4936823104693141,"the intersection of the simplicial complexes of the VR filtration on X with the (higher-dimensional)
491"
REFERENCES,0.49458483754512633,"Delaunay triangulation of X in R. Due to algorithmic reasons, the filtration value of a simplex is
492"
REFERENCES,0.4954873646209386,"then the radius of the circumscribed sphere instead of the maximum pair-wise distance of vertices.
493"
REFERENCES,0.4963898916967509,"This reduces the number of required simplices across all dimensions to O(|X|⌈n/2⌉). However, the
494"
REFERENCES,0.4972924187725632,"Delaunay triangulation becomes computationally infeasible for larger n.
495"
REFERENCES,0.4981949458483754,"Definition B.1 (n-dimensional Delaunay triangulation). Given a set of vertices V ∈Rn, a Delaunay
496"
REFERENCES,0.4990974729241877,"triangulation DT(V ) is a triangulation of V such that for any n-simplex σn ∈DT(V ) the interior
497"
REFERENCES,0.5,"of the circum-hypersphere of σn contains no point of DT(V ). A triangulation of V is a SC S with
498"
REFERENCES,0.5009025270758123,"vertex set V such that its geometric realisation covers the convex hull of V hull(V ) = |S| and we
499"
REFERENCES,0.5018050541516246,"have for any two simplices σ, σ′ that the intersection of geometric realisations |σ| ∩|σ′| is either
500"
REFERENCES,0.5027075812274369,"empty or the geometric realisation |ˆσ| of a common sub-simplex ˆσ ⊂σ, σ′.
501"
REFERENCES,0.5036101083032491,"If V is in general position, the Delaunay triangulation is unique and guaranteed to exist [18].
502"
REFERENCES,0.5045126353790613,"Definition B.2 (α-complex of a point cloud). Given a finite point cloud X in real space Rn, the
503"
REFERENCES,0.5054151624548736,"α-complex αε(X) is the subset of the n-dimensional Delaunay triangulation DT(X) consisting of
504"
REFERENCES,0.5063176895306859,"all σ ∈DT(X) with a radius r of its circumscribed sphere with r ≤ε.
505"
REFERENCES,0.5072202166064982,"Proof of the main theorem
We will now give the proof of the theorem that guarantees that TOPF
506"
REFERENCES,0.5081227436823105,"works. First, let us recall Theorem 4.1:
507"
REFERENCES,0.5090252707581228,"Theorem 4.1 (Topological Point Features of Spheres). Let X consist of at least (n + 2) points
508"
REFERENCES,0.509927797833935,"(denoted by S) sampled uniformly at random from a unit n-sphere in Rn+1 and an arbitrary number
509"
REFERENCES,0.5108303249097473,"of points with distance of at least 2 to S. When we now consider the α-filtration on this point
510"
REFERENCES,0.5117328519855595,"cloud, with probability 1 we have that (i) there exists an n-th persistent homology class generated
511"
REFERENCES,0.5126353790613718,"by the 2-simplices on the convex hull hull of S, (ii) the associated unweighted harmonic homology
512"
REFERENCES,0.5135379061371841,"representative takes values in {0, ±1} where the 2-simplices on the boundary of the convex hull are
513"
REFERENCES,0.5144404332129964,"assigned a value of ±1, and (iii) the support of the associated topological point feature (TOPF) F∗
n
514"
REFERENCES,0.5153429602888087,"is precisely S: supp(F∗
n) = S. (iv) The same holds true for point clouds sampled from multiple
515"
REFERENCES,0.516245487364621,"ni-spheres if the above conditions are met on each individual sphere.
516"
REFERENCES,0.5171480144404332,"Proof. Assume that we are in the scenario of the theorem. Now because the n-volume of (n −1)-
517"
REFERENCES,0.5180505415162455,"submanifolds is zero, we have that with probability 1 the points of S don’t lie on a single (n −1)
518"
REFERENCES,0.5189530685920578,"sphere inside the n-sphere. Let us now look at the α-filtration of the simplices in S: Recall that the
519"
REFERENCES,0.51985559566787,"filtration values of a k-simplex is given by the radius of the (k −1)-sphere determined by its vertices.
520"
REFERENCES,0.5207581227436823,"Because all of the (n+1)-simplices σn+1 with vertices V ⊂S in S lie on the same unit n-sphere Sn,
521"
REFERENCES,0.5216606498194946,"they all share the filtration value of α(σn+1) = 1. By the same argument as above, with probability 1
522"
REFERENCES,0.5225631768953068,"there are no (n + 1) points in S that lie on an unit (n −1)-sphere. Thus all of the n-simplices σn lie
523"
REFERENCES,0.5234657039711191,"on (n −1)-spheres Sn with a radius r < 1 smaller than 1 and hence have a filtration value α(σn)
524"
REFERENCES,0.5243682310469314,"smaller than 1. Let
525"
REFERENCES,0.5252707581227437,"b := max ({α(σn) : σn ⊂∂hull(S)})
be the maximum filtration value of an n-simplex on the boundary of the convex hull of S. Then, then
526"
REFERENCES,0.526173285198556,"a linear combination g of the n-simplices of the boundary of the convex hull of S with coefficients in
527"
REFERENCES,0.5270758122743683,"±1 is a generator of a persistent homology class with life time (b, 1) (this follows from the fact that
528"
REFERENCES,0.5279783393501805,"n-spheres and their triangulations are orientable). This proves claim (i).
529"
REFERENCES,0.5288808664259927,"Because of the assumption that all points not contained in S have a distance of at least 2 to the points
530"
REFERENCES,0.529783393501805,"in S, all (n+1)-simplices σn+1 with vertices both in S and its complement in X will have a filtration
531"
REFERENCES,0.5306859205776173,"value α(σn+1) ≥1 of at least 1. Recall that all (n + 1)-simplices σn+1 ⊂S with vertices inside S
532"
REFERENCES,0.5315884476534296,"have a filtration value of α(σn+1) = 1. Thus the adjoint of the n-th boundary operator B⊤
n is trivial
533"
REFERENCES,0.5324909747292419,"on the homology generator g. Thus, we have that for the n-th Hodge Laplacian
534"
REFERENCES,0.5333935018050542,"Lng = B⊤
n−1Bn−1g + BnB⊤
n g = 0 + 0 = 0"
REFERENCES,0.5342960288808665,"and hence g is a harmonic generator for the entire filtration range of (b, 1), which proves claim (ii).
535"
REFERENCES,0.5351985559566786,"Claim (iii) and (iv) then follow from the construction of the TOPF values.
□
536"
REFERENCES,0.5361010830324909,"C
Topological Clustering Benchmark Suite
537"
REFERENCES,0.5370036101083032,"We introduce seven point clouds for topological point cloud clustering in the topological clustering
538"
REFERENCES,0.5379061371841155,"benchmark suite (TCBS). The ground truth and the point clouds are depicted in Figure 6. The point
539"
REFERENCES,0.5388086642599278,"clouds represent a mix between 0-, 1- and 2-dimensional topological structures in noiseless and noisy
540"
REFERENCES,0.5397111913357401,"settings in ambient 2-dimensional and 3-dimensional space. The results of clustering according to
541"
REFERENCES,0.5406137184115524,"TOPF can be found in Figure 7.
542"
REFERENCES,0.5415162454873647,"D
Implementation
543"
REFERENCES,0.5424187725631769,"We will release an implementation of TOPF and the code and data required to reproduce
544"
REFERENCES,0.5433212996389891,"the experimental results of this paper under https://anonymous.4open.science/r/topf_
545"
REFERENCES,0.5442238267148014,"submission-5C40/. In particular, we will release the topological clustering benchmark suite.
546"
REFERENCES,0.5451263537906137,"All experiments were run on a Apple M1 Pro chipset with 10 cores and 32 GB memory. TOPF
547"
REFERENCES,0.546028880866426,"and the experiments are implemented in Python and Julia. For persistent homology computations,
548"
REFERENCES,0.5469314079422383,"we used GUDHI [48] (© The GUDHI developers, MIT license) and Ripserer [52] (© mtsch, MIT
549"
REFERENCES,0.5478339350180506,"license), which is a modified Julia implementation of [3]. For the least square problems, we used
550"
REFERENCES,0.5487364620938628,"the LSMR implementation of SciPy [22]. We used the Node2Vec python implementation https:
551"
REFERENCES,0.5496389891696751,"//github.com/eliorc/node2vec (© Elior Cohen, MIT License) based on the Node2Vec Paper
552"
REFERENCES,0.5505415162454874,"[25]. We used the pgeof Python package for computation of geometric features https://github.
553"
REFERENCES,0.5514440433212996,"Figure 6: Data sets of the Topological Clustering Benchmark Suite (TCBS) with true la-
bels. Top: 2D data sets. From left to right: 4Spheres (656 points), Ellipses (158 points),
Spheres+Grid (866 points), Halved Circle (249 points). Bottom: 3D data sets. From left to
right: 2Spheres2Circles (4600 points), SphereinCircle (267 points), spaceship (650 points)."
REFERENCES,0.5523465703971119,"Figure 7: Data sets of the Topological Clustering Benchmark Suite (TCBS) with labels generated
by TOPF. Top: 2D data sets. From left to right: 4Spheres (0.81 ARI), Ellipses (0.95 ARI),
Spheres+Grid (0.70 ARI), Halved Circle (0.71 ARI). Bottom: 3D data sets. From left to right:
2Spheres2Circles (0.94 ARI), SphereinCircle (0.97 ARI), spaceship (0.92 ARI)."
REFERENCES,0.5532490974729242,"com/drprojects/point_geometric_features (© Damien Robert, Loic Landrieu, Romain Jan-
554"
REFERENCES,0.5541516245487365,"vier, MIT license). We use parts of the implementation of TPCC https://git.rwth-aachen.
555"
REFERENCES,0.5550541516245487,"de/netsci/publication-2023-topological-point-cloud-clustering (© Computational
556"
REFERENCES,0.555956678700361,"Network Science Group, RWTH Aachen University, MIT license).
557"
REFERENCES,0.5568592057761733,"D.1
Hyperparameters
558"
REFERENCES,0.5577617328519856,"All the relevant hyperparameters are already mentioned in their respective sections. However, for
559"
REFERENCES,0.5586642599277978,"convenience we gather and briefly discuss them in this section. We note that TOPF is robust and
560"
REFERENCES,0.5595667870036101,"applicable in most scenarios when using the default parameters without tuning hyperparameters. The
561"
REFERENCES,0.5604693140794224,"hyperparameters should more be thought of as an additional way where detailed domain-knowledge
562"
REFERENCES,0.5613718411552346,"can enter the TOPF pipeline.
563"
REFERENCES,0.5622743682310469,"Maximum Homology Dimension d
The maximum homology dimension determines the dimen-
564"
REFERENCES,0.5631768953068592,"sions of persistent homology the algorithm computes.
565"
REFERENCES,0.5640794223826715,"For the choice of the maximum homology degree d to be considered there are mainly three heuristics
566"
REFERENCES,0.5649819494584838,"which we will list in decreasing importance (Cf. [24]):
567"
REFERENCES,0.5658844765342961,"I. In applications, we usually know which kind of topological features we are interested in, which
568"
REFERENCES,0.5667870036101083,"will then determine d. This means that 1-dimensional homology and d = 1 suffices when we
569"
REFERENCES,0.5676895306859205,"are looking at loops of protein chains. On the other hand, if we are working with voids and
570"
REFERENCES,0.5685920577617328,"cavities in 3d histological data, we need d = 2 and thus compute 2-dimensional homology.
571"
REFERENCES,0.5694945848375451,"II. Algebraic topology tells us that there are no closed n-dimensional submanifolds of Rn. Hence
572"
REFERENCES,0.5703971119133574,"their top-homology will always vanish and all interesting homological activity will appear for
573"
REFERENCES,0.5712996389891697,"d < n.
574"
REFERENCES,0.572202166064982,"III. In the vast majority of cases, the choice will be between d = 1 or d = 2 because empirically
575"
REFERENCES,0.5731046931407943,"there are virtually no higher-dimensional topological features in practice.
576"
REFERENCES,0.5740072202166066,"In our quantitative experiments, we have always chosen d = n −1.
577"
REFERENCES,0.5749097472924187,"Thresholding parameter δ
In step 4 of the algorithm, we normalise and threshold the harmonic
578"
REFERENCES,0.575812274368231,"representatives. After normalising, the entries of the vectors lie in the interval of [0, 1]. The
579"
REFERENCES,0.5767148014440433,"thresholding parameter δ now essentially determines an interval of [0, δ] which we will linearly map
580"
REFERENCES,0.5776173285198556,"to [0, 1], while mapping all entries above δ to 1 as well. This is necessary as most of the entries in
581"
REFERENCES,0.5785198555956679,"the vector ei
k are very close to 0 with a very small number of entries being close to 1. Without this
582"
REFERENCES,0.5794223826714802,"thresholding, TOPF would now be almost entirely determined by these few large values. Thus this
583"
REFERENCES,0.5803249097472925,"step limits the maximum possible influence of a single entry. However, because most of the entries of
584"
REFERENCES,0.5812274368231047,"ei
k are concentrated around 0, small changes in δ will not have a large effect and we chose δ = 0.07
585"
REFERENCES,0.5821299638989169,"in all our experiments.
586"
REFERENCES,0.5830324909747292,"Interpolation coefficient λ
The interpolation coefficient λ ∈[0, 1) determines whether we build
587"
REFERENCES,0.5839350180505415,"our simplicial complexes close to the birth or the death of the relevant homological features at time
588"
REFERENCES,0.5848375451263538,"t = b1−λd. This then in turns controls how localised or smooth the harmonic representative will
589"
REFERENCES,0.5857400722021661,"be. In general, the noisier the ground data is the higher we should choose λ. However, TOPFis not
590"
REFERENCES,0.5866425992779783,"sensitive to small changes in λ. We have picked λ = 0.3 for all the quantitative experiments, which
591"
REFERENCES,0.5875451263537906,"empirically represents a good choice for a broad range of applications.
592"
REFERENCES,0.5884476534296029,"Feature selection factor β
Increasing β leads to TOPF preferring to pick a larger number of relevant
593"
REFERENCES,0.5893501805054152,"topological features. Without specific domain-knowledge, β = 0 represents a good choice.
594"
REFERENCES,0.5902527075812274,"Feature selection quotients max_total_quot, min_rel_quot, and min_0_ratio
These are
595"
REFERENCES,0.5911552346570397,"technical hyperparameters controlling the feature selection module of TOPF. For a technical account
596"
REFERENCES,0.592057761732852,"of them, see Appendix E. In most of the cases without domain knowledge, they do not have an effect
597"
REFERENCES,0.5929602888086642,"on the performance of TOPF and should be kept at their default values.
598"
REFERENCES,0.5938628158844765,"Simplicial Complex Weights
Although the simplicial weights are not technically a hyperparameter,
599"
REFERENCES,0.5947653429602888,"there are many potential ways to weigh the considers SCs that can highlight or suppress different
600"
REFERENCES,0.5956678700361011,"topological and geometric properties. In all our experiments, we use w∆weights discussed in
601"
REFERENCES,0.5965703971119134,"Appendix F.
602"
REFERENCES,0.5974729241877257,"E
How to pick the most relevant topological features
603"
REFERENCES,0.5983754512635379,"Simplified heuristic
The persistent homology Pk module in dimension k is given to us as a list of
604"
REFERENCES,0.5992779783393501,"pairs of birth and death times (bk
i , dk
i ). We can assume these pairs are ordered in non-increasing order
605"
REFERENCES,0.6001805054151624,"of the durations lk
i = dk
i −bk
i . This list is typically very long and consists to a large part of noisy
606"
REFERENCES,0.6010830324909747,"homological features which vanish right after they appear. In contrast, we are interested in connected
607"
REFERENCES,0.601985559566787,"components, loops, cavities, etc. that persist over a long time, indicating that they are important for
608"
REFERENCES,0.6028880866425993,"the shape of the point cloud. Distinguishing between the relevant and the irrelevant features is in
609"
REFERENCES,0.6037906137184116,"general difficult and may depend on additional insights on the domain of application. In order to
610"
REFERENCES,0.6046931407942239,"provide a heuristic which does not depend on any a-priori assumptions on the number of relevant
611"
REFERENCES,0.605595667870036,"Figure 8:
TOPF heatmaps for three proteins. Top left NALCN channelosome [32] Top right:
Mutated Cys123 of E. coli [29], with convex hull added during computation, only 2-dimensional
homology features Bottom: GroEL of E. coli [10] (Selected features)."
REFERENCES,0.6064981949458483,"features we pick the smallest quotient qk
i := lk
i+1/lk
i > 0 as the point of cut-off Nk := arg mini qk
i .
612"
REFERENCES,0.6074007220216606,"The only underlying assumption of this approach is that the band of “relevant” features is separated
613"
REFERENCES,0.6083032490974729,"from the “noisy” homological features by a drop in persistence.
614"
REFERENCES,0.6092057761732852,"Advanced Heuristic
However, certain applications have a single very prominent feature, followed
615"
REFERENCES,0.6101083032490975,"by a range of still relevant features with significantly smaller life times, that are then followed by
616"
REFERENCES,0.6110108303249098,"the noisy features after another drop-off. This then could potentially lead the heuristic to find the
617"
REFERENCES,0.6119133574007221,"wrong drop-off. We propose to mitigate this issue by introducing a hyperparameter β ∈R>0. We
618"
REFERENCES,0.6128158844765343,"then define the i-th importance-drop-off quotient qk
i by
619"
REFERENCES,0.6137184115523465,"qk
i := lk
i+1/lk
i (1 + β/i) ."
REFERENCES,0.6146209386281588,"The basic idea is now to consider the most significant Nk homology classes in dimension k when
620"
REFERENCES,0.6155234657039711,"setting Nk to be
621"
REFERENCES,0.6164259927797834,"Nk := arg min
i
qk
i ."
REFERENCES,0.6173285198555957,"Increasing β leads the heuristic to prefer selections with more features than with fewer features.
622"
REFERENCES,0.618231046931408,"Empirically, we still found β = 0 to work well in a broad range of application scenarios and used
623"
REFERENCES,0.6191335740072202,"it throughout all experiments. There are only a few cases where domain-specific knowledge could
624"
REFERENCES,0.6200361010830325,"suggest picking a larger β.
625"
REFERENCES,0.6209386281588448,"To catch edge cases with multiple steep drops or a continuous transition between real features and
626"
REFERENCES,0.621841155234657,"noise, we introduce two more checks: We allow a minimal qk
i of min_rel_quot = 0.1 and a
627"
REFERENCES,0.6227436823104693,"maximal quotient qh
1/qk
i of max_total_quot = 10 between any homology dimensions. Because
628"
REFERENCES,0.6236462093862816,"features in 0-dimensional homology are often more noisy than features in higher dimensions, we add
629"
REFERENCES,0.6245487364620939,"a minimum zero-dimensional homology ratio of min_0_ratio = 5, i.e. every chosen 0-dimensional
630"
REFERENCES,0.6254512635379061,"feature needs to be at least min_0_ratio more persistent then the minimum persistence of the
631"
REFERENCES,0.6263537906137184,"higher-dimensional features. Because these hyperparameters only deal with the edge cases of
632"
REFERENCES,0.6272563176895307,"feature selection, TOPF is not very sensitive to them. For all our experiments, we used the above
633"
REFERENCES,0.628158844765343,"hyperparameters. We advise to change them only in cases where one has in-depth domain knowledge
634"
REFERENCES,0.6290613718411552,"about the nature of relevant topological features.
635"
REFERENCES,0.6299638989169675,"Point cloud Unweight. harm. rep.
Eff. Res.
Weight. harm. rep.
1/Num tris"
REFERENCES,0.6308664259927798,"VR complex
alpha complex"
REFERENCES,0.631768953068592,Weight. harm. rep.
REFERENCES,0.6326714801444043,"Figure 9: Effect of weighing a simplicial complex on harmonic representatives. Top: VR complex.
Bottom: α-complex Left: The base point cloud with different densities. 2nd Left: Unweighted
harmonic homology representative of the large loop. 3rd Right: Effective resistance of the 1-simplices.
3rd Right: Harmonic homology representative of the complex weighted by effective resistance.
2nd Right: Inverse of number of incident triangles (Definition F.1). Right: Harmonic homology
representative of the complex weighted by number of incident triangles. Up to a small threshold,
the standard harmonic representative in the VR complex is almost exclusively supported in the
low-density regions of the simplicial complex. This leads to poor and unpredictable classification
performance in downstream tasks. In contrast, the harmonic homology representative of the weighted
VR complex has a more homogenous support along the loop, while still being able to discriminate the
edges not contributing to the loop. The α-complex suffers less from this phenomenon (at least in
dimension 2), and hence reweighing is not necessarily required."
REFERENCES,0.6335740072202166,"F
Simplicial Weights
636"
REFERENCES,0.6344765342960289,"In an ideal world, the harmonic eigenvectors in dimension k would be vectors assigning ±1 to all
637"
REFERENCES,0.6353790613718412,"k-simplices contributing to k-dimensional homological feature, a 0 to all k-simplices not contributing
638"
REFERENCES,0.6362815884476535,"or orthogonal to the feature, and a value in (−1, 1) for all simplices based on the alignment of the
639"
REFERENCES,0.6371841155234657,"simplex with the boundary of the void. However, this is not the case: In dimension 1, we can for
640"
REFERENCES,0.6380866425992779,"example imagine a total flow of 1 circling around the hole. This flow is then split up between all
641"
REFERENCES,0.6389891696750902,"parallel edges which means two things: I Edges where the loop has a larger diameter have smaller
642"
REFERENCES,0.6398916967509025,"harmonic values than edges in thin areas and II in VR complexes, which are the most frequently
643"
REFERENCES,0.6407942238267148,"used simplicial complexes in TDA, edges in areas with a high point density have smaller harmonic
644"
REFERENCES,0.6416967509025271,"values than edges in low-density areas. Point II is another advantage of α-complexes: The expected
645"
REFERENCES,0.6425992779783394,"number of simplices per point does not scale with the point density in the same way as it does in the
646"
REFERENCES,0.6435018050541517,"VR complex, because only the simplices of the Delaunay triangulation can appear in the complex.
647"
REFERENCES,0.644404332129964,"We address this problem by weighing the k-simplices of the simplicial complex. The idea behind this
648"
REFERENCES,0.6453068592057761,"is to weigh the simplicial complex in such a way that it increases and decreases the harmonic values
649"
REFERENCES,0.6462093862815884,"of some simplices in an effort to make the harmonic eigenvectors more homogeneous. For weights
650"
REFERENCES,0.6471119133574007,"w ∈RSk, W = diag(w), the symmetric weighted Hodge Laplacian [45] takes the form of
651"
REFERENCES,0.648014440433213,"Lw
k = W 1/2Bk−1B⊤
k−1W 1/2 + W −1/2BkB⊤
k W −1/2."
REFERENCES,0.6489169675090253,"Because we want the homology representative to lie in the weighted gradient space, we have to scale
652"
REFERENCES,0.6498194945848376,"its entries with the weight and set ei
k,w := W −1/2ei
k. With this, we have that
653"
REFERENCES,0.6507220216606499,"B⊤
k−1W 1/2ei
k,w = B⊤
k−1W 1/2W −1/2ei
k = B⊤
k−1ei
k = 0"
REFERENCES,0.6516245487364621,"We propose two options to weigh the simplicial complex. The first option is to weigh a k-simplex by
654"
REFERENCES,0.6525270758122743,"the square of the number of k + 1-simplices the simplex is contained in:
655"
REFERENCES,0.6534296028880866,"w∆(σk) = 1/(|{σk+1 ∈St
k+1 : σk ⊂σk+1}| + 1)2"
REFERENCES,0.6543321299638989,"where the +1 is to enforce good behaviour at simplices that are not contained in any higher-order
656"
REFERENCES,0.6552346570397112,"simplices. One of the advantages of the α-complex is that we don’t have large concentrations of
657"
REFERENCES,0.6561371841155235,"simplices in well-connected areas. The proposed weighting w∆is computationally straightforward,
658"
REFERENCES,0.6570397111913358,"as it can be obtained as the column sums of the absolute value of the boundary matrix |Bk|. The
659"
REFERENCES,0.657942238267148,"weights also deal with the previously mentioned problem II: As the homology representative is scaled
660"
REFERENCES,0.6588447653429603,"inversely to the weight vector w, the simplices in high-density regions will be assigned a low weight
661"
REFERENCES,0.6597472924187726,"and thus their weighted homology representative will have a larger entry. By the projection to the
662"
REFERENCES,0.6606498194945848,"orthogonal complement of the curl space, this large entry is then diffused among the high-density
663"
REFERENCES,0.6615523465703971,"region of the SC with many simplices, whereas the lower entries of the simplices in low-density
664"
REFERENCES,0.6624548736462094,"regions are only diffused among fewer adjacent simplices.
665"
REFERENCES,0.6633574007220217,"However, the first weight is not able to incorporate the number of parallel simplices into the weighting.
666"
REFERENCES,0.6642599277978339,"This is why we propose a second simplicial weight function based on generalised effective resistance.
667"
REFERENCES,0.6651624548736462,"Definition F.1 (Effective Hodge resistance weights). For a simplicial complex S with boundary
668"
REFERENCES,0.6660649819494585,"matrices (Bk), we define the effective Hodge resistance weights wR on k-simplices to be:
669"
REFERENCES,0.6669675090252708,"wR := diag
 
B+
k−1Bk−1
2"
REFERENCES,0.6678700361010831,"where diag(−) denotes the vector of diagonal entries and (−)+ denotes taking the Moore–Penrose
670"
REFERENCES,0.6687725631768953,"inverse.
671"
REFERENCES,0.6696750902527075,"Intuitively for k = 1, we can assume that every edge has a resistance of 1 and then the effective
672"
REFERENCES,0.6705776173285198,"resistance coincides with the notion from Physics. Thus simplices with many parallel simplices are
673"
REFERENCES,0.6714801444043321,"assigned a small effective resistance, whereas simplices with few parallel simplices are assigned an
674"
REFERENCES,0.6723826714801444,"effective resistance close to 1. However, computing the Moore–Penrose inverse is computationally
675"
REFERENCES,0.6732851985559567,"expensive and only feasible for small simplicial complexes.
676"
REFERENCES,0.674187725631769,"In Figure 9, we show that the weights w∆are a good approximation of the effective resistance in
677"
REFERENCES,0.6750902527075813,"terms of the resulting harmonic representative. The standard form of TOPF used in all experiments
678"
REFERENCES,0.6759927797833934,"uses w∆-weights.
679"
REFERENCES,0.6768953068592057,"G
Limitations
680"
REFERENCES,0.677797833935018,"Topological features are not everywhere
The proposed topological point features take relevant
681"
REFERENCES,0.6787003610108303,"persistent homology generators and turn these into point-level features. As such, applying TOPF
682"
REFERENCES,0.6796028880866426,"only produces meaningful results on point clouds that have a topological structure. On these point
683"
REFERENCES,0.6805054151624549,"clouds, TOPF can extract structural information unobtainable by non-topological methods. Although
684"
REFERENCES,0.6814079422382672,"TDA has been successful in a wide range of applications, a large number of data sets does not
685"
REFERENCES,0.6823104693140795,"possess a meaningful topological structure. Applying TOPF in these cases will produce no additional
686"
REFERENCES,0.6832129963898917,"information. Other data sets require pre-processing before containing topological features. In Figure 4
687"
REFERENCES,0.6841155234657039,"left, the 2d topological features characterising protein pockets of Cys123 only appear after artificially
688"
REFERENCES,0.6850180505415162,"adding points sampled on the convex hull of the point cloud (Cf [40]).
689"
REFERENCES,0.6859205776173285,"Computing persistent homology can be computationally expensive
As TOPF relies on the
690"
REFERENCES,0.6868231046931408,"computation of persistent homology including homology generators, its runtime increases on very
691"
REFERENCES,0.6877256317689531,"large point clouds. This is especially true when using VR instead of α-filtrations, which become
692"
REFERENCES,0.6886281588447654,"computationally infeasible for higher-dimensional point clouds. Persistent homology computations
693"
REFERENCES,0.6895306859205776,"for dimensions above 2 are only feasible for very small point clouds. Because virtually all discovered
694"
REFERENCES,0.6904332129963899,"relevant homological features in applications appear in dimension 0, 1, or 2, this does not present
695"
REFERENCES,0.6913357400722022,"a large problem. Despite these computational challenges, subsampling, either randomly or using
696"
REFERENCES,0.6922382671480144,"landmarks, usually preserves relevant topological features and thus extends the applicability of TDA
697"
REFERENCES,0.6931407942238267,"in general and TOPF even to very large point clouds.
698"
REFERENCES,0.694043321299639,"Automatic feature selection is difficult without domain knowledge
While the proposed heuristics
699"
REFERENCES,0.6949458483754513,"works well across a variety of domains and application scenarios, only domain- and problem-specific
700"
REFERENCES,0.6958483754512635,"knowledge makes truthful feature selection feasible.
701"
REFERENCES,0.6967509025270758,"Experimental Evaluation
There are no benchmark sets for topological point features in the
702"
REFERENCES,0.6976534296028881,"literature, which makes benchmarking TOPF not straightforward. On the level of clustering, we
703"
REFERENCES,0.6985559566787004,"introduced the topological clustering benchmark suite to make quantitative comparisons of TOPF
704"
REFERENCES,0.6994584837545126,"possible, and benchmarked TOPF on some of the point clouds of [24]. On both the level of point
705"
REFERENCES,0.7003610108303249,"features and real-world data sets, it is however hard to establish what a ground truth of topological
706"
REFERENCES,0.7012635379061372,"features would mean. Instead we chose to qualitatively report the results of TOPF on proteins and
707"
REFERENCES,0.7021660649819494,"real-world data, see Figure 4.
708"
REFERENCES,0.7030685920577617,"NeurIPS Paper Checklist
709"
CLAIMS,0.703971119133574,"1. Claims
710"
CLAIMS,0.7048736462093863,"Question: Do the main claims made in the abstract and introduction accurately reflect the
711"
CLAIMS,0.7057761732851986,"paper’s contributions and scope?
712"
CLAIMS,0.7066787003610109,"Answer: [Yes]
713"
CLAIMS,0.7075812274368231,"Justification: The claims about TOPF are supported by the theoretical background in Section 2
714"
CLAIMS,0.7084837545126353,"and Section 3, quantitatively and qualitatively validated and benchmarked in Section 5.
715"
CLAIMS,0.7093862815884476,"Furthermore, a theoretical guarantee can be found in Section 4.
716"
CLAIMS,0.7102888086642599,"Guidelines:
717"
CLAIMS,0.7111913357400722,"• The answer NA means that the abstract and introduction do not include the claims
718"
CLAIMS,0.7120938628158845,"made in the paper.
719"
CLAIMS,0.7129963898916968,"• The abstract and/or introduction should clearly state the claims made, including the
720"
CLAIMS,0.7138989169675091,"contributions made in the paper and important assumptions and limitations. A No or
721"
CLAIMS,0.7148014440433214,"NA answer to this question will not be perceived well by the reviewers.
722"
CLAIMS,0.7157039711191335,"• The claims made should match theoretical and experimental results, and reflect how
723"
CLAIMS,0.7166064981949458,"much the results can be expected to generalize to other settings.
724"
CLAIMS,0.7175090252707581,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
725"
CLAIMS,0.7184115523465704,"are not attained by the paper.
726"
LIMITATIONS,0.7193140794223827,"2. Limitations
727"
LIMITATIONS,0.720216606498195,"Question: Does the paper discuss the limitations of the work performed by the authors?
728"
LIMITATIONS,0.7211191335740073,"Answer: [Yes]
729"
LIMITATIONS,0.7220216606498195,"Justification: We believe that being open about limitations is crucial for the practice of
730"
LIMITATIONS,0.7229241877256317,"doing good Science. We briefly discuss the main limitations in ??, and talk in detail about
731"
LIMITATIONS,0.723826714801444,"limitations in Appendix G. Finally, we are open about limitations when talking about the
732"
LIMITATIONS,0.7247292418772563,"theoretical background and the algorithm in Section 2 and Section 3 and the remark in
733"
LIMITATIONS,0.7256317689530686,"Section 4.
734"
LIMITATIONS,0.7265342960288809,"Guidelines:
735"
LIMITATIONS,0.7274368231046932,"• The answer NA means that the paper has no limitation while the answer No means that
736"
LIMITATIONS,0.7283393501805054,"the paper has limitations, but those are not discussed in the paper.
737"
LIMITATIONS,0.7292418772563177,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
738"
LIMITATIONS,0.73014440433213,"• The paper should point out any strong assumptions and how robust the results are to
739"
LIMITATIONS,0.7310469314079422,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
740"
LIMITATIONS,0.7319494584837545,"model well-specification, asymptotic approximations only holding locally). The authors
741"
LIMITATIONS,0.7328519855595668,"should reflect on how these assumptions might be violated in practice and what the
742"
LIMITATIONS,0.733754512635379,"implications would be.
743"
LIMITATIONS,0.7346570397111913,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
744"
LIMITATIONS,0.7355595667870036,"only tested on a few datasets or with a few runs. In general, empirical results often
745"
LIMITATIONS,0.7364620938628159,"depend on implicit assumptions, which should be articulated.
746"
LIMITATIONS,0.7373646209386282,"• The authors should reflect on the factors that influence the performance of the approach.
747"
LIMITATIONS,0.7382671480144405,"For example, a facial recognition algorithm may perform poorly when image resolution
748"
LIMITATIONS,0.7391696750902527,"is low or images are taken in low lighting. Or a speech-to-text system might not be
749"
LIMITATIONS,0.740072202166065,"used reliably to provide closed captions for online lectures because it fails to handle
750"
LIMITATIONS,0.7409747292418772,"technical jargon.
751"
LIMITATIONS,0.7418772563176895,"• The authors should discuss the computational efficiency of the proposed algorithms
752"
LIMITATIONS,0.7427797833935018,"and how they scale with dataset size.
753"
LIMITATIONS,0.7436823104693141,"• If applicable, the authors should discuss possible limitations of their approach to
754"
LIMITATIONS,0.7445848375451264,"address problems of privacy and fairness.
755"
LIMITATIONS,0.7454873646209387,"• While the authors might fear that complete honesty about limitations might be used by
756"
LIMITATIONS,0.7463898916967509,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
757"
LIMITATIONS,0.7472924187725631,"limitations that aren’t acknowledged in the paper. The authors should use their best
758"
LIMITATIONS,0.7481949458483754,"judgment and recognize that individual actions in favor of transparency play an impor-
759"
LIMITATIONS,0.7490974729241877,"tant role in developing norms that preserve the integrity of the community. Reviewers
760"
LIMITATIONS,0.75,"will be specifically instructed to not penalize honesty concerning limitations.
761"
THEORY ASSUMPTIONS AND PROOFS,0.7509025270758123,"3. Theory Assumptions and Proofs
762"
THEORY ASSUMPTIONS AND PROOFS,0.7518050541516246,"Question: For each theoretical result, does the paper provide the full set of assumptions and
763"
THEORY ASSUMPTIONS AND PROOFS,0.7527075812274369,"a complete (and correct) proof?
764"
THEORY ASSUMPTIONS AND PROOFS,0.7536101083032491,"Answer: [Yes]
765"
THEORY ASSUMPTIONS AND PROOFS,0.7545126353790613,"Justification: We provide a full set of assumptions for the theorem in Section 4 and a
766"
THEORY ASSUMPTIONS AND PROOFS,0.7554151624548736,"complete proof in Appendix B. We give references for all cited propositions and theorems
767"
THEORY ASSUMPTIONS AND PROOFS,0.7563176895306859,"exceeding basic common mathematical knowledge.
768"
THEORY ASSUMPTIONS AND PROOFS,0.7572202166064982,"Guidelines:
769"
THEORY ASSUMPTIONS AND PROOFS,0.7581227436823105,"• The answer NA means that the paper does not include theoretical results.
770"
THEORY ASSUMPTIONS AND PROOFS,0.7590252707581228,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
771"
THEORY ASSUMPTIONS AND PROOFS,0.759927797833935,"referenced.
772"
THEORY ASSUMPTIONS AND PROOFS,0.7608303249097473,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
773"
THEORY ASSUMPTIONS AND PROOFS,0.7617328519855595,"• The proofs can either appear in the main paper or the supplemental material, but if
774"
THEORY ASSUMPTIONS AND PROOFS,0.7626353790613718,"they appear in the supplemental material, the authors are encouraged to provide a short
775"
THEORY ASSUMPTIONS AND PROOFS,0.7635379061371841,"proof sketch to provide intuition.
776"
THEORY ASSUMPTIONS AND PROOFS,0.7644404332129964,"• Inversely, any informal proof provided in the core of the paper should be complemented
777"
THEORY ASSUMPTIONS AND PROOFS,0.7653429602888087,"by formal proofs provided in appendix or supplemental material.
778"
THEORY ASSUMPTIONS AND PROOFS,0.766245487364621,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
779"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7671480144404332,"4. Experimental Result Reproducibility
780"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7680505415162455,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
781"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7689530685920578,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
782"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.76985559566787,"of the paper (regardless of whether the code and data are provided or not)?
783"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7707581227436823,"Answer: [Yes]
784"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7716606498194946,"Justification: We list all the steps necessary to reproduce TOPF in Section 3, Appendix E, Ap-
785"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7725631768953068,"pendix F and talk in detail about the hyperparameter choices in Appendix D.1. Furthermore,
786"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7734657039711191,"we will both release the Topological Clustering Benchmark Suite and the code necessary to
787"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7743682310469314,"reproduce all experiments in this paper.
788"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7752707581227437,"Guidelines:
789"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.776173285198556,"• The answer NA means that the paper does not include experiments.
790"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7770758122743683,"• If the paper includes experiments, a No answer to this question will not be perceived
791"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7779783393501805,"well by the reviewers: Making the paper reproducible is important, regardless of
792"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7788808664259927,"whether the code and data are provided or not.
793"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.779783393501805,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
794"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7806859205776173,"to make their results reproducible or verifiable.
795"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7815884476534296,"• Depending on the contribution, reproducibility can be accomplished in various ways.
796"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7824909747292419,"For example, if the contribution is a novel architecture, describing the architecture fully
797"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7833935018050542,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
798"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7842960288808665,"be necessary to either make it possible for others to replicate the model with the same
799"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7851985559566786,"dataset, or provide access to the model. In general. releasing code and data is often
800"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7861010830324909,"one good way to accomplish this, but reproducibility can also be provided via detailed
801"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7870036101083032,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
802"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7879061371841155,"of a large language model), releasing of a model checkpoint, or other means that are
803"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7888086642599278,"appropriate to the research performed.
804"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7897111913357401,"• While NeurIPS does not require releasing code, the conference does require all submis-
805"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7906137184115524,"sions to provide some reasonable avenue for reproducibility, which may depend on the
806"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7915162454873647,"nature of the contribution. For example
807"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7924187725631769,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
808"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7933212996389891,"to reproduce that algorithm.
809"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7942238267148014,"(b) If the contribution is primarily a new model architecture, the paper should describe
810"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7951263537906137,"the architecture clearly and fully.
811"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.796028880866426,"(c) If the contribution is a new model (e.g., a large language model), then there should
812"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7969314079422383,"either be a way to access this model for reproducing the results or a way to reproduce
813"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7978339350180506,"the model (e.g., with an open-source dataset or instructions for how to construct
814"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7987364620938628,"the dataset).
815"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7996389891696751,"(d) We recognize that reproducibility may be tricky in some cases, in which case
816"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8005415162454874,"authors are welcome to describe the particular way they provide for reproducibility.
817"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8014440433212996,"In the case of closed-source models, it may be that access to the model is limited in
818"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8023465703971119,"some way (e.g., to registered users), but it should be possible for other researchers
819"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8032490974729242,"to have some path to reproducing or verifying the results.
820"
OPEN ACCESS TO DATA AND CODE,0.8041516245487365,"5. Open access to data and code
821"
OPEN ACCESS TO DATA AND CODE,0.8050541516245487,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
822"
OPEN ACCESS TO DATA AND CODE,0.805956678700361,"tions to faithfully reproduce the main experimental results, as described in supplemental
823"
OPEN ACCESS TO DATA AND CODE,0.8068592057761733,"material?
824"
OPEN ACCESS TO DATA AND CODE,0.8077617328519856,"Answer: [Yes]
825"
OPEN ACCESS TO DATA AND CODE,0.8086642599277978,"Justification: We will release the full code necessary to reproduce all experimental results of
826"
OPEN ACCESS TO DATA AND CODE,0.8095667870036101,"this paper. Furthermore, we will release the topological clustering benchmark suite to the
827"
OPEN ACCESS TO DATA AND CODE,0.8104693140794224,"public.
828"
OPEN ACCESS TO DATA AND CODE,0.8113718411552346,"Guidelines:
829"
OPEN ACCESS TO DATA AND CODE,0.8122743682310469,"• The answer NA means that paper does not include experiments requiring code.
830"
OPEN ACCESS TO DATA AND CODE,0.8131768953068592,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
831"
OPEN ACCESS TO DATA AND CODE,0.8140794223826715,"public/guides/CodeSubmissionPolicy) for more details.
832"
OPEN ACCESS TO DATA AND CODE,0.8149819494584838,"• While we encourage the release of code and data, we understand that this might not be
833"
OPEN ACCESS TO DATA AND CODE,0.8158844765342961,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
834"
OPEN ACCESS TO DATA AND CODE,0.8167870036101083,"including code, unless this is central to the contribution (e.g., for a new open-source
835"
OPEN ACCESS TO DATA AND CODE,0.8176895306859205,"benchmark).
836"
OPEN ACCESS TO DATA AND CODE,0.8185920577617328,"• The instructions should contain the exact command and environment needed to run to
837"
OPEN ACCESS TO DATA AND CODE,0.8194945848375451,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
838"
OPEN ACCESS TO DATA AND CODE,0.8203971119133574,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
839"
OPEN ACCESS TO DATA AND CODE,0.8212996389891697,"• The authors should provide instructions on data access and preparation, including how
840"
OPEN ACCESS TO DATA AND CODE,0.822202166064982,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
841"
OPEN ACCESS TO DATA AND CODE,0.8231046931407943,"• The authors should provide scripts to reproduce all experimental results for the new
842"
OPEN ACCESS TO DATA AND CODE,0.8240072202166066,"proposed method and baselines. If only a subset of experiments are reproducible, they
843"
OPEN ACCESS TO DATA AND CODE,0.8249097472924187,"should state which ones are omitted from the script and why.
844"
OPEN ACCESS TO DATA AND CODE,0.825812274368231,"• At submission time, to preserve anonymity, the authors should release anonymized
845"
OPEN ACCESS TO DATA AND CODE,0.8267148014440433,"versions (if applicable).
846"
OPEN ACCESS TO DATA AND CODE,0.8276173285198556,"• Providing as much information as possible in supplemental material (appended to the
847"
OPEN ACCESS TO DATA AND CODE,0.8285198555956679,"paper) is recommended, but including URLs to data and code is permitted.
848"
OPEN ACCESS TO DATA AND CODE,0.8294223826714802,"6. Experimental Setting/Details
849"
OPEN ACCESS TO DATA AND CODE,0.8303249097472925,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
850"
OPEN ACCESS TO DATA AND CODE,0.8312274368231047,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
851"
OPEN ACCESS TO DATA AND CODE,0.8321299638989169,"results?
852"
OPEN ACCESS TO DATA AND CODE,0.8330324909747292,"Answer: [Yes]
853"
OPEN ACCESS TO DATA AND CODE,0.8339350180505415,"Justification: We do not train neural networks in this paper. However, we will release
854"
OPEN ACCESS TO DATA AND CODE,0.8348375451263538,"the topological clustering benchmark suite. We talk in detail about how to reproduce the
855"
OPEN ACCESS TO DATA AND CODE,0.8357400722021661,"algorithm and the relevant choices of hyperparameters, and how we evaluate the experiments.
856"
OPEN ACCESS TO DATA AND CODE,0.8366425992779783,"Guidelines:
857"
OPEN ACCESS TO DATA AND CODE,0.8375451263537906,"• The answer NA means that the paper does not include experiments.
858"
OPEN ACCESS TO DATA AND CODE,0.8384476534296029,"• The experimental setting should be presented in the core of the paper to a level of detail
859"
OPEN ACCESS TO DATA AND CODE,0.8393501805054152,"that is necessary to appreciate the results and make sense of them.
860"
OPEN ACCESS TO DATA AND CODE,0.8402527075812274,"• The full details can be provided either with the code, in appendix, or as supplemental
861"
OPEN ACCESS TO DATA AND CODE,0.8411552346570397,"material.
862"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.842057761732852,"7. Experiment Statistical Significance
863"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8429602888086642,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
864"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8438628158844765,"information about the statistical significance of the experiments?
865"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8447653429602888,"Answer: [Yes]
866"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8456678700361011,"Justification: We provide standard deviations where applicable in Table 1, unless the
867"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8465703971119134,"standard deviation is 0, which we talk about in the caption of the table. In Figure 5 we give
868"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8474729241877257,"a confidence interval for all the experiments.
869"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8483754512635379,"Guidelines:
870"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8492779783393501,"• The answer NA means that the paper does not include experiments.
871"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8501805054151624,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
872"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8510830324909747,"dence intervals, or statistical significance tests, at least for the experiments that support
873"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.851985559566787,"the main claims of the paper.
874"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8528880866425993,"• The factors of variability that the error bars are capturing should be clearly stated (for
875"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8537906137184116,"example, train/test split, initialization, random drawing of some parameter, or overall
876"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8546931407942239,"run with given experimental conditions).
877"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.855595667870036,"• The method for calculating the error bars should be explained (closed form formula,
878"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8564981949458483,"call to a library function, bootstrap, etc.)
879"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8574007220216606,"• The assumptions made should be given (e.g., Normally distributed errors).
880"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8583032490974729,"• It should be clear whether the error bar is the standard deviation or the standard error
881"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8592057761732852,"of the mean.
882"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8601083032490975,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
883"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8610108303249098,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
884"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8619133574007221,"of Normality of errors is not verified.
885"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8628158844765343,"• For asymmetric distributions, the authors should be careful not to show in tables or
886"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8637184115523465,"figures symmetric error bars that would yield results that are out of range (e.g. negative
887"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8646209386281588,"error rates).
888"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8655234657039711,"• If error bars are reported in tables or plots, The authors should explain in the text how
889"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8664259927797834,"they were calculated and reference the corresponding figures or tables in the text.
890"
EXPERIMENTS COMPUTE RESOURCES,0.8673285198555957,"8. Experiments Compute Resources
891"
EXPERIMENTS COMPUTE RESOURCES,0.868231046931408,"Question: For each experiment, does the paper provide sufficient information on the com-
892"
EXPERIMENTS COMPUTE RESOURCES,0.8691335740072202,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
893"
EXPERIMENTS COMPUTE RESOURCES,0.8700361010830325,"the experiments?
894"
EXPERIMENTS COMPUTE RESOURCES,0.8709386281588448,"Answer: [Yes]
895"
EXPERIMENTS COMPUTE RESOURCES,0.871841155234657,"Justification: We list the hardware used in Appendix D and list the required running times in
896"
EXPERIMENTS COMPUTE RESOURCES,0.8727436823104693,"our quantitative experiments, see Table 1. Because we did not train neural networks, the
897"
EXPERIMENTS COMPUTE RESOURCES,0.8736462093862816,"results are easily reproducible on any PC in reasonable time.
898"
EXPERIMENTS COMPUTE RESOURCES,0.8745487364620939,"Guidelines:
899"
EXPERIMENTS COMPUTE RESOURCES,0.8754512635379061,"• The answer NA means that the paper does not include experiments.
900"
EXPERIMENTS COMPUTE RESOURCES,0.8763537906137184,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
901"
EXPERIMENTS COMPUTE RESOURCES,0.8772563176895307,"or cloud provider, including relevant memory and storage.
902"
EXPERIMENTS COMPUTE RESOURCES,0.878158844765343,"• The paper should provide the amount of compute required for each of the individual
903"
EXPERIMENTS COMPUTE RESOURCES,0.8790613718411552,"experimental runs as well as estimate the total compute.
904"
EXPERIMENTS COMPUTE RESOURCES,0.8799638989169675,"• The paper should disclose whether the full research project required more compute
905"
EXPERIMENTS COMPUTE RESOURCES,0.8808664259927798,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
906"
EXPERIMENTS COMPUTE RESOURCES,0.881768953068592,"didn’t make it into the paper).
907"
CODE OF ETHICS,0.8826714801444043,"9. Code Of Ethics
908"
CODE OF ETHICS,0.8835740072202166,"Question: Does the research conducted in the paper conform, in every respect, with the
909"
CODE OF ETHICS,0.8844765342960289,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
910"
CODE OF ETHICS,0.8853790613718412,"Answer: [Yes]
911"
CODE OF ETHICS,0.8862815884476535,"Justification: We have reviewed the NeurIPS Ethics guidelines to make sure our research
912"
CODE OF ETHICS,0.8871841155234657,"complies with them. (It does comply.)
913"
CODE OF ETHICS,0.8880866425992779,"Guidelines:
914"
CODE OF ETHICS,0.8889891696750902,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
915"
CODE OF ETHICS,0.8898916967509025,"• If the authors answer No, they should explain the special circumstances that require a
916"
CODE OF ETHICS,0.8907942238267148,"deviation from the Code of Ethics.
917"
CODE OF ETHICS,0.8916967509025271,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
918"
CODE OF ETHICS,0.8925992779783394,"eration due to laws or regulations in their jurisdiction).
919"
BROADER IMPACTS,0.8935018050541517,"10. Broader Impacts
920"
BROADER IMPACTS,0.894404332129964,"Question: Does the paper discuss both potential positive societal impacts and negative
921"
BROADER IMPACTS,0.8953068592057761,"societal impacts of the work performed?
922"
BROADER IMPACTS,0.8962093862815884,"Answer: [NA]
923"
BROADER IMPACTS,0.8971119133574007,"Justification: As the paper is of foundational nature, we do not foresee any direct societal
924"
BROADER IMPACTS,0.898014440433213,"impacts.
925"
BROADER IMPACTS,0.8989169675090253,"Guidelines:
926"
BROADER IMPACTS,0.8998194945848376,"• The answer NA means that there is no societal impact of the work performed.
927"
BROADER IMPACTS,0.9007220216606499,"• If the authors answer NA or No, they should explain why their work has no societal
928"
BROADER IMPACTS,0.9016245487364621,"impact or why the paper does not address societal impact.
929"
BROADER IMPACTS,0.9025270758122743,"• Examples of negative societal impacts include potential malicious or unintended uses
930"
BROADER IMPACTS,0.9034296028880866,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
931"
BROADER IMPACTS,0.9043321299638989,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
932"
BROADER IMPACTS,0.9052346570397112,"groups), privacy considerations, and security considerations.
933"
BROADER IMPACTS,0.9061371841155235,"• The conference expects that many papers will be foundational research and not tied
934"
BROADER IMPACTS,0.9070397111913358,"to particular applications, let alone deployments. However, if there is a direct path to
935"
BROADER IMPACTS,0.907942238267148,"any negative applications, the authors should point it out. For example, it is legitimate
936"
BROADER IMPACTS,0.9088447653429603,"to point out that an improvement in the quality of generative models could be used to
937"
BROADER IMPACTS,0.9097472924187726,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
938"
BROADER IMPACTS,0.9106498194945848,"that a generic algorithm for optimizing neural networks could enable people to train
939"
BROADER IMPACTS,0.9115523465703971,"models that generate Deepfakes faster.
940"
BROADER IMPACTS,0.9124548736462094,"• The authors should consider possible harms that could arise when the technology is
941"
BROADER IMPACTS,0.9133574007220217,"being used as intended and functioning correctly, harms that could arise when the
942"
BROADER IMPACTS,0.9142599277978339,"technology is being used as intended but gives incorrect results, and harms following
943"
BROADER IMPACTS,0.9151624548736462,"from (intentional or unintentional) misuse of the technology.
944"
BROADER IMPACTS,0.9160649819494585,"• If there are negative societal impacts, the authors could also discuss possible mitigation
945"
BROADER IMPACTS,0.9169675090252708,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
946"
BROADER IMPACTS,0.9178700361010831,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
947"
BROADER IMPACTS,0.9187725631768953,"feedback over time, improving the efficiency and accessibility of ML).
948"
SAFEGUARDS,0.9196750902527075,"11. Safeguards
949"
SAFEGUARDS,0.9205776173285198,"Question: Does the paper describe safeguards that have been put in place for responsible
950"
SAFEGUARDS,0.9214801444043321,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
951"
SAFEGUARDS,0.9223826714801444,"image generators, or scraped datasets)?
952"
SAFEGUARDS,0.9232851985559567,"Answer: [NA]
953"
SAFEGUARDS,0.924187725631769,"Justification: We do not foresee any such risks.
954"
SAFEGUARDS,0.9250902527075813,"Guidelines:
955"
SAFEGUARDS,0.9259927797833934,"• The answer NA means that the paper poses no such risks.
956"
SAFEGUARDS,0.9268953068592057,"• Released models that have a high risk for misuse or dual-use should be released with
957"
SAFEGUARDS,0.927797833935018,"necessary safeguards to allow for controlled use of the model, for example by requiring
958"
SAFEGUARDS,0.9287003610108303,"that users adhere to usage guidelines or restrictions to access the model or implementing
959"
SAFEGUARDS,0.9296028880866426,"safety filters.
960"
SAFEGUARDS,0.9305054151624549,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
961"
SAFEGUARDS,0.9314079422382672,"should describe how they avoided releasing unsafe images.
962"
SAFEGUARDS,0.9323104693140795,"• We recognize that providing effective safeguards is challenging, and many papers do
963"
SAFEGUARDS,0.9332129963898917,"not require this, but we encourage authors to take this into account and make a best
964"
SAFEGUARDS,0.9341155234657039,"faith effort.
965"
LICENSES FOR EXISTING ASSETS,0.9350180505415162,"12. Licenses for existing assets
966"
LICENSES FOR EXISTING ASSETS,0.9359205776173285,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
967"
LICENSES FOR EXISTING ASSETS,0.9368231046931408,"the paper, properly credited and are the license and terms of use explicitly mentioned and
968"
LICENSES FOR EXISTING ASSETS,0.9377256317689531,"properly respected?
969"
LICENSES FOR EXISTING ASSETS,0.9386281588447654,"Answer: [Yes]
970"
LICENSES FOR EXISTING ASSETS,0.9395306859205776,"Justification: We credit the creators and owners of code used in the model, and state the
971"
LICENSES FOR EXISTING ASSETS,0.9404332129963899,"licenses.
972"
LICENSES FOR EXISTING ASSETS,0.9413357400722022,"Guidelines:
973"
LICENSES FOR EXISTING ASSETS,0.9422382671480144,"• The answer NA means that the paper does not use existing assets.
974"
LICENSES FOR EXISTING ASSETS,0.9431407942238267,"• The authors should cite the original paper that produced the code package or dataset.
975"
LICENSES FOR EXISTING ASSETS,0.944043321299639,"• The authors should state which version of the asset is used and, if possible, include a
976"
LICENSES FOR EXISTING ASSETS,0.9449458483754513,"URL.
977"
LICENSES FOR EXISTING ASSETS,0.9458483754512635,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
978"
LICENSES FOR EXISTING ASSETS,0.9467509025270758,"• For scraped data from a particular source (e.g., website), the copyright and terms of
979"
LICENSES FOR EXISTING ASSETS,0.9476534296028881,"service of that source should be provided.
980"
LICENSES FOR EXISTING ASSETS,0.9485559566787004,"• If assets are released, the license, copyright information, and terms of use in the
981"
LICENSES FOR EXISTING ASSETS,0.9494584837545126,"package should be provided. For popular datasets, paperswithcode.com/datasets
982"
LICENSES FOR EXISTING ASSETS,0.9503610108303249,"has curated licenses for some datasets. Their licensing guide can help determine the
983"
LICENSES FOR EXISTING ASSETS,0.9512635379061372,"license of a dataset.
984"
LICENSES FOR EXISTING ASSETS,0.9521660649819494,"• For existing datasets that are re-packaged, both the original license and the license of
985"
LICENSES FOR EXISTING ASSETS,0.9530685920577617,"the derived asset (if it has changed) should be provided.
986"
LICENSES FOR EXISTING ASSETS,0.953971119133574,"• If this information is not available online, the authors are encouraged to reach out to
987"
LICENSES FOR EXISTING ASSETS,0.9548736462093863,"the asset’s creators.
988"
NEW ASSETS,0.9557761732851986,"13. New Assets
989"
NEW ASSETS,0.9566787003610109,"Question: Are new assets introduced in the paper well documented and is the documentation
990"
NEW ASSETS,0.9575812274368231,"provided alongside the assets?
991"
NEW ASSETS,0.9584837545126353,"Answer: [Yes]
992"
NEW ASSETS,0.9593862815884476,"Justification: The code and benchmark suite which we will release with the paper are
993"
NEW ASSETS,0.9602888086642599,"described and documented in the paper.
994"
NEW ASSETS,0.9611913357400722,"Guidelines:
995"
NEW ASSETS,0.9620938628158845,"• The answer NA means that the paper does not release new assets.
996"
NEW ASSETS,0.9629963898916968,"• Researchers should communicate the details of the dataset/code/model as part of their
997"
NEW ASSETS,0.9638989169675091,"submissions via structured templates. This includes details about training, license,
998"
NEW ASSETS,0.9648014440433214,"limitations, etc.
999"
NEW ASSETS,0.9657039711191335,"• The paper should discuss whether and how consent was obtained from people whose
1000"
NEW ASSETS,0.9666064981949458,"asset is used.
1001"
NEW ASSETS,0.9675090252707581,"• At submission time, remember to anonymize your assets (if applicable). You can either
1002"
NEW ASSETS,0.9684115523465704,"create an anonymized URL or include an anonymized zip file.
1003"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9693140794223827,"14. Crowdsourcing and Research with Human Subjects
1004"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.970216606498195,"Question: For crowdsourcing experiments and research with human subjects, does the paper
1005"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9711191335740073,"include the full text of instructions given to participants and screenshots, if applicable, as
1006"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9720216606498195,"well as details about compensation (if any)?
1007"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9729241877256317,"Answer: [NA]
1008"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.973826714801444,"Justification: This paper does not involve crowdsourcing nor research with human subjects.
1009"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9747292418772563,"Guidelines:
1010"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9756317689530686,"• The answer NA means that the paper does not involve crowdsourcing nor research with
1011"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9765342960288809,"human subjects.
1012"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9774368231046932,"• Including this information in the supplemental material is fine, but if the main contribu-
1013"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9783393501805054,"tion of the paper involves human subjects, then as much detail as possible should be
1014"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9792418772563177,"included in the main paper.
1015"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.98014440433213,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
1016"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9810469314079422,"or other labor should be paid at least the minimum wage in the country of the data
1017"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9819494584837545,"collector.
1018"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9828519855595668,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
1019"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.983754512635379,"Subjects
1020"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9846570397111913,"Question: Does the paper describe potential risks incurred by study participants, whether
1021"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9855595667870036,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
1022"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9864620938628159,"approvals (or an equivalent approval/review based on the requirements of your country or
1023"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9873646209386282,"institution) were obtained?
1024"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9882671480144405,"Answer: [NA]
1025"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9891696750902527,"Justification: This paper does not involve crowdsourcing nor research with human subjects.
1026"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.990072202166065,"Guidelines:
1027"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9909747292418772,"• The answer NA means that the paper does not involve crowdsourcing nor research with
1028"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9918772563176895,"human subjects.
1029"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9927797833935018,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
1030"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9936823104693141,"may be required for any human subjects research. If you obtained IRB approval, you
1031"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9945848375451264,"should clearly state this in the paper.
1032"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9954873646209387,"• We recognize that the procedures for this may vary significantly between institutions
1033"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9963898916967509,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
1034"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9972924187725631,"guidelines for their institution.
1035"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9981949458483754,"• For initial submissions, do not include any information that would break anonymity (if
1036"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9990974729241877,"applicable), such as the institution conducting the review.
1037"
