Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.000946073793755913,"Self-training, a semi-supervised learning algorithm, leverages a large amount of
unlabeled data to improve learning when the labeled data are limited. Despite em-
pirical successes, its theoretical characterization remains elusive. To the best of
our knowledge, this work establishes the ﬁrst theoretical analysis for the known
iterative self-training paradigm and proves the beneﬁts of unlabeled data in both
training convergence and generalization ability. To make our theoretical analysis
feasible, we focus on the case of one-hidden-layer neural networks. However,
theoretical understanding of iterative self-training is non-trivial even for a shal-
low neural network. One of the key challenges is that existing neural network
landscape analysis built upon supervised learning no longer holds in the (semi-
supervised) self-training paradigm. We address this challenge and prove that itera-
tive self-training converges linearly with both convergence rate and generalization
accuracy improved in the order of 1/
√"
ABSTRACT,0.001892147587511826,"M, where M is the number of unlabeled
samples. Experiments from shallow neural networks to deep neural networks are
also provided to justify the correctness of our established theoretical insights on
self-training."
INTRODUCTION,0.002838221381267739,"1
INTRODUCTION"
INTRODUCTION,0.003784295175023652,"Self-training (Scudder, 1965; Yarowsky, 1995; Lee et al., 2013; Han et al., 2019), one of the most
powerful semi-supervised learning (SemiSL) algorithms, augments a limited number of labeled data
with unlabeled data so as to achieve improved generalization performance on test data, compared
with the model trained by supervised learning using the labeled data only. Self-training has shown
empirical success in diversiﬁed applications such as few-shot image classiﬁcation (Su et al., 2020;
Xie et al., 2020; Chen et al., 2020a; Yalniz et al., 2019; Zoph et al., 2020), objective detection
(Rosenberg et al., 2005), robustness-aware model training against adversarial attacks (Carmon et al.,
2019), continual lifelong learning (Lee et al., 2019), and natural language processing (He et al.,
2019; Kahn et al., 2020). The terminology “self-training” has been used to describe various SemiSL"
INTRODUCTION,0.004730368968779565,Published as a conference paper at ICLR 2022
INTRODUCTION,0.005676442762535478,"algorithms in the literature, while this paper is centered on the commonly-used iterative self-training
method in particular. In this setup, an initial teacher model (learned from the labeled data) is applied
to the unlabeled data to generate pseudo labels. One then trains a student model by minimizing the
weighted empirical risk of both the labeled and unlabeled data. The student model is then used as
the new teacher to update the pseudo labels of the unlabeled data. This process is repeated multiple
times to improve the eventual student model. We refer readers to Section 2 for algorithmic details."
INTRODUCTION,0.006622516556291391,"Despite the empirical achievement of self-training methods with neural networks, the theoretical
justiﬁcation of such success is very limited, even in the ﬁeld of SemiSL. The majority of the theo-
retical results on general SemiSL are limited to linear networks (Chen et al., 2020b; Raghunathan
et al., 2020; Oymak & Gulcu, 2020; Oneto et al., 2011). The authors in (Balcan & Blum, 2010)
show that unlabeled data can improve the generalization bound if the unlabeled data distribution and
target model are compatible. For instance, the unlabeled data need to be well-chosen such that the
target function for labeled data can separate the unlabeled data clusters, which, however, may not be
able to be veriﬁed ahead. Moreover, (Rigollet, 2007; Singh et al., 2008) proves that unlabeled data
can improve the convergence rate and generalization error under a similar clustering assumption,
where the data contains clusters that have homogeneous labels. A recent work by Wei et al. (2020)
analyzes SemiSL on nonlinear neural networks and proves that an inﬁnite number of unlabeled data
can improve the generalization compared with training with labeled data only. However, Wei et al.
(2020) considers single shot rather than iterative SemiSL, and the training problem aims to minimize
the consistency regularization rather than the risk function in the conventional self-training method
(Lee et al., 2013). Moreover, Wei et al. (2020) directly analyzes the global optimum of the noncon-
vex training problem without any discussion about how to achieve the global optimum. To the best
of our knowledge, there exists no analytical characterization of how the unlabeled data affect the
generalization of the learned model by iterative self-training on nonlinear neural networks."
K,0.007568590350047304,"100K
200K
300K
400K
500K
Number of unlabeled data 5.5 6 6.5 7"
K,0.008514664143803218,Test accuracy
K,0.00946073793755913,Improvement (%)
K,0.010406811731315043,"Figure 1:
The trend of test accuracy
improvement (%) on CIFAR-10 by self-
training on CIFAR-10 (labeled) with dif-
ferent amount of unlabeled data from 80
Million Tiny Images matches our theoret-
ical prediction."
K,0.011352885525070956,"Contributions. This paper provides the ﬁrst theoretical
study of iterative self-training on nonlinear neural net-
works. Focusing on one-hidden-layer neural networks,
this paper provides a quantitative analysis of the gen-
eralization performance of iterative self-training as a
function of the number of labeled and unlabeled sam-
ples. Speciﬁcally, our contributions include"
K,0.01229895931882687,"1.
Quantitative justiﬁcation of generalization im-
provement by unlabeled data.
Assuming the exis-
tence of a ground-truth model with weights W ∗that
maps the features to the corresponding labels, we prove
that the learned model via iterative self-training moves
closer to W ∗as the number M of unlabeled data in-
creases, indicating a better testing performance. Specif-
ically, we prove that the Frobenius distance to W ∗,
which is approximately linear in the generalization er-
ror, decreases in the order of 1/
√"
K,0.013245033112582781,"M.
As an exam-
ple, Figure 1 shows that the proposed theoretical bound
matches the empirical self-training performance versus the number of unlabeled data for image clas-
siﬁcation; see details in Section 4.2."
K,0.014191106906338695,"2. Analytical justiﬁcation of iterative self-training over single shot alternative. We prove that
the student models returned by the iterative self-training method converges linearly to a model close
to W ∗, with the rate improvement in the order of 1/
√ M."
K,0.015137180700094607,"3. Sample complexity analysis of labeled and unlabeled data for learning a proper model.
We quantify the impact of labeled and unlabeled data on the generalization of the learned model.
In particular, we prove that the sample complexity of labeled data can be reduced compared with
supervised learning."
RELATED WORKS,0.01608325449385052,"1.1
RELATED WORKS"
RELATED WORKS,0.017029328287606435,"Semi-supervised learning. Besides self-training, many recent SemiSL algorithms exploit either
consistency regularization or entropy minimization. Consistency regularization is based on the as-"
RELATED WORKS,0.017975402081362345,Published as a conference paper at ICLR 2022
RELATED WORKS,0.01892147587511826,"sumption that the learned model will return same or similar output when the input is perturbed
(Laine & Aila, 2016; Bachman et al., 2014; Sajjadi et al., 2016; Tarvainen & Valpola, 2017; Reed
et al., 2015). (Grandvalet & Bengio, 2005) claims that the unlabeled data are more informative if the
pseudo labels of the unlabeled data have lower entropy. Therefore, a line of works (Grandvalet &
Bengio, 2005; Miyato et al., 2018) adds a regularization term that minimizes the entropy of the out-
puts of the unlabeled data. In addition, hybrid algorithms that unify both the above regularizations
have been developed like (Berthelot et al., 2019a;b; Sohn et al., 2020)."
RELATED WORKS,0.019867549668874173,"Domain adaptation. Domain adaptation exploits abundant data in the source domain to learn a
model for the target domain, where only limited training data are available (Liebelt & Schmid,
2010; Vazquez et al., 2013; Zhang et al., 2013; Long et al., 2015; Tzeng et al., 2014). Source and
target domain are related but different. Unsupervised domain adaptation (Ganin & Lempitsky, 2015;
Ganin et al., 2016; Gong et al., 2013; Bousmalis et al., 2016), where training data in target domain
are unlabeled, is similar to SemiSL, and self-training methods have been used for analysis (Zou
et al., 2018; Tang et al., 2012; French et al., 2018). However, self-training and unsupervised domain
adaptation are fundamentally different. The former learns a model for the domain where there is
limited labeled data, with the help of a large number of unlabeled data from a different domain. The
latter learns a model for the domain where the training data are unlabeled, with the help of sufﬁcient
labeled data from a different domain."
RELATED WORKS,0.020813623462630087,"Generalization analysis of supervised learning. In theory, the testing error is upper bounded by the
training error plus the generalization gap between training and testing. These two quantities are often
analyzed separately and cannot be proved to be small simultaneously for deep neural networks. For
example, neural tangent kernel (NTK) method (Jacot et al., 2018; Du et al., 2018; Lee et al., 2018)
shows the training error can be zero, and the Rademacher complexity in (Bartlett & Mendelson,
2002) bounds the generalization gap (Arora et al., 2019a). For one-hidden-layer neural networks
(Safran & Shamir, 2018), the testing error can be proved to be zero under mild conditions. One
common assumption is that the input data belongs to the Gaussian distribution (Zhong et al., 2017;
Ge et al., 2018; Kalai et al., 2008; Bakshi et al., 2019; Zhang et al., 2016; Brutzkus & Globerson,
2017; Li & Yuan, 2017; Soltanolkotabi et al., 2018). Another line of approaches (Brutzkus et al.,
2018; Li & Liang, 2018; Wang et al., 2019) consider linearly separable data."
RELATED WORKS,0.021759697256385997,"The rest of this paper is organized as follows. Section 2 introduces the problem formulation and
self-training algorithm. Major results are summarized in Section 3, and empirical evaluations are
presented in Section 4. Section 5 concludes the whole paper. All the proofs are in the Appendix."
RELATED WORKS,0.02270577105014191,"2
FORMALIZING SELF-TRAINING: NOTATION, FORMULATION, AND
ALGORITHM"
RELATED WORKS,0.023651844843897825,"Problem formulation.
Given N labeled data sampled from distribution Pl, denoted by D =
{xn, yn}N
n=1, and M unlabeled data drawn from distribution Pu, denoted by eD = {exm}M
m=1. The
aim is to ﬁnd a neural network model g(W ), where W denotes the trainable weights, that minimizes
the testing error on data sampled from Pl."
RELATED WORKS,0.02459791863765374,Table 1: Iterative Self-Training
RELATED WORKS,0.02554399243140965,"(S1) Initialize iteration ℓ= 0 and obtain a model W (ℓ) as the teacher using labeled data D
only;
(S2) Use the teacher model to obtain pseudo labels eym of unlabeled data in eD;
(S3) Train the neural network by minimizing (1) via T-step mini-batch gradient descent
method using disjoint subsets {Dt}T −1
t=0 and { eDt}T −1
t=0 of eD. Let W (ℓ+1) denote the obtained
student model;
(S4) Use W (ℓ+1) as the current teacher model. Let ℓ←ℓ+ 1 and go back to step (S2);"
RELATED WORKS,0.026490066225165563,"Iterative self-training. In each iteration, given the current teacher predictor g(W (ℓ)), the pseudo-
labels for the unlabeled data in eD are computed as ˜ym = g(W (ℓ); exm). The method then minimizes
the weighted empirical risk ˆfD, e
D(W ) of both labeled and unlabeled data through stochastic gradient"
RELATED WORKS,0.027436140018921477,Published as a conference paper at ICLR 2022
RELATED WORKS,0.02838221381267739,"descent, where"
RELATED WORKS,0.0293282876064333,"ˆfD, e
D(W ) =
λ
2N N
X n=1"
RELATED WORKS,0.030274361400189215," 
yn −g(W ; xn)
2 +
eλ
2M M
X m=1"
RELATED WORKS,0.03122043519394513," 
eym −g(W ; exm)
2,
(1)"
RELATED WORKS,0.03216650898770104,"and λ + eλ = 1. The learned student model g(W (ℓ+1)) is used as the teacher model in the next iter-
ation. The initial model g(W (0)) is learned from labeled data. The formal algorithm is summarized
as in Table 1."
RELATED WORKS,0.033112582781456956,"Model and assumptions. This paper considers regression1, where g is a one-hidden-layer fully
connected neural network equipped with K neurons. Namely, given the input x ∈Rd and weights
W = [w1, w2, · · · , wK] ∈Rd×K, we have"
RELATED WORKS,0.03405865657521287,"g(W ; x) := 1 K K
X"
RELATED WORKS,0.03500473036896878,"j=1
φ(wT
j x),
(2)"
RELATED WORKS,0.03595080416272469,"where φ is the ReLU activation function2, and φ(z) = max{z, 0} for any input z ∈R. Here, we ﬁx
the top layer weights as 1 for simplicity, and the equivalence of such a simpliﬁcation is discussed in
Appendix K."
RELATED WORKS,0.036896877956480605,"Moreover, we assume an unknown ground-truth model with weights W ∗that maps all the features to
the corresponding labels drawn from Pl, i.e., y = g(W ∗; x), where (x, y) ∼Pl. The generalization
function (GF) with respect to g(W ) is deﬁned as"
RELATED WORKS,0.03784295175023652,"I
 
g(W )

= E(x,y)∼Pl
 
y −g(W ; x)
2 = E(x,y)∼Pl
 
g(W ∗; x) −g(W ; x)
2.
(3)"
RELATED WORKS,0.03878902554399243,"By deﬁnition I
 
g(W ∗)

is zero. Clearly, W ∗is not unique because any column permutation of
W ∗, which corresponds to permuting neurons, represents the same function as W ∗and minimizes
GF in (3) too. To simplify the representation, we follow the convention and abuse the notation that
the distance from W to W ∗, denoted by ∥W −W ∗∥F , means the smallest distance from W to
any permutation of W ∗. Additionally, some important notations are summarized in Table 2."
RELATED WORKS,0.039735099337748346,"We assume the inputs of both the labeled and unlabeled data belong to the zero mean Gaussian
distribution, i.e., x ∼N(0, δ2Id), and ex ∼N(0, ˜δ2Id). The Gaussian assumption is motivated
by the data whitening (LeCun et al., 2012) and batch normalization techniques (Ioffe & Szegedy,
2015) that are commonly used in practice to improve learning performance. Moreover, training one-
hidden-layer neural network with multiple neurons is NP-Complete (Blum & Rivest, 1992) without
any assumption."
RELATED WORKS,0.04068117313150426,"The focus of this paper. This paper will analyze three aspects about self-training: (1) the gener-
alization performance of W (L), the returned model by self-training after L iterations, measured by
∥W (L) −W ∗∥F 3; (2) the inﬂuence of parameter λ in (1) on the training performance; and (3) the
impact of unlabeled data on the training and generalization performance."
RELATED WORKS,0.041627246925260174,Table 2: Some Important Notations
RELATED WORKS,0.04257332071901608,"D = {xn, yn}N
n=1 Labeled dataset with N number of samples;
eD = {exm}M
m=1
Unlabeled dataset with M number of samples;
d
Dimension of the input x or ex;
K
Number of neurons in the hidden layer;
κ
Conditional number (the ratio of the largest and smallest singular values) of W ∗;
W (ℓ)
Model returned by self-training after ℓiterations; W (0) is the initial model;
W ∗
Weights of the ground truth model;"
RELATED WORKS,0.043519394512771994,"W [ˆλ]
W [ˆλ] = ˆλW ∗+ (1 −ˆλ)W (0);"
RELATED WORKS,0.04446546830652791,"1The results can be extended to binary classiﬁcation with a cross-entropy loss function.
Please see
Appendix-I."
RELATED WORKS,0.04541154210028382,"2Because ReLU is non-linear and non-smooth, (1) is non-convex and non-smooth, which poses analytical
challenges. The results can be easily extended to smooth functions with bounded gradients, e.g., Sigmoid."
WE USE THIS METRIC BECAUSE I,0.046357615894039736,"3We use this metric because I
 
g(W )

is shown to be linear in ∥W (L) −W ∗∥F numerically when W (L)"
WE USE THIS METRIC BECAUSE I,0.04730368968779565,"is close to W ∗, see Figure 4."
WE USE THIS METRIC BECAUSE I,0.048249763481551564,Published as a conference paper at ICLR 2022
THEORETICAL RESULTS,0.04919583727530748,"3
THEORETICAL RESULTS"
THEORETICAL RESULTS,0.050141911069063384,"Beyond supervised learning:
Challenge of self-training.
The existing theoretical works
such as (Zhong et al., 2017; Zhang et al., 2020a;b;c) verify that for one-hidden-layer neu-
ral networks, if only labeled data are available, and x are drawn from the standard Gaus-
sian distribution, then supervised learning by minimizing (1) with λ
=
1 can return a
model with ground-truth weights W ∗(up to column permutation), as long as the num-
ber of labeled data N is at least N ∗, which depends on κ, K and d.
In contrast, this
paper focuses on the low labeled-data regime when N is less than N ∗.
Speciﬁcally, 𝑾𝑾 𝑾𝑾∗"
THEORETICAL RESULTS,0.0510879848628193,Generalization
THEORETICAL RESULTS,0.05203405865657521,function
THEORETICAL RESULTS,0.052980132450331126,"Objective function
with unlabeled data"
THEORETICAL RESULTS,0.05392620624408704,Local minima 𝑾𝑾(0)
THEORETICAL RESULTS,0.05487228003784295,"Objective function 
without unlabeled data"
THEORETICAL RESULTS,0.05581835383159887,"Figure 2: Adding unlabeled data in the em-
pirical risk function drives its local minimum
closer to W ∗, which minimizes the generaliza-
tion function."
THEORETICAL RESULTS,0.05676442762535478,"N ∗/4 < N ≤N ∗.
(4)"
THEORETICAL RESULTS,0.05771050141911069,"Intuitively, if N < N ∗, the landscape of the empir-
ical risk of the labeled data becomes highly non-
convex, even in a neighborhood of W ∗, thus, the
existing analyses for supervised learning do not
hold in this region. With additional unlabeled data,
the landscape of the weighted empirical risk be-
comes smoother near W ∗. Moreover, as M in-
creases, and starting from a nearby initialization,
the returned model W (L) by iterative self-training
can converge to a local minimum that is closer to
W ∗(see illustration in Figure 2)."
THEORETICAL RESULTS,0.0586565752128666,"Compared with supervised learning, the formal analyses of self-training need to handle new techni-
cal challenges from two aspects. First, the existing analyses of supervised learning exploit the fact
that the GF and the empirical risk have the same minimizer, i.e., W ∗. This property does not hold
for self-training as W ∗no longer minimizes the weighted empirical risk in (1). Second, the iterative
manner of self-training complicates the analyses. Speciﬁcally, the empirical risk in each iteration is
different and depends on the model trained in the previous iteration through the pseudo labels."
THEORETICAL RESULTS,0.059602649006622516,"In what follows, we provide theoretical insights and the formal theorems. Some important quantities
ˆλ and µ are deﬁned below"
THEORETICAL RESULTS,0.06054872280037843,"ˆλ :=
λδ2"
THEORETICAL RESULTS,0.06149479659413434,"λδ2 + eλ˜δ2 ,
and
µ = µ(δ, ˜δ) := s"
THEORETICAL RESULTS,0.06244087038789026,λδ2 + eλ˜δ2
THEORETICAL RESULTS,0.06338694418164617,"λρ(δ) + eλρ(˜δ)
,
(5)"
THEORETICAL RESULTS,0.06433301797540208,"where ρ is a positive function deﬁned in (73). ˆλ is an increasing function of λ. Also, from Lemma
11 (in Appendix), ρ(δ) is in the order of δ2 when δ ≤1 for ReLU activation functions. Thus, µ is a
ﬁxed constant, denoted by µ∗, for all δ, ˜δ ≤1. When δ and ˜δ are large, µ increases as they increase.
The formal deﬁnition of N ∗in (4) is c(κ)µ∗2K3d log q, where c(κ) is some polynomial function of
κ and can be viewed as constant."
INFORMAL KEY THEORETICAL FINDINGS,0.065279091769158,"3.1
INFORMAL KEY THEORETICAL FINDINGS"
INFORMAL KEY THEORETICAL FINDINGS,0.06622516556291391,"𝑾𝑾(0)
𝑾𝑾∗ 𝑾𝑾(1) 𝑾𝑾(2)"
INFORMAL KEY THEORETICAL FINDINGS,0.06717123935666983,"𝑾𝑾(𝐿𝐿)
. . ."
INFORMAL KEY THEORETICAL FINDINGS,0.06811731315042574,𝑾𝑾[෡𝜆𝜆] 𝜟𝜟𝟎𝟎
INFORMAL KEY THEORETICAL FINDINGS,0.06906338694418164,"𝜟𝜟𝟏𝟏=
1 + 𝒪𝒪
1
𝑀𝑀
ȉ Δ0
𝐾𝐾
𝓔𝓔𝟎𝟎= 1 −̂𝜆𝜆ȉ 𝑾𝑾∗−𝑾𝑾(0)
𝑭𝑭"
INFORMAL KEY THEORETICAL FINDINGS,0.07000946073793755,"𝓔𝓔𝟏𝟏=
1 + 𝒪𝒪
1
𝑀𝑀
ȉ ℰ0
𝐾𝐾"
INFORMAL KEY THEORETICAL FINDINGS,0.07095553453169347,"Figure 3: Illustration of the (1) ground truth W ∗,
(2) iterations {W (ℓ)}L
ℓ=0, (3) convergent point
W (L), and (4) W [ˆλ] = ˆλW ∗+ (1 −ˆλ)W (0)."
INFORMAL KEY THEORETICAL FINDINGS,0.07190160832544938,"To the best of our knowledge, Theorems 1 and
2 provide the ﬁrst theoretical characterization of
iterative self-training on nonlinear neural net-
works.
Before formally presenting them, we
summarize the highlights as follows."
INFORMAL KEY THEORETICAL FINDINGS,0.0728476821192053,"1. Linear convergence of the learned models.
The learned models converge linearly to a model
close to W ∗. Thus, the iterative approach re-
turns a model with better generalization than that
by the single-shot method. Moreover, the con-
vergence rate is a constant term plus a term in
the order of 1/
√"
INFORMAL KEY THEORETICAL FINDINGS,0.07379375591296121,"M (see ∆1 in Figure 3), indi-
cating a faster convergence with more unlabeled
data."
INFORMAL KEY THEORETICAL FINDINGS,0.07473982970671712,Published as a conference paper at ICLR 2022
INFORMAL KEY THEORETICAL FINDINGS,0.07568590350047304,"2. Returning a model with guaranteed generalization in the low labeled-data regime. Even
when the number of labeled data is much less than the required sample complexity to obtain W ∗
in supervised learning, we prove that with the help of unlabeled data, the iterative self-training can
return a model in the neighborhood of W [ˆλ], where W [ˆλ] is in the line segment of W (0) (ˆλ = 0)
and ground truth W ∗(ˆλ = 1). Moreover, ˆλ is upper bounded by
p"
INFORMAL KEY THEORETICAL FINDINGS,0.07663197729422895,"N/N ∗. Thus W (L) moves
closer to W ∗as N increases (E0 in Figure 3), indicating a better generalization performance with
more labeled data."
INFORMAL KEY THEORETICAL FINDINGS,0.07757805108798486,3. Guaranteed generalization improvement by unlabeled data. The distance between W (L)
INFORMAL KEY THEORETICAL FINDINGS,0.07852412488174078,"and W [ˆλ] (E1 in Figure 3) scales in the order of 1/
√"
INFORMAL KEY THEORETICAL FINDINGS,0.07947019867549669,"M. With a larger number of unlabeled data
M, W (L) moves closer to W [ˆλ] and thus W ∗, indicating an improved generalization performance
(Theorem 1). When N is close to N ∗but still smaller as deﬁned in (12), both W (L) and W [ˆλ]
converge to W ∗, and thus the learned model achieves zero generalization error (Theorem 2)."
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.0804162724692526,"3.2
FORMAL THEORY IN LOW LABELED-DATA REGIME"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.08136234626300852,"Takeaways of Theorem 1: Theorem 1 characterizes the convergence rate of the proposed algorithm
and the accuracy of the learned model W (L) in a low labeled-data regime. Speciﬁcally, the iterates
converge linearly, and the learned model is close to W [ˆλ] and guaranteed to outperform the initial
model W (0).
Theorem 1. Suppose the initialization W (0) and the number of labeled data satisfy"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.08230842005676443,"∥W (0) −W ∗∥F ≤p−1 ·
∥W ∗∥F
c(κ)µ2K3/2
with
p ∈
 1"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.08325449385052035,"2, 1

,
(6)"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.08420056764427625,"and
max
n 1"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.08514664143803216,"K , p −2p −1 µ
√ K"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.08609271523178808,"o2
· N ∗≤N ≤N ∗.
(7)"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.08703878902554399,If the value of ˆλ in (5) and unlabeled data amount M satisfy
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.0879848628192999,"max
n 1"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.08893093661305582,"K , p −2p −1 µ
√ K"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.08987701040681173,"o
≤ˆλ ≤min
nr"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.09082308420056764,"N
N ∗, p + 2p −1 µ
√ K"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.09176915799432356,"o
,
(8)"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.09271523178807947,"and
M ≥(2p −1)−2c(κ)µ2 
1 −ˆλ
2K3d log q.
(9)
Then, when the number T of SGD iterations is large enough in each loop ℓ, with probability at least
1 −q−d, the iterates {W (ℓ)}L
ℓ=0 converge to W [ˆλ] as"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.09366130558183539,"∥W (L) −W [ˆλ]∥F ≤

1 + Θ
  µ(1−ˆλ)
√"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.0946073793755913,"M

· ˆλ
L
· ∥W (0) −W [ˆλ]∥2 +

1 + Θ
  µ(1−ˆλ)
√"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.09555345316934721,"M

· ∥W ∗−W [ˆλ]∥F ,"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.09649952696310313,"(10)
where W [ˆλ] = ˆλW ∗+ (1 −ˆλ)W (0). Typically, when the iteration number L is sufﬁcient large, we
have"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.09744560075685904,"∥W (L) −W ∗∥F ≤

1 + Θ
 µ(1 −ˆλ)
√ M"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.09839167455061495,"
· 2(1 −ˆλ) · ∥W ∗−W (0)∥F .
(11)"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.09933774834437085,"The accuracy of the learned model W (L) with respect to W ∗is characterized as (10), and the
learning model is better than initial model as in (11) if the following conditions hold. First, the
weights λ in (1) are properly chosen as in (8). Second, the number of unlabeled data is sufﬁciently
large as in (9)."
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.10028382213812677,"Selection of λ in self-training algorithms. When ˆλ increases, the required number of unlabeled
data is reduced from (9), and the convergence point W (L) becomes closer to W ∗from (11), which
indicates a smaller generalization error. Thus, a large ˆλ within its feasible range (8) is desirable.
When the initial model W (0) is closer to W ∗(corresponding to a larger p), and the number of
labeled data N increases, the upper bound in (8) increases, and thus, one can select a larger ˆλ."
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.10122989593188268,"The initial model W (0). The tensor initialization from (Zhong et al., 2017) can return a W (0) that
satisﬁes (6) when the number of labeled data is N = p2N ∗(see Lemma 3 in Appendix). Combining
with the requirement in (7), Theorem 1 applies to the case that N is at least N ∗/4."
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.1021759697256386,Published as a conference paper at ICLR 2022
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.10312204351939451,"3.3
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.10406811731315042,"Takeaways of Theorem 2: Theorem 2 indicates the model returned by the proposed algorithm con-
verges linearly to the ground truth W ∗. Thus the distance between the learned model and the ground
truth can be arbitrarily small with the ability to achieve zero generalization error. The required sam-
ple complexity is reduced by a constant factor compared with supervised learning.
Theorem 2. Consider the number of unlabeled data satisﬁes
 
1 −1/(µ
√"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.10501419110690634,"K)
2 · N ∗≤N ≤N ∗,
(12)"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.10596026490066225,"we choose ˆλ such that
1 −1/(µ
√"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.10690633869441817,"K) ≤ˆλ ≤
p"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.10785241248817408,"N/N ∗.
(13)"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.10879848628192999,Suppose the initial model W (0) and the number of unlabeled data M satisfy
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.1097445600756859,"∥W (0) −W ∗∥F ≤
∥W ∗∥F
c(κ)µ2K3/2
and
M ≥c(κ)µ2(1 −ˆλ)2K3d log q,
(14)"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.11069063386944182,"the iterates {W (ℓ)}L
ℓ=0 converge to the ground truth W ∗as follows,"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.11163670766319773,"∥W (L) −W ∗∥F ≤
h 
1 + c(κ)ˆλ
√"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.11258278145695365,"N
+ c(κ)(1 −ˆλ)
√ M"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.11352885525070956,"
· µ
√"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.11447492904446546,"K(1 −ˆλ)
iL
· ∥W (0) −W ∗∥F .
(15)"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.11542100283822138,"The models W (ℓ)’s converge linearly to the ground truth W ∗as (15) when the number of labeled
data satisﬁes (12). In contrast, supervised learning requires at least N ∗labeled samples to estimate
W ∗accurately without unlabeled data, which suggests self-training at least saves a constant fraction
of labeled data."
THE MAIN PROOF IDEA,0.11636707663197729,"3.4
THE MAIN PROOF IDEA"
THE MAIN PROOF IDEA,0.1173131504257332,"Our proof builds upon and extends one recent line of works on supervised learning such as (Zhong
et al., 2017; Zhang et al., 2020b;c; 2021). The standard framework of these works is ﬁrst to show
that the generalization function I(g(W )) in (3) is locally convex near W ∗, which is its global
minimizer. Then, when M = 0 and N is sufﬁciently large, the empirical risk function using labeled
data only can approximate I(g(W )) well in the neighborhood of W ∗. Thus, if initialized in this
local convex region, the iterations, returned by applying gradient descent approach on the empirical
risk function, converge to W ∗linearly."
THE MAIN PROOF IDEA,0.11825922421948912,"The technical challenge here is that in self-training, when unlabeled data are paired with pseudo
labels, W ∗is no longer a global minimizer of the empirical risk ˆfD, e
D in (1), and ˆfD, e
D does not
approach I(g(W )) even when M and N increase to inﬁnity. Our new idea is to design a population
risk function f(W ; ˆλ) in (17) (see appendix), which is a lower bound of ˆfD, e
D when M and N are"
THE MAIN PROOF IDEA,0.11920529801324503,"inﬁnity. f(W ; ˆλ) is locally convex around its minimizer W [ˆλ], and W [ˆλ] approaches W ∗as ˆλ
increases. Then we show the iterates generated by ˆfD, e
D stay close to f(W ; ˆλ), and the returned"
THE MAIN PROOF IDEA,0.12015137180700095,"model W (L) is close to W [ˆλ]. New technical tools are developed to bound the distance between the
functions ˆfD, e
D and f(W ; ˆλ)."
EMPIRICAL RESULTS,0.12109744560075686,"4
EMPIRICAL RESULTS"
SYNTHETIC DATA EXPERIMENTS,0.12204351939451277,"4.1
SYNTHETIC DATA EXPERIMENTS"
SYNTHETIC DATA EXPERIMENTS,0.12298959318826869,"We generate a ground-truth neural network with the width K = 10. Each entry of W ∗is uniformly
selected from [−2.5, 2.5]. The input of labeled data xn are generated from Gaussian distribution
N(0, Id) independently, and the corresponding label yn is generated through (2) using W ∗. The
unlabeled data exm are generated from N(0, eδ2Id) independently with eδ = 1 except in Figure 7.
d is set as 50 except in Figure 9. The value of λ is selected as
p"
SYNTHETIC DATA EXPERIMENTS,0.1239356669820246,"N/(2Kd) except in Figure 8.
We consider one-hidden-layer except in Figure 4. The initial teacher model W (0) in self-training
is randomly selected from {W |∥W −W ∗∥F /∥W ∗∥F ≤0.5} to reduce the computation. In"
SYNTHETIC DATA EXPERIMENTS,0.12488174077578051,Published as a conference paper at ICLR 2022
SYNTHETIC DATA EXPERIMENTS,0.12582781456953643,"each iteration, the maximum number of SGD steps T is 10. Self-training terminates if ∥W (ℓ+1) −
W (ℓ)∥F /∥W (ℓ)∥F ≤10−4 or reaching 1000 iterations. In Figures 5 to 8, all the points on the
curves are averaged over 1000 independent trials, and the regions in lower transparency indicate
the corresponding one-standard-deviation error bars. Our empirical observations are summarized
below."
SYNTHETIC DATA EXPERIMENTS,0.12677388836329234,"(a) GF (testing performance) proportional to ∥W −W ∗∥F . Figure 4 illustrates the GF in (3)
against the distance to the ground truth W ∗. To visualize results for different networks together,
GF is normalized in [0, 1], divided by its largest value for each network architecture. All the results
are averaged over 100 independent choice of W . One can see that for one-hidden-layer neural
networks, in a large region near W ∗, GF is almost linear in ∥W −W ∗∥F . When the number of
hidden layers increases, this region decreases, but the linear dependence still holds locally. This is
an empirical justiﬁcation of using ∥W −W ∗∥F to evaluate the GF and, thus, the testing error in
Theorems 1 and 2."
SYNTHETIC DATA EXPERIMENTS,0.12771996215704826,"(b) ∥W (L) −W ∗∥F as a linear function of 1/
√"
SYNTHETIC DATA EXPERIMENTS,0.12866603595080417,"M. Figure 5 shows the relative error ∥W (L) −
W ∗∥F /∥W ∗∥F when the number of unlabeled data and labeled data changes. One can see that the
relative error decreases when either M or N increases. Additionally, the dash-dotted lines represent
the best ﬁtting of the linear functions of 1/
√"
SYNTHETIC DATA EXPERIMENTS,0.12961210974456008,"M using the least square method. Therefore, the relative
error is indeed a linear function of 1/
√"
SYNTHETIC DATA EXPERIMENTS,0.130558183538316,"M, as predicted by our results in (11) and (15)."
SYNTHETIC DATA EXPERIMENTS,0.1315042573320719,"0
0.1
0.2
0.3
0.4
0.5
0 0.2 0.4 0.6 0.8 1"
-HIDDEN-LAYER,0.13245033112582782,"1-hidden-layer
5-hidden-layer
10-hidden-layer
50-hidden-layer"
-HIDDEN-LAYER,0.13339640491958374,"Figure 4:
The generalization
function against the distance to
the ground truth neural network"
-HIDDEN-LAYER,0.13434247871333965,"200
400
600
800
1000
Number of unlabeled data (M) 3 3.5 4 4.3"
-HIDDEN-LAYER,0.13528855250709557,Relative error (%)
-HIDDEN-LAYER,0.13623462630085148,"Figure 5:
The relative error
against the number of unlabeled
data."
-HIDDEN-LAYER,0.13718070009460737,"0.018
0.0175
0.017
0.0165
0.9993"
-HIDDEN-LAYER,0.13812677388836328,0.99935
-HIDDEN-LAYER,0.1390728476821192,0.9994
-HIDDEN-LAYER,0.1400189214758751,0.99945
-HIDDEN-LAYER,0.14096499526963102,0.9995
-HIDDEN-LAYER,0.14191106906338694,0.99955
-HIDDEN-LAYER,0.14285714285714285,Convergence rate
-HIDDEN-LAYER,0.14380321665089876,"N = 250
N = 300
N = 350"
-HIDDEN-LAYER,0.14474929044465468,"Figure 6: The convergence rate
with different M when N
<
N ∗."
-HIDDEN-LAYER,0.1456953642384106,"(c) Convergence rate as a linear function of 1/
√"
-HIDDEN-LAYER,0.1466414380321665,"M. Figure 6 illustrates the convergence rate
when M and N change. We can see that the convergence rate is a linear function of 1/
√"
-HIDDEN-LAYER,0.14758751182592242,"M, as
predicted by our results (11) and (15). When M increases, the convergence rate is improved, and
the method converges faster."
-HIDDEN-LAYER,0.14853358561967833,"(d) Increase of eδ slows down convergence. Figure 7 shows that the convergence rate becomes
worse when the variance of the unlabeled data eδ increases from 1. When eδ is less than 1, the
convergence rate almost remains the same, which is consistent with our characterization in (10) that
the convergence rate is linear in µ. From the discussion after (5), µ increases as eδ increases from 1
and stays constant when eδ is less than 1."
-HIDDEN-LAYER,0.14947965941343425,"(e) ∥W (L)−W ∗∥F /∥W ∗∥F is improved as a linear function of ˆλ. Figure 8 shows that the relative
errors of W (L) with respect to W ∗decrease almost linearly when ˆλ increases, which is consistent
with the theoretical result in (11). Moreover, when λ exceeds a certain threshold positively correlated
with N, the relative error increases rather than decreases. That is consistent with the analysis in (8)
that ˆλ has an upper limit, and such a limit increases as N increases."
-HIDDEN-LAYER,0.15042573320719016,"(f) Unlabeled data reduce the sample complexity to learn W ∗. Figure 9 depicts the phase tran-
sition of returning W (L). For every pair of d and N, we construct 100 independent trials, and each
trial is said to be successful if ∥W (L) −W ∗∥F /∥W ∗∥F ≤10−2. The white blocks correspond to
the successful trials, while the block in black indicates all failures. When d increases, the required
number of labeled data to learn W ∗is linear in d. Thus, the sample complexity bound in (12) is
order-wise optimal for d. Moreover, the phase transition line when M = 1000 is below the one
when M = 0. Therefore, with unlabeled data, the required sample complexity of N is reduced."
-HIDDEN-LAYER,0.15137180700094607,Published as a conference paper at ICLR 2022
-HIDDEN-LAYER,0.152317880794702,"1
2
3
4
5 0.99 0.995 1"
-HIDDEN-LAYER,0.1532639545884579,Convergence rate
-HIDDEN-LAYER,0.15421002838221382,"Figure 7: Convergence rate
with different ˆδ."
-HIDDEN-LAYER,0.15515610217596973,"0.1
0.2
0.3
0.4
0.5
5.3 5.7 6.1 6.5 6.9"
-HIDDEN-LAYER,0.15610217596972564,Relative error (%)
-HIDDEN-LAYER,0.15704824976348156,"N=200
N=240
N=280"
-HIDDEN-LAYER,0.15799432355723747,"Figure
8:
∥W (L)−W ∗∥F"
-HIDDEN-LAYER,0.15894039735099338,"∥W ∗∥F
when ˆλ and N change."
-HIDDEN-LAYER,0.1598864711447493,"20 26 32 38 44 50
200
260
320
380
440
500
560
620
680"
-HIDDEN-LAYER,0.1608325449385052,"20 26 32 38 44 50
200
260
320
380
440
500
560
620
680"
-HIDDEN-LAYER,0.16177861873226113,"Figure 9: Empirical phase transition of
the curves with (a) M = 0 and (b) M =
1000."
-HIDDEN-LAYER,0.16272469252601704,"4.2
IMAGE CLASSIFICATION ON AUGMENTED CIFAR-10 DATASET"
-HIDDEN-LAYER,0.16367076631977295,"We evaluate self-training on the augmented CIFAR-10 dataset, which has 50K labeled data. The
unlabeled data are mined from 80 Million Tiny Images following the setup in (Carmon et al., 2019)4,
and additional 50K images are selected for each class, which is a total of 500K images, to form the
unlabeled data. The self-training method is the same implementation as that in (Carmon et al., 2019).
λ and eλ is selected as N/(M + N) and M/(N + M), respectively, and the algorithm stops after
200 epochs. In Figure 10, the dash lines stand for the best ﬁtting of the linear functions of 1/
√"
-HIDDEN-LAYER,0.16461684011352887,"M
via the least square method. One can see that the test accuracy is improved by up to 7% using
unlabeled data, and the empirical evaluations match the theoretical predictions. Figure 11 shows the
convergence rate calculated based on the ﬁrst 50 epochs, and the convergence rate is almost a linear
function of 1/
√"
-HIDDEN-LAYER,0.16556291390728478,"M, as predicted by (10)."
-HIDDEN-LAYER,0.1665089877010407,"0
100K
200K
300K
400K
500K
Number of unlabeled data (M) 80 85 90"
-HIDDEN-LAYER,0.16745506149479658,Test accuracy (%)
-HIDDEN-LAYER,0.1684011352885525,"Figure 10:
The test accuracy against the
number of unlabeled data"
-HIDDEN-LAYER,0.1693472090823084,"5
6
7
8
9
10 10-3 0.952 0.954 0.956 0.958 0.96 0.962"
-HIDDEN-LAYER,0.17029328287606432,Convergence rate
-HIDDEN-LAYER,0.17123935666982024,"N=15K
N=30K
N=50K"
-HIDDEN-LAYER,0.17218543046357615,"Figure 11: The convergence rate against the
number of unlabeled data"
CONCLUSION,0.17313150425733206,"5
CONCLUSION"
CONCLUSION,0.17407757805108798,"This paper provides new theoretical insights into understanding the inﬂuence of unlabeled data in
the iterative self-training algorithm. We show that the improved generalization error and conver-
gence rate is a linear function of 1/
√"
CONCLUSION,0.1750236518448439,"M, where M is the number of unlabeled data. Moreover,
compared with supervised learning, using unlabeled data reduces the required sample complexity of
labeled data for achieving zero generalization error. Future directions include generalizing the anal-
ysis to multi-layer neural networks and other semi-supervised learning problems such as domain
adaptation."
CONCLUSION,0.1759697256385998,ACKNOWLEDGEMENT
CONCLUSION,0.17691579943235572,"This work was supported by AFOSR FA9550-20-1-0122, ARO W911NF-21-1-0255, NSF 1932196
and the Rensselaer-IBM AI Research Collaboration (http://airc.rpi.edu), part of the IBM AI Hori-
zons Network (http://ibm.biz/AIHorizons)."
CONCLUSION,0.17786187322611163,4The codes are downloaded from https://github.com/yaircarmon/semisup-adv
CONCLUSION,0.17880794701986755,Published as a conference paper at ICLR 2022
REFERENCES,0.17975402081362346,REFERENCES
REFERENCES,0.18070009460737937,"Zeyuan Allen-Zhu, Yuanzhi Li, and Yingyu Liang. Learning and generalization in overparameter-
ized neural networks, going beyond two layers. In Advances in neural information processing
systems, pp. 6158–6169, 2019."
REFERENCES,0.1816461684011353,"Sanjeev Arora, Simon Du, Wei Hu, Zhiyuan Li, and Ruosong Wang. Fine-grained analysis of op-
timization and generalization for overparameterized two-layer neural networks. In International
Conference on Machine Learning, pp. 322–332. PMLR, 2019a."
REFERENCES,0.1825922421948912,"Sanjeev Arora, Simon S Du, Wei Hu, Zhiyuan Li, and Ruosong Wang. Fine-grained analysis of
optimization and generalization for overparameterized two-layer neural networks. In 36th In-
ternational Conference on Machine Learning, ICML 2019, pp. 477–502. International Machine
Learning Society (IMLS), 2019b."
REFERENCES,0.18353831598864712,"Philip Bachman, Ouais Alsharif, and Doina Precup. Learning with pseudo-ensembles. Advances in
neural information processing systems, 2014."
REFERENCES,0.18448438978240303,"Ainesh Bakshi, Rajesh Jayaram, and David P Woodruff. Learning two layer rectiﬁed neural networks
in polynomial time. In Conference on Learning Theory, pp. 195–268. PMLR, 2019."
REFERENCES,0.18543046357615894,"Maria-Florina Balcan and Avrim Blum. A discriminative model for semi-supervised learning. Jour-
nal of the ACM (JACM), 57(3):1–46, 2010."
REFERENCES,0.18637653736991486,"Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and
structural results. Journal of Machine Learning Research, 3(Nov):463–482, 2002."
REFERENCES,0.18732261116367077,"David Berthelot, Nicholas Carlini, Ekin D Cubuk, Alex Kurakin, Kihyuk Sohn, Han Zhang, and
Colin Raffel. Remixmatch: Semi-supervised learning with distribution matching and augmenta-
tion anchoring. In International Conference on Learning Representations, 2019a."
REFERENCES,0.18826868495742669,"David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, and Colin
Raffel.
Mixmatch:
A holistic approach to semi-supervised learning.
arXiv preprint
arXiv:1905.02249, 2019b."
REFERENCES,0.1892147587511826,"Rajendra Bhatia. Matrix analysis, volume 169. Springer Science & Business Media, 2013."
REFERENCES,0.1901608325449385,"Avrim L Blum and Ronald L Rivest. Training a 3-node neural network is np-complete. Neural
Networks, 5(1):117–127, 1992."
REFERENCES,0.19110690633869443,"Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman, Dilip Krishnan, and Dumitru Erhan.
Domain separation networks. In Proceedings of the 30th International Conference on Neural
Information Processing Systems, pp. 343–351, 2016."
REFERENCES,0.19205298013245034,"Alon Brutzkus and Amir Globerson. Globally optimal gradient descent for a convnet with gaussian
inputs. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp.
605–614. JMLR. org, 2017."
REFERENCES,0.19299905392620625,"Alon Brutzkus, Amir Globerson, Eran Malach, and Shai Shalev-Shwartz.
Sgd learns over-
parameterized networks that provably generalize on linearly separable data.
In International
Conference on Learning Representations, 2018."
REFERENCES,0.19394512771996217,"Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, John C Duchi, and Percy S Liang. Unlabeled
data improves adversarial robustness. Advances in Neural Information Processing Systems, 32:
11192–11203, 2019."
REFERENCES,0.19489120151371808,"Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey E Hinton. Big
self-supervised models are strong semi-supervised learners.
Advances in Neural Information
Processing Systems, 33:22243–22255, 2020a."
REFERENCES,0.195837275307474,"Yining Chen, Colin Wei, Ananya Kumar, and Tengyu Ma.
Self-training avoids using spurious
features under domain shift. Advances in Neural Information Processing Systems, 33, 2020b."
REFERENCES,0.1967833491012299,Published as a conference paper at ICLR 2022
REFERENCES,0.1977294228949858,"Simon S Du, Xiyu Zhai, Barnabas Poczos, and Aarti Singh. Gradient descent provably optimizes
over-parameterized neural networks. In International Conference on Learning Representations,
2018."
REFERENCES,0.1986754966887417,"Geoffrey French, Michal Mackiewicz, and Mark Fisher. Self-ensembling for visual domain adapta-
tion. In International Conference on Learning Representations, number 6, 2018."
REFERENCES,0.19962157048249762,"Haoyu Fu, Yuejie Chi, and Yingbin Liang. Guaranteed recovery of one-hidden-layer neural networks
via cross entropy. IEEE Transactions on Signal Processing, 68:3225–3235, 2020."
REFERENCES,0.20056764427625354,"Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In
International conference on machine learning, pp. 1180–1189. PMLR, 2015."
REFERENCES,0.20151371807000945,"Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, François
Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural net-
works. The journal of machine learning research, 17(1):2096–2030, 2016."
REFERENCES,0.20245979186376536,"Rong Ge, Jason D. Lee, and Tengyu Ma. Learning one-hidden-layer neural networks with land-
scape design. In International Conference on Learning Representations, 2018. URL https:
//openreview.net/forum?id=BkwHObbRZ."
REFERENCES,0.20340586565752128,"Boqing Gong, Kristen Grauman, and Fei Sha. Connecting the dots with landmarks: Discrimina-
tively learning domain-invariant features for unsupervised domain adaptation. In International
Conference on Machine Learning, pp. 222–230. PMLR, 2013."
REFERENCES,0.2043519394512772,"Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In Con-
ference d’apprentissage CAp, pp. 281, 2005."
REFERENCES,0.2052980132450331,"Jiangfan Han, Ping Luo, and Xiaogang Wang. Deep self-learning from noisy labels. In Proceedings
of the IEEE/CVF International Conference on Computer Vision, pp. 5138–5147, 2019."
REFERENCES,0.20624408703878902,"Junxian He, Jiatao Gu, Jiajun Shen, and Marc’Aurelio Ranzato. Revisiting self-training for neural
sequence generation. In International Conference on Learning Representations, 2019."
REFERENCES,0.20719016083254493,"Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by
reducing internal covariate shift. volume 37 of Proceedings of Machine Learning Research, pp.
448–456, Lille, France, 07–09 Jul 2015. PMLR."
REFERENCES,0.20813623462630085,"Arthur Jacot, Franck Gabriel, and Clément Hongler. Neural tangent kernel: Convergence and gen-
eralization in neural networks. In Proceedings of the 32nd International Conference on Neural
Information Processing Systems, 2018."
REFERENCES,0.20908230842005676,"Jacob Kahn, Ann Lee, and Awni Hannun.
Self-training for end-to-end speech recognition.
In
ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing
(ICASSP), pp. 7084–7088. IEEE, 2020."
REFERENCES,0.21002838221381268,"Adam Tauman Kalai, Adam R Klivans, Yishay Mansour, and Rocco A Servedio. Agnostically
learning halfspaces. SIAM Journal on Computing, 37(6):1777–1805, 2008."
REFERENCES,0.2109744560075686,"Volodymyr Kuleshov, Arun Chaganty, and Percy Liang. Tensor factorization via matrix factoriza-
tion. In Artiﬁcial Intelligence and Statistics, pp. 507–516, 2015."
REFERENCES,0.2119205298013245,"Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning. arXiv preprint
arXiv:1610.02242, 2016."
REFERENCES,0.21286660359508042,"Yann A LeCun, Léon Bottou, Genevieve B Orr, and Klaus-Robert Müller. Efﬁcient backprop. In
Neural networks: Tricks of the trade, pp. 9–48. Springer, 2012."
REFERENCES,0.21381267738883633,"Dong-Hyun Lee et al. Pseudo-label: The simple and efﬁcient semi-supervised learning method for
deep neural networks. In Workshop on challenges in representation learning, ICML, volume 3,
2013."
REFERENCES,0.21475875118259224,"Jaehoon Lee, Yasaman Bahri, Roman Novak, Samuel S Schoenholz, Jeffrey Pennington, and Jascha
Sohl-Dickstein. Deep neural networks as gaussian processes. In International Conference on
Learning Representations, 2018."
REFERENCES,0.21570482497634816,Published as a conference paper at ICLR 2022
REFERENCES,0.21665089877010407,"Kibok Lee, Kimin Lee, Jinwoo Shin, and Honglak Lee. Overcoming catastrophic forgetting with un-
labeled data in the wild. In Proceedings of the IEEE/CVF International Conference on Computer
Vision, pp. 312–321, 2019."
REFERENCES,0.21759697256385999,"Yuanzhi Li and Yingyu Liang. Learning overparameterized neural networks via stochastic gradient
descent on structured data. In Advances in Neural Information Processing Systems, pp. 8157–
8166, 2018."
REFERENCES,0.2185430463576159,"Yuanzhi Li and Yang Yuan. Convergence analysis of two-layer neural networks with ReLU activa-
tion. In Advances in Neural Information Processing Systems, pp. 597–607. 2017."
REFERENCES,0.2194891201513718,"Joerg Liebelt and Cordelia Schmid. Multi-view object class detection with a 3d geometric model.
In 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp.
1688–1695. IEEE, 2010."
REFERENCES,0.22043519394512773,"Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features with
deep adaptation networks. In International conference on machine learning, pp. 97–105. PMLR,
2015."
REFERENCES,0.22138126773888364,"Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial training: a
regularization method for supervised and semi-supervised learning. IEEE transactions on pattern
analysis and machine intelligence, 41(8):1979–1993, 2018."
REFERENCES,0.22232734153263956,"Luca Oneto, Davide Anguita, Alessandro Ghio, and Sandro Ridella. The impact of unlabeled pat-
terns in rademacher complexity theory for kernel classiﬁers. Advances in neural information
processing systems, 24:585–593, 2011."
REFERENCES,0.22327341532639547,"Samet Oymak and Talha Cihad Gulcu.
Statistical and algorithmic insights for semi-supervised
learning with self-training. arXiv preprint arXiv:2006.11006, 2020."
REFERENCES,0.22421948912015138,"Samet Oymak and Mahdi Soltanolkotabi. End-to-end learning of a convolutional neural network via
deep tensor decomposition. arXiv preprint arXiv: 1805.06523, 2018."
REFERENCES,0.2251655629139073,"Aditi Raghunathan, Sang Michael Xie, Fanny Yang, John Duchi, and Percy Liang. Understanding
and mitigating the tradeoff between robustness and accuracy. In International Conference on
Machine Learning, pp. 7909–7919. PMLR, 2020."
REFERENCES,0.2261116367076632,"Scott E Reed, Honglak Lee, Dragomir Anguelov, Christian Szegedy, Dumitru Erhan, and Andrew
Rabinovich. Training deep neural networks on noisy labels with bootstrapping. In ICLR (Work-
shop), 2015."
REFERENCES,0.22705771050141912,"Philippe Rigollet. Generalization error bounds in semi-supervised classiﬁcation under the cluster
assumption. Journal of Machine Learning Research, 8(7), 2007."
REFERENCES,0.228003784295175,"Chuck Rosenberg, Martial Hebert, and Henry Schneiderman. Semi-supervised self-training of object
detection models. In Proceedings of the Seventh IEEE Workshops on Application of Computer
Vision (WACV/MOTION’05)-Volume 1-Volume 01, pp. 29–36, 2005."
REFERENCES,0.22894985808893092,"Itay Safran and Ohad Shamir. Spurious local minima are common in two-layer relu neural networks.
In International Conference on Machine Learning, pp. 4430–4438, 2018."
REFERENCES,0.22989593188268684,"Mehdi Sajjadi, Mehran Javanmardi, and Tolga Tasdizen. Regularization with stochastic transfor-
mations and perturbations for deep semi-supervised learning. Advances in neural information
processing systems, 29:1163–1171, 2016."
REFERENCES,0.23084200567644275,"Henry Scudder. Probability of error of some adaptive pattern-recognition machines. IEEE Transac-
tions on Information Theory, 11(3):363–371, 1965."
REFERENCES,0.23178807947019867,"Aarti Singh, Robert Nowak, and Jerry Zhu. Unlabeled data: Now it helps, now it doesn’t. Advances
in neural information processing systems, 21:1513–1520, 2008."
REFERENCES,0.23273415326395458,"Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao Zhang, Han Zhang, Colin A Raffel,
Ekin Dogus Cubuk, Alexey Kurakin, and Chun-Liang Li. Fixmatch: Simplifying semi-supervised
learning with consistency and conﬁdence. Advances in Neural Information Processing Systems,
33, 2020."
REFERENCES,0.2336802270577105,Published as a conference paper at ICLR 2022
REFERENCES,0.2346263008514664,"Mahdi Soltanolkotabi, Adel Javanmard, and Jason D Lee. Theoretical insights into the optimization
landscape of over-parameterized shallow neural networks. IEEE Transactions on Information
Theory, 65(2):742–769, 2018."
REFERENCES,0.23557237464522232,"Jong-Chyi Su, Subhransu Maji, and Bharath Hariharan. When does self-supervision improve few-
shot learning? In European Conference on Computer Vision, pp. 645–666. Springer, 2020."
REFERENCES,0.23651844843897823,"Kevin Tang, Vignesh Ramanathan, Fei-Fei Li, and Daphne Koller.
Shifting weights: Adapting
object detectors from image to video. In Advances in Neural Information Processing Systems, pp.
647–655, 2012."
REFERENCES,0.23746452223273415,"Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consis-
tency targets improve semi-supervised deep learning results. In Proceedings of the 31st Interna-
tional Conference on Neural Information Processing Systems, pp. 1195–1204, 2017."
REFERENCES,0.23841059602649006,"Joel A Tropp. User-friendly tail bounds for sums of random matrices. Foundations of computational
mathematics, 12(4):389–434, 2012."
REFERENCES,0.23935666982024598,"Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and Trevor Darrell. Deep domain confusion:
Maximizing for domain invariance. arXiv preprint arXiv:1412.3474, 2014."
REFERENCES,0.2403027436140019,"David Vazquez, Antonio M Lopez, Javier Marin, Daniel Ponsa, and David Geronimo. Virtual and
real world adaptation for pedestrian detection. IEEE transactions on pattern analysis and machine
intelligence, 36(4):797–809, 2013."
REFERENCES,0.2412488174077578,"Roman Vershynin. Introduction to the non-asymptotic analysis of random matrices. arXiv preprint
arXiv:1011.3027, 2010."
REFERENCES,0.24219489120151372,"Gang Wang, Georgios B Giannakis, and Jie Chen. Learning relu networks on linearly separable
data: Algorithm, optimality, and generalization. IEEE Transactions on Signal Processing, 67(9):
2357–2370, 2019."
REFERENCES,0.24314096499526963,"Colin Wei, Kendrick Shen, Yining Chen, and Tengyu Ma. Theoretical analysis of self-training
with deep networks on unlabeled data. In International Conference on Learning Representations,
2020."
REFERENCES,0.24408703878902555,"Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc V Le. Self-training with noisy student
improves imagenet classiﬁcation. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, pp. 10687–10698, 2020."
REFERENCES,0.24503311258278146,"I Zeki Yalniz, Hervé Jégou, Kan Chen, Manohar Paluri, and Dhruv Mahajan. Billion-scale semi-
supervised learning for image classiﬁcation. arXiv preprint arXiv:1905.00546, 2019."
REFERENCES,0.24597918637653737,"David Yarowsky. Unsupervised word sense disambiguation rivaling supervised methods. In 33rd
annual meeting of the association for computational linguistics, pp. 189–196, 1995."
REFERENCES,0.2469252601702933,"Kun Zhang, Bernhard Schölkopf, Krikamol Muandet, and Zhikun Wang. Domain adaptation under
target and conditional shift. In International Conference on Machine Learning, pp. 819–827.
PMLR, 2013."
REFERENCES,0.2478713339640492,"Shuai Zhang, Meng Wang, Sijia Liu, Pin-Yu Chen, and Jinjun Xiong. Guaranteed convergence
of training convolutional neural networks via accelerated gradient descent. In 2020 54th An-
nual Conference on Information Sciences and Systems (CISS), 2020a. URL doi:10.1109/
CISS48834.2020.1570627111."
REFERENCES,0.24881740775780511,"Shuai Zhang, Meng Wang, Sijia Liu, Pin-Yu Chen, and Jinjun Xiong. Fast learning of graph neural
networks with guaranteed generalizability:one-hidden-layer case. In 2020 International Confer-
ence on Machine Learning (ICML), 2020b."
REFERENCES,0.24976348155156103,"Shuai Zhang, Meng Wang, Jinjun Xiong, Sijia Liu, and Pin-Yu Chen. Improved linear convergence
of training cnns with generalizability guarantees: A one-hidden-layer case. IEEE Transactions
on Neural Networks and Learning Systems, 32(6):2622–2635, 2020c."
REFERENCES,0.2507095553453169,Published as a conference paper at ICLR 2022
REFERENCES,0.25165562913907286,"Shuai Zhang, Meng Wang, Sijia Liu, Pin-Yu Chen, and Jinjun Xiong. Why lottery ticket wins? a the-
oretical perspective of sample complexity on pruned neural networks. In Thirty-ﬁfth Conference
on Neural Information Processing Systems (NeurIPS), 2021."
REFERENCES,0.25260170293282874,"Xiao Zhang, Yaodong Yu, Lingxiao Wang, and Quanquan Gu.
Learning one-hidden-layer relu
networks via gradient descent. In The 22nd International Conference on Artiﬁcial Intelligence
and Statistics, pp. 1524–1534. PMLR, 2019."
REFERENCES,0.2535477767265847,"Yuchen Zhang, Jason D. Lee, and Michael I. Jordan. L1-regularized neural networks are improperly
learnable in polynomial time. In Proceedings of The 33rd International Conference on Machine
Learning, volume 48, pp. 993–1001, 2016."
REFERENCES,0.25449385052034057,"Kai Zhong, Zhao Song, Prateek Jain, Peter L Bartlett, and Inderjit S Dhillon. Recovery guaran-
tees for one-hidden-layer neural networks. In Proceedings of the 34th International Conference
on Machine Learning-Volume 70, pp. 4140–4149. JMLR. org, https://arxiv.org/abs/1706.03175,
2017."
REFERENCES,0.2554399243140965,"Barret Zoph, Golnaz Ghiasi, Tsung-Yi Lin, Yin Cui, Hanxiao Liu, Ekin Dogus Cubuk, and Quoc Le.
Rethinking pre-training and self-training. Advances in Neural Information Processing Systems,
33, 2020."
REFERENCES,0.2563859981078524,"Yang Zou, Zhiding Yu, BVK Kumar, and Jinsong Wang. Unsupervised domain adaptation for se-
mantic segmentation via class-balanced self-training. In Proceedings of the European conference
on computer vision (ECCV), pp. 289–305, 2018."
REFERENCES,0.25733207190160834,Published as a conference paper at ICLR 2022
REFERENCES,0.2582781456953642,Appendix
REFERENCES,0.25922421948912017,"A
OVERVIEW OF THE PROOF TECHNIQUES"
REFERENCES,0.26017029328287605,We ﬁrst provide an overview of the techniques used in proving Theorems 1 and 2.
REFERENCES,0.261116367076632,"1. Characterization of a proper population risk function. To characterize the performance of the
iterative self-training algorithm via the stochastic gradient descent method, we need ﬁrst to deﬁne
a population risk function such that the following two properties hold. First, the landscape of the
population risk function should be analyzable near {W (ℓ)}L
ℓ=0. Second, the distance between the
empirical risk function in (1) and the population risk function should be bounded near {W (ℓ)}L
ℓ=0.
The generalization function deﬁned in (3), which is widely used in the supervised learning problem
with a sufﬁcient number of samples, failed the second requirement. To this end, we turn to ﬁnd a
new population risk function deﬁned in (17), and the illustrations of the population risk function and
objection function are included in Figure 12."
REFERENCES,0.2620624408703879,"2. Local convex region of the population risk function. The purpose is to characterize the it-
erations via the stochastic gradient descent method in the population risk function. To obtain the
local convex region of the population risk function, we ﬁrst bound the Hessian of the population risk
function at its global optimal. Then, we utilize Lemma 12 in Appendix H.1 to obtain the Hessian of
the population risk function near the global optimal. The local convex region of the population risk
function is summarized in Lemma 1, and the proof of Lemma 1 is included in Appendix H.1."
REFERENCES,0.2630085146641438,"3. Bound between the population risk and empirical risk functions. After the characterization of
the iterations via the stochastic gradient descent method in the population risk function, we need to
bound the distance between the population risk function and empirical risk function. Therefore, the
behaviors of the iterations via the stochastic gradient descent method in the empirical risk function
can be described by the ones in the population risk function and the distance between these two. The
key lemma is summarized in Lemma 2 (see Appendix H.2), and the proof is included in Appendix
H.2. 𝑾𝑾"
REFERENCES,0.2639545884578997,Local convex region
REFERENCES,0.26490066225165565,"of  ̂𝑓𝑓𝒟𝒟near 𝑾𝑾(0,0)"
REFERENCES,0.26584673604541154,"𝑾𝑾∗
𝑾𝑾(0,2)
𝑾𝑾(0,1)
𝑾𝑾(0,𝑇𝑇)"
REFERENCES,0.2667928098391675,"𝛽𝛽(𝑾𝑾0,1 −𝑾𝑾(0,0))"
REFERENCES,0.26773888363292336,𝜂𝜂𝜂𝜂̂𝑓𝑓𝒟𝒟 . . .
REFERENCES,0.2686849574266793,Population risk function: 𝑓𝑓(𝑾𝑾; 𝑝𝑝)
REFERENCES,0.2696310312204352,Objective function: ̂𝑓𝑓𝒟𝒟(𝑾𝑾)
REFERENCES,0.27057710501419113,𝑾𝑾[𝑝𝑝]
REFERENCES,0.271523178807947,Figure 12: The landscapes of the objection function and population risk function.
REFERENCES,0.27246925260170296,"In the following contexts, the details of the iterative self-training algorithm are included in Appendix
B. We then ﬁrst provide the proof of Theorem 2 in Appendix E, which can be viewed as a special
case of Theorem 1. Then, with the preliminary knowledge from proving Theorem 2, we turn to
present the full proof of a more general statement summarized in Theorem 3 (see Appendix F),
which is related to Theorem 1. The deﬁnition and relative proofs of µ and ρ are all included in
Appendix G. The proofs of preliminary lemmas are included in Appendix H."
REFERENCES,0.27341532639545885,"B
ITERATIVE SELF-TRAINING ALGORITHM"
REFERENCES,0.27436140018921473,"In this section, we implement the details of the mini-batch stochastic gradient descent used in each
stage of the iterative self-training algorithm. After t number of iterations via mini-batch stochastic"
REFERENCES,0.2753074739829707,Published as a conference paper at ICLR 2022
REFERENCES,0.27625354777672656,"gradient descent at ℓ-th stage of self-training algorithm, the learned model is denoted as W (ℓ,t). One
can easily check that W (ℓ) in the main context is denoted as W (ℓ,0) in this section and the following
proofs. Last, the pseudo-code of the iterative self-training algorithm is summarized in Algorithm 1."
REFERENCES,0.2771996215704825,Algorithm 1 Iterative Self-Training Algorithm
REFERENCES,0.2781456953642384,"Input: labeled D = {(xn, yn)}N
n=1, unlabeled data eD = {exm}M
m=1, and gradient step size η;"
REFERENCES,0.27909176915799433,"Initialization: preliminary teacher model with weights W (0,0);"
REFERENCES,0.2800378429517502,"Partition: randomly and independently pick data from D and eD to form T subsets {Dt}T −1
t=0 and
{ eDt}T −1
t=0 , respectively;"
REFERENCES,0.28098391674550616,"for ℓ= 0, 1, · · · , L −1 do"
REFERENCES,0.28192999053926204,"ym = g(W (ℓ,0); exm) for m = 1, 2, · · · , M"
REFERENCES,0.282876064333018,"for t = 0, 1, · · · , T −1 do"
REFERENCES,0.28382213812677387,"W (ℓ,t+1) = W (ℓ,t) −η · ∇ˆfDt, e
Dt(W (ℓ,t)) + β ·
 
W (ℓ,t) −W (ℓ,t−1)"
REFERENCES,0.2847682119205298,end for
REFERENCES,0.2857142857142857,"W (ℓ+1,0) = W (ℓ,T )"
REFERENCES,0.28666035950804164,end for
REFERENCES,0.2876064333017975,"C
NOTATIONS"
REFERENCES,0.28855250709555347,"In this section, we ﬁrst introduce some important notations that will be used in the following proofs,
and the notations are summarized in Table 1."
REFERENCES,0.28949858088930935,"As shown in Algorithm 1, W (ℓ,t) denotes the learned model after t number of iterations via mini-
batch stochastic gradient descent at ℓ-th stage of the iterative self-training algorithm. Given a student
model f
W , the pseudo label for ex ∈eD is generated as"
REFERENCES,0.2904446546830653,"˜y = g(f
W ; ex).
(16)"
REFERENCES,0.2913907284768212,"Further, let W [p] = pW ∗+ (1 −p)W (0,0), we then deﬁne the population risk function as"
REFERENCES,0.2923368022705771,f(W ; p) = λ
EX,0.293282876064333,"2 Ex

y∗(p) −g(W ; x)
2
+
eλ
2 Eex

ey∗(p) −g(W ; ex)
2
,
(17)"
EX,0.29422894985808895,"where y∗(p) = g(W [p]; x) with x ∼N(0, δ2I) and ey∗(p) = g(W [p]; ex) with ex ∼N(0, ˜δ2I).
When p = 1, we have W [p] = W ∗and y∗(p) = y for data in D."
EX,0.29517502365184484,"Moreover, we use σi to denote the i-th largest singular value of W ∗. Then, κ is deﬁned as σ1/σK,
and γ = QK
i=1 σi/σK. Additionally, to avoid high dimensional tensors, the ﬁrst order derivative of
the empirical risk function is deﬁned in the form of vectorized W as"
EX,0.2961210974456008,"∇ˆf(W ) =
h ∂f ∂w1"
EX,0.29706717123935666,"T
, ∂f ∂w2"
EX,0.2980132450331126,"T
, · · · , ∂f ∂wK"
EX,0.2989593188268685,"T iT
∈RdK
(18)"
EX,0.29990539262062443,"with W = [w1, w2, · · · , wK] ∈Rd×K. Therefore, the second order derivative of the empiri-
cal risk function is in Rdk×dk. Similar to (18), the high order derivatives of the population risk
functions are deﬁned based on vectorized W as well. In addition, without special descriptions,
α = [αT
1 , αT
2 , · · · , αT
K]T stands for any unit vector that in RdK with αj ∈Rd. Therefore, we have"
EX,0.3008514664143803,"∥∇2 ˆf∥2 = max
α ∥αT ∇2 ˆfα∥2 = max
α  K
X"
EX,0.30179754020813626,"j=1
αT
j
∂ˆf
∂wj"
EX,0.30274361400189215,"2
.
(19)"
EX,0.30368968779564803,Published as a conference paper at ICLR 2022
EX,0.304635761589404,"Finally, since we focus on order-wise analysis, some constant numbers will be ignored in the major-
ity of the steps. In particular, we use h1(z) ≳(or ≲, ≂)h2(z) to denote there exists some positive
constant C such that h1(z) ≥(or ≤, =)C · h2(z) when z ∈R is sufﬁciently large."
EX,0.30558183538315986,Table 3: Some Important Notations
EX,0.3065279091769158,"D = {xn, yn}N
n=1
Labeled dataset with N number of samples;"
EX,0.3074739829706717,"eD = {exm}M
m=1
Unlabeled dataset with M number of samples;"
EX,0.30842005676442763,"Dt = {xn, yn}Nt
n=1 a subset of D with Nt number of labeled data;"
EX,0.3093661305581835,"eDt = {exm}Mt
m=1
a subset of eD with Mt number of unlabeled data;"
EX,0.31031220435193946,"d
Dimension of the input x or ex;"
EX,0.31125827814569534,"K
Number of neurons in the hidden layer;"
EX,0.3122043519394513,"W ∗
Weights of the ground truth model;"
EX,0.31315042573320717,"W [p]
W [p] = pW ∗+ (1 −p)W (0,0);"
EX,0.3140964995269631,"W (ℓ,t)
Model returned by iterative self-training after t step mini-batch stochastic gradient de-
scent at stage ℓ; W (0,0) is the initial model;
ˆfD, e
D( or ˆf)
The empirical risk function deﬁned in (1);"
EX,0.315042573320719,"f(W ; p)
The population risk function deﬁned in (17);
ˆλ
The value of λδ2/(λδ2 + eλ˜δ2);"
EX,0.31598864711447494,"µ
The value of
λδ2+eλ˜δ2"
EX,0.3169347209082308,λρ(δ)+eλρ(˜δ);
EX,0.31788079470198677,"σi
The i-th largest singular value of W ∗;"
EX,0.31882686849574265,"κ
The value of σ1/σK;"
EX,0.3197729422894986,"γ
The value of QK
i=1 σi/σK;"
EX,0.3207190160832545,"q
Some large constant in R+;"
EX,0.3216650898770104,"D
PRELIMINARY LEMMAS"
EX,0.3226111636707663,"We will ﬁrst start with some preliminary lemmas. As outlined at the beginning of the supplementary
material, Lemma 1 illustrates the local convex region of the population risk function, and Lemma
2 explains the error bound between the population risk and empirical risk functions. Then, Lemma
3 describes the returned initial model W (0,0) via tensor initialization method (Zhong et al., 2017)
purely using labeled data. Next, Lemma 4 is the well known Weyl’s inequality in the matrix setting.
Moreover, Lemma 5 is the concentration theorem for independent random matrices. The deﬁnitions
of the sub-Gaussian and sub-exponential variables are summarized in Deﬁnitions 1 and 2. Lemmas
6 and 7 serve as the technical tools in bounding matrix norms under the framework of the conﬁdence
interval."
EX,0.32355723746452225,"Lemma 1. Given any W ∈Rd×K, let p satisfy"
EX,0.32450331125827814,"p ≲
σK
µ2K · ∥W −W ∗∥F
.
(20)"
EX,0.3254493850520341,"Then, we have"
EX,0.32639545884578997,λρ(δ) + eλρ(˜δ)
EX,0.3273415326395459,"12κ2γK2
⪯∇2f(W ; p) ⪯7(λδ2 + eλ˜δ2)"
EX,0.3282876064333018,"K
.
(21)"
EX,0.32923368022705773,Published as a conference paper at ICLR 2022
EX,0.3301797540208136,"Lemma 2. Let f and ˆf be the functions deﬁned in (17) and (1), respectively. Suppose the pseudo
label is generated through (16) with weights f
W . Then, we have"
EX,0.33112582781456956,∥∇f(W ) −∇ˆf(W )∥2 ≲λδ2 K r
EX,0.33207190160832545,d log q
EX,0.3330179754020814,"N
· ∥W −W ∗∥+
eλ˜δ2 K r"
EX,0.3339640491958373,d log q
EX,0.33491012298959316,"M
· ∥W −f
W ∥2 +"
EX,0.3358561967833491,"λδ2 ·
 f
W −W [p]
+ eλ˜δ2 ·
 
W ∗−W [p]
2
2K (22)"
EX,0.336802270577105,with probability at least 1 −q−d.
EX,0.33774834437086093,"Lemma 3 (Initialization, (Zhong et al., 2017)). Assuming the number of labeled data satisﬁes"
EX,0.3386944181646168,"N ≥p2N ∗
(23)"
EX,0.33964049195837276,for some large constant q and p ∈[ 1
EX,0.34058656575212864,"K , 1], the tensor initialization method, which is summarized in
Appendix I, outputs W (0,0) such that"
EX,0.3415326395458846,"∥W (0,0) −W ∗∥F ≤
σK
p · c(κ)µ2K
(24)"
EX,0.3424787133396405,with probability at least 1 −q−d.
EX,0.3434247871333964,"Lemma 4 (Weyl’s inequality, (Bhatia, 2013)). Let B = A + E be a matrix with dimension m × m.
Let λi(B) and λi(A) be the i-th largest eigenvalues of B and A, respectively. Then, we have"
EX,0.3443708609271523,"|λi(B) −λi(A)| ≤∥E∥2,
∀
i ∈[m].
(25)"
EX,0.34531693472090824,"Lemma 5 ((Tropp, 2012), Theorem 1.6). Consider a ﬁnite sequence {Zk} of independent, random
matrices with dimensions d1 × d2. Assume that such random matrix satisﬁes"
EX,0.34626300851466413,"E(Zk) = 0
and
∥Zk∥≤R
almost surely.
Deﬁne
δ2 := max
n
X"
EX,0.34720908230842007,"k
E(ZkZ∗
k)
,

X"
EX,0.34815515610217596,"k
E(Z∗
kZk)

o
."
EX,0.3491012298959319,"Then for all t ≥0, we have Prob ( X k
Zk ≥t )"
EX,0.3500473036896878,"≤(d1 + d2) exp

−t2/2
δ2 + Rt/3 
."
EX,0.3509933774834437,"Deﬁnition 1 (Deﬁnition 5.7, (Vershynin, 2010)). A random variable X is called a sub-Gaussian
random variable if it satisﬁes
(E|X|p)1/p ≤c1
√p
(26)"
EX,0.3519394512771996,"for all p ≥1 and some constant c1 > 0. In addition, we have"
EX,0.35288552507095555,"Ees(X−EX) ≤ec2∥X∥2
ψ2s2
(27)"
EX,0.35383159886471144,"for all s ∈R and some constant c2 > 0, where ∥X∥φ2 is the sub-Gaussian norm of X deﬁned as
∥X∥ψ2 = supp≥1 p−1/2(E|X|p)1/p."
EX,0.3547776726584674,"Moreover, a random vector X ∈Rd belongs to the sub-Gaussian distribution if one-dimensional
marginal αT X is sub-Gaussian for any α ∈Rd, and the sub-Gaussian norm of X is deﬁned as
∥X∥ψ2 = sup∥α∥2=1 ∥αT X∥ψ2."
EX,0.35572374645222327,"Deﬁnition 2 (Deﬁnition 5.13, (Vershynin, 2010)). A random variable X is called a sub-exponential
random variable if it satisﬁes
(E|X|p)1/p ≤c3p
(28)"
EX,0.3566698202459792,"for all p ≥1 and some constant c3 > 0. In addition, we have"
EX,0.3576158940397351,"Ees(X−EX) ≤ec4∥X∥2
ψ1s2
(29)"
EX,0.35856196783349104,"for s ≤1/∥X∥ψ1 and some constant c4 > 0, where ∥X∥ψ1 is the sub-exponential norm of X
deﬁned as ∥X∥ψ1 = supp≥1 p−1(E|X|p)1/p."
EX,0.3595080416272469,Published as a conference paper at ICLR 2022
EX,0.36045411542100286,"Lemma 6 (Lemma 5.2, (Vershynin, 2010)). Let B(0, 1) ∈{α
∥α∥2 = 1, α ∈Rd} denote a
unit ball in Rd. Then, a subset Sξ is called a ξ-net of B(0, 1) if every point z ∈B(0, 1) can be
approximated to within ξ by some point α ∈B(0, 1), i.e., ∥z −α∥2 ≤ξ. Then the minimal
cardinality of a ξ-net Sξ satisﬁes
|Sξ| ≤(1 + 2/ξ)d.
(30)
Lemma 7 (Lemma 5.3, (Vershynin, 2010)). Let A be an d1 × d2 matrix, and let Sξ(d) be a ξ-net
of B(0, 1) in Rd for some ξ ∈(0, 1). Then"
EX,0.36140018921475875,"∥A∥2 ≤(1 −ξ)−1
max
α1∈Sξ(d1),α2∈Sξ(d2) |αT
1 Aα2|.
(31)"
EX,0.3623462630085147,"Lemma 8 (Mean Value Theorem). Let U ⊂Rn1 be open and f : U −→Rn2 be continuously
differentiable, and x ∈U, h ∈Rn1 vectors such that the line segment x + th, 0 ≤t ≤1 remains
in U. Then we have:"
EX,0.3632923368022706,"f(x + h) −f(x) =
Z 1"
EX,0.36423841059602646,"0
∇f(x + th)dt

· h,"
EX,0.3651844843897824,where ∇f denotes the Jacobian matrix of f.
EX,0.3661305581835383,"E
PROOF OF THEOREM 2"
EX,0.36707663197729423,"With p = 1 in (17), the population risk function is reduced as"
EX,0.3680227057710501,f(W ) = λ
EX,0.36896877956480606,"2 Ex(y −g(W ; x)) +
eλ
2 Eex(ey∗−g(W ; ex)),
(32)"
EX,0.36991485335856195,"where y = g(W ∗; x) with x ∼N(0, δ2I) and ey∗= g(W ∗; ex) with ex ∼N(0, ˜δ2I). In fact,
(32) can be viewed as the expectation of the empirical risk function in (1) given eym = g(W ∗; exm).
Moreover, the ground-truth model W ∗is the global optimal to (32) as well. Lemmas 9 and 10
are the special case of Lemmas 1 and 2 with p = 1. The proof of Theorem 2 is followed by the
presentation of the two lemmas."
EX,0.3708609271523179,"The main idea in proving Theorem 2 is to characterize the gradient descent term by the MVT in
Lemma 8 as shown in (36) and (37). The IVT is not directly applied in the empirical risk func-
tion because of its non-smoothness. However, the population risk functions deﬁned in (17) and
(32), which are the expectations over the Gaussian variables, are smooth. Then, as the distance
∥∇f(W ) −∇f(W ∗)∥F is upper bounded by a linear function of ∥W −W ∗∥F as shown in (47),
we can establish the connection between ∥W (ℓ,t+1) −W ∗∥F and ∥W (ℓ,t) −W ∗∥F as shown in
(50). Finally, by mathematical induction over ℓand t, one can characterize ∥W (L,0) −W ∗∥F by
∥W (0,0) −W ∗∥F as shown in (52), which completes the whole proof."
EX,0.3718070009460738,"Lemma 9 (Lemma 1 with p = 1). Let f and ˆf are the functions deﬁned in (32) and (1), respectively.
Then, for any W that satisﬁes,
∥W −W ∗∥F ≤σK"
EX,0.3727530747398297,"µ2K ,
(33)"
EX,0.3736991485335856,"we have
λρ(δ) + eλρ(˜δ)"
EX,0.37464522232734154,"12κ2γK2
⪯∇2f(W ) ⪯7(λδ2 + eλ˜δ2)"
EX,0.37559129612109743,"K
.
(34)"
EX,0.37653736991485337,"Lemma 10 (Lemma 2 with p = 1). Let f and ˆf be the functions deﬁned in (32) and (1), respectively.
Suppose the pseudo label is generated through (16) with weights f
W . Then, we have"
EX,0.37748344370860926,"∥∇f(W ) −∇ˆf(W )∥2 ≲
λδ2 K r"
EX,0.3784295175023652,d log q
EX,0.3793755912961211,"N
+ (1 −λ)˜δ2 K r"
EX,0.380321665089877,d log q M
EX,0.3812677388836329,"
· ∥W −W ∗∥2"
EX,0.38221381267738885,+ (1 −λ)˜δ2 K r
EX,0.38315988647114474,"d log q M
+ 1 2"
EX,0.3841059602649007,"
· ∥f
W −W ∗∥2 (35)"
EX,0.38505203405865657,with probability at least 1 −q−d.
EX,0.3859981078524125,Published as a conference paper at ICLR 2022
EX,0.3869441816461684,"Proof of Theorem 2. From Algorithm 1, in the ℓ-th outer loop, we have"
EX,0.38789025543992434,"W (ℓ,t+1) =W (ℓ,t) −η∇ˆfDt, e
Dt(W (ℓ,t)) + β(W (ℓ,t) −W (ℓ,t−1))"
EX,0.3888363292336802,"=W (ℓ,t) −η∇f(W (ℓ,t)) + β(W (ℓ,t) −W (ℓ,t−1))"
EX,0.38978240302743616,"+ η ·
 
∇f(W (ℓ,t)) −∇ˆfDt, e
Dt(W (ℓ,t))

. (36)"
EX,0.39072847682119205,"Since ∇f is a smooth function and W ∗is a local (global) optimal to f, then we have"
EX,0.391674550614948,"∇f(W (ℓ,t)) =∇f(W (ℓ,t)) −∇f(W ∗) = Z 1"
EX,0.3926206244087039,"0
∇2f

W (ℓ,t) + u · (W (ℓ,t) −W ∗)

du · (W (ℓ,t) −W ∗),
(37)"
EX,0.3935666982024598,"where the last equality comes from MVT in Lemma 8. For notational convenience, we use H(ℓ,t)
to denote the integration as"
EX,0.3945127719962157,"H(ℓ,t) :=
Z 1"
EX,0.3954588457899716,"0
∇2f

W (ℓ,t) + u · (W (ℓ,t) −W ∗)

du.
(38)"
EX,0.39640491958372753,"Then, we have
""
W (ℓ,t+1) −W ∗"
EX,0.3973509933774834,"W (ℓ,t) −W ∗ # ="
EX,0.39829706717123936,"""
I −ηH(ℓ,t)
βI I
0"
EX,0.39924314096499525,"# ""
W (ℓ,t) −W ∗"
EX,0.4001892147587512,"W (ℓ,t−1) −W ∗ # + η"
EX,0.4011352885525071,"""
∇f(W (ℓ,t)) −∇ˆfDt, e
Dt(W (ℓ,t)) 0 # . (39)"
EX,0.402081362346263,"Let H(ℓ,t) = SΛST be the eigen-decomposition of H(ℓ,t). Then, we deﬁne"
EX,0.4030274361400189,A(β) :=
EX,0.40397350993377484,"""
ST
0"
ST,0.40491958372753073,"0
ST # A(β) ""
S
0"
S,0.40586565752128667,"0
S # ="
S,0.40681173131504256,"""
I −ηΛ + βI
βI I
0 #"
S,0.4077578051087985,".
(40) Since ""
S
0"
S,0.4087038789025544,"0
S"
S,0.4096499526963103,"# ""
ST
0"
ST,0.4105960264900662,"0
ST # = ""
I
0"
I,0.41154210028382215,"0
I #"
I,0.41248817407757804,", we know A(β) and"
I,0.413434247871334,"""
I −ηΛ + βI
βI I
0 #"
I,0.41438032166508987,share the same
I,0.4153263954588458,"eigenvalues. Let γ(Λ)
i
be the i-th eigenvalue of ∇2f( b
w(t)), then the corresponding i-th eigenvalue
of (40), denoted by γ(A)
i
, satisﬁes"
I,0.4162724692526017,"(γ(A)
i
(β))2 −(1 −ηγ(Λ)
i
+ β)γ(A)
i
(β) + β = 0.
(41)"
I,0.41721854304635764,"By simple calculation, we have"
I,0.4181646168401135,"|γ(A)
i
(β)| = 

 
"
I,0.41911069063386946,"√β,
if
β ≥
 
1 −
q"
I,0.42005676442762535,"ηγ(Λ)
i
2, 1
2"
I,0.4210028382213813,"(1 −ηγ(Λ)
i
+ β) +
q"
I,0.4219489120151372,"(1 −ηγ(Λ)
i
+ β)2 −4β
 , otherwise.
(42)"
I,0.4228949858088931,"Speciﬁcally, we have"
I,0.423841059602649,"γ(A)
i
(0) > γ(A)
i
(β),
for
∀β ∈
 
0, (1 −ηγ(Λ)
i
)2
,
(43)"
I,0.4247871333964049,"and γ(A)
i
achieves the minimum γ(A)∗
i
=
1 −
q"
I,0.42573320719016083,"ηγ(Λ)
i
 when β =

1 −
q"
I,0.4266792809839167,"ηγ(Λ)
i
2
. From Lemma"
I,0.42762535477767266,"9, for any a ∈Rd with ∥a∥2 = 1, we have"
I,0.42857142857142855,"aT ∇f(W (ℓ,t))a =
Z 1"
I,0.4295175023651845,"0
aT ∇2f

W (ℓ,t) + u · (W (ℓ,t) −W ∗)

adu ≤
Z 1"
I,0.4304635761589404,"0
γmax∥a∥2
2du = γmax,"
I,0.4314096499526963,"aT ∇f(W (ℓ,t))a =
Z 1"
I,0.4323557237464522,"0
aT ∇2f

W (ℓ,t) + u · (W (ℓ,t) −W ∗)

adu ≥
Z 1"
I,0.43330179754020814,"0
γmin∥a∥2
2du = γmin, (44)"
I,0.43424787133396403,Published as a conference paper at ICLR 2022
I,0.43519394512771997,where γmax = 7(λδ2+eλ˜δ2)
I,0.43614001892147586,"K
, and γmin = λρ(δ)+eλρ(˜δ)"
I,0.4370860927152318,"12κ2γK2 . Therefore, we have"
I,0.4380321665089877,"γ(Λ)
min = λρ(δ) + eλρ(˜δ)"
I,0.4389782403027436,"12κ2γK2
,
and
γ(Λ)
max = 7(λδ2 + eλ˜δ2)"
I,0.4399243140964995,"K
.
(45)"
I,0.44087038789025546,"Thus, we can select η =
 
1
√"
I,0.44181646168401134,"γ(Λ)
max+
q"
I,0.4427625354777673,"γ(Λ)
min"
I,0.44370860927152317,"2, and ∥A(β)∥2 can be bounded by"
I,0.4446546830652791,"min
β ∥A(β)∥2 ≤1 − s"
I,0.445600756859035, λρ(δ) + eλρ(˜δ)
I,0.44654683065279094,"12κ2γK2

/
 
2 · 7(λδ2 + eλ˜δ2) K
"
I,0.4474929044465468,"=1 −
µ(δ, ˜δ)
p"
I,0.44843897824030277,"168κ2γK
, (46)"
I,0.44938505203405865,"where µ(δ, ˜δ) =

λρ(δ)+eλρ(˜δ)"
I,0.4503311258278146,"λδ2+eλ˜δ2
1/2
."
I,0.4512771996215705,"From Lemma 10, we have"
I,0.4522232734153264,"∥∇f(W (ℓ,t)) −∇ˆf(W (ℓ,t))∥2 =
λδ2 K r"
I,0.4531693472090823,d log q
I,0.45411542100283825,"Nt
+
eλ˜δ2 K r"
I,0.45506149479659413,d log q Mt
I,0.45600756859035,"
· ∥W (ℓ,t) −W ∗∥2"
I,0.45695364238410596,"+
eλ˜δ2 K r"
I,0.45789971617786185,d log q
I,0.4588457899716178,"Mt
+ 1 2"
I,0.4597918637653737,"
· ∥W (ℓ,0) −W ∗∥2. (47)"
I,0.4607379375591296,"Given ε > 0 and ˜ε > 0 with ε + ˜ε < 1, let"
I,0.4616840113528855,η · λδ2 K r
I,0.46263008514664145,d log q
I,0.46357615894039733,"Nt
≤
εµ(δ, ˜δ)
p"
I,0.4645222327341533,"168κ2γK
,"
I,0.46546830652790916,"and
η ·
eλ˜δ2 K r"
I,0.4664143803216651,d log q
I,0.467360454115421,"Mt
≤
˜εµ(δ, ˜δ)
p"
I,0.46830652790917693,"168κ2γK
, (48)"
I,0.4692526017029328,where we need
I,0.47019867549668876,"Nt ≥ε−2µ−2 
λδ2"
I,0.47114474929044464,"λδ2 + eλ˜δ2
2κ2γK3d log q,"
I,0.4720908230842006,"and
Mt ≥˜ε−2µ−2 
eλ˜δ2"
I,0.47303689687795647,"λδ2 + eλ˜δ2
2κ2γK3d log q. (49)"
I,0.4739829706717124,"Therefore, from (46), (47) and (48), we have"
I,0.4749290444654683,"∥W (ℓ,t+1) −W ∗∥2"
I,0.47587511825922424,"≤

1 −(1 −ε −˜ε)µ(δ, ˜δ)
p"
I,0.4768211920529801,168κ2γK
I,0.47776726584673607,"
∥W (ℓ,t) −W ∗∥2 + η ·
eλ˜δ2 K r"
I,0.47871333964049195,d log q
I,0.4796594134342479,"Mt
+ 1 2"
I,0.4806054872280038,"
· ∥W (ℓ,0) −W ∗∥2"
I,0.4815515610217597,"≤

1 −(1 −ε −˜ε)µ(δ, ˜δ)
p"
I,0.4824976348155156,168κ2γK
I,0.48344370860927155,"
∥W (ℓ,t) −W ∗∥2 + η ·
eλ˜δ2"
I,0.48438978240302744,"K ∥W (ℓ,0) −W ∗∥2 (50)"
I,0.4853358561967833,"when M ≥4d log q. By mathematical induction on (50) over t, we have"
I,0.48628192999053926,"∥W (ℓ,t) −W ∗∥2"
I,0.48722800378429515,"≤

1 −(1 −ε −˜ε)µ
p"
I,0.4881740775780511,168κ2γK
I,0.489120151371807,"t
· ∥W (ℓ,0) −W ∗∥2 + p"
I,0.4900662251655629,"168κ2γK
(1 −ε −˜ε)µ · √ K"
I,0.4910122989593188,"14(λδ2 + eλ˜δ2)
·
eλ˜δ2"
I,0.49195837275307475,"K ∥W (ℓ,0) −W ∗∥2"
I,0.49290444654683063,"≤

1 −(1 −ε −˜ε)µ
p"
I,0.4938505203405866,"168κ2γK t
+ p"
I,0.49479659413434246,κ2γeλ˜δ2
I,0.4957426679280984,(1 −ε −˜ε)µ(λδ2 + eλ˜δ2)
I,0.4966887417218543,"
· ∥W (ℓ,0) −W ∗∥2 (51)"
I,0.49763481551561023,Published as a conference paper at ICLR 2022
I,0.4985808893093661,"By mathematical induction on (51) over ℓ, we have"
I,0.49952696310312206,"∥W (ℓ,T ) −W ∗∥2"
I,0.5004730368968779,"≤

1 −(1 −ε −˜ε)µ
p"
I,0.5014191106906338,"168κ2γK T
+ p"
I,0.5023651844843898,κ2γeλ˜δ2
I,0.5033112582781457,(1 −ε −˜ε)µ(λδ2 + eλ˜δ2)
I,0.5042573320719016,"ℓ
· ∥W (0,0) −W ∗∥2
(52)"
I,0.5052034058656575,"F
PROOF OF THEOREM 1"
I,0.5061494796594135,"Instead of proving Theorem 1, we turn to prove a stronger version, as shown in Theorem 3. One can
verify that Theorem 1 is a special case of Theorem 3 by selecting ˆλ in the order of p and eε is in the
order of (2p −1)."
I,0.5070955534531694,"The major idea in proving Theorem 3 is similar to that of Theorem 2. The ﬁrst step is to characterize
the gradient descent term on the population risk function by the MVT in Lemma 8 as shown in
(58) and (59). Then, the connection between ∥W (ℓ+1,0) −W [p]∥F and ∥W (ℓ,0) −W [p]∥F are
characterized in (64). Compared with proving Theorem 2, where the induction over ℓholds naturally
with large size of labeled data, the induction over ℓrequires a proper value of p as shown in (69). By
induction over ℓon (64), the relative error ∥W (L,0) −W [p]∥F can be characterized by ∥W (0,0) −
W [p]∥F as shown in (71)."
I,0.5080416272469253,"Theorem 3. Suppose the initialization W (0,0) satisﬁes with"
I,0.5089877010406811,"|p −ˆλ| ≤2(1 −eε)p −1 µ
√ K (53)"
I,0.5099337748344371,"for some constant eε ∈(0, 1/2), where"
I,0.510879848628193,"ˆλ :=
λδ2"
I,0.5118259224219489,"λδ2 + eλ˜δ2 =
 
N
κ2γK3µ2d log q
 1"
I,0.5127719962157048,"2
(54) and"
I,0.5137180700094608,"µ = µ(δ, ˜δ) =
λδ2 + eλ˜δ2"
I,0.5146641438032167,"λρ(δ) + eλρ(˜δ)
.
(55)"
I,0.5156102175969726,"Then, if the number of samples in eD further satisﬁes"
I,0.5165562913907285,"M ≳˜ε−2κ2γµ2 
1 −ˆλ
2K3d log q,
(56)"
I,0.5175023651844843,"the iterates {W (ℓ,t)}L,T
ℓ,t=0 converge to W [p] with p satisﬁes (53) as"
I,0.5184484389782403,"lim
T →∞∥W (ℓ,T ) −W [p]∥2"
I,0.5193945127719962,"≤
1
1 −˜ε ·

1 −p∗+ µ
√"
I,0.5203405865657521,"K
(ˆλ −p∗)


· ∥W (0,0) −W ∗∥2 +
˜ε
(1 −˜ε) · ∥W (ℓ,0) −W [p]∥2, (57)"
I,0.521286660359508,with probability at least 1 −q−d.
I,0.522232734153264,"Proof of Theorem 3. From Algorithm 1, in the ℓ-th outer loop, we have"
I,0.5231788079470199,"W (ℓ,t+1) =W (ℓ,t) −η∇ˆfDt, e
Dt(W (ℓ,t)) + β(W (ℓ,t) −W (ℓ,t−1))"
I,0.5241248817407758,"=W (ℓ,t) −η∇f(W (ℓ,t)) + β(W (ℓ,t) −W (ℓ,t−1))"
I,0.5250709555345316,"+ η ·

∇f(W (ℓ,t)) −∇ˆfDt, e
Dt(W (ℓ,t))

(58)"
I,0.5260170293282876,"Since ∇f is a smooth function and W [p] is a local (global) optimal to f, then we have"
I,0.5269631031220435,"∇f(W (ℓ,t)) =∇f(W (ℓ,t)) −∇f(W [p]) =
Z 1"
I,0.5279091769157994,"0
∇2f

W (ℓ,t) + u · (W (ℓ,t) −W [p])

du · (W (ℓ,t) −W [p]),
(59)"
I,0.5288552507095553,Published as a conference paper at ICLR 2022
I,0.5298013245033113,where the last equality comes from Lemma 8.
I,0.5307473982970672,"Similar to the proof of Theorem 2, we have"
I,0.5316934720908231,"∥W (ℓ,t+1)−W [p]∥2 ≤∥A(β)∥2·∥W (ℓ,t)−W [p]∥2+η·∥∇f(W (ℓ,t))−∇ˆfDt, e
Dt(W (ℓ,t))∥2. (60)"
I,0.532639545884579,"From Lemma 2, we have"
I,0.533585619678335,"∥∇f(W (ℓ,t)) −∇ˆf(W (ℓ,t))∥2 ≲λδ2 K r"
I,0.5345316934720908,d log q
I,0.5354777672658467,"Nt
· ∥W (ℓ,t) −W ∗∥+
eλ˜δ2 K r"
I,0.5364238410596026,d log q
I,0.5373699148533586,"Mt
· ∥W (ℓ,t) −W (ℓ,0)∥2 +"
I,0.5383159886471145,"λδ2 · (W (0,0) −W [p]) −eλ˜δ2 · (W ∗−W [p]) K (61)"
I,0.5392620624408704,"When ℓ= 0, following the similar steps from (41) to (46), we have"
I,0.5402081362346263,"∥∇f(W (ℓ,t)) −∇ˆf(W (ℓ,t))∥2 ≲λδ2 K r"
I,0.5411542100283823,d log q
I,0.5421002838221382,"Nt
· ∥W (ℓ,t) −W [p]∥+
eλ˜δ2 K r"
I,0.543046357615894,d log q
I,0.5439924314096499,"Mt
· ∥W (ℓ,t) −W [p]∥2 + λδ2 K r"
I,0.5449385052034059,d log q
I,0.5458845789971618,"Nt
· ∥W ∗−W [p]∥+
eλ˜δ2 K r"
I,0.5468306527909177,d log q
I,0.5477767265846736,"Mt
· ∥W (0,0) −W [p]∥2 +"
I,0.5487228003784295,λδ2 · (1 −p) −eλ˜δ2 · p
I,0.5496688741721855,"K
· ∥W (0,0) −W ∗∥2 (62) and"
I,0.5506149479659413,"∥W (ℓ,t+1) −W [p]∥2"
I,0.5515610217596972,"≤

1 −
1 −˜ε"
I,0.5525070955534531,"µ(δ, ˜δ)
p"
I,0.5534531693472091,154κ2γK
I,0.554399243140965,"
· ∥W (ℓ,t) −W [p]∥2"
I,0.5553453169347209,"+ η ·
λδ2(1 −p) K r"
I,0.5562913907284768,"d log q Nt
+"
I,0.5572374645222328,λδ2 · (1 −p) −eλ˜δ2 · p K
I,0.5581835383159887,"
· ∥W (0,0) −W ∗∥2"
I,0.5591296121097445,"+ η · ˜εeλ˜δ2 · p K
· r"
I,0.5600756859035004,d log q
I,0.5610217596972564,"Mt
∥W (0,0) −W ∗∥2. (63)"
I,0.5619678334910123,"Therefore, we have"
I,0.5629139072847682,"lim
T →∞∥W (ℓ,T ) −W [p]∥2 ≤µ
p"
I,0.5638599810785241,154κ2γK
I,0.5648060548722801,"1 −˜ε
· η ·
hλδ2(1 −p) K r"
I,0.565752128666036,"d log q Nt
+"
I,0.5666982024597919,λδ2 · (1 −p) −eλ˜δ2 · p K
I,0.5676442762535477,"
· ∥W (0,0) −W ∗∥2"
I,0.5685903500473037,"+ ˜εeλ˜δ2 · p K
· r"
I,0.5695364238410596,d log q
I,0.5704824976348155,"Mt
· ∥W (0,0) −W ∗∥2
i ≤µ
p"
I,0.5714285714285714,154κ2γK
I,0.5723746452223274,"1 −˜ε
·
K"
I,0.5733207190160833,"14(λδ2 + eλ˜δ2)
·
hλδ2(1 −p) K r"
I,0.5742667928098392,"d log q Nt
+"
I,0.575212866603595,λδ2 · (1 −p) −eλ˜δ2 · p K 
I,0.5761589403973509,"· ∥W (0,0) −W ∗∥2 + ˜εeλ˜δ2 · p K
· r"
I,0.5771050141911069,d log q
I,0.5780510879848628,"Mt
· ∥W (0,0) −W ∗∥2
i"
I,0.5789971617786187,"≃
1
1 −˜ε ·

1 −p +
√"
I,0.5799432355723746,"K ·
(1 −p)µˆλ −pµ(1 −ˆλ)


· ∥W (0,0) −W ∗∥2"
I,0.5808893093661306,"+
˜εp
(1 −˜ε) · ∥W (0,0) −W ∗∥2"
I,0.5818353831598865,"=
1
1 −˜ε ·

1 −p + µ
√"
I,0.5827814569536424,"K
bλ −p


· ∥W (0,0) −W ∗∥2 +
˜εp
(1 −˜ε) · ∥W (0,0) −W ∗∥2, (64)"
I,0.5837275307473982,"where ˆλ =
λδ2"
I,0.5846736045411542,λδ2+eλ˜δ2 .
I,0.5856196783349101,Published as a conference paper at ICLR 2022
I,0.586565752128666,"To guarantee the convergence in the outer loop, we require"
I,0.5875118259224219,"lim
T →∞∥W (ℓ,T ) −W [p]∥2 ≤∥W (0,0) −W [p]∥2 = p∥W (0,0) −W ∗∥2,"
I,0.5884578997161779,"and
lim
T →∞∥W (ℓ,T ) −W ∗∥2 ≤∥W (0,0) −W ∗∥2.
(65)"
I,0.5894039735099338,Since we have
I,0.5903500473036897,"∥W (ℓ,T ) −W [p]∥2 ≤∥W (ℓ,T ) −W ∗∥2 + ∥W ∗−W [p]∥2"
I,0.5912961210974456,"=∥W (ℓ,T ) −W ∗∥2 + (1 −p) · ∥W ∗−W (0,0)∥2,
(66)"
I,0.5922421948912016,it is clear that (65) holds if and only if
I,0.5931882686849574,"1
1 −˜ε ·

1 −p + eεp + µ
√"
I,0.5941343424787133,"K
ˆλ −p


+ 1 −p ≤1.
(67)"
I,0.5950804162724692,"To guarantee the iterates strictly converges to the desired point, we let"
I,0.5960264900662252,"1
1 −˜ε ·

1 −p + eεp + µ
√"
I,0.5969725638599811,"K
ˆλ −p


+ 1 −p ≤1 −1"
I,0.597918637653737,"C
(68)"
I,0.5988647114474929,"for some larger constant C, which is equivalent to"
I,0.5998107852412489,"|p −ˆλ| ≤2(1 −eε)p −1 µ
√"
I,0.6007568590350048,"K
.
(69)"
I,0.6017029328287606,"To make the bound in (69) meaningful, we need"
I,0.6026490066225165,"p ≥
1
2(1 −eε).
(70)"
I,0.6035950804162725,"When ℓ> 1, following similar steps in (64), we have"
I,0.6045411542100284,"lim
T →∞∥W (ℓ,T ) −W [p]∥2"
I,0.6054872280037843,"≤
1
1 −˜ε ·

1 −p + µ
√"
I,0.6064333017975402,"K
(ˆλ −p)


· ∥W (0,0) −W ∗∥2 +
˜εp
1 −˜ε · ∥W (ℓ,0) −W [p]∥2,
(71)"
I,0.6073793755912961,"Given (69) holds, from (71), we have"
I,0.6083254493850521,"lim
L→∞,T →∞∥W (L,T ) −W [p]∥2"
I,0.609271523178808,"≤
1
1 −eε ·

1 −p + µ
√"
I,0.6102175969725638,"K
ˆλ −p


· ∥W (0,0) −W ∗∥2"
I,0.6111636707663197,"≤
1
1 −eε ·

1 −p + µ
√"
I,0.6121097445600757,"K
ˆλ −p


· ∥W (0,0) −W ∗∥2. (72)"
I,0.6130558183538316,"G
DEFINITION AND RELATIVE PROOFS OF ρ"
I,0.6140018921475875,"In this section, the formal deﬁnition of ρ is included in Deﬁnition 3, and a corresponding claim about
ρ is summarized in Lemma 11. One can quickly check that the ReLU activation function satisﬁes
the conditions in Lemma 11."
I,0.6149479659413434,"The major idea in proving Lemma 11 is to show Hr(δ) and Jr(δ) in Deﬁnition 3 are in the order of
δr when δ is small.
Deﬁnition 3. Let Hr(δ) = Ez∼N(0,δ2)
 
φ′(σKz)zr
and Jr(δ) = Ez∼N(0,δ2)
 
φ′2(σKz)zr
. Then,
ρ = ρ(δ) is deﬁned as"
I,0.6158940397350994,"ρ(δ) = min
n
J0(δ) −H2
0(δ) −H2
1(δ), J2(δ) −H2
1(δ) −H2
2(δ), H0(δ) · H2(δ) −H2
1(δ)
o
, (73)"
I,0.6168401135288553,where σK is the minimal singular value of W ∗.
I,0.6177861873226111,Published as a conference paper at ICLR 2022
I,0.618732261116367,"Lemma 11 (Order analysis of ρ). If ρ(δ) > 0 for δ ∈(0, ξ) for some positive constant ξ and the
sub-gradient of ρ(δ) at 0 can be non-zero, then ρ(δ) = Θ(δ2) when δ →0+. Typically, for ReLU
activation function, µ in (5) is a ﬁxed constant for all δ, ˜δ ≤1."
I,0.619678334910123,"Proof of Lemma 11 . From Deﬁnition 3, we know that Hr(δ) = Ez∼N(0,δ2)φ′(σKz)zr. Suppose
we have Hr(δ) = Θ(δr) and Jr(δ) = Θ(δr), then from (73) we have"
I,0.6206244087038789,"J0(δ) −H2
0(δ) −H2
1(δ) ∈Θ(1) −Θ(δ2),"
I,0.6215704824976348,"J2(δ) −H2
1(δ) −H2
2(δ) ∈Θ(δ2),"
I,0.6225165562913907,"H0(δ) · H2(δ) −H2
1(δ) ∈Θ(δ2) −Θ(δ4). (74)"
I,0.6234626300851467,"Because ρ is a continuous function with ρ(z) > 0 for some z > 0. Therefore, ρ ̸= J0(δ) −H2
0(δ) −
H2
1(δ) when δ →0+, otherwise ρ(z) < 0 for any z > 0. When δ →0+, both J2(δ) −H2
1(δ) −
H2
2(δ) and H0(δ) · H2(δ) −H2
1(δ) are in the order of δ2, which indicates that µ is a ﬁxed constant
when both δ and ˜δ are close to 0. In addition, J2(δ) −H2
1(δ) −H2
2(δ) goes to +∞while both
J0(δ) −H2
0(δ) −H2
1(δ) and H0(δ) · H2(δ) −H2
1(δ) go to −∞when δ →+∞. Therefore, with a
large enough δ, we have"
I,0.6244087038789026,"ρ(δ) ∈Θ(δ2) −Θ(δ4)
or
Θ(1) −Θ(δ2),
(75)"
I,0.6253547776726585,which indicates that µ is a strictly decreasing function when δ and ˜δ are large enough.
I,0.6263008514664143,"Next, we provide the conditions that guarantee Hr(δ) = Θ(δr) hold, and the relative proof for Jr(δ)
can be derived accordingly following the similar steps as well. From Deﬁnition 3, we have"
I,0.6272469252601703,"lim
δ→0+
Hr(δ)"
I,0.6281929990539262,"δr
= lim
δ→0+ Z +∞"
I,0.6291390728476821,"−∞
φ′(σKz)
 z"
I,0.630085146641438,"δ
r
1
√"
I,0.631031220435194,2πδ e−z2 δ2 dz
I,0.6319772942289499,"(a)
= lim
δ→0+ Z +∞"
I,0.6329233680227058,"−∞
φ′(σKδt) tr √"
I,0.6338694418164617,2π e−t2dt
I,0.6348155156102177,"= lim
δ→0+ Z 0−"
I,0.6357615894039735,"−∞
φ′(σKδt) tr √"
I,0.6367076631977294,"2π e−t2dt + lim
δ→0+ Z +∞"
I,0.6376537369914853,"0+
φ′(σKδt) tr √"
I,0.6385998107852412,2π e−t2dt
I,0.6395458845789972,"=φ′(0−)
Z 0− −∞ tr
√"
I,0.6404919583727531,"2π e−t2dt + φ′(0+)
Z +∞"
I,0.641438032166509,"0+
tr
√"
I,0.6423841059602649,"2π e−t2dt, (76)"
I,0.6433301797540208,where equality (a) holds by letting t = z
I,0.6442762535477767,δ . It is easy to verify that Z +∞
I,0.6452223273415326,"0+
tr
√"
I,0.6461684011352885,"2π e−t2dt = (−1)r
Z 0− −∞ tr
√"
I,0.6471144749290445,"2π e−t2dt,"
I,0.6480605487228004,"and both are bounded for a ﬁxed r. Thus, as long as either φ′(0−) or φ′(0+) is non-zero, we have
Hr(δ) = Θ(δr) when δ →0+."
I,0.6490066225165563,"If φ has bounded gradient as |φ′| ≤Cφ for some positive constant Cφ. Then, we have Hr(δ)"
I,0.6499526963103122,"δr
 =

Z +∞"
I,0.6508987701040682,"−∞
φ′(σKz)
 z"
I,0.651844843897824,"δ
r
1
√"
I,0.6527909176915799,2πδ e−z2 δ2 dz
I,0.6537369914853358,"=

Z +∞"
I,0.6546830652790918,"−∞
φ′(σKδt) tr √"
I,0.6556291390728477,2π e−t2dt
I,0.6565752128666036,"≤Cφ ·

Z +∞ −∞ tr
√"
I,0.6575212866603595,2π e−t2dt (77)
I,0.6584673604541155,"Therefore, we have Hr(δ) = O(δr) for all δ > 0 when φ has bounded gradient."
I,0.6594134342478714,"Typiclly, for ReLU function, one can directly calculate that Hr(δ) = δr for δ ∈R, and ρ(δ) = Cδ2
when δ ≤1 for some constant C = 0.091. Then, it is easy to check that µ is a constant when
δ, ˜δ ≤1."
I,0.6603595080416272,Published as a conference paper at ICLR 2022
I,0.6613055818353831,"H
PROOF OF PRELIMINARY LEMMAS"
I,0.6622516556291391,"H.1
PROOF OF LEMMA 1"
I,0.663197729422895,"The eigenvalues of ∇2f(·; p) at any ﬁxed point W can be bounded in the form of (80) by Weyl’s
inequality (Lemma 4). Therefore, the primary technical challenge lies in bounding ∥∇2f(W ; p) −
∇2f(W [p]; p)∥2, which is summarized in Lemma 12. Lemma 13 provides the exact calulation of"
I,0.6641438032166509,"the lower bound of Ex
 PK
j=1 αT
j xφ′(w[p]T
j
x)
2
when x belongs to Gaussian distribution with
zero mean, which is used in proving the lower bound of the Hessian matrix in (81)."
I,0.6650898770104068,"Lemma 12. Let f(W ; p) be the population risk function deﬁned in (17) with p and W satisfying
(20). Then, we have"
I,0.6660359508041628,∥∇2f(W [p]; p) −∇2f(W ; p)∥2 ≲λδ2 + (1 −λ)˜δ2
I,0.6669820245979187,"K
· ∥W [p] −W ∥2"
I,0.6679280983916746,"σK
.
(78)"
I,0.6688741721854304,"Lemma 13 (Lemma D.6, (Zhong et al., 2017)). For any {wj}K
j=1 ∈Rd, let α ∈RdK be the unit
vector deﬁned in (19). When the φ is ReLU function, we have"
I,0.6698202459791863,"min
∥α∥2=1 Ex∼N(0,σ2)
 K
X"
I,0.6707663197729423,"j=1
αT
j xφ′(wT
j x)
2
≳ρ(σ),
(79)"
I,0.6717123935666982,where ρ(σ) is deﬁned in Deﬁnition 3.
I,0.6726584673604541,"Proof of Lemma 1. Let λmax(W ) and λmin(W ) denote the largest and smallest eigenvalues of
∇2f(W ; p) at point W , respectively. Then, from Lemma 4, we have"
I,0.67360454115421,"λmax(W ) ≤λmax(W [p]) + ∥∇2f(W ; p) −∇2f(W [p]; p)∥2,"
I,0.674550614947966,"λmin(W ) ≥λmin(W [p])−∥∇2f(W ; p) −∇2f(W [p]; p)∥2.
(80)"
I,0.6754966887417219,"Then, we provide the lower bound of the Hessian matrix of the population function at W [p]. For
any α ∈RdK deﬁned in (19) with ∥α∥2 = 1, we have"
I,0.6764427625354777,"min
∥α∥2=1 αT ∇2f(W [p]; p)α = 1"
I,0.6773888363292336,"K2
min
∥α∥2=1"
I,0.6783349101229896,"h
λEx
 K
X"
I,0.6792809839167455,"j=1
αT
j xφ′(w[p]T
j
x)
2
+ eλEex
 K
X"
I,0.6802270577105014,"j=1
αT
j exφ′(w[p]T
j
ex)
2i ≥1"
I,0.6811731315042573,"K2
min
∥α∥2=1 λEx
 K
X"
I,0.6821192052980133,"j=1
αT
j xφ′(w[p]T
j
x)
2
+
min
∥α∥2=1
eλEex
 K
X"
I,0.6830652790917692,"j=1
αT
j exφ′(w[p]T
j
ex)
2"
I,0.6840113528855251,≥λρ(δ) + eλρ(˜δ)
I,0.684957426679281,"11κ2γK2
, (81)"
I,0.6859035004730369,where the last inequality comes from Lemma 13.
I,0.6868495742667928,"Next, the upper bound can be bounded as"
I,0.6877956480605487,"max
∥α∥2=1 αT ∇2f(W [p]; p)α = 1"
I,0.6887417218543046,"K2
max
∥α∥2=1"
I,0.6896877956480606,"h
λEx
 K
X"
I,0.6906338694418165,"j=1
αT
j xφ′(w[p]T
j
x)
2
+ eλEex
 K
X"
I,0.6915799432355724,"j=1
αT
j exφ′(w[p]T
j
ex)
2i ≤1"
I,0.6925260170293283,"K2
max
∥α∥2=1 λEx
 K
X"
I,0.6934720908230843,"j=1
αT
j xφ′(w[p]T
j
x)
2
+ max
∥α∥2=1
eλEex
 K
X"
I,0.6944181646168401,"j=1
αT
j exφ′(w[p]T
j
ex)
2
. (82)"
I,0.695364238410596,Published as a conference paper at ICLR 2022
I,0.6963103122043519,"For Ex
 PK
j=1 αT
j xφ′(w[p]T
j
x)
2
, we have"
I,0.6972563859981078,"Ex
 K
X"
I,0.6982024597918638,"j=1
αT
j xφ′(w[p]T
j
x)
2 =Ex K
X j1=1 K
X"
I,0.6991485335856197,"j2=1
αT
j1xφ′(w[p]T
j1
x)αT
j2xφ′(w[p]T
j2
x) = K
X j1=1 K
X"
I,0.7000946073793756,"j2=1
ExαT
j1xφ′(w[p]T
j1
x)αT
j2xφ′(w[p]T
j2
x) ≤ K
X j1=1 K
X j2=1"
I,0.7010406811731315,"h
Ex(αT
j1x)4Ex(φ′(w[p]T
j1
x))4Ex(αT
j2x)4Ex(φ′(w[p]T
j2
x))4i1/4 ≤ K
X j1=1 K
X"
I,0.7019867549668874,"j2=1
3δ2∥αj1∥2∥αj2∥2"
I,0.7029328287606433,"≤6δ2
K
X j1=1 K
X j2=1"
I,0.7038789025543992,"1
2(∥αj1∥2
2 + ∥αj2∥2
2) =6Kδ2 (83)"
I,0.7048249763481551,"Therefore, we have"
I,0.7057710501419111,"max
∥α∥2=1 αT ∇2f(W [p]; p)α ≤1"
I,0.706717123935667,"K2
max
∥α∥2=1 λEx
 K
X"
I,0.7076631977294229,"j=1
αT
j xφ′(w[p]T
j
x)
2
+ max
∥α∥2=1
eλEex
 K
X"
I,0.7086092715231788,"j=1
αT
j exφ′(w[p]T
j
ex)
2"
I,0.7095553453169348,"≤6(λδ2 + eλ˜δ2) K
. (84)"
I,0.7105014191106906,"Then, given (20), we have"
I,0.7114474929044465,"∥W (0,0) −W [p]∥F = p∥W (0,0) −W ∗∥F ≲σK"
I,0.7123935666982024,"µ2K .
(85)"
I,0.7133396404919584,"Combining (85) and Lemma 12, we have"
I,0.7142857142857143,∥∇2f(W ; p) −∇2f(W [p]; p)∥2 ≲λρ(δ) + eλρ(˜δ)
I,0.7152317880794702,"132κ2γK2
.
(86)"
I,0.7161778618732261,"Therefore, (86) and (80) completes the whole proof."
I,0.7171239356669821,"H.2
PROOF OF LEMMA 2"
I,0.718070009460738,"The task of bounding of the quantity between ∥∇ˆf −∇f∥2 is dividing into bounding I1, I2, I3 and
I4 as shown in (89). I1 and I3 represent the deviation of the mean of several random variables to
their expectation, which can be bounded through concentration inequality, i.e, Chernoff bound. I2
and I4 come from the inconsistency of the output label y and pseudo label ey in the empirical risk
function in (1) and population risk function in (17). The major challenge lies in characterizing the
upper bound of I2 and I4 as the linear function of f
W −W [p] and W [p]−W ∗, which is summarized
in (96)."
I,0.7190160832544938,Published as a conference paper at ICLR 2022
I,0.7199621570482497,"Proof of Lemma 2. From (1), we know that"
I,0.7209082308420057,"∂ˆf
∂wk
(W ) = λ N N
X n=1  1 K K
X"
I,0.7218543046357616,"j=1
φ(wT
j xn) −yn

xn + 1 −λ M M
X m=1  1 K K
X"
I,0.7228003784295175,"j=1
φ(wT
j exm) −eyn

exm"
I,0.7237464522232734,"=
λ
K2N N
X n=1 K
X j=1"
I,0.7246925260170294,"
φ(wT
j xn) −φ(w∗T
j xn)

xn"
I,0.7256385998107853,"+ 1 −λ K2M M
X m=1 K
X j=1"
I,0.7265846736045412,"
φ(wT
j exm) −φ( e
wT
j exm)

exm."
I,0.727530747398297,"(87)
From (32), we know that"
I,0.7284768211920529,"∂ˆf
∂wk
(W ) = λ K2 Ex K
X j=1"
I,0.7294228949858089,"
φ(wT
j x) −φ(w∗T
j x)

x + 1 −λ"
I,0.7303689687795648,"K2 Eex K
X j=1"
I,0.7313150425733207,"
φ(wT
j ex) −φ( e
wT
j ex)

ex."
I,0.7322611163670766,"(88)
Then, from (17), we have"
I,0.7332071901608326,"∂ˆf
∂wk
(W ) −∂f"
I,0.7341532639545885,"∂wk
(W ; p)"
I,0.7350993377483444,"=
λ
K2N K
X j=1 h
N
X n=1"
I,0.7360454115421002," 
φ(wT
j xn) −φ(w∗T
j xn)

xn −Ex
 
φ(wT
j x) −φ(w[p]T
j
x)

x
i"
I,0.7369914853358562,"+ 1 −λ K2M K
X j=1 h
M
X m=1"
I,0.7379375591296121," 
φ(wT
j exm) −φ( e
wT
j exm)
exm −Eex
 
φ(wT
j ex) −φ(w[p]T
j
ex)
ex
i = λ K2 K
X j=1 h 1 N N
X n=1"
I,0.738883632923368," 
φ(wT
j xn) −φ(w∗T
j xn)

xn −Ex
 
φ(wT
j x) −φ(w∗T
j x)

x
i + λ K2 K
X"
I,0.7398297067171239,"j=1
Ex
h 
φ(w∗T
j x) −φ(w[p]T
j
x)

x
i"
I,0.7407757805108799,"+ 1 −λ K2 K
X j=1 h 1 M M
X m=1"
I,0.7417218543046358," 
φ(wT
j exm) −φ( e
wT
j exm)
exm −Eex
 
φ(wT
j ex) −φ( e
wT
j ex)
ex
i"
I,0.7426679280983917,"+ 1 −λ K2 K
X"
I,0.7436140018921475,"j=1
Eex
h 
φ( e
wT
j ex) −φ(w[p]T
j
(p)ex)
ex
i"
I,0.7445600756859035,:=I1 + I2 + I3 + I4. (89)
I,0.7455061494796594,"For any αj ∈Rd with ∥αj∥2 ≤1, we deﬁne a random variable Z(j) =
 
φ(wT
j x)−φ(w∗T
j x)

αT
j x
and Zn(j) =
 
φ(wT
j xn)−φ(w∗T
j xn)

αT
j xn as the realization of Z(j) for n = 1, 2 · · · , N. Then,
for any p ∈N+, we have
 
E|Z|p1/p =

E|φ(wT
j x) −φ(w∗T
j x)|p · |αT
j x|p1/p"
I,0.7464522232734153,"≤

E|(wj −w∗
j )T x|p · |αT
j x|p1/p"
I,0.7473982970671712,"≤C · δ2∥wj −w∗
j ∥2 · p, (90)"
I,0.7483443708609272,"where C is a positive constant and the last inequality holds since x ∼N(0, δ2). From Deﬁnition 2,
we know that Z belongs to sub-exponential distribution with ∥Z∥ψ1 ≲δ2∥wj −w∗
j ∥2. Therefore,
by Chernoff inequality, we have"
I,0.7492904446546831,"P
 1 N N
X"
I,0.750236518448439,"n=1
Zn(j) −EZ(j)
 < t

≤1 −e−C(δ2∥wj−w∗
j ∥2)2·Ns2"
I,0.7511825922421949,"eNst
(91)"
I,0.7521286660359509,Published as a conference paper at ICLR 2022
I,0.7530747398297067,for some positive constant C and any s ∈R.
I,0.7540208136234626,"Let t = δ2∥wj −w∗
j ∥2
q"
I,0.7549668874172185,d log q
I,0.7559129612109745,"N
and s =
2
Cδ2∥wj−w∗
j ∥2 · t for some large constant q > 0, we have 1 N N
X"
I,0.7568590350047304,"n=1
Zn(j) −EZ(j)
 ≲δ2∥wj −w∗
j ∥2 · r"
I,0.7578051087984863,d log q
I,0.7587511825922422,"N
(92)"
I,0.759697256385998,"with probability at least 1 −q−d. From Lemma 7, we have 1 N N
X n=1"
I,0.760643330179754," 
φ(wT
j xn) −φ(w∗T
j xn)

xn −Ex
 
φ(wT
j x) −φ(w∗T
j x)

x

2"
I,0.7615894039735099,"≤2δ2∥wj −w∗
j ∥2 · r"
I,0.7625354777672658,d log q N (93)
I,0.7634815515610217,"with probability at least 1 −(q/5)−d. Since q is a large constant, we release the probability as
1 −q−d for simpliﬁcation. Similar to Z, we have 1 M M
X m=1"
I,0.7644276253547777," 
φ(wT
j exm) −φ( e
wT
j exm)
exm −Eex
 
φ(wT
j ex) −φ( e
wT
j ex)
ex

2"
I,0.7653736991485336,"≲˜δ2∥wj −e
wj∥2 · r"
I,0.7663197729422895,d log q M (94)
I,0.7672658467360454,with probability at least 1 −q−d.
I,0.7682119205298014,"𝒘𝒘𝑗𝑗
∗ 𝜃𝜃1 II
I III IV-A 𝜃𝜃1"
I,0.7691579943235572,"𝒘𝒘𝑗𝑗
[𝑝𝑝]"
I,0.7701040681173131,"Figure 13: The subspace spanned by w∗
j and w[p]
j"
I,0.771050141911069,"For term Ex
h 
φ(w∗T
j x)−φ(w[p]T
j
x)

x
i
, let us deﬁne the angle between w∗
j and w[p]
j
as θ1. Figure
13 shows the subspace spanned by the vector w∗
j and e
wj. We divide the subspace by 4 pieces, where
the gray region denotes area I, and the blue area denotes area II. Areas III and IV are the symmetries
of II and I from the origin, respectively. Hence, we have"
I,0.771996215704825,"Ex
h 
φ(w∗T
j x) −φ(w[p]T
j
x)

x
i"
I,0.7729422894985809,"=Ex∈area I
h 
φ(w∗T
j x) −φ(w[p]T
j
x)

x
i
+ Ex∈area II
h 
φ(w∗T
j x) −φ(w[p]T
j
x)

x
i"
I,0.7738883632923368,"+ Ex∈area III
h 
φ(w∗T
j x) −φ(w[p]T
j
x)

x
i
+ Ex∈area IV
h 
φ(w∗T
j x) −φ(w[p]T
j
x)

x
i"
I,0.7748344370860927,"=Ex∈area I
h 
φ(w∗T
j x) −φ(w[p]T
j
x)

x
i
+ Ex∈area II

w∗T
j
exex

−Ex∈area III

w[p]T
j
xx
"
I,0.7757805108798487,"=Ex∈area I

(w∗
j −w[p]
j )T xx

+ Ex∈area II

(w∗
j −w[p]
j )T xx
 =1"
EX,0.7767265846736046,"2Ex

(w∗
j −w[p]
j )T xx
 (95)"
EX,0.7776726584673604,Published as a conference paper at ICLR 2022
EX,0.7786187322611163,"Therefore, we have

λ
K2 Ex
h 
φ(w∗T
j x) −φ(w[p]T
j
x)

x
i
+ 1 −λ"
EX,0.7795648060548723,"K2 Eex
h 
φ( e
wT
j ex) −φ(w[p]T
j
ex)
ex
i
2"
EX,0.7805108798486282,"=

λ
2K2 Ex

(w∗
j −w[p]
j )T xx

+ 1 −λ"
EX,0.7814569536423841,"2K2 Eex

( e
wj −w[p]
j )T xx

2 ="
EX,0.78240302743614,"λδ2 ·
  e
wj −w[p]
j

+ (1 −λ)˜δ2 ·
 
w∗
j −w[p]
j

2
2K2
. (96)"
EX,0.783349101229896,"From (93), (94) and (96), we have
 ∂ˆf"
EX,0.7842951750236519,"∂wk
(W ; p) −∂f"
EX,0.7852412488174078,"∂wk
(W )

2 ≤λ K2 K
X j=1 1 N N
X n=1"
EX,0.7861873226111636," 
φ(wT
j xn) −φ(w∗T
j xn)

xn −Ex
 
φ(wT
j x) −φ(w∗T
j x)

x

2"
EX,0.7871333964049196,"+ 1 −λ K2 K
X j=1 1 M M
X m=1"
EX,0.7880794701986755," 
φ(wT
j exm) −φ( e
wT
j exm)
exm −Eex
 
φ(wT
j ex) −φ( e
wT
j ex)
ex

2 + K
X j=1"
EX,0.7890255439924314,"λ
K2 Ex
h 
φ(w∗T
j x) −φ(w[p]T
j
x)

x
i
+ 1 −λ"
EX,0.7899716177861873,"K2 Eex
h 
φ( e
wT
j ex) −φ(w[p]T
j
ex)
ex
i
2 ≤λ"
EX,0.7909176915799432,"K2 δ2
r"
EX,0.7918637653736992,"d log q N
· K
X"
EX,0.7928098391674551,"j=1
∥wj −w∗
j ∥2 + 1 −λ"
EX,0.793755912961211,"K2
· ˜δ2
r"
EX,0.7947019867549668,"d log q M
· K
X"
EX,0.7956480605487228,"j=1
∥wj −e
wj∥2"
EX,0.7965941343424787,"+
1
2K2 · K
X j=1"
EX,0.7975402081362346,"λδ2 ·
  e
wj −w[p]
j

+ eλ˜δ2 ·
 
w∗
j −w[p]
j

2"
EX,0.7984862819299905,"≤
λ
K3/2 δ2
r"
EX,0.7994323557237465,d log q
EX,0.8003784295175024,"N
· ∥W −W ∗∥2 + 1 −λ"
EX,0.8013245033112583,"K3/2 · ˜δ2
r"
EX,0.8022705771050141,d log q
EX,0.8032166508987701,"M
· ∥W −f
W ∥2"
EX,0.804162724692526,"+
1
2K3/2
λδ2 ·
 f
W −W [p]
+ (1 −λ)˜δ2 ·
 
W ∗−W [p]
2 (97)"
EX,0.8051087984862819,with probability at least 1 −q−d.
EX,0.8060548722800378,"In conclusion, let α ∈RKd and αj ∈Rd with α = [αT
1 , αT
2 , · · · , αT
K]T , we have"
EX,0.8070009460737938,"∥∇f(W ) −∇ˆf(W )∥2 =
αT  
∇f(W ) −∇ˆf(W )
 ≤ K
X k=1"
EX,0.8079470198675497,"αT
k
  ∂ˆf"
EX,0.8088930936613056,"∂wk
(W ) −∂f"
EX,0.8098391674550615,"∂wk
(W )
 ≲ K
X k=1 ∂ˆf"
EX,0.8107852412488175,"∂wk
(W ) −∂f"
EX,0.8117313150425733,"∂wk
(W )

2 · ∥αk∥2 ≲λ"
EX,0.8126773888363292,"K δ2
r"
EX,0.8136234626300851,d log q
EX,0.8145695364238411,"N
· ∥W −W ∗∥2 + 1 −λ"
EX,0.815515610217597,"K
· ˜δ2
r"
EX,0.8164616840113529,d log q
EX,0.8174077578051088,"M
· ∥W −f
W ∥2"
EX,0.8183538315988647,"+
1
2K"
EX,0.8192999053926207,"λδ2 ·
 f
W −W [p]
+ (1 −λ)˜δ2 ·
 
W ∗−W [p]
2
(98)"
EX,0.8202459791863765,with probability at least 1 −q−d.
EX,0.8211920529801324,"H.3
PROOF OF LEMMA 12"
EX,0.8221381267738883,"The distance of the second order derivatives of the population risk function f(·; p) at point W and
W [p] can be converted into bounding P1, P2, P3 and P4, which are deﬁned in (101). The major"
EX,0.8230842005676443,Published as a conference paper at ICLR 2022
EX,0.8240302743614002,"idea in proving P1 is to connect the error bound to the angle between W and W [p]. Similar ideas
apply in bounding the other three items as well."
EX,0.8249763481551561,"Proof of Lemma 12. From (17), we have"
EX,0.825922421948912,"∂2f
∂wj1∂wj2
(W [p]; p) = λ"
EX,0.826868495742668,"K2 Exφ′(w[p]T
j1
x)φ′(w[p]T
j2
x)xxT + 1 −λ"
EX,0.8278145695364238,"K2 Eexφ′(w[p]T
j1
ex)φ′(w[p]T
j2
ex)exexT , (99)"
EX,0.8287606433301797,"and
∂2f
∂wj1∂wj2
(W ; p) = λ"
EX,0.8297067171239356,"K2 Exφ′(wT
j1x)φ′(wT
j2x)xxT + 1 −λ"
EX,0.8306527909176916,"K2 Eexφ′(wT
j1 ex)φ′(wT
j2 ex)exexT , (100)"
EX,0.8315988647114475,"where w[p]
j
is the j-th column of W [p]. Then, we have"
EX,0.8325449385052034,"∂2f
∂wj1∂wj2
(W ∗) −
∂2f
∂wj1∂wj2
(W ) = λ"
EX,0.8334910122989593,"K2 Ex
h"
EX,0.8344370860927153,"φ′(w[p]T
j1
x)φ′(w[p]T
j2
x) −φ′(wT
j1x)φ′(wT
j2x)
i
xxT"
EX,0.8353831598864712,+ 1 −λ
EX,0.836329233680227,"K2 Eex
h
φ′(w[p]T
j1
ex)φ′(w[p]T
j2
ex) −φ′(wT
j1 ex)φ′(wT
j2 ex)
i
exexT = λ"
EX,0.8372753074739829,"K2 Ex
h
φ′(w[p]T
j1
x)
 
φ′(w[p]T
j2
x) −φ′(wT
j2x)

+ φ′(wT
j2x)
 
φ′(w[p]T
j1
x) −φ′(wT
j1x)
i
xxT"
EX,0.8382213812677389,+ 1 −λ
EX,0.8391674550614948,"K2 Eex
h
φ′(w[p]T
j1
ex)
 
φ′(w[p]T
j2
ex) −φ′(wT
j2 ex)

+ φ′(wT
j2 ex)
 
φ′(w[p]T
j1
ex) −φ′(wT
j1 ex)
i
exexT = λ K2"
EX,0.8401135288552507,"h
Exφ′(w[p]T
j1
x)
 
φ′(w[p]T
j2
x) −φ′(wT
j2x)

xxT + Exφ′(wT
j2x)
 
φ′(w[p]T
j1
x) −φ′(wT
j1x)

xxT i"
EX,0.8410596026490066,+ 1 −λ K2
EX,0.8420056764427626,"h
Eexφ′(w[p]T
j1
ex)
 
φ′(w[p]T
j2
ex) −φ′(wT
j2 ex)
exexT + Eexφ′(wT
j2 ex)
 
φ′(w[p]T
j1
ex) −φ′(wT
j1 ex)
exexT i := λ"
EX,0.8429517502365185,K2 (P1 + P2) + 1 −λ
EX,0.8438978240302744,K2 (P3 + P4). (101)
EX,0.8448438978240302,"For any a ∈Rd with ∥a∥2 = 1, we have"
EX,0.8457899716177862,"aT P1a =Exφ′(w[p]T
j1
x)
 
φ′(w[p]T
j2
x) −φ′(wT
j2x)

(aT x)2
(102)"
EX,0.8467360454115421,"where a ∈Rd. Let I = φ′(w[p]T
j1
x)
 
φ′(w[p]T
j2
x)−φ′(wT
j2x)

·(aT x)2. It is easy to verify there ex-
ists a group of orthonormal vectors such that B = {a, b, c, a⊥
4 , · · · , a⊥
d } with {a, b, c} spans a sub-"
EX,0.847682119205298,"space that contains a, wj2 and w∗
j2. Then, for any x, we have a unique z =
h
z1,
z2,
· · · ,
zd
iT"
EX,0.8486281929990539,"such that
x = z1a + z2b + z3c + · · · + zda⊥
d .
Also, since x ∼N(0, δ2Id), we have z ∼N(0, δ2Id). Then, we have"
EX,0.8495742667928098,"I =Ez1,z2,z3|φ′ 
wT
j2x

−φ′ 
w[p]T
j2
x

| · |aT x|2"
EX,0.8505203405865658,"=
Z
|φ′ 
wT
j2x

−φ′ 
w[p]T
j2
x

| · |aT x|2 · fZ(z1, z2, z3)dz1dz2dz3,"
EX,0.8514664143803217,"where x = z1a + z2b + z3c and fZ(z1, z2, z3) is probability density function of (z1, z2, z3). Next,
we consider spherical coordinates with z1 = Rcosφ1, z2 = Rsinφ1sinφ2, z3 = Rsinφ1cosφ2.
Hence,"
EX,0.8524124881740776,"I =
Z
|φ′ 
wT
j2x

−φ′ 
w[p]T
j2
x

| · |R cos φ1|2 · fZ(R, φ1, φ2)R2 sin φ1dRdφ1dφ2.
(103)"
EX,0.8533585619678334,"It is easy to verify that φ′ 
wT
j2x

only depends on the direction of x and"
EX,0.8543046357615894,"fZ(R, φ1, φ2) =
1"
EX,0.8552507095553453,"(2πδ2)
3
2 e−
z2
1+z2
2+z2
3
2δ2
=
1"
EX,0.8561967833491012,"(2πδ2)
3
2 e−R2 2δ2"
EX,0.8571428571428571,Published as a conference paper at ICLR 2022
EX,0.8580889309366131,"only depends on R. Then, we have"
EX,0.859035004730369,"I(i2, j2)"
EX,0.8599810785241249,"=
Z
|φ′ 
wT
j2(x/R)

−φ′ 
w[p]T
j2
(x/R)

| · |R cos φ1|2 · fZ(R)R2 sin φ1dRdφ1dφ2 =
Z ∞"
EX,0.8609271523178808,"0
R4fz(R)dR
Z π 0 Z 2π"
EX,0.8618732261116367,"0
| cos φ1|2 · sin φ1 · |φ′ 
wT
j2(x/R)

−φ′ 
w[p]T
j2
(x/R)

|dφ1dφ2"
EX,0.8628192999053926,"(a)
≤3δ2 ·
Z ∞"
EX,0.8637653736991485,"0
R2fz(R)dR
Z π 0 Z 2π"
EX,0.8647114474929044,"0
sin φ1 · |φ′ 
wT
j2(x/R)

−φ′ 
w[p]T
j2
(x/R)

|dφ1dφ2"
EX,0.8656575212866604,"=3δ2 · Ez1,z2,z3
φ′ 
wT
j2x

−φ′ 
w[p]T
j2
x

|"
EX,0.8666035950804163,"≤3δ2 · Ex
φ′ 
wT
j2x

−φ′ 
w[p]T
j2
x

|,
(104)"
EX,0.8675496688741722,"where the inequality (a) is derived from the fact that |cosφ1| ≤1 and
Z ∞"
EX,0.8684957426679281,"0
R4
1"
EX,0.8694418164616841,"(2πδ2)
3
2 e−R2"
EX,0.8703878902554399,"2δ2 dR =
Z ∞"
EX,0.8713339640491958,"0
−R3δ2"
EX,0.8722800378429517,"(2πδ2)
3
2 d(e−R2 2δ2 ) =
Z ∞"
EX,0.8732261116367077,"0
e−R2"
EX,0.8741721854304636,2δ2 d R3δ2
EX,0.8751182592242195,"(2πδ2)
3
2"
EX,0.8760643330179754,"=3δ2
Z ∞"
EX,0.8770104068117314,"0
R2
1"
EX,0.8779564806054873,"(2πδ2)
3
2 e−R2"
EX,0.8789025543992431,2δ2 dR. (105)
EX,0.879848628192999,"Deﬁne a set A1 = {x|(w[p]T
j2
x)(wT
j2x) < 0}. If x ∈A1, then w[p]T
j2
x and wT
j2x have different"
EX,0.8807947019867549,"signs, which means the value of φ′(wT
j2x) and φ′(w[p]T
j2
x) are different. This is equivalent to say
that"
EX,0.8817407757805109,"|φ′(wT
j2x) −φ′(w[p]T
j2
x)| =

1, if x ∈A1
0, if x ∈Ac
1
.
(106)"
EX,0.8826868495742668,"Moreover, if x ∈A1, then we have"
EX,0.8836329233680227,"|w[p]T
j2
x| ≤|w[p]T
j2
x −wT
j2x| ≤∥w[p]
j2 −wj2∥2 · ∥x∥2.
(107)"
EX,0.8845789971617786,Let us deﬁne a set A2 such that
EX,0.8855250709555346,"A2 =
n
x

|w[p]T
j2
x|
∥w∗
j2∥2∥x∥2
≤∥w∗
j2 −wj2∥2"
EX,0.8864711447492905,"∥w∗
j2∥2"
EX,0.8874172185430463,"o
=
n
θx,w∗
j2"
EX,0.8883632923368022,"| cos θx,w[p]
j2 | ≤
∥w[p]
j2 −wj2∥2"
EX,0.8893093661305582,"∥w[p]
j2 ∥2"
EX,0.8902554399243141,"o
. (108)"
EX,0.89120151371807,"Hence, we have that"
EX,0.8921475875118259,"Ex|φ′(wT
j2x) −φ′(w[p]T
j2
x)|2 =Ex|φ′(wT
j2x) −φ′(w[p]T
j2
x)|"
EX,0.8930936613055819,"=Prob(x ∈A1)
≤Prob(x ∈A2). (109)"
EX,0.8940397350993378,"Since x ∼N(0, δ2∥a∥2
2I), θx,w[p]
j2 belongs to the uniform distribution on [−π, π], we have"
EX,0.8949858088930936,"Prob(x ∈A2) =
π −arccos
∥w[p]
j2 −wj2∥2"
EX,0.8959318826868495,"∥w[p]
j2 ∥2
π
≤1"
EX,0.8968779564806055,"π tan(π −arccos
∥w[p]
j2 −wj2∥2"
EX,0.8978240302743614,"∥w[p]
j2 ∥2
) = 1"
EX,0.8987701040681173,"π cot(arccos
∥w[p]
j2 −wj2∥2"
EX,0.8997161778618732,"∥w[p]
j2 ∥2
) ≤2"
EX,0.9006622516556292,"π
∥w[p]
j2 −wj2∥2"
EX,0.9016083254493851,"∥w[p]
j2 ∥2
. (110)"
EX,0.902554399243141,Published as a conference paper at ICLR 2022
EX,0.9035004730368968,"Hence, (104) and (110) suggest that"
EX,0.9044465468306528,I ≤6δ2
EX,0.9053926206244087,"π
∥wj2 −w[p]
j2 ∥2
σK
· ∥a∥2
2.
(111)"
EX,0.9063386944181646,The same bound that shown in (111) holds for P2 as well.
EX,0.9072847682119205,P3 and P4 satisfy (111) except for changing δ2 to ˜δ2.
EX,0.9082308420056765,"Therefore, we have"
EX,0.9091769157994324,∥∇2f(W [p]; p) −∇2f(W ; p)∥2
EX,0.9101229895931883,"= max
∥α∥2≤1"
EX,0.9110690633869442,"αT (∇2f(W [p]; p) −∇2f(W ; p))α ≤ K
X j1=1 K
X j2=1 αT
j1"
EX,0.9120151371807,"
∂2f
∂wj1∂wj2
(W [p]; p) −
∂2f
∂wj1∂wj2
(W ; p)

αj2  ≤1 K2 K
X j1=1 K
X j2=1"
EX,0.912961210974456,"
λ∥P1 + P2∥2 + (1 −λ)∥P3 + P4∥2

∥αj1∥2∥αj2∥2 ≤1 K2 K
X j1=1 K
X"
EX,0.9139072847682119,"j2=1
4(λδ2 + (1 −λ)˜δ2)
∥w[p]
j2 −wj2∥2"
EX,0.9148533585619678,"σK
∥αj1∥2∥αj2∥2 ≤4"
EX,0.9157994323557237,"K
 
λδ2 + (1 −λ)˜δ2
· ∥W [p] −W ∥2 σK
, (112)"
EX,0.9167455061494797,"where α ∈RKd and αj ∈Rd with α = [αT
1 , αT
2 , · · · , αT
K]T ."
EX,0.9176915799432356,"I
INITIALIZATION VIA TENSOR METHOD"
EX,0.9186376537369915,"In this section, we brieﬂy summarize the tensor initialization in (Zhong et al., 2017) by studying the
target function class as y = 1 K K
X"
EX,0.9195837275307474,"j=1
v∗
j φ(w∗T
j x),
(113)"
EX,0.9205298013245033,"where v∗
j ∈R. Note that for ReLU function, we have v∗
j φ(w∗T
j x) = sign(v∗
j )φ(|v∗
j |w∗T
j x).
Without loss of generalization, we can assume v∗
j ∈{+1, −1}. Additionally, it is clear that the
function studied in (2) is the special case of (113) when v∗
j = 1 for all j. In addition, Theorem 5.6
in (Zhong et al., 2017) show that the sign of v∗
j can be directly recovered using tensor initialization,
which indicates the the equivalence of (2) and (113) when using tensor initialization."
EX,0.9214758751182592,We ﬁrst deﬁne some high order momenta in the following way:
EX,0.9224219489120151,"M1 = Ex{yx} ∈Rd,
(114)"
EX,0.923368022705771,"M2 = Ex
h
y
 
x ⊗x −δ2I
i
∈Rd×d,
(115)"
EX,0.924314096499527,"M3 = Ex
h
y
 
x⊗3 −xe⊗δ2I
i
∈Rd×d×d,
(116)"
EX,0.9252601702932829,where Ex is the expectation over x and z⊗3 := z ⊗z ⊗z. The operator e⊗is deﬁned as
EX,0.9262062440870388,"ve⊗Z = d2
X"
EX,0.9271523178807947,"i=1
(v ⊗zi ⊗zi + zi ⊗v ⊗zi + zi ⊗zi ⊗v),
(117)"
EX,0.9280983916745507,for any vector v ∈Rd1 and Z ∈Rd1×d2.
EX,0.9290444654683065,Published as a conference paper at ICLR 2022
EX,0.9299905392620624,"Following the same calculation formulas in the Claim 5.2 (Zhong et al., 2017), there exist some
known constants ψi, i = 1, 2, 3, such that M1 = K
X"
EX,0.9309366130558183,"j=1
ψ1 · ∥w∗
j ∥2 · w∗
j,
(118) M2 = K
X"
EX,0.9318826868495743,"j=1
ψ2 · ∥w∗
j ∥2 · w∗
jw∗T
j ,
(119) M3 = K
X"
EX,0.9328287606433302,"j=1
ψ3 · ∥w∗
j ∥2 · w∗⊗3
j
,
(120)"
EX,0.9337748344370861,"where w∗
j = w∗
j /∥w∗
j ∥2 in (114)-(116) is the normalization of w∗
j . Therefore, we can see that the
information of {w∗
j }K
j=1 are separated as the direction of wj and the magnitude of wj in M1, M2
and M3."
EX,0.934720908230842,"M1, M2 and M3 can be estimated through the samples

(xn, yn)
	N
n=1, and let c
M1, c
M2, c
M3
denote the corresponding estimates. First, we will decompose the rank-K tensor M3 and obtain the
{w∗
j}K
j=1. By applying the tensor decomposition method (Kuleshov et al., 2015) to c
M3, the outputs,"
EX,0.935666982024598,"denoted by bw
∗
j, are the estimations of {sjw∗
j}K
j=1, where sj is an unknown sign. Second, we will
estimate sj, v∗
j and ∥w∗
j ∥2 through M1 and M2. Note that M2 does not contain the information of
sj because s2
j is always 1. Then, through solving the following two optimization problem:"
EX,0.9366130558183539,"bα1 = arg min
α1∈RK :
 c
M1 − K
X"
EX,0.9375591296121097,"j=1
ψ1α1,j bw
∗
j
,"
EX,0.9385052034058656,"bα2 = arg min
α2∈RK :
 c
M2 − K
X"
EX,0.9394512771996215,"j=1
ψ2α2,j bw
∗
j bw
∗T
j
, (121)"
EX,0.9403973509933775,The estimation of sj can be given as
EX,0.9413434247871334,"ˆsj = sign(bα1,j/bα2,j)."
EX,0.9422894985808893,"Also, we know that |bα1,j| is the estimation of ∥w∗
j ∥and"
EX,0.9432355723746452,"ˆvj = sign(bα1,j/sj) = sign(bα2,j)."
EX,0.9441816461684012,"Thus, W (0) is given as
h
sign(bα2,1)bα1,1 bw
∗
1,
· · · ,
sign(bα2,K)bα1,K bw
∗
K
i
."
EX,0.945127719962157,Subroutine 1 Tensor Initialization Method
EX,0.9460737937559129,"1: Input: labeled data D = {(xn, yn)}N
n=1;
2: Partition D into three disjoint subsets D1, D2, D3;
3: Calculate c
M1, c
M2 following (114), (115) using D1, D2, respectively;
4: Obtain the estimate subspace bV of c
M2;
5: Calculate c
M3( bV , bV , bV ) through D3;"
EX,0.9470198675496688,"6: Obtain {bsj}K
j=1 via tensor decomposition method (Kuleshov et al., 2015) on c
M3( bV , bV , bV );
7: Obtain bα1, bα2 by solving optimization problem (121);"
EX,0.9479659413434248,"8: Return: w(0)
j
= sign(bα2,j)bα1,j bV buj and v(0)
j
= sign(bα2,j), j = 1, ..., K."
EX,0.9489120151371807,"To reduce the computational complexity of tensor decomposition, one can project c
M3 to a lower-
dimensional tensor (Zhong et al., 2017). The idea is to ﬁrst estimate the subspace spanned by
{w∗
j }K
j=1, and let bV denote the estimated subspace. Moreover, we have"
EX,0.9498580889309366,"M3( bV , bV , bV ) = Ex
h
y
 
( bV T x)⊗3 −( bV T x)e⊗Ex( bV T x)( bV T x)T i
∈RK×K×K,
(122)"
EX,0.9508041627246925,Published as a conference paper at ICLR 2022
EX,0.9517502365184485,"Then, one can decompose the estimate c
M3( bV , bV , bV ) to obtain unit vectors {ˆsj}K
j=1 ∈RK. Since
w∗lies in the subspace V , we have V V T w∗
j = w∗
j. Then, bV ˆsj is an estimate of w∗
j. The
initialization process is summarized in Subroutine 1."
EX,0.9526963103122044,"J
CLASSIFICATION PROBLEMS"
EX,0.9536423841059603,"The framework in this paper is extendable to binary classiﬁcation problem. For binary classiﬁcation
problem, the output y given input x is deﬁned as"
EX,0.9545884578997161,"Prob{y = 1} = g(W ∗; x)
(123)"
EX,0.9555345316934721,"with some ground truth parameter W ∗. To guarantee the output is within [0, 1], the activation
function is often used as sigmoid. For classiﬁcation, the loss function is cross-entropy, and the
objective function over labeled data D is deﬁned as"
EX,0.956480605487228,fD(W ) = 1 N X
EX,0.9574266792809839,"(xn,yn)∈D
−yn log g(W ; xn) −(1 −yn) log(1 −g(W ; xn)).
(124)"
EX,0.9583727530747398,The expectation of objective function can be written as
EX,0.9593188268684958,"EDfD(W ) =E(x,y) −y log(g(W ; xn)) −(1 −y) log(1 −g(W ; x))"
EX,0.9602649006622517,=ExE(y|x) −y log(g(W ; xn)) −(1 −y) log(1 −g(W ; x))
EX,0.9612109744560076,"=Ex
h
−g(W ∗; x) log(g(W ; xn)) −(1 −g(W ∗; x)) log(1 −g(W ; xn))
i
(125)"
EX,0.9621570482497634,Please note that (125) is exactly the same as (32) with λ = 1 when the loss function is squared loss.
EX,0.9631031220435194,"For cross entropy loss function, the second order derivative of (125) is calculated as"
EX,0.9640491958372753,"∂fD(W )
∂wj∂wk
= 1"
EX,0.9649952696310312,"N [
yn
g2(W ; x) +
1 −yn
(1 −g(W ; x))2 ] · φ′(wT
j x)φ′(wT
k x)xxT .
(126)"
EX,0.9659413434247871,"when j ̸= k. Refer to (88) in (Fu et al., 2020) or (132) in (Zhang et al., 2020b), we have

yn(φ′(wT
j x)φ′(wT
k x))
g2(W ; x)"
EX,0.9668874172185431,"2 ≤

φ′(wT
j x)φ′(wT
k x)
g2(W ; x)"
EX,0.967833491012299,"2 ≤K2.
(127)"
EX,0.9687795648060549,"Following similar steps in (90), from Deﬁntion 2, we know that αT
j
∂fD(W )
∂wj∂wk αk belongs to the sub-
exponential distribution. Therefore, similiar results for objective function with cross-entropy loss
can be established as well. One can check (Fu et al., 2020) or (Zhang et al., 2020b) for details."
EX,0.9697256385998108,"K
ONE-HIDDEN LAYER NEURAL NETWORK WITH TOP LAYER WEIGHTS"
EX,0.9706717123935666,"For a general one-hidden layer neural network, the output of the neural network is deﬁned as"
EX,0.9716177861873226,"g(W , v; x) = 1 K K
X"
EX,0.9725638599810785,"j=1
vjφ(wT
j x),
(128)"
EX,0.9735099337748344,"where v = [v1, v2, · · · , vK] ∈RK. Then, the target function can be deﬁned as"
EX,0.9744560075685903,"y = g(W ∗, v∗; x) = 1 K K
X"
EX,0.9754020813623463,"j=1
v∗
j φ(w∗T
j x)
(129)"
EX,0.9763481551561022,for some unknown weights W ∗and v∗.
EX,0.9772942289498581,"In the following paragraphs, we will provide a short description for the equivalence of (129) and (2)
in theoretical analysis. Note that for ReLU functions, we have vjφ(wT
j x) = sign(vj)φ(|vj|wT
j x)."
EX,0.978240302743614,Published as a conference paper at ICLR 2022
EX,0.97918637653737,"Without loss of generalization, we can assume vj, v∗
j ∈{+1, −1} for all j ∈[K]5. From Appendix
I, we know that the sign of v∗
j can exactly estimated through tensor initialization. There, we can
focus on analysis the neural network in the form as"
EX,0.9801324503311258,"g(W ; x) = 1 K K
X"
EX,0.9810785241248817,"j=1
v∗
j φ(wT
j x).
(130)"
EX,0.9820245979186376,"Considering the objective function in (1) and population risk function in (17), we have ∂ˆf"
EX,0.9829706717123936,"∂wk
(W ) −∂f"
EX,0.9839167455061495,"∂wk
(W ; p)

2"
EX,0.9848628192999054,"=

λ
K2N K
X"
EX,0.9858088930936613,"j=1
v∗
j
h
N
X n=1"
EX,0.9867549668874173," 
φ(wT
j xn) −φ(w∗T
j xn)

xn −Ex
 
φ(wT
j x) −φ(w[p]T
j
x)

x
i"
EX,0.9877010406811731,+ 1 −λ
EX,0.988647114474929,"K2M v∗
j K
X j=1 h
M
X m=1"
EX,0.9895931882686849," 
φ(wT
j exm) −φ( e
wT
j exm)
exm −Eex
 
φ(wT
j ex) −φ(w[p]T
j
ex)
ex
i
2 ≤ K
X"
EX,0.9905392620624409,"j=1
·|v∗
j | ·

λ
K2N h
N
X n=1"
EX,0.9914853358561968," 
φ(wT
j xn) −φ(w∗T
j xn)

xn −Ex
 
φ(wT
j x) −φ(w[p]T
j
x)

x
i"
EX,0.9924314096499527,"+ 1 −λ K2M h
M
X m=1"
EX,0.9933774834437086," 
φ(wT
j exm) −φ( e
wT
j exm)
exm −Eex
 
φ(wT
j ex) −φ(w[p]T
j
ex)
ex
i
2 = K
X j=1 λ
K2N h
N
X n=1"
EX,0.9943235572374646," 
φ(wT
j xn) −φ(w∗T
j xn)

xn −Ex
 
φ(wT
j x) −φ(w[p]T
j
x)

x
i"
EX,0.9952696310312205,"+ 1 −λ K2M h
M
X m=1"
EX,0.9962157048249763," 
φ(wT
j exm) −φ( e
wT
j exm)
exm −Eex
 
φ(wT
j ex) −φ(w[p]T
j
ex)
ex
i
2, (131)"
EX,0.9971617786187322,"which is exact the same as (89). Similar results can be derived for Lemma 12. Therefore, the
conclusions and proofs of Lemma 1 and Lemma 2 does not change at all."
EX,0.9981078524124882,"Additionally, ﬁxing the second-layer weights and only training the hidden layer is the state-of-the-
art practice in analyzing two-layer neural networks (Arora et al., 2019b;a; Allen-Zhu et al., 2019;
Safran & Shamir, 2018; Li & Liang, 2018; Brutzkus & Globerson, 2017; Oymak & Soltanolkotabi,
2018; Zhang et al., 2019). Additionally, as indicated in (Safran & Shamir, 2018), training a one-
hidden-layer neural network with all vj ﬁxed as 1 has intractable many spurious local minima, which
indicates that training problem is not trivial."
EX,0.9990539262062441,"5To see this, one can view |v∗
j |w∗
j as the new ground truth weights, and the goal for this paper is to recover
the new ground truth weights."
