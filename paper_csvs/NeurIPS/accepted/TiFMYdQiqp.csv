Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.002793296089385475,"Two-photon optogenetics has transformed our ability to probe the structure and
function of neural circuits. However, achieving precise optogenetic control of
neural ensemble activity has remained fundamentally constrained by the problem
of off-target stimulation (OTS): the inadvertent activation of nearby non-target
neurons due to imperfect confinement of light onto target neurons. Here we propose
a novel computational approach to this problem called Bayesian target optimisation.
Our approach uses nonparametric Bayesian inference to model neural responses
to optogenetic stimulation, and then optimises the laser powers and optical target
locations needed to achieve a desired activity pattern with minimal OTS. We
validate our approach in simulations and using data from in vitro experiments,
showing that Bayesian target optimisation considerably reduces OTS across all
conditions we test. Together, these results establish our ability to overcome OTS,
enabling optogenetic stimulation with substantially improved precision."
INTRODUCTION,0.00558659217877095,"1
Introduction"
INTRODUCTION,0.008379888268156424,"A key technological goal in neuroscience is to gain precise control over the activity of neurons. Cur-
rently, one of the most promising approaches for achieving such control is two-photon optogenetics
[1–4]. This technique relies on the use of two-photon excitation to activate opsin molecules expressed
in the somatic membrane, allowing individual neurons to be targeted for stimulation. Holographic
optogenetics further extends this technique by focusing two-photon excitation into ∼10 µm disks
of light that illuminate all of a neuron’s opsin molecules in parallel [5–9]. Replicating this illumi-
nation pattern across many neurons at once then grants simultaneous optogenetic control of entire
neural ensembles [10–12]. However, the spatial precision of holographic optogenetics has remained
fundamentally limited by the problem of off-target stimulation (OTS): if multiple opsin-expressing
neurons lie in close proximity (in the most extreme case, if their membranes are in physical contact),
two-photon excitation will frequently activate opsin molecules in each neuron when attempting to
stimulate only one. This can inadvertently elicit spikes in non-target neurons, compromising the
precision and specificity of the optogenetic manipulation [13]."
INTRODUCTION,0.0111731843575419,"Previous attempts at overcoming OTS have been either optical or molecular in nature (e.g. by using
temporal focusing [2, 6, 7, 14] or improving the soma-targeting of the opsin [15, 16, 10]), but
have not yet achieved ""true"" single-cell precision under many experimental conditions. Frequently,
experimenters will simply express opsin sparsely in a population to avoid OTS, as this reduces
the number of nearby opsin-expressing neurons that could be mistakenly activated [17]. However,
sparse opsin expression reduces the number of neurons that can potentially be probed during an"
INTRODUCTION,0.013966480446927373,"experiment, and therefore limits the kinds of scientific questions that can be addressed using two-
photon optogenetics. Conversely, in an ideal experiment, one could precisely stimulate any neuron
despite a moderate or high density of opsin-expressing cells."
INTRODUCTION,0.01675977653631285,"Here, we develop a novel computational strategy for all-optical experiments [18–21] that reduces
(and in some cases entirely eliminates) OTS (Figure 1a, b). The key insight is that heterogeneity in
opsin expression and intrinsic excitability causes neurons to have different sensitivities to optical
stimulation. This implies that in some cases laser power could be safely turned down to prevent
the spiking of a nearby non-target neuron that is weakly driven by stimulation while still spiking
a target neuron that is strongly driven by stimulation. Further, the spatial arrangement of neurons
can be exploited by moving a holographic target off of a neuron’s nucleus (the typical stimulation
point) towards a less dense area (e.g. towards neuropil or less photosensitive neurons) while still
exciting a sufficient number of the target neuron’s opsin molecules to elicit a spike. While some
prior experimental research has considered cell-specific tuning of laser powers [22], our advance is to
identify both the optimal laser powers and target locations automatically using efficient Bayesian
techniques."
INTRODUCTION,0.019553072625698324,"To achieve highly precise optogenetic ensemble control, we propose a two-phase process called
Bayesian target optimisation (Bataro). In the first phase, we map the ""optogenetic receptive field""
(ORF) of each neuron by stimulating at various locations around cell nuclei and at a range of laser
powers to test whether they elicit spikes. To infer these ORFs without exhaustively testing every
combination of location and power, we use Gaussian processes (GPs) to encode prior knowledge
about how neurons respond to optogenetic stimulation. Further, we propose to use holographic
stimulation to test multiple locations around one or many neurons simultaneously, ensuring that the
mapping phase completes quickly. This also allows us to model how neurons integrate two-photon
excitation from multiple nearby holograms. In the second phase, we then exploit knowledge of the
ORFs to optimise holographic targets. We use properties of the GP to infer gradients of an objective
function at a spatial resolution that exceeds the original sampling resolution, enabling us to optimise
for the exact holographic targets and laser powers needed to evoke a specific neural activity pattern."
RELATED WORK,0.0223463687150838,"2
Related work"
RELATED WORK,0.025139664804469275,"Our work is related to prior research in three areas: GP-based receptive field inference, optimal
stimulus design, and statistical methods for estimating connectivity using optogenetic stimulation.
Since ref. [23], many studies have used GPs to infer the relationship between neural spiking and
multi-dimensional covariates. This includes using GPs to infer place fields [24, 25] and orientation
preference maps [26], as well as with Bayesian active learning techniques for inferring sensory
receptive fields [27, 28]. However, none to our knowledge have used GP inference to model responses
to optogenetic stimulation. Closed-loop methods for optimal control of neural activity using one-
photon or electrical stimulation have been recently explored [29–34], though these approaches lack
the necessary spatial specificity for highly precise ensemble control. Ref. [35] considers optimising
spike-timing using two-photon stimulation (in addition to electrical stimulation), but focused on
single neurons and did not use GP estimation methods. Finally, a number of papers have developed
statistical models of optogenetic data to infer functional or synaptic connectivity [36–43], but do not
consider identifying the exact stimulation parameters needed to evoke specific activity patterns. Here,
we unify these three approaches to develop a novel computational framework for optimal holographic
stimulation of neural ensembles."
METHODS,0.027932960893854747,"3
Methods"
OPTOGENETIC RECEPTIVE FIELD MODEL,0.030726256983240222,"3.1
Optogenetic receptive field model"
OPTOGENETIC RECEPTIVE FIELD MODEL,0.0335195530726257,"Given a population of N neurons, we first wish to learn ORF functions gn that model how each neuron
responds to optogenetic stimulation at different laser powers and locations near the cell soma. Ideally,
ORF mapping should be completed quickly, stimulating as few times as possible, so that stimulus
optimisation and the desired experiment can begin. Therefore, an ORF model should leverage prior
knowledge of how neurons respond to stimulation. Importantly, spike probability should increase
monotonically with laser power until saturation [42], and the ORF should approximately match
the shape of the somatic membrane (though enlarged to account for the ∼10 µm diameter of the spike"
OPTOGENETIC RECEPTIVE FIELD MODEL,0.036312849162011177,"no 
response"
OPTOGENETIC RECEPTIVE FIELD MODEL,0.03910614525139665,Holographic
OPTOGENETIC RECEPTIVE FIELD MODEL,0.04189944134078212,"ensemble 
stimulation a
c"
OPTOGENETIC RECEPTIVE FIELD MODEL,0.0446927374301676,"opsin concentration
low
high"
OPTOGENETIC RECEPTIVE FIELD MODEL,0.04748603351955307,"Target neuron
Optimised holo
Naive holo
b"
OPTOGENETIC RECEPTIVE FIELD MODEL,0.05027932960893855,"Figure 1: Off-target stimulation with two-photon optogenetics. (a) Two-photon holographic opto-
genetics can be used to elicit spikes in specific ensembles of experimenter-selected neurons. (b)
OTS arises due to an inability to confine two-photon excitation to the soma of a target neuron. By
repositioning the hologram away from the soma, OTS could be avoided while still activating the target
neuron. (c) Data from real two-photon optogenetics experiment showing that at high power (e.g. 40
mW) a neuron can be activated from 15-20 µm away, though this depends on the specific pattern of
opsin expression at the soma and proximal dendrites. Red and gray circles indicate locations where
stimulation resulted in successful or unsuccessful spikes. Colour map shows the inferred probability
of spiking (i.e., the ORF) using the log-barrier Newton method from Subsection 3.2. As the number of
sampled locations and laser powers increases, the GP model adapts to the particular ORF shape (see
supplementary material for the prior mean). This shape can then be exploited to precisely optimise
holographic stimuli. Data from PV-neuron in L2/3 of V1 expressing the soma-targeted, excitatory
opsin ChroME2f [44]."
OPTOGENETIC RECEPTIVE FIELD MODEL,0.05307262569832402,"holographic disk [22]). However, any residual expression of opsin molecules in the proximal dendrites
of a neuron creates unique differences in its ORF shape compared to other neurons (Figure 1c).
Further, neurons can express opsin in variable concentrations and vary in their intrinsic excitability,
leading to an unpredictable dependence of spiking on power. Thus, we need an approach to modelling
an ORF that roughly describes the typical shape and photosensitivity of a cell, but that can flexibly
adapt to variation across neurons."
OPTOGENETIC RECEPTIVE FIELD MODEL,0.055865921787709494,"To simultaneously account for these factors, we use a novel variant of the GP-Bernoulli model.
Let ynt ∈{0, 1} denote the response of neuron n on trial t to a holographic stimulus xt ∈RJ×3.
As our approach is designed for all-optical experiments, the response to stimulation is assumed
to be observed for all neurons at once using calcium or voltage imaging. Each stimulus delivers
two-photon excitation to J ≥1 different target locations, with xj
t = (cj
1t, cj
2t, Ij
t ) ∈R3 representing
the two-dimensional coordinates and laser power of the jth target (though note that we can also
handle three-dimensional hologram coordinates without any substantial changes to the model). While
in some cases the targets will be far enough apart in space to not interact with each other, frequently a
neuron will integrate two-photon excitation from multiple nearby targets, increasing the risk of OTS.
To account for this, we model the probability of evoking a spike in neuron n by summing across all J
points on that neuron’s ORF,"
OPTOGENETIC RECEPTIVE FIELD MODEL,0.05865921787709497,"ynt ∼Bernoulli(σ(γn(xt) −θn)),
γn(xt) = J
X"
OPTOGENETIC RECEPTIVE FIELD MODEL,0.061452513966480445,"j=1
gn(xj
t),
(1)"
OPTOGENETIC RECEPTIVE FIELD MODEL,0.06424581005586592,"where σ is the logistic sigmoid function and θn ∈R is a scalar threshold. We model each ORF using
a three-dimensional GP prior that describes the effect of stimulating at a given location and power:
gn ∼GP(mn(·), k(·, ·)), where mn and k are respectively the mean and covariance functions of
the GP. During inference (as discussed below) we constrain gn to be non-negative, which ensures
that stimulation cannot have an inhibitory effect. Further, using a non-negativity constraint rather
than (e.g.) applying a rectifying nonlinearity to gn guarantees that the posterior distribution remains
log-concave, facilitating tractable identification of the global optimum."
OPTOGENETIC RECEPTIVE FIELD MODEL,0.0670391061452514,"To encode prior knowledge about optogenetic stimulation, the mean function should have the property
that the probability of evoking a spike increases with laser power but decays quickly as the hologram"
OPTOGENETIC RECEPTIVE FIELD MODEL,0.06983240223463687,"is positioned further away from the nucleus. To this end, we set"
OPTOGENETIC RECEPTIVE FIELD MODEL,0.07262569832402235,"mn(x) = ρI exp(−∥c −Ln∥2/σ2
m)
(2)"
OPTOGENETIC RECEPTIVE FIELD MODEL,0.07541899441340782,"for n = 1, . . . , N (note that we suppress reference to the target dimension j for notational clarity here
and in the definition of the covariance function below). Here c = (c1, c2) denotes the coordinates of
the holographic target, Ln is the location of neuron n, and ρ can be loosely interpreted as the average
opsin expression level, determining how laser power affects the probability of spiking. While we
treat ρ and σ2
m as static hyperparameters, in future work one could consider a hierarchical model
where the mean function is also learned, with its accuracy improving as additional ORFs are probed."
OPTOGENETIC RECEPTIVE FIELD MODEL,0.0782122905027933,"We model the covariance between points on the ORF using the radial basis function (RBF) kernel k,
which regularises the ORF by encouraging it to vary smoothly through space and power. However,
we note that other covariance kernels could be used here provided that they are differentiable with
respect to x. We define"
OPTOGENETIC RECEPTIVE FIELD MODEL,0.08100558659217877,"k(x, x′) = α2 exp

−1"
OPTOGENETIC RECEPTIVE FIELD MODEL,0.08379888268156424,"2(x −x′)⊤Λ(x −x′)

+ σ2
dδx,x′,
(3)"
OPTOGENETIC RECEPTIVE FIELD MODEL,0.08659217877094973,"where Λ = diag(λs, λs, λI) is a diagonal matrix with each diagonal term giving the characteristic
lengthscale for the corresponding GP dimension. We assume that the lengthscales λs in the two
spatial dimensions are equal (a typical assumption in holography, see e.g. ref. [6]), but take a different
lengthscale λI for the laser power dimension. Finally, we denote the hyperparameters of the ORF
prior by ϕ = (α2, σ2
d, λs, λI, ρ, σ2
m)."
INFERENCE,0.0893854748603352,"3.2
Inference"
INFERENCE,0.09217877094972067,"During an ORF mapping experiment we first collect calibration data by performing stimulation
in a series of trials x1, . . . , xT , where each xt targets J different locations and laser powers near
a random set of neurons. Then we combine these stimuli with the corresponding observations of
any evoked activity y:,1, . . . , y:,T to estimate the ORFs. Here each y:,t ∈{0, 1}N describes the
population response to the stimulus xt. Due to the non-negativity constraints on gn, the posterior
p(gn | yn, {xt}T
t=1, θn, ϕ) is not itself a GP, and hence we perform maximum a posteriori (MAP)
inference rather than attempting to obtain a complete description of posterior uncertainty (though
see the supplementary material for a full treatment of posterior uncertainty in the J = 1 case). To
this end, the MAP estimates are obtained by maximising the log-posterior, which, via Bayes rule, is
equivalent to computing"
INFERENCE,0.09497206703910614,"ˆgn, ˆθn = argmax
gn,θn ( T
X"
INFERENCE,0.09776536312849161,"t=1
ln p(ynt | xt, gn, θn) + ln p(gn(x1), . . . , gn(xT ) | ϕ) ) (4)"
INFERENCE,0.1005586592178771,"such that gn(xt) ≥0 for t = 1, . . . , T."
INFERENCE,0.10335195530726257,"Note that we have abbreviated ˆgn(X) (the MAP version of the ORF) as ˆgn. To solve Equation 4 we
alternate between using Newton’s method with a log-barrier to update gn (such that the optimised
ORFs respect the non-negativity constraints), and performing gradient descent steps for updating θn.
We also adaptively set the Newton step-size using a standard backtracking line-search method."
OPTIMISATION APPROACH,0.10614525139664804,"3.3
Optimisation approach"
OPTIMISATION APPROACH,0.10893854748603352,"Given the estimated ORFs, we then aim to identify holographic stimuli that evoke specific neural
activity patterns as accurately as possible (i.e., minimising off-target activation). To do this, we
introduce a novel optimisation approach that exploits properties of the GP to compute gradients of an
error function between a target activity pattern and the (predicted) evoked activity. To this end, let
G = {ˆgn, ˆθn}N
n=1 be the MAP-estimated ORFs, and define the predicted evoked activity as"
OPTIMISATION APPROACH,0.11173184357541899,"ˆy(x, G) = (σ(ˆγ1(x) −ˆθ1), . . . , σ(ˆγN(x) −ˆθN)) ∈RN,
(5)"
OPTIMISATION APPROACH,0.11452513966480447,"where ˆγn(x) = PJ
j=1 ˆgn(xj). Let Ω∈{0, 1}N denote a target activity pattern. The optimal
holographic stimulus is then"
OPTIMISATION APPROACH,0.11731843575418995,"xoptimal = argmin
x
∥Ω−ˆy(x, G)∥2 such that 0 ≤I ≤Imax.
(6)"
OPTIMISATION APPROACH,0.12011173184357542,"Note that we include Imax as an upper bound on the laser power, which can be set to match the power
practically deliverable by the microscopy system or to prevent tissue damage due to excess heating."
OPTIMISATION APPROACH,0.12290502793296089,"We propose to solve Equation 6 using a projected gradient descent algorithm. While for the ORF
mapping phase we only need to compute the ORFs ˆgn at a small set of stimulation points xt, for the
optimisation phase we must evaluate the gradients of Equation 6 (and therefore of the ORFs) at a
series of new, unobserved points constituting an optimisation path. However, it is not immediately
obvious how to evaluate these gradients for a general nonparametric function gn. The key idea
for our approach is that at each step, gradient descent will provide an updated estimate x∗of the
optimal stimulus, which will act as a ""test point"" commonly used in GP regression. We then leverage
properties of the GP to perform inference of the ORF gradients at x∗, and subsequently perform a
gradient descent update that reduces the value of the objective function in Equation 6."
OPTIMISATION APPROACH,0.12569832402234637,"Inferring the ORF gradients relies on the fact that a GP and its derivative are jointly GP-distributed,
and hence the derivative can be inferred just from a small number of observations of the GP itself. To
this end, note that the covariance between a GP and its derivative is given by [45, Sec 9.4]"
OPTIMISATION APPROACH,0.12849162011173185,"cov

gn(xt),
∂
∂x∗
d
gn(x∗)

= ∂k(xt, x∗)"
OPTIMISATION APPROACH,0.13128491620111732,"∂x∗
d
,
(7)"
OPTIMISATION APPROACH,0.1340782122905028,"where d is any dimension of x∗and where we have suppressed reference to the hologram target j
for notational clarity here and in the following equation. The expression in Equation 7 can be used
to obtain a predictive distribution over derivative functions consistent with the observed data points,
which we use to evaluate the derivatives of ˆgn at the test point x∗via"
OPTIMISATION APPROACH,0.13687150837988826,∂ˆgn(x∗)
OPTIMISATION APPROACH,0.13966480446927373,"∂x∗
d
= ∂mn(x∗)"
OPTIMISATION APPROACH,0.1424581005586592,"∂x∗
d
+ cov

gn(X), ∂gn(x∗) ∂x∗
d"
OPTIMISATION APPROACH,0.1452513966480447,"⊤
K−1(ˆgn(X) −mn(X)),
(8)"
OPTIMISATION APPROACH,0.14804469273743018,"where X ∈RJT ×3 is the collection of JT unique points on the ORF that were probed during ORF
mapping, gn(X), mn(X) ∈RJT give the value of the GP and mean function evaluated at each such
point, and where K is the corresponding GP covariance matrix obtained by evaluating the covariance
kernel k at every pair of elements of X. Further details are provided in the supplementary material."
OPTIMISATION APPROACH,0.15083798882681565,"Equation 8 allows us to define a closed-form gradient of the objective function, which we use in a
projected gradient descent algorithm (Algorithm 1). Note, however, that the objective function is not
convex in x, and therefore such updates are only guaranteed to converge to a locally optimal solution.
We therefore typically run Algorithm 1 with several random initialisations and select the optimised
target with the lowest predicted error."
OPTIMISATION APPROACH,0.15363128491620112,Algorithm 1: Bayesian target optimisation (Bataro).
OPTIMISATION APPROACH,0.1564245810055866,"1 Compute MAP estimates of ORFs {ˆgn, ˆθn}N
n=1 from calibration data {yn}N
n=1, {xt}T
t=1 using
Newton’s method with log-barrier."
OPTIMISATION APPROACH,0.15921787709497207,"2 Initialise targets x ∈RJ×3 to random locations near the somas of the J target neurons and with
random laser powers."
WHILE TARGET NOT CONVERGED DO,0.16201117318435754,3 while target not converged do
WHILE TARGET NOT CONVERGED DO,0.164804469273743,"4
Construct gradient vectors ∇xˆγn(x) for n = 1, . . . , N using inference of ORF derivatives
(Equation 8)."
WHILE TARGET NOT CONVERGED DO,0.16759776536312848,"5
Set δx = −2 PN
n=1(Ωn −σ(ˆγn(x) −ˆθn))σ′(ˆγn(x) −ˆθn)∇xˆγn(x)."
WHILE TARGET NOT CONVERGED DO,0.17039106145251395,"6
Perform gradient descent update x ←x + βδx with step-size β."
WHILE TARGET NOT CONVERGED DO,0.17318435754189945,"7
Project laser power onto feasible domain, Ij ←min(Ij, Imax) for j = 1, . . . , J."
END,0.17597765363128492,8 end
RESULTS,0.1787709497206704,"4
Results"
SIMULATIONS,0.18156424581005587,"4.1
Simulations"
SIMULATIONS,0.18435754189944134,"We first tested Bataro by simulating an optical ""write-in"" experiment, where we attempted to write
specific activity patterns into a hypothetical neural population. To do this, we positioned 50 neurons
randomly in a 250 µm × 250 µm field of view (FOV), sampled each neuron’s ORF from its GP a
b c d"
SIMULATIONS,0.1871508379888268,"random 
6-target 
ensembles"
SIMULATIONS,0.18994413407821228,"Figure 2: Minimising off-target stimulation using Bayesian target optimisation. (a) Direct nuclear
stimulation at 70 mW successfully activates the target neurons with high probability, but also activates
nearby non-target neurons due to OTS. Triangles indicate target neurons. Shading indicates probability
of spiking. Optical write-in error (bottom) given as the sum of squared errors between the evoked
and desired activity patterns. (b) Optimised stimulation using Algorithm 1 repositions the hologram
locations away from the nuclei of non-target neurons, resulting in a substantial reduction in off-target
activation. (c) Optimisation trajectory of the 6 different target laser powers. Initial laser powers
selected randomly between 50 and 70 mW. (d) Optimising holographic targets for 20 different random
ensembles shows a robust reduction of optical write-in error (average reduction, 75%)."
SIMULATIONS,0.19273743016759776,"prior, and generated responses to ensemble stimulation. To quantify the optical write-in error, we
used the sum of squared errors P"
SIMULATIONS,0.19553072625698323,"n(Ωn −yn(x))2, where yn(x) is the ground truth probability of
neuron n spiking in response to stimulus x. This error takes the interpretable value of ∼m if m
non-target neurons are inadvertently recruited due to OTS. In this simulation, holographic stimulation
of an example ensemble consisting of 6 selected neurons resulted in a substantial recruitment of
activity from non-target neurons due to OTS, especially when multiple holograms converged on
nearby non-target neurons (Figure 2a; optical write-in error = 7.84)."
SIMULATIONS,0.19832402234636873,"To optimally reposition the holographic targets, we probed the population’s ORFs using 10-target
ensemble stimulation, and then used Bataro (Algorithm 1). This successfully repositioned holographic
targets an appropriate distance from the nuclei of the target neurons, such that while minimal excitation
was applied to the non-target neurons, the target neurons were still driven to spike with high probability
(Figure 2b,c; write-in error = 1.61). To confirm that the improvement in write-in precision was robust,
we repeated the optimisation for 20 additional random 6-target ensembles and found that off-target
effects were substantially reduced in every case, with the write-in error reducing by 75% on average
compared to naively stimulating the nucleus of each neuron (Figure 2d)."
SIMULATIONS,0.2011173184357542,"Next, we investigated two variables known to critically constrain the ability to evoke specific neural
activity patterns: (1) the density of opsin-expressing neurons in the stimulation FOV, and (2) the
size of the ensemble that one is attempting to activate. Figure 3a illustrates how increasing the
number of opsin-expressing neurons introduces many more potential non-target neurons that could
be inadvertently activated. This causes errors induced by direct nuclear stimulation of (e.g.) 5-neuron
ensembles to grow rapidly (Figure 3b, grey curve), though note that the magnitude of the error
depends on many experimental factors including the size of the ORF, numerical aperture of the
microscope, and the soma-targeting efficacy. By optimising holographic target locations and laser
powers, the average write-in error was reduced by 76% relative to nuclear stimulation (Figure 3b,
red curve). Similarly, in these simulations, nuclear stimulation resulted in an error that grew almost a"
SIMULATIONS,0.20391061452513967,"50
100
150
Population size 0 2 4 6 8 10 12 14 16 18"
SIMULATIONS,0.20670391061452514,Write-in error b
SIMULATIONS,0.20949720670391062,Nuclear
SIMULATIONS,0.2122905027932961,Optimised
SIMULATIONS,0.21508379888268156,"



6WLPXODWHG HQVHPEOH VL]H"
SIMULATIONS,0.21787709497206703,"








"
SIMULATIONS,0.2206703910614525,:ULWHLQ HUURU c
SIMULATIONS,0.22346368715083798,"Figure 3: Performance of Bayesian target optimisation in increasingly difficult contexts. (a) Two
example scenarios with low (left) and high (right) density of opsin-expressing neurons. Triangles
indicate example 5-target ensemble to be stimulated. At low density, the risk of OTS is low because
neurons are often spaced far apart. However, at high density, OTS arising from direct nuclear
stimulation at high power is unavoidable. (b) Optical write-in error for nuclear and optimised
stimulation of 5-target ensembles. Error bars show the mean error ± 1 s.d. over 10 different
simulations. For each simulation we averaged the write-in error over 20 random ensembles. (c) Same
as (b), but for a fixed population size of 50 and varying ensemble size. a
b
c 30 μm"
SIMULATIONS,0.22625698324022347,"Figure 4: Performance of Bayesian target optimisation using simulations based on two-photon
holographic optogenetics data. (a) Left: field of view from a real in vitro optogenetics experiment
showing every optimised single-target hologram. Opsin fused to red fluorescent protein mRuby3 so
that opsin-expressing neurons can be visualised. Unfilled white circles represent putative neurons
detected by automated cell segmentation method. Smaller filled white circles represent optimised
holographic targets, shown in relation to the cell nucleus by a straight white line. Right: zoomed view
of optimised targets, corresponding to dashed region in the left panel. (b) Optimised laser powers
relative to their initialised values show how Bataro exploits differences in photosensitivity to avoid
OTS. Each circle represents the power delivered to a single holographic target. (c) Reduction of
optical write-in error using optimised holographic targets. Each circle represents the error when
attempting to stimulate a single neuron."
SIMULATIONS,0.22905027932960895,"directly proportionally to the size of the stimulated ensemble, indicating that almost as many non-
target neurons were activated as target neurons. However, Bataro reduced the average write-in error
by 69% across ensembles of size 1-15 (Figure 3c)."
APPLICATION TO HOLOGRAPHIC OPTOGENETICS EXPERIMENTS,0.23184357541899442,"4.2
Application to holographic optogenetics experiments"
APPLICATION TO HOLOGRAPHIC OPTOGENETICS EXPERIMENTS,0.2346368715083799,"To test whether Bataro could eliminate OTS in realistic settings, we created synthetic optogenetics
experiments involving >100 neurons from a small number (n=4) of detailed cell-attached recordings
in slice [42]. Briefly, each slice experiment was performed by first establishing a cell-attached
electrophysiological recording of a single L2/3 interneuron from mouse V1 expressing the soma-
targeted opsin ChroME2f. Then, the recorded neuron was optogenetically stimulated at a dense grid"
APPLICATION TO HOLOGRAPHIC OPTOGENETICS EXPERIMENTS,0.23743016759776536,"target 
neuron"
APPLICATION TO HOLOGRAPHIC OPTOGENETICS EXPERIMENTS,0.24022346368715083,"Δxy = 2 μm
Δz = 11 μm"
APPLICATION TO HOLOGRAPHIC OPTOGENETICS EXPERIMENTS,0.2430167597765363,target b
APPLICATION TO HOLOGRAPHIC OPTOGENETICS EXPERIMENTS,0.24581005586592178,deeper
APPLICATION TO HOLOGRAPHIC OPTOGENETICS EXPERIMENTS,0.24860335195530725,"a
75 μm 50 μm"
APPLICATION TO HOLOGRAPHIC OPTOGENETICS EXPERIMENTS,0.25139664804469275,"target 
neuron 25 μm 0 μm"
APPLICATION TO HOLOGRAPHIC OPTOGENETICS EXPERIMENTS,0.2541899441340782,"Δxy = 14 μm
Δz = 1 μm"
APPLICATION TO HOLOGRAPHIC OPTOGENETICS EXPERIMENTS,0.2569832402234637,"target f
g"
APPLICATION TO HOLOGRAPHIC OPTOGENETICS EXPERIMENTS,0.25977653631284914,"c
75 μm
50 μm"
APPLICATION TO HOLOGRAPHIC OPTOGENETICS EXPERIMENTS,0.26256983240223464,"25 μm
0 μm e d 20 μm"
APPLICATION TO HOLOGRAPHIC OPTOGENETICS EXPERIMENTS,0.26536312849162014,z-projection
APPLICATION TO HOLOGRAPHIC OPTOGENETICS EXPERIMENTS,0.2681564245810056,"Figure 5: Optimisation of holographic targets in three-dimensional space. (a) Example target neuron
and optimised holographic stimulus (plane 3, 25 µm). By repositioning the hologram (primarily in
the x/y dimensions), off-target activation is entirely eliminated (bottom spike probability plots, inset
numbers show write-in error). Deepest plane labelled as 0 µm by convention. Solid white circle
indicates target neuron. Dashed white circles indicate nearby non-target neurons that must be avoided.
(b) Similar to (a), but for a neuron in plane 2 (50 µm) and with repositioning of the hologram primarily
in the z dimension. (c) All optimised single-target holograms over four stimulation planes. Targets
shown at their original depth for visualisation. Average displacement of optimised holographic
targets relative to nuclei, 8.3 µm. Scale bar, 20 µm. (d) Max-projection over z-planes simultaneously
showing locations of all segmented opsin-expressing neurons. (e) Optimised depths of holographic
targets corresponding to neurons in (c). Depths are shown in comparison to one of four depths that
the target neuron was segmented at during the experiment. (f) Optimised laser powers relative to their
initialised values. (g) Reduction of optical write-in error for all neurons, across multiple depths."
APPLICATION TO HOLOGRAPHIC OPTOGENETICS EXPERIMENTS,0.2709497206703911,"of locations surrounding the cell and at a range of laser powers to comprehensively map its ORF (see
Figure 1c, ""100% sampled"" column, also see supplementary material for additional examples). We
used this data to create a set of four ""ground truth"" ORFs by fitting the GP-Bernoulli model from
Equation 1, where the hyperparameters of the GP covariance kernel were selected using the cross-
validated predictive log-likelihood. Next, we used a fluorescence image from a separate experiment to
extract the locations of 116 putative opsin-expressing neurons, and randomly assigned each putative
neuron one of four ground-truth ORFs. Together, this enabled us to simulate responses to optogenetic
stimulation at arbitrary locations and laser powers and for a large number of neurons that were
realistically distributed in space."
APPLICATION TO HOLOGRAPHIC OPTOGENETICS EXPERIMENTS,0.2737430167597765,"We sampled responses to optogenetic stimulation at a sparse grid of locations surrounding each
neuron to map their ORFs in a hypothetical experiment (see supplementary methods for details).
Then, we used Bataro to compute single-target stimuli that activated each neuron individually and
minimised OTS (Figure 4a). We found that, on the one hand, a subset of neurons required no change
from nuclear stimulation at high power due to being spatially isolated. However, regions with large
numbers of closely-packed, opsin-expressing neurons required repositioning of the holographic
targets (Figure 4a, right) and adjustment to the laser powers (Figure 4b) to eliminate OTS (average
distance between nuclear and optimised stimuli, 4.9 µm). Across all single-target holograms, target
optimisation reduced the average write-in error by 85% (Figure 4c). We also performed a control"
APPLICATION TO HOLOGRAPHIC OPTOGENETICS EXPERIMENTS,0.276536312849162,"analysis by matching the nuclear stimulation laser power to the average optimised laser power and
obtained similar results (Figure S3)."
APPLICATION TO HOLOGRAPHIC OPTOGENETICS EXPERIMENTS,0.27932960893854747,"Some holographic microscopy systems cannot position holograms at arbitrary continuous depths,
instead either requiring holograms to be positioned in two dimensions or on a preselected number
of discrete stimulation planes. Hence, thus far, we focused our efforts on the much more common
case of two-dimensional optogenetics experiments. However, OTS is generally observed to be even
more prevalent in three dimensions, as the optical point spread function is elongated in the ""z""-axis
[15, 6, 13, 17]. We therefore tested Bataro in the more general setting of three spatial dimensions and
laser power (i.e., four dimensions in total), under the assumption that some microscopy systems may
be able to flexibly reposition holograms continuously across depths."
APPLICATION TO HOLOGRAPHIC OPTOGENETICS EXPERIMENTS,0.28212290502793297,"We used the fact that the cell-attached recordings were repeated at multiple depths to generate
synthetic optogenetics experiments with four-dimensional ORFs (Figure 5a,b). Optimisation of
holographic targets successfully reduced OTS by exploiting both the x/y dimensions (Figure 5a), as
well the z dimension (Figure 5b), in addition to automatically adjusting the laser power where needed.
Repeating the optimisation for every single-target hologram reduced the average optical write-in error
by 89% (from 0.7 to 0.08, Figure 5c-g; average distance between nuclear and optimised targets, 8.3
µm), demonstrating the feasibility of largely eliminating OTS in optogenetics experiments involving
all three spatial dimensions."
CONCLUSIONS,0.2849162011173184,"5
Conclusions"
CONCLUSIONS,0.2877094972067039,"We developed Bataro, a novel computational framework for two-photon optogenetics that optimises
holographic stimuli to evoke neural activity patterns with minimal off-target activation. Our pre-
liminary in vitro experiments predict that specific adjustments to holographic target placements
of 5-10 µm (on average) could substantially reduce OTS, even in the more challenging regime of
three-dimensional optogenetic stimulation. Our key idea was to simultaneously exploit variability
in photoexcitability, residual opsin expression in proximal dendrites (due to imperfections in opsin
soma-targeting), and the specific spatial arrangement of neurons in the stimulation FOV. Optimisation
using these three factors ultimately led to reductions in the optical write-in error of 85-89% for
single-target holograms using data from in vitro two-photon optogenetics experiments."
CONCLUSIONS,0.2905027932960894,"Whether achieving such stimulus precision is worth spending valuable experiment time mapping
ORFs is, of course, highly dependent on the application. While for some experiments minimising
off-target activation may not be critical, there are many cases where stimulating with as close to
""true"" single-cell precision as possible is essential to testing a scientific hypothesis. For example,
""hub"" neurons in the hippocampus are believed to orchestrate network-level function through their
unilateral activity [46, 47]. Thus, using two-photon optogenetics to test whether an individual neuron
represents a functional hub by stimulating that neuron alone requires true single-cell precision. In
such cases, we believe devoting experiment time to ORF mapping and stimulus optimisation is a
necessary trade-off."
CONCLUSIONS,0.29329608938547486,"Throughout our analysis we have assumed that ORFs are stable over time (i.e., are stationary).
However, desensitisation of opsins following prolonged illumination has previously been observed
[11], indicating that some nonstationarity could be encountered in real experiments. To account
for this, we note that after the ORFs have been mapped and holographic stimuli optimised, it is
straightforward to periodically recompute the MAP estimate of the ORF as the experiment proceeds.
This would provide an updated estimate of the laser power required to maintain optimal precision.
We hypothesise that this would not require repeating the entire ORF mapping phase as we do not
expect the shape of the ORF to change drastically beyond desensitisation."
CONCLUSIONS,0.29608938547486036,"Standard GP regression methods scale cubically with the number of locations and laser powers
probed, and therefore estimation of each neuron’s ORF could encroach on experiment time if ORFs
are mapped at high detail just due to required computation time. However, computational efficiency
could be improved by appealing to modern GP techniques such as inducing point methods [48], or by
adaptively mapping ORFs using Bayesian active learning to minimise the number of probed locations
and powers [49, 50]. While in this work we have focused primarily on demonstrating the feasibility
of overcoming OTS, in future work we plan to minimise both required experiment and computation
time in order to deploy Bataro online."
CONCLUSIONS,0.2988826815642458,Acknowledgements
CONCLUSIONS,0.3016759776536313,"We thank Darcy Peterka, Benjamin Antin, Cole Hurwitz, Shizhe Chen, and Ben Shababo for
helpful discussions and suggestions. This work was funded by NIH awards 1RF1MH120680 and
1U19NS107613-01 to HA and LP. MAT and LP were supported by the Gatsby Charitable Foundation
and NSF NeuroNex award 1707398."
REFERENCES,0.30446927374301674,References
REFERENCES,0.30726256983240224,"[1] John Peter Rickgauer and David W Tank. Two-photon excitation of channelrhodopsin-2 at
saturation. Proceedings of the National Academy of Sciences, 106(35):15025–15030, 2009."
REFERENCES,0.3100558659217877,"[2] Eirini Papagiakoumou, Francesca Anselmi, Aurélien Bègue, Vincent De Sars, Jesper Glückstad,
Ehud Y Isacoff, and Valentina Emiliani. Scanless two-photon excitation of channelrhodopsin-2.
Nature Methods, 7(10):848–854, 2010."
REFERENCES,0.3128491620111732,"[3] Adam M Packer, Darcy S Peterka, Jan J Hirtz, Rohit Prakash, Karl Deisseroth, and Rafael
Yuste. Two-photon optogenetics of dendritic spines and neural circuits. Nature Methods,
9(12):1202–1205, 2012."
REFERENCES,0.31564245810055863,"[4] Rohit Prakash, Ofer Yizhar, Benjamin Grewe, Charu Ramakrishnan, Nancy Wang, Inbal
Goshen, Adam M Packer, Darcy S Peterka, Rafael Yuste, Mark J Schnitzer, et al. Two-photon
optogenetic toolbox for fast inhibition, excitation and bistable modulation. Nature Methods,
9(12):1171–1179, 2012."
REFERENCES,0.31843575418994413,"[5] Oscar Hernandez, Eirini Papagiakoumou, Dimitrii Tanese, Kevin Fidelin, Claire Wyart, and
Valentina Emiliani. Three-dimensional spatiotemporal focusing of holographic patterns. Nature
Communications, 7(1):1–11, 2016."
REFERENCES,0.32122905027932963,"[6] Nicolas C Pégard, Alan R Mardinly, Ian Antón Oldenburg, Savitha Sridharan, Laura Waller, and
Hillel Adesnik. Three-dimensional scanless holographic optogenetics with temporal focusing
(3d-shot). Nature Communications, 8(1):1–14, 2017."
REFERENCES,0.3240223463687151,"[7] Emiliano Ronzitti, Cathie Ventalon, Marco Canepari, Benoît C Forget, Eirini Papagiakoumou,
and Valentina Emiliani. Recent advances in patterned photostimulation for optogenetics. Journal
of Optics, 19(11):113001, 2017."
REFERENCES,0.3268156424581006,"[8] Nicolò Accanto, Clément Molinier, Dimitrii Tanese, Emiliano Ronzitti, Zachary L Newman,
Claire Wyart, Ehud Isacoff, Eirini Papagiakoumou, and Valentina Emiliani. Multiplexed
temporally focused light shaping for high-resolution multi-cell targeting. Optica, 5(11):1478–
1491, 2018."
REFERENCES,0.329608938547486,"[9] Weijian Yang, Luis Carrillo-Reid, Yuki Bando, Darcy S Peterka, and Rafael Yuste. Simultaneous
two-photon imaging and two-photon optogenetics of cortical circuits in three dimensions. elife,
7:e32671, 2018."
REFERENCES,0.3324022346368715,"[10] Alan R Mardinly, Ian Antón Oldenburg, Nicolas C Pégard, Savitha Sridharan, Evan H Lyall,
Kirill Chesnov, Stephen G Brohawn, Laura Waller, and Hillel Adesnik. Precise multimodal
optical control of neural ensemble activity. Nature Neuroscience, 21(6):881–893, 2018."
REFERENCES,0.33519553072625696,"[11] James H Marshel, Yoon Seok Kim, Timothy A Machado, Sean Quirin, Brandon Benson,
Jonathan Kadmon, Cephra Raja, Adelaida Chibukhchyan, Charu Ramakrishnan, Masatoshi
Inoue, et al.
Cortical layer–specific critical dynamics triggering perception.
Science,
365(6453):eaaw5202, 2019."
REFERENCES,0.33798882681564246,"[12] Luis Carrillo-Reid, Shuting Han, Weijian Yang, Alejandro Akrouh, and Rafael Yuste. Control-
ling visually guided behavior by holographic recalling of cortical ensembles. Cell, 178(2):447–
457, 2019."
REFERENCES,0.3407821229050279,"[13] Hillel Adesnik and Lamiae Abdeladim. Probing neural codes with two-photon holographic
optogenetics. Nature Neuroscience, 24(10):1356–1366, 2021."
REFERENCES,0.3435754189944134,"[14] Eirini Papagiakoumou, Emiliano Ronzitti, and Valentina Emiliani. Scanless two-photon excita-
tion with temporal focusing. Nature Methods, 17(6):571–581, 2020."
REFERENCES,0.3463687150837989,"[15] Christopher A Baker, Yishai M Elyada, Andres Parra, and M McLean Bolton. Cellular resolution
circuit mapping with temporal-focused excitation of soma-targeted channelrhodopsin. Elife,
5:e14193, 2016."
REFERENCES,0.34916201117318435,"[16] Or A Shemesh, Dimitrii Tanese, Valeria Zampini, Changyang Linghu, Kiryl Piatkevich, Emil-
iano Ronzitti, Eirini Papagiakoumou, Edward S Boyden, and Valentina Emiliani. Temporally
precise single-cell-resolution optogenetics. Nature Neuroscience, 20(12):1796–1806, 2017."
REFERENCES,0.35195530726256985,"[17] Travis A Hage, Alice Bosma-Moody, Christopher A Baker, Megan B Kratz, Luke Campagnola,
Tim Jarsky, Hongkui Zeng, and Gabe J Murphy. Synaptic connectivity to l2/3 of primary visual
cortex measured by two-photon optogenetic stimulation. Elife, 11:e71103, 2022."
REFERENCES,0.3547486033519553,"[18] Valentina Emiliani, Adam E Cohen, Karl Deisseroth, and Michael Häusser. All-optical interro-
gation of neural circuits. Journal of Neuroscience, 35(41):13917–13926, 2015."
REFERENCES,0.3575418994413408,"[19] Adam M Packer, Lloyd E Russell, Henry WP Dalgleish, and Michael Häusser. Simultaneous
all-optical manipulation and recording of neural circuit activity with cellular resolution in vivo.
Nature Methods, 12(2):140–146, 2015."
REFERENCES,0.36033519553072624,"[20] Zihui Zhang, Lloyd E Russell, Adam M Packer, Oliver M Gauld, and Michael Häusser. Closed-
loop all-optical interrogation of neural circuits in vivo. Nature Methods, 15(12):1037–1040,
2018."
REFERENCES,0.36312849162011174,"[21] Lloyd E Russell, Henry WP Dalgleish, Rebecca Nutbrown, Oliver M Gauld, Dustin Herrmann,
Mehmet Fi¸sek, Adam M Packer, and Michael Häusser. All-optical interrogation of neural
circuits in behaving mice. Nature Protocols, 17(7):1579–1620, 2022."
REFERENCES,0.3659217877094972,"[22] Hayley A Bounds, Masato Sadahiro, William D Hendricks, Marta Gajowa, Ian Antón Oldenburg,
Karthika Gopakumar, Daniel Quintana, Tanya Daigle, Hongkui Zeng, and Hillel Adesnik.
Multifunctional cre-dependent transgenic mice for high-precision all-optical interrogation of
neural circuits. bioRxiv, page 463223, 2021."
REFERENCES,0.3687150837988827,"[23] Kamiar Rahnama Rad and Liam Paninski. Efficient, adaptive estimation of two-dimensional
firing rate surfaces via gaussian process methods. Network: Computation in Neural Systems,
21(3-4):142–168, 2010."
REFERENCES,0.3715083798882682,"[24] Cristina Savin and Gasper Tkacik. Estimating nonlinear neural response functions using gp
priors and kronecker methods. Advances in Neural Information Processing Systems, 29, 2016."
REFERENCES,0.3743016759776536,"[25] M Rule, P Chaudhuri-Vayalambrone, Marino Krstulovic, Marius Bauza, Julija Krupic, and
Timothy O’Leary. Variational log-gaussian point-process methods for grid cells. bioRxiv, pages
2023–03, 2023."
REFERENCES,0.3770949720670391,"[26] Jakob H Macke, Sebastian Gerwinn, Leonard E White, Matthias Kaschube, and Matthias Bethge.
Gaussian process methods for estimating cortical maps. NeuroImage, 56(2):570–581, 2011."
REFERENCES,0.37988826815642457,"[27] Mijung Park, Greg Horwitz, and Jonathan Pillow. Active learning of neural response functions
with gaussian processes. Advances in Neural Information Processing Systems, 24, 2011."
REFERENCES,0.38268156424581007,"[28] Mijung Park, J Patrick Weller, Gregory D Horwitz, and Jonathan W Pillow. Bayesian ac-
tive learning of neural firing rate maps with transformed gaussian process priors. Neural
Computation, 26(8):1519–1541, 2014."
REFERENCES,0.3854748603351955,"[29] Jonathan P Newman, Ming-fai Fong, Daniel C Millard, Clarissa J Whitmire, Garrett B Stanley,
and Steve M Potter. Optogenetic feedback control of neural activity. Elife, 4:e07192, 2015."
REFERENCES,0.388268156424581,"[30] Yuxiao Yang, Allison T Connolly, and Maryam M Shanechi. A control-theoretic system
identification framework and a real-time closed-loop clinical simulation testbed for electrical
brain stimulation. Journal of Neural Engineering, 15(6):066007, 2018."
REFERENCES,0.39106145251396646,"[31] Michael F Bolus, Adam A Willats, Clarissa J Whitmire, Christopher J Rozell, and Garrett B
Stanley. Design strategies for dynamic closed-loop optogenetic neurocontrol in vivo. Journal of
Neural Engineering, 15(2):026011, 2018."
REFERENCES,0.39385474860335196,"[32] Nishal Shah, Sasidhar Madugula, Pawel Hottowy, Alexander Sher, Alan Litke, Liam Paninski,
and EJ Chichilnisky. Efficient characterization of electrically evoked responses for neural
interfaces. Advances in Neural Information Processing Systems, 32, 2019."
REFERENCES,0.39664804469273746,"[33] Michael F Bolus, Adam A Willats, Christopher J Rozell, and Garrett B Stanley. State-space op-
timal feedback control of optogenetically driven neural activity. Journal of Neural Engineering,
18(3):036006, 2021."
REFERENCES,0.3994413407821229,"[34] Yuxiao Yang, Shaoyu Qiao, Omid G Sani, J Isaac Sedillo, Breonna Ferrentino, Bijan Pesaran,
and Maryam M Shanechi. Modelling and prediction of the dynamic responses of large-scale
brain networks during direct electrical stimulation. Nature Biomedical Engineering, 5(4):324–
345, 2021."
REFERENCES,0.4022346368715084,"[35] Yashar Ahmadian, Adam M Packer, Rafael Yuste, and Liam Paninski. Designing optimal
stimuli to control neuronal spike timing. Journal of Neurophysiology, 106(2):1038–1053, 2011."
REFERENCES,0.40502793296089384,"[36] Tao Hu and Dmitri Chklovskii. Reconstruction of sparse circuits using multi-neuronal excitation
(rescume). Advances in Neural Information Processing Systems, 22:790–798, 2009."
REFERENCES,0.40782122905027934,"[37] Alyson K Fletcher, Sundeep Rangan, Lav R Varshney, and Aniruddha Bhargava. Neural
reconstruction with approximate message passing (neuramp). Advances in Neural Information
Processing Systems, 2011."
REFERENCES,0.4106145251396648,"[38] Ben Shababo, Brooks Paige, Ari Pakman, and Liam Paninski. Bayesian inference and on-
line experimental design for mapping neural microcircuits. Advances in Neural Information
Processing Systems, 26:1304–1312, 2013."
REFERENCES,0.4134078212290503,"[39] Alyson K Fletcher and Sundeep Rangan. Scalable inference for neuronal connectivity from
calcium imaging. Advances in Neural Information Processing Systems, 2014."
REFERENCES,0.41620111731843573,"[40] Laurence Aitchison, Lloyd Russell, Adam Packer, Jinyao Yan, Philippe Castonguay, Michael
Häusser, and Srinivas C Turaga. Model-based bayesian inference of neural activity and con-
nectivity from all-optical interrogation of a neural circuit. Advances in Neural Information
Processing Systems, 2017."
REFERENCES,0.41899441340782123,"[41] Anne Draelos and John Pearson. Online neural connectivity estimation with noisy group testing.
Advances in Neural Information Processing Systems, 33, 2020."
REFERENCES,0.42178770949720673,"[42] Marcus A Triplett, Marta Gajowa, Benjamin Antin, Masato Sadahiro, Hillel Adesnik, and Liam
Paninski. Rapid learning of neural circuitry from holographic ensemble stimulation enabled by
model-based compressed sensing. bioRxiv, page 507926, 2022."
REFERENCES,0.4245810055865922,"[43] Yoav Printz, Pritish Patil, Mathias Mahn, Asaf Benjamin, Anna Litvin, Rivka Levy, Max
Bringmann, and Ofer Yizhar. Determinants of functional synaptic connectivity among amygdala-
projecting prefrontal cortical neurons in male mice. Nature Communications, 14(1):1667, 2023."
REFERENCES,0.4273743016759777,"[44] Savitha Sridharan, Marta A Gajowa, Mora B Ogando, Uday K Jagadisan, Lamiae Abdeladim,
Masato Sadahiro, Hayley A Bounds, William D Hendricks, Toby S Turney, Ian Tayler, et al.
High-performance microbial opsins for spatially and temporally precise perturbations of large
neuronal networks. Neuron, 2022."
REFERENCES,0.4301675977653631,"[45] Christopher KI Williams and Carl Edward Rasmussen. Gaussian Processes for Machine
Learning, volume 2. MIT Press Cambridge, MA, 2006."
REFERENCES,0.4329608938547486,"[46] Paolo Bonifazi, Miri Goldin, Michel A Picardo, Isabel Jorquera, A Cattani, Gregory Bianconi,
Alfonso Represa, Yehezkel Ben-Ari, and Rosa Cossart. Gabaergic hub neurons orchestrate
synchrony in developing hippocampal networks. Science, 326(5958):1419–1424, 2009."
REFERENCES,0.43575418994413406,"[47] Marco Bocchio, Claire Gouny, David Angulo-Garcia, Tom Toulat, Thomas Tressard, Eleonora
Quiroli, Agnès Baude, and Rosa Cossart. Hippocampal hub neurons maintain distinct connec-
tivity throughout their lifetime. Nature Communications, 11(1):4559, 2020."
REFERENCES,0.43854748603351956,"[48] Michalis Titsias. Variational learning of inducing variables in sparse gaussian processes. In
Artificial Intelligence and Statistics (AISTATS), pages 567–574. PMLR, 2009."
REFERENCES,0.441340782122905,"[49] Jeremy Lewi, Robert Butera, and Liam Paninski. Sequential optimal design of neurophysiology
experiments. Neural Computation, 21(3):619–687, 2009."
REFERENCES,0.4441340782122905,"[50] Jonathan W Pillow and Mijung Park. Adaptive bayesian methods for closed-loop neurophysiol-
ogy. Closed Loop Neuroscience, pages 3–18, 2016."
REFERENCES,0.44692737430167595,"[51] Andrew James McHutchon et al. Nonlinear modelling and control using Gaussian processes.
PhD thesis, Citeseer, 2015."
SUPPLEMENTARY MATERIAL,0.44972067039106145,"6
Supplementary material"
ANIMAL ETHICS STATEMENT,0.45251396648044695,"6.1
Animal ethics statement"
ANIMAL ETHICS STATEMENT,0.4553072625698324,"All experiments on animals were conducted with approval of the Animal Care and Use Committee of
the University of California, Berkeley."
COMPUTE,0.4581005586592179,"6.2
Compute"
COMPUTE,0.46089385474860334,"All computational procedures were performed either on a desktop workstation running Ubuntu 18.04
with an Intel Xeon E5-2620 v4 CPU, four GTX 1080 Ti GPUs, and 112GB RAM, or on the Axon
computer cluster based at the Zuckerman Institute (Columbia University) using nodes comprised of
two Xeon E5-2660 v4 CPUs, eight GTX 1080 Ti GPUs, and 125GB RAM."
BROADER SOCIETAL IMPACT,0.46368715083798884,"6.3
Broader societal impact"
BROADER SOCIETAL IMPACT,0.4664804469273743,"Our work is significant for interventional approaches to studying the brain and its connection
to disease. By minimising off-target activation, Bayesian target optimisation could enable (e.g.)
more precise synaptic connectivity mapping, improving our understanding of neural circuitry. This
advancement has potential implications for understanding brain disorders like epilepsy, where
abnormal synaptic connections are central to seizure generation and propagation. Deepening our
understanding of these diseases can lead to enhanced targeted interventions and more effective
therapeutic strategies, benefiting individuals with neurological disorders."
CODE AVAILABILITY,0.4692737430167598,"6.4
Code availability"
CODE AVAILABILITY,0.4720670391061452,"An open-source implementation of Bayesian target optimisation is available in Python at https:
//github.com/marcustriplett/bataro."
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.4748603351955307,"6.5
Single-target holographic stimulus optimisation with posterior uncertainty"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.4776536312849162,"Here we provide further mathematical details for optimising holographic stimuli. First, we develop
the approach for single optogenetic targets, as this is most closely related to existing GP-based
receptive field inference techniques. The single-target case also allows us to have a full treatment
of posterior uncertainty (unlike for optimising ensemble stimuli) which may be desired in certain
applications."
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.48044692737430167,"Optogenetic receptive field model. We use a GP-Bernoulli approach to model the response ynt of
neuron n on trial t to a single-target stimulus xt,"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.48324022346368717,"ynt ∼Bernoulli(σ(gn(xt))),
(9)"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.4860335195530726,"where the stimulus xt = (c1t, c2t, It) ∈R3 represents the two-dimensional coordinates and laser
power of the t-th hologram. Each ORF follows a three-dimensional GP prior gn ∼GP(mn(·), k(·, ·)),
where mn and k again are the mean and covariance functions of the GP."
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.4888268156424581,"Posterior inference. Unlike for ensemble stimulation, for single-target stimulation we do not require
that the ORF gn is non-negative. This is because now if a point on the ORF becomes inhibitory (by
taking a negative value), it will not conflict with excitation from any other hologram. Consequently,
the posterior of gn is a GP, which allows us to work with a full description of posterior uncertainty.
To compute the posterior, we use the conventional Laplace approximation. Briefly, this consists of
approximating the posterior using a multivariate normal q(gn | µn, Σn) = Normal(gn | µn, Σn) ≈
p(gn | yn, X, ϕ). The mean µn is obtained by maximising the log-posterior, given by the expression"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.49162011173184356,"ln p(gn | yn, X, ϕ) = T
X"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.49441340782122906,"t=1
ln p(ynt | xt, gn) + ln p(gn(x1), . . . , gn(xT ) | ϕ) + const,
(10)"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.4972067039106145,"where X = (x1, . . . , xT ) and where const does not depend on gn. Since the posterior is log-concave
in gn, we use Newton’s method to identify the global optimum of Equation 10, and adaptively set the
Newton step-size using a standard backtracking line-search method. Letting H = ∇∇gn ln p(gn |"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5,"yn, X, ϕ) be the Hessian of the log-posterior, the posterior covariance matrix is obtained by setting
Σn = −H−1 |gn=µn."
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5027932960893855,"Target optimisation. Let G = (g1, . . . , gN), and define the predicted evoked activity for single
holographic targets as ˆy(x, G) = (σ(g1(x)), . . . , σ(gN(x))). To minimise the error between a target
binary activity pattern Ω∈{0, 1}N and the predicted evoked activity, we solve an optimisation
problem that accounts for the uncertainty in the ORF estimates:"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.505586592178771,"xoptimal = argmin
x
Eq(G|µ,Σ)
h
∥Ω−ˆy(x, G)∥2i
such that
0 ≤I ≤Imax,
(11)"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5083798882681564,"where q(G | µ, Σ) = QN
n=1 q(gn | µn, Σn) gives the joint posterior across all ORFs. To solve
Equation 11, we first sample ORFs g(s)
n
(for s = 1, . . . , S) from their posterior distributions to
approximate the expected error at the current estimate x∗,"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5111731843575419,"Eq(G|µ,Σ)
h
∥Ω−ˆy(x∗, G)∥2i
≈1 S S
X s=1 N
X n=1"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5139664804469274,"
Ωn −σ(g(s)
n (x∗))
2
.
(12)"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5167597765363129,"Then, we compute the partial derivative (in dimension d) of the expected error by differentiating
through the Monte Carlo approximation,"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5195530726256983,"∂
∂x∗
d
Eq(G|µ,Σ)
h
∥Ω−ˆy(x∗, G)∥2i
≈−2 S S
X s=1 N
X"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5223463687150838,"n=1
(Ωn −σ(g(s)
n (x∗))σ′(g(s)
n (x∗)) ∂"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5251396648044693,"∂x∗
d
g(s)
n (x∗). (13)"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5279329608938548,"Next we must evaluate the partial derivative on the right-hand side of Equation 13. We use the fact
that a GP and its derivative are jointly GP-distributed, and hence infer the derivative from observations
of the ORF. The covariance between a GP and its derivative is given by [45, Sec 9.4]"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5307262569832403,"cov

gn(xt),
∂
∂x∗
d
gn(x∗)

= ∂k(xt, x∗)"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5335195530726257,"∂x∗
d
= α2"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5363128491620112,"λ2
d
(xdt −x∗
d) exp

−∥xt −x∗∥2 2λ2
d"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5391061452513967,"
,
(14)"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5418994413407822,"where the second equality is specific to the RBF covariance. Thus, we can use Equation 14 to obtain
the posterior predictive mean for the derivative GPs in closed form as [51, Sec 2.7]"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5446927374301676,"Eq(gn|µn,Σn)"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.547486033519553,"∂gn(x∗) ∂x∗
d"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5502793296089385,"
= ∂mn(x∗)"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.553072625698324,"∂x∗
d
+ cov

gn(X), ∂gn(x∗) ∂x∗
d"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5558659217877095,"⊤
K−1(µn −mn(X)).
(15)"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5586592178770949,"Here X = (x1, . . . , xT ) is the collection of unique points on the ORF probed during calibration.
If Equation 15 is combined with an expression for the posterior predictive variance, one obtains a
full predictive distribution over derivative functions consistent with the observed neural responses.
However, rather than working with this full distribution, we instead use Equation 15 to approximate
the derivatives of the Monte Carlo samples by replacing the posterior mean µn with a Monte Carlo
sample,"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5614525139664804,"∂g(s)
n (x∗)"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5642458100558659,"∂x∗
d
≈∂mn(x∗)"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5670391061452514,"∂x∗
d
+ cov

gn(X), ∂gn(x∗) ∂x∗
d"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5698324022346368,"⊤
K−1(g(s)
n (X) −mn(X)).
(16)"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5726256983240223,"Equation 16 then allows us to define a closed-form approximate gradient ˜∇x∗g(s)
n
at test point x∗,
defined as"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5754189944134078,"˜∇x∗g(s)
n
="
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5782122905027933,"""
∂g(s)
n (x∗)"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5810055865921788,"∂x∗
1
, . . . , ∂g(s)
n (x∗)
∂x∗
D #⊤"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5837988826815642,",
(17)"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5865921787709497,"which we use in the single-target projected gradient descent algorithm (Algorithm 2). Note that one
could also consider a quadrature approach to solving Equation 12, which may be more efficient than
Monte Carlo sampling. However, the presentation of the Monte Carlo approach is instructive for
deriving the optimisation of ensemble stimuli below."
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5893854748603352,"Algorithm 2: Projected Monte Carlo gradient descent algorithm for optimising single-target
holograms"
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5921787709497207,"1 Infer ORF posterior q(G | µ, Σ) from calibration data {yn}N
n=1, X using the Laplace
approximation."
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5949720670391061,"2 Precompute the negative of the Hessian Wn = −∇∇ln p(yn | X, gn) |gn=µn for each n."
SINGLE-TARGET HOLOGRAPHIC STIMULUS OPTIMISATION WITH POSTERIOR UNCERTAINTY,0.5977653631284916,3 Initialise x to random location near soma of target neuron and with random laser power.
WHILE TARGET NOT CONVERGED DO,0.6005586592178771,4 while target not converged do
WHILE TARGET NOT CONVERGED DO,0.6033519553072626,"5
for n = 1, . . . , N do"
COMPUTE MEAN AND VARIANCE OF POSTERIOR PREDICTIVE DISTRIBUTION AT CURRENT TARGET ESTIMATE,0.6061452513966481,"6
Compute mean and variance of posterior predictive distribution at current target estimate
x via µn(x) = mn(x) + k(X, x)⊤K−1(µn −mn(X)), and
σ2
n(x) = k(x, x) −k(X, x)⊤(K + W−1
n )−1k(X, x)."
COMPUTE MEAN AND VARIANCE OF POSTERIOR PREDICTIVE DISTRIBUTION AT CURRENT TARGET ESTIMATE,0.6089385474860335,"7
Sample ORFs at the current target estimate, g(s)
n (x) ∼Normal(µn(x), σ2
n(x)) for
s = 1, . . . , S."
COMPUTE MEAN AND VARIANCE OF POSTERIOR PREDICTIVE DISTRIBUTION AT CURRENT TARGET ESTIMATE,0.611731843575419,"8
Construct approximate gradients ˜∇xg(s)
n
for s = 1, . . . , S using Equation 17."
END,0.6145251396648045,"9
end"
END,0.61731843575419,"10
Set δx = −2"
END,0.6201117318435754,"S
PS
s=1
PN
n=1(Ωn −σ(g(s)
n (x))σ′(g(s)
n (x)) ˜∇xg(s)
n (x) as per Equation 13."
END,0.6229050279329609,"11
Perform gradient descent update, x ←x + βδx with step-size β."
END,0.6256983240223464,"12
Project laser power onto feasible domain, I ←min(I, Imax)."
END,0.6284916201117319,13 end
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6312849162011173,"6.6
Additional details on ensemble stimulus optimisation approach"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6340782122905028,"The approach for optimising holographic ensemble stimuli is based on the approach for single-target
optimisation, but modified to account for differences in the ORF model and inference. In particular,
we again seek to minimise the error between a target activity pattern Ωand the predicted evoked
activity, but now using the MAP estimates G = {ˆgn, ˆθn}N
n=1 in place of the full posterior distributions.
Let ˆy(x, G) = (σ(ˆγ1(x) −ˆθ1), . . . , σ(ˆγN(x) −ˆθN)) be the predicted population response to an
ensemble stimulus, where ˆγn(x) = PJ
j=1 ˆgn
 
xj
. The optimal ensemble stimulus is now"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6368715083798883,"xoptimal = argmin
x
∥Ω−ˆy(x, G)∥2 = argmin
x N
X n=1"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6396648044692738,"
Ωn −σ(ˆγn(x) −ˆθn)
2
(18)"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6424581005586593,"such that 0 ≤I ≤Imax. Evaluating the partial derivative of Equation 18 with respect to dimension d
of a test point x∗yields,"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6452513966480447,"∂
∂x∗
d
∥Ω−ˆy(x∗, G)∥2 = −2 N
X"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6480446927374302,"n=1
(Ωn −σ(ˆγn(x∗) −ˆθn))σ′(ˆγn(x∗) −ˆθn) ∂"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6508379888268156,"∂x∗
d
ˆγn(x∗).
(19)"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6536312849162011,"The derivative on the right-hand side of Equation 19 is given by
∂
∂x∗
d ˆγn(x) = PJ
j=1
∂
∂x∗
d ˆgn(xj),"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6564245810055865,"which requires computing the derivative of ˆgn(xj). To evaluate this derivative, we use a similar trick
to Equation 16, but substituting the MAP estimate in place of the posterior mean or Monte Carlo
sample,"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.659217877094972,"∂
∂x∗
d
ˆgn(x∗) =
∂
∂x∗
d
mn(x∗) + cov

gn(X),
∂
∂x∗
d
gn(x∗)
⊤
K−1(ˆgn(X) −mn(X)).
(20)"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6620111731843575,"This expression can also be arrived at by first evaluating the posterior predictive mean of gn(x∗), and
then differentiating with respect to x∗
d."
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.664804469273743,We use Equation 20 to define a closed-form gradient ∇x∗ˆγn at test point x∗via
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6675977653631285,"∇x∗ˆγn =
∂ˆγn(x∗)"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6703910614525139,"∂x∗
1
, . . . , ∂ˆγn(x∗) ∂x∗
D"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6731843575418994,"⊤
.
(21)"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6759776536312849,"Finally, Equation 21 is used in the projected gradient descent algorithm for optimising ensemble
stimuli (Algorithm 1)."
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6787709497206704,"1
5
10
15
Stimulated ensemble size 0 2 4 6 8 10 12 14 16 18"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6815642458100558,Write-in error
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6843575418994413,"Nuclear
High coverage
Low coverage"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6871508379888268,"−20
−10
0
10
20
X distance (μm) −20 −10 0 10 20"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6899441340782123,Y distance (μm)
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6927374301675978,High coverage
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6955307262569832,"−20
−10
0
10
20
X distance (μm) −20 −10 0 10 20"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.6983240223463687,Y distance (μm)
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.7011173184357542,"Low coverage
a
b
c"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.7039106145251397,"Figure S1: Effect of reducing the number of points at which each ORF is probed. (a) In the high
coverage case (left), each ORF is probed by stimulating at a 5×5 grid of points near the soma (grid
points separated by 10 µm), at three different laser powers. In the low coverage case (right), this
reduces to stimulating at just a 3×3 grid (grid points separated by 12 µm) at three powers. However,
as the density of opsin-expressing neurons increases, ORFs are probed at high density even in the low
coverage case as the grids from different neurons increasingly overlap. (b) Minimal performance
difference between the high and low coverage cases in simulations with 50 neurons. (c) Reduction in
optical write-in error using cell-attached recordings as in Figure 4, but with low coverage. Reduction
in average write-in error, 74% (c.f. 85% with high coverage, Figure 4c)."
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.7067039106145251,"6.7
Further details on simulations and ""synthetic"" optogenetics experiments"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.7094972067039106,"Simulations consisted of both ORF mapping and stimulus optimisation phases. ORF mapping
required probing responses to stimulation at a range of laser powers and stimulus locations. We
defined a grid of stimulation points surrounding each neuron. In the spatial dimensions, the grid
ranged from −20 µm to 20 µm relative to the centroid of the neuron in steps of 10 µm, and powers
ranged from 30 mW to 70 mW in steps of 20 mW. The complete grid was thus given by the Cartesian
product {−20, −10, 0, 10, 20}×{−20, −10, 0, 10, 20}×{30, 50, 70}. For opsin-expressing neurons
that were spaced far apart, this coarse-resolution grid was sufficient because risk of OTS was low,
and therefore ORF mapping was not needed at high detail. On the other hand, as the density of
opsin-expressing neurons increased, the grids surrounding each neuron increasingly overlapped with
each other, resulting in much denser sampling of the ORFs."
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.7122905027932961,"For the synthetic optogenetics experiments (based on the cell-attached recordings), we used the same
spatial grid spacing but used laser powers of 10, 25, and 40 mW to match the range of powers used
in the underlying slice experiment, though note that the slice experiment had a denser spacing than
our chosen 15 mW (see example loose-patch recordings below), which we chose to reduce the ORF
mapping time. For the optogenetics experiments involving three spatial dimensions, we extended
the grid sampling to include depths of −60 µm to 60 µm in steps of 30 µm. We also explored the
effect of reducing the number of probed grid points to further reduce the time spent mapping ORFs,
and found that Bayesian target optimisation maintained high performance when probing with a 3 × 3
spatial grid of {−12, 0, 12} × {−12, 0, 12} (Figure S1)."
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.7150837988826816,"We selected the parameters of the GP covariance kernel using 5-fold cross-validation on a separate set
of recordings that were made on the same set of four cells, ensuring the hyperparameter selection was
using out-of-sample data. Cross-validation was performed using a grid search over a set of possible
hyperparameters: the possible radial lengthscales were 2, 4, 8, 16, the power lengthscales were 2,
4, 8, 16, and the amplitudes were 1, 2, 4, 8, 16. For each hyperparameter combination θ and for
each cell, we used Newton’s method to fit the GP-Bernoulli model to 80% of the trials in the loose-
patch data, yielding an ORF estimate ˆgθ. On the remaining 20% of the trials (denoted as Theld-out),
we evaluated the log-likelihood, P"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.7178770949720671,"t∈Theld-out {yt ln(σ(ˆgθ(xt))) + (1 −yt) ln(1 −σ(ˆgθ(xt)))} . We
averaged the log-likelihood across all five folds and across all four cells, and chose the hyperparameter
combination θ that yielded the largest average log-likelihood, resulting in a radial lengthscale of 8, a
power lengthscale of 16, and a kernel amplitude of 8."
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.7206703910614525,"The GP parameters for generating the simulations in Figure 3, inferring the resulting ORFs, and
generating synthetic optogenetics experiments with two and three spatial dimensions are given in
Table S1. For reference, a typical ORF mean function is given in Figure S2. 25 0 25"
ADDITIONAL DETAILS ON ENSEMBLE STIMULUS OPTIMISATION APPROACH,0.723463687150838,GP mean
MW,0.7262569832402235,"70 mW
Sample 1
Sample 2
Sample 3
Sample 4 25 0 25"
MW,0.729050279329609,Y distance ( m)
MW,0.7318435754189944,50 mW
MW,0.7346368715083799,"25 0
25 25 0 25"
MW,0.7374301675977654,30 mW
MW,0.7402234636871509,"25 0
25
25 0
25
X distance ( m)"
MW,0.7430167597765364,"25 0
25
25 0
25 0.0 0.5 1.0"
MW,0.7458100558659218,Spike prob
MW,0.7486033519553073,"Figure S2: Example mean function (shown at three powers) used for simulations (left column). Also
shown are four samples from the ORF prior corresponding to this mean function (right four columns).
Parameters given in Table S1."
MW,0.7513966480446927,Nuclear
MW,0.7541899441340782,Optimised 0.0 0.3 0.6 0.9 1.2 1.5
MW,0.7569832402234636,Write-in error
MW,0.7597765363128491,Nuclear
MW,0.7625698324022346,Optimised
MW,0.7653631284916201,(average) 30 32 34 36 38 40
MW,0.7681564245810056,Laser power (mW)
MW,0.770949720670391,"Average performance
(5 random repeats, matched powers)"
MW,0.7737430167597765,"Figure S3: Performance of Bayesian target optimisation compared to nuclear stimulation when
average laser powers are matched. Each repeat consists of randomly reassigning neurons different
optogenetic receptive fields while keeping their spatial positions fixed, and performing a full mapping
and target optimisation sequence. Within each repeat, nuclear stimulation was performed at the
average optimised power. Left: average write-in error for nuclear stimulation remains substantially
higher than with optimised stimulation despite having matched average powers. Each circle represents
a single neuron. Right: powers used within each repetition. Note that these powers are lower than the
40 mW used to benchmark performance in Figures 4 and 5 in the main text."
MW,0.776536312849162,"Parameter
Symbol
Value
Simulations (data generation)
Mean function excitability
ρ
0.125
Mean function width
σ2
m
3 × 102 µm
Spike threshold
θ
3.5
Kernel radial lengthscale
λs
8 µm
Kernel power lengthscale
λI
20 mW
Kernel amplitude
α2
0.2
Kernel marginal variance
σ2
d
10−5"
MW,0.7793296089385475,"Simultaneously stimulated neurons during ORF mapping
J
10
Simulations (ORF inference)
Mean function excitability
ρ
0.125
Mean function width
σ2
m
3 × 102 µm
Kernel radial lengthscale
λs
5 µm
Kernel power lengthscale
λI
16 mW
Kernel amplitude
α2
1
Kernel marginal variance
σ2
d
10−5"
MW,0.7821229050279329,"Learning rate for spike thresholds ({θn}N
n=1)
−
5
Number of random initialisations
−
5
Synthetic optogenetics experiments (two spatial dimensions)
Mean function excitability
ρ
0.175
Mean function width
σ2
m
3 × 102 µm
Kernel radial lengthscale
λs
8 µm
Kernel power lengthscale
λI
16 mW
Kernel amplitude
α2
8
Kernel marginal variance
σ2
d
10−5"
MW,0.7849162011173184,"Learning rate for spike thresholds ({θn}N
n=1)
−
5
Number of random initialisations
−
5
Synthetic optogenetics experiments (three spatial dimensions)
Mean function excitability
ρ
0.175
Mean function width (x/y dimensions)
σ2
m
3 × 102 µm
Mean function width (z dimension)
−
3 × 103 µm
Kernel radial lengthscale (x/y dimensions)
λs
8 µm
Kernel axial lengthscale (z dimension)
λz
32 µm
Kernel power lengthscale
λI
16 mW
Kernel amplitude
α2
8
Kernel marginal variance
σ2
d
10−5"
MW,0.7877094972067039,"Learning rate for spike thresholds ({θn}N
n=1)
−
5
Number of random initialisations
−
5"
MW,0.7905027932960894,Table S1: Parameters used for simulations and generating synthetic optogenetics experiments.
ADDITIONAL EXAMPLES OF OPTOGENETIC RECEPTIVE FIELDS FROM CELL-ATTACHED RECORDINGS,0.7932960893854749,"6.8
Additional examples of optogenetic receptive fields from cell-attached recordings"
ADDITIONAL EXAMPLES OF OPTOGENETIC RECEPTIVE FIELDS FROM CELL-ATTACHED RECORDINGS,0.7960893854748603,"Figures S4 to S7 show examples of four ORFs that have been comprehensively mapped using two-
photon optogenetic stimulation and cell-attached recordings of evoked spikes. Note the unpredictable
differences in ORF shape across laser powers and depths, motivating a nonparametric approach. 25 0 25"
ADDITIONAL EXAMPLES OF OPTOGENETIC RECEPTIVE FIELDS FROM CELL-ATTACHED RECORDINGS,0.7988826815642458,Depth = 75 m
ADDITIONAL EXAMPLES OF OPTOGENETIC RECEPTIVE FIELDS FROM CELL-ATTACHED RECORDINGS,0.8016759776536313,Y distance ( m)
MW,0.8044692737430168,"10 mW
15 mW
20 mW
30 mW
40 mW 25 0 25"
M,0.8072625698324022,50 m
M,0.8100558659217877,Y distance ( m) 25 0 25
M,0.8128491620111732,25 m
M,0.8156424581005587,Y distance ( m) 25 0 25
M,0.8184357541899442,0 m
M,0.8212290502793296,Y distance ( m) 25 0 25 -25 m
M,0.8240223463687151,Y distance ( m) 25 0 25 -50 m
M,0.8268156424581006,Y distance ( m)
M,0.8296089385474861,"25
0
25
X distance ( m) 25 0 25 -75 m"
M,0.8324022346368715,Y distance ( m)
M,0.835195530726257,"25
0
25
X distance ( m)"
M,0.8379888268156425,"25
0
25
X distance ( m)"
M,0.840782122905028,"25
0
25
X distance ( m)"
M,0.8435754189944135,"25
0
25
X distance ( m)"
M,0.8463687150837989,Figure S4: Loose-patch recording and inferred ORF (experiment 1/4). 25 0 25
M,0.8491620111731844,Depth = 75 m
M,0.8519553072625698,Y distance ( m)
MW,0.8547486033519553,"10 mW
15 mW
20 mW
30 mW
40 mW 25 0 25"
M,0.8575418994413407,50 m
M,0.8603351955307262,Y distance ( m) 25 0 25
M,0.8631284916201117,25 m
M,0.8659217877094972,Y distance ( m) 25 0 25
M,0.8687150837988827,0 m
M,0.8715083798882681,Y distance ( m) 25 0 25 -25 m
M,0.8743016759776536,Y distance ( m) 25 0 25 -50 m
M,0.8770949720670391,Y distance ( m)
M,0.8798882681564246,"25
0
25
X distance ( m) 25 0 25 -75 m"
M,0.88268156424581,Y distance ( m)
M,0.8854748603351955,"25
0
25
X distance ( m)"
M,0.888268156424581,"25
0
25
X distance ( m)"
M,0.8910614525139665,"25
0
25
X distance ( m)"
M,0.8938547486033519,"25
0
25
X distance ( m)"
M,0.8966480446927374,Figure S5: Loose-patch recording and inferred ORF (experiment 2/4) 25 0 25
M,0.8994413407821229,Depth = 75 m
M,0.9022346368715084,Y distance ( m)
MW,0.9050279329608939,"10 mW
15 mW
20 mW
30 mW
40 mW 25 0 25"
M,0.9078212290502793,50 m
M,0.9106145251396648,Y distance ( m) 25 0 25
M,0.9134078212290503,25 m
M,0.9162011173184358,Y distance ( m) 25 0 25
M,0.9189944134078212,0 m
M,0.9217877094972067,Y distance ( m) 25 0 25 -25 m
M,0.9245810055865922,Y distance ( m) 25 0 25 -50 m
M,0.9273743016759777,Y distance ( m)
M,0.9301675977653632,"25
0
25
X distance ( m) 25 0 25 -75 m"
M,0.9329608938547486,Y distance ( m)
M,0.9357541899441341,"25
0
25
X distance ( m)"
M,0.9385474860335196,"25
0
25
X distance ( m)"
M,0.9413407821229051,"25
0
25
X distance ( m)"
M,0.9441340782122905,"25
0
25
X distance ( m)"
M,0.946927374301676,Figure S6: Loose-patch recording and inferred ORF (experiment 3/4) 25 0 25
M,0.9497206703910615,Depth = 75 m
M,0.952513966480447,Y distance ( m)
MW,0.9553072625698324,"10 mW
15 mW
20 mW
30 mW
40 mW 25 0 25"
M,0.9581005586592178,50 m
M,0.9608938547486033,Y distance ( m) 25 0 25
M,0.9636871508379888,25 m
M,0.9664804469273743,Y distance ( m) 25 0 25
M,0.9692737430167597,0 m
M,0.9720670391061452,Y distance ( m) 25 0 25 -25 m
M,0.9748603351955307,Y distance ( m) 25 0 25 -50 m
M,0.9776536312849162,Y distance ( m)
M,0.9804469273743017,"25
0
25
X distance ( m) 25 0 25 -75 m"
M,0.9832402234636871,Y distance ( m)
M,0.9860335195530726,"25
0
25
X distance ( m)"
M,0.9888268156424581,"25
0
25
X distance ( m)"
M,0.9916201117318436,"25
0
25
X distance ( m)"
M,0.994413407821229,"25
0
25
X distance ( m)"
M,0.9972067039106145,Figure S7: Loose-patch recording and inferred ORF (experiment 4/4)
