Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0011350737797956867,"Dataset Distillation aims to compress a large dataset into a significantly more
2"
ABSTRACT,0.0022701475595913734,"compact, synthetic one without compromising the performance of the trained mod-
3"
ABSTRACT,0.00340522133938706,"els. To achieve this, existing methods use the agent model to extract information
4"
ABSTRACT,0.004540295119182747,"from the target dataset and embed it into the distilled dataset. Consequently, the
5"
ABSTRACT,0.0056753688989784334,"quality of extracted and embedded information determines the quality of the dis-
6"
ABSTRACT,0.00681044267877412,"tilled dataset. In this work, we find that existing methods introduce misaligned
7"
ABSTRACT,0.007945516458569807,"information in both information extraction and embedding stages. To alleviate
8"
ABSTRACT,0.009080590238365494,"this, we propose Prioritize Alignment in Dataset Distillation (PAD), which aligns
9"
ABSTRACT,0.01021566401816118,"information from the following two perspectives. 1) We prune the target dataset
10"
ABSTRACT,0.011350737797956867,"according to the compressing ratio to filter the information that can be extracted
11"
ABSTRACT,0.012485811577752554,"by the agent model. 2) We use only deep layers of the agent model to perform the
12"
ABSTRACT,0.01362088535754824,"distillation to avoid excessively introducing low-level information. This simple
13"
ABSTRACT,0.014755959137343927,"strategy effectively filters out misaligned information and brings non-trivial im-
14"
ABSTRACT,0.015891032917139614,"provement for mainstream matching-based distillation algorithms. Furthermore,
15"
ABSTRACT,0.0170261066969353,"built on trajectory matching, PAD achieves remarkable improvements on vari-
16"
ABSTRACT,0.018161180476730987,"ous benchmarks, achieving state-of-the-art performance. The code and distilled
17"
ABSTRACT,0.019296254256526674,"datasets will be made public.
18"
INTRODUCTION,0.02043132803632236,"1
Introduction
19"
INTRODUCTION,0.021566401816118047,"Dataset Distillation (DD) [43] aims to compress a large dataset into a small synthetic dataset that
20"
INTRODUCTION,0.022701475595913734,"preserves important features for models to achieve comparable performances. Ever since being
21"
INTRODUCTION,0.02383654937570942,"introduced, DD has gained a lot of attention because of its wide applications in practical fields such
22"
INTRODUCTION,0.024971623155505107,"as privacy preservation [5, 44], continual learning [28, 35], and neural architecture search [12, 32].
23"
INTRODUCTION,0.026106696935300794,"Recently, matching-based methods [46, 42, 6] have achieved promising performance in distilling
24"
INTRODUCTION,0.02724177071509648,"high-quality synthetic datasets. Generally, the process of these methods can be summarized into two
25"
INTRODUCTION,0.028376844494892167,"steps: (1) Information Extraction: an agent model is used to extract important information from the
26"
INTRODUCTION,0.029511918274687854,"target dataset by recording various metrics such as gradients [49], distributions [48], and training
27"
INTRODUCTION,0.03064699205448354,"trajectories [1], (2) Information Embedding: the synthetic samples are optimized to incorporate the
28"
INTRODUCTION,0.03178206583427923,"extracted information, which is achieved by minimizing the differences between the same metric
29"
INTRODUCTION,0.032917139614074914,"calculated on the synthetic data and the one recorded in the previous step.
30"
INTRODUCTION,0.0340522133938706,"In this work, we first reveal both steps will introduce misaligned information, which is redundant
31"
INTRODUCTION,0.03518728717366629,"and potentially detrimental to the quality of the synthetic data. Then, by analyzing the cause of this
32"
INTRODUCTION,0.036322360953461974,"misalignment, we propose alleviating this problem through the following two perspectives.
33"
INTRODUCTION,0.03745743473325766,"Typically, in the Information Extraction step, most distillation methods allow the agent model to
34"
INTRODUCTION,0.03859250851305335,"see all samples in the target dataset. This means information extracted by the agent model comes
35"
INTRODUCTION,0.039727582292849034,"from samples with various difficulties (see Figure 1(a)). However, according to previous study
36 +"
INTRODUCTION,0.04086265607264472,"100% easy 
100% hard"
INTRODUCTION,0.04199772985244041,"for all IPCs
IPC"
INTRODUCTION,0.043132803632236094,100% easy +
INTRODUCTION,0.04426787741203178,"100% easy 
50% hard +"
INTRODUCTION,0.04540295119182747,"50% easy 
100% hard"
INTRODUCTION,0.046538024971623154,"small
medium
large …
…"
INTRODUCTION,0.04767309875141884,"previous methods
ours"
INTRODUCTION,0.04880817253121453,(a) Data used for distillation
INTRODUCTION,0.049943246311010214,"IPC
small
medium
large"
INTRODUCTION,0.0510783200908059,"discard
discard
discard"
INTRODUCTION,0.05221339387060159,agent model
INTRODUCTION,0.053348467650397274,shallow layer
INTRODUCTION,0.05448354143019296,"deep layer
distill"
INTRODUCTION,0.05561861520998865,distill
INTRODUCTION,0.056753688989784334,"more 
semantical 
information"
INTRODUCTION,0.05788876276958002,"more 
low-level 
information"
INTRODUCTION,0.05902383654937571,(b) Parameters used for distillation
INTRODUCTION,0.060158910329171394,"Figure 1: (a) Compared with using all samples without differentiation in IPCs (left), PAD meticulously
selects a subset of samples for different IPCs to align the expected difficulty of information required
(right). (b) Different layers distill different patterns (left). PAD masks out (grey box) shallow-layer
parameters during metric matching in accordance with IPCs (right)."
INTRODUCTION,0.06129398410896708,"[10], information related to easy samples is only needed when the compression ratio is high. This
37"
INTRODUCTION,0.06242905788876277,"misalignment leads to the sub-optimal of the distillation performance.
38"
INTRODUCTION,0.06356413166855845,"To alleviate the above issue, we first use data selection methods to measure the difficulty of each
39"
INTRODUCTION,0.06469920544835414,"sample in the target dataset. Then, during the distillation, a data scheduler is employed to ensure only
40"
INTRODUCTION,0.06583427922814983,"data whose difficulty is aligned with the compression ratio is available for the agent model.
41"
INTRODUCTION,0.06696935300794551,"In the Information Embedding step, most distillation methods except DM [48] choose to use all
42"
INTRODUCTION,0.0681044267877412,"parameters of the agent model to perform the distillation. Intuitively, this will ensure the information
43"
INTRODUCTION,0.06923950056753689,"extracted by the agent model is fully utilized. However, we find shallow layer parameters of the
44"
INTRODUCTION,0.07037457434733257,"model can only provide low-quality, basic signals, which are redundant for dataset distillation in
45"
INTRODUCTION,0.07150964812712826,"most cases. Conversely, performing the distillation with only parameters from deep layers will yield
46"
INTRODUCTION,0.07264472190692395,"high-quality synthetic samples. We attribute this contradiction to the fact that deeper layers in DNNs
47"
INTRODUCTION,0.07377979568671963,"tend to learn higher-level representations of input data [27, 37].
48"
INTRODUCTION,0.07491486946651532,"Based on our findings, to avoid embedding misaligned information in the Information Embedding step,
49"
INTRODUCTION,0.07604994324631101,"we propose to use only parameters from deeper layers of the agent model to perform distillation, as
50"
INTRODUCTION,0.0771850170261067,"illustrated in Figure 1(b). This simple change brings significant performance improvement, showing
51"
INTRODUCTION,0.07832009080590238,"its effectiveness in aligning information.
52"
INTRODUCTION,0.07945516458569807,"Through experiments, we validate that our two-step alignment strategy is effective for distillation
53"
INTRODUCTION,0.08059023836549375,"methods based on matching gradients [49], distributions [48], and trajectories [1]. Moreover, by
54"
INTRODUCTION,0.08172531214528944,"applying our alignment strategy on trajectory matching [1, 10], we propose our novel method named
55"
INTRODUCTION,0.08286038592508513,"Prioritize Alignment in Dataset Distillation (PAD). After conducting comprehensive evaluation
56"
INTRODUCTION,0.08399545970488081,"experiments, we show PAD achieves state-of-the-art (SOTA) performance.
57"
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.0851305334846765,"2
Misaligned Information in Dataset Distillation
58"
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.08626560726447219,"Generally, we can summarize the distillation process of matching-based methods into the following
59"
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.08740068104426787,"two steps: (1) Information Extraction: use an agent model to extract essential information from the
60"
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.08853575482406356,"target dataset, realized by recording metrics such as gradients [49], distributions [48], and training
61"
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.08967082860385925,"trajectories [1], (2) Information Embedding: the synthetic samples are optimized to incorporate the
62"
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.09080590238365494,"extracted information, realized by minimizing the differences between the same metric calculated on
63"
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.09194097616345062,"the synthetic data and the one recorded in the first step.
64 65 66 67"
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.09307604994324631,"10
15
20
25
Ratio (%) 16 17 18 19"
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.094211123723042,Acc (%)
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.09534619750283768,"Remove easy
samples"
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.09648127128263337,"Remove hard
samples
ipc500
ipc1
baseline"
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.09761634506242906,(a) Matching gradients 69 70 71
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.09875141884222474,"10
15
20
25
Ratio (%) 25 26 27 28"
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.09988649262202043,Acc (%)
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.10102156640181612,(b) Matching distributions 82 83
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.1021566401816118,"10
15
20
25
Ratio (%) 45 46 47"
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.10329171396140749,Acc (%)
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.10442678774120318,(c) Matching trajectories
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.10556186152099886,"Figure 2: Distillation performance on CIFAR-10 where data points are removed with different ratios.
Removing unnecessary data points helps to improve the performance of methods based on matching
gradients, distributions, and trajectories, both in low and high IPC cases. 65 66"
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.10669693530079455,"0
25
50
75
Ratio (%) 27 28 29"
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.10783200908059024,Acc (%)
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.10896708286038592,"ipc500
ipc10
baseline"
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.11010215664018161,(a) Matching gradients 67 68
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.1112372304199773,"0
25
50
75
Ratio (%) 27 28 29"
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.11237230419977298,Acc (%)
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.11350737797956867,(b) Matching distributions 83 84
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.11464245175936436,"0
25
50
75
Ratio (%) 65 66 67"
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.11577752553916004,Acc (%)
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.11691259931895573,(c) Matching trajectories
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.11804767309875142,"Figure 3: Distillation performances on CIFAR-10 where n% (ratio) shallow layer parameters are not
utilized during distillation. Discarding shallow-layer parameters is beneficial for methods based on
matching gradients, distributions, and trajectories, both in low and high IPC cases."
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.1191827468785471,"In this section, through analyses and experimental verification, we show the above two steps both
65"
MISALIGNED INFORMATION IN DATASET DISTILLATION,0.12031782065834279,"will introduce misaligned information to the synthetic data.
66"
MISALIGNED INFORMATION EXTRACTED BY AGENT MODELS,0.12145289443813848,"2.1
Misaligned Information Extracted by Agent Models
67"
MISALIGNED INFORMATION EXTRACTED BY AGENT MODELS,0.12258796821793416,"In the information extraction step, an agent model is employed to extract information from the target
68"
MISALIGNED INFORMATION EXTRACTED BY AGENT MODELS,0.12372304199772985,"dataset. Generally, most existing methods [1, 6, 49, 46] allow the agent model to see the full dataset.
69"
MISALIGNED INFORMATION EXTRACTED BY AGENT MODELS,0.12485811577752554,"This implies that the information extracted by the agent model originates from samples with diverse
70"
MISALIGNED INFORMATION EXTRACTED BY AGENT MODELS,0.12599318955732122,"levels of difficulty. However, the expected difficulty of distilled information varies with changes in
71"
MISALIGNED INFORMATION EXTRACTED BY AGENT MODELS,0.1271282633371169,"IPC: smaller IPCs prefer easier information while larger IPCs should distill harder one [10].
72"
MISALIGNED INFORMATION EXTRACTED BY AGENT MODELS,0.1282633371169126,"To verify if this misalignment will influence the quality of synthetic data, we perform the distillation
73"
MISALIGNED INFORMATION EXTRACTED BY AGENT MODELS,0.12939841089670828,"where hard/easy samples of target dataset are removed with various ratios. As the results reported in
74"
MISALIGNED INFORMATION EXTRACTED BY AGENT MODELS,0.13053348467650397,"Figure 2, pruning unaligned data points is beneficial for all matching-based methods. This proves the
75"
MISALIGNED INFORMATION EXTRACTED BY AGENT MODELS,0.13166855845629966,"misalignment indeed will influence the distillation performance and can be alleviated by filtering out
76"
MISALIGNED INFORMATION EXTRACTED BY AGENT MODELS,0.13280363223609534,"misaligned data from the target dataset.
77"
MISALIGNED INFORMATION EMBEDDED BY METRIC MATCHING,0.13393870601589103,"2.2
Misaligned Information Embedded by Metric Matching
78"
MISALIGNED INFORMATION EMBEDDED BY METRIC MATCHING,0.13507377979568672,"Most existing methods use all parameters of the agent model to compute the metric used for matching.
79"
MISALIGNED INFORMATION EMBEDDED BY METRIC MATCHING,0.1362088535754824,"Intuitively, this helps to improve the distillation performance, since in this way all information
80"
MISALIGNED INFORMATION EMBEDDED BY METRIC MATCHING,0.1373439273552781,"extracted by the agent model will be embedded into the synthetic dataset. However, since shallow
81"
MISALIGNED INFORMATION EMBEDDED BY METRIC MATCHING,0.13847900113507378,"layers in DNNs tend to learn basic distributions of data [27, 37], using parameters from these layers
82"
MISALIGNED INFORMATION EMBEDDED BY METRIC MATCHING,0.13961407491486946,"can only provide low-level signals that turned out to be redundant in most cases.
83"
MISALIGNED INFORMATION EMBEDDED BY METRIC MATCHING,0.14074914869466515,"As can be observed in Figure 3, it is evident that across all matching-based methods, the removal
84"
MISALIGNED INFORMATION EMBEDDED BY METRIC MATCHING,0.14188422247446084,"of shallow layer parameters consistently enhances performance, regardless of the IPC setting. This
85"
MISALIGNED INFORMATION EMBEDDED BY METRIC MATCHING,0.14301929625425652,"proves employing over-shallow layer parameters to perform the distillation will introduce misaligned
86"
MISALIGNED INFORMATION EMBEDDED BY METRIC MATCHING,0.1441543700340522,"information to the synthetic data, compromising the quality of distilled data.
87"
METHOD,0.1452894438138479,"3
Method
88"
METHOD,0.14642451759364358,"To alleviate the information misalignment issue, based on trajectory matching (TM) [1, 10], we
89"
METHOD,0.14755959137343927,"propose Prioritizing Alignment in Dataset Distillation (PAD). PAD can also be applied to methods
90"
METHOD,0.14869466515323496,"based on matching gradients [49] and distributions [48], which are introduced in Appendix A.1.
91"
PRELIMINARY OF TRAJECTORY MATCHING,0.14982973893303064,"3.1
Preliminary of Trajectory Matching
92"
PRELIMINARY OF TRAJECTORY MATCHING,0.15096481271282633,"Following the two-step procedure, to extract information, TM-based methods [1, 10] first train agent
93"
PRELIMINARY OF TRAJECTORY MATCHING,0.15209988649262202,"models on the real dataset DR and record the changes of the parameters. Specifically, let {θ∗
t }N
0 be
94"
PRELIMINARY OF TRAJECTORY MATCHING,0.1532349602724177,"an expert trajectory, which is a parameter sequence recorded during the training of agent model. At
95"
PRELIMINARY OF TRAJECTORY MATCHING,0.1543700340522134,"each iteration of trajectory matching, θ∗
t and θ∗
t+M are randomly selected from expert trajectories as
96"
PRELIMINARY OF TRAJECTORY MATCHING,0.15550510783200908,"the start and target parameters.
97"
PRELIMINARY OF TRAJECTORY MATCHING,0.15664018161180476,"To embed the information into the synthetic data, TM methods minimize the distance between the
98"
PRELIMINARY OF TRAJECTORY MATCHING,0.15777525539160045,"expert trajectory and the student trajectory. Let ˆθt denote the parameters of the student agent model
99"
PRELIMINARY OF TRAJECTORY MATCHING,0.15891032917139614,"trained on synthetic dataset DS at timestep t. The student trajectory progresses by doing gradient
100"
PRELIMINARY OF TRAJECTORY MATCHING,0.16004540295119182,"descent on the cross-entropy loss l for N steps:
101"
PRELIMINARY OF TRAJECTORY MATCHING,0.1611804767309875,"ˆθt+i+1 = ˆθt+i −α∇l(ˆθt+i, DS),
(1)
Finally, the synthetic data is optimized by minimizing the distance metric, which is formulated as:
102"
PRELIMINARY OF TRAJECTORY MATCHING,0.1623155505107832,"L = ||ˆθt+N −θ∗
t+M||
||θ∗
t+M −θ∗
t || ,
(2)"
FILTERING INFORMATION EXTRACTION,0.16345062429057888,"3.2
Filtering Information Extraction
103"
FILTERING INFORMATION EXTRACTION,0.16458569807037457,"In section 2.1, we show using data selection to filter out unmatched samples could alleviate the
104"
FILTERING INFORMATION EXTRACTION,0.16572077185017026,"misalignment caused in Information Extraction step. According to previous work [10], TM-based
105"
FILTERING INFORMATION EXTRACTION,0.16685584562996594,"methods prefer easy information and choose to match only early trajectories when IPC is small.
106"
FILTERING INFORMATION EXTRACTION,0.16799091940976163,"Conversely, hard information is preferred by high IPCs and they match only late trajectories. Hence,
107"
FILTERING INFORMATION EXTRACTION,0.16912599318955732,"we should use easy samples to train early trajectories, while late trajectories should be trained with
108"
FILTERING INFORMATION EXTRACTION,0.170261066969353,"hard samples. To realize this efficiently, we first use the data selection method to measure the difficulty
109"
FILTERING INFORMATION EXTRACTION,0.1713961407491487,"of samples contained in the target dataset. Then, during training expert trajectories, a scheduler is
110"
FILTERING INFORMATION EXTRACTION,0.17253121452894438,"implemented to gradually incorporate hard samples into the training set while excluding easier ones
111"
FILTERING INFORMATION EXTRACTION,0.17366628830874006,"from it.
112"
FILTERING INFORMATION EXTRACTION,0.17480136208853575,"Difficulty Scoring Function
Identifying the difficulty of data for DNNs to learn has been well
113"
FILTERING INFORMATION EXTRACTION,0.17593643586833144,"studied in data selection area [29, 17, 16, 40]. For simplicity consideration, we use Error L2-Norm
114"
FILTERING INFORMATION EXTRACTION,0.17707150964812712,"(EL2N) score [33] as the metric to evaluate the difficulty of training examples (other metrics can also
115"
FILTERING INFORMATION EXTRACTION,0.1782065834279228,"be chosen, see Section 4.3.2). Specifically, let x and y denote a data point and its label, respectively.
116"
FILTERING INFORMATION EXTRACTION,0.1793416572077185,"Then, the EL2N score can be calculated by:
117"
FILTERING INFORMATION EXTRACTION,0.18047673098751418,"χt(x, y) = E||p(wt, x) −y||2,
(3)
where p(wt, x) = σ(f(wt, x)) is the output of a model f at training step t transformed into a
118"
FILTERING INFORMATION EXTRACTION,0.18161180476730987,"probability distribution. In consistent with [40], samples with higher EL2N scores are considered as
119"
FILTERING INFORMATION EXTRACTION,0.18274687854710556,"harder samples in this paper.
120"
FILTERING INFORMATION EXTRACTION,0.18388195232690124,"Scheduler
The scheduler can be divided into the following stages. Firstly, the hardest samples are
121"
FILTERING INFORMATION EXTRACTION,0.18501702610669693,"removed from the training set, ensuring that it exclusively comprises data meeting a predetermined
122"
FILTERING INFORMATION EXTRACTION,0.18615209988649262,"initial ratio (IR). Then, during training expert trajectories, samples are gradually added to the training
123"
FILTERING INFORMATION EXTRACTION,0.1872871736662883,"set in order of increasing difficulty. After incorporating all the data into the training set, the scheduler
124"
FILTERING INFORMATION EXTRACTION,0.188422247446084,"will begin to remove easy samples from the target dataset. Unlike the gradual progression involved in
125"
FILTERING INFORMATION EXTRACTION,0.18955732122587968,"adding data, the action of reducing data is completed in a single operation, since now the model has
126"
FILTERING INFORMATION EXTRACTION,0.19069239500567536,"been trained on simple samples for a sufficient time.
127"
FILTERING INFORMATION EXTRACTION,0.19182746878547105,"Dataset
CIFAR-10
CIFAR-100
Tiny ImageNet
IPC
1
10
50
500
1000
1
10
50
100
1
10
50
Ratio
0.02
0.2
1
10
20
0.2
2
10
20
0.2
2
10"
FILTERING INFORMATION EXTRACTION,0.19296254256526674,"Random
15.4±0.3
31.0±0.5
50.6±0.3
73.2±0.3
78.4±0.2
4.2±0.3
14.6±0.5
33.4±0.4
42.8±0.3
1.4±0.1
5.0±0.2
15.0±0.4
KIP [31]
49.9±0.2
62.7±0.3
68.6±0.2
-
-
15.7±0.2
28.3±0.1
-
-
-
-
-
FRePo [50]
46.8±0.7
65.5±0.4
71.7±0.2
-
-
28.7±0.1
42.5±0.2
44.3±0.2
-
15.4±0.3
25.4±0.2
-
RCIG [26]
53.9±1.0
69.1±0.4
73.5±0.3
-
-
39.3±0.4
44.1±0.4
46.7±0.3
-
25.6±0.3
29.4±0.2
-"
FILTERING INFORMATION EXTRACTION,0.19409761634506242,"DC [49]
28.3±0.5
44.9±0.5
53.9±0.5
72.1±0.4
76.6±0.3
12.8±0.3
25.2±0.3
-
-
-
-
-
DM [48]
26.0±0.8
48.9±0.6
63.0±0.4
75.1±0.3
78.8±0.1
11.4±0.3
29.7±0.3
43.6±0.4
-
3.9±0.2
12.9±0.4
24.1±0.3
DSA [47]
28.8±0.7
52.1±0.5
60.6±0.5
73.6±0.3
78.7±0.3
13.9±0.3
32.3±0.3
42.8±0.4
-
-
-
-
TESLA [4]
48.5±0.8
66.4±0.8
72.6±0.7
-
-
24.8±0.4
41.7±0.3
47.9±0.3
49.2±0.4
-
-
-
CAFE [42]
30.3±1.1
46.3±0.6
55.5±0.6
-
-
12.9±0.3
27.8±0.3
37.9±0.3
-
-
-
-
MTT [1]
46.2±0.8
65.4±0.7
71.6±0.2
-
-
24.3±0.3
39.7±0.4
47.7±0.2
49.2±0.4
8.8±0.3
23.2±0.2
28.0±0.3
FTD [6]
46.0±0.4
65.3±0.4
73.2±0.2
-
-
24.4±0.4
42.5±0.2
48.5±0.3
49.7±0.4
10.5±0.2
23.4±0.3
28.2±0.4
DATM [10]
46.9±0.5
66.8±0.2
76.1±0.3
83.5±0.2
85.5±0.4
27.9±0.2
47.2±0.4
55.0±0.2
57.5±0.2
17.1±0.3
31.1±0.3
39.7±0.3
PAD
47.2±0.6
67.4±0.3
77.0±0.5
84.6±0.3
86.7±0.2
28.4±0.5
47.8±0.2
55.9±0.3
58.5±0.3
17.7±0.2
32.3±0.4
41.6±0.4"
FILTERING INFORMATION EXTRACTION,0.1952326901248581,"Full Dataset
84.8±0.1
56.2±0.3
37.6±0.4"
FILTERING INFORMATION EXTRACTION,0.1963677639046538,"Table 1: Comparison with previous dataset distillation methods (bottom: matching-based, top: others)
on CIFAR-10, CIFAR-100 and Tiny ImageNet. ConvNet is used for the distillation and evaluation.
Our method consistently outperforms prior matching-based methods."
FILTERING INFORMATION EMBEDDING,0.19750283768444948,"3.3
Filtering Information Embedding
128"
FILTERING INFORMATION EMBEDDING,0.19863791146424517,"To filter out misaligned information introduced by matching shallow-layer parameters, we propose
129"
FILTERING INFORMATION EMBEDDING,0.19977298524404086,"to add a parameter selection module that masks out part of shallow layers for metric computation.
130"
FILTERING INFORMATION EMBEDDING,0.20090805902383654,"Specifically, parameters of an agent network can be represented as a flattened array of length L that
131"
FILTERING INFORMATION EMBEDDING,0.20204313280363223,"stores weights of agent models ordered from shallow to deep layers (parameters within the same
132"
FILTERING INFORMATION EMBEDDING,0.20317820658342792,"layer are sorted in default order). The parameter selection sets a threshold ratio α such that the first
133"
FILTERING INFORMATION EMBEDDING,0.2043132803632236,"k = L · α parameters are not used for distillation. Then the parameters used for matching can now be
134"
FILTERING INFORMATION EMBEDDING,0.2054483541430193,"formulated as:
135"
FILTERING INFORMATION EMBEDDING,0.20658342792281498,"ˆθt+N = {ˆθ0, ˆθ1, · · · , ˆθk−1
|
{z
}
discard"
FILTERING INFORMATION EMBEDDING,0.20771850170261066,", ˆθk, ˆθk+1, · · · , ˆθL
|
{z
}
used for matching"
FILTERING INFORMATION EMBEDDING,0.20885357548240635,"}.
(4)"
FILTERING INFORMATION EMBEDDING,0.20998864926220204,"In practice, the ratio α should vary with the change of IPC. For smaller IPCs, it is necessary to
136"
FILTERING INFORMATION EMBEDDING,0.21112372304199772,"incorporate basic information thus α should be lower. Conversely, basic information is redundant in
137"
FILTERING INFORMATION EMBEDDING,0.2122587968217934,"larger IPC cases, so α should be higher accordingly.
138"
EXPERIMENTS,0.2133938706015891,"4
Experiments
139"
SETTINGS,0.21452894438138478,"4.1
Settings
140"
SETTINGS,0.21566401816118047,"We compare PAD with several prominent dataset distillation methods, which can be divided into two
141"
SETTINGS,0.21679909194097616,"categories: matching-based approaches including DC [49], DM [48], DSA [47], CAFE [42], MTT [1],
142"
SETTINGS,0.21793416572077184,"FTD [6], DATM [10], TESLA [4], and kernel-based approaches including KIP [31], FRePo [50],
143"
SETTINGS,0.21906923950056753,"RCIG [26]. The assessment is conducted on widely recognized datasets: CIFAR-10, CIFAR-100[18],
144"
SETTINGS,0.22020431328036322,"and Tiny ImageNet [20]. We implemented our method based on DATM [10]. In both the distillation
145"
SETTINGS,0.2213393870601589,"and evaluation phases, we apply the standard set of differentiable augmentations commonly used in
146"
SETTINGS,0.2224744608399546,"previous studies [1, 6, 10]. By default, networks are constructed with instance normalization unless
147"
SETTINGS,0.22360953461975028,"explicitly labeled with ""-BN,"" indicating batch normalization (e.g., ConvNet-BN). For CIFAR-10
148"
SETTINGS,0.22474460839954596,"and CIFAR-100, distillation is typically performed using a 3-layer ConvNet, while Tiny ImageNet
149"
SETTINGS,0.22587968217934165,"requires a 4-layer ConvNet. Cross-architecture experiments also utilize LeNet [21], AlexNet [19],
150"
SETTINGS,0.22701475595913734,"VGG11 [39], and ResNet18 [11]. More details can be found in the appendix.
151"
MAIN RESULTS,0.22814982973893302,"4.2
Main Results
152"
MAIN RESULTS,0.2292849035187287,"CIFAR and Tiny ImageNet
We conduct comprehensive experiments to compare the performance
153"
MAIN RESULTS,0.2304199772985244,"of our method with previous works. As the results presented in Table 1, PAD outperforms previous
154"
MAIN RESULTS,0.23155505107832008,"matching-based methods on three datasets except for the case when IPC=1. When compared with
155"
MAIN RESULTS,0.23269012485811577,"kernel-based methods which use a larger network to perform the distillation, our technique exhibits
156"
MAIN RESULTS,0.23382519863791146,"superior performance in most cases, particularly when the compression ratio exceeds 1%. As can be
157"
MAIN RESULTS,0.23496027241770714,"observed, PAD performs relatively better when IPC is high, suggesting our filtering out misaligned
158"
MAIN RESULTS,0.23609534619750283,"information strategy becomes increasingly effective as IPC increases.
159"
MAIN RESULTS,0.23723041997729852,"Dataset
Ratio
Method
ConvNet
ConvNet-BN
ResNet18
ResNet18-BN
VGG11
AlexNet
LeNet
MLP
Avg."
MAIN RESULTS,0.2383654937570942,"CIFAR-10
20%"
MAIN RESULTS,0.2395005675368899,"Random
78.38
80.25
84.58
87.21
80.81
80.75
61.85
50.98
75.60
Glister
62.46
70.52
81.10
74.59
78.07
70.55
56.56
40.59
66.81
Forgetting
76.27
80.06
85.67
87.18
82.04
81.35
64.59
52.21
76.17
DATM
85.50
85.23
87.22
88.13
84.65
85.14
66.70
52.40
79.37
PAD
86.90
85.67
86.95
88.09
84.34
85.83
67.28
53.62
79.84
↑
+8.52
+5.42
+2.37
+0.88
+3.53
+5.08
+5.43
+2.64
+4.24"
MAIN RESULTS,0.24063564131668558,"CIFAR-100
20%"
MAIN RESULTS,0.24177071509648126,"Random
42.80
46.38
47.48
55.62
42.69
38.05
25.91
20.66
39.95
Glister
35.45
37.13
42.49
46.14
43.06
28.58
23.33
17.08
34.16
Forgetting
45.52
49.99
51.44
54.65
43.28
43.47
27.22
22.90
42.30
DATM
57.50
57.75
57.98
63.34
55.10
55.69
33.57
26.39
50.92
PAD
58.50
58.66
58.15
63.17
55.02
55.93
33.87
27.12
51.30
↑
+15.70
+12.28
+10.67
+7.55
+12.33
+17.88
+7.96
+6.46
+11.35"
MAIN RESULTS,0.24290578887627695,"Tiny
10%"
MAIN RESULTS,0.24404086265607264,"Random
15.00
24.21
17.73
28.07
22.51
14.03
9.25
5.85
17.08
Glister
17.32
19.77
18.84
23.12
19.10
11.68
8.84
3.86
15.32
Forgetting
20.04
23.83
19.38
28.88
23.77
12.13
12.06
5.54
18.20
DATM
39.68
40.32
36.12
43.14
38.35
35.10
12.41
9.02
31.76
PAD
41.02
40.88
36.08
42.96
38.64
35.02
13.17
9.68
32.18
↑
+26.02
+16.67
+18.35
+14.89
+16.13
+20.99
+3.92
+3.83
+15.10
Table 2: Cross-architecture evaluation of distilled data on unseen networks. Results worse than
random selection are indicated with red color. ↑denotes the performance improvement brought by
our method compared with random selection. Tiny denotes Tiny ImageNet."
MAIN RESULTS,0.24517593643586832,"Method
ConvNet
ResNet18
VGG
AlexNet"
MAIN RESULTS,0.246311010215664,"Random
33.46
31.95
32.18
26.65
FTD
48.90
46.65
43.24
42.20
DATM
55.03
51.71
45.38
45.74
PAD
55.91
52.35
44.97
45.92"
MAIN RESULTS,0.2474460839954597,"(a) Datasets distilled by PAD general-
ize well across various architectures."
MAIN RESULTS,0.24858115777525538,"FIEX
FIEM
Accuracy(%)"
MAIN RESULTS,0.24971623155505107,"66.7
✓
66.9
✓
67.2
✓
✓
67.4"
MAIN RESULTS,0.2508513053348468,"(b) Each module brings non-
trivial improvements."
MAIN RESULTS,0.25198637911464244,"IR
AEE
20
40
60"
MAIN RESULTS,0.25312145289443816,"50%
66.23
66.07
65.92
75%
67.36
67.34
66.58
80%
67.26
67.08
66.47"
MAIN RESULTS,0.2542565266742338,"(c) Set IR as 75% always per-
form best."
MAIN RESULTS,0.25539160045402953,"Table 3: (a) Cross-Architecture evaluation on CIFAR-100 IPC50. (b) Ablation studies on the modules
of our method on CIFAR-10 IPC10. (c) Results of different sets of data selection hyper-parameters
on CIFAR-10 IPC10."
MAIN RESULTS,0.2565266742338252,"Cross Architecture Generalization
We evaluate the generalizability of our distilled data in both
160"
MAIN RESULTS,0.2576617480136209,"low and high IPC cases. As results reported in Table 3(a), when IPC is small, our distilled data
161"
MAIN RESULTS,0.25879682179341656,"outperforms the previous SOTA method DATM on ResNet and AlexNet while maintaining comparable
162"
MAIN RESULTS,0.2599318955732123,"accuracy on VGG. This suggests that our distilled data on high compressing ratios generalizes well
163"
MAIN RESULTS,0.26106696935300794,"across various unseen networks. Moreover, as reflected in Table 2, our distilled datasets on large IPCs
164"
MAIN RESULTS,0.26220204313280365,"also have the best performance on most evaluated architectures, showing good generalizability in the
165"
MAIN RESULTS,0.2633371169125993,"low compressing ratio case.
166"
ABLATION STUDY,0.264472190692395,"4.3
Ablation Study
167"
ABLATION STUDY,0.2656072644721907,"To validate the effectiveness of each component of our method, we conducted ablation experiments
168"
ABLATION STUDY,0.2667423382519864,"on modules (section 4.3.1) and their hyper-parameter settings (section 4.3.2 and section 4.3.2).
169"
MODULES,0.26787741203178206,"4.3.1
Modules
170"
MODULES,0.2690124858115778,"Our method incorporates two separate modules to filter information extraction (FIEX) and information
171"
MODULES,0.27014755959137343,"embedding (FIEM), respectively. To verify their isolated effectiveness, we conduct an ablation study
172"
MODULES,0.27128263337116915,"by applying two modules individually. As depicted in Table 3(b), both FIEX and FIEM bring
173"
MODULES,0.2724177071509648,"improvements, implying their efficacy. By applying these two modules, we are able to effectively
174"
MODULES,0.2735527809307605,"remove unaligned information, improving the distillation performance.
175"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.2746878547105562,"4.3.2
Hyper-parameters of Filtering Information Extraction
176"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.2758229284903519,"Initial Ratio and Data Addition Epoch
To filter the information learned by agent models, we
177"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.27695800227014755,"initialize the training set with only easy samples, and the size is determined by a certain ratio of
178"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.27809307604994327,"the total size. Then, we gradually add hard samples into the training set. In practice, we use two
179"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.2792281498297389,"hyper-parameters to control the addition process: the initial ratio (IR) of training data for training
180"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.28036322360953464,"set initialization and the end epoch of hard sample addition (AEE). These two parameters together
181"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.2814982973893303,"control the amount of data agent models can see at each epoch and the speed of adding hard samples.
182"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.282633371169126,"Method
IPC
1
10
500"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.28376844494892167,"Loss
45.74
66.45
83.47
Uncertainty [3]
46.22
66.99
84.22
EL2N [33]
47.23
67.38
84.63"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.2849035187287174,"(a) Using EL2N to measure the diffi-
culty of samples has the best perfor-
mance."
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.28603859250851305,"IPC
Ratio
100%
75%
50%
25%"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.28717366628830876,"1
47.2
46.56
45.98
41.32
10
67.2
67.34
66.86
65.15
500
83.71
83.82
84.23
84.64"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.2883087400681044,"(b) As IPC increases, removing
more shallow-layer parameters
becomes more effective."
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.28944381384790013,"Strategy
IPC
10
50"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.2905788876276958,"Baseline
67.2
76.5
Loss
67.3
77.0
Depth
67.7
77.3"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.2917139614074915,"(c) Using layer depth to select
parameters outperforms using
matching loss."
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.29284903518728717,"Table 4: (a) Ablation of different difficulty scoring functions on CIFAR-10. (b) Results of masking
out different ratios of shallow-layer parameters across various IPCs on CIFAR-10. (c) Ablation on
the strategy used for parameter selection on CIFAR-10"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.2939841089670829,"(a) with 100% parameters
(b) with 75% parameters
(c) with 50% parameters"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.29511918274687854,"Figure 4: Synthetic images of CIFAR-10 IPC50 obtained by PAD with different ratios of parameter
selection. Smoother image features indicate that by removing some shallow-layer parameters during
matching, PAD successfully filters out coarse-grained low-level information."
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.29625425652667425,"In Table 3(c), we show the distillation results where different hyper-parameters are utilized. In
183"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.2973893303064699,"general, a larger initial ratio and faster speed of addition bring better performances. Although the
184"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.2985244040862656,"distillation benefited more from learning simpler information when IPC is small [10], our findings
185"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.2996594778660613,"indicate that excessively removing difficult samples (e.g., more than a quarter) early in the training
186"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.300794551645857,"phase can adversely affect the distilled data. This negative impact is likely due to the excessive
187"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.30192962542565266,"removal leading to distorted feature distributions within each category. On the other hand, reasonably
188"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.3030646992054484,"improving the speed of adding hard samples allows the agent model to achieve a more balanced
189"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.30419977298524403,"learning of information of varying difficulty across different stages.
190"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.30533484676503975,"Other Difficulty Scoring Functions
Identifying the difficulty of data points is the key to filtering
191"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.3064699205448354,"out misaligned information in the extraction step. Here, we compare the effect of using other
192"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.3076049943246311,"difficulty-scoring functions to evaluate the difficulty of data. (1) prediction loss of a pre-trained
193"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.3087400681044268,"ResNet. (2) uncertainty score [3]. (3) EL2N [33]. As can be observed in Table 4(a), EL2N performs
194"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.3098751418842225,"the best across various IPCs; thus, we use it to measure how hard each data point is as default in our
195"
HYPER-PARAMETERS OF FILTERING INFORMATION EXTRACTION,0.31101021566401815,"method. Note that this can also be replaced with a more advanced data selection algorithm.
196"
RATIOS OF PARAMETER SELECTION,0.31214528944381387,"4.3.3
Ratios of Parameter Selection
197"
RATIOS OF PARAMETER SELECTION,0.3132803632236095,"It is important to find a good balance between the percentage of shallow-layer parameters removed
198"
RATIOS OF PARAMETER SELECTION,0.31441543700340524,"from matching and the loss of information. In Table 4(b), we show results obtained on different
199"
RATIOS OF PARAMETER SELECTION,0.3155505107832009,"IPCs by discarding various ratios of shallow-layer parameters. The impact of removing varying
200"
RATIOS OF PARAMETER SELECTION,0.3166855845629966,"proportions of shallow parameters on the distilled data and its relationship with changes in IPC
201"
RATIOS OF PARAMETER SELECTION,0.3178206583427923,"is consistent with prior conclusions. For small IPCs, distilled data requires more low-level basic
202"
RATIOS OF PARAMETER SELECTION,0.318955732122588,"information. Thus, removing too many shallow-layer parameters causes a negative effect on the
203"
RATIOS OF PARAMETER SELECTION,0.32009080590238365,"classification performance. By contrast, high-level semantic information is more important when
204"
RATIOS OF PARAMETER SELECTION,0.32122587968217936,"it comes to large IPCs. With increasing ratios of shallow-layer parameters being discarded, we can
205"
RATIOS OF PARAMETER SELECTION,0.322360953461975,"ensure that low-level information is effectively filtered out from the distilled data.
206"
DISCUSSION,0.32349602724177073,"5
Discussion
207"
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.3246311010215664,"5.1
Distilled Images with Filtering Information Embedding
208"
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.3257661748013621,"To see the concrete patterns brought by removing shallow-layer parameters to perform the trajectory
209"
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.32690124858115777,"matching, we present distilled images obtained by discarding various ratios of shallow-layer parame-
210"
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.3280363223609535,"ters in Figure 4. As can be observed in Figure 4(a), without removing any shallow-layer parameters
211"
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.32917139614074914,"1
2
3
4
5
6
Layer 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0"
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.33030646992054485,"iter 0
iter 1000
iter 5000 Loss"
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.3314415437003405,(a) CIFAR-10 IPC1
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.3325766174801362,"1
2
3
4
5
6
Layer 0.00 0.25 0.50 0.75 1.00 1.25 1.50"
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.3337116912599319,"1.75
iter 0
iter 1000
iter 5000 Loss"
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.3348467650397276,(b) CIFAR-10 IPC10
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.33598183881952326,"1
2
3
4
5
6
Layer 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Loss"
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.337116912599319,"iter 0
iter 1000
iter 5000"
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.33825198637911463,(c) CIFAR-10 IPC500
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.33938706015891035,"Figure 5: Losses of different layers of ConvNet after matching trajectories for 0, 1000, and 5000
iterations. We notice a similar phenomenon on both small (IPC1 and IPC10) and large IPCs (IPC500):
losses of shallow-layer parameters fluctuate along the matching process, while losses of deep-layer
parameters show a clear trend of decreasing."
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.340522133938706,"(a) Match shallow layers only
(b) Original
(c) Match deep layers only"
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.3416572077185017,"Figure 6: Synthetic images visualization with parameter selection. Matching parameters in shallow
layers produces an abundance of low-level texture features, whereas patterns generated by matching
deep-layer parameters embody richer high-level semantic information."
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.3427922814982974,"to filter misaligned information, synthetic images are interspersed with substantial noises. These
212"
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.3439273552780931,"noises often take the form of coarse and generic information, such as the overall color distribution
213"
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.34506242905788875,"and edges in the image, which provides minimal utility for precise classification.
214"
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.34619750283768447,"By contrast, images distilled by our enhanced methodology (see Figure 4(b) and Figure 4(c)), which
215"
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.3473325766174801,"includes meticulous masking out shallow-layer parameters during trajectory matching according to the
216"
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.34846765039727584,"compressing ratio, contain more fine-grained and smoother features. These images also encapsulate
217"
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.3496027241770715,"a broader range of semantic information, which is crucial for helping the model make accurate
218"
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.3507377979568672,"classifications. Moreover, we observe a clear trend: as the amount of the removed shallow-layer
219"
DISTILLED IMAGES WITH FILTERING INFORMATION EMBEDDING,0.3518728717366629,"parameters increases, the distilled images exhibit clearer and smoother features.
220"
RATIONALE FOR PARAMETER SELECTION,0.3530079455164586,"5.2
Rationale for Parameter Selection
221"
RATIONALE FOR PARAMETER SELECTION,0.35414301929625425,"In this section, we analyze from the perspective of trajectory matching why shallow-layer parameters
222"
RATIONALE FOR PARAMETER SELECTION,0.35527809307604996,"should be masked out. In Figure 5, we present the changes in trajectory matching loss across different
223"
RATIONALE FOR PARAMETER SELECTION,0.3564131668558456,"layers as the distillation progresses. Compared to the deep-layer parameters of the agent model,
224"
RATIONALE FOR PARAMETER SELECTION,0.35754824063564133,"a substantial number of shallow-layer parameters exhibit low loss values that fluctuate during the
225"
RATIONALE FOR PARAMETER SELECTION,0.358683314415437,"matching process (see Figure 5). By contrast, the loss values of the deep layers are much higher but
226"
RATIONALE FOR PARAMETER SELECTION,0.3598183881952327,"consistently decrease as distillation continues. This suggests that matching shallow layers primarily
227"
RATIONALE FOR PARAMETER SELECTION,0.36095346197502837,"conveys low-level information that is readily captured by the synthetic data and quickly saturated.
228"
RATIONALE FOR PARAMETER SELECTION,0.3620885357548241,"Consequently, the excessive addition of such low-level information produces noise, reducing the
229"
RATIONALE FOR PARAMETER SELECTION,0.36322360953461974,"quality of distilled datasets.
230"
RATIONALE FOR PARAMETER SELECTION,0.36435868331441545,"For a concrete visualization, we provide distilled images resulting from using only shallow-layer
231"
RATIONALE FOR PARAMETER SELECTION,0.3654937570942111,"parameters or only deep-layer parameters to match trajectories in Figure 6. The coarse image features
232"
RATIONALE FOR PARAMETER SELECTION,0.36662883087400683,"depicted in Figure 6(a) further substantiate our analysis.
233"
PARAMETER SELECTION STRATEGY,0.3677639046538025,"5.3
Parameter Selection Strategy
234"
PARAMETER SELECTION STRATEGY,0.3688989784335982,"In the previous section, we observed a positive correlation between the depth of the model layers
235"
PARAMETER SELECTION STRATEGY,0.37003405221339386,"and the magnitude of their trajectory-matching losses. Notably, the loss in the first layer of the
236"
PARAMETER SELECTION STRATEGY,0.3711691259931896,"ConvNet was higher compared to other shallow layers. Consequently, we further compared different
237"
PARAMETER SELECTION STRATEGY,0.37230419977298523,"parameter alignment strategies, specifically by sorting the parameters based on their matching losses
238"
PARAMETER SELECTION STRATEGY,0.37343927355278095,"and excluding a certain proportion of parameters with lower losses. Higher loss values indicate
239"
PARAMETER SELECTION STRATEGY,0.3745743473325766,"greater discrepancies in parameter weights; thus, continuing to match these parameters can inject
240"
PARAMETER SELECTION STRATEGY,0.3757094211123723,"more information into the synthetic data. As shown in Table 4(c), sorting by loss results in an
241"
PARAMETER SELECTION STRATEGY,0.376844494892168,"improvement compared with no parameter alignment, but filtering based on parameter depth proves
242"
PARAMETER SELECTION STRATEGY,0.3779795686719637,"to be more effective.
243"
RELATED WORK,0.37911464245175935,"6
Related Work
244"
RELATED WORK,0.38024971623155507,"Introduced by [43], dataset distillation aims to synthesize a compact set of data that allows models to
245"
RELATED WORK,0.3813847900113507,"achieve similar test performances compared with the original dataset. Since then, a number of studies
246"
RELATED WORK,0.38251986379114644,"have explored various approaches. These methods can be divided into three types: kernel-based,
247"
RELATED WORK,0.3836549375709421,"matching-based, and using generative models [45].
248"
RELATED WORK,0.3847900113507378,"Kernel-based methods are able to achieve closed-form solutions for the inner optimization [31] via
249"
RELATED WORK,0.3859250851305335,"kernel ridge regression with NTK [22]. FRePo [50] distills a compact dataset through neural feature
250"
RELATED WORK,0.3870601589103292,"regression and reduces the training cost.
251"
RELATED WORK,0.38819523269012485,"Matching-based methods first use agent models to extract information from the target dataset
252"
RELATED WORK,0.38933030646992056,"by recording a specific metric [7, 23, 38, 24]. Representative works that design different metrics
253"
RELATED WORK,0.3904653802497162,"include DC [49] that matches gradients, DM [48] that matches distributions, and MTT [1] that
254"
RELATED WORK,0.39160045402951194,"matches training trajectories. Then, the distilled dataset is optimized by minimizing the matched
255"
RELATED WORK,0.3927355278093076,"distance between the metric computed on synthetic data and the record one from the previous step.
256"
RELATED WORK,0.3938706015891033,"Following this workflow, many works have been proposed to improve the efficacy of the distilled
257"
RELATED WORK,0.39500567536889897,"dataset. For example, CAFE [42] preserves the real feature distribution and the discriminative power
258"
RELATED WORK,0.3961407491486947,"of the synthetic data and achieves prominent generalization ability across various architectures.
259"
RELATED WORK,0.39727582292849034,"DREAM [25] employs K-Means to select representative samples for distillation and improves the
260"
RELATED WORK,0.39841089670828606,"distillation efficiency. DATM [10] proposes to match early trajectories for small IPCs and late
261"
RELATED WORK,0.3995459704880817,"trajectories for large IPCs, achieving SOTA performances on several benchmarks. Moreover, new
262"
RELATED WORK,0.40068104426787743,"metrics such as spatial attention maps [36, 15] have also been introduced and achieved promising
263"
RELATED WORK,0.4018161180476731,"performance in distilling large-scale datasets.
264"
RELATED WORK,0.4029511918274688,"Generative models such as GANs [8, 13, 14, 41] and diffusion models [34, 30, 9] can also be used to
265"
RELATED WORK,0.40408626560726446,"distill high quality datasets. DiM [41] uses deep generative models to store information of the target
266"
RELATED WORK,0.4052213393870602,"dataset. GLaD [2] transfers synthetic data optimization from the pixel space to the latent space by
267"
RELATED WORK,0.40635641316685583,"employing deep generative priors. It enhances the generalizability of previous distillation methods.
268"
CONCLUSION,0.40749148694665155,"7
Conclusion
269"
CONCLUSION,0.4086265607264472,"In this work, we find a limitation of existing Dataset Distillation methods in that they will introduce
270"
CONCLUSION,0.4097616345062429,"misaligned information to the distilled datasets. To alleviate this, we propose PAD, which incorporates
271"
CONCLUSION,0.4108967082860386,"two modules to filter out misaligned information. For information extraction, PAD prunes the target
272"
CONCLUSION,0.4120317820658343,"dataset based on sample difficulty for different IPCs so that only information with aligned difficulty
273"
CONCLUSION,0.41316685584562995,"is extracted by the agent model. For information embedding, PAD discards part of shallow-layer
274"
CONCLUSION,0.41430192962542567,"parameters to avoid injecting low-level basic information into the synthetic data. PAD achieves
275"
CONCLUSION,0.41543700340522133,"SOTA performance on various benchmarks. Moreover, we show PAD can also be applied to methods
276"
CONCLUSION,0.41657207718501704,"based on matching gradients and distribution, bringing remarkable improvements across various IPC
277"
CONCLUSION,0.4177071509648127,"settings.
278"
CONCLUSION,0.4188422247446084,"Limitations
Our alignment strategy could also be applied to methods based on matching gradients
279"
CONCLUSION,0.4199772985244041,"and distributions (see Appendix A.1). However, due to the limitation of computing resources,
280"
CONCLUSION,0.4211123723041998,"for methods based on matching distributions and gradients, we have only validated our method’s
281"
CONCLUSION,0.42224744608399545,"effectiveness on DM [48] and DC [49] (see Table 5 and Table 6).
282"
REFERENCES,0.42338251986379116,"References
283"
REFERENCES,0.4245175936435868,"[1] George Cazenavette, Tongzhou Wang, Antonio Torralba, Alexei A. Efros, and Jun-Yan Zhu.
284"
REFERENCES,0.42565266742338254,"Dataset distillation by matching training trajectories. 2022 IEEE/CVF Conference on Computer
285"
REFERENCES,0.4267877412031782,"Vision and Pattern Recognition (CVPR), pages 10708–10717, 2022.
286"
REFERENCES,0.4279228149829739,"[2] George Cazenavette, Tongzhou Wang, Antonio Torralba, Alexei A. Efros, and Jun-Yan Zhu.
287"
REFERENCES,0.42905788876276957,"Generalizing dataset distillation via deep generative prior. 2023 IEEE/CVF Conference on
288"
REFERENCES,0.4301929625425653,"Computer Vision and Pattern Recognition (CVPR), pages 3739–3748, 2023.
289"
REFERENCES,0.43132803632236094,"[3] Cody Coleman, Christopher Yeh, Stephen Mussmann, Baharan Mirzasoleiman, Peter Bailis,
290"
REFERENCES,0.43246311010215666,"Percy Liang, Jure Leskovec, and Matei Zaharia. Selection via proxy: Efficient data selection for
291"
REFERENCES,0.4335981838819523,"deep learning. arXiv preprint arXiv:1906.11829, 2019.
292"
REFERENCES,0.43473325766174803,"[4] Justin Cui, Ruochen Wang, Si Si, and Cho-Jui Hsieh. Scaling up dataset distillation to imagenet-
293"
REFERENCES,0.4358683314415437,"1k with constant memory. In International Conference on Machine Learning, 2022.
294"
REFERENCES,0.4370034052213394,"[5] Tian Dong, Bo Zhao, and Lingjuan Lyu. Privacy for free: How does dataset condensation help
295"
REFERENCES,0.43813847900113506,"privacy? ArXiv, abs/2206.00240, 2022.
296"
REFERENCES,0.4392735527809308,"[6] Jiawei Du, Yiding Jiang, Vincent Y. F. Tan, Joey Tianyi Zhou, and Haizhou Li. Minimizing the
297"
REFERENCES,0.44040862656072643,"accumulated trajectory error to improve dataset distillation. 2023 IEEE/CVF Conference on
298"
REFERENCES,0.44154370034052215,"Computer Vision and Pattern Recognition (CVPR), pages 3749–3758, 2022.
299"
REFERENCES,0.4426787741203178,"[7] Jiawei Du, Qin Shi, and Joey Tianyi Zhou. Sequential subset matching for dataset distillation.
300"
REFERENCES,0.4438138479001135,"ArXiv, abs/2311.01570, 2023.
301"
REFERENCES,0.4449489216799092,"[8] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil
302"
REFERENCES,0.4460839954597049,"Ozair, Aaron C. Courville, and Yoshua Bengio. Generative adversarial networks. Communica-
303"
REFERENCES,0.44721906923950056,"tions of the ACM, 63:139 – 144, 2014.
304"
REFERENCES,0.44835414301929627,"[9] Jianyang Gu, Saeed Vahidian, Vyacheslav Kungurtsev, Haonan Wang, Wei Jiang, Yang You,
305"
REFERENCES,0.44948921679909193,"and Yiran Chen. Efficient dataset distillation via minimax diffusion. ArXiv, abs/2311.15529,
306"
REFERENCES,0.45062429057888764,"2023.
307"
REFERENCES,0.4517593643586833,"[10] Ziyao Guo, Kai Wang, George Cazenavette, Hui Li, Kaipeng Zhang, and Yang You. Towards
308"
REFERENCES,0.452894438138479,"lossless dataset distillation via difficulty-aligned trajectory matching. ArXiv, abs/2310.05773,
309"
REFERENCES,0.4540295119182747,"2023.
310"
REFERENCES,0.4551645856980704,"[11] Kaiming He, X. Zhang, Shaoqing Ren, and Jian Sun.
Deep residual learning for image
311"
REFERENCES,0.45629965947786605,"recognition. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
312"
REFERENCES,0.45743473325766176,"pages 770–778, 2015.
313"
REFERENCES,0.4585698070374574,"[12] Haifeng Jin, Qingquan Song, and Xia Hu. Auto-keras: An efficient neural architecture search
314"
REFERENCES,0.45970488081725314,"system. Proceedings of the 25th ACM SIGKDD International Conference on Knowledge
315"
REFERENCES,0.4608399545970488,"Discovery & Data Mining, 2018.
316"
REFERENCES,0.4619750283768445,"[13] Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative
317"
REFERENCES,0.46311010215664017,"adversarial networks. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition
318"
REFERENCES,0.4642451759364359,"(CVPR), pages 4396–4405, 2018.
319"
REFERENCES,0.46538024971623154,"[14] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila.
320"
REFERENCES,0.46651532349602726,"Analyzing and improving the image quality of stylegan. 2020 IEEE/CVF Conference on
321"
REFERENCES,0.4676503972758229,"Computer Vision and Pattern Recognition (CVPR), pages 8107–8116, 2019.
322"
REFERENCES,0.46878547105561863,"[15] Samir Khaki, Ahmad Sajedi, Kai Wang, Lucy Z. Liu, Yuri A. Lawryshyn, and Konstantinos N.
323"
REFERENCES,0.4699205448354143,"Plataniotis. Atom: Attention mixer for efficient dataset distillation, 2024.
324"
REFERENCES,0.47105561861521,"[16] Krishnateja Killamsetty, Durga Sivasubramanian, Ganesh Ramakrishnan, Abir De, and
325"
REFERENCES,0.47219069239500566,"Rishabh K. Iyer. Grad-match: Gradient matching based data subset selection for efficient
326"
REFERENCES,0.4733257661748014,"deep model training. In International Conference on Machine Learning, 2021.
327"
REFERENCES,0.47446083995459704,"[17] Krishnateja Killamsetty, Durga Sivasubramanian, Ganesh Ramakrishnan, Rishabh Iyer Univer-
328"
REFERENCES,0.47559591373439275,"sity of Texas at Dallas, Indian Institute of Technology Bombay Institution One, and IN Two.
329"
REFERENCES,0.4767309875141884,"Glister: Generalization based data subset selection for efficient and robust learning. In AAAI
330"
REFERENCES,0.4778660612939841,"Conference on Artificial Intelligence, 2020.
331"
REFERENCES,0.4790011350737798,"[18] Alex Krizhevsky. Learning multiple layers of features from tiny images. 2009.
332"
REFERENCES,0.4801362088535755,"[19] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep
333"
REFERENCES,0.48127128263337116,"convolutional neural networks. Communications of the ACM, 60:84 – 90, 2012.
334"
REFERENCES,0.48240635641316687,"[20] Ya Le and Xuan S. Yang. Tiny imagenet visual recognition challenge. 2015.
335"
REFERENCES,0.48354143019296253,"[21] Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning
336"
REFERENCES,0.48467650397275824,"applied to document recognition. Proc. IEEE, 86:2278–2324, 1998.
337"
REFERENCES,0.4858115777525539,"[22] Jaehoon Lee, Lechao Xiao, Samuel S. Schoenholz, Yasaman Bahri, Roman Novak,
338"
REFERENCES,0.4869466515323496,"Jascha Narain Sohl-Dickstein, and Jeffrey Pennington. Wide neural networks of any depth
339"
REFERENCES,0.4880817253121453,"evolve as linear models under gradient descent. Journal of Statistical Mechanics: Theory and
340"
REFERENCES,0.489216799091941,"Experiment, 2020, 2019.
341"
REFERENCES,0.49035187287173665,"[23] Saehyung Lee, Sanghyuk Chun, Sangwon Jung, Sangdoo Yun, and Sung-Hoon Yoon. Dataset
342"
REFERENCES,0.49148694665153236,"condensation with contrastive signals. In International Conference on Machine Learning, 2022.
343"
REFERENCES,0.492622020431328,"[24] Haoyang Liu, Tiancheng Xing, Luwei Li, Vibhu Dalal, Jingrui He, and Haohan Wang. Dataset
344"
REFERENCES,0.49375709421112374,"distillation via the wasserstein metric. ArXiv, abs/2311.18531, 2023.
345"
REFERENCES,0.4948921679909194,"[25] Yanqing Liu, Jianyang Gu, Kai Wang, Zheng Hua Zhu, Wei Jiang, and Yang You. Dream: Effi-
346"
REFERENCES,0.4960272417707151,"cient dataset distillation by representative matching. 2023 IEEE/CVF International Conference
347"
REFERENCES,0.49716231555051077,"on Computer Vision (ICCV), pages 17268–17278, 2023.
348"
REFERENCES,0.4982973893303065,"[26] Noel Loo, Ramin M. Hasani, Mathias Lechner, and Daniela Rus. Dataset distillation with
349"
REFERENCES,0.49943246311010214,"convexified implicit gradients. ArXiv, abs/2302.06755, 2023.
350"
REFERENCES,0.5005675368898979,"[27] Aravindh Mahendran and Andrea Vedaldi. Visualizing deep convolutional neural networks
351"
REFERENCES,0.5017026106696936,"using natural pre-images. International Journal of Computer Vision, 120:233 – 255, 2016.
352"
REFERENCES,0.5028376844494892,"[28] Wojciech Masarczyk and Ivona Tautkute. Reducing catastrophic forgetting with learning on
353"
REFERENCES,0.5039727582292849,"synthetic data. In CVPR Workshop, 2020.
354"
REFERENCES,0.5051078320090806,"[29] Baharan Mirzasoleiman, Jeff A. Bilmes, and Jure Leskovec. Coresets for data-efficient training
355"
REFERENCES,0.5062429057888763,"of machine learning models. In International Conference on Machine Learning, 2019.
356"
REFERENCES,0.5073779795686719,"[30] Brian B. Moser, Federico Raue, Sebastián M. Palacio, Stanislav Frolov, and Andreas Dengel.
357"
REFERENCES,0.5085130533484676,"Latent dataset distillation with diffusion models. ArXiv, abs/2403.03881, 2024.
358"
REFERENCES,0.5096481271282634,"[31] Timothy Nguyen, Zhourung Chen, and Jaehoon Lee. Dataset meta-learning from kernel
359"
REFERENCES,0.5107832009080591,"ridge-regression. ArXiv, abs/2011.00050, 2020.
360"
REFERENCES,0.5119182746878547,"[32] Ramakanth Pasunuru and Mohit Bansal. Continual and multi-task architecture search. ArXiv,
361"
REFERENCES,0.5130533484676504,"abs/1906.05226, 2019.
362"
REFERENCES,0.5141884222474461,"[33] Mansheej Paul, Surya Ganguli, and Gintare Karolina Dziugaite. Deep learning on a data diet:
363"
REFERENCES,0.5153234960272418,"Finding important examples early in training. In Neural Information Processing Systems, 2021.
364"
REFERENCES,0.5164585698070374,"[34] Robin Rombach, A. Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. High-
365"
REFERENCES,0.5175936435868331,"resolution image synthesis with latent diffusion models. 2022 IEEE/CVF Conference on
366"
REFERENCES,0.5187287173666288,"Computer Vision and Pattern Recognition (CVPR), pages 10674–10685, 2021.
367"
REFERENCES,0.5198637911464246,"[35] Andrea Rosasco, Antonio Carta, Andrea Cossu, Vincenzo Lomonaco, and Davide Bacciu.
368"
REFERENCES,0.5209988649262202,"Distilled replay: Overcoming forgetting through synthetic samples. In International Workshop
369"
REFERENCES,0.5221339387060159,"on Continual Semi-Supervised Learning, 2021.
370"
REFERENCES,0.5232690124858116,"[36] Ahmad Sajedi, Samir Khaki, Ehsan Amjadian, Lucy Z. Liu, Yuri A. Lawryshyn, and Kon-
371"
REFERENCES,0.5244040862656073,"stantinos N. Plataniotis. Datadam: Efficient dataset distillation with attention matching. In
372"
REFERENCES,0.5255391600454029,"Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages
373"
REFERENCES,0.5266742338251986,"17097–17107, October 2023.
374"
REFERENCES,0.5278093076049943,"[37] Ramprasaath R. Selvaraju, Abhishek Das, Ramakrishna Vedantam, Michael Cogswell, Devi
375"
REFERENCES,0.52894438138479,"Parikh, and Dhruv Batra. Grad-cam: Visual explanations from deep networks via gradient-based
376"
REFERENCES,0.5300794551645857,"localization. International Journal of Computer Vision, 128:336 – 359, 2016.
377"
REFERENCES,0.5312145289443814,"[38] Seung-Jae Shin, Heesun Bae, DongHyeok Shin, Weonyoung Joo, and Il-Chul Moon. Loss-
378"
REFERENCES,0.5323496027241771,"curvature matching for dataset selection and condensation. In International Conference on
379"
REFERENCES,0.5334846765039728,"Artificial Intelligence and Statistics, 2023.
380"
REFERENCES,0.5346197502837684,"[39] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale
381"
REFERENCES,0.5357548240635641,"image recognition. CoRR, abs/1409.1556, 2014.
382"
REFERENCES,0.5368898978433598,"[40] Ben Sorscher, Robert Geirhos, Shashank Shekhar, Surya Ganguli, and Ari Morcos. Beyond
383"
REFERENCES,0.5380249716231555,"neural scaling laws: beating power law scaling via data pruning. Advances in Neural Information
384"
REFERENCES,0.5391600454029511,"Processing Systems, 35:19523–19536, 2022.
385"
REFERENCES,0.5402951191827469,"[41] Kai Wang, Jianyang Gu, Daquan Zhou, Zheng Hua Zhu, Wei Jiang, and Yang You. Dim:
386"
REFERENCES,0.5414301929625426,"Distilling dataset into generative model. ArXiv, abs/2303.04707, 2023.
387"
REFERENCES,0.5425652667423383,"[42] Kai Wang, Bo Zhao, Xiangyu Peng, Zheng Hua Zhu, Shuo Yang, Shuo Wang, Guan Huang,
388"
REFERENCES,0.5437003405221339,"Hakan Bilen, Xinchao Wang, and Yang You. Cafe learning to condense dataset by aligning
389"
REFERENCES,0.5448354143019296,"features. 2022.
390"
REFERENCES,0.5459704880817253,"[43] Tongzhou Wang, Jun-Yan Zhu, Antonio Torralba, and Alexei A. Efros. Dataset distillation,
391"
REFERENCES,0.547105561861521,"2020.
392"
REFERENCES,0.5482406356413166,"[44] Qiying Yu, Yang Liu, Yimu Wang, Ke Xu, and Jingjing Liu. Multimodal federated learning via
393"
REFERENCES,0.5493757094211124,"contrastive representation ensemble. ArXiv, abs/2302.08888, 2023.
394"
REFERENCES,0.5505107832009081,"[45] Ruonan Yu, Songhua Liu, and Xinchao Wang. Dataset distillation: A comprehensive review.
395"
REFERENCES,0.5516458569807038,"IEEE Transactions on Pattern Analysis and Machine Intelligence, 46:150–170, 2023.
396"
REFERENCES,0.5527809307604994,"[46] Bo Zhao and Hakan Bilen. Dataset condensation with differentiable siamese augmentation. In
397"
REFERENCES,0.5539160045402951,"International Conference on Machine Learning, 2021.
398"
REFERENCES,0.5550510783200908,"[47] Bo Zhao and Hakan Bilen. Dataset condensation with differentiable siamese augmentation. In
399"
REFERENCES,0.5561861520998865,"International Conference on Machine Learning, 2021.
400"
REFERENCES,0.5573212258796821,"[48] Bo Zhao and Hakan Bilen. Dataset condensation with distribution matching. 2023 IEEE/CVF
401"
REFERENCES,0.5584562996594779,"Winter Conference on Applications of Computer Vision (WACV), pages 6503–6512, 2021.
402"
REFERENCES,0.5595913734392736,"[49] Bo Zhao, Konda Reddy Mopuri, and Hakan Bilen. Dataset condensation with gradient matching.
403"
REFERENCES,0.5607264472190693,"ArXiv, abs/2006.05929, 2020.
404"
REFERENCES,0.5618615209988649,"[50] Yongchao Zhou, Ehsan Nezhadarya, and Jimmy Ba. Dataset distillation using neural feature
405"
REFERENCES,0.5629965947786606,"regression. ArXiv, abs/2206.00719, 2022.
406"
REFERENCES,0.5641316685584563,"IPC
Ratio
Baseline
10%
15%
20%
25%"
REFERENCES,0.565266742338252,"1
17.03
16.34
18.27
18.91
16.32
500
65.21
65.34
66.47
66.31
65.27"
REFERENCES,0.5664018161180476,"(a) Removing various ratios of hard/easy sam-
ples improves DC on small/large IPCs."
REFERENCES,0.5675368898978433,"IPC
Ratio
Baseline
10%
15%
20%
25%"
REFERENCES,0.5686719636776391,"1
26.66
27.24
27.97
27.48
25.41
500
70.74
70.89
70.37
69.80
70.32"
REFERENCES,0.5698070374574348,"(b) Removing various ratios of hard/easy sam-
ples improves DM on small/large IPCs."
REFERENCES,0.5709421112372304,"Table 5: Results of filtering information extraction by removing hard/easy samples in DC(a) and
DM(b) on CIFAR-10."
REFERENCES,0.5720771850170261,"IPC
Ratio
Baseline
25%
50%
75%"
REFERENCES,0.5732122587968218,"10
29.23
28.67
27.36
28.88
500
65.88
65.97
66.24
65.39"
REFERENCES,0.5743473325766175,"(a) Matching gradients from deep-layer parameters
leads to improvements."
REFERENCES,0.5754824063564131,"IPC
Ratio
Baseline
25%
50%
75%"
REFERENCES,0.5766174801362088,"10
29.23
28.67
27.36
28.88
500
67.48
67.76
68.14
67.39"
REFERENCES,0.5777525539160046,"(b) Matching distributions from deep-layer param-
eters leads to improvements."
REFERENCES,0.5788876276958003,"Table 6: Results of filtering information embedding by masking out shallow-layer parameters for
metric computation in DC(a) and DM(b) on CIFAR-10."
REFERENCES,0.5800227014755959,"A
Appendix
407"
REFERENCES,0.5811577752553916,"A.1
Filtering Misaligned Information in DC and DM
408"
REFERENCES,0.5822928490351873,"Although PAD is implemented based on trajectory matching methods, we also test our proposed
409"
REFERENCES,0.583427922814983,"data alignment and parameter alignment on gradient matching and distribution matching. The
410"
REFERENCES,0.5845629965947786,"performances of enhanced DC and DM with each of the two modules are reported in Table 5 and
411"
REFERENCES,0.5856980703745743,"Tabl 6, respectively. We provide details of how we integrate these two modules into gradient matching
412"
REFERENCES,0.58683314415437,"and distribution matching in the following sections.
413"
REFERENCES,0.5879682179341658,"Gradient Matching We use the official implementation1 of DC [49]. In the Information Extraction
414"
REFERENCES,0.5891032917139614,"step, DC uses an agent model to calculate the gradients after being trained on the target dataset. We
415"
REFERENCES,0.5902383654937571,"employ filter misaligned information in this step as follows: When IPC is small, a certain ratio of
416"
REFERENCES,0.5913734392735528,"hard samples is removed from the target dataset so that the recorded gradients only contain simple
417"
REFERENCES,0.5925085130533485,"information. Conversely, when IPC becomes large, we remove easy samples instead.
418"
REFERENCES,0.5936435868331441,"In the Information Embedding step, DC optimizes the synthetic data by back-propagating on the
419"
REFERENCES,0.5947786606129398,"gradient matching loss. The loss is computed by summing the differences in gradients between
420"
REFERENCES,0.5959137343927355,"each pair of model parameters. Thus, we apply parameter selection by discarding a certain ratio of
421"
REFERENCES,0.5970488081725313,"parameters in the shallow layers.
422"
REFERENCES,0.5981838819523269,"Distribution Matching We use the official implementation of DM [48], which can be accessed
423"
REFERENCES,0.5993189557321226,"via the same link as DC. In the Information Extraction step, DM uses an agent model to generate
424"
REFERENCES,0.6004540295119183,"embeddings of input images from the target dataset. Similarly, filtering information extraction is
425"
REFERENCES,0.601589103291714,"applied by removing hard samples for small IPCs and easy samples for large IPCs.
426"
REFERENCES,0.6027241770715096,"In the Information Embedding step, since DM only uses the output of the last layer to match
427"
REFERENCES,0.6038592508513053,"distributions, we modify the implementation of the network such that outputs of each layer in the
428"
REFERENCES,0.604994324631101,"model are returned by the forward function. Then, we perform parameter selection following the
429"
REFERENCES,0.6061293984108967,"same practice as before.
430"
REFERENCES,0.6072644721906924,"A.2
Experiment Settings
431"
REFERENCES,0.6083995459704881,"We use DATM [10] as the backbone TM algorithm and our proposed PAD is built upon. Thus, our
432"
REFERENCES,0.6095346197502838,"configurations for distillation, evaluation, and network are consistent with DATM.
433"
REFERENCES,0.6106696935300795,1https://github.com/VICO-UoE/DatasetCondensation.git
REFERENCES,0.6118047673098751,"Distillation. We conduct the distillation process for 10,000 iterations to ensure full convergence of
434"
REFERENCES,0.6129398410896708,"the optimization. By default, ZCA whitening is applied in all the experiments.
435"
REFERENCES,0.6140749148694665,"Evaluation. We train a randomly initialized network on the distilled dataset and evaluate its per-
436"
REFERENCES,0.6152099886492622,"formance on the entire validation set of the original dataset. Following DATM [10], the evaluation
437"
REFERENCES,0.6163450624290578,"networks are trained for 1000 epochs to ensure full optimization convergence. For fairness, the
438"
REFERENCES,0.6174801362088536,"experimental results of previous distillation methods in both low and high IPC settings are sourced
439"
REFERENCES,0.6186152099886493,"from [10].
440"
REFERENCES,0.619750283768445,"Network. We employ a range of networks to assess the generalizability of our distilled datasets.
441"
REFERENCES,0.6208853575482406,"For scaling ResNet, LeNet, and AlexNet to Tiny-ImageNet, we modify the stride of their initial
442"
REFERENCES,0.6220204313280363,"convolutional layer from 1 to 2. In the case of VGG, we adjust the stride of its final max pooling
443"
REFERENCES,0.623155505107832,"layer from 1 to 2. The MLP used in our evaluations features a single hidden layer with 128 units.
444"
REFERENCES,0.6242905788876277,"Hyper-parameters. Hyper-parameters of our experiments on CIFAR-10, CIFAR-100, and Tiny-
445"
REFERENCES,0.6254256526674233,"ImageNet are reported in Table 7. Hyper-parameters can be divided into three parts including data
446"
REFERENCES,0.626560726447219,"alignment (DA), parameter alignment (PA) and trajectory matching (TM). Soft labels are applied in
447"
REFERENCES,0.6276958002270148,"all experiments , we set its momentum to 0.9.
448"
REFERENCES,0.6288308740068105,"Compute resources. Our experiments are run on 4 NVIDIA A100 GPUs, each with 80 GB of
449"
REFERENCES,0.6299659477866061,"memory. The amount of GPU memory needed is mainly determined by the batch size of synthetic
450"
REFERENCES,0.6311010215664018,"data and the number of steps that the agment model is trained on synthetic data. To reduce the GPU
451"
REFERENCES,0.6322360953461975,"usage when IPC is large, one can apply TESLA [4] or simply reducing the synthetic steps N or the
452"
REFERENCES,0.6333711691259932,"synthetic batch size. However, the decrement of hyper-parameters shown in Table 7 could result in
453"
REFERENCES,0.6345062429057888,"performance degradation.
454"
REFERENCES,0.6356413166855845,"Dataset
IPC
DA
PA
TM"
REFERENCES,0.6367763904653803,"IR
AEE
α
N
M
T −
T
T +
Interval
Synthetic
Batch Size
Learning Rate
(Label)
Learning Rate
(Pixels)"
REFERENCES,0.637911464245176,CIFAR-10 1
REFERENCES,0.6390465380249716,"0.75
20"
REFERENCES,0.6401816118047673,"0%
80
2
0
4
4
-
10
5
100
10
25%
80
2
0
10
20
100
100
2
100
50
25%
80
2
0
20
40
100
500
2
1000
500
50%
80
2
40
60
60
-
1000
10
50
1000
75%
80
2
40
60
60
-
1000
10
50"
REFERENCES,0.641316685584563,CIFAR-100 1
REFERENCES,0.6424517593643587,"0.75
40"
REFERENCES,0.6435868331441543,"0%
40
3
0
10
20
100
100
10
1000
10
25%
80
2
0
20
40
100
1000
10
1000
50
50%
80
2
40
60
80
100
1000
10
1000
100
50%
80
2
40
80
80
-
1000
10
50 TI
1"
REFERENCES,0.64472190692395,"0.75
40"
REFERENCES,0.6458569807037458,"0%
60
2
0
15
30
400
200
10
10000
10
25%
60
2
0
20
40
100
250
10
100
50
50%
80
2
20
40
60
100
250
10
100"
REFERENCES,0.6469920544835415,Table 7: Hyper-parameters for different benchmarks.
REFERENCES,0.6481271282633371,Figure 7: Distilled images of CIFAR-10 IPC10
REFERENCES,0.6492622020431328,Figure 8: Distilled images of CIFAR-10 IPC10
REFERENCES,0.6503972758229285,Figure 9: Distilled images of CIFAR-10 IPC10
REFERENCES,0.6515323496027242,"NeurIPS Paper Checklist
455"
CLAIMS,0.6526674233825198,"1. Claims
456"
CLAIMS,0.6538024971623155,"Question: Do the main claims made in the abstract and introduction accurately reflect the
457"
CLAIMS,0.6549375709421112,"paper’s contributions and scope?
458"
CLAIMS,0.656072644721907,"Answer: [Yes]
459"
CLAIMS,0.6572077185017026,"Justification: Our main claim does accurately reflect the paper’s contributions and scope.
460"
CLAIMS,0.6583427922814983,"Guidelines:
461"
CLAIMS,0.659477866061294,"• The answer NA means that the abstract and introduction do not include the claims
462"
CLAIMS,0.6606129398410897,"made in the paper.
463"
CLAIMS,0.6617480136208853,"• The abstract and/or introduction should clearly state the claims made, including the
464"
CLAIMS,0.662883087400681,"contributions made in the paper and important assumptions and limitations. A No or
465"
CLAIMS,0.6640181611804767,"NA answer to this question will not be perceived well by the reviewers.
466"
CLAIMS,0.6651532349602725,"• The claims made should match theoretical and experimental results, and reflect how
467"
CLAIMS,0.6662883087400681,"much the results can be expected to generalize to other settings.
468"
CLAIMS,0.6674233825198638,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
469"
CLAIMS,0.6685584562996595,"are not attained by the paper.
470"
LIMITATIONS,0.6696935300794552,"2. Limitations
471"
LIMITATIONS,0.6708286038592508,"Question: Does the paper discuss the limitations of the work performed by the authors?
472"
LIMITATIONS,0.6719636776390465,"Answer: [Yes]
473"
LIMITATIONS,0.6730987514188422,"Justification: We discuss limitations at the end of the paper.
474"
LIMITATIONS,0.674233825198638,"Guidelines:
475"
LIMITATIONS,0.6753688989784336,"• The answer NA means that the paper has no limitation while the answer No means that
476"
LIMITATIONS,0.6765039727582293,"the paper has limitations, but those are not discussed in the paper.
477"
LIMITATIONS,0.677639046538025,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
478"
LIMITATIONS,0.6787741203178207,"• The paper should point out any strong assumptions and how robust the results are to
479"
LIMITATIONS,0.6799091940976163,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
480"
LIMITATIONS,0.681044267877412,"model well-specification, asymptotic approximations only holding locally). The authors
481"
LIMITATIONS,0.6821793416572077,"should reflect on how these assumptions might be violated in practice and what the
482"
LIMITATIONS,0.6833144154370034,"implications would be.
483"
LIMITATIONS,0.684449489216799,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
484"
LIMITATIONS,0.6855845629965948,"only tested on a few datasets or with a few runs. In general, empirical results often
485"
LIMITATIONS,0.6867196367763905,"depend on implicit assumptions, which should be articulated.
486"
LIMITATIONS,0.6878547105561862,"• The authors should reflect on the factors that influence the performance of the approach.
487"
LIMITATIONS,0.6889897843359818,"For example, a facial recognition algorithm may perform poorly when image resolution
488"
LIMITATIONS,0.6901248581157775,"is low or images are taken in low lighting. Or a speech-to-text system might not be
489"
LIMITATIONS,0.6912599318955732,"used reliably to provide closed captions for online lectures because it fails to handle
490"
LIMITATIONS,0.6923950056753689,"technical jargon.
491"
LIMITATIONS,0.6935300794551645,"• The authors should discuss the computational efficiency of the proposed algorithms
492"
LIMITATIONS,0.6946651532349603,"and how they scale with dataset size.
493"
LIMITATIONS,0.695800227014756,"• If applicable, the authors should discuss possible limitations of their approach to
494"
LIMITATIONS,0.6969353007945517,"address problems of privacy and fairness.
495"
LIMITATIONS,0.6980703745743473,"• While the authors might fear that complete honesty about limitations might be used by
496"
LIMITATIONS,0.699205448354143,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
497"
LIMITATIONS,0.7003405221339387,"limitations that aren’t acknowledged in the paper. The authors should use their best
498"
LIMITATIONS,0.7014755959137344,"judgment and recognize that individual actions in favor of transparency play an impor-
499"
LIMITATIONS,0.70261066969353,"tant role in developing norms that preserve the integrity of the community. Reviewers
500"
LIMITATIONS,0.7037457434733257,"will be specifically instructed to not penalize honesty concerning limitations.
501"
THEORY ASSUMPTIONS AND PROOFS,0.7048808172531215,"3. Theory Assumptions and Proofs
502"
THEORY ASSUMPTIONS AND PROOFS,0.7060158910329172,"Question: For each theoretical result, does the paper provide the full set of assumptions and
503"
THEORY ASSUMPTIONS AND PROOFS,0.7071509648127128,"a complete (and correct) proof?
504"
THEORY ASSUMPTIONS AND PROOFS,0.7082860385925085,"Answer: [NA]
505"
THEORY ASSUMPTIONS AND PROOFS,0.7094211123723042,"Justification: We didn’t present any theoretical results in this paper.
506"
THEORY ASSUMPTIONS AND PROOFS,0.7105561861520999,"Guidelines:
507"
THEORY ASSUMPTIONS AND PROOFS,0.7116912599318955,"• The answer NA means that the paper does not include theoretical results.
508"
THEORY ASSUMPTIONS AND PROOFS,0.7128263337116912,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
509"
THEORY ASSUMPTIONS AND PROOFS,0.713961407491487,"referenced.
510"
THEORY ASSUMPTIONS AND PROOFS,0.7150964812712827,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
511"
THEORY ASSUMPTIONS AND PROOFS,0.7162315550510783,"• The proofs can either appear in the main paper or the supplemental material, but if
512"
THEORY ASSUMPTIONS AND PROOFS,0.717366628830874,"they appear in the supplemental material, the authors are encouraged to provide a short
513"
THEORY ASSUMPTIONS AND PROOFS,0.7185017026106697,"proof sketch to provide intuition.
514"
THEORY ASSUMPTIONS AND PROOFS,0.7196367763904654,"• Inversely, any informal proof provided in the core of the paper should be complemented
515"
THEORY ASSUMPTIONS AND PROOFS,0.720771850170261,"by formal proofs provided in appendix or supplemental material.
516"
THEORY ASSUMPTIONS AND PROOFS,0.7219069239500567,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
517"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7230419977298524,"4. Experimental Result Reproducibility
518"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7241770715096482,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
519"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7253121452894438,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
520"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7264472190692395,"of the paper (regardless of whether the code and data are provided or not)?
521"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7275822928490352,"Answer: [Yes]
522"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7287173666288309,"Justification: All hyper-parameters and computing resources needed for experiments are
523"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7298524404086265,"listed in the Appendix.
524"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7309875141884222,"Guidelines:
525"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7321225879682179,"• The answer NA means that the paper does not include experiments.
526"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7332576617480137,"• If the paper includes experiments, a No answer to this question will not be perceived
527"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7343927355278093,"well by the reviewers: Making the paper reproducible is important, regardless of
528"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.735527809307605,"whether the code and data are provided or not.
529"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7366628830874007,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
530"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7377979568671964,"to make their results reproducible or verifiable.
531"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.738933030646992,"• Depending on the contribution, reproducibility can be accomplished in various ways.
532"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7400681044267877,"For example, if the contribution is a novel architecture, describing the architecture fully
533"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7412031782065834,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
534"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7423382519863791,"be necessary to either make it possible for others to replicate the model with the same
535"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7434733257661748,"dataset, or provide access to the model. In general. releasing code and data is often
536"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7446083995459705,"one good way to accomplish this, but reproducibility can also be provided via detailed
537"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7457434733257662,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
538"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7468785471055619,"of a large language model), releasing of a model checkpoint, or other means that are
539"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7480136208853575,"appropriate to the research performed.
540"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7491486946651532,"• While NeurIPS does not require releasing code, the conference does require all submis-
541"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7502837684449489,"sions to provide some reasonable avenue for reproducibility, which may depend on the
542"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7514188422247446,"nature of the contribution. For example
543"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7525539160045402,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
544"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.753688989784336,"to reproduce that algorithm.
545"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7548240635641317,"(b) If the contribution is primarily a new model architecture, the paper should describe
546"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7559591373439274,"the architecture clearly and fully.
547"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.757094211123723,"(c) If the contribution is a new model (e.g., a large language model), then there should
548"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7582292849035187,"either be a way to access this model for reproducing the results or a way to reproduce
549"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7593643586833144,"the model (e.g., with an open-source dataset or instructions for how to construct
550"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7604994324631101,"the dataset).
551"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7616345062429057,"(d) We recognize that reproducibility may be tricky in some cases, in which case
552"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7627695800227015,"authors are welcome to describe the particular way they provide for reproducibility.
553"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7639046538024972,"In the case of closed-source models, it may be that access to the model is limited in
554"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7650397275822929,"some way (e.g., to registered users), but it should be possible for other researchers
555"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7661748013620885,"to have some path to reproducing or verifying the results.
556"
OPEN ACCESS TO DATA AND CODE,0.7673098751418842,"5. Open access to data and code
557"
OPEN ACCESS TO DATA AND CODE,0.7684449489216799,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
558"
OPEN ACCESS TO DATA AND CODE,0.7695800227014756,"tions to faithfully reproduce the main experimental results, as described in supplemental
559"
OPEN ACCESS TO DATA AND CODE,0.7707150964812712,"material?
560"
OPEN ACCESS TO DATA AND CODE,0.771850170261067,"Answer: [Yes]
561"
OPEN ACCESS TO DATA AND CODE,0.7729852440408627,"Justification: Our code will be made public.
562"
OPEN ACCESS TO DATA AND CODE,0.7741203178206584,"Guidelines:
563"
OPEN ACCESS TO DATA AND CODE,0.775255391600454,"• The answer NA means that paper does not include experiments requiring code.
564"
OPEN ACCESS TO DATA AND CODE,0.7763904653802497,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
565"
OPEN ACCESS TO DATA AND CODE,0.7775255391600454,"public/guides/CodeSubmissionPolicy) for more details.
566"
OPEN ACCESS TO DATA AND CODE,0.7786606129398411,"• While we encourage the release of code and data, we understand that this might not be
567"
OPEN ACCESS TO DATA AND CODE,0.7797956867196367,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
568"
OPEN ACCESS TO DATA AND CODE,0.7809307604994324,"including code, unless this is central to the contribution (e.g., for a new open-source
569"
OPEN ACCESS TO DATA AND CODE,0.7820658342792282,"benchmark).
570"
OPEN ACCESS TO DATA AND CODE,0.7832009080590239,"• The instructions should contain the exact command and environment needed to run to
571"
OPEN ACCESS TO DATA AND CODE,0.7843359818388195,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
572"
OPEN ACCESS TO DATA AND CODE,0.7854710556186152,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
573"
OPEN ACCESS TO DATA AND CODE,0.7866061293984109,"• The authors should provide instructions on data access and preparation, including how
574"
OPEN ACCESS TO DATA AND CODE,0.7877412031782066,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
575"
OPEN ACCESS TO DATA AND CODE,0.7888762769580022,"• The authors should provide scripts to reproduce all experimental results for the new
576"
OPEN ACCESS TO DATA AND CODE,0.7900113507377979,"proposed method and baselines. If only a subset of experiments are reproducible, they
577"
OPEN ACCESS TO DATA AND CODE,0.7911464245175936,"should state which ones are omitted from the script and why.
578"
OPEN ACCESS TO DATA AND CODE,0.7922814982973894,"• At submission time, to preserve anonymity, the authors should release anonymized
579"
OPEN ACCESS TO DATA AND CODE,0.793416572077185,"versions (if applicable).
580"
OPEN ACCESS TO DATA AND CODE,0.7945516458569807,"• Providing as much information as possible in supplemental material (appended to the
581"
OPEN ACCESS TO DATA AND CODE,0.7956867196367764,"paper) is recommended, but including URLs to data and code is permitted.
582"
OPEN ACCESS TO DATA AND CODE,0.7968217934165721,"6. Experimental Setting/Details
583"
OPEN ACCESS TO DATA AND CODE,0.7979568671963677,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
584"
OPEN ACCESS TO DATA AND CODE,0.7990919409761634,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
585"
OPEN ACCESS TO DATA AND CODE,0.8002270147559591,"results?
586"
OPEN ACCESS TO DATA AND CODE,0.8013620885357549,"Answer: [Yes]
587"
OPEN ACCESS TO DATA AND CODE,0.8024971623155505,"Justification: All details are listed in the Appendix.
588"
OPEN ACCESS TO DATA AND CODE,0.8036322360953462,"Guidelines:
589"
OPEN ACCESS TO DATA AND CODE,0.8047673098751419,"• The answer NA means that the paper does not include experiments.
590"
OPEN ACCESS TO DATA AND CODE,0.8059023836549376,"• The experimental setting should be presented in the core of the paper to a level of detail
591"
OPEN ACCESS TO DATA AND CODE,0.8070374574347332,"that is necessary to appreciate the results and make sense of them.
592"
OPEN ACCESS TO DATA AND CODE,0.8081725312145289,"• The full details can be provided either with the code, in appendix, or as supplemental
593"
OPEN ACCESS TO DATA AND CODE,0.8093076049943246,"material.
594"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8104426787741204,"7. Experiment Statistical Significance
595"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.811577752553916,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
596"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8127128263337117,"information about the statistical significance of the experiments?
597"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8138479001135074,"Answer: [Yes]
598"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8149829738933031,"Justification: Our experiment results are reflected by classification accuracy.
599"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8161180476730987,"Guidelines:
600"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8172531214528944,"• The answer NA means that the paper does not include experiments.
601"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8183881952326901,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
602"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8195232690124858,"dence intervals, or statistical significance tests, at least for the experiments that support
603"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8206583427922814,"the main claims of the paper.
604"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8217934165720772,"• The factors of variability that the error bars are capturing should be clearly stated (for
605"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8229284903518729,"example, train/test split, initialization, random drawing of some parameter, or overall
606"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8240635641316686,"run with given experimental conditions).
607"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8251986379114642,"• The method for calculating the error bars should be explained (closed form formula,
608"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8263337116912599,"call to a library function, bootstrap, etc.)
609"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8274687854710556,"• The assumptions made should be given (e.g., Normally distributed errors).
610"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8286038592508513,"• It should be clear whether the error bar is the standard deviation or the standard error
611"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8297389330306469,"of the mean.
612"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8308740068104427,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
613"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8320090805902384,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
614"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8331441543700341,"of Normality of errors is not verified.
615"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8342792281498297,"• For asymmetric distributions, the authors should be careful not to show in tables or
616"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8354143019296254,"figures symmetric error bars that would yield results that are out of range (e.g. negative
617"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8365493757094211,"error rates).
618"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8376844494892168,"• If error bars are reported in tables or plots, The authors should explain in the text how
619"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8388195232690124,"they were calculated and reference the corresponding figures or tables in the text.
620"
EXPERIMENTS COMPUTE RESOURCES,0.8399545970488081,"8. Experiments Compute Resources
621"
EXPERIMENTS COMPUTE RESOURCES,0.8410896708286039,"Question: For each experiment, does the paper provide sufficient information on the com-
622"
EXPERIMENTS COMPUTE RESOURCES,0.8422247446083996,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
623"
EXPERIMENTS COMPUTE RESOURCES,0.8433598183881952,"the experiments?
624"
EXPERIMENTS COMPUTE RESOURCES,0.8444948921679909,"Answer: [Yes]
625"
EXPERIMENTS COMPUTE RESOURCES,0.8456299659477866,"Justification: All details are listed in the Appendix.
626"
EXPERIMENTS COMPUTE RESOURCES,0.8467650397275823,"Guidelines:
627"
EXPERIMENTS COMPUTE RESOURCES,0.8479001135073779,"• The answer NA means that the paper does not include experiments.
628"
EXPERIMENTS COMPUTE RESOURCES,0.8490351872871736,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
629"
EXPERIMENTS COMPUTE RESOURCES,0.8501702610669694,"or cloud provider, including relevant memory and storage.
630"
EXPERIMENTS COMPUTE RESOURCES,0.8513053348467651,"• The paper should provide the amount of compute required for each of the individual
631"
EXPERIMENTS COMPUTE RESOURCES,0.8524404086265607,"experimental runs as well as estimate the total compute.
632"
EXPERIMENTS COMPUTE RESOURCES,0.8535754824063564,"• The paper should disclose whether the full research project required more compute
633"
EXPERIMENTS COMPUTE RESOURCES,0.8547105561861521,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
634"
EXPERIMENTS COMPUTE RESOURCES,0.8558456299659478,"didn’t make it into the paper).
635"
CODE OF ETHICS,0.8569807037457434,"9. Code Of Ethics
636"
CODE OF ETHICS,0.8581157775255391,"Question: Does the research conducted in the paper conform, in every respect, with the
637"
CODE OF ETHICS,0.8592508513053349,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
638"
CODE OF ETHICS,0.8603859250851306,"Answer: [Yes]
639"
CODE OF ETHICS,0.8615209988649262,"Justification: We follow the code of ethics.
640"
CODE OF ETHICS,0.8626560726447219,"Guidelines:
641"
CODE OF ETHICS,0.8637911464245176,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
642"
CODE OF ETHICS,0.8649262202043133,"• If the authors answer No, they should explain the special circumstances that require a
643"
CODE OF ETHICS,0.8660612939841089,"deviation from the Code of Ethics.
644"
CODE OF ETHICS,0.8671963677639046,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
645"
CODE OF ETHICS,0.8683314415437003,"eration due to laws or regulations in their jurisdiction).
646"
BROADER IMPACTS,0.8694665153234961,"10. Broader Impacts
647"
BROADER IMPACTS,0.8706015891032917,"Question: Does the paper discuss both potential positive societal impacts and negative
648"
BROADER IMPACTS,0.8717366628830874,"societal impacts of the work performed?
649"
BROADER IMPACTS,0.8728717366628831,"Answer: [NA]
650"
BROADER IMPACTS,0.8740068104426788,"Justification: Our work doesn’t have societal impacts.
651"
BROADER IMPACTS,0.8751418842224744,"Guidelines:
652"
BROADER IMPACTS,0.8762769580022701,"• The answer NA means that there is no societal impact of the work performed.
653"
BROADER IMPACTS,0.8774120317820658,"• If the authors answer NA or No, they should explain why their work has no societal
654"
BROADER IMPACTS,0.8785471055618616,"impact or why the paper does not address societal impact.
655"
BROADER IMPACTS,0.8796821793416572,"• Examples of negative societal impacts include potential malicious or unintended uses
656"
BROADER IMPACTS,0.8808172531214529,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
657"
BROADER IMPACTS,0.8819523269012486,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
658"
BROADER IMPACTS,0.8830874006810443,"groups), privacy considerations, and security considerations.
659"
BROADER IMPACTS,0.8842224744608399,"• The conference expects that many papers will be foundational research and not tied
660"
BROADER IMPACTS,0.8853575482406356,"to particular applications, let alone deployments. However, if there is a direct path to
661"
BROADER IMPACTS,0.8864926220204313,"any negative applications, the authors should point it out. For example, it is legitimate
662"
BROADER IMPACTS,0.887627695800227,"to point out that an improvement in the quality of generative models could be used to
663"
BROADER IMPACTS,0.8887627695800226,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
664"
BROADER IMPACTS,0.8898978433598184,"that a generic algorithm for optimizing neural networks could enable people to train
665"
BROADER IMPACTS,0.8910329171396141,"models that generate Deepfakes faster.
666"
BROADER IMPACTS,0.8921679909194098,"• The authors should consider possible harms that could arise when the technology is
667"
BROADER IMPACTS,0.8933030646992054,"being used as intended and functioning correctly, harms that could arise when the
668"
BROADER IMPACTS,0.8944381384790011,"technology is being used as intended but gives incorrect results, and harms following
669"
BROADER IMPACTS,0.8955732122587968,"from (intentional or unintentional) misuse of the technology.
670"
BROADER IMPACTS,0.8967082860385925,"• If there are negative societal impacts, the authors could also discuss possible mitigation
671"
BROADER IMPACTS,0.8978433598183881,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
672"
BROADER IMPACTS,0.8989784335981839,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
673"
BROADER IMPACTS,0.9001135073779796,"feedback over time, improving the efficiency and accessibility of ML).
674"
SAFEGUARDS,0.9012485811577753,"11. Safeguards
675"
SAFEGUARDS,0.9023836549375709,"Question: Does the paper describe safeguards that have been put in place for responsible
676"
SAFEGUARDS,0.9035187287173666,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
677"
SAFEGUARDS,0.9046538024971623,"image generators, or scraped datasets)?
678"
SAFEGUARDS,0.905788876276958,"Answer: [NA]
679"
SAFEGUARDS,0.9069239500567536,"Justification: This is not applicable to our work.
680"
SAFEGUARDS,0.9080590238365494,"Guidelines:
681"
SAFEGUARDS,0.9091940976163451,"• The answer NA means that the paper poses no such risks.
682"
SAFEGUARDS,0.9103291713961408,"• Released models that have a high risk for misuse or dual-use should be released with
683"
SAFEGUARDS,0.9114642451759364,"necessary safeguards to allow for controlled use of the model, for example by requiring
684"
SAFEGUARDS,0.9125993189557321,"that users adhere to usage guidelines or restrictions to access the model or implementing
685"
SAFEGUARDS,0.9137343927355278,"safety filters.
686"
SAFEGUARDS,0.9148694665153235,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
687"
SAFEGUARDS,0.9160045402951191,"should describe how they avoided releasing unsafe images.
688"
SAFEGUARDS,0.9171396140749148,"• We recognize that providing effective safeguards is challenging, and many papers do
689"
SAFEGUARDS,0.9182746878547106,"not require this, but we encourage authors to take this into account and make a best
690"
SAFEGUARDS,0.9194097616345063,"faith effort.
691"
LICENSES FOR EXISTING ASSETS,0.9205448354143019,"12. Licenses for existing assets
692"
LICENSES FOR EXISTING ASSETS,0.9216799091940976,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
693"
LICENSES FOR EXISTING ASSETS,0.9228149829738933,"the paper, properly credited and are the license and terms of use explicitly mentioned and
694"
LICENSES FOR EXISTING ASSETS,0.923950056753689,"properly respected?
695"
LICENSES FOR EXISTING ASSETS,0.9250851305334846,"Answer: [Yes]
696"
LICENSES FOR EXISTING ASSETS,0.9262202043132803,"Justification: We cite all code, data, and previous works in a proper manner.
697"
LICENSES FOR EXISTING ASSETS,0.927355278093076,"Guidelines:
698"
LICENSES FOR EXISTING ASSETS,0.9284903518728718,"• The answer NA means that the paper does not use existing assets.
699"
LICENSES FOR EXISTING ASSETS,0.9296254256526674,"• The authors should cite the original paper that produced the code package or dataset.
700"
LICENSES FOR EXISTING ASSETS,0.9307604994324631,"• The authors should state which version of the asset is used and, if possible, include a
701"
LICENSES FOR EXISTING ASSETS,0.9318955732122588,"URL.
702"
LICENSES FOR EXISTING ASSETS,0.9330306469920545,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
703"
LICENSES FOR EXISTING ASSETS,0.9341657207718501,"• For scraped data from a particular source (e.g., website), the copyright and terms of
704"
LICENSES FOR EXISTING ASSETS,0.9353007945516458,"service of that source should be provided.
705"
LICENSES FOR EXISTING ASSETS,0.9364358683314415,"• If assets are released, the license, copyright information, and terms of use in the
706"
LICENSES FOR EXISTING ASSETS,0.9375709421112373,"package should be provided. For popular datasets, paperswithcode.com/datasets
707"
LICENSES FOR EXISTING ASSETS,0.9387060158910329,"has curated licenses for some datasets. Their licensing guide can help determine the
708"
LICENSES FOR EXISTING ASSETS,0.9398410896708286,"license of a dataset.
709"
LICENSES FOR EXISTING ASSETS,0.9409761634506243,"• For existing datasets that are re-packaged, both the original license and the license of
710"
LICENSES FOR EXISTING ASSETS,0.94211123723042,"the derived asset (if it has changed) should be provided.
711"
LICENSES FOR EXISTING ASSETS,0.9432463110102156,"• If this information is not available online, the authors are encouraged to reach out to
712"
LICENSES FOR EXISTING ASSETS,0.9443813847900113,"the asset’s creators.
713"
NEW ASSETS,0.945516458569807,"13. New Assets
714"
NEW ASSETS,0.9466515323496028,"Question: Are new assets introduced in the paper well documented and is the documentation
715"
NEW ASSETS,0.9477866061293984,"provided alongside the assets?
716"
NEW ASSETS,0.9489216799091941,"Answer: [NA]
717"
NEW ASSETS,0.9500567536889898,"Justification: This is not applicable to our work.
718"
NEW ASSETS,0.9511918274687855,"Guidelines:
719"
NEW ASSETS,0.9523269012485811,"• The answer NA means that the paper does not release new assets.
720"
NEW ASSETS,0.9534619750283768,"• Researchers should communicate the details of the dataset/code/model as part of their
721"
NEW ASSETS,0.9545970488081725,"submissions via structured templates. This includes details about training, license,
722"
NEW ASSETS,0.9557321225879682,"limitations, etc.
723"
NEW ASSETS,0.9568671963677639,"• The paper should discuss whether and how consent was obtained from people whose
724"
NEW ASSETS,0.9580022701475596,"asset is used.
725"
NEW ASSETS,0.9591373439273553,"• At submission time, remember to anonymize your assets (if applicable). You can either
726"
NEW ASSETS,0.960272417707151,"create an anonymized URL or include an anonymized zip file.
727"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9614074914869466,"14. Crowdsourcing and Research with Human Subjects
728"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9625425652667423,"Question: For crowdsourcing experiments and research with human subjects, does the paper
729"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.963677639046538,"include the full text of instructions given to participants and screenshots, if applicable, as
730"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9648127128263337,"well as details about compensation (if any)?
731"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9659477866061293,"Answer: [NA]
732"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9670828603859251,"Justification: This is not applicable to our work.
733"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9682179341657208,"Guidelines:
734"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9693530079455165,"• The answer NA means that the paper does not involve crowdsourcing nor research with
735"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9704880817253121,"human subjects.
736"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9716231555051078,"• Including this information in the supplemental material is fine, but if the main contribu-
737"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9727582292849035,"tion of the paper involves human subjects, then as much detail as possible should be
738"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9738933030646992,"included in the main paper.
739"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9750283768444948,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
740"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9761634506242906,"or other labor should be paid at least the minimum wage in the country of the data
741"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9772985244040863,"collector.
742"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.978433598183882,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
743"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9795686719636776,"Subjects
744"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9807037457434733,"Question: Does the paper describe potential risks incurred by study participants, whether
745"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.981838819523269,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
746"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9829738933030647,"approvals (or an equivalent approval/review based on the requirements of your country or
747"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9841089670828603,"institution) were obtained?
748"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.985244040862656,"Answer: [NA]
749"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9863791146424518,"Justification: This is not applicable to our work.
750"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9875141884222475,"Guidelines:
751"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9886492622020431,"• The answer NA means that the paper does not involve crowdsourcing nor research with
752"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9897843359818388,"human subjects.
753"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9909194097616345,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
754"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9920544835414302,"may be required for any human subjects research. If you obtained IRB approval, you
755"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9931895573212258,"should clearly state this in the paper.
756"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9943246311010215,"• We recognize that the procedures for this may vary significantly between institutions
757"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9954597048808173,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
758"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.996594778660613,"guidelines for their institution.
759"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9977298524404086,"• For initial submissions, do not include any information that would break anonymity (if
760"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9988649262202043,"applicable), such as the institution conducting the review.
761"
