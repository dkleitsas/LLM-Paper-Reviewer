Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0016233766233766235,"Humans excel at continually learning from an ever-changing environment whereas
it remains a challenge for deep neural networks which exhibit catastrophic forget-
ting. The complementary learning system (CLS) theory suggests that the interplay
between rapid instance-based learning and slow structured learning in the brain is
crucial for accumulating and retaining knowledge. Here, we propose CLS-ER, a
novel dual memory experience replay (ER) method which maintains short-term
and long-term semantic memories that interact with the episodic memory. Our
method employs an effective replay mechanism whereby new knowledge is ac-
quired while aligning the decision boundaries with the semantic memories. CLS-
ER does not utilize the task boundaries or make any assumption about the dis-
tribution of the data which makes it versatile and suited for “general continual
learning”. Our approach achieves state-of-the-art performance on standard bench-
marks as well as more realistic general continual learning settings. 1"
INTRODUCTION,0.003246753246753247,"1
INTRODUCTION"
INTRODUCTION,0.00487012987012987,"Continual learning (CL) refers to the ability of a learning agent to continuously interact with a
dynamic environment and process a stream of information to acquire new knowledge while consoli-
dating and retaining previously obtained knowledge (Parisi et al., 2019). This ability to continuously
learn from a changing environment is a hallmark of intelligence and a critical missing component in
our quest towards making our models truly intelligent. The major challenge towards enabling CL in
deep neural networks (DNNs) is that the continual acquisition of incrementally available informa-
tion from non-stationary data distributions leads to catastrophic forgetting whereby the performance
of the model on previously learned tasks drops drastically (McCloskey & Cohen, 1989)."
INTRODUCTION,0.006493506493506494,"Several approaches have been proposed to address the issue of catastrophic forgetting in CL. These
can be broadly categorized into regularization-based methods (Farajtabar et al., 2020; Kirkpatrick
et al., 2017; Ritter et al., 2018; Zenke et al., 2017) which penalizes changes in the network weights,
network expansion-based methods (Rusu et al., 2016; Yoon et al., 2017) which dedicate a distinct
set of network parameters to distinct tasks, and rehearsal-based methods (Chaudhry et al., 2018;
Lopez-Paz & Ranzato, 2017) which maintains a memory buffer and replays samples from previous
tasks. Amongst these, rehearsal-based methods have proven to be more effective in challenging CL
tasks (Farquhar & Gal, 2018). However, an optimal approach for replaying memory samples and
constraining the model update to efﬁciently consolidate knowledge remains an open question."
INTRODUCTION,0.008116883116883116,"In the brain, the ability to continually acquire, consolidate, and transfer knowledge over time is
mediated by a rich set of neurophysiological processing principles (Parisi et al., 2019; Zenke et al.,
2017) and multiple memory systems (Hassabis et al., 2017). In particular, the CLS theory (Kumaran
et al., 2016) posits that efﬁcient learning requires two complementary learning systems: the hip-
pocampus exhibits short-term adaptation and rapid learning of episodic information which is then
gradually consolidated to the neocortex for slow learning of structured information. Furthermore, a
recent study by Hayes et al. (2021) identiﬁed the missing elements of biological reply in the replay"
INTRODUCTION,0.00974025974025974,"∗Contributed equally.
1The code is avaiable at: https://github.com/NeurAI-Lab/CLS-ER"
INTRODUCTION,0.011363636363636364,Published as a conference paper at ICLR 2022
INTRODUCTION,0.012987012987012988,Working Model
INTRODUCTION,0.01461038961038961,Update
INTRODUCTION,0.016233766233766232,Consistency Loss
INTRODUCTION,0.017857142857142856,Semantic
INTRODUCTION,0.01948051948051948,Memory
INTRODUCTION,0.021103896103896104,Plastic Model
INTRODUCTION,0.022727272727272728,"Stable
Model"
INTRODUCTION,0.024350649350649352,Episodic
INTRODUCTION,0.025974025974025976,Memory
INTRODUCTION,0.027597402597402596,Reservoir
INTRODUCTION,0.02922077922077922,"and
Update with rates"
INTRODUCTION,0.030844155844155844,Data Stream ...
INTRODUCTION,0.032467532467532464,Plastic Model
INTRODUCTION,0.03409090909090909,"- Fast
learning of
recent
experiences"
INTRODUCTION,0.03571428571428571,"- Short-term
adaptation"
INTRODUCTION,0.037337662337662336,"- Efficient 
representation
of recent tasks"
INTRODUCTION,0.03896103896103896,Working Model
INTRODUCTION,0.040584415584415584,"- Memorization
of episodic-like
events"
INTRODUCTION,0.04220779220779221,"- Learns
statistical
structure of the
perceived event"
INTRODUCTION,0.04383116883116883,"Storage,
retrieval,"
INTRODUCTION,0.045454545454545456,replay
INTRODUCTION,0.04707792207792208,Stable Model
INTRODUCTION,0.048701298701298704,"- Slow
learning of
structural
knowledge"
INTRODUCTION,0.05032467532467533,"- Long-term
retention"
INTRODUCTION,0.05194805194805195,"- Efficient
representation
across the
tasks"
INTRODUCTION,0.05357142857142857,"Storage,
retrieval,"
INTRODUCTION,0.05519480519480519,replay
INTRODUCTION,0.056818181818181816,"Figure 1: CLS-ER employs a dual-memory learning mechanism whereby the episodic memory
stores the samples and the semantic memories build short-term and long-term memories of the
learned representations of the working model. The two memories interact to enforce a consistency
loss on the working model which prevents rapid changes in the parameter space and enables the
alignment of the decision boundary with semantic memories for effective knowledge consolidation."
INTRODUCTION,0.05844155844155844,"mechanisms employed in DNNs for CL. They highlight that many existing approaches only focus on
modeling the prefrontal cortex directly and do not have a fast learning network which plays a critical
role in enabling efﬁcient CL in the brain. Inspired by these studies, we hypothesize that mimicking
the slow and rapid adaptation of information and having an efﬁcient mechanism for incorporating
them into the working memory can enable better CL in DNNs."
INTRODUCTION,0.060064935064935064,"To this end, we propose a novel dual memory experience replay method based on the complementary
learning systems theory in the brain, dubbed as CLS-ER. In addition to a small episodic memory,
our method builds long-term and short-term semantic memories which mimic the rapid and slow
adaptation of information (Figure 1). As the network weights encode the learned representations of
the tasks (Krishnan et al., 2019), the semantic memories are maintained by taking the exponential
moving average of the working model’s weights to consolidate information across the tasks with
varying time windows and frequencies. The semantic memories interact with the episodic memory
to extract consolidated replay activation patterns and enforce a consistency loss on the update of
the working model so that new knowledge is acquired while aligning the decision boundary of
the working model with the decision boundaries of semantic memories. This maintains a balance
between the plasticity and stability of the model for effective knowledge consolidation."
INTRODUCTION,0.06168831168831169,"CLS-ER provides a general CL method that does not utilize the task boundaries or make any strong
assumption regarding the distribution of the data and tasks. We demonstrate the versatility and
effectiveness of our method on a wide range of CL benchmark tasks as well as more challenging
scenarios which simulate the complexities of CL in the real world."
RELATED WORK,0.0633116883116883,"2
RELATED WORK"
RELATED WORK,0.06493506493506493,"The base method for the rehearsal-based approach, Experience Replay (ER) (Riemer et al., 2018)
combines the memory samples with the task samples into the training batch. Several techniques
have since been employed on top of ER. Meta Experience Replay (MER) (Riemer et al., 2018)
considers replay as a meta-learning problem for maximizing the transfer from previous tasks and
minimizing the interference. iCARL (Rebufﬁet al., 2017) uses the nearest average representation
of past exemplars to classify in an incrementally learned representation space. Gradient Episodic
Memory (GEM) (Lopez-Paz & Ranzato, 2017) formulates optimization constraints on the exem-
plars in memory. Gradient-based Sample Selection (GSS) (Aljundi et al., 2019) aims for memory
sample diversity in the gradient space and provides a greedy selection approach. Function Distance
Regularization (FDR) (Benjamin et al., 2018) saves the network response at the task boundaries and
adds a consistency loss on top of ER. Dark Experience Replay (DER++) applies knowledge distil-
lation (Sarfraz et al., 2021) and regularization on logits sampled during the optimization trajectory."
RELATED WORK,0.06655844155844155,"CLS has been used as a source of inspiration for dual memory learning systems in earlier works
(French, 1999; Robins, 1993) but they have not been shown to scale to current computer vision
tasks (Parisi et al., 2019). Recently, Rostami et al. (2019) utilizes a generative model to couple
sequential tasks in a latent embedding space. Kamra et al. (2017) utilizes two generative models"
RELATED WORK,0.06818181818181818,Published as a conference paper at ICLR 2022
RELATED WORK,0.0698051948051948,Task 1
RELATED WORK,0.07142857142857142,Task 2
RELATED WORK,0.07305194805194805,Task 3
RELATED WORK,0.07467532467532467,Task 4
RELATED WORK,0.0762987012987013,Task 5
RELATED WORK,0.07792207792207792,After Task 1
RELATED WORK,0.07954545454545454,After Task 2
RELATED WORK,0.08116883116883117,After Task 3
RELATED WORK,0.08279220779220779,After Task 4
RELATED WORK,0.08441558441558442,After Task 5
RELATED WORK,0.08603896103896104,"98.7
0.0
0.0
0.0
0.0"
RELATED WORK,0.08766233766233766,"93.05
88.55
0.0
0.0
0.0"
RELATED WORK,0.08928571428571429,"87.5
74.6
78.3
0.0
0.0"
RELATED WORK,0.09090909090909091,"88.8
73.4
74.25
46.05
0.0"
RELATED WORK,0.09253246753246754,"77.5
55.7
76.1
84.3
78.55"
RELATED WORK,0.09415584415584416,Stable Model
RELATED WORK,0.09577922077922078,Task 1
RELATED WORK,0.09740259740259741,Task 2
RELATED WORK,0.09902597402597403,Task 3
RELATED WORK,0.10064935064935066,Task 4
RELATED WORK,0.10227272727272728,Task 5
RELATED WORK,0.1038961038961039,"98.6
0.0
0.0
0.0
0.0"
RELATED WORK,0.10551948051948051,"75.55
90.95
0.0
0.0
0.0"
RELATED WORK,0.10714285714285714,"80.45
31.5
96.05
0.0
0.0"
RELATED WORK,0.10876623376623376,"79.8
37.4
48.35
98.25
0.0"
RELATED WORK,0.11038961038961038,"51.1
40.05
58.05
72.65
97.75"
RELATED WORK,0.11201298701298701,Working Model
RELATED WORK,0.11363636363636363,Task 1
RELATED WORK,0.11525974025974026,Task 2
RELATED WORK,0.11688311688311688,Task 3
RELATED WORK,0.1185064935064935,Task 4
RELATED WORK,0.12012987012987013,Task 5
RELATED WORK,0.12175324675324675,"98.85
0.0
0.0
0.0
0.0"
RELATED WORK,0.12337662337662338,"84.25
92.55
0.0
0.0
0.0"
RELATED WORK,0.125,"84.1
55.25
92.65
0.0
0.0"
RELATED WORK,0.1266233766233766,"86.05
66.9
67.9
82.9
0.0"
RELATED WORK,0.12824675324675325,"68.3
50.7
70.25
75.8
94.2"
RELATED WORK,0.12987012987012986,Plastic Model
RELATED WORK,0.1314935064935065,"Figure 2: Task-wise performance on S-CIFAR-10 test set with 500 buffer size. The models are
evaluated at the end of each task (y-axis) to evaluate how the task performances (x-axis) are af-
fected as training progress. The stable model retains information from earlier tasks while the plastic
model quickly adapts to the recent task. Note that there is less forgetting in the semantic memories
compared to the working model. For other buffer sizes and S-TinyImageNet see Figures S1 and S2."
RELATED WORK,0.1331168831168831,"in a dual memory architecture. However, they utilize the task boundaries and generative replay has
its own set of challenges as it is difﬁcult to learn a faithful distribution and performs sub-par in
comparison to instance-based replay methods on challenging CL settings. Generally, the inspiration
from CLS theory in DNNs has been mostly limited to episodic memory and mimicking the rapid
and slow learning mechanism is majorly ignored (Hayes et al., 2021) which we aim to address."
METHOD,0.13474025974025974,"3
METHOD"
METHOD,0.13636363636363635,"We ﬁrst provide an overview of the CLS theory for the brain and how we aim to mimic it for DNNs
before introducing the main components of our method and the overall formulation."
COMPLEMENTARY LEARNING SYSTEM THEORY,0.137987012987013,"3.1
COMPLEMENTARY LEARNING SYSTEM THEORY"
COMPLEMENTARY LEARNING SYSTEM THEORY,0.1396103896103896,"The CLS theory posits that effective lifelong learning in the brain requires two complementary learn-
ing systems. The hippocampus rapidly encodes novel information as a short-term memory which is
subsequently used to transfer and consolidate knowledge in the neocortex which gradually acquires
structured knowledge representation as long-term memory through experience replay. The interplay
between the functionality of the hippocampus and neocortex is crucial for concurrently learning efﬁ-
cient representations (for better generalization) and the speciﬁcs of instance-based episodic memory."
COMPLEMENTARY LEARNING SYSTEM BASED EXPERIENCED REPLAY,0.14123376623376624,"3.2
COMPLEMENTARY LEARNING SYSTEM BASED EXPERIENCED REPLAY"
COMPLEMENTARY LEARNING SYSTEM BASED EXPERIENCED REPLAY,0.14285714285714285,"Inspired by the CLS theory, we propose a dual memory experience replay method, CLS-ER, which
aims to mimic the interplay between fast learning and slow learning mechanisms for enabling ef-
fective CL in DNNs. Our method maintains short-term and long-term semantic memories of the
encountered tasks which interact with the episodic memory for replaying the associated neural ac-
tivities. The working model is updated so that it acquires new knowledge while aligning its decision
boundary with the semantic memories to enable the consolidation of structured knowledge across
the tasks. Figure 1 highlights the parallels between CLS theory and our method."
COMPLEMENTARY LEARNING SYSTEM BASED EXPERIENCED REPLAY,0.1444805194805195,"Semantic Memories: Central to our method is the maintenance of two semantic memories which
accumulate and consolidate information over long-term and short-term periods. As the acquired
knowledge of the learned tasks is encoded in the weights of DNNs (Krishnan et al., 2019), we
aim to form our semantic memories by accumulating the knowledge encoded in the corresponding
weights of the model as it sequentially learns different tasks."
COMPLEMENTARY LEARNING SYSTEM BASED EXPERIENCED REPLAY,0.1461038961038961,"An efﬁcient method for aggregating the weights of a model is provided by Mean Teacher (Tarvainen
& Valpola, 2017) which is a knowledge distillation approach that uses an exponential moving aver-
age (EMA) of the student’s weights during training as a teacher for semi-supervised learning. It can
also be considered as forming a self-ensemble of the intermediate model states that leads to better"
COMPLEMENTARY LEARNING SYSTEM BASED EXPERIENCED REPLAY,0.14772727272727273,Published as a conference paper at ICLR 2022
COMPLEMENTARY LEARNING SYSTEM BASED EXPERIENCED REPLAY,0.14935064935064934,"internal representations. We adapt the Mean Teacher approach to build our semantic memories as it
provides a computational and memory-efﬁcient method for accumulating knowledge over the tasks."
COMPLEMENTARY LEARNING SYSTEM BASED EXPERIENCED REPLAY,0.15097402597402598,"As CL involves learning tasks sequentially, the model weights at each training step can be consid-
ered as a student model specialized for a particular task. Therefore, averaging the weights during
training can be considered as forming an ensemble of task-speciﬁc student models which effec-
tively aggregates information across the tasks and leads to smoother decision boundaries. CLS-ER
builds long-term (stable model) and short-term (plastic model) semantic memories by maintaining
two EMA-weighted models over the working model’s weights. The stable model is updated less
frequently with a larger window size so that it retains more information from the earlier tasks while
the plastic model is updated more frequently with a smaller window size so that it adapts faster to
information from new tasks (Figure 2). Section D further demonstrates the beneﬁts of employing
two semantic memories instead of a single semantic memory."
COMPLEMENTARY LEARNING SYSTEM BASED EXPERIENCED REPLAY,0.1525974025974026,"Episodic Memory: Replay of samples from the previous tasks stored in a small episodic memory
is a common approach in CL that has proven to be effective in mitigating catastrophic forgetting.
As we aim to position CLS-ER as a versatile general incremental learning method, we do not utilize
the task boundaries or make any strong assumptions about the distribution of the tasks or samples.
Therefore, to maintain a ﬁxed episodic memory buffer, we employ Reservoir sampling (Vitter, 1985)
which assigns equal probability to each sample in the stream for being represented in the buffer and
randomly replaces the existing memory samples (Algorithm 2). It is a global distribution matching
strategy that ensures that at any given time the distribution of samples in the buffer will approxi-
mately match the distribution of all the samples seen so far (Isele & Cosgun, 2018)."
COMPLEMENTARY LEARNING SYSTEM BASED EXPERIENCED REPLAY,0.15422077922077923,"Consolidation of Information: The key challenge in CL is the consolidation of new information
with the previously acquired information. This requires an effective balance between the stability
and plasticity of the model. Furthermore, the sharp change in decision boundary as a new task is
learned makes the consolidation of information over tasks more challenging. CLS-ER tackles these
challenges through a novel dual memory experience replay mechanism. The long-term and short-
term semantic memories interact with the episodic memory to extract the consolidated activations
for the memory samples which are then utilized to constrain the update of the working model so that
new knowledge is obtained whilst the decision boundary is aligned with the semantic memories.
This prevents rapid changes in the parameter space as new tasks are learned. Furthermore, aligning
the working model’s decision boundary with the semantic memories serves two goals: (i) helps in
retaining and consolidating information and (ii) leads to a smoother adaptation of decision boundary."
FORMULATION,0.15584415584415584,"3.3
FORMULATION"
FORMULATION,0.15746753246753248,"CLS-ER involves training a working model f(.; θw) on a data stream D sampled from a non-iid
distribution. Two additional EMA-weighted models are maintained as semantic memories: plastic
model f(.; θP ) and the stable model f(.; θS). Finally, Reservoir sampling (Vitter, 1985) is employed
to maintain a small episodic memory M."
FORMULATION,0.1590909090909091,"At each training step, the working model receives the training batch Xb from the data stream and
retrieves a random batch of exemplars Xm from the episodic memory. This is then followed by
the retrieval of optimal semantic information, i.e. the structural knowledge encoded in the semantic
memories which account for the consolidation of feature space and adaptation of the decision bound-
aries of the previous tasks. The semantic memories are designed so that the plastic model has higher
performance on recent tasks whereas the stable model prioritizes retaining information on the older
tasks. Therefore, we would prefer to use the logits from the stable model ZS for older exemplars and
the plastic model ZP for recent exemplars. As CLS-ER is a general incremental learning method,
instead of using a hard threshold or task information, we opt for a simple task-agnostic approach
of using the performance of the semantic memories on the exemplars as a selection criterion that
empirically works well. For each exemplar, we select the replay logits Z based on which model has
the highest softmax score for the ground-truth class (lines 5-6 in Algorithm 1)."
FORMULATION,0.16071428571428573,"The selected replay logits from the semantic memories are then used to enforce a consistency loss
on the working model so that it does not deviate from the already learned experiences. Hence, the
working model is updated with a combination of the cross-entropy loss on the union of the data
stream and episodic memory samples, X, and the consistency loss on the exemplars Xm,"
FORMULATION,0.16233766233766234,"L = LCE(σ(f(X; θW )), Y ) + λLMSE(f(Xm; θW ), Z)
(1)"
FORMULATION,0.16396103896103897,Published as a conference paper at ICLR 2022
FORMULATION,0.16558441558441558,Algorithm 1 Complementary Learning System-Experience Replay Algorithm
FORMULATION,0.1672077922077922,"Input: Data stream D, Learning rate η, Consistency weight λ, Update rates rP and rS, Decay
parameters αP and αS
Initialize: θW = θP = θS
M ←−{}
1: while Training do
2:
(Xb, Yb) ∼D and (Xm, Ym) ∼M
3:
(X, Y ) = {(Xb, Yb), (Xm, Ym)}
4:
ZP , ZS ←−f(Xm; θP ), f(Xm; θS)
▷Select optimal semantic memory
5:
Z ←−ZP if σ(ZP )(Ym) > σ(ZS)(Ym) else ZS
6:
L = LCE(σ(f(X; θW )), Y ) + λLMSE(f(Xm; θW ), Z)
▷Update working model
7:
θW ←−θW −η∇θW L
8:
a, b ∼U(0, 1)
▷Update semantic memories
9:
θP ←−αpθP + (1 −αP )θW if a < rP else θP
10:
θS ←−αSθS + (1 −αS)θW if b < rS else θS
11:
M ←−Reservoir(M, (Xb, Yb))
▷Update episodic memory (Algorithm 2)
return θW , θP , θS"
FORMULATION,0.16883116883116883,"where σ is the softmax function, λ the regularization parameter, and LMSE the mean squared error
loss used as consistency term."
FORMULATION,0.17045454545454544,"After updating the working model, we stochastically update the plastic and stable models with rates
rP and rS (note that rP > rS so that the plastic model is updated more frequently). A stochastic
rather than a deterministic approach is more biologically plausible (Maass, 2014; Arani et al., 2021)
which reduces the overlap in the snapshots of the working model and leads to more diversity in
semantic memories. The semantic memories are updated by taking an exponential moving average
of the working model’s weights (Tarvainen & Valpola, 2017) with decay parameters αP and αS,"
FORMULATION,0.17207792207792208,"θi = αiθi + (1 −αi)θW ,
i ∈{P, S}
(2)"
FORMULATION,0.1737012987012987,"Note that αP ≤αS so that the plastic model mimics the rapid adaptation of information while the
stable model mimics slow acquisition of structured knowledge. See Algorithm 1 for more details."
FORMULATION,0.17532467532467533,"For inference, we use the stable model as it retains long-term memory across the tasks, consolidates
structural knowledge, and learns efﬁcient representations for generalization (Figure 1)."
EXPERIMENTAL SETUP,0.17694805194805194,"4
EXPERIMENTAL SETUP"
EXPERIMENTAL SETUP,0.17857142857142858,"To ensure a fair comparison of different CL methods under uniform experimental settings, we ex-
tended the Mammoth framework (Buzzega et al., 2020a) and unless stated otherwise, we follow
the same training scheme (learning rate, batch sizes of incoming data and memory buffer, and the
number of training epochs) as them for each of the evaluation settings. To ﬁnd the optimal hyper-
parameters for CLS-ER, we run a grid search over λ, αS, αP , rS, and rP on a small validation set.
Sections C.4 and E show that our method is not highly sensitive to the particular choice of hyperpa-
rameters and different settings can attain similar performance. Also, because of the complementary
nature of the components, we can often ﬁx a set of parameters (e.g. λ, αS, αP and rS) and only
ﬁnetune the remaining parameters (e.g. rP ) which facilitates hyperparameter tuning signiﬁcantly."
EXPERIMENTAL SETUP,0.18019480519480519,"Following Buzzega et al. (2020a), we employ a fully connected network with two hidden layers,
each with 100 ReLU units on all the variants of the MNIST dataset and ResNet-18 (He et al., 2015)
without pretraining for the other datasets. In all the settings, we use the SGD optimizer. We use
random horizontal ﬂip and random crop on both the stream and buffer samples for S-CIFAR-10,
S-Tiny-ImageNet, and GCIL-CIFAR-100. The selected hyperparameters for each of the settings
are provided in Table S4. Note that for the vast majority of datasets, we use uniform settings (lr,
epochs, batch size, memory batch size, and lambda) across different buffer sizes and only slight
modiﬁcations in the other hyperparameters which shows that our method does not require extensive
ﬁnetuning for different memory budgets. For each of our experiments, we ﬁx the order of the classes
and report the average and one standard deviation of the mean test accuracy of all the tasks across 10
runs with different initializations. Section E provides further training and implementation details."
EXPERIMENTAL SETUP,0.18181818181818182,Published as a conference paper at ICLR 2022
EXPERIMENTAL SETUP,0.18344155844155843,"Buffer
Method
Class-IL
Domain-IL
S-MNIST
S-CIFAR-10
S-Tiny-ImageNet
R-MNIST
P-MNIST"
EXPERIMENTAL SETUP,0.18506493506493507,"–
JOINT
95.57±0.24
92.20±0.15
59.99±0.19
95.76±0.04
94.33±0.17
SGD
19.60±0.04
19.62±0.05
7.92±0.26
67.66±8.53
40.70±2.33 200"
EXPERIMENTAL SETUP,0.18668831168831168,"ER
80.43±1.89
44.79±1.86
8.49±0.16
85.01±1.90
72.37±0.87
GEM
80.11±1.54
25.54±0.76
-
80.80±1.15
66.93±1.25
iCaRL
70.51±0.53
49.02±3.20
7.53±0.79
-
-
FDR
79.43±3.26
30.91±2.74
8.70±0.19
85.22±3.35
74.77±0.83
GSS
38.92±2.49
39.07±5.59
-
79.50±0.41
63.72±0.70
DER++
85.61±1.40
64.88±1.17
10.96±1.17
90.43±1.87
83.58±0.59
CLS-ER
89.54±0.21
66.19±0.75
23.47±0.80
92.26±0.18
84.63±0.40 500"
EXPERIMENTAL SETUP,0.18831168831168832,"ER
86.12±1.89
57.74±0.27
9.99±0.29
88.91±1.44
80.60±0.86
GEM
85.99±1.35
26.20±1.26
-
81.15±1.98
76.88±0.52
iCaRL
70.10±1.08
47.55±3.95
9.38±1.53
-
-
FDR
85.87±4.04
28.71±3.23
10.54±0.21
89.67±1.63
83.18±0.53
GSS
49.76±4.73
49.73±4.78
-
81.58±0.58
76.00±0.87
DER++
91.00±1.49
72.70±1.36
19.38±1.41
92.77±1.05
88.21±0.39
CLS-ER
92.05±0.32
75.22±0.71
31.03±0.56
94.06±0.07
88.30±0.14 5120"
EXPERIMENTAL SETUP,0.18993506493506493,"ER
93.40±1.29
82.47±0.52
27.40±0.31
93.45±0.56
89.90±0.13
GEM
95.11±0.87
25.26±3.46
-
88.57±0.40
87.42±0.95
iCaRL
70.60±1.03
55.07±1.55
14.08±1.92
-
-
FDR
87.47±3.15
19.70±0.07
28.97±0.41
94.19±0.44
90.87±0.16
GSS
89.39±0.75
67.27±4.27
-
85.24±0.59
82.22±1.14
DER++
95.30±1.20
85.24±0.49
39.02±0.97
94.65±0.33
92.26±0.17
CLS-ER
95.73±0.11
86.78±0.17
46.74±0.31
94.25±0.06
92.03±0.05"
EXPERIMENTAL SETUP,0.19155844155844157,"Table 1: Comparison with prior works on Class-IL and Domain-IL settings. The baseline results are
from Buzzega et al. (2020a) (- indicates the experiments that the authors were unable to run)."
EMPIRICAL EVALUATION,0.19318181818181818,"5
EMPIRICAL EVALUATION"
EMPIRICAL EVALUATION,0.19480519480519481,"There are a plethora of evaluation protocols in the CL literature, each of which biases the evaluation
towards a certain approach (Farquhar & Gal, 2018; Mi et al., 2020; van de Ven & Tolias, 2019). It
is therefore of utmost importance to conduct an extensive and robust evaluation over different CL
settings to gauge the versatility of the method. Details of the datasets used in each CL setting are
provided in Section A. We compare our method with the state-of-the-art rehearsal-based approaches
on various CL settings and memory budgets under uniform experimental settings. SGD refers to
standard training and JOINT provides an upper bound given by training all tasks jointly."
EMPIRICAL EVALUATION,0.19642857142857142,"Class Incremental Learning (Class-IL): refers to the CL scenario where new classes are added
with each subsequent task and the agent must learn to distinguish not only amongst the classes
within the current task but also across previous tasks. Class-IL measures how well the method can
learn general representations, accumulate, consolidate, and transfer the acquired knowledge to learn
efﬁcient representations and decision boundaries for all the classes seen so far."
EMPIRICAL EVALUATION,0.19805194805194806,"Table 1 provides the comparison with six rehearsal-based approaches on Class-IL settings with
varying datasets and task length complexities. CLS-ER provides the highest performance in all of
these scenarios. In particular, as the dataset complexity and number of tasks increase from S-MNIST
to S-Tiny-ImageNet, the performance gap between CLS-ER and DER++ increases considerably.
Especially, with a smaller memory budget, CLS-ER is able to retain more information than other
methods. In the most challenging setting, S-Tiny-ImageNet with 200 buffer size, CLS-ER provides
a percentage gain of 176% and 114% over the baseline ER and the current state-of-the-art DER++,
respectively. The results demonstrate the capability of CLS-ER to efﬁciently accumulate and retain
knowledge over longer sequences under complex and memory restrictive scenarios."
EMPIRICAL EVALUATION,0.19967532467532467,"We believe that the performance gains over DER++ highlight a key component of an efﬁcient CL
agent: the ability to consolidate previously acquired knowledge. DER++ fails to account for the con-
solidation of feature space and adaptation of the decision boundaries of the previous tasks. There-
fore, constraining the model to match the sub-optimal logits might hamper the consolidation of
knowledge. This becomes more prominent as the number of classes in each task, the sequence"
EMPIRICAL EVALUATION,0.2012987012987013,Published as a conference paper at ICLR 2022
EMPIRICAL EVALUATION,0.20292207792207792,"JOINT
SGD
Buffer
ER
MER
GSS
DER++
CLS-ER"
EMPIRICAL EVALUATION,0.20454545454545456,"82.98±3.24
19.09±0.69"
EMPIRICAL EVALUATION,0.20616883116883117,"200
49.27±2.25
48.58±1.07
43.92±2.43
54.16±3.02
66.37±0.83
500
65.04±1.53
62.21±1.36
54.45±3.14
69.62±1.59
75.70±0.41
1000
75.18±1.50
70.91±0.76
63.84±2.09
76.03±1.61
79.54±0.34"
EMPIRICAL EVALUATION,0.2077922077922078,"Table 2: Comparison with prior works on MNIST-360 test set. The baseline results are from Buzzega
et al. (2020a)."
EMPIRICAL EVALUATION,0.20941558441558442,"Distribution
Uniform
Longtail
JOINT
58.36±1.02
56.94±1.56
SGD
12.67±0.24
22.88±0.53
Buffer
200
500
1000
200
500
1000
ER
16.40±0.37
28.21±0.69
31.98±0.72
19.27±0.77
20.30±0.63
34.13±0.83
DER++
18.84±0.60
32.92±0.74
38.95±0.56
26.94±1.27
25.82±0.83
33.64±0.88
CLS-ER
25.06±0.81
36.34±0.59
39.69±0.66
28.54±0.87
28.63±0.68
39.52±0.91"
EMPIRICAL EVALUATION,0.21103896103896103,Table 3: Comparison with prior works on GCIL-CIFAR-100 dataset.
EMPIRICAL EVALUATION,0.21266233766233766,"length, and the cross-task resemblance increase. For instance, for DER++, replaying a sample from
Task-1 when training on S-Tiny-ImageNet Task-10, the reference logit values which are used to
enforce the consistency are from a model representation state which has not considered how to dis-
tinguish the 20 classes in Task-1 from 80 additional classes which are visually and semantically
similar. It stands to reason that the optimal representation space and subsequently the decision
boundaries for the classes in Task-1 would drift considerably when required to distinguish between
80 additional classes as well. Therefore, the local information provided by the sub-optimal saved
logits in DER++ fails to provide the global context required for consolidating knowledge. CLS-ER,
on the other hand, extracts logits from the semantic memories which consolidate knowledge across
the tasks, and hence the working model receives more optimal feedback."
EMPIRICAL EVALUATION,0.21428571428571427,"Domain Incremental Learning (Domain-IL): refers to the CL scenario where the classes remain
the same in subsequent tasks but the input distribution changes. We consider R-MNIST where each
task contains digits rotated by a ﬁxed angle and P-MNIST which applies a ﬁxed random permutation
to the pixels for each task. Table 1 shows that CLS-ER provides generalization gains under both
settings, particularly for lower memory budget, and performs on par with DER++ on 5120 buffer
size. We attribute this to the consolidated soft targets from the semantic memories which provide
relational information about the classes from a global context compared to the local information in
DER++. This enables our method to maintain the similarity structure across sequences effectively."
EMPIRICAL EVALUATION,0.2159090909090909,"General Incremental Learning (GIL): Class-IL and Domain-IL fail to assimilate the challenges
in the real-world setting where the task boundaries are blurry, and classes can reappear and have
different distributions. The CL method has to consider the sample efﬁciency, challenge of imbal-
anced data, and efﬁcient knowledge transfer in addition to preventing catastrophic forgetting. We
consider two GIL settings: MNIST-360 (Buzzega et al., 2020a) exposes the model to both sharp
(changes in class) and smooth (rotation of digits) distribution shifts. This requires the CL method to
tackle the challenges of class-IL as well as domain-IL. The Generalized Class Incremental Learning
(GCIL; Mi et al. (2020)) is the closest to the real-world scenario as it utilizes probabilistic modeling
to sample the classes and data distributions in each task. The number of classes in each task is not
ﬁxed, the classes can overlap and the sample size for each class can vary."
EMPIRICAL EVALUATION,0.21753246753246752,"Table 2 shows that CLS-ER provides considerable performance gains on the challenging MNIST-
360, particularly with a low memory budget. Similarly, Table 3 demonstrates the effectiveness of
CLS-ER on GCIL-CIFAR-100 under both uniform and imbalanced class samples. Both of these
settings involve recurring classes in subsequent sequences which makes the transfer of knowledge
from previous occurrences important. The performance gap between CLS-ER and DER++ in the
recurring classes setting alludes to another shortcoming of saving logits from the previous state.
Consider the case where class c appears in sequence (Seq)-1 with 20 samples, and then subsequently
in Seq-5 with 200 samples. In the following sequences, DER++ uses exemplars from class c saved
in Seq-1 with sub-optimal logits from the model state which was attained with only 20 samples and
fails to take advantage of the better learned representations with additional data in Seq-5. CLS-ER,"
EMPIRICAL EVALUATION,0.21915584415584416,Published as a conference paper at ICLR 2022
EMPIRICAL EVALUATION,0.22077922077922077,"5
10
15
20
25
30
35
40
Perturbation ( x10
3) 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5"
EMPIRICAL EVALUATION,0.2224025974025974,Train Loss
EMPIRICAL EVALUATION,0.22402597402597402,"ER
DER++
CLS-ER"
EMPIRICAL EVALUATION,0.22564935064935066,"5
10
15
20
25
30
35
40
Perturbation ( x10
3) 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8"
EMPIRICAL EVALUATION,0.22727272727272727,Train Accuracy
EMPIRICAL EVALUATION,0.2288961038961039,"ER
DER++
CLS-ER"
EMPIRICAL EVALUATION,0.2305194805194805,"ER
DER++
CLS-ER
0.0 0.1 0.2 0.3 0.4"
EMPIRICAL EVALUATION,0.23214285714285715,Task Probability
EMPIRICAL EVALUATION,0.23376623376623376,"Task 1
Task 2
Task 3
Task 4
Task 5"
EMPIRICAL EVALUATION,0.2353896103896104,"Figure 3: Model characteristics analyses of different methods trained on S-CIFAR-10 with 500
buffer size. The Left and middle ﬁgures show the training loss and accuracy under varying Gaussian
noise added to the weights of each layer of the model. CLS-ER is considerably less sensitive to per-
turbations, suggesting convergence to ﬂatter minima. The right ﬁgure shows the task probabilities.
CLS-ER effectively mitigates the bias to the recent tasks and provides a more uniform probability
of being predicted for the classes over the tasks even very early ones."
EMPIRICAL EVALUATION,0.237012987012987,"on the other hand, is able to take advantage of the additional samples and provide feedback from
the improved learned representations. Moreover, the considerable performance improvement in the
longtail setting shows that CLS-ER is more robust to class imbalance"
EMPIRICAL EVALUATION,0.23863636363636365,"Note that the MNIST-based settings can be considered under the online CL setting (see Section A.4)
as we only pass through the data once for each task and the performance of CLS-ER on these settings
demonstrates its potential as an efﬁcient method for online CL."
MODEL CHARACTERISTICS,0.24025974025974026,"6
MODEL CHARACTERISTICS"
MODEL CHARACTERISTICS,0.2418831168831169,"We analyze CLS-ER and provide some insights into the characteristics of the proposed approach
which enables it to learn effectively under challenging CL scenarios. In the subsequent analyses, we
compare CLS-ER with the baseline ER and DER++."
CONVERGENCE TO FLATTER MINIMA,0.2435064935064935,"6.1
CONVERGENCE TO FLATTER MINIMA"
CONVERGENCE TO FLATTER MINIMA,0.24512987012987014,"Due to the non-convexity of the loss landscape, there can be multiple solutions to the optimization
objective, however, the local geometry at the convergence point can affect the generalization of the
model. Solutions that reside in wide valleys instead of narrow crevices generalize better (Chaudhari
et al., 2019; Hochreiter & Schmidhuber, 1997; Keskar et al., 2016) as the predictions do not change
drastically with small perturbations. A CL model which converges to ﬂatter minima has more ﬂex-
ibility to explore the neighboring parameter space to optimize on the new task without drastically
increasing the loss on the previous tasks. Following the analysis in Zhang et al. (2018), we add inde-
pendent Gaussian noise of increasing strength to the parameters of the trained model and analyze the
change in accuracy and loss across the training samples. Figure 3 shows that CLS-ER is signiﬁcantly
less sensitive to perturbations compared to ER and DER++. CLS-ER also retains performance for a
longer period and its performance drops more smoothly. These results suggest that the fast and slow
adaptation of information in CLS-ER can guide the optimization to wider valleys."
TASK PROBABILITIES,0.24675324675324675,"6.2
TASK PROBABILITIES"
TASK PROBABILITIES,0.2483766233766234,"Because of the sequential nature of CL, an implicit bias is induced towards the current task (Wu
et al., 2019). A number of CL methods employ explicit techniques to reduce this bias (Hou et al.,
2019; Wu et al., 2019), however, they utilize the task boundaries which is counterproductive for
general incremental learning. We believe that the efﬁcient knowledge consolidation in CLS-ER
through the semantic memories can implicitly mitigate the bias towards recent tasks. We follow the
analysis performed in Buzzega et al. (2020b) to observe the probability of each task being predicted
at the end of the training. For each sample in the test dataset, we take the softmax output and then"
TASK PROBABILITIES,0.25,Published as a conference paper at ICLR 2022
TASK PROBABILITIES,0.25162337662337664,"0.00
0.25
0.50
0.75
1.00
Confidence 0.0 0.2 0.4 0.6 0.8 1.0"
TASK PROBABILITIES,0.2532467532467532,Accuracy ER
TASK PROBABILITIES,0.25487012987012986,ECE=32.24
TASK PROBABILITIES,0.2564935064935065,"0.00
0.25
0.50
0.75
1.00
Confidence DER++"
TASK PROBABILITIES,0.25811688311688313,ECE=16.57
TASK PROBABILITIES,0.2597402597402597,"0.00
0.25
0.50
0.75
1.00
Confidence"
TASK PROBABILITIES,0.26136363636363635,CLS-ER
TASK PROBABILITIES,0.262987012987013,ECE=6.41
TASK PROBABILITIES,0.26461038961038963,"Gap
Outputs"
TASK PROBABILITIES,0.2662337662337662,"Figure 4: Reliability plots for different methods on S-CIFAR-10 with 500 buffer size. CLS-ER
results in considerably better-calibrated models and hence more reliable predictions. For other buffer
sizes and S-TinyImageNet see Figures S5 and S6."
TASK PROBABILITIES,0.26785714285714285,"average the probabilities of the associated classes for each task across the dataset. We normalize
the values and report the probability of each task being predicted. Figure 3 (right plot) shows that
CLS-ER is able to maintain a more uniform prediction probability across all the tasks over a long
sequence. Figures S3 and S4 shows similar results for other buffer sizes and S-TinyImageNet."
MODEL CALIBRATION,0.2694805194805195,"6.3
MODEL CALIBRATION"
MODEL CALIBRATION,0.2711038961038961,"Model calibration refers to the accuracy with which the scores provided by the model reﬂect its
predictive uncertainty. The class probabilities predicted by DNNs are uncalibrated, often tending
towards over-conﬁdence which is detrimental to the reliability of the model’s prediction (Guo et al.,
2017). This is even more pronounced in CL where the models tend to be biassed towards recent
tasks. Following Guo et al. (2017), we provide the reliability diagrams (model accuracy as a function
of its prediction conﬁdence) and the Expected Calibration Error (ECE; a weighted average over the
absolute difference between accuracy and conﬁdence). Figure 4 shows the remarkable ability of
CLS-ER to provide well-calibrated models without the application of any calibration technique."
MODEL CALIBRATION,0.2727272727272727,"Note that these characteristics are complementary in nature: convergence to ﬂatter minima allows
our method to remain in the vicinity of optimal parameters for previous tasks when adapting to the
new task, this leads to more uniform performance across tasks which can improve the task probabil-
ities, and since the model is not too biased towards the current task, the model can provide reliable
prediction across the tasks which improve the calibration. Additional characteristics analyses on
different datasets and buffer sizes are provided in Appendix. We observe that our model’s behavior
is consistent across varying datasets and buffer sizes."
CONCLUSION,0.27435064935064934,"7
CONCLUSION"
CONCLUSION,0.275974025974026,"We proposed a novel dual memory experience replay method based on the complementary learning
systems theory in the brain. Our method maintains long-term and short-term semantic memories
which are utilized to effectively replay the neural activities of the episodic memories and align the
decision boundary of the working model for efﬁcient knowledge consolidation. We demonstrated
the effectiveness of our approach on benchmark datasets as well as more challenging general incre-
mental learning scenarios and achieved the new state-of-the-art in the vast majority of the continual
learning settings. We further showed that CLS-ER converges to ﬂatter minima, mitigates the bias
towards recent tasks, and provides a well-calibrated high-performance model. Our strong empirical
results motivate further study into mimicking the complementary learning system in the brain more
faithfully to enable optimal continual learning in DNNs."
CONCLUSION,0.2775974025974026,Published as a conference paper at ICLR 2022
REFERENCES,0.2792207792207792,REFERENCES
REFERENCES,0.28084415584415584,"Rahaf Aljundi, Min Lin, Baptiste Goujaud, and Yoshua Bengio. Gradient based sample selection
for online continual learning. In Advances in Neural Information Processing Systems, pp. 11816–
11825, 2019. 2, 14"
REFERENCES,0.2824675324675325,"Elahe Arani, Fahad Sarfraz, and Bahram Zonooz. Noise as a resource for learning in knowledge
distillation. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer
Vision, pp. 3129–3138, 2021. 5"
REFERENCES,0.2840909090909091,"Ari S Benjamin, David Rolnick, and Konrad Kording. Measuring and regularizing networks in
function space. arXiv preprint arXiv:1805.08289, 2018. 2"
REFERENCES,0.2857142857142857,"Pietro Buzzega, Matteo Boschini, Angelo Porrello, Davide Abati, and Simone Calderara. Dark expe-
rience for general continual learning: a strong, simple baseline. arXiv preprint arXiv:2004.07211,
2020a. 5, 6, 7, 13, 14, 17, 20"
REFERENCES,0.28733766233766234,"Pietro Buzzega, Matteo Boschini, Angelo Porrello, and Simone Calderara. Rethinking experience
replay: a bag of tricks for continual learning. arXiv preprint arXiv:2010.05595, 2020b. 8"
REFERENCES,0.288961038961039,"Pratik Chaudhari, Anna Choromanska, Stefano Soatto, Yann LeCun, Carlo Baldassi, Christian
Borgs, Jennifer Chayes, Levent Sagun, and Riccardo Zecchina. Entropy-sgd: Biasing gradient
descent into wide valleys. Journal of Statistical Mechanics: Theory and Experiment, 2019(12):
124018, 2019. 8"
REFERENCES,0.2905844155844156,"Arslan Chaudhry, Marc’Aurelio Ranzato, Marcus Rohrbach, and Mohamed Elhoseiny. Efﬁcient
lifelong learning with a-gem. arXiv preprint arXiv:1812.00420, 2018. 1"
REFERENCES,0.2922077922077922,"Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales Leonardis, Gregory
Slabaugh, and Tinne Tuytelaars. A continual learning survey: Defying forgetting in classiﬁcation
tasks. arXiv preprint arXiv:1909.08383, 2019. 13"
REFERENCES,0.29383116883116883,"Mehrdad Farajtabar, Navid Azizan, Alex Mott, and Ang Li. Orthogonal gradient descent for contin-
ual learning. In International Conference on Artiﬁcial Intelligence and Statistics, pp. 3762–3773.
PMLR, 2020. 1"
REFERENCES,0.29545454545454547,"Sebastian Farquhar and Yarin Gal. Towards robust evaluations of continual learning. arXiv preprint
arXiv:1805.09733, 2018. 1, 6, 13, 14"
REFERENCES,0.29707792207792205,"Robert M French. Catastrophic forgetting in connectionist networks. Trends in cognitive sciences,
3(4):128–135, 1999. 2"
REFERENCES,0.2987012987012987,"Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger.
On calibration of modern neural
networks. In International Conference on Machine Learning, pp. 1321–1330. PMLR, 2017. 9"
REFERENCES,0.3003246753246753,"Demis Hassabis,
Dharshan Kumaran,
Christopher Summerﬁeld,
and Matthew Botvinick.
Neuroscience-inspired artiﬁcial intelligence. Neuron, 95(2):245–258, 2017. 1"
REFERENCES,0.30194805194805197,"Tyler L Hayes, Giri P Krishnan, Maxim Bazhenov, Hava T Siegelmann, Terrence J Sejnowski,
and Christopher Kanan. Replay in deep learning: Current approaches and missing biological
elements. arXiv preprint arXiv:2104.04132, 2021. 1, 3"
REFERENCES,0.30357142857142855,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. corr abs/1512.03385 (2015), 2015. 5"
REFERENCES,0.3051948051948052,"Sepp Hochreiter and Jürgen Schmidhuber. Flat minima. Neural computation, 9(1):1–42, 1997. 8"
REFERENCES,0.3068181818181818,"Saihui Hou, Xinyu Pan, Chen Change Loy, Zilei Wang, and Dahua Lin. Learning a uniﬁed classiﬁer
incrementally via rebalancing. In Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition, pp. 831–839, 2019. 8"
REFERENCES,0.30844155844155846,"David Isele and Akansel Cosgun. Selective experience replay for lifelong learning. In Proceedings
of the AAAI Conference on Artiﬁcial Intelligence, volume 32, 2018. 4"
REFERENCES,0.31006493506493504,Published as a conference paper at ICLR 2022
REFERENCES,0.3116883116883117,"Nitin Kamra, Umang Gupta, and Yan Liu. Deep generative dual memory network for continual
learning. arXiv preprint arXiv:1710.10368, 2017. 2"
REFERENCES,0.3133116883116883,"Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak Pe-
ter Tang. On large-batch training for deep learning: Generalization gap and sharp minima. arXiv
preprint arXiv:1609.04836, 2016. 8"
REFERENCES,0.31493506493506496,"J Kirkpatrick, R Pascanu, N Rabinowitz, J Veness, G Desjardins, AA Rusu, K Milan, J Quan, T Ra-
malho, A Grabska-Barwinska, et al. Overcoming catastrophic forgetting in neural networks.(dec.
arXiv preprint cs.LG/1612.00796, 2016. 13"
REFERENCES,0.31655844155844154,"James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A
Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcom-
ing catastrophic forgetting in neural networks. Proceedings of the national academy of sciences,
114(13):3521–3526, 2017. 1"
REFERENCES,0.3181818181818182,"Giri P Krishnan, Timothy Tadros, Ramyaa Ramyaa, and Maxim Bazhenov. Biologically inspired
sleep algorithm for artiﬁcial neural networks. arXiv preprint arXiv:1908.02240, 2019. 2, 3"
REFERENCES,0.3198051948051948,Alex Krizhevsky et al. Learning multiple layers of features from tiny images. 2009. 13
REFERENCES,0.32142857142857145,"Dharshan Kumaran, Demis Hassabis, and James L McClelland. What learning systems do intelligent
agents need? complementary learning systems theory updated. Trends in cognitive sciences, 20
(7):512–534, 2016. 1"
REFERENCES,0.32305194805194803,"Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998. 13"
REFERENCES,0.3246753246753247,"David Lopez-Paz and Marc’Aurelio Ranzato. Gradient episodic memory for continual learning. In
Advances in neural information processing systems, pp. 6467–6476, 2017. 1, 2, 13"
REFERENCES,0.3262987012987013,"Wolfgang Maass. Noise as a resource for computation and learning in networks of spiking neurons.
Proceedings of the IEEE, 102(5):860–880, 2014. 5"
REFERENCES,0.32792207792207795,"Zheda Mai, Ruiwen Li, Jihwan Jeong, David Quispe, Hyunwoo Kim, and Scott Sanner. Online
continual learning in image classiﬁcation: An empirical survey. Neurocomputing, 469:28–51,
2022. 14"
REFERENCES,0.32954545454545453,"Michael McCloskey and Neal J Cohen. Catastrophic interference in connectionist networks: The
sequential learning problem. In Psychology of learning and motivation, volume 24, pp. 109–165.
Elsevier, 1989. 1"
REFERENCES,0.33116883116883117,"Fei Mi, Lingjing Kong, Tao Lin, Kaicheng Yu, and Boi Faltings. Generalized class incremental
learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recogni-
tion Workshops, pp. 240–241, 2020. 6, 7, 13, 20"
REFERENCES,0.3327922077922078,"German I Parisi, Ronald Kemker, Jose L Part, Christopher Kanan, and Stefan Wermter. Continual
lifelong learning with neural networks: A review. Neural Networks, 113:54–71, 2019. 1, 2"
REFERENCES,0.3344155844155844,"Hadi Pouransari and Saman Ghili. Tiny imagenet visual recognition challenge. CS231N course,
Stanford Univ., Stanford, CA, USA, 2015. 13"
REFERENCES,0.336038961038961,"Sylvestre-Alvise Rebufﬁ, Alexander Kolesnikov, Georg Sperl, and Christoph H Lampert. icarl:
Incremental classiﬁer and representation learning. In Proceedings of the IEEE conference on
Computer Vision and Pattern Recognition, pp. 2001–2010, 2017. 2"
REFERENCES,0.33766233766233766,"Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina Rish, Yuhai Tu, and Gerald
Tesauro. Learning to learn without forgetting by maximizing transfer and minimizing interfer-
ence. arXiv preprint arXiv:1810.11910, 2018. 2"
REFERENCES,0.3392857142857143,"Hippolyt Ritter, Aleksandar Botev, and David Barber. Online structured laplace approximations for
overcoming catastrophic forgetting. In Advances in Neural Information Processing Systems, pp.
3738–3748, 2018. 1"
REFERENCES,0.3409090909090909,Published as a conference paper at ICLR 2022
REFERENCES,0.3425324675324675,"Anthony Robins. Catastrophic forgetting in neural networks: the role of rehearsal mechanisms.
In Proceedings 1993 The First New Zealand International Two-Stream Conference on Artiﬁcial
Neural Networks and Expert Systems, pp. 65–68. IEEE, 1993. 2"
REFERENCES,0.34415584415584416,"Mohammad Rostami, Soheil Kolouri, and Praveen K Pilly. Complementary learning for overcoming
catastrophic forgetting using experience replay. arXiv preprint arXiv:1903.04566, 2019. 2"
REFERENCES,0.3457792207792208,"Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray
Kavukcuoglu, Razvan Pascanu, and Raia Hadsell. Progressive neural networks. arXiv preprint
arXiv:1606.04671, 2016. 1"
REFERENCES,0.3474025974025974,"Fahad Sarfraz, Elahe Arani, and Bahram Zonooz. Knowledge distillation beyond model compres-
sion. In 2020 25th International Conference on Pattern Recognition (ICPR), pp. 6136–6143.
IEEE, 2021. 2"
REFERENCES,0.349025974025974,"Dongsub Shim, Zheda Mai, Jihwan Jeong, Scott Sanner, Hyunwoo Kim, and Jongseong Jang.
Online class-incremental continual learning with adversarial shapley value. arXiv e-prints, pp.
arXiv–2009, 2020. 13"
REFERENCES,0.35064935064935066,"Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consis-
tency targets improve semi-supervised deep learning results. arXiv preprint arXiv:1703.01780,
2017. 3, 5"
REFERENCES,0.3522727272727273,"Gido M van de Ven and Andreas S Tolias. Three scenarios for continual learning. arXiv preprint
arXiv:1904.07734, 2019. 6, 13"
REFERENCES,0.3538961038961039,"Jeffrey S Vitter. Random sampling with a reservoir. ACM Transactions on Mathematical Software
(TOMS), 11(1):37–57, 1985. 4"
REFERENCES,0.3555194805194805,"Yue Wu, Yinpeng Chen, Lijuan Wang, Yuancheng Ye, Zicheng Liu, Yandong Guo, and Yun Fu.
Large scale incremental learning. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, pp. 374–382, 2019. 8"
REFERENCES,0.35714285714285715,"Jaehong Yoon, Eunho Yang, Jeongtae Lee, and Sung Ju Hwang. Lifelong learning with dynamically
expandable networks. arXiv preprint arXiv:1708.01547, 2017. 1"
REFERENCES,0.3587662337662338,"Friedemann Zenke, Ben Poole, and Surya Ganguli. Continual learning through synaptic intelligence.
Proceedings of machine learning research, 70:3987, 2017. 1, 13"
REFERENCES,0.36038961038961037,"Ying Zhang, Tao Xiang, Timothy M Hospedales, and Huchuan Lu.
Deep mutual learning.
In
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4320–
4328, 2018. 8"
REFERENCES,0.362012987012987,Published as a conference paper at ICLR 2022
REFERENCES,0.36363636363636365,"A
CONTINUAL LEARNING SETTINGS"
REFERENCES,0.3652597402597403,"There are a plethora of evaluation protocols in the CL literature, each of which biases the evaluation
towards a certain approach (Farquhar & Gal, 2018; Mi et al., 2020; Shim et al., 2020; van de Ven
& Tolias, 2019). It is therefore of utmost importance to conduct an extensive and robust evaluation
to gauge the versatility of the method. We believe that adhering to the key desiderata as suggested
in Farquhar & Gal (2018) would help the CL community immensely in moving towards a robust
evaluation of methods. An experimental protocol that trains the method on a long sequence of tasks
where the boundaries between the tasks are not distinct and the tasks themselves are not disjoint
and the method does not make sure of task boundaries during training or testing can be considered
as adhering to all ﬁve desiderata. Our work focuses on the aforementioned setting which can be
considered as General Incremental Learning (GIL) setting. Here, we provide a broad categorization
of these evaluation protocols which test different aspects of CL."
REFERENCES,0.36688311688311687,"A.1
CLASS INCREMENTAL LEARNING (CLASS-IL)"
REFERENCES,0.3685064935064935,"Class-IL refers to the CL scenario where new classes are added with each subsequent task and the
agent must learn to distinguish not only amongst the classes within the current task but also across
previous tasks. Class-IL measures how well the method can learn general representations, accumu-
late, consolidate, and transfer the acquired knowledge to learn efﬁcient representations and decision
boundaries for all the classes seen so far. Following Buzzega et al. (2020a); De Lange et al. (2019);
Zenke et al. (2017), we consider the common benchmark datasets MNIST (LeCun et al., 1998) (S-
MNIST), CIFAR-10 (Krizhevsky et al., 2009) (S-CIFAR-10) and Tiny-ImageNet (Pouransari &
Ghili, 2015) (S-Tiny-ImageNet) which are split into 5, 5, and 10 tasks each including 2, 2, and 20
classes respectively. These represent Class-IL settings of increasing dataset complexity as well as
longer sequences. While it is an important and challenging benchmark, it assumes that each subse-
quent task will have the same number of disjoint classes and have uniform samples for each class
which is not representative of real-world scenarios. We do not consider the related Task Increment
Learning (Task-IL) setting as it assumes the availability of task labels at both training and inference
which cannot truly be considered as a CL task (Farquhar & Gal, 2018)."
REFERENCES,0.37012987012987014,"A.2
DOMAIN INCREMENTAL LEARNING (DOMAIN-IL)"
REFERENCES,0.3717532467532468,"Domain-IL refers to the CL scenario where the classes remain the same in each subsequent task
but the input distribution changes. We consider Rotated-MNIST (Lopez-Paz & Ranzato, 2017)
(R-MNIST) where each task contains digits rotated by a ﬁxed angle between 0 and 180 degrees and
Permuted-MNIST (Kirkpatrick et al., 2016) (P-MNIST) which applies a ﬁxed random permutation
to the pixels for each task. Though we provide the results for Permuted MNIST for completion, we
share the opinion by Farquhar & Gal (2018) that it should not be considered as a benchmark dataset
as it violates the cross-task resemblance desiderata and deviates from the goal of continual learning."
REFERENCES,0.37337662337662336,"A.3
GENERAL INCREMENTAL LEARNING (GIL)"
REFERENCES,0.375,"The aforementioned CL scenarios fail to assimilate the challenges in the real world, setting where
the task boundaries are blurry and the learning agent must rather learn from a continuous stream of
data where classes can reappear and have different data distributions. The CL method must deal with
the issues of sample efﬁciency, imbalanced classes, and efﬁcient transfer of knowledge in addition
to preventing catastrophic forgetting. To test the efﬁcacy of our method in this challenging setting,
we consider two GIL evaluation protocols. MNIST-360 (Buzzega et al., 2020a) models a stream
of data which presents batches of two consecutive MNIST images with each sample rotated at an
increasing angle and the sequence is repeated three times. This exposes the model to both a sharp
distribution shift when the class changes and a smooth rotational distribution shift. However, the
number of classes in each task and the samples are uniform. The Generalized Class Incremental
Learning (GCIL) (Mi et al., 2020) utilizes probabilistic modeling to sample the classes and data
distributions in each task. Hence, the number of classes in each task is not ﬁxed, the classes can
overlap and the sample size for each class can vary. Following Mi et al. (2020), we use GCIL
on CIFAR-100 (Krizhevsky et al., 2009) dataset (GCIL-CIFAR-100), set the number of samples"
REFERENCES,0.37662337662337664,Published as a conference paper at ICLR 2022
REFERENCES,0.3782467532467532,"and maximum number of classes per task to 1000 and 50 respectively, number of tasks to 20, and
evaluate on both uniform and longtail (imbalanced) sample distribution."
REFERENCES,0.37987012987012986,"A.4
ONLINE CONTINUAL LEARNING"
REFERENCES,0.3814935064935065,"Online continual learning refers to the challenging scenario where a stream of samples is only seen
once and is non-iid (Mai et al., 2022; Aljundi et al., 2019). The common approach in the literature
is to use the single-epoch protocol where the network is trained on each task in the sequence for
only one epoch and there are no additional passages over data. As we aim to position CLS-ER as a
general incremental learning method, we are also interested in the online continual learning setting.
However, similar to Buzzega et al. (2020a), we also believe that the dataset complexity needs to be
considered when setting the number of epochs to disentangle the effect of catastrophic forgetting
from underﬁtting and share their suggestion that future CL works should strive for realism by de-
signing experimental settings which are in line with the guidelines of General Continual Learning
(Farquhar & Gal, 2018) which is the goal of our study rather than adopting the single-epoch proto-
col. For the MNIST-based settings, we use only one epoch per task as it is sufﬁcient for the SGD
baseline to learn the single task well. And for the more complex settings, we increase the number
of epochs: 50 epochs for Sequential CIFAR-10 and Sequential Tiny-ImageNet and 100 epochs for
GCIL-CIFAR-100."
REFERENCES,0.38311688311688313,"We would also like to emphasize that the experiments on MNIST based settings (S-MNIST, R-
MNIST, P-MNIST, and MNIST-360) can be considered as online continual learning settings as we
only train the network for 1 epoch, and thereby the model only sees the data for each task once. CLS-
ER’s performance in these settings demonstrates its potential for the challenging online continual
learning setting."
REFERENCES,0.3847402597402597,"B
RESERVOIR SAMPLING"
REFERENCES,0.38636363636363635,"Here, we provide the algorithm for the Reservoir Sampling for maintaining a ﬁxed-size memory
buffer. Reservoir sampling takes in a data stream of unknown length and assigns equal probability to
each sample for being represented in the memory buffer (M) with a ﬁxed budget size (B). Sampling
and replacement are done at random and no priority is assigned to the samples being added or
replaced from the memory buffer."
REFERENCES,0.387987012987013,Algorithm 2 Reservoir Sampling Algorithm
REFERENCES,0.38961038961038963,"Input: Memory Buffer M, Memory Budget B, Number of seen examples N, Selected example
(x, y)
1: if B > N then
▷Memory is not full
2:
M[N] ←−(x, y)
3: else
▷Select a sample to remove
4:
ν = randomInteger(min = 0, max = N)
5:
if ν < B then
6:
M[ν] ←−(x, y)
return M"
REFERENCES,0.3912337662337662,"C
ADDITIONAL RESULTS"
REFERENCES,0.39285714285714285,"In this section, we provide additional experimental results and analysis of the behavior of the model."
REFERENCES,0.3944805194805195,"C.1
CLS-ER COMPONENTS PERFORMANCE"
REFERENCES,0.3961038961038961,"CLS-ER involves the interplay between the working model and the two semantic memories: the
plastic and stable models. While we use the stable model for ﬁnal inference, here we provide the
performance of each of these individual components to provide further insights into the workings of
our method. Table S1 shows the corresponding performance of the working model and plastic model
for each of our experimental settings. We can see that the stable model can effectively consolidate"
REFERENCES,0.3977272727272727,Published as a conference paper at ICLR 2022
REFERENCES,0.39935064935064934,"Dataset
Buffer
Stable Model
Working Model
Plastic Model"
REFERENCES,0.400974025974026,"S-MNIST
200
89.54±0.21
89.32±0.23
89.52±0.21
500
92.05±0.30
91.61±0.47
92.04±0.33
5120
95.73±0.10
95.65±0.15
95.73±0.12"
REFERENCES,0.4025974025974026,"S-CIFAR-10
200
66.19±0.75
50.09±1.48
62.68±1.94
500
75.22±0.71
63.09±1.12
71.32±0.89
5120
86.78±0.17
85.00±0.33
86.77±0.17"
REFERENCES,0.4042207792207792,"S-Tiny-ImageNet
200
23.47±0.80
9.97±0.18
17.19±0.71
500
31.03±0.56
15.35±0.34
27.16±0.43
5120
46.74±0.31
41.39±0.39
47.10±0.42"
REFERENCES,0.40584415584415584,"R-MNIST
200
92.26±0.18
89.37±0.47
89.99±0.43
500
94.06±0.07
93.24±0.14
93.52±0.09
5120
94.25±0.06
94.28±0.08
94.37±0.06"
REFERENCES,0.4074675324675325,"P-MNIST
200
84.63±0.40
84.33±0.45
84.54±0.41
500
88.30±0.14
88.12±0.16
88.25±0.14
5120
92.03±0.05
91.96±0.06
92.02±0.05"
REFERENCES,0.4090909090909091,"MNIST-360
200
66.37±0.83
55.59±1.74
60.60±1.41
500
75.70±0.41
72.70±0.80
75.03±0.37
1000
79.54±0.34
78.39±0.69
79.16±0.42"
REFERENCES,0.4107142857142857,"GCIL-CIFAR-100 (Uniform)
200
33.15±2.80
31.74±2.72
32.70±2.78
500
37.01±1.67
35.89±1.69
36.18±1.68
1000
41.09±1.58
40.44±1.80
40.70±1.66"
REFERENCES,0.41233766233766234,"GCIL-CIFAR-100 (Longtail)
200
29.57±3.80
28.19±3.90
29.12±3.89
500
33.26±3.66
32.22±3.79
32.95±3.70
1000
39.21±3.46
38.51±3.55
38.84±3.52"
REFERENCES,0.413961038961039,Table S1: CLS-ER components performance analysis for each of the experimental setting.
REFERENCES,0.4155844155844156,"knowledge across the tasks and therefore provide the highest mean performance for the vast majority
of the settings. Figures S1 and S2 further shows how the task-wise performance (on test set) of each
of the component varies as subsequent tasks are learned. The stable model retains the performance
on previous tasks while the plastic model adapts better to the recent task. Both these models provide
feedback to the working model which in turn improves the plastic and stable model."
REFERENCES,0.4172077922077922,"C.2
TASK PROBABILITIES"
REFERENCES,0.41883116883116883,"To test the effectiveness of our method in mitigating the bias towards recent tasks, we provide the
task probabilities of the models trained with different buffer sizes on S-CIFAR-10 and S-Tiny-
ImageNet. Figures S3 and S4 show that CLS-ER consistently achieves more uniform task prob-
abilities compared to ER and DER++ and effectively mitigates the bias towards the last task."
REFERENCES,0.42045454545454547,"C.3
MODEL CALIBRATION"
REFERENCES,0.42207792207792205,"To further test the consistency of CLS-ER in providing well-calibrated models and the impact of the
buffer size, we evaluate the calibration of models trained with different buffer sizes on S-CIFAR-10
and S-Tiny-ImageNet. Figures S5 and S6 show that CLS-ER consistently provides better calibrated
models compared to ER and DER++. Remarkably, for both the datasets, on lower buffer sizes, the
difference in Expected Calibration Error (ECE) is considerable. This demonstrates the capability of
CLS-ER to train high-performance and reliable models under challenging conditions."
REFERENCES,0.4237012987012987,"C.4
EFFECT OF HYPERPARAMETERS"
REFERENCES,0.4253246753246753,"The interaction between the three components of CLS-ER is complementary. Table S3 shows how
the performance of each component is affected under different hyperparameter settings. We can
draw the following conclusions from the results. The performance improvement in the plastic and
stable model is reﬂected in the working model and the best performance is seen in cases where both
the semantic memories are performing well (albeit the focus on tasks is different). This highlights"
REFERENCES,0.42694805194805197,Published as a conference paper at ICLR 2022
REFERENCES,0.42857142857142855,After Task 1
REFERENCES,0.4301948051948052,After Task 2
REFERENCES,0.4318181818181818,After Task 3
REFERENCES,0.43344155844155846,After Task 4
REFERENCES,0.43506493506493504,After Task 5
REFERENCES,0.4366883116883117,Buffer 200
REFERENCES,0.4383116883116883,"98.65
0.0
0.0
0.0
0.0"
REFERENCES,0.43993506493506496,"88.95
89.5
0.0
0.0
0.0"
REFERENCES,0.44155844155844154,"78.2
53.45
89.05
0.0
0.0"
REFERENCES,0.4431818181818182,"81.25
42.4
76.3
87.5
0.0"
REFERENCES,0.4448051948051948,"69.2
41.5
76.8
83.3
41.15"
REFERENCES,0.44642857142857145,Stable Model
REFERENCES,0.44805194805194803,"98.35
0.0
0.0
0.0
0.0"
REFERENCES,0.4496753246753247,"67.4
92.65
0.0
0.0
0.0"
REFERENCES,0.4512987012987013,"67.4
22.95
95.65
0.0
0.0"
REFERENCES,0.45292207792207795,"59.9
15.35
31.8
99.1
0.0"
REFERENCES,0.45454545454545453,"20.55
15.9
45.15
63.55
98.1"
REFERENCES,0.45616883116883117,Working Model
REFERENCES,0.4577922077922078,"98.85
0.0
0.0
0.0
0.0"
REFERENCES,0.4594155844155844,"75.8
94.15
0.0
0.0
0.0"
REFERENCES,0.461038961038961,"71.0
29.3
95.55
0.0
0.0"
REFERENCES,0.46266233766233766,"72.2
27.95
54.9
97.05
0.0"
REFERENCES,0.4642857142857143,"59.9
34.05
73.05
80.6
74.75"
REFERENCES,0.4659090909090909,Plastic Model
REFERENCES,0.4675324675324675,After Task 1
REFERENCES,0.46915584415584416,After Task 2
REFERENCES,0.4707792207792208,After Task 3
REFERENCES,0.4724025974025974,After Task 4
REFERENCES,0.474025974025974,After Task 5
REFERENCES,0.47564935064935066,Buffer 500
REFERENCES,0.4772727272727273,"98.7
0.0
0.0
0.0
0.0"
REFERENCES,0.4788961038961039,"93.05
88.55
0.0
0.0
0.0"
REFERENCES,0.4805194805194805,"87.5
74.6
78.3
0.0
0.0"
REFERENCES,0.48214285714285715,"88.8
73.4
74.25
46.05
0.0"
REFERENCES,0.4837662337662338,"77.5
55.7
76.1
84.3
78.55"
REFERENCES,0.48538961038961037,"98.6
0.0
0.0
0.0
0.0"
REFERENCES,0.487012987012987,"75.55
90.95
0.0
0.0
0.0"
REFERENCES,0.48863636363636365,"80.45
31.5
96.05
0.0
0.0"
REFERENCES,0.4902597402597403,"79.8
37.4
48.35
98.25
0.0"
REFERENCES,0.49188311688311687,"51.1
40.05
58.05
72.65
97.75"
REFERENCES,0.4935064935064935,"98.85
0.0
0.0
0.0
0.0"
REFERENCES,0.49512987012987014,"84.25
92.55
0.0
0.0
0.0"
REFERENCES,0.4967532467532468,"84.1
55.25
92.65
0.0
0.0"
REFERENCES,0.49837662337662336,"86.05
66.9
67.9
82.9
0.0"
REFERENCES,0.5,"68.3
50.7
70.25
75.8
94.2"
REFERENCES,0.5016233766233766,Task 1
REFERENCES,0.5032467532467533,Task 2
REFERENCES,0.5048701298701299,Task 3
REFERENCES,0.5064935064935064,Task 4
REFERENCES,0.5081168831168831,Task 5
REFERENCES,0.5097402597402597,After Task 1
REFERENCES,0.5113636363636364,After Task 2
REFERENCES,0.512987012987013,After Task 3
REFERENCES,0.5146103896103896,After Task 4
REFERENCES,0.5162337662337663,After Task 5
REFERENCES,0.5178571428571429,Buffer 5120
REFERENCES,0.5194805194805194,"98.8
0.0
0.0
0.0
0.0"
REFERENCES,0.5211038961038961,"95.9
91.95
0.0
0.0
0.0"
REFERENCES,0.5227272727272727,"96.1
78.45
91.15
0.0
0.0"
REFERENCES,0.5243506493506493,"94.9
75.6
85.7
93.7
0.0"
REFERENCES,0.525974025974026,"91.0
74.5
86.85
91.2
82.7"
REFERENCES,0.5275974025974026,Task 1
REFERENCES,0.5292207792207793,Task 2
REFERENCES,0.5308441558441559,Task 3
REFERENCES,0.5324675324675324,Task 4
REFERENCES,0.5340909090909091,Task 5
REFERENCES,0.5357142857142857,"98.7
0.0
0.0
0.0
0.0"
REFERENCES,0.5373376623376623,"93.25
90.85
0.0
0.0
0.0"
REFERENCES,0.538961038961039,"93.0
74.65
90.2
0.0
0.0"
REFERENCES,0.5405844155844156,"92.65
67.85
82.5
97.2
0.0"
REFERENCES,0.5422077922077922,"83.4
69.2
84.05
91.45
97.0"
REFERENCES,0.5438311688311688,Task 1
REFERENCES,0.5454545454545454,Task 2
REFERENCES,0.547077922077922,Task 3
REFERENCES,0.5487012987012987,Task 4
REFERENCES,0.5503246753246753,Task 5
REFERENCES,0.551948051948052,"98.75
0.0
0.0
0.0
0.0"
REFERENCES,0.5535714285714286,"95.95
92.0
0.0
0.0
0.0"
REFERENCES,0.5551948051948052,"96.05
78.85
91.2
0.0
0.0"
REFERENCES,0.5568181818181818,"94.85
75.45
85.75
93.65
0.0"
REFERENCES,0.5584415584415584,"91.0
74.35
86.75
91.2
83.0"
REFERENCES,0.560064935064935,"Figure S1: Test set task-wise performance for the individual models on S-CIFAR-10 with different
buffer sizes. The task-wise performance (x-axis) is evaluated at the end of training of each task
(y-axis) to evaluate how it is affected as training progresses."
REFERENCES,0.5616883116883117,"the crucial role of both memories in enabling CLS-ER to learn efﬁciently. For a ﬁxed rS value,
the ﬁnal performance of the stable model is affected considerably by the performance of the plastic
model. The method is not highly sensitive to the particular choice of hyperparameters as different
settings can attain similar performance. Because of the complementary nature of the components,
we can often ﬁx a set of parameters (e.g. λ, αS, αS and rS) and only ﬁnetune the remaining
parameters (e.g. r′
P ) which facilitates hyperparameter tuning signiﬁcantly."
REFERENCES,0.5633116883116883,"D
COMPARISON WITH A SINGLE SEMANTIC MEMORY"
REFERENCES,0.564935064935065,"CLS-ER employs two semantic memories as we aim to mimic the fast and slow learning mechanisms
in the hippocampus and neocortex respectively. Here we compare our method with a single semantic
memory (Mean-ER) and Table S2 shows that while it still performs admirably compared to the
other CL methods, the dual semantic memories in CLS-ER provides additional performance gains
especially on the complex datasets under the challenging lower memory buffer settings and has a
much lower variance. We attribute this to the failure of Mean-ER in maintaining the performance
on both the recent and earlier tasks together i.e there is an inherent trade-off as tuning the semantic
memory to adapt to the recent changes comes at the cost of performance on earlier tasks and vice
versa. CLS-ER efﬁciently tackles this trade-off by maintaining two specialized long-term and short-
term memories. The performance of Mean-ER, however, provides further evidence for the beneﬁts
of using consolidated information for memory replay."
REFERENCES,0.5665584415584416,"Note that for a fair comparison, we use the same hyperparameter search space as CLS-ER for ﬁnd-
ing the optimal parameters for Mean-ER and report the average and 1 std of 10 runs with different
initializations using the best parameters for each setting. Table S6 provides the chosen hyperparam-
eters. For inference, similar to CLS-ER, we use the EMA-weighted model (semantic memory) for
Mean-ER."
REFERENCES,0.5681818181818182,Published as a conference paper at ICLR 2022
REFERENCES,0.5698051948051948,After Task 1
REFERENCES,0.5714285714285714,After Task 2
REFERENCES,0.573051948051948,After Task 3
REFERENCES,0.5746753246753247,After Task 4
REFERENCES,0.5762987012987013,After Task 5
REFERENCES,0.577922077922078,After Task 6
REFERENCES,0.5795454545454546,After Task 7
REFERENCES,0.5811688311688312,After Task 8
REFERENCES,0.5827922077922078,After Task 9
REFERENCES,0.5844155844155844,After Task 10
REFERENCES,0.586038961038961,Buffer 200
REFERENCES,0.5876623376623377,"68.5
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.5892857142857143,"69.6
37.9
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.5909090909090909,"56.0
54.8
28.7
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.5925324675324676,"46.2
41.6
57.7
19.9
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.5941558441558441,"39.0
33.6
49.9
54.7
23.9
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.5957792207792207,"30.0
26.8
34.8
45.5
54.3
27.5
0.0
0.0
0.0
0.0"
REFERENCES,0.5974025974025974,"23.6
18.5
29.6
31.2
35.3
55.8
16.0
0.0
0.0
0.0"
REFERENCES,0.599025974025974,"19.5
12.9
21.1
20.8
21.7
41.7
55.1
27.6
0.0
0.0"
REFERENCES,0.6006493506493507,"16.8
9.6
18.4
18.3
11.8
22.4
39.5
51.4
20.8
0.0"
REFERENCES,0.6022727272727273,"12.0
9.0
14.1
15.7
8.0
13.9
26.2
34.9
46.9
19.0"
REFERENCES,0.6038961038961039,Stable Model
REFERENCES,0.6055194805194806,"76.1
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6071428571428571,"17.9
70.7
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6087662337662337,"11.6
10.4
76.7
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6103896103896104,"7.9
3.9
14.0
80.8
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.612012987012987,"5.5
2.2
5.1
11.2
77.8
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6136363636363636,"4.1
1.7
3.3
5.3
3.3
77.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6152597402597403,"2.5
0.7
3.0
2.3
2.2
4.6
79.1
0.0
0.0
0.0"
REFERENCES,0.6168831168831169,"2.2
0.9
1.8
2.4
2.6
2.7
5.8
77.2
0.0
0.0"
REFERENCES,0.6185064935064936,"2.1
0.9
1.4
2.6
1.9
1.5
1.2
4.1
71.6
0.0"
REFERENCES,0.6201298701298701,"1.8
0.5
2.4
1.0
1.5
1.4
0.6
3.0
3.4
80.5"
REFERENCES,0.6217532467532467,Working Model
REFERENCES,0.6233766233766234,"72.6
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.625,"49.7
64.9
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6266233766233766,"35.2
41.9
69.3
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6282467532467533,"26.6
21.7
48.8
70.7
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6298701298701299,"17.3
13.6
23.4
47.0
71.8
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6314935064935064,"12.0
8.2
12.5
18.3
28.9
72.6
0.0
0.0
0.0
0.0"
REFERENCES,0.6331168831168831,"9.0
4.4
10.9
11.7
9.4
36.2
73.6
0.0
0.0
0.0"
REFERENCES,0.6347402597402597,"9.5
4.0
7.7
8.5
5.5
14.3
42.9
68.5
0.0
0.0"
REFERENCES,0.6363636363636364,"8.6
3.5
6.5
7.9
4.8
6.6
16.9
33.2
64.6
0.0"
REFERENCES,0.637987012987013,"5.5
3.4
4.9
7.1
3.8
4.2
5.2
11.7
34.4
71.5"
REFERENCES,0.6396103896103896,Plastic Model
REFERENCES,0.6412337662337663,After Task 1
REFERENCES,0.6428571428571429,After Task 2
REFERENCES,0.6444805194805194,After Task 3
REFERENCES,0.6461038961038961,After Task 4
REFERENCES,0.6477272727272727,After Task 5
REFERENCES,0.6493506493506493,After Task 6
REFERENCES,0.650974025974026,After Task 7
REFERENCES,0.6525974025974026,After Task 8
REFERENCES,0.6542207792207793,After Task 9
REFERENCES,0.6558441558441559,After Task 10
REFERENCES,0.6574675324675324,Buffer 500
REFERENCES,0.6590909090909091,"69.7
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6607142857142857,"71.7
40.6
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6623376623376623,"61.1
55.5
40.8
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.663961038961039,"53.3
44.4
61.6
34.5
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6655844155844156,"46.9
37.4
54.7
59.4
23.4
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6672077922077922,"40.9
31.5
46.1
51.7
55.4
27.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6688311688311688,"36.5
25.0
33.5
40.4
45.1
55.5
25.4
0.0
0.0
0.0"
REFERENCES,0.6704545454545454,"30.3
21.4
27.5
30.7
33.9
46.1
56.2
31.2
0.0
0.0"
REFERENCES,0.672077922077922,"29.3
18.4
23.7
25.7
25.1
33.0
44.8
56.5
28.9
0.0"
REFERENCES,0.6737012987012987,"24.2
17.5
19.8
21.1
18.6
23.9
34.3
48.1
52.8
28.2"
REFERENCES,0.6753246753246753,"75.7
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.676948051948052,"35.7
71.4
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6785714285714286,"26.5
20.6
77.6
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6801948051948052,"23.1
13.9
30.5
79.6
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6818181818181818,"17.9
9.9
12.5
23.7
79.4
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6834415584415584,"15.1
8.6
7.2
12.7
13.4
78.2
0.0
0.0
0.0
0.0"
REFERENCES,0.685064935064935,"11.3
7.5
7.2
8.0
9.7
16.4
78.8
0.0
0.0
0.0"
REFERENCES,0.6866883116883117,"12.1
6.3
3.8
7.1
5.7
8.4
15.1
77.2
0.0
0.0"
REFERENCES,0.6883116883116883,"11.1
3.4
5.6
6.5
5.0
7.3
7.1
17.9
72.9
0.0"
REFERENCES,0.689935064935065,"8.5
4.8
4.9
5.5
3.7
5.4
4.8
13.1
13.3
79.9"
REFERENCES,0.6915584415584416,"74.4
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6931818181818182,"62.4
60.8
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6948051948051948,"49.5
44.5
69.4
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6964285714285714,"42.4
34.1
59.0
66.1
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.698051948051948,"35.4
24.7
40.9
53.5
67.1
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.6996753246753247,"28.4
20.2
25.0
35.2
49.0
68.5
0.0
0.0
0.0
0.0"
REFERENCES,0.7012987012987013,"25.7
16.7
18.4
24.9
29.7
51.0
67.1
0.0
0.0
0.0"
REFERENCES,0.702922077922078,"22.8
15.1
15.8
19.3
19.5
31.6
53.7
66.8
0.0
0.0"
REFERENCES,0.7045454545454546,"20.0
11.6
12.9
15.1
12.5
19.5
31.0
52.6
63.0
0.0"
REFERENCES,0.7061688311688312,"16.8
10.7
12.7
14.3
10.8
14.6
21.5
36.2
51.6
68.8"
REFERENCES,0.7077922077922078,Task 1
REFERENCES,0.7094155844155844,Task 2
REFERENCES,0.711038961038961,Task 3
REFERENCES,0.7126623376623377,Task 4
REFERENCES,0.7142857142857143,Task 5
REFERENCES,0.7159090909090909,Task 6
REFERENCES,0.7175324675324676,Task 7
REFERENCES,0.7191558441558441,Task 8
REFERENCES,0.7207792207792207,Task 9
REFERENCES,0.7224025974025974,Task 10
REFERENCES,0.724025974025974,After Task 1
REFERENCES,0.7256493506493507,After Task 2
REFERENCES,0.7272727272727273,After Task 3
REFERENCES,0.7288961038961039,After Task 4
REFERENCES,0.7305194805194806,After Task 5
REFERENCES,0.7321428571428571,After Task 6
REFERENCES,0.7337662337662337,After Task 7
REFERENCES,0.7353896103896104,After Task 8
REFERENCES,0.737012987012987,After Task 9
REFERENCES,0.7386363636363636,After Task 10
REFERENCES,0.7402597402597403,Buffer 5120
REFERENCES,0.7418831168831169,"76.6
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.7435064935064936,"76.5
47.2
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.7451298701298701,"73.3
60.4
42.6
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.7467532467532467,"69.7
57.5
63.3
41.1
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.7483766233766234,"65.6
54.5
64.9
62.0
31.8
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.75,"61.4
52.0
60.6
62.1
54.4
28.8
0.0
0.0
0.0
0.0"
REFERENCES,0.7516233766233766,"57.6
47.1
56.2
59.3
56.5
51.5
34.6
0.0
0.0
0.0"
REFERENCES,0.7532467532467533,"52.8
44.3
52.7
55.4
53.1
51.6
56.4
38.8
0.0
0.0"
REFERENCES,0.7548701298701299,"49.0
40.6
48.8
54.2
50.1
48.6
53.7
53.7
31.8
0.0"
REFERENCES,0.7564935064935064,"48.5
36.9
44.6
48.9
47.9
44.7
50.7
51.7
45.8
32.5"
REFERENCES,0.7581168831168831,Task 1
REFERENCES,0.7597402597402597,Task 2
REFERENCES,0.7613636363636364,Task 3
REFERENCES,0.762987012987013,Task 4
REFERENCES,0.7646103896103896,Task 5
REFERENCES,0.7662337662337663,Task 6
REFERENCES,0.7678571428571429,Task 7
REFERENCES,0.7694805194805194,Task 8
REFERENCES,0.7711038961038961,Task 9
REFERENCES,0.7727272727272727,Task 10
REFERENCES,0.7743506493506493,"78.1
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.775974025974026,"67.3
68.5
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.7775974025974026,"62.4
51.0
73.6
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.7792207792207793,"59.1
47.9
59.0
75.4
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.7808441558441559,"54.2
44.6
51.6
55.1
73.9
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.7824675324675324,"50.8
40.2
45.4
49.7
46.8
73.2
0.0
0.0
0.0
0.0"
REFERENCES,0.7840909090909091,"45.5
39.2
45.2
47.5
47.7
44.0
74.6
0.0
0.0
0.0"
REFERENCES,0.7857142857142857,"45.4
36.9
41.3
46.3
41.4
40.2
50.0
72.7
0.0
0.0"
REFERENCES,0.7873376623376623,"42.7
30.3
38.9
43.7
39.2
37.6
43.2
44.2
67.7
0.0"
REFERENCES,0.788961038961039,"35.0
29.2
36.0
39.0
38.0
35.2
36.9
37.0
37.1
77.9"
REFERENCES,0.7905844155844156,Task 1
REFERENCES,0.7922077922077922,Task 2
REFERENCES,0.7938311688311688,Task 3
REFERENCES,0.7954545454545454,Task 4
REFERENCES,0.797077922077922,Task 5
REFERENCES,0.7987012987012987,Task 6
REFERENCES,0.8003246753246753,Task 7
REFERENCES,0.801948051948052,Task 8
REFERENCES,0.8035714285714286,Task 9
REFERENCES,0.8051948051948052,Task 10
REFERENCES,0.8068181818181818,"76.9
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.8084415584415584,"76.3
47.6
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.810064935064935,"72.5
59.5
49.8
0.0
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.8116883116883117,"68.9
56.9
64.4
44.6
0.0
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.8133116883116883,"64.3
54.0
64.6
62.5
44.3
0.0
0.0
0.0
0.0
0.0"
REFERENCES,0.814935064935065,"59.7
50.8
58.0
62.1
57.8
39.9
0.0
0.0
0.0
0.0"
REFERENCES,0.8165584415584416,"56.7
46.6
55.1
58.5
57.2
54.0
40.6
0.0
0.0
0.0"
REFERENCES,0.8181818181818182,"51.8
43.9
52.4
54.5
52.9
51.8
57.3
41.4
0.0
0.0"
REFERENCES,0.8198051948051948,"48.9
40.1
48.3
53.9
49.4
48.7
54.0
54.0
34.6
0.0"
REFERENCES,0.8214285714285714,"47.5
36.4
44.1
48.5
47.2
44.4
50.5
51.3
47.1
40.8"
REFERENCES,0.823051948051948,"Figure S2: Test set task-wise performance for the individual models on S-Tiny-ImageNet with dif-
ferent buffer sizes. The task-wise performance (x-axis) is evaluated at the end of training of each
task (y-axis) to evaluate how it is affected as training progresses."
REFERENCES,0.8246753246753247,"ER
DER++
CLS-ER
0.0 0.1 0.2 0.3 0.4 0.5 0.6"
REFERENCES,0.8262987012987013,Task Probability
REFERENCES,0.827922077922078,Buffer 200
REFERENCES,0.8295454545454546,"ER
DER++
CLS-ER"
REFERENCES,0.8311688311688312,Buffer 500
REFERENCES,0.8327922077922078,"ER
DER++
CLS-ER"
REFERENCES,0.8344155844155844,Buffer 5120
REFERENCES,0.836038961038961,"Task 1
Task 2
Task 3
Task 4
Task 5"
REFERENCES,0.8376623376623377,Figure S3: Task probabilities for different methods on S-CIFAR-10 with varying memory budget.
REFERENCES,0.8392857142857143,"E
TRAINING AND IMPLEMENTATION DETAILS"
REFERENCES,0.8409090909090909,"For a fair comparison, we aim to keep the experimental settings close to the current state-of-the-
art DER++ (Buzzega et al., 2020a) as much as possible to disassociate the effect of the training"
REFERENCES,0.8425324675324676,Published as a conference paper at ICLR 2022
REFERENCES,0.8441558441558441,"ER
DER++
CLS-ER
0.0 0.2 0.4 0.6 0.8 1.0"
REFERENCES,0.8457792207792207,Task Probability
REFERENCES,0.8474025974025974,Buffer 200
REFERENCES,0.849025974025974,"ER
DER++
CLS-ER"
REFERENCES,0.8506493506493507,Buffer 500
REFERENCES,0.8522727272727273,"ER
DER++
CLS-ER"
REFERENCES,0.8538961038961039,Buffer 5120
REFERENCES,0.8555194805194806,"Task 1
Task 2
Task 3
Task 4
Task 5
Task 6
Task 7
Task 8
Task 9
Task 10"
REFERENCES,0.8571428571428571,"Figure S4: Task probabilities for different methods on S-Tiny-ImageNet with varying memory bud-
get. 0.0 0.2 0.4 0.6 0.8 1.0"
REFERENCES,0.8587662337662337,Buffer 200
REFERENCES,0.8603896103896104,Accuracy ER
REFERENCES,0.862012987012987,ECE=44.39 DER++
REFERENCES,0.8636363636363636,ECE=20.31
REFERENCES,0.8652597402597403,CLS-ER
REFERENCES,0.8668831168831169,ECE=6.85
REFERENCES,0.8685064935064936,"Gap
Outputs 0.0 0.2 0.4 0.6 0.8 1.0"
REFERENCES,0.8701298701298701,Buffer 500
REFERENCES,0.8717532467532467,Accuracy
REFERENCES,0.8733766233766234,"ECE=32.24
ECE=16.57
ECE=6.41"
REFERENCES,0.875,"Gap
Outputs"
REFERENCES,0.8766233766233766,"0.0
0.2
0.4
0.6
0.8
1.0
Confidence 0.0 0.2 0.4 0.6 0.8 1.0"
REFERENCES,0.8782467532467533,Buffer 5120
REFERENCES,0.8798701298701299,Accuracy
REFERENCES,0.8814935064935064,ECE=13.37
REFERENCES,0.8831168831168831,"0.0
0.2
0.4
0.6
0.8
1.0
Confidence"
REFERENCES,0.8847402597402597,ECE=8.49
REFERENCES,0.8863636363636364,"0.0
0.2
0.4
0.6
0.8
1.0
Confidence"
REFERENCES,0.887987012987013,ECE=6.73
REFERENCES,0.8896103896103896,"Gap
Outputs"
REFERENCES,0.8912337662337663,Figure S5: Reliability plots for the different methods on S-CIFAR-10 with varying memory budget.
REFERENCES,0.8928571428571429,"schedule. We use the same optimizer, the number of epochs, batch size, and memory batch size as
DER++. For S-Tiny-ImageNet, we reduce the number of epochs to 50 from 100 used by DER++
as our method can learn efﬁciently with fewer epochs, and quickly acquiring new knowledge is
preferred for CL. Similar to DER++, we ﬁnetune the memory batch size for S-MNIST and MNIST-
360. We select the hyperparameters for each of the experimental setting using a small validation set,"
REFERENCES,0.8944805194805194,Published as a conference paper at ICLR 2022 0.0 0.2 0.4 0.6 0.8 1.0
REFERENCES,0.8961038961038961,Buffer 200
REFERENCES,0.8977272727272727,Accuracy ER
REFERENCES,0.8993506493506493,ECE=74.54 DER++
REFERENCES,0.900974025974026,ECE=26.60
REFERENCES,0.9025974025974026,CLS-ER
REFERENCES,0.9042207792207793,ECE=5.27
REFERENCES,0.9058441558441559,"Gap
Outputs 0.0 0.2 0.4 0.6 0.8 1.0"
REFERENCES,0.9074675324675324,Buffer 500
REFERENCES,0.9090909090909091,Accuracy
REFERENCES,0.9107142857142857,"ECE=69.54
ECE=14.31
ECE=8.23"
REFERENCES,0.9123376623376623,"Gap
Outputs"
REFERENCES,0.913961038961039,"0.0
0.2
0.4
0.6
0.8
1.0
Confidence 0.0 0.2 0.4 0.6 0.8 1.0"
REFERENCES,0.9155844155844156,Buffer 5120
REFERENCES,0.9172077922077922,Accuracy
REFERENCES,0.9188311688311688,ECE=51.31
REFERENCES,0.9204545454545454,"0.0
0.2
0.4
0.6
0.8
1.0
Confidence"
REFERENCES,0.922077922077922,ECE=13.16
REFERENCES,0.9237012987012987,"0.0
0.2
0.4
0.6
0.8
1.0
Confidence"
REFERENCES,0.9253246753246753,ECE=12.34
REFERENCES,0.926948051948052,"Gap
Outputs"
REFERENCES,0.9285714285714286,"Figure S6: Reliability plots for the different methods on S-Tiny-ImageNet with varying memory
budget."
REFERENCES,0.9301948051948052,"Buffer
Method
Class-IL
Domain-IL
S-MNIST
S-CIFAR-10
S-Tiny-ImageNet
R-MNIST
P-MNIST"
REFERENCES,0.9318181818181818,"–
JOINT
95.57±0.24
92.20±0.15
59.99±0.19
95.76±0.04
94.33±0.17
SGD
19.60±0.04
19.62±0.05
7.92±0.26
67.66±8.53
40.70±2.33"
MEAN-ER,0.9334415584415584,"200
Mean-ER
88.32±0.65
61.88±2.43
17.68±1.65
92.10±1.07
83.28±0.68
CLS-ER
89.54±0.21
66.19±0.75
23.47±0.80
92.26±0.18
84.63±0.40"
MEAN-ER,0.935064935064935,"500
Mean-ER
91.79±0.23
70.40±1.21
24.97±0.80
92.78±0.44
87.73±0.39
CLS-ER
92.05±0.32
75.22±0.71
31.03±0.56
94.06±0.07
88.30±0.14"
MEAN-ER,0.9366883116883117,"5120
Mean-ER
95.57±0.18
84.84±2.0
45.69±0.58
94.25±0.51
91.90±0.11
CLS-ER
95.73±0.11
86.78±0.17
46.74±0.31
94.25±0.06
92.03±0.05"
MEAN-ER,0.9383116883116883,"Table S2: Comparison of CLS-ER with Mean-ER (single semantic memory) on Class-IL and
Domain-IL settings. We report the mean and 1 std of 10 runs with different initializations."
MEAN-ER,0.939935064935065,"αS, αP ∈(0.99, 0.999), rS, rP ∈(0, 1], λ ∈(0, 2]. Table S4 provides the hyperparameters used
for each of the experimental settings. Note that for the vast majority of datasets, we use uniform
settings (lr, epochs, batch size, memory batch size, and lambda) across the different buffer sizes and
requires only slight modiﬁcations in the other hyperparameters which shows that our method does
not require extensive ﬁnetuning for different memory budgets."
MEAN-ER,0.9415584415584416,Published as a conference paper at ICLR 2022
MEAN-ER,0.9431818181818182,"E.1
GCIL-CIFAR-100"
MEAN-ER,0.9448051948051948,"To test our method under challenging GIL settings that better simulate the challenges of CL in
the real world, we incorporate the GCIL setting from the code provided by Mi et al. (2020) with the
continual dataset template class in the mammoth framework. We set the number of phases (length of
task sequences) to 20, with the total number of samples in each phase set to 1000 and the maximum
number of classes in each phase set to 50. We evaluate on both uniform and longtail (imbalanced)
data distributions. Since GCIL involves the probabilistic sampling of the classes and their samples
in each phase, the random seed determines the complexity of the GCIL setting. Therefore, for
reproduciblility and to gauge the stability of the methods, we ﬁx the dataset seed to 1993 and report
the average and standard deviation of 10 differently initialized models trained on the same settings."
MEAN-ER,0.9464285714285714,"For each of our method, we use identical training scheme (lr=0.1, epochs=100, batch size=32 and
memory batch size=32). For DER++, as per the authors suggestion, we performed hyperparame-
ter search over α ∈[0.2, 0.3] and beta ∈[0.5, 1.0] with step size of 0.1. Table S5 provides the
parameters chosen for each of the method under the different settings."
MEAN-ER,0.948051948051948,"E.2
PERTURBATION ANALYSIS"
MEAN-ER,0.9496753246753247,"For the perturbation analysis, we used the code and checkpoints provided by Buzzega et al. (2020a)
for DER++ and ER. We would like to express our gratitude to the authors for their support and for
making the mammoth framework available for the research community which provides a framework
for a fair comparison of different CL methods under uniform experimental conditions."
MEAN-ER,0.9512987012987013,Published as a conference paper at ICLR 2022
MEAN-ER,0.952922077922078,"λλλ
rS
rS
rS
rP
rP
rP
Stable Model
Working Model
Plastic Model 0.1 0.1"
MEAN-ER,0.9545454545454546,"0.2
73.53±1.07
62.80±0.63
71.11±2.21
0.3
72.44±1.37
63.53±1.98
70.97±1.71
0.4
73.05±0.93
61.81±1.92
68.75±2.20
0.5
75.16±1.09
63.95±1.92
70.42±1.09
0.6
75.04±0.66
62.82±0.70
69.61±0.31
0.7
73.94±0.48
63.34±0.46
70.30±1.68
0.8
74.61±1.10
62.68±0.65
70.74±0.39
0.9
73.74±2.14
62.69±1.97
69.52±0.79
1.0
75.73±0.68
64.21±1.11
72.00±0.56 0.2"
MEAN-ER,0.9561688311688312,"0.3
70.26±1.79
61.63±1.03
69.31±1.82
0.4
71.80±1.17
62.64±0.18
70.64±1.22
0.5
70.69±2.13
61.76±0.64
69.65±1.92
0.6
72.45±0.68
63.87±0.85
71.29±0.72
0.7
71.47±1.98
61.12±1.90
70.22±2.24
0.8
72.16±0.56
62.71±0.57
70.83±0.64
0.9
72.09±0.59
63.33±1.01
71.20±0.87
1.0
72.05±1.35
63.74±1.75
71.01±1.28 0.3"
MEAN-ER,0.9577922077922078,"0.4
68.46±1.48
60.96±1.62
68.31±1.40
0.5
70.05±2.54
63.06±1.26
69.90±2.57
0.6
69.57±1.07
61.25±1.96
69.36±1.06
0.7
68.99±2.34
61.61±2.17
68.81±2.27
0.8
71.21±0.48
63.08±0.82
70.99±0.57
0.9
71.26±1.47
62.33±0.64
71.03±1.56
1
69.00±0.41
61.38±0.92
68.69±0.31 0.15 0.1"
MEAN-ER,0.9594155844155844,"0.2
70.19±1.97
61.39±2.06
69.81±1.60
0.3
73.72±0.83
62.07±0.84
70.18±0.09
0.4
71.60±2.30
61.11±2.00
69.15±1.08
0.5
74.18±0.37
63.32±0.98
71.08±2.04
0.6
74.90±0.40
62.35±2.31
71.58±0.79
0.7
74.52±1.10
62.59±2.64
70.90±2.30
0.8
75.27±1.21
62.00±1.98
71.27±1.64
0.9
74.61±0.91
63.47±1.60
70.49±0.95
1.0
76.03±0.64
63.63±1.01
71.42±1.11 0.2"
MEAN-ER,0.961038961038961,"0.3
72.59±1.44
61.81±1.03
72.02±1.30
0.4
71.30±3.42
63.15±0.51
70.92±2.83
0.5
69.89±1.95
60.60±0.95
68.87±2.56
0.6
72.34±0.89
62.18±1.31
71.15±0.94
0.7
72.70±1.11
62.50±1.18
71.49±1.21
0.8
72.42±1.50
61.85±0.83
71.04±1.68
0.9
71.18±0.71
61.81±1.29
70.09±0.54
1.0
73.52±0.65
64.19±0.86
72.56±0.52 0.3"
MEAN-ER,0.9626623376623377,"0.4
70.32±1.39
62.39±2.00
70.13±1.33
0.5
71.60±1.53
62.67±2.08
71.40±1.54
0.6
70.36±1.82
62.28±2.28
70.13±2.03
0.7
69.79±1.93
61.13±1.37
69.65±1.82
0.8
69.85±0.95
60.69±1.63
69.78±0.60
0.9
71.32±1.68
61.79±1.41
71.03±1.61
1.0
71.39±0.49
62.35±0.88
71.11±0.55"
MEAN-ER,0.9642857142857143,"Table S3: The effect of different hyperparameter settings on the individual components of CLS-ER
trained on S-CIFAR-10 with 500 buffer size. For all the experiments αS and αP are ﬁxed to 0.999
and the performance is averaged over 3 runs with different initialization."
MEAN-ER,0.9659090909090909,Published as a conference paper at ICLR 2022
MEAN-ER,0.9675324675324676,"Dataset
Buffer
lr
Epochs
Batch Size
Memory
Batch Size
λλλ
αS
αS
αS
αP
αP
αP
rS
rS
rS
rP
rP
rP"
MEAN-ER,0.9691558441558441,"S-MNIST
200
0.03
1
10
128
2.0
0.99
0.99
0.9
1.0
500
0.1
1
10
32
2.0
0.99
0.99
0.9
1.0
5120
0.1
1
10
32
2.0
0.99
0.99
0.8
1.0"
MEAN-ER,0.9707792207792207,"S-CIFAR-10
200
0.1
50
32
32
0.15
0.999
0.999
0.1
0.3
500
0.1
50
32
32
0.15
0.999
0.999
0.1
0.9
5120
0.1
50
32
32
0.15
0.999
0.999
0.8
1.0"
MEAN-ER,0.9724025974025974,"S-Tiny-ImageNet
200
0.05
50
32
32
0.1
0.999
0.999
0.04
0.08
500
0.05
50
32
32
0.1
0.999
0.999
0.05
0.08
5120
0.05
50
32
32
0.1
0.999
0.999
0.07
0.08"
MEAN-ER,0.974025974025974,"R-MNIST
200
0.2
1
128
128
0.75
0.999
0.99
1.0
1.0
500
0.2
1
128
128
0.75
0.999
0.99
1.0
1.0
5120
0.2
1
128
128
0.75
0.999
0.99
1.0
1.0"
MEAN-ER,0.9756493506493507,"P-MNIST
200
0.2
1
128
128
1.0
0.99
0.99
0.8
1.0
500
0.2
1
128
128
1.0
0.99
0.99
0.8
1.0
5120
0.2
1
128
128
1.0
0.99
0.99
0.9
1.0"
MEAN-ER,0.9772727272727273,"MNIST-360
200
0.2
1
16
16
0.75
0.999
0.99
1.0
1.0
500
0.2
1
16
32
1.25
0.99
0.99
0.9
1.0
1000
0.2
1
16
128
0.75
0.99
0.99
0.9
1.0"
MEAN-ER,0.9788961038961039,"GCIL-CIFAR-100
200
0.1
100
32
32
0.1
0.999
0.999
0.6
0.7
500
0.1
100
32
32
0.1
0.999
0.999
0.6
0.7
1000
0.1
100
32
32
0.1
0.999
0.999
0.6
0.8"
MEAN-ER,0.9805194805194806,Table S4: The hyperparameters used for each of the experimental settings for CLS-ER.
MEAN-ER,0.9821428571428571,"Distribution
Buffer
lr
Epochs
Batch Size
Memory
Batch Size
ααα
βββ"
MEAN-ER,0.9837662337662337,"Uniform
200
0.1
100
32
32
0.2
0.5
500
0.1
100
32
32
0.2
0.6
1000
0.1
100
32
32
0.3
0.6"
MEAN-ER,0.9853896103896104,"Longtail
200
0.1
100
32
32
0.2
0.6
500
0.1
100
32
32
0.2
0.8
1000
0.1
100
32
32
0.3
0.9"
MEAN-ER,0.987012987012987,"Table S5: The hyperparameters used for DER++ on GCIL-CIFAR-100 experiments. CLS-ER uses
the same hyperparameters for both Uniform and Longtail settings (Table S4)."
MEAN-ER,0.9886363636363636,"Dataset
Buffer
lr
Epochs
Batch Size
Memory
Batch Size
λλλ
ααα
rrr"
MEAN-ER,0.9902597402597403,"S-MNIST
200
0.03
1
10
128
2.0
0.99
1.0
500
0.1
1
10
32
2.0
0.99
1.0
5120
0.1
1
10
32
2.0
0.99
1.0"
MEAN-ER,0.9918831168831169,"S-CIFAR-10
200
0.1
50
32
32
0.15
0.999
0.2
500
0.1
50
32
32
0.15
0.999
0.5
5120
0.1
50
32
32
0.15
0.999
0.8"
MEAN-ER,0.9935064935064936,"S-Tiny-ImageNet
200
0.05
50
32
32
0.1
0.999
0.06
500
0.05
50
32
32
0.1
0.999
0.08
5120
0.05
50
32
32
0.1
0.999
0.08"
MEAN-ER,0.9951298701298701,"R-MNIST
200
0.2
1
128
128
0.75
0.999
1.0
500
0.2
1
128
128
0.75
0.999
1.0
5120
0.2
1
128
128
0.75
0.999
1.0"
MEAN-ER,0.9967532467532467,"P-MNIST
200
0.2
1
128
128
1.0
0.99
0.9
500
0.2
1
128
128
1.0
0.99
1.0
5120
0.2
1
128
128
1.0
0.99
0.9"
MEAN-ER,0.9983766233766234,Table S6: The hyperparameters used for each of the experimental settings for Mean-ER.
