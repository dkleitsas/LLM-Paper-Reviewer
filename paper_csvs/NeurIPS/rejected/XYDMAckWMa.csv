Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0007189072609633358,"This paper proposes a novel method, Explicit Flow Matching (ExFM), for training
1"
ABSTRACT,0.0014378145219266715,"and analyzing flow-based generative models. ExFM leverages a theoretically
2"
ABSTRACT,0.002156721782890007,"grounded loss function, ExFM loss (a tractable form of Flow Matching (FM) loss),
3"
ABSTRACT,0.002875629043853343,"to demonstrably reduce variance during training, leading to faster convergence and
4"
ABSTRACT,0.0035945363048166786,"more stable learning. Based on theoretical analysis of these formulas, we derived
5"
ABSTRACT,0.004313443565780014,"exact expressions for the vector field (and score in stochastic cases) for model
6"
ABSTRACT,0.0050323508267433505,"examples (in particular, for separating multiple exponents), and in some simple
7"
ABSTRACT,0.005751258087706686,"cases, exact solutions for trajectories. In addition, we also investigated simple cases
8"
ABSTRACT,0.006470165348670022,"of diffusion generative models by adding a stochastic term and obtained an explicit
9"
ABSTRACT,0.007189072609633357,"form of the expression for score. While the paper emphasizes the theoretical
10"
ABSTRACT,0.007907979870596693,"underpinnings of ExFM, it also showcases its effectiveness through numerical
11"
ABSTRACT,0.008626887131560028,"experiments on various datasets, including high-dimensional ones. Compared to
12"
ABSTRACT,0.009345794392523364,"traditional FM methods, ExFM achieves superior performance in terms of both
13"
ABSTRACT,0.010064701653486701,"learning speed and final outcomes.
14"
INTRODUCTION,0.010783608914450037,"1
Introduction
15"
INTRODUCTION,0.011502516175413372,"In recent years, there has been a remarkable surge in Deep Learning, wherein the advancements
16"
INTRODUCTION,0.012221423436376708,"have transitioned from purely neural networks to tackling differential equations. Notably, Diffusion
17"
INTRODUCTION,0.012940330697340043,"Models [16] have emerged as key players in this field. This models transform a simple initial
18"
INTRODUCTION,0.013659237958303379,"distribution, usually a standard Gaussian distribution, into a target distribution via a solution of
19"
INTRODUCTION,0.014378145219266714,"Stochastic Differentiable Equation (SDE) [1] or Ordinary Differentiable Equation (ODE)[2] with
20"
INTRODUCTION,0.01509705248023005,"right-hand side representing a trained neural network. The Conditional Flow Matching (CFM) [9]
21"
INTRODUCTION,0.015815959741193385,"technique, which we focus on in our research, is a promising approach for constructing probability
22"
INTRODUCTION,0.01653486700215672,"distributions using conditional probability paths, which is notably a robust and stable alternative for
23"
INTRODUCTION,0.017253774263120056,"training Diffusion Models. The development of the CFM-based approach includes various techniques
24"
INTRODUCTION,0.017972681524083392,"and heuristics [4, 7, 13] aimed at improving convergence or quality of learning or inference. For
25"
INTRODUCTION,0.018691588785046728,"example, in the works [19, 20, 10] it was proposed to straighten the trajectories between points by
26"
INTRODUCTION,0.019410496046010063,"different methods, which led to serious modifications of the learning process. We refer the reader
27"
INTRODUCTION,0.020129403306973402,"for, example, to the paper [20] where different FM-based approaches are summarised, and to the
28"
INTRODUCTION,0.020848310567936738,"paper [9] for the connection between Diffusion Models and CFM.
29"
INTRODUCTION,0.021567217828900073,"In our work, we introduced an approach which we called Explicit Flow Matching (ExFM), to consider
30"
INTRODUCTION,0.02228612508986341,"the Flow Matching framework theoretically by modifying the loss and writing the explicit value of
31"
INTRODUCTION,0.023005032350826744,"the vector field. Strictly speaking, the presented loss is a tractable form of the FM loss, see Eq. (5)
32"
INTRODUCTION,0.02372393961179008,"of [9]. Base on this methods we can improve the convergence of the method in practical examples
33"
INTRODUCTION,0.024442846872753415,"reducing the variance of the loss, but the main focus of our paper is on theoretical derivations.
34"
INTRODUCTION,0.02516175413371675,"Our method allows us to write an expression for the vector field in closed form for quite simple
35"
INTRODUCTION,0.025880661394680086,"cases (Gaussian distributions), however, we note that Diffusion Models framework in the case of
36"
INTRODUCTION,0.026599568655643422,"a Gaussian Mixture of two Gaussian as a target distribution is still under investigation, see recent
37"
INTRODUCTION,0.027318475916606758,"publications [15, 8].
38"
INTRODUCTION,0.028037383177570093,"Our main contributions are:
39"
INTRODUCTION,0.02875629043853343,"1. A tractable form of the FM loss is presented, which reaches a minimum on the same function
40"
INTRODUCTION,0.029475197699496764,"as the loss used in Conditional Flow Matching, but has a smaller variance;
41"
THE EXPLICIT EXPRESSION IN INTEGRAL FORM FOR THE VECTOR FIELD DELIVERING THE MINIMUM TO THIS,0.0301941049604601,"2. The explicit expression in integral form for the vector field delivering the minimum to this
42"
THE EXPLICIT EXPRESSION IN INTEGRAL FORM FOR THE VECTOR FIELD DELIVERING THE MINIMUM TO THIS,0.030913012221423435,"loss (therefore for Flow Matching loss) is presented.
43"
THE EXPLICIT EXPRESSION IN INTEGRAL FORM FOR THE VECTOR FIELD DELIVERING THE MINIMUM TO THIS,0.03163191948238677,"3. As a consequence, we derive expressions for the flow matching vector field and score in
44"
THE EXPLICIT EXPRESSION IN INTEGRAL FORM FOR THE VECTOR FIELD DELIVERING THE MINIMUM TO THIS,0.03235082674335011,"several particular cases (when linear conditional mapping is used, normal distribution, etc.);
45"
ANALYTICAL ANALYSIS OF SGD CONVERGENCE SHOWED THAT OUR FORMULA HAVE BETTER TRAINING,0.03306973400431344,"4. Analytical analysis of SGD convergence showed that our formula have better training
46"
ANALYTICAL ANALYSIS OF SGD CONVERGENCE SHOWED THAT OUR FORMULA HAVE BETTER TRAINING,0.03378864126527678,"variance on several cases;
47"
ANALYTICAL ANALYSIS OF SGD CONVERGENCE SHOWED THAT OUR FORMULA HAVE BETTER TRAINING,0.03450754852624011,"5. Numerical experiments show that we can achieve better learning results in fewer steps.
48"
PRELIMINARIES,0.03522645578720345,"1.1
Preliminaries
49"
PRELIMINARIES,0.035945363048166784,"Flow matching is well known method for finding a flow to connect samples from two distribution
50"
PRELIMINARIES,0.03666427030913012,"with densities ρ0 and ρ1. It is done by solving continuity equation with respect to the time dependent
51"
PRELIMINARIES,0.037383177570093455,"vector field v(x, t) and time-dependent density ρ(x, t) with boundary conditions:
52 
 "
PRELIMINARIES,0.038102084831056794,"∂ρ(x, t)"
PRELIMINARIES,0.038820992092020126,"∂t
= −div(ρ(x, t)v(x, t)),"
PRELIMINARIES,0.039539899352983465,"ρ(x, 0) = ρ0(x),
ρ(x, 1) = ρ1(x).
(1)"
PRELIMINARIES,0.040258806613946804,"Function ρ(x, t) is called probability density path. Typically, the distribution ρ0 is known and it is
53"
PRELIMINARIES,0.040977713874910136,"chosen for convenience reasons, for example, as standard normal distribution ρ(x) = N(x | 0, I).
54"
PRELIMINARIES,0.041696621135873475,"The distribution ρ1 is unknown and we only know the set of samples from it, so the problem is to
55"
PRELIMINARIES,0.04241552839683681,"approximate the vector field v(x, t) ≈v(x, t) using these samples. To make problem (1) well defined,
56"
PRELIMINARIES,0.043134435657800146,"one usually imposes additional regularity conditions on the densities, such as smoothness. The
57"
PRELIMINARIES,0.04385334291876348,"rigorous justification of the obtained results we put in the Appendix, leaving the general formulations
58"
PRELIMINARIES,0.04457225017972682,"of theorems and ideas in the main text.
59"
PRELIMINARIES,0.04529115744069015,"From a given vector field, we can construct a flow ϕt, i. e., a time-dependent map, satisfying the
60"
PRELIMINARIES,0.04601006470165349,ODE ∂ϕt(x)
PRELIMINARIES,0.04672897196261682,"∂t
= v(ϕt(x), t) with initial condition ϕ0(x) = x. Thus, one can sample a point x0 from
61"
PRELIMINARIES,0.04744787922358016,"the distribution ρ0 and then using this ODE obtain a point x1 = ϕ1(x0) which have a distribution
62"
PRELIMINARIES,0.04816678648454349,"approximately equal to ρ1. For given boundary ρ0 and ρ1, the vector field or path solutions are not
63"
PRELIMINARIES,0.04888569374550683,"the only solutions, but if we have found any solution, it will already allow us to sample from the
64"
PRELIMINARIES,0.04960460100647016,"unknown density rho1. However, if the problem is more narrowly defined, e. g., one needs to have a
65"
PRELIMINARIES,0.0503235082674335,"map that is close to the Optimal Transport (OT) map, we have to impose additional constraints.
66"
PRELIMINARIES,0.051042415528396834,"The problem of finding any vector field v is solved in conditional manner in the paper [9], where
67"
PRELIMINARIES,0.05176132278936017,"so-called Conditional Flow Matching (CFM) is present. Namely, the following loss function was
68"
PRELIMINARIES,0.052480230050323505,"introduced for the training a model vθ which depends on parameters θ
69"
PRELIMINARIES,0.053199137311286844,"LCFM(θ) = EtEx1,x0
vθ(ϕt,x1(x0), t) −ϕ′
t,x1(x0)
2,
(2)"
PRELIMINARIES,0.05391804457225018,"where ϕt,x1(x0) is some flow, conditioned on x1 (one can take ϕt,x1(x0) = (1 −t)x0 + tx1 + σstx0
70"
PRELIMINARIES,0.054636951833213515,"in the simplest case, where σs > 0 is a small parameter need for this map to be invertable at
71"
PRELIMINARIES,0.055355859094176854,"any 0 ≤t ≤1). Hereinafter the dash indicates the time derivative. Time variable t is uniformly
72"
PRELIMINARIES,0.056074766355140186,"distributed: t ∼U[0, 1] and random variables x0 and x1 are distributed according to the initial and
73"
PRELIMINARIES,0.056793673616103525,"final distributions, respectively: x0 ∼ρ0, x1 ∼ρ1. Below we omit specifying of the symbol E the
74"
PRELIMINARIES,0.05751258087706686,"distribution by which the expectation is taken where it does not lead to ambiguity.
75"
PRELIMINARIES,0.058231488138030196,"1.2
Why new method?
76"
PRELIMINARIES,0.05895039539899353,"Model training using loss (2) have the following disadvantage: during training, due to the randomness
77"
PRELIMINARIES,0.05966930265995687,"of x0 and x1, significantly different values can be presented for model as output value at close model
78"
PRELIMINARIES,0.0603882099209202,"CFM
ExFM ExFM"
PRELIMINARIES,0.06110711718188354,"Figure 1: (Left) The key novelty of our approach is that in classical CFM, highly divergent directions
can appear in a small spatial area at similar times (left part). In our approach (right part) we average
over these vectors, training the model on a smoothed unnoised vector field. (Right) The comparison
evaluated dispersion norm over time parameter t for CFM and ExFM in matching standard Gaussian
ρ0 = N(0, I) to general Gaussian ρ1 = N(µ, σ2I) distributions. The y-axis represents the sum of
dispersion vector components, denoted as |Dx,x1∆v(x, t)|. The left panel illustrates samples drawn
from the ρ0 and ρ1 distributions, as well as the corresponding flows. The right panel depicts the
dispersion trend over time for both CFM (black line) and ExFM (red line) objectives. The dotted
lines correspond to the dispersion levels (in top-down order |Dx1|, |Dx0|, |Dx1|/N."
PRELIMINARIES,0.06182602444284687,"argument values (xt, t). Indeed, a fixed point xt = ϕt,x1(x0) can be obtained by an infinite set of x0
79"
PRELIMINARIES,0.0625449317038102,"and x1 pairs, some of which are directly opposite, and at least for small times t the probability of these
80"
PRELIMINARIES,0.06326383896477354,"different directions may not be significantly different. At the same time, data ϕ′
t,x1(x0) on which the
81"
PRELIMINARIES,0.06398274622573688,"model learns significantly different for such different positions of pairs x0 and x1. Thus, the model is
82"
PRELIMINARIES,0.06470165348670022,"forced to do two functions during training: generalize and take the mathematical expectation (clean
83"
PRELIMINARIES,0.06542056074766354,"the data from noise).
84"
PRELIMINARIES,0.06613946800862688,"In our approach, see Fig. 1(a), we feed the model input with cleaned data with small variance. Thus,
85"
PRELIMINARIES,0.06685837526959022,"the model only needs to generalize the data, which happens much faster (in fewer training steps).
86"
PRELIMINARIES,0.06757728253055356,"Moreover, in the process of constructing the modified loss, we have developed the exact formula for
87"
PRELIMINARIES,0.0682961897915169,"the vector field, see Eq. (11), (34). The existence of an explicit formula for the vector field is of great
88"
PRELIMINARIES,0.06901509705248023,"importance not only from a theoretical but also from a practical point of view.
89"
MAIN IDEA,0.06973400431344356,"2
Main idea
90"
MODIFIED OBJECTIVE,0.0704529115744069,"2.1
Modified objective
91"
MODIFIED OBJECTIVE,0.07117181883537024,"Lets expand the last two mathematical expectations in the loss (2) and substitute variables using
92"
MODIFIED OBJECTIVE,0.07189072609633357,"map ϕt,x1, passing from the point x0 to its position xt = ϕt,x1(x0) at time t:
93"
MODIFIED OBJECTIVE,0.07260963335729691,"Ex1,x0
vθ(ϕt,x1(x0), t) −ϕ′
t,x1(x0)
2 =
ZZ vθ(ϕt,x1(x0), t) −ϕ′
t,x1(x0)
2ρ0(x0)ρ1(x1)dx0dx1"
MODIFIED OBJECTIVE,0.07332854061826025,"=
ZZ vθ(xt, t) −ϕ′
t,x1
 
ϕ−1
t,x1(xt)
2 det """
MODIFIED OBJECTIVE,0.07404744787922359,"∂ϕ−1
t,x1(x)

∂x

x=xt #"
MODIFIED OBJECTIVE,0.07476635514018691,"ρ0
 
ϕ−1
t,x1(xt)
"
MODIFIED OBJECTIVE,0.07548526240115025,"|
{z
}
ρx1(xt,t)"
MODIFIED OBJECTIVE,0.07620416966211359,ρ1(x1) dxt dx1
MODIFIED OBJECTIVE,0.07692307692307693,"= Ex1,xt∼ρx1(·,t)
vθ(xt, t) −ϕ′
t,x1
 
ϕ−1
t,x1(xt)
2.
(3)"
MODIFIED OBJECTIVE,0.07764198418404025,"We assume, that the map ϕt,x1 is invertible at each 0 < t < 1, i. e. that ϕ−1
t,x1(xt) exits on this
94"
MODIFIED OBJECTIVE,0.07836089144500359,"time interval and for all xt = {ϕt(x0) | ∀x0 : ρ(x0) > 0}. Eq. (3) can be seen as a transition
95"
MODIFIED OBJECTIVE,0.07907979870596693,"from expectation on the variable x0 ∼ρ0 to expectation on the variable xt ∼ρx1(·, t), where
96"
MODIFIED OBJECTIVE,0.07979870596693027,"ρx1(x, t) = [ϕt,x1]∗ρ0(x) := ρ0
 
ϕ−1
t,x1(x)

det

∂ϕ−1
t,x1(x)

∂x

. See paper [5] for details about the
97"
MODIFIED OBJECTIVE,0.08051761322789361,"push-forward operator “*”. Our representation (3) is very similar to expression (9) of the cited
98"
MODIFIED OBJECTIVE,0.08123652048885693,"paper [9], only we write it in terms of the conditional flow rather than the conditional vector field.
99"
MODIFIED OBJECTIVE,0.08195542774982027,"To obtain the modified loss, we return to end of the standard CFM loss representation in (3). It is
100"
MODIFIED OBJECTIVE,0.08267433501078361,"written as the expectation over two random variables x1 and xt having a common distribution density
101"
MODIFIED OBJECTIVE,0.08339324227174695,"{x1, xt} ∼ρj(x1, xt, t) = ρx1(xt, t)ρ1(x1),
(4)"
MODIFIED OBJECTIVE,0.08411214953271028,"which, generally speaking, is not factorizable. Let us rewrite this expectations in terms of two inde-
102"
MODIFIED OBJECTIVE,0.08483105679367361,"pendent random variables, each of which have its marginal distribution. The marginal distribution ρm
103"
MODIFIED OBJECTIVE,0.08554996405463695,"of xt can be obtained via integration:
104"
MODIFIED OBJECTIVE,0.08626887131560029,"ρm(xt, t) =
Z
ρj(x1, xt, t) dx1 =
Z
ρx1(xt, t)ρ1(x1) dx1 ,
(5)"
MODIFIED OBJECTIVE,0.08698777857656362,"while the marginal distribution of x1 is just (unknown) function ρ1. Let for convenience w(t, x1, x) =
105"
MODIFIED OBJECTIVE,0.08770668583752696,"ϕ′
t,x1
 
ϕ−1
t,x1(x)
1. We have
106"
MODIFIED OBJECTIVE,0.0884255930984903,"LCFM(θ) = Et,x1,xt∼ρx1(·,t)∥vθ(xt, t) −w(t, x1, xt)∥2 =
Z 1 0"
MODIFIED OBJECTIVE,0.08914450035945364,"ZZ
∥vθ(xt, t) −w(t, x1, xt)∥2ρx1(x, t)ρ1(x1) dxt dx1dt = Z 1 0"
MODIFIED OBJECTIVE,0.08986340762041696,"ZZ
∥vθ(xt, t) −w(t, x1, xt)∥2 (ρx1(xt,t)/ρm(xt,t)) ρm(xt, t)ρ1(x1) dxt dx1dt ="
MODIFIED OBJECTIVE,0.0905823148813803,"Et,x1,x∼ρm(·,t)∥vθ(x, t) −w(t, x1, x)∥2 ρc(x|x1, t)/ρ1(x1),
(6)"
MODIFIED OBJECTIVE,0.09130122214234364,"where we introduce a conditional distribution
107"
MODIFIED OBJECTIVE,0.09202012940330698,"ρc(x|x1, t) := ρx1(x, t)ρ1(x1)/ρm(x, t) := ρx1(x, t)ρ1(x1)
Z
ρx1(x, t)ρ1(x1) dx1.
(7)"
MODIFIED OBJECTIVE,0.0927390366642703,"The key feature of the representation (6) is that the integration variables x1 and x are independent.
108"
MODIFIED OBJECTIVE,0.09345794392523364,"Thus, we can evaluate them using Monte Carlo-like schemes in different ways. However, we go
109"
MODIFIED OBJECTIVE,0.09417685118619698,"further and make a modification to this loss to reduce the variance of Monte Carlo methods.
110"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.09489575844716032,"2.2
New loss and exact expression for vector field
111"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.09561466570812366,"Note that so far the expression for LCFM have not changed, it has just been rewritten in different forms.
112"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.09633357296908698,"Now we change this expression so that its numerical value, generally speaking, may be different, but
113"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.09705248023005032,"the derivative of the model parameters will be the same. We introduce the following loss
114"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.09777138749101366,"LExFM(θ) = EtEx∼ρm
vθ(x, t) −Ex1∼ρ1w(t, x1, x)ρc(x|x1, t)/ρ1(x1)

2
=
Z 1 0"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.098490294751977,"Z vθ(x, t) −
Z
w(t, x1, x) × ρc(x|x1, t) dx1

2
ρm(x, t) dx dt.
(8)"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.09920920201294033,"Theorem 2.1. Losses LCFM in Eq. (2) and LExFM in Eq. (8) have the same derivative with respect to
115"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.09992810927390366,"model parameters:
116"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.100647016534867,"dLCFM(θ)/dθ = dLExFM(θ)/dθ .
(9)"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.10136592379583034,"Proof is in the Appendix A.1.
117"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.10208483105679367,"In the presented loss LExFM, the integration (outside the norm operator) proceeds on those variables
118"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.102803738317757,"on which the model depends, while inside this operator there are no other free variables. Thus, using
119"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.10352264557872035,"this kind of loss, it is possible to find an exact analytical expression for the vector field for which the
120"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.10424155283968368,"minimum of this loss is zero (unlike the loss LCFM). Namely, we have
121"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.10496046010064701,"v(x, t) =
Z
w(t, x1, x)ρc(x|x1, t) dx1 .
(10)"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.10567936736161035,"We can obtain the exact form of this vector field given the particular map ϕt,x1. For example, the
122"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.10639827462257369,"following statement holds:
123"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.10711718188353703,"1Note, that w(t, x1, x) is the conditional velocity at the given point x."
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.10783608914450037,"Corollary 2.2. Consider the linear conditioned flow ϕt,x1(x0) = (1 −t)x0 + tx1 which is inevitable
124"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.10855499640546369,"as 0 ≤t < 1. Then w(t, x1, x) = x1−x"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.10927390366642703,"1−t , ρx1(x, t) = ρ0

x−x1t"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.10999281092739037,"1−t

1
(1−t)d and the loss LExFM in
125"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.11071171818835371,"Eq. (8) reaches zero value when the model of the vector field have the following analytical form
126"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.11143062544931703,"v(x, t) =
Z
(x1 −x)ρ0"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.11214953271028037,x −x1t 1 −t
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.11286843997124371,"
ρ1(x1) dx1"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.11358734723220705,"
(1 −t)
Z
ρ0"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.11430625449317038,x −x1t 1 −t
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.11502516175413371,"
ρ1(x1) dx1"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.11574406901509705,"
. (11)"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.11646297627606039,"This is the exact value of the vector field whose flow translates the given distribution ρ0 to ρ1.
127"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.11718188353702372,"Complete proofs are in the Appendix A.3.1. Note that the result (11) is not totally new, for example,
128"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.11790079079798706,"a similar result (though in the form of a general expression rather than an explicit formula), was given
129"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.1186196980589504,"in [19], Eq. (9). However, our contribution consists of both the general form (10) and practical and
130"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.11933860531991373,"theoretical conclusions from it (see below).
131"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.12005751258087707,"Remark 2.3. In the case of the initial and final times t = 0, 1, Eq. (11) is noticeably simpler
132"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.1207764198418404,"v(x, 0) = Ex1x1 −x =
Z
x1ρ1(x1) dx1 −x.
v(x, 1) = x −
Z
x0ρ0(x0) dx0 .
(12)"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.12149532710280374,"This expression for the initial velocity means that each point first tends to the center of mass of the
133"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.12221423436376708,"unknown distribution ρ1 regardless of its initial position.
134"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.12293314162473042,"Extensions to SDE
Now let the conditional map be stochastic: ϕt,x1 = (1 −t)x0 + tx1 + σe(t)ϵ,
135"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.12365204888569374,"where ϵ ∼N(0, 1). Typically, σe(0) = σe(1) = 0, for example, σe(t) = t(1 −t)σe.
136"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.12437095614665708,"Note that this formulation covers (with appropriate selection of the σe(t) parameter) the case of
137"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.1250898634076204,"diffusion models [20].
138"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.12580877066858376,"Then, we can write the exact solution for a so-called score and flow matching objective (see [20] for
139"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.12652767792954708,"details)
140"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.12724658519051044,"L[SF]2M(θ) = E

∥vθ(x, t) −u◦
t (x)∥2
|
{z
}
flow matching loss"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.12796549245147376,"+λ(t)2 ∥sθ(x, t) −∇log pt(x)∥2
|
{z
}
score matching loss 
."
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.1286843997124371,"that corresponds to this map. In the last expression, the following explicit conditional expressions are
141"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.12940330697340044,"considered in the cited paper for the case σe(t) =
p"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.13012221423436376,"t(1 −t)σe
142"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.1308411214953271,"u◦
t (x) = 1 −2t"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.13156002875629044,"t(1 −t)(x −(tx1 + (1 −t)x0)) + (x1 −x0), ∇log pt(x) = tx1 + (1 −t)x0 −x"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.13227893601725377,"σ2et(1 −t)
."
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.13299784327821712,"The exact solution (our result, explicit analog of the Eq. (10) from [20]) under consideration has
143"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.13371675053918045,"the form (44) and (46) and, for example for the for the Gaussian ρ0 this expressions reduced to the
144"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.13443565780014377,"Eq. (49) and (50), correspondingly. See Appendix E for the details on this case.
145"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.13515456506110712,"Simple examples
Consider the case of Standard Normal Distribution as ρ0 and Gaussian Mixture
146"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.13587347232207045,"of two Gaussians as ρ1. Vector field have a closed form (37) in this case, and we can fast numerically
147"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.1365923795830338,"solve ODE for trajectories. Random generated trajectories and plot of the vector field are shown
148"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.13731128684399713,"on Fig. 2 (a)–(b). Detailed explanation of this case is in the Sec. D.2. Another example is related
149"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.13803019410496045,"to the case of a stochastic map in the form of Brownian Bridge, which briefly described in the last
150"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.1387491013659238,"paragraph and considered in Sec. E.3.2 in details, see Fig. 2 (c)–(f). Note that at some σe values the
151"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.13946800862688713,"trajectories are a little bit straightened in this case compared to the usual linear map, if we compare
152"
NEW LOSS AND EXACT EXPRESSION FOR VECTOR FIELD,0.14018691588785046,"cases on the Fig. 6.
153"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.1409058231488138,"2.3
Training scheme based on the modified loss
154"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.14162473040977713,"Let us consider the difference between our new scheme based on loss LExFM and the classical CFM
155"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.14234363767074049,"learning scheme. As a basis for the implementation of the learning scheme, we take the open-source
156"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.1430625449317038,"code2 from the works [20, 19].
157"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.14378145219266714,"Consider a general framework of numerical schemes in classical CFM. We first sample m random time
158"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.1445003594536305,"variables t ∼U[0, 1]. Then we sample several values of x. To do this, we sample a certain number n
159"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.14521926671459381,"samples {xi
0}n
i=1 from the “noisy” distribution ρ0, and the same number n of samples {xi
1}n
i=1 from
160"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.14593817397555714,2https://github.com/atong01/conditional-flow-matching
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.1466570812365205,"0.2
0.4
0.6
0.8
1.0 t -3 -2 -1 1 2 3 x(t)"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.14737598849748382,"(a) GM trajecto-
ries"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.14809489575844717,(b) GM VF
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.1488138030194105,"0.2
0.4
0.6
0.8
1.0 t -5 5 10 x(t)"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.14953271028037382,"(c) BB Trajecto-
ries, σe = 3"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.15025161754133717,"(d) BB VF,
σe = 3"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.1509705248023005,"0.2
0.4
0.6
0.8
1.0 t -5 5 10 x(t)"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.15168943206326385,"(e) BB Trajecto-
ries, σe = 10"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.15240833932422718,"(f) BB VF,
σe = 10"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.1531272465851905,"Figure 2: Trajectories and vector field obtained in simple cases: (a) N = 80 random trajectories from
N
 
·
 0, 12
to GM; (b) 2D plot of the vector field in this case (c)–(f) N = 40 random trajectories
from N
 
·
 0, 12
to N
 
·
 2, 32
and 2D plot of the vector fieldfor different σe for the Brownian
Bridge map"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.15384615384615385,"the unknown distribution ρ1. Then we pair them (according to some scheme), and get n samples as
161"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.15456506110711718,"xj,i = ϕtj,xi
1(xi
0) (e. g. a linear combination in the simple case of linear map: xj,i = (1−tj)xi
0+tjxi
1),
162"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.1552839683680805,"∀i = 1, 2, . . . , n; ∀j = 1, 2, . . . , m. Note, than one of the variable n or m (or both) can be equal to 1.
163"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.15600287562904386,"At the step 2, the following discrete loss is constructed from the obtained samples
164"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.15672178289000718,"Ld
CFM(θ) = m
X j=1 n
X i=1"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.15744069015097054,"vθ(xj,i, tj) −ϕ′
tj,xi
1(xi
0)

2
.
(13)"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.15815959741193386,"Finally, we do a standard gradient descent step to update model parameters θ using this loss.
165"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.1588785046728972,"The first and last step in our algorithm is the same as in the standard algorithm, but the second step is
166"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.15959741193386054,"significantly different. Namely, we additionally generate a sufficiently large number N ≫n · m of
167"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.16031631919482386,"samples x1 from the unknown distribution ρ1, sampling (N −n) new samples and adding to it the
168"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.16103522645578722,"samples {xi
1}n
1 that are already obtained on the previous step.
169"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.16175413371675054,"Then we form the following discrete loss which replaces the integral on x1 in LExFM by its evalua-
170"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.16247304097771387,"tion vd by self-normalized importance sampling or rejection sampling (see Appendix B for details)
171"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.16319194823867722,"Ld
ExFM(θ) = m
X j=1 n
X i=1"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.16391085549964055,"vθ(xj,i, tj) −vd(xj,i, tj)

2
.
(14)"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.16462976276060387,"For example, if we use self-normalized importance sampling and assume that the Jacobian
172"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.16534867002156722,"det

∂ϕ−1
t,x1(x)

∂x

do not depend on x1, we can write
173"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.16606757728253055,"vd(x, t) = N
X"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.1667864845434939,"k=1
w(t, xk
1, x)ρ0
 
ϕ−1
t,xk
1(x)

!, N
X"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.16750539180445723,"k=1
ρ0
 
ϕ−1
t,xk
1(x)

.
(15)"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.16822429906542055,"Theorem 2.4. Under mild conditions, the error variance of the integral gradient (9) using the Monte
174"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.1689432063263839,"Carlo method (14) is lower than using formula (13) with the same number n · m of samples for {x}.
175"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.16966211358734723,"Sketch of the proof is in the Appendix A.2. The steps of our scheme are formally summarized in
176"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.17038102084831055,"Algorithm 1.
177"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.1710999281092739,"Particular case of linear map and Gaussian noise
Let ϕt,x1 be the linear flow: ϕt,x1(x0) =
178"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.17181883537023723,"(1 −t)x0 + tx1. and consider the case of standard normal distribution for the initial density ρ0:
179"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.17253774263120059,"ρ0(x) ∼N(x | 0, I). Then in the case of using self-normalized importance sampling, we have
180"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.1732566498921639,"vd(x, t) = N
X k=1"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.17397555715312724,"xk
1 −x
1 −t
 
SoftMax(Y 1, . . . , Y N)
"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.1746944644140906,"k,
where
Y k = −1 2"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.17541337167505391,"x −t · xk
1
2
Rd
1 −t
.
(16)"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.17613227893601727,"Here, the lower index k in SoftMax stands for the k-th component, and the SoftMax operation itself
181"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.1768511861969806,"came about due to exponents in the Gaussian density as a more stable substitute for computing than
182"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.17757009345794392,"directly through exponents.
183"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.17828900071890727,"Extension of other maps and initial densities ρ0
Common expression (10) can be reduced to
184"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.1790079079798706,"closed form for the particular choices of density ρ0 and map ϕ (consequently, expression for w). We
185"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.17972681524083392,"summarise several known approaches for which FM-based techniques can be applied in Table 13.
186"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.18044572250179727,"See Appendix C and D for derivations of formulas and for more extensions.
187"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.1811646297627606,3The idea and common structure of the Table is taken from [20]
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.18188353702372395,"Table 1:
Correspondence between some methods which can reduced to FM framework and our
theoretical descriptions of them."
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.18260244428468728,"Probability Path
q(z)
µt(z)
σt
Explicit expressions:
vector field (VF) and score (S)
Var. Exploding [17]
ρ1(x1)
x1
σ1−t
VF: (32)"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.1833213515456506,"Var. Preserving [6]
ρ1(x1)
α1−tx1
q"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.18404025880661395,"1 −α2
1−t
VF: (31)
Flow Matching [9]
ρ1(x1)
tx1
tσs −t + 1
VF: (11) if σ = 0; and (26)
Independent CFM
ρ0(x0)ρ1(x1)
tx1 + (1 −t)x0
σ
VF: (10)
Schrödinger Bridge CFM [20]
ρ0(x0)ρ1(x1)
tx1 + (1 −t)x0
σ
p"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.18475916606757728,"t(1 −t)
Can be obtained by SDE using
VF: (49), S:(50)"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.1854780733285406,"Complexity
We assume that the main running time of the algorithm is spent on training the model,
188"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.18619698058950396,"especially if it is quite complex. Thus, the running time of one training step depends crucially on the
189"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.18691588785046728,"number n · m of samples {x} and it is approximately the same for both algorithms: the addition of
190"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.18763479511143064,"points x1 entails only an additional calculation using formula (16), which can be done quickly and,
191"
TRAINING SCHEME BASED ON THE MODIFIED LOSS,0.18835370237239396,"moreover, can be simple parallelized.
192"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.18907260963335729,"2.4
Irreducible dispersion of gradient for CFM optimization
193"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.18979151689432064,"Ensuring the stability of optimization is vital. Let ∆θ be changes in parameters, obtained by SGD
194"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.19051042415528396,"with step size γ/2 applied to the functional from Eq. (13):
195"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.19122933141624732,"∆v(xj,i, tj) = −γ ·
 
v(xj,i, tj) −vd(xj,i, tj)

.
(17)"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.19194823867721064,"For simplification, we consider a function, vθ(x, t), capable of perfectly fitting the CFM problem and
196"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.19266714593817397,"providing an optimal solution for any point x and time t. For a linear conditional flow at a specific
197"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.19338605319913732,"point xj,i ∼ρxi
1(·, tj) at time tj ∼U(0, 1), the update ∆v(xj,i, tj) can be represented as follows:
198"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.19410496046010065,"∆v(xj,i, tj) = γ
 
xi
1 −ˆxi
0 −v(xj,i, tj)

,
(18)"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.19482386772106397,"where ˆxi
0 = xj,i−tjxi
1
1−tj
. We define the dispersion Dx,x1f(x, x1) for x ∼ρx1(·, t) and x1 ∼ρ1 as:
199"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.19554277498202732,"Dx,x1f(x, x1) = Ex,x1f 2(x, x1) −(Ex,x1f(x, x1))2.
(19)"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.19626168224299065,"Proposition 2.5. At the time t = 0, the dispersion of update in the form (18) have the following
200"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.196980589503954,"element-wise lower bound:
201"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.19769949676491733,"Dxj,i,xi
1∆v(xj,i, 0) = γ2Dxi
1xi
1 + γ2Dxj,i,xi
1(xj,i + v(xj,i, 0)) ≥γ2Dxi
1xi
1."
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.19841840402588065,"Equality is reached when the model v(xj,i, 0) has exact values equal to (12).
202"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.199137311286844,"Given that the dispersion cannot be reduced with an increase in batch size, the only available option
203"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.19985621854780733,"is to decrease the step size of the optimization method, i. e., reduce the learning rate slowing down the
204"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.20057512580877068,"convergence. The situation is much better for the proposed loss in (14). We can express the update
205"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.201294033069734,"∆v(xj,i, tj) in the case of ExFM objective as:
206"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.20201294033069733,"∆v(xj, tj) = γ2 N
X"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.20273184759166069,"k=1
xk
1 ˜ρ
 
xj,i|xk
1, tj
−xj,i −v(xj,i, tj)

,
(20)"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.203450754852624,"where xj,i ∼ρxi
1(·, tj), xk
1 ∼ρ1 and ˜ρ
 
xj,i|xk
1, tj
= ρ0

xj,i−tjxk
1
1−tj

/
N
P"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.20416966211358734,"k=1
ρ0

xj,i−tjxk
1
1−tj

. Similar
207"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.2048885693745507,"to the derivations in the previous part, we can found simplified form for the dispersion of update at
208"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.205607476635514,"t = 0.
209"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.20632638389647737,"Proposition 2.6. At the time t = 0, the dispersion of update from (20) have the following element-wise
210"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.2070452911574407,"lower bound:
211"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.20776419841840402,"Dxj,i,xk
1∆v(xj,i, 0) = γ2"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.20848310567936737,"N Dxk
1xk
1 + γ2Dxj,i,xk
1(xj,i + v(xj,i, 0)) ≥γ2"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.2092020129403307,"N Dxk
1xk
1."
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.20992092020129402,"Equality is reached when the model v(xj,i, 0) has exact values equal to (12).
212"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.21063982746225737,"In comparison to CFM, the dispersion of the update is N times smaller than the dispersion of the
213"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.2113587347232207,"target distribution and could be controlled without impeding convergence by adjusting the number of
214"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.21207764198418405,"samples N. In Figure 1(b), we visually compare the dispersions of CFM and ExFM. The illustration
215"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.21279654924514738,"aligns a standard normal distribution N(0, I) with a shifted and scaled variant N(µ, Iσ2). ExFM
216"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.2135154565061107,"yields lower dispersion throughout the range t ∈[0, 1]. Detailed analytical calculations of the optimal
217"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.21423436376707405,"velocity v(x, t) and dispersion are provided in the Appendix G.
218"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.21495327102803738,"(a) swissroll
(b) moons
(c) circles
(d) 2spirals (e)
checkerboard"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.21567217828900073,"(f) pinwheel
(g) rings"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.21639108554996406,"Figure 3: Visual comparison of methods on toy 2D data. First row are original samples, second row
sampled by ExFM, third row sampled by CFM."
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.21710999281092738,Table 2: ExFM and CFM metrics comparison table on toy 2D data.
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.21782890007189074,"MSE TRAINING LOSS
ENERGY DISTANCE
DATA
EXFM
CFM
EXFM
CFM"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.21854780733285406,"SWISSROLL
1.13E-02
2.12E+00
2.58e-03
1.07E-02
MOONS
9.96E-03
2.01E+00
2.74e-03
1.41E-02
8GAUSSIANS
2.40E-02
2.77E+00
4.90e-03
2.45E-02
CIRCLES
9.28E-03
2.79E+00
6.69e-04
1.32E-02
2SPIRALS
8.92E-03
2.34E+00
1.27e-03
8.35E-03
CHECKERBOARD
1.04E-02
3.12E+00
1.01e-02
1.63E-02
PINWHEEL
4.53E-03
2.12E+00
1.01e-03
9.22E-03
RINGS
8.60E-03
1.93E+00
3.55e-04
2.37E-03"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.21926671459381739,"Table 3: NLL comparison for ExFM, CFM and OT-CFM methods over 10 000 learning steps, mean
and std taken from 10 sampling iterations."
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.21998562185478074,"DATA
EXFM
CFM
OT-CFM"
IRREDUCIBLE DISPERSION OF GRADIENT FOR CFM OPTIMIZATION,0.22070452911574406,"POWER
-8.51e-02 ± 4.85e-02
1.64E-01 ± 4.18E-02
5.22E-02 ± 3.92E-02
GAS
-5.53e+00 ± 3.66e-02
-5.00E+00 ± 2.56E-02
-5.48E+00 ± 2.90E-02
HEPMASS
2.16E+01 ± 6.31E-02
2.21e+01 ± 6.13e-02
2.16E+01 ± 4.32E-02
BSDS300
-1.29E+02 ± 8.40E-01
-1.29E+02 ± 8.97E-01
-1.32e+02 ± 6.39e-01
MINIBOONE
1.34e+01 ± 1.95e-04
1.42E+01 ± 1.29E-04
1.43E+01 ± 9.22E-05"
NUMERICAL EXPERIMENTS,0.22142343637670742,"3
Numerical Experiments
219"
NUMERICAL EXPERIMENTS,0.22214234363767074,"Toy 2D data
We conducted unconditional density estimation among eight distributions. Additional
220"
NUMERICAL EXPERIMENTS,0.22286125089863407,"details of the experiments see in the Appendix H. We commence the exposition of our findings
221"
NUMERICAL EXPERIMENTS,0.22358015815959742,"by showcasing a series of classical 2-dimensional examples, as depicted in Fig. 3 and Table 2.
222"
NUMERICAL EXPERIMENTS,0.22429906542056074,"Our observations indicate that ExFM adeptly handles complex distribution shapes is particularly
223"
NUMERICAL EXPERIMENTS,0.22501797268152407,"noteworthy, especially considering its ability to do so within a small number of epochs. Additionally,
224"
NUMERICAL EXPERIMENTS,0.22573687994248742,"the visual comparison underscores the evident superiority of ExFM over the CFM approach.
225"
NUMERICAL EXPERIMENTS,0.22645578720345075,"Tabular data
We conducted unconditional density estimation on five tabular datasets, namely
226"
NUMERICAL EXPERIMENTS,0.2271746944644141,"power, gas, hepmass, minibone, and BSDS300. Additional details of the experiments see in the
227"
NUMERICAL EXPERIMENTS,0.22789360172537743,"Appendix H. The empirical findings obtained from the numerical experiments from Table 3 indicate
228"
NUMERICAL EXPERIMENTS,0.22861250898634075,"a statistically significant improvement in the performance of our proposed method. Notably, ExFM
229"
NUMERICAL EXPERIMENTS,0.2293314162473041,"demonstrates a notable acceleration in convergence rate.
230"
NUMERICAL EXPERIMENTS,0.23005032350826743,"High-dimensional data and additional experiments
We conducted experiments on high-
231"
NUMERICAL EXPERIMENTS,0.23076923076923078,"dimensional data, among them experiments on CIFAR10 and MNIST dataset. FID results on
232"
NUMERICAL EXPERIMENTS,0.2314881380301941,"CIFAR10 shows slightly better score among sampled images.
233"
NUMERICAL EXPERIMENTS,0.23220704529115743,"Additional details of the experiments and sampled images see in the Appendix H.
234"
NUMERICAL EXPERIMENTS,0.23292595255212079,"Stochastic ExFM (ExFM-S) on toy 2D data
We evaluated the performance of the stochastic
235"
NUMERICAL EXPERIMENTS,0.2336448598130841,"version of ExFM (ExFM-S) with use of expressions given in Sec. E.3.2 on four standard toy datasets.
236"
NUMERICAL EXPERIMENTS,0.23436376707404744,"The primary experimental setup follows that used in [19]. Additional details on the hyperparameters
237"
NUMERICAL EXPERIMENTS,0.2350826743350108,"used are available in Appendix H. Based on the findings presented in Table 4, we determine that
238"
NUMERICAL EXPERIMENTS,0.2358015815959741,"ExFM-S surpasses I-CFM on all four datasets in terms of generative performance (W2) and also
239"
NUMERICAL EXPERIMENTS,0.23652048885693747,"outperforms in terms of OT optimality (NPE) on two of them, exhibiting similar results on the
240"
NUMERICAL EXPERIMENTS,0.2372393961179008,"remaining datasets. It also demonstrates performance similar to OT-CFM. While ExFM-S is not as
241"
NUMERICAL EXPERIMENTS,0.23795830337886412,"robust as the basic ExFM, it enables the matching of one dataset to another (moons →8gaussians) as
242"
NUMERICAL EXPERIMENTS,0.23867721063982747,"it does not necessitate the presence of an explicit formula for ρ0. Among other things, this experiment
243"
NUMERICAL EXPERIMENTS,0.2393961179007908,demonstrates the feasibility of our methods when both distributions ρ0 and ρ1 are unknown.
NUMERICAL EXPERIMENTS,0.24011502516175415,"Table 4: ExFM-S evaluation on four toy datasets (µ ± σ over three seeds). For comparison we take
I-CFM, OT-CFM, and ExFM (no values for moons →8gaussians due to the absence of explicit
formula for ρ0). Performance in generative modeling (W2) and dynamic OT optimality (NPE) is
assessed. The best result for each metric is highlighted in bold. Instances where we outperform CFM
are underscored."
NUMERICAL EXPERIMENTS,0.24083393242271747,"Metric →
W2 ↓
NPE ↓
Algorithm ↓Dataset →
N →moons
N →8gaussians
moons →8gaussians
N →2spirals
N →moons
N →8gaussians
moons →8gaussians
N →2spirals
I-CFM
0.522 ± 0.015
0.647 ± 0.078
0.966 ± 0.21
1.662 ± 0.067
0.328 ± 0.051
0.209 ± 0.009
0.945 ± 0.025
0.098 ± 0.04
OT-CFM
0.427 ± 0.038
0.528 ± 0.053
0.569 ± 0.018
1.322 ± 0.052
0.065 ± 0.068
0.031 ± 0.018
0.074 ± 0.026
0.031 ± 0.02
ExFM
0.318 ± 0.010
0.445 ± 0.075
–
1.276 ± 0.043
0.382 ± 0.050
0.213 ± 0.023
–
0.069 ± 0.064
ExFM-S
0.486 ± 0.09
0.570 ± 0.053
0.728 ± 0.063
1.361 ± 0.181
0.35 ± 0.143
0.166 ± 0.039
0.946 ± 0.059
0.083 ± 0.059 244"
CONCLUSIONS,0.2415528396836808,"4
Conclusions
245"
CONCLUSIONS,0.24227174694464415,"The presented method introduces a new loss function in tracrable form (in terms of integrals) that
246"
CONCLUSIONS,0.24299065420560748,"improves upon the existing Conditional Flow Matching approach. New loss as a function of the model
247"
CONCLUSIONS,0.2437095614665708,"parameters, reaches zero at its minimum. Thanks to this, we can: a) write an explicit expression for
248"
CONCLUSIONS,0.24442846872753415,"the vector field on which the loss minimum is achieved; b) get a smaller variance when training on
249"
CONCLUSIONS,0.24514737598849748,"the discrete version of the loss, therefore, we can learn the model faster and more accurately.
250"
CONCLUSIONS,0.24586628324946083,"Numerical experiments conducted on toy 2D data show reliable outcomes under uniform conditions
251"
CONCLUSIONS,0.24658519051042416,"and parameters. Comparison of the absolute values of loss for the proposed method and for CFM for
252"
CONCLUSIONS,0.24730409777138748,"the same distributions show that the absolute values of loss for these models differ strikingly, by a
253"
CONCLUSIONS,0.24802300503235084,"factor of 102–103. Experiments on high-dimensional datasets also confirm the theoretical deductions
254"
CONCLUSIONS,0.24874191229331416,"about the variance reduction of our method. However, we emphasize that we do not expect to use the
255"
CONCLUSIONS,0.24946081955427749,"proposed method in its pure form. On the contrary, we expect that the theoretical implications of our
256"
CONCLUSIONS,0.2501797268152408,"formulas will contribute to the construction of better learning or inference algorithms in conjunction
257"
CONCLUSIONS,0.25089863407620416,"with other heuristics or methods.
258"
CONCLUSIONS,0.2516175413371675,"Algebraic analysis of variance for some cases (in particular, for the case t = 0 or for the case of
259"
CONCLUSIONS,0.2523364485981308,"two Gaussians as initial and final distributions) show an improvement in variance when using the
260"
CONCLUSIONS,0.25305535585909417,"new loss. However, it is rather difficult to analyze in the general case, for all times t and general
261"
CONCLUSIONS,0.2537742631200575,"distributions ρ0 and ρ1.
262"
CONCLUSIONS,0.2544931703810209,"Having the expression for the vector field and score in the form of integrals, we can explicitly write
263"
CONCLUSIONS,0.25521207764198417,"out their expressions for some simple cases; in the case of Gaussian distributions we can also write
264"
CONCLUSIONS,0.2559309849029475,"out the exact solution for the trajectories. Thus, our approach allows one to advance the theoretical
265"
CONCLUSIONS,0.2566498921639109,"study of FM-based and Diffusion Model-based frameworks.
266"
REFERENCES,0.2573687994248742,"References
267"
REFERENCES,0.2580877066858375,"[1]
Michael S. Albergo, Nicholas M. Boffi, and Eric Vanden-Eijnden. “Stochastic Interpolants: A
268"
REFERENCES,0.2588066139468009,"Unifying Framework for Flows and Diffusions”. In: arXiv preprint 2303.08797 (2023).
269"
REFERENCES,0.2595255212077642,"[2]
Michael S. Albergo and Eric Vanden-Eijnden. “Building Normalizing Flows with Stochastic
270"
REFERENCES,0.26024442846872753,"Interpolants”. In: International Conference on Learning Representations (ICLR) (2023).
271"
REFERENCES,0.2609633357296909,"[3]
Gabriel Cardoso et al. “BR-SNIS: Bias Reduced Self-Normalized Importance Sampling”.
272"
REFERENCES,0.2616822429906542,"In: Advances in Neural Information Processing Systems. Ed. by S. Koyejo et al. Vol. 35.
273"
REFERENCES,0.26240115025161753,"Curran Associates, Inc., 2022, pp. 716–729. URL: https://proceedings.neurips.cc/
274"
REFERENCES,0.2631200575125809,"paper _ files / paper / 2022 / file / 04bd683d5428d91c5fbb5a7d2c27064d - Paper -
275"
REFERENCES,0.26383896477354424,"Conference.pdf.
276"
REFERENCES,0.26455787203450754,"[4]
Ricky T. Q. Chen and Yaron Lipman. “Riemannian Flow Matching on General Geometries”.
277"
REFERENCES,0.2652767792954709,"In: arXiv:2302.03660 (2023).
278"
REFERENCES,0.26599568655643424,"[5]
Ricky T. Q. Chen et al. “Neural Ordinary Differential Equations”. In: Advances in Neural
279"
REFERENCES,0.26671459381739754,"Information Processing Systems. Ed. by S. Bengio et al. Vol. 31. Curran Associates, Inc.,
280"
REFERENCES,0.2674335010783609,"2018. URL: https://proceedings.neurips.cc/paper_files/paper/2018/file/
281"
REFERENCES,0.26815240833932424,"69386f6bb1dfed68692a24c8686939b9-Paper.pdf.
282"
REFERENCES,0.26887131560028754,"[6]
Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising Diffusion Probabilistic Models. 2020.
283"
REFERENCES,0.2695902228612509,"arXiv: 2006.11239 [cs.LG].
284"
REFERENCES,0.27030913012221425,"[7]
Alexia Jolicoeur-Martineau, Kilian Fatras, and Tal Kachman. “Generating and Imputing
285"
REFERENCES,0.27102803738317754,"Tabular Data via Diffusion and Flow-based Gradient-Boosted Trees”. In: arXiv:2309.09968
286"
REFERENCES,0.2717469446441409,"(2023). arXiv: 2309.09968 [cs.LG].
287"
REFERENCES,0.27246585190510425,"[8]
Puheng Li et al. “On the Generalization Properties of Diffusion Models”. In: Advances in
288"
REFERENCES,0.2731847591660676,"Neural Information Processing Systems. Ed. by A. Oh et al. Vol. 36. Curran Associates, Inc.,
289"
REFERENCES,0.2739036664270309,"2023, pp. 2097–2127. URL: https://proceedings.neurips.cc/paper_files/paper/
290"
REFERENCES,0.27462257368799425,"2023/file/06abed94583030dd50abe6767bd643b1-Paper-Conference.pdf.
291"
REFERENCES,0.2753414809489576,"[9]
Yaron Lipman et al. “Flow Matching for Generative Modeling”. In: The Eleventh International
292"
REFERENCES,0.2760603882099209,"Conference on Learning Representations. 2023. URL: https://openreview.net/forum?
293"
REFERENCES,0.27677929547088426,"id=PqvMRDCJT9t.
294"
REFERENCES,0.2774982027318476,"[10]
Xingchao Liu, Chengyue Gong, and qiang liu. “Flow Straight and Fast: Learning to Generate
295"
REFERENCES,0.2782171099928109,"and Transfer Data with Rectified Flow”. In: The Eleventh International Conference on Learning
296"
REFERENCES,0.27893601725377426,"Representations. 2023. URL: https://openreview.net/forum?id=XVjTT1nw5z.
297"
REFERENCES,0.2796549245147376,"[11]
D. Martin et al. “A database of human segmented natural images and its application to
298"
REFERENCES,0.2803738317757009,"evaluating segmentation algorithms and measuring ecological statistics”. In: Proceedings
299"
REFERENCES,0.28109273903666426,"Eighth IEEE International Conference on Computer Vision. ICCV 2001. Vol. 2. 2001, 416–423
300"
REFERENCES,0.2818116462976276,"vol.2. DOI: 10.1109/ICCV.2001.937655.
301"
REFERENCES,0.28253055355859097,"[12]
Gaurav Parmar, Richard Zhang, and Jun-Yan Zhu. “On Aliased Resizing and Surprising
302"
REFERENCES,0.28324946081955427,"Subtleties in GAN Evaluation”. In: CVPR. 2022.
303"
REFERENCES,0.2839683680805176,"[13]
Aram-Alexandre Pooladian et al. “Multisample Flow Matching: Straightening Flows with
304"
REFERENCES,0.28468727534148097,"Minibatch Couplings”. In: Proceedings of the 40th International Conference on Machine
305"
REFERENCES,0.28540618260244427,"Learning. Ed. by Andreas Krause et al. Vol. 202. Proceedings of Machine Learning Research.
306"
REFERENCES,0.2861250898634076,"PMLR, July 2023, pp. 28100–28127. URL: https://proceedings.mlr.press/v202/
307"
REFERENCES,0.286843997124371,"pooladian23a.html.
308"
REFERENCES,0.2875629043853343,"[14]
Aaditya Ramdas, Nicolás García Trillos, and Marco Cuturi. “On wasserstein two-sample
309"
REFERENCES,0.2882818116462976,"testing and related families of nonparametric tests”. In: Entropy 19.2 (2017), p. 47.
310"
REFERENCES,0.289000718907261,"[15]
Kulin Shah, Sitan Chen, and Adam Klivans. “Learning Mixtures of Gaussians Using the
311"
REFERENCES,0.2897196261682243,"DDPM Objective”. In: Thirty-seventh Conference on Neural Information Processing Systems.
312"
REFERENCES,0.29043853342918763,"2023. URL: https://openreview.net/forum?id=aig7sgdRfI.
313"
REFERENCES,0.291157440690151,"[16]
Jascha Sohl-Dickstein et al. “Deep Unsupervised Learning using Nonequilibrium Thermody-
314"
REFERENCES,0.2918763479511143,"namics”. In: Proceedings of the 32nd International Conference on Machine Learning. Ed. by
315"
REFERENCES,0.29259525521207763,"Francis Bach and David Blei. Vol. 37. Proceedings of Machine Learning Research. Lille,
316"
REFERENCES,0.293314162473041,"France: PMLR, July 2015, pp. 2256–2265. URL: https://proceedings.mlr.press/v37/
317"
REFERENCES,0.29403306973400434,"sohl-dickstein15.html.
318"
REFERENCES,0.29475197699496763,"[17]
Yang Song and Stefano Ermon. “Generative Modeling by Estimating Gradients of the Data
319"
REFERENCES,0.295470884255931,"Distribution”. In: Neural Information Processing Systems (NeurIPS) (2019).
320"
REFERENCES,0.29618979151689434,"[18]
Gábor J Székely. “E-statistics: The energy of statistical samples”. In: Bowling Green State
321"
REFERENCES,0.29690869877785764,"University, Department of Mathematics and Statistics Technical Report 3.05 (2003), pp. 1–18.
322"
REFERENCES,0.297627606038821,"[19]
Alexander Tong et al. “Improving and generalizing flow-based generative models with mini-
323"
REFERENCES,0.29834651329978434,"batch optimal transport”. In: Transactions on Machine Learning Research (2024). Expert
324"
REFERENCES,0.29906542056074764,"Certification. ISSN: 2835-8856. URL: https://openreview.net/forum?id=CD9Snc73AW.
325"
REFERENCES,0.299784327821711,"[20]
Alexander Tong et al. “Simulation-Free Schrödinger Bridges via Score and Flow Matching”.
326"
REFERENCES,0.30050323508267435,"In: The 27th International Conference on Artificial Intelligence and Statistics. 2024. URL:
327"
REFERENCES,0.30122214234363764,"https://virtual.aistats.org/virtual/2024/poster/6691.
328"
REFERENCES,0.301941049604601,"NeurIPS Paper Checklist
329"
CLAIMS,0.30265995686556435,"1. Claims
330"
CLAIMS,0.3033788641265277,"Question: Do the main claims made in the abstract and introduction accurately reflect the
331"
CLAIMS,0.304097771387491,"paper’s contributions and scope?
332"
CLAIMS,0.30481667864845435,"Answer: [Yes]
333"
CLAIMS,0.3055355859094177,"Justification: Theoretical things are proved in theorems in the main text and in the Appendix,
334"
CLAIMS,0.306254493170381,"and numerical experiments have been performed
335"
CLAIMS,0.30697340043134436,"Guidelines:
336"
CLAIMS,0.3076923076923077,"• The answer NA means that the abstract and introduction do not include the claims
337"
CLAIMS,0.308411214953271,"made in the paper.
338"
CLAIMS,0.30913012221423436,"• The abstract and/or introduction should clearly state the claims made, including the
339"
CLAIMS,0.3098490294751977,"contributions made in the paper and important assumptions and limitations. A No or
340"
CLAIMS,0.310567936736161,"NA answer to this question will not be perceived well by the reviewers.
341"
CLAIMS,0.31128684399712436,"• The claims made should match theoretical and experimental results, and reflect how
342"
CLAIMS,0.3120057512580877,"much the results can be expected to generalize to other settings.
343"
CLAIMS,0.31272465851905107,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
344"
CLAIMS,0.31344356578001437,"are not attained by the paper.
345"
LIMITATIONS,0.3141624730409777,"2. Limitations
346"
LIMITATIONS,0.31488138030194107,"Question: Does the paper discuss the limitations of the work performed by the authors?
347"
LIMITATIONS,0.31560028756290437,"Answer: [Yes]
348"
LIMITATIONS,0.3163191948238677,"Justification:
349"
LIMITATIONS,0.3170381020848311,"Guidelines: Limitation is discussed both in the theoretical part (in particular, in the formu-
350"
LIMITATIONS,0.3177570093457944,"lation of theorems) and in the practical part, where we can see at which cases our method
351"
LIMITATIONS,0.3184759166067577,"works better or worse
352"
LIMITATIONS,0.3191948238677211,"• The answer NA means that the paper has no limitation while the answer No means that
353"
LIMITATIONS,0.3199137311286844,"the paper has limitations, but those are not discussed in the paper.
354"
LIMITATIONS,0.32063263838964773,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
355"
LIMITATIONS,0.3213515456506111,"• The paper should point out any strong assumptions and how robust the results are to
356"
LIMITATIONS,0.32207045291157443,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
357"
LIMITATIONS,0.32278936017253773,"model well-specification, asymptotic approximations only holding locally). The authors
358"
LIMITATIONS,0.3235082674335011,"should reflect on how these assumptions might be violated in practice and what the
359"
LIMITATIONS,0.32422717469446444,"implications would be.
360"
LIMITATIONS,0.32494608195542773,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
361"
LIMITATIONS,0.3256649892163911,"only tested on a few datasets or with a few runs. In general, empirical results often
362"
LIMITATIONS,0.32638389647735444,"depend on implicit assumptions, which should be articulated.
363"
LIMITATIONS,0.32710280373831774,"• The authors should reflect on the factors that influence the performance of the approach.
364"
LIMITATIONS,0.3278217109992811,"For example, a facial recognition algorithm may perform poorly when image resolution
365"
LIMITATIONS,0.32854061826024444,"is low or images are taken in low lighting. Or a speech-to-text system might not be
366"
LIMITATIONS,0.32925952552120774,"used reliably to provide closed captions for online lectures because it fails to handle
367"
LIMITATIONS,0.3299784327821711,"technical jargon.
368"
LIMITATIONS,0.33069734004313445,"• The authors should discuss the computational efficiency of the proposed algorithms
369"
LIMITATIONS,0.33141624730409774,"and how they scale with dataset size.
370"
LIMITATIONS,0.3321351545650611,"• If applicable, the authors should discuss possible limitations of their approach to
371"
LIMITATIONS,0.33285406182602445,"address problems of privacy and fairness.
372"
LIMITATIONS,0.3335729690869878,"• While the authors might fear that complete honesty about limitations might be used by
373"
LIMITATIONS,0.3342918763479511,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
374"
LIMITATIONS,0.33501078360891445,"limitations that aren’t acknowledged in the paper. The authors should use their best
375"
LIMITATIONS,0.3357296908698778,"judgment and recognize that individual actions in favor of transparency play an impor-
376"
LIMITATIONS,0.3364485981308411,"tant role in developing norms that preserve the integrity of the community. Reviewers
377"
LIMITATIONS,0.33716750539180446,"will be specifically instructed to not penalize honesty concerning limitations.
378"
THEORY ASSUMPTIONS AND PROOFS,0.3378864126527678,"3. Theory Assumptions and Proofs
379"
THEORY ASSUMPTIONS AND PROOFS,0.3386053199137311,"Question: For each theoretical result, does the paper provide the full set of assumptions and
380"
THEORY ASSUMPTIONS AND PROOFS,0.33932422717469446,"a complete (and correct) proof?
381"
THEORY ASSUMPTIONS AND PROOFS,0.3400431344356578,"Answer: [Yes]
382"
THEORY ASSUMPTIONS AND PROOFS,0.3407620416966211,"Justification: All theorems are formulated according to strict mathematical rules. There are
383"
THEORY ASSUMPTIONS AND PROOFS,0.34148094895758446,"proofs or proof sketches in the text or Appendix.
384"
THEORY ASSUMPTIONS AND PROOFS,0.3421998562185478,"Guidelines:
385"
THEORY ASSUMPTIONS AND PROOFS,0.34291876347951117,"• The answer NA means that the paper does not include theoretical results.
386"
THEORY ASSUMPTIONS AND PROOFS,0.34363767074047447,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
387"
THEORY ASSUMPTIONS AND PROOFS,0.3443565780014378,"referenced.
388"
THEORY ASSUMPTIONS AND PROOFS,0.34507548526240117,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
389"
THEORY ASSUMPTIONS AND PROOFS,0.34579439252336447,"• The proofs can either appear in the main paper or the supplemental material, but if
390"
THEORY ASSUMPTIONS AND PROOFS,0.3465132997843278,"they appear in the supplemental material, the authors are encouraged to provide a short
391"
THEORY ASSUMPTIONS AND PROOFS,0.3472322070452912,"proof sketch to provide intuition.
392"
THEORY ASSUMPTIONS AND PROOFS,0.34795111430625447,"• Inversely, any informal proof provided in the core of the paper should be complemented
393"
THEORY ASSUMPTIONS AND PROOFS,0.3486700215672178,"by formal proofs provided in appendix or supplemental material.
394"
THEORY ASSUMPTIONS AND PROOFS,0.3493889288281812,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
395"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.3501078360891445,"4. Experimental Result Reproducibility
396"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.35082674335010783,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
397"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.3515456506110712,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
398"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.35226455787203453,"of the paper (regardless of whether the code and data are provided or not)?
399"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.35298346513299783,"Answer: [Yes]
400"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.3537023723939612,"Justification: Yes, all parameters and hyperparameters required for reproducibility are
401"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.35442127965492454,"described in the Appendix
402"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.35514018691588783,"Guidelines:
403"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.3558590941768512,"• The answer NA means that the paper does not include experiments.
404"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.35657800143781454,"• If the paper includes experiments, a No answer to this question will not be perceived
405"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.35729690869877784,"well by the reviewers: Making the paper reproducible is important, regardless of
406"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.3580158159597412,"whether the code and data are provided or not.
407"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.35873472322070454,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
408"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.35945363048166784,"to make their results reproducible or verifiable.
409"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.3601725377426312,"• Depending on the contribution, reproducibility can be accomplished in various ways.
410"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.36089144500359455,"For example, if the contribution is a novel architecture, describing the architecture fully
411"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.3616103522645579,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
412"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.3623292595255212,"be necessary to either make it possible for others to replicate the model with the same
413"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.36304816678648455,"dataset, or provide access to the model. In general. releasing code and data is often
414"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.3637670740474479,"one good way to accomplish this, but reproducibility can also be provided via detailed
415"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.3644859813084112,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
416"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.36520488856937455,"of a large language model), releasing of a model checkpoint, or other means that are
417"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.3659237958303379,"appropriate to the research performed.
418"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.3666427030913012,"• While NeurIPS does not require releasing code, the conference does require all submis-
419"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.36736161035226456,"sions to provide some reasonable avenue for reproducibility, which may depend on the
420"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.3680805176132279,"nature of the contribution. For example
421"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.3687994248741912,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
422"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.36951833213515456,"to reproduce that algorithm.
423"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.3702372393961179,"(b) If the contribution is primarily a new model architecture, the paper should describe
424"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.3709561466570812,"the architecture clearly and fully.
425"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.37167505391804456,"(c) If the contribution is a new model (e.g., a large language model), then there should
426"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.3723939611790079,"either be a way to access this model for reproducing the results or a way to reproduce
427"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.37311286843997127,"the model (e.g., with an open-source dataset or instructions for how to construct
428"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.37383177570093457,"the dataset).
429"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.3745506829618979,"(d) We recognize that reproducibility may be tricky in some cases, in which case
430"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.37526959022286127,"authors are welcome to describe the particular way they provide for reproducibility.
431"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.37598849748382457,"In the case of closed-source models, it may be that access to the model is limited in
432"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.3767074047447879,"some way (e.g., to registered users), but it should be possible for other researchers
433"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.3774263120057513,"to have some path to reproducing or verifying the results.
434"
OPEN ACCESS TO DATA AND CODE,0.37814521926671457,"5. Open access to data and code
435"
OPEN ACCESS TO DATA AND CODE,0.3788641265276779,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
436"
OPEN ACCESS TO DATA AND CODE,0.3795830337886413,"tions to faithfully reproduce the main experimental results, as described in supplemental
437"
OPEN ACCESS TO DATA AND CODE,0.3803019410496046,"material?
438"
OPEN ACCESS TO DATA AND CODE,0.38102084831056793,"Answer: [NA]
439"
OPEN ACCESS TO DATA AND CODE,0.3817397555715313,"Justification: We do not provide a code, paper is mostly theoretical. We use open datasets.
440"
OPEN ACCESS TO DATA AND CODE,0.38245866283249463,"Guidelines:
441"
OPEN ACCESS TO DATA AND CODE,0.38317757009345793,"• The answer NA means that paper does not include experiments requiring code.
442"
OPEN ACCESS TO DATA AND CODE,0.3838964773544213,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
443"
OPEN ACCESS TO DATA AND CODE,0.38461538461538464,"public/guides/CodeSubmissionPolicy) for more details.
444"
OPEN ACCESS TO DATA AND CODE,0.38533429187634793,"• While we encourage the release of code and data, we understand that this might not be
445"
OPEN ACCESS TO DATA AND CODE,0.3860531991373113,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
446"
OPEN ACCESS TO DATA AND CODE,0.38677210639827464,"including code, unless this is central to the contribution (e.g., for a new open-source
447"
OPEN ACCESS TO DATA AND CODE,0.38749101365923794,"benchmark).
448"
OPEN ACCESS TO DATA AND CODE,0.3882099209202013,"• The instructions should contain the exact command and environment needed to run to
449"
OPEN ACCESS TO DATA AND CODE,0.38892882818116464,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
450"
OPEN ACCESS TO DATA AND CODE,0.38964773544212794,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
451"
OPEN ACCESS TO DATA AND CODE,0.3903666427030913,"• The authors should provide instructions on data access and preparation, including how
452"
OPEN ACCESS TO DATA AND CODE,0.39108554996405465,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
453"
OPEN ACCESS TO DATA AND CODE,0.391804457225018,"• The authors should provide scripts to reproduce all experimental results for the new
454"
OPEN ACCESS TO DATA AND CODE,0.3925233644859813,"proposed method and baselines. If only a subset of experiments are reproducible, they
455"
OPEN ACCESS TO DATA AND CODE,0.39324227174694465,"should state which ones are omitted from the script and why.
456"
OPEN ACCESS TO DATA AND CODE,0.393961179007908,"• At submission time, to preserve anonymity, the authors should release anonymized
457"
OPEN ACCESS TO DATA AND CODE,0.3946800862688713,"versions (if applicable).
458"
OPEN ACCESS TO DATA AND CODE,0.39539899352983465,"• Providing as much information as possible in supplemental material (appended to the
459"
OPEN ACCESS TO DATA AND CODE,0.396117900790798,"paper) is recommended, but including URLs to data and code is permitted.
460"
OPEN ACCESS TO DATA AND CODE,0.3968368080517613,"6. Experimental Setting/Details
461"
OPEN ACCESS TO DATA AND CODE,0.39755571531272466,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
462"
OPEN ACCESS TO DATA AND CODE,0.398274622573688,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
463"
OPEN ACCESS TO DATA AND CODE,0.3989935298346513,"results?
464"
OPEN ACCESS TO DATA AND CODE,0.39971243709561466,"Answer: [Yes]
465"
OPEN ACCESS TO DATA AND CODE,0.400431344356578,"Justification: Yes, all parameters and hyperparameters required for reproducibility are
466"
OPEN ACCESS TO DATA AND CODE,0.40115025161754136,"described in the Appendix
467"
OPEN ACCESS TO DATA AND CODE,0.40186915887850466,"Guidelines:
468"
OPEN ACCESS TO DATA AND CODE,0.402588066139468,"• The answer NA means that the paper does not include experiments.
469"
OPEN ACCESS TO DATA AND CODE,0.40330697340043137,"• The experimental setting should be presented in the core of the paper to a level of detail
470"
OPEN ACCESS TO DATA AND CODE,0.40402588066139467,"that is necessary to appreciate the results and make sense of them.
471"
OPEN ACCESS TO DATA AND CODE,0.404744787922358,"• The full details can be provided either with the code, in appendix, or as supplemental
472"
OPEN ACCESS TO DATA AND CODE,0.40546369518332137,"material.
473"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.40618260244428467,"7. Experiment Statistical Significance
474"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.406901509705248,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
475"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.4076204169662114,"information about the statistical significance of the experiments?
476"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.40833932422717467,"Answer: [Yes]
477"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.409058231488138,"Justification: For several experiments variances are given.
478"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.4097771387491014,"Guidelines:
479"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.4104960460100647,"• The answer NA means that the paper does not include experiments.
480"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.411214953271028,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
481"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.4119338605319914,"dence intervals, or statistical significance tests, at least for the experiments that support
482"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.41265276779295473,"the main claims of the paper.
483"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.41337167505391803,"• The factors of variability that the error bars are capturing should be clearly stated (for
484"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.4140905823148814,"example, train/test split, initialization, random drawing of some parameter, or overall
485"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.41480948957584474,"run with given experimental conditions).
486"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.41552839683680803,"• The method for calculating the error bars should be explained (closed form formula,
487"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.4162473040977714,"call to a library function, bootstrap, etc.)
488"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.41696621135873474,"• The assumptions made should be given (e.g., Normally distributed errors).
489"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.41768511861969804,"• It should be clear whether the error bar is the standard deviation or the standard error
490"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.4184040258806614,"of the mean.
491"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.41912293314162474,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
492"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.41984184040258804,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
493"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.4205607476635514,"of Normality of errors is not verified.
494"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.42127965492451475,"• For asymmetric distributions, the authors should be careful not to show in tables or
495"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.4219985621854781,"figures symmetric error bars that would yield results that are out of range (e.g. negative
496"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.4227174694464414,"error rates).
497"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.42343637670740475,"• If error bars are reported in tables or plots, The authors should explain in the text how
498"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.4241552839683681,"they were calculated and reference the corresponding figures or tables in the text.
499"
EXPERIMENTS COMPUTE RESOURCES,0.4248741912293314,"8. Experiments Compute Resources
500"
EXPERIMENTS COMPUTE RESOURCES,0.42559309849029475,"Question: For each experiment, does the paper provide sufficient information on the com-
501"
EXPERIMENTS COMPUTE RESOURCES,0.4263120057512581,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
502"
EXPERIMENTS COMPUTE RESOURCES,0.4270309130122214,"the experiments?
503"
EXPERIMENTS COMPUTE RESOURCES,0.42774982027318476,"Answer: [Yes]
504"
EXPERIMENTS COMPUTE RESOURCES,0.4284687275341481,"Justification: The experiments are simple enough to be reproduced on publicly available
505"
EXPERIMENTS COMPUTE RESOURCES,0.4291876347951114,"resources
506"
EXPERIMENTS COMPUTE RESOURCES,0.42990654205607476,"Guidelines:
507"
EXPERIMENTS COMPUTE RESOURCES,0.4306254493170381,"• The answer NA means that the paper does not include experiments.
508"
EXPERIMENTS COMPUTE RESOURCES,0.43134435657800146,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
509"
EXPERIMENTS COMPUTE RESOURCES,0.43206326383896476,"or cloud provider, including relevant memory and storage.
510"
EXPERIMENTS COMPUTE RESOURCES,0.4327821710999281,"• The paper should provide the amount of compute required for each of the individual
511"
EXPERIMENTS COMPUTE RESOURCES,0.43350107836089147,"experimental runs as well as estimate the total compute.
512"
EXPERIMENTS COMPUTE RESOURCES,0.43421998562185476,"• The paper should disclose whether the full research project required more compute
513"
EXPERIMENTS COMPUTE RESOURCES,0.4349388928828181,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
514"
EXPERIMENTS COMPUTE RESOURCES,0.43565780014378147,"didn’t make it into the paper).
515"
CODE OF ETHICS,0.43637670740474477,"9. Code Of Ethics
516"
CODE OF ETHICS,0.4370956146657081,"Question: Does the research conducted in the paper conform, in every respect, with the
517"
CODE OF ETHICS,0.4378145219266715,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
518"
CODE OF ETHICS,0.43853342918763477,"Answer: [Yes]
519"
CODE OF ETHICS,0.4392523364485981,"Justification: The article and experiments meet all the requirements of the code of ethics, all
520"
CODE OF ETHICS,0.4399712437095615,"citations for materials used are given.
521"
CODE OF ETHICS,0.44069015097052483,"Guidelines: The research conducted in the article and its text meet the ethics codex.
522"
CODE OF ETHICS,0.4414090582314881,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
523"
CODE OF ETHICS,0.4421279654924515,"• If the authors answer No, they should explain the special circumstances that require a
524"
CODE OF ETHICS,0.44284687275341483,"deviation from the Code of Ethics.
525"
CODE OF ETHICS,0.44356578001437813,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
526"
CODE OF ETHICS,0.4442846872753415,"eration due to laws or regulations in their jurisdiction).
527"
BROADER IMPACTS,0.44500359453630484,"10. Broader Impacts
528"
BROADER IMPACTS,0.44572250179726813,"Question: Does the paper discuss both potential positive societal impacts and negative
529"
BROADER IMPACTS,0.4464414090582315,"societal impacts of the work performed?
530"
BROADER IMPACTS,0.44716031631919484,"Answer: [NA]
531"
BROADER IMPACTS,0.44787922358015814,"Justification: Paper is mostly theoretical, there’s little chance there could be a negative
532"
BROADER IMPACTS,0.4485981308411215,"impact.
533"
BROADER IMPACTS,0.44931703810208484,"Guidelines:
534"
BROADER IMPACTS,0.45003594536304814,"• The answer NA means that there is no societal impact of the work performed.
535"
BROADER IMPACTS,0.4507548526240115,"• If the authors answer NA or No, they should explain why their work has no societal
536"
BROADER IMPACTS,0.45147375988497485,"impact or why the paper does not address societal impact.
537"
BROADER IMPACTS,0.4521926671459382,"• Examples of negative societal impacts include potential malicious or unintended uses
538"
BROADER IMPACTS,0.4529115744069015,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
539"
BROADER IMPACTS,0.45363048166786485,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
540"
BROADER IMPACTS,0.4543493889288282,"groups), privacy considerations, and security considerations.
541"
BROADER IMPACTS,0.4550682961897915,"• The conference expects that many papers will be foundational research and not tied
542"
BROADER IMPACTS,0.45578720345075485,"to particular applications, let alone deployments. However, if there is a direct path to
543"
BROADER IMPACTS,0.4565061107117182,"any negative applications, the authors should point it out. For example, it is legitimate
544"
BROADER IMPACTS,0.4572250179726815,"to point out that an improvement in the quality of generative models could be used to
545"
BROADER IMPACTS,0.45794392523364486,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
546"
BROADER IMPACTS,0.4586628324946082,"that a generic algorithm for optimizing neural networks could enable people to train
547"
BROADER IMPACTS,0.4593817397555715,"models that generate Deepfakes faster.
548"
BROADER IMPACTS,0.46010064701653486,"• The authors should consider possible harms that could arise when the technology is
549"
BROADER IMPACTS,0.4608195542774982,"being used as intended and functioning correctly, harms that could arise when the
550"
BROADER IMPACTS,0.46153846153846156,"technology is being used as intended but gives incorrect results, and harms following
551"
BROADER IMPACTS,0.46225736879942486,"from (intentional or unintentional) misuse of the technology.
552"
BROADER IMPACTS,0.4629762760603882,"• If there are negative societal impacts, the authors could also discuss possible mitigation
553"
BROADER IMPACTS,0.46369518332135157,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
554"
BROADER IMPACTS,0.46441409058231486,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
555"
BROADER IMPACTS,0.4651329978432782,"feedback over time, improving the efficiency and accessibility of ML).
556"
SAFEGUARDS,0.46585190510424157,"11. Safeguards
557"
SAFEGUARDS,0.46657081236520487,"Question: Does the paper describe safeguards that have been put in place for responsible
558"
SAFEGUARDS,0.4672897196261682,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
559"
SAFEGUARDS,0.4680086268871316,"image generators, or scraped datasets)?
560"
SAFEGUARDS,0.46872753414809487,"Answer: [NA]
561"
SAFEGUARDS,0.4694464414090582,"Justification: Our work has a very low risk of misuse.
562"
SAFEGUARDS,0.4701653486700216,"Guidelines:
563"
SAFEGUARDS,0.47088425593098493,"• The answer NA means that the paper poses no such risks.
564"
SAFEGUARDS,0.4716031631919482,"• Released models that have a high risk for misuse or dual-use should be released with
565"
SAFEGUARDS,0.4723220704529116,"necessary safeguards to allow for controlled use of the model, for example by requiring
566"
SAFEGUARDS,0.47304097771387493,"that users adhere to usage guidelines or restrictions to access the model or implementing
567"
SAFEGUARDS,0.47375988497483823,"safety filters.
568"
SAFEGUARDS,0.4744787922358016,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
569"
SAFEGUARDS,0.47519769949676494,"should describe how they avoided releasing unsafe images.
570"
SAFEGUARDS,0.47591660675772823,"• We recognize that providing effective safeguards is challenging, and many papers do
571"
SAFEGUARDS,0.4766355140186916,"not require this, but we encourage authors to take this into account and make a best
572"
SAFEGUARDS,0.47735442127965494,"faith effort.
573"
LICENSES FOR EXISTING ASSETS,0.47807332854061824,"12. Licenses for existing assets
574"
LICENSES FOR EXISTING ASSETS,0.4787922358015816,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
575"
LICENSES FOR EXISTING ASSETS,0.47951114306254494,"the paper, properly credited and are the license and terms of use explicitly mentioned and
576"
LICENSES FOR EXISTING ASSETS,0.4802300503235083,"properly respected?
577"
LICENSES FOR EXISTING ASSETS,0.4809489575844716,"Answer: [Yes]
578"
LICENSES FOR EXISTING ASSETS,0.48166786484543495,"Justification: Links are provided to articles with open repositories whose code was used in
579"
LICENSES FOR EXISTING ASSETS,0.4823867721063983,"the work
580"
LICENSES FOR EXISTING ASSETS,0.4831056793673616,"Guidelines:
581"
LICENSES FOR EXISTING ASSETS,0.48382458662832495,"• The answer NA means that the paper does not use existing assets.
582"
LICENSES FOR EXISTING ASSETS,0.4845434938892883,"• The authors should cite the original paper that produced the code package or dataset.
583"
LICENSES FOR EXISTING ASSETS,0.4852624011502516,"• The authors should state which version of the asset is used and, if possible, include a
584"
LICENSES FOR EXISTING ASSETS,0.48598130841121495,"URL.
585"
LICENSES FOR EXISTING ASSETS,0.4867002156721783,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
586"
LICENSES FOR EXISTING ASSETS,0.4874191229331416,"• For scraped data from a particular source (e.g., website), the copyright and terms of
587"
LICENSES FOR EXISTING ASSETS,0.48813803019410495,"service of that source should be provided.
588"
LICENSES FOR EXISTING ASSETS,0.4888569374550683,"• If assets are released, the license, copyright information, and terms of use in the
589"
LICENSES FOR EXISTING ASSETS,0.4895758447160316,"package should be provided. For popular datasets, paperswithcode.com/datasets
590"
LICENSES FOR EXISTING ASSETS,0.49029475197699496,"has curated licenses for some datasets. Their licensing guide can help determine the
591"
LICENSES FOR EXISTING ASSETS,0.4910136592379583,"license of a dataset.
592"
LICENSES FOR EXISTING ASSETS,0.49173256649892166,"• For existing datasets that are re-packaged, both the original license and the license of
593"
LICENSES FOR EXISTING ASSETS,0.49245147375988496,"the derived asset (if it has changed) should be provided.
594"
LICENSES FOR EXISTING ASSETS,0.4931703810208483,"• If this information is not available online, the authors are encouraged to reach out to
595"
LICENSES FOR EXISTING ASSETS,0.49388928828181167,"the asset’s creators.
596"
NEW ASSETS,0.49460819554277496,"13. New Assets
597"
NEW ASSETS,0.4953271028037383,"Question: Are new assets introduced in the paper well documented and is the documentation
598"
NEW ASSETS,0.49604601006470167,"provided alongside the assets?
599"
NEW ASSETS,0.49676491732566497,"Answer: [NA]
600"
NEW ASSETS,0.4974838245866283,"Justification: We do not provide a code. All Theorems and Satetements are well formulated.
601"
NEW ASSETS,0.4982027318475917,"Guidelines:
602"
NEW ASSETS,0.49892163910855497,"• The answer NA means that the paper does not release new assets.
603"
NEW ASSETS,0.4996405463695183,"• Researchers should communicate the details of the dataset/code/model as part of their
604"
NEW ASSETS,0.5003594536304816,"submissions via structured templates. This includes details about training, license,
605"
NEW ASSETS,0.501078360891445,"limitations, etc.
606"
NEW ASSETS,0.5017972681524083,"• The paper should discuss whether and how consent was obtained from people whose
607"
NEW ASSETS,0.5025161754133717,"asset is used.
608"
NEW ASSETS,0.503235082674335,"• At submission time, remember to anonymize your assets (if applicable). You can either
609"
NEW ASSETS,0.5039539899352984,"create an anonymized URL or include an anonymized zip file.
610"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5046728971962616,"14. Crowdsourcing and Research with Human Subjects
611"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.505391804457225,"Question: For crowdsourcing experiments and research with human subjects, does the paper
612"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5061107117181883,"include the full text of instructions given to participants and screenshots, if applicable, as
613"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5068296189791517,"well as details about compensation (if any)?
614"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.507548526240115,"Answer: [NA]
615"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5082674335010784,"Justification: we have no crowdsourcing
616"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5089863407620417,"Guidelines:
617"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.509705248023005,"• The answer NA means that the paper does not involve crowdsourcing nor research with
618"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5104241552839683,"human subjects.
619"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5111430625449317,"• Including this information in the supplemental material is fine, but if the main contribu-
620"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.511861969805895,"tion of the paper involves human subjects, then as much detail as possible should be
621"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5125808770668584,"included in the main paper.
622"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5132997843278218,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
623"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.514018691588785,"or other labor should be paid at least the minimum wage in the country of the data
624"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5147375988497483,"collector.
625"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5154565061107117,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
626"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.516175413371675,"Subjects
627"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5168943206326384,"Question: Does the paper describe potential risks incurred by study participants, whether
628"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5176132278936018,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
629"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5183321351545651,"approvals (or an equivalent approval/review based on the requirements of your country or
630"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5190510424155284,"institution) were obtained?
631"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5197699496764917,"Answer: [NA]
632"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5204888569374551,"Justification: There are no experiments with subjects in the paper, only numerical experi-
633"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5212077641984184,"ments.
634"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5219266714593818,"Guidelines:
635"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5226455787203451,"• The answer NA means that the paper does not involve crowdsourcing nor research with
636"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5233644859813084,"human subjects.
637"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5240833932422717,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
638"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5248023005032351,"may be required for any human subjects research. If you obtained IRB approval, you
639"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5255212077641984,"should clearly state this in the paper.
640"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5262401150251618,"• We recognize that the procedures for this may vary significantly between institutions
641"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5269590222861251,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
642"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5276779295470885,"guidelines for their institution.
643"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5283968368080517,"• For initial submissions, do not include any information that would break anonymity (if
644"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5291157440690151,"applicable), such as the institution conducting the review.
645"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5298346513299784,"A
Proof of the theorems
646"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5305535585909418,"A.1
Proof of the Theorem 2.1
647"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5312724658519051,"Proof. We need to proof, that dLCFM(θ)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5319913731128685,"dθ
= dLExFM(θ)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5327102803738317,"dθ
.
648"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5334291876347951,"To establish the equivalence of LCFM and LExFM up to a constant term, we begin by expressing LCFM
649"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5341480948957584,"in the format specified by equation (6):
650"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5348670021567218,"LCFM = Et,x1,x∼ρm(·,t)∥vθ(x, t) −w(t, x1, x)∥2 × ρc(x|x1, t)/ρ1(x1)."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5355859094176851,"Utilizing the bilinearity of the 2-norm, we can rewrite LCFM as:
651"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5363048166786485,"LCFM = Et,x1,x∼ρm(·,t)
∥vθ(x, t)∥2ρc(x|x1, t)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5370237239396118,"ρ1(x1)
−"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5377426312005751,"2Et,x1,x∼ρm(·,t)
vθ(x, t)T · w(t, x1, x)ρc(x|x1, t)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5384615384615384,"ρ1(x1)
+ C.
(21)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5391804457225018,"Here, T denotes transposed vector, dot denotes scalar product, C represents a constant independent
652"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5398993529834651,"of θ.
653"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5406182602444285,"Noting that Ex1ρc(x|x1, t)/ρ1(x1) = 1:
654"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5413371675053918,"Ex1
ρc(x|x1, t)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5420560747663551,"ρ1(x1)
=
Z
ρx1(x, t)ρ1(x1) dx1
R
ρx1(x, t)ρ1(x1) dx1
= 1,"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5427749820273184,"we can simplify the first term in the expansion (21):
655"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5434938892882818,"Et,x1,x∼ρm(·,t)
∥vθ(x, t)∥2ρc(x|x1, t)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5442127965492451,"ρ1(x1)
="
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5449317038102085,"Et,x∼ρm(·,t)∥vθ(x, t)∥2 Ex1
ρc(x|x1, t)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5456506110711719,"ρ1(x1)
= Et,x∼ρm(·,t)∥vθ(x, t)∥2.
(22)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5463695183321352,"For our loss LExFM in the form (8) we also use the bilinearity of the norm:
656"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5470884255930984,"LExFM = Et,x∼ρm(·,t)∥vθ(x, t)∥2 −2Et,x∼ρm(·,t)Ex1
vθ(x, t)T · w(t, x1, x)ρc(x|x1, t)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5478073328540618,"ρ1(x1)
+ C. (23)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5485262401150252,"Comparing the last expression and the Eq. (21) with the modification (22) and also taking into account
657"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5492451473759885,"the independence of random variables x and x1, we come to the conclusion that LExFM is equal to
658"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5499640546369519,"LCFM up to some constant independent of the model parameters.
659 660"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5506829618979152,"A.2
Sketch of the proof of the Theorem 2.4
661"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5514018691588785,"Proof. We need to prove that D dLd
ExFM(θ)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5521207764198418,"dθ
≤D dLd
CFM(θ)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5528396836808052,"dθ
, where Ld
ExFM(θ) and Ld
CFM(θ) discrete loss
662"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5535585909417685,"functions presented in (14) and (13). Firstly, let us rewrite the derivative of loss functions using the
663"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5542774982027319,"bilinearity:
664"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5549964054636952,"dLd
ExFM(θ)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5557153127246586,"dθ
= 2
X i,j"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5564342199856218,"dvθ(xj,i, tj) dθ"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5571531272465852,"T
·
 
vθ(xj,i, tj) −vd(xj,i, tj)

."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5578720345075485,"Note that in this expression, values xj,i as well as tj, which are included in the argument of the
665"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5585909417685119,"function v, are fixed (our goal to calculate the variance with fixed model arguments). Thus, we need
666"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5593098490294752,"to consider the variance of the remaining expression arising from the randomness of xk
1.
667"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5600287562904386,"Recall (below we will omit the indices at variables x and t),"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5607476635514018,"vd(x, t) ="
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5614665708123652,"PN
k=1 w(t, xk
1, x) · ρ0
 
ϕ−1
t,xk
1(x)
"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5621854780733285,"PN
k=1 ρ0
 
ϕ−1
t,xk
1(x)

."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5629043853342919,"Note, that if N = 1, (i. e. we do not sample any additional points other than the ones we have
668"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5636232925952552,"already sampled) this expression is exactly the same as the derivative of the common discretized
669"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5643421998562186,"CFM loss dLd
CFM(θ)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5650611071171819,"dθ
.
670"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5657800143781452,"Moreover, recall that one of the points (without loss of generality, we can assume that its index is 1)
671"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5664989216391085,"x1
1 is added from the set from which point x was derived: x = ϕt,x1
1(x0). (Here x0 is the paired point
672"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5672178289000719,"to x1
1)
673"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5679367361610352,"Thus, we can rewrite expression for vd:
674"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5686556434219986,"vd(x, t) =
w(t, x1
1, x)ρ0(x0) + PN
k=2 w(t, xk
1, x) · ρ0

ϕ−1
t,xk
1(x)
"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5693745506829619,"ρ0(x0) + PN
k=2 ρ0

ϕ−1
t,xk
1(x)

.
(24)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5700934579439252,"Thus, our task was reduced to evaluating how well the additional terms (for k starting from 2) improve
675"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5708123652048885,"approximate of the original integrals that are in loss (8).
676"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5715312724658519,"So, we need to estimate the following dispersion ratio, where in the numerator is the variance of
discrete loss CFM, and in the denominator — the variance of loss ExFM:"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5722501797268152,"kD =
D
 
vθ(x, t) −w(t, x1
1, x)
 D "
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5729690869877786,"vθ(x, t) −"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.573687994248742,"PN
k=1 w(t,xk
1,x)·ρ0
 
ϕ−1
t,xk
1
(x)
"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5744069015097053,"PN
k=1 ρ0
 
ϕ−1
t,xk
1
(x)
 !"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5751258087706685,"The smaller coefficient kD is, the better the proposed loss ExFM works.
677"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5758447160316319,"Formally, we can write our problem as an importance sampling problem for the following integral:"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5765636232925953,"I =
Z
f(x)p(x) dx ."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5772825305535586,"This integral we estimate by sample mean of the following expectation over some random variable
with density function q(x):
I = Ex∼q
 
w(x)f(x)
 with"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.578001437814522,w(x) = p(x) q(x).
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5787203450754853,We replace the exact value of I with the value
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5794392523364486,"I =
PN
k=1 w(xi
1)f(xk
1)
PN
i=k w(xk
1)
."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5801581595974119,"It follows from the strong law of large numbers that in the limit N →∞, I →I almost surely. From
678"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5808770668583753,"the central limit theorem we can find the asymptotic variance:
679"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5815959741193386,DI = 1
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.582314881380302,"N Ex∼q
 
w2(x)(f(x) −I)2
.
(25)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5830337886412653,"In our case (loss LExFM), we have q(x1) = ρ1(x1), f(x1) = w(t, x1, x) and w(x1) = ρ0
 
ϕ−1
t,x1(x)

.
680"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5837526959022286,"Despite the fact that the equation (25) for the variance contains N in the denominator, it is rather
681"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5844716031631919,"difficult to give an estimate of its behavior in general. The point is that this formula is well suited for
682"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5851905104241553,"the case when w in it is of approximately the same order. In the considered case, this is achieved at
683"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5859094176851186,"times t noticeably less than 1.
684"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.586628324946082,"But in the case, when t is closed to 1 we have, for example, for the linear map, that"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5873472322070453,"w(x1) = ρ0
 
ϕ−1
t,x1(x)

= ρ0"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5880661394680087,x −x1t 1 −t 
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5887850467289719,"and this function has a sharp peak near the point x/t if it is considered as a function of x1. Thus, at
685"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5895039539899353,"such values of t, only a small number of summands will give a sufficient contribution to the sum
686"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5902228612508986,"compared to the first term.
687"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.590941768511862,"Finally, inequality kD < 1 is formally fulfilled, but how much kD is less than one depends on many
688"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5916606757728253,"factors.
689 690"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5923795830337887,"A.3
Expressions for the regularized map
691"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5930984902947519,"To justify the expression (11), we use a invertable transformation and then strictly take the limit σs →
692"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5938173975557153,"0.
693"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5945363048166786,"Expression Eq. (11), (16) are obtained for the simple map ϕt,x1(x0) = (1 −t)x0 + tx1 which
694"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.595255212077642,"is not invertable at t = 1. For the map with small regaluraziting parameter σs > 0 ϕt,x1(x0) =
695"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5959741193386053,"(1 −t)x0 + tx1 + σsx0, which is invertable at all time values 0 ≤t ≤1, Eq. (11), (16) needs
696"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5966930265995687,"modifications. Namely, for this map the following exact formulas holds true
697"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.597411933860532,"v(x, t) =
Z
w(t, x1, x)ρc(x|x1, t)ρ1(x1) dx1 ="
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5981308411214953,"R  
x1 −x(1 −σs)

ρ0

x−x1t
1+σst−t

ρ1(x1) dx1"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.5988497483824586,"(1 + σst −t)
R
ρ0

x−x1t
1+σst−t

ρ1(x1) dx1
."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.599568655643422,"(26)
By direct substitution we make sure that for this vector field
698"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6002875629043853,"v(x, 0) =
Z
x1ρ1(x1) dx1 −x(1 −σs)
(27)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6010064701653487,"and
699"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.601725377426312,"v(x, 1) ="
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6024442846872753,"R
(x −y)ρ0(y)ρ1(x −yσs) dy
R
ρ0(y)ρ1(x −yσs) dy
,
(28)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6031631919482386,where we perform change of the variables y ←x1−x
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.603882099209202,"σst .
700"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6046010064701653,"A.3.1
Prof of the explicit formula (11) for the vector field
701"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6053199137311287,"Assumption A.1. Density ρ1 is continuous at any point x ∈(−∞, ∞).
702"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.606038820992092,"Theorem A.2. In equations (26), (27) and (28) we can take the limit σs →0 under integrals to get
703"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6067577282530554,"Eq. (11) and (12).
704"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6074766355140186,"Proof. Assuming that the distribution ρ1 has a finite first moment: |
R
ξρ1(ξ) dξ | < C1 and that the
density of ρ0 is bounded: ρ0(x) < C2, ∀x ∈(−∞, ∞), we obtain that the integrand functions in the
numerator and denominator in the Eq. (26) can be bounded by the following integrable functions
independent of σs and t: ρ0"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.608195542774982, x −x1t
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6089144500359454,1 + σs −t
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6096333572969087,"
ρ1(x1) < C1ρ1(x1) and"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6103522645578721,0 ≤x1ρ0
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6110711718188354,"
x −x1t
1 + σst −t"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6117900790797987,"
ρ1(x1) < x1C1ρ1(x1),
x ≥0,"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.612508986340762,0 > x1ρ0
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6132278936017254,"
x −x1t
1 + σst −t"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6139468008626887,"
ρ1(x1) > x1C1ρ1(x1),
x < 0."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6146657081236521,"It follows that both integrals in expression (26) converge absolutely and uniformly. So, we can swap
705"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6153846153846154,"the operations of taking the limit and integration, and we can take the limit σs →0 in the integrand
706"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6161035226455788,"for any time t ∈[0, t0] for arbitrary t0 < 1.
707"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.616822429906542,"Now, let us consider the case t = 1. From Assumption A.1 the boundedness of the density ρ1 follows:
ρ1(x) < C2, ∀x ∈(−∞, ∞). Thus, integrand functions in the numerator and denominator in the
Eq. (28) can be bounded by the following integrable functions independent of σs:"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6175413371675054,"ρ0(y)ρ1(x −yσs) < ρ0(y)C2
and
0 ≤yρ0(y)ρ1(x −yσs) < yC2ρ0(y),
y ≥0,
0 > yρ0(y)ρ1(x −yσs) > yC2ρ0(y),
y < 0.
The existence of the limit
lim
σs→0 ρ1(x −yσs) = ρ1(x),"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6182602444284687,"follows from Assumption A.1.
708"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6189791516894321,"Finally, we conclude that formula (11), regarded as the limit σs →0 of the (26) at any t ∈[0, 1], is
709"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6196980589503954,"true.
710"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6204169662113588,"Theorem A.3. The vector field in Eq. (11) delivers minimum to the Flow Matching objective (see the
work [9]),
EtEx∼ρ(x,t)∥v(x, t) −v(x, t)∥,
where ρ(x, t) and v(x, t) satisfy the equation (1) with the given densities ρ0 and ρ1.
711"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.621135873472322,"Proof. The proof is based on the previous statements and on a Theorem 1 from [9] (that the marginal
712"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6218547807332854,"vector field based on conditional vector fields generates the marginal probability path based on
713"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6225736879942487,"conditional probability paths.
714"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6232925952552121,"To complete the proof, we must justify that, with σs tending to zero, the marginal path at t = 1
715"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6240115025161754,"coincides with a given probability ρ1.
716"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6247304097771388,"Consider the marginal probability path pt(x, t)
717"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6254493170381021,"pt(x, t) =
Z
pt(x|x1, σs)ρ1(x1)dx1
(29)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6261682242990654,"where pt(x|x1, σs) is conditional probability paths obtained by regularized linear conditional map.
718"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6268871315600287,"Distribution pt in the time t = 0 is equal to standard normal distribution p0(x|x1, σs) = N(x | 0, 1)
719"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6276060388209921,"and at the time t = 1 it is a stretched Gaussian centered at x1: p1(x|x1, σs) = N(x | x1, σsI).
720"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6283249460819554,"Substituting p1 into the Eq. (29) and considering that there exists a limit σs →0 due to Assump-
tion A.1, we obtain"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6290438533429188,"p1(x) = lim
σs→0"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6297627606038821,"Z
pt(x|x1, σs)ρ1(x1)dx1 = ρ1(x1)."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6304816678648454,"This finish the proof.
721"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6312005751258087,"A.3.2
Learning procedure for σs > 0
722"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6319194823867721,"Using standard normal distribution as initial density ρ0, and the regularized map ϕt,x1(x0) =
723"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6326383896477354,"(1 −t)x0 + tx1 + σstx0 we obtain the following approximation formula
724"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6333572969086988,"vd(x, t) ="
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6340762041696621,"PN
k=1"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6347951114306255,"xk
1−x(1−σs)
1−t(1−σs) exp
 
Y k"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6355140186915887,"PN
k=1 exp(Y k)
,
where
Y k = −1 2"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6362329259525521,"x −t · xk
1
2
Rd
1 −t(1 −σs) ."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6369518332135155,"In practical applications, the exponent calculation is replaced by the SoftMax function calculation,
725"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6376707404744788,"which is more stable.
726"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6383896477354422,"B
Estimation of integrals
727"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6391085549964055,"In general, we need to estimate the following expression
728"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6398274622573688,I(η) =
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6405463695183321,"R
w(x1, η)f(x1, η)ρ1(x1) dx1
R
f(x1, η)ρ1(x1) dx1
."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6412652767792955,"In particular, substituting η →{x, t}, w(x, η) →(x1 −x)/(1 −t) we obtain formula (11) and
729"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6419841840402588,"similar ones with similar substitutions.
730"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6427030913012222,"If we can sample from the ρ1 distribution, we can estimate this integral in two ways: self-normalized
731"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6434219985621855,"importance sampling and rejection sampling.
732"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6441409058231489,"Let X = {xk
1}N
k=1 be N samples from the distribution ρ1.
733"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6448598130841121,"Self-normalized Importance Sampling
In this case
734"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6455787203450755,"I(η) ≈ N
P"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6462976276060388,"k=1
w(xk
1, η)f(xk
1, η)ρ1(xk
1) dx1 N
P"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6470165348670022,"k=1
f(xk
1, η)ρ1(xk
1) dx1"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6477354421279655,".
(30)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6484543493889289,"This estimate is biased in theory, but there several methods to reduce this bias and improve this
735"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6491732566498921,"estimate, see, for example, [3]. Our numerical experiments generally show that the estimation (30) in
736"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6498921639108555,"the form is already sufficient for stable results; we don not observe any bias.
737"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6506110711718188,"Rejection sampling
Let Y = {yk}M
k=1 ⊂X be a subset of the the initially given set of samples,
which is formed according to the following rule. Let C = supx ρ1(x). For a given sample xj
1 we
generate a random uniformly distributed variable ξj ∼U(0, 1) and if"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6513299784327822,"f(xj
1) ≥Cξj,"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6520488856937455,"then we put the point xj
k to the set Y; otherwise we reject it.
738"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6527677929547089,"Having formed the set Y, we evaluate the integral as
739"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6534867002156722,"I(η) ≈1 M M
X"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6542056074766355,"k=1
w(yk, η)."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6549245147375988,"To justify the last estimation, we note, that the points from the set Y are distributed according
740"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6556434219985622,"to (non-normalized) density ρ(x)f(x, η)ρ1(x). One can show it using the proof of the rejection
741"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6563623292595255,"sampling method. This is the same density as in Eq. (7) and thus we estimate the expression (10)
742"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6570812365204889,"using Important Sampling without any additional denominator.
743"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6578001437814522,"Comparison
When we apply these techniques to evaluating the expression for the vector field, we
744"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6585190510424155,"know that when the time parameter t is close to 1, the function f(x1, η) (which is a scaled ρ0) has a
745"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6592379583033788,"peak at the point x = x1. This means that only a small number of points from the original set will
746"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6599568655643422,"end up in the set Y. Moreover, in the case when the time t is very close to one and the data are well
747"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6606757728253055,"separated, only one point x1 will end up in Y. This explains why we initially put this point in the
748"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6613946800862689,"set X, because otherwise it would be possible that the set Y is empty and M = 0.
749"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6621135873472322,"As a future work, we indicate a theoretical finding of the probability of hitting a particular point x1 in
750"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6628324946081955,"the set Y and, thus, a modification of our algorithm, when the sample x1 will not always go to the
751"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6635514018691588,"set X, but with some probability — the greater the t the closer this probability to 1.
752"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6642703091301222,"C
The main Algorithm and extensions and generalization of the exact
753"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6649892163910855,"expression
754"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6657081236520489,"Algorithm 1 Vector field model training algorithm
Require: Sampler from distribution ρ1 (or a set of samples); parameters n and m (number of spatial
and time points, correspondingly); parameter N (number of averaging point); model vθ(x, t);
algorithm with parameters for SGD
Ensure: quasi-optimal parameters θ for the trained model"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6664270309130123,"1: Initialize θ (maybe random)
2: while exit condition is not met do
3:
Sample m points {tj} from U[0, 1]
4:
Sample n points pairs {xi
0, xi
1}n
i=1 from joint distribution π (π(x0, x1) = ρ0(x0)ρ1(x1) if
variables are independent)
5:
Sample N −n points {ˆxl
1} from ρ1 and form {xk
1} = {xi
1}∪{ˆxl
1} // We can take all available
samples as {xk
1} if we don’t have access to a sampler, but only ready-made samples.
6:
For all i and j calculate the sum at the right side of (14) (using (16) if ρ0 is standard Gaussian
or (24) in general)
7:
Calculate the sum on i and j in discrete loss (14), and take backward derivative, obtaining
approximate grad G ≈∇θLExFM of loss LExFM on model parameters θ.
8:
Update model parameters θ ←SGD(θ, G)
9: end while"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6671459381739756,"General form of the proposed Algorithm is given in Alg 1.
755"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6678648454349388,"When using other maps, formula (11) is modified accordingly. For example, if we use the regularized
756"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6685837526959022,"map ϕt,x1(x0) = (1 −t)x0 + tx1 + σstx0, we get the formula (26).Note, that in this case the
757"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6693026599568656,"final density ρ(x, 1), obtained from the continuity equation is not equal to ρ1, but is its smoothed
758"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6700215672178289,"modification.
759"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6707404744787923,"When using a different initial density ρ0 (not the normal distribution), an obvious modification will
760"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6714593817397556,"be made to formula (16).
761"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6721782890007189,"Diffusion-like models
We can treat so-called Variance Preserving [6] model as CFM with the map"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6728971962616822,"ϕt,x1(x) = α1−tx +
q"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6736161035226456,"1 −α2
1−tx1."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6743350107836089,"and ρ0 as standard normal distribution: ρ0 = N
 
·
 0, 12
In this case, the common expression (10)
762"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6750539180445723,"for vector filed transforms to
763"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6757728253055356,"v(x, t) ="
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.676491732566499,"R
(xα1−t −x1)α′
1−t ρ0"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6772106398274622,"
x−x1α1−t
√"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6779295470884256,"1−α2
1−t"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6786484543493889,"
ρ1(x1) dx1"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6793673616103523,"(1 −α2
1−t)
R
ρ0"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6800862688713156,"
x−x1α1−t
√"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.680805176132279,"1−α2
1−t"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6815240833932422,"
ρ1(x1) dx1
,
(31)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6822429906542056,"where α′
s = dαs"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6829618979151689,"ds .
764"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6836808051761323,Similarity we can treat so-called Variance Exploding [17] model as CFM with the map
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6843997124370956,"ϕt,x1(x) = σ1−tx + x1."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.685118619698059,"and ρ0 also as standard normal distribution: ρ0 = N
 
·
 0, 12
In this case, the common expres-
765"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6858375269590223,"sion (10) for vector filed transforms to
766"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6865564342199856,"v(x, t) ="
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6872753414809489,"R
(x1 −x)σ′
1−t ρ0

x−x1 σ1−t"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6879942487419123,"
ρ1(x1) dx1"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6887131560028756,"σ1−t
R
ρ0

x−x1 σ1−t"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.689432063263839,"
ρ1(x1) dx1
,
(32)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6901509705248023,"where σ′
s = dσs"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6908698777857656,"ds .
767"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6915887850467289,"Joint Distribution
Moreover, in addition to the independent densities x0 ∼ρ0 and x1 ∼ρ1, we
768"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6923076923076923,"can use the joint density {x0, x1} ∼π(x0, x1). In the papers [20, 19], optimal transport (OT)
769"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6930265995686556,"and Schrödinger’s bridge are taken as π. In this case the expression for the vector field changes
770"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.693745506829619,"insignificantly: the conditional probability ρc from Eq. (7) is subject to change:
771"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6944644140905823,"ρc(x|x1, t) =
π
 
ϕ−1
t,x1(x), x1

det

∂ϕ−1
t,x1(x) ∂x "
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6951833213515457,"R
π
 
ϕ−1
t,x1(x), x1

det

∂ϕ−1
t,x1(x) ∂x"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6959022286125089,"
dx1
.
(33)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6966211358734723,"Then, Eq. (10) remains the same in general case. In the case of linear ϕ, the extension of Eq. (11)
772"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6973400431344356,"reads
773"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.698058950395399,"v(x, t) ="
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6987778576563624,"R
(x1 −x) π
 
ϕ−1
t,x1(x), x1

det

∂ϕ−1
t,x1(x) ∂x 
dx1"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.6994967649173257,"(1 −t)
R
π
 
ϕ−1
t,x1(x), x1

det

∂ϕ−1
t,x1(x) ∂x"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.700215672178289,"
dx1
.
(34)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7009345794392523,"In all of the above cases, the essence of Algorithm 1 does not change (except that in the case of
774"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7016534867002157,"dependent x0 and x1 we should be able either to calculate the value of π
 
ϕ−1
t,x1(x), x1

/ρ1(x1) or to
775"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.702372393961179,"estimate it).
776"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7030913012221424,"D
Several analytical results, following from the explicit formula
777"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7038102084831057,"In this section, we present several analytical results that directly follow from our exact formulas for
778"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7045291157440691,"the vector field, which, to the best of our knowledge, have not been published before.
779"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7052480230050323,"D.1
Exact path from one Gaussian to another Gaussian
780"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7059669302659957,"Consider the flow from a one-dimensional Gaussian distribution ρ0 ∼N
 
·
 µ0, σ2
0

into another (with
781"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.706685837526959,"other parameters) Gaussian distribution ρ1 ∼N
 
·
 µ1, σ2
1

. Note that in this case the generalization
782"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7074047447879224,"to the multivariate case is done directly, so the spatial variables are separated.
783"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7081236520488857,"From the general formula (11) we have:
784"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7088425593098491,"v(x, t) ="
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7095614665708123,"R
(x1 −x)N

x−tx1"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7102803738317757,"1−t
 µ0, σ2
0

N
 
x1
 µ1, σ2
1

dx1"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.710999281092739,"(1 −t)
R
N

x−tx1"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7117181883537024,"1−t
 µ0, σ2
0

N (x1| µ1, σ2
1) dx1
. = ="
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7124370956146657,"R
(x1 −x) exp

−
  x−tx1"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7131560028756291,"1−t −µ0
2/(2σ2
0) −(x1 −µ1)2/(2σ2
1)

dx1"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7138749101365924,"(1 −t)
R
exp

−
  x−tx1"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7145938173975557,"1−t −µ0
2/(2σ2
0) −(x1 −µ1)2/(2σ2
1)

dx1
."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.715312724658519,"Both integrals in the last expression are taken explicitly:
785"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7160316319194824,"Z
N
x −tx1 1 −t"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7167505391804457,"µ0, σ2
0"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7174694464414091,"
N
 
x1
 µ1, σ2
1

dx1 ="
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7181883537023724,"=
exp

−(x−µ0(1−t)−µ1t)2"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7189072609633357,"2(σ2
1t2+σ2
0(1−t)2)  √ 2π
q"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.719626168224299,"σ2
0 +
σ2
1t2"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7203450754852624,"(t−1)2
= N

x
1 −t"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7210639827462257,µ0(1 −t) + µ1t
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7217828900071891,"1 −t
, σ2
0 +
σ2
1t2"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7225017972681524,"(t −1)2 
."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7232207045291158,"Note that the last relation can be obtained as a distribution of two Gaussian random variables with
786"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.723939611790079,"corresponding parameters.
787"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7246585190510424,"The second integral:
788"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7253774263120057,Z x1 −x
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7260963335729691,"1 −t N
x −tx1 1 −t"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7268152408339325,"µ0, σ2
0"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7275341480948958,"
N
 
x1
 µ1, σ2
1

dx1 ="
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.728253055355859,"=
exp

−(x−µ0(1−t)−µ1t)2"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7289719626168224,"2(σ2
1t2+σ2
0(1−t)2)  √ 2π"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7296908698777858,"(1 −t)
 
σ2
1t(x −µ0) + σ2
0(t −1)(x −µ1)
"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7304097771387491,"(σ2
1t2 + σ2
0(1 −t)2)3/2
."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7311286843997125,"Thus, in the considered case we can explicitly write the expression for the vector field v:
789"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7318475916606758,"v(x, t) = σ2
1t(x −µ0) −σ2
0(1 −t)(x −µ1)
σ2
1t2 + σ2
0(1 −t)2
.
(35)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.732566498921639,"For this vector field we can explicitly solve the equation for the path x(t) starting from the arbitrary
790"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7332854061826024,"point x0
791

  ∂x(t)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7340043134435658,"∂t
= v(x(t), t),"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7347232207045291,"x(0) = x0
."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7354421279654925,"The solution is:
792"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7361610352264558,"x(t) = (1 −t)µ0 + tµ1 + (x0 −µ0)
p"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7368799424874192,"(σ1/σ0)2t2 + (1 −t)2.
(36)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7375988497483824,"Note that although this solution does not correspond to the Optimal Transport joint distribution, since
793"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7383177570093458,"the obtained path is not a straight line in general, (i. e. we do not have a solution to the Kantorovich’s
794"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7390366642703091,formulation of the OT problem) the endpoint x(1) = µ1 + (x0 −µ0)σ1
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7397555715312725,"σ0
falls exactly in the one that
795"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7404744787922358,"is optimal if we solve the OT problem in the Monge formultation. Thus, the map x(0) →x(1) is the
796"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7411933860531992,"OT map for the case of 2 Gaussian.
797"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7419122933141624,"See the Fig. 4 for the examples of the paths for the obtained solution.
798"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7426312005751258,"D.2
From one Gaussian to Gaussian Mixture
799"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7433501078360891,"Let initial distribution be standard Gaussian ρ0 = N
 
·
 0, 12
, and the target distribution be Gaussian
800"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7440690150970525,"Mixture (GM) of two symmetric Gaussians: ρ1(x) = 1/2(N
 
x
 µ, σ2
) + N
 
x
 −µ, σ2
), In this
801"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7447879223580158,"0.2
0.4
0.6
0.8
1.0 t -2 2 4 6 8 x(t)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7455068296189792,"(a) Trajectories
(b) Vector field"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7462257368799425,"Figure 4: a) N = 40 random trajectories from from N
 
·
 0, 12
to N
 
·
 2, 32
; (b) 2D plot of the
vector field in this case"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7469446441409058,"case, we can obtain exact form for v
802"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7476635514018691,"v(x, t) =
exp

−µ2"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7483824586628325,"2σ2 +
µ2t2+x2"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7491013659237958,"σ2t2+(t−1)2 −
x2
2(t−1)2
"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7498202731847592,"(σ2t2 + (t −1)2)

e"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7505391804457225,(x−µt)2
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7512580877066858,2(σ2t2+(t−1)2) + e
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7519769949676491,(µt+x)2
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7526959022286125,"2(σ2t2+(t−1)2)
× """
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7534148094895758,µ(t −1)  exp
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7541337167505392," 
µ(t −1)2 −σ2tx
 2"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7548526240115025,2σ2(t −1)2 (σ2t2 + (t −1)2) ! −exp
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7555715312724659," 
µ(t −1)2 + σ2tx
 2"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7562904385334291,2σ2(t −1)2 (σ2t2 + (t −1)2) !! +
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7570093457943925,"+x
 
σ2t + t −1
 exp"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7577282530553558," 
µ(t −1)2 −σ2tx
 2"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7584471603163192,2σ2(t −1)2 (σ2t2 + (t −1)2) ! + exp
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7591660675772826," 
µ(t −1)2 + σ2tx
 2"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7598849748382459,"2σ2(t −1)2 (σ2t2 + (t −1)2) !!# , (37)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7606038820992091,"but the expression for the path x(t) is unknown.
803"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7613227893601725,"0.2
0.4
0.6
0.8
1.0 t -3 -2 -1 1 2 3 x(t)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7620416966211359,"(a) Trajectories
(b) Vector field"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7627606038820992,"Figure 5: a) N = 80 random trajectories from N
 
·
 0, 12
to GM of N
 
·
 −2, 1/22
and
N
 
·
 2, 1/22
; (b) 2D plot of the vector field in this case"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7634795111430626,"Numerically solution of the differential equation with the obtained vector field give the trajectories
804"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7641984184040259,"shown in Fig. 5.
805"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7649173256649893,"D.3
From Gaussian to Gaussian with stochastic
806"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7656362329259525,"Using Eq. (44)-(46) we can explicitly calculate vector field v and score s with the setup as in Sec. D.1
807"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7663551401869159,"but with additional noise, i. e. in the stochastic case.
808"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7670740474478792,"D.3.1
Gaussian to Gaussian with noise
809"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7677929547088426,"Consider like in the Sec. D.1 the flow from a one-dimensional standard Gaussian distribution
810"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7685118619698059,"ρ0 ∼N
 
·
 0, 02
into another (with other parameters) Gaussian distribution ρ1 ∼N
 
·
 µ1, σ2
1

but
811"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7692307692307693,"with additional noise as described above.
812"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7699496764917325,"In this case we have for the field.
813"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7706685837526959,"v(x, t) = x
 
tσ2
1 + (1 −t)σ2
e/2

−(x −µ1)
 
(1 −t) + tσ2
e/2
"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7713874910136592,"t(1 −t)σ2e + σ2
1t2 + (1 −t)2
(38)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7721063982746226,"We can solve ODE with this field and get the expression for the trajectories, starting from the given
814"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7728253055355859,"point x0:
815"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7735442127965493,"x(t) = µ1t + x0
q"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7742631200575126,"t(1 −t)σ2e + σ2
1t2 + (1 −t)2.
(39)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7749820273184759,"These trajectories, for different x0 are depicted in Fig. 6."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7757009345794392,"0.2
0.4
0.6
0.8
1.0 t -5 5 10 x(t)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7764198418404026,"(a) Trajectories, σe = 0.3
(b) Vector field,
σe = 0.3"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7771387491013659,"0.2
0.4
0.6
0.8
1.0 t -5 5 10 x(t)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7778576563623293,"(c) Trajectories, σe = 1
(d) Vector field,
σe = 1"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7785765636232926,"0.2
0.4
0.6
0.8
1.0 t -5 5 10 x(t)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7792954708842559,"(e) Trajectories, σe = 3
(f) Vector
field,
σe = 3"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7800143781452192,"0.2
0.4
0.6
0.8
1.0 t -5 5 10 x(t)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7807332854061826,"(g) Trajectories, σe = 10
(h) Vector field,
σe = 10"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7814521926671459,"Figure 6: a) N = 40 random trajectories from N
 
·
 0, 12
to N
 
·
 2, 32
and 2D plot of the vector
field in this case for different σe 816"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7821710999281093,"At the limit σe →0 expressions (38) and (39) turn into expressions (35) and (36) as expected.
817"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7828900071890726,"For the score s in the considered case we have
818"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.783608914450036,"s(x, t) =
tµ1 −x
(1 −t)2 + t(1 −t)σ2e + t2σ2
1"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7843278217109992,"Thus, we can explicitly write expressions for the stochastic process for the evolution from the initial
819"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7850467289719626,"distribution rho0 (standard Gaussian) to the final distribution ρ1:
820"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.785765636232926,dx(x) =
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7864845434938893,"""
x
 
tσ2
1 + (1 −t)σ2
e/2

−(x −µ1)
 
(1 −t) + tσ2
e/2
"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7872034507548527,"t(1 −t)σ2e + σ2
1t2 + (1 −t)2
+"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.787922358015816,+ g2(t)
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7886412652767792,"2
tµ1 −x
(1 −t)2 + t(1 −t)σ2e + t2σ2
1"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7893601725377426,"
dt + g(t) dW(t) ."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.790079079798706,"Here g(t) is arbitrary smooth function. In the case of Shrödinger Bridge we take g(t) = σe
p"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7907979870596693,"t(1 −t).
821"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7915168943206327,"E
Detail on the SDE case
822"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.792235801581596,"E.1
Optimal vector field and score for stochastic map
823"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7929547088425594,"Following [20] we consider a so-called Brownian bridge B(t) from x0 to x1 with constant diffusion
824"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7936736161035226,"rate σe. This stochastic process can be expressed through a multidimensional standard Winner
825"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.794392523364486,"process W(t) as
826"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7951114306254493,"B(t | x0, x1) = (1 −t)x0 + tx1 + σe(1 −t)W

t
1 −t"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7958303378864127,"
.
(40)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.796549245147376,"Thus, the conditional distribution p(t, x | x0, x1) conditioned on the starting x0 and end point x1 is
827"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7972681524083394,"Gaussian:
828"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7979870596693026,"p(x, t | x0, x1) = N
 
x
 (1 −t)x0 + tx1, σ2
et(1 −t)

."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.798705966930266,"We can not directly use the results Theorem 3 from [9] (or similar Theorem 2.1 from [19] ) for
829"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.7994248741912293,"the Gaussian paths, as in this case σ(0) = 0. To circumvent this obstacle and to be able to write
830"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8001437814521927,"an expression for the conditional velocity, we assume that we have a Gaussian distribution with a
831"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.800862688713156,"very narrow peak at the initial (t = 0) and final (t = 1) points. In other words, we will consider
832"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8015815959741194,"conditional probabilities of the form
833"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8023005032350827,"p(x, t | x0, x1) = N
 
x
 (1 −t)x0 + tx1, σ2
e(t + η)(1 −t + η)

,
(41)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.803019410496046,"where parameter η is small enough. Then we can use the above Theorems and immediately write
834"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8037383177570093,"vx0,x1(x, t) = σ′(t)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8044572250179727,"σ(t)
 
x−µ(t)

+µ′(t) =
1 −2t
2(t + η)(1 −t + η)
 
x−(1−t)x0−tx1

+x1−x0. (42)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.805176132278936,"After integrating over x0 and x1, we can take the limit η →0. Thus, now for fixed x0 and x1 we do
835"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8058950395398994,"not have a fixed value of xt in which to train the model, but a random one. In general case, we end up
836"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8066139468008627,"to the loss:
837"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.807332854061826,"Lv = Et∼U(0,1), {x1,x0}∼π, x∼p(·,t|x0,x1)∥vθ(x, t) −vx0,x1(x, t)∥2,
(43)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8080517613227893,"where π(x1, x0) is the density of the joint distributions with the marginal equal to the two given
838"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8087706685837527,"probabilities:
839
Z
π(x1, x0) dx1 = ρ0(x0),
Z
π(x1, x0) dx0 = ρ1(x1)."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.809489575844716,"In the simple case, π(x1, x0) = ρ0(x0)ρ1(x1). Vector field in Eq. (43) if taken in the form of
840"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8102084831056794,"Eq. (42).
841"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8109273903666427,"Now, we can obtain an explicit form for the vector field v at which the written loss is reached its
842"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.811646297627606,"minimum by performing the same calculations as in the derivation of formula (10):
843"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8123652048885693,"v(x, t) ="
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8130841121495327,"RR
vx0,x1(x, t) p(x, t | x0, x1) π(x0, x1) dx0 dx1
RR
p(x, t | x0, x1) π(x0, x1) dx0 dx1
.
(44)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.813803019410496,"As in the work [20] we can also train score network. Namely, as marginals for Brownian bridge are
844"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8145219266714594,"Gaussian, we can write explicit conditional score for conditional probabilistic path
845"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8152408339324227,"∇log p(x, t | x0, x1) = µ(t) −x"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8159597411933861,"σ2e(t)
= x0(1 −t) + x1t −x"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8166786484543493,"σ2et(1 −t)
."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8173975557153127,"In the work [20] the following loss is introduced to train a model for this score
846"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.818116462976276,"Ls = Et∼U(0,1), {x1,x0}∼π, x∼p(·,t|x0,x1)∥sθ(x, t) −∇log p(x, t | x0, x1)∥2.
(45)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8188353702372394,"Similar to (44), for the optimal score s we have:
847"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8195542774982028,"s(x, t) ="
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8202731847591661,"RR
∇log p(x, t | x0, x1) p(x, t | x0, x1) π(x0, x1) dx0 dx1
RR
p(x, t | x0, x1) π(x0, x1) dx0 dx1
,
(46)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8209920920201293,"where p is given in (41).
848"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8217109992810927,"E.2
Use stochastic
849"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.822429906542056,"Note that the obtained vector field gives marginal distributions p(x, t), which (in the limit η →0) at
850"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8231488138030194,"t = 1 leads to the distribution we need: p(x, t = 1) = ρ1(x). However, the addition of the stochastic
851"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8238677210639828,"term allows us to extend the scope of application of the explicit formula for the vector field. In
852"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8245866283249461,"particular, it can be applied to the situation when we have two sets of samples and both distributions
853"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8253055355859095,"are unknown, as well as the possibility of constructing SDE and solving it using, for example, the
854"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8260244428468727,"Euler–Maruyama method (see examples below).
855"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8267433501078361,"As consequence of Theorem 3.1 from [20] we have that, if v is given by Eq. (44) then ODE
856"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8274622573687994,"∂ρ(x, t)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8281811646297628,"∂t
= −div
 
ρ(x, t)v(x, t)

(47)"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8289000718907261,"recovers the marginal ρ(x, t) (with the given initial conditions) of the stochastic process P(t) which
857"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8296189791516895,"is obtained by marginalization conditional Brownian bridge (40) over initial and target distribution
858"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8303378864126527,"P(t) =
Z
B(t | x0, x1)π(x0, x1) dx0 dx1 ."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8310567936736161,"As the second consequence of this Theorem, the SDE
859"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.8317757009345794,"dx(t) =

v
 
x(t), t

+ g2(t)"
S,0.8324946081955428,"2
s
 
x(t), t

dt + g(t) dW(t)
(48)"
S,0.8332135154565061,"generates so-called Markovization of the process P(t). Indeed, we can rewrite PDE Eq. (47) in the
860"
S,0.8339324227174695,"form
861"
S,0.8346513299784328,"∂ρ(x, t)"
S,0.8353702372393961,"∂t
= −div

ρ(x, t)v(x, t) + g2(t)"
S,0.8360891445003594,"2
∇ρ(x, t)

+ g2(t)"
S,0.8368080517613228,"2
∆ρ(x, t),"
S,0.8375269590222861,"where nabla operator is defined as ∆= div ∇. Thus, we get the Fokker–Planck equation for the
862"
S,0.8382458662832495,"density of the stochastic process (48).
863"
S,0.8389647735442128,"E.3
Particular cases
864"
S,0.8396836808051761,"In particular case of Brownian bridge when σe(t) = σϵ
p"
S,0.8404025880661394,"t(1 −t), then σ′
e(t) = σϵ(1 −
865"
S,0.8411214953271028,"2t)/
 
2
p"
S,0.8418404025880661,"t(1 −t)

. In this section we consider simple case of separable variables π(x0, x1) =
866"
S,0.8425593098490295,"ρ0(x0)ρ1(x1).
867"
S,0.8432782171099928,"E.3.1
Gaussian initial distribution
868"
S,0.8439971243709562,"In the case, when ρ0 is standard Gaussian distribution: ρ0 = N
 
·
 0, 12
, we can take integral
869"
S,0.8447160316319194,"on x0 and then take the limit η →0 in the expressions for v and s. First, consider the expression
870"
S,0.8454349388928828,"for v: where we use explicit expression (41) for conditional density path and Eq. (42) for conditional
871"
S,0.8461538461538461,"velocity:
872"
S,0.8468727534148095,"v(x, t) ="
S,0.8475916606757729,"R
w(x, t | x1)N
 
x
 x1t, σ2
et(1 −t) + (1 −t)2
ρ1(x1)dx1
R
N (x| x1t, σ2et(1 −t) + (1 −t)2) ρ1(x1)dx1
= ="
S,0.8483105679367362,"R
w(x, t | x1)ρ0

x−x1t
√"
S,0.8490294751976994,"σ2et(1−t)+(1−t)2

ρ1(x1)dx1
R
ρ0

x−x1t
√"
S,0.8497483824586628,"σ2et(1−t)+(1−t)2

ρ1(x1)dx1
,
(49)"
S,0.8504672897196262,"where w(x, t | x1) is the conditional velocity, generated by the conditional map ϕt,x1(x) =
873
p"
S,0.8511861969805895,"σ2et(1 −t) + (1 −t)2 + tx1:
874"
S,0.8519051042415529,"w(x, t | x1) =
x1 −x
1 −t + tσ2e
+ σ2
e
(1 −2t)x + tx1
2
 
(1 −t)2 + (1 −t)tσ2e
."
S,0.8526240115025162,"Thus, note that in the case of Gaussian distributions, all the difference between this expression and
875"
S,0.8533429187634796,"the expression without the stochastic part is the appearance of additional (time-dependent, in general)
876"
S,0.8540618260244428,"variance. Marginal distributions are still Gaussian’s.
877"
S,0.8547807332854062,"Similar, using Eq. (46) we have for the score s:
878"
S,0.8554996405463695,"s(x, t) ="
S,0.8562185478073329,"R
(tx1 −x)N
 
x
 x1t, σ2
et(1 −t) + (1 −t)2
ρ1(x1)dx1
 
(1 −t)2 + (1 −t)tσ2e
 R
N (x| x1t, σ2et(1 −t) + (1 −t)2) ρ1(x1)dx1
= ="
S,0.8569374550682962,"R
(tx1 −x)ρ0

x−x1t
√"
S,0.8576563623292596,"σ2et(1−t)+(1−t)2

ρ1(x1)dx1
 
(1 −t)2 + (1 −t)tσ2e
 R
ρ0

x−x1t
√"
S,0.8583752695902228,"σ2et(1−t)+(1−t)2

ρ1(x1)dx1
.
(50)"
S,0.8590941768511862,"E.3.2
Samples instead of distributions
879"
S,0.8598130841121495,"Consider the case where we only have access to the samples {xi
0}N0
i=1 and {xi
1}N1
i=1 from both
880"
S,0.8605319913731129,"distributions, ρ0 and ρ1, but do not know their explicit expressions. In this case, we can estimate the
881"
S,0.8612508986340762,"vector field using by a method similar to the one we used to estimate the vector field in (15):
882"
S,0.8619698058950396,"v(x, t) ≈"
S,0.8626887131560029,"PN0
i=1
PN1
j=1 vxi
0,xj
1(x, t) p(x, t | xi
0, xj
1)
PN0
i=1
PN1
j=1 p(x, t | xi
0, xj
1)
.
(51)"
S,0.8634076204169662,"Similar for the score
883"
S,0.8641265276779295,"s(x, t) ≈"
S,0.8648454349388929,"PN0
i=1
PN1
j=1 ∇p(x, t | xi
0, xj
1) p(x, t | xi
0, xj
1)
PN0
i=1
PN1
j=1 p(x, t | xi
0, xj
1)
.
(52)"
S,0.8655643421998562,"In addition, we can also use the importance sampling method in this case. Namely we can use
884"
S,0.8662832494608196,"both approaches: self-normalized importance sampling and rejection sampling, similar to what is
885"
S,0.8670021567217829,"described in Sec. B
886"
S,0.8677210639827462,"F
Consistency of Eq. (24) in the case of optimal transport
887"
S,0.8684399712437095,"Let us analyze what happens if in formula (24) the joint density π represents the following Dirac
delta-function4:
π(x0, x1) = δ
 
x0 −F(x1)

,"
S,0.8691588785046729,"i. e. we have a deterministic mapping F from x1 to x0. Then, the Eq. (34) come to
888"
S,0.8698777857656362,"v(x, t) ="
S,0.8705966930265996,"R
(x1 −x) δ
 
ϕ−1
t,x1(x) −F(x1)

dx1
(1 −t)
R
δ
 
ϕ−1
t,x1(x) −F(x1)

dx1
."
S,0.8713156002875629,"Let y(x, t) be the unique solution of the equation
889"
S,0.8720345075485263,"ϕ−1
t,y(x) = F(y),
(53)"
S,0.8727534148094895,considered as an equation on y. Then
S,0.8734723220704529,"v(x, t) = x −y(x, t)"
S,0.8741912293314162,"1 −t
."
S,0.8749101365923796,"Now, let us use linear mapping ϕt,x1(x) = x1t + x(1 −t), with inverse ϕ−1
t,x1(x) = x−tx1"
S,0.875629043853343,"1−t , and
consider the simplest case when the original distribution is a d-dimensional standard Gaussian and ρ1
is a d-dimensional Gaussian with mean µ and diagonal variance Σ = diag(σ). We know the OT
correspondence between Gaussians, namely"
S,0.8763479511143063," 
F(x1)
"
S,0.8770668583752695,i = (x1 −µ)i
S,0.8777857656362329,"Σii
,
∀1 ≥i ≥d."
S,0.8785046728971962,"4Further reasoning is not absolutely rigorous, and in order not to introduce the axiomatics of generalized
functions, we can assume that the delta function is the limit of the density of a normal distribution with mean 0
and variance tending to zero."
S,0.8792235801581596,"Here and further by index i we denote ith component of the corresponding vector. Then, the Eq. (53)
reads as
(x −yt)i"
S,0.879942487419123,"1 −t
= (y −µ)i Σii
,"
S,0.8806613946800863,"with the solution
 
y(x, t)
"
S,0.8813803019410497,i = µi(1 −t) + xiΣii
S,0.8820992092020129,1 + (Σii −1)t .
S,0.8828181164629763,Then the expression for the vector field is
S,0.8835370237239396," 
v(x, t)
"
S,0.884255930984903,i = µi + xi(Σii −1)
S,0.8849748382458663,1 + (Σii −1)t .
S,0.8856937455068297,"Now, knowing the expression for velocity, we can write the equations for the trajectories x(t):

 "
S,0.8864126527677929," 
x′(t)
"
S,0.8871315600287563,i = µi + (x(t))i(Σii −1)
S,0.8878504672897196,"1 + (Σii −1)t
,"
S,0.888569374550683,x(0)i = (x0)i .
S,0.8892882818116463,This equation have closed-form solution:
S,0.8900071890726097,x(t) = µt + x0 −(1 −σ) tx0.
S,0.8907260963335729,"Analyzing the obtained solution, we conclude that, first, the trajectories obey the given mapping F:"
S,0.8914450035945363," 
F(x(1))
"
S,0.8921639108554996,"i = (x0)i = (x(1) −µ)i Σii
,"
S,0.892882818116463,"And, second, the trajectories are straight lines (in space), as they should be when the flow carries
890"
S,0.8936017253774263,"points along the optimal transport.
891"
S,0.8943206326383897,"As a final conclusion, note that, of course, if we are mapping optimal transport F, then it is meaning-
892"
S,0.895039539899353,"less to use numerical formula (16). However, usually the exact value of the mapping F is not known,
893"
S,0.8957584471603163,"and our theoretical formula (34) can help to rigorously establish the error that is committed when an
894"
S,0.8964773544212796,"approximate mapping is used instead of the optimal one.
895"
S,0.897196261682243,"G
Analytical derivations for example in Fig. 1(b)
896"
S,0.8979151689432063,"G.1
CFM dispersion
897"
S,0.8986340762041697,"To derive the analytical expression for the optimal flow velocity in the case of two normal distributions
898"
S,0.899352983465133,"ρ0 ∼N(0, I) and ρ1 ∼N(µ, σ2I), we start by substituting µ0 = 0, σ0 = 1, µ1 = µ, σ1 = σ, to the
899"
S,0.9000718907260963,"exact expression (35) to get
900"
S,0.9007907979870596,"v(x, t) =
tσ2 + t −1
(1 −t)2 + t2σ2 x +
1
(1 −t)2 + t2σ2 (µ −tµ) = w(t)x + C,
(54) where"
S,0.901509705248023,"w(t) =
tσ2 + t −1
(1 −t)2 + t2σ2 ,"
S,0.9022286125089863,"and C is constant independent of x. We then redefine the dispersion based on Eq. (19) using
901"
S,0.9029475197699497,"x = (1 −t)x0 + tx1 with x0 ∼ρ0 and x1 ∼ρ1:
902"
S,0.903666427030913,"Dx,x1f(x, x1) = Dx0,x1f
 
(1 −t)x0 + tx1, x1

(55)"
S,0.9043853342918764,"This leads us to the final expression:
903"
S,0.9051042415528396,"Dx,x1∆v(x, t) = Dx0,x1((1 −w(t))x1 −(1 + w(t)(1 −t))x0) ="
S,0.905823148813803,= (1 + w(t)(1 −t))2Dx0x0 + (1 −w(t))2Dx1x1.
S,0.9065420560747663,"This provides a comprehensive representation of the updated dispersion for the CFM objective at any
904"
S,0.9072609633357297,"given time t.
905"
S,0.907979870596693,"Algorithm 2 Computation ExFM dispersion algorithm
Require: Density function for initial distribution ρ0; sampler for target distribution ρ1; parameter
M (number of samples for evaluation); parameter N (number of samples from ρ1 for certain
samples x ∼ρm(x, t)); optimal model v(x, t); time for evaluation t.
Ensure: numerical evaluation of dispersion update for ExFM objective"
S,0.9086987778576564,"1: Sample (M · N) samples xi,j
1 from ρ1, where i ∈[1, M] and j ∈[1, N]
2: Sample (M) samples xi
0 from ρ0, where i ∈[1, M]
3: Compute points xi as (1 −t)xi
0 + txi,0
1"
S,0.9094176851186196,"4: Compute vd(xi, t) =
N
P"
S,0.910136592379583,"j=1
˜ρi,j(t) xi,j
1 −xi"
S,0.9108554996405464,"1−t
, where ˜ρi,j(t) = ρ0

xi−txi,j
1
1−t

/
N
P"
S,0.9115744069015097,"j=1
ρ0

xi−txi,j
1
1−t
"
S,0.9122933141624731,"5: Compute and return dispersion Di(v(xi, t) −vd(xi, t))"
S,0.9130122214234364,"G.2
ExFM dispersion
906"
S,0.9137311286843998,"The analytical derivation of the updated dispersion for the ExFM objective proves to be complex in
907"
S,0.914450035945363,"practice. Therefore, for the example at hand, a numerical scheme was employed for evaluation. The
908"
S,0.9151689432063264,"procedure outlined in Alg. 2 was utilized for this task. The experiment’s parameters for the algorithm
909"
S,0.9158878504672897,"were as follows: M = 200k, N = 128, ρ0 = N(0, I), ρ1 = N(µ, σ2I), and the optimal model
910"
S,0.9166067577282531,"v(x, t) was derived from equation (54).
911"
S,0.9173256649892164,"H
Additional Experiments
912"
S,0.9180445722501798,"H.1
2D toy examples
913"
S,0.918763479511143,"To ensure the reliability and impartiality of the outcomes, we carried out the experiment under
914"
S,0.9194823867721064,"uniform conditions and parameters. Initially, we generated a training set of batch size N = 10,000
915"
S,0.9202012940330697,"points. The employed model was a simple Multilayer Perceptron with ReLu activations and 2 hidden
916"
S,0.9209202012940331,"layers of 512 neurons, Adam optimizer with a learning rate of 10−3, and no learning rate scheduler.
917"
S,0.9216391085549964,"We determined the number of iteration steps equal to 10000. Subsequently, we configured the mini
918"
S,0.9223580158159598,"batch size n = 256 during the training procedure, with the primary objective of minimizing the Mean
919"
S,0.9230769230769231,"Squared Error (MSE) loss. The full training algorithm and notations can be seen in Algorithm 1. To
920"
S,0.9237958303378864,"perform sampling, we employed the function odeint with dopri5 method from the python package
921"
S,0.9245147375988497,"torchdiffeq import odeint with atol and rtol equal 1e −5.
922"
S,0.9252336448598131,"H.2
Tabular
923"
S,0.9259525521207764,"The power dataset (dimension = 6, train size = 1659917, test size = 204928) consisted of electric
924"
S,0.9266714593817398,"power consumption data from households over a period of 47 months. The gas dataset (dimension
925"
S,0.9273903666427031,"= 8, train size = 852174, test size = 105206) recorded readings from 16 chemical sensors exposed
926"
S,0.9281092739036664,"to gas mixtures. The hepmass dataset (dimension = 21, train size = 315123, test size = 174987)
927"
S,0.9288281811646297,"described Monte Carlo simulations for high energy physics experiments. The minibone (dimension
928"
S,0.9295470884255931,"= 43, train size = 29556, test size = 3648) dataset contained examples of electron neutrino and muon
929"
S,0.9302659956865564,"neutrino. Furthermore, we utilized the BSDS300 dataset (dimension = 63, train size = 1000000, test
930"
S,0.9309849029475198,"size = 250000), which involved extracting random 8 x 8 monochrome patches from the BSDS300
931"
S,0.9317038102084831,"datasets of natural images [11].
932"
S,0.9324227174694465,"These diverse multivariate datasets are selected to provide a comprehensive evaluation of performance
933"
S,0.9331416247304097,"across various domains. To maintain consistency, we followed the code available at the given GitHub
934"
S,0.9338605319913731,"link5 to ensure that the same instances and covariates were used for all the datasets.
935"
S,0.9345794392523364,"To ensure the correctness of the experiments we conduct them with the same parameters. To train
936"
S,0.9352983465132998,"the model we use the same MultiLayer Perceptron (1024 x 3) model with ReLu activations, Adam
937"
S,0.9360172537742631,"as optimizer with learning rate of 10−3 and no learning rate scheduler. As in the pretrained step,
938"
S,0.9367361610352265,"we use separately training and testing sets for training the model and calculating metrics. We train
939"
S,0.9374550682961897,"the models on the full dataset (of size train_set_size) with batch size N = 5000 (batch_size)
940"
S,0.9381739755571531,5https://github.com/gpapamak/maf
S,0.9388928828181164,"Figure 7: Training loss comparison for ExFM, CFM and OT-CFM methods over 10 000 learning
steps."
S,0.9396117900790798,"(except miniboone dataset, here we used 2000 since the smaller size of the dataset) and mini
941"
S,0.9403306973400432,"batches n = 256 elements (mini_batch_size), the number of epochs and steps for each dataset
942"
S,0.9410496046010065,"is adaptive num_epochs = train_set_size // batch_size and num_steps = batch_size
943"
S,0.9417685118619699,"// mini_batch_size.
944"
S,0.9424874191229331,"For both 2D-toy an tabular data: we take m = n time variable, individual value of variable t
945"
S,0.9432063263838965,"corresponds to its pair (x0, x1). The notations N, n and m corresponds to those in Algorithm 1. To
946"
S,0.9439252336448598,"perform sampling, we employed the function odeint with dopri5 method from the python package
947"
S,0.9446441409058232,"torchdiffeq import odeint with atol and rtol equal 1e −5.
948"
S,0.9453630481667865,Table 5: Learning parameters for Tabular datasets.
S,0.9460819554277499,"DATA
MLP LAYERS
LR"
S,0.9468008626887131,"POWER
[512, 1024, 2048]
1E-3
GAS
[512, 1024,1024]
1E-4
HEPMASS
[512, 1024]
1E-3
BSDS300
[512, 1024,1024]
1E-4
MINIBOONE
[512, 1024]
1E-3"
S,0.9475197699496765,"Table 6: NLL comparison for ExFM, CFM and OT-CFM methods over 10 000 learning steps, mean
and std taken from 10 sampling iterations."
S,0.9482386772106398,"DATA
EXFM
CFM
OT-CFM"
S,0.9489575844716032,"POWER
-8.51e-02 ± 4.85e-02
1.64E-01 ± 4.18E-02
5.22E-02 ± 3.92E-02
GAS
-5.53e+00 ± 3.66e-02
-5.00E+00 ± 2.56E-02
-5.48E+00 ± 2.90E-02
HEPMASS
2.16E+01 ± 6.31E-02
2.21e+01 ± 6.13e-02
2.16E+01 ± 4.32E-02
BSDS300
-1.29E+02 ± 8.40E-01
-1.29E+02 ± 8.97E-01
-1.32e+02 ± 6.39e-01
MINIBOONE
1.34e+01 ± 1.95e-04
1.42E+01 ± 1.29E-04
1.43E+01 ± 9.22E-05"
S,0.9496764917325665,"H.3
ExFM-S evaluation
949"
S,0.9503953989935299,"The models were assessed using four toy datasets of two dimensions each. A three-layer MLP
950"
S,0.9511143062544932,"network was utilized, featuring SeLU activations and a hidden dimension of 64. Optimization was
951"
S,0.9518332135154565,"carried out using the AdamW optimizer with a learning rate of 10−3 and a weight decay of 10−5.
952"
S,0.9525521207764198,"Figure 8: NLL comparison for ExFM, CFM and OT-CFM methods over 10 000 learning steps, mean
and std for range taken from 10 sampling iterations."
S,0.9532710280373832,"Figure 9: Training loss comparison for ExFM, CFM and OT-CFM methods, CIFAR-10 dataset."
S,0.9539899352983465,"The model was trained over 2,000 iterations with a batch size of 128. Inference was conducted using
953"
S,0.9547088425593099,"the Euler solver for Ordinary Differential Equations (ODE) with 100 steps. To validate the models,
954"
S,0.9554277498202732,"the POT library was employed to compute the Wasserstein distance based on 4,000 samples. The
955"
S,0.9561466570812365,"experiments were performed on a single Nvidia H100 GPU with 80gb memory.
956"
S,0.9568655643421998,"H.4
CIFAR 10 and MNIST
957"
S,0.9575844716031632,"We conducted experiments related to high dimensional data, the parameters for training were taken
958"
S,0.9583033788641265,"from the open-source code6 from the works [20, 19]. We saved the leverage of additional heuris-
959"
S,0.9590222861250899,"tics(EMA, lr scheduler).
960"
S,0.9597411933860532,"Table 7: FID comparison for 4 sampling iterations, 400 000 learning steps."
S,0.9604601006470166,"METHOD
FID"
S,0.9611790079079798,"EXFM
3.686 ± 0.029
CFM
3.727 ± 0.026
OT-CFM
3.843 ± 0.033"
S,0.9618979151689432,6https://github.com/atong01/conditional-flow-matching
S,0.9626168224299065,"Table 8: FID comparison for ExFM, CFM and OT-CFM methods over 400 000 learning steps, mean
and std taken from 4 sampling iterations."
S,0.9633357296908699,"Step
ExFM FID
CFM FID
OT-CFM FID"
S,0.9640546369518332,"0
447.256 ± 0.116
447.106 ± 0.130
447.091 ± 0.081
20000
281.060 ± 0.243
275.044 ± 0.123
281.499 ± 0.287
40000
52.050 ± 0.245
51.436 ± 0.142
45.976 ± 0.109
60000
9.125 ± 0.060
9.181 ± 0.035
10.358 ± 0.054
80000
6.624 ± 0.053
6.978 ± 0.062
7.492 ± 0.050
100000
5.641 ± 0.048
5.894 ± 0.045
6.299 ± 0.031
120000
5.085 ± 0.031
5.247 ± 0.051
5.558 ± 0.017
140000
4.766 ± 0.036
4.902 ± 0.053
5.120 ± 0.043
160000
4.486 ± 0.054
4.593 ± 0.068
4.828 ± 0.046
180000
4.294 ± 0.023
4.447 ± 0.045
4.576 ± 0.051
200000
4.180 ± 0.029
4.204 ± 0.013
4.434 ± 0.031
220000
4.022 ± 0.036
4.182 ± 0.024
4.331 ± 0.036
240000
3.925 ± 0.028
4.037 ± 0.036
4.227 ± 0.050
260000
3.852 ± 0.047
3.937 ± 0.018
4.125 ± 0.015
280000
3.842 ± 0.053
3.870 ± 0.040
4.056 ± 0.029
300000
3.758 ± 0.032
3.788 ± 0.024
4.017 ± 0.029
320000
3.749 ± 0.029
3.792 ± 0.034
3.937 ± 0.052
340000
3.724 ± 0.042
3.747 ± 0.033
3.897 ± 0.037
360000
3.714 ± 0.022
3.751 ± 0.041
3.875 ± 0.015
380000
3.707 ± 0.028
3.754 ± 0.020
3.917 ± 0.037
400000
3.686 ± 0.029
3.727 ± 0.026
3.843 ± 0.033"
S,0.9647735442127966,"Figure 10: Training loss comparison for ExFM, CFM and OT-CFM methods, MNIST dataset."
S,0.9654924514737598,"H.5
Metrics
961"
S,0.9662113587347232,"For evaluating 2D toy data we use Energy Distance and W2 metricis, for Tabular datasets we use
962"
S,0.9669302659956865,"Negative Log Likelihood, for CIFAR10 we took Fréchet inception distance (FID) metrics. This
963"
S,0.9676491732566499,"choice is connected with an instability and poor evaluation quality of Energy Distance metrics and
964"
S,0.9683680805176133,"W2 among high-dimensional data .
965"
S,0.9690869877785766,"H.5.1
Energy Distance
966"
S,0.9698058950395398,"We use the generalized Energy Distance [18] (or E-metrics) to the metric space.
967"
S,0.9705248023005032,"Consider the null hypothesis that two random variables, X and Y , have the same probability distribu-
968"
S,0.9712437095614666,"tions: µ = ν .
969"
S,0.9719626168224299,For statistical samples from Xand Y :
S,0.9726815240833933,"{x1, . . . , xn}
and
{y1, . . . , ym},"
S,0.9734004313443566,"the following arithmetic averages of distances are computed between the X and the Y samples:
970"
S,0.97411933860532,"A =
1
nm n
X i=1 m
X"
S,0.9748382458662832,"j=1
∥xi −yj∥,
B = 1 n2 n
X i=1 n
X"
S,0.9755571531272466,"j=1
∥xi −xj∥,
C =
1
m2 m
X i=1 m
X"
S,0.9762760603882099,"j=1
∥yi −yj∥."
S,0.9769949676491733,"Figure 11: FID comparison for ExFM, CFM and OT-CFM methods, CIFAR-10 dataset."
S,0.9777138749101366,"Figure 12: Sampled images from ExFM method, CIFAR-10 dataset."
S,0.9784327821711,"Figure 13: Sampled images from ExFM method, MNIST dataset."
S,0.9791516894320632,"The E-statistic of the underlying null hypothesis is defined as follows:
971"
S,0.9798705966930266,"En,m(X, Y ) := 2A −B −C"
S,0.9805895039539899,"H.5.2
2-Wasserstein distance (W2)
972"
S,0.9813084112149533,"The 2-Wasserstein distance [14], also called the Earth mover’s distance or the optimal transport
973"
S,0.9820273184759166,"distance W is a metric to describe the distance between two distributions, representing two different
974"
S,0.98274622573688,"subsets A and B. For continuous distributions, it is:
975"
S,0.9834651329978433,"W := W(FA, FB) =
Z 1 0"
S,0.9841840402588066,"F −1
A (u) −F −1
B (u)
2 du
 1 2
,"
S,0.9849029475197699,"where FA and FB are the corresponding cumulative distribution functions and F −1
A
and F −1
B
the
976"
S,0.9856218547807333,"respective quantile functions.
977"
S,0.9863407620416966,"H.5.3
Negative Log Likelihood (NLL)
978"
S,0.98705966930266,"To compute the NLL, we first sampled N = 5000 samples {xs
i}N
i=1 from the target distribution. Then
979"
S,0.9877785765636233,"we solved the following inverse flow ODE:
980 
  ∂x(t)"
S,0.9884974838245866,"∂t
= vθ(x(t), t),"
S,0.9892163910855499,x(1) = xs
S,0.9899352983465133,"for t from 1 to 0. For simplicity, changing time variable τ = 1 −t we solve the following ODE:
981 
  ∂x(τ)"
S,0.9906542056074766,"∂τ
= −vθ(x(τ), 1 −τ),"
S,0.99137311286844,x(0) = xs
S,0.9920920201294033,"for τ from 0 to 1. Thus we obtained N solutions {x0
i }N
i=1 which are expected to be distributed
according to the standard normal distribution N(x | 0, I). So we calculate NLL as"
S,0.9928109273903667,"NLL = −1 N N
X"
S,0.9935298346513299,"i=1
ln N(x0
i | 0, I)."
S,0.9942487419122933,"H.5.4
Fréchet inception distance (FID)
982"
S,0.9949676491732566,"For images evaluation we take Fréchet inception distance (FID) metrics, in particular the implementa-
983"
S,0.99568655643422,"tion from [12]. The main idea of FID metrics is to measure the gap between two data distributions,
984"
S,0.9964054636951833,"such as between a training set and samples from a trained model. After resizing the images, and
985"
S,0.9971243709561467,"feature extraction, the mean (µ, ˆµ) and covariance matrix (Σ, ˆΣ) of the corresponding features are
986"
S,0.9978432782171099,"used to compute FID:
987"
S,0.9985621854780733,"FID = ||µ −ˆµ||2
2 + Tr(Σ + bΣ −2(ΣˆΣ)1/2),
988"
S,0.9992810927390366,"where Tr is the trace of the matrix.
989"
