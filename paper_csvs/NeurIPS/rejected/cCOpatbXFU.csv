Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0007230657989877079,"Mirror Descent is a popular algorithm, that extends Gradients Descent (GD) beyond
1"
ABSTRACT,0.0014461315979754157,"the Euclidean geometry. One of its benefits is to enable strong convergence
2"
ABSTRACT,0.0021691973969631237,"guarantees through smooth-like analyses, even for objectives with exploding or
3"
ABSTRACT,0.0028922631959508315,"vanishing curvature. This is achieved through the introduction of the notion of
4"
ABSTRACT,0.0036153289949385392,"relative smoothness, which holds in many of the common use-cases of Mirror
5"
ABSTRACT,0.004338394793926247,"descent. While basic deterministic results extend well to the relative setting, most
6"
ABSTRACT,0.005061460592913955,"existing stochastic analyses require additional assumptions on the mirror, such as
7"
ABSTRACT,0.005784526391901663,"strong convexity (in the usual sense), to ensure bounded variance. In this work, we
8"
ABSTRACT,0.006507592190889371,"revisit Stochastic Mirror Descent (SMD) proofs in the (relatively-strongly-) convex
9"
ABSTRACT,0.0072306579898770785,"and relatively-smooth setting, and introduce a new (less restrictive) definition
10"
ABSTRACT,0.007953723788864787,"of variance which can generally be bounded (globally) under mild regularity
11"
ABSTRACT,0.008676789587852495,"assumptions. We then investigate this notion in more details, and show that it
12"
ABSTRACT,0.009399855386840203,"naturally leads to strong convergence guarantees for stochastic mirror descent.
13"
ABSTRACT,0.01012292118582791,"Finally, we leverage this new analysis to obtain convergence guarantees for the
14"
ABSTRACT,0.010845986984815618,"Maximum Likelihood Estimator of a Gaussian with unknown mean and variance.
15"
INTRODUCTION,0.011569052783803326,"1
Introduction
16"
INTRODUCTION,0.012292118582791034,"The central problem of this paper is to solve optimization problems of the following form:
17"
INTRODUCTION,0.013015184381778741,"min
x∈C f(x), where f(x) = E [fξ(x)] ,
(1)"
INTRODUCTION,0.01373825018076645,"where C is a closed convex subset of Rd, and fξ are differentiable convex functions (stochasticity
18"
INTRODUCTION,0.014461315979754157,"is on the variable ξ). The problems that we will consider typically arise from machine-learning
19"
INTRODUCTION,0.015184381778741865,"use-cases, meaning that the dimension d can be very large. Therefore, first-order methods are popular
20"
INTRODUCTION,0.015907447577729574,"for solving these problems, since they usually scale well with the dimension.
21"
INTRODUCTION,0.016630513376717282,"In standard machine learning setups, computing a gradient of f is very costly (or even impossible),
22"
INTRODUCTION,0.01735357917570499,"since it requires computing gradients for all individual examples in the dataset. Yet, gradients of fξ
23"
INTRODUCTION,0.018076644974692697,"are relatively cheap, and arbitrarily high precisions are generally not required. This makes Stochastic
24"
INTRODUCTION,0.018799710773680405,"Gradient Descent (SGD) the method of choice [4]. Using a step-size η > 0, the SGD update from
25"
INTRODUCTION,0.019522776572668113,"point x ∈Rd can be written as x+
SGD = arg minu∈C

η∇fξ(x)⊤u + 1"
INTRODUCTION,0.02024584237165582,"2∥u −x∥2	
.
26"
INTRODUCTION,0.02096890817064353,"While the standard Euclidean geometry leading to Gradient Descent (GD) fits many use-cases quite
27"
INTRODUCTION,0.021691973969631236,"well, several applications are better solved with Mirror Descent (MD), a generalization of GD which
28"
INTRODUCTION,0.022415039768618944,"allows to better capture the geometry of the problem. For instance, the Kullback-Leibler divergence
29"
INTRODUCTION,0.023138105567606652,"might be better suited to discriminating between probability distributions than the (squared) Euclidean
30"
INTRODUCTION,0.02386117136659436,"norm, and this is something that one can leverage using MD with entropy as a mirror. As a matter
31"
INTRODUCTION,0.024584237165582067,"of fact, many standard algorithms can be interpreted as MD, i.e., as generalized first-order methods.
32"
INTRODUCTION,0.025307302964569775,"This is for instance the case in statistics, where Expectation Minimization and Maximum A Posteriori
33"
INTRODUCTION,0.026030368763557483,"estimators can be interpreted as running MD with specific mirror and step-sizes [15, 17]. Mirror
34"
INTRODUCTION,0.02675343456254519,"descent can also be used to solve Poisson inverse problems, which have many applications in
35"
INTRODUCTION,0.0274765003615329,"astronomy and medicine [3], to reduce the communication cost of distributed algorithms [24, 12],
36"
INTRODUCTION,0.028199566160520606,"or to solve convex quartic problems [6]. In the online learning community as well, many standard
37"
INTRODUCTION,0.028922631959508314,"algorithms such as Exponential Weight Updates or Follow-The-Regularized-Leader can be interpreted
38"
INTRODUCTION,0.02964569775849602,"as running mirror descent [21, 13]. There are still many open questions regarding the convergence
39"
INTRODUCTION,0.03036876355748373,"guarantees for most of the algorithms mentioned above. Therefore, progress on the understanding of
40"
INTRODUCTION,0.03109182935647144,"MD can lead to a plethora of results on these applications, and more generally to a more consistent
41"
INTRODUCTION,0.03181489515545915,"theory for Majorization-Minimization algorithms. This paper is a stepping stone in this direction.
42"
INTRODUCTION,0.03253796095444685,"Let us now introduce the mirror map, or potential function h, together with the Bregman divergence
43"
INTRODUCTION,0.033261026753434564,"with respect to h, which is defined for x, y ∈dom h as Dh(x, y) = h(x)−h(y)−∇h(y)⊤(x−y). We
44"
INTRODUCTION,0.03398409255242227,"now introduce the Stochastic Mirror Descent (SMD) update, which can be found in its deterministic
45"
INTRODUCTION,0.03470715835140998,"form in, e.g., Nemirovskij and Yudin [22]. SMD consists in replacing the squared Euclidean norm
46"
INTRODUCTION,0.035430224150397684,"from the SGD update by the Bregman divergence with respect to the mirror map h:
47"
INTRODUCTION,0.036153289949385395,"x+(η, ξ) = arg min
u∈C

η∇fξ(x)⊤u + Dh(u, x)
	
.
(2)"
INTRODUCTION,0.0368763557483731,"Note that since D∥·∥2(x, y) = ∥x −y∥2, one can recover SGD by taking h = 1"
INTRODUCTION,0.03759942154736081,"2∥· ∥2. In this sense,
48"
INTRODUCTION,0.038322487346348515,"SMD can be viewed as standard SGD, but changing the way distances are computed, and so the
49"
INTRODUCTION,0.039045553145336226,"geometry of the problem. Yet, this change significantly complicates the convergence analysis of the
50"
INTRODUCTION,0.03976861894432393,"method, since the Bregman divergence, in general: (i) does not satisfy the triangular inequality, (ii) is
51"
INTRODUCTION,0.04049168474331164,"not symmetric, (iii) is not translation-invariant, (iv) is not convex in its second argument.
52"
INTRODUCTION,0.04121475054229935,"This means that analyzing mirror descent methods requires quite some care, and that many standard
53"
INTRODUCTION,0.04193781634128706,"(S)GD results do not extend to the mirror setting. For instance, one can prove that mirror descent
54"
INTRODUCTION,0.04266088214027477,"cannot be accelerated in general [8]. Similarly, applying techniques such as variance-reduction
55"
INTRODUCTION,0.04338394793926247,"requires additional assumptions [7]. To ensure that x+(η, ξ) exists and is unique, we first make the
56"
INTRODUCTION,0.044107013738250184,"following blanket assumption throughout the paper:
57"
INTRODUCTION,0.04483007953723789,"Assumption 1. Function h : Rd →R ∪{∞} is twice continuously differentiable and strictly convex
58"
INTRODUCTION,0.0455531453362256,"on C. For every y ∈Rd, the problem minx∈C h(x) −x⊤y has a unique solution, which lies in int C,
59"
INTRODUCTION,0.046276211135213303,"and all fξ are convex.
60"
INTRODUCTION,0.046999276934201015,"Note that the regularity assumption on h could be relaxed, as discussed in Section 3, but we choose a
61"
INTRODUCTION,0.04772234273318872,"rather strong one to make sure all the objects we will manipulate are well-defined. Interestingly, while
62"
INTRODUCTION,0.04844540853217643,"mirror descent changes the way distances are computed to move away from the Euclidean geometry,
63"
INTRODUCTION,0.049168474331164135,"standard analyses of mirror descent methods, and in particular in the online learning community,
64"
INTRODUCTION,0.049891540130151846,"still require strong convexity and Lipschitz continuity with respect to norms [5, Chapter 4]. It is
65"
INTRODUCTION,0.05061460592913955,"only recently that a relative smoothness assumption was introduced to study mirror descent [2, 20],
66"
INTRODUCTION,0.05133767172812726,"together with the corresponding relative strong convexity.
67"
INTRODUCTION,0.052060737527114966,"Definition 1. The function f is said to be L-relatively smooth and µ-relatively strongly convex with
68"
INTRODUCTION,0.05278380332610268,"respect to h if for all x, y ∈C: µDh(x, y) ≤Df(x, y) ≤LDh(x, y). To lighten notation, we will
69"
INTRODUCTION,0.05350686912509038,"omit the dependence on h and simply write that f is L-rel.-smooth unless clearly specified.
70"
INTRODUCTION,0.05422993492407809,"Definition 1 extends the standard smooth and strongly convex assumptions that correspond to the case
71 h = 1"
INTRODUCTION,0.0549530007230658,"2∥· ∥2, so that for all x ∈C, ∇2h(x) = I the identity matrix. These assumptions allow MD
72"
INTRODUCTION,0.05567606652205351,"analyses to generalize standard GD analyses, and in particular to obtain similar linear and sublinear
73"
INTRODUCTION,0.05639913232104121,"rates, with constant step-size and conditions adapted to the relative assumptions.
74"
INTRODUCTION,0.05712219812002892,"While the basic deterministic setting is now well-understood under relative assumptions, a good
75"
INTRODUCTION,0.05784526391901663,"understanding of the stochastic setting remains elusive. In particular, as we will see in more details in
76"
INTRODUCTION,0.05856832971800434,"the related work section, all existing proofs somehow require the mirror h to be globally strongly
77"
INTRODUCTION,0.05929139551699204,"convex with respect to a norm, or have non-vanishing variance. The only case that can be analyzed
78"
INTRODUCTION,0.060014461315979754,"tightly is under interpolation (there exists a point that minimizes all stochastic functions), or when
79"
INTRODUCTION,0.06073752711496746,"using Coordinate Descent instead of SMD [10, 11]. This is a major weakness, as the goal of relative
80"
INTRODUCTION,0.06146059291395517,"smoothness is precisely to avoid comparisons to norms. Indeed, even when these “absolute” regularity
81"
INTRODUCTION,0.06218365871294288,"assumptions hold, the smoothness and strong convexity constants are typically very loose, and the
82"
INTRODUCTION,0.06290672451193059,"theory is not representative of the observed behaviour of the algorithms.
83"
INTRODUCTION,0.0636297903109183,"However, as hinted at earlier, this was expected: acceleration is notoriously hard to achieve for mirror
84"
INTRODUCTION,0.064352856109906,"descent (and even impossible in general [8]), and variance reduction typically encounters the same
85"
INTRODUCTION,0.0650759219088937,"problems [7]. For stochastic updates, this comes from the fact that it is impossible to disentangle the
86"
INTRODUCTION,0.06579898770788142,"stochastic gradient from the effect of the curvature of h at the point at which it is applied.
87"
INTRODUCTION,0.06652205350686913,"Contribution and outline. The main contribution of this paper is to introduce a new analysis for
88"
INTRODUCTION,0.06724511930585683,"mirror descent, with a variance notion which is provably bounded under mild regularity assumptions:
89"
INTRODUCTION,0.06796818510484454,"typically, the same as those required for the deterministic case. We introduce our new variance
90"
INTRODUCTION,0.06869125090383225,"notion, and compare it with standard ones from the literature in Section 2. This new analysis is both
91"
INTRODUCTION,0.06941431670281996,"simpler and tighter than existing ones, as shown in Section 3. Finally, we use our results to analyse
92"
INTRODUCTION,0.07013738250180766,"the convergence of the Maximum Likelihood and Maximum A Posteriori estimators for a Gaussian
93"
INTRODUCTION,0.07086044830079537,"with unknown mean and variance in Section 4, and show that it is the first generic stochastic mirror
94"
INTRODUCTION,0.07158351409978309,"descent analysis that obtains meaningful finite-time convergence guarantees in this case.
95"
VARIANCE ASSUMPTIONS,0.07230657989877079,"2
Variance Assumptions
96"
VARIANCE ASSUMPTIONS,0.0730296456977585,"We now focus on the various variance assumptions under which Stochastic Mirror Descent is analyzed.
97"
VARIANCE ASSUMPTIONS,0.0737527114967462,"Some manipulations require technical lemmas, such as the duality property of the Bregman divergence
98"
VARIANCE ASSUMPTIONS,0.07447577729573392,"or the Bregman co-coercivity lemma, which can be found in Appendix A.
99"
VARIANCE ASSUMPTIONS,0.07519884309472162,"We start by introducing our variance definition, prove a few good properties for it, and then compare
100"
VARIANCE ASSUMPTIONS,0.07592190889370933,"it with the existing ones to highlight their shortcomings. The two key properties we would like to
101"
VARIANCE ASSUMPTIONS,0.07664497469269703,"ensure (and which are not satisfied by other definitions) are: (i) boundedness without strong convexity
102"
VARIANCE ASSUMPTIONS,0.07736804049168475,"of h or restricting the SMD iterates, and (ii) finiteness for η →0 (with the appropriate scaling).
103"
NEW VARIANCE DEFINITION,0.07809110629067245,"2.1
New variance definition
104"
NEW VARIANCE DEFINITION,0.07881417208966016,"Let η > 0, and recall that x+(η, ξ) is the result of a SMD step from x using function fξ with step-size
105"
NEW VARIANCE DEFINITION,0.07953723788864786,"η (Equation (2)). From now on, when clear from the context, we will simply denote this point x+.
106"
NEW VARIANCE DEFINITION,0.08026030368763558,"Yet, although the dependence is now implicit, do keep in mind that x+ is a stochastic quantity that is
107"
NEW VARIANCE DEFINITION,0.08098336948662328,"not independent from ξ nor η, as this is critical in most results. Under Assumption 1, x+ writes:
108"
NEW VARIANCE DEFINITION,0.08170643528561099,"∇h(x+) = ∇h(x) −η∇fξ(x).
(3)"
NEW VARIANCE DEFINITION,0.0824295010845987,"Similarly, we denote by x+ the deterministic Mirror Descent update, which is such that ∇h(x+) =
109"
NEW VARIANCE DEFINITION,0.08315256688358641,"∇h(x) −η∇f(x). We also introduce h∗: y 7→arg maxx∈C x⊤y −h(x) the convex conjugate of h,
110"
NEW VARIANCE DEFINITION,0.08387563268257411,"which verifies ∇h∗(∇h(x)) = x. Let us now define the key function
111"
NEW VARIANCE DEFINITION,0.08459869848156182,fη(x) = f(x) −1
NEW VARIANCE DEFINITION,0.08532176428054954,"η E

Dh(x, x+)

.
(4)"
NEW VARIANCE DEFINITION,0.08604483007953724,"Definition 2. We define the variance of the stochastic mirror descent iterates given by (2) as
112"
NEW VARIANCE DEFINITION,0.08676789587852494,"σ2
⋆,η = 1"
NEW VARIANCE DEFINITION,0.08749096167751265,"η supx∈C (f(x⋆) −fη(x)) =
f ⋆−f ⋆
η
η
, where f ⋆and f ⋆
η are respectively the inf. of f and fη.
113"
NEW VARIANCE DEFINITION,0.08821402747650037,"We now state various bounds on σ2
⋆,η, to help understand its behaviour. We start by positivity, which
114"
NEW VARIANCE DEFINITION,0.08893709327548807,"is an essential property that justifies the square in the definition.
115"
NEW VARIANCE DEFINITION,0.08966015907447578,"Proposition 2.1 (Positivity). For all η > 0, σ⋆,η ≥0.
116"
NEW VARIANCE DEFINITION,0.09038322487346348,"This result follows from fη(x) ≤f(x), since Dh(x, x+) ≥0 for all x ∈C by convexity of h.
117"
NEW VARIANCE DEFINITION,0.0911062906724512,"Stochastic functions after a step.
We first upper bound σ2
⋆,η directly in terms of fξ.
118"
NEW VARIANCE DEFINITION,0.0918293564714389,"Proposition 2.2. If fξ is L-rel.-smooth and η ≤1/L, then σ2
⋆,η ≤1"
NEW VARIANCE DEFINITION,0.09255242227042661,"η (f(x⋆) −minx∈C E [fξ(x+)]).
119"
NEW VARIANCE DEFINITION,0.09327548806941431,"Proof. Since Dh(x, x+) = ⟨∇h(x+) −∇h(x), x+ −x⟩−Dh(x+, x), then Dh(x, x+) =
120"
NEW VARIANCE DEFINITION,0.09399855386840203,"−η∇fξ(x)⊤(x+ −x) −Dh(x+, x) = η
 
Dfξ(x+, x) −fξ(x+) + fξ(x)

−Dh(x+, x). The rela-
121"
NEW VARIANCE DEFINITION,0.09472161966738973,"tive smoothness of fξ and the step-size condition imply that ηDfξ(x+, x) ≤Dh(x+, x), leading to
122"
NEW VARIANCE DEFINITION,0.09544468546637744,"1
ηDh(x, x+) ≤fξ(x) −fξ(x+), and the result follows.
123"
NEW VARIANCE DEFINITION,0.09616775126536514,"This bound offers a new point of view on the variance, which can be bounded as the difference
124"
NEW VARIANCE DEFINITION,0.09689081706435286,"between the optimum of f, and the optimum of a related function, in which we make one mirror
125"
NEW VARIANCE DEFINITION,0.09761388286334056,"descent step before evaluating each fξ.
126"
NEW VARIANCE DEFINITION,0.09833694866232827,"Finiteness. Proposition 2.2 implies the following:
127"
NEW VARIANCE DEFINITION,0.09906001446131597,"Corollary 2.3. If fξ is L-relatively-smooth w.r.t. h and admits a minimum xξ
⋆∈int C a.s., then for
128"
NEW VARIANCE DEFINITION,0.09978308026030369,"all η ≤1/L, σ2
⋆,η ≤
f(x⋆)−E[fξ(xξ
⋆)]
η
. In particular, σ2
⋆,η is finite.
129"
NEW VARIANCE DEFINITION,0.1005061460592914,"This result directly comes from the fact that minx∈C E [fξ(x+)] ≥E [minx∈C fξ(x+)] ≥
130"
NEW VARIANCE DEFINITION,0.1012292118582791,"E
h
fξ(xξ
⋆)
i
. It shows that the standard regularity assumptions for the convergence of stochastic
131"
NEW VARIANCE DEFINITION,0.1019522776572668,"mirror descent guarantee that the variance as introduced in Definition 2 remains bounded. This is a
132"
NEW VARIANCE DEFINITION,0.10267534345625452,"strong result, that justifies the supremum in the variance definition. Indeed, most other variance
133"
NEW VARIANCE DEFINITION,0.10339840925524223,"definitions require additional assumptions for the variance to remain bounded after the supre-
134"
NEW VARIANCE DEFINITION,0.10412147505422993,"mum. Instead, we globalize the variance definition, by taking the supremum over the right quantity
135"
NEW VARIANCE DEFINITION,0.10484454085321765,"to ensure that it remains bounded over the whole domain without having to explicitly assume it.
136"
NEW VARIANCE DEFINITION,0.10556760665220535,"Note that the bound from Corollary 2.3 has already been investigating in other settings for stochastic
137"
NEW VARIANCE DEFINITION,0.10629067245119306,"optimization [19], as discussed in Section 2.2. While useful to show boundedness, this bound has a
138"
NEW VARIANCE DEFINITION,0.10701373825018076,"major drawback, which is that it explodes when the step-size η vanishes. This does not reflect what
139"
NEW VARIANCE DEFINITION,0.10773680404916848,"happens in practice, which is why we investigate finer bounds on σ2
⋆,η.
140"
NEW VARIANCE DEFINITION,0.10845986984815618,"Gradient norm at optimum.
A usual way of formulating variance is to express it as the norm
141"
NEW VARIANCE DEFINITION,0.10918293564714389,"of the difference between stochastic gradients and the deterministic gradients. While the previous
142"
NEW VARIANCE DEFINITION,0.1099060014461316,"bounds highlight dependencies on the gradient steps (through evaluations at x+), none of them really
143"
NEW VARIANCE DEFINITION,0.11062906724511931,"corresponds to “the size of the stochastic gradients at optimum”. The key subtlety is that when using
144"
NEW VARIANCE DEFINITION,0.11135213304410702,"mirror descent, it is important to also specify the point at which these gradients are applied, and the
145"
NEW VARIANCE DEFINITION,0.11207519884309472,"following proposition gives a bound of this flavor on σ2
⋆,η. In this section, xη denotes the minimizer
146"
NEW VARIANCE DEFINITION,0.11279826464208242,"of fη when it exists and is in int C. Otherwise, unless explicitly stated, results involving xη can be
147"
NEW VARIANCE DEFINITION,0.11352133044107014,"replaced by a limit for x →xη.
148"
NEW VARIANCE DEFINITION,0.11424439624005785,"Proposition 2.4. If f is L-rel.-smooth, η ≤1/L and x⋆∈int C, σ2
⋆,η ≤
1
η2 E
h
Dh
"
NEW VARIANCE DEFINITION,0.11496746203904555,"x+
η , x+
η
i
.
149"
NEW VARIANCE DEFINITION,0.11569052783803326,"This can be considered as the Mirror Descent equivalent of E

∥∇fξ(x⋆)∥2
. Yet, a key difference is
150"
NEW VARIANCE DEFINITION,0.11641359363702097,"that stochastic gradients are evaluated at point xη instead of x⋆, and ∇f(xη) ̸= 0 in general.
151"
NEW VARIANCE DEFINITION,0.11713665943600868,"Proof. For all x, applying the duality property of the Bregman divergence leads to:
152"
NEW VARIANCE DEFINITION,0.11785972523499638,"E

Dh(x, x+)

= E

Dh∗(∇h(x+), ∇h(x))

= E [Dh∗(∇h(x) −η∇fξ(x), ∇h(x))]"
NEW VARIANCE DEFINITION,0.11858279103398409,"= E [Dh∗(∇h(x) −η∇f(x), ∇h(x))] + E [Dh∗(∇h(x) −η∇fξ(x), ∇h(x) −η∇f(x))]"
NEW VARIANCE DEFINITION,0.1193058568329718,"= E [Dh∗(∇h(x) −η [∇f(x) −∇f(x⋆)] , ∇h(x))] + E
h
Dh
"
NEW VARIANCE DEFINITION,0.12002892263195951,"x+, x+i
,"
NEW VARIANCE DEFINITION,0.12075198843094721,"where the last equality comes from the Bregman bias-variance decomposition Lemma [23].
153"
NEW VARIANCE DEFINITION,0.12147505422993492,"We then use the Bregman cocoercivity Lemma [7] to obtain: E [Dh(x, x+)] ≤ηDf(x, x⋆) +
154"
NEW VARIANCE DEFINITION,0.12219812002892264,"E
h
Dh
"
NEW VARIANCE DEFINITION,0.12292118582791034,"x+, x+i
. All these technical results can be found in Appendix A. In the end, fη(x) ≥
155"
NEW VARIANCE DEFINITION,0.12364425162689804,f(x⋆) −1
NEW VARIANCE DEFINITION,0.12436731742588576,"ηE
h
Dh(x+, x+)
i
, and this is in particular true for x = xη.
156"
NEW VARIANCE DEFINITION,0.12509038322487345,"Limit behaviour. A first observation is that both the Dh(x, x+) term in the definition of fη and our
157"
NEW VARIANCE DEFINITION,0.12581344902386118,"variance definition are scaled by η−1. Yet, they remain finite when η →0. While this is clear in the
158"
NEW VARIANCE DEFINITION,0.1265365148228489,"Euclidean setting, this property holds more generally, as shown in the two following results.
159"
NEW VARIANCE DEFINITION,0.1272595806218366,"Proposition 2.5. Let x ∈C and η0 > 0 s.t. EDh(x, x+(η0, ξ)) < ∞. Then, fη(x)
η→0
−−−→f(x).
160"
NEW VARIANCE DEFINITION,0.1279826464208243,"Note that uniform convergence of fη to f would require that there exists η > 0 such that
161"
NEW VARIANCE DEFINITION,0.128705712219812,"supx∈C Dh(x, x+) is finite, which we cannot guarantee in general (it does not hold for f = g =
162"
NEW VARIANCE DEFINITION,0.1294287780187997,"1
2∥· ∥2 defined on Rd for instance). Denote ∥x∥2
A = x⊤Ax, then:
163"
NEW VARIANCE DEFINITION,0.1301518438177874,"Proposition 2.6 (Small step-sizes limit). If fξ are L-rel.-smooth and f has a unique minimizer x⋆
164"
NEW VARIANCE DEFINITION,0.13087490961677511,"and for some η0 > 0, xη = arg min fη(x) exists and is in int C for η ≤η0,
165"
NEW VARIANCE DEFINITION,0.13159797541576285,"lim
η→0 σ2
⋆,η = lim
η→0
1
η2 E

Dh(x+
⋆, x⋆)

= 1"
"E
H",0.13232104121475055,"2E
h
∥∇fξ(x⋆)∥2
∇2h(x⋆)−1
i
.
(5)"
"E
H",0.13304410701373826,"This variance is actually the best we can hope for in the Bregman setting, which indicates the
166"
"E
H",0.13376717281272596,"relevance of Definition 2. Indeed, this term exactly correspond to the variance one would obtain
167"
"E
H",0.13449023861171366,"when making infinitesimal SMD steps from x⋆, i.e., the norm of the stochastic gradients at optimum
168"
"E
H",0.13521330441070137,"in the geometry given by ∇2h(x⋆)−1.
169"
STANDARD ASSUMPTIONS,0.13593637020968907,"2.2
Standard Assumptions
170"
STANDARD ASSUMPTIONS,0.13665943600867678,"We now compare Definition 2 with several variance assumptions from the literature. Note that they
171"
STANDARD ASSUMPTIONS,0.1373825018076645,"typically “only” require the bounds to hold for all iterates over the trajectory. However, in the absence
172"
STANDARD ASSUMPTIONS,0.1381055676066522,"of proof that the iterates stay in certain regions of the space, suprema over the whole domain are
173"
STANDARD ASSUMPTIONS,0.13882863340563992,"required for all variance definitions.
174"
STANDARD ASSUMPTIONS,0.13955169920462762,"Euclidean case. Let us now take a step back and look at the Euclidean case, h = 1"
STANDARD ASSUMPTIONS,0.14027476500361533,"2∥· ∥2, and assume
175"
STANDARD ASSUMPTIONS,0.14099783080260303,"that f is L-smooth. Writing Equation (3) with this specific h and replacing xη by a supremum, we
176"
STANDARD ASSUMPTIONS,0.14172089660159073,"obtain σ2
⋆,η ≤supx∈C E
 1"
STANDARD ASSUMPTIONS,0.14244396240057844,"2∥∇f(x) −∇fξ(x)∥2
, which is a common though debatable variance
177"
STANDARD ASSUMPTIONS,0.14316702819956617,"assumption. Indeed, it involves a maximum over the domain, and is in particular not bounded in
178"
STANDARD ASSUMPTIONS,0.14389009399855388,"general even for simple examples like Linear Regression. Yet, we can recover another standard
179"
STANDARD ASSUMPTIONS,0.14461315979754158,"variance assumption by assuming the smoothness of all fξ [9], which writes σ2
⋆,η ≤E

∥∇fξ(x⋆)∥2
.
180"
STANDARD ASSUMPTIONS,0.14533622559652928,"This result is obtained by writing that ∥∇fξ(x)∥2 ≤2∥∇fξ(x) −∇fξ(x⋆)∥2 + 2∥∇fξ(x⋆)∥2, and
181"
STANDARD ASSUMPTIONS,0.146059291395517,"bounding the first term using smoothness. In particular, we see that standard Euclidean variance
182"
STANDARD ASSUMPTIONS,0.1467823571945047,"definitions are natural bounds of σ2
⋆,η. Detailed derivations can be found in Appendix B.
183"
STANDARD ASSUMPTIONS,0.1475054229934924,"Divergence between stochastic and deterministic gradients. An early variance definition for SMD
184"
STANDARD ASSUMPTIONS,0.14822848879248013,"in the relative setting comes from Hanzely and Richtárik [10], who define σ2
sym as:
185"
STANDARD ASSUMPTIONS,0.14895155459146783,"σ2
sym = 1"
STANDARD ASSUMPTIONS,0.14967462039045554,"η sup
x∈C
E
hD
∇f(x) −∇fξ(x), x+ −x+
Ei
= 1"
STANDARD ASSUMPTIONS,0.15039768618944324,"η2 sup
x∈C
E
h
Dh

x+, x+

+ Dh
"
STANDARD ASSUMPTIONS,0.15112075198843095,"x+, x+i
,"
STANDARD ASSUMPTIONS,0.15184381778741865,"where we recall that x+ is such that ∇h(x+) = ∇h(x) −η∇f(x). We remark two main things when
186"
STANDARD ASSUMPTIONS,0.15256688358640635,"comparing σ2
sym with Proposition 2.4: (i) σ2
⋆,η is not symmetrized, and contains only one of the two
187"
STANDARD ASSUMPTIONS,0.15328994938539406,"terms, and (ii) the bound only needs to hold at xη instead of for all x ∈C. As a result, we directly
188"
STANDARD ASSUMPTIONS,0.1540130151843818,"obtain that σ2
⋆,η ≤σ2
sym, and σ2
sym is actually infinite in most cases, whereas σ2
⋆,η is usually finite, as
189"
STANDARD ASSUMPTIONS,0.1547360809833695,"seen above.
190"
STANDARD ASSUMPTIONS,0.1554591467823572,"Stochastic gradients at optimum. Dragomir et al. [7] define the variance as:
191"
STANDARD ASSUMPTIONS,0.1561822125813449,"σ2
DEH = sup
x∈C"
STANDARD ASSUMPTIONS,0.1569052783803326,"1
2η2 E [Dh∗(∇h(x) −2η∇fξ(x⋆), ∇h(x))] = sup
x∈C
E
h
∥∇fξ(x⋆)∥2
∇2h∗(z(x))
i
,"
STANDARD ASSUMPTIONS,0.1576283441793203,"where z(x) ∈[∇h(x), ∇h(x) −η∇fξ(x⋆)] The main interest of this definition is that stochastic
192"
STANDARD ASSUMPTIONS,0.15835140997830802,"gradients are only taken at x⋆. In particular, this variance is 0 in case there is interpolation (all
193"
STANDARD ASSUMPTIONS,0.15907447577729572,"stochastic functions share a common minimum). However, this quantity can blow up if h is not
194"
STANDARD ASSUMPTIONS,0.15979754157628345,"strongly convex, since in this case ∇2h∗is not upper bounded (indeed, smoothness of the conjugate
195"
STANDARD ASSUMPTIONS,0.16052060737527116,"is ensured by strong convexity of the primal function [14]). Following similar derivations, but after
196"
STANDARD ASSUMPTIONS,0.16124367317425886,"the supremum has been taken, we arrive at:
197"
STANDARD ASSUMPTIONS,0.16196673897324657,"Proposition 2.7. If f is L-relatively-smooth w.r.t.
h, then for η < 1/(2L) and some zη ∈
198"
STANDARD ASSUMPTIONS,0.16268980477223427,"[∇h(xη), ∇h(xη) −η∇fξ(x⋆)], the variance can be bounded as σ2
⋆,η ≤E
h
∥∇fξ(x⋆)∥2
∇2h∗(zη)
i
.
199"
STANDARD ASSUMPTIONS,0.16341287057122197,"In particular, we obtain a finite bound without having to restrict the space.
200"
STANDARD ASSUMPTIONS,0.16413593637020968,"Functions variance. Another variance definition that appears in the SGD literature is of the form
201"
STANDARD ASSUMPTIONS,0.1648590021691974,"f(x⋆) −E
h
fξ(xξ
⋆)
i
, using the optima of the stochastic functions [19]. Unfortunately, the results
202"
STANDARD ASSUMPTIONS,0.16558206796818511,"derived with this definition do not obtain a vanishing variance term when η →0, unlike most other
203"
STANDARD ASSUMPTIONS,0.16630513376717282,"variance definitions, and contrary to what is observed in practice, that smaller step-sizes reduce
204"
STANDARD ASSUMPTIONS,0.16702819956616052,"the variance. The vanishing variance term can be obtained by rescaling by 1/η (so considering
205

f(x⋆) −E
h
fξ(xξ
⋆)
i
/η instead), but this variance definition would explode for η →0. This is
206"
STANDARD ASSUMPTIONS,0.16775126536514823,"because using such a definition would come down to performing the supremum step within the
207"
STANDARD ASSUMPTIONS,0.16847433116413593,"expectation from Proposition 2.2, using that fξ(x+) ≥fξ(xξ
⋆), which is a very crude bound. Instead,
208"
STANDARD ASSUMPTIONS,0.16919739696312364,"Corolary 2.3 directly shows that our variance definition is tighter than this one, and in particular (i) it is
209"
STANDARD ASSUMPTIONS,0.16992046276211134,"bounded for all η > 0, (ii) it remains finite as η →0 even with the proper rescaling (Proposition 2.6).
210"
STANDARD ASSUMPTIONS,0.17064352856109907,"Relation to c-transform. Mirror descent can be viewed as an alternate minimization method on
211"
STANDARD ASSUMPTIONS,0.17136659436008678,"transforms of f [18]. This point of view subsumes many methods, including the Newton Method or
212"
STANDARD ASSUMPTIONS,0.17208966015907448,"Mirror Descent. Central to their analysis is the notion of c-transform f c(y) = supx∈C f(x)−c(x, y),
213"
STANDARD ASSUMPTIONS,0.17281272595806219,"a standard quantity from optimal transport [25]. It turns out that for η ≤1/L, fη is actually
214"
STANDARD ASSUMPTIONS,0.1735357917570499,"linked to the c-transform as fη(x) = E
h
f c
ξ (x+)
i
, where we use the cost c(x, y) =
1
ηDh(x, y).
215"
STANDARD ASSUMPTIONS,0.1742588575560376,"Since f(x⋆) = f c(x⋆) = arg minx∈C f(x+), denoting Tc(g) = gc(∇h∗(∇h(x) −η∇g(x))), we
216"
STANDARD ASSUMPTIONS,0.1749819233550253,"have that σ2
⋆,η = 1"
STANDARD ASSUMPTIONS,0.175704989154013,"η(minx∈C Tc(E [fξ])(x)−minx∈C E [Tc(fξ)] (x)). We recognize the structure of a
217"
STANDARD ASSUMPTIONS,0.17642805495300073,"variance, as the difference between an operator applied to the expectation of a random variable, and
218"
STANDARD ASSUMPTIONS,0.17715112075198844,"the expectation of the operator applied to the random variable. Yet, compared to standard (Euclidean)
219"
STANDARD ASSUMPTIONS,0.17787418655097614,"analyses of SGD, it does not simply corresponds to the variance of the stochastic gradients (at
220"
STANDARD ASSUMPTIONS,0.17859725234996385,"optimum), and bears a more complex form.
221"
STANDARD ASSUMPTIONS,0.17932031814895155,"In this section, we have highlighted the connections with other definitions, and argued that fη (and
222"
STANDARD ASSUMPTIONS,0.18004338394793926,"its minimum) is a relevant quantity. In particular, Definition 2 is the only definition that allows
223"
STANDARD ASSUMPTIONS,0.18076644974692696,"boundedness of the variance notion both after a supremum step over the iterates (and without strong
224"
STANDARD ASSUMPTIONS,0.18148951554591466,"convexity of h) and in the η →0 limit with the proper rescaling.
225"
CONVERGENCE ANALYSIS,0.1822125813449024,"3
Convergence Analysis
226"
CONVERGENCE ANALYSIS,0.1829356471438901,"Now that we have (extensively) investigated σ2
⋆,η, and the various interpretations that come from
227"
CONVERGENCE ANALYSIS,0.1836587129428778,"different bounds, we are ready to state the convergence results. Some proofs in this section are just
228"
CONVERGENCE ANALYSIS,0.1843817787418655,"sketched, but complete derivations can be found in Appendix C.
229"
CONVERGENCE ANALYSIS,0.18510484454085321,"3.1
Relatively Strongly Convex setting.
230"
CONVERGENCE ANALYSIS,0.18582791033984092,"Recall that f ⋆
η = infx∈C fη(x). Starting from an arbitrary x(0), the sequence (x(k))k≥0 is built as
231"
CONVERGENCE ANALYSIS,0.18655097613882862,"x(k+1) = (x(k))+ for k ∈{0, T} for some T > 0
232"
CONVERGENCE ANALYSIS,0.18727404193781635,"Theorem 3.1. If f is µ-relatively-strongly-convex with respect to h, under a constant step-size η, the
233"
CONVERGENCE ANALYSIS,0.18799710773680406,"iterates obtained by SMD (Equation (3)) verify
234"
CONVERGENCE ANALYSIS,0.18872017353579176,"η
h
E
h
fη(x(T ))
i
−f ⋆
η
i
+ E
h
Dh(x⋆, x(T +1))
i
≤(1 −ηµ)T +1Dh(x⋆, x(0)) + ησ2
⋆,η
µ
.
(6)"
CONVERGENCE ANALYSIS,0.18944323933477947,"Note that the (relatively) strongly-convex theorem has a standard form, and recovers usual MD results
235"
CONVERGENCE ANALYSIS,0.19016630513376717,"if we remove the variance, and standard SGD results if we take h = 1"
CONVERGENCE ANALYSIS,0.19088937093275488,"2∥· ∥2.
236"
CONVERGENCE ANALYSIS,0.19161243673174258,"Proof of Theorem 3.1. We start from a variation of Dragomir et al. [7, Lemma 4]:
237"
CONVERGENCE ANALYSIS,0.19233550253073028,"E

Dh(x⋆, x+)

−Dh(x⋆, x) + ηDf(x⋆, x) = −η[f(x) −f(x⋆)] + E

Dh(x, x+)

(7)"
CONVERGENCE ANALYSIS,0.19305856832971802,"= η

f(x⋆) −

f(x) −1"
CONVERGENCE ANALYSIS,0.19378163412870572,"η E

Dh(x, x+)

= η [f(x⋆) −fη(x)]
(8)"
CONVERGENCE ANALYSIS,0.19450469992769343,"= −η

fη(x) −f ⋆
η

+ η

f(x⋆) −f ⋆
η

.
(9)"
CONVERGENCE ANALYSIS,0.19522776572668113,"Using that Df(x⋆, x) ≥µDh(x⋆, x), and remarking that f(x⋆) −f ⋆
η = ησ2
⋆,η, we obtain:
238"
CONVERGENCE ANALYSIS,0.19595083152566883,"η

fη(x) −f ⋆
η

+ E

Dh(x⋆, x+)

≤(1 −ηµ)Dh(x⋆, x) + η2σ2
⋆,η.
(10)"
CONVERGENCE ANALYSIS,0.19667389732465654,"At this point, we can neglect the η

fη(x) −f ⋆
η

≥0 terms and chain the inequalities for x = x(t)
239"
CONVERGENCE ANALYSIS,0.19739696312364424,"for t from 0 to T to obtain the result.
240"
CONVERGENCE ANALYSIS,0.19812002892263195,"This proof is quite simple, and naturally follows from Lemma C.1. One can also note that relative
241"
CONVERGENCE ANALYSIS,0.19884309472161968,"smoothness of f is not required to obtain Theorem 3.1, which has no condition on the step-size. This
242"
CONVERGENCE ANALYSIS,0.19956616052060738,"is not a typo, but reflects the fact that step-size conditions are needed to obtain a bounded variance.
243"
CONVERGENCE ANALYSIS,0.2002892263195951,"Indeed, the variance as defined here entangles aspects tied with the error due to discretization (which
244"
CONVERGENCE ANALYSIS,0.2010122921185828,"is usually dealt with using smoothness), and the error due to stochasticity. This is natural, as the
245"
CONVERGENCE ANALYSIS,0.2017353579175705,"stochastic noise vanishes in the continuous limit (η →0). Besides, the magnitude of the updates
246"
CONVERGENCE ANALYSIS,0.2024584237165582,"depends both on where the stochastic gradient is applied and on the step-size. Yet, the simplicity of
247"
CONVERGENCE ANALYSIS,0.2031814895155459,"the proof is partly due to this entanglement, meaning that we have deferred some of the complexity
248"
CONVERGENCE ANALYSIS,0.2039045553145336,"to the bounding of the variance term.
249"
CONVERGENCE ANALYSIS,0.20462762111352134,"Also note that Theorem 3.1 uses constant step-sizes, but Equation (10) can be used with time-varying
250"
CONVERGENCE ANALYSIS,0.20535068691250905,"step-sizes, as is done for instance in the proof of Theorem 4.3. A variant of Theorem 3.1 in which the
251"
CONVERGENCE ANALYSIS,0.20607375271149675,"discretization error is partly removed from the notion of variance writes:
252"
CONVERGENCE ANALYSIS,0.20679681851048445,"Corollary 3.2. Let f be µ-strongly-convex and L-relatively-smooth with respect to h, and f ⋆
+ =
253"
CONVERGENCE ANALYSIS,0.20751988430947216,"infx∈C E [fξ(x+)]. If η ≤1/L, the SMD iterates (Equation (3)) with constant step-size η verify
254"
CONVERGENCE ANALYSIS,0.20824295010845986,"η
h
E
h
fξ((x(T ))+)
i
−f ⋆
+
i
+E
h
Dh(x⋆, x(T +1))
i
≤(1−ηµ)T +1Dh(x⋆, x(0))+ η µ"
CONVERGENCE ANALYSIS,0.20896601590744757,"f(x⋆) −f ⋆
+
η 
."
CONVERGENCE ANALYSIS,0.2096890817064353,"This alternate version is obtained using that fη(x) ≥E [fξ(x+)], a key step from the proof of
255"
CONVERGENCE ANALYSIS,0.210412147505423,"Proposition 2.2 (see (8)). In the deterministic case, f ⋆
+ = f(x⋆), and we recover standard results.
256"
CONVERGENCE ANALYSIS,0.2111352133044107,"3.2
Convex setting.
257"
CONVERGENCE ANALYSIS,0.2118582791033984,"Let us now consider the convex case, meaning that µ = 0.
258"
CONVERGENCE ANALYSIS,0.21258134490238612,"Theorem 3.3. If f is convex, the iterates obtained by SMD using a constant step-size η > 0 verify
259"
CONVERGENCE ANALYSIS,0.21330441070137382,"1
T + 1 T
X"
CONVERGENCE ANALYSIS,0.21402747650036152,"k=0
E
h
fη(x(k)) −f ⋆
η + Df(x⋆, x(k))
i
≤Dh(x⋆, x(0))"
CONVERGENCE ANALYSIS,0.21475054229934923,"η(T + 1)
+ ησ2
⋆,η.
(11)"
CONVERGENCE ANALYSIS,0.21547360809833696,"This theorem is obtained by summing Equation (9) for x = x(k) for all k ∈{1, . . . , T} and
260"
CONVERGENCE ANALYSIS,0.21619667389732466,"rearranging the terms. Note that varying step-size results can be obtained in the same way.
261"
CONVERGENCE ANALYSIS,0.21691973969631237,"This case differs from standard convex analyses, in that we obtain a control on fη(x(k)) −f ⋆
η +
262"
CONVERGENCE ANALYSIS,0.21764280549530007,"Df(x⋆, x(k)) instead of the usual f(x(k)) −f(x⋆). One of the main consequences is that we cannot
263"
CONVERGENCE ANALYSIS,0.21836587129428778,"get a control on the average iterate since Bregman divergences are in general not convex in their
264"
CONVERGENCE ANALYSIS,0.21908893709327548,"second argument, and fη is not necessarily convex. This non-standard result is a direct consequence
265"
CONVERGENCE ANALYSIS,0.2198120028922632,"of our choice of variance definition, but it is actually a quantity that naturally arises in the analysis.
266"
CONVERGENCE ANALYSIS,0.2205350686912509,"Note that a variant involving f ⋆
+ can be obtained in the same lines as Corollary 3.2.
267"
CONVERGENCE ANALYSIS,0.22125813449023862,"Controlling fη. The results in this section do not directly control the function gap f(x) −f ∗, but
268"
CONVERGENCE ANALYSIS,0.22198120028922633,"rather the transformed one fη(x) −f ⋆
η . Yet, the continuity result (in η) from Proposition 2.5 shows
269"
CONVERGENCE ANALYSIS,0.22270426608821403,"that the bounds we provide can still be interpreted as relevant function values for small η.
270"
CONVERGENCE ANALYSIS,0.22342733188720174,"Controlling Df(x⋆, x(k)). An interesting property of Df(x⋆, x(k)) is that it can be linked with the
271"
CONVERGENCE ANALYSIS,0.22415039768618944,"size of the gradients of f, as shown by the following result.
272"
CONVERGENCE ANALYSIS,0.22487346348517714,"Proposition 3.4. If ∇f(x⋆) = 0 and f is L-relatively smooth with respect to h then for all x ̸= x⋆,
273"
CONVERGENCE ANALYSIS,0.22559652928416485,"Df(x⋆, x) ≥LDh∗

∇h(x⋆)+ ∇f(x)"
CONVERGENCE ANALYSIS,0.22631959508315258,"L
, ∇h(x⋆)

> 0.
274"
CONVERGENCE ANALYSIS,0.22704266088214028,"This is a Bregman equivalent of controlling the gradient squared norm, with the additional benefit
275"
CONVERGENCE ANALYSIS,0.227765726681128,"that the reference point at which we apply the gradient is the optimum x⋆. Besides, Proposition 3.4
276"
CONVERGENCE ANALYSIS,0.2284887924801157,"shows that Df(x⋆, x) > 0 for x ̸= x⋆without requiring f to be strictly convex (only h).
277"
CONVERGENCE ANALYSIS,0.2292118582791034,"Minimal assumptions on h. Note that the theorems in this section do not actually require h to satisfy
278"
CONVERGENCE ANALYSIS,0.2299349240780911,"Assumption 1, but only that iterations can be written in the form of Equation 3 (which is guaranteed
279"
CONVERGENCE ANALYSIS,0.2306579898770788,"by Assumption 1). While Assumption 1 allows for instance to use the Bregman cocoercivity lemma
280"
CONVERGENCE ANALYSIS,0.2313810556760665,"with any points, or ensures that ∇2h is well-defined, which we leverage extensively in Section 2, our
281"
CONVERGENCE ANALYSIS,0.23210412147505424,"theorems are much more general than this, and include applications such as proximal gradient mirror
282"
CONVERGENCE ANALYSIS,0.23282718727404195,"descent (next remark) or the MAP for Gaussian Parameters Estimation (next section).
283"
CONVERGENCE ANALYSIS,0.23355025307302965,"Stochastic Mirror Descent with a Proximal term. Note that our results can be directly extended to
284"
CONVERGENCE ANALYSIS,0.23427331887201736,"handle a proximal term (similarly to the Euclidean proximal gradient algorithm), to handle composite
285"
CONVERGENCE ANALYSIS,0.23499638467100506,"objectives of the form f + g (and in particular projections, for cases in which g is the indicator of a
286"
CONVERGENCE ANALYSIS,0.23571945046999276,"convex set). More details can be found in Appendix E.
287"
CONVERGENCE ANALYSIS,0.23644251626898047,"4
MAP For Gaussian Parameters Estimation.
288"
CONVERGENCE ANALYSIS,0.23716558206796817,"So far, we have proposed new variance definitions for the analysis of stochastic mirror descent, and
289"
CONVERGENCE ANALYSIS,0.2378886478669559,"we have shown that they compare favorably to existing ones, while leading to simple convergence
290"
CONVERGENCE ANALYSIS,0.2386117136659436,"proofs. In this section, we investigate the open problem formulated by Le Priol et al. [17], which is to
291"
CONVERGENCE ANALYSIS,0.2393347794649313,"find non-asymptotic convergence guarantees for the KL-divergence of the Maximum A Posteriori
292"
CONVERGENCE ANALYSIS,0.24005784526391902,"(MAP) estimator. In particular, this example highlights the relevance of the infimum step on fη, since
293"
CONVERGENCE ANALYSIS,0.24078091106290672,"it gives the first generic analysis that obtains meaningful finite time convergence rates.
294"
CONVERGENCE ANALYSIS,0.24150397686189443,"4.1
MAP and MLE of exponential families.
295"
CONVERGENCE ANALYSIS,0.24222704266088213,"We now rapidly review the formalism of exponential families. More details can be found in Le Priol
296"
CONVERGENCE ANALYSIS,0.24295010845986983,"et al. [17], and Wainwright et al. [26, Chapter 3]. Let X be a random variable, and T a deterministic
297"
CONVERGENCE ANALYSIS,0.24367317425885757,"function, then the density of an exponential family for a sample x writes pθ(x) = p(x|θ) =
298"
CONVERGENCE ANALYSIS,0.24439624005784527,"exp(⟨θ, T(x)⟩−A(θ)), where A is often refered to as the log-partition function. In this case, θ is called
299"
CONVERGENCE ANALYSIS,0.24511930585683298,"the natural parameter, and T is the sufficient statistic. Function A is convex, and we can thus establish
300"
CONVERGENCE ANALYSIS,0.24584237165582068,"a form of duality through convex conjugacy. The entropy writes A∗(µ) = maxθ′∈Θ⟨µ, θ′⟩−A(θ′).
301"
CONVERGENCE ANALYSIS,0.24656543745480838,"Parameter µ is called the mean parameter, and the standard MAP estimator can be derived for n0 ∈N,
302"
CONVERGENCE ANALYSIS,0.2472885032537961,"µ0 ∈R as µ(n)
MAP = n0µ(0)+Pn
i=1 T (Xi)
n0+n
. The Maximum Likelihood Estimator (MLE) corresponds to
303"
CONVERGENCE ANALYSIS,0.2480115690527838,"taking n0 = 0. An interesting observation is that µ(n)
MAP can be obtained recursively for n > 0, as
304"
CONVERGENCE ANALYSIS,0.24873463485177152,"µ(0)
MAP = µ(0), ηn = (n+n0)−1, µ(n+1)
MAP = µ(n)
MAP−ηn∇gXn(µ(n)
MAP), with ∇gXn(µ) = µ−T(Xn).
305"
CONVERGENCE ANALYSIS,0.24945770065075923,"In terms of primal variable θ(n) = ∇A∗(µ(n)
MAP), the MAP writes:
306"
CONVERGENCE ANALYSIS,0.2501807664497469,"∇A(θ(n+1)) = ∇A(θ(n)) −η∇fXn(θ(n)),
(12)"
CONVERGENCE ANALYSIS,0.25090383224873464,"where fXn(θ) = A(θ) −⟨θ, T(Xn)⟩, so that f(θ) = A(θ) −⟨θ, µ⋆⟩. We recognize stochastic mirror
307"
CONVERGENCE ANALYSIS,0.25162689804772237,"descent iterations, with mirror A and stochastic gradients ∇fX. Similar results on the MLE can be
308"
CONVERGENCE ANALYSIS,0.25234996384671005,"obtained by taking n0 = 0. This key observation implies that convergence guarantees on the MAP
309"
CONVERGENCE ANALYSIS,0.2530730296456978,"and the MLE can be deduced from stochastic mirror descent convergence guarantees.
310"
CONVERGENCE ANALYSIS,0.25379609544468545,"While this appears as an appealing way to obtain convergence guarantees for the MAP, Le Priol et al.
311"
CONVERGENCE ANALYSIS,0.2545191612436732,"[17] observe that none of the existing SMD results obtain meaningful rates for the convergence of the
312"
CONVERGENCE ANALYSIS,0.25524222704266086,"MAP for general exponential families. In particular, none of them recover the O(1/n) asymptotic
313"
CONVERGENCE ANALYSIS,0.2559652928416486,"convergence rate for estimating a Gaussian with unknown mean and covariance.
314"
CONVERGENCE ANALYSIS,0.25668835864063627,"This is due to the variance definitions used in the existing analyses, that all have issues (not uniformly
315"
CONVERGENCE ANALYSIS,0.257411424439624,"bounded over the domain, not decreasing with the step-size...) as discussed in Section 2. Our analysis
316"
CONVERGENCE ANALYSIS,0.25813449023861174,"fixes this problem, and thus yields finite-time guarantees for the MAP estimator for the estimation of
317"
CONVERGENCE ANALYSIS,0.2588575560375994,"a Gaussian with unknown mean and covariance. This shows the relevance of Assumption 2.
318"
CONVERGENCE ANALYSIS,0.25958062183658714,"4.2
Full Gaussian (unknown mean and covariance)
319"
CONVERGENCE ANALYSIS,0.2603036876355748,"The main problem studied in Le Priol et al. [17] is that of the one-dimensional full-Gaussian
320"
CONVERGENCE ANALYSIS,0.26102675343456255,"case, where the goal is to estimate the mean and covariance of a Gaussian from i.i.d. samples
321"
CONVERGENCE ANALYSIS,0.26174981923355023,"X1, . . . , Xn ∼N(m⋆, Σ⋆), with Σ⋆> 0. Note that although notation Σ is usually reserved for
322"
CONVERGENCE ANALYSIS,0.26247288503253796,"the covariance matrix of a multivariate Gaussian, we use it for a scalar value here to highlight the
323"
CONVERGENCE ANALYSIS,0.2631959508315257,"distinction with σ2
⋆,η, the variance from stochastic mirror descent. In this case, the sufficient statistics
324"
CONVERGENCE ANALYSIS,0.26391901663051337,"write T(X) = (X, X2), and the log-partition and entropy functions are, up to constants, A(θ) =
325"
CONVERGENCE ANALYSIS,0.2646420824295011,"θ2
1
−4θ2 −1"
CONVERGENCE ANALYSIS,0.2653651482284888,"2 log(−θ2), A∗(µ) = −1"
CONVERGENCE ANALYSIS,0.2660882140274765,"2 log(µ2 −µ2
1), for θ ∈Θ = R × R∗
−and µ ∈{(u, v), u2 < v}.
326"
CONVERGENCE ANALYSIS,0.2668112798264642,"The goal is to estimate DA(θ, θ⋆), for which Le Priol et al. [17] show that only partial solutions
327"
CONVERGENCE ANALYSIS,0.2675343456254519,"exist: results are either asymptotic, or rely on the objective being (approximately) quadratic. Note
328"
CONVERGENCE ANALYSIS,0.26825741142443965,"that there is a relationship between natural parameters, mean parameters, and (m, Σ2), the mean and
329"
CONVERGENCE ANALYSIS,0.26898047722342733,"covariance of the Gaussian we would like to estimate. In the following, we will often abuse notations,
330"
CONVERGENCE ANALYSIS,0.26970354302241506,"and write for instance DA(˜θ, θ) in terms of (m, Σ2) and ( ˜m, ˜Σ2) rather than θ and ˜θ. We now state a
331"
CONVERGENCE ANALYSIS,0.27042660882140274,"few results, for which detailed derivations can be found in Appendix F. More specifically:
332"
CONVERGENCE ANALYSIS,0.27114967462039047,"DA(˜θ, θ) = −1"
LOG,0.27187274041937814,"2 log
Σ2 ˜Σ2"
LOG,0.2725958062183659,"
−
˜Σ2 −Σ2"
LOG,0.27331887201735355,"2˜Σ2
+ ( ˜m −m)2"
LOG,0.2740419378163413,"2˜Σ2
."
LOG,0.274765003615329,"The update formulas for the parameters are given by:
333"
LOG,0.2754880694143167,"m+ = (1 −η)m + ηX,
(Σ2)+ = (1 −η)

Σ2 + η(m −X)2
.
(13)
Therefore, MAP iterations are well-defined although A does not verify Assumption 1.
334"
LOG,0.2762111352133044,"Proposition 4.1. The iterations (12) are well-defined for η < 1 in the sense that if θ(n) ∈Θ = R×R∗
−,
335"
LOG,0.2769342010122921,"then ∇A(θ(n)) −η∇fXn(θ(n)) ∈Range(∇A) almost surely, so that θ(n+1) ∈Θ is well-defined
336"
LOG,0.27765726681127983,"almost surely. Besides, fξ is 1-relatively-smooth and 1-relatively-strongly-convex with respect to A.
337"
LOG,0.2783803326102675,"This result is a direct consequence of the fact that Dfξ = Df = DA for all ξ, and the fact that
338"
LOG,0.27910339840925524,"∇A(θ) −η∇fXn(θ) = (1 −η)∇A(θ) + ηT(Xn) ∈{(u, v), u2 < v} if ∇A(θ) ∈{(u, v), u2 < v}.
339"
LOG,0.279826464208243,"Proposition 4.1 means that we can apply Theorem 3.1, so the next step is to bound the variance σ2
⋆,η.
340"
LOG,0.28054953000723065,fη(θ) −f(θ⋆) = 1
LOG,0.2812725958062184,"2η E

log

(1 −η)

1 + η (m −X)2 Σ2"
LOG,0.28199566160520606,"
−1"
LOG,0.2827187274041938,"2 log
Σ2
⋆
Σ2"
LOG,0.28344179320318147,"
.
(14)"
LOG,0.2841648590021692,"We now use this expression to to lower bound f ⋆
η and so upper bound σ2
⋆,η.
341"
LOG,0.2848879248011569,"Lemma 4.2. Let (mη, Σ2
η) be the minimizer of fη. Then, for η < 1/3, mη = m⋆, Σ2
⋆≥Σ2
η ≥
342"
LOG,0.2856109906001446,"(1 −3η) Σ2
⋆. In particular, the variance σ2
⋆,η verifies σ2
⋆,η ≤−1"
LOG,0.28633405639913234,"2η log (1 −3η). For 1/3 < η ≤1−ε,
343"
LOG,0.28705712219812,"σ2
⋆,η ≤cε, where cε is a numerical constant that only depends on ε.
344"
LOG,0.28778018799710775,"Note that we show in this example that Σ2
η is arbitrarily close to Σ2
⋆as η →0, which is expected.
345"
LOG,0.2885032537960954,"Theorem 4.3. Let Γ ≥0 be a numerical constant and Γ = 0 if n0 > 3. The MAP estimator satisfies:
346"
LOG,0.28922631959508316,"E
h
DA(θ⋆, θ(n))
i
≤
n0DA(θ⋆, θ(0)) + 3"
LOG,0.28994938539407084,2 log(1 + n+1
LOG,0.29067245119305857,n0 ) + Γ
LOG,0.2913955169920463,"n + n0
."
LOG,0.292118582791034,"Numerical constants are not optimized. Theorem 4.3 gives an anytime result on the convergence of
347"
LOG,0.2928416485900217,"the MAP estimator for all n ≥0, n0 ≥1 directly from the general SMD convergence theorem. Yet,
348"
LOG,0.2935647143890094,"the open problem from Le Priol et al. [17] is not completely solved still, as discussed below.
349"
LOG,0.2942877801879971,"Reverse KL bound. We obtain a bound on DA(θ⋆, θ(n)), instead of DA(θ(n), θ⋆) = f(θ) −f(θ⋆).
350"
LOG,0.2950108459869848,"DA(θ(n), θ⋆) can be controlled asymptotically thanks to the bound on fη(θ(n))−fη(θη), and fη →f
351"
LOG,0.2957339117859725,"when η = 1/n →0, but we might also be able to exploit this control over the course of the iterations.
352"
LOG,0.29645697758496026,"Asymptotic convergence. Theorem 4.3 leads to a O(log n/n) asymptotic convergence rate instead
353"
LOG,0.29718004338394793,"of the expected O(1/n) [17]. This indicates that the fηn(θ(n)) −f ⋆
ηn terms should not be neglected.
354"
LOG,0.29790310918293567,"Indeed, θ(n) actually has a lot of structure in this example, since ∇A(θ(n)) = 1"
LOG,0.29862617498192334,"n
Pn
k=1 T(Xk). The
355"
LOG,0.2993492407809111,"SMD analysis is oblivious to this structure, hence the gap. Note that we can get rid of the log n factor
356"
LOG,0.30007230657989875,"and recover the right O(1/n) rate from the same analysis by using a slightly different estimator than
357"
LOG,0.3007953723788865,"the MAP (or MLE). This is done by setting the step-size as ηn =
2
n+1 for n > 1, and the analysis of
358"
LOG,0.30151843817787416,"this variant follows Lacoste-Julien et al. [16], as detailed in Appendix F.3.
359"
LOG,0.3022415039768619,"The special case of the MLE. The MLE corresponds to n0 = 0, which is not handled in our analysis
360"
LOG,0.3029645697758496,"since the first step corresponds to η = 1, which necessarily results in θ(1)
2
= −∞(which corresponds
361"
LOG,0.3036876355748373,"to Σ2 = 0, as can be seen from (13)). If we consider that mirror descent is run from θ(1), then we
362"
LOG,0.30441070137382503,"obtain E

DA(θ⋆, θ(1))

= ∞in general, where the expectation is over the value of the first sample
363"
LOG,0.3051337671728127,"drawn. Therefore, we need to start the SMD analysis at θ(2) to fit the MLE into this framework, and in
364"
LOG,0.30585683297180044,"particular we need to be able to evaluate E

DA(θ⋆, θ(2))

. This is further discussed in Appendix F.4.
365"
CONCLUSION,0.3065798987707881,"5
Conclusion
366"
CONCLUSION,0.30730296456977585,"This paper introduces a new notion of variance for the analysis of stochastic mirror descent. This
367"
CONCLUSION,0.3080260303687636,"notion, based on the fact that a certain function fη admits a minimum, is less restrictive than existing
368"
CONCLUSION,0.30874909616775126,"ones, has the right asymptotic scaling with the step-size and is bounded regardless of the trajectory of
369"
CONCLUSION,0.309472161966739,"the iterates without further assumptions.
370"
CONCLUSION,0.31019522776572667,"We strongly believe that our analysis of SMD opens up new perspectives. As an example, we use our
371"
CONCLUSION,0.3109182935647144,"SMD results to show convergence of the MAP for estimating a Gaussian with unknown mean and
372"
CONCLUSION,0.3116413593637021,"covariance. As evidenced in Le Priol et al. [17], all existing generic analyses of stochastic mirror
373"
CONCLUSION,0.3123644251626898,"descent failed to obtain such results.
374"
REFERENCES,0.31308749096167754,"References
375"
REFERENCES,0.3138105567606652,"[1] H. H. Bauschke, J. M. Borwein, et al. Legendre functions and the method of random bregman
376"
REFERENCES,0.31453362255965295,"projections. Journal of convex analysis, 4(1):27–67, 1997.
377"
REFERENCES,0.3152566883586406,"[2] H. H. Bauschke, J. Bolte, and M. Teboulle. A descent lemma beyond lipschitz gradient
378"
REFERENCES,0.31597975415762836,"continuity: first-order methods revisited and applications. Mathematics of Operations Research,
379"
REFERENCES,0.31670281995661603,"42(2):330–348, 2017.
380"
REFERENCES,0.31742588575560376,"[3] M. Bertero, P. Boccacci, G. Desiderà, and G. Vicidomini. Image deblurring with poisson data:
381"
REFERENCES,0.31814895155459144,"from cells to galaxies. Inverse Problems, 25(12):123006, 2009.
382"
REFERENCES,0.3188720173535792,"[4] L. Bottou. Large-scale machine learning with stochastic gradient descent. In Proceedings of
383"
REFERENCES,0.3195950831525669,"COMPSTAT’2010: 19th International Conference on Computational StatisticsParis France,
384"
REFERENCES,0.3203181489515546,"August 22-27, 2010 Keynote, Invited and Contributed Papers, pages 177–186. Springer, 2010.
385"
REFERENCES,0.3210412147505423,"[5] S. Bubeck et al. Convex optimization: Algorithms and complexity. Foundations and Trends®
386"
REFERENCES,0.32176428054953,"in Machine Learning, 8(3-4):231–357, 2015.
387"
REFERENCES,0.3224873463485177,"[6] R.-A. Dragomir and Y. Nesterov. Convex quartic problems: homogenized gradient method and
388"
REFERENCES,0.3232104121475054,"preconditioning. arXiv preprint arXiv:2306.17683, 2023.
389"
REFERENCES,0.32393347794649313,"[7] R. A. Dragomir, M. Even, and H. Hendrikx. Fast stochastic bregman gradient methods: Sharp
390"
REFERENCES,0.32465654374548086,"analysis and variance reduction. In International Conference on Machine Learning, pages
391"
REFERENCES,0.32537960954446854,"2815–2825. PMLR, 2021.
392"
REFERENCES,0.32610267534345627,"[8] R.-A. Dragomir, A. B. Taylor, A. d’Aspremont, and J. Bolte. Optimal complexity and certifica-
393"
REFERENCES,0.32682574114244395,"tion of bregman first-order methods. Mathematical Programming, pages 1–43, 2021.
394"
REFERENCES,0.3275488069414317,"[9] R. M. Gower, N. Loizou, X. Qian, A. Sailanbayev, E. Shulgin, and P. Richtárik. Sgd: General
395"
REFERENCES,0.32827187274041936,"analysis and improved rates. In International conference on machine learning, pages 5200–5209.
396"
REFERENCES,0.3289949385394071,"PMLR, 2019.
397"
REFERENCES,0.3297180043383948,"[10] F. Hanzely and P. Richtárik. Fastest rates for stochastic mirror descent methods. Computational
398"
REFERENCES,0.3304410701373825,"Optimization and Applications, 79:717–766, 2021.
399"
REFERENCES,0.33116413593637023,"[11] H. Hendrikx, F. Bach, and L. Massoulié. Dual-free stochastic decentralized optimization with
400"
REFERENCES,0.3318872017353579,"variance reduction. Advances in neural information processing systems, 33:19455–19466, 2020.
401"
REFERENCES,0.33261026753434564,"[12] H. Hendrikx, L. Xiao, S. Bubeck, F. Bach, and L. Massoulie. Statistically preconditioned
402"
REFERENCES,0.3333333333333333,"accelerated gradient method for distributed optimization.
In International conference on
403"
REFERENCES,0.33405639913232105,"machine learning, pages 4203–4227. PMLR, 2020.
404"
REFERENCES,0.3347794649313087,"[13] D. Hoeven, T. Erven, and W. Kotłowski. The many faces of exponential weights in online
405"
REFERENCES,0.33550253073029646,"learning. In Conference On Learning Theory, pages 2067–2092. PMLR, 2018.
406"
REFERENCES,0.3362255965292842,"[14] S. Kakade, S. Shalev-Shwartz, A. Tewari, et al. On the duality of strong convexity and
407"
REFERENCES,0.33694866232827186,"strong smoothness: Learning applications and matrix regularization. Unpublished Manuscript,
408"
REFERENCES,0.3376717281272596,"http://ttic. uchicago. edu/shai/papers/KakadeShalevTewari09. pdf, 2(1):35, 2009.
409"
REFERENCES,0.3383947939262473,"[15] F. Kunstner, R. Kumar, and M. Schmidt. Homeomorphic-invariance of em: Non-asymptotic
410"
REFERENCES,0.339117859725235,"convergence in kl divergence for exponential families via mirror descent. In International
411"
REFERENCES,0.3398409255242227,"Conference on Artificial Intelligence and Statistics, pages 3295–3303. PMLR, 2021.
412"
REFERENCES,0.3405639913232104,"[16] S. Lacoste-Julien, M. Schmidt, and F. Bach. A simpler approach to obtaining an o (1/t) conver-
413"
REFERENCES,0.34128705712219815,"gence rate for the projected stochastic subgradient method. arXiv preprint arXiv:1212.2002,
414"
REFERENCES,0.3420101229211858,"2012.
415"
REFERENCES,0.34273318872017355,"[17] R. Le Priol, F. Kunstner, D. Scieur, and S. Lacoste-Julien. Convergence rates for the map
416"
REFERENCES,0.34345625451916123,"of an exponential family and stochastic mirror descent–an open problem. arXiv preprint
417"
REFERENCES,0.34417932031814896,"arXiv:2111.06826, 2021.
418"
REFERENCES,0.34490238611713664,"[18] F. Léger and P.-C. Aubin-Frankowski. Gradient descent with a general cost. arXiv preprint
419"
REFERENCES,0.34562545191612437,"arXiv:2305.04917, 2023.
420"
REFERENCES,0.34634851771511205,"[19] N. Loizou, S. Vaswani, I. H. Laradji, and S. Lacoste-Julien. Stochastic polyak step-size for
421"
REFERENCES,0.3470715835140998,"sgd: An adaptive learning rate for fast convergence. In International Conference on Artificial
422"
REFERENCES,0.3477946493130875,"Intelligence and Statistics, pages 1306–1314. PMLR, 2021.
423"
REFERENCES,0.3485177151120752,"[20] H. Lu, R. M. Freund, and Y. Nesterov. Relatively smooth convex optimization by first-order
424"
REFERENCES,0.3492407809110629,"methods, and applications. SIAM Journal on Optimization, 28(1):333–354, 2018.
425"
REFERENCES,0.3499638467100506,"[21] B. McMahan. Follow-the-regularized-leader and mirror descent: Equivalence theorems and
426"
REFERENCES,0.35068691250903833,"l1 regularization. In Proceedings of the Fourteenth International Conference on Artificial
427"
REFERENCES,0.351409978308026,"Intelligence and Statistics, pages 525–533. JMLR Workshop and Conference Proceedings,
428"
REFERENCES,0.35213304410701374,"2011.
429"
REFERENCES,0.35285610990600147,"[22] A. S. Nemirovskij and D. B. Yudin. Problem complexity and method efficiency in optimization.
430"
REFERENCES,0.35357917570498915,"1983.
431"
REFERENCES,0.3543022415039769,"[23] D. Pfau. A generalized bias-variance decomposition for bregman divergences. Unpublished
432"
REFERENCES,0.35502530730296455,"Manuscript, 2013.
433"
REFERENCES,0.3557483731019523,"[24] O. Shamir, N. Srebro, and T. Zhang. Communication-efficient distributed optimization using
434"
REFERENCES,0.35647143890093996,"an approximate newton-type method. In International conference on machine learning, pages
435"
REFERENCES,0.3571945046999277,"1000–1008. PMLR, 2014.
436"
REFERENCES,0.3579175704989154,"[25] C. Villani et al. Optimal transport: old and new, volume 338. Springer, 2009.
437"
REFERENCES,0.3586406362979031,"[26] M. J. Wainwright, M. I. Jordan, et al. Graphical models, exponential families, and variational
438"
REFERENCES,0.35936370209689084,"inference. Foundations and Trends® in Machine Learning, 1(1–2):1–305, 2008.
439"
REFERENCES,0.3600867678958785,"A
Technical results on Bregman divergences
440"
REFERENCES,0.36080983369486624,"As for the rest of this paper, Assumption 1 is assumed throughout this section. However, some of
441"
REFERENCES,0.3615328994938539,"these results hold even with less regularity, and in particular do not require second order continuous
442"
REFERENCES,0.36225596529284165,"differentiability.
443"
REFERENCES,0.36297903109182933,"Lemma A.1 (Duality). For all x, y ∈C, it holds that:
444"
REFERENCES,0.36370209689081706,"Dh(x, y) = Dh∗(∇h(y), ∇h(x))
(15)"
REFERENCES,0.3644251626898048,"See, e.g. Bauschke et al. [1, Theorem 3.7] for the proof.
445"
REFERENCES,0.36514822848879247,"Lemma A.2 (Symmetrized Bregman). For all x, y ∈C, it holds that:
446"
REFERENCES,0.3658712942877802,"Dh(x, y) + Dh(y, x) = ⟨∇h(x) −∇h(y), x −y⟩
(16)"
REFERENCES,0.3665943600867679,"The proof immediately follows from the definition of the Bregman divergence. The following result
447"
REFERENCES,0.3673174258857556,"corresponds to Dragomir et al. [7, Lemma 3].
448"
REFERENCES,0.3680404916847433,"Lemma A.3 (Bregman cocoercivity). If a convex function f is L-relatively-smooth with respect to h,
449"
REFERENCES,0.368763557483731,"then for all η ≤1/L,
450"
REFERENCES,0.36948662328271875,"Dh∗(∇h(x) −η [∇f(x) −∇f(y)] , ∇h(x)) ≤ηDf(x, y).
(17)"
REFERENCES,0.37020968908170643,"Denoting x+y = ∇h∗(∇h(x) −η [∇f(x) −∇f(y)]), a tighter result actually writes:
451"
REFERENCES,0.37093275488069416,"Dh(x, x+y) + ηDf(x+y, y) ≤ηDf(x, y).
(18)"
REFERENCES,0.37165582067968184,"The proof of the tighter version is simply obtained by not using that Df(x+y, y) ≥0 in the original
452"
REFERENCES,0.37237888647866957,"proof. While we don’t directly use it in this paper, it is sometimes useful. We now introduce the
453"
REFERENCES,0.37310195227765725,"generalized bias-variance decomposition Lemma [23, Theorem 0.1].
454"
REFERENCES,0.373825018076645,"Lemma A.4. If X is a random variable, then for all u ∈C,
455"
REFERENCES,0.3745480838756327,"E [Dh∗(X, u)] = Dh∗(E [X] , u) + Dh∗(X, E [X]).
(19)"
REFERENCES,0.3752711496746204,"B
Missing results on the variances
456"
REFERENCES,0.3759942154736081,"We start this section by proving the following lemma, which in particular ensures that Dh(x, x+)/η
457"
REFERENCES,0.3767172812725958,"increases with η (and so decreases as η →0).
458"
REFERENCES,0.3774403470715835,Lemma B.1. Let ϕξ : η 7→1
REFERENCES,0.3781634128705712,"ηDh(x, x+(η, ξ)). Then, ∇ϕξ(η) =
1
η2 Dh(x+(η, ξ), x) ≥0.
459"
REFERENCES,0.37888647866955893,"Proof. First remark that since ∇h(x+) = ∇h(x) −η∇fξ(x), we can write
460"
REFERENCES,0.3796095444685466,"∇η

Dh(x, x+)

= ∇η

h(x) −h(x+) −∇h(x+)⊤(x −x+)
"
REFERENCES,0.38033261026753434,= −∇h(x+)⊤∇ηx+ + ∇fξ(x)⊤(x −x+) + ∇h(x+)⊤∇ηx+
REFERENCES,0.3810556760665221,= ∇fξ(x)⊤(x −x+) = 1
REFERENCES,0.38177874186550975,"η
 
∇h(x) −∇h(x+)
⊤(x −x+) = Dh(x, x+) + Dh(x+, x) η
."
REFERENCES,0.3825018076644975,"Then, the expression follows from
461"
REFERENCES,0.38322487346348516,∇ϕξ(η) = ∇η 1
REFERENCES,0.3839479392624729,"η Dh(x, x+)

= 1"
REFERENCES,0.38467100506146057,"η ∇η

Dh(x, x+)

−1"
REFERENCES,0.3853940708604483,"η2 Dh(x, x+) = 1"
REFERENCES,0.38611713665943603,"η2 Dh(x+, x).
(20) 462"
REFERENCES,0.3868402024584237,"Proof of Proposition 2.5. We now prove that fη →f when η →0. To show this, we note that for
463"
REFERENCES,0.38756326825741144,"any fixed x ∈int C:
464"
REFERENCES,0.3882863340563991,"• For any fixed ξ, 1"
REFERENCES,0.38900939985538685,"ηDh(x, x+) = η"
REFERENCES,0.3897324656543745,"2||∇fξ(x)||2
∇2h∗(z) for z ∈[∇h(x), ∇h(x) −η∇fξ(x)].
465"
REFERENCES,0.39045553145336226,"Therefore, 1"
REFERENCES,0.39117859725235,"ηDh(x, x+) →0 for η →0 since ∇2h∗(∇h(x)) = (∇2h(x))−1 < ∞by strict
466"
REFERENCES,0.39190166305133767,"convexity of h.
467"
REFERENCES,0.3926247288503254,"• Let η ≤η0. Then, for all ξ, 1"
REFERENCES,0.3933477946493131,"ηDh(x, x+(η, ξ)) ≤
1
η0 Dh(x, x+(η0, ξ)) since the function
468 η 7→1"
REFERENCES,0.3940708604483008,"ηDh(x, x+(η, ξ)) is an increasing function (positive gradient using Lemma B.1).
469"
REFERENCES,0.3947939262472885,"•
1
η0 E [Dh(x, x+(η0, ξ))] is finite.
470"
REFERENCES,0.3955169920462762,"Then, using the dominated convergence theorem, we obtain that we can invert the integral (expecta-
471"
REFERENCES,0.3962400578452639,"tion) and the limit, so that limη→0 E 1"
REFERENCES,0.3969631236442516,"ηDh(x, x+) = E limη→0 1"
REFERENCES,0.39768618944323936,"ηDh(x, x+) = 0.
472"
REFERENCES,0.39840925524222703,"Proof of Proposition 2.6. We prove this result by successively upper bounding and lower bounding
473"
REFERENCES,0.39913232104121477,"σ2
⋆,η, and making η →0.
474"
REFERENCES,0.39985538684020244,"1 - Upper bound on σ2
⋆,η. One side is direct, by writing that f(xη) ≥f(x⋆):
475"
REFERENCES,0.4005784526391902,"σ2
⋆,η = 1 η"
REFERENCES,0.40130151843817785,"
f(x⋆) −f(xη) + 1"
REFERENCES,0.4020245842371656,"η E

Dh(xη, x+
η )

≤1"
REFERENCES,0.4027476500361533,"η2 E

Dh(xη, x+
η )

.
(21)"
REFERENCES,0.403470715835141,"From the proof of Proposition 2.5 we have pointwise convergence of fη to f. Since f is convex and
476"
REFERENCES,0.4041937816341287,"has a unique minimizer x⋆, then xη →x⋆for η →0, which leads to the result.
477"
REFERENCES,0.4049168474331164,"2 - Lower bound on σ2
⋆,η. By definition of xη as the minimizer of fη, we have fη(xη) ≤fη(x⋆), and
478"
REFERENCES,0.40563991323210413,"so:
479"
REFERENCES,0.4063629790310918,"σ2
⋆,η = f(x⋆) −fη(xη)"
REFERENCES,0.40708604483007954,"η
≥f(x⋆) −fη(x⋆) η
= 1"
REFERENCES,0.4078091106290672,"η2 E

Dh(x⋆, x+
⋆)

.
(22) 480"
REFERENCES,0.40853217642805495,"Let us now prove the following proposition, which follows the proof from Dragomir et al. [7].
481"
REFERENCES,0.4092552422270427,"Proof of Proposition 2.7. Let us prove that σ2
⋆,η ≤E
h
∥∇fξ(x⋆)∥2
∇2h∗(zη)
i
. We start by
482"
REFERENCES,0.40997830802603036,"Dh(x, x+) = Dh∗(∇h(x) −η∇fξ(x), ∇h(x))
(23)
= Dh∗(∇h(x) −η [∇fξ(x) −∇fξ(x⋆)] −η∇fξ(x⋆), ∇h(x))
(24)"
REFERENCES,0.4107013738250181,= Dh∗((∇h(x) −2η [∇fξ(x) −∇fξ(x⋆)]) + (∇h(x) −2η∇fξ(x⋆))
REFERENCES,0.41142443962400577,"2
, ∇h(x)). (25)"
REFERENCES,0.4121475054229935,"Using the convexity of Dh∗in its first argument and then the Bregman cocoercivity lemma, we obtain
483"
REFERENCES,0.4128705712219812,"for η ≤1/2L:
484"
REFERENCES,0.4135936370209689,"Dh(x, x+) ≤1"
REFERENCES,0.41431670281995664,"2Dh∗(∇h(x) −2η [∇fξ(x) −∇fξ(x⋆)]), ∇h(x))
(26) + 1"
REFERENCES,0.4150397686189443,"2Dh∗(∇h(x) −2η∇fξ(x⋆), ∇h(x))
(27)"
REFERENCES,0.41576283441793205,"≤ηDfξ(x, x⋆) + 1"
REFERENCES,0.4164859002169197,"2Dh∗(∇h(x) −2η∇fξ(x⋆), ∇h(x)).
(28)"
REFERENCES,0.41720896601590746,"Using that E

Dfξ(x, x⋆)

= Df(x, x⋆) and applying this to x = xη, we obtain
485"
REFERENCES,0.41793203181489513,"σ2
⋆,η = f(x⋆) −fη(xη) η"
REFERENCES,0.41865509761388287,"= E

Dh(xη, x+
η )

+ ηf(x⋆) −ηf(xη) η2"
REFERENCES,0.4193781634128706,"≤
1
2η2 E [Dh∗(∇h(xη) −2η∇fξ(x⋆), ∇h(xη))] + Df(xη, x⋆) + f(x⋆) −f(xη) η"
REFERENCES,0.4201012292118583,"=
1
2η2 E [Dh∗(∇h(xη) −2η∇fξ(x⋆), ∇h(xη))] =
1
2η2 × E
1"
REFERENCES,0.420824295010846,"2∥2η∇fξ(x⋆)∥2
∇2h∗(zη) 
,"
REFERENCES,0.4215473608098337,"and the result follows. The last inequality comes from the fact that if x⋆= arg minx∈C f(x), then
486"
REFERENCES,0.4222704266088214,"−∇f(x⋆) is normal to C so −∇f(x⋆)⊤(xη −x⋆) ≤0. .
487"
REFERENCES,0.4229934924078091,"C
Convergence results.
488"
REFERENCES,0.4237165582067968,"In this section, we detail the proofs of the various convergence theorems that were only sketched in
489"
REFERENCES,0.4244396240057845,"the main text. We start by proving the first identity, which is a variation of e.g., Dragomir et al. [7,
490"
REFERENCES,0.42516268980477223,"Lemma 4], which we detail here for the sake of completeness.
491"
REFERENCES,0.42588575560375996,"Lemma C.1. Let x+ ∈C be such that ∇h(x+) = ∇h(x)−η∇fξ(x), with fξ a random differentiable
492"
REFERENCES,0.42660882140274764,"function such that E [fξ] = f. Then, for all points y ∈C,
493"
REFERENCES,0.42733188720173537,"E

Dh(y, x+)

−Dh(y, x) + ηDf(y, x) = −η[f(x) −f(y)] + E

Dh(x, x+)

(29)"
REFERENCES,0.42805495300072305,"In particular, we can apply the result to y = x⋆.
494"
REFERENCES,0.4287780187997108,"Proof. We give a slightly different proof than Dragomir et al. [7], and in particular this version of the
495"
REFERENCES,0.42950108459869846,"identity is slightly more direct (though maybe less insightful) and does not require ∇f(y) = 0. We
496"
REFERENCES,0.4302241503976862,"write:
497"
REFERENCES,0.4309472161966739,"E

Dh(y, x+)

= E

h(y) −h(x+) −∇h(x+)⊤(y −x+)
"
REFERENCES,0.4316702819956616,"= E

h(y) −h(x+) −∇h(x+)⊤(y −x) −∇h(x+)⊤(x −x+)
"
REFERENCES,0.43239334779464933,"= E

h(y) −h(x) −∇h(x)⊤(y −x) + η∇fξ(x)⊤(y −x)"
REFERENCES,0.433116413593637,"∇h(x+)⊤(x −x+) + h(x) −h(x+)
"
REFERENCES,0.43383947939262474,"= Dh(y, x) + η∇f(x)⊤(y −x) + E

Dh(x, x+)
"
REFERENCES,0.4345625451916124,"= Dh(y, x) −ηDf(y, x) + η [f(y) −f(x)] + E

Dh(x, x+)

. 498"
REFERENCES,0.43528561099060015,"Proof of Corollary 3.2. We start back from Equation (8), and write, using that fη(x) ≥E [fξ(x+)]
499"
REFERENCES,0.4360086767895879,"(proof of Proposition 2.2):
500"
REFERENCES,0.43673174258857556,"E

Dh(x⋆, x+)

−Dh(x⋆, x)+ηDf(x⋆, x) = η [f(x⋆) −fη(x)]
(30)"
REFERENCES,0.4374548083875633,"≤η

f(x⋆) −E

fξ(x+)

(31)"
REFERENCES,0.43817787418655096,"≤−η

E

fξ(x+)

−f +
⋆

+ η2
f(x⋆) −f +
⋆
η"
REFERENCES,0.4389009399855387,"
.
(32)"
REFERENCES,0.4396240057845264,"The result follows naturally from using the relative strong convexity of f, leading to:
501"
REFERENCES,0.4403470715835141,"η[E

fξ(x+)

−f ⋆
+] + E

Dh(x⋆, x+)

≤(1 −ηµ)Dh(x⋆, x) + η2
f(x⋆) −f ⋆
+
η"
REFERENCES,0.4410701373825018,"
.
(33)"
REFERENCES,0.4417932031814895,"Then, we chain iterations as done for Theorem 3.1
502"
REFERENCES,0.44251626898047725,"Proof of Theorem 3.3. We also start from the same result as above, and write it for x = x(k), so that
503"
REFERENCES,0.4432393347794649,"x+ = x(k+1):
504"
REFERENCES,0.44396240057845265,"E
h
Dh(x⋆, x(k+1))
i
−Dh(x⋆, x(k))+ηDf(x⋆, x(k)) = η
h
f(x⋆) −fη(x(k))
i
(34)"
REFERENCES,0.44468546637744033,"≤−η
h
fη(x(k)) −fη(xη)
i
+ η2σ2
⋆,η.
(35)"
REFERENCES,0.44540853217642806,"Moving the fη terms to the left, and summing this for k = 0 to T leads to:
505 η T
X k=0"
REFERENCES,0.44613159797541574,"h
fη(x(k)) −fη(xη) + Df(x⋆, x(k))
i
≤Dh(x⋆, x(0))−E
h
Dh(x⋆, x(k+1))
i
+Tη2σ2
⋆,η. (36)"
REFERENCES,0.44685466377440347,"The final result is obtained by dividing by ηT, and the fact that E

Dh(x⋆, x(k+1))

≥0.
506"
REFERENCES,0.4475777295733912,Proof of Proposition 3.4. We use Bregman cocoercivity (Lemma A.3) with η = 1
REFERENCES,0.4483007953723789,"L between x⋆and
507"
REFERENCES,0.4490238611713666,"x (instead of x and x⋆as it had been done previously), which directly leads to:
508"
REFERENCES,0.4497469269703543,"Dh∗

∇h∗(x⋆) −1"
REFERENCES,0.450469992769342,"L [∇f(x⋆) −∇f(x)]

≤1"
REFERENCES,0.4511930585683297,"LDf(x⋆, x).
(37)"
REFERENCES,0.45191612436731743,"The first part of the proposition follows from the fact that ∇f(x⋆) = 0. For the rest proof, we start
509"
REFERENCES,0.45263919016630516,"with Inequality (32), which gives:
510"
REFERENCES,0.45336225596529284,0 = Dh∗(∇h(x⋆) −1
REFERENCES,0.45408532176428057,"L∇f(x), ∇h(x⋆)) = Dh"
REFERENCES,0.45480838756326825,"
x⋆, ∇h∗

∇h(x⋆) −1"
REFERENCES,0.455531453362256,"L∇f(x)

."
REFERENCES,0.45625451916124365,"At this point, strict convexity of h leads to ∇h∗ 
∇h(x⋆) −1"
REFERENCES,0.4569775849602314,"L∇f(x)

= x⋆, so that ∇f(x) = 0 by
511"
REFERENCES,0.45770065075921906,"applying ∇h on both sides.
512"
REFERENCES,0.4584237165582068,"D
Variation on the convex case
513"
REFERENCES,0.4591467823571945,"In this section, we quickly illustrate that the result we obtain is tightly linked to the notion of variance
514"
REFERENCES,0.4598698481561822,"that we define. As an example, a variation of Theorem 3.3 can be obtained with a control on
515"
REFERENCES,0.46059291395516994,"f(x) −f(x⋆), but this requires a different notion of variance:
516"
REFERENCES,0.4613159797541576,"Theorem D.1. If f is convex, the iterates obtained by SMD using a constant step-sizes η > 0 verify
517 E "" f"
T,0.46203904555314534,"1
T T
X"
T,0.462762111352133,"k=0
x(k)
!#"
T,0.46348517715112075,"−f(x⋆) ≤Dh(x⋆, x(0))"
T,0.4642082429501085,"ηT
+ η˜σ2
⋆,η,
(38)"
T,0.46493130874909616,"where
518"
T,0.4656543745480839,"˜σ2
⋆,η = 1"
T,0.46637744034707157,"η max
x∈C 1"
T,0.4671005061460593,"η E

Dh(x, x+)

−Df(x⋆, x)

.
(39)"
T,0.467823571945047,"Note that this alternative variance definition can be unbounded even when σ2
⋆,η is bounded, as is the
519"
T,0.4685466377440347,"case for instance in the Gaussian MAP example. Besides, it does not inherit from most of the good
520"
T,0.4692697035430224,"properties of σ2
⋆,η presented in Section 2, and cannot be compared to the other standard variance
521"
T,0.4699927693420101,"notions. The main case in which this alternative definition makes sense is the Euclidean case, in
522"
T,0.47071583514099785,"which ˜σ2
⋆,η can be bounded using cocoercivity.
523"
T,0.47143890093998553,"Proof of Theorem D.1. This proof directly starts from Lemma C.1:
524"
T,0.47216196673897326,"E
h
Dh(x⋆, x(k+1))
i
(40)"
T,0.47288503253796094,"= Dh(x⋆, x(k)) −ηDf(x⋆, x(k)) −η[f(x(k)) −f(x⋆)] + E
h
Dh(x(k), (x(k))+)
i
(41)"
T,0.47360809833694867,"= Dh(x⋆, x(k)) −η[f(x(k)) −f(x⋆)] + η
1"
T,0.47433116413593635,"η E
h
Dh(x(k), (x(k))+)
i
−Df(x⋆, x(k))

(42)"
T,0.4750542299349241,"≤Dh(x⋆, x(k)) −η[f(x(k)) −f(x⋆)] + η2˜σ2
⋆,η.
(43)"
T,0.4757772957339118,"Summing this for k = 0 to T, and dividing by ηT we obtain:
525"
T,0.4765003615328995,"1
T T
X"
T,0.4772234273318872,"k=0
f(x(k)) −f(x⋆) ≤Dh(x⋆, x(0))"
T,0.4779464931308749,"ηT
+ η˜σ2
⋆,η
(44)"
T,0.4786695589298626,"The result on the average iterate then follows from convexity of f and taking expectation on x(k).
526"
T,0.4793926247288503,"E
Stochastic Mirror Descent with a Proximal term
527"
T,0.48011569052783803,"We are interested in this section in a variation of the original problem, where we would like to solve
528"
T,0.48083875632682577,"the following problem:
529"
T,0.48156182212581344,"min
x∈C f(x) + g(x),
(45)"
T,0.4822848879248012,"where g is a convex proper lower semi-continuous function (but not necessarily differentiable). This
530"
T,0.48300795372378885,"problem can be solved using the following stochastic proximal mirror descent algorithm:
531"
T,0.4837310195227766,"x+ = arg min
u∈C g(u) + ∇fξ(x)⊤u + 1"
T,0.48445408532176426,"η Dh(u, x).
(46)"
T,0.485177151120752,"This is a “proximal” version, which for instance corresponds to projected stochastic mirror descent if
532"
T,0.48590021691973967,"g is the indicator of a convex set. Under Assumption 1, the iterations write:
533"
T,0.4866232827187274,"∇h(x+) = ∇h(x) −η [∇fξ(x) + ω]
(47)"
T,0.48734634851771513,"where ω ∈∂g(x+), the subgradient of g at point x+. Equation (47) can be rewritten as
534"
T,0.4880694143167028,"∇h(x+) + ηω = ∇h(x) + ηωx −η [∇fξ(x) + ωx]
(48)"
T,0.48879248011569054,"for any ωx ∈∂g(x). In particular, (47) can be interpreted as a Stochastic mirror descent step with
535"
T,0.4895155459146782,"objective fξ + g and mirror h + ηg. While the mirror does not satisfy Assumption 1 (and in particular
536"
T,0.49023861171366595,"twice differentiability in case g is the indicator of a set), the iterations can still be written in the form
537"
T,0.4909616775126536,"of Equation (3). In particular, the theorems from Section 3 still apply, with the adapted variance
538"
T,0.49168474331164136,"definition involving function f + g and mirror h + ηg. Similarly, f + g is 1/η relatively-smooth with
539"
T,0.4924078091106291,"respect to h + ηg as long as f is L-relatively-smooth with respect to h and η ≤1/L.
540"
T,0.49313087490961677,"We now prove an equivalent for Lemma C.1.
541"
T,0.4938539407086045,"Lemma E.1. Let x+ ∈C be such that ∇h(x+) = ∇h(x) −η [∇fξ(x) + ω], with fξ a random
542"
T,0.4945770065075922,"differentiable function such that E [fξ] = f and ω ∈∂g(x+) where g is a convex proper lower
543"
T,0.4953000723065799,"semi-continuous function. Then, for all y ∈C ∩domg,
544"
T,0.4960231381055676,"E

Dh(y, x+)

= Dh(y, x) −ηDf(y, x) −η[f(x) −f(y)]"
T,0.4967462039045553,"+ E

Dh(x, x+f) −Dh(x+, x+f)

+ ηω⊤(y −x+),"
T,0.49746926970354305,"where x+f is the point such that ∇h(x+f) = ∇h(x) −η∇fξ(x).
545"
T,0.4981923355025307,"Proof. We write:
546"
T,0.49891540130151846,"Dh(y, x+) = h(y) −h(x+) −∇h(x+)⊤(y −x+)"
T,0.49963846710050613,= h(y) −h(x+f) −∇h(x+f)⊤(y −x+) + ηω⊤(y −x+) −h(x+) + h(x+f)
T,0.5003615328994938,"= Dh(y, x+f) −∇h(x+f)⊤(x+f −x+) + ηω⊤(y −x+) −h(x+) + h(x+f)"
T,0.5010845986984815,"= Dh(y, x+f) −Dh(x+, x+f) + ηω⊤(y −x+)"
T,0.5018076644974693,"The result follows from applying Lemma C.1 to Dh(y, x+f).
547"
T,0.502530730296457,"Note that by abuse of notation, if we denote Dg(y, x+) = g(y) −g(x+) −ω⊤(y −x+), and
548"
T,0.5032537960954447,"Dg(y, x) = g(y)−g(x)−ω⊤
x (y−x) for any ωx ∈∂g(x), then with a few lines of computations, and
549"
T,0.5039768618944324,"noting in particular that Dh(x, x+f) −Dh(x+, x+f) = Dh(x, x+) −

∇h(x+f) −∇h(x+)
⊤(x −
550"
T,0.5046999276934201,"x+) we obtain:
551"
T,0.5054229934924078,"E

Dh+ηg(y, x+)

= Dh(y, x) −ηDf(y, x) −η[f(x) −f(y)]"
T,0.5061460592913956,"+ E

Dh(x, x+)

−ηE

ω⊤(x −x+)

+ ηE

g(y) −g(x+)
"
T,0.5068691250903832,"= Dh+ηg(y, x) −ηDg(y, x) −ηDf(y, x) −η[f(x) −f(y)]"
T,0.5075921908893709,"+ E

Dh+ηg(x, x+)

+ η [g(y) −g(x)]"
T,0.5083152566883586,"In particular, we exactly recover the result of Lemma C.1 applied to the iterations in which we take
552"
T,0.5090383224873464,"(sub)-gradients of f + g with mirror h + ηg, i.e.,
553"
T,0.5097613882863341,"E

Dh+ηg(y, x+)

=Dh+ηg(y, x) −ηDf+g(y, x) −η[(f + g)(x) −(f + g)(y)] + EDh+g(x, x+)."
T,0.5104844540853217,"Therefore, using the same sequence of derivations, Theorems 3.1 and 3.3 can be transposed directly
554"
T,0.5112075198843095,"to the composite (f + g) setting by simply defining generalized Bregman divergences where the
555"
T,0.5119305856832972,"gradient parts are replaced by the subgradients picked in the actual SMD steps.
556"
T,0.5126536514822849,"While h + ηg does not necessarily satisfy Assumption 1, the key point is that iterations can be written
557"
T,0.5133767172812725,"in the form of Equation (47), which is the case for instance if g is the indicator of a convex set.
558"
T,0.5140997830802603,"Note that Corollary 3.2 also holds in the same way, since relative smoothness is only needed to obtain
559"
T,0.514822848879248,"that ηDfξ+g(x, x+) ≤Dh+ηg(x, x+), which is equivalent to ηDfξ(x, x+) ≤Dh(x, x+), which
560"
T,0.5155459146782357,"holds by L-relative smoothness of f with respect to h for η ≤1/L.
561"
T,0.5162689804772235,"F
Gaussian case with unknown covariance.
562"
T,0.5169920462762111,"In this section, we prove the various results for Gaussian estimation with unknown mean and
563"
T,0.5177151120751988,"covariance. For the sake of brevity, we only prove the propositions, and refer the interested reader to,
564"
T,0.5184381778741866,"e.g., Le Priol et al. [17] for standard results about the setting.
565"
T,0.5191612436731743,"F.1
Instanciation in the Stochastic mirror descent setting
566"
T,0.519884309472162,"We first write what the various divergences are in our setting, together with the mirror updates and
567"
T,0.5206073752711496,"finally the form of fη. Following Le Priol et al. [17, Section 4.2], we write that:
568"
T,0.5213304410701374,θ1 = m
T,0.5220535068691251,"Σ2 ,
θ2 = −1"
T,0.5227765726681128,"2Σ2 .
(49)"
T,0.5234996384671005,"This allows us to express A(θ) in terms of (m, Σ2):
569"
T,0.5242227042660882,A(θ) = −1
T,0.5249457700650759,"2 log(−θ2) −θ2
1
4θ2
= 1"
T,0.5256688358640637,"2 log(2Σ2) + 1 2
m2"
T,0.5263919016630514,"Σ2
(50)"
T,0.527114967462039,"Proposition F.1. The Bregman divergence with respect to ˜θ, θ writes:
570"
T,0.5278380332610267,"DA(˜θ, θ) = −1"
LOG,0.5285610990600145,"2 log
Σ2 ˜Σ2"
LOG,0.5292841648590022,"
−
˜Σ2 −Σ2"
LOG,0.5300072306579898,"2˜Σ2
+ ( ˜m −m)2"
LOG,0.5307302964569776,"2˜Σ2
.
(51)"
LOG,0.5314533622559653,"Proof. We know that ∇A(θ) = µ = (m, m2 + Σ2). Therefore,
571"
LOG,0.532176428054953,"∇A(θ)⊤(˜θ −θ) = m
 ˜m"
LOG,0.5328994938539408,"˜Σ2 −m Σ2 
−1"
LOG,0.5336225596529284,"2(m2 + Σ2)
 1"
LOG,0.5343456254519161,˜Σ2 −1 Σ2
LOG,0.5350686912509038,"
(52)"
LOG,0.5357917570498916,= m ˜m
LOG,0.5365148228488793,˜Σ2 −m2
LOG,0.5372378886478669,2Σ2 −m2
LOG,0.5379609544468547,2˜Σ2 −1 2 Σ2
LOG,0.5386840202458424,"˜Σ2 −1

(53)"
LOG,0.5394070860448301,= −(m −˜m)2
LOG,0.5401301518438177,"2˜Σ2
+ ˜m2"
LOG,0.5408532176428055,2˜Σ2 −m2
LOG,0.5415762834417932,2Σ2 −Σ2 −˜Σ2
LOG,0.5422993492407809,"2˜Σ2
.
(54)"
LOG,0.5430224150397687,"Using Equation (50), we obtain:
572"
LOG,0.5437454808387563,"DA(˜θ, θ) = A(˜θ) −A(θ) −∇A(θ)⊤(˜θ −θ) = 1"
LOG,0.544468546637744,2 log(2˜Σ2) −1
LOG,0.5451916124367318,2 log(2Σ2) + Σ2 −˜Σ2
LOG,0.5459146782357195,"2˜Σ2
+ (m −˜m)2"
LOG,0.5466377440347071,"2˜Σ2
,"
LOG,0.5473608098336948,"which finishes the proof.
573"
LOG,0.5480838756326826,"In the Gaussian with unknown covariance, the sufficient statistics are:
574"
LOG,0.5488069414316703,"T(X) = (X, X2),
(55)"
LOG,0.549530007230658,"where x ∈R is an observation drawn from N(m⋆, Σ⋆).
575"
LOG,0.5502530730296457,"Let us now prove the form on the updates, which corresponds to (13):
576"
LOG,0.5509761388286334,"Proposition F.2. In (m, Σ2) parameters, the updates write:
577"
LOG,0.5516992046276211,"m+ = (1 −η)m + ηX,
(56)"
LOG,0.5524222704266089,"(Σ2)+ = (1 −η)

Σ2 + η(m −X)2
.
(57)"
LOG,0.5531453362255966,"Proof. Since the (stochastic) gradients write g(µ) = µ −T(X), the iterations are defined by:
578"
LOG,0.5538684020245842,"µ+
1 = (1 −η)µ1 + ηX
(58)"
LOG,0.5545914678235719,"µ+
2 = (1 −η)µ2 + ηX2.
(59)"
LOG,0.5553145336225597,"Since (µ1, µ2) = (m, m2 + Σ2), the update on m is immediate. For the update on Σ2, we write:
579"
LOG,0.5560375994215474,"(Σ2)+ = µ+
2 −(m+)2"
LOG,0.556760665220535,= (1 −η)µ2 + ηX2 −((1 −η)m + ηX)2
LOG,0.5574837310195228,= (1 −η)Σ2 + (1 −η)m2 + ηX2 −(1 −η)2m2 −2η(1 −η)Xm −η2X2
LOG,0.5582067968185105,= (1 −η)Σ2 + η(1 −η)(m −X)2. 580
LOG,0.5589298626174982,"We now use this to show that updates are well-defined.
581"
LOG,0.559652928416486,"Proof of Proposition 4.1. If θ2 < 0 then Σ2 > 0 so for η < 1, (Σ2)+ > 0 almost surely so that
582"
LOG,0.5603759942154736,"θ+
2 < 0 and |θ+
1 | < ∞. In particular, θ+ ∈R × R∗
−so the update is well-defined. The rest of the
583"
LOG,0.5610990600144613,"proposition comes from the fact that ∇2fξ = ∇2f = ∇2A.
584"
LOG,0.561822125813449,"We can now proceed to proving the form of fη. We first start by writing that:
585"
LOG,0.5625451916124368,"f(θ) = A(θ) −θ⊤(m⋆, m2
⋆+ Σ2
⋆)
(60) = 1"
LOG,0.5632682574114244,"2 log(2Σ2) + 1 2
m2"
LOG,0.5639913232104121,Σ2 −mm⋆
LOG,0.5647143890093999,"Σ2
+ m2
⋆+ Σ2
⋆
2Σ2
.
(61)"
LOG,0.5654374548083876,"Therefore,
586"
LOG,0.5661605206073753,f(θ) = 1
LOG,0.5668835864063629,"2 log(2Σ2) + Σ2
⋆
2Σ2 + (m −m⋆)2"
LOG,0.5676066522053507,"2Σ2
(62)"
LOG,0.5683297180043384,"In particular,
587"
LOG,0.5690527838033261,f(θ) −f(θ⋆) = 1
LOG,0.5697758496023138,"2 log
Σ2 Σ2⋆"
LOG,0.5704989154013015,"
+ Σ2
⋆−Σ2"
LOG,0.5712219812002892,"2Σ2
+ (m −m⋆)2"
LOG,0.571945046999277,"2Σ2
(63)"
LOG,0.5726681127982647,"Note that, as expected, this corresponds to DA(θ, θ⋆), that we can also compute through Proposi-
588"
LOG,0.5733911785972523,"tion F.1. We now write:
589"
LOG,0.57411424439624,"DA(θ, θ+) = −1"
LOG,0.5748373101952278,"2 log
(Σ2)+ Σ2"
LOG,0.5755603759942155,"
−Σ2 −(Σ2)+"
LOG,0.5762834417932032,"2Σ2
+ (m −m+)2"
LOG,0.5770065075921909,"2Σ2
(64) = −1"
LOG,0.5777295733911786,"2 log

(1 −η)

1 + η (m −X)2 Σ2"
LOG,0.5784526391901663,"
+ (1 −η)(Σ2 + η(m −X)2) −Σ2"
LOG,0.579175704989154,"2Σ2
+ η2(m −X)2"
LOG,0.5798987707881417,"2Σ2
(65) = −1"
LOG,0.5806218365871294,"2 log

(1 −η)

1 + η (m −X)2 Σ2 
−η"
LOG,0.5813449023861171,2 + η(1 −η)(m −X)2
LOG,0.5820679681851049,"2Σ2
+ η2(m −X)2"
LOG,0.5827910339840926,"2Σ2
(66) = −1"
LOG,0.5835140997830802,"2 log

(1 −η)

1 + η (m −X)2 Σ2 
−η"
LOG,0.584237165582068,2 + η (m −X)2
LOG,0.5849602313810557,"2Σ2
.
(67)"
LOG,0.5856832971800434,"Therefore,
590"
LOG,0.586406362979031,"f(θ) −DA(θ, θ+)"
LOG,0.5871294287780188,"η
−f(θ⋆)
(68) = 1"
LOG,0.5878524945770065,"2 log
Σ2 Σ2⋆"
LOG,0.5885755603759942,"
+ Σ2
⋆−Σ2"
LOG,0.589298626174982,"2Σ2
+ (m −m⋆)2"
LOG,0.5900216919739696,"2Σ2
+ 1"
LOG,0.5907447577729573,"2η log

(1 −η)

1 + η (m −X)2 Σ2"
LOG,0.591467823571945,"
+ 1"
LOG,0.5921908893709328,2 −(m −X)2
LOG,0.5929139551699205,"2Σ2
(69) = 1"
LOG,0.5936370209689081,"2 log
Σ2 Σ2⋆ 
+ 1"
LOG,0.5943600867678959,"2η log

(1 −η)

1 + η (m −X)2 Σ2"
LOG,0.5950831525668836,"
+ Σ2
⋆
2Σ2 + (m −m⋆)2"
LOG,0.5958062183658713,"2Σ2
−(m −X)2 2Σ2
. (70)"
LOG,0.596529284164859,"Finally, E

(m −X)2
= (m −m⋆)2 + Σ2
⋆, and so:
591"
LOG,0.5972523499638467,fη(θ) −f(θ⋆) = 1
LOG,0.5979754157628344,"2 log
Σ2 Σ2⋆ 
+ 1"
LOG,0.5986984815618221,"2η E

log

(1 −η)

1 + η (m −X)2 Σ2"
LOG,0.5994215473608099,"
,
(71)"
LOG,0.6001446131597975,"which precisely corresponds to Equation (14). We now proceed to proving bounds on θη for η < 1.
592"
LOG,0.6008676789587852,"F.2
Bounding the stochastic mirror descent variance σ2
⋆,η.
593"
LOG,0.601590744757773,"Now that we have an explicit form for fη, we can characterize its minimizer θη, and use this to prove
594"
LOG,0.6023138105567607,"results on fη(θη), which will in turn lead to bounds on σ2
⋆,η. This is the core of Lemma 4.2.
595"
LOG,0.6030368763557483,"Proof. Proof of Lemma 4.2. The proof will proceed in three different stages:
596"
LOG,0.603759942154736,"• Differentiating fη with respect to m and Σ2.
597"
LOG,0.6044830079537238,"• Using these expressions to obtain bounds on the (mη, Σ2
η) for which ∇fη is 0.
598"
LOG,0.6052060737527115,"• Plugging these bounds into the expression of fη to bound Σ2
η.
599"
LOG,0.6059291395516992,"1 - Differentiating fη.
Before differentiating, we rewrite:
600"
LOG,0.6066522053506869,fη(θ) −f(θ⋆) = 1
LOG,0.6073752711496746,"2 log
 
Σ2
+ 1"
LOG,0.6080983369486623,"2η E

log

1 + η (m −X)2 Σ2 
−1"
LOG,0.6088214027476501,"2 log
 
Σ2
⋆

+ 1"
LOG,0.6095444685466378,2η log(1 −η) (72)
LOG,0.6102675343456254,= −1 −η
LOG,0.6109906001446131,"2η
log
 
Σ2
+ 1"
LOG,0.6117136659436009,"2η E

log
 
Σ2 + η(m −X)2
−1"
LOG,0.6124367317425886,"2 log
 
Σ2
⋆

+ 1"
LOG,0.6131597975415762,2η log(1 −η).
LOG,0.613882863340564,"(73)
Indeed, the two terms on the right are constant and so do not matter. If we differentiate in m, we
601"
LOG,0.6146059291395517,"obtain:
602"
LOG,0.6153289949385394,"∇mfη(θ) = E
 1"
LOG,0.6160520607375272,2η 2η m −X
LOG,0.6167751265365148,"Σ2
1
Σ2 + η(m −X)2"
LOG,0.6174981923355025,"
= E

m −X
Σ2 + η(m −X)2"
LOG,0.6182212581344902,"
.
(74)"
LOG,0.618944323933478,"Now, differentiating in Σ2 yields:
603"
LOG,0.6196673897324656,∇Σ2fη(θ) = −1 −η
LOG,0.6203904555314533,2ηΣ2 + 1
LOG,0.6211135213304411,"2η E

1
Σ2 + η(m −X)2"
LOG,0.6218365871294288,"
=
1
2Σ2 −E

(m −X)2"
LOG,0.6225596529284165,2Σ2(Σ2 + η(m −X)2)
LOG,0.6232827187274042,"
. (75)"
LOG,0.6240057845263919,"2 - Obtaining bounds on (mη, Σ2
η).
The solution to ∇mfη(θ) = 0 is m = m⋆. Indeed, it is direct
604"
LOG,0.6247288503253796,"to verify that in this case, E
h
˜
X
Σ2+η ˜
X2
i
= 0 since ˜X = m⋆−X is symmetric (with respect to 0). For
605"
LOG,0.6254519161243673,"m > m⋆, E
h
˜
X
Σ2+η ˜
X2
i
> 0 since we integrate the same values as the previous case, but now more
606"
LOG,0.6261749819233551,"mass is put on the positive values (and similarly for m < m⋆). Note that this is the case regardless of
607"
LOG,0.6268980477223427,"Σ2
η.
608"
LOG,0.6276211135213304,"We are now interested in Σ2
η. Note that we will not get such a clean expression as for mη, but only
609"
LOG,0.6283441793203182,"bounds. From its expression, we deduce that ∇Σ2fη(θη) = 0 can be reformulated as:
610"
LOG,0.6290672451193059,"E

(mη −X)2"
LOG,0.6297903109182935,Σ2η + ηη(m −X)2
LOG,0.6305133767172812,"
= 1
(76)"
LOG,0.631236442516269,"For the upper bound, we simply write that:
611"
LOG,0.6319595083152567,"1 = E

(mη −X)2"
LOG,0.6326825741142444,Σ2η + ηη(m −X)2
LOG,0.6334056399132321,"
≤E
(mη −X)2 Σ2η"
LOG,0.6341287057122198,"
= Σ2
⋆
Σ2η
,
(77)"
LOG,0.6348517715112075,"from which we deduce that Σ2
η ≤Σ2
⋆. Let us now introduce some α > 0. We have that:
612"
LOG,0.6355748373101953,"E

(mη −X)2"
LOG,0.6362979031091829,Σ2η + η(mη −X)2
LOG,0.6370209689081706,"
= E

(mη −X)2"
LOG,0.6377440347071583,"α −α + Σ2η + η(mη −X)2 
= E"
LOG,0.6384671005061461,"""
(mη −X)2 α
1"
LOG,0.6391901663051338,"1 −1 +
Σ2η+η(mη−X)2 α # (78)"
LOG,0.6399132321041214,"We now use that for u ≥−1,
1
1+u ≥1 −u, and so:
613"
LOG,0.6406362979031092,"E

(mη −X)2"
LOG,0.6413593637020969,"Σ2η + η(mη −X)2 
≥E"
LOG,0.6420824295010846,"""
(mη −X)2 α  1 − """
LOG,0.6428054953000724,"−1 + Σ2
η + η(mη −X)2 α #!# (79) = E"
LOG,0.64352856109906,"""
(mη −X)2 α "
LOG,0.6442516268980477,"2 −Σ2
η
α !"
LOG,0.6449746926970354,−η (mη −X)4 α2 #
LOG,0.6456977584960232,".
(80)"
LOG,0.6464208242950108,"Now, recall that mη = m⋆, so X −mη ∼N(0, Σ⋆), leading to
614"
LOG,0.6471438900939985,"1 = E

(mη −X)2"
LOG,0.6478669558929863,Σ2η + η(mη −X)2
LOG,0.648590021691974,"
≥Σ2
⋆
α "
LOG,0.6493130874909617,"2 −Σ2
η
α !"
LOG,0.6500361532899493,"−η 3Σ4
⋆
α2 .
(81)"
LOG,0.6507592190889371,"Rearranging terms, we obtain:
615 α2"
LOG,0.6514822848879248,"Σ2⋆
−2α ≥−Σ2
η −3Σ2
⋆, so Σ2
η ≥2αΣ2
⋆−α2"
LOG,0.6522053506869125,"Σ2⋆
−3ηΣ2
⋆.
(82)"
LOG,0.6529284164859002,"We see that α = Σ2
⋆maximizes the right term, and we obtain the desired result, i.e.:
616"
LOG,0.6536514822848879,"Σ2
η ≥(1 −3η)Σ2
⋆.
(83)"
LOG,0.6543745480838756,"Unfortunately, we see that this bound is only informative for 3η < 1. For the rest of the cases, we
617"
LOG,0.6550976138828634,"will use the Markov inequality instead, which writes for all a > 0:
618"
LOG,0.6558206796818511,"P

(mη −X)2"
LOG,0.6565437454808387,"Σ2η + η(mη −X)2 ≥a

≤1"
LOG,0.6572668112798264,"aE

(mη −X)2"
LOG,0.6579898770788142,"Σ2η + η(mη −X)2 
= 1"
LOG,0.6587129428778019,"a.
(84)"
LOG,0.6594360086767896,"Yet,
619"
LOG,0.6601590744757773,"P

(mη −X)2"
LOG,0.660882140274765,"Σ2η + η(mη −X)2 ≥a

= P"
LOG,0.6616052060737527,(mη −X)2
LOG,0.6623282718727405,"Σ2⋆
≥
a
1 −ηa
Σ2
η
Σ2⋆ !"
LOG,0.6630513376717281,"= 2P
X −m⋆"
LOG,0.6637744034707158,"Σ⋆
≥
r
a
1 −ηa
Ση
Σ⋆ 
."
LOG,0.6644974692697035,"(85)
Therefore, denoting Φ the cumulative distribution function of the standard Gaussian, we have:
620"
LOG,0.6652205350686913,"2

1 −Φ
r
a
1 −ηa
Ση
Σ⋆ 
≤1"
LOG,0.665943600867679,"a,
(86)"
LOG,0.6666666666666666,"and since Φ−1 is an increasing function, this leads to:
621
r
a
1 −ηa
Ση
Σ⋆
≥Φ−1

1 −1"
A,0.6673897324656544,2a
A,0.6681127982646421,"
,
(87)"
A,0.6688358640636298,"so that:
622"
A,0.6695589298626174,"Ση ≥
p"
A,0.6702819956616052,"1 −ηaΦ−1  
1 −1"
A,0.6710050614605929,"2a
"
A,0.6717281272595806,"√a
Σ⋆
(88)"
A,0.6724511930585684,"One can check that Φ−1  
1 −1"
A,0.673174258857556,"2a

/√a < 1 for all a, which is consistent with the fact that Σ2
η ≤Σ2
⋆.
623"
A,0.6738973246565437,"Also note that for η = 1, a non-trivial bound would require a < 1, but then Φ−1  
1 −1"
A,0.6746203904555315,"2a

≤0 so
624"
A,0.6753434562545192,"(as expected), we cannot get better than Σ2
η ≥0. However, the previous bounding (Equation (83)) is
625"
A,0.6760665220535069,"more precise for small η since Φ−1  
1 −1"
A,0.6767895878524945,"2a

/√a < 1 −c with c > 0 a constant regardless of a. In
626"
A,0.6775126536514823,"particular, for any ε, by using any 1 < a < 1/(1 −ε), we obtain that Σ2
η ≥αεΣ2
⋆for some constant
627"
A,0.67823571945047,"αε that only depends on the a that we choose. In particular, we can handle the cases η = 1/2 and
628"
A,0.6789587852494577,"η = 1/3 that gave trivial results Σ2
η ≥0 with the previous bounds.
629"
A,0.6796818510484454,The last part consists in proving that fη(θη) −f(θ⋆) ≥1
LOG,0.6804049168474331,"2 log
 Σ2
η
Σ2⋆"
LOG,0.6811279826464208,"
. To do so, we start back from
630"
LOG,0.6818510484454086,fη(θ) −f(θ⋆) = 1
LOG,0.6825741142443963,"2 log
Σ2 Σ2⋆ 
+ 1"
LOG,0.6832971800433839,"2η E

log

(1 −η)

1 + η (m −X)2 Σ2 
,"
LOG,0.6840202458423716,"and show that E
h
log

(1 −η)
h
1 + η (mη−X)2 Σ2
η"
LOG,0.6847433116413594,"ii
≥0. We start by the inequality log(1+x) ≥
x
1+x,
631"
LOG,0.6854663774403471,"leading to:
632"
LOG,0.6861894432393347,"E

log

(1 −η)

1 + η (mη −X)2 Σ2η"
LOG,0.6869125090383225,"
≥E "
LOG,0.6876355748373102,"
(1 −η)
h
1 + η (mη−X)2 Σ2
η i
−1"
LOG,0.6883586406362979,"(1 −η)
h
1 + η (mη−X)2 Σ2
η i "
LOG,0.6890817064352857,"
(89) = E "
LOG,0.6898047722342733,"
η(1 −η) (mη−X)2"
LOG,0.690527838033261,"Σ2η
−η"
LOG,0.6912509038322487,"(1 −η)
h
1 + η (mη−X)2 Σ2η i "
LOG,0.6919739696312365,"
(90) = ηE"
LOG,0.6926970354302241,"""
(1 −η)(mη −X)2 −Σ2
η
(1 −η)

Σ2η + η(mη −X)2 # (91)"
LOG,0.6934201012292118,"Recall that the optimality conditions for (mη, Σ2
η) write:
633"
LOG,0.6941431670281996,"1 = E

(mη −X)2"
LOG,0.6948662328271873,"Σ2η + η(mη −X)2 
= 1 η E """
LOG,0.695589298626175,"1 −
Σ2
η
Σ2η + η(mη −X)2 #"
LOG,0.6963123644251626,",
(92)"
LOG,0.6970354302241504,"so that
634 E"
LOG,0.6977584960231381,"""
Σ2
η
Σ2η + η(mη −X)2 #"
LOG,0.6984815618221258,"= 1 −η.
(93)"
LOG,0.6992046276211136,"Combining these, we obtain that
635 E "" log "
LOG,0.6999276934201012,"(1 −η)

1 + η (mη −X)2 Σ2η  !# ≥ηE"
LOG,0.7006507592190889,"""
(1 −η)(mη −X)2 −Σ2
η
(1 −η)

Σ2η + η(mη −X)2 # = η "
LOG,0.7013738250180767,"E

(mη −X)2"
LOG,0.7020968908170644,Σ2η + η(mη −X)2
LOG,0.702819956616052,"
−
1
1 −η E"
LOG,0.7035430224150397,"""
Σ2
η
Σ2η + η(mη −X)2 #! = 0,"
LOG,0.7042660882140275,"which is the desired result.
636"
LOG,0.7049891540130152,"The final result is obtained by plugging the lower bounds for Σ2
η into this bound, leading to either
637"
LOG,0.7057122198120029,"σ2
⋆,η ≤−1"
LOG,0.7064352856109906,"2η log(1 −3η) for η < 1/3 or σ2
⋆,η ≤−1"
LOG,0.7071583514099783,"2η log αε for η < 1 −ε.
638 639"
LOG,0.707881417208966,"F.3
Unrolling the recursions to derive actual convergence results.
640"
LOG,0.7086044830079538,"F.3.1
Proof of Theorem 4.3
641"
LOG,0.7093275488069414,"Now that we have bounded the stochastic mirror descent variance σ2
⋆,η in this setting, we can plug it
642"
LOG,0.7100506146059291,"into Theorem 3.1 to obtain finite-time convergence guarantees on the MAP and MLE estimators.
643"
LOG,0.7107736804049168,"Proof of Theorem 4.3. Starting from Theorem 3.1, we obtain:
644"
LOG,0.7114967462039046,"DA(θ⋆, θ(k+1)) ≤(1 −η)DA(θ⋆, θ(k)) −η"
LOG,0.7122198120028923,"2 log (1 −3η) ≤(1 −η)DA(θ⋆, θ(k)) + 3η2"
LOG,0.7129428778018799,"2 ,
(94)"
LOG,0.7136659436008677,where the right term is replaced by cε (where cϵ = −1
LOG,0.7143890093998554,"2 log αε) for k ≤3. Taking η = 1/k for k > 1
645"
LOG,0.7151120751988431,"and multiplying by k leads for k > 3 to:
646"
LOG,0.7158351409978309,"kDA(θ⋆, θ(k+1)) ≤(k −1)DA(θ⋆, θ(k)) + 3"
LOG,0.7165582067968185,"2k .
(95)"
LOG,0.7172812725958062,"Therefore, a telescopic sum leads to, for n0 > 0:
647"
LOG,0.7180043383947939,"(n + n0)DA(θ⋆, θ(n)) ≤n0DA(θ⋆, θ(0)) + 3 2"
LOG,0.7187274041937817,"n+n0
X k=n0"
LOG,0.7194504699927693,"1
k + 2c1/2,
(96)"
LOG,0.720173535791757,"and so, since Pn
k=n0
1
k ≤log(n + n0 + 1) −log(n0):
648"
LOG,0.7208966015907448,"DA(θ⋆, θ(n)) ≤n0DA(θ⋆, θ(0)) + (3/2) log(1 + (n + 1)/n0) + Γ"
LOG,0.7216196673897325,"n + n0
,
(97)"
LOG,0.7223427331887202,"where Γ = 2c1/2 and we actually have Γ = 0 for n0 > 3.
649"
LOG,0.7230657989877078,"F.3.2
O(1/n) convergence result.
650"
LOG,0.7237888647866956,"We now consider a different estimator (from the MAP and the MLE), which we construct in the
651"
LOG,0.7245119305856833,"following way:
652"
LOG,0.725234996384671,"• Choose n0 ≥6 and initial parameter ˜θ(n0).
653"
LOG,0.7259580621836587,"• Obtain ˜θ(n) by performing n −n0 stochastic mirror descent steps from ˜θ(n0) with step-sizes
654"
LOG,0.7266811279826464,"ηk = 2/(k + 1) for k ∈{n0, ..., n}.
655"
LOG,0.7274041937816341,"This estimator is a modified version of the MAP, where n0 controls how much weight we would like
656"
LOG,0.7281272595806219,"to put on the prior, and ˜θ(n0) would typically be the same starting parameter as for the MAP estimator.
657"
LOG,0.7288503253796096,"This estimator is built so that we can use the convergence analysis from Lacoste-Julien et al. [16] and
658"
LOG,0.7295733911785972,"obtain a O(1/n) convergence rate. Note that we make the n0 ≥6 restriction for simplicity to ensure
659"
LOG,0.7302964569775849,"that σ2
⋆,η ≤3/2, but the result can be easily adapted to n0 ≥2.
660"
LOG,0.7310195227765727,"Proposition F.3. After n −n0 steps, this modified estimator ˜θ(n) verifies:
661"
LOG,0.7317425885755604,"EDh(θ⋆, ˜θ(n)) ≤2n0(n0 −1)"
LOG,0.7324656543745481,"n(n −1)
Dh(θ⋆, ˜θ(n0)) + 6"
LOG,0.7331887201735358,"n.
(98)"
LOG,0.7339117859725235,"Proof. Let us note Dk = E
h
Dh(θ⋆, ˜θ(k))
i
. In this case, using that σ2
⋆,η ≤3/2, Theorem 3.1 writes
662"
LOG,0.7346348517715112,"(since µ = 1):
663"
LOG,0.735357917570499,"Dk+1 ≤(1 −ηk)Dk + 3η2
k
2 .
(99)"
LOG,0.7360809833694866,"At this point, we can multiply by k(k + 1) on both sides, and take ηk =
2
k+1 for k ≥n0. Remarking
664"
LOG,0.7368040491684743,"that 1 −ηk = 1 −
2
k+1 = k−1"
LOG,0.737527114967462,"k+1, we obtain that:
665"
LOG,0.7382501807664498,"(k + 1)kDk+1 ≤k(k −1)Dk +
6k
k + 1 ≤k(k −1)Dk + 6.
(100)"
LOG,0.7389732465654375,"Unrolling this recursion from k = n0 to k = n −1 (since (k + 1)kDk+1 = Lk+1, where Lk =
666"
LOG,0.7396963123644251,"k(k −1)Dk), we obtain:
667"
LOG,0.7404193781634129,"n(n −1)Dn ≤n0(n0 −1)Dn0 + n−1
X"
LOG,0.7411424439624006,"k=n0
6,
(101)"
LOG,0.7418655097613883,"and the result follows by dividing by n(n −1), and using that (n −n0)/(n −1) ≤1.
668"
LOG,0.7425885755603759,"F.4
The case of the MLE
669"
LOG,0.7433116413593637,"For the MLE estimator, directly applying the mirror descent approach would require using η0 = 1,
670"
LOG,0.7440347071583514,"starting from an arbitrary θ(0) (that would not affect the results anyway). The problem in this case
671"
LOG,0.7447577729573391,"is that Dh(θ⋆, θ(1)) is infinite since Σ(2) = 0. This also means that we cannot start the stochastic
672"
LOG,0.7454808387563269,"mirror descent algorithm from θ(1), since the recursion would still involve the infinite Dh(θ⋆, θ(1)).
673"
LOG,0.7462039045553145,"Therefore, in the case of the MLE, considering that the first two samples are X(1) and X(2), then the
674"
LOG,0.7469269703543022,"first two points are:
675"
LOG,0.74765003615329,"m(1) = X(1), Σ(1) = 0 and m(2) = X(1) + X(2)"
LOG,0.7483731019522777,"2
, (Σ(2))2 = (X(1) −X(2))2"
LOG,0.7490961677512654,"4
.
(102)"
LOG,0.749819233550253,"More generally, a direct recursion for the MLE leads to:
676"
LOG,0.7505422993492408,"m(n) = 1 n n
X"
LOG,0.7512653651482285,"k=1
X(k), (Σ(n))2 = 1 n n
X"
LOG,0.7519884309472162,"k=1
(X(k) −m(n))2.
(103)"
LOG,0.7527114967462039,"From this, we derive that:
677"
LOG,0.7534345625451916,"E
h
(Σ(n))2i
= E
h
(X(n) −m(n))2i
(104) = E"
LOG,0.7541576283441793,"""
1 −1 n"
LOG,0.754880694143167,"
X(n) −n −1"
LOG,0.7556037599421548,"n
m(n−1)
2# (105)"
LOG,0.7563268257411424,"=
n −1 n"
LOG,0.7570498915401301,"2
E

X(n) −m⋆−(m(n−1) −m⋆)
2
(106)"
LOG,0.7577729573391179,"=
n −1 n"
LOG,0.7584960231381056,"2
E

X(n) −m⋆
2
+

m(n−1) −m⋆
2
(107)"
LOG,0.7592190889370932,"=
n −1 n"
LOG,0.759942154736081,"2 
Σ2
⋆+
1
n −1Σ2
⋆"
LOG,0.7606652205350687,"
=

1 −1 n"
LOG,0.7613882863340564,"
Σ2
⋆,
(108)"
LOG,0.7621113521330442,"where (107) comes from the fact that X(n) and m(n−1) are independent with mean m⋆. Plugging
678"
LOG,0.7628344179320318,"this into the expression of Dh(θ⋆, θ) for the MLE after n steps, we obtain:
679"
LOG,0.7635574837310195,"Dh(θ⋆, θ(n)) = −1"
E,0.7642805495300072,"2E

log (Σ(n))2 Σ2⋆"
E,0.765003615328995,"
.
(109)"
E,0.7657266811279827,"Unfortunately, there is no closed-form for this expression for arbitrary n, hence the need for a more
680"
E,0.7664497469269703,"involved analysis, for instance through the mirror descent framework. For the case n = 2 however
681"
E,0.767172812725958,"(which is the one we are interested in), we obtain that
682"
E,0.7678958785249458,"Dh(θ⋆, θ(2)) = −1"
E,0.7686189443239335,"2E """
E,0.7693420101229211,"log
X(1) −X(2) 2Σ⋆ 2# = −1"
E,0.7700650759219089,"2E

log Y 2 2"
E,0.7707881417208966,"
,
(110)"
E,0.7715112075198843,where Y = X(1)−X(2) √
E,0.7722342733188721,"2Σ⋆
∼N(0, 1). Therefore, this can simply be treated as a constant that we can
683"
E,0.7729573391178597,"precisely evaluate numerically (for instance remarking that Y 2 is gamma distributed and using results
684"
E,0.7736804049168474,"on logarithmic expectations of gamma distributions).
685"
E,0.7744034707158352,"For n > 2, it is tempting to use the convexity of −log to use a similar reasoning, but this only leads
686"
E,0.7751265365148229,"to a constant bound on Dh(θ⋆, θ(n)).
687"
E,0.7758496023138105,"NeurIPS Paper Checklist
688"
CLAIMS,0.7765726681127982,"1. Claims
689"
CLAIMS,0.777295733911786,"Question: Do the main claims made in the abstract and introduction accurately reflect the
690"
CLAIMS,0.7780187997107737,"paper’s contributions and scope?
691"
CLAIMS,0.7787418655097614,"Answer: [Yes]
692"
CLAIMS,0.779464931308749,"Justification: We have theorems for all the results we claim to have in the abstract.
693"
CLAIMS,0.7801879971077368,"Guidelines:
694"
CLAIMS,0.7809110629067245,"• The answer NA means that the abstract and introduction do not include the claims
695"
CLAIMS,0.7816341287057122,"made in the paper.
696"
CLAIMS,0.7823571945047,"• The abstract and/or introduction should clearly state the claims made, including the
697"
CLAIMS,0.7830802603036876,"contributions made in the paper and important assumptions and limitations. A No or
698"
CLAIMS,0.7838033261026753,"NA answer to this question will not be perceived well by the reviewers.
699"
CLAIMS,0.7845263919016631,"• The claims made should match theoretical and experimental results, and reflect how
700"
CLAIMS,0.7852494577006508,"much the results can be expected to generalize to other settings.
701"
CLAIMS,0.7859725234996384,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
702"
CLAIMS,0.7866955892986262,"are not attained by the paper.
703"
LIMITATIONS,0.7874186550976139,"2. Limitations
704"
LIMITATIONS,0.7881417208966016,"Question: Does the paper discuss the limitations of the work performed by the authors?
705"
LIMITATIONS,0.7888647866955893,"Answer: [Yes]
706"
LIMITATIONS,0.789587852494577,"Justification: Limitations for each result are discussed after they are introduced, in particular
707"
LIMITATIONS,0.7903109182935647,"the fact that Theorem 4.3 does not completely solve the problem from Le Priol et. al. (2021).
708"
LIMITATIONS,0.7910339840925524,"Guidelines:
709"
LIMITATIONS,0.7917570498915402,"• The answer NA means that the paper has no limitation while the answer No means that
710"
LIMITATIONS,0.7924801156905278,"the paper has limitations, but those are not discussed in the paper.
711"
LIMITATIONS,0.7932031814895155,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
712"
LIMITATIONS,0.7939262472885033,"• The paper should point out any strong assumptions and how robust the results are to
713"
LIMITATIONS,0.794649313087491,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
714"
LIMITATIONS,0.7953723788864787,"model well-specification, asymptotic approximations only holding locally). The authors
715"
LIMITATIONS,0.7960954446854663,"should reflect on how these assumptions might be violated in practice and what the
716"
LIMITATIONS,0.7968185104844541,"implications would be.
717"
LIMITATIONS,0.7975415762834418,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
718"
LIMITATIONS,0.7982646420824295,"only tested on a few datasets or with a few runs. In general, empirical results often
719"
LIMITATIONS,0.7989877078814173,"depend on implicit assumptions, which should be articulated.
720"
LIMITATIONS,0.7997107736804049,"• The authors should reflect on the factors that influence the performance of the approach.
721"
LIMITATIONS,0.8004338394793926,"For example, a facial recognition algorithm may perform poorly when image resolution
722"
LIMITATIONS,0.8011569052783803,"is low or images are taken in low lighting. Or a speech-to-text system might not be
723"
LIMITATIONS,0.8018799710773681,"used reliably to provide closed captions for online lectures because it fails to handle
724"
LIMITATIONS,0.8026030368763557,"technical jargon.
725"
LIMITATIONS,0.8033261026753434,"• The authors should discuss the computational efficiency of the proposed algorithms
726"
LIMITATIONS,0.8040491684743312,"and how they scale with dataset size.
727"
LIMITATIONS,0.8047722342733189,"• If applicable, the authors should discuss possible limitations of their approach to
728"
LIMITATIONS,0.8054953000723066,"address problems of privacy and fairness.
729"
LIMITATIONS,0.8062183658712943,"• While the authors might fear that complete honesty about limitations might be used by
730"
LIMITATIONS,0.806941431670282,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
731"
LIMITATIONS,0.8076644974692697,"limitations that aren’t acknowledged in the paper. The authors should use their best
732"
LIMITATIONS,0.8083875632682574,"judgment and recognize that individual actions in favor of transparency play an impor-
733"
LIMITATIONS,0.8091106290672451,"tant role in developing norms that preserve the integrity of the community. Reviewers
734"
LIMITATIONS,0.8098336948662328,"will be specifically instructed to not penalize honesty concerning limitations.
735"
THEORY ASSUMPTIONS AND PROOFS,0.8105567606652205,"3. Theory Assumptions and Proofs
736"
THEORY ASSUMPTIONS AND PROOFS,0.8112798264642083,"Question: For each theoretical result, does the paper provide the full set of assumptions and
737"
THEORY ASSUMPTIONS AND PROOFS,0.812002892263196,"a complete (and correct) proof?
738"
THEORY ASSUMPTIONS AND PROOFS,0.8127259580621836,"Answer: [Yes]
739"
THEORY ASSUMPTIONS AND PROOFS,0.8134490238611713,"Justification: Assumptions are clearly introduced, and all proofs can be found in the ap-
740"
THEORY ASSUMPTIONS AND PROOFS,0.8141720896601591,"pendix.
741"
THEORY ASSUMPTIONS AND PROOFS,0.8148951554591468,"Guidelines:
742"
THEORY ASSUMPTIONS AND PROOFS,0.8156182212581344,"• The answer NA means that the paper does not include theoretical results.
743"
THEORY ASSUMPTIONS AND PROOFS,0.8163412870571222,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
744"
THEORY ASSUMPTIONS AND PROOFS,0.8170643528561099,"referenced.
745"
THEORY ASSUMPTIONS AND PROOFS,0.8177874186550976,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
746"
THEORY ASSUMPTIONS AND PROOFS,0.8185104844540854,"• The proofs can either appear in the main paper or the supplemental material, but if
747"
THEORY ASSUMPTIONS AND PROOFS,0.819233550253073,"they appear in the supplemental material, the authors are encouraged to provide a short
748"
THEORY ASSUMPTIONS AND PROOFS,0.8199566160520607,"proof sketch to provide intuition.
749"
THEORY ASSUMPTIONS AND PROOFS,0.8206796818510484,"• Inversely, any informal proof provided in the core of the paper should be complemented
750"
THEORY ASSUMPTIONS AND PROOFS,0.8214027476500362,"by formal proofs provided in appendix or supplemental material.
751"
THEORY ASSUMPTIONS AND PROOFS,0.8221258134490239,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
752"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8228488792480115,"4. Experimental Result Reproducibility
753"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8235719450469993,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
754"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.824295010845987,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
755"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8250180766449747,"of the paper (regardless of whether the code and data are provided or not)?
756"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8257411424439624,"Answer: [NA]
757"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8264642082429501,"Justification: No experimental results.
758"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8271872740419378,"Guidelines:
759"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8279103398409255,"• The answer NA means that the paper does not include experiments.
760"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8286334056399133,"• If the paper includes experiments, a No answer to this question will not be perceived
761"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8293564714389009,"well by the reviewers: Making the paper reproducible is important, regardless of
762"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8300795372378886,"whether the code and data are provided or not.
763"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8308026030368764,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
764"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8315256688358641,"to make their results reproducible or verifiable.
765"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8322487346348517,"• Depending on the contribution, reproducibility can be accomplished in various ways.
766"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8329718004338394,"For example, if the contribution is a novel architecture, describing the architecture fully
767"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8336948662328272,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
768"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8344179320318149,"be necessary to either make it possible for others to replicate the model with the same
769"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8351409978308026,"dataset, or provide access to the model. In general. releasing code and data is often
770"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8358640636297903,"one good way to accomplish this, but reproducibility can also be provided via detailed
771"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.836587129428778,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
772"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8373101952277657,"of a large language model), releasing of a model checkpoint, or other means that are
773"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8380332610267535,"appropriate to the research performed.
774"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8387563268257412,"• While NeurIPS does not require releasing code, the conference does require all submis-
775"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8394793926247288,"sions to provide some reasonable avenue for reproducibility, which may depend on the
776"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8402024584237165,"nature of the contribution. For example
777"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8409255242227043,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
778"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.841648590021692,"to reproduce that algorithm.
779"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8423716558206796,"(b) If the contribution is primarily a new model architecture, the paper should describe
780"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8430947216196674,"the architecture clearly and fully.
781"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8438177874186551,"(c) If the contribution is a new model (e.g., a large language model), then there should
782"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8445408532176428,"either be a way to access this model for reproducing the results or a way to reproduce
783"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8452639190166306,"the model (e.g., with an open-source dataset or instructions for how to construct
784"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8459869848156182,"the dataset).
785"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8467100506146059,"(d) We recognize that reproducibility may be tricky in some cases, in which case
786"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8474331164135936,"authors are welcome to describe the particular way they provide for reproducibility.
787"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8481561822125814,"In the case of closed-source models, it may be that access to the model is limited in
788"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.848879248011569,"some way (e.g., to registered users), but it should be possible for other researchers
789"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8496023138105567,"to have some path to reproducing or verifying the results.
790"
OPEN ACCESS TO DATA AND CODE,0.8503253796095445,"5. Open access to data and code
791"
OPEN ACCESS TO DATA AND CODE,0.8510484454085322,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
792"
OPEN ACCESS TO DATA AND CODE,0.8517715112075199,"tions to faithfully reproduce the main experimental results, as described in supplemental
793"
OPEN ACCESS TO DATA AND CODE,0.8524945770065075,"material?
794"
OPEN ACCESS TO DATA AND CODE,0.8532176428054953,"Answer: [NA]
795"
OPEN ACCESS TO DATA AND CODE,0.853940708604483,"Justification: No experimental results.
796"
OPEN ACCESS TO DATA AND CODE,0.8546637744034707,"Guidelines:
797"
OPEN ACCESS TO DATA AND CODE,0.8553868402024585,"• The answer NA means that paper does not include experiments requiring code.
798"
OPEN ACCESS TO DATA AND CODE,0.8561099060014461,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
799"
OPEN ACCESS TO DATA AND CODE,0.8568329718004338,"public/guides/CodeSubmissionPolicy) for more details.
800"
OPEN ACCESS TO DATA AND CODE,0.8575560375994216,"• While we encourage the release of code and data, we understand that this might not be
801"
OPEN ACCESS TO DATA AND CODE,0.8582791033984093,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
802"
OPEN ACCESS TO DATA AND CODE,0.8590021691973969,"including code, unless this is central to the contribution (e.g., for a new open-source
803"
OPEN ACCESS TO DATA AND CODE,0.8597252349963846,"benchmark).
804"
OPEN ACCESS TO DATA AND CODE,0.8604483007953724,"• The instructions should contain the exact command and environment needed to run to
805"
OPEN ACCESS TO DATA AND CODE,0.8611713665943601,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
806"
OPEN ACCESS TO DATA AND CODE,0.8618944323933478,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
807"
OPEN ACCESS TO DATA AND CODE,0.8626174981923355,"• The authors should provide instructions on data access and preparation, including how
808"
OPEN ACCESS TO DATA AND CODE,0.8633405639913232,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
809"
OPEN ACCESS TO DATA AND CODE,0.8640636297903109,"• The authors should provide scripts to reproduce all experimental results for the new
810"
OPEN ACCESS TO DATA AND CODE,0.8647866955892987,"proposed method and baselines. If only a subset of experiments are reproducible, they
811"
OPEN ACCESS TO DATA AND CODE,0.8655097613882863,"should state which ones are omitted from the script and why.
812"
OPEN ACCESS TO DATA AND CODE,0.866232827187274,"• At submission time, to preserve anonymity, the authors should release anonymized
813"
OPEN ACCESS TO DATA AND CODE,0.8669558929862617,"versions (if applicable).
814"
OPEN ACCESS TO DATA AND CODE,0.8676789587852495,"• Providing as much information as possible in supplemental material (appended to the
815"
OPEN ACCESS TO DATA AND CODE,0.8684020245842372,"paper) is recommended, but including URLs to data and code is permitted.
816"
OPEN ACCESS TO DATA AND CODE,0.8691250903832248,"6. Experimental Setting/Details
817"
OPEN ACCESS TO DATA AND CODE,0.8698481561822126,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
818"
OPEN ACCESS TO DATA AND CODE,0.8705712219812003,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
819"
OPEN ACCESS TO DATA AND CODE,0.871294287780188,"results?
820"
OPEN ACCESS TO DATA AND CODE,0.8720173535791758,"Answer: [NA]
821"
OPEN ACCESS TO DATA AND CODE,0.8727404193781634,"Justification: No experiments.
822"
OPEN ACCESS TO DATA AND CODE,0.8734634851771511,"Guidelines:
823"
OPEN ACCESS TO DATA AND CODE,0.8741865509761388,"• The answer NA means that the paper does not include experiments.
824"
OPEN ACCESS TO DATA AND CODE,0.8749096167751266,"• The experimental setting should be presented in the core of the paper to a level of detail
825"
OPEN ACCESS TO DATA AND CODE,0.8756326825741142,"that is necessary to appreciate the results and make sense of them.
826"
OPEN ACCESS TO DATA AND CODE,0.8763557483731019,"• The full details can be provided either with the code, in appendix, or as supplemental
827"
OPEN ACCESS TO DATA AND CODE,0.8770788141720897,"material.
828"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8778018799710774,"7. Experiment Statistical Significance
829"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8785249457700651,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
830"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8792480115690527,"information about the statistical significance of the experiments?
831"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8799710773680405,"Answer: [NA]
832"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8806941431670282,"Justification: No experimental results.
833"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8814172089660159,"Guidelines:
834"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8821402747650036,"• The answer NA means that the paper does not include experiments.
835"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8828633405639913,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
836"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.883586406362979,"dence intervals, or statistical significance tests, at least for the experiments that support
837"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8843094721619668,"the main claims of the paper.
838"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8850325379609545,"• The factors of variability that the error bars are capturing should be clearly stated (for
839"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8857556037599421,"example, train/test split, initialization, random drawing of some parameter, or overall
840"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8864786695589298,"run with given experimental conditions).
841"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8872017353579176,"• The method for calculating the error bars should be explained (closed form formula,
842"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8879248011569053,"call to a library function, bootstrap, etc.)
843"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.888647866955893,"• The assumptions made should be given (e.g., Normally distributed errors).
844"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8893709327548807,"• It should be clear whether the error bar is the standard deviation or the standard error
845"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8900939985538684,"of the mean.
846"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8908170643528561,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
847"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8915401301518439,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
848"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8922631959508315,"of Normality of errors is not verified.
849"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8929862617498192,"• For asymmetric distributions, the authors should be careful not to show in tables or
850"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8937093275488069,"figures symmetric error bars that would yield results that are out of range (e.g. negative
851"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8944323933477947,"error rates).
852"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8951554591467824,"• If error bars are reported in tables or plots, The authors should explain in the text how
853"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.89587852494577,"they were calculated and reference the corresponding figures or tables in the text.
854"
EXPERIMENTS COMPUTE RESOURCES,0.8966015907447578,"8. Experiments Compute Resources
855"
EXPERIMENTS COMPUTE RESOURCES,0.8973246565437455,"Question: For each experiment, does the paper provide sufficient information on the com-
856"
EXPERIMENTS COMPUTE RESOURCES,0.8980477223427332,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
857"
EXPERIMENTS COMPUTE RESOURCES,0.8987707881417208,"the experiments?
858"
EXPERIMENTS COMPUTE RESOURCES,0.8994938539407086,"Answer: [NA]
859"
EXPERIMENTS COMPUTE RESOURCES,0.9002169197396963,"Justification: No experimental results.
860"
EXPERIMENTS COMPUTE RESOURCES,0.900939985538684,"Guidelines:
861"
EXPERIMENTS COMPUTE RESOURCES,0.9016630513376718,"• The answer NA means that the paper does not include experiments.
862"
EXPERIMENTS COMPUTE RESOURCES,0.9023861171366594,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
863"
EXPERIMENTS COMPUTE RESOURCES,0.9031091829356471,"or cloud provider, including relevant memory and storage.
864"
EXPERIMENTS COMPUTE RESOURCES,0.9038322487346349,"• The paper should provide the amount of compute required for each of the individual
865"
EXPERIMENTS COMPUTE RESOURCES,0.9045553145336226,"experimental runs as well as estimate the total compute.
866"
EXPERIMENTS COMPUTE RESOURCES,0.9052783803326103,"• The paper should disclose whether the full research project required more compute
867"
EXPERIMENTS COMPUTE RESOURCES,0.9060014461315979,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
868"
EXPERIMENTS COMPUTE RESOURCES,0.9067245119305857,"didn’t make it into the paper).
869"
CODE OF ETHICS,0.9074475777295734,"9. Code Of Ethics
870"
CODE OF ETHICS,0.9081706435285611,"Question: Does the research conducted in the paper conform, in every respect, with the
871"
CODE OF ETHICS,0.9088937093275488,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
872"
CODE OF ETHICS,0.9096167751265365,"Answer: [Yes]
873"
CODE OF ETHICS,0.9103398409255242,"Justification: Only theoretical results for the convergence of an optimization algorithm, with
874"
CODE OF ETHICS,0.911062906724512,"no foreseeable societal impact.
875"
CODE OF ETHICS,0.9117859725234997,"Guidelines:
876"
CODE OF ETHICS,0.9125090383224873,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
877"
CODE OF ETHICS,0.913232104121475,"• If the authors answer No, they should explain the special circumstances that require a
878"
CODE OF ETHICS,0.9139551699204628,"deviation from the Code of Ethics.
879"
CODE OF ETHICS,0.9146782357194505,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
880"
CODE OF ETHICS,0.9154013015184381,"eration due to laws or regulations in their jurisdiction).
881"
BROADER IMPACTS,0.9161243673174259,"10. Broader Impacts
882"
BROADER IMPACTS,0.9168474331164136,"Question: Does the paper discuss both potential positive societal impacts and negative
883"
BROADER IMPACTS,0.9175704989154013,"societal impacts of the work performed?
884"
BROADER IMPACTS,0.918293564714389,"Answer: [NA]
885"
BROADER IMPACTS,0.9190166305133767,"Justification: This is a theoretical work on an optimization algorithm, it has no foreseeable
886"
BROADER IMPACTS,0.9197396963123644,"societal impact bey
887"
BROADER IMPACTS,0.9204627621113521,"Guidelines:
888"
BROADER IMPACTS,0.9211858279103399,"• The answer NA means that there is no societal impact of the work performed.
889"
BROADER IMPACTS,0.9219088937093276,"• If the authors answer NA or No, they should explain why their work has no societal
890"
BROADER IMPACTS,0.9226319595083152,"impact or why the paper does not address societal impact.
891"
BROADER IMPACTS,0.923355025307303,"• Examples of negative societal impacts include potential malicious or unintended uses
892"
BROADER IMPACTS,0.9240780911062907,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
893"
BROADER IMPACTS,0.9248011569052784,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
894"
BROADER IMPACTS,0.925524222704266,"groups), privacy considerations, and security considerations.
895"
BROADER IMPACTS,0.9262472885032538,"• The conference expects that many papers will be foundational research and not tied
896"
BROADER IMPACTS,0.9269703543022415,"to particular applications, let alone deployments. However, if there is a direct path to
897"
BROADER IMPACTS,0.9276934201012292,"any negative applications, the authors should point it out. For example, it is legitimate
898"
BROADER IMPACTS,0.928416485900217,"to point out that an improvement in the quality of generative models could be used to
899"
BROADER IMPACTS,0.9291395516992046,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
900"
BROADER IMPACTS,0.9298626174981923,"that a generic algorithm for optimizing neural networks could enable people to train
901"
BROADER IMPACTS,0.93058568329718,"models that generate Deepfakes faster.
902"
BROADER IMPACTS,0.9313087490961678,"• The authors should consider possible harms that could arise when the technology is
903"
BROADER IMPACTS,0.9320318148951554,"being used as intended and functioning correctly, harms that could arise when the
904"
BROADER IMPACTS,0.9327548806941431,"technology is being used as intended but gives incorrect results, and harms following
905"
BROADER IMPACTS,0.9334779464931309,"from (intentional or unintentional) misuse of the technology.
906"
BROADER IMPACTS,0.9342010122921186,"• If there are negative societal impacts, the authors could also discuss possible mitigation
907"
BROADER IMPACTS,0.9349240780911063,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
908"
BROADER IMPACTS,0.935647143890094,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
909"
BROADER IMPACTS,0.9363702096890817,"feedback over time, improving the efficiency and accessibility of ML).
910"
SAFEGUARDS,0.9370932754880694,"11. Safeguards
911"
SAFEGUARDS,0.9378163412870572,"Question: Does the paper describe safeguards that have been put in place for responsible
912"
SAFEGUARDS,0.9385394070860448,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
913"
SAFEGUARDS,0.9392624728850325,"image generators, or scraped datasets)?
914"
SAFEGUARDS,0.9399855386840202,"Answer: [NA]
915"
SAFEGUARDS,0.940708604483008,"Justification: No model release.
916"
SAFEGUARDS,0.9414316702819957,"Guidelines:
917"
SAFEGUARDS,0.9421547360809833,"• The answer NA means that the paper poses no such risks.
918"
SAFEGUARDS,0.9428778018799711,"• Released models that have a high risk for misuse or dual-use should be released with
919"
SAFEGUARDS,0.9436008676789588,"necessary safeguards to allow for controlled use of the model, for example by requiring
920"
SAFEGUARDS,0.9443239334779465,"that users adhere to usage guidelines or restrictions to access the model or implementing
921"
SAFEGUARDS,0.9450469992769343,"safety filters.
922"
SAFEGUARDS,0.9457700650759219,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
923"
SAFEGUARDS,0.9464931308749096,"should describe how they avoided releasing unsafe images.
924"
SAFEGUARDS,0.9472161966738973,"• We recognize that providing effective safeguards is challenging, and many papers do
925"
SAFEGUARDS,0.9479392624728851,"not require this, but we encourage authors to take this into account and make a best
926"
SAFEGUARDS,0.9486623282718727,"faith effort.
927"
LICENSES FOR EXISTING ASSETS,0.9493853940708604,"12. Licenses for existing assets
928"
LICENSES FOR EXISTING ASSETS,0.9501084598698482,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
929"
LICENSES FOR EXISTING ASSETS,0.9508315256688359,"the paper, properly credited and are the license and terms of use explicitly mentioned and
930"
LICENSES FOR EXISTING ASSETS,0.9515545914678236,"properly respected?
931"
LICENSES FOR EXISTING ASSETS,0.9522776572668112,"Answer: [NA]
932"
LICENSES FOR EXISTING ASSETS,0.953000723065799,"Justification: Not using existing assets.
933"
LICENSES FOR EXISTING ASSETS,0.9537237888647867,"Guidelines:
934"
LICENSES FOR EXISTING ASSETS,0.9544468546637744,"• The answer NA means that the paper does not use existing assets.
935"
LICENSES FOR EXISTING ASSETS,0.9551699204627621,"• The authors should cite the original paper that produced the code package or dataset.
936"
LICENSES FOR EXISTING ASSETS,0.9558929862617498,"• The authors should state which version of the asset is used and, if possible, include a
937"
LICENSES FOR EXISTING ASSETS,0.9566160520607375,"URL.
938"
LICENSES FOR EXISTING ASSETS,0.9573391178597253,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
939"
LICENSES FOR EXISTING ASSETS,0.958062183658713,"• For scraped data from a particular source (e.g., website), the copyright and terms of
940"
LICENSES FOR EXISTING ASSETS,0.9587852494577006,"service of that source should be provided.
941"
LICENSES FOR EXISTING ASSETS,0.9595083152566883,"• If assets are released, the license, copyright information, and terms of use in the
942"
LICENSES FOR EXISTING ASSETS,0.9602313810556761,"package should be provided. For popular datasets, paperswithcode.com/datasets
943"
LICENSES FOR EXISTING ASSETS,0.9609544468546638,"has curated licenses for some datasets. Their licensing guide can help determine the
944"
LICENSES FOR EXISTING ASSETS,0.9616775126536515,"license of a dataset.
945"
LICENSES FOR EXISTING ASSETS,0.9624005784526392,"• For existing datasets that are re-packaged, both the original license and the license of
946"
LICENSES FOR EXISTING ASSETS,0.9631236442516269,"the derived asset (if it has changed) should be provided.
947"
LICENSES FOR EXISTING ASSETS,0.9638467100506146,"• If this information is not available online, the authors are encouraged to reach out to
948"
LICENSES FOR EXISTING ASSETS,0.9645697758496024,"the asset’s creators.
949"
NEW ASSETS,0.96529284164859,"13. New Assets
950"
NEW ASSETS,0.9660159074475777,"Question: Are new assets introduced in the paper well documented and is the documentation
951"
NEW ASSETS,0.9667389732465654,"provided alongside the assets?
952"
NEW ASSETS,0.9674620390455532,"Answer: [NA]
953"
NEW ASSETS,0.9681851048445409,"Justification: No new assets.
954"
NEW ASSETS,0.9689081706435285,"Guidelines:
955"
NEW ASSETS,0.9696312364425163,"• The answer NA means that the paper does not release new assets.
956"
NEW ASSETS,0.970354302241504,"• Researchers should communicate the details of the dataset/code/model as part of their
957"
NEW ASSETS,0.9710773680404917,"submissions via structured templates. This includes details about training, license,
958"
NEW ASSETS,0.9718004338394793,"limitations, etc.
959"
NEW ASSETS,0.9725234996384671,"• The paper should discuss whether and how consent was obtained from people whose
960"
NEW ASSETS,0.9732465654374548,"asset is used.
961"
NEW ASSETS,0.9739696312364425,"• At submission time, remember to anonymize your assets (if applicable). You can either
962"
NEW ASSETS,0.9746926970354303,"create an anonymized URL or include an anonymized zip file.
963"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9754157628344179,"14. Crowdsourcing and Research with Human Subjects
964"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9761388286334056,"Question: For crowdsourcing experiments and research with human subjects, does the paper
965"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9768618944323934,"include the full text of instructions given to participants and screenshots, if applicable, as
966"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9775849602313811,"well as details about compensation (if any)?
967"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9783080260303688,"Answer: [NA]
968"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9790310918293564,"Justification: No human subjects or crowdsourcing.
969"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9797541576283442,"Guidelines:
970"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9804772234273319,"• The answer NA means that the paper does not involve crowdsourcing nor research with
971"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9812002892263196,"human subjects.
972"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9819233550253073,"• Including this information in the supplemental material is fine, but if the main contribu-
973"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.982646420824295,"tion of the paper involves human subjects, then as much detail as possible should be
974"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9833694866232827,"included in the main paper.
975"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9840925524222705,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
976"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9848156182212582,"or other labor should be paid at least the minimum wage in the country of the data
977"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9855386840202458,"collector.
978"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9862617498192335,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
979"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9869848156182213,"Subjects
980"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.987707881417209,"Question: Does the paper describe potential risks incurred by study participants, whether
981"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9884309472161966,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
982"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9891540130151844,"approvals (or an equivalent approval/review based on the requirements of your country or
983"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9898770788141721,"institution) were obtained?
984"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9906001446131598,"Answer: [NA]
985"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9913232104121475,"Justification:
986"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9920462762111352,"Guidelines:
987"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9927693420101229,"• The answer NA means that the paper does not involve crowdsourcing nor research with
988"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9934924078091106,"human subjects.
989"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9942154736080984,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
990"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9949385394070861,"may be required for any human subjects research. If you obtained IRB approval, you
991"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9956616052060737,"should clearly state this in the paper.
992"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9963846710050615,"• We recognize that the procedures for this may vary significantly between institutions
993"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9971077368040492,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
994"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9978308026030369,"guidelines for their institution.
995"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9985538684020245,"• For initial submissions, do not include any information that would break anonymity (if
996"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9992769342010123,"applicable), such as the institution conducting the review.
997"
