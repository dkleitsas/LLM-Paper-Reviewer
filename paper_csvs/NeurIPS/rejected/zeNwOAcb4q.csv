Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.001321003963011889,"Learning with noisy labels is a common problem in weakly supervised learning,
1"
ABSTRACT,0.002642007926023778,"where the transition matrix approach is a prevalent method for dealing with label
2"
ABSTRACT,0.003963011889035667,"noise. It estimates the transition probabilities from a clean label distribution to a
3"
ABSTRACT,0.005284015852047556,"noisy label distribution and has garnered continuous attention. However, existing
4"
ABSTRACT,0.0066050198150594455,"transition matrix methods predominantly focus on class-dependent noise, making
5"
ABSTRACT,0.007926023778071334,"it challenging to incorporate feature information for learning instance-dependent
6"
ABSTRACT,0.009247027741083224,"label noise. This paper proposes the idea of using diffusion models for estimating
7"
ABSTRACT,0.010568031704095112,"transition matrix in the context of instance-dependent label noise. Specifically, we
8"
ABSTRACT,0.011889035667107,"first estimate grouped transition matrices through clustering. Then, we introduce
9"
ABSTRACT,0.013210039630118891,"a process of adding noise and denoising with the transition matrix, incorporating
10"
ABSTRACT,0.01453104359313078,"features extracted by unsupervised pre-trained models. The proposed method
11"
ABSTRACT,0.015852047556142668,"enables the estimation of instance-dependent transition matrix and extends the
12"
ABSTRACT,0.017173051519154558,"application of transition matrix method to a broader range of noisy label data.
13"
ABSTRACT,0.018494055482166448,"Experimental results demonstrate the significant effectiveness of our approach on
14"
ABSTRACT,0.019815059445178335,"both synthetic and real-world datasets with instance-dependent noise. The code
15"
ABSTRACT,0.021136063408190225,"will be open sourced upon acceptance of the paper.
16"
INTRODUCTION,0.022457067371202115,"1
Introduction
17"
INTRODUCTION,0.023778071334214,"For classification problems with given labels, deep neural networks have demonstrated significant
18"
INTRODUCTION,0.02509907529722589,"improvements compared to traditional methods in recent years [25]. The efficacy of deep neural
19"
INTRODUCTION,0.026420079260237782,"networks heavily relies on the accuracy of the labels. Directly incorporating polluted erroneous labels
20"
INTRODUCTION,0.02774108322324967,"into network learning can result in the network fitting the noise, potentially severely impacting the
21"
INTRODUCTION,0.02906208718626156,"predictive performance of the network [8]. However, in reality, obtaining accurate annotated data can
22"
INTRODUCTION,0.03038309114927345,"be prohibitively expensive, and a substantial amount of data comes from the Internet or is annotated
23"
INTRODUCTION,0.031704095112285335,"by non-expert annotators, inevitably containing noisy labels. Therefore, researching and promoting
24"
INTRODUCTION,0.03302509907529723,"methods to mitigate the damage to models and make them more robust in the face of label noise data
25"
INTRODUCTION,0.034346103038309116,"is a highly worthwhile problem to investigate, known as the problem of learning with noisy labels
26"
INTRODUCTION,0.035667107001321,"[23, 10, 34, 1].
27"
INTRODUCTION,0.036988110964332896,"Different approaches have been proposed to address the problem of label noise. One category
28"
INTRODUCTION,0.03830911492734478,"[31, 22] involves the design of specialized loss functions or network structures to enhance the model’s
29"
INTRODUCTION,0.03963011889035667,"robustness against noisy labels. Another major category focuses on sample selection [2, 10, 14],
30"
INTRODUCTION,0.04095112285336856,"where samples are partitioned into a set of clean samples and a set of contaminated noisy samples
31"
INTRODUCTION,0.04227212681638045,"based on the magnitude of the loss or the similarity of extracted features. The labels of the noisy
32"
INTRODUCTION,0.043593130779392336,"samples are then modified or their weights are reduced, followed by learning using semi-supervised
33"
INTRODUCTION,0.04491413474240423,"methods. Sample selection methods are currently mainstream and have achieved promising results.
34"
INTRODUCTION,0.046235138705416116,"However, the selection process relies heavily on intuition and lacks theoretical support. Additionally,
35"
INTRODUCTION,0.047556142668428,"the sample selection procedure is often complex and computationally intensive. In contrast, another
36"
INTRODUCTION,0.0488771466314399,Figure 1: Diffusion Model for Transition Matrix.
INTRODUCTION,0.05019815059445178,"significant category of methods is the transition matrix method [34, 17, 12, 42], which estimates the
37"
INTRODUCTION,0.05151915455746367,"transition probabilities from the clean label distribution to the noisy label distribution. This class
38"
INTRODUCTION,0.052840158520475564,"of methods reveals the generation process of noisy labels and exhibits statistical consistency, often
39"
INTRODUCTION,0.05416116248348745,"accompanied by theoretical analyses as methodological support. As a result, they have garnered
40"
INTRODUCTION,0.05548216644649934,"continuous attention and occupy an important position in various algorithms for learning with noisy
41"
INTRODUCTION,0.05680317040951123,"labels.
42"
INTRODUCTION,0.05812417437252312,"In transition matrix methods, accurate estimation of the transition matrix is crucial. If an accurate
43"
INTRODUCTION,0.059445178335535004,"estimation of the transition matrix can be obtained, along with the observed data for estimating the
44"
INTRODUCTION,0.0607661822985469,"posterior distribution of the noisy labels, it is possible to infer the distribution of clean labels for
45"
INTRODUCTION,0.062087186261558784,"neural network learning. Previous transition matrix methods [34, 17, 39] have mainly focused on
46"
INTRODUCTION,0.06340819022457067,"class-dependent label noise, where a single transition matrix is estimated for all samples, which is
47"
INTRODUCTION,0.06472919418758256,"typically straightforward. However, for instance-dependent label noise and complex real-world data,
48"
INTRODUCTION,0.06605019815059446,"the label transition probabilities for each sample are not entirely identical. The transition matrix often
49"
INTRODUCTION,0.06737120211360634,"depends on the specific features of individual samples, requiring the estimation of a separate transition
50"
INTRODUCTION,0.06869220607661823,"matrix for each sample. However, in most cases, a single observed label corresponds to each sample
51"
INTRODUCTION,0.07001321003963012,"in the dataset, making it an identifiability problem to estimate a separate transition matrix for each
52"
INTRODUCTION,0.071334214002642,"sample [20]. Although some methods [33, 41, 15] have utilized separate small networks to generate
53"
INTRODUCTION,0.0726552179656539,"the transition matrix or divided the data into groups to transform it into a grouped class-dependent
54"
INTRODUCTION,0.07397622192866579,"scenario, there still exist significant estimation errors and a lack of incorporating features effectively
55"
INTRODUCTION,0.07529722589167767,"into the estimation of the transition matrix.
56"
INTRODUCTION,0.07661822985468957,"To better incorporate the feature information of images into the estimation of the transition matrix,
57"
INTRODUCTION,0.07793923381770146,"this work employs conditional diffusion models. The diffusion model originates from generative
58"
INTRODUCTION,0.07926023778071334,"models and has been widely applied in various computer vision tasks in recent years [36, 7], showing
59"
INTRODUCTION,0.08058124174372523,"remarkable results. The proposed method revolves around the core idea of replacing image samples in
60"
INTRODUCTION,0.08190224570673713,"the original diffusion process with a transition matrix. The matrix undergoes a process of adding noise
61"
INTRODUCTION,0.083223249669749,"and denoising, where the denoising step incorporates the sample features extracted by a pre-trained
62"
INTRODUCTION,0.0845442536327609,"model as conditions. This generates a feature-dependent transition matrix. The constructed diffusion
63"
INTRODUCTION,0.08586525759577279,"module is illustrated in Figure 1. Additionally, considering the assumption that instance-dependent
64"
INTRODUCTION,0.08718626155878467,"label noise is usually correlated with features [6], clustering methods are utilized at the feature level
65"
INTRODUCTION,0.08850726552179657,"to group samples. Preliminary estimations of the transition matrices are obtained for each group,
66"
INTRODUCTION,0.08982826948480846,"which are then incorporated into the diffusion module for learning. The overall framework of the
67"
INTRODUCTION,0.09114927344782034,"method is depicted in Figure 2.
68"
INTRODUCTION,0.09247027741083223,"The subsequent sections are organized as follows. Section 2 presents an in-depth review of the
69"
INTRODUCTION,0.09379128137384413,"relevant works. In Section 3, we introduce our proposed model framework. Section 4 outlines
70"
INTRODUCTION,0.095112285336856,"the experimental analysis conducted on diverse synthetic and real-world noisy datasets, along with
71"
INTRODUCTION,0.0964332892998679,"comparisons against other existing methods. Finally, we provide concluding in Section 5. The
72"
INTRODUCTION,0.0977542932628798,"primary contributions of this paper can be summarized as follows:
73"
INTRODUCTION,0.09907529722589167,"• We propose a method that utilizes diffusion models to add noise and denoise on the transition
74"
INTRODUCTION,0.10039630118890357,"matrix, incorporating image features extracted through pre-trained encoder.
75"
INTRODUCTION,0.10171730515191546,"• By combining the transition matrix-based diffusion model with feature-based clustering, we
76"
INTRODUCTION,0.10303830911492734,"establish a framework capable of addressing instance-dependent label noise problems.
77"
INTRODUCTION,0.10435931307793923,Figure 2: The overall framework of DTM.
INTRODUCTION,0.10568031704095113,"• Our method demonstrates significant improvements over other transition matrix methods on
78"
INTRODUCTION,0.10700132100396301,"both synthetic and real-world noisy datasets, and it achieves comparable performance to
79"
INTRODUCTION,0.1083223249669749,"state-of-the-art methods.
80"
RELATED WORKS,0.1096433289299868,"2
Related Works
81"
TRANSITION MATRIX METHODS,0.11096433289299867,"2.1
Transition Matrix Methods
82"
TRANSITION MATRIX METHODS,0.11228533685601057,"Most previous methods for estimating transition matrix in the presence of label noise have primarily
83"
TRANSITION MATRIX METHODS,0.11360634081902246,"focused on class-dependent noise scenarios, simplifying the estimation process. Methods such as
84"
TRANSITION MATRIX METHODS,0.11492734478203434,"[24, 34] assume the existence of anchor points to identify the transition matrix.
[17] and [39]
85"
TRANSITION MATRIX METHODS,0.11624834874504623,"introduce different regularization techniques to relax the anchor point assumption. Additionally,
86"
TRANSITION MATRIX METHODS,0.11756935270805813,"[26, 38] apply techniques such as meta-learning to estimate the transition matrix, but these approaches
87"
TRANSITION MATRIX METHODS,0.11889035667107001,"may require more clean data and computational resources. While these methods are effective for
88"
TRANSITION MATRIX METHODS,0.1202113606340819,"handling class-dependent label noise, they are not suitable for instance-dependent noise or real-world
89"
TRANSITION MATRIX METHODS,0.1215323645970938,"noisy data.
90"
TRANSITION MATRIX METHODS,0.12285336856010567,"However, estimating an individual transition matrix for each sample without additional assumptions
91"
TRANSITION MATRIX METHODS,0.12417437252311757,"or multiple noisy labels is infeasible [20]. To approximate the estimation of the instance-dependent
92"
TRANSITION MATRIX METHODS,0.12549537648612946,"transition matrix, [9] utilize an adaptation layer that estimates the transition matrix based on the
93"
TRANSITION MATRIX METHODS,0.12681638044914134,"output of each sample. [37] employs a separate network to estimate the transition matrix based on
94"
TRANSITION MATRIX METHODS,0.12813738441215325,"Bayesian labels. Some methods, such as [33, 30, 41], employ clustering to learn part-dependent
95"
TRANSITION MATRIX METHODS,0.12945838837516513,"or group-dependent matrices, which can be viewed as a compromise between instance-dependent
96"
TRANSITION MATRIX METHODS,0.130779392338177,"and class-dependent methods. Other approaches, including [6, 12], utilize the similarity in the
97"
TRANSITION MATRIX METHODS,0.13210039630118892,"feature space to aid in learning the transition matrix. Although these instance-dependent transition
98"
TRANSITION MATRIX METHODS,0.1334214002642008,"matrix methods achieve identifiability through specialized treatments, they have not effectively
99"
TRANSITION MATRIX METHODS,0.13474240422721268,"utilized feature information in the learning process, resulting in errors in estimating feature-dependent
100"
TRANSITION MATRIX METHODS,0.13606340819022458,"transition matrices.
101"
DIFFUSION MODELS,0.13738441215323646,"2.2
Diffusion Models
102"
DIFFUSION MODELS,0.13870541611624834,"Diffusion models, as generative models, have played a significant role in computer vision [36, 7].
103"
DIFFUSION MODELS,0.14002642007926025,"Prominent examples include DDPM [11], DDIM [27], score matching methods [28], and methods
104"
DIFFUSION MODELS,0.14134742404227213,"based on stochastic differential equations [29]. Diffusion models and their variants have been applied
105"
DIFFUSION MODELS,0.142668428005284,"to various computer vision tasks such as image generation, image-to-image translation, text-to-image
106"
DIFFUSION MODELS,0.14398943196829592,"generation, among others. However, their application to the problem of label noise is relatively novel.
107"
DIFFUSION MODELS,0.1453104359313078,"To the best of our knowledge, only one existing work [3] has utilized diffusion models for addressing
108"
DIFFUSION MODELS,0.14663143989431968,"this problem. However, this work treats labels as the output of the diffusion model, which limits
109"
DIFFUSION MODELS,0.14795244385733158,"their expressive power due to the low dimension of the labels. Moreover, it overly relies on directly
110"
DIFFUSION MODELS,0.14927344782034346,"incorporating image features as conditions in the label generation process, which depends heavily on
111"
DIFFUSION MODELS,0.15059445178335534,"pre-trained models and may not be as reasonable as incorporating them into the transition matrix that
112"
DIFFUSION MODELS,0.15191545574636725,"reveals the process of noise generation. Experimental results also support this perspective.
113"
METHOD,0.15323645970937913,"3
Method
114"
METHOD,0.154557463672391,"In this section, we present the definitions of symbols and introduce our method of using Diffusion
115"
METHOD,0.15587846763540292,"models to construct the Transition Matrix (DTM).
116"
PRELIMINARIES,0.1571994715984148,"3.1
Preliminaries
117"
PRELIMINARIES,0.15852047556142668,"Let X ⊂Rd be the input image space, Y = {1, 2, · · · , C} be the label space, where C is the number
118"
PRELIMINARIES,0.15984147952443858,"of classes. Random variables (X, Y ), (X, ˜Y ) ∈X × Y denote the underlying data distributions
119"
PRELIMINARIES,0.16116248348745046,"with true and noisy labels respectively. In general, we can not observe the latent true data samples
120"
PRELIMINARIES,0.16248348745046234,"D = {(xi, yi)}N
i=1, but can only obtain the corrupted data ˜D = {(xi, ˜yi)}N
i=1, where ˜y ∈Y is the
121"
PRELIMINARIES,0.16380449141347425,"noisy label corrupted from the true label y, while denote corresponding one-hot label as y and ˜y.
122"
PRELIMINARIES,0.16512549537648613,"Transition matrix methods use a matrix T (x) ∈[0, 1]C×C to represent the probability from clean
123"
PRELIMINARIES,0.166446499339498,"label to noisy label, where the ij-th entry of the transition matrix is the probability that the instance
124"
PRELIMINARIES,0.16776750330250992,"x with the clean label i corrupted to a noisy label j. The matrix satisfies the requirement that the
125"
PRELIMINARIES,0.1690885072655218,"sum of each row PC
j=1 T ij(x) is 1, and usually has the requirement for T ii(x) > T ij(x), ∀j ̸= i.
126"
PRELIMINARIES,0.17040951122853368,"Let P(Y |X = x) = [P(Y = 1|X = x), · · · , P(Y = C|X = x)]⊤be the clean class-posterior
127"
PRELIMINARIES,0.17173051519154559,"probability and P( ˜Y |X = x) = [P( ˜Y = 1|X = x), · · · , P( ˜Y = C|X = x)]⊤be the noisy
128"
PRELIMINARIES,0.17305151915455746,"class-posterior probability, the formula can be write as:
129"
PRELIMINARIES,0.17437252311756934,"P( ˜Y |X = x) = T (x)⊤P(Y |X = x).
(1)"
PRELIMINARIES,0.17569352708058125,"By estimating the transition matrix and the noisy class-posterior probability, the clean class-posterior
130"
PRELIMINARIES,0.17701453104359313,"probability can be inferred by
131"
PRELIMINARIES,0.178335535006605,"P(Y |X = x) = T (x)−⊤P( ˜Y |X = x),
(2)"
PRELIMINARIES,0.17965653896961692,"where the symbol −⊤denotes the transpose of the inverse matrix.
132"
PRELIMINARIES,0.1809775429326288,"The majority of existing methods [24, 10, 17] focus on studying the class-dependent and instance-
133"
PRELIMINARIES,0.18229854689564068,"independent transition matrix, i.e., T (x) ≡T for ∀x. However, these methods are not applicable to
134"
PRELIMINARIES,0.18361955085865259,"instance-dependent noise scenarios where the transition matrix T (x) varies with respect to the input
135"
PRELIMINARIES,0.18494055482166447,"X. The main focus of our work is to utilize the feature information from input images to construct a
136"
PRELIMINARIES,0.18626155878467635,"instance-dependent transition matrix T (x).
137"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.18758256274768825,"3.2
Diffusion Model for Transition Matrix
138"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.18890356671070013,"We adopt the classic DDPM model [11] from diffusion models as a reference to perform noise
139"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.190224570673712,"addition and denoising on the transition matrix. The diagram is illustrated in Figure 1.
140"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.19154557463672392,"For the forward diffusion process beginning with transition matrix T 0 ∼q(T ), the process of
141"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.1928665785997358,"gradually adding noise is obtained according to the following Markov process:
142"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.19418758256274768,"q (T m | T m−1) = N

T m;
p"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.1955085865257596,"1 −βmT m−1, βmI

,
(3)"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.19682959048877147,"for m = 1, 2, · · · , M, where we use M to replace T, which is usually used in other diffusion models,
143"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.19815059445178335,"in above equation for distinguishing from the symbol of transition matrix T .
144"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.19947159841479525,"We aim to make the distribution of q(T M) approach a standard normal distribution N (0, I) and
145"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.20079260237780713,"through T M to conduct the reverse denoising process by fitting a neural network µθ to fit the
146"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.202113606340819,"disttibution:
147"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.20343461030383092,"pθ (T m−1 | T m) = N

T m−1; µθ (T m, x, fp, m) , ˜βmI

,
(4)"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.2047556142668428,where define ˜βm = 1−¯αm−1
DIFFUSION MODEL FOR TRANSITION MATRIX,0.20607661822985468,"1−¯αm βm, αm = 1 −βm, ¯αm = Qm
i=1 αi. The fp in equation (4) denotes the
148"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.2073976221928666,"pre-trained encoder for feature extraction.
149"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.20871862615587847,"The diffusion model can be learned by optimizing the evidence lower bound:
150"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.21003963011889035,"LELBO = Eq "" LM + M
X"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.21136063408190225,"m>1
Lm−1 + L0 # ,
(5)"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.21268163804491413,"where
151"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.21400264200792601,"L0 = −log pθ (T 0 | T 1) ,
Lm−1 = DKL (q (T m−1 | T m, T 0) ∥pθ (T m−1 | T m)) ,
LM = DKL (q (T M | T 0) ∥pθ (T M)) .
(6)"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.21532364597093792,"Similar to the derivation and simplification process of DDPM, when a pre-trained encoder fp is
152"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.2166446499339498,"provided along with the training data incorporating the initial transition matrix T , the learning
153"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.21796565389696168,"algorithm for the diffusion model is presented in Algorithm 1.
154"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.2192866578599736,Algorithm 1 Diffusion Model for Transition Matrix
DIFFUSION MODEL FOR TRANSITION MATRIX,0.22060766182298547,"Input: Training data {xi, T i}N
i=1, pre-trained encoder fp.
while not converged do"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.22192866578599735,"Sample (x0, T 0) from data
Sample m ∼{1, · · · , M}
Sample noise ϵ ∼N(0, I)
Take gradient descent step on the loss:"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.22324966974900926,"∇θ
ϵ −ϵθ
 √¯αmT 0 +
√"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.22457067371202113,"1 −¯αmϵ, x0, fp, m
2"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.22589167767503301,end while
DIFFUSION MODEL FOR TRANSITION MATRIX,0.22721268163804492,"Next, for each image x, we can sample the corresponding transition matrix T (x) as shown in
155"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.2285336856010568,"Algorithm 2.
156"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.22985468956406868,Algorithm 2 Sample for Transition Matrix
DIFFUSION MODEL FOR TRANSITION MATRIX,0.2311756935270806,"Sample T M ∼N(0, I)
for m = M, · · · , 1 do"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.23249669749009247,"z ∼N(0, I) if t > 1, else z = 0"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.23381770145310435,"T m−1 =
1
√αm"
DIFFUSION MODEL FOR TRANSITION MATRIX,0.23513870541611626,"
T m −
1−αm
√1−¯αm ϵθ (T m, x, fp, m)

+ σmz
end for
Output: T 0"
FEATURE-DEPENDENT FRAMEWORK,0.23645970937912814,"3.3
Feature-Dependent Framework
157"
FEATURE-DEPENDENT FRAMEWORK,0.23778071334214002,"From Algorithm 1, it can be observed that there are two components of the diffusion process that
158"
FEATURE-DEPENDENT FRAMEWORK,0.23910171730515192,"need to be provided in advance: the pre-trained encoder fp and the initial input T (x).
159"
FEATURE-DEPENDENT FRAMEWORK,0.2404227212681638,"The pre-trained encoder fp can be obtained through self-supervised learning or directly using the
160"
FEATURE-DEPENDENT FRAMEWORK,0.24174372523117568,"large model like CLIP. In our experiments, we employ the commonly used SimCLR [4] method in
161"
FEATURE-DEPENDENT FRAMEWORK,0.2430647291941876,"contrastive learning as the feature extraction model.
162"
FEATURE-DEPENDENT FRAMEWORK,0.24438573315719947,"On the other hand, the part involving the transition matrix T (x) used for learning the diffusion
163"
FEATURE-DEPENDENT FRAMEWORK,0.24570673712021135,"model is also related to the pre-trained encoder fp. Based on the assumption that the noise transition
164"
FEATURE-DEPENDENT FRAMEWORK,0.24702774108322326,"probability depends on image features, we adopt a group-dependent transition matrix as the initial
165"
FEATURE-DEPENDENT FRAMEWORK,0.24834874504623514,"input. We perform clustering algorithms at the feature extraction level fp(x), using the K-means
166"
FEATURE-DEPENDENT FRAMEWORK,0.24966974900924702,"method in our experiments, to group the image data. Then, based on the method VolMinNet [17], we
167"
FEATURE-DEPENDENT FRAMEWORK,0.2509907529722589,"train class-dependent transition matrices for each group and obtain the initial transition matrix T (x)
168"
FEATURE-DEPENDENT FRAMEWORK,0.2523117569352708,"for each image x, which is then used as input in Algorithm 1. It is worth to note that the initial T (x)
169"
FEATURE-DEPENDENT FRAMEWORK,0.2536327608982827,"used as input for the diffusion process does not require different for each x. However, the denoising
170"
FEATURE-DEPENDENT FRAMEWORK,0.25495376486129456,"process of the diffusion model will further incorporate the feature information into the learning of the
171"
FEATURE-DEPENDENT FRAMEWORK,0.2562747688243065,"transition matrix.
172"
FEATURE-DEPENDENT FRAMEWORK,0.2575957727873184,"After obtaining the instance-dependent estimated transition matrix T (x), the neural network can be
173"
FEATURE-DEPENDENT FRAMEWORK,0.25891677675033026,"learned to fit the clean label distribution by the loss function:
174 L = 1 N N
X"
FEATURE-DEPENDENT FRAMEWORK,0.26023778071334214,"i=1
ℓ
 
T (xi)⊤fϕ(xi), ˜yi

,
(7)"
FEATURE-DEPENDENT FRAMEWORK,0.261558784676354,"where fϕ(·) : X →∆C−1 (∆C−1 ⊂[0, 1]C is the C-dimensional simplex) is a differentiable
175"
FEATURE-DEPENDENT FRAMEWORK,0.2628797886393659,"function represented by a neural network with parameters ϕ and ℓis a loss function usually using
176"
FEATURE-DEPENDENT FRAMEWORK,0.26420079260237783,"cross-entropy (CE) loss.
177"
FEATURE-DEPENDENT FRAMEWORK,0.2655217965653897,"The schematic diagram of the proposed framework is shown in Figure 2, and the pseudocode is
178"
FEATURE-DEPENDENT FRAMEWORK,0.2668428005284016,"presented in Algorithm 3.
179"
FEATURE-DEPENDENT FRAMEWORK,0.26816380449141347,Algorithm 3 A framework of DTM
FEATURE-DEPENDENT FRAMEWORK,0.26948480845442535,"Input: Training set {(xi, yi)}N
i=1, pre-trained encoder fp, diffusion model ϵθ, classification neural
network fϕ."
FEATURE-DEPENDENT FRAMEWORK,0.27080581241743723,"1: Utilize input data to train fp or directly utilizing fp to extract features.
2: Perform K-means on feature space and estimate the transition matrix for each group to get data
{xi, T i}N
i=1.
3: Train the diffusion model ϵθ with Algorithm 1.
4: Sample instance-dependent train matrix T (x) for any input image xi with Algorithm 2.
5: Update the parameters of the classification network by incorporating the transition matrix T (xi)
into equation (7).
Output: Network parameters ϕ."
MATRIX TRANSFORMATION,0.27212681638044917,"3.4
Matrix Transformation
180"
MATRIX TRANSFORMATION,0.27344782034346105,"Considering that the transition matrix typically require the sum of each row PC
j=1 T ij(x) is 1, and
181"
MATRIX TRANSFORMATION,0.2747688243064729,"for T ii(x) > T ij(x), ∀j ̸= i, we employ a transformation during the update learning process in our
182"
MATRIX TRANSFORMATION,0.2760898282694848,"practical experiments.
183"
MATRIX TRANSFORMATION,0.2774108322324967,"We utilize a C × C weight matrix W = (wij) to assist in the process. Denote matrix A as
184"
MATRIX TRANSFORMATION,0.27873183619550856,"Aii = 1 + σ (wii) for all i ∈{1, 2, . . . , C} and Aij = σ (wij) for all i ̸= j where σ is the sigmoid
185"
MATRIX TRANSFORMATION,0.2800528401585205,"function. Then we do the normalization T ij =
Aij
PC
k=1 Akj to get the transition matrix T .
186"
MATRIX TRANSFORMATION,0.2813738441215324,"Through this transformation, we ensure that the learned transition matrix has row sums equal to 1 and
187"
MATRIX TRANSFORMATION,0.28269484808454426,"that the diagonal elements are the largest in each row. In practical experiments, we apply the diffusion
188"
MATRIX TRANSFORMATION,0.28401585204755614,"modeling discussed in subsection 3.2 to the matrix W , and then transform it into the transition matrix
189"
MATRIX TRANSFORMATION,0.285336856010568,"T for application. To simplify the notation, we uniformly use the term of transition matrix W to
190"
MATRIX TRANSFORMATION,0.2866578599735799,"represent it, unless it leads to singularity.
191"
EXPERIMENTS,0.28797886393659183,"4
Experiments
192"
EXPERIMENTS,0.2892998678996037,"In this section, we present experimental findings to showcase the effectiveness of our proposed
193"
EXPERIMENTS,0.2906208718626156,"method compared to other methods. We evaluate our approach on both synthetic instance-dependent
194"
EXPERIMENTS,0.2919418758256275,"noisy datasets and real-world noisy datasets.
195"
DATASETS,0.29326287978863935,"4.1
Datasets
196"
DATASETS,0.29458388375165123,"We conduct experiments on following image classification datasets: CIFAR-10 and CIFAR-100 [13],
197"
DATASETS,0.29590488771466317,"CIFAR-10N and CIFAR-100N [32], Clothing1M [35], Webvision and ILSVRC12 [16]. Among
198"
DATASETS,0.29722589167767505,"them, CIFAR-10 and CIFAR-100 both have 32 × 32 × 3 color images including 50,000 training
199"
DATASETS,0.2985468956406869,"images and 10,000 test images. CIFAR-10 has 10 classes while CIFAR-100 has 100 classes. We
200"
DATASETS,0.2998678996036988,"generate instance-dependent noisy data on CIFAR-10 and CIFAR-100 with noise rates ranging from
201"
DATASETS,0.3011889035667107,"10% to 50%, following the same generation method as in [33]. CIFAR-10N has three annotated
202"
DATASETS,0.30250990752972257,"labels, namely Random1, Random 2 and Random 3. The ""Aggregate"" is the aggregation of three noisy
203"
DATASETS,0.3038309114927345,"labels by majority voting, and the ""Worst"" is the dataset with the worst case. For CIFAR-100N, each
204"
DATASETS,0.3051519154557464,"image contains a coarse label and a fine label given by a human annotator. Clothing1M is a real-world
205"
DATASETS,0.30647291941875826,"dataset consisting of 1 million training images, consisting of 14 categories. WebVision contains 2.4
206"
DATASETS,0.30779392338177014,"million images crawled from the websites using the 1,000 concepts in ImageNet ILSVRC12, but only
207"
DATASETS,0.309114927344782,"the first 50 classes of the Google image subset are used in our experiments. For the validation set
208"
DATASETS,0.3104359313077939,"selection in our BTR method, we randomly sampled 10 samples from each observed class for each
209"
DATASETS,0.31175693527080584,"dataset to form the validation set, while the remaining samples were used for the training set.
210"
EXPERIMENTAL SETUP,0.3130779392338177,"4.2
Experimental Setup
211"
EXPERIMENTAL SETUP,0.3143989431968296,"For the pre-trained model, we employ the commonly used SimCLR model [4] from contrastive
212"
EXPERIMENTAL SETUP,0.3157199471598415,"learning, which directly performs self-supervised learning on input images without utilizing additional
213"
EXPERIMENTAL SETUP,0.31704095112285335,"datasets. For the diffusion model, we follow the setup similar to DDPM [11] to set β1 = 10−4, βM =
214"
EXPERIMENTAL SETUP,0.31836195508586523,"0.02 and utilize a similar U-Net network architecture but we reduce the M from 1000 to 10 to
215"
EXPERIMENTAL SETUP,0.31968295904887717,"accelerate the learning process. As for the classification network, it may vary depending on the
216"
EXPERIMENTAL SETUP,0.32100396301188905,"specific dataset. More specifically, for CIFAR-10/10N, we use ResNet-18 as the backbone network
217"
EXPERIMENTAL SETUP,0.32232496697490093,"with batch size 128 and learning rate 0.05. For CIFAR-100/100N, we use ResNet-34 network
218"
EXPERIMENTAL SETUP,0.3236459709379128,"with batch size 128, learning rate 0.02. For clothing1M, we use a ResNet-50 pre-trained with 10
219"
EXPERIMENTAL SETUP,0.3249669749009247,"epochs, batch size 64, learning rate 0.002 for network and divided by 10 after the 5th epoch. We use
220"
EXPERIMENTAL SETUP,0.32628797886393657,"InceptionResNetV2 network on Webvision, with 100 epochs, batch size 32, learning rate 0.02 for
221"
EXPERIMENTAL SETUP,0.3276089828269485,"network and divided by 10 after the 30th and 60th epoch. For clustering, we utilize the K-means
222"
EXPERIMENTAL SETUP,0.3289299867899604,"method, where the number of clusters is set to 10 times the number of classes in the datasets. For
223"
EXPERIMENTAL SETUP,0.33025099075297226,"the initialization of transition matrix, the update method and setting are consistent with [17]. While
224"
EXPERIMENTAL SETUP,0.33157199471598414,"the updates for other parameters are performed using the stochastic gradient descent optimization
225"
EXPERIMENTAL SETUP,0.332892998678996,"method.
226"
EXPERIMENTAL SETUP,0.3342140026420079,Table 1: Test accuracy with instance-dependent noise on CIFAR-10/100.
EXPERIMENTAL SETUP,0.33553500660501984,"CIFAR-10
IDN-10%
IDN-20%
IDN-30%
IDN-40%
IDN-50%
CE
88.86±0.23
86.93±0.17
82.42±0.44
76.68±0.23
58.93±1.54
VolMinNet
89.97±0.57
87.01±0.64
83.80±0.67
79.52±0.83
61.90±1.06
PeerLoss
90.89±0.07
89.21±0.63
85.70±0.56
78.51±1.23
59.08±1.05
BLTM
90.45±0.72
88.14±0.66
84.55±0.48
79.71±0.95
63.33±2.75
PartT
90.32±0.15
89.33±0.70
85.33±1.86
80.59±0.41
64.58±2.86
MEIDTM
92.91±0.07
92.26±0.25
90.73±0.34
85.94±0.92
73.77±0.82
SOP
93.58±0.31
93.07±0.45
92.42±0.43
89.83±0.77
82.52±0.97
CC
95.24±0.20
93.68±0.12
93.31±0.46
94.97±0.09
91.19±0.34
LRA
95.87±0.42
94.70±0.28
93.79±0.40
92.72±0.29
90.95±0.43
DTM
96.45±0.17
95.90±0.21
95.14±0.20
94.82±0.31
92.04±0.42
CIFAR-100
IDN-10%
IDN-20%
IDN-30%
IDN-40%
IDN-50%
CE
66.55±0.23
63.94±0.51
61.97±1.16
58.70±0.56
56.63±0.69
VolMinNet
67.78±0.62
66.13±0.47
61.08±0.90
57.35±0.83
52.60±1.31
PeerLoss
65.64±1.07
63.83±0.48
61.64±0.67
58.30±0.80
55.41±0.28
BLTM
68.42±0.42
66.62±0.85
64.72±0.64
59.38±0.65
55.68±1.43
PartT
67.33±0.33
65.33±0.59
64.56±1.55
59.73±0.76
56.80±1.32
MEIDTM
69.88±0.45
69.16±0.16
66.76±0.30
63.46±0.48
59.18±0.16
SOP
74.09±0.52
73.13±0.46
72.14±0.46
68.98±0.58
64.24±0.86
CC
80.52±0.22
79.61±0.19
77.34±0.31
76.58±0.25
72.68±0.36
LRA
81.20±0.16
80.53±0.29
78.22±0.19
76.55±0.31
72.97±0.51
DTM
82.96±0.25
82.04±0.32
80.87±0.45
78.56±0.60
74.85±0.56"
COMPARISON METHODS,0.3368560105680317,"4.3
Comparison Methods
227"
COMPARISON METHODS,0.3381770145310436,"In our experiments, we included the following common transition matrix and baseline methods as
228"
COMPARISON METHODS,0.3394980184940555,"comparison: (1) VolMinNet [17], (2) PeerLoss [21] (3) BLTM [37], (4) PartT [33], (5) MEIDTM
229"
COMPARISON METHODS,0.34081902245706736,"[6], as well as state-of-the-art methods for learning with noisy labels: (6) Co-teaching [10], (7) ELR+
230"
COMPARISON METHODS,0.34214002642007924,"[18], (8) DivideMix [14], (9) SOP and SOP+ [19], (10) PGDF [5], (11) CC [40], (12) LRA [3]
231"
COMPARISON METHODS,0.34346103038309117,"with SimCLR as encoder similarly.
232"
COMPARISON METHODS,0.34478203434610305,Table 2: Test accuracy on CIFAR-10N and CIFAR-100N.
COMPARISON METHODS,0.34610303830911493,"CIFAR-10N
CIFAR-100N
Aggregate
Random 1
Random 2
Random 3
Worst
Noisy
Co-teaching 91.20±0.13 90.33±0.13 90.30±0.17 90.15±0.18 83.83±0.13
60.37±0.27
ELR+
94.83±0.10 94.43±0.41 94.20±0.24 94.34±0.22 91.09±1.60
66.72±0.07
DivideMix
95.01±0.71 95.16±0.19 94.89±0.23 95.03±0.20 92.56±0.42
71.13±0.48
SOP+
95.61±0.13 95.28±0.13 95.31±0.10 95.39±0.11 93.24±0.21
67.81±0.23
PGDF
95.35±0.12 94.95±0.21 94.78±0.34 94.92±0.28 94.22±0.29
67.76±0.35
CC
95.63±0.21 95.11±0.31 94.93±0.37 95.09±0.21 94.24±0.40
71.21±0.22
LRA
94.57±0.23 94.19±0.17 94.38±0.42 94.02±0.32 93.20±0.59
70.96±0.53
DTM
96.13±0.17 95.98±0.22 96.01±0.28 95.78±0.34 94.93±0.21
72.51±0.30"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.3474240422721268,"4.4
Experimental Results on Synthetic Datasets
233"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.3487450462351387,"We primarily validated our proposed method DTM against previous instance-based transition matrix
234"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.35006605019815057,"methods on synthetic CIFAR-10/100 noise datasets. These methods mainly focus on estimating the
235"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.3513870541611625,"transition matrix and some methods applicable to instance-dependent label noise. We performed 5
236"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.3527080581241744,"independent runs for each experimental configuration, and the average values and standard deviations
237"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.35402906208718626,"of each experiment are presented in Table 1.
238"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.35535006605019814,"The results demonstrate that our proposed DTR method outperforms other methods of the same
239"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.35667107001321,"category across various noise rates. It is evident that traditional transition matrix methods for class-
240"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.3579920739762219,"dependent noise as VolMinNet exhibit subpar performance when handling instance-dependent noise.
241"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.35931307793923384,"While even advanced transition matrix methods for instance-dependent label noise such as BLTM,
242"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.3606340819022457,"ParT and MEIDTM, still show significant gaps compared to our method.
243"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.3619550858652576,"Furthermore, as the noise rates increase, the test accuracy of existing transition matrix methods
244"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.3632760898282695,"significantly decline. This is particularly pronounced in the case of CIFAR-100 with 50% instance-
245"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.36459709379128136,"dependent noise (IDN) data, where all transition matrix methods achieve test accuracy below 60%.
246"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.36591809775429324,"In contrast, our proposed DTR method achieves a remarkable test accuracy of 74.85%, showcasing
247"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.36723910171730517,"its exceptional performance. That demonstrates relatively robust performance of DTM with only a
248"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.36856010568031705,"slight decrease as the noise rate increases.
249"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.36988110964332893,"This experiment clearly demonstrates that there is a significant performance gap between previous
250"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.3712021136063408,"transition matrix methods and other advanced techniques, such as CC and LRA, when dealing with
251"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.3725231175693527,"instance-dependent noise problems. However, the experimental results indicate that our proposed
252"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.37384412153236457,"method DTM, which incorporates the diffusion model into the estimation of the transition matrix,
253"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.3751651254953765,"outperforms these advanced techniques, except for the case of 40% noise in CIFAR-100, where
254"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.3764861294583884,"our method slightly underperforms CC. It is evident that by leveraging the diffusion modeling to
255"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.37780713342140027,"estimate the transition matrix, we effectively incorporate the image’s feature information, leading to a
256"
EXPERIMENTAL RESULTS ON SYNTHETIC DATASETS,0.37912813738441214,"substantial improvement in the effectiveness of the transition matrix.
257"
EXPERIMENTAL RESULTS ON REAL-WORLD DATASETS,0.380449141347424,"4.5
Experimental Results on Real-World Datasets
258"
EXPERIMENTAL RESULTS ON REAL-WORLD DATASETS,0.3817701453104359,"In addition to synthetic datasets, we also applied our method to real-world datasets and compared it
259"
EXPERIMENTAL RESULTS ON REAL-WORLD DATASETS,0.38309114927344784,"with other state-of-the-art techniques for handling label noise problems. The results are presented in
260"
EXPERIMENTAL RESULTS ON REAL-WORLD DATASETS,0.3844121532364597,"Table 2 and Table 3.
261"
EXPERIMENTAL RESULTS ON REAL-WORLD DATASETS,0.3857331571994716,"Table 3: Test accuracy on Clothing1M, Webvision and ILSVRC12."
EXPERIMENTAL RESULTS ON REAL-WORLD DATASETS,0.3870541611624835,"Clothing1M
Webvision
ILSVRC12
Co-teaching
69.2
63.6
61.5
ELR+
74.81
77.78
70.29
DivideMix
74.76
77.32
75.20
SOP+
74.98
77.60
75.29
PGDF
75.19
81.47
75.45
CC
75.40
79.36
76.08
LRA
75.32
80.05
76.64
DTM
75.57
81.95
77.55"
EXPERIMENTAL RESULTS ON REAL-WORLD DATASETS,0.38837516512549536,"The results demonstrate that regardless of the type of noise labels, whether it is aggregated, random,
262"
EXPERIMENTAL RESULTS ON REAL-WORLD DATASETS,0.38969616908850724,"or the worst-case scenario in CIFAR-10N, as well as in CIFAR-100N with more label categories,
263"
EXPERIMENTAL RESULTS ON REAL-WORLD DATASETS,0.3910171730515192,"our method consistently achieves the best results in handling real-world noise. When dealing with
264"
EXPERIMENTAL RESULTS ON REAL-WORLD DATASETS,0.39233817701453105,"large datasets like Clothing1M and complex image datasets like Webvision, DTM also performs
265"
EXPERIMENTAL RESULTS ON REAL-WORLD DATASETS,0.39365918097754293,"comparably to other state-of-the-art methods.
266"
EXPERIMENTAL RESULTS ON REAL-WORLD DATASETS,0.3949801849405548,"Through extensive experiments on five real-world datasets and the rusults on synthetic datasets above,
267"
EXPERIMENTAL RESULTS ON REAL-WORLD DATASETS,0.3963011889035667,"our method outperforms the LRA method, which also utilizes the diffusion model for label noise
268"
EXPERIMENTAL RESULTS ON REAL-WORLD DATASETS,0.39762219286657857,"problems. The LRA method models label diffusion with fewer dimensional information and lacks the
269"
EXPERIMENTAL RESULTS ON REAL-WORLD DATASETS,0.3989431968295905,"rationale of our method, which considers noise generation from a transfer probability distribution
270"
EXPERIMENTAL RESULTS ON REAL-WORLD DATASETS,0.4002642007926024,"perspective. The experiments demonstrate that our method achieves better learning performance by
271"
EXPERIMENTAL RESULTS ON REAL-WORLD DATASETS,0.40158520475561427,"effectively integrating the transition matrix with the diffusion model.
272"
ABLATION STUDY,0.40290620871862615,"4.6
Ablation Study
273"
ABLATION STUDY,0.404227212681638,"Besides the aforementioned experiments, we conducted ablation studies on proposed DTM method
274"
ABLATION STUDY,0.40554821664464996,"to assess the importance of each component. Table 4 presents the comparative results under 20%
275"
ABLATION STUDY,0.40686922060766184,"and 40% instance-dependent noise rates, where ""w/o"" denotes ""without"". We conducted ablation
276"
ABLATION STUDY,0.4081902245706737,"experiments on three components of our method, they are diffusion module, pre-trained encoder
277"
ABLATION STUDY,0.4095112285336856,"module, and clustering module respectively. ""w/o diffusion"" indicates directly using the features
278"
ABLATION STUDY,0.4108322324966975,"extracted by the pre-trained model for the classification task with the transition matrix. ""w/o pre-train""
279"
ABLATION STUDY,0.41215323645970936,"means not extracting features through self-supervised learning and directly utilizing the classification
280"
ABLATION STUDY,0.4134742404227213,"network with the diffusion model. ""w/o clustering"" indicates that the initial transition matrix used for
281"
ABLATION STUDY,0.4147952443857332,"the diffusion model is the same for all samples.
282"
ABLATION STUDY,0.41611624834874505,Table 4: Ablation study of DTR. The data in the table represents the test accuracy.
ABLATION STUDY,0.41743725231175693,"CIFAR-10
CIFAR-100
IDN-0.2
IDN-0.4
IDN-0.2
IDN-0.4
w/o pre-train
90.52
83.61
66.17
61.79
w/o clustering
92.25
88.35
71.93
66.47
w/o diffusion
93.74
91.66
79.82
73.51
DTR
95.90
94.82
82.04
78.56"
ABLATION STUDY,0.4187582562747688,"From the results in Table 4, it can be observed that regardless of which component of diffusion
283"
ABLATION STUDY,0.4200792602377807,"module, pre-trained encoder module and clustering module is missing, the performance is consistently
284"
ABLATION STUDY,0.42140026420079263,"weaker compared to the original DTM. This indicates that each module plays a crucial role in our
285"
ABLATION STUDY,0.4227212681638045,"method. Our approach effectively combines the transition matrix, diffusion model, and pre-trained
286"
ABLATION STUDY,0.4240422721268164,"feature extraction, leading to significant improvements.
287"
CONCLUSION,0.42536327608982827,"5
Conclusion
288"
CONCLUSION,0.42668428005284015,"In this paper, we propose a method that models the transition matrix using diffusion models, incorpo-
289"
CONCLUSION,0.42800528401585203,"rating the feature information extracted by a pre-trained encoder into the estimation of the transition
290"
CONCLUSION,0.42932628797886396,"matrix. This approach enables the model to handle instance-dependent label noise with a wider range
291"
CONCLUSION,0.43064729194187584,"of applicability. Experimental results on both synthetic and real-world noisy datasets demonstrate the
292"
CONCLUSION,0.4319682959048877,"effectiveness of our proposed method.
293"
REFERENCES,0.4332892998678996,"References
294"
REFERENCES,0.4346103038309115,"[1] Görkem Algan and Ilkay Ulusoy. Image classification with deep learning in the presence of
295"
REFERENCES,0.43593130779392336,"noisy labels: A survey. Knowledge-Based Systems, 215:106771, 2021.
296"
REFERENCES,0.4372523117569353,"[2] Devansh Arpit, Stanisław Jastrz˛ebski, Nicolas Ballas, David Krueger, Emmanuel Bengio,
297"
REFERENCES,0.4385733157199472,"Maxinder S Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, et al.
298"
REFERENCES,0.43989431968295906,"A closer look at memorization in deep networks. In International Conference on Machine
299"
REFERENCES,0.44121532364597094,"Learning, pages 233–242. PMLR, 2017.
300"
REFERENCES,0.4425363276089828,"[3] Jian Chen, Ruiyi Zhang, Tong Yu, Rohan Sharma, Zhiqiang Xu, Tong Sun, and Changyou Chen.
301"
REFERENCES,0.4438573315719947,"Label-retrieval-augmented diffusion models for learning from noisy labels. arXiv preprint
302"
REFERENCES,0.44517833553500663,"arXiv:2305.19518, 2023.
303"
REFERENCES,0.4464993394980185,"[4] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework
304"
REFERENCES,0.4478203434610304,"for contrastive learning of visual representations. In International Conference on Machine
305"
REFERENCES,0.44914134742404227,"Learning, pages 1597–1607. PMLR, 2020.
306"
REFERENCES,0.45046235138705415,"[5] Wenkai Chen, Chuang Zhu, and Mengting Li. Sample prior guided robust model learning to
307"
REFERENCES,0.45178335535006603,"suppress noisy labels. In Joint European Conference on Machine Learning and Knowledge
308"
REFERENCES,0.45310435931307796,"Discovery in Databases, pages 3–19. Springer, 2023.
309"
REFERENCES,0.45442536327608984,"[6] De Cheng, Tongliang Liu, Yixiong Ning, Nannan Wang, Bo Han, Gang Niu, Xinbo Gao,
310"
REFERENCES,0.4557463672391017,"and Masashi Sugiyama. Instance-dependent label-noise learning with manifold-regularized
311"
REFERENCES,0.4570673712021136,"transition matrix estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision
312"
REFERENCES,0.4583883751651255,"and Pattern Recognition, pages 16630–16639, 2022.
313"
REFERENCES,0.45970937912813736,"[7] Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, and Mubarak Shah. Diffusion
314"
REFERENCES,0.4610303830911493,"models in vision: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence,
315"
REFERENCES,0.4623513870541612,"2023.
316"
REFERENCES,0.46367239101717306,"[8] Amit Daniely and Elad Granot. Generalization bounds for neural networks via approximate
317"
REFERENCES,0.46499339498018494,"description length. Advances in Neural Information Processing Systems, 32, 2019.
318"
REFERENCES,0.4663143989431968,"[9] Jacob Goldberger and Ehud Ben-Reuven. Training deep neural-networks using a noise adapta-
319"
REFERENCES,0.4676354029062087,"tion layer. In International Conference on Learning Representations, 2016.
320"
REFERENCES,0.46895640686922063,"[10] Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi
321"
REFERENCES,0.4702774108322325,"Sugiyama. Co-teaching: Robust training of deep neural networks with extremely noisy labels.
322"
REFERENCES,0.4715984147952444,"Advances in Neural Information Processing Systems, 31, 2018.
323"
REFERENCES,0.47291941875825627,"[11] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances
324"
REFERENCES,0.47424042272126815,"in Neural Information Processing Systems, 33:6840–6851, 2020.
325"
REFERENCES,0.47556142668428003,"[12] Zhimeng Jiang, Kaixiong Zhou, Zirui Liu, Li Li, Rui Chen, Soo-Hyun Choi, and Xia Hu. An
326"
REFERENCES,0.47688243064729197,"information fusion approach to learning with instance-dependent label noise. In International
327"
REFERENCES,0.47820343461030385,"Conference on Learning Representations, 2021.
328"
REFERENCES,0.4795244385733157,"[13] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.
329"
REFERENCES,0.4808454425363276,"2009.
330"
REFERENCES,0.4821664464993395,"[14] Junnan Li, Richard Socher, and Steven CH Hoi. Dividemix: Learning with noisy labels as
331"
REFERENCES,0.48348745046235136,"semi-supervised learning. arXiv preprint arXiv:2002.07394, 2020.
332"
REFERENCES,0.4848084544253633,"[15] Shikun Li, Xiaobo Xia, Hansong Zhang, Yibing Zhan, Shiming Ge, and Tongliang Liu. Esti-
333"
REFERENCES,0.4861294583883752,"mating noise transition matrix with label correlations for noisy multi-label learning. Advances
334"
REFERENCES,0.48745046235138706,"in Neural Information Processing Systems, 35:24184–24198, 2022.
335"
REFERENCES,0.48877146631439894,"[16] Wen Li, Limin Wang, Wei Li, Eirikur Agustsson, and Luc Van Gool. Webvision database:
336"
REFERENCES,0.4900924702774108,"Visual learning and understanding from web data. arXiv preprint arXiv:1708.02862, 2017.
337"
REFERENCES,0.4914134742404227,"[17] Xuefeng Li, Tongliang Liu, Bo Han, Gang Niu, and Masashi Sugiyama. Provably end-to-end
338"
REFERENCES,0.49273447820343463,"label-noise learning without anchor points. In International Conference on Machine Learning,
339"
REFERENCES,0.4940554821664465,"pages 6403–6413. PMLR, 2021.
340"
REFERENCES,0.4953764861294584,"[18] Sheng Liu, Jonathan Niles-Weed, Narges Razavian, and Carlos Fernandez-Granda. Early-
341"
REFERENCES,0.4966974900924703,"learning regularization prevents memorization of noisy labels. Advances in Neural Information
342"
REFERENCES,0.49801849405548215,"Processing Systems, 33:20331–20342, 2020.
343"
REFERENCES,0.49933949801849403,"[19] Sheng Liu, Zhihui Zhu, Qing Qu, and Chong You. Robust training under label noise by over-
344"
REFERENCES,0.5006605019815059,"parameterization. In International Conference on Machine Learning, pages 14153–14172.
345"
REFERENCES,0.5019815059445178,"PMLR, 2022.
346"
REFERENCES,0.5033025099075297,"[20] Yang Liu, Hao Cheng, and Kun Zhang. Identifiability of label noise transition matrix. In
347"
REFERENCES,0.5046235138705416,"International Conference on Machine Learning, pages 21475–21496. PMLR, 2023.
348"
REFERENCES,0.5059445178335535,"[21] Yang Liu and Hongyi Guo. Peer loss functions: Learning from noisy labels without knowing
349"
REFERENCES,0.5072655217965654,"noise rates. In International Conference on Machine Learning, pages 6226–6236. PMLR, 2020.
350"
REFERENCES,0.5085865257595773,"[22] Xingjun Ma, Hanxun Huang, Yisen Wang, Simone Romano, Sarah Erfani, and James Bailey.
351"
REFERENCES,0.5099075297225891,"Normalized loss functions for deep learning with noisy labels. In International Conference on
352"
REFERENCES,0.5112285336856011,"Machine Learning, pages 6543–6553. PMLR, 2020.
353"
REFERENCES,0.512549537648613,"[23] Nagarajan Natarajan, Inderjit S Dhillon, Pradeep K Ravikumar, and Ambuj Tewari. Learning
354"
REFERENCES,0.5138705416116248,"with noisy labels. Advances in Neural Information Processing Systems, 26, 2013.
355"
REFERENCES,0.5151915455746368,"[24] Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu.
356"
REFERENCES,0.5165125495376486,"Making deep neural networks robust to label noise: A loss correction approach. In Proceedings
357"
REFERENCES,0.5178335535006605,"of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1944–1952, 2017.
358"
REFERENCES,0.5191545574636723,"[25] Samira Pouyanfar, Saad Sadiq, Yilin Yan, Haiman Tian, Yudong Tao, Maria Presa Reyes, Mei-
359"
REFERENCES,0.5204755614266843,"Ling Shyu, Shu-Ching Chen, and Sundaraja S Iyengar. A survey on deep learning: Algorithms,
360"
REFERENCES,0.5217965653896962,"techniques, and applications. ACM Computing Surveys (CSUR), 51(5):1–36, 2018.
361"
REFERENCES,0.523117569352708,"[26] Jun Shu, Qian Zhao, Zongben Xu, and Deyu Meng. Meta transition adaptation for robust deep
362"
REFERENCES,0.52443857331572,"learning with noisy labels. arXiv preprint arXiv:2006.05697, 2020.
363"
REFERENCES,0.5257595772787318,"[27] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. arXiv
364"
REFERENCES,0.5270805812417437,"preprint arXiv:2010.02502, 2020.
365"
REFERENCES,0.5284015852047557,"[28] Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data
366"
REFERENCES,0.5297225891677675,"distribution. Advances in Neural Information Processing Systems, 32, 2019.
367"
REFERENCES,0.5310435931307794,"[29] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and
368"
REFERENCES,0.5323645970937912,"Ben Poole. Score-based generative modeling through stochastic differential equations. arXiv
369"
REFERENCES,0.5336856010568032,"preprint arXiv:2011.13456, 2020.
370"
REFERENCES,0.535006605019815,"[30] Jialu Wang, Yang Liu, and Caleb Levy. Fair classification with group-dependent label noise. In
371"
REFERENCES,0.5363276089828269,"Proceedings of the 2021 ACM conference on fairness, accountability, and transparency, pages
372"
REFERENCES,0.5376486129458389,"526–536, 2021.
373"
REFERENCES,0.5389696169088507,"[31] Yisen Wang, Xingjun Ma, Zaiyi Chen, Yuan Luo, Jinfeng Yi, and James Bailey. Symmetric cross
374"
REFERENCES,0.5402906208718626,"entropy for robust learning with noisy labels. In Proceedings of the IEEE/CVF International
375"
REFERENCES,0.5416116248348745,"Conference on Computer Vision, pages 322–330, 2019.
376"
REFERENCES,0.5429326287978864,"[32] Jiaheng Wei, Zhaowei Zhu, Hao Cheng, Tongliang Liu, Gang Niu, and Yang Liu. Learning
377"
REFERENCES,0.5442536327608983,"with noisy labels revisited: A study using real-world human annotations. arXiv preprint
378"
REFERENCES,0.5455746367239102,"arXiv:2110.12088, 2021.
379"
REFERENCES,0.5468956406869221,"[33] Xiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Mingming Gong, Haifeng Liu, Gang Niu,
380"
REFERENCES,0.5482166446499339,"Dacheng Tao, and Masashi Sugiyama. Part-dependent label noise: Towards instance-dependent
381"
REFERENCES,0.5495376486129459,"label noise. Advances in Neural Information Processing Systems, 33:7597–7610, 2020.
382"
REFERENCES,0.5508586525759577,"[34] Xiaobo Xia, Tongliang Liu, Nannan Wang, Bo Han, Chen Gong, Gang Niu, and Masashi
383"
REFERENCES,0.5521796565389696,"Sugiyama. Are anchor points really indispensable in label-noise learning? Advances in Neural
384"
REFERENCES,0.5535006605019815,"Information Processing Systems, 32, 2019.
385"
REFERENCES,0.5548216644649934,"[35] Tong Xiao, Tian Xia, Yi Yang, Chang Huang, and Xiaogang Wang. Learning from massive
386"
REFERENCES,0.5561426684280053,"noisy labeled data for image classification. In Proceedings of the IEEE Conference on Computer
387"
REFERENCES,0.5574636723910171,"Vision and Pattern Recognition, pages 2691–2699, 2015.
388"
REFERENCES,0.5587846763540291,"[36] Ling Yang, Zhilong Zhang, Yang Song, Shenda Hong, Runsheng Xu, Yue Zhao, Wentao Zhang,
389"
REFERENCES,0.560105680317041,"Bin Cui, and Ming-Hsuan Yang. Diffusion models: A comprehensive survey of methods and
390"
REFERENCES,0.5614266842800528,"applications. ACM Computing Surveys, 56(4):1–39, 2023.
391"
REFERENCES,0.5627476882430648,"[37] Shuo Yang, Erkun Yang, Bo Han, Yang Liu, Min Xu, Gang Niu, and Tongliang Liu. Estimating
392"
REFERENCES,0.5640686922060766,"instance-dependent bayes-label transition matrix using a deep neural network. In International
393"
REFERENCES,0.5653896961690885,"Conference on Machine Learning, pages 25302–25312. PMLR, 2022.
394"
REFERENCES,0.5667107001321003,"[38] LIN Yong, Renjie Pi, Weizhong Zhang, Xiaobo Xia, Jiahui Gao, Xiao Zhou, Tongliang Liu,
395"
REFERENCES,0.5680317040951123,"and Bo Han. A holistic view of label noise transition matrix in deep learning and beyond. In
396"
REFERENCES,0.5693527080581242,"The Eleventh International Conference on Learning Representations, 2022.
397"
REFERENCES,0.570673712021136,"[39] Yivan Zhang, Gang Niu, and Masashi Sugiyama. Learning noise transition matrix from only
398"
REFERENCES,0.571994715984148,"noisy labels via total variation regularization. In International Conference on Machine Learning,
399"
REFERENCES,0.5733157199471598,"pages 12501–12512. PMLR, 2021.
400"
REFERENCES,0.5746367239101717,"[40] Ganlong Zhao, Guanbin Li, Yipeng Qin, Feng Liu, and Yizhou Yu. Centrality and consistency:
401"
REFERENCES,0.5759577278731837,"two-stage clean samples identification for learning with instance-dependent noisy labels. In
402"
REFERENCES,0.5772787318361955,"European Conference on Computer Vision, pages 21–37. Springer, 2022.
403"
REFERENCES,0.5785997357992074,"[41] Zhaowei Zhu, Yiwen Song, and Yang Liu. Clusterability as an alternative to anchor points
404"
REFERENCES,0.5799207397622193,"when learning with noisy labels. In International Conference on Machine Learning, pages
405"
REFERENCES,0.5812417437252312,"12912–12923. PMLR, 2021.
406"
REFERENCES,0.582562747688243,"[42] Zhaowei Zhu, Jialu Wang, and Yang Liu. Beyond images: Label noise transition matrix
407"
REFERENCES,0.583883751651255,"estimation for tasks with lower-quality features. In International Conference on Machine
408"
REFERENCES,0.5852047556142669,"Learning, pages 27633–27653. PMLR, 2022.
409"
REFERENCES,0.5865257595772787,"NeurIPS Paper Checklist
410"
CLAIMS,0.5878467635402906,"1. Claims
411"
CLAIMS,0.5891677675033025,"Question: Do the main claims made in the abstract and introduction accurately reflect the
412"
CLAIMS,0.5904887714663144,"paper’s contributions and scope?
413"
CLAIMS,0.5918097754293263,"Answer: [Yes]
414"
CLAIMS,0.5931307793923382,"Justification: The main content and contributions of the work are reflected in the abstract
415"
CLAIMS,0.5944517833553501,"and introduction.
416"
CLAIMS,0.5957727873183619,"Guidelines:
417"
CLAIMS,0.5970937912813739,"• The answer NA means that the abstract and introduction do not include the claims
418"
CLAIMS,0.5984147952443857,"made in the paper.
419"
CLAIMS,0.5997357992073976,"• The abstract and/or introduction should clearly state the claims made, including the
420"
CLAIMS,0.6010568031704095,"contributions made in the paper and important assumptions and limitations. A No or
421"
CLAIMS,0.6023778071334214,"NA answer to this question will not be perceived well by the reviewers.
422"
CLAIMS,0.6036988110964333,"• The claims made should match theoretical and experimental results, and reflect how
423"
CLAIMS,0.6050198150594451,"much the results can be expected to generalize to other settings.
424"
CLAIMS,0.6063408190224571,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
425"
CLAIMS,0.607661822985469,"are not attained by the paper.
426"
LIMITATIONS,0.6089828269484808,"2. Limitations
427"
LIMITATIONS,0.6103038309114928,"Question: Does the paper discuss the limitations of the work performed by the authors?
428"
LIMITATIONS,0.6116248348745046,"Answer: [Yes]
429"
LIMITATIONS,0.6129458388375165,"Justification: In the experimental section, we analyze the applicability and limitations of our
430"
LIMITATIONS,0.6142668428005285,"method.
431"
LIMITATIONS,0.6155878467635403,"Guidelines:
432"
LIMITATIONS,0.6169088507265522,"• The answer NA means that the paper has no limitation while the answer No means that
433"
LIMITATIONS,0.618229854689564,"the paper has limitations, but those are not discussed in the paper.
434"
LIMITATIONS,0.619550858652576,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
435"
LIMITATIONS,0.6208718626155878,"• The paper should point out any strong assumptions and how robust the results are to
436"
LIMITATIONS,0.6221928665785997,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
437"
LIMITATIONS,0.6235138705416117,"model well-specification, asymptotic approximations only holding locally). The authors
438"
LIMITATIONS,0.6248348745046235,"should reflect on how these assumptions might be violated in practice and what the
439"
LIMITATIONS,0.6261558784676354,"implications would be.
440"
LIMITATIONS,0.6274768824306473,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
441"
LIMITATIONS,0.6287978863936592,"only tested on a few datasets or with a few runs. In general, empirical results often
442"
LIMITATIONS,0.6301188903566711,"depend on implicit assumptions, which should be articulated.
443"
LIMITATIONS,0.631439894319683,"• The authors should reflect on the factors that influence the performance of the approach.
444"
LIMITATIONS,0.6327608982826949,"For example, a facial recognition algorithm may perform poorly when image resolution
445"
LIMITATIONS,0.6340819022457067,"is low or images are taken in low lighting. Or a speech-to-text system might not be
446"
LIMITATIONS,0.6354029062087186,"used reliably to provide closed captions for online lectures because it fails to handle
447"
LIMITATIONS,0.6367239101717305,"technical jargon.
448"
LIMITATIONS,0.6380449141347424,"• The authors should discuss the computational efficiency of the proposed algorithms
449"
LIMITATIONS,0.6393659180977543,"and how they scale with dataset size.
450"
LIMITATIONS,0.6406869220607662,"• If applicable, the authors should discuss possible limitations of their approach to
451"
LIMITATIONS,0.6420079260237781,"address problems of privacy and fairness.
452"
LIMITATIONS,0.6433289299867899,"• While the authors might fear that complete honesty about limitations might be used by
453"
LIMITATIONS,0.6446499339498019,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
454"
LIMITATIONS,0.6459709379128138,"limitations that aren’t acknowledged in the paper. The authors should use their best
455"
LIMITATIONS,0.6472919418758256,"judgment and recognize that individual actions in favor of transparency play an impor-
456"
LIMITATIONS,0.6486129458388376,"tant role in developing norms that preserve the integrity of the community. Reviewers
457"
LIMITATIONS,0.6499339498018494,"will be specifically instructed to not penalize honesty concerning limitations.
458"
THEORY ASSUMPTIONS AND PROOFS,0.6512549537648613,"3. Theory Assumptions and Proofs
459"
THEORY ASSUMPTIONS AND PROOFS,0.6525759577278731,"Question: For each theoretical result, does the paper provide the full set of assumptions and
460"
THEORY ASSUMPTIONS AND PROOFS,0.6538969616908851,"a complete (and correct) proof?
461"
THEORY ASSUMPTIONS AND PROOFS,0.655217965653897,"Answer: [NA]
462"
THEORY ASSUMPTIONS AND PROOFS,0.6565389696169088,"Justification: The focus of the work is on application and does not include a theoretical
463"
THEORY ASSUMPTIONS AND PROOFS,0.6578599735799208,"proof component.
464"
THEORY ASSUMPTIONS AND PROOFS,0.6591809775429326,"Guidelines:
465"
THEORY ASSUMPTIONS AND PROOFS,0.6605019815059445,"• The answer NA means that the paper does not include theoretical results.
466"
THEORY ASSUMPTIONS AND PROOFS,0.6618229854689565,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
467"
THEORY ASSUMPTIONS AND PROOFS,0.6631439894319683,"referenced.
468"
THEORY ASSUMPTIONS AND PROOFS,0.6644649933949802,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
469"
THEORY ASSUMPTIONS AND PROOFS,0.665785997357992,"• The proofs can either appear in the main paper or the supplemental material, but if
470"
THEORY ASSUMPTIONS AND PROOFS,0.667107001321004,"they appear in the supplemental material, the authors are encouraged to provide a short
471"
THEORY ASSUMPTIONS AND PROOFS,0.6684280052840158,"proof sketch to provide intuition.
472"
THEORY ASSUMPTIONS AND PROOFS,0.6697490092470277,"• Inversely, any informal proof provided in the core of the paper should be complemented
473"
THEORY ASSUMPTIONS AND PROOFS,0.6710700132100397,"by formal proofs provided in appendix or supplemental material.
474"
THEORY ASSUMPTIONS AND PROOFS,0.6723910171730515,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
475"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6737120211360634,"4. Experimental Result Reproducibility
476"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6750330250990753,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
477"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6763540290620872,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
478"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6776750330250991,"of the paper (regardless of whether the code and data are provided or not)?
479"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.678996036988111,"Answer: [Yes]
480"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6803170409511229,"Justification: The paper provides a detailed description of the model construction and the
481"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6816380449141347,"specifics of the experimental data.
482"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6829590488771466,"Guidelines:
483"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6842800528401585,"• The answer NA means that the paper does not include experiments.
484"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6856010568031704,"• If the paper includes experiments, a No answer to this question will not be perceived
485"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6869220607661823,"well by the reviewers: Making the paper reproducible is important, regardless of
486"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6882430647291942,"whether the code and data are provided or not.
487"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6895640686922061,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
488"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6908850726552179,"to make their results reproducible or verifiable.
489"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6922060766182299,"• Depending on the contribution, reproducibility can be accomplished in various ways.
490"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6935270805812418,"For example, if the contribution is a novel architecture, describing the architecture fully
491"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6948480845442536,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
492"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6961690885072656,"be necessary to either make it possible for others to replicate the model with the same
493"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6974900924702774,"dataset, or provide access to the model. In general. releasing code and data is often
494"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6988110964332893,"one good way to accomplish this, but reproducibility can also be provided via detailed
495"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7001321003963011,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
496"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7014531043593131,"of a large language model), releasing of a model checkpoint, or other means that are
497"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.702774108322325,"appropriate to the research performed.
498"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7040951122853368,"• While NeurIPS does not require releasing code, the conference does require all submis-
499"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7054161162483488,"sions to provide some reasonable avenue for reproducibility, which may depend on the
500"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7067371202113606,"nature of the contribution. For example
501"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7080581241743725,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
502"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7093791281373845,"to reproduce that algorithm.
503"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7107001321003963,"(b) If the contribution is primarily a new model architecture, the paper should describe
504"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7120211360634082,"the architecture clearly and fully.
505"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.71334214002642,"(c) If the contribution is a new model (e.g., a large language model), then there should
506"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.714663143989432,"either be a way to access this model for reproducing the results or a way to reproduce
507"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7159841479524438,"the model (e.g., with an open-source dataset or instructions for how to construct
508"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7173051519154557,"the dataset).
509"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7186261558784677,"(d) We recognize that reproducibility may be tricky in some cases, in which case
510"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7199471598414795,"authors are welcome to describe the particular way they provide for reproducibility.
511"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7212681638044914,"In the case of closed-source models, it may be that access to the model is limited in
512"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7225891677675033,"some way (e.g., to registered users), but it should be possible for other researchers
513"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7239101717305152,"to have some path to reproducing or verifying the results.
514"
OPEN ACCESS TO DATA AND CODE,0.7252311756935271,"5. Open access to data and code
515"
OPEN ACCESS TO DATA AND CODE,0.726552179656539,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
516"
OPEN ACCESS TO DATA AND CODE,0.7278731836195509,"tions to faithfully reproduce the main experimental results, as described in supplemental
517"
OPEN ACCESS TO DATA AND CODE,0.7291941875825627,"material?
518"
OPEN ACCESS TO DATA AND CODE,0.7305151915455746,"Answer: [No]
519"
OPEN ACCESS TO DATA AND CODE,0.7318361955085865,"Justification: Upon acceptance of our paper, we will provide open-source code. The data we
520"
OPEN ACCESS TO DATA AND CODE,0.7331571994715984,"used is from commonly available open-source datasets.
521"
OPEN ACCESS TO DATA AND CODE,0.7344782034346103,"Guidelines:
522"
OPEN ACCESS TO DATA AND CODE,0.7357992073976222,"• The answer NA means that paper does not include experiments requiring code.
523"
OPEN ACCESS TO DATA AND CODE,0.7371202113606341,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
524"
OPEN ACCESS TO DATA AND CODE,0.7384412153236459,"public/guides/CodeSubmissionPolicy) for more details.
525"
OPEN ACCESS TO DATA AND CODE,0.7397622192866579,"• While we encourage the release of code and data, we understand that this might not be
526"
OPEN ACCESS TO DATA AND CODE,0.7410832232496698,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
527"
OPEN ACCESS TO DATA AND CODE,0.7424042272126816,"including code, unless this is central to the contribution (e.g., for a new open-source
528"
OPEN ACCESS TO DATA AND CODE,0.7437252311756936,"benchmark).
529"
OPEN ACCESS TO DATA AND CODE,0.7450462351387054,"• The instructions should contain the exact command and environment needed to run to
530"
OPEN ACCESS TO DATA AND CODE,0.7463672391017173,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
531"
OPEN ACCESS TO DATA AND CODE,0.7476882430647291,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
532"
OPEN ACCESS TO DATA AND CODE,0.7490092470277411,"• The authors should provide instructions on data access and preparation, including how
533"
OPEN ACCESS TO DATA AND CODE,0.750330250990753,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
534"
OPEN ACCESS TO DATA AND CODE,0.7516512549537648,"• The authors should provide scripts to reproduce all experimental results for the new
535"
OPEN ACCESS TO DATA AND CODE,0.7529722589167768,"proposed method and baselines. If only a subset of experiments are reproducible, they
536"
OPEN ACCESS TO DATA AND CODE,0.7542932628797886,"should state which ones are omitted from the script and why.
537"
OPEN ACCESS TO DATA AND CODE,0.7556142668428005,"• At submission time, to preserve anonymity, the authors should release anonymized
538"
OPEN ACCESS TO DATA AND CODE,0.7569352708058125,"versions (if applicable).
539"
OPEN ACCESS TO DATA AND CODE,0.7582562747688243,"• Providing as much information as possible in supplemental material (appended to the
540"
OPEN ACCESS TO DATA AND CODE,0.7595772787318362,"paper) is recommended, but including URLs to data and code is permitted.
541"
OPEN ACCESS TO DATA AND CODE,0.760898282694848,"6. Experimental Setting/Details
542"
OPEN ACCESS TO DATA AND CODE,0.76221928665786,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
543"
OPEN ACCESS TO DATA AND CODE,0.7635402906208718,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
544"
OPEN ACCESS TO DATA AND CODE,0.7648612945838837,"results?
545"
OPEN ACCESS TO DATA AND CODE,0.7661822985468957,"Answer: [Yes]
546"
OPEN ACCESS TO DATA AND CODE,0.7675033025099075,"Justification: The experimental section of the paper provides details of the model and data.
547"
OPEN ACCESS TO DATA AND CODE,0.7688243064729194,"Guidelines:
548"
OPEN ACCESS TO DATA AND CODE,0.7701453104359313,"• The answer NA means that the paper does not include experiments.
549"
OPEN ACCESS TO DATA AND CODE,0.7714663143989432,"• The experimental setting should be presented in the core of the paper to a level of detail
550"
OPEN ACCESS TO DATA AND CODE,0.7727873183619551,"that is necessary to appreciate the results and make sense of them.
551"
OPEN ACCESS TO DATA AND CODE,0.774108322324967,"• The full details can be provided either with the code, in appendix, or as supplemental
552"
OPEN ACCESS TO DATA AND CODE,0.7754293262879789,"material.
553"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7767503302509907,"7. Experiment Statistical Significance
554"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7780713342140027,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
555"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7793923381770145,"information about the statistical significance of the experiments?
556"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7807133421400264,"Answer: [Yes]
557"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7820343461030383,"Justification: We conducted multiple repeated experiments to validate our approach and
558"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7833553500660502,"performed ablation experiments.
559"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7846763540290621,"Guidelines:
560"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7859973579920739,"• The answer NA means that the paper does not include experiments.
561"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7873183619550859,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
562"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7886393659180978,"dence intervals, or statistical significance tests, at least for the experiments that support
563"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7899603698811096,"the main claims of the paper.
564"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7912813738441216,"• The factors of variability that the error bars are capturing should be clearly stated (for
565"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7926023778071334,"example, train/test split, initialization, random drawing of some parameter, or overall
566"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7939233817701453,"run with given experimental conditions).
567"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7952443857331571,"• The method for calculating the error bars should be explained (closed form formula,
568"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7965653896961691,"call to a library function, bootstrap, etc.)
569"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.797886393659181,"• The assumptions made should be given (e.g., Normally distributed errors).
570"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7992073976221928,"• It should be clear whether the error bar is the standard deviation or the standard error
571"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8005284015852048,"of the mean.
572"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8018494055482166,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
573"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8031704095112285,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
574"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8044914134742405,"of Normality of errors is not verified.
575"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8058124174372523,"• For asymmetric distributions, the authors should be careful not to show in tables or
576"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8071334214002642,"figures symmetric error bars that would yield results that are out of range (e.g. negative
577"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.808454425363276,"error rates).
578"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.809775429326288,"• If error bars are reported in tables or plots, The authors should explain in the text how
579"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8110964332892999,"they were calculated and reference the corresponding figures or tables in the text.
580"
EXPERIMENTS COMPUTE RESOURCES,0.8124174372523117,"8. Experiments Compute Resources
581"
EXPERIMENTS COMPUTE RESOURCES,0.8137384412153237,"Question: For each experiment, does the paper provide sufficient information on the com-
582"
EXPERIMENTS COMPUTE RESOURCES,0.8150594451783355,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
583"
EXPERIMENTS COMPUTE RESOURCES,0.8163804491413474,"the experiments?
584"
EXPERIMENTS COMPUTE RESOURCES,0.8177014531043593,"Answer: [Yes]
585"
EXPERIMENTS COMPUTE RESOURCES,0.8190224570673712,"Justification: We list the relevant details in the experimental section.
586"
EXPERIMENTS COMPUTE RESOURCES,0.8203434610303831,"Guidelines:
587"
EXPERIMENTS COMPUTE RESOURCES,0.821664464993395,"• The answer NA means that the paper does not include experiments.
588"
EXPERIMENTS COMPUTE RESOURCES,0.8229854689564069,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
589"
EXPERIMENTS COMPUTE RESOURCES,0.8243064729194187,"or cloud provider, including relevant memory and storage.
590"
EXPERIMENTS COMPUTE RESOURCES,0.8256274768824307,"• The paper should provide the amount of compute required for each of the individual
591"
EXPERIMENTS COMPUTE RESOURCES,0.8269484808454426,"experimental runs as well as estimate the total compute.
592"
EXPERIMENTS COMPUTE RESOURCES,0.8282694848084544,"• The paper should disclose whether the full research project required more compute
593"
EXPERIMENTS COMPUTE RESOURCES,0.8295904887714664,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
594"
EXPERIMENTS COMPUTE RESOURCES,0.8309114927344782,"didn’t make it into the paper).
595"
CODE OF ETHICS,0.8322324966974901,"9. Code Of Ethics
596"
CODE OF ETHICS,0.8335535006605019,"Question: Does the research conducted in the paper conform, in every respect, with the
597"
CODE OF ETHICS,0.8348745046235139,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
598"
CODE OF ETHICS,0.8361955085865258,"Answer: [Yes]
599"
CODE OF ETHICS,0.8375165125495376,"Justification: We submitted the paper following the NeurIPS Code of Ethics.
600"
CODE OF ETHICS,0.8388375165125496,"Guidelines:
601"
CODE OF ETHICS,0.8401585204755614,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
602"
CODE OF ETHICS,0.8414795244385733,"• If the authors answer No, they should explain the special circumstances that require a
603"
CODE OF ETHICS,0.8428005284015853,"deviation from the Code of Ethics.
604"
CODE OF ETHICS,0.8441215323645971,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
605"
CODE OF ETHICS,0.845442536327609,"eration due to laws or regulations in their jurisdiction).
606"
BROADER IMPACTS,0.8467635402906208,"10. Broader Impacts
607"
BROADER IMPACTS,0.8480845442536328,"Question: Does the paper discuss both potential positive societal impacts and negative
608"
BROADER IMPACTS,0.8494055482166446,"societal impacts of the work performed?
609"
BROADER IMPACTS,0.8507265521796565,"Answer: [Yes]
610"
BROADER IMPACTS,0.8520475561426685,"Justification: We discuss the positive implications of our work and ensure it does not have
611"
BROADER IMPACTS,0.8533685601056803,"any negative societal impact.
612"
BROADER IMPACTS,0.8546895640686922,"Guidelines:
613"
BROADER IMPACTS,0.8560105680317041,"• The answer NA means that there is no societal impact of the work performed.
614"
BROADER IMPACTS,0.857331571994716,"• If the authors answer NA or No, they should explain why their work has no societal
615"
BROADER IMPACTS,0.8586525759577279,"impact or why the paper does not address societal impact.
616"
BROADER IMPACTS,0.8599735799207398,"• Examples of negative societal impacts include potential malicious or unintended uses
617"
BROADER IMPACTS,0.8612945838837517,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
618"
BROADER IMPACTS,0.8626155878467635,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
619"
BROADER IMPACTS,0.8639365918097754,"groups), privacy considerations, and security considerations.
620"
BROADER IMPACTS,0.8652575957727873,"• The conference expects that many papers will be foundational research and not tied
621"
BROADER IMPACTS,0.8665785997357992,"to particular applications, let alone deployments. However, if there is a direct path to
622"
BROADER IMPACTS,0.8678996036988111,"any negative applications, the authors should point it out. For example, it is legitimate
623"
BROADER IMPACTS,0.869220607661823,"to point out that an improvement in the quality of generative models could be used to
624"
BROADER IMPACTS,0.8705416116248349,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
625"
BROADER IMPACTS,0.8718626155878467,"that a generic algorithm for optimizing neural networks could enable people to train
626"
BROADER IMPACTS,0.8731836195508587,"models that generate Deepfakes faster.
627"
BROADER IMPACTS,0.8745046235138706,"• The authors should consider possible harms that could arise when the technology is
628"
BROADER IMPACTS,0.8758256274768824,"being used as intended and functioning correctly, harms that could arise when the
629"
BROADER IMPACTS,0.8771466314398944,"technology is being used as intended but gives incorrect results, and harms following
630"
BROADER IMPACTS,0.8784676354029062,"from (intentional or unintentional) misuse of the technology.
631"
BROADER IMPACTS,0.8797886393659181,"• If there are negative societal impacts, the authors could also discuss possible mitigation
632"
BROADER IMPACTS,0.8811096433289299,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
633"
BROADER IMPACTS,0.8824306472919419,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
634"
BROADER IMPACTS,0.8837516512549538,"feedback over time, improving the efficiency and accessibility of ML).
635"
SAFEGUARDS,0.8850726552179656,"11. Safeguards
636"
SAFEGUARDS,0.8863936591809776,"Question: Does the paper describe safeguards that have been put in place for responsible
637"
SAFEGUARDS,0.8877146631439894,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
638"
SAFEGUARDS,0.8890356671070013,"image generators, or scraped datasets)?
639"
SAFEGUARDS,0.8903566710700133,"Answer: [NA]
640"
SAFEGUARDS,0.8916776750330251,"Justification: There are no concerns in this regard regarding this work.
641"
SAFEGUARDS,0.892998678996037,"Guidelines:
642"
SAFEGUARDS,0.8943196829590488,"• The answer NA means that the paper poses no such risks.
643"
SAFEGUARDS,0.8956406869220608,"• Released models that have a high risk for misuse or dual-use should be released with
644"
SAFEGUARDS,0.8969616908850726,"necessary safeguards to allow for controlled use of the model, for example by requiring
645"
SAFEGUARDS,0.8982826948480845,"that users adhere to usage guidelines or restrictions to access the model or implementing
646"
SAFEGUARDS,0.8996036988110965,"safety filters.
647"
SAFEGUARDS,0.9009247027741083,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
648"
SAFEGUARDS,0.9022457067371202,"should describe how they avoided releasing unsafe images.
649"
SAFEGUARDS,0.9035667107001321,"• We recognize that providing effective safeguards is challenging, and many papers do
650"
SAFEGUARDS,0.904887714663144,"not require this, but we encourage authors to take this into account and make a best
651"
SAFEGUARDS,0.9062087186261559,"faith effort.
652"
LICENSES FOR EXISTING ASSETS,0.9075297225891678,"12. Licenses for existing assets
653"
LICENSES FOR EXISTING ASSETS,0.9088507265521797,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
654"
LICENSES FOR EXISTING ASSETS,0.9101717305151915,"the paper, properly credited and are the license and terms of use explicitly mentioned and
655"
LICENSES FOR EXISTING ASSETS,0.9114927344782034,"properly respected?
656"
LICENSES FOR EXISTING ASSETS,0.9128137384412153,"Answer: [Yes]
657"
LICENSES FOR EXISTING ASSETS,0.9141347424042272,"Justification: The data and code used in our work are all publicly available and open-source.
658"
LICENSES FOR EXISTING ASSETS,0.9154557463672391,"Guidelines:
659"
LICENSES FOR EXISTING ASSETS,0.916776750330251,"• The answer NA means that the paper does not use existing assets.
660"
LICENSES FOR EXISTING ASSETS,0.9180977542932629,"• The authors should cite the original paper that produced the code package or dataset.
661"
LICENSES FOR EXISTING ASSETS,0.9194187582562747,"• The authors should state which version of the asset is used and, if possible, include a
662"
LICENSES FOR EXISTING ASSETS,0.9207397622192867,"URL.
663"
LICENSES FOR EXISTING ASSETS,0.9220607661822986,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
664"
LICENSES FOR EXISTING ASSETS,0.9233817701453104,"• For scraped data from a particular source (e.g., website), the copyright and terms of
665"
LICENSES FOR EXISTING ASSETS,0.9247027741083224,"service of that source should be provided.
666"
LICENSES FOR EXISTING ASSETS,0.9260237780713342,"• If assets are released, the license, copyright information, and terms of use in the
667"
LICENSES FOR EXISTING ASSETS,0.9273447820343461,"package should be provided. For popular datasets, paperswithcode.com/datasets
668"
LICENSES FOR EXISTING ASSETS,0.9286657859973579,"has curated licenses for some datasets. Their licensing guide can help determine the
669"
LICENSES FOR EXISTING ASSETS,0.9299867899603699,"license of a dataset.
670"
LICENSES FOR EXISTING ASSETS,0.9313077939233818,"• For existing datasets that are re-packaged, both the original license and the license of
671"
LICENSES FOR EXISTING ASSETS,0.9326287978863936,"the derived asset (if it has changed) should be provided.
672"
LICENSES FOR EXISTING ASSETS,0.9339498018494056,"• If this information is not available online, the authors are encouraged to reach out to
673"
LICENSES FOR EXISTING ASSETS,0.9352708058124174,"the asset’s creators.
674"
NEW ASSETS,0.9365918097754293,"13. New Assets
675"
NEW ASSETS,0.9379128137384413,"Question: Are new assets introduced in the paper well documented and is the documentation
676"
NEW ASSETS,0.9392338177014531,"provided alongside the assets?
677"
NEW ASSETS,0.940554821664465,"Answer: [NA]
678"
NEW ASSETS,0.9418758256274768,"Justification: The paper currently does not include any new assets.
679"
NEW ASSETS,0.9431968295904888,"Guidelines:
680"
NEW ASSETS,0.9445178335535006,"• The answer NA means that the paper does not release new assets.
681"
NEW ASSETS,0.9458388375165125,"• Researchers should communicate the details of the dataset/code/model as part of their
682"
NEW ASSETS,0.9471598414795245,"submissions via structured templates. This includes details about training, license,
683"
NEW ASSETS,0.9484808454425363,"limitations, etc.
684"
NEW ASSETS,0.9498018494055482,"• The paper should discuss whether and how consent was obtained from people whose
685"
NEW ASSETS,0.9511228533685601,"asset is used.
686"
NEW ASSETS,0.952443857331572,"• At submission time, remember to anonymize your assets (if applicable). You can either
687"
NEW ASSETS,0.9537648612945839,"create an anonymized URL or include an anonymized zip file.
688"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9550858652575958,"14. Crowdsourcing and Research with Human Subjects
689"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9564068692206077,"Question: For crowdsourcing experiments and research with human subjects, does the paper
690"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9577278731836195,"include the full text of instructions given to participants and screenshots, if applicable, as
691"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9590488771466315,"well as details about compensation (if any)?
692"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9603698811096433,"Answer: [NA]
693"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9616908850726552,"Justification: The paper does not involve crowdsourcing nor research with human subjects.
694"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9630118890356671,"Guidelines:
695"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.964332892998679,"• The answer NA means that the paper does not involve crowdsourcing nor research with
696"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9656538969616909,"human subjects.
697"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9669749009247027,"• Including this information in the supplemental material is fine, but if the main contribu-
698"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9682959048877147,"tion of the paper involves human subjects, then as much detail as possible should be
699"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9696169088507266,"included in the main paper.
700"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9709379128137384,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
701"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9722589167767504,"or other labor should be paid at least the minimum wage in the country of the data
702"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9735799207397622,"collector.
703"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9749009247027741,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
704"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9762219286657859,"Subjects
705"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9775429326287979,"Question: Does the paper describe potential risks incurred by study participants, whether
706"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9788639365918098,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
707"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9801849405548216,"approvals (or an equivalent approval/review based on the requirements of your country or
708"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9815059445178336,"institution) were obtained?
709"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9828269484808454,"Answer: [NA]
710"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9841479524438573,"Justification: The paper does not involve crowdsourcing nor research with human subjects.
711"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9854689564068693,"Guidelines:
712"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9867899603698811,"• The answer NA means that the paper does not involve crowdsourcing nor research with
713"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.988110964332893,"human subjects.
714"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9894319682959049,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
715"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9907529722589168,"may be required for any human subjects research. If you obtained IRB approval, you
716"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9920739762219286,"should clearly state this in the paper.
717"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9933949801849405,"• We recognize that the procedures for this may vary significantly between institutions
718"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9947159841479525,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
719"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9960369881109643,"guidelines for their institution.
720"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9973579920739762,"• For initial submissions, do not include any information that would break anonymity (if
721"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9986789960369881,"applicable), such as the institution conducting the review.
722"
