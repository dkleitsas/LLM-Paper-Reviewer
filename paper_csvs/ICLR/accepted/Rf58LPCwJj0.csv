Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0013774104683195593,"Machine learning systems often experience a distribution shift between training
and testing. In this paper, we introduce a simple variational objective whose optima
are exactly the set of all representations on which risk minimizers are guaranteed to
be robust to any distribution shift that preserves the Bayes predictor, e.g., covariate
shifts. Our objective has two components. First, a representation must remain
discriminative for the task, i.e., some predictor must be able to simultaneously
minimize the source and target risk. Second, the representation’s marginal support
needs to be the same across source and target. We make this practical by designing
self-supervised objectives that only use unlabelled data and augmentations to train
robust representations. Our objectives give insights into the robustness of CLIP, and
further improve CLIP’s representations to achieve SOTA results on DomainBed."
INTRODUCTION,0.0027548209366391185,"1
INTRODUCTION"
INTRODUCTION,0.004132231404958678,"It is hard to build machine learning (ML) systems that are robust to distribution shifts between a
source (train) and target (test) domain. One promising approach to domain generalization (DG)
is learning robust representations from which predictors trained on source must perform well on
target. In practice, however, no current DG methods for learning representation uniformly outperform
empirical source-risk minimizers (ERM) (Gulrajani & Lopez-Paz, 2021). Furthermore, our theoretical
understanding of DG is still lacking. Speciﬁcally, while previous work have studied properties that
would or would not imply robust representations (Ben-David et al., 2007; 2010a; Zhao et al., 2019;
Johansson et al., 2019), the minimal set of achievable requirements for perfect DG is not yet known."
INTRODUCTION,0.005509641873278237,"We introduce the ﬁrst, simple, variational objective whose optima are exactly the set of all represen-
tations on which source risk minimizers are guaranteed to generalize across distribution shifts that
preserve the Bayes predictor. We work in an idealized DG (IDG) setting; we assume that a learner has
access to the source population risk. Our variational characterization implies that it is both sufﬁcient
and necessary for optimal IDG that a representation: (a) remains discriminative for the learning task,
i.e., there must exist predictors from the representation to the labels that can simultaneously minimize
both source and target risk; and (b) keeps the support of its marginal distribution invariant to shifts."
INTRODUCTION,0.006887052341597796,"This means that any optimal representation learning method must seek discriminative information
about the target. Even worse, we prove that without access to some knowledge about the target, any
representation learning algorithm cannot uniformly (over all target domains) outperform a constant
representation, which may explain why DG methods struggle to outperform ERM."
INTRODUCTION,0.008264462809917356,"We show, in theory and practice, how to overcome these challenges using only a large set of unlabeled
examples and particular data augmentations that retain all discriminative information but minimal
domain-speciﬁc information. Text descriptions of images are examples of such augmentations, as they
are informative for many downstream classiﬁcation tasks, but they remove a lot of domain-speciﬁc
information. With such augmentations, we design practical self-supervised learning (SSL) objectives
for learning robust representations. Our objectives give insights into the robustness of CLIP (Radford
et al., 2021) over other SSL methods, and lead to improved CLIP-based representations that achieve
state-of-the-art (SOTA) results on DomainBed (Gulrajani & Lopez-Paz, 2021). To summarize, we:"
INTRODUCTION,0.009641873278236915,"• provide minimal sufﬁcient objectives whose optima achieve optimal DG under covariate shift;
• prove that it is impossible to learn useful representations without accessing target information;
• provide practical objectives to learn optimally robust representations using speciﬁc augmentations;
• obtain SOTA results on typical domain generalization benchmarks.1"
INTRODUCTION,0.011019283746556474,"∗Authors contributed equally.
1Our implementation is released at https://github.com/ryoungj/optdom."
INTRODUCTION,0.012396694214876033,Published as a conference paper at ICLR 2022
INTRODUCTION,0.013774104683195593,"2
BACKGROUND: DOMAIN GENERALIZATION AND REPRESENTATIONS"
INTRODUCTION,0.015151515151515152,"We are interested in predictions that are robust across distribution shifts. We formalize this using
domain generalization (DG) language. Given a distribution pX,Y | ds over inputs x ∈X and labels
y ∈Y from the source domain ds ∈D, we select a predictor f : X →Γ. The predictions γ ∈Γ
could for example be labels or distributions over labels. Despite being selected on the source domain,
we would like f to achieve a small expected risk with respect to a loss function ℓ: Y × Γ →R≥0,"
INTRODUCTION,0.01652892561983471,"Rd
f [Y | X] := EpX,Y | d[ℓ(Y, f(X))] ,
(1)"
INTRODUCTION,0.01790633608815427,"on a distribution pX,Y | d from a target domain d = dt ∈D, which is somehow related to ds."
INTRODUCTION,0.01928374655647383,"A common strategy for DG is to learn robust representations, which splits the problem into two.
First, learn an encoder pZ | X, which maps inputs X to representations Z. Then, learn a predictor
h : Z →Γ from representations Z to labels Y using standard risk minimization. The goal is to
design a robust representation Z, so that predictors h trained to minimize the source risk Rds
h [Y | Z]
also achieve low target risk Rdt
h [Y | Z]. Many methods have been proposed to try to learn such Z,
e.g., by enforcing domain invariance of the marginal pZ | d (e.g., Ganin et al., 2016). Still, many of
these proposals are not sound (Zhao et al., 2019; Johansson et al., 2019). Furthermore, they rarely
outperform source empirical risk minimization (ERM) in practice (Gulrajani & Lopez-Paz, 2021)."
OPTIMAL REPRESENTATIONS FOR DOMAIN GENERALIZATION,0.02066115702479339,"3
OPTIMAL REPRESENTATIONS FOR DOMAIN GENERALIZATION"
OPTIMAL REPRESENTATIONS FOR DOMAIN GENERALIZATION,0.02203856749311295,"To separate domain generalization from ﬁnite sample generalization, we consider an idealized DG
(IDG), where the predictor h is selected on the source population risk rather than empirical risk. We
assume sample spaces X, Z, Y, D are discrete; formal statements and proofs are in Appxs. A and B."
DEFINING OPTIMAL REPRESENTATIONS FOR IDEALIZED DOMAIN GENERALIZATION,0.023415977961432508,"3.1
DEFINING OPTIMAL REPRESENTATIONS FOR IDEALIZED DOMAIN GENERALIZATION"
DEFINING OPTIMAL REPRESENTATIONS FOR IDEALIZED DOMAIN GENERALIZATION,0.024793388429752067,"We want to evaluate the quality of a representation Z of X. In our IDG, the learner is given a random
source Ds; she selects any source risk minimizer; and is scored according to her risk on a random
target domain Dt. To give uniform guarantees while reﬂecting the uncertainty over the source-target
pair (Ds, Dt), we measure the quality of Z as the expected risk of the learner’s worst-case choice."
DEFINING OPTIMAL REPRESENTATIONS FOR IDEALIZED DOMAIN GENERALIZATION,0.026170798898071626,"Deﬁnition. The idealized domain generalization risk (IDG risk) of an encoder pZ | X is the expected
(over domains) worst-case (over source risk minimizers) target risk, i.e.,"
DEFINING OPTIMAL REPRESENTATIONS FOR IDEALIZED DOMAIN GENERALIZATION,0.027548209366391185,"RIDG [Y | Z] := EpDs,Dt """
DEFINING OPTIMAL REPRESENTATIONS FOR IDEALIZED DOMAIN GENERALIZATION,0.028925619834710745,"sup
h∈H∗
Ds
RDt
h [Y | Z] # (2)"
DEFINING OPTIMAL REPRESENTATIONS FOR IDEALIZED DOMAIN GENERALIZATION,0.030303030303030304,"where H∗
Ds := arg minh RDs
h
[Y | Z] are the source risk minimizers, and pDs,Dt is any joint distribu-
tion that has full support over D × D. We call a representation Z∗(or its encoder) optimal for IDG if
it minimizes the IDG risk."
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT,0.03168044077134986,"3.2
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT"
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT,0.03305785123966942,"The IDG risk is useful to evaluate representations, but gives few insights into IDG and is impractical to
optimize due to the supremum in Eq. (2). Under mild assumptions, we provide a simpliﬁed, equivalent
objective, which is easier to optimize. For convenience, we assume that there is a unique Bayes pre-
dictor f ∗, which minimizes the expected risk over domains, i.e., f ∗= arg minf EpDt[RDt
f
[Y | X]].
This is satisﬁed by standard ML tasks pY,X and losses ℓ. More importantly, we assume the following
domain structure, which ensures the existence of optimal encoders and allows our simpliﬁcation."
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT,0.03443526170798898,Assumptions. All domains d ∈D we consider are related by the following assumptions:
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT,0.03581267217630854,"1. Generalized covariate shift. All domain-speciﬁc risk minimizers f ∈arg minf[Rd
f [Y | X]] are
equal to the Bayes predictor f ∗on their support, i.e., f(x) = f ∗(x) for all x ∈supp(pX | d)."
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT,0.0371900826446281,"2. Invariance of Bayes predictions. The set of Bayes predictions is the same for all domains, i.e.,

f ∗(x) | x ∈supp(pX | d)
	
={f ∗(x) | x ∈X}."
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT,0.03856749311294766,Published as a conference paper at ICLR 2022 h
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT,0.03994490358126722,"Y = 0
Y = 1"
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT,0.04132231404958678,source
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT,0.04269972451790634,target pZ|dt pZ|ds
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT,0.0440771349862259,"(a) discriminative & support match
(b) only support match
(c) only discriminative"
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT,0.045454545454545456,"Figure 1: (a) Optimal representations for IDG must have invariant supports while being simultaneously
discriminative on all domains: (b) without the discriminative requirement, a source-risk minimizer
can mispredict the target, and (c) without support match, some risk minimizer will perform poorly."
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT,0.046831955922865015,"Generalized covariate shift (GCS) ensures that f ∗is simultaneously optimal on all domains. For
log-loss ℓit recovers standard covariate shift, i.e., pY | x,d = pY | x. For other losses, GCS is weaker,
e.g., it only requires invariance of most likely labels for 0-1 loss, and of conditional expectations for
MSE. Invariance of Bayes predictors is necessary to learn useful predictors using a single domain.
For example, for 0-1 loss it ensures that each label is seen at least once in each domain."
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT,0.048209366391184574,"The intuition behind our objective is that under GCS any source risk minimizer will make optimal
predictions on target samples x that are also in the source. Thus, IDG optimal representations are
exactly those that (a) have the same support in Z for all domain, and (b) retain GCS from Z without
sacriﬁcing the ability to predict Y , which can be ensured by minimizing the risk from Z. See Fig. 1."
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT,0.049586776859504134,"Theorem 1. Under our assumptions, an encoder pZ∗| X is optimal for IDG if and only if it minimizes
the risk R [Y | Z] := infh EpDt

RDt
h [Y | Z]

while matching the support of Z across domains, i.e.,"
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT,0.05096418732782369,"pZ∗| X ∈arg min
pZ | X
R [Y | Z]
s.t.
∀d ∈D, supp(pZ | d) = supp(pZ)
(3)"
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT,0.05234159779614325,"Moreover, such encoders exist and their IDG risk is the Bayes risk RIDG [Y | Z∗] = R [Y | X]."
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT,0.05371900826446281,"Theorem 1 provides an objective to learn representations on which performing risk minimization
using a single domain and Z∗is as good as performing risk minimization on the target domain
from inputs X. Other sufﬁcient conditions have previously been hinted towards, e.g., matching
the marginal pZ | d instead of its support (e.g., Ben-David et al., 2010a) which is the focus of most
DG methods (e.g., Ganin et al., 2016). Note that previous conditions are nevertheless generally
not necessary and could be too stringent to be achievable. To our knowledge, Thm. 1 is the ﬁrst
characterization of necessary and sufﬁcient conditions, which gives better insights into the essential
goal for optimal IDG and provides a guide for deriving the least stringent objectives in practice."
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT,0.05509641873278237,"The risk minimization (Eq. (3)) shows that one must have some knowledge about the target domains
to learn optimal representations for IDG. Access to targets might seem unrealistic, but without such
knowledge or additional assumptions it is provably impossible to beat even constant representations."
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT,0.05647382920110193,"Proposition 1 (No free lunch for IDG). Let ds be any source domain, Zds be any representation
chosen on source ds, and C ∈Z be a constant representation. Under minor assumptions, for every
“good” target domain outside the source’s support on which Zds outperforms C for IDG, there are
many “bad” target domains on which Zds is strictly worse than C. Formal statement in Appx. B.3."
CHARACTERIZING OPTIMAL REPRESENTATIONS FOR IDG UNDER COVARIATE SHIFT,0.05785123966942149,"Proposition 1 shows that target knowledge is necessary for learning useful representations in IDG.
This may explain why previous DG methods have been unable to outperform ERM in standard
benchmarks (Gulrajani & Lopez-Paz, 2021): the knowledge they have access to is insufﬁcient to
generalize. Taken together, Prop. 1 and Thm. 1 say that either you have access to target domains dt,
in which case you can achieve an IDG risk that matches supervised learning, or you do not access dt,
in which case any representation learning algorithm can achieve worse IDG risk than a constant."
LEARNING REPRESENTATIONS UNDER COVARIATE SHIFT,0.05922865013774105,"4
LEARNING REPRESENTATIONS UNDER COVARIATE SHIFT"
SELF-SUPERVISED LEARNING USING DOMAIN-AGNOSTIC AUGMENTATIONS,0.06060606060606061,"4.1
SELF-SUPERVISED LEARNING USING DOMAIN-AGNOSTIC AUGMENTATIONS"
SELF-SUPERVISED LEARNING USING DOMAIN-AGNOSTIC AUGMENTATIONS,0.06198347107438017,"Our characterization of optimal representations for IDG (Thm. 1) requires labeled data from all
domains, which is impractical. We show how this can be overcome with self-supervised learning"
SELF-SUPERVISED LEARNING USING DOMAIN-AGNOSTIC AUGMENTATIONS,0.06336088154269973,Published as a conference paper at ICLR 2022
SELF-SUPERVISED LEARNING USING DOMAIN-AGNOSTIC AUGMENTATIONS,0.06473829201101929,"(a) standard augmentations
(b) supervised augmentations"
SELF-SUPERVISED LEARNING USING DOMAIN-AGNOSTIC AUGMENTATIONS,0.06611570247933884,"“A dog with ﬂoppy ears.” 
“A pointy-eared dog.”"
SELF-SUPERVISED LEARNING USING DOMAIN-AGNOSTIC AUGMENTATIONS,0.0674931129476584,(c) image-text augmentations
SELF-SUPERVISED LEARNING USING DOMAIN-AGNOSTIC AUGMENTATIONS,0.06887052341597796,"Figure 2: Image-text augmentations are practical domain-agnostic augmentations. Arrows denote
augmenters. Bubbles denote inputs that have the same representations, as induced by predicting the
augmentations. (a) Standard augmentations are not domain-agnostic. (b) Supervised augmentations
uniformly augment inputs inside their label class, irrespective of domains. (c) Image-text augmenta-
tions are (nearly) domain-agnostic as they map images across domains to similar descriptions."
SELF-SUPERVISED LEARNING USING DOMAIN-AGNOSTIC AUGMENTATIONS,0.07024793388429752,"(SSL), which is a technique for training representations without direct access to labels, and a particular
class of data augmentations. E.g, in CLIP, images are augmented with alt-text collected on the internet
and invariance is enforced between the representations of the image and its text pair (Radford et al.,
2021). Representations learned like this preserve discriminative information about all downstream
tasks Y whose label information is preserved by the augmentation (e.g., Dubois et al., 2021)."
SELF-SUPERVISED LEARNING USING DOMAIN-AGNOSTIC AUGMENTATIONS,0.07162534435261708,"More precisely, an augmentation A is a random variable sampled conditionally from the input X. The
key requirement is that augmentations retain task information. Speciﬁcally, if any samples x, x′ ∈X
have the same augmentation conditional pA | x = pA | x′, then their Bayes predictions must be the
same f ∗(x) = f ∗(x′). With such A, one can learn an encoder that minimizes the risk R [Y | Z] by
instead maximizing mutual information I[A; Z]. Intuitively, if Z has all augmentation information,
then it must have information about the conditional pA | X, and thus the Bayes prediction f ∗(X)."
SELF-SUPERVISED LEARNING USING DOMAIN-AGNOSTIC AUGMENTATIONS,0.07300275482093664,"This suggests learning optimal representations for IDG by replacing Eq. (3) with a maximiza-
tion of I[A; Z]. Unfortunately, fully optimizing I[A; Z] w.r.t. pZ | X is not generally possible un-
der the support constraint Eq. (3). This can be overcome under a domain-agnostic assumption,
which requires that the set of possible augmentation distributions is the same across domains, i.e.,

pA | x | x ∈supp(pX | d)
	
=

pA | x | x ∈X
	
."
SELF-SUPERVISED LEARNING USING DOMAIN-AGNOSTIC AUGMENTATIONS,0.0743801652892562,"Proposition 2. Let pA | X be a domain-agnostic augmenter. Then any optimal solution pZ∗| X of the
following objective is optimal for IDG:"
SELF-SUPERVISED LEARNING USING DOMAIN-AGNOSTIC AUGMENTATIONS,0.07575757575757576,"pZ∗| X ∈arg max
pZ | X
I[A; Z]
s.t.
∀d ∈D, supp(pZ | d) = supp(pZ)
(4)"
SELF-SUPERVISED LEARNING USING DOMAIN-AGNOSTIC AUGMENTATIONS,0.07713498622589532,"Proposition 2 shows that we can still learn IDG optimal representations without labels if we have
access to the right augmentations. How realistic are those augmentations? For 0-1 loss ℓ, the most
likely label should be preserved, which is satisﬁed by standard image augmentations like rotations
and color jittering. Those augmentations are nevertheless not domain-agnostic for typical domains
(e.g. sketches and photos), since outputs A are correlated with the input’s domain D. See Fig. 2a."
SELF-SUPERVISED LEARNING USING DOMAIN-AGNOSTIC AUGMENTATIONS,0.07851239669421488,"A practical choice of augmentation that is nearly domain-agnostic, is a mapping from images to
text descriptions, as with CLIP (Radford et al., 2021) which uses text-image pairs. Image-text
augmentations have many advantages. First, text augmentations preserve label information for many
downstream tasks. Second, they are close to being domain-agnostic, since images from different
domains (e.g., sketches and photos) but similar semantics are often mapped to similar descriptions.2
(Fig. 2c). This gives insights into the open question (Radford et al., 2021) about why CLIP’s
representations are so robust compared to other SSL methods. Finally, image-text pairs are easy to
access in practice given their abundance on the internet. Many other multi-modal augmentations, e.g.,
audio-video (Wang et al., 2021), are also likely domain-agnostic and can be explored in practice."
SELF-SUPERVISED LEARNING USING DOMAIN-AGNOSTIC AUGMENTATIONS,0.07988980716253444,"In practice, even the domain information D is usually unknown. One can nevertheless still optimize
(Eq. (4)) by replace the support constraint with a stronger one that does not rely on D e.g., minimizing
I[Z; X] (see Sec. 4.2.2), . This highlights the potential of Prop. 2: if one can ﬁnd a large source of
inputs X and domain-agnostic augmentations A (e.g., the 400M image-text pairs of CLIP) then one
can, in principle, learn optimal representations for IDG on any downstream task Y that A preserves."
SELF-SUPERVISED LEARNING USING DOMAIN-AGNOSTIC AUGMENTATIONS,0.081267217630854,"2Although text descriptions might contain domain information (e.g., referring to “sketch”), they are still
much better than standard augmentations that rarely map together images from different domains."
SELF-SUPERVISED LEARNING USING DOMAIN-AGNOSTIC AUGMENTATIONS,0.08264462809917356,Published as a conference paper at ICLR 2022
PRACTICAL OBJECTIVES,0.08402203856749312,"4.2
PRACTICAL OBJECTIVES"
PRACTICAL OBJECTIVES,0.08539944903581267,"We now design practical objectives for learning optimal representations without labels. Proposition 2
does provide an objective but it is impractical as it involves constrained optimization. We can
nevertheless convert it to the following unconstrained objective by using a Lagrangian relaxation and
introducing a domain bottleneck B[Z, D] that enforces support match,
arg min
pZ | X
−I[A; Z] + λ B[Z, D] ,
(5)"
PRACTICAL OBJECTIVES,0.08677685950413223,"Eq. (5) is a valid reformulation of Prop. 2 as long as minimizing B[Z, D] while maximizing I[A; Z]
enforces the support constraint in Eq. (4). Below, we provide different choices of such B[Z, D]
each of which results in a different SSL objective. In practice, however, terms in Eq. (5) are hard to
estimate from ﬁnite samples. We now discuss two variational bounds that can be efﬁciently estimated
and optimized with stochastic gradient descent (Bottou, 2010). For simplicity, we use a deterministic
encoder eϕ : X →Z for the rest of the paper. Detailed derivations are in Appx. C."
PRACTICAL OBJECTIVES,0.0881542699724518,"For both practical objectives we use a contrastive variational lower bound on I[A; Z] based on
InfoNCE (Oord et al., 2018), which is standard in SSL. Speciﬁcally, for a sample X, we ﬁrst obtain
the augmented ‘positive’ A by sampling from pA | X. We then obtain n augmented ‘negatives’

A−
i
	n
i=1 i.i.d. from the marginal pA by ﬁrst independently sampling X :=

X−
i
	n
i=1 from pX and
then sampling A−
i from pA | X−
i . We denote A :=

A, A−
1 , . . . , A−
n
	
. InfoNCE then uses a critic sψ
to score how likely each A′ ∈A is to be positive, resulting in the following variational bound,"
PRACTICAL OBJECTIVES,0.08953168044077135,"I[A; Z] ≥log(n + 1) + EpA,X,Z"
PRACTICAL OBJECTIVES,0.09090909090909091,"
log
exp sψ(A, Z)
P"
PRACTICAL OBJECTIVES,0.09228650137741047,"A′∈A exp sψ(A′, Z)"
PRACTICAL OBJECTIVES,0.09366391184573003,"
.
(6)"
PRACTICAL OBJECTIVES,0.09504132231404959,"When A = X, one can tie the parameters of the critic and the encoder by passing augmentations
through the encoder and taking an inner product, i.e., sψ(A, Z) := eϕ(A)T Z."
PRACTICAL OBJECTIVES,0.09641873278236915,"Many previous DG regularizers (e.g., Ganin et al., 2016; Li et al., 2018b;a) could be valid domain
bottlenecks. In the following, we discuss two possible B[Z, D] , the ﬁrst of which is novel."
PRACTICAL OBJECTIVES,0.09779614325068871,"4.2.1
CONTRASTIVE ADVERSARIAL DOMAIN BOTTLENECK (CAD)"
PRACTICAL OBJECTIVES,0.09917355371900827,Algorithm 1 CAD objective
PRACTICAL OBJECTIVES,0.10055096418732783,"Require: eϕ, sψ, D, X, n"
PRACTICAL OBJECTIVES,0.10192837465564739,"1: Z ←eϕ(X)
2: A ←sample(pA | X) 3:"
PRACTICAL OBJECTIVES,0.10330578512396695,"
(D−
i , X−
i , A−
i )
	n
i=1
i.i.d.
←−−sample(pD,X,A)
4: X, A ←

X−
i
	n
i=1,{A} ∪

A−
i
	n
i=1
5: X¬D ←

X−
i | D−
i ̸= D, i ∈[n]"
PRACTICAL OBJECTIVES,0.1046831955922865,"6: Laug ←−log
exp sψ(A,Z)
P
A′∈A exp sψ(A′,Z)
▷−I[A; Z]"
PRACTICAL OBJECTIVES,0.10606060606060606,7: Lsupp ←−log
PRACTICAL OBJECTIVES,0.10743801652892562,"P
X′∈X¬D exp eϕ(X′)T Z
P
X′′∈X exp eϕ(X′′)T Z
▷I[Z; D]"
PRACTICAL OBJECTIVES,0.10881542699724518,8: return LCAD = Laug + λLsupp
PRACTICAL OBJECTIVES,0.11019283746556474,"Our ﬁrst domain bottleneck minimizes B[Z, D] =
I[Z; D], which enforces support match using a KL
divergence. Dropping constants w.r.t. Z we thus
aim to maximize H[D | Z]. Domain-adversarial
neural network (DANN, Ganin et al., 2016) does
so by ensuring that a domain classiﬁer qφ cannot
predict domains from representations, i.e., it max-
imizes EpD,Z[−log qφ(D | Z)] ≥H[D | Z] w.r.t.
encoder parameter ϕ but minimizes it w.r.t. φ.
However, DANN suffers from two issues: (i) it
maximizes an upper bound on the desired term;
(ii) it requires adversarial training, which is chal-
lenging in practice."
PRACTICAL OBJECTIVES,0.1115702479338843,"To overcome these issues, we construct q(D | Z) without introducing additional parameters and with
a bound that is tight with enough samples. In short, using the equality pD | Z = EpX | Z

pD | X

, we
set our variational distribution to q(D | Z) = Eqϕ,X[ˆp(D | X)], where qϕ,X(X | Z) is a contrastive
variational distribution of pX | Z constructed with samples X and a critic eϕ(X)T Z tied with the
encoder, ˆp is a count estimate of pD | X. Detailed derivations and explanations are in Appx. C.3. The
resulting contrastive adversarial domain (CAD) objective is in Algorithm 1. First, sample domains
D :={D
−
i }n
i=1 for each X′ ∈X. Then collect inputs associated with a different domain from the
current domain D, i.e., X¬D :={X
−
i | D
−
i ̸= D, i ∈[n]}. Ignoring constants, the ﬁnal loss is"
PRACTICAL OBJECTIVES,0.11294765840220386,"LCAD(ϕ, ψ) := EpD,X,A,Z """
PRACTICAL OBJECTIVES,0.11432506887052342,"−log
exp sψ(A, Z)
P"
PRACTICAL OBJECTIVES,0.11570247933884298,"A′∈A exp sψ(A′, Z) −λ log X"
PRACTICAL OBJECTIVES,0.11707988980716254,"X′∈X¬D
qϕ,X(X′ | Z) !# .
(7)"
PRACTICAL OBJECTIVES,0.1184573002754821,"In Appx. C.4, we also derive a conditional variation of CAD that minimizes I[Z; D | Y ], which can
be used when labels are available and supervised augmentations are used."
PRACTICAL OBJECTIVES,0.11983471074380166,Published as a conference paper at ICLR 2022
PRACTICAL OBJECTIVES,0.12121212121212122,"4.2.2
ENTROPY BOTTLENECK (ENT)"
PRACTICAL OBJECTIVES,0.12258953168044077,"Our second domain bottleneck is the entropy bottleneck (Ent) that minimizes H[Z] = I[Z; X] ≥
I[Z; D], where the ﬁrst equality uses the encoder’s determinism. Ent enforces support match by
removing all information that is not needed to maximize I[Z; A]. In particular, minimizing I[Z; X] is
more stringent than I[Z; D], as it also matches the representations inside a domain. The advantage of
Ent is that it does not require domain samples D, which are rarely accessible in SSL. We consider
the standard variational bound used in neural compression (Ballé et al., 2016; Theis et al., 2017),
H[Z] ≤EpZ[−log qθ(Z)], where an entropy model qθ(Z) is used. This leads to"
PRACTICAL OBJECTIVES,0.12396694214876033,"LEnt(ψ, ϕ, θ) := EpX,A,Z"
PRACTICAL OBJECTIVES,0.12534435261707988,"
−log
exp sψ(A, Z)
P
A′∈A exp sψ(A′, Z) −λ log qθ(Z)

.
(8)"
RELATED WORK,0.12672176308539945,"5
RELATED WORK"
RELATED WORK,0.128099173553719,"Provably robust representations under covariate shift. Previous work mostly focuses on domain
generalization bounds for robust representations. Ben-David et al. (2007; 2010a) bound the target
risk using the source risk, a divergence between source and target distributions, and the joint optimal
risk over source and target domains. Mansour et al. (2009) generalizes these results from 0-1 loss to
more general losses. Johansson et al. (2019) takes this further by deriving a support-based bound.
In our setting, these bounds only hint towards a sufﬁcient condition for optimality, i.e., matching
the marginal pZ | d or its support while minimizing R [Y | Z]. However, these bounds can often be
loose and the implied sufﬁcient conditions are neither necessary nor generally achievable. Ben-David
et al. (2010b) suggests that separately minimizing R [Y | Z] or matching the marginal is not sufﬁcient,
while Zhao et al. (2019) also proves minimizing only the source risk Rds [Y | Z] is not sufﬁcient; but
none of them proves the desired necessary condition. Our work distinguishes from previous work on
three key aspects: (i) we are the ﬁrst to study and formalize optimally robust representations, and
provide the achievable sufﬁcient and necessary conditions; (ii) we prove that one can practically
learn optimal Z∗with SSL using domain-agnostic augmentations; (iii) we consider a more general
framework with any standard losses and a less stringent generalized covariate shift assumption, Still,
our work is more speciﬁc than others, as we consider idealized DG and unrestricted predictors H."
RELATED WORK,0.12947658402203857,"Practical objectives for DG. The most popular DG methods aim to learn domain-invariant represen-
tation by minimizing various divergernces between the marginal distributions pZ | d and pZ (Long
et al., 2015; Ganin et al., 2016; Sun & Saenko, 2016; Long et al., 2017; Li et al., 2018a; Shen et al.,
2018; Nguyen et al., 2021). Others propose matching the conditional pZ | y,d across domains instead
(Gong et al., 2016; Li et al., 2018b; Tachet des Combes et al., 2020). These regularizers would all be
valid domain bottlenecks B[Z, D] . Another line of work aims at learning Z with invariant predictors
pY | z,d across domains (e.g., Arjovsky et al., 2019; Krueger et al., 2021; Li et al., 2021). However,
none of these methods outperform ERM with fair model selections (Gulrajani & Lopez-Paz, 2021)."
EXPERIMENTS,0.13085399449035812,"6
EXPERIMENTS"
EXPERIMENTS,0.1322314049586777,"In our experiments, we aimed to: (i) verify our theoretical results in practice; (ii) investigate our
proposed representation learning objectives in practical DG; (iii) take advantage of pretrained SSL
models (in particular, CLIP) to achieve powerful models for DG. Unless stated otherwise, we consider
a two-stage training setup. First, the representation learner (“the representor”) trains an encoder pZ | X
using a speciﬁed objective and freezes it. Then, the person performing predictions (“the learner”)
trains her predictor h from Z by minimizing the risk on source data. Finally, the representation Z
and predictor h are evaluated on target data. In all experiments, the learner uses a linear classiﬁer
for h. For the Ent bottleneck, we used Ballé et al.’s (2018) entropy model. For the CAD bottleneck
we used its conditional version whenever labels were available. When a model contains no domain
bottleneck, we label it as “Base”. For experimental details and additional results see Appxs. E and F."
EXPERIMENTS,0.13360881542699724,"6.1
SCIENTIFIC SETTING: EXPLORING OPTIMAL REPRESENTATIONS FOR WORST-CASE DG"
EXPERIMENTS,0.1349862258953168,"To validate our theory, we studied optimal representations in a scientiﬁc setup that is as close to our
IDG framework as possible with log-loss ℓ. In particular, we used the PACS dataset (Li et al., 2017)"
EXPERIMENTS,0.13636363636363635,Published as a conference paper at ICLR 2022
EXPERIMENTS,0.13774104683195593,"Base
Ent
CAD"
EXPERIMENTS,0.13911845730027547,R[Y |Z]
EXPERIMENTS,0.14049586776859505,H[A|Z]
EXPERIMENTS,0.1418732782369146,"-5.1±0.3
-0.4±0.1
-0.7±0.1"
EXPERIMENTS,0.14325068870523416,"-3.5±0.1
-0.0±0.0
-0.8±0.2"
EXPERIMENTS,0.1446280991735537,(a) Effect of different objectives
EXPERIMENTS,0.14600550964187328,"10
2
100
102
104
6 4 2 0"
EXPERIMENTS,0.14738292011019283,Log likelihood
EXPERIMENTS,0.1487603305785124,"source
target"
EXPERIMENTS,0.15013774104683195,(b) Effect of λ
EXPERIMENTS,0.15151515151515152,"DA
Approx.
Non-DA
Augmentation type -10 -8 -6 -4 -2 0"
EXPERIMENTS,0.15289256198347106,Log likelihood
EXPERIMENTS,0.15426997245179064,"Supervised
SingleDom
ApproxDA
IntraDom
Standard"
EXPERIMENTS,0.15564738292011018,(c) Effect of augmentations
EXPERIMENTS,0.15702479338842976,"Figure 3: (a) Adding bottlenecks signiﬁcantly improves the worst-case DG performance and using
domain-agnostic (DA) augmentations (H[A | Z]) performs as well as with labels (R [Y | Z]). (b) In-
creasing the domain bottleneck weight λ will improve target performance until it decreases source
performance. (c) DA augmentations are crucial but approx. DA aug. might be also be sufﬁcient."
EXPERIMENTS,0.1584022038567493,"and approximated the idealized DG by treating the dataset as the population distribution, i.e., we
did not split datasets into train and test sets. To approximate the worst-case source predictor, we
followed Dubois et al. (2020) by incorporating the wrongly labeled target data to the source domain.
The experimental setup goes as follows: (i) the representor trains a ResNet-18 (He et al., 2016) to
minimize the objective on labeled data from all domains; (ii) the learner trains a worst-case source
classiﬁer h on every possible pair of (source, target); (iii) the negative target risk (log likelihood)
for each h is evaluated. We reported the log likelihood averaged over 5 seeds. For more realistic
scenarios (i.e. non-idealized average-case DG) see Appx. F.2 which replicates the following results."
EXPERIMENTS,0.15977961432506887,"Do our domain bottlenecks improve worst-case DG?
In Fig. 3a, we compare IDG performance
of representations trained with (Ent, CAD) and without (Base) domain bottlenecks. We see that
both bottlenecks signiﬁcantly improve the worst-case DG, and nearly achieve the source-domain
performance (0 log likelihood). This shows the importance of support match (Thm. 2) and the
effectiveness of our bottlenecks to enforce it. In Appx. F.2, we show that bottlenecks also helps in
practical scenarios, i.e., non-idealized average-case DG evaluated with accuracy (95.9% →96.7%)."
EXPERIMENTS,0.16115702479338842,"What is the effect of λ?
Fig. 3b shows the effect of the bottleneck weight λ on the worst-case
target and source performance. We see that increasing λ will decrease the DG gap. As a result the
target performance improves until λ ≈102, where source performance starts to decrease."
EXPERIMENTS,0.162534435261708,"What if the representor has access to domain-agnostic augmentations instead of labels?
In
Sec. 4.2, we provide a contrastive objective for using augmentations. To show the effectiveness of the
objective, we compared minimizing H[A | Z] using Eq. (6) to standard supervised risk minimization
R [Y | Z] and used the domain-agnostic supervised augmentations (Fig. 2b). The 1st and 2nd row of
Fig. 3a show that our objective performs similarly to direct label prediction."
EXPERIMENTS,0.16391184573002754,"How important is the choice of augmentations?
Prop. 2 shows that domain-agnostic (DA) aug-
mentations are sufﬁcient for achieving IDG, but it does not give necessary conditions. Here we
investigate the effect of using our loss with different choices of augmentations. Speciﬁcally, we used
LCAD with ﬁve augmentations. The ﬁrst two are DA. ‘Supervised’: augment inputs inside the label
class across all domains as in Fig. 2b; ‘SingleDom’: augment inputs to same label samples from a
ﬁxed domain. The second two are not DA. ‘Standard’: standard SSL augmentations (Chen et al.,
2020) as in Fig. 2a; ‘IntraDom’: augment inputs to same label and same domain samples. Finally, we
consider ‘ApproxDA’, which is approximately DA by augmenting 10% of the time with ‘Supervised‘
and 90% of the time with ‘IntraDom‘. Fig. 3c shows that the non-DA augmentations give terrible
results compared to DA. Interestingly, ‘ApproxDA’ also performs very well, which suggests that
approximately DA augmentations might be sufﬁcient to learn optimal representations in practice."
EXPERIMENTS,0.1652892561983471,"What if the representor does not have access to target domains?
Prop. 1 shows that DG without
access to target domains is generally impossible. We empirically veriﬁed this by excluding a
predeﬁned target dt domain from the representor’s training set, i.e., LCAD is optimized on 3 of the 4
domains. The learner then trains a predictor h on each source. We ﬁnally evaluate each h on the target
domain dt, and average over choices of dt. The resulting worst-case log likelihood was −4.2 ± 0.2,
which is signiﬁcantly worse than when the representor had access to all domains (−0.8 ± 0.2)."
EXPERIMENTS,0.16666666666666666,Published as a conference paper at ICLR 2022
APPROXIMATING OPTIMAL REPRESENTATIONS BY EXPLOITING PRETRAINED SSL,0.16804407713498623,"6.2
APPROXIMATING OPTIMAL REPRESENTATIONS BY EXPLOITING PRETRAINED SSL"
APPROXIMATING OPTIMAL REPRESENTATIONS BY EXPLOITING PRETRAINED SSL,0.16942148760330578,"As discussed in Sec. 4.1, one can learn optimal representations for IDG by performing SSL with
a domain bottleneck on a large sample of inputs X and domain-agnostic augmentations A. This
is nearly how CLIP was pretrained (SSL with 400M image-text pairs) except it did not include a
domain bottleneck. In this section, we investigate how to take advantage of CLIP to approximate
optimal representations for IDG. We did so in two simple steps. First, we froze the pretrained CLIP
and added a multi-layer perceptron (MLP) that could effectively ﬁnetune CLIP’s representations.
Then, we trained the MLP by minimizing our CAD bottleneck and R [Y | Z] on the available data."
APPROXIMATING OPTIMAL REPRESENTATIONS BY EXPLOITING PRETRAINED SSL,0.17079889807162535,"In all experiments, we used the standard DomainBed benchmark (with non-MNIST datasets) and
protocol (Gulrajani & Lopez-Paz, 2021). In particular, we left out a target domain for evaluation
and used the union of other domains for training both the encoder and the classiﬁer. Contrary to our
scientiﬁc setting, the representor does not get access to the target domain. All our representations
were evaluated by ﬁtting a linear classiﬁer on source domains with source validation selection. As
in DomainBed we selected the encoder based on ‘oracle selection’ over 10 hyperparameters, and
reported the target accuracy averaged over all choices of targets and 5 random seeds with standard
errors. Note that using ‘oracle selection’ is more consistent with our theory since it gets access to the
necessary target information (for model selection), as discussed in Appx. F.3. Due to space limit,
we only included as baselines ‘ERM’ and ‘DomainBed SOTA’ which for each dataset is the best
result over all baselines. The extended results and baselines are in Table 4. Details in Appx. E.3. We
investigated two pretrained CLIP models with different number of parameters. The larger ViT-B/32
denoted ‘CLIP L’ and the smaller ResNet-50 denoted ‘CLIP S’."
APPROXIMATING OPTIMAL REPRESENTATIONS BY EXPLOITING PRETRAINED SSL,0.1721763085399449,"Table 1: CLIP signiﬁcantly outperforms the previous SOTA result on DomainBed, as supported
by our theoretical analysis. Finetuning CLIP with our CAD bottleneck consistently improves the
robustness of its representations and achieves SOTA performance."
APPROXIMATING OPTIMAL REPRESENTATIONS BY EXPLOITING PRETRAINED SSL,0.17355371900826447,"Algorithm
VLCS
PACS
OfﬁceHome
TerraIncognita
DomainNet"
APPROXIMATING OPTIMAL REPRESENTATIONS BY EXPLOITING PRETRAINED SSL,0.174931129476584,"ERM
77.6 ± 0.3
86.7 ± 0.3
66.4 ± 0.5
53.0 ± 0.3
41.3 ± 0.1
DomainBed SOTA
79.9 ± 0.2
87.2 ± 0.1
68.4 ± 0.2
54.4 ± 0.3
41.8 ± 0.1"
APPROXIMATING OPTIMAL REPRESENTATIONS BY EXPLOITING PRETRAINED SSL,0.1763085399449036,"DINO + CAD
69.6 ± 0.6
76.1 ± 0.1
56.9 ± 0.5
25.9 ± 1.2
33.6 ± 0.1"
APPROXIMATING OPTIMAL REPRESENTATIONS BY EXPLOITING PRETRAINED SSL,0.17768595041322313,"CLIP S
81.1 ± 0.5
90.3 ± 0.2
70.6 ± 0.1
29.6 ± 0.8
47.7 ± 0.0
CLIP S + Base
81.3 ± 0.5
91.2 ± 0.3
70.6 ± 0.1
36.4 ± 0.7
46.8 ± 0.2
CLIP S + CAD
82.3 ± 0.3
92.0 ± 0.2
71.9 ± 0.2
36.2 ± 0.8
48.8 ± 0.1"
APPROXIMATING OPTIMAL REPRESENTATIONS BY EXPLOITING PRETRAINED SSL,0.1790633608815427,"CLIP L
80.7 ± 0.4
93.7 ± 0.8
79.6 ± 0.1
36.9 ± 0.6
52.8 ± 0.1
CLIP L + CAD
81.6 ± 0.1
94.9 ± 0.3
80.0 ± 0.2
40.6 ± 1.1
53.7 ± 0.1"
APPROXIMATING OPTIMAL REPRESENTATIONS BY EXPLOITING PRETRAINED SSL,0.18044077134986225,"Approx. Optimal Z∗
86.8 ± 0.6
97.2 ± 0.6
86.3 ± 1.6
76.5 ± 4.1
66.7 ± 0.2"
APPROXIMATING OPTIMAL REPRESENTATIONS BY EXPLOITING PRETRAINED SSL,0.18181818181818182,"Can we approximate optimal representations by exploiting pretrained CLIP?
The row ‘CLIP
L + CAD’ in Table 1 shows that ﬁnetuning a large pretrained CLIP model with our CAD achieves
SOTA on nearly all DomainBed benchmarks by a very large margin (see 2nd row). Note that the
poor performance on TerraIncognita is likely because CLIP’s dataset does not cover such images
(camera traps monitoring animals). The last row essentially shows an optimal representation, which
we approximate by ﬁnetuning CLIP L with our CAD on all domains including the target. The gap
between CLIP L + CAD and the upper-bound suggests that one can still learn better representations.
We hypothesize that end-to-end training of our objective would greatly shrink this gap."
APPROXIMATING OPTIMAL REPRESENTATIONS BY EXPLOITING PRETRAINED SSL,0.18319559228650137,"Are gains due to the architectural differences?
DomainBed’s baselines ﬁnetuned an ImageNet
pretrained ResNet-50. In contrast, CLIP L pretrained a larger ViT. To decouple gains due to our
objective from architectural gains, we evaluated ResNet-50 pretrained CLIP S. Table 1 shows that
CLIP S + CAD still signiﬁcantly outperforms DomainBed baselines. Note that our theory does not
constrain the encoder and so we expect larger encoders to be better as seen in Table 1."
APPROXIMATING OPTIMAL REPRESENTATIONS BY EXPLOITING PRETRAINED SSL,0.18457300275482094,"What is the effect of domain bottlenecks?
In the “CLIP” rows of Table 1, we investigated the
effect of ﬁnetuning CLIP with our CAD bottleneck. We see that for both CLIP L and CLIP S, it
consistently improves results by around 1 ∼2%. These gains are due to the bottleneck, rather than
ﬁnetuning on source data as seen by ‘CLIP S + Base’. We believe the gains could potentially be much
larger if CLIP was trained end-to-end with our bottleneck. Note that raw CLIP S already signiﬁcantly"
APPROXIMATING OPTIMAL REPRESENTATIONS BY EXPLOITING PRETRAINED SSL,0.1859504132231405,Published as a conference paper at ICLR 2022
APPROXIMATING OPTIMAL REPRESENTATIONS BY EXPLOITING PRETRAINED SSL,0.18732782369146006,"outperforms baselines. We hypothesize that this is because SGD acts as an information bottleneck
that naturally favors support match (Shwartz-Ziv & Tishby, 2017)."
APPROXIMATING OPTIMAL REPRESENTATIONS BY EXPLOITING PRETRAINED SSL,0.1887052341597796,"Which pretrained SSL model to use?
Our theory suggests that we can exploit pretrained SSL
models as long as their augmentations are domain-agnostic and their training set covers desired
domains. We investigated adaption of SSL models that do not satisfy those properties by ﬁnetuning
DINO (Caron et al., 2021), the current SOTA on SSL ImageNet. DINO is pretraiend using standard
augmentations. As a result, Table 1 shows that the ﬁnetuned DINO + CAD signiﬁcantly underper-
forms compared to CLIP S and DomainBed baselines. This supports our hypothesis that CLIP is
much more robust than other SSL methods due to its domain-agnostic augmentations."
TOWARDS GENERIC ROBUST REPRESENTATIONS WITH SSL,0.19008264462809918,"6.3
TOWARDS GENERIC ROBUST REPRESENTATIONS WITH SSL"
TOWARDS GENERIC ROBUST REPRESENTATIONS WITH SSL,0.19146005509641872,"In the previous section, we ﬁnetuned CLIP in a task speciﬁc fashion by optimizing R [Y | Z] and our
CAD bottleneck. To get generic (task agnostic) robust representations, one should instead directly
use our objectives on a sufﬁciently large dataset with image-text augmentations. Unfortunately, we
cannot fully train CLIP with our bottlenecks as we do not have access to CLIP’s original dataset and
sufﬁcient compute. In this section, we aim to emulate such training of generic robust representations."
TOWARDS GENERIC ROBUST REPRESENTATIONS WITH SSL,0.1928374655647383,"To do so we used LAION-400M (Schuhmann et al., 2021) that is a public dataset that contains 400M
web-crawled image-text pairs. Due to our computational budget, we again froze the pretrained CLIP
L and only ﬁnetuned an additional MLP with our LEnt. We used LEnt as it only requires access to paired
image X and text A but no prior information about domain D. As in CLIP’s paper, we evaluated the
learned representation Z in Taori et al.’s (2020) realistic setting, where a linear classiﬁer h from Z is
trained on ImageNet and tested on 7 natural distribution shift datasets. Details in Appx. E.4."
TOWARDS GENERIC ROBUST REPRESENTATIONS WITH SSL,0.19421487603305784,"Would training CLIP with a bottleneck have improved its robustness?
As shown in the last
2 rows of Table 2, ﬁnetuning CLIP L on LAION with LEnt (Tuned w/ Ent) outperforms ﬁnetuning
without bottleneck (Tuned w/o Ent) on all 7 distribution shift datasets. This suggests that directly
training CLIP with our Ent bottleneck would improve the robustness of learned representations. We
hypothesize that the gains could be larger if SSL models trained LEnt end-to-end. In Appx. F.4, we
show similar results on DomainBed. Note that both models underperform the original CLIP L, likely
due to non-end-to-end training and LAION data with (possibly) lower quality than CLIP’s data."
TOWARDS GENERIC ROBUST REPRESENTATIONS WITH SSL,0.19559228650137742,"Table 2: Finetuning CLIP L on LAION with an entropy bottleneck improves its robustness compared
to ﬁnetuning without on 7 distribution shift datasets. The pretrained CLIP L is still better likely due
to end-to-end training with higher quality data. IN denotes ImageNet."
TOWARDS GENERIC ROBUST REPRESENTATIONS WITH SSL,0.19696969696969696,"IN
IN-V2
IN-S
YT-BB
IN-Vid
ObjectNet
IN-A
IN-R
Avg."
TOWARDS GENERIC ROBUST REPRESENTATIONS WITH SSL,0.19834710743801653,"CLIP L
75.2
64.2
41.0
58.4
71.6
42.8
27.5
62.9
52.6"
TOWARDS GENERIC ROBUST REPRESENTATIONS WITH SSL,0.19972451790633608,"Tuned w/o Ent
73.8
62.1
37.0
56.9
68.8
41.3
26.0
58.1
50.0
Tuned w/ Ent
74.2
62.7
38.9
58.1
70.1
42.1
26.2
60.8
51.3"
CONCLUSION,0.20110192837465565,"7
CONCLUSION"
CONCLUSION,0.2024793388429752,"We gave a simple variational characterization of all representations on which source-risk minimizers
are guaranteed to generalize to target domains that preserve the Bayes predictor. Similar to previous
work, our theory strongly implies the need for target information when learning representations for
domain generalization. Nevertheless, we identiﬁed a domain-agnostic property of data augmentations
that make it possible to learn optimal representations from unlabelled data. Thus, we showed that it is
possible to learn robust representations using only large sources of inputs X and augmentations A."
CONCLUSION,0.20385674931129477,"There are caveats that need to be addressed in future work. First, we studied an idealized DG,
which assumes access to the population distributions. This gives insights into the challenges that are
speciﬁc to DG, rather than ﬁnite sample challenges faced throughout ML. Second, we considered risk
minimizers from an unconstrained hypothesis class. The support constraint can likely be weakened,
if the hypothesis class is constrained. Finally, we focus only on optimal representations, but it would
be interesting to characterize approximately optimal representations. Nevertheless, in this idealized
setting, our characterization is a springboard from which all future objectives can be derived, and, in
general, it brings us closer to the goal of robust machine learning systems."
CONCLUSION,0.20523415977961432,Published as a conference paper at ICLR 2022
CONCLUSION,0.2066115702479339,"Acknowledgement
We would like to thank Elliot Creager, Roger Grosse, Elan Rosenfeld, Guodong
Zhang, Han Zhao, and anonymous reviewers for their helpful feedbacks and encouragements. Re-
sources used in preparing this research were provided, in part, by the Province of Ontario, the
Government of Canada through CIFAR, and companies sponsoring the Vector Institute. We acknowl-
edge the support of the Natural Sciences and Engineering Research Council of Canada (NSERC),
RGPIN-2021-03445."
CONCLUSION,0.20798898071625344,"Reproducibility
For our theoretical results, we include formal assumptions, statements, and proofs
in Appxs. A and B. We include the detailed derivations of our algorithms in Appx. C. For our
experiments, we include experimental details for reproducing our results in Appx. E and have
released our code at https://github.com/ryoungj/optdom."
REFERENCES,0.209366391184573,REFERENCES
REFERENCES,0.21074380165289255,"Alexander A Alemi, Ian Fischer, Joshua V Dillon, and Kevin Murphy. Deep variational information
bottleneck. arXiv preprint arXiv:1612.00410, 2016."
REFERENCES,0.21212121212121213,"Martin Arjovsky, Léon Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization.
arXiv preprint arXiv:1907.02893, 2019."
REFERENCES,0.21349862258953167,"Johannes Ballé, Valero Laparra, and Eero P Simoncelli. End-to-end optimized image compression.
arXiv preprint arXiv:1611.01704, 2016."
REFERENCES,0.21487603305785125,"Johannes Ballé, David Minnen, Saurabh Singh, Sung Jin Hwang, and Nick Johnston. Variational
image compression with a scale hyperprior. arXiv preprint arXiv:1802.01436, 2018."
REFERENCES,0.2162534435261708,"Andrei Barbu, David Mayo, Julian Alverio, William Luo, Christopher Wang, Danny Gutfreund,
Joshua Tenenbaum, and Boris Katz. Objectnet: A large-scale bias-controlled dataset for pushing
the limits of object recognition models. 2019."
REFERENCES,0.21763085399449036,"Sara Beery, Grant Van Horn, and Pietro Perona. Recognition in terra incognita. In Proceedings of the
European conference on computer vision (ECCV), pp. 456–473, 2018."
REFERENCES,0.2190082644628099,"Shai Ben-David, John Blitzer, Koby Crammer, Fernando Pereira, et al. Analysis of representations
for domain adaptation. Advances in neural information processing systems, 19:137, 2007."
REFERENCES,0.22038567493112948,"Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman
Vaughan. A theory of learning from different domains. Machine Learning, 79(1):151–175, 2010a."
REFERENCES,0.22176308539944903,"Shai Ben-David, Tyler Lu, Teresa Luu, and David Pal. Impossibility theorems for domain adaptation.
In Yee Whye Teh and Mike Titterington (eds.), Proceedings of the Thirteenth International
Conference on Artiﬁcial Intelligence and Statistics, volume 9 of Proceedings of Machine Learning
Research, pp. 129–136, Chia Laguna Resort, Sardinia, Italy, 13–15 May 2010b. PMLR. URL
https://proceedings.mlr.press/v9/david10a.html."
REFERENCES,0.2231404958677686,"Léon Bottou. Large-scale machine learning with stochastic gradient descent. In Proceedings of
COMPSTAT’2010, pp. 177–186. Springer, 2010."
REFERENCES,0.22451790633608815,"Mathilde Caron, Hugo Touvron, Ishan Misra, Hervé Jégou, Julien Mairal, Piotr Bojanowski, and
Armand Joulin. Emerging properties in self-supervised vision transformers. arXiv preprint
arXiv:2104.14294, 2021."
REFERENCES,0.22589531680440772,"Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for
contrastive learning of visual representations. In International conference on machine learning, pp.
1597–1607. PMLR, 2020."
REFERENCES,0.22727272727272727,"Yann Dubois, Douwe Kiela, David J Schwab, and Ramakrishna Vedantam. Learning optimal repre-
sentations with the decodable information bottleneck. In H. Larochelle, M. Ranzato, R. Hadsell,
M. F. Balcan, and H. Lin (eds.), Advances in Neural Information Processing Systems, volume 33,
pp. 18674–18690. Curran Associates, Inc., 2020. URL https://proceedings.neurips.
cc/paper/2020/file/d8ea5f53c1b1eb087ac2e356253395d8-Paper.pdf."
REFERENCES,0.22865013774104684,"Yann Dubois, Benjamin Bloem-Reddy, Karen Ullrich, and Chris J. Maddison. Lossy compression for
lossless prediction. arXiv preprint arXiv:2106.10800, 2021."
REFERENCES,0.23002754820936638,Published as a conference paper at ICLR 2022
REFERENCES,0.23140495867768596,"Chen Fang, Ye Xu, and Daniel N Rockmore. Unbiased metric learning: On the utilization of multiple
datasets and web images for softening bias. In Proceedings of the IEEE International Conference
on Computer Vision, pp. 1657–1664, 2013."
REFERENCES,0.2327823691460055,"Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, François
Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks.
The journal of machine learning research, 17(1):2096–2030, 2016."
REFERENCES,0.23415977961432508,"Tilmann Gneiting and Adrian E Raftery. Strictly proper scoring rules, prediction, and estimation.
Journal of the American statistical Association, 102(477):359–378, 2007."
REFERENCES,0.23553719008264462,"Mingming Gong, Kun Zhang, Tongliang Liu, Dacheng Tao, Clark Glymour, and Bernhard Schölkopf.
Domain adaptation with conditional transferable components. In International conference on
machine learning, pp. 2839–2848. PMLR, 2016."
REFERENCES,0.2369146005509642,"Ian Goodfellow.
Nips 2016 tutorial:
Generative adversarial networks.
arXiv preprint
arXiv:1701.00160, 2016."
REFERENCES,0.23829201101928374,"Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. In International
Conference on Learning Representations, 2021. URL https://openreview.net/forum?
id=lQdXeXDoWtI."
REFERENCES,0.2396694214876033,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pp. 770–778, 2016."
REFERENCES,0.24104683195592286,"Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul
Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et al. The many faces of robustness: A critical
analysis of out-of-distribution generalization. arXiv preprint arXiv:2006.16241, 2020."
REFERENCES,0.24242424242424243,"Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, and Dawn Song. Natural adver-
sarial examples. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition, pp. 15262–15271, 2021."
REFERENCES,0.24380165289256198,"Fredrik D Johansson, David Sontag, and Rajesh Ranganath. Support and invertibility in domain-
invariant representations. In The 22nd International Conference on Artiﬁcial Intelligence and
Statistics, pp. 527–536. PMLR, 2019."
REFERENCES,0.24517906336088155,"Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron
Maschinot, Ce Liu, and Dilip Krishnan.
Supervised contrastive learning.
arXiv preprint
arXiv:2004.11362, 2020."
REFERENCES,0.2465564738292011,"Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014."
REFERENCES,0.24793388429752067,"Naveen Kodali, Jacob Abernethy, James Hays, and Zsolt Kira. On convergence and stability of gans.
arXiv preprint arXiv:1705.07215, 2017."
REFERENCES,0.2493112947658402,"David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai
Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapola-
tion (rex). In International Conference on Machine Learning, pp. 5815–5826. PMLR, 2021."
REFERENCES,0.25068870523415976,"Bo Li, Yifei Shen, Yezhen Wang, Wenzhen Zhu, Colorado J Reed, Jun Zhang, Dongsheng Li, Kurt
Keutzer, and Han Zhao. Invariant information bottleneck for domain generalization. arXiv preprint
arXiv:2106.06333, 2021."
REFERENCES,0.25206611570247933,"Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales. Deeper, broader and artier domain
generalization. In Proceedings of the IEEE international conference on computer vision, pp.
5542–5550, 2017."
REFERENCES,0.2534435261707989,"Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C Kot. Domain generalization with adver-
sarial feature learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition, pp. 5400–5409, 2018a."
REFERENCES,0.2548209366391185,Published as a conference paper at ICLR 2022
REFERENCES,0.256198347107438,"Ya Li, Xinmei Tian, Mingming Gong, Yajing Liu, Tongliang Liu, Kun Zhang, and Dacheng Tao.
Deep domain generalization via conditional invariant adversarial networks. In Proceedings of the
European Conference on Computer Vision (ECCV), pp. 624–639, 2018b."
REFERENCES,0.25757575757575757,"Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features with
deep adaptation networks. In International conference on machine learning, pp. 97–105. PMLR,
2015."
REFERENCES,0.25895316804407714,"Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Deep transfer learning with joint
adaptation networks. In International conference on machine learning, pp. 2208–2217. PMLR,
2017."
REFERENCES,0.2603305785123967,"Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Domain adaptation: Learning bounds
and algorithms. arXiv preprint arXiv:0902.3430, 2009."
REFERENCES,0.26170798898071623,"A Tuan Nguyen, Toan Tran, Yarin Gal, Philip HS Torr, and Atılım Güne¸s Baydin. Kl guided domain
adaptation. arXiv preprint arXiv:2106.07780, 2021."
REFERENCES,0.2630853994490358,"Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predictive
coding. arXiv preprint arXiv:1807.03748, 2018."
REFERENCES,0.2644628099173554,"Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang. Moment matching
for multi-source domain adaptation. In Proceedings of the IEEE/CVF International Conference on
Computer Vision, pp. 1406–1415, 2019."
REFERENCES,0.26584022038567495,"Ben Poole, Sherjil Ozair, Aaron Van Den Oord, Alex Alemi, and George Tucker. On variational
bounds of mutual information. In International Conference on Machine Learning, pp. 5171–5180.
PMLR, 2019."
REFERENCES,0.26721763085399447,"Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal,
Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever.
Learning transferable visual models from natural language supervision. In Marina Meila and Tong
Zhang (eds.), Proceedings of the 38th International Conference on Machine Learning, volume
139 of Proceedings of Machine Learning Research, pp. 8748–8763. PMLR, 18–24 Jul 2021. URL
https://proceedings.mlr.press/v139/radford21a.html."
REFERENCES,0.26859504132231404,"Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do imagenet classiﬁers
generalize to imagenet? In International Conference on Machine Learning, pp. 5389–5400. PMLR,
2019."
REFERENCES,0.2699724517906336,"Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust
neural networks for group shifts: On the importance of regularization for worst-case generalization.
arXiv preprint arXiv:1911.08731, 2019."
REFERENCES,0.2713498622589532,"Nikunj Saunshi, Orestis Plevrakis, Sanjeev Arora, Mikhail Khodak, and Hrishikesh Khandeparkar.
A Theoretical Analysis of Contrastive Unsupervised Representation Learning. In Kamalika
Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of the 36th International Conference
on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97
of Proceedings of Machine Learning Research, pp. 5628–5637. PMLR, 2019. URL http:
//proceedings.mlr.press/v97/saunshi19a.html."
REFERENCES,0.2727272727272727,"Christoph Schuhmann, Richard Vencu, Romain Beaumont, Robert Kaczmarczyk, Clayton Mullis,
Aarush Katta, Theo Coombes, Jenia Jitsev, and Aran Komatsuzaki. Laion-400m: Open dataset of
clip-ﬁltered 400 million image-text pairs. arXiv preprint arXiv:2111.02114, 2021."
REFERENCES,0.2741046831955923,"Ohad Shamir, Sivan Sabato, and Naftali Tishby. Learning and generalization with the information
bottleneck. Theor. Comput. Sci., 411(29-30):2696–2711, 2010. doi: 10.1016/j.tcs.2010.04.006.
URL https://doi.org/10.1016/j.tcs.2010.04.006."
REFERENCES,0.27548209366391185,"Vaishaal Shankar, Achal Dave, Rebecca Roelofs, Deva Ramanan, Benjamin Recht, and Ludwig
Schmidt. Do image classiﬁers generalize across time? arXiv preprint arXiv:1906.02168, 2019."
REFERENCES,0.2768595041322314,"Jian Shen, Yanru Qu, Weinan Zhang, and Yong Yu. Wasserstein distance guided representation
learning for domain adaptation. In Thirty-Second AAAI Conference on Artiﬁcial Intelligence, 2018."
REFERENCES,0.27823691460055094,Published as a conference paper at ICLR 2022
REFERENCES,0.2796143250688705,"Ravid Shwartz-Ziv and Naftali Tishby. Opening the black box of deep neural networks via information.
CoRR, abs/1703.00810, 2017. URL http://arxiv.org/abs/1703.00810."
REFERENCES,0.2809917355371901,"Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In
European conference on computer vision, pp. 443–450. Springer, 2016."
REFERENCES,0.28236914600550966,"Remi Tachet des Combes, Han Zhao, Yu-Xiang Wang, and Geoffrey J Gordon. Domain adaptation
with conditional distribution matching and generalized label shift. Advances in Neural Information
Processing Systems, 33, 2020."
REFERENCES,0.2837465564738292,"Rohan Taori, Achal Dave, Vaishaal Shankar, Nicholas Carlini, Benjamin Recht, and Ludwig
Schmidt.
Measuring robustness to natural distribution shifts in image classiﬁcation.
arXiv
preprint arXiv:2007.00644, 2020."
REFERENCES,0.28512396694214875,"Lucas Theis, Wenzhe Shi, Andrew Cunningham, and Ferenc Huszár. Lossy image compression with
compressive autoencoders. arXiv preprint arXiv:1703.00395, 2017."
REFERENCES,0.2865013774104683,"Naftali Tishby, Fernando C Pereira, and William Bialek. The information bottleneck method. arXiv
preprint physics/0004057, 2000."
REFERENCES,0.2878787878787879,"Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan. Deep
hashing network for unsupervised domain adaptation. In Proceedings of the IEEE conference on
computer vision and pattern recognition, pp. 5018–5027, 2017."
REFERENCES,0.2892561983471074,"Haohan Wang, Songwei Ge, Eric P Xing, and Zachary C Lipton. Learning robust global representa-
tions by penalizing local predictive power. arXiv preprint arXiv:1905.13549, 2019."
REFERENCES,0.290633608815427,"Luyu Wang, Pauline Luc, Adria Recasens, Jean-Baptiste Alayrac, and Aaron van den Oord. Multi-
modal self-supervised learning of general audio representations. arXiv preprint arXiv:2104.12807,
2021."
REFERENCES,0.29201101928374656,"Aolin Xu and Maxim Raginsky.
Minimum excess risk in bayesian learning.
arXiv preprint
arXiv:2012.14868, 2020."
REFERENCES,0.29338842975206614,"Shen Yan, Huan Song, Nanxiang Li, Lincan Zou, and Liu Ren. Improve unsupervised domain
adaptation with mixup training. arXiv preprint arXiv:2001.00677, 2020."
REFERENCES,0.29476584022038566,"Han Zhao, Remi Tachet Des Combes, Kun Zhang, and Geoffrey Gordon. On learning invariant
representations for domain adaptation. In International Conference on Machine Learning, pp.
7523–7532. PMLR, 2019."
REFERENCES,0.29614325068870523,Published as a conference paper at ICLR 2022
REFERENCES,0.2975206611570248,Appendix
REFERENCES,0.2988980716253444,Table of Contents
REFERENCES,0.3002754820936639,"A Preliminaries
15
A.1
Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
A.2
Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
A.3
Assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17"
REFERENCES,0.30165289256198347,"B
Proofs
19
B.1
Lemmas for general losses . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
B.2
Proof of Theorem 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
B.3
Impossibility results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
B.4
Augmentations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25"
REFERENCES,0.30303030303030304,"C Practical objectives
27
C.1
Mutual information bottleneck B[Z, X, Y, D] = I[Z; X]
. . . . . . . . . . . .
27
C.2
Entropy bottleneck B[Z, X, Y, D] = H[Z] . . . . . . . . . . . . . . . . . . . .
28
C.3
Contrastive adversarial domain bottleneck B[Z, X, Y, D] = I[Z; D] . . . . . . .
29
C.4
Conditional CAD B[Z, X, Y, D] = I[Z; D | Y ]
. . . . . . . . . . . . . . . . .
30"
REFERENCES,0.3044077134986226,"D Extended Related Work
32"
REFERENCES,0.30578512396694213,"E
Experimental Details
32
E.1
Scientiﬁc . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
32
E.2
Bridge . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
33
E.3
DomainBed . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
E.4
LAION
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
35"
REFERENCES,0.3071625344352617,"F
Additional Experimental Results
36
F.1
Scientiﬁc . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
F.2
Bridge . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
F.3
DomainBed . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
F.4
LAION
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38"
REFERENCES,0.3085399449035813,Published as a conference paper at ICLR 2022
REFERENCES,0.30991735537190085,"A
PRELIMINARIES"
REFERENCES,0.31129476584022037,"A.1
NOTATION"
REFERENCES,0.31267217630853994,"For the most part, we will assume that all spaces are discrete probability spaces. A full list of
assumptions is found at Appx. A.3."
REFERENCES,0.3140495867768595,"General
The image of a set A ⊆X under a function f : X →Y is denoted f →(A) =
{f(x) | x ∈A}. The pre-image is denoted f ←(B) ={x ∈X | f(x) ∈B} for B ⊆Y."
REFERENCES,0.3154269972451791,"Probability
Random variables (r.v.) are denoted by uppercase letters (e.g., X), and their sam-
ple space and realizations are denoted by the corresponding calligraphic (e.g., X) and lowercase
letters (e.g., x) respectively. The probability mass function (pmf) of a random variable X is
denoted as pX. We use capital P instead of p to denote the measure under p. The support
supp(pX) of a discrete distribution is the set of all points x ∈X with positive probability, i.e.,
supp(pX) = {x ∈X | pX(x) > 0}. The space of all probability distributions on X is denoted
P(X) =

pX | pX(x) ≥0 and P"
REFERENCES,0.3168044077134986,"x∈X pX(x) = 1
	
."
REFERENCES,0.3181818181818182,"When it is necessary to be explicit, we will denote ‘X is distributed as pX’ using the notation
X
d∼pX. Expectations are written as: EpX[f(X)], independence of two r.v. as ·⊥⊥·, conditional
independence as ·⊥⊥· | ·."
REFERENCES,0.31955922865013775,"For jointly distributed random variables (X, Y ) taking value in (t.v.i.) X × Y, the conditional
distribution is denoted as pY | X : Y × X →[0, 1]. For convenience, let pY | x = pY | X( · | x) be the
conditional distribution of Y given x. All random variables are independently distributed, unless an
explicit joint distribution or coupling is given."
REFERENCES,0.3209366391184573,"A.2
DEFINITIONS"
REFERENCES,0.32231404958677684,"We are interested in prediction problems with domain shift. There are three random variables: the
target domain Dt, the input X, the label Y . They have the following joint distribution:
(Dt, X, Y )
d∼pDt · pX,Y | Dt
(9)
where we drop the arguments of the probability densities for clarity. We make a variety of convenience
assumptions on these random variables (Assumption 6). Crucially, we will be making the Bayes
invariance assumption on pDt,X,Y that can be thought of as a generalized covariate shift assumption
(Assumption 4)."
REFERENCES,0.3236914600550964,"We will be studying the effect of changing the representation of the data. This is done by “encoding”
X into a representation Z using a conditional distribution pZ | X."
REFERENCES,0.325068870523416,"Deﬁnition 1 (Encoder). An encoder is a conditional distribution pZ | X : Z × X →[0, 1] from the
input space X to the representation space Z."
REFERENCES,0.32644628099173556,"The data together with the representation has the following joint:
(Dt, X, Y, Z)
d∼pDt · pX,Y | Dt · pZ | X
(10)
The key thing to notice here is that Z is conditionally independent of Y, Dt given X. In particular,
the same encoder is used across all domains."
REFERENCES,0.3278236914600551,"A.2.1
RISK MINIMIZATION"
REFERENCES,0.32920110192837465,"Our ultimate goal is to predict Y from the representation Z of X in a manner that is robust to changes
in the domain."
REFERENCES,0.3305785123966942,"We formalize this in the standard way by making predictions γ ∈Γ in a space of predictions or
actions. For example the prediction space may be the set of all possible labels Γ = Y, in which case
we would be predicting deterministic labels. Or we may predict a distribution over labels, in which
case the prediction space would be the set of all probability distributions on Y, i.e. Γ = P(Y)."
REFERENCES,0.3319559228650138,"A predictor is a function mapping inputs to predictions, i.e., f : X →Γ, or representations to
predictions, i.e., h : Z →Γ. For example, f may be a neural network that takes as input a sample x
and outputs a vector of logits that parameterize a softmax distribution over ﬁnitely many labels."
REFERENCES,0.3333333333333333,Published as a conference paper at ICLR 2022
REFERENCES,0.3347107438016529,We select predictors according to the risk deﬁned via a loss function ℓ: Y × Γ →R≥0 ∪{∞}:
REFERENCES,0.33608815426997246,"Rf [Y | X] := EpX,Y [ℓ(Y, f(X))] .
(11)"
REFERENCES,0.33746556473829203,"In particular, we are interested in the Bayes (minimum) risk over all predictors:"
REFERENCES,0.33884297520661155,"R [Y | X] := inf
f Rf [Y | X] ,
(12)"
REFERENCES,0.3402203856749311,We denote the set of all optimal predictors from X as
REFERENCES,0.3415977961432507,"F∗:={f | Rf [Y | X] = R [Y | X]}
(13)"
REFERENCES,0.34297520661157027,"Similarly, we deﬁne the risk Rh [Y | Z], the Bayes risk R [Y | Z], and the set of optimal predictors"
REFERENCES,0.3443526170798898,"H∗
Z :={h | Rh [Y | Z] = R [Y | Z]}
(14)"
REFERENCES,0.34573002754820936,"from Z, all of which vary as a function of the encoder pZ | X. Note, in the main body of the paper,
we omitted the subscript Z from H∗
Z for clarity, but we will keep it in the Appendices. We assume
that together our loss and prediction space always admit optima (Item 2 of Assumption 2), and thus
F∗, H∗
Z are always non-empty."
REFERENCES,0.34710743801652894,"We will be assuming that the risk admits unique optimal prediction when predicting from X (Item 3
of Assumption 2). Thus it makes sense to deﬁne the following:"
REFERENCES,0.3484848484848485,"Deﬁnition 2 (The Bayes predictor). The Bayes predictor f ∗: X →Γ is the unique predictor that is
optimal for all x ∈X:
f ∗(x) = arg min
γ∈Γ EpY | x[ℓ(Y, γ)]
(15)"
REFERENCES,0.349862258953168,"Deﬁnition 3 (The Bayes image). The image of all the inputs under the Bayes predictor will be
denoted as Γ∗= f ∗→(X) and called the Bayes image."
REFERENCES,0.3512396694214876,"Note that F∗becomes a singleton {f ∗}, but it is not necessarily the case for H∗
Z since we will not be
making any uniqueness assumption on optimal prediction from Z."
REFERENCES,0.3526170798898072,"A.2.2
DOMAIN GENERALIZATION"
REFERENCES,0.35399449035812675,"We are interested in controlling the risk in a domain generalization setting, and so we deﬁne the
domain-conditional risk,"
REFERENCES,0.35537190082644626,"Rd
f [Y | X] := EpX,Y | d[ℓ(Y, f(X))] .
(16)"
REFERENCES,0.35674931129476584,"Rd [Y | X] , F∗
d are deﬁned as Eqs. (12) and (13), respectively, but with respect to Rd
f. Similarly,
deﬁne the Bayes image for domain d as"
REFERENCES,0.3581267217630854,"Γ∗
d := f ∗→ 
supp(pX | d)

.
(17)"
REFERENCES,0.359504132231405,"We also deﬁne domain-conditional quantities for prediction from a representation Z. The most
important term which we will be investigating is an idealization of the domain generalization worst-
case risk."
REFERENCES,0.3608815426997245,"Deﬁnition 4 (IDG risk). Given an encoder pZ | X and a distribution pDt,Ds over a target domain Dt
and source domain Ds, the idealized domain generalization worst-case risk, IDG risk for short, is the
expected worst-case target risk taken over source minimizers, i.e.,"
REFERENCES,0.3622589531680441,"RIDG [Y | Z] := EpDt,Ds """
REFERENCES,0.36363636363636365,"sup
h∈H∗
Z,Ds
RDt
h [Y | Z] # (18)"
REFERENCES,0.3650137741046832,"Note that the IDG risk is well-deﬁned because H∗
Z,Ds is non-empty by Assumption 2. The desired
optimal representations, are then those that minimize the IDG risk."
REFERENCES,0.36639118457300274,"Deﬁnition 5 (Optimal representations for IDG). An encoder pZ∗| X is optimal for idealized domain
generalization if and only if it minimizes the IDG risk, i.e.,"
REFERENCES,0.3677685950413223,"RIDG [Y | Z∗] = inf
pZ | X RIDG [Y | Z]
(19)"
REFERENCES,0.3691460055096419,Published as a conference paper at ICLR 2022
REFERENCES,0.37052341597796146,"A.3
ASSUMPTIONS"
REFERENCES,0.371900826446281,"We make a the following assumptions throughout the paper. All these assumptions should hold for
practical settings."
REFERENCES,0.37327823691460055,"Assumption 1 (Convenience: discrete probability spaces). All data spaces (D, X, Y, Z, A) are
discrete spaces. Because the distributions of X, Y, D are ﬁxed, we assume for convenience that
supp(pX) = X, supp(pY ) = Y, and supp(pDt) = D."
REFERENCES,0.3746556473829201,"Assumption 1 is a convenience assumption to avoid measure theory for the sake of clarity. It always
holds in practice due to ﬁniteness of computers, i.e., all spaces will be ﬁnite but arbitrarily large. We
believe that our claims can nevertheless be generalized to typical continuous spaces with some minor
technical assumptions."
REFERENCES,0.3760330578512397,Assumption 2 (Losses admit optima). We assume that our risk always admits optimal predictions:
REFERENCES,0.3774104683195592,1. |Γ| > 1.
REFERENCES,0.3787878787878788,"2. For all pΥ ∈P(Y), there exists γ∗∈Γ, such that"
REFERENCES,0.38016528925619836,"EpΥ[ℓ(Υ, γ∗)] ≤EpΥ[ℓ(Υ, γ)]
∀γ ∈Γ.
(20)"
REFERENCES,0.38154269972451793,"3. For all x ∈X, there exist γ∗∈Γ, such that"
REFERENCES,0.38292011019283745,"EpY | x[ℓ(Y, γ∗)] < EpY | x[ℓ(Y, γ)]
∀γ ̸= γ∗.
(21)"
REFERENCES,0.384297520661157,"Note that for log-loss ℓ(y, γ) = −log γ(y) and ﬁnite Y, these assumptions are satisﬁed if Γ = P(Y)
where the optimal prediction for Item 3 is γ∗= pY | x by strict properness (Gneiting & Raftery,
2007). If we consider the 0-1 loss (reverse accuracy) ℓ(y, γ) = 1 −1[y = γ] with Γ = Y and a ﬁnite
label space where the optimal prediction for Item 3 is γ∗= arg maxy∈Y pY | x(y), this assumption is
mostly satisﬁed, except we assume that pY | x has a unique mode."
REFERENCES,0.3856749311294766,"Assumption 2 serves two purposes: Item 2 ensures that for any representation the optimal predictors
from Z exists such that the IDG risk is well-deﬁned as in Def. 5; Item 3 ensures a unique Bayes
predictor from X, which simpliﬁes the analysis and is satisﬁed by common losses as described above."
REFERENCES,0.38705234159779617,Assumption 3 (Cardinalities). We assume that
REFERENCES,0.3884297520661157,"|Z| ≥|Γ∗| ≥2
(22)"
REFERENCES,0.38980716253443526,Assumption 3 is very weak and ensures that optimal representations always exists (Prop. 3).
REFERENCES,0.39118457300275483,"Assumption 4 (Generalized covariate shift). The Bayes predictor is optimal for all domains. I.e., for
all (x, d) ∈supp(pX,Dt), γ ∈Γ such that γ ̸= f ∗(x), we have"
REFERENCES,0.3925619834710744,"EpY | x,d[ℓ(Y, f ∗(x))] < EpY | x,d[ℓ(Y, γ)] .
(23)"
REFERENCES,0.3939393939393939,"For example, in the case of strictly proper scoring rules, e.g. log loss, covariate shift pY | X,D = pY | X
is equivalent to the invariance of the Bayes predictor. For the 0-1 loss, this is guaranteed by invariance
of the most likely label. For MSE it is guaranteed by the invariance of the expected label. In the latter
two cases, Assumption 4 is less stringent than the typical covariate shift assumption."
REFERENCES,0.3953168044077135,"Assumption 4 is the core assumption for our theoretical results. It ensures that source and target
domains are related in a useful way that can be utilized by the representation."
REFERENCES,0.39669421487603307,"Assumption 5 (Constant Bayes image). The Bayes image is invariant across domains, i.e., for all
d ∈D,
Γ∗
d = Γ∗.
(24)
For the case of 0-1 loss, this simply means that the label set for all domains is the same, which is
trivial. For log-loss, this means that the set of possible conditional distributions Γ∗
d = {pY | x | x ∈
supp(pX | d)} is the same across domains."
REFERENCES,0.39807162534435264,Published as a conference paper at ICLR 2022
REFERENCES,0.39944903581267216,"Assumption 5 is crucial to be able to learn. Without it, in the extreme case, one could set each domain
to be all examples associated with a single element from the label set (or the Bayes image set) in
which case it is impossible to generalize across different domains. Assumption 5 is also necessary to
guarantee the existence of optimal representations as in Prop. 3."
REFERENCES,0.40082644628099173,"Assumption 6 (Domain joint). pDt,Ds is any distribution such that supp(pDt,Ds) = D × D."
REFERENCES,0.4022038567493113,"In a simpliﬁed scenario, one could deﬁne the source Ds and target Dt as i.i.d. r.v. from pDt, where
pDt,Ds = pDt · pDs = pDt · pDt and Assumption 6 is trivially satisﬁed."
REFERENCES,0.4035812672176309,Published as a conference paper at ICLR 2022
REFERENCES,0.4049586776859504,"B
PROOFS"
REFERENCES,0.40633608815426997,"B.1
LEMMAS FOR GENERAL LOSSES"
REFERENCES,0.40771349862258954,"An important result that we will be using is the generalized data processing inequality of Bayes risk
(Xu & Raginsky, 2020; Dubois et al., 2021). We include it here for completeness."
REFERENCES,0.4090909090909091,"Lemma 1 (Generalized DPI (Xu & Raginsky, 2020; Dubois et al., 2021)). Let Z −X −Y be a
Markov chain of random variables. For any loss function ℓ,"
REFERENCES,0.41046831955922863,"R [Y | X] ≤R [Y | Z] .
(25)"
REFERENCES,0.4118457300275482,For the case of strictly proper losses (Assumption 2) we can go one step further.
REFERENCES,0.4132231404958678,"Lemma 2. Let Z −X −Y be a Markov chain of random variables. Then, under Assumptions 1
and 2 we have that"
REFERENCES,0.41460055096418735,"R [Y | Z] = R [Y | X]
⇐⇒
∀h∗∈H∗
Z, ∀(x, z) ∈supp(pX,Z), h∗(z) = f ∗(x).
(26)"
REFERENCES,0.41597796143250687,"Proof. Suppose that for all h∗∈H∗
Z we have h∗(z) = f ∗(x) on the support of pX,Z. Then,"
REFERENCES,0.41735537190082644,"R [Y | X] = EpX,Y [ℓ(Y, f ∗(X))]
(27)"
REFERENCES,0.418732782369146,"= EpX,Y pZ | X[ℓ(Y, f ∗(X))]
(28)"
REFERENCES,0.4201101928374656,"= EpX,Y pZ | X[ℓ(Y, h∗(Z))]
(29)"
REFERENCES,0.4214876033057851,"= EpZ,Y [ℓ(Y, h∗(Z))]
(30)"
REFERENCES,0.4228650137741047,"= R [Y | Z] .
(31)"
REFERENCES,0.42424242424242425,"Now suppose there exists a h∗∈H∗
Z and a pair (x′, z′) ∈supp(pX,Z) such that h∗(z′) ̸= f ∗(x′).
Then"
REFERENCES,0.4256198347107438,"R [Y | Z]
(32)
= EpX,ZpY | X[ℓ(Y, h∗(Z))]
(33)"
REFERENCES,0.42699724517906334,"= pX,Z(x′, z′) EpY | x′[ℓ(Y, h∗(z′))] +
X"
REFERENCES,0.4283746556473829,"(x,z)̸=(x′,z′)
pX,Z(x, z) EpY | x[ℓ(Y, h∗(z))]
(34)"
REFERENCES,0.4297520661157025,"≥pX,Z(x′, z′) EpY | x′[ℓ(Y, h∗(z′))] +
X"
REFERENCES,0.43112947658402206,"(x,z)̸=(x′,z′)
pX,Z(x, z) EpY | x[ℓ(Y, f ∗(x))]
(35)"
REFERENCES,0.4325068870523416,"> pX,Z(x′, z′) EpY | x′[ℓ(Y, f ∗(x′))] +
X"
REFERENCES,0.43388429752066116,"(x,z)̸=(x′,z′)
pX,Z(x, z) EpY | x[ℓ(Y, f ∗(x))]
(36)"
REFERENCES,0.43526170798898073,"= R [Y | X]
(37)"
REFERENCES,0.4366391184573003,"Eq. (35) follows by Item 3 of Assumption 2 along with the deﬁnition of f ∗. Eq. (36) follows by Item 3
of Assumption 2 and the fact that h∗(z′) ̸= f ∗(x′). This completes the proof, because Lemma 1
prevents R [Y | Z] < R [Y | X]."
REFERENCES,0.4380165289256198,"B.2
PROOF OF THEOREM 1"
REFERENCES,0.4393939393939394,"First we will show that the desired representation exists by taking all inputs for which the Bayes
predictor predicts similarly and “bucketing” them to the same representation. This is a direct extension
of the example from Dubois et al.’s (2020) Proposition 6, to the case of proper losses."
REFERENCES,0.44077134986225897,"Proposition 3 (Existence of optimal representations). Under Assumptions 1 to 5, there exists an
encoder pZ∗| X that is optimal for Eq. (3), i.e.,"
REFERENCES,0.44214876033057854,"pZ∗| X ∈arg min
pZ | X R [Y | Z]
s.t.
∀d ∈D, supp(pZ | d) = supp(pZ).
(38)"
REFERENCES,0.44352617079889806,"Moreover, we have that
R [Y | X] = R [Y | Z∗] .
(39)"
REFERENCES,0.44490358126721763,Published as a conference paper at ICLR 2022
REFERENCES,0.4462809917355372,"Proof. Because we assume arbitrary encoders pZ | X, the essence of this construction is simple: we
embed the Bayes image into Z. Indeed, let φ : Γ∗→Z be any one-to-one function, which exists due
to Assumption 3 (here we use deterministic one-to-one function for simplicity, the construction can
be easily extended to stochastic case). Then let Z∗= φ(f ∗(X)). We now verify the properties of
pZ∗| X."
REFERENCES,0.4476584022038568,"1. Z∗satisﬁes R [Y | X] = R [Y | Z∗]. Indeed,"
REFERENCES,0.4490358126721763,"R [Y | X] = EpX,Y [ℓ(Y, f ∗(X))]
(40)"
REFERENCES,0.45041322314049587,"= EpX,Y pZ∗| X[ℓ(Y, f ∗(X))]
(41)"
REFERENCES,0.45179063360881544,"= EpZ∗,Y

ℓ(Y, φ−1(Z∗))

(42)"
REFERENCES,0.453168044077135,"≥R [Y | Z∗] .
(43)"
REFERENCES,0.45454545454545453,"Eq. (42) is by our construction of Z∗and Eq. (43) is by the deﬁnition of the Bayes risk.
Due to the data processing inequality of Bayes risk (Lemma 1) we also have R [Y | X] ≤
R [Y | Z∗], from which we conclude that R [Y | X] = R [Y | Z∗] and that Eq. (39) holds."
REFERENCES,0.4559228650137741,"2. Recall that Γ∗= f ∗→(X) and Γ∗
d = f ∗→ 
supp(pX | d)

. Now let us compute the desired
support for all d ∈D:"
REFERENCES,0.4573002754820937,"supp(pZ∗| d) = φ
→(Γ∗
d)
(44)"
REFERENCES,0.45867768595041325,"= φ
→(Γ∗)
(45)
= supp(pZ∗).
(46)"
REFERENCES,0.46005509641873277,Eq. (45) is by Assumption 5.
REFERENCES,0.46143250688705234,"Because R [Y | X] is the minimum achievable risk by any encoder regardless of constraint (this is by
Lemma 1), this implies that pZ∗| X is an optimal encoder for Eq. (3)."
REFERENCES,0.4628099173553719,"The following lemma essentially says that when R [Y | Z] is minimized, then the optimal predictors
for each domain all agree on the intersection of their support."
REFERENCES,0.4641873278236915,"Lemma 3. Let pZ | X be an encoder such that R [Y | Z] = R [Y | X]. Under Assumptions 1 and 2,
we have that for all z ∈supp(pZ), there exists γ∗∈Γ such that"
REFERENCES,0.465564738292011,"EpY | z[ℓ(Y, γ∗)] < EpY | z[ℓ(Y, γ)]
∀γ ̸= γ∗.
(47)"
REFERENCES,0.4669421487603306,"In other words, the restriction of any h∗∈H∗
Z to supp(pZ) is unique. If, in addition, Assumption 4
holds, then for all (z, d) ∈supp(pZ,Dt), γ ∈Γ such that γ ̸= h∗(z),"
REFERENCES,0.46831955922865015,"EpY | z,d[ℓ(Y, h∗(z)] < EpY | z,d[ℓ(Y, γ)] .
(48)"
REFERENCES,0.4696969696969697,"In other words, the restriction of any h ∈H∗
Z,d to supp(pZ | d) is unique and equal to h∗."
REFERENCES,0.47107438016528924,"Proof. For the ﬁrst result, let z ∈supp(pZ) and consider x ∈supp(pX | z). By Lemma 2, it must be
the case that f ∗is constant on supp(pX | z). Thus, we can pick γ∗= f ∗(x). Now, let γ ̸= γ∗. We
have that,"
REFERENCES,0.4724517906336088,"EpY | z[ℓ(Y, γ∗)] = EpX | zpY | X[ℓ(Y, γ∗)]
(49)"
REFERENCES,0.4738292011019284,"= EpX | zpY | X[ℓ(Y, f ∗(X))]
(50)"
REFERENCES,0.47520661157024796,"< EpX | zpY | X[ℓ(Y, γ)]
(51)"
REFERENCES,0.4765840220385675,"= EpY | z[ℓ(Y, γ)] .
(52)"
REFERENCES,0.47796143250688705,"Eq. (49) is due to the conditional independence of Y and Z given X. Eq. (51) is due to Assumption 2
and the deﬁnition of the Bayes predictor. Let h∗: supp(pZ) →Γ be the unique Bayes predictor
from Z."
REFERENCES,0.4793388429752066,"Now, for the second result, note that"
REFERENCES,0.4807162534435262,"R [Y | X] = Rf∗[Y | X]
(53)"
REFERENCES,0.4820936639118457,"Published as a conference paper at ICLR 2022 =
X"
REFERENCES,0.4834710743801653,"d∈D
pDt(d) Rd
f∗[Y | X]
(54) =
X"
REFERENCES,0.48484848484848486,"d∈D
pDt(d) Rd [Y | X] ,
Assumption 4
(55) and"
REFERENCES,0.48622589531680444,"R [Y | Z] = Rh∗[Y | Z]
(56) =
X"
REFERENCES,0.48760330578512395,"d∈D
pDt(d) Rd
h∗[Y | Z]
(57) ≥
X"
REFERENCES,0.4889807162534435,"d∈D
pDt(d) Rd [Y | Z] ,
(58)"
REFERENCES,0.4903581267217631,where Eq. (58) is due to the deﬁnition of (domain-conditional) Bayes risk. Then
REFERENCES,0.49173553719008267,"R [Y | Z] −R [Y | X] ≥
X"
REFERENCES,0.4931129476584022,"d∈D
pDt(d)

Rd [Y | Z] −Rd [Y | X]

(59)"
REFERENCES,0.49449035812672176,"≥0.
Lemma 1 conditioned on d
(60)"
REFERENCES,0.49586776859504134,"Thus, any encoder that achieves R [Y | Z] = R [Y | X] also satisﬁes Rd [Y | Z] = Rd [Y | X] for
all d ∈D since we assume that supp(pDt) = D in Assumption 1. Now, let d ∈D. An argument
analogous to Lemma 2 gives us,"
REFERENCES,0.4972451790633609,"∀h ∈H∗
Z,d, ∀(x, z) ∈supp(pX,Z | d), h(z) = f ∗(x) = h∗(z).
(61)"
REFERENCES,0.4986225895316804,"Eq. (61) is derived from Rd [Y | Z] = Rd [Y | X] using Assumption 4 in place of Item 3 of As-
sumption 2 for a speciﬁc domain d. Let z ∈supp(pZ | d) and γ ∈Γ such that γ ̸= h∗(z). Since
supp(pX | z,d) ⊆supp(pX | z), f ∗is a constant on supp(pX | z,d) and equal to h∗. Now, as above,
we have that"
REFERENCES,0.5,"EpY | z,d[ℓ(Y, h∗(z))] = EpX | z,dpY | X,d[ℓ(Y, h∗(z))]
(62)"
REFERENCES,0.5013774104683195,"= EpX | z,dpY | X,d[ℓ(Y, f ∗(X))]
(63)"
REFERENCES,0.5027548209366391,"< EpX | z,dpY | X,d[ℓ(Y, γ)]
(64)"
REFERENCES,0.5041322314049587,"= EpY | z,d[ℓ(Y, γ)] .
(65)"
REFERENCES,0.5055096418732782,Eq. (64) is due to Assumption 4.
REFERENCES,0.5068870523415978,"Corollary 1. Let pZ | X be an encoder such that R [Y | Z] = R [Y | X]. Under Assumptions 1, 2
and 4 we have that H∗
Z ⊆H∗
Z,d for all d ∈D and that for all ds, dt ∈D"
REFERENCES,0.5082644628099173,"inf
h∈H∗
Z,ds
Rdt
h [Y | Z] = Rdt [Y | Z]
(66)"
REFERENCES,0.509641873278237,"Proof. H∗
Z ⊆H∗
Z,d is immediate from Lemma 3. Now, we have that Rdt
h [Y | Z] ≥Rdt [Y | Z]. So,
the result follows by taking any h ∈H∗
Z ⊆H∗
Z,ds in the inf of Eq. (66)."
REFERENCES,0.5110192837465565,"Theorem 2 (Characterizing optimal representations for IDG, equiv. Theorem 1). Under Assump-
tions 1 to 6, an encoder pZ | X is optimal for idealized domain generalization if and only if it minimizes
the Bayes risk while matching the support of pZ | d and pZ for all d ∈D, i.e.,"
REFERENCES,0.512396694214876,"pZ | X ∈arg min
pZ | X R [Y | Z]
(67)"
REFERENCES,0.5137741046831956,"s.t.
∀d ∈D, supp(pZ | d) = supp(pZ)
(68)"
REFERENCES,0.5151515151515151,Proof. The IDG risk is lower bounded by R [Y | X]:
REFERENCES,0.5165289256198347,"RIDG [Y | Z] ≥EpDs,Dt """
REFERENCES,0.5179063360881543,"inf
h∈H∗
Z,Ds
RDt
h [Y | Z] # (69)"
REFERENCES,0.5192837465564738,Published as a conference paper at ICLR 2022
REFERENCES,0.5206611570247934,"≥EpDs,Dt

RDt [Y | Z]

(70)"
REFERENCES,0.522038567493113,"≥EpDs,Dt

RDt [Y | X]

Lemma 1
(71)"
REFERENCES,0.5234159779614325,"= R [Y | X]
Assumption 4
(72)"
REFERENCES,0.5247933884297521,"We will now show that this lower bound is achieved by an encoder if and only if it satisﬁes Eqs. (67)
and (68), which exist by Prop. 3."
REFERENCES,0.5261707988980716,"Sufﬁciency ( ⇐= ): Let pZ | X be an encoder that satisﬁes Eqs. (67) and (68). Note that R [Y | Z] =
R [Y | X] by Prop. 3. Let h∗∈H∗
Z, then we have the following IDG risk"
REFERENCES,0.5275482093663911,"RIDG [Y | Z]
(73)"
REFERENCES,0.5289256198347108,"= EpDs,Dt """
REFERENCES,0.5303030303030303,"sup
h∈H∗
Z,Ds
EpZ,Y | Dt[ℓ(Y, h(Z))] # (74)"
REFERENCES,0.5316804407713499,"= EpDs,Dt """
REFERENCES,0.5330578512396694,"sup
h∈H∗
Z,Ds
EpZ,Y | Dt[ℓ(Y, h∗(Z))] #"
REFERENCES,0.5344352617079889,"Lemma 3 under matching support
(75)"
REFERENCES,0.5358126721763086,"= EpDt
h
EpZ,Y | Dt[ℓ(Y, h∗(Z))]
i
constant w.r.t Ds
(76)"
REFERENCES,0.5371900826446281,"= R [Y | Z] = R [Y | X]
(77)"
REFERENCES,0.5385674931129476,"Necessity ( =⇒): If the IDG risk is R [Y | X], then it must be the case that"
REFERENCES,0.5399449035812672,"R [Y | Z] = R [Y | X]
(78)"
REFERENCES,0.5413223140495868,"sup
h∈H∗
Z,ds
Rdt
h [Y | Z] = Rdt [Y | Z]
∀(ds, dt) ∈supp(pDs,Dt)
(79)"
REFERENCES,0.5426997245179064,"We will prove by contrapositive that Eq. (79) implies support match (Eq. (68)). Suppose that the
support match does not hold. Since supp(pZ) = ∪d∈Dsupp(pZ | d) and supp(pDs,Dt) = D × D
(Assumption 6), there must exist (ds, dt) ∈supp(pDs,Dt) such that supp(pZ | ds) ̸= supp(pZ | ds)."
REFERENCES,0.5440771349862259,"Deﬁne the set S = supp(pZ | ds) ∩supp(pZ | dt) and ¯S = supp(pZ | dt) \ supp(pZ | ds), let ρ =
PZ | dt(S), and let h∗∈H∗
Z. Then,"
REFERENCES,0.5454545454545454,"sup
h∈H∗
Z,ds
Rdt
h [Y | Z]
(80)"
REFERENCES,0.546831955922865,"=
sup
h∈H∗
Z,ds
ρ EpY,Z | S,dt[ℓ(Y, h(Z))] + (1 −ρ) EpY,Z | ¯
S,dt[ℓ(Y, h(Z))]
(81)"
REFERENCES,0.5482093663911846,"=
sup
h∈H∗
Z,ds
ρ EpY,Z | S,dt[ℓ(Y, h∗(Z))] + (1 −ρ) EpY,Z | ¯
S,dt[ℓ(Y, h(Z))]
Lem. 3
(82)"
REFERENCES,0.5495867768595041,"= ρ EpY,Z | S,dt[ℓ(Y, h∗(Z))] + (1 −ρ)
sup
h∈H∗
Z,ds
EpY,Z | ¯
S,dt[ℓ(Y, h(Z))]
(83)"
REFERENCES,0.5509641873278237,"= Rdt [Y | Z] + (1 −ρ)
sup
h∈H∗
Z,ds
EpY,Z | ¯
S,dt[ℓ(Y, h(Z)) −ℓ(Y, h∗(Z))]
(84)"
REFERENCES,0.5523415977961432,"> Rdt [Y | Z]
Lem. 3
(85)"
REFERENCES,0.5537190082644629,"Eq. (85) uses the following reasoning. 1 −ρ > 0 due to support mismatch. For any h ∈H∗
Z,ds such
that h ̸= h∗on ¯S (such an h exists by Item 1 of Assumption 2), we have that"
REFERENCES,0.5550964187327824,"EpY,Z | ¯
S,dt[ℓ(Y, h(Z)) −ℓ(Y, h∗(Z))] > 0
(86)"
REFERENCES,0.5564738292011019,by Lemma 3.
REFERENCES,0.5578512396694215,"As a corollary from the proof strategy we directly have that the optimal DG risk is simply R [Y | X].
This means that using the optimal encoder one can actually perform just as well by training on the
source as if you were to directly train on the target using the raw data."
REFERENCES,0.559228650137741,"Corollary 2 (Optimal IDG Risk). Under Assumptions 1 to 6, infpZ | X RIDG [Y | Z] = R [Y | X]."
REFERENCES,0.5606060606060606,Published as a conference paper at ICLR 2022
REFERENCES,0.5619834710743802,"B.3
IMPOSSIBILITY RESULTS"
REFERENCES,0.5633608815426997,"As a direct corollary of Thm. 2 we know that it is impossible to learn an optimal representation
without knowledge or assumptions on the target domain. We can actually prove the following much
stronger negative result, which essentially states that it is impossible to ﬁnd a useful representation
without having some information about the target domain. Speciﬁcally, we prove that if there exists a
non-trivial target domain on which the representation is advantageous then there exists an inﬁnite
amount of target domains on which it is disadvantageous compared to predicting from a constant."
REFERENCES,0.5647382920110193,"For clarity, we will focus on the proof for the standard accuracy (0-1 loss) which is much shorter
and simpler to understand, but note that we can generalize the proof to all losses with the right
assumptions."
REFERENCES,0.5661157024793388,"The key is that outside of the source domain, the label distribution is unconstrained because general-
ized covariate shift has no effect. In other words, for any domain which gives some probability mass
on an example that has not been seen during training, then all possible labels for that example gives
a valid domain. Furthermore, if there exists one domain on which the representation is good, then
one can construct a domain on which the representation is bad simply by labelling this point as the
constant prediction."
REFERENCES,0.5674931129476584,"Proposition 4 (No free lunch for learning representations for IDG, equiv. Proposition 1). Let ℓbe
the 0-1 loss with prediction space Γ = Y. Let Rep : P(X, Y) →P(Z|X) be any algorithm for
choosing an encoder pZ | X from the data distribution pX,Y , C be any constant r.v. that t.v.i. Z, and
pX,Y | ds be any desired source distribution such that"
REFERENCES,0.568870523415978,"• there is a unique constant prediction γC = arg miny∈Y EpY | ds [ℓ(Y, y)],"
REFERENCES,0.5702479338842975,• and |X \ supp(pX | ds)| > 1.
REFERENCES,0.571625344352617,"Let pZds | X := Rep(pX,Y | ds) be the chosen source encoder. If there exists a target domain pX,Y | dg
t
such that"
REFERENCES,0.5730027548209367,"• (Non-trivial support) ∅̸= supp(pX | dg
t ) ⊆X \ supp(pX | ds);"
REFERENCES,0.5743801652892562,"• (Satisﬁes Bayes image invariance) Γ∗
dg
t = Y, i.e., there is at least one example for every
possible label;"
REFERENCES,0.5757575757575758,"• (Source encoder is useful) pZds | X performs better than a constant representation,"
REFERENCES,0.5771349862258953,"sup
h∈H∗
Zds ,ds
Rdg
t
h [Y | Zds] <
sup
h∈H∗
C,ds
Rdg
t
h [Y | C] ,
(87)"
REFERENCES,0.5785123966942148,"Then there exist multiple target domains db
t such that pZds | X underperforms a constant encoder,"
REFERENCES,0.5798898071625345,"sup
h∈H∗
Zds ,ds
Rdb
t
h [Y | Zds] >
sup
h∈H∗
C,ds
Rdb
t
h [Y | C] .
(88)"
REFERENCES,0.581267217630854,"Proof. Let h∗∈H∗
Zds ,ds be any source Bayes predictor corresponding to our encoder. Partition Z
according to whether h∗predicts like the constant or not:"
REFERENCES,0.5826446280991735,"ZC :={z ∈Z | h∗(z) = γC}
Z̸=C := Z \ ZC.
(89)"
REFERENCES,0.5840220385674931,"We know by assumption that dg
t is s.t."
REFERENCES,0.5853994490358126,"sup
h∈H∗
Zds ,ds
Rdg
t
h [Y | Zds] <
sup
h∈H∗
C,ds
Rdg
t
h [Y | C] ,
(90)"
REFERENCES,0.5867768595041323,"which is clearly only possible if
PZds | dg
t (Z̸=C) > 0.
(91)"
REFERENCES,0.5881542699724518,"In other words, there exists some input x̸=C ∈X \ supp(pX | ds) that will get represented outside of
the constant region, i.e.,
PZds | x̸=C(Z̸=C) > 0.
(92)"
REFERENCES,0.5895316804407713,Published as a conference paper at ICLR 2022
REFERENCES,0.5909090909090909,"We will now construct the desired bad domain db
t by giving nearly all mass to this x̸=C, speciﬁcally,
let pX | db
t(x̸=C) = 1 −δ for some 0 < δ < 1. We assign this example to the constant label, i.e.,
pY | x̸=C,db
t(γC) = 1. The rest of the target domain mass δ is distributed as with the source domain,
i.e., pX,Y | db
t(x, y) = δ · pX,Y | ds(x, y) for all x, y ∈supp(pX,Y | ds). Importantly, the constructed
domain db
t is valid. Indeed, the Bayes image is the same as the source’s (Assumption 5), because
we removed no prediction γ from the source’s Bayes image (δ > 0). We added no new prediction γ,
because f ∗(x̸=C) = γC ∈Y which must already have been in Γ∗due to the validity of dg
t ."
REFERENCES,0.5922865013774105,"Now let us compute the desired risk for that “bad” domain and show that the desired encoder performs
worse than a constant encoder."
REFERENCES,0.59366391184573,"sup
h∈H∗
Zds ,ds
Rdb
t
h [Y | Zds]
(93)"
REFERENCES,0.5950413223140496,"=
sup
h∈H∗
Zds ,ds
(1 −δ) EpZds | x̸=C [1 −1[γC = h(Zds)]] + δ Rds
h [Y | Zds]
(94)"
REFERENCES,0.5964187327823691,"≥(1 −δ)(1 −PZds | x̸=C(ZC))
(95)"
REFERENCES,0.5977961432506887,"= (1 −δ)PZds | x̸=C(Z̸=C)
(96)"
REFERENCES,0.5991735537190083,"In contrast, it is easy to show that suph∈H∗
C,ds Rdb
t
h [Y | C] ≤δ because the constant predictor would"
REFERENCES,0.6005509641873278,"be perfect for x̸=C. So any choice of 0 < δ <
PZds | x̸=C (Z̸=C)"
REFERENCES,0.6019283746556474,"1+PZds | x̸=C (Z̸=C), would satisfy Eq. (88). We"
REFERENCES,0.6033057851239669,"conclude the proof by noting that there are inﬁnitely many such choices of δ, and any choice of those
would result in a different valid bad domain db
t."
REFERENCES,0.6046831955922864,"Note that representations can often be much worse than using a constant r.v. Speciﬁcally, if an
encoder pZ | X maps an x outside of the source support then there exists an inﬁnite number of target
domains where that representation is the worst possible representation."
REFERENCES,0.6060606060606061,"Proposition 5 (Worst representation). Let Rep, pY,X | ds, pZds | X, ℓbe as in Prop. 4, and ϵ > 0. If
there exists an example xb ∈X \ supp(pX | ds) that is mapped outside of the source support, i.e.,
supp(pZds | xb) ∩supp(pZ | ds) = ∅, then there exist many target domains pX,Y | dt s.t. pZds | X is ϵ
close to the worst possible loss, i.e.,"
REFERENCES,0.6074380165289256,"sup
h∈H∗
Zds ,ds
Rdt
h [Y | Zds] ≥1 −ϵ.
(97)"
REFERENCES,0.6088154269972452,"Proof. By assumption there exists an xb whose support is outside the source support. Then similarly
to Prop. 4 we construct a bad target domain dt by giving nearly all mass to that example pX | dt(xb) =
1 −δ where δ > 0 and assign with probability 1 to some label that is in the source Bayes image,
i.e., pY | xb,dt(γb) = 1 for some γb ∈Γ∗
ds. The rest of the target domain mass δ is distributed as in
Prop. 4 to the source inputs. As in Prop. 4, such a target domain dt satisﬁes our assumptions. Now let
us compute the risk for that dt and show that the desired encoder performs arbitrarily bad."
REFERENCES,0.6101928374655647,"sup
h∈H∗
Zds ,ds
Rdt
h [Y | Zds]
(98)"
REFERENCES,0.6115702479338843,"=
sup
h∈H∗
Zds ,ds
(1 −δ) EpZds | xb [1 −1[γb = h(Zds)]] + δ Rds
h [Y | Zds]
Eq. (94)
(99)"
REFERENCES,0.6129476584022039,"≥
sup
h∈H∗
Zds ,ds
(1 −δ) EpZds | xb [1 −1[γb = h(Zds)]]
(100)"
REFERENCES,0.6143250688705234,"= 1 −δ
(101)
Eq. (101) uses the fact that H∗
Zds ,ds is unconstrained outside of the source support and that by
assumption supp(pZds | xb) ∩supp(pZds | ds) = ∅. To achieve the sup 1 −δ it then sufﬁces to predict
an γ ̸= γb ∈Γ. We thus see that Eq. (97) holds for dt as long as 0 < δ < ϵ. We conclude the
proof by noting that there is an inﬁnite possible choices of δ each of which give rise to a bad target
domain."
REFERENCES,0.6157024793388429,Published as a conference paper at ICLR 2022
REFERENCES,0.6170798898071626,"B.4
AUGMENTATIONS"
REFERENCES,0.6184573002754821,"Proposition 2 shows that the optimal representations for IDG can be learned with augmentations in a
self-supervised fashion. Here, we provide formal deﬁnitions, assumptions, and proofs."
REFERENCES,0.6198347107438017,"Deﬁnition 6 (Augmenter). An augmenter is a conditional distribution pA | X : A × X →[0, 1] from
the input space X to an augmentation space A. For example, in CLIP X is the space of images and A
is the space of text. In standard SSL, A is typically the same as X (e.g., both X and A are the space
of images)."
REFERENCES,0.6212121212121212,"Deﬁnition 7 (Augmentation conditional set). Given an augmenter pA | X, deﬁne the augmentation
conditional set as the set of conditionals of A given X:"
REFERENCES,0.6225895316804407,"P∗(A | X) :=

pA | x | x ∈X
	
(102)"
REFERENCES,0.6239669421487604,"Similarly, we can deﬁne the augmentation conditional set for domain d:"
REFERENCES,0.6253443526170799,"P∗
d(A | X) :=

pA | x | x ∈supp(pX | d)
	
(103)"
REFERENCES,0.6267217630853994,"These sets are clearly countable. Note that the augmentation conditional set can be seen as a special
case of the Bayes image (Def. 3) if we view the augmentation A as the label and consider the log-loss
where the conditional distribution is the Bayes optimal predictor due to its strict properness (Gneiting
& Raftery, 2007)."
REFERENCES,0.628099173553719,"Assumption 7 (Finite augmentation entropy). We consider the augmenter pA | X such that the entropy
of the augmentation A is ﬁnite, i.e., H[A] < ∞."
REFERENCES,0.6294765840220385,Assumption 8 (Cardinalities). We assume that
REFERENCES,0.6308539944903582,"|Z| ≥|P∗(A | X)|
(104)"
REFERENCES,0.6322314049586777,"This is a similar assumption as Assumption 3, which ensures the existence of optimal representations."
REFERENCES,0.6336088154269972,"Assumption 9 (Domain-agnostic augmentation). We assume that the augmentation A is domain-
agnostic, i.e., the augmentation conditional set is invariant across domains,"
REFERENCES,0.6349862258953168,"P∗
d(A | X) = P∗(A | X),
∀d ∈D
(105)"
REFERENCES,0.6363636363636364,"This assumption is generalized from the constant Bayes image assumption (Assumption 5), which
guarantees the existence of optimal representations."
REFERENCES,0.6377410468319559,"Domain-agnostic augmentations essentially ensures that each augmentation conditional pA | x ∈
P∗(A | X) is seen at least once in all domains. If we introduce an equivalence relation ∼as x ∼x′
iff pA | x = pA | x′ and the equivalence class [x] := {x′ ∈X | x′ ∼x}. Under this relation, it is
easy to see that the above assumption is satisﬁed if and only if, for all possible equivalence classes
[x] ∈{[x′] | x′ ∈X}, we have that [x] has intersections with all domains:"
REFERENCES,0.6391184573002755,"[x] ∩supp(pX | d) ̸= ∅,
∀d ∈D
(106)"
REFERENCES,0.640495867768595,"Not all augmentations are domain-agnostic. In particular, the standard image augmentations used by
typical SSL models like SimCLR are not domain-agnostic, but the text-image augmentations of CLIP
nearly are, as discussed in the main body (Sec. 4)."
REFERENCES,0.6418732782369146,"Assumption 10 (Bayes-preserving augmentation). We assume that the augmentation A is Bayes-
preserving, i.e., ∀x, x′ ∈X,"
REFERENCES,0.6432506887052342,"pA | x = pA | x′ =⇒f ∗(x) = f ∗(x′).
(107)"
REFERENCES,0.6446280991735537,"Under the notion of equivalence relation in Assumption 9, this means that for each equivalence class
[x], all x′ ∈[x] have the same Bayes prediction. Note that most augmentations used in practice like
standard image augmentations are Bayes-preserving."
REFERENCES,0.6460055096418733,"Next, we show that under the above assumptions, we can learn optimal representations by maximizing
the mutual information I[A; Z] (in the case of log-loss ℓ) under the support match constraint. We use
log-loss simply because it is typically the loss used for training in practice. Note that the learned
representations are optimal for any strict proper losses."
REFERENCES,0.6473829201101928,Published as a conference paper at ICLR 2022
REFERENCES,0.6487603305785123,"Proposition 6 (Learning optimal representations without labels, equiv. Proposition 2). Let pA | X be
an augmenter. Under Assumptions 1 to 10, any encoder pZ | X such that"
REFERENCES,0.650137741046832,"pZ | X ∈arg max
pZ | X I[A; Z]
(108)"
REFERENCES,0.6515151515151515,"s.t.
∀d ∈D, supp(pZ | d) = supp(pZ)
(109)"
REFERENCES,0.6528925619834711,is optimal for idealized domain generalization.
REFERENCES,0.6542699724517906,"Proof. The support match constraint Eq. (109) is equivalent to the support match constraint Eq. (68).
Thus, Prop. 3 and Thm. 2 state that we only need to prove that maximizing the mutual information of
A and Z under the support constraint implies that"
REFERENCES,0.6556473829201102,"R [Y | Z] = R [Y | X] .
(110)"
REFERENCES,0.6570247933884298,We will prove this by constructing an optimal predictor h∗.
REFERENCES,0.6584022038567493,Since H[A] < ∞(Assumption 7) we have that
REFERENCES,0.6597796143250688,"arg max
pZ | X I[A; Z] = arg min
pZ | X H[A | Z] .
(111)"
REFERENCES,0.6611570247933884,"Note the fact that the conditional entropy is the Bayes risk under the log-loss (Gneiting & Raftery,
2007), i.e., H[A | Z] = R [A | Z]. By construction, A satisﬁes covariate shift w.r.t. X (thus Bayes
invariant) since A −X −D forms a Markov chain. Together with Assumptions 1 and 7 to 9, it means
that the optimization problem in Eqs. (108) and (109) satisﬁes the assumptions of Prop. 3, with A in
place of Y . Thus, an optimal encoder satisﬁes R [A | Z] = R [A | X], which leads to"
REFERENCES,0.662534435261708,"H[A | Z] = H[A | X] .
(112)"
REFERENCES,0.6639118457300276,"By Assumption 7, we can invoke Lemma 2 with the fact that A −X −Z forms a Markove chain to
show that for all (x, z) ∈supp(pX,Z)"
REFERENCES,0.6652892561983471,"pA | z = pA | x,
(113)"
REFERENCES,0.6666666666666666,as the conditional distributions are the Bayes optimal predictors due to strict properness of log-loss.
REFERENCES,0.6680440771349863,"Now, deﬁne the following equivalence relation on X,"
REFERENCES,0.6694214876033058,"x ∼x′
⇐⇒
pA | x = pA | x′.
(114)"
REFERENCES,0.6707988980716253,"Because the number of equivalence classes under ∼is countable, there exists a maximal invariant
M : X →N from X to the natural numbers (for our deﬁnition of a maximal invariant see Deﬁnition
2, Dubois et al., 2021). By Assumption 10, f ∗is invariant on the equivalence classes [x] := {x′ ∈
X | x′ ∼x} for all x ∈X. Thus, there exists a function g : N →A such that f ∗= g ◦M
(Lemma 5, Dubois et al., 2021). Given z ∈supp(pZ), we construct h∗in the following way. Let
xz ∈supp(pX | z) be any input point that could have led to this representation z and deﬁne"
REFERENCES,0.6721763085399449,"h∗(z) = g(M(xz)).
(115)"
REFERENCES,0.6735537190082644,"By Eq. (113) we are guaranteed that all x ∈supp(pX | z) share the same value for f ∗since they are
in the same equivalence class. Thus, by the deﬁnition of M we have that"
REFERENCES,0.6749311294765841,"M(xZ) = M(X)
for
(X, Z) ∼pX,Z.
(116)"
REFERENCES,0.6763085399449036,"Therefore,"
REFERENCES,0.6776859504132231,"Rh∗[Y | Z] = EpY,Z[ℓ(Y, h∗(Z)]
(117)"
REFERENCES,0.6790633608815427,"= EpY | XpX,Z[ℓ(Y, h∗(Z)]
(118)"
REFERENCES,0.6804407713498623,"= EpY | XpX,Z[ℓ(Y, g(M(xZ)))]
Eq. (115)
(119)"
REFERENCES,0.6818181818181818,"= EpY | XpX,Z[ℓ(Y, g(M(X)))]
Eq. (116)
(120)"
REFERENCES,0.6831955922865014,"= EpY | XpX,Z[ℓ(Y, f ∗(X))] = R [Y | X] .
(121)"
REFERENCES,0.6845730027548209,Published as a conference paper at ICLR 2022
REFERENCES,0.6859504132231405,"C
PRACTICAL OBJECTIVES"
REFERENCES,0.6873278236914601,"Proposition 6 provides an objective to obtain the desired optimal representations, compared to
Thm. 2 it is more practical in that it does not require direct access to the labels and in that it can use
augmentations under appropriate assumptions. There are nevertheless multiple remaining issues for
deriving objectives that can be trained with in practice. Speciﬁcally, (i) the support constraint is hard
to satisfy in practice; (ii) mutual information I[A; Z] is hard to estimate from samples (Poole et al.,
2019); (iii) the objective is constrained which is harder to optimize. We will now show different
objectives and variational bounds of them that do not suffer from these issues, and could still recover
the desired encoders in their optima. In contrast to the proofs of main theoretical results (previous
section), here the derivations will be less formal."
REFERENCES,0.6887052341597796,"As we have seen in Proposition 6, the optimal representation achieves I[A; Z] = I[A; X]. In the
following, we will rewrite the objective as the constrained optimization:"
REFERENCES,0.6900826446280992,"pZ | X ∈arg min
pZ | X B[Z, X, Y, D]
(122)"
REFERENCES,0.6914600550964187,"s.t.
I[A; Z] = I[A; X]
(123)"
REFERENCES,0.6928374655647382,"where we introduce the domain bottleneck B[Z, X, Y, D] as the objective for enforcing support
match (which we denote as B[Z, D] in the main body for simplicity). The requirement on the domain
bottleneck objective is that minimizing Eq. (122) under Eq. (123) implies that the support match
constraint holds (and can be achieved by some encoder), which leads to optimal representations for
IDG. Different domain bottlenecks will be derived later this section. We can then use Lagrangian
relaxation to get the following unconstrained objectives."
REFERENCES,0.6942148760330579,"arg min
pZ | X
−I[A; Z] + λ B[Z, X, Y, D]
(124)"
REFERENCES,0.6955922865013774,"The ﬁrst term can be easily optimized using variational bounds on MI. Throughout the paper, we will
use a contrastive variational lower bound which is based on InfoNCE (Oord et al., 2018). Namely, let
X be the input sample and A be the ‘positive’ augmentation sampled from pA | X. We then obtain n
‘negative’ augmentations

A−
i
	n
i=1 by ﬁrst independently sampling

X−
i
	n
i=1 from the marginal pX
and then sampling A−
i from pA | X−
i . It is easy to see that the negatives A−
i follow the marginal pA.
We construct A :=

A, A−
1 , . . . , A−
n
	
. Let Z be the representation of X by passing it through the
encoder pϕ := pZ | X parameterized by ϕ and sψ the critic function parametrized by ψ used to score
which A′ ∈A is the positive augmentation. Then we have the following variational lower bound
(Poole et al., 2019):"
REFERENCES,0.696969696969697,"I[A; Z] ≥log(n + 1) + EpA,X,Z"
REFERENCES,0.6983471074380165,"
log
exp sψ(A, Z)
P"
REFERENCES,0.699724517906336,"A′∈A exp sψ(A′, Z)"
REFERENCES,0.7011019283746557,"
(125)"
REFERENCES,0.7024793388429752,"In the case of unconstrained variational families sψ, pϕ and inﬁnite samples (n →∞), the above
variational bound recovers I[A; Z] up to a constant (see Oord et al. (2018); Dubois et al. (2021)).
Typically the critic is separable, i.e., sψ(A, Z) := gψ(A)T hψ(Z). As discussed in the main body, it
can be tied with the encoder pϕ when A = X."
REFERENCES,0.7038567493112947,"In the following we focus on the second term B[Z, X, Y, D] and discuss several choices."
REFERENCES,0.7052341597796143,"Throughout this section, the function M : X →N is the maximal invariant deﬁned in Prop. 6 via the
equivalence relation deﬁned in Eq. (114)."
REFERENCES,0.7066115702479339,"C.1
MUTUAL INFORMATION BOTTLENECK B[Z, X, Y, D] = I[Z; X]"
REFERENCES,0.7079889807162535,"The ﬁrst bottleneck we consider is so called mutual information (MI) bottleneck B[Z, X, Y, D] =
I[Z; X], which was introduced by Tishby et al. (2000) to achieve a tradeoff between the predictive
power and the complexity of representations. Intuitively, it tries to remove all information of Z that
is not needed for maximizing I[Z; A]. In particular, using the fact that Z −X −D forms a Markov
chain and the chain rule of MI, we have I[Z; X] = I[Z; X, D] = I[Z; D] + I[Z; X | D]. Thus, it
not only minimizes I[Z; D], i.e., matches the representations’ distribution across domains, but also
minimizes I[Z; X | D], i.e., matches the representations’ distribution inside domains."
REFERENCES,0.709366391184573,Published as a conference paper at ICLR 2022
REFERENCES,0.7107438016528925,"Why
The key to show is that minimizing Eq. (122), i.e., arg minpZ | X I[Z; X] under I[A; Z] =
I[A; X], implies the support match constraint. This can be seen as a speciﬁc subcase of Dubois
et al.’s (2021) Corollary 15 with A in place of Y and M(X) induced by pA | X as in the proof of
Prop. 6. From the corollary, we know that minpZ | X I[Z; X] = H[M(X)] which can be achieved
by any Z s.t. pZ | x = pZ | x′
⇐⇒
M(x) = M(x′). With the assumption of domain-agnostic
augmentations (Assumption 9), we have that the set of maximal invariant {M(x) | x ∈supp(pX | d)}
is invariant across domains. Then we directly have supp(pZ | d) = ∪x∈supp(pX | d)supp(pZ | x) =
∪x∈supp(pX)supp(pZ | x) = supp(pZ), where we use the fact that x within the same equivalence
class has the the same pZ | x."
REFERENCES,0.7121212121212122,"How
Essentially, we can use any variational upper bound of mutual information. We consider the
one used by Variational Information Bottelenck (Alemi et al., 2016), i.e.,"
REFERENCES,0.7134986225895317,"I[Z; X] = EpX,Z"
REFERENCES,0.7148760330578512,"
log pϕ(Z | X) pZ(Z)"
REFERENCES,0.7162534435261708,"
(126)"
REFERENCES,0.7176308539944903,"= EpX,Z"
REFERENCES,0.71900826446281,"
log pϕ(Z | X) qθ(Z)"
REFERENCES,0.7203856749311295,"
−DKL[pZ(Z)∥qθ(Z)]
(127)"
REFERENCES,0.721763085399449,"≤EpX,Z"
REFERENCES,0.7231404958677686,"
log pϕ(Z | X) qθ(Z)"
REFERENCES,0.7245179063360881,"
(128)"
REFERENCES,0.7258953168044077,"= EpX[DKL[pϕ(Z | X)∥qθ(Z)]]
(129)"
REFERENCES,0.7272727272727273,"where a variational distribution qθ is used to approximate pZ and is jointly optimized with pϕ to
minimize the bound. The approximation gap of the bound is DKL[pZ(Z)∥qθ(Z)]. Ignoring the
constant, the ﬁnal loss becomes"
REFERENCES,0.7286501377410468,"LMI(ψ, ϕ, θ) := EpX,A,Z"
REFERENCES,0.7300275482093664,"
−log
exp sψ(A, Z)
P"
REFERENCES,0.731404958677686,"A′∈A exp sψ(A′, Z) + λ DKL[pϕ(Z | X)∥qθ(Z)]

(130)"
REFERENCES,0.7327823691460055,"which recovers the optimal encoder in the case of unconstrained variational families for pϕ, qθ, sψ,
inﬁnite samples n →∞, and any λ > 1 (Dubois et al., 2021)."
REFERENCES,0.7341597796143251,"C.2
ENTROPY BOTTLENECK B[Z, X, Y, D] = H[Z]"
REFERENCES,0.7355371900826446,"The entropy (Ent) bottleneck introduced in the main body is a special case of the MI bottleneck,
where the encoder is a deterministic mapping, i.e., pϕ(Z | x) is a dirac delta function for all x ∈X
and we denote by eϕ(x) the deterministic encoder s.t. pϕ(eϕ(x) | x) = 1."
REFERENCES,0.7369146005509641,"Why
In the deterministic case, the MI bottleneck becomes the entropy bottleneck because I[X; Z] =
H[Z] −H[Z | X] = H[Z], where we use the fact that H[Z | X] = 0. Importantly, considering only
deterministic encoders does not constrain our ability to learning optimal encoders. Indeed, just as
with the MI bottleneck optimizing the objective with the entropy bottleneck under I[A; Z] = I[A; X]
will recover encoders s.t. eϕ(x) = eϕ(x′) ⇐⇒M(x) = M(x′), which also satisﬁes the support
match constraint as discussed before."
REFERENCES,0.7382920110192838,"How
Using the same derivation as the MI bottleneck, we can derive the variational upper bound on
entropy"
REFERENCES,0.7396694214876033,"H[Z] ≤EpZ[−log qθ(Z)]
(131)"
REFERENCES,0.7410468319559229,"which is the standard variational bound used in neural compression (Ballé et al., 2016; Theis et al.,
2017). Putting all together, we have"
REFERENCES,0.7424242424242424,"LEnt(ψ, θ, ϕ) := EpX,A,Z"
REFERENCES,0.743801652892562,"
−log
exp sψ(A, Z)
P"
REFERENCES,0.7451790633608816,"A′∈A exp sψ(A′, Z) −λ log qθ(Z)

(132)"
REFERENCES,0.7465564738292011,"which also recovers the optimal encoder with unconstrained variational families, inﬁnite samples, and
λ > 1 as with the MI bottleneck. The detialed algorithm is provided in Algorithm 2. Note that the
discreteness of Z could lead to difﬁculty of gradient-based optimization, and we follow Ballé et al.
(2016) to add uniform noise to Z as a differentiable substitute for rounding during training. In our
experiments, we will mostly use the Ent bottleneck instead of the MI bottleneck to avoid introducing
stochastic encoders."
REFERENCES,0.7479338842975206,Published as a conference paper at ICLR 2022
REFERENCES,0.7493112947658402,Algorithm 2 Ent objective
REFERENCES,0.7506887052341598,"Require: eϕ, sψ, qθ, X, n"
REFERENCES,0.7520661157024794,"1: Z ←eϕ(X)
2: A ←sample(pA | X)"
REFERENCES,0.7534435261707989,"3: {(X
−
i , A
−
i )}n
i=1
i.i.d.
←−−sample(pX,A)
4: A ←{A} ∪{A
−
i }n
i=1
5: Laug ←−log
exp sψ(A,Z)
P"
REFERENCES,0.7548209366391184,"A′∈A exp sψ(A′,Z) ▷−I[A; Z]"
REFERENCES,0.756198347107438,"6: Lsupp ←−log qθ(Z)
▷H[Z]
7: return LEnt = Laug + λLsupp"
REFERENCES,0.7575757575757576,"C.3
CONTRASTIVE ADVERSARIAL DOMAIN BOTTLENECK B[Z, X, Y, D] = I[Z; D]"
REFERENCES,0.7589531680440771,"The previous two bottlenecks require removing the information of Z (about X) as much as possible,
which seems to be unnecessary since our ultimate goal is to match the support of Z across domains.
Now we introduce a bottleneck B[Z, X, Y, D] = I[Z; D] which we only seek to remove the informa-
tion of Z about the domain D. This is very related to the work on invariant representation learning
for domain generalization/adaptation (e.g., Ganin et al., 2016; Li et al., 2018a). We derive a new
variational bound called the contrastive adversarial domain (CAD) bottleneck that is more stable to
train and leads to better empirical performance. For simplicity we consider the deterministic encoder
eϕ(x) as with the main body."
REFERENCES,0.7603305785123967,"Why
Similar to the previous analysis, we aim to show that arg minpZ | X I[Z; D] under I[A; Z] =
I[A; X] leads to the support match constraint. Using Eq. (116) we have I[Z; D] = I[Z, M(XZ); D] =
I[Z, M(X); D] = I[M(X); D] + I[Z; D | M(X)] where the last equality uses the chain rule of
mutual information. Due to the non-negativity of (conditional) mutual information, we have that
the minimum of I[Z; D] under I[A; Z] = I[A; X] is I[M(X); D]. Then we show the minimum is
achievable by constructing the same optimal encoder eϕ(X) as the Ent bottleneck which clearly
satisﬁes I[Z; D | M(X)] = 0. It is then easy to show that the support match constraint has to hold
when I[Z; D | M(X)] = 0 by contrapositive. Indeed, suppose that the support constraint does not
hold then it must be true that I[Z; D | M(X)] > 0 and so the encoder cannot be optimal."
REFERENCES,0.7617079889807162,"How
The typical way of minimizing I[Z; D] is to derive the variational bound as"
REFERENCES,0.7630853994490359,"I[Z; D] = H[D] −H[D | Z]
(133)"
REFERENCES,0.7644628099173554,"= (const) −EpD,Z

−log pD | Z(D | Z)

(134)"
REFERENCES,0.7658402203856749,"≥(const) −EpD,Z[−log qφ(D | Z)]
(135)"
REFERENCES,0.7672176308539945,"where a variational distribution (or domain classiﬁer) qφ is used to approximate pD | Z and jointly
trained to maximize the bound. This recovers the domain-adversarial training method as introduced
in Ganin et al. (2016). However, this has two potential issues: 1) it gives a lower bound instead of
the desired upper bound on I[Z; D]; 2) it requires adversarial training which is not stable in practice
(Goodfellow, 2016; Kodali et al., 2017)."
REFERENCES,0.768595041322314,"We propose the contrastive adversarial domain (CAD) bottleneck, which is based on the above explicit
version but uses a variational distribution qφ(D | Z) that is tied with other parts of the model, thus no
need to learn a domain classiﬁer. Suppose we have access to a set of inputs X, we ﬁrst introduce a
contrastive variational distribution qϕ,X(X | Z) of pX | Z as"
REFERENCES,0.7699724517906336,"qϕ,X(X | Z) :=
exp sϕ(X, Z)
P"
REFERENCES,0.7713498622589532,"X′∈X exp sϕ(X′, Z)
(136)"
REFERENCES,0.7727272727272727,"where sϕ(X, Z) := eϕ(X)T Z is tied with the encoder eϕ. Note that qϕ,X has support over X, and
equals pX | Z when sϕ(X, Z) ∝log pX,Z(X, Z) and X recovers X. In practice, we use a variety of
crude approximations. Our ﬁrst crude approximation is that we use the minibatch of samples, i.e., the
independently sampled

X−
i
	n
i=1 as X. Now, since pD | Z can be rewritten as EpX | Z

pD | X

using
the fact that D −X −Z forms a Markov chain, we obtain the following variational distribution:"
REFERENCES,0.7741046831955923,"qϕ,X(D | Z) = Eqϕ,X

pD | X(D | X)

(137)"
REFERENCES,0.7754820936639119,Published as a conference paper at ICLR 2022
REFERENCES,0.7768595041322314,"which recovers pD | Z when qϕ,X = pX | Z. Note that pD | X is still not available. For our second
crude approximation, we use a count estimate ˆpD,X. In particular, we obtain a collection D by taking
each X′ ∈X and independently sampling D′ from pD | X′ to get D := {D
−
i }n
i=1. In other words,
{(D
−
i , X
−
i )}n
i=1 are all i.i.d. sampled from pD,X. Then we use a count estimate"
REFERENCES,0.778236914600551,"ˆpD,X(d | x) =
Pn
i=1 I (X
−
i = x, D
−
i = d)
Pn
i=1 I (X
−
i = x)
(138)"
REFERENCES,0.7796143250688705,which is an accurate estimate with inﬁnite samples. This leads to our ﬁnal variational distribution:
REFERENCES,0.78099173553719,"qϕ,X,D(D | Z) =
X"
REFERENCES,0.7823691460055097,"X′∈X
qϕ,X(X′ | Z)ˆpD,X(D | X′)
(139)"
REFERENCES,0.7837465564738292,Putting all together we get that the loss:
REFERENCES,0.7851239669421488,"LCAD(ϕ, ψ) := EpD,X,A.Z """
REFERENCES,0.7865013774104683,"−log
exp sψ(A, Z)
P
A′∈A exp sψ(A′, Z) + λ log X"
REFERENCES,0.7878787878787878,"X′∈X
qϕ,X(X′ | Z)ˆpD,X(D | X′) !# ."
REFERENCES,0.7892561983471075,"(140)
In practice, ˆpD,X(D | X) is typically a dirac delta function since it is rare to have the same samples
in a minibatch. Thus, in Eq. (139) we only need to sum qϕ,X(X′ | Z) over those associated with
the same domain label D as X, i.e., XD :={X
−
i | D
−
i = D, i ∈[n]} where [n] :={1, . . . , n}. This
leads to the simpliﬁed loss:"
REFERENCES,0.790633608815427,"LCAD(ϕ, ψ) := EpD,X,A,Z """
REFERENCES,0.7920110192837465,"−log
exp sψ(A, Z)
P"
REFERENCES,0.7933884297520661,"A′∈A exp sψ(A′, Z) + λ log X"
REFERENCES,0.7947658402203857,"X′∈XD
qϕ,X(X′ | Z) !#"
REFERENCES,0.7961432506887053,. (141)
REFERENCES,0.7975206611570248,"In practice, we ﬁnd that the second term that minimizes the log probability leads to numerical
instability. Intuitively, this could be seen by the exploding gradient of the function log(p) when
p →0. We thus replace it with −log(1 −p) which has the same optima. I.e. in practice we
maximize the log of the probablity summed over X¬D := X \ XD. This reduces Eq. (141) to Eq. (7)
described in the main body with a detailed algorithm in Algorithm 1. Note that it is easy to generalize
Algorithm 1 to parallel computation within a batch of samples. Indeed, for each sample in the batch,
we can view all other samples in the batch as negatives and compute the loss efﬁciently in parallel."
REFERENCES,0.7988980716253443,"C.4
CONDITIONAL CAD B[Z, X, Y, D] = I[Z; D | Y ]"
REFERENCES,0.800275482093664,"The analysis of the CAD bottleneck also implies that we can minimize the conditional mutual
information I[Z; D | M(X)] if we have access to M(X). However, since M(X) is typically not
available in practice, we consider the special case where M(X) = Y . In particular, this is the case
where the labels are available and the supervised augmentations are used (see Fig. 2b). This reduces
the bottleneck to B[Z, X, Y, D] = I[Z; D | Y ] which is related to the conditional version of the
domain-adversarial neural network (Li et al., 2018b). In practice, minimizing I[Z; D | Y ] could be
easier for optimization than I[Z; D], as it does not require to remove the information that D has about
Y . In the following, we derive the conditional CAD (C2AD) bottleneck using a similar idea as CAD."
REFERENCES,0.8016528925619835,"How
In this case, we want to minimize"
REFERENCES,0.803030303030303,"I[Z; D | Y ] = H[D | Y ] −H[D | Z, Y ]
(142)
= (const) −H[D | Z, Y ]
(143)
≥(const) −EpD,Z,Y [−log q(D | Z, Y )]
(144)"
REFERENCES,0.8044077134986226,"where q(D | Z, Y ) is a variational distribution of pD | Z,Y . Similar to the unconditional case, we
also aim to use a non-parametric approximation that is tied with other parts of the model, and we
obtain it using the fact pD | Z,Y = EpX | Z,Y

pD | X

. Speciﬁcally, let Y be the label of input X
sampled from pY | X and Y :={Y
−
1 , . . . , Y −
n } be the collection of labels obtained by independently
sampling the label from pY | X′ for each X′ ∈X. We collect samples associated with the label Y ,
i.e., XY :={X
−
i | Y
−
i
= Y, i ∈[n]} and obtain a variational distribution of pX | Z,Y :"
REFERENCES,0.8057851239669421,"qϕ,X,Y(X | Z, Y ) :=
exp sϕ(X, Z)
P"
REFERENCES,0.8071625344352618,"X′∈XY exp sϕ(X′, Z)
(145)"
REFERENCES,0.8085399449035813,Published as a conference paper at ICLR 2022
REFERENCES,0.8099173553719008,"where we use the same critic sϕ(X, Z) := eϕ(X)T Z that is tied with the encoder eϕ as before, but
only take softmax over those samples with the same label Y . For the term pD | X, we use the same
count estimate ˆpD,X in Eq. (138). Then we obtain the variational distribution of pD | Z,Y :"
REFERENCES,0.8112947658402204,"qϕ,X,D,Y(D | Z, Y ) =
X"
REFERENCES,0.8126721763085399,"X′∈XY
qϕ,X,Y(X′ | Z, Y )ˆpD,X(D | X′)
(146)"
REFERENCES,0.8140495867768595,Putting all together we get that the ﬁnal loss:
REFERENCES,0.8154269972451791,"LC2AD(ϕ, ψ) := EpD,X,A,Y,Z """
REFERENCES,0.8168044077134986,"−log
exp sψ(A, Z)
P
A′∈A exp sψ(A′, Z) + λ log X"
REFERENCES,0.8181818181818182,"X′∈XY
qϕ,X,Y(X′ | Z, Y )ˆpD,X(D | X′) !# ."
REFERENCES,0.8195592286501377,"(147)
Again, since in practice ˆpD,X(D | X) is typically a dirac delta function, the summation in Eq. (146)
can be done only over those associated with the same label Y and the same domain label D as X,
i.e., XY,D := {X
−
i | Y
−
i
= Y, D
−
i = D, i ∈[n]}. Similarly, instead of minimizing the log of the
probability summed over XY,D, we maximize the log of the probability summed over XY,¬D :=
XY \ XY,D ={X
−
i | Y
−
i
= Y, D
−
i ̸= D, i ∈[n]}. Finally we obtaine the simpliﬁed loss:"
REFERENCES,0.8209366391184573,"LC2AD(ϕ, ψ) := EpD,X,A,Y,Z "
REFERENCES,0.8223140495867769,"−log
exp sψ(A, Z)
P"
REFERENCES,0.8236914600550964,"A′∈A exp sψ(A′, Z) −λ log  
X"
REFERENCES,0.8250688705234159,"X′∈XY,¬D
qϕ,X,Y(X′ | Z, Y )    ."
REFERENCES,0.8264462809917356,"(148)
A detailed algorithm is in Algorithm 3."
REFERENCES,0.8278236914600551,Algorithm 3 conditional CAD (C2AD) objective
REFERENCES,0.8292011019283747,"Require: eϕ, sψ, D, X, Y, n"
REFERENCES,0.8305785123966942,"1: Z ←eϕ(X)
2: A ←sample(pA | X) 3:"
REFERENCES,0.8319559228650137,"
(D−
i , X−
i , A−
i , Y −
i )
	n
i=1
i.i.d.
←−−sample(pD,X,A,Y )
4: X, A ←

X−
i
	n
i=1,{A} ∪

A−
i
	n
i=1
5: XY ←

X−
i | Y −
i
= Y, i ∈[n]"
REFERENCES,0.8333333333333334,"6: XY,¬D ←

X−
i | Y −
i
= Y, D−
i ̸= D, i ∈[n]"
REFERENCES,0.8347107438016529,"7: Laug ←−log
exp sψ(A,Z)
P
A′∈A exp sψ(A′,Z)
▷−I[A; Z]"
REFERENCES,0.8360881542699724,8: Lsupp ←−log
REFERENCES,0.837465564738292,"P
X′∈XY,¬D exp eϕ(X′)T Z
P
X′′∈XY exp eϕ(X′′)T Z
▷I[Z; D | Y ]"
REFERENCES,0.8388429752066116,9: return LC2AD = Laug + λLsupp
REFERENCES,0.8402203856749312,Published as a conference paper at ICLR 2022
REFERENCES,0.8415977961432507,"D
EXTENDED RELATED WORK"
REFERENCES,0.8429752066115702,"Provably optimal representations. Many previous work have theoretically studied advantages of
representations in various two-stage settings (representation learning followed by standard training of
predictors) by bounding downstream performance (e.g., Ben-David et al., 2007; Shamir et al., 2010;
Saunshi et al., 2019). As learning theoretical bounds can be loose, it is hard to know whether they give
the right insights into the problem. Our work instead proves the properties of optimal representations,
which ensure best downstream performance. Those properties need to be approximated but give the
right insights into what to aim for. This perspective and our proofs were inspired by Dubois et al.
(2020) who gives sufﬁcient conditions for optimal representations in supervised learning."
REFERENCES,0.8443526170798898,"E
EXPERIMENTAL DETAILS"
REFERENCES,0.8457300275482094,"E.1
SCIENTIFIC"
REFERENCES,0.8471074380165289,"In both the scientiﬁc setting and the following bridge setting, we consider rather unrealistic setups
for verifying our theory where we have access to labels from all domains. We can choose to directly
minimize the risk R [Y | Z] with the cross-entropy loss (denoted as CE henceafter), or minimize
H[A | Z] (i.e., maximize I[A; Z]) with supervised augmentations as in Fig. 2b detailed below."
REFERENCES,0.8484848484848485,"Implementation of supervised augmentations
When using supervised augmentations, for each
sample we obtain its augmentations from within its label class across all domains. A constrastive
loss with such augmentations will essentially reduce to the supervised contrast loss (SupCon, Khosla
et al., 2020). In particular, for a single sample in a batch, all samples in the batch with the same
labels can be used as the positives (could come from the same domain or different domains) and
others as the negatives. In Khosla et al. (2020), two variants of SupCon loss were introduced for
solving the issue of multi-positives depending on whether the summation over multi-positives was
located inside (SupCon-In, Eq. (3) in Khosla et al. (2020)) or outside (SupCon-Out, Eq. (2) in Khosla
et al. (2020)) the log. Though Khosla et al. (2020) chose SupCon-Out because it worked better
than SupCon-In, we hypothesized that this is because SupCon-Out has an implicit bottleneck effect.
Intuitively, SupCon-Out upper bounds SupCon-In and achieves its optima only if the logits with
positive samples are all the same by Jensen’s inequality, which may encourage positive samples from
different domains to get clustered. Since this might confound with the effect of our bottlenecks,
we chose to use SupCon-In though it performed slightly worse in out initial experiments. For the
implementation of SupCon, we followed Khosla et al. (2020) except that no projection was used.
Speciﬁcally, the temperature was set to 0.1, and normalization was applied when computing the
logits."
REFERENCES,0.849862258953168,"In the scientiﬁc setting, we tried to simulate our theory to the greatest extent. In particular, we had
two special considerations as detailed below:"
REFERENCES,0.8512396694214877,"Eliminating empirical generalization
As our theory focuses on the idealized domain generaliza-
tion that assumes access to population distribution, we considered the setup where the empirical
generalization was eliminated. Speciﬁcally, we treated the dataset as the population distribution and
used the same dataset for training the encoder and training/evaluating the predictor. The ResNet-18
encoder was trained to 300 epochs without any regularization, using the Adam optimizer (Kingma &
Ba, 2014) with a learning rate of 5e-5, a batch size of 192 (48 for each domain), and a cosine learning
rate decay schedule."
REFERENCES,0.8526170798898072,"Worst-case approximation
To approximate the worst-case source predictor, we included the target
data with randomly assigned wrong labels to the training set for training the source predictor. The
target data samples were down-weighted with a sample weight that maximizes the target risk while
keeping the source risk close to optima (which is 0). We selected the sample weight by sweeping
over [10−10, 1] with a logarithmic scale using CE-Base and SupCon-Base, as shown in Fig. 4. As
the sample weight increases, the target log likelihood (neg. risk) ﬁrst decreases and then increases.
We hypothesized that the increasing trend was due to that the source performance was already not
optimal (though not visible from the ﬁgure), thus we selected the weight close to the turning point and
10−5 seemed to be reasonable for both CE-Base and SupCon-Base. Although we did not adaptively
select the sample weight for each setup due to the computational cost, the pre-speciﬁed sample turned"
REFERENCES,0.8539944903581267,Published as a conference paper at ICLR 2022
REFERENCES,0.8553719008264463,"10
9
10
7
10
5
10
3
10
1"
REFERENCES,0.8567493112947658,sample weight 6 4 2 0
REFERENCES,0.8581267217630854,Log likelihood
REFERENCES,0.859504132231405,(a) CE-Base
REFERENCES,0.8608815426997245,"10
9
10
7
10
5
10
3
10
1"
REFERENCES,0.8622589531680441,sample weight 5 4 3 2 1 0
REFERENCES,0.8636363636363636,Log likelihood
REFERENCES,0.8650137741046832,"source
target"
REFERENCES,0.8663911845730028,(b) SupCon-Base
REFERENCES,0.8677685950413223,"Figure 4: Sweeping the sample weight using CE-Base and SupCon-Base. We selected 10−5 which
seemed to be reasonble for both cases."
REFERENCES,0.8691460055096418,"out to be reasonable for all other losses and different λ combinations. Furthermore, we also removed
regularization when training the linear classiﬁer and initialized the linear weight i.i.d. from N(0, 1)."
REFERENCES,0.8705234159779615,"Next, we provide other experimental details for reproducibility:"
REFERENCES,0.871900826446281,"Implementation of standard augmentations
We followed SimCLR (Chen et al., 2020) for imple-
menting standard image augmentations. For a fair comparison between the cases when using standard
augmentations (SimCLR) and supervised augmentations (SupCon), we kept the total batch size the
same and also used the same conﬁgurations for computing the SupCon loss, i.e., temperature set to
0.1, no projection, and normalization applied."
REFERENCES,0.8732782369146006,"Details of Fig. 3c
In Fig. 3c, we considered different choices of augmentations. The ‘Standard‘
augmentation implementation is described above (Appx. E.1). The ‘Supervised’ augmentation was
essentially implemented using the SupCon loss as described in Appx. E.1. For other augmentations
considered, we implemented them by dropout inter-domain supervised augmentations in SupCon.
Speciﬁcally, for each sample in the batch, we randomly masked the samples from different domains
(i.e., both inter-domain positives and negatives) i.i.d. with the speciﬁed dropout probability, while
samples within the same domain were always kept. ‘IntraDom’ and ‘ApproxDA’ correspond to
dropout probability 1 and 0.9, respectively. ‘SingleDom’ were implemented by dropout all inter-
domain samples with probability 1 except for a ﬁxed domain (the ‘A’ domain of PACS in our
case)."
REFERENCES,0.8746556473829201,"E.2
BRIDGE"
REFERENCES,0.8760330578512396,"In the bridge setting (see Appx. F.2), we aimed to bridge the gap between our theoretical setup to the
practical setup. The main differences from the scientiﬁc setups are that the empirical generalization
gap is considered and the average-case source predictor is used, as detailed below:"
REFERENCES,0.8774104683195593,"Incorporating empirical generalization
In practice, empirical-generalization gap should also be
considered besides the source-target generalization gap. Thus, we randomly split the PACS dataset
to 80% training and 20% validation splits for each domain. The training splits were used to train
both the encoder and the source predictor, and the validation splits were used for encoder and source
predictor selection as well as evaluation on target domains. We used the ResNet-50 model as the
encoder and initialized it from ImageNet pretrained model. The encoder was trained to a maximum of
50 epochs with a 1e-5 weight decay, using the Adam optimizer (Kingma & Ba, 2014) with a learning
rate of 5e-5, a batch size of 112 (28 for each domain), and a cosine learning rate decay schedule."
REFERENCES,0.8787878787878788,"Using average-case source predictor
Instead of approximating the worst-case source predictor in
the scientiﬁc setting, we considered the average-case3 source predictor which is closer to the common
practice. Speciﬁcally, we freezed the encoder and trained a SVM classiﬁer with L2 regularization on"
REFERENCES,0.8801652892561983,"3Here we have a slight abuse use of the phrase ‘average-case’ to distinguish from the ‘worst-case’ that we
use in the scientiﬁc setting. In fact, the source predictor could be close to the ‘best-case’ since the max-margin
classiﬁer (SVM) was used."
REFERENCES,0.8815426997245179,Published as a conference paper at ICLR 2022
REFERENCES,0.8829201101928374,"the source training split. The regularization parameter was tuned over {1e-4, 1e-3, 1e-2, 1e-1, 1, 1e1,
1e2, 1e3} with the source validation accuracy."
REFERENCES,0.8842975206611571,"Next, we provide other experimental details for reproducibility:"
REFERENCES,0.8856749311294766,"Selection of λ
For all different setups considered in bridge settings, the CAD bottleneck was used
and the λ was tuned over {1e-3, 1e-2, 1e-1, 1, 1e1} independently for each."
REFERENCES,0.8870523415977961,"E.3
DOMAINBED"
REFERENCES,0.8884297520661157,"Datasets
We used non-MNIST datasets on DomainBed that were non-synthetic, including VLCS
(Fang et al., 2013), PACS (Li et al., 2017), OfﬁceHome (Venkateswara et al., 2017), TerraIncognita
(Beery et al., 2018), and DomainNet (Peng et al., 2019). For each dataset, we split it to 80%/20%
training/validation set according to DomainBed."
REFERENCES,0.8898071625344353,"SSL-based models & Training
For all models based on pretrained SSL models (either CLIP-based
or DINO-based) with ﬁnetuning in this experiment, we freezed the pretrained SSL model and added
on top a 1-layer MLP with hidden size 1024, and residual connection. We used CLIP ResNet-50
(CLIP S) to obtain the best possible fair comparison with baselines from DomainBed, and CLIP
ViT-B/32 (CLIP L) to achieve the best results. Note that the ResNet-50 model of CLIP S was
modiﬁed as described in Radford et al. (2021) and contained 38M parameters (more than 23M of
the original CLIP). The model was trained to 300 epochs for DomainNet and 50 epochs on other
datasets (an epoch is deﬁned as a single pass over the smallest domain according to DomainBed). No
data augmentation was used and the temperature for scaling the logits in CAD was ﬁxed to 0.05. We
used the Adam optimizer with a 1e-5 weight dacay, and a cosine learning rate decay schedule. The
hyperparameter search space is:"
REFERENCES,0.8911845730027548,"• Learning rate: discrete set {1e-4, 3e-4, 1e-3, 3e-3}"
REFERENCES,0.8925619834710744,"• Batch size: discrete set {128, 256, 512} for DomainNet and OfﬁceHome, and {64, 128,
256} for other datasets"
REFERENCES,0.8939393939393939,"• MLP dropout: discrete set {0., 0.1, 0.5}"
REFERENCES,0.8953168044077136,"• Learning rate warmup: discrete set {True, False}"
REFERENCES,0.8966942148760331,"End-to-end models & Training
In Table 1, we also included an end-to-end trained model without
any pretrained SSL models. We used exactly the same model architecture (the original ResNet-
50, initialized from ImageNet pretrained model), training procedure and evaluation protocal as
baselines on DomainBed. Importantly, the linear classiﬁer was jointly trained with the encoder, and
no reﬁtting was applied. The model was trained to a maximum of 5000 steps on each dataset, and
data augmentations were applied. The Adam optimizer was used without any particular learning
rate schedule. The hyperparameter search space is (same as DomainBed except we added the
temperature):"
REFERENCES,0.8980716253443526,"• Learning rate: log-uniform over [1e-5, 1e-3.5]"
REFERENCES,0.8994490358126722,"• Batch size: log-uniform over [8, 64] for DomainNet, and [8, 25.5] for other datasets"
REFERENCES,0.9008264462809917,"• MLP dropout: discrete set {0., 0.1, 0.5}"
REFERENCES,0.9022038567493113,"• Weight decay: log-uniform over [1e-6, 1e-2]"
REFERENCES,0.9035812672176309,"• Temperature: discrete set {0.05, 0.1}"
REFERENCES,0.9049586776859504,"Linear Probe Evaluation
In all the experiments except for the end-to-end training setup, we
always followed the procedure of two-stage training, where we ﬁrst trained the encoder with speciﬁed
objectives, and then reﬁt the classiﬁer. For datasets except DomainNet, we ﬁtted the SVM classiﬁer
and tuned the regularization parameter over {1e-4, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3} with source
validation selection. Since DomainNet was too large and SVM cannot ﬁt it efﬁciently, we used the
logistic regression classiﬁer which was trained with a batch size 512, the Adam optimizer with a
learning rate 5e-4 and early stopping. Note that an alternative was to just use the linear head ﬁtted
when training the representor (as we used CE loss with source labels), and we found this could work
better than reﬁtting since the classiﬁer was less overﬁtted to the source domain. However, we didn’t
do that since we wanted to stick to the representation learning protocol with two-stage training. We"
REFERENCES,0.90633608815427,Published as a conference paper at ICLR 2022
REFERENCES,0.9077134986225895,"did that in our end-to-end training setup since we wanted it to be compeletely comparable to baselines
on DomainBed (which did not do reﬁtting)."
REFERENCES,0.9090909090909091,"Selection of λ
In our experiments, we treated λ as a special hyperparamter. For each model, we
used the same λ selected on PACS on all datasets except DomainNet, because our bottleneck is fairly
robust to the choice of λ. For the large-scale DomainNet dataset, we selected its λ individually. The
λ values chosen for each model were:"
REFERENCES,0.9104683195592287,• CLIP S: 1 on DomainNet and 1e-2 on other datasets
REFERENCES,0.9118457300275482,• CLIP L: 1e-1 on DomainNet and 1e-2 on other datasets
REFERENCES,0.9132231404958677,• DINO: 1e-1 on all datasets
REFERENCES,0.9146005509641874,• End-to-end ResNet-50: 1e-5 on all datasets
REFERENCES,0.9159779614325069,"E.4
LAION"
REFERENCES,0.9173553719008265,"Model
We used the CLIP L model (i.e., CLIP ViT-B/32) with an additional network on top for
ﬁnetuning. The additional network were two blocks of 2-layer MLP, each with hidden size 2048,
pre-activation batch normalization, residual connection, and dropout probability 0.1. Note that the
original CLIP L model was frozen and only the additional network was trained."
REFERENCES,0.918732782369146,"Dataset
We used the LAION-400M dataset which contained 400 million image-text pairs for
training. Though the dataset might not be as clean as the original CLIP training data (as evidenced by
our experimental results), it was the largest publicly available image-text-pair dataset that we could
get access to. As we froze the CLIP L model and only did ﬁnetuning, we used the 1TB preprocessed
embeddings provided by LAION-400M4. No further preprocessing was applied."
REFERENCES,0.9201101928374655,"Training
We used the image-text contrastive loss as introduced in Radford et al. (2021) for training
model. The temperature was learnable which was initialized as 0.07 and clipped with a minimum
0.01. The model was trained for 1 epoch using the Adam optimizer with a batch size of 16384 and a
cosine learning rate decay schedule. The learning rate was tuned over the set {3e-5, 1e-4, 3e-4, 1e-3,
3e-3, 1e-2} and the λ value for the Ent bottleneck was tuned over {1e-3, 1e-2, 1e-1, 1, 1e1}."
REFERENCES,0.9214876033057852,"Evaluation
For the evaluation on the ImageNet-related datasets, we followed a similar procedure in
Radford et al. (2021), where a linear classiﬁer was ﬁtted on ImageNet using the model representations
and evaluated on 7 natural distribution shift datasets. In particular, we ﬁtted a logistic regression
classiﬁer with 1e-5 L2 regularization on ImageNet training set which was trained with a batch size
512, the Adam optimizer with a learning rate 3e-4 and early stopping. Note that this was different
from Radford et al. (2021), where a logistic regression classiﬁer was ﬁtted using full-batch data
with decent hyperparameter tuning, due to our computational budget. For evaluation on natural
distribution shift datasets, we followed Taori et al. (2020) and used their released testbed5. The
evaluation datasets and their abbreviations used in Table 2 were: ImageNetV2 (IN-V2, Recht et al.,
2019), ImageNet-Sketch (IN-S, Wang et al., 2019), Youtube-BB (YT-BB, Shankar et al., 2019),
ImageNet-Vid (IN-Vid, Shankar et al., 2019), ObjectNet (Barbu et al., 2019), ImageNet Adversarial
(IN-A, Hendrycks et al., 2021), and ImageNet Rendition (IN-R Hendrycks et al., 2020)."
REFERENCES,0.9228650137741047,"4See https://laion.ai/laion-400-open-dataset/ for details.
5https://github.com/modestyachts/imagenet-testbed"
REFERENCES,0.9242424242424242,Published as a conference paper at ICLR 2022
REFERENCES,0.9256198347107438,"F
ADDITIONAL EXPERIMENTAL RESULTS"
REFERENCES,0.9269972451790633,"F.1
SCIENTIFIC"
REFERENCES,0.928374655647383,"10
2
100
102
104
6 5 4 3 2 1"
REFERENCES,0.9297520661157025,Log likelihood
REFERENCES,0.931129476584022,"Base
CAD
Ent"
REFERENCES,0.9325068870523416,(a) CE (R [Y | Z]) objectives
REFERENCES,0.9338842975206612,"10
2
100
102
104 4 3 2 1 0"
REFERENCES,0.9352617079889807,Log likelihood
REFERENCES,0.9366391184573003,"Base
CAD
Ent"
REFERENCES,0.9380165289256198,(b) SupCon (H[A | Z]) objectives
REFERENCES,0.9393939393939394,Figure 5: The worst-case DG performance of Ent bottleneck is more sensitive to λ than CAD
REFERENCES,0.940771349862259,"What’s the effect of λ for different objectives on the worst-case DG performance?
In Fig. 5,
the worst-case target log likelihood versus λ values for different objectives is shown. We found that
Ent is much more sensitive to the choice of λ than CAD, which was part of the reason why we used
the latter in most of our experiments. Note that for SupCon-Ent with small λ values, it was worse
than SupCon-Base because of the discretization introduced by the Ent bottleneck, which we veriﬁed
by observing that setting λ = 0 lead to similar results."
REFERENCES,0.9421487603305785,"F.2
BRIDGE"
REFERENCES,0.9435261707988981,"The scientiﬁc setup is closer to our theory than what we do in practice in that worst-case predictor
was considered and empirical generalization gap was ignored. Here we bridged these gaps with a
more practical setup. In particular, we split the PACS dataset to training and validation splits for each
domain and considered the setting: the representor trains the encoder on all-domain training splits
with a validation loss selection; the learner trains the SVM predictor (average-case) on the source
training split which is selected over the source validation split, and evaluates on the validation splits
of other target domains. The target validation accuracy averaged over all (source, target) setups was
reported. For simplicity, we will use CE to denote the objective with the cross-entropy loss that uses
labels to minimize R [Y | Z], and SupCon for the contrastive loss that uses supervised augmentations
to minimize H[A | Z]. We will use CAD in following experiments unless otherwise speciﬁed (chosen
with initial experiments). Details in Appx. E.2."
REFERENCES,0.9449035812672176,"Table 3: We repeated most empirical analysis (in the scientiﬁc setting) in the more practical bridge
setting and observed similar results."
REFERENCES,0.9462809917355371,"Setup
Avg. target acc."
REFERENCES,0.9476584022038568,"CE-Base
95.9 ± 0.5
CE-CAD
96.7 ± 0.2
CE-CAD (partial domains)
82.6 ± 0.5"
REFERENCES,0.9490358126721763,"SupCon-CAD
96.7 ± 0.4
SupCon-CAD (SingleDom)
96.7 ± 0.3
SupCon-CAD (ApproxDA)
96.6 ± 0.3
SupCon-CAD (IntraDom)
96.2 ± 0.7
SimCLR-CAD
61.7 ± 0.8"
REFERENCES,0.9504132231404959,Published as a conference paper at ICLR 2022
REFERENCES,0.9517906336088154,"Does domain bottleneck improve the average-case DG performance?
Though our theory fo-
cuses on the worst-case DG, we empirically showed that adding bottlenecks to enforce support match
can also improve the average-case DG performance by comparing CE-Base and CE-CAD in Table 3."
REFERENCES,0.953168044077135,"What if the representor only has access to source domains?
Similar to what we did in the
scientiﬁc setting, we considered the setup where one single domain is speciﬁed as the target domain
and excluded from the training set of the representor and used for evaluation with source predictors
trained on other domains. This is denoted as CE+CAD (partial domains) in Table 3, which is much
worse then CE-CAD. This shows the necessity of getting access to target domain information for DG."
REFERENCES,0.9545454545454546,"What if the representor only has access to domain-agnostic augmentations?
In Table 3, we
also compared SupCon-CAD which used supervised augmentations through the labels with CE-
CAD and they achieved the same performance. This shows that the representor can still learn good
representations without labels but only domain-agnostic augmentations in practice."
REFERENCES,0.9559228650137741,"Can we use standard augmentations?
In Fig. 2, we point out that standard augmentations are not
domain-agnostic and thus not suitable for SSL with our objectives. We empirically showed this by
using augmentations of SimCLR (see Appx. E.1 for details) with our objectives (SimCLR-CAD). In
Table 3, we indeed observed that using standard augmentations performed much worse than using
desired augmentations (SupCon-CAD)."
REFERENCES,0.9573002754820936,"How do augmentations matter?
Besides investigating the ‘Supervised’ augmentations (SupCon-
CAD) and ‘Standard’ augmentations (SimCLR-CAD) above, we also compared other three aug-
mentations as in the scientiﬁc section. Speciﬁcally, we considered the ‘SingleDom’, ‘IntraDom’,
and ‘ApproxDA’ augmentations. As shown in Table 3, SupCon-CAD (SingleDom) and (ApproxDA)
maintained the DG performance but SupCon-CAD (IntraDom) was slightly worse (0.5 accuracy
drop). We assumed the small gap was due to the speciﬁc dataset that we used (PACS). We did
the same analysis on VLCS, and SupCon-CAD with ‘Supervised’, ‘SingleDom’, and ‘IntraDom’
augmentations gave 84.7 ± 0.4, 83.2 ± 0.3, and 77.5 ± 2.3, respectively. This shows the importance
of using domain-agnostic augmentations in practice."
REFERENCES,0.9586776859504132,"Do standard augmentations affect source performance?
Previously, we showed that using stan-
dard augmentations hurt the DG performance measured by the average target accuracy. It is natural to
ask whether using standard augmentations also hurt the source performance since we should also be
interested in the ‘effective robustness’ (Taori et al., 2020). Thus we also reported the average source
accuracy of SupCon-CAD and SimCLR-CAD which were 96.9 ± 0.2 and 90.1 ± 0.2, respectively.
The source performance using standard augmentations was indeed worse, but if we consider the
source-target gap which was 0.2 for SupCon-CAD and 28.4 for SimCLR-CAD, which still veriﬁed
that the non-domain-agnostic standard augmentations were harder to force support match. To be
even more convincing, we did the same analysis on VLCS, and the average source accuracy of
SupCon-CAD and SimCLR-CAD were 86.6 ± 0.1 and 84.6 ± 0.5 which were fairly close, but the
average target accuracy were 84.7 ± 0.4 and 57.5 ± 1.7, respectively."
REFERENCES,0.9600550964187328,"F.3
DOMAINBED"
REFERENCES,0.9614325068870524,"Full result of Table 1
We included the full result of Table 1 with all baselines on DomainBed as in
Table 4. We considered most representative baselines from DomainBed, most of which considered
learning invariant representations or optimal classiﬁers across domains. Speciﬁcally, we included
IRM (Arjovsky et al., 2019), GroupDRO (Sagawa et al., 2019), Mixup (Yan et al., 2020), CORAL
(Sun & Saenko, 2016), MMD (Li et al., 2018a), DANN (Ganin et al., 2016), CDANN (Li et al.,
2018b), and VREx (Krueger et al., 2021). We also included the result pretrained CLIP S model with
a zero-shot classiﬁer using text representations (CLIP S Zero Shot), which demonstrated better DG
performance than CLIP S with linear probe. But we observed that it was outperformed by our CLIP
S + CAD."
REFERENCES,0.9628099173553719,"What is the impact of CLIP pretraining?
To ensure that our gains are not only due to a novel
CAD bottleneck, but the synergy between enforcing support constraint and using desired SSL models,
we investigated CAD using the standard DomainBed protocol denoted as CAD in the table. It
shows that CAD on its own performs similarly with DomainBed baselines (see Table 4 for a full
comparison)."
REFERENCES,0.9641873278236914,Published as a conference paper at ICLR 2022
REFERENCES,0.9655647382920111,Table 4: Full results on DomainBed with ‘oracle selection’ method.
REFERENCES,0.9669421487603306,"Algorithm
VLCS
PACS
OfﬁceHome
TerraIncognita
DomainNet"
REFERENCES,0.9683195592286501,"ERM
77.6 ± 0.3
86.7 ± 0.3
66.4 ± 0.5
53.0 ± 0.3
41.3 ± 0.1
IRM
76.9 ± 0.6
84.5 ± 1.1
63.0 ± 2.7
50.5 ± 0.7
28.0 ± 5.1
GroupDRO
77.4 ± 0.5
87.1 ± 0.1
66.2 ± 0.6
52.4 ± 0.1
33.4 ± 0.3
Mixup
78.1 ± 0.3
86.8 ± 0.3
68.0 ± 0.2
54.4 ± 0.3
39.6 ± 0.1
CORAL
77.7 ± 0.2
87.1 ± 0.5
68.4 ± 0.2
52.8 ± 0.2
41.8 ± 0.1
MMD
77.9 ± 0.1
87.2 ± 0.1
66.2 ± 0.3
52.0 ± 0.4
23.5 ± 9.4
DANN
79.7 ± 0.5
85.2 ± 0.2
65.3 ± 0.8
50.6 ± 0.4
38.3 ± 0.1
CDANN
79.9 ± 0.2
85.8 ± 0.8
65.3 ± 0.5
50.8 ± 0.6
38.5 ± 0.2
VREx
78.1 ± 0.2
87.2 ± 0.6
65.7 ± 0.3
51.4 ± 0.5
30.1 ± 3.7"
REFERENCES,0.9696969696969697,"CAD
78.0 ± 0.1
87.3 ± 0.2
67.0 ± 0.5
53.5 ± 0.9
41.5 ± 0.1"
REFERENCES,0.9710743801652892,"DINO + CAD
69.6 ± 0.6
76.1 ± 0.1
56.9 ± 0.5
25.9 ± 1.2
33.6 ± 0.1"
REFERENCES,0.9724517906336089,"CLIP S
81.1 ± 0.5
90.3 ± 0.2
70.6 ± 0.1
29.6 ± 0.8
47.7 ± 0.0
CLIP S (Zero-Shot)
80.9 ± 0.1
91.8 ± 0.1
70.4 ± 0.2
19.1 ± 0.1
46.9 ± 0.0
CLIP S + Base
81.3 ± 0.5
91.2 ± 0.3
70.6 ± 0.1
36.4 ± 0.7
46.8 ± 0.2
CLIP S + CAD
82.3 ± 0.3
92.0 ± 0.2
71.9 ± 0.2
36.2 ± 0.8
48.8 ± 0.1"
REFERENCES,0.9738292011019284,"CLIP L
80.7 ± 0.4
93.7 ± 0.8
79.6 ± 0.1
36.9 ± 0.6
52.8 ± 0.1
CLIP L + CAD
81.6 ± 0.1
94.9 ± 0.3
80.0 ± 0.2
40.6 ± 1.1
53.7 ± 0.1"
REFERENCES,0.9752066115702479,"Why ‘oracle’ selection?
In the main body, we provided the results with ‘oracle selection’ which
was the closest to our theory among the model selection methods in DomainBed (in the sense that
we needed target domain information to achieve IDG). Here, we also provided results with ‘source
validation’ selection in Table 5. Source validation selection relies on the assumption that source
and target data follow similar distributions (Gulrajani & Lopez-Paz, 2021) thus source and target
accuracy are highly correlated, which is not really true in practice. We found some issues with source
validation selection results:"
REFERENCES,0.9765840220385675,"• The selected model with the highest source validation accuracy tends to overﬁt the source
domain, thus possibly leads to worse performance on the target domain. This can be probed
by the fact that the ﬁnetuned CLIP models (CLIP + Base or CLIP + CAD) were generally
worse than the original CLIP model;"
REFERENCES,0.977961432506887,"• Selecting model with source validation accuracy tends to diminish the effect of bottlenecks.
This can be seen by the fact that the gap between CLIP + Base and CLIP + CAD of source
validation selection is much smaller than that of oracle selection;"
REFERENCES,0.9793388429752066,"• The source accuracy is not a good indicator of target accuracy thus its result has a larger
variance."
REFERENCES,0.9807162534435262,"F.4
LAION"
REFERENCES,0.9820936639118457,"Evaluation results on DomainBed
We included the evaluation results of trained models on Do-
mainBed in Table 6, where we followed exactly the same linear evaluation protocal discussed in
Appx. E.3. We observed similar results as Table 2: the CLIP L model trained with the Ent bottle-
neck on LAION (Tuned w/ Ent) outperformed the one without (Tuned w/o Ent) on all DomainBed
datasets, but slightly underperformed the original CLIP L model (which might be due to quality of
the LAION-400M dataset)."
REFERENCES,0.9834710743801653,Published as a conference paper at ICLR 2022
REFERENCES,0.9848484848484849,"Table 5: Results on DomainBed with ‘source validation’ selection. Source validation selected model
tends to overﬁt more to the source domain and diminish the effect of bottlenecks."
REFERENCES,0.9862258953168044,"Algorithm
VLCS
PACS
OfﬁceHome
TerraIncognita
DomainNet"
REFERENCES,0.987603305785124,"ERM
77.5 ± 0.4
85.5 ± 0.2
66.5 ± 0.3
46.1 ± 1.8
40.9 ± 0.1
IRM
78.5 ± 0.5
83.5 ± 0.8
64.3 ± 2.2
47.6 ± 0.8
33.9 ± 2.8
GroupDRO
76.7 ± 0.6
84.4 ± 0.8
66.0 ± 0.7
43.2 ± 1.1
33.3 ± 0.2
Mixup
77.4 ± 0.6
84.6 ± 0.6
68.1 ± 0.3
47.9 ± 0.8
39.2 ± 0.1
CORAL
78.8 ± 0.6
86.2 ± 0.3
68.7 ± 0.3
47.6 ± 1.0
41.5 ± 0.1
MMD
77.5 ± 0.9
84.6 ± 0.5
66.3 ± 0.1
42.2 ± 1.6
23.4 ± 9.5
DANN
78.6 ± 0.4
83.6 ± 0.4
65.9 ± 0.6
46.7 ± 0.5
38.3 ± 0.1
CDANN
77.5 ± 0.1
82.6 ± 0.9
65.8 ± 1.3
45.8 ± 1.6
38.3 ± 0.3
VREx
78.3 ± 0.2
84.9 ± 0.6
66.4 ± 0.6
46.4 ± 0.6
33.6 ± 2.9"
REFERENCES,0.9889807162534435,"CAD
78.0 ± 0.5
85.2 ± 0.9
67.4 ± 0.2
47.3 ± 2.2
41.0 ± 0.1"
REFERENCES,0.990358126721763,"DINO + CAD
68.9 ± 0.9
75.4 ± 0.5
56.4 ± 0.7
23.6 ± 1.2
31.0 ± 2.3"
REFERENCES,0.9917355371900827,"CLIP S
81.1 ± 0.5
90.3 ± 0.2
70.6 ± 0.1
29.6 ± 0.8
47.7 ± 0.0
CLIP S (Zero-Shot)
80.9 ± 0.1
91.8 ± 0.1
70.4 ± 0.2
19.1 ± 0.1
46.9 ± 0.0
CLIP S + Base
81.4 ± 0.4
89.6 ± 0.7
70.4 ± 0.2
30.9 ± 2.2
44.6 ± 1.6
CLIP S + CAD
81.2 ± 0.6
90.0 ± 0.6
70.5 ± 0.3
30.3 ± 0.9
45.5 ± 2.1"
REFERENCES,0.9931129476584022,"CLIP L
80.6 ± 0.7
93.5 ± 0.8
79.4 ± 0.2
37.5 ± 0.7
50.1 ± 1.1
CLIP L + CAD
80.8 ± 0.7
93.5 ± 0.7
79.7 ± 0.2
37.4 ± 1.2
51.7 ± 1.4"
REFERENCES,0.9944903581267218,"Table 6: Finetuning CLIP L on LAION with an entropy bottleneck performs better on DomainBed
than ﬁnetuning without."
REFERENCES,0.9958677685950413,"Algorithm
VLCS
PACS
OfﬁceHome
TerraIncognita
DomainNet"
REFERENCES,0.9972451790633609,"CLIP L
80.7 ± 0.4
93.7 ± 0.8
79.9 ± 0.1
36.9 ± 0.6
52.8 ± 0.1"
REFERENCES,0.9986225895316805,"Tuned w/o Ent
79.2 ± 0.7
93.4 ± 0.3
77.2 ± 0.5
36.1 ± 0.4
51.2 ± 0.1
Tuned w/ Ent
80.7 ± 0.4
94.3 ± 0.8
78.2 ± 0.2
36.8 ± 0.4
52.2 ± 0.1"
