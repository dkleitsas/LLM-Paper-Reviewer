Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.003676470588235294,"Physics-inspired neural networks (NNs), such as Hamiltonian or Lagrangian NNs,
dramatically outperform other learned dynamics models by leveraging strong in-
ductive biases. These models, however, are challenging to apply to many real
world systems, such as those that don’t conserve energy or contain contacts, a
common setting for robotics and reinforcement learning. In this paper, we exam-
ine the inductive biases that make physics-inspired models successful in practice.
We show that, contrary to conventional wisdom, the improved generalization of
HNNs is the result of modeling acceleration directly and avoiding artiﬁcial com-
plexity from the coordinate system, rather than symplectic structure or energy con-
servation. We show that by relaxing the inductive biases of these models, we can
match or exceed performance on energy-conserving systems while dramatically
improving performance on practical, non-conservative systems. We extend this
approach to constructing transition models for common Mujoco environments,
showing that our model can appropriately balance inductive biases with the ﬂexi-
bility required for model-based control. 25% 50% 75% 100%"
ABSTRACT,0.007352941176470588,Performance
ABSTRACT,0.011029411764705883,+ ODE Bias
ABSTRACT,0.014705882352941176,+ Second-Order Bias
ABSTRACT,0.01838235294117647,+ Symplectic Bias
ABSTRACT,0.022058823529411766,Hamiltonian NN
ABSTRACT,0.025735294117647058,Expectation 25% 50% 75% 100%
ABSTRACT,0.029411764705882353,Performance
ABSTRACT,0.03308823529411765,+ ODE Bias
ABSTRACT,0.03676470588235294,+ Second-Order Bias
ABSTRACT,0.04044117647058824,+ Symplectic Bias
ABSTRACT,0.04411764705882353,Hamiltonian NN
ABSTRACT,0.04779411764705882,Reality
ABSTRACT,0.051470588235294115,"Figure 1: The common perception in physics-informed machine learning is that increased perfor-
mance is the result of complex biases. We ﬁnd, however, that simpler implicit biases (such as
second-order structure) often account for almost all of the improvement over baselines."
INTRODUCTION,0.05514705882352941,"1
INTRODUCTION"
INTRODUCTION,0.058823529411764705,"The inductive biases of convolutional neural networks, such as translation equivariance, locality,
and parameter sharing, play a key role in their generalization properties. Other biases have similarly
guided the development of deep models for other domains like graphs and point clouds. Yet since
models often encode multiple biases simultaneously, it can be challenging to identify how each
contributes to generalization in isolation. By understanding which inductive biases are essential, and
which are merely ancillary, we can simplify our models, and improve performance. For example,
Wu et al. (2019) demonstrate that Graph Convolutional Networks can be radically simpliﬁed to mere
logistic regression by removing nonlinearities, leading to dramatic gains in computational efﬁciency,
while retaining comparable accuracy."
INTRODUCTION,0.0625,"Hamiltonian Neural Networks (HNNs) (Greydanus et al., 2019) have emerged as a leading approach
for modeling dynamical systems. These dynamics models encode physical priors and outperform
alternative Neural ODE approaches (Chen et al., 2018). In the spirit of Wu et al. (2019), we seek to
identify the critical components of HNNs. Since Lagrangian models (LNNs) (Lutter et al., 2019a;"
INTRODUCTION,0.0661764705882353,Published as a conference paper at ICLR 2022
INTRODUCTION,0.06985294117647059,"Cranmer et al., 2020) share the same structure and inductive biases as HNNs, we focus on HNNs
where energy conservation and symplecticity are more explicit."
INTRODUCTION,0.07352941176470588,HNNs encode a number of inductive biases that help model physical systems:
INTRODUCTION,0.07720588235294118,"1. ODE bias: HNNs model derivatives of the state rather than the states directly.
2. Second-order (SO) bias: HNNs model changes in position through changes in velocity.
3. Energy conservation bias: HNNs conserve their learned energy function.
4. Symplectic bias: HNNs dynamics are symplectic: phase space areas are conserved, and
the vector ﬁeld has a Hamiltonian structure."
INTRODUCTION,0.08088235294117647,"In this paper we theoretically and empirically examine the role of these biases. In contrast to conven-
tional wisdom, we ﬁnd that the generalization beneﬁt of HNNs is not explained by their symplectic
or energy-conserving properties, but rather by their implicit second-order bias. We highlight these
ﬁndings in Figure 1. Abstracting and extracting out this second-order bias, we show how to improve
the performance of Neural ODEs, empowering applications when HNNs assumptions are violated as
is often the case. Code for our experiments can be found at: https://github.com/ngruver/decon-hnn."
RELATED WORK,0.08455882352941177,"2
RELATED WORK"
RELATED WORK,0.08823529411764706,"Physics-inspired models and energy conservation
Since Greydanus et al. (2019), many re-
searchers have sought to extend the HNN approach to make it more general or applicable to systems
that break energy conservation. Jin et al. (2020), Li et al. (2020), Tong et al. (2021), and Xiong
et al. (2020) propose methods for creating neural networks that preserve symplectic structure di-
rectly. Zhong et al. (2020), and later Desai et al. (2021), Li et al. (2021), and Lee et al. (2021)
propose models with additional capacity for changes to the system energy. In our analysis, we com-
pare against approaches that add additional capacity for changes in energy, although our approach
is fundamentally different — we attempt to remove unnecessary biases rather than add complexity."
RELATED WORK,0.09191176470588236,"Physics-inspired models for control
A large and rapidly expanding body of work explores how
to use physics-based biases in dynamics models with controls or contacts (Lutter et al., 2019b;
Zhong et al., 2019; Gupta et al., 2019; 2020; Chen et al., 2019; Hochlehnert et al., 2021; Chen et al.,
2020; Zhong et al., 2021b) intended for application in model-based planning. Especially relevant
to our evaluations, Alvarez et al. (2020) models MuJoCo (Todorov et al., 2012) trajectories with a
numerically integrated neural network but does not explore other physics-inspired inductive biases."
RELATED WORK,0.09558823529411764,"Analyzing physics-based inductive biases
Karniadakis et al. (2021) and Liu et al. (2021) propose
conceptual frameworks for deep learning with physics-based inductive biases, but present minimal
empirical analysis of common design decisions. Zhong et al. (2021a) compare many approaches
to physics-inspired deep learning, with results that parallel some ﬁndings here. The contribution of
our work, however, is not simply benchmarking but also an actionable theory of HNNs’ success. In
spirit, our work is similar to Botev et al. (2021), which also critically examines the role of physics-
based priors in dynamics models, though their focus is on learning latent space dynamics, while we
focus on temporal models in observation space."
BACKGROUND,0.09926470588235294,"3
BACKGROUND"
BACKGROUND,0.10294117647058823,"We consider dynamical systems described by ordinary differential equations (ODEs) which deter-
mine how the system evolves over time. Even with high order derivatives, these systems can be
arranged into the form dz"
BACKGROUND,0.10661764705882353,"dt = F(z, t) for z ∈Rn. If the dynamics F are time-independent, then the
ODE can be understood as a vector ﬁeld, specifying at each point where the next state will be."
BACKGROUND,0.11029411764705882,"Neural ODEs (NODEs) (Chen et al., 2018) parametrize a vector ﬁeld with a neural network and learn
the dynamics directly from observed trajectories. A NODE dynamics model ˆFθ is rolled out from
the initial condition z0 with ODE integration, ˆzt = ODESolve(z0, ˆFθ, t), and ﬁt to trajectory data
by minimizing an L2 loss L(θ) = PT
t=1 ∥ˆzt −zt∥2 between the predicted and observed trajectories,
ˆzt and zt."
BACKGROUND,0.11397058823529412,Published as a conference paper at ICLR 2022
BACKGROUND,0.11764705882352941,"Like NODEs, HNNs also model dynamical systems as a parameterized vector ﬁeld, dz"
BACKGROUND,0.1213235294117647,"dt = J∇ˆHθ with J =

0
I
−I
0"
BACKGROUND,0.125,"
,
(1)"
BACKGROUND,0.12867647058823528,"where ˆHθ is a neural network with scalar output (Greydanus et al., 2019)."
BACKGROUND,0.1323529411764706,"This differential equation expresses Hamiltonian dynamics where p and q are the canonical positions
and momenta,"
BACKGROUND,0.13602941176470587,"z =

q
p"
BACKGROUND,0.13970588235294118,"
and d dt 
q
p 
="
BACKGROUND,0.14338235294117646,"""
∂ˆ
H
∂p
−∂ˆ
H
∂q . # .
(2)"
BACKGROUND,0.14705882352941177,"It is common practice to also explicitly deﬁne H = T + V , where T and V are the kinetic and
potential energy (Zhong et al., 2019; Gupta et al., 2019; Finzi et al., 2020). The assumption that the
Hamiltonian is separable holds for mechanical systems and allows for further simpliﬁcation,"
BACKGROUND,0.15073529411764705,"ˆHθ(q, p) = 1"
BACKGROUND,0.15441176470588236,"2pT M −1
θ
(q)p + Vθ(q) ,
(3)"
BACKGROUND,0.15808823529411764,where positive deﬁnite mass matrix M and scalar V are outputs of the neural network.
BREAKING DOWN HNN PERFORMANCE,0.16176470588235295,"4
BREAKING DOWN HNN PERFORMANCE"
BREAKING DOWN HNN PERFORMANCE,0.16544117647058823,"In the following section we investigate to what extent commonly held beliefs about HNN prop-
erties actually explain the ability of HNNs to generalize. To separate out the different properties
of these models, we select synthetic environments from Finzi et al. (2020) and Finzi et al. (2021)
that are derived from a time independent Hamiltonian, where energy is preserved exactly. We use
kChainPendulum, a k link pendulum in angular coordinates, and kSpringPendulum, a pendulum
connected with k spring links in Cartesian coordinates."
BREAKING DOWN HNN PERFORMANCE,0.16911764705882354,"We compute relative error between predicted states, ˆz, and ground truth, z, as ∥ˆz −z∥2/∥ˆz∥2∥z∥2
and between the predicted and ground truth Hamiltonian as | ˆH −H|/| ˆH||H|. Following Finzi et al.
(2020), we evaluate the performance of the model by computing the geometric mean of the relative
error of the state over rollouts of length 20 times the size used at training, which more faithfully
predicts downstream performance compared to other metrics like MSE (Finzi et al., 2020). The
geometric mean of a function f over time T is given by exp( 1"
BREAKING DOWN HNN PERFORMANCE,0.17279411764705882,"T
R T
t=0 log f(t)dt)."
ENERGY CONSERVATION,0.17647058823529413,"4.1
ENERGY CONSERVATION"
ENERGY CONSERVATION,0.1801470588235294,"HNNs are commonly believed to be superior for energy conservation than comparable models
(Greydanus et al., 2019; Cranmer et al., 2020). While there is some empirical evidence to sup-
port this claim, a precise mathematical explanation for why this should be the case has not been
established. Surprisingly, we ﬁnd that conditioned on the trajectory reconstruction error, HNNs are
no better at conserving the true energy of the system than unconstrained NeuralODE models."
ENERGY CONSERVATION,0.18382352941176472,"Up to the numerical accuracy of an ODE solver, HNNs do conserve their own learned energy func-
tion ˆH (different from the true energy of the system H), due to basic properties of Hamiltonian
mechanics,
d ˆH(ˆz)"
ENERGY CONSERVATION,0.1875,"dt
= ∇ˆH⊤dˆz"
ENERGY CONSERVATION,0.19117647058823528,"dt = ∇ˆH⊤J∇ˆH = 0 ,
(4)"
ENERGY CONSERVATION,0.1948529411764706,"where the last equality follows from the antisymmetry of J. If the HNN has ﬁt the data well, we
might expect ˆH to be close to the true Hamiltonian H, and so if ˆH is conserved then it seems that
H should be too. As we show in Appendix B.2, the problem with this argument is that we have no
guarantees that ˆH and H are close even if we have ﬁt the data well with low error in the rollouts
or the dynamics. Since the dynamics error and the training rollout error depend only on gradients
∇ˆH, while the gradients may be close, the differences between the two scalar functions can grow
arbitrarily large."
ENERGY CONSERVATION,0.19852941176470587,"In Figure 2 (left) we show that the degree of energy conservation is highly correlated with the
rollout error of the model, regardless of the choice of architecture. While HNNs have better rollout"
ENERGY CONSERVATION,0.20220588235294118,Published as a conference paper at ICLR 2022
ENERGY CONSERVATION,0.20588235294117646,"10 4
10 2
100"
ENERGY CONSERVATION,0.20955882352941177,Rollout Error 10 4 10 2 100
ENERGY CONSERVATION,0.21323529411764705,Energy Violation
ENERGY CONSERVATION,0.21691176470588236,"HNN
NODE + SO
NODE 10
4 10
2 100"
LINK,0.22058823529411764,"2 link
3 link
4 link 10
1 10
4 10
2 100"
LINK,0.22426470588235295,"10
1
10
1"
LINK,0.22794117647058823,"HNN
NODE"
LINK,0.23161764705882354,"Chain
Spring"
LINK,0.23529411764705882,Energy Error
LINK,0.23897058823529413,Rollout Time T
LINK,0.2426470588235294,"Figure 2:
Left: The degree of energy violation (| ˆH −H|/| ˆH||H|) on test rollouts as a function
of rollout relative error (∥ˆz −z∥/∥ˆz∥∥z∥) across different environments and random seeds. Both
HNNs and NeuralODEs are scattered around the line x = y. Conditioned on the rollout perfor-
mance, whether or not the model is Hamiltonian has little impact on the energy violation. Right:
Energy violation on test trajectories is plotted as a function of the time T of the rollout, with the
shaded regions showing 1 standard deviation in log space taken across 5 random seeds and the test
trajectories."
LINK,0.24632352941176472,"performance than NeuralODEs, they are on the same regression line with Rollout Error ∝Energy
Violation. The differences in energy violation are best predicted by the rollout error and not the
architecture."
LINK,0.25,"In Appendix B.1, we derive a bound that helps explain this behaviour. Given that the trajectories
are in a bounded region of the phase space and that there is a ﬁxed amount of error in the dynamics
model, the energy violation grows at most linearly in time and the dynamics error. In Figure 2 (right)
we demonstrate empirically that energy is not conserved as time progresses for HNNs.1 In fact,
the energy error of both NODE and HNN models grow linearly as our bound suggests. Although
energy conservation may be helpful for generalization, the evidence does not indicate that HNNs
are inherently better at conserving energy than NODEs, suggesting that the superior generalization
of HNNs cannot be attributed to superior energy conservation."
SYMPLECTIC VECTOR FIELDS,0.2536764705882353,"4.2
SYMPLECTIC VECTOR FIELDS"
SYMPLECTIC VECTOR FIELDS,0.25735294117647056,"A deﬁning property of Hamiltonian mechanics is the fact that the dynamics are symplectic. If energy
conservation does not explain the effectiveness of HNNs, the symplectic property of HNN dynamics
may be the cause. Informally, one of the consequences of symplectic dynamics is that every part of
the state space is equally attractive and repulsive. There are no sources where all nearby trajectories
ﬂow out from, or sinks where all nearby trajectories ﬂow into, only saddle points and centers where
the inﬂow and outﬂow is balanced. Symplectic integrators (Leimkuhler and Skeel, 1994) make use
of this property for more stable integration of Hamiltonian systems over very long timespans, and
it is intuitive that enforcing this property in learned dynamics would have beneﬁts also, at the very
least for reducing the size of the hypothesis space."
SYMPLECTIC VECTOR FIELDS,0.2610294117647059,"More formally, symplecticity is the property that the J matrix (the symplectic form) is preserved by
the dynamics (Equation 1). This condition can be expressed as a constraint on the Jacobian DF of
the vector ﬁeld F(z) = dz"
SYMPLECTIC VECTOR FIELDS,0.2647058823529412,"dt (here the derivative D maps from a function to its Jacobian). In terms of
the Jacobian, symplecticity is the condition DF ⊤J + JDF = 0 or equivalently (JDF)T = JDF
since J⊤= −J. The signiﬁcance of this condition is that areas occupied by states in phase space
(which have units of energy) are preserved by symplectic transformations. One consequence is that
a volume of solutions in phase space will continue to occupy the same volume over time and will
not be compressed or expanded. In other words, the vector ﬁeld has 0 divergence: Tr(DF) = 0,
which one can derive from the above expression."
SYMPLECTIC VECTOR FIELDS,0.26838235294117646,1The energy violation is considerably larger than merely the numerical error associated with the solver.
SYMPLECTIC VECTOR FIELDS,0.27205882352941174,Published as a conference paper at ICLR 2022
SYMPLECTIC VECTOR FIELDS,0.2757352941176471,"Chain 1
Chain 2
Chain 3
Spring 1
Spring 2
Spring 3 10 4 10 3 10 2 10 1"
SYMPLECTIC VECTOR FIELDS,0.27941176470588236,Rollout Error =
SYMPLECTIC VECTOR FIELDS,0.28308823529411764,"0.001
0.01
0.1
1.0
10.0
100.0"
SYMPLECTIC VECTOR FIELDS,0.2867647058823529,"1e-10 1e-08 1e-060.0001 0.01
1
100"
SYMPLECTIC VECTOR FIELDS,0.29044117647058826,Symplectic Error
SYMPLECTIC VECTOR FIELDS,0.29411764705882354,0.0001 0.001 0.01 0.1 1
SYMPLECTIC VECTOR FIELDS,0.2977941176470588,Rollout Error
SYMPLECTIC VECTOR FIELDS,0.3014705882352941,"Chain 1
Chain 2
Chain 3
Spring 1
Spring 2
Spring 3"
SYMPLECTIC VECTOR FIELDS,0.30514705882352944,"Figure 3:
Left: Test rollout error as a function of the regularization weighting in the loss. Even
at an optimally chosen symplectic regularization strength, the beneﬁt to model generalization is
negligible. Right: Test rollout error plotted against the ﬁnal value of the symplecticity error for the
regularized models. For systems with more than a couple degrees of freedom, symplecticity error is
negatively correlated with the quality of predictions."
SYMPLECTIC VECTOR FIELDS,0.3088235294117647,"On Rn, it can be shown that all symplectic vector ﬁelds can be expressed as the dynamics of some
Hamiltonian system, and vice versa:"
SYMPLECTIC VECTOR FIELDS,0.3125,"F = J∇H ⇐⇒(JDF)T = JDF
(5)"
SYMPLECTIC VECTOR FIELDS,0.3161764705882353,"To show the forward direction, one can simply substitute in Hamiltonian dynamics. It is clear that the
symplecticity property is satisﬁed: using J2 = −I, JDF = JD(J∇H) = J2∇2H = −∇2H, and
−∇2H is a symmetric matrix. The reverse direction is less obvious; however, by Poincaré’s lemma
if a vector ﬁeld F satisﬁes (JDF)T = JDF on Rn, then there exists a Hamiltonian function H
such that F = J∇H, which is shown in subsection B.3."
SYMPLECTIC VECTOR FIELDS,0.31985294117647056,"The equivalence of Hamiltonian dynamics and symplecticity allows us separate the unique proper-
ties of HNNs from other inductive biases that result indirectly from modeling F through H. Follow-
ing Ghosh et al. (2020), we can create a regularizer SymplecticError(F) = ∥(JDF)T −JDF∥2
that directly measures the degree to which the symplectic property is violated. By parametrizing a
NeuralODE and regularizing the symplectic error, we can enforce Hamiltonian structure while still
directly modeling dz"
SYMPLECTIC VECTOR FIELDS,0.3235294117647059,"dt = F rather than H. Alongside an unregularized NeuralODE, we can isolate
and evaluate the beneﬁt of this Hamiltonian structure bias with a direct comparison."
SYMPLECTIC VECTOR FIELDS,0.3272058823529412,"Surprisingly, we ﬁnd that the Hamiltonian structure bias, as enforced by the symplectic regularizer,
provides no real beneﬁt to the model’s ability to generalize over the long test rollouts (Figure 3 left).
The achieved symplectic error Figure 3 (right) is not positively correlated with the ﬁnal test rollout
error of the model, and in some cases is even negatively correlated. Even when the symplectic error
is very low and the symplecticity condition is enforced, there is no consistent improvement on the
rollout generalization."
SECOND-ORDER STRUCTURE,0.33088235294117646,"4.3
SECOND-ORDER STRUCTURE"
SECOND-ORDER STRUCTURE,0.33455882352941174,"If the superior performance of HNNs over NeuralODEs does not come from their better energy
conservation properties, nor from the symplectic structure of the predicted vector ﬁeld, what is the
true cause?"
SECOND-ORDER STRUCTURE,0.3382352941176471,"In previous work, authors have used slightly different implementations of HNNs. One subtle im-
provement over the original work (Greydanus et al., 2019) comes from explicitly splitting the Hamil-
tonian as ˆH = T + V = p⊤M(q)−1p/2 + V (q) and modeling the mass matrix M(q) and the po-
tential V (q) with separate neural networks rather than using a single neural network for ˆH (Zhong
et al., 2019). This splitting enforces a strong assumption about the functional form of the Hamil-
tonian that applies to mechanical systems that makes it easier to learn and extrapolate. Through
Hamiltons equations ˆF = J∇ˆH, this splitting is in fact specifying the relationship between position
and momentum dq"
SECOND-ORDER STRUCTURE,0.34191176470588236,dt = ∂H
SECOND-ORDER STRUCTURE,0.34558823529411764,"∂p = M −1(q)p, and that forces can only affect dp dt ."
SECOND-ORDER STRUCTURE,0.3492647058823529,Published as a conference paper at ICLR 2022
SECOND-ORDER STRUCTURE,0.35294117647058826,"Chain 2
Chain 3
Chain 4
Spring 2
Spring 3
Spring 4 10 2 10 1"
SECOND-ORDER STRUCTURE,0.35661764705882354,Rollout Error
SECOND-ORDER STRUCTURE,0.3602941176470588,NODE Models
SECOND-ORDER STRUCTURE,0.3639705882352941,"Chain 2
Chain 3
Chain 4
Spring 2
Spring 3
Spring 4"
SECOND-ORDER STRUCTURE,0.36764705882352944,HNN Models
SECOND-ORDER STRUCTURE,0.3713235294117647,"Without SO bias
With SO bias"
SECOND-ORDER STRUCTURE,0.375,"Figure 4: Left: NODE model with and without second-order structure (encoding dq/dt = v).
Right: HNN models with and without second-order structure. Models with the SO bias signiﬁcantly
outperform those that do not. Error bars show standard error across 5 seeds."
SECOND-ORDER STRUCTURE,0.3786764705882353,"Chain 1
Chain 2
Chain 3
Chain 4 10 3 10 1 101"
SECOND-ORDER STRUCTURE,0.38235294117647056,Rollout Error
SECOND-ORDER STRUCTURE,0.3860294117647059,Complex Coordinates
SECOND-ORDER STRUCTURE,0.3897058823529412,"Spring 1
Spring 2
Spring 3
Spring 4 10 3 10 1"
SECOND-ORDER STRUCTURE,0.39338235294117646,Rollout Error
SECOND-ORDER STRUCTURE,0.39705882352941174,Simple Coordinates
SECOND-ORDER STRUCTURE,0.4007352941176471,"NODE + SO
HNN"
SECOND-ORDER STRUCTURE,0.40441176470588236,"Figure 5: Left: Log rollout error for NODEs with second order bias and HNNs trained chain pendu-
lums, where the analytic form of the Hamiltonian is simpler than the vector ﬁeld. Right: Mechanic-
sNNs and HNNs trained on spring pendulums, which have Hamiltonians and vector ﬁelds of similar
complexity. HNNs outperform NODE with second order bias on systems that use non-Cartesian
coordinates. Error bars show standard error across 5 seeds."
SECOND-ORDER STRUCTURE,0.40808823529411764,"In fact, we can see that this assumption essentially leads to the second-order differential equation
 dq dt
dp dt"
SECOND-ORDER STRUCTURE,0.4117647058823529,"
=
M −1(q)p
−dV dq"
SECOND-ORDER STRUCTURE,0.41544117647058826,"
=⇒d2q"
SECOND-ORDER STRUCTURE,0.41911764705882354,"dt2 =
 d"
SECOND-ORDER STRUCTURE,0.4227941176470588,"dtM −1(q)

M(q)dq"
SECOND-ORDER STRUCTURE,0.4264705882352941,dt −M −1(q)dV
SECOND-ORDER STRUCTURE,0.43014705882352944,"dq = A(q, dq"
SECOND-ORDER STRUCTURE,0.4338235294117647,"dt )
(6)"
SECOND-ORDER STRUCTURE,0.4375,"This second-order (SO) structure,
 dq dt
dv dt"
SECOND-ORDER STRUCTURE,0.4411764705882353,"
=

v
A(q, v)"
SECOND-ORDER STRUCTURE,0.44485294117647056,"
, is a direct by-product of the separable Hamil-"
SECOND-ORDER STRUCTURE,0.4485294117647059,"tonian inductive bias, but is more general, applying to both conservative and non-conservative phys-
ical systems."
SECOND-ORDER STRUCTURE,0.4522058823529412,"We can isolate the effect of this bias by directly observing its effect on both HNNs and NODEs.
For HNNs the bias is made explicit in separable Hamiltonians, but not in the general case, when
H(q, p) is the direct output of the network instead of V (q). We can design a NODE with second-
order structure (NODE + SO) by setting z = [q, p] with p = Mv and dq"
SECOND-ORDER STRUCTURE,0.45588235294117646,"dt = v, dp"
SECOND-ORDER STRUCTURE,0.45955882352941174,"dt = ˜Aθ(q, p), or"
SECOND-ORDER STRUCTURE,0.4632352941176471,equivalently just the second order equation d2q
SECOND-ORDER STRUCTURE,0.46691176470588236,"dt2 = Aθ(q, dq"
SECOND-ORDER STRUCTURE,0.47058823529411764,"dt ). Figure 4 shows the effect of second
order structure on the test predictions of NODEs and HNNs. It is clear that this bias explains the
superior performance of HNNs much more than other biases that are frequently given more credit.
In fact, when we add this bias to NODE models, we see that their performance more closely matches
HNNs than vanilla NODEs without creating a conservative or symplectic vector."
FUNCTIONAL COMPLEXITY,0.4742647058823529,"4.4
FUNCTIONAL COMPLEXITY"
FUNCTIONAL COMPLEXITY,0.47794117647058826,"Adding second order structure to NODEs is always helpful, and matches the HNN performance for
many of the systems. However, we see that there is still a gap for some systems, and curiously
in each of these cases the system is described in a non-Cartesian coordinate system, such as with
joint angles and Euler angles. Recall that with the symplecticity bias, we only found no beneﬁt for
enforcing that there exists a function ˆH such that ˆF = J∇ˆH bias while parametrizing ˆF; however,
for HNNs this function not only exists, it is directly parametrized by the neural net. If the function"
FUNCTIONAL COMPLEXITY,0.48161764705882354,Published as a conference paper at ICLR 2022
FUNCTIONAL COMPLEXITY,0.4852941176470588,"Chain 1
Chain 2
Chain 3
Spring 1
Spring 2
Spring 3 10 3 10 2"
FUNCTIONAL COMPLEXITY,0.4889705882352941,Rollout Error
FUNCTIONAL COMPLEXITY,0.49264705882352944,"NODE
NODE + SO
HNN
SymODEN"
FUNCTIONAL COMPLEXITY,0.4963235294117647,"Figure 6: Comparing the performance on damped systems. The NODE + SO matches the perfor-
mance of a SymODEN with a fraction of the parameters and compute. HNNs without forcing terms
encode the wrong inductive biases and thus ﬁt the data poorly. Error bars denote standard error
across 5 seeds."
FUNCTIONAL COMPLEXITY,0.5,"ˆH happens to be a simpler function to express and learn than ∇H, then representing the solution in
this way can be beneﬁcial."
FUNCTIONAL COMPLEXITY,0.5036764705882353,"For systems expressed in Cartesian coordinates like the spring pendulum, the mass matrix M(q) =
M is a constant, and so the gradients of H = p⊤Mp + V (q) are simple to express and learn. How-
ever, for systems with constraints such as the Chain pendulum, where states are typically expressed
in angular coordinates, the mass matrix M(q) will have a complicated form and that complexity
will be magniﬁed when taking the derivative. As an example, consider the Hamiltonian that an
HNN must learn for the 2 link chain pendulum versus the vector ﬁeld that a NODE + SO model
must learn for this system (derived in Finzi et al. (2020), Appendix F.2). For the spring pendulum
the functional complexity of the Hamiltonian and vector ﬁelds is comparable, while for the chain
pendulum, the vector ﬁeld contains many more terms."
FUNCTIONAL COMPLEXITY,0.5073529411764706,"Parameterizing such a system via its Hamiltonian simpliﬁes the learning problem, and enables a
neural network to converge more rapidly towards a plausible solution. This observation aligns with
the insight in Finzi et al. (2020), which shows that changing the coordinate system to Cartesian
dramatically simpliﬁes the learning problem, at the expense of needing to enforce the constraints to
the conﬁguration space more directly."
FUNCTIONAL COMPLEXITY,0.5110294117647058,"Figure 5 shows the relative performance of the NODE+SO across the chain pendulum and spring
pendulum environments. As we would now expect, the gap between the NODE+SO and HNN
vanishes (and even favors NODE+SO) when complexity of the Hamiltonian and vector ﬁeld are
comparable."
NON-CONSERVATIVE SYSTEMS,0.5147058823529411,"4.4.1
NON-CONSERVATIVE SYSTEMS"
NON-CONSERVATIVE SYSTEMS,0.5183823529411765,"Perfectly energy-conserving systems are useful for analyzing the limiting behaviour of physics-
informed networks, but in the vast majority of real world applications, we do not model closed
systems. Energy is changed through contact with the environment (as in friction or drag) or an actor
applying controls. In these cases, HNNs can be generalized by adding a forcing term  dq dt
dp dt 
= ""
∂H"
NON-CONSERVATIVE SYSTEMS,0.5220588235294118,"∂p
−∂H ∂q #"
NON-CONSERVATIVE SYSTEMS,0.5257352941176471,"+

0
g(q, p)"
NON-CONSERVATIVE SYSTEMS,0.5294117647058824,"
u
(7)"
NON-CONSERVATIVE SYSTEMS,0.5330882352941176,"as in SymODEN (Zhong et al., 2019; 2020) and Desai et al. (2021), where u is the control input,
which can be ﬁxed as constant in systems with drag or friction."
NON-CONSERVATIVE SYSTEMS,0.5367647058823529,"Though SymODEN can accommodate controls and damping, we show that simply using the bias of
second-order dynamics is sufﬁcient to achieve nearly the same performance with much less com-
plexity. We demonstrate the matching performance on our n-body pendulum systems, augmented
with drag, dp"
NON-CONSERVATIVE SYSTEMS,0.5404411764705882,dt = −∂H
NON-CONSERVATIVE SYSTEMS,0.5441176470588235,∂q −λv (Figure 6).
NON-CONSERVATIVE SYSTEMS,0.5477941176470589,Published as a conference paper at ICLR 2022
NON-CONSERVATIVE SYSTEMS,0.5514705882352942,"HalfCheetah
Hopper
Swimmer 10 1 100"
NON-CONSERVATIVE SYSTEMS,0.5551470588235294,Rollout Err Test
NON-CONSERVATIVE SYSTEMS,0.5588235294117647,"HalfCheetah
Hopper
Swimmer 10 2 10 1"
NON-CONSERVATIVE SYSTEMS,0.5625,Rollout Err Train
NON-CONSERVATIVE SYSTEMS,0.5661764705882353,"NODE
NODE + SO
SymODEN"
NON-CONSERVATIVE SYSTEMS,0.5698529411764706,"Figure 7:
HNNs perform very poorly on complex dynamics like OpenAI Gym Mujoco control
systems. Biasing the model towards Hamiltonian dynamics makes it difﬁcult to ﬁt the training
data. Simply imposing second-order structure on a NODE is much more effective. Error bars show
standard error across 4 seeds."
MODELING MUJOCO TRANSITION DYNAMICS,0.5735294117647058,"5
MODELING MUJOCO TRANSITION DYNAMICS"
MODELING MUJOCO TRANSITION DYNAMICS,0.5772058823529411,"HNNs are typically evaluated on relatively simple systems, like those considered in the previous
sections. In principle, we would expect these results to extend to more complex systems that are
governed by similar physical laws. In practice, however, there is little evidence to suggest that
applying HNN methods to complex systems is easy or effective."
MODELING MUJOCO TRANSITION DYNAMICS,0.5808823529411765,"The MuJoCo physics simulator (Todorov et al., 2012) is one such complex system that we would
expect to beneﬁt from HNN inductive biases. Gym Mujoco systems are heavily used in model-based
reinforcement learning (MBRL) literature, but the dynamics models commonly used are surprisingly
simple (often just MLPs trained to predict the next change in state) (Chua et al., 2018; Wang and
Ba, 2019)."
MODELING MUJOCO TRANSITION DYNAMICS,0.5845588235294118,"Given how much beneﬁt other applications of deep learning have derived from specialized archi-
tectures, such as CNNs for computer vision (LeCun et al., 1989), RNNs for NLP (Mikolov et al.,
2010), or WaveNets for audio (Oord et al., 2016), we would expect analogous improvements to be
possible in MBRL. Algorithms for MBRL are infamously sensitive to choice of prediction horizon,
and one possible explanation is poor generalization caused by weak inductive biases (Janner et al.,
2019; Pan et al., 2020; Amos et al., 2021). Improving model design for mechanical systems has the
potential to improve both the sample efﬁciency of MBRL algorithms and their robustness."
MODELING MUJOCO TRANSITION DYNAMICS,0.5882352941176471,"We train NODEs and HNNs on trajectories from several OpenAI Gym Mujoco environments
(Brockman et al., 2016). Crucially, we compare NODEs endowed with second-order structure
(NODE + SO) against pre-existing NODE and HNN models, as we did in Section 4.4.1. Note
that with ﬁxed step size integrators, NODEs are equivalent to discrete transition models that predict
the next state or delta directly with an MLP, and therefore our NODE baseline is representative of
models commonly used in MBRL. See Appendix C for implementation details."
MODELING MUJOCO TRANSITION DYNAMICS,0.5919117647058824,"In Figure 7 we show that NODE + SO signiﬁcantly outperforms baseline methods. Surprisingly
HNNs underperform NODEs on all the systems we consider. Although the HNN could in principle
learn the dynamics, in practice the bias towards Hamiltonian dynamics makes ﬁtting the training data
very difﬁcult and provides no tangible beneﬁt to generalization. This outcome is notably different
from what we observe in toy tasks, where HNNs can ﬁt non-conservative systems (e.g., pendulums
with drag) with little difﬁculty."
MODELING MUJOCO TRANSITION DYNAMICS,0.5955882352941176,"In spirit, our results parallel the ﬁndings of Wu et al. (2019) in the different setting of graph CNNs.
We are able to distill the inductive biases of HNNs into a NODE + SO without losing performance
on systems that HNNs perform well on, and, even more importantly, these reduced systems are much
more capable of scaling to complex systems and larger datasets."
MODELING MUJOCO TRANSITION DYNAMICS,0.5992647058823529,Published as a conference paper at ICLR 2022
CONCLUSION,0.6029411764705882,"6
CONCLUSION"
CONCLUSION,0.6066176470588235,"In this paper, we deconstructed the inductive biases of highly performing HNN models into their
component parts, a NeuralODE, symplecticity, conservation of the learned energy function, and
second order structure. Contrary to conventional wisdom, the success of HNNs is not from their en-
ergy conservation or symplecticity, but rather from the assumption that the system can be expressed
as a single second order differential equation. Stripping away the other components of an HNN, we
are left with a model that is simpler, more computationally efﬁcient, and less restrictive in that it can
be directly applied to non-Hamiltonian systems. As a consequence, we are able to apply the result-
ing model to constructing transition models for the challenging Mujoco locomotion environments,
with promising performance."
CONCLUSION,0.6102941176470589,ACKNOWLEDGEMENTS
CONCLUSION,0.6139705882352942,"The authors would like to thank Greg Benton and Pavel Izmailov for helpful comments on our
original submission. This research is supported by an Amazon Research Award, Facebook Research,
Google Research, NSF I-DISRE 193471, NIH R01DA048764-01A1, NSF IIS-1910266, and NSF
1922658 NRT-HDR: FUTURE Foundations, Translation, and Responsibility for Data Science."
CONCLUSION,0.6176470588235294,Published as a conference paper at ICLR 2022
REFERENCES,0.6213235294117647,REFERENCES
REFERENCES,0.625,"Victor M Martinez Alvarez, Rare¸s Ro¸sca, and Cristian G F˘alcu¸tescu.
Dynode:
Neural or-
dinary differential equations for dynamics modeling in continuous control.
arXiv preprint
arXiv:2009.04278, 2020."
REFERENCES,0.6286764705882353,"Brandon Amos, Samuel Stanton, Denis Yarats, and Andrew Gordon Wilson. On the model-based
stochastic value gradient for continuous reinforcement learning. In Learning for Dynamics and
Control, pages 6–20. PMLR, 2021."
REFERENCES,0.6323529411764706,"Aleksandar Botev, Andrew Jaegle, Peter Wirnsberger, Daniel Hennes, and Irina Higgins. Which
priors matter? benchmarking models for learning latent dynamics. 2021."
REFERENCES,0.6360294117647058,"Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and
Wojciech Zaremba. Openai gym. arXiv preprint arXiv:1606.01540, 2016."
REFERENCES,0.6397058823529411,"Ricky TQ Chen, Brandon Amos, and Maximilian Nickel. Learning neural event functions for ordi-
nary differential equations. arXiv preprint arXiv:2011.03902, 2020."
REFERENCES,0.6433823529411765,"Tian Qi Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. Neural ordinary dif-
ferential equations. In Advances in neural information processing systems, pages 6571–6583,
2018."
REFERENCES,0.6470588235294118,"Zhengdao Chen, Jianyu Zhang, Martin Arjovsky, and Léon Bottou. Symplectic recurrent neural
networks. arXiv preprint arXiv:1909.13334, 2019."
REFERENCES,0.6507352941176471,"Kurtland Chua, Roberto Calandra, Rowan McAllister, and Sergey Levine. Deep reinforcement learn-
ing in a handful of trials using probabilistic dynamics models. arXiv preprint arXiv:1805.12114,
2018."
REFERENCES,0.6544117647058824,"Miles Cranmer, Sam Greydanus, Stephan Hoyer, Peter Battaglia, David Spergel, and Shirley Ho.
Lagrangian neural networks. arXiv preprint arXiv:2003.04630, 2020."
REFERENCES,0.6580882352941176,"Shaan Desai, Marios Mattheakis, David Sondak, Pavlos Protopapas, and Stephen Roberts. Port-
hamiltonian neural networks for learning explicit time-dependent dynamical systems.
arXiv
preprint arXiv:2107.08024, 2021."
REFERENCES,0.6617647058823529,"Marc Finzi, Ke Alexander Wang, and Andrew Gordon Wilson. Simplifying hamiltonian and la-
grangian neural networks via explicit constraints. arXiv preprint arXiv:2010.13581, 2020."
REFERENCES,0.6654411764705882,"Marc Finzi, Max Welling, and Andrew Gordon Wilson. A practical method for constructing equiv-
ariant multilayer perceptrons for arbitrary matrix groups. arXiv preprint arXiv:2104.09459, 2021."
REFERENCES,0.6691176470588235,"Arnab Ghosh, Harkirat Singh Behl, Emilien Dupont, Philip HS Torr, and Vinay Namboodiri. Steer:
Simple temporal regularization for neural odes. arXiv preprint arXiv:2006.10711, 2020."
REFERENCES,0.6727941176470589,"Samuel J Greydanus, Misko Dzumba, and Jason Yosinski. Hamiltonian neural networks. 2019."
REFERENCES,0.6764705882352942,"Jayesh K Gupta, Kunal Menda, Zachary Manchester, and Mykel J Kochenderfer. A general frame-
work for structured learning of mechanical systems. arXiv preprint arXiv:1902.08705, 2019."
REFERENCES,0.6801470588235294,"Jayesh K Gupta, Kunal Menda, Zachary Manchester, and Mykel Kochenderfer. Structured mechani-
cal models for robot learning and control. In Learning for Dynamics and Control, pages 328–337.
PMLR, 2020."
REFERENCES,0.6838235294117647,"Tuomas Haarnoja, Aurick Zhou, Kristian Hartikainen, George Tucker, Sehoon Ha, Jie Tan, Vikash
Kumar, Henry Zhu, Abhishek Gupta, Pieter Abbeel, et al. Soft actor-critic algorithms and appli-
cations. arXiv preprint arXiv:1812.05905, 2018."
REFERENCES,0.6875,"Andreas Hochlehnert, Alexander Terenin, Steindór Sæmundsson, and Marc Deisenroth. Learning
contact dynamics using physically structured neural networks. In International Conference on
Artiﬁcial Intelligence and Statistics, pages 2152–2160. PMLR, 2021."
REFERENCES,0.6911764705882353,"Michael Janner, Justin Fu, Marvin Zhang, and Sergey Levine. When to trust your model: Model-
based policy optimization. arXiv preprint arXiv:1906.08253, 2019."
REFERENCES,0.6948529411764706,Published as a conference paper at ICLR 2022
REFERENCES,0.6985294117647058,"Pengzhan Jin, Zhen Zhang, Aiqing Zhu, Yifa Tang, and George Em Karniadakis. Sympnets: Intrin-
sic structure-preserving symplectic networks for identifying hamiltonian systems. Neural Net-
works, 132:166–179, 2020."
REFERENCES,0.7022058823529411,"George Em Karniadakis, Ioannis G Kevrekidis, Lu Lu, Paris Perdikaris, Sifan Wang, and Liu Yang.
Physics-informed machine learning. Nature Reviews Physics, 3(6):422–440, 2021."
REFERENCES,0.7058823529411765,"Yann LeCun, Bernhard Boser, John Denker, Donnie Henderson, Richard Howard, Wayne Hubbard,
and Lawrence Jackel. Handwritten digit recognition with a back-propagation network. Advances
in neural information processing systems, 2, 1989."
REFERENCES,0.7095588235294118,"Kookjin Lee, Nathaniel Trask, and Panos Stinis. Machine learning structure preserving brackets for
forecasting irreversible processes. Advances in Neural Information Processing Systems, 34, 2021."
REFERENCES,0.7132352941176471,"Benedict J Leimkuhler and Robert D Skeel. Symplectic numerical integrators in constrained hamil-
tonian systems. Journal of Computational Physics, 112(1):117–125, 1994."
REFERENCES,0.7169117647058824,"Shuo-Hui Li, Chen-Xiao Dong, Linfeng Zhang, and Lei Wang. Neural canonical transformation
with symplectic ﬂows. Physical Review X, 10(2):021020, 2020."
REFERENCES,0.7205882352941176,"Ziming Li, Bohan Wang, Qi Meng, Wei Chen, Max Tegmark, and Tie-Yan Liu. Machine-learning
non-conservative dynamics for new-physics detection. arXiv preprint arXiv:2106.00026, 2021."
REFERENCES,0.7242647058823529,"Ziming Liu, Yunyue Chen, Yuanqi Du, and Max Tegmark. Physics-augmented learning: A new
paradigm beyond physics-informed learning. arXiv preprint arXiv:2109.13901, 2021."
REFERENCES,0.7279411764705882,"Michael Lutter, Christian Ritter, and Jan Peters. Deep lagrangian networks: Using physics as model
prior for deep learning. arXiv preprint arXiv:1907.04490, 2019a."
REFERENCES,0.7316176470588235,"Michael Lutter, Christian Ritter, and Jan Peters. Deep lagrangian networks: Using physics as model
prior for deep learning. arXiv preprint arXiv:1907.04490, 2019b."
REFERENCES,0.7352941176470589,"Tomas Mikolov, Martin Karaﬁát, Lukas Burget, Jan Cernock`y, and Sanjeev Khudanpur. Recurrent
neural network based language model. In Interspeech, volume 2, pages 1045–1048. Makuhari,
2010."
REFERENCES,0.7389705882352942,"Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves,
Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. Wavenet: A generative model for
raw audio. arXiv preprint arXiv:1609.03499, 2016."
REFERENCES,0.7426470588235294,"Feiyang Pan, Jia He, Dandan Tu, and Qing He. Trust the model when it is conﬁdent: Masked
model-based actor-critic. arXiv preprint arXiv:2010.04893, 2020."
REFERENCES,0.7463235294117647,"Emanuel Todorov, Tom Erez, and Yuval Tassa. Mujoco: A physics engine for model-based control.
In 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems, pages 5026–5033.
IEEE, 2012."
REFERENCES,0.75,"Yunjin Tong, Shiying Xiong, Xingzhe He, Guanghan Pan, and Bo Zhu. Symplectic neural networks
in taylor series form for hamiltonian systems. Journal of Computational Physics, 437:110325,
2021."
REFERENCES,0.7536764705882353,"Tingwu Wang and Jimmy Ba. Exploring model-based planning with policy networks. arXiv preprint
arXiv:1906.08649, 2019."
REFERENCES,0.7573529411764706,"Felix Wu, Amauri Souza, Tianyi Zhang, Christopher Fifty, Tao Yu, and Kilian Weinberger. Sim-
plifying graph convolutional networks. In International conference on machine learning, pages
6861–6871. PMLR, 2019."
REFERENCES,0.7610294117647058,"Shiying Xiong, Yunjin Tong, Xingzhe He, Shuqi Yang, Cheng Yang, and Bo Zhu. Nonseparable
symplectic neural networks. arXiv preprint arXiv:2010.12636, 2020."
REFERENCES,0.7647058823529411,"Yaofeng Desmond Zhong, Biswadip Dey, and Amit Chakraborty. Symplectic ode-net: Learning
hamiltonian dynamics with control. arXiv preprint arXiv:1909.12077, 2019."
REFERENCES,0.7683823529411765,Published as a conference paper at ICLR 2022
REFERENCES,0.7720588235294118,"Yaofeng Desmond Zhong, Biswadip Dey, and Amit Chakraborty.
Dissipative symoden: En-
coding hamiltonian dynamics with dissipation and control into deep learning. arXiv preprint
arXiv:2002.08860, 2020."
REFERENCES,0.7757352941176471,"Yaofeng Desmond Zhong, Biswadip Dey, and Amit Chakraborty. Benchmarking energy-conserving
neural networks for learning dynamics from data. In Learning for Dynamics and Control, pages
1218–1229. PMLR, 2021a."
REFERENCES,0.7794117647058824,"Yaofeng Desmond Zhong, Biswadip Dey, and Amit Chakraborty. Extending lagrangian and hamil-
tonian neural networks with differentiable contact models. Advances in Neural Information Pro-
cessing Systems, 34, 2021b."
REFERENCES,0.7830882352941176,Published as a conference paper at ICLR 2022
REFERENCES,0.7867647058823529,"A
APPENDIX OUTLINE"
REFERENCES,0.7904411764705882,"This appendix is organized as follows. In Section B, we present proofs for the energy conservation
properties of HNNs and Neural ODEs, as well as a more detailed description of symplecticity. In
Section C, we described the details of our experiments on Mujuco, including our data preprocessing,
training, and architectural decisions. Lastly, in Section D, we provide additional experimental results
requested by reviewers of our original submission. These include a comparison of alternative loss
functions and a comparison on additional rigid body systems."
REFERENCES,0.7941176470588235,"B
MATHEMATICAL DETAILS"
REFERENCES,0.7977941176470589,"B.1
ENERGY CONSERVATION FOR NEURAL ODES"
REFERENCES,0.8014705882352942,"Let F = J∇H be the ground truth dynamics of a time independent Hamiltonian, and ˆF be the
dynamics learned by a neural network through an learned Hamiltonian ˆH for HNNs or otherwise.
Given some initial condition z0, let ˆzT denote the solution to ˙z = ˆF(z) at time T starting from z0
and zT be the solution to the ground truth dynamics from z0."
REFERENCES,0.8051470588235294,"Suppose the error in the dynamics model e(z) = ˆF(z) −F(z) is bounded ∀z : ∥e(z)∥< δ and that
we are only considering a bounded region of the state space (such as the states of a pendulum with
bounded energy)."
REFERENCES,0.8088235294117647,"Since energy is conserved H(zt) = H(z0) = H(ˆz0), we can write the the energy error"
REFERENCES,0.8125,"H(ˆzT ) −H(zT ) = H(ˆzT ) −H(ˆz0) =
Z ˆzT"
REFERENCES,0.8161764705882353,"ˆz0
∇H(z)⊤dz"
REFERENCES,0.8198529411764706,"Since the value is independent of the path, we may consider the path given by the approximated
dynamics ˆzt. Noting that dˆz/dt = ˆF(ˆzt) = J∇H(ˆzt) + e(ˆzt), we have"
REFERENCES,0.8235294117647058,"H(ˆzT ) −H(zT ) =
Z T"
REFERENCES,0.8272058823529411,"0
∇H(z)⊤dˆz"
REFERENCES,0.8308823529411765,"dt dt =
Z T"
REFERENCES,0.8345588235294118,"0
∇H(ˆzt)⊤ˆF(ˆzt)dt =
Z T"
REFERENCES,0.8382352941176471,"0
[∇H(ˆzt)⊤J∇H(ˆzt) + ∇H(ˆzt)⊤e(ˆzt)]dt =
Z T"
REFERENCES,0.8419117647058824,"0
∇H(ˆzt)⊤e(ˆzt)dt."
REFERENCES,0.8455882352941176,"Bounding the maximum value of the integrand along the path, we have that"
REFERENCES,0.8492647058823529,"|H(ˆzT ) −H(zT )| < Tδ sup ∥∇H∥,
(8)"
REFERENCES,0.8529411764705882,which grows only linearly with time.
REFERENCES,0.8566176470588235,"This linear bound on the energy error is in stark contrast with the state error which could grow
exponentially according to the Lyapunov exponents, even if the dynamics error is arbitrarily small.
Advancing the ground truth and learned dynamics forward to some small time t = ϵ, ˆzϵ = z0 +
ϵ ˆF(z0) yields error ∥ˆzϵ −zϵ∥= ∥ϵ ˆF(z0) −ϵF(z0)∥= ϵ∥e(z)∥< ϵδ. And yet, this error even if
propagated by the ground truth dynamics will grow exponentially ∥ˆzT −zT ∥≈eλT ∥ˆzϵ −zϵ∥=
eλT ϵ∥e(z)∥"
REFERENCES,0.8602941176470589,"B.2
HNN ENERGY CONSERVATION"
REFERENCES,0.8639705882352942,"A simple but erroneous argument for why HNNs approximately conserve the true energy goes as
follows:"
REFERENCES,0.8676470588235294,"We would like to know if HNNs achieve better energy conservation given the same levels of error
in the predicted dynamics. For HNNs, ˆF = J∇ˆH, and we can see that the dynamics error e(z) can
also be written as e(z) = J∇( ˆH −H)."
REFERENCES,0.8713235294117647,"If we could convert a bound on the derivatives ∥e∥= ∥∇( ˆH −H)∥< δ (since J is an orthogonal
matrix) into a bound on the learned Hamiltonian itself E(z) := ˆH(z) −H(z) −c and |E| < ∆"
REFERENCES,0.875,Published as a conference paper at ICLR 2022
REFERENCES,0.8786764705882353,"holding globally for some constant c, then we would have a constraint on the energy error that
doesn’t grow with time. Expanding the difference in initial and ﬁnal energy, the constant c cancels
out and we have"
REFERENCES,0.8823529411764706,"H(ˆzT ) −H(ˆz0) = ˆH(ˆzT ) −ˆH(ˆz0) −E(ˆzT ) + E(ˆz0)
= −E(ˆzT ) + E(ˆz0),"
REFERENCES,0.8860294117647058,"using the fact that the learned energy function ˆH is conserved over the model rollout ˆzt. If there was
a constraint |E| < ∆then"
REFERENCES,0.8897058823529411,|H(ˆzT ) −H(ˆz0)| < 2∆.
REFERENCES,0.8933823529411765,"Unfortunately, even if the gradients are close and δ is small, that does not imply that ∆is small.
Small differences in gradient can add up to very large differences in the values of the two functions.
While the dynamics may well approximate the data, and achieve low rollout error, there is no reason
to believe that at a given point in phase space the learned Hamiltonian should have a value that is
close to the true Hamiltonian."
REFERENCES,0.8970588235294118,"B.3
SYMPLECTICITY"
REFERENCES,0.9007352941176471,"Symplecticity is the requirement that the dynamics satisfy (JDF)⊤= JDF. Deﬁning G = JF,
the requirement is simply that the antisymmetric part of the jacobian is 0, DG⊤−DG = 0."
REFERENCES,0.9044117647058824,"Unpacking Poincare’s lemma requires some familiarity with differential geometry concepts such as
differential forms and exterior derivatives, and so we will assume them but for this section only.
Poincare’s lemma states that on a contractible domain (such as Rn) if a differential k-form ω is
closed dω = 0 (the exterior derivative of ω is 0) then it is also exact ω = dν (it is the exterior
derivative of another differential (k −1)-form ν). While F is a vector ﬁeld, G = JF is a differential
1-form (dual to a vector ﬁeld). If DG is symmetric, then it is also closed: dG = P"
REFERENCES,0.9080882352941176,"i ∂iGjdxi∧dxj =
2 P"
REFERENCES,0.9117647058823529,"i(∂iGj −∂jGi)dxi ∧dxj = 0 since (∂iGj −∂jGi) = 0 is just another way of expressing
DG⊤−DG = 0. Therefore by Poincare’s lemma, G = dφ for some 0-form (scalar function) φ.
Therefore F = J−1dφ = Jd(−φ) since J−1 = −J. As the exterior derivative of scalar function
is just the gradient, we can deﬁne H = −φ and see that there exists a scalar function H such that
F = J∇H."
REFERENCES,0.9154411764705882,"C
MUJOCO EXPERIMENT DETAILS"
REFERENCES,0.9191176470588235,"Data collection: for each control task we trained a standard soft actor-critic RL agent to convergence
(Haarnoja et al., 2018). Note that we had to use modiﬁed versions of the Gym environments since
the standard environments preprocess observations in ad-hoc ways. For example, Hopper clips
the velocity observations to [−10, 10]d and truncates part of the position.2 Our versions of the
environments simply return [q, v] as the observation. Then we randomly split the episodes in the
replay buffer into train and test. The training data was 40K 3-step trajectories (i.e. two transitions)
randomly sampled from the training episodes. The test data was 200 200-step trajectories randomly
sampled from the test episodes. This data-collection strategy is important to the experiment because
random controls typically do not cause the agent to cover the entire state-action space. Similarly
many control policies are highly cyclical, so it is important to separate train and test splits at the
episode level."
REFERENCES,0.9227941176470589,"Training: we trained each model for 256 epochs using Adam with a batch size of 200 and weight
decay (λ = 1e-4). We used a cosine annealing learning rate schedule, with ηmax = 2e-4, ηmin =
1e-6."
REFERENCES,0.9264705882352942,"Model Architecture Each network was parameterized as a 2-layer MLP with 128 hidden units.
Each model used the Euler integration rule with 8 integration steps per transition step. The step size
was determined by the integration step size of the underlying environment, h = ∆t/8."
REFERENCES,0.9301470588235294,"NODE + SO: given the state z and controls u, a standard NODE takes dz/dt = f(z, u, θ). However,
if z = [q, v] (that is, if both position and velocity are observed), then we already have a good estimate"
REFERENCES,0.9338235294117647,2https://github.com/openai/gym/blob/master/gym/envs/mujoco/hopper.py#L31
REFERENCES,0.9375,Published as a conference paper at ICLR 2022
REFERENCES,0.9411764705882353,"of dq/dt in the observation itself, namely v. Hence we propose only using the network to model
acceleration dv/dt = f(z, u, θ), and to model dq/dt implicitly. It is important to note that we
cannot take dq/dt = v because v is observed before the control u is applied. Instead we take
dq/dt = v/2 + (v + h × dv/dt)/2, averaging the velocity at time t (before the control is applied)
and the predicted velocity at time t + 1 (after the control is applied), given an Euler integration step
of size h on v."
REFERENCES,0.9448529411764706,"This integration rule can be viewed as an approximate RK2 step on qt, where vt+1 is approximated
via a learned Euler step on vt. This approach has two beneﬁts. In the ﬁrst place it constrains the
predicted velocity and acceleration to be consistent across time. Second the model is able to take an
approximate RK2 step on q at the cost of a single forward pass (instead of 2). The latter is important
because integration error can accumulate over long rollouts, even if the model ﬁts the dynamics very
well."
REFERENCES,0.9485294117647058,"D
ADDITIONAL EXPERIMENTAL RESULTS"
REFERENCES,0.9522058823529411,"D.1
COMPARISON OF LOSS FUNCTIONS"
REFERENCES,0.9558823529411765,"In the experimental results presented in the body of the paper were obtained training on l2 loss
between integrated and ground truth trajectories. As noted in feedback the an early version of the
paper, this practice goes contrary to prior work using l1 loss for stability (Finzi et al., 2020). In
Figure 8 we show the result of changing the loss."
REFERENCES,0.9595588235294118,"Chain (l1 loss)
Chain (l2 loss)
Spring (l1 loss)
Spring (l2 loss) 10 2"
REFERENCES,0.9632352941176471,Rollout Error
REFERENCES,0.9669117647058824,"NODE
NODE + SO
HNN"
REFERENCES,0.9705882352941176,"Figure 8:
Switching from l2 to l1 loss can improve rollout error slightly, but doesn’t impact the
ordering of the models. The other elements of the experimental setup are identical to above. Error
bars show one standard deviation."
REFERENCES,0.9742647058823529,"D.2
ADDITIONAL SYSTEMS"
REFERENCES,0.9779411764705882,"To extend the comparison of NODE and HNN models, we trained models on three additional sys-
tems presented by Finzi et al. (2020). Figure 9 shows the rollout error of NODE, NODE + SO, and
HNN models. One the gyroscope system, we observe a similar result to the one above. In the magnet
pendulum and rotor systems, the results are slightly more counterintuitive, with the NODE model
outperforming the more sophisticated alternatives. We suspect the small difference in performance
in the models is due to the challenge of stably training HNNs in complex systems (with magnet
pendulum having complex dynamics and rotor having a complex coordinate system)."
REFERENCES,0.9816176470588235,Published as a conference paper at ICLR 2022
REFERENCES,0.9852941176470589,"Gyroscope
Magnet
Rotor 10 4 10 3"
REFERENCES,0.9889705882352942,Rollout Error
REFERENCES,0.9926470588235294,"NODE
NODE + SO
HNN"
REFERENCES,0.9963235294117647,"Figure 9: On the additional systems from Finzi et al. (2020), we can observe the effect of second
order structure, compared with NODE and HNN baselines. As before, second order structure seems
to account for much of the difference between NODE and HNN models. Error bars show one
standard deviation."
