Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0018832391713747645,"Job-shop scheduling problem (JSP) is a mathematical optimization problem widely
1"
ABSTRACT,0.003766478342749529,"used in industries like manufacturing, and flexible JSP (FJSP) is also a common
2"
ABSTRACT,0.005649717514124294,"variant. Since they are NP-hard, it is intractable to find the optimal solution for
3"
ABSTRACT,0.007532956685499058,"all cases within reasonable times. Thus, it becomes important to develop efficient
4"
ABSTRACT,0.009416195856873822,"heuristics to solve JSP/FJSP. A kind of method of solving scheduling problems
5"
ABSTRACT,0.011299435028248588,"is construction heuristics, which constructs scheduling solutions via heuristics.
6"
ABSTRACT,0.013182674199623353,"Recently, many methods for construction heuristics leverage deep reinforcement
7"
ABSTRACT,0.015065913370998116,"learning (DRL) with graph neural networks (GNN). In this paper, we propose a new
8"
ABSTRACT,0.01694915254237288,"approach, named residual scheduling, to solving JSP/FJSP. In this new approach,
9"
ABSTRACT,0.018832391713747645,"we remove irrelevant machines and jobs such as those finished, such that the states
10"
ABSTRACT,0.02071563088512241,"include the remaining (or relevant) machines and jobs only. Our experiments show
11"
ABSTRACT,0.022598870056497175,"that our approach reaches state-of-the-art (SOTA) among all known construction
12"
ABSTRACT,0.02448210922787194,"heuristics on most well-known open JSP and FJSP benchmarks. In addition, we
13"
ABSTRACT,0.026365348399246705,"also observe that even though our model is trained for scheduling problems of
14"
ABSTRACT,0.02824858757062147,"smaller sizes, our method still performs well for scheduling problems of large sizes.
15"
ABSTRACT,0.030131826741996232,"Interestingly in our experiments, our approach even reaches zero gap for 49 among
16"
ABSTRACT,0.032015065913371,"50 JSP instances whose job numbers are more than 150 on 20 machines.
17"
INTRODUCTION,0.03389830508474576,"1
Introduction
18"
INTRODUCTION,0.035781544256120526,"The job-shop scheduling problem (JSP) is a mathematical optimization (MO) problem widely used in
19"
INTRODUCTION,0.03766478342749529,"many industries, like manufacturing (Zhang et al., 2020; Waschneck et al., 2016). For example, a
20"
INTRODUCTION,0.03954802259887006,"semiconductor manufacturing process can be viewed as a complex JSP problem (Waschneck et al.,
21"
INTRODUCTION,0.04143126177024482,"2016), where a set of given jobs are assigned to a set of machines under some constraints to achieve
22"
INTRODUCTION,0.04331450094161959,"some expected goals such as minimizing makespan which is focused on in this paper. While there are
23"
INTRODUCTION,0.04519774011299435,"many variants of JSP (Abdolrazzagh-Nezhad and Abdullah, 2017), we also consider an extension
24"
INTRODUCTION,0.047080979284369114,"called flexible JSP (FJSP) where job operations can be done on designated machines.
25"
INTRODUCTION,0.04896421845574388,"A generic approach to solving MO problems is to use mathematical programming, such as mixed
26"
INTRODUCTION,0.05084745762711865,"integer linear programming (MILP) and constraint satisfaction problem (CSP). Two popular generic
27"
INTRODUCTION,0.05273069679849341,"MO solvers for solving MO are OR-Tools (Perron and Furnon, 2019) and IBM ILOG CPLEX
28"
INTRODUCTION,0.054613935969868174,"Optimizer (abbr. CPLEX) (Cplex, 2009). However, both JSP and FJSP, as well as many other MO
29"
INTRODUCTION,0.05649717514124294,"problems, have been shown to be NP-hard (Garey and Johnson, 1979; Lageweg et al., 1977). That
30"
INTRODUCTION,0.0583804143126177,"said, it is unrealistic and intractable to find the optimal solution for all cases within reasonable times.
31"
INTRODUCTION,0.060263653483992465,"These tools can obtain the optimal solutions if sufficient time (or unlimited time) is given; otherwise,
32"
INTRODUCTION,0.062146892655367235,"return best-effort solutions during the limited time, which usually have gaps to the optimum. When
33"
INTRODUCTION,0.064030131826742,"problems are scaled up, the gaps usually grow significantly.
34"
INTRODUCTION,0.06591337099811675,"In practice, some heuristics (Gupta and Sivakumar, 2006; Haupt, 1989) or approximate methods
35"
INTRODUCTION,0.06779661016949153,"(Jansen et al., 2000) were used to cope with the issue of intractability. A simple greedy approach is to
36"
INTRODUCTION,0.0696798493408663,"use the heuristics following the so-called priority dispatching rule (PDR) (Haupt, 1989) to construct
37"
INTRODUCTION,0.07156308851224105,"solutions. These can also be viewed as a kind of solution construction heuristics or construction
38"
INTRODUCTION,0.07344632768361582,"heuristics. Some of PDR examples are First In First Out (FIFO), Shortest Processing Time (SPT),
39"
INTRODUCTION,0.07532956685499058,"Most WorK Remaining (MWKR), and Most Operation Remaining (MOR). Although these heuristics
40"
INTRODUCTION,0.07721280602636535,"are usually computationally fast, it is hard to design generally effective rules to minimize the gap to
41"
INTRODUCTION,0.07909604519774012,"the optimum, and the derived results are usually far from the optimum.
42"
INTRODUCTION,0.08097928436911488,"Furthermore, a generic approach to automating the design of heuristics is called metaheuristics, such
43"
INTRODUCTION,0.08286252354048965,"as tabu search (Dell’Amico and Trubian, 1993; Saidi-Mehrabad and Fattahi, 2007) , genetic algorithm
44"
INTRODUCTION,0.0847457627118644,"(GA) (Pezzella et al., 2008; Ren and Wang, 2012), and PSO algorithms (Lian et al., 2006; Liu et al.,
45"
INTRODUCTION,0.08662900188323917,"2011). However, metaheuristics still take a high computation time, and it is not ensured to obtain the
46"
INTRODUCTION,0.08851224105461393,"optimal solution either.
47"
INTRODUCTION,0.0903954802259887,"Recently, deep reinforcement learning (DRL) has made several significant successes for some
48"
INTRODUCTION,0.09227871939736347,"applications, such as AlphaGo (Silver et al., 2016), AlphaStar (Vinyals et al., 2019), AlphaTensor
49"
INTRODUCTION,0.09416195856873823,"(Fawzi et al., 2022), and thus it also attracted much attention in the MO problems, including chip
50"
INTRODUCTION,0.096045197740113,"design (Mirhoseini et al., 2021) and scheduling problems (Zhang et al., 2023). In the past, several
51"
INTRODUCTION,0.09792843691148775,"researchers used DRL methods as construction heuristics, and their methods did improve scheduling
52"
INTRODUCTION,0.09981167608286252,"performance, illustrated as follows. Park et al. (2020) proposed a method based on DQN (Mnih et al.,
53"
INTRODUCTION,0.1016949152542373,"2015) for JSP in semiconductor manufacturing and showed that their DQN model outperformed GA
54"
INTRODUCTION,0.10357815442561205,"in terms of both scheduling performance (namely gap to the optimum on makespan) and computation
55"
INTRODUCTION,0.10546139359698682,"time. Lin et al. (2019) and Luo (2020) proposed different DQN models to decide the scheduling action
56"
INTRODUCTION,0.10734463276836158,"among the heuristic rules and improved the makespan and the tardiness over PDRs, respectively.
57"
INTRODUCTION,0.10922787193973635,"A recent DRL-based approach to solving JSP/FJSP problems is to leverage graph neural networks
58"
INTRODUCTION,0.1111111111111111,"(GNN) to design a size-agnostic representation (Zhang et al., 2020; Park et al., 2021b,a; Song et al.,
59"
INTRODUCTION,0.11299435028248588,"2023). In this approach, graph representation has better generalization ability in larger instances
60"
INTRODUCTION,0.11487758945386065,"and provides a holistic view of scheduling states. Zhang et al. (2020) proposed a DRL method
61"
INTRODUCTION,0.1167608286252354,"with disjunctive graph representation for JSP, called L2D (Learning to Dispatch), and used GNN
62"
INTRODUCTION,0.11864406779661017,"to encode the graph for scheduling decision. Besides, Song et al. (2023) extended their methods
63"
INTRODUCTION,0.12052730696798493,"to FJSP. Park et al. (2021b) used a similar strategy of (Zhang et al., 2020) but with different state
64"
INTRODUCTION,0.1224105461393597,"features and model structure. Park et al. (2021a) proposed a new approach to solving JSP, called
65"
INTRODUCTION,0.12429378531073447,"ScheduleNet, by using a different graph representation and a DRL model with the graph attention for
66"
INTRODUCTION,0.12617702448210924,"scheduling decision. Most of the experiments above showed that their models trained from small
67"
INTRODUCTION,0.128060263653484,"instances still worked reasonably well for large test instances, and generally better than PDRs. Among
68"
INTRODUCTION,0.12994350282485875,"these methods, ScheduleNet achieved state-of-the-art (SOTA) performance. There are still other
69"
INTRODUCTION,0.1318267419962335,"DRL-based approaches to solving JSP/FJSP problems, but not construction heuristics. Zhang et al.
70"
INTRODUCTION,0.1337099811676083,"(2022) proposes another approach, called Learning to Search (L2S), a kind of search-based heuristics.
71"
INTRODUCTION,0.13559322033898305,"In this paper, we propose a new approach to solving JSP/FJSP, a kind of construction heuristics, also
72"
INTRODUCTION,0.1374764595103578,"based on GNN. In this new approach, we remove irrelevant machines and jobs, such as those finished,
73"
INTRODUCTION,0.1393596986817326,"such that the states include the remaining machines and jobs only. This approach is named residual
74"
INTRODUCTION,0.14124293785310735,"scheduling in this paper to indicate to work on the remaining graph.
75"
INTRODUCTION,0.1431261770244821,"Without irrelevant information, our experiments show that our approach reaches SOTA by outper-
76"
INTRODUCTION,0.14500941619585686,"forming the above mentioned construction methods on some well-known open benchmarks, seven
77"
INTRODUCTION,0.14689265536723164,"for JSP and two for FJSP, as described in Section 4. We also observe that even though our model
78"
INTRODUCTION,0.1487758945386064,"is trained for scheduling problems of smaller sizes, our method still performs well for scheduling
79"
INTRODUCTION,0.15065913370998116,"problems of large sizes. Interestingly in our experiments, our approach even reaches zero gap for 49
80"
INTRODUCTION,0.15254237288135594,"among 50 JSP instances whose job numbers are more than 150 on 20 machines.
81"
PROBLEM FORMULATION,0.1544256120527307,"2
Problem Formulation
82"
JSP AND FJSP,0.15630885122410546,"2.1
JSP and FJSP
83"
JSP AND FJSP,0.15819209039548024,"A n × m JSP instance contains n jobs and m machines. Each job Jj consists of a sequence of kj
84"
JSP AND FJSP,0.160075329566855,"operations {Oj,1, . . . , Oj,kj}, where operation Oj,i must be started after Oj,i−1 is finished. One
85"
JSP AND FJSP,0.16195856873822975,"machine can process at most one operation at a time, and preemption is not allowed upon processing
86"
JSP AND FJSP,0.1638418079096045,"operations. In JSP, one operation Oj,i is allowed to be processed on one designated machine, denoted
87"
JSP AND FJSP,0.1657250470809793,"by Mj,i, with a processing time, denoted by T (op)
j,i . Table 1 (a) illustrates a 3 × 3 JSP instance, where
88"
JSP AND FJSP,0.16760828625235405,"the three jobs have 3, 3, 2 operations respectively, each of which is designated to be processed on
89"
JSP AND FJSP,0.1694915254237288,"one of the three machines {M1, M2, M3} in the table. A solution of a JSP instance is to dispatch all
90"
JSP AND FJSP,0.1713747645951036,"operations Oj,i to the corresponding machine Mj,i at time τ (s)
j,i , such that the above constraints are
91"
JSP AND FJSP,0.17325800376647835,"satisfied. Two solutions of the above 3x3 JSP instance are given in Figure 1 (a) and (b).
92"
JSP AND FJSP,0.1751412429378531,Table 1: JSP and FJSP instances
JSP AND FJSP,0.17702448210922786,"(a) A 3 × 3 JSP instance
Job
Operation
M1
M2
M3 Job 1"
JSP AND FJSP,0.17890772128060264,"O1,1
3
O1,2
5
O1,3
4 Job 2"
JSP AND FJSP,0.1807909604519774,"O2,1
2
O2,2
4
O2,3
3"
JSP AND FJSP,0.18267419962335216,"Job 3
O3,1
3
O3,2
2"
JSP AND FJSP,0.18455743879472694,"(b) A 3 × 3 FJSP instance
Job
Operation
M1
M2
M3 Job 1"
JSP AND FJSP,0.1864406779661017,"O1,1
3
2
O1,2
3
5
O1,3
4
3 Job 2"
JSP AND FJSP,0.18832391713747645,"O2,1
2
O2,2
4
O2,3
3"
JSP AND FJSP,0.1902071563088512,"Job 3
O3,1
3
4
O3,2
2
2"
JSP AND FJSP,0.192090395480226,"(a)
(b)
(c)
(d)"
JSP AND FJSP,0.19397363465160075,"Figure 1: Both (a) and (b) are solutions of the 3x3 JSP instance in Table 1 (a), and the former has the
minimal makespan, 12. Both (c) and (d) are solutions of the 3x3 FJSP instance in Table 1 (b), and the
former has the minimal makespan, 9."
JSP AND FJSP,0.1958568738229755,"While there are different expected goals, such as makespan, tardiness, etc., this paper focuses on
93"
JSP AND FJSP,0.1977401129943503,"makespan. Let the first operation start at time τ = 0 in a JSP solution initially. The makespan of the
94"
JSP AND FJSP,0.19962335216572505,"solution is defined to be T (mksp) = max(τ (c)
j,i ) for all operations Oj,i, where τ (c)
j,i = τ (s)
j,i + T (op)
j,i
95"
JSP AND FJSP,0.2015065913370998,"denotes the completion time of Oj,i. The makespans for the two solutions illustrated in Figure 1 (a)
96"
JSP AND FJSP,0.2033898305084746,"and (b) are 12 and 15 respectively. The objective is to derive a solution that minimizes the makespan
97"
JSP AND FJSP,0.20527306967984935,"T (mksp), and the solution of Figure 1 (a) reaches the optimal.
98"
JSP AND FJSP,0.2071563088512241,"A n × m FJSP instance is also a n × m JSP instance with the following difference. In FJSP,
99"
JSP AND FJSP,0.20903954802259886,"all operations Oj,i are allowed to be dispatched to multiple designated machines with designated
100"
JSP AND FJSP,0.21092278719397364,"processing times. Table 1 (b) illustrates a 3 × 3 FJSP instance, where multiple machines can be
101"
JSP AND FJSP,0.2128060263653484,"designated to be processed for one operation. Figure 1 (c) illustrates a solution of an FJSP instance,
102"
JSP AND FJSP,0.21468926553672316,"which takes a shorter time than that in Figure 1 (d).
103"
CONSTRUCTION HEURISTICS,0.21657250470809794,"2.2
Construction Heuristics
104"
CONSTRUCTION HEURISTICS,0.2184557438794727,"An approach to solving these scheduling problems is to construct solutions step by step in a greedy
105"
CONSTRUCTION HEURISTICS,0.22033898305084745,"manner, and the heuristics based on this approach is called construction heuristics in this paper. In
106"
CONSTRUCTION HEURISTICS,0.2222222222222222,"the approach of construction heuristics, a scheduling solution is constructed through a sequence of
107"
CONSTRUCTION HEURISTICS,0.224105461393597,"partial solutions in a chronicle order of dispatching operations step by step, defined as follows. The
108"
CONSTRUCTION HEURISTICS,0.22598870056497175,"t-th partial solution St associates with a dispatching time τt and includes a partial set of operations
109"
CONSTRUCTION HEURISTICS,0.2278719397363465,"that have been dispatched by τt (inclusive) while satisfying the above JSP constraints, and all the
110"
CONSTRUCTION HEURISTICS,0.2297551789077213,"remaining operations must be dispatched after τt (inclusive). The whole construction starts with S0
111"
CONSTRUCTION HEURISTICS,0.23163841807909605,"where none of operations have been dispatched and the dispatching time is τ0 = 0. For each St, a set
112"
CONSTRUCTION HEURISTICS,0.2335216572504708,"of operations to be chosen for dispatching form a set of pairs of (M, O), called candidates Ct, where
113"
CONSTRUCTION HEURISTICS,0.23540489642184556,"operations O are allowed to be dispatched on machines M at τt. An agent (or a heuristic algorithm)
114"
CONSTRUCTION HEURISTICS,0.23728813559322035,"chooses one from candidates Ct for dispatching, and transits the partial solution to the next St+1. If
115"
CONSTRUCTION HEURISTICS,0.2391713747645951,"there exists no operations for dispatching, the whole solution construction process is done and the
116"
CONSTRUCTION HEURISTICS,0.24105461393596986,"partial solution is a solution, since no further operations are to be dispatched.
117"
CONSTRUCTION HEURISTICS,0.24293785310734464,"(a) S0
(b) S1
(c) S2"
CONSTRUCTION HEURISTICS,0.2448210922787194,"(d) S3
(e) S4
(f) S5"
CONSTRUCTION HEURISTICS,0.24670433145009416,"(g) S6
(h) S7
(i) S8"
CONSTRUCTION HEURISTICS,0.24858757062146894,"Figure 2: Solution construction, a sequence of partial solutions from S0 to S8."
CONSTRUCTION HEURISTICS,0.2504708097928437,"Figure 2 illustrates a solution construction process for the 3x3 JSP instance in Table 1(a), constructed
118"
CONSTRUCTION HEURISTICS,0.2523540489642185,"through nine partial solutions step by step. The initial partial solution S0 starts without any operations
119"
CONSTRUCTION HEURISTICS,0.2542372881355932,"dispatched as in Figure 2 (a). The initial candidates C0 are {(M1, O1,1), (M3, O2,1), (M1, O3,1)}.
120"
CONSTRUCTION HEURISTICS,0.256120527306968,"Following some heuristic, construct a solution from partial solution S0 to S9 step by step as in the
121"
CONSTRUCTION HEURISTICS,0.2580037664783427,"Figure, where the dashed line in red indicate the time τt. The last one S9, the same as the one in
122"
CONSTRUCTION HEURISTICS,0.2598870056497175,"Figure 1 (a), is a solution, since all operations have been dispatched, and the last operation ends at
123"
CONSTRUCTION HEURISTICS,0.2617702448210923,"time 12, the makespan of the solution.
124"
CONSTRUCTION HEURISTICS,0.263653483992467,"For FJSP, the process of solution construction is almost the same except for that one operation have
125"
CONSTRUCTION HEURISTICS,0.2655367231638418,"multiple choices from candidates. Besides, an approach based on solution construction can be also
126"
CONSTRUCTION HEURISTICS,0.2674199623352166,"viewed as the so-called Markov decision process (MDP), and the MDP formulation for solution
127"
CONSTRUCTION HEURISTICS,0.2693032015065913,"construction is described in more detail in the appendix.
128"
OUR APPROACH,0.2711864406779661,"3
Our Approach
129"
OUR APPROACH,0.2730696798493409,"In this section, we present a new approach, called residual scheduling, to solving scheduling problems.
130"
OUR APPROACH,0.2749529190207156,"We introduce the residual scheduling in Subsection 3.1, describe the design of the graph representation
131"
OUR APPROACH,0.2768361581920904,"in Subsection 3.2, propose a model architecture based on graph neural network in Subsection 3.3 and
132"
OUR APPROACH,0.2787193973634652,"present a method to train this model in Subsection 3.4;
133"
RESIDUAL SCHEDULING,0.2806026365348399,"3.1
Residual Scheduling
134"
RESIDUAL SCHEDULING,0.2824858757062147,"In our approach, the key is to remove irrelevant information, particularly for operations, from states
135"
RESIDUAL SCHEDULING,0.2843691148775895,"(including partial solutions). An important benefit from this is that we do not need to include all
136"
RESIDUAL SCHEDULING,0.2862523540489642,"irrelevant information while training to minimize the makespan. Let us illustrate by the state for the
137"
RESIDUAL SCHEDULING,0.288135593220339,"partial solution S3 at time τ3 = 3 in Figure 2 (d). All processing by τ3 are irrelevant to the remaining
138"
RESIDUAL SCHEDULING,0.2900188323917137,"scheduling. Since operations O1,1 and O2,1 are both finished and irrelevant the rest of scheduling,
139"
RESIDUAL SCHEDULING,0.2919020715630885,"they can be removed from the state of S3. In addition, operation O2,2 is dispatched at time 2 (before
140"
RESIDUAL SCHEDULING,0.2937853107344633,"τ3 = 3) and its processing time is T (op)
2,1
= 4, so the operation is marked as ongoing. Thus, the
141"
RESIDUAL SCHEDULING,0.295668549905838,"operation can be modified to start at τ3 = 3 with a processing time 4 −(3 −2). Thus, the modified
142"
RESIDUAL SCHEDULING,0.2975517890772128,"state for S3 do not contain both O1,1 and O2,1, and modify O2,2 as above. Let us consider two more
143"
RESIDUAL SCHEDULING,0.2994350282485876,"examples. For S4, one more operation O2,2 is dispatched and thus marked as ongoing, however, the
144"
RESIDUAL SCHEDULING,0.3013182674199623,"time τ4 remains unchanged and no more operations are removed. In this case, the state is almost the
145"
RESIDUAL SCHEDULING,0.3032015065913371,"same except for including one more ongoing operation O2,2. Then, for S5, two more operations O3,1
146"
RESIDUAL SCHEDULING,0.3050847457627119,"and O2,2 are removed and the ongoing operation O1,2 changes its processing time to the remaining
147"
RESIDUAL SCHEDULING,0.3069679849340866,"time (5-3).
148"
RESIDUAL SCHEDULING,0.3088512241054614,"For residual scheduling, we also reset the dispatching time τ = 0 for all states with partial solutions
149"
RESIDUAL SCHEDULING,0.3107344632768362,"modified as above, so we derive makespans which is also irrelevant to the earlier operations. Given
150"
RESIDUAL SCHEDULING,0.3126177024482109,"a scheduling policy π, T (mksp)
π
(S) is defined to be the makespan derived from an episode starting
151"
RESIDUAL SCHEDULING,0.3145009416195857,"from states S by following π, and T (mksp)
π
(S, a) the makespan by taking action a on S.
152"
RESIDUAL GRAPH REPRESENTATION,0.3163841807909605,"3.2
Residual Graph Representation
153"
RESIDUAL GRAPH REPRESENTATION,0.3182674199623352,"In this paper, our model design is based on graph neural network (GNN), and leverage GNN to
154"
RESIDUAL GRAPH REPRESENTATION,0.32015065913371,"extract the scheduling decision from the relationship in graph. In this subsection, we present the
155"
RESIDUAL GRAPH REPRESENTATION,0.3220338983050847,"graph representation. Like many other researchers such as Park et al. (2021a), we formulate a partial
156"
RESIDUAL GRAPH REPRESENTATION,0.3239171374764595,"solution into a graph G = (V, E), where V is a set of nodes and E is a set of edges. A node is either a
157"
RESIDUAL GRAPH REPRESENTATION,0.3258003766478343,"machine node M or an operation node O. An edge connects two nodes to represent the relationship
158"
RESIDUAL GRAPH REPRESENTATION,0.327683615819209,"between two nodes, basically including three kinds of edges, namely operation-to-operation (O →O),
159"
RESIDUAL GRAPH REPRESENTATION,0.3295668549905838,"machine-to-operation (M →O) and operation-to-machine (O →M). All operations in the same
160"
RESIDUAL GRAPH REPRESENTATION,0.3314500941619586,"job are fully connected as O →O edges. If an operation O is able to be performed on a machine
161"
RESIDUAL GRAPH REPRESENTATION,0.3333333333333333,"M, there exists both O →M and M →O directed edges. In (Park et al., 2021a), they also let all
162"
RESIDUAL GRAPH REPRESENTATION,0.3352165725047081,"machines be fully connected as M →M edges. However, our experiments in section 4 show that
163"
RESIDUAL GRAPH REPRESENTATION,0.3370998116760829,"mutual M →M edges do not help much based on our Residual Scheduling. An illustration for graph
164"
RESIDUAL GRAPH REPRESENTATION,0.3389830508474576,"representation of S3 is depicted in Figure 3 (a).
165"
RESIDUAL GRAPH REPRESENTATION,0.3408662900188324,"(a) Graph for S3
(b) Graph embedding
(c) Score function"
RESIDUAL GRAPH REPRESENTATION,0.3427495291902072,Figure 3: Graph representation and networks.
RESIDUAL GRAPH REPRESENTATION,0.3446327683615819,"In the graph representation, all nodes need to include some attributes so that a partial solution S at
166"
RESIDUAL GRAPH REPRESENTATION,0.3465160075329567,"the dispatching time τ can be supported in the MDP formulation (in the appendix). Note that many of
167"
RESIDUAL GRAPH REPRESENTATION,0.3483992467043315,"the attributes below are normalized to reduce variance. For nodes corresponding to operations Oj,i,
168"
RESIDUAL GRAPH REPRESENTATION,0.3502824858757062,"we have the following attributes:
169"
RESIDUAL GRAPH REPRESENTATION,0.352165725047081,"Status ϕj,i: The operation status ϕj,i is completed if the operation has been finished by τ, ongoing if
170"
RESIDUAL GRAPH REPRESENTATION,0.3540489642184557,"the operation is ongoing (i.e., has been dispatched to some machine by τ and is still being processed
171"
RESIDUAL GRAPH REPRESENTATION,0.3559322033898305,"at τ), ready if the operation designated to the machine which is idle has not been dispatched yet and
172"
RESIDUAL GRAPH REPRESENTATION,0.3578154425612053,"its precedent operation has been finished, and unready otherwise. For example, in Figure 3 (a), the
173"
RESIDUAL GRAPH REPRESENTATION,0.35969868173258,"gray nodes are completed, the red ongoing, the yellow ready and the white unready. In our residual
174"
RESIDUAL GRAPH REPRESENTATION,0.3615819209039548,"scheduling, there exists no completed operations in all partial solutions, since they are removes for
175"
RESIDUAL GRAPH REPRESENTATION,0.3634651600753296,"irrelevance of the rest of scheduling. The attribute is a one-hot vector to represent the current status
176"
RESIDUAL GRAPH REPRESENTATION,0.3653483992467043,"of the operation, which is one of ongoing, ready and unready. Illustration for all states S0 to S8 are
177"
RESIDUAL GRAPH REPRESENTATION,0.3672316384180791,"shown in the appendix.
178"
RESIDUAL GRAPH REPRESENTATION,0.3691148775894539,"Normalized processing time ¯T (op)
j,i : Let the maximal processing time be T (op)
max = max∀j,i(T (op)
j,i ).
179"
RESIDUAL GRAPH REPRESENTATION,0.3709981167608286,"Then, ¯T (op)
j,i
= T (op)
j,i /T (op)
max. In our residual scheduling, the operations that have been finished are
180"
RESIDUAL GRAPH REPRESENTATION,0.3728813559322034,"removed in partial solutions and therefore their processing time can be ignored; the operations that
181"
RESIDUAL GRAPH REPRESENTATION,0.3747645951035782,"has not been dispatched yet still keep their processing times the same; the operations that are ongoing
182"
RESIDUAL GRAPH REPRESENTATION,0.3766478342749529,"change their processing times to the remaining times after the dispatching time τt. As for FJSP, the
183"
RESIDUAL GRAPH REPRESENTATION,0.3785310734463277,"operations that has not been dispatched yet may have several processing times on different machines,
184"
RESIDUAL GRAPH REPRESENTATION,0.3804143126177024,"and thus we can simply choose the average of these processing times.
185"
RESIDUAL GRAPH REPRESENTATION,0.3822975517890772,"Normalized job remaining time ¯T (job)
j,i
: Let the rest of processing time for job Jj be T (job)
j,i
=
186 P"
RESIDUAL GRAPH REPRESENTATION,0.384180790960452,"∀i′≥i T (op)
j,i′ , and let the processing time for the whole job j be T (job)
j
= P"
RESIDUAL GRAPH REPRESENTATION,0.3860640301318267,"∀i′ T (op)
j,i′ . In practice,
187"
RESIDUAL GRAPH REPRESENTATION,0.3879472693032015,"T (job)
j
is replaced by the processing time for the original job j. Thus, ¯T (job)
j,i
= T (job)
j,i
/T (job)
j
. For
188"
RESIDUAL GRAPH REPRESENTATION,0.3898305084745763,"FJSP, since operations Oj,i can be dispatched to different designated machines Ml, say with the
189"
RESIDUAL GRAPH REPRESENTATION,0.391713747645951,"processing time T (op)
j,i,l , we simply let T (op)
j,i
be the average of T (op)
j,i,l for all Ml.
190"
RESIDUAL GRAPH REPRESENTATION,0.3935969868173258,"For machine nodes corresponding to machines Ml, we have the following attributes:
191"
RESIDUAL GRAPH REPRESENTATION,0.3954802259887006,"Machine status ϕl: The machine status ϕl is processing if some operation has been dispatched to
192"
RESIDUAL GRAPH REPRESENTATION,0.3973634651600753,"and is being processed by Ml at τ, and idle otherwise (no operation is being processed at τ). The
193"
RESIDUAL GRAPH REPRESENTATION,0.3992467043314501,"attribute is a one-hot vector to represent the current status, which is one of processing and idle.
194"
RESIDUAL GRAPH REPRESENTATION,0.4011299435028249,"Normalized operation processing time ¯T (mac)
l
: On the machine Ml, the processing time T (mac)
l
is
195"
RESIDUAL GRAPH REPRESENTATION,0.4030131826741996,"T (op)
j,i
(the same as the normalized processing time for node Oj,i) if the machine status is processing,
196"
RESIDUAL GRAPH REPRESENTATION,0.4048964218455744,"i.e., some ongoing operation Oj,i is being processed but not finished yet, is zero if the machine status
197"
RESIDUAL GRAPH REPRESENTATION,0.4067796610169492,"is idle. Then, this attribute is normalized to T (op)
max and thus ¯T (mac)
l
= T (mac)
l
/T (op)
max.
198"
RESIDUAL GRAPH REPRESENTATION,0.4086629001883239,"Now, consider edges in a residual scheduling graph. As described above, there exists three relationship
199"
RESIDUAL GRAPH REPRESENTATION,0.4105461393596987,"sets for edges, O →O, O →M and M →O. First, for the same job, say Jj, all of its operation
200"
RESIDUAL GRAPH REPRESENTATION,0.4124293785310734,"nodes for Oj,i are fully connected. Note that for residual scheduling the operations finished by the
201"
RESIDUAL GRAPH REPRESENTATION,0.4143126177024482,"dispatching time τ are removed and thus have no edges to them. Second, a machine node for Ml is
202"
RESIDUAL GRAPH REPRESENTATION,0.416195856873823,"connected to an operation node for Oj,i, if the operation Oj,i is designated to be processed on the
203"
RESIDUAL GRAPH REPRESENTATION,0.4180790960451977,"machine Ml, which forms two edges O →M and M →O. Both contains the following attribute.
204"
RESIDUAL GRAPH REPRESENTATION,0.4199623352165725,"Normalized operation processing time ¯T (edge)
j,i,l
: The attribute is ¯T (edge)
j,i,l
= T (op)
j,i /T (op)
max. Here,
205"
RESIDUAL GRAPH REPRESENTATION,0.4218455743879473,"T (op)
j,i
= T (op)
j,i,l in the case of FJSP. If operation Oj,i is ongoing (or being processed), T (op)
j,i
is the
206"
RESIDUAL GRAPH REPRESENTATION,0.423728813559322,"remaining time as described above.
207"
GRAPH NEURAL NETWORK,0.4256120527306968,"3.3
Graph Neural Network
208"
GRAPH NEURAL NETWORK,0.4274952919020716,"In this subsection, we present our model based on graph neural network (GNN). GNN are a family
209"
GRAPH NEURAL NETWORK,0.4293785310734463,"of deep neural networks (Battaglia et al., 2018) that can learn representation of graph-structured
210"
GRAPH NEURAL NETWORK,0.4312617702448211,"data, widely used in many applications (Lv et al., 2021; Zhou et al., 2020). A GNN aggregates
211"
GRAPH NEURAL NETWORK,0.4331450094161959,"information from node itself and its neighboring nodes and then update the data itself, which allows
212"
GRAPH NEURAL NETWORK,0.4350282485875706,"the GNN to capture the complex relationships within the data graph. For GNN, we choose Graph
213"
GRAPH NEURAL NETWORK,0.4369114877589454,"Isomorphism Network (GIN), which was shown to have strong discriminative power (Xu et al., 2019)
214"
GRAPH NEURAL NETWORK,0.4387947269303202,"and summarily reviewed as follows. Given a graph G = (V, E) and K GNN layers (K iterations),
215"
GRAPH NEURAL NETWORK,0.4406779661016949,"GIN performs the k-th iterations of updating feature embedding h(k) for each node v ∈V:
216"
GRAPH NEURAL NETWORK,0.4425612052730697,"h(k)
v
= MLP (k)((1 + ϵ(k))h(k−1)
v
+
X"
GRAPH NEURAL NETWORK,0.4444444444444444,"u∈Nb(v)
h(k−1)
u
),
(1)"
GRAPH NEURAL NETWORK,0.4463276836158192,"where h(k)
v
is the embedding of node v at the k-th layer, ϵ(k) is an arbitrary number that can be
217"
GRAPH NEURAL NETWORK,0.448210922787194,"learned, and Nb(v) is the neighbors of v via edges in E. Note that h(0)
v
refers to its raw features for
218"
GRAPH NEURAL NETWORK,0.4500941619585687,"input. MLP (k) is a Multi-Layer Perceptron (MLP) for the k-th layer with a batch normalization
219"
GRAPH NEURAL NETWORK,0.4519774011299435,"(Ioffe and Szegedy, 2015).
220"
GRAPH NEURAL NETWORK,0.4538606403013183,"Furthermore, we actually use heterogeneous GIN, also called HGIN, since there are two types of
221"
GRAPH NEURAL NETWORK,0.455743879472693,"nodes, machine and operation nodes, and three relations, O →O, O →M and M →O in the
222"
GRAPH NEURAL NETWORK,0.4576271186440678,"graph representation. Although we do not have cross machine relations M →M as described above,
223"
GRAPH NEURAL NETWORK,0.4595103578154426,"updating machine nodes requires to include the update from itself as in (1), that is, there is also one
224"
GRAPH NEURAL NETWORK,0.4613935969868173,"more relation M →M. Thus, HGIN encodes graph information between all relations by using the
225"
GRAPH NEURAL NETWORK,0.4632768361581921,"four MLPs as follows,
226"
GRAPH NEURAL NETWORK,0.4651600753295669,"h(k+1)
v
=
X"
GRAPH NEURAL NETWORK,0.4670433145009416,"R
MLP (k+1)
R
((1 + ϵ(k+1)
R
)h(k)
v
+
X"
GRAPH NEURAL NETWORK,0.4689265536723164,"u∈NR(v)
h(k)
u )
(2)"
GRAPH NEURAL NETWORK,0.4708097928436911,"where R is one of the above four relations and MLP (k)
R
is the MLP for R. For example, for S0 in
227"
GRAPH NEURAL NETWORK,0.4726930320150659,"Figure 2 (a), the embedding of M1 in the (k + 1)-st iteration can be derived as follows.
228"
GRAPH NEURAL NETWORK,0.4745762711864407,"h(k+1)
M1
= MLP (k+1)
MM ((1 + ϵ(k+1)
MM )h(k)
M1) + MLP (k+1)
OM
(h(k)
O1,1 + h(k)
O1,2 + h(k)
O1,3)
(3)"
GRAPH NEURAL NETWORK,0.4764595103578154,"Similarly, the embedding of O1,1 in the (k + 1)-st iteration is:
229"
GRAPH NEURAL NETWORK,0.4783427495291902,"h(k+1)
O1,1
= MLP (k+1)
OO
((1 + ϵ(k+1)
OO
)h(k)
O1,1 + h(k)
O1,2 + h(k)
O1,3) + MLP (k+1)
MO
(h(k)
M1)
(4)"
GRAPH NEURAL NETWORK,0.480225988700565,"In our approach, an action includes the two phases, graph embedding phase and action selection phase.
230"
GRAPH NEURAL NETWORK,0.4821092278719397,"Let h(k)
G
denote the whole embedding of the graphs G, a summation of the embeddings of all nodes,
231"
GRAPH NEURAL NETWORK,0.4839924670433145,"h(k+1)
v
. In the graph embedding phase, we use an HGIN to encode node and graph embeddings as
232"
GRAPH NEURAL NETWORK,0.4858757062146893,"described above. An example with three HGIN layers is illustrated in Figure 3 (b).
233"
GRAPH NEURAL NETWORK,0.487758945386064,"In the action selection phase, we select an action based on a policy, after node and graph embedding
234"
GRAPH NEURAL NETWORK,0.4896421845574388,"are encoded in the graph embedding phase. The policy is described as follows. First, collect all
235"
GRAPH NEURAL NETWORK,0.4915254237288136,"ready operations O to be dispatched to machines M. Then, for all pairs (M, O), feed their node
236"
GRAPH NEURAL NETWORK,0.4934086629001883,"embeddings (h(k)
M , h(k)
O ) into a MLP Score(M, O) to calculate their scores as shown in Figure 3 (c).
237"
GRAPH NEURAL NETWORK,0.4952919020715631,"The probability of selecting (M, O) is calculated based on a softmax function of all scores, which
238"
GRAPH NEURAL NETWORK,0.4971751412429379,"also serves as the model policy π for the current state.
239"
POLICY-BASED RL TRAINING,0.4990583804143126,"3.4
Policy-Based RL Training
240"
POLICY-BASED RL TRAINING,0.5009416195856874,"In this paper, we propose to use a policy-based RL training mechanism that follows REINFORCE
241"
POLICY-BASED RL TRAINING,0.5028248587570622,"(Sutton and Barto, 2018) to update our model by policy gradient with a normalized advantage
242"
POLICY-BASED RL TRAINING,0.504708097928437,"makespan with respect to a baseline policy πb as follows.
243"
POLICY-BASED RL TRAINING,0.5065913370998116,"Aπ(S, a) = T (mksp)
πb
(S, a) −T (mksp)
π
(S, a)"
POLICY-BASED RL TRAINING,0.5084745762711864,"T (mksp)
πb
(S, a)
(5)"
POLICY-BASED RL TRAINING,0.5103578154425612,"In this paper, we choose a lightweight PDR, MWKR, as baseline πb, which performed best for
244"
POLICY-BASED RL TRAINING,0.512241054613936,"makespan among all PDRs reported from the previous work (Zhang et al., 2020). In fact, our
245"
POLICY-BASED RL TRAINING,0.5141242937853108,"experiment also shows that using MWKR is better than the other PDRs shown in the appendix. The
246"
POLICY-BASED RL TRAINING,0.5160075329566854,"model for policy π is parametrized by θ, which is updated by ∇θlogπθAπθ(St, at). Our algorithm
247"
POLICY-BASED RL TRAINING,0.5178907721280602,"based on REINFORCE is listed in the appendix.
248"
EXPERIMENTS,0.519774011299435,"4
Experiments
249"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5216572504708098,"4.1
Experimental Settings and Evaluation Benchmarks
250"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5235404896421846,"In our experiments, the settings of our model are described as follows. All embedding and hidden
251"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5254237288135594,"vectors in our model have a dimension of 256. The model contains three HGIN layers for graph
252"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.527306967984934,"embedding, and an MLP for the score function, as shown in Figure 3 (b) and (c). All MLP networks
253"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5291902071563088,"including those in HGIN and for score contain two hidden layers. The parameters of our model, such
254"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5310734463276836,"as MLP, generally follow the default settings in PyTorch (Paszke et al., 2019) and PyTorch Geometric
255"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5329566854990584,"(Fey and Lenssen, 2019). More settings are in the appendix.
256"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5348399246704332,"Each of our models is trained with one million episodes, each with one scheduling instance. Each
257"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.536723163841808,"instance is generated by following the procedure which is used to generate the TA dataset (Taillard,
258"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5386064030131826,"1993). Given (N, M), we use the procedure to generate an n × m JSP instance by conforming to
259"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5404896421845574,"the following distribution, n ∼U(3, N), m ∼U(3, n), and operation count kj = m, where U(x, y)
260"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5423728813559322,"represents a distribution that uniformly samples an integer in a close interval [x, y] at random. The
261"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.544256120527307,"details of designation for machines and processing times refer to (Taillard, 1993) and thus are omitted
262"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5461393596986818,"here. We choose (10,10) for all experiments, since (10,10) generally performs better than the other
263"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5480225988700564,"two as described in the appendix. Following the method described in Subsection 3.4, the model is
264"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5499058380414312,"updated from the above randomly generated instances. For testing our models for JSP and FJSP,
265"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.551789077212806,"seven JSP open benchmarks and two FJSP open benchmarks are used, as listed in the appendix.
266"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5536723163841808,"The performance for a given policy method π on an instance is measured by the makespan gap G
267"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5555555555555556,"defined as
268"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5574387947269304,"G = T (mksp)
π
−T (mksp)
π∗
T (mksp)
π∗
(6)"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.559322033898305,"where T (mksp)
π∗
is the optimal makespan or the best-effort makespan, from a mathematical optimization
269"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5612052730696798,"tool, OR-Tools, serving as π∗. By the best-effort makespan, we mean the makespan derived with a
270"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5630885122410546,"Table 2: Average makespan gaps for TA benchmarks.
Size
15×15
20×15
20×20
30×15
30×20
50×15
50×20
100×20
Avg.
RS
0.148
0.165
0.169
0.144
0.177
0.067
0.100
0.026
0.125
RS+op
0.143
0.193
0.159
0.192
0.213
0.123
0.126
0.050
0.150
MWKR
0.191
0.233
0.218
0.239
0.251
0.168
0.179
0.083
0.195
MOR
0.205
0.235
0.217
0.228
0.249
0.173
0.176
0.091
0.197
SPT
0.258
0.328
0.277
0.352
0.344
0.241
0.255
0.144
0.275
FIFO
0.239
0.314
0.273
0.311
0.311
0.206
0.239
0.135
0.254
L2D
0.259
0.300
0.316
0.329
0.336
0.223
0.265
0.136
0.270
Park
0.201
0.249
0.292
0.246
0.319
0.159
0.212
0.092
0.221
SchN
0.152
0.194
0.172
0.190
0.237
0.138
0.135
0.066
0.161"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5649717514124294,"sufficiently large time limitation, namely half a day with OR-Tools. For comparison in experiments,
271"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5668549905838042,"we use a server with Intel Xeon E5-2683 CPU and a single NVIDIA GeForce GTX 1080 Ti GPU.
272"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.568738229755179,"Our method uses a CPU thread and a GPU to train and evaluate, while OR-Tools uses eight threads
273"
EXPERIMENTAL SETTINGS AND EVALUATION BENCHMARKS,0.5706214689265536,"to find the solution.
274"
EXPERIMENTS FOR JSP,0.5725047080979284,"4.2
Experiments for JSP
275"
EXPERIMENTS FOR JSP,0.5743879472693032,"For JSP, we first train a model based on residual scheduling, named RS. For ablation testing, we
276"
EXPERIMENTS FOR JSP,0.576271186440678,"also train a model, named RS+op, by following the same training method but without removing
277"
EXPERIMENTS FOR JSP,0.5781544256120528,"irrelevant operations. When using these models to solve testing instances, action selection is based
278"
EXPERIMENTS FOR JSP,0.5800376647834274,"on the greedy policy that simply chooses the action (M, O) with the highest score deterministically,
279"
EXPERIMENTS FOR JSP,0.5819209039548022,"obtained from the score network as in Figure 3 (c).
280"
EXPERIMENTS FOR JSP,0.583804143126177,"For comparison, we consider the three DRL construction heuristics, respectively developed in (Zhang
281"
EXPERIMENTS FOR JSP,0.5856873822975518,"et al., 2020) called L2D, (Park et al., 2021b) by Park et al., and (Park et al., 2021a), called ScheduleNet.
282"
EXPERIMENTS FOR JSP,0.5875706214689266,"We directly use the performance results of these methods for open benchmarks from their articles.
283"
EXPERIMENTS FOR JSP,0.5894538606403014,"For simplicity, they are named L2D, Park and SchN respectively in this paper. We also include some
284"
EXPERIMENTS FOR JSP,0.591337099811676,"construction heuristics based PDR, such as MWKR, MOR, SPT and FIFO. Besides, to derive the
285"
EXPERIMENTS FOR JSP,0.5932203389830508,"gaps to the optimum in all cases, OR-Tools serve as π∗as described in (6).
286"
EXPERIMENTS FOR JSP,0.5951035781544256,"Now, let us analyze the performances of RS as follows. Table 2 shows the average makespan gaps
287"
EXPERIMENTS FOR JSP,0.5969868173258004,"for each collection of JSP TA benchmarks with sizes, 15×15, 20×15, 20×20, 30×15, 30×20, 50×15,
288"
EXPERIMENTS FOR JSP,0.5988700564971752,"50×20 and 100×20, where the best performances (the smallest gaps) are marked in bold. In general,
289"
EXPERIMENTS FOR JSP,0.60075329566855,"RS performs the best, and generally outperforms the other methods for all collections by large
290"
EXPERIMENTS FOR JSP,0.6026365348399246,"margins, except for that it has slightly higher gaps than RS+op for the two collections, 15 × 15 and
291"
EXPERIMENTS FOR JSP,0.6045197740112994,"20 × 20. In fact, RS+op also generally outperforms the rest of methods, except for that it is very
292"
EXPERIMENTS FOR JSP,0.6064030131826742,"close to SchN for two collections. For the other six open benchmarks, ABZ, FT, ORB, YN, SWV
293"
EXPERIMENTS FOR JSP,0.608286252354049,"and LA, the performances are similar and thus presented in the appendix. It is concluded that RS
294"
EXPERIMENTS FOR JSP,0.6101694915254238,"generally performs better than other construction heuristics by large margins.
295"
EXPERIMENTS FOR FJSP,0.6120527306967984,"4.3
Experiments for FJSP
296"
EXPERIMENTS FOR FJSP,0.6139359698681732,Table 3: Average makespan gaps for FJSP open benchmarks
EXPERIMENTS FOR FJSP,0.615819209039548,"Method
MK
LA(rdata)
LA(edata)
LA(vdata)
RS
0.232
0.099
0.146
0.031
RS+op
0.254
0.113
0.168
0.029
DRL-G
0.254
0.111
0.150
0.040
MWKR
0.282
0.125
0.149
0.051
MOR
0.296
0.147
0.179
0.061
SPT
0.457
0.277
0.262
0.182
FIFO
0.307
0.166
0.220
0.075"
EXPERIMENTS FOR FJSP,0.6177024482109228,"For FJSP, we also train a model based on residual scheduling, named RS, and a ablation version,
297"
EXPERIMENTS FOR FJSP,0.6195856873822976,"named RS+op, without removing irrelevant operations. We compares ours with one DRL construction
298"
EXPERIMENTS FOR FJSP,0.6214689265536724,"heuristics developed by (Song et al., 2023), called DRL-G, and four PDR-based heuristics, MOR,
299"
EXPERIMENTS FOR FJSP,0.623352165725047,"MWKR, SPT and FIFO. We directly use the performance results of these methods for open datasets
300"
EXPERIMENTS FOR FJSP,0.6252354048964218,"according to the reports from (Song et al., 2023).
301"
EXPERIMENTS FOR FJSP,0.6271186440677966,"Table 3 shows the average makespan gaps in the four open benchmarks, MK, LA(rdata), LA(edata)
302"
EXPERIMENTS FOR FJSP,0.6290018832391714,"and LA(vdata). From the table, RS generally outperforms all the other methods for all benchmarks
303"
EXPERIMENTS FOR FJSP,0.6308851224105462,"by large margins, except for that RS+op is slightly better for the benchmark LA(vdata).
304"
DISCUSSIONS,0.632768361581921,"5
Discussions
305"
DISCUSSIONS,0.6346516007532956,"In this paper, we propose a new approach, called residual scheduling, to solving JSP an FJSP problems,
306"
DISCUSSIONS,0.6365348399246704,"and the experiments show that our approach reaches SOTA among DRL-based construction heuristics
307"
DISCUSSIONS,0.6384180790960452,"on the above open JSP and FJSP benchmarks. We further discusses three issues: large instances,
308"
DISCUSSIONS,0.64030131826742,"computation times and further improvement.
309"
DISCUSSIONS,0.6421845574387948,Figure 4: Average makespan gaps of JSP instances with different problem sizes.
DISCUSSIONS,0.6440677966101694,"First, from the above experiments particularly for TA benchmark for JSP, we observe that the average
310"
DISCUSSIONS,0.6459510357815442,"gaps gets smaller as the number of jobs increases, even if we use the same model trained with
311"
DISCUSSIONS,0.647834274952919,"(N, M) = (10, 10). In order to investigate size-agnostics, we further generate 13 collections of JSP
312"
DISCUSSIONS,0.6497175141242938,"instances of sizes for testing, from 15 × 15 to 200 × 20, and generate 10 instances for each collection
313"
DISCUSSIONS,0.6516007532956686,"by using the procedure above. Figure 4 shows the average gaps for these collections for RS and L2D,
314"
DISCUSSIONS,0.6534839924670434,"and these collections are listed in the order of sizes in the x-axis. Note that we only show the results
315"
DISCUSSIONS,0.655367231638418,"of L2D in addition to our RS, since L2D is the only open-source among the above DRL heuristics.
316"
DISCUSSIONS,0.6572504708097928,"Interestingly, using RS, the average gaps are nearly zero for the collections with sizes larger than 100
317"
DISCUSSIONS,0.6591337099811676,"× 15, namely, 100 × 15, 100 × 20, 150 × 15, 200 × 15 and 200 × 20. Among the 50 JSP instances
318"
DISCUSSIONS,0.6610169491525424,"in the five collections, 49 reaches zero gaps. A strong implication is that our RS approach can be
319"
DISCUSSIONS,0.6629001883239172,"scaled up for job sizes and even reach the optimal for sufficient large job count.
320"
DISCUSSIONS,0.664783427495292,"Second, the computation times for RS are relatively small and has low variance like most of other
321"
DISCUSSIONS,0.6666666666666666,"construction heuristics. Here, we just use the collection of TA 100x20 for illustration. It takes about
322"
DISCUSSIONS,0.6685499058380414,"30 seconds on average for both RS and RS+op, about 28 for L2D and about 444 for SchN. In contrast,
323"
DISCUSSIONS,0.6704331450094162,"it takes about 4000 seconds with high variance for OR-tools. The times for other collections are listed
324"
DISCUSSIONS,0.672316384180791,"in more detail in the appendix.
325"
DISCUSSIONS,0.6741996233521658,Table 4: Average makespan gaps for FJSP open benchmark.
DISCUSSIONS,0.6760828625235404,"Method
MK
LA(rdata)
LA(edata)
LA(vdata)
RS
0.232
0.099
0.146
0.031
RS+100
0.154
0.047
0.079
0.007
DRL-G
0.254
0.111
0.150
0.040
DRL+100
0.190
0.058
0.082
0.014"
DISCUSSIONS,0.6779661016949152,"Third, as proposed by Song et al. (2023), construction heuristics can further improve the gap by
326"
DISCUSSIONS,0.67984934086629,"constructing multiple solutions based on the softmax policy, in addition to the greedy policy. They
327"
DISCUSSIONS,0.6817325800376648,"had a version constructing 100 solutions for FJSP, called DRL+100 in this paper. In this paper, we
328"
DISCUSSIONS,0.6836158192090396,"also implement a RS version for FJSP based on the softmax policy, as described in Subsection 3.3,
329"
DISCUSSIONS,0.6854990583804144,"and then use the version, called RS+100, to constructing 100 solutions. In Table 4, the experimental
330"
DISCUSSIONS,0.687382297551789,"results show that RS+100 performs the best, much better than RS, DRL-G and DRL+100. An
331"
DISCUSSIONS,0.6892655367231638,"important property for such an improvement is that constructing multiple solutions can be done in
332"
DISCUSSIONS,0.6911487758945386,"parallel. That is, for construction heuristics, the solution quality can be improved by adding more
333"
DISCUSSIONS,0.6930320150659134,"computation powers.
334"
REFERENCES,0.6949152542372882,"References
335"
REFERENCES,0.696798493408663,"Majid Abdolrazzagh-Nezhad and Salwani Abdullah. 2017. Job Shop Scheduling: Classification, Con-
336"
REFERENCES,0.6986817325800376,"straints and Objective Functions. International Journal of Computer and Information Engineering
337"
REFERENCES,0.7005649717514124,"11, 4 (2017), 429–434.
338"
REFERENCES,0.7024482109227872,"Joseph William Adams, Egon Balas, and Daniel J. Zawack. 1988. The Shifting Bottleneck Procedure
339"
REFERENCES,0.704331450094162,"for Job Shop Scheduling. Management science 34, 3 (1988), 391–401.
340"
REFERENCES,0.7062146892655368,"David L. Applegate and William J. Cook. 1991. A Computational Study of the Job-Shop Scheduling
341"
REFERENCES,0.7080979284369114,"Problem. INFORMS Journal on Computing 3, 2 (1991), 149–156. https://doi.org/10.1287/
342"
REFERENCES,0.7099811676082862,"ijoc.3.2.149
343"
REFERENCES,0.711864406779661,"Peter W. Battaglia, Jessica B. Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinícius Flores
344"
REFERENCES,0.7137476459510358,"Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner,
345"
REFERENCES,0.7156308851224106,"Çaglar Gülçehre, H. Francis Song, Andrew J. Ballard, Justin Gilmer, George E. Dahl, Ashish
346"
REFERENCES,0.7175141242937854,"Vaswani, Kelsey R. Allen, Charles Nash, Victoria Langston, Chris Dyer, Nicolas Heess, Daan
347"
REFERENCES,0.71939736346516,"Wierstra, Pushmeet Kohli, Matthew M. Botvinick, Oriol Vinyals, Yujia Li, and Razvan Pascanu.
348"
REFERENCES,0.7212806026365348,"2018. Relational inductive biases, deep learning, and graph networks. CoRR abs/1806.01261
349"
REFERENCES,0.7231638418079096,"(2018). arXiv:1806.01261 http://arxiv.org/abs/1806.01261
350"
REFERENCES,0.7250470809792844,"Dennis Behnke and Martin Josef Geiger. 2012. Test instances for the flexible job shop scheduling
351"
REFERENCES,0.7269303201506592,"problem with work centers. Arbeitspapier/Research Paper/Helmut-Schmidt-Universität, Lehrstuhl
352"
REFERENCES,0.7288135593220338,"für Betriebswirtschaftslehre, insbes. Logistik-Management (2012).
353"
REFERENCES,0.7306967984934086,"Paolo Brandimarte. 1993. Routing and scheduling in a flexible job shop by tabu search. Ann. Oper.
354"
REFERENCES,0.7325800376647834,"Res. 41, 3 (1993), 157–183. https://doi.org/10.1007/BF02023073
355"
REFERENCES,0.7344632768361582,"IBM ILOG Cplex. 2009. V12. 1: User’s Manual for CPLEX. International Business Machines
356"
REFERENCES,0.736346516007533,"Corporation 46, 53 (2009), 157.
357"
REFERENCES,0.7382297551789078,"Mauro Dell’Amico and Marco Trubian. 1993. Applying tabu search to the job-shop scheduling
358"
REFERENCES,0.7401129943502824,"problem. Annals of Operations Research 41, 3 (1993), 231–252. https://doi.org/10.1007/
359"
REFERENCES,0.7419962335216572,"BF02023076
360"
REFERENCES,0.743879472693032,"Alhussein Fawzi, Matej Balog, Aja Huang, Thomas Hubert, Bernardino Romera-Paredes, Moham-
361"
REFERENCES,0.7457627118644068,"madamin Barekatain, Alexander Novikov, Francisco J R Ruiz, Julian Schrittwieser, Grzegorz
362"
REFERENCES,0.7476459510357816,"Swirszcz, et al. 2022. Discovering faster matrix multiplication algorithms with reinforcement
363"
REFERENCES,0.7495291902071564,"learning. Nature 610, 7930 (2022), 47–53.
364"
REFERENCES,0.751412429378531,"Matthias Fey and Jan Eric Lenssen. 2019. Fast Graph Representation Learning with PyTorch
365"
REFERENCES,0.7532956685499058,"Geometric, In ICLR Workshop on Representation Learning on Graphs and Manifolds. CoRR
366"
REFERENCES,0.7551789077212806,"abs/1903.02428. arXiv:1903.02428 http://arxiv.org/abs/1903.02428
367"
REFERENCES,0.7570621468926554,"M. R. Garey and David S. Johnson. 1979. Computers and Intractability: A Guide to the Theory of
368"
REFERENCES,0.7589453860640302,"NP-Completeness. W. H. Freeman, USA.
369"
REFERENCES,0.7608286252354048,"Amit Kumar Gupta and Appa Iyer Sivakumar. 2006. Job shop scheduling techniques in semiconductor
370"
REFERENCES,0.7627118644067796,"manufacturing. The International Journal of Advanced Manufacturing Technology 27, 11 (2006),
371"
REFERENCES,0.7645951035781544,"1163–1169.
372"
REFERENCES,0.7664783427495292,"Reinhard Haupt. 1989. A survey of priority rule-based scheduling. Operations-Research-Spektrum
373"
REFERENCES,0.768361581920904,"11, 1 (1989), 3–16.
374"
REFERENCES,0.7702448210922788,"Johann Hurink, Bernd Jurisch, and Monika Thole. 1994. Tabu search for the job-shop scheduling
375"
REFERENCES,0.7721280602636534,"problem with multi-purpose machines. Operations-Research-Spektrum 15 (1994), 205–215.
376"
REFERENCES,0.7740112994350282,"Sergey Ioffe and Christian Szegedy. 2015. Batch Normalization: Accelerating Deep Network Training
377"
REFERENCES,0.775894538606403,"by Reducing Internal Covariate Shift. In International Conference on Machine Learning (ICML)
378"
REFERENCES,0.7777777777777778,"(JMLR Workshop and Conference Proceedings, Vol. 37), Francis R. Bach and David M. Blei (Eds.).
379"
REFERENCES,0.7796610169491526,"JMLR.org, 448–456. http://proceedings.mlr.press/v37/ioffe15.html
380"
REFERENCES,0.7815442561205274,"Klaus Jansen, Monaldo Mastrolilli, and Roberto Solis-Oba. 2000. Approximation Algorithms for
381"
REFERENCES,0.783427495291902,"Flexible Job Shop Problems. In Latin American Symposium on Theoretical Informatics (Lecture
382"
REFERENCES,0.7853107344632768,"Notes in Computer Science, Vol. 1776), Gaston H. Gonnet, Daniel Panario, and Alfredo Viola
383"
REFERENCES,0.7871939736346516,"(Eds.). Springer, 68–77. https://doi.org/10.1007/10719839_7
384"
REFERENCES,0.7890772128060264,"BJ Lageweg, JK Lenstra, and AHG Rinnooy Kan. 1977. Job-shop scheduling by implicit enumeration.
385"
REFERENCES,0.7909604519774012,"Management Science 24, 4 (1977), 441–450.
386"
REFERENCES,0.7928436911487758,"Stephen Lawrence. 1984. Resouce constrained project scheduling: An experimental investigation
387"
REFERENCES,0.7947269303201506,"of heuristic scheduling techniques (Supplement). Graduate School of Industrial Administration,
388"
REFERENCES,0.7966101694915254,"Carnegie-Mellon University (1984).
389"
REFERENCES,0.7984934086629002,"Zhigang Lian, Bin Jiao, and Xingsheng Gu. 2006. A similar particle swarm optimization algorithm
390"
REFERENCES,0.800376647834275,"for job-shop scheduling to minimize makespan. Appl. Math. Comput. 183, 2 (2006), 1008–1017.
391"
REFERENCES,0.8022598870056498,"https://doi.org/10.1016/j.amc.2006.05.168
392"
REFERENCES,0.8041431261770244,"Chun-Cheng Lin, Der-Jiunn Deng, Yen-Ling Chih, and Hsin-Ting Chiu. 2019. Smart Manufacturing
393"
REFERENCES,0.8060263653483992,"Scheduling With Edge Computing Using Multiclass Deep Q Network. IEEE Trans. Ind. Informatics
394"
REFERENCES,0.807909604519774,"15, 7 (2019), 4276–4284. https://doi.org/10.1109/TII.2019.2908210
395"
REFERENCES,0.8097928436911488,"Min Liu, Zhi-jiang Sun, Junwei Yan, and Jing-song Kang. 2011. An adaptive annealing genetic
396"
REFERENCES,0.8116760828625236,"algorithm for the job-shop planning and scheduling problem. Expert Systems with Applications 38,
397"
REFERENCES,0.8135593220338984,"8 (2011), 9248–9255. https://doi.org/10.1016/j.eswa.2011.01.136
398"
REFERENCES,0.815442561205273,"Shu Luo. 2020. Dynamic scheduling for flexible job shop with new job insertions by deep reinforce-
399"
REFERENCES,0.8173258003766478,"ment learning. Applied Soft Computing 91 (2020), 106208.
https://doi.org/10.1016/j.
400"
REFERENCES,0.8192090395480226,"asoc.2020.106208
401"
REFERENCES,0.8210922787193974,"Mingqi Lv, Zhaoxiong Hong, Ling Chen, Tieming Chen, Tiantian Zhu, and Shouling Ji. 2021.
402"
REFERENCES,0.8229755178907722,"Temporal Multi-Graph Convolutional Network for Traffic Flow Prediction. IEEE Transactions
403"
REFERENCES,0.8248587570621468,"on Intelligent Transportation Systems 22, 6 (2021), 3337–3348. https://doi.org/10.1109/
404"
REFERENCES,0.8267419962335216,"TITS.2020.2983763
405"
REFERENCES,0.8286252354048964,"Azalia Mirhoseini, Anna Goldie, Mustafa Yazgan, Joe Wenjie Jiang, Ebrahim M. Songhori, Shen
406"
REFERENCES,0.8305084745762712,"Wang, Young-Joon Lee, Eric Johnson, Omkar Pathak, Azade Nazi, Jiwoo Pak, Andy Tong, Kavya
407"
REFERENCES,0.832391713747646,"Srinivasa, Will Hang, Emre Tuncer, Quoc V. Le, James Laudon, Richard Ho, Roger Carpenter, and
408"
REFERENCES,0.8342749529190208,"Jeff Dean. 2021. A graph placement methodology for fast chip design. Nature 594, 7862 (2021),
409"
REFERENCES,0.8361581920903954,"207–212.
410"
REFERENCES,0.8380414312617702,"Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A. Rusu, Joel Veness, Marc G. Belle-
411"
REFERENCES,0.839924670433145,"mare, Alex Graves, Martin A. Riedmiller, Andreas Fidjeland, Georg Ostrovski, Stig Petersen,
412"
REFERENCES,0.8418079096045198,"Charles Beattie, Amir Sadik, Ioannis Antonoglou, Helen King, Dharshan Kumaran, Daan Wierstra,
413"
REFERENCES,0.8436911487758946,"Shane Legg, and Demis Hassabis. 2015. Human-level control through deep reinforcement learning.
414"
REFERENCES,0.8455743879472694,"Nature 518, 7540 (2015), 529–533. https://doi.org/10.1038/nature14236
415"
REFERENCES,0.847457627118644,"J.F. Muth and G.L. Thompson. 1963. Industrial Scheduling. Prentice-Hall.
416"
REFERENCES,0.8493408662900188,"In-Beom Park, Jaeseok Huh, Joongkyun Kim, and Jonghun Park. 2020. A Reinforcement Learning
417"
REFERENCES,0.8512241054613936,"Approach to Robust Scheduling of Semiconductor Manufacturing Facilities. IEEE Transactions on
418"
REFERENCES,0.8531073446327684,"Automation Science and Engineering 17, 3 (2020), 1420–1431. https://doi.org/10.1109/
419"
REFERENCES,0.8549905838041432,"TASE.2019.2956762
420"
REFERENCES,0.8568738229755178,"Junyoung Park, Sanjar Bakhtiyar, and Jinkyoo Park. 2021a. ScheduleNet: Learn to solve multi-agent
421"
REFERENCES,0.8587570621468926,"scheduling problems with reinforcement learning. CoRR abs/2106.03051 (2021). arXiv:2106.03051
422"
REFERENCES,0.8606403013182674,"https://arxiv.org/abs/2106.03051
423"
REFERENCES,0.8625235404896422,"Junyoung Park, Jaehyeong Chun, Sang Hun Kim, Youngkook Kim, and Jinkyoo Park. 2021b.
424"
REFERENCES,0.864406779661017,"Learning to schedule job-shop problems: representation and policy learning using graph neural
425"
REFERENCES,0.8662900188323918,"network and reinforcement learning. International Journal of Production Research 59, 11 (2021),
426"
REFERENCES,0.8681732580037664,"3360–3377. https://doi.org/10.1080/00207543.2020.1870013
427"
REFERENCES,0.8700564971751412,"Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
428"
REFERENCES,0.871939736346516,"Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Köpf, Ed-
429"
REFERENCES,0.8738229755178908,"ward Z. Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit
430"
REFERENCES,0.8757062146892656,"Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. 2019. PyTorch: An Imperative Style, High-
431"
REFERENCES,0.8775894538606404,"Performance Deep Learning Library. In Neural Information Processing Systems (NeurIPS),
432"
REFERENCES,0.879472693032015,"Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d’Alché-Buc, Emily B. Fox,
433"
REFERENCES,0.8813559322033898,"and Roman Garnett (Eds.). 8024–8035. https://proceedings.neurips.cc/paper/2019/
434"
REFERENCES,0.8832391713747646,"hash/bdbca288fee7f92f2bfa9f7012727740-Abstract.html
435"
REFERENCES,0.8851224105461394,"Laurent Perron and Vincent Furnon. 2019. OR-Tools. Google. https://developers.google.
436"
REFERENCES,0.8870056497175142,"com/optimization/
437"
REFERENCES,0.8888888888888888,"Ferdinando Pezzella, Gianluca Morganti, and Giampiero Ciaschetti. 2008. A genetic algorithm for
438"
REFERENCES,0.8907721280602636,"the Flexible Job-shop Scheduling Problem. Computers and Operations Research 35, 10 (2008),
439"
REFERENCES,0.8926553672316384,"3202–3212. https://doi.org/10.1016/j.cor.2007.02.014
440"
REFERENCES,0.8945386064030132,"Qing-dao-er-ji Ren and Yuping Wang. 2012. A new hybrid genetic algorithm for job shop scheduling
441"
REFERENCES,0.896421845574388,"problem. Computers and Operations Research 39, 10 (2012), 2291–2299. https://doi.org/
442"
REFERENCES,0.8983050847457628,"10.1016/j.cor.2011.12.005
443"
REFERENCES,0.9001883239171374,"Mohammad Saidi-Mehrabad and Parviz Fattahi. 2007. Flexible job shop scheduling with tabu search
444"
REFERENCES,0.9020715630885122,"algorithms. The International Journal of Advanced Manufacturing Technology 32, 5 (2007),
445"
REFERENCES,0.903954802259887,"563–570.
446"
REFERENCES,0.9058380414312618,"David Silver, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den Driess-
447"
REFERENCES,0.9077212806026366,"che, Julian Schrittwieser, Ioannis Antonoglou, Vedavyas Panneershelvam, Marc Lanctot, Sander
448"
REFERENCES,0.9096045197740112,"Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy P. Lillicrap,
449"
REFERENCES,0.911487758945386,"Madeleine Leach, Koray Kavukcuoglu, Thore Graepel, and Demis Hassabis. 2016. Mastering
450"
REFERENCES,0.9133709981167608,"the game of Go with deep neural networks and tree search. Nature 529, 7587 (2016), 484–489.
451"
REFERENCES,0.9152542372881356,"https://doi.org/10.1038/nature16961
452"
REFERENCES,0.9171374764595104,"Wen Song, Xinyang Chen, Qiqiang Li, and Zhiguang Cao. 2023. Flexible Job-Shop Scheduling via
453"
REFERENCES,0.9190207156308852,"Graph Neural Network and Deep Reinforcement Learning. IEEE Trans. Ind. Informatics 19, 2
454"
REFERENCES,0.9209039548022598,"(2023), 1600–1610. https://doi.org/10.1109/TII.2022.3189725
455"
REFERENCES,0.9227871939736346,"Robert H. Storer, S. David Wu, and Renzo Vaccari. 1992. New search spaces for sequencing problems
456"
REFERENCES,0.9246704331450094,"with application to job shop scheduling. Management science 38, 10 (1992), 1495–1509.
457"
REFERENCES,0.9265536723163842,"Richard S. Sutton and Andrew G. Barto. 2018. Reinforcement Learning: An Introduction (second
458"
REFERENCES,0.928436911487759,"ed.). The MIT Press. http://incompleteideas.net/book/the-book-2nd.html
459"
REFERENCES,0.9303201506591338,"Éric D. Taillard. 1993. Benchmarks for basic scheduling problems. european journal of operational
460"
REFERENCES,0.9322033898305084,"research 64, 2 (1993), 278–285.
461"
REFERENCES,0.9340866290018832,"Oriol Vinyals, Igor Babuschkin, Wojciech M. Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung
462"
REFERENCES,0.935969868173258,"Chung, David H. Choi, Richard Powell, Timo Ewalds, Petko Georgiev, Junhyuk Oh, Dan Horgan,
463"
REFERENCES,0.9378531073446328,"Manuel Kroiss, Ivo Danihelka, Aja Huang, Laurent Sifre, Trevor Cai, John P. Agapiou, Max
464"
REFERENCES,0.9397363465160076,"Jaderberg, Alexander Sasha Vezhnevets, Rémi Leblond, Tobias Pohlen, Valentin Dalibard, David
465"
REFERENCES,0.9416195856873822,"Budden, Yury Sulsky, James Molloy, Tom Le Paine, Çaglar Gülçehre, Ziyu Wang, Tobias Pfaff,
466"
REFERENCES,0.943502824858757,"Yuhuai Wu, Roman Ring, Dani Yogatama, Dario Wünsch, Katrina McKinney, Oliver Smith, Tom
467"
REFERENCES,0.9453860640301318,"Schaul, Timothy P. Lillicrap, Koray Kavukcuoglu, Demis Hassabis, Chris Apps, and David Silver.
468"
REFERENCES,0.9472693032015066,"2019. Grandmaster level in StarCraft II using multi-agent reinforcement learning. Nature 575,
469"
REFERENCES,0.9491525423728814,"7782 (2019), 350–354. https://doi.org/10.1038/s41586-019-1724-z
470"
REFERENCES,0.9510357815442562,"Bernd Waschneck, Thomas Altenmüller, Thomas Bauernhansl, and Andreas Kyek. 2016. Production
471"
REFERENCES,0.9529190207156308,"Scheduling in Complex Job Shops from an Industry 4.0 Perspective: A Review and Challenges
472"
REFERENCES,0.9548022598870056,"in the Semiconductor Industry. In Proceedings of the 1st International Workshop on Science,
473"
REFERENCES,0.9566854990583804,"Application and Methods in Industry 4.0 (i-KNOW) (CEUR Workshop Proceedings, Vol. 1793),
474"
REFERENCES,0.9585687382297552,"Roman Kern, Gerald Reiner, and Olivia Bluder (Eds.). CEUR-WS.org. http://ceur-ws.org/
475"
REFERENCES,0.96045197740113,"Vol-1793/paper3.pdf
476"
REFERENCES,0.9623352165725048,"Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2019. How Powerful are Graph Neural
477"
REFERENCES,0.9642184557438794,"Networks? (2019). https://openreview.net/forum?id=ryGs6iA5Km
478"
REFERENCES,0.9661016949152542,"Takeshi Yamada and Ryohei Nakano. 1992. A Genetic Algorithm Applicable to Large-Scale Job-
479"
REFERENCES,0.967984934086629,"Shop Problems. In Parallel Problem Solving from Nature 2, (PPSN-II), Reinhard Männer and
480"
REFERENCES,0.9698681732580038,"Bernard Manderick (Eds.). Elsevier, 283–292.
481"
REFERENCES,0.9717514124293786,"Cong Zhang, Wen Song, Zhiguang Cao, Jie Zhang, Puay Siew Tan, and Chi Xu. 2020. Learning
482"
REFERENCES,0.9736346516007532,"to Dispatch for Job Shop Scheduling via Deep Reinforcement Learning. In Neural Information
483"
REFERENCES,0.975517890772128,"Processing Systems (NeurIPS), Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-
484"
REFERENCES,0.9774011299435028,"Florina Balcan, and Hsuan-Tien Lin (Eds.).
https://proceedings.neurips.cc/paper/
485"
REFERENCES,0.9792843691148776,"2020/hash/11958dfee29b6709f48a9ba0387a2431-Abstract.html
486"
REFERENCES,0.9811676082862524,"Cong Zhang, Wen Song, Zhiguang Cao, Jie Zhang, Puay Siew Tan, and Chi Xu. 2022. Learning to
487"
REFERENCES,0.9830508474576272,"Search for Job Shop Scheduling via Deep Reinforcement Learning. CoRR abs/2211.10936 (2022).
488"
REFERENCES,0.9849340866290018,"https://doi.org/10.48550/arXiv.2211.10936 arXiv:2211.10936
489"
REFERENCES,0.9868173258003766,"Cong Zhang, Yaoxin Wu, Yining Ma, Wen Song, Zhang Le, Zhiguang Cao, and Jie Zhang. 2023. A
490"
REFERENCES,0.9887005649717514,"review on learning to solve combinatorial optimisation problems in manufacturing. IET Collabora-
491"
REFERENCES,0.9905838041431262,"tive Intelligent Manufacturing 5, 1 (2023), e12072. https://doi.org/10.1049/cim2.12072
492"
REFERENCES,0.992467043314501,"arXiv:https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/cim2.12072
493"
REFERENCES,0.9943502824858758,"Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng Wang,
494"
REFERENCES,0.9962335216572504,"Changcheng Li, and Maosong Sun. 2020. Graph neural networks: A review of methods and
495"
REFERENCES,0.9981167608286252,"applications. AI Open 1 (2020), 57–81. https://doi.org/10.1016/j.aiopen.2021.01.001
496"
