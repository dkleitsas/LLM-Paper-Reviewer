Section,Section Appearance Order,Paragraph
THE UNIVERSITY OF TOKYO,0.0,"1The University of Tokyo
2The Chinese University of Hong Kong
3The University of British Columbia
4RIKEN
{lu@edu.,sugi@}k.u-tokyo.ac.jp,
{zwang21@cse.,qidou@}cuhk.edu.hk
xiaoxiao.li@ece.ubc.ca,
gang.niu.ml@gmail.com"
ABSTRACT,0.002638522427440633,ABSTRACT
ABSTRACT,0.005277044854881266,"Supervised federated learning (FL) enables multiple clients to share the trained
model without sharing their labeled data. However, potential clients might even
be reluctant to label their own data, which could limit the applicability of FL in
practice. In this paper, we show the possibility of unsupervised FL whose model is
still a classifier for predicting class labels, if the class-prior probabilities are shifted
while the class-conditional distributions are shared among the unlabeled data
owned by the clients. We propose federation of unsupervised learning (FedUL),
where the unlabeled data are transformed into surrogate labeled data for each of
the clients, a modified model is trained by supervised FL, and the wanted model is
recovered from the modified model. FedUL is a very general solution to unsuper-
vised FL: it is compatible with many supervised FL methods, and the recovery of
the wanted model can be theoretically guaranteed as if the data have been labeled.
Experiments on benchmark and real-world datasets demonstrate the effectiveness
of FedUL. Code is available at https://github.com/lunanbit/FedUL."
INTRODUCTION,0.0079155672823219,"1
INTRODUCTION"
INTRODUCTION,0.010554089709762533,"Federated learning (FL) has received significant attention from both academic and industrial perspec-
tives in that it can bring together separate data sources and allow multiple clients to train a central
model in a collaborative but private manner (McMahan et al., 2017; Kairouz et al., 2019; Yang et al.,
2019). So far, the majority of FL researches focused on the supervised setting, requiring collected
data at each client to be fully labeled. In practice, this may hinder the applicability of FL since
manually labeling large-scale training data can be extremely costly, and sometimes may not even be
possible for privacy concerns in for example medical diagnosis (Ng et al., 2021)."
INTRODUCTION,0.013192612137203167,"To promote the applicability of FL, we are interested in a challenging unsupervised FL setting where
only unlabeled (U) data are available at the clients under the condition described blow. Our goal is
still to train a classification model that can predict accurate class labels. It is often observed that the
clients collect their own data with different temporal and/or spatial patterns, e.g., a hospital (data
center) may store patient data every month or a particular user (mobile device) may take photos at
different places. Therefore, we consider a realistic setting that the U data at a client come in the form
of separate data sets, and the data distribution of each U set and the number of U sets available at
each client may vary. Without any labels, it is unclear whether FL can be performed effectively."
INTRODUCTION,0.0158311345646438,"In this paper, we show the possibility: the aforementioned unsupervised FL problem can be solved if
the class-prior probabilities are shifted while the class-conditional distributions are shared between the
available U sets at the clients, and these class priors are known to the clients. Such a learning scenario
is conceivable in many real-world problems. For example, the hospital may not release the diagnostic
labels of patients due to privacy concerns, but the morbidity rates of diseases (corresponding to the
class priors) may change over time and can be accessible from public medical reports (Croft et al.,
2018); moreover, in many cases it is possible to estimate the class priors much more cheaply than to
collect ground-truth labels (Quadrianto et al., 2009a; Sugiyama et al., 2022)."
INTRODUCTION,0.018469656992084433,‚àóCorrespondence to: Gang Niu <gang.niu.ml@gmail.com>.
INTRODUCTION,0.021108179419525065,"Published as a conference paper at ICLR 2022 ùë∏ùüè
ùíáùüè"
INTRODUCTION,0.023746701846965697,Surrogate label ùíáùüè 1 ùëÄ ‚Ä¶
INTRODUCTION,0.026385224274406333,Server ‚Ä¶
INTRODUCTION,0.029023746701846966,"Client ùê∂
Client 2
Client 1"
INTRODUCTION,0.0316622691292876,True label ùíáùüê
INTRODUCTION,0.03430079155672823,True label ùíáùë™
INTRODUCTION,0.036939313984168866,"True label
‚Ä¶ ùë∏ùüê
ùíáùüê"
INTRODUCTION,0.0395778364116095,"Surrogate label 1 ùëÄ ‚Ä¶ ùë∏ùë™
ùíáùë™"
INTRODUCTION,0.04221635883905013,Surrogate label 1 ùëÄ ‚Ä¶
INTRODUCTION,0.044854881266490766,"Client ùê∂
Client 2
Client 1"
INTRODUCTION,0.047493403693931395,"Server update
Local update
ùíá
Server
ùíá"
INTRODUCTION,0.05013192612137203,"In the left panel, each client fc (c ‚àà[C]) has access to fully labeled data, and a global model f can be trained
using a supervised FL scheme, e.g., Federated Averaging (FedAvg) (McMahan et al., 2017). In the right panel,
each client has access to only unlabeled (U) data coming in the form of separate sets, where supervised FL
methods cannot be directly applied. We propose FedUL that treats the indexes of the U sets as surrogate labels,
transforms the local U datasets to (surrogate) labeled datasets, and formulates a surrogate supervised FL task.
Then we modify each client model to be compatible with the surrogate task by adding a fixed transition layer Qc
to the original model output fc. FedUL can incorporate existing supervised FL methods as its base method for
surrogate training, and the wanted model f can be retrieved from the surrogate model."
INTRODUCTION,0.052770448548812667,Figure 1: Illustration of standard supervised FL scheme vs. proposed FedUL scheme.
INTRODUCTION,0.055408970976253295,"Based on this finding, we propose the federation of unsupervised learning (FedUL) (see Figure 1).
In FedUL, the original clients with U data are transformed to surrogate clients with (surrogate)
labeled data and then supervised FL can be applied, which we call the surrogate task. Here, the
difficulty is how to infer the wanted model for the original classification task from the model learned
by the surrogate task. We solve this problem by bridging the original and surrogate class-posterior
probabilities with certain injective transition functions. This can be implemented by adding a
specifically designed transition layer to the output of each client model, so that the learned model is
guaranteed to be a good approximation of the original class-posterior probability."
INTRODUCTION,0.05804749340369393,"FedUL has many key advantages. On the one hand, FedUL is a very general and flexible solution: it
works as a wrapper that transforms the original clients to the surrogate ones and therefore is compatible
with many supervised FL methods, e.g., FedAvg. On the other hand, FedUL is computationally
efficient and easy-to-implement: since the added transformation layer is fixed and determined by
the class priors, FedUL adds no more burden on hyper-parameter tuning and/or optimization. Our
contributions are summarized as follows:"
INTRODUCTION,0.06068601583113457,"‚Ä¢ Methodologically, we propose a novel FedUL method that solves a certain unsupervised FL
problem, expanding the applicability of FL.
‚Ä¢ Theoretically, we prove the optimal global model learned by FedUL from only U data converges to
the optimal global model learned by supervised FL from labeled data under mild conditions.
‚Ä¢ Empirically, we demonstrate the effectiveness of FedUL on benchmark and real-world datasets."
INTRODUCTION,0.0633245382585752,"Related Work: FL has been extensively studied in the supervised setting. One of the most popular
supervised FL paradigms is FedAvg (McMahan et al., 2017) which aggregates the local updates at
the server and transmits the averaged model back to local clients. In contrast, FL in the unsupervised
setting is less explored. Recent studies have shown the possibility of federated clustering with U
data (Ghosh et al., 2020; Dennis et al., 2021). However, these clustering based methods rely on
geometric or information-theoretic assumptions to build their learning objectives (Chapelle et al.,
2006), and are suboptimal for classification goals. Our work is intrinsically different from them in
the sense that we show the possibility of federated classification with U data based on empirical risk
minimization (ERM) (Vapnik, 1998), and therefore the optimal model recovery can be guaranteed."
INTRODUCTION,0.06596306068601583,"Learning from multiple U sets has also been studied in classical centralized learning. Mainstream
methods include learning with label proportions (LLP) (Quadrianto et al., 2009b) and Um classi-
fication (Lu et al., 2021). The former learns a multiclass classifier from multiple U sets based on"
INTRODUCTION,0.06860158311345646,Published as a conference paper at ICLR 2022
INTRODUCTION,0.0712401055408971,"empirical proportion risk minimization (EPRM) (Yu et al., 2014), while the latter learns a binary
classifier from multiple U sets based on ERM. EPRM is inferior to ERM since its learning is not
consistent. Yet, it is still unexplored how to learn a multiclass classification model from multiple
U sets based on ERM. To the best of our knowledge, this work is the first attempt to tackle this
problem in the FL setup, which is built upon the binary Um classification in centralized learning. A
full discussion of related work can be found at Appendix B."
STANDARD FEDERATED LEARNING,0.07387862796833773,"2
STANDARD FEDERATED LEARNING"
STANDARD FEDERATED LEARNING,0.07651715039577836,"We begin by reviewing the standard FL. Let us consider a K-class classification problem with
the feature space X ‚äÇRd and the label space Y = [K], where d is the input dimension and
[K] := {1, . . . , K}. Let x ‚ààX and y ‚ààY be the input and output random variables following
an underlying joint distribution with density p(x, y), which can be identified via the class priors
{œÄk = p(y = k)}K
k=1 and the class-conditional densities {p(x | y = k)}K
k=1. Let f : X ‚ÜíRK be a
classification model that assigns a score to each of the K classes for a given input x and then outputs
the predicted label by ypred = argmaxk‚àà[K](f(x))k, where (f(x))k is the k-th element of f(x)."
STANDARD FEDERATED LEARNING,0.079155672823219,"In the standard FL setup with C clients, for c ‚àà[C], the c-th client has access to a labeled training set
Dc = {(xc
i, yc
i )}nc
i=1‚àºpc(x, y) of sample size nc and learns its local model fc by minimizing the risk
Rc(fc) := E(x,y)‚àºpc(x,y)[‚Ñì(fc(x), y)].
(1)"
STANDARD FEDERATED LEARNING,0.08179419525065963,"Here, E denotes the expectation, ‚Ñì: RK √ó Y ‚ÜíR+ is a proper loss function, e.g., the
softmax cross-entropy loss ‚Ñìce(fc(x), y)
=
‚àíPK
k=1 1(y
=
k) log

exp((fc(x))k)
PK
i=1 exp((fc(x))i) 
="
STANDARD FEDERATED LEARNING,0.08443271767810026,"log
PK
i=1 exp((fc(x))i)

‚àí(fc(x))y, where 1(¬∑) is the indicator function. In practice, ERM
is commonly used to compute an approximation of Rc(fc) based on the client‚Äôs local data Dc by
bRc(fc; Dc) =
1
nc
Pnc
i=1 ‚Ñì(fc(xc
i), yc
i )."
STANDARD FEDERATED LEARNING,0.0870712401055409,"The goal of standard FL (McMahan et al., 2017) is that the C clients collaboratively train a global
classification model f that generalizes well with respect to p(x, y), without sharing their local data
Dc. The problem can be formalized as minimizing the aggregated risk:"
STANDARD FEDERATED LEARNING,0.08970976253298153,R(f) = 1 C XC
STANDARD FEDERATED LEARNING,0.09234828496042216,"c=1 Rc(f).
(2)"
STANDARD FEDERATED LEARNING,0.09498680738786279,"Typically, we employ a server to coordinate the iterative distributed training as follows:"
STANDARD FEDERATED LEARNING,0.09762532981530343,"‚Ä¢ in each global round of training, the server broadcasts its current model f to all the clients {fc}C
c=1;
‚Ä¢ each client c copies the current server model fc = f, performs L local step updates"
STANDARD FEDERATED LEARNING,0.10026385224274406,"fc ‚Üêfc ‚àíŒ±l ¬∑ ‚àábRc(fc; Dc),
(3)
where Œ±l is the local step-size, and sends fc ‚àíf back to the server;
‚Ä¢ the server aggregates the updates {fc ‚àíf}C
c=1 to form a new server model using FedAvg:"
STANDARD FEDERATED LEARNING,0.10290237467018469,"f ‚Üêf ‚àíŒ±g ¬∑
XC"
STANDARD FEDERATED LEARNING,0.10554089709762533,"c=1(fc ‚àíf),
(4)"
STANDARD FEDERATED LEARNING,0.10817941952506596,where Œ±g is the global step-size.
STANDARD FEDERATED LEARNING,0.11081794195250659,"3
FEDERATED LEARNING: NO LABEL NO CRY"
STANDARD FEDERATED LEARNING,0.11345646437994723,"Next, we formulate the problem setting of FL with only U training sets, propose our method called
federation of unsupervised learning (FedUL), and provide the theoretical analysis of FedUL. All
proofs are given in Appendix C."
PROBLEM FORMULATION,0.11609498680738786,"3.1
PROBLEM FORMULATION"
PROBLEM FORMULATION,0.11873350923482849,"In this paper, we consider a challenging setting: instead of fully labeled training data, each client
c ‚àà[C] observes Mc (Mc ‚â•K, ‚àÄc)1 sets of unlabeled samples, Uc = {Um
c }Mc
m=1, where Um
c
="
PROBLEM FORMULATION,0.12137203166226913,"1Note that we do not require each client has the same number of U sets. We only assume the condition
Mc ‚â•K, ‚àÄc to ensure the full column rank matrix Œ†c, which is essential for FL with U training sets."
PROBLEM FORMULATION,0.12401055408970976,Published as a conference paper at ICLR 2022
PROBLEM FORMULATION,0.1266490765171504,"{xc,m
i
}nc,m
i=1 denotes the collection of the m-th U set for client c with sample size nc,m. Each U set
can be seen as a set of data points drawn from a mixture of the original class-conditional densities:"
PROBLEM FORMULATION,0.12928759894459102,"Um
c ‚àºpm
c (x) =
XK"
PROBLEM FORMULATION,0.13192612137203166,"k=1 œÄm,k
c
p(x | y = k),
(5)"
PROBLEM FORMULATION,0.1345646437994723,"where œÄm,k
c
= pm
c (y = k) denotes the k-th class prior of the m-th U set at client c. These class priors
form a full column rank matrix Œ†c ‚ààRMc√óK with the constraint that each row sums up to 1. Note
that we do not require any labels to be known, only assume the class priors within each of the involved
datasets are available, i.e., the training class priors œÄm,k
c
and the test class prior œÄk = p(y = k)."
PROBLEM FORMULATION,0.13720316622691292,"Our goal is the same as standard FL: the C clients are interested in collaboratively training a global
classification model f that generalizes well with respect to p(x, y), but using only U training sets (5)
on each local client."
PROPOSED METHOD,0.13984168865435356,"3.2
PROPOSED METHOD"
PROPOSED METHOD,0.1424802110817942,"As discussed, FedAvg is a representative approach for aggregating clients in the FL framework. It
also serves as the basis for many advanced federated aggregation techniques, e.g., Fedprox (Li et al.,
2020), FedNova (Wang et al., 2020), and SCAFFOLD (Karimireddy et al., 2020). However, these
methods cannot handle clients without labels. To tackle this problem, we consider the construction of
surrogate clients by transforming the local U datasets into labeled datasets and modifying the local
model such that it is compatible with the transformed data for training."
PROPOSED METHOD,0.14511873350923482,"Local Data Transformation
First, we transform the data for the clients. For each client c ‚àà[C],
let y be the index of given U sets, and pc(x, y) be an underlying joint distribution for the random
variables x ‚ààX and y ‚àà[M], where M = maxc‚àà[C] Mc.2 By treating y as a surrogate label, we
may transform the original U training sets Uc = {Um
c }Mc
m=1 to a labeled training set for client c,"
PROPOSED METHOD,0.14775725593667546,"Uc = {xi, yi}nc
i=1 ‚àºpc(x, y),
(6)"
PROPOSED METHOD,0.1503957783641161,"where nc = PMc
m=1 nc,m. Obviously, the surrogate class-conditional density pc(x | y = m)
corresponds to pm
c (x) in (5), for m ‚àà[Mc]. If ‚àÉMc < m ‚â§M, we pad pc(x | y = m) = 0. The
surrogate class prior œÄm
c = pc(y = m) can be estimated by nc,m/nc."
PROPOSED METHOD,0.15303430079155672,"Based on the data transformation, we then formulate a surrogate supervised FL task: the C clients
aim to collaboratively train a global classification model g : X ‚ÜíRM that predicts the surrogate
label y for the given input x, without sharing their local data Uc. This task can be easily solved by
standard supervised FL methods. More specifically, we minimize"
PROPOSED METHOD,0.15567282321899736,J(g) = 1 C XC
PROPOSED METHOD,0.158311345646438,"c=1 Jc(g) := E(x,y)‚àºpc(x,y)[‚Ñì(g(x), y)]
(7)"
PROPOSED METHOD,0.16094986807387862,"by employing a server g that iteratively broadcasts its model to all local clients {gc}C
c=1 and aggregates
local updates from all clients using e.g., FedAvg. The local and global update procedures exactly
follow (3) and (4) in standard FL."
PROPOSED METHOD,0.16358839050131926,"Now a natural question arises: can we infer our desired model f from the surrogate model g? To
answer it, we study the relationship between the original and surrogate class-posterior probabilities.
Theorem 1. For each client c ‚àà[C], let Œ∑c : X ‚Üí‚àÜM‚àí1 and Œ∑ : X ‚Üí‚àÜK‚àí1 be the surrogate
and original class-posterior probability functions, where (Œ∑c(x))m = pc(y = m | x) for m ‚àà[M],
(Œ∑(x))k = p(y = k | x) for k ‚àà[K], ‚àÜM‚àí1 and ‚àÜK‚àí1 are the M- and K-dimensional simplexes.
Let œÄc = [œÄ1
c, ¬∑ ¬∑ ¬∑ , œÄM
c ]‚ä§and œÄ = [œÄ1, ¬∑ ¬∑ ¬∑ , œÄK]‚ä§be vector forms of the surrogate and original
class priors, and Œ†c ‚ààRM√óK be the matrix form of œÄm,k
c
defined in (5). Then we have
Œ∑c(x) = Qc(Œ∑(x); œÄ, œÄc, Œ†c),
(8)
where the unnormalized version of vector-valued function Qc is given by
e
Qc(Œ∑(x); œÄ, œÄc, Œ†c) = DœÄc ¬∑ Œ†c ¬∑ D‚àí1
œÄ ¬∑ Œ∑(x).
Da denotes the diagonal matrix with diagonal terms being vector a and ¬∑ denotes matrix multiplica-
tion. Qc is normalized by the sum of all entries, i.e., (Qc)i =
( e
Qc)i
P"
PROPOSED METHOD,0.1662269129287599,"j( e
Qc)j ."
PROPOSED METHOD,0.16886543535620052,"2To make the problem well-defined, for client c with Mc < M, we set Um
c = ‚àÖ, ‚àÄMc < m ‚â§M."
PROPOSED METHOD,0.17150395778364116,Published as a conference paper at ICLR 2022
PROPOSED METHOD,0.1741424802110818,"Algorithm 1 Federation of unsupervised learning (FedUL)
Server Input: initial f, global step-size Œ±g, and global communication round R
Client c‚Äôs Input: local model fc, unlabeled training sets Uc = {Um
c }Mc
m=1, class priors Œ†c and œÄ,
local step-size Œ±l, and local updating iterations L"
PROPOSED METHOD,0.17678100263852242,"1: We start with initializing clients with Procedure A.
2: For r = 1 ‚ÜíR rounds, we run Procedure B and Procedure C iteratively .
3: procedure A. CLIENTINIT(c)
4:
transform Uc to a surrogate labeled dataset Uc according to (6)
5:
modify f to gc = Qc(f), where Qc is computed according to Theorem 1
6: end procedure
7: procedure B. CLIENTUPDATE(c)
8:
fc ‚Üêf
‚ñ∑Receive updated model from SERVEREXECUTE
9:
gc ‚ÜêQc(fc)
10:
for l = 1 ‚ÜíL do
11:
gc ‚Üêgc ‚àíŒ±l ¬∑ ‚àábJc(gc; Uc)
‚ñ∑SGD update based on objective (7)
12:
fc ‚Üêfc ‚àíŒ±l ¬∑ ‚àábJc(Qc(fc); Uc)
‚ñ∑The update on gc induces an update on fc
13:
end for
14:
send fc ‚àíf to SERVEREXECUTE
15: end procedure
16: procedure C. SERVEREXECUTE(r)
17:
receive local models‚Äô updates {fc ‚àíf}C
c=1 from CLIENTUPDATE
18:
f ‚Üêf ‚àíŒ±g ¬∑ PC
c=1(fc ‚àíf)
‚ñ∑FL aggregation
19:
broadcast f to CLIENTUPDATE
20: end procedure"
PROPOSED METHOD,0.17941952506596306,"Note that œÄ, œÄc, and Œ†c are all fixed, Qc is deterministic and can be identified with the knowledge of
œÄ, Œ†c, and an estimate of œÄc. In addition, we note that if Mc < M, the last M ‚àíMc entries of Qc
are padded with zero by construction. We further study the property of Qc in the following lemma."
PROPOSED METHOD,0.1820580474934037,"Lemma 2. For each client c ‚àà[C], the transition function Qc : (X ‚Üí‚àÜK‚àí1) ‚Üí(X ‚Üí‚àÜM‚àí1)
defined in Theorem 1 is an injective function."
PROPOSED METHOD,0.18469656992084432,"In this sense, the transition function Qc naturally bridges the class-posterior probability of our desired
task Œ∑(x) and that of the learnable surrogate task Œ∑c(x) given only U training sets. This motivates
us to embed the estimation of Œ∑(x) into the estimation of Œ∑c(x) at the client side."
PROPOSED METHOD,0.18733509234828497,"Local Model Modification
Second, we modify the model for the clients. Let f(x) be the original
global model output that estimates Œ∑(x). At each client c ‚àà[C], we implement Qc by adding a
transition layer following fc and then we have gc(x) = Qc(fc(x)). Based on the local model
modification, (7) can be reformulated as follows:"
PROPOSED METHOD,0.18997361477572558,J(f) = 1 C XC
PROPOSED METHOD,0.19261213720316622,"c=1 Jc(Qc(f)) := E(x,y)‚àºpc(x,y)[‚Ñì(Qc(f(x)), y)].
(9) xùíô xùíá xùúΩ"
PROPOSED METHOD,0.19525065963060687,"xùë¶
xùíà
x‡¥§ùë¶"
PROPOSED METHOD,0.19788918205804748,"x
ùëÖ(ùíá; ùë¶)
x
ùêΩ(ùíà; ‡¥§ùë¶)"
PROPOSED METHOD,0.20052770448548812,ùë∏(ùíá) = ùíà
PROPOSED METHOD,0.20316622691292877,"Figure 2: Graphical representa-
tion of supervised FL (in blue)
and FedUL (in green)."
PROPOSED METHOD,0.20580474934036938,"Therefore, local updates on the surrogate model gc naturally yield
updates on the underlying model f. Now we can aggregate the
surrogate clients by a standard FL scheme. A detailed algorithm,
using FedAvg as an example, is given in Algorithm 1."
PROPOSED METHOD,0.20844327176781002,"Remarks
The relationship elucidating the supervised and sur-
rogate FL paradigms (for a single client) is visually shown in
Figure 2. The blue part illustrates a supervised FL scheme: the
global model is f(x) parameterized by Œ∏; the loss is R(f; y) in
(2) where labels y are observed. However, we cannot observe y
and thus employ a surrogate FedUL scheme which is shown in
green: the global model is g(x) directly modified from f; the
loss is J(g; y) in (7) where y are surrogate labels."
PROPOSED METHOD,0.21108179419525067,Published as a conference paper at ICLR 2022
THEORETICAL ANALYSIS,0.21372031662269128,"3.3
THEORETICAL ANALYSIS"
THEORETICAL ANALYSIS,0.21635883905013192,"In what follows, we provide theoretical analysis on the convergence and optimal model recovery for
the proposed method."
THEORETICAL ANALYSIS,0.21899736147757257,"Convergence of the Algorithm
In supervised FL, convergence analysis has been studied with
regularity conditions (see Section 3.2.2 in Kairouz et al. (2019) for a comprehensive survey), e.g.,
the bounded gradient dissimilarity (Karimireddy et al., 2020) that associates the client model with
the server model for non-IID data distributions.3 In our analysis, we focus on the behaviour of our
surrogate learning objective J with the effect from transformation Qc.
Proposition 3 (Theorem V in Karimireddy et al. (2020)). Assume that J(g) in (7) satisfies
(A1)-(A3) in Appendix C.3. Denote g‚àó= argming‚ààG bJ(g), where bJ(g) =
1
C
PC
c=1 bJc(g) :=
1
nc
Pnc
i=1 ‚Ñì(g(xi), yi). Let the global step-size Œ±g ‚â•1 and local step-size Œ±l ‚â§
1
8(1+B2)Œ≤LŒ±g ,
FedUL given by Algorithm 1 is expected to have contracting gradient: with the initialized model g0,
F := J(g0) ‚àíJ(g‚àó) and constant M = œÉ
q 1 + C"
THEORETICAL ANALYSIS,0.22163588390501318,"Œ±2g , in R rounds, the learned model gR satisfies"
THEORETICAL ANALYSIS,0.22427440633245382,"E[‚à•‚àáJ(gR)‚à•2] ‚â§O Œ≤M
‚àö F
‚àö"
THEORETICAL ANALYSIS,0.22691292875989447,"RLC
+ Œ≤1/3(FG)2/3"
THEORETICAL ANALYSIS,0.22955145118733508,"(R + 1)2/3
+ Œ≤B2F R ! ."
THEORETICAL ANALYSIS,0.23218997361477572,"Note that the proposition statement is w.r.t. the convergence of g learned from the surrogate task. By
model construction, g is built from Qc(f). By Lemma 2, the convergence of trained model g to the
optimal model g‚àóin the function class G implies the convergence of the retrieved model f to the
optimal model f ‚àó= argminf‚ààF bJ(f) in the corresponding function class F (induced by G), where
bJ(f) = 1"
THEORETICAL ANALYSIS,0.23482849604221637,"C
PC
c=1 bJc(Qc(f)) :=
1
nc
Pnc
i=1 ‚Ñì(Qc(f(xi)), yi) is the empirical version of (9)."
THEORETICAL ANALYSIS,0.23746701846965698,"Optimal Model Recovery
In our context, the model is optimal in the sense that the minimizer of
the surrogate task J(f; y) coincide with the minimizer of the supervised task R(f; y) , as if all the
data have been labeled. Based on the convergence of surrogate training, we show that FedUL can
recover this optimal model.
Theorem 4. Assume that the cross-entropy loss is chosen for ‚Ñì, and the model used for g
is very flexible, e.g., deep neural networks, so that g‚àó‚àó‚ààG where g‚àó‚àó= argming J(g; y).
Let f ‚àó= argminf‚ààF bJ(f) be the optimal classifier learned with FedUL by Algorithm 1, and
f ‚ãÜ= argminf R(f; y) be the optimal classifier learned with supervised FL. By assumptions in
Proposition 3, we have f ‚àó= f ‚ãÜ."
EXPERIMENTS,0.24010554089709762,"4
EXPERIMENTS"
EXPERIMENTS,0.24274406332453827,"In this section, we conduct experiments to validate the effectiveness of the proposed FedUL method
under various testing scenarios. Compared with the baseline methods, FedUL consistently achieves
superior results on both benchmark and real-world datasets. The detailed experimental settings and
additional supportive results are presented in Appendix D & E."
BENCHMARK EXPERIMENTS,0.24538258575197888,"4.1
BENCHMARK EXPERIMENTS"
BENCHMARK EXPERIMENTS,0.24802110817941952,"Setup: As proof-of-concepts, we first perform experiments on widely adopted benchmarks MNIST
(LeCun et al., 1998) and CIFAR10 (Krizhevsky et al., 2009). We generate M sets of U training data
according to (5) for each client c ‚àà[C]. The total number of training samples nc on each client is
fixed, and the number of instances contained in each set indexed by m is also fixed as nc/M. In order
to simulate the real world cases, we uniformly select class priors œÄm,k
c
from range [0.1, 0.9] and then
regularize them to formulate a valid Œ†c ‚ààRM√óK as discussed in Section 3.1."
BENCHMARK EXPERIMENTS,0.25065963060686014,"For model training, we use the cross-entropy loss and Adam (Kingma & Ba, 2015) optimizer with
a learning rate of 1e‚àí4 and train 100 rounds. If not specified, our default setting for local update"
BENCHMARK EXPERIMENTS,0.2532981530343008,"3The IID case is equivalent to batch sampling from the same distribution, where the analysis is less interesting
associated with our FL setting and we omit details here."
BENCHMARK EXPERIMENTS,0.2559366754617414,Published as a conference paper at ICLR 2022
BENCHMARK EXPERIMENTS,0.25857519788918204,"Table 1: Quantitative comparison of our method with the baseline methods on benchmark datasets
under IID and Non-IID setting (mean error (std)). The best method (paired t-test at significance level
5%) is highlighted in boldface."
BENCHMARK EXPERIMENTS,0.2612137203166227,IID Task with 5 Clients
BENCHMARK EXPERIMENTS,0.2638522427440633,"Dataset
Sets
FedPL
FedLLP
FedLLP-VAT
FedUL
FedAvg 10% MNIST"
BENCHMARK EXPERIMENTS,0.26649076517150394,"10
2.12 (0.10)
19.00 (15.90)
20.53 (5.39)
0.78 (0.06)"
BENCHMARK EXPERIMENTS,0.2691292875989446,"1.79 (0.09)
20
2.98 (0.15)
4.38 (3.95)
4.40 (5.11)
1.12 (0.09)
40
3.90 (0.22)
10.11 (15.74)
11.96 (9.56)
1.00 (0.29)"
BENCHMARK EXPERIMENTS,0.2717678100263852,CIFAR10
BENCHMARK EXPERIMENTS,0.27440633245382584,"10
34.60 (0.30)
77.01 (5.02)
77.56 (8.71)
18.56 (0.04)"
BENCHMARK EXPERIMENTS,0.2770448548812665,"32.85 (1.03)
20
42.06 (1.63)
78.74 (6.96)
84.18 (5.95)
19.66 (0.30)
40
46.20 (0.67)
73.75 (4.78)
78.65 (6.91)
20.31 (0.69)"
BENCHMARK EXPERIMENTS,0.2796833773087071,Non-IID Task with 5 Clients
BENCHMARK EXPERIMENTS,0.28232189973614774,"Dataset
Sets
FedPL
FedLLP
FedLLP-VAT
FedUL
FedAvg 10% MNIST"
BENCHMARK EXPERIMENTS,0.2849604221635884,"10
15.54 (3.48)
20.52 (15.00)
23.39 (15.34)
2.98 (1.72)"
BENCHMARK EXPERIMENTS,0.287598944591029,"3.82 (1.56)
20
7.54 (2.77)
6.63 (7.94)
11.76 (6.60)
1.77 (0.49)
40
5.76 (0.90)
5.53 (2.51)
7.82 (10.73)
1.64 (0.18)"
BENCHMARK EXPERIMENTS,0.29023746701846964,CIFAR10
BENCHMARK EXPERIMENTS,0.2928759894459103,"10
70.65 (2.38)
81.12 (5.41)
81.55 (7.09)
42.92 (3.02)"
BENCHMARK EXPERIMENTS,0.2955145118733509,"58.62 (8.63)
20
63.53 (1.24)
65.51 (13.16)
70.51 (7.66)
35.24 (0.98)
40
53.78 (0.13)
65.72 (3.93)
60.23 (5.71)
31.43 (1.72)"
BENCHMARK EXPERIMENTS,0.29815303430079154,"epochs (E) is 1 and batch size (B) is 128 with 5 clients (C) in our FL system. We use LeNet (LeCun
et al., 1998) and ResNet18 (He et al., 2016) as backbone for MNIST and CIFAR10, respectively.
Here, we investigate two different FL settings: IID and Non-IID, where the overall label distribution
across clients is the same in the IID setting, whereas clients have different label distributions in the
non-IID setting. Specially, for Non-IID setting, we impose class-prior shift as follows:"
BENCHMARK EXPERIMENTS,0.3007915567282322,"‚Ä¢ the classes are divided into the majority and minority classes, where the fraction of each minority
class is less than 0.08 while the fraction of each majority class is in the range [0.15, 0.25];
‚Ä¢ the training data for every client are sampled from 2 majority classes and 8 minority classes;
‚Ä¢ the test data are uniformly sampled from all classes."
BENCHMARK EXPERIMENTS,0.3034300791556728,"Baselines: (1) Federated Pseudo Labeling (FedPL) (Diao et al., 2021): at each client of a FedAvg
system, we choose the label with the largest class prior in a U set as the pseudo label for all the
data in this set. During local training, these pseudo labels are boosted by Mixup (Zhang et al., 2017)
high-confidence data and low-confidence data, where the confidence is given by model predictions.
(2) Federated LLP (FedLLP) (Dulac-Arnold et al., 2019): each client model is updated by minimizing
the distance between the ground truth label proportion and the predicted label proportion, and we
aggregate them using FedAvg. (3) FedLLP with Virtual Adversarial Training (FedLLP-VAT) (Tsai
& Lin, 2020): a consistency term is added to FedLLP as regularization for optimizing client model
in FedAvg. (4) FedAvg with 10% labeled data (FedAvg 10%): following Chen et al. (2020), we
also compare with supervised learning based on FedAvg using 10% fully labeled data. The detailed
baseline settings are depicted in Appendix D."
BENCHMARK EXPERIMENTS,0.30606860158311344,"Results: The experimental results of our method and baselines on two benchmark datasets under
IID and Non-IID settings are reported in Table 1, where the mean error (std) over clients based on
3 independent runs are shown. Given the limited number of total data available in the benchmark
datasets, we compare our method with baselines in an FL system with five clients and vary the number
of U sets M ‚àà{10, 20, 40} at each client. In this regard, each set contains a sufficient number of
data samples to train the model."
BENCHMARK EXPERIMENTS,0.3087071240105541,"Our observations are as follows. First, the proposed FedUL method outperforms other baseline
methods by a large margin under both IID and Non-IID settings. Second, when varying the number of
sets M ‚àà{10, 20, 40}, FedUL not only achieves lower classification error but also shows more stable
performance compared to baselines. Third, as we use FedAvg as the default aggregation strategy for
all the methods, the performances of FedUL, FedPL, and FedAvg all degrade under the inter-client
Non-IID setting, as expected. The error rates of FedLLP and FedLLP-VAT are high and unstable,
which demonstrates that the EPRM based methods are inferior as discussed in Section 1."
BENCHMARK EXPERIMENTS,0.3113456464379947,Published as a conference paper at ICLR 2022
BENCHMARK EXPERIMENTS,0.31398416886543534,"(a)
(b)
(c)
(d)"
BENCHMARK EXPERIMENTS,0.316622691292876,"Figure 3: Ablation studies on MNIST under a Non-IID FL system. (a) Study on the robustness of our
method with noisy class priors. (b) Effects of the number of accessible Non-IID U data. (c) Analysis
of local updating epochs. (d) Effects of training batch size."
ABLATION STUDIES,0.31926121372031663,"4.2
ABLATION STUDIES"
ABLATION STUDIES,0.32189973614775724,"In the following, we present a comprehensive investigation on the ablation studies of the proposed
FedUL method on MNIST benchmark."
ABLATION STUDIES,0.3245382585751979,"Robustness with Noisy Class Priors: To investigate the robustness of our method, we further apply
FedUL in a noisy environment. Specifically, we perturb the class priors œÄm,k
c
by a random noise
Œ≥, and let the method treat the noisy class prior eœÄm,k
c
= œÄm,k
c
¬∑ ((2œµ ‚àí1)Œ≥ + 1), where Œ≥ uniform
randomly take values in [0, 1] and œµ ‚àà{0, 0.2, 0.4, 0.8, 1.6}, as the true œÄm,k
c
during the whole
learning process. Note that we tailor the noisy eœÄm,k
c
if it surpasses the range. We conduct experiments
with five clients and ten U sets at each client. The experimental setup is the same as before except for
the replacement of œÄm,k
c
. From Figure 3(a), we can see that FedUL performs stably even with some
challenging noise perturbations (see when noise ratio œµ > 0)."
ABLATION STUDIES,0.32717678100263853,"Effects of the Number of Accessible Non-IID U Data: The purpose of FL is utilizing more data to
empower model performance. While how unlabeled data, especially unlabeled Non-IID data, can
contribute to FL model performance needs investigation. To this end, we analyze the effects of the
number of accessible Non-IID U data. We set each client with nc = 500 samples ‚àÄc ‚àà[C] and
conduct experiments by changing the amount of Non-IID U data by increasing the number of clients
C ‚àà{10, 20, 30, 40, 50}. As shown in Figure 3(b), the model performance improves by a large
margin as the number of accessible Non-IID U data increases by using our proposed FedUL method."
ABLATION STUDIES,0.32981530343007914,"Analysis of Local Updating Epochs: The frequency of aggregation may sometimes influence the
model performance in an FL system. We would like to explore if FedUL is stable when the local
clients are updated with different local epochs E. In Figure 3(c), we explore E ‚àà{1, 2, 4, 8, 16}
with fixed B = 128 and C = 5. The results demonstrate that with different E, the performances of
FedUL are reasonably stable."
ABLATION STUDIES,0.3324538258575198,"Effects of Batch Size: The training batch size is always an important factor in machine learning tasks,
especially in an FL system. Hence here, we study how batch size affects our model performance.
Specifically, we train the model using different batch sizes B ‚àà{16, 64, 128, 512, ‚àû} with fixed
E = 1 and C = 5. Here B = ‚àûstands for loading all of the training samples into a single batch.
The results in Figure 3(d) indicate that FedUL can effectively work under a wide range of batch sizes."
CASE STUDY ON REAL-WORLD PROBLEM,0.33509234828496043,"4.3
CASE STUDY ON REAL-WORLD PROBLEM"
CASE STUDY ON REAL-WORLD PROBLEM,0.33773087071240104,"To demonstrate the feasibility of our proposed FedUL scheme to the real problem, we test FedUL on
a medical application for the diagnosis of brain disease. In the rest of this section, we introduce the
problem formulation, data and setting, and then discuss the results."
CASE STUDY ON REAL-WORLD PROBLEM,0.3403693931398417,"Real Problem Formulation: For the real-world scenario, we consider a clinical setting for disease
classification in C different healthcare systems. Suppose each healthcare system has M hospitals
located in different regions, each associated with unique class priors due to population diversities.
Medical data are not shareable between the healthcare systems for privacy reasons. We assume
patient-wise diagnosis information is unavailable, but each hospital provides the prevalence of these
patients (i.e., class priors of the disease classes)."
CASE STUDY ON REAL-WORLD PROBLEM,0.34300791556728233,Published as a conference paper at ICLR 2022
CASE STUDY ON REAL-WORLD PROBLEM,0.34564643799472294,"Table 2: Quantitative comparison of our method with the baseline methods for the five healthcare
systems (HS) using the real-world intracranial hemorrhage detection dataset. Results of three runs
are reported in mean error (std) format. The best methods are highlighted in boldface."
CASE STUDY ON REAL-WORLD PROBLEM,0.3482849604221636,"Hospitals
Method
HS 1
HS 2
HS 3
HS 4
HS 5"
FEDPL,0.35092348284960423,"12
FedPL
44.69 (4.28)
46.42 (4.35)
46.29 (1.83)
47.55 (2.84)
46.53 (2.40)
FedUL (ours)
40.26 (1.39)
40.35 (1.10)
39.31 (1.10)
39.72 (0.67)
39.43 (1.42)"
FEDPL,0.35356200527704484,"24
FedPL
42.71 (2.97)
42.18 (3.00)
42.30 (1.28)
41.79 (1.98)
41.46 (0.53)
FedUL (ours)
32.27 (2.71)
30.99 (2.03)
31.29 (1.05)
31.72 (1.23)
31.37 (1.58)"
FEDPL,0.3562005277044855,"48
FedPL
41.44 (3.04)
40.38 (1.38)
41.06 (2.88)
41.44 (1.78)
40.26 (2.35)
FedUL (ours)
31.48 (2.25)
30.92 (0.88)
31.16 (0.84)
31.55 (0.58)
30.57 (1.37)
-
FedAvg 10%
46.79 (1.91)
46.44 (0.78)
47.19 (1.05)
47.29 (1.93)
46.20 (1.61)"
FEDPL,0.35883905013192613,"(a) Healthy
(b) Epidural
(c) Intraparenchymal
(d) Intraventricular
(e) Subarachnoid
(f) Subdural"
FEDPL,0.36147757255936674,"Figure 4: Example samples of each class in the distributed medical dataset (Flanders et al., 2020)."
FEDPL,0.3641160949868074,"Dataset and Settings: We use the RSNA Intracranial Hemorrhage Detection dataset (Flanders et al.,
2020), which contains large-scale Magnetic Response Image (MRI) data from several hospitals (see
Figure 4), to simulate this real-world scenario. There are 106k samples in the dataset belonging to six
classes, including five types of intracranial hemorrhage (Epidural, Intraparenchymal, Intraventricular,
Subarachnoid, and Subdural) and healthy control type. We model an FL system with five healthcare
systems (i.e., clients). Each healthcare system contains 21.2k data samples. To show the effect on the
number of samples in each U set, we vary the number of hospitals (i.e., sets) M = 12, 24, and 48 in
each system. Here we generate each œÄm,k
c
for the k-th class in m-th U set at c-th client from range
[0.1, 0.9] and check that the generated class priors are not all identical. For model training, we use
the cross-entropy loss and Adam (Kingma & Ba, 2015) optimizer with a learning rate of 1e ‚àí4 and
train 100 rounds. We use ResNet18 (He et al., 2016) as backbone for this experiment."
FEDPL,0.36675461741424803,"Results and Analysis: As indicated in our proof-of-concept (Table 1), FedPL consistently outper-
forms the other two LLP baselines, i.e., FedLLP and FedLLP-VAT. Here we focus on comparing
FedUL with FedPL. The supervised baseline FedAvg with 10% fully labeled data is also included
for reference. We report the results of each hospital in mean error (std) format over three runs in
Table 2. We can see that our proposed FedUL method consistently outperforms FedPL and FedAvg
10% for all the hospitals and under different set number settings. The superiority of FedUL in this
challenging real-world FL setting further indicates the effectiveness and robustness of our algorithm.
These results are inspiring and bring the hope of deploying FedUL to the healthcare field, where data
are often very costly to be labeled, heterogeneous, and distributed."
CONCLUSION,0.36939313984168864,"5
CONCLUSION"
CONCLUSION,0.3720316622691293,"In this paper, we propose FedUL, a novel FL algorithm using only U data. FedUL works as a
wrapper that transforms the unlabeled client data and modifies the client model to form a surrogate
supervised FL task, which can be easily solved using existing FL paradigms. Theoretically, we prove
that the recovery of the optimal model by using the FedUL method can be guaranteed under mild
conditions. Through extensive experiments on benchmark and real-world datasets, we show FedUL
can significantly outperform the baseline methods under different settings. As a wrapper, we expect
FedUL can be further improved by incorporating advanced FL aggregation or optimization schemes
for the non-IID setting (Wang et al., 2020; Li et al., 2020; 2021; Karimireddy et al., 2020)."
CONCLUSION,0.37467018469656993,Published as a conference paper at ICLR 2022
ETHICS STATEMENT,0.37730870712401055,ETHICS STATEMENT
ETHICS STATEMENT,0.37994722955145116,"Collecting sample-wise labels for training can be costly and may violate data privacy. Considering
data in the real world are often distributed at a large scale, we provide a promising solution to perform
multi-class classification on distributed U data in the FL system. Our method FedUL can be widely
applied to data-sensitive fields, such as healthcare, politics, and finance, where the sample-wise label
is not available, but populational prevalence can be accessed. With FedUL, we hope the future FL
can enjoy significant labeling cost reduction and improve its privacy. The real datasets used in this
work are publicly available with appropriate prepossessing to de-identify patients‚Äô identities. We
provide proper references to the datasets, libraries, and tools used in our study. This study does not
have any legal compliance, conflict of interest, or research integrity issues."
REPRODUCIBILITY STATEMENT,0.38258575197889183,REPRODUCIBILITY STATEMENT
REPRODUCIBILITY STATEMENT,0.38522427440633245,"We provide the codes to reproduce the main experimental results at https://github.com/
lunanbit/FedUL. We further provide experimental details and additional information of the
datasets in the supplementary materials."
REPRODUCIBILITY STATEMENT,0.38786279683377306,ACKNOWLEDGMENTS
REPRODUCIBILITY STATEMENT,0.39050131926121373,"NL was supported by JST AIP Challenge Program and the Institute for AI and Beyond, UTokyo.
ZW and QD were supported by project of Shenzhen-HK Collaborative Development Zone. XL
was thankful for the support by NVIDIA. GN was supported by JST AIP Acceleration Research
Grant Number JPMJCR20U. MS was supported by JST AIP Acceleration Research Grant Number
JPMJCR20U3 and the Institute for AI and Beyond, UTokyo."
REFERENCES,0.39313984168865435,REFERENCES
REFERENCES,0.39577836411609496,"Abdullatif Albaseer, Bekir Sait Ciftler, Mohamed Abdallah, and Ala Al-Fuqaha. Exploiting unlabeled
data in smart cities using federated edge learning. In 2020 International Wireless Communications
and Mobile Computing (IWCMC), pp. 1666‚Äì1671. IEEE, 2020."
REFERENCES,0.39841688654353563,"Manoj Ghuhan Arivazhagan, Vinay Aggarwal, Aaditya Kumar Singh, and Sunav Choudhary. Feder-
ated learning with personalization layers. arXiv preprint arXiv:1912.00818, 2019."
REFERENCES,0.40105540897097625,"Dimitri P Bertsekas. Nonlinear programming. Journal of the Operational Research Society, 48(3):
334‚Äì334, 1997."
REFERENCES,0.40369393139841686,"O. Chapelle, B. Sch√∂lkopf, and A. Zien (eds.). Semi-Supervised Learning. MIT Press, 2006."
REFERENCES,0.40633245382585753,"Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for
contrastive learning of visual representations. In International Conference on Machine Learning,
pp. 1597‚Äì1607. PMLR, 2020."
REFERENCES,0.40897097625329815,"Janet B Croft, Anne G Wheaton, Yong Liu, Fang Xu, Hua Lu, Kevin A Matthews, Timothy J
Cunningham, Yan Wang, and James B Holt. Urban-rural county and state differences in chronic
obstructive pulmonary disease‚Äîunited states, 2015. Morbidity and Mortality Weekly Report, 67
(7):205, 2018."
REFERENCES,0.41160949868073876,"Pieter-Tjerk De Boer, Dirk P Kroese, Shie Mannor, and Reuven Y Rubinstein. A tutorial on the
cross-entropy method. Annals of operations research, 134(1):19‚Äì67, 2005."
REFERENCES,0.41424802110817943,"Don Kurian Dennis, Tian Li, and Virginia Smith. Heterogeneity for the win: One-shot federated clus-
tering. In Marina Meila and Tong Zhang (eds.), Proceedings of the 38th International Conference
on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pp. 2611‚Äì2620.
PMLR, 18‚Äì24 Jul 2021."
REFERENCES,0.41688654353562005,"Enmao Diao, Jie Ding, and Vahid Tarokh. Semifl: Communication efficient semi-supervised federated
learning with unlabeled clients. arXiv preprint arXiv:2106.01432, 2021."
REFERENCES,0.41952506596306066,Published as a conference paper at ICLR 2022
REFERENCES,0.42216358839050133,"Gabriel Dulac-Arnold, Neil Zeghidour, Marco Cuturi, Lucas Beyer, and Jean-Philippe Vert. Deep
multi-class learning from label proportions. arXiv preprint arXiv:1905.12909, 2019."
REFERENCES,0.42480211081794195,"Alireza Fallah, Aryan Mokhtari, and Asuman E Ozdaglar. Personalized federated learning with
theoretical guarantees: A model-agnostic meta-learning approach. In NeurIPS, 2020."
REFERENCES,0.42744063324538256,"Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of
deep networks. In International Conference on Machine Learning. PMLR, 2017."
REFERENCES,0.43007915567282323,"Adam E Flanders, Luciano M Prevedello, George Shih, Safwan S Halabi, Jayashree Kalpathy-
Cramer, Robyn Ball, John T Mongan, Anouk Stein, Felipe C Kitamura, Matthew P Lungren,
et al. Construction of a machine learning dataset through collaboration: the rsna 2019 brain ct
hemorrhage challenge. Radiology: Artificial Intelligence, 2(3):e190211, 2020."
REFERENCES,0.43271767810026385,"Avishek Ghosh, Jichan Chung, Dong Yin, and Kannan Ramchandran. An efficient framework
for clustered federated learning. In Proceedings of the 34th Conference on Neural Information
Processing Systems, 2020."
REFERENCES,0.43535620052770446,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pp. 770‚Äì778, 2016."
REFERENCES,0.43799472295514513,"Sohei Itahara, Takayuki Nishio, Yusuke Koda, Masahiro Morikura, and Koji Yamamoto. Distillation-
based semi-supervised federated learning for communication-efficient collaborative training with
non-iid private data. arXiv preprint arXiv:2008.06180, 2020."
REFERENCES,0.44063324538258575,"Wonyong Jeong, Jaehong Yoon, Eunho Yang, and Sung Ju Hwang. Federated semi-supervised
learning with inter-client consistency & disjoint learning. In International Conference on Learning
Representations (ICLR), 2021."
REFERENCES,0.44327176781002636,"Yihan Jiang, Jakub KoneÀácn`y, Keith Rush, and Sreeram Kannan. Improving federated learning
personalization via model agnostic meta learning. arXiv preprint arXiv:1909.12488, 2019."
REFERENCES,0.44591029023746703,"Peter Kairouz, H Brendan McMahan, Brendan Avent, Aur√©lien Bellet, Mehdi Bennis, Arjun Nitin
Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Ad-
vances and open problems in federated learning. arXiv preprint arXiv:1912.04977, 2019."
REFERENCES,0.44854881266490765,"Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In
International Conference on Machine Learning, pp. 5132‚Äì5143. PMLR, 2020."
REFERENCES,0.45118733509234826,"Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. International
Conference on Learning Representation, pp. 1‚Äî-13, 2015."
REFERENCES,0.45382585751978893,"Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.
Technical report, 2009."
REFERENCES,0.45646437994722955,"Yann LeCun, L√©on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278‚Äì2324, 1998."
REFERENCES,0.45910290237467016,"Jeffrey Li, Mikhail Khodak, Sebastian Caldas, and Ameet Talwalkar. Differentially private meta-
learning. arXiv preprint arXiv:1909.05830, 2019."
REFERENCES,0.46174142480211083,"Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith.
Federated optimization in heterogeneous networks. In Conference on Machine Learning and
Systems, 2020a, 2020."
REFERENCES,0.46437994722955145,"Xiaoxiao Li, Meirui JIANG, Xiaofei Zhang, Michael Kamp, and Qi Dou. FedBN: Federated learning
on non-IID features via local batch normalization. In International Conference on Learning
Representations, 2021. URL https://openreview.net/forum?id=6YEQUn0QICG."
REFERENCES,0.46701846965699206,"Nan Lu, Shida Lei, Gang Niu, Issei Sato, and Masashi Sugiyama. Binary classification from multiple
unlabeled datasets via surrogate set classification.
In International Conference on Machine
Learning, pp. 7134‚Äì7144. PMLR, 2021."
REFERENCES,0.46965699208443273,Published as a conference paper at ICLR 2022
REFERENCES,0.47229551451187335,"Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-efficient learning of deep networks from decentralized data. In Artificial intelli-
gence and statistics, pp. 1273‚Äì1282. PMLR, 2017."
REFERENCES,0.47493403693931396,"Dianwen Ng, Xiang Lan, Melissa Min-Szu Yao, Wing P Chan, and Mengling Feng. Federated
learning: a collaborative effort to achieve better medical imaging models for individual sites that
have small labelled datasets. Quantitative Imaging in Medicine and Surgery, 11(2):852, 2021."
REFERENCES,0.47757255936675463,"N. Quadrianto, A. J. Smola, T. S. Caetano, and Q. V. Le. Estimating labels from label proportions.
Journal of Machine Learning Research, 10:2349‚Äì2374, 2009a."
REFERENCES,0.48021108179419525,"Novi Quadrianto, Alex J Smola, Tiberio S Caetano, and Quoc V Le. Estimating labels from label
proportions. Journal of Machine Learning Research, 10(10), 2009b."
REFERENCES,0.48284960422163586,"Mark D Reid and Robert C Williamson. Composite binary losses. The Journal of Machine Learning
Research, 11:2387‚Äì2422, 2010."
REFERENCES,0.48548812664907653,"Felix Sattler, Klaus-Robert M√ºller, and Wojciech Samek. Clustered federated learning: Model-
agnostic distributed multitask optimization under privacy constraints. IEEE transactions on neural
networks and learning systems, 2020."
REFERENCES,0.48812664907651715,"Neta Shoham, Tomer Avidor, Aviv Keren, Nadav Israel, Daniel Benditkis, Liron Mor-Yosef,
and Itai Zeitak. Overcoming forgetting in federated learning on non-iid data. arXiv preprint
arXiv:1910.07796, 2019."
REFERENCES,0.49076517150395776,"M. Sugiyama, H. Bao, T. Ishida, N. Lu, T. Sakai, and G. Niu. Machine Learning from Weak
Supervision: An Empirical Risk Minimization Approach. MIT Press, Cambridge, Massachusetts,
USA, 2022."
REFERENCES,0.49340369393139843,"Kuen-Han Tsai and Hsuan-Tien Lin. Learning from label proportions with consistency regularization.
In Asian Conference on Machine Learning, pp. 513‚Äì528. PMLR, 2020."
REFERENCES,0.49604221635883905,"V. N. Vapnik. Statistical Learning Theory. John Wiley & Sons, 1998."
REFERENCES,0.49868073878627966,"Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and H Vincent Poor. Tackling the objective
inconsistency problem in heterogeneous federated optimization. arXiv preprint arXiv:2007.07481,
2020."
REFERENCES,0.5013192612137203,"Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. Federated machine learning: Concept and
applications. ACM Transactions on Intelligent Systems and Technology (TIST), 10(2):1‚Äì19, 2019."
REFERENCES,0.503957783641161,"Xin Yao and Lifeng Sun. Continual local training for better initialization of federated models. In
2020 IEEE International Conference on Image Processing (ICIP), pp. 1736‚Äì1740. IEEE, 2020."
REFERENCES,0.5065963060686016,"Felix X Yu, Krzysztof Choromanski, Sanjiv Kumar, Tony Jebara, and Shih-Fu Chang. On learning
from label proportions. arXiv preprint arXiv:1402.5902, 2014."
REFERENCES,0.5092348284960422,"Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup: Beyond empirical
risk minimization. arXiv preprint arXiv:1710.09412, 2017."
REFERENCES,0.5118733509234829,Xiaojin Jerry Zhu. Semi-supervised learning literature survey. 2005.
REFERENCES,0.5145118733509235,Published as a conference paper at ICLR 2022
REFERENCES,0.5171503957783641,Supplementary Material
REFERENCES,0.5197889182058048,"Roadmap
The appendix is organized as follows. We summarize notations used in our paper in
Section A and give a full discussion of related work in Section B. Our proofs are presented in
Section C. We provide detailed experimental settings in Section D and supplementary experimental
results on the benchmark datasets in Section E."
REFERENCES,0.5224274406332454,"A
NOTATION TABLE"
REFERENCES,0.525065963060686,"Table A.1: Notations used in the paper.
Notations
Description
d
input dimension
K
number of classes for the original classification task
k
index of the class k ‚àà[K]
X
input space X ‚äÇRd"
REFERENCES,0.5277044854881267,"Y
label space Y = [K] where [K] := {1, . . . , K}
x
input x ‚ààX
y
true label y ‚ààY
p
test data distribution
œÄk
k-th class prior œÄk := p(y = k) of the test set
œÄ
vector form of œÄk where œÄ = [œÄ1, ¬∑ ¬∑ ¬∑ , œÄK]‚ä§"
REFERENCES,0.5303430079155673,"‚Ñì
loss function for a classification task
R
risk for the original FL task
f
global model predicting label y for input x
C
number of clients in the FL setup
c
index of the client c ‚àà[C]
fc
c-th client model predicting label y for input x
pc
local data distribution at the c-th client
nc
number of training data at the c-th client
Dc
labeled training set Dc = {(xc
i, yc
i )}nc
i=1 at the c-th client
Œ±l
local step size
Œ±g
global step size
R
global communication round
L
local updating iterations
Mc
number of available U sets at the c-th client
m
index of the U set m ‚àà[Mc]
nc,m
number of training data in the m-th U set at the c-th client
pm
c
m-th U data distribution at the c-th client
Um
c
m-th U set at the c-th client Um
c = {xc,m
i
}nc,m
i=1
Uc
all available U sets at the c-th client Uc = {Um
c }Mc
m=1
M
the maximum number of available U sets among all clients M = maxc‚àà[C] Mc
œÄm,k
c
k-th class prior œÄm,k
c
= pm
c (y = k) of the m-th U set at the c-th client
Œ†c
matrix form of œÄm,k
c
where Œ†c ‚ààRMc√óK"
REFERENCES,0.5329815303430079,"y
surrogate label ¬Øy ‚àà[M]
pc
surrogate local data distribution at the c-th client
Uc
surrogate labeled training set Uc = {xi, yi}nc
i=1 at the c-th client
œÄm
c
m-th surrogate class prior œÄm
c = pc(y = m) at the c-th client
œÄc
vector form of œÄm
c where œÄc = [œÄ1
c, ¬∑ ¬∑ ¬∑ , œÄM
c ]‚ä§"
REFERENCES,0.5356200527704486,"g
surrogate global model predicting surrogate label y for input x
Œ∑c
surrogate class-posterior probability at the c-th client where (Œ∑c(x))m = pc(y = m | x)
Œ∑
true class-posterior probability at the c-th client where (Œ∑(x))k = p(y = k | x)
Qc
vector-valued transition function Qc : (X ‚Üí‚àÜK) ‚Üí(X ‚Üí‚àÜM)
J
surrogate risk for the surrogate FL task"
REFERENCES,0.5382585751978892,Published as a conference paper at ICLR 2022
REFERENCES,0.5408970976253298,"B
RELATED WORK"
REFERENCES,0.5435356200527705,"B.1
PERSONALIZED FEDERATED LEARNING"
REFERENCES,0.5461741424802111,"Considering the heterogeneity of data, clients, and systems, personalization is a natural and trending
solution to improve FL performance. Many efforts have been made in personalized FL. FedProx(Li
et al., 2020), FedCurv (Shoham et al., 2019), and FedCL (Yao & Sun, 2020) propose regularization-
based methods that include special regularization terms to improve FL model generalizing to various
clients. Meta-learning methods, such as MAML (Finn et al., 2017), are also used to learn personalized
models for each client (Jiang et al., 2019; Fallah et al., 2020; Li et al., 2019). Unlike the methods
mentioned above that yield a single generalizable model, multiple FL models can be trained using
clustering strategies (Sattler et al., 2020; Ghosh et al., 2020). Different local FL models can also be
achieved by changing the last personalized layers (Li et al., 2021; Arivazhagan et al., 2019)."
REFERENCES,0.5488126649076517,"At first glance, FedUL looks similar to personalized FL since each client learns a ""personalized""
model gc which contains a client-specific transition layer Qc. However, our learning setting and
method are very different from existing personalized FL approaches, as explained below. First, our
framework focuses on FL with only unlabeled data. The personalized model gc only serves as a
proxy, in order to be compatible with the transformed unlabeled data, and our ultimate goal is to learn
f that is not exactly personalized. Specifically, 1) if the inter-clients are IID, FedUL yields the same
proxy model gc and federated model f for all the clients; 2) if the inter-clients are Non-IID, although
gc is different (as Qc is different), the underlying model f (what we want) is still the same. Second,
our method differs from the previous personalized FL methods by its surrogate training nature: it
works as a wrapper that transforms unlabeled clients to (surrogate) labeled ones and is compatible
with many supervised FL methods."
REFERENCES,0.5514511873350924,"B.2
SEMI-SUPERVISED FEDERATED LEARNING"
REFERENCES,0.554089709762533,"Another line of research working on utilizing unlabeled data in FL follows the semi-supervised
learning framework (Zhu, 2005; Chapelle et al., 2006), which assumes a small amount of labeled
data available at the client side (labels-at-client) or at the server side (labels-at-server). For example,
FedMatch (Jeong et al., 2021) introduces a new inter-client consistency loss that maximizes the
agreement between multiple clients and decomposes the model parameters into one for labeled data
and the other for unlabeled data for disjoint learning. FedSem (Albaseer et al., 2020) generates pseudo
labels for unlabeled data based on the trained FedAvg model with labeled data, and the generated
(pseudo) labeled data are further used to retrain FedAvg to obtain the global model. Moreover,
distillation-based semi-supervised FL (Itahara et al., 2020) considers using shared unlabeled data for
distillation-based message exchanging."
REFERENCES,0.5567282321899736,"Although the motivation of FedUL can be related to semi-supervised FL since both work on utilizing
unlabeled data in FL, our learning setting is different since we only have unlabeled data at both
the client and the server sides, and our method is different since FedUL follows the empirical risk
minimization framework."
REFERENCES,0.5593667546174143,Published as a conference paper at ICLR 2022
REFERENCES,0.5620052770448549,"C
PROOFS"
REFERENCES,0.5646437994722955,"In this appendix, we prove all theorems."
REFERENCES,0.5672823218997362,"C.1
PROOF OF THEOREM 1"
REFERENCES,0.5699208443271768,"By the Bayes‚Äô rule, ‚àÄm ‚àà[M] we have:"
REFERENCES,0.5725593667546174,"(Œ∑c(x))m = pc(x, y = m) pc(x)"
REFERENCES,0.575197889182058,"=
pc(x, y = m)
PMc
m=1 pc(x, y = m)"
REFERENCES,0.5778364116094987,"=
pc(x | y = m)pc(y = m)
PMc
m=1 pc(x | y = m)pc(y = m)"
REFERENCES,0.5804749340369393,"=
pm
c (x)œÄm
c
PMc
m=1 pm
c (x)œÄm
c"
REFERENCES,0.58311345646438,"=
œÄm
c
PK
k=1 œÄm,k
c
p(x | y = k)
PMc
m=1 œÄm
c
PK
k=1 œÄm,k
c
p(x | y = k)"
REFERENCES,0.5857519788918206,"=
œÄm
c
PK
k=1 œÄm,k
c
(Œ∑(x))k"
REFERENCES,0.5883905013192612,"œÄk
PMc
m=1 œÄm
c
PK
k=1 œÄm,k
c
(Œ∑(x))k"
REFERENCES,0.5910290237467019,"œÄk
.
(10)"
REFERENCES,0.5936675461741425,"By transforming (10) to the matrix form, we complete the proof."
REFERENCES,0.5963060686015831,"C.2
PROOF OF LEMMA 2"
REFERENCES,0.5989445910290238,"Given our data generation process in Section 3.1, we have that Mc ‚â•k and Œ†c ‚ààRMc√óK is a full
column rank matrix. With DœÄc and D‚àí1
œÄ being non-degenerate, we obtain that Qc(Œ∑(x)) presents
an injective mapping from Œ∑(x) to Œ∑c(x)."
REFERENCES,0.6015831134564644,"C.3
PROOF OF PROPOSITION 3"
REFERENCES,0.604221635883905,The assumptions (A1)-(A3) are listed as follows.
REFERENCES,0.6068601583113457,"(A1) Bounded gradient dissimilarity: ‚àÉconstants G ‚â•0 and B ‚â•1 s.t.
1
C XC"
REFERENCES,0.6094986807387863,"c=1 ‚à•‚àáJc(g)‚à•2 ‚â§G2 + B2‚à•‚àáJ(g)‚à•2, ‚àÄg."
REFERENCES,0.6121372031662269,(A2) Œ≤-smooth function Jc satisfies
REFERENCES,0.6147757255936676,"‚à•‚àáJc(Œ∏) ‚àí‚àáJc(Œ∏‚Ä≤)‚à•‚â§Œ≤‚à•Œ∏ ‚àíŒ∏‚Ä≤‚à•, ‚àÄc, Œ∏, Œ∏‚Ä≤."
REFERENCES,0.6174142480211082,(A3) Unbiased stochastic gradient with bounded variance:
REFERENCES,0.6200527704485488,"E[‚à•‚àábJc(g; Uc) ‚àí‚àáJc(g)‚à•2] ‚â§œÉ2, ‚àÄc, g,"
REFERENCES,0.6226912928759895,"where bJc(g; Uc) =
1
nc
Pnc
i=1 ‚Ñì(g(xi), yi)."
REFERENCES,0.6253298153034301,"Note that this proposition statement is w.r.t. the convergence of model g learned from the surrogate
supervised learning task. The proof follows directly from Theorem V in Karimireddy et al. (2020)."
REFERENCES,0.6279683377308707,"C.4
PROOF OF THEOREM 4"
REFERENCES,0.6306068601583114,"When a proper loss (Reid & Williamson, 2010) is used for ‚Ñì, the mapping of g‚àó‚àóis the unique
minimizer of J(g). We show an example of the a widely used proper loss function: the cross-entropy
loss (De Boer et al., 2005) defined as"
REFERENCES,0.633245382585752,"‚Ñìce(g(x), y) = ‚àí
XM"
REFERENCES,0.6358839050131926,m=1 1(y = m) log(g(x))m = ‚àílog(g(x))y.
REFERENCES,0.6385224274406333,Published as a conference paper at ICLR 2022
REFERENCES,0.6411609498680739,"We can see that the cross-entropy loss is non-negative by its definition. Therefore, minimizing J(g)
can be obtained by minimizing the conditional risk Ep(y|x)[‚Ñì(g(x), y) | x] for every x ‚ààX. So we
are now optimizing"
REFERENCES,0.6437994722955145,"œï(g) = ‚àí M
X"
REFERENCES,0.6464379947229552,"m=1
p(y = m | x) ¬∑ log(g(x))m,
s.t. M
X"
REFERENCES,0.6490765171503958,"m=1
(g(x))m = 1."
REFERENCES,0.6517150395778364,"By using the Lagrange multiplier method (Bertsekas, 1997), we have L = ‚àí M
X"
REFERENCES,0.6543535620052771,"m=1
p(y = m | x) ¬∑ log(g(x))m ‚àíŒª ¬∑ ( M
X"
REFERENCES,0.6569920844327177,"m=1
(g(x))m ‚àí1)."
REFERENCES,0.6596306068601583,The derivative of L with respect to g is ‚àÇL
REFERENCES,0.662269129287599,"‚àÇg =

‚àíp(y = 1 | x)"
REFERENCES,0.6649076517150396,"(g(x))1
‚àíŒª, ¬∑ ¬∑ ¬∑, ‚àíp(y = M | x)"
REFERENCES,0.6675461741424802,"(g(x))M
‚àíŒª
‚ä§
."
REFERENCES,0.6701846965699209,By setting this derivative to 0 we obtain
REFERENCES,0.6728232189973615,(g(x))m = ‚àí1
REFERENCES,0.6754617414248021,"Œª ¬∑ p(y = m | x),
‚àÄm = 1, . . . , M and ‚àÄx ‚ààX."
REFERENCES,0.6781002638522428,"Since g ‚àà‚àÜM‚àí1 is the M-dimensional simplex, we have PM
m=1(g‚àó‚àó(x))m = 1 and PM
m=1 p(y =
j | x) = 1. Then
M
X"
REFERENCES,0.6807387862796834,"m=1
(g‚àó‚àó(x))m = ‚àí1 Œª ¬∑ M
X"
REFERENCES,0.683377308707124,"m=1
p(y = m | x) = 1."
REFERENCES,0.6860158311345647,"Therefore we obtain Œª = ‚àí1 and (g‚àó‚àó(x))m = p(y = m | x) = (Œ∑(x))m, ‚àÄm = 1, . . . , M and
‚àÄx ‚ààX, which is equivalent to g‚àó‚àó(x) = ¬ØŒ∑(x). Similarly, we obtain"
REFERENCES,0.6886543535620053,"f ‚ãÜ(x) = Œ∑(x).
(11)"
REFERENCES,0.6912928759894459,"Given Proposition 3 and the assumption that the model used for g is sufficiently flexible, we obtain
that the classification model learned by FedUL (see Algorithm 1) satisfies g‚àó= g‚àó‚àó. By our model
construction, g is built from Qc(f). Then we have"
REFERENCES,0.6939313984168866,"f ‚àó= f ‚àó‚àó
(12)"
REFERENCES,0.6965699208443272,"where f ‚àó‚àó= argminf J(f) is the model induced by g‚àó‚àó. Given Theorem 1 and Lemma 2, we
obtain that g‚àó‚àó(x) = ¬ØŒ∑(x) if and only if"
REFERENCES,0.6992084432717678,"f ‚àó‚àó(x) = Œ∑(x).
(13)"
REFERENCES,0.7018469656992085,"By summarizing (11), (12), and (13) we obtain f ‚àó= f ‚ãÜ."
REFERENCES,0.7044854881266491,Published as a conference paper at ICLR 2022
REFERENCES,0.7071240105540897,"D
EXPERIMENTAL DETAILS"
REFERENCES,0.7097625329815304,"We illustrate our model architectures and training details of the benchmark and real-world experiments
in this section."
REFERENCES,0.712401055408971,"D.1
MODEL ARCHITECTURE"
REFERENCES,0.7150395778364116,"For our benchmark experiment on MNIST, we use a six-layer convolutional neural network. The
network details are listed in Table D.2. For our benchmark experiment on CIFAR10 and real-world
experiment, we use ResNet18 as our backbone. The network details are listed in Table D.3."
REFERENCES,0.7176781002638523,"Layer
Details
1
Conv2D(3, 64, 5, 1, 2), BN(64), ReLU, MaxPool2D(2, 2)
2
Conv2D(64, 64, 5, 1, 2), BN(64), ReLU, MaxPool2D(2, 2)
3
Conv2D(64, 128, 5, 1, 2), BN(128), ReLU
4
FC(6272, 2048), BN(2048), ReLU
5
FC(2048, 512), BN(512), ReLU
6
FC(512, 10)"
REFERENCES,0.7203166226912929,"Table D.2: Model architecture of the benchmark experiment on MNIST. For convolutional layer
(Conv2D), we list parameters with sequence of input and output dimension, kernel size, stride and
padding. For max pooling layer (MaxPool2D), we list kernel and stride. For fully connected layer
(FC), we list input and output dimension. For BatchNormalization layer (BN), we list the channel
dimension."
REFERENCES,0.7229551451187335,"D.2
TRAINING DETAILS"
REFERENCES,0.7255936675461742,"Benchmark Experiments:
We implement all the methods by PyTorch and conduct all the experi-
ments on an NVIDIA TITAN X GPU. Please note for all experiments, we split 20% original data
for validation and model selection. During training process, we use Adam optimizer with learning
rate 1e ‚àí4 and the cross-entropy loss. We set batch size to 128 and training rounds to 100. To avoid
overfitting, we use L1 regularization. The detailed weight of L1 regularization used in benchmark
experiments is shown in Table D.4. The detailed number of samples at each client for MNIST and
CIFAR10 under IID and Non-IID setting is given in Table D.5 and Table D.6, respectively."
REFERENCES,0.7282321899736148,We describe details of the baseline methods and corresponding hyper-parameters as follows.
REFERENCES,0.7308707124010554,"‚Ä¢ FedPL (Diao et al., 2021): this method is based on empirical classification risk minimization.
The learning objective is"
REFERENCES,0.7335092348284961,"bR(f) = 1 C C
X c=1 Mc
X"
REFERENCES,0.7361477572559367,"m=1
Lfix + ŒªLmix,
(14)"
REFERENCES,0.7387862796833773,"where
Lfix = ‚Ñì
 
f
 
x+
b

, y+
b

(15)"
REFERENCES,0.741424802110818,"is the ""fix"" loss. (x+
b , y+
b ) represents for a sample x+
b with high confidence pseudo label y+
b
and
Lmix = Œªmix ¬∑ ‚Ñì
 
f (xmix) , y+
b

+ (1 ‚àíŒªmix) ¬∑ ‚Ñì
 
f (xmix) , y‚àí
b

(16)"
REFERENCES,0.7440633245382586,"is the ""mix"" loss, in which"
REFERENCES,0.7467018469656992,"Œªmix ‚àºBeta(a, a),
xmix ‚ÜêŒªmixx+
b + (1 ‚àíŒªmix) x‚àí
b .
(17)"
REFERENCES,0.7493403693931399,"a is the mixup hyper-parameter and (x‚àí
b , y‚àí
b ) represents for a sample x‚àí
b with low confidence
pseudo label y‚àí
b . Following the default implementation in Diao et al. (2021), we set hyper-
parameter a = 0.75. Moreover, we set the weight of ""mix"" loss Œª = 0.3 and the confidence
threshold œÑ = 0.4."
REFERENCES,0.7519788918205804,Published as a conference paper at ICLR 2022
REFERENCES,0.7546174142480211,"Layer
Details
1
Conv2D(3, 64, 7, 2, 3), BN(64), ReLU
2
Conv2D(64, 64, 3, 1, 1), BN(64), ReLU
3
Conv2D(64, 64, 3, 1, 1), BN(64)
4
Conv2D(64, 64, 3, 1, 1), BN(64), ReLU
5
Conv2D(64, 64, 3, 1, 1), BN(64)
6
Conv2D(64, 128, 3, 2, 1), BN(128), ReLU
7
Conv2D(128, 128, 3, 1, 1), BN(64)
8
Conv2D(64, 128, 1, 2, 0), BN(128)
9
Conv2D(128, 128, 3, 1, 1), BN(128), ReLU
10
Conv2D(128, 128, 3, 1, 1), BN(64)
11
Conv2D(128, 256, 3, 2, 1), BN(128), ReLU
12
Conv2D(256, 256, 3, 1, 1), BN(64)
13
Conv2D(128, 256, 1, 2, 0), BN(128)
14
Conv2D(256, 256, 3, 1, 1), BN(128), ReLU
15
Conv2D(256, 256, 3, 1, 1), BN(64)
16
Conv2D(256, 512, 3, 2, 1), BN(512), ReLU
17
Conv2D(512, 512, 3, 1, 1), BN(512)
18
Conv2D(256, 512, 1, 2, 0), BN(512)
19
Conv2D(512, 512, 3, 1, 1), BN(512), ReLU
20
Conv2D(512, 512, 3, 1, 1), BN(512)
21
AvgPool2D
22
FC(512, 10)"
REFERENCES,0.7572559366754618,"Table D.3: Model architecture of the benchmark experiment on CIFAR10. For convolutional layer
(Conv2D), we list parameters with sequence of input and output dimension, kernel size, stride and
padding. For max pooling layer (MaxPool2D), we list kernel and stride. For fully connected layer
(FC), we list input and output dimension. For BatchNormalization layer (BN), we list the channel
dimension."
REFERENCES,0.7598944591029023,Table D.4: Detailed weight of L1 regularization used in benchmark experiments.
REFERENCES,0.762532981530343,"Dataset
MNIST
CIFAR10
Sets
10
20
30
10
20
30
Weight
1e-5
5e-5
2e-6
2e-5
1e-5
4e-6"
REFERENCES,0.7651715039577837,"‚Ä¢ FedLLP (Dulac-Arnold et al., 2019): this baseline method is based on empirical proportion
risk minimization. The learning objective is the aggregated proportion risk, i.e.,"
REFERENCES,0.7678100263852242,"bR(f) = 1 C C
X c=1 Mc
X"
REFERENCES,0.7704485488126649,"m=1
dprop (œÄm
c , bœÄm
c )
(18)"
REFERENCES,0.7730870712401056,"where œÄm
c and bœÄm
c are the true and predicted label proportions for the m-th U set Um
c at the
c-th client, bœÄm
c :=
1
Mc
P"
REFERENCES,0.7757255936675461,"x‚àºUm
c f(x). For each client c, dprop is defined as"
REFERENCES,0.7783641160949868,"dprop(œÄm
c , bœÄm
c ) := ‚àí K
X"
REFERENCES,0.7810026385224275,"k=1
œÄm
c log bœÄm
c ."
REFERENCES,0.783641160949868,"‚Ä¢ FedLLP-VAT (Tsai & Lin, 2020): this method is based on empirical proportion risk mini-
mization, integrated with a consistency regularization term. The learning objective is the"
REFERENCES,0.7862796833773087,Published as a conference paper at ICLR 2022
REFERENCES,0.7889182058047494,Table D.5: Detailed number of samples at each client for MNIST benchmark
REFERENCES,0.7915567282321899,"Class
0
1
2
3
4
5
6
7
8
9 IID"
REFERENCES,0.7941952506596306,"Client1
920
1098
970
972
945
893
898
1007
971
926
Client2
920
1098
970
972
945
893
898
1007
971
926
Client3
920
1098
970
972
945
893
898
1007
971
926
Client4
920
1098
970
972
945
893
898
1007
971
926
Client5
920
1098
970
972
945
893
898
1007
971
926"
REFERENCES,0.7968337730870713,Non-IID
REFERENCES,0.7994722955145118,"Client1
4498
4646
56
56
54
57
54
60
60
54
Client2
57
54
4425
4737
49
50
49
58
57
58
Client3
64
61
57
61
4316
4217
54
53
58
57
Client4
53
58
55
35
50
0
4572
4576
60
57
Client5
57
58
61
0
60
0
19
54
4418
4576"
REFERENCES,0.8021108179419525,Table D.6: Detailed number of samples at each client for CIFAR10 benchmark
REFERENCES,0.8047493403693932,"Class
airplane
automobile
bird
cat
deer
dog
frog
horse
ship
truck IID"
REFERENCES,0.8073878627968337,"Client1
755
788
794
796
791
842
827
788
820
799
Client2
755
788
794
796
791
842
827
788
820
799
Client3
755
788
794
796
791
842
827
788
820
799
Client4
755
788
794
796
791
842
827
788
820
799
Client5
755
788
794
796
791
842
827
788
820
799"
REFERENCES,0.8100263852242744,Non-IID
REFERENCES,0.8126649076517151,"Client1
3748
3872
47
46
45
47
45
50
50
45
Client2
48
45
3688
3938
41
41
41
48
48
48
Client3
53
51
48
0
3597
3887
45
53
48
47
Client4
44
18
46
0
42
0
3810
3813
50
48
Client5
47
0
51
0
50
0
46
45
3788
3790"
REFERENCES,0.8153034300791556,"aggregated proportion risk with consistency regularization, i.e.,"
REFERENCES,0.8179419525065963,"bR(f) = 1 C C
X c=1 Mc
X"
REFERENCES,0.820580474934037,"m=1
dprop (œÄm
c , bœÄm
c ) + Œ±‚Ñìcons (f) !"
REFERENCES,0.8232189973614775,",
(19)"
REFERENCES,0.8258575197889182,"where œÄm
c and bœÄm
c are the true and predicted label proportions for the m-th U set Um
c at the
c-th client, and dprop is a distance function."
REFERENCES,0.8284960422163589,"‚Ñìcons (f) = dcons (f(x), f(bx))
(20)"
REFERENCES,0.8311345646437994,"is the consistency loss, where dcons is a distance function, and bx is a perturbed input from
the original x. Following the default implementation in their paper (Tsai & Lin, 2020), we
set the hyper-parameter, the weight of consistency loss Œ± = 0.05 and the perturbation weight
¬µ = 6.0 for FedLLP-VAT on CIFAR10 benchmark experiment. For MNIST benchmark,
we set the hyper-parameter, the weight of consistency loss Œ± = 5e ‚àí4 and the perturbation
weight ¬µ = 1e ‚àí2."
REFERENCES,0.8337730870712401,"Real-world Experiments:
We perform a case study on the clinical task ‚Äî intracranial hemorrhage
diagnosis. We use the RSNA Intracranial Hemorrhage Detection dataset (Flanders et al., 2020)
(Figure 4), which contains large-scale Magnetic Response Image (MRI) data from several hospi-
tals.There are 106k samples in the dataset belonging to six classes, including five types of intracranial
hemorrhage (Epidural, Intraparenchymal, Intraventricular, Subarachnoid, and Subdural) and healthy
control type. In our experiments, we simulate a real-world scenario with five healthcare systems
(a.k.a. clients) and assume the number of hospitals (a.k.a sets) in each healthcare systems varies
M = 12, 24, and 48. At first, we randomly split the whole dataset for five healthcare systems equally,
so each healthcare systems is assigned 21.2k samples. Then we generate œÄm
c for m-th set in c-th
client from range [0.1, 0.9] for all the hospitals with U data only. We check that the generated class
priors are not all identical. Finally, we load samples for each the hospitals following the generated œÄ.
Detailed dataset statistics is given in Table D.7."
REFERENCES,0.8364116094986808,"During training process, we use Adam optimizer with learning rate 1e ‚àí4 and cross-entropy loss. We
set batch size to 128 and training rounds to 100. To avoid overfitting, we use L1 regularization. We"
REFERENCES,0.8390501319261213,Published as a conference paper at ICLR 2022
REFERENCES,0.841688654353562,"Table D.7: Detailed number of samples in each healthcare system (HS) for real-world RSNA
Intracranial Hemorrhage Detection dataset (Flanders et al., 2020)."
REFERENCES,0.8443271767810027,"Type
Healthy
Epidural
Intraparenchymal
Intraventricular
Subarachnoid
Subdural
HS 1
3726
221
2023
1198
2027
4005
HS 2
3756
226
1923
1190
2063
4042
HS 3
3804
177
1932
1266
2040
3981
HS 4
3805
224
1939
1187
2074
3971
HS 5
3711
198
1929
1299
2080
3983"
REFERENCES,0.8469656992084432,"set the weight of L1 regularization as 2e ‚àí6, 8e ‚àí7 and 4e ‚àí7 for 10, 20 and 40 sets, respectively.
In real-world experiments, we use the same hyper-parameters as benchmark experiments for all
methods except FedLLP-VAT. For FedLLP-VAT, we set the weight of consistency loss Œ± = 0.05 and
the perturbation weight ¬µ = 6.0."
REFERENCES,0.8496042216358839,"Training Efficiency:
We further evaluate the training efficiency of our method with comparison
to baseline methods. The detailed one epoch training time (mean) and forward FLOPs are given
in Table D.8. The computation time is evaluated on a PC with one Nvidia TITAN X GPU. We can
see that our method slightly increase the forward FLOPs and can achieve higher training efficiency
compared with FedPL and FedLLP-VAT."
REFERENCES,0.8522427440633246,"Table D.8: Quantitative comparison of our method with the baseline methods training epoch time and
forward flops on benchmark and real-world datasets under Non-IID and IID setting."
REFERENCES,0.8548812664907651,"Dataset
Method
Non-IID Task with 5 Clients
IID Task with 5 Clients
Computation time (s)
FLOPs (G)
Computation time (s)
FLOPs (G) MNIST"
REFERENCES,0.8575197889182058,"FedPL
3.29"
REFERENCES,0.8601583113456465,0.048125312 4.78
FEDLLP,0.862796833773087,"0.048125312
FedLLP
1.67
2.45
FedLLP-VAT
2.10
2.87
FedUL
1.80
0.048125422
2.35
0.048125422"
FEDLLP,0.8654353562005277,CIFAR10
FEDLLP,0.8680738786279684,"FedPL
3.37"
FEDLLP,0.8707124010554089,0.141595648 5.70
FEDLLP,0.8733509234828496,"0.141595648
FedLLP
1.95
2.44
FedLLP-VAT
3.43
4.86
FedUL
2.63
0.141595758
3.80
0.141595758"
FEDLLP,0.8759894459102903,"Real-world
FedPL
32.47
6.937938944
-
-
FedUL
32.34
6.937939028
-
-"
FEDLLP,0.8786279683377308,Published as a conference paper at ICLR 2022
FEDLLP,0.8812664907651715,"E
MORE EXPERIMENTAL RESULTS ON THE BENCHMARK DATASETS"
FEDLLP,0.8839050131926122,"E.1
DETAILED STATISTICS OF FIGURE 3(A)"
FEDLLP,0.8865435356200527,"We show detailed statistics of Figure 3(a) in Table E.9. With different noisy class priors, even with
challenging œµ = 0.8 and œµ = 1.6, our method still achieves low error rate, which verify the robustness
and effectiveness of our method."
FEDLLP,0.8891820580474934,"Table E.9: Inaccurate class priors experiments with different noise ratio œµ on MNIST under Non-IID
setting with 5 clients and 10 sets for every client (mean error (std))."
FEDLLP,0.8918205804749341,"œµ = 0 (Clean)
œµ = 0.2
œµ = 0.4
œµ = 0.8
œµ = 1.6
2.98 (1.72)
3.02 (1.30)
3.10 (0.96)
3.02 (1.36)
3.49 (1.74)"
FEDLLP,0.8944591029023746,"E.2
DETAILED STATISTICS OF FIGURE 3(B)"
FEDLLP,0.8970976253298153,"We show detailed statistics of Figure 3(b) in Table E.10. With more Non-IID data, our method
performs better, which validates that more unlabeled Non-IID data can be helpful for FL."
FEDLLP,0.899736147757256,Table E.10: Experiments on accessible data amount under the Non-IID setting (mean error (std)).
K,0.9023746701846965,"5k
10k
15k
20k
25k
3.56 (0.09)
2.62 (0.07)
1.97 (0.38)
1.75 (0.11)
1.72 (0.13)"
K,0.9050131926121372,"E.3
DIFFERENT COMBINATIONS OF E AND B"
K,0.9076517150395779,"We compare our method with different combinations of E and B on benchmark dataset MNIST in
the Non-IID setting. The classification error rate (mean and std) is consistently small as presented (cf.
Table E.11), which indicates our method can work under a wide range combinations of E and B."
K,0.9102902374670184,"Table E.11: Experiments using different combinations of training batch size B and local update epoch
E on benchmark dataset MNIST in the Non-IID setting (mean error (std))."
K,0.9129287598944591,"E
1
4
16
B
16
128
‚àû
16
128
‚àû
16
128
‚àû"
K,0.9155672823218998,"Error
7.99
(9.83)"
K,0.9182058047493403,"2,93
(1.20)"
K,0.920844327176781,"3.69
(0.88)"
K,0.9234828496042217,"2.54
(1.09)"
K,0.9261213720316622,"4.16
(3.44)"
K,0.9287598944591029,"2.81
(0.37)"
K,0.9313984168865436,"2.92
(1.12)"
K,0.9340369393139841,"3.51
(1.88)"
K,0.9366754617414248,"2.88
(1.06)"
K,0.9393139841688655,"E.4
BENCHMARK EXPERIMENTS ON CLIENTS WITH DIFFERENT SETS"
K,0.941952506596306,"Here we conduct experiments on benchmark datasets under IID and Non-IID setting with 5 clients
and different sets for each client (10, 20, 30, 40, 50). The experimental results are shown in Table
E.12, which further indicates the effectiveness of our method even under this challenging setting."
K,0.9445910290237467,"E.5
BENCHMARK EXPERIMENTS WITH MORE CLIENTS"
K,0.9472295514511874,"To study the influence of the number of clients, here we further conduct benchmark experiments
on both MNIST and CIFAR10 with 10 clients. The detailed results are shown in Table E.13. The
observations are similar to Table 1."
K,0.9498680738786279,Published as a conference paper at ICLR 2022
K,0.9525065963060686,"Table E.12: Quantitative comparison of our method with the baseline methods on benchmark datasets
under Non-IID and IID setting (mean error (std)) with different sets for each client. The best method
(paired t-test at significance level 5%) is highlighted in boldface."
K,0.9551451187335093,IID Task with 5 Clients
K,0.9577836411609498,"Dataset
FedPL
FedLLP
FedLLP-VAT
FedUL
FedAvg 10%
MNIST
3.74 (0.78)
5.22 (5.38)
2.24 (0.05)
1.19 (0.11)
2.21 (0.07)
CIFAR10
45.49 (2.74)
84.16 (0.71)
86.01 (2.54)
31.17 (2.80)
42.27 (1.06)
Non-IID Task with 5 Clients"
K,0.9604221635883905,"Dataset
FedPL
FedLLP
FedLLP-VAT
FedUL
FedAvg 10%
MNIST
12.03 (2.89)
4.26 (3.20)
3.88 (2.89)
2.31 (1.14)
3.42 (0.20)
CIFAR10
59.06 (3.73)
62.44 (16.99)
59.72 (18.73)
35.46 (1.40)
53.13 (0.22)"
K,0.9630606860158312,"Table E.13: Quantitative comparison of our method with the baseline methods on benchmark datasets
under Non-IID and IID setting (mean error (std)). The best method (paired t-test at significance level
5%) is highlighted in boldface."
K,0.9656992084432717,IID Task with 10 Clients
K,0.9683377308707124,"Dataset
Sets
FedPL
FedLLP
FedLLP-VAT
FedUL
FedAvg 10% MNIST"
K,0.9709762532981531,"10
2.19 (0.04)
10.11 (7.12)
25.83 (22.64)
0.74 (0.14)"
K,0.9736147757255936,"1.58 (0.23)
20
2.55 (0.30)
24.23 (17.52)
28.40 (23.20)
1.05 (0.05)
40
3.13 (0.25)
32.53 (16.93)
34.46 (15.46)
1.47 (0.11)"
K,0.9762532981530343,CIFAR10
K,0.978891820580475,"10
40.47 (0.58)
76.23 (1.47)
76.25 (1.65)
20.40 (0.63)"
K,0.9815303430079155,"33.57 (1.03)
20
46.44 (0.71)
78.10 (3.58)
76.26 (3.83)
21.61 (0.23)
40
51.58 (1.18)
79.10 (2.34)
80.44 (1.60)
22.71 (0.17)
Non-IID Task with 10 Clients"
K,0.9841688654353562,"Dataset
Sets
FedPL
FedLLP
FedLLP-VAT
FedUL
FedAvg 10% MNIST"
K,0.9868073878627969,"10
12.24 (1.36)
20.81 (14.72)
17.26 (10.39)
1.91 (0.16)"
K,0.9894459102902374,"3.03 (0.24)
20
5.73 (0.89)
17.67 (11.48)
18.45 (4.30)
1.45 (0.27)
40
4.16 (0.56)
14.98 (10.11)
13.62 (5.47)
1.27 (0.12)"
K,0.9920844327176781,CIFAR10
K,0.9947229551451188,"10
68.53 (1.14)
84.11 (2.63)
82.17 (2.58)
39.20 (0.79)"
K,0.9973614775725593,"52.48 (1.55)
20
61.49 (1.42)
71.69 (7.59)
72.34 (7.39)
34.12 (0.57)
40
55.89 (2.19)
58.21 (4.95)
59.42 (9.59)
32.21 (1.02)"
