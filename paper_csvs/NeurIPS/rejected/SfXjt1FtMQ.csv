Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0024813895781637717,"This paper introduces the Gaussian multi-Graphical Model, a model to construct
1"
ABSTRACT,0.004962779156327543,"sparse graph representations of matrix- and tensor-variate data. We generalize
2"
ABSTRACT,0.007444168734491315,"prior work in this area by simultaneously learning this representation across several
3"
ABSTRACT,0.009925558312655087,"tensors that share axes, which is necessary to allow the analysis of multimodal
4"
ABSTRACT,0.01240694789081886,"datasets such as those encountered in multi-omics. Our algorithm uses only a
5"
ABSTRACT,0.01488833746898263,"single eigendecomposition per axis, achieving an order of magnitude speedup over
6"
ABSTRACT,0.017369727047146403,"prior work in the ungeneralized case. This allows the use of our methodology
7"
ABSTRACT,0.019851116625310174,"on large multi-modal datasets such as single-cell multi-omics data, which was
8"
ABSTRACT,0.022332506203473945,"challenging with previous approaches. We validate our model on synthetic data
9"
ABSTRACT,0.02481389578163772,"and five real-world datasets.
10"
INTRODUCTION,0.02729528535980149,"1
Introduction
11"
INTRODUCTION,0.02977667493796526,"A number of modern applications require the estimation of networks (graphs) exploring the de-
12"
INTRODUCTION,0.03225806451612903,"pendency structures underlying the data. In this paper, we propose a new approach for estimating
13"
INTRODUCTION,0.034739454094292806,"conditional dependency graphs. Two datapoints x, y are conditionally independent (with respect to
14"
INTRODUCTION,0.03722084367245657,"a dataset D) if knowing one provides no information about the other that is not already contained
15"
INTRODUCTION,0.03970223325062035,"in the rest of the dataset: P(x|y, D\xy) = P(x|D\xy). For normally distributed data, conditional
16"
INTRODUCTION,0.04218362282878412,"dependencies are encoded in the inverse of the covariance matrix (the ‘precision’ matrix). Two
17"
INTRODUCTION,0.04466501240694789,"datapoints are conditionally dependent on each other if and only if their corresponding element in the
18"
INTRODUCTION,0.04714640198511166,"precision matrix is not zero. If our dataset were in the form of a vector d, we could then model it as
19"
INTRODUCTION,0.04962779156327544,"d ∼N(0, Ψ−1) for precision matrix Ψ. This is a Gaussian Graphical Model (GGM); Ψ encodes
20"
INTRODUCTION,0.052109181141439205,"the graph.
21"
INTRODUCTION,0.05459057071960298,"However, datasets are often more structured than vectors. For example, single-cell RNA sequencing
22"
INTRODUCTION,0.05707196029776675,"datasets (scRNA-seq) come in the form of a matrix of gene expression counts whose rows are cells
23"
INTRODUCTION,0.05955334987593052,"and columns are genes. Video data naturally requires a third-order tensor of pixels to represent
24"
INTRODUCTION,0.062034739454094295,"it - rows, columns, and frames. Furthermore multi-omics datasets such as those including both
25"
INTRODUCTION,0.06451612903225806,"scRNA-seq and scATAC-seq may require two or more matrices to be properly represented; one for
26"
INTRODUCTION,0.06699751861042183,"each modality.
27"
INTRODUCTION,0.06947890818858561,"We could assume that each row of our matrix is an i.i.d. sample drawn from our model. However,
28"
INTRODUCTION,0.07196029776674938,"independence is a strong and often incorrect assumption. If we wanted to make no independence
29"
INTRODUCTION,0.07444168734491315,"assumptions, we could vectorize the dataset D and estimate Ψ in vec[D] ∼N(0, Ψ−1). However,
30"
INTRODUCTION,0.07692307692307693,"this produces intractably large Ψ, whose number of elements is quadratic in the product of the lengths
31"
INTRODUCTION,0.0794044665012407,"of our dataset’s axes.
32"
INTRODUCTION,0.08188585607940446,"Thankfully, tensors are highly structured, and we are often interested in the dependency structure
33"
INTRODUCTION,0.08436724565756824,"of each axis individually - i.e. the dependencies between samples or the dependencies between
34"
INTRODUCTION,0.08684863523573201,"features - rather than the dependencies between the elements of the tensor themselves. To model this,
35"
INTRODUCTION,0.08933002481389578,"we can represent Ψ as some deterministic combination of the axis-wise dependencies: vec[D] ∼
36"
INTRODUCTION,0.09181141439205956,"Species
Metabolites"
INTRODUCTION,0.09429280397022333,People
INTRODUCTION,0.0967741935483871,People
INTRODUCTION,0.09925558312655088,Metagenomics
INTRODUCTION,0.10173697270471464,Metabolomics
INTRODUCTION,0.10421836228287841,"Figure 1: The two matrices of the LifeLines-DEEP dataset. As both matrices include data for the
same people, the learned graph between people should be the same."
INTRODUCTION,0.10669975186104218,"N(0, ζ(Ψrow, Ψcol)−1), for some function ζ. The strategy is to estimate Ψrow, Ψcol directly, without
37"
INTRODUCTION,0.10918114143920596,"computing the intractable ζ(Ψrow, Ψcol)−1. While there are multiple choices for ζ, this paper
38"
INTRODUCTION,0.11166253101736973,"considers only the Kronecker sum.
39"
PRIOR WORK,0.1141439205955335,"1.1
Prior work
40"
PRIOR WORK,0.11662531017369727,"The Kronecker sum BiGraphical Lasso (BiGLasso) model was first considered by Kalaitzis et al.
41"
PRIOR WORK,0.11910669975186104,"[14]. BiGLasso is the multi-axis analog to graphical lasso methods [10], which are used to estimate
42"
PRIOR WORK,0.12158808933002481,"covariance matrices of data drawn from a multivariate Gaussian distribution. The Kronecker sum
43"
PRIOR WORK,0.12406947890818859,"of two matrices, A ⊕B, can be expressed in terms of Kronecker products: A ⊗I + I ⊗B. When
44"
PRIOR WORK,0.12655086848635236,"the matrices A, B are adjacency matrices of graphs, the Kronecker sum has the interpretation as
45"
PRIOR WORK,0.12903225806451613,"the Cartesian product of those graphs. This sum is one choice ζ to combine the per-axis precision
46"
PRIOR WORK,0.1315136476426799,"matrices into the precision matrix of the vectorized dataset, vec[D] ∼N(0, (Ψrow ⊕Ψcol)−1).
47"
PRIOR WORK,0.13399503722084366,"Other choices for ζ have been considered, such as using the Kronecker product [23, 8], or the square
48"
PRIOR WORK,0.13647642679900746,"of the Kronecker sum [24, 25]. Each method has its strengths; the benefits of a Kronecker sum
49"
PRIOR WORK,0.13895781637717122,"structure are its interpretability as a graph product, stronger sparsity, and its allowance of inter-task
50"
PRIOR WORK,0.141439205955335,"transfer [14].
51"
PRIOR WORK,0.14392059553349876,"The original BiGLasso model was very slow to converge to a solution, in large part due to its non-
52"
PRIOR WORK,0.14640198511166252,"optimal space complexity of O(n2p2). This prohibited its use on large datasets (measuring in a
53"
PRIOR WORK,0.1488833746898263,"couple hundred samples and/or features). Numerous modifications have been made to the algorithm
54"
PRIOR WORK,0.1513647642679901,"to improve its speed and achieve an optimal space complexity of O(n2 + p2), such as scBiGLasso
55"
PRIOR WORK,0.15384615384615385,"[17], TeraLasso [12], and EiGLasso [27]. Of these, TeraLasso is notable in that it generalizes to an
56"
PRIOR WORK,0.15632754342431762,"arbitrary number of axes, i.e. ζ(Ψ1, ..., Ψk) = Ψ1 ⊕... ⊕Ψk. TeraLasso and EiGLasso, the fastest
57"
PRIOR WORK,0.1588089330024814,"prior work, both rely on computing an eigendecomposition every iteration.
58"
PRIOR WORK,0.16129032258064516,"All of these algorithms and models, including our own, rely on a normality assumption. We are most
59"
PRIOR WORK,0.16377171215880892,"interested in the case of omics data, in which case a log-transform renders our dataset sufficiently
60"
PRIOR WORK,0.1662531017369727,"Gaussian-like for our algorithm to achieve good performance. An overview of the use of GGMs in
61"
PRIOR WORK,0.1687344913151365,"omics data is given by Altenbuchinger et al. [2].
62"
UNMET NEED,0.17121588089330025,"1.2
Unmet need
63"
UNMET NEED,0.17369727047146402,"Many datasets, especially those in multi-omics, are representable as a collection of matrices or tensors.
64"
UNMET NEED,0.1761786600496278,"As a case study, we consider (a subset of) the Lifelines-DEEP dataset from Tigchelaar et al. [22],
65"
UNMET NEED,0.17866004962779156,"which is summarized graphically in Figure 1.
66"
UNMET NEED,0.18114143920595532,"In this dataset, two different modalities of data were gathered from the same people: counts of
67"
UNMET NEED,0.18362282878411912,"microbial species found in their stools (metagenomics) and counts of metabolites found in their
68"
UNMET NEED,0.18610421836228289,"blood plasma (metabolomics). While different matrices, each modality shares an axis. If we were to
69"
UNMET NEED,0.18858560794044665,"estimate a graph of people on each modality independently, they would likely yield different graphs.
70"
UNMET NEED,0.19106699751861042,"This is not ideal; if our aim is to estimate the true graph of conditional dependencies, there should be
71"
UNMET NEED,0.1935483870967742,"only one resultant graph. To estimate it, we should be considering both modalities simultaneously.
72"
UNMET NEED,0.19602977667493796,"Species
Metabolites"
UNMET NEED,0.19851116625310175,People
UNMET NEED,0.20099255583126552,People
UNMET NEED,0.20347394540942929,Metagenomics
UNMET NEED,0.20595533498759305,Metabolomics
UNMET NEED,0.20843672456575682,Elements
UNMET NEED,0.2109181141439206,Structure
UNMET NEED,0.21339950372208435,Metabolites
UNMET NEED,0.21588089330024815,Cells from
UNMET NEED,0.21836228287841192,Patient 1 Genes
UNMET NEED,0.22084367245657568,Transcriptomics Genes
UNMET NEED,0.22332506203473945,Transcriptomics (A) (B)
UNMET NEED,0.22580645161290322,"Cells from
 Patient N"
UNMET NEED,0.228287841191067,"Figure 2: (A) A hypothetical dataset whose structure cannot be reduced to a single tensor by
concatenation. Concatenating would lead to a block of missing values for a hypothetical (and
nonsensical) species by elements matrix. (B) A hypothetical single-cell RNA-sequencing dataset
procured from multiple patients. Concatenation is possible, but would lead to a very large output
graph for a modest number of patients."
UNMET NEED,0.23076923076923078,"One way to do this would be to concatenate the modalities, producing a matrix of people by
73"
UNMET NEED,0.23325062034739455,"""species+metabolites"". This could yield interesting results, if one is interested in connections between
74"
UNMET NEED,0.23573200992555832,"individual species and a metabolite. However, it would increase the size of the output graph, which
75"
UNMET NEED,0.23821339950372208,"grows quadratically in the length of the axis. Furthermore, it is not always possible or feasible; some
76"
UNMET NEED,0.24069478908188585,"datasets may not be concatenatable. We visually demonstrate some cases where concatenation fails
77"
UNMET NEED,0.24317617866004962,"in Figure 2.
78"
OUR CONTRIBUTIONS,0.2456575682382134,"1.3
Our contributions
79"
OUR CONTRIBUTIONS,0.24813895781637718,"We introduce a novel method to extend the use of Gaussian Graphical Models to multi-tensor datasets.
80"
OUR CONTRIBUTIONS,0.2506203473945409,"This extension is essential to model conditional dependencies in multimodal datasets such as those
81"
OUR CONTRIBUTIONS,0.2531017369727047,"frequently occurring in multi-omics. We present an efficient algorithm to estimate these conditional
82"
OUR CONTRIBUTIONS,0.2555831265508685,"dependencies. When restricted to the single-tensor case, our algorithm is much faster than previous
83"
OUR CONTRIBUTIONS,0.25806451612903225,"algorithms that estimated conditional dependency graphs for each axis, such as TeraLasso[12] and
84"
OUR CONTRIBUTIONS,0.26054590570719605,"EiGLasso[27].
85"
METHODS,0.2630272952853598,"2
Methods
86"
NOTATION,0.2655086848635236,"2.1
Notation
87"
NOTATION,0.2679900744416873,"In prior work, a single-tensor dataset D is modelled as vec [D] ∼N

0, (L"
NOTATION,0.2704714640198511,"ℓΨℓ)−1
, also written
88"
NOTATION,0.2729528535980149,"as D ∼NKS ({Ψℓ}ℓ).
89"
NOTATION,0.27543424317617865,"Our model considers multiple tensors, each with their own (potentially shared) axes. We aim to
90"
NOTATION,0.27791563275434245,"estimate the precision matrices Ψℓfor each axis ℓof each tensor Dγ, indexed by γ ∈N. To describe
91"
NOTATION,0.2803970223325062,"that an axis ℓis one of the axes of a tensor Dγ, we will write ℓ∈γ. Some values will be indexed
92"
NOTATION,0.28287841191067,"by both an axis and a tensor; for consistency we will use subscripts to denote axes (typically ℓ) and
93"
NOTATION,0.2853598014888337,"superscripts to denote tensors (typically γ). dγ
∀will represent the number of elements in Dγ, and
94 d∀= P"
NOTATION,0.2878411910669975,"γ dγ
∀.
95"
NOTATION,0.2903225806451613,"An important concept is the Gram matrix Sγ
ℓ. In the single-tensor case, this is a sufficient statistic; all
96"
NOTATION,0.29280397022332505,"prior work first computes these matrices as the first step in their algorithm. Let matℓ[Dγ] represent
97"
NOTATION,0.29528535980148884,"the ""matricization"" of Dγ along axis ℓ, then Sγ
ℓ= matℓ[Dγ] matℓ[Dγ]T . The matricization of a
98"
NOTATION,0.2977667493796526,"tensor picks one axis, ℓ, to index the rows, and flattens the rest out into columns. Note that for
99"
NOTATION,0.3002481389578164,"a matrix M, matcolumns [M] = MT . Rather than Sγ
ℓ, we consider the ""effective Gram matrices""
100 Sℓ= P"
NOTATION,0.3027295285359802,"γ|ℓ∈γ Sγ
ℓ, as these fulfill the role of the Gram matrices in the multi-tensor case.
101"
THE MODEL,0.3052109181141439,"2.2
The model
102"
THE MODEL,0.3076923076923077,"To properly handle sets of tensors, we propose modelling each tensor as being drawn independently
103"
THE MODEL,0.31017369727047145,"from a Kronecker-sum normal distribution. If the tensors share an axis ℓ, then they will still be drawn
104"
THE MODEL,0.31265508684863524,"independently - but their distributions will be parameterized by the same Ψℓ. For an arbitrary set of
105"
THE MODEL,0.315136476426799,"tensors, the model is:
106"
THE MODEL,0.3176178660049628,"Dγ ∼NKS

{Ψℓ}ℓ∈γ
"
THE MODEL,0.3200992555831266,for Dγ ∈{Dγ}γ
THE MODEL,0.3225806451612903,"We call this model the ""Gaussian multi-Graphical Model"" (GmGM) as it extends Gaussian Graphical
107"
THE MODEL,0.3250620347394541,"Models to estimate multiple graphs from a set of tensors. In this paper, we will make the assumption
108"
THE MODEL,0.32754342431761785,"that no tensor in our set contains the same axis twice - notably, covariance matrices would violate
109"
THE MODEL,0.33002481389578164,"this assumption. Any tensor with a repeated axis would naturally be interpretable as a graph - such
110"
THE MODEL,0.3325062034739454,"datasets are rare, and if one already has a graph the need for an algorithm such as this is diminished.
111"
THE MODEL,0.3349875930521092,"As an example, we model the LifeLines-DEEP dataset Dmetagenomics and Dmetabolomics indepen-
112"
THE MODEL,0.337468982630273,"dently as:
113"
THE MODEL,0.3399503722084367,"Dmetagenomics ∼NKS (Ψpeople, Ψspecies)"
THE MODEL,0.3424317617866005,"Dmetabolomics ∼NKS (Ψpeople, Ψmetabolites)"
THE ALGORITHM,0.34491315136476425,"2.3
The algorithm
114"
THE ALGORITHM,0.34739454094292804,"Here, we present an algorithm to compute the maximum likelihood estimate (MLE) jointly for all
115"
THE ALGORITHM,0.34987593052109184,"parameters Ψℓof the GmGM. The general idea is to produce an analytic estimate for the eigenvectors
116"
THE ALGORITHM,0.3523573200992556,"of Ψℓ, and then iterate to solve for the eigenvalues; this is summed up graphically in Figure 3.
117"
THE ALGORITHM,0.3548387096774194,"In the supplementary material, we derive the following:
118"
THE ALGORITHM,0.3573200992555831,p({Dγ}) = Q γ rL
THE ALGORITHM,0.3598014888337469,ℓ∈γ Ψℓ (2π) d∀
E,0.36228287841191065,"2
e
−1"
P,0.36476426799007444,"2
P"
P,0.36724565756823824,"ℓtr[ΨℓSℓ]
(pdf of GmGM)"
P,0.369727047146402,"NLL [{Dγ}] ∝
X"
P,0.37220843672456577,"ℓ
tr [ΨℓSℓ] −
X γ
log  M"
P,0.3746898263027295,"ℓ∈γ
Ψℓ"
P,0.3771712158808933,(negative log likelihood)
P,0.37965260545905705,"From this, we can observe that the effective Gram matrices Sℓform a set of sufficient statistics for
119"
P,0.38213399503722084,"our distribution. Furthermore, the log-likelihood is the sum of log-likelihoods in the single-axis case,
120"
P,0.38461538461538464,"thus preserving convexity of the loss function.
121"
P,0.3870967741935484,"Theorem 1. Let VℓeℓVT
ℓbe the eigendecomposition of Sℓ(where Vℓ∈Rdℓ×dℓand eℓ∈Rdℓ×dℓ
122"
P,0.38957816377171217,"is a diagonal matrix). Then Vℓare the eigenvectors of the maximum likelihood estimate of Ψℓ.
123"
P,0.3920595533498759,"Theorem 1 is critical to allowing efficient estimation of Ψℓ, as it not only allows us to extract the
124"
P,0.3945409429280397,"computationally intensive eigendecomposition operation from the iterative portion of the algorithm,
125"
P,0.3970223325062035,"but also reduces the number of parameters to be linear in the length of an axis.
126"
P,0.39950372208436724,"To find the eigenvalues Λℓof Ψℓ, we produce the second theorem:
127 T
T"
P,0.40198511166253104,Theorem 1
P,0.4044665012406948,Compute Gram
P,0.40694789081885857,Matrices
P,0.4094292803970223,"Eigendecompose
Eigen-recompose"
P,0.4119106699751861,Threshold
P,0.4143920595533499,Theorem 2: Iterate until Convergence
P,0.41687344913151364,"For each dataset , compute intermediate values"
P,0.41935483870967744,And use this to update our estimate of the eigenvalues
P,0.4218362282878412,"Figure 3: A graphical overview of how the GmGM algorithm works. We use γ to represent an
arbitrary modality, and ℓto represent an arbitrary axis. Proofs are given in the supplementary
material."
P,0.42431761786600497,"Theorem 2. Let {Gγ
ℓ} be matrices such that the expression L"
P,0.4267990074441687,"ℓ∈γ Gγ
ℓis the best Frobenius-norm
128"
P,0.4292803970223325,"approximation of
L"
P,0.4317617866004963,"ℓ∈γ Λt
ℓ
−1
. Then, for a learning rate µt, gradient descent can be performed
129"
P,0.43424317617866004,"with the update equation Λt+1
ℓ
= Λt
ℓ−µt
h
eℓ−P
γ|ℓ∈γ Gγ
ℓ
i
. As Ψℓis positive definite, µt must
130"
P,0.43672456575682383,"be chosen to prevent Λt
ℓfrom becoming negative.
131"
P,0.4392059553349876,"While the definition of Gγ
ℓis technical, it is analogous to the notion of the blockwise-trace from
132"
P,0.44168734491315137,"Kalaitzis et al. [14] and projK from Greenewald, Zhou, and Hero III [12]. Proofs of Theorems 1
133"
P,0.4441687344913151,"and 2, along with a method to compute Gγ
ℓ, are given in the supplementary material. Overall, our
134"
P,0.4466501240694789,"algorithm is described in the pseudocode at the top of the next page.
135"
P,0.4491315136476427,"For regularization, one can choose to either keep the top p% of edges, or keep the top k edges per
136"
P,0.45161290322580644,"vertex (for parameters p, k). The incorporation of more advanced regularizers, such as Lasso, would
137"
P,0.45409429280397023,"require an eigen-recomposition on each iteration, which would be much slower. As we demonstrate
138"
P,0.456575682382134,"empirically in Section 3, it is not necessary to use advanced regularizers to recover the graph structure
139"
P,0.45905707196029777,"to the same precision as prior work.
140"
P,0.46153846153846156,"The GmGM algorithm
Input: {Dγ
i }, tolerance
Output: {Ψℓ}"
P,0.4640198511166253,"1: for 1 ≤ℓ≤K
2:
Sℓ←P"
P,0.4665012406947891,"γ|ℓ∈γ
1
nγ
Pnγ"
P,0.46898263027295284,"i
matℓ[Dγ
i ] matℓ[Dγ
i ]T"
P,0.47146401985111663,"3:
Vℓ←eigenvectors[Sℓ]
4:
eℓ←eigenvalues[Sℓ]
5: end for
6: Λ ←[1
...
1]T"
P,0.4739454094292804,"7: µ ←1
8: while not converged
9:
for 1 ≤ℓ≤K"
P,0.47642679900744417,"10:
Gγ
ℓ←projKS L"
P,0.47890818858560796,"ℓ′∈γ Λℓ
−1"
P,0.4813895781637717,"11:
Λ′
ℓ←Λℓ−µ
h
eℓ−P"
P,0.4838709677419355,"γ|ℓ∈γ Gγ
ℓ
i"
P,0.48635235732009924,"12:
end for
13:
for 1 ≤ℓ≤K
14:
Λℓ←Λ′
ℓ
15:
end for
16:
for γ
17:
if P"
P,0.48883374689826303,"ℓ∈γ minΛℓ< tolerance then
18:
decrease µ so that this result is sufficiently far from zero
19:
end if
20:
end for
21: end while
22: for 1 ≤ℓ≤K
23:
Ψℓ←VℓΛℓVT
ℓ
24: end for"
RESULTS,0.4913151364764268,"3
Results
141"
RESULTS,0.49379652605459057,"We tested our algorithm on synthetic data and five real-world datasets. Explanations of data generation,
142"
RESULTS,0.49627791563275436,"collection, preprocessing, and regularization are given in the supplementary material.
143"
SYNTHETIC DATA,0.4987593052109181,"3.1
Synthetic Data
144"
SYNTHETIC DATA,0.5012406947890818,"We verified that our algorithm was indeed faster on matrix-variate data compared to prior work
145"
SYNTHETIC DATA,0.5037220843672456,"(Figure 4) on our computer (Ubuntu 20.04 with Intel Core i7 Processor and 8GB RAM). Our results
146"
SYNTHETIC DATA,0.5062034739454094,"on matrix data are encouraging - extrapolating the runtimes, datasets up to size 16,000 by 16,000
147"
SYNTHETIC DATA,0.5086848635235732,"could have their graphs estimated in less than an hour. Larger datasets would require more than 6GB
148"
SYNTHETIC DATA,0.511166253101737,"of memory for our algorithm to run, pushing the limits of RAM. Our algorithm was not significantly
149"
SYNTHETIC DATA,0.5136476426799007,"faster on higher-order tensor data (see the supplementary material). This is due to the complexity of
150"
SYNTHETIC DATA,0.5161290322580645,"computing the Gram matrices, which grows exponentially with the number of axes.
151"
SYNTHETIC DATA,0.5186104218362283,"In addition to these speed improvements, we show that we perform equivalently to state-of-the-art
152"
SYNTHETIC DATA,0.5210918114143921,"on matrix data (Figure 5a). On higher-order tensor data, we are outperformed by TeraLasso, which
153"
SYNTHETIC DATA,0.5235732009925558,"is able to achieve near-perfect recovery of the graphs. We believe this is due to our algorithm’s use
154"
SYNTHETIC DATA,0.5260545905707196,"of thresholding rather than a more advanced regularization technique. Since our speed gains are
155"
SYNTHETIC DATA,0.5285359801488834,"not significant relative to TeraLasso, on higher-order tensor data without shared axes one should
156"
SYNTHETIC DATA,0.5310173697270472,"prefer TeraLasso to GmGM. Finally, we demonstrate that taking into account shared axes does indeed
157"
SYNTHETIC DATA,0.533498759305211,"improve performance (see blue line, Figure 5b). Prior work could not take this into account.
158"
REAL DATA,0.5359801488833746,"3.2
Real Data
159"
REAL DATA,0.5384615384615384,"We tested our method on various real datasets. These include two video datasets (COIL-20 [19] and
160"
REAL DATA,0.5409429280397022,"EchoNet-Dynamic [20]), a transcriptomics dataset (E-MTAB-2805 [5]), and two multi-omics datasets
161"
REAL DATA,0.543424317617866,"(LifeLines-DEEP [22] and a 10x Genomics dataset [1]).
162"
REAL DATA,0.5459057071960298,"(a)
(b)"
REAL DATA,0.5483870967741935,"Figure 4: A comparison of the runtimes of our algorithm against (a) bi-graphical and (b) tensor-
graphical prior work. Runtimes were averaged over 5 runs."
REAL DATA,0.5508684863523573,"(a)
(b)"
REAL DATA,0.5533498759305211,"Figure 5: (a) Precision-recall curves comparing various algorithms on synthetic 50x50 matrix data.
(b) Precision-recall curves comparing our algorithm on two 50x50 matrices with one shared axis. We
considered both modalities simultaneously (blue) and an individual modality (red, orange). In both
subfigures, each edge of the true graphs was generated independently with probability 1 5."
REAL DATA,0.5558312655086849,"(a)
(b)"
REAL DATA,0.5583126550868487,"Figure 6: The estimated precision matrices on the E-MTAB-2805 dataset (a) and the EchoNet-
Dynamic dataset (b). Yellow represents an edge and purple represents the lack of an edge. The
E-MTAB-2805 cells have been grouped together by cell cycle stage, in the order G, S, and G2/M. -0.1 0.0 0.1 0.2"
REAL DATA,0.5607940446650124,"100
1000
10000
Number of Edges"
REAL DATA,0.5632754342431762,Assortativities
REAL DATA,0.56575682382134,"linetype
GmGM
ziln
Phylum
Class
Order
Family
Genus"
REAL DATA,0.5682382133995038,Assortativities without Metabolites (a) -0.1 0.0 0.1 0.2 0.3
REAL DATA,0.5707196029776674,"100
1000
10000
Number of Edges"
REAL DATA,0.5732009925558312,Assortativities
REAL DATA,0.575682382133995,"linetype
GmGM
ziln
Phylum
Class
Order
Family
Genus"
REAL DATA,0.5781637717121588,Assortativities with Metabolites (b)
REAL DATA,0.5806451612903226,"Figure 7: Assortativity with increasing regulatization in the LifeLines-DEEP dataset, comparing our
method with the Zero-inflated Log-Normal (ZiLN) model. In one case we show the performance of
our algorithm restricted to the metagenomics dataset (a) and when augmented with the metabolomics
dataset (b). In both cases, ZiLN is only trained on the metagenomics dataset, as it is a single-axis
model."
REAL DATA,0.5831265508684863,"The E-MTAB-2805 dataset consists of transcriptomics data for individual cells split into three groups
163"
REAL DATA,0.5856079404466501,"by their stage in the cell cycle (G, S, and G2/M). If our estimated precision matrices had a 3x3
164"
REAL DATA,0.5880893300248139,"block-diagonal structure, this would indicate that it had recreated this grouping. This is not what we
165"
REAL DATA,0.5905707196029777,"see, but we do see a 3x3 block matrix structure (Figure 6a). We found that cells in the DNA synthesis
166"
REAL DATA,0.5930521091811415,"stage (S) had few connections between them, and that there were many connections between the G1
167"
REAL DATA,0.5955334987593052,"and G2/M stages. This result is biologically plausible, as cells in the synthesis stage are the most
168"
REAL DATA,0.598014888337469,"variable.
169"
REAL DATA,0.6004962779156328,"The results on EchoNet-Dynamic (Figure 6b) are much more encouraging, as we would expect a
170"
REAL DATA,0.6029776674937966,"periodic structure due to the beating of the heart. A precision matrix with repeating diagonals is what
171"
REAL DATA,0.6054590570719603,"we would expect to see in this case, which is what our algorithm produces. In the supplementary
172"
REAL DATA,0.607940446650124,"material, we further verify that this corresponds to a heartbeat by using the repetition to accurately
173"
REAL DATA,0.6104218362282878,"predict the opening of the mitral valve in the video.
174"
REAL DATA,0.6129032258064516,"The duck video in the COIL-20 dataset was considered in the original BiGLasso paper [14], in which
175"
REAL DATA,0.6153846153846154,"they showed that their algorithm could recover the ordering of the frames of the video. To do this they
176"
REAL DATA,0.6178660049627791,"had to heavily downsample the image (to a 9x9 image with half the frames), and flatten the rows and
177"
REAL DATA,0.6203473945409429,"frames into a single axis. Due to the speed improvements of our algorithm, and its ability to handle
178"
REAL DATA,0.6228287841191067,"tensor-variate data, we were able to run our algorithm on the raw, unprocessed data and achieve a
179"
REAL DATA,0.6253101736972705,"similar result in negligible time. Specifically, the reconstruction of the frames had an accuracy of
180"
REAL DATA,0.6277915632754343,"99%.
181"
REAL DATA,0.630272952853598,"Prior work by Prost, Gazut, and Brüls [21] used assortativity to assess their validity of the species
182"
REAL DATA,0.6327543424317618,"graph estimated by their model on the LifeLines-DEEP metagenomics dataset. Assortativity repre-
183"
REAL DATA,0.6352357320099256,"sents the tendency of related species to cluster together in the graph. A random graph would have
184"
REAL DATA,0.6377171215880894,"an assortativity of zero, but we would expect moderate assortativity in the true network as similar
185"
REAL DATA,0.6401985111662531,"species may fulfill similar roles in the gut microbiome. Our assortativity is comparable to prior work
186"
REAL DATA,0.6426799007444168,"(Figure 7). We also found that our graphs were more robust to noise than prior work; we analyze this
187"
REAL DATA,0.6451612903225806,"in the supplementary material.
188"
REAL DATA,0.6476426799007444,"Finally, we tested our approach on a 10x Genomics single-cell (RNA+ATAC) dataset taken from a
189"
REAL DATA,0.6501240694789082,"B Cell lymphoma tumour. We demonstrate that the clusters we find (using Louvain clustering[3])
190"
REAL DATA,0.652605459057072,"on the graph remain visually cohesive when projected into lower-dimensional space by UMAP[18]
191"
REAL DATA,0.6550868486352357,"(Figure 8). In particular, the disconnected “islands” in UMAP correspond to their own cluster on the
192"
REAL DATA,0.6575682382133995,"graph as well. As these island-clusters were arrived at independently through two methods, UMAP
193"
REAL DATA,0.6600496277915633,"and our algorithm, it increases our confidence in the validity of the clustering. In the supplementary
194"
REAL DATA,0.6625310173697271,"(a)
(b)"
REAL DATA,0.6650124069478908,"Figure 8: Two plots of the same cells from the 10x Genomics dataset, displayed via UMAP [18] (a)
and the Fruchterman-Reingold layout algorithm[11] (b). Colors are based on Louvain clustering[3]
of the graph, and represent the same clustering in both figures."
REAL DATA,0.6674937965260546,"material, we verify that these clusters do represent distinct groups via a GO term enrichment analysis.
195"
REAL DATA,0.6699751861042184,"Our overall approach has been implemented in Python. All of the code to run the algorithm and
196"
REAL DATA,0.6724565756823822,"recreate the experiments has been made publicly available on GitHub; https://github.com/NeurIPS-
197"
REAL DATA,0.674937965260546,"GmGM-Paper/GmGM.
198"
LIMITATIONS,0.6774193548387096,"4
Limitations
199"
LIMITATIONS,0.6799007444168734,"Our method uses thresholding rather than more sophisticated regularizers. However, there is no
200"
LIMITATIONS,0.6823821339950372,"fundamental barrier preventing our algorithm from allowing regularizers at the cost of an eigen-
201"
LIMITATIONS,0.684863523573201,"recomposition per iteration. This would increase the asymptotic complexity of the iterative portion
202"
LIMITATIONS,0.6873449131513648,"of our algorithm, making it questionable whether any gains in precision would be worth the loss in
203"
LIMITATIONS,0.6898263027295285,"efficiency.
204"
LIMITATIONS,0.6923076923076923,"Our method assumes that no tensor has a repeated axis (i.e. a matrix of people by people rather than
205"
LIMITATIONS,0.6947890818858561,"people by species). If there is a repeated axis, one can no longer analytically find the eigenvectors of
206"
LIMITATIONS,0.6972704714640199,"the MLE, at least by our methods. This is not a substantial issue, as such datasets are uncommon and
207"
LIMITATIONS,0.6997518610421837,"already represent graphs. Rather than extending the algorithm to work with repeated-axis tensors, it
208"
LIMITATIONS,0.7022332506203474,"would be more fruitful to extend it to work with priors.
209"
LIMITATIONS,0.7047146401985112,"When considering multi-tensor datasets, it may be the case that two axes only partially overlap. For
210"
LIMITATIONS,0.707196029776675,"example, the full LifeLines-DEEP dataset contains a second (follow-up) metagenomics dataset for a
211"
LIMITATIONS,0.7096774193548387,"third of the study participants; two thirds of the patients are missing from this dataset. We do not
212"
LIMITATIONS,0.7121588089330024,"make an attempt to handle this type of missing data, even though missing data shows up in many
213"
LIMITATIONS,0.7146401985111662,"applications. The lack of ability to handle missing data is a major limitation of our algorithm. It is
214"
LIMITATIONS,0.71712158808933,"nontrivial to extend the algorithm to handle this case, as it renders Theorem 1 ineffective and hence
215"
LIMITATIONS,0.7196029776674938,"removes the speed advantage we attained. Prior work has not addressed this problem, as it only exists
216"
LIMITATIONS,0.7220843672456576,"in multi-tensor datasets and we are the first to consider this case.
217"
CONCLUSION,0.7245657568238213,"5
Conclusion
218"
CONCLUSION,0.7270471464019851,"We have created a novel model, GmGM, which successfully generalizes Gaussian graphical models
219"
CONCLUSION,0.7295285359801489,"to the common scenario of multi-tensor datasets. Furthermore, we demonstrated that our algorithm is
220"
CONCLUSION,0.7320099255583127,"significantly faster than prior work focusing on Gaussian tensor-graphical models such as EiGLasso
221"
CONCLUSION,0.7344913151364765,"and TeraLasso while still preserving state-of-the-art performance. These speed improvements allow
222"
CONCLUSION,0.7369727047146402,"tensor-graphical models to be applied to datasets with axes of length in the thousands. Finally, we
223"
CONCLUSION,0.739454094292804,"demonstrated the application of our algorithm on five real-world datasets to prove its efficacy.
224"
REFERENCES,0.7419354838709677,"References
225"
REFERENCES,0.7444168734491315,"[1]
10x Genomics. Flash-Frozen Lymph Node with B Cell Lymphoma (14k sorted nuclei). en. May
226"
REFERENCES,0.7468982630272953,"2021. URL: https://www.10xgenomics.com/resources/datasets/fresh-frozen-
227"
REFERENCES,0.749379652605459,"lymph-node-with-b-cell-lymphoma-14-k-sorted-nuclei-1-standard-2-0-0
228"
REFERENCES,0.7518610421836228,"(visited on 05/10/2023).
229"
REFERENCES,0.7543424317617866,"[2]
Michael Altenbuchinger et al. “Gaussian and Mixed Graphical Models as (multi-)omics
230"
REFERENCES,0.7568238213399504,"data analysis tools”. en. In: Biochimica et Biophysica Acta (BBA) - Gene Regulatory
231"
REFERENCES,0.7593052109181141,"Mechanisms. Transcriptional Profiles and Regulatory Gene Networks 1863.6 (June 2020),
232"
REFERENCES,0.7617866004962779,"p. 194418. ISSN: 1874-9399. DOI: 10.1016/j.bbagrm.2019.194418. URL: https:
233"
REFERENCES,0.7642679900744417,"//www.sciencedirect.com/science/article/pii/S187493991930224X (visited on
234"
REFERENCES,0.7667493796526055,"02/24/2023).
235"
REFERENCES,0.7692307692307693,"[3]
Vincent D. Blondel et al. “Fast unfolding of communities in large networks”. In: Journal of
236"
REFERENCES,0.771712158808933,"Statistical Mechanics: Theory and Experiment 2008.10 (Oct. 2008). arXiv:0803.0476 [cond-
237"
REFERENCES,0.7741935483870968,"mat, physics:physics], P10008. ISSN: 1742-5468. DOI: 10.1088/1742-5468/2008/10/
238"
REFERENCES,0.7766749379652605,"P10008. URL: http://arxiv.org/abs/0803.0476 (visited on 05/16/2023).
239"
REFERENCES,0.7791563275434243,"[4]
Danila Bredikhin, Ilia Kats, and Oliver Stegle. “MUON: multimodal omics analysis frame-
240"
REFERENCES,0.7816377171215881,"work”. In: Genome Biology 23.1 (Feb. 2022), p. 42. ISSN: 1474-760X. DOI: 10.1186/s13059-
241"
REFERENCES,0.7841191066997518,"021-02577-8. URL: https://doi.org/10.1186/s13059-021-02577-8 (visited on
242"
REFERENCES,0.7866004962779156,"05/16/2023).
243"
REFERENCES,0.7890818858560794,"[5]
Florian Buettner et al. “Computational analysis of cell-to-cell heterogeneity in single-cell
244"
REFERENCES,0.7915632754342432,"RNA-sequencing data reveals hidden subpopulations of cells”. en. In: Nature Biotechnology
245"
REFERENCES,0.794044665012407,"33.2 (Feb. 2015). Number: 2 Publisher: Nature Publishing Group, pp. 155–160. ISSN: 1546-
246"
REFERENCES,0.7965260545905707,"1696. DOI: 10.1038/nbt.3102. URL: https://www.nature.com/articles/nbt.3102
247"
REFERENCES,0.7990074441687345,"(visited on 05/10/2023).
248"
REFERENCES,0.8014888337468983,"[6]
Thomas A. Caswell et al. matplotlib/matplotlib: REL: v3.7.1. Mar. 2023. DOI: 10.5281/
249"
REFERENCES,0.8039702233250621,"zenodo.7697899. URL: https://zenodo.org/record/7697899 (visited on 05/16/2023).
250"
REFERENCES,0.8064516129032258,"[7]
Gabor Csardi and Tamas Nepusz. “The Igraph Software Package for Complex Network
251"
REFERENCES,0.8089330024813896,"Research”. In: InterJournal Complex Systems (Nov. 2005), p. 1695.
252"
REFERENCES,0.8114143920595533,"[8]
Andy Dahl et al. Network inference in matrix-variate Gaussian models with non-independent
253"
REFERENCES,0.8138957816377171,"noise. arXiv:1312.1622 [stat]. Dec. 2013. DOI: 10.48550/arXiv.1312.1622. URL: http:
254"
REFERENCES,0.8163771712158809,"//arxiv.org/abs/1312.1622 (visited on 02/27/2023).
255"
REFERENCES,0.8188585607940446,"[9]
Pan Du, Warren A. Kibbe, and Simon M. Lin. “Improved peak detection in mass spectrum by
256"
REFERENCES,0.8213399503722084,"incorporating continuous wavelet transform-based pattern matching”. In: Bioinformatics 22.17
257"
REFERENCES,0.8238213399503722,"(Sept. 2006), pp. 2059–2065. ISSN: 1367-4803. DOI: 10.1093/bioinformatics/btl355.
258"
REFERENCES,0.826302729528536,"URL: https://doi.org/10.1093/bioinformatics/btl355 (visited on 05/11/2023).
259"
REFERENCES,0.8287841191066998,"[10]
Jerome Friedman, Trevor Hastie, and Robert Tibshirani. “Sparse inverse covariance estima-
260"
REFERENCES,0.8312655086848635,"tion with the graphical lasso”. In: Biostatistics 9.3 (July 2008), pp. 432–441. ISSN: 1465-
261"
REFERENCES,0.8337468982630273,"4644. DOI: 10.1093/biostatistics/kxm045. URL: https://doi.org/10.1093/
262"
REFERENCES,0.8362282878411911,"biostatistics/kxm045 (visited on 05/09/2023).
263"
REFERENCES,0.8387096774193549,"[11]
Thomas M. J. Fruchterman and Edward M. Reingold. “Graph drawing by force-
264"
REFERENCES,0.8411910669975186,"directed placement”. en. In: Software: Practice and Experience 21.11 (1991). _eprint:
265"
REFERENCES,0.8436724565756824,"https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.4380211102, pp. 1129–1164. ISSN: 1097-
266"
REFERENCES,0.8461538461538461,"024X. DOI: 10.1002/spe.4380211102. URL: https://onlinelibrary.wiley.com/
267"
REFERENCES,0.8486352357320099,"doi/abs/10.1002/spe.4380211102 (visited on 05/16/2023).
268"
REFERENCES,0.8511166253101737,"[12]
Kristjan Greenewald, Shuheng Zhou, and Alfred Hero III. Tensor Graphical Lasso (TeraLasso).
269"
REFERENCES,0.8535980148883374,"arXiv:1705.03983 [stat]. Sept. 2019. URL: http://arxiv.org/abs/1705.03983 (visited
270"
REFERENCES,0.8560794044665012,"on 02/24/2023).
271"
REFERENCES,0.858560794044665,"[13]
Charles R. Harris et al. “Array programming with NumPy”. en. In: Nature 585.7825 (Sept.
272"
REFERENCES,0.8610421836228288,"2020). Number: 7825 Publisher: Nature Publishing Group, pp. 357–362. ISSN: 1476-4687. DOI:
273"
REFERENCES,0.8635235732009926,"10.1038/s41586-020-2649-2. URL: https://www.nature.com/articles/s41586-
274"
REFERENCES,0.8660049627791563,"020-2649-2 (visited on 05/16/2023).
275"
REFERENCES,0.8684863523573201,"[14]
Alfredo Kalaitzis et al. “The Bigraphical Lasso”. en. In: Proceedings of the 30th International
276"
REFERENCES,0.8709677419354839,"Conference on Machine Learning. ISSN: 1938-7228. PMLR, May 2013, pp. 1229–1237. URL:
277"
REFERENCES,0.8734491315136477,"https://proceedings.mlr.press/v28/kalaitzis13.html (visited on 02/24/2023).
278"
REFERENCES,0.8759305210918115,"[15]
Tamara Kolda. Multilinear operators for higher-order decompositions. en. Tech. rep.
279"
REFERENCES,0.8784119106699751,"SAND2006-2081, 923081. Apr. 2006, SAND2006–2081, 923081. DOI: 10.2172/923081.
280"
REFERENCES,0.8808933002481389,"URL: https://www.osti.gov/servlets/purl/923081/ (visited on 05/05/2023).
281"
REFERENCES,0.8833746898263027,"[16]
Tamara G. Kolda and Brett W. Bader. “Tensor Decompositions and Applications”. en. In:
282"
REFERENCES,0.8858560794044665,"SIAM Review 51.3 (Aug. 2009), pp. 455–500. ISSN: 0036-1445, 1095-7200. DOI: 10.1137/
283"
REFERENCES,0.8883374689826302,"07070111X. URL: http://epubs.siam.org/doi/10.1137/07070111X (visited on
284"
REFERENCES,0.890818858560794,"02/26/2023).
285"
REFERENCES,0.8933002481389578,"[17]
Sijia Li et al. Scalable Bigraphical Lasso: Two-way Sparse Network Inference for Count
286"
REFERENCES,0.8957816377171216,"Data. arXiv:2203.07912 [cs, stat]. Mar. 2022. URL: http://arxiv.org/abs/2203.07912
287"
REFERENCES,0.8982630272952854,"(visited on 02/24/2023).
288"
REFERENCES,0.9007444168734491,"[18]
Leland McInnes, John Healy, and James Melville. UMAP: Uniform Manifold Approximation
289"
REFERENCES,0.9032258064516129,"and Projection for Dimension Reduction. arXiv:1802.03426 [cs, stat]. Sept. 2020. DOI: 10.
290"
REFERENCES,0.9057071960297767,"48550/arXiv.1802.03426. URL: http://arxiv.org/abs/1802.03426 (visited on
291"
REFERENCES,0.9081885856079405,"05/10/2023).
292"
REFERENCES,0.9106699751861043,"[19]
Sameer A Nene, Shree K Nayar, and Hiroshi Murase. “Columbia Object Image Library
293"
REFERENCES,0.913151364764268,"(COIL-20)”. en. In: ().
294"
REFERENCES,0.9156327543424317,"[20]
David Ouyang et al. “Video-based AI for beat-to-beat assessment of cardiac function”. en. In:
295"
REFERENCES,0.9181141439205955,"Nature 580.7802 (Apr. 2020). Number: 7802 Publisher: Nature Publishing Group, pp. 252–256.
296"
REFERENCES,0.9205955334987593,"ISSN: 1476-4687. DOI: 10.1038/s41586-020-2145-8. URL: https://www.nature.com/
297"
REFERENCES,0.9230769230769231,"articles/s41586-020-2145-8 (visited on 05/10/2023).
298"
REFERENCES,0.9255583126550868,"[21]
Vincent Prost, Stéphane Gazut, and Thomas Brüls. “A zero inflated log-normal model for
299"
REFERENCES,0.9280397022332506,"inference of sparse microbial association networks”. en. In: PLOS Computational Biology
300"
REFERENCES,0.9305210918114144,"17.6 (June 2021). Publisher: Public Library of Science, e1009089. ISSN: 1553-7358. DOI: 10.
301"
REFERENCES,0.9330024813895782,"1371/journal.pcbi.1009089. URL: https://journals.plos.org/ploscompbiol/
302"
REFERENCES,0.9354838709677419,"article?id=10.1371/journal.pcbi.1009089 (visited on 02/24/2023).
303"
REFERENCES,0.9379652605459057,"[22]
Ettje F. Tigchelaar et al. “Cohort profile: LifeLines DEEP, a prospective, general population
304"
REFERENCES,0.9404466501240695,"cohort study in the northern Netherlands: study design and baseline characteristics”. en. In:
305"
REFERENCES,0.9429280397022333,"BMJ Open 5.8 (Aug. 2015). Publisher: British Medical Journal Publishing Group Section: Epi-
306"
REFERENCES,0.9454094292803971,"demiology, e006772. ISSN: 2044-6055, 2044-6055. DOI: 10.1136/bmjopen-2014-006772.
307"
REFERENCES,0.9478908188585607,"URL: https://bmjopen.bmj.com/content/5/8/e006772 (visited on 04/30/2023).
308"
REFERENCES,0.9503722084367245,"[23]
Theodoros Tsiligkaridis, Alfred O. Hero III, and Shuheng Zhou. “Convergence Properties
309"
REFERENCES,0.9528535980148883,"of Kronecker Graphical Lasso Algorithms”. In: IEEE Transactions on Signal Processing
310"
REFERENCES,0.9553349875930521,"61.7 (Apr. 2013). arXiv:1204.0585 [stat], pp. 1743–1755. ISSN: 1053-587X, 1941-0476. DOI:
311"
REFERENCES,0.9578163771712159,"10.1109/TSP.2013.2240157. URL: http://arxiv.org/abs/1204.0585 (visited on
312"
REFERENCES,0.9602977667493796,"02/27/2023).
313"
REFERENCES,0.9627791563275434,"[24]
Yu Wang and Alfred Hero. “SG-PALM: a Fast Physically Interpretable Tensor Graphical
314"
REFERENCES,0.9652605459057072,"Model”. en. In: Proceedings of the 38th International Conference on Machine Learning.
315"
REFERENCES,0.967741935483871,"ISSN: 2640-3498. PMLR, July 2021, pp. 10783–10793. URL: https://proceedings.mlr.
316"
REFERENCES,0.9702233250620348,"press/v139/wang21k.html (visited on 02/27/2023).
317"
REFERENCES,0.9727047146401985,"[25]
Yu Wang, Byoungwook Jang, and Alfred Hero. The Sylvester Graphical Lasso (SyGlasso).
318"
REFERENCES,0.9751861042183623,"arXiv:2002.00288 [cs, stat]. Feb. 2020. DOI: 10.48550/arXiv.2002.00288. URL: http:
319"
REFERENCES,0.9776674937965261,"//arxiv.org/abs/2002.00288 (visited on 02/27/2023).
320"
REFERENCES,0.9801488833746899,"[26]
F. Alexander Wolf, Philipp Angerer, and Fabian J. Theis. “SCANPY: large-scale single-cell
321"
REFERENCES,0.9826302729528535,"gene expression data analysis”. In: Genome Biology 19.1 (Feb. 2018), p. 15. ISSN: 1474-760X.
322"
REFERENCES,0.9851116625310173,"DOI: 10.1186/s13059-017-1382-0. URL: https://doi.org/10.1186/s13059-017-
323"
REFERENCES,0.9875930521091811,"1382-0 (visited on 05/16/2023).
324"
REFERENCES,0.9900744416873449,"[27]
Jun Ho Yoon and Seyoung Kim. “EiGLasso: Scalable Estimation of Cartesian Product of Sparse
325"
REFERENCES,0.9925558312655087,"Inverse Covariance Matrices”. en. In: Proceedings of the 36th Conference on Uncertainty
326"
REFERENCES,0.9950372208436724,"in Artificial Intelligence (UAI). ISSN: 2640-3498. PMLR, Aug. 2020, pp. 1248–1257. URL:
327"
REFERENCES,0.9975186104218362,"https://proceedings.mlr.press/v124/ho-yoon20a.html (visited on 02/24/2023).
328"
