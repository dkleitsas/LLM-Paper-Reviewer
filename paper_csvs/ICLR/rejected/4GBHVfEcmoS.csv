Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0030120481927710845,"We propose a new approach to propagating probability distributions through neural
networks. To handle non-linearities, we use local linearization and show this to be
an optimal approximation in terms of total variation for ReLUs. We demonstrate the
advantages of our method over the moment matching approach popularized in prior
works. In addition, we formulate new loss functions for training neural networks
based on distributions. To demonstrate the utility of propagating distributions,
we apply it to quantifying prediction uncertainties. In regression tasks we obtain
calibrated conﬁdence intervals, and in a classiﬁcation setting we improve selective
prediction on out-of-distribution data. We also show empirically that training with
our uncertainty aware losses improve robustness to random and adversarial noise."
INTRODUCTION,0.006024096385542169,"1
INTRODUCTION"
INTRODUCTION,0.009036144578313253,"Neural networks are routinely used in applications affecting our daily lives, including safety-critical
domains. As a result, quantifying uncertainties in neural network decisions and improving their
robustness against noise has become an important problem. A prominent example is autonomous
driving [1], where a neural network is not only supposed to detect and classify various objects
like other cars or pedestrians on the road, but also to know how certain it is about this decision
and to allow, e.g., for human assistance for uncertain cases. As pointed out by many works, e.g.,
by Kendall and Gal [2] or by Kiureghian et al. [3], prediction uncertainties can arise from two
different sources: systematic uncertainty in the data, which is referred to as epistemic uncertainty,
or random uncertainties in the data, e.g., because of noisy sensors, which is referred to as aleatoric
uncertainty [4]. Both types of uncertainty, epistemic and aleatoric, have received considerable
attention. Works focusing on epistemic uncertainties include out-of-distribution (OOD) detection
[5], e.g., via orthogonal certiﬁcates [6] or via Bayesian neural networks [7–10]. Other works focus
on aleatoric uncertainties, e.g., via uncertainty propagation [1, 11–13], via ensembles [14], via
simultaneous quantile regression [6], or also via Bayesian neural networks [15]. Note that many of
the aforementioned methods can be applied to quantify both types of uncertainties. Similarly, in this
work, we focus on both aleatoric and epistemic uncertainties."
INTRODUCTION,0.012048192771084338,"We consider the problem of evaluating f(x + ǫ), where f is a neural network, x is an input data point,
and ǫ is a random noise variable. Therefore, f(x + ǫ) is a random variable, where its mean is used
for prediction, and its variance for quantifying the uncertainty. This perspective allows assessing the
sensitivity of the neural network for uncertainty quantiﬁcation. Aleatoric uncertainty due to input
measurement errors can be estimated by modeling how much a prediction changes under a respective
input uncertainty. Incorporating the sensitivity of a neural network during training can also allow
epistemic uncertainty quantiﬁcation: when the output variance is regularized (as in our proposed loss
function), the variance of predictions for observed data is minimized. Thus, for the regions where
data does not provide sufﬁcient information, the variance can be larger. We visualize the uncertainty
quantiﬁcation on a toy problem in Fig. 1: on the left our method identiﬁes high uncertainty in the
regions where samples from two classes overlap corresponding to aleatoric uncertainty; on the right,
we capture epistemic uncertainty due to many possible decision boundaries separating the two classes.
See ﬁgure 6 in Hüllermeier et al. [16] for an analogous example with linear models."
INTRODUCTION,0.015060240963855422,"Due to the high complexity of neural networks, speciﬁcally many non-linear functions, it is intractable
to compute the distribution of f(x + ǫ) analytically. A straightforward way to approximate the mean
and (co-)variances of f(x+ǫ) is to use the Monte Carlo method. Unfortunately, this is not suitable for"
INTRODUCTION,0.018072289156626505,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.02108433734939759,"Figure 1: Aleatoric (left) and epistemic (right) uncertainty estimation. Yellow indicates a large
estimated uncertainty and blue indicates a small estimated uncertainty."
INTRODUCTION,0.024096385542168676,"the problems we consider: evaluating a neural network f many times is computationally prohibitive,
and the quality of the approximation for the (co-)variances as well as the quality of the gradients
deteriorates quickly when the data is high-dimensional, e.g., images. Instead, we consider analytical
parametric approximations of f(x + ǫ). The key challenge is to approximate the transformations of
distributions by non-linearities such as ReLU. The widely used moment matching technique [17]
computes mean and variance of the corresponding transformed distribution and uses a Gaussian
distribution with the same mean and variance as the approximation. Moment matching can also be
applied for other distributions of the exponential distribution family [18]. However, this procedure
requires that the moments are deﬁned and ﬁnite, which is not always the case, e.g., for Cauchy
distributions. Also, it cannot be applied to conventionally pre-trained deep neural networks. In
addition, in our empirical studies, we observed that training with moment matching is numerically
unstable, requiring careful hyperparameter tuning to obtain meaningful results."
INTRODUCTION,0.02710843373493976,Contributions
INTRODUCTION,0.030120481927710843,"• We propose an approximation of a distribution transformed by a ReLU non-linearity that minimizes
the total variation distance to the true distribution. Empirically, we show that this approximation is
also effective in approximating transformations with other popular activation functions, and applicable
to multivariate and multilayer cases.
• We propose a new loss function for learning with Gaussian and Cauchy input distributions.
• We show that our method can quantify aleatoric uncertainty by obtaining calibrated conﬁdence
intervals in regression and epistemic uncertainty by improving selective prediction in classiﬁcation.
• We demonstrate that our method improves robustness against random and adversarial noise."
INTRODUCTION,0.03313253012048193,Our PyTorch-based [19] framework for propagating distributions will be publicly available.
RELATED WORK,0.03614457831325301,"2
RELATED WORK"
RELATED WORK,0.0391566265060241,"Several approaches have been suggested to introduce some treatment of uncertainty into neural
networks. They can be grouped into three broad categories, although there are also hybrid approaches."
RELATED WORK,0.04216867469879518,"The ﬁrst category tries to model uncertainty via sampling. Here, we ﬁnd, among others: Variational
inference for neural networks [9], a tractable approximation to Bayesian inference for neural networks;
Bayes by Backprop [8], which learns a probability distribution by Monte Carlo sampling to introduce
uncertainty in the weights of the network; Monte Carlo dropout [20], which estimates models’
prediction uncertainties by applying dropout [21] at test time. An overview of current techniques
for Bayesian deep learning in the context of computer vision models can be found in Gustafsson et
al. [22]. For aleatoric uncertainties Bouchacourt et al. [23] minimize the dissimilarity coefﬁcient
between the true and an estimated distribution (modeled by a neural network). The drawback of these
methods is the computationally expensive inference, i.e., to make a single prediction they require
many forward passes of a neural network."
RELATED WORK,0.045180722891566265,Under review as a conference paper at ICLR 2022
RELATED WORK,0.04819277108433735,"The second category of approaches concentrates on modeling uncertainties without sampling, i.e.,
analytically. These works approximately propagate normal distributions at individual training samples
through the network to model the network response to perturbed inputs [11, 12, 18, 24]. Wang et
al. [18] propose Natural-Parameter networks, which allow using exponential-family distributions
to model weights and neurons. Similarly, Wang et al. [25] and Postels et al. [26] use uncertainty
propagation to sampling-free approximate dropout. These methods use moment matching for
propagating parametric probability distributions through neural networks, as we will discuss in
greater detail subsequently. Wu et al. [27] propose an approximation to moment matching of
Gaussian distributions with covariance for ReLU non-linearities to provide a deterministic variational
inference approximation (DVIA) for Bayesian neural networks."
RELATED WORK,0.05120481927710843,"The third category of approaches estimates uncertainties by training a neural network to predict not
only an output value but also the output value’s uncertainty. Lakshminarayanan et al. [14] use neural
networks for predicting Gaussian distributions instead of individual values and extend this idea with
deep ensembles. Tagasovska et al. [6] learn conditional quantiles for aleatoric uncertainty estimation
and propose orthonormal certiﬁcates for quantifying epistemic uncertainty. We use several methods
from this category as baselines in our experiments."
RELATED WORK,0.05421686746987952,"Our approach falls into the second category and is most similar to Gast et al. [11] and Shekhovtsov et
al. [12]. Our approach differs in how distributions are passed through non-linearities such as ReLUs.
Previous work relies on moment matching [17], also known as assumed density ﬁltering. Moment
matching is a technique where the ﬁrst two moments of a distribution, such as the output distribution
of ReLU (i.e., the mean and variance) are computed and used as parameters for a normal distribution
to approximate the true distribution. As it is otherwise usually intractable, moment matching assumes
diagonal covariances. In our approach, we propagate normal distributions by an approximation that
minimizes the total variation (TV) distance for ReLU activations. We ﬁnd that our approximation is
faster to compute, a better approximation with respect to TV, and allows propagating full covariances.
Further, as we do not rely on moment matching, we can also propagate Cauchy distributions for
which the moments are not ﬁnitely deﬁned. Another advantage of our method is that it can be applied
to pre-trained models. On the other hand, moment matching changes the mean such that there are
deviations from what a network without uncertainty propagation would compute, leading to poor
predictions when applied to a pre-trained network. Lastly, instead of approximating the distribution
of the output classes for the loss function [11, 12], we propose a new loss function suitable for
distributional outputs."
PROPAGATING DISTRIBUTIONS THROUGH NEURAL NETWORKS,0.0572289156626506,"3
PROPAGATING DISTRIBUTIONS THROUGH NEURAL NETWORKS"
PROPAGATING DISTRIBUTIONS THROUGH NEURAL NETWORKS,0.060240963855421686,"For propagating parametric distributions through neural networks, we consider afﬁne transformations
and non-linearities, such as ReLU, separately. For afﬁne transformations, exact computation of
the parametric output distribution is possible due to the reproductive property of Gaussian and
Cauchy distributions. For non-linearities, we use local linearization and show that this approximation
minimizes the TV distance to the true intractable distribution for ReLUs. Recall that in our setting,
the input to a neural network is a random variable and the weights are learned parameters."
AFFINE TRANSFORMATIONS,0.06325301204819277,"3.1
AFFINE TRANSFORMATIONS"
AFFINE TRANSFORMATIONS,0.06626506024096386,Fully connected layers as well as convolutional layers are afﬁne transformations of their inputs.
AFFINE TRANSFORMATIONS,0.06927710843373494,"For fully connected layers, we use the notation y = xA⊤+ b where A ∈Rm×n is the weight matrix
and b ∈R1×m is the bias vector with n, m ∈N+."
AFFINE TRANSFORMATIONS,0.07228915662650602,"As convolutional layers can be expressed as fully connected layers, we discuss them in greater detail
in Supplementary Material B and only discuss fully connected layers here."
AFFINE TRANSFORMATIONS,0.07530120481927711,"Given a multivariate normal distribution X ∼N(µ, Σ), µ ∈R1×n, Σ ∈Rn×n, X can be
transformed by a fully connected layer via µ 7→µA⊤+ b and Σ 7→AΣA⊤."
AFFINE TRANSFORMATIONS,0.0783132530120482,"Given a multivariate normal distribution without covariances X ∼N(µ, σ2), µ ∈R1×n, σ ∈
R1×n, X can be transformed by a fully connected layer as follows: µ 7→µA⊤+ b and σ2 7→
σ2(A2)⊤where · 2 denotes the element-wise square."
AFFINE TRANSFORMATIONS,0.08132530120481928,Under review as a conference paper at ICLR 2022
AFFINE TRANSFORMATIONS,0.08433734939759036,"Given a multivariate Cauchy distribution X ∼C(x0, γ), x0 ∈R1×n, γ ∈R1×n, X can be
transformed by a fully connected layer by x0 7→x0A⊤+ b and γ 7→γ Abs(A)⊤."
AFFINE TRANSFORMATIONS,0.08734939759036145,"Notably, in all cases, the location µ/x0 does coincide with the values propagated in conventional
network layers. This allows applying this method directly to conventionally trained neural networks."
AFFINE TRANSFORMATIONS,0.09036144578313253,"Average pooling down-samples by averaging the values of pooling regions. As this is a linear
combination, it can be expressed using matrix multiplications and thus needs no special treatment."
NON-LINEAR TRANSFORMATIONS,0.09337349397590361,"3.2
NON-LINEAR TRANSFORMATIONS"
NON-LINEAR TRANSFORMATIONS,0.0963855421686747,"To handle non-linearities, we utilize local linearization. That is, we transform the mean / median and
the variance / scale as follows:
(µ, σ) 7→(f(µ), f ′(µ) · σ)
(1)"
NON-LINEAR TRANSFORMATIONS,0.09939759036144578,"for univariate distributions and as
(µ, Σ) 7→(f(µ), f ′(µ)Σf ′(µ)⊤)
(2)"
NON-LINEAR TRANSFORMATIONS,0.10240963855421686,"for multivariate distributions. ReLU is the most common non-linearity for neural networks, and we
now study it in more detail. Following local linearization (Eq. 1), our approximation for transforming
distributions with ReLUs is"
NON-LINEAR TRANSFORMATIONS,0.10542168674698796,"ReLU : (µ, σ) 7→
(µ, σ)
µ ≥0
(0, 0)
otherwise
(3)"
NON-LINEAR TRANSFORMATIONS,0.10843373493975904,"for distributions parameterized via µ and σ. In fact, for Gaussian and Cauchy distributions, this
approximation is optimal wrt. TV. The TV between two probability distributions, i.e., between the
true distribution QQQ and an approximation PPP, is deﬁned as"
NON-LINEAR TRANSFORMATIONS,0.11144578313253012,"TV (PPP,QQQ) = sup
A  Z"
NON-LINEAR TRANSFORMATIONS,0.1144578313253012,"A
(p −q) dν
 = 1 2"
NON-LINEAR TRANSFORMATIONS,0.11746987951807229,"Z
|p −q| dν .
(4)"
NON-LINEAR TRANSFORMATIONS,0.12048192771084337,"To motivate our choice of the approximation quality metric, we note that TV is a proper distance
metric on probability distributions. Speciﬁcally, a TV of 0 implies that two distributions are the same,
i.e., all their moments (including means) are equal. Devroye et al. [28] show that TV upper bounds
the maximum of differences between moments for Gaussian distributions."
NON-LINEAR TRANSFORMATIONS,0.12349397590361445,"In the following theorem, we formalize that our approximation of the ReLU non-linearity minimizes
the TV. Note that when parameterizing a Gaussian or Cauchy distribution with (0, 0), we are referring
to Dirac’s δ distribution. An illustration of the transformed distributions and their approximations can
be found in Supplementary Material A.
Theorem 1. Local linearization provides the best Gaussian approximation of a Gaussian distribution
transformed by a ReLU non-linearity with respect to the total variation:"
NON-LINEAR TRANSFORMATIONS,0.12650602409638553,"arg min
(˜µ,˜σ)
TV (PPP,QQQ) =
(µ, σ)
µ ≥0
(0, 0)
otherwise
(5)"
NON-LINEAR TRANSFORMATIONS,0.12951807228915663,"where PPP = N(˜µ, ˜σ2), QQQ = ReLU(N(µ, σ2))"
NON-LINEAR TRANSFORMATIONS,0.13253012048192772,"Proof. We distinguish 3 cases, µ < 0, µ = 0, and µ > 0:"
NON-LINEAR TRANSFORMATIONS,0.1355421686746988,"(µ < 0)
In the ﬁrst case, the true distribution has a probability mass of p0 > 0.5 at 0 because all
values below 0 will be mapped to 0 and CDF(0) > 0.5. As the approximation is parameterized as
(0, 0), it has a probability mass of 1 at 0. Therefore, the TV is |1 −p0| < 0.5. All parameterized
distributions where σ > 0 have no probability mass at 0 and thus a TV of at least |0−p0| = p0 > 0.5."
NON-LINEAR TRANSFORMATIONS,0.13855421686746988,"(µ = 0)
In this case,
R ∞
0
|p −q| dν = 0 because the distributions are equal on this domain. The
true distribution has a probability mass of p0 = 0.5 at 0, therefore the TV is |0 −p0| = 0.5. In
fact, all distributions with σ > 0 have a TV of at least 0.5 because |0 −p0| = 0.5. The distribution
parameterized by (0, 0) has the same TV at this point."
NON-LINEAR TRANSFORMATIONS,0.14156626506024098,"(µ > 0)
In this case, p0 = CDF(0) < 0.5. Further, again
R ∞
0
|p −q| dν = 0. Thus, the TV of our
distribution is |0 −p0| = p0 < 0.5. All distributions with σ > 0 have a TV of at least p0 because
|0 −p0| = p0. The distribution parameterized by (0, 0) has a TV of |1 −p0| > 0.5."
NON-LINEAR TRANSFORMATIONS,0.14457831325301204,"Thus, the approximation by linearization (Eq. 3) is the optimal approximation wrt. total variation."
NON-LINEAR TRANSFORMATIONS,0.14759036144578314,Under review as a conference paper at ICLR 2022
NON-LINEAR TRANSFORMATIONS,0.15060240963855423,"Corollary 1. Theorem 1 also applies to Cauchy distributions parameterized via x0, γ instead of µ, σ.
Proof. The proof of Theorem 1 also applies here."
NON-LINEAR TRANSFORMATIONS,0.1536144578313253,"Table 1: Simulation of propagating normal distributions through a
neural net. Reported is the intersection of probability mass (1 −TV )."
NON-LINEAR TRANSFORMATIONS,0.1566265060240964,"σ
With Cov. (Ours)
DVIA [27]
Without Cov. (Ours) Moment Matching"
NON-LINEAR TRANSFORMATIONS,0.15963855421686746,"0.1
0.9791
0.9791
0.9791 ± 0.0202 0.9720 ± 0.0228
0.2361 ± 0.0250
0.2611 ± 0.0256
1
0.8747
0.8747
0.8747 ± 0.0546 0.8519 ± 0.0543
0.2243 ± 0.0237
0.2195 ± 0.0294
10
0.7586
0.7586
0.7586 ± 0.0407 0.7035 ± 0.0366
0.2186 ± 0.0244
0.1976 ± 0.0179
100
0.6877
0.6877
0.6877 ± 0.0333 0.5845 ± 0.0479
0.2261 ± 0.0282
0.1724 ± 0.0111
1000 0.6808
0.6808
0.6808 ± 0.0318 0.5318 ± 0.0516
0.2193 ± 0.0248
0.1706 ± 0.0109"
NON-LINEAR TRANSFORMATIONS,0.16265060240963855,"To demonstrate the accu-
racy of this approximation
in the multi-dimensional
and multi-layer case, we
simulate multi-layer neural
networks with ReLU ac-
tivations and evaluate the
TV between parametric ap-
proximations and Monte
Carlo approximation with
106 samples representing the oracle. We use a neural network with 4 hidden layers and 100 neurons
per layer with ReLU non-linearities trained with softmax cross-entropy on the Iris data set. This data
set has small input and output dimensionalities, allowing us to use Monte Carlo as a feasible and
accurate oracle estimator of the truth. The results of this simulation are displayed in Tab. 1."
NON-LINEAR TRANSFORMATIONS,0.16566265060240964,"The simulation shows that propagating the covariances produces the best estimates of the output
distribution. Further, the simulation shows that when discarding covariances after each layer, on
average, the approximation from Eq. 3 performs better than moment matching. Note that moment
matching with covariances is intractable. Therefore, we use the deterministic variational inference
approximation method (DVIA) by Wu et al. [27] in this case as a baseline. As DVIA has a signiﬁcantly
larger computational complexity (its computational overhead is linear in the size of the largest
layer; see Section 5.5 for additional details), we can compare our method only in these simulation
experiments to DVIA. Overall, all methods are better for small input standard deviations σ. The reason
for this is that larger variances cause a larger part of the distribution to be mapped to 0 (for positive
means) or to positive values (for negative means), which are the sources of error in the approximations.
Results for additional architectures and non-linearities are presented in Supplementary Material C.1.
There, we evaluate our method also for Leaky-ReLU, GELU [29], and SiLU [30]."
LEARNING WITH UNCERTAINTY PROPAGATION,0.1686746987951807,"4
LEARNING WITH UNCERTAINTY PROPAGATION"
LEARNING WITH UNCERTAINTY PROPAGATION,0.1716867469879518,"With the ability to propagate parametric distributions through neural networks, we can shift our
focus to learning with such uncertainty propagation. Recall that the output of a neural network is
now a (multivariate) Gaussian or a Cauchy distribution. We want to incorporate the covariances
corresponding to a neural network’s output into the loss function. This is simple to achieve for
regression, i.e., by using log-likelihood as the loss, however, for classiﬁcation it is more challenging."
REGRESSION,0.1746987951807229,"4.1
REGRESSION"
REGRESSION,0.17771084337349397,"For regression (possibly with multiple outputs), we use the probability density of the predicted
distribution at the corresponding value as our training objective. For normal distributions, our
objective is maximizing the probability density by minimizing the negative log likelihood"
REGRESSION,0.18072289156626506,"log det(Σ) + (y −µ)⊤Σ−1(y −µ) .
(6)"
REGRESSION,0.18373493975903615,"Here, the k dimensional prediction is µ with covariance matrix Σ and the ground truth value is y.
For Cauchy distributions, the respective probability density can be maximized analogously."
CLASSIFICATION,0.18674698795180722,"4.2
CLASSIFICATION"
CLASSIFICATION,0.1897590361445783,"More interesting than regression is the classiﬁcation case, for which we propose a new loss function.
Previous work has proposed using moment matching of softmax [11], Dirichlet outputs [11], and
an approximation to the (n −1)-variate logistic distribution [12]. Instead of ﬁnding a surrogate that
incorporates the variance of the prediction, we use exact probabilities for classiﬁcation. This allows
incorporating not only the variances but also the covariances of a neural network’s prediction."
CLASSIFICATION,0.1927710843373494,"To arrive at our loss, we compute the probability of correct classiﬁcation, i.e., the probability that
the score for a certain class is the maximum among all classes. As the exact probability of a score
among n ≫2 scores being the maximum is intractable, we resort to computing the pairwise exact
probability of correct classiﬁcation, which also allows us to consider their covariance."
CLASSIFICATION,0.19578313253012047,Under review as a conference paper at ICLR 2022
CLASSIFICATION,0.19879518072289157,The exact probability of pairwise correct classiﬁcation for two random variables X and Y is
CLASSIFICATION,0.20180722891566266,"P(X > Y ) = P(X −Y > 0) =
Z ∞"
CLASSIFICATION,0.20481927710843373,"0
PDFX−Y (x) d x = CDFY −X(0) .
(7)"
CLASSIFICATION,0.20783132530120482,"For a multivariate normal distribution (X, Y ) ∼N((µX, µY ), Σ) with covariance matrix Σ."
CLASSIFICATION,0.21084337349397592,P(X > Y ) = 1
CLASSIFICATION,0.21385542168674698,"2

1 + erf

µX−µY
√"
CLASSIFICATION,0.21686746987951808,"2(σ2
XX+σ2
Y Y −2σXY )"
CLASSIFICATION,0.21987951807228914,"
(8)"
CLASSIFICATION,0.22289156626506024,"For independent normal distributions X ∼N(µX, σ2
X) and Y ∼N(µY , σ2
Y )."
CLASSIFICATION,0.22590361445783133,P(X > Y ) = 1
CLASSIFICATION,0.2289156626506024,"2

1 + erf

µX−µY
√"
CLASSIFICATION,0.2319277108433735,"2(σ2
X+σ2
Y )"
CLASSIFICATION,0.23493975903614459,"
(9)"
CLASSIFICATION,0.23795180722891565,"For Cauchy distributions X ∼C(xX, γX) and Y ∼C(xY , γY )."
CLASSIFICATION,0.24096385542168675,P(X > Y ) = 1
CLASSIFICATION,0.24397590361445784,"π

arctan

xX−xY
γX+γY"
CLASSIFICATION,0.2469879518072289,"
+ 1"
CLASSIFICATION,0.25,"2
(10)"
CLASSIFICATION,0.25301204819277107,"With that, our classiﬁcation training objective is maximizing P"
CLASSIFICATION,0.2560240963855422,"e̸=c
1
k−1 P(Zc > Ze),
(11)
where Zc takes on the distribution of the correct class score and Ze takes on the distributions of the
corresponding (among k −1) erroneous class scores. We refer to this loss function as the pairwise
Gaussian and the pairwise Cauchy, respectively."
EXPERIMENTS,0.25903614457831325,"5
EXPERIMENTS"
EXPERIMENTS,0.2620481927710843,"First, we investigate how well our method quantiﬁes aleatoric uncertainty on UCI regression tasks.
Second, we test how well our method can estimate epistemic uncertainty for detection of out-of-
distribution test data. Third, we investigate robustness against Gaussian noise and adversarial attacks."
ALEATORIC UNCERTAINTY QUANTIFICATION,0.26506024096385544,"5.1
ALEATORIC UNCERTAINTY QUANTIFICATION"
ALEATORIC UNCERTAINTY QUANTIFICATION,0.2680722891566265,"To evaluate aleatoric uncertainty predicted though uncertainty propagation, we examine its capability
to produce calibrated prediction intervals on eight UCI regression tasks. We follow the experimental
setting of Tagasovska et al. [6] and compare our method to their Conditional Quantiles method as
well as to their best baseline, Conditional Gaussians [14]. Conditional Quantiles enable learning
all conditional quantiles of a given target variable. Conditional Gaussian ﬁts a conditional normal
distribution, i.e., a neural network with two outputs, the mean and the variance. In comparison, our
approach does not let a neural network predict the variance, but instead propagates input uncertainties
through a neural network and computes calibrated prediction intervals from the output covariances."
ALEATORIC UNCERTAINTY QUANTIFICATION,0.2710843373493976,"We use the same model architecture, hyper-parameters, and evaluation metrics as Tagasovska et
al. [6] for all three methods. The evaluation metrics are Prediction Interval Coverage Probability
(PICP), i.e., the fraction of test data points falling into the predicted intervals, and the Mean Prediction
Interval Width (MPIW). In Tab. 2, following Tagasovska et al. [6], we report the test PICP and
MPIW of those models where the validation PICP lies between 92.5% and 97.5%. The goal is to
achieve a narrow interval (small MPIW) while the optimal test PICP is 95%. Our method achieves
the narrowest well-calibrated prediction intervals. Speciﬁcally, for 5 out of 8 data sets, our method
has the narrowest intervals while Conditional Gaussian as well as Conditional Quantile each achieve
the narrowest well-calibrated prediction intervals on only 2 of the data sets. Notably, for the ‘naval’
task, our method has the best-calibrated coverage intervals while having by far the smallest MPIW."
ALEATORIC UNCERTAINTY QUANTIFICATION,0.2740963855421687,"Table 2: Results for the aleatoric uncertainty experiment. The task is to compute calibrated prediction
intervals for 8 UCI data sets. Reported are test PICP and MPIW in parentheses. For MPIW lower is
better. All results are averaged over 20 runs. Prior methods are duplicated from Tagasovska et al. [6]."
ALEATORIC UNCERTAINTY QUANTIFICATION,0.27710843373493976,"Data Set
Uncertainty Propagation
Conditional Gaussian
Conditional Quantile"
ALEATORIC UNCERTAINTY QUANTIFICATION,0.28012048192771083,"concrete
0.92 ± 0.03 (0.25
0.25
0.25 ± 0.02)
0.94 ± 0.03 (0.32 ± 0.09)
0.94 ± 0.03 (0.31 ± 0.06)
power
0.94 ± 0.01 (0.20 ± 0.00)
0.94 ± 0.01 (0.18
0.18
0.18 ± 0.00)
0.93 ± 0.01 (0.18
0.18
0.18 ± 0.01)
wine
0.92 ± 0.03 (0.45
0.45
0.45 ± 0.03)
0.94 ± 0.02 (0.49 ± 0.03)
0.93 ± 0.03 (0.45
0.45
0.45 ± 0.04)
yacht
0.93 ± 0.04 (0.06 ± 0.01)
0.93 ± 0.06 (0.03
0.03
0.03 ± 0.01)
0.93 ± 0.06 (0.06 ± 0.04)
naval
0.94 ± 0.02 (0.02
0.02
0.02 ± 0.00)
0.96 ± 0.01 (0.15 ± 0.25)
0.95 ± 0.02 (0.12 ± 0.09)
energy
0.91 ± 0.05 (0.05
0.05
0.05 ± 0.01)
0.94 ± 0.03 (0.12 ± 0.18)
0.94 ± 0.03 (0.08 ± 0.03)
boston
0.93 ± 0.04 (0.28
0.28
0.28 ± 0.02)
0.94 ± 0.03 (0.55 ± 0.20)
0.92 ± 0.06 (0.36 ± 0.09)
kin8nm
0.95 ± 0.01 (0.24 ± 0.03)
0.93 ± 0.01 (0.20
0.20
0.20 ± 0.01)
0.93 ± 0.01 (0.23 ± 0.02)"
ALEATORIC UNCERTAINTY QUANTIFICATION,0.28313253012048195,Under review as a conference paper at ICLR 2022
ALEATORIC UNCERTAINTY QUANTIFICATION,0.286144578313253,"0.0
0.2
0.4
0.6
0.8
1.0
Coverage 0.0 0.1 0.2 0.3 0.4 0.5 Risk"
ALEATORIC UNCERTAINTY QUANTIFICATION,0.2891566265060241,"Trained w/ CE, Eval. w/ Softmax"
ALEATORIC UNCERTAINTY QUANTIFICATION,0.2921686746987952,"Trained w/ CE, Eval. w/ Dirichlet-Distribution"
ALEATORIC UNCERTAINTY QUANTIFICATION,0.29518072289156627,"Trained w/ CE, Eval. w/ Pairwise-Gaussian"
ALEATORIC UNCERTAINTY QUANTIFICATION,0.29819277108433734,"Trained w/ CE, Eval. w/ Pairwise-Cauchy"
ALEATORIC UNCERTAINTY QUANTIFICATION,0.30120481927710846,"Trained w/ CE, Eval. w/ Orthonormal Certiﬁcates
Perfect Prediction"
ALEATORIC UNCERTAINTY QUANTIFICATION,0.3042168674698795,"0.0
0.2
0.4
0.6
0.8
1.0
Coverage 0.0 0.1 0.2 0.3 0.4 0.5 Risk"
ALEATORIC UNCERTAINTY QUANTIFICATION,0.3072289156626506,"Trained w/ Pairwise-Gaussian, Eval. w/ Softmax"
ALEATORIC UNCERTAINTY QUANTIFICATION,0.3102409638554217,"Trained w/ Pairwise-Gaussian, Eval. w/ Pairwise-Gaussian"
ALEATORIC UNCERTAINTY QUANTIFICATION,0.3132530120481928,"Trained w/ Pairwise-Gaussian, Eval. w/ Pairwise-Cauchy"
ALEATORIC UNCERTAINTY QUANTIFICATION,0.31626506024096385,"Trained w/ MM + Dirichlet, Eval. w/ MM + Dirichlet"
ALEATORIC UNCERTAINTY QUANTIFICATION,0.3192771084337349,"Trained w/ MM + Dirichlet, Eval. w/ MM + Pairwise-Gaussian
Perfect Prediction"
ALEATORIC UNCERTAINTY QUANTIFICATION,0.32228915662650603,"Figure 2: Selective prediction on MNIST with EMNIST letters as OOD data. Left: risk-coverage plots
for off-the-shelf models trained with softmax cross-entropy. Right: models trained with uncertainty
propagation. The grey line indicates perfect prediction. Results averaged over 10 runs."
ALEATORIC UNCERTAINTY QUANTIFICATION,0.3253012048192771,Table 3: Selective prediction settings including the risk-coverage AUC for Fig. 2.
ALEATORIC UNCERTAINTY QUANTIFICATION,0.32831325301204817,"Training Objective
Uncertainty Prop.
Selective Prediction
Risk-Coverage AUC"
ALEATORIC UNCERTAINTY QUANTIFICATION,0.3313253012048193,"Softmax CE
—
Softmax Entropy
21.4%
Softmax CE
Our Propagation
Pairwise Gaussian
20.4%
Softmax CE
Our Propagation
Pairwise Cauchy
19.2%
19.2%
19.2%
Softmax CE
Our Propagation
Dirichlet Dist.
32.0%
Softmax CE
—
Orthonormal Cert.
24.2%"
ALEATORIC UNCERTAINTY QUANTIFICATION,0.33433734939759036,"Pairwise Gaussian
Our Propagation
Softmax Entropy
20.6%
Pairwise Gaussian
Our Propagation
Pairwise Gaussian
19.0%
Pairwise Gaussian
Our Propagation
Pairwise Cauchy
18.3%
18.3%
18.3%"
ALEATORIC UNCERTAINTY QUANTIFICATION,0.3373493975903614,"Dirichlet Dist.
Moment Matching
Dirichlet Dist.
19.2%
Dirichlet Dist.
Moment Matching
Pairwise Gaussian
19.0%
19.0%
19.0%"
ALEATORIC UNCERTAINTY QUANTIFICATION,0.34036144578313254,"Perfect Prediction
12.5%"
EPISTEMIC UNCERTAINTY FOR OUT-OF-DISTRIBUTION SELECTIVE PREDICTION,0.3433734939759036,"5.2
EPISTEMIC UNCERTAINTY FOR OUT-OF-DISTRIBUTION SELECTIVE PREDICTION"
EPISTEMIC UNCERTAINTY FOR OUT-OF-DISTRIBUTION SELECTIVE PREDICTION,0.3463855421686747,"Selective prediction [31] is a formulation where instead of only predicting a class, a neural network
can also abstain from a prediction if it is not certain. We benchmark selective prediction on MNIST
[32] and use EMNIST letters [33] as out-of-distribution data. EMNIST letters is a data set that
contains letters from A to Z in the same format as MNIST. We train a neural network on the MNIST
training data set and then combine the MNIST test data set (10 000 images) with 10 000 images
from the EMNIST letter data set. This gives us a test data set of 20 000 images, 50% of which are
out-of-distribution samples and for which the model should abstain from prediction."
EPISTEMIC UNCERTAINTY FOR OUT-OF-DISTRIBUTION SELECTIVE PREDICTION,0.3493975903614458,"In the ﬁrst setting, we train a neural network with conventional softmax cross-entropy to simulate an
existing off-the-shelf network. In the second setting, we train the neural network using uncertainty
propagation with the pairwise Gaussian loss (ours) as well as using moment matching propagation
and Dirichlet outputs [11]. We evaluate using ﬁve methods to compute certainty scores. First, we use
the softmax entropy of the prediction, and apply Orthonormal Certiﬁcates from Tagasovska et al. [6].
Second, we propagate a distribution with σ = 0.1 through the network to obtain the covariances.
Using these covariances, we use our pairwise Gaussian probabilities as well as the categorical
probabilities of the Dirichlet outputs proposed by Gast et al. [11] to compute the entropies of the
predictions. In Fig. 2, we provide risk-coverage plots [31] of the selective prediction based on these
scores. Risk-coverage plots report the empirical risk (i.e., the error) for each degree of coverage
α. That is, we select the α most certain predictions and report the error. This corresponds to a
setting, where a predictor can abstain from prediction in 1 −α of the cases. We use risk-coverage
area-under-the-curve (AUC) to quantify the overall selective prediction performance. Smaller AUC
implies that the network is accurate on in-distribution test data, while abstaining from making a
wrong prediction on out-of-distribution examples. In this experiment, no correct prediction on OOD
data is possible because the classiﬁer can only predict numbers while the OOD data consists of letters."
EPISTEMIC UNCERTAINTY FOR OUT-OF-DISTRIBUTION SELECTIVE PREDICTION,0.35240963855421686,"We evaluate a variety of combinations of training losses, uncertainty propagation methods, and conﬁ-
dence scores for selective prediction. See Tab. 3 for the summary and the corresponding risk-coverage
AUC results. We ﬁnd that training with an uncertainty-aware training objective (pairwise Gaussian"
EPISTEMIC UNCERTAINTY FOR OUT-OF-DISTRIBUTION SELECTIVE PREDICTION,0.35542168674698793,Under review as a conference paper at ICLR 2022
EPISTEMIC UNCERTAINTY FOR OUT-OF-DISTRIBUTION SELECTIVE PREDICTION,0.35843373493975905,"and Cauchy losses and Dirichlet outputs) improves the out-of-distribution detection substantially.
Further, we ﬁnd that the pairwise Cauchy scores achieve the best out-of-distribution detection on a
pre-trained model. Orthonormal certiﬁcates (OC) estimate null-space of data in the latent space to
detect out-of-distribution examples. In our setting, digits and letters may share a similar null-space,
making OC not as effective. The Dirichtlet distribution does not perform well on a pretrained model
because it is not designed for this scenario but instead designed to work in accordance with moment
matching. We also observe that, for a model trained with Dirichlet outputs and moment matching
uncertainty propagation, selective prediction conﬁdence scores of pairwise Gaussian and pairwise
Cauchy offer an improvement in comparison to the Dirichlet output based scores. This suggest
that pairwise Cauchy scores are beneﬁcial across various training approaches. The overall best
accuracy (18.3% AUC) is achieved by training with an uncertainty-aware objective and evaluating
using pairwise Cauchy. We also report AUC of a perfect predictor, i.e., one that always abstains on
out-of-distribution data and always predicts correctly in-distribution."
EPISTEMIC UNCERTAINTY FOR OUT-OF-DISTRIBUTION SELECTIVE PREDICTION,0.3614457831325301,"10−8
10−6
10−4
10−2
100
102
104"
EPISTEMIC UNCERTAINTY FOR OUT-OF-DISTRIBUTION SELECTIVE PREDICTION,0.3644578313253012,Input σ / γ during Training 0.0 0.2 0.4 0.6 0.8 1.0
EPISTEMIC UNCERTAINTY FOR OUT-OF-DISTRIBUTION SELECTIVE PREDICTION,0.3674698795180723,"Accuracy
Acc. under noise σ = 0.5
Cauchy distribution
Normal distribution w/o Cov."
EPISTEMIC UNCERTAINTY FOR OUT-OF-DISTRIBUTION SELECTIVE PREDICTION,0.3704819277108434,"Normal distribution w/ Cov.
Moment Matching + Dirichlet
Softmax Cross-Entropy"
EPISTEMIC UNCERTAINTY FOR OUT-OF-DISTRIBUTION SELECTIVE PREDICTION,0.37349397590361444,"10−8
10−6
10−4
10−2
100
102
104"
EPISTEMIC UNCERTAINTY FOR OUT-OF-DISTRIBUTION SELECTIVE PREDICTION,0.37650602409638556,Input σ / γ during Training 0.0 0.2 0.4 0.6 0.8 1.0
EPISTEMIC UNCERTAINTY FOR OUT-OF-DISTRIBUTION SELECTIVE PREDICTION,0.3795180722891566,"Accuracy
PGD ǫ = 16/255
Cauchy distribution
Normal distribution w/o Cov."
EPISTEMIC UNCERTAINTY FOR OUT-OF-DISTRIBUTION SELECTIVE PREDICTION,0.3825301204819277,"Normal distribution w/ Cov.
Moment Matching + Dirichlet
Softmax Cross-Entropy"
EPISTEMIC UNCERTAINTY FOR OUT-OF-DISTRIBUTION SELECTIVE PREDICTION,0.3855421686746988,"Figure 3: Robustness of CNNs on the MNIST data set against Gaussian noise (left) as well as PGD
adversarial noise (right). The continuous lines show the test accuracy and the dashed lines show the
robust accuracy. The black lines indicate the softmax cross-entropy trained baseline. Results are
averaged over 3 runs. Results on CIFAR-10 and further settings are in Supplementary Material C.2."
ROBUSTNESS AGAINST GAUSSIAN AND ADVERSARIAL NOISE,0.3885542168674699,"5.3
ROBUSTNESS AGAINST GAUSSIAN AND ADVERSARIAL NOISE"
ROBUSTNESS AGAINST GAUSSIAN AND ADVERSARIAL NOISE,0.39156626506024095,"Robustness of neural networks has received signiﬁcant attention in the past years [34–36]. There are
many methods for robustifying neural networks against random noise in the inputs or adversarially
crafted perturbations. Our method is not explicitly designed for these purposes, however, here we
empirically demonstrate that it achieves meaningful robustness improvements. This is an additional
beneﬁt to its main purpose of quantifying uncertainties."
ROBUSTNESS AGAINST GAUSSIAN AND ADVERSARIAL NOISE,0.39457831325301207,"We evaluate the robustness of classiﬁcation models trained with uncertainty propagation on the
MNIST [32] and CIFAR-10 [37] data sets. We consider the following training scenarios: First, we
propagate normal distributions with and without covariance and train using the pairwise Gaussian
loss. Second, we train with Cauchy distribution propagation using the pairwise Cauchy loss. As
for baselines, we compare to training with softmax cross-entropy as well as moment matching
propagation with the Dirichlet output loss [11]. The network architectures, hyper-parameters, as well
as the results on CIFAR-10 are presented in Supplementary Material C.2."
ROBUSTNESS AGAINST GAUSSIAN AND ADVERSARIAL NOISE,0.39759036144578314,"Random Gaussian Noise
To evaluate the random noise robustness of models trained with uncer-
tainty propagation, we add random Gaussian per-pixel noise during evaluation. Speciﬁcally, we use
input noise with σ = 0.5 (see Supplementary Material C.2 for σ ∈{0.25, 0.75}) and clamp the
image to the original pixel value range (between 0 and 1). In Fig. 3 (left), we display results for input
standard deviations / scales from 10−9 to 104. For every input standard deviation, we train separate
models. For each method, the range of good hyperparameters is around 4 −6 orders of magnitude.
We observe, when training with uncertainty propagation and the pairwise Gaussian / Cauchy losses,
the models are substantially more robust than with conventional training on the MNIST data set."
ROBUSTNESS AGAINST GAUSSIAN AND ADVERSARIAL NOISE,0.4006024096385542,"Adversarial Noise
To evaluate the adversarial robustness of models trained with uncertainty prop-
agation, we use the projected gradient descent (PGD) attack [35] as it is a popular and powerful
attack. In Fig. 3 (right), we demonstrate the adversarial robustness of CNNs on distributions. We
can see that our approach is competitive with the accuracy of the softmax cross-entropy loss and
can even outperform it. For measuring the adversarial robustness, we use L∞-bounded PGD, for"
ROBUSTNESS AGAINST GAUSSIAN AND ADVERSARIAL NOISE,0.4036144578313253,Under review as a conference paper at ICLR 2022
ROBUSTNESS AGAINST GAUSSIAN AND ADVERSARIAL NOISE,0.4066265060240964,"MNIST with ǫ = 16/255 (and with ǫ = 8/255 in the supplementary material), and for CIFAR with
ǫ ∈{3/255, 4/255} (results for CIFAR are presented in the supplementary material). Note that our
uncertainty propagation, in combination with pairwise probability classiﬁcation losses, outperform
both baselines in each case. We ﬁnd that the adversarially most robust training method is propagating
normal distributions with covariances, where we achieve a robust accuracy of 85% with ǫ = 16/255
on the MNIST data set compared to a robust accuracy of 14% for models trained with softmax cross-
entropy. Note that the baseline Dirichlet loss with moment-matching [11] offers no robustness gains
in this experiment. We observe that, when training with normal distributions without covariances, the
models are only robust against adversarial noise for rather large input standard deviations. At the
same time, this effect is inverse for random Gaussian noise, where robustness against random noise is
achieved when input standard deviations are rather small."
ROBUSTNESS AGAINST GAUSSIAN AND ADVERSARIAL NOISE,0.40963855421686746,"We perform PGD on our models with our objective functions as described in Eq. 11 and PGD
on the cross-entropy trained models with the softmax cross-entropy objective. In Supplementary
Material C.2, we provide results where a softmax cross-entropy based objective is used by the
adversary: our models are more robust against the cross-entropy based attack than against the true
objective based attacks which are reported in the plot. Our methods are not as robust as methods
speciﬁcally designed for that purpose, e.g., adversarial training [35]. However, our methods provide a
substantial improvement over training with softmax cross-entropy."
PROPAGATING DISTRIBUTIONS THROUGH RESNETS,0.4126506024096386,"5.4
PROPAGATING DISTRIBUTIONS THROUGH RESNETS"
PROPAGATING DISTRIBUTIONS THROUGH RESNETS,0.41566265060240964,Table 4: CIFAR-10 performance with ResNets.
PROPAGATING DISTRIBUTIONS THROUGH RESNETS,0.4186746987951807,"Model
Softmax CE
Pairwise Gaussian (w/ cov.)"
PROPAGATING DISTRIBUTIONS THROUGH RESNETS,0.42168674698795183,"ResNet-18
90.1% ± 0.2%
89.5% ± 0.6%
ResNet-34
90.5% ± 0.2%
89.6% ± 0.2%"
PROPAGATING DISTRIBUTIONS THROUGH RESNETS,0.4246987951807229,"To validate that our method also performs well
for large architectures, we apply it to learning
CIFAR-10 with ResNet-18 and ResNet-34 [38]
architectures. Here, we train each model using
Adam [39] for 400 epochs and compare it to the
same setting with the softmax cross-entropy loss
in Tab. 4. The results validate that training with the Pairwise Gaussian loss (w/ covariances) does not
substantially damage the performance in comparsion to softmax cross-entropy."
RUNTIME ANALYSIS,0.42771084337349397,"5.5
RUNTIME ANALYSIS"
RUNTIME ANALYSIS,0.4307228915662651,"Table 5: Computational Cost Benchmark. Times per epoch
on CIFAR-10 with a batch size of 128 on a single V100 GPU."
RUNTIME ANALYSIS,0.43373493975903615,"Model
regular
moment matching
dist. w/o cov.
dist. w/ cov."
LAYER CNN,0.4367469879518072,"3 Layer CNN
6.29s
6.33s
6.31s
20.8s
ResNet-18
9.85s
30.7s∗
28.5s
251s"
LAYER CNN,0.4397590361445783,"∗as moment matching for some layers of ResNet (such as MaxPool for more
than two inputs) is very expensive and does not have a closed form solution in the
literature, we use our approximation for these layers."
LAYER CNN,0.4427710843373494,"In Tab. 5, we report runtimes for prop-
agating distributions. For small mod-
els, propagating distributions without
covariances is almost without over-
head while propagating covariances is
slower. Moment matching is slightly
more expensive than the proposed
propagation, which is because mo-
ment matching requires evaluating ad-
ditional (scalar) functions at the non-linearities. The complexity (as a factor of the cost of propagating
a single point through the neural network) of propagating distributions with covariances is linear in
the number of outputs, while for propagating distributions without covariances it is constant. As
a reference, exact propagation of the distributions (and not a parametric approximation as in this
work) has an exponential runtime factor in the number of neurons [40]. The runtime factor of DVIA
[27] is linear in the number of neurons in the largest layer, which makes experiments exceeding
Table 1 infeasible. For example, in the robustness experiments on MNIST dataset in Section 5.3, the
dimension of the largest hidden layer is ≈12 500, i.e., computational time of a single forward pass
with DVIA is over 12 500 regular forward passes."
CONCLUSION,0.4457831325301205,"6
CONCLUSION"
CONCLUSION,0.44879518072289154,"We studied the problem of uncertainty propagation in neural networks. Uncertainty propagation
allows quantifying both epistemic and aleatoric uncertainties, and promotes robustness to input noises,
as demonstrated in our empirical studies. Our local linearization based methods, together with the
pairwise Gaussian and Cauchy loss functions, performed well. Extending our theoretical results to
better understand the empirical success could be an interesting direction for future work."
CONCLUSION,0.45180722891566266,Under review as a conference paper at ICLR 2022
REPRODUCIBILITY STATEMENT,0.45481927710843373,REPRODUCIBILITY STATEMENT
REPRODUCIBILITY STATEMENT,0.4578313253012048,"We will make the source code and experiments of this work publicly available to foster future research
in this direction. All data sets are publicly available. We specify all necessary hyperparameters for
each experiment. Each experiment can be reproduced on a single GPU."
REFERENCES,0.4608433734939759,REFERENCES
REFERENCES,0.463855421686747,"[1]
A. Loquercio, M. Segu, and D. Scaramuzza, “A general framework for uncertainty estimation in deep
learning,” IEEE Robotics and Automation Letters, vol. 5, no. 2, pp. 3153–3160, 2020.
[2]
A. Kendall and Y. Gal, “What uncertainties do we need in bayesian deep learning for computer vision?”
In Proc. 31st Conf. on Neural Information Processing Systems (NIPS 2017, Long Beach, CA), 2017,
pp. 5574–5584.
[3]
A. Der Kiureghian and O. Ditlevsen, “Aleatory or epistemic? does it matter?” Structural safety, vol. 31,
no. 2, pp. 105–112, 2009.
[4]
Y. Gal, “Uncertainty in deep learning,” University of Cambridge, vol. 1, no. 3, 2016.
[5]
D. Hendrycks and K. Gimpel, “A baseline for detecting misclassiﬁed and out-of-distribution examples in
neural networks,” Proceedings of International Conference on Learning Representations, 2017.
[6]
N. Tagasovska and D. Lopez-Paz, “Single-model uncertainties for deep learning,” in Proc. Neural
Information Processing Systems (NIPS), 2019.
[7]
S. Ghosh, F. M. D. Fave, and J. Yedidia, “Assumed density ﬁltering methods for learning bayesian neural
networks,” in Proceedings of the Thirtieth AAAI Conference on Artiﬁcial Intelligence, ser. AAAI’16,
Phoenix, Arizona: AAAI Press, 2016, pp. 1589–1595.
[8]
C. Blundell, J. Cornebise, K. Kavukcuoglu, and D. Wierstra, “Weight uncertainty in neural networks,”
in Proc. 32nd Int. Conf. on Machine Learning (ICML 2015, Lille, France), ML Research Press, 2015,
pp. 1613–1622.
[9]
A. Graves, “Practical variational inference for neural networks,” in Proc. 25th Conf. on Neural Informa-
tion Processing Systems (NIPS 2011, Granada, Spain), 2011, pp. 2348–2356.
[10]
A. Buchholz, F. Wenzel, and S. Mandt, “Quasi-Monte Carlo variational inference,” J. Dy and A. Krause,
Eds., ser. Proceedings of Machine Learning Research, vol. 80, Stockholmsmässan, Stockholm Sweden:
PMLR, Oct. 2018, pp. 668–677. [Online]. Available: http://proceedings.mlr.press/v80/
buchholz18a.html.
[11]
J. Gast and S. Roth, “Lightweight probabilistic deep networks,” in Proc. IEEE Int. Conf. Computer Vision
and Pattern Recognition (CVPR 2018, Salt Lake City, UT), Piscataway, NJ, USA: IEEE Press, 2018.
[12]
A. Shekhovtsov and B. Flach, “Feed-forward propagation in probabilistic neural networks with categorical
and max layers,” in Proc. Int. Conf. on Learning Representations (ICLR 2019, New Orleans, LA), 2019.
[13]
J. J. Thiagarajan, I. Kim, R. Anirudh, and P. Bremer, “Understanding deep neural networks through input
uncertainties,” in ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal
Processing (ICASSP), 2019, pp. 2812–2816.
[14]
B. Lakshminarayanan, A. Pritzel, and C. Blundell, “Simple and scalable predictive uncertainty estimation
using deep ensembles,” in Proc. Neural Information Processing Systems (NIPS), 2017.
[15]
E. Goan and C. Fookes, “Bayesian neural networks: An introduction and survey,” in Case Studies in
Applied Bayesian Data Science, Springer, 2020, pp. 45–87.
[16]
E. Hüllermeier and W. Waegeman, “Aleatoric and epistemic uncertainty in machine learning: An
introduction to concepts and methods,” Machine Learning, vol. 110, no. 3, pp. 457–506, 2021.
[17]
B. J. Frey and G. E. Hinton, “Variational learning in nonlinear gaussian belief networks,” Neural
Computation, vol. 11, pp. 193–213, 1 1999.
[18]
H. Wang, X. Shi, and D.-Y. Yeung, “Natural-parameter networks: A class of probabilistic neural networks,”
in Proc. 30th Conf. on Neural Information Processing Systems (NIPS 2016, Barcelona, Spain), 2016,
pp. 118–126.
[19]
A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein,
L. Antiga, A. Desmaison, A. Kopf, E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner,
L. Fang, J. Bai, and S. Chintala, “Pytorch: An imperative style, high-performance deep learning library,”
in Proc. Neural Information Processing Systems (NIPS), 2019, pp. 8024–8035.
[20]
Y. Gal and Z. Ghahramani, “Dropout as a bayesian approximation: Representing model uncertainty in
deep learning,” in international conference on machine learning, PMLR, 2016, pp. 1050–1059.
[21]
N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov, “Dropout: A simple way
to prevent neural networks from overﬁtting,” The journal of machine learning research, vol. 15, no. 1,
pp. 1929–1958, 2014."
REFERENCES,0.46686746987951805,Under review as a conference paper at ICLR 2022
REFERENCES,0.46987951807228917,"[22]
F. K. Gustafsson, M. Danelljan, and T. B. Schon, “Evaluating scalable bayesian deep learning methods
for robust computer vision,” in 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition
Workshops (CVPRW), 2020, pp. 1289–1298.
[23]
D. Bouchacourt, M. P. Kumar, and S. Nowozin, “Disco nets: Dissimilarity coefﬁcient networks,” in Proc.
30th Conf. on Neural Information Processing Systems (NIPS 2016, Barcelona, Spain), 2016, pp. 352–360.
[24]
J. Jin, A. Dundar, and E. Culutciello, “Robust convolutional neural networks under adversarial noise,” in
Workshop Track Int. Conf. on Learning Representations (ICLR 2016, San Juan, Puerto Rico), 2016.
[25]
S. Wang and C. Manning, “Fast dropout training,” in International Conference on Machine Learning
(ICML), PMLR, 2013, pp. 118–126.
[26]
J. Postels, F. Ferroni, H. Coskun, N. Navab, and F. Tombari, “Sampling-free epistemic uncertainty
estimation using approximated variance propagation,” in Proc. International Conference on Computer
Vision (ICCV), 2019, pp. 2931–2940.
[27]
A. Wu, S. Nowozin, E. Meeds, R. E. Turner, J. M. Hernandez-Lobato, and A. L. Gaunt, “Deterministic
variational inference for robust bayesian neural networks,” in International Conference on Learning
Representations (ICLR), 2019.
[28]
L. Devroye, A. Mehrabian, and T. Reddad, “The total variation distance between high-dimensional
gaussians,” arXiv preprint arXiv:1810.08693, 2018.
[29]
D. Hendrycks and K. Gimpel, “Gaussian error linear units (gelus),” arXiv preprint arXiv:1606.08415,
2016.
[30]
S. Elfwing, E. Uchibe, and K. Doya, “Sigmoid-weighted linear units for neural network function
approximation in reinforcement learning. arxiv e-prints (2017),” arXiv preprint arXiv:1702.03118, 2017.
[31]
Y. Geifman and R. El-Yaniv, “Selective classiﬁcation for deep neural networks,” in Proc. Neural
Information Processing Systems (NIPS), 2017.
[32]
Y. LeCun, C. Cortes, and C. Burges, “Mnist handwritten digit database,” ATT Labs, vol. 2, 2010. [Online].
Available: http://yann.lecun.com/exdb/mnist.
[33]
G. Cohen, S. Afshar, J. Tapson, and A. van Schaik, “EMNIST: an extension of MNIST to handwritten
letters,” arXiv preprint arXiv:1702.05373, 2017.
[34]
N. Carlini, A. Athalye, N. Papernot, W. Brendel, J. Rauber, D. Tsipras, I. Goodfellow, A. Madry, and
A. Kurakin, “On evaluating adversarial robustness,” arXiv preprint arXiv:1902.06705, 2019.
[35]
A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu, “Towards deep learning models resistant
to adversarial attacks,” arXiv preprint arXiv:1706.06083, 2017.
[36]
E. Wong and Z. Kolter, “Provable defenses against adversarial examples via the convex outer adversarial
polytope,” in International Conference on Machine Learning (ICML), 2018.
[37]
A. Krizhevsky, V. Nair, and G. Hinton, “Cifar-10 (canadian institute for advanced research),” 2009.
[Online]. Available: http://www.cs.toronto.edu/~kriz/cifar.html.
[38]
K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recognition,” in Proceedings of
the IEEE conference on computer vision and pattern recognition, 2016, pp. 770–778.
[39]
D. Kingma and J. Ba, “Adam: A method for stochastic optimization,” in International Conference on
Learning Representations (ICLR), 2015.
[40]
R. Balestriero, S. Paris, and R. G. Baraniuk, “Analytical Probability Distributions and EM-Learning for
Deep Generative Networks,” in Proc. Neural Information Processing Systems (NIPS), 2020."
REFERENCES,0.47289156626506024,Under review as a conference paper at ICLR 2022
REFERENCES,0.4759036144578313,"Supplementary Material for
Propagating Distributions through Neural Networks"
REFERENCES,0.4789156626506024,"A
ILLUSTRATION OF PARAMETRIC APPROXIMATIONS OF RELU 1
√ 2πσ2 Φ(−µ σ)"
REFERENCES,0.4819277108433735,"µ = −1.0
σ =
1.0 1
√ 2πσ2 Φ(−µ σ)"
REFERENCES,0.48493975903614456,"µ = 1.0
σ = 1.0 1
√ 2πσ2 Φ(−µ σ)"
REFERENCES,0.4879518072289157,"µ = −1.0
σ =
1.0 1
√ 2πσ2 Φ(−µ σ)"
REFERENCES,0.49096385542168675,"µ = 1.0
σ = 1.0"
REFERENCES,0.4939759036144578,"Figure 4: Illustration of parametric approximations of ReLU. In each plot, the gray distribution is the
input and the green distribution is the true output distribution. The red distributions (top) are our local
linearization approximation. The orange distributions (bottom) are produced by moment matching."
REFERENCES,0.49698795180722893,"B
TRANSFORMATION OF CONVOLUTIONS"
REFERENCES,0.5,"For two-dimensional convolutions, we use the notation Y = X ∗W + B where X ∈Rc0×n0×n1
is the input (image), W ∈Rc1×c0×k0×k1 is the weight tensor, and B, Y ∈Rc1×m0×m1 are the
bias and output tensors with c0, c1, k0, k1, n0, n1, m0, m1, m0, m1 ∈N+. Further, let XU ∈
Rm0×m1×c0×k0×k1 be the unfolded sliding local blocks1 from tensor X such that Yc1m0m1 =
P"
REFERENCES,0.5030120481927711,"c0k0k1 XU
m0m1c0k0k1Wc1c0k0k1 + B = X ∗W + B."
REFERENCES,0.5060240963855421,"Normal Distribution with Covariances
For the convolutional layer, µ ∈Rc0×n0×n1, Σ ∈
Rc0×n0×n1×c0×n0×n1. Note that ΣU ∈Rm0×m1×c0×k0×k1×m0×m1×c0×k0×k1 is the unfolded slid-
ing local blocks covariance of the covariance tensor Σ. µ 7→µ ∗W + B and Σc1m0m1c′
1m′
0m′
1 7→
P"
REFERENCES,0.5090361445783133,"c0k0k1c′
0k′
0k′
1 Wc1c0k0k1ΣU
m0m1c0k0k1m′
0m′
1c′
0k′
0k′
1Wc′
1c′
0k′
0k′
1."
REFERENCES,0.5120481927710844,"Normal Distribution without Covariances
For the convolutional layer, µ, σ ∈Rc0×n0×n1. µ 7→
µ ∗W + B and σ2 7→σ2 ∗W2."
REFERENCES,0.5150602409638554,"Cauchy Distribution
For the convolutional layer, x0, γ ∈Rc0×n0×n1. x0 7→x0 ∗W + B and
γ 7→γ ∗Abs(W)."
REFERENCES,0.5180722891566265,1Einstein summation notation. The unfolded sliding local blocks are equivalent to torch.unfold.
REFERENCES,0.5210843373493976,Under review as a conference paper at ICLR 2022
REFERENCES,0.5240963855421686,"C
ADDITIONAL EXPERIMENTS"
REFERENCES,0.5271084337349398,"C.1
SIMULATION OF PROPAGATING NORMAL DISTRIBUTIONS"
REFERENCES,0.5301204819277109,"Tab. 6–22 show additional simulations with 1, 2, 4, and 6 hidden layers as well as ReLU, Leaky-ReLU,
GELU, SiLU, and logistic sigmoid activations. Here, the reported metric is intersection of probability
mass, i.e., 1 −TV . The baseline is computed via 106 samples."
REFERENCES,0.5331325301204819,Tab. 23 considers the average ratio between predicted and true standard deviations.
REFERENCES,0.536144578313253,"As there we did not ﬁnd a moment matching method for GELU and SiLU in the literature, we omit
moment matching in these cases. DVIA [27] is only applicable to ReLU among the non-linearities
we consider. For moment matching with logistic sigmoid, we use numerical integration as it does not
have a closed form solution."
REFERENCES,0.5391566265060241,"Table 6: Simulation of propagating normal distributions. The network is a 2 layer ReLU activated
network with dimensions 4-100-3, i.e., 1 ReLU activation."
REFERENCES,0.5421686746987951,"σ
With Covariances
DVIA [27]
Without Covariances
Moment Matching"
REFERENCES,0.5451807228915663,"0.1
0.9874 ± 0.0079
0.9875 ± 0.0074
0.4574 ± 0.0275
0.4552 ± 0.0288
1
0.9578 ± 0.0188
0.9619 ± 0.0165
0.4643 ± 0.0235
0.4439 ± 0.0238
10
0.8648 ± 0.0206
0.8982 ± 0.0247
0.4966 ± 0.0232
0.4580 ± 0.0136
100
0.8157 ± 0.0231
0.8608 ± 0.0353
0.5034 ± 0.0248
0.4640 ± 0.0178
1000
0.8103 ± 0.0236
0.8555 ± 0.0372
0.5041 ± 0.0254
0.4640 ± 0.0182"
REFERENCES,0.5481927710843374,"Table 7: Simulation of propagating normal distributions. The network is a 3 layer ReLU activated
network with dimensions 4-100-100-3, i.e., 2 ReLU activations."
REFERENCES,0.5512048192771084,"σ
With Covariances
DVIA [27]
Without Covariances
Moment Matching"
REFERENCES,0.5542168674698795,"0.1
0.9861 ± 0.0099
0.9840 ± 0.0112
0.3070 ± 0.0185
0.3111 ± 0.0193
1
0.9259 ± 0.0279
0.9247 ± 0.0270
0.3123 ± 0.0133
0.3004 ± 0.0136
10
0.8093 ± 0.0234
0.8276 ± 0.0255
0.3463 ± 0.0206
0.2972 ± 0.0170
100
0.7439 ± 0.0257
0.8152 ± 0.0347
0.3931 ± 0.0207
0.3065 ± 0.0237
1000
0.7373 ± 0.0259
0.8061 ± 0.0384
0.3981 ± 0.0188
0.3079 ± 0.0249"
REFERENCES,0.5572289156626506,"Table 8: Simulation of propagating normal distributions. The network is a 5 layer ReLU activated
network with dimensions 4-100-100-100-100-3, i.e., 4 ReLU activations."
REFERENCES,0.5602409638554217,"σ
With Covariances
DVIA [27]
Without Covariances
Moment Matching"
REFERENCES,0.5632530120481928,"0.1
0.9791 ± 0.0202
0.9720 ± 0.0228
0.2361 ± 0.0250
0.2611 ± 0.0256
1
0.8747 ± 0.0546
0.8519 ± 0.0543
0.2243 ± 0.0237
0.2195 ± 0.0294
10
0.7586 ± 0.0407
0.7035 ± 0.0366
0.2186 ± 0.0244
0.1976 ± 0.0179
100
0.6877 ± 0.0333
0.5845 ± 0.0479
0.2261 ± 0.0282
0.1724 ± 0.0111
1000
0.6808 ± 0.0318
0.5318 ± 0.0516
0.2193 ± 0.0248
0.1706 ± 0.0109"
REFERENCES,0.5662650602409639,"Table 9: Simulation of propagating normal distributions. The network is a 7 layer ReLU activated
network with dimensions 4-100-100-100-100-100-100-3, i.e., 6 ReLU activations."
REFERENCES,0.5692771084337349,"σ
With Covariances
DVIA [27]
Without Covariances
Moment Matching"
REFERENCES,0.572289156626506,"0.1
0.9732 ± 0.0219
0.9660 ± 0.0226
0.2196 ± 0.0208
0.2601 ± 0.0323
1
0.8494 ± 0.0853
0.8166 ± 0.0986
0.2292 ± 0.0303
0.2236 ± 0.0368
10
0.7743 ± 0.0477
0.6309 ± 0.0553
0.2420 ± 0.0295
0.2327 ± 0.0571
100
0.7077 ± 0.0348
0.5265 ± 0.0975
0.3525 ± 0.2337
0.1800 ± 0.0188
1000
0.7013 ± 0.0334
0.5166 ± 0.1223
0.4422 ± 0.2450
0.1764 ± 0.0175"
REFERENCES,0.5753012048192772,Under review as a conference paper at ICLR 2022
REFERENCES,0.5783132530120482,"Table 10: Simulation of propagating normal distributions. The network is a 2 layer Leaky-ReLU
activated network with dimensions 4-100-3, i.e., 1 Leaky-ReLU activation with negative slope
α = 0.1."
REFERENCES,0.5813253012048193,"σ
With Covariances
Without Covariances
Moment Matching"
REFERENCES,0.5843373493975904,"0.1
0.9852 ± 0.0065
0.4484 ± 0.0204
0.4481 ± 0.0208
1
0.9624 ± 0.0152
0.4547 ± 0.0183
0.4417 ± 0.0172
10
0.8876 ± 0.0194
0.4838 ± 0.0198
0.4454 ± 0.0118
100
0.8458 ± 0.0226
0.4912 ± 0.0203
0.4581 ± 0.0139
1000
0.8411 ± 0.0232
0.4918 ± 0.0207
0.4594 ± 0.0141"
REFERENCES,0.5873493975903614,"Table 11: Simulation of propagating normal distributions. The network is a 3 layer Leaky-ReLU
activated network with dimensions 4-100-100-3, i.e., 2 Leaky-ReLU activations with negative
slope α = 0.1."
REFERENCES,0.5903614457831325,"σ
With Covariances
Without Covariances
Moment Matching"
REFERENCES,0.5933734939759037,"0.1
0.9806 ± 0.0085
0.3020 ± 0.0162
0.3063 ± 0.0171
1
0.9324 ± 0.0255
0.3055 ± 0.0129
0.3007 ± 0.0124
10
0.8321 ± 0.0254
0.3343 ± 0.0180
0.2963 ± 0.0147
100
0.7716 ± 0.0294
0.3769 ± 0.0203
0.3040 ± 0.0189
1000
0.7651 ± 0.0297
0.3825 ± 0.0190
0.3056 ± 0.0198"
REFERENCES,0.5963855421686747,"Table 12: Simulation of propagating normal distributions. The network is a 5 layer Leaky-ReLU
activated network with dimensions 4-100-100-100-100-3, i.e., 4 Leaky-ReLU activations
with negative slope α = 0.1."
REFERENCES,0.5993975903614458,"σ
With Covariances
Without Covariances
Moment Matching"
REFERENCES,0.6024096385542169,"0.1
0.9689 ± 0.0163
0.2325 ± 0.0224
0.2566 ± 0.0249
1
0.8856 ± 0.0460
0.2260 ± 0.0197
0.2218 ± 0.0236
10
0.7638 ± 0.0393
0.2146 ± 0.0220
0.1975 ± 0.0169
100
0.6912 ± 0.0352
0.2364 ± 0.0227
0.1756 ± 0.0112
1000
0.6835 ± 0.0337
0.2361 ± 0.0216
0.1743 ± 0.0116"
REFERENCES,0.6054216867469879,"Table 13: Simulation of propagating normal distributions. The network is a 7 layer Leaky-ReLU
activated network with dimensions 4-100-100-100-100-100-100-3, i.e., 6 Leaky-ReLU
activations with negative slope α = 0.1."
REFERENCES,0.608433734939759,"σ
With Covariances
Without Covariances
Moment Matching"
REFERENCES,0.6114457831325302,"0.1
0.9585 ± 0.0203
0.2197 ± 0.0199
0.2519 ± 0.0292
1
0.8573 ± 0.0720
0.2251 ± 0.0289
0.2220 ± 0.0351
10
0.7701 ± 0.0465
0.2332 ± 0.0301
0.2243 ± 0.0259
100
0.7047 ± 0.0378
0.2940 ± 0.1864
0.1779 ± 0.0171
1000
0.6979 ± 0.0371
0.3518 ± 0.2209
0.1746 ± 0.0159"
REFERENCES,0.6144578313253012,Under review as a conference paper at ICLR 2022
REFERENCES,0.6174698795180723,"Table 14: Simulation of propagating normal distri-
butions. The network is a 2 layer SiLU activated
network with dimensions 4-100-3, i.e., 1 SiLU
activation."
REFERENCES,0.6204819277108434,"σ
With Covariances
Without Covariances"
REFERENCES,0.6234939759036144,"0.1
0.9910 ± 0.0025
0.4494 ± 0.0192
1
0.9813 ± 0.0076
0.4550 ± 0.0158
10
0.8635 ± 0.0180
0.5158 ± 0.0251
100
0.8104 ± 0.0201
0.5328 ± 0.0282
1000
0.8050 ± 0.0205
0.5347 ± 0.0288"
REFERENCES,0.6265060240963856,"Table 15: Simulation of propagating normal distri-
butions. The network is a 3 layer SiLU activated
network with dimensions 4-100-100-3, i.e., 2
SiLU activations."
REFERENCES,0.6295180722891566,"σ
With Covariances
Without Covariances"
REFERENCES,0.6325301204819277,"0.1
0.9876 ± 0.0051
0.3056 ± 0.0178
1
0.9658 ± 0.0121
0.3076 ± 0.0122
10
0.8067 ± 0.0136
0.3531 ± 0.0189
100
0.7425 ± 0.0162
0.3806 ± 0.0261
1000
0.7365 ± 0.0167
0.3829 ± 0.0233"
REFERENCES,0.6355421686746988,"Table 16:
Simulation of propagating nor-
mal distributions.
The network is a 5
layer SiLU activated network with dimensions
4-100-100-100-100-3, i.e., 4 SiLU activa-
tions."
REFERENCES,0.6385542168674698,"σ
With Covariances
Without Covariances"
REFERENCES,0.641566265060241,"0.1
0.9704 ± 0.0126
0.2471 ± 0.0277
1
0.9174 ± 0.0343
0.2414 ± 0.0096
10
0.7478 ± 0.0342
0.2357 ± 0.0141
100
0.6846 ± 0.0241
0.2453 ± 0.0254
1000
0.6789 ± 0.0238
0.2371 ± 0.0236"
REFERENCES,0.6445783132530121,"Table 17:
Simulation of propagating nor-
mal distributions.
The network is a
7
layer SiLU activated network with dimensions
4-100-100-100-100-100-100-3, i.e., 6
SiLU activations."
REFERENCES,0.6475903614457831,"σ
With Covariances
Without Covariances"
REFERENCES,0.6506024096385542,"0.1
0.9147 ± 0.0421
0.2326 ± 0.0345
1
0.8248 ± 0.0777
0.2348 ± 0.1062
10
0.7293 ± 0.0388
0.2762 ± 0.1315
100
0.6726 ± 0.0411
0.2326 ± 0.0282
1000
0.6675 ± 0.0417
0.2363 ± 0.0309"
REFERENCES,0.6536144578313253,"Table 18: Simulation of propagating normal dis-
tributions. The network is a 2 layer GELU acti-
vated network with dimensions 4-100-3, i.e., 1
GELU activation."
REFERENCES,0.6566265060240963,"σ
With Covariances
Without Covariances"
REFERENCES,0.6596385542168675,"0.1
0.9875 ± 0.0075
0.4567 ± 0.0317
1
0.9732 ± 0.0096
0.4682 ± 0.0225
10
0.8530 ± 0.0185
0.5204 ± 0.0266
100
0.8039 ± 0.0211
0.5251 ± 0.0278
1000
0.7987 ± 0.0216
0.5255 ± 0.0282"
REFERENCES,0.6626506024096386,"Table 19: Simulation of propagating normal distri-
butions. The network is a 3 layer GELU activated
network with dimensions 4-100-100-3, i.e., 2
GELU activations."
REFERENCES,0.6656626506024096,"σ
With Covariances
Without Covariances"
REFERENCES,0.6686746987951807,"0.1
0.9860 ± 0.0054
0.3065 ± 0.0244
1
0.9453 ± 0.0169
0.3129 ± 0.0164
10
0.8024 ± 0.0128
0.3560 ± 0.0176
100
0.7446 ± 0.0155
0.3966 ± 0.0237
1000
0.7390 ± 0.0159
0.4004 ± 0.0222"
REFERENCES,0.6716867469879518,"Table 20:
Simulation of propagating nor-
mal distributions.
The network is a 5
layer GELU activated network with dimensions
4-100-100-100-100-3, i.e., 4 GELU acti-
vations."
REFERENCES,0.6746987951807228,"σ
With Covariances
Without Covariances"
REFERENCES,0.677710843373494,"0.1
0.9706 ± 0.0104
0.2389 ± 0.0287
1
0.8916 ± 0.0359
0.2442 ± 0.0131
10
0.7607 ± 0.0247
0.2460 ± 0.0220
100
0.6975 ± 0.0184
0.2532 ± 0.0295
1000
0.6915 ± 0.0193
0.2465 ± 0.0288"
REFERENCES,0.6807228915662651,"Table 21:
Simulation of propagating nor-
mal distributions.
The network is a
7
layer GELU activated network with dimensions
4-100-100-100-100-100-100-3, i.e., 6
GELU activations."
REFERENCES,0.6837349397590361,"σ
With Covariances
Without Covariances"
REFERENCES,0.6867469879518072,"0.1
0.9262 ± 0.0294
0.2261 ± 0.0352
1
0.8387 ± 0.0858
0.2710 ± 0.1547
10
0.7342 ± 0.0266
0.3557 ± 0.2025
100
0.6898 ± 0.0218
0.2244 ± 0.0259
1000
0.6854 ± 0.0220
0.2235 ± 0.0264"
REFERENCES,0.6897590361445783,Under review as a conference paper at ICLR 2022
REFERENCES,0.6927710843373494,"Table 22: Simulation of propagating normal distributions. The network is a 5 layer Logistic Sigmoid
activated network with dimensions 4-100-100-100-100-3, i.e., 4 Logistic Sigmoid activations."
REFERENCES,0.6957831325301205,"σ
With Covariances
Without Covariances
Moment Matching"
REFERENCES,0.6987951807228916,"0.1
0.9890
0.7809
0.7793
1
0.9562
0.7880
0.7912
10
0.8647
0.8656
0.7674
100
0.8443
0.8442
0.8027
1000
0.8440
0.8440
0.8070"
REFERENCES,0.7018072289156626,"Table 23: Simulation of propagating normal distributions. The network is a 5 layer ReLU activated
network with dimensions 4-100-100-100-100-3, i.e., 4 ReLU activations. Displayed is the
average ratio between the output standard deviations. The 3 values, correspond to the three output
dimensions of the Iris model.
A value of 1 is optimal. We ﬁnd that both our method with covariances as well as DVIA achieve
a good accuracy in this setting, while the methods which do not consider covariances (ours (w/o
cov.) and Moment Matching) underestimate the output standard deviations by a large factor. For
small input standard deviations, our method w/ cov. as well as DVIA perform better. For large
input standard deviations, our method tends to overestimate the output standard deviation, while
DVIA underestimates the standard deviation. The ratios for our method and DVIA (while going into
opposite directions) are similar, e.g., 2.6095 for our method and 1/0.3375=2.9629 for DVIA."
REFERENCES,0.7048192771084337,"σ
With Cov.
DVIA
Without Cov.
Moment Matching"
REFERENCES,0.7078313253012049,"0.1
0.9933
1.0043
0.9954
0.9904
0.9917
0.9906
0.0126
0.0180
0.0112
0.0255
0.0373
0.0211
1
0.9248
1.0184
0.9598
0.8462
0.9256
0.8739
0.0103
0.0170
0.0100
0.0101
0.0166
0.0097
10
1.9816
2.2526
2.0629
0.6035
0.6664
0.6172
0.0207
0.0359
0.0205
0.0166
0.0269
0.0157
100
2.5404
2.8161
2.6217
0.3721
0.4194
0.3849
0.0264
0.0450
0.0260
0.0186
0.0296
0.0174
1000
2.6095
2.8857
2.6906
0.3375
0.3839
0.3503
0.0271
0.0462
0.0267
0.0188
0.0298
0.0175"
REFERENCES,0.7108433734939759,Under review as a conference paper at ICLR 2022
REFERENCES,0.713855421686747,"10−8
10−6
10−4
10−2
100
102
104"
REFERENCES,0.7168674698795181,Input σ / γ during Training 0.0 0.2 0.4 0.6 0.8 1.0
REFERENCES,0.7198795180722891,"Accuracy
Acc. under noise σ = 0.75
Cauchy distribution
Normal distribution w/o Cov."
REFERENCES,0.7228915662650602,"Normal distribution w/ Cov.
Moment Matching + Dirichlet
Softmax Cross-Entropy"
REFERENCES,0.7259036144578314,"10−8
10−6
10−4
10−2
100
102
104"
REFERENCES,0.7289156626506024,Input σ / γ during Training 0.0 0.2 0.4 0.6 0.8 1.0
REFERENCES,0.7319277108433735,"Accuracy
PGD ǫ = 8/255
Cauchy distribution
Normal distribution w/o Cov."
REFERENCES,0.7349397590361446,"Normal distribution w/ Cov.
Moment Matching + Dirichlet
Softmax Cross-Entropy"
REFERENCES,0.7379518072289156,"Figure 5: Robustness of CNNs on the MNIST data set against Gaussian noise (left) as well as
PGD adversarial noise (right). While Fig. 3 presents σ = 0.5 and ǫ = 16/255, this ﬁgure presents
σ = 0.75 and ǫ = 8/255 The continuous lines show the test accuracy and the dashed lines show the
robust accuracy. The black lines indicate the softmax cross-entropy trained baseline. Results are
averaged over 3 runs."
REFERENCES,0.7409638554216867,"C.2
GAUSSIAN AND ADVERSARIAL NOISE ROBUSTNESS"
REFERENCES,0.7439759036144579,"In Fig. 5, we present an extension to Fig. 3 which demonstrates random and adversarial noise
robustness for alternative noise intensities."
REFERENCES,0.7469879518072289,"In Fig. 9 and 10, we present an additional demonstration of the adversarial and random noise
robustness of CNNs on distributions. Note that we do not include results for normal distributions
with covariances (as in Figures 3 and 5). Here, the emphasis is set on using both MNIST and CIFAR."
REFERENCES,0.75,"In Fig. 6, we show the robustness where a cross-entropy based objective (green) is used by the
adversary. A cross-entropy based objective could be used in practice in multiple scenarios: For
example, publishing just the weights of the model without information about the objective function,
or by using a standard library for adversarial attacks that does not require or support speciﬁcation of
the training objective. We emphasize that our models are more robust against the cross-entropy based
attack (CE-PGD) than the pairwise distribution loss based attack (PA-PGD) which is reported in all
other plots."
REFERENCES,0.7530120481927711,"Note that the phenomenon of vanishing gradients can occur in our models (as it can also occur in any
cross-entropy based model). Thus, we decided to consider all attempted attacks, where the gradient is
zero or zero for some of the pixels in the input image, as successful attacks because the attack might
be mitigated by a lack of gradients. In Fig. 7, we compare conventional robustness to robustness
with the additional Gradient-Non-Zero (GNZ) requirement. We emphasize that we use the GNZ
requirement also in all other plots."
REFERENCES,0.7560240963855421,"For evaluating the robustness against random noise, we use input noise with σ ∈{0.25, 0.5, 0.75}
and clamp the image to the original pixel value range."
REFERENCES,0.7590361445783133,"C.3
PROPAGATING WITHOUT COVARIANCES"
REFERENCES,0.7620481927710844,"We analyze the accuracy of a fully connected neural network (FCNN) where a normal distribution is
introduced in the kth out of 5 layers. Here, the normal distribution is modeled without covariances.
The result is displayed in Fig. 8, where we can observe that there is an optimal scale such that the
accuracy is as large as possible. Further, we can see the behavior if the distribution is not introduced
in the ﬁrst layer, but in a later layer instead. That is, the ﬁrst layers are conventional layers and the
distribution is introduced after a certain number of layers. Here, we can see that the more layers
propagate distributions rather than single values, the larger the optimal standard deviation is. The
reason for this is that the scale of the distribution decays with each layer such that for deep models a
larger input standard deviation is necessary to get an adequate output standard deviation for training
the model. This is because we modeled the distributions without covariances, which demonstrates
that propagating without covariances underestimates the variances."
REFERENCES,0.7650602409638554,Under review as a conference paper at ICLR 2022
REFERENCES,0.7680722891566265,"10−4
10−3
10−2
10−1
100
101
102
103
104"
REFERENCES,0.7710843373493976,Input σ during Training 0.0 0.2 0.4 0.6 0.8 1.0
REFERENCES,0.7740963855421686,CE-based vs. PA-based PGD. (MNIST data set)
REFERENCES,0.7771084337349398,"Accuracy
PA-PGD ǫ = 8/255"
REFERENCES,0.7801204819277109,"CE-PGD ǫ = 8/255
Normal distribution
Cross-Entropy"
REFERENCES,0.7831325301204819,"Figure 6: Softmax Cross-Entropy (CE) vs. pairwise distribution loss (PA) based PGD attack. Averaged
over 3 runs."
REFERENCES,0.786144578313253,"10−4
10−3
10−2
10−1
100
101
102
103
104"
REFERENCES,0.7891566265060241,Input σ during Training 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7
REFERENCES,0.7921686746987951,PGD with vs. without GNZ Requirement. (CIFAR-10 data set)
REFERENCES,0.7951807228915663,"Accuracy
PA-PGD w/ GNZ ǫ = 3/255"
REFERENCES,0.7981927710843374,"PA-PGD w/o GNZ ǫ = 3/255
Normal distribution
Cross-Entropy"
REFERENCES,0.8012048192771084,Figure 7: Effect of the gradient-non-zero (GNZ) requirement. Averaged over 3 runs.
REFERENCES,0.8042168674698795,"10−4
10−3
10−2
10−1
100
101
102
103"
REFERENCES,0.8072289156626506,Input σ during Training 0.1 0.2 0.3 0.4 0.5
REFERENCES,0.8102409638554217,Accuracy
REFERENCES,0.8132530120481928,Introduction of dist. in kth layer. (CIFAR-10 data set)
REFERENCES,0.8162650602409639,"k = 0
k = 1
k = 2
k = 3
k = 4
k = 5
CE"
REFERENCES,0.8192771084337349,"Figure 8: The normal distribution is introduced in the kth layer of a 5 layer fully connected network
(k ∈{0, 1, 2, 3, 4, 5}). Averaged over 3 runs."
REFERENCES,0.822289156626506,Under review as a conference paper at ICLR 2022
REFERENCES,0.8253012048192772,"10−9
10−7
10−5
10−3
10−1
101"
REFERENCES,0.8283132530120482,Input σ during Training 0.0 0.2 0.4 0.6 0.8 1.0
REFERENCES,0.8313253012048193,Adversarial Robustness Cauchy Dist. (MNIST data set)
REFERENCES,0.8343373493975904,"Accuracy
PGD ǫ = 8/255"
REFERENCES,0.8373493975903614,"PGD ǫ = 16/255
Cauchy distribution
Cross-Entropy"
REFERENCES,0.8403614457831325,"10−4
10−3
10−2
10−1
100
101
102
103
104"
REFERENCES,0.8433734939759037,Input σ during Training 0.0 0.2 0.4 0.6 0.8 1.0
REFERENCES,0.8463855421686747,Adversarial Robustness Normal Dist. (MNIST data set)
REFERENCES,0.8493975903614458,"Accuracy
PGD ǫ = 8/255"
REFERENCES,0.8524096385542169,"PGD ǫ = 16/255
Normal distribution
Cross-Entropy"
REFERENCES,0.8554216867469879,"10−9
10−7
10−5
10−3
10−1
101"
REFERENCES,0.858433734939759,Input σ during Training 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7
REFERENCES,0.8614457831325302,Adversarial Robustness Cauchy Dist. (CIFAR-10 data set)
REFERENCES,0.8644578313253012,"Accuracy
PGD ǫ = 3/255"
REFERENCES,0.8674698795180723,"PGD ǫ = 4/255
Cauchy distribution
Cross-Entropy"
REFERENCES,0.8704819277108434,"10−4
10−3
10−2
10−1
100
101
102
103
104"
REFERENCES,0.8734939759036144,Input σ during Training 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7
REFERENCES,0.8765060240963856,Adversarial Robustness Normal Dist. (CIFAR-10 data set)
REFERENCES,0.8795180722891566,"Accuracy
PGD ǫ = 3/255"
REFERENCES,0.8825301204819277,"PGD ǫ = 4/255
Normal distribution
Cross-Entropy"
REFERENCES,0.8855421686746988,"Figure 9: Accuracy and adversarial robustness under PGD attack. Left: Cauchy distribution. Right:
Normal distribution without propagating covariances. Top: MNIST data set. Bottom: CIFAR-10 data
set. Averaged over 3 runs."
REFERENCES,0.8885542168674698,"10−9
10−7
10−5
10−3
10−1
101"
REFERENCES,0.891566265060241,Input γ during Training 0.0 0.2 0.4 0.6 0.8 1.0
REFERENCES,0.8945783132530121,Noise Robustness Cauchy Dist. (MNIST data set)
REFERENCES,0.8975903614457831,"Accuracy
Acc. under noise σ = 0.5
Acc. under noise σ = 0.75
Cauchy distribution
Cross-Entropy"
REFERENCES,0.9006024096385542,"10−4
10−3
10−2
10−1
100
101
102
103
104"
REFERENCES,0.9036144578313253,Input γ during Training 0.0 0.2 0.4 0.6 0.8 1.0
REFERENCES,0.9066265060240963,Noise Robustness Normal Dist. (MNIST data set)
REFERENCES,0.9096385542168675,"Accuracy
Acc. under noise σ = 0.5
Acc. under noise σ = 0.75
Normal distribution
Cross-Entropy"
REFERENCES,0.9126506024096386,"10−9
10−7
10−5
10−3
10−1
101"
REFERENCES,0.9156626506024096,Input γ during Training 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7
REFERENCES,0.9186746987951807,Noise Robustness Cauchy Dist. (CIFAR-10 data set)
REFERENCES,0.9216867469879518,"Accuracy
Acc. under noise σ = 0.25
Acc. under noise σ = 0.5
Cauchy distribution
Cross-Entropy"
REFERENCES,0.9246987951807228,"10−4
10−3
10−2
10−1
100
101
102
103
104"
REFERENCES,0.927710843373494,Input γ during Training 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7
REFERENCES,0.9307228915662651,Noise Robustness Normal Dist. (CIFAR-10 data set)
REFERENCES,0.9337349397590361,"Accuracy
Acc. under noise σ = 0.25
Acc. under noise σ = 0.5
Normal distribution
Cross-Entropy"
REFERENCES,0.9367469879518072,"Figure 10: Accuracy and robustness against random normal noise. Left: Cauchy distribution. Right:
Normal distribution without propagating covariances. Top: MNIST data set. Bottom: CIFAR-10 data
set. Averaged over 3 runs."
REFERENCES,0.9397590361445783,Under review as a conference paper at ICLR 2022
REFERENCES,0.9427710843373494,"D
IMPLEMENTATION DETAILS"
REFERENCES,0.9457831325301205,"D.1
SIMULATION OF PROPAGATING NORMAL DISTRIBUTIONS"
REFERENCES,0.9487951807228916,"We trained a fully-connected neural network with 1, 2, or 4 hidden layers and ReLU / Leaky-ReLU
activations for 5000 epochs on the Iris data set via the softmax cross-entropy loss. Here, each hidden
layer has 100 hidden neurons. Results are averaged over 10 runs, and 10 inputs are propagated for
each of these 10 runs. Across all methods of propagating distributions, each Monte Carlo baseline as
well as model weights are shared."
REFERENCES,0.9518072289156626,"D.2
ALEATORIC UNCERTAINTY QUANTIFICATION"
REFERENCES,0.9548192771084337,"For the aleatoric uncertainty quantiﬁcation experiment, we use the same hyperparameter and
settings as Tagasovska et al. [6].
That is, we use a network with 1 ReLU activated hidden
layer, with 64 hidden neurons and train it for 5000 epochs.
We perform this for 20 seeds
and for a learning rate η ∈{10−2, 10−3, 10−4} and weight decay ∈{0, 10−3, 10−2, 10−1, 1}.
For the input standard deviation, we made a single initial run with input variance σ2
∈
{10−8, 10−7, 10−6, 10−5, 10−4, 10−3, 10−2, 10−1, 100} and then (for each data set) used 11 vari-
ances at a resolution of 100.1 around the best initial variance."
REFERENCES,0.9578313253012049,"D.3
EPISTEMIC UNCERTAINTY FOR SELECTIVE PREDICTION ON OUT-OF-DISTRIBUTION
DATA"
REFERENCES,0.9608433734939759,"Here we use the same network architecture as for the robustness experiments in the next subsection
(A CNN composed of two ReLU-activated convolutional layers with a kernel size of 3, a stride of 2,
and hidden sizes of 64 and 128; followed by a convolutional layer mapping it to an output size of 10)
and also train it for 100 epochs, however, at a learning rate of 10−3. For training with our uncertainty
propagation, we use an input standard deviation of σ = 0.1. For training with uncertainty propagation
via moment matching and the Dirichlet loss as in Gast et al. [11], we use an input standard deviation
of σ = 0.01, which is what they use in their experiments and also performs best in our experiment."
REFERENCES,0.963855421686747,"D.4
GAUSSIAN AND ADVERSARIAL NOISE ROBUSTNESS"
REFERENCES,0.9668674698795181,"Here, our CNN is composed of two ReLU-activated convolutional layers with a kernel size of 3, a
stride of 2, and hidden sizes of 64 and 128. After ﬂattening, this is followed by a convolutional
layer mapping it to an output size of 10. We have trained all models for 100 epochs with an Adam
optimizer, a learning rate of 10−4, and a batch size of 128."
REFERENCES,0.9698795180722891,"D.5
PROPAGATING WITHOUT COVARIANCES"
REFERENCES,0.9728915662650602,The architecture of the 5-layer ReLU-activated FCNN is 784-256-256-256-256-10.
REFERENCES,0.9759036144578314,"D.6
EVALUATION METICS"
REFERENCES,0.9789156626506024,"D.6.1
COMPUTATION OF TOTAL VARIATION IN THE SIMULATION EXPERIMENTS"
REFERENCES,0.9819277108433735,"We compute the total variation using the following procedure: We sample 106 samples from the
continuous propagated distribution. We bin the distributions into 10 × 10 × 10 bins (the output
is 3-dimensional) and compute the total variation for the bins. Here, we have an average of 1000
samples per bin. For each setting, we compute this for 10 input points and on 10 models (trained with
different seeds) each, so the results are averaged over 100 data point / model conﬁgurations. Between
the different methods, we use the same seeds and oracles. To validate that this is reliable, we also
tested propagating 107 samples, which yielded very similar results, but just took longer to compute
the oracle. We also validated the evaluation methods by using a higher bin resolution, which also
yielded very similar results."
REFERENCES,0.9849397590361446,Under review as a conference paper at ICLR 2022
REFERENCES,0.9879518072289156,"D.6.2
COMPUTATION OF MPIW"
REFERENCES,0.9909638554216867,"Given a predicted mean and standard deviation, the Prediction Interval Width (for 95%) can be
computed directly. In a normal distribution, 68.27% of samples lie within 1 standard deviation of
the mean. For covering 95% of a Gaussian distribution, we need to cover ±1.96 standard deviations.
Therefore, the PIW is 3.92 standard deviations. We computed the reported MPIW on the test data set.
This setup follows the setup by Tagasovska et al. [6]."
REFERENCES,0.9939759036144579,"D.7
MAXPOOL"
REFERENCES,0.9969879518072289,"For MaxPool, we apply Equation 1 such that (µ, σ) 7→(max(µ), arg max(µ) · σ) where arg max
yields a one-hot vector. The equation maxpools all inputs to one output; applying it to subsets of
neurons correspondingly maxpools the respective subsets."
