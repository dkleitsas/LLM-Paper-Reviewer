Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.003105590062111801,"There has been signiÔ¨Åcant recent progress designing deep generative models that
generate realistic sequence data such as text or music. Nevertheless, it remains
difÔ¨Åcult to incorporate high-level structure to guide the generative process, and
many such models perform well on local coherence, but less so on global coherence.
We propose a novel approach for incorporating global structure in the form of
relational constraints between different subcomponents of an example (e.g., lines of
a poem or measures of music). Our generative model has two parts: (i) one model to
generate a realistic set of relational constraints, and (ii) a second model to generate
realistic data satisfying these constraints. For model (i), we propose a program
synthesis algorithm that infers the relational constraints present in the training data,
and then learn a generative model based on the resulting constraint data. In our
experiments, we show that our approach signiÔ¨Åcantly improves over state-of-the-art
in terms of capturing high-level structure in the data, while performing comparably
or better in terms of low-level structure."
INTRODUCTION,0.006211180124223602,"1
INTRODUCTION"
INTRODUCTION,0.009316770186335404,"There has been tremendous recent progress in designing deep generative models for generating
sequence data such as natural language (Vaswani et al., 2017) or music (Huang et al., 2019). These
approaches leverage the vast quantities of data available in conjunction with unsupervised and self-
supervised learning to learn probabilistic models of the data; then, new examples can be generated by
sampling from these models, with the possibility of conditioning on initial elements of the sequence."
INTRODUCTION,0.012422360248447204,"A key challenge facing deep generative models is the difÔ¨Åculty incorporating high-level structure
into the generated examples‚Äîe.g., rhyming and meter across lines of a poem, or repetition across
measures of a piece of music. Capturing high-level structure is important for improving the quality
of the generated data, especially in low-data regimes where only small numbers of examples are
available; intuitively, knowledge of the structure compresses the amount of information the generative
model has to learn. Furthermore, explicit representations of structure (i.e., symbolically rather than as
a vector embedding) has the beneÔ¨Åt that users can modify the structure to guide generation."
INTRODUCTION,0.015527950310559006,"Recently, Young et al. (2019) proposed neurosymbolic generative models for incorporating high-level
structure into image generation, focusing on simple 2D repeating patterns in images of building
facades (e.g., repeating windows). The basic idea is to leverage program synthesis to extract structure
from data‚Äîin particular, given an example image x, they devise an algorithm A that extracts a
program c = A(x) that represents the set of 2D repeating patterns present in training examples x.
Then, using the pairs (x, c), they train two generative models: (i) a model pœÜ(c) that generates a
program, and (ii) a model pŒ∏(x | c) that generates an image that contains the structure represented by
c. However, their approach is heavily tailored to images in two ways. First, their representation of
structure is geared towards simple patterns occurring in images of building facades. Second, their
algorithm A is speciÔ¨Åcally designed to extract this kind of program from an image, as are their
models pœÜ(c) for generating programs c and pŒ∏(x | c) for generating images x conditioned on c."
INTRODUCTION,0.018633540372670808,"We represent the relational constraints cx present in an example x by relating each subcomponent w
of a given example x with a prototype Àúw, which can be thought of as the ‚Äúoriginal"" subcomponent
from which w is constructed. In particular, the relationship between w and Àúw is labeled with a set
of relations R, which encodes the constraint that w and Àúw should satisfy relation r for each r ‚ààR."
INTRODUCTION,0.021739130434782608,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.024844720496894408,"Importantly, while each subcomponent is associated with a single prototype, each prototype may be
associated with multiple subcomponents. As a consequence, different subcomponents associated
with the same prototype are related in some way. This representation is compact, only requiring
linearly many constraints in the number of subcomponents in x (assuming the number of prototypes
is constant). Compactness ensures the representation both generalizes well and is easy to generate."
INTRODUCTION,0.027950310559006212,"Then, we design a synthesis algorithm that can extract an optimal representation of the structure
present in a training example x (i.e., the relational constraints cx). We show how to express the
synthesis problem as a constrained combinatorial optimization problem, which we solve using an
SMT solver Z3 (De Moura & Bj√∏rner, 2008). Next, we represent relational constraints c as sequences,
and design the model pœÜ(c) to be a specialized sequence VAE. Finally, we propose three possible
designs of pŒ∏(x | c), all of which try to identify an example x that is realistic (e.g., according to a
pretrained model pŒ∏(x)) while simultaneously satisÔ¨Åes the given constraints c."
INTRODUCTION,0.031055900621118012,"We evaluate our approach on two tasks: poetry generation, where the relational constraints include
rhyming lines or lines with shared meter, and music generation, where the relational constraints
include equality in terms of pitch or rhythm, that one measure is a transposition of another (i.e.,
pitches shifted up or down by a constant amount), etc. We show that our approaches outperform
or perform similarly to state-of-the-art models in terms of low-level structure, while signiÔ¨Åcantly
outperforming them in terms of high-level structure. We also perform a user study in the poetry
domain to determine user-perceived quality of the generated poetry along three dimensions (structure,
lyricism, and coherence), and found that on average, our approach outperformed state-of-the-art
baselines including GPT-2. Finally, we demonstrate how our approach allows users to guide the
generation process without sacriÔ¨Åcing overall realism by specifying values of constraints."
INTRODUCTION,0.034161490683229816,"Example. Figure 1 illustrates how our approach is applied to generate poetry. During training, our
approach uses program synthesis to infer relational constraints cx present in the examples x, and uses
both x and cx to train the generative models. Here, cx is a bipartite graph, where the LHS vertices
are prototypes, and the RHS vertices correspond to lines of x. Each vertex on the right is connected
to exactly one prototype, and is labeled with constraints on how it should relate to its prototype. To
generate new examples, it Ô¨Årst samples relational constraints c, and then samples an example x that
satisÔ¨Åes c‚Äîi.e., we need to choose a line to Ô¨Åll each RHS node in a way that the line satisÔ¨Åes the
relations with its prototype. Furthermore, a user can modify the sampled constraint c to guide the
generative process. Thus, our approach enables users to Ô¨Çexibly incorporate domain knowledge
on the high-level structure of the data into the generative process, both in terms of the relational
constraints included and by allowing them to modify the generated relational constraints."
INTRODUCTION,0.037267080745341616,"Related work. There has been recent work using program synthesis to improve machine learning.
For instance, it has been applied to unsupervised learning of latent structure in drawings (Ellis
et al., 2015) and to reinforcement learning (Verma et al., 2018). These techniques have beneÔ¨Åts
such as improving interpretability (Verma et al., 2018; Ellis et al., 2020), enabling learning from
fewer examples (Ellis et al., 2015), generalizing more robustly (Inala et al., 2019), and being easier
to formally verify (Bastani et al., 2018). More recently, there has been work leveraging program
synthesis in conjunction with deep learning, where the DNN handles perception and program synthesis
handles high-level structure (Ellis et al., 2017), including work in the lifelong learning setting (Valkov
et al., 2018). In contrast to these approaches, our focus is on generative models. In particular, we
extend recent work leveraging these ideas for image generation to incorporating high-level relational
structure into sequence generation tasks (Young et al., 2019). Finally, much research over the past
few decades has focused on music and poetry generation, and on using relational constraints in neural
models; we include a discussion of the most relevant such research in Appendix A."
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.040372670807453416,"2
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.043478260869565216,"Consider the problem of learning a generative model given training data from the underlying distri-
bution. Given training examples x1, ..., xk ‚àºp‚àó, our goal is to learn a generative model pŒ∏ ‚âàp‚àó
from which we can draw additional samples x ‚àºpŒ∏. We consider sequence data‚Äîi.e., an example
x ‚ààX is a sequence x = (w1, ..., wm) ‚ààWm.1 For example, each subcomponent w may be a line
of a poem or a measure of music, and x may be a poem or song."
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.046583850931677016,1We use a Ô¨Åxed m to simplify our exposition; our approach trivially extends to variable m.
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.049689440993788817,Under review as a conference paper at ICLR 2022
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.052795031055900624,Sample Relational Constraints
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.055900621118012424,ùëê‚àºùëù! ‚ãÖùëß
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.059006211180124224,Sample Example
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.062111801242236024,"ùë•‚àºùëù"" ‚ãÖùëê
Sample Latent Vector ùëß‚àºùëù‚ãÖ"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.06521739130434782,"rhymes, meter
rhymes, meter ùëß= 0.5"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.06832298136645963,"‚Ä¶
‚àí1.2"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.07142857142857142,"Music to song, on the city air
A little music to live upon
Song, a song, yes, yes, a long with the sun,
And all together if they are all ten,
Until all is ready for men again and then,
To the capital I hall ride with chase,
And look like men tied full all around
You, and whisper that I shall found,
Though I‚Äôm not built upon a little dome,
I say, I made a home, I make a roam."
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.07453416149068323,"Music to song, on the city air"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.07763975155279502,A little music to live upon
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.08074534161490683,"rhymes, meter
Song, a song, yes, yes, a long with the sun,"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.08385093167701864,"Until all is ready for men again and then,"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.08695652173913043,"To the capital I hall ride with chase,"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.09006211180124224,And look like men tied full all around
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.09316770186335403,"Though I‚Äôm not built upon a little dome,"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.09627329192546584,"rhymes
rhymes, meter
rhymes, meter
rhymes, meter
rhymes
rhymes, meter
rhymes"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.09937888198757763,"""Father,"" I said, ""Father, I cannot play
The harp that thou didst give me, and all day
I sit in idleness, while to and fro
About me thy serene, grave servants go;
And I am weary of my lonely ease.
Better a perilous journey overseas
Away from thee, than this, the life I lead,
To sit all day in the sunshine like a weed
That grows to naught‚ÄîI love thee more than they 
Who serve thee most; yet serve thee in no way"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.10248447204968944,"Training Example ùë•
Relational Constraints ùëê#"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.10559006211180125,"The harp that thou didst give me, and all day"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.10869565217391304,"I sit in idleness, while to and fro"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.11180124223602485,And I am weary of my lonely ease.
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.11490683229813664,"Away from thee, than this, the life I lead,"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.11801242236024845,"rhymes, meter
rhymes"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.12111801242236025,"rhymes, meter"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.12422360248447205,rhymes
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.12732919254658384,"rhymes, meter"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.13043478260869565,"rhymes, meter"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.13354037267080746,"rhymes, meter
rhymes"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.13664596273291926,"rhymes, meter"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.13975155279503104,"rhymes, meter"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.14285714285714285,"Figure 1: Top: For each training example x, our algorithm uses program synthesis to infer the
relational constraints cx = A(x) present in x. Then, it uses cx and x to train pœÜ(cx) and pŒ∏(x | cx).
Bottom: Process for generating a sample x from the learned VAE pœÜ(cx | z) (where z is Gaussian
noise) and model pŒ∏(x | cx). Lines with the same prototype are shown in the same color; metrical
constraints are represented as purple and rhyme constraints as green edges."
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.14596273291925466,"We are interested in domains where likely examples satisfy latent relational constraints c ‚ààC over
the subcomponents. For instance, c may say that two measures wi and wj of x start with the same
series of pitches, or that two lines wi and wj of x rhyme. We assume given a set of relations R (e.g.,
r ‚ààR might be ‚Äúrhyme‚Äù or ‚Äúequal‚Äù), and a function f : W √ó W √ó R ‚Üí[0, 1] such that f(w, w‚Ä≤, r)
indicates to what extent w and w‚Ä≤ satisfy relation r. Then, c is a compact representation of the
relations present in an input x. We describe the structure of c in detail in Section 3.1; for now, the
approach we describe works for any choice of c. In particular, we build on neurosymbolic generative
models (Young et al., 2019), where c is itself generated based on a latent value z ‚ààZ‚Äîi.e.,"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.14906832298136646,"pŒ∏,œÜ(x) =
Z X"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.15217391304347827,"c‚ààC
pŒ∏(x | c) ¬∑ pœÜ(c | z) ¬∑ p(z)dz."
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.15527950310559005,"Then, Young et al. (2019) considers the variational distribution"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.15838509316770186,"q ÀúœÜ(c, z | x) = q ÀúœÜ(z | c) ¬∑ q(c | x)
and
q(c | x) = Œ¥(c ‚àícx)."
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.16149068322981366,"Here, Œ¥ is the Dirac delta function and cx is a single representative generated from x using a program
synthesis algorithm (David & Kroening, 2017)‚Äîi.e., an algorithm A that takes as input an example
x and outputs a program c = A(x) encoding the relational constraints present in x. Next, Young
et al. (2019) derive an evidence lower bound"
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.16459627329192547,"log pŒ∏,œÜ(x) ‚â•log pŒ∏(x | cx) + Eq Àú
œÜ(z|cx)[log pœÜ(cx | z)] ‚àíDKL(q ÀúœÜ(z | cx) ‚à•p(z))."
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.16770186335403728,"where DKL is the KL divergence and H is information entropy. The Ô¨Årst term is the log-likelihood
of a generative model predicting the probability of example x given relational constraints cx, and
the second and third terms form the loss of a variational autoencoder (VAE) pœÜ(c | z) and q ÀúœÜ(z |
c) (Kingma & Welling, 2019). In summary, given training examples x ‚ààX, this approach separately
learns (i) a VAE to generate c, trained on the relational constraints cx synthesized from each training
example x, and (ii) a model to generate x given cx; the latter can take multiple forms such as a second
VAE or a generative adversarial network (GAN) (Goodfellow et al., 2014). This approach is called
synthesis-guided generative models (SGM) since it uses program synthesis to guide training."
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.17080745341614906,Under review as a conference paper at ICLR 2022
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.17391304347826086,"To leverage this framework, we have to instantiate (i) the space of relational constraints C, (ii) the
synthesis algorithm A : X ‚ÜíC used to extract a program encoding the structure of x, and (iii) the
architectures of pœÜ(c | z), q ÀúœÜ(z | c), and pŒ∏(x | c). In prior work, Young et al. (2019) used heuristics
speciÔ¨Åc to the the image domain to achieve these goals‚Äîin particular, they used (i) simple equality
constraints on sub-regions of the image designed to capture 2D repeating patterns, (ii) a custom
synthesis algorithm that greedily adds constraints in the data to the program, and (iii) a representation
of cx as an image, in which case pŒ∏ is a generative model over images, and pœÜ, q ÀúœÜ based on an
encoding of c as a Ô¨Åxed-length vector."
BACKGROUND ON NEUROSYMBOLIC GENERATIVE MODELS,0.17701863354037267,"We design a synthesis algorithm that expresses the synthesis problem as a constrained combinatorial
optimization problem, which it solves using an SMT solver called Z3 (De Moura & Bj√∏rner, 2008).
In terms of (iii), our programs encode declarative constraints rather than imperative renderings, so
the previous architectures of pœÜ, and q ÀúœÜ cannot be used. Instead, we use expert domain-speciÔ¨Åc
heuristics, transformers (Vaswani et al., 2017), or graph neural networks (GNNs) (Kipf & Welling,
2017) for pœÜ and q ÀúœÜ. For pŒ∏, we propose several methods for imposing the constraints encoded by c
when generating an example x."
RELATIONAL CONSTRAINTS FOR SEQUENCE DATA,0.18012422360248448,"3
RELATIONAL CONSTRAINTS FOR SEQUENCE DATA"
RELATIONAL CONSTRAINTS FOR SEQUENCE DATA,0.18322981366459629,"We describe how we represent relational constraints r, as well as our algorithm A for synthesizing
the relational constraints cx = A(x) present in an example sequence x."
GRAPH REPRESENTATION OF RELATIONAL CONSTRAINTS,0.18633540372670807,"3.1
GRAPH REPRESENTATION OF RELATIONAL CONSTRAINTS"
GRAPH REPRESENTATION OF RELATIONAL CONSTRAINTS,0.18944099378881987,"Recall that our generative model operates by Ô¨Årst generating a relational program c, and then
generating an example x that satisÔ¨Åes c. Thus, for each training example x, we need to design a
relational program c that encode constraints on the structure of x. A program c encodes a set of
relational constraints, each of which imposes a constraint that subcomponents of x should have
certain kinds of relations. We begin by describing the structure of a single relational constraint, and
then describe how c encodes a set of relational constraints."
GRAPH REPRESENTATION OF RELATIONAL CONSTRAINTS,0.19254658385093168,"A relational constraint œÜ ‚ààŒ¶ = W √ó I √ó R, where I = {1, ..., m}, is a tuple œÜ = ( Àúw, i, r); we
call Àúw ‚ààW a prototype subcomponent. An example x satisÔ¨Åes œÜ to extent h (denoted x |=h œÜ) if
f( Àúw, wi, r) = h, where wi is the ith subcomponent of x. That is, œÜ says the ith subcomponent wi
of x should have relation r with prototype subcomponent Àúw. Thus, we can interpret œÜ as a function
œÜ : X ‚Üí[0, 1], where œÜ(x) = 1 if x satisÔ¨Åes œÜ to the maximal extent and œÜ(x) = 0 if x does not
satisfy œÜ at all."
GRAPH REPRESENTATION OF RELATIONAL CONSTRAINTS,0.1956521739130435,"Next, a relational program c encodes a set of relational constraints on examples x. We represent c as an
undirected labeled bipartite graph c = ( ÀúV , V, E) with vertices ÀúV and V and edges E ‚äÜÀúV √ó V √ó 2R,
where R is the set of relations and 2R is the power set of R. The vertices Àúw ‚ààÀúV are prototype
subcomponents Àúw ‚ààW; equivalently, they may be vector embeddings of prototype subcomponents.
The vertices i ‚ààV = {1, ..., m} are the indices of subcomponents in x. The edges e ‚ààE are tuples
e = ( Àúw, i, R), where R = [0, 1]|R|. For tractability of synthesis, we impose the constraint that each
v ‚ààV is part of a single edge ( Àúw, v, R) (though Àúv ‚ààÀúV may be part of multiple edges). Finally, c
encodes the set of relational constraints"
GRAPH REPRESENTATION OF RELATIONAL CONSTRAINTS,0.19875776397515527,"Œ¶c = {( Àúw, i, r, h) | ( Àúw, i, R) ‚ààE ‚àßR[r] = h} ."
GRAPH REPRESENTATION OF RELATIONAL CONSTRAINTS,0.20186335403726707,"In other words, c includes the relational constraint that each subcomponent wi of x should have all
relations r ‚ààR with prototype Àúw to extent h, where v is connected to Àúw."
GRAPH REPRESENTATION OF RELATIONAL CONSTRAINTS,0.20496894409937888,"In this paper, for most examples, we consider binary relationships that have 0 or 1 as values, and
informally state that a pair Àúw, i does not have a relationship r if f( Àúw, i, r) = 0. However, as we show
in our experiments, non-boolean functions with values between 0 and 1 can be used as well."
GRAPH REPRESENTATION OF RELATIONAL CONSTRAINTS,0.2080745341614907,"For example, in Figure 1, the graph shown on the top right encodes a relational constraint cx, and the
top right shows an example x that satisÔ¨Åes all the constraints œÜ ‚ààŒ¶cx with a value greater than 0.
The nodes on the left-hand side of cx are prototype subcomponents Àúw ‚ààW, each of which is a line
of poetry. The nodes on the right-hand side correspond to indices i (from i = 1 on top to i = m = 10"
GRAPH REPRESENTATION OF RELATIONAL CONSTRAINTS,0.2111801242236025,Under review as a conference paper at ICLR 2022
GRAPH REPRESENTATION OF RELATIONAL CONSTRAINTS,0.21428571428571427,"on the bottom); each one is labeled with a set of relations Ri. Then, Œ¶cx contains constraints
œÜ = ( Àúw, i, Ri) for each edge Àúw ‚Üíi in the graph, which says that line i of x should have relations
r ‚ààRi with Àúw. For instance, the last (10th) node in cx has constraints R10 = {rhyme, meter}, and
is connected to prototype line Àúw =‚ÄúThe harp that thou...‚Äù. Thus, this edge encodes a constraint
œÜ = ( Àúw, 10, R10) saying that the last line of x should rhyme and have the same meter as Àúw. Indeed,
the last line of x is w10 =‚ÄúWho serve thee most...‚Äù, which satisÔ¨Åes this constraint.
Remark 3.1. We use prototypes rather than direct relationships between components to ensure the
size of the graph is tractable‚Äîwith this choice, the graph is linear in the size of the input (assuming the
number of prototypes is constant) rather than quadratic. A compact graph is both each to synthesize
(for training) and train a model to generate (for generation). In our experiments, we show that our
approach signiÔ¨Åcantly outperforms attempting to generate full graphs (i.e., adjacency tensors).
Remark 3.2. We refer to c as a program since it can be interpreted as a Datalog program (Ceri et al.,
1989) (i.e., a relational logic program); in particular, Œ¶c is a set of Datalog relations over x ‚ààX."
SYNTHESIZING RELATIONAL CONSTRAINTS,0.21739130434782608,"3.2
SYNTHESIZING RELATIONAL CONSTRAINTS"
SYNTHESIZING RELATIONAL CONSTRAINTS,0.2204968944099379,"Recall that when training our generative model, we need to design a program synthesis algorithm A
that synthesizes a relational program cx = A(x) that best encodes the latent relational constraints
present in each training example x. A key question is where the prototypes come from. We simply
choose the prototypes Àúw to be actual subcomponents in x. Thus, cx encodes that subcomponents of x
are each related to one of a small number of distinguished subcomponents of x. As described below,
we formulate the problem of synthesizing cx as a constrained optimization problem."
SYNTHESIZING RELATIONAL CONSTRAINTS,0.2236024844720497,"Optimization variables. The variables are a binary vector H ‚ààBm and a binary matrix K ‚ààBm√óm.
Intuitively, Hi indicates whether subcomponent wi of x is a prototype subcomponent in c, and Kij
indicates whether wi is the prototype for subcomponent wj."
SYNTHESIZING RELATIONAL CONSTRAINTS,0.2267080745341615,Constraints. Our optimization problem has the following three constraints:
SYNTHESIZING RELATIONAL CONSTRAINTS,0.22981366459627328,"œà1 ‚â°kmin ‚â§ m
X"
SYNTHESIZING RELATIONAL CONSTRAINTS,0.2329192546583851,"i=1
Hi ‚â§kmax,
œà2 ‚â° m
^ j=1 m
X"
SYNTHESIZING RELATIONAL CONSTRAINTS,0.2360248447204969,"i=1
Kij = 1,
œà3 ‚â° m
^ i=1 m
X"
SYNTHESIZING RELATIONAL CONSTRAINTS,0.2391304347826087,"j=1
Kij ‚â§m ¬∑ Hi."
SYNTHESIZING RELATIONAL CONSTRAINTS,0.2422360248447205,"First, œà1 says that the number of prototype subcomponents is between kmin and kmax. Next, œà2 says
that every subcomponent wj corresponds to exactly one prototype subcomponent wi. Finally, œà3
says that for every i, if wi is the prototype subcomponent of wj according to K, then it must be a
prototype subcomponent according to H as well."
SYNTHESIZING RELATIONAL CONSTRAINTS,0.2453416149068323,"Objective. The objective of our optimization problem is expressed in terms of a precomputed
distance matrix D ‚ààRm√óm, where Dij measures the similarity between components wi and wj;
smaller values indicate a greater degree of similarity. In particular, we deÔ¨Åne"
SYNTHESIZING RELATIONAL CONSTRAINTS,0.2484472049689441,"Dij =
1
P
r‚ààR(f(wi, wj, r)),"
SYNTHESIZING RELATIONAL CONSTRAINTS,0.2515527950310559,"i.e., Dij is the extent to which each r ‚ààR are not satisÔ¨Åed by wi and wj. Then, our objective (which
is to be minimized) has the following three terms: J1 = m
X"
SYNTHESIZING RELATIONAL CONSTRAINTS,0.2546583850931677,"i,j=1
Kij ¬∑ Dij,
J2 = m
X i,j=1 Y"
SYNTHESIZING RELATIONAL CONSTRAINTS,0.2577639751552795,"k
Kki ¬∑ Kkj !"
SYNTHESIZING RELATIONAL CONSTRAINTS,0.2608695652173913,"¬∑ Dij,
J3 = ‚àí m
X"
SYNTHESIZING RELATIONAL CONSTRAINTS,0.2639751552795031,"i,j=1
Hi ¬∑ Hj ¬∑ Dij."
SYNTHESIZING RELATIONAL CONSTRAINTS,0.2670807453416149,"First, J1 says that subcomponents should be similar to their prototypes. Second, J2 says that
subcomponents should also be similar to other subcomponents that share the same prototype. Third,
J3 says that different prototype subcomponents should be dissimilar."
SYNTHESIZING RELATIONAL CONSTRAINTS,0.2701863354037267,Optimization problem. Our algorithm A uses Z3 to solve the optimization problem
SYNTHESIZING RELATIONAL CONSTRAINTS,0.2732919254658385,"(H‚àó, K‚àó) = arg min
H,K
{Œª1 ¬∑ J1 + Œª2 ¬∑ J2 + Œª3 ¬∑ J3}
subj. to
œà1 ‚àßœà2 ‚àßœà3,
(1)"
SYNTHESIZING RELATIONAL CONSTRAINTS,0.27639751552795033,"where Œª1, Œª2, Œª3 ‚ààR‚â•0 are hyperparameters. Finally, to construct cx, A chooses"
SYNTHESIZING RELATIONAL CONSTRAINTS,0.2795031055900621,"ÀúV = {wi | H‚àó
i = 1},
V = {1, ..., m},
E = {(wi, j, Rij) | K‚àó
ij = 1},"
SYNTHESIZING RELATIONAL CONSTRAINTS,0.2826086956521739,Under review as a conference paper at ICLR 2022
SYNTHESIZING RELATIONAL CONSTRAINTS,0.2857142857142857,"where Rij = {r ‚ààR | f(wi, wj, r) = 1}‚Äîi.e., ÀúV are the prototype subcomponents according to
H‚àó, E are the edges according to K‚àó, and Rij are the extent to which relations are satisÔ¨Åed by wi
and wj. Z3 is guaranteed to Ô¨Ånd the optimal solution; in the event that multiple such solutions exist,
it chooses one nondeterministically. Intuitively, our approach should perform well when a handful of
prototypes are sufÔ¨Åcient to approximately capture the relational structure in the data, which appears
to be true in the domains of rhyming poetry and melodies. Also, the user can deÔ¨Åne relations in a
way that captures desired structure for any domain."
RELATIONAL CONSTRAINTS IN NEUROSYMBOLIC GENERATIVE MODELS,0.2888198757763975,"4
RELATIONAL CONSTRAINTS IN NEUROSYMBOLIC GENERATIVE MODELS"
RELATIONAL CONSTRAINTS IN NEUROSYMBOLIC GENERATIVE MODELS,0.2919254658385093,"We describe our model for generating examples x. Recall that our approach proceeds in two steps: (i)
generate c, and (ii) generate x given Œ¶c. We describe each step in detail below."
RELATIONAL CONSTRAINTS IN NEUROSYMBOLIC GENERATIVE MODELS,0.2950310559006211,"4.1
STEP 1: GENERATING RELATIONAL CONSTRAINTS"
RELATIONAL CONSTRAINTS IN NEUROSYMBOLIC GENERATIVE MODELS,0.2981366459627329,"The Ô¨Årst step of our generative model is to generate relational constraints Œ¶c using a VAE‚Äîi.e.,
pœÜ(c | z) is a VAE with p(z) = N(z; 0, I) being a Gaussian distribution. The main choice is
the architecture to use for the VAE. In particular, we consider a representation of c as a sequence
(s1, ..., sm), where si ‚àà{0, 1, ..., k} for each i; intuitively, si encodes that subcomponent wi should
have the same prototype subcomponent as wi‚àísi, or if si ‚â§0, that wi corresponds to a new prototype
subcomponent. In practice, we found that in the music domain, the vast majority of examples could
be described using k ‚â§6, which decreased the number of possible values that could be predicted and
simpliÔ¨Åed the problem; however, it would be possible in other domains for k to be as large as m ‚àí1."
RELATIONAL CONSTRAINTS IN NEUROSYMBOLIC GENERATIVE MODELS,0.30124223602484473,"More precisely, we initialize Œ¶c = ‚àÖ. Then, we generate the sequence si ‚àà{0, 1, ..., k} and
ri ‚àà{0, 1, ..., m} (where ri is represented as a binary vector of length n = |R|) using either: (i) an
LSTM-VAE, or (ii) a feedforward network whose output is iteratively sampled from as a categorical
distribution and then used as input in the next step (see Appendix C.1 for details). For each i, we
generate ( Àúw, Ri) based on si and ri according to the following approach: If si = 0, we generate a
new prototype subcomponent Àúw using a domain-speciÔ¨Åc generative model, and add œÜi = ( Àúwi, i, Ri)
to Œ¶c. If si > 0, we let œÜi = ( Àúwi‚àísi, i, Ri)."
RELATIONAL CONSTRAINTS IN NEUROSYMBOLIC GENERATIVE MODELS,0.30434782608695654,"4.2
STEP 2: GENERATING EXAMPLES GIVEN RELATIONAL CONSTRAINTS"
RELATIONAL CONSTRAINTS IN NEUROSYMBOLIC GENERATIVE MODELS,0.30745341614906835,"Next, we describe how we implement the second step pŒ∏(x | c) of our generative model. We propose
three approaches for generating x given Œ¶c; we give details in Appendix B."
RELATIONAL CONSTRAINTS IN NEUROSYMBOLIC GENERATIVE MODELS,0.3105590062111801,"Approach 1: Constrained sampling. We sample values x ‚àºpŒ∏(¬∑) by sequentially sampling wi ‚àº
pŒ∏(¬∑) from a pretrained generative model pŒ∏(w). We do so using rejection sampling at each step‚Äîi.e.,
we sample wi ‚àºpŒ∏(¬∑) until we Ô¨Ånd wi satisfying f( Àúw, wi, r) ‚âàh for each ( Àúw, i, r, h) ‚ààŒ¶c. In
addition, to speed up sampling, at each step of sampling wi (e.g., a word in a line or a pitch in a
measure), we eliminate choices that violate Œ¶c."
RELATIONAL CONSTRAINTS IN NEUROSYMBOLIC GENERATIVE MODELS,0.3136645962732919,"Approach 2: Constraint-aware embeddings. We train a conditional variational autoencoder
(cVAE) pŒ∏(w1, ..., wm | c) in the form of a graph convolutional network (GCN) that simultaneously
generates all m subcomponents in a way that satisÔ¨Åes c, and sample x = (w1, ..., wm) ‚àºpŒ∏(¬∑ | c).
The GCN takes as input embeddings of each prototype and subcomponent of x, and the adjacency
matrix is given by the edges in c (where the relation is encoded as an edge attribute). Then, the
GCN-cVAE is trained using the standard VAE objective (Kingma & Welling, 2019), along with a
semantic consistency loss that encourages the generated examples to satisfy c."
RELATIONAL CONSTRAINTS IN NEUROSYMBOLIC GENERATIVE MODELS,0.3167701863354037,"Approach 3: Combinatorial optimization. We sample x ‚àºpŒ∏(¬∑) by sequentially generating wi by
solving an optimization problem whose objective is to maximize adherence to Œ¶c plus additional
terms encoding domain-speciÔ¨Åc heuristics encouraging wi to be realistic."
EXPERIMENTS,0.3198757763975155,"5
EXPERIMENTS"
EXPERIMENTS,0.32298136645962733,"We evaluate our approach on two domains: music and poetry generation. We provide details on
experimental design and additional results in Appendix C."
EXPERIMENTS,0.32608695652173914,Under review as a conference paper at ICLR 2022
EXPERIMENTS,0.32919254658385094,"Models
NLL
GCN Disc.
RF"
EXPERIMENTS,0.33229813664596275,"SGM (Ours) (A2)
1028.4
0.63
0.79
MusicVAE
1158.6
0.50
0.85
MusicAutobot
1760.0
0.51
0.95"
EXPERIMENTS,0.33540372670807456,"Models
FD
GCN Disc.
RF"
EXPERIMENTS,0.3385093167701863,"SGM (Ours) (A1)
43.4
0.54
0.89
SGM (Ours) (A2)
32.7
0.63
0.79
SGM (Ours) (A3)
37.5
0.43
0.91
SGM (Ours) (A2, No Synth. Ablation)
42.1
0.42
0.89
SGM (Ours) (A2, Greedy Synth. Ablation)
40.5
0.50
0.88
SGM (Ours) (A2, Continuous Relation)
33.2
0.46
0.88
Attention-RNN
39.9
0.47
0.88
MusicAutobot
53.7
0.51
0.95
StructureNet
44.0
0.45
0.91"
EXPERIMENTS,0.3416149068322981,"Table 1: Results for the music domain. Left: We show negative log-likelihood (‚ÄúNLL‚Äù, lower is
better) on the held-out human test set (i.e., by estimating the ELBo using sampling). Right: We show
Fr√©chet distance on MusicVAE embeddings (‚ÄúFD‚Äù, lower is better). Both: We show the cross-entropy
loss of the graph discriminator trained to distinguish synthesized programs of generated examples
vs. held-out test set examples (‚ÄúGCN Disc.‚Äù, higher is better), and the accuracy of a random forest
trained to do the same thing on a handcrafted featurization of the programs (‚ÄúRF‚Äù, lower is better).
The highest score in each column is bolded. As can be seen, our approach with sampling strategy A2
outperforms the baselines on all metrics, also outperforming the ablation using the same strategy but
without program synthesis (i.e., using the full adjacency tensor)."
MUSIC GENERATION,0.3447204968944099,"5.1
MUSIC GENERATION"
MUSIC GENERATION,0.34782608695652173,"We evaluated our approach on a music generation, where x is a song and w are measures of music.
We consider 20 relations including equality, same rhythm, etc.; see Appendix C.2."
MUSIC GENERATION,0.35093167701863354,"Dataset. We used songs from the Essen folk song corpus (Schaffrath, 1995), using 2223 for
training and 555 for testing (after removing examples with less than 16 measures or that were
not in the standard 4/4 meter). For this dataset, we used each of the three approaches A1, A2,
and A3 described in Section 4 to sample x ‚àºpŒ∏(¬∑ | c). For A1, we use a pretrained transformer
called MusicAutoBot (Shaw, 2020). For A2, we require a generative model that constructs vector
embeddings of measures; we use the pretrained version of Magenta‚Äôs MusicVAE which embeds
pairs of measures (Roberts et al., 2018) and adapted it to produce single-measure embeddings. We
Ô¨Ånetune all models on our training examples."
MUSIC GENERATION,0.35403726708074534,"Baselines. We compare to MusicAutoBot, a pretrained and Ô¨Ånetuned attention LSTM (Attention-
RNN) (Waite, 2016), Magenta‚Äôs 16-bar MusicVAE (pretrained and Ô¨Ånetuned), and StructureNet,
which integrates structure into an LSTM (Medeot et al., 2018). To show the importance of synthesis,
we compare to an ablation that uses A2 but with full adjacency tensors instead of synthesizing
compact representations of relational constraints, and one that uses a greedy synthesizer‚Äîi.e., at
each step, greedily choose the single prototype and its relations that most increases (1). Finally, we
consider using a continuous relation, namely, the cosine similarity of the MagentaVAE embeddings."
MUSIC GENERATION,0.35714285714285715,"Metrics. We compare performance in terms of both high-level and low-level structure. For low-
level structure, we use the negative log likelihood (NLL) on a held-out test set for MusicVAE,
MusicAutobot, and our approach with strategy A2. The remaining approaches are not probabilistic
(or estimating probabilities is intractable). For these approaches, we use a variant of the standard
Fr√©chet distance (FD) score used to evaluate GANs (Borji, 2019)‚Äîi.e., the Fr√©chet distance between
the MusicVAE (16-bar) embeddings of the generated music and the held-out test set."
MUSIC GENERATION,0.36024844720496896,"For high-level structure, given a generated (or human) example x, we use our synthesis algorithm to
synthesize its relational constraints cx = A(x). Then, given a collection Cgen = {cx | x ‚ààXgen} of
synthesized structure for generated examples, along with a collection Chuman = {cx | x ‚ààXhuman} of
synthesized structure for the held-out human examples, we train a graph convolutional neural network
(GCN) to try and discriminate Cgen from Chuman, as well as a random forest (RF) over handcrafted
features (see Appendix C.4). Intuitively, higher discriminative power should indicate less realistic
structure. In both cases, we use a balanced dataset (i.e., 50% human held-out and 50% generated) so
random predictions have accuracy 0.5. Recent work has shown that such discriminator-based metrics
are valid for evaluating quality of generated examples (Lopez-Paz & Oquab, 2016)."
MUSIC GENERATION,0.36335403726708076,"Results. In Table 1, we show results for models for which we can compute the test set NLL (left)
and results for the remaining models (right). As can be seen, our approach (SGM) with sampling"
MUSIC GENERATION,0.36645962732919257,Under review as a conference paper at ICLR 2022
MUSIC GENERATION,0.3695652173913043,"Models
GCN Disc.
FD"
MUSIC GENERATION,0.37267080745341613,"SGM (Ours, A1)
0.69
21.5
SGM (Ours, A3)
0.62
13.51
SGM (No Learned Structure Ablation)
0.59
21.2
GPT2
0.47
14.3
GPT2-Opt
0.56
14.4
BERT
0.50
54.9
RichLyrics
0.51
23.0"
MUSIC GENERATION,0.37577639751552794,"Table 2: Results for the poetry domain. We show Fr√©chet distance on SentenceBERT embeddings
(‚ÄúFD‚Äù, lower is better), along with the cross-entropy loss of the graph discriminator trained to
distinguish synthesized programs of generated examples vs. held-out test set examples (‚ÄúGCN Disc.‚Äù,
higher is better). The best score in each column is bolded. As can be seen, our approach (SGM)
with sampling strategy A1 outperforms all other approaches in terms of high-level structure, while
our approach with sampling strategy A3 outperforms all baselines in high-level structure and is also
competitive with GPT-2-based models in FD scores."
MUSIC GENERATION,0.37888198757763975,"strategy A2 outperforms all other models in both tables, in terms of both high-level structure and
low-level structure. In Table 1 (left), the closest alternative is MusicVAE, for which the NLL is not
too much larger; however, it performs signiÔ¨Åcantly worse than our approach in terms of high-level
structure. In Table 1 (right), we Ô¨Ånd that our other approaches also perform well (though not as well
as A2). In particular, A1 performs well in terms of low-level structure, but is more mixed in terms
of high-level structure. In contrast, A3 performs well in terms of high-level structure, but is mixed
in terms of low-level structure, most likely since it does not use a learning-based model to generate
low-level structure. Our ablation where we perform no synthesis performs poorly, especially in terms
of structure, as does the one using greedy synthesis, demonstrating the importance of using constraint
solving to synthesize compact representations of structure. On the other hand, greedy synthesis can
be signiÔ¨Åcantly more scalable than constrained optimization for large examples; thus, improving this
strategy is an interesting direction for future work. Finally, using a continuous relation performs
competitively in terms of FD score (though interestingly, it performs worse in terms of high-level
structure), demonstrating that our approach can be applied with continuous relations."
POETRY GENERATION,0.38198757763975155,"5.2
POETRY GENERATION"
POETRY GENERATION,0.38509316770186336,"Next, we apply our approach (SGM) to poetry generation; in this case, x is a poem, and w is a line.
We consider two relations, rhyming and equal meter; see Appendix C.3 for details."
POETRY GENERATION,0.38819875776397517,"Dataset. We use from Project Gutenberg‚Äôs poetry collection (Parrish, 2018), focusing on 10-line
poems with rhymes and meter, with 2700 for training and 300 for testing."
POETRY GENERATION,0.391304347826087,"Our approach. In the rhyming domain, due to the lack of rhyme-aware line embeddings, we did not
perform A2. In applying A1, rather than sample words going forward, we sample them backwards,
making it easier to sample lines that satisfy rhyming constraints; see Appendix B. Thus, we use BERT
to sample (Devlin et al., 2018), since it is bidirectional. We apply A3 by performing constrained
optimization to satisfy as many relations as possible while maintaining a low NLL."
POETRY GENERATION,0.3944099378881988,"Baselines. We compare to generation using beam search for BERT and GPT2 (Radford et al., 2019;
Vaswani et al., 2017), both Ô¨Ånetuned on our dataset. We also consider a variant GPT2-Opt of GPT2
where we use beam search to choose line breaks in a way that maximizes occurrences of rhyme and
meter. We also tried a variant of GPT2 that used constrained sampling to try and Ô¨Ånd poems that Ô¨Åt a
given rhyme and meter, but the search space was too large and it failed to generate a single poem
even after several hours. We also compare to an implementation of RichLyrics (Castro & Attarian,
2018), where the consecutive parts of speech for each line given the previous line and the ability to
Ô¨Åll in the correct word for the given part of speech were both learned separately from the corpus.
Finally, to show the importance of learning the distribution over constraints, we consider an ablation
that uses A1, but sampling Œ¶c uniformly randomly rather than from a learned distribution."
POETRY GENERATION,0.39751552795031053,"Metrics. For low-level structure, we use FD score on SentenceBert embeddings, which are unaware
of rhyme and meter (Reimers & Gurevych, 2019); we cannot evaluate log-likelihood since we are
using constrained sampling. For high-level structure, we train a GCN to discriminate synthesized
programs for generated examples vs, test examples."
POETRY GENERATION,0.40062111801242234,Under review as a conference paper at ICLR 2022
POETRY GENERATION,0.40372670807453415,"Figure 2: Left: Poetry generated using relational constraints c ‚àºpœÜ(¬∑). Right: user modiÔ¨Åed variant
of c where the last two lines share a prototype with the two lines before them."
POETRY GENERATION,0.40683229813664595,"Method
Average Score
Lyricism
Coherence
Rhyme/Meter"
POETRY GENERATION,0.40993788819875776,"SGM (Ours, A1)
3.66
3.81
3.59
3.59
GPT2-Finetune
3.30
2.90
3.91
3.12
BERT-Finetune
2.28
2.11
2.00
2.77
RichLyrics
3.09
3.24
3.09
2.93"
POETRY GENERATION,0.41304347826086957,"Table 3: A user study evaluation in the poetry domain. While GPT2-Finetune outperforms our
model in terms of coherence (presumably due to the well-known superiority of GPT-2 over BERT for
generation), our method outperforms in terms of overall lyricism (i.e., whether the poem reads like
poetry or prose), prominence of rhythmic/metrical structure, and average score."
POETRY GENERATION,0.4161490683229814,"Results. We show results in Table 2. Our approach (SGM) with sampling strategy A3 signiÔ¨Åcantly
outperforms all baselines in terms of high-level programmatic structure, while also outperforming
them in terms of FD scores. Approach A1 performs even better in terms of programmatic structure,
but is not competitive with respect to FD scores, presumably due to the fact that GPT-2 is signiÔ¨Åcantly
better at natural language generation than BERT."
POETRY GENERATION,0.4192546583850932,"User study. We also performed a user study, discussed in Appendix C.5, which further conÔ¨Årmed
this methods‚Äô strength in the poetry domain. in this domain, with 50 participants."
POETRY GENERATION,0.422360248447205,"User modiÔ¨Åcations. A key beneÔ¨Åt of our approach is that the user can modify the relational
constraints c (or construct their own from scratch) for use in the second step pŒ∏(x | c), giving the
user a way to guide the generative process. An example in the poetry domain is shown in Figure 5.2,
and musical examples are shown in Appendix D.2."
CONCLUSION,0.4254658385093168,"6
CONCLUSION"
CONCLUSION,0.42857142857142855,"We have presented a novel approach for representing and synthesizing relational constraints on
sequence data, and for generating examples whose relational structure resembles that of the training
data. Our experiments demonstrate that we outperform existing approaches in terms of achieving
human-like structure, while performing comparably or better on both a user study and widely-used
quantitative metrics that do not explicitly account for structure. Finally, our approach enables users to
guide the generative process by modifying constraints. A key direction for future work is to apply
our approach to other applications such as dialog generation and summarization, which may require
novel programmatic structure compared to the ones we study."
CONCLUSION,0.43167701863354035,"Reproducibility. We strove to maintain reproducibility for our code. Included in the supplement is
all the material to obtain our results with instructions for running it and signiÔ¨Åcant documentation,
except for the code for the approach (A1) in the music domain (which performed the worst out of the
three approaches). We do not provide the data sets for attribution rights reasons, but include the links
by which users can obtain that data."
CONCLUSION,0.43478260869565216,Under review as a conference paper at ICLR 2022
REFERENCES,0.43788819875776397,REFERENCES
REFERENCES,0.4409937888198758,"V Atanassova and S Pulov. Prolog realization of a poetry generator. In Proceedings First International
IEEE Symposium Intelligent Systems, volume 3, pp. 52‚Äì53. IEEE, 2002."
REFERENCES,0.4440993788819876,"Osbert Bastani, Yewen Pu, and Armando Solar-Lezama. VeriÔ¨Åable reinforcement learning via policy
extraction. In Advances in neural information processing systems, pp. 2494‚Äì2504, 2018."
REFERENCES,0.4472049689440994,"Ali Borji. Pros and cons of gan evaluation measures. Computer Vision and Image Understanding,
179:41‚Äì65, 2019."
REFERENCES,0.4503105590062112,"Pablo Samuel Castro and Maria Attarian. Combining learned lyrical structures and vocabulary for
improved lyric generation. CoRR, abs/1811.04651, 2018. URL http://arxiv.org/abs/
1811.04651."
REFERENCES,0.453416149068323,"Stefano Ceri, Georg Gottlob, Letizia Tanca, et al. What you always wanted to know about datalog(and
never dared to ask). IEEE transactions on knowledge and data engineering, 1(1):146‚Äì166, 1989."
REFERENCES,0.45652173913043476,"David Cope. An expert system for computer-assisted composition. Computer Music Journal, 11(4):30‚Äì
46, 1987. ISSN 01489267, 15315169. URL http://www.jstor.org/stable/3680238."
REFERENCES,0.45962732919254656,"Sumanth Dathathri, Andrea Madotto, Janice Lan, Jane Hung, Eric Frank, Piero Molino, Jason
Yosinski, and Rosanne Liu. Plug and play language models: A simple approach to controlled text
generation. CoRR, abs/1912.02164, 2019. URL http://arxiv.org/abs/1912.02164."
REFERENCES,0.46273291925465837,"Cristina David and Daniel Kroening. Program synthesis: challenges and opportunities. Philosophical
Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 375(2104):
20150403, 2017. doi: 10.1098/rsta.2015.0403."
REFERENCES,0.4658385093167702,"Leonardo De Moura and Nikolaj Bj√∏rner. Z3: An efÔ¨Åcient smt solver. Berlin, Heidelberg, 2008.
Springer-Verlag. ISBN 3540787992."
REFERENCES,0.468944099378882,"Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of deep
bidirectional transformers for language understanding. CoRR, abs/1810.04805, 2018. URL
http://arxiv.org/abs/1810.04805."
REFERENCES,0.4720496894409938,"Kevin Ellis, Armando Solar-Lezama, and Josh Tenenbaum. Unsupervised learning by program
synthesis. In Advances in neural information processing systems, pp. 973‚Äì981, 2015."
REFERENCES,0.4751552795031056,"Kevin Ellis, Daniel Ritchie, Armando Solar-Lezama, and Joshua B. Tenenbaum. Learning to
infer graphics programs from hand-drawn images. CoRR, abs/1707.09627, 2017. URL http:
//arxiv.org/abs/1707.09627."
REFERENCES,0.4782608695652174,"Kevin Ellis, Catherine Wong, Maxwell I. Nye, Mathias Sabl√©-Meyer, Luc Cary, Lucas Morales,
Luke B. Hewitt, Armando Solar-Lezama, and Joshua B. Tenenbaum. Dreamcoder: Growing
generalizable, interpretable knowledge with wake-sleep bayesian program learning.
CoRR,
abs/2006.08381, 2020. URL https://arxiv.org/abs/2006.08381."
REFERENCES,0.4813664596273292,"Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Z. Ghahramani, M. Welling,
C. Cortes, N. D. Lawrence, and K. Q. Weinberger (eds.), Advances in Neural Information Process-
ing Systems 27, pp. 2672‚Äì2680. Curran Associates, Inc., 2014. URL http://papers.nips.
cc/paper/5423-generative-adversarial-nets.pdf."
REFERENCES,0.484472049689441,"C. Horton and L. Ritchey. Workbook for Harmony Through Melody: The Interaction of Melody,
Counterpoint, and Harmony in Western Music. Scarecrow Press, 2000. ISBN 9781461664147.
URL https://books.google.com/books?id=XK3psrVckcAC."
REFERENCES,0.48757763975155277,"Cheng-Zhi Anna Huang, Ashish Vaswani, Jakob Uszkoreit, Noam Shazeer, Ian Simon, Curtis
Hawthorne, Andrew Dai, Matt Hoffman, Monica Dinculescu, and Douglas Eck. Music transformer:
Generating music with long-term structure. 2019. URL https://arxiv.org/abs/1809.
04281."
REFERENCES,0.4906832298136646,Under review as a conference paper at ICLR 2022
REFERENCES,0.4937888198757764,"Jeevana Priya Inala, Osbert Bastani, Zenna Tavares, and Armando Solar-Lezama. Synthesizing
programmatic policies that inductively generalize. In International Conference on Learning
Representations, 2019."
REFERENCES,0.4968944099378882,"Dasaem Jeong, Taegyun Kwon, Yoojin Kim, and Juhan Nam. Graph neural network for music
score data and modeling expressive piano performance. In Kamalika Chaudhuri and Ruslan
Salakhutdinov (eds.), ICML, volume 97 of Proceedings of Machine Learning Research, pp. 3060‚Äì
3070. PMLR, 2019. URL http://dblp.uni-trier.de/db/conf/icml/icml2019.
html#JeongKKN19."
REFERENCES,0.5,"Gullapalli Keerti, A N Vaishnavi, Prerana Mukherjee, A Sree Vidya, Gattineni Sai Sreenithya, and
Deeksha Nayab. Attentional networks for music generation. ArXiv, abs/2002.03854, 2020."
REFERENCES,0.5031055900621118,"Diederik P. Kingma and Max Welling.
An introduction to variational autoencoders.
CoRR,
abs/1906.02691, 2019. URL http://arxiv.org/abs/1906.02691."
REFERENCES,0.5062111801242236,"Thomas N. Kipf and Max Welling. Semi-Supervised ClassiÔ¨Åcation with Graph Convolutional
Networks. In Proceedings of the 5th International Conference on Learning Representations, ICLR
‚Äô17, 2017. URL https://openreview.net/forum?id=SJU4ayYgl."
REFERENCES,0.5093167701863354,"Jey Han Lau, Trevor Cohn, Timothy Baldwin, Julian Brooke, and Adam Hammond. Deep-speare:
A joint neural model of poetic language, meter and rhyme. CoRR, abs/1807.03491, 2018. URL
http://arxiv.org/abs/1807.03491."
REFERENCES,0.5124223602484472,"Xiang Lisa Li and Alexander M. Rush.
Posterior control of blackbox generation.
CoRR,
abs/2005.04560, 2020. URL https://arxiv.org/abs/2005.04560."
REFERENCES,0.515527950310559,"Yi Liao, Yasheng Wang, Qun Liu, and Xin Jiang. Gpt-based generation for classical chinese poetry.
CoRR, abs/1907.00151, 2019a. URL http://arxiv.org/abs/1907.00151."
REFERENCES,0.5186335403726708,"Yi Liao, Yasheng Wang, Qun Liu, and Xin Jiang. Gpt-based generation for classical chinese poetry.
CoRR, abs/1907.00151, 2019b. URL http://arxiv.org/abs/1907.00151."
REFERENCES,0.5217391304347826,"David Lopez-Paz and Maxime Oquab.
Revisiting classiÔ¨Åer two-sample tests.
arXiv preprint
arXiv:1610.06545, 2016."
REFERENCES,0.5248447204968945,"Gabriele Medeot, Srikanth Cherla, Katerina Kosta, Matt McVicar, Samer Abdallah, Marco Selvi,
Ed Newton-Rex, and Kevin Webster. Structurenet: Inducing structure in generated melodies. In
Emilia G√≥mez, Xiao Hu, Eric Humphrey, and Emmanouil Benetos (eds.), Proceedings of the 19th
International Society for Music Information Retrieval Conference, ISMIR 2018, Paris, France,
September 23-27, 2018, pp. 725‚Äì731, 2018. URL http://ismir2018.ircam.fr/doc/
pdfs/126_Paper.pdf."
REFERENCES,0.5279503105590062,"Hongyuan Mei, Guanghui Qin, Minjie Xu, and Jason Eisner. Neural datalog through time: Informed
temporal modeling via logical speciÔ¨Åcation. CoRR, abs/2006.16723, 2020a. URL https:
//arxiv.org/abs/2006.16723."
REFERENCES,0.531055900621118,"Hongyuan Mei, Guanghui Qin, Minjie Xu, and Jason Eisner. Neural datalog through time: Informed
temporal modeling via logical speciÔ¨Åcation. CoRR, abs/2006.16723, 2020b. URL https:
//arxiv.org/abs/2006.16723."
REFERENCES,0.5341614906832298,"Ning Miao, Hao Zhou, Lili Mou, Rui Yan, and Lei Li. CGMH: constrained sentence generation
by metropolis-hastings sampling. CoRR, abs/1811.10996, 2018. URL http://arxiv.org/
abs/1811.10996."
REFERENCES,0.5372670807453416,"Islam Elgamal Muhammad Faisal, Islam Faisal. Generating random, yet, constrained music. 2017.
URL https://decltype.me/publication/motifate-me/."
REFERENCES,0.5403726708074534,"OpenAI. Musenet, 2019. URL https://openai.com/blog/musenet."
REFERENCES,0.5434782608695652,"Russell Ovans and Rod Davison. An iterative constraint-based expert assistant for music composi-
tion. In Proceedings of the Biennial Conference-Canadian Society for Computational Studies of
Intelligence, pp. 76‚Äì76. Citeseer, 1992."
REFERENCES,0.546583850931677,Under review as a conference paper at ICLR 2022
REFERENCES,0.5496894409937888,"Allison
Parrish,
2018.
URL
https://github.com/aparrish/
gutenberg-poetry-corpus."
REFERENCES,0.5527950310559007,"Jeffrey Pennington, Richard Socher, and Christopher D. Manning. Glove: Global vectors for word
representation. In Empirical Methods in Natural Language Processing (EMNLP), pp. 1532‚Äì1543,
2014. URL http://www.aclweb.org/anthology/D14-1162."
REFERENCES,0.5559006211180124,"Donya Quick. Learning production probabilities for musical grammars. Journal of New Music
Research, 45:295‚Äì313, 10 2016. doi: 10.1080/09298215.2016.1228680."
REFERENCES,0.5590062111801242,"Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language
models are unsupervised multitask learners. 2019."
REFERENCES,0.562111801242236,"Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bert-networks.
CoRR, abs/1908.10084, 2019. URL http://arxiv.org/abs/1908.10084."
REFERENCES,0.5652173913043478,"Adam Roberts, Jesse H. Engel, Colin Raffel, Curtis Hawthorne, and Douglas Eck. A hierarchical
latent vector model for learning long-term structure in music. CoRR, abs/1803.05428, 2018. URL
http://arxiv.org/abs/1803.05428."
REFERENCES,0.5683229813664596,"Asir Saeed, Suzana Ilic, and Eva Zangerle. Creative gans for generating poems, lyrics, and metaphors.
CoRR, abs/1909.09534, 2019. URL http://arxiv.org/abs/1909.09534."
REFERENCES,0.5714285714285714,"√ñrjan Sandred, Mikael Laurson, and Mika Kuuskankare. Revisiting the illiac suite - a rule-based
approach to stochastic processes. Sonic Ideas/Ideas Sonicas, 2:42‚Äì46, 01 2009."
REFERENCES,0.5745341614906833,H. Schaffrath. The essen folksong collection in the humdrum kern format. 1995.
REFERENCES,0.577639751552795,"Andrew Shaw, 2020. URL https://github.com/bearpelican/musicautobot."
REFERENCES,0.5807453416149069,"Y. Cem S√ºbakan and Paris Smaragdis.
Diagonal rnns in symbolic music modeling.
CoRR,
abs/1704.05420, 2017. URL http://arxiv.org/abs/1704.05420."
REFERENCES,0.5838509316770186,"Dima Suleiman, Arafat Awajan, and Wael Al Etaiwi.
The use of hidden markov model in
natural arabic language processing: a survey.
Procedia Computer Science, 113:240‚Äì247,
2017.
ISSN 1877-0509.
doi: https://doi.org/10.1016/j.procs.2017.08.363.
URL https:
//www.sciencedirect.com/science/article/pii/S1877050917317738. The
8th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EU-
SPN 2017) / The 7th International Conference on Current and Future Trends of Information and
Communication Technologies in Healthcare (ICTH-2017) / AfÔ¨Åliated Workshops."
REFERENCES,0.5869565217391305,Mattt Thompson. M√∂bius: Exploring a new modality for poetry generation. 2009.
REFERENCES,0.5900621118012422,"Lazar Valkov, Dipak Chaudhari, Akash Srivastava, Charles Sutton, and Swarat Chaudhuri. Houdini:
Lifelong learning as program synthesis. In Advances in Neural Information Processing Systems,
pp. 8687‚Äì8698, 2018."
REFERENCES,0.593167701863354,"Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez,
Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. CoRR, abs/1706.03762, 2017. URL
http://arxiv.org/abs/1706.03762."
REFERENCES,0.5962732919254659,"Abhinav Verma, Vijayaraghavan Murali, Rishabh Singh, Pushmeet Kohli, and Swarat Chaudhuri.
Programmatically interpretable reinforcement learning. In International Conference on Machine
Learning, pp. 5045‚Äì5054, 2018."
REFERENCES,0.5993788819875776,"Elliot
Waite,
2016.
URL
https://magenta.tensorflow.org/2016/07/15/
lookback-rnn-attention-rnn."
REFERENCES,0.6024844720496895,"Zhe Wang, Wei He, Hua Wu, Haiyang Wu, Wei Li, Haifeng Wang, and Enhong Chen. Chinese
poetry generation with planning based neural network. CoRR, abs/1610.09889, 2016. URL
http://arxiv.org/abs/1610.09889."
REFERENCES,0.6055900621118012,"Li-Chia Yang, Szu-Yu Chou, and Yi-Hsuan Yang. Midinet: A convolutional generative adversarial
network for symbolic-domain music generation using 1d and 2d conditions. CoRR, abs/1703.10847,
2017a. URL http://arxiv.org/abs/1703.10847."
REFERENCES,0.6086956521739131,Under review as a conference paper at ICLR 2022
REFERENCES,0.6118012422360248,"Xiaopeng Yang, Xiaowen Lin, Shunda Suo, and Ming Li. Generating thematic chinese poetry with
conditional variational autoencoder. CoRR, abs/1711.07632, 2017b. URL http://arxiv.
org/abs/1711.07632."
REFERENCES,0.6149068322981367,"Halley Young, Osbert Bastani, and Mayur Naik. Learning neurosymbolic generative models via
program synthesis. 2019."
REFERENCES,0.6180124223602484,Under review as a conference paper at ICLR 2022
REFERENCES,0.6211180124223602,"A
ADDITIONAL RELATED WORK"
REFERENCES,0.6242236024844721,"Music and poetry generation. Both early music generation and poetry generation approaches were
rule-based (Ovans & Davison, 1992; Atanassova & Pulov, 2002) or used simple statistical models
such as Markov models (Sandred et al., 2009; Cope, 1987; Suleiman et al., 2017) or probabilistic
CFGs (Quick, 2016; Thompson, 2009). Recent work has used deep learning to generate music (Huang
et al., 2019; OpenAI, 2019) and poetry (Liao et al., 2019a); our experiments show that these
approaches have difÔ¨Åculty generating realistic high-level structure."
REFERENCES,0.6273291925465838,"Music generation has been approached using many machine learning techniques, including convolu-
tional neural networks (CNN‚Äôs) (Yang et al., 2017a), graph convolutional networks (GCN‚Äôs) (Jeong
et al., 2019), recurrent neural networks (RNN‚Äôs) (S√ºbakan & Smaragdis, 2017)), and transform-
ers (Huang et al., 2019). In particular, we leverage attention-based RNN‚Äôs (Keerti et al., 2020) and
transformers for constrained sampling of program structure."
REFERENCES,0.6304347826086957,"Poetry has been approached with a variety of techniques as well, including relying on Ô¨Ånetuned
transformers (an approach we extend) (Liao et al., 2019b), RNN-based conditional-VAEs (Yang
et al., 2017b), RNN-based planning (Wang et al., 2016), and GANs with both transformer and LSTM
backends (Saeed et al., 2019)."
REFERENCES,0.6335403726708074,"Approaches have incorporated structure into deep learning to generate music (Medeot et al., 2018)
or poetry (Castro & Attarian, 2018), but they are domain speciÔ¨Åc; we Ô¨Ånd they do not perform at
a human level on capturing global (and sometimes local) structure. Some approaches incorporate
expert-provided constraints such as rhyme and meter to generate poetry (Lau et al., 2018); unlike our
approach, they cannot automatically learn and generate these constraints from data."
REFERENCES,0.6366459627329193,"Constrained text generation. There has been work on constraining language models to produce
outputs that satisfy a given decision function, or that maximize a given scoring function (Li & Rush,
2020; Miao et al., 2018; Dathathri et al., 2019). In contrast, our work focuses on settings where
constraints are generated, and furthermore the distribution over constraints must itself be learned."
REFERENCES,0.639751552795031,"Relational constraints and neural models. Several previous works have focused on learning
datalog programs, one component of our project. Mei et al. (2020b) learn Datalog programs which
represent certain point processes, and use this to predict future events. Similarly, Mei et al. (2020a)
also learn Datalog programs, and is able to achieve great success in certain autoregressive domains;
however, they do not frame their problem as a generative process to generate realistic human data
from their output."
REFERENCES,0.6428571428571429,"B
GENERATING EXAMPLES GIVEN RELATIONAL CONSTRAINTS"
REFERENCES,0.6459627329192547,"B.1
APPROACH 1: CONSTRAINED SAMPLING"
REFERENCES,0.6490683229813664,"In the music domain, we choose the pretrained generative model pŒ∏(w) to be a pretrained version
of MusicAutoBot. To generate x, we sequentially sample each measure wi conditioned on all prior
measures w1, ..., wi‚àí1. Each measure is sampled by sequentially sampling a sequence of pitch-
duration pairs until the total duration is 16 beats (i.e., the length of a measure). During sampling, we
mask pitch-duration pairs that cannot satisfy Œ¶c (i.e., we set their sampling probability to zero and
rescale the remaining probabilities). For instance, if the ‚Äúhas similar interval‚Äù relation is supposed
to hold between the the prototype measure and measure i, and we are sampling the second note of
measure i, then we mask any pitch k in measure i such that"
REFERENCES,0.6521739130434783,"|(pitchk ‚àípitchk‚àí1) ‚àí( g
pitchk ‚àíg
pitchk‚àí1)| ‚â•3,"
REFERENCES,0.65527950310559,"where g
pitchk is pitch k in the prototype corresponding to wi. In other words, we eliminate pitches
that would cause sampling to violate this constraint."
REFERENCES,0.6583850931677019,"In the the poetry domain, we Ô¨Ånetune a pretrained BERT model on our dataset, by taking the
pretrained models weights and then training the model on our dataset with a strong gradient weight
decay. BERT has the ability to complete masked words in a sentence. We leverage this ability to
sample lines that rhyme and have the same meter, which is a challenging task since such lines are
a tiny fraction of the search space. We describe how we simultaneously handle rhyming and equal"
REFERENCES,0.6614906832298136,Under review as a conference paper at ICLR 2022
REFERENCES,0.6645962732919255,"meter; the cases where only one of these two constraints has to hold are similar. Given a prototype Àúw,
we work backwards‚Äîon each step j, we sample from BERT a word wordk that has the same number
of syllables as the corresponding word ]
wordk in the prototype. More precisely, we feed BERT the
sequence"
REFERENCES,0.6677018633540373,"]
word1, ..., ]
wordk‚àí1, MASK, wordk+1, ..."
REFERENCES,0.6708074534161491,"and ask it to Ô¨Åll in the masked word, setting the probability of any word with different number of
syllables as ]
wordk to zero."
REFERENCES,0.6739130434782609,"In addition, to avoid producing a line which is similar to the original line, we also set the probability
of any word too similar to the original word in terms of GloVe cosine similarity (Pennington et al.,
2014) to zero, except for in the case of the last word, where we instead restrict to words that rhyme
with ]
wordk. To increase diversity, we sample the remaining words twice‚Äî(i) backwards-to-forwards
from word k ‚àí1 to word 1, where k is the number of words, and (ii) we resample each of the k ‚àí1
words (i.e., except the last word) in a random order. We discard any lines which, according to BERT,
after being sampled are determined to be too unlikely when preceded by the previously generated
lines."
REFERENCES,0.6770186335403726,"B.2
APPROACH 2: CONSTRAINT-AWARE EMBEDDINGS"
REFERENCES,0.6801242236024845,"This approach uses a graph convolutional network (GCN) conditional variational autoencoder (cVAE),
or GCN-cVAE, which consists of a GCN encoder qŒ∏(z‚Ä≤ | x, cx) and a GCN decoder pŒ∏(x | z‚Ä≤, cx)."
REFERENCES,0.6832298136645962,"In more detail, we assume x = (w1, ..., wm) is represented as a sequence of vectors (u1, ..., um)‚Äî
e.g., in the music domain, we use MusicVAE pœà to encode u ‚àºqœà(¬∑ | w) or decode w ‚àºpœà(¬∑ | u).
Then, the latent encoding z‚Ä≤ consists of an embedding vector for each subcomponent u of x."
REFERENCES,0.6863354037267081,"Next, cx is incorporated into each GCN by converting it into a tensor with dimensions | ÀÜw|√ó| ÀÜw|√ó|R|
used as the adjacency matrix of that GCN (the last dimension is the edge attribute). Intuitively, the
edges in x are relations in c between subcomponents and prototypes."
REFERENCES,0.6894409937888198,"This GCN-cVAE it is trained using the usual VAE objective (Kingma & Welling, 2019): (i) a KL
divergence term encouraging the embeddings z‚Ä≤ to be Gaussian, and (ii) a reconstruction loss in
terms of mean-squared error. We also include a semantic consistency loss to enforce the satisfaction
of the constraints Œ¶c. In particular, we train a classiÔ¨Åer pŒ±(u, u‚Ä≤; r) that predicts whether two
subcomponents u, u‚Ä≤ satisfy relation r (more precisely, when decoded by pœà). The model pŒ± is
trained examples (u, u‚Ä≤, r) from the training data x. Then, we include the loss
X"
REFERENCES,0.6925465838509317,"( Àú
w,i,r)‚ààŒ¶c
pŒ±(Àúu, ui, r),"
REFERENCES,0.6956521739130435,"where Àúu ‚àºpœà(¬∑ | Àúw) is the encoding of Àúw, ui ‚àºpœà(¬∑ | wi) is the encoding of wi, and r is a relation."
REFERENCES,0.6987577639751553,"For the music domain, we use a pretrained MusicVAE for pœà and qœà; unlike the MusicVAE we use
for evaluation, we Ô¨Ånetune a model that decodes 1 measure of music from a 256-dimensional vector."
REFERENCES,0.7018633540372671,"B.3
APPROACH 3: COMBINATORIAL OPTIMIZATION"
REFERENCES,0.7049689440993789,"Given sampled program c, this approach attempts to generate values x = (w0, . . . , wm) such that
x |= Œ¶c by solving a system of constraints. However, when generated using a neural network,
relational constraints œÜ ‚ààŒ¶c are not always consistent with one another, so we convert the constraint
x |= Œ¶c into an objective‚Äîi.e.,"
REFERENCES,0.7080745341614907,"x = arg max
x‚ààX m
X i=1 X"
REFERENCES,0.7111801242236024,"r‚ààR
1(R( Àúw, wi, n) ‚áî( Àúw, i, n) ‚ààŒ¶c)."
REFERENCES,0.7142857142857143,"The ability to encode this optimization problem as one that Z3 can solve depends on the domain and
relations. For this approach to work, we may need to include additional, handcrafted terms in the
objective that encourage the generated example x is realistic."
REFERENCES,0.717391304347826,Under review as a conference paper at ICLR 2022
REFERENCES,0.7204968944099379,"For the music domain, the optimization variables are the optimal sequence of pitches and their
durations. The objective function is a linear combination of the degree to which x satisÔ¨Åes c, along
with domain-speciÔ¨Åc heuristics‚Äîe.g., minimizing large jumps in pitch values (i.e., |pitchk+1 ‚àí
pitchk| ‚â•4), not having any intervals of length 6 (i.e., |pitchk+1 ‚àípitchk| = 6) due to the unpleasant
harmonic nature of that interval, and not having two consecutive jumps in pitch (i.e., |pitchk+2 ‚àí
pitchk+1| ‚â•5) ‚àß|pitchk+1 ‚àípitchk| ‚â•5). These heuristics are based on standard concepts from
music theory (Horton & Ritchey, 2000)."
REFERENCES,0.7236024844720497,"For the language domain, we use GPT-2 to sample a line except for the last word; then, the optimiza-
tion variables are the last words in each line. This strategy optimizes the relations between each line
and its prototype, while leveraging GPT-2 to maintain low NLL for the entire poem."
REFERENCES,0.7267080745341615,"C
EVALUATION DETAILS"
REFERENCES,0.7298136645962733,"C.1
EXPERIMENTAL SETUP"
REFERENCES,0.7329192546583851,"Synthesizing programs. The hyperparameters J1, J2, and J3 in the program synthesis task, as
described in the main section of this paper, regulate the degree to which the optimization favors
solutions which have high similarity between prototype and sequence measures, have high similarity
between elements sharing a prototype, and have high difference between prototypes, respectively.
Their values were different with respect to the two different domains. In the poetry domain, J1,
J2, and J3 were 1, 10, and 1, respectively. In the music domain, J1, J2, and J3 were 1, 5, and
1, respectively. These values were arrived at through attempting to arrive at results which closely
matched a set of human (author) annotated programs."
REFERENCES,0.7360248447204969,"Generating c. To generate c in the poetry domain, we use an LSTM-VAE with 6 LSTM layers and a
latent size of 50. This model is trained to reproduce a given sequence of (si, ri) pairs which are given
as input, with an additional requirement that the distribution of their encodings should be roughly
equivalent to a Gaussian normal distribution. In the music domain, while we experimented with using
an LSTM-VAE, empirically we had more success using a feedforward 3-layer network which took
the previous n (usually n = 6) (si, ri) pairs, and outputted a distribution over the following pair."
REFERENCES,0.7391304347826086,"Each (si, ri) pair is represented as a (S + |R|)-dimensional vector, where S is the maximum distance
between objects with the same prototype and R is the set of relations."
REFERENCES,0.7422360248447205,"High-level structure. We evaluate high-level structure by using our algorithm to synthesize the
relational constraints in every generated example‚Äîi.e., Cgen = {A(x) | x ‚ààXgen}, where Xgen is the
set of examples generated using a model. Similarly, we can construct Chuman = {A(x) | x ‚ààXhuman},
where Xhuman is the set of human-created examples held-out from the training dataset. Then, we
evaluate high-level structure by training a model to try to discriminate Cgen from Chuman; if the model
achieves lower performance, then the quality of high-level structure is higher. A general approach is
to train a graph neural network (e.g., a graph convolutional network) to do so; this model takes as
input the graph structure of relational constraints c, along with vector embeddings of the prototype
subcomponents, and outputs whether c ‚ààCgen or c ‚ààChuman. We balance the data so it consists
of 50% human data and 50% generated data. We report the cross-entropy (CE) loss; higher values
correspond to better generative models. In the music domain, we additionally used a random forest
(RF) trained on a manual featurization of c. We report the accuracy of the RF; lower values (i.e.,
closer to 50%) correspond to better generative models."
REFERENCES,0.7453416149068323,"C.2
MUSICAL RELATIONS USED"
REFERENCES,0.7484472049689441,The following are the relations r ‚ààR used in the music domain:
REFERENCES,0.7515527950310559,1. Measures i and j have the same pitch classes.
REFERENCES,0.7546583850931677,2. Measures i and j have the same pitch class preÔ¨Åx.
REFERENCES,0.7577639751552795,3. Measures i and j have the same pitch class sufÔ¨Åx.
REFERENCES,0.7608695652173914,4. Measures i and j‚Äôs pitches have an edit distance of 1.
REFERENCES,0.7639751552795031,5. Measures i and j have approximately the same interval structure.
REFERENCES,0.7670807453416149,Under review as a conference paper at ICLR 2022
REFERENCES,0.7701863354037267,6. Measures i and j have the same interval preÔ¨Åx.
REFERENCES,0.7732919254658385,7. Measures i and j have the same interval sufÔ¨Åx.
REFERENCES,0.7763975155279503,8. Measures i and j have the same note (pitch + duration) preÔ¨Åx.
REFERENCES,0.7795031055900621,9. Measures i and j have the same note (pitch + duration) sufÔ¨Åx.
REFERENCES,0.782608695652174,10. Measures i and j have the same rhythm.
REFERENCES,0.7857142857142857,11. Measures i and j‚Äôs rhythm has an edit distance of ‚â§2.
REFERENCES,0.7888198757763976,"12. Either measure i‚Äôs onsets are a subset of measure j‚Äôs onsets, or measure j‚Äôs onsets are a
subset of measure i‚Äôs onsets."
REFERENCES,0.7919254658385093,13. Measures i and j have the same rhythmic and melodic contour.
REFERENCES,0.7950310559006211,14. Measures i and j have the same rhythmic and melodic contour preÔ¨Åx.
REFERENCES,0.7981366459627329,15. Measures i and j have the same rhythmic and melodic contour sufÔ¨Åx.
REFERENCES,0.8012422360248447,16. Either the Ô¨Årst or second half of measures i and j are identical.
REFERENCES,0.8043478260869565,17. Either both or neither of measures i and j have leaps.
REFERENCES,0.8074534161490683,18. Measures i and j Ô¨Åt within the same diatonic scale.
REFERENCES,0.8105590062111802,19. Either both or neither of measures i and j have syncopation.
EITHER BOTH OR NEITHER OF MEASURES I AND J HAVE CONSECUTIVE NOTES SHORTER THAN AN EIGHTH,0.8136645962732919,"20. Either both or neither of measures i and j have consecutive notes shorter than an eighth
note."
EITHER BOTH OR NEITHER OF MEASURES I AND J HAVE CONSECUTIVE NOTES SHORTER THAN AN EIGHTH,0.8167701863354038,"21. (Continuous) The cosine similarity between the Measure-VAE embeddings of measure i
and measure j."
EITHER BOTH OR NEITHER OF MEASURES I AND J HAVE CONSECUTIVE NOTES SHORTER THAN AN EIGHTH,0.8198757763975155,"C.3
POETRY RELATIONS USED"
EITHER BOTH OR NEITHER OF MEASURES I AND J HAVE CONSECUTIVE NOTES SHORTER THAN AN EIGHTH,0.8229813664596274,The following are the relations r ‚ààR used in the poetry domain:
EITHER BOTH OR NEITHER OF MEASURES I AND J HAVE CONSECUTIVE NOTES SHORTER THAN AN EIGHTH,0.8260869565217391,1. Lines i and j have the same end rhyme.
EITHER BOTH OR NEITHER OF MEASURES I AND J HAVE CONSECUTIVE NOTES SHORTER THAN AN EIGHTH,0.8291925465838509,2. Lines i and j have the same meter.
EITHER BOTH OR NEITHER OF MEASURES I AND J HAVE CONSECUTIVE NOTES SHORTER THAN AN EIGHTH,0.8322981366459627,"C.4
RANDOM FOREST FEATURES"
EITHER BOTH OR NEITHER OF MEASURES I AND J HAVE CONSECUTIVE NOTES SHORTER THAN AN EIGHTH,0.8354037267080745,"The following are the manually constructed features used in the random forest discriminator for the
music domain:"
EITHER BOTH OR NEITHER OF MEASURES I AND J HAVE CONSECUTIVE NOTES SHORTER THAN AN EIGHTH,0.8385093167701864,1. Mean number of relations between prototype and sequence measures.
EITHER BOTH OR NEITHER OF MEASURES I AND J HAVE CONSECUTIVE NOTES SHORTER THAN AN EIGHTH,0.8416149068322981,2. Variance of number of relations between prototype and sequence measures.
EITHER BOTH OR NEITHER OF MEASURES I AND J HAVE CONSECUTIVE NOTES SHORTER THAN AN EIGHTH,0.84472049689441,3. Variance in histogram of prototype measure mappings.
EITHER BOTH OR NEITHER OF MEASURES I AND J HAVE CONSECUTIVE NOTES SHORTER THAN AN EIGHTH,0.8478260869565217,4. Longest sequence i . . . j such that wi . . . wj all have the same prototype measure.
EITHER BOTH OR NEITHER OF MEASURES I AND J HAVE CONSECUTIVE NOTES SHORTER THAN AN EIGHTH,0.8509316770186336,"5. Number of pairs (i, j) such that Àúwi = Àúwj and Àúwi+1 = Àúwj+1."
EITHER BOTH OR NEITHER OF MEASURES I AND J HAVE CONSECUTIVE NOTES SHORTER THAN AN EIGHTH,0.8540372670807453,6. Mean distance between two measures with the same prototype.
EITHER BOTH OR NEITHER OF MEASURES I AND J HAVE CONSECUTIVE NOTES SHORTER THAN AN EIGHTH,0.8571428571428571,7. Variance in distance between two measures with the same prototype.
EITHER BOTH OR NEITHER OF MEASURES I AND J HAVE CONSECUTIVE NOTES SHORTER THAN AN EIGHTH,0.860248447204969,"C.5
USER STUDY DETAILS"
EITHER BOTH OR NEITHER OF MEASURES I AND J HAVE CONSECUTIVE NOTES SHORTER THAN AN EIGHTH,0.8633540372670807,"50 participants took place in the study on Mechanical Turk. Each was paid $5 to complete a survey
with 12 questions (3 poems each from four sources, Ours, GPT2-Finetune, BERT-Finetune, and
RichLyrics). All poems were chosen automatically by taking the top 3 examples from the generated
datasets according to GPT2-log-likelihood. The participants were asked to rank the following 3
statements from ""strongly disagree"" to ""strongly agree"" (1-5) as follows:"
IT IS OBVIOUS THAT THIS IS A POEM,0.8664596273291926,1. It is obvious that this is a poem
THIS TEXT IS COHERENT,0.8695652173913043,2. This text is coherent
THIS TEXT IS COHERENT,0.8726708074534162,Under review as a conference paper at ICLR 2022
THIS TEXT IS COHERENT,0.8757763975155279,"Method
Average Score
Lyricism
Coherence
Rhyme/Meter"
THIS TEXT IS COHERENT,0.8788819875776398,"SGM (Ours)
3.66
3.81
3.59
3.59
GPT2-Finetune
3.30
2.90
3.91
3.12
BERT-Finetune
2.28
2.11
2.00
2.77
RichLyrics
3.09
3.24
3.09
2.93"
THIS TEXT IS COHERENT,0.8819875776397516,"Table 4: A user study evaluation in the poetry domain. While GPT2-Finetune outperforms our model
in terms of coherence (likely because GPT-2 outperforms BERT at generation), our method outper-
forms in terms of overall lyricism (i.e., whether the poem reads like poetry or prose), prominence of
rhythmic/metrical structure, and average score."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.8850931677018633,3. I notice that this text has rhyme and meter
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.8881987577639752,"D
ADDITIONAL RESULTS"
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.8913043478260869,"D.1
COMPARISON TO CONSTRAINT SOLVING"
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.8944099378881988,"We also considered a comparison to a constraint-based implementation called Motifate, with explicit
attention to development of musical material (Muhammad Faisal, 2017). This approach was designed
with heuristics for 3-beat measures, while our evaluation models anticipated 4-beat measures, so
we could not obtain FD scores. Nevertheless, we found that even the structure was insufÔ¨Åcient‚Äîits
RF discriminator had accuracy 0.91, and its GCN discriminator had cross entropy loss 0.43, both of
which are signiÔ¨Åcantly worse than the other approaches."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.8975155279503105,"D.2
CONDITIONING ON USER-PROVIDED STRUCTURES"
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9006211180124224,"Here we show how user modiÔ¨Åcations can occur in the music and poetry settings. By explicitly
modifying c, we are able to generate two pieces of poetry or two tunes with similar internal patterns
but with different structural characteristics."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9037267080745341,"Figure 3: A song generated using our approach, and a nearly identical song generated where part of
the sampled relational constraints c were manually modiÔ¨Åed. These pieces were generated using A3,
and the same reference measures Àúw were used, but Œ¶c was slightly perturbed (the similarity relations
were changed)."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.906832298136646,"D.3
QUALITATIVE OBSERVATIONS ON THE MUSIC DOMAIN"
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9099378881987578,"In addition to quantitative measurements, we evaluated the strengths and weaknesses of our approach
using A2 (which was the best according to quantitative metrics). According to our observations,
the strengths of A2 include clearer phrases with obvious resolutions, likely and plausibly repetitive
rhythms, intervals between notes which seemed plausible but not overly repetitive, and less variance"
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9130434782608695,Under review as a conference paper at ICLR 2022
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9161490683229814,"Figure 4: Left: Poetry generated using relational constraints c ‚àºpœÜ(¬∑). Right: user modiÔ¨Åed variant
of c where the last two lines share a prototype with the two lines before them."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9192546583850931,"in quality. However, the results were not very rhythmically diverse, and certain idiomatic patterns
of resolutions of intervals between notes and at the end of phrases were not followed. Furthermore,
AttentionRNN does better in terms of creating realistic chord progressions (we did not explicitly
consider chord progressions in our model; doing so is a promising direction for future work). Finally,
while global structure is much better than the baselines, examples still relatively infrequently had the
full four-bar repetitions characteristic of much folk music."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.922360248447205,"D.4
EXAMPLES FROM THE MUSIC DOMAIN"
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9254658385093167,"We show an example of generated songs using our approach with each A1, A2, and A3 in Figure 5,
Figure 6, and Figure 7, respectively, and show an example generated using each of the baselines
MusicVAE16, AttentionRNN, MusicAutoBot, and StructureNet in Figures 8, 9, 10, & 11, respec-
tively. Qualitatively, the generated music and poetry appears plausible, exhibiting realistic high-level
structure without sacriÔ¨Åcing low-level structure."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9285714285714286,"Figure 5: An example of a song generated using our approach (A1). Measures that have the same
prototype are shown in the same color. Note the existence of repeating four-bar phrases, found
commonly in folk songs."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9316770186335404,"Figure 6: An example of a song generated using our approach (A2). Measures that have the same
prototype are shown in the same color. Note the existence of clear phrase endings marked by long
notes or rests, particularly the recurring pattern of fast notes resolving into long notes."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9347826086956522,"D.5
EXAMPLES FROM THE POETRY DOMAIN"
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.937888198757764,"In Figure D.5, we show an example poem generated using our approach (top) along with one generated
using GPT2-Opt (bottom). As can be seen, the GPT2-Opt poem does not capture structure in the
same way human poems do‚Äîe.g., adjacent lines are unrelated, lines have very unequal length, and
the only rhymes are the word ‚Äúthe‚Äù in the brown lines and the words ‚Äúto‚Äù and ‚Äútoo‚Äù in the green lines.
There is even less structure in poems generated using vanilla GPT2. Thus, GPT2 is completely unable
to capture high-level structure in the real poetry provided as training data. In contrast, our poem
captures structure very similar to the human poem shown in Figure 1, such as rhyming adjacent lines."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9409937888198758,Under review as a conference paper at ICLR 2022
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9440993788819876,"Figure 7: An example of a song generated using our approach (A3). Measures that have the same
prototype are shown in the same color. The existence of two-bar and three-bar phrases is apparent,
but the close note and rhythm similarities among different prototypes weaken the overall clarity of
the song‚Äôs melody."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9472049689440993,"Figure 8: An example of a song generated using Magenta‚Äôs hierarchical MusicVAE model Ô¨Ånetuned
on our dataset. While the local structure is extremely coherent, it does not seem to possess the
expected internal repetition/development."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9503105590062112,"Figure 9: An example of a song generated using AttentionRNN trained on our dataset. Note the
existence of erratic rhythms and unclear structure, which are common traits of custom-trained
AttentionRNN models."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.953416149068323,"Figure 10: An example of a song generated using MusicAutoBot. Note the repetitive nature and
stark contrast between the Ô¨Årst half and second half of the song, which are common problems with
transformer models."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9565217391304348,"Figure 11: An example of a song generated using StructureNet. While some degree of internal
structure is apparent, and the local coherence is high, the pattern of internal repetition seems fairly
arbitrary."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9596273291925466,"We also give examples of poetry generated using our baselines‚Äîin particular, GPT2 Ô¨Ånetuned and
optimized for rhyme and meter in Figure 15, BERT Ô¨Ånetuned as a language generation model in"
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9627329192546584,Under review as a conference paper at ICLR 2022
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9658385093167702,"Figure 17, RichLyrics, and our ablation (i.e., use BERT in conjunction with a uniformly randomly
sampled Œ¶c) in Figure 18."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.968944099378882,"Figure 12: Left: Poetry generated using relational constraints c ‚àºpœÜ(¬∑). Right: Poetry generated by
GPT2-Opt. Notice the lack of characteristic structure in GPT2-Opt, despite its coherence."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9720496894409938,"I know many things, and therefore I forgot,
Though I needed time to look ahead,
To understand something, time to let it fade away
As though it was yesterday as they
Were common things, free, rather‚Äîfree, to go like the tide;
But another is to make no one, as it does.
Perhaps you know it. A queen, her beautiful son,
And another woman who has to go without one.
The voices like their cries of war,
They let us believe in a good restore!"
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9751552795031055,"Figure 13: An example of poetry generated using our approach (A1). Lines that have the same
prototype are shown in the same color."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9782608695652174,Under review as a conference paper at ICLR 2022
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9813664596273292,Figure 14: An example of poetry generated using our approach (A3).
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.984472049689441,"Figure 15: A poem generated using GPT2-Opt. It is more plausible than BERT in terms of global
structure, which may be due to the fact that GPT2 is a better text generation tool than BERT, but it is
still somewhat repetitive and its structure is not very human-like."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9875776397515528,"Figure 16: A poem generated using BERT. It is clearly overly repetitive and not very semantically
coherent, and lacks high-level structure."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9906832298136646,Under review as a conference paper at ICLR 2022
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9937888198757764,"Figure 17: A poem generated using RichLyrics. While it is less repetitive than non-conditioned
BERT, it is still not very semantically coherent, and lacks high-level structure."
I NOTICE THAT THIS TEXT HAS RHYME AND METER,0.9968944099378882,"Figure 18: A poem generated using our ablation. While it is much more coherent, it lacks the
idiomatic rhyme and meter structure of our approach."
