Section,Section Appearance Order,Paragraph
MICROSOFT RESEARCH NEW ENGLAND,0.0,"1 Microsoft Research New England
2 Microsoft Research Asia
{jiaxinshi,chang.liu,lmackey}@microsoft.com"
ABSTRACT,0.0016638935108153079,ABSTRACT
ABSTRACT,0.0033277870216306157,"We introduce a new family of particle evolution samplers suitable for constrained
domains and non-Euclidean geometries. Stein Variational Mirror Descent and
Mirrored Stein Variational Gradient Descent minimize the Kullback-Leibler (KL)
divergence to constrained target distributions by evolving particles in a dual space
deﬁned by a mirror map. Stein Variational Natural Gradient exploits non-Euclidean
geometry to more efﬁciently minimize the KL divergence to unconstrained targets.
We derive these samplers from a new class of mirrored Stein operators and adaptive
kernels developed in this work. We demonstrate that these new samplers yield
accurate approximations to distributions on the simplex, deliver valid conﬁdence in-
tervals in post-selection inference, and converge more rapidly than prior methods in
large-scale unconstrained posterior inference. Finally, we establish the convergence
of our new procedures under veriﬁable conditions on the target distribution."
INTRODUCTION,0.004991680532445923,"1
INTRODUCTION"
INTRODUCTION,0.0066555740432612314,"Accurately approximating an unnormalized distribution with a discrete sample is a fundamental
challenge in machine learning, probabilistic inference, and Bayesian inference. Particle evolution
methods like Stein variational gradient descent (SVGD, Liu & Wang, 2016) tackle this challenge
by applying deterministic updates to particles using operators based on Stein’s method (Stein, 1972;
Gorham & Mackey, 2015; Oates et al., 2017; Liu et al., 2016; Chwialkowski et al., 2016; Gorham &
Mackey, 2017) and reproducing kernels (Berlinet & Thomas-Agnan, 2011) to sequentially minimize
Kullback-Leibler (KL) divergence. SVGD has found great success in approximating unconstrained
distributions for probabilistic learning (Feng et al., 2017; Haarnoja et al., 2017; Kim et al., 2018) but
breaks down for constrained targets, like distributions on the simplex (Patterson & Teh, 2013) or the
targets of post-selection inference (Taylor & Tibshirani, 2015; Lee et al., 2016; Tian et al., 2016), and
fails to exploit informative non-Euclidean geometry (Amari, 1998)."
INTRODUCTION,0.008319467554076539,"In this work, we derive a family of particle evolution samplers suitable for target distributions with
constrained domains and non-Euclidean geometries. Our development draws inspiration from mirror
descent (MD) (Nemirovskij & Yudin, 1983), a ﬁrst-order optimization method that generalizes
gradient descent with non-Euclidean geometry. To sample from a distribution with constrained
support, our method ﬁrst maps particles to a dual space. There, we update particle locations using
a new class of mirrored Stein operators and adaptive reproducing kernels introduced in this work.
Finally, the dual particles are mapped back to sample points in the original space, ensuring that all
constraints are satisﬁed. We illustrate this procedure in Fig. 1. In Sec. 3, we develop two algorithms –
Mirrored SVGD (MSVGD) and Stein Variational Mirror Descent (SVMD) – with different updates
in the dual space; when only a single particle is used, MSVGD reduces to gradient ascent on the
log dual space density, and SVMD reduces to mirror ascent on the log target density. In addition,
by exploiting the connection between MD and natural gradient descent (Amari, 1998; Raskutti &
Mukherjee, 2015), we develop a third algorithm – Stein Variational Natural Gradient (SVNG) – that
extends SVMD to unconstrained targets with non-Euclidean geometry."
INTRODUCTION,0.009983361064891847,"In Sec. 5, we demonstrate the advantages of our algorithms on benchmark simplex-constrained
problems from the literature, constrained sampling problems in post-selection inference (Taylor &
Tibshirani, 2015; Lee et al., 2016; Tian et al., 2016), and unconstrained large-scale posterior inference
with the Fisher information metric. Finally, we analyze the convergence of our mirrored algorithms
in Sec. 6 and discuss our results in Sec. 7."
INTRODUCTION,0.011647254575707155,Published as a conference paper at ICLR 2022 Θ ∇ψ ∇ψ∗
INTRODUCTION,0.013311148086522463,"θt
θt+1 ηt ηt+1"
INTRODUCTION,0.014975041597337771,"ϵtEθ∼qt[Mp,ψK(θt, θ)]"
INTRODUCTION,0.016638935108153077,"Figure 1: Updating particle approximations in constrained domains Θ. Standard updates like SVGD
(dashed arrow) can push particles outside of the support. Our mirrored Stein updates in Alg. 1 (solid
arrows) preserve the support by updating particles in a dual space and mapping back to Θ."
INTRODUCTION,0.018302828618968387,"Related work
Our mirrored Stein operators (6) are instances of diffusion Stein operators in the
sense of Gorham & Mackey (2017), but their speciﬁc properties have not been studied, nor have
they been used to develop sampling algorithms. There is now a large body of work on transferring
algorithmic ideas from optimization to MCMC (e.g., Welling & Teh, 2011; Simsekli et al., 2016;
Dalalyan, 2017; Durmus et al., 2018; Ma et al., 2019) and SVGD-like sampling methods (e.g., Liu
et al., 2019a;b; Zhu et al., 2020; Zhang et al., 2020a). The closest to our work in this space is the
recent marriage of mirror descent and MCMC. For example, Hsieh et al. (2018) propose to run
Langevin Monte Carlo (LMC, an Euler discretization of the Langevin diffusion) in a mirror space.
Zhang et al. (2020b) analyze the convergence properties of the mirror-Langevin diffusion, Chewi et al.
(2020) demonstrate its advantages over the Langevin diffusion when using a Newton-type metric, and
Ahn & Chewi (2020) study its discretization for MCMC sampling in constrained domains. Relatedly,
Patterson & Teh (2013) proposed stochastic Riemannian LMC for sampling on the simplex."
INTRODUCTION,0.019966722129783693,"Several modiﬁcations of SVGD have been proposed to incorporate geometric information. Rieman-
nian SVGD (RSVGD, Liu & Zhu, 2018) generalizes SVGD to Riemannian manifolds, but, even with
the same metric tensor, their updates are more complex than ours: notably they require higher-order
kernel derivatives, do not operate in a mirror space, and do not reduce to natural gradient descent
when a single particle is used. They also reportedly do not perform well when with scalable stochastic
estimates of ∇log p. Stein Variational Newton (SVN, Detommaso et al., 2018; Chen et al., 2019)
introduces second-order information into SVGD. Their algorithm requires an often expensive Hessian
computation and need not lead to descent directions, so inexact approximations are employed in
practice. Our SVNG can be seen as an instance of matrix SVGD (MatSVGD, Wang et al., 2019) with
an adaptive time-dependent kernel discussed in Sec. 4.4, a choice that is not explored in Wang et al.
(2019) and which recovers natural gradient descent when n = 1 unlike the heuristic kernel construc-
tions of Wang et al. (2019). None of the aforementioned works provide convergence guarantees, and
neither SVN nor matrix SVGD deals with constrained domains."
INTRODUCTION,0.021630615640599003,"2
BACKGROUND: MIRROR DESCENT AND NON-EUCLIDEAN GEOMETRY"
INTRODUCTION,0.02329450915141431,"Standard gradient descent can be viewed as optimizing a local quadratic approximation to the target
function f: θt+1 = argminθ∈Θ ∇f(θt)⊤θ +
1
2ϵt ∥θ −θt∥2
2. When Θ ⊆Rd is constrained, it can be
advantageous to replace ∥· ∥2 with a function Ψ that reﬂects the geometry of a problem (Nemirovskij
& Yudin, 1983; Beck & Teboulle, 2003):"
INTRODUCTION,0.024958402662229616,θt+1 = argminθ∈Θ ∇f(θt)⊤θ + 1
INTRODUCTION,0.026622296173044926,"ϵt Ψ(θ, θt).
(1)"
INTRODUCTION,0.028286189683860232,"We consider the mirror descent algorithm (Nemirovskij & Yudin, 1983; Beck & Teboulle, 2003)
which chooses Ψ to be the Bregman divergence induced by a strongly convex, essentially smooth1
function ψ : Θ →R ∪{∞}: Ψ(θ, θ′) = ψ(θ) −ψ(θ′) −∇ψ(θ′)⊤(θ −θ′). When Θ is a (d + 1)-
simplex {θ : Pd
i=1 θi ≤1 and θi ≥0 for i ∈[d]}, a common choice of ψ is the negative entropy
ψ(θ) = Pd+1
i=1 θi log θi, for θd+1 ≜1 −Pd
i=1 θd. The solution of (1) is given by"
INTRODUCTION,0.029950083194675542,"θt+1 = ∇ψ∗(∇ψ(θt) −ϵt∇f(θt)),
(2)"
INTRODUCTION,0.03161397670549085,"where ψ∗(η) ≜supθ∈Θ η⊤θ −ψ(θ) is the convex conjugate of ψ and ∇ψ is a bijection from Θ to
dom(ψ∗) with inverse map (∇ψ)−1 = ∇ψ∗. We can view the update in (2) as ﬁrst mapping θt to ηt
by ∇ψ, applying the update ηt+1 = ηt −ϵt∇f(θt), and mapping back through θt+1 = ∇ψ∗(ηt+1)."
INTRODUCTION,0.033277870216306155,1ψ is continuously differentiable on the interior of Θ with ∥∇ψ(θt)∥→∞whenever θt →θ ∈∂Θ.
INTRODUCTION,0.03494176372712146,Published as a conference paper at ICLR 2022
INTRODUCTION,0.036605657237936774,"Mirror descent can also be viewed as a discretization of the continuous-time dynamics dηt =
−∇f(θt)dt, θt = ∇ψ∗(ηt), which is equivalent to the Riemannian gradient ﬂow (see App. A):"
INTRODUCTION,0.03826955074875208,"dθt = −∇2ψ(θt)−1∇f(θt)dt,
or equivalently,
dηt = −∇2ψ∗(ηt)−1∇ηtf(∇ψ∗(ηt))dt, (3)"
INTRODUCTION,0.03993344425956739,"where ∇2ψ(θ) and ∇2ψ∗(η) are Riemannian metric tensors. In information geometry, the discretiza-
tion of (3) is known as natural gradient descent (Amari, 1998). There is considerable theoretical and
practical evidence (Martens, 2014) showing that natural gradient works efﬁciently in learning."
INTRODUCTION,0.04159733777038269,"3
STEIN’S IDENTITY AND MIRRORED STEIN OPERATORS"
INTRODUCTION,0.04326123128119801,"Stein’s identity (Stein, 1972) is a tool for characterizing a target distribution P using a so-called Stein
operator. We assume P has a differentiable density p with a closed convex support Θ ⊆Rd. A Stein
operator Sp takes as input functions g from a Stein set G and outputs mean-zero functions under p:"
INTRODUCTION,0.04492512479201331,"Eθ∼p[(Spg)(θ)] = 0,
for all g ∈G.
(4)"
INTRODUCTION,0.04658901830282862,Gorham & Mackey (2015) proposed the Langevin Stein operator given by
INTRODUCTION,0.048252911813643926,"(Spg)(θ) = g(θ)⊤∇log p(θ) + ∇· g(θ),
(5)"
INTRODUCTION,0.04991680532445923,"where g is a vector-valued function and ∇· g is its divergence. For an unconstrained domain with
Ep[∥∇log p(θ)∥2] < ∞, Stein’s identity (4) holds for this operator whenever g ∈C1 is bounded and
Lipschitz by (Gorham et al., 2019, proof of Prop. 3). However, on constrained domains Θ, Stein’s
identity fails to hold for many reasonable inputs g if p is non-vanishing or explosive at the boundary."
INTRODUCTION,0.051580698835274545,"Motivated by this deﬁciency and by a desire to exploit non-Euclidean geometry, we propose an
alternative mirrored Stein operator,"
INTRODUCTION,0.05324459234608985,"(Mp,ψg)(θ) = g(θ)⊤∇2ψ(θ)−1∇log p(θ) + ∇· (∇2ψ(θ)−1g(θ)),
(6)"
INTRODUCTION,0.05490848585690516,"where ψ is a strongly convex, essentially smooth function as in Sec. 2 with (∇2ψ)−1 differentiable
and Lipschitz on Θ. We derive this operator from the (inﬁnitesimal) generator of the mirror-Langevin
diffusion (19) in App. C. The following result, proved in App. I.1, shows that Mp,ψ generates
mean-zero functions under p whenever ∇2ψ−1 suitably cancels the growth of p at the boundary.
Proposition 1. Suppose that ∇2ψ(θ)−1∇log p(θ) and ∇· ∇2ψ(θ)−1 are p-integrable.
If
limr→∞
R"
INTRODUCTION,0.056572379367720464,"∂Θr p(θ)∥∇2ψ(θ)−1nr(θ)∥2dθ = 0 for Θr ≜{θ ∈Θ : ∥θ∥∞≤r} and nr(θ) the
outward unit normal vector2 to ∂Θr at θ, then Ep[(Mp,ψg)(θ)] = 0 if g ∈C1 is bounded Lipschitz."
INTRODUCTION,0.05823627287853577,"Example 1 (Dirichlet p, Negative entropy ψ). When θ1:d+1 ∼Dir(α) for α ∈Rd+1
+
, even
setting g(θ) = 1 in (5) need not cause the identity to hold when some αj ≤1. However, when
ψ(θ) = Pd+1
j=1 θj log θj, we show in App. B that the conditions of Prop. 1 are met for any α.
Remarkably, the mirror-Langevin diffusion for our choice of ψ is the Wright-Fisher diffusion (Ethier,
1976) which Gan et al. (2017) recently used to bound distances to Dirichlet distributions."
SAMPLING WITH MIRRORED STEIN OPERATORS,0.059900166389351084,"4
SAMPLING WITH MIRRORED STEIN OPERATORS"
SAMPLING WITH MIRRORED STEIN OPERATORS,0.06156405990016639,"Liu & Wang (2016) pioneered the idea of using Stein operators to approximate a target distribution
with particles. Their popular SVGD algorithm updates each particle in its approximation by applying
the update rule θt+1 = θt + ϵtgt(θt) for a chosen mapping gt : Rd →Rd. Speciﬁcally, SVGD
chooses the mapping g∗
t that leads to the largest decrease in KL divergence to p in the limit as ϵt →0.
The following theorem summarizes their main ﬁndings.
Theorem 2 (Liu & Wang, 2016, Thm. 3.1). Suppose (θt)t≥0 satisﬁes dθt = gt(θt)dt for bounded
Lipschitz gt ∈C1 : Rd →Rd and that θt has density qt with Eqt[∥∇log qt∥2] < ∞. If KL(qt∥p) ≜
Eqt[log(qt/p)] exists then, for the Langevin Stein operator Sp (5),"
SAMPLING WITH MIRRORED STEIN OPERATORS,0.0632279534109817,"d
dtKL(qt∥p) = −Eθt∼qt[(Spgt)(θt)].
(7)"
SAMPLING WITH MIRRORED STEIN OPERATORS,0.064891846921797,"2For a closed convex set whose boundary ∂Θ can be locally represented as F(θ1, . . . , θd) = 0, its unit
normal vector is deﬁned as n(θ) = ±
∇F (θ1,...,θd)
∥∇F (θ1,...,θd)∥2 ."
SAMPLING WITH MIRRORED STEIN OPERATORS,0.06655574043261231,Published as a conference paper at ICLR 2022
SAMPLING WITH MIRRORED STEIN OPERATORS,0.06821963394342762,Algorithm 1 Mirrored Stein Variational Gradient Descent & Stein Variational Mirror Descent
SAMPLING WITH MIRRORED STEIN OPERATORS,0.06988352745424292,"Input: density p on Θ, kernel k, mirror function ψ, particles (θi
0)n
i=1 ⊂Θ, step sizes (ϵt)T
t=1
Init: ηi
0 ←∇ψ(θi
0) for i ∈[n]
for t = 0 : T do"
SAMPLING WITH MIRRORED STEIN OPERATORS,0.07154742096505824,"if SVMD then Kt ←Kψ,t (13) else Kt ←kI (MSVGD)
for i ∈[n], ηi
t+1 ←ηi
t + ϵt 1"
SAMPLING WITH MIRRORED STEIN OPERATORS,0.07321131447587355,"n
Pn
j=1 Mp,ψKt(θi
t, θj
t)
(for Mp,ψKt(·, θ) deﬁned in Thm. 3)
for i ∈[n], θi
t+1 ←∇ψ∗(ηi
t+1)
return {θi
T +1}n
i=1."
SAMPLING WITH MIRRORED STEIN OPERATORS,0.07487520798668885,"To improve its current particle approximation, SVGD ﬁnds the choice of gt that most quickly
decreases KL(qt∥p) at time t, i.e., it minimizes
d
dtKL(qt∥p) over a set of candidate directions gt.
SVGD ﬁnds gt in a reproducing kernel Hilbert space (RKHS, Berlinet & Thomas-Agnan, 2011) norm
ball BHd = {g : ∥g∥Hd ≤1}, where Hd is the product RKHS containing vector-valued functions
with each component in the RKHS H of k. Then the optimal g∗
t ∈BHd that minimizes (7) is"
SAMPLING WITH MIRRORED STEIN OPERATORS,0.07653910149750416,"g∗
t ∝g∗
qt,k ≜Eθt∼qt[k(θt, ·)∇log p(θt) + ∇θtk(θt, ·)] = Eθt∼qt[SpKk(·, θt)],"
SAMPLING WITH MIRRORED STEIN OPERATORS,0.07820299500831947,"where we let Kk(θ, θ′) = k(θ, θ′)I, and SpKk(·, θ) denotes applying Sp to each row of Kk(·, θ).
SVGD has found great success in approximating unconstrained target distributions p but breaks
down for constrained targets and fails to exploit non-Euclidean geometry. Our goal is to develop new
particle evolution samplers suitable for constrained domains and non-Euclidean geometries."
MIRRORED DYNAMICS,0.07986688851913477,"4.1
MIRRORED DYNAMICS"
MIRRORED DYNAMICS,0.08153078202995008,"SVGD encounters two difﬁculties when faced with a constrained support. First, the SVGD updates can
push the random variable θt outside of its support Θ, rendering all future updates undeﬁned. Second,
Stein’s identity (4) often fails to hold for candidate directions in BHd (cf. Ex. 1). When this occurs,
SVGD need not converge to p as p is not a stationary point of its dynamics (i.e., d"
MIRRORED DYNAMICS,0.08319467554076539,"dtKL(qt∥p)|qt=p ̸= 0
when qt = p). Inspired by mirror descent (Nemirovskij & Yudin, 1983), we consider the following
mirrored dynamics"
MIRRORED DYNAMICS,0.08485856905158069,"θt = ∇ψ∗(ηt)
for
dηt = gt(θt)dt,
or, equivalently,
dθt = ∇2ψ(θt)−1gt(θt)dt,
(8)"
MIRRORED DYNAMICS,0.08652246256239601,"where gt : Θ →Rd now represents the update direction in η space. The inverse mirror map ∇ψ∗
automatically guarantees that θt belongs to the constrained domain Θ. Since ψ is strongly convex
and ∇2ψ−1 is bounded Lipschitz, from Thm. 2 it follows for any bounded Lipschitz gt that"
MIRRORED DYNAMICS,0.08818635607321132,"d
dtKL(qt∥p) = −Eθt∼qt[(Mp,ψgt)(θt)],
(9)"
MIRRORED DYNAMICS,0.08985024958402663,"where Mp,ψ is the mirrored Stein operator (6). In the following sections, we propose three new
deterministic sampling algorithms by seeking the optimal direction gt that minimizes (9) over different
function classes. Thm. 3 (proved in App. I.2) forms the basis of our analysis.
Theorem 3 (Optimal mirror updates in RKHS). Suppose (θt)t≥0 follows the mirrored dynamics (8).
Let HK denote the RKHS of a matrix-valued kernel K : Θ × Θ →Sd×d (Micchelli & Pontil, 2005).
Then, the optimal direction of gt that minimizes (9) in the norm ball BHK ≜{g : ∥g∥HK ≤1} is"
MIRRORED DYNAMICS,0.09151414309484193,"g∗
t ∝g∗
qt,K ≜Eθt∼qt[Mp,ψK(·, θt)],
(10)"
MIRRORED DYNAMICS,0.09317803660565724,"where Mp,ψK(·, θ) applies Mp,ψ (6) to each row of the matrix-valued function Kθ = K(·, θ)."
MIRRORED STEIN VARIATIONAL GRADIENT DESCENT,0.09484193011647254,"4.2
MIRRORED STEIN VARIATIONAL GRADIENT DESCENT"
MIRRORED STEIN VARIATIONAL GRADIENT DESCENT,0.09650582362728785,"Following the pattern of SVGD, one can choose the K of Thm. 3 to be Kk(θ, θ′) = k(θ, θ′)I, where
k is any scalar-valued kernel. In this case, the resulting update g∗
qt,Kk(·) = Eθt∼qt[Mp,ψKk(·, θt)]
is equivalent to running SVGD in the dual η space before mapping back to Θ.
Theorem 4 (Mirrored SVGD updates).
In the setting of Thm. 3,
let kψ(η, η′)
=
k(∇ψ∗(η), ∇ψ∗(η′)), pH(η) = p(∇ψ∗(η)) · | det ∇2ψ∗(η)| denote the density of η = ∇ψ(θ)
when θ ∼p, and qt,H denote the distribution of ηt under the mirrored dynamics (8). If Kk = kI,"
MIRRORED STEIN VARIATIONAL GRADIENT DESCENT,0.09816971713810316,"g∗
qt,Kk(θ′) = Eηt∼qt,H[kψ(ηt, η′)∇log pH(ηt) + ∇ηtkψ(ηt, η′)]
∀θ′ ∈Θ, η′ = ∇ψ(θ′).
(11)"
MIRRORED STEIN VARIATIONAL GRADIENT DESCENT,0.09983361064891846,Published as a conference paper at ICLR 2022
MIRRORED STEIN VARIATIONAL GRADIENT DESCENT,0.10149750415973377,"The proof is in App. I.3. By discretizing the dynamics dηt = g∗
qt,Kk(θt)dt and initializing with any
particle approximation q0 = 1"
MIRRORED STEIN VARIATIONAL GRADIENT DESCENT,0.10316139767054909,"n
Pn
i=1 δθi
0, we obtain Mirrored SVGD (MSVGD), our ﬁrst algorithm
for sampling in constrained domains. The details are summarized in Alg. 1."
MIRRORED STEIN VARIATIONAL GRADIENT DESCENT,0.1048252911813644,"When only a single particle is used (n = 1) and the differentiable input kernel satisﬁes ∇k(θ, θ) = 0,
the MSVGD update (11) reduces to gradient descent on −log pH(η). Note however that the modes
of the mirrored density pH(η) need not match those of the target density p(θ) (see the examples in
App. E). Since we are primarily interested in the θ-space density, it is natural to ask whether there
exists a mirrored dynamics that reduces to ﬁnding the mode of p(θ) in this limiting case. In the next
section, we give an answer to this question by designing an adaptive reproducing kernel that yields a
mirror descent-like update."
STEIN VARIATIONAL MIRROR DESCENT,0.1064891846921797,"4.3
STEIN VARIATIONAL MIRROR DESCENT"
STEIN VARIATIONAL MIRROR DESCENT,0.10815307820299501,"Our second sampling algorithm for constrained problems is called Stein Variational Mirror De-
scent (SVMD). We start by introducing a new matrix-valued kernel that incorporates the metric ∇2ψ
and evolves with the distribution qt.
Deﬁnition 1 (Kernels for SVMD). Given a continuous scalar-valued kernel k, consider the Mercer
representation3 k(θ, θ′) = P"
STEIN VARIATIONAL MIRROR DESCENT,0.10981697171381032,"i≥1 λt,iut,i(θ)ut,i(θ′) w.r.t. qt, where ut,i is an eigenfunction satisfying"
STEIN VARIATIONAL MIRROR DESCENT,0.11148086522462562,"Eθt∼qt[k(θ, θt)ut,i(θt)] = λt,iut,i(θ).
(12)"
STEIN VARIATIONAL MIRROR DESCENT,0.11314475873544093,"For k1/2
t
(θ, θ′) ≜P"
STEIN VARIATIONAL MIRROR DESCENT,0.11480865224625623,"i≥1 λ1/2
t,i ut,i(θ)ut,i(θ′), we deﬁne the adaptive SVMD kernel at time t,"
STEIN VARIATIONAL MIRROR DESCENT,0.11647254575707154,"Kψ,t(θ, θ′) ≜Eθt∼qt[k1/2
t
(θ, θt)∇2ψ(θt)k1/2
t
(θt, θ′)].
(13)"
STEIN VARIATIONAL MIRROR DESCENT,0.11813643926788686,"By Thm. 3, the optimal update direction for the SVMD kernel ball is g∗
qt,Kψ,t =Eqt[Mp,ψKψ,t(·, θt)].
We obtain the SVMD algorithm (summarized in Alg. 1) by discretizing dηt = g∗
qt,Kψ,t(θt)dt and
initializing with q0 = 1"
STEIN VARIATIONAL MIRROR DESCENT,0.11980033277870217,"n
Pn
i=1 δθi
0. Because of the discrete representation of qt, Kψ,t takes the form"
STEIN VARIATIONAL MIRROR DESCENT,0.12146422628951747,"Kψ,t(θ, θ′) = Pn
i=1
Pn
j=1 λ1/2
t,i λ1/2
t,j ut,i(θ)ut,j(θ′)Γt,ij,"
STEIN VARIATIONAL MIRROR DESCENT,0.12312811980033278,"Γt,ij = 1"
STEIN VARIATIONAL MIRROR DESCENT,0.12479201331114809,"n
Pn
ℓ=1 ut,i(θℓ
t)ut,j(θℓ
t)∇2ψ(θℓ
t)."
STEIN VARIATIONAL MIRROR DESCENT,0.1264559068219634,"Here both λt,j and ut,j(θi
t) can be computed by solving a matrix eigenvalue problem involving the
particle set {θi
t}n
i=1: Btvt,j = nλt,jvt,j, where Bt = (k(θi
t, θj
t))n
i,j=1 ∈Rn×n is the Gram matrix of
pairwise kernel evaluations at particle locations, and the i-th element of vt,j is ut,j(θi
t). To compute
∇θKψ,t(θ, θ′), we differentiate both sides of (12) to ﬁnd that ∇ut,j(θ) =
1
λt,j
Pn
i=1 vt,j,i∇θk(θ, θi
t).
This technique was used in Shi et al. (2018) to estimate gradients of eigenfunctions w.r.t. a continuous
q. Following their recommendations, we truncate the sum at the J-th largest eigenvalues according to
a threshold (τ ≥PJ
j=1 λt,j/ Pn
j=1 λt,j) to ensure numerical stability."
STEIN VARIATIONAL MIRROR DESCENT,0.1281198003327787,"Notably, SVMD differs from MSVGD only in its choice of kernel, but, whenever ∇k(θ, θ) = 0, this
change is sufﬁcient to exactly recover mirror descent when n = 1.
Proposition 5 (Single-particle SVMD is mirror descent). If n = 1, then one step of SVMD becomes"
STEIN VARIATIONAL MIRROR DESCENT,0.129783693843594,"ηt+1 = ηt + ϵt(k(θt, θt)∇log p(θt) + ∇k(θt, θt)),
θt+1 = ∇ψ∗(ηt+1)."
STEIN VARIATIONAL NATURAL GRADIENT,0.1314475873544093,"4.4
STEIN VARIATIONAL NATURAL GRADIENT"
STEIN VARIATIONAL NATURAL GRADIENT,0.13311148086522462,"The fact that SVMD recovers mirror descent as a special case is not only of relevance in constrained
problems. We next exploit the connection between MD and natural gradient descent discussed in
Sec. 2 to design a new sampler – Stein Variational Natural Gradient (SVNG) – that more efﬁciently
approximates unconstrained targets. The idea is to replace the Hessian ∇2ψ(·) in the SVMD dynamics
dθt = ∇2ψ(θt)−1g∗
qt,Kψ,t(θt) with a general metric tensor G(·). The result is the Riemannian
gradient ﬂow"
STEIN VARIATIONAL NATURAL GRADIENT,0.13477537437603992,"dθt = G(θt)−1g∗
qt,KG,t(θt)dt
with
KG,t(θ, θ′) ≜Eθt∼qt[k1/2(θ, θt)G(θt)k1/2(θt, θ′)].
(14)"
STEIN VARIATIONAL NATURAL GRADIENT,0.13643926788685523,3See App. F for background on Mercer representations in non-compact domains.
STEIN VARIATIONAL NATURAL GRADIENT,0.13810316139767054,Published as a conference paper at ICLR 2022
STEIN VARIATIONAL NATURAL GRADIENT,0.13976705490848584,"0
200
400
Number of particle updates, T 0.0 0.5 1.0 1.5"
STEIN VARIATIONAL NATURAL GRADIENT,0.14143094841930118,Energy distance
STEIN VARIATIONAL NATURAL GRADIENT,0.14309484193011648,Sparse Dirichlet
STEIN VARIATIONAL NATURAL GRADIENT,0.1447587354409318,"Projected SVGD
SVMD
MSVGD, k
MSVGD, k2"
STEIN VARIATIONAL NATURAL GRADIENT,0.1464226289517471,"0
200
400
Number of particle updates, T 0.0 0.1 0.2 0.3"
STEIN VARIATIONAL NATURAL GRADIENT,0.1480865224625624,Quadratic
STEIN VARIATIONAL NATURAL GRADIENT,0.1497504159733777,"Projected SVGD
SVMD
MSVGD, k
MSVGD, k2"
STEIN VARIATIONAL NATURAL GRADIENT,0.15141430948419302,"Figure 2: Quality of 50-particle approximations to 20-dimensional distributions on the simplex after
T particle updates. (Left) Sparse Dirichlet posterior of Patterson & Teh (2013). (Right) Quadratic
simplex target of Ahn & Chewi (2020). Details of the target distributions are in App. G.1."
STEIN VARIATIONAL NATURAL GRADIENT,0.15307820299500832,"Given any initial particle approximation q0 =
1
n
Pn
i=1 δθi
0, we discretize these dynamics to
obtain the unconstrained SVNG sampler of Alg. 2 in the appendix.
SVNG can be seen
as an instance of MatSVGD (Wang et al., 2019) with a new adaptive time-dependent kernel
G−1(θ)KG,t(θ, θ′)G−1(θ′). However, similar to Prop. 5 and unlike the heuristic kernels of Wang
et al. (2019), SVNG reduces to natural gradient ascent for ﬁnding the mode of p(θ) when n = 1.
SVNG is well-suited to Bayesian inference problems where the target is a posterior distribution
p(θ) ∝π(θ)π(y|θ). There, the metric tensor G(θ) can be set to the Fisher information matrix
Eπ(y|θ)[∇log π(y|θ)∇log π(y|θ)⊤] of the data likelihood π(y|θ). Ample precedent from natu-
ral gradient variational inference (Hoffman et al., 2013; Khan & Nielsen, 2018) and Riemannian
MCMC (Patterson & Teh, 2013) suggests that encoding problem geometry in this manner often leads
to more rapid convergence."
EXPERIMENTS,0.15474209650582363,"5
EXPERIMENTS"
EXPERIMENTS,0.15640599001663893,"We next conduct a series of simulated and real-data experiments to assess (1) distributional approxi-
mation on the simplex, (2) frequentist conﬁdence interval construction for (constrained) post-selection
inference, and (3) large-scale posterior inference with non-Euclidean geometry. To compare with
standard SVGD on constrained domains and to prevent its particles from exiting the domain Θ, we
introduce a Euclidean projection onto Θ following each SVGD update. For SVMD, we need to solve
an eigenvalue problem, which costs O(n3) time. In practice the number of particles used for particle
evolution algorithms is relatively small, even for SVGD, due to the O(n2) cost of updates. We have
produced a practical SVMD implementation that is computationally competitive with MSVGD and
SVGD for standard particle counts like n = 50 (used in all experiments)."
APPROXIMATION QUALITY ON THE SIMPLEX,0.15806988352745424,"5.1
APPROXIMATION QUALITY ON THE SIMPLEX"
APPROXIMATION QUALITY ON THE SIMPLEX,0.15973377703826955,"We ﬁrst measure distributional approximation quality using two 20-dimensional simplex-constrained
targets: the sparse Dirchlet posterior of Patterson & Teh (2013) extended to 20 dimensions and the
quadratic simplex target of Ahn & Chewi (2020). The Dirichlet target mimics the multimodal sparse
conditionals that arise in latent Dirichlet allocation (Blei et al., 2003) but induces a log concave
density in η space, while the quadratic is log-concave in θ space. In Fig. 2, we compare the quality of
MSVGD, SVMD, and projected SVGD with 50 particles and inverse multiquadric kernel k (Gorham &
Mackey, 2017) by computing the energy distance (Sz´ekely & Rizzo, 2013) to a surrogate ground truth
sample of size 1000 (drawn i.i.d. or, in the quadratic case, from the No-U-Turn Sampler (Hoffman &
Gelman, 2014)). We also compare to MSVGD with k2(θ, θ′) = k(∇ψ(θ), ∇ψ(θ′)), a choice which
corresponds to running SVGD in the dual space with kernel k by Thm. 4 and which ensures the
convergence of MSVGD to p by the upcoming Thms. 6 to 8."
APPROXIMATION QUALITY ON THE SIMPLEX,0.16139767054908485,"In the quadratic case, SVMD is favored over MSVGD as it is able to exploit the log-concavity of p(θ).
In contrast, for the multimodal sparse Dirichlet with p(θ) unbounded near the boundary, MSVGD
converges slightly more rapidly than SVMD by exploiting the log concave structure in η space. This
parallels the observation of Hsieh et al. (2018) that LMC in the mirror space outperforms Riemannian
LMC for sparse Dirichlet distributions. Projected SVGD fails to converge to the target in both cases
and has particular difﬁculty in approximating the sparse Dirichlet target with unbounded density."
APPROXIMATION QUALITY ON THE SIMPLEX,0.16306156405990016,Published as a conference paper at ICLR 2022
APPROXIMATION QUALITY ON THE SIMPLEX,0.16472545757071547,"1000
1500
2000
2500
3000
Number of sample points, N 0.86 0.88 0.90 0.92 0.94"
APPROXIMATION QUALITY ON THE SIMPLEX,0.16638935108153077,Actual coverage
APPROXIMATION QUALITY ON THE SIMPLEX,0.16805324459234608,"Standard
MSVGD
SVMD"
APPROXIMATION QUALITY ON THE SIMPLEX,0.16971713810316139,(a) Nominal coverage: 0.9
APPROXIMATION QUALITY ON THE SIMPLEX,0.1713810316139767,"0.80
0.85
0.90
0.95
1.00
Nominal coverage 0.80 0.85 0.90 0.95 1.00"
APPROXIMATION QUALITY ON THE SIMPLEX,0.17304492512479203,Actual coverage
APPROXIMATION QUALITY ON THE SIMPLEX,0.17470881863560733,"Standard
MSVGD
SVMD"
APPROXIMATION QUALITY ON THE SIMPLEX,0.17637271214642264,(b) N = 5000 sample points
APPROXIMATION QUALITY ON THE SIMPLEX,0.17803660565723795,"Figure 3: Coverage of post-selection CIs across (a) 500 / (b) 200 replications of simulation of Sepehri
& Markovic (2017)."
APPROXIMATION QUALITY ON THE SIMPLEX,0.17970049916805325,"MSVGD with k and k2 perform very similarly, but we observe that k yields better approximation
quality upon convergence. Therefore, we employ k in the remaining MSVGD experiments."
CONFIDENCE INTERVALS FOR POST-SELECTION INFERENCE,0.18136439267886856,"5.2
CONFIDENCE INTERVALS FOR POST-SELECTION INFERENCE"
CONFIDENCE INTERVALS FOR POST-SELECTION INFERENCE,0.18302828618968386,"We next apply our algorithms to the constrained sampling problems that arise in post-selection
inference (Taylor & Tibshirani, 2015; Lee et al., 2016). Speciﬁcally, we consider the task of forming
valid conﬁdence intervals (CIs) for regression parameters selected using the randomized Lasso (Tian
et al., 2016) with data X ∈R˜n×p and y ∈R˜n and user-generated randomness w ∈Rp from a
log-concave distribution with density g. The randomized Lasso returns ˆβ ∈Rp with non-zero
coefﬁcients denoted by ˆβE and their signs by sE. It is common practice to report least squares CIs
for βE by running a linear regression on the selected features E. However, since E is chosen based
on the same data, the resulting CIs are often invalid."
CONFIDENCE INTERVALS FOR POST-SELECTION INFERENCE,0.18469217970049917,"Post-selection inference solves this problem by conditioning the inference on the knowledge of E
and sE. To construct valid CIs, it sufﬁces to approximate the selective distribution with support
{ˆβE, u−E : sE ⊙ˆβE > 0, u−E ∈[−1, 1]p−|E|} and density"
CONFIDENCE INTERVALS FOR POST-SELECTION INFERENCE,0.18635607321131448,"ˆg(ˆβE, u−E) ∝g
 
X⊤y −
  X⊤
E XE+ϵI|E|
X⊤
−EXE
ˆβE + λ
  sE
u−E

."
CONFIDENCE INTERVALS FOR POST-SELECTION INFERENCE,0.18801996672212978,"In our experiments, we integrate out u−E analytically, following Tian et al. (2016), and reparameterize
ˆβE as sE ⊙|ˆβE| to obtain a log-concave density of |ˆβE| supported on the nonnegative orthant with
mirror function ψ(θ) = Pd
j=1(θj log θj −θj). In Fig. 4a we show the example of a 2D selective
distribution using samples drawn by NUTS (Hoffman & Gelman, 2014). We also plot the results by
projected SVGD, SVMD, and MSVGD in this example. Projected SVGD fails to approximate the
target with many samples gathering at the truncation boundary, while the samples by MSVGD and
SVMD closely resemble the truth."
CONFIDENCE INTERVALS FOR POST-SELECTION INFERENCE,0.1896838602329451,"We then compare our methods with the standard norejection MCMC approach of the
selectiveInference R package (Tibshirani et al., 2019) using the example simulation setting
described in Sepehri & Markovic (2017) and a penalty factor 0.7. To generate N total sample
points we run MCMC for N iterations after burn-in or aggregate the particles from N/n independent
runs of MSVGD or SVMD with n = 50 particles. As N ranges from 1000 to 3000 in Fig. 3a,
the MSVGD and SVMD CIs consistently yield higher coverage than the standard 90% CIs. This
increased coverage is of particular value for smaller sample sizes, for which the standard CIs tend
to undercover. For a much larger sample size of N = 5000 in Fig. 3b, the SVMD and standard CIs
closely track one another across conﬁdence levels, while MSVGD consistently yields longer CIs with
high coverage. The higher coverage of MSVGD is only of value for larger conﬁdence levels at which
the other methods begin to undercover."
CONFIDENCE INTERVALS FOR POST-SELECTION INFERENCE,0.1913477537437604,"We next apply our samplers to a post-selection inference task on the HIV-1 drug resistance
dataset (Rhee et al., 2006), where we run randomized Lasso (Tian et al., 2016) to ﬁnd statisti-
cally signiﬁcant mutations associated with drug resistance using susceptibility data on virus isolates."
CONFIDENCE INTERVALS FOR POST-SELECTION INFERENCE,0.1930116472545757,Published as a conference paper at ICLR 2022
CONFIDENCE INTERVALS FOR POST-SELECTION INFERENCE,0.194675540765391,"We take the vitro measurement of log-fold change under the 3TC drug as response and include
mutations that had appeared at least 11 times in the dataset as regressors. In Fig. 4b we plot the
CIs of selected mutations obtained with N = 5000 sample points. We see that the invalid unad-
justed least squares CIs can lead to premature conclusions, e.g., declaring mutation 215Y signiﬁcant
when there is insufﬁcient support after conditioning on the selection event. In contrast, mutation
184V, which has known association with drug resistance, is declared signiﬁcant by all methods even
after post-selection adjustment. The MSVGD and SVMD CIs mostly track those of the standard
selectiveInference method, but their conclusions sometimes differ: e.g., 62Y is ﬂagged as
signiﬁcant by MSVGD and SVMD but not by selectiveInference."
CONFIDENCE INTERVALS FOR POST-SELECTION INFERENCE,0.19633943427620631,"Truth
Projected SVGD"
CONFIDENCE INTERVALS FOR POST-SELECTION INFERENCE,0.19800332778702162,"SVMD
MSVGD (a) 2.0 2.2"
"UNADJUSTED
STANDARD
SVMD
MSVGD",0.19966722129783693,"2.4
Unadjusted
Standard
SVMD
MSVGD P41L P62V P65R P67N P69i P70R P83K P151M P181C P184V P210W P215Y −0.2 0.0 0.2 0.4 (b)"
"UNADJUSTED
STANDARD
SVMD
MSVGD",0.20133111480865223,"Figure 4: (a) Sampling from a 2D selective density; (b) Unadjusted and post-selection CIs for the
mutations selected by the randomized Lasso as candidates for HIV-1 drug resistance (see Sec. 5.2)."
LARGE-SCALE POSTERIOR INFERENCE WITH NON-EUCLIDEAN GEOMETRY,0.20299500831946754,"5.3
LARGE-SCALE POSTERIOR INFERENCE WITH NON-EUCLIDEAN GEOMETRY"
LARGE-SCALE POSTERIOR INFERENCE WITH NON-EUCLIDEAN GEOMETRY,0.20465890183028287,"Finally, we demonstrate the advantages of exploiting non-Euclidean geometry by recreating the
real-data large-scale Bayesian logistic regression experiment of Liu & Wang (2016) with 581,012
datapoints and d = 54 feature dimensions. Here, the target p is the posterior distribution over logistic
regression parameters. We adopt the Fisher information metric tensor G, compare 20-particle SVNG
to SVGD and its prior geometry-aware variants RSVGD (Liu & Zhu, 2018) and MatSVGD with
average and mixture kernels (Wang et al., 2019), and for all methods use stochastic minibatches of
size 256 to scalably approximate each log likelihood query. In Fig. 5, all geometry-aware methods
substantially improve the log predictive probability of SVGD. SVNG also strongly outperforms
RSVGD and converges to its maximum test probability in half as many steps as MatSVGD (Avg) and
more rapidly than MatSVGD (Mixture)."
CONVERGENCE GUARANTEES,0.20632279534109818,"6
CONVERGENCE GUARANTEES"
CONVERGENCE GUARANTEES,0.2079866888519135,"We next turn our attention to the convergence properties of our proposed methods. For Kt and ϵt
as in Alg. 1, let (q∞
t , q∞
t,H) represent the distributions of the mirrored Stein updates (θt, ηt) when
θ0 ∼q∞
0 and ηt+1 = ηt + ϵtg∗
qt,Kt(θt) for t ≥0. Our ﬁrst result, proved in App. I.5, shows that if
the Alg. 1 initialization qn
0,H = 1"
CONVERGENCE GUARANTEES,0.2096505823627288,"n
Pn
i=1 δηi
0 converges in Wasserstein distance to a distribution q∞
0,H
as n →∞, then, on each round t > 0, the output of Alg. 1, qn
t = 1"
CONVERGENCE GUARANTEES,0.2113144758735441,"n
Pn
i=1 δθi
t, converges to q∞
t ."
CONVERGENCE GUARANTEES,0.2129783693843594,"Theorem 6 (Convergence of mirrored updates as n →∞). Suppose Alg. 1 is initialized with
qn
0,H = 1"
CONVERGENCE GUARANTEES,0.2146422628951747,"n
Pn
i=1 δηi
0 satisfying W1(qn
0,H, q∞
0,H) →0 for W1 the L1 Wasserstein distance. Deﬁne the
η-induced kernel K∇ψ∗,t(η, η′) ≜Kt(∇ψ∗(η), ∇ψ∗(η′)). If, for some c1, c2 > 0,"
CONVERGENCE GUARANTEES,0.21630615640599002,"∥∇(K∇ψ∗,t(·, η)∇log pH(η) + ∇· K∇ψ∗,t(·, η))∥op ≤c1(1 + ∥η∥2),
∥∇(K∇ψ∗,t(η′, ·)∇log pH(·) + ∇· K∇ψ∗,t(η′, ·))∥op ≤c2(1 + ∥η′∥2),"
CONVERGENCE GUARANTEES,0.21797004991680533,"then, W1(qn
t,H, q∞
t,H) →0 and qn
t ⇒q∞
t
for each round t."
CONVERGENCE GUARANTEES,0.21963394342762063,Published as a conference paper at ICLR 2022
CONVERGENCE GUARANTEES,0.22129783693843594,"0
500
1000
1500
2000
2500
3000
Number of particle updates, T −0.58 −0.57 −0.56 −0.55 −0.54 −0.53 −0.52 −0.51"
CONVERGENCE GUARANTEES,0.22296173044925124,Test log predictive probability
CONVERGENCE GUARANTEES,0.22462562396006655,"SVGD
SVNG
RSVGD"
CONVERGENCE GUARANTEES,0.22628951747088186,"0
100
200
300
400
Number of particle updates, T"
CONVERGENCE GUARANTEES,0.22795341098169716,−0.550
CONVERGENCE GUARANTEES,0.22961730449251247,−0.545
CONVERGENCE GUARANTEES,0.23128119800332778,−0.540
CONVERGENCE GUARANTEES,0.23294509151414308,−0.535
CONVERGENCE GUARANTEES,0.23460898502495842,−0.530
CONVERGENCE GUARANTEES,0.23627287853577372,−0.525
CONVERGENCE GUARANTEES,0.23793677204658903,−0.520
CONVERGENCE GUARANTEES,0.23960066555740434,−0.515
CONVERGENCE GUARANTEES,0.24126455906821964,Test log predictive probability
CONVERGENCE GUARANTEES,0.24292845257903495,"SVNG
Matrix SVGD (Avg)"
CONVERGENCE GUARANTEES,0.24459234608985025,Matrix SVGD (Mixture)
CONVERGENCE GUARANTEES,0.24625623960066556,"0
50
100
150
200
250
300
350
400
Number of particle updates, T 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5"
CONVERGENCE GUARANTEES,0.24792013311148087,Time (s)
CONVERGENCE GUARANTEES,0.24958402662229617,"SVNG
Matrix SVGD (Avg)"
CONVERGENCE GUARANTEES,0.2512479201331115,Matrix SVGD (Mixture)
CONVERGENCE GUARANTEES,0.2529118136439268,Figure 5: Value of non-Euclidean geometry in large-scale Bayesian logistic regression.
CONVERGENCE GUARANTEES,0.2545757071547421,"Remark
The pre-conditions hold, for example, whenever ∇log pH is Lipschitz, ψ is strongly
convex, and Kt = kI for k bounded with bounded derivatives."
CONVERGENCE GUARANTEES,0.2562396006655574,"Given a mirrored Stein operator (6), an arbitrary Stein set G, and an arbitrary matrix-valued kernel K
we deﬁne the mirrored Stein discrepancy and mirrored kernel Stein discrepancy"
CONVERGENCE GUARANTEES,0.2579034941763727,"MSD(q, p, G) ≜supg∈G Eq[(Mp,ψg)(θ)]
and
MKSDK(q, p) ≜MSD(q, p, BHK).
(15)
The former is an example of a diffusion Stein discrepancy (Gorham et al., 2019) and the latter an
example of a diffusion kernel Stein discrepancy (Barp et al., 2019). Since the MKSD optimiza-
tion problem (15) matches that in Thm. 3, we have that MKSDK(q, p) = ∥g∗
q,K∥HK. Our next
result, proved in App. I.6, shows that the inﬁnite-particle mirrored Stein updates reduce the KL
divergence to p whenever the step size is sufﬁciently small and drive MKSD to 0 if, for example,
ϵt = Ω(MKSDKt(q∞
t , p)α) for any α > 0. We also provide two conditions in App. H that generalize
the Stein Log-Sobolev and Stein Poincar´e inequalities in Duncan et al. (2019); Korba et al. (2020)
and which imply exponential convergence rates of our algorithms in continuous time.
Theorem 7 (Inﬁnite-particle mirrored Stein updates decrease KL and MKSD). Assume κ1 ≜
supθ∥Kt(θ, θ)∥op < ∞, κ2 ≜Pd
i=1 supθ ∥∇2
i,d+iKt(θ, θ)∥op < ∞, ∇log pH is L-Lipschitz, and
ψ is α-strongly convex. If ϵt < 1/(2 supθ ∥∇2ψ(θ)−1∇g∗
q∞
t ,Kt(θ) + ∇g∗
q∞
t ,Kt(θ)⊤∇2ψ(θ)−1∥op),"
CONVERGENCE GUARANTEES,0.259567387687188,"KL(q∞
t+1∥p) −KL(q∞
t ∥p) ≤−
 
ϵt −
  Lκ1"
CONVERGENCE GUARANTEES,0.2612312811980033,"2
+ 2κ2"
CONVERGENCE GUARANTEES,0.2628951747088186,"α2

ϵ2
t

MKSDKt(q∞
t , p)2."
CONVERGENCE GUARANTEES,0.26455906821963393,"Our last result, proved in App. I.7, shows that q∞
t
⇒p if MKSDKk(q∞
t , p) →0. Hence, by Thms. 6
and 7, n-particle MSVGD converges weakly to p if ϵt decays at a suitable rate.
Theorem 8 (MKSDKk determines weak convergence). Assume pH is distantly dissipative (Eberle,
2016) with ∇log pH Lipschitz, ψ is strongly convex with continuous ∇ψ∗, and k(θ, θ′) =
κ(∇ψ(θ), ∇ψ(θ′)) for κ(x, y) = (c2 + ∥x −y∥2
2)β with β ∈(−1, 0).
Then, q∞
t
⇒p if
MKSDKk(q∞
t , p) →0."
CONVERGENCE GUARANTEES,0.26622296173044924,"Remark
The pre-conditions hold, for example, for any Dirichlet target with negative entropy ψ."
DISCUSSION,0.26788685524126454,"7
DISCUSSION"
DISCUSSION,0.26955074875207985,"This paper introduced the mirrored Stein operator along with three new particle evolution algorithms
for sampling with constrained domains and non-Euclidean geometries. The ﬁrst algorithm MSVGD
performs SVGD updates in a mirrored space before mapping to the target domain. The other two
algorithms are different discretizations of the same continuous dynamics for exploiting non-Euclidean
geometry. SVMD is a multi-particle generalization of mirror descent for constrained domains, while
SVNG is designed for unconstrained problems with informative metric tensors."
DISCUSSION,0.27121464226289516,"We highlight three limitations. First, like SVGD, our MSVGD require O(n2) time per update.
Second, SVMD and SVNG are more costly than MSVGD due to the adaptive kernel construction.
Low-rank kernel approximation may be needed to reduce their complexity. Third, we leave open
the question of convergence when stochastic gradient estimates are employed, but we suspect
the results of Gorham et al. (2020, Thm. 7) can be extended to our setting. In the future, we
hope to deploy our mirrored Stein operators for other inferential tasks on constrained domains
including sample quality measurement (Gorham & Mackey, 2015; Huggins & Mackey, 2018),
goodness-of-ﬁt testing (Chwialkowski et al., 2016; Liu et al., 2016; Jitkrittum et al., 2017), graphical
model inference (Zhuo et al., 2018; Wang et al., 2018), parameter estimation (Barp et al., 2019),
thinning (Riabiz et al., 2020), and de novo sampling (Chen et al., 2018; Futami et al., 2019)."
DISCUSSION,0.27287853577371046,Published as a conference paper at ICLR 2022
REPRODUCIBILITY STATEMENT,0.27454242928452577,REPRODUCIBILITY STATEMENT
REPRODUCIBILITY STATEMENT,0.2762063227953411,See App. G for experimental details and
REPRODUCIBILITY STATEMENT,0.2778702163061564,https://github.com/thjashin/mirror-stein-samplers
REPRODUCIBILITY STATEMENT,0.2795341098169717,for Python and R code replicating all experiments.
REFERENCES,0.281198003327787,REFERENCES
REFERENCES,0.28286189683860236,"Kwangjun Ahn and Sinho Chewi. Efﬁcient constrained sampling via the mirror-Langevin algorithm.
arXiv preprint arXiv:2010.16212, 2020."
REFERENCES,0.28452579034941766,"Shun-Ichi Amari. Natural gradient works efﬁciently in learning. Neural Computation, 10(2):251–276,
1998."
REFERENCES,0.28618968386023297,"Andrew D Barbour. Stein’s method and Poisson process convergence. Journal of Applied Probability,
pp. 175–184, 1988."
REFERENCES,0.2878535773710483,"Alessandro Barp, Francois-Xavier Briol, Andrew Duncan, Mark Girolami, and Lester Mackey.
Minimum Stein discrepancy estimators. In Advances in Neural Information Processing Systems,
pp. 12964–12976, 2019."
REFERENCES,0.2895174708818636,"Amir Beck and Marc Teboulle. Mirror descent and nonlinear projected subgradient methods for
convex optimization. Operations Research Letters, 31(3):167–175, 2003."
REFERENCES,0.2911813643926789,"Alain Berlinet and Christine Thomas-Agnan. Reproducing kernel Hilbert spaces in probability and
statistics. Springer Science & Business Media, 2011."
REFERENCES,0.2928452579034942,"Rabi N Bhattacharya and Edward C Waymire. Stochastic processes with applications. SIAM, 2009."
REFERENCES,0.2945091514143095,"David M Blei, Andrew Y Ng, and Michael I Jordan. Latent Dirichlet allocation. Journal of Machine
Learning Research, 3:993–1022, 2003."
REFERENCES,0.2961730449251248,"Peng Chen, Keyi Wu, Joshua Chen, Tom O'Leary-Roseberry, and Omar Ghattas. Projected Stein
variational Newton: A fast and scalable Bayesian inference method in high dimensions. In
Advances in Neural Information Processing Systems, volume 32, 2019."
REFERENCES,0.2978369384359401,"Wilson Ye Chen, Lester Mackey, Jackson Gorham, Franc¸ois-Xavier Briol, and Chris Oates. Stein
points. In International Conference on Machine Learning, pp. 844–853, 2018."
REFERENCES,0.2995008319467554,"Sinho Chewi, Thibaut Le Gouic, Chen Lu, Tyler Maunu, Philippe Rigollet, and Austin Stromme.
Exponential ergodicity of mirror-Langevin diffusions. arXiv preprint arXiv:2005.09669, 2020."
REFERENCES,0.3011647254575707,"Kacper Chwialkowski, Heiko Strathmann, and Arthur Gretton. A kernel test of goodness of ﬁt. In
International Conference on Machine Learning, pp. 2606–2615, 2016."
REFERENCES,0.30282861896838603,"Arnak Dalalyan. Further and stronger analogy between sampling and optimization: Langevin Monte
Carlo and gradient descent. In Conference on Learning Theory, pp. 678–689, 2017."
REFERENCES,0.30449251247920134,"Gianluca Detommaso, Tiangang Cui, Youssef Marzouk, Alessio Spantini, and Robert Scheichl.
A Stein variational Newton method. In Advances in Neural Information Processing Systems,
volume 31, pp. 9187–9197, 2018."
REFERENCES,0.30615640599001664,"John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and
stochastic optimization. Journal of Machine Learning Research, 12(7), 2011."
REFERENCES,0.30782029950083195,"Andrew Duncan, Nikolas N¨usken, and Lukasz Szpruch. On the geometry of Stein variational gradient
descent. arXiv preprint arXiv:1912.00894, 2019."
REFERENCES,0.30948419301164726,"Alain Durmus, Eric Moulines, and Marcelo Pereyra. Efﬁcient Bayesian computation by proximal
Markov chain Monte Carlo: when Langevin meets Moreau. SIAM Journal on Imaging Sciences,
11(1):473–506, 2018."
REFERENCES,0.31114808652246256,Published as a conference paper at ICLR 2022
REFERENCES,0.31281198003327787,"Andreas Eberle. Reﬂection couplings and contraction rates for diffusions. Probability Theory and
Related Fields, 166(3):851–886, 2016."
REFERENCES,0.3144758735440932,"Stewart N Ethier.
A class of degenerate diffusion processes occurring in population genetics.
Communications on Pure and Applied Mathematics, 29(5):483–493, 1976."
REFERENCES,0.3161397670549085,"Yihao Feng, Dilin Wang, and Qiang Liu. Learning to draw samples with amortized Stein variational
gradient descent. Uncertainty in Artiﬁcial Intelligence, 2017."
REFERENCES,0.3178036605657238,"JC Ferreira and VA Menegatto. Eigenvalues of integral operators deﬁned by smooth positive deﬁnite
kernels. Integral Equations and Operator Theory, 64(1):61–81, 2009."
REFERENCES,0.3194675540765391,"Futoshi Futami, Zhenghang Cui, Issei Sato, and Masashi Sugiyama. Bayesian posterior approximation
via greedy particle optimization. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence,
pp. 3606–3613, 2019."
REFERENCES,0.3211314475873544,"Han L Gan, Adrian R¨ollin, and Nathan Ross. Dirichlet approximation of equilibrium distributions in
Cannings models with mutation. Advances in Applied Probability, 49(3):927–959, 2017."
REFERENCES,0.3227953410981697,"Damien Garreau, Wittawat Jitkrittum, and Motonobu Kanagawa. Large sample analysis of the median
heuristic. arXiv preprint arXiv:1707.07269, 2017."
REFERENCES,0.324459234608985,"Jackson Gorham and Lester Mackey. Measuring sample quality with Stein’s method. In Advances in
Neural Information Processing Systems, pp. 226–234, 2015."
REFERENCES,0.3261231281198003,"Jackson Gorham and Lester Mackey. Measuring sample quality with kernels. In International
Conference on Machine Learning, pp. 1292–1301, 2017."
REFERENCES,0.3277870216306156,"Jackson Gorham, Andrew B Duncan, Sebastian J Vollmer, and Lester Mackey. Measuring sample
quality with diffusions. The Annals of Applied Probability, 29(5):2884–2928, 2019."
REFERENCES,0.32945091514143093,"Jackson Gorham, Anant Raj, and Lester Mackey. Stochastic stein discrepancies. arXiv preprint
arXiv:2007.02857, 2020."
REFERENCES,0.33111480865224624,"Tuomas Haarnoja, Haoran Tang, Pieter Abbeel, and Sergey Levine. Reinforcement learning with
deep energy-based policies. In International Conference on Machine Learning, pp. 1352–1361,
2017."
REFERENCES,0.33277870216306155,"Geoffrey Hinton, Nitish Srivastava, and Kevin Swersky. Neural networks for machine learning lecture
6a: overview of mini-batch gradient descent. 2012."
REFERENCES,0.33444259567387685,"Matthew D Hoffman and Andrew Gelman. The No-U-Turn sampler: adaptively setting path lengths
in Hamiltonian Monte Carlo. Journal of Machine Learning Research, 15(1):1593–1623, 2014."
REFERENCES,0.33610648918469216,"Matthew D Hoffman, David M Blei, Chong Wang, and John Paisley. Stochastic variational inference.
Journal of Machine Learning Research, 14(5), 2013."
REFERENCES,0.33777038269550747,"Ya-Ping Hsieh, Ali Kavis, Paul Rolland, and Volkan Cevher. Mirrored Langevin dynamics. In
Advances in Neural Information Processing Systems, pp. 2878–2887, 2018."
REFERENCES,0.33943427620632277,"Jonathan Huggins and Lester Mackey. Random feature Stein discrepancies. In S. Bengio, H. Wal-
lach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural
Information Processing Systems, pp. 1903–1913. 2018."
REFERENCES,0.3410981697171381,"Wittawat Jitkrittum, Wenkai Xu, Zolt´an Szab´o, K. Fukumizu, and A. Gretton. A Linear-Time Kernel
Goodness-of-Fit Test. In Advances in Neural Information Processing Systems, 2017."
REFERENCES,0.3427620632279534,"Sham Kakade, Shai Shalev-Shwartz, Ambuj Tewari, et al. On the duality of strong convexity and
strong smoothness: Learning applications and matrix regularization. Unpublished Manuscript, 2
(1), 2009."
REFERENCES,0.34442595673876875,"Mohammad Emtiyaz Khan and Didrik Nielsen. Fast yet simple natural-gradient descent for variational
inference in complex models. In 2018 International Symposium on Information Theory and Its
Applications (ISITA), pp. 31–35. IEEE, 2018."
REFERENCES,0.34608985024958405,Published as a conference paper at ICLR 2022
REFERENCES,0.34775374376039936,"Taesup Kim, Jaesik Yoon, Ousmane Dia, Sungwoong Kim, Yoshua Bengio, and Sungjin Ahn.
Bayesian model-agnostic meta-learning. Advances in Neural Information Processing Systems,
2018."
REFERENCES,0.34941763727121466,"Anna Korba, Adil Salim, Michael Arbel, Giulia Luise, and Arthur Gretton. A non-asymptotic analysis
for Stein variational gradient descent. Advances in Neural Information Processing Systems, 33,
2020."
REFERENCES,0.35108153078202997,"Jason D Lee, Dennis L Sun, Yuekai Sun, and Jonathan E Taylor. Exact post-selection inference, with
application to the lasso. Annals of Statistics, 44(3):907–927, 2016."
REFERENCES,0.3527454242928453,"Chang Liu and Jun Zhu. Riemannian Stein variational gradient descent for Bayesian inference. In
Proceedings of the AAAI Conference on Artiﬁcial Intelligence, pp. 3627–3634, 2018."
REFERENCES,0.3544093178036606,"Chang Liu, Jingwei Zhuo, Pengyu Cheng, Ruiyi Zhang, and Jun Zhu. Understanding and accelerating
particle-based variational inference. In International Conference on Machine Learning, pp. 4082–
4092, 2019a."
REFERENCES,0.3560732113144759,"Chang Liu, Jingwei Zhuo, and Jun Zhu. Understanding MCMC dynamics as ﬂows on the Wasserstein
space. In Proceedings of the 36th International Conference on Machine Learning, pp. 4093–4103,
2019b."
REFERENCES,0.3577371048252912,"Qiang Liu. Stein variational gradient descent as gradient ﬂow. In Advances in Neural Information
Processing Systems, pp. 3115–3123, 2017."
REFERENCES,0.3594009983361065,"Qiang Liu and Dilin Wang. Stein variational gradient descent: A general purpose Bayesian inference
algorithm. Advances in Neural Information Processing Systems, 29:2378–2386, 2016."
REFERENCES,0.3610648918469218,"Qiang Liu, Jason Lee, and Michael Jordan. A kernelized Stein discrepancy for goodness-of-ﬁt tests.
In International Conference on Machine Learning, pp. 276–284, 2016."
REFERENCES,0.3627287853577371,"Yi-An Ma, Tianqi Chen, and Emily Fox. A complete recipe for stochastic gradient MCMC. In
Advances in Neural Information Processing Systems, pp. 2917–2925, 2015."
REFERENCES,0.3643926788685524,"Yi-An Ma, Niladri Chatterji, Xiang Cheng, Nicolas Flammarion, Peter Bartlett, and Michael I Jordan.
Is there an analog of Nesterov acceleration for MCMC? arXiv preprint arXiv:1902.00996, 2019."
REFERENCES,0.36605657237936773,"James Martens. New insights and perspectives on the natural gradient method. arXiv preprint
arXiv:1412.1193, 2014."
REFERENCES,0.36772046589018303,"Charles A Micchelli and Massimiliano Pontil. On learning vector-valued functions. Neural Computa-
tion, 17(1):177–204, 2005."
REFERENCES,0.36938435940099834,"Arkadij Semenovic Nemirovskij and David Borisovich Yudin. Problem complexity and method
efﬁciency in optimization. 1983."
REFERENCES,0.37104825291181365,"Chris J Oates, Mark Girolami, and Nicolas Chopin. Control functionals for Monte Carlo integration.
Journal of the Royal Statistical Society: Series B (Methodological), 79(3):695–718, 2017."
REFERENCES,0.37271214642262895,"Bernt Øksendal. Stochastic Differential Equations: An Introduction with Applications. Springer
Science & Business Media, 2003."
REFERENCES,0.37437603993344426,"Sam Patterson and Yee Whye Teh. Stochastic gradient Riemannian Langevin dynamics on the
probability simplex. In Advances in Neural Information Processing Systems, pp. 3102–3110, 2013."
REFERENCES,0.37603993344425957,"Garvesh Raskutti and Sayan Mukherjee. The information geometry of mirror descent. IEEE
Transactions on Information Theory, 61(3):1451–1457, 2015."
REFERENCES,0.3777038269550749,"Soo-Yon Rhee, Jonathan Taylor, Gauhar Wadhera, Asa Ben-Hur, Douglas L Brutlag, and Robert W
Shafer. Genotypic predictors of human immunodeﬁciency virus type 1 drug resistance. Proceedings
of the National Academy of Sciences, 103(46):17355–17360, 2006."
REFERENCES,0.3793677204658902,"Marina Riabiz, Wilson Chen, Jon Cockayne, Pawel Swietach, Steven A Niederer, Lester Mackey,
Chris Oates, et al. Optimal thinning of MCMC output. arXiv preprint arXiv:2005.03952, 2020."
REFERENCES,0.3810316139767055,Published as a conference paper at ICLR 2022
REFERENCES,0.3826955074875208,"Amir Sepehri and Jelena Markovic. Non-reversible, tuning-and rejection-free Markov chain Monte
Carlo via iterated random functions. arXiv preprint arXiv:1711.07177, 2017."
REFERENCES,0.3843594009983361,"Jiaxin Shi, Shengyang Sun, and Jun Zhu. A spectral approach to gradient estimation for implicit
distributions. In International Conference on Machine Learning, pp. 4644–4653, 2018."
REFERENCES,0.3860232945091514,"Umut Simsekli, Roland Badeau, Taylan Cemgil, and Ga¨el Richard. Stochastic quasi-Newton Langevin
Monte Carlo. In International Conference on Machine Learning, pp. 642–651, 2016."
REFERENCES,0.3876871880199667,"Charles Stein. A bound for the error in the normal approximation to the distribution of a sum of
dependent random variables. In Proceedings of the Sixth Berkeley Symposium on Mathemati-
cal Statistics and Probability, Volume 2: Probability Theory. The Regents of the University of
California, 1972."
REFERENCES,0.389351081530782,"G´abor J Sz´ekely and Maria L Rizzo. Energy statistics: A class of statistics based on distances.
Journal of Statistical Planning and Inference, 143(8):1249–1272, 2013."
REFERENCES,0.3910149750415973,"Jonathan Taylor and Robert J Tibshirani. Statistical learning and selective inference. Proceedings of
the National Academy of Sciences, 112(25):7629–7634, 2015."
REFERENCES,0.39267886855241263,"Xiaoying Tian, Nan Bi, and Jonathan Taylor. MAGIC: a general, powerful and tractable method for
selective inference. arXiv preprint arXiv:1607.02630, 2016."
REFERENCES,0.39434276206322794,"Ryan Tibshirani, Rob Tibshirani, Jonatha Taylor, Joshua Loftus, Stephen Reid, and Jelena
Markovic. selectiveInference: Tools for Post-Selection Inference, 2019. URL https://CRAN.
R-project.org/package=selectiveInference. R package version 1.2.5."
REFERENCES,0.39600665557404324,"Dilin Wang, Zhe Zeng, and Qiang Liu. Stein variational message passing for continuous graphical
models. In International Conference on Machine Learning, pp. 5219–5227, 2018."
REFERENCES,0.39767054908485855,"Dilin Wang, Ziyang Tang, Chandrajit Bajaj, and Qiang Liu. Stein variational gradient descent with
matrix-valued kernels. In Advances in Neural Information Processing Systems, pp. 7836–7846,
2019."
REFERENCES,0.39933444259567386,"Max Welling and Yee W Teh. Bayesian learning via stochastic gradient Langevin dynamics. In
International Conference on Machine Learning, pp. 681–688, 2011."
REFERENCES,0.40099833610648916,"Edwin B Wilson. Probable inference, the law of succession, and statistical inference. Journal of the
American Statistical Association, 22(158):209–212, 1927."
REFERENCES,0.40266222961730447,"Tatiana Xifara, Chris Sherlock, Samuel Livingstone, Simon Byrne, and Mark Girolami. Langevin
diffusions and the Metropolis-adjusted Langevin algorithm. Statistics & Probability Letters, 91:
14–19, 2014."
REFERENCES,0.4043261231281198,"Jianyi Zhang, Yang Zhao, and Changyou Chen. Variance reduction in stochastic particle-optimization
sampling. In Proceedings of the 37th International Conference on Machine Learning, pp. 11307–
11316, 2020a."
REFERENCES,0.4059900166389351,"Kelvin Shuangjian Zhang, Gabriel Peyr´e, Jalal Fadili, and Marcelo Pereyra. Wasserstein control of
mirror Langevin Monte Carlo. arXiv preprint arXiv:2002.04363, 2020b."
REFERENCES,0.40765391014975044,"Michael Zhu, Chang Liu, and Jun Zhu. Variance reduction and quasi-Newton for particle-based
variational inference. In Proceedings of the 37th International Conference on Machine Learning,
pp. 11576–11587, 2020."
REFERENCES,0.40931780366056575,"Jingwei Zhuo, Chang Liu, Jiaxin Shi, Jun Zhu, Ning Chen, and Bo Zhang. Message passing Stein
variational gradient descent. In International Conference on Machine Learning, pp. 6018–6027,
2018."
REFERENCES,0.41098169717138106,Published as a conference paper at ICLR 2022
REFERENCES,0.41264559068219636,Algorithm 2 Stein Variational Natural Gradient (SVNG)
REFERENCES,0.41430948419301167,"Input: density p(θ) on Rd, kernel k, metric tensor G(θ), particles (θi
0)n
i=1, step sizes (ϵt)T
t=1
for t = 0 : T do"
REFERENCES,0.415973377703827,"for i ∈[n], θi
t+1 ←θi
t + ϵtG(θi
t)−1g∗
G,t(θi
t), where
g∗
G,t(θ) = 1"
REFERENCES,0.4176372712146423,"n
Pn
j=1[KG,t(θ, θj
t)G(θj
t)−1∇log p(θj
t)+∇θj
t ·(KG,t(θ, θj
t)G(θj
t)−1)] (see (14))"
REFERENCES,0.4193011647254576,"return {θi
T +1}n
i=1."
REFERENCES,0.4209650582362729,"A
MIRROR DESCENT, RIEMANNIAN GRADIENT FLOW, AND NATURAL
GRADIENT"
REFERENCES,0.4226289517470882,"The equivalence between the mirror ﬂow dηt = −∇f(θt)dt, θt = ∇ψ∗(ηt)dt and the Riemannian
gradient ﬂow in (3) is a direct result of the chain rule:
dθt"
REFERENCES,0.4242928452579035,"dt = −∇ηtθt
dηt"
REFERENCES,0.4259567387687188,dt = −(∇θtηt)−1 dηt
REFERENCES,0.4276206322795341,"dt = −∇2ψ(θt)−1∇f(θt),
(16) dηt"
REFERENCES,0.4292845257903494,"dt = −∇f(θt) = −∇θtηt∇ηtf(∇ψ∗(ηt)) = −∇2ψ∗(ηt)−1∇ηtf(∇ψ∗(ηt)).
(17)"
REFERENCES,0.43094841930116473,"Depending on discretizing (16) or (17), there are two natural gradient descent (NGD) updates that
can arise from the same gradient ﬂow:
NGD (a):
θt+1 = θt −ϵt∇2ψ(θt)−1∇f(θt),"
REFERENCES,0.43261231281198004,"NGD (b):
ηt+1 = ηt −ϵt∇2ψ∗(ηt)−1∇ηtf(∇ψ∗(ηt)).
With ﬁnite step sizes ϵt, their updates need not be the same and can lead to different optimization
paths. Since ∇f(θt) = ∇2ψ∗(ηt)−1∇ηtf(∇ψ∗(ηt)), NGD (b) is equivalent to the dual-space update
by mirror descent. This relationship was pointed out in Raskutti & Mukherjee (2015) and has been
used for developing natural gradient variational inference algorithms (Khan & Nielsen, 2018). We
emphasize, however, our SVNG algorithm developed in Sec. 4.4 corresponds to the discretization
in the primal space as in NGD (a). Therefore, it does not require an explicit dual space, and allows
replacing ∇2ψ with more general information metric tensors."
REFERENCES,0.43427620632279534,"B
DETAILS OF EXAMPLE 1"
REFERENCES,0.43594009983361065,"For the entropic mirror map ψ(θ) = Pd+1
j=1 θj log θj, we have ∇2ψ(θ)−1 = diag(θ) −θθ⊤. Note"
REFERENCES,0.43760399334442596,"here θ denotes a d-dimensional vector and does not include θd+1 = 1 −Pd
j=1 θd. Since Θ is a
(d + 1)-simplex, ∂Θ is composed of d + 1 faces with θ in the j-th face satisﬁes θj = 0. The outward
unit normal vector n(θ) for the ﬁrst d faces are −ej for 1 ≤j ≤d, where ej denotes the j-th standard
basis of Rd. The outward unit normal vector for the (d + 1)-st face is a vector with 1/
√"
REFERENCES,0.43926788685524126,"d in all
coordinates. Therefore, we have
Z"
REFERENCES,0.44093178036605657,"∂Θ
p(θ)g(θ)⊤∇2ψ(θ)−1n(θ)dθ =
Z"
REFERENCES,0.4425956738768719,"∂Θ
p(θ)g(θ)⊤(diag(θ) −θθ⊤)n(θ)dθ =
Z"
REFERENCES,0.4442595673876872,"∂Θ
p(θ)(θ ⊙g(θ) −θθ⊤g(θ))⊤n(θ)dθ = d
X j=1 Z"
REFERENCES,0.4459234608985025,"θj=0
p(θ)(θ⊤g(θ) −gj(θ))θjdθ−j + 1
√ d Z"
REFERENCES,0.4475873544093178,"θd+1=0
p(θ)θ⊤g(θ)θd+1dθ =0,"
REFERENCES,0.4492512479201331,"where in the second to last identity we used θ⊤1 = 1 −θd+1. Finally, we can verify the condition in
Prop. 1 as"
REFERENCES,0.4509151414309484,"lim
r→∞ Z"
REFERENCES,0.4525790349417637,"∂Θr
p(θ)∥∇2ψ(θ)−1nr(θ)∥2dθ =
sup
∥g∥∞≤1 Z"
REFERENCES,0.454242928452579,"∂Θ
p(θ)g(θ)⊤∇2ψ(θ)−1n(θ)dθ = 0."
REFERENCES,0.4559068219633943,Published as a conference paper at ICLR 2022
REFERENCES,0.45757071547420963,"C
DERIVATION OF THE MIRRORED STEIN OPERATOR"
REFERENCES,0.45923460898502494,"We ﬁrst review the (overdamped) Langevin diffusion – a Markov process that underlies many recent
advances in Stein’s method – along with its recent mirrored generalization. The Langevin diffusion
with equilibrium density p on Rd is a Markov process (θt)t≥0 ⊂Rd satisfying the stochastic
differential equation (SDE)
dθt = ∇log p(θt)dt +
√"
DBT,0.46089850249584025,"2dBt
(18)
with (Bt)t≥0 a standard Brownian motion (Bhattacharya & Waymire, 2009, Sec. 4.5)."
DBT,0.46256239600665555,"To identify Stein operators that satisfy (4) for broad classes of targets p, Gorham & Mackey (2015)
proposed to build upon the generator method of Barbour (1988): First, identify a Markov process
(θt)t≥0 that has p as the equilibrium density; they chose the Langevin diffusion of (18). Next, build a
Stein operator based on the (inﬁnitesimal) generator A of the process (Øksendal, 2003, Def. 7.3.1):"
DBT,0.46422628951747086,(Af)(θ) = limt→0 1
DBT,0.46589018302828616,"t (Ef(θt) −Ef(θ0))
for f : Rd →R,"
DBT,0.46755407653910147,"as the generator satisﬁes Eθ∼p[(Af)(θ)] = 0 under relatively mild conditions. We use the following
theorem to derive the generator of the processes described by SDEs like (18):
Theorem 9 (Generator of Itˆo diffusion; Øksendal, 2003, Thm 7.3.3). Let (xt)t≥0 be the Itˆo diffusion
in X ⊆Rd satisfying dxt = b(xt)dt + σ(xt)dBt. For any f ∈C2c (X), the (inﬁnitesimal) generator
A of (xt)t≥0 is"
DBT,0.46921797004991683,(Af)(x) = b(x)⊤∇f(x) + 1
DBT,0.47088186356073214,2 Tr(σ(x)σ(x)⊤∇2f(x)).
DBT,0.47254575707154745,"For the Langevin diffusion (18), substituting ∇log p(·) for b(·) and
√"
DBT,0.47420965058236275,"2I for σ(·) in Thm. 9, we
obtain Af = (∇log p)⊤∇f + ∇· ∇f. Replacing ∇f with a vector-valued function g gives the
Langevin Stein operator in (5)."
DBT,0.47587354409317806,"To derive a Stein operator that works well for constrained domains, we consider the Riemannian
Langevin diffusion (Patterson & Teh, 2013; Xifara et al., 2014; Ma et al., 2015) that extends the
Langevin diffusion to non-Euclidean geometries encoded in a positive deﬁnite metric tensor G(θ):"
DBT,0.47753743760399336,"dθt = (G(θt)−1∇log p(θt) + ∇· G(θt)−1)dt +
√"
DBT,0.47920133111480867,2G(θt)−1/2dBt.4
DBT,0.480865224625624,"We show in App. D that the choice G = ∇2ψ yields the recent mirror-Langevin diffusion (Zhang
et al., 2020b; Chewi et al., 2020)"
DBT,0.4825291181364393,"θt = ∇ψ∗(ηt),
dηt = ∇log p(θt)dt +
√"
DBT,0.4841930116472546,"2∇2ψ(θt)1/2dBt.
(19)"
DBT,0.4858569051580699,"According to Thm. 9, the generator of the mirror-Langevin diffusion described by (20) is"
DBT,0.4875207986688852,"(Ap,ψf)(θ) = (∇2ψ(θ)−1∇log p(θ) + ∇· ∇2ψ(θ)−1)⊤∇f(θ) + Tr(∇2ψ(θ)−1∇2f(θ))"
DBT,0.4891846921797005,= ∇f(θ)⊤∇2ψ(θ)−1∇log p(θ) + ∇· (∇2ψ(θ)−1∇f(θ)).
DBT,0.4908485856905158,"Now substituting g(θ) for ∇f(θ), we obtain the associated mirrored Stein operator:"
DBT,0.4925124792013311,"(Mp,ψg)(θ) = g(θ)⊤∇2ψ(θ)−1∇log p(θ) + ∇· (∇2ψ(θ)−1g(θ))."
DBT,0.49417637271214643,"D
RIEMANNIAN LANGEVIN DIFFUSIONS AND MIRROR-LANGEVIN
DIFFUSIONS"
DBT,0.49584026622296173,"Zhang et al. (2020b) pointed out (19) is a particular case of the Riemannian LD. However, they did
not give an explicit derivation. The Riemannian LD (Patterson & Teh, 2013; Xifara et al., 2014; Ma
et al., 2015) with ∇2ψ(·) as the metric tensor is"
DBT,0.49750415973377704,"dθt = (∇2ψ(θt)−1∇log p(θt) + ∇· ∇2ψ(θt)−1)dt +
√"
DBT,0.49916805324459235,"2∇2ψ(θt)−1/2dBt.
(20)"
DBT,0.5008319467554077,"To see the connection with mirror-Langevin diffusion, we would like to obtain the SDE that describes
the evolution of ηt = ∇ψ(θt) under the diffusion. This requires the following theorem that provides
the analog of the “chain rule” in SDEs."
DBT,0.502495840266223,4A matrix divergence ∇· G(θ) is the vector obtained by computing the divergence of each row of G(θ).
DBT,0.5041597337770383,Published as a conference paper at ICLR 2022
DBT,0.5058236272878536,"Theorem 10 (Itˆo formula; Øksendal, 2003, Thm 4.2.1). Let (xt)t≥0 be an Itˆo process in X ⊂Rd"
DBT,0.5074875207986689,"satisfying dxt = b(xt)dt + σ(xt)dBt. Let f(x) ∈C2 : Rd →Rd′. Then yt = f(xt) is again an Itˆo
process, and its i-th dimension satisﬁes"
DBT,0.5091514143094842,"dyt,i = (∇fi(xt)⊤b(xt) + 1"
DBT,0.5108153078202995,2 Tr(∇2fi(xt)σ(xt)σ(xt)⊤)dt + ∇fi(xt)⊤σ(xt)dBt.
DBT,0.5124792013311148,"Substituting ∇ψ for f in Thm. 10, we have the SDE of ηt = ∇ψ(θt) as"
DBT,0.5141430948419301,"dηt = (∇log p(θt) + ∇2ψ(θt)∇· ∇2ψ(θt)−1 + h(θt))dt +
√"
DBT,0.5158069883527454,"2∇2ψ(θt)1/2dBt,"
DBT,0.5174708818635607,"where h(θt)i = Tr(∇2
θt(∇θt,iψ(θt))∇2ψ(θt)−1). Moreover, we have"
DBT,0.519134775374376,"[∇2ψ(θt)∇· ∇2ψ(θt)−1]i + Tr(∇2
θt(∇θt,iψ(θt))∇2ψ(θt)−1) = d
X ℓ=1 d
X"
DBT,0.5207986688851913,"j=1
∇2ψ(θt)ij∇θt,ℓ[∇2ψ(θt)−1]jℓ+ d
X ℓ=1 d
X"
DBT,0.5224625623960066,"j=1
∇θt,ℓ∇2ψ(θt)ij[∇2ψ(θt)−1]jℓ = d
X"
DBT,0.5241264559068219,"ℓ=1
∇θt,ℓ  
d
X"
DBT,0.5257903494176372,"j=1
∇2ψ(θt)ij[∇2ψ(θt)−1]jℓ  = d
X"
DBT,0.5274542429284526,"ℓ=1
∇θt,ℓIiℓ= 0."
DBT,0.5291181364392679,"Therefore, the ηt diffusion is described by the SDE:"
DBT,0.5307820299500832,"dηt = ∇log p(θt)dt +
√"
DBT,0.5324459234608985,"2∇2ψ(θt)1/2dBt,
θt = ∇ψ∗(ηt)."
DBT,0.5341098169717138,"E
MODE MISMATCH UNDER TRANSFORMATIONS"
DBT,0.5357737104825291,"0.0
0.2
0.4
0.6
0.8
1.0
0.0 2.5 5.0 7.5 10.0 12.5 p( )"
DBT,0.5374376039933444,"10
5
0
5
10
0.00 0.04 0.08 0.12 0.16 pH( )"
DBT,0.5391014975041597,"0.0
0.2
0.4
0.6
0.8
1.0
0 2 4 6 8 p( )"
DBT,0.540765391014975,"10
5
0
5
10
0.0 0.1 0.2 0.3 pH( )"
DBT,0.5424292845257903,"Figure 6: The density functions of the same distribution in θ (left) and η (right) space under
the transformation η = ∇ψ(θ). Each θ follows a Beta distributions on [0, 1]. We choose the
negative entropy ψ(θ) = θ log θ + (1 −θ) log(1 −θ). Then, the transformation is the logit function
η = log(θ/(1−θ)) and its reverse is the sigmoid function θ = 1/(1+e−η). Top: θ ∼Beta(0.5, 0.5).
Dashed lines mark the mode of the transformed density pH(η) and the corresponding θ, which gives
the lowest value of p(θ); Bottom: θ ∼Beta(1.1, 10). Dashed lines mark the mode of the target
density p(θ) and the corresponding η, which clearly does not match the mode of pH(η)."
DBT,0.5440931780366056,Published as a conference paper at ICLR 2022
DBT,0.5457570715474209,"F
BACKGROUND ON REPRODUCING KERNEL HILBERT SPACES"
DBT,0.5474209650582362,"Let H be a Hilbert space of functions deﬁned on X and taking their values in R. We say k is a
reproducing kernel (or kernel) of H if ∀x ∈X, k(x, ·) ∈H and ∀f ∈H, ⟨f, k(x, ·)⟩H = f(x). H is
called a reproducing kernel Hilbert space (RKHS) if it has a kernel. Kernels are positive deﬁnite (p.d.)
functions, which means that matrices with the form (k(xi, xj))ij are positive semideﬁnite. For any
p.d. function k, there is a unique RKHS with k as the reproducing kernel, which can be constructed
by the completion of {Pn
i=1 aik(xi, ·), xi ∈X, ai ∈R, i ∈N}."
DBT,0.5490848585690515,"Now we assume X is a metric space, k is a bounded continuous kernel with the RKHS H, and ν is a
positive measure on X. L2(ν) denote the space of all square-integrable functions w.r.t. ν. Then the
kernel integral operator Tk : L2(ν) →L2(ν) deﬁned by"
DBT,0.5507487520798668,"Tkg =
Z"
DBT,0.5524126455906821,"X
g(x)k(x, ·)dν"
DBT,0.5540765391014975,"is compact and self-adjoint. Therefore, according to the spectral theorem, there exists an at most
countable set of positive eigenvalues {λj}j∈J ⊂R with λ1 ≥λ2 ≥. . . converging to zero and
orthonormal eigenfunctions {uj}j∈J such that"
DBT,0.5557404326123128,"Tkuj = λjuj,"
DBT,0.5574043261231281,"and k has the representation k(x, x′) = P"
DBT,0.5590682196339434,"j∈J λjuj(x)uj(x′) (Mercer’s theorem on non-compact
domains), where the convergence of the sum is absolute and uniform on compact subsets of X ×
X (Ferreira & Menegatto, 2009)."
DBT,0.5607321131447587,"G
SUPPLEMENTARY EXPERIMENTAL DETAILS AND ADDITIONAL RESULTS"
DBT,0.562396006655574,"In this section, we report supplementary details and additional results from the experiments of Sec. 5.
In Secs. 5.1 and 5.2, we use the inverse multiquadric input kernel k(θ, θ′) = (1 + ∥θ −θ′∥2
2/ℓ2)−1/2
due to its convergence control properties (Gorham & Mackey, 2017). In the unconstrained experiments
of Sec. 5.3, we use the Gaussian kernel k(θ, θ′) = exp(−∥θ −θ′∥2
2/ℓ2) for consistency with past
work. The bandwidth ℓis determined by the median heuristic (Garreau et al., 2017). We select τ
from {0.98, 0.99} for all SVMD experiments. For unconstrained targets, we report, for each method,
results from the best ﬁxed step size ϵ ∈{0.01, 0.05, 0.1, 0.5, 1} selected on a separate validation
set. For constrained targets, we select step sizes adaptively to accommodate rapid density growth
near the boundary; speciﬁcally, we use RMSProp (Hinton et al., 2012), an extension of the AdaGrad
algorithm (Duchi et al., 2011) used in Liu & Wang (2016), and report performance with the best
learning rate. Results were recorded on an Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz and an
NVIDIA Tesla P100 PCIe 16GB."
DBT,0.5640599001663894,"G.1
APPROXIMATION QUALITY ON THE SIMPLEX"
DBT,0.5657237936772047,"The sparse Dirichlet posterior of Patterson & Teh (2013) extended to 20 dimensions features a sparse,
symmetric Dir(α) prior with αk = 0.1 for k ∈{1, . . . , 20} and sparse count data n1 = 90, n2 =
n3 = 5, nj = 0 (j > 3), modeled via a multinomial likelihood. The quadratic target satisﬁes
log p(θ) = −1"
DBT,0.56738768718802,"2σ2 θ⊤Aθ + const, where we slightly modify the target density of Ahn & Chewi (2020)
to make it less ﬂat by introducing a scale parameter σ = 0.01. A ∈R19×19 is a positive deﬁnite
matrix generated by normalizing products of random matrices with i.i.d. elements drawn from
Unif[−1, 1]."
DBT,0.5690515806988353,"We initialize all methods with i.i.d samples from Dirichlet(5) to prevent any of the initial particles
being too close to the boundary. For each method and each learning rate we apply 500 particle updates.
For SVMD we set τ = 0.98. We search the base learning rates of RMSProp in {0.1, 0.01, 0.001} for
SVMD and MSVGD. Since projected SVGD applies updates in the θ space, the appropriate learning
rate range is smaller than those of SVMD and MSVGD. There we search the base learning rate of
RMSProp in {0.01, 0.001, 0.0001}. For all methods the results under each base learning rate are
plotted in Fig. 7."
DBT,0.5707154742096506,Published as a conference paper at ICLR 2022
DBT,0.5723793677204659,"0
200
400
Number of particle updates, T 0.0 0.5 1.0 1.5"
DBT,0.5740432612312812,Energy distance
DBT,0.5757071547420965,Projected SVGD
DBT,0.5773710482529119,"LR=0.01
LR=0.001
LR=0.0001"
DBT,0.5790349417637272,"0
200
400
Number of particle updates, T 0.0 0.5 1.0 1.5 SVMD"
DBT,0.5806988352745425,"LR=0.1
LR=0.01
LR=0.001"
DBT,0.5823627287853578,"0
200
400
Number of particle updates, T 0.0 0.5 1.0 1.5"
DBT,0.5840266222961731,"MSVGD, k"
DBT,0.5856905158069884,"LR=0.1
LR=0.01
LR=0.001"
DBT,0.5873544093178037,"0
200
400
Number of particle updates, T 0.0 0.5 1.0 1.5"
DBT,0.589018302828619,"MSVGD, k2"
DBT,0.5906821963394343,"LR=0.1
LR=0.01
LR=0.001"
DBT,0.5923460898502496,"Figure 7: Sampling from a Dirichlet target on a 20-simplex. We plot the energy distance to a ground
truth sample of size 1000."
DBT,0.5940099833610649,"0
200
400
Number of particle updates, T 0.0 0.1 0.2 0.3"
DBT,0.5956738768718802,Energy distance
DBT,0.5973377703826955,Projected SVGD
DBT,0.5990016638935108,"LR=0.01
LR=0.001
LR=0.0001"
DBT,0.6006655574043261,"0
200
400
Number of particle updates, T 0.0 0.1 0.2 0.3 SVMD"
DBT,0.6023294509151415,"LR=0.1
LR=0.01
LR=0.001"
DBT,0.6039933444259568,"0
200
400
Number of particle updates, T 0.0 0.1 0.2 0.3"
DBT,0.6056572379367721,"MSVGD, k"
DBT,0.6073211314475874,"LR=0.1
LR=0.01
LR=0.001"
DBT,0.6089850249584027,"0
200
400
Number of particle updates, T 0.0 0.1 0.2 0.3"
DBT,0.610648918469218,"MSVGD, k2"
DBT,0.6123128119800333,"LR=0.1
LR=0.01
LR=0.001"
DBT,0.6139767054908486,"Figure 8: Sampling from a quadratic target on a 20-simplex. We plot the energy distance to a ground
truth sample of size 1000 drawn by NUTS (Hoffman & Gelman, 2014)."
DBT,0.6156405990016639,"G.2
CONFIDENCE INTERVALS FOR POST-SELECTION INFERENCE"
DBT,0.6173044925124792,"Given a dataset X ∈R˜n×p, y ∈R˜n, the randomized Lasso (Tian et al., 2016) solves the following
problem:"
DBT,0.6189683860232945,argminβ∈Rp 1
DBT,0.6206322795341098,"2∥y −Xβ∥2
2 + λ∥β∥1 −w⊤β + ϵ"
DBT,0.6222961730449251,"2∥β∥2
2,
w ∼G."
DBT,0.6239600665557404,"where G is a user-speciﬁed log-concave distribution with density g. We choose G to be zero-
mean independent Gaussian distributions while leaving its scale and the ridge parameter ϵ to be
automatically determined by the randomizedLasso function of the selectiveInference
package. We initialize the particles of our SVMD and MSVGD in the following way: First, we map
the solution ˆβE to the dual space by ∇ψ. Next, we add i.i.d. standard Gaussian noise to n copies of
the image in the dual space. Finally, we map the n particles back to the primal space by ∇ψ∗and use
them as the initial locations. Below we discuss the remaining settings and additional results of the
simulation and the HIV-1 drug resistance experiment separately."
DBT,0.6256239600665557,"Simulation
In our simulation we mostly follow the settings of Sepehri & Markovic (2017) except
using a different penalty level λ recommended in the selectiveInference R package. We
set ˜n = 100 and p = 40. The design matrix X is generated from an equi-correlated model, i.e.,
each datapoint xi ∈Rp is generated i.i.d. from N(0, Σ) with Σii = 1, Σij = 0.3 (i ̸= j) and then
normalized to have almost unit length. The normalization is done by ﬁrst centering each dimension
by subtracting the mean and dividing the standard deviation of that column of X, then additionally
multiplying 1/˜n1/2. y is generated from a standard Gaussian which is independent of X, i.e., we
assume the global null setting where the true value of β is zero. We set λ to be the value returned
by theoretical.lambda of the selectiveInference R package multiplied a coefﬁcient
0.7˜n, where the 0.7 adjustment is introduced in the test examples of the R package to reduce the
regularization effect so that we have a reasonably large set of selected features when p = 40. The
base learning rates for SVMD and MSVGD are set to 0.01 and we run them for T = 1000 particle
updates. τ is set to 0.98 for SVMD."
DBT,0.627287853577371,"Our 2D example in Fig. 4a is grabbed from one run of the simulation where there happen to be
only 2 features selected by the randomized Lasso. The selective distribution in this case has log-
density log p(θ) = −8.07193((2.39859θ1 + 1.90816θ2 + 2.39751)2 + (1.18099θ2 −1.46104)2) +
const, θ1,2 ≥0."
DBT,0.6289517470881864,Published as a conference paper at ICLR 2022
DBT,0.6306156405990017,"The error bars for actual coverage levels in Fig. 3a and Fig. 3b are 95% Wilson intervals (Wilson,
1927), which is known to be more accurate than ±2 standard deviation intervals for binomial
proportions like the coverage. In Fig. 9a and Fig. 9b we additionally plot the average length of the
conﬁdence intervals w.r.t. different sample size N and nominal coverage levels. For all three methods
the CI widths are very close, although MSVGD consistently has wider intervals than SVMD and
selectiveInference. This indicates that SVMD can be preferred over MSVGD when both
methods produce coverage above the nominal level."
DBT,0.632279534109817,"HIV-1 drug resistance
We take the vitro measurement of log-fold change under the 3TC drug
as response and include mutations that had appeared 11 times in the dataset as regressors. This
results in ˜n = 663 datapoints with p = 91 features. We choose λ to be the value returned by
theoretical.lambda of the selectiveInference R package multiplied by ˜n. The base
learning rates for SVMD and MSVGD are set to 0.01 and we run them for T = 2000 particle updates.
τ is set to 0.99 for SVMD."
DBT,0.6339434276206323,"1000
1500
2000
2500
3000
Number of sample points, N 0 1 2 3 4 5 6 7 8 Width"
DBT,0.6356073211314476,"Standard
MSVGD
SVMD"
DBT,0.6372712146422629,(a) Nominal coverage: 0.9
DBT,0.6389351081530782,"0.80
0.85
0.90
0.95
1.00
Nominal coverage 0 1 2 3 4 5 6 7 8 Width"
DBT,0.6405990016638935,"Standard
MSVGD
SVMD"
DBT,0.6422628951747088,(b) N = 5000 sample points
DBT,0.6439267886855241,"Figure 9: Width of post-selection CIs across (a) 500 / (b) 200 replications of simulation of Sepehri &
Markovic (2017)."
DBT,0.6455906821963394,"G.3
LARGE-SCALE POSTERIOR INFERENCE WITH NON-EUCLIDEAN GEOMETRY"
DBT,0.6472545757071547,"The Bayesian logistic regression model we consider is Q˜n
i=1 p(yi|xi, w)p(w), where p(w) =
N(w|0, I), p(yi|xi, w) = Bernoulli(σ(w⊤xi)). The bias parameter is absorbed into into w by
adding an additional feature 1 to each xi. The gradient of the log density of the posterior distribution
of w is ∇w log p(w|{yi, xi}N
i=1) = PN
i=1 xi(yi −σ(w⊤xi)) −w. We choose the metric tensor
∇2ψ(w) to be the Fisher information matrix (FIM) of the likelihood: F = 1 ˜n ˜n
X"
DBT,0.64891846921797,"i=1
Ep(yi|w,xi)[∇w log p(yi|xi, w)∇w log p(yi|xi, w)⊤] = 1 ˜n ˜n
X"
DBT,0.6505823627287853,"i=1
σ(w⊤xi)(1 −σ(w⊤xi))xix⊤
i ."
DBT,0.6522462562396006,"Following Wang et al. (2019), for each iteration r (r ≥1), we estimate the sum with a stochastic
minibatch Br of size 256: ˆFBr =
˜n
|Br|
P"
DBT,0.653910149750416,"i∈Br σ(w⊤xi)(1 −σ(w⊤xi))xix⊤
i and approximate the
FIM with a moving average across iterations:"
DBT,0.6555740432612313,"ˆFr = ρr ˆFr−1 + (1 −ρr) ˆFBr,
where ρr = min(1 −1/r, 0.95)."
DBT,0.6572379367720466,"To ensure the positive deﬁniteness of the FIM, a damping term 0.01I is added before taking the
inverse. For RSVGD and SVNG, the gradient of the inverse of FIM is estimated with ∇wjF −1 ≈
−ˆF −1
r
( ˆ∇r
wjF) ˆF −1
r
, where ˆ∇r
wjF = ρr ˆ∇r−1
wj F + (1 −ρr)∇wj ˆFBr."
DBT,0.6589018302828619,"We run each method for T = 3000 particle updates with learning rates in {0.01, 0.05, 0.1, 0.5, 1}
and average the results for 5 random trials. τ is set to 0.98 for SVNG. For each run, we randomly"
DBT,0.6605657237936772,Published as a conference paper at ICLR 2022
DBT,0.6622296173044925,"keep 20% of the dataset as test data, 20% of the remaining points as the validation set, and all the rest
as the training set. The results of each method on validation sets with all choices of learning rates are
plotted in Fig. 10. We see that the SVNG updates are very robust to the change in learning rates and
is able to accommodate very large learning rates (up to 1) without a signiﬁcant loss in performance.
The results in Fig. 5 are reported with the learning rate that performs best on the validation set."
DBT,0.6638935108153078,"0
1000
2000
3000
Number of particle updates, T −0.62 −0.60 −0.58 −0.56 −0.54 −0.52"
DBT,0.6655574043261231,Validation log predictive probability SVGD
DBT,0.6672212978369384,"0.01
0.05
0.1
0.5
1.0"
DBT,0.6688851913477537,"0
1000
2000
3000
Number of particle updates, T −0.62 −0.60 −0.58 −0.56 −0.54 −0.52"
DBT,0.670549084858569,Validation log predictive probability SVNG
DBT,0.6722129783693843,"0.01
0.05
0.1
0.5
1.0"
DBT,0.6738768718801996,"0
1000
2000
3000
Number of particle updates, T −0.62 −0.60 −0.58 −0.56 −0.54 −0.52"
DBT,0.6755407653910149,Validation log predictive probability RSVGD
DBT,0.6772046589018302,"0.01
0.05
0.1"
DBT,0.6788685524126455,"0
1000
2000
3000
Number of particle updates, T −0.62 −0.60 −0.58 −0.56 −0.54 −0.52"
DBT,0.6805324459234608,Validation log predictive probability
DBT,0.6821963394342762,Matrix SVGD (Avg)
DBT,0.6838602329450915,"0.01
0.05
0.1
0.5
1.0"
DBT,0.6855241264559068,"0
1000
2000
3000
Number of particle updates, T −0.62 −0.60 −0.58 −0.56 −0.54 −0.52"
DBT,0.6871880199667221,Validation log predictive probability
DBT,0.6888519134775375,Matrix SVGD (Mixture)
DBT,0.6905158069883528,"0.01
0.05
0.1
0.5
1.0"
DBT,0.6921797004991681,"Figure 10: Logistic regression results on validation sets with learning rates in {0.01, 0.05, 0.1, 0.5,
1}. Running RSVGD with learning rates 0.5 and 1 produces numerical errors. Therefore, we did not
include them in the plot."
DBT,0.6938435940099834,"H
EXPONENTIAL CONVERGENCE OF CONTINUOUS-TIME ALGORITHMS"
DBT,0.6955074875207987,"We derive a time-inhomogeneous generalization of the Stein Log-Sobolev inequality of Duncan et al.
(2019) and Korba et al. (2020) which ensures the exponential convergence of our continuous-time
algorithms and time-inhomogeneous generalization of the Stein Poincar´e inequality of Duncan et al.
(2019) which guarantees exponential convergence near equilibrium (i.e., when qt is sufﬁciently close
to p). As the results hold for a generic sequence of kernels (Kt)t≥0, the implications apply to both
MSVGD and SVMD."
DBT,0.697171381031614,Published as a conference paper at ICLR 2022
DBT,0.6988352745424293,"Deﬁnition 2 (Mirror Stein Log-Sobolev inequality). We deﬁne the Mirror Stein Log-Sobolev inequal-
ity (cf., Korba et al., 2020, Def. 2) as"
DBT,0.7004991680532446,KL(qt∥p) ≤1
DBT,0.7021630615640599,"2λMKSD2
Kt(qt, p) = 1"
DBT,0.7038269550748752,2λEqt[(∇2ψ−1∇log qt
DBT,0.7054908485856906,"p )⊤PKt,qt∇2ψ−1∇log qt p ],"
DBT,0.7071547420965059,"where MKSDKt is deﬁned in Eq. (15); PKt,qt : L2(qt) →L2(qt) is the kernel integral operator:
(PKt,qtϕ)(·) ≜Eqt(θ)[Kt(·, θ)ϕ(θ)] for a general kernel Kt and vector-valued function ϕ on Θ, and
the stated equality holds whenever integration-by-parts is applicable.
Proposition 11. Suppose (θt)t≥0 follows the mirrored dynamics (8) with gt chosen to be g∗
qt,Kt as
in (10). Then, the dissipation of KL(qt∥p) is
d
dtKL(qt∥p) = −MKSDKt(qt, p)2."
DBT,0.7088186356073212,"Proof
The proof directly follows from Thm. 3 since the optimization problem there matches the
deﬁnition of MKSD in (15)."
DBT,0.7104825291181365,"Therefore, when the Mirror Stein Log-Sobolev inequality holds, we have
d
dtKL(qt∥p) ≤−2λKL(qt∥p),"
DBT,0.7121464226289518,"and the exponential convergence KL(qt∥p) ≤KL(q0∥p)e−2λt follows by Gronwall’s lemma (Gron-
wall, 1919).
Deﬁnition 3 (Mirror Stein Poincar´e inequality). We say that the distribution p satisﬁes the Mirror
Stein Poincar´e inequality (cf., Duncan et al. 2019, Eq. (57)) with strongly convex ψ and constant λ if"
DBT,0.7138103161397671,Varp[φ] ≤1
DBT,0.7154742096505824,"λEp[∇φ⊤PKt,p∇2ψ−1∇φ]"
DBT,0.7171381031613977,"for all φ ∈L2(p) ∩C∞(Θ) that is locally Lipschitz, where PKt,p is the kernel integral operator
under p deﬁned similarly as in Deﬁnition 2."
DBT,0.718801996672213,"This inequality can also be viewed as a kernelized generalization of the mirror Poincar´e inequality
introduced in Chewi et al. (2020, Def. 1) for proving exponential convergence of mirror-Langevin
diffusion. In a manner analogous to Thm. 1 of Chewi et al. (2020), the following proposition relates
the Mirror Stein Poincar´e inequality to chi-squared divergence.
Proposition 12. Suppose (θt)t≥0 follows the mirrored dynamics (8) with gt chosen to be g∗
qt,Kt as
in (10). Then, the dissipation of chi-square divergence χ2(qt∥p) is
d
dtχ2(qt∥p) = −2Eqt 
∇qt p"
DBT,0.7204658901830283,"⊤
PKt,p∇2ψ−1∇qt p "
DBT,0.7221297836938436,whenever integration-by-parts is applicable.
DBT,0.7237936772046589,"Proof
We ﬁrst note that by applying integration-by-parts, g∗
qt,Kt as in (10) can be equivalently
written as
g∗
qt,Kt = −PKt,qt∇2ψ−1∇log qt p ."
DBT,0.7254575707154742,"Then using the Fokker-Planck equation of qt under the dynamics, we have"
DBT,0.7271214642262895,"d
dtχ2(qt∥p) = d dt Z qt p"
DBT,0.7287853577371048,"2
dp = 2
Z qt"
DBT,0.7304492512479202,p · dqt
DBT,0.7321131447587355,dt = −2Eqt
DBT,0.7337770382695508,"
g∗
t,Kt
⊤∇qt p "
DBT,0.7354409317803661,= −2Eqt
DBT,0.7371048252911814,"""
PKt,qt∇2ψ−1∇log qt p"
DBT,0.7387687188019967,"⊤
∇qt p #"
DBT,0.740432612312812,"= −2Eqt 
∇qt p"
DBT,0.7420965058236273,"⊤
PKt,p∇2ψ−1∇qt p 
."
DBT,0.7437603993344426,"Note that the right hand side of the equation differs from the Mirror Stein Poincar´e inequality
only in the base measure of the expectation. Duncan et al. (2019) proposes to replace qt with p
to study the convergence near equilibrium (See their Sec. 6, where Eq. (46) is replaced with Eq.
(51)). If we do the same and combine this identity with the Mirror Stein Poincar´e inequality, we
obtain d"
DBT,0.7454242928452579,dtχ2(qt∥p) ≤−2λVarp[ qt
DBT,0.7470881863560732,"p ] = −2λχ2(qt∥p), which implies exponential convergence in KL
KL(qt∥p) ≤χ2(qt∥p) ≤χ2(q0∥p)e−2λt by Gronwall’s lemma (Gronwall, 1919)."
DBT,0.7487520798668885,Published as a conference paper at ICLR 2022
DBT,0.7504159733777038,"I
PROOFS"
DBT,0.7520798668885191,"I.1
PROOF OF PROP. 1"
DBT,0.7537437603993344,"Proof
Fix any g ∈Gψ. Since g and ∇g are bounded and ∇2ψ(θ)−1∇log p(θ) and ∇· ∇2ψ(θ)−1
are p-integrable, the expectation Eθ∼p[(Mp,ψg)(θ)] exists. Because Θ is convex, Θr is bounded and
convex with Lipschitz boundary. Since p∇2ψ−1g ∈C1, we have
|Ep[(Mp,ψg)(θ)]| = |Ep[g(θ)⊤∇2ψ(θ)−1∇log p(θ) + ∇· (∇2ψ(θ)−1g(θ))]| = Z"
DBT,0.7554076539101497,"Θ
∇p(θ)⊤∇2ψ(θ)−1g(θ) + p(θ)∇· (∇2ψ(θ)−1g(θ))dθ = Z"
DBT,0.757071547420965,"Θ
∇· (p(θ)∇2ψ(θ)−1g(θ))dθ"
DBT,0.7587354409317804,"=
 lim
r→∞ Z"
DBT,0.7603993344425957,"Θr
∇· (p(θ)∇2ψ(θ)−1g(θ))dθ

(by dominated convergence)"
DBT,0.762063227953411,"=
 lim
r→∞ Z"
DBT,0.7637271214642263,"∂Θr
(p(θ)∇2ψ(θ)−1g(θ))⊤nr(θ)dθ

(by the divergence theorem)"
DBT,0.7653910149750416,"≤lim
r→∞ Z"
DBT,0.7670549084858569,"∂Θr
p(θ)∥g(θ)∥2
∇2ψ(θ)−1nr(θ)

2dθ
(by Cauchy-Schwarz)"
DBT,0.7687188019966722,"≤∥g∥∞lim
r→∞ Z"
DBT,0.7703826955074875,"∂Θr
p(θ)
∇2ψ(θ)−1nr(θ)

2dθ = 0
(by assumption)."
DBT,0.7720465890183028,"I.2
PROOF OF THM. 3: OPTIMAL MIRROR UPDATES IN RKHS"
DBT,0.7737104825291181,"Proof
Let ei denote the standard basis vector of Rd with the i-th element being 1 and others being
zeros. Since m ∈HK, we have
m(θ)⊤∇2ψ(θ)−1∇log p(θ) = ⟨m, K(·, θ)∇2ψ(θ)−1∇log p(θ)⟩HK"
DBT,0.7753743760399334,"∇· (∇2ψ(θ)−1m(θ)) = d
X"
DBT,0.7770382695507487,"i=1
∇θi(m(θ)⊤∇2ψ(θ)−1ei) = d
X"
DBT,0.778702163061564,"i=1
⟨m, ∇θi(K(·, θ)∇2ψ(θ)−1ei)⟩HK"
DBT,0.7803660565723793,"= ⟨m, ∇θ · (K(·, θ)∇2ψ(θ)−1)⟩HK,
where we deﬁne the divergence of a matrix as a vector whose elements are the divergences of each
row of the matrix. Then, we write (9) as
−Eqt[m(θ)⊤∇2ψ(θ)−1∇log p(θ) + ∇· (∇2ψ(θ)−1m(θ))]"
DBT,0.7820299500831946,"= −Eqt[⟨m, K(·, θ)∇2ψ(θ)−1∇log p(θ) + ∇θ · (K(·, θ)∇2ψ(θ)−1)⟩HK]"
DBT,0.78369384359401,"= −⟨m, Eqt[K(·, θ)∇2ψ(θ)−1∇log p(θ) + ∇θ · (K(·, θ)∇2ψ(θ)−1)]⟩HK
= −⟨m, Eqt[Mp,ψK(·, θ)]⟩HK.
Therefore, the optimal direction in the HK norm ball BHK = {g : ∥g∥HK ≤1} that minimizes (9)
is g∗
t ∝g∗
qt,K = Eqt[Mp,ψK(·, θ)]."
DBT,0.7853577371048253,"I.3
PROOF OF THM. 4: MIRRORED SVGD UPDATES"
DBT,0.7870216306156406,"Proof
A p.d. kernel k composed with any map φ is still a p.d. kernel. To prove this, let
{x1, . . . , xp} = {φ(η1), . . . , φ(ηn)}, p ≤n. Then
X"
DBT,0.7886855241264559,"i,j
αiαjk(φ(ηi), φ(ηj)) =
X"
DBT,0.7903494176372712,"ℓ,m
βℓβmk(xℓ, xm) ≥0,"
DBT,0.7920133111480865,Published as a conference paper at ICLR 2022
DBT,0.7936772046589018,where βℓ= P
DBT,0.7953410981697171,"i∈Sℓαi, Sℓ= {i : φ(ηi) = xℓ}. Therefore, kψ(η, η′) = k(∇ψ∗(η), ∇ψ∗(η′)) is a
p.d. kernel. Plugging K = kI into Lem. 13, for any θ′ ∈Θ and η′ = ∇ψ(θ′), we have"
DBT,0.7970049916805324,"g∗
qt,Kk(θ′) = Eηt∼qt,H[K∇ψ∗(∇ψ(θ′), ηt)∇log pH(ηt) + ∇ηt · K∇ψ∗(∇ψ(θ′), ηt)]"
DBT,0.7986688851913477,"= Eηt∼qt,H[k(∇ψ∗(η′), ∇ψ∗(ηt))∇log pH(ηt) + d
X"
DBT,0.800332778702163,"j=1
∇ηt,jk(∇ψ∗(η′), ∇ψ∗(ηt))ej]"
DBT,0.8019966722129783,"= Eηt∼qt,H[kψ(η′, ηt)∇log pH(ηt) + ∇ηtkψ(η′, ηt)]."
DBT,0.8036605657237936,"I.4
PROOF OF PROP. 5: SINGLE-PARTICLE SVMD IS MIRROR DESCENT"
DBT,0.8053244592346089,"Proof
When n = 1, λ1 = k(θt, θt), u1 = 1, and thus Kψ,t(θt, θt) = k(θt, θt)∇2ψ(θt)."
DBT,0.8069883527454242,"I.5
PROOF OF THM. 6: CONVERGENCE OF MIRRORED UPDATES AS n →∞"
DBT,0.8086522462562395,"Proof
The idea is to reinterpret our mirrored updates as one step of a matrix SVGD in η space based
on Lem. 13 and then follow the path of Gorham et al. (2020, Thm. 7). Assume that qn
t,H and q∞
t,H have
integrable means. Let ηn, η∞be an optimal Wasserstein-1 coupling of qn
t,H and q∞
t,H. Let Φqt,Kt
denote the transform through one step of mirrored update: θt = ∇ψ⋆(ηt), ηt+1 = ηt + ϵtg∗
qt,Kt(θt).
Then, with Lem. 13, we have"
DBT,0.8103161397670549,"∥Φqt,Kt(η) −Φqt,Kt(η′)∥2
= ∥η + ϵtg∗
qn
t ,Kt(θ) −η′ −ϵtg∗
q∞
t ,Kt(θ′)∥2"
DBT,0.8119800332778702,"≤∥η −η′∥2 + ϵt∥g∗
qn
t ,Kt(θ) −g∗
q∞
t ,Kt(θ′)∥2"
DBT,0.8136439267886856,"≤∥η −η′∥2
+ ϵt∥Eηn[K∇ψ∗,t(η, ηn)∇log pH(ηn) + ∇ηn · K∇ψ∗,t(η, ηn)"
DBT,0.8153078202995009,"−(K∇ψ∗,t(η′, ηn)∇log pH(ηn) + ∇ηn · K∇ψ∗,t(η′, ηn))]∥2
+ ϵt∥Eηn,η∞[K∇ψ∗,t(η′, ηn)∇log pH(ηn) + ∇ηn · K∇ψ∗,t(η, ηn)"
DBT,0.8169717138103162,"−(K∇ψ∗,t(η′, η∞)∇log pH(η∞) + ∇η∞· K∇ψ∗,t(η′, η∞))]∥2
≤∥η −η′∥2 + ϵtc1(1 + E[∥ηn∥2)]∥η −η′∥2 + ϵtc2(1 + ∥η′∥2)Eηn,η∞[∥ηn −η∞∥2]"
DBT,0.8186356073211315,"= ∥η −η′∥2 + ϵtc1(1 + Eqn
t,H[∥·∥2])∥η −η′∥2 + ϵtc2(1 + ∥η′∥2)W1(qn
t,H, q∞
t,H)."
DBT,0.8202995008319468,"Since Φqt,Kt(ηn) ∼qn
t+1,H, Φqt,K(η∞) ∼q∞
t+1,H, we conclude"
DBT,0.8219633943427621,"W1(qn
t+1,H, q∞
t+1,H)"
DBT,0.8236272878535774,"≤E[∥Φqt,K(ηn) −Φqt,K(η∞)∥2]"
DBT,0.8252911813643927,"≤(1 + ϵtc1(1 + Eqn
t,H[∥·∥2]))E[∥ηn −η∞∥2] + ϵtc2(1 + ∥η′∥2)W1(qn
t,H, q∞
t,H)]"
DBT,0.826955074875208,"≤(1 + ϵtc1(1 + Eqn
t,H[∥·∥2]) + ϵtc2(1 + Eq∞
t,H[∥·∥2]))W1(qn
t,H, q∞
t,H)."
DBT,0.8286189683860233,"The ﬁnal claim qn
t ⇒q∞
t now follows by the continuous mapping theorem as ∇ψ∗is continuous."
DBT,0.8302828618968386,"I.6
PROOF OF THM. 7: INFINITE-PARTICLE MIRRORED STEIN UPDATES DECREASE KL AND
MKSD"
DBT,0.831946755407654,"Proof
Let Tq∞
t ,Kt denote transform of the density function through one step of mirrored update:
θt = ∇ψ⋆(ηt), ηt+1 = ηt + ϵtg∗
q∞
t ,Kt(θt). Then"
DBT,0.8336106489184693,"KL(q∞
t+1∥p) −KL(q∞
t ∥p)"
DBT,0.8352745424292846,"= KL(q∞
t ∥T −1
q∞
t ,Ktp) −KL(q∞
t ∥p)"
DBT,0.8369384359400999,"= Eηt∼q∞
t,H[log pH(ηt) −log pH(ηt + ϵtg∗
q∞
t ,Kt(θt)) −log | det(I + ϵt∇ηtg∗
q∞
t ,Kt(θt))|],"
DBT,0.8386023294509152,Published as a conference paper at ICLR 2022
DBT,0.8402662229617305,"where we have used the invariance of KL divergence under reparameterization: KL(qt∥p) =
KL(qt,H∥pH) . Following Liu (2017), we bound the difference of the ﬁrst two terms as"
DBT,0.8419301164725458,"log pH(ηt) −log pH(ηt + ϵtg∗
q∞
t ,Kt(θt))"
DBT,0.8435940099833611,"= −
Z 1"
DBT,0.8452579034941764,"0
∇s log pH(ηt(s)) ds,
where ηt(s) ≜ηt + sϵtg∗
q∞
t ,Kt(θt)"
DBT,0.8469217970049917,"= −
Z 1"
DBT,0.848585690515807,"0
∇log pH(ηt(s))⊤(ϵtg∗
q∞
t ,Kt(θt)) ds"
DBT,0.8502495840266223,"= −ϵt∇log pH(ηt)⊤g∗
q∞
t ,Kt(θt) +
Z 1"
DBT,0.8519134775374376,"0
(∇log pH(ηt) −∇log pH(ηt(s)))⊤(ϵtg∗
q∞
t ,Kt(θt)) ds"
DBT,0.8535773710482529,"≤−ϵt∇log pH(ηt)⊤g∗
q∞
t ,Kt(θt) + ϵt Z 1"
DBT,0.8552412645590682,"0
∥∇log pH(η) −∇log pH(ηt(s))∥2 · ∥g∗
q∞
t ,Kt(θt)∥2 ds"
DBT,0.8569051580698835,"≤−ϵt∇log pH(ηt)⊤g∗
q∞
t ,Kt(θt) + Lϵ2
t
2 ∥g∗
q∞
t ,Kt(θt)∥2
2,"
DBT,0.8585690515806988,and bound the log determinant term using Lem. 15:
DBT,0.8602329450915142,"−log | det(I + ϵt∇ηtg∗
q∞
t ,Kt(θt)) ≤−ϵt Tr(∇ηtg∗
q∞
t ,Kt(θt)) + 2ϵ2
t∥∇ηtg∗
q∞
t ,Kt(θt)∥2
F ."
DBT,0.8618968386023295,"The next thing to notice is that Eηt∼q∞
t,H[∇log pH(ηt)⊤g∗
q∞
t ,Kt(θt) + Tr(∇ηtg∗
q∞
t ,Kt(θt))] is the
square of the MKSD in (15). We can show this equivalence using the identity proved in Lem. 14:"
DBT,0.8635607321131448,"Eηt∼q∞
t,H[g∗
q∞
t ,Kt(θt)⊤∇log pH(ηt) + Tr(∇ηtg∗
q∞
t ,Kt(θt))]"
DBT,0.8652246256239601,"= Eθt∼q∞
t [g∗
q∞
t ,Kt(θt)⊤∇2ψ(θt)−1∇θt(log p(θt) −log det ∇2ψ(θt))"
DBT,0.8668885191347754,"+ Tr(∇2ψ(θt)−1∇g∗
q∞
t ,Kt(θt))]"
DBT,0.8685524126455907,"= Eθt∼q∞
t [g∗
q∞
t ,Kt(θt)⊤∇2ψ(θt)−1∇log p(θt) + ∇· (∇2ψ(θt)−1g∗
q∞
t ,Kt(θt))]
(Lem. 14)"
DBT,0.870216306156406,"= Eθt∼q∞
t [(Mp,ψg∗
q∞
t ,Kt)(θt)]"
DBT,0.8718801996672213,"= MKSDKt(q∞
t , p)2."
DBT,0.8735440931780366,"Finally, we are going to bound ∥g∗
q∞
t ,Kt(θt)∥2
2 and ∥∇ηtg∗
q∞
t ,Kt(θt)∥2
F . From the assumptions we
have ψ is α-strongly convex and thus ψ∗is 1"
DBT,0.8752079866888519,"α-strongly smooth (Kakade et al., 2009), therefore
∥∇2ψ∗(·)∥2 ≤1"
DBT,0.8768718801996672,"α. By Lem. 16, we know"
DBT,0.8785357737104825,"∥g∗
q∞
t ,Kt(θt)∥2
2 ≤∥g∗
q∞
t ,Kt∥2
HKt∥K(θt, θt)∥op = MKSDKt(q∞
t , p)2∥Kt(θt, θt)∥op,"
DBT,0.8801996672212978,"∥∇ηtg∗
q∞
t ,Kt(θt)∥2
F = ∥∇2ψ∗(ηt)∇g∗
q∞
t ,Kt(θt)∥2
F
≤∥∇2ψ∗(ηt)∥2
2∥∇g∗
q∞
t ,Kt(θt)∥2
F ≤1"
DBT,0.8818635607321131,"α2 ∥g∗
q∞
t ,Kt∥2
HKt d
X"
DBT,0.8835274542429284,"i=1
∥∇2
i,d+iKt(θt, θt)∥op = 1"
DBT,0.8851913477537438,"α2 MKSDKt(q∞
t , p)2
d
X"
DBT,0.8868552412645591,"i=1
∥∇2
i,d+iKt(θt, θt)∥op,"
DBT,0.8885191347753744,"where ∇2
i,d+iK(θ, θ) denotes ∇2
θi,θ′
iK(θ, θ′)|θ′=θ. Combining all of the above, we have"
DBT,0.8901830282861897,"KL(q∞
t+1∥p) −KL(q∞
t ∥p) ≤− "
DBT,0.891846921797005,"ϵt −Lϵ2
t
2
sup
θ
∥Kt(θ, θ)∥op −2ϵ2
t
α2 d
X"
DBT,0.8935108153078203,"i=1
sup
θ
∥∇2
i,d+iKt(θ, θ)∥op !"
DBT,0.8951747088186356,"MKSDKt(q∞
t , p)2."
DBT,0.8968386023294509,Plugging in the deﬁnition of κ1 and κ2 ﬁnishes the proof.
DBT,0.8985024958402662,Published as a conference paper at ICLR 2022
DBT,0.9001663893510815,"I.7
PROOF OF THM. 8: MKSDKk DETERMINES WEAK CONVERGENCE"
DBT,0.9018302828618968,"Proof
According to Thm. 4,"
DBT,0.9034941763727121,"g∗
q,Kk = EqH[k(·, ∇ψ∗(η))∇log pH(η) + ∇ηk(∇ψ∗(η), ·)],"
DBT,0.9051580698835274,"where qH(η) denotes the density of η = ∇ψ(θ) under the distribution θ ∼q. From the assumptions
we have k(θ, θ′) = κ(∇ψ(θ), ∇ψ(θ′)). With this speciﬁc choice of k, the squared MKSD is"
DBT,0.9068219633943427,"MKSDKk(q, p)2 = ∥g∗
q,Kk∥2
HKk"
DBT,0.908485856905158,"= Eη,η′∼qH"
DBT,0.9101497504159733,"
1
pH(η)pH(η′)∇η∇η′(pH(η)k(∇ψ∗(η), ∇ψ∗(η′))pH(η′))
"
DBT,0.9118136439267887,"= Eη,η′∼qH"
DBT,0.913477537437604,"
1
pH(η)pH(η′)∇η∇η′(pH(η)κ(η, η′)pH(η′))

.
(21)"
DBT,0.9151414309484193,"The ﬁnal expression in (21) is the squared kernel Stein discrepancy (KSD) (Liu et al., 2016;
Chwialkowski et al., 2016; Gorham & Mackey, 2017) between qH and pH with the kernel κ:
KSDκ(qH, pH)2.
Recall that it is proved in Gorham & Mackey (2017, Theorem 8) that, for
κ(x, y) = (c2 + ∥x −y∥2
2)β with β ∈(−1, 0) and distantly dissipative pH with Lipschitz score
functions, qH ⇒pH if KSDκ(qH, pH) →0. The advertised result (q ⇒p if MKSDKk(q, p) →0)
now follows by the continuous mapping theorem as ∇ψ∗is continuous."
DBT,0.9168053244592346,"J
LEMMAS"
DBT,0.9184692179700499,"Lemma 13. Let K∇ψ∗(η, η′) ≜K(∇ψ∗(η), ∇ψ∗(η′)). The mirrored updates g∗
qt,K in (10) can be
equivalently expressed as"
DBT,0.9201331114808652,"g∗
qt,K = Eqt,H[K∇ψ∗(∇ψ(·), η)∇log pH(η) + ∇η · K∇ψ∗(∇ψ(·), η)]."
DBT,0.9217970049916805,"Proof
We will use the identity proved in Lem. 14."
DBT,0.9234608985024958,"g∗
qt,K = Eqt[Mp,ψK(·, θ)]"
DBT,0.9251247920133111,"= Eqt[K(·, θ)∇2ψ(θ)−1∇log p(θ) + ∇θ · (K(·, θ)∇2ψ(θ)−1)]"
DBT,0.9267886855241264,"= Eqt[K(·, θ)∇2ψ(θ)−1∇θ(log pH(∇ψ(θ)) + log det ∇2ψ(θ)) + ∇θ · (K(·, θ)∇2ψ(θ)−1)]
(by change-of-variable formula)"
DBT,0.9284525790349417,"= Eqt[K(·, θ)∇2ψ(θ)−1∇θ log pH(∇ψ(θ)) + d
X"
DBT,0.930116472545757,"i,j=1
[∇2ψ(θ)−1]ij∇θiK(·, θ):,j]"
DBT,0.9317803660565723,"(by applying Lem. 14 to each row of K(·, θ))"
DBT,0.9334442595673876,"= Eqt[K(·, θ)∇2ψ(θ)−1∇θ log pH(∇ψ(θ)) + d
X"
DBT,0.9351081530782029,"j=1
∇ηjK(·, θ):,j]"
DBT,0.9367720465890182,"= Eqt,H[K(·, ∇ψ∗(η))∇log pH(η) + d
X"
DBT,0.9384359400998337,"j=1
∇ηjK(·, ∇ψ∗(η)):,j]"
DBT,0.940099833610649,"= Eqt,H[K∇ψ∗(∇ψ(·), η)∇log pH(η) + ∇η · K∇ψ∗(∇ψ(·), η)],"
DBT,0.9417637271214643,"where A:,j denotes the j-th column of a matrix A."
DBT,0.9434276206322796,"Lemma 14. For a strictly convex function ψ ∈C2 : Rd →R and any vector-valued g ∈C1 : Rd →
Rd, the following relation holds:"
DBT,0.9450915141430949,∇· (∇2ψ(θ)−1g(θ)) = Tr(∇2ψ(θ)−1∇g(θ)) −g(θ)⊤∇2ψ(θ)−1∇θ log det ∇2ψ(θ).
DBT,0.9467554076539102,"Proof
By the product rule of differentiation:"
DBT,0.9484193011647255,"∇· (∇2ψ(θ)−1g(θ)) = Tr(∇2ψ(θ)−1∇g(θ)) + g(θ)⊤∇· (∇2ψ(θ)−1).
(22)"
DBT,0.9500831946755408,Published as a conference paper at ICLR 2022
DBT,0.9517470881863561,"This already gives us the ﬁrst term on the right side. Next, we have
[∇2ψ(θ)−1∇log det ∇2ψ(θ)]i = d
X"
DBT,0.9534109816971714,"j=1
[∇2ψ(θ)−1]ij Tr(∇2ψ(θ)−1∇θj∇2ψ(θ)) = d
X"
DBT,0.9550748752079867,"j=1
[∇2ψ(θ)−1]ij d
X"
DBT,0.956738768718802,"ℓ,m=1
[∇2ψ(θ)−1]ℓm[∇θj∇2ψ(θ)]mℓ = d
X"
DBT,0.9584026622296173,"j,ℓ,m=1
[∇2ψ(θ)−1]ij[∇2ψ(θ)−1]ℓm∇θj∇2ψ(θ)mℓ = d
X"
DBT,0.9600665557404326,"j,ℓ,m=1
[∇2ψ(θ)−1]ij∇θm∇2ψ(θ)jℓ[∇2ψ(θ)−1]ℓm = − d
X"
DBT,0.961730449251248,"m=1
∇θm(∇2ψ(θ)−1)im"
DBT,0.9633943427620633,"= −[∇· ∇2ψ(θ)−1]i.
Plugging the above relation into (22) proves the claimed result."
DBT,0.9650582362728786,"Lemma 15 (Liu, 2017, Lemma A.1). Let A be a square matrix, and 0 < ϵ <
1
2∥A+A⊤∥op . Then,"
DBT,0.9667221297836939,"log | det(I + ϵA)| ≥ϵ Tr(A) −2ϵ2∥A∥2
F ,
where ∥· ∥F denotes the Frobenius norm of a matrix.
Lemma 16. Let K be a matrix-valued kernel and HK be the corresponding RKHS. Then, for any
f ∈HK (f is vector-valued), we have"
DBT,0.9683860232945092,"∥f(x)∥2 ≤∥f∥HK∥K(x, x)∥1/2
op ,
∥∇f(x)∥2
F ≤∥f∥2
HK d
X"
DBT,0.9700499168053245,"i=1
∥∇2
xi,x′
iK(x, x′)|x′=x∥op,"
DBT,0.9717138103161398,where ∥· ∥op denotes the operator norm of a matrix induced by the vector 2-norm.
DBT,0.9733777038269551,"Proof
We ﬁrst bound the ∥f(x)∥2 as"
DBT,0.9750415973377704,"∥f(x)∥2 =
sup
∥y∥2=1
f(x)⊤y =
sup
∥y∥2=1
⟨f, K(·, x)y⟩HK ≤∥f∥HK
sup
∥y∥2=1
∥K(·, x)y∥HK"
DBT,0.9767054908485857,"= ∥f∥HK
sup
∥y∥2=1
(y⊤K(x, x)y)1/2 ≤∥f∥HK
sup
∥y∥2=1
sup
∥u∥2=1
(u⊤K(x, x)y)1/2"
DBT,0.978369384359401,"= ∥f∥HK
sup
∥y∥2=1
∥K(x, x)y∥1/2
2
= ∥f∥HK∥K(x, x)∥1/2
op ."
DBT,0.9800332778702163,"The second result follows similarly,"
DBT,0.9816971713810316,"∥∇f(x)∥2
F = d
X"
DBT,0.9833610648918469,"i=1
∥∇xif(x)∥2
2 = d
X"
DBT,0.9850249584026622,"i=1
sup
∥y∥2=1
(∇xif(x)⊤y)2 =
X"
DBT,0.9866888519134775,"i=1
sup
∥y∥2=1
(⟨f, ∇xiK(·, x)y⟩HK)2"
DBT,0.9883527454242929,"≤∥f∥2
HK d
X"
DBT,0.9900166389351082,"i=1
sup
∥y∥2=1
∥∇xiK(·, x)y∥2
HK = ∥f∥2
HK d
X"
DBT,0.9916805324459235,"i=1
sup
∥y∥2=1
(y⊤∇2
xi,x′
iK(x, x′)|x=x′y)"
DBT,0.9933444259567388,"≤∥f∥2
HK d
X"
DBT,0.9950083194675541,"i=1
sup
∥y∥2=1
sup
∥u∥2=1
(u⊤∇2
xi,x′
iK(x, x′)|x=x′y)"
DBT,0.9966722129783694,"= ∥f∥2
HK d
X"
DBT,0.9983361064891847,"i=1
∥∇2
xi,x′
iK(x, x′)|x′=x∥op."
