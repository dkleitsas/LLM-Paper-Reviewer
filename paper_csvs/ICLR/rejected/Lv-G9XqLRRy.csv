Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.004830917874396135,"Deep learning models are trained on multiple categories jointly to solve several
real-world problems. However, there can be cases where some of the classes may
become restricted in the future and need to be excluded after the model has already
been trained on them (Class-level Privacy). It can be due to privacy, ethical or legal
concerns. A naive solution is to simply train the model from scratch on the complete
training data while leaving out the training samples from the restricted classes (FDR
- full data retraining). But this can be a very time-consuming process. Further, this
approach will not work well if we no longer have access to the complete training
data and instead only have access to very few training data. The objective of this
work is to remove the information about the restricted classes from the network
representations of all layers using limited data without affecting the prediction
power of the model for the remaining classes. Simply ﬁne-tuning the model on
the limited available training data for the remaining classes will not be able to
sufﬁciently remove the restricted class information, and aggressive ﬁne-tuning
on the limited data may also lead to overﬁtting. We propose a novel solution to
achieve this objective that is signiﬁcantly faster (∼200× on ImageNet) than the
naive solution. Speciﬁcally, we propose a novel technique for identifying the model
parameters that are mainly relevant to the restricted classes. We also propose a
novel technique that uses the limited training data of the restricted classes to remove
the restricted class information from these parameters and uses the limited training
data of the remaining classes to reuse these parameters for the remaining classes.
The model obtained through our approach behaves as if it was never trained on the
restricted classes and performs similar to FDR (which needs the complete training
data). We also propose several baseline approaches and compare our approach with
them in order to demonstrate its efﬁcacy."
INTRODUCTION,0.00966183574879227,"1
INTRODUCTION"
INTRODUCTION,0.014492753623188406,"There are several real-world problems in which deep learning models have exceeded human-level
performance. This has led to a wide deployment of deep learning models. Deep learning models
generally train jointly on a number of categories/classes of data. However, the use of some of these
classes may get restricted in the future (restricted classes), and a model with the capability to identify
these classes may violate legal/privacy concerns, e.g., a company may legally prevent a deep learning
model from having the capability to identify its copyright-protected logo, patented products, and so
on. Another example is a treatment prediction model that predicts the best treatment for a patient
based on the disease. If one of the treatments for a disease is banned due to its side-effects or ethical
concerns, the restricted treatment category has to be excluded from the trained model. Individuals
and organizations are becoming increasingly aware of these issues leading to an increasing number
of legal cases on privacy issues in recent years. In such situations, the model has to be stripped
of its capability to identify these categories. This is a difﬁcult problem to solve, especially if the
full training data is no longer available and only a few training examples are available. We present
a “Restricted Category Removal from Model Representations with Limited Data” (RCRMR-LD)
problem setting that simulates the above problem. In this paper, we propose to solve this problem in
a fast and efﬁcient manner."
INTRODUCTION,0.01932367149758454,"The objective of the RCRMR-LD problem is to remove the information regarding the restricted
classes from the network representations of all layers using the limited training data available without"
INTRODUCTION,0.024154589371980676,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.028985507246376812,"affecting the ability of the model to identify the remaining classes. If we have access to the full
training data, then we can simply exclude the restricted class examples from the training data and
perform a full training of the model from scratch using the abundant data (FDR - full data retraining).
However, the RCRMR-LD problem setting is based on the scenario that the directive to exclude the
restricted classes is received in the future after the model has already been trained on the full data and
now only a limited amount of training data is available to carry out this process. Simply training the
network from scratch on only the limited training data of the remaining classes will result in severe
overﬁtting and signiﬁcantly affect the model performance (Baseline 2, as shown in Tables 1, 6)."
INTRODUCTION,0.033816425120772944,"Another possible solution to this problem is to remove the weights of the fully-connected classiﬁcation
layer of the network corresponding to the excluded classes such that it can no longer classify the
excluded classes. However, this approach suffers from a serious problem. Since, in this approach,
we only remove some of the weights of the classiﬁcation layer and the rest of the model remains
unchanged, it still contains the information required for recognizing the excluded classes. This
information can be easily accessed through the features that the model extracts from the images.
Therefore, we can use these features for performing classiﬁcation. In this paper, we use a nearest
prototype-based classiﬁer to demonstrate that the model features still contain information regarding
the restricted classes. Speciﬁcally, we use the model features of the examples from the limited training
data to compute the average class prototype for each class and create a nearest class prototype-based
classiﬁer using them. Next, for any given test image, we extract its features using the model and
then ﬁnd the class prototype closest to the given test image. This nearest class prototype-based
classiﬁer performs close to the original fully-connected classiﬁer on the excluded classes as shown in
Tables 1, 6 (Baseline 1). Therefore, even after using this approach, the resulting model still contains
information regarding the restricted classes. Another possible approach can be to apply the standard
ﬁne-tuning approach to the model using the limited available training data of the remaining classes
(Baseline 8). However, ﬁne-tuning on such limited training data is not able to sufﬁciently remove
the restricted class information from the model representations (see Tables 1, 6), and aggressive
ﬁne-tuning on the limited training data may result in overﬁtting."
INTRODUCTION,0.03864734299516908,"Considering the problems faced by the naive approaches mentioned above, we propose a novel
“Efﬁcient Removal with Preservation” (ERwP) approach to address the RCRMR-LD problem. First,
we propose a novel technique to identify the model parameters that are highly relevant to the restricted
classes, and to the best of our knowledge, there are no existing prior works for ﬁnding such class-
speciﬁc relevant parameters. Next, we propose a novel technique that optimizes the model on the
limited available training data in such a way that the restricted class information is discarded from
the restricted class relevant parameters, and these parameters are reused for the remaining classes."
INTRODUCTION,0.043478260869565216,"To the best of our knowledge, this is the ﬁrst work that addresses the RCRMR-LD problem. Therefore,
we also propose several baseline approaches for this problem (see Sec. 11.2). However, our proposed
approach signiﬁcantly outperforms all the proposed baseline approaches. Our proposed approach
requires very few epochs to address the RCRMR-LD problem and is, therefore, very fast (∼200
times faster than the full data retraining model for the ImageNet dataset) and efﬁcient. The model
obtained after applying our approach forgets the excluded classes to such an extent that it behaves
as though it was never trained on examples from the excluded classes. The performance of our
model is very similar to the full data retraining (FDR) model (see Sec. 8.1, Fig. 5). We also propose
the performance metrics needed to evaluate the performance of any approach for the RCRMR-LD
problem. We perform experiments on several datasets to demonstrate the efﬁcacy of our method."
PROBLEM SETTING,0.04830917874396135,"2
PROBLEM SETTING"
PROBLEM SETTING,0.05314009661835749,"In this work, we present the restricted category removal from model representations with limited
data (RCRMR-LD) problem setting, in which a deep learning model Mo trained on a speciﬁc
dataset has to be modiﬁed to exclude information regarding a set of restricted/excluded classes from
all layers of the deep learning model without affecting its identiﬁcation power for the remaining
classes (see Fig. 1). The classes that need to be excluded are referred to as the restricted/excluded
classes. Let {Ce
1, Ce
2, ..., Ce
Ne} be the restricted/excluded classes, where Ne refers to the number of
excluded classes. The remaining classes of the dataset are the remaining/non-excluded classes. Let
{Cne
1 , Cne
2 , ..., Cne
Nne} be the non-excluded classes, where Nne refers to the number of remaining/non-
excluded classes. Additionally, we only have access to a limited amount of training data for the
restricted classes and the remaining classes, for carrying out this process. Therefore, any approach
for addressing this problem can only utilize this limited training data."
PROBLEM SETTING,0.057971014492753624,Under review as a conference paper at ICLR 2022
PROBLEM SETTING,0.06280193236714976,"Figure 1: The RCRMR-LD
problem setting aims to re-
move the information regard-
ing
the
restricted/excluded
classes ({Ce
1, .., Ce
Ne}) from
all layers of a trained model
Mo while preserving its pre-
dictive power for the remain-
ing classes ({Cne
1 , .., Cne
Nne})
using limited training data.
The category removal (de-
noted by a red cross) has to
take place at the classiﬁer level
(denoted as squares for each
output logit) and at the fea-
ture/representation level (de-
noted as a circle)."
PROBLEM SETTING,0.06763285024154589,"Figure 2:
ERwP identiﬁes
those parameters in the model
that are highly relevant to
the restricted classes. To ob-
tain these parameters, ERwP
modiﬁes training images from
a restricted class using a
data augmentation f and per-
forms backpropagation using
the classiﬁcation loss on these
training images. ERwP then
studies the gradient update
that each parameter receives
in this process in order to iden-
tify the highly relevant param-
eters for the restricted classes
(denoted by dotted circles)."
PROBLEM SETTING,0.07246376811594203,"Figure 3: ERwP only optimizes the
restricted class relevant parameters
in the model (denoted by dotted cir-
cles). ERwP uses Le
c, Lne
c
and Lkd
losses to remove the restricted class
information from the model while
preserving its performance on the
remaining classes. Le
c and Lne
c
de-
note the classiﬁcation loss on the re-
stricted class training examples and
the remaining class training exam-
ple, respectively. Lkd denotes the
knowledge distillation-based regu-
larization loss that preserves the
logits corresponding to only the re-
maining classes for all the training
examples."
RCRMR-LD PROBLEM IN REAL WORLD SCENARIOS,0.07729468599033816,"3
RCRMR-LD PROBLEM IN REAL WORLD SCENARIOS"
RCRMR-LD PROBLEM IN REAL WORLD SCENARIOS,0.0821256038647343,"A real-world scenario where our proposed RCRMR-LD problem can arise is federated learn-
ing (McMahan et al., 2017). In the federated learning setting, there are multiple collaborators
that have a part of the training data stored locally, and a model is trained collaboratively using these
private data without sharing or collating the data due to privacy concerns. Suppose organization A
has a part of the training data, and there are other collaborators that have other parts of the training
data for the same classes. Organization A collaboratively trains a model with other collaborators
using federated learning. After the model has been trained, a few classes may become restricted in
the future due to some ethical or privacy concerns, and these classes should be removed from the
model. However, the other collaborators may not be available or may charge a huge amount of money
for collaborating again to train a fresh model from scratch. In this case, organization A does not
have access to the full training data of the non-excluded/remaining classes that it can use to re-train a
model from scratch in order to exclude the restricted classes information. This clearly shows that the
RCRMR-LD problem is possible in federated learning."
RCRMR-LD PROBLEM IN REAL WORLD SCENARIOS,0.08695652173913043,"Another real-world scenario is the incremental learning setting (Rebufﬁet al., 2017; Kemker & Kanan,
2018), where the model receives training data in the form of sequentially arriving tasks. Each task
contains a new set of classes. During a training session t, the model receives the task t for training
and cannot access the full data of the previous tasks. Instead, the model has access to very few
exemplars of the classes in the previous tasks. Suppose before training a model on training session t,
it is noticed that some classes from a previous task (< t) have to be removed from the model since
those classes have become restricted due to privacy or ethical concerns. In this case, only a limited
number of exemplars are available for all these previous classes (restricted and remaining). This
demonstrates that the RCRMR-LD problem is also possible in the incremental learning setting. We
experimentally demonstrate in Sec. 8.3, how our approach can address the RCRMR-LD problem in
the incremental learning setting."
RCRMR-LD PROBLEM IN REAL WORLD SCENARIOS,0.09178743961352658,Under review as a conference paper at ICLR 2022
PROPOSED METHOD,0.0966183574879227,"4
PROPOSED METHOD
Let, B refer to a mini-batch (of size S) from the available limited training data, and B contains
training datapoints from the restricted/excluded classes ({(xe
i, ye
i )|(xe
1, ye
1), ..., (xe
Se, ye
Se)}) and from
the remaining/non-excluded classes ({(xne
j , yne
j )|(xne
1 , yne
1 ), ..., (xne
Sne, yne
Sne)}). Here, (xe
i, ye
i ) refers
to a training datapoint from the excluded classes where xe
i is an image, ye
i is the corresponding label
and ye
i ∈{Ce
1, Ce
2, ..., Ce
Ne}. (xne
j , yne
j ) refers to a training datapoint from the non-excluded classes
where xne
j
is an image, yne
j
is the corresponding label and yne
j
∈{Cne
1 , Cne
2 , ..., Cne
Nne}. Here, Se and
Sne refer to the number of training examples in the mini-batch from the excluded and non-excluded
classes, respectively, such that S = Se + Sne. Ne and Nne refer to the number of excluded and
non-excluded classes, respectively. Let M refer to the deep learning model being trained using our
approach and Mo is the original trained deep learning model."
PROPOSED METHOD,0.10144927536231885,"In a trained model, some of the parameters may be highly relevant to the restricted classes, and
the performance of the model on the restricted classes is mainly dependent on such highly relevant
parameters. Therefore, in our approach, we focus on removing the excluded class information from
these restricted class relevant parameters. Since the model is trained on all the classes jointly, the
parameters are shared across the different classes. Therefore identifying these class-speciﬁc relevant
parameters is very difﬁcult. Let us consider a model that is trained on color images of a class. If we
now train it on grayscale images of the class, then the model has to learn to identify these new images.
In order to do so, the parameters relevant to that class will receive large gradient updates as compared
to the other parameters (see Sec. 9.1). We propose a novel approach for identifying the relevant
parameters for the restricted classes using this idea. For each restricted class, we choose the training
images belonging to that class from the limited available training data. Next, we apply a grayscale
data augmentation technique/transformation f to these images so that these images become different
from the images that the original model was earlier trained on (assuming that the original model has
not been trained on grayscale images). We can also use other data augmentation techniques that are
not seen during the training process of the original model and that do not change the class of the
image (refer to Sec. 11.7 in the appendix). Next, we combine the predictions for each training image
into a single average prediction and perform backpropagation. During the backpropagation, we study
the gradients for all the parameters in each layer of the model. Accordingly, we select the parameters
with the highest absolute gradient as the relevant parameters for the corresponding restricted class.
Speciﬁcally, for a given restricted class, we choose the minimum number of such parameters from
each network layer such that pruning these parameters will result in the maximum degradation of
model performance on that restricted class. We provide a detailed description of the process for
identifying the restricted class relevant parameters in Sec. 11.1 of the appendix. The combined set
of the relevant parameters for all the excluded classes is referred to as the restricted/excluded class
relevant parameters Θexrel (see Fig. 2). Please note that we use this process only to identify Θexrel,
and we do not update the model parameters during this step."
PROPOSED METHOD,0.10628019323671498,"Pruning the relevant parameters for a restricted class can severely impact the performance of the
model for that class (see Sec. 9.1). However, this may also degrade the performance of the model
on the non-excluded classes because the parameters are shared across multiple classes. Therefore,
we cannot address the RCRMR-LD problem by pruning the relevant parameters of the excluded
classes. Finetuning these parameters on the limited remaining class data will also not be able to
sufﬁciently remove the restricted class information from the model (see Sec. 11.10 in appendix).
Based on this, we propose to address the RCRMR-LD problem by optimizing the relevant parameters
of the restricted classes to remove the restricted class information from them and to reuse them for
the remaining classes."
PROPOSED METHOD,0.1111111111111111,"After identifying the restricted class relevant parameters, our ERwP approach uses a classiﬁcation
loss based on the cross-entropy loss function to optimize the restricted class relevant parameters of
the model on each mini-batch (see Fig. 3). We know that the gradient ascent optimization algorithm
can be used to maximize a loss function and encourage the model to perform badly on the given input.
Therefore, we use the gradient ascent optimization on the classiﬁcation loss for the limited restricted
class training examples to remove the information regarding the restricted classes from Θexrel. We
achieve this by multiplying the classiﬁcation loss for the augmented training examples from the
excluded classes by a constant negative factor of -1. We also optimize Θexrel using the gradient
descent optimization on the classiﬁcation loss for the limited remaining class training example, in
order to reuse these parameters for the remaining classes. We validate using this approach through
various ablation experiments as shown in Sec. 9.2. The classiﬁcation loss for the examples from the"
PROPOSED METHOD,0.11594202898550725,Under review as a conference paper at ICLR 2022
PROPOSED METHOD,0.12077294685990338,"excluded and non-excluded classes and the overall classiﬁcation loss for each mini-batch are deﬁned
as follows."
PROPOSED METHOD,0.12560386473429952,"Le
c = Se
X"
PROPOSED METHOD,0.13043478260869565,"i=1
−1 ∗ℓ(ye
i , ye∗
i )
(1)"
PROPOSED METHOD,0.13526570048309178,"Lne
c
= Sne
X"
PROPOSED METHOD,0.14009661835748793,"j=1
ℓ(yne
j , yne∗
j
)
(2)"
PROPOSED METHOD,0.14492753623188406,Lc = 1
PROPOSED METHOD,0.1497584541062802,"S (Le
c + Lne
c )
(3)"
PROPOSED METHOD,0.15458937198067632,"Where, ye∗
i
and yne∗
j
refer to the predicted class labels for xe
i and xne
j , respectively. ℓ(., .) refers
to the cross-entropy loss function. Le
c and Lne
c
refer to the classiﬁcation loss for the examples
from the excluded and non-excluded classes in the mini-batch, respectively. Lc refers to the overall
classiﬁcation loss for each mini-batch."
PROPOSED METHOD,0.15942028985507245,"Since all the network parameters were jointly trained on all the classes (restricted and remaining),
the restricted class relevant parameters also contain information relevant to the remaining classes.
Applying the above process alone will still harm the model’s predictive power for the non-excluded
classes (as shown in Sec. 9.2, Table 3). This is because the gradient ascent optimization strategy
will also erase some of the relevant information regarding the remaining classes. Further, applying
Lne
c
on the limited training examples of the remaining classes will lead to overﬁtting and will not
be effective enough to fully preserve the model performance on the remaining classes. In order to
ensure that the model’s predictive power for the non-excluded classes does not change, we use a
knowledge distillation-based regularization loss. Knowledge distillation (Hinton et al., 2014) ensures
that the predictive power of the teacher network is replicated in the student network. In this problem
setting, we want the ﬁnal model to replicate the same predictive power of the original model for the
remaining classes. Therefore, given any training example, we use the knowledge distillation-based
regularization loss to ensure that the output logits produced by the model corresponding to only
the non-excluded classes remain the same as that produced by the original model. We apply the
knowledge distillation loss to the limited training examples from both the excluded and remaining
classes, to preserve the non-excluded class logits of the model for any input image. We validate this
regularization loss through ablation experiments as shown in Table 3. We use the original model Mo
(before applying ERwP) as the teacher network and the current model M being processed by ERwP
as the student network, for the knowledge distillation process. Please note that the optimization for
this loss is also carried out only for the restricted class relevant parameters of the model. Let KD
refer to the knowledge distillation loss function. It computes the Kullback-Liebler (KL) divergence
between the soft predictions of the teacher and the student networks and can be deﬁned as follows:
KD(ps, pt) = KL(σ(ps), σ(pt))
(4)"
PROPOSED METHOD,0.1642512077294686,"where, σ(.) refers to the softmax activation function that converts logit ai for each class i into a
probability by comparing ai with logits of other classes aj, i.e., σ(ai) =
expai/κ
P"
PROPOSED METHOD,0.16908212560386474,j expaj /κ . κ refers to the
PROPOSED METHOD,0.17391304347826086,"temperature (Hinton et al., 2014), KL refers to the KL-Divergence function. ps, pt refer to the logits
produced by the student network and the teacher network, respectively."
PROPOSED METHOD,0.178743961352657,The knowledge distillation-based regularization losses in our approach are deﬁned as follows.
PROPOSED METHOD,0.18357487922705315,"Le
kd = Se
X"
PROPOSED METHOD,0.18840579710144928,"i=1
KD(M(xe
i)[Cne], Mo(xe
i)[Cne])
(5)"
PROPOSED METHOD,0.1932367149758454,"Lne
kd = Sne
X"
PROPOSED METHOD,0.19806763285024154,"j=1
KD(M(xne
j )[Cne], Mo(xne
j )[Cne])
(6)"
PROPOSED METHOD,0.2028985507246377,Lkd = 1
PROPOSED METHOD,0.20772946859903382,"S (Le
kd + Lne
kd)
(7)"
PROPOSED METHOD,0.21256038647342995,"Where, M(#)[Cne] and Mo(#)[Cne] refer to the output logits corresponding to the remaining
classes produced by M and Mo, respectively. # can be either xe
i or xne
j . Le
kd and Lne
kd refer to
knowledge distillation-based regularization loss for the examples from the excluded and non-excluded
classes, respectively. Lkd refers to the overall knowledge distillation-based regularization loss for
each mini-batch."
PROPOSED METHOD,0.21739130434782608,Under review as a conference paper at ICLR 2022
PROPOSED METHOD,0.2222222222222222,The total loss Lerwp of our approach for each mini-batch is deﬁned as follows.
PROPOSED METHOD,0.22705314009661837,"Lerwp = Lc + βLkd
(8)"
PROPOSED METHOD,0.2318840579710145,"Where, β is a hyper-parameter that controls the contribution of the knowledge distillation-based
regularization loss. We use this loss for ﬁne-tuning the model for very few epochs."
RELATED WORK,0.23671497584541062,"5
RELATED WORK"
RELATED WORK,0.24154589371980675,"Pruning involves removing redundant and unimportant weights (Carreira-Perpin´an & Idelbayev, 2018;
Dong et al., 2017; Guo et al., 2016; Han et al., 2015a;b; Tung & Mori, 2018; Zhang et al., 2018) or
ﬁlters (He et al., 2019a; 2018; 2019b;c; Li et al., 2016) from a deep learning model without affecting
the model performance. In contrast, our approach identiﬁes class-speciﬁc important parameters, and
therefore, the pruning techniques cannot be applied in our approach. In the incremental learning
setting (Douillard et al., 2020; Hou et al., 2019; Tao et al., 2020; Yu et al., 2020; Liu et al., 2021), the
objective is to preserve the predictive power of the model for previously seen classes while learning a
new set of classes. In contrast, our proposed RCRMR-LD problem setting involves removing the
information regarding speciﬁc classes from the pre-trained model while preserving the capacity of
the model to identify the remaining classes. Privacy-preserving deep learning (Nan & Tao, 2020;
Louizos et al., 2015; Edwards & Storkey, 2015; Hamm, 2017) involves learning representations that
incorporate features from the data relevant to the given task and ignore sensitive information (such as
the identity of a person). In contrast, the objective of the RCRMR-LD problem setting, is to achieve
class-level privacy, i.e., if a class is declared as private/restricted, then all information about this class
should be removed from the model trained on it, without affecting its ability to identify the remaining
classes. The authors in (Ginart et al., 2019) propose an approach to delete individual data points from
trained machine learning models like a clustering model. In contrast, RCRMR-LD involves removing
the information of a set of classes from all layers of a deep learning model. Therefore, the approach
proposed in (Ginart et al., 2019) cannot be applied to the RCRMR-LD problem setting."
BASELINES,0.2463768115942029,"6
BASELINES"
BASELINES,0.25120772946859904,"We propose 9 baseline models for the RCRMR-LD problem and compare our proposed approach
with them. The baseline 1 involves deleting the weights of the fully-connected classiﬁcation layer
corresponding to the excluded classes. Baselines 2, 3, 4, 5 involve training the model on the limited
training data of the remaining classes. Baselines 6, 7, 8, 9 involve ﬁne-tuning the model on the
available limited training data. Please refer to Sec. 11.2 in the appendix for details about the baselines."
PERFORMANCE METRICS,0.2560386473429952,"7
PERFORMANCE METRICS"
PERFORMANCE METRICS,0.2608695652173913,"In the RCRMR-LD problem setting, we propose three performance metrics to validate the per-
formance of any method: forgetting accuracy (FAe), forgetting prototype accuracy (FPAe), and
constraint accuracy (CAne). The forgetting accuracy refers to the fully-connected classiﬁcation layer
accuracy of the model for the excluded classes. The forgetting prototype accuracy refers to the nearest
class prototype-based classiﬁer accuracy of the model for the excluded classes. CAne refers to the
fully-connected classiﬁcation layer accuracy of the model for the non-excluded classes."
PERFORMANCE METRICS,0.26570048309178745,"In order to judge any approach on the basis of these metrics, we follow the following sequence. First,
we analyze the constraint accuracy (CAne) of the model produced by the given approach to verify if
the approach has preserved the prediction power of the model for the non-excluded classes. CAne
of the model should be close to that of the original model. If this condition is not satisﬁed, then
the approach is not suitable for this problem, and we need not analyze the other metrics. This is
because if the constraint accuracy is not maintained, then the overall usability of the model is hurt
signiﬁcantly. Next, we analyze the forgetting accuracy (FAe) of the model to verify if the excluded
class information has been removed from the model at the classiﬁer level. FAe of the model should
be as close to 0% as possible. Finally, we analyze the forgetting prototype accuracy (FPAe) of the
model to verify if the excluded class information has been removed from the model at the feature
level. FPAe of the model should be signiﬁcantly less than that of the original model. However, the
FPAe will not become zero since any trained model will learn to extract meaningful features, which
will help the nearest class prototype-based classiﬁer to achieve some non-negligible accuracy even
on the excluded classes. Therefore, for a better analysis of the level of forgetting of the excluded
classes at the feature level, we compare the FPAe of the model with the FPAe of the FDR model. The"
PERFORMANCE METRICS,0.27053140096618356,Under review as a conference paper at ICLR 2022
PERFORMANCE METRICS,0.2753623188405797,Table 1: Experimental results on the CIFAR-100 dataset for the RCRMR-LD problem.
PERFORMANCE METRICS,0.28019323671497587,"Methods
ResNet-20
ResNet-56
ResNet-164"
PERFORMANCE METRICS,0.28502415458937197,"FAe
FPAe
CAne
FAe
FPAe
CAne
FAe
FPAe
CAne
Original
70.15% 65.25% 67.06% 70.80% 68.65% 69.88% 79.00% 76.40% 76.30%"
PERFORMANCE METRICS,0.2898550724637681,"No Training
Baseline 1 - WD
0.00% 65.25% 69.88% 0.00% 68.65% 72.44% 0.00% 76.40% 77.01%"
PERFORMANCE METRICS,0.2946859903381642,"Full Train Schedule
Baseline 2 - TSLNRC
0.00% 22.20% 31.55% 0.00% 20.20% 30.21% 0.00% 33.05% 40.65%
Baseline 3 - TSLNRC-KD
0.00% 27.55% 40.81% 0.00% 22.50% 32.26% 0.00% 38.55% 45.74%
Baseline 4 - TOLNRC
0.00% 50.85% 58.01% 0.00% 48.60% 57.81% 0.00% 51.55% 62.78%
Baseline 5 - TOLNRC-KD
0.00% 60.25% 67.85% 0.00% 51.25% 61.14% 0.00% 52.80% 63.75%"
PERFORMANCE METRICS,0.2995169082125604,"Only Fine-Tuning
Baseline 6 - FOLMRCSC
24.25% 59.55% 64.03% 13.35% 60.25% 65.23% 15.40% 59.20% 71.06%
Baseline 7 - FOLMRCSC-KD 13.50% 58.80% 63.79% 12.75% 64.95% 63.41% 16.75% 65.30% 68.61%
Baseline 8 - FOLNRC
59.05% 64.30% 68.34% 66.90% 68.45% 70.11% 77.35% 75.85% 75.95%
Baseline 9 - FOLNRC-KD
57.99% 64.40% 68.40% 65.95% 68.40% 70.01% 73.30% 73.55% 75.99%
ERwP (Ours)
0.00% 48.06% 66.84% 0.00% 47.84% 69.32% 0.74% 56.23% 75.65%"
PERFORMANCE METRICS,0.30434782608695654,"FDR model is a good candidate for this analysis since it has not been trained on the excluded classes
(only trained on the complete dataset of the remaining classes), and it still achieves a non-negligible
performance of the excluded classes (see Sec 8.1). However, it should be noted that this comparison
is only for analysis and the comparison is not fair since the FDR model needs to train on the entire
dataset (except the excluded classes)."
EXPERIMENTS,0.30917874396135264,"8
EXPERIMENTS"
EXPERIMENTS,0.3140096618357488,"We have reported the experimental results for the CIFAR-100 and ImageNet-1k datasets in this
section. We have provided the results on the CUB-200 dataset in the appendix. Please refer to the
appendix for the details regarding the dataset and implementation."
EXPERIMENTS,0.3188405797101449,"8.1
CIFAR-100 RESULTS"
EXPERIMENTS,0.32367149758454106,"We report the performance of different baselines and our proposed ERwP method on the RCRMR-LD
problem using the CIFAR-100 dataset with different architectures in Table 1. We observe that the
baseline 1 (weight deletion) achieves high constraint accuracy CAne and 0% forgetting accuracy
FAe. But its forgetting prototype accuracy FPAe remains the same as the original model for all the
three architectures, i.e., ResNet-20/56/164. Therefore, baseline 1 fails to remove the excluded class
information from the model at the feature level. Baseline 2 is not able to preserve the constraint
accuracy CAne even though it performs full training on the limited excluded class data. Baseline 3
achieves higher CAne than baseline 2, but the constraint accuracy is still too low. Baselines 4 and
5 demonstrate signiﬁcantly better constraint accuracy than baseline 2 and 3, but their constraint
accuracy is still signiﬁcantly lower than the original model (except baseline 5 for ResNet-20). The
baseline 5 with ResNet-20 maintains the constraint accuracy and achieves 0% forgetting accuracy
FAe but its FPAe is still signiﬁcantly high and, therefore, is unable to remove the excluded class
information from the model at the feature level. The ﬁne-tuning based baselines 6 and 7 are able to
signiﬁcantly reduce the forgetting accuracy FAe but their constraint accuracy CAne drops signiﬁcantly.
The ﬁne-tuning based baselines 8 and 9 only ﬁnetune the model on the limited remaining class data
and as a result they are not able to sufﬁciently reduce either the forgetting accuracy FAe or the
forgetting prototype accuracy FPAe."
EXPERIMENTS,0.3285024154589372,"Our proposed ERwP approach achieves a constraint accuracy CAne that is very close to the original
model for all three architectures. It achieves close to 0% FAe. Further, it achieves a signiﬁcantly lower
FPAe than the original model. Speciﬁcally, the FPAe of our approach is signiﬁcantly lower than that
of the original model by absolute margins of 17.19%, 20.81%, and 20.17% for the ResNet-20, ResNet-
56, and ResNet-164 architectures, respectively. The FPAe for the FDR model is 44.20%, 45.40%
and 51.85% for the ResNet-20, ResNet-56 and ResNet-164 architectures, respectively. Therefore,
the FPAe of our approach is close to that of the FDR model by absolute margins of 3.86%, 2.44%
and 4.38% for the ResNet-20, ResNet-56 and ResNet-164 architectures, respectively. Therefore,
our ERwP approach makes the model behave similar to the FDR model even though it was trained
on only limited data from the excluded and remaining classes. Further, our ERwP requires only 10
epochs to remove the excluded class information from the model. Since the available limited training"
EXPERIMENTS,0.3333333333333333,Under review as a conference paper at ICLR 2022
EXPERIMENTS,0.33816425120772947,Table 2: Experimental results on ImageNet-1k.
EXPERIMENTS,0.34299516908212563,"Model
Methods
Top-1
Top-5"
EXPERIMENTS,0.34782608695652173,"FAe
CAne
FAe
CAne"
EXPERIMENTS,0.3526570048309179,"Res-18
Original 69.76% 69.76% 89.58% 89.02%
ERwP
0.28%
69.13%
1.01%
88.93%"
EXPERIMENTS,0.357487922705314,"Res-50
Original 76.30% 76.11% 93.04% 92.84%
ERwP
0.25%
75.45%
2.55%
92.39%"
EXPERIMENTS,0.36231884057971014,"Mob-V2 Original 72.38% 70.83% 91.28% 90.18%
ERwP
0.17%
70.81%
0.81%
89.95%"
EXPERIMENTS,0.3671497584541063,Table 3: Signiﬁcance of ERwP components.
EXPERIMENTS,0.3719806763285024,"Le
c
Lne
c
Lkd
FAe
FPAe
CAne



66.50%
68.19%
69.79%



0.00%
24.40%
6.45%



0.00%
47.84%
69.32%"
EXPERIMENTS,0.37681159420289856,"Figure 4: Ablation to validate our approach for
identifying relevant model parameters for a ran-
dom restricted class of CIFAR-100."
EXPERIMENTS,0.38164251207729466,Table 4: Performance of ERwP in the incremental learning setting using ResNet-18.
EXPERIMENTS,0.3864734299516908,"Model
FAe
CAne
Original Model obtained after Session 4 [M4]
56.39%
58.32%
M4 modiﬁed with ERwP (Ours)
0.20%
59.93%"
EXPERIMENTS,0.391304347826087,"data is only 10% of the entire CIFAR-100 dataset, therefore, our ERwP approach is approximately
30 ∗10 = 300× faster than the FDR method that is trained on the full training data for 300 epochs."
IMAGENET RESULTS,0.3961352657004831,"8.2
IMAGENET RESULTS"
IMAGENET RESULTS,0.40096618357487923,"Table 2 reports the experimental results for different approaches to RCRMR-LD problem over the
ImageNet-1k dataset using the ResNet-18, ResNet-50 and MobileNet V2 architectures. Our proposed
ERwP approach achieves a top-1 constraint accuracy CAne that is very close to that of the original
model by absolute margins of 0.63%, 0.66% and 0.02% for the ResNet-18, ResNet-50 and MobileNet
V2 architectures, respectively. It achieves close to 0% top-1 forgetting accuracy FAe for all the three
architectures. Therefore, our approach performs well even on the large-scale ImageNet-1k dataset.
Further, our ERwP requires only 10 epochs to remove the excluded class information from the model.
Since the available limited training data is only 5% of the entire CIFAR-100 dataset, therefore, our
ERwP approach is approximately 20 ∗10 = 200× faster than the FDR method that is trained on the
full data for 100 epochs."
RCRMR-LD PROBLEM IN INCREMENTAL LEARNING,0.4057971014492754,"8.3
RCRMR-LD PROBLEM IN INCREMENTAL LEARNING"
RCRMR-LD PROBLEM IN INCREMENTAL LEARNING,0.4106280193236715,"In this section, we experimentally demonstrate how the RCRMR-LD problem in the incremental
learning setting is addressed using our proposed approach. We consider an incremental learning
setting on the CIFAR-100 dataset in which each task contains 20 classes. We use the BIC (Wu et al.,
2019) method for incremental learning on this dataset. The exemplar memory size is ﬁxed at 2000 as
per the setting in (Wu et al., 2019). In this setting, there are 5 tasks. Let us assume that the model
(M4) has already been trained on 4 tasks (80 classes), and we are in the ﬁfth training session. Suppose,
at this stage, it is noticed that all the classes in the ﬁrst task (20 classes) have become restricted and
need to be removed before the model is trained on task 5. However, we only have a limited number
of exemplars of the 80 classes seen till now, i.e., 2000/80 = 25 per class. We apply our proposed
approach to the model obtained after training session 4, and the results are reported in Table 4. The
results indicate that our approach modiﬁed the model obtained after session 4, such that the forgetting
accuracy of the restricted classes approaches 0% and the constraint accuracy of the remaining classes
is not affected. In fact, the modiﬁed model behaves as if, it was never trained on the classes from task
1. We can now perform the incremental training of the modiﬁed model on task 5."
ABLATION STUDIES,0.41545893719806765,"9
ABLATION STUDIES"
RESTRICTED CLASS RELEVANT PARAMETERS,0.42028985507246375,"9.1
RESTRICTED CLASS RELEVANT PARAMETERS"
RESTRICTED CLASS RELEVANT PARAMETERS,0.4251207729468599,"We perform ablation experiments to verify our approach of identifying the highly relevant parameters
for any restricted class. We perform these experiments on the CIFAR-100 dataset with the ResNet-56
architecture and report the forgetting accuracy FAe for the randomly chosen excluded class. Please
note that in this case, only the chosen class of CIFAR-100 is the restricted class and all the remaining"
RESTRICTED CLASS RELEVANT PARAMETERS,0.42995169082125606,Under review as a conference paper at ICLR 2022
RESTRICTED CLASS RELEVANT PARAMETERS,0.43478260869565216,"Table 5: Experimental results on the CIFAR-100
dataset using ResNet-56 for ERwP with different
number of excluded classes. # R/E →no. of non-
excluded classes / no. of excluded classes"
RESTRICTED CLASS RELEVANT PARAMETERS,0.4396135265700483,"# R/E Methods
ResNet-20
ResNet-56"
RESTRICTED CLASS RELEVANT PARAMETERS,0.4444444444444444,"FAe
CAne
FAe
CAne"
RESTRICTED CLASS RELEVANT PARAMETERS,0.4492753623188406,"60/40 Original 68.18% 67.35% 69.98% 70.11%
ERwP
0.00% 67.03% 0.00% 69.98%"
RESTRICTED CLASS RELEVANT PARAMETERS,0.45410628019323673,"70/30 Original 67.83% 67.61% 69.60% 70.26%
ERwP
0.00% 67.25% 0.00% 69.81%"
RESTRICTED CLASS RELEVANT PARAMETERS,0.45893719806763283,"80/20 Original 70.15% 67.06% 70.80% 69.88%
ERwP
0.00% 66.85% 0.00% 69.26%"
RESTRICTED CLASS RELEVANT PARAMETERS,0.463768115942029,"90/10 Original 67.90% 67.66% 68.40% 70.24%
ERwP
0.00% 67.26% 0.00% 69.69%"
RESTRICTED CLASS RELEVANT PARAMETERS,0.46859903381642515,"95/5 Original 66.20% 67.76% 67.00% 70.22%
ERwP
0.00% 67.55% 0.00% 69.63%"
RESTRICTED CLASS RELEVANT PARAMETERS,0.47342995169082125,"Figure 5: Plot denoting the performance of our
proposed ERwP during the optimization process."
RESTRICTED CLASS RELEVANT PARAMETERS,0.4782608695652174,"classes constitute the non-excluded classes. In order to show the effectiveness of our approach, we
sort the absolute gradients of the parameters in the model (obtained through backpropagation for the
excluded class augmented images) and choose a set of high relevance and low relevance parameters.
We then prune/zero out these parameters and record the forgetting accuracy. Fig. 4 demonstrates that
as we zero out the high relevance parameters, the forgetting accuracy of the excluded class drops by a
huge margin. It also shows that as we zero out the low relevance parameters, there is only a minor
change in the forgetting accuracy of the excluded class. This validates our approach for identifying
the high relevant parameters for the restricted classes."
SIGNIFICANCE OF THE COMPONENTS OF THE PROPOSED ERWP APPROACH,0.4830917874396135,"9.2
SIGNIFICANCE OF THE COMPONENTS OF THE PROPOSED ERWP APPROACH"
SIGNIFICANCE OF THE COMPONENTS OF THE PROPOSED ERWP APPROACH,0.48792270531400966,"We perform ablations on the CIFAR-100 dataset using the ResNet-56 model to study the signiﬁcance
of the Le
c, Lne
c
and Lkd components of our proposed ERwP approach. Table 3 indicates that
optimizing the restricted class relevant parameters using only Lne
c
cannot signiﬁcantly remove
the information regarding the restricted classes from the model. Applying Lne
c
along with Le
c
signiﬁcantly reduces the forgetting accuracy FAe and forgetting prototype accuracy FPAe but also
signiﬁcantly reduces the constraint accuracy CAne. Finally, applying the Lkd loss along with Lne
c
and
Le
c signiﬁcantly reduces FAe and FPAe while maintaining the constraint accuracy CAne very close to
that of the original model."
ABLATION ON THE NUMBER OF EXCLUDED CLASSES,0.4927536231884058,"9.3
ABLATION ON THE NUMBER OF EXCLUDED CLASSES"
ABLATION ON THE NUMBER OF EXCLUDED CLASSES,0.4975845410628019,"We report the experimental results for our approach for different splits of excluded and remaining
classes of the CIFAR-100 dataset in Table 5. We observe that our ERwP performs well for all the
splits for both the ResNet-20 and ResNet-56 architectures."
PERFORMANCE OF ERWP OVER TRAINING EPOCHS,0.5024154589371981,"9.4
PERFORMANCE OF ERWP OVER TRAINING EPOCHS"
PERFORMANCE OF ERWP OVER TRAINING EPOCHS,0.5072463768115942,"We analyze the change in the performance of the model after every epoch of our proposed ERwP
approach in Fig. 5. We observe that as the training progresses the constraint accuracy is maintained
close to that of the original model, the forgetting accuracy keeps dropping till it reaches 0% and the
forgetting prototype accuracy keeps falling and comes closer to that of the FDR model."
CONCLUSION,0.5120772946859904,"10
CONCLUSION"
CONCLUSION,0.5169082125603864,"In this paper, we present a “Restricted Category Removal from Model Representations with Lim-
ited Data” problem in which the objective is to remove the information regarding a set of ex-
cluded/restricted classes from a trained deep learning model without hurting its predictive power for
the remaining classes. We propose several baseline approaches and also the performance metrics
for this setting. First, we propose a novel approach to identify the model parameters that are highly
relevant to the restricted classes. Next, we propose a novel efﬁcient approach that optimizes these
model parameters in order to remove the restricted class information and re-use these parameters for
the remaining classes. We experimentally show how our approach signiﬁcantly outperforms all the
proposed baselines and performs similar to the full data retraining model."
CONCLUSION,0.5217391304347826,Under review as a conference paper at ICLR 2022
REFERENCES,0.5265700483091788,REFERENCES
REFERENCES,0.5314009661835749,"Miguel A Carreira-Perpin´an and Yerlan Idelbayev. “learning-compression” algorithms for neural net
pruning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp.
8532–8541, 2018."
REFERENCES,0.5362318840579711,"Xin Dong, Shangyu Chen, and Sinno Jialin Pan. Learning to prune deep neural networks via
layer-wise optimal brain surgeon. In Proceedings of the 31st International Conference on Neural
Information Processing Systems, NIPS’17, pp. 4860–4874, Red Hook, NY, USA, 2017. Curran
Associates Inc. ISBN 9781510860964."
REFERENCES,0.5410628019323671,"Arthur Douillard, Matthieu Cord, Charles Ollion, Thomas Robert, and Eduardo Valle. Podnet: Pooled
outputs distillation for small-tasks incremental learning. In ECCV, 2020."
REFERENCES,0.5458937198067633,"Harrison Edwards and Amos Storkey. Censoring representations with an adversary. arXiv preprint
arXiv:1511.05897, 2015."
REFERENCES,0.5507246376811594,"Antonio Ginart, Melody Y Guan, Gregory Valiant, and James Zou. Making ai forget you: Data
deletion in machine learning. arXiv preprint arXiv:1907.05012, 2019."
REFERENCES,0.5555555555555556,"Yiwen Guo, Anbang Yao, and Yurong Chen. Dynamic network surgery for efﬁcient dnns. Advances
in Neural Information Processing Systems, 29:1379–1387, 2016."
REFERENCES,0.5603864734299517,"Jihun Hamm. Minimax ﬁlter: Learning to preserve privacy from inference attacks. The Journal of
Machine Learning Research, 18(1):4704–4734, 2017."
REFERENCES,0.5652173913043478,"Song Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks
with pruning, trained quantization and huffman coding. arXiv preprint arXiv:1510.00149, 2015a."
REFERENCES,0.5700483091787439,"Song Han, Jeff Pool, John Tran, and William Dally. Learning both weights and connections for
efﬁcient neural network. Advances in Neural Information Processing Systems, 28, 2015b."
REFERENCES,0.5748792270531401,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
pp. 770–778, 2016."
REFERENCES,0.5797101449275363,"Y He, G Kang, X Dong, Y Fu, and Y Yang. Soft ﬁlter pruning for accelerating deep convolutional
neural networks. In IJCAI International Joint Conference on Artiﬁcial Intelligence, 2018."
REFERENCES,0.5845410628019324,"Yang He, Xuanyi Dong, Guoliang Kang, Yanwei Fu, Chenggang Yan, and Yi Yang. Asymptotic soft
ﬁlter pruning for deep convolutional neural networks. IEEE transactions on cybernetics, 50(8):
3594–3604, 2019a."
REFERENCES,0.5893719806763285,"Yang He, Ping Liu, Ziwei Wang, Zhilan Hu, and Yi Yang. Filter pruning via geometric median for
deep convolutional neural networks acceleration. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, pp. 4340–4349, 2019b."
REFERENCES,0.5942028985507246,"Yang He, Ping Liu, Linchao Zhu, and Yi Yang. Meta ﬁlter pruning to accelerate deep convolutional
neural networks. arXiv preprint arXiv:1904.03961, 2019c."
REFERENCES,0.5990338164251208,"Geoffrey Hinton,
Oriol Vinyals,
and Jeffrey Dean.
Distilling the knowledge in a
neural network.
In NIPS Deep Learning and Representation Learning Workshop,
2014.
URL https://fb56552f-a-62cb3a1a-s-sites.googlegroups.com/
site/deeplearningworkshopnips2014/65.pdf."
REFERENCES,0.6038647342995169,"Saihui Hou, Xinyu Pan, Chen Change Loy, Zilei Wang, and Dahua Lin. Learning a uniﬁed classiﬁer
incrementally via rebalancing. In CVPR, pp. 831–839, 2019."
REFERENCES,0.6086956521739131,"Ronald Kemker and Christopher Kanan. Fearnet: Brain-inspired model for incremental learning. In
International Conference on Learning Representations, 2018. URL https://openreview.
net/forum?id=SJ1Xmf-Rb."
REFERENCES,0.6135265700483091,"Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009."
REFERENCES,0.6183574879227053,Under review as a conference paper at ICLR 2022
REFERENCES,0.6231884057971014,"Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter Graf. Pruning ﬁlters for
efﬁcient convnets. arXiv preprint arXiv:1608.08710, 2016."
REFERENCES,0.6280193236714976,"Yaoyao Liu, Bernt Schiele, and Qianru Sun. Adaptive aggregation networks for class-incremental
learning. In The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),
2021."
REFERENCES,0.6328502415458938,"Christos Louizos, Kevin Swersky, Yujia Li, Max Welling, and Richard Zemel. The variational fair
autoencoder. arXiv preprint arXiv:1511.00830, 2015."
REFERENCES,0.6376811594202898,"Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-Efﬁcient Learning of Deep Networks from Decentralized Data. In Aarti Singh
and Jerry Zhu (eds.), Proceedings of the 20th International Conference on Artiﬁcial Intelligence
and Statistics, volume 54 of Proceedings of Machine Learning Research, pp. 1273–1282. PMLR,
20–22 Apr 2017. URL https://proceedings.mlr.press/v54/mcmahan17a.html."
REFERENCES,0.642512077294686,"Lihao Nan and Dacheng Tao. Variational approach for privacy funnel optimization on continuous
data. Journal of Parallel and Distributed Computing, 137:17–25, 2020."
REFERENCES,0.6473429951690821,"Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito,
Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in
pytorch, 2017."
REFERENCES,0.6521739130434783,"Sylvestre-Alvise Rebufﬁ, Alexander Kolesnikov, Georg Sperl, and Christoph H Lampert. icarl:
Incremental classiﬁer and representation learning. In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition, pp. 2001–2010, 2017."
REFERENCES,0.6570048309178744,"Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang,
Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual recognition
challenge. International journal of computer vision, 115(3):211–252, 2015."
REFERENCES,0.6618357487922706,"Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh,
and Dhruv Batra. Grad-cam: Visual explanations from deep networks via gradient-based local-
ization. In Proceedings of the IEEE International Conference on Computer Vision, pp. 618–626,
2017."
REFERENCES,0.6666666666666666,"Xiaoyu Tao, Xinyuan Chang, Xiaopeng Hong, Xing Wei, and Yihong Gong. Topology-preserving
class-incremental learning. In ECCV, 2020."
REFERENCES,0.6714975845410628,"Frederick Tung and Greg Mori. Clip-q: Deep network compression learning by in-parallel pruning-
quantization. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pp. 7873–7882, 2018."
REFERENCES,0.6763285024154589,"Catherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge Belongie. The caltech-ucsd
birds-200-2011 dataset, 2011."
REFERENCES,0.6811594202898551,"Yue Wu, Yinpeng Chen, Lijuan Wang, Yuancheng Ye, Zicheng Liu, Yandong Guo, and Yun Fu. Large
scale incremental learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, pp. 374–382, 2019."
REFERENCES,0.6859903381642513,"Lu Yu, Bartlomiej Twardowski, Xialei Liu, Luis Herranz, Kai Wang, Yongmei Cheng, Shangling Jui,
and Joost van de Weijer. Semantic drift compensation for class-incremental learning. In CVPR, pp.
6982–6991, 2020."
REFERENCES,0.6908212560386473,"Tianyun Zhang, Shaokai Ye, Kaiqi Zhang, Jian Tang, Wujie Wen, Makan Fardad, and Yanzhi Wang.
A systematic dnn weight pruning framework using alternating direction method of multipliers. In
Proceedings of the European Conference on Computer Vision (ECCV), pp. 184–199, 2018."
REFERENCES,0.6956521739130435,Under review as a conference paper at ICLR 2022
APPENDIX,0.7004830917874396,"11
APPENDIX"
PROCESS FOR SELECTING THE RESTRICTED CLASS RELEVANT PARAMETERS,0.7053140096618358,"11.1
PROCESS FOR SELECTING THE RESTRICTED CLASS RELEVANT PARAMETERS"
PROCESS FOR SELECTING THE RESTRICTED CLASS RELEVANT PARAMETERS,0.7101449275362319,"First, we apply a data augmentation technique f, not used during training, to the images of the given
restricted class. Next, we combine the predictions for these images and perform backpropagation.
Finally, we select the parameters with the highest absolute gradient as the relevant parameters for
the corresponding restricted class. Speciﬁcally, for a given restricted class, we choose the minimum
number of such parameters from each network layer such that pruning these parameters will result in
the maximum degradation of model performance on that restricted class. We use a process similar to
the binary search for automatically selecting the parameters with the highest absolute gradient. We
use an automated script that ﬁrst creates a list of parameters in each layer, sorts them in descending
order according to the gradient values, and checks if zeroing out the weights of the ﬁrst 5% parameters
from this list leads to near zero accuracy for that class. If not, then we select double the number
of parameters chosen earlier and repeat this process. If the accuracy is near zero, we repeat the
process with half the number of parameters chosen earlier. Please note, this process is just for
identifying the parameters relevant to the restricted classes, and their weights are restored after this
process. The combined set of the relevant parameters for all the excluded classes is referred to as the
restricted/excluded class relevant parameters."
BASELINES,0.714975845410628,"11.2
BASELINES"
BASELINES,0.7198067632850241,"We propose several baseline models for the RCRMR-LD problem and compare our proposed approach
with them. The baseline approaches are deﬁned as follows:"
BASELINES,0.7246376811594203,"Original model: It refers to the original model that is trained on the complete training set containing
all the training examples from both the excluded and non-excluded classes. It represents the model
that has not been modiﬁed by any technique to remove the excluded class information."
BASELINES,0.7294685990338164,"Baseline 1 - Weight Deletion (WD): It refers to the original model with a modiﬁed fully-connected
classiﬁcation layer. Speciﬁcally, we remove the weights corresponding to the excluded classes in the
fully-connected classiﬁcation layer so that it cannot classify the excluded classes."
BASELINES,0.7342995169082126,"Baseline 2 - Training from Scratch on Limited Non-Restricted Class data (TSLNRC): In this
baseline, we train a new model from scratch using the limited training examples of only the non-
excluded classes. It uses the complete training schedule as the original model and only uses the
classiﬁcation loss for training the model."
BASELINES,0.7391304347826086,"Baseline 3 - Training from Scratch on Limited Non-Restricted Class data with KD (TSLNRC-
KD): This baseline is the same as baseline 2, but in addition to the classiﬁcation loss, it also uses a
knowledge distillation loss to ensure that the non-excluded class logits of the model (student) match
that of the original model (teacher)."
BASELINES,0.7439613526570048,"Baseline 4 - Training of Original model on Limited Non-Restricted Class data (TOLNRC):
This baseline is the same as baseline 2, but the model is initialized with the weights of the original
model instead of randomly initializing it."
BASELINES,0.748792270531401,"Baseline 5 - Training of Original model on Limited Non-Restricted Class data with KD
(TOLNRC-KD): This baseline is the same as baseline 4, but in addition to the classiﬁcation loss, it
also uses a knowledge distillation loss."
BASELINES,0.7536231884057971,"Baseline 6 - Fine-tuning of Original model on Limited data after Mapping Restricted Classes
to a Single Class (FOLMRCSC): In this baseline approach, we ﬁrst replace all the excluded class
labels in the limited training data with a new single excluded class label and then ﬁne-tune the original
model for a few epochs on the limited training data of both the excluded and remaining classes. In
the case of the examples from the excluded classes, the model is trained to predict the new single
excluded class. In the case of the examples from the remaining classes, the model is trained to predict
the corresponding non-excluded classes."
BASELINES,0.7584541062801933,"Baseline 7 - Fine-tuning of Original model on Limited data after Mapping Restricted Classes
to a Single Class with KD (FOLMRCSC-KD): This baseline is the same as baseline 6, but in"
BASELINES,0.7632850241545893,Under review as a conference paper at ICLR 2022
BASELINES,0.7681159420289855,"addition to the classiﬁcation loss, it also uses a knowledge distillation loss to ensure that the non-
excluded class logits of the model (student) match that of the original model (teacher)."
BASELINES,0.7729468599033816,"Baseline 8 - Fine-tuning of Original model on Limited Non-Restricted Class data (FOLNRC):
In this baseline approach, we ﬁne-tune the original model for a few epochs on the limited training
data of non-excluded/remaining classes. The model is trained to predict the corresponding excluded
classes of the training examples."
BASELINES,0.7777777777777778,"Baseline 9 - Fine-tuning of Original model on Limited Non-Restricted Class data with KD
(FOLNRC-KD): This baseline is the same as baseline 8, but in addition to the classiﬁcation loss, it
also uses a knowledge distillation loss."
DATASETS,0.782608695652174,"11.3
DATASETS"
DATASETS,0.7874396135265701,"For the RCRMR-LD problem setting, we modify the CIFAR-100 (Krizhevsky et al., 2009), CUB (Wah
et al., 2011) and ImageNet-1k (Russakovsky et al., 2015) datasets. In order to simulate the RCRMR-
LD problem setting with limited training data, we choose the last 20 classes of the CIFAR-100 dataset
as the excluded classes and take only 10% of the training images of each class. Similarly, we choose
the last 20 classes of the CUB dataset as the excluded classes with only 3 training images per class.
For ImageNet-1K, we choose the last 100 classes as the excluded classes with 5% of the training
images to simulate the limited data available for this problem setting."
IMPLEMENTATION DETAILS,0.7922705314009661,"11.4
IMPLEMENTATION DETAILS"
IMPLEMENTATION DETAILS,0.7971014492753623,"In this section, we provide all the details required to reproduce our experimental results. We use
the ResNet-20 (He et al., 2016), ResNet-56, ResNet-164 architectures for the experiments on the
CIFAR-100 dataset. We use the standard data augmentation methods of random cropping to a size
of 32 × 32 (zero-padded on each side with four pixels before taking a random crop) and random
horizontal ﬂipping, which is a standard practice for training a model on CIFAR-100. In order to
obtain the original and FDR models for the CIFAR-100 dataset, we train the network for 300 epochs
with a mini-batch size of 128 using the stochastic gradient descent optimizer with momentum 0.9 and
weight decay 1e −4. We choose the initial learning rate as 0.1, and we decrease it by a factor of 5
after every 50 epochs. For the CIFAR-100 experiments with ERwP using the ResNet-20, ResNet-56,
and ResNet-164 architectures, we take learning rate= 1e −4, β = 10 and optimize the network for
10 epochs. Since the available limited training data is only 10% of the entire CIFAR-100 dataset,
therefore, our ERwP approach is approximately 30 ∗10 = 300× faster than the FDR method."
IMPLEMENTATION DETAILS,0.8019323671497585,"For the experiments on the ImageNet dataset, we use the ResNet-18, ResNet-50, and MobileNet-V2
architectures. We use the standard data augmentation methods of random cropping to a size of
224 × 224 and random horizontal ﬂipping, which is a standard practice for training a model on
ImageNet-1k. In order to obtain the original and FDR models for the ImageNet dataset, we train the
network for 100 epochs with a mini-batch size of 256 using the stochastic gradient descent optimizer
with momentum 0.9 and weight decay 1e −4. We choose the initial learning rate as 0.1, and we
decrease it by a factor of 10 after every 30 epochs. For evaluation, the validation images are subjected
to center cropping of size 224 × 224. For the ImageNet-1k experiments (5% training data) with
ERwP using the ResNet-50 architecture, we optimize the network for 10 epochs with a learning
rate of 9e −5 using β = 200. For the ERwP experiments using the ResNet-18 architecture, we
optimize the network for 10 epochs using β = 200 with an initial learning rate of 1.1e −4 and a
learning rate of 1.1e −5 from the third epoch onward. In the case of the ERwP experiments with the
MobileNet-V2 architecture, we optimize the network for 10 epochs using β = 400 with an initial
learning rate of 1.5e −4 and a learning rate of 1.5e −5 from the third epoch onward. Since the
available limited training data is only 5% of the entire ImageNet-1k dataset, therefore, our ERwP
approach is approximately 20 ∗10 = 200× faster than the FDR method. For the experiments on the
CUB-200 dataset, we use the ResNet-50 architecture pre-trained on the ImageNet dataset. In order to
obtain the original and FDR models for the CUB-200 dataset, we train the network for 50 epochs
with a mini-batch size of 64 using the stochastic gradient descent optimizer with momentum 0.9 and
weight decay 1e −3. We choose the initial learning rate as 1e −2, and we decrease it by a factor
of 10 after epochs 30 and 40. For the CUB-200 experiments (3 images per class, i.e., 10% training
data) with ERwP using the ResNet-50 architecture, we optimize the network for 10 epochs with a
learning rate of 1e −4 using β = 10. Since the available limited training data is only 10% of the"
IMPLEMENTATION DETAILS,0.8067632850241546,Under review as a conference paper at ICLR 2022
IMPLEMENTATION DETAILS,0.8115942028985508,"Table 6: Experimental results on the CUB dataset with ResNet-50 architecture for the RCRMR-LD
problem with 20 excluded classes using only 3 training images per class."
IMPLEMENTATION DETAILS,0.8164251207729468,"Methods
FAe
FPAe
CAne
Original
85.20% 84.69% 77.37%"
IMPLEMENTATION DETAILS,0.821256038647343,"No Training
Baseline 1 - WD
0.00% 85.71% 77.64%"
IMPLEMENTATION DETAILS,0.8260869565217391,"Full Train Schedule
Baseline 2 - TSLNRC
0.00% 30.27% 27.56%
Baseline 3 - TSLNRC-KD
0.00% 35.54% 31.66%
Baseline 4 - TOLNRC
0.00% 60.37% 64.60%
Baseline 5 - TOLNRC-KD
0.00% 68.37% 70.48%"
IMPLEMENTATION DETAILS,0.8309178743961353,"Only Fine-Tuning
Baseline 6 - FOLMRCSC
53.40% 77.38% 74.39%
Baseline 7 - FOLMRCSC-KD 60.88% 81.12% 75.14%
Baseline 8 - FOLNRC
84.86% 84.18% 76.85%
Baseline 9 - FOLNRC-KD
84.35% 85.20% 77.70%
ERwP (Ours)
0.77% 48.89% 75.45%"
IMPLEMENTATION DETAILS,0.8357487922705314,"entire CUB-200 dataset, therefore, our ERwP approach is approximately 5 ∗10 = 50× faster than
the FDR method."
IMPLEMENTATION DETAILS,0.8405797101449275,"In our proposed approach, we use κ = 2 for all the experiments. We use a popular Pytorch
implementation1 for performing knowledge distillation. We run all the experiments 3 times (using
different random seeds) and report the average accuracy. We perform all the experiments using the
Pytorch framework version 1.6.0 (Paszke et al., 2017) and Python 3.0. We use 4 GeForce GTX 1080
Ti graphics processing units for our experiments."
IMPLEMENTATION DETAILS,0.8454106280193237,"11.5
RCRMR-LD PROBLEM IN CUB-200 CLASSIFICATION"
IMPLEMENTATION DETAILS,0.8502415458937198,"Table 6 reports the experimental results for different approaches to the RCRMR-LD problem over the
CUB dataset using the ResNet-50 architecture. Our proposed ERwP approach achieves a constraint
accuracy CAne that is very close to that of the original model even though we use only 3 images
per class for optimizing the model. It achieves close to 0% forgetting accuracy FAe and achieves
a FPAe that is signiﬁcantly lower than that of the original model by an absolute margin of 35.80%.
Similar to the CIFAR-100 experiments, our ERwP approach outperforms all the baseline approaches.
Further, our ERwP requires only 10 epochs to remove the excluded class information from the model.
Since the available limited training data is only 10% of the entire CUB dataset, therefore, our ERwP
approach is approximately 5 ∗10 = 50× faster than the FDR method that is trained on the full
training data for 50 epochs."
IMPLEMENTATION DETAILS,0.855072463768116,"11.6
ABLATION EXPERIMENTS FOR β AND κ"
IMPLEMENTATION DETAILS,0.8599033816425121,"We perform ablation experiments to identify the most suitable values for the hyper-parameters β and
κ for our proposed ERwP. The ablation results in Tables 7, 8, validate our choice of hyper-parameter
values considering the forgetting accuracy and the constraint accuracy of the resulting model."
"EFFECT OF DIFFERENT DATA AUGMENTATIONS ON THE IDENTIFICATION OF CLASS
RELEVANT MODEL PARAMETERS",0.8647342995169082,"11.7
EFFECT OF DIFFERENT DATA AUGMENTATIONS ON THE IDENTIFICATION OF CLASS
RELEVANT MODEL PARAMETERS"
"EFFECT OF DIFFERENT DATA AUGMENTATIONS ON THE IDENTIFICATION OF CLASS
RELEVANT MODEL PARAMETERS",0.8695652173913043,"We perform experiments to verify our approach of identifying the highly relevant parameters for any
restricted class using various augmentation techniques (grayscale, vertical ﬂip, rotation, random afﬁne
augmentations). We chose the same restricted class of CIFAR-100 and used the ResNet-56 network
for all the experiments. The results in Fig. 6 indicate that for all the compared data augmentations
approaches, pruning/zeroing out the high relevance parameters obtained using our approach, results"
"EFFECT OF DIFFERENT DATA AUGMENTATIONS ON THE IDENTIFICATION OF CLASS
RELEVANT MODEL PARAMETERS",0.8743961352657005,1https://github.com/peterliht/knowledge-distillation-pytorch/blob/master/model/net.py
"EFFECT OF DIFFERENT DATA AUGMENTATIONS ON THE IDENTIFICATION OF CLASS
RELEVANT MODEL PARAMETERS",0.8792270531400966,Under review as a conference paper at ICLR 2022
"EFFECT OF DIFFERENT DATA AUGMENTATIONS ON THE IDENTIFICATION OF CLASS
RELEVANT MODEL PARAMETERS",0.8840579710144928,"Table 7: Experimental results on the CIFAR-
100 dataset with ResNet-20 architecture for the
RCRMR-LD problem with 20 excluded classes
using our proposed ERwP with different values
of β."
"EFFECT OF DIFFERENT DATA AUGMENTATIONS ON THE IDENTIFICATION OF CLASS
RELEVANT MODEL PARAMETERS",0.8888888888888888,"β
Methods
FAe
CAne
-
Original
70.15%
67.06%"
ERWP,0.893719806763285,"8
ERwP
0.00%
66.03%
9
ERwP
0.00%
66.23%
10
ERwP
0.00%
66.79%
11
ERwP
0.00%
66.58%
12
ERwP
0.00%
66.15%"
ERWP,0.8985507246376812,"Table 8: Experimental results on the CIFAR-
100 dataset with ResNet-20 architecture for the
RCRMR-LD problem with 20 excluded classes
using our proposed ERwP with different values
of κ."
ERWP,0.9033816425120773,"κ
Methods
FAe
CAne
-
Original
70.15%
67.06%"
ERWP,0.9082125603864735,"1.0
ERwP
0.00%
66.05%
1.5
ERwP
0.00%
66.08%
2.0
ERwP
0.00%
66.79%
2.5
ERwP
0.00%
66.30%
3.0
ERwP
0.00%
66.23%"
ERWP,0.9130434782608695,"Figure 6: Ablation to validate our approach for identifying restricted class relevant model parameters
using different augmentation techniques w.r.t. the same randomly chosen restricted class of CIFAR-
100. We use the ResNet-56 network for these experiments. The data augmentation techniques used
are (a) grayscale augmentation, (b) vertical ﬂip augmentation, (c) rotation augmentation, (d) random
afﬁne augmentation. In each case, the ﬁgure shows the model performance when the low relevance
and high relevance parameters obtained using our approach are zeroed out."
ERWP,0.9178743961352657,"in a huge drop in the forgetting accuracy of the excluded class. Further, zeroing out the low relevance
parameters, has a minor impact on the forgetting accuracy of the excluded class."
ABLATION EXPERIMENTS ON THE RESTRICTED CLASS RELEVANT PARAMETERS,0.9227053140096618,"11.8
ABLATION EXPERIMENTS ON THE RESTRICTED CLASS RELEVANT PARAMETERS"
ABLATION EXPERIMENTS ON THE RESTRICTED CLASS RELEVANT PARAMETERS,0.927536231884058,"We perform ablation experiments with ERwP to check if only 25% and 50% of the restricted class
relevant parameters of each layer identiﬁed using our proposed procedure can be used for ERwP. We
run each of these experiments for the same number of epochs for the CIFAR-100 dataset and ResNet-
56 network. However, we observed that the ﬁnal FPAe falls from 68.65% to 60.35% and 53.7%,
respectively, for 25% and 50% of restricted class relevant parameters of each layer as compared to
47.84% when using all the restricted class relevant parameters per layer identiﬁed using our approach.
The good performance of our approach is more evident in light of the performance of the FDR model
that achieves a FPAe accuracy of 45.40%. We provide this result as a reference to demonstrate
that the 47.84% FPAe accuracy is due to the generalization power of the model and not due to the
restricted classes information in the model. This shows that our approach effectively identiﬁes the
class-relevant parameters of the model for a given class."
PERFORMANCE OF ERWP OVER TRAINING EPOCHS,0.9323671497584541,"11.9
PERFORMANCE OF ERWP OVER TRAINING EPOCHS"
PERFORMANCE OF ERWP OVER TRAINING EPOCHS,0.9371980676328503,"We analyze the change in the performance of the model after every epoch of our proposed ERwP
approach in Fig. 7 for the CIFAR-100 dataset with 20 excluded classes using the ResNet-20 and
ResNet-56 architectures. For both architectures, we observe that as the training progresses, ERwP
maintains the constraint accuracy close to that of the original model and forces the forgetting accuracy
to drop to 0%. ERwP also forces the forgetting prototype accuracy to keep dropping and makes it
similar to the FDR model."
PERFORMANCE OF ERWP OVER TRAINING EPOCHS,0.9420289855072463,Under review as a conference paper at ICLR 2022
PERFORMANCE OF ERWP OVER TRAINING EPOCHS,0.9468599033816425,"(a)
(b)"
PERFORMANCE OF ERWP OVER TRAINING EPOCHS,0.9516908212560387,"Figure 7: Plots denoting the performance of our proposed ERwP during the optimization process for
forgetting 20 excluded classes from CIFAR-100 using a) ResNet-20 and b) ResNet-56 architectures."
PERFORMANCE OF ERWP OVER TRAINING EPOCHS,0.9565217391304348,"Figure 8: Class activation maps of ImageNet images from the excluded and non-excluded classes, for
the original ResNet-50 (second row) and ResNet-50 after applying our proposed ERwP approach
(third row). First row depicts the real images."
FINETUNING RESTRICTED CLASS RELEVANT PARAMETERS ON REMAINING CLASSES,0.961352657004831,"11.10
FINETUNING RESTRICTED CLASS RELEVANT PARAMETERS ON REMAINING CLASSES"
FINETUNING RESTRICTED CLASS RELEVANT PARAMETERS ON REMAINING CLASSES,0.966183574879227,"In our experimental results, we demonstrated how ﬁnetuning the model on the limited training data of
the non-excluded classes cannot sufﬁciently remove the excluded class information from the model.
We also perform an ablation experiment to demonstrate that ﬁnetuning only the restricted class
relevant parameters using the limited training data of the non-excluded classes is also not effective in
sufﬁciently removing the excluded class information from the model. We perform these experiments
on the CIFAR-100 dataset with the ResNet-56 architecture. We observe the constraint accuracy CAne,
forgetting accuracy FAe and the forgetting prototype accuracy FAe are almost the same even in this
case. Therefore, ﬁnetuning only on the remaining class data cannot sufﬁciently remove the excluded
class information from the model representations."
"EFFECT OF USING THE PROPOSED ERWP APPROACH WHEN THE ENTIRE DATASET IS
AVAILABLE",0.9710144927536232,"11.11
EFFECT OF USING THE PROPOSED ERWP APPROACH WHEN THE ENTIRE DATASET IS
AVAILABLE"
"EFFECT OF USING THE PROPOSED ERWP APPROACH WHEN THE ENTIRE DATASET IS
AVAILABLE",0.9758454106280193,"We perform ablation experiments to demonstrate the performance of our proposed ERwP approach
when the entire training data is available. We perform these experiments on the CIFAR-100 dataset
using ResNet-20 and ResNet-56. We observe experimentally that for both the ResNet-20 and ResNet-"
"EFFECT OF USING THE PROPOSED ERWP APPROACH WHEN THE ENTIRE DATASET IS
AVAILABLE",0.9806763285024155,Under review as a conference paper at ICLR 2022
"EFFECT OF USING THE PROPOSED ERWP APPROACH WHEN THE ENTIRE DATASET IS
AVAILABLE",0.9855072463768116,"56 experiments using ERwP, the forgetting accuracy FAe accuracy is 0% and the constraint accuracy
CAne matches that of the original model. Further, the gap between the forgetting prototype accuracy
FPAe of ERwP and the FDR model reduces from 3.86% (for limited data) to 2.79% for ResNet-20.
Similarly, the gap reduces from 2.44% (for limited data) to 1.65% for ResNet-56. However, ERwP
requires only 2-3 epochs of optimization (∼100-150× faster than the FDR model) for achieving this
performance when trained on the entire dataset. This makes it signiﬁcantly faster than any approach
that trains on the entire dataset."
QUALITATIVE ANALYSIS,0.9903381642512077,"11.12
QUALITATIVE ANALYSIS"
QUALITATIVE ANALYSIS,0.9951690821256038,"In order to analyze the effect of removing the excluded class information from the model using our
proposed ERwP approach, we study the class activation map visualizations (Selvaraju et al., 2017) of
the model before and after applying ERwP. We observe in Fig. 8 that for the images from the excluded
classes, the model’s region of attention gets scattered after applying ERwP, unlike the images from
the remaining classes."
