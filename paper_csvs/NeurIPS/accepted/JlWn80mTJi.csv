Section,Section Appearance Order,Paragraph
UNIVERSITY OF MICHIGAN,0.0,"1University of Michigan
2Technion - Israel Institute of Technology
3Illinois Institute of Technology
{hrithikr, clayscot}@umich.edu
daniel.soudry@gmail.com
ywang562@iit.edu"
ABSTRACT,0.0013869625520110957,Abstract
ABSTRACT,0.0027739251040221915,"Implicit bias describes the phenomenon where optimization-based training algo-
rithms, without explicit regularization, show a preference for simple estimators
even when more complex estimators have equal objective values. Multiple works
have developed the theory of implicit bias for binary classification under the as-
sumption that the loss satisfies an exponential tail property. However, there is
a noticeable gap in analysis for multiclass classification, with only a handful of
results which themselves are restricted to the cross-entropy loss. In this work,
we employ the framework of Permutation Equivariant and Relative Margin-based
(PERM) losses [Wang and Scott, 2024] to introduce a multiclass extension of
the exponential tail property. This class of losses includes not only cross-entropy
but also other losses. Using this framework, we extend the implicit bias result of
Soudry et al. [2018] to multiclass classification. Furthermore, our proof techniques
closely mirror those of the binary case, thus illustrating the power of the PERM
framework for bridging the binary-multiclass gap."
INTRODUCTION,0.004160887656033287,"1
Introduction"
INTRODUCTION,0.005547850208044383,"Overparameterized models such as neural networks have shown state-of-the-art performance in many
applications, despite having the potential to overfit. Zhang et al. [2021] demonstrate that this potential
is indeed realizable by training real-world models to fit random noise. In recent years, there have
been several research efforts that aim to understand the impressive performance of overparametrized
models despite this ability to overfit. Both the model architecture and the training algorithms for
selecting the weights have been investigated in this regard."
INTRODUCTION,0.006934812760055479,"Work on implicit bias [Soudry et al., 2018, Ji et al., 2020, Vardi, 2022] has focused on the latter factor.
Implicit bias is the hypothesis that gradient-based methods have a built-in preference for models
with low-complexity. This hypothesis is perhaps best understood in the setting of (unregularized)
empirical risk minimization for learning a linear model under the assumption of linearly separable
data. Soudry et al. [2018] showed that in binary classification, implicit bias holds when the loss has
the exponential tail property [Soudry et al., 2018, Theorem 3]. The same work also demonstrated
implicit bias in the multiclass setting for the cross-entropy loss, but implicit bias for a more broadly
defined class of losses in the multiclass case is left open. In this work, we extend the notion of the
exponential tail property to multiclass losses and prove that the property is sufficient for implicit
bias to occur in the multiclass setting. Toward this end, we employ the framework of permutation
equivariant and relative margin-based (PERM) losses [Wang and Scott, 2024]."
CONTRIBUTIONS,0.008321775312066574,"1.1
Contributions"
CONTRIBUTIONS,0.009708737864077669,"Multiclass extension of the exponential tail property (Definition 2.2)
It is unclear how the
exponential tail property for binary margin losses should be extended to the multiclass setting. By
using the PERM framework, we provide a multiclass extension that generalizes the exponential tail
property to multiclass (Definition 2.2 in Section 2.3). We further verify that this property holds for
some common losses."
CONTRIBUTIONS,0.011095700416088766,"Sufficiency of the exponential tail property for implicit bias (Theorem 3.4)
We prove that the
proposed multiclass exponential tail property is sufficient for implicit bias. More precisely, we show
in Theorem 3.4 that for almost all linearly separable multiclass datasets, given a convex, (β-smooth,
strictly decreasing) PERM loss satisfying the exponential tail property in Definition 2.2, gradient
descent exhibits directional convergence to the hard-margin multiclass SVM."
RELATED WORK,0.012482662968099861,"1.2
Related Work"
RELATED WORK,0.013869625520110958,"Soudry et al. [2018] show that gradient descent, applied to unregularized empirical risk minimization,
converges to the hard-margin SVM solution at a slow logarithmic rate, provided the loss satisfies
the exponential tail property (defined below). Nacson et al. [2019] improve the convergence rate
using a specific step-size schedule. Ji and Telgarsky [2019] extend implicit bias to the setting of
quasi-complete separation [Candès and Sur, 2020], where the two classes are linearly separated but
with a margin of zero. Many works have also considered gradient-based methods beyond gradient
descent. For example, Gunasekar et al. [2018] examine the implicit bias effects of mirror descent
[Beck and Teboulle, 2003], steepest descent [Boyd and Vandenberghe, 2004], and adaptive gradient
descent [Duchi et al., 2011, Kingma and Ba, 2015]. Cotter et al. [2012], Clarkson et al. [2012], Ji
et al. [2021] study first order methods that are designed specifically to approach the hard-margin
SVM as quickly as possible."
RELATED WORK,0.015256588072122053,"Results for the multiclass setting are more scarce, and are always specific to cross-entropy. Soudry
et al. [2018] establish implicit bias for cross-entropy loss. Lyu and Li [2019] focus on homogeneous
predictors and prove convergence of GD on cross-entropy loss to a KKT point of the margin-
maximization problem. Lyu and Li [2019] proves convergence of gradient flow to a generalized max-
margin classifier for multiclass classification with cross-entropy loss using homogeneous models.1 In
the special case when the model are linear classifiers, the generalized max-margin classifier reduces
to the classical hard-margin SVM. Lyu et al. [2021] consider two-layer neural networks and prove
convergence of GD on cross-entropy loss to the max-margin solution under an additional assumption
on the data, that both x and its negative counterpart −x must belong to the dataset. Wang et al.
[2023] prove that in certain overparameterized regimes, gradient descent on squared loss leads to an
equivalent solution to gradient descent on cross-entropy loss."
RELATED WORK,0.016643550624133148,"Beyond work establishing (rate of) convergence to the max-margin classifier, there is also a separate
line of work [Shamir, 2021, Schliserman and Koren, 2022, 2023] focusing on the generalization
aspect of implicit bias. These works examine the binary classification setting, with the exception of
Schliserman and Koren [2022] who consider cross-entropy."
NOTATIONS,0.018030513176144243,"1.3
Notations"
NOTATIONS,0.019417475728155338,"Let K ≥2 and d ≥1 denote the number of classes and feature space dimension, respectively. Let
[K] := {1, 2, . . . , K}. Vectors are denoted by boldface lowercase letters, e.g., v ∈RK whose
entries are denoted by vj for j ∈[K]. Likewise, matrices are denoted by boldface uppercase letters,
e.g., W ∈Rd×K. The columns of W are denoted w1, . . . , wK. By 0n and 1n we denote the
n-dimensional vectors of all 0’s and all 1’s respectively. The n × n identity matrix is denoted by In."
NOTATIONS,0.020804438280166437,"By ∥v∥we denote the Euclidean norm of vector v. ∥A∥2 is the spectral norm of matrix A. Given
two vectors w, v ∈Rk, we write w ⪰v (resp. w ≻v) if wj ≥vj (resp. wj > vj) for all j ∈[k];
similarly we write w ⪯v (resp. w ≺v) if wj ≤vj (resp. wj < vj) for all j ∈[k]. On the other"
NOTATIONS,0.022191400832177532,"1Lyu and Li [2019] could be thought of as analyzing losses beyond CE, but the optimization problem
would be non-convex so convergence might not be to a global minimum. See Appendix A for a more detailed
discussion."
NOTATIONS,0.023578363384188627,"hand, if A and B are equally-sized symmetric matrices, then by A ⪰B (resp. A ⪯B) we mean
that A −B (resp. B −A) is positive semi-definite, i.e. A −B ⪰0 (resp. B −A ⪰0)."
NOTATIONS,0.024965325936199722,"A bijection from [k] to itself is called a permutation on [k]. Denote by Sym(k) the set of all
permutations on [k]. For each σ ∈Sym(k), let Sσ denote the permutation matrix corresponding to σ.
In other words, if v ∈Rk is a vector, then [Sσv]j = vσ(j)."
MULTICLASS LOSS FUNCTIONS,0.026352288488210817,"2
Multiclass Loss Functions"
MULTICLASS LOSS FUNCTIONS,0.027739251040221916,"In multiclass classification, a classifier is typically represented in terms of a class-score function
f = (f1, . . . , fK) : Rd →RK, which maps an input x ∈Rd to a vector v := f(x) of class scores.
For instance, f may be a feed-forward neural network and v in this context is sometimes referred to
as the logits. The label set is [K], and a label is predicted as argmaxjfj(x). A K-ary multiclass loss
function is a vector-valued function L = (L1, . . . , LK) : RK →RK where Ly(f(x)) is the loss
incurred for outputting f(x) when the ground truth label is y."
MULTICLASS LOSS FUNCTIONS,0.02912621359223301,"In binary classification, a classifier is typically represented using a function g : Rd →R. The label
set is {−1, 1}, and labels are predicted as x 7→sign(g(x)). A binary margin loss is a function of
the form ψ : R →R where ψ(yg(x)) is the loss incurred for outputting g(x) when the ground truth
label is y. Margin losses have been central to the development of the theory of binary classification,
and the lack of a multiclass counterpart to binary margin losses may have impaired the development
of corresponding theory for multiclass classification. To address this issue, Wang and Scott [2024]
introduce PERM losses as a bridge between binary and multiclass classification."
MULTICLASS LOSS FUNCTIONS,0.030513176144244106,"2.1
Permutation equivariant and relative margin-based (PERM) losses"
MULTICLASS LOSS FUNCTIONS,0.0319001386962552,"Assume the label set is [K]. Define 2 the matrix D := [−IK−1
1K−1] ∈R(K−1)×K. Observe that
Dv = (vK −v1, vK −v2, . . . , vK −vK−1)⊤for all v ∈RK.
Definition 2.1 (PERM loss [Wang and Scott, 2024]). Let K ≥2 be an integer, and L be a K-ary
multiclass loss function. We say that L is"
MULTICLASS LOSS FUNCTIONS,0.033287101248266296,"1. permutation equivariant if L(Sσv) = SσL(v) for all v ∈RK and σ ∈Sym(K),"
MULTICLASS LOSS FUNCTIONS,0.03467406380027739,"2. relative margin-based if for each y ∈[K] there exists a function ℓy : RK−1 →R so that
Ly(v) = ℓy(Dv) = ℓy(vK −v1, vK −v2, . . . , vK −vK−1), for all v ∈RK. We refer to
the vector-valued function ℓ:= (ℓ1, . . . , ℓK) as the reduced form of L."
MULTICLASS LOSS FUNCTIONS,0.036061026352288486,"3. PERM if L is both permutation equivariant and relative margin-based. In this case, the
function ψ := ℓK is referred to as the template of L."
MULTICLASS LOSS FUNCTIONS,0.03744798890429958,"Wang and Scott [2024] show that PERM losses are characterized by their template ψ. To show this,
they introduce the matrix label code, an encoding of labels as matrices. Thus, for each y ∈[K −1],
let Υy be the (K −1) × (K −1) identity matrix, but with the y-th column replaced by all −1’s.
For y = K, let Υy be the identity matrix. Note that when K = 2, this definition reduces to
Υy = (−1)y, the standard encoding of labels in the binary setting. Observe that (after permutation)
ΥyDv = (vy −v1, vy −v2, . . . , vy −vK)⊤∈RK−1, where the vy −vy = 0 entry is omitted. Please
see Wang and Scott [2024, Lemma B.2] for a simple proof."
MULTICLASS LOSS FUNCTIONS,0.038834951456310676,"Theorem 2.1 (Wang and Scott [2024]). Let L : RK →RK be a PERM loss with template ψ, and let
v ∈RK and y ∈[K] be arbitrary. Then ψ is a symmetric function. Moreover,"
MULTICLASS LOSS FUNCTIONS,0.04022191400832178,"Ly (v) = ψ (ΥyDv) .
(1)"
MULTICLASS LOSS FUNCTIONS,0.04160887656033287,"Conversely, let ψ : RK−1 →R be a symmetric function. Define a multiclass loss function L =
(L1, . . . , Lk) : RK →RK according to Eqn. (1). Then L is a PERM loss with template ψ."
MULTICLASS LOSS FUNCTIONS,0.04299583911234397,"Theorem 2.1 shows that a PERM loss is characterized by its template ψ. The right hand side of
Eqn. (1) is referred to as the relative margin form of the loss, which extends binary margin losses to
multiclass. As noted by Wang and Scott [2024], an advantage of the relative margin form is that it"
MULTICLASS LOSS FUNCTIONS,0.044382801664355064,"2Also see [Wang and Scott, 2024, Definition 2]."
MULTICLASS LOSS FUNCTIONS,0.04576976421636616,"Figure 1: An illustration of the exponential tail property for the cross entropy/multinomial logistic
loss when K = 3. Panel a. Plot of ψ(u) = log(1 + exp(−u1) + exp(−u2)), the template for the
multinomial logistic loss. Note that the complement of the positive orthant in the domain R2 is shown
in gray. Panel b. and c. Plot of the upper bound (shown in black) and lower bounds (red) of −∂ψ"
MULTICLASS LOSS FUNCTIONS,0.047156726768377254,"∂u1
(blue) respectively. These bounds are from Appendix C.1.3 where u± = 0 and c = 1. Note that the
lower bound is valid in the positive orthant, i.e., the red surface is below the blue one there."
MULTICLASS LOSS FUNCTIONS,0.04854368932038835,"decouples the labels from the predicted scores, which facilitates analysis. Our results below support
this understanding."
MULTICLASS LOSS FUNCTIONS,0.049930651872399444,"Many losses in the literature are PERM losses, including the cross-entropy loss whose template
is ψ(u) = log(1 + PK−1
i=1 exp(−ui)), the multiclass exponential loss [Mukherjee and Schapire,
2013] whose template is ψ(u) = PK−1
i=1 exp(−ui), and the PairLogLoss [Wang et al., 2022] whose
template is = ψ(u) = PK−1
i=1 log(1 + exp(−ui)). See Wang and Scott [2024] for other examples."
REGULARITY ASSUMPTIONS ON LOSS FUNCTIONS,0.05131761442441054,"2.2
Regularity assumptions on loss functions"
REGULARITY ASSUMPTIONS ON LOSS FUNCTIONS,0.052704576976421634,Let L be a PERM loss with differentiable template ψ. If
REGULARITY ASSUMPTIONS ON LOSS FUNCTIONS,0.05409153952843273,"∂ψ
∂ui
(u) < 0,
for all i ∈{1, 2 . . . , K −1}, u ∈RK−1,"
REGULARITY ASSUMPTIONS ON LOSS FUNCTIONS,0.05547850208044383,"i.e., the gradient of the template is entrywise strictly negative, then we say that the PERM loss L
is strictly decreasing. In this case, we write ∇ψ ≺0, where 0 is the 0-vector. If the template is
differentiable, then it is convex if:"
REGULARITY ASSUMPTIONS ON LOSS FUNCTIONS,0.056865464632454926,"ψ(u1) ≥ψ(u2) + ∇ψ(u2)⊤(u1 −u2),
for all u1, u2 ∈RK−1."
REGULARITY ASSUMPTIONS ON LOSS FUNCTIONS,0.05825242718446602,"If ψ is twice-differentiable, this is equivalent to saying that the Hessian is positive-semidefinite:"
REGULARITY ASSUMPTIONS ON LOSS FUNCTIONS,0.059639389736477116,"∇2ψ (u) ⪰0
for all u ∈RK−1."
REGULARITY ASSUMPTIONS ON LOSS FUNCTIONS,0.06102635228848821,"Finally, the template is said to be β-smooth if its gradient is β-Lipschitz:"
REGULARITY ASSUMPTIONS ON LOSS FUNCTIONS,0.06241331484049931,"∥∇ψ (u1) −∇ψ (u2) ∥≤β∥u1 −u2∥,
for all u1, u2 ∈RK−1."
REGULARITY ASSUMPTIONS ON LOSS FUNCTIONS,0.0638002773925104,"If ψ is twice-differentiable, this is equivalent to saying that the maximum eigenvalue of its Hessian is
bounded by β:"
REGULARITY ASSUMPTIONS ON LOSS FUNCTIONS,0.0651872399445215,"∥∇2ψ (u) ∥2 ≤β
for all u ∈RK−1,"
REGULARITY ASSUMPTIONS ON LOSS FUNCTIONS,0.06657420249653259,where ∥A∥2 is the spectral norm of matrix A.
MULTICLASS ANALOGUE OF EXPONENTIAL TAIL PROPERTY,0.06796116504854369,"2.3
Multiclass analogue of exponential tail property"
MULTICLASS ANALOGUE OF EXPONENTIAL TAIL PROPERTY,0.06934812760055478,"In the binary setting, the exponential tail property defined in prior work (Soudry et al. [2018], Nacson
et al. [2019], Ji et al. [2020]) is assumed to hold for the negative derivative of the loss. Similarly, in
the multiclass setting we are interested in bounding the negative gradient of the PERM loss template."
MULTICLASS ANALOGUE OF EXPONENTIAL TAIL PROPERTY,0.07073509015256588,"Definition 2.2 (Multiclass exponential tail property). A multiclass PERM loss with template ψ :
RK−1 →R has the exponential tail (ET) property if there exist u+, u−∈R and positive c > 0 such"
MULTICLASS ANALOGUE OF EXPONENTIAL TAIL PROPERTY,0.07212205270457697,that for all i ∈[K −1] the following holds:
MULTICLASS ANALOGUE OF EXPONENTIAL TAIL PROPERTY,0.07350901525658807,"∀u s.t.
min
j∈[K−1] uj > u+, we have −∂ψ"
MULTICLASS ANALOGUE OF EXPONENTIAL TAIL PROPERTY,0.07489597780859916,"∂ui
(u) ≤c exp(−ui),
and"
MULTICLASS ANALOGUE OF EXPONENTIAL TAIL PROPERTY,0.07628294036061026,"∀u s.t.
min
j∈[K−1] uj > u−, we have −∂ψ"
MULTICLASS ANALOGUE OF EXPONENTIAL TAIL PROPERTY,0.07766990291262135,"∂ui
(u) ≥c "
MULTICLASS ANALOGUE OF EXPONENTIAL TAIL PROPERTY,0.07905686546463246,"1 −
X"
MULTICLASS ANALOGUE OF EXPONENTIAL TAIL PROPERTY,0.08044382801664356,"j∈[K−1]
exp (−uj) "
MULTICLASS ANALOGUE OF EXPONENTIAL TAIL PROPERTY,0.08183079056865465,exp(−ui).
MULTICLASS ANALOGUE OF EXPONENTIAL TAIL PROPERTY,0.08321775312066575,"Remark 2.2. We show in Appendix C that cross-entropy (CE), multiclass exponential loss, and
PairLogLoss all have this property."
MAIN RESULT,0.08460471567267684,"3
Main Result"
MAIN RESULT,0.08599167822468794,"Consider a dataset {(xn, yn)}N
n=1, with xn ∈Rd and class labels yn ∈[K] := {1, . . . , K}. The
class score function for class k is fk(x) = wT
k x. Define X ∈Rd×N to be the matrix whose nth
column is xn. Define W ∈Rd×K to be the matrix whose kth column is wk. The learning objective
is"
MAIN RESULT,0.08737864077669903,"R (W) = N
X"
MAIN RESULT,0.08876560332871013,"n=1
Lyn
 
W⊤xn

.
(2)"
MAIN RESULT,0.09015256588072122,"From Eqn. 1, if L is a PERM loss, then Ly (v) = ψ (ΥyDv), and the learning objective becomes"
MAIN RESULT,0.09153952843273232,"R(W) = N
X"
MAIN RESULT,0.09292649098474341,"i=1
ψ
 
ΥyiDW⊤xi

.
(3)"
MAIN RESULT,0.09431345353675451,"Up to permuting the entries, ΥyiDW⊤xi is equal to the (K −1)-dimensional vector of relative-
margins

(wyi −w1)⊤xi, (wyi −w2)⊤xi, . . . , (wyi −wK)⊤xi
⊤, where the 0-valued entry
(wyi −wyi)⊤xi is omitted. This follows from Wang and Scott [2024, Lemma B.2]."
MAIN RESULT,0.0957004160887656,"We are now ready to state our assumptions on the loss:
Assumption 3.1. The PERM loss’s template ψ is convex, β-smooth, strictly decreasing and non-
negative. 3 4"
MAIN RESULT,0.0970873786407767,Assumption 3.2. The PERM loss has exponential tail as defined in Definition 2.2.
MAIN RESULT,0.09847434119278779,"To optimize Eqn. (2) we employ gradient descent with fixed learning rate η. Define w := vec(W)
where vec denotes vectorization by column-stacking (See Definition B.1), and let the gradient descent
iterate at time t be w (t). Then:"
MAIN RESULT,0.09986130374479889,w (t + 1) = w (t) −η∇R (w(t)) .
MAIN RESULT,0.10124826629680998,"Define the “matrix-version” of the trajectory W(t) ∈Rd×K such that w(t) = vec(W(t)). Through-
out this work, we frequently work with the risk as a matrix-input scalar-output function R(W), and
as a vector-input scalar-output function R(w)."
MAIN RESULT,0.10263522884882108,"These two formulations will each be useful in different situations. For instances, adopting the matrix
perspective can facilitate calculation of bounds, e.g., in Section 4.2. On the other hand, the vectorized
formulation is easier for defining the Hessian of the risk ∇2R(w). See Appendix B for detail."
MAIN RESULT,0.10402219140083217,"We focus on linearly separable datasets:
Assumption 3.3. The dataset is linearly separable, i.e. there exists w ∈RdK such that ∀n ∈
[N], ∀k ∈[K]\{yn} : w⊤
ynxn ≥w⊤
k xn + 1. Equivalently, there exists W ∈Rd×K such that
∀n ∈[N], ΥynDW⊤xn ⪰1."
MAIN RESULT,0.10540915395284327,"3We note that in the binary case the implicit bias result in [Soudry et al., 2018, Theorem 3] does not require
the loss to be convex. Closing this binary-multiclass gap is an open question.
4Note that multiclass exponential loss ψ (u) does not have a global smoothness constant. However, we show
in Appendix C.2.2 that any learning rate η < 1/
 
B2R (w(0))

is sufficient for the gradient descent iterates to
achieve local smoothness, where B =
p"
MAIN RESULT,0.10679611650485436,"(2K −2) PN
i=1 ∥xi∥."
MAIN RESULT,0.10818307905686546,"Finally, let ˆw be the multiclass hard-margin SVM solution for the linearly separable dataset:"
MAIN RESULT,0.10957004160887657,"ˆw = argminw
1
2∥w∥2 s.t. ∀n, ∀k ̸= yn : w⊤
ynxn ≥w⊤
k xn + 1.
(4)"
MAIN RESULT,0.11095700416088766,"Now we state the main result of the paper:
Theorem 3.4. For any PERM loss satisfying Assumptions 3.1 and 3.2, for all linearly separable
datasets such that Assumption 4.1 holds, any sufficiently small learning rate 0 < η < 2β−1σ−2
max (X),
and any initialization w(0), the iterates of gradient descent will behave as
w(t) = ˆw log(t) + ρ(t)
where the norm of the residual, ∥ρ(t)∥, is bounded. This implies a directional convergence behavior:"
MAIN RESULT,0.11234396671289876,"lim
t→∞
w (t)
∥w (t)∥=
ˆw
∥ˆw∥."
MAIN RESULT,0.11373092926490985,"In Appendix I, we show experimental results demonstrating implicit bias towards the hard margin
SVM when using the PairLogLoss, in line with Theorem 3.4."
PROOF SKETCH,0.11511789181692095,"4
Proof Sketch"
PROOF SKETCH,0.11650485436893204,"In this section we will overview the proof of the result. Along the way, we prove lemmas that extend
to the multiclass setting results from Soudry et al. [2018]. The extensions are facilitated by the PERM
framework, in particular the relative margin from of the loss."
PROOF SKETCH,0.11789181692094314,"We adopt the notation of Soudry et al. [2018] where possible throughout this proof. Recalling
the notation and definitions from the paper: let us define the standard basis ek ∈RK such that
(ek)i = δki (where δ is the Kronecker-delta function), and the d-dimension identity matrix Id. Define
Ak ∈RdK×d as the Kronecker product between ek and Id, i.e. Ak = ek ⊗Id. We can then relate
the original kth-class predictor wk to the long column-vector w as follows: A⊤
k w = wk. Next
define ˜xn,k := (Ayn −Ak)xn. Using this notation, the multiclass SVM becomes"
PROOF SKETCH,0.11927877947295423,"argminw
1
2∥w∥2
s.t.
∀n, ∀k ̸= yn : w⊤˜xn,k ≥1
(5)"
PROOF SKETCH,0.12066574202496533,"For each k ∈[K], define Sk = arg minn( ˆwyn −ˆwk)⊤xn = {n : ( ˆwyn −ˆwk)⊤xn = 1}, i.e., the
kth class support vectors. From the KKT optimality conditions for Eqn. (5), we have for some dual
variables αn,k > 0 that ˆw = N
X n=1 K
X"
PROOF SKETCH,0.12205270457697642,"k=1
αn,k˜xn,k1n∈Sk.
(6)"
PROOF SKETCH,0.12343966712898752,"Finally, define
r (t) = w (t) −log (t) ˆw −˜w
(7)
where ˜w is a solution to
∀k ∈[K], ∀n ∈Sk : η exp
 
−x⊤
n ( ˜wyn −˜wk)

= αn,k.
(8)
In Soudry et al. [2018], the existence of ˜w is proven for the binary case for almost all datasets, and
assumed in the multiclass case. Here, we also state the existence of ˜w as an additional assumption:
Assumption 4.1. Eqn. 8 has a solution, denoted ˜w."
PROOF SKETCH,0.12482662968099861,"We pose the problem of proving Assumption 4.1 for almost all datasets as a conjecture in Appendix H,
where we also show experimentally that on a large number (100 instances for each choice of
d ∈{2, 3, 4, 5, 6} and K ∈{3, 4, 5, 6}) of synthetically generated linearly separable datasets,
Assumption 4.1 indeed holds."
PROOF SKETCH,0.1262135922330097,"Note that r(t) = ρ(t) −˜w, and ˜w is independent of t, so bounding r(t) is equivalent to bounding
ρ(t). Following the same steps as Soudry et al. [2018, Appendix E.3]:"
PROOF SKETCH,0.1276005547850208,"∥r (t + 1)∥2 −∥r (t)∥2 = ∥r (t + 1) −r (t)∥2
|
{z
}
First Term"
PROOF SKETCH,0.1289875173370319,"+2 (r (t + 1) −r (t))⊤r (t)
|
{z
}
Second Term (9)"
PROOF SKETCH,0.130374479889043,"The high-level approach is to bound the two terms of the above expansion for r(t) and then use
a telescoping argument to bound r(t) for all t > 0. Below we provide the main arguments; for a
complete proof of the second term’s bound, please refer to Appendix F."
BOUNDING THE FIRST TERM,0.1317614424410541,"4.1
Bounding the First Term"
BOUNDING THE FIRST TERM,0.13314840499306518,"Using log(1 + x) ≤x for all x > 0, we expand the first term as follows:"
BOUNDING THE FIRST TERM,0.13453536754507628,"∥r (t + 1) −r (t)∥2 ≤η2 ∥∇R (w (t))∥2 + ∥ˆw∥2 t−2 + 2η ˆw⊤∇R (w (t)) log
 
1 + t−1"
BOUNDING THE FIRST TERM,0.13592233009708737,≤η2 ∥∇R (w (t))∥2 + ∥ˆw∥2 t−2
BOUNDING THE FIRST TERM,0.13730929264909847,Obtaining the second inequality requires proving that
BOUNDING THE FIRST TERM,0.13869625520110956,"2η ˆw⊤∇R (w (t)) log
 
1 + t−1
≤0, or equivalently, ˆw⊤∇R (w (t)) < 0
(10)"
BOUNDING THE FIRST TERM,0.14008321775312066,We will spend the rest of this subsection going over the complete proof of this inequality.
BOUNDING THE FIRST TERM,0.14147018030513175,"First we state the following lemma (derived in Appendix B.2) that gives us a useful expression for
the gradient of the risk w.r.t. W:"
BOUNDING THE FIRST TERM,0.14285714285714285,"Lemma 4.2. For any W ∈Rd×K, we have that ∇R(W) = PN
i=1 xi∇ψ
 
ΥyiDW⊤xi
⊤ΥyiD."
BOUNDING THE FIRST TERM,0.14424410540915394,"This expression involves weight matrix W. However the inequality we set out to prove (Eqn. (10))
is in terms of w = vec(W). Throughout our main result proof, these two different forms – weight
matrix versus vectorization of that matrix – will each be useful in different situations. Thus, to shuttle
back and forth between these forms, the following well-known identity is useful:
Lemma 4.3. For equally sized matrices M and N, we have vec(M)⊤vec(N) = tr(M⊤N)."
BOUNDING THE FIRST TERM,0.14563106796116504,"Now we can prove our inequality of interest, i.e., Eqn. (10).
Lemma 4.4. (Multiclass generalization of Soudry et al. [2018, Lemma 1]) For any PERM loss that
is β-smooth, strictly decreasing, and non-negative, (Assumption 3.1) and Assumption 3.2, and for
almost all linearly separable datasets (Assumption 3.3), we have ˆw⊤∇R(w(t)) < 0."
BOUNDING THE FIRST TERM,0.14701803051317613,"Proof. Define matrix ˆ
W such that ˆw = vec( ˆ
W). Since w(t) = vec(W(t)), Lemma 4.3 implies"
BOUNDING THE FIRST TERM,0.14840499306518723,"ˆw⊤∇R(w(t)) = tr( ˆ
W⊤∇R(W(t)))
(11)"
BOUNDING THE FIRST TERM,0.14979195561719832,"To see how the PERM framework allows for a simple generalization of binary results, we will compare
our multiclass proof side-by-side with the binary proof discussed in Soudry et al. [2018, Lemma 1].
In the binary case, we have R (w) = PN
i=1 ψ
 
yiw⊤xi

=⇒∇R (w) = PN
i=1 ψ′  
yiw⊤xi

yixi.
Thus ˆw⊤∇R (w) = PN
i=1 ψ′  
yiw⊤xi

yi ˆw⊤xi. In the multiclass case, the analogous quantity is
tr( ˆ
W⊤∇R(W(t))) which can be computed as N
X"
BOUNDING THE FIRST TERM,0.15117891816920942,"i=1
tr( ˆ
W⊤xi∇ψ
 
ΥyiDW(t)⊤xi
⊤ΥyiD) = N
X"
BOUNDING THE FIRST TERM,0.15256588072122051,"i=1
∇ψ
 
ΥyiDW(t)⊤xi
⊤ΥyiD ˆ
W⊤xi."
BOUNDING THE FIRST TERM,0.1539528432732316,"In the multiclass proof we used the risk gradient from Lemma 4.2 as well as the cyclic property of the
trace operator. Then we dropped the trace because ∇ψ
 
ΥyiDW(t)⊤xi
⊤ΥyiD ˆ
W⊤xi is a scalar
(since ∇ψ (·) ∈RK−1, ΥyiDW(t)⊤xi ∈RK−1). For illustrative purpose, we place the rest of the
proof, in both the binary and multiclass setting, side-by-side:"
BOUNDING THE FIRST TERM,0.1553398058252427,"Binary: ˆw⊤∇R(w(t)).
Focusing on just the i-th term of this sum:"
BOUNDING THE FIRST TERM,0.15672676837725383,"ψ′  
yiw(t)⊤xi

yi ˆw⊤xi"
BOUNDING THE FIRST TERM,0.15811373092926492,"ψ is assumed to be strictly decreasing, i.e.
ψ′  
yiw(t)⊤xi

< 0. The dataset is lin-
early separable, so yi ˆw⊤xi ≥1. Thus we
obtain a sum (from i = 1 to N) of negative
terms."
BOUNDING THE FIRST TERM,0.15950069348127602,"Multiclass: tr( ˆ
W⊤∇R(W(t))).
Focusing on just the i-th term of this sum:"
BOUNDING THE FIRST TERM,0.1608876560332871,"∇ψ
 
ΥyiDW(t)⊤xi
⊤ΥyiD ˆ
W⊤xi"
BOUNDING THE FIRST TERM,0.1622746185852982,"ψ is assumed to be strictly decreasing, i.e.
∇ψ
 
ΥyiDW(t)⊤xi

≺0.
The dataset
is linearly separable, so ΥyiD ˆ
W⊤xi ⪰1.
Thus we obtain a sum (from i = 1 to N) of
negative terms."
BOUNDING THE FIRST TERM,0.1636615811373093,"Thus we see how the PERM framework allows us to essentially mirror the binary proof. In Remark
4.5, we elaborate more on the necessity of the relative margin form here."
BOUNDING THE FIRST TERM,0.1650485436893204,"Lemma 4.4 directly implies the auxiliary inequality we set out to prove (see Eqn. (10)). Thus we
obtain:"
BOUNDING THE FIRST TERM,0.1664355062413315,"∥r (t + 1) −r (t)∥2 ≤η2 ∥∇R (w (t))∥2 + ∥ˆw∥2 t−2
(12)"
BOUNDING THE FIRST TERM,0.1678224687933426,"Remark 4.5. Let us see what happens to our proof if we just used the general risk form in Eqn. (2)
without the PERM framework. First, we need an expression for the gradient of the risk: ∇R (W) =
PN
i=1 xi∇Ryi
 
W⊤xi
⊤. Proceeding similarly to the binary case, we focus on just the i-th term of"
BOUNDING THE FIRST TERM,0.16920943134535368,"tr

ˆ
W⊤∇R (W)

:"
BOUNDING THE FIRST TERM,0.17059639389736478,"tr

ˆ
W⊤xi∇Ryi
 
W⊤xi
⊤
= tr

∇Ryi
 
W⊤xi
⊤ˆ
W⊤xi

= ∇Ryi
 
W⊤xi
⊤ˆ
W⊤xi"
BOUNDING THE FIRST TERM,0.17198335644937587,"From here it is not clear how to proceed. The linear separability condition (Assumption 3.3) is not
useful anymore- it does not make a statement about the scores in the vector ˆ
W⊤xi, but rather their
relative margins (produced by the multiplication ΥyiD ˆ
W⊤xi)."
BOUNDING THE SECOND TERM,0.17337031900138697,"4.2
Bounding the Second Term"
BOUNDING THE SECOND TERM,0.17475728155339806,"In the previous subsection we established a bound on the first term of Eqn. (9). Here we sketch the
main arguments required to bound the second term, i.e. (r (t + 1) −r (t))⊤r (t). For more details
please refer to Appendix F. We state our final bound below as a lemma:"
BOUNDING THE SECOND TERM,0.17614424410540916,"Lemma 4.6. (Generalization of Soudry et al. [2018, Lemma 20]) Define θ to be the minimum SVM
margin across all datapoints and classes, i.e. θ = mink
h
minn/∈Sk ˜x⊤
n,k ˆw
i
> 1. Then"
BOUNDING THE SECOND TERM,0.17753120665742025,"∃C1, C2, t1 : ∀t > t1 : (r (t + 1) −r (t))⊤r (t) ≤C1t−θ + C2t−2 .
(13)"
BOUNDING THE SECOND TERM,0.17891816920943135,"A remark is in order on the difference of the above result to Soudry et al. [2018, Lemma 20]: on a
high-level, we are able to generalize the argument of Soudry et al. [2018, Lemma 20] to account for
both binary and multiclass classification, as well as general PERM ET losses beyond just CE."
BOUNDING THE SECOND TERM,0.18030513176144244,We now proceed with the proof sketch. The first step is to rewrite (r (t + 1) −r (t))⊤r (t) as
BOUNDING THE SECOND TERM,0.18169209431345354,"(−η∇R (w (t)) −ˆw [log (t + 1) −log (t)])⊤r (t)
∵Definition of r(t) in Equation (7)"
BOUNDING THE SECOND TERM,0.18307905686546463,"= ˆw⊤r(t)
 
t−1 −log
 
1 + t−1
+ tr    −η N
X"
BOUNDING THE SECOND TERM,0.18446601941747573,"i=1
xi∇ψ
 
ΥyiDW(t)⊤xi
⊤ΥyiD !⊤ R(t)  "
BOUNDING THE SECOND TERM,0.18585298196948682,"−t−1 ˆw⊤r(t)
∵Expression for ∇R (w (t)) from Lemma 4.4
(14)"
BOUNDING THE SECOND TERM,0.18723994452149792,"We defer the bound on the first term ˆw⊤r(t)
 
t−1 −log
 
1 + t−1
of Equation (14) to the appendix,
and instead focus on the second two terms. Using the cyclic property of the trace, the term in the
above final line involving the trace can be further simplified as: N
X"
BOUNDING THE SECOND TERM,0.18862690707350901,"i=1
−∇ψ
 
ΥyiDW(t)⊤xi
⊤ΥyiDR(t)⊤xi
(15)"
BOUNDING THE SECOND TERM,0.1900138696255201,"Note that for each i ∈[N], a summand in Equation (15) is an inner product between two (K −1)-
dimensional vectors, i.e., −∇ψ
 
ΥyiDW(t)⊤xi

and ΥyiDR(t)⊤xi. To proceed, to expand this
inner product out as N
X i=1 X"
BOUNDING THE SECOND TERM,0.1914008321775312,"k∈[K]\{yi}
J−∇ψ
 
ΥyiDW(t)⊤xi

KkJΥyiDR(t)⊤xiKk
(16)"
BOUNDING THE SECOND TERM,0.1927877947295423,"Remark 4.7. Here, J·Kk : RK−1 →R is defined as the coordinate projection such that
JΥyiDW⊤xiKk = ˜x⊤
i,kw. Note that J·Kk implicitly depends on i (the ˜xi,yi 0-entry is omitted).
But we abuse notation for brevity. Please see Appendix D for a more precise definition."
BOUNDING THE SECOND TERM,0.1941747572815534,"Using Equation (6) and Equation (8) we express the last two terms in Equation (14) as  N
X i=1 X"
BOUNDING THE SECOND TERM,0.1955617198335645,"k∈[K]\{yi}
J−∇ψ
 
ΥyiDW(t)⊤xi

KkJΥyiDR(t)⊤xiKk

−t−1 ˆw⊤r(t) = N
X i=1 X"
BOUNDING THE SECOND TERM,0.19694868238557559,k∈[K]\{yi}
BOUNDING THE SECOND TERM,0.19833564493758668," 
J−∇ψ
 
ΥyiDW(t)⊤xi

Kk −t−1 exp(−˜w⊤˜xi,k)1{i∈Sk}
˜x⊤
i,kr(t)
(17)"
BOUNDING THE SECOND TERM,0.19972260748959778,"Finally, to upper bound the above expression, we consider a single tuple (i, k) case-by-case, depending
on the sign of ˜x⊤
i,kr(t). This is the step where the upper and lower bounds in Definition 2.2 come in.
Lemma D.2 in the appendix essentially applies Definition 2.2 to the relative margins to yield"
BOUNDING THE SECOND TERM,0.20110957004160887,"J−∇ψ(ΥyiDW(t)⊤xi)Kk ≤exp(−˜x⊤
i,kw(t)),
and
(18)"
BOUNDING THE SECOND TERM,0.20249653259361997,"J−∇ψ(ΥyiDW(t)⊤xi)Kk ≥(1 −P
r∈[K]\{yi} exp(−˜x⊤
i,rw(t))) exp(−˜x⊤
i,kw(t))
(19)"
BOUNDING THE SECOND TERM,0.20388349514563106,"for all k ∈[K] \ {yi}. We use Definition 2.2’s exponential tail bounds by proving that the relative
margins ˜x⊤
i,kw(t) that appear in Lemma D.2 eventually become positive. This is true due to the
following lemma (see Appendix E for the proof, which again mirrors the binary case):"
BOUNDING THE SECOND TERM,0.20527045769764216,"Lemma 4.8. (Multiclass generalization of Soudry et al. [2018, Lemma 1]) Consider any linearly
separable dataset, and any PERM loss with template ψ that is convex, β-smooth, strictly decreasing,
and non-negative. For all k ∈{1, ..., K}, let wk(t) be the gradient descent iterates at iteration t for
the kth class. Then ∀i ∈{1, ..., N}, ∀j ∈{1, ..., K}\{yi} : limt→∞(wyi(t) −wj(t))⊤xi →∞."
BOUNDING THE SECOND TERM,0.20665742024965325,"This lemma lets us use the exponential tail bounds with any finite u±. To conclude, we apply the
upper (18) and lower bounds (19) to the summation in Equation (17), and reduce the problem to that
of Soudry et al. [2018, Appendix E], thereby proving Lemma 4.6. See our Appendix F for details."
TYING IT ALL TOGETHER,0.20804438280166435,"4.3
Tying It All Together"
TYING IT ALL TOGETHER,0.20943134535367544,"We use the logic of Soudry et al. [2018, Appendix A.2] to conclude the analysis. Define C = ∞
X"
TYING IT ALL TOGETHER,0.21081830790568654,"t=0
∥r (t + 1) −r (t)∥2 ≤ ∞
X"
TYING IT ALL TOGETHER,0.21220527045769763,"t=0
η2 ∥∇R (w (t))∥2 + ∥ˆw∥2 t−2."
TYING IT ALL TOGETHER,0.21359223300970873,"In the latter inequality we used Eqn. (12). Thus, C is bounded because from Soudry et al. [2018,
Lemma 10], we know that P∞
t=0 ∥∇R (w (t))∥2 < ∞. Here we note that Soudry et al. [2018,
Lemma 10] requires the ERM objective R (w) to be β′-smooth for some positive β′. It is easy to
show that if the loss is β-smooth, then R (w) is βσ2
max (X)-smooth. This explains the learning rate
condition η < 2/
 
βσ2
max (X)

in our theorem. Also, a t−p power series converges for any p > 1."
TYING IT ALL TOGETHER,0.21497919556171982,Recalling the initial expansion of ∥r(t + 1)∥from Eqn. (9):
TYING IT ALL TOGETHER,0.21636615811373092,"∥r (t + 1)∥2 = ∥r (t + 1) −r (t)∥2 + 2 (r (t + 1) −r (t))⊤r (t) + ∥r (t)∥2 .
(20)"
TYING IT ALL TOGETHER,0.217753120665742,"Combining the bounds in Eqn. (12) and Lemma 4.6 into Eqn. (9), we find"
TYING IT ALL TOGETHER,0.21914008321775313,"∥r (t)∥2 −∥r (t1)∥2 = t−1
X u=t1"
TYING IT ALL TOGETHER,0.22052704576976423,"h
∥r (u + 1)∥2 −∥r (u)∥2i
≤C + 2 t−1
X u=t1"
TYING IT ALL TOGETHER,0.22191400832177532,"
C1u−θ + C2u−2
."
TYING IT ALL TOGETHER,0.22330097087378642,"Therefore, ∥r (t)∥is bounded, which proves our main theorem."
LIMITATIONS,0.22468793342579751,"5
Limitations"
LIMITATIONS,0.2260748959778086,"Here we describe some of our work’s limitations/possible future research directions. We note that
these questions have been analyzed for the binary classification setting, but not for multiclass."
LIMITATIONS,0.2274618585298197,"Non-ET losses
In our paper we only analyze multiclass implicit bias for losses with the ET property.
Another possible line of future work is to analyze the gradient descent dynamics for non-ET losses.
Nacson et al. [2019] and Ji et al. [2020] prove that in the binary setting, ET and well-behaved
super-polynomial tailed losses ensure convergence to the maximum-margin direction, while other
losses may converge to a different direction with poor margin. Is such a characterization possible in
the multiclass setting?"
LIMITATIONS,0.2288488210818308,"Other gradient-based methods
This paper only analyzes vanilla gradient descent. Another line
of work involves exploring implicit bias effects of other gradient-based methods, such as those
characterized in Gunasekar et al. [2018]. Nacson et al. [2022] uses similar proof techniques to prove
results for SGD, which is prevalent in practice and often generalizes better than vanilla GD ([Amir
et al., 2021])."
LIMITATIONS,0.2302357836338419,"Non-asymptotic analysis
Our result proves that the gradient descent predictors asymptotically do
not overfit. However, in the binary classification case, Shamir [2021] goes one step further and proves
that for gradient-based methods, throughout the entire training process (not just asymptotically),
both the empirical risk and the generalization error decrease at an essentially optimal rate (or remain
optimally constant). Does the same phenomenon occur in the multiclass setting?"
CONCLUSION,0.231622746185853,"6
Conclusion"
CONCLUSION,0.23300970873786409,"We use the permutation equivariant and relative margin-based (PERM) loss framework to provide
an multiclass extension of the binary ET property. On a high level, while the binary ET bounds
the negative derivative of the loss, our multiclass ET bounds each negative partial derivative of the
PERM template ψ. We demonstrate our definition’s validity for multinomial logistic loss, multiclass
exponential loss, and PairLogLoss. We develop new techniques for analyzing multiclass gradient
descent, and apply these to generalize binary implicit bias results to the multiclass setting. Our main
result is that for almost all linearly separable multiclass datasets and a suitable ET PERM loss, the
gradient descent iterates directionally converge towards the hard-margin multiclass SVM solution."
CONCLUSION,0.23439667128987518,"Our proof techniques in this paper demonstrate the power of the PERM framework to facilitate
extensions of known binary results to multiclass settings and provide a unified treatment of both
binary and multiclass classification. Thus it is possible that the binary results discussed in the
Limitations section can also be extended using the PERM loss framework. In the future we would
like to consider more complex settings that have been analyzed primarily for the binary case, such as
non-separable data (Ji and Telgarsky [2019]) and two-layer neural nets (Lyu et al. [2021])."
CONCLUSION,0.23578363384188628,Acknowledgments and Disclosure of Funding
CONCLUSION,0.23717059639389737,"CS was supported in part by the National Science Foundation under award 2008074, and by the
Department of Defense, Defense Threat Reduction Agency under award HDTRA1-20-2-0002. The
research of DS was funded by the European Union (ERC, A-B-C-Deep, 101039436). Views and
opinions expressed are however those of the author only and do not necessarily reflect those of
the European Union or the European Research Council Executive Agency (ERCEA). Neither the
European Union nor the granting authority can be held responsible for them. DS also acknowledges
the support of the Schmidt Career Advancement Chair in AI. YW was supported in part by the Eric
and Wendy Schmidt AI in Science Postdoctoral Fellowship, a Schmidt Futures program."
REFERENCES,0.23855755894590847,References
REFERENCES,0.23994452149791956,"Idan Amir, Tomer Koren, and Roi Livni. Sgd generalizes better than gd (and regularization doesn’t
help), 2021."
REFERENCES,0.24133148404993066,"Amir Beck and Marc Teboulle. Mirror descent and nonlinear projected subgradient methods for
convex optimization. Operations Research Letters, 31(3):167–175, 2003."
REFERENCES,0.24271844660194175,"Stephen Boyd and Lieven Vandenberghe. Convex optimization. Cambridge University Press, 2004."
REFERENCES,0.24410540915395285,"Emmanuel J. Candès and Pragya Sur. The phase transition for the existence of the maximum
likelihood estimate in high-dimensional logistic regression. The Annals of Statistics, 48(1):27–42,
2020."
REFERENCES,0.24549237170596394,"Kenneth L Clarkson, Elad Hazan, and David P Woodruff. Sublinear optimization for machine
learning. Journal of the ACM (JACM), 59(5):1–49, 2012."
REFERENCES,0.24687933425797504,"Andrew Cotter, Shai Shalev-Shwartz, and Nathan Srebro. The kernelized stochastic batch perceptron.
In Proceedings of the 29th International Coference on International Conference on Machine
Learning, pages 739–746, 2012."
REFERENCES,0.24826629680998613,"John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and
stochastic optimization. Journal of machine learning research, 12(7), 2011."
REFERENCES,0.24965325936199723,"Suriya Gunasekar, Jason Lee, Daniel Soudry, and Nathan Srebro. Characterizing implicit bias in terms
of optimization geometry. In International Conference on Machine Learning, pages 1832–1841.
PMLR, 2018."
REFERENCES,0.2510402219140083,"Ziwei Ji and Matus Telgarsky. The implicit bias of gradient descent on nonseparable data. In
Conference on Learning Theory, pages 1772–1798. PMLR, 2019."
REFERENCES,0.2524271844660194,"Ziwei Ji, Miroslav Dudik, Robert E Schapire, and Matus Telgarsky. Gradient descent follows the
regularization path for general losses. In Conference on Learning Theory, pages 2109–2136.
PMLR, 2020."
REFERENCES,0.2538141470180305,"Ziwei Ji, Nathan Srebro, and Matus Telgarsky. Fast margin maximization via dual acceleration. In
International Conference on Machine Learning, pages 4860–4869. PMLR, 2021."
REFERENCES,0.2552011095700416,"CG Khatri and C Radhakrishna Rao. Solutions to some functional equations and their applications to
characterization of probability distributions. Sankhy¯a: The Indian Journal of Statistics, Series A,
pages 167–180, 1968."
REFERENCES,0.2565880721220527,"Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International
Conference on Learning Representations, volume 6, 2015."
REFERENCES,0.2579750346740638,"Shuangzhe Liu. Matrix results on the khatri-rao and tracy-singh products. Linear Algebra and its
Applications, 289(1-3):267–277, 1999."
REFERENCES,0.2593619972260749,"Kaifeng Lyu and Jian Li. Gradient descent maximizes the margin of homogeneous neural networks.
arXiv preprint arXiv:1906.05890, 2019."
REFERENCES,0.260748959778086,"Kaifeng Lyu, Zhiyuan Li, Runzhe Wang, and Sanjeev Arora. Gradient descent on two-layer nets:
Margin maximization and simplicity bias. Advances in Neural Information Processing Systems,
34:12978–12991, 2021."
REFERENCES,0.2621359223300971,"Jan R Magnus and Heinz Neudecker. Matrix differential calculus with applications in statistics and
econometrics. John Wiley & Sons, 2019."
REFERENCES,0.2635228848821082,"Indraneel Mukherjee and Robert E Schapire. A theory of multiclass boosting. Journal of Machine
Learning Research, 2013."
REFERENCES,0.26490984743411927,"Mor Shpigel Nacson, Jason Lee, Suriya Gunasekar, Pedro Henrique Pamplona Savarese, Nathan
Srebro, and Daniel Soudry. Convergence of gradient descent on separable data. In The 22nd
International Conference on Artificial Intelligence and Statistics, pages 3420–3428. PMLR, 2019."
REFERENCES,0.26629680998613037,"Mor Shpigel Nacson, Nathan Srebro, and Daniel Soudry. Stochastic gradient descent on separable
data: Exact convergence with a fixed learning rate, 2022."
REFERENCES,0.26768377253814146,"Robert R Phelps. Convex functions, monotone operators and differentiability, volume 1364. Springer,
2009."
REFERENCES,0.26907073509015256,"Matan Schliserman and Tomer Koren. Stability vs implicit bias of gradient methods on separable
data and beyond. In Conference on Learning Theory, pages 3380–3394. PMLR, 2022."
REFERENCES,0.27045769764216365,"Matan Schliserman and Tomer Koren. Tight risk bounds for gradient descent on separable data. arXiv
preprint arXiv:2303.01135, 2023."
REFERENCES,0.27184466019417475,"Ohad Shamir. Gradient methods never overfit on separable data. The Journal of Machine Learning
Research, 22(1):3847–3866, 2021."
REFERENCES,0.27323162274618584,"Daniel Soudry, Elad Hoffer, Mor Shpigel Nacson, Suriya Gunasekar, and Nathan Srebro. The implicit
bias of gradient descent on separable data. The Journal of Machine Learning Research, 19(1):
2822–2878, 2018. See arxiv.org/abs/1710.10345v7 for the most up-to-date version."
REFERENCES,0.27461858529819694,"Gal Vardi. On the implicit bias in deep-learning algorithms. arXiv preprint arXiv:2208.12591, 2022."
REFERENCES,0.27600554785020803,"Ke Wang, Vidya Muthukumar, and Christos Thrampoulidis. Benign overfitting in multiclass classifi-
cation: All roads lead to interpolation, 2023."
REFERENCES,0.27739251040221913,"Nan Wang, Zhen Qin, Le Yan, Honglei Zhuang, Xuanhui Wang, Michael Bendersky, and Marc
Najork. Rank4class: A ranking formulation for multiclass classification, 2022."
REFERENCES,0.2787794729542302,"Yutong Wang and Clayton Scott. Unified binary and multiclass margin-based classification. Accepted
to Journal of Machine Learning Research, arXiv:2311.17778, 2024."
REFERENCES,0.2801664355062413,"Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep
learning (still) requires rethinking generalization. Communications of the ACM, 64(3):107–115,
2021."
REFERENCES,0.2815533980582524,"A
Discussion of Lyu and Li [2019]"
REFERENCES,0.2829403606102635,"Lyu and Li [2019] allow the class score functions to be linear classifiers, e.g., w⊤
k xi, but also
nonlinear, e.g., “cubed” linear classifier (w⊤
k xi)3. By shifting the cubing operation to the loss, we
can view the implicit regularization result of Lyu and Li [2019] as a result for losses beyond the cross
entropy. This resulting loss is rather exotic and we are not aware of it being used in the literature;
it is interesting nevertheless. However, the optimization problem would become non-convex, so
convergence would not necessarily be to a global minimum:"
REFERENCES,0.2843273231622746,"min
w
1
2∥w∥2
s.t.
 
w⊤
yixi
3 −
 
w⊤
k xi
3 ≥1 for all i ∈[N], j ∈[K]\{yi}"
REFERENCES,0.2857142857142857,"Moreover, the decision region for the k-th class, i.e., the set of x ∈Rd such that (w⊤
k x)3 > (w⊤
j x)3
for all j ̸= k, is an intersection of sets constructed via cubic hypersurfaces."
REFERENCES,0.2871012482662968,"More precisely, the k-th decision region can be written as"
REFERENCES,0.2884882108183079,"{x ∈Rd : (w⊤
k x)3 = argmaxj∈[K](w⊤
j x)3} =
\"
REFERENCES,0.289875173370319,"j∈[K]:j̸=k
{x ∈Rd : (w⊤
k x)3 > (w⊤
j x)3}"
REFERENCES,0.2912621359223301,"Let us define Hj := {x ∈Rd : (w⊤
k x)3 = (w⊤
j x)3}. Note that Hj ⊆Rd is the zero set of degree 3
polynomials with variables in x, hence, a cubic hypersurface. Now, the set {x ∈Rd : (w⊤
k x)3 >
(w⊤
j x)3} is a subset of the set-theoretic complement of Hj in Rd. Thus, the decision regions are
complicated geometric objects, compared to the classical hard-margin SVM."
REFERENCES,0.2926490984743412,"B
Matrix Calculus"
REFERENCES,0.29403606102635227,"This section of the appendix establishes matrix identities that will be useful for us to calculate the
gradient/Hessian of the empirical risk objective R(w)."
REFERENCES,0.29542302357836336,"Vector-input scalar-output function. Suppose f : Rn →R is a continuously differentiable function.
Let x = [x1, · · · , xn]⊤∈Rn be a vector of variables for differentiation. Define the (column) vector"
REFERENCES,0.29680998613037446,"of partial derivatives w.r.t. x: ∂x :=
h
∂
∂xi i"
REFERENCES,0.29819694868238555,"i∈[n]. The gradient of f, denoted ∇f, is the function"
REFERENCES,0.29958391123439665,"∇f : Rn →Rn,
where
∇f(x) = ∂xf(x) =
h
∂f
∂x1 (x)
· · ·
∂f
∂xn (x)
i⊤
.
(21)"
REFERENCES,0.30097087378640774,"Suppose that f is twice continuously differentiable. The Hessian of f, denoted ∇2f, is the function"
REFERENCES,0.30235783633841884,"∇2f : Rn →Rn×n,
where
∇2f(x) =
h
∂2f
∂xi∂xj (x)
i"
REFERENCES,0.30374479889042993,"i,j∈[n] .
(22)"
REFERENCES,0.30513176144244103,"Matrix-input scalar-output function. Let f : Rm×n →R be a differentiable function. Let
X = [xij]i∈[m],j∈[n] ∈Rm×n be an arbitrary matrix. Define the matrix of partial derivatives w.r.t.
X:
∂X :=
h
∂
∂xij i"
REFERENCES,0.3065187239944521,"i∈[m],j∈[n]
Define the gradient of f, denoted ∇f, to be the function"
REFERENCES,0.3079056865464632,"∇f : Rm×n →Rm×n,
where
∇(f)(X) := ∂Xf(X) =
h
∂
∂xij f(X)
i"
REFERENCES,0.3092926490984743,"i∈[m],j∈[n] .
(23)"
REFERENCES,0.3106796116504854,"We do not define the Hessian of a matrix-input scalar-output function f : Rm×n →R. Instead, we
will define the Hessian for its vectorization vec(f) : Rmn →R.
Definition B.1 (Vectorization operator). Let vec denote the vectorization operator by stacking the
columns of a vector. In other words, if A ∈Rm×n is a matrix with columns a1, . . . , an ∈Rm, then"
REFERENCES,0.3120665742024965,"vec(A) :=

a⊤
1
a⊤
2
· · ·
a⊤
n
⊤."
REFERENCES,0.31345353675450766,"Definition B.2 (Vectorization of a matrix-input function). Let f : Rm×n →R be a matrix-input
function, we define vec(f) : Rmn →R to be the vector-input function such that"
REFERENCES,0.31484049930651875,f(A) = vec(f)(vec(A)).
REFERENCES,0.31622746185852985,"In particular, if f is already a vector-input function, then vec(f) = f."
REFERENCES,0.31761442441054094,"See [Magnus and Neudecker, 2019, Ch.5-§15]. Below in Lemma B.4, we give a convenient formula
to calculate the Hessian of R(w), the vectorization of R(W)."
REFERENCES,0.31900138696255204,"The following relates the vectorization operator with the Kronecker product:
Lemma B.1. Let A ∈Rp×n, B ∈Rn×m, C ∈Rm×q be matrices. Then"
REFERENCES,0.32038834951456313,vec(ABC) = (C⊤⊗A)vec(B).
REFERENCES,0.3217753120665742,"Proof. This is [Magnus and Neudecker, 2019, Theorem 2.2]."
REFERENCES,0.3231622746185853,"B.1
Special case of the chain rule for linear functions"
REFERENCES,0.3245492371705964,"Proposition B.2. Let M ∈Rm×n be a matrix. Let f : Rm →R be a continuously differentiable
function and define g : Rn →R by g(x) := f(Mx). Then"
REFERENCES,0.3259361997226075,"∇g(x) = M⊤∇f(Mx),
and
∇2g(x) = M⊤∇2f(Mx)M."
REFERENCES,0.3273231622746186,"Proof. See [Magnus and Neudecker, 2019, Ch.9-§13] for the first identity and [Magnus and
Neudecker, 2019, Ch.10-§8] for the second identity."
REFERENCES,0.3287101248266297,"The next two results will be referred to as the “gradient formula” and the “Hessian formula”,
respectively, for the function g(X) := f(AX⊤B).
Lemma B.3. Let f : Rp×q →R be a matrix-input scalar-output differentiable function with Jacobian
denoted ∇f : Rp×q →Rp×q. Let A ∈Rp×n, X ∈Rm×n, and B ∈Rm×q. Define a function
g : Rm×n →R by g(X) := f(AX⊤B). Then"
REFERENCES,0.3300970873786408,∇g(X) = ∂Xf(AX⊤B) = B∇f(AX⊤B)⊤A.
REFERENCES,0.3314840499306519,"Lemma B.4. Let f : Rp →R be a vector-input scalar-output twice differentiable function. Let
A ∈Rp×n, X ∈Rm×n be matrices and b ∈Rm be a (column) vector. Let V be another matrix
with the same shape as X. Let x := vec(X) and v := vec(V). Define g(X) := f(AX⊤b)
and let g = vec(g) be the vectorization of g. Then we have the following formula for computing
v⊤∇2g(x)v:
v⊤∇2g(x)v = (AV⊤b)⊤∇2f(AX⊤b)AV⊤b⊤."
REFERENCES,0.332871012482663,"B.2
Proof of the gradient formula: Lemma 4.2"
REFERENCES,0.3342579750346741,"In the notation of Section 2.8.1 of the Matrix Cookbook, define matrix U ∈Rp×q by U := AX⊤B.
Note that U is a function of X. Then by Eqn. (137) of the Matrix Cookbook, we have for each
(i, j) ∈[m] × [n]"
REFERENCES,0.3356449375866852,"∂
∂Xij
f(AX⊤B) =
∂
∂Xij
f(U) = Tr"
REFERENCES,0.33703190013869627,"""∂f(U) ∂U ⊤∂U ∂Xij #"
REFERENCES,0.33841886269070737,"Note that by definition, we have ∂f(U)"
REFERENCES,0.33980582524271846,"∂U
= ∇f(U). Therefore"
REFERENCES,0.34119278779472956,"∂
∂Xij
f(AX⊤B) = Tr

∇f(U)⊤∂U ∂Xij "
REFERENCES,0.34257975034674065,"Next, write U = [Ukℓ]k∈[p],ℓ∈[q] in the “matrix-comprehension” notation. Recall that Ukℓ, i.e., the
(k, ℓ)-th entry of U, is precisely computed by A[k, :](X⊤B)[:, ℓ] = A[k, :]X⊤B[:, ℓ]. For each
k, ℓ∈[p] × [q], we have
∂Ukℓ
∂Xij
= ∂(A[k, :]X⊤B[:, ℓ])"
REFERENCES,0.34396671289875175,"∂Xij
where “[k, :]” and “ [:, ℓ] ” denote taking the k-th row vector and ℓ-th column vector, respectively.
Now, by Eqn. (71) of the Matrix Cookbook, we have the following expression of the matrix-partial
derivative as an outer product ∂Ukℓ"
REFERENCES,0.34535367545076284,"∂X = ∂A[k, :]X⊤B[:, ℓ]"
REFERENCES,0.34674063800277394,"∂X
= B[:, ℓ]A[k, :]."
REFERENCES,0.34812760055478503,"From this, it follows that computing the entry-wise partial derivative at Xij is simply obtained by
indexing at (i, j), i.e., ∂Ukℓ"
REFERENCES,0.34951456310679613,"∂Xij = B[i, ℓ]A[k, j] = A[k, j]B[i, ℓ] (we emphasize that this is just a"
REFERENCES,0.3509015256588072,"product of two scalars). Thus,
∂U
∂Xij = A[:, j]B[i, :]. Consequently,"
REFERENCES,0.3522884882108183,"∂
∂Xij
f(AX⊤B) = Tr

∇f(U)⊤A[:, j]B[i, :]

= B[i, :]∇f(U)⊤A[:, j]."
REFERENCES,0.3536754507628294,"In other words,
∂
∂Xf(AX⊤B) = B∇f(U)⊤A ."
REFERENCES,0.3550624133148405,"For our purposes, we replace f with ψ, A with ΥyiD, X with W, and B with xi. Thus we obtain"
REFERENCES,0.3564493758668516,"∇R (W) = N
X i=1"
REFERENCES,0.3578363384188627,"∂
∂Wψ
 
ΥyiDW⊤xi

= N
X"
REFERENCES,0.3592233009708738,"i=1
xi∇ψ
 
ΥyiDW⊤xi
⊤ΥyiD"
REFERENCES,0.3606102635228849,"as desired.
□"
REFERENCES,0.361997226074896,"B.3
Proof of Hessian formula: Lemma B.4"
REFERENCES,0.3633841886269071,"Our goal is to calculate the Hessian of vec(g). First, we note that by definition"
REFERENCES,0.3647711511789182,vec(g)(x) = vec(g)(vec(X)) = vec(f)(vec(AX⊤b))
REFERENCES,0.36615811373092927,"Note that the last equality is simply vec(f)(vec(AX⊤b)) = f(AX⊤b), but we work in the more
general case of a matrix B right now. We will need to simplify vec(AX⊤b). It is more convenient
during the first phase of the proof viewing b as a m × 1 matrix and denote it using uppercase letter
B. First, applying Lemma B.1 to vec(AX⊤B), we get"
REFERENCES,0.36754507628294036,vec(AX⊤B) = (B⊤⊗A)vec(X⊤)
REFERENCES,0.36893203883495146,"However, vec(X⊤) ̸= vec(X) in general. However, these two expressions are related using the
commutation matrix:
Definition B.3 (Commutation matrix). Define Km,n to be the permutation matrix in Rmn×mn such
that Km,nvec(A) = vec(A⊤) for all matrices A ∈Rm×n."
REFERENCES,0.37031900138696255,"See [Magnus and Neudecker, 2019, Ch.3-§7]. Below, we drop the subscripts in Definition B.3 and
simply write K := Km,n. Now, we have"
REFERENCES,0.37170596393897365,vec(AX⊤B) = (B⊤⊗A)K⊤vec(X) = (B⊤⊗A)K⊤x
REFERENCES,0.37309292649098474,"Thus
vec(g)(x) = vec(g)(vec(X)) = vec(f)((B⊤⊗A)K⊤x)"
REFERENCES,0.37447988904299584,"By Proposition B.2, we have
∇2vec(g)(x)"
REFERENCES,0.37586685159500693,= ((B⊤⊗A)K⊤)⊤∇2vec(f)((B⊤⊗A)K⊤x)(B⊤⊗A)K⊤
REFERENCES,0.37725381414701803,= ((B⊤⊗A)K⊤)⊤∇2vec(f)(vec(AX⊤B))(B⊤⊗A)K⊤.
REFERENCES,0.3786407766990291,"From this, we see that (recall that v = vec(V))"
REFERENCES,0.3800277392510402,v⊤∇2vec(g)(x)v = ((B⊤⊗A)K⊤v)⊤∇2vec(f)(vec(AX⊤B))(B⊤⊗A)K⊤v.
REFERENCES,0.3814147018030513,"Now, by Lemma B.1, we have"
REFERENCES,0.3828016643550624,"(B⊤⊗A)K⊤v = (B⊤⊗A)K⊤vec(V) = vec(AV⊤B).
Now, since B = b is just a vector, we have"
REFERENCES,0.3841886269070735,"vec(AV⊤B) = AV⊤b.
and
∇2vec(f)(vec(AX⊤B)) = ∇2f(AX⊤b)
Putting it all together, we get the desired equality.
□"
REFERENCES,0.3855755894590846,"C
PERM Losses That Satisfy Assumptions 3.1 and 3.2"
REFERENCES,0.3869625520110957,"C.1
Cross-Entropy"
REFERENCES,0.3883495145631068,"By Wang and Scott [2024, Example 1], the cross-entropy loss Ly (v) = −log

exp(vy)
PK
k=1 exp(vk) 
has"
REFERENCES,0.3897364771151179,"template ψ (u) = log

1 + PK−1
k=1 exp (−uk)

. We calculate the partial derivatives:"
REFERENCES,0.391123439667129,"∂ψ
∂ui
(u)"
REFERENCES,0.3925104022191401,"= −
exp (−ui)"
REFERENCES,0.39389736477115117,"1 + PK−1
k=1 exp (−uk)
(24)"
REFERENCES,0.39528432732316227,"= −
1
1 + (Ci + 1) exp (ui)
where Ci = P"
REFERENCES,0.39667128987517336,"k∈[K−1]:k̸=i exp (−uk) .
(25)"
REFERENCES,0.39805825242718446,"C.1.1
Convexity"
REFERENCES,0.39944521497919555,"Let us analyze the entries of the Hessian of the template, i.e. ∇2ψ (u). Let [A]l,m denote the element
of A at the l-th row and m-th column. We get for all i, j ∈[K −1] where j ̸= i:

∇2ψ (u)
"
REFERENCES,0.40083217753120665,"i,i = ∂2ψ (u)"
REFERENCES,0.40221914008321774,"∂u2
i
=
(Ci + 1) e−ui

1 + PK−1
k=1 e−uk
2"
REFERENCES,0.40360610263522884,"
∇2ψ (u)
"
REFERENCES,0.40499306518723993,"i,j =

∇2ψ (u)
"
REFERENCES,0.406380027739251,"j,i = ∂2ψ (u)"
REFERENCES,0.4077669902912621,"∂uiuj
=
−e−ui−uj

1 + PK−1
k=1 e−uk
2"
REFERENCES,0.4091539528432732,"From the definition of Ci, this implies that:

∇2ψ (u)
"
REFERENCES,0.4105409153952843,"i,i =
X"
REFERENCES,0.4119278779472954,"j∈[K−1],j̸=i"
REFERENCES,0.4133148404993065,"
∇2ψ (u)
 i,j"
REFERENCES,0.4147018030513176,"+
e−ui

1 + PK−1
k=1 e−uk
2"
REFERENCES,0.4160887656033287,"Thus, the Hessian is a symmetric diagonally dominant matrix, and hence is positive semi-definite."
REFERENCES,0.4174757281553398,"C.1.2
β-smoothness"
REFERENCES,0.4188626907073509,"For any diagonally dominant matrix B, let |B| be the matrix obtained by taking the absolute value of
each element of B, that is:
[|B|]l,m =
[B]l,m

for all l, m."
REFERENCES,0.420249653259362,"Additionally, let diag(·) : Rp →Rp×p (for any p ∈N) be the function that maps a vector to a
diagonal matrix in the obvious way."
REFERENCES,0.42163661581137307,"Then we have the following lemma:
Lemma C.1. Let B′ := diag (|B| 1) where 1 is the appropriately-sized vector of all-1’s. Then
B ⪯B′."
REFERENCES,0.42302357836338417,"Proof. This can be proven simply by observing that B′ −B is symmetric and diagonally dominant
(and thus positive semi-definite)."
REFERENCES,0.42441054091539526,"Lemma C.1 can be directly applied to analyze the Hessian (and eventually bound its maximum
eigenvalue). Define H′ = diag
 ∇2ψ (u)
 1

. In other words, from Eqn. (25):"
REFERENCES,0.42579750346740636,"[H′]i,i = K−1
X k=1"
REFERENCES,0.42718446601941745,"∇2ψ (u)

i,k =
(2Ci + 1) e−ui

1 + PK−1
k=1 e−uk
2
(26)"
REFERENCES,0.42857142857142855,"[H′]i,j = 0"
REFERENCES,0.42995839112343964,"Thus, by directly applying Lemma C.1, we obtain
∇2ψ (u) ⪯H′"
REFERENCES,0.43134535367545074,"So now since H′ is defined to be a diagonal matrix, all that’s left to do is bound the diagonal entries
by a positive constant. First note that from the definition of Ci, it follows that 1 + PK−1
k=1 e−uk =
Ci + 1 + e−ui. Combining this with Eqn. (26), we get:
(2Ci + 1) e−ui"
REFERENCES,0.43273231622746183,"((Ci + 1) + e−ui)2 =
(2Ci + 1)
((Ci + 1) + e−ui) ((Ci + 1) eui + 1)
We can find a global minimum of the denominator of the above expression and thus arrive at an
upper bound for the expression. Differentiating with respect to ui and setting to 0 yields a single
critical point at ui = −log (Ci + 1), which produces a value of 4 (Ci + 1) when substituted in the
denominator (this is a global minimum of the denominator expression). Thus, we get"
REFERENCES,0.43411927877947293,"[H′]i,i ≤(2Ci + 1)"
REFERENCES,0.435506241331484,4 (Ci + 1) = 1
REFERENCES,0.4368932038834951,"2 −
1
4 (Ci + 1)
In the binary i.e. K = 2 case, Ci = 0, so our bound is exactly 1/4. However, in the multiclass case
(i.e. K > 2), Ci can be arbitrarily large. Setting Ci = ∞yields a final upper bound of 1/2."
REFERENCES,0.43828016643550627,So our final bound can be summarized as follows:
REFERENCES,0.43966712898751736,"∥∇2ψ (u) ∥2 ≤[H′]i,i ≤
1/4
, if K = 2
1/2
, if K > 2."
REFERENCES,0.44105409153952846,"Thus, β = 1/4 for binary cross-entropy (logistic loss), but β = 1/2 for K-class cross-entropy."
REFERENCES,0.44244105409153955,"C.1.3
Exponential Tail"
REFERENCES,0.44382801664355065,"We claim that for the cross-entropy Definition 2.2 holds with u± = 0 and c = a = 1. We are
interested in analyzing the (negative) gradient of the template. From Eqn. 24: −∂ψ"
REFERENCES,0.44521497919556174,"∂ui
(u) =
e−ui"
REFERENCES,0.44660194174757284,"1 + PK−1
k=1 e−uk ≤e−ui ≥e−ui 1 − K−1
X"
REFERENCES,0.44798890429958393,"k=1
e−uk
!"
REFERENCES,0.44937586685159503,"∵∀x ≥0,
1
1+x ≥1 −x"
REFERENCES,0.4507628294036061,This proves that the cross-entropy loss satisfies Definition 2.2 with u± = 0 and c = 1.
REFERENCES,0.4521497919556172,"C.2
Multiclass Exponential Loss [Mukherjee and Schapire, 2013]"
REFERENCES,0.4535367545076283,The multiclass exponential loss L : RK →R can be written as Ly(v) = P
REFERENCES,0.4549237170596394,"k∈[K]:k̸=y exp(−(vy −
vk)). Thus, the template function ψ : RK−1 →R can be expressed as ψ(u) = P
i∈[K−1] e−ui. The
partial derivatives of the template are then simply:"
REFERENCES,0.4563106796116505,"∂
∂ui
ψ(u) = −e−ui
for all i ∈[K −1].
(27)"
REFERENCES,0.4576976421636616,"C.2.1
Convexity"
REFERENCES,0.4590846047156727,We have
REFERENCES,0.4604715672676838,"∇2ψ(u) = diag(exp(−ui) : i = 1, . . . , K −1).
(28)"
REFERENCES,0.4618585298196949,The Hessian is a diagonal matrix with all diagonal entries positive. Hence it is positive definite.
REFERENCES,0.463245492371706,"C.2.2
β-“smoothness”"
REFERENCES,0.4646324549237171,Recall the identity derived in Lemma B.4:
REFERENCES,0.46601941747572817,v⊤∇2g(x)v = (AV⊤b)⊤∇2f(AX⊤b)AV⊤b⊤.
REFERENCES,0.46740638002773927,"We are interested in the special case where X ←W is a linear classifier (represented as a matrix) and
x ←vec(W) = w is its vectorization as in Section 3. Moreover, g(X) represents the risk R(W),
viewed as a matrix-input scalar-output function (defined in Appendix B), while g(x) represents the
vectorized risk R(w), viewed as a vector-input scalar-output function (defined in Appendix B). We
will use the formula in Lemma B.4 to calculate v⊤∇2R(w)v, where we substitute in"
REFERENCES,0.46879334257975036,"A ←ΥyiD ∈R(K−1)×K,
b ←xi ∈Rd,
f ←ψ."
REFERENCES,0.47018030513176146,"where (xi, yi) is a training sample and ψ is the template of a PERM loss. Since ∇2 is linear (i.e.,
distributive over additions), we have by Lemma B.4 that"
REFERENCES,0.47156726768377255,"v⊤∇2R(w)v = vec(V)⊤∇2R(w)vec(V) = N
X"
REFERENCES,0.47295423023578365,"i=1
(ΥyiD⊤Vxi)⊤∇2ψ(ΥyiD⊤Wxi)ΥyiD⊤Vxi."
REFERENCES,0.47434119278779474,"Note that ∥v∥= ∥vec(V)∥= ∥V∥F by the definitions of the Frobenius norm and vectorization.
Thus,
max
v∈RdK:∥v∥=1 v⊤∇2R(w)v =
max
V∈Rd×K:∥V∥F =1 vec(V)⊤∇2R(w)vec(V).
(29)"
REFERENCES,0.47572815533980584,"We note that we never defined the Hessian of a matrix-input function, i.e., we do not work with
∇2R(W). Combining the two previous identities, we have proven
Corollary C.2. Let R(W) be the risk viewed as a matrix-input scalar-output function defined in
Equation (3). Let R(w) be the vectorization of R(W). Then we have"
REFERENCES,0.47711511789181693,"max
v∈RdK:∥v∥=1 v⊤∇2R(w)v"
REFERENCES,0.478502080443828,"=
max
V∈Rd×K:∥V∥F =1 N
X"
REFERENCES,0.4798890429958391,"i=1
(ΥyiD⊤Vxi)⊤∇2ψ(ΥyiD⊤Wxi)ΥyiD⊤Vxi."
REFERENCES,0.4812760055478502,We have
REFERENCES,0.4826629680998613,"∇2ψ(u) = diag(exp(−ui) : i = 1, . . . , K −1).
(30)"
REFERENCES,0.4840499306518724,"Let vdiag(·) be the “inverse” of diag(·), i.e., vdiag(·) takes a diagonal matrix and returns the vector
of the diagonal elements."
REFERENCES,0.4854368932038835,"The max eigenvalue of the Hessian of R(w), i.e., Equation (29), is computed below:"
REFERENCES,0.4868238557558946,"max
v∈RdK:∥v∥=1 v⊤∇2R(w)v"
REFERENCES,0.4882108183079057,"1=
max
V∈Rd×K:∥V∥F =1 N
X"
REFERENCES,0.4895977808599168,"i=1
(ΥyiDV⊤xi)⊤∇2ψ(ΥyiDW⊤xi)ΥyiDV⊤xi
∵Corollary C.2"
REFERENCES,0.4909847434119279,"2=
max
V∈Rd×K:∥V∥F =1 N
X"
REFERENCES,0.492371705963939,"i=1
tr

∇2ψ(ΥyiDW⊤xi) ΥyiDV⊤xi(ΥyiDV⊤xi)⊤
|
{z
}"
REFERENCES,0.49375866851595007,(K−1)-by-(K−1) outer product 
REFERENCES,0.49514563106796117,"3=
max
V∈Rd×K:∥V∥F =1 N
X"
REFERENCES,0.49653259361997226,"i=1
vdiag(∇2ψ(ΥyiDW⊤xi))⊤
|
{z
}
Vector of diagonal elements of ∇2ψ"
REFERENCES,0.49791955617198336,"(ΥyiDV⊤xi)⊙2
|
{z
}
entrywise square"
REFERENCES,0.49930651872399445,"≤
max
V∈Rd×K:∥V∥F =1 N
X"
REFERENCES,0.5006934812760055,"i=1
R(W)1⊤(ΥyiDV⊤xi)⊙2
∵replace each entry of vdiag with risk"
REFERENCES,0.5020804438280166,"In equality 2 we took trace of a scalar (the expression in equality 1 is a scalar, so taking the trace of it
will not change the value) and used the cyclic property. For equality 3: as per Equation (28), ∇2ψ is
a diagonal matrix. Finally, in the last inequality, we bound each element of the diagonal vector (i.e.
exp (−ui) for all i ∈[K −1]). Dropping the R(W) and “maxV∈Rd×K:∥V∥F =1” from the front: N
X"
REFERENCES,0.5034674063800277,"i=1
1⊤(ΥyiDV⊤xi)⊙2 = N
X"
REFERENCES,0.5048543689320388,"i=1
(ΥyiDV⊤xi)⊤ΥyiDV⊤xi = N
X"
REFERENCES,0.5062413314840499,"i=1
tr
 
(ΥyiDV⊤xi)⊤ΥyiDV⊤xi
 = N
X"
REFERENCES,0.507628294036061,"i=1
tr

D⊤Υ⊤
yiΥyiDV⊤xix⊤
i V

Note that V⊤xi ∈RK ≤ N
X"
REFERENCES,0.5090152565880721,"i=1
∥D⊤Υ⊤
yiΥyiD∥F ∥V⊤xix⊤
i V∥F
∵Cauchy-Schwarz inequality"
REFERENCES,0.5104022191400832,"Note that we applied Cauchy-Schwarz to the inner product space RK×K with inner product ⟨A, B⟩:=
tr(A⊤B). Now, continuing with the calculation: N
X"
REFERENCES,0.5117891816920943,"i=1
∥D⊤Υ⊤
yiΥyiD∥F ∥V⊤xix⊤
i V∥F ≤ N
X"
REFERENCES,0.5131761442441054,"i=1
∥ΥyiD∥2
F ∥V⊤∥F ∥xix⊤
i ∥F ∥V∥F
∵∥AB∥F ≤∥A∥F ∥B∥F"
REFERENCES,0.5145631067961165,"≤(2K −2) N
X"
REFERENCES,0.5159500693481276,"i=1
∥xi∥2
∵Lemma C.3, ∥xix⊤
i ∥F = ∥xi∥2, ∥V∥F = 1"
REFERENCES,0.5173370319001387,"≤(2K −2) N
X"
REFERENCES,0.5187239944521498,"i=1
∥xi∥ !2"
REFERENCES,0.5201109570041609,"∵for all aj > 0, M ≥1, PM
i=1 a2
j ≤
PM
i=1 aj
2"
REFERENCES,0.521497919556172,"Therefore we have proven that ∥∇2R (w) ∥2 ≤B2R (w), where B =
p"
REFERENCES,0.5228848821081831,"(2K −2) N
X"
REFERENCES,0.5242718446601942,"i=1
∥xi∥.
(31)"
REFERENCES,0.5256588072122053,"Now we will also analyze the Euclidean norm of the gradient, for reasons that will become clear later."
REFERENCES,0.5270457697642164,"∥∇R (w) ∥= ∥∇R (W) ∥F =  N
X"
REFERENCES,0.5284327323162274,"i=1
xi∇ψ
 
ΥyiDW⊤xi
⊤ΥyiD F ≤ N
X i=1"
REFERENCES,0.5298196948682385,"xi∇ψ
 
ΥyiDW⊤xi
⊤ΥyiD

F
∵triangle inequality ≤ N
X"
REFERENCES,0.5312066574202496,"i=1
∥xi∥2
∇ψ
 
ΥyiDW⊤xi

2 ∥ΥyiD∥F
∵∥AB∥F ≤∥A∥F ∥B∥F =
p"
REFERENCES,0.5325936199722607,"(2K −2) N
X"
REFERENCES,0.5339805825242718,"i=1
∥xi∥2
∇ψ
 
ΥyiDW⊤xi

2
∵Lemma C.3 ≤
p"
REFERENCES,0.5353675450762829,"(2K −2) N
X"
REFERENCES,0.536754507628294,"i=1
∥xi∥R (w)
∵for all aj > 0, M ≥1,
qPM
i=1 a2
j ≤PM
i=1 aj"
REFERENCES,0.5381414701803051,"Gradient descent is a special case of steepest descent with the Euclidean norm [Boyd and Vanden-
berghe, 2004]. Thus, we can apply Gunasekar et al. [2018, Lemmas 11 & 12] to see that ∇R (w) →0
even for multiclass exponential loss. Elaborating on this: these lemmas from Gunasekar et al. [2018]
assume a convex risk objective (which we have in the case of multiclass exponential loss). Addition-
ally, they assume that ∥∇R (w)∥≤BR (w) and
∇2R (w)

2 ≤B2R (w). In the above section
we prove these exact results with B as defined in Eqn. 31. Finally, Lemma C.3 below proves that
∥ΥkD∥F =
√"
REFERENCES,0.5395284327323162,2K −2 for all k ∈[K −1].
REFERENCES,0.5409153952843273,"In conclusion, by Gunasekar et al. [2018, Lemma 11], if our learning rate η <
1
B2R(w(0)), we can
use Soudry et al. [2018, Lemma 10]."
REFERENCES,0.5423023578363384,"Finally, we calculate ∥ΥkD∥F which was used in several places above:"
REFERENCES,0.5436893203883495,"Lemma C.3. For each k ∈[K], we have ∥ΥkD∥F =
p"
REFERENCES,0.5450762829403606,2(K −1).
REFERENCES,0.5464632454923717,"Proof. First, if k = K, then ΥK is the identity matrix. In this case, we have ΥkD = D =
[−IK−1
1K−1] is the negative (K −1)-by-(K −1) identity matrix concatenated with the all-ones
vector. Thus,
∥ΥkD∥2
F = ∥D∥2
F = ∥IK−1∥2
F + ∥1K−1∥2 = 2(K −1)"
REFERENCES,0.5478502080443828,"If k ̸= K, then
ΥkD = [−Υk
Υk1K−1]"
REFERENCES,0.5492371705963939,"and so
∥ΥkD∥2
F = ∥Υk∥2
F + ∥Υk1K−1∥2"
REFERENCES,0.550624133148405,"Now, we recall from the definition of Υk (Definition 2.4 of Wang and Scott [2024]) that Υk is
obtained by replacing the k-th column of the identity matrix by the “all-negative-ones” vector. Thus"
REFERENCES,0.5520110957004161,"∥Υk∥2
F = 2(K −1) −1,
and
∥Υk1K−1∥2
F = ∥−ek∥2
F = 1."
REFERENCES,0.5533980582524272,"This proves Lemma C.3, as desired."
REFERENCES,0.5547850208044383,"C.2.3
Exponential Tail"
REFERENCES,0.5561719833564494,"From Eqn. (27), the negative partial derivative of the template is clearly always positive: −∂"
REFERENCES,0.5575589459084604,"∂ui
ψ(u) = e−ui ≥0."
REFERENCES,0.5589459084604715,"From the above, it is clear that the upper and lower bounds in Definition 2.2 hold when u± = 0 and
c = 1."
REFERENCES,0.5603328710124826,"C.3
PairLogLoss [Wang et al., 2022]"
REFERENCES,0.5617198335644937,"Recall that the template of the PairLogLoss is ψ (u) = PK−1
k=1 log (1 + exp (−uk)). By elementary
calculus, we see that ∂ψ(u)"
REFERENCES,0.5631067961165048,"∂uk
= −
e−uk"
REFERENCES,0.5644937586685159,1 + e−uk .
REFERENCES,0.565880721220527,"C.3.1
Convexity"
REFERENCES,0.5672676837725381,We have
REFERENCES,0.5686546463245492,"∇2ψ(u) = diag

eui/ (1 + eui)2 : i = 1, . . . , K −1

."
REFERENCES,0.5700416088765603,The Hessian is a diagonal matrix with all diagonal entries positive. Hence it is positive definite.
REFERENCES,0.5714285714285714,"C.3.2
β-smoothness"
REFERENCES,0.5728155339805825,"Notice that the partial derivative of the template is exactly the same expression as the derivative of
the logistic loss (i.e. binary cross-entropy). Thus, the exact same proof as logistic loss can be used to
prove β-smoothness for the PairLogLoss as well. Thus, from Appendix C.1.2, β = 1/4 (logistic loss
is simply the K = 2 case for cross-entropy)."
REFERENCES,0.5742024965325936,"C.3.3
Exponential Tail"
REFERENCES,0.5755894590846047,−∂ψ(u)
REFERENCES,0.5769764216366158,"∂uk
=
e−uk"
REFERENCES,0.5783633841886269,1 + e−uk ≤e−uk
REFERENCES,0.579750346740638,This gives us the desired upper tail. As for the lower tail:
REFERENCES,0.5811373092926491,−∂ψ(u)
REFERENCES,0.5825242718446602,"∂uk
=
e−uk"
REFERENCES,0.5839112343966713,1 + e−uk
REFERENCES,0.5852981969486823,"≥e−uk  
1 −e−uk
∵
1
1+x ≥1 −x for all x ≥0 ≥e−uk 1 − K−1
X"
REFERENCES,0.5866851595006934,"i=1
e−ui
!"
REFERENCES,0.5880721220527045,"Thus, PairLogLoss satisfies Definition 2.2 with u± = 0 and c = a = 1."
REFERENCES,0.5894590846047156,"D
Pseudo-index"
REFERENCES,0.5908460471567267,"Note that ΥyiDR(t)⊤xi produces a (K −1)-dimensional vector with entries of the form of
(ryi(t) −rk(t))⊤xi, ∀k ∈[K]\{yi}. For k ∈[K]\{yi}, let us represent the corresponding en-
try of the vector as JΥyiDR(t)⊤xiKk. Note that this indexing is not the same as the kth entry of the
vectors, since the yith entry (ryi(t) −ryi(t))⊤xi is not present in the vector. Similarly, let us define
J−∇ψ
 
ΥyiDW(t)⊤xi

Kk to be the corresponding entry of −∇ψ."
REFERENCES,0.5922330097087378,"This section makes this indexing trick rigorous.
Lemma D.1. Let W ∈Rd×K be arbitrary and w := vec(W) be its vectorization. Let (xi, yi) be a
training sample. Then there exists a bijection that depends only on yi that maps the entries of"
REFERENCES,0.5936199722607489,ΥyDW⊤xi ∈RK−1
REFERENCES,0.59500693481276,"to the elements of the set of “yi-versus-k” relative margins, i.e., {˜x⊤
i,kw ∈R : k ∈[K] \ {yi}}."
REFERENCES,0.5963938973647711,"The following definition makes the bijection from Lemma D.1 concrete.
Definition D.1 (Pseudo-index). In the situation of Lemma D.1, define J·Ki,k : RK−1 →R to be
the coordinate projection such that JΥyiDWxiKi,k = ˜x⊤
i,kw. In other words, J·Ki,k selects the
yi-versus-k relative margin. When the sample index i is clear from context, we drop i from the
subscript and simply write J·Kk."
REFERENCES,0.5977808599167822,"The pseudo-index is useful for working with the exponential tail bounds:
Lemma D.2. In the situation of Lemma D.1, consider ∇ψ(ΥyiDW⊤xi) which is the (K −1)-
dimensional vector of partial derivatives of the template evaluated at ΥyiDW⊤xi. If ψ satisfies
Definition 2.2, then
J−∇ψ(ΥyiDW⊤xi)Kk ≤exp(−˜x⊤
i,kw)
and
J−∇ψ(ΥyiDW⊤xi)Kk ≥(1 −P"
REFERENCES,0.5991678224687933,"r∈[K]\{yi} exp(−˜x⊤
i,rw)) exp(−˜x⊤
i,kw)"
REFERENCES,0.6005547850208044,for all k ∈[K] \ {yi}.
REFERENCES,0.6019417475728155,"D.1
Proofs of Lemma D.1 and Lemma D.2"
REFERENCES,0.6033287101248266,"In both lemmas, we work with a fixed sample, i.e., the index i does not change. As such, we simply
drop the index and write y ←yi, x ←xi, ˜xk ←˜xi,k, and J·Kk ←J·Ki,k."
REFERENCES,0.6047156726768377,"Below, we fix k ∈[K −1] throughout the proof. Let v := w⊤x = [v1, . . . , vK]⊤. Note that"
REFERENCES,0.6061026352288488,ΥyD⊤W⊤x = Υy  
REFERENCES,0.6074895977808599,"vK −v1
...
vK −vK−1 "
REFERENCES,0.608876560332871,"
(32)"
REFERENCES,0.6102635228848821,"We prove Lemma D.1 by considering the case y = K and y ̸= K separately. First, let us consider
the case when y = K. Then Υy is the identity matrix and so"
REFERENCES,0.6116504854368932,"k-th component of Equation (32) is = vK −vk = (wK −wk)⊤x = ˜x⊤
k w."
REFERENCES,0.6130374479889042,"Thus, we’ve proven Lemma D.1 when y = K. In this case, J·Kk simply picks out the k-th entry of
the input (K −1)-dimensional) vector. In other words,"
REFERENCES,0.6144244105409153,"JzKk = zk,
for all z = [z1, . . . , zK−1]⊤∈RK−1 when y = K.
(33)"
REFERENCES,0.6158113730929264,"By definition, we note that the k-th row of Υy is"
REFERENCES,0.6171983356449375,"Υy[k, :] =
ek −ey
: k ̸= y,
−ey
: otherwise."
REFERENCES,0.6185852981969486,"Thus, when y ̸= K"
REFERENCES,0.6199722607489597,"k-th component of Equation (32) =
(vK −vn)
: k ̸= y,
−(vK −vy)
: k = y."
REFERENCES,0.6213592233009708,"=
(wy −wk)⊤x = ˜xk
: k ̸= y,
(wy −wK)⊤x = ˜xK
: k = y."
REFERENCES,0.6227461858529819,"Thus, we’ve proven Lemma D.1 when y ̸= K as well. In this case, J·Kk picks out the k-th element of
the input (K −1)-dimensional) vector when k ̸= y. Otherwise when k = y, we have that J·Kk picks
out the y-th element. More explicitly,"
REFERENCES,0.624133148404993,"JzKk =
zk
: k ̸= y
zy
: k = y ,
for all z = [z1, . . . , zK−1]⊤∈RK−1 when y ̸= K.
(34)"
REFERENCES,0.6255201109570042,"Next, we prove Lemma D.2 by considering the case y = K and y ̸= K separately. First, assume that
we are in the y = K case. From Equation (33), we get that"
REFERENCES,0.6269070735090153,J−∇ψ(ΥyiD⊤W⊤xi)Kk = −∂ψ
REFERENCES,0.6282940360610264,"∂uk
(ΥyiD⊤W⊤xi)"
REFERENCES,0.6296809986130375,"Now, we have that for u = [u1, . . . , uK−1]⊤∈RK−1, the upper and lower exponential tail bounds
are −∂ψ"
REFERENCES,0.6310679611650486,"∂uk
(u) ≤c exp(−uk),
and
−∂ψ"
REFERENCES,0.6324549237170597,"∂uk
(u) ≥c "
REFERENCES,0.6338418862690708,"1 −
X"
REFERENCES,0.6352288488210819,"r∈[K−1]
exp (−ur) "
REFERENCES,0.636615811373093,exp(−uk).
REFERENCES,0.6380027739251041,"Letting u := ΥyiD⊤W⊤xi, using Lemma D.1 and Equation (33), we immediately prove Lemma D.2
in the case when y = K. This is because we have"
REFERENCES,0.6393897364771152,"exp(−uk) = exp(−JΥyiD⊤W⊤xiKk) = exp(−˜x⊤
i,kw) and
X"
REFERENCES,0.6407766990291263,"r∈[K−1]
exp (−ur) =
X"
REFERENCES,0.6421636615811374,"r∈[K]\{yi}
exp (−ur) =
X"
REFERENCES,0.6435506241331485,"k∈[K]\{yi}
exp
 
−˜x⊤
i,kw
"
REFERENCES,0.6449375866851595,"When y = K, a similar argument proves Lemma D.2 using Equation (33) for the pseudo-index J·Kk."
REFERENCES,0.6463245492371706,"E
Proof of Lemma 4.8"
REFERENCES,0.6477115117891817,Re-stating the lemma:
REFERENCES,0.6490984743411928,"Lemma 4.8. (Multiclass generalization of Soudry et al. [2018, Lemma 1]) Consider any linearly
separable dataset, and any PERM loss with template ψ that is convex, β-smooth, strictly decreasing,
and non-negative. For all k ∈{1, ..., K}, let wk(t) be the gradient descent iterates at iteration t for
the kth class. Then ∀i ∈{1, ..., N}, ∀j ∈{1, ..., K}\{yi} : limt→∞(wyi(t) −wj(t))⊤xi →∞."
REFERENCES,0.6504854368932039,"Proof. We know that limt→∞∇R (w (t)) = 0 by Soudry et al. [2018, Lemma 10]."
REFERENCES,0.651872399445215,"This implies that ˆw⊤∇R(w(t)) →0. Following the same steps as in the proof of Lemma 4.4, this is
equivalent to saying:"
REFERENCES,0.6532593619972261,"ˆw⊤∇R(w(t)) = tr(∇ψ
 
ΥyiDW(t)⊤xi
⊤ΥyiD ˆ
W⊤xi) →0."
REFERENCES,0.6546463245492372,"However, for linearly separable data we know that ΥyiD ˆ
W⊤xi ⪰1 (since ˆ
W here is the hard-
margin SVM solution). Thus for the above limit to be true, the limit"
REFERENCES,0.6560332871012483,"lim
t→∞∇ψ
 
ΥyiDW(t)⊤xi

= 0"
REFERENCES,0.6574202496532594,"must hold. By Proposition G.1, we have"
REFERENCES,0.6588072122052705,"lim
t→∞ΥyiDW(t)⊤xi = ∞
∀i ∈[N]"
REFERENCES,0.6601941747572816,where ∞is the “vector” whose entries are all equal to infinity. This is equivalent to
REFERENCES,0.6615811373092927,"lim
t→∞(wyi(t) −wj(t))⊤xi = ∞
∀i ∈[N], ∀j ∈[K]\{yi}"
REFERENCES,0.6629680998613038,(since JΥyiDW(t)⊤xiKj = (wyi(t) −wj(t))⊤xi).
REFERENCES,0.6643550624133149,"Note that in the binary case, the above “convergence-to-infinity” condition is for a scalar quanity,
where the assumption that the loss be strictly decreasing and non-negative suffices. In the multiclass
setting, we must ensure that all entries of the vector ΥyiDW(t)⊤xi converges to infinity. This is a
nontrivial result and is addressed by our Proposition G.1."
REFERENCES,0.665742024965326,"F
Proof of Lemma 4.6"
REFERENCES,0.6671289875173371,Let us first re-state the lemma we want to prove.
REFERENCES,0.6685159500693482,"Lemma 4.6. (Generalization of Soudry et al. [2018, Lemma 20]) Define θ to be the minimum SVM
margin across all data points and classes, i.e., θ = mink
h
minn/∈Sk ˜x⊤
n,k ˆw
i
> 1. Then:"
REFERENCES,0.6699029126213593,"∃C1, C2, t1 : ∀t > t1 : (r (t + 1) −r (t))⊤r (t) ≤C1t−θ + C2t−2"
REFERENCES,0.6712898751733704,"Proof. Proceeding the same way as Soudry et al. [2018], we have"
REFERENCES,0.6726768377253814,(r (t + 1) −r (t))⊤r (t)
REFERENCES,0.6740638002773925,= (−η∇R (w (t)) −ˆw [log (t + 1) −log (t)])⊤r (t)
REFERENCES,0.6754507628294036,"= (−η∇R (w (t)))⊤r(t) −ˆw⊤r(t) log
 
1 + t−1"
REFERENCES,0.6768377253814147,"= ˆw⊤r(t)
 
t−1 −log
 
1 + t−1
+ tr    −η N
X"
REFERENCES,0.6782246879334258,"i=1
xi∇ψ
 
ΥyiDW(t)⊤xi
⊤ΥyiD !⊤ R(t)  "
REFERENCES,0.6796116504854369,"−t−1 ˆw⊤r(t)
(35)"
REFERENCES,0.680998613037448,"The last equality is a new step required for our multiclass generalization, in which we used Lemma
4.2 and introduced the matrices W(t) and R(t), where vec(W(t)) = w(t) and vec(R(t)) = r(t).
Let us focus just on the second term of this expansion. tr    −η N
X"
REFERENCES,0.6823855755894591,"i=1
xi∇ψ
 
ΥyiDW(t)⊤xi
⊤ΥyiD !⊤ R(t)  "
REFERENCES,0.6837725381414702,"(1)
= ηtr N
X"
REFERENCES,0.6851595006934813,"i=1
R(t)⊤xi
 
−∇ψ
 
ΥyiDW(t)⊤xi
⊤ΥyiD !"
REFERENCES,0.6865464632454924,"(2)
= ηtr N
X i=1"
REFERENCES,0.6879334257975035," 
−∇ψ
 
ΥyiDW(t)⊤xi
⊤ΥyiDR(t)⊤xi ! (36)"
REFERENCES,0.6893203883495146,"In step (1) we used the fact that for any square matrix M, tr(M) = tr
 
M⊤
. In step (2) we used the
cyclic property of the trace."
REFERENCES,0.6907073509015257,"Similar to in the proof of Lemma 4.4, the trace’s cyclic property has enabled us to convert a matrix-
product into a simple dot product. Since dot products are scalars, we can now drop the trace and
rewrite our expression in Eqn. (36) as a dot product: η N
X i=1 X"
REFERENCES,0.6920943134535368,"k∈[K]\{yi}
J−∇ψ
 
ΥyiDW(t)⊤xi

KkJΥyiDR(t)⊤xiKk"
REFERENCES,0.6934812760055479,"Using this form, we can rewrite Eqn. (35):"
REFERENCES,0.694868238557559,"(r (t + 1) −r (t))⊤r (t) = ˆw⊤r(t)
 
t−1 −log
 
1 + t−1 + η N
X i=1 X"
REFERENCES,0.6962552011095701,"k∈[K]\{yi}
J−∇ψ
 
ΥyiDW(t)⊤xi

KkJΥyiDR(t)⊤xiKk"
REFERENCES,0.6976421636615812,"−t−1 ˆw⊤r(t)
(37)"
REFERENCES,0.6990291262135923,"The first term ˆw⊤r(t)
 
t−1 −log
 
t−1
is bounded in [Soudry et al., 2018, Eqn. (139)]. We will
focus on the second and third terms. Recall by Equation (6) and Equation (8) that ˆw = N
X i=1 X"
REFERENCES,0.7004160887656034,"k∈[K]\{yi}
αi,k1{i∈Sk}˜xi,k = N
X i=1 X"
REFERENCES,0.7018030513176144,"k∈[K]\{yi}
η exp(−˜w⊤˜xi,k)1{i∈Sk}˜xi,k"
REFERENCES,0.7031900138696255,"Thus, the third term on the RHS of Equation (37) can be written as"
REFERENCES,0.7045769764216366,"t−1 ˆw⊤r(t) = η N
X i=1 X"
REFERENCES,0.7059639389736477,"k∈[K]\{yi}
t−1 exp(−˜w⊤˜xi,k)˜x⊤
i,kr(t)1{i∈Sk}"
REFERENCES,0.7073509015256588,"Therefore, the last two terms on the RHS of Equation (37) can be written as η N
X i=1 X"
REFERENCES,0.7087378640776699,"k∈[K]\{yi}
J−∇ψ
 
ΥyiDW(t)⊤xi

KkJΥyiDR(t)⊤xiKk −t−1 ˆw⊤r(t)"
REFERENCES,0.710124826629681,"= η
 N
X i=1 X"
REFERENCES,0.7115117891816921,"k∈[K]\{yi}
J−∇ψ
 
ΥyiDW(t)⊤xi

KkJΥyiDR(t)⊤xiKk"
REFERENCES,0.7128987517337032,"−t−1 exp(−˜w⊤˜xi,k)˜x⊤
i,kr(t)1{i∈Sk}
"
REFERENCES,0.7142857142857143,"Since η > 0 is constant, we ignore it below and consider only the term inside the parenthesis: N
X i=1 X"
REFERENCES,0.7156726768377254,"k∈[K]\{yi}
J−∇ψ
 
ΥyiDW(t)⊤xi

KkJΥyiDR(t)⊤xiKk"
REFERENCES,0.7170596393897365,"−t−1 exp(−˜w⊤˜xi,k)˜x⊤
i,kr(t)1{i∈Sk} (1)
= N
X i=1 X"
REFERENCES,0.7184466019417476,k∈[K]\{yi}
REFERENCES,0.7198335644937587," 
J−∇ψ
 
ΥyiDW(t)⊤xi

Kk"
REFERENCES,0.7212205270457698,"−t−1 exp(−˜w⊤˜xi,k)1{i∈Sk}
˜x⊤
i,kr(t) (2)
≤ N
X i=1 X"
REFERENCES,0.7226074895977809,k∈[K]\{yi}
REFERENCES,0.723994452149792," 
exp
 
−w(t)⊤˜xi,k
"
REFERENCES,0.7253814147018031,"−t−1 exp(−˜w⊤˜xi,k)1{i∈Sk}
˜x⊤
i,kr(t)1{˜x⊤
i,kr(t)≥0} + N
X i=1 X"
REFERENCES,0.7267683772538142,k∈[K]\{yi}
REFERENCES,0.7281553398058253,"
exp
 
−w(t)⊤˜xi,k
  
1 −
X"
REFERENCES,0.7295423023578363,"k∈[K]
exp(−w(t)⊤˜xi,k)
"
REFERENCES,0.7309292649098474,"−t−1 exp(−˜w⊤˜xi,k)1{i∈Sk}

˜x⊤
i,kr(t)1{˜x⊤
i,kr(t)<0}.
(38)"
REFERENCES,0.7323162274618585,"In (1) we used Lemma D.1, which implies that ˜x⊤
i,kr(t) = JΥyiDR(t)⊤xiKk. For (2), from the
exponential tail upper/lower bound and Lemma D.2, we have that"
REFERENCES,0.7337031900138696,"exp
 
−w(t)⊤˜xi,k

≥J−∇ψ
 
ΥyiDW(t)⊤xi

Kk"
REFERENCES,0.7350901525658807,"≥exp
 
−w(t)⊤˜xi,k
 
1 −
X"
REFERENCES,0.7364771151178918,"k∈[K]\{yi}
exp(−w(t)⊤˜xi,k)

."
REFERENCES,0.7378640776699029,"We note that Eqn. (38) above is identical to the right hand side of inequality (1) in [Soudry et al.,
2018, Eqn. (141)]. Thus, the remainder of the analysis proceeds identically as in Soudry et al. [2018,
Lemma 20]."
REFERENCES,0.739251040221914,"G
A structural result on symmetric and convex functions"
REFERENCES,0.7406380027739251,"Proposition G.1. Let ψ : RK−1 →R be the template of a PERM loss that satisfies our Theorem 3.4.
Let ut ∈RK−1 be any sequence, where t = 1, 2, . . ., such that"
REFERENCES,0.7420249653259362,"lim
t→∞∇ψ(ut) = 0"
REFERENCES,0.7434119278779473,"is the zero vector. Then limt→∞ut
j = ∞for every j ∈[K −1]."
REFERENCES,0.7447988904299584,"We prove Proposition G.1 by first proving a structural result (Theorem G.2) concerning symmetric
and convex function f : Rn →R. The proof of Proposition G.1 will be presented in Appendix G.2
as an application of the structural result, where we take f = ψ, the template of a PERM loss, and
n = K −1, number of classes minus one."
REFERENCES,0.7461858529819695,"Given a vector x ∈Rn and a real number C ∈R, define x ∨C ∈Rn to be the vector such that"
REFERENCES,0.7475728155339806,"[x ∨C]i := max{xi, C},
for all i ∈[n]."
REFERENCES,0.7489597780859917,"In other words, x ∨C “boosts” entries of x up to C if those entries are smaller than C. Entries of x
larger than C are kept as-is."
REFERENCES,0.7503467406380028,"Define min(x) = minj∈[n] xj and argmin(x) := {i ∈[n] : xi = min(x)}. We note the following
easy-to-prove properties of the “∨” operation:"
REFERENCES,0.7517337031900139,"1. min(x ∨C) ≥C with equality if min(x) ≤C,"
REFERENCES,0.753120665742025,2. argmin(x ∨C) ⊇argmin(x).
REFERENCES,0.7545076282940361,"Theorem G.2. Suppose that f : Rn →R is a symmetric, convex, and differentiable function. Then
for any real number C ∈R and any x ∈Rn, we have"
REFERENCES,0.7558945908460472,"∂f
∂xi (x) ≤∂f"
REFERENCES,0.7572815533980582,"∂xi (x ∨C),
for any i ∈argmin(x)."
REFERENCES,0.7586685159500693,"Before proceeding with the proof (which is in Appendix G.1), we first introduce some necessary
preliminary notations and facts. Given a vector x ∈Rn, we define"
REFERENCES,0.7600554785020804,"val(x) := {xi : i = 1, . . . , n}"
REFERENCES,0.7614424410540915,"to be the set of values consistings of the entries of x. For example, if x is the all-ones vector, then
val(x) = {1}. Given v ∈val(x), we let idx(v, x) = {i ∈x : xi = v} be the set of indices that
attains the value v."
REFERENCES,0.7628294036061026,"Fact 1: For a convex and differentiable function f : Rn →R, we have that"
REFERENCES,0.7642163661581137,"⟨∇f(x) −∇f(y), x −y⟩≥0,
for all x, y ∈Rn.
(39)"
REFERENCES,0.7656033287101248,"This is a simple and well-known consequence of convexity. See this stackexchange answer for a short
proof. When n = 1, Ineq. (39) is the fact that a convex differentiable function has nondecreasing
derivative. Ineq. (39) is also a consequence of [Phelps, 2009, Theorem 3.24]."
REFERENCES,0.7669902912621359,"Fact 2: For a symmetric and differentiable function f : Rn →R, we have that"
REFERENCES,0.768377253814147,"∂f
∂xi (x) =
∂f
∂xj (x),
whenever xi = xj.
(40)"
REFERENCES,0.7697642163661581,"This fact follows from the chain rule and the definition of a symmetric function. To be precise, let
T : Rn →Rn be the permutation matrix that switches the i and j-th coordinate. Then f(x) = f(Tx)
and moreover ∂f"
REFERENCES,0.7711511789181692,∂xi (x) = ∂f
REFERENCES,0.7725381414701803,"∂xi (Tx) = [T∇f(Tx)]i = [∇f(Tx)]j = [∇f(x)]j =
∂f
∂xj (x)."
REFERENCES,0.7739251040221914,"G.1
Proof of Theorem G.2"
REFERENCES,0.7753120665742025,"Now, to prove the above theorem, we will use induction on “m” in the following lemma, which is
simply a “stratification” of Theorem G.2 into cases indexed by the “parameter” m:
Lemma G.3. Suppose that f : Rn →R is a convex, symmetric, and differentiable function. Let
m ∈{0, 1, . . . , n}. Then for any real number C ∈R and any x ∈Rn with the property that
|{v ∈val(x) : v < C}| = m, we have"
REFERENCES,0.7766990291262136,"∂f
∂xi (x) ≤∂f"
REFERENCES,0.7780859916782247,"∂xi (x ∨C),
for any i ∈argmin(x)."
REFERENCES,0.7794729542302358,"Note that if we have proved Lemma G.3 for each m ∈{0, 1, . . . , n}, then Theorem G.2 holds."
REFERENCES,0.7808599167822469,"The base step: we prove Lemma G.3 when m = 0 and m = 1. Strictly speaking, the proof-by-
induction technique typically only involve only the base case, which would be the m = 0 case in this
instance. But below, we will see that in the induction step, the m = 1 case is helpful."
REFERENCES,0.782246879334258,"Note that the m = 0 case holds vacuously, since x ∨C = x. Below, we focus on the m = 1 case,
where there exists a unique v ∈val(x) such that v ≤C. Let i ∈argmin(x). Note that we have
idx(v, x) = argmin(x). Using Equation (39) (Fact 1), we have that"
REFERENCES,0.7836338418862691,"⟨∇f(x ∨C) −∇f(x), (x ∨C) −x⟩≥0."
REFERENCES,0.7850208044382802,"Definition G.1. Given any set S ⊆[n], we let χS ∈Rn denote the characteristic vector on S: χS is
the vector whose jth entry is = 1 if j ∈S and = 0 otherwise."
REFERENCES,0.7864077669902912,"By construction, we have"
REFERENCES,0.7877947295423023,"(x ∨C) −x = (C −v)χidx(v,x) = (C −v)χargmin(x)."
REFERENCES,0.7891816920943134,The “ ∂f
REFERENCES,0.7905686546463245,"∂xi (·)” notation for partial derivatives is a bit cumbersome. Instead, we will write “[∇f(·)]i”
from now on. By Equation (40) (Fact 2), we have"
REFERENCES,0.7919556171983356,"[∇f(x)]j = [∇f(x)]j′,
for all j, j′ ∈idx(v, x)"
REFERENCES,0.7933425797503467,"and likewise
[∇f(x ∨C)]j = [∇f(x ∨C)]j′,
for all j, j′ ∈idx(v, x)."
REFERENCES,0.7947295423023578,"Thus, by Equation (40), we have"
REFERENCES,0.7961165048543689,"⟨∇f(x ∨C) −∇f(x), (x ∨C) −x⟩= |argmin(x)| · (C −v)([∇f(x ∨C)]i −[∇f(x)]i)."
REFERENCES,0.79750346740638,"Now, since C > v and |argmin(x)| > 0, we must have that [∇f(x ∨C)]i −[∇f(x)]i ≥0, as
desired. This proves the base step."
REFERENCES,0.7988904299583911,"Induction step: Suppose Lemma G.3 holds for every integer m where 0 ≤m < n, we must
show that Lemma G.3 also holds for m + 1. To this end, let x ∈Rn and C ∈R be such that
|{v ∈val(x) : v < C}| = m+1. Let v1, . . . , vm+1 ∈R be all the elements of {v ∈val(x) | v < C}
enumerated in increasing order, i.e., v1 < · · · < vm+1."
REFERENCES,0.8002773925104022,"Note by construction, we have that {v ∈val(x) | v < vm+1} = {v1, . . . , vm} and so we immediately
get that |{v ∈val(x) | v < vm+1}| = m. By the m-th case of Lemma G.3 (i.e., the induction
hypothesis) using vm+1 as C, we get"
REFERENCES,0.8016643550624133,"[∇f(x ∨vm+1)]i ≥[∇f(x)]i
for any i ∈argmin(x).
(41)"
REFERENCES,0.8030513176144244,"Below fix some i ∈argmin(x) arbitrarily. Let x′ := x ∨vm+1. We note that by construction, all the
entries of x′ that are less than C are set to equal to vm+1. In other words,"
REFERENCES,0.8044382801664355,{v ∈val(x′) : v < C} = {vm+1}
REFERENCES,0.8058252427184466,"is a singleton set. Thus, by the m = 1 case of Lemma G.3 applied to x′, we get that"
REFERENCES,0.8072122052704577,"[∇f(x′ ∨C)]i′ ≥[∇f(x′)]i′,
for any i′ ∈argmin(x′)."
REFERENCES,0.8085991678224688,"Since argmin(x′) ⊇argmin(x), we have that i ∈argmin(x′) as well (recall that i was chosen
earlier from argmin(x) arbitrarily). Thus the above inequality implies in particular that"
REFERENCES,0.8099861303744799,[∇f(x′ ∨C)]i ≥[∇f(x′)]i = [∇f(x ∨vm+1)]i.
REFERENCES,0.811373092926491,"Combined with Equation (41), we get"
REFERENCES,0.812760055478502,[∇f(x′ ∨C)]i ≥[∇f(x)]i.
REFERENCES,0.8141470180305131,"Finally, we note that x′ ∨C = (x ∨vm+1) ∨C = x ∨C. Thus, the above implies"
REFERENCES,0.8155339805825242,"[∇f(x ∨C)]i ≥[∇f(x)]i
for any i ∈argmin(x)"
REFERENCES,0.8169209431345353,since the choice of i ∈argmin(x) was arbitrary.
REFERENCES,0.8183079056865464,"G.2
Application to our setting"
REFERENCES,0.8196948682385575,"The condition limt→∞ut
j = ∞by definition means that for every real number M ∈R, there exists
T such that for all t ≥T we have ut
j > M. Thus, suppose that there exists j ∈[K −1] such
that limt→∞ut
j ̸= ∞, then there exists a real number M ∈R such that for all T = 1, 2, . . . there
exists some t ≥T such that ut
j ≤M. Passing to a subsequence, we assume that ut
j ≤M (and so
min(ut) ≤M) for all t = 1, 2, . . .. Note that limt→∞∇ψ(ut) = 0 continues to hold."
REFERENCES,0.8210818307905686,"Below, whenever we say “for all/every t”, we mean “for all/every t = 1, 2, . . .”."
REFERENCES,0.8224687933425797,Onto the proof. First recall the lower bound portion of the exponential tail property:
REFERENCES,0.8238557558945908,"For all u ∈RK−1 such that min(u) > u−, we have"
REFERENCES,0.8252427184466019,"−[∇ψ(u)]i ≥c

1 − K−1
X"
REFERENCES,0.826629680998613,"j=1
exp(−uj)

exp(−ui),
for all i ∈[K −1].
(42)"
REFERENCES,0.8280166435506241,"Let C := max{ 2|u−|, M, −log(
1
2(K−1)) } and vt := ut ∨C for all t. This choice of C (and vt)
has the following consequences:"
REFERENCES,0.8294036061026352,"1. The fact that C ≥−log(
1
2(K−1)) implies

1 −PK−1
j=1 exp(−vj)

≥1 2."
REFERENCES,0.8307905686546463,"2. If v ∈RK−1 is such that min(v) ≥C, then we have by Equation (42) that"
REFERENCES,0.8321775312066574,−[∇ψ(v)]i ≥1
REFERENCES,0.8335644937586685,"2c exp(−vi).
(43)"
REFERENCES,0.8349514563106796,3. min(ut) ≤C. This is true since min(ut) ≤M.
REFERENCES,0.8363384188626907,"4. Choose it ∈argmin(ut) for every t. Then vt
it = min(vt) = C for every t. This is simply
a consequence of the fact that argmin(ut) ⊆argmin(vt)."
REFERENCES,0.8377253814147018,"5. We have limt→∞[∇ψ(ut)]it
=
0.
This follows from the assumption that
limt→∞∇ψ(ut) = 0."
REFERENCES,0.8391123439667129,"By Theorem G.2, we have for every t that"
REFERENCES,0.840499306518724,[∇ψ(ut)]it ≤[∇ψ(vt)]it.
REFERENCES,0.841886269070735,"By plugging in vt for u in Equation (43) above and the fact that vt
it = C, we have"
REFERENCES,0.8432732316227461,[∇ψ(vt)]it ≤−1
REFERENCES,0.8446601941747572,2c exp(−vit) = −1
REFERENCES,0.8460471567267683,2c exp(−C) < 0.
REFERENCES,0.8474341192787794,Since −1
REFERENCES,0.8488210818307905,"2c exp(−C) is a constant that doesn’t depend on t, it is impossible for limt→∞[∇ψ(vt)]it =
0 to hold. This proves Proposition G.1."
REFERENCES,0.8502080443828016,"H
On the existence of ˜w"
REFERENCES,0.8515950069348127,"The goal of this section is to explain the challenge and the current gap in the proof of the existence of
˜w that satisfies the condition in Equation (8) for almost all linearly separable datasets. To this end,
recall Equation (4), the hard-margin SVM formulated as a constrained optimization:"
REFERENCES,0.8529819694868238,"ˆw = argminw
1
2∥w∥2 s.t. ∀n, ∀k ̸= yn : w⊤
ynxn ≥w⊤
k xn + 1.
(44)"
REFERENCES,0.8543689320388349,"Moreover, recall that Sk, the set of support vectors for each k ∈[K], is defined by"
REFERENCES,0.855755894590846,Sk := {n : ( ˆwyn −ˆwk)⊤xn = 1}.
REFERENCES,0.8571428571428571,The Lagrangian of the objective in Equation (44) is
REFERENCES,0.8585298196948682,"L(w, α) = 1 2 K
X"
REFERENCES,0.8599167822468793,"r=1
∥wr∥2 + N
X n=1 X"
REFERENCES,0.8613037447988904,"r̸=yn
αn,r (wyn −wr)⊤xn
(45)"
REFERENCES,0.8626907073509015,"where αn,r are the dual variables. Let δi,j denote the Kronecker delta, i.e., δi,j = 1 if i = j and
δi,j = 0 otherwise. Taking the gradient of L(w, α) with respect to wk, we get wk + N
X n=1 X"
REFERENCES,0.8640776699029126,"r̸=yn
αn,k (δr,yn −δr,k) xn = wk + N
X n=1 "
REFERENCES,0.8654646324549237,"δk,yn
X"
REFERENCES,0.8668515950069348,"r̸=yn
αn,r −αn,k  xn."
REFERENCES,0.8682385575589459,"So the KKT conditions satisfied by a stationary point ˆw (hence globally optimal for Equation (44))
are"
REFERENCES,0.869625520110957,"∀k ∈[K] : ˆwk = N
X n=1 "
REFERENCES,0.871012482662968,"αn,k −δk,yn
X"
REFERENCES,0.8723994452149791,"r̸=k
αn,r "
REFERENCES,0.8737864077669902,"xn
(46)"
REFERENCES,0.8751733703190014,∀k ∈[K] : ∀n : one of the following holds
REFERENCES,0.8765603328710125,"(
αn,k ≥0 and ( ˆwyn −ˆwk)⊤xn = 1
αn,k = 0 and ( ˆwyn −ˆwk)⊤xn > 1
(47)"
REFERENCES,0.8779472954230236,where Eqn. (47) (the second line) above is the complementary slackness condition.
REFERENCES,0.8793342579750347,"The goal of this section is to prove the following result regarding the existence of ˜w that satisfies the
condition in Equation (8), which we restate below:"
REFERENCES,0.8807212205270458,"∀k ∈[K], ∀n ∈Sk : η exp
 
−x⊤
n ( ˜wyn −˜wk)

= αn,k.
(48)"
REFERENCES,0.8821081830790569,"Conjecture H.1. For almost all linearly separable multiclass datasets, Assumption 4.1 holds, i.e.,
Eqn. (48) has a solution ˜w."
REFERENCES,0.883495145631068,"Below, we use the word “generically” to mean “for linearly separable datasets outside of a set of
Lebesgue measure zero”. In order for (48) to have a solution in ˜w generically, two conditions need to
hold (generically)."
REFERENCES,0.8848821081830791,"Condition 1. αn,k > 0 for all k and n such that n ∈Sk := {n : ( ˆwyn −ˆwk)⊤xn = 1}."
REFERENCES,0.8862690707350902,"Condition 1 is already nontrivial and a gap in proving the Conjecture, as we will see below. For the
sake of explaining Condition 2 below, let us assume Condition 1 holds. Then we can rewrite (48) as"
REFERENCES,0.8876560332871013,"∀k ∈[K], ∀n ∈Sk : x⊤
n ( ˜wyn −˜wk) = log
 η αn,k"
REFERENCES,0.8890429958391124,"
.
(49)"
REFERENCES,0.8904299583911235,"Define the vector mn,k obtained by taking the difference between the k-th and yn-th elementary
basis vector in RK, i.e.,"
REFERENCES,0.8918169209431346,"mn,k := ek −eyn ∈RK."
REFERENCES,0.8932038834951457,Then we can further rewrite (49) as
REFERENCES,0.8945908460471568,"∀k ∈[K], ∀n ∈Sk : (mn,k ⊗xn)⊤˜w = log
 η αn,k"
REFERENCES,0.8959778085991679,"
.
(50)"
REFERENCES,0.897364771151179,"It is more convenient to pool all the class-specific support vectors Sk into a single set: S ≜
n
(n, k) : ( ˆwyn −ˆwk)⊤xn = 1
o
. For readability, we linearly order the tuples in S, i.e., we as-
sign to each (n, k) ∈S a unique index i ∈{1, ..., |S|}. In other words, we define n(1), . . . , n(|S|)
and k(1), . . . , k(|S|) such that"
REFERENCES,0.8987517337031901,"S = {(n(1), k(1)), (n(2), k(2)), . . . , (n(|S|), k(|S|))}."
REFERENCES,0.9001386962552012,"To reduce notational clutter in the subscript, define xi ≜xn(i) and mi ≜mn(i),k(i). Finally, define M ≜
"
REFERENCES,0.9015256588072122,"m1, . . . , m|S|

RK×|S|, X ≜
"
REFERENCES,0.9029126213592233,"x1, . . . , x|S|

∈Rd×|S|, and G ≜(M ◦X) ∈RdK×|S|."
REFERENCES,0.9042995839112344,"with ◦denoting the Khatri-Rao product, which is, by definition, the matrix obtained by taking the
Kronecker product of corresponding columns [Khatri and Rao, 1968]. Note that the Khatri-Rao
product is only defined for two matrices that have the same number of columns. See Liu [1999] for a
reference. We now state"
REFERENCES,0.9056865464632455,Condition 2. rank(G) = |S| generically.
REFERENCES,0.9070735090152566,"Note that given Condition 2, Eqn. (50) has a solution in ˜w, while Condition 1 is necessary for the
logarithm in (50) to be valid in the first place."
REFERENCES,0.9084604715672677,"The challenge in proving Condition 2 in the multiclass case is that the column vectors of X may
have repeats, i.e., it is possible for n(i) = n(i′) when i ̸= i′. It is easy to generate synthetic linearly"
REFERENCES,0.9098474341192788,"Figure 2: Small simulation with N = 10, d = 2 and K = 3. The loss used is the “PairLogLoss”.
Top row. Decision regions of classifiers along the gradient path w(t) at t = 100, 1000, and 100000,
respectively from left to right. Bottom row. Decision regions of the hard-margin multiclass SVM.
Note that most of the progress is made between iterations 100 and 1000."
REFERENCES,0.9112343966712899,"separable multiclass datasets satisfying this condition. Nonetheless, we observe that even in such a
case, the matrix G has rank |S|, i.e., Condition 2 holds. We verify this experimentally in the Python
notebook checking_conjecture_in_Appendix_H.ipynb available at"
REFERENCES,0.912621359223301,https://github.com/YutongWangML/neurips2024-multiclass-IR-figures
REFERENCES,0.9140083217753121,"In the binary case, linear classifiers are parametrized simply as a single vector, rather than the more
cumbersome one-vector-per-class parametrization. Under the one-vector parametrization, the M
matrix becomes a 1-by-|S| matrix consistings of only ±1’s, and G reduces to X. Moreover X has no
repeats. Thus, Condition 2 holds trivially. In both the multiclass and binary settings, given Condition
2, the proof for Condition 1 can proceed exactly as in Lemma 12 from Soudry et al. [2018] where
their XS is replaced by our G."
REFERENCES,0.9153952843273232,"I
Additional Experiments"
REFERENCES,0.9167822468793343,"We provide additional experimental support for our main theoretical result for the PairLogLoss [Wang
et al., 2022]. Code for recreating the figures can be found at"
REFERENCES,0.9181692094313454,https://github.com/YutongWangML/neurips2024-multiclass-IR-figures
REFERENCES,0.9195561719833565,The code can be ran on Google Colab with a CPU runtime in under one hour.
REFERENCES,0.9209431345353676,"Figure 3: Large simulations with N = 100, d = 10 and K = 3. The loss used is the “PairLogLoss”.
The curves are 10 independent runs with randomly sampled data and random initialization for gradient
descent over 100000 iterations. Note that the convergence in direction of the gradient descent iterates
to the hard-margin SVM slows down in log-log space."
REFERENCES,0.9223300970873787,NeurIPS Paper Checklist
CLAIMS,0.9237170596393898,1. Claims
CLAIMS,0.9251040221914009,"Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: Our abstract clearly introduces the problem considered (implicit bias), identifies
a gap in research (few multiclass results, which themselves are only for cross-entropy), and
states our contributions (new ET property and implicit bias theorem for new losses). For the
sake of brevity we do not state additional assumptions on the loss apart from ET (which we
state later in the main text, i.e. smoothness, strictly decreasing, non-negative), because the
ET property is a novel contribution and deserves to appear in the abstract.
Guidelines:"
CLAIMS,0.926490984743412,"• The answer NA means that the abstract and introduction do not include the claims
made in the paper.
• The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
• The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
• It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2. Limitations"
CLAIMS,0.9278779472954231,"Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: We have a separate section where we talk about our work’s limitations. We
highlight 2 natural questions one can ask: non-ET loss characterization, and non-asymptotic
analysis (answering whether overfitting occurs after some finite number of (S)GD timesteps).
Guidelines:"
CLAIMS,0.9292649098474342,"• The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate ""Limitations"" section in their paper.
• The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
• The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
• The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
• The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
• If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
• While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3. Theory Assumptions and Proofs"
CLAIMS,0.9306518723994452,"Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: All assumptions are stated clearly in bold at the beginning of section 3, and
also re-iterated multiple times throughout the paper, The assumption on the learning rate
being sufficiently small is mentioned in the theorem statement. Partial proofs are provided
in the main text because they highlight salient features of our techniques (namely, simple
generalization of binary proof techniques to multiclass). Complete proofs are provided in
the appendix.
Guidelines:"
CLAIMS,0.9320388349514563,"• The answer NA means that the paper does not include theoretical results.
• All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
• All assumptions should be clearly stated or referenced in the statement of any theorems.
• The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
• Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4. Experimental Result Reproducibility"
CLAIMS,0.9334257975034674,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: We use a simple synthetic setup which can be reproduced easily with Google
Colab."
CLAIMS,0.9348127600554785,Guidelines:
CLAIMS,0.9361997226074896,"• The answer NA means that the paper does not include experiments.
• If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
• If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
• Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
• While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a) If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b) If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c) If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d) We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5. Open access to data and code"
CLAIMS,0.9375866851595007,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: In Appendices H and I, we include a link to our GitHub repo which contains
the complete code to reproduce the experiments.
Guidelines:"
CLAIMS,0.9389736477115118,"• The answer NA means that paper does not include experiments requiring code.
• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
public/guides/CodeSubmissionPolicy) for more details.
• While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
• The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines (https:
//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
• The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
• The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why."
CLAIMS,0.9403606102635229,"• At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
• Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted."
CLAIMS,0.941747572815534,6. Experimental Setting/Details
CLAIMS,0.9431345353675451,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?"
CLAIMS,0.9445214979195562,Answer: [Yes]
CLAIMS,0.9459084604715673,Justification: All details can be found in the GitHub repository.
CLAIMS,0.9472954230235784,Guidelines:
CLAIMS,0.9486823855755895,"• The answer NA means that the paper does not include experiments.
• The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
• The full details can be provided either with the code, in appendix, or as supplemental
material."
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9500693481276006,7. Experiment Statistical Significance
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9514563106796117,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9528432732316228,Answer: [No]
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9542302357836339,"Justification: Our experiments are used to illustrate the main theoretical result, which is of
mathematical nature. All experiments support the convergence behavior that we analyzed."
EXPERIMENT STATISTICAL SIGNIFICANCE,0.955617198335645,Guidelines:
EXPERIMENT STATISTICAL SIGNIFICANCE,0.957004160887656,"• The answer NA means that the paper does not include experiments.
• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
• The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
• The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
• It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
• It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
• For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
• If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text."
EXPERIMENTS COMPUTE RESOURCES,0.9583911234396671,8. Experiments Compute Resources
EXPERIMENTS COMPUTE RESOURCES,0.9597780859916782,"Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?"
EXPERIMENTS COMPUTE RESOURCES,0.9611650485436893,"Answer: [Yes]
Justification: Yes, the experiments can be run with a Google Colab CPU runtime as men-
tioned in the Appendix."
EXPERIMENTS COMPUTE RESOURCES,0.9625520110957004,Guidelines:
EXPERIMENTS COMPUTE RESOURCES,0.9639389736477115,"• The answer NA means that the paper does not include experiments.
• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
• The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
• The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper)."
CODE OF ETHICS,0.9653259361997226,9. Code Of Ethics
CODE OF ETHICS,0.9667128987517337,"Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?"
CODE OF ETHICS,0.9680998613037448,Answer: [Yes]
CODE OF ETHICS,0.9694868238557559,Justification: [NA]
CODE OF ETHICS,0.970873786407767,Guidelines:
CODE OF ETHICS,0.9722607489597781,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
• If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction)."
BROADER IMPACTS,0.9736477115117892,10. Broader Impacts
BROADER IMPACTS,0.9750346740638003,"Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?"
BROADER IMPACTS,0.9764216366158114,Answer: [NA]
BROADER IMPACTS,0.9778085991678225,Justification: [NA]
BROADER IMPACTS,0.9791955617198336,Guidelines:
BROADER IMPACTS,0.9805825242718447,"• The answer NA means that there is no societal impact of the work performed.
• If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
• Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
• The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
• The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
• If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML)."
SAFEGUARDS,0.9819694868238558,11. Safeguards
SAFEGUARDS,0.9833564493758669,"Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?"
SAFEGUARDS,0.984743411927878,Answer: [NA]
SAFEGUARDS,0.986130374479889,"Justification: [NA]
Guidelines:"
SAFEGUARDS,0.9875173370319001,"• The answer NA means that the paper poses no such risks.
• Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
• Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
• We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12. Licenses for existing assets"
SAFEGUARDS,0.9889042995839112,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [NA]
Justification: [NA]
Guidelines:"
SAFEGUARDS,0.9902912621359223,"• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
• The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
• For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
• If assets are released, the license, copyright information, and terms of use in the package
should be provided. For popular datasets, paperswithcode.com/datasets has
curated licenses for some datasets. Their licensing guide can help determine the license
of a dataset.
• For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
• If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13. New Assets"
SAFEGUARDS,0.9916782246879334,"Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: [NA]
Guidelines:"
SAFEGUARDS,0.9930651872399445,"• The answer NA means that the paper does not release new assets.
• Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
• The paper should discuss whether and how consent was obtained from people whose
asset is used.
• At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14. Crowdsourcing and Research with Human Subjects"
SAFEGUARDS,0.9944521497919556,"Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?"
SAFEGUARDS,0.9958391123439667,"Answer: [NA]
Justification: [NA]
Guidelines:"
SAFEGUARDS,0.9972260748959778,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: [NA]
Guidelines:"
SAFEGUARDS,0.9986130374479889,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
• We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
• For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review."
