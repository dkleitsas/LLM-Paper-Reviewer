Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.00273224043715847,"Black-box optimization formulations for biological sequence design have drawn
recent attention due to their promising potential impact on the pharmaceutical
industry.
In this work, we propose to unify two seemingly distinct worlds:
likelihood-free inference and black-box optimization, under one probabilistic
framework. In tandem, we provide a recipe for constructing various sequence
design methods based on this framework. We show how previous optimization
approaches can be “reinvented” in our framework, and further propose new prob-
abilistic black-box optimization algorithms. Extensive experiments on sequence
design application illustrate the beneﬁts of the proposed methodology."
INTRODUCTION,0.00546448087431694,"1
INTRODUCTION"
INTRODUCTION,0.00819672131147541,"Discovering new drugs to fulﬁll speciﬁc criteria, such as binding afﬁnity towards a given molecular
target, is a fundamental problem in chemistry and the pharmaceutical industry (Hughes et al., 2011).
In this work, we focus on an important subdomain: de novo biological sequence design. This task is
challenging for two reasons: (1) the exploration space for sequences is combinatorially large; and (2)
sequence usefulness is evaluated via a complicated process which usually involves time-consuming
and expensive wet-lab experiments."
INTRODUCTION,0.01092896174863388,"Despite the difﬁculty of this task, many approaches have been developed over the past few decades
thanks to recent advances in biochemistry and machine learning. The Nobel Prize wining paradigm,
directed evolution (Chen & Arnold, 1991), which conducts local evolutionary search under human
guidance, is one of the popular techniques. Unfortunately, it is limited by its sample inefﬁciency
and reliance on strong prior knowledge, e.g., about where to mutate (Ahn et al., 2020). Further-
more, to compete with other machine learning methods (Gottipati et al., 2020), guided evolution
(Yoshikawa et al., 2018; Jensen, 2019; Nigam et al., 2019) heavily relies on human intuition for
designing domain-speciﬁc evolutionary operators, which may not always apply to tasks at hand."
INTRODUCTION,0.01366120218579235,"In this work, we deem sequence design to be a black-box optimization problem, tasked with maxi-
mizing an unknown oracle function. We assume that oracle queries are limited due to the constraint
on resources, such as the budgets for evaluating queries in a wet-lab. Thus, sample efﬁciency is
crucial. We develop a probabilistic framework by reformulating the aforementioned black-box opti-
mization target as a posterior modeling problem. With this framework, we draw a surprising connec-
tion between likelihood-free inference and sequence design, and thus linking two ﬁelds which are
previously considered as unrelated. The key observation we leverage here for establishing this con-
nection is that both settings share similar elements and targets which will be elaborated in Section
2.2. This connection facilitates our understanding of both ﬁelds and provides a recipe for developing
sequence design algorithms. Going beyond, we also combine different probabilistic modeling in-
sights and develop three novel composite probabilistic algorithms. We point out that our framework
could actually be applied to any black-box optimization settings, but in this work we focus on its
application to biological sequence design."
INTRODUCTION,0.01639344262295082,"To demonstrate the empirical effectiveness of our methods, we conduct systematical experiments
to evaluate their performance on four in-silico sequence design benchmarks. Our proposed meth-"
INTRODUCTION,0.01912568306010929,∗Corresponding Author
INTRODUCTION,0.02185792349726776,Published as a conference paper at ICLR 2022
INTRODUCTION,0.02459016393442623,"ods achieve at least comparable results to existing baselines, and the proposed composite methods
behave consistently better than all other ones across various sequence design tasks."
INTRODUCTION,0.0273224043715847,We summarize our contribution as follows:
INTRODUCTION,0.030054644808743168,"• We develop a probabilistic framework that uniﬁes likelihood-free inference and black-box
optimization."
INTRODUCTION,0.03278688524590164,"• Based on this framework, we provide a recipe for designing algorithms for black-box prob-
lems. We apply these ideas to propose a series of composite design algorithms."
INTRODUCTION,0.03551912568306011,"• We perform systematical evaluation on a series of black-box sequence design benchmarks,
and ﬁnd that these algorithms achieves consistently comparable or better results compared
to previous ones, thus illustrating the beneﬁt of the proposed uniﬁed framework."
A UNIFYING PROBABILISTIC FRAMEWORK,0.03825136612021858,"2
A UNIFYING PROBABILISTIC FRAMEWORK"
BACKGROUND,0.040983606557377046,"2.1
BACKGROUND"
BACKGROUND,0.04371584699453552,"Likelihood-free inference (LFI). We use θ ∈Θ and x ∈X to separately denote the parameters
and the data generated via the mechanism x ∼p(x|θ). In this scenario, LFI refers to a special kind
of Bayesian inference setting where the likelihood function is not tractable but sampling (by sim-
ulation) from the likelihood is feasible. Consider the objective of modeling the Bayesian posterior
when we cannot compute the likelihood p(xo|θ):"
BACKGROUND,0.04644808743169399,"p(θ|xo) ∝p(θ) p(xo|θ)
| {z }
? ,
(1)"
BACKGROUND,0.04918032786885246,"where xo is the observed data, p(θ) is the (given) prior over the model parameters θ, p(x|θ) is the
intractable likelihood function and p(θ|x) is the desired posterior over θ. While we do not have
access to the exact likelihood, we can still simulate (sample) data x from the model simulator: x ∼
p(x|θ). Instead of trying to obtain a numerical value of the generic posterior p(θ|x) for arbitrary x,
LFI only tries to obtain an approximation of p(θ|xo) for the given xo. During the inference process,
we can take advantage of the sampled data: D = {(θi, xi)}n
i=1 where xi ∼p(x|θi) for selected
values of θi."
BACKGROUND,0.05191256830601093,"Biological black-box sequence design. We consider biological sequence design as a black-box
optimization problem:
m∗= arg max
m∈M
f(m),"
BACKGROUND,0.0546448087431694,"where f(·) is the oracle score function, and we would like to discover values of m for which f(m)
is large. In real-world situations, a query of this oracle f could represent a series of wet-lab ex-
periments to measure speciﬁc chemical properties or speciﬁcity for a given binding site target. In
general, these experiments are time- and cost-consuming. As a result, the total number of queries is
limited."
BACKGROUND,0.05737704918032787,"In our setting, we use M = VL to denote the search space for sequences with ﬁxed length L, where
V is the vocabulary for each entry of the sequence: for DNA nucleotides |V| = 4, and for protein
amino acids |V| = 20. For variable length setting, we have M = ∪L∈[Lmin,Lmax]VL, where Lmin and
Lmax are the minimal and maximal length, respectively."
CONNECTING LFI AND BLACK-BOX OPTIMIZATION,0.060109289617486336,"2.2
CONNECTING LFI AND BLACK-BOX OPTIMIZATION"
CONNECTING LFI AND BLACK-BOX OPTIMIZATION,0.06284153005464481,"In order to draw a connection to LFI, we require a probabilistic formulation of the black-box se-
quence design problem. To this end, we relax the goal of searching for a single maximum of the
oracle / score function f to a posterior modeling problem, i.e., ﬁnding a representative sample of the
conﬁgurations of m sampled with probability related to some target posterior. Think of C is the set
of sequences with these desirable conﬁgurations, E is a Boolean event about whether a sequence m
belongs to C, and our goal is to characterize the posterior distribution p(m|E) from which we obtain
the desired sequences. Below, we consider two speciﬁc ways of doing this:"
CONNECTING LFI AND BLACK-BOX OPTIMIZATION,0.06557377049180328,Published as a conference paper at ICLR 2022
CONNECTING LFI AND BLACK-BOX OPTIMIZATION,0.06830601092896176,"Example A. We explicitly deﬁne C (and E accordingly) as all the sequences whose scores are larger
than a given threshold s:"
CONNECTING LFI AND BLACK-BOX OPTIMIZATION,0.07103825136612021,"C = {m|f(m) ≥s}.
(2)"
CONNECTING LFI AND BLACK-BOX OPTIMIZATION,0.07377049180327869,"Here s could be any ﬁxed value, or a certain quantile of a particular score distribution. In this way,
we have p(E|m) = p(m ∈C|m) = 1{f(m) ≥s} where 1{} is the indicator function.
Example B. In a softer version of E and C, we can deﬁne its conditional probability of being true
to follow a Boltzmann distribution:"
CONNECTING LFI AND BLACK-BOX OPTIMIZATION,0.07650273224043716,"p(E|m) = p(m ∈C|m) ∝exp(f(m)/τ).
(3)"
CONNECTING LFI AND BLACK-BOX OPTIMIZATION,0.07923497267759563,"where τ is a temperature parameter. We introduce the exponential because f(·) does not necessarily
take positive values. Any monotone transformation of f(·) to non-negative reals could be used, so
that sequences with larger oracle scores have a greater probability of making E true."
CONNECTING LFI AND BLACK-BOX OPTIMIZATION,0.08196721311475409,"With this posterior objective, our goal now becomes effectively modeling and sampling from the
posterior p(m|E). It is thus natural to resort to the tools of Bayesian inference for this task. In
order to examine this possibility, we draw a detailed comparison between the settings of black-box
sequence design problem and likelihood-free Bayesian inference in Table 1."
CONNECTING LFI AND BLACK-BOX OPTIMIZATION,0.08469945355191257,"Likelihood-free inference
Black-box optimization"
CONNECTING LFI AND BLACK-BOX OPTIMIZATION,0.08743169398907104,"Element
(θ, x)
(m, s)"
CONNECTING LFI AND BLACK-BOX OPTIMIZATION,0.09016393442622951,"Target
p(θ|xo)
p(m|E)"
CONNECTING LFI AND BLACK-BOX OPTIMIZATION,0.09289617486338798,"Constraint
limited simulation: x ∼p(x|θ)
limited query: s ∼f(m)
intractable likelihood: p(x|θ)
black-box oracle: f(m)"
CONNECTING LFI AND BLACK-BOX OPTIMIZATION,0.09562841530054644,Table 1: Correspondence between likelihood-free inference and black-box optimization.
CONNECTING LFI AND BLACK-BOX OPTIMIZATION,0.09836065573770492,"It can be observed that both tasks share similar elements and targets. The two settings also share
similar limitations on the allowed queries, which are too time-consuming and / or cost-intensive.
Notice that in sequence design, the oracle could be either exact or noisy, thus we use the more
general s ∼f(m) formulation rather than s = f(m). We will further present several concrete
examples as demonstrations of this correspondence in the following section."
CONNECTING LFI AND BLACK-BOX OPTIMIZATION,0.10109289617486339,Another way to understand this correspondence is to consider the following mapping T:
CONNECTING LFI AND BLACK-BOX OPTIMIZATION,0.10382513661202186,"T : Θ × X →M × R
(θ, x) 7→(m, s),
s.t. s = −∥x −xo∥."
CONNECTING LFI AND BLACK-BOX OPTIMIZATION,0.10655737704918032,"Here we can see the score value s as a quantitative metric for how close the generated data x (given
θ) is to the target observed data xo. In addition, querying the oracle in the sequence design setting
can also be thought of as follows: (1) sample x ∼p(·|θ) and then (2) calculate s = −∥x −xo∥
under some distance ∥·∥. In this manner, T could conceptually transform any LFI problem into a
black-box optimization task. In this work, we only focus on the application of sequence design."
METHODOLOGY,0.1092896174863388,"3
METHODOLOGY"
METHODOLOGY,0.11202185792349727,"We provide a recipe for designing new sequence design algorithms based on the correspondence in
Section 2.2. The recipe induces different approaches by modeling different probabilistic component
of the Bayesian inference problem. We begin with common algorithm restrictions under this setting."
METHODOLOGY,0.11475409836065574,"Common constraint for algorithms. Due to the restriction of simulation / query in our setting,
we constrain our algorithms to act in a sequential / iterative way, gradually achieving the desired
posterior round by round. Every algorithm starts with an empty dataset D = ∅and an initial
proposal p1(·) = p(·), where p(·) is the prior given by the task. In the r-th round of this multi-round
setting, the algorithm would use the proposal pr(·) of this round to sample a batch of data (θ / m)
for simulation / query, and augment the current dataset D with the newly obtained batch of data. We
use n to denote the batch size for each round’s simulation / query. Afterwards, the algorithm updates"
METHODOLOGY,0.11748633879781421,Published as a conference paper at ICLR 2022
METHODOLOGY,0.12021857923497267,"the proposal to pr+1(·). The outcomes for the two settings we discuss may be slightly different: an
algorithm for likelihood-free inference would return the posterior, while a sequence design method
would return the dataset of all the sequences it has queried, which hopefully contains desired high
scored sequences. On the other hand, a sequence design method could produce as an intermediate
result a generative model for sampling queries, which then completely ﬁts with the LFI framework."
BACKWARD MODELING OF THE MECHANISM,0.12295081967213115,"3.1
BACKWARD MODELING OF THE MECHANISM"
BACKWARD MODELING OF THE MECHANISM,0.12568306010928962,"Approximate Bayesian Computation (ABC) (Beaumont et al., 2002) is a standard method for tack-
ling LFI problems. In Algorithm 1, we display one of the most popular variants: Sequential Monte
Carlo-Approximate Bayesian Computation (SMC-ABC) (Beaumont et al., 2009). In each round, pa-
rameters θ are sampled from the current proposal distribution pr(θ) for simulation. A rejection step
is then involved to remove the θi whose simulation outcomes xi cannot reproduce the observed data
xo with sufﬁcient accuracy. The remaining accepted {θi}i are adopted to update the next round’s
proposal pr+1(·) towards the target posterior, i.e., by reﬁtting qφ with the modiﬁed data. We defer
more details of this approach to Section A.1 in Appendix."
BACKWARD MODELING OF THE MECHANISM,0.1284153005464481,Algorithm 1 SMC-ABC
BACKWARD MODELING OF THE MECHANISM,0.13114754098360656,"p1(θ) ←p(θ);
for r in 1 to R do"
BACKWARD MODELING OF THE MECHANISM,0.13387978142076504,repeat
BACKWARD MODELING OF THE MECHANISM,0.1366120218579235,"sample θi ∼pr(θ);
simulate xi ∼p(x|θi);
until n samples are obtained
D ←D ∪{(θi, xi)}n
i=1
sort D according to −∥xi −xo∥;
ﬁt qφ(θ) with top {θi}i in D;
pr+1(θ) ←qφ(θ);
end for
return ˆp(θ|xo) = pR+1(θ)"
BACKWARD MODELING OF THE MECHANISM,0.13934426229508196,Algorithm 2 FB-VAE
BACKWARD MODELING OF THE MECHANISM,0.14207650273224043,"p1(m) ←p(m);
for r in 1 to R do"
BACKWARD MODELING OF THE MECHANISM,0.1448087431693989,repeat
BACKWARD MODELING OF THE MECHANISM,0.14754098360655737,"sample mi ∼pr(m);
query the oracle: si ←f(mi);
until n samples are obtained
D ←D ∪{(mi, si)}n
i=1;
sort D according to si
ﬁt qφ(m) with top {mi}i in D;
pr+1(m) ←qφ(m);
end for
return {m : (m, s) ∈D}"
BACKWARD MODELING OF THE MECHANISM,0.15027322404371585,"It would then be natural to construct an analogical sequence design algorithm using top scored
entities {mi}i to guide the update of a certain sequence distribution, see Algorithm 2. Interestingly,
this is the proposed sequence design algorithm in Gupta & Zou (2019), where the authors name this
kind of updating “feedback” because training of the parametric generator qφ(m) exploits feedback
signals from the oracle. In this paper, we follow Brookes & Listgarten (2018) to crystallize qφ(m)
to be a variational autoencoder (Kingma & Welling, 2014), and use the term Feedback-Variational
AutoEncoder (FB-VAE) to refer to Algorithm 2. We place Algorithm 1 & 2 side-by-side to highlight
their correspondence. We also make the same arrangement for the following Algorithm 3 & 4,
Algorithm 5 & 6 and Algorithm 7 & 8."
BACKWARD MODELING OF THE MECHANISM,0.15300546448087432,Algorithm 3 Sequential Neural Posterior
BACKWARD MODELING OF THE MECHANISM,0.1557377049180328,"p1(θ) ←p(θ);
for r in 1 to R do"
BACKWARD MODELING OF THE MECHANISM,0.15846994535519127,repeat
BACKWARD MODELING OF THE MECHANISM,0.16120218579234974,"sample θi ∼pr(θ);
simulate xi ∼p(x|θi);
until n samples are obtained
D ←D ∪{(θi, xi)}n
i=1;
qφ ←arg minq Ex [DKL(p(θ|x)∥q)];
pr+1(θ) ←qφ(θ|xo);
end for
return ˆp(θ|xo) = pR+1(θ)"
BACKWARD MODELING OF THE MECHANISM,0.16393442622950818,Algorithm 4 Design by Adaptive Sampling
BACKWARD MODELING OF THE MECHANISM,0.16666666666666666,"p1(m) ←p(m);
for r in 1 to R do"
BACKWARD MODELING OF THE MECHANISM,0.16939890710382513,repeat
BACKWARD MODELING OF THE MECHANISM,0.1721311475409836,"sample mi ∼pr(m);
query the oracle: si ←f(mi);
until n samples are obtained
D ←D ∪{(mi, si)}n
i=1;
qφ ←arg minq DKL(p(m|E)∥q);
pr+1(m) ←qφ(m);
end for
return {m : (m, s) ∈D}"
BACKWARD MODELING OF THE MECHANISM,0.17486338797814208,"In comparison with SMC-ABC, the Sequential Neural Posterior (SNP) method (Papamakarios &
Murray, 2016; Lueckmann et al., 2017; Greenberg et al., 2019) for likelihood-free inference adopts
a more ﬂexible approach, taking the power of conditional neural density estimator (e.g., Papamakar-
ios et al. (2017)) to model the general posterior p(θ|x), which takes arbitrary θ and x as two in-
puts and outputs a distribution. This neural estimator is trained via approximately minimizing the"
BACKWARD MODELING OF THE MECHANISM,0.17759562841530055,Published as a conference paper at ICLR 2022
BACKWARD MODELING OF THE MECHANISM,0.18032786885245902,"Kullback–Leibler (KL) divergence between qφ(θ|x) and the true posterior p(θ|x). We defer more
training details to Section A.1 in Appendix. Under the connection viewpoint, one similar algorithm
for sequence design is the Design by Adaptive Sampling (DbAS) proposed in Brookes & Listgarten
(2018) which is characterized in Algorithm 4, ﬁtting qφ(m) through minimizing the KL divergence
with the posterior p(m|E). Based on the difference in speciﬁc implementations, both algorithms
have more than one variant, whose details are deferred to Section A.1 in Appendix."
BACKWARD MODELING OF THE MECHANISM,0.1830601092896175,"We refer to the above algorithms as “backward modeling” because the trained generative network
qφ (going from x/E to θ/m) is a sort of reverse model of the simulation mechanism (which goes
from θ/m to x/s)."
FORWARD MODELING OF THE MECHANISM,0.18579234972677597,"3.2
FORWARD MODELING OF THE MECHANISM"
FORWARD MODELING OF THE MECHANISM,0.1885245901639344,"Whereas the above methods focus on directly modeling the target posterior with a generative model
that learns a “reverse mechanism” of the simulation process, it is also possible to model the “forward
mechanism”, which is consistent with the simulation process. Papamakarios et al. (2019) claim that
the forward modeling approach may be an easier task than its backward counterpart, as unbiased
estimation of the likelihood does not depend on the choice of proposal. Consequently, in contrast to
SNP, Papamakarios et al. (2019) chooses to train a neural density estimator to model the conditional
likelihood distribution qφ(x|θ) sequentially in each round. The training is achieved by maximizing
the total log likelihood maxq
P"
FORWARD MODELING OF THE MECHANISM,0.1912568306010929,"i log qφ(xi|θi) with data samples from the dataset D at the current
(r-th) round. The downside of this forward approach is an additional computational Markov Chain
Monte Carlo (MCMC) step is needed to sample from the r-th round posterior / proposal pr(θ). The
resulting approach, which is coined (Papamakarios et al., 2019) the Sequential Neural Likelihood
(SNL), is summarized in Algorithm 5."
FORWARD MODELING OF THE MECHANISM,0.19398907103825136,"In the spirit of directly modeling the forward mechanism of sequence design, we train a regressor
ˆfφ(m) in a supervised manner to ﬁt the oracle scorer. In order to adapt this regressor into the update
procedure of the proposal of the next round, we use ˜q(m) to denote the unknown posterior p(m|E)
with knowledge of ˆfφ(m) and prior p(m). The speciﬁc construction of ˜q(m) depends on the choice
of E. For instance, if we choose Example B in Section 2.2 to be the deﬁnition of E, then ˜q(m) is the
distribution with (unnormalized) probability p(m)·exp( ˆfφ(m)/τ). See Section A.2 in Appendix for
more elaboration about this point. We then choose the update procedure of the proposal pr+1(m) to
be analogical to that of SNL. We name this proposed algorithm to be Iterative Scoring (IS) to avoid
confusion with likelihood-free inference algorithms. Furthermore, depending on different deﬁnition
of E, we use the name “IS-A” and “IS-B” for them in the following sections."
FORWARD MODELING OF THE MECHANISM,0.19672131147540983,Algorithm 5 Sequential Neural Likelihood
FORWARD MODELING OF THE MECHANISM,0.1994535519125683,"p1(θ) ←p(θ);
for r in 1 to R do"
FORWARD MODELING OF THE MECHANISM,0.20218579234972678,repeat
FORWARD MODELING OF THE MECHANISM,0.20491803278688525,"sample θi ∼pr(θ);
simulate xi ∼p(x|θi);
until n samples are obtained
D ←D ∪{(θi, xi)}n
i=1
ﬁt qφ(x|θ) with D;
pr+1(θ) ∝p(θ) · qφ(xo|θ);
end for
return ˆp(θ|xo) = pR+1(θ)"
FORWARD MODELING OF THE MECHANISM,0.20765027322404372,Algorithm 6 Iterative Scoring
FORWARD MODELING OF THE MECHANISM,0.2103825136612022,"p1(m) ←p(m);
for r in 1 to R do"
FORWARD MODELING OF THE MECHANISM,0.21311475409836064,repeat
FORWARD MODELING OF THE MECHANISM,0.21584699453551912,"sample mi ∼pr(m);
query the oracle: si ←f(mi);
until n samples are obtained
D ←D ∪{(mi, si)}n
i=1;
ﬁt ˆfφ(m) with D;
construct ˜q(m) with ˆfφ(·) and p(m);
pr+1(m) ←˜q(m);
end for
return {m : (m, s) ∈D}"
MODELING A PROBABILITY RATIO,0.2185792349726776,"3.3
MODELING A PROBABILITY RATIO"
MODELING A PROBABILITY RATIO,0.22131147540983606,"In this subsection, we discuss yet another approach, through the estimation of a probability ratio.
Gutmann & Hyv¨arinen (2010) proposes noise contrastive estimation as a statistical inference ap-
proach. This methodology turns a hard probability modeling problem into binary classiﬁcation,
which is considered easier to learn. In contrast to the aforementioned likelihood-free inference
methods which rely on a form of density estimation to perform the task, Sequential Neural Ratio"
MODELING A PROBABILITY RATIO,0.22404371584699453,Published as a conference paper at ICLR 2022
MODELING A PROBABILITY RATIO,0.226775956284153,"(SNR) (Hermans et al., 2019) takes a similar approach as noise contrastive estimation. SNR adopts a
classiﬁcation approach to estimate the likelihood-to-evidence ratio r(θ, x) = p(θ|x)/p(θ). SNR is
summarized in Algorithm 7. Speciﬁcally, in each round, SNR ﬁts a binary classiﬁer dφ(θ, x) ∈[0, 1]
in the following manner:"
MODELING A PROBABILITY RATIO,0.22950819672131148,"arg min
d X"
MODELING A PROBABILITY RATIO,0.23224043715846995,"(θi,xi)∈D [−log d(xi, θi)] +
X"
MODELING A PROBABILITY RATIO,0.23497267759562843,"(θ′
i,xi)∈D′ [−log(1 −d(xi, θ′
i))]

.
(4)"
MODELING A PROBABILITY RATIO,0.23770491803278687,"We show that with the D and D′ established in Algorithm 7, we have"
MODELING A PROBABILITY RATIO,0.24043715846994534,"d∗(θ, x) =
p(θ|x)
p(θ) + p(θ|x),
r∗(θ, x) :=
d∗(θ, x)
1 −d∗(θ, x) = p(θ|x) p(θ)"
MODELING A PROBABILITY RATIO,0.24316939890710382,where the “∗” denotes the optimality. We have the following Proposition 1:
MODELING A PROBABILITY RATIO,0.2459016393442623,"Proposition 1. Let p0(a) and p1(a) be two distributions for da-dimension random variable a which
takes value in the space of A = Rda, and d(a) : A →[0, 1] is a real-value function mapping any a
to a positive real value number. Then the functional optimization problem"
MODELING A PROBABILITY RATIO,0.24863387978142076,"arg max
d:A→[0,1]"
MODELING A PROBABILITY RATIO,0.25136612021857924,"
Ea∼p0(a)[log d(a)] + Ea∼p1(a)[log(1 −d(a))]
	
."
MODELING A PROBABILITY RATIO,0.2540983606557377,"will lead to the optimal solution d∗(a) =
p0(a)
p0(a)+p1(a)."
MODELING A PROBABILITY RATIO,0.2568306010928962,"See the proof in Section A.3 in Appendix. After training d, SNR can obtain the posterior density
value by p(θ|x) = r∗(θ, x)p(θ). SNR mirrors SNL in that it samples the new proposal pr+1(θ)
without explicitly modeling the posterior."
MODELING A PROBABILITY RATIO,0.25956284153005466,"On the other hand, we propose a sequence design algorithm analogous to SNR and named Iterative
Ratio (IR), which estimates the probability ratio r(m) = p(m|E)/p(m) for the purpose of poste-
rior sampling. IR ﬁrst builds two datasets D and D′, corresponding to two different distributions
p(m|E) and p(m). We take a similar binary classiﬁcation approach, whose training objective is
mind
P"
MODELING A PROBABILITY RATIO,0.26229508196721313,m∈D[−log d(m)] + P
MODELING A PROBABILITY RATIO,0.2650273224043716,"m∈D′[−log(1 −d(m))]
	
. The desired ratio is then obtained by
r(m) := d(m)/(1 −d(m)). Other components of IR follow the scheme of IS, and IR is schema-
tized in Algorithm 8. We point out that IR does not have two variants as IS does, as the deﬁnition for
E in Example B is not usable because of the unknown normalizing constant for probability p(E|m).
See Section A.3 in Appendix for more explanation."
MODELING A PROBABILITY RATIO,0.2677595628415301,Algorithm 7 Sequential Neural Ratio
MODELING A PROBABILITY RATIO,0.27049180327868855,"p1(θ) ←p(θ);
for r in 1 to R do"
MODELING A PROBABILITY RATIO,0.273224043715847,repeat
MODELING A PROBABILITY RATIO,0.27595628415300544,"sample θi, θ′
i ∼pr(θ);
simulate xi ∼p(x|θi);
until n samples are obtained
D ←D ∪{(θi, xi)}n
i=1
D′ ←D′ ∪{(θ′
i, xi)}n
i=1
train dφ(θ, x) classifying between D and D′
with the loss in Eq. 4;"
MODELING A PROBABILITY RATIO,0.2786885245901639,"rφ(θ, x) ←
dφ(θ,x)
1−dφ(θ,x);
pr+1(θ) ∝rφ(θ, x) · p(θ);
end for
return ˆp(θ|xo) = pR+1(θ)"
MODELING A PROBABILITY RATIO,0.2814207650273224,Algorithm 8 Iterative Ratio
MODELING A PROBABILITY RATIO,0.28415300546448086,"p1(m) ←p(m);
for r in 1 to R do"
MODELING A PROBABILITY RATIO,0.28688524590163933,repeat
MODELING A PROBABILITY RATIO,0.2896174863387978,"sample mi ∼pr(m);
query the oracle: si ←f(mi);
until n samples are obtained
D ←D ∪{(mi, si)}n
i=1;
construct ˜D with m in D satisfying E;
construct ˜D′ from p(m);
train dφ(m) classifying between ˜D and ˜D′;
rφ(m) ←
dφ(m)
1−dφ(m);
pr+1(θ) ∝rφ(m) · p(m);
end for
return {m : (m, s) ∈D}"
MODELING A PROBABILITY RATIO,0.2923497267759563,"Interestingly, a recent SNR-like work, EG-LF-MCMC (Begy & Schikuta, 2021), proposes to train
the classiﬁer on tuples of (θ, ϵ = ∥x −xo∥) instead of (θ, x). This algorithm can be also seen as a
more precise analogy of our Iterative Ratio in the LFI context, as we have pointed out in Section 2.2
that a conceptual link could be drawn between s and −∥x −xo∥."
MODELING A PROBABILITY RATIO,0.29508196721311475,Published as a conference paper at ICLR 2022
COMPOSITE PROBABILISTIC METHODS,0.2978142076502732,"3.4
COMPOSITE PROBABILISTIC METHODS"
COMPOSITE PROBABILISTIC METHODS,0.3005464480874317,"Building on the above analogies and framework, we move beyond the above algorithms in this
subsection. The previous lines of approach – the direct posterior modeling methods in Section 3.1
and the indirect methods in Section 3.2 and 3.3 – both have their own advantages and disadvantages.
The former methods may fail to get accurate inference result due to unmatched proposals, while the
latter ones would need extra large amount of computation for the MCMC sampling process before
obtaining accurate posterior samples, etc. Here we study composite algorithms that combine the
aforementioned ingredients through the lens of our proposed uniﬁed framework. Our goal is to
combine the strengths from both kinds of methods."
COMPOSITE PROBABILISTIC METHODS,0.30327868852459017,"We ﬁrst introduce Iterative Posterior Scoring (IPS) method illustrated in Algorithm 9. IPS also
uses a neural network ˆfφ(m) to model the forward mechanism as IS does, and again we use ˜q here
to denote the target posterior p(m|E). Instead of applying computational MCMC steps here, we
train a second parametrized model qψ to model ˜q by minimizing the KL divergence between them.
Notice that the optimization of qψ is restricted within a neural network parameterization family. As
a result, in the next round, we can directly utilize qψ(m) to serve as a ﬂexible generative proposal
of pr+1(m). Like IS, the IPS algorithm also has two different variants with regard to different
choices of E, we name them to be IPS-A and IPS-B. Two choices differ in the detailed construction
of distribution ˜q(m)."
COMPOSITE PROBABILISTIC METHODS,0.30601092896174864,"In a similar spirit, we propose the Iterative Posterior Ratio (IPR) algorithm (see Algorithm 10). IPR
is close to the IR algorithm in many aspects, but also adopts a second neural network model qψ(m)
like IPS. IPR works similarly to IR, in that we also construct ˜q(m), taking advantage of rφ(m) and
the prior p(m) simply via ˜q(m) ←rφ(m) · p(m). Note that the usage of two models in IPR is not
exactly the same as in IPS: qψ(m) is also achieved via minimizing KL divergence with ˜q(m), but
the training of model dφ(m) is closer to that in IR rather than the ˆfφ(m) in IS. Another similarity
between IPR and IR is that IPR also only has one variant, since the Example B is not applicable for
this ratio modeling approach (see Section A.4 in Appendix for more details)."
COMPOSITE PROBABILISTIC METHODS,0.3087431693989071,Algorithm 9 Iterative Posterior Scoring
COMPOSITE PROBABILISTIC METHODS,0.3114754098360656,"p1(m) ←p(m);
for r in 1 to R do"
COMPOSITE PROBABILISTIC METHODS,0.31420765027322406,repeat
COMPOSITE PROBABILISTIC METHODS,0.31693989071038253,"sample mi ∼pr(m);
query the oracle: si ←f(mi);
until n samples are obtained
D ←D ∪{(mi, si)}n
i=1;
ﬁt ˆfφ(m) with D;
construct ˜q(m) with ˆfφ(·) and p(m);
qψ ←arg minq DKL(˜q(m)∥q);
pr+1(m) ←qψ(m);
end for
return {m : (m, s) ∈D}"
COMPOSITE PROBABILISTIC METHODS,0.319672131147541,Algorithm 10 Iterative Posterior Ratio
COMPOSITE PROBABILISTIC METHODS,0.3224043715846995,"p1(m) ←p(m);
for r in 1 to R do"
COMPOSITE PROBABILISTIC METHODS,0.3251366120218579,repeat
COMPOSITE PROBABILISTIC METHODS,0.32786885245901637,"sample mi ∼pr(m);
query the oracle: si ←f(mi);
until n samples are obtained
D ←D ∪{(mi, si)}n
i=1;
construct ˜D with m in D satisfying E;
construct ˜D′ from p(m);
train dφ(m) classifying between ˜D and ˜D′;
rφ(m) ←
dφ(m)
1−dφ(m);
construct ˜q(m) with rφ(m) and p(m);
qψ ←arg minq DKL(˜q(m)∥q);
pr+1(m) ←qψ(m);
end for
return {m : (m, s) ∈D}"
EXPERIMENTS,0.33060109289617484,"4
EXPERIMENTS"
SETUP,0.3333333333333333,"4.1
SETUP"
SETUP,0.3360655737704918,"In this section, we systematically evaluate the proposed methods and baselines on four different
in-silico biological sequence design benchmarks. In every round, we allow each algorithm to query
the black-box oracle for a batch of n sequences mi to obtain their true scores si, with n = 100 for
all experiments. The total number of rounds differs across different tasks."
SETUP,0.33879781420765026,"We experiment with our six proposed methods: Iterative Scoring (-A/B) from Section 3.2, Iterative
Ratio from Section 3.3, Iterative Posterior Scoring (-A/B) and Iterative Posterior Ratio from Sec-"
SETUP,0.34153005464480873,Published as a conference paper at ICLR 2022
SETUP,0.3442622950819672,"2
4
6
8
10
Round 0.32 0.34 0.36 0.38 0.40 0.42 0.44"
SETUP,0.3469945355191257,Top-10 score
SETUP,0.34972677595628415,KLF11_R402Q_R1
SETUP,0.3524590163934426,"2
4
6
8
10
Round 0.325 0.350 0.375 0.400 0.425 0.450 0.475"
SETUP,0.3551912568306011,Top-10 score
SETUP,0.35792349726775957,PBX4_REF_R2
SETUP,0.36065573770491804,"2
4
6
8
10
Round 0.35 0.40 0.45 0.50"
SETUP,0.3633879781420765,Top-10 score
SETUP,0.366120218579235,CRX_E80A_R1
SETUP,0.36885245901639346,"2
4
6
8
10
Round 0.15 0.20 0.25 0.30 0.35 0.40"
SETUP,0.37158469945355194,Top-100 score
SETUP,0.3743169398907104,"2
4
6
8
10
Round 0.10 0.15 0.20 0.25 0.30 0.35 0.40"
SETUP,0.3770491803278688,Top-100 score
SETUP,0.3797814207650273,"2
4
6
8
10
Round 0.1 0.2 0.3 0.4"
SETUP,0.3825136612021858,Top-100 score
SETUP,0.38524590163934425,"IS-A
IS-B
IR
IPS-A
IPS-B
IPR
Random
Evolution
DbAS
FB-VAE"
SETUP,0.3879781420765027,"Figure 1: Top score (y-axis) curves of different methods on 3 TfBind problems (KLF11 R402Q R1,
PBX4 REF R2 and CRX E80A R1) with regard to the number of rounds."
SETUP,0.3907103825136612,"IS-A
IS-B
IR
IPS-A
IPS-B
IPR
RANDOM
EVOLUTION
DBAS
FB-VAE"
SETUP,0.39344262295081966,"TOP-10
8.43
6.93
4.79
6.21
8.36
7.00
1.14
4.36
5.07
2.71
TOP-100
9.57
7.93
4.07
6.71
7.64
6.00
1.00
5.50
4.57
2.00"
SETUP,0.39617486338797814,"Table 2:
Mean rank of evaluated algorithms with regard to the area under the top score curve for
TfBind problems. The rank ranges from 1 to 10. Higher rank is better."
SETUP,0.3989071038251366,"tion 3.4. Apart from these proposed methods, we consider as baselines a battery of existing methods
designed for batched black-box sequence design tasks: (1) Random, a method that randomly se-
lect proposal sequences at every round; (2) FB-VAE (Gupta & Zou, 2019) depicted in Section 3.1;
(3) Evolution based (Brindle, 1980; Real et al., 2019) sequence design algorithm; and (4) DbAS
(Brookes & Listgarten, 2018), described in Section 3.1."
SETUP,0.4016393442622951,"We evaluate these sequence design algorithms by the average score of the top-10 and top-100 se-
quences in the resulting dataset D at each round. We plot the average score curves with regard to the
number of rounds. We also use the area under the curve as a scalar metric for sample efﬁciency to
compare the methods being evaluated. Speciﬁcally, since the area depends on the choice of x-axis,
we simply cumulate the scores of all rounds to calculate the area. The result could be non-positive,
since the score can take negative values."
RESULTS,0.40437158469945356,"4.2
RESULTS"
RESULTS,0.40710382513661203,"Transcription factor binding sites (TfBind). Protein sequences that bind with DNA sequences to
adjust their activity are called transcription factors. In Barrera et al. (2016), the authors measure
the binding properties between a battery of transcription factors and all possible length-8 DNA
sequences through biological experiments. Concretely, we choose 15 transcription factors to serve
as 15 different tasks. For each transcription factor, the algorithm needs to search for sequences
that maximize the corresponding binding activity score. The size of the search space is |V|L =
48 = 65536. The number of total rounds is ﬁxed to 10. For validation, we follow Angerm¨uller
et al. (2020b) and use one task (ZNF200 S265Y R1) for hyperparameter selection. Then we test the
algorithms’ performance on the other 14 held-out tasks."
RESULTS,0.4098360655737705,"Figure 1 displays a comparison for all ten methods on three of the chosen binding afﬁnity tasks.
We can observe that after 10 rounds, our proposed methods perform consistently better than the"
RESULTS,0.412568306010929,Published as a conference paper at ICLR 2022
RESULTS,0.41530054644808745,"4
6
8
10
Round 1.05 1.10 1.15 1.20 1.25 1.30 1.35"
RESULTS,0.4180327868852459,Top-10 score UTR
RESULTS,0.4207650273224044,"4
6
8
10
12
14
Round 0.250 0.225 0.200 0.175 0.150 0.125 0.100"
RESULTS,0.42349726775956287,Top-10 score AMP
RESULTS,0.4262295081967213,"5
10
15
20
Round 1.6 1.8 2.0 2.2 2.4"
RESULTS,0.42896174863387976,Top-10 score Fluo
RESULTS,0.43169398907103823,"4
6
8
10
Round 0.8 0.9 1.0 1.1 1.2"
RESULTS,0.4344262295081967,Top-100 score
RESULTS,0.4371584699453552,"4
6
8
10
12
14
Round 0.50 0.45 0.40 0.35 0.30 0.25 0.20 0.15"
RESULTS,0.43989071038251365,Top-100 score
RESULTS,0.4426229508196721,"5
10
15
20
Round 1.6 1.8 2.0 2.2 2.4"
RESULTS,0.4453551912568306,Top-100 score
RESULTS,0.44808743169398907,"IS-A
IS-B
IR
IPS-A
IPS-B
IPR
Random
Evolution
DbAS
FB-VAE"
RESULTS,0.45081967213114754,"Figure 2: Top score (y-axis) curves of different methods on 3 sequence design problems (left: UTR,
middle: AMP, right: Fluo) with regard to the number of rounds."
RESULTS,0.453551912568306,"IS-A
IS-B
IR
IPS-A
IPS-B
IPR
RANDOM
EVOLUTION
DBAS
FB-VAE"
RESULTS,0.4562841530054645,"UTR
8.46
9.61
9.03
10.04
10.19
9.52
8.12
9.23
9.59
8.20
AMP
−5.67
−5.11
−5.37
−4.65
−4.39
−5.42
−5.96
−5.79
−5.39
−5.54
FLUO
32.76
33.33
32.95
44.51
43.13
42.42
31.64
35.44
41.40
32.52"
RESULTS,0.45901639344262296,"Table 3: Comparison of the area under top-100 curves for UTR, AMP and Fluo benchmarks. Larger
area means better sample efﬁciency."
RESULTS,0.46174863387978143,"backward modeling methods like DbAS and FB-VAE in terms of both Top-10 and Top-100 scores.
Among all baselines, the evolution method is the strongest one, and it beats IR on some of the tasks
(see complete results in Table 4 and 5 in Appendix). We also ﬁnd that IS-A and IS-B increase top
scores slightly faster than other methods, especially on PBX4 REF R2 and CRX E80A R1. This
indicates that composite methods’ way of using parameterized models to replace computational
procedures is not the optimal solution for small-scale tasks."
RESULTS,0.4644808743169399,"5’ untranslated regions (UTR). The translation efﬁciency is mainly determined by the sequence
of 5’ UTR (Alipanahi et al., 2015). In Sample et al. (2019), the authors create a library of gene
sequences with ribosome loading level as labels. They further train a convolutional neural network
with this library to predict the relationship between a 5’UTR sequence and the corresponding gene
expression level. We use this neural network as an oracle for this benchmark. The length of the gene
sequences is ﬁxed to 50, and thus the size of the search space is 450. For this 5’UTR benchmark,
we also allow each algorithm to explore for 10 rounds. Figure 2 (left) shows that our proposed
composite methods signiﬁcantly outperform other methods on the UTR task. Different from the
results on the TfBind task, forward modeling methods do not achieve the best performance."
RESULTS,0.4672131147540984,"Antimicrobial peptides (AMP). Protein modeling has recently become a popular sub-area of ma-
chine learning research. We are tasked to generate AMP sequences, which are short protein se-
quences against multi-resistant pathogens. We train a binary classiﬁer model to classify whether a
short protein sequence belongs to AMP and defer the related details to Appendix. This is the only
task we consider regarding sequence design with alterable lengths, where the length of sequences
ranges from 12 to 60. Since each entry of protein sequence has |V| = 20 different choices on amino
acids, the size of search space is P60
L=12 20L. We set the number of total rounds to be 15 for this
task. Figure 2 (middle) clearly shows that the performances of IPS-A and IPS-B dominate the AMP
generation task, which demonstrates the effectiveness of our composite strategy."
RESULTS,0.46994535519125685,Published as a conference paper at ICLR 2022
RESULTS,0.4726775956284153,"Fluorescence proteins (Fluo). As another protein engineering task, we consider the optimization
over ﬂuorescent proteins, which is a commonly used test bed of modern molecular biology. This
task is similar to the AMP task introduced above, but its ground-truth measurement relies on a
regressor. We use a pretrained model taken from Rao et al. (2019) to act as our task oracle, which
is a regressor trained to predict log-ﬂuorescence intensity value over approximately 52,000 protein
sequences of length 238 (Sarkisyan et al., 2016). More concretely, the regressor is ﬁt on a small
neighborhood of parent green ﬂuorescent protein, and is then evaluated on a more distant protein.
The training data is derived from the naturally occurring GFP in Aequorea victoria. The task Fluo’s
search space is 20238 and we set the number of rounds to 20. We demonstrate the Fluo results in
Figure 2 (right), where we can see both composite methods and DbAS achieve much better results
than other approaches. This might signify that for long sequence design tasks, backward modeling
is superior to other modeling methods, which is not consistent with LFI (Papamakarios et al., 2019).
We also summarize the sample efﬁciency results for the latter 3 benchmarks in Table 3 and 6, from
which we can see that our proposed three composite methods perform remarkably promising results."
CONCLUSION,0.47540983606557374,"5
CONCLUSION"
CONCLUSION,0.4781420765027322,"We propose a probabilistic framework that uniﬁes likelihood-free inference and black-box optimiza-
tion for designing biological sequences. This uniﬁed perspective enables us to design a variety of
novel composite probabilistic sequence design methods combining the best of both worlds. Exten-
sive experiments have demonstrated the beneﬁts of the uniﬁed perspective. While the composite
probabilistic methods usually outperform other baseline methods in most sequence design tasks we
consider in this work, the key contribution of our paper is not just about the superiority of those com-
posite methods, as different speciﬁc tasks might prefer different algorithmic conﬁgurations due to
no free lunch theorem (Wolpert & Macready, 1997). Actually, we would like to attribute the strong
performance to the uniﬁed probabilistic framework, which enables us to develop a richer algorithm
pool, based on which we can design performant algorithms for particular sequence design tasks."
CONCLUSION,0.4808743169398907,ACKNOWLEDGEMENT
CONCLUSION,0.48360655737704916,"The authors would like to thank Christof Angermueller, Yanzhi Chen, Michael Gutmann, and anony-
mous reviewers for helpful feedbacks. Jie Fu thanks Microsoft Research Montreal for funding his
postdoctoral position at University of Montreal and Mila. Yoshua Bengio acknowledges the fund-
ing from CIFAR, Samsung, IBM and Microsoft. Aaron Courville thanks the support of Samsung,
Hitachi and CIFAR."
REFERENCES,0.48633879781420764,REFERENCES
REFERENCES,0.4890710382513661,"Sungsoo Ahn, Junsu Kim, Hankook Lee, and Jinwoo Shin. Guiding deep molecular optimization
with genetic exploration. ArXiv, abs/2007.04897, 2020."
REFERENCES,0.4918032786885246,"Babak Alipanahi, Andrew Delong, Matthew T Weirauch, and Brendan J Frey. Predicting the se-
quence speciﬁcities of dna-and rna-binding proteins by deep learning. Nature biotechnology, 33
(8):831–838, 2015."
REFERENCES,0.49453551912568305,"Christof Angerm¨uller, David Belanger, Andreea Gane, Zelda E. Mariet, David Dohan, Kevin Mur-
phy, Lucy J. Colwell, and D. Sculley. Population-based black-box optimization for biological
sequence design. In ICML, 2020a."
REFERENCES,0.4972677595628415,"Christof Angerm¨uller, David Dohan, David Belanger, Ramya Deshpande, Kevin Murphy, and
Lucy J. Colwell. Model-based reinforcement learning for biological sequence design. In ICLR,
2020b."
REFERENCES,0.5,"Luis A. Barrera, Anastasia Vedenko, Jesse V. Kurland, Julia M Rogers, Stephen S. Gisselbrecht,
Elizabeth J Rossin, Jaie C. Woodard, Luca Mariani, Kian Hong Kock, Sachi Inukai, Trevor Sig-
gers, Leila Shokri, Raluca Gordˆan, Nidhi Sahni, Chris Cotsapas, Tong Hao, S. Stephen Yi, Mano-
lis Kellis, Mark J. Daly, Marc Vidal, David E. Hill, and Martha L. Bulyk. Survey of variation
in human transcription factors reveals prevalent dna binding changes. Science, 351:1450 – 1454,
2016."
REFERENCES,0.5027322404371585,Published as a conference paper at ICLR 2022
REFERENCES,0.505464480874317,"M. Beaumont, Wenyang Zhang, and D. Balding. Approximate bayesian computation in population
genetics. Genetics, 162 4:2025–35, 2002."
REFERENCES,0.5081967213114754,"M. Beaumont, J. Cornuet, J. Marin, and C. Robert. Adaptive approximate bayesian computation.
Biometrika, 96:983–990, 2009."
REFERENCES,0.5109289617486339,"Volodimir Begy and Erich Schikuta. Error-guided likelihood-free mcmc. 2021 International Joint
Conference on Neural Networks (IJCNN), pp. 1–7, 2021."
REFERENCES,0.5136612021857924,"Michael G. B. Blum. Approximate bayesian computation: A nonparametric perspective. Journal of
the American Statistical Association, 105:1178 – 1187, 2009."
REFERENCES,0.5163934426229508,"Johann Brehmer, Gilles Louppe, Juan Pavez, and Kyle Cranmer. Mining gold from implicit models
to improve likelihood-free inference. Proceedings of the National Academy of Sciences, 117:5242
– 5249, 2020."
REFERENCES,0.5191256830601093,A. Brindle. Genetic algorithms for function optimization. 1980.
REFERENCES,0.5218579234972678,"David H. Brookes and J. Listgarten. Design by adaptive sampling. ArXiv, abs/1810.03714, 2018."
REFERENCES,0.5245901639344263,"David H. Brookes, Hahnbeom Park, and Jennifer Listgarten. Conditioning by adaptive sampling for
robust design. In ICML, 2019."
REFERENCES,0.5273224043715847,"Jeffrey Chan, Valerio Perrone, Jeffrey P. Spence, Paul A. Jenkins, Sara Mathieson, and Yun S. Song.
A likelihood-free inference framework for population genetic data using exchangeable neural
networks. bioRxiv, 2018."
REFERENCES,0.5300546448087432,"K. Chen and F. Arnold. Enzyme engineering for nonaqueous solvents: Random mutagenesis to
enhance activity of subtilisin e in polar organic media. Bio/Technology, 9:1073–1077, 1991."
REFERENCES,0.5327868852459017,"Yanzhi Chen and Michael U. Gutmann. Adaptive gaussian copula abc. ArXiv, abs/1902.10704,
2019."
REFERENCES,0.5355191256830601,"Yanzhi Chen, Dinghuai Zhang, M. Gutmann, Aaron C. Courville, and Zhanxing Zhu. Neural ap-
proximate sufﬁcient statistics for implicit models. ArXiv, abs/2010.10079, 2021."
REFERENCES,0.5382513661202186,"P. T. de Boer, Dirk P. Kroese, Shie Mannor, and Reuven Y. Rubinstein. A tutorial on the cross-
entropy method. Annals of Operations Research, 134:19–67, 2005."
REFERENCES,0.5409836065573771,"Christopher C. Drovandi, Clara Grazian, Kerrie L. Mengersen, and Christian P. Robert. Approxi-
mating the likelihood in approximate bayesian computation. arXiv: Computation, 2018."
REFERENCES,0.5437158469945356,"Ahmed Elnaggar, Michael Heinzinger, Christian Dallago, Ghalia Rihawi, Yu Wang, Llion Jones,
Tom Gibbs, Tamas Feher, Christoph Angerer, Martin Steinegger, et al. Prottrans: towards crack-
ing the language of life’s code through self-supervised deep learning and high performance com-
puting. arXiv preprint arXiv:2007.06225, 2020."
REFERENCES,0.546448087431694,"Paul Fearnhead and Dennis Prangle. Constructing summary statistics for approximate bayesian
computation: semi-automatic approximate bayesian computation (with discussion). 2012."
REFERENCES,0.5491803278688525,"Rafael G´omez-Bombarelli, David Kristjanson Duvenaud, Jos´e Miguel Hern´andez-Lobato, Jorge
Aguilera-Iparraguirre, Timothy D. Hirzel, Ryan P. Adams, and Al´an Aspuru-Guzik. Automatic
chemical design using a data-driven continuous representation of molecules. ACS Central Sci-
ence, 4:268 – 276, 2018."
REFERENCES,0.5519125683060109,"Sai Krishna Gottipati, Boris Sattarov, Sufeng Niu, Yashaswi Pathak, Haoran Wei, Shengchao Liu,
Simon Blackburn, Karam Thomas, Connor Coley, Jian Tang, et al. Learning to navigate the
synthetically accessible chemical space using reinforcement learning. In International Conference
on Machine Learning, pp. 3668–3679. PMLR, 2020."
REFERENCES,0.5546448087431693,"David S. Greenberg, M. Nonnenmacher, and J. Macke. Automatic posterior transformation for
likelihood-free inference. ArXiv, abs/1905.07488, 2019."
REFERENCES,0.5573770491803278,Published as a conference paper at ICLR 2022
REFERENCES,0.5601092896174863,"Gabriel Lima Guimaraes, Benjam´ın S´anchez-Lengeling, Pedro Luis Cunha Farias, and Al´an Aspuru-
Guzik.
Objective-reinforced generative adversarial networks (organ) for sequence generation
models. ArXiv, abs/1705.10843, 2017."
REFERENCES,0.5628415300546448,"Anvita Gupta and J. Zou.
Feedback gan for dna optimizes protein functions.
Nature Machine
Intelligence, 1:105–111, 2019."
REFERENCES,0.5655737704918032,"Michael U. Gutmann and Aapo Hyv¨arinen. Noise-contrastive estimation: A new estimation princi-
ple for unnormalized statistical models. In AISTATS, 2010."
REFERENCES,0.5683060109289617,"Michael U. Gutmann, Ritabrata Dutta, Samuel Kaski, and Jukka Corander. Likelihood-free infer-
ence via classiﬁcation. Statistics and Computing, 28:411 – 425, 2018."
REFERENCES,0.5710382513661202,"Tatsunori B. Hashimoto, Steve Yadlowsky, and John C. Duchi. Derivative free optimization via
repeated classiﬁcation. In AISTATS, 2018."
REFERENCES,0.5737704918032787,"J. Hermans, Volodimir Begy, and Gilles Louppe. Likelihood-free mcmc with amortized approximate
likelihood ratios. arXiv: Machine Learning, 2019."
REFERENCES,0.5765027322404371,"Sepp Hochreiter and J¨urgen Schmidhuber. Long short-term memory. Neural Computation, 9:1735–
1780, 1997."
REFERENCES,0.5792349726775956,"Jp Hughes, S. Rees, SB Kalindjian, and KL Philpott. Principles of early drug discovery. British
Journal of Pharmacology, 162, 2011."
REFERENCES,0.5819672131147541,"Rafael Izbicki, Ann B. Lee, and Chad M. Schafer. High-dimensional density ratio estimation with
extensions to approximate likelihood computation. In AISTATS, 2014."
REFERENCES,0.5846994535519126,"Jan H Jensen. A graph-based genetic algorithm and generative model/monte carlo tree search for
the exploration of chemical space. Chemical science, 10(12):3567–3572, 2019."
REFERENCES,0.587431693989071,"Diederik P. Kingma and M. Welling. Auto-encoding variational bayes. CoRR, abs/1312.6114, 2014."
REFERENCES,0.5901639344262295,"Jian Ping Li, David J. Nott, Y. Fan, and Scott Anthony Sisson. Extending approximate bayesian
computation methods to high dimensions via a gaussian copula model. Comput. Stat. Data Anal.,
106:77–89, 2017."
REFERENCES,0.592896174863388,"Jarno Lintusaari, Michael U. Gutmann, Ritabrata Dutta, Samuel Kaski, and Jukka Corander. Funda-
mentals and recent developments in approximate bayesian computation. Systematic Biology, 66:
e66 – e82, 2017."
REFERENCES,0.5956284153005464,"Ge Liu, Haoyang Zeng, Jonas Mueller, Brandon Carter, Ziheng Wang, Jonas Schilz, Geraldine
Horny, Michael E. Birnbaum, Stefan Ewert, and David Kenneth Gifford. Antibody complemen-
tarity determining region design using high-capacity machine learning. bioRxiv, 2020."
REFERENCES,0.5983606557377049,"Jan-Matthis Lueckmann, Pedro J. Gonc¸alves, G. Bassetto, Kaan ¨Ocal, M. Nonnenmacher, and
J. Macke. Flexible statistical inference for mechanistic models of neural dynamics. In NIPS,
2017."
REFERENCES,0.6010928961748634,"Jan-Matthis Lueckmann,
Giacomo Bassetto,
Theofanis Karaletsos,
and Jakob H. Macke.
Likelihood-free inference with emulator networks. ArXiv, abs/1805.09294, 2018."
REFERENCES,0.6038251366120219,"Jean-Michel Marin, Pierre Pudlo, Christian P. Robert, and Robin J. Ryder. Approximate bayesian
computational methods. Statistics and Computing, 22:1167–1180, 2012."
REFERENCES,0.6065573770491803,"Kerrie L. Mengersen, Pierre Pudlo, and Christian P. Robert. Approximate bayesian computation via
empirical likelihood. 2012."
REFERENCES,0.6092896174863388,"Daniel Neil, Marwin H. S. Segler, Laura Guasch, Mohamed Ahmed, Dean Plumbley, Matthew
Sellwood, and Nathan Brown. Exploring deep recurrent models with reinforcement learning for
molecule design. In ICLR, 2018."
REFERENCES,0.6120218579234973,"AkshatKumar Nigam, Pascal Friederich, Mario Krenn, and Al´an Aspuru-Guzik. Augmenting ge-
netic algorithms with deep neural networks for exploring the chemical space. arXiv preprint
arXiv:1909.11655, 2019."
REFERENCES,0.6147540983606558,Published as a conference paper at ICLR 2022
REFERENCES,0.6174863387978142,"George Papamakarios and Iain Murray. Fast ϵ-free inference of simulation models with bayesian
conditional density estimation. In NIPS, 2016."
REFERENCES,0.6202185792349727,"George Papamakarios, Iain Murray, and Theo Pavlakou. Masked autoregressive ﬂow for density
estimation. ArXiv, abs/1705.07057, 2017."
REFERENCES,0.6229508196721312,"George Papamakarios, D. Sterratt, and Iain Murray. Sequential neural likelihood: Fast likelihood-
free inference with autoregressive ﬂows. In AISTATS, 2019."
REFERENCES,0.6256830601092896,"Roshan Rao, Nicholas Bhattacharya, Neil Thomas, Yan Duan, Xi Chen, John Canny, Pieter Abbeel,
and Yun S Song. Evaluating protein transfer learning with tape. In Advances in Neural Informa-
tion Processing Systems, 2019."
REFERENCES,0.6284153005464481,"Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc V. Le. Regularized evolution for image
classiﬁer architecture search. In AAAI, 2019."
REFERENCES,0.6311475409836066,"Reuven Y. Rubinstein and Dirk P. Kroese. The cross-entropy method. In Information Science and
Statistics, 2004."
REFERENCES,0.6338797814207651,"Tim Salimans, Jonathan Ho, Xi Chen, and Ilya Sutskever. Evolution strategies as a scalable alterna-
tive to reinforcement learning. ArXiv, abs/1703.03864, 2017."
REFERENCES,0.6366120218579235,"Paul Sample, Ban Wang, David W. Reid, Vladimir Presnyak, Iain J Mcfadyen, David R. Morris,
and Georg Seelig. Human 5 utr design and variant effect prediction from a massively parallel
translation assay. Nature Biotechnology, 37:803–809, 2019."
REFERENCES,0.639344262295082,"Karen S Sarkisyan, Dmitry A Bolotin, Margarita V Meer, Dinara R Usmanova, Alexander S Mishin,
George V Sharonov, Dmitry N Ivankov, Nina G Bozhanova, Mikhail S Baranov, Onuralp Soyle-
mez, et al. Local ﬁtness landscape of the green ﬂuorescent protein. Nature, 533(7603):397–401,
2016."
REFERENCES,0.6420765027322405,"Bobak Shahriari, Kevin Swersky, Ziyun Wang, Ryan P. Adams, and Nando de Freitas. Taking the
human out of the loop: A review of bayesian optimization. Proceedings of the IEEE, 104:148–
175, 2016."
REFERENCES,0.644808743169399,"Chence Shi, Minkai Xu, Zhaocheng Zhu, Weinan Zhang, Ming Zhang, and Jian Tang. Graphaf: a
ﬂow-based autoregressive model for molecular graph generation. ArXiv, abs/2001.09382, 2020."
REFERENCES,0.6475409836065574,"Nitish Srivastava, Geoffrey E. Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.
Dropout: a simple way to prevent neural networks from overﬁtting. J. Mach. Learn. Res., 15:
1929–1958, 2014."
REFERENCES,0.6502732240437158,"Owen Thomas, Ritabrata Dutta, Jukka Corander, Samuel Kaski, and Michael U. Gutmann.
Likelihood-free inference by ratio estimation. arXiv: Machine Learning, 2016."
REFERENCES,0.6530054644808743,"Minh-Ngoc Tran, David J. Nott, and Robert Kohn. Variational bayes with intractable likelihood.
Journal of Computational and Graphical Statistics, 26:873 – 882, 2015."
REFERENCES,0.6557377049180327,"Laurens van der Maaten and Geoffrey E. Hinton. Visualizing data using t-sne. Journal of Machine
Learning Research, 9:2579–2605, 2008."
REFERENCES,0.6584699453551912,"Daan Wierstra, Tom Schaul, Jan Peters, and Juergen Schmidhuber. Natural evolution strategies.
2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational
Intelligence), pp. 3381–3387, 2008."
REFERENCES,0.6612021857923497,"Jacob Witten and Zack Witten. Deep learning regression model for antimicrobial peptide design.
BioRxiv, pp. 692681, 2019."
REFERENCES,0.6639344262295082,"David H. Wolpert and William G. Macready. No free lunch theorems for optimization. IEEE Trans.
Evol. Comput., 1:67–82, 1997."
REFERENCES,0.6666666666666666,"Simon N. Wood. Statistical inference for noisy nonlinear ecological dynamic systems. Nature, 466:
1102–1104, 2010."
REFERENCES,0.6693989071038251,Published as a conference paper at ICLR 2022
REFERENCES,0.6721311475409836,"Zachary Wu, S B Jennifer Kan, Russell D Lewis, Bruce J. Wittmann, and Frances H. Arnold. Ma-
chine learning-assisted directed protein evolution with combinatorial libraries. Proceedings of the
National Academy of Sciences, 116:8852 – 8858, 2019."
REFERENCES,0.674863387978142,"Kevin K. Yang, Zachary Wu, and Frances H. Arnold. Machine-learning-guided directed evolution
for protein engineering. Nature Methods, pp. 1–8, 2019."
REFERENCES,0.6775956284153005,"Naruki Yoshikawa, Kei Terayama, Masato Sumita, Teruki Homma, Kenta Oono, and Koji Tsuda.
Population-based de novo molecule generation, using grammatical evolution. Chemistry Letters,
47(11):1431–1434, 2018."
REFERENCES,0.680327868852459,"Zhenpeng Zhou, Steven M. Kearnes, Li Li, Richard N. Zare, and Patrick F. Riley. Optimization of
molecules via deep reinforcement learning. Scientiﬁc Reports, 9, 2019."
REFERENCES,0.6830601092896175,Published as a conference paper at ICLR 2022
REFERENCES,0.6857923497267759,"A
MORE ABOUT METHODOLOGY"
REFERENCES,0.6885245901639344,"A.1
BACKWARD MODELING OF THE MECHANISM"
REFERENCES,0.6912568306010929,"About SMC-ABC. In Algorithm 1, when we pick the top-m θ at the r-th round, the picked param-
eters actually follow such a distribution"
REFERENCES,0.6939890710382514,"p(θ|xo) ∝ r
X"
REFERENCES,0.6967213114754098,"l=1
pl(θ) · p(∥x −xo∥< ϵ | θ) = r
X"
REFERENCES,0.6994535519125683,"l=1
pl(θ) !"
REFERENCES,0.7021857923497268,"· p(∥x −xo∥< ϵ | θ)
(5)"
REFERENCES,0.7049180327868853,"where the ϵ here is implicitly deﬁned by how ”top” the selection process is, namely the ratio m"
REFERENCES,0.7076502732240437,"nr. As
a result, we point out that in Algorithm 1, another more complicated form of the last step pr+1(θ) ←
qφ(θ) is pr+1(θ) ∝qφ(θ)p(θ)/ Pr
l pl(θ), where an additional renormalizing term is involved. We
ignore this term and used the simpler alternative in order to keep our main text clean. We refer
interested readers to Beaumont et al. (2009) for more details."
REFERENCES,0.7103825136612022,"About Sequential Neural Posterior. Deﬁne p(x) =
R
p(x|θ)p(θ)dθ and ˜p(x) =
R
p(x|θ)˜p(θ)dθ
for any arbitrary proposal distribution ˜p(θ) which is not necessary to be the prior p(θ). What’s more,
we deﬁne p(θ|x) = p(x|θ)p(θ)/p(x) and ˜p(θ|x) = p(x|θ)˜p(θ)/˜p(x) to be the true posterior and
the proposal posterior."
REFERENCES,0.7131147540983607,"Starting from the goal of approximating the true posterior,"
REFERENCES,0.7158469945355191,"arg min
q
Ep(x)[DKL(p(θ|x)∥q(θ|x))] = arg max
q"
REFERENCES,0.7185792349726776,"Z
p(x)dx
Z
p(θ|x) log q(θ|x)dθ"
REFERENCES,0.7213114754098361,"= arg max
q"
REFERENCES,0.7240437158469946,"Z
p(θ, x) log q(θ|x)dθx"
REFERENCES,0.726775956284153,"= arg max
q
Ep(θ,x)[log q(θ|x)]."
REFERENCES,0.7295081967213115,"It seems that we can directly train the parameterized neural density estimator qφ in a data driven
manner via maxφ
P"
REFERENCES,0.73224043715847,"i log qφ(θi|xi) where i is the index for data sample. When the number of
training samples as well as the parameterization family of φ are large enough, the obtained qφ would
be close enough to the true posterior. This would require the data samples to follow (θi, xi) ∼
p(θ, x) = p(θ)p(x|θ). However, practically one uses a proposal ˜p(θ) to ﬁrst generate some {θi}i
and then generate {xi}i by simulation. When the proposal distribution ˜p(θ) is not exactly the prior
distribution p(θ), the resulting qφ(·|·) would be:"
REFERENCES,0.7349726775956285,˜p(θ|x) = p(θ|x) ˜p(θ)p(x)
REFERENCES,0.7377049180327869,p(θ)˜p(x) ∝p(θ|x) ˜p(θ)
REFERENCES,0.7404371584699454,"p(θ),
(6)"
REFERENCES,0.7431693989071039,which is a biased estimation and is not what we want.
REFERENCES,0.7459016393442623,"Three variants of SNP take different approaches to try to ﬁx this bias. SNP-A (Papamakarios & Mur-
ray, 2016) ﬁrst ﬁts the biased proposal posterior ˜p(θ|x) in the aforementioned way and utilize the
relation in Eq. 6 to solve for an unbiased estimation. This approach is restricted to mixture of Gaus-
sian distribution family and thus has limited expressiveness. SNP-B (Lueckmann et al., 2017) uses
importance sampling to address this issue via maxφ E(x,θ)∼p(x|θ)˜p(θ)
h
p(θ)"
REFERENCES,0.7486338797814208,"˜p(θ) log qφ(θ | x)
i
. One"
REFERENCES,0.7513661202185792,"downside of this approach is the high variance involved by the importance weights p(θ)/˜p(θ).
SNP-C (Greenberg et al., 2019) proposes to use reparameterize the proposal posterior by setting
˜qφ(θ|x) = qφ(θ|x) ˜p(θ)"
REFERENCES,0.7540983606557377,"p(θ)
1
Zφ(x) where Zφ(x) =
R
qφ(θ|x) ˜p(θ)"
REFERENCES,0.7568306010928961,"p(θ)dθ is the corresponding normalizing
factor for x. SNP-C then maximizes E(x,θ)∼p(x|θ)˜p(θ) [log ˜qφ(θ | x)]."
REFERENCES,0.7595628415300546,"About Design by Adaptive Sampling. We aim to approximate the posterior via minimizing the KL
divergence:"
REFERENCES,0.7622950819672131,Published as a conference paper at ICLR 2022
REFERENCES,0.7650273224043715,"arg min
q
DKL(p(m|E)∥q(m)) = arg max
q"
REFERENCES,0.76775956284153,"Z
p(m|E) log q(m)dm"
REFERENCES,0.7704918032786885,"= arg max
q"
REFERENCES,0.773224043715847,"Z
p(E|m)p(m) log q(m)dm"
REFERENCES,0.7759562841530054,"= arg max
q
E˜q(m) p(m)"
REFERENCES,0.7786885245901639,"˜q(m)p(E|m) log q(m)

,"
REFERENCES,0.7814207650273224,"where ˜q(m) could be any distribution of m. Brookes et al. (2019) takes this formulation. Brookes
& Listgarten (2018) only differs in the place that it ignores the denominator term. According to
Angerm¨uller et al. (2020b), we choose the latter variant as one of our baselines because it is more
stable in practice. We refer interested readers to Brookes & Listgarten (2018) for more details."
REFERENCES,0.7841530054644809,"Notice that we are not doing exactly the same things for LFI and black-box sequence design. Since
LFI models ﬂexible posterior p(θ|x) which is a distribution for arbitrary x, we can also choose
to model p(m|s) for arbitrary s. Nevertheless, in the neural network modeling, conditioning by a
scalar value is not an effective approach as the effect of low dimensional scalar value conditioning
may be covered by other high dimensional input. Therefore, we choose to directly model the target
posterior p(m|E) with a single neural network."
REFERENCES,0.7868852459016393,"A.2
FORWARD MODELING OF THE MECHANISM"
REFERENCES,0.7896174863387978,"We still use ˜p(θ) to denote an arbitrary proposal distribution and ˜p(θ, x) := p(x|θ)˜p(θ). Then we
have"
REFERENCES,0.7923497267759563,"arg min
q
E˜p(θ) [DKL (p(x|θ)∥q(x|θ))] = arg max
q"
REFERENCES,0.7950819672131147,"Z
˜p(θ)dθ
Z
p(x|θ) log q(x|θ)dx"
REFERENCES,0.7978142076502732,"= arg max
q
E˜p(θ,x) [log q(x|θ)] ."
REFERENCES,0.8005464480874317,"We point out that with much enough data and large enough expressiveness of the neural density
estimator parameterization family, no matter what proposal ˜p(θ) is used to provide training samples
{(θi, xi)}i ∼˜p(θ, x), we have the resulting q ˆφ(θ|x) equals true likelihood p(x|θ) in the support of
the proposal. What SNL gives is an unbiased estimation and thus does not have the same problem
as SNP."
REFERENCES,0.8032786885245902,"Now we elaborate the construction of ˜q(m) in Iterative Scoring algorithm. Here we use the notation
˜q(m) to denote our approximation of the posterior p(m|E). Notice that we want ˜q(m) ∝p(m) ·
p(E|m). If we choose Example A to serve as the deﬁnition of event E, then the samples of ˜q(m)
can be obtained in this way: (1) sample m from prior p(m) and (2) accept this sample if ˆfφ(m)
is larger than threshold s, or otherwise reject it. Alternatively, if we choose Example B, we have
˜q(m) ∝p(m) · exp( ˆfφ(m)/τ). Similar to SNL, we do MCMC sampling from this unnormalized
probability function."
REFERENCES,0.8060109289617486,"A.3
MODELING A PROBABILITY RATIO"
REFERENCES,0.8087431693989071,"About Sequential Neural Ratio. Dataset D is generated in the way that (1) ﬁrst sample θ ∼p(θ)
and (2) simulate x ∼p(x|θ). Consequently, D follows the distribution p(θ)p(x|θ) = p(θ, x). On
the other hand, the other dataset D′ generates θ and x in parallel and independent manner. Notice
here θ ∼p(θ) and x follows the marginal distribution: x ∼p(x) =
R
p(θ)p(x|θ)dθ."
REFERENCES,0.8114754098360656,Proof of Proposition 1.
REFERENCES,0.8142076502732241,Proof. We deﬁne a functional F to be the optimization objective:
REFERENCES,0.8169398907103825,F[d] = Ea∼p0(a)[log d(a)] + Ea∼p1(a)[log(1 −d(a))]
REFERENCES,0.819672131147541,Published as a conference paper at ICLR 2022
REFERENCES,0.8224043715846995,We calculate its functional derivative. For arbitrary function u and inﬁnite small ϵ
REFERENCES,0.825136612021858,F[d + ϵu] −F[d] = Ep0[log(1 + ϵu
REFERENCES,0.8278688524590164,d)] + Ep1[log(1 + ϵ −u
REFERENCES,0.8306010928961749,1 −d)]
REFERENCES,0.8333333333333334,"= ϵ
Z
u ·
p0"
REFERENCES,0.8360655737704918,d + −p1 1 −d
REFERENCES,0.8387978142076503,"
+ O(ϵ)"
REFERENCES,0.8415300546448088,"⇒lim
ϵ→0
F[d + ϵu] −F[d]"
REFERENCES,0.8442622950819673,"ϵ
=
Z
u ·
p0"
REFERENCES,0.8469945355191257,d + −p1 1 −d
REFERENCES,0.8497267759562842,"
=
Z
u · δF."
REFERENCES,0.8524590163934426,We set the functional derivative to zero:
REFERENCES,0.855191256830601,δF = 0 ⇒p0
REFERENCES,0.8579234972677595,"p1
=
d
1 −d"
REFERENCES,0.860655737704918,"⇒d(a) =
p0(a)
p0(a) + p1(a)."
REFERENCES,0.8633879781420765,"This optimal function d∗apparently takes value in [0, 1]."
REFERENCES,0.8661202185792349,"About Iterative Ratio. Notice that in Algorithm 8 we construct two datasets: ˜D and ˜D′. To generate
˜D, we need to be able to pick some sequence samples m from D and make the selected ones follow
the posterior p(m|E). This procedure will depend on our choice of event E. For Example A this is
easy, since we just need to ﬁlter out the sequences whose oracle value is smaller than the threshold.
However, for Example B, it is hard to do similar things, since given score value from D we only
know the unnormalized value of posterior probability, and cannot determine which sequence should
be ﬁltered out. The construction of ˜D′ which follows prior distribution p(m) is trivial."
REFERENCES,0.8688524590163934,"A.4
COMPOSITE PROBABILISTIC METHODS"
REFERENCES,0.8715846994535519,"For IPS, the optimization with regard to the second parameterized model qψ(m) is"
REFERENCES,0.8743169398907104,"qψ = arg min
q
DKL(˜q(m)∥q) = arg max
q"
REFERENCES,0.8770491803278688,"Z
˜q(m) log q(m)dm"
REFERENCES,0.8797814207650273,"= arg max
q"
REFERENCES,0.8825136612021858,"Z
p(m|E) log q(m)dm = arg max
q"
REFERENCES,0.8852459016393442,"Z
p(E|m)p(m) log q(m)dm."
REFERENCES,0.8879781420765027,"The exact value of p(E|m) depends on different choices of conﬁguration feature E in Section 2.2.
On the other hand, IPR, like IR, also only has one variant, which is with Example A:"
REFERENCES,0.8907103825136612,"qψ = arg min
q
DKL(˜q(m)∥q) = arg max
q"
REFERENCES,0.8934426229508197,"Z
rφ(m)p(m) log q(m)dm,"
REFERENCES,0.8961748633879781,"which is a tractable optimization problem. Both IPR and IR are not ﬁt for Example B since it cannot
provide an exact probability value and thus cannot be adopted to construct ˜D."
REFERENCES,0.8989071038251366,"B
MORE ABOUT EXPERIMENTS"
REFERENCES,0.9016393442622951,"Random method uses no neural network model. FB-VAE uses a VAE model. The encoder of the
VAE ﬁrst linearly transform one-hot input into a hidden feature which is 64 dimension, and then sep-
arately linearly transform to a 64-dimension mean output and 64-dimension variance output. The
decoder contains a 64×64 linear layer and a linear layer that maps the hidden feature to categorical
output. All other methods utilize bi-directional long short-term memory model (BiLSTM) (Hochre-
iter & Schmidhuber, 1997) with a linear embedding layer. Both the embedding dimension and the
hidden size of LSTM is set to 32. For composite methods that use two models, we use one-layer
LSTM for each of them. For the other algorithms that only use one LSTM, we set its number of"
REFERENCES,0.9043715846994536,Published as a conference paper at ICLR 2022
REFERENCES,0.907103825136612,"2
1
0
1
2"
REFERENCES,0.9098360655737705,POU6F2_REF_R1
REFERENCES,0.912568306010929,"2
1
0
1
2"
REFERENCES,0.9153005464480874,POU6F2_REF_R1  final sequences
REFERENCES,0.9180327868852459,"2
1
0
1
2"
REFERENCES,0.9207650273224044,KLF11_R402Q_R1
REFERENCES,0.9234972677595629,"2
1
0
1
2"
REFERENCES,0.9262295081967213,KLF11_R402Q_R1  final sequences
REFERENCES,0.9289617486338798,"IS-A
IS-B
IR
IPS-A
IPS-B
IPR
Random
Evolution
DbAS
FB-VAE"
REFERENCES,0.9316939890710383,Figure 3: Diversity visualization results for two TfBind tasks.
REFERENCES,0.9344262295081968,"IS-A
IS-B
IR
IPS-A
IPS-B
IPR
RANDOM
EVO.
DBAS
FB-VAE"
REFERENCES,0.9371584699453552,"POU6F2 REF R1
9
7
3
5
10
8
1
4
6
2
KLF11 R402Q R1
8
6
5
7
9
10
1
4
2
3
EGR2 R359W R1
4
5
8
9
7
6
1
2
10
3
HOXD13 S316C R1
8
10
3
4
7
9
1
5
6
2
HOXB7 K191R R1
10
8
6
4
9
3
1
5
7
2
PBX4 REF R2
10
9
8
7
5
4
1
6
2
3
GFI1B A204T R1
8
7
3
4
9
10
1
6
5
2
FOXC1 REF R1
10
8
3
5
7
9
1
4
6
2
KLF1 REF R1
6
4
7
9
8
10
3
1
2
5
SIX6 REF R1
8
7
3
10
9
6
1
5
2
4
ARX L343Q R2
10
3
4
7
9
5
1
6
8
2
CRX E80A R1
9
10
7
5
8
2
1
6
3
4
ESX1 K193R R1
9
6
3
5
10
8
1
4
7
2
VSX1 G160D R1
9
7
4
6
10
8
1
3
5
2"
REFERENCES,0.9398907103825137,"AVERAGE
8.43
6.93
4.79
6.21
8.36
7.00
1.14
4.36
5.07
2.71"
REFERENCES,0.9426229508196722,"Table 4:
Top-10 score ranking for the TfBind instances that we adopt. “Evo.” stands for the
evolution algorithm."
REFERENCES,0.9453551912568307,"layers to be two. No Dropout (Srivastava et al., 2014) is used in LSTM models. In this way, the num-
ber of parameters of the VAE is slightly larger than that of the two layer BiLSTM, and all methods
(except Random) share similar model parameter size."
REFERENCES,0.9480874316939891,"All the experiments are repeated with ﬁfty random seeds and report the mean value (and also stan-
dard deviation in the ﬁgure plots). We set p(m) to be uniform prior for all tasks for simplicity,
which uniformly samples from the dictionary V for each entry of the sequence. For length alterable
task, we ﬁrst uniformly sample the length between minimum length and maximum length and then
sample each entry."
REFERENCES,0.9508196721311475,"We explain details about evolution based method mentioned in the main text, which can be seen as a
substantial example of directed evolution (Chen & Arnold, 1991). Like other model based methods,
Evolution also trains an LSTM regressor to predict the score of a sequence, which is further used
to assist in the reproduce procedure. The Evolution algorithm maintains a generation list through
the whole exploration process. In each round, the method mutates and reproduces the sequences to
enlarge the generation list, and then utilizes the learned regressor to select top sequences for the next
generation."
REFERENCES,0.953551912568306,"For validation, we follow (Angerm¨uller et al., 2020b) and sweep each algorithm for ﬁfty trials and
pick the best conﬁguration. We tune learning rate and whether to re-initialize the optimizer for
each new round for all methods. We tune threshold for DbAS, FB-VAE and the methods that is
with Example A. For the other choice of E, we tune the temperature. For evolution, we tune the
number of offsprings for each sequence in generation list, the probability of substitution, insertion
and deletion. For TfBind we use ZNF200 S265Y R1 for validation. For UTR, AMP and Fluo, since
we only have one oracle instance for each benchmark, we do not use a hold-out validation method."
REFERENCES,0.9562841530054644,Published as a conference paper at ICLR 2022
REFERENCES,0.9590163934426229,"IS-A
IS-B
IR
IPS-A
IPS-B
IPR
RANDOM
EVO.
DBAS
FB-VAE"
REFERENCES,0.9617486338797814,"POU6F2 REF R1
10
8
3
5
9
6
1
7
4
2
KLF11 R402Q R1
10
7
4
8
9
6
1
5
3
2
EGR2 R359W R1
7
8
4
10
5
9
1
3
6
2
HOXD13 S316C R1
10
9
3
4
7
6
1
5
8
2
HOXB7 K191R R1
10
9
3
6
8
4
1
5
7
2
PBX4 REF R2
10
9
7
5
6
4
1
8
3
2
GFI1B A204T R1
10
7
4
5
9
6
1
8
3
2
FOXC1 REF R1
10
7
4
8
6
9
1
5
3
2
KLF1 REF R1
8
6
5
9
7
10
1
4
3
2
SIX6 REF R1
9
7
5
10
8
4
1
6
3
2
ARX L343Q R2
10
7
4
8
9
3
1
6
5
2
CRX E80A R1
10
9
5
7
8
4
1
6
3
2
ESX1 K193R R1
10
9
3
4
8
6
1
5
7
2
VSX1 G160D R1
10
9
3
5
8
7
1
4
6
2"
REFERENCES,0.9644808743169399,"AVERAGE
9.57
7.93
4.07
6.71
7.64
6.00
1.00
5.50
4.57
2.00"
REFERENCES,0.9672131147540983,"Table 5:
Top-100 score ranking for the TfBind instances that we adopt. “Evo.” stands for the
evolution algorithm."
REFERENCES,0.9699453551912568,"IS-A
IS-B
IR
IPS-A
IPS-B
IPR
RANDOM
EVOLUTION
DBAS
FB-VAE"
REFERENCES,0.9726775956284153,"UTR
10.87
11.71
11.43
12.06
12.15
11.94
10.60
11.20
11.89
10.65
AMP
−2.98
−2.67
−2.84
−2.54
−2.16
−2.74
−3.36
−3.09
−2.73
−2.80
FLUO
35.31
35.82
35.59
46.19
44.28
43.88
34.33
37.40
43.45
34.78"
REFERENCES,0.9754098360655737,"Table 6: Comparison of the area under top-10 curves for UTR, AMP and Fluo benchmarks. Larger
area means better sample efﬁciency."
REFERENCES,0.9781420765027322,"For TfBind benchmark, we use the following transcription factor instances and treat them as differ-
ent black-box optimization tasks: ZNF200 S265Y R1, POU6F2 REF R1 8, KLF11 R402Q R1,
EGR2 R359W R1, HOXD13 S316C R1, HOXB7 K191R R1, PBX4 REF R2, GFI1B A204T R1,
FOXC1 REF R1,
KLF1 REF R1,
SIX6 REF R1,
ARX L343Q R2,
CRX E80A R1,
ESX1 K193R R1 and VSX1 G160D R1.
We do not do post-processing such as score nor-
malization whitening for the data for simplicity.
We ﬁrst calculate the area under curve to
summarize the performance in a scalar output, and put the ranking result for each algorithm in
Table 4 and Table 5, which provide more details for Table 2. To further investigate the diversity of
different algorithms, we choose two TfBind instances (POU6F2 REF R1 and KLF11 R402Q R1)
and visualize the resulting sequences with T-SNE (van der Maaten & Hinton, 2008) in Figure 3.
We provide two visualization views for both task instances: (1) we uniformly sample 20 sequences
from the whole n · R sequences for each algorithm and visualize them; (2) for each algorithm,
we visualize 20 sequences uniformly sampled from the last batch (i.e., at the last round). This is
notated with “ﬁnal sequences” in the ﬁgure. We do not visualize all the sequences for simplicity.
We use Hamming distance in the computation of T-SNE. From Figure 3, we can see that there is
no obvious difference for the evaluated methods. This indicates that our proposed methods can
achieve better performance while maintaining on-par diversity level with the baselines. This is not
exactly consistent to the ﬁndings of Angerm¨uller et al. (2020a), which claims some algorithms such
as DbAS achieve very limited diversity. We do not use the “optima fraction” metric in Angerm¨uller
et al. (2020a;b), since this metric may not deal with multimode oracle landscape well and needs
extra unstable computation such as clustering.
Besides, this metric cannot generalize to other
benchmarks."
REFERENCES,0.9808743169398907,"We elaborate the construction of our AMP oracle. We use the AMP dataset from (Witten & Witten,
2019) which contains 6,760 AMP sequences. A multilayer perceptron classiﬁer is trained to predict
if a protein sequence can prohibit the growth of a particular pathogen in that AMP dataset. This clas-
siﬁer operates on the features extracted by ProtAlbert (Elnaggar et al., 2020) model. Following the
setup in (Angerm¨uller et al., 2020b), we treat the predicted logits as the ground-truth measurement.
Moreover, we demonstrate the area under Top-10 curves for UTR, AMP and Fluo benchmarks in
Table 6, which is a good complement for Table 3 but is missing due to limited space in the main text."
REFERENCES,0.9836065573770492,Published as a conference paper at ICLR 2022
REFERENCES,0.9863387978142076,"C
RELATED WORKS AND DISCUSSION"
REFERENCES,0.9890710382513661,"Likelihood-free inference. We have already introduced the main classes of likelihood-free infer-
ence algorithms in the main text: (1) Approximate Bayesian Computation (ABC) method (Beaumont
et al., 2009; Blum, 2009; Marin et al., 2012; Lintusaari et al., 2017) in Section 3.1; (2) Posterior
modeling method that is also stated in Section 3.1, including classical ones (Tran et al., 2015; Li
et al., 2017; Chen & Gutmann, 2019) and modern SNP methods (Papamakarios & Murray, 2016;
Lueckmann et al., 2017; Greenberg et al., 2019); (3) Likelihood modeling method described in Sec-
tion 3.2, also containing various classical algorithms (Wood, 2010; Mengersen et al., 2012; Drovandi
et al., 2018) and modern SNL variants (Lueckmann et al., 2018; Papamakarios et al., 2019); and (4)
Probability ratio modeling methods mentioned in Section 3.3 diverge in estimating likelihood ratio
(Gutmann & Hyv¨arinen, 2010; Gutmann et al., 2018; Brehmer et al., 2020) or likelihood-to-evidence
ratio (Thomas et al., 2016; Izbicki et al., 2014), where the latter paradigm is a good ﬁt for LFI prob-
lem (Hermans et al., 2019). Besides, there are also works about how to construct low-dimensional
summary statistics for LFI (Fearnhead & Prangle, 2012; Chan et al., 2018; Chen et al., 2021)."
REFERENCES,0.9918032786885246,"Machine learning based drug design. Generative modeling and discriminative modeling are two
basic ways of thinking in machine learning. In literature for sequence design, generative modeling
is also known as cross entropy method. This is a famous kind of design method that is close to our
“backward modeling of the mechanism” approach. Cross entropy methods seek to solve an expec-
tation maximization problem (i.e., maxp Ep(m)[f(m)]) where the sequences follow a distribution p.
This can also be related to simulated annealing, a large family of black-box optimization algorithm
– the sequential neural posterior could be thought to maintain a distribution which is gradually be-
coming sharper to a delta distribution at the optimal value. On the other hand, we think of this as a
way for modeling the posterior p(m|E) and develop corresponding analysis under the probabilistic
framework, which is like a more accurate version of cross entropy method. Many related methods
(including the ones stated in Section 3.1) train the distribution by likelihood maximization for se-
quences with large scores, or use some sort of reweighting to achieve similar effects (Rubinstein &
Kroese, 2004; de Boer et al., 2005; Neil et al., 2018; Gupta & Zou, 2019; Brookes et al., 2019)."
REFERENCES,0.994535519125683,"Discriminative modeling usually goes in a “model-based optimization” way (terminology from
Angerm¨uller et al. (2020a)), i.e., use a discriminative model ˆf(m) to ﬁt the real oracle f(m) and act
as a surrogate for it. The surrogate model can replace the true oracle f(m) which involves costly bi-
ological experiments. This corresponds to our “forward modeling of the mechanism” in Section 3.2.
Bayesian optimization (Shahriari et al., 2016) is a classical example, which utilizes ˆf (typically a
Gaussian process model) to deﬁne an acquisition function to guide the exploration and exploitation.
Many modern biochemical methods also belong to this category (G´omez-Bombarelli et al., 2018;
Hashimoto et al., 2018; Yang et al., 2019; Wu et al., 2019; Sample et al., 2019; Liu et al., 2020)."
REFERENCES,0.9972677595628415,"There seems not much related literature about probability ratio estimation based method in this
topic. On the other hand, Hashimoto et al. (2018) shares a classiﬁcation based approach with IR but
they differ on how to use the classiﬁer. This algorithm utilizes the learned classiﬁer to update the
proposal with multiplicative weights algorithm, making the proposal to have large probability where
the classiﬁer logit is small. Other categories of drug design methods include evolution algorithms
(Brindle, 1980; Wierstra et al., 2008; Salimans et al., 2017; Yoshikawa et al., 2018; Jensen, 2019;
Real et al., 2019; Ahn et al., 2020) that search over the target space with genetic operators like insert,
mutation, and crossover, and reinforcement learning (Guimaraes et al., 2017; Neil et al., 2018; Zhou
et al., 2019; Shi et al., 2020; Angerm¨uller et al., 2020b) which see the formation of a drug as a
Markov decision process and train the policy to learn highly-rewarding drugs. We do not ﬁnd other
work that is similar to our probability ratio modeling approach (Section 3.3) from the literature,
which we take as a novel contribution."
