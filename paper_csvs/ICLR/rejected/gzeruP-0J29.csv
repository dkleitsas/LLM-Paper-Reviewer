Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0033783783783783786,"Adversarial training (AT) has become a widely recognized defense mechanism
to improve the robustness of deep neural networks against adversarial attacks. It
originated from solving a min-max optimization problem, where the minimizer
(i.e., defender) seeks a robust model to minimize the worst-case training loss in the
presence of adversarial examples crafted by the maximizer (i.e., attacker). However,
the min-max nature makes AT computationally intensive and thus difﬁcult to scale.
Thus, the problem of FAST-AT arises. Nearly all the recent progress is achieved
based on the following simpliﬁcation: The iterative attack generation method used
in the maximization step of AT is replaced by the simplest one-shot gradient sign-
based PGD method. Nevertheless, FAST-AT is far from satisfactory, and it lacks
theoretically-grounded design. For example, a FAST-AT method may suffer from
robustness catastrophic overﬁtting when training with strong adversaries.
In this paper, we foster a technological breakthrough for designing FAST-AT
through the lens of bi-level optimization (BLO) instead of min-max optimization.
First, we theoretically show that the most commonly-used algorithmic speciﬁcation
of FAST-AT is equivalent to the linearized BLO along the direction given by the
sign of input gradient. Second, with the aid of BLO, we develop a new systematic
and effective fast bi-level AT framework, termed FAST-BAT, whose algorithm is
rigorously derived by leveraging the theory of implicit gradient. In contrast to FAST-
AT, FAST-BAT has the least restriction to placing the tradeoff between computation
efﬁciency and adversarial robustness. For example, it is capable of defending
sign-based projected gradient descent (PGD) attacks without calling any gradient
sign method and explicit robust regularization during training. Furthermore, we
empirically show that our method outperforms state-of-the-art FAST-AT baselines.
In particular, FAST-BAT can achieve superior model robustness without inducing
robustness catastrophic overﬁtting and losing standard accuracy."
INTRODUCTION,0.006756756756756757,"1
INTRODUCTION"
INTRODUCTION,0.010135135135135136,"Given the fact that machine learning (ML) models can be easily fooled by tiny adversarial perturba-
tions (also known as adversarial attacks) on the input (Goodfellow et al., 2014; Carlini & Wagner,
2017; Papernot et al., 2016), learning robust deep neural networks (DNNs) is now a major focus in
research. Nearly all existing effective defense mechanisms (Madry et al., 2018; Zhang et al., 2019b;
Shafahi et al., 2019; Wong et al., 2020; Zhang et al., 2019a; Athalye et al., 2018a) are built on the ad-
versarial training (AT) recipe, ﬁrst developed in (Szegedy et al., 2014) and later formalized in (Madry
et al., 2018) using min-max optimization. In contrast to standard model training using empirical
risk minimization, AT (Madry et al., 2018) calls min-max optimization. That is, a minimizer (i.e.
defender) seeks to update model parameters against a maximizer (i.e. attacker) that aims to worsen
the training loss by perturbing each training example."
INTRODUCTION,0.013513513513513514,"The AT-type defenses have been widely adopted in various application domains including image
classiﬁcation (Goodfellow et al., 2014; Madry et al., 2018; Kurakin et al., 2017), object detection
(Zhang & Wang, 2019), natural language processing (Miyato et al., 2016; Zhu et al., 2019), and
healthcare (Finlayson et al., 2019; Mahmood et al., 2019). Despite their effectiveness, the min-max
optimization nature makes them difﬁcult to scale. This is because multiple maximization steps"
INTRODUCTION,0.016891891891891893,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.02027027027027027,"(required by an iterative attack generator) are needed at every model training step in AT. The resulting
prohibitive computation cost prevents AT from a feasible solution to enhance adversarial robustness
when computing resource is limited. For example, Xie et al. (2019) used 128 GPUs to make AT
practical on ImageNet. Thereby, how to speed up AT without losing accuracy and robustness is now
a grand challenge for adversarial defense."
INTRODUCTION,0.02364864864864865,"Very recently, some work attempted to develop computationally-efﬁcient alternatives of AT, which we
call ‘fast’ versions of AT (Shafahi et al., 2019; Zhang et al., 2019a; Wong et al., 2020; Andriushchenko
& Flammarion, 2020). To the best of our knowledge, FAST-AT (Wong et al., 2020) and FAST-AT
with gradient alignment (GA) regularization, termed FAST-AT-GA (Andriushchenko & Flammarion,
2020), are the two state-of-the-art (SOTA) ‘fast’ versions of AT, since they achieve a signiﬁcant
reduction in computation complexity and preserve accuracy and robustness to some extent. To
be speciﬁc, FAST-AT (Wong et al., 2020) replaces an iterative attack generator used in AT with
a heuristics-based single-step attack generation method. Thus, it merely takes computation cost
comparable to standard model training. However, FAST-AT suffers two main issues: (i) lack of
stability, i.e., large variance in performance (Li et al., 2020), and (ii) robustness catastrophic overﬁtting,
i.e., a large drop of robustness when training with strong adversaries (Andriushchenko & Flammarion,
2020). To alleviate these problems, Andriushchenko & Flammarion (2020) proposed FAST-AT-GA
by penalizing FAST-AT using an explicit robust regularization given by GA. However, we will show
that FAST-AT-GA encounters a new problem (iii): FAST-AT-GA hampers standard accuracy, making
a poor accuracy-robustness tradeoff at large attack budget (ϵ = 16/255), i.e. the improvement on RA
is at cost of a sharp drop on SA. Given the limitations (i)-(iii), we ask:"
INTRODUCTION,0.02702702702702703,"How to design a theoretically-grounded ‘fast’ version of AT with improved stability, mitigated
catastrophic overﬁtting, and enhanced accuracy-robustness tradeoff?"
INTRODUCTION,0.030405405405405407,"To address above question, paper we revisit and advance AT through the lens of bi-level optimization
(BLO) (Dempe, 2002), where we cast the attack generation problem as a lower-level optimization
problem with constraints and the defense as an upper-level optimization problem in the objective.
To the best of our knowledge, this is the ﬁrst work to make a solid connection between adversarial
defense and BLO. Technically, we show that FAST-AT can be interpreted as BLO with linearized
lower-level problems. Delving into linearization of BLO, we propose a novel, theoretically-grounded
‘fast’ AT framework, fast bi-level AT (FAST-BAT). Practically, Table 1 highlights some achieved
improvements over FAST-AT and FAST-AT-GA: When a stronger train-time attack (i.e., ϵ = 16/255
vs. 8/255) is adopted, FAST-AT suffers a large degradation of robust accuracy (RA) and standard
accuracy (SA), together with higher variances than proposed FAST-BAT. Although FAST-AT-GA
outperforms FAST-AT, it still incurs a signiﬁcant SA loss (over 21%) at ϵ = 16/255. By contrast,
FAST-BAT yields a more graceful SA-RA tradeoff: 9% improvement of SA without loss of RA.
Different from FAST-AT-GA, FAST-BAT achieves above improvements in stability, RA and SA
without resorting to any extra robust regularization and thus takes less computation cost."
INTRODUCTION,0.033783783783783786,"Table 1: Performance overview of proposed FAST-BAT vs. the baselines FAST-AT (Wong et al., 2020) and
FAST-AT-GA (Andriushchenko & Flammarion, 2020) on (CIFAR-10, PreActResNet-18). All methods are
robustly trained under two perturbation budgets ϵ = 8/255 and 16/255 over 20 epochs. We use the early-stop
policy (Rice et al., 2020) to report the model of best robustness for each method. The evaluation metrics include
robust accuracy (RA) against PGD-50-10 attacks (50-step PGD attack with 10 restarts) (Madry et al., 2018) at
ϵ = 8/255 and 16/255 (test-time ϵ is same as the train-time), RA against AutoAttack (AA) (Croce & Hein,
2020) at ϵ = 8/255 and 16/255, and computation time (per epoch). The result a±b represents mean a and
standard deviation b over 10 random trials. All experiments are run on a single Tesla-P100 GPU."
INTRODUCTION,0.037162162162162164,"Method
RA-PGD (%)
(ϵ = 8/255)"
INTRODUCTION,0.04054054054054054,"RA-PGD (%)
(ϵ = 16/255)"
INTRODUCTION,0.04391891891891892,"RA-AA (%)
(ϵ = 8/255)"
INTRODUCTION,0.0472972972972973,"RA-AA (%)
(ϵ = 16/255)"
INTRODUCTION,0.05067567567567568,"SA (%)
(ϵ = 8/255)"
INTRODUCTION,0.05405405405405406,"SA (%)
(ϵ = 16/255)
Time (s)"
INTRODUCTION,0.057432432432432436,"FAST-AT
45.47±0.39
21.79±0.93
41.97±0.15
12.57±0.33
81.72±0.36
46.02±2.79
42
FAST-AT-GA
47.43±0.42
26.22±0.19
43.52±0.32
18.03±0.39
79.84±0.49
58.57±1.19
150
FAST-BAT
48.74±0.11
26.15±0.12
44.89±0.12
18.21±0.15
79.43±0.08
67.79±0.08
135"
INTRODUCTION,0.060810810810810814,"Contributions.
We summarize our contributions below."
INTRODUCTION,0.06418918918918919,"x We propose a new formulation of adversarially robust training through the lens of BLO, yielding a
novel and theoretically-grounded interpretation of FAST-AT."
INTRODUCTION,0.06756756756756757,"y We propose a new systematic and effective fast BLO-oriented AT framework, termed FAST-BAT,
with rigorously-established theory and algorithm."
INTRODUCTION,0.07094594594594594,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.07432432432432433,"z We conduct extensive experiments on FAST-BAT, showing its improved stability, mitigated
catastrophic overﬁtting, and enhanced accuracy-robustness tradeoff; see illustrations in Table 1."
RELATED WORK,0.0777027027027027,"2
RELATED WORK"
RELATED WORK,0.08108108108108109,"Adversarial attack.
Adversarial attacks are techniques to generate malicious perturbations that are
imperceptible to humans but can mislead the machine learning (ML) models (Goodfellow et al., 2014;
Carlini & Wagner, 2017; Croce & Hein, 2020; Xu et al., 2019; Athalye et al., 2018b). A popular
threat model that an adversary used is known as ℓp-norm ball constrained attack (p ∈{0, 1, 2, ∞}).
This is also the focus of this paper. The adversarial attack has become a major approach to evaluate
the robustness of deep neural networks (DNNs) and thus, help build safe artiﬁcial intelligence in
many high stakes applications such as autonomous driving (Deng et al., 2020; Kumar et al., 2020),
surveillance (Thys et al., 2019; Xu et al., 2020), and healthcare (Finlayson et al., 2019)."
RELATED WORK,0.08445945945945946,"Adversarial defense and robust training at scale.
Our work falls into the category of robust
training, which was mostly built upon min-max optimization. For example, Madry et al. (2018)
established the framework of AT for the ﬁrst time, which has been recognized as one of the most
powerful defenses (Athalye et al., 2018a). Extended from AT, TRADES (Zhang et al., 2019b) sought
the optimal balance between robustness and generalization ability. Further, AT-type defense has
been generalized to the semi-/self-supervised settings (Carmon et al., 2019; Chen et al., 2020) and
integrated 1 with certiﬁed defense techniques such as randomized smoothing (Salman et al., 2019)."
RELATED WORK,0.08783783783783784,"Despite the effectiveness of AT and its variants, they need to take high computation costs. How to
speed up AT without losing performance remains an open question. Some recent works attempted
to impose algorithmic simpliﬁcations to AT, leading to fast but approximate AT algorithms, such
as ‘free’ AT (Shafahi et al., 2019), you only propagate once (YOPO) (Zhang et al., 2019a), FAST-
AT (Wong et al., 2020), and FAST-AT regularized by gradient alignment (termed FAST-AT-GA)
(Andriushchenko & Flammarion, 2020). In particular, FAST-AT and FAST-AT-GA are the baselines
most relevant to ours since they were designed with the least computation complexity. However,
their defense performance is far from satisfactory. For example, FAST-AT has poor training stability
(Li et al., 2020) and suffers catastrophic overﬁtting when facing strong attacks (Andriushchenko &
Flammarion, 2020). In contrast to FAST-AT, FAST-AT-GA yields improved robustness but has a
poor accuracy-robustness tradeoff (e.g., Table 1). In this paper, we aim to advance the algorithm
foundation of ‘fast robust training’ through the lens of BLO (bi-level optimization). We will show that
the proposed FAST-BAT can lead to stable robust learning without suffering catastrophic overﬁtting
and graceful tradeoff between accuracy and robustness."
RELATED WORK,0.09121621621621621,"Bi-level optimization (BLO).
BLO is a uniﬁed hierarchical learning framework, where the objec-
tive and variables of an upper-level problem depend on the optimizer of certain lower-level problems.
The BLO problem in its most generic form is a class of very challenging problems, and thus, the
design of algorithms and theory for BLO focuses on special cases (Vicente et al., 1994; White
& Anandalingam, 1993; Gould et al., 2016; Ghadimi & Wang, 2018; Ji et al., 2020; Hong et al.,
2020). In practice, some successful applications of BLO to ML have been witnessed in meta-learning
(Rajeswaran et al., 2019), data poisoning attack design (Huang et al., 2020), and reinforcement
learning (Chen et al., 2019). However, as will be evident later, the existing BLO approach is not
directly applied to adversarial defense due to the presence of the constrained nonconvex lower-level
problem (for attack generation). To the best of our knowledge, our work makes a rigorous connection
between adversarial defense and BLO for the ﬁrst time."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.0945945945945946,"3
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.09797297297297297,"Preliminaries on FAST-AT.
FAST-AT is designed for solving the adversarial training problem
(Madry et al., 2018) given below"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.10135135135135136,"minimize
θ
E(x,y)∈D"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.10472972972972973,"
maximize
δ∈C
ℓtr(θ, x + δ, y)

,
(1)"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.10810810810810811,"where θ ∈Rn denotes model parameters, D is the training set consisting of labeled data pairs
with feature x and label y, δ ∈Rd represents adversarial perturbations subject to the perturbation"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.11148648648648649,Under review as a conference paper at ICLR 2022
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.11486486486486487,"constraint C, e.g., C = {δ | ∥δ∥∞≤ϵ, δ ∈[0, 1]} for ϵ-toleration ℓ∞-norm constrained attack
(normalized to [0, 1]), (x + δ) is then called adversarial example, and ℓtr(·) represents a training loss."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.11824324324324324,"The standard solver to problem (1) is known as AT (Madry et al., 2018). However, it has to call an
iterative optimization method (e.g., K-step PGD attack) to solve the inner maximization problem of
(1). As a result, AT is computationally intensive. To improve its scalability, FAST-AT that only takes
the single-step PGD attack for inner maximization was proposed and successfully implemented in
(Wong et al., 2020). The algorithm backbone of FAST-AT is summarized below."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.12162162162162163,FAST-AT algorithm
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.125,"Let θt be the model parameters at iteration t. The (t + 1)th iteration is given by
x (Inner maximization by 1-step PGD): δ ←−PC (δ0 + α · sign (∇δℓtr(θt, x + δ0, y))),
where PC(a) denotes the projection operation that projects the point a onto C, i.e., PC(z) =
arg minδ∈C ∥δ −z∥2
2, δ0 is a random uniform initialization within [0, 1], α > 0 is a proper
learning rate (e.g., 1.25ϵ), and sign(·) is the element-wise sign operation.
y (Outer minimization for model training): This can be conducted by any standard optimizer,
e.g., SGD. That is, θt+1 ←−θt −β∇θℓtr(θt, x + δ, y), where β > 0 is a proper learning rate
(e.g., cyclic learning rate), and δ is provided from the inner maximization step."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.12837837837837837,"Roughly speaking, FAST-AT is a simpliﬁcation of AT using 1-step PGD for inner maximization.
However, as shown in (Wong et al., 2020), the successful implementation of FAST-AT is different
from the 1-step PGD-based AT (Madry et al., 2018) due to the former’s sophisticated hyperparameter
choices in α, δ0, and β. Despite the efﬁcacy of FAST-AT in some cases, Andriushchenko &
Flammarion (2020) demonstrated that it could lead to the issue of robustness catastrophic overﬁtting
when facing strong adversaries during training. In the literature, there was no grounded theory to
justify the pros and cons of FAST-AT. We will show that BLO provides a promising solution."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.13175675675675674,"BLO: Towards a uniﬁed formulation of robust training.
BLO (bi-level optimization) is a uniﬁed
hierarchical learning framework, involving two levels (i.e., upper and lower levels) of optimization
tasks, where one task is nested inside the other (i.e., the objective and variables of an upper-level
problem depend on the optimizer of the lower-level problem). The hierarchical learning framework
provided by BLO can be used to precisely depict a robust training paradigm. Speciﬁcally, we can
cast robustiﬁcation as an upper-level problem whose optimization relies on a lower-level problem
deﬁned for attack generation. Thus, the BLO formulation of (1) is given by"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.13513513513513514,"minimize
θ
E(x,y)∈D[ℓtr(θ, x + δ∗(θ; x, y), y)]"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.13851351351351351,"subject to
δ∗(θ; x, y) = arg min
δ∈C
ℓatk(θ, δ; x, y),
(2)"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.14189189189189189,"where ℓatk denotes an attack objective. For notation simplicity, we will use data-omitted expressions
of ℓtr, ℓatk, and δ∗. The formulation (2) has two key differences from (1):"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.14527027027027026,"– First, the lower-level attack objective ℓatk is customizable, not necessarily to be same as the opposite
of the training objective, −ℓtr. As will be evident later, the ﬂexibility of attack conﬁguration in (2)
enables us to interpret FAST-AT through the lens of BLO."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.14864864864864866,"– Second, BLO calls an optimization routine different from min-max optimization used by (1). Even
if we set ℓatk = −ℓtr, problem (2) does not reduce to (1) due to the presence of lower-level constraint
δ ∈C (see rigorous analysis in Appendix B). Speciﬁcally, solving the upper-level problem of (2) by
gradient descent yields"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.15202702702702703,"dℓtr(θ, δ∗(θ))"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.1554054054054054,"dθ
= ∇θℓtr(θ, δ∗(θ)) + dδ∗(θ)⊤"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.15878378378378377,"dθ
|
{z
}
IG"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.16216216216216217,"∇δℓtr(θ, δ∗(θ)),
(3)"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.16554054054054054,"where the superscript ⊤denotes the transpose operation, and ∇θℓtr(θ, δ∗(θ)) denotes the partial
derivative with respect to (w.r.t.) the ﬁrst input argument θ. In (3), dδ∗(θ)⊤"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.16891891891891891,"dθ
∈Rn×d is referred to
as implicit gradient (IG) because it is deﬁned through an implicit constrained optimization problem
minδ∈C ℓatk. The dependence on IG is a ‘ﬁngerprint’ of BLO (1) in contrast to AT or FAST-AT."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.17229729729729729,"BLO-enabled interpretation of FAST-AT.
In what follows, we demonstrate how FAST-AT relates
to BLO. Our main ﬁnding is summarized below."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.17567567567567569,Under review as a conference paper at ICLR 2022
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.17905405405405406,Bi-level interpretation of FAST-AT
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.18243243243243243,FAST-AT can be interpreted as the lower-level linearized BLO with z = δ0 and λ = 1/α:
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.1858108108108108,"minimize
θ
E(x,y)∈D[ℓtr(θ, δ∗(θ))]"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.1891891891891892,"subject to
δ∗(θ) = arg min
δ∈C
[(δ −z)⊤sign(∇δ=zℓatk(θ, δ)) + (λ/2)∥δ −z∥2
2],
(4)"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.19256756756756757,"where z is the linearization point, ∇δ=zℓatk denotes the partial derivative of ℓatk (w.r.t. δ)
evaluated at z, sign(∇δ=zℓatk(θ, δ)) is the linearization direction, and λ > 0 is a regulariza-
tion parameter associated with the quadratic residual of linearization."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.19594594594594594,Our justiﬁcation on the above claim is elaborated on below.
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.19932432432432431,"– First, the simpliﬁed lower-level problem of (4) leads to the closed-form solution"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.20270270270270271,"δ∗(θ) = arg min
δ∈C
(λ/2)∥δ −z + (1/λ)sign(∇δ=zℓatk(θ, δ))∥2
2"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.20608108108108109,"=PC (z −(1/λ)sign(∇δ=zℓatk(θ, δ))) ,
(5)"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.20945945945945946,"which is given by the 1-step PGD attack with initialization z and learning rate (1/λ). In the lin-
earization used in (4), a quadratic regularization term (with regularization parameter λ) is introduced
to ensure the strong convexity of the inner-level attack objective within the constraint set δ ∈C.
Assisted by that, the lower-level solution is unique and its closed form is given by (5). Note that
imposing such a strongly convex regularizer is also commonly used to stabilize the convergence
of min-max optimization and BLO (Qian et al., 2019; Hong et al., 2020). If we set z = δ0 and
λ = 1/α, then (5) precisely depicts the inner maximization step used in FAST-AT ."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.21283783783783783,"– Second, by substituting (5) into the upper-level problem of (4), we can then follow (3) to update
the model parameters θ. However, this calls the computation of IG dδ∗(θ)⊤"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.21621621621621623,"dθ
. If we regard PC is
differentiable, then based on the closed-form of δ∗(θ) in (5), IG becomes"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.2195945945945946,dδ∗(θ)⊤
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.22297297297297297,"dθ
= 0,
(6)"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.22635135135135134,"where we use two facts: (1) The linearization point z is independent of θ, i.e. z = δ0; And (2)
dsign(·)"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.22972972972972974,"dθ
= 0 holds almost everywhere. Please refer to Appendix C for a rigorous proof of (6) using
KKT conditions. Clearly, the use of gradient sign method simpliﬁes the IG computation. Substituting
(6) into (3), the upper-level optimization of (4) yields θ ←−θ −β∇θℓtr(θ, δ∗(θ)) (with learning rate
β), which is precisely same as the outer minimization step used in FAST-AT."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.23310810810810811,"The aforementioned analysis shows that the linearized BLO (4) is equivalent to FAST-AT by setting
the linearization point z and the regularization parameter λ as z = δ0 and λ = 1/α."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.23648648648648649,"4
FAST-BAT: ADVANCING FAST-AT BY BLO"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.23986486486486486,"FAST-BAT and rationale.
The key take-away from (4) is that the conventional FAST-AT adopts
the sign of input gradient to linearize the lower-level attack objective. However, a more natural and
wiser choice is to use the ﬁrst-order Taylor expansion for linearization. By doing so, problem (4) can
be modiﬁed to the form of FAST-BAT"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.24324324324324326,"minimize
θ
E(x,y)∈D[ℓtr(θ, δ∗(θ))]"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.24662162162162163,"subject to
δ∗(θ) = arg min
δ∈C
[(δ −z)⊤∇δ=zℓatk(θ, δ) + (λ/2)∥δ −z∥2
2],
(7)"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.25,"where similar to (5), the lower-level problem can be solved analytically as"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.2533783783783784,"δ∗(θ) = PC (z −(1/λ)∇δ=zℓatk(θ, δ)) .
(8)"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.25675675675675674,"In contrast to (6), the IG associated with (7) is no longer vacant since the gradient sign operation
is not present in (8). To compute IG, the auto-differentiation (which calls the chain rule) can be
applied to the closed-form of δ∗(θ). However, this will not give us an accurate and generalizable IG
solution since the projection operation PC is not smooth and thus, the use of chain rule does not yield
a rigorous derivation. Therefore, the IG challenge arises, which will be addressed in what follows."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.26013513513513514,Under review as a conference paper at ICLR 2022
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.2635135135135135,"IG theory for FAST-BAT.
The problem of FAST-BAT (7) falls into a class of very challenging
BLO problems, which require constrained lower-level optimization. The unconstrained case is easier
to handle since one can apply the implicit function theory to the stationary condition of the lower-level
problem to obtain IG (Hong et al., 2020). Yet, in the case of constrained problems, a stationary point
could violate the constraints, and thus the stationary condition becomes non-applicable."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.2668918918918919,"In problem (7), we are dealing with a special class of lower-level constraints – linear constraints:"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.2702702702702703,"C = {∥δ∥∞≤ϵ, δ ∈[−x, 1 −x]} ⇐⇒Bδ ≤b, with B :=

I
−I"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.27364864864864863,"
, b :=

min{ϵ1, 1 −x}
−max{−ϵ1, −x}"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.27702702702702703,"
.
(9)"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.28040540540540543,"By exploiting above linearly constrained problem structure, we show that the IG challenge associated
with (7) can be addressed via Karush–Kuhn–Tucker (KKT) conditions. We summarize our main
theoretical result below and refer readers to Appendix A for detailed derivation."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.28378378378378377,"Theorem 1 With a Hessian-free assumption, i.e., ∇δδℓatk = 0, the IG (implicit gradient) of (7) is"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.28716216216216217,dδ∗(θ)⊤
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.2905405405405405,"dθ
= −(1/λ)∇θδℓatk(θ, δ∗)HC, with HC :=
1p1<δ∗
1 <q1e1
· · ·
1p1<δ∗
d<qded

,
(10)"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.2939189189189189,"where δ∗is given by (8), and ∇θδℓ(θ, δ∗) ∈Rn×d denotes the second-order partial derivative
evaluated at θ and δ∗(θ), respectively. In HC ∈Rd×d, 1pi<δ∗
i <qi ∈{0, 1} denotes the indicator
function over the constraint of {δi | pi < δ∗
i < qi}, which returns 1 if the constraint is satisﬁed,
δ∗
i denotes the ith entry of δ∗(θ), pi = max{−ϵ, −xi} and qi = min{ϵ, 1 −xi} characterize the
boundary of the linear constraint (9) for the variable δi, and ei ∈Rd denotes the basis vector with
the ith entry being 1 and others being 0s."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.2972972972972973,"In Theorem 1, the rationale behind the Hessian-free assumption is that ReLU-based neural networks
commonly lead to a piece-wise linear decision boundary w.r.t. the inputs (Moosavi-Dezfooli et al.,
2019; Alfarra et al., 2020), and thus, its second-order derivative (Hessian) ∇δδℓatk is close to zero.
In Appendix E, we will empirically show that the Hessian-free assumption is reasonable for both
ReLU and non-ReLU neural networks."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.30067567567567566,"FAST-BAT algorithm and implementation.
Similar to FAST-AT or AT, the FAST-BAT algorithm
follows the principle of alternating optimization. Speciﬁcally, it consists of the IG-based upper-level
gradient descent (3), interlaced with the lower-level optimal attack (8). We summarize the FAST-BAT
algorithm below."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.30405405405405406,FAST-BAT algorithm
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.30743243243243246,"The (t + 1)th upper-level iteration of FAST-BAT is given below
x (Lower-level solution): Obtain δ∗(θt) from (8);
y (Upper-level model training): Integrating the IG (10) into (3), call SGD to update"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.3108108108108108,"θt+1 = θt −α1∇θℓtr(θt, δ∗(θt)) −α2(−1/λ)∇θδℓatk(θt, δ∗(θt))HC∇δℓtr(θt, δ∗(θt)),
(11)"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.3141891891891892,"where α1, α2 > 0 are learning rates associated with the standard model gradient and the
IG-augmented descent direction, respectively."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.31756756756756754,"It is clear from (11) that to train a robust model, FAST-BAT can be dissected into the regular FAST-AT
update (i.e., α1-associated term) and the additional update that involves IG, (i.e., α2-associated term).
To successfully implement FAST-BAT, we highlight some key hyper-parameter setups different from
FAST-AT (Wong et al., 2020) and FAST-AT-GA (Andriushchenko & Flammarion, 2020)."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.32094594594594594,"Remark 1 Choice of learning rate for IG-involved descent term: In (11), the choice of α2 could
affect the trade-off between accuracy and robustness (see empirical justiﬁcation in Appendix E).
Clearly, if α2 = 0, then the upper-level model parameter updating step reduces to the standard
FAST-AT. In Sec. 5.1, we will show that the α2-associated term plays a positive role in alleviating
catastrophic robust overﬁtting. Meanwhile, λ in (7) could also affect the accuracy-robustness tradeoff.
For example, if λ →∞, then δ = 0 (no robustness gain). Spurred by above, we choose the following
combination of α2 and λ, α2/λ = 0.1α1, which works well in practice; see Table A1."
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.32432432432432434,"Remark 2 Choice of linearization point z: To specify (7), we investigate two classes of linearization
schemes. The ﬁrst class is random constant linearization, which includes: “uniformly random"
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.3277027027027027,Under review as a conference paper at ICLR 2022
A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT,0.3310810810810811,"linearization”, i.e., z = δ0 as FAST-AT, and “random corner linearization"" under the ϵ-radius ℓ∞-
ball, i.e., z ∈{−ϵ, ϵ}d. The second class is 1-step perturbation warm-up-based linearization, which
includes the other two speciﬁcations: “1-step PGD"" z = PC (δ0 + α · sign (∇δℓtr(θt, δ0))), and
“1-step PGD w/o sign"" z = PC (δ0 + α∇δℓtr(θt, δ0)). We consider the aforementioned linearization
schemes since FAST-BAT combined with these linearizations takes computation cost comparable
to the baselines FAST-AT and FAST-AT-GA. Our experiments show that FAST-BAT using “1-step
PGD w/o sign"" leads to the best defense performance; see justiﬁcation in Table A3."
EXPERIMENTS,0.3344594594594595,"5
EXPERIMENTS"
EXPERIMENT SETUP,0.33783783783783783,"5.1
EXPERIMENT SETUP"
EXPERIMENT SETUP,0.34121621621621623,"Datasets and model architectures.
We will evaluate the effectiveness of our proposal under
CIFAR-10 (Krizhevsky & Hinton, 2009) and ImageNet (Deng et al., 2009). Unless speciﬁed
otherwise, we will train DNN models PreActResNet (PARN)-18 (He et al., 2016b) for CIFAR-10,
and ResNet (RN)-50 (He et al., 2016a) for ImageNet. As a part of ablation study, we also train larger
models PARN-50 and WideResNet (WRN)-16-8 (Zagoruyko & Komodakis, 2016) on CIFAR-10."
EXPERIMENT SETUP,0.34459459459459457,"Baselines.
We consider three methods as our baselines: FAST-AT (Wong et al., 2020), FAST-AT-
GA (Andriushchenko & Flammarion, 2020), and PGD-2-AT (Madry et al., 2018), i.e., the 2-step
PGD attack-based AT. The primal criterion of baseline selection is computation complexity. The
training time of all methods including ours falls between the time of FAST-AT and that of FAST-AT-
GA. We remark that when evaluating on ImageNet, we only compare ours with FAST-AT since as
shown in Table 6 of (Andriushchenko & Flammarion, 2020), the other baseline methods did not show
improvement over Fast-AT at the attack budget ϵ = 2/255."
EXPERIMENT SETUP,0.34797297297297297,"Training details.
We choose the training perturbation strength ϵ ∈{2, 4, . . . , 16}/255 for CIFAR-
10 and ϵ = 2/255 for ImageNet following (Wong et al., 2020; Andriushchenko & Flammarion, 2020).
Throughout the experiments, we utilize an SGD optimizer with a momentum of 0.9 and weight
decay of 5 × 10−4. For CIFAR-10, we train each model for 20 epochs in total, where we use cyclic
scheduler to adjust the learning rate. The learning rate linearly ascends from 0 to 0.2 within the ﬁrst
10 epochs and then reduces to 0 within the last 10 epochs. Our batch size is set to 128 for all settings.
In the implementation of FAST-BAT, we adjust the hyperparameter λ from 255/5000 to 255/2000
based on the speciﬁcation of train-time ϵ. For ImageNet, we strictly follows the setup given by Wong
et al. (2020). In FAST-BAT, we set λ = 255/3000. For each method, we use the early stopping
method to pick the model with best robust accuracy, following (Rice et al., 2020). All the CIFAR-10
experiments are conducted on a single Tesla P-100 GPU and all ImageNet experiments run on a
single machine with two Tesla P-100s. All the baselines are implemented using the recommended
training conﬁgurations in their ofﬁcial GitHub repos. We refer readers to Appendix D for more details
on training setup."
EXPERIMENT SETUP,0.35135135135135137,"Evaluation details.
For adversarial evaluation, we report robust test accuracy (RA) of a learned
model against PGD attacks (Madry et al., 2018) (RA-PGD). Unless otherwise speciﬁed, we set
the test-time perturbation strength (ϵ) same as the train-time value, and take 50-step PGD with 10
restarts for both CIFAR-10 and ImageNet evaluation. We also measure robust accuracy against
AutoAttacks (Croce & Hein, 2020), termed RA-AA. Further, we measure the standard accuracy (SA)
against natural examples. Results are averaged over 5 independent trials with different random seeds."
RESULTS,0.3547297297297297,"5.2
RESULTS
Table 3: SA and RA on ImageNet."
RESULTS,0.3581081081081081,"Method
SA (%)
RA-PGD (%)"
RESULTS,0.3614864864864865,"FAST-AT
60.90
43.43
FAST-BAT
60.18
44.64
Overall performance of FAST-BAT.
In Table 2 and 3, we
compare the performance of our proposed FAST-BAT with base-
lines on CIFAR-10 and ImageNet, respectively."
RESULTS,0.36486486486486486,"First, we ﬁnd that FAST-BAT consistently outperforms the other baselines across datasets and attack
types. For example, FAST-BAT at least improves 1.35% RA-PGD and 1.41% RA-AA with test-time
ϵ = 8/255 in the training setup (CIFAR-10, ϵ = 8/255). On ImageNet, FAST-BAT outperforms
FAST-AT by 1.23% when facing attacks with ϵ = 2/255."
RESULTS,0.36824324324324326,Under review as a conference paper at ICLR 2022
RESULTS,0.3716216216216216,"Table 2: SA, RA-PGD and RA-AA of different robust training methods in the setup (CIFAR-10, PARN-18
training with ϵ = 8/255) and (CIFAR-10, PARN-18 training with ϵ = 16/255), respectively. All the results are
averaged over 5 independent trials with different random seeds."
RESULTS,0.375,"CIFAR-10, PARN-18 trained with ϵ = 8/255"
RESULTS,0.3783783783783784,"Method
SA (%)
RA-PGD (%)
RA-AA (%)
ϵ = 4
ϵ = 8
ϵ = 12
ϵ = 16
ϵ = 2
ϵ = 8
ϵ = 16"
RESULTS,0.38175675675675674,"FAST-AT
81.89±0.31
65.92 ±0.11
45.44 ±0.38
23.69 ±0.34
9.56 ±0.26
72.54 ±0.20
41.95 ±0.13
7.91 ±0.06
FAST-AT-GA
79.78±0.47
65.74 ±0.19
47.32 ±0.35
28.67 ±0.26
11.57±0.32
71.60 ±0.39
43.45 ±0.27
9.48 ±0.15
PGD-2-AT
83.26±0.28
65.59 ±0.34
44.71 ±0.42
23.67 ±0.35
9.42 ±0.33
73.28±0.15
41.73 ±0.20
7.54±0.25
FAST-BAT
79.47 ±0.14
66.26 ±0.08
48.67 ±0.18
29.87 ±0.46
14.00 ±0.21
72.07 ±0.22
44.86 ±0.34
11.51 ±0.20"
RESULTS,0.38513513513513514,"CIFAR-10, PARN-18 trained with ϵ = 16/255"
RESULTS,0.3885135135135135,"FAST-AT
46.13±2.25
42.74 ±0.91
37.17 ±0.74
27.99 ±0.72
21.92 ±0.71
36.31 ±2.20
31.66 ±0.27
12.48 ±0.29
FAST-AT-GA
58.53 ±1.20
51.71 ±0.99
43.86 ±0.67
35.46 ±0.36
26.29 ±0.14
53.61 ±1.10
38.69 ±0.56
18.11 ±0.36
PGD-2-AT
69.40 ±0.30
59.25 ±0.16
48.79 ±0.31
32.12 ±5.63
24.30 ±0.46
61.90 ±0.28
41.59 ±0.22
15.40 ±0.29
FAST-BAT
67.81 ±0.18
59.35 ±0.13
49.05 ±0.12
37.71 ±0.36
26.07 ±0.28
62.16 ±0.14
43.64 ±0.26
18.18 ±0.34"
RESULTS,0.3918918918918919,"Second, FAST-BAT leads to a better SA-RA trade-off compared with the other baselines. For
example, in the setup of (CIFAR-10, PARN-18 trained with ϵ = 8/255), we observe that FAST-BAT
outperforms FAST-AT-GA in RA, without losing SA.And in the setup of (CIFAR-10, PARN-18
trained with ϵ = 16/255), FAST-BAT signiﬁcantly outperforms FAST-AT-GA, with 9.28% SA
improvement and comparable or even better RA. Compared with PGD-2-AT, FAST-BAT is much
more resilient against strong adversaries, e.g., ϵ = 16."
RESULTS,0.3952702702702703,"Third, the robustness advantage of our method becomes more notable when the test-time attack budget
becomes smaller than the train-time budget. For examples, the RA-AA improvement of FAST-BAT
over FAST-AT-GA grows from 0.07% (evaluated at ϵ = 16/255) to 4.95% (evaluated at ϵ = 8/255),
and 8.55% (evaluated at ϵ = 2/255) in the case of (CIFAR-10, trained with ϵ = 16/255)."
RESULTS,0.39864864864864863,"Performance under different model architectures.
Besides PARN-18 reported above, Table 4
presents experiment results on both deeper (PARN-50) and wider (WRN-18-6) models. As we can
see, FAST-BAT consistently yields RA improvement over the other baselines. We also note that
PGD-2-AT could be a competitive baseline in terms of SA, e.g., the case of (PARN-50, ϵ = 8/255).
In contrast to FAST-AT and FAST-AT-GA, FAST-BAT is the only approach that yields an evident RA
improvement over PGD-2-AT.
Table 4: Performance of different robust training methods under different model types. All the models are both
trained and evaluated with the same perturbation strength ϵ."
RESULTS,0.40202702702702703,"Model
Method
SA(%)
(ϵ = 8/255)"
RESULTS,0.40540540540540543,RA-PGD(%)
RESULTS,0.40878378378378377,(ϵ = 8/255)
RESULTS,0.41216216216216217,"SA(%)
(ϵ = 16/255)"
RESULTS,0.4155405405405405,"RA-PGD(%)
(ϵ = 16/255)"
RESULTS,0.4189189189189189,"PARN-50
FAST-AT
73.15±6.10
41.03±2.99
43.86±4.31
22.08±0.27
FAST-AT-GA
77.40±0.81
46.16±0.98
42.28±6.69
22.87±1.25
PGD-2-AT
83.53±0.17
46.17±0.59
68.88±0.39
22.37±0.41
FAST-BAT
78.91±0.68
49.18±0.35
69.01±0.19
24.55±0.06"
RESULTS,0.4222972972972973,"WRN-16-8
FAST-AT
84.39±0.46
45.80±0.57
49.39±2.17
21.99±0.41
FAST-AT-GA
81.51±0.38
48.29±0.20
45.95±13.65
23.10±3.90
PGD-2-AT
85.52±0.14
45.47±0.14
72.11±0.33
23.61±0.16
FAST-BAT
81.66±0.54
49.93±0.36
68.12±0.47
25.63±0.44"
RESULTS,0.42567567567567566,"(a) Without early stopping
(b) With early stopping
Figure 1: RA-PGD of different robust training methods for (CIFAR-
10, PARN-18) with the same training and evaluation attack strengths."
RESULTS,0.42905405405405406,"Mitigation of robustness catas-
trophic overﬁtting.
As shown in
(Andriushchenko & Flammarion,
2020),
FAST-AT
suffers
robust-
ness catastrophic overﬁtting when
the train-time and test-time attack
strength ϵ grows.
Following (An-
driushchenko & Flammarion, 2020),
Figure 1 presents two RA-PGD tra-
jectories, i.e., training w/o early stop-
ping and training w/ early stopping,
versus the train- and test-time ϵ. As
we can see, FAST-AT encounters a sharp RA drop when ϵ > 8 when early stopping is not used,
consistent with (Andriushchenko & Flammarion, 2020). Assisted by early stopping, the overﬁtting"
RESULTS,0.43243243243243246,Under review as a conference paper at ICLR 2022
RESULTS,0.4358108108108108,"of RA can be alleviated to some extent for FAST-AT, but its performance still remains the worst.
Moreover, different from (Andriushchenko & Flammarion, 2020), we ﬁnd that PGD-2-AT yields
resilient performance against robustness catastrophic overﬁtting. Our implementation gives a more
positive baseline than the implementation of PGD-2-AT in (Andriushchenko & Flammarion, 2020),
since the latter did not use random initialization to generate train-time attacks. Furthermore, Figure 1
shows that our proposal mitigates the issue of robustness catastrophic overﬁtting and yields improved
RA over the other baselines. We highlight that such a achievement made by FAST-BAT is ‘free’ of
any robustness stability regularization, like gradient alignment used in FAST-AT-GA."
RESULTS,0.4391891891891892,Figure 2: GA evaluation.
RESULTS,0.44256756756756754,"Gradient alignment for ‘free’.
As shown by Andriushchenko &
Flammarion (2020), gradient alignment (GA) is a key performance
indicator to measure the appearance of robustness catastrophic over-
ﬁtting. The insight from Figure 1 suggested that FAST-BAT can mit-
igate overﬁtting without using explicit GA regularization. Spurred by
above, Figure 2 presents the GA score versus the training epoch num-
ber, where GA characterizes the sensitivity of loss landscape against
random input perturbations; see derivations in (Andriushchenko &
Flammarion, 2020). The higher GA is, the more stable the robust
training is. Figure 2 shows that FAST-BAT automatically enforces
GA and it outperforms FAST-AT and PGD-2-AT. FAST-BAT remains very close to FAST-AT-GA,
which maximizes GA using an extra train-time regularization The above empirical results imply
that gradient alignment may be just a necessary condition for avoiding catastrophic overﬁtting, but
not a sufﬁcient one. A possible justiﬁcation can be made from the perspective of the ﬂatness of the
loss landscape. A higher gradient alignment implies a ﬂatter loss landscape with respect to input
perturbations. However, the direct penalization on the norm of the input gradient may not achieve the
state-of-the-art model robustness.
Table 5: RA of robust PARN-18 trained by the four differ-
ent methods against adaptive attacks (‘RA-PGD’ column)
and transfer attacks (‘Transfer Attack’ columns). Naturally
trained PARN-18, PARN-50, and WRN-16-8 are used as
surrogate models for PGD-20 attack with ϵ = 8/255."
RESULTS,0.44594594594594594,"Method
RA-PGD(%)
RA-Transfer Attack(%)
PARN-18
PARN-50
WRN-16-8"
RESULTS,0.44932432432432434,"FAST-AT
45.44
76.35
76.94
77.23
PGD-2-AT
44.71
77.56
78.64
78.84
FAST-AT-GA
47.31
77.34
78.34
78.53
FAST-BAT(Ours)
48.67
78.03
79.93
79.21"
RESULTS,0.4527027027027027,"Sanity check for obfuscated gradients
As pointed out by Athalye et al. (2018a),
model robustness could be overestimated
due to obfuscated gradients. The model
with obfuscated gradients could have ‘ob-
fuscated’ stronger resilience to white-box
attacks than transfer (black-box) attacks. To
justify the validity of FAST-BAT, Table 2
summarizes the comparison between our
proposal and the other baselines when facing white-box adaptive and black-box transfer attacks.
Firstly, RA increases if the transfer attack is present for each method, implying that the transfer attack
is weaker than the white-box adaptive attack. This is desired in the absence of obfuscated gradients.
Moreover, FAST-BAT consistently outperforms the other three baselines when defending against
both adaptive and transfer attacks. The absence of obfuscated gradients can also be justiﬁed by RA vs.
the growth of attack budget ϵ in Table 2, and the ﬂatness of adversarial loss landscape in Figure. A1."
RESULTS,0.4560810810810811,"Ablation studies.
In Appendix E, we present additional empirical studies including 1) the sensitivity
analysis of the linearization hyperparameter λ, 2) the choice of the linearization point, 3) the sensitivity
analysis of α2, 4) the inﬂuence of Hessian matrix on ReLU, and 5) non-ReLU neural networks."
CONCLUSION,0.4594594594594595,"6
CONCLUSION"
CONCLUSION,0.46283783783783783,"In this paper, we introduce a novel bi-level optimization (BLO)-based fast adversarial training
framework, termed FAST-BAT. The rationale behind designing fast robust training through the lens
of BLO lies in two aspects. First, from the perspective of implicit gradients, we show that existing
FAST-AT framework is equivalent to the lower-level linearized BLO along the sign direction of input
gradient. Second, we show that FAST-BAT enables the least restriction to achieve improved staibility
of performance, mitigated catastrophic overﬁtting, and enhanced accuracy-robustness trade-off. To
the best of our knowledge, we for the ﬁrst time establish the theory and the algorithmic foundation
of BLO for adversarially robust training. Extensive experiments are provided to demonstrate the
superiority of our method to state-of-the-art accelerated AT baselines."
CONCLUSION,0.46621621621621623,Under review as a conference paper at ICLR 2022
REFERENCES,0.46959459459459457,REFERENCES
REFERENCES,0.47297297297297297,"Motasem Alfarra, Adel Bibi, Hasan Hammoud, Mohamed Gaafar, and Bernard Ghanem. On the decision
boundaries of deep neural networks: A tropical geometry perspective. arXiv preprint arXiv:2002.08838,
2020."
REFERENCES,0.47635135135135137,"Maksym Andriushchenko and Nicolas Flammarion. Understanding and improving fast adversarial training.
NeurIPS, 2020."
REFERENCES,0.4797297297297297,"Anish Athalye, Nicholas Carlini, and David Wagner. Obfuscated gradients give a false sense of security:
Circumventing defenses to adversarial examples. arXiv preprint arXiv:1802.00420, 2018a."
REFERENCES,0.4831081081081081,"Anish Athalye, Logan Engstrom, Andrew Ilyas, and Kevin Kwok. Synthesizing robust adversarial examples. In
International Conference on Machine Learning, pp. 284–293, 2018b."
REFERENCES,0.4864864864864865,"Nicholas Carlini and David Wagner. Towards evaluating the robustness of neural networks. In IEEE Symposium
on S&P, 2017."
REFERENCES,0.48986486486486486,"Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, Percy Liang, and John C Duchi. Unlabeled data improves
adversarial robustness. arXiv preprint arXiv:1905.13736, 2019."
REFERENCES,0.49324324324324326,"T. Chen, S. Liu, S. Chang, Y. Cheng, L. Amini, and Z. Wang. Adversarial robustness: From self-supervised
pretraining to ﬁne-tuning. In CVPR, 2020."
REFERENCES,0.4966216216216216,"Zhangyu Chen, Dong Liu, Xiaofei Wu, and Xiaochun Xu. Research on distributed renewable energy transaction
decision-making based on multi-agent bilevel cooperative reinforcement learning. 2019."
REFERENCES,0.5,"Francesco Croce and Matthias Hein. Reliable evaluation of adversarial robustness with an ensemble of diverse
parameter-free attacks. In International Conference on Machine Learning, pp. 2206–2216. PMLR, 2020."
REFERENCES,0.5033783783783784,"Stephan Dempe. Foundations of bilevel programming. Springer Science & Business Media, 2002."
REFERENCES,0.5067567567567568,"Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical
image database. In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp.
248–255. IEEE, 2009."
REFERENCES,0.5101351351351351,"Yao Deng, Xi Zheng, Tianyi Zhang, Chen Chen, Guannan Lou, and Miryung Kim. An analysis of adversarial
attacks and defenses on autonomous driving models. In 2020 IEEE International Conference on Pervasive
Computing and Communications (PerCom), pp. 1–10. IEEE, 2020."
REFERENCES,0.5135135135135135,"Logan Engstrom, Andrew Ilyas, and Anish Athalye. Evaluating and understanding the robustness of adversarial
logit pairing. arXiv preprint arXiv:1807.10272, 2018."
REFERENCES,0.5168918918918919,"Samuel G Finlayson, John D Bowers, Joichi Ito, Jonathan L Zittrain, Andrew L Beam, and Isaac S Kohane.
Adversarial attacks on medical machine learning. Science, 363(6433):1287–1289, 2019."
REFERENCES,0.5202702702702703,"Saeed Ghadimi and Mengdi Wang. Approximation methods for bilevel programming. arXiv preprint:1802.02246,
2018."
REFERENCES,0.5236486486486487,"Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples.
arXiv preprint arXiv:1412.6572, 2014."
REFERENCES,0.527027027027027,"Stephen Gould, Basura Fernando, Anoop Cherian, Peter Anderson, Rodrigo Santa Cruz, and Edison Guo. On
differentiating parameterized argmin and argmax problems with application to bi-level optimization. arXiv
preprint arXiv:1607.05447, 2016."
REFERENCES,0.5304054054054054,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In
Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770–778, 2016a."
REFERENCES,0.5337837837837838,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Identity mappings in deep residual networks. In
European conference on computer vision, pp. 630–645. Springer, 2016b."
REFERENCES,0.5371621621621622,"Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran Yang.
A two-timescale framework for bilevel
optimization: Complexity analysis and application to actor-critic. arXiv preprint arXiv:2007.05170, 2020."
REFERENCES,0.5405405405405406,"W Ronny Huang, Jonas Geiping, Liam Fowl, Gavin Taylor, and Tom Goldstein. Metapoison: Practical
general-purpose clean-label data poisoning. arXiv preprint arXiv:2004.00225, 2020."
REFERENCES,0.543918918918919,"Kaiyi Ji, Junjie Yang, and Yingbin Liang. Bilevel optimization: Nonasymptotic analysis and faster algorithms.
arXiv preprint arXiv:2010.07962, 2020."
REFERENCES,0.5472972972972973,Under review as a conference paper at ICLR 2022
REFERENCES,0.5506756756756757,"A. Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images. Master’s thesis, Department
of Computer Science, University of Toronto, 2009."
REFERENCES,0.5540540540540541,"K Naveen Kumar, C Vishnu, Reshmi Mitra, and C Krishna Mohan. Black-box adversarial attacks in autonomous
vehicle technology. In 2020 IEEE Applied Imagery Pattern Recognition Workshop (AIPR), pp. 1–7. IEEE,
2020."
REFERENCES,0.5574324324324325,"Alexey Kurakin, Ian J. Goodfellow, and Samy Bengio. Adversarial machine learning at scale. 2017 ICLR, arXiv
preprint arXiv:1611.01236, 2017. URL http://arxiv.org/abs/1611.01236."
REFERENCES,0.5608108108108109,"Bai Li, Shiqi Wang, Suman Jana, and Lawrence Carin. Towards understanding fast adversarial training. arXiv
preprint arXiv:2006.03089, 2020."
REFERENCES,0.5641891891891891,"Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep
learning models resistant to adversarial attacks. In International Conference on Learning Representations,
2018."
REFERENCES,0.5675675675675675,"Faisal Mahmood, Daniel Borders, Richard J Chen, Gregory N McKay, Kevan J Salimian, Alexander Baras, and
Nicholas J Durr. Deep adversarial training for multi-organ nuclei segmentation in histopathology images.
IEEE transactions on medical imaging, 39(11):3257–3267, 2019."
REFERENCES,0.5709459459459459,"Takeru Miyato, Andrew M Dai, and Ian Goodfellow. Adversarial training methods for semi-supervised text
classiﬁcation. arXiv preprint arXiv:1605.07725, 2016."
REFERENCES,0.5743243243243243,"Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Jonathan Uesato, and Pascal Frossard. Robustness via
curvature regularization, and vice versa. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pp. 9078–9086, 2019."
REFERENCES,0.5777027027027027,"Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z Berkay Celik, and Ananthram Swami. The
limitations of deep learning in adversarial settings. In Security and Privacy (EuroS&P), 2016 IEEE European
Symposium on, pp. 372–387. IEEE, 2016."
REFERENCES,0.581081081081081,"Qi Qian, Shenghuo Zhu, Jiasheng Tang, Rong Jin, Baigui Sun, and Hao Li. Robust optimization over multiple
domains. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 33, pp. 4739–4746, 2019."
REFERENCES,0.5844594594594594,"Aravind Rajeswaran, Chelsea Finn, Sham Kakade, and Sergey Levine. Meta-learning with implicit gradients.
arXiv preprint arXiv:1909.04630, 2019."
REFERENCES,0.5878378378378378,"Prajit Ramachandran, Barret Zoph, and Quoc V Le.
Searching for activation functions.
arXiv preprint
arXiv:1710.05941, 2017."
REFERENCES,0.5912162162162162,"Leslie Rice, Eric Wong, and Zico Kolter. Overﬁtting in adversarially robust deep learning. In International
Conference on Machine Learning, pp. 8093–8104. PMLR, 2020."
REFERENCES,0.5945945945945946,"Hadi Salman, Greg Yang, Jerry Li, Pengchuan Zhang, Huan Zhang, Ilya Razenshteyn, and Sebastien Bubeck.
Provably robust deep learning via adversarially trained smoothed classiﬁers. arXiv preprint arXiv:1906.04584,
2019."
REFERENCES,0.597972972972973,"Ali Shafahi, Mahyar Najibi, Mohammad Amin Ghiasi, Zheng Xu, John Dickerson, Christoph Studer, Larry S
Davis, Gavin Taylor, and Tom Goldstein. Adversarial training for free! In Advances in Neural Information
Processing Systems, pp. 3353–3364, 2019."
REFERENCES,0.6013513513513513,"Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob
Fergus. Intriguing properties of neural networks. International Conference on Learning Representations,
2014."
REFERENCES,0.6047297297297297,"Simen Thys, Wiebe Van Ranst, and Toon Goedemé. Fooling automated surveillance cameras: adversarial
patches to attack person detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition Workshops, pp. 0–0, 2019."
REFERENCES,0.6081081081081081,"Luis Vicente, Gilles Savard, and Joaquim Júdice. Descent approaches for quadratic bilevel programming.
Journal of Optimization Theory and Applications, 81(2):379–399, 1994."
REFERENCES,0.6114864864864865,"Douglas J White and G Anandalingam. A penalty function approach for solving bi-level linear programs.
Journal of Global Optimization, 3(4):397–419, 1993."
REFERENCES,0.6148648648648649,"Eric Wong, Leslie Rice, and J. Zico Kolter. Fast is better than free: Revisiting adversarial training. In
International Conference on Learning Representations, 2020."
REFERENCES,0.6182432432432432,Under review as a conference paper at ICLR 2022
REFERENCES,0.6216216216216216,"Cihang Xie, Yuxin Wu, Laurens van der Maaten, Alan L Yuille, and Kaiming He. Feature denoising for
improving adversarial robustness. In Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, pp. 501–509, 2019."
REFERENCES,0.625,"Kaidi Xu, Sijia Liu, Pu Zhao, Pin-Yu Chen, Huan Zhang, Quanfu Fan, Deniz Erdogmus, Yanzhi Wang, and Xue
Lin. Structured adversarial attack: Towards general implementation and better interpretability. In ICLR, 2019."
REFERENCES,0.6283783783783784,"Kaidi Xu, Gaoyuan Zhang, S. Liu, Quanfu Fan, Mengshu Sun, Hongge Chen, Pin-Yu Chen, Yanzhi Wang, and
Xue Lin. Adversarial T-Shirt! evading person detectors in a physical world. In ECCV, 2020."
REFERENCES,0.6317567567567568,"Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. arXiv preprint arXiv:1605.07146, 2016."
REFERENCES,0.6351351351351351,"Dinghuai Zhang, Tianyuan Zhang, Yiping Lu, Zhanxing Zhu, and Bin Dong. You only propagate once:
Accelerating adversarial training via maximal principle. arXiv preprint arXiv:1905.00877, 2019a."
REFERENCES,0.6385135135135135,"Haichao Zhang and Jianyu Wang. Towards adversarially robust object detection. In Proceedings of the IEEE/CVF
International Conference on Computer Vision, pp. 421–430, 2019."
REFERENCES,0.6418918918918919,"Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric P Xing, Laurent El Ghaoui, and Michael I Jordan. Theoretically
principled trade-off between robustness and accuracy. ICML, 2019b."
REFERENCES,0.6452702702702703,"Chen Zhu, Yu Cheng, Zhe Gan, Siqi Sun, Tom Goldstein, and Jingjing Liu. Freelb: Enhanced adversarial
training for natural language understanding. arXiv preprint arXiv:1909.11764, 2019."
REFERENCES,0.6486486486486487,Under review as a conference paper at ICLR 2022
REFERENCES,0.652027027027027,"A
PROOF OF THEOREM 1"
REFERENCES,0.6554054054054054,"Proof: Upon deﬁning g(θ, δ) = (δ −z)⊤∇δ=zℓatk(θ, δ) + (λ/2)∥δ −z∥2
2, we repeat (7) as"
REFERENCES,0.6587837837837838,"minimize
θ
E(x,y)∈D[ℓtr(θ, δ∗(θ))]"
REFERENCES,0.6621621621621622,"subject to
δ∗(θ) = arg min
Bδ≤b
g(θ, δ),
(12)"
REFERENCES,0.6655405405405406,where we have used the expression of linear constraints in (9).
REFERENCES,0.668918918918919,Our goal is to derive the IG dδ∗(θ)⊤
REFERENCES,0.6722972972972973,"dθ
shown in (3). To this end, we ﬁrst build implicit functions by
leveraging KKT conditions of the lower-level problem of (12). We say δ∗(θ) and λ∗(θ) (Lagrangian
multipliers) satisfy the KKT conditions:"
REFERENCES,0.6756756756756757,"Stationarity:
∇δg(θ, δ∗(θ)) + B⊤λ∗(θ) = 0,
Complementary slackness :
λ∗(θ) · (Bδ∗(θ) −b) = 0
Dual feasibility:
λ∗(θ) ≥0
(13)"
REFERENCES,0.6790540540540541,where · denotes the elementwise product.
REFERENCES,0.6824324324324325,"Active constraints and deﬁnition of B0: Let B0 denote the sub-matrix of B and b0 the sub-vector
of b, which consists of only the active constraints at δ∗(θ), i.e., those satisﬁed with the equality
B0δ∗(θ) = b0 (corresponding to nonzero dual variables). The determination of active constraints is
done given θ at each iteration."
REFERENCES,0.6858108108108109,"With the aid of (B0, b0), KKT (13) becomes"
REFERENCES,0.6891891891891891,"∇δg(θ, δ∗(θ)) + B⊤
0 λ∗(θ) = 0, and B0δ∗(θ) −b0 = 0,
(14)"
REFERENCES,0.6925675675675675,"where the nonzero λ∗(θ) only correspond to active constraints. We take derivatives w.r.t. θ for (14),
and thus obtain
d∇δg(θ, δ∗(θ))⊤"
REFERENCES,0.6959459459459459,"dθ
+ ∇θλ∗(θ)⊤B0 = 0"
REFERENCES,0.6993243243243243,"=⇒∇θδg(θ, δ∗(θ)) + dδ∗(θ)⊤"
REFERENCES,0.7027027027027027,"dθ
|
{z
}
IG"
REFERENCES,0.706081081081081,"∇δδg(θ, δ∗(θ)) + ∇θλ∗(θ)⊤B0 = 0,
(15)"
REFERENCES,0.7094594594594594,and dδ∗(θ)⊤
REFERENCES,0.7128378378378378,"dθ
|
{z
}
IG"
REFERENCES,0.7162162162162162,"B⊤
0 = 0,
(16)"
REFERENCES,0.7195945945945946,"where ∇θδ ∈R|θ|×|δ| denotes second-order partial derivatives (recall that |θ| = n and |δ| = d).
According to (15), we have"
REFERENCES,0.722972972972973,dδ∗(θ)⊤
REFERENCES,0.7263513513513513,"dθ
= −[∇θδg(θ, δ∗(θ)) + ∇θλ∗(θ)⊤B0]∇δδg(θ, δ∗(θ))−1.
(17)"
REFERENCES,0.7297297297297297,"Substituting the above into (16), we obtain"
REFERENCES,0.7331081081081081,"∇θδg(θ, δ∗(θ))∇δδg(θ, δ∗(θ))−1B⊤
0 + ∇θλ∗(θ)⊤B0∇δδg(θ, δ∗(θ))−1B⊤
0 = 0,
(18)"
REFERENCES,0.7364864864864865,which yields:
REFERENCES,0.7398648648648649,"∇θλ∗(θ)⊤= −∇θδg(θ, δ∗(θ))∇δδg(θ, δ∗(θ))−1B⊤
0 [B0∇δδg(θ, δ∗(θ))−1B⊤
0 ]−1,
(19)"
REFERENCES,0.7432432432432432,"and thus,"
REFERENCES,0.7466216216216216,"∇θλ∗(θ)⊤B0 = −∇θδg(θ, δ∗(θ))∇δδg(θ, δ∗(θ))−1B⊤
0 [B0∇δδg(θ, δ∗(θ))−1B⊤
0 ]−1B0. (20)"
REFERENCES,0.75,"Substituting (20) into (17), we obtain the IG"
REFERENCES,0.7533783783783784,dδ∗(θ)⊤
REFERENCES,0.7567567567567568,"dθ
= −∇θδg(θ, δ∗(θ))∇δδg(θ, δ∗(θ))−1 −∇θλ∗(θ)⊤B0∇δδg(θ, δ∗(θ))−1"
REFERENCES,0.7601351351351351,"= −∇θδg(θ, δ∗(θ))∇δδg(θ, δ∗(θ))−1"
REFERENCES,0.7635135135135135,"+ ∇θδg(θ, δ∗(θ))∇δδg(θ, δ∗(θ))−1B⊤
0 [B0∇δδg(θ, δ∗(θ))−1B⊤
0 ]−1B0∇δδg(θ, δ∗(θ))−1.
(21)"
REFERENCES,0.7668918918918919,Under review as a conference paper at ICLR 2022
REFERENCES,0.7702702702702703,"To further compute (21), the Hessian matrix ∇δδℓatk is needed. Recall from the deﬁnition of the
lower-level objective that the Hessian matrix is given by"
REFERENCES,0.7736486486486487,"∇δδg(θ, δ∗(θ)) = ∇δδℓatk + λI = 0 + λI.
(22)"
REFERENCES,0.777027027027027,"Here we used the assumption that ∇δδℓatk = 0. The rationale behind that is neural networks
commonly leads to a piece-wise linear decision boundary w.r.t. the inputs (Moosavi-Dezfooli et al.,
2019; Alfarra et al., 2020), and thus, its second-order derivative (Hessian) ∇δδℓatk is close to zero."
REFERENCES,0.7804054054054054,"Based on the simpliﬁcation (22), we have"
REFERENCES,0.7837837837837838,dδ∗(θ)⊤
REFERENCES,0.7871621621621622,"dθ
= −(1/λ)∇θδg(θ, δ∗(θ))
 
I −B⊤
0 [B0B⊤
0 ]−1B0
"
REFERENCES,0.7905405405405406,"|
{z
}
:=HC
−(1/λ)∇θδℓatk(θ, δ∗(θ))HC,
(23)"
REFERENCES,0.793918918918919,where we have used the fact that ∇θδg = ∇θδℓatk.
REFERENCES,0.7972972972972973,"What is HC in (23)? Since B =

I
−I"
REFERENCES,0.8006756756756757,"
, we can obtain that B0B⊤
0 = I and B⊤
0 B0 is a sparse diagonal"
REFERENCES,0.8040540540540541,"matrix with diagonal entries being 0 or 1. Thus, HC can be ﬁrst simpliﬁed to"
REFERENCES,0.8074324324324325,"HC = I −B⊤
0 B0.
(24)"
REFERENCES,0.8108108108108109,"Clearly, HC is also a diagonal matrix with either 0 or 1 diagonal entries. The 1-valued diagonal
entry of HC corresponds to the inactive constraints in Bδ∗(θ) < b, i.e., those satisﬁed with strict
inequalities in {∥δ∥∞≤ϵ, 0 ≤δ ≤1}. This can be expressed as"
REFERENCES,0.8141891891891891,"HC =
1p1≤δ∗
1≤q1e1, . . . , 1p1≤δ∗
d≤qded

(25)"
REFERENCES,0.8175675675675675,"where 1pi≤δ∗
i ≤qi ∈{0, 1} denotes the indicator function over the constraint {pi ≤δ∗
i ≤qi} and
returns 1 if the constraint is satisﬁed, δ∗
i denotes the ith entry of δ∗(θ), pi = max{−ϵ, −xi} and
qi = min{ϵ, 1 −xi}, and ei ∈Rd denotes the basis vector with the ith entry being 1 and others
being 0s."
REFERENCES,0.8209459459459459,"Based on the deﬁnition of g, (23) and (25), we can eventually achieve the desired IG formula (10).
The proof is now complete.
□"
REFERENCES,0.8243243243243243,Under review as a conference paper at ICLR 2022
REFERENCES,0.8277027027027027,"B
DISCUSSION ON CASE ℓatk = −ℓtr"
REFERENCES,0.831081081081081,"We provide an explanation on the argument ""Even if we set ℓatk = −ℓtr, problem (2) does not reduce
to problem (1) due to the presence of lower-level constraint"" from the following two points."
REFERENCES,0.8344594594594594,"• In the absence of the constraint δ ∈C, if we set ℓatk = −ℓtr, then Problem 2 will reduce to
Problem 1.
This is a known BLO result (e.g. Ghadimi & Wang (2018)) and can be readily proven
using the stationary condition. To be speciﬁc, based on the stationary condition of uncon-
strained lower-level optimization, we have ∇δℓatk(θ, δ∗) = 0. Since ℓatk = −ℓtr, we have
∇δℓtr(θ, δ∗) = 0. As a result, the second term in Eq. 3 becomes 0 and solving problem 2
becomes identical to solving the min-max problem 1."
REFERENCES,0.8378378378378378,"• In the presence of the constraint δ ∈C, the stationary condition cannot be applied since the
stationary point may not be a feasible point in the constraint. In other words, ∇δℓatk(θ, δ∗) =
0 does not hold in the case of ℓatk = −ℓtr. As a matter of fact, one has to resort to KKT
conditions instead of the stationary condition for a constrained lower-level problem. Similar
to our proof in Theorem 1, the implicit gradient (and thus the second term of Eq. 3) cannot
be omitted in general. This makes problem 2 different from the problem 1."
REFERENCES,0.8412162162162162,"C
DERIVATION OF IMPLICIT GRADIENT FOR FAST-AT"
REFERENCES,0.8445945945945946,"We can derive Eq. 6 using KKT condition similar to Theorem 1. Speciﬁcally, let"
REFERENCES,0.847972972972973,"g(θ, δ) = ⟨sign(∇δ=zℓatk(θ, δ; x, y)), δ −z⟩+ λ"
REFERENCES,0.8513513513513513,"2 ∥δ −z∥2
2,
(26)"
REFERENCES,0.8547297297297297,we have
REFERENCES,0.8581081081081081,"∇θδg = 0.
(27)"
REFERENCES,0.8614864864864865,"Following (21), we can further obtain (6) based on (27)."
REFERENCES,0.8648648648648649,"D
DETAILED EXPERIMENT SETTINGS"
REFERENCES,0.8682432432432432,"D.1
TRAINING SET-UP"
REFERENCES,0.8716216216216216,"For CIFAR-10, we summarize the training setup for each method. 1) FAST-AT: We use FGSM with
an attack step size of 1.25ϵ to generate perturbations; 2) PGD-2-AT: 2-step PGD attacks1 with an
attack step size of 0.5ϵ is implemented; 3) FAST-AT-GA: The gradient alignment regularization
parameter is set to the recommended value for each ϵ; 4) FAST-BAT: We select λ from 255/5000 to
255/2000 for different ϵ. At the same time, we adjust α2 accordingly, so that the coefﬁcient of the
second term in (11), namely α2/λ always equals to 0.1α1."
REFERENCES,0.875,"For ImageNet, we set ϵ to 2/255 , and we strictly follow the training setting adopted by Wong et al.
(2020). In FAST-BAT, we ﬁx λ at 255/3000 and adopt the same α2 selection strategy as CIFAR-10."
REFERENCES,0.8783783783783784,"Parameter for FAST-AT-GA
Regarding FAST-AT-GA with different model types, we adopt the
same regularization parameter recommended in its ofﬁcial repo2 intended for PreActResNet-18
(namely 0.2 for ϵ = 8/255 and 2.0 for ϵ = 16/255)."
REFERENCES,0.8817567567567568,"1We use random initialization to generate perturbations for PGD, while in the paper of FAST-AT-GA (An-
driushchenko & Flammarion, 2020), 2-step PGD is initialized at zero point, which we believe will underestimate
the effect of PGD-2-AT
2FAST-AT-GA: https://github.com/tml-epfl/understanding-fast-adv-training/
blob/master/sh"
REFERENCES,0.8851351351351351,Under review as a conference paper at ICLR 2022
REFERENCES,0.8885135135135135,"E
ADDITIONAL EXPERIMENTAL RESULTS"
REFERENCES,0.8918918918918919,"FAST-AT
FAST-AT-GA
FAST-BAT"
REFERENCES,0.8952702702702703,"Figure A1: Visualization of adversarial loss landscapes of FAST-AT, FAST-AT-GA and FAST-BAT trained
using the ResNet-18 model on the CIFAR-10 dataset. The losses at are calculated w.r.t. the same image example
ID #001456, and the landscape is obtained by tracking the loss changes w.r.t. input variations following Engstrom
et al. (2018). That is, the loss landscape is generated by z = loss(I + x · r1 + y · r2), where I denotes an image,
and the x-axis and the y-axis correspond to linear coefﬁcients associated with the sign-based attack direction
r1 = sign(∇Iloss(I)) ˆx and a random direction r2 ∼Rademacher(0.5), respectively."
REFERENCES,0.8986486486486487,"Table A1: Performance of FAST-BAT with different
parameter λ. We train and evaluate with the same attack
budget ϵ = 16/255 on CIFAR-10 to show the inﬂuence
brought by λ."
REFERENCES,0.902027027027027,"CIFAR-10, PreActResNet-18, ϵ = 16/255"
REFERENCES,0.9054054054054054,"1/λ (/255)
500
1000
1500
2000
2500"
REFERENCES,0.9087837837837838,"SA (%)
83.20
75.06
69.31
67.81
67.59
RA-PGD (%)
19.02
21.42
23.34
26.07
26.12"
REFERENCES,0.9121621621621622,"Sensitivity to regularization parameter λ
In Table A1, we show the sensitivity of FAST-
BAT to the regularization parameter λ. All the
parameters remain the same as default setting,
except that for different λ. We always adjust
α2 so that α2/λ = 0.1α1 holds. Note 1/λ also
serves as the attack step in (8). As λ decreases,
the improvement on robust accuracy is evidently
strengthened, and there is a obvious trade-off
between robust accuracy (SA) and standard ac-
curacy (RA). At a certain level of λ, namely
when λ ≤255/2000, RA starts to converge and stop surging."
REFERENCES,0.9155405405405406,"Table A2: Performance of FAST-BATwith different α2
choices on CIFAR-10. Models are trained and evaluated
with the same attack budget (ϵ = 16/255). Here α1 is
set as the cyclic learning rate and thus, is not a constant
parameter. α2 is always set proportionate to α1 for
simplicity."
REFERENCES,0.918918918918919,"α2 (CIFAR-10,
PreActResNet18,
ϵ = 16/255)
0.025α1
0.0167α1
0.0125α1
0.008α1"
REFERENCES,0.9222972972972973,"SA (%)
75.06
69.31
67.81
57.92
RA-PGD (%)
21.42
23.34
26.07
20.53"
REFERENCES,0.9256756756756757,"Sensitivity to different α2 choices
We con-
sider the case of robust training with the large ϵ
choice (16/255). As we can see from Table A2,
if α2 is set too small (α2 = 0.008α1), then both
SA and RA will drop signiﬁcantly. Here α1 is
set as the cyclic learning rate and thus not a
constant parameter. However, in the α2 inter-
val [0.0125α1, 0.025α1], we observed a tradeoff
between standard accuracy (SA) and robust ac-
curacy (RA): That is, the improvement in RA
corresponds to a loss in SA. In our experiments,
we choose α2 when the tradeoff yields the best
RA without suffering a signiﬁcant drop of SA (which still outperforms the baseline approaches)."
REFERENCES,0.9290540540540541,"Table A3: Performance of FAST-BAT with different
linearization schemes. Besides 1-step PGD without sign
(PGD w/o Sign), we further generate linearization point
with the following methods: uniformly random noise
[−ϵ, ϵ]d (Uniformly Random); uniformly random cor-
ner {−ϵ, ϵ}d (Random Corner); and perturbation from
1-step PGD attack with 0.5ϵ as attack step (PGD)."
REFERENCES,0.9324324324324325,"CIFAR-10, PreActResNet-18, ϵ = 16/255"
REFERENCES,0.9358108108108109,"Linearization
Method"
REFERENCES,0.9391891891891891,"PGD
w/o Sign
Uniformly
Random
Random
Corner
PGD"
REFERENCES,0.9425675675675675,"SA (%)
69.31
43.42
62.19
75.30
RA-PGD (%)
23.34
21.25
16.5
19.42"
REFERENCES,0.9459459459459459,"Sensitivity of linearization schemes
Fast-
BAT needs a good linearization point z in (7).
In experiments, we adopt the perturbation gener-
ated by 1-step PGD without sign as our default
linearization scheme. In Table A3, we show
the performance of the other possible lineariza-
tion options. We can ﬁnd 1-step PGD without
sign achieves best robust accuracy among all the
choices. This is not spurring since this lineariza-
tion point choice is consistent with the ﬁrst-
Taylor expansion that we used along the direc-
tion of input gradient without sign involved. By
contrast, FAST-BAT linearized with uniformly
random noise suffers from catastrophic overﬁtting and reaches a rather low standard accuracy (SA).
FAST-BAT with other linearizations also yields worse SA-RA trade-off than our proposal."
REFERENCES,0.9493243243243243,Under review as a conference paper at ICLR 2022
REFERENCES,0.9527027027027027,"Table A4: Performance of Hessian-free and Hessian-aware FAST-BATon CIFAR-10. We train and evaluate
with the same attack budgets ϵ = 8/255 and ϵ = 16/255 to show the inﬂuence brought by Hessian matrix."
REFERENCES,0.956081081081081,"Method
RA-PGD (%)
(ϵ = 8/255)
RA-PGD (%)
(ϵ = 16/255)
RA-AA (%)
(ϵ = 8/255)
RA-AA (%)
(ϵ = 16/255)
SA (%)
(ϵ = 8/255)
SA (%)
(ϵ = 16/255)
Time
(s/epoch)"
REFERENCES,0.9594594594594594,"Hessian-free
Fast-BAT
48.67
26.07
44.86
18.18
79.47
67.81
135"
REFERENCES,0.9628378378378378,"Hessian-aware
Fast-BAT
48.52
26.12
44.81
18.31
79.54
67.93
179"
REFERENCES,0.9662162162162162,"Table A5: Performance of FAST-ATand FAST-BATwith different activation functions on CIFAR-10. ReLU,
Swish and Softplus are taken into consideration. For FAST-BAT, we compare the Hessian-free and Hessian-aware
version to verify the inﬂuence of Hessian matrix. The results are averaged over 3 independent trials."
REFERENCES,0.9695945945945946,"Setting
SA (%)
(ϵ = 8/255)
RA-PGD (%)
(ϵ = 8/255)
SA (%)
(ϵ = 16/255)
RA-PGD (%)
(ϵ = 16/255)
Time
(s/epoch)"
REFERENCES,0.972972972972973,"Fast-AT-ReLU
81.88
45.44
46.13
21.75
42
Fast-BAT-ReLU
(Hessian-aware)
79.54
48.52
67.93
26.12
179"
REFERENCES,0.9763513513513513,"Fast-BAT-ReLU
(Hessian-free)
79.47
48.67
67.81
26.07
135"
REFERENCES,0.9797297297297297,"Fast-AT-Softplus
81.29
47.26
45.39
22.40
42
Fast-BAT-Softplus
(Hessian-aware)
79.59
49.74
68.63
25.54
178"
REFERENCES,0.9831081081081081,"Fast-BAT-Softplus
(Hessian-free)
79.48
49.67
68.57
25.59
137"
REFERENCES,0.9864864864864865,"Fast-AT-Swish
75.61
44.43
52.03
23.08
49
Fast-BAT-Swish
(Hessian-aware)
73.93
45.97
62.49
23.99
196"
REFERENCES,0.9898648648648649,"Fast-BAT-Swish
(Hessian-free)
73.89
45.90
62.59
23.81
141"
REFERENCES,0.9932432432432432,"Inﬂuence of Hessian matrix
In Theorem 1, the Hessian-free assumption, i.e.∇δδℓatk = 0, was
made to simplify the computation of IG term (implicit gradient). To examine how the Hessian matrix
∇δδℓatk affects the performance of Fast-BAT, we conduct experiments to compare the Hessian-free
FAST-BATwith the Hessian-aware version. In Hessian-aware FAST-BAT, the implicit gradient is
calculated based on (21). In Table A4, the results do not indicate much difference when Hessian is
used. However, the extra calculation brought by Hessian heavily slows down FAST-BATas around
30% more time is needed. Therefore, the Hessian-free assumption is reasonable and also necessary
in terms of the efﬁciency of the algorithm."
REFERENCES,0.9966216216216216,"Ablation study on smooth activation functions
The Hessian-free assumption is based on the
fact that the commonly used ReLU activation function is piece-wise linear w.r.t. input. We further
conduct experiments to verify the feasibility of such assumption on models with non-ReLU activation
functions. We choose two commonly used activation functions, Swish(Ramachandran et al., 2017)
and Softplus, as alternatives for non-smooth ReLU function. We compare the results both calculating
Hessian as well as the Hessian-free version to see if the Hessian-free assumption still holds for the
non-ReLU neural network. The results are shown in Table A5. As we can see, the use of Hessian does
not affect performance much. A similar phenomenon can be observed across different ϵ and different
model activation functions (ReLU, Softplus, and Swish). However, the introduction of Hessian leads
to an increase in time consumption by more than 30%. Therefore, we can draw the conclusion that
the Hessian-free assumption is reasonable across different activation function choices."
