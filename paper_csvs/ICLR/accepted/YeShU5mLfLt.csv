Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.00205761316872428,"Interval Bound Propagation (IBP) is so far the base of state-of-the-art methods
for training neural networks with certiﬁable robustness guarantees when potential
adversarial perturbations present, while the convergence of IBP training remains
unknown in existing literature. In this paper, we present a theoretical analysis
on the convergence of IBP training. With an overparameterized assumption, we
analyze the convergence of IBP robust training. We show that when using IBP
training to train a randomly initialized two-layer ReLU neural network with lo-
gistic loss, gradient descent can linearly converge to zero robust training error
with a high probability if we have sufﬁciently small perturbation radius and large
network width."
INTRODUCTION,0.00411522633744856,"1
INTRODUCTION"
INTRODUCTION,0.006172839506172839,"It has been shown that deep neural networks are vulnerable against adversarial examples (Szegedy
et al., 2014; Goodfellow et al., 2015), where a human imperceptible adversarial perturbation can
easily alter the prediction by neural networks. This poses concerns to safety-critical applications
such as autonomous vehicles, healthcare or ﬁnance systems. To combat adversarial examples, many
defense mechanisms have been proposed in the past few years (Kurakin et al., 2016; Madry et al.,
2018; Zhang et al., 2019; Guo et al., 2018; Song et al., 2018; Xiao et al., 2020). However, due to the
lack of reliable measurement on adversarial robustness, many defense methods are later broken by
stronger attacks (Carlini & Wagner, 2017; Athalye et al., 2018; Tramer et al., 2020)."
INTRODUCTION,0.00823045267489712,"There are recently a line of robust training works, known as certiﬁed robust training (certiﬁed de-
fense), focusing on training neural networks with certiﬁed and provable robustness – the network is
considered robust on an example if and only if the prediction is provably correct for any perturbation
in a predeﬁned set (e.g., a small ℓ∞ball) (Wang et al., 2018b; Bunel et al., 2018; Zhang et al., 2018;
Wang et al., 2018c; Wong & Kolter, 2018; Singh et al., 2018; 2019; Weng et al., 2018; Xu et al.,
2020). Certiﬁed defense methods provide provable robustness guarantees without referring to any
speciﬁc attack and thus do not rely on the strength of attack algorithms."
INTRODUCTION,0.0102880658436214,"To obtain a neural network with certiﬁed robustness, a common practice is to derive a neural network
veriﬁcation method that computes the upper and lower bounds of output neurons given an input
region under perturbation, and then train the model by optimizing the loss deﬁned on the worst-
case output from veriﬁcation w.r.t. any possible perturbation. Many methods along this line have
been proposed (Wong & Kolter, 2018; Wong et al., 2018; Mirman et al., 2018; Gowal et al., 2018;
Raghunathan et al., 2018a; Zhang et al., 2020a). Among these methods, Interval Bound Propagation
(IBP) (Mirman et al., 2018; Gowal et al., 2018) is a simple but effective and efﬁcient method so
far, which propagates the interval bounds of each neuron through the network to obtain the output
bounds of the network. Most of the latest state-of-the-art certiﬁed defense works are at least partly
based on IBP training (Zhang et al., 2020a; Shi et al., 2021; Lyu et al., 2021; Zhang et al., 2021)."
INTRODUCTION,0.012345679012345678,"However, the convergence properties of IBP training remained unknown. For standard neural net-
work training (without considering adversarial perturbation, aka natural training), it has been shown
that gradient descent for overparameterized networks can provably converge to a global minimizer
with random initialization (Li & Liang, 2018; Du et al., 2019b;a; Jacot et al., 2018; Allen-Zhu
et al., 2019; Zou et al., 2018). Compared to standard training, IBP-based robust training has a very"
INTRODUCTION,0.01440329218106996,Published as a conference paper at ICLR 2022
INTRODUCTION,0.01646090534979424,"different training scheme which requires a different convergence analysis. First, in the robust train-
ing problem, input can contain perturbations and the training objective is deﬁned differently from
standard training. Second, IBP training essentially optimizes a different network augmented with
IBP computation, as illustrated in Zhang et al. (2020a). Third, in IBP training, the activation state
of each neuron depends on the certiﬁed bounds rather than the values in standard neural network
computation, which introduces special perturbation-related terms in our analysis."
INTRODUCTION,0.018518518518518517,"In this paper, we conduct a theoretical analysis to study the convergence of IBP training. Follow-
ing recent convergence analysis on Stochastic Gradient Descent (SGD) for standard training, we
consider IBP robust training with gradient ﬂow (gradient descent with inﬁnitesimal step size) for a
two-layer overparameterized neural network on a classiﬁcation task. We summarize our contribu-
tions below:"
INTRODUCTION,0.0205761316872428,"• We provide the ﬁrst convergence analysis for IBP-based certiﬁed robust training. On a
two-layer overparameterized ReLU network with logistic loss, with sufﬁciently small per-
turbation radius and large network width, gradient ﬂow with IBP has a linear convergence
rate, and is guaranteed to converge to zero training error with high probability."
INTRODUCTION,0.02263374485596708,"• This result also implies that IBP converges to a state where the certiﬁed robust accuracy
measured by IBP bounds tightly reﬂects the true robustness of the network."
INTRODUCTION,0.024691358024691357,"• We show additional perturbation-related conditions required to guarantee the convergence
of IBP training and identify particular challenges in the convergence analysis for IBP train-
ing compared to standard training."
INTRODUCTION,0.026748971193415638,"Notation
We use lowercase letters to denote scalars, and use lower and upper case boldface let-
ters to denote vectors and matrices respectively. 1(·) stand for the indicator function. For a d-
dimensional vector x ∈Rd, ∥x∥p is its ℓp-norm. For two sequences {an} and {bn}, n > 0, we have
an = O(bn) if and only if ∃C > 0, ∃N > 0, ∀n > N, an ≤Cbn,. And we have an = Ω(bn) if and
only if ∃C > 0, ∃N > 0, ∀n > N, an ≥Cbn."
RELATED WORK,0.02880658436213992,"2
RELATED WORK"
CERTIFIED ROBUST TRAINING,0.030864197530864196,"2.1
CERTIFIED ROBUST TRAINING"
CERTIFIED ROBUST TRAINING,0.03292181069958848,"The goal of certiﬁed robust training is to maximize the certiﬁed robust accuracy of a model evalu-
ated by provable robustness veriﬁers. Some works added heuristic regularizations during adversarial
training to improve certiﬁed robustness (Xiao et al., 2019; Balunovic & Vechev, 2020). More ef-
fectively, certiﬁed defense works typically optimize a certiﬁed robust loss which is a certiﬁed upper
bound of the loss w.r.t. all considered perturbations. Among them, Wong & Kolter (2018); Mirman
et al. (2018); Dvijotham et al. (2018); Wong et al. (2018); Wang et al. (2018a) used veriﬁcation
with linear relaxation for nonlinear activations, and Raghunathan et al. (2018b) used semi-deﬁnite
relaxation. However, IBP (Mirman et al., 2018; Gowal et al., 2018), which computes and propagates
interval lower and bounds for each neuron, has been shown as efﬁcient and effective and can even
outperform methods using more complicated relaxation (Lee et al., 2021; Jovanovi´c et al., 2021).
Most of the effective certiﬁed defense methods are at least partly based on IBP. For example, Zhang
et al. (2020a) combined IBP with linear relaxation bounds; Lyu et al. (2021) designed a parameter-
ized activation; Zhang et al. (2021) designed a 1-Lipschitz layer with ℓ∞-norm computation before
layers using IBP; Shi et al. (2021) accelerated IBP training with shortened training schedules. As
most state-of-the-art methods so far contain IBP as an important part, we focus on analyzing the
convergence of IBP training in this paper."
CERTIFIED ROBUST TRAINING,0.03497942386831276,"On the theoretical analysis for IBP bounds, Baader et al. (2020) analyzed the universal approxima-
tion of IBP veriﬁcation bounds, and Wang et al. (2020) extended the analysis to other activation
functions beyond ReLU. However, to the best of our knowledge, there is still no existing work
analyzing the convergence of IBP training."
CERTIFIED ROBUST TRAINING,0.037037037037037035,"The aforementioned methods for certiﬁed robustness target at robustness with deterministic certiﬁ-
cation. There are also some other works on probabilistic certiﬁcation such as randomized smooth-
ing (Cohen et al., 2019; Li et al., 2019; Salman et al., 2019) which is out of our scope."
CERTIFIED ROBUST TRAINING,0.03909465020576132,Published as a conference paper at ICLR 2022
CONVERGENCE OF STANDARD NEURAL NETWORK TRAINING,0.0411522633744856,"2.2
CONVERGENCE OF STANDARD NEURAL NETWORK TRAINING"
CONVERGENCE OF STANDARD NEURAL NETWORK TRAINING,0.043209876543209874,"There have been many works analyzing the convergence of standard neural network training. For
randomly initialized two-layer ReLU networks with quadratic loss, Du et al. (2019b) proved that
gradient descent can converge to a globally optimum with a large enough network width polynomial
in the data size. Ji & Telgarsky (2019) pushed the requirement of network width to a polylogarithmic
function. For deep neural networks, Allen-Zhu et al. (2019) proved that for deep ReLU networks,
gradient descent has a linear convergence rate for various loss functions with width polynomial in
network depth and data size. Chen et al. (2019) proved that a polylogarithmic width is also sufﬁcient
for deep neural networks to converge. However, they only focus on standard training and cannot be
directly adapted to the robust training settings."
CONVERGENCE OF EMPIRICAL ADVERSARIAL TRAINING,0.04526748971193416,"2.3
CONVERGENCE OF EMPIRICAL ADVERSARIAL TRAINING"
CONVERGENCE OF EMPIRICAL ADVERSARIAL TRAINING,0.047325102880658436,"Robust training is essentially a min-max optimization. For a training data distribution X, the objec-
tive for learning a model fθ parameterized by θ can be written as1:"
CONVERGENCE OF EMPIRICAL ADVERSARIAL TRAINING,0.04938271604938271,"arg min
θ
E(x,y)∼X max
∆∈S ℓ(fθ(x + ∆), y),"
CONVERGENCE OF EMPIRICAL ADVERSARIAL TRAINING,0.051440329218107,"where (x, y) is a sample, ℓ(·, y) is the loss function, S is the space of perturbations. Empirical
adversarial training approximates the inner minimization by adversarial attacks, and some works
analyzed the convergence of adversarial training: Wang et al. (2019) considered a ﬁrst-order station-
ary condition for the inner maximization problem; Gao et al. (2019); Zhang et al. (2020b) showed
that overparameterized networks with projected gradient descent can converge to a state with robust
loss close to 0 and the the inner maximization by adversarial attack is nearly optimal; and Zou et al.
(2021) showed that adversarial training provably learns robust halfspaces in the presence of noise."
CONVERGENCE OF EMPIRICAL ADVERSARIAL TRAINING,0.053497942386831275,"However, there is a signiﬁcant difference between empirical adversarial training and certiﬁed robust
training such as IBP. Adversarial training involves a concrete perturbation ∆, which is an approx-
imate solution for the inner maximization and could lead to a concrete adversarial input x + ∆.
However, in IBP-based training, the inner maximization is computed from certiﬁed bounds, where
for each layer, the certiﬁed bounds of each neuron are computed independently, and thereby the cer-
tiﬁed bounds of the network generally do not correspond to any speciﬁc ∆. Due to this signiﬁcant
difference, prior theoretical analysis on adversarial training, which requires a concrete ∆for inner
maximization, is not applicable to IBP."
PRELIMINARIES,0.05555555555555555,"3
PRELIMINARIES"
NEURAL NETWORKS,0.05761316872427984,"3.1
NEURAL NETWORKS"
NEURAL NETWORKS,0.059670781893004114,"Following Du et al. (2019b), we consider a similar two-layer ReLU network. Unlike Du et al.
(2019b) which considered a regression task with the square loss, we consider a classiﬁcation task
where IBP is usually used, and we consider binary classiﬁcation for simplicity. On a training dataset
{(xi, yi)}n
i=1, for every i ∈[n], (xi, yi) is a training example with d-dimensional input xi(xi ∈Rd)
and label yi(yi ∈{±1}), and the network output is:"
NEURAL NETWORKS,0.06172839506172839,"f(W, a, xi) =
1
√m m
X"
NEURAL NETWORKS,0.06378600823045268,"r=1
arσ(w⊤
r xi),
(1)"
NEURAL NETWORKS,0.06584362139917696,"where m is the width of hidden layer (the ﬁrst layer) in the network, W ∈Rm×d is the weight ma-
trix of the hidden layer, wr(r∈[m]) is the r-th row of W, a ∈Rm is the weight vector of the second
layer (output layer) with elements a1, · · · , am, and σ(·) is the activation function. We assume the ac-
tivation is ReLU as IBP is typically used with ReLU. For initialization, we set ar ∼unif[{1, −1}] and
wr ∼N(0, I). Only the ﬁrst layer is trained after initialization. Since we consider binary classiﬁca-
tion, we use a logistic loss. For training example (xi, yi), we deﬁne ui(W, a, xi) := yif(W, a, xi),"
NEURAL NETWORKS,0.06790123456790123,"1Here we use notations to denote the general robust training problem, but in our later analysis, we will have
different notations for a simpliﬁed problem setting."
NEURAL NETWORKS,0.06995884773662552,Published as a conference paper at ICLR 2022
NEURAL NETWORKS,0.0720164609053498,"the loss on this example is computed as l(ui(W, a, xi)) = log(1 + exp(−ui(W, a, xi))), and the
standard training loss on the whole training set is L = n
X"
NEURAL NETWORKS,0.07407407407407407,"i=1
l(ui(W, a, xi)) = n
X"
NEURAL NETWORKS,0.07613168724279835,"i=1
log

1 + exp(−ui(W, a, xi))

."
CERTIFIED ROBUST TRAINING,0.07818930041152264,"3.2
CERTIFIED ROBUST TRAINING"
CERTIFIED ROBUST TRAINING,0.08024691358024691,"In the robust training setting, for original input xi (∀i ∈[n]), we consider that the actual input
may be perturbed into xi + ∆i by perturbation ∆i. For a widely adopted setting, we consider ℓ∞
perturbations, where ∆i is bounded by an ℓ∞ball with radius ϵ(0 ≤ϵ ≤1), i.e., ∥∆i∥∞≤ϵ.
For the convenience of subsequent analysis and without loss of generality, we make the following
assumption on each xi, which can be easily satisﬁed by normalizing the training data:
Assumption 1. ∀i ∈[n], we assume there exists some ξ > 0, such that xi ∈[ϵ, 1]d, ∥xi∥2 ≥ξ."
CERTIFIED ROBUST TRAINING,0.0823045267489712,"In Du et al. (2019b), they also assume there are no parallel data points, and in our case we assume
this holds under any possible perturbation, formulated as:
Assumption 2. For perturbation radius ϵ, we assume that"
CERTIFIED ROBUST TRAINING,0.08436213991769548,"∀i, j ∈[n], i ̸= j, ∀x′
i ∈B∞(xi, ϵ), ∀x′
j ∈B∞(xj, ϵ),
x′
i ∦x′
j,"
CERTIFIED ROBUST TRAINING,0.08641975308641975,"where B∞(xi, ϵ) stands for the ℓ∞-ball with radius ϵ centered at xi."
CERTIFIED ROBUST TRAINING,0.08847736625514403,"IBP training computes and optimizes a robust loss L, which is an upper bound of the standard loss
for any possible perturbation ∆i (∀i ∈[n]): L ≥ n
X"
CERTIFIED ROBUST TRAINING,0.09053497942386832,"i=1
max
∆i"
CERTIFIED ROBUST TRAINING,0.09259259259259259,"
log

1 + exp(−yif(W, a, xi + ∆i))

| ∥∆i∥∞≤ϵ

."
CERTIFIED ROBUST TRAINING,0.09465020576131687,"To compute L, since log(·) and exp(·) are both monotonic, for every i ∈[n], IBP ﬁrst computes the
lower bound of ui(W, a, xi + ∆i) for ∥∆i∥∞≤ϵ, denoted as ui. Then the IBP robust loss is: L = n
X"
CERTIFIED ROBUST TRAINING,0.09670781893004116,"i=1
log(1 + exp(−ui)),
where ui ≤min
∆i ui(W, a, xi + ∆i) (i ∈[n]).
(2)"
CERTIFIED ROBUST TRAINING,0.09876543209876543,"IBP computes and propagates an interval lower and upper bound for each neuron in the network,
and then ui is equivalent to the lower bound of the ﬁnal output neuron. Initially, the interval bound
of the input is [xi −ϵ · 1, x + ϵ · 1] given ∥∆i∥∞≤ϵ, since xi −ϵ · 1 ≤xi + ∆i ≤xi + ϵ · 1
element-wisely holds. Then this interval bound is propagated to the ﬁrst hidden layer, and we have
the interval bound for each neuron in the ﬁrst layer:"
CERTIFIED ROBUST TRAINING,0.10082304526748971,"∀r ∈[m], σ
 
w⊤
r xi −ϵ∥wr∥1

≤σ
 
w⊤
r (xi + ∆i)

≤σ
 
w⊤
r xi + ϵ∥wr∥1

."
CERTIFIED ROBUST TRAINING,0.102880658436214,"These bounds are further propagated to the second layer. We focus on the lower bound of ui, which
can be computed from the bounds of the ﬁrst layer by considering the sign of multiplier yiar:"
CERTIFIED ROBUST TRAINING,0.10493827160493827,"ui(W, a, xi + ∆i) = yi
1
√m m
X"
CERTIFIED ROBUST TRAINING,0.10699588477366255,"r=1
arσ(w⊤
r (xi + ∆i))"
CERTIFIED ROBUST TRAINING,0.10905349794238683,"≥
1
√m m
X r=1"
CERTIFIED ROBUST TRAINING,0.1111111111111111,"
1(yiar = 1)σ
 
w⊤
r xi −ϵ∥wr∥1
"
CERTIFIED ROBUST TRAINING,0.11316872427983539,"+ 1(yiar = −1)σ
 
w⊤
r xi + ϵ∥wr∥1

:= ui.
(3)"
CERTIFIED ROBUST TRAINING,0.11522633744855967,"Then the IBP robust loss can be obtained as Eq. (2). And we deﬁne u := (u1, u2, · · · , un)."
CERTIFIED ROBUST TRAINING,0.11728395061728394,"We deﬁne certiﬁed robust accuracy in IBP training as the percentage of examples that IBP bounds
can successfully certify that the prediction is correct for any concerned perturbation. An example
i(i ∈[n]) is considered as robustly classiﬁed under IBP veriﬁcation if and only if ui > 0. Let ˜ui be
the exact solution of the minimization in Eq. (2) rather than relaxed IBP bounds, we also deﬁne the
true robust accuracy, where the robustness requires ˜ui > 0. The certiﬁed robust accuracy by IBP
is a provable lower bound of the true robust accuracy."
CERTIFIED ROBUST TRAINING,0.11934156378600823,Published as a conference paper at ICLR 2022
GRADIENT FLOW,0.12139917695473251,"3.3
GRADIENT FLOW"
GRADIENT FLOW,0.12345679012345678,"Gradient ﬂow is gradient descent with inﬁnitesimal step size for a continuous time analysis, and it
is adopted in prior works analyzing standard training (Arora et al., 2018; Du et al., 2019a;b). In IBP
training, gradient ﬂow is deﬁned as:"
GRADIENT FLOW,0.12551440329218108,"∀r ∈[m], dwr(t)"
GRADIENT FLOW,0.12757201646090535,"dt
= −∂L(t)"
GRADIENT FLOW,0.12962962962962962,"∂wr(t),
(4)"
GRADIENT FLOW,0.13168724279835392,"where w1(t), w2(t), · · · , wm(t) are rows of the weight matrix at time t, and L(t) is the IBP robust
loss deﬁned as Eq. (2) using weights at time t."
GRAM MATRIX,0.1337448559670782,"3.4
GRAM MATRIX"
GRAM MATRIX,0.13580246913580246,"Under the gradient ﬂow setting as Eq. (4), for all i ∈[n], we analyze the dynamics of ui during IBP
training, and we use ui(t) to denote its value at time t:"
GRAM MATRIX,0.13786008230452676,"d
dtui(t) = m
X r=1"
GRAM MATRIX,0.13991769547325103,∂ui(t)
GRAM MATRIX,0.1419753086419753,"∂wr(t), dwr(t) dt = n
X"
GRAM MATRIX,0.1440329218106996,"j=1
−l′(uj)Hij(t),
(5)"
GRAM MATRIX,0.14609053497942387,"where l′(uj) is the derivative of the loss, H(t) is a Gram matrix and deﬁned as Hij(t) =
Pm
r=1"
GRAM MATRIX,0.14814814814814814,"∂ui(t)
∂wr(t),
∂uj(t)
∂wr(t)"
GRAM MATRIX,0.15020576131687244,"(∀1 ≤i, j ≤n). We provide a detailed derivation in Appendix B.1."
GRAM MATRIX,0.1522633744855967,The dynamic of ui can be described using H.
GRAM MATRIX,0.15432098765432098,"From Eq. (3), ∀i ∈[n], r ∈[m], derivative ∂ui(t)"
GRAM MATRIX,0.15637860082304528,∂wr(t) can be computed as follows:
GRAM MATRIX,0.15843621399176955,"∂ui(t)
∂wr(t) =
1
√myiar"
GRAM MATRIX,0.16049382716049382,"
A+
ri(t)

xi −ϵ sign(wr(t))

+ A−
ri(t)

xi + ϵ sign(wr(t))

,"
GRAM MATRIX,0.16255144032921812,"where sign(wr(t)) is element-wise for wr(t), and we deﬁne indicators"
GRAM MATRIX,0.1646090534979424,"A+
ri(t) := 1(yiar = 1, wr(t)⊤xi −ϵ∥wr(t)∥1 > 0),"
GRAM MATRIX,0.16666666666666666,"A−
ri(t) := 1(yiar = −1, wr(t)⊤xi + ϵ∥wr(t)∥1 > 0)."
GRAM MATRIX,0.16872427983539096,Then elements in H can be written as:
GRAM MATRIX,0.17078189300411523,"Hij(t) = 1 myiyj m
X"
GRAM MATRIX,0.1728395061728395,"r=1
a2
r"
GRAM MATRIX,0.1748971193415638,"
A+
ri(t)

xi −ϵ sign(wr(t))

+ A−
ri(t)

xi + ϵ sign(wr(t))
⊤"
GRAM MATRIX,0.17695473251028807,"
A+
rj(t)

xj −ϵ sign(wr(t))

+ A−
rj(t)

xj + ϵ sign(wr(t))
 = 1 myiyj"
GRAM MATRIX,0.17901234567901234,"
x⊤
i xj m
X"
GRAM MATRIX,0.18106995884773663,"r=1
αrij(t) −ϵ
 m
X"
GRAM MATRIX,0.1831275720164609,"r=1
(βrij(t)xi + βrji(t)xj)⊤sign(wr(t))

+ ϵ2d m
X"
GRAM MATRIX,0.18518518518518517,"r=1
γrij(t)

, (6)"
GRAM MATRIX,0.18724279835390947,"where αrij(t), βrij(t), γrij(t) are deﬁned as follows"
GRAM MATRIX,0.18930041152263374,"αrij(t) = (A+
ri(t) + A−
ri(t))(A+
rj(t) + A−
rj(t)),"
GRAM MATRIX,0.19135802469135801,"βrij(t) = (A+
ri(t) + A−
ri(t))(A+
rj(t) −A−
rj(t)),"
GRAM MATRIX,0.1934156378600823,"γrij(t) = (A+
ri(t) −A−
ri(t))(A+
rj(t) −A−
rj(t))."
GRAM MATRIX,0.19547325102880658,"Further, we deﬁne H∞which is the elementwise expectation of H(0), to characterize H(0) on the
random initialization basis:"
GRAM MATRIX,0.19753086419753085,"∀1 ≤i, j ≤n, H∞
ij := E∀1≤r≤m,wr∼N(0,I),ar∼unif[{−1,1}]Hij(0),"
GRAM MATRIX,0.19958847736625515,"where Hij(0) depends on the initialization of weights wr and ar. We also deﬁne λ0 := λmin(H∞)
as the least eigenvalue of H∞. We will prove that H(0) is positive deﬁnite with high probability, by
showing that H∞is positive deﬁnite and bounding the difference between H(0) and H∞."
GRAM MATRIX,0.20164609053497942,Published as a conference paper at ICLR 2022
CONVERGENCE ANALYSIS FOR IBP TRAINING,0.2037037037037037,"4
CONVERGENCE ANALYSIS FOR IBP TRAINING"
CONVERGENCE ANALYSIS FOR IBP TRAINING,0.205761316872428,"We present the following main theorem which shows the convergence of IBP training under certain
conditions on perturbation radius and network width:
Theorem 1 (Convergence of IBP Training). Suppose Assumptions 1 and 2 hold for the train-"
CONVERGENCE ANALYSIS FOR IBP TRAINING,0.20781893004115226,"ing data, and the ℓ∞perturbation radius satisﬁes ϵ ≤O

min

δ2λ2
0
d2.5n3 ,
√"
DR,0.20987654320987653,"2dR
log(√ 2πd R ξ)"
DR,0.21193415637860083,"
, where"
DR,0.2139917695473251,"R =
cδλ0
d1.5n2 , c =
√"
DR,0.21604938271604937,"2πξ
384 . For a two-layer ReLU network (Eq. (1)), suppose its width for the"
DR,0.21810699588477367,"ﬁrst hidden layer satisﬁes m ≥Ω

d1.5n4δλ0
δ2λ2
0−ϵd2.5n4
2
, and the network is randomly initialized"
DR,0.22016460905349794,"as ar ∼unif[{1, −1}], wr ∼N(0, I), with the second layer ﬁxed during training. Then for any
conﬁdence δ(0<δ<1), with probability at least 1−δ, IBP training with gradient ﬂow can converge
to zero training error."
DR,0.2222222222222222,"The theorem contains two ﬁndings: First, for a given ϵ, as long as it satisﬁes the upper bound on ϵ
speciﬁed in the theorem, with a sufﬁciently large width m, convergence of IBP training is guaranteed
with high probability; Second, when ϵ is larger than the upper bound, IBP training is not guaranteed
to converge under our analysis even with arbitrarily large m, which is essentially different from
analysis on standard training and implies a possible limitation of IBP training."
DR,0.2242798353909465,"In the following part of this section, we provide the proof sketch for the main theorem."
STABILITY OF THE GRAM MATRIX DURING IBP TRAINING,0.22633744855967078,"4.1
STABILITY OF THE GRAM MATRIX DURING IBP TRAINING"
STABILITY OF THE GRAM MATRIX DURING IBP TRAINING,0.22839506172839505,"We ﬁrst analyze the stability of H during training since H can characterize the dynamic of the
training as deﬁned in Eq. (5). We show that when there exists some R such that the change of
wr(∀r ∈[m]) is restricted to ∥wr(t) −wr(0)∥2 ≤R during training, we can guarantee that
λmin(H(t)) remains positive with high probability. This property will be later used to reach the
conclusion on the convergence. We defer the derivation for the constraint on R to a later part."
STABILITY OF THE GRAM MATRIX DURING IBP TRAINING,0.23045267489711935,"For all r ∈[m], with the aforementioned constraint on wr(t), we ﬁrst show that during the IBP
training, most of αrij(t), βrij(t), γrij(t) terms in Eq. (6) remain the same as their initialized values
(t = 0). This is because for for each of αrij(t), βrij(t), γrij(t), the probability that its value changes
during training can be upper bounded by a polynomial in R, and thereby the probability can be made
sufﬁciently small for a sufﬁciently small R, as the following lemma shows:
Lemma 1. ∀r ∈[m], at some time t > 0, suppose ∥wr(t) −wr(0)∥2 ≤R holds for some R, and
ϵ ≤
√"
DR,0.23251028806584362,"2dR
log(√ 2πd"
DR,0.2345679012345679,"R ξ) holds, then for all 1≤i, j ≤n, we have"
DR,0.2366255144032922,"Pr(αrij(t) ̸= αrij(0)), Pr(βrij(t) ̸= βrij(0)), Pr(γrij(t) ̸= γrij(0)) ≤
12
√"
DR,0.23868312757201646,"2πξ (1 + ϵ)
√"
DR,0.24074074074074073,dR := ˜R.
DR,0.24279835390946503,"We provide the full proof in Appendix A.1. Probabilities in Lemma 1 can be bounded as long as the
probability that each of indicator A+
ri(t), A−
ri(t), A+
rj(t), A−
rj(t) changes is upper bounded respec-
tively. When the change of wr(t) is bounded, the indicators can change during the training only if at
initialization |wr(0)⊤xi±ϵ∥wr(0)∥1| is sufﬁciently small, whose probability can be upper bounded
(notation ± here means the analysis is consistent for both + and −cases). To bound this probability,
while Du et al. (2019b) simply used the anti-concentration of standard Gaussian distribution in their
standard training setting, here our analysis is different due to additional perturbation-related terms
ϵ∥wr(0)∥1, and we combine anti-concentration and the tail bound of standard Gaussian in our proof."
DR,0.2448559670781893,"We can then bound the change of the Gram matrix, i.e., ∥H(t) −H(0)∥2:
Lemma 2. ∀r ∈[m], at some time t > 0, suppose ∥wr(t) −wr(0)∥2 ≤R holds for some constant
R, for any conﬁdence δ(0 < δ < 1), with probability at least 1 −δ, it holds that"
DR,0.24691358024691357,∥H(t) −H(0)∥2 ≤12(1 + ϵ)(1 + 2ϵ + ϵ2)d1.5n2 √
DR,0.24897119341563786,"2πξδ
R.
(7)"
DR,0.25102880658436216,"This can be proved by ﬁrst upper bounding E[|Hij(t) −Hij(0)|] (∀1 ≤i, j ≤n) using Lemma 1,
and then by Markov’s inequality, we can upper bound ∥H(t) −H(0)∥2 with high probability."
DR,0.25308641975308643,Published as a conference paper at ICLR 2022
DR,0.2551440329218107,"We provide the proof in Appendix A.2.
And by triangle inequality, we can also lower bound
λmin(H(t)):
Corollary 1. ∀r ∈[m], at some time t > 0, suppose ∥wr(t) −wr(0)∥2 ≤R holds for some
constant R, for any conﬁdence δ(0 < δ < 1), with probability at least 1 −δ, it holds that"
DR,0.257201646090535,λmin(H(t)) ≥λmin(H(0)) −12(1 + ϵ)(1 + 2ϵ + ϵ2)d1.5n2 √
DR,0.25925925925925924,"2πξδ
R,
(8)"
DR,0.2613168724279835,where λmin(·) stands for the minimum eigenvalue.
DR,0.26337448559670784,"We also need to lower bound λmin(H(0)) in order to lower bound λmin(H(t)). Given Assumption 2,
we show that the minimum eigenvalue of H∞is positive:
Lemma 3. When the dataset satisﬁes Assumption 2, λ0 := λmin(H∞) > 0 holds true."
DR,0.2654320987654321,"The lemma can be similarly proved as Theorem 3.1 in Du et al. (2019b), but we have a different
Assumption 2 considering perturbations. We discuss in more detail in Appendix A.3. Then we can
lower bound λmin(H(0)) by Lemma 3.1 from Du et al. (2019b):
Lemma 4 (Lemma 3.1 from Du et al. (2019b)). If λ0 > 0, for any conﬁdence δ(0 < δ < 1), take
m = Ω( n2"
DR,0.2674897119341564,"λ2
0 log( n"
DR,0.26954732510288065,"δ )), then with probability at least 1 −δ, it holds true that λmin(H(0)) ≥3 4λ0."
DR,0.2716049382716049,"Although we have different values in H(0) for IBP training, we can still adopt their original lemma
because their proof by Hoeffding’s inequality is general regardless of values in H(0). We then
plug in λmin(H(0)) ≥3"
DR,0.2736625514403292,"4λ0 to Eq. (8), and we solve the inequality to ﬁnd a proper R such that
λmin(H)(t) ≥λ0"
DR,0.2757201646090535,"2 , as shown in the following lemma (proved in Appendix A.4):
Lemma 5. For any conﬁdence δ(0 < δ < 1), ∀r ∈[m], suppose ∥wr(t) −wr(0)∥2 ≤R holds,
where R =
cδλ0
d1.5n2 with c =
√"
DR,0.2777777777777778,"2πξ
384 , then probability at least 1 −δ, λmin(H(t)) ≥λ0"
DR,0.27983539094650206,2 holds.
DR,0.28189300411522633,"Therefore, we have shown that with overparameterization (required by Lemma 4), when wr is rel-
atively stable during training for all r ∈[m], i.e., the maximum change on wr(t) is upper bounded
during training (characterized by the ℓ2-norm of weight change restricted by R), H(t) is also rela-
tively stable and remains positive deﬁnite with high probability."
CONVERGENCE OF THE IBP ROBUST LOSS,0.2839506172839506,"4.2
CONVERGENCE OF THE IBP ROBUST LOSS"
CONVERGENCE OF THE IBP ROBUST LOSS,0.28600823045267487,"Next, we can derive the upper bound of the IBP loss during training. In the following lemma, we
show that when H(t) remains positive deﬁnite, the IBP loss L(t) descends in a linear convergence
rate, and meanwhile we have an upper bound on the change of wr(t) w.r.t. time t:"
CONVERGENCE OF THE IBP ROBUST LOSS,0.2880658436213992,"Lemma 6. Suppose for 0 ≤s ≤t, λmin(H(t)) ≥λ0"
CONVERGENCE OF THE IBP ROBUST LOSS,0.29012345679012347,"2 , we have"
CONVERGENCE OF THE IBP ROBUST LOSS,0.29218106995884774,"L(t) ≤exp

2L(0)
"
CONVERGENCE OF THE IBP ROBUST LOSS,0.294238683127572,"L(0) exp

−λ0t 2"
CONVERGENCE OF THE IBP ROBUST LOSS,0.2962962962962963,"
,
∥wr(t) −wr(0)∥2 ≤nt
√m."
CONVERGENCE OF THE IBP ROBUST LOSS,0.29835390946502055,"This lemma is proved in Appendix A.5, which follows the proof of Lemma 5.4 in Zou et al. (2018).
To guarantee that λmin(H(s)) ≥λ0"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3004115226337449,"2 for 0 ≤s ≤t, by Lemma 5, we only require
nt
√m ≤R ="
CONVERGENCE OF THE IBP ROBUST LOSS,0.30246913580246915,"cδλ0
d1.5n2 , which holds sufﬁciently by"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3045267489711934,"t ≤cδλ0
√m
d1.5n3 .
(9)"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3065843621399177,"Meanwhile, for each example i, the model can be certiﬁed by IBP on example i with any ℓ∞per-
turbation within radius ϵ, if and only if ui > 0, and this condition is equivalent to l(ui) < κ, where
κ := log(1 + exp(0)). Therefore, to reach zero training error on the whole training set at time t, we
can require L(t) < κ, which implies that ∀1 ≤i ≤n, l(ui) < κ. Then with Lemma 6, we want the
upper bound of L(t) to be less than κ:"
CONVERGENCE OF THE IBP ROBUST LOSS,0.30864197530864196,"L(t) ≤exp

2L(0)
"
CONVERGENCE OF THE IBP ROBUST LOSS,0.31069958847736623,"L(0) exp

−λ0t 2"
CONVERGENCE OF THE IBP ROBUST LOSS,0.31275720164609055,"
< κ,"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3148148148148148,Published as a conference paper at ICLR 2022
CONVERGENCE OF THE IBP ROBUST LOSS,0.3168724279835391,which holds sufﬁciently by t > 4 λ0
CONVERGENCE OF THE IBP ROBUST LOSS,0.31893004115226337,"
log
L(0) κ"
CONVERGENCE OF THE IBP ROBUST LOSS,0.32098765432098764,"
+ L(0)

.
(10)"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3230452674897119,"To make Eq. (10) reachable at some t, with the constraint in Eq. (9) we require: 4
λ0"
CONVERGENCE OF THE IBP ROBUST LOSS,0.32510288065843623,"
log
L(0) κ"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3271604938271605,"
+ L(0)

< cδλ0
√m
d1.5n3 .
(11)"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3292181069958848,"The left-hand-side of Eq. (11) can be upper bounded by 4
λ0"
CONVERGENCE OF THE IBP ROBUST LOSS,0.33127572016460904,"
log
L(0) κ"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3333333333333333,"
+ L(0)

= 4"
CONVERGENCE OF THE IBP ROBUST LOSS,0.33539094650205764,"λ0
(L(0) + log(L(0)) −log(κ)) ≤4"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3374485596707819,"λ0
(2L(0) −log(κ))."
CONVERGENCE OF THE IBP ROBUST LOSS,0.3395061728395062,"Therefore, in order to have Eq. (11) hold, it sufﬁces to have"
CONVERGENCE OF THE IBP ROBUST LOSS,0.34156378600823045,"4
λ0
(2L(0) −log(κ)) < cδλ0
√m
d1.5n3
=⇒L(0) + c0 < c′δλ2
0
√m
d1.5n3
,
(12)"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3436213991769547,where c′ := c
CONVERGENCE OF THE IBP ROBUST LOSS,0.345679012345679,8 and c0 are positive constants.
CONVERGENCE OF THE IBP ROBUST LOSS,0.3477366255144033,"Since L(0) has randomness from the randomly initialized weight W, we need to upper bound the
value of L(0) as we show in the following lemma (proved in Appendix A.6 by concentration):
Lemma 7. In natural training, for any conﬁdence δ(0 < δ < 1), with probability at least 1 −δ,
L(0) = O( n"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3497942386831276,"δ ) holds. In IBP training, for any conﬁdence δ(0 < δ < 1), with probability at least
1 −δ, L(0) = O( n√mdϵ δ
+ n"
CONVERGENCE OF THE IBP ROBUST LOSS,0.35185185185185186,δ ) holds.
CONVERGENCE OF THE IBP ROBUST LOSS,0.35390946502057613,"And this lemma implies that with large n and m, there exist constants c1, c2, c3 such that"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3559670781893004,L(0) ≤c1n√mdϵ
CONVERGENCE OF THE IBP ROBUST LOSS,0.35802469135802467,"δ
+ c2n"
CONVERGENCE OF THE IBP ROBUST LOSS,0.360082304526749,"δ
+ c3.
(13)"
CONVERGENCE OF THE IBP ROBUST LOSS,0.36213991769547327,"Plug Eq. (13) into Eq. (12), then the requirement in Eq. (12) can be relaxed into:"
CONVERGENCE OF THE IBP ROBUST LOSS,0.36419753086419754,"c′δλ2
0
√m
d1.5n3
> c1n√mdϵ"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3662551440329218,"δ
+ c2n"
CONVERGENCE OF THE IBP ROBUST LOSS,0.3683127572016461,"δ
+ c3 + c0 =⇒
 c′δλ2
0
d1.5n3 −c1ndϵ δ"
CONVERGENCE OF THE IBP ROBUST LOSS,0.37037037037037035,√m > c2n
CONVERGENCE OF THE IBP ROBUST LOSS,0.3724279835390947,"δ
+ c4,
(14)"
CONVERGENCE OF THE IBP ROBUST LOSS,0.37448559670781895,"where c4 := c3 + c0 is a constant. As long as Eq. (14) holds, Eq. (11) also holds, and thereby IBP
training is guaranteed to converge to zero IBP robust error on the training set."
PROVING THE MAIN THEOREM,0.3765432098765432,"4.3
PROVING THE MAIN THEOREM"
PROVING THE MAIN THEOREM,0.3786008230452675,"Finally, we are ready to prove the main theorem. To make Eq. (11) satisﬁed, we want to make its
relaxed version, Eq. (14) hold by sufﬁciently enlarging m. This requires that the coefﬁcient of √m
in Eq. (14) , c′δλ2
0
d1.5n3 −c1ndϵ"
PROVING THE MAIN THEOREM,0.38065843621399176,"δ
to be positive, and we also plug in the constraint on ϵ in Lemma 1:"
PROVING THE MAIN THEOREM,0.38271604938271603,"c′δλ2
0
d1.5n3 −c1ndϵ"
PROVING THE MAIN THEOREM,0.38477366255144035,"δ
> 0, ϵ ≤ √"
DR,0.3868312757201646,2dR
DR,0.3888888888888889,"log(
q 2πd"
DR,0.39094650205761317,"R ξ)
."
DR,0.39300411522633744,"Combining these two constraints, we can obtain the constraint for ϵ in the main theorem:"
DR,0.3950617283950617,"ϵ < min
 c′δ2λ2
0
c1d2.5n3 , √"
DR,0.39711934156378603,2dR
DR,0.3991769547325103,"log(
q 2πd R ξ) 
."
DR,0.4012345679012346,"Then by Eq. (14), our requirement on width m is"
DR,0.40329218106995884,"m ≥Ω

d1.5n4δλ0
δ2λ2
0 −ϵd2.5n4 2
."
DR,0.4053497942386831,"This completes the proof of the main theorem.s In our analysis, we focus on IBP training with ϵ > 0.
But IBP with ϵ = 0 can also be viewed as standard training. By setting ϵ = 0, if m ≥Ω( n8d3"
DR,0.4074074074074074,"λ4
0δ4 ),
our result implies that for any conﬁdence δ (0 < δ < 1), standard training with logistic loss also
converges to zero training error with probability at least 1 −δ. And as ϵ gets larger, the required m
for convergence also becomes larger."
DR,0.4094650205761317,Published as a conference paper at ICLR 2022
DR,0.411522633744856,"500
2000
5000
10000
80000
Model width m 0.00 0.01 0.02 0.03 0.04 Error"
DR,0.41358024691358025,"standard training
IBP training with = 0.04"
DR,0.4156378600823045,IBP training with = 0.001
DR,0.4176954732510288,"(a) Final training error of standard training and
IBP (with ϵ ∈{0.001, 0.04}) respectively, when
the width m of the model is varied."
DR,0.41975308641975306,"0.04
0.05
0.1
0.2
 perutbration radius 0.1 0.2 0.3 0.4 Error"
DR,0.4218106995884774,"hidden layer width=2000
hidden layer width=5000"
DR,0.42386831275720166,"(b) Final training error of IBP training (on models
with width 2000 and 5000 respectively), when the
perturbation radius ϵ is varied."
DR,0.42592592592592593,Figure 1: Experimental results.
EXPERIMENTS,0.4279835390946502,"5
EXPERIMENTS"
EXPERIMENTS,0.43004115226337447,"We further conduct experiments to compare the convergence of networks with different widths m for
natural training and IBP training respectively. We use the MNIST (LeCun et al., 2010) dataset and
take digit images with label 2 and 5 for binary classiﬁcation. And we use a two-layer fully-connected
ReLU network with a variable width. We train the model for 70 epochs with SGD, and we keep ϵ
ﬁxed throughout the whole training process. We present results in Figure 1. First, compared with
standard training, for the same width m, IBP has higher training errors (Figure 1a). Second, for
relatively large ϵ (ϵ = 0.04), even if we enlarge m up to 80,000 limited by the memory of a single
GeForce RTX 2080 GPU, IBP error is still far away from 0 (Figure 1a). This is consistent with
our main theorem that when ϵ is too large, simply enlarging m cannot guarantee the convergence.
Moreover, when ϵ is even larger, IBP training falls into a local minimum of random guess (with
errors close to 50%) (Figure 1b). We conjecture that this is partly because λ0 can be very small
with a large perturbation, and then the training can be much more difﬁcult, and this difﬁculty cannot
be alleviated by simply enlarging the network width m. Existing works with IBP-based training
typically use a scheduling on ϵ and gradually increase ϵ from 0 until the target value for more stable
training. Overall, the empirical observations match our theoretical results."
CONCLUSION,0.43209876543209874,"6
CONCLUSION"
CONCLUSION,0.43415637860082307,"In this paper, we present the ﬁrst theoretical analysis of IBP-based certiﬁed robust training, and
we show that IBP training can converge to zero training error with high probability, under certain
conditions on perturbation radius and network width. Meanwhile, since the IBP robust accuracy
is a lower bound of the true robust accuracy (see Section 3.2), upon convergence the true robust
accuracy also converges to 100% on training data and the certiﬁcation by IBP accurately reﬂects
the true robustness. Our results have a condition requiring a small upper bound on ϵ, and it will be
interesting for future work to study how to relax this condition, take the effect of ϵ scheduling into
consideration, and extend the analysis to deeper networks."
CONCLUSION,0.43621399176954734,ACKNOWLEDGEMENTS
CONCLUSION,0.4382716049382716,"We thank the anonymous reviewers for their helpful comments. This work is partially supported
by NSF under IIS-2008173, IIS-2048280 and by Army Research Laboratory under agreement num-
ber W911NF-20-2-0158; QG is partially supported by the National Science Foundation CAREER
Award 1906169 and IIS-2008981. The views and conclusions contained in this paper are those of
the authors and should not be interpreted as representing any funding agencies."
CONCLUSION,0.4403292181069959,Published as a conference paper at ICLR 2022
REFERENCES,0.44238683127572015,REFERENCES
REFERENCES,0.4444444444444444,"Zeyuan Allen-Zhu, Yuanzhi Li, and Zhao Song. A convergence theory for deep learning via over-
parameterization. In International Conference on Machine Learning, volume 97 of Proceed-
ings of Machine Learning Research, pp. 242–252, 2019. URL http://proceedings.mlr.
press/v97/allen-zhu19a.html."
REFERENCES,0.44650205761316875,"Sanjeev Arora, Nadav Cohen, and Elad Hazan.
On the optimization of deep networks: Im-
plicit acceleration by overparameterization.
In International Conference on Machine Learn-
ing, volume 80 of Proceedings of Machine Learning Research, pp. 244–253, 2018.
URL
http://proceedings.mlr.press/v80/arora18a.html."
REFERENCES,0.448559670781893,"Anish Athalye, Nicholas Carlini, and David A. Wagner. Obfuscated gradients give a false sense
of security: Circumventing defenses to adversarial examples. In International Conference on
Machine Learning, volume 80 of Proceedings of Machine Learning Research, pp. 274–283, 2018.
URL http://proceedings.mlr.press/v80/athalye18a.html."
REFERENCES,0.4506172839506173,"Maximilian Baader, Matthew Mirman, and Martin T. Vechev. Universal approximation with certiﬁed
networks. In International Conference on Learning Representations, 2020. URL https://
openreview.net/forum?id=B1gX8kBtPr."
REFERENCES,0.45267489711934156,"Mislav Balunovic and Martin T. Vechev.
Adversarial training and provable defenses: Bridging
the gap.
In International Conference on Learning Representations, 2020.
URL https://
openreview.net/forum?id=SJxSDxrKDr."
REFERENCES,0.4547325102880658,"Rudy Bunel, Ilker Turkaslan, Philip H. S. Torr, Pushmeet Kohli, and Pawan Kumar Mudigonda. A
uniﬁed view of piecewise linear neural network veriﬁcation. In Advances in Neural Information
Processing Systems, pp. 4795–4804, 2018. URL https://proceedings.neurips.cc/
paper/2018/hash/be53d253d6bc3258a8160556dda3e9b2-Abstract.html."
REFERENCES,0.4567901234567901,"Nicholas Carlini and David Wagner. Adversarial examples are not easily detected: Bypassing ten
detection methods.
In Proceedings of the 10th ACM Workshop on Artiﬁcial Intelligence and
Security, pp. 3–14, 2017."
REFERENCES,0.4588477366255144,"Zixiang Chen, Yuan Cao, Difan Zou, and Quanquan Gu. How much over-parameterization is sufﬁ-
cient to learn deep relu networks? CoRR, abs/1911.12360, 2019. URL http://arxiv.org/
abs/1911.12360."
REFERENCES,0.4609053497942387,"Jeremy M. Cohen, Elan Rosenfeld, and J. Zico Kolter. Certiﬁed adversarial robustness via random-
ized smoothing. In International Conference on Machine Learning, volume 97 of Proceedings
of Machine Learning Research, pp. 1310–1320, 2019. URL http://proceedings.mlr.
press/v97/cohen19c.html."
REFERENCES,0.46296296296296297,"Simon S. Du, Jason D. Lee, Haochuan Li, Liwei Wang, and Xiyu Zhai.
Gradient descent
ﬁnds global minima of deep neural networks. In International Conference on Machine Learn-
ing, volume 97 of Proceedings of Machine Learning Research, pp. 1675–1685, 2019a. URL
http://proceedings.mlr.press/v97/du19c.html."
REFERENCES,0.46502057613168724,"Simon S. Du, Xiyu Zhai, Barnab´as P´oczos, and Aarti Singh. Gradient descent provably optimizes
over-parameterized neural networks. In International Conference on Learning Representations,
2019b. URL https://openreview.net/forum?id=S1eK3i09YQ."
REFERENCES,0.4670781893004115,"Krishnamurthy Dvijotham,
Sven Gowal,
Robert Stanforth,
Relja Arandjelovic,
Brendan
O’Donoghue, Jonathan Uesato, and Pushmeet Kohli. Training veriﬁed learners with learned ver-
iﬁers. arXiv preprint arXiv:1805.10265, 2018."
REFERENCES,0.4691358024691358,"Ruiqi Gao, Tianle Cai, Haochuan Li, Cho-Jui Hsieh, Liwei Wang, and Jason D. Lee. Convergence of
adversarial training in overparametrized neural networks. In Advances in Neural Information Pro-
cessing Systems, pp. 13009–13020, 2019. URL https://proceedings.neurips.cc/
paper/2019/hash/348a38cd25abeab0e440f37510e9b1fa-Abstract.html."
REFERENCES,0.4711934156378601,"Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. In International Conference on Learning Representations, 2015. URL http://
arxiv.org/abs/1412.6572."
REFERENCES,0.4732510288065844,Published as a conference paper at ICLR 2022
REFERENCES,0.47530864197530864,"Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin, Jonathan Ue-
sato, Timothy Mann, and Pushmeet Kohli. On the effectiveness of interval bound propagation for
training veriﬁably robust models. arXiv preprint arXiv:1810.12715, 2018."
REFERENCES,0.4773662551440329,"Chuan Guo, Mayank Rana, Moustapha Ciss´e, and Laurens van der Maaten. Countering adversarial
images using input transformations. In International Conference on Learning Representations,
2018. URL https://openreview.net/forum?id=SyJ7ClWCb."
REFERENCES,0.4794238683127572,"Arthur Jacot, Cl´ement Hongler, and Franck Gabriel.
Neural tangent kernel: Convergence and
generalization in neural networks. In Advances in Neural Information Processing Systems, pp.
8580–8589, 2018. URL https://proceedings.neurips.cc/paper/2018/hash/
5a4be1fa34e62bb8a6ec6b91d2462f5a-Abstract.html."
REFERENCES,0.48148148148148145,"Ziwei Ji and Matus Telgarsky.
Polylogarithmic width sufﬁces for gradient descent to achieve
arbitrarily small test error with shallow relu networks.
CoRR, abs/1909.12292, 2019.
URL
http://arxiv.org/abs/1909.12292."
REFERENCES,0.4835390946502058,"Nikola Jovanovi´c, Mislav Balunovi´c, Maximilian Baader, and Martin Vechev. Certiﬁed defenses:
Why tighter relaxations may hurt training? arXiv preprint arXiv:2102.06700, 2021."
REFERENCES,0.48559670781893005,"Alexey Kurakin, Ian Goodfellow, and Samy Bengio. Adversarial examples in the physical world.
arXiv preprint arXiv:1607.02533, 2016."
REFERENCES,0.4876543209876543,"Yann LeCun, Corinna Cortes, and CJ Burges. Mnist handwritten digit database. ATT Labs [Online].
Available: http://yann.lecun.com/exdb/mnist, 2, 2010."
REFERENCES,0.4897119341563786,"Sungyoon Lee, Woojin Lee, Jinseong Park, and Jaewook Lee. Loss landscape matters: Training
certiﬁably robust models with favorable loss landscape. OpenReview, 2021."
REFERENCES,0.49176954732510286,"Bai Li, Changyou Chen, Wenlin Wang, and Lawrence Carin. Certiﬁed adversarial robustness with
additive noise. In Advances in Neural Information Processing Systems, pp. 9464–9474, 2019."
REFERENCES,0.49382716049382713,"Yuanzhi Li and Yingyu Liang. Learning overparameterized neural networks via stochastic gra-
dient descent on structured data. In Advances in Neural Information Processing Systems, pp.
8168–8177, 2018. URL https://proceedings.neurips.cc/paper/2018/hash/
54fe976ba170c19ebae453679b362263-Abstract.html."
REFERENCES,0.49588477366255146,"Zhaoyang Lyu, Minghao Guo, Tong Wu, Guodong Xu, Kehuan Zhang, and Dahua Lin. Towards
evaluating and training veriﬁably robust neural networks. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition, pp. 4308–4317, 2021."
REFERENCES,0.49794238683127573,"Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. To-
wards deep learning models resistant to adversarial attacks. In International Conference on Learn-
ing Representations, 2018. URL https://openreview.net/forum?id=rJzIBfZAb."
REFERENCES,0.5,"Matthew Mirman, Timon Gehr, and Martin T. Vechev. Differentiable abstract interpretation for
provably robust neural networks.
In International Conference on Machine Learning, vol-
ume 80 of Proceedings of Machine Learning Research, pp. 3575–3583, 2018.
URL http:
//proceedings.mlr.press/v80/mirman18b.html."
REFERENCES,0.5020576131687243,"Aditi Raghunathan, Jacob Steinhardt, and Percy Liang.
Certiﬁed defenses against adversarial
examples.
In International Conference on Learning Representations, 2018a.
URL https:
//openreview.net/forum?id=Bys4ob-Rb."
REFERENCES,0.5041152263374485,"Aditi Raghunathan, Jacob Steinhardt, and Percy Liang.
Semideﬁnite relaxations for certifying
robustness to adversarial examples.
In Advances in Neural Information Processing Systems,
pp. 10900–10910, 2018b. URL https://proceedings.neurips.cc/paper/2018/
hash/29c0605a3bab4229e46723f89cf59d83-Abstract.html."
REFERENCES,0.5061728395061729,"Hadi Salman, Jerry Li, Ilya P. Razenshteyn, Pengchuan Zhang, Huan Zhang, S´ebastien
Bubeck,
and Greg Yang.
Provably robust deep learning via adversarially trained
smoothed classiﬁers.
In Advances in Neural Information Processing Systems, pp. 11289–
11300,
2019.
URL https://proceedings.neurips.cc/paper/2019/hash/
3a24b25a7b092a252166a1641ae953e7-Abstract.html."
REFERENCES,0.5082304526748971,Published as a conference paper at ICLR 2022
REFERENCES,0.5102880658436214,"Zhouxing Shi, Yihan Wang, Huan Zhang, Jinfeng Yi, and Cho-Jui Hsieh.
Fast certiﬁed robust
training via better initialization and shorter warmup. arXiv preprint arXiv:2103.17268, 2021."
REFERENCES,0.5123456790123457,"Gagandeep Singh, Timon Gehr, Matthew Mirman, Markus P¨uschel, and Martin T. Vechev. Fast
and effective robustness certiﬁcation. In Advances in Neural Information Processing Systems,
pp. 10825–10836, 2018.
URL https://proceedings.neurips.cc/paper/2018/
hash/f2f446980d8e971ef3da97af089481c3-Abstract.html."
REFERENCES,0.51440329218107,"Gagandeep Singh, Timon Gehr, Markus P¨uschel, and Martin Vechev. An abstract domain for certi-
fying neural networks. Proceedings of the ACM on Programming Languages, 3(POPL):41, 2019."
REFERENCES,0.5164609053497943,"Yang Song, Taesup Kim, Sebastian Nowozin, Stefano Ermon, and Nate Kushman. Pixeldefend:
Leveraging generative models to understand and defend against adversarial examples. In Interna-
tional Conference on Learning Representations, 2018. URL https://openreview.net/
forum?id=rJUYGxbCW."
REFERENCES,0.5185185185185185,"Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J. Goodfel-
low, and Rob Fergus. Intriguing properties of neural networks. In International Conference on
Learning Representations, 2014. URL http://arxiv.org/abs/1312.6199."
REFERENCES,0.5205761316872428,"Florian Tramer, Nicholas Carlini, Wieland Brendel, and Aleksander Madry. On adaptive attacks to
adversarial example defenses. arXiv preprint arXiv:2002.08347, 2020."
REFERENCES,0.522633744855967,"Shiqi Wang, Yizheng Chen, Ahmed Abdou, and Suman Jana. Mixtrain: Scalable training of formally
robust neural networks. arXiv preprint arXiv:1811.02625, 2018a."
REFERENCES,0.5246913580246914,"Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana.
Efﬁcient formal
safety analysis of neural networks. In Advances in Neural Information Processing Systems, pp.
6369–6379, 2018b. URL https://proceedings.neurips.cc/paper/2018/hash/
2ecd2bd94734e5dd392d8678bc64cdab-Abstract.html."
REFERENCES,0.5267489711934157,"Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana. Formal security analysis
of neural networks using symbolic intervals. In 27th {USENIX} Security Symposium ({USENIX}
Security 18), pp. 1599–1614, 2018c."
REFERENCES,0.5288065843621399,"Yisen Wang, Xingjun Ma, James Bailey, Jinfeng Yi, Bowen Zhou, and Quanquan Gu.
On the
convergence and robustness of adversarial training.
In International Conference on Machine
Learning, volume 97 of Proceedings of Machine Learning Research, pp. 6586–6595, 2019. URL
http://proceedings.mlr.press/v97/wang19i.html."
REFERENCES,0.5308641975308642,"Zi Wang, Aws Albarghouthi, Gautam Prakriya, and Somesh Jha. Interval universal approximation
for neural networks. arXiv preprint arXiv:2007.06093, 2020."
REFERENCES,0.5329218106995884,"Tsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Luca Daniel, Duane S.
Boning, and Inderjit S. Dhillon. Towards fast computation of certiﬁed robustness for relu net-
works. In International Conference on Machine Learning, volume 80 of Proceedings of Machine
Learning Research, pp. 5273–5282, 2018.
URL http://proceedings.mlr.press/
v80/weng18a.html."
REFERENCES,0.5349794238683128,"Eric Wong and J. Zico Kolter. Provable defenses against adversarial examples via the convex outer
adversarial polytope. In International Conference on Machine Learning, volume 80 of Proceed-
ings of Machine Learning Research, pp. 5283–5292, 2018. URL http://proceedings.
mlr.press/v80/wong18a.html."
REFERENCES,0.5370370370370371,"Eric Wong, Frank R. Schmidt, Jan Hendrik Metzen, and J. Zico Kolter.
Scaling prov-
able adversarial defenses.
In Advances in Neural Information Processing Systems, pp.
8410–8419, 2018. URL https://proceedings.neurips.cc/paper/2018/hash/
358f9e7be09177c17d0d17ff73584307-Abstract.html."
REFERENCES,0.5390946502057613,"Chang Xiao, Peilin Zhong, and Changxi Zheng.
Enhancing adversarial defense by k-winners-
take-all.
In International Conference on Learning Representations, 2020.
URL https:
//openreview.net/forum?id=Skgvy64tvr."
REFERENCES,0.5411522633744856,Published as a conference paper at ICLR 2022
REFERENCES,0.5432098765432098,"Kai Y. Xiao, Vincent Tjeng, Nur Muhammad (Mahi) Shaﬁullah, and Aleksander Madry. Training
for faster adversarial robustness veriﬁcation via inducing relu stability. In International Confer-
ence on Learning Representations, 2019. URL https://openreview.net/forum?id=
BJfIVjAcKm."
REFERENCES,0.5452674897119342,"Kaidi Xu, Zhouxing Shi, Huan Zhang, Yihan Wang, Kai-Wei Chang, Minlie Huang, Bhavya
Kailkhura, Xue Lin, and Cho-Jui Hsieh. Automatic perturbation analysis for scalable certiﬁed
robustness and beyond. Advances in Neural Information Processing Systems, 33, 2020."
REFERENCES,0.5473251028806584,"Bohang Zhang, Tianle Cai, Zhou Lu, Di He, and Liwei Wang. Towards certifying l-inﬁnity ro-
bustness using neural networks with l-inf-dist neurons. In International Conference on Machine
Learning, pp. 12368–12379. PMLR, 2021."
REFERENCES,0.5493827160493827,"Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric P. Xing, Laurent El Ghaoui, and Michael I. Jordan.
Theoretically principled trade-off between robustness and accuracy. In International Conference
on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pp. 7472–7482,
2019. URL http://proceedings.mlr.press/v97/zhang19p.html."
REFERENCES,0.551440329218107,"Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel. Efﬁcient neural net-
work robustness certiﬁcation with general activation functions. In Advances in Neural Information
Processing Systems, pp. 4944–4953, 2018. URL https://proceedings.neurips.cc/
paper/2018/hash/d04863f100d59b3eb688a11f95b0ae60-Abstract.html."
REFERENCES,0.5534979423868313,"Huan Zhang, Hongge Chen, Chaowei Xiao, Sven Gowal, Robert Stanforth, Bo Li, Duane S. Boning,
and Cho-Jui Hsieh. Towards stable and efﬁcient training of veriﬁably robust neural networks. In
International Conference on Learning Representations, 2020a. URL https://openreview.
net/forum?id=Skxuk1rFwB."
REFERENCES,0.5555555555555556,"Yi Zhang, Orestis Plevrakis, Simon S Du, Xingguo Li, Zhao Song, and Sanjeev Arora.
Over-
parameterized adversarial training: An analysis overcoming the curse of dimensionality. arXiv
preprint arXiv:2002.06668, 2020b."
REFERENCES,0.5576131687242798,"Difan Zou, Yuan Cao, Dongruo Zhou, and Quanquan Gu. Stochastic gradient descent optimizes
over-parameterized deep relu networks. arXiv preprint arXiv:1811.08888, 2018."
REFERENCES,0.5596707818930041,"Difan Zou, Spencer Frei, and Quanquan Gu. Provable robustness of adversarial training for learning
halfspaces with noise. arXiv preprint arXiv:2104.09437, 2021."
REFERENCES,0.5617283950617284,Published as a conference paper at ICLR 2022
REFERENCES,0.5637860082304527,"A
PROOF OF LEMMAS"
REFERENCES,0.565843621399177,"A.1
PROOF OF LEMMA 1"
REFERENCES,0.5679012345679012,"Proof. For all i ∈[n], r ∈[m], we ﬁrst consider the change of indicator 1(wr(t)⊤xi±ϵ∥wr(t)∥1 >
0) during training compared to the value at t = 0 (the notation ± here means the analysis is consis-
tent for both + and −cases). Under the constraint that ∥wr(t)±wr(0)∥2 ≤R and ∥xi∥∞∈[0, 1]d,
we have (see Appendix B.2 for details):
wr(t)⊤xi ± ϵ∥wr(t)∥1 −(wr(0)⊤xi ± ϵ∥wr(0)∥1)
 ≤(1 + ϵ)
√"
REFERENCES,0.5699588477366255,"dR.
(15)"
REFERENCES,0.5720164609053497,"Thereby, if sign(wr(t)⊤xi ± ϵ∥wr(t)∥1) ̸= sign(wr(0)⊤xi ± ϵ∥wr(0)∥1), then at initialization,
we must have"
REFERENCES,0.5740740740740741,"|wr(0)⊤xi ± ϵ∥wr(0)∥1| ≤(1 + ϵ)
√"
REFERENCES,0.5761316872427984,"dR.
(16)"
REFERENCES,0.5781893004115226,"We want to upper bound the probability that Eq. (16) holds. It is easy to show that if the following
two inequalities hold, then Eq. (16) does not hold for sure:"
REFERENCES,0.5802469135802469,"|wr(0)⊤xi| ≥2(1 + ϵ)
√"
REFERENCES,0.5823045267489712,"dR,
(17)"
REFERENCES,0.5843621399176955,"ϵ∥wr(0)∥1 ≤(1 + ϵ)
√"
REFERENCES,0.5864197530864198,"dR.
(18)"
REFERENCES,0.588477366255144,"Therefore,"
REFERENCES,0.5905349794238683,"Pr

|wr(0)⊤xi ± ϵ∥wr(0)∥1| ≤(1 + ϵ)
√ dR
"
REFERENCES,0.5925925925925926,"≤1 −Pr

|wr(0)⊤xi| ≥2(1 + ϵ)
√"
REFERENCES,0.5946502057613169,"dR and ∥wr(0)∥1 ≤(1 + ϵ)
√"
REFERENCES,0.5967078189300411,"dR

."
REFERENCES,0.5987654320987654,"For Eq. (17), by anti-concentration inequality for Gaussian, we have"
REFERENCES,0.6008230452674898,"Pr(|wr(0)⊤xi| ≤2(1 + ϵ)
√"
REFERENCES,0.602880658436214,"dR) ≤4(1 + ϵ)
√ dR
√"
REFERENCES,0.6049382716049383,"2πξ
.
(19)"
REFERENCES,0.6069958847736625,"In other words, with probability at least 1 −4(1 + ϵ)
√"
REFERENCES,0.6090534979423868,"dR/(
√"
REFERENCES,0.6111111111111112,"2πξ), Eq. (17) holds. And for Eq.
(18), by the tail bound of standard Gaussian and union bound, we have"
REFERENCES,0.6131687242798354,"Pr(ϵ∥wr(0)∥1 ≤(1 + ϵ)
√"
REFERENCES,0.6152263374485597,"dR) ≥1 −2d exp

−2(1 + ϵ)2dR2 ϵ2"
REFERENCES,0.6172839506172839,"
.
(20)"
REFERENCES,0.6193415637860082,"Combining Eq. (19) and Eq. (20), Eq. (16) holds with at most the following probability"
REFERENCES,0.6213991769547325,"4(1 + ϵ)
√ dR
√"
REFERENCES,0.6234567901234568,"2πξ
+ 2d exp

−2(1 + ϵ)2dR2 ϵ2"
REFERENCES,0.6255144032921811,"
.
(21)"
REFERENCES,0.6275720164609053,Here we require ϵ to be sufﬁciently small such that
REFERENCES,0.6296296296296297,"(1 + ϵ)
√ dR
√"
REFERENCES,0.6316872427983539,"2πξ
≥d exp

−2(1 + ϵ)2dR2 ϵ2"
REFERENCES,0.6337448559670782,"
(22)"
REFERENCES,0.6358024691358025,and we can solve the inequality to obtain an upper bound for ϵ (detailed in Appendix B.3): ϵ ≤ √
DR,0.6378600823045267,2dR
DR,0.6399176954732511,"log(
q 2πd"
DR,0.6419753086419753,"R ξ)
,
(23)"
DR,0.6440329218106996,"and in this case Eq. (21) holds with probability at least 6
√"
DR,0.6460905349794238,"2πξ (1 + ϵ)
√ dR."
DR,0.6481481481481481,Published as a conference paper at ICLR 2022
DR,0.6502057613168725,"Therefore, we upper bound the probability:"
DR,0.6522633744855967,"Pr

sign(wr(t)⊤xi ± ϵ∥wr(t)∥1) ̸= sign(wr(0)⊤xi ± ϵ∥wr(0)∥1)

≤
6
√"
DR,0.654320987654321,"2πξ (1 + ϵ)
√ dR."
DR,0.6563786008230452,Thereby
DR,0.6584362139917695,"∀i ∈[n], r ∈[m], Pr(A+
ri(t) ̸= A+
ri(0)), Pr(A−
ri(t) ̸= A−
ri(0)) ≤
6
√"
DR,0.6604938271604939,"2πξ (1 + ϵ)
√ dR."
DR,0.6625514403292181,"Note that at least one of A+
ri(t) and A−
ri(t) always remains zero during training, because condition
yiar = 1 in A+
ri(t) and condition yiar = −1 in A−
ri(t) are mutually exclusive. Then"
DR,0.6646090534979424,"Pr(A+
ri(t) + A−
ri(t) ̸= A+
ri(0) + A−
ri(0)) ≤
6
√"
DR,0.6666666666666666,"2πξ (1 + ϵ)
√ dR,"
DR,0.668724279835391,"Pr(A+
ri(t) −A−
ri(t) ̸= A+
ri(0) −A−
ri(0)) ≤
6
√"
DR,0.6707818930041153,"2πξ (1 + ϵ)
√ dR."
DR,0.6728395061728395,"Next we can upper bound the probability that each of αrij(t), βrij(t), γrij(t) (∀i, j ∈[n], r ∈[m])
changes respectively:"
DR,0.6748971193415638,"Pr(αrij(t) ̸= αrij(0)), Pr(βrij(t) ̸= βrij(0)), Pr(γrij(t) ̸= γrij(0)) ≤
12
√"
DR,0.676954732510288,"2πξ (1 + ϵ)
√ dR."
DR,0.6790123456790124,"A.2
PROOF OF LEMMA 2"
DR,0.6810699588477366,"Proof. With Lemma 1, we can bound the expectation of the change for each element in H(t) (Eq.
(6)) as:"
DR,0.6831275720164609,E[|Hij(t) −Hij(0)|] ≤1
DR,0.6851851851851852,"mE

m ˜R∥xi∥2∥xj∥2 + ϵm ˜R
 
(∥xi∥2 + ∥xj∥2)∥sign(wr(t))∥2

+ ϵ2dm ˜R
"
DR,0.6872427983539094,≤˜Rd(1 + 2ϵ + ϵ2)
DR,0.6893004115226338,= 12(1 + ϵ)(1 + 2ϵ + ϵ2)d1.5 √
DR,0.691358024691358,"2π
(∀i, j ∈[n])"
DR,0.6934156378600823,"Then by Markov’s inequality, we have that with probability at least 1 −δ,"
DR,0.6954732510288066,"∥H(t) −H(0)∥2 ≤
X"
DR,0.6975308641975309,"i∈[n],j∈[n]
|Hij(t) −Hij(0)| ≤12(1 + ϵ)(1 + 2ϵ + ϵ2)d1.5n2 √"
DR,0.6995884773662552,"2πξδ
R."
DR,0.7016460905349794,"A.3
PROOF OF LEMMA 3"
DR,0.7037037037037037,"Proof. First for simplicity, we deﬁne ρi = −A+
ri(0) + A−
ri(0) (ρi ∈{−1, 0, 1}), and"
DR,0.7057613168724279,"φ(xi)(wr(0)) = yi

xi + ϵρi sign(wr(0)

1

wr(0)⊤
xi + ϵρi sign(wr(0))

> 0

."
DR,0.7078189300411523,"To prove that λ0 > 0, similar as Theorem 3.1 in Du et al. (2019b), we need to prove that for any
r ∈[m], if η1, η2, ..., ηn (∀i ∈[n], ηi ∈R) satisfy Pn
i=1 ηiφ(xi)(wr(0)) = 0 almost everywhere
(a.e.) for any wr(0), we have ∀i ∈[n], ηi = 0."
DR,0.7098765432098766,"In Theorem 3.1 in Du et al. (2019b), it is proved that for φ′(xi)(w) = xi1(w⊤xi) (i ∈[n]), when
∀i ̸= j, xi ∦xj holds, for any η1, η2, ..., ηn(∀i ∈[n], ηi ∈R), if n
X"
DR,0.7119341563786008,"i=1
ηiφ′(xi)(wr(0)) = 0,"
DR,0.7139917695473251,Published as a conference paper at ICLR 2022
DR,0.7160493827160493,"then ∀i ∈[n], ηi = 0. For any r ∈[m], by taking ∀i ∈[n], x′
i = xi + ϵρi sign(wr(0)), we
have φ(xi)(wr(0)) = φ′(x′
i)(wr(0)), and it holds that x′
i ∈B∞(xi, ϵ), x′
j ∈B∞(xj, ϵ). Then if
xi ∦xj, ∀i, j, η1, η2, ..., ηn satisfy Pn
i=1 ηiφ′(x′
i)(wr(0)) = 0 a.e., we have ∀i ∈[n], ηi = 0."
DR,0.7181069958847737,"Therefore if ∀i, j ∈[n], i ̸= j, ∀x′
i ∈B∞(xi, ϵ), ∀x′
j ∈B∞(xj, ϵ), x′
i ∦x′
j, if η1, ..., ηn satisfy X"
DR,0.720164609053498,"i
ηiφ(xi)(wr(0)) = 0, then X"
DR,0.7222222222222222,"i
ηiφ′(x′
i)(wr(0)) = 0"
DR,0.7242798353909465,"also holds, and then ∀i ∈[n], ηi = 0."
DR,0.7263374485596708,"A.4
PROOF OF LEMMA 5"
DR,0.7283950617283951,Proof. The lemma can be proved by solving inequality
DR,0.7304526748971193,λmin(H(t)) ≥λmin(H(0)) −12(1 + ϵ)(1 + 2ϵ + ϵ2)d1.5n2 √
DR,0.7325102880658436,"2πξδ
R ≥λ0"
DR,0.7345679012345679,"2 .
(24)"
DR,0.7366255144032922,"According to Lemma 4, λmin(H(0)) ≥3"
DR,0.7386831275720165,"4λ0. And with Eq. (8), in order to ensure λmin(H(t)) ≥λ0"
DR,0.7407407407407407,"2 ,
we can make"
DR,0.742798353909465,12(1 + ϵ)(1 + 2ϵ + ϵ2)d1.5n2 √
DR,0.7448559670781894,"2πξδ
R ≤λ0 4 ."
DR,0.7469135802469136,This yields R ≤ √
DR,0.7489711934156379,"2πξδλ0
48(1 + ϵ)(1 + 2ϵ + ϵ2)d1.5n2 ."
DR,0.7510288065843621,"Note that 0 ≤ϵ ≤1, and thus 1 + ϵ ≤2 and 1 + 2ϵ + ϵ2 ≤4 can be upper bounded by constants
respectively. Then we can take R ≤ √"
DR,0.7530864197530864,"2πξδλ0
384d1.5n2 = cδλ0"
DR,0.7551440329218106,"d1.5n2 ,
where c = √"
DR,0.757201646090535,"2πξ
384 ,"
DR,0.7592592592592593,and in this case λmin(H(t)) ≥λ0
DR,0.7613168724279835,2 w.p. at least 1 −δ probability.
DR,0.7633744855967078,"A.5
PROOF OF LEMMA 6"
DR,0.7654320987654321,"Proof. The proof of this lemma is inspired by the proof of Lemma 5.4 in Zou et al. (2018). In our
proof, we deﬁne f(x) = (f(x1), f(x2), ..., f(xn)), where f(x) is a scalar function and x is a vector
of length n. When λmin(H)(s) ≥λ0"
DR,0.7674897119341564,"2 holds for 0 ≤s ≤t, we can bound the derivative of L(t):"
DR,0.7695473251028807,"Published as a conference paper at ICLR 2022 dL(u) dt
= n
X"
DR,0.7716049382716049,"i=1
l′(ui)∂ui ∂t = − n
X"
DR,0.7736625514403292,"i=1
l′(ui) n
X"
DR,0.7757201646090535,"j=1
l′(uj)Hij"
DR,0.7777777777777778,= −l′(u)⊤Hl′(u)
DR,0.779835390946502,"(i)
≤−λ0 2 n
X"
DR,0.7818930041152263,"i=1
l′(ui)2"
DR,0.7839506172839507,"(ii)
≤λ0 2 n
X"
DR,0.7860082304526749,"i=1
l′(ui)"
DR,0.7880658436213992,"(iii)
≤−λ0 2 n
X"
DR,0.7901234567901234,"i=1
min(1/2, l(ui) 2
)"
DR,0.7921810699588477,"(iv)
≤−λ0"
MIN,0.7942386831275721,"2 min

1/2, n
X i=1 l(ui) 2  = −λ0"
MIN,0.7962962962962963,"2 min(1/2, L(u) 2
)"
MIN,0.7983539094650206,"(v)
≤−λ0"
MIN,0.8004115226337448,"2
1
2 + 2/L(u),"
MIN,0.8024691358024691,"where (i) is due to λmin(H) ≥λ0, (ii) is due to −l′(u) ≤1, (iii) holds due to the following property
of cross entropy loss −l′(u) ≥min(1/2, l(u)"
MIN,0.8045267489711934,"2 ), (iv) holds due to the function min(1/2, x) is a
concave function and Jenson’s inequality, (v) holds due to min(a, b) ≥
1
1/a+1/b"
MIN,0.8065843621399177,"Therefore, we have"
MIN,0.808641975308642,2dL(u)
MIN,0.8106995884773662,"dt
+
2
L(u)
dL(u)"
MIN,0.8127572016460906,"dt
≤−λ0 2 ."
MIN,0.8148148148148148,"By integration on both sides from 0 to t, we have"
MIN,0.8168724279835391,"L(u(t)) −L(u(0)) + log
"
MIN,0.8189300411522634,"L(u(t))

−log
"
MIN,0.8209876543209876,"L(u(0))

≤−λ0t 4 ."
MIN,0.823045267489712,"Therefore, we have log
"
MIN,0.8251028806584362,"L(u(t))

≤−λ0t"
MIN,0.8271604938271605,"4 + L(u(0)) + log
"
MIN,0.8292181069958847,"L(u(0))

,"
MIN,0.831275720164609,which yields
MIN,0.8333333333333334,"L(u(t)) ≤exp

−λ0t 4"
MIN,0.8353909465020576,"
exp
"
MIN,0.8374485596707819,"L(u(0))
"
MIN,0.8395061728395061,L(u(0)).
MIN,0.8415637860082305,"And we can bound the change of wr.

dwr(t) dt"
MIN,0.8436213991769548,"2
=

dL(t) dwr 2 = n
X"
MIN,0.845679012345679,"i=1
l′(ui) 1
√maryiσ′(⟨wr, xi ± ϵ∥wr∥1⟩)(xi ± ϵ∥wr∥1)

2"
MIN,0.8477366255144033,"≤
1
√m n
X"
MIN,0.8497942386831275,"i=1
∥l′(ui)∥2"
MIN,0.8518518518518519,"≤
n
√m,"
MIN,0.8539094650205762,Published as a conference paper at ICLR 2022
MIN,0.8559670781893004,where σ′(·) stands for the derivative of the ReLU activation. Thus
MIN,0.8580246913580247,"∥wr(t) −wr(0)∥2 ≤nt
√m."
MIN,0.8600823045267489,"A.6
PROOF OF LEMMA 7"
MIN,0.8621399176954733,Proof. We ﬁrst prove the standard training part. As we have deﬁned previously that
MIN,0.8641975308641975,"L(0) = n
X"
MIN,0.8662551440329218,"i=1
log(1 + exp(−ui(0))), where"
MIN,0.8683127572016461,"ui(0) = yi
1
√m m
X"
MIN,0.8703703703703703,"r=1
arσ(wr(0)⊤xi)."
MIN,0.8724279835390947,"For each arσ(wr(0)⊤xi), r ∈[m], i ∈[n], note that the randomness only comes from random
initialization for wr, there is 1"
MIN,0.8744855967078189,"2 possibility that it is equal to 0, and another 1"
POSSIBILITY THAT IT,0.8765432098765432,"2 possibility that it
follows a normal distribution N(0, σ2
i ), where σi = ∥xi∥2
2. Therefore, we have"
POSSIBILITY THAT IT,0.8786008230452675,"E(arσ(wr(0)⊤xi)) = 0,"
POSSIBILITY THAT IT,0.8806584362139918,"Var(arσ(wr(0)⊤xi)) = σ2
i
2 ,"
POSSIBILITY THAT IT,0.8827160493827161,"E
 1
√m m
X"
POSSIBILITY THAT IT,0.8847736625514403,"r=1
arσ(wr(0)⊤xi)

= 0,"
POSSIBILITY THAT IT,0.8868312757201646,"Var
 1
√m m
X"
POSSIBILITY THAT IT,0.8888888888888888,"r=1
arσ(wr(0)⊤xi)

= σ2
i
2 ."
POSSIBILITY THAT IT,0.8909465020576132,"Therefore, by Chebyshev’s inequality, we can bound"
POSSIBILITY THAT IT,0.8930041152263375,"Pr(|ui(0)| ≤σ2
i
2δ ) ≥1 −δ."
POSSIBILITY THAT IT,0.8950617283950617,"And we can bound L(0) = O( n maxn
i=1 σ2
i
2δ
) = O( n"
POSSIBILITY THAT IT,0.897119341563786,δ ) with probability at least 1 −δ.
POSSIBILITY THAT IT,0.8991769547325102,"For IBP training,"
POSSIBILITY THAT IT,0.9012345679012346,"ui(0) =
1
√m m
X"
POSSIBILITY THAT IT,0.9032921810699589,"r=1
1(yiar = 1)σ
 
wr(0)⊤xi −ϵ∥wr(0)∥1

+ 1(yiar = −1)σ
 
wr(0)⊤xi + ϵ∥wr(0)∥1

. Thus"
POSSIBILITY THAT IT,0.9053497942386831,"|ui(0) −ui(0)| ≤
1
√mmϵ∥wr(0)∥1 = √mϵ∥wr(0)∥1."
POSSIBILITY THAT IT,0.9074074074074074,"By E(∥wr∥1) = O(d) and Markov’s inequality, with probability at least 1 −δ,"
POSSIBILITY THAT IT,0.9094650205761317,"|ui(0) −ui(0)| ≤O(
√mdϵ δ
)."
POSSIBILITY THAT IT,0.911522633744856,"And we can bound L(0) = O( n√mdϵ δ
+ n"
POSSIBILITY THAT IT,0.9135802469135802,δ ) with probability at least 1 −δ.
POSSIBILITY THAT IT,0.9156378600823045,Published as a conference paper at ICLR 2022
POSSIBILITY THAT IT,0.9176954732510288,"B
DETAILED DERIVATION FOR OTHER EQUATIONS OR INEQUALITIES"
POSSIBILITY THAT IT,0.9197530864197531,"B.1
DERIVATION ON THE DYNAMICS OF ui(t)"
POSSIBILITY THAT IT,0.9218106995884774,"We provide a detailed derivation on the dynamics of ui(t) presented in Eq. (5), which we use Hi(t)
to describe d"
POSSIBILITY THAT IT,0.9238683127572016,dtui(t):
POSSIBILITY THAT IT,0.9259259259259259,"d
dtui(t) = m
X r=1"
POSSIBILITY THAT IT,0.9279835390946503,∂ui(t)
POSSIBILITY THAT IT,0.9300411522633745,"∂wr(t), dwr(t) dt  = m
X r=1"
POSSIBILITY THAT IT,0.9320987654320988,∂ui(t)
POSSIBILITY THAT IT,0.934156378600823,"∂wr(t), −∂L(W(t), a)"
POSSIBILITY THAT IT,0.9362139917695473,"∂wr(t)  = m
X r=1"
POSSIBILITY THAT IT,0.9382716049382716,∂ui(t)
POSSIBILITY THAT IT,0.9403292181069959,"∂wr(t), − n
X"
POSSIBILITY THAT IT,0.9423868312757202,"j=1
l′(uj) ∂uj(t)"
POSSIBILITY THAT IT,0.9444444444444444,"∂wr(t)  = n
X"
POSSIBILITY THAT IT,0.9465020576131687,"j=1
−l′(uj) m
X r=1"
POSSIBILITY THAT IT,0.948559670781893,∂ui(t)
POSSIBILITY THAT IT,0.9506172839506173,"∂wr(t), ∂uj(t)"
POSSIBILITY THAT IT,0.9526748971193416,"∂wr(t)  = n
X"
POSSIBILITY THAT IT,0.9547325102880658,"j=1
−l′(uj)Hij(t),"
POSSIBILITY THAT IT,0.9567901234567902,"B.2
DERIVATION FOR EQ. (15)"
POSSIBILITY THAT IT,0.9588477366255144,"Eq. (15) basically comes by triangle inequality:
wr(t)⊤xi −ϵ∥wr(t)∥1 −(wr(0)⊤xi −ϵ∥wr(0)∥1)"
POSSIBILITY THAT IT,0.9609053497942387,"=
(wr(t) −wr(0))⊤xi −ϵ∥wr(t)∥1 + ϵ∥wr(0)∥1"
POSSIBILITY THAT IT,0.9629629629629629,"≤|(wr(t) −wr(0))⊤xi| + ϵ
∥wr(t)∥1 −∥wr(0)∥1"
POSSIBILITY THAT IT,0.9650205761316872,"≤|(wr(t) −wr(0))⊤xi| + ϵ
wr(t) −wr(0)

1
≤(1 + ϵ)
√ dR."
POSSIBILITY THAT IT,0.9670781893004116,"B.3
DERIVATION FOR EQ. (23)"
POSSIBILITY THAT IT,0.9691358024691358,"We solve the inequality in Eq. (22) to derive an upper bound for ϵ in Eq. (23): 1
√"
POSSIBILITY THAT IT,0.9711934156378601,"2πξ (1 + ϵ)
√"
POSSIBILITY THAT IT,0.9732510288065843,"dR ≥
1
√ 2πξ √"
POSSIBILITY THAT IT,0.9753086419753086,"dR ≥d exp

−2(1 + ϵ)2dR2 ϵ2 
, R
√"
POSSIBILITY THAT IT,0.977366255144033,"2πdξ
≥exp

−2(1 + ϵ)2dR2 ϵ2 
,"
POSSIBILITY THAT IT,0.9794238683127572,"log

R
√ 2πdξ"
POSSIBILITY THAT IT,0.9814814814814815,"
≥−2(1 + ϵ)2dR2 ϵ2
,"
POSSIBILITY THAT IT,0.9835390946502057,and then we can require
POSSIBILITY THAT IT,0.98559670781893,"log

R
√ 2πdξ"
POSSIBILITY THAT IT,0.9876543209876543,"
≥−2dR2"
POSSIBILITY THAT IT,0.9897119341563786,"ϵ2
≥−2(1 + ϵ)2dR2"
POSSIBILITY THAT IT,0.9917695473251029,"ϵ2
⇒ϵ ≤ √"
DR,0.9938271604938271,2dR
DR,0.9958847736625515,"log(
q 2πd"
DR,0.9979423868312757,"R ξ)
."
