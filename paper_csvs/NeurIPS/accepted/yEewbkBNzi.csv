Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0011876484560570072,"In this paper, we provide a rigorous proof of convergence of the Adaptive Moment
Estimate (Adam) algorithm for a wide class of optimization objectives. Despite the
popularity and efficiency of the Adam algorithm in training deep neural networks,
its theoretical properties are not yet fully understood, and existing convergence
proofs require unrealistically strong assumptions, such as globally bounded gra-
dients, to show the convergence to stationary points. In this paper, we show that
Adam provably converges to œµ-stationary points with O(œµ‚àí4) gradient complexity
under far more realistic conditions. The key to our analysis is a new proof of bound-
edness of gradients along the optimization trajectory of Adam, under a generalized
smoothness assumption according to which the local smoothness (i.e., Hessian
norm when it exists) is bounded by a sub-quadratic function of the gradient norm.
Moreover, we propose a variance-reduced version of Adam with an accelerated
gradient complexity of O(œµ‚àí3)."
INTRODUCTION,0.0023752969121140144,"1
Introduction"
INTRODUCTION,0.0035629453681710215,"In this paper, we study the non-convex unconstrained stochastic optimization problem"
INTRODUCTION,0.004750593824228029,"min
x {f(x) = EŒæ [f(x, Œæ)]} .
(1)"
INTRODUCTION,0.0059382422802850355,"The Adaptive Moment Estimation (Adam) algorithm [23] has become one of the most popular
optimizers for solving (1) when f is the loss for training deep neural networks. Owing to its efficiency
and robustness to hyper-parameters, it is widely applied or even sometimes the default choice in many
machine learning application domains such as natural language processing [44; 4; 13], generative
adversarial networks [35; 21; 55], computer vision [14], and reinforcement learning [28; 33; 40]. It
is also well known that Adam significantly outperforms stochastic gradient descent (SGD) for certain
models like transformer [50; 24; 1]."
INTRODUCTION,0.007125890736342043,"Despite its success in practice, theoretical analyses of Adam are still limited. The original proof
of convergence in [23] was later shown by [37] to contain gaps. The authors in [37] also showed
that for a range of momentum parameters chosen independently with the problem instance, Adam
does not necessarily converge even for convex objectives. However, in deep learning practice, the
hyper-parameters are in fact problem-dependent as they are usually tuned after given the problem and
weight initialization. Recently, there have been many works proving the convergence of Adam for
non-convex functions with various assumptions and problem-dependent hyper-parameter choices.
However, these results leave significant room for improvement. For example, [12; 19] prove the
convergence to stationary points assuming the gradients are bounded by a constant, either explicitly
or implicitly. On the other hand, [51; 45] consider weak assumptions, but their convergence results
are still limited. See Section 2 for more detailed discussions of related works."
INTRODUCTION,0.00831353919239905,"To address the above-mentioned gap between theory and practice, we provide a new convergence
analysis of Adam without assuming bounded gradients, or equivalently, Lipschitzness of the objective
function. In addition, we also relax the standard global smoothness assumption, i.e., the Lipschitzness
of the gradient function, as it is far from being satisfied in deep neural network training. Instead, we"
INTRODUCTION,0.009501187648456057,"consider a more general, relaxed, and non-uniform smoothness condition according to which the
local smoothness (i.e., Hessian norm when it exists) around x is bounded by a sub-quadratic function
of the gradient norm ‚à•‚àáf(x)‚à•(see Definition 3.2 and Assumption 2 for the details). This generalizes
the (L0, L1) smoothness condition proposed by [49] based on language model experiments. Even
though our assumptions are much weaker and more realistic, we can still obtain the same O(œµ‚àí4)
gradient complexity for convergence to an œµ-stationary point."
INTRODUCTION,0.010688836104513063,"The key to our analysis is a new technique to obtain a high probability, constant upper bound on the
gradients along the optimization trajectory of Adam, without assuming Lipschitzness of the objective
function. In other words, it essentially turns the bounded gradient assumption into a result that can be
directly proven. Bounded gradients imply bounded stepsize at each step, with which the analysis of
Adam essentially reduces to the simpler analysis of AdaBound [31]. Furthermore, once the gradient
boundedness is achieved, the analysis under the generalized non-uniform smoothness assumption is
not much harder than that under the standard smoothness condition. We will introduce the technique
in more details in Section 5. We note that the idea of bounding gradient norm along the trajectory of
the optimization algorithm can be use in other problems as well. For more details, we refer the reader
to our concurrent work [26] in which we present a set of new techiniques and methods for bounding
gradient norm for other optimization algorithms under a generalized smoothness condition."
INTRODUCTION,0.011876484560570071,"Another contribution of this paper is to show that the gradient complexity of Adam can be further
improved with variance reduction methods. To this end, we propose a variance-reduced version of
Adam by modifying its momentum update rule, inspired by the idea of the STORM algorithm [9].
Under additional generalized smoothness assumption of the component function f(¬∑, Œæ) for each Œæ,
we show that this provably accelerates the convergence with a gradient complexity of O(œµ‚àí3). This
rate improves upon the existing result of [47] where the authors obtain an asymptotic convergence of
their approach to variance reduction for Adam in the non-convex setting, under the bounded gradient
assumption."
CONTRIBUTIONS,0.013064133016627079,"1.1
Contributions"
CONTRIBUTIONS,0.014251781472684086,"In light of the above background, we summarize our main contributions as follows."
CONTRIBUTIONS,0.015439429928741092,"‚Ä¢ We develop a new analysis to show that Adam converges to stationary points under relaxed
assumptions. In particular, we do not assume bounded gradients or Lipschitzness of the
objective function. Furthermore, we also consider a generalized non-uniform smoothness
condition where the local smoothness or Hessian norm is bounded by a sub-quadratic
function of the gradient norm. Under these more realistic assumptions, we obtain a dimension
free gradient complexity of O(œµ‚àí4) if the gradient noise is centered and bounded.
‚Ä¢ We generalize our analysis to the setting where the gradient noise is centered and has
sub-Gaussian norm, and show the convergence of Adam with a gradient complexity of
O(œµ‚àí4 log3.25(1/œµ)).
‚Ä¢ We propose a variance-reduced version of Adam (VRAdam) with provable convergence
guarantees. In particular, we obtain the accelerated O(œµ‚àí3) gradient complexity."
RELATED WORK,0.0166270783847981,"2
Related work"
RELATED WORK,0.017814726840855107,"In this section, we discuss the relevant literature related to convergence of Adam and the generalized
smoothness condition, and defer additional related work on variants of Adam and variance reduction
methods to Appendix A."
RELATED WORK,0.019002375296912115,"Convergence of Adam. Adam was first proposed by Kingma and Ba [23] with a theoretical
convergence guarantee for convex functions. However, Reddi et al. [37] found a gap in the proof of
this convergence analysis, and also constructed counter-examples for a range of hyper-parameters
on which Adam does not converge. That being said, the counter-examples depend on the hyper-
parameters of Adam, i.e., they are constructed after picking the hyper-parameters. Therefore, it
does not rule out the possibility of obtaining convergence guarantees for problem-dependent hyper-
parameters, as also pointed out by [42; 51]."
RELATED WORK,0.020190023752969122,"Many recent works have developed convergence analyses of Adam with various assumptions and
hyper-parameter choices. Zhou et al. [54] show Adam with certain hyper-parameters can work on
the counter-examples of [37]. De et al. [10] prove convergence for general non-convex functions"
RELATED WORK,0.021377672209026127,"assuming gradients are bounded and the signs of stochastic gradients are the same along the trajectory.
The analysis in [12] also relies on the bounded gradient assumption. Guo et al. [19] assume the
adaptive stepsize is upper and lower bounded by two constants, which is not necessarily satisfied
unless assuming bounded gradients or considering the AdaBound variant [31]. [51; 45] consider
very weak assumptions. However, they show either 1) ‚Äúconvergence‚Äù only to some neighborhood
of stationary points with a constant radius, unless assuming the strong growth condition; or 2)
convergence to stationary points but with a slower rate."
RELATED WORK,0.022565320665083134,"Generalized smoothness condition. Generalizing the standard smoothness condition in a variety of
settings has been a focus of many recent papers. Recently, [49] proposed a generalized smoothness
condition called (L0, L1) smoothness, which assumes the local smoothness or Hessian norm is
bounded by an affine function of the gradient norm. The assumption was well-validated by extensive
experiments conducted on language models. Various analyses of different algorithms under this
condition were later developed [48; 34; 52; 17; 38; 8]. One recent closely-related work is [45] which
studies converges of Adam under the (L0, L1) smoothness condition. However, their results are still
limited, as we have mentioned above. In this paper, we consider an even more general smoothness
condition where the local smoothness is bounded by a sub-quadratic function of the gradient norm,
and prove the convergence of Adam under this condition. In our concurrent work [26], we further
analyze various other algorithms in both convex and non-convex settings under similar generalized
smoothness conditions following the same key idea of bounding gradients along the trajectory."
PRELIMINARIES,0.023752969121140142,"3
Preliminaries"
PRELIMINARIES,0.02494061757719715,"Notation. Let ‚à•¬∑‚à•denote the Euclidean norm of a vector or spectral norm of a matrix. For any given
vector x, we use (x)i to denote its i-th coordinate and x2, ‚àöx, |x| to denote its coordinate-wise
square, square root, and absolute value respectively. For any two vectors x and y, we use x ‚äôy
and x/y to denote their coordinate-wise product and quotient respectively. We also write x ‚™Øy
or x ‚™∞y to denote the coordinate-wise inequality between x and y, which means (x)i ‚â§(y)i or
(x)i ‚â•(y)i for each coordinate index i. For two symmetric real matrices A and B, we say A ‚™ØB or
A ‚™∞B if B ‚àíA or A ‚àíB is positive semi-definite (PSD). Given two real numbers a, b ‚ààR, we
denote a ‚àßb := min{a, b} for simplicity. Finally, we use O(¬∑), Œò(¬∑), and ‚Ñ¶(¬∑) for the standard big-O,
big-Theta, and big-Omega notation."
DESCRIPTION OF THE ADAM ALGORITHM,0.026128266033254157,"3.1
Description of the Adam algorithm"
DESCRIPTION OF THE ADAM ALGORITHM,0.027315914489311165,Algorithm 1 ADAM
DESCRIPTION OF THE ADAM ALGORITHM,0.028503562945368172,"1: Input: Œ≤, Œ≤sq, Œ∑, Œª, T, xinit
2: Initialize m0 = v0 = 0 and x1 = xinit
3: for t = 1, ¬∑ ¬∑ ¬∑ , T do
4:
Draw a new sample Œæt and perform the following updates
5:
mt = (1 ‚àíŒ≤)mt‚àí1 + Œ≤‚àáf(xt, Œæt)
6:
vt = (1 ‚àíŒ≤sq)vt‚àí1 + Œ≤sq(‚àáf(xt, Œæt))2"
DESCRIPTION OF THE ADAM ALGORITHM,0.029691211401425176,"7:
ÀÜmt =
mt
1‚àí(1‚àíŒ≤)t
8:
ÀÜvt =
vt
1‚àí(1‚àíŒ≤sq)t
9:
xt+1 = xt ‚àí
Œ∑
‚àöÀÜvt+Œª ‚äôÀÜmt
10: end for"
DESCRIPTION OF THE ADAM ALGORITHM,0.030878859857482184,"The formal definition of Adam proposed in [23] is shown in Algorithm 1, where Lines 5‚Äì9 describe
the update rule of iterates {xt}1‚â§t‚â§T . Lines 5‚Äì6 are the updates for the first and second order
momentum, mt and vt, respectively. In Lines 7‚Äì8, they are re-scaled to ÀÜmt and ÀÜvt in order to correct
the initialization bias due to setting m0 = v0 = 0. Then the iterate is updated by xt+1 = xt‚àíht‚äôÀÜmt
where ht = Œ∑/(‚àöÀÜvt + Œª) is the adaptive stepsize vector for some parameters Œ∑ and Œª."
ASSUMPTIONS,0.032066508313539195,"3.2
Assumptions"
ASSUMPTIONS,0.0332541567695962,"In what follows below, we will state our main assumptions for analysis of Adam."
FUNCTION CLASS,0.0344418052256532,"3.2.1
Function class"
FUNCTION CLASS,0.035629453681710214,"We start with a standard assumption in optimization on the objective function f whose domain lies in
a Euclidean space with dimension d."
FUNCTION CLASS,0.03681710213776722,"Assumption 1. The objective function f is differentiable and closed within its open domain
dom(f) ‚äÜRd and is bounded from below, i.e., f ‚àó:= infx f(x) > ‚àí‚àû.
Remark 3.1. A function f is said to be closed if its sub-level set {x ‚ààdom(f) | f(x) ‚â§a} is closed
for each a ‚ààR. In addition, a continuous function f over an open domain is closed if and only f(x)
tends to infinity whenever x approaches to the boundary of dom(f), which is an important condition
to ensure the iterates of Adam with a small enough stepsize Œ∑ stay within the domain with high
probability. Note that this condition is mild since any continuous function defined over the entire
space Rd is closed."
FUNCTION CLASS,0.03800475059382423,"Besides Assumption 1, the only additional assumption we make regarding f is that its local smooth-
ness is bounded by a sub-quadratic function of the gradient norm. More formally, we consider the
following (œÅ, L0, LœÅ) smoothness condition with 0 ‚â§œÅ < 2.
Definition 3.2. A differentiable real-valued function f is (œÅ, L0, LœÅ) smooth for some constants
œÅ, L0, LœÅ ‚â•0 if the following inequality holds almost everywhere in dom(f)
‚àá2f(x)
 ‚â§L0 + LœÅ ‚à•‚àáf(x)‚à•œÅ ."
FUNCTION CLASS,0.039192399049881234,"Remark 3.3. When œÅ = 1 , Definition 3.2 reduces to the (L0, L1) smoothness condition in [49].
When œÅ = 0 or LœÅ = 0, it reduces to the standard smoothness condition.
Assumption 2. The objective function f is (œÅ, L0, LœÅ) smooth with 0 ‚â§œÅ < 2."
FUNCTION CLASS,0.040380047505938245,"The standard smooth function class is very restrictive as it only contains functions that are upper
and lower bounded by quadratic functions. The (L0, L1) smooth function class is more general
since it also contains, e.g., univariate polynomials and exponential functions. Assumption 2 is even
more general and contains univariate rational functions, double exponential functions, etc. See
Appendix D.1 for the formal propositions and proofs. We also refer the reader to our concurrent
work [26] for more detailed discussions of examples of (œÅ, L0, LœÅ) smooth functions for different œÅs."
FUNCTION CLASS,0.04156769596199525,"It turns out that bounded Hessian norm at a point x implies local Lipschitzness of the gradient in the
neighborhood around x. In particular, we have the following lemma.
Lemma 3.4. Under Assumptions 1 and 2, for any a > 0 and two points x ‚ààdom(f), y ‚ààRd such
that ‚à•y ‚àíx‚à•‚â§
a
L0+LœÅ(‚à•‚àáf(x)‚à•+a)œÅ , we have y ‚ààdom(f) and"
FUNCTION CLASS,0.04275534441805225,‚à•‚àáf(y) ‚àí‚àáf(x)‚à•‚â§(L0 + LœÅ(‚à•‚àáf(x)‚à•+ a)œÅ) ¬∑ ‚à•y ‚àíx‚à•.
FUNCTION CLASS,0.043942992874109264,"Remark 3.5. Lemma 3.4 can be actually used as the definition of (œÅ, L0, LœÅ) smooth functions in
place of Assumption 2. Besides the local gradient Lipschitz condition, it also suggests that, as long
as the update at each step is small enough, the iterates will not go outside of the domain."
FUNCTION CLASS,0.04513064133016627,"For the special case of œÅ = 1, choosing a = max{‚à•‚àáf(x)‚à•, L0/L1}, one can verify that the required
locality size in Lemma 3.4 satisfies
a
L0+L1(‚à•‚àáf(x)‚à•+a) ‚â•
1
3L1 . In this case, Lemma 3.4 states that
‚à•x ‚àíy‚à•‚â§1/(3L1) implies ‚à•‚àáf(y) ‚àí‚àáf(x)‚à•‚â§2(L0 + L1 ‚à•‚àáf(x)‚à•) ‚à•y ‚àíx‚à•. Therefore, it
reduces to the local gradient Lipschitz condition for (L0, L1) smooth functions in [49; 48] up to
numerical constant factors. For œÅ Ã∏= 1, the proof is more involved because Gr√∂nwall‚Äôs inequality used
in [49; 48] no longer applies. Therefore we defer the detailed proof of Lemma 3.4 to Appendix D.2."
STOCHASTIC GRADIENT,0.04631828978622328,"3.2.2
Stochastic gradient"
STOCHASTIC GRADIENT,0.047505938242280284,"We consider one of the following two assumptions on the stochastic gradient ‚àáf(xt, Œæt) in our
analysis of Adam.
Assumption 3. The gradient noise is centered and almost surely bounded. In particular, for some
œÉ ‚â•0 and all t ‚â•1,"
STOCHASTIC GRADIENT,0.048693586698337295,"Et‚àí1[‚àáf(xt, Œæt)] = ‚àáf(xt),
‚à•‚àáf(xt, Œæt) ‚àí‚àáf(xt)‚à•‚â§œÉ, a.s.,"
STOCHASTIC GRADIENT,0.0498812351543943,"where Et‚àí1[ ¬∑ ] := E[ ¬∑ |Œæ1, . . . , Œæt‚àí1] is the conditional expectation given Œæ1, . . . , Œæt‚àí1.
Assumption 4. The gradient noise is centered with sub-Gaussian norm. In particular, for some
R ‚â•0 and all t ‚â•1,"
STOCHASTIC GRADIENT,0.0510688836104513,"Et‚àí1[‚àáf(xt, Œæt)] = ‚àáf(xt),
Pt‚àí1 (‚à•‚àáf(xt, Œæt) ‚àí‚àáf(xt)‚à•‚â•s) ‚â§2e‚àís2"
STOCHASTIC GRADIENT,0.052256532066508314,"2R2 , ‚àÄs ‚ààR,"
STOCHASTIC GRADIENT,0.05344418052256532,"where Et‚àí1[ ¬∑ ] := E[ ¬∑ |Œæ1, . . . , Œæt‚àí1] and Pt‚àí1[ ¬∑ ] := P[ ¬∑ |Œæ1, . . . , Œæt‚àí1] are the conditional expecta-
tion and probability given Œæ1, . . . , Œæt‚àí1."
STOCHASTIC GRADIENT,0.05463182897862233,"Assumption 4 is strictly weaker than Assumption 3 since an almost surely bounded random variable
clearly has sub-Gaussian norm, but it results in a slightly worse convergece rate up to poly-log factors
(see Theorems 4.1 and 4.2). Both of them are stronger than the most standard bounded variance
assumption E[‚à•‚àáf(xt, Œæt) ‚àí‚àáf(xt)‚à•2] ‚â§œÉ2 for some œÉ ‚â•0, although Assumption 3 is actually a
common assumption in existing analyses under the (L0, L1) smoothness condition (see e.g. [49; 48]).
The extension to the bounded variance assumption is challenging and a very interesting future work
as it is also the assumption considered in the lower bound [3]. We suspect that such an extension
would be straightforward if we consider a mini-batch version of Algorithm 1 with a batch size of
S = ‚Ñ¶(œµ‚àí2), since this results in a very small variance of O(œµ2) and thus essentially reduces the
analysis to the deterministic setting. However, for practical Adam with an O(1) batch size, the
extension is challenging and we leave it as a future work."
RESULTS,0.055819477434679333,"4
Results"
RESULTS,0.057007125890736345,"In the section, we provide our convergence results for Adam under Assumptions 1, 2, and 3 or 4. To
keep the statements of the theorems concise, we first define several problem-dependent constants.
First, we let ‚àÜ1 := f(x1) ‚àíf ‚àó< ‚àûbe the initial sub-optimality gap. Next, given a large enough
constant G > 0, we define"
RESULTS,0.05819477434679335,"r := min
n
1
5LœÅGœÅ‚àí1 ,
1
5(LœÅ‚àí1
0
LœÅ)1/œÅ
o
,
L := 3L0 + 4LœÅGœÅ,
(2)"
RESULTS,0.05938242280285035,"where L can be viewed as the effective smoothness constant along the trajectory if one can show
‚à•‚àáf(xt)‚à•‚â§G and ‚à•xt+1 ‚àíxt‚à•‚â§r at each step (see Section 5 for more detailed discussions). We
will also use c1, c2 to denote some small enough numerical constants and C1, C2 to denote some
large enough ones. The formal convergence results under Assumptions 1, 2, and 3 are presented in
the following theorem, whose proof is deferred in Appendix E."
RESULTS,0.060570071258907364,"Theorem 4.1. Suppose Assumptions 1, 2, and 3 hold. Denote Œπ := log(1/Œ¥) for any 0 < Œ¥ < 1. Let"
RESULTS,0.06175771971496437,"G be a constant satisfying G ‚â•max
n
2Œª, 2œÉ, ‚àöC1‚àÜ1L0, (C1‚àÜ1LœÅ)
1
2‚àíœÅ
o
. Choose"
RESULTS,0.06294536817102138,"0 ‚â§Œ≤sq ‚â§1,
Œ≤ ‚â§min

1, c1Œªœµ2 œÉ2G‚àöŒπ"
RESULTS,0.06413301662707839,"
,
Œ∑ ‚â§c2 min
rŒª"
RESULTS,0.06532066508313539,"G ,
œÉŒªŒ≤
LG‚àöŒπ,
Œª3/2Œ≤ L
‚àö G 
."
RESULTS,0.0665083135391924,"Let T = max
n
1
Œ≤2 ,
C2‚àÜ1G"
RESULTS,0.06769596199524941,"Œ∑œµ2
o
. Then with probability at least 1‚àíŒ¥, we have ‚à•‚àáf(xt)‚à•‚â§G for every"
RESULTS,0.0688836104513064,"1 ‚â§t ‚â§T, and 1"
RESULTS,0.07007125890736342,"T
PT
t=1 ‚à•‚àáf(xt)‚à•2 ‚â§œµ2."
RESULTS,0.07125890736342043,"Note that G, the upper bound of gradients along the trajectory, is a constant that depends on
Œª, œÉ, L0, LœÅ, and the initial sub-optimality gap ‚àÜ1, but not on œµ. There is no requirement on the
second order momentum parameter Œ≤sq, although many existing works like [12; 51; 45] need certain
restrictions on it. We choose very small Œ≤ and Œ∑, both of which are O(œµ2). Therefore, from the choice
of T, it is clear that we obtain a gradient complexity of O(œµ‚àí4), where we only consider the leading
term. We are not clear whether the dependence on œµ is optimal or not, as the ‚Ñ¶(œµ‚àí4) lower bound in
[3] assumes the weaker bounded variance assumption than our Assumpion 3. However, it matches
the state-of-the-art complexity among existing analyses of Adam."
RESULTS,0.07244655581947744,"One limitation of the dependence of our complexity on Œª is O(Œª‚àí2), which might be large since
Œª is usually small in practice, e.g., the default choice is Œª = 10‚àí8 in the PyTorch implementation.
There are some existing analyses on Adam [12; 51; 45] whose rates do not depend explicitly on Œª or
only depend on log(1/Œª). However, all of them depend on poly(d), whereas our rate is dimension
free. The dimension d is also very large, especially when training transformers, for which Adam is
widely used. We believe that independence on d is better than that on Œª, because d is fixed given the
architecture of the neural network but Œª is a hyper-parameter which we have the freedom to tune. In
fact, based on our preliminary experimental results on CIFAR-10 shown in Figure 1, the performance
of Adam is not very sensitive to the choice of Œª. Although the default choice of Œª is 10‚àí8, increasing
it up to 0.01 only makes minor differences."
RESULTS,0.07363420427553444,"As discussed in Section 3.2.2, we can generalize the bounded gradient noise condition in Assumption 3
to the weaker sub-Gaussian noise condition in Assumption 4. The following theorem formally shows
the convergence result under Assumptions 1, 2, and 4, whose proof is deferred in Appendix E.6."
RESULTS,0.07482185273159145,"0
100
200
300
400 Epoch 0 20 40 60 80"
RESULTS,0.07600950118764846,Test Error (%)
RESULTS,0.07719714964370546,Œª=1e-8
RESULTS,0.07838479809976247,Œª=1e-4
RESULTS,0.07957244655581948,Œª=1e-3
RESULTS,0.08076009501187649,Œª=0.01 Œª=0.1 Œª=1
RESULTS,0.08194774346793349,(a) CNN
RESULTS,0.0831353919239905,"0
100
200
300
400 Epoch 0 20 40 60 80"
RESULTS,0.08432304038004751,Test Error (%)
RESULTS,0.0855106888361045,Œª=1e-8
RESULTS,0.08669833729216152,Œª=1e-4
RESULTS,0.08788598574821853,Œª=1e-3
RESULTS,0.08907363420427554,Œª=0.01 Œª=0.1 Œª=1
RESULTS,0.09026128266033254,(b) ResNet-Small
RESULTS,0.09144893111638955,"0
100
200
300
400 Epoch 0 20 40 60 80"
RESULTS,0.09263657957244656,Test Error (%)
RESULTS,0.09382422802850356,Œª=1e-8
RESULTS,0.09501187648456057,Œª=1e-4
RESULTS,0.09619952494061758,Œª=1e-3
RESULTS,0.09738717339667459,Œª=0.01 Œª=0.1 Œª=1
RESULTS,0.09857482185273159,(c) ResNet110
RESULTS,0.0997624703087886,"Figure 1: Test errors of different models trained on CIFAR-10 using the Adam optimizer with
Œ≤ = 0.9, Œ≤sq = 0.999, Œ∑ = 0.001 and different Œªs. From left to right: (a) a shallow CNN with 6
layers; (b) ResNet-Small with 20 layers; and (c) ResNet110 with 110 layers."
RESULTS,0.10095011876484561,"Theorem 4.2. Suppose Assumptions 1, 2, and 4 hold.
Denote Œπ
:=
log(2/Œ¥) and
œÉ
:=
R
p"
RESULTS,0.1021377672209026,"2 log(4T/Œ¥) for any 0
<
Œ¥
<
1.
Let G be a constant satisfying G
‚â•"
RESULTS,0.10332541567695962,"max
n
2Œª, 2œÉ, ‚àöC1‚àÜ1L0, (C1‚àÜ1LœÅ)
1
2‚àíœÅ
o
. Choose"
RESULTS,0.10451306413301663,"0 ‚â§Œ≤sq ‚â§1,
Œ≤ ‚â§min

1, c1Œªœµ2 œÉ2G‚àöŒπ"
RESULTS,0.10570071258907364,"
,
Œ∑ ‚â§c2 min
rŒª"
RESULTS,0.10688836104513064,"G ,
œÉŒªŒ≤
LG‚àöŒπ,
Œª3/2Œ≤ L
‚àö G 
."
RESULTS,0.10807600950118765,"Let T = max
n
1
Œ≤2 ,
C2‚àÜ1G"
RESULTS,0.10926365795724466,"Œ∑œµ2
o
. Then with probability at least 1‚àíŒ¥, we have ‚à•‚àáf(xt)‚à•‚â§G for every"
RESULTS,0.11045130641330166,"1 ‚â§t ‚â§T, and 1"
RESULTS,0.11163895486935867,"T
PT
t=1 ‚à•‚àáf(xt)‚à•2 ‚â§œµ2."
RESULTS,0.11282660332541568,"Note that the main difference of Theorem 4.2 from Theorem 4.1 is that œÉ is now O(‚àölog T) instead
of a constant. With some standard calculations, one can show that the gradient complexity in
Theorem 4.2 is bounded by O(œµ‚àí4 logp(1/œµ)), where p = max

3, 9+2œÅ"
RESULTS,0.11401425178147269,"4
	
< 3.25."
ANALYSIS,0.11520190023752969,"5
Analysis"
BOUNDING THE GRADIENTS ALONG THE OPTIMIZATION TRAJECTORY,0.1163895486935867,"5.1
Bounding the gradients along the optimization trajectory"
BOUNDING THE GRADIENTS ALONG THE OPTIMIZATION TRAJECTORY,0.11757719714964371,"We want to bound the gradients along the optimization trajectory mainly for two reasons. First, as
discussed in Section 2, many existing analyses of Adam rely on the assumption of bounded gradients,
because unbounded gradient norm leads to unbounded second order momentum ÀÜvt which implies
very small stepsize, and slow convergence. On the other hand, once the gradients are bounded, it is
straightforward to control ÀÜvt as well as the stepsize, and therefore the analysis essentially reduces to
the easier one for AdaBound. Second, informally speaking1, under Assumption 2, bounded gradients
also imply bounded Hessians, which essentially reduces the (œÅ, L0, LœÅ) smoothness to the standard
smoothness. See Section 5.2 for more formal discussions."
BOUNDING THE GRADIENTS ALONG THE OPTIMIZATION TRAJECTORY,0.1187648456057007,"In this paper, instead of imposing the strong assumption of globally bounded gradients, we develop a
new analysis to show that with high probability, the gradients are always bounded along the trajectory
of Adam until convergence. The essential idea can be informally illustrated by the following ‚Äúcircular""
reasoning that we will make precise later. On the one hand, if ‚à•‚àáf(xt)‚à•‚â§G for every t ‚â•1, it is
not hard to show the gradient converges to zero based on our discussions above. On the other hand,
we know that a converging sequence must be upper bounded. Therefore there exists some G‚Ä≤ such
that ‚à•‚àáf(xt)‚à•‚â§G‚Ä≤ for every t ‚â•1. In other words, the bounded gradient condition implies the
convergence result and the convergence result also implies the boundedness condition, forming a
circular argument."
BOUNDING THE GRADIENTS ALONG THE OPTIMIZATION TRAJECTORY,0.11995249406175772,"This circular argument is of course flawed. However, we can break the circularity of reasoning and
rigorously prove both the bounded gradient condition and the convergence result using a contradiction"
THE STATEMENT IS INFORMAL BECAUSE HERE WE CAN ONLY SHOW BOUNDED GRADIENTS AND HESSIANS AT THE ITERATE,0.12114014251781473,"1The statement is informal because here we can only show bounded gradients and Hessians at the iterate
points, which only implies local smoothness near the neighborhood of each iterate point (see Section 5.2).
However, the standard smoothness condition is a stronger global condition which assumes bounded Hessian at
every point within a convex set."
THE STATEMENT IS INFORMAL BECAUSE HERE WE CAN ONLY SHOW BOUNDED GRADIENTS AND HESSIANS AT THE ITERATE,0.12232779097387174,"argument. Before introducing the contradiction argument, we first need to provide the following
useful lemma, which is the reverse direction of a generalized Polyak-Lojasiewicz (PL) inequality,
whose proof is deferred in Appendix D.3."
THE STATEMENT IS INFORMAL BECAUSE HERE WE CAN ONLY SHOW BOUNDED GRADIENTS AND HESSIANS AT THE ITERATE,0.12351543942992874,"Lemma 5.1. Under Assumptions 1 and 2, we have ‚à•‚àáf(x)‚à•2 ‚â§3(3L0+4LœÅ ‚à•‚àáf(x)‚à•œÅ)(f(x)‚àíf ‚àó)."
THE STATEMENT IS INFORMAL BECAUSE HERE WE CAN ONLY SHOW BOUNDED GRADIENTS AND HESSIANS AT THE ITERATE,0.12470308788598575,"Define the function Œ∂(u) :=
u2
3(3L0+4LœÅuœÅ) over u ‚â•0. It is easy to verify that if œÅ < 2, Œ∂ is increasing
and its range is [0, ‚àû). Therefore, Œ∂ is invertible and Œ∂‚àí1 is also increasing. Then, for any constant
G > 0, denoting F = Œ∂(G), Lemma 5.1 suggests that if f(x) ‚àíf ‚àó‚â§F, we have"
THE STATEMENT IS INFORMAL BECAUSE HERE WE CAN ONLY SHOW BOUNDED GRADIENTS AND HESSIANS AT THE ITERATE,0.12589073634204276,‚à•‚àáf(x)‚à•‚â§Œ∂‚àí1(f(x) ‚àíf ‚àó) ‚â§Œ∂‚àí1(F) = G.
THE STATEMENT IS INFORMAL BECAUSE HERE WE CAN ONLY SHOW BOUNDED GRADIENTS AND HESSIANS AT THE ITERATE,0.12707838479809977,"In other words, if œÅ < 2, the gradient is bounded within any sub-level set, even though the sub-level
set could be unbounded. Then, let œÑ be the first time the sub-optimality gap is strictly greater than F,
truncated at T + 1, or formally,"
THE STATEMENT IS INFORMAL BECAUSE HERE WE CAN ONLY SHOW BOUNDED GRADIENTS AND HESSIANS AT THE ITERATE,0.12826603325415678,"œÑ := min{t | f(xt) ‚àíf ‚àó> F} ‚àß(T + 1).
(3)"
THE STATEMENT IS INFORMAL BECAUSE HERE WE CAN ONLY SHOW BOUNDED GRADIENTS AND HESSIANS AT THE ITERATE,0.12945368171021376,"Then at least when t < œÑ, we have f(xt) ‚àíf ‚àó‚â§F and thus ‚à•‚àáf(xt)‚à•‚â§G. Based on our
discussions above, it is not hard to analyze the updates before time œÑ, and one can contruct some
Lyapunov function to obtain an upper bound on f(xœÑ) ‚àíf ‚àó. On the other hand, if œÑ ‚â§T, we
immediately obtain a lower bound on f(xœÑ), that is f(xœÑ) ‚àíf ‚àó> F, by the definition of œÑ in (3). If
the lower bound is greater than the upper bound, it leads to a contradiction, which shows œÑ = T + 1,
i.e., the sub-optimality gap and the gradient norm are always bounded by F and G respectively before
the algorithm terminates. We will illustrate the technique in more details in the simple deterministic
setting in Section 5.3, but first, in Section 5.2, we introduce several prerequisite lemmas on the
(œÅ, L0, LœÅ) smoothness."
LOCAL SMOOTHNESS,0.13064133016627077,"5.2
Local smoothness"
LOCAL SMOOTHNESS,0.13182897862232779,"In Section 5.1, we informally mentioned that (œÅ, L0, LœÅ) smoothness essentially reduces to the
standard smoothness if the gradient is bounded. In this section, we will make the statement more
precise. First, note that Lemma 3.4 implies the following useful corollary.
Corollary 5.2. Under Assumptions 1 and 2, for any G > 0 and two points x ‚ààdom(f), y ‚ààRd"
LOCAL SMOOTHNESS,0.1330166270783848,"such that ‚à•‚àáf(x)‚à•‚â§G and ‚à•y ‚àíx‚à•‚â§r := min
n
1
5LœÅGœÅ‚àí1 ,
1
5(LœÅ‚àí1
0
LœÅ)1/œÅ
o
, denoting L :="
LOCAL SMOOTHNESS,0.1342042755344418,"3L0 + 4LœÅGœÅ, we have y ‚ààdom(f) and"
LOCAL SMOOTHNESS,0.13539192399049882,"‚à•‚àáf(y) ‚àí‚àáf(x)‚à•‚â§L ‚à•y ‚àíx‚à•,
f(y) ‚â§f(x) +

‚àáf(x), y ‚àíx

+ L"
LOCAL SMOOTHNESS,0.13657957244655583,2 ‚à•y ‚àíx‚à•2 .
LOCAL SMOOTHNESS,0.1377672209026128,"The proof of Corollary 5.2 is deferred in Appendix D.4. Although the inequalities in Corollary 5.2
look very similar to the standard global smoothness condition with constant L, it is still a local
condition as it requires ‚à•x ‚àíy‚à•‚â§r. Fortunately, at least before œÑ, such a requirement is easy to
satisfy for small enough Œ∑, according to the following lemma whose proof is deferred in Appendix E.5.
Lemma 5.3. Under Assumption 3, if t < œÑ and choosing G ‚â•œÉ, we have ‚à•xt+1 ‚àíxt‚à•‚â§Œ∑D where
D := 2G/Œª."
LOCAL SMOOTHNESS,0.13895486935866982,"Then as long as Œ∑ ‚â§r/D, we have ‚à•xt+1 ‚àíxt‚à•‚â§r which satisfies the requirement in Corollary 5.2.
Then we can apply the inequalities in it in the same way as the standard smoothness condition. In other
words, most classical inequalities derived for standard smooth functions also apply to (œÅ, L0, LœÅ)
smooth functions."
LOCAL SMOOTHNESS,0.14014251781472684,"5.3
Warm-up: analysis in the deterministic setting"
LOCAL SMOOTHNESS,0.14133016627078385,"In this section, we consider the simpler deterministic setting where the stochastic gradient ‚àáf(xt, Œæt)
in Algorithm 1 or (18) is replaced with the exact gradient ‚àáf(xt). As discussed in Section 5.1, the
key in our contradiction argument is to obtain both upper and lower bounds on f(xœÑ) ‚àíf ‚àó. In the
following derivations, we focus on illustrating the main idea of our analysis technique and ignore
minor proof details. In addition, all of them are under Assumptions 1, 2, and 3."
LOCAL SMOOTHNESS,0.14251781472684086,"In order to obtain the upper bound, we need the following two lemmas. First, denoting œµt :=
ÀÜmt ‚àí‚àáf(xt), we can obtain the following informal descent lemma for deterministic Adam."
LOCAL SMOOTHNESS,0.14370546318289787,"Lemma 5.4 (Descent lemma, informal). For any t < œÑ, choosing G ‚â•Œª and a small enough Œ∑,"
LOCAL SMOOTHNESS,0.14489311163895488,f(xt+1) ‚àíf(xt) ‚™Ö‚àíŒ∑
LOCAL SMOOTHNESS,0.14608076009501186,4G ‚à•‚àáf(xt)‚à•2 + Œ∑
LOCAL SMOOTHNESS,0.14726840855106887,"2Œª ‚à•œµt‚à•2 ,
(4)"
LOCAL SMOOTHNESS,0.14845605700712589,where ‚Äú‚™Ö‚Äù omits less important terms.
LOCAL SMOOTHNESS,0.1496437054631829,"Compared with the standard descent lemma for gradient descent, there is an additional term of ‚à•œµt‚à•2"
LOCAL SMOOTHNESS,0.1508313539192399,"in Lemma 5.4. In the next lemma, we bound this term recursively."
LOCAL SMOOTHNESS,0.15201900237529692,"Lemma 5.5 (Informal). Choosing Œ≤ = Œò(Œ∑GœÅ+1/2), if t < œÑ, we have"
LOCAL SMOOTHNESS,0.15320665083135393,‚à•œµt+1‚à•2 ‚â§(1 ‚àíŒ≤/4) ‚à•œµt‚à•2 + ŒªŒ≤
LOCAL SMOOTHNESS,0.1543942992874109,"16G ‚à•‚àáf(xt)‚à•2 .
(5)"
LOCAL SMOOTHNESS,0.15558194774346792,"The proof sketches of the above two lemmas are deferred in Appendix B. Now we combine them to
get the upper bound on f(xœÑ) ‚àíf ‚àó. Define the function Œ¶t := f(xt) ‚àíf ‚àó+ 2Œ∑"
LOCAL SMOOTHNESS,0.15676959619952494,"ŒªŒ≤ ‚à•œµt‚à•2. Note that for
any t < œÑ, (4)+ 2Œ∑"
LOCAL SMOOTHNESS,0.15795724465558195,ŒªŒ≤ √ó(5) gives
LOCAL SMOOTHNESS,0.15914489311163896,Œ¶t+1 ‚àíŒ¶t ‚â§‚àíŒ∑
LOCAL SMOOTHNESS,0.16033254156769597,"8G ‚à•‚àáf(xt)‚à•2 .
(6)"
LOCAL SMOOTHNESS,0.16152019002375298,"The above inequality shows Œ¶t is non-increasing and thus a Lyapunov function. Therefore, we have"
LOCAL SMOOTHNESS,0.16270783847980996,"f(xœÑ) ‚àíf ‚àó‚â§Œ¶œÑ ‚â§Œ¶1 = ‚àÜ1,"
LOCAL SMOOTHNESS,0.16389548693586697,"where in the last inequality we use Œ¶1 = f(x1) ‚àíf ‚àó= ‚àÜ1 since œµ1 = ÀÜm1 ‚àí‚àáf(x1) = 0 in the
deterministic setting."
LOCAL SMOOTHNESS,0.16508313539192399,"As discussed in Section 5.1, if œÑ ‚â§T, we have F < f(xœÑ) ‚àíf ‚àó‚â§‚àÜ1. Note that we are able to
choose a large enough constant G so that F =
G2
3(3L0+4LœÅGœÅ) is greater than ‚àÜ1, which leads to a
contradiction and shows œÑ = T + 1. Therefore, (6) holds for all 1 ‚â§t ‚â§T. Taking a summation
over 1 ‚â§t ‚â§T and re-arranging terms, we get"
T,0.166270783847981,"1
T T
X"
T,0.167458432304038,"t=1
‚à•‚àáf(xt)‚à•2 ‚â§8G(Œ¶1 ‚àíŒ¶T +1)"
T,0.16864608076009502,"Œ∑T
‚â§8G‚àÜ1"
T,0.16983372921615203,"Œ∑T
‚â§œµ2,"
T,0.171021377672209,if choosing T ‚â•8G‚àÜ1
T,0.17220902612826602,"Œ∑œµ2 , i.e., it shows convergence with a gradient complexity of O(œµ‚àí2) since both
G and Œ∑ are constants independent of œµ in the deterministic setting."
EXTENSION TO THE STOCHASTIC SETTING,0.17339667458432304,"5.4
Extension to the stochastic setting"
EXTENSION TO THE STOCHASTIC SETTING,0.17458432304038005,"In this part, we briefly introduce how to extend the analysis to the more challenging stochastic setting.
It becomes harder to obtain an upper bound on f(xœÑ) ‚àíf ‚àóbecause Œ¶t is no longer non-increasing
due to the existence of noise. In addition, œÑ defined in (3) is now a random variable. Note that all the
derivations, such as Lemmas 5.4 and 5.5, are conditioned on the random event t < œÑ. Therefore, one
can not simply take a total expectation of them to show E[Œ¶t] is non-increasing."
EXTENSION TO THE STOCHASTIC SETTING,0.17577197149643706,"Fortunately, œÑ is in fact a stopping time with nice properties. If the noise is almost surely bounded
as in Assumption 3, by a more careful analysis, we can obtain a high probability upper bound on
f(xœÑ)‚àíf ‚àóusing concentration inequalities. Then we can still obtain a contradiction and convergence
under this high probability event. If the noise has sub-Gaussian norm as in Assumption 4, one can
change the definition of œÑ to"
EXTENSION TO THE STOCHASTIC SETTING,0.17695961995249407,"œÑ := min{t | f(xt) ‚àíf ‚àó> F} ‚àßmin{t | ‚à•‚àáf(xt) ‚àí‚àáf(xt, Œæt)‚à•> œÉ} ‚àß(T + 1)"
EXTENSION TO THE STOCHASTIC SETTING,0.17814726840855108,"for appropriately chosen F and œÉ. Then at least when t < œÑ, the noise is bounded by œÉ. Hence we
can get the same upper bound on f(xœÑ) ‚àíf ‚àóas if Assumption 3 still holds. However, when t ‚â§T,
the lower bound f(xœÑ) ‚àíf ‚àó> F does not necessarily holds, which requires some more careful
analyses. The details of the proofs are involved and we defer them in Appendix E."
VARIANCE-REDUCED ADAM,0.17933491686460806,"6
Variance-reduced Adam"
VARIANCE-REDUCED ADAM,0.18052256532066507,"In this section, we propose a variance-reduced version of Adam (VRAdam). This new algorithm is
depicted in Algorithm 2. Its main difference from the original Adam is that in the momentum update"
VARIANCE-REDUCED ADAM,0.18171021377672208,"rule (Line 6), an additional term of (1 ‚àíŒ≤) (‚àáf(xt, Œæt) ‚àí‚àáf(xt‚àí1, Œæt)) is added, inspired by the
STORM algorithm [9]. This term corrects the bias of mt so that it is an unbiased estimate of ‚àáf(xt)
in the sense of total expectation, i.e., E[mt] = ‚àáf(xt). We will also show that it reduces the variance
and accelerates the convergence."
VARIANCE-REDUCED ADAM,0.1828978622327791,"Aside from the adaptive stepsize, one major difference between Algorithm 2 and STORM is that
our hyper-parameters Œ∑ and Œ≤ are fixed constants whereas theirs are decreasing as a function of t.
Choosing constant hyper-parameters requires a more accurate estimate at the initialization. That is
why we use a mega-batch S1 to evaluate the gradient at the initial point to initialize m1 and v1 (Lines
2‚Äì3). In practice, one can also do a full-batch gradient evaluation at initialization. Note that there is
no initialization bias for the momentum, so we do not re-scale mt and only re-scale vt. We also want
to point out that although the initial mega-batch gradient evaluation makes the algorithm a bit harder
to implement, constant hyper-parameters are usually easier to tune and more common in training
deep neural networks. It should be not hard to extend our analysis to time-decreasing Œ∑ and Œ≤ and we
leave it as an interesting future work."
VARIANCE-REDUCED ADAM,0.1840855106888361,Algorithm 2 VARIANCE-REDUCED ADAM (VRADAM)
VARIANCE-REDUCED ADAM,0.18527315914489312,"1: Input: Œ≤, Œ≤sq, Œ∑, Œª, T, S1, xinit
2: Draw a batch of samples S1 with size S1 and use them to evaluate the gradient ‚àáf(xinit, S1).
3: Initialize m1 = ‚àáf(xinit, S1), v1 = Œ≤sqm2
1, and x2 = xinit ‚àí
Œ∑m1
|m1|+Œª.
4: for t = 2, ¬∑ ¬∑ ¬∑ , T do
5:
Draw a new sample Œæt and perform the following updates:
6:
mt = (1 ‚àíŒ≤)mt‚àí1 + Œ≤‚àáf(xt, Œæt)+(1 ‚àíŒ≤) (‚àáf(xt, Œæt) ‚àí‚àáf(xt‚àí1, Œæt))
7:
vt = (1 ‚àíŒ≤sq)vt‚àí1 + Œ≤sq(‚àáf(xt, Œæt))2"
VARIANCE-REDUCED ADAM,0.18646080760095013,"8:
ÀÜvt =
vt
1‚àí(1‚àíŒ≤sq)t
9:
xt+1 = xt ‚àí
Œ∑
‚àöÀÜvt+Œª ‚äômt
10: end for"
VARIANCE-REDUCED ADAM,0.1876484560570071,"In addition to Assumption 1, we need to impose the following assumptions which can be viewed as
stronger versions of Assumptions 2 and 3, respectively."
VARIANCE-REDUCED ADAM,0.18883610451306412,"Assumption 5. The objective function f and the component function f(¬∑, Œæ) for each fixed Œæ are
(œÅ, L0, LœÅ) smooth with 0 ‚â§œÅ < 2."
VARIANCE-REDUCED ADAM,0.19002375296912113,"Assumption 6. The random variables {Œæt}1‚â§t‚â§T are sampled i.i.d. from some distribution P such
that for any x ‚ààdom(f),"
VARIANCE-REDUCED ADAM,0.19121140142517815,"EŒæ‚àºP[‚àáf(x, Œæ)] = ‚àáf(x),
‚à•‚àáf(x, Œæ) ‚àí‚àáf(x)‚à•‚â§œÉ, a.s."
VARIANCE-REDUCED ADAM,0.19239904988123516,"Remark 6.1. Assumption 6 is stronger than Assumption 3. Assumption 3 applies only to the iterates
generated by the algorithm, while Assumption 6 is a pointwise assumption over all x ‚ààdom(f)
and further assumes an i.i.d. nature of the random variables {Œæt}1‚â§t‚â§T . Also note that, similar
to Adam, it is straightforward to generalize the assumption to noise with sub-Gaussian norm as in
Assumption 4."
ANALYSIS,0.19358669833729217,"6.1
Analysis"
ANALYSIS,0.19477434679334918,"In this part, we briefly discuss challenges in the analysis of VRAdam. The detailed analysis is
deferred in Appendix F. Note that Corollary 5.2 requires bounded update ‚à•xt+1 ‚àíxt‚à•‚â§r at each
step. For Adam, it is easy to satisfy for a small enough Œ∑ according to Lemma 5.3. However, for
VRAdam, obtaining a good enough almost sure bound on the update is challenging even though the
gradient noise is bounded. To bypass this difficulty, we directly impose a bound on ‚à•‚àáf(xt) ‚àímt‚à•
by changing the definition of the stopping time œÑ, similar to how we deal with the sub-Gaussian noise
condition for Adam. In particular, we define"
ANALYSIS,0.19596199524940616,œÑ := min{t | ‚à•‚àáf(xt)‚à•> G} ‚àßmin{t | ‚à•‚àáf(xt) ‚àímt‚à•> G} ‚àß(T + 1).
ANALYSIS,0.19714964370546317,"Then by definition, both ‚à•‚àáf(xt)‚à•and ‚à•‚àáf(xt) ‚àímt‚à•are bounded by G before time œÑ, which
directly implies bounded update ‚à•xt+1 ‚àíxt‚à•. Of course, the new definition brings new challenges to
lower bounding f(xœÑ) ‚àíf ‚àó, which requires more careful analyses specific to the VRAdam algorithm.
Please see Appendix F for the details."
CONVERGENCE GUARANTEES FOR VRADAM,0.19833729216152018,"6.2
Convergence guarantees for VRAdam"
CONVERGENCE GUARANTEES FOR VRADAM,0.1995249406175772,"In the section, we provide our main results for convergence of VRAdam under Assumptions 1, 5, and 6.
We consider the same definitions of problem-dependent constants ‚àÜ1, r, L as those in Section 4 to
make the statements of theorems concise. Let c be a small enough numerical constant and C be a
large enough numerical constant. The formal convergence result is shown in the following theorem."
CONVERGENCE GUARANTEES FOR VRADAM,0.2007125890736342,"Theorem 6.2. Suppose Assumptions 1, 5, and 6 hold. For any 0 < Œ¥ < 1, let G > 0 be a constant
satisfying G ‚â•max
n
2Œª, 2œÉ,
p"
CONVERGENCE GUARANTEES FOR VRADAM,0.20190023752969122,"C‚àÜ1L0/Œ¥, (C‚àÜ1LœÅ/Œ¥)
1
2‚àíœÅ
o
. Choose 0 ‚â§Œ≤sq ‚â§1 and Œ≤ = a2Œ∑2,"
CONVERGENCE GUARANTEES FOR VRADAM,0.20308788598574823,"where a = 40L
‚àö"
CONVERGENCE GUARANTEES FOR VRADAM,0.2042755344418052,GŒª‚àí3/2. Choose
CONVERGENCE GUARANTEES FOR VRADAM,0.20546318289786222,"Œ∑ ‚â§c ¬∑ min (
rŒª"
CONVERGENCE GUARANTEES FOR VRADAM,0.20665083135391923,"G ,
Œª
L,
Œª2Œ¥
‚àÜ1L2 ,
Œª2‚àö"
CONVERGENCE GUARANTEES FOR VRADAM,0.20783847980997625,"Œ¥œµ
œÉGL )"
CONVERGENCE GUARANTEES FOR VRADAM,0.20902612826603326,",
T = 64G‚àÜ1"
CONVERGENCE GUARANTEES FOR VRADAM,0.21021377672209027,"Œ∑Œ¥œµ2 ,
S1 ‚â•
1
2Œ≤2T ."
CONVERGENCE GUARANTEES FOR VRADAM,0.21140142517814728,"Then with probability at least 1 ‚àíŒ¥, we have ‚à•‚àáf(xt)‚à•‚â§G for every 1 ‚â§t ‚â§T, and
1
T
PT
t=1 ‚à•‚àáf(xt)‚à•2 ‚â§œµ2."
CONVERGENCE GUARANTEES FOR VRADAM,0.21258907363420426,"Note that the choice of G, the upper bound of gradients along the trajectory of VRAdam, is very
similar to that in Theorem 4.1 for Adam. The only difference is that now it also depends on the failure
probability Œ¥. Similar to Theorem 4.1, there is no requirement on Œ≤sq and we choose a very small
Œ≤ = O(œµ2). However, the variance reduction technique allows us to take a larger stepsize Œ∑ = O(œµ)
(compared with O(œµ2) for Adam) and obtain an accelerated gradient complexity of O(œµ‚àí3), where
we only consider the leading term. We are not sure whether it is optimal as the ‚Ñ¶(œµ‚àí3) lower bound
in [3] assumes the weaker bounded variance condition. However, our result significantly improves
upon [47], which considers a variance-reduced version of Adam by combining Adam and SVRG [22]
and only obtains asymptotic convergence in the non-convex setting. Similar to Adam, our gradient
complexity for VRAdam is dimension free but its dependence on Œª is O(Œª‚àí2). Another limitation is
that, the dependence on the failure probability Œ¥ is polynomial, worse than the poly-log dependence
in Theorem 4.1 for Adam."
CONCLUSION AND FUTURE WORKS,0.21377672209026127,"7
Conclusion and future works"
CONCLUSION AND FUTURE WORKS,0.21496437054631828,"In this paper, we proved the convergence of Adam and its variance-reduced version under less
restrictive assumptions compared to those in the existing literature. We considered a generalized non-
uniform smoothness condition, according to which the Hessian norm is bounded by a sub-quadratic
function of the gradient norm almost everywhere. Instead of assuming the Lipschitzness of the
objective function as in existing analyses of Adam, we use a new contradiction argument to prove that
gradients are bounded by a constant along the optimization trajectory. There are several interesting
future directions that one could pursue following this work."
CONCLUSION AND FUTURE WORKS,0.2161520190023753,"Relaxation of the bounded noise assumption. Our analysis relies on the assumption of bounded
noise or noise with sub-Gaussian norm. However, the existing lower bounds in [3] consider the
weaker bounded variance assumption. Hence, it is not clear whether the O(œµ‚àí4) complexity we obtain
for Adam is tight in this setting. It will be interesting to see whether one can relax the assumption
to the bounded variance setting. One may gain some insights from recent papers such as [16; 46]
that analyze AdaGrad under weak noise conditions. An alternative way to show the tightness of the
O(œµ‚àí4) complexity is to prove a lower bound under the bounded noise assumption."
CONCLUSION AND FUTURE WORKS,0.2173396674584323,"Potential applications of our technique. Another interesting future direction is to see if the
techniques developed in this work for bounding gradients (including those in the the concurrent
work [26]) can be generalized to improve the convergence results for other optimization problems and
algorithms. We believe it is possible so long as the function class is well behaved and the algorithm
is efficient enough so that f(xœÑ) ‚àíf ‚àócan be well bounded for some appropriately defined stopping
time œÑ."
CONCLUSION AND FUTURE WORKS,0.21852731591448932,"Understanding why Adam is better than SGD. We want to note that our results can not explain
why Adam is better than SGD for training transformers, because [26] shows that non-adaptive SGD
converges with the same O(œµ‚àí4) gradient complexity under even weaker conditions. It would be
interesting and impactful if one can find a reasonable setting (function class, gradient oracle, etc)
under which Adam or other adaptive methods provably outperform SGD."
CONCLUSION AND FUTURE WORKS,0.21971496437054633,Acknowledgments
CONCLUSION AND FUTURE WORKS,0.2209026128266033,"This work was supported, in part, by the MIT-IBM Watson AI Lab and ONR Grants N00014-20-1-
2394 and N00014-23-1-2299. We also acknowledge support from DOE under grant DE-SC0022199,
and NSF through awards DMS-2031883 and DMS-1953181."
REFERENCES,0.22209026128266032,References
REFERENCES,0.22327790973871733,"[1] Kwangjun Ahn, Xiang Cheng, Minhak Song, Chulhee Yun, Ali Jadbabaie, and Suvrit Sra.
Linear attention is (maybe) all you need (to understand transformer optimization). arXiv
preprint arXiv:2310.01082, 2023."
REFERENCES,0.22446555819477435,"[2] Zeyuan Allen-Zhu and Elad Hazan. Variance reduction for faster non-convex optimization. In
International conference on machine learning, pages 699‚Äì707. PMLR, 2016."
REFERENCES,0.22565320665083136,"[3] Yossi Arjevani, Yair Carmon, John C Duchi, Dylan J Foster, Nathan Srebro, and Blake Wood-
worth. Lower bounds for non-convex stochastic optimization. Mathematical Programming, 199
(1-2):165‚Äì214, 2023."
REFERENCES,0.22684085510688837,"[4] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhari-
wal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal,
Ariel Herbert-Voss, Gretchen Krueger, T. J. Henighan, Rewon Child, Aditya Ramesh, Daniel M.
Ziegler, Jeff Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin,
Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Rad-
ford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. ArXiv,
abs/2005.14165, 2020."
REFERENCES,0.22802850356294538,"[5] Congliang Chen, Li Shen, Fangyu Zou, and Wei Liu. Towards practical adam: Non-convexity,
convergence theory, and mini-batch acceleration. The Journal of Machine Learning Research,
23(1):10411‚Äì10457, 2022."
REFERENCES,0.22921615201900236,"[6] Xiangyi Chen, Sijia Liu, Ruoyu Sun, and Mingyi Hong. On the convergence of a class of
adam-type algorithms for non-convex optimization. arXiv preprint arXiv:1808.02941, 2018."
REFERENCES,0.23040380047505937,"[7] Ziyi Chen, Yi Zhou, Yingbin Liang, and Zhaosong Lu. Generalized-smooth nonconvex opti-
mization is as efficient as smooth nonconvex optimization. arXiv preprint arXiv:2303.02854,
2023."
REFERENCES,0.23159144893111638,"[8] Michael Crawshaw, Mingrui Liu, Francesco Orabona, Wei Zhang, and Zhenxun Zhuang.
Robustness to unbounded smoothness of generalized signsgd. Advances in Neural Information
Processing Systems, 35:9955‚Äì9968, 2022."
REFERENCES,0.2327790973871734,"[9] Ashok Cutkosky and Francesco Orabona. Momentum-based variance reduction in non-convex
sgd. ArXiv, abs/1905.10018, 2019."
REFERENCES,0.2339667458432304,"[10] Soham De, Anirbit Mukherjee, and Enayat Ullah. Convergence guarantees for rmsprop and
adam in non-convex optimization and an empirical comparison to nesterov acceleration. arXiv:
Learning, 2018."
REFERENCES,0.23515439429928742,"[11] Aaron Defazio, Francis Bach, and Simon Lacoste-Julien. Saga: A fast incremental gradi-
ent method with support for non-strongly convex composite objectives. Advances in neural
information processing systems, 27, 2014."
REFERENCES,0.23634204275534443,"[12] Alexandre D‚Äôefossez, L√©on Bottou, Francis R. Bach, and Nicolas Usunier. A simple convergence
proof of adam and adagrad. arXiv: Machine Learning, 2020."
REFERENCES,0.2375296912114014,"[13] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of
deep bidirectional transformers for language understanding. ArXiv, abs/1810.04805, 2019."
REFERENCES,0.23871733966745842,"[14] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai,
Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly,
Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image
recognition at scale. ArXiv, abs/2010.11929, 2020."
REFERENCES,0.23990498812351543,"[15] Cong Fang, Chris Junchi Li, Zhouchen Lin, and Tong Zhang. Spider: Near-optimal non-
convex optimization via stochastic path-integrated differential estimator. Advances in neural
information processing systems, 31, 2018."
REFERENCES,0.24109263657957244,"[16] Matthew Faw, Isidoros Tziotis, Constantine Caramanis, Aryan Mokhtari, Sanjay Shakkottai,
and Rachel Ward. The power of adaptivity in sgd: Self-tuning step sizes with unbounded
gradients and affine variance. In Conference on Learning Theory, pages 313‚Äì355. PMLR, 2022."
REFERENCES,0.24228028503562946,"[17] Matthew Faw, Litu Rout, Constantine Caramanis, and Sanjay Shakkottai. Beyond uniform
smoothness: A stopped analysis of adaptive sgd. arXiv preprint arXiv:2302.06570, 2023."
REFERENCES,0.24346793349168647,"[18] S√©bastien Gadat and Ioana Gavra. Asymptotic study of stochastic adaptive algorithms in
non-convex landscape. The Journal of Machine Learning Research, 23(1):10357‚Äì10410, 2022."
REFERENCES,0.24465558194774348,"[19] Zhishuai Guo, Yi Xu, Wotao Yin, Rong Jin, and Tianbao Yang. A novel convergence analysis
for algorithms of the adam family. ArXiv, abs/2112.03459, 2021."
REFERENCES,0.24584323040380046,"[20] Hideaki Iiduka. Theoretical analysis of adam using hyperparameters close to one without
lipschitz smoothness. Numerical Algorithms, pages 1‚Äì39, 2023."
REFERENCES,0.24703087885985747,"[21] Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A. Efros. Image-to-image translation
with conditional adversarial networks. 2017 IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), pages 5967‚Äì5976, 2016."
REFERENCES,0.24821852731591448,"[22] Rie Johnson and Tong Zhang. Accelerating stochastic gradient descent using predictive variance
reduction. In NIPS, 2013."
REFERENCES,0.2494061757719715,"[23] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. CoRR,
abs/1412.6980, 2014."
REFERENCES,0.2505938242280285,"[24] Frederik Kunstner, Jacques Chen, Jonathan Wilder Lavington, and Mark Schmidt. Noise is not
the main factor behind the gap between sgd and adam on transformers, but sign descent might
be. arXiv preprint arXiv:2304.13960, 2023."
REFERENCES,0.2517814726840855,"[25] Lihua Lei, Cheng Ju, Jianbo Chen, and Michael I Jordan. Non-convex finite-sum optimization
via scsg methods. Advances in Neural Information Processing Systems, 30, 2017."
REFERENCES,0.2529691211401425,"[26] Haochuan Li, Jian Qian, Yi Tian, Alexander Rakhlin, and Ali Jadbabaie. Convex and non-convex
optimization under generalized smoothness. arXiv preprint arXiv:2306.01264, 2023."
REFERENCES,0.25415676959619954,"[27] Zhize Li, Hongyan Bao, Xiangliang Zhang, and Peter Richt√°rik. Page: A simple and optimal
probabilistic gradient estimator for nonconvex optimization. In International conference on
machine learning, pages 6286‚Äì6295. PMLR, 2021."
REFERENCES,0.25534441805225655,"[28] Timothy P. Lillicrap, Jonathan J. Hunt, Alexander Pritzel, Nicolas Manfred Otto Heess, Tom
Erez, Yuval Tassa, David Silver, and Daan Wierstra. Continuous control with deep reinforcement
learning. CoRR, abs/1509.02971, 2015."
REFERENCES,0.25653206650831356,"[29] Deyi Liu, Lam M Nguyen, and Quoc Tran-Dinh. An optimal hybrid variance-reduced algorithm
for stochastic composite nonconvex optimization. arXiv preprint arXiv:2008.09055, 2020."
REFERENCES,0.25771971496437057,"[30] Zijian Liu, Perry Dong, Srikanth Jagabathula, and Zhengyuan Zhou. Near-optimal high-
probability convergence for non-convex stochastic optimization with variance reduction. arXiv
preprint arXiv:2302.06032, 2023."
REFERENCES,0.2589073634204275,"[31] Liangchen Luo, Yuanhao Xiong, Yan Liu, and Xu Sun. Adaptive gradient methods with dynamic
bound of learning rate. ArXiv, abs/1902.09843, 2019."
REFERENCES,0.26009501187648454,"[32] Julien Mairal. Optimization with first-order surrogate functions. In International Conference
on Machine Learning, pages 783‚Äì791. PMLR, 2013."
REFERENCES,0.26128266033254155,"[33] Volodymyr Mnih, Adri√† Puigdom√®nech Badia, Mehdi Mirza, Alex Graves, Timothy P. Lill-
icrap, Tim Harley, David Silver, and Koray Kavukcuoglu. Asynchronous methods for deep
reinforcement learning. ArXiv, abs/1602.01783, 2016."
REFERENCES,0.26247030878859856,"[34] Jiang Qian, Yuren Wu, Bojin Zhuang, Shaojun Wang, and Jing Xiao. Understanding gradient
clipping in incremental gradient methods. In International Conference on Artificial Intelligence
and Statistics, 2021."
REFERENCES,0.26365795724465557,"[35] Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with
deep convolutional generative adversarial networks. CoRR, abs/1511.06434, 2015."
REFERENCES,0.2648456057007126,"[36] Sashank J. Reddi, Ahmed Hefny, Suvrit Sra, Barnabas Poczos, and Alex Smola. Stochastic vari-
ance reduction for nonconvex optimization. In Maria Florina Balcan and Kilian Q. Weinberger,
editors, Proceedings of The 33rd International Conference on Machine Learning, volume 48
of Proceedings of Machine Learning Research, pages 314‚Äì323, New York, New York, USA,
20‚Äì22 Jun 2016. PMLR. URL https://proceedings.mlr.press/v48/reddi16.html."
REFERENCES,0.2660332541567696,"[37] Sashank J. Reddi, Satyen Kale, and Sanjiv Kumar. On the convergence of adam and beyond.
ArXiv, abs/1904.09237, 2018."
REFERENCES,0.2672209026128266,"[38] Amirhossein Reisizadeh, Haochuan Li, Subhro Das, and Ali Jadbabaie. Variance-reduced
clipping for non-convex optimization. arXiv preprint arXiv:2303.00883, 2023."
REFERENCES,0.2684085510688836,"[39] Nicolas Roux, Mark Schmidt, and Francis Bach. A stochastic gradient method with an expo-
nential convergence _rate for finite training sets. In F. Pereira, C.J. Burges, L. Bottou, and K.Q.
Weinberger, editors, Advances in Neural Information Processing Systems, volume 25. Curran
Associates, Inc., 2012. URL https://proceedings.neurips.cc/paper_files/paper/
2012/file/905056c1ac1dad141560467e0a99e1cf-Paper.pdf."
REFERENCES,0.2695961995249406,"[40] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal
policy optimization algorithms. ArXiv, abs/1707.06347, 2017."
REFERENCES,0.27078384798099764,"[41] Shai Shalev-Shwartz and Tong Zhang. Stochastic dual coordinate ascent methods for regularized
loss minimization. Journal of Machine Learning Research, 14(1), 2013."
REFERENCES,0.27197149643705465,"[42] Naichen Shi, Dawei Li, Mingyi Hong, and Ruoyu Sun. Rmsprop converges with proper
hyper-parameter. In International Conference on Learning Representations, 2021."
REFERENCES,0.27315914489311166,"[43] Quoc Tran-Dinh, Nhan H Pham, Dzung T Phan, and Lam M Nguyen. Hybrid stochastic gradient
descent algorithms for stochastic nonconvex optimization. arXiv preprint arXiv:1905.05920,
2019."
REFERENCES,0.27434679334916867,"[44] Ashish Vaswani, Noam M. Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N.
Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. ArXiv, abs/1706.03762,
2017."
REFERENCES,0.2755344418052256,"[45] Bohan Wang, Yushun Zhang, Huishuai Zhang, Qi Meng, Zhirui Ma, Tie-Yan Liu, and Wei
Chen. Provable adaptivity in adam. ArXiv, abs/2208.09900, 2022."
REFERENCES,0.27672209026128264,"[46] Bohan Wang, Huishuai Zhang, Zhiming Ma, and Wei Chen. Convergence of adagrad for
non-convex objectives: Simple proofs and relaxed assumptions. In The Thirty Sixth Annual
Conference on Learning Theory, pages 161‚Äì190. PMLR, 2023."
REFERENCES,0.27790973871733965,"[47] Ruiqi Wang and Diego Klabjan. Divergence results and convergence of a variance reduced
version of adam. ArXiv, abs/2210.05607, 2022."
REFERENCES,0.27909738717339666,"[48] Bohang Zhang, Jikai Jin, Cong Fang, and Liwei Wang. Improved analysis of clipping algorithms
for non-convex optimization. Advances in Neural Information Processing Systems, 33:15511‚Äì
15521, 2020."
REFERENCES,0.28028503562945367,"[49] J. Zhang, Tianxing He, Suvrit Sra, and Ali Jadbabaie. Why gradient clipping accelerates
training: A theoretical justification for adaptivity. arXiv: Optimization and Control, 2019."
REFERENCES,0.2814726840855107,"[50] Jingzhao Zhang, Sai Praneeth Karimireddy, Andreas Veit, Seungyeon Kim, Sashank Reddi,
Sanjiv Kumar, and Suvrit Sra. Why are adaptive methods good for attention models? Advances
in Neural Information Processing Systems, 33:15383‚Äì15393, 2020."
REFERENCES,0.2826603325415677,"[51] Yushun Zhang, Congliang Chen, Naichen Shi, Ruoyu Sun, and Zhimin Luo. Adam can converge
without any modification on update rules. ArXiv, abs/2208.09632, 2022."
REFERENCES,0.2838479809976247,"[52] Shen-Yi Zhao, Yin-Peng Xie, and Wu-Jun Li. On the convergence and improvement of stochastic
normalized gradient descent. Science China Information Sciences, 64, 2021."
REFERENCES,0.2850356294536817,"[53] Dongruo Zhou, Jinghui Chen, Yuan Cao, Yiqi Tang, Ziyan Yang, and Quanquan Gu. On
the convergence of adaptive gradient methods for nonconvex optimization. arXiv preprint
arXiv:1808.05671, 2018."
REFERENCES,0.2862232779097387,"[54] Zhiming Zhou, Qingru Zhang, Guansong Lu, Hongwei Wang, Weinan Zhang, and Yong
Yu. Adashift: Decorrelation and convergence of adaptive learning rate methods.
ArXiv,
abs/1810.00143, 2018."
REFERENCES,0.28741092636579574,"[55] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A. Efros. Unpaired image-to-image
translation using cycle-consistent adversarial networks. 2017 IEEE International Conference
on Computer Vision (ICCV), pages 2242‚Äì2251, 2017."
REFERENCES,0.28859857482185275,"[56] Fangyu Zou, Li Shen, Zequn Jie, Weizhong Zhang, and Wei Liu. A sufficient condition for
convergences of adam and rmsprop. 2019 IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR), pages 11119‚Äì11127, 2018."
REFERENCES,0.28978622327790976,"A
Additional related work"
REFERENCES,0.29097387173396677,"In this section, we discuss additional related work on variants of Adam and variance reduction
methods."
REFERENCES,0.2921615201900237,"Variants of Adam.
After Reddi et al. [37] pointed out the non-convergence issue with Adam,
various variants of Adam that can be proved to converge were proposed [56; 18; 6; 5; 31; 54].
For example, AMSGrad [37] and AdaFom [6] modify the second order momentum so that it is
non-decreasing. AdaBound [31] explicitly imposes upper and lower bounds on the second order
momentum so that the stepsize is also bounded. AdaShift [54] uses a new estimate of the second
order momentum to correct the bias. There are also some works [53; 18; 20] that provide convergence
guarantees of these variants. One closely related work to ours is [47], which considers a variance-
reduced version of Adam by combining Adam and SVRG [22]. However, they assume bounded
gradients and can only get an asymptotic convergence in the non-convex setting."
REFERENCES,0.29334916864608074,"Variance reduction methods.
The technique of variance reduction was introduced to accelerate
convex optimization in the finite-sum setting [39; 22; 41; 32; 11]. Later, many works studied
variance-reduced methods in the non-convex setting and obtained improved convergence rates
for standard smooth functions. For example, SVRG and SCSG improve the O(œµ‚àí4) gradient
complexity of stochastic gradient descent (SGD) to O(œµ‚àí10/3) [2; 36; 25]. Many new variance
reduction methods [15; 43; 29; 27; 9; 30] were later proposed to further improve the complexity
to O(œµ‚àí3), which is optimal and matches the lower bound in [3]. Recently, [38; 7] obtained the
O(œµ‚àí3) complexity for the more general (L0, L1) smooth functions. Our variance-reduced Adam
is motivated by the STORM algorithm proposed by [9], where an additional term is added in the
momentum update to correct the bias and reduce the variance."
REFERENCES,0.29453681710213775,"B
Proof sketches of informal lemmas in Section 5.3"
REFERENCES,0.29572446555819476,"In this section, we provide the proof sketches of the informal lemmas in Section 5.3. We focus on
illustrating the ideas rather than rigorous proof details. Please see Appendix E for more rigorous and
detailed proofs of Adam in the stochastic setting."
REFERENCES,0.29691211401425177,"Proof Sketch of Lemma 5.4. By the definition of œÑ, for all t < œÑ, we have f(xt) ‚àíf ‚àó‚â§F which
implies ‚à•‚àáf(xt)‚à•‚â§G. Then from the update rule (18) in Proposition E.1 provided later in
Appendix E, it is easy to verify ÀÜvt ‚™ØG2 since ÀÜvt is a convex combination of {(‚àáf(xs))2}s‚â§t. Let
ht := Œ∑/(‚àöÀÜvt + Œª) be the stepsize vector and denote Ht := diag(ht). We know"
REFERENCES,0.2980997624703088,"Œ∑
2GI ‚™Ø
Œ∑
G + ŒªI ‚™ØHt ‚™ØŒ∑"
REFERENCES,0.2992874109263658,"ŒªI.
(7)"
REFERENCES,0.3004750593824228,"As discussed in Section 5.2, when Œ∑ is small enough, we can apply Corollary 5.2 to obtain"
REFERENCES,0.3016627078384798,"f(xt+1) ‚àíf(xt) ‚™Ö

‚àáf(xt), xt+1 ‚àíxt"
REFERENCES,0.3028503562945368,"= ‚àí‚à•‚àáf(xt)‚à•2
Ht ‚àí‚àáf(xt)‚ä§Htœµt ‚â§‚àí1"
REFERENCES,0.30403800475059384,"2 ‚à•‚àáf(xt)‚à•2
Ht + 1"
REFERENCES,0.30522565320665085,"2 ‚à•œµt‚à•2
Ht ‚â§‚àíŒ∑"
REFERENCES,0.30641330166270786,4G ‚à•‚àáf(xt)‚à•2 + Œ∑
REFERENCES,0.30760095011876487,"2Œª ‚à•œµt‚à•2 ,"
REFERENCES,0.3087885985748218,where in the first (approximate) inequality we ignore the second order term 1
REFERENCES,0.30997624703087884,"2L ‚à•xt+1 ‚àíxt‚à•2 ‚àùŒ∑2
in Corollary 5.2 for small enough Œ∑; the equality applies the update rule xt+1 ‚àíxt = ‚àíHt ÀÜmt =
‚àíHt(‚àáf(xt) + œµt); in the second inequality we use 2a‚ä§Ab ‚â§‚à•a‚à•2
A + ‚à•b‚à•2
A for any PSD matrix A
and vectors a and b; and the last inequality is due to (7)."
REFERENCES,0.31116389548693585,"Proof Sketch of Lemma 5.5. By the update rule (18) in Proposition E.1, we have"
REFERENCES,0.31235154394299286,"œµt+1 = (1 ‚àíŒ±t+1) (œµt + ‚àáf(xt) ‚àí‚àáf(xt+1)) .
(8)"
REFERENCES,0.31353919239904987,"For small enough Œ∑, we can apply Corollary 5.2 to get"
REFERENCES,0.3147268408551069,"‚à•‚àáf(xt+1)‚àí‚àáf(xt)‚à•2 ‚â§L2 ‚à•xt+1‚àíxt‚à•2 ‚â§O(Œ∑2G2œÅ) ‚à•ÀÜmt‚à•2 ‚â§O(Œ∑2G2œÅ)(‚à•‚àáf(xt)‚à•2+‚à•œµt‚à•2),
(9)"
REFERENCES,0.3159144893111639,"where the second inequality is due to L = O(GœÅ) and ‚à•xt+1 ‚àíxt‚à•= O(Œ∑) ‚à•ÀÜmt‚à•; and the last
inequality uses ÀÜmt = ‚àáf(xt) + œµt and Young‚Äôs inequality ‚à•a + b‚à•2 ‚â§2 ‚à•a‚à•2 + 2 ‚à•b‚à•2. Therefore,"
REFERENCES,0.3171021377672209,‚à•œµt+1‚à•2 ‚â§(1 ‚àíŒ±t+1)(1 + Œ±t+1/2) ‚à•œµt‚à•2 + (1 + 2/Œ±t+1) ‚à•‚àáf(xt+1) ‚àí‚àáf(xt)‚à•2
REFERENCES,0.3182897862232779,"‚â§(1 ‚àíŒ±t+1/2) ‚à•œµt‚à•2 + O(Œ∑2G2œÅ/Œ±t+1)

‚à•‚àáf(xt)‚à•2 + ‚à•œµt‚à•2"
REFERENCES,0.3194774346793349,‚â§(1 ‚àíŒ≤/4) ‚à•œµt‚à•2 + ŒªŒ≤
REFERENCES,0.32066508313539194,"16G ‚à•‚àáf(xt)‚à•2 ,"
REFERENCES,0.32185273159144895,where the first inequality uses (8) and Young‚Äôs inequality ‚à•a + b‚à•2 ‚â§(1 + u) ‚à•a‚à•2 + (1 + 1/u) ‚à•b‚à•2
REFERENCES,0.32304038004750596,"for any u > 0; the second inequality uses (1 ‚àíŒ±t+1)(1 + Œ±t+1/2) ‚â§1 ‚àíŒ±t+1/2 and (9); and in the
last inequality we use Œ≤ ‚â§Œ±t+1 and choose Œ≤ = Œò(Œ∑GœÅ+1/2) which implies O(Œ∑2G2œÅ/Œ±t+1) ‚â§
ŒªŒ≤
16G ‚â§Œ≤/4."
REFERENCES,0.32422802850356297,"C
Probabilistic lemmas"
REFERENCES,0.3254156769596199,"In this section, we state several well-known and useful probabilistic lemmas without proof.
Lemma C.1 (Azuma-Hoeffding inequality). Let {Zt}t‚â•1 be a martingale with respect to a filtration
{Ft}t‚â•0. Assume that |Zt ‚àíZt‚àí1| ‚â§ct almost surely for all t ‚â•0. Then for any fixed T, with
probability at least 1 ‚àíŒ¥,"
REFERENCES,0.32660332541567694,ZT ‚àíZ0 ‚â§
REFERENCES,0.32779097387173395,"v
u
u
t2 T
X"
REFERENCES,0.32897862232779096,"t=1
c2
t log(1/Œ¥)."
REFERENCES,0.33016627078384797,"Lemma C.2 (Optional Stopping Theorem). Let {Zt}t‚â•1 be a martingale with respect to a filtration
{Ft}t‚â•0. Let œÑ be a bounded stopping time with respect to the same filtration. Then we have
E[ZœÑ] = E[Z0]."
REFERENCES,0.331353919239905,"D
Proofs related to (œÅ, L0, LœÅ) smoothness"
REFERENCES,0.332541567695962,"In this section, we provide proofs related to (œÅ, L0, LœÅ) smoothness. In what follows, we first
provide a formal proposition in Appendix D.1 showing that univariate rational functions and double
exponential functions are (œÅ, L0, LœÅ) smooth with œÅ < 2, as we claimed in Section 3.2.1, and then
provide the proofs of Lemma 3.4, Lemma 5.1, and Corollary 5.2 in Appendix D.2, D.3 and D.4
respectively."
REFERENCES,0.333729216152019,"D.1
Examples"
REFERENCES,0.334916864608076,"Proposition D.1. Any univariate rational function P(x)/Q(x), where P, Q are two polynomials,
and any double exponential function a(bx), where a, b > 1, are (œÅ, L0, LœÅ) smooth with 1 < œÅ < 2.
However, they are not necessarily (L0, L1) smooth."
REFERENCES,0.336104513064133,Proof of Proposition D.1. We prove the proposition in the following four parts:
REFERENCES,0.33729216152019004,"1. Univariate rational functions are (œÅ, L0, LœÅ) smooth with 1 < œÅ < 2. Let f(x) = P(x)/Q(x)
where P and Q are two polynomials. Then the partial fractional decomposition of f(x) is given by"
REFERENCES,0.33847980997624705,"f(x) = w(x) + m
X i=1 ji
X r=1"
REFERENCES,0.33966745843230406,"Air
(x ‚àíai)r + n
X i=1 ki
X r=1"
REFERENCES,0.34085510688836107,"Birx + Cir
(x2 + bix + ci)r ,"
REFERENCES,0.342042755344418,"where w(x) is a polynomial, Air, Bir, Cir, ai, bi, ci are all real constants satisfying b2
i ‚àí4ci < 0 for
each 1 ‚â§i ‚â§n which implies x2 + bix + ci > 0 for all x ‚ààR. Assume Aiji Ã∏= 0 without loss of"
REFERENCES,0.34323040380047504,"generality. Then we know f has only finite singular points {ai}1‚â§i‚â§m and has continuous first and
second order derivatives at all other points. To simplify notation, denote"
REFERENCES,0.34441805225653205,"pir(x) :=
Air
(x ‚àíai)r ,
qir(x) :=
Birx + Cir
(x2 + bix + ci)r ."
REFERENCES,0.34560570071258906,"Then we have f(x) = w(x) + Pm
i=1
Pji
r=1 pir(x) + Pn
i=1
Pki
r=1 qir(x). For any 3/2 < œÅ < 2, we
know that œÅ > r+2"
REFERENCES,0.34679334916864607,r+1 for any r ‚â•1. Then we can show that
REFERENCES,0.3479809976247031,"lim
x‚Üíai
|f ‚Ä≤(x)|œÅ"
REFERENCES,0.3491686460807601,"|f ‚Ä≤‚Ä≤(x)| = lim
x‚Üíai"
REFERENCES,0.3503562945368171,"p‚Ä≤
iji(x)
œÅ
p‚Ä≤‚Ä≤
iji(x)
 = ‚àû,
(10)"
REFERENCES,0.3515439429928741,"where the first equality is because one can easily verify that the first and second order derivatives
of piji dominate those of all other terms when x goes to ai, and the second equality is because
p‚Ä≤
iji(x)
œÅ = O
 
(x ‚àíai)‚àíœÅ(ji+1)
,
p‚Ä≤‚Ä≤
iji(x)
 = O
 
(x ‚àíai)‚àí(ji+2)
, and œÅ(ji + 1) > ji + 2 (here
we assume ji ‚â•1 since otherwise there is no need to prove (10) for i). Note that (10) implies that,
for any LœÅ > 0, there exists Œ¥i > 0 such that"
REFERENCES,0.3527315914489311,"|f ‚Ä≤‚Ä≤(x)| ‚â§LœÅ |f ‚Ä≤(x)|œÅ ,
if |x ‚àíai| < Œ¥i.
(11)"
REFERENCES,0.35391923990498814,"Similarly, one can show limx‚Üí‚àû|f ‚Ä≤(x)|
œÅ"
REFERENCES,0.35510688836104515,"|f ‚Ä≤‚Ä≤(x)| = ‚àû, which implies there exists M > 0 such that"
REFERENCES,0.35629453681710216,"|f ‚Ä≤‚Ä≤(x)| ‚â§LœÅ |f ‚Ä≤(x)|œÅ ,
if |x| > M.
(12)
Define
B := {x ‚ààR | |x| ‚â§M and |x ‚àíai| ‚â•Œ¥i, ‚àÄi} ."
REFERENCES,0.35748218527315917,"We know B is a compact set and therefore the continuous function f ‚Ä≤‚Ä≤ is bounded within B, i.e., there
exists some constant L0 > 0 such that
|f ‚Ä≤‚Ä≤(x)| ‚â§L0,
if x ‚ààB.
(13)
Combining (11), (12), and (13), we have shown
|f ‚Ä≤‚Ä≤(x)| ‚â§L0 + LœÅ |f ‚Ä≤(x)|œÅ ,
‚àÄx ‚ààdom(f),
which completes the proof of the first part."
REFERENCES,0.3586698337292161,"2. Rational functions are not necessarily (L0, L1) smooth. Consider the ration function f(x) =
1/x. Then we know that f ‚Ä≤(x) = ‚àí1/x2 and f ‚Ä≤‚Ä≤(x) = 2/x3. Note that for any 0 < x ‚â§
min{(L0 + 1)‚àí1/3, (L1 + 1)‚àí1}, we have"
REFERENCES,0.35985748218527314,|f ‚Ä≤‚Ä≤(x)| = 1
REFERENCES,0.36104513064133015,x3 + 1
REFERENCES,0.36223277909738716,"x ¬∑ |f ‚Ä≤(x)| > L0 + L1 |f ‚Ä≤(x)| ,"
REFERENCES,0.36342042755344417,"which shows f is not (L0, L1) smooth for any L0, L1 ‚â•0."
REFERENCES,0.3646080760095012,"3. Double exponential functions are (œÅ, L0, LœÅ) smooth with 1 < œÅ < 2. Let f(x) = a(bx), where
a, b > 1, be a double exponential function. Then we know that"
REFERENCES,0.3657957244655582,"f ‚Ä≤(x) = log(a) log(b) bxa(bx),
f ‚Ä≤‚Ä≤(x) = log(b)(log(a)bx + 1) ¬∑ f ‚Ä≤(x).
For any œÅ > 1, we have"
REFERENCES,0.3669833729216152,"lim
x‚Üí+‚àû
|f ‚Ä≤(x)|œÅ"
REFERENCES,0.3681710213776722,"|f ‚Ä≤‚Ä≤(x)| =
lim
x‚Üí+‚àû
|f ‚Ä≤(x)|œÅ‚àí1"
REFERENCES,0.3693586698337292,"log(b)(log(a)bx + 1) =
lim
y‚Üí+‚àû
(log(a) log(b)y)œÅ‚àí1 a(œÅ‚àí1)y"
REFERENCES,0.37054631828978624,"log(b)(log(a)y + 1)
= ‚àû,"
REFERENCES,0.37173396674584325,"where the first equality is a direct calculation; the second equality uses change of variable y = bx; and
the last equality is because exponential function grows faster than linear function. Then we complete
the proof following a similar argument to that in Part 1."
REFERENCES,0.37292161520190026,"4. Double exponential functions are not necessarily (L0, L1) smooth. Consider the double
exponential function f(x) = e(ex). Then we have"
REFERENCES,0.37410926365795727,"f ‚Ä≤(x) = exe(ex),
f ‚Ä≤‚Ä≤(x) = (ex + 1) ¬∑ f ‚Ä≤(x).
For any x ‚â•max {log(L0 + 1), log(L1 + 1)}, we can show that
|f ‚Ä≤‚Ä≤(x)| > (L1 + 1)f ‚Ä≤(x) > L0 + L1 |f ‚Ä≤(x)| ,
which shows f is not (L0, L1) smooth for any L0, L1 ‚â•0."
REFERENCES,0.3752969121140142,"D.2
Proof of Lemma 3.4"
REFERENCES,0.37648456057007124,"Before proving Lemma 3.4, we need the following lemma that generalizes (a special case of)
Gr√∂nwall‚Äôs inequality.
Lemma D.2. Let u : [a, b] ‚Üí[0, ‚àû) and ‚Ñì: [0, ‚àû) ‚Üí(0, ‚àû) be two continuous functions. Suppose
u‚Ä≤(t) ‚â§‚Ñì(u(t)) for all t ‚àà(a, b). Denote function œï(w) :=
R
1
‚Ñì(w) dw. We have for all t ‚àà[a, b],"
REFERENCES,0.37767220902612825,œï(u(t)) ‚â§œï(u(a)) ‚àía + t.
REFERENCES,0.37885985748218526,"Proof of Lemma D.2. First, by definition, we know that œï is increasing since œï‚Ä≤ =
1
‚Ñì> 0. Let
function v be the solution of the following differential equation"
REFERENCES,0.38004750593824227,"v‚Ä≤(t) = ‚Ñì(v(t)) ‚àÄt ‚àà(a, b),
v(a) = u(a).
(14)"
REFERENCES,0.3812351543942993,It is straightforward to verify that the solution to (14) satisfies
REFERENCES,0.3824228028503563,œï(v(t)) ‚àít = œï(u(a)) ‚àía.
REFERENCES,0.3836104513064133,"Then it suffices to show œï(u(t)) ‚â§œï(v(t)) ‚àÄt ‚àà[a, b]. Note that"
REFERENCES,0.3847980997624703,"(œï(u(t)) ‚àíœï(v(t)))‚Ä≤ = œï‚Ä≤(u(t))u‚Ä≤(t) ‚àíœï‚Ä≤(v(t))v‚Ä≤(t) =
u‚Ä≤(t)
‚Ñì(u(t)) ‚àív‚Ä≤(t)"
REFERENCES,0.3859857482185273,"‚Ñì(v(t)) ‚â§0,"
REFERENCES,0.38717339667458434,"where the inequality is because u‚Ä≤(t) ‚â§‚Ñì(u(t)) by the assumption of this lemma and v‚Ä≤(t) = ‚Ñì(v(t))
by (14). Since œï(u(a)) ‚àíœï(v(a)) = 0, we know for all t ‚àà[a, b], œï(u(t)) ‚â§œï(v(t))."
REFERENCES,0.38836104513064135,"With Lemma D.2, one can bound the gradient norm within a small enough neighborhood of a given
point as in the following lemma.
Lemma D.3. Suppose f is (œÅ, L0, LœÅ) smooth for some œÅ, œÅ, L0, LœÅ ‚â•0. For any a > 0 and points
x, y ‚ààdom(f) satisfying ‚à•y ‚àíx‚à•‚â§
a
L0+LœÅ(‚à•‚àáf(x)‚à•+a)œÅ , we have"
REFERENCES,0.38954869358669836,‚à•‚àáf(y)‚à•‚â§‚à•‚àáf(x)‚à•+ a.
REFERENCES,0.39073634204275537,"Proof of Lemma D.3. Denote functions z(t) := (1‚àít)x+ty and u(t) := ‚à•‚àáf(z(t))‚à•for 0 ‚â§t ‚â§1.
Note that for any 0 ‚â§t ‚â§s ‚â§1, by triangle inequality,"
REFERENCES,0.3919239904988123,u(s) ‚àíu(t) ‚â§‚à•‚àáf(z(s)) ‚àí‚àáf(z(t))‚à•.
REFERENCES,0.39311163895486934,"We know that u(t) = ‚à•‚àáf(z(t))‚à•is differentiable since f is second order differentiable2. Then we
have"
REFERENCES,0.39429928741092635,"u‚Ä≤(t) = lim
s‚Üìt
u(s) ‚àíu(t)"
REFERENCES,0.39548693586698336,"s ‚àít
‚â§lim
s‚Üìt
‚à•‚àáf(z(s)) ‚àí‚àáf(z(t))‚à•"
REFERENCES,0.39667458432304037,"s ‚àít
=
lim
s‚Üìt
‚àáf(z(s)) ‚àí‚àáf(z(t)) s ‚àít "
REFERENCES,0.3978622327790974,"‚â§
‚àá2f(z(t))
 ‚à•y ‚àíx‚à•‚â§(L0 + LœÅu(t)œÅ) ‚à•y ‚àíx‚à•."
REFERENCES,0.3990498812351544,"Let œï(w) :=
R w
0
1
(L0+LœÅvœÅ)‚à•y‚àíx‚à•dv. By Lemma D.2, we know that"
REFERENCES,0.4002375296912114,œï (‚à•‚àáf(y)‚à•) = œï(u(1)) ‚â§œï(u(0)) + 1 = œï (‚à•‚àáf(x)‚à•) + 1.
REFERENCES,0.4014251781472684,"Denote œà(w) :=
R w
0
1
(L0+LœÅvœÅ)dv = œï(w) ¬∑ ‚à•y ‚àíx‚à•. We have"
REFERENCES,0.4026128266033254,œà (‚à•‚àáf(y)‚à•) ‚â§œà (‚à•‚àáf(x)‚à•) + ‚à•y ‚àíx‚à•
REFERENCES,0.40380047505938244,"‚â§œà (‚à•‚àáf(x)‚à•) +
a
L0 + LœÅ(‚à•‚àáf(x)‚à•+ a)œÅ"
REFERENCES,0.40498812351543945,"‚â§
Z ‚à•‚àáf(x)‚à• 0"
REFERENCES,0.40617577197149646,"1
(L0 + LœÅvœÅ)dv +
Z ‚à•‚àáf(x)‚à•+a"
REFERENCES,0.40736342042755347,‚à•‚àáf(x)‚à•
REFERENCES,0.4085510688836104,"1
(L0 + LœÅvœÅ)dv"
REFERENCES,0.40973871733966744,=œà(‚à•‚àáf(x)‚à•+ a)
REFERENCES,0.41092636579572445,"Since œà is increasing, we have ‚à•‚àáf(y)‚à•‚â§‚à•‚àáf(x)‚à•+ a."
REFERENCES,0.41211401425178146,"2Here we assume u(t) > 0 for 0 < t < 1. Otherwise, we can define tm = sup{0 < t < 1 | u(t) = 0} and
consider the interval [tm, 1] instead."
REFERENCES,0.41330166270783847,"With Lemma D.3, we are ready to prove Lemma 3.4."
REFERENCES,0.4144893111638955,"Proof of Lemma 3.4. Denote z(t) := (1 ‚àít)x + ty for some y ‚ààRd satisfying ‚à•y ‚àíx‚à•‚â§
a
L0+LœÅ(‚à•‚àáf(x)‚à•+a)œÅ . We first show y ‚ààdom(f) by contradiction. Suppose y /‚ààdom(f), let
us define tb := inf{0 ‚â§t ‚â§1 | z(t) /‚ààX} and zb := z(tb). Then we know zb is a boundary point of
X. Since f is a closed function with an open domain, we have"
REFERENCES,0.4156769596199525,"lim
t‚Üëtb f(z(t)) = ‚àû.
(15)"
REFERENCES,0.4168646080760095,"On the other hand, by the definition of tb, we know z(t) ‚ààX for every 0 ‚â§t < tb. Then by
Lemma D.3, for all 0 ‚â§t < tb, we have ‚à•‚àáf(z(t))‚à•‚â§‚à•‚àáf(x)‚à•+ a. Therefore for all 0 ‚â§t < tb"
REFERENCES,0.4180522565320665,"f(z(t)) ‚â§f(x) +
Z t 0"
REFERENCES,0.4192399049881235,"‚àáf(z(s)), y ‚àíx

ds"
REFERENCES,0.42042755344418054,"‚â§f(x) + (‚à•‚àáf(x)‚à•+ a) ¬∑ ‚à•y ‚àíx‚à•
<‚àû,"
REFERENCES,0.42161520190023755,which contradicts with (15). Therefore we have shown y ‚ààdom(f). We have
REFERENCES,0.42280285035629456,‚à•‚àáf(y) ‚àí‚àáf(x)‚à•= Z 1
REFERENCES,0.42399049881235157,"0
‚àá2f(z(t)) ¬∑ (y ‚àíx) dt"
REFERENCES,0.4251781472684085,"‚â§‚à•y ‚àíx‚à•¬∑
Z 1"
REFERENCES,0.42636579572446553,"0
(L0 + LœÅ ‚à•‚àáf(z(t))‚à•œÅ) dt"
REFERENCES,0.42755344418052255,‚â§‚à•y ‚àíx‚à•¬∑ (L0 + LœÅ ¬∑ (‚à•‚àáf(x)‚à•+ a)œÅ)
REFERENCES,0.42874109263657956,where the last inequality is due to Lemma D.3.
REFERENCES,0.42992874109263657,"D.3
Proof of Lemma 5.1"
REFERENCES,0.4311163895486936,"Proof of Lemma 5.1. Denote G := ‚à•‚àáf(x)‚à•and L := 3L0 + 4LœÅGœÅ. Let y := x ‚àí
1
2L‚àáf(x).
Then we have"
REFERENCES,0.4323040380047506,‚à•y ‚àíx‚à•= G
REFERENCES,0.4334916864608076,"2L =
G
6L0 + 8LœÅGœÅ ‚â§min"
REFERENCES,0.4346793349168646,"(
1
5LœÅGœÅ‚àí1 ,
1
5(LœÅ‚àí1
0
LœÅ)1/œÅ ) =: r,"
REFERENCES,0.4358669833729216,"where the inequality can be easily verified considering both cases of G ‚â§(L0/LœÅ)1/œÅ and G ‚â•
(L0/LœÅ)1/œÅ. Then based on Corollary 5.2, we have y ‚ààdom(f) and"
REFERENCES,0.43705463182897863,"f ‚àó‚àíf(x) ‚â§f(y) ‚àíf(x) ‚â§

‚àáf(x), y ‚àíx

+ L"
REFERENCES,0.43824228028503565,2 ‚à•y ‚àíx‚à•2 = 3LG2
REFERENCES,0.43942992874109266,"8
‚â§LG2 3
,"
REFERENCES,0.44061757719714967,which completes the proof.
REFERENCES,0.4418052256532066,"D.4
Proof of Corollary 5.2"
REFERENCES,0.44299287410926363,"Proof of Corollary 5.2. First, Lemma 3.4 states that for any a > 0,"
REFERENCES,0.44418052256532065,"‚à•y ‚àíx‚à•‚â§
a
L0+LœÅ¬∑(‚à•‚àáf(x)‚à•+a)œÅ =‚áí‚à•‚àáf(y)‚àí‚àáf(x)‚à•‚â§(L0+LœÅ ¬∑ (‚à•‚àáf(x)‚à•+a)œÅ) ‚à•y ‚àíx‚à•."
REFERENCES,0.44536817102137766,"If ‚à•‚àáf(x)‚à•‚â§G, we choose a = max{G, (L0/LœÅ)1/œÅ}. Then it is straightforward to verify that"
REFERENCES,0.44655581947743467,"a
L0 + LœÅ ¬∑ (‚à•‚àáf(x)‚à•+ a)œÅ ‚â•min"
REFERENCES,0.4477434679334917,"(
1
5LœÅGœÅ‚àí1 ,
1
5(LœÅ‚àí1
0
LœÅ)1/œÅ ) =: r,"
REFERENCES,0.4489311163895487,L0 + LœÅ ¬∑ (‚à•‚àáf(x)‚à•+ a)œÅ ‚â§3L0 + 4LœÅGœÅ =: L.
REFERENCES,0.4501187648456057,"Therefore we have shown for any x, y satisfying ‚à•y ‚àíx‚à•‚â§r,"
REFERENCES,0.4513064133016627,"‚à•‚àáf(y) ‚àí‚àáf(x)‚à•‚â§L ‚à•y ‚àíx‚à•.
(16)"
REFERENCES,0.4524940617577197,"Next, let z(t) := (1 ‚àít)x + ty for 0 ‚â§t ‚â§1. We know"
REFERENCES,0.45368171021377673,"f(y) ‚àíf(x) =
Z 1 0"
REFERENCES,0.45486935866983375,"‚àáf(z(t), y ‚àíx

dt =
Z 1 0"
REFERENCES,0.45605700712589076,"‚àáf(x), y ‚àíx

+

‚àáf(z(t)) ‚àí‚àáf(x), y ‚àíx

dt"
REFERENCES,0.45724465558194777,"‚â§

‚àáf(x), y ‚àíx

+
Z 1"
REFERENCES,0.4584323040380047,"0
L ‚à•z(t) ‚àíx‚à•‚à•y ‚àíx‚à•dt"
REFERENCES,0.45961995249406173,"=

‚àáf(x), y ‚àíx

+ L ‚à•y ‚àíx‚à•2
Z 1"
T DT,0.46080760095011875,"0
t dt"
T DT,0.46199524940617576,"=

‚àáf(x), y ‚àíx

+ 1"
T DT,0.46318289786223277,"2L ‚à•y ‚àíx‚à•2 ,"
T DT,0.4643705463182898,where the inequality is due to (16).
T DT,0.4655581947743468,"E
Convergence analysis of Adam"
T DT,0.4667458432304038,"In this section, we provide detailed convergence analysis of Adam. We will focus on proving
Theorem 4.1 under the bounded noise assumption (Assumption 3) in most parts of this section except
Appendix E.6 where we will show how to generalize the results to noise with sub-Gaussian norm
(Assumption 4) and provide the proof of Theorem 4.2."
T DT,0.4679334916864608,"For completeness, we repeat some important technical definitions here. First, we define"
T DT,0.4691211401425178,"œµt := ÀÜmt ‚àí‚àáf(xt)
(17)"
T DT,0.47030878859857483,"as the deviation of the re-scaled momentum from the actual gradient. Given a large enough constant
G defined in Theorem 4.1, denoting F =
G2
3(3L0+4LœÅGœÅ), we formally define the stopping time œÑ as"
T DT,0.47149643705463185,"œÑ := min{t | f(xt) ‚àíf ‚àó> F} ‚àß(T + 1),"
T DT,0.47268408551068886,"i.e., œÑ is the first time when the sub-optimality gap is strictly greater than F, truncated at T + 1 to
make sure it is bounded in order to apply Lemma C.2. Based on Lemma 5.1 and the discussions
below it, we know that if t < œÑ, we have both f(xt) ‚àíf ‚àó‚â§F and ‚à•‚àáf(xt)‚à•‚â§G. It is clear to see
that œÑ is a stopping time3 with respect to {Œæt}t‚â•1 because the event {œÑ ‚â•t} is a function of {Œæs}s<t
and independent of {Œæs}s‚â•t. Next, let"
T DT,0.47387173396674587,"ht :=
Œ∑
‚àöÀÜvt + Œª"
T DT,0.4750593824228028,"be the stepsize vector and Ht := diag(ht) be the diagonal stepsize matrix. Then the update rule can
be written as"
T DT,0.47624703087885983,xt+1 = xt ‚àíht ‚äôÀÜmt = xt ‚àíHt ÀÜmt.
T DT,0.47743467933491684,"Finally, as in Corollary 5.2 and Lemma 5.3, we define the following constants."
T DT,0.47862232779097386,r := min
T DT,0.47980997624703087,"(
1
5LœÅGœÅ‚àí1 ,
1
5(LœÅ‚àí1
0
LœÅ)1/œÅ ) ,"
T DT,0.4809976247030879,"L := 3L0 + 4LœÅGœÅ,
D := 2G/Œª."
T DT,0.4821852731591449,"E.1
Equivalent update rule of Adam"
T DT,0.4833729216152019,"The bias correction steps in Lines 7‚Äì8 make Algorithm 1 a bit complicated. In the following
proposition, we provide an equivalent yet simpler update rule of Adam."
T DT,0.4845605700712589,"3Indeed, œÑ ‚àí1 is also a stopping time because ‚àáf(xt) only depends on {Œæs}s<t, but that is unnecessary for
our analysis."
T DT,0.4857482185273159,"Proposition E.1. Denote Œ±t =
Œ≤
1‚àí(1‚àíŒ≤)t and Œ±sq
t =
Œ≤sq
1‚àí(1‚àíŒ≤sq)t . Then the update rule in Algorithm 1
is equivalent to"
T DT,0.48693586698337293,"ÀÜmt = (1 ‚àíŒ±t) ÀÜmt‚àí1 + Œ±t‚àáf(xt, Œæt),"
T DT,0.48812351543942994,"ÀÜvt = (1 ‚àíŒ±sq
t )ÀÜvt‚àí1 + Œ±sq
t (‚àáf(xt, Œæt))2,
(18)"
T DT,0.48931116389548696,"xt+1 = xt ‚àí
Œ∑
‚àöÀÜvt + Œª ‚äôÀÜmt,"
T DT,0.49049881235154397,"where initially we set ÀÜm1 = ‚àáf(x1, Œæ1) and ÀÜv1 = (‚àáf(x1, Œæ1))2. Note that since 1‚àíŒ±1 = 1‚àíŒ±sq
1 =
0, there is no need to define ÀÜm0 and ÀÜv0."
T DT,0.4916864608076009,"Proof of Proposition E.1. Denote Zt = 1 ‚àí(1 ‚àíŒ≤)t. Then we know Œ±t = Œ≤/Zt and mt = Zt ÀÜmt.
By the momentum update rule in Algorithm 1, we have"
T DT,0.49287410926365793,"Zt ÀÜmt = (1 ‚àíŒ≤)Zt‚àí1 ÀÜmt‚àí1 + Œ≤‚àáf(xt, Œæt)."
T DT,0.49406175771971494,Note that Zt satisfies the following property
T DT,0.49524940617577196,(1 ‚àíŒ≤)Zt‚àí1 = 1 ‚àíŒ≤ ‚àí(1 ‚àíŒ≤)t = Zt ‚àíŒ≤.
T DT,0.49643705463182897,Then we have
T DT,0.497624703087886,ÀÜmt =Zt ‚àíŒ≤
T DT,0.498812351543943,"Zt
¬∑ ÀÜmt‚àí1 + Œ≤"
T DT,0.5,"Zt
¬∑ ‚àáf(xt, Œæt)"
T DT,0.501187648456057,"=(1 ‚àíŒ±t) ÀÜmt‚àí1 + Œ±t‚àáf(xt, Œæt)."
T DT,0.502375296912114,"Next, we verify the initial condition. By Algorithm 1, since we set m0 = 0, we have m1 =
Œ≤‚àáf(x1, Œæ1). Therefore we have ÀÜm1 = m1/Z1 = ‚àáf(x1, Œæ1) since Z1 = Œ≤. Then the proof is
completed by applying the same analysis on vt and ÀÜvt."
T DT,0.503562945368171,"E.2
Useful lemmas for Adam"
T DT,0.504750593824228,"In this section, we list several useful lemmas for the convergence analysis. Their proofs are all
deferred in Appendix E.5."
T DT,0.505938242280285,"First note that when t < œÑ, all the quantities in the algorithm are well bounded. In particular, we have
the following lemma.
Lemma E.2. If t < œÑ, we have"
T DT,0.5071258907363421,"‚à•‚àáf(xt)‚à•‚â§G,
‚à•‚àáf(xt, Œæt)‚à•‚â§G + œÉ,
‚à•ÀÜmt‚à•‚â§G + œÉ,"
T DT,0.5083135391923991,"ÀÜvt ‚™Ø(G + œÉ)2,
Œ∑
G + œÉ + Œª ‚™Øht ‚™ØŒ∑ Œª."
T DT,0.5095011876484561,"Next, we provide a useful lemma regarding the time-dependent re-scaled momentum parameters in
(18)."
T DT,0.5106888361045131,"Lemma E.3. Let Œ±t =
Œ≤
1‚àí(1‚àíŒ≤)t , then for all T ‚â•2, we have PT
t=2 Œ±2
t ‚â§3(1 + Œ≤2T)."
T DT,0.5118764845605701,"In the next lemma, we provide an almost sure bound on œµt in order to apply Azuma-Hoeffding
inequality (Lemma C.1)."
T DT,0.5130641330166271,"Lemma E.4. Denote Œ≥t‚àí1 = (1 ‚àíŒ±t)(œµt‚àí1 + ‚àáf(xt‚àí1) ‚àí‚àáf(xt)). Choosing Œ∑ ‚â§min
n
r
D, œÉŒ≤"
T DT,0.5142517814726841,"DL
o
,"
T DT,0.5154394299287411,"if t ‚â§œÑ, we have ‚à•œµt‚à•‚â§2œÉ and ‚à•Œ≥t‚àí1‚à•‚â§2œÉ."
T DT,0.5166270783847982,"Finally, the following lemma hides messy calculations and will be useful in the contradiction
argument.
Lemma E.5. Denote"
T DT,0.517814726840855,I1 :=8G Œ∑Œª
T DT,0.5190023752969121,"
‚àÜ1Œª + 8œÉ2
 Œ∑"
T DT,0.5201900237529691,"Œ≤ + Œ∑Œ≤T

+ 20œÉ2Œ∑
p"
T DT,0.5213776722090261,"(1/Œ≤2 + T)Œπ

,"
T DT,0.5225653206650831,I2 :=8GF
T DT,0.5237529691211401,"Œ∑
= 8G3 3Œ∑L."
T DT,0.5249406175771971,"Under the parameter choices in either Theorem 4.1 or Theorem 4.2, we have I1 ‚â§I2 and I1/T ‚â§œµ2."
T DT,0.5261282660332541,"E.3
Proof of Theorem 4.1"
T DT,0.5273159144893111,"Before proving the main theorems, several important lemmas are needed. First, we provide a descent
lemma for Adam.
Lemma E.6. If t < œÑ, choosing G ‚â•œÉ + Œª and Œ∑ ‚â§min
 r D, Œª"
L,0.5285035629453682,"6L
	
, we have"
L,0.5296912114014252,f(xt+1) ‚àíf(xt) ‚â§‚àíŒ∑
L,0.5308788598574822,4G ‚à•‚àáf(xt)‚à•2 + Œ∑
L,0.5320665083135392,Œª ‚à•œµt‚à•2 .
L,0.5332541567695962,"Proof of Lemma E.6. By Lemma E.2, we have if t < œÑ,"
L,0.5344418052256532,"Œ∑I
2G ‚â§
Œ∑I
G + œÉ + Œª ‚™ØHt ‚™ØŒ∑I"
L,0.5356294536817102,"Œª .
(19)"
L,0.5368171021377672,"Since we choose Œ∑ ‚â§
r
D, by Lemma 5.3, we have ‚à•xt+1 ‚àíxt‚à•‚â§r if t < œÑ. Then we can apply
Corollary 5.2 to show that for any t < œÑ,"
L,0.5380047505938242,"f(xt+1) ‚àíf(xt) ‚â§

‚àáf(xt), xt+1 ‚àíxt

+ L"
L,0.5391923990498813,2 ‚à•xt+1 ‚àíxt‚à•2
L,0.5403800475059383,= ‚àí(‚àáf(xt))‚ä§Ht ÀÜmt + L
L,0.5415676959619953,"2 ÀÜm‚ä§
t H2
t ÀÜmt"
L,0.5427553444180523,"‚â§‚àí‚à•‚àáf(xt)‚à•2
Ht ‚àí(‚àáf(xt))‚ä§Htœµt + Œ∑L"
L,0.5439429928741093,"2Œª ‚à•ÀÜmt‚à•2
Ht ‚â§‚àí2"
L,0.5451306413301663,"3 ‚à•‚àáf(xt)‚à•2
Ht + 3"
L,0.5463182897862233,"4 ‚à•œµt‚à•2
Ht + Œ∑L Œª"
L,0.5475059382422803,"
‚à•‚àáf(xt)‚à•2
Ht + ‚à•œµt‚à•2
Ht  ‚â§‚àí1"
L,0.5486935866983373,"2 ‚à•‚àáf(xt)‚à•2
Ht + ‚à•œµt‚à•2
Ht ‚â§‚àíŒ∑"
L,0.5498812351543944,4G ‚à•‚àáf(xt)‚à•2 + Œ∑
L,0.5510688836104513,"Œª ‚à•œµt‚à•2 ,"
L,0.5522565320665083,"where the second inequality uses (17) and (19); the third inequality is due to Young‚Äôs inequality
a‚ä§Ab ‚â§1"
L,0.5534441805225653,"3 ‚à•a‚à•2
A + 3"
L,0.5546318289786223,"4 ‚à•b‚à•2
A and ‚à•a + b‚à•2
A ‚â§2 ‚à•a‚à•2
A + 2 ‚à•b‚à•A for any PSD matrix A; the second last
inequality uses Œ∑ ‚â§
Œª
6L; and the last inequality is due to (19)."
L,0.5558194774346793,"The following lemma bounds the sum of the error term ‚à•œµt‚à•2 before the stopping time œÑ. Since its
proof is complicated, we defer it in Appendix E.4."
L,0.5570071258907363,"Lemma E.7. If G ‚â•2œÉ and Œ∑ ‚â§min
n
r
D, Œª3/2Œ≤"
L,0.5581947743467933,"6L
‚àö G, œÉŒ≤"
L,0.5593824228028503,"DL
o
, with probability 1 ‚àíŒ¥, œÑ‚àí1
X"
L,0.5605700712589073,"t=1
‚à•œµt‚à•2 ‚àíŒª"
L,0.5617577197149644,8G ‚à•‚àáf(xt)‚à•2 ‚â§8œÉ2 (1/Œ≤ + Œ≤T) + 20œÉ2p
L,0.5629453681710214,(1/Œ≤2 + T) log(1/Œ¥).
L,0.5641330166270784,"Combining Lemma E.6 and Lemma E.7, we obtain the following useful lemma, which simultaneously
bounds f(xt) ‚àíf ‚àóand PœÑ‚àí1
t=1 ‚à•‚àáf(xt)‚à•2."
L,0.5653206650831354,"Lemma E.8. If G ‚â•2 max{Œª, œÉ} and Œ∑ ‚â§min
n
r
D, Œª3/2Œ≤"
L,0.5665083135391924,"6L
‚àö G, œÉŒ≤"
L,0.5676959619952494,"DL
o
, then with probability at least
1 ‚àíŒ¥, œÑ‚àí1
X"
L,0.5688836104513064,"t=1
‚à•‚àáf(xt)‚à•2 + 8G"
L,0.5700712589073634,Œ∑ (f(xœÑ) ‚àíf ‚àó) ‚â§8G Œ∑Œª
L,0.5712589073634204,"
‚àÜ1Œª + 8œÉ2
 Œ∑"
L,0.5724465558194775,"Œ≤ + Œ∑Œ≤T

+ 20œÉ2Œ∑
p"
L,0.5736342042755345,"(1/Œ≤2 + T) log(1/Œ¥)

."
L,0.5748218527315915,"Proof of Lemma E.8. By telescoping, Lemma E.6 implies œÑ‚àí1
X"
L,0.5760095011876485,"t=1
2 ‚à•‚àáf(xt)‚à•2 ‚àí8G"
L,0.5771971496437055,Œª ‚à•œµt‚à•2 ‚â§8G
L,0.5783847980997625,Œ∑ (f(x1) ‚àíf(xœÑ)) ‚â§8‚àÜ1G
L,0.5795724465558195,"Œ∑
.
(20)"
L,0.5807600950118765,"Lemma E.7 could be written as œÑ‚àí1
X t=1"
G,0.5819477434679335,8G
G,0.5831353919239906,Œª ‚à•œµt‚à•2 ‚àí‚à•‚àáf(xt)‚à•2 ‚â§8G Œª
G,0.5843230403800475,"
8œÉ2 (1/Œ≤ + Œ≤T) + 20œÉ2p"
G,0.5855106888361045,"(1/Œ≤2 + T) log(1/Œ¥)

.
(21)"
G,0.5866983372921615,(20) + (21) gives the desired result.
G,0.5878859857482185,"With Lemma E.8, we are ready to complete the contradiction argument and the convergence analysis.
Below we provide the proof of Theorem 4.1."
G,0.5890736342042755,"Proof of Theorem 4.1. According to Lemma E.8, there exists some event E with P(E) ‚â•1 ‚àíŒ¥, such
that conditioned on E, we have"
G,0.5902612826603325,8G
G,0.5914489311163895,Œ∑ (f(xœÑ) ‚àíf ‚àó) ‚â§8G Œ∑Œª
G,0.5926365795724465,"
‚àÜ1Œª + 8œÉ2
 Œ∑"
G,0.5938242280285035,"Œ≤ + Œ∑Œ≤T

+ 20œÉ2Œ∑
p"
G,0.5950118764845606,"(1/Œ≤2 + T) log(1/Œ¥)

=: I1. (22)"
G,0.5961995249406176,"By the definition of œÑ, if œÑ ‚â§T, we have"
G,0.5973871733966746,8G
G,0.5985748218527316,Œ∑ (f(xœÑ) ‚àíf ‚àó) > 8GF
G,0.5997624703087886,"Œ∑
= 8G3"
G,0.6009501187648456,3Œ∑L =: I2.
G,0.6021377672209026,"Based on Lemma E.5, we have I1 ‚â§I2, which leads to a contradiction. Therefore, we must have
œÑ = T + 1 conditioned on E. Then, Lemma E.8 also implies that under E,"
T,0.6033254156769596,"1
T"
T,0.6045130641330166,"T ‚àí1
X"
T,0.6057007125890737,"t=1
‚à•‚àáf(xt)‚à•2 ‚â§I1"
T,0.6068883610451307,"T ‚â§œµ2,"
T,0.6080760095011877,where the last inequality is due to Lemma E.5.
T,0.6092636579572447,"E.4
Proof of Lemma E.7"
T,0.6104513064133017,"In order to prove Lemma E.7, we need the following several lemmas.
Lemma E.9. Denote Œ≥t‚àí1 = (1 ‚àíŒ±t)(œµt‚àí1 + ‚àáf(xt‚àí1) ‚àí‚àáf(xt)). If G ‚â•2œÉ and Œ∑ ‚â§"
T,0.6116389548693587,"min
n
r
D, Œª3/2Œ≤"
L,0.6128266033254157,"6L
‚àö G"
L,0.6140142517814727,"o
, we have for every 2 ‚â§t ‚â§œÑ,"
L,0.6152019002375297,"‚à•œµt‚à•2 ‚â§

1 ‚àíŒ±t 2"
L,0.6163895486935868,"
‚à•œµt‚àí1‚à•2 + ŒªŒ≤"
L,0.6175771971496437,"16G ‚à•‚àáf(xt‚àí1)‚à•2 + Œ±2
tœÉ2 + 2Œ±t"
L,0.6187648456057007,"Œ≥t‚àí1, ‚àáf(xt, Œæt) ‚àí‚àáf(xt)

."
L,0.6199524940617577,"Proof of Lemma E.9. According to the update rule (18), we have"
L,0.6211401425178147,"œµt =(1 ‚àíŒ±t)(œµt‚àí1 + ‚àáf(xt‚àí1) ‚àí‚àáf(xt)) + Œ±t(‚àáf(xt, Œæt) ‚àí‚àáf(xt))
=Œ≥t‚àí1 + Œ±t(‚àáf(xt, Œæt) ‚àí‚àáf(xt)).
(23)"
L,0.6223277909738717,"Since we choose Œ∑ ‚â§
r
D, by Lemma 5.3, we have ‚à•xt ‚àíxt‚àí1‚à•‚â§r if t ‚â§œÑ. Therefore by
Corollary 5.2, for any 2 ‚â§t ‚â§œÑ,"
L,0.6235154394299287,‚à•‚àáf(xt‚àí1) ‚àí‚àáf(xt)‚à•‚â§L ‚à•xt ‚àíxt‚àí1‚à•‚â§Œ∑L
L,0.6247030878859857,Œª ‚à•ÀÜmt‚àí1‚à•‚â§Œ∑L
L,0.6258907363420427,"Œª (‚à•‚àáf(xt‚àí1)‚à•+ ‚à•œµt‚àí1‚à•) ,
(24)"
L,0.6270783847980997,Therefore
L,0.6282660332541568,‚à•Œ≥t‚àí1‚à•2 = ‚à•(1 ‚àíŒ±t)œµt‚àí1 + (1 ‚àíŒ±t)(‚àáf(xt‚àí1) ‚àí‚àáf(xt))‚à•2
L,0.6294536817102138,"‚â§(1 ‚àíŒ±t)2 (1 + Œ±t) ‚à•œµt‚àí1‚à•2 + (1 ‚àíŒ±t)2

1 + 1 Œ±t"
L,0.6306413301662708,"
‚à•‚àáf(xt‚àí1) ‚àí‚àáf(xt)‚à•2"
L,0.6318289786223278,‚â§(1 ‚àíŒ±t) ‚à•œµt‚àí1‚à•2 + 1
L,0.6330166270783848,"Œ±t
‚à•‚àáf(xt‚àí1) ‚àí‚àáf(xt)‚à•2"
L,0.6342042755344418,‚â§(1 ‚àíŒ±t) ‚à•œµt‚àí1‚à•2 + 2Œ∑2L2 Œª2Œ≤
L,0.6353919239904988,"
‚à•‚àáf(xt‚àí1)‚à•2 + ‚à•œµt‚àí1‚à•2"
L,0.6365795724465558,"‚â§

1 ‚àíŒ±t 2"
L,0.6377672209026128,"
‚à•œµt‚àí1‚à•2 + ŒªŒ≤"
L,0.6389548693586699,"16G ‚à•‚àáf(xt‚àí1)‚à•2 ,"
L,0.6401425178147269,"where the first inequality uses Young‚Äôs inequality ‚à•a + b‚à•2 ‚â§(1 + u) ‚à•a‚à•2 + (1 + 1/u) ‚à•b‚à•2 for any
u > 0; the second inequality is due to
(1 ‚àíŒ±t)2 (1 + Œ±t) = (1 ‚àíŒ±t)(1 ‚àíŒ±2
t) ‚â§(1 ‚àíŒ±t),"
L,0.6413301662707839,"(1 ‚àíŒ±t)2

1 + 1 Œ±t 
= 1"
L,0.6425178147268409,"Œ±t
(1 ‚àíŒ±t)2 (1 + Œ±t) ‚â§1"
L,0.6437054631828979,"Œ±t
(1 ‚àíŒ±t) ‚â§1 Œ±t
;"
L,0.6448931116389549,the third inequality uses (24) and Young‚Äôs inequality; and in the last inequality we choose Œ∑ ‚â§Œª3/2Œ≤
L,0.6460807600950119,"6L
‚àö G,"
L,0.6472684085510689,which implies 2Œ∑2L2
L,0.6484560570071259,"Œª2Œ≤
‚â§
ŒªŒ≤
16G ‚â§Œ≤ 2 ‚â§Œ±t"
L,0.649643705463183,"2 . Then by (23), we have"
L,0.6508313539192399,‚à•œµt‚à•2 = ‚à•Œ≥t‚àí1‚à•2 + 2Œ±t
L,0.6520190023752969,"Œ≥t‚àí1, ‚àáf(xt, Œæt) ‚àí‚àáf(xt)

+ Œ±2
t ‚à•‚àáf(xt, Œæt) ‚àí‚àáf(xt)‚à•2"
L,0.6532066508313539,"‚â§

1 ‚àíŒ±t 2"
L,0.6543942992874109,"
‚à•œµt‚àí1‚à•2 + ŒªŒ≤"
L,0.6555819477434679,"16G ‚à•‚àáf(xt‚àí1)‚à•2 + Œ±2
tœÉ2 + 2Œ±t"
L,0.6567695961995249,"Œ≥t‚àí1, ‚àáf(xt, Œæt) ‚àí‚àáf(xt)

."
L,0.6579572446555819,Lemma E.10. Denote Œ≥t‚àí1 = (1 ‚àíŒ±t)(œµt‚àí1 + ‚àáf(xt‚àí1) ‚àí‚àáf(xt)). If G ‚â•2œÉ and Œ∑ ‚â§
L,0.6591448931116389,"min
n
r
D, œÉŒ≤"
L,0.6603325415676959,"DL
o
, with probability 1 ‚àíŒ¥, œÑ
X"
L,0.661520190023753,"t=2
Œ±t"
L,0.66270783847981,"Œ≥t‚àí1, ‚àáf(xt, Œæt) ‚àí‚àáf(xt)

‚â§5œÉ2p"
L,0.663895486935867,(1 + Œ≤2T) log(1/Œ¥).
L,0.665083135391924,"Proof of Lemma E.10. First note that œÑ
X"
L,0.666270783847981,"t=2
Œ±t"
L,0.667458432304038,"Œ≥t‚àí1, ‚àáf(xt, Œæt) ‚àí‚àáf(xt)

= T
X"
L,0.668646080760095,"t=2
Œ±t"
L,0.669833729216152,"Œ≥t‚àí11œÑ‚â•t, ‚àáf(xt, Œæt) ‚àí‚àáf(xt)

."
L,0.671021377672209,"Since œÑ is a stopping time, we know that 1œÑ‚â•t is a function of {Œæs}s<t. Also, by definition, we know
Œ≥t‚àí1 is a function of {Œæs}s<t. Then, denoting"
L,0.672209026128266,Xt = Œ±t
L,0.6733966745843231,"Œ≥t‚àí11œÑ‚â•t, ‚àáf(xt, Œæt) ‚àí‚àáf(xt)

,"
L,0.6745843230403801,"we know that Et‚àí1[Xt] = 0, which implies {Xt}t‚â§T is a martingale difference sequence. Also, by
Assumption 3 and Lemma E.4, we can show that for all 2 ‚â§t ‚â§T,
|Xt| ‚â§Œ±tœÉ ‚à•Œ≥t‚àí11œÑ‚â•t‚à•‚â§2Œ±tœÉ2.
Then by the Azuma-Hoeffding inequality (Lemma C.1), we have with probability at least 1 ‚àíŒ¥, T
X"
L,0.6757719714964371,"t=2
Xt ‚â§2œÉ2"
L,0.6769596199524941,"v
u
u
t2 T
X"
L,0.6781472684085511,"t=2
Œ±2
t log(1/Œ¥) ‚â§5œÉ2p"
L,0.6793349168646081,"(1 + Œ≤2T) log(1/Œ¥),"
L,0.6805225653206651,where in the last inequality we use Lemma E.3.
L,0.6817102137767221,Then we are ready to prove Lemma E.7.
L,0.6828978622327792,"Proof of Lemma E.7. By Lemma E.9, we have for every 2 ‚â§t ‚â§œÑ,
Œ≤"
L,0.684085510688836,2 ‚à•œµt‚àí1‚à•2 ‚â§Œ±t
L,0.6852731591448931,2 ‚à•œµt‚àí1‚à•2 ‚â§‚à•œµt‚àí1‚à•2 ‚àí‚à•œµt‚à•2 + ŒªŒ≤
L,0.6864608076009501,"16G ‚à•‚àáf(xt‚àí1)‚à•2 + Œ±2
tœÉ2 + 2Œ±t"
L,0.6876484560570071,"Œ≥t‚àí1, ‚àáf(xt, Œæt) ‚àí‚àáf(xt)

."
L,0.6888361045130641,"Taking a summation over t from 2 to œÑ, we have
œÑ
X t=2 Œ≤"
L,0.6900237529691211,2 ‚à•œµt‚àí1‚à•2 ‚àíŒªŒ≤
L,0.6912114014251781,"16G ‚à•‚àáf(xt‚àí1)‚à•2 ‚â§‚à•œµ1‚à•2 ‚àí‚à•œµœÑ‚à•2 + œÉ2
œÑ
X"
L,0.6923990498812351,"t=2
Œ±2
t + 10œÉ2p"
L,0.6935866983372921,(1 + Œ≤2T) log(1/Œ¥)
L,0.6947743467933492,‚â§4œÉ2(1 + Œ≤2T) + 10œÉ2p
L,0.6959619952494062,"(1 + Œ≤2T) log(1/Œ¥),"
L,0.6971496437054632,"where the first inequality uses Lemma E.10; and the second inequality uses Lemma E.3 and ‚à•œµ1‚à•2 =
‚à•‚àáf(x1, Œæ1) ‚àí‚àáf(x1)‚à•2 ‚â§œÉ2. Then we complete the proof by multiplying both sides by 2/Œ≤."
L,0.6983372921615202,"E.5
Omitted proofs for Adam"
L,0.6995249406175772,"In this section, we provide all the omitted proofs for Adam including those of Lemma 5.3 and all the
lemmas in Appendix E.2."
L,0.7007125890736342,"Proof of Lemma 5.3. According to Lemma E.2, if t < œÑ,"
L,0.7019002375296912,‚à•xt+1 ‚àíxt‚à•‚â§Œ∑
L,0.7030878859857482,Œª ‚à•ÀÜmt‚à•‚â§Œ∑(G + œÉ)
L,0.7042755344418052,"Œª
‚â§2Œ∑G Œª ."
L,0.7054631828978623,"Proof of Lemma E.2. By definition of œÑ, we have ‚à•‚àáf(xt)‚à•‚â§G if t < œÑ. Then Assumption 3
directly implies ‚à•‚àáf(xt, Œæt)‚à•‚â§G + œÉ. ‚à•ÀÜmt‚à•can be bounded by a standard induction argument as
follows. First note that ‚à•ÀÜm1‚à•= ‚à•‚àáf(x1, Œæ1)‚à•‚â§G + œÉ. Supposing ‚à•ÀÜmk‚àí1‚à•‚â§G + œÉ for some
k < œÑ, then we have"
L,0.7066508313539193,"‚à•ÀÜmk‚à•‚â§(1 ‚àíŒ±k) ‚à•ÀÜmk‚àí1‚à•+ Œ±k ‚à•‚àáf(xk, Œæk)‚à•‚â§G + œÉ."
L,0.7078384798099763,"Then we can show ÀÜvt ‚™Ø(G + œÉ)2 in a similar way noting that (‚àáf(xt, Œæt))2 ‚™Ø‚à•‚àáf(xt, Œæt)‚à•2 ‚â§
(G + œÉ)2. Given the bound on ÀÜvt, it is straight forward to bound the stepsize ht."
L,0.7090261282660333,"Proof of Lemma E.3. First, when t ‚â•1/Œ≤, we have (1 ‚àíŒ≤)t ‚â§1/e. Therefore,
X"
L,0.7102137767220903,"1/Œ≤‚â§t‚â§T
(1 ‚àí(1 ‚àíŒ≤)t)‚àí2 ‚â§(1 ‚àí1/e)‚àí2T ‚â§3T."
L,0.7114014251781473,"Next, note that when t < 1/Œ≤, we have (1 ‚àíŒ≤)t ‚â§1 ‚àí1"
L,0.7125890736342043,"2Œ≤t. Then we have
X"
L,0.7137767220902613,"2‚â§t<1/Œ≤
(1 ‚àí(1 ‚àíŒ≤)t)‚àí2 ‚â§4 Œ≤2
X"
L,0.7149643705463183,"t‚â•2
t‚àím ‚â§3 Œ≤2 ."
L,0.7161520190023754,"Therefore we have PT
t=2 Œ±2
t ‚â§3(1 + Œ≤2T)."
L,0.7173396674584323,"Proof of Lemma E.4. We prove ‚à•œµt‚à•‚â§2œÉ for all t ‚â§œÑ by induction. First, note that for t = 1, we
have
‚à•œµ1‚à•= ‚à•‚àáf(x1, Œæ1) ‚àí‚àáf(x1)‚à•‚â§œÉ ‚â§2œÉ.
Now suppose ‚à•œµt‚àí1‚à•‚â§2œÉ for some 2 ‚â§t ‚â§œÑ. According to the update rule (18), we have"
L,0.7185273159144893,"œµt =(1 ‚àíŒ±t)(œµt‚àí1 + ‚àáf(xt‚àí1) ‚àí‚àáf(xt)) + Œ±t(‚àáf(xt, Œæt) ‚àí‚àáf(xt)),"
L,0.7197149643705463,which implies
L,0.7209026128266033,‚à•œµt‚à•‚â§(2 ‚àíŒ±t)œÉ + ‚à•‚àáf(xt‚àí1) ‚àí‚àáf(xt)‚à•.
L,0.7220902612826603,"Since we choose Œ∑ ‚â§
r
D, by Lemma 5.3, we have ‚à•xt ‚àíxt‚àí1‚à•‚â§Œ∑D ‚â§r if t ‚â§œÑ. Therefore by
Corollary 5.2, we have for any 2 ‚â§t ‚â§œÑ,"
L,0.7232779097387173,"‚à•‚àáf(xt) ‚àí‚àáf(xt‚àí1)‚à•‚â§L ‚à•xt ‚àíxt‚àí1‚à•‚â§Œ∑DL ‚â§œÉŒ±t,"
L,0.7244655581947743,"where the last inequality uses the choice of Œ∑ and Œ≤ ‚â§Œ±t. Therefore we have ‚à•œµt‚à•‚â§2œÉ which
completes the induction. Then it is straight forward to show"
L,0.7256532066508313,‚à•Œ≥t‚àí1‚à•‚â§(1 ‚àíŒ±t) (2œÉ + Œ±tœÉ) ‚â§2œÉ.
L,0.7268408551068883,Proof of Lemma E.5. We first list all the related parameter choices below for convenience.
L,0.7280285035629454,"G ‚â•max
n
2Œª, 2œÉ,
p"
L,0.7292161520190024,"C1‚àÜ1L0, (C1‚àÜ1LœÅ)
1
2‚àíœÅ
o
,
Œ≤ ‚â§min

1, c1Œªœµ2 œÉ2G‚àöŒπ 
,"
L,0.7304038004750594,"Œ∑ ‚â§c2 min
rŒª"
L,0.7315914489311164,"G ,
œÉŒªŒ≤
LG‚àöŒπ, Œª3/2Œ≤ L
‚àö G"
L,0.7327790973871734,"
,
T = max
 1"
L,0.7339667458432304,"Œ≤2 , C2‚àÜ1G Œ∑œµ2 
."
L,0.7351543942992874,"We will show I1/I2 ‚â§1 first. Note that if denoting W =
3L
ŒªG2 , we have"
L,0.7363420427553444,"I1/I2 = W‚àÜ1Œª + 8WœÉ2
 Œ∑"
L,0.7375296912114014,"Œ≤ + Œ∑Œ≤T

+ 20WœÉ2p"
L,0.7387173396674585,"(Œ∑2/Œ≤2 + Œ∑2T)Œπ,"
L,0.7399049881235155,Below are some facts that can be easily verified given the parameter choices.
L,0.7410926365795725,"(a) By the choice of G, we have G2 ‚â•6‚àÜ1(3L0 + 4LœÅGœÅ) = 6‚àÜ1L for large enough C1,
which implies W ‚â§
1
2‚àÜ1Œª."
L,0.7422802850356295,"(b) By the choice of T, we have Œ∑Œ≤T ‚â§Œ∑"
L,0.7434679334916865,"Œ≤ + C2‚àÜ1GŒ≤ œµ2
."
L,0.7446555819477435,"(c) By the choice of T, we have Œ∑2T = max

Œ∑
Œ≤
2
, C2Œ∑‚àÜ1G œµ2"
L,0.7458432304038005,"
‚â§

Œ∑
Œ≤
2
+ C2‚àÜ1œÉŒ≤"
L,0.7470308788598575,"œµ2
¬∑ Œ∑ Œ≤ ‚â§"
L,0.7482185273159145,"3
2

Œ∑
Œ≤
2
+ 1"
L,0.7494061757719715,"2

C2‚àÜ1œÉŒ≤"
L,0.7505938242280285,"œµ2
2
."
L,0.7517814726840855,"(d) By the choice of Œ∑, we have Œ∑/Œ≤ ‚â§
c2œÉŒª
LG‚àöŒπ, which implies WœÉ2‚àöŒπ ¬∑ Œ∑"
L,0.7529691211401425,Œ≤ ‚â§3c2œÉ3
L,0.7541567695961995,"G3
‚â§
1
200 for
small enough c2."
L,0.7553444180522565,"(e) By the choice of Œ≤ and (a), we have W œÉ2‚àÜ1G‚àöŒπŒ≤"
L,0.7565320665083135,"œµ2
‚â§œÉ2G‚àöŒπŒ≤"
L,0.7577197149643705,"2Œªœµ2
‚â§
1
100C2 for small enough c1."
L,0.7589073634204275,"Therefore,"
L,0.7600950118764845,I1/I2 ‚â§1
L,0.7612826603325415,"2 + 8WœÉ2
2Œ∑"
L,0.7624703087885986,Œ≤ + C2‚àÜ1GŒ≤ œµ2
L,0.7636579572446556,"
+ 20WœÉ2‚àöŒπ Ô£´ Ô£≠ s 5Œ∑2"
L,0.7648456057007126,2Œ≤2 + 1 2
L,0.7660332541567696,"C2‚àÜ1œÉŒ≤ œµ2 2
Ô£∂ Ô£∏ ‚â§1"
L,0.7672209026128266,2 + 48WœÉ2‚àöŒπ ¬∑ Œ∑
L,0.7684085510688836,"Œ≤ + 24C2WœÉ2‚àÜ1G‚àöŒπŒ≤ œµ2 ‚â§1,"
L,0.7695961995249406,"where the first inequality is due to Facts (a-c); the second inequality uses œÉ ‚â§G, Œπ ‚â•1, and
‚àö"
L,0.7707838479809976,"a + b ‚â§‚àöa +
‚àö"
L,0.7719714964370546,"b for a, b ‚â•0; and the last inequality is due to Facts (d-e)."
L,0.7731591448931117,"Next, we will show I1/T ‚â§œµ2. We have"
L,0.7743467933491687,I1/T =8G‚àÜ1
L,0.7755344418052257,"Œ∑T
+ 64œÉ2G"
L,0.7767220902612827,"ŒªŒ≤T
+ 64œÉ2GŒ≤"
L,0.7779097387173397,"Œª
+ 160œÉ2G‚àöŒπ Œª"
L,0.7790973871733967,"r
1
Œ≤2T 2 + 1 T ‚â§8œµ2"
L,0.7802850356294537,"C2
+ 224œÉ2G‚àöŒπ"
L,0.7814726840855107,"ŒªŒ≤T
+ 64œÉ2GŒ≤"
L,0.7826603325415677,"Œª
+ 160œÉ2G‚àöŒπ Œª
‚àö T ‚â§8œµ2"
L,0.7838479809976246,"C2
+ 450œÉ2G‚àöŒπŒ≤ Œª =
 8"
L,0.7850356294536817,"C2
+ 450c1 
œµ2 ‚â§œµ2,"
L,0.7862232779097387,where in the first inequality we use T ‚â•C2‚àÜ1G
L,0.7874109263657957,"Œ∑œµ2
and
‚àö"
L,0.7885985748218527,"a + b ‚â§‚àöa +
‚àö"
L,0.7897862232779097,"b for a, b ‚â•0; the second
inequality uses T ‚â•
1
Œ≤2 ; the second equality uses the parameter choice of Œ≤; and in the last inequality
we choose a large enough C2 and small enough c1."
L,0.7909738717339667,"E.6
Proof of Theorem 4.2"
L,0.7921615201900237,Proof of Theorem 4.2. We define stopping time œÑ as follows
L,0.7933491686460807,"œÑ1 := min{t | f(xt) ‚àíf ‚àó> F} ‚àß(T + 1),
œÑ2 := min{t | ‚à•‚àáf(xt) ‚àí‚àáf(xt, Œæt)‚à•> œÉ} ‚àß(T + 1),
œÑ := min{œÑ1, œÑ2}."
L,0.7945368171021377,"Then it is straightforward to verify that œÑ1, œÑ2, œÑ are all stopping times."
L,0.7957244655581948,"Since we want to show P(œÑ ‚â§T) is small, noting that {œÑ ‚â§T} = {œÑ = œÑ1 ‚â§T} ‚à™{œÑ = œÑ2 ‚â§T},
it suffices to bound both P(œÑ = œÑ1 ‚â§T) and P(œÑ = œÑ2 ‚â§T)."
L,0.7969121140142518,"First, we know that"
L,0.7980997624703088,P(œÑ = œÑ2 ‚â§T) ‚â§P(œÑ2 ‚â§T) =P Ô£´ Ô£≠[
L,0.7992874109263658,"1‚â§t‚â§T
‚à•‚àáf(xt) ‚àí‚àáf(xt, Œæt)‚à•> œÉ Ô£∂ Ô£∏ ‚â§
X"
L,0.8004750593824228,"1‚â§t‚â§T
P (‚à•‚àáf(xt) ‚àí‚àáf(xt, Œæt)‚à•> œÉ) ‚â§
X"
L,0.8016627078384798,"1‚â§t‚â§T
E [Pt‚àí1 (‚à•‚àáf(xt) ‚àí‚àáf(xt, Œæt)‚à•> œÉ)] ‚â§
X"
L,0.8028503562945368,"1‚â§t‚â§T
E
h
2e‚àíœÉ2 2R2
i"
L,0.8040380047505938,"=2Te‚àíœÉ2 2R2 ‚â§Œ¥/2,"
L,0.8052256532066508,"where the fourth inequality uses Assumption 4; and the last inequality uses œÉ = R
p"
L,0.8064133016627079,2 log(4T/Œ¥).
L,0.8076009501187649,"Next, if œÑ = œÑ1 ‚â§T, by definition, we have f(xœÑ) ‚àíf ‚àó> F, or equivalently,"
G,0.8087885985748219,8G
G,0.8099762470308789,Œ∑ (f(xœÑ) ‚àíf ‚àó) > 8GF
G,0.8111638954869359,"Œ∑
= 8G3"
G,0.8123515439429929,3Œ∑L =: I2.
G,0.8135391923990499,"On the other hand, since for any t < œÑ, under the new definition of œÑ, we still have"
G,0.8147268408551069,"f(xt) ‚àíf ‚àó‚â§F,
‚à•f(xt)‚à•‚â§G,
‚à•‚àáf(xt) ‚àí‚àáf(xt, Œæt)‚à•‚â§œÉ."
G,0.815914489311164,"Then we know that Lemma E.8 still holds because all of its requirements are still satisfied, i.e., there
exists some event E with P(E) ‚â§Œ¥/2, such that under its complement Ec, œÑ‚àí1
X"
G,0.8171021377672208,"t=1
‚à•‚àáf(xt)‚à•2 + 8G"
G,0.8182897862232779,Œ∑ (f(xœÑ) ‚àíf ‚àó) ‚â§8G Œ∑Œª
G,0.8194774346793349,"
‚àÜ1Œª + 8œÉ2
 Œ∑"
G,0.8206650831353919,"Œ≤ + Œ∑Œ≤T

+ 20œÉ2Œ∑
p"
G,0.8218527315914489,"(1/Œ≤2 + T)Œπ
"
G,0.8230403800475059,=: I1.
G,0.8242280285035629,"By Lemma E.5, we know I1 ‚â§I2, which suggests that Ec ‚à©{œÑ = œÑ1 ‚â§T} = ‚àÖ, i.e., {œÑ = œÑ1 ‚â§
T} ‚äÇE. Then we can show"
G,0.8254156769596199,P(E ‚à™{œÑ ‚â§T}) ‚â§P(E) + P(œÑ = œÑ2 ‚â§T) ‚â§Œ¥.
G,0.8266033254156769,"Therefore,"
G,0.827790973871734,"P(Ec ‚à©{œÑ = T + 1}) ‚â•1 ‚àíP(E ‚à™{œÑ ‚â§T}) ‚â•1 ‚àíŒ¥,"
G,0.828978622327791,"and under the event Ec ‚à©{œÑ = T + 1}, we have œÑ = T + 1 and"
T,0.830166270783848,"1
T t
X"
T,0.831353919239905,"t=1
‚à•‚àáf(xt)‚à•2 ‚â§I1/T ‚â§œµ2,"
T,0.832541567695962,where the last inequality is due to Lemma E.5.
T,0.833729216152019,"F
Convergence analysis of VRAdam"
T,0.834916864608076,"In this section, we provide detailed convergence analysis of VRAdam and prove Theorem 6.2. To do
that, we first provide some technical definitions4. Denote"
T,0.836104513064133,œµt :=mt ‚àí‚àáf(xt)
T,0.83729216152019,4Note that the same symbol for Adam and VRAdam may have different meanings.
T,0.838479809976247,"as the deviation of the momentum from the actual gradient. From the update rule in Algorithm 2, we
can write
œµt = (1 ‚àíŒ≤)œµt‚àí1 + Wt,
(25)
where we define
Wt :=‚àáf(xt, Œæt) ‚àí‚àáf(xt) ‚àí(1 ‚àíŒ≤) (‚àáf(xt‚àí1, Œæt) ‚àí‚àáf(xt‚àí1)) ."
T,0.8396674584323041,"Let G be the constant defined in Theorem 6.2 and denote F :=
G2
3(3L0+4LœÅGœÅ). We define the
following stopping times as discussed in Section 6.1.
œÑ1 := min{t | f(xt) ‚àíf ‚àó> F} ‚àß(T + 1),
œÑ2 := min{t | ‚à•œµt‚à•> G} ‚àß(T + 1),
(26)
œÑ := min{œÑ1, œÑ2}.
It is straight forward to verify that œÑ1, œÑ2, œÑ are all stopping times. Then if t < œÑ, we have
f(xt) ‚àíf ‚àó‚â§F,
‚à•‚àáf(xt)‚à•‚â§G,
‚à•œµt‚à•‚â§G.
Then we can also bound the update ‚à•xt+1 ‚àíxt‚à•‚â§Œ∑D where D = 2G/Œª if t < œÑ (see Lemma F.3
for the details). Finally, we consider the same definition of r and L as those for Adam. Specifically,"
T,0.8408551068883611,r := min
T,0.8420427553444181,"(
1
5LœÅGœÅ‚àí1 ,
1
5(LœÅ‚àí1
0
LœÅ)1/œÅ )"
T,0.8432304038004751,",
L := 3L0 + 4LœÅGœÅ.
(27)"
T,0.8444180522565321,"F.1
Useful lemmas"
T,0.8456057007125891,"We first list several useful lemmas in this section without proofs. Their proofs are deferred later in
Appendix F.3."
T,0.8467933491686461,"To start with, we provide a lemma on the local smoothness of each component function f(¬∑, Œæ) when
the gradient of the objective function f is bounded.
Lemma F.1. For any constant G ‚â•œÉ and two points x ‚ààdom(f), y ‚ààRd such that ‚à•‚àáf(x)‚à•‚â§G
and ‚à•y ‚àíx‚à•‚â§r/2, we have y ‚ààdom(f) and
‚à•‚àáf(y) ‚àí‚àáf(x)‚à•‚â§L ‚à•y ‚àíx‚à•,
‚à•‚àáf(y, Œæ) ‚àí‚àáf(x, Œæ)‚à•‚â§4L ‚à•y ‚àíx‚à•, ‚àÄŒæ,"
T,0.8479809976247031,"f(y) ‚â§f(x) +

‚àáf(x), y ‚àíx

+ 1"
T,0.8491686460807601,"2L ‚à•y ‚àíx‚à•2 ,"
T,0.850356294536817,where r and L are defined in (27).
T,0.8515439429928741,"With the new definition of stopping time œÑ in (26), all the quantities in Algorithm 2 are well bounded
before œÑ. In particular, the following lemma holds.
Lemma F.2. If t < œÑ, we have
‚à•‚àáf(xt)‚à•‚â§G,
‚à•‚àáf(xt, Œæt)‚à•‚â§G + œÉ,
‚à•mt‚à•‚â§2G,"
T,0.8527315914489311,"ÀÜvt ‚™Ø(G + œÉ)2,
Œ∑
G + œÉ + Œª ‚™Øht ‚™ØŒ∑ Œª."
T,0.8539192399049881,"Next, we provide the following lemma which bounds the update at each step before œÑ.
Lemma F.3. if t < œÑ, ‚à•xt+1 ‚àíxt‚à•‚â§Œ∑D where D = 2G/Œª."
T,0.8551068883610451,"The following lemma bounds ‚à•Wt‚à•when t ‚â§œÑ.
Lemma F.4. If t ‚â§œÑ, G ‚â•2œÉ, and Œ∑ ‚â§
r
2D,"
T,0.8562945368171021,‚à•Wt‚à•‚â§Œ≤œÉ + 5Œ∑L
T,0.8574821852731591,"Œª
(‚à•‚àáf(xt‚àí1)‚à•+ ‚à•œµt‚àí1‚à•) ."
T,0.8586698337292161,"Finally, we present some inequalities regarding the parameter choices, which will simplify the
calculations later.
Lemma F.5. Under the parameter choices in Theorem 6.2, we have 2‚àÜ1 F
‚â§Œ¥"
T,0.8598574821852731,"4,
Œª‚àÜ1Œ≤"
T,0.8610451306413301,"Œ∑G2
‚â§Œ¥"
T,0.8622327790973872,"4,
Œ∑Œ≤T ‚â§Œª‚àÜ1"
T,0.8634204275534442,"8œÉ2 ,
Œ∑ ‚â§Œª3/2"
L,0.8646080760095012,"40L r Œ≤
G."
L,0.8657957244655582,"F.2
Proof of Theorem 6.2"
L,0.8669833729216152,"Before proving the theorem, we will need to present several important lemmas. First, note that the
descent lemma still holds for VRAdam.
Lemma F.6. If t < œÑ, choosing G ‚â•œÉ + Œª and Œ∑ ‚â§min
 r 2D, Œª"
L,0.8681710213776722,"6L
	
, we have"
L,0.8693586698337292,f(xt+1) ‚àíf(xt) ‚â§‚àíŒ∑
L,0.8705463182897862,4G ‚à•‚àáf(xt)‚à•2 + Œ∑
L,0.8717339667458432,Œª ‚à•œµt‚à•2 .
L,0.8729216152019003,Proof of Lemma F.6. The proof is essentially the same as that of Lemma E.6.
L,0.8741092636579573,"Lemma F.7. Choose G ‚â•max {2œÉ, 2Œª}, S1 ‚â•
1
2Œ≤2T , and Œ∑ ‚â§min

r
2D, Œª3/2"
L,0.8752969121140143,"40L q Œ≤
G"
L,0.8764845605700713,"
. We have E"
L,0.8776722090261283,"""œÑ‚àí1
X t=1 Œ≤"
L,0.8788598574821853,2 ‚à•œµt‚à•2 ‚àíŒªŒ≤
L,0.8800475059382423,"16G ‚à•‚àáf(xt)‚à•2
#"
L,0.8812351543942993,‚â§4œÉ2Œ≤2T ‚àíE[‚à•œµœÑ‚à•2].
L,0.8824228028503563,"Proof of Lemma F.7. By Lemma F.4, we have"
L,0.8836104513064132,‚à•Wt‚à•2 ‚â§2œÉ2Œ≤2 + 100Œ∑2L2 Œª2
L,0.8847980997624703,"
‚à•‚àáf(xt‚àí1)‚à•2 + ‚à•œµt‚àí1‚à•2"
L,0.8859857482185273,‚â§2œÉ2Œ≤2 + ŒªŒ≤
G,0.8871733966745843,16G
G,0.8883610451306413,"
‚à•‚àáf(xt‚àí1)‚à•2 + ‚à•œµt‚àí1‚à•2
,"
G,0.8895486935866983,where in the second inequality we choose Œ∑ ‚â§Œª3/2
L,0.8907363420427553,40L q
L,0.8919239904988123,"Œ≤
G. Therefore, noting that
ŒªŒ≤
16G ‚â§Œ≤/2, by (25),
we have"
L,0.8931116389548693,"‚à•œµt‚à•2 =(1 ‚àíŒ≤)2 ‚à•œµt‚àí1‚à•2 + ‚à•Wt‚à•2 + (1 ‚àíŒ≤)

œµt‚àí1, Wt "
L,0.8942992874109263,‚â§(1 ‚àíŒ≤/2) ‚à•œµt‚àí1‚à•2 + ŒªŒ≤
L,0.8954869358669834,"16G ‚à•‚àáf(xt‚àí1)‚à•2 + 2œÉ2Œ≤2 + (1 ‚àíŒ≤)

œµt‚àí1, Wt ."
L,0.8966745843230404,"Taking a summation over 2 ‚â§t ‚â§œÑ and re-arranging the terms, we get œÑ‚àí1
X t=1 Œ≤"
L,0.8978622327790974,2 ‚à•œµt‚à•2 ‚àíŒªŒ≤
L,0.8990498812351544,"16G ‚à•‚àáf(xt)‚à•2 ‚â§‚à•œµ1‚à•2 ‚àí‚à•œµœÑ‚à•2 + 2œÉ2Œ≤2(œÑ ‚àí1) + (1 ‚àíŒ≤) œÑ
X t=2"
L,0.9002375296912114,"œµt‚àí1, Wt ."
L,0.9014251781472684,"Taking expectations on both sides, noting that E "" œÑ
X t=2"
L,0.9026128266033254,"œµt‚àí1, Wt # = 0"
L,0.9038004750593824,"by the Optional Stopping Theorem (Lemma C.2), we have E"
L,0.9049881235154394,"""œÑ‚àí1
X t=1 Œ≤"
L,0.9061757719714965,2 ‚à•œµt‚à•2 ‚àíŒªŒ≤
L,0.9073634204275535,"16G ‚à•‚àáf(xt)‚à•2
#"
L,0.9085510688836105,"‚â§2œÉ2Œ≤2T + E[‚à•œµ1‚à•2] ‚àíE[‚à•œµœÑ‚à•2] ‚â§4œÉ2Œ≤2T ‚àíE[‚à•œµœÑ‚à•2],"
L,0.9097387173396675,"where in the second inequality we choose S1 ‚â•
1
2Œ≤2T which implies E[‚à•œµ1‚à•2] ‚â§œÉ2/S1 ‚â§2œÉ2Œ≤2T."
L,0.9109263657957245,"Lemma F.8. Under the parameter choices in Theorem 6.2, we have E"
L,0.9121140142517815,"""œÑ‚àí1
X"
L,0.9133016627078385,"t=1
‚à•‚àáf(xt)‚à•2
#"
L,0.9144893111638955,‚â§16G‚àÜ1
L,0.9156769596199525,"Œ∑
,
E[f(xœÑ) ‚àíf ‚àó] ‚â§2‚àÜ1,
E[‚à•œµœÑ‚à•2] ‚â§Œª‚àÜ1Œ≤ Œ∑
."
L,0.9168646080760094,"Proof of Lemma F.8. First note that according to Lemma F.5, it is straight forward to verify that the
parameter choices in Theorem 6.2 satisfy the requirements in Lemma F.6 and Lemma F.7. Then by
Lemma F.6, if t < œÑ,"
L,0.9180522565320665,f(xt+1) ‚àíf(xt) ‚â§‚àíŒ∑
L,0.9192399049881235,4G ‚à•‚àáf(xt)‚à•2 + Œ∑
L,0.9204275534441805,Œª ‚à•œµt‚à•2 .
L,0.9216152019002375,"Taking a summation over 1 ‚â§t < œÑ, re-arranging terms, multiplying both sides by 8G"
L,0.9228028503562945,"Œ∑ , and taking an
expection, we get E"
L,0.9239904988123515,"""œÑ‚àí1
X"
L,0.9251781472684085,"t=1
2 ‚à•‚àáf(xt)‚à•2 ‚àí8G"
L,0.9263657957244655,"Œª ‚à•œµt‚à•2
# ‚â§8G"
L,0.9275534441805225,Œ∑ E[f(x1) ‚àíf(xœÑ)] ‚â§8G
L,0.9287410926365796,Œ∑ (‚àÜ1 ‚àíE[f(xœÑ) ‚àíf ‚àó]) . (28)
L,0.9299287410926366,"By Lemma F.7, we have E"
L,0.9311163895486936,"""œÑ‚àí1
X t=1"
G,0.9323040380047506,8G
G,0.9334916864608076,"Œª ‚à•œµt‚à•2 ‚àí‚à•‚àáf(xt)‚à•2
#"
G,0.9346793349168646,‚â§64GœÉ2Œ≤T
G,0.9358669833729216,"Œª
‚àí16G"
G,0.9370546318289786,ŒªŒ≤ E[‚à•œµœÑ‚à•2] ‚â§8G‚àÜ1
G,0.9382422802850356,"Œ∑
‚àí16G"
G,0.9394299287410927,"ŒªŒ≤ E[‚à•œµœÑ‚à•2], (29)"
G,0.9406175771971497,where the last inequality is due to Lemma F.5. Then (28) + (29) gives E
G,0.9418052256532067,"""œÑ‚àí1
X"
G,0.9429928741092637,"t=1
‚à•‚àáf(xt)‚à•2
# + 8G"
G,0.9441805225653207,Œ∑ E[f(xœÑ) ‚àíf ‚àó] + 16G
G,0.9453681710213777,"ŒªŒ≤ E[‚à•œµœÑ‚à•2] ‚â§16G‚àÜ1 Œ∑
,"
G,0.9465558194774347,which completes the proof.
G,0.9477434679334917,"With all the above lemmas, we are ready to prove the theorem."
G,0.9489311163895487,"Proof of Theorem 6.2. First note that according to Lemma F.5, it is straight forward to verify that the
parameter choices in Theorem 6.2 satisfy the requirements in all the lemmas for VRAdam."
G,0.9501187648456056,"Then, first note that if œÑ = œÑ1 ‚â§T, we know f(xœÑ) ‚àíf ‚àó> F by the definition of œÑ. Therefore,"
G,0.9513064133016627,P(œÑ = œÑ1 ‚â§T) ‚â§P(f(xœÑ) ‚àíf ‚àó> F) ‚â§E[f(xœÑ) ‚àíf ‚àó]
G,0.9524940617577197,"F
‚â§2‚àÜ1 F
‚â§Œ¥ 4,"
G,0.9536817102137767,"where the second inequality uses Markov‚Äôs inequality; the third inequality is by Lemma F.8; and the
last inequality is due to Lemma F.5."
G,0.9548693586698337,"Similarly, if œÑ2 = œÑ ‚â§T, we know ‚à•œµœÑ‚à•> G. We have"
G,0.9560570071258907,P(œÑ2 = œÑ ‚â§T) ‚â§P(‚à•œµœÑ‚à•> G) = P(‚à•œµœÑ‚à•2 > G2) ‚â§E[‚à•œµœÑ‚à•2]
G,0.9572446555819477,"G2
‚â§Œª‚àÜ1Œ≤"
G,0.9584323040380047,"Œ∑G2
‚â§Œ¥ 4,"
G,0.9596199524940617,"where the second inequality uses Markov‚Äôs inequliaty; the third inequality is by Lemma F.8; and the
last inequality is due to Lemma F.5. where the last inequality is due to Lemma F.5. Therefore,"
G,0.9608076009501187,P(œÑ ‚â§T) ‚â§P(œÑ1 = œÑ ‚â§T) + P(œÑ2 = œÑ ‚â§T) ‚â§Œ¥ 2.
G,0.9619952494061758,"Also, note that by Lemma F.8 16G‚àÜ1 Œ∑
‚â•E"
G,0.9631828978622328,"""œÑ‚àí1
X"
G,0.9643705463182898,"t=1
‚à•‚àáf(xt)‚à•2
#"
G,0.9655581947743468,"‚â•P(œÑ = T + 1)E "" T
X"
G,0.9667458432304038,"t=1
‚à•‚àáf(xt)‚à•2
 œÑ = T + 1 # ‚â•1"
E,0.9679334916864608,"2E "" T
X"
E,0.9691211401425178,"t=1
‚à•‚àáf(xt)‚à•2
 œÑ = T + 1 # ,"
E,0.9703087885985748,"where the last inequality is due to P(œÑ = T + 1) = 1 ‚àíP(œÑ ‚â§T) ‚â•1 ‚àíŒ¥/2 ‚â•1/2. Then we can
get E ""
1
T T
X"
E,0.9714964370546318,"t=1
‚à•‚àáf(xt)‚à•2
 œÑ = T + 1 #"
E,0.9726840855106889,‚â§32G‚àÜ1
E,0.9738717339667459,"Œ∑T
‚â§Œ¥œµ2 2 ."
E,0.9750593824228029,"Let F :=
n
1
T
PT
t=1 ‚à•‚àáf(xt)‚à•2 > œµ2o
be the event of not converging to stationary points. By
Markov‚Äôs inequality, we have"
E,0.9762470308788599,P(F|œÑ = T + 1) ‚â§Œ¥ 2.
E,0.9774346793349169,"Therefore,
P(F ‚à™{œÑ ‚â§T}) ‚â§P(œÑ ‚â§T) + P(F|œÑ = T + 1) ‚â§Œ¥,"
E,0.9786223277909739,"i.e., with probability at least 1 ‚àíŒ¥, we have both œÑ = T + 1 and 1"
E,0.9798099762470309,"T
PT
t=1 ‚à•‚àáf(xt)‚à•2 ‚â§œµ2."
E,0.9809976247030879,"F.3
Proofs of lemmas in Appendix F.1"
E,0.982185273159145,"Proof of Lemma F.1. This lemma is a direct corollary of Corollary 5.2. Note that by Assumption 6,
we have ‚à•‚àáf(x, Œæ)‚à•‚â§G + œÉ ‚â§2G. Hence, when computing the locality size and smoothness
constant for the component function f(¬∑, Œæ), we need to replace the constant G in Corollary 5.2 with
2G, that is why we get a smaller locality size of r/2 and a larger smoothness constant of 4L."
E,0.9833729216152018,"Proof of Lemma F.2. The bound on ‚à•mt‚à•is by the definition of œÑ in (26). All other quantities for
VRAdam are defined in the same way as those in Adam (Algorithm 1), so they have the same upper
bounds as in Lemma E.2."
E,0.9845605700712589,Proof of Lemma F.3.
E,0.9857482185273159,"‚à•xt+1 ‚àíxt‚à•‚â§Œ∑ ‚à•mt‚à•/Œª ‚â§2Œ∑G/Œª = Œ∑D,"
E,0.9869358669833729,"where the first inequality uses the update rule in Algorithm 2 and ht ‚™ØŒ∑/Œª by Lemma F.2; the
second inequality is again due to Lemma F.2."
E,0.9881235154394299,"Proof of Lemma F.4. By the definition of Wt, it is easy to verify that"
E,0.9893111638954869,"Wt = Œ≤(‚àáf(xt, Œæt) ‚àí‚àáf(xt)) + (1 ‚àíŒ≤)Œ¥t, where"
E,0.9904988123515439,"Œ¥t = ‚àáf(xt, Œæt) ‚àí‚àáf(xt‚àí1, Œæt) ‚àí‚àáf(xt) + ‚àáf(xt‚àí1)."
E,0.9916864608076009,Then we can bound
E,0.9928741092636579,"‚à•Œ¥t‚à•‚â§‚à•‚àáf(xt, Œæt) ‚àí‚àáf(xt‚àí1, Œæt)‚à•+ ‚à•‚àáf(xt) ‚àí‚àáf(xt‚àí1)‚à•
‚â§5L ‚à•xt ‚àíxt‚àí1‚à• ‚â§5Œ∑L"
E,0.994061757719715,"Œª
(‚à•‚àáf(xt‚àí1)‚à•+ ‚à•œµt‚àí1‚à•) ,"
E,0.995249406175772,"where the second inequality uses Lemma F.1; and the last inequality is due to ‚à•xt ‚àíxt‚àí1‚à•‚â§
Œ∑ ‚à•mt‚àí1‚à•/Œª ‚â§Œ∑ (‚à•‚àáf(xt‚àí1)‚à•+ ‚à•œµt‚àí1‚à•) /Œª. Then, we have"
E,0.996437054631829,‚à•Wt‚à•‚â§Œ≤œÉ + 5Œ∑L
E,0.997624703087886,"Œª
(‚à•‚àáf(xt‚àí1)‚à•+ ‚à•œµt‚àí1‚à•) ."
E,0.998812351543943,Proof of Lemma F.5. These inequalities can be obtained by direct calculations.
