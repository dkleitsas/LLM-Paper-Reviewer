Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.001589825119236884,"Empirical studies on the robustness of graph neural networks (GNNs) have sug-
gested a relation between the vulnerabilities of GNNs to adversarial attacks and
the increased presence of heterophily in perturbed graphs (where edges tend to
connect nodes with dissimilar features and labels). In this work, we formalize
the relation between heterophily and robustness, bridging two topics previously
investigated by separate lines of research. We theoretically and empirically show
that for graphs exhibiting homophily (low heterophily), impactful structural at-
tacks always lead to increased levels of heterophily, while for graph with het-
erophily the change in the homophily level depends on the node degrees. By
leveraging these insights, we deduce that a design principle identiﬁed to signif-
icantly improve predictive performance under heterophily—separate aggregators
for ego- and neighbor-embeddings—can also inherently offer increased robust-
ness to GNNs. Our extensive empirical analysis shows that GNNs adopting this
design alone can achieve signiﬁcantly improved empirical and certiﬁable robust-
ness compared to the best-performing unvaccinated model. Furthermore, models
with this design can be readily combined with explicit defense mechanisms to
yield improved robustness with up to 18.33% increase in performance under at-
tacks compared to the best-performing vaccinated model."
INTRODUCTION,0.003179650238473768,"1
INTRODUCTION"
INTRODUCTION,0.0047694753577106515,"Graph neural networks (GNNs) aim to translate the enormous empirical success of deep learning
to data deﬁned on non-Euclidean domains, such as manifolds or graphs (Bronstein et al., 2017),
and have become important tools to solve a variety of learning problems for graph structured and
geometrically embedded data. However, recent works show that GNNs—much like their “standard”
deep learning counterparts—have a high sensitivity to adversarial attacks: intentionally introduced
minor changes in the graph structure can lead to signiﬁcant changes in performance. This ﬁnding,
ﬁrst articulated by Z¨ugner et al. (2018) and Dai et al. (2018), has triggered studies that investigated
different attack scenarios (Xu et al., 2019; Wu et al., 2019; Li et al., 2020a; Ma et al., 2020)."
INTRODUCTION,0.006359300476947536,"A different aspect of GNNs that has been scrutinized recently is that most GNNs do not perform well
with many heterophilous datasets. GNNs generally perform well under homophily (or assortativity),
i.e., the tendency of nodes with similar features or class labels to connect (Pei et al., 2020; Zhu et al.,
2020). Such datasets are thus called homophilous (or assortative). While homophilous datasets
dominate the study of networks, homophily is not a universal principle; certain networks, such as
romantic relationship networks or predator-prey networks in ecology, are mostly heterophilous (or
disassortative). Employing a GNN which does not account for heterophily can lead to signiﬁcant
performance loss in heterophilous settings (Abu-El-Haija et al., 2019; Zhu et al., 2020; Bo et al.,
2021). Previous works have thus proposed architectures for heterophilous data."
INTRODUCTION,0.00794912559618442,"While previous work has focused on naturally-occurring heterophily, heterophilous interactions may
also be introduced as adversarial noise: as many GNNs exploit homophilous correlation, they can
be sensitive to changes that render the data more heterophilous. A natural follow-up question is
if and how this observation manifests itself in previously proposed attacking strategies on GNNs.
In this work, we thus investigate the relation between heterophily and robustness of GNNs against
adversarial perturbations of graph structure, focusing on semi-supervised node classiﬁcation tasks."
INTRODUCTION,0.009538950715421303,"More speciﬁcally, our main contributions are:"
INTRODUCTION,0.011128775834658187,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.012718600953895072,"• Formalization: We formalize the relation between adversarial structural attacks and the change
of homophily level in the underlying graphs with theoretical (§3.1) and empirical (§5.1) analysis.
Speciﬁcally, we show that on homophilous graphs, effective structural attacks lead to increased
heterophily, while, on heterophilous graphs, they alter the homophily level contingent on node
degrees. To our knowledge, this is the ﬁrst formal analysis of such kind.
• Heterophily-inspired Design: We show how the relation between attacks and heterophily can in-
spire more robust GNNs by demonstrating that a key architectural feature in handling heterophily,
separate aggregators for ego- and neighbor-embeddings, also improves the robustness of GNNs
against attacks (§3.2).
• Extensive Empirical Analysis: We show the effectiveness of the heterophilous design in im-
proving empirical (§5.2) and certiﬁable (§5.3) robustness of GNNs with extensive experiments
on real-world homophilous and heterophilous datasets. Speciﬁcally, we compare GNNs with this
design, which we refer to as heterophily-adjusted GNNs, to non-adjusted models, including state-
of-the-art models designed with robustness in mind. We ﬁnd that heterophily-adjusted GNNs are
up to 5 times more certiﬁably robust and have stronger performance under attacks by up to 32.92%
compared to non-adjusted, standard models. Moreover, this design can be combined with exist-
ing vaccination mechanisms, yielding up to 18.33% higher accuracy under attacks than the best
non-adjusted vaccinated model."
NOTATION AND PRELIMINARIES,0.014308426073131956,"2
NOTATION AND PRELIMINARIES"
NOTATION AND PRELIMINARIES,0.01589825119236884,"Let G = (V, E, X) be a simple graph with node set V, edge set E and node attributes X. The one-hop
neighborhood N(v) = {u : (u, v) ∈E} of a node v ∈V is the set of all nodes directly adjacent
to v; the k-hop neighborhood of v ∈V is the set of nodes reachable by a shortest path of length k.
We represent the graph G algebraically by an adjacency matrix A ∈{0, 1}|V|×|V| and node feature
matrix X ∈R|V|×F . We use As = A + I to denote the adjacency matrix with self-loops added, and
denote the corresponding row-stochastic matrices as ¯A = D−1A and ¯As = D−1
s As, respectively,
where D is a diagonal matrix with Dii = P
j Aij (Ds is deﬁned analogously). We further assume
that there exists a vector y, which contains a unique class label yv for each node v. Given a training
set TV = {(v1, y1), (v2, y2), ...} of labeled nodes, the goal of semi-supervised node classiﬁcation is
to learn a mapping ℓ: V →Y from the nodes to the set Y of class labels."
NOTATION AND PRELIMINARIES,0.017488076311605722,"Graph neural networks (GNNs). Most current GNNs operate according to a message passing
paradigm where a representation vector rv is assigned to each node v ∈V and continually updated
by K layers of learnable transformations. These layers ﬁrst aggregate representations over neigh-
boring nodes N(v) and then update the current representation via an encoder ENC. For prevailing
GNN models like GCN (Kipf & Welling, 2017) and GAT (Veliˇckovi´c et al., 2018), each layer can
be formalized as r(k)
v
= ENC

AGGR
n
r(k−1)
u
: u ∈N(v) ∪{v}
o
, where AGGR is the mean func-
tion weighted by node degrees (GCN) or an attention mechanism (GAT), and ENC is a learnable
(nonlinear) mapping."
NOTATION AND PRELIMINARIES,0.019077901430842606,"Adversarial attacks on graphs. Given a graph G = (V, E, X) and a GNN f that processes G, an
adversarial attacker tries to create a perturbed graph G′ = (V, E′, X) with a modiﬁed edge-set E′
such that the performance of the GNN f is maximally degraded. The information available to the
attacker can vary under different scenarios (Jin et al., 2020a; Sun et al., 2020). Here, we follow
the gray-box formalization by Z¨ugner et al. (2018), where the attacker knows the training set TV,
but not the trained GNN f. The attacker thus considers a surrogate GNN and picks perturbations
that maximize an attack loss Latk (Z¨ugner et al., 2018; Z¨ugner & G¨unnemann, 2019a), assuming
that attacks to the surrogate model are transferable to the attacked GNN. For node classiﬁcation,
the attack loss Latk quantiﬁes how the predictions zv ∈[0, 1]|Y| made by the GNN f differ from
the true labels y. For a targeted attack of node v with class label yv ∈Y, we adopt the negative
classiﬁcation margin (CM-type) (Z¨ugner et al., 2018; Xu et al., 2019): Latk = −∆c = −(zv,yv −
maxy̸=yv zv,y). The attacker usually has additional constraints, such as a limit on the size of the
perturbations allowed (Z¨ugner et al., 2018; Z¨ugner & G¨unnemann, 2019a)."
NOTATION AND PRELIMINARIES,0.02066772655007949,"Taxonomy of attacks. We follow the taxonomy of attacks introduced in (Jin et al., 2020a; Sun et al.,
2020). For node classiﬁcation, the attacker may aim to change the classiﬁcation of a speciﬁc node
v ∈V (targeted attack), or to decrease the overall classiﬁcation accuracy (untargeted attack).
Attacks can also happen at different stages of the training process: we refer to attacks introduced"
NOTATION AND PRELIMINARIES,0.022257551669316374,Under review as a conference paper at ICLR 2022
NOTATION AND PRELIMINARIES,0.02384737678855326,"before training as (pre-training) poison attacks, and attacks introduced after the training process
(and before potential retraining on perturbed data) as (post-training) evasion attacks. While our
theoretical analysis (§3) mainly considers targeted evasion attacks, we consider other attacks in our
empirical evaluation (§5)."
NOTATION AND PRELIMINARIES,0.025437201907790145,"Characterizing homophily and heterophily in graphs. Using class labels, we characterize the
types of connections in a graph contributing to its overall level of homophily/heterophily as follows:
Deﬁnition 1 (Homo/Heterophilous path and edge) A k-hop homophilous path from node w to u
is a length-k path between endpoint nodes with the same class label yw = yu. Otherwise, the path
is called heterophilous. A homophilous or heterophilous edge is a special case with k = 1."
NOTATION AND PRELIMINARIES,0.02702702702702703,"Following (Zhu et al., 2020; Lim et al., 2021), we deﬁne the homophily ratio h as:
Deﬁnition 2 (Homophily ratio) The homophily ratio is the fraction of homophilous edges among
all the edges in a graph: h = |{(u, v) ∈E|yu = yv}|/|E|."
NOTATION AND PRELIMINARIES,0.028616852146263912,"When the edges in a graph are wired randomly, independent to the node labels, the expectation for
h is hr = 1/|Y| for balanced classes (Lim et al., 2021). For simplicity, we informally refer to
graphs with homophily ratio h ≫1/|Y| as homophilous graphs (which have been the focus in
most prior works), graphs with homophily ratio h ≪1/|Y| as heterophilous graphs, and graphs
with homophily ratio h ≈1/|Y| as weakly heterophilous graphs."
RELATION BETWEEN GRAPH HETEROPHILY & MODEL ROBUSTNESS,0.030206677265500796,"3
RELATION BETWEEN GRAPH HETEROPHILY & MODEL ROBUSTNESS"
RELATION BETWEEN GRAPH HETEROPHILY & MODEL ROBUSTNESS,0.03179650238473768,"In this section, we ﬁrst show theoretical results on the relation between adversarial structural attacks
and the change in the homophily level of the underlying graphs. Though empirical analyses from
previous works have suggested this relation on homophilous graphs (Wu et al., 2019; Jin et al.,
2020a), to our knowledge, we are the ﬁrst to formalize it with theoretical analysis and address the
case of heterophilous graphs. As an implication of the relation, we then discuss how a key design that
improves predictive performance of GNNs under heterophily can also help boost their robustness."
RELATION BETWEEN GRAPH HETEROPHILY & MODEL ROBUSTNESS,0.033386327503974564,"3.1
HOW DO STRUCTURAL ATTACKS CHANGE HOMOPHILY IN GRAPHS?"
RELATION BETWEEN GRAPH HETEROPHILY & MODEL ROBUSTNESS,0.034976152623211444,"Homophilous Graphs: Structural Attacks are Mostly Heterophilous Attacks. Our ﬁrst re-
sult shows that, for homophilous data, effective structural attacks on GNNs (as measured by loss
Latk) always result in a reduced level of homophily where either new heterophilous connections
are added or existing homophilous connections are removed. It also states that direct perturba-
tions on 1-hop neighbors of the target nodes are more effective than indirect perturbations (inﬂu-
encer attacks (Z¨ugner et al., 2018)) on multi-hop neighbors. For simplicity, akin to previous works
(Z¨ugner et al., 2018; Z¨ugner & G¨unnemann, 2019a) we establish our results for targeted evasion
(post-training) attacks in a stylized learning setup with a linear GNN. However, our ﬁndings gen-
eralize to more general setups on real-world datasets as we show in our experiments (§5.1). In the
theorems below, we use the notion of gambit node: node u is called a gambit if a perturbation that
targets node v ∈V adjusts the connectivity of node u ∈V."
RELATION BETWEEN GRAPH HETEROPHILY & MODEL ROBUSTNESS,0.03656597774244833,"Theorem 1 Let G = (V, E, X) be a self-loop-free graph with adjacency matrix A and node features
xv = p · onehot(yv) + 1−p"
RELATION BETWEEN GRAPH HETEROPHILY & MODEL ROBUSTNESS,0.03815580286168521,"|Y| · 1 for each node v, where 1 is an all-1 vector, and p is a parameter that
regulates the signal to noise ratio. Assume that a fraction h of each node’s neighbors belong to the
same class, while a fraction
1−h
|Y|−1 belongs uniformly to any other class. Consider a 2-layer linear
GNN f (2)
s
(A, X) = ¯A2
sXW trained on a training set TV ⊆DV, with at least one node from each
class y ∈Y, and degree d for all nodes with a distance less than 2 to any v ∈DV. For a unit
structural perturbation that involves a target node v ∈DV, and a correctly classiﬁed gambit node
with degree da, the following statements hold if h ≥
1
|Y|:
1. the attack loss Latk (§2) of the target v increases only for actions increasing heterophily, i.e.,
when removing a homophilous edge or path, or adding a heterophilous edge or path to node v;
2. direct perturbations on edges (or 1-hop paths) incident to the target node v lead to greater
increase in Latk than indirect perturbations on multi-hop paths to target node v."
RELATION BETWEEN GRAPH HETEROPHILY & MODEL ROBUSTNESS,0.0397456279809221,"We give the proof in App. C.1. Intuitively, the relative inability of existing GNNs to make full use
of heterophilous data (Pei et al., 2020; Zhu et al., 2020) can be exploited by inserting heterophilous"
RELATION BETWEEN GRAPH HETEROPHILY & MODEL ROBUSTNESS,0.04133545310015898,Under review as a conference paper at ICLR 2022
RELATION BETWEEN GRAPH HETEROPHILY & MODEL ROBUSTNESS,0.04292527821939587,"connections in graphs where homophilous ones are expected. Though the theorem shows that effec-
tive attacks on homophilous graphs necessarily reduce the homophily level, the converse is not true:
not all perturbations which reduce the homophily level are effective attacks (Ma et al., 2021)."
RELATION BETWEEN GRAPH HETEROPHILY & MODEL ROBUSTNESS,0.04451510333863275,"Heterophilous Graphs: Structural Attacks Can Be Homophilous or Heterophilous, depending
on Node Degrees. When a graph displays heterophily, our analysis shows a more complicated
picture on how the level of homophily in the graph is changed by effective structural attacks: in
heterophilous case, the direction of change is dependent on the degrees of both the target node v and
the gambit node u of the attack. Speciﬁcally, if the degree of either node is low, attacks increasing
the heterophily are still effective; however, if the degrees d and da of both nodes are high, attacks
decreasing the heterophily will be effective. Similar to the homophilous case, we formalize our
results below for targeted evasion attacks in a stylized learning setup.
Theorem 2 Under the setup of Thm. 1, for a unit perturbation that involves a target node v with
degree d, and a correctly classiﬁed gambit node with degree da, the following statements hold:
1. (Low-degree target node) if 0 < d ≤|Y| −2, for any da ≥0 and h ∈[0, 1], the attack loss
Latk (§2) of v increases only under actions increasing heterophily in the graph;
2. (High-degree target node) if d > |Y| −2, conditioning on the degree da of the gambit node:"
RELATION BETWEEN GRAPH HETEROPHILY & MODEL ROBUSTNESS,0.046104928457869634,(a) (Low-degree gambit node) if da < (d+2)(|Y|−1)
RELATION BETWEEN GRAPH HETEROPHILY & MODEL ROBUSTNESS,0.04769475357710652,"d−|Y|+2
, for any h ∈[0, 1], the attack loss Latk
(§2) of v increases only under actions increasing heterophily in the graph;
(b) (High-degree gambit node) if da ≥(d+2)(|Y|−1)"
RELATION BETWEEN GRAPH HETEROPHILY & MODEL ROBUSTNESS,0.0492845786963434,"d−|Y|+2
, for 0 ≤h < da(d−|Y|+2)−(d+2)(|Y|−1)"
RELATION BETWEEN GRAPH HETEROPHILY & MODEL ROBUSTNESS,0.05087440381558029,"(d+1)|Y|da
<"
RELATION BETWEEN GRAPH HETEROPHILY & MODEL ROBUSTNESS,0.05246422893481717,"1
|Y|, Latk (§2) of v increases only under actions reducing heterophily in the graph."
RELATION BETWEEN GRAPH HETEROPHILY & MODEL ROBUSTNESS,0.05405405405405406,"In the statements above, the actions increasing heterophily in the graph include removing a ho-
mophilous edge or adding a heterophilous edge to node v, and the actions reducing heterophily in
the graph include when adding a homophilous edge or removing a heterophilous edge to node v.
The above theorems cover the situation when the gambit nodes are initially classiﬁed correctly
(where attacks introducing heterophily can be unambiguously deﬁned using the ground-truth class
labels of the nodes involved). However, in §5.1, we show on real-world datasets that a relaxed in-
terpretation of the theorems, where heterophily is instead deﬁned by the predicted class labels of
GNNs, can explain the behavior of the attacks regardless of the initial correctness of the gambits."
BOOSTING ROBUSTNESS WITH A SIMPLE HETEROPHILOUS DESIGN,0.05564387917329094,"3.2
BOOSTING ROBUSTNESS WITH A SIMPLE HETEROPHILOUS DESIGN"
BOOSTING ROBUSTNESS WITH A SIMPLE HETEROPHILOUS DESIGN,0.057233704292527825,"A natural follow-up question is whether GNNs with better performance under heterophily are also
more robust against structural attacks. We deduce that a key design for improving GNN performance
for heterophilous data—separate aggregators for ego- and neighbor-embeddings—can also boost
the robustness of GNNs by enabling them to better cope with adversarially-introduced changes in
heterophily."
BOOSTING ROBUSTNESS WITH A SIMPLE HETEROPHILOUS DESIGN,0.058823529411764705,"Separate Aggregators for Ego- and Neighbor-embeddings. This design uses separate GNN ag-
gregators for ego-embedding rv and neighbor-embeddings {ru : u ∈N(v)}. Formally, the repre-
sentation learned for node v in the k-th layer is:"
BOOSTING ROBUSTNESS WITH A SIMPLE HETEROPHILOUS DESIGN,0.06041335453100159,"r(k)
v
= ENC

AGGR1(r(k−1)
v
, r(k−2)
v
, ..., r(0)
v ), AGGR2({r(k−1)
u
: u ∈N(v)})

,
(1)"
BOOSTING ROBUSTNESS WITH A SIMPLE HETEROPHILOUS DESIGN,0.06200317965023847,"where AGGR1 and AGGR2 are separate aggregators, such as averaging functions (GCN), atten-
tion mechanisms (GAT), or other pooling mechanisms (Hamilton et al., 2017). The ego-aggregator
AGGR1 may also introduce skip connections (Xu et al., 2018) to the ego-embeddings aggregated
in previous layers as shown in Eq. (1). This design has been utilized in existing GNN models (see
§D.1 for details), and has been shown to signiﬁcantly boost the representation power of GNNs under
natural heterophily (Zhu et al., 2020)."
BOOSTING ROBUSTNESS WITH A SIMPLE HETEROPHILOUS DESIGN,0.06359300476947535,"Intuition. The key design changes, as compared to the GCN formulation in §2, allow for the ego-
embedding rv to be aggregated and weighted separately from the neighbor-embeddings {ru : u ∈
N(v)}, as well as for the use of skip connections to ego-embeddings of previous layers. Intuitively,
ego-embeddings of feature vectors at the ﬁrst layer are independent of the graph structure and thus
unaffected by adversarial structural perturbations. Hence, a separate aggregator and skip connections
can provide better access to unperturbed information, and helps mitigate the effects of the attacks."
BOOSTING ROBUSTNESS WITH A SIMPLE HETEROPHILOUS DESIGN,0.06518282988871224,"Theoretical Analysis. We formalize the above intuition that shows how separate aggregators for
ego- and neighbor-embeddings enable GNN layers to reduce the attack loss."
BOOSTING ROBUSTNESS WITH A SIMPLE HETEROPHILOUS DESIGN,0.06677265500794913,Under review as a conference paper at ICLR 2022
BOOSTING ROBUSTNESS WITH A SIMPLE HETEROPHILOUS DESIGN,0.06836248012718601,"Theorem 3 Under the setup of Thm. 1, consider two alternative layers from which a two-layer
linear GNN is built: (1) a layer deﬁned as fs(A, X) = ¯AsXW; and (2) a layer formulated as
f(A, X; α) =
 
(1 −α) ¯A + αI

XW, which mixes the ego- and neighbor-embedding linearly un-
der a predeﬁned weight α ∈[0, 1]. Then, for h > 1/|Y|, α > 1/(1 + da), and a unit perturbation
increasing Latk as in Thm. 1, outputs of layer f lead to a strictly smaller increase in Latk than fs."
BOOSTING ROBUSTNESS WITH A SIMPLE HETEROPHILOUS DESIGN,0.06995230524642289,"We provide the proof in App. C.3; note that for α = 1/(1 + da), the two layers are the same:
f(A, X; α) = fs(A, X). Theorem 3 shows that an increase to the weights of ego-embedding
improves the robustness of the GNN f for a homophily ratio h > 1/|Y|. Though aggregators and
encoders are stylized in the theorem, the empirical analysis in §5.2 conﬁrms that GNNs with more
advanced aggregators and encoders also beneﬁt from separate aggregators. Speciﬁcally, we ﬁnd that
such GNNs outperform methods without this design by up to 33.33% and 48.88% on homophilous
and heterophilous graphs, respectively, while performing comparably on clean datasets."
RELATED WORK,0.07154213036565978,"4
RELATED WORK"
RELATED WORK,0.07313195548489666,"Adversarial Attacks and Defense Strategies for Graphs Since NETTACK (Z¨ugner et al., 2018)
and RL-S2V (Dai et al., 2018) ﬁrst demonstrated the vulnerabilities of GNNs against adversarial
perturbations, a variety of attack strategies under different scenarios have been proposed, including
adversarial attacks on the graph structure (Dai et al., 2018; Xu et al., 2019; Bojchevski & G¨unne-
mann, 2019a; Li et al., 2020a; Chang et al., 2020), node features (Takahashi, 2019; Ma et al., 2020),
or combinations of both (Z¨ugner et al., 2018; Z¨ugner & G¨unnemann, 2019a; Wu et al., 2019). On
the defense side, various techniques for improving the GNN robustness against adversarial attacks
have been proposed, including: adversarial training (Xu et al., 2019; Z¨ugner & G¨unnemann, 2019a;
Bojchevski & G¨unnemann, 2019b); RGCN (Zhu et al., 2019), which adopts Gaussian-based embed-
dings and a variance-based attention mechanism; low-rank approximation of graph adjacency (En-
tezari et al., 2020) against Nettack (Z¨ugner et al., 2018); Pro-GNN (Jin et al., 2020b), which es-
timates the unperturbed graph structure in training with the assumptions of low-rank, sparsity, and
homophily of node features; GCN-Jaccard (Wu et al., 2019) and GNNGuard (Zhang & Zitnik, 2020),
which assume homophily of features (or structural embeddings) and train GNN models on a pruned
graph with only strong homophilous links; and Soft Medoid (Geisler et al., 2020), an aggrega-
tion function with improved robustness. Other recent works have looked into the certiﬁcation of
nodes that are guaranteed to be robust against certain structural and feature perturbations (Z¨ugner
& G¨unnemann, 2019b; Bojchevski & G¨unnemann, 2019b; Z¨ugner & G¨unnemann, 2020), including
approaches based on model-agnostic randomized smoothing (Cohen et al., 2019; Lee et al., 2019;
Bojchevski et al., 2020). Interested readers are referred to the recent surveys (Jin et al., 2020a; Sun
et al., 2020) for a comprehensive review of the literature."
RELATED WORK,0.07472178060413355,"GNNs & Heterophily Recent works (Pei et al., 2020; Liu et al., 2020; Zhu et al., 2020; Ma et al.,
2021) have shown that heterophilous datasets can lead to signiﬁcant performance loss for popular
GNN architectures (e.g., GCN (Kipf & Welling, 2017), GAT (Veliˇckovi´c et al., 2018)). This issue is
also known in classical semi-supervised learning (Peel, 2017). To address this issue, several GNN
designs for handling heterophilous connections have been proposed (Abu-El-Haija et al., 2019; Pei
et al., 2020; Zhu et al., 2020; Dong et al., 2021; Li et al., 2021; Zhu et al., 2021; Bo et al., 2021).
Yan et al. (2021) recently discussed the connection between heterophily and oversmoothing for
GNNs, and proposed designs to simultaneously address both issues. However, the formal connection
between heterophily and robustness of GNNs has received little attention. Here we focus on a simple
yet powerful design that signiﬁcantly improves performance under heterophily (Zhu et al., 2020),
and can be readily incorporated into GNNs."
EMPIRICAL EVALUATION,0.07631160572337042,"5
EMPIRICAL EVALUATION"
EMPIRICAL EVALUATION,0.07790143084260731,"Our analysis seeks to answer the following questions: (Q1) Does our theoretical analysis on the rela-
tions between adversarial attacks and changes in heterophily level generalize to real-world datasets?
(Q2) Do heterophily-adjusted GNNs, i.e., models with separate aggregators for ego- and neighbor-
embeddings, show improved robustness against state-of-the-art attacks? (Q3) Does the identiﬁed
design improve the certiﬁable robustness of GNNs?"
EMPIRICAL EVALUATION,0.0794912559618442,Under review as a conference paper at ICLR 2022
EMPIRICAL EVALUATION,0.08108108108108109,"First, we describe the experimental setup and datasets that we use to answer the above questions."
EMPIRICAL EVALUATION,0.08267090620031796,"Attack Setup.
We consider both targeted and untargeted attacks (§2), generated by NET-
TACK (Z¨ugner et al., 2018) and Metattack (Z¨ugner & G¨unnemann, 2019a), respectively. For each
attack method, we consider poison (pre-training) and evasion (post-training) attacks, yielding 4 at-
tack scenarios in total. We focus on robustness against structural perturbations and keep the node
features unchanged. We randomly generate 3 sets of perturbations per attack method and dataset,
and consistently evaluate each GNN model on them. We provide more details in App. D.2."
EMPIRICAL EVALUATION,0.08426073131955485,"GNN Models. To show the effectiveness of our identiﬁed design, we evaluate four groups of models
against adversarial attacks: (1) Models with this heterophilous design only: GraphSAGE (Hamilton
et al., 2017), H2GCN (Zhu et al., 2020), CPGNN (Zhu et al., 2021), GPR-GNN (Chien et al., 2021)
and FAGCN (Bo et al., 2021); we discuss how these models instantiate this design in App. §D.1;
(2) State-of-the-art “vaccinated” architectures designed with robustness in mind: ProGNN (Jin et al.,
2020b), GNNGuard (Zhang & Zitnik, 2020) and GCN-SVD (Entezari et al., 2020); (3) Models
with both the heterophilous design and explicit robustness-enhancing mechanisms based on low-
rank approximation: H2GCN-SVD and GraphSAGE-SVD; (4) Models without any vaccination,
including some of the most popular methods: GCN (Kipf & Welling, 2017), GAT (Veliˇckovi´c et al.,
2018), and the graph-agnostic multilayer perceptron (MLP) which relies only on node features. We
discuss the implementations and parameters used for the models in App. D."
EMPIRICAL EVALUATION,0.08585055643879173,Table 1: Dataset statistics.
EMPIRICAL EVALUATION,0.08744038155802862,"Homophilous graphs
Heterophilous graphs"
EMPIRICAL EVALUATION,0.0890302066772655,"Cora
Citeseer
FB100
Snap"
EMPIRICAL EVALUATION,0.09062003179650238,"#Nodes |V|
2,485
2,110
2,032
4,562
#Edges |E|
5,069
3,668
78,733
12,103
#Classes |Y|
7
6
2
5
#Features F
1,433
3,703
1,193
269
Homophily h
0.804
0.736
0.531
0.134"
EMPIRICAL EVALUATION,0.09220985691573927,"Datasets & Evaluation Setup. We con-
sider two standard datasets with strong ho-
mophily, Cora (McCallum, 2000) and Cite-
seer (Sen et al., 2008), complemented with
one weakly and one strongly heterophilous
graph, introduced by Lim et al. (2021):
FB100 (Traud et al., 2012) and Snap
Patents (Leskovec et al., 2005; Leskovec &
Krevl, 2014). We report summary statistics
in Table 1, and provide more details in App. D.5. For computational tractability, we subsample the
Snap Patents data via snowball sampling (Goodman, 1961), where we keep 20% of the neighbors
for each traversed node (see App. D.5 for details). We follow the evaluation procedure of Z¨ugner
et al. (2018) and Jin et al. (2020b), where we split the nodes of each dataset into training (10%),
validation (10%) and test (80%) data, and determine the model parameters using the training and
validation splits. We report the average performance and standard deviation on the 3 sets of gener-
ated perturbations. For targeted attacks with NETTACK, we report the classiﬁcation accuracy on the
target nodes; for untargeted attacks with Metattack, we report it over the whole test data."
EMPIRICAL EVALUATION,0.09379968203497616,"Robustness Certiﬁcates. We adopt randomized smoothing for GNNs (Bojchevski et al., 2020) to
evaluate the certiﬁable robustness, with parameter choices as detailed in App. D.2. We only consider
structural perturbations in the randomization scheme. Following Geisler et al. (2020), we measure
the certiﬁable robustness of GNN models with the accumulated certiﬁcations (AC) and the average
maximum certiﬁable radii for edge additions (¯ra) and deletions (¯rd) over all correctly predicted
nodes. More speciﬁcally, AC is deﬁned as −R(0, 0) + P"
EMPIRICAL EVALUATION,0.09538950715421304,"ra,rd≥0 R(ra, rd), where R(ra, rd) is the
certiﬁably correct ratio, i.e., the ratio of the nodes in the test splits that are both predicted correctly by
the smoothed classiﬁer and certiﬁably robust at radius (ra, rd). In addition, we report the accuracy
of each model with randomized smoothing enabled on the test splits of the clean datasets, which is
equal to R(0, 0). We report the average and standard deviation of each statistic over the 3 different
training, validation and test splits."
EMPIRICAL EVALUATION,0.09697933227344992,"5.1
(Q1) STRUCTURAL ATTACKS ARE MOSTLY HETEROPHILOUS: EMPIRICAL VALIDATION"
EMPIRICAL EVALUATION,0.0985691573926868,"To show that our theoretical analysis in §3.1 generalizes to more complex settings beyond the as-
sumptions we made in the theorems, we look into effective targeted attacks made by NETTACK on
real-world homophilous and heterophilous datasets, and present statistics of the attacks in Table 2,
with a focus on the ratios of heterophilous attacks. We use a budget of 1 perturbation per target node
in this experiment, and the statistics are reported among all effective perturbations targeting nodes
that are correctly classiﬁed on clean datasets by the surrogate GNN used by NETTACK (i.e., GCN)
as described in §5. To help validate the dependency between the degrees of the target/gambit nodes"
EMPIRICAL EVALUATION,0.10015898251192369,Under review as a conference paper at ICLR 2022
EMPIRICAL EVALUATION,0.10174880763116058,"and the changes of heterophily predicted by Thm. 2, we also show the scatter plots of target and
gambit node degrees in Fig. 2 in App. E.5."
EMPIRICAL EVALUATION,0.10333863275039745,"Table 2: Effective targeted attacks by NETTACK: ra-
tios of edge additions, deletions and heterophilous at-
tacks (i.e., attacks increasing heterophily). We consider
two heterophily deﬁnitions, one based on ground-truth
class labels (Label), and the other on predicted class la-
bels by GCN on clean datasets (Pred.). All attacks are
direct perturbations on edges incident to the targets."
EMPIRICAL EVALUATION,0.10492845786963434,"Dataset
Sample
Sizes
Attack Type
Hete. Attacks"
EMPIRICAL EVALUATION,0.10651828298887123,"Add.
Del.
Label
Pred."
EMPIRICAL EVALUATION,0.10810810810810811,NETTACK
EMPIRICAL EVALUATION,0.10969793322734499,"Cora
150
99.33%
0.67%
100.00%
100.00%
Citeseer
121
100.00%
0.00%
100.00%
100.00%
FB100
112
100.00%
0.00%
50.00%
100.00%
Snap
51
100.00%
0.00%
64.71%
100.00%"
EMPIRICAL EVALUATION,0.11128775834658187,"Homophilous Networks. For the strongly
homophilous Cora and Citeseer graphs,
all changes in the graph structure that
are introduced by effectives attacks fol-
low the conclusion of Thm. 1: they re-
duce homophily (increase heterophily) by
adding heterophilous edges or removing
homophilous edges.
These results show
that despite the simpliﬁed analysis, the
takeaway of Thm. 1 can be generalized to
real-world datasets.
In addition, the at-
tacks mostly introduce, rather than prune,
edges, suggesting that attacks adding out-
lier edges to the graph are more powerful
than attacks removing informative existing edges. These observations in our experiments are con-
sistent with the observations from previous works (Jin et al., 2020a; Geisler et al., 2020)."
EMPIRICAL EVALUATION,0.11287758346581876,"Heterophilous Networks. For heterophilous graphs FB100 (h ≈1/|Y|) and Snap (h < 1/|Y|),
Fig. 2 in App. E.5 shows that almost all attacks leverage gambit nodes with low degrees (1 or 2); no
node with degree higher than 5 is leveraged. All attacks leveraging correctly classiﬁed gambit nodes
are connecting node u ∈V with a different ground-truth class label yu ̸= yv to the target nodes
v ∈V; attacks leveraging incorrectly classiﬁed gambit nodes are always connecting node u with a
different predicted class label ˆyu ̸= ˆyv = yv to the target node v, even though some gambit nodes
have the same ground-truth class label yu = yv ̸= ˆyu as the target nodes. These results validate
the conclusion of Thm. 2 on correctly classiﬁed gambit nodes, and demonstrate its generalizability
under the heterophily deﬁnition based on predicted class labels. Note that the predicted class labels
ˆyu for each node u ∈V are based on GCN, which is the surrogate GNN used by NETTACK."
EMPIRICAL EVALUATION,0.11446740858505565,"5.2
(Q2) BENCHMARK STUDY OF GNN MODELS: HETEROPHILOUS DESIGN LEADS TO
IMPROVED EMPIRICAL ROBUSTNESS"
EMPIRICAL EVALUATION,0.11605723370429252,"To answer (Q2) on whether heterophily-adjusted GNN models show improved performance against
state-of-the-art attacks, we conduct a comprehensive benchmark study. We consider all four cat-
egories of GNN models mentioned in §5, and evaluate their robustness against both targeted and
untargeted attacks. We report the hyperparameters for each method in App. D.4. Table 3 shows
the performance of each method under poison (pre-training) attacks, and Fig. 1 visualizes the corre-
sponding performance changes relative to the clean datasets. For conciseness, we report further re-
sults under evasion (post-training) attacks and on clean (unperturbed) data in the Appendix (Table 7
for NETTACK; Table 8 for Metattack). Also, in App. E.4 we discuss how our simple heterophilous
design leads to only minor computational overhead compared to existing vaccination mechanisms."
EMPIRICAL EVALUATION,0.11764705882352941,"Targeted attacks by NETTACK. 1⃝Poison attacks. Under targeted poison attacks, Table 3 (left)
shows that GraphSAGE-SVD and H2GCN-SVD, which combine our identiﬁed design with a low-
rank vaccination approach adopted in GCN-SVD (Entezari et al., 2020) (details in App. D.3), out-
perform state-of-the-art methods across all datasets by up to 13.34% in homophilous settings and
18.33% in heterophilous settings."
EMPIRICAL EVALUATION,0.1192368839427663,"Methods merely employing the identiﬁed design also show signiﬁcantly improved robustness,
though there are differences in the amount of robustness improvement due to architectural differ-
ences. Speciﬁcally, these methods outperform the best unvaccinated method (GAT) on all datasets
by up to 32.92% in average, despite having comparable performance on clean datasets. On Citeseer
and FB100, methods with the heterophilous design also show comparable or even better robustness
than state-of-the-art vaccinated GNNs like ProGNN and GCN-SVD."
EMPIRICAL EVALUATION,0.12082670906200318,"2⃝Evasion attacks. Under evasion attacks (Table 7), we observe similar trends as in poison attacks:
GraphSAGE-SVD and H2GCN-SVD are up to 20.55% more accurate than the GCN-SVD baseline,
and methods featuring the identiﬁed design alone achieve up to 24.45% gain in average performance
against the best unvaccinated baseline. We note that GNNGuard and ProGNN are not capable of ad-"
EMPIRICAL EVALUATION,0.12241653418124006,Under review as a conference paper at ICLR 2022
EMPIRICAL EVALUATION,0.12400635930047695,"Table 3: Benchmark study: mean accuracy against poison attacks (accuracy on clean datasets in
paranthesis). Accuracy is reported on target nodes for NETTACK, and on full test splits for Metattack.
Best GNN model is highlighted in blue per dataset, and in gray per model group. MLP is immune
to structural attacks and not considered as a GNN model. Detailed results, including stdev and
accuracy against evasion attacks, are listed in Table 7 and 8 and the setup in §5."
EMPIRICAL EVALUATION,0.12559618441971382,Hetero.
EMPIRICAL EVALUATION,0.1271860095389507,Vaccin.
EMPIRICAL EVALUATION,0.1287758346581876,"Homophilous graphs
Heterophilous graphs
Homophilous graphs
Heterophilous graphs"
EMPIRICAL EVALUATION,0.13036565977742448,"Cora
Citeseer
FB100
Snap
Cora
Citeseer
FB100
Snap
h=0.804
h=0.736
h=0.531
h=0.134
h=0.804
h=0.736
h=0.531
h=0.134"
EMPIRICAL EVALUATION,0.13195548489666137,"H2GCN-SVD
✓
✓
70.00 (74.44)
65.00 (70.00)
59.44 (61.67)
28.89 (30.56)
67.87 (76.89)
70.42 (73.42)
56.72 (56.81)
25.60 (27.63)
GraphSAGE-SVD
✓
✓
71.67 (77.22)
67.78 (70.00)
60.00 (60.00)
26.67 (27.22)
68.86 (77.52)
69.10 (72.16)
55.76 (57.38)
26.58 (26.72)
H2GCN
✓
38.89 (82.78)
27.22 (69.44)
27.78 (60.56)
12.78 (30.00)
57.75 (83.94)
54.34 (75.34)
54.84 (56.95)
25.34 (27.49)
GraphSAGE
✓
36.67 (82.22)
31.67 (70.56)
33.89 (60.00)
16.67 (24.44)
54.68 (82.21)
59.74 (74.64)
54.72 (56.60)
24.14 (27.18)
CPGNN
✓
47.22 (81.67)
40.56 (73.33)
49.44 (66.11)
21.67 (28.89)
74.55 (80.67)
68.07 (74.92)
61.58 (60.17)
26.76 (27.13)
GPR-GNN
✓
21.67 (82.22)
24.44 (67.78)
2.78 (56.67)
4.44 (27.78)
48.29 (81.84)
35.25 (70.71)
59.94 (62.40)
21.06 (26.08)
FAGCN
✓
26.11 (83.33)
25.56 (70.56)
6.11 (58.33)
8.33 (29.44)
60.11 (81.59)
53.18 (73.99)
55.97 (59.64)
24.04 (27.15)
GNNGuard
✓
58.33 (77.22)
59.44 (67.78)
0.56 (67.22)
9.44 (28.33)
74.20 (80.15)
68.13 (72.61)
60.89 (65.66)
23.78 (26.51)
ProGNN
✓
48.89 (79.44)
32.78 (67.22)
33.89 (51.11)
17.78 (27.22)
45.10 (81.32)
46.58 (71.82)
53.40 (49.84)
24.80 (27.49)
GCN-SVD
✓
53.33 (75.56)
28.89 (59.44)
41.67 (50.56)
25.00 (27.78)
47.82 (76.61)
51.20 (66.90)
55.00 (55.47)
25.25 (26.63)
GAT
13.89 (84.44)
8.89 (70.00)
0.56 (60.56)
3.89 (30.56)
41.70 (83.72)
48.40 (73.40)
50.37 (61.69)
25.00 (27.30)
GCN
1.67 (82.78)
4.44 (69.44)
0.56 (63.33)
2.22 (33.33)
37.46 (84.32)
45.81 (74.27)
51.82 (64.86)
25.03 (27.30)
MLP*"
EMPIRICAL EVALUATION,0.13354531001589826,NETTACK
EMPIRICAL EVALUATION,0.13513513513513514,"64.44 (64.44)
70.56 (70.56)
57.78 (57.78)
30.00 (30.00)"
EMPIRICAL EVALUATION,0.13672496025437203,Metattack
EMPIRICAL EVALUATION,0.1383147853736089,"64.55 (64.55)
67.67 (67.67)
56.56 (56.56)
26.25 (26.25)"
EMPIRICAL EVALUATION,0.13990461049284578,"dressing evasion attacks. In summary, these observations show that the heterophily-inspired design
is orthogonal to existing vaccination mechanisms for improving the robustness of GNNs."
EMPIRICAL EVALUATION,0.14149443561208266,"0
20
40
60
80
Clean Accuracy 0 20 40 60 80"
EMPIRICAL EVALUATION,0.14308426073131955,Poison Accuracy
EMPIRICAL EVALUATION,0.14467408585055644,Citeseer (h = 0.736)
EMPIRICAL EVALUATION,0.14626391096979333,"0
20
40
60
80
Clean Accuracy 0 20 40 60 80"
EMPIRICAL EVALUATION,0.1478537360890302,Poison Accuracy
EMPIRICAL EVALUATION,0.1494435612082671,FB100 (h = 0.531)
EMPIRICAL EVALUATION,0.151033386327504,"H2GCN-SVD
GraphSAGE-SVD"
EMPIRICAL EVALUATION,0.15262321144674085,"H2GCN
GraphSAGE"
EMPIRICAL EVALUATION,0.15421303656597773,"CPGNN
GPR-GNN"
EMPIRICAL EVALUATION,0.15580286168521462,"FAGCN
GNNGuard"
EMPIRICAL EVALUATION,0.1573926868044515,"ProGNN
GCN-SVD"
EMPIRICAL EVALUATION,0.1589825119236884,"GAT
GCN MLP"
EMPIRICAL EVALUATION,0.16057233704292528,"Figure 1: (Best viewed in color.) Classiﬁcation accu-
racy on clean data and against poison attacks for target
nodes attacked by NETTACK. Error bars show standard
deviation across different sets of experiments. Detailed
results are listed in Table 7. As expected, MLP is not
inﬂuenced by the adversarial structural attacks."
EMPIRICAL EVALUATION,0.16216216216216217,"Untargeted
attacks
by
Metattack.
1⃝Poison attacks.
We also test the
robustness of each method against un-
targeted attacks.
Table 3 (right) shows
the performance under poison attacks.
Though our theoretical analysis in §3
focuses on the effect of the heterophilous
design under targeted attacks, we ob-
serve similar improvements in robustness
against untargeted attacks in the poison
setup.
GNNs with the identiﬁed design
show mostly improved robustness com-
pared to unvaccinated models,
while
having similar performance on the clean
datasets.
Speciﬁcally, CPGNN shows
exceptional
robustness,
outperforming
the best unvaccinated model by up to
32.85%.
Moreover, models combining
the identiﬁed design with low-rank approximation show more than 10% improvement accuracy
compared to GCN-SVD, which uses only low-rank approximation, and ProGNN. We note that
GNNGuard, which uses a similarity-based defense strategy, also shows more competitive robustness
under untargeted attacks. This is in line with existing works showing that low-rank based approach
does not adapt well to untargeted attacks (Jin et al., 2020b). Nevertheless, methods combining a
heterophilous design and low-rank approximations still outperform GNNGuard on two datasets.
2⃝Evasion attacks. We present the performance under evasion attacks and on clean datasets in Ta-
ble 8 in the Appendix. Unlike the poison attacks, the evasion setup only leads to a slight decrease
in average accuracy of less than 2% for most models. Moreover, there appears to be no clearly
increased robustness for vaccinated models (with the identiﬁed design or other vaccination mach-
anisms) compared to unvaccinated models. This can be attributed to the reduced effectiveness of
evasion vs. poison attacks (as in NETTACK), and the increased challenges of untargeted attacks."
EMPIRICAL EVALUATION,0.16375198728139906,"5.3
(Q3) HETEROPHILY-ADJUSTED GNNS ARE CERTIFIABLY MORE ROBUST"
EMPIRICAL EVALUATION,0.16534181240063592,"It is worth noting that robustness against speciﬁc attacks such as NETTACK and Metattack does
not guarantee robustness towards other possible attacks. To overcome this limitation, robustness
certiﬁcates provide guarantees (in some cases probabilistically) that attacks within a certain radius
cannot change a model’s predictions. Complementary to our evaluation on empirical robustness, we
further demonstrate that heterophily-adjusted GNNs featuring our identiﬁed design are certiﬁably"
EMPIRICAL EVALUATION,0.1669316375198728,Under review as a conference paper at ICLR 2022
EMPIRICAL EVALUATION,0.1685214626391097,"Table 4: Accumulated certiﬁcations (AC), average certiﬁable radii (¯ra and ¯rd) and accuracy of
GNNs with randomized smoothing enabled (i.e., f(φ(s))) on the test splits of the clean datasets,
with a ramdomization scheme φ allowing both addition and deletion (i.e., p+ = 0.001, p−= 0.4).
For each statistic, we report the mean and stdev across 3 runs. Best results highlighted in blue per
dataset, and in gray per model group. For results with other randomization schemes, see Table 9. Hete."
EMPIRICAL EVALUATION,0.17011128775834658,"Addition & Deletion
Addition & Deletion"
EMPIRICAL EVALUATION,0.17170111287758347,"AC
¯ra
¯rd
Acc. %
AC
¯ra
¯rd
Acc. %"
EMPIRICAL EVALUATION,0.17329093799682035,"H2GCN
✓ Cora"
EMPIRICAL EVALUATION,0.17488076311605724,"3.91±0.31
0.46±0.08
3.88±0.29
79.14±2.01"
EMPIRICAL EVALUATION,0.17647058823529413,Citeseer
EMPIRICAL EVALUATION,0.178060413354531,"2.98±0.88
0.34±0.13
3.29±0.67
71.43±3.92
GraphSAGE
✓
2.12±0.07
0.12±0.00
2.41±0.04
79.43±1.43
2.25±0.15
0.20±0.01
2.59±0.10
73.34±2.66
CPGNN
✓
1.87±0.27
0.14±0.05
2.24±0.30
75.37±1.65
2.03±0.17
0.11±0.01
2.52±0.20
73.48±0.61
GPR-GNN
✓
4.42±0.43
0.63±0.06
4.35±0.22
74.90±2.34
4.63±0.27
0.81±0.07
4.92±0.24
66.33±0.20
FAGCN
✓
4.30±0.07
0.57±0.02
4.25±0.04
76.49±1.73
4.07±0.15
0.58±0.02
4.23±0.09
71.82±0.73
GAT
1.60±0.10
0.07±0.01
1.83±0.05
79.88±2.49
1.30±0.06
0.08±0.02
1.62±0.06
72.87±0.80
GCN
1.73±0.09
0.09±0.01
1.99±0.03
79.39±3.72
1.77±0.08
0.14±0.02
2.09±0.07
73.48±0.53"
EMPIRICAL EVALUATION,0.17965023847376788,"H2GCN
✓ FB100"
EMPIRICAL EVALUATION,0.18124006359300476,"8.12±0.10
1.76±0.02
8.14±0.06
57.38±0.17 Snap"
EMPIRICAL EVALUATION,0.18282988871224165,"1.44±0.18
0.59±0.10
3.79±0.40
26.97±0.10
GraphSAGE
✓
6.98±0.06
1.50±0.04
7.32±0.13
56.72±1.56
0.70±0.21
0.19±0.11
2.16±0.54
26.84±0.47
CPGNN
✓
6.80±0.19
1.41±0.21
7.05±0.70
59.00±5.71
1.45±0.23
0.61±0.14
3.89±0.51
26.71±0.25
GPR-GNN
✓
5.81±0.16
1.11±0.02
5.95±0.10
61.99±0.44
0.52±0.06
0.11±0.01
1.70±0.14
26.31±1.03
FAGCN
✓
7.45±0.21
1.53±0.02
7.40±0.06
59.76±1.47
1.41±0.10
0.56±0.06
3.81±0.22
27.07±0.16
GAT
4.30±0.26
0.77±0.04
4.72±0.19
61.56±0.78
0.28±0.09
0.04±0.01
0.95±0.33
27.12±0.52
GCN
3.93±0.09
0.64±0.02
4.24±0.10
65.54±0.43
0.33±0.06
0.03±0.00
1.17±0.25
26.79±0.39"
EMPIRICAL EVALUATION,0.18441971383147854,"more robust than methods without it, thus answering (Q3). For GNN models, we include H2GCN,
GraphSAGE, CPGNN, GPR-GNN, FAGCN, GAT and GCN in this analysis. We exclude other
models that either learn to rewrite the graph structure through the training process or require a
recalculation of the low-rank approximation for every randomized perturbation as sampling on these
models is infeasible. We use the same hyperparameters as in the benchmark study in §5.2."
EMPIRICAL EVALUATION,0.18600953895071543,"Table 4 shows multiple metrics of certiﬁable robustness of each GNN model under a randomiza-
tion scheme allowing for both addition and deletion of edges; we additionally report results under
randomization schemes allowing only addition or deletion in Table 9. For the scheme allowing
both addition and deletion, we observe that all heterophily-adjusted methods have better certiﬁable
robustness compared to methods without the design. Speciﬁcally, on homophilous datasets (Cora
and Citeseer), methods with the identiﬁed design achieve an up to 1.6 times relative improvement
in accumulated certiﬁcation. On heterophilous datasets (FB100 and Snap), they outperform the
baselines by a factor of 4.4. In the more challenging case with the addition only scheme, methods
with the design also show up to 1.2 times relative increase in AC on the homophilous datasets and
5.0 times relative increase in AC on the heterophilous datasets compared to the baselines. For the
deletion only scheme, unvaccinated models like GCN already have decent certiﬁable robustness in
this scenario. This is commensurate with our discussions in §5.1 that deletions create less severe
perturbations. Overall, our results show that models featuring our identiﬁed design achieve signif-
icantly improved certiﬁable robustness compared to models lacking this design. However, like in
our empirical robustness evaluation, architectural differences lead to some variability of robustness;
the results also show tradeoffs between accuracy and robustness. We also observe that the robust-
ness rankings for methods under certiﬁable and empirical robustness are different, as in the previous
results from Geisler et al. (2020); we discuss possible reasons in App. E.3."
CONCLUSION,0.1875993640699523,"6
CONCLUSION"
CONCLUSION,0.1891891891891892,"We formalized the relation between heterophily and adversarial structural attacks, and showed the-
oretically and empirically that effective attacks gravitate towards increasing heterophily in both
homophilous and heterophilous graphs by leveraging low-degree (gambit) nodes. Using these in-
sights, we showed that a key design addressing heterophily, namely separate aggregators for ego- and
neighbor-embeddings, can lead to competitive improvement on empirical and certiﬁable robustness,
with only small inﬂuence on clean performance. Finally, we compared the design with state-of-the-
art vaccination mechanisms under different attack scenarios for various datasets, and illustrated that
they are complementary and that their combination can lead to more robust GNN models. We note
that while we focus on the structural attacks, GNNs are also vulnerable to other types of attacks such
as feature perturbations. In addition, the graph-agnostic MLP, which is immune to structural attacks,
on some datasets outperforms all GNNs against attacks; this calls for further works in understanding
of the nature of the attacks and also for effective defense strategies upon our discoveries."
CONCLUSION,0.1907790143084261,Under review as a conference paper at ICLR 2022
REPRODUCIBILITY STATEMENT,0.19236883942766295,REPRODUCIBILITY STATEMENT
REPRODUCIBILITY STATEMENT,0.19395866454689983,"For reproducibility, we describe the experimental setups in §5 with additional details in App. D.2,
including the implementation and the hyperparameter settings used for each method, and the hard-
ware speciﬁcations. We provide anonymized code and datasets in the supplementary material with
instructions for replicating the experiments, and will make them publicly available upon acceptance."
REFERENCES,0.19554848966613672,REFERENCES
REFERENCES,0.1971383147853736,"Sami Abu-El-Haija, Bryan Perozzi, Amol Kapoor, Hrayr Harutyunyan, Nazanin Alipourfard,
Kristina Lerman, Greg Ver Steeg, and Aram Galstyan. Mixhop: Higher-order graph convolu-
tion architectures via sparsiﬁed neighborhood mixing. In International Conference on Machine
Learning (ICML), 2019."
REFERENCES,0.1987281399046105,"Deyu Bo, Xiao Wang, Chuan Shi, and Huawei Shen. Beyond low-frequency information in graph
convolutional networks. arXiv preprint arXiv:2101.00797, 2021."
REFERENCES,0.20031796502384738,"Aleksandar Bojchevski and Stephan G¨unnemann. Adversarial attacks on node embeddings via graph
poisoning. In Proceedings of the 36th International Conference on Machine Learning, ICML,
Proceedings of Machine Learning Research. PMLR, 2019a."
REFERENCES,0.20190779014308427,"Aleksandar Bojchevski and Stephan G¨unnemann. Certiﬁable robustness to graph perturbations. In
Neural Information Processing Systems, NeurIPS, 2019b."
REFERENCES,0.20349761526232116,"Aleksandar Bojchevski, Johannes Klicpera, and Stephan G¨unnemann. Efﬁcient robustness certiﬁ-
cates for discrete data: Sparsity-aware randomized smoothing for graphs, images and more. In
International Conference on Machine Learning, pp. 1003–1013. PMLR, 2020."
REFERENCES,0.20508744038155802,"Michael M Bronstein, Joan Bruna, Yann LeCun, Arthur Szlam, and Pierre Vandergheynst. Geomet-
ric deep learning: going beyond euclidean data. IEEE Signal Processing Magazine, 34(4):18–42,
2017."
REFERENCES,0.2066772655007949,"Heng Chang, Yu Rong, Tingyang Xu, Wenbing Huang, Honglei Zhang, Peng Cui, Wenwu Zhu, and
Junzhou Huang. A restricted black-box adversarial framework towards attacking graph embed-
ding models. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 34, pp.
3389–3396, 2020."
REFERENCES,0.2082670906200318,"Eli Chien, Jianhao Peng, Pan Li, and Olgica Milenkovic. Adaptive universal generalized pagerank
graph neural network. In International Conference on Learning Representations, 2021. URL
https://openreview.net/forum?id=n6jl7fLxrP."
REFERENCES,0.20985691573926868,"Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. Certiﬁed adversarial robustness via randomized
smoothing. In International Conference on Machine Learning, pp. 1310–1320. PMLR, 2019."
REFERENCES,0.21144674085850557,"Hanjun Dai, Hui Li, Tian Tian, Xin Huang, Lin Wang, Jun Zhu, and Le Song. Adversarial attack on
graph structured data. In International conference on machine learning, pp. 1115–1124. PMLR,
2018."
REFERENCES,0.21303656597774245,"Yushun Dong, Kaize Ding, Brian Jalaian, Shuiwang Ji, and Jundong Li. Graph neural networks with
adaptive frequency response ﬁlter. arXiv preprint arXiv:2104.12840, 2021."
REFERENCES,0.21462639109697934,"Negin Entezari, Saba A Al-Sayouri, Amirali Darvishzadeh, and Evangelos E Papalexakis. All you
need is low (rank) defending against adversarial attacks on graphs. In Proceedings of the 13th
International Conference on Web Search and Data Mining, pp. 169–177, 2020."
REFERENCES,0.21621621621621623,"Simon Geisler, Daniel Z¨ugner, and Stephan G¨unnemann. Reliable graph neural networks via robust
aggregation. Advances in Neural Information Processing Systems, 33, 2020."
REFERENCES,0.2178060413354531,"Leo A. Goodman.
Snowball Sampling.
The Annals of Mathematical Statistics, 32(1):148 –
170, 1961. doi: 10.1214/aoms/1177705148. URL https://doi.org/10.1214/aoms/
1177705148."
REFERENCES,0.21939586645468998,Under review as a conference paper at ICLR 2022
REFERENCES,0.22098569157392686,"Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs.
In Advances in neural information processing systems (NeurIPS), pp. 1024–1034, 2017."
REFERENCES,0.22257551669316375,"Wei Jin, Yaxin Li, Han Xu, Yiqi Wang, and Jiliang Tang. Adversarial attacks and defenses on
graphs: A review and empirical study. arXiv preprint arXiv:2003.00653, 2020a."
REFERENCES,0.22416534181240064,"Wei Jin, Yao Ma, Xiaorui Liu, Xianfeng Tang, Suhang Wang, and Jiliang Tang. Graph structure
learning for robust graph neural networks. In Proceedings of the 26th ACM SIGKDD International
Conference on Knowledge Discovery & Data Mining, pp. 66–74, 2020b."
REFERENCES,0.22575516693163752,"Thomas N. Kipf and Max Welling. Semi-supervised classiﬁcation with graph convolutional net-
works. In International Conference on Learning Representations (ICLR), 2017."
REFERENCES,0.2273449920508744,"Guang-He Lee, Yang Yuan, Shiyu Chang, and Tommi Jaakkola. Tight certiﬁcates of adversarial ro-
bustness for randomly smoothed classiﬁers. Advances in Neural Information Processing Systems,
32:4910–4921, 2019."
REFERENCES,0.2289348171701113,"Jure Leskovec and Andrej Krevl. SNAP Datasets: Stanford large network dataset collection. http:
//snap.stanford.edu/data, June 2014."
REFERENCES,0.23052464228934816,"Jure Leskovec, Jon Kleinberg, and Christos Faloutsos. Graphs over time: Densiﬁcation laws, shrink-
ing diameters and possible explanations. 08 2005. doi: 10.1145/1081870.1081893."
REFERENCES,0.23211446740858505,"Jia Li, Honglei Zhang, Zhichao Han, Yu Rong, Hong Cheng, and Junzhou Huang. Adversarial attack
on community detection by hiding individuals. In Proceedings of The Web Conference 2020, pp.
917–927, 2020a."
REFERENCES,0.23370429252782193,"Sean Li, Dongwoo Kim, and Qing Wang. Beyond low-pass ﬁlters: Adaptive feature propagation on
graphs. arXiv preprint arXiv:2103.14187, 2021."
REFERENCES,0.23529411764705882,"Yaxin Li, Wei Jin, Han Xu, and Jiliang Tang. Deeprobust: A pytorch library for adversarial attacks
and defenses, 2020b."
REFERENCES,0.2368839427662957,"Derek Lim, Xiuyu Li, Felix Hohne, and Ser-Nam Lim. New benchmarks for learning on non-
homophilous graphs. arXiv preprint arXiv:2104.01404, 2021."
REFERENCES,0.2384737678855326,"Meng Liu, Zhengyang Wang, and Shuiwang Ji. Non-local graph neural networks. arXiv preprint
arXiv:2005.14612, 2020."
REFERENCES,0.24006359300476948,"Jiaqi Ma, Shuangrui Ding, and Qiaozhu Mei. Towards more practical adversarial attacks on graph
neural networks. Advances in neural information processing systems, 2020."
REFERENCES,0.24165341812400637,"Yao Ma, Xiaorui Liu, Neil Shah, and Jiliang Tang.
Is homophily a necessity for graph neural
networks? arXiv preprint arXiv:2106.06134, 2021."
REFERENCES,0.24324324324324326,"A.K. McCallum. Automating the construction of internet portals with machine learning. Information
Retrieval, 3:127–163, 01 2000."
REFERENCES,0.24483306836248012,"Leto Peel. Graph-based semi-supervised learning for relational networks. In Proceedings of the
2017 SIAM International Conference on Data Mining, pp. 435–443. SIAM, 2017."
REFERENCES,0.246422893481717,"Hongbin Pei, Bingzhe Wei, Kevin Chen-Chuan Chang, Yu Lei, and Bo Yang. Geom-gcn: Geometric
graph convolutional networks. In International Conference on Learning Representations (ICLR),
2020. URL https://openreview.net/forum?id=S1e2agrFvS."
REFERENCES,0.2480127186009539,"Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and Tina Eliassi-Rad.
Collective classiﬁcation in network data. AI magazine, 29(3):93–93, 2008."
REFERENCES,0.24960254372019078,"Lichao Sun, Yingtong Dou, Carl Yang, Ji Wang, Philip S Yu, Lifang He, and Bo Li. Adversarial
attack and defense on graph data: A survey. arXiv preprint arXiv:1812.10528, 2020."
REFERENCES,0.25119236883942764,"Tsubasa Takahashi. Indirect adversarial attacks via poisoning neighbors for graph convolutional
networks. In 2019 IEEE International Conference on Big Data (Big Data), pp. 1395–1400. IEEE,
2019."
REFERENCES,0.2527821939586645,Under review as a conference paper at ICLR 2022
REFERENCES,0.2543720190779014,"Amanda L. Traud, Peter J. Mucha, and Mason A. Porter.
Social structure of facebook net-
works.
Physica A: Statistical Mechanics and its Applications, 391(16):4165–4180, 2012.
ISSN 0378-4371.
doi: https://doi.org/10.1016/j.physa.2011.12.021.
URL https://www.
sciencedirect.com/science/article/pii/S0378437111009186."
REFERENCES,0.2559618441971383,"Petar Veliˇckovi´c, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li`o, and Yoshua
Bengio.
Graph Attention Networks.
International Conference on Learning Representations
(ICLR), 2018. URL https://openreview.net/forum?id=rJXMpikCZ."
REFERENCES,0.2575516693163752,"Huijun Wu, Chen Wang, Yuriy Tyshetskiy, Andrew Docherty, Kai Lu, and Liming Zhu. Adver-
sarial examples for graph data: Deep insights into attack and defense. In Proceedings of the
Twenty-Eighth International Joint Conference on Artiﬁcial Intelligence, IJCAI-19, pp. 4816–
4823. International Joint Conferences on Artiﬁcial Intelligence Organization, 7 2019.
doi:
10.24963/ijcai.2019/669. URL https://doi.org/10.24963/ijcai.2019/669."
REFERENCES,0.2591414944356121,"Kaidi Xu, Hongge Chen, Sijia Liu, Pin-Yu Chen, Tsui-Wei Weng, Mingyi Hong, and Xue Lin.
Topology attack and defense for graph neural networks: An optimization perspective.
arXiv
preprint arXiv:1906.04214, 2019."
REFERENCES,0.26073131955484896,"Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, and Stefanie
Jegelka. Representation learning on graphs with jumping knowledge networks. In Proceedings
of the 35th International Conference on Machine Learning, ICML, volume 80, pp. 5449–5458.
PMLR, 2018."
REFERENCES,0.26232114467408585,"Yujun Yan, Milad Hashemi, Kevin Swersky, Yaoqing Yang, and Danai Koutra. Two sides of the same
coin: Heterophily and oversmoothing in graph convolutional neural networks. arXiv preprint
arXiv:2102.06462, 2021."
REFERENCES,0.26391096979332274,"Xiang Zhang and Marinka Zitnik. Gnnguard: Defending graph neural networks against adversarial
attacks. Advances in Neural Information Processing Systems, 33, 2020."
REFERENCES,0.2655007949125596,"Dingyuan Zhu, Ziwei Zhang, Peng Cui, and Wenwu Zhu. Robust graph convolutional networks
against adversarial attacks. In Proceedings of the 25th ACM SIGKDD International Conference
on Knowledge Discovery & Data Mining, pp. 1399–1407, 2019."
REFERENCES,0.2670906200317965,"Jiong Zhu, Yujun Yan, Lingxiao Zhao, Mark Heimann, Leman Akoglu, and Danai Koutra. Beyond
homophily in graph neural networks: Current limitations and effective designs. Advances in
Neural Information Processing Systems, 33, 2020."
REFERENCES,0.2686804451510334,"Jiong Zhu, Ryan A Rossi, Anup Rao, Tung Mai, Nedim Lipka, Nesreen K Ahmed, and Danai
Koutra. Graph neural networks with heterophily. In Proceedings of the AAAI Conference on
Artiﬁcial Intelligence, volume 35, pp. 11168–11176, 2021."
REFERENCES,0.2702702702702703,"Daniel Z¨ugner and Stephan G¨unnemann. Adversarial attacks on graph neural networks via meta
learning. In International Conference on Learning Representations, 2019a."
REFERENCES,0.2718600953895072,"Daniel Z¨ugner and Stephan G¨unnemann. Certiﬁable robustness and robust training for graph con-
volutional networks. In Proceedings of the 25th ACM SIGKDD International Conference on
Knowledge Discovery & Data Mining, pp. 246–256, 2019b."
REFERENCES,0.27344992050874406,"Daniel Z¨ugner and Stephan G¨unnemann. Certiﬁable robustness of graph convolutional networks
under structure perturbations. In Proceedings of the 26th ACM SIGKDD International Conference
on Knowledge Discovery & Data Mining, pp. 1656–1665, 2020."
REFERENCES,0.27503974562798095,"Daniel Z¨ugner, Amir Akbarnejad, and Stephan G¨unnemann. Adversarial attacks on neural networks
for graph data. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge
Discovery & Data Mining, pp. 2847–2856, 2018."
REFERENCES,0.2766295707472178,Under review as a conference paper at ICLR 2022
REFERENCES,0.27821939586645467,"A
SOCIETAL IMPACTS"
REFERENCES,0.27980922098569155,"A large number of popular GNN models are inherently based on homophily. Our work shows
that such models may be less robust to adversarial perturbations, and thus when employed for
decision-making these models may lead to undesirable, erroneous or biased results. For exam-
ple, an inherently homophilous GNN model may lead to the so-called “ﬁlter bubble” phenomenon
in a recommendation system in which existing beliefs or preferences are reinforced. Similarly, as
homophily-based GNNs typically average over node neighborhoods, this may result in less visibility
of minority groups in the network, thus reinforcing disparities. Heterophilous network design may
improve some of these aspects, and also beneﬁt from some additional robustness as shown in this
work."
REFERENCES,0.28139904610492844,"However, it should be noted that heterophilous GNNs on their own cannot fully solve the aforemen-
tioned issues. In particular, while heterophilous design can improve robustness, it is not (in general)
constructed to ensure other important aspects such as fairness. Better understanding of GNNs and
tailored auditing tools are necessary in order to deploy these learning algorithms in the context of
decision-making affecting humans."
REFERENCES,0.28298887122416533,"B
NOMENCLATURE"
REFERENCES,0.2845786963434022,We summarize the main symbols used in this work and their deﬁnitions below:
REFERENCES,0.2861685214626391,Table 5: Major symbols and deﬁnitions.
REFERENCES,0.287758346581876,"Symbols
Deﬁnitions"
REFERENCES,0.2893481717011129,"G = (V, E, X)
graph G with nodeset V, edgeset E, and |V| × F node feature matrix X
X
|V| × F node feature matrix of G, X ∈R|V|×F"
REFERENCES,0.29093799682034976,"A
|V| × |V| adjacency matrix of G, A ∈{0, 1}|V|×|V|"
REFERENCES,0.29252782193958665,"As
adjacency matrix with self-loops added, As = A + I
D
diagonal matrix of degrees, with Dii = P"
REFERENCES,0.29411764705882354,"j Aij
¯A
row-stochastic matrix for A, ¯A = D−1A
¯As
row-stochastic matrix for As, ¯As = D−1
s As
˜A
low-rank approximation of the adjacency matrix A
W
learnable weight matrix for GNN models
xv
F-dimensional feature vector for node v
N(v)
direct (1-hop) neighbors of node v in G without self-loops (i.e., excluding v)
Y
set of class labels
yv
class label for node v ∈V
y
|V|-dimensional vector of class labels (for all the nodes)
TV = {(v1, y1), (v2, y2), ...}
training data for semi-supervised node classiﬁcation
G′ = (V, E′, X)
graph G′ with modiﬁed edgeset E′"
REFERENCES,0.2957074721780604,"f
a certain GNN model that processes G
K
the number of layers of GNN f
r(k)
v
node representations learned by GNN f at round / layer k
AGGR
function that aggregates node feature representations within a neighborhood
ENC
learnable (nonlinear) mapping that generates latent representation
zv
label prediction by GNN f for node v ∈V, zv ∈[0, 1]|Y|"
REFERENCES,0.2972972972972973,"Latk
attack loss that quantiﬁes the mismatch between z and the true labels y
LCM
atk
attack loss deﬁned with negative classiﬁcation margin
LCM
atk = −∆c = −(zv,yv −maxy̸=yv zv,y)
d
the degree of the nodes which have a distance less than 2 to any v ∈DV
da
the degree of a gambit node leveraged by an attack
p
parameter regulating the signal strength of one-hot class label vs. uniform noise
α
a predeﬁned weight scalar in Theorem 3, α ∈[0, 1]
h
homophily ratio deﬁned on node class labels, h = |{(u, v) ∈E|yu = yv}|/|E|"
REFERENCES,0.2988871224165342,Under review as a conference paper at ICLR 2022
REFERENCES,0.3004769475357711,"C
PROOFS AND DISCUSSIONS OF THEOREMS"
REFERENCES,0.302066772655008,"C.1
DETAILED ANALYSIS OF THEOREM 1"
REFERENCES,0.3036565977742448,"Proof 1 (for Thm. 1) We give the proof in three parts: ﬁrst, we analyze the training process of the
GNN f (2)
s
(A, X) = ¯A2
sXW on clean data and analytically derive the optimal weight matrix W∗
in a stylized learning setup; then, we construct a targeted evasion attack and calculate the attack
loss for a unit structural attack; last, we summarize and validate the statements in the theorem."
REFERENCES,0.3052464228934817,"Stylized learning on clean data. Given the 2-layer linearized GNN f (2)
s
(A, X) = ¯A2
sXW and the
training set TV ⊆DV, the goal of the training process is to optimize the weight matrix W to min-
imize the cross-entropy loss function L([z]TV,:, [Y]TV,:), where predictions [z]TV,: = [ ¯A2
sX]TV,:W
correspond to the predicted class label distributions for each node v in the training set TV, and
[Y]TV,: is the one-hot encoding of class labels provided in the training set."
REFERENCES,0.3068362480127186,"Without loss of generality, we reorder TV accordingly such that the one-hot encoding of labels for
nodes in the training set [Y]TV,: is in increasing order of the class label yv:"
REFERENCES,0.30842607313195547,"[Y]TV,: = "
REFERENCES,0.31001589825119236,
REFERENCES,0.31160572337042924,"1
0
0
· · ·
0
...
...
...
...
...
1
0
0
· · ·
0"
REFERENCES,0.31319554848966613,"0
1
0
· · ·
0
...
...
...
...
...
0
1
0
· · ·
0"
REFERENCES,0.314785373608903,"...
...
...
...
..."
REFERENCES,0.3163751987281399,"0
0
0
· · ·
1
...
...
...
...
...
0
0
0
· · ·
1 "
REFERENCES,0.3179650238473768,
REFERENCES,0.3195548489666137,|TV|×|Y| (2)
REFERENCES,0.32114467408585057,"Now we look at the term [ ¯A2
sX]TV,: in [z]TV,: = [ ¯A2
sX]TV,:W, which are the feature vectors aggre-
gated by the two GNN layers for nodes v in the training set TV. As stated in the theorem, we assume
TV ⊆DV, where node u ∈DV have degree d; proportion h of their neighbors belong to the same
class, while proportion
1−h
|Y|−1 of them belong to any other class uniformly, and for each node v ∈V"
REFERENCES,0.32273449920508746,the node features are given as xv = p · onehot(yv) + 1−p
REFERENCES,0.32432432432432434,"|Y| · 1 for each node v ∈V. Then, after the
ﬁrst layer, we have:"
REFERENCES,0.32591414944356123,"[ ¯AsX]TV,: =
1
d + 1 "
REFERENCES,0.3275039745627981,
REFERENCES,0.32909379968203495,"(hd + 1)p
1−h
|Y|−1dp
1−h
|Y|−1dp
· · ·
1−h
|Y|−1dp
...
...
...
...
...
(hd + 1)p
1−h
|Y|−1dp
1−h
|Y|−1dp
· · ·
1−h
|Y|−1dp"
REFERENCES,0.33068362480127184,"1−h
|Y|−1dp
(hd + 1)p
1−h
|Y|−1dp
· · ·
1−h
|Y|−1dp
...
...
...
...
...
1−h
|Y|−1dp
(hd + 1)p
1−h
|Y|−1dp
· · ·
1−h
|Y|−1dp"
REFERENCES,0.3322734499205087,"...
...
...
...
..."
REFERENCES,0.3338632750397456,"1−h
|Y|−1dp
1−h
|Y|−1dp
1−h
|Y|−1dp
· · ·
(hd + 1)p
...
...
...
...
...
1−h
|Y|−1dp
1−h
|Y|−1dp
1−h
|Y|−1dp
· · ·
(hd + 1)p "
REFERENCES,0.3354531001589825,
REFERENCES,0.3370429252782194,|TV|×|Y|
REFERENCES,0.3386327503974563,+ 1 −p |Y| (3)
REFERENCES,0.34022257551669316,Under review as a conference paper at ICLR 2022
REFERENCES,0.34181240063593005,and after the second layer
REFERENCES,0.34340222575516693,"[ ¯A2
sX]TV,: =
1
(d + 1)2|Y|(|Y| −1) "
REFERENCES,0.3449920508744038,
REFERENCES,0.3465818759936407,"S1
T1
T1
· · ·
T1
...
...
...
...
...
S1
T1
T1
· · ·
T1"
REFERENCES,0.3481717011128776,"T1
S1
T1
· · ·
T1
...
...
...
...
...
T1
S1
T1
· · ·
T1"
REFERENCES,0.3497615262321145,"...
...
...
...
..."
REFERENCES,0.35135135135135137,"T1
T1
T1
· · ·
S1
...
...
...
...
...
T1
T1
T1
· · ·
S1 "
REFERENCES,0.35294117647058826,
REFERENCES,0.35453100158982515,|TV|×|Y| + 1
REFERENCES,0.356120826709062,"|Y|,
(4)"
REFERENCES,0.35771065182829886,"where S1 = ((h|Y| −1)d + |Y| −1)2 p, and T1 = ((h|Y|−1)d+|Y|−1)2p"
REFERENCES,0.35930047694753575,"|Y|−1
."
REFERENCES,0.36089030206677264,"For [Y]TV,: and [ ¯A2
sX]TV,: which we derived in Eq. (2) and (4), we can ﬁnd the optimal weight
matrix W∗such that [ ¯A2
sX]TV,:W∗= [Y]TV,:, making the cross-entropy loss L([z]TV,:, [Y]TV,:) =
0."
REFERENCES,0.3624801271860095,"To ﬁnd W∗, we can proceed as follows. First, sample one node from each class to form a smaller
set TS ⊂TV. Therefore, we have:"
REFERENCES,0.3640699523052464,"[Y]TS,: =  "
REFERENCES,0.3656597774244833,"1
0
0
· · ·
0
0
1
0
· · ·
0
...
...
...
...
...
0
0
0
· · ·
1  "
REFERENCES,0.3672496025437202,|Y|×|Y|
REFERENCES,0.3688394276629571,= I|Y|×|Y| and
REFERENCES,0.37042925278219396,"[ ¯A2
sX]TS,: =
1
(d + 1)2|Y|(|Y| −1)  "
REFERENCES,0.37201907790143085,"S1
T1
T1
· · ·
T1
T1
S1
T1
· · ·
T1
...
...
...
...
...
T1
T1
T1
· · ·
S1  "
REFERENCES,0.37360890302066774,|Y|×|Y| + 1 |Y|.
REFERENCES,0.3751987281399046,"Note that [ ¯A2
sX]TS,: is a speciﬁc circulant matrix, and therefore its inverse exists.
Using the
Sherman-Morrison formula, we can ﬁnd its inverse as:"
REFERENCES,0.3767885532591415," 
[ ¯A2
sX]TS,:
−1 =
(d + 1)2(|Y| −1)2"
REFERENCES,0.3783783783783784,p(d(h|Y| −1) + |Y| −1)2|Y| ·  
REFERENCES,0.3799682034976153,"|Y| −1
−1
· · ·
−1
−1
|Y| −1
· · ·
−1
...
...
...
...
−1
−1
· · ·
|Y| −1 + 1 |Y| "
REFERENCES,0.3815580286168522,".
(5)"
REFERENCES,0.383147853736089,"Now, let W∗=
 
[ ¯A2
sX]TS,:
−1, then we have [z]TS,: = [ ¯A2
sX]TS,:W∗= [Y]TS,: = I|Y|×|Y|. It is
also easy to verify that [z]TV,: = [ ¯A2
sX]TV,:W∗= [Y]TV,:. Since W∗satisﬁes L([z]TV,:, [Y]TV,:) =
0, we know W∗=
 
[ ¯A2
sX]TS,:
−1 is the optimal weight matrix that we can learn under TV."
REFERENCES,0.3847376788553259,"Attack loss under evasion attacks. Now consider an arbitrary target node v ∈DV with class label
yv ∈Y, and a unit structural perturbation leveraging gambit node u ∈V with degree da that af-
fects the predictions zv of node v made by GNN f (2)
s
. Without loss of generality, we assume node
v has yv = 1. As f (2)
s
contains 2 GNN layers with each layer aggregating feature vectors within
neighborhood N(v) of each node v, the perturbation must take place in the direct (1-hop) neighbor-
hood N(v) or 2-hop neighborhood N2(v) to affect the predictions zv. For the unit perturbation, the"
REFERENCES,0.3863275039745628,Under review as a conference paper at ICLR 2022
REFERENCES,0.38791732909379967,"attacker can add or remove a homophilous edge or path between nodes u and v, which we denote
as δ1 (δ1 = 1 for addition and δ1 = −1 for removal); alternatively, the attacker can add or remove
a heterophilous edge or path between nodes u and v, which we denote as δ2 = ±1 analogously. We
denote the perturbed graph adjacency matrix as ¯A′
s, and z′
v = [ ¯A′2
s X]v,:W∗"
REFERENCES,0.38950715421303655,"1⃝Unit perturbation in direct neighborhood N(v). We ﬁrst consider a unit perturbation in the direct
(1-hop) neighborhood N(v) of node v. For simplicity of derivation, we assume that the perturbation
does not change the row-stochastic normalization of ¯As, and only affects the aggregated feature
vectors of the target node v."
REFERENCES,0.39109697933227344,"In the case of δ1 = ±1 and δ2 = 0, we have"
REFERENCES,0.39268680445151033,"[ ¯A′
sX]v,: −[ ¯AsX]v,: =
1
da + 1"
REFERENCES,0.3942766295707472,"h
δ1

1−p"
REFERENCES,0.3958664546899841,"|Y| + p

δ1

1−p"
REFERENCES,0.397456279809221,"|Y|

· · ·
δ1

1−p"
REFERENCES,0.3990461049284579,"|Y|
 i"
REFERENCES,0.40063593004769477,"and
[ ¯A′2
s X]v,: −[ ¯A2
sX]v,: =
1
(da + 1)2(d + 1)|Y|"
REFERENCES,0.40222575516693165,"h
S2
T2
|Y|−1
· · ·
T2
|Y|−1
i
,"
REFERENCES,0.40381558028616854,"where S2 = δ1 (da(p(d(h|Y| −1) + h|Y| + |Y| −2) + d + 2) + (d + 2)(|Y| −1)p + d + 2) and
T2 = δ1 (−(da(p(d(h|Y| −1) + h|Y| + |Y| −2) + (−d −2)(|Y| −1)) + (d + 2)(|Y| −1)(p −1))).
By Multiplying [ ¯A′2
s X]v,: by W∗, we can get the predictions z′
v after perturbations; we omit the
analytical expression of z′
v here due to its complexity."
REFERENCES,0.40540540540540543,"On the perturbed graph, the CM-type attack loss is calculated as"
REFERENCES,0.4069952305246423,"LCM
atk (z′
v) = −(z′
v,yv −max
y̸=yv z′
v,y)"
REFERENCES,0.40858505564387915,"Since on clean data, LCM
atk (zv) = −1, the change in attack loss before and after attack is"
REFERENCES,0.41017488076311603,"∆LCM
atk = LCM
atk (z′
v) −LCM
atk (zv) = LCM
atk (z′
v) + 1
(6)"
REFERENCES,0.4117647058823529,= −(d + 1)δ1(|Y| −1) (da(d(h|Y| −1) + h|Y| + |Y| −2) + (d + 2)(|Y| −1))
REFERENCES,0.4133545310015898,"(da + 1)2(d(h|Y| −1) + |Y| −1)2
.
(7)"
REFERENCES,0.4149443561208267,"Solving following system of inequalities for δ1,



 

"
REFERENCES,0.4165341812400636,"∆LCM
atk > 0
h ∈[0, 1]
|Y| ≥2
d, da, |Y| ∈Z+ (8)"
REFERENCES,0.41812400635930047,"we get the valid range of δ1 as





"
REFERENCES,0.41971383147853736,"



"
REFERENCES,0.42130365659777425,"δ1 < 0, when 0 < d ≤|Y| −2
δ1 < 0, when d > |Y| −2 and da < (d+2)(|Y|−1)"
REFERENCES,0.42289348171701113,"d−|Y|+2
δ1 < 0, when d > |Y| −2 and da ≥(d+2)(|Y|−1)"
REFERENCES,0.424483306836248,"d−|Y|+2
and 1 ≥h > da(d−|Y|+2)−(d+2)(|Y|−1)"
REFERENCES,0.4260731319554849,"(d+1)|Y|da
δ1 > 0, when d > |Y| −2 and da ≥(d+2)(|Y|−1)"
REFERENCES,0.4276629570747218,"d−|Y|+2
and 0 ≤h < da(d−|Y|+2)−(d+2)(|Y|−1)"
REFERENCES,0.4292527821939587,(d+1)|Y|da .
REFERENCES,0.43084260731319557,"(9)
Note that the above solution is not applicable when h = d−|Y|+1"
REFERENCES,0.43243243243243246,"d|Y|
, in which case d(h|Y|−1)+|Y|−"
REFERENCES,0.43402225755166934,"1 = 0 and the solution of optimal weight matrix W∗=
 
[ ¯A2
sX]TS,:
−1 is undeﬁned."
REFERENCES,0.4356120826709062,"In the case of δ1 = 0 and δ2 = ±1, we have"
REFERENCES,0.43720190779014306,"[ ¯A′
sX]v,: −[ ¯AsX]v,: =
1
da + 1"
REFERENCES,0.43879173290937995,"h
δ2

1−p"
REFERENCES,0.44038155802861684,"|Y|

δ2

1−p"
REFERENCES,0.4419713831478537,"|Y| + p

· · ·
δ2

1−p"
REFERENCES,0.4435612082670906,"|Y| + p
 i"
REFERENCES,0.4451510333863275,"and
[ ¯A′2
s X]v,: −[ ¯A2
sX]v,: =
1
(da + 1)2(d + 1)|Y|"
REFERENCES,0.4467408585055644,"h
S4
|Y|−1
T4
· · ·
T4
i
,"
REFERENCES,0.4483306836248013,"where S4 = δ2 (−(da(p(d(h|Y| −1) + h|Y| + |Y| −2) + (−d −2)(|Y| −1)) + (d + 2)(|Y| −1)(p −1)))
and T4 = δ2 (da(p(d(h|Y| −1) + h|Y| + |Y| −2) + d + 2) + (d + 2)(|Y| −1)p + d + 2).
By"
REFERENCES,0.44992050874403816,Under review as a conference paper at ICLR 2022
REFERENCES,0.45151033386327505,"multiplying [ ¯A′2
s X]v,: with W∗, we can get the predictions z′
v after the perturbations. Following a
similar derivation to that in the previous case, we can compute the change in the CM-type attack
loss before and after attack as"
REFERENCES,0.45310015898251194,"∆LCM
atk = (d + 1)(|Y| −1) (da(d(h|Y| −1) + h|Y| + |Y| −2) + (d + 2)(|Y| −1)) δ2"
REFERENCES,0.4546899841017488,"(da + 1) 2(d(h|Y| −1) + |Y| −1)2
.
(10)"
REFERENCES,0.4562798092209857,"Solving the same system of inequalities as Eq. (8) for δ2, we obtain the valid range of δ2 as





"
REFERENCES,0.4578696343402226,"



"
REFERENCES,0.4594594594594595,"δ2 > 0, when 0 < d ≤|Y| −2
δ2 > 0, when d > |Y| −2 and da < (d+2)(|Y|−1)"
REFERENCES,0.4610492845786963,"d−|Y|+2
δ2 > 0, when d > |Y| −2 and da ≥(d+2)(|Y|−1)"
REFERENCES,0.4626391096979332,"d−|Y|+2
and 1 ≥h > da(d−|Y|+2)−(d+2)(|Y|−1)"
REFERENCES,0.4642289348171701,"(d+1)|Y|da
δ2 < 0, when d > |Y| −2 and da ≥(d+2)(|Y|−1)"
REFERENCES,0.465818759936407,"d−|Y|+2
and 0 ≤h < da(d−|Y|+2)−(d+2)(|Y|−1)"
REFERENCES,0.46740858505564387,(d+1)|Y|da .
REFERENCES,0.46899841017488075,"(11)
Note that the above solution is not applicable when h = d−|Y|+1"
REFERENCES,0.47058823529411764,"d|Y|
, in which case d(h|Y|−1)+|Y|−"
REFERENCES,0.47217806041335453,"1 = 0 and the solution of optimal weight matrix W∗=
 
[ ¯A2
sX]TS,:
−1 is undeﬁned. We also note
that we always have da(d−|Y|+2)−(d+2)(|Y|−1)"
REFERENCES,0.4737678855325914,"(d+1)|Y|da
−
1
|Y| = −(|Y|−1)(da+d+2)"
REFERENCES,0.4753577106518283,"(d+1)|Y|da
< 0 when |Y| ≥2."
REFERENCES,0.4769475357710652,"2⃝Unit perturbation in 2-hop neighborhood N2(v). We now consider a unit perturbation in the
2-hop neighborhood N(v) of node v. In this case we will have [ ¯A′
sX]v,: = [ ¯AsX]v,:."
REFERENCES,0.4785373608903021,"In the case of δ1 = ±1 and δ2 = 0, we have"
REFERENCES,0.48012718600953896,"[ ¯A′2
s X]v,: −[ ¯A2
sX]v,: =
1
(da + 1)2|Y|"
REFERENCES,0.48171701112877585,"h
S5
T5
|Y|−1
· · ·
T5
|Y|−1
i
,"
REFERENCES,0.48330683624801274,"where
S5 = (da(p(h|Y| −1) + 1) + (|Y| −1)p + 1) δ1
and
T5 = (da(−h|Y|p + |Y| + p −1) + |Y|(−p) + |Y| + p −1) δ1.
By multiplying [ ¯A′2
s X]v,: with W∗, we can get the predictions z′
v after perturbations. Following
a similar derivation as before, we can get the change in the CM-type attack loss before and after
attack as"
REFERENCES,0.4848966613672496,"∆LCM
atk = −(d + 1)2(|Y| −1) (da(h|Y| −1) + |Y| −1) δ1"
REFERENCES,0.4864864864864865,"(da + 1) 2(d(h|Y| −1) + |Y| −1)2
.
(12)"
REFERENCES,0.48807631160572335,"Solving the same system of inequalities as Eq. (8) for δ1, we get the valid range of δ1 as


 
"
REFERENCES,0.48966613672496023,"δ1 < 0, when da < |Y| −1
δ1 < 0, when da ≥|Y| −1 and da−|Y|+1"
REFERENCES,0.4912559618441971,"|Y|da
< h ≤1"
REFERENCES,0.492845786963434,"δ1 > 0, when da > |Y| −1 and 0 ≤h < da−|Y|+1 |Y|da"
REFERENCES,0.4944356120826709,".
(13)"
REFERENCES,0.4960254372019078,Note that the above solution is not applicable when h = d−|Y|+1
REFERENCES,0.49761526232114467,"d|Y|
, in which case d(h|Y|−1)+|Y|−"
REFERENCES,0.49920508744038156,"1 = 0 and the solution of optimal weight matrix W∗=
 
[ ¯A2
sX]TS,:
−1 is undeﬁned."
REFERENCES,0.5007949125596184,"For the case δ1 = 0 and δ2 = ±1, we have"
REFERENCES,0.5023847376788553,"[ ¯A′2
s X]v,: −[ ¯A2
sX]v,: =
1
(da + 1)2|Y|"
REFERENCES,0.5039745627980922,"h
S6
|Y|−1
T6
· · ·
T6
i"
REFERENCES,0.505564387917329,"where
S6 = δ2 (da(−h|Y|p + |Y| + p −1) + |Y|(−p) + |Y| + p −1)
and
T6 = δ2 (da(p(h|Y| −1) + 1) + (|Y| −1)p + 1) .
Multiplying [ ¯A′2
s X]v,: with W∗, we can get the predictions z′
v after perturbations. As before we can
compute the change in the CM-type attack loss before and after attack as"
REFERENCES,0.5071542130365659,"∆LCM
atk = (d + 1)2(|Y| −1) (da(h|Y| −1) + |Y| −1) δ2"
REFERENCES,0.5087440381558028,"(da + 1) 2(d(h|Y| −1) + |Y| −1)2
(14)"
REFERENCES,0.5103338632750397,Under review as a conference paper at ICLR 2022
REFERENCES,0.5119236883942766,"Finally, solving the same system of inequalities as Eq. (8) for δ2, we get the valid range of δ2 as


 
"
REFERENCES,0.5135135135135135,"δ2 > 0, when da < |Y| −1
δ2 > 0, when da ≥|Y| −1 and da−|Y|+1"
REFERENCES,0.5151033386327504,"|Y|da
< h ≤1"
REFERENCES,0.5166931637519873,"δ2 < 0, when da > |Y| −1 and 0 ≤h < da−|Y|+1 |Y|da"
REFERENCES,0.5182829888712241,".
(15)"
REFERENCES,0.519872813990461,Note that the above solution is not applicable when h = d−|Y|+1
REFERENCES,0.5214626391096979,"d|Y|
, in which case d(h|Y|−1)+|Y|−"
REFERENCES,0.5230524642289348,"1 = 0 and the solution of optimal weight matrix W∗=
 
[ ¯A2
sX]TS,:
−1 is undeﬁned. We also note
that we always have da−|Y|+1"
REFERENCES,0.5246422893481717,"|Y|da
−
1
|Y| = 1−|Y|"
REFERENCES,0.5262321144674086,|Y|da < 0 when |Y| ≥2.
REFERENCES,0.5278219395866455,"Summary and validation of theorem statements. Based on our derivations, we summarize and
validate our statements in the theorem next."
REFERENCES,0.5294117647058824,"1⃝The attack losses Latk (CM-type, §2) increase only by removing a homophilous edge or path, or
adding a heterophilous edge or path to node v. From Eq. (9), (11), (13), (15), we observe that for
both direct attacks in 1-hop neighborhood N(v) and indirect attacks in 2-hop neighborhood N2(v),
when h ≥
1
|Y|, the attack loss increases only if δ1 < 0, which represents removal of a homophilous
edge or path to node v, or if δ2 > 0, which represents addition of a heterophilous edge or path to
node v."
REFERENCES,0.5310015898251192,"2⃝Direct perturbations on edges (or 1-hop paths) of the target node v lead to greater increase in
Latk than indirect perturbations on multi-hop paths to target node v."
REFERENCES,0.5325914149443561,"From Eq. (7) and Eq. (10), the change in the CM-type attack loss ∆LCM
atk (z′
v) for direct perturba-
tions on 1-hop neighborhood N(v) of the target node v considering both δ1 and δ2 can be written
as"
REFERENCES,0.534181240063593,"∆LCM,direct
atk
= (d + 1)(|Y| −1) (da(d(h|Y| −1) + h|Y| + |Y| −2) + (d + 2)(|Y| −1)) (δ2 −δ1)"
REFERENCES,0.5357710651828299,"(da + 1) 2(d(h|Y| −1) + |Y| −1)2
(16)"
REFERENCES,0.5373608903020668,"From Eq. (12) and Eq. (14), the change in the CM-type attack loss ∆LCM
atk (z′
v) for indirect pertur-
bations on 2-hop neighborhood N2(v) of the target node v considering both δ1 and δ2 is"
REFERENCES,0.5389507154213037,"∆LCM,indirect
atk
= (d + 1)2(|Y| −1) (da(h|Y| −1) + |Y| −1) (δ2 −δ1)"
REFERENCES,0.5405405405405406,"(da + 1) 2(d(h|Y| −1) + |Y| −1)2
(17)"
REFERENCES,0.5421303656597775,"Note that when h ≥
1
|Y|, we have h|Y| ≥1, and"
REFERENCES,0.5437201907790143,"dh|Y| −d + 2|Y| −2
d(h|Y| −1) + |Y| −1 = 1 + da(d(h|Y| −1) + |Y| −1) + (d + 1)(|Y| −1)"
REFERENCES,0.5453100158982512,"da(h|Y| −1) + |Y| −1
> 1
(18)"
REFERENCES,0.5468998410174881,"Therefore we will always have ∆LCM,direct
atk
> ∆LCM,indirect
atk
for an effective unit perturbation that
increases attack loss LCM
atk (i.e., δ1 = −1 and δ2 = 0, or δ1 = 0 and δ2 = 1) when h ≥
1
|Y|. ■"
REFERENCES,0.548489666136725,"C.2
DETAILED ANALYSIS OF THEOREM 2"
REFERENCES,0.5500794912559619,"Proof 2 (for Thm. 2) For a direct unit perturbation in the 1-hop neighborhood N(v) of the target
node v, from Eq. (9) and (11) of Proof 1, we observe that the signs of δ1 and δ2 which increase the
attack loss are contingent on the degree of the target node d, the degree of the gambit node da and
the homophily ratio h of the graph:"
REFERENCES,0.5516693163751988,"1⃝if 0 < d ≤|Y| −2 (i.e., when degree d of the target node is low), regardless of da and h, the
attack loss increases only if δ1 < 0, which represents removal of a homophilous edge to node v, or
if δ2 > 0, which represents addition of a heterophilous edge to v;"
REFERENCES,0.5532591414944356,"2⃝if d > |Y| −2 (i.e., when degree d of the target node is high), the increase of the attack loss will
be dependent to the degree of the gambit node da and the homophily ratio h of the graph:"
REFERENCES,0.5548489666136724,Under review as a conference paper at ICLR 2022
REFERENCES,0.5564387917329093,(a) when da < (d+2)(|Y|−1)
REFERENCES,0.5580286168521462,"d−|Y|+2
(i.e., when degree da of the gambit node is low), regardless of h, the
attack loss increases only if δ1 < 0, which represents removal of a homophilous edge to node
v, or if δ2 > 0, which represents addition of a heterophilous edge to v;"
REFERENCES,0.5596184419713831,"(b) when da ≥
(d+2)(|Y|−1)"
REFERENCES,0.56120826709062,"d−|Y|+2
(i.e., when degree da of the gambit node is high), for 0 ≤h <"
REFERENCES,0.5627980922098569,da(d−|Y|+2)−(d+2)(|Y|−1)
REFERENCES,0.5643879173290938,"(d+1)|Y|da
<
1
|Y|, the attack loss increases only if δ1 < 0, which represents
removal of a homophilous edge to node v, or if δ2 > 0, which represents addition of a het-
erophilous edge to v."
REFERENCES,0.5659777424483307,We note that the above conclusions are not applicable when h = d−|Y|+1
REFERENCES,0.5675675675675675,"d|Y|
, in which case d(h|Y| −"
REFERENCES,0.5691573926868044,"1) + |Y| −1 = 0 and the solution of optimal weight matrix W∗=
 
[ ¯A2
sX]TS,:
−1 is undeﬁned. ■"
REFERENCES,0.5707472178060413,"C.3
DETAILED ANALYSIS OF THEOREM 3"
REFERENCES,0.5723370429252782,"Proof 3 (for Thm. 3) In this proof, we mainly focus on analyzing the increase in Latk for the GNN
layer deﬁned as f(A, X; α) =
 
(1 −α) ¯A + αI

XW. We follow a similar process as in Proof 1,
since the layer deﬁned as fs(A, X) = ¯AsXW is a special case of the previous formulation when
α =
1
1+d."
REFERENCES,0.5739268680445151,"Layer f(A, X; α) =
 
(1 −α) ¯A + αI

XW. We ﬁrst derive the optimal weight matrix W∗in a
stylized learning setup as in Proof 1. Following a similar process, for this GNN layer we have"
REFERENCES,0.575516693163752," 
(1 −α) ¯A + αI

X
"
REFERENCES,0.5771065182829889,"TS,: = 1 −p |Y|
+  "
REFERENCES,0.5786963434022258,"S7
T7
T7
· · ·
T7
T7
S7
T7
· · ·
T7
...
...
...
...
...
T7
T7
T7
· · ·
S7  "
REFERENCES,0.5802861685214626,|Y|×|Y|
REFERENCES,0.5818759936406995,"where S7 = p(α + h −αh), and T7 = (α−1)(h−1)p"
REFERENCES,0.5834658187599364,"|Y|−1
, and"
REFERENCES,0.5850556438791733,"[Y]TS,: =  "
REFERENCES,0.5866454689984102,"1
0
0
· · ·
0
0
1
0
· · ·
0
...
...
...
...
...
0
0
0
· · ·
1  "
REFERENCES,0.5882352941176471,|Y|×|Y|
REFERENCES,0.589825119236884,= I|Y|×|Y|
REFERENCES,0.5914149443561209,"Using the Sherman-Morrison formula, we ﬁnd its inverse:
 
(1 −α) ¯A + αI

X
 TS,:"
REFERENCES,0.5930047694753577,"−1
=
|Y| −1
p(a(h −1)|Y| −h|Y| + 1)|Y|·  "
REFERENCES,0.5945945945945946,"1 −|Y|
1
1
· · ·
1
1
1 −|Y|
1
· · ·
1
...
...
...
...
...
1
1
1
· · ·
1 −|Y| "
REFERENCES,0.5961844197138315,+ 1 |Y|
REFERENCES,0.5977742448330684,"Assuming W∗=
 
(1 −α) ¯A + αI

X
 TS,:"
REFERENCES,0.5993640699523053,"−1
, we obtain"
REFERENCES,0.6009538950715422,"[z]TS,: =
 
(1 −α) ¯A + αI

X
"
REFERENCES,0.6025437201907791,"TS,: W∗= [Y]TS,: = I|Y|×|Y|."
REFERENCES,0.604133545310016,"Since W∗satisﬁes L([z]TV,:, [Y]TV,:) = 0, we know W∗is the optimal weight matrix that we can
learn under TV."
REFERENCES,0.6057233704292527,"Now consider an arbitrary target node v ∈DV with class label yv ∈Y, and a unit structural
perturbation leveraging gambit node u ∈V with degree da that affects the predictions zv of node v
made by GNN f (2)
s
. Without loss of generality, we assume node v has yv = 1. Note that we will only
discuss the case of direct structural perturbation to the 1-hop neighborhood N(v) of target node"
REFERENCES,0.6073131955484896,Under review as a conference paper at ICLR 2022
REFERENCES,0.6089030206677265,"v, as indirect perturbations do not affect the predictions zv for node v produced by a single GNN
layer. Denote ∆¯A = ¯A′ −¯A as the change in the adjacency matrix ¯A before and after the attack.
Similar to Proof 1, for simplicity of derivation, we assume that the perturbation does not change the
row-stochastic normalization of ¯A, and we use δ1 to denote addition (δ1 = 1) or removal (δ1 = −1)
of a homophilous edge to node v, and use δ2 to denote addition or removal of a heterophilous edge
to node v."
REFERENCES,0.6104928457869634,"In the case of δ1 = ±1 and δ2 = 0, we have
 
(1 −α)∆¯A + αI

X
"
REFERENCES,0.6120826709062003,"v,: = (1 −α)δ1"
REFERENCES,0.6136724960254372,"da|Y|
[ ((|Y| −1)p + 1)
(1 −p)
· · ·
(1 −p) ]"
REFERENCES,0.615262321144674,"and the change in the CM-type attack loss LCM
atk before and after the perturbation can be derived as"
REFERENCES,0.6168521462639109,"∆LCM
atk =
((1 −α)|Y| + α −1)δ1
da(α(h −1) −h)|Y| + da
.
(19)"
REFERENCES,0.6184419713831478,"In the case of δ1 = 0 and δ2 = ±1, we have
 
(1 −α)∆¯A + αI

X
"
REFERENCES,0.6200317965023847,"v,: = (1 −α)δ2"
REFERENCES,0.6216216216216216,"da|Y|
[ (1 −p)
(|Y| −1)p + 1
· · ·
(|Y| −1)p + 1 ]"
REFERENCES,0.6232114467408585,"and the change in the CM-type attack loss LCM
atk before and after the perturbation can be derived as"
REFERENCES,0.6248012718600954,"∆LCM
atk =
(α −1)(|Y| −1)δ2
da(α(h −1) −h)|Y| + da
.
(20)"
REFERENCES,0.6263910969793323,"From Eq. (19) and Eq. (20), the change in the CM-type attack loss ∆LCM
atk for GNN layer f(A, X; α)
considering both δ1 and δ2 can be written as"
REFERENCES,0.6279809220985691,"∆LCM,f
atk
=
((1 −α)|Y| + α −1)δ1
da(α(h −1) −h)|Y| + da
+
(α −1)(|Y| −1)δ2
da(α(h −1) −h)|Y| + da
.
(21)"
REFERENCES,0.629570747217806,"Layer fs(A, X) =
¯AsXW.
This formulation is a special case of the previously discussed
f(A, X; α) formulation when α =
1
1+da ."
REFERENCES,0.6311605723370429,"In the case of δ1 = ±1 and δ2 = 0, from Eq. (19), we have the change in the CM-type attack loss
LCM
atk before and after the perturbation as"
REFERENCES,0.6327503974562798,"∆LCM
atk = −
(|Y| −1)δ1
da(h|Y| −1) + |Y| −1.
(22)"
REFERENCES,0.6343402225755167,"In the case of δ1 = 0 and δ2 = ±1, from Eq. (20), we have the change in the CM-type attack loss
LCM
atk before and after the perturbation as"
REFERENCES,0.6359300476947536,"∆LCM
atk =
(|Y| −1)δ2
da(h|Y| −1) + |Y| −1.
(23)"
REFERENCES,0.6375198728139905,"From Eq. (22) and Eq. (23), the change in the CM-type attack loss ∆LCM
atk for GNN layer fs(A, X)
considering both δ1 and δ2 can be written as"
REFERENCES,0.6391096979332274,"∆LCM,fs
atk
= −
(|Y| −1)δ1
da(h|Y| −1) + |Y| −1 +
(|Y| −1)δ2
da(h|Y| −1) + |Y| −1
(24)"
REFERENCES,0.6406995230524642,"Comparison of increase in attack loss ∆LCM
atk ."
REFERENCES,0.6422893481717011,"Solving the following system of inequalities for variable α






"
REFERENCES,0.643879173290938,"




"
REFERENCES,0.6454689984101749,"∆LCM,fs
atk
> ∆LCM,f
atk
> 0
α, h ∈[0, 1]
|Y| ≥2
da, |Y| ∈Z+"
REFERENCES,0.6470588235294118,"δ1, δ2 ∈{−1, 0, 1} (25)"
REFERENCES,0.6486486486486487,Under review as a conference paper at ICLR 2022
REFERENCES,0.6502384737678856,"we get the valid range of α as


 
"
REFERENCES,0.6518282988871225,"1
da+1 < α < 1, when 0 ≤h <
1
|Y| and 0 < da <
1−|Y|
h|Y|−1 and δ1 < δ2
0 ≤α <
1
da+1, when 0 ≤h <
1
|Y| and da >
1−|Y|
h|Y|−1 and δ1 > δ2
1
da+1 < α < 1, when
1
|Y| ≤h ≤1 and δ1 < δ2"
REFERENCES,0.6534181240063593,".
(26)"
REFERENCES,0.6550079491255962,"From the solution in Eq. (26), we observe that when h >
1
|Y|, a unit perturbation increasing Latk as
discussed in Theorem 1 (i.e. δ1 = −1 and δ2 = 0, or δ1 = 0 and δ2 = 1) will satisfy the condition
δ1 < δ2, and thus lead to a strictly smaller increase ∆LCM,f
atk
in the attack loss for layer f(A, X; α)
than the increase ∆LCM,fs
atk
for layer fs(A, X) if α >
1
da+1.
■"
REFERENCES,0.6565977742448331,Under review as a conference paper at ICLR 2022
REFERENCES,0.6581875993640699,"D
DETAILED EXPERIMENTAL SETUPS AND HYPERPARAMETERS"
REFERENCES,0.6597774244833068,"D.1
INSTANTIATIONS OF DESIGN ON GNNS"
REFERENCES,0.6613672496025437,"We explicitly demonstrate how the heterophilous design outlined in Eq. (1) of §3.2 are instanti-
ated in various GNN models used in our experiments. In particular, we highlight how these GNN
architectures allow separate aggregations of the ego- and neighbor-embeddings."
REFERENCES,0.6629570747217806,"• In H2GCN, a ﬁnal hidden representation is computed for each node v ∈V through r(ﬁnal)
v
=
CONCAT(r(0)
v , r(1)
v , ..., r(K)
v
), where r(0)
v
is the non-linear ego-embedding of node features and
r(k)
v
are the intermediate representations aggregated in the k-th layer, where k ∈(1, ..., K). By
interpreting the update rule’s CONCAT as the ENC operation, AGGR1 as the skip connection to
the ego-embedding of node features, and the concatenation of the intermediate representations
as AGGR2, the ego- and neighbor-embeddings are separately aggregated and the identiﬁed het-
erophilous design is recovered."
REFERENCES,0.6645468998410174,"• Similarly, GraphSAGE (with mean aggregator) utilizes a concatenation-based encoding scheme
through their update of"
REFERENCES,0.6661367249602543,"r(k)
v
= σ

CONCAT

r(k−1)
v
, MEAN

{r(k−1)
u
, ∀u ∈N(i)}

· W
"
REFERENCES,0.6677265500794912,"where AGGR1(·) = r(k−1)
u
, AGGR2 is the mean function and ENC(x1, x2) = σ(CONCAT(x1, x2)·
W)."
REFERENCES,0.6693163751987281,"• GPR-GNN embeds each node feature vector separately with a fully connected layer to compute
r(0)
v
(or H(0)
v: as in the original paper), similar to H2GCN, and then updates each node’s hidden
representations through a weighted sum of all k-th hop layers around the ego-node, where k ∈
(0, 1, ..., K). By interpreting the summation as the ENC operation as well as AGGR1(·) = γ0H(0)"
REFERENCES,0.670906200317965,"and AGGR2(·) = PK
k=1 γk ˜Ak
symH(k−1), where γ is a vector denoting the weights associated with
each k-hop ego network, the aggregation of the ego- and neighbor-embeddings can be decoupled
and thus GPR-GNN also satisﬁes the heterophilous design."
REFERENCES,0.6724960254372019,• FAGCN follows a similar update function to GPR-GNN with
REFERENCES,0.6740858505564388,"h(l)
i
= εh(0)
i
+
X"
REFERENCES,0.6756756756756757,j∈N(i)
REFERENCES,0.6772655007949125,"αG
ij
p"
REFERENCES,0.6788553259141494,"didj
h(l−1)
j"
REFERENCES,0.6804451510333863,"where h(0)
i , equivalent to r(0)
i
in Eq. (1), represents the non-linear ego-embedding and αG
ij is a
proportionality constant measuring the ratio of low and high frequency components. The relation-
ship between FAGCN and the proposed heterophilous design can similarly be inferred by inter-
preting the sum as the ENC operation, AGGR1(·) = εh(0)
i
as a weighted skip connection to the
ego-embedding of feature vectors, and the weighted sum of embeddings within the neighborhood
N(i) of node i ∈V as AGGR2(·)."
REFERENCES,0.6820349761526232,"• CPGNN formulates the update function of belief vectors ¯B(k) after the k-th propagation layer as
¯B(k) = ¯B(0) + A ¯B(k−1) ¯H, where ¯B(0) consists of prior belief vectors for each node (which can
be seen as the ego-embedding r(0)
i
in Eq. (1)), and ¯H is the linearized compatibility matrix. The
heterophilous design can be recovered by letting AGGR1(·) = ¯B(0) as a skip connection to the
prior belief, AGGR2(·) = A ¯B(k−1) ¯H, and the ENC operation as the summation."
REFERENCES,0.6836248012718601,Under review as a conference paper at ICLR 2022
REFERENCES,0.685214626391097,"D.2
MORE DETAILS ON THE EXPERIMENTAL SETUP"
REFERENCES,0.6868044515103339,"Benchmark Implementations. Our empirical framework is built on DeepRobust (Li et al., 2020b),
Python Fire1 and signac2. We incorporated the following implementations of GNN models in our
framework. For GNNGuard and GCN-SVD, there are some implementation ambiguities, which we
discuss in the next paragraph."
REFERENCES,0.6883942766295708,"H2GCN (Zhu et al., 2020)
https://github.com/GemsLab/H2GCN
GraphSAGE (Hamilton et al., 2017)
Implemented on top of https://github.com/GemsLab/H2GCN
CPGNN (Zhu et al., 2021)
https://github.com/GemsLab/CPGNN
GNNGuard (Zhang & Zitnik, 2020)
https://github.com/mims-harvard/GNNGuard
ProGNN (Jin et al., 2020b)
https://github.com/ChandlerBang/Pro-GNN
GCN-SVD (Entezari et al., 2020)
https://github.com/DSE-MSU/DeepRobust/blob/master/examples/graph/test_gcn_svd.py
GAT (Veliˇckovi´c et al., 2018)
https://github.com/DSE-MSU/DeepRobust/blob/master/deeprobust/graph/defense/gat.py
GCN (Kipf & Welling, 2017)
https://github.com/DSE-MSU/DeepRobust/blob/master/deeprobust/graph/defense/gcn.py"
REFERENCES,0.6899841017488076,"Notes on the GNNGuard and GCN-SVD Implementations. We note that there are ambiguities in
the implementations of GNNGuard (Zhang & Zitnik, 2020) and GCN-SVD (Entezari et al., 2020),
which can lead to different variants with different performance and robustness, as we show in Ta-
ble 6."
REFERENCES,0.6915739268680445,"Table 6: Performance comparison between variants of GNNGuard and GCN-SVD: mean accuracy
± stdev over multiple sets of experiments."
REFERENCES,0.6931637519872814,"Homophilous graphs
Heterophilous graphs
Homophilous graphs
Heterophilous graphs"
REFERENCES,0.6947535771065183,"Cora
Citeseer
FB100
Snap
Cora
Citeseer
FB100
Snap
h=0.804
h=0.736
h=0.531
h=0.134
h=0.804
h=0.736
h=0.531
h=0.134"
REFERENCES,0.6963434022257552,"Clean Datasets
Clean Datasets"
REFERENCES,0.6979332273449921,"GNNGuard ( I )
75.56±5.15
70.00±6.24
68.89±2.08
31.67±0.00
79.58±0.97
71.68±1.10
65.31±1.48
26.37±0.70
GNNGuard (II)
77.22±6.29
67.78±4.78
67.22±2.08
28.33±3.60
80.15±0.55
72.61±0.28
65.66±0.60
26.51±0.98
GCN-SVD ( I ) k = 5
66.67±8.16
63.89±5.50
51.67±6.24
29.44±0.79
69.43±0.99
68.31±0.34
52.95±0.13
27.66±0.05
GCN-SVD (II) k = 5
52.78±5.50
35.00±1.36
50.56±4.37
25.00±5.93
55.05±1.77
41.47±0.72
52.40±0.18
25.84±0.07
GCN-SVD ( I ) k = 10
66.11±6.71
65.00±3.60
52.78±4.16
30.56±2.08
71.08±0.46
69.19±1.13
54.47±0.32
27.57±0.18
GCN-SVD (II) k = 10
66.11±4.78
45.00±3.60
51.11±2.08
22.22±4.78
64.79±1.56
52.17±0.39
51.19±0.41
25.45±0.21
GCN-SVD ( I ) k = 15
72.78±6.98
63.89±7.74
57.78±2.83
28.89±2.08
72.74±0.29
66.51±1.53
57.67±0.36
27.61±0.55
GCN-SVD (II) k = 15
69.44±2.08
46.67±6.24
52.78±5.15
21.67±1.36
65.61±0.19
60.55±0.73
53.24±0.45
26.63±0.25
GCN-SVD ( I ) k = 50
78.89±6.29
66.67±3.60
65.56±2.83
31.11±0.79
77.98±0.43
68.25±0.86
63.41±0.45
27.81±0.39
GCN-SVD (II) k = 50"
REFERENCES,0.699523052464229,NETTACK
REFERENCES,0.7011128775834659,"75.56±4.16
59.44±0.79
55.00±1.36
27.78±6.71"
REFERENCES,0.7027027027027027,Metattack
REFERENCES,0.7042925278219396,"76.61±0.31
66.90±0.16
55.47±0.23
25.62±0.12"
REFERENCES,0.7058823529411765,"Poison Attacks
Poison Attacks"
REFERENCES,0.7074721780604134,"GNNGuard ( I )
57.22±2.08
60.00±3.60
0.56±0.79
11.11±0.79
73.68±0.99
67.89±0.92
60.82±0.45
23.98±0.71
GNNGuard (II)
58.33±1.36
59.44±3.14
0.56±0.79
9.44±1.57
74.20±0.55
68.13±0.74
60.89±0.48
23.78±0.67
GCN-SVD ( I ) k = 5
64.44±9.06
60.00±4.71
41.67±6.24
27.78±6.29
64.65±2.57
66.35±1.48
53.14±0.43
25.64±0.47
GCN-SVD (II) k = 5
44.44±2.83
33.33±2.72
41.67±2.36
25.00±6.80
42.19±5.33
40.17±1.57
51.87±0.38
24.82±0.43
GCN-SVD ( I ) k = 10
67.78±5.50
57.78±1.57
35.56±1.57
31.67±5.93
65.54±1.28
65.46±0.92
55.68±0.15
25.93±0.75
GCN-SVD (II) k = 10
48.89±3.14
31.67±2.36
34.44±0.79
26.11±6.85
49.92±5.88
47.16±3.93
53.16±0.45
25.30±0.28
GCN-SVD ( I ) k = 15
64.44±3.93
52.78±4.78
23.89±6.29
29.44±3.93
65.46±2.33
61.04±1.04
58.06±0.05
25.83±0.69
GCN-SVD (II) k = 15
51.11±3.42
33.89±3.93
30.56±2.83
26.11±6.14
50.30±3.80
47.87±1.31
54.20±0.36
25.25±0.91
GCN-SVD ( I ) k = 50
61.67±4.71
48.33±7.07
16.67±4.08
30.56±7.97
60.06±5.43
49.31±4.52
62.07±0.69
26.05±0.63
GCN-SVD (II) k = 50"
REFERENCES,0.7090620031796503,NETTACK
REFERENCES,0.7106518282988871,"53.33±4.91
28.89±2.08
23.33±2.72
25.00±5.44"
REFERENCES,0.712241653418124,Metattack
REFERENCES,0.7138314785373608,"47.82±7.59
51.20±1.78
55.00±2.06
25.18±0.98"
REFERENCES,0.7154213036565977,"Evasion Attacks
Evasion Attacks"
REFERENCES,0.7170111287758346,"GNNGuard ( I )
-
-
-
-
-
-
-
-
GNNGuard (II)
-
-
-
-
-
-
-
-
GCN-SVD ( I ) k = 5
64.44±8.20
59.44±3.93
41.11±7.97
31.67±3.60
68.18±1.13
67.54±0.97
52.91±0.28
27.40±0.29
GCN-SVD (II) k = 5
46.67±4.08
32.22±4.37
45.56±3.93
26.11±6.14
52.01±2.45
30.69±1.01
52.32±0.10
25.87±0.27
GCN-SVD ( I ) k = 10
65.56±7.49
57.22±3.42
36.11±1.57
31.11±0.79
68.36±1.33
67.85±0.72
54.51±0.68
27.30±0.30
GCN-SVD (II) k = 10
57.22±6.14
37.78±3.93
36.67±3.60
30.56±8.85
58.70±3.00
45.62±2.52
52.58±0.20
24.60±0.26
GCN-SVD ( I ) k = 15
67.22±6.14
54.44±6.14
24.44±5.50
30.00±1.36
69.32±1.21
65.26±0.97
57.79±0.38
28.06±0.23
GCN-SVD (II) k = 15
65.56±6.14
38.33±5.93
23.89±6.98
27.22±7.97
64.02±1.30
54.09±2.25
53.81±0.35
25.29±0.41
GCN-SVD ( I ) k = 50
65.00±6.24
50.56±6.43
18.33±2.36
25.56±1.57
75.30±0.62
64.49±1.58
63.53±0.26
27.74±0.61
GCN-SVD (II) k = 50"
REFERENCES,0.7186009538950715,NETTACK
REFERENCES,0.7201907790143084,"60.00±6.24
47.78±4.37
25.00±4.71
30.56±9.56"
REFERENCES,0.7217806041335453,Metattack
REFERENCES,0.7233704292527822,"73.21±1.68
59.34±3.42
56.95±0.33
25.80±0.67"
REFERENCES,0.724960254372019,"For GNNGuard, the ambiguity comes from different interpretations of Eq. (4) in the original pa-
per (Zhang & Zitnik, 2020): we consider the authors’ original implementation as variant (I), and
the model described in the original paper as variant (II), which we implement by building on the
authors’ implementation."
REFERENCES,0.7265500794912559,"1https://github.com/google/python-fire
2https://signac.io"
REFERENCES,0.7281399046104928,Under review as a conference paper at ICLR 2022
REFERENCES,0.7297297297297297,"Table 6 shows that the differences in accuracy between the two variants are in most cases less than
2%, while in many cases variant (II) shows better accuracy compared to variant (I), especially in
experiments against Metattack. Thus, we use variant (II) as the default implementation for the
empirical evaluations in §5."
REFERENCES,0.7313195548489666,"For GCN-SVD, the ambiguity comes from the order of applying the preprocessing and low-rank
approximation for the adjacency matrix A, which is not discussed in the original paper (Entezari
et al., 2020)."
REFERENCES,0.7329093799682035,"• Variant (I): Since the original authors’ implementation is not publicly available, we consider
the implementation provided in DeepRobust (Li et al., 2020b) as variant (I): it ﬁrst calculates
the rank-k approximation ˜A of A, and then generates the preprocessed adjacency matrix ˆAs =
˜D−1/2
s
( ˜A + I) ˜D−1/2
s
= ˜D−1/2
s
˜As ˜D−1/2
s
, which is then processed by a GCN (Kipf & Welling,
2017). However, as the identity matrix I is added into ˜A after the low-rank approximation, the
diagonal elements of the resulting ˆAs matrix (i.e., the weights for the self-loop edges in the graph)
can become signiﬁcantly larger than the off-diagonal elements, especially when the rank k is low.
As a result, this order of applying the preprocessing and low-rank approximation inadvertently
adopts Design 1 which we identiﬁed; we have shown in Theorem 3 that even merely increasing
the weights α for the ego-embedding in the linear combination ENC in Eq. (1) can lead to reduced
attack loss Latk under structural perturbations.
• Variant (II): In variant (II), we consider the opposite order where we ﬁrst add the identity matrix
I (self-loops) into the original adjacency matrix A, then we perform the low-rank approximation,
and ﬁnally we symmetrically normalize the low-rank matrix ˜As to generate the preprocessed ˆAs
used by a GCN model. This order allows the diagonal elements to be more on par in magnitude
with the off-diagonal elements. As an example, on Citeseer, when using variant (I) with rank
k = 5, the average magnitude of the diagonal elements of the resulting ˆAs can be 22.3 times
the average magnitude of the off-diagonal elements; when using variant (II) instead, the average
magnitude of the diagonal elements is only 9.0 times that of the off-diagonal elements."
REFERENCES,0.7344992050874404,"In Table 6, we report the performance of the two variants of GCN-SVD under the experimental set-
tings considered in §5 with rank k ∈{5, 10, 15, 50}: Variant (I), with our ﬁrst design implicitly built-
in, has in most cases signiﬁcantly higher performance than variant (II), especially on homophilous
datasets and when rank k is low. These results further demonstrate the effectiveness of Design 1 that
we identiﬁed. To enable a clear perspective of the performance and robustness improvement brought
by Design 1, in our empirical analysis in §5, on top of the low-rank approximation vaccination we
adopt variant (II) as the default implementation."
REFERENCES,0.7360890302066773,"Attack Implementations.
We incorporate the following implementations of attacks from
DeepRobust (Li et al., 2020b) to our empirical framework."
REFERENCES,0.7376788553259142,"NETTACK (Z¨ugner et al., 2018)
https://github.com/DSE-MSU/DeepRobust/blob/master/deeprobust/graph/targeted_attack/nettack.py
Metattack (Z¨ugner & G¨unnemann, 2019a)
https://github.com/DSE-MSU/DeepRobust/blob/master/deeprobust/graph/global_attack/mettack.py"
REFERENCES,0.739268680445151,"More Details on the Attack Setup. For NETTACK, we randomly select 60 nodes from the graph as
the target nodes for each set of perturbations, instead of the GCN-based target selection approach as
in (Z¨ugner et al., 2018): the approach in (Z¨ugner et al., 2018) only selects nodes that are correctly
classiﬁed by GCN (Kipf & Welling, 2017) on clean data, thus introducing unfair advantages towards
GCN, especially on heterophilous datasets where GCN can exhibit signiﬁcantly inferior accuracy to
models like GraphSAGE (Zhu et al., 2020). For the experiments in §5.1, we use a budget of 1
perturbation per target node to match the setups of our theorems; for the benchmark study in §5.2,
we use an attack budget equal to a node’s degree and allow direct attacks on target nodes. For
Metattack, we budget the attack as 20% of the number of edges in each dataset, and we use the
Meta-Self variant as it shows the most destructiveness (Z¨ugner & G¨unnemann, 2019a)."
REFERENCES,0.7408585055643879,"More Details on Randomized Smoothing Setup. Following Bojchevski et al. (2020), we similarly
set the signiﬁcance level α = 0.01 (i.e., the certiﬁcates hold with probability 1 −α = 0.99), using
103 samples to estimate the predictions of the smoothed classiﬁer f(φ(s)) for input s, and another
106 samples to obtain multi-class certiﬁcates. For the randomization scheme φ, we only consider
structural perturbations where with probability p+ an new edge is added, and with probability p−
an existing edge is removed. We consider multiple sets of (p+, p−) in our experiments for a ﬁner-"
REFERENCES,0.7424483306836248,Under review as a conference paper at ICLR 2022
REFERENCES,0.7440381558028617,"grained evaluation: (1) p+ = 0.001, p−= 0.4, where both addition and deletion are allowed; (2)
p+ = 0.001, p−= 0, where only addition is allowed; and (3) p+ = 0, p−= 0.4, where only
deletion is allowed."
REFERENCES,0.7456279809220986,"Hardware Speciﬁcations. We use a workstation with a 12-core AMD Ryzen 9 3900X CPU, 64GB
RAM, and a Quadro P6000 GPU with 24 GB GPU Memory."
REFERENCES,0.7472178060413355,"D.3
COMBINING HETEROPHILOUS DESIGN WITH LOW-RANK APPROXIMATION"
REFERENCES,0.7488076311605724,"In this section, we provide more details on how we incorporate the low-rank approximation vacci-
nation into the formulations of H2GCN (Zhu et al., 2020) and GraphSAGE (Hamilton et al., 2017)
in order to form the hybrid methods, H2GCN-SVD and GraphSAGE-SVD."
REFERENCES,0.7503974562798092,"H2GCN-SVD. From (Zhu et al., 2020), each layer in the neighborhood aggregation stage of
H2GCN can be algebraically formulated as"
REFERENCES,0.7519872813990461,"R(k) = CONCAT

ˆA2R(k−1), ˆAR(k−1), R(k−1)
,
(27)"
REFERENCES,0.753577106518283,"where ˆA = D−1/2AD−1/2 is the symmetrically normalized adjacency matrix without self-
loops; ˆA2 = D−1/2
2
A2D−1/2
2
is the symmetrically normalized 2-hop graph adjacency matrix
A2 ∈{0, 1}|V|×|V|, with [A2]u,v = 1 if v is in the 2-hop neighborhood N2(u) of node u; R(k)
are the node representations after the k-th layer, and CONCAT is the column-wise concatenation
function. For H2GCN-SVD, we replace ˆA and ˆA2 in Eq. (27) respectively with the low-rank
approximations of ˜A and ˜A2, which are both postprocessed to be symmetrically normalized."
REFERENCES,0.7551669316375199,"GraphSAGE-SVD. From (Hamilton et al., 2017), each layer in GraphSAGE can be algebraically
formulated as
R(k) = σ

CONCAT

¯AR(k−1), R(k−1)
· W(k−1)
,
(28)"
REFERENCES,0.7567567567567568,"where ¯A is the row-stochastic graph adjacency matrix without self-loops; R(k) are the node rep-
resentations after the k-th layer; CONCAT is the column-wise concatenation function; W(k) is the
learnable weight matrix for the k-th layer, and σ is the non-linear activation function (ReLU). For
GraphSAGE-SVD, we replace ¯A in Eq. (28) with the low-rank approximation of the adjacency
matrix ˜A, postprocessed by row-stochastic normalization. Note that we do not enable the neighbor-
hood sampling function for the GraphSAGE and GraphSAGE-SVD models tested in this work, as
noted in Appendix D.4."
REFERENCES,0.7583465818759937,"D.4
HYPERPARAMETERS"
REFERENCES,0.7599364069952306,• H2GCN-SVD
REFERENCES,0.7615262321144675,Initialization Parameters:
REFERENCES,0.7631160572337043,"– adj svd rank:
best k chosen from {5, 50} for each dataset"
REFERENCES,0.7647058823529411,Training Parameters:
REFERENCES,0.766295707472178,"– early stopping: Yes
– train iters: 200
– patience: 100"
REFERENCES,0.7678855325914149,• GraphSAGE-SVD
REFERENCES,0.7694753577106518,Initialization Parameters:
REFERENCES,0.7710651828298887,"– adj nhood: [’1’]
– network setup:
I-T1-G-V-C1-M64-R-T2-G-V-C2-MO-R
– adj norm type: rw
– adj svd rank:
best k chosen from {5, 50} for each dataset"
REFERENCES,0.7726550079491256,Training Parameters:
REFERENCES,0.7742448330683624,"– early stopping: Yes
– train iters: 200
– patience: 100"
REFERENCES,0.7758346581875993,Under review as a conference paper at ICLR 2022
REFERENCES,0.7774244833068362,• H2GCN
REFERENCES,0.7790143084260731,"Initialization Parameters:
(default parameters)"
REFERENCES,0.78060413354531,Training Parameters:
REFERENCES,0.7821939586645469,"– early stopping: Yes
– train iters: 200
– patience: 100
– lr: 0.01"
REFERENCES,0.7837837837837838,• GraphSAGE
REFERENCES,0.7853736089030207,Initialization Parameters:
REFERENCES,0.7869634340222575,"– adj nhood: [’1’]
– network setup:
I-T1-G-V-C1-M64-R-T2-G-V-C2-MO-R
– adj norm type: rw"
REFERENCES,0.7885532591414944,Training Parameters:
REFERENCES,0.7901430842607313,"– early stopping: Yes
– train iters: 200
– patience: 100
– lr: 0.01"
REFERENCES,0.7917329093799682,• CPGNN
REFERENCES,0.7933227344992051,Initialization Parameters:
REFERENCES,0.794912559618442,"– network setup:
M64-R-MO-E-BP2"
REFERENCES,0.7965023847376789,Training Parameters:
REFERENCES,0.7980922098569158,"– early stopping: Yes
– train iters: 400
– patience: 100
– lr: 0.01"
REFERENCES,0.7996820349761526,• GPR-GNN
REFERENCES,0.8012718600953895,Initialization Parameters:
REFERENCES,0.8028616852146264,"– nhid: 64
– alpha: 0.9, which is chosen from the best
α ∈{0.1, 0.2, 0.5, 0.9} on all datasets"
REFERENCES,0.8044515103338633,Training Parameters:
REFERENCES,0.8060413354531002,"– train iters: 200
– lr: 0.01"
REFERENCES,0.8076311605723371,• FAGCN
REFERENCES,0.809220985691574,Initialization Parameters:
REFERENCES,0.8108108108108109,"– nhid: 64
– alpha: 0.9, which is chosen from the best
α ∈{0.1, 0.2, 0.5, 0.9} on all datasets
– dropout: 0.5"
REFERENCES,0.8124006359300477,Training Parameters:
REFERENCES,0.8139904610492846,"– early stopping: Yes
– lr: 0.01"
REFERENCES,0.8155802861685215,• GNNGuard
REFERENCES,0.8171701112877583,Initialization Parameters:
REFERENCES,0.8187599364069952,"– nhid: 64
– dropout: 0.5
– base model: GCN for variant (I);
GCN-fixed for variant (II) (default)."
REFERENCES,0.8203497615262321,Training Parameters:
REFERENCES,0.821939586645469,"– train iters: 81
– lr: 0.01"
REFERENCES,0.8235294117647058,Under review as a conference paper at ICLR 2022
REFERENCES,0.8251192368839427,• ProGNN
REFERENCES,0.8267090620031796,Initialization Parameters:
REFERENCES,0.8282988871224165,"– nhid: 64
– dropout: 0.5"
REFERENCES,0.8298887122416534,Training Parameters:
REFERENCES,0.8314785373608903,"– epochs: 400
– lr: 0.01
– lr adj: 0.01
– weight decay: 5e-4
– alpha: 5e-4
– beta: 1.5
– gamma: 1
– lambda : 0
– phi: 0
– outer steps: 1
– innter steps: 2"
REFERENCES,0.8330683624801272,• GCN-SVD
REFERENCES,0.834658187599364,Initialization Parameters:
REFERENCES,0.8362480127186009,"– nhid: 64
– k: best k chosen from {5, 10, 15, 50} for
each dataset
– dropout: 0.5
– svd solver:
eye-svd (for variant (II) only)"
REFERENCES,0.8378378378378378,Training Parameters:
REFERENCES,0.8394276629570747,"– train iters: 200
– weight decay: 5e-4
– lr: 0.01 • GCN"
REFERENCES,0.8410174880763116,"Initialization Parameters
(in class MultiLayerGCN):"
REFERENCES,0.8426073131955485,"– nhid: 64
– nlayer: 2"
REFERENCES,0.8441971383147854,Training Parameters:
REFERENCES,0.8457869634340223,"– train iters: 200
– lr: 0.01
– weight decay: 5e-4 • GAT"
REFERENCES,0.8473767885532592,Initialization Parameters
REFERENCES,0.848966613672496,"– nhid: 8
– heads: 8
– dropout: 0.5"
REFERENCES,0.8505564387917329,Training Parameters:
REFERENCES,0.8521462639109698,"– early stopping: Yes
– train iters: 1000
– patience: 100
– lr: 0.01
– weight decay: 5e-4 • MLP"
REFERENCES,0.8537360890302067,"Initialization Parameters:
(in class H2GCN):
– network setup:
M64-R-D0.5-MO"
REFERENCES,0.8553259141494436,Training Parameters:
REFERENCES,0.8569157392686805,"– early stopping: Yes
– train iters: 200
– patience: 100
– lr: 0.01"
REFERENCES,0.8585055643879174,Under review as a conference paper at ICLR 2022
REFERENCES,0.8600953895071543,"D.5
DATASETS"
REFERENCES,0.8616852146263911,Dataset and Unidentiﬁability.
REFERENCES,0.863275039745628,"• Heterophilous Datasets: FB100 (Traud et al., 2012) is a set of 100 university friendship network
snapshots from Facebook in 2005 (Lim et al., 2021), from which we use one network. Each node
is labeled with the reported gender, and the features encode education and accommodation. Data is
sent to the original authors (Lim et al., 2021) in an anonymized form. Though the dataset contains
limited demographic (categorical) information volunteered by users on their individual Facebook
pages, we manually inspect the dataset and conﬁrm that the anonymized dataset is not recoverable
and thus not identiﬁable. Also, no offensive content is found within the data.
Snap Patents (Leskovec et al., 2005; Leskovec & Krevl, 2014) is a utility patent citation network.
Node labels reﬂect the time the patent was granted, and the features are derived from the patent’s
metadata. The dataset is maintained by the National Bureau of Economic Research, and is freely
available for download3. Neither personally identiﬁable information nor offensive content is iden-
tiﬁed when we manually inspect the dataset.
• Homophilous Datasets: Cora (McCallum, 2000) and Citeseer (Sen et al., 2008) datasets are
scientiﬁc publication citation networks, whose labels categorize the research ﬁeld, and features
indicate the absence or presence of the corresponding word from the dictionary. No personally
identiﬁable information or offensive content is identiﬁed when we manually inspect both datasets."
REFERENCES,0.8648648648648649,"Downsampling. For better computational tractability, we sample a subset of the Snap Patents data
using a snowball sampling approach (Goodman, 1961), where a random 20% of the neighbors for
each traversed node are kept. We provide the pseudocode for the downsampling process in Algo-
rithm 1."
REFERENCES,0.8664546899841018,"Algorithm 1: Downsampling Algorithm For Snap Patents
Input: Graph to sample G
Number of nodes to sample N
Sampling ratio p
Output: Downsampled graph G′"
INITIALIZATION,0.8680445151033387,1 initialization
INITIALIZATION,0.8696343402225755,"/* Initialize a queue bfsquene for Breadth First Search,
and a list nodessampled for storing sampled nodes
*/"
INITIALIZATION,0.8712241653418124,2 bfsquene ←QUEUE()
INITIALIZATION,0.8728139904610492,3 nodessampled ←LIST()
INITIALIZATION,0.8744038155802861,"/* Start BFS with a random node from the largest connected component
in G;
RANDOM(array, n) returns n elements from an array with equal
probability without replacement
*/"
INITIALIZATION,0.875993640699523,"4 nodestarting ←RANDOM(LARGESTCONNECTEDCOMPONENT(G), 1)"
PUSH NODESTARTING INTO BFSQUENE,0.8775834658187599,5 push nodestarting into bfsquene
PUSH NODESTARTING INTO BFSQUENE,0.8791732909379968,6 while LENGTH(nodessampled) ¡ N do
PUSH NODESTARTING INTO BFSQUENE,0.8807631160572337,"7
node ←bfsquene.pop()"
PUSH NODESTARTING INTO BFSQUENE,0.8823529411764706,"8
neighbors ←one hop neighbors of node"
PUSH NODESTARTING INTO BFSQUENE,0.8839427662957074,"9
neighborsdrawn ←RANDOM(neighbors, p× LENGTH(neighbors))"
PUSH NODESTARTING INTO BFSQUENE,0.8855325914149443,"10
for neighbor ∈neighborsdrawn do"
PUSH NODESTARTING INTO BFSQUENE,0.8871224165341812,"11
if neighbor /∈nodessampled then"
APPEND NEIGHBOR TO NODESSAMPLED,0.8887122416534181,"12
append neighbor to nodessampled"
PUSH NEIGHBOR INTO BFSQUENE,0.890302066772655,"13
push neighbor into bfsquene"
END,0.8918918918918919,"14
end"
END,0.8934817170111288,"15
end"
END,0.8950715421303657,16 end
END,0.8966613672496025,17 G′ ←subgraph induced by nodessampled
END,0.8982511923688394,18 return G′
END,0.8998410174880763,3https://www.nber.org/research/data/us-patents
END,0.9014308426073132,Under review as a conference paper at ICLR 2022
END,0.9030206677265501,"E
DETAILED EXPERIMENT RESULTS"
END,0.904610492845787,"E.1
DETAILED RESULTS FOR EVALUATION ON EMPIRICAL ROBUSTNESS"
END,0.9062003179650239,"Table 7: Detailed classiﬁcation accuracy (and standard deviation) of each method for the target
nodes attacked by NETTACK, calculated across different sets of perturbation."
END,0.9077901430842608,"Homophilous graphs
Heterophilous graphs"
END,0.9093799682034976,"Cora
Citeseer
FB100
Snap
h=0.804
h=0.736
h=0.531
h=0.134 Clean"
END,0.9109697933227345,"H2GCN-SVD
74.44±3.42
70.00±2.72
61.67±2.36
30.56±2.08
GraphSAGE-SVD
77.22±4.78
70.00±1.36
60.00±4.08
27.22±5.50
H2GCN
82.78±8.31
69.44±6.98
60.56±1.57
30.00±2.72
GraphSAGE
82.22±9.56
70.56±6.85
60.00±2.72
24.44±4.16
CPGNN
81.67±8.28
73.33±1.36
66.11±4.16
28.89±5.50
GPRGNN
82.22±7.49
67.78±2.08
56.67±4.91
27.78±3.42
FAGCN
83.33±8.16
70.56±5.15
58.33±5.93
29.44±0.79
GNNGuard
77.22±6.29
67.78±4.78
67.22±2.08
28.33±3.60
ProGNN
79.44±3.42
67.22±4.78
51.11±3.93
27.22±5.50
GCN-SVD
75.56±4.16
59.44±0.79
50.56±4.37
27.78±6.71
GAT
84.44±3.42
70.00±7.20
60.56±0.79
30.56±2.83
GCN
82.78±4.78
69.44±7.74
63.33±2.72
33.33±2.72
MLP
64.44±3.42
70.56±3.42
57.78±2.83
30.00±2.72"
END,0.9125596184419714,Poison (Pre-training)
END,0.9141494435612083,"H2GCN-SVD
70.00±2.72
65.00±3.60
59.44±3.42
28.89±3.42
GraphSAGE-SVD
71.67±2.36
67.78±3.42
60.00±1.36
26.67±6.80
H2GCN
38.89±5.50
27.22±1.57
27.78±3.42
12.78±2.83
GraphSAGE
36.67±2.72
31.67±10.89
33.89±3.42
16.67±7.07
CPGNN
47.22±6.14
40.56±9.65
49.44±10.30
21.67±2.72
GPRGNN
21.67±2.72
24.44±2.08
2.78±0.79
4.44±2.08
FAGCN
26.11±6.14
25.56±6.43
6.11±2.83
8.33±3.60
GNNGuard
58.33±1.36
59.44±3.14
0.56±0.79
9.44±1.57
ProGNN
48.89±7.97
32.78±7.49
33.89±4.78
17.78±9.26
GCN-SVD
53.33±4.91
28.89±2.08
41.67±2.36
25.00±5.44
GAT
13.89±0.79
8.89±3.42
0.56±0.79
3.89±4.37
GCN
1.67±0.00
4.44±2.83
0.56±0.79
2.22±2.08
MLP
64.44±3.42
70.56±3.42
57.78±2.83
30.00±2.72"
END,0.9157392686804452,Evasion (Post-training)
END,0.9173290937996821,"H2GCN-SVD
70.56±3.42
66.11±4.78
60.00±2.72
28.89±3.14
GraphSAGE-SVD
70.56±2.08
68.33±3.60
59.44±2.83
26.11±6.85
H2GCN
45.56±3.42
33.89±1.57
32.78±0.79
12.78±2.83
GraphSAGE
44.44±3.14
35.00±8.92
42.22±2.83
15.56±6.71
CPGNN
52.22±6.98
46.67±6.80
15.56±2.83
22.78±4.78
GPRGNN
29.44±3.14
32.22±0.79
9.44±2.83
3.33±1.36
FAGCN
38.89±6.71
37.78±4.78
12.78±2.83
10.00±2.36
GNNGuard
-
-
-
-
ProGNN
-
-
-
-
GCN-SVD
60.00±6.24
47.78±4.37
45.56±3.93
30.56±9.56
GAT
12.22±4.16
23.33±5.44
1.67±1.36
2.22±3.14
GCN
5.56±2.08
8.89±4.16
0.56±0.79
0.56±0.79
MLP
64.44±3.42
70.56±3.42
57.78±2.83
30.00±2.72"
END,0.918918918918919,Under review as a conference paper at ICLR 2022
END,0.9205087440381559,"Table 8: Detailed classiﬁcation accuracy (and standard deviation) for the unlabeled nodes of each
method attacked by Metattack with budget as 20% of the total number of edges of each graph,
calculated across different sets of perturbation."
END,0.9220985691573926,"Homophilous graphs
Heterophilous graphs"
END,0.9236883942766295,"Cora
Citeseer
FB100
Snap
h=0.804
h=0.736
h=0.531
h=0.134 Clean"
END,0.9252782193958664,"H2GCN-SVD
76.89±0.37
73.42±1.03
56.81±0.77
27.63±0.26
GraphSAGE-SVD
77.52±0.29
72.16±0.17
57.38±0.86
26.72±0.70
H2GCN
83.94±0.97
75.34±0.90
56.95±0.13
27.49±0.05
GraphSAGE
82.21±0.63
74.64±0.93
56.60±1.40
27.18±0.84
CPGNN
80.67±0.51
74.92±0.62
60.17±7.09
27.13±0.63
GPRGNN
81.84±1.75
70.71±0.46
62.40±0.83
26.08±0.31
FAGCN
81.59±0.82
73.99±0.63
59.64±1.38
27.15±0.23
GNNGuard
80.15±0.55
72.61±0.28
65.66±0.60
26.51±0.98
ProGNN
81.32±0.43
71.82±1.12
49.84±0.03
27.49±0.66
GCN-SVD
76.61±0.31
66.90±0.16
55.47±0.23
26.63±0.25
GAT
83.72±0.24
73.40±1.00
61.69±0.92
27.30±0.03
GCN
84.32±0.32
74.27±0.15
64.86±0.79
27.30±0.43
MLP
64.55±1.58
67.67±0.11
56.56±0.58
26.25±1.05"
END,0.9268680445151033,Poison (Pre-training)
END,0.9284578696343402,"H2GCN-SVD
67.87±0.47
70.42±0.46
56.72±0.08
25.60±0.14
GraphSAGE-SVD
68.86±1.32
69.10±0.52
55.76±0.33
26.58±0.30
H2GCN
57.75±6.61
54.34±0.82
54.84±0.76
25.34±0.59
GraphSAGE
54.68±2.56
59.74±1.74
54.72±0.83
24.14±0.76
CPGNN
74.55±1.23
68.07±1.93
61.58±1.50
26.76±0.41
GPRGNN
48.29±5.23
35.25±2.77
59.94±0.60
21.06±1.29
FAGCN
60.11±4.82
53.18±6.00
55.97±1.81
24.04±0.62
GNNGuard
74.20±0.55
68.13±0.74
60.89±0.48
23.78±0.67
ProGNN
45.10±6.20
46.58±1.02
53.40±1.19
24.80±1.09
GCN-SVD
47.82±7.59
51.20±1.78
55.00±2.06
25.25±0.91
GAT
41.70±3.60
48.40±2.17
50.37±0.66
25.00±0.73
GCN
37.46±3.35
45.81±2.99
51.82±1.41
25.03±0.68
MLP
64.55±1.58
67.67±0.11
56.56±0.58
26.25±1.05"
END,0.9300476947535771,Evasion (Post-training)
END,0.931637519872814,"H2GCN-SVD
74.01±0.35
71.54±1.92
56.58±0.63
27.26±0.17
GraphSAGE-SVD
74.31±0.40
70.22±0.90
57.38±0.88
26.77±1.01
H2GCN
82.86±1.01
73.20±2.04
57.05±0.20
27.10±0.06
GraphSAGE
80.57±0.55
72.89±1.72
56.91±1.61
27.16±0.78
CPGNN
79.06±1.18
73.44±0.98
60.19±7.20
27.02±0.75
GPRGNN
80.80±1.67
69.77±0.42
61.91±0.74
26.16±0.25
FAGCN
80.70±0.99
73.14±1.02
59.39±1.36
27.25±0.30
GNNGuard
-
-
-
-
ProGNN
-
-
-
-
GCN-SVD
73.21±1.68
59.34±3.42
56.95±0.33
25.29±0.41
GAT
81.96±0.31
70.70±0.69
61.44±0.94
27.45±0.13
GCN
83.03±0.69
73.06±0.58
64.86±0.47
27.15±0.39
MLP
64.55±1.58
67.67±0.11
56.56±0.58
26.25±1.05"
END,0.9332273449920508,Under review as a conference paper at ICLR 2022
END,0.9348171701112877,"E.2
DETAILED RESULTS FOR EVALUATION ON CERTIFIABLE ROBUSTNESS"
END,0.9364069952305246,"Table 9: Accumulated certiﬁcations (AC), average certiﬁable radii (¯ra and ¯rd) and accuracy of
GNNs with randomized smoothing enabled (i.e., f(φ(s))) on all nodes of the clean datasets, with a
ramdomization scheme φ allowing addition only (i.e., p+ = 0.001, p−= 0) or deletion only (i.e.,
p+ = 0, p−= 0.4). For each statistic, we report the mean and stdev across 3 runs. Best results are
highlighted in blue per dataset, and in gray per model group. For results with randomization scheme
allowing both addition and deletion, see Table 4. Hete."
END,0.9379968203497615,"Addition Only
Deletion Only"
END,0.9395866454689984,"AC
¯ra
¯rd
Acc. %
AC
¯ra
¯rd
Acc. %"
END,0.9411764705882353,"H2GCN
✓ Cora"
END,0.9427662957074722,"0.42±0.01
0.52±0.03
-
80.85±1.98
5.41±0.23
-
6.44±0.20
84.04±1.55
GraphSAGE
✓
0.28±0.03
0.34±0.03
-
81.05±1.34
5.05±0.12
-
6.12±0.06
82.49±1.06
CPGNN
✓
0.17±0.02
0.21±0.03
-
78.34±1.26
4.92±0.33
-
6.17±0.42
79.69±0.81
GPR-GNN
✓
0.43±0.03
0.55±0.03
-
76.96±2.18
5.37±0.14
-
6.58±0.05
81.56±1.59
FAGCN
✓
0.43±0.01
0.54±0.01
-
79.04±0.68
5.74±0.06
-
7.03±0.05
81.56±0.80
GAT
0.19±0.04
0.23±0.04
-
81.62±2.01
5.56±0.12
-
6.58±0.06
84.46±1.08
GCN
0.19±0.02
0.24±0.02
-
81.52±3.10
5.71±0.07
-
6.76±0.03
84.49±0.84"
END,0.9443561208267091,"H2GCN
✓"
END,0.9459459459459459,Citeseer
END,0.9475357710651828,"0.29±0.05
0.40±0.06
-
72.93±2.30
5.55±0.10
-
7.29±0.18
76.17±0.48
GraphSAGE
✓
0.33±0.01
0.45±0.01
-
74.66±1.19
5.43±0.07
-
7.15±0.12
75.97±0.47
CPGNN
✓
0.15±0.02
0.20±0.02
-
74.62±0.30
5.59±0.22
-
7.54±0.22
74.05±0.84
GPR-GNN
✓
0.40±0.01
0.59±0.02
-
67.52±0.49
5.05±0.05
-
7.21±0.06
70.10±0.15
FAGCN
✓
0.38±0.02
0.53±0.02
-
72.41±1.03
5.46±0.09
-
7.42±0.12
73.56±0.18
GAT
0.09±0.01
0.13±0.02
-
74.07±0.44
5.39±0.16
-
7.25±0.12
74.33±1.43
GCN
0.18±0.01
0.25±0.00
-
74.07±1.65
5.55±0.10
-
7.42±0.16
74.76±0.72"
END,0.9491255961844197,"H2GCN
✓ FB100"
END,0.9507154213036566,"0.54±0.00
0.94±0.00
-
57.11±0.10
4.75±0.03
-
8.32±0.03
57.15±0.23
GraphSAGE
✓
0.52±0.01
0.92±0.01
-
56.70±1.41
4.28±0.05
-
7.56±0.10
56.58±1.32
CPGNN
✓
0.54±0.04
0.90±0.04
-
60.39±7.26
4.22±0.05
-
6.66±0.11
63.30±0.29
GPR-GNN
✓
0.46±0.01
0.73±0.02
-
62.26±0.26
4.04±0.08
-
6.51±0.10
62.05±0.31
FAGCN
✓
0.55±0.00
0.90±0.01
-
60.60±0.36
4.58±0.10
-
7.71±0.03
59.45±1.26
GAT
0.46±0.03
0.74±0.04
-
61.97±1.41
3.33±0.09
-
5.37±0.11
62.01±1.01
GCN
0.42±0.01
0.65±0.01
-
64.70±0.55
3.28±0.04
-
5.01±0.11
65.50±0.56"
END,0.9523052464228935,"H2GCN
✓ Snap"
END,0.9538950715421304,"0.11±0.01
0.42±0.05
-
26.74±0.18
1.41±0.04
-
5.16±0.19
27.28±0.21
GraphSAGE
✓
0.06±0.02
0.24±0.08
-
27.00±0.63
1.10±0.11
-
4.04±0.36
27.21±0.99
CPGNN
✓
0.12±0.02
0.43±0.08
-
27.00±0.41
1.69±0.06
-
6.39±0.13
26.45±0.50
GPR-GNN
✓
0.03±0.01
0.11±0.02
-
26.14±0.73
1.10±0.04
-
4.19±0.17
26.24±0.43
FAGCN
✓
0.10±0.01
0.36±0.03
-
27.13±0.16
1.77±0.05
-
6.48±0.20
27.25±0.18
GAT
0.02±0.00
0.08±0.02
-
27.00±0.59
1.10±0.03
-
4.06±0.11
27.18±0.04
GCN
0.02±0.00
0.07±0.01
-
27.45±0.82
1.38±0.05
-
5.01±0.16
27.57±0.27"
END,0.9554848966613673,"E.3
COMPARISON BETWEEN CERTIFIABLE AND EMPIRICAL ROBUSTNESS"
END,0.9570747217806042,"While the evaluations on both empirical and certiﬁable robustness have shown that methods fea-
turing the design have shown largely improved robustness compared to the best-performing unvac-
cinated method, we ﬁnd that the robustness rankings for methods under certiﬁable and empirical
robustness are different; previous results from Geisler et al. (2020) have also shown discrepancy in
certiﬁable and empirical robustness rankings."
END,0.958664546899841,"We think this discrepancy may be attributed to multiple factors. Firstly, the radius on which cer-
tiﬁcates can be issued with randomized smoothing may not cover the radius of perturbations we
allowed for NETTACK and Metattack in §5.2, which are more than tens of edges for Metattack and
high-degree nodes in NETTACK (where we use an attack budget equal to the degree of the target
node). Furthermore, even for low-degree nodes, attacks are much more inclined to introduce new
edges instead of removing existing ones, as we have shown in §5.1, which can make it much harder
to obtain certiﬁcates (Bojchevski et al., 2020). In our case, the methods we evaluated generally have
¯ra < 1, meaning that for most nodes there are no certiﬁcates to cover even the addition of a single
edge. Thus, methods which display higher certiﬁable robustness under smaller perturbations may
not keep their robustness under larger perturbations by empirical attacks. Moreover, while we are
evaluating on randomized smoothed models f(φ(s)) to measure certiﬁable robustness, in empirical"
END,0.9602543720190779,Under review as a conference paper at ICLR 2022
END,0.9618441971383148,"robustness we are evaluating on the robustness of the base models f(s), which may differ from the
robustness of the randomized smoothed models. Lastly, it is worth noting that the lack of certiﬁca-
tion for a model within certain radius does not imply a vulnerability to all adversarial attacks within
that radius; the model may still be robust against many attacks within that radius. Similarly, it is also
possible for existing certiﬁcation approaches to miss some certiﬁable cases. Taking all these factors
into account, we believe that while evaluations on certiﬁable robustness provide complementary per-
spectives to evaluations empirical robustness, at the current stage it cannot replace the evaluations
on empirical robustness, and the relation between certiﬁable and empirical robustness remains as a
question for future works."
END,0.9634340222575517,"E.4
COMPLEXITY AND RUNTIME OF HETEROPHILOUS VACCINATION"
END,0.9650238473767886,"Another beneﬁt of adopting heterophily-inspired design for boosting robustness of GNNs is their
smaller computational overhead compared to existing vaccination mechanisms, especially vaccina-
tions based on low-rank approximation. As our identiﬁed design can be applied as simple archi-
tectural changes on top of an existing GNN, they usually maintain the same order of computational
complexity as the base model. For example, adding the heterophilous design to GCN (Kipf &
Welling, 2017) results in an architecture similar to GraphSAGE (Hamilton et al., 2017); both have
the same order of computational complexity as O(|V| + |E|) by leveraging the sparse connectivity
of most real-world graphs. Low-rank approximation-based vaccination, on the other hand, approx-
imates the adjacency matrix of a graph by an SVD, resulting in an adjusted low-rank adjacency
matrix ˜A based on which the GNN runs. However, not only is computing an SVD potentially costly
(O(|V|3) in general), but in most cases it also results in a dense ˜A (in contrast to the sparse original
adjacency matrix), thus increasing the complexity of each iteration of the GNN."
END,0.9666136724960255,"Table 10: Runtime (in seconds) of 200 training iterations on Cora. See App. D for the implementa-
tion used for each method."
END,0.9682034976152624,"GCN
GAT
GNNGuard
ProGNN
GCN-SVD
H2GCN"
END,0.9697933227344993,"2.17
2.98
39.63
220.30
134.81
16.54"
END,0.9713831478537361,"GraphSAGE
FAGCN
GRP-GNN
CPGNN
H2GCN-SVD
GraphSAGE-SVD"
END,0.972972972972973,"17.24
1.91
2.66
24.08
62.33
55.45"
END,0.9745627980922098,"Table 10 shows the runtime of 200 training iterations of each model. We observe that models with
the heterophilous design have the smallest runtime among all vaccinated models. Even for methods
based on the same implementation, H2GCN and GraphSAGE are still 3-4 times faster than the cor-
responding H2GCN-SVD and GraphSAGE-SVD methods. For fair runtime measurements, we mea-
sure the runtime of each model on an Amazon EC2 instance with instance type as p3.2xlarge,
which features an 8-core CPU, 61 GB Memory, and a Tesla V100 GPU with 16 GB GPU Memory."
END,0.9761526232114467,"E.5
ADDITIONAL RESULTS ON STRUCTURAL ATTACKS ON HETEROPHILOUS GRAPHS"
END,0.9777424483306836,"10
0
10
1
10
2"
END,0.9793322734499205,"Target Degree 10
0 10
1 10
2"
END,0.9809220985691574,Gambit Degree
END,0.9825119236883942,Cora (h = 0.804)
END,0.9841017488076311,"10
0
10
1
10
2"
END,0.985691573926868,"Target Degree 10
0 10
1 10
2"
END,0.9872813990461049,Citeseer (h = 0.736)
END,0.9888712241653418,"10
0
10
1
10
2"
END,0.9904610492845787,"Target Degree 10
0 10
1 10
2"
END,0.9920508744038156,FB100 (h = 0.531)
END,0.9936406995230525,"10
0
10
1
10
2"
END,0.9952305246422893,"Target Degree 10
0 10
1 10
2"
END,0.9968203497615262,Snap (h = 0.134)
END,0.9984101748807631,"Figure 2: Scatter plots of the degrees of the target nodes (x-axis) and gambit nodes (y-axis) involved
in the targeted attacks studied in §5.1. Attacks tend to leverage gambit nodes with low degrees,
especially on heterophious graphs, which makes attacks increasing heterophily effective following
the conclusions of Thm. 2."
