Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.000999000999000999,"Data augmentation (DA) encodes invariance and provides implicit regularization
critical to a model’s performance in image classification tasks. However, while
DA improves average accuracy, recent studies have shown that its impact can be
highly class dependent: achieving optimal average accuracy comes at the cost of
significantly hurting individual class accuracy by as much as 20% on ImageNet.
There has been little progress in resolving class-level accuracy drops due to a
limited understanding of these effects. In this work, we present a framework for
understanding how DA interacts with class-level learning dynamics. Using higher-
quality multi-label annotations on ImageNet, we systematically categorize the
affected classes and find that the majority are inherently ambiguous, co-occur, or
involve fine-grained distinctions, while DA controls the model’s bias towards one
of the closely related classes. While many of the previously reported performance
drops are explained by multi-label annotations, our analysis of class confusions re-
veals other sources of accuracy degradation. We show that simple class-conditional
augmentation strategies informed by our framework improve performance on the
negatively affected classes."
INTRODUCTION,0.001998001998001998,"1
Introduction"
INTRODUCTION,0.002997002997002997,"Data augmentation (DA) provides numerous benefits for training of deep neural networks including
promoting invariance and providing regularization. In particular, DA significantly improves the
generalization performance in image classification problems when measured by average accuracy
[24, 19, 2, 18]. However, Balestriero et al. [1] and Bouchacourt et al. [9] showed that strong DA, in
particular, Random Resized Crop (RRC) used in training of most modern computer vision models,
may disproportionately hurt accuracies on some classes, e.g. with up to 20% class-level degradation
on ImageNet compared to milder augmentation settings (see Figure 1 left). Performance degradation
even on a small set of classes might result in poor generalization on downstream tasks related to the
affected classes [55], while in other applications it would be unethical to sacrifice accuracy on some
classes for improvements in average accuracy [28, 7, 63, 10]."
INTRODUCTION,0.003996003996003996,"Balestriero et al. [1] attempted to address class-level performance degradation by applying DA
selectively to the classes where the accuracy improves with DA strength. Surprisingly, they found that
this augmentation policy did not address the issue and the performance on non-augmented classes
still degraded with augmentation strength. In this work we perform detailed analysis and explore
the mechanisms causing the class-level performance degradation. In particular, we identify the
interactions between class-conditional data distributions as the cause of the class-level performance
degradation with augmentation: DA creates an overlap between the data distributions associated with
different classes. As a simple illustrative example, in Figure 1 (right) we show that the standard RRC
operation creates an overlap between the “car” and “wheel” classes. As a result, the model learns to
predict label “car” on “wheel” images, and the performance on the “wheel” class drops. Importantly, 70 72 74 76 78"
INTRODUCTION,0.004995004995004995,ImageNet
INTRODUCTION,0.005994005994005994,"avg of all ImageNet classes
avg of 950 classes
avg of 50 remaining classes 54 56 58 60"
INTRODUCTION,0.006993006993006993,validation accuracy (%)
INTRODUCTION,0.007992007992007992,"stronger augmentation
default
pytorch
augmentation"
INTRODUCTION,0.008991008991008992,Removing augmentation from the affected
INTRODUCTION,0.00999000999000999,classes does not recover performance
INTRODUCTION,0.01098901098901099,Fine-grained and non-trivial
INTRODUCTION,0.011988011988011988,"Stronger data augmentation leads to 
degradation in accuracy for some classes"
INTRODUCTION,0.012987012987012988,Analyzing class confusion types
INTRODUCTION,0.013986013986013986,"sunglass
sunglasses"
INTRODUCTION,0.014985014985014986,"wheel
car"
INTRODUCTION,0.015984015984015984,Accuracy degradation is caused by class
INTRODUCTION,0.016983016983016984,confusions induced by augmentation
INTRODUCTION,0.017982017982017984,Ambiguous
INTRODUCTION,0.01898101898101898,"Augmentation strategy which accounts for 
class interactions leads +2.5% improvement"
INTRODUCTION,0.01998001998001998,on affected ImageNet classes 12 14 16 18 20
INTRODUCTION,0.02097902097902098,% misclassiﬁed
INTRODUCTION,0.02197802197802198,"stronger augmentation
default
pytorch
augmentation"
INTRODUCTION,0.022977022977022976,Test wheel images classiﬁed as car
INTRODUCTION,0.023976023976023976,Default pytorch Random Resized Crop
INTRODUCTION,0.024975024975024976,(input to the model)
INTRODUCTION,0.025974025974025976,"Figure 1: We show that the classes negatively affected by data augmentation are often ambigu-
ous, co-occurring or fine-grained categories and analyze how data augmentation exacerbates
class confusions. Left: Average accuracy of ResNet-50 on ImageNet against Random Resized
Crop (RRC) data augmentation strength: average of all classes (blue), average of the 50 classes on
which stronger RRC hurts accuracy the most (red), and the average of the remaining 950 classes
(green). Yellow line indicates the default RRC setting used in training of most computer vision
models. Middle: We systematically categorize the types of class confusions exacerbated by strong
data augmentation: while some of them include ambiguous or correlated classes, there is a number of
fine-grained and non-trivial confusions. Right: Often the class-level accuracy drops due to overlap
with other classes after applying augmentation: e.g. heavily augmented samples from “car” class
can look like typical images from “wheel” class. As a result, the model learns to predict “car” on
“wheel” images, and the accuracy on the “wheel” class drops. To resolve the negative effect of strong
augmentation on classes like “wheel”, we should modify augmentation strength of classes like “car”."
INTRODUCTION,0.026973026973026972,"if we want to improve the performance on the “wheel” class, we need to modify the augmentation
policy on the class “car” and not “wheel” as was done in prior work [1]. We summarize our findings
in Figure 1. In particular, our contributions are the following:"
INTRODUCTION,0.027972027972027972,"• We refine the analysis of class-level effects of data augmentations by correcting for label
ambiguity. Specifically, we use multi-label annotations on ImageNet [4] and measure
the effects of data augmentation for each class in terms of the original and multi-label
accuracy. Through this analysis, we find that class-level performance degradation reported
in Balestriero et al. [2] and Bouchacourt et al. [9] is overestimated (Section 4)."
INTRODUCTION,0.028971028971028972,"• We systematically categorize the class confusions exacerbated by strong augmentation and
find that many affected classes are ambiguous or co-occurring and are often affected by label
noise (Figure 1 middle and Section 5). We focus on addressing the remaining fine-grained
and non-trivial class confusions."
INTRODUCTION,0.029970029970029972,"• We show that for addressing DA biases it is important to consider the classes with an
increasing number of false positive mistakes, and not only the classes negatively affected in
accuracy. By taking into account our observations on DA affecting class interactions, we
propose a simple class-conditional data augmentation strategy that leads to improvement
on the affected group of classes by 2.5% on ImageNet (Section 6). This improvement is
in contrast to the previously explored class-conditional DA in Balestriero et al. [1] which
failed to improve class-level accuracy."
INTRODUCTION,0.030969030969030968,"• We confirm our findings across multiple computer vision architectures including
ResNet-50 [22], EfficientNet [61] and ViT [15] (Section F), multiple data augmentation
transformations including Random Resized Crop, mixup [73], RandAugment [13] and
colojitter (Section G), as well as two additional datasets besides ImageNet (Section G)."
RELATED WORK,0.03196803196803197,"2
Related work"
RELATED WORK,0.03296703296703297,"Understanding data augmentation, invariance and regularization.
Hernández-García and
König [24] analyzed the DA from the perspective of implicit regularization. Botev et al. [8] propose
an explicit regularizer that encourages invariance and show that it leads to improved generalization.
Balestriero et al. [2] derive an explicit regularizer to simulate DA to quantify its benefits and
limitations and estimate the number of samples for learning invariance. Gontijo-Lopes et al. [19]
and Geiping et al. [18] study the mechanisms behind the effectiveness of DA, which include data
diversity, exchange rates between real and augmented data, additional stochasticity and distribution
shift. Bouchacourt et al. [9] measure the learned invariances using DA. Lin et al. [37] studied how
data augmentation induces implicit spectral regularization which improves generalization."
RELATED WORK,0.03396603396603397,"Biases of data augmentations.
While DA is commonly applied to improve generalization and
robustness, a number of prior works identified its potential negative effects. Hermann et al. [23]
showed that decreasing minimum crop size in Random Resized Crops leads to increased texture
bias. Shah et al. [56] showed that using standard DA amplifies model’s reliance on spurious features
compared to models trained without augmentations. Idrissi et al. [30] provided a thorough analysis
on how the strength of DA for different transformations has a disparate effect on subgroups of data
corresponding to different factors of variation. Kapoor et al. [33] suggested that DA can cause models
to misinterpret uncertainty. Izmailov et al. [31] showed that DA can hurt the quality of learned
features on some classification tasks with spurious correlations. Balestriero et al. [1] and Bouchacourt
et al. [9] showed that strong DA may disproportionately hurt accuracies on some classes on ImageNet,
and in this work we focus on understanding this class-level performance degradation through the lens
of interactions between classes."
RELATED WORK,0.03496503496503497,"Multi-label annotations on ImageNet.
A number of prior works identified that ImageNet
dataset contains label noise such as ambiguous classes, multi-object images and mislabeled examples
[4, 57, 69, 46, 59, 45]. Tsipras et al. [67] found that nearly 20% of ImageNet validation set images
contain objects from multiple classes. Hooker et al. [27] ran a human study and showed that examples
most affected by pruning a neural network are often mislabeled, multi-object or fine-grained. Yun
et al. [72] generate pixel-level multi-label annotations for ImageNet train set using a large-scale
computer vision model. Beyer et al. [4] provide re-assessed (ReaL) multi-label annotations for
ImageNet validation set which aim to resolve label noise issues, and we use ReaL labels in our
analysis to refine the understanding of per-class effects of DA."
RELATED WORK,0.03596403596403597,"Adaptive and learnable data augmentation.
Xu et al. [70] showed that data augmentation
may exacerbate data bias which may lead to model’ suboptimal performance on the original data
distribution. They propose to train the model on a mix of augmented and unaugmented samples and
then fine-tune it on unaugmented data after training which showed improved performance on CIFAR
dataset. Raghunathan et al. [49] showed standard error in linear regression could increase when
training with original data and data augmentation, even when data augmentation is label-preserving.
Rey-Area et al. [51] and Ratner et al. [50] learn DA transformation using GAN framework, while
Hu and Li [29] study the bias of GAN-learned data augmentation. Fujii et al. [17] take into account
the distances between classes to adapt mixed-sample DA. Hauberg et al. [21] learn class-specific
DA on MNIST. Numerous works, e.g. Cubuk et al. [12], Lim et al. [36], Ho et al. [25], Hataya et al.
[20], Li et al. [35], Cubuk et al. [13], Tang et al. [62], Müller and Hutter [43] and Zheng et al. [74]
find dataset-dependent augmentation strategies. Benton et al. [3] proposed Augerino framework to
learn augmentation form training data. Zhou et al. [75], Cheung and Yeung [11], Mahan et al. [40]
and Miao et al. [41] learn class- or input-dependent augmentation policies. Yao et al. [71] propose to
modify mixed-sample augmentation to improve out-of-domain generalization."
RELATED WORK,0.03696303696303696,"Robustness and model evaluation beyond average accuracy.
While Miller et al. [42] showed
that model’s average accuracy is strongly correlated with its out-of-distribution performance, there is a
number of works that showed that only evaluating average performance can be deceptive. Teney et al.
[64] showed counter-examples for “accuracy-on-the-line” phenomenon. Kaplun et al. [32] show that
while model’s average accuracy improves during training, it may decrease on a subset of examples.
Sagawa et al. [54] show that training with Empirical Risk Minimization may lead to suboptimal
performance in the worst case. Bitterwolf et al. [6] evaluated ImageNet models’ performance in
terms of a number of metrics beyond average accuracy, including worst-class accuracy and precision.
Richards et al. [52] demonstrate that improved average accuracy on ImageNet and standard out-of-
distribution ImageNet variants may lead to exacerbated geographical disparities."
EVALUATION SETUP AND NOTATION,0.03796203796203796,"3
Evaluation setup and notation"
EVALUATION SETUP AND NOTATION,0.03896103896103896,"Since we aim to understand class-level accuracy degradation emerging with strong data augmentation
reported in Balestriero et al. [1], we closely follow their experimental setup. We focus on ResNet-50
models [22] trained on ImageNet [53] and study how average and class-level performance changes
depending on the Random Resized Crop augmentation strength: it is by far the most widely adopted
augmentation which leads to significant average accuracy improvements and is used for training
the state-of-the-art computer vision models [58, 65, 38]. We train ResNet-50 for 88 epochs using
label smoothing with α = 0.1 [60]. We use image resolution Rtrain = 176 during training and
evaluate on images with resolution Rtest = 224 following Balestriero et al. [1], Touvron et al. [66]
and torchvision training recipe1. More implementation details can be found in Appendix A."
EVALUATION SETUP AND NOTATION,0.03996003996003996,"Data augmentation.
We apply random horizontal flips and Random Resized Crop (RRC) DA
when training our models. In particular, for an input image of size h × w the RRC transformation
samples the crop scale s ∼U[slow, sup] and the aspect ratio r ∼U[rlow, rup], where U[a, b] denotes
a uniform distribution between a and b. RRC then takes a random crop of size
√"
EVALUATION SETUP AND NOTATION,0.04095904095904096,"shwr×
p"
EVALUATION SETUP AND NOTATION,0.04195804195804196,"shw/r and
resizes it to a chosen resolution R × R. We use the standard values for sup = 100% and aspect ratios
rlow = 3/4, rup = 4/3, and vary the lower bound of the crop scale slow (for simplicity, we will further
use s) between 8% and 100% which controls the strength of augmentation: s = 8% corresponds to
the strongest augmentation (note this is the default value in pytorch [48] RRC implementation) and
s = 100% corresponds no cropping hence no augmentation. For each augmentation strength, we
train 10 models with different random seeds."
EVALUATION SETUP AND NOTATION,0.04295704295704296,"ReaL labels.
Beyer et al. [4] used large-scale vision models to generate new label proposals
for ImageNet validation set which were then evaluated by human annotators. These Reassessed
Labels (ReaL) correct the label noise present in the original labels including mislabeled examples,
multi-object images and ambiguous classes. Since there are possibly multiple ReaL labels for each
image, model’s prediction is considered correct if it matches one of the plausible labels. Further we
will use lReaL(x) to denote the set of ReaL labels of example x."
EVALUATION SETUP AND NOTATION,0.04395604395604396,"Evaluation metrics.
We aim to measure performance of model fs(x) as a function of DA strength,
i.e. RRC lower bound of the crop scale s. We measure average accuracy a(s), and per-class accuracy
ak(s) with respect to both original ImageNet labels and ReaL multi-label annotations given by:"
EVALUATION SETUP AND NOTATION,0.04495504495504495,"aor
k (s) = 1/|Xk|
X"
EVALUATION SETUP AND NOTATION,0.04595404595404595,"x∈Xk
I[fs(x) = k]
and
aReaL
k
(s) = 1/|Xk|
X"
EVALUATION SETUP AND NOTATION,0.04695304695304695,"x∈Xk
I[fs(x) ∈lReaL(x)],"
EVALUATION SETUP AND NOTATION,0.04795204795204795,"where Xk are images from class k in validation set. We will refer to aor and aReaL as original
accuracy and ReaL accuracy, respectively. To quantify the class accuracy drops, Balestriero et al. [1]
compare the per-class accuracy of models trained with the strongest DA (s = 8%) and models trained
without augmentation (s = 100% which effectively just resizes input images without cropping),
while Bouchacourt et al. [9] compared class-level accuracy of models trained with RRC with s = 8%
and models trained with fixed size Center Crop. In our analysis, we evaluate per-class accuracy drops
comparing the maximum accuracy attained on a particular class k across all augmentation levels
maxs ak(s) and accuracy on that class when training with strongest DA ak(s = 8%). We will refer
to the classes with the highest accuracy degradation computed by:"
EVALUATION SETUP AND NOTATION,0.04895104895104895,"∆ak = max
s
ak(s) −ak(s = 8%)"
EVALUATION SETUP AND NOTATION,0.04995004995004995,"as the classes most negatively affected by DA (with respect to either original labels or multi-label
ReaL annotations). To summarize performance on the affected classes, we will evaluate average
accuracy of classes with the highest ∆ak (in many cases focusing on 5% of ImageNet classes with
the highest accuracy drop following Balestriero et al. [1]). In the following sections, we also highlight
the importance of measuring other metrics beyond average and per-class accuracy which comprise a
more thorough evaluation of DA biases."
EVALUATION SETUP AND NOTATION,0.05094905094905095,"While we focus on the analysis of ResNet-50 on ImageNet with RRC augmentation as the main setup
following prior work [1, 9], we additionally confirm our observations on other architectures (Efficient-
Net [61] and ViT [14]) in Appendix F, other data augmentation transformations (RandAugment [13],
colorjitter and mixup [73]), and other datasets (CIFAR-100 and Flowers102 [44]) in Appendix G."
EVALUATION SETUP AND NOTATION,0.05194805194805195,1https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/ 70 75 80
EVALUATION SETUP AND NOTATION,0.052947052947052944,validation acc (%) 70 75 80 55 60 65 70
EVALUATION SETUP AND NOTATION,0.053946053946053944,"25
50
75
100"
EVALUATION SETUP AND NOTATION,0.054945054945054944,RRC scale lower bound s 50 60 70
EVALUATION SETUP AND NOTATION,0.055944055944055944,validation acc (%)
EVALUATION SETUP AND NOTATION,0.056943056943056944,"25
50
75
100"
EVALUATION SETUP AND NOTATION,0.057942057942057944,RRC scale lower bound s 35 40 45
EVALUATION SETUP AND NOTATION,0.058941058941058944,"25
50
75
100"
EVALUATION SETUP AND NOTATION,0.059940059940059943,RRC scale lower bound s 40 50 60 70 80
EVALUATION SETUP AND NOTATION,0.060939060939060936,"Avg of all IN classes
∆aor = 0, ∆aReaL = 0"
EVALUATION SETUP AND NOTATION,0.061938061938061936,"Avg of 950 IN classes
∆aor = 0, ∆aReaL = 0"
EVALUATION SETUP AND NOTATION,0.06293706293706294,"Avg of 50 IN classes
∆aor = 5, ∆aReaL = 1"
EVALUATION SETUP AND NOTATION,0.06393606393606394,"barn spider
∆aor = 15, ∆aReaL = 0"
EVALUATION SETUP AND NOTATION,0.06493506493506493,"overskirt
∆aor = 13, ∆aReaL = 3"
EVALUATION SETUP AND NOTATION,0.06593406593406594,"academic gown
∆aor = 13, ∆aReaL = 1"
EVALUATION SETUP AND NOTATION,0.06693306693306693,"stronger augmentation
original
ReaL"
EVALUATION SETUP AND NOTATION,0.06793206793206794,"0.0
2.5
5.0
7.5
10.0
12.5
15.0
Accuracy gap (%) 0 100 200 300 400"
EVALUATION SETUP AND NOTATION,0.06893106893106893,# classes
EVALUATION SETUP AND NOTATION,0.06993006993006994,Distribution of per-class ¢aor and ¢aReaL
EVALUATION SETUP AND NOTATION,0.07092907092907093,"4
6
8
10
12
14
16
0 5 10 15 20"
"ORIGINAL
REAL",0.07192807192807193,"25
original
ReaL"
"ORIGINAL
REAL",0.07292707292707293,"Figure 2: We find that for many classes the negative effects of strong data augmentation are
muted if we use high-quality multi-label annotations. Left: Average and per-class accuracy of
ResNet-50 trained on ImageNet evaluated with original and ReaL labels as a function of Random
Resized Crop augmentation strength (s = 8% corresponds to the strongest and default augmentation).
The top row shows the average accuracy of all ImageNet classes, the 50 classes with the highest
original accuracy degradation and the remaining 950 classes. The bottom row shows the accuracy of
3 individual classes most significantly affected in original accuracy when using strong augmentation.
Right: Distribution of per-class accuracy drops ∆ak for original and ReaL labels. The distribution of
∆aor
k has a heavier tail compared to the one computed with ReaL labels."
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.07392607392607392,"4
Per-class accuracy degradation with strong data augmentation is
overestimated due to label ambiguity"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.07492507492507493,"Previous studies reported that the performance of ImageNet models is effectively better when
evaluated using re-assessed multi-label annotations which address label noise issues in ImageNet
[4, 57, 69]. These works showed that recent performance improvements on ImageNet might be
saturating, but the effects of this label noise on granular per-class performance has not been previously
studied. In particular, it is unclear how correcting for label ambiguity would affect the results of
Balestriero et al. [1] and Bouchacourt et al. [9] on the effects of DA on class-level performance."
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.07592407592407592,"We observe that for many classes with severe drops in accuracy on original labels, the class-level
ReaL multi-label accuracy is considerably less affected. The right panel of Figure 2 shows the
distributions of per-class accuracy drops ∆aor
k and ∆aReaL
k
, and we note that the distribution of
∆aor
k has a much heavier tail. Using multi-label accuracy in evaluation reveals there are much fewer
classes which have severe effective performance drop: e.g. only 37 classes with ∆aReaL
k
> 4% as
opposed to 83 classes with ∆aor
k > 4%, moreover, there are no classes with ∆aReaL
k
> 11%."
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.07692307692307693,"On the left panel of Figure 2, we show how multi-label accuracy evaluation impacts the average and
individual class performance across different augmentation strengths s. In particular, in the top row
plots we see that while the average accuracy of all classes follows a similar trend when evaluated
with either original or ReaL labels, the average accuracy of 50 classes most negatively affected in
original accuracy only decreases by 1% with ReaL labels as opposed to more significant 5% drop
with original labels. The bottom row shows the accuracy for “barn spider”, “overskirt” and “academic
gown” classes which have the highest ∆aor
k , and accuracy trends for all 50 most negatively affected
classes are shown in Appendix C. For many of these classes which are hurt in original accuracy by
using stronger DA, the ReaL accuracy is much less affected. For example, for the class “barn spider”
the original accuracy is decreased from 63% to 47% if we use the model trained with RRC s = 8%
compared to s = 70%, while the highest ReaL accuracy is achieved by the strongest augmentation
setting on this class."
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.07792207792207792,"However, there are still classes for which the ReaL accuracy degrades with stronger augmentation,
and in Appendix C we show ReaL accuracy trends against augmentation strength s for 50 classes
with the highest ∆aReaL. While some of them (especially classes from the “animal” categories)"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.07892107892107893,"may still be affected by the remaining label noise [69, 68, 57, 39, 4], for other classes the strongest
DA leads to suboptimal accuracy. In the next section, we aim to understand why strong DA hurts
the performance on these classes. We analyze model’s predictions and consistent confusions on
these classes and find that the degradation in performance is caused by the interactions between
class-conditional distributions induced by DA."
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.07992007992007992,"5
Data augmentation most significantly affects classification of ambiguous,
co-occurring and fine-grained categories"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.08091908091908091,"In this section, we aim to understand the reasons behind per-class accuracy degradation when using
stronger data augmentation by analyzing the most common mistakes the models make on the affected
classes and how they evolve as we vary the data augmentation strength. We consider the classes most
affected by strong DA (see Figures in Appendix C) which do not belong to the “animal” subtree
category in the WordNet hierarchy [16] since fine-grained animal classes were reported to have
higher label noise in previous studies [68, 57, 39, 4]. We focus on the 50 classes with the highest
∆aor
k (corresponding to ∆aor
k > 5%), and 50 classes with the highest ∆aReaL
k
(corresponding to
∆aReaL
k
> 4%). For a pair of classes k and l we define the confusion rate (CR) as:"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.08191808191808192,"CRk→l(s) = 1/|Xk|
X"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.08291708291708291,"x∈Xk
I[fs(x) = l],"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.08391608391608392,"i.e. the ratio of examples from class k misclassified as l. For each affected class, we identify most
common confusions and track the CR against the RRC crop scale lower bound s. We also analyze
the reverse confusion rate CRl→k(s)."
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.08491508491508491,"We observe that in many cases DA strength controls the model’s preference in predicting one or
another plausible ReaL label, or preference among semantically similar classes. We roughly outline
the most common types of confusions on the classes which are significantly affected by DA. The
different types of confusion differ in the extent to which the accuracy degradation can be attributed to
label noise versus the presence of DA. We also characterize how DA effectively changes the data
distribution of these classes leading to changes in performance. These categories are closely related
to common mistake types on ImageNet identified by Beyer et al. [4] and Vasudevan et al. [69], but we
focus on class-level interactions as opposed to instance-level mistakes and particularly connect them
to the impact of DA. We use semantic similarity and ReaL labels co-occurence as a criteria to identify
a confusion category for a pair of classes. We can measure semantic similarity by (a) WordNet class
similarity, given by the Wu-Palmer score which relies on the most specific common ancestor of the
class pair in the WordNet tree, and (b) similarity of the class name embeddings2. To estimate the
intrinsic distribution overlap of the classes, we compute ReaL labels co-occurrence between classes k
and l as:
Ckl =
X"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.08591408591408592,"x∈X
I[k ∈lReaL(x)] × I[l ∈lReaL(x)]/
X"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.08691308691308691,"x∈X
I[k ∈lReaL(x)],"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.08791208791208792,"which is the ratio of examples that have both labels k and l among the examples with the label k.
Using these metrics, depending on a higher or lower semantic similarity and higher or lower ReaL
labels overlap, we categorize confused class pairs as ambiguous, co-occurring, fine-grained or
semantically unrelated. Below we discuss each category in detail, and the examples are shown in
Figure 3 and Appendix Figure 6. We provide more details on computing the metrics for identifying
the confusion type and categorize the confusions of all affected classes in Appendix D."
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.08891108891108891,"Class-conditional distributions induced by DA.
To aid our understanding of the class-specific
effects of DA, it is helpful to reason about how a parametrized class of DA transformations Ts(·)
changes the distributions of each class in the training data pk(x). We denote the augmented class
distributions by Ts(pk). In particular, if supports of the distributions Ts(pk) and Ts(pl) for two
classes k and l overlap, the model is trained to predict different labels k and l on similar inputs
corresponding to features from both classes k and l which will lead to performance degradation.
Some class distributions pk and pl are intrinsically almost coinciding or highly overlapping in the
ImageNet dataset, while others have distinct supports, but in all cases the parameters of DA s will
control the overlap of the induced class distributions Ts(pk) and Ts(pl), and thus the biases of the
model when making predictions on such classes."
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.0899100899100899,2We use NLTK library [5] for WordNet and spaCy library [26] for embeddings similarity. 60 65 70
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.09090909090909091,predictions on “muzzle”
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.0919080919080919,"muzzle
sandal"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.09290709290709291,"20
40
60
80
100"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.0939060939060939,augmentation strength s 0 2 4
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.09490509490509491,% of val examples 60 70
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.0959040959040959,"80
predictions on “sandal”"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.0969030969030969,"muzzle
sandal"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.0979020979020979,"20
40
60
80
100"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.0989010989010989,augmentation strength s 0 2 4
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.0999000999000999,% of val examples 40 45 50
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.1008991008991009,predictions on “frying pan”
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.1018981018981019,"frying pan
wok"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.1028971028971029,"20
40
60
80
100"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.1038961038961039,augmentation strength s 6 8 10 12
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.1048951048951049,% of val examples 50 55 60
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.10589410589410589,"65
predictions on “sandbar”"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.1068931068931069,"seashore
sandbar"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.10789210789210789,"20
40
60
80
100"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.1088911088911089,augmentation strength s 16 18 20 22
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.10989010989010989,% of val examples 40 45 50
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.1108891108891109,predictions on “seashore”
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.11188811188811189,"seashore
sandbar"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.11288711288711288,"20
40
60
80
100"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.11388611388611389,augmentation strength s 6 8 10 12
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.11488511488511488,% of val examples
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.11588411588411589,"20
40
60
80
100"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.11688311688311688,augmentation strength s 15 20 25 30 35
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.11788211788211789,% of val examples
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.11888111888111888,predictions on “sunglass”
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.11988011988011989,"sunglass
sunglasses"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.12087912087912088,"20
40
60
80
100"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.12187812187812187,augmentation strength s 15 20 25 30 35 40
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.12287712287712288,% of val examples
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.12387612387612387,predictions on “sunglasses”
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.12487512487512488,"sunglass
sunglasses"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.1258741258741259,"Ambiguous
Co-occurring"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.12687312687312688,"Fine-grained
Semantically unrelated"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.12787212787212787,Higher
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.12887112887112886,"ReaL 
overlap 40 45 50 55"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.12987012987012986,"60
predictions on “wok”"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.13086913086913088,"frying pan
wok"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.13186813186813187,"20
40
60
80
100"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.13286713286713286,augmentation strength s 0 2 4 6
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.13386613386613386,% of val examples Lower
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.13486513486513488,"ReaL 
overlap"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.13586413586413587,"Higher semantic similarity
Lower semantic similarity"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.13686313686313686,"Figure 3:
Types of class confusions affected by data augmentation with varied semantic
similarity and data distribution overlap. Each panel shows a pair of confused classes which we
categorize into: ambiguous, co-occurring, fine-grained and semantically unrelated, depending on
the inherent class overlap and semantic similarity. For each confused class pair, the left subplot
corresponds to the class k whose accuracy decreases with strong data augmentation (DA), e.g.
“sunglass” on top left panel: the ratio of validation samples from that class which are classified
correctly decreases with stronger DA, while the confusion rate with another class l (e.g. class
“sunglasses” on top left panel) increases. The right subplot shows the percent of examples from class
l that get classified as k or l against DA strength."
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.13786213786213786,"Intrinsically ambiguous or semantically (almost) identical classes.
Prior works [e.g. 4, 57, 69,
67] identified that some pairs of ImageNet classes are practically indistinguishable, e.g. “sunglasses”
and “sunglass”, “monitor” and “screen”, “maillot” and “maillot, tank suit”. These pairs of classes
generally have higher semantic similarity and higher ReaL labels overlap Ckl. We observe that in
many cases the accuracy on one class within the ambiguous pair degrades with stronger augmentations,
while the accuracy on another class improves. The supports of distributions of these class pairs pk
and pl highly overlap or even coincide, but with varying s depending on how the supports of Ts(pk)
and Ts(pl) overlap the model would be biased towards predicting one of the classes. In Figure 3 top
left panel, we show how the frequencies of most commonly predicted labels change on an ambiguous
pair of classes “sunglass” and “sunglasses” as we vary the crop scale parameter. The ReaL labels for
these classes overlap with Ckl = 87%, and the majority of confusions are resolved after accounting
for multi-label annotations. We note that for images from both classes the frequency of “sunglasses”
label increases with stronger DA while “sunglass” predictions have the opposite trend. Models trained
on ImageNet often achieve a better-than-random-guess accuracy when classifying between these
classes due to overfitting to marginal statistical differences and idiosyncrasies of the data labeling
pipelines. While DA strength controls model’s bias towards predicting one or another plausible label,
the models are not effectively making mistakes when confusing such classes."
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.13886113886113885,"For the remaining categories described below, the class distributions become more overlapping
when strong DA is applied during training, and data augmentation amplifies or causes problematic
misclassification."
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.13986013986013987,"Co-occurring or overlapping classes.
There is a number of classes in ImageNet which correspond
to semantically different objects which often appear together, e.g. “academic gown” and “mortar-
board”, “Windsor tie” and “suit”, “assault rifle” and “military uniform”, “seashore” and “sandbar”.
These pairs of classes have rather high overlap in ReaL labels depending on the spurious correlation
strength, and their semantic similarity can vary, but generally it would be lower than for ambiguous
classes. The class distributions of co-occurring classes inherently overlap, however, stronger DA
may increase the overlap in class distribution supports. For example, with RRC we may augment the"
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.14085914085914086,"sample such that only the spuriously co-occurring object, but not the main object, is left in the image,
and the model would still be trained to predict the original label: e.g. we can crop just the mortarboard
in an image labeled as “academic gown”. It was previously shown that RRC can increase model’s
reliance on spurious correlations [23, 56] which can lead to meaningful mistakes, not explained by
label ambiguity. In Figure 3 top right panel, we show how DA strength impacts model’s bias towards
predicting “sandbar” or “seashore” class (these classes co-occur with Ckl = 64% and the majority of
confusions are resolved by accounting for ReaL labels). We emphasize that unlike the ambiguous
classes, the co-occuring classes cause meaningful mistakes on the test data, which are not always
resolved by multi-label annotations. For example, the model will be biased to predict “academic
gown” even when shown an image of just the mortarboard."
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.14185814185814186,"Fine-grained categories.
There is a number of semantically related class pairs like “tobacco shop”
and “barbershop”, “frying pan” and “wok”, “violin” and “cello”, where objects appear in related
contexts, share some visually similar features and generally represent fine-grained categories of a
similar object type. These classes have high semantic similarity and do not have a significant ReaL
label overlap (sometimes such examples are affected by mislabeling but such classes generally do not
co-occur). The class distributions for such categories are close to each other or slightly overlapping,
but strong DA pulls them closer, and T (pi) and T (pk) would be more overlapping due to e.g. RRC
resulting in the crops of the visually similar features or shared contexts in the augmented images from
different categories. In Figure 3 bottom left panel, we show how model’s confusion rates change
depending on RRC crop scale for fine-grained classes “frying pan” and “wok” (these classes rarely
overlap with only Ckl = 9%)."
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.14285714285714285,"Semantically unrelated.
In the rare but most problematic cases, the stronger DA will result in
confusion of semantically unrelated classes. While they share similar low-level visual features, they
are semantically different, their distributions pk and pl and ReaL labels do not overlap, and they get
confused with one another specifically because of strong DA), for example, categories like “muzzle”
and “sandal”, “bath towel” and “pillow”. Figure 3 bottom right panel shows how confusions between
unrelated classes “bath towel” and “pillow” emerge with stronger DA."
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.14385614385614387,"In Appendix D we show a larger selection of example pairs from each confusion category. Among
the confusions on the most significantly affected classes, approximately 53% are fine-grained, 21%
are co-occurring, 16% are ambiguous and the remaining 10% are semantically unrelated. While the
confusion of semantically unrelated categories is the most rare, it is potentially most concerning since
it corresponds to more severe mistakes."
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.14485514485514486,"While in some cases we can intuitively explain why the model becomes biased to predict one of the
two closely related classes with stronger DA (such as with “car” and “wheel” classes in Figure 1), in
other cases the bias arises due to statistical differences in the training data such as data imbalance.
ImageNet train set is not perfectly balanced with 104 classes out of 1000 containing less training
examples than the remaining classes. We observed that 21% of these less represented classes were
among the ones most significantly affected in original or ReaL per-class accuracy. Since DA can
push class-conditional distributions of related classes closer together, if one of such classes is less
represented in training data it may be more likely to be impacted by stronger augmentation. In
Appendix C we show how average accuracy on the underrepresented classes changes depending on
the data augmentation strength."
"PER-CLASS ACCURACY DEGRADATION WITH STRONG DATA AUGMENTATION IS
OVERESTIMATED DUE TO LABEL AMBIGUITY",0.14585414585414586,"We observe that using other data augmentation transformations such as RandAugment [13] or
colorjitter on ImageNet, or mixup [73] on CIFAR-100 results in similar effects of exacerbated
confusions of related categories (see Appendix section G). In particular, RandAugment and colorjitter
often affect class pairs which are distinct in their color or texture, while mixup on CIFAR-100 may
amplify confusions of classes within the same superclass."
CLASS-CONDITIONAL DATA AUGMENTATION POLICY INTERVENTIONS,0.14685314685314685,"6
Class-conditional data augmentation policy interventions"
CLASS-CONDITIONAL DATA AUGMENTATION POLICY INTERVENTIONS,0.14785214785214784,"In Section 5, we showed that class-level performance degradation occurs with stronger augmentation
because of the interactions between different classes. The models tend to consistently misclassify
images of one class to another related, e.g. co-occurring, class. In this section, we use these insights
to develop a class-conditional augmentation policy and improve the performance on the classes
negatively affected by DA."
CLASS-CONDITIONAL DATA AUGMENTATION POLICY INTERVENTIONS,0.14885114885114886,"Table 1: Class-conditional data augmentation policy informed by our insights improves per-
formance on the negatively affected classes while maintaining high overall accuracy. Average
accuracy of different augmentation policies on all ImageNet classes, negatively affected classes and
remaining majority of classes."
CLASS-CONDITIONAL DATA AUGMENTATION POLICY INTERVENTIONS,0.14985014985014986,"Augmentation strategy
Avg acc
Avg acc of
50 classes
Avg acc of
950 classes"
CLASS-CONDITIONAL DATA AUGMENTATION POLICY INTERVENTIONS,0.15084915084915085,"Standard DA
s = 8%
76.79±0.03
53.93±0.20
77.99±0.02
s = 60%
74.65±0.03
59.11±0.20
75.47±0.02
Class-cond. Balestriero et al. [1]
76.11±0.05
43.02±0.28
77.85±0.04"
CLASS-CONDITIONAL DATA AUGMENTATION POLICY INTERVENTIONS,0.15184815184815184,"Our class-cond. DA
m = 10
76.70±0.03
54.99±0.15
77.84±0.03
m = 30
76.70±0.03
55.48±0.23
77.82±0.03
m = 50
76.68±0.04
56.34±0.14
77.75±0.04"
CLASS-CONDITIONAL DATA AUGMENTATION POLICY INTERVENTIONS,0.15284715284715283,"Balestriero et al. [1] identified that DA leads to degradation in accuracy for some classes and also
showed that a naive class-conditional augmentation approach is not sufficient for removing these
negative effects. In particular, using oracle knowledge of validation accuracies of models pretrained
with different augmentation levels, they evaluated a DA strategy where augmentation is applied to
all classes except the ones with degraded accuracy (i.e. classes with ∆aor
k > 0) which are instead
processed with Center Crop. Since this approach didn’t recover the accuracy on the affected classes,
they hypothesized that DA induces a general invariance or an implicit bias that still negatively affects
classes that are not augmented when DA is applied to the majority of the training data."
CLASS-CONDITIONAL DATA AUGMENTATION POLICY INTERVENTIONS,0.15384615384615385,"We explore a simple class-conditional augmentation strategy based on our insights regarding class
confusions. By changing the augmentation strength for as few as 1% to 5% of classes, we observe
substantial improvements on the classes negatively affected by the standard DA. We also provide an al-
ternative explanation for why the class-conditional augmentation approach from Balestriero et al. [1]
was not effective. In particular, we found in many cases that as we train models with stronger
augmentation, a class k negatively affected by DA consistently gets misclassified as a related class l
(see Section 5). We can precisely describe these confusions in terms of False Negative (FN) mistakes
for class k (not recognizing an instance from class k) and False Positive (FP) mistakes for class l
(misclassifying an instance from another class as class l):"
CLASS-CONDITIONAL DATA AUGMENTATION POLICY INTERVENTIONS,0.15484515484515485,"FN or
k (s) =
X"
CLASS-CONDITIONAL DATA AUGMENTATION POLICY INTERVENTIONS,0.15584415584415584,"x∈Xk
I[fs(x) ̸= k]
and
FP or
l (s) =
X"
CLASS-CONDITIONAL DATA AUGMENTATION POLICY INTERVENTIONS,0.15684315684315683,"(x∈X)∩(x/∈Xl)
I[fs(x) = l]."
CLASS-CONDITIONAL DATA AUGMENTATION POLICY INTERVENTIONS,0.15784215784215785,"We argue that to address the degraded accuracy of class k it is also important to consider DA effect
on class l. In Appendix E, we show the number of class-level False Positive mistakes as a function of
DA strength for the set of classes with the highest ∆FPl = FPl(s = 8%) −mins FPl(s) (i.e. the
classes for which the number of FP mistakes increased the most with standard augmentation). Note
that these classes are often semantically related to and confused with the ones affected in accuracy,
for example “stage” is confused with “guitar”, “barbershop” with “tobacco shop”."
CLASS-CONDITIONAL DATA AUGMENTATION POLICY INTERVENTIONS,0.15884115884115885,"We explore a simple adaptation of DA policy informed by the following observations: (1) generally
stronger DA is helpful for the majority of classes and leads to learning more diverse features, (2) a
substantially increased number of False Positive mistakes for a particular class likely indicates that
its augmented data distribution overlaps with other classes and it might negatively affect accuracy of
those related classes. Further, we discuss training the model from scratch using class-conditional
augmentation policy, and in Appendix E we consider fine-tuning the model using class-conditional
augmentation starting from a checkpoint pre-trained with the strongest augmentation strength."
CLASS-CONDITIONAL DATA AUGMENTATION POLICY INTERVENTIONS,0.15984015984015984,"Class-conditional augmentation policy.
In general, for a class that is not closely related to
other classes, strong RRC augmentation should lead to learning diverse features correlated with the
class label and improving accuracy. Thus, by default we set the strongest data augmentation value
s = 8% for the majority of classes, and change augmentation level for a small subset of classes.
We change the augmentation strength for m classes for which False Positive mistakes grew the
most with stronger DA (i.e. the classes with the highest ∆FPl). However, completely removing
augmentation from these classes would hurt their accuracy (or equivalently increase the number"
CLASS-CONDITIONAL DATA AUGMENTATION POLICY INTERVENTIONS,0.16083916083916083,"of False Negative mistakes) so we need to balance the tradeoff between learning diverse features
and avoiding class confusions. As a heuristic, we set augmentation strength for each class l to
s∗= arg mins FPl(s) + FNl(s) corresponding to the minimum of the total number of class-related
mistakes across augmentation levels."
CLASS-CONDITIONAL DATA AUGMENTATION POLICY INTERVENTIONS,0.16183816183816183,"We vary the number of classes for which we change augmentations in the range m ∈{10, 30, 50}.
In Table 1 we show the results where the parameters of the augmentation policy are defined using
original ImageNet labels and in Appendix E we use ReaL multi-label annotations. We compare this
intervention to the baseline model trained with the strongest augmentation s = 8%, mild augmentation
level s = 60% optimal for average accuracy on the affected set of classes, and the class-conditional
augmentation approach studied in Balestriero et al. [1] where we remove augmentation from the
negatively affected classes. We find existing approaches sacrifice accuracy on the subset of negatively
affected classes for overall average accuracy or vice versa. For example, as we previously observed
the default model trained with s = 8% achieves high average accuracy on the majority of classes
but suboptimal accuracy on the 50 classes affected by strong augmentation. Optimal performance
on these 50 classes is attained by the model trained with s = 60%, but the overall average accuracy
significantly degrades. Removing augmentation from the negatively affected classes only exacerbates
the effect and decreases the accuracy both on the affected set and on average. At the same time, tuning
down augmentation level on 1 to 5% of classes with the highest FP mistake increase improves the
accuracy on the affected classes by 2.5% for m = 50, and taking into account the tradeoff between
False Positive and False Negative mistakes helps to maintain high average accuracy overall and on
majority of classes (the average accuracy decreased by 0.1% for m = 50). These results support our
hypothesis and demonstrate how a simple intervention on a small number of classes informed by the
appropriate metrics can substantially improve performance on the negatively affected data."
CLASS-CONDITIONAL DATA AUGMENTATION POLICY INTERVENTIONS,0.16283716283716285,"In Appendix F we study the class-level accuracy degradation of the ViT-S [15] model trained on
ImageNet with varied RRC augmentation strength. We observe that a similar set of classes is
negatively affected in accuracy with stronger augmentation and multi-label annotations resolve some
cases of accuracy degradation. Similarly, we identify the same categories of class confusions. By
conducting class-conditional augmentation intervention and adapting augmentation strength for
m = 10 classes with the highest increase in False Positive mistakes, we improve the average accuracy
on the degraded classes by over 3%: from 52.28% ± 0.18% to 55.49% ± 0.07%."
DISCUSSION,0.16383616383616384,"7
Discussion"
DISCUSSION,0.16483516483516483,"In this work, we provide new insights into the class-level accuracy degradation on ImageNet when
using standard data augmentation. We show that it is important to consider the interactions among
class-conditional data distributions, and how data augmentation affects these interactions. We sys-
tematically categorize the most significantly affected classes as inherently ambiguous, co-occurring,
or involving fine-grained distinctions. These categories often suffer from label noise and thus the
overall negative effect is significantly muted when evaluating performance with cleaner multi-label
annotations. However, we also identify non-trivial cases, where the negative effects of data augmenta-
tion cannot be explained by label noise such as fine-grained categories. Finally, in contrast to prior
attempts, we show that a simple class-conditional data augmentation policy based on our insights can
significantly improve performance on the classes negatively affected by standard data augmentation."
DISCUSSION,0.16583416583416583,"Practical recommendations.
When evaluating model performance, one should not only check
average accuracy, which may conceal class-level learning dynamics. Instead, we recommend re-
searchers also consider other metrics such as False Negative and False Positive mistakes to better
detect which confusions data augmentation introduces or exacerbates. In particular, when training
a model with strong augmentations, one should train another model with milder augmentation to
check whether these finer-grained metrics degraded as an indicator that augmentation is biasing the
model’s predictions. We can then design targeted augmentation policies to improve performance on
the groups negatively affected by standard augmentation."
DISCUSSION,0.16683316683316685,Acknowledgements
DISCUSSION,0.16783216783216784,"We thank Yucen Lily Li, Sanae Lotfi, Pavel Izmailov, David Lopez-Paz and Badr Idrissi for useful
discussions. Polina Kirichenko and Andrew Gordon Wilson were partially supported by NSF
CAREER IIS-2145492, NSF I-DISRE 193471, NIH R01DA048764-01A1, NSF IIS-1910266, NSF
1922658 NRT-HDR, Meta Core Data Science, Google AI Research, BigHat Biosciences, Capital
One, and an Amazon Research Award."
REFERENCES,0.16883116883116883,References
REFERENCES,0.16983016983016982,"[1] Balestriero, R., Bottou, L., and LeCun, Y. (2022a). The effects of regularization and data augmentation are
class dependent. arXiv preprint arXiv:2204.03632."
REFERENCES,0.17082917082917082,"[2] Balestriero, R., Misra, I., and LeCun, Y. (2022b). A data-augmentation is worth a thousand samples: Exact
quantification from analytical augmented sample moments. arXiv preprint arXiv:2202.08325."
REFERENCES,0.17182817182817184,"[3] Benton, G., Finzi, M., Izmailov, P., and Wilson, A. G. (2020). Learning invariances in neural networks from
training data. Advances in neural information processing systems, 33:17605–17616."
REFERENCES,0.17282717282717283,"[4] Beyer, L., Hénaff, O. J., Kolesnikov, A., Zhai, X., and Oord, A. v. d. (2020). Are we done with imagenet?
arXiv preprint arXiv:2006.07159."
REFERENCES,0.17382617382617382,"[5] Bird, S., Klein, E., and Loper, E. (2009). Natural language processing with Python: analyzing text with the
natural language toolkit. "" O’Reilly Media, Inc.""."
REFERENCES,0.17482517482517482,"[6] Bitterwolf, J., Meinke, A., Boreiko, V., and Hein, M. (2022). Classifiers should do well even on their worst
classes. In ICML 2022 Shift Happens Workshop."
REFERENCES,0.17582417582417584,"[7] Blodgett, S. L., Green, L., and O’Connor, B. (2016). Demographic dialectal variation in social media: A
case study of african-american english. arXiv preprint arXiv:1608.08868."
REFERENCES,0.17682317682317683,"[8] Botev, A., Bauer, M., and De, S. (2022). Regularising for invariance to data augmentation improves
supervised learning. arXiv preprint arXiv:2203.03304."
REFERENCES,0.17782217782217782,"[9] Bouchacourt, D., Ibrahim, M., and Morcos, A. (2021). Grounding inductive biases in natural images:
invariance stems from variations in data. Advances in Neural Information Processing Systems, 34:19566–
19579."
REFERENCES,0.17882117882117882,"[10] Buolamwini, J. and Gebru, T. (2018). Gender shades: Intersectional accuracy disparities in commercial
gender classification. In Conference on fairness, accountability and transparency, pages 77–91. PMLR."
REFERENCES,0.1798201798201798,"[11] Cheung, T.-H. and Yeung, D.-Y. (2022). Adaaug: Learning class-and instance-adaptive data augmentation
policies. In International Conference on Learning Representations."
REFERENCES,0.18081918081918083,"[12] Cubuk, E. D., Zoph, B., Mane, D., Vasudevan, V., and Le, Q. V. (2018). Autoaugment: Learning
augmentation policies from data. arXiv preprint arXiv:1805.09501."
REFERENCES,0.18181818181818182,"[13] Cubuk, E. D., Zoph, B., Shlens, J., and Le, Q. V. (2020). Randaugment: Practical automated data
augmentation with a reduced search space. In Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition workshops, pages 702–703."
REFERENCES,0.18281718281718282,"[14] Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M.,
Minderer, M., Heigold, G., Gelly, S., et al. (2020). An image is worth 16x16 words: Transformers for image
recognition at scale. arXiv preprint arXiv:2010.11929."
REFERENCES,0.1838161838161838,"[15] Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M.,
Minderer, M., Heigold, G., Gelly, S., Uszkoreit, J., and Houlsby, N. (2021). An image is worth 16x16 words:
Transformers for image recognition at scale. In ICLR."
REFERENCES,0.1848151848151848,"[16] Fellbaum, C. (1998). WordNet: An Electronic Lexical Database. The MIT Press."
REFERENCES,0.18581418581418582,"[17] Fujii, S., Ishii, Y., Kozuka, K., Hirakawa, T., Yamashita, T., and Fujiyoshi, H. (2022). Data augmentation
by selecting mixed classes considering distance between classes. arXiv preprint arXiv:2209.05122."
REFERENCES,0.18681318681318682,"[18] Geiping, J., Goldblum, M., Somepalli, G., Shwartz-Ziv, R., Goldstein, T., and Wilson, A. G. (2022). How
much data are augmentations worth? an investigation into scaling laws, invariance, and implicit regularization.
arXiv preprint arXiv:2210.06441."
REFERENCES,0.1878121878121878,"[19] Gontijo-Lopes, R., Smullin, S. J., Cubuk, E. D., and Dyer, E. (2020). Affinity and diversity: Quantifying
mechanisms of data augmentation. arXiv preprint arXiv:2002.08973."
REFERENCES,0.1888111888111888,"[20] Hataya, R., Zdenek, J., Yoshizoe, K., and Nakayama, H. (2020). Faster autoaugment: Learning augmenta-
tion strategies using backpropagation. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow,
UK, August 23–28, 2020, Proceedings, Part XXV 16, pages 1–16. Springer."
REFERENCES,0.18981018981018982,"[21] Hauberg, S., Freifeld, O., Larsen, A. B. L., Fisher, J., and Hansen, L. (2016). Dreaming more data:
Class-dependent distributions over diffeomorphisms for learned data augmentation. In Artificial intelligence
and statistics, pages 342–350. PMLR."
REFERENCES,0.19080919080919082,"[22] He, K., Zhang, X., Ren, S., and Sun, J. (2016). Deep residual learning for image recognition. In CVPR."
REFERENCES,0.1918081918081918,"[23] Hermann, K., Chen, T., and Kornblith, S. (2020). The origins and prevalence of texture bias in convolutional
neural networks. Advances in Neural Information Processing Systems, 33:19000–19015."
REFERENCES,0.1928071928071928,"[24] Hernández-García, A. and König, P. (2018). Further advantages of data augmentation on convolutional
neural networks. In Artificial Neural Networks and Machine Learning–ICANN 2018: 27th International
Conference on Artificial Neural Networks, Rhodes, Greece, October 4-7, 2018, Proceedings, Part I 27, pages
95–103. Springer."
REFERENCES,0.1938061938061938,"[25] Ho, D., Liang, E., Chen, X., Stoica, I., and Abbeel, P. (2019). Population based augmentation: Efficient
learning of augmentation policy schedules. In International Conference on Machine Learning, pages
2731–2741. PMLR."
REFERENCES,0.19480519480519481,"[26] Honnibal, M., Montani, I., Van Landeghem, S., and Boyd, A. (2020). spacy: Industrial-strength natural
language processing in python."
REFERENCES,0.1958041958041958,"[27] Hooker, S., Courville, A., Clark, G., Dauphin, Y., and Frome, A. (2019). What do compressed deep neural
networks forget? arXiv preprint arXiv:1911.05248."
REFERENCES,0.1968031968031968,"[28] Hovy, D. and Søgaard, A. (2015). Tagging performance correlates with author age. In Proceedings of
the 53rd annual meeting of the Association for Computational Linguistics and the 7th international joint
conference on natural language processing (volume 2: Short papers), pages 483–488."
REFERENCES,0.1978021978021978,"[29] Hu, M. and Li, J. (2019). Exploring bias in gan-based data augmentation for small samples. arXiv preprint
arXiv:1905.08495."
REFERENCES,0.19880119880119881,"[30] Idrissi, B. Y., Bouchacourt, D., Balestriero, R., Evtimov, I., Hazirbas, C., Ballas, N., Vincent, P., Drozdzal,
M., Lopez-Paz, D., and Ibrahim, M. (2022). Imagenet-x: Understanding model mistakes with factor of
variation annotations. arXiv preprint arXiv:2211.01866."
REFERENCES,0.1998001998001998,"[31] Izmailov, P., Kirichenko, P., Gruver, N., and Wilson, A. G. (2022). On feature learning in the presence of
spurious correlations. arXiv preprint arXiv:2210.11369."
REFERENCES,0.2007992007992008,"[32] Kaplun, G., Ghosh, N., Garg, S., Barak, B., and Nakkiran, P. (2022). Deconstructing distributions: A
pointwise framework of learning. arXiv preprint arXiv:2202.09931."
REFERENCES,0.2017982017982018,"[33] Kapoor, S., Maddox, W. J., Izmailov, P., and Wilson, A. G. (2022). On uncertainty, tempering, and data
augmentation in bayesian classification. arXiv preprint arXiv:2203.16481."
REFERENCES,0.20279720279720279,"[34] Leclerc, G., Ilyas, A., Engstrom, L., Park, S. M., Salman, H., and Madry, A. (2022). FFCV: Accelerating
training by removing data bottlenecks. https://github.com/libffcv/ffcv/. commit xxxxxxx."
REFERENCES,0.2037962037962038,"[35] Li, Y., Hu, G., Wang, Y., Hospedales, T., Robertson, N. M., and Yang, Y. (2020). Dada: Differentiable
automatic data augmentation. arXiv preprint arXiv:2003.03780."
REFERENCES,0.2047952047952048,"[36] Lim, S., Kim, I., Kim, T., Kim, C., and Kim, S. (2019). Fast autoaugment. Advances in Neural Information
Processing Systems, 32."
REFERENCES,0.2057942057942058,"[37] Lin, C.-H., Kaushik, C., Dyer, E. L., and Muthukumar, V. (2022). The good, the bad and the ugly sides of
data augmentation: An implicit spectral regularization perspective. arXiv preprint arXiv:2210.05021."
REFERENCES,0.20679320679320679,"[38] Liu, Z., Mao, H., Wu, C.-Y., Feichtenhofer, C., Darrell, T., and Xie, S. (2022). A convnet for the 2020s.
arXiv preprint arXiv:2201.03545."
REFERENCES,0.2077922077922078,"[39] Luccioni, A. S. and Rolnick, D. (2022). Bugs in the data: How imagenet misrepresents biodiversity. arXiv
preprint arXiv:2208.11695."
REFERENCES,0.2087912087912088,"[40] Mahan, S., Kvinge, H., and Doster, T. (2021). Rotating spiders and reflecting dogs: a class conditional
approach to learning data augmentation distributions. arXiv preprint arXiv:2106.04009."
REFERENCES,0.2097902097902098,"[41] Miao, N., Mathieu, E., Dubois, Y., Rainforth, T., Teh, Y. W., Foster, A., and Kim, H. (2022). Learning
instance-specific data augmentations. arXiv preprint arXiv:2206.00051."
REFERENCES,0.21078921078921078,"[42] Miller, J. P., Taori, R., Raghunathan, A., Sagawa, S., Koh, P. W., Shankar, V., Liang, P., Carmon, Y.,
and Schmidt, L. (2021). Accuracy on the line: on the strong correlation between out-of-distribution and
in-distribution generalization. In International Conference on Machine Learning, pages 7721–7735. PMLR."
REFERENCES,0.21178821178821178,"[43] Müller, S. G. and Hutter, F. (2021). Trivialaugment: Tuning-free yet state-of-the-art data augmentation. In
Proceedings of the IEEE/CVF international conference on computer vision, pages 774–782."
REFERENCES,0.2127872127872128,"[44] Nilsback, M.-E. and Zisserman, A. (2008). Automated flower classification over a large number of classes.
In 2008 Sixth Indian Conference on Computer Vision, Graphics Image Processing, pages 722–729."
REFERENCES,0.2137862137862138,"[45] Northcutt, C., Jiang, L., and Chuang, I. (2021a). Confident learning: Estimating uncertainty in dataset
labels. Journal of Artificial Intelligence Research, 70:1373–1411."
REFERENCES,0.21478521478521478,"[46] Northcutt, C. G., Athalye, A., and Mueller, J. (2021b). Pervasive label errors in test sets destabilize machine
learning benchmarks. arXiv preprint arXiv:2103.14749."
REFERENCES,0.21578421578421578,"[47] Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z., Desmaison, A., Antiga, L.,
and Lerer, A. (2017). Automatic differentiation in pytorch."
REFERENCES,0.21678321678321677,"[48] Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N.,
Antiga, L., Desmaison, A., Kopf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner,
B., Fang, L., Bai, J., and Chintala, S. (2019). Pytorch: An imperative style, high-performance deep learning
library. In Wallach, H., Larochelle, H., Beygelzimer, A., d'Alché-Buc, F., Fox, E., and Garnett, R., editors,
Advances in Neural Information Processing Systems 32, pages 8024–8035. Curran Associates, Inc."
REFERENCES,0.2177822177822178,"[49] Raghunathan, A., Xie, S. M., Yang, F., Duchi, J., and Liang, P. (2020). Understanding and mitigating the
tradeoff between robustness and accuracy. arXiv preprint arXiv:2002.10716."
REFERENCES,0.21878121878121878,"[50] Ratner, A. J., Ehrenberg, H., Hussain, Z., Dunnmon, J., and Ré, C. (2017). Learning to compose domain-
specific transformations for data augmentation. Advances in neural information processing systems, 30."
REFERENCES,0.21978021978021978,"[51] Rey-Area, M., Guirado, E., Tabik, S., and Ruiz-Hidalgo, J. (2020). Fucitnet: Improving the generalization
of deep learning networks by the fusion of learned class-inherent transformations. Information Fusion,
63:188–195."
REFERENCES,0.22077922077922077,"[52] Richards, M., Kirichenko, P., Bouchacourt, D., and Ibrahim, M. (2023). Does progress on object recognition
benchmarks improve real-world generalization? arXiv preprint arXiv:2307.13136."
REFERENCES,0.2217782217782218,"[53] Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A.,
Bernstein, M., et al. (2015). Imagenet large scale visual recognition challenge. International journal of
computer vision, 115:211–252."
REFERENCES,0.22277722277722278,"[54] Sagawa, S., Koh, P. W., Hashimoto, T. B., and Liang, P. (2019). Distributionally robust neural net-
works for group shifts: On the importance of regularization for worst-case generalization. arXiv preprint
arXiv:1911.08731."
REFERENCES,0.22377622377622378,"[55] Salman, H., Jain, S., Ilyas, A., Engstrom, L., Wong, E., and Madry, A. (2022). When does bias transfer in
transfer learning? arXiv preprint arXiv:2207.02842."
REFERENCES,0.22477522477522477,"[56] Shah, H., Park, S. M., Ilyas, A., and Madry, A. (2022). Modeldiff: A framework for comparing learning
algorithms. arXiv preprint arXiv:2211.12491."
REFERENCES,0.22577422577422576,"[57] Shankar, V., Roelofs, R., Mania, H., Fang, A., Recht, B., and Schmidt, L. (2020). Evaluating machine
accuracy on imagenet. In International Conference on Machine Learning, pages 8634–8644. PMLR."
REFERENCES,0.22677322677322678,"[58] Steiner, A., Kolesnikov, A., Zhai, X., Wightman, R., Uszkoreit, J., and Beyer, L. (2021). How to train your
vit? data, augmentation, and regularization in vision transformers. arXiv preprint arXiv:2106.10270."
REFERENCES,0.22777222777222778,"[59] Stock, P. and Cisse, M. (2018). Convnets and imagenet beyond accuracy: Understanding mistakes and
uncovering biases. In Proceedings of the European Conference on Computer Vision (ECCV), pages 498–512."
REFERENCES,0.22877122877122877,"[60] Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z. (2016). Rethinking the inception architecture
for computer vision. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pages 2818–2826."
REFERENCES,0.22977022977022976,"[61] Tan, M. and Le, Q. (2019). Efficientnet: Rethinking model scaling for convolutional neural networks. In
International conference on machine learning, pages 6105–6114. PMLR."
REFERENCES,0.23076923076923078,"[62] Tang, Z., Peng, X., Li, T., Zhu, Y., and Metaxas, D. N. (2019). Adatransform: Adaptive data transformation.
In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 2998–3006."
REFERENCES,0.23176823176823177,"[63] Tatman, R. (2017). Gender and dialect bias in youtube’s automatic captions. In Proceedings of the first
ACL workshop on ethics in natural language processing, pages 53–59."
REFERENCES,0.23276723276723277,"[64] Teney, D., Lin, Y., Oh, S. J., and Abbasnejad, E. (2022). Id and ood performance are sometimes inversely
correlated on real-world datasets. arXiv preprint arXiv:2209.00613."
REFERENCES,0.23376623376623376,"[65] Touvron, H., Cord, M., Douze, M., Massa, F., Sablayrolles, A., and Jégou, H. (2021). Training data-efficient
image transformers & distillation through attention. In International conference on machine learning, pages
10347–10357. PMLR."
REFERENCES,0.23476523476523475,"[66] Touvron, H., Vedaldi, A., Douze, M., and Jégou, H. (2019). Fixing the train-test resolution discrepancy.
Advances in neural information processing systems, 32."
REFERENCES,0.23576423576423577,"[67] Tsipras, D., Santurkar, S., Engstrom, L., Ilyas, A., and Madry, A. (2020). From imagenet to image
classification: Contextualizing progress on benchmarks. In International Conference on Machine Learning,
pages 9625–9635. PMLR."
REFERENCES,0.23676323676323677,"[68] Van Horn, G., Branson, S., Farrell, R., Haber, S., Barry, J., Ipeirotis, P., Perona, P., and Belongie, S. (2015).
Building a bird recognition app and large scale dataset with citizen scientists: The fine print in fine-grained
dataset collection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
pages 595–604."
REFERENCES,0.23776223776223776,"[69] Vasudevan, V., Caine, B., Gontijo-Lopes, R., Fridovich-Keil, S., and Roelofs, R. (2022). When does dough
become a bagel? analyzing the remaining mistakes on imagenet. arXiv preprint arXiv:2205.04596."
REFERENCES,0.23876123876123875,"[70] Xu, Y., Noy, A., Lin, M., Qian, Q., Li, H., and Jin, R. (2020). Wemix: How to better utilize data
augmentation. arXiv preprint arXiv:2010.01267."
REFERENCES,0.23976023976023977,"[71] Yao, H., Wang, Y., Li, S., Zhang, L., Liang, W., Zou, J., and Finn, C. (2022). Improving out-of-distribution
robustness via selective augmentation. In International Conference on Machine Learning, pages 25407–25437.
PMLR."
REFERENCES,0.24075924075924077,"[72] Yun, S., Oh, S. J., Heo, B., Han, D., Choe, J., and Chun, S. (2021). Re-labeling imagenet: from single
to multi-labels, from global to localized labels. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, pages 2340–2350."
REFERENCES,0.24175824175824176,"[73] Zhang, H., Cisse, M., Dauphin, Y. N., and Lopez-Paz, D. (2017). mixup: Beyond empirical risk minimiza-
tion. arXiv preprint arXiv:1710.09412."
REFERENCES,0.24275724275724275,"[74] Zheng, Y., Zhang, Z., Yan, S., and Zhang, M. (2022). Deep autoaugment. arXiv preprint arXiv:2203.06172."
REFERENCES,0.24375624375624375,"[75] Zhou, F., Li, J., Xie, C., Chen, F., Hong, L., Sun, R., and Li, Z. (2021). Metaaugment: Sample-aware data
augmentation policy learning. In Proceedings of the AAAI conference on artificial intelligence, volume 35,
pages 11097–11105."
REFERENCES,0.24475524475524477,Appendix Outline
REFERENCES,0.24575424575424576,This appendix is organized as follows:
REFERENCES,0.24675324675324675,"• In Section A, we provide additional details on the training procedure and hyper-parameters
used in our experiments."
REFERENCES,0.24775224775224775,• In Section B we provide precise definitions of our evaluation metrics.
REFERENCES,0.24875124875124874,"• In Section C we visualize the accuracy on the classes most negatively affected by data
augmentation."
REFERENCES,0.24975024975024976,• We discuss the different types of class confusions caused by data augmentation in Section D.
REFERENCES,0.25074925074925075,"• In Section E we provide additional experiments for the proposed class-conditional data
augmentation policy."
REFERENCES,0.2517482517482518,"• In Section F we provide additional results with EfficientNet and Vision Transformer archi-
tectures."
REFERENCES,0.25274725274725274,"• In Section G we confirm our results on additional data augmentation transformations and
two addditional datasets."
REFERENCES,0.25374625374625376,• We discuss broader impacts and limitations in Section H.
REFERENCES,0.2547452547452547,"A
Training details"
REFERENCES,0.25574425574425574,"Following [1], we train ResNet-50 models for 88 epochs with SGD with momentum 0.9, using batch
size 1024, weight decay 10−4, and label smoothing 0.1. We use cyclic learning rate schedule starting
from the initial learning rate 10−4 with the peak value 1 after 2 epochs and linearly decaying to 0
until the end of training. We use PyTorch [47], automatic mixed precision training with torch.amp
package3, ffcv package [34] for fast data loading. We use image resolution 176 during training,
and resolution 224 during evaluation, following Touvron et al. [66] and torchvision training
recipe4. Balestriero et al. [1] also use different image resolution at training and test time: ramping
up resolution from 160 to 192 during training and evaluating models on images with resolution
256. We train 10 independent models with different random seeds for each augmentation strength
s ∈{8, 20, 30, 40, 50, 60, 70, 80, 90, 99%} where s = 8% corresponds to the strongest and default
augmentation."
REFERENCES,0.25674325674325676,"B
Evaluation metrics"
REFERENCES,0.25774225774225773,"To understand the biases introduced or exacerbated by data augmentation, we use a number of
fine-grained metrics and evaluate them for models trained with different augmentation levels. We
compute these metrics using original ImageNet validation labels and ReaL multi-label annotations
[4]. We use fs(·) to denote a neural network trained with augmentation parameter s, lReaL(x) a
set of ReaL labels for a validation example x, X a set of all validation images, Xk the validation
examples with the original label k."
REFERENCES,0.25874125874125875,Accuracy. The average accuracy for original and ReaL labels is defined as:
REFERENCES,0.2597402597402597,"aor(s) = 1/|X|
X"
REFERENCES,0.26073926073926074,"x∈X
I[fs(x) = k]
and
aReaL = 1/|X|
X"
REFERENCES,0.26173826173826176,"x∈X
I[fs(x) ∈lReaL(x)],"
REFERENCES,0.2627372627372627,"while for per-class accuracies aor
k (s) and aReaL
k
(s) the summation is over the set Xk instead of all
validation examples X. The accuracy on class k with original labels aor
k (s) also correspond to the
recall of the model on that class."
REFERENCES,0.26373626373626374,"Confusion. In Section 5 we looked at class confusions, in particular, for a pair of classes k and l the
confusion rate (CR) is defined as:"
REFERENCES,0.2647352647352647,"3https://pytorch.org/docs/stable/amp.html
4https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/"
REFERENCES,0.26573426573426573,"CRk→l(s) = 1/|Xk|
X"
REFERENCES,0.26673326673326675,"x∈Xk
I[fs(x) = l],"
REFERENCES,0.2677322677322677,"i.e. the ratio of examples from class k misclassified as l. We are only discussing confusions CRk→l
in the context of original labels."
REFERENCES,0.26873126873126874,"False Positive and False Negative mistakes. In Section 6, we emphasized the importance of looking
at how data augmentation impacts not only per-class accuracy but also the number of False Positive
(FP) mistakes for a particular class:"
REFERENCES,0.26973026973026976,"FP or
k (s) =
X"
REFERENCES,0.2707292707292707,"(x∈X)∩(x/∈Xk)
I[fs(x) = k]
and
FP ReaL
k
(s) =
X"
REFERENCES,0.27172827172827174,"(x∈X)∩(k/∈lReaL(x))
I[fs(x) = k]"
REFERENCES,0.2727272727272727,"for original and Real labels respectively. The number of False Negative mistakes on class k in terms
of the original labels are directly related to the accuracy, or recall, on that class:"
REFERENCES,0.27372627372627373,"FN or
k (s) =
X"
REFERENCES,0.27472527472527475,"x∈Xk
I[fs(x) ̸= k] = |Xk|(1 −aor(s)),"
REFERENCES,0.2757242757242757,while for multi-label annotations we define it as:
REFERENCES,0.27672327672327673,"FN ReaL
k
(s) =
X"
REFERENCES,0.2777222777222777,"(x∈X)∩(k∈lReaL(x))
I[fs(x) /∈lReaL(x)],"
REFERENCES,0.2787212787212787,"i.e. the number of examples x which were misclassidied by the model where k was in the ReaL label
set lReaL(x). In Section 6 we explored s∗
k = arg min FNk(s) + FNk(s) as a proxy for optimal
class-conditional augmentation level which emphasizes the inherent tradeoff between class-level
accuracy and the number of False Positive mistakes."
REFERENCES,0.27972027972027974,"Affected classes. We are focusing on analyzing model’s behavior on the classes which were negatively
affected by strong (default) augmentation in terms of original or ReaL accuracy, i.e. classes where
the accuracy drop ∆ak = ak(s∗
k) −ak(s = 8%) from ak(s∗
k) = maxs ak(s) to ak(s = 8%) is the
highest. We focus on 5% of classes (50 classes) with the highest ∆ak following Balestriero et al. [1]
and measure the average accuracy on this set of classes as a function of s and after interventions in
Section 6. In Section 6, we also look at classes where the number of FP mistakes increased the most
with strong DA, i.e. with the highest ∆FPk = FPk(s = 8%) −mins FPk(s)."
REFERENCES,0.2807192807192807,"C
Accuracy of the classes most negatively affected by data augmentation"
REFERENCES,0.2817182817182817,"We show the per-class accuracies as a function of data augmentation strength s for (1) the 50 classes
most negatively affected in original accuracy, i.e. with the highest ∆aor
k in Figure 4, and (2) 50
classes most negatively affected in ReaL accuracy in Figure 5. 50 60 70"
REFERENCES,0.2827172827172827,validation acc (%) 35 40 45 40 60 80 40 60 40 60 80 50 60
REFERENCES,0.2837162837162837,validation acc (%) 40 60 20 40 60 80 50 60 70 65 70 75 80 40 50
REFERENCES,0.28471528471528473,validation acc (%) 55 60 50 60 70 60 70 70 75 80 65 70 75 80
REFERENCES,0.2857142857142857,validation acc (%) 60 70 80 40 50 60 70 60 70 80 25 50 75 70 75 80
REFERENCES,0.2867132867132867,validation acc (%) 30 40 30 40 50 70 75 80 75 80 85 90.0 92.5 95.0 97.5
REFERENCES,0.28771228771228774,validation acc (%) 75 80 85 50 60 70 50 60 70 80 45 50 55 60 50 60
REFERENCES,0.2887112887112887,validation acc (%) 65 70 75 80 50 60 60 80 75 80 85 75 80 85 90
REFERENCES,0.2897102897102897,validation acc (%) 65 70 75 65.0 67.5 70.0 72.5 40 50 60 65 70 75 65 70 75 80
REFERENCES,0.2907092907092907,validation acc (%) 75 80 85 40 50 60 70 30 40 50 60 60 70 80
REFERENCES,0.2917082917082917,"25
50
75
100"
REFERENCES,0.29270729270729273,RRC scale lower bound s 86 88 90 92
REFERENCES,0.2937062937062937,validation acc (%)
REFERENCES,0.2947052947052947,"25
50
75
100"
REFERENCES,0.2957042957042957,RRC scale lower bound s 40 50 60 70
REFERENCES,0.2967032967032967,"25
50
75
100"
REFERENCES,0.2977022977022977,RRC scale lower bound s 60 70 80 90
REFERENCES,0.2987012987012987,"original IN label
ReaL labels"
REFERENCES,0.2997002997002997,"25
50
75
100"
REFERENCES,0.3006993006993007,RRC scale lower bound s 70 75
REFERENCES,0.3016983016983017,"25
50
75
100"
REFERENCES,0.3026973026973027,RRC scale lower bound s 40 50 60 70
REFERENCES,0.3036963036963037,"barn spider
∆aor = 15, ∆aReaL = 0"
REFERENCES,0.3046953046953047,"overskirt
∆aor = 13, ∆aReaL = 3"
REFERENCES,0.30569430569430567,"academic gown
∆aor = 13, ∆aReaL = 1"
REFERENCES,0.3066933066933067,"sunglass
∆aor = 12, ∆aReaL = 0"
REFERENCES,0.3076923076923077,"maillot
∆aor = 11, ∆aReaL = 3"
REFERENCES,0.3086913086913087,"Siberian husky
∆aor = 11, ∆aReaL = 9"
REFERENCES,0.3096903096903097,"Windsor tie
∆aor = 11, ∆aReaL = 7"
REFERENCES,0.3106893106893107,"screen
∆aor = 9, ∆aReaL = 1"
REFERENCES,0.3116883116883117,"toy terrier
∆aor = 9, ∆aReaL = 4"
REFERENCES,0.3126873126873127,"green mamba
∆aor = 9, ∆aReaL = 4"
REFERENCES,0.31368631368631367,"tobacco shop
∆aor = 8, ∆aReaL = 11"
REFERENCES,0.3146853146853147,"monastery
∆aor = 8, ∆aReaL = 2"
REFERENCES,0.3156843156843157,"tailed frog
∆aor = 8, ∆aReaL = 3"
REFERENCES,0.3166833166833167,"thresher
∆aor = 8, ∆aReaL = 0"
REFERENCES,0.3176823176823177,"parallel bars
∆aor = 8, ∆aReaL = 4"
REFERENCES,0.31868131868131866,"otterhound
∆aor = 7, ∆aReaL = 1"
REFERENCES,0.3196803196803197,"mailbag
∆aor = 7, ∆aReaL = 5"
REFERENCES,0.3206793206793207,"chain
∆aor = 7, ∆aReaL = 0"
REFERENCES,0.32167832167832167,"bulletproof vest
∆aor = 7, ∆aReaL = 7"
REFERENCES,0.3226773226773227,"maillot
∆aor = 7, ∆aReaL = 8"
REFERENCES,0.32367632367632365,"sombrero
∆aor = 7, ∆aReaL = 0"
REFERENCES,0.3246753246753247,"velvet
∆aor = 7, ∆aReaL = 1"
REFERENCES,0.3256743256743257,"tape player
∆aor = 7, ∆aReaL = 0"
REFERENCES,0.32667332667332666,"redbone
∆aor = 7, ∆aReaL = 2"
REFERENCES,0.3276723276723277,"bighorn
∆aor = 7, ∆aReaL = 8"
REFERENCES,0.32867132867132864,"damselﬂy
∆aor = 6, ∆aReaL = 6"
REFERENCES,0.32967032967032966,"gar
∆aor = 6, ∆aReaL = 5"
REFERENCES,0.3306693306693307,"assault riﬂe
∆aor = 6, ∆aReaL = 1"
REFERENCES,0.33166833166833165,"cornet
∆aor = 6, ∆aReaL = 6"
REFERENCES,0.33266733266733267,"pole
∆aor = 6, ∆aReaL = 3"
REFERENCES,0.3336663336663337,"bloodhound
∆aor = 6, ∆aReaL = 0"
REFERENCES,0.33466533466533466,"muzzle
∆aor = 6, ∆aReaL = 4"
REFERENCES,0.3356643356643357,"frying pan
∆aor = 6, ∆aReaL = 4"
REFERENCES,0.33666333666333664,"ear
∆aor = 6, ∆aReaL = 2"
REFERENCES,0.33766233766233766,"electric ray
∆aor = 6, ∆aReaL = 0"
REFERENCES,0.3386613386613387,"vault
∆aor = 6, ∆aReaL = 1"
REFERENCES,0.33966033966033965,"barrel
∆aor = 5, ∆aReaL = 1"
REFERENCES,0.34065934065934067,"French loaf
∆aor = 5, ∆aReaL = 0"
REFERENCES,0.34165834165834164,"spatula
∆aor = 5, ∆aReaL = 2"
REFERENCES,0.34265734265734266,black-and-tan coonhound
REFERENCES,0.3436563436563437,"∆aor = 5, ∆aReaL = 5"
REFERENCES,0.34465534465534464,"sax
∆aor = 5, ∆aReaL = 4"
REFERENCES,0.34565434565434566,"wire-haired fox terrier
∆aor = 5, ∆aReaL = 3"
REFERENCES,0.34665334665334663,"seashore
∆aor = 5, ∆aReaL = 1"
REFERENCES,0.34765234765234765,"English foxhound
∆aor = 5, ∆aReaL = 3"
REFERENCES,0.34865134865134867,"safety pin
∆aor = 5, ∆aReaL = 4"
REFERENCES,0.34965034965034963,"pomegranate
∆aor = 5, ∆aReaL = 5"
REFERENCES,0.35064935064935066,"coﬀee mug
∆aor = 5, ∆aReaL = 0"
REFERENCES,0.3516483516483517,"collie
∆aor = 5, ∆aReaL = 2"
REFERENCES,0.35264735264735264,"Walker hound
∆aor = 5, ∆aReaL = 1"
REFERENCES,0.35364635364635366,"breastplate
∆aor = 5, ∆aReaL = 0"
REFERENCES,0.3546453546453546,stronger augmentation
REFERENCES,0.35564435564435565,"Figure 4: Per-class class validation accuracies of ResNet-50 trained on ImageNet computed with
original and ReaL labels as a function of Random Resized Crop data augmentation scale lower
bound s. We show the accuracy trends for the classes with the highest difference between the
maximum accuracy on that class across augmentation levels maxs aor
k (s) and the accuracy of the
model trained with s = 8%. On each subplot below the name of the class we show the accuracy
drops with respect to original and ReaL labels: ∆aor
k and ∆aReaL
k
. We report the mean and standard
error over 10 independent runs of the network. 40 50"
REFERENCES,0.35664335664335667,validation acc (%) 50 60 75 80 85 75 80 85 90 25 50 75 40 60
REFERENCES,0.35764235764235763,validation acc (%) 60 70 60 70 80 75 80 85 90 65 70 75 80 60 65 70
REFERENCES,0.35864135864135865,validation acc (%) 50 60 70 80 90.0 92.5 95.0 97.5 40 45 50 55 45 50 55 60 70
REFERENCES,0.3596403596403596,validation acc (%) 60 65 70 75 65 70 75 80 75 80 85 70 75 80 86 88 90 92
REFERENCES,0.36063936063936064,validation acc (%) 60 70 80 70 80 90 80 85 70 75 80 65 70 75 80
REFERENCES,0.36163836163836166,validation acc (%) 30 40 50 60 60 70 60 70 40 60 80 60 70 80
REFERENCES,0.3626373626373626,validation acc (%) 76 78 80 82 60 65 70 75 60 70 80 50 60 40 50 60
REFERENCES,0.36363636363636365,validation acc (%) 65 70 75 50 60 70 70 80 50 60 70 60 70 80
REFERENCES,0.3646353646353646,validation acc (%) 30 40 50 60 57.5 60.0 62.5 50 60 70 60 65 70
REFERENCES,0.36563436563436563,"25
50
75
100"
REFERENCES,0.36663336663336665,RRC scale lower bound s 60 70 80
REFERENCES,0.3676323676323676,validation acc (%)
REFERENCES,0.36863136863136864,"25
50
75
100"
REFERENCES,0.3696303696303696,RRC scale lower bound s 60 70 80
REFERENCES,0.3706293706293706,"25
50
75
100"
REFERENCES,0.37162837162837165,RRC scale lower bound s 60 70 80
REFERENCES,0.3726273726273726,"original IN label
ReaL labels"
REFERENCES,0.37362637362637363,"25
50
75
100"
REFERENCES,0.37462537462537465,RRC scale lower bound s 50 60
REFERENCES,0.3756243756243756,"25
50
75
100"
REFERENCES,0.37662337662337664,RRC scale lower bound s 70 75 80
REFERENCES,0.3776223776223776,"tobacco shop
∆aor = 8, ∆aReaL = 11"
REFERENCES,0.3786213786213786,"Siberian husky
∆aor = 11, ∆aReaL = 9"
REFERENCES,0.37962037962037964,"bighorn
∆aor = 7, ∆aReaL = 8"
REFERENCES,0.3806193806193806,"honeycomb
∆aor = 5, ∆aReaL = 8"
REFERENCES,0.38161838161838163,"maillot
∆aor = 7, ∆aReaL = 8"
REFERENCES,0.3826173826173826,"Windsor tie
∆aor = 11, ∆aReaL = 7"
REFERENCES,0.3836163836163836,"hand-held computer
∆aor = 5, ∆aReaL = 7"
REFERENCES,0.38461538461538464,"bulletproof vest
∆aor = 7, ∆aReaL = 7"
REFERENCES,0.3856143856143856,"trimaran
∆aor = 3, ∆aReaL = 7"
REFERENCES,0.3866133866133866,"strawberry
∆aor = 4, ∆aReaL = 7"
REFERENCES,0.3876123876123876,"alp
∆aor = 5, ∆aReaL = 6"
REFERENCES,0.3886113886113886,"cornet
∆aor = 6, ∆aReaL = 6"
REFERENCES,0.38961038961038963,"damselﬂy
∆aor = 6, ∆aReaL = 6"
REFERENCES,0.3906093906093906,"miniature poodle
∆aor = 1, ∆aReaL = 5"
REFERENCES,0.3916083916083916,"hair slide
∆aor = 2, ∆aReaL = 5"
REFERENCES,0.3926073926073926,"red wolf
∆aor = 2, ∆aReaL = 5"
REFERENCES,0.3936063936063936,black-and-tan coonhound
REFERENCES,0.3946053946053946,"∆aor = 5, ∆aReaL = 5"
REFERENCES,0.3956043956043956,"beacon
∆aor = 5, ∆aReaL = 5"
REFERENCES,0.3966033966033966,"gar
∆aor = 6, ∆aReaL = 5"
REFERENCES,0.39760239760239763,"limousine
∆aor = 3, ∆aReaL = 5"
REFERENCES,0.3986013986013986,"pomegranate
∆aor = 5, ∆aReaL = 5"
REFERENCES,0.3996003996003996,"mailbag
∆aor = 7, ∆aReaL = 5"
REFERENCES,0.4005994005994006,"pickelhaube
∆aor = 4, ∆aReaL = 5"
REFERENCES,0.4015984015984016,"nipple
∆aor = 4, ∆aReaL = 5"
REFERENCES,0.4025974025974026,"parallel bars
∆aor = 8, ∆aReaL = 4"
REFERENCES,0.4035964035964036,"sax
∆aor = 5, ∆aReaL = 4"
REFERENCES,0.4045954045954046,"hook
∆aor = 1, ∆aReaL = 4"
REFERENCES,0.40559440559440557,"bib
∆aor = 4, ∆aReaL = 4"
REFERENCES,0.4065934065934066,"home theater
∆aor = 0, ∆aReaL = 4"
REFERENCES,0.4075924075924076,"green lizard
∆aor = 0, ∆aReaL = 4"
REFERENCES,0.4085914085914086,"stopwatch
∆aor = 4, ∆aReaL = 4"
REFERENCES,0.4095904095904096,"groenendael
∆aor = 5, ∆aReaL = 4"
REFERENCES,0.41058941058941056,"Great Dane
∆aor = 3, ∆aReaL = 4"
REFERENCES,0.4115884115884116,"Yorkshire terrier
∆aor = 1, ∆aReaL = 4"
REFERENCES,0.4125874125874126,"plunger
∆aor = 3, ∆aReaL = 4"
REFERENCES,0.41358641358641357,"power drill
∆aor = 5, ∆aReaL = 4"
REFERENCES,0.4145854145854146,"suit
∆aor = 5, ∆aReaL = 4"
REFERENCES,0.4155844155844156,"shopping basket
∆aor = 3, ∆aReaL = 4"
REFERENCES,0.4165834165834166,"digital clock
∆aor = 2, ∆aReaL = 4"
REFERENCES,0.4175824175824176,"ashcan
∆aor = 4, ∆aReaL = 4"
REFERENCES,0.41858141858141856,"switch
∆aor = 4, ∆aReaL = 4"
REFERENCES,0.4195804195804196,"backpack
∆aor = 0, ∆aReaL = 4"
REFERENCES,0.4205794205794206,"toy poodle
∆aor = 1, ∆aReaL = 4"
REFERENCES,0.42157842157842157,"toy terrier
∆aor = 9, ∆aReaL = 4"
REFERENCES,0.4225774225774226,"cocktail shaker
∆aor = 1, ∆aReaL = 4"
REFERENCES,0.42357642357642356,soft-coated wheaten terrier
REFERENCES,0.4245754245754246,"∆aor = 3, ∆aReaL = 4"
REFERENCES,0.4255744255744256,"Staﬀordshire bullterrier
∆aor = 3, ∆aReaL = 4"
REFERENCES,0.42657342657342656,"safety pin
∆aor = 5, ∆aReaL = 4"
REFERENCES,0.4275724275724276,"frying pan
∆aor = 6, ∆aReaL = 4"
REFERENCES,0.42857142857142855,"isopod
∆aor = 2, ∆aReaL = 4"
REFERENCES,0.42957042957042957,stronger augmentation
REFERENCES,0.4305694305694306,"Figure 5: Per-class class validation accuracies of ResNet-50 trained on ImageNet computed with
original and ReaL labels as a function of Random Resized Crop data augmentation scale lower
bound s. We show the accuracy trends for the classes with the highest difference between the
maximum ReaL accuracy on that class across augmentation levels maxs aReaL
k
(s) and the ReaL
accuracy of the model trained with s = 8%. On each subplot below the name of the class we show
the accuracy drops with respect to original and ReaL labels: ∆aor
k and ∆aReaL
k
. We report the mean
and standard error over 10 independent runs of the network."
REFERENCES,0.43156843156843155,"D
Class confusion types"
REFERENCES,0.4325674325674326,"In Table 2 we show the classes most negatively affected in accuracy by strong data augmentation
(column “Affected class k”) and the confusions the model starts making more frequently with stronger
augmentation (“Confused class l”). In particular, we study the union of 50 classes most affected in
original accuracy and 50 classes most affected in ReaL accuracy (see Section C) which do not belong
to the animal subtree in WordNet tree. We focus on the confusions l where confusion rate difference"
REFERENCES,0.43356643356643354,"∆CRk→l = CRk→l(s = 8%) −min
s
CRk→l(s)"
REFERENCES,0.43456543456543456,"is the highest for class k and above 2.5% (see Section B for definition of confusion rate CRk→l(s)).
Additionally for each pair of confused classes k and l we also look at"
REFERENCES,0.4355644355644356,"∆CR∗
l→k = max
s
CRl→k(s) −CRl→k(s = 8%)"
REFERENCES,0.43656343656343655,"which characterizes to what extent the model trained with weaker augmentation starts making the
reverse confusion more often compared to the strong DA model."
REFERENCES,0.43756243756243757,"To quantitatively estimate the confusion type for each pair of classes, we measure the intrinsic
distribution overlap of the classes and their semantic similarity. We compute the overlap in Real
labels for classes k and l, which is the ratio of examples that have both labels k and l among the
examples with the label k:"
REFERENCES,0.4385614385614386,"Ckl =
X"
REFERENCES,0.43956043956043955,"x∈X
I[k ∈lReaL(x)] × I[l ∈lReaL(x)]/
X"
REFERENCES,0.4405594405594406,"x∈X
I[k ∈lReaL(x)]"
REFERENCES,0.44155844155844154,and intersection-over-union of the two classes:
REFERENCES,0.44255744255744256,"IoUkl =
X"
REFERENCES,0.4435564435564436,"x∈X
I[k ∈lReaL(x)] × I[l ∈lReaL(x)]/
X"
REFERENCES,0.44455544455544455,"x∈X
I[k ∈lReaL(x) or l ∈lReaL(x)]."
REFERENCES,0.44555444555444557,"We use WordNet class similarity and similarity of word embeddings from spaCy [26] to measure
semantic similarity. Note that these metrics only serve as approximate measures of distribution
overlap and semantic distance since (1) the ReaL labels still contain some amount of label noise and
may contain mislabelled examples or examples that are missing some of the plausible labels, (2) the
WordNet distance is sometimes low for classes that are semantically very similar, and (3) spaCy
doesn’t have a representation for all words and is underestimating the similarity of closely related
concepts. However, all together these metrics can point towards one of the appropriate confusion
type categories."
REFERENCES,0.44655344655344653,"In Figure 6 we show more examples of the confusion rates for different pairs of classes k and l as
a function of data augmentation strength s where k is among the ones most negatively affected in
accuracy and l is the class the model misclassified examples from the class k to. We show example
pairs from different confusion types defined in Section 5."
REFERENCES,0.44755244755244755,"In Figure 7 we show average original and ReaL accuracy on the 104 classes which have less than
1300 examples in the ImageNet train split (while the remaining majority of classes have exactly 1300
examples in train data). We hypothesize that if one of the confused classes has less examples in the
train data and DA leads to higher class distribution overlap, the underrepresented class will likely be
affected in accuracy by stronger augmentation."
REFERENCES,0.4485514485514486,"E
Additional details for the class-conditional augmentation intervention
experiments"
REFERENCES,0.44955044955044954,"In Figures 8 and 9 we show how the number of False Positive (FP) mistakes changes with data
augmentation strength for the set of classes where FP number increased the most with strong DA (see
Figure 8 for the set of classes where original FP mistakes increased the most and Figure 9 for ReaL
FP mistakes). In Section 6, we conducted class-conditional data augmentation interventions changing
the DA strength for these sets of classes and showed that it improved the accuracy on the classes
negatively affected in accuracy. While in Section 6 we show results for adapting augmentation level
for classes using original labels to evaluate False Positive and False Negative mistakes, in Table 3 we
show analogous results when using ReaL labels which also shows that this targeted augmentation
policy intervention for a small number of classes leads to improvement in ReaL average accuracy on
the affected classes (we specifically consider the set of classes affected in ReaL accuracy)."
REFERENCES,0.45054945054945056,"Ambiguous
Ambiguous"
REFERENCES,0.4515484515484515,"20
40
60
80
100"
REFERENCES,0.45254745254745254,augmentation strength s 25 30 35 40 45 50
REFERENCES,0.45354645354645357,% of val examples
REFERENCES,0.45454545454545453,"predictions on “maillot, tank suit”"
REFERENCES,0.45554445554445555,"maillot, tank suit
maillot 50 55 60"
REFERENCES,0.4565434565434565,"65
predictions on “maillot”"
REFERENCES,0.45754245754245754,"maillot, tank suit
maillot"
REFERENCES,0.45854145854145856,"20
40
60
80
100"
REFERENCES,0.4595404595404595,augmentation strength s 20 25 30
REFERENCES,0.46053946053946054,% of val examples
REFERENCES,0.46153846153846156,"20
40
60
80
100"
REFERENCES,0.46253746253746253,augmentation strength s 16 18 20 22 24 26 28
REFERENCES,0.46353646353646355,% of val examples
REFERENCES,0.4645354645354645,"predictions on “screen, CRT screen”"
REFERENCES,0.46553446553446554,"screen, CRT screen
monitor 30 35 40"
REFERENCES,0.46653346653346656,"45
predictions on “monitor”"
REFERENCES,0.4675324675324675,"screen
monitor"
REFERENCES,0.46853146853146854,"20
40
60
80
100"
REFERENCES,0.4695304695304695,augmentation strength s 10 15
REFERENCES,0.47052947052947053,% of val examples
REFERENCES,0.47152847152847155,"Co-occurring
Co-occurring"
REFERENCES,0.4725274725274725,"20
40
60
80
100"
REFERENCES,0.47352647352647353,augmentation strength s 25 30 35 40 45 50 55
REFERENCES,0.4745254745254745,% of val examples
REFERENCES,0.4755244755244755,predictions on “academic gown”
REFERENCES,0.47652347652347654,"academic gown
mortarboard"
REFERENCES,0.4775224775224775,"20
40
60
80
100"
REFERENCES,0.4785214785214785,augmentation strength s 20 30 40 50 60
REFERENCES,0.47952047952047955,% of val examples
REFERENCES,0.4805194805194805,predictions on “mortarboard”
REFERENCES,0.48151848151848153,"academic gown
mortarboard 45 50 55"
REFERENCES,0.4825174825174825,"60
predictions on “assault riﬂe”"
REFERENCES,0.4835164835164835,"assault riﬂe
military uniform"
REFERENCES,0.48451548451548454,"20
40
60
80
100"
REFERENCES,0.4855144855144855,augmentation strength s 5 10 15 20
REFERENCES,0.4865134865134865,% of val examples 60 65 70
REFERENCES,0.4875124875124875,75 predictions on “military uniform”
REFERENCES,0.4885114885114885,"assault riﬂe
military uniform"
REFERENCES,0.48951048951048953,"20
40
60
80
100"
REFERENCES,0.4905094905094905,augmentation strength s −1 0 1 2 3
REFERENCES,0.4915084915084915,% of val examples
REFERENCES,0.4925074925074925,"Fine-grained
Fine-grained"
REFERENCES,0.4935064935064935,"20
40
60
80
100"
REFERENCES,0.4945054945054945,augmentation strength s 10 20 30 40 50
REFERENCES,0.4955044955044955,% of val examples
REFERENCES,0.4965034965034965,predictions on “tobacco shop”
REFERENCES,0.4975024975024975,"tobacco shop
barbershop"
REFERENCES,0.4985014985014985,"20
40
60
80
100"
REFERENCES,0.4995004995004995,augmentation strength s 0 10 20 30 40 50 60
REFERENCES,0.5004995004995005,% of val examples
REFERENCES,0.5014985014985015,predictions on “barbershop”
REFERENCES,0.5024975024975025,"tobacco shop
barbershop"
REFERENCES,0.5034965034965035,"20
40
60
80
100"
REFERENCES,0.5044955044955045,augmentation strength s 10 20 30 40
REFERENCES,0.5054945054945055,% of val examples
REFERENCES,0.5064935064935064,predictions on “overskirt”
REFERENCES,0.5074925074925075,"overskirt
hoopskirt"
REFERENCES,0.5084915084915085,"20
40
60
80
100"
REFERENCES,0.5094905094905094,augmentation strength s 0 10 20 30 40 50 60 70
REFERENCES,0.5104895104895105,% of val examples
REFERENCES,0.5114885114885115,predictions on “hoopskirt”
REFERENCES,0.5124875124875125,"overskirt
hoopskirt"
REFERENCES,0.5134865134865135,"Fine-grained
Semantically unrelated"
REFERENCES,0.5144855144855145,"20
40
60
80
100"
REFERENCES,0.5154845154845155,augmentation strength s 10 20 30 40 50 60 70
REFERENCES,0.5164835164835165,% of val examples
REFERENCES,0.5174825174825175,predictions on “thresher”
REFERENCES,0.5184815184815185,"thresher
harvester"
REFERENCES,0.5194805194805194,"20
40
60
80
100"
REFERENCES,0.5204795204795205,augmentation strength s 0 20 40 60 80
REFERENCES,0.5214785214785215,% of val examples
REFERENCES,0.5224775224775224,predictions on “harvester”
REFERENCES,0.5234765234765235,"thresher
harvester"
REFERENCES,0.5244755244755245,"20
40
60
80
100"
REFERENCES,0.5254745254745254,augmentation strength s 0 10 20 30 40 50 60 70
REFERENCES,0.5264735264735265,% of val examples
REFERENCES,0.5274725274725275,predictions on “bath towel”
REFERENCES,0.5284715284715285,"bath towel
pillow"
REFERENCES,0.5294705294705294,"20
40
60
80
100"
REFERENCES,0.5304695304695305,augmentation strength s 0 20 40 60 80
REFERENCES,0.5314685314685315,% of val examples
REFERENCES,0.5324675324675324,predictions on “pillow”
REFERENCES,0.5334665334665335,"bath towel
pillow"
REFERENCES,0.5344655344655345,"Figure 6: Confusion rate for classes most negatively affected by strong data augmentation and
the corresponding classes they get confused with. We categorize confusions into ambiguous, co-
occurring, fine-grained and unrelated."
REFERENCES,0.5354645354645354,"20
40
60
80
100"
REFERENCES,0.5364635364635365,RRC scale lower bound s 64 66 68
REFERENCES,0.5374625374625375,validation acc (%)
REFERENCES,0.5384615384615384,original
REFERENCES,0.5394605394605395,"20
40
60
80
100"
REFERENCES,0.5404595404595405,RRC scale lower bound s 72 74 76 ReaL
REFERENCES,0.5414585414585414,Avg of underrepresented ImageNet classes
REFERENCES,0.5424575424575424,"Figure 7: Average accuracy of the 104 underrepresented ImageNet classes depending on the Random
Resized Crop augmentation strength. Average original accuracy on the underrepresented subset of
ImageNet decreases by 0.6% with stronger augmentation."
REFERENCES,0.5434565434565435,Table 2: Confusions on the classes most affected by data augmentation.
REFERENCES,0.5444555444555444,"Affected
class k
Confused
class l
∆conf. rate (%)
Label co-occur.
Semantic sim.
Confusion
type
∆CRk→l
∆CR∗
l→k
Clk
IoU
WN
spacy"
REFERENCES,0.5454545454545454,"overskirt
hoopskirt
5.80
3.60
0.31
0.17
0.91
–
fine-gr. (ambig.)
bonnet
4.20
0.00
0.03
0.02
0.73
0.32
fine-gr.
gown
4.00
2.40
0.50
0.21
0.73
0.37
fine-gr. (ambig.)
trench coat
3.60
0.40
0.00
0.00
0.75
0.42
fine-gr."
REFERENCES,0.5464535464535465,"academic gown
mortarboard
18.40
7.00
0.72
0.50
0.73
0.10
co-occur."
REFERENCES,0.5474525474525475,"sunglass
sunglasses
13.00
22.40
0.87
0.81
0.64
0.84
ambig."
REFERENCES,0.5484515484515484,"maillot
maillot
15.00
7.20
0.73
0.63
0.70
1.00
ambig."
REFERENCES,0.5494505494505495,"Windsor tie
suit
7.20
4.00
0.61
0.32
0.82
0.24
co-occur."
REFERENCES,0.5504495504495505,"screen
desktop computer
7.80
7.00
0.59
0.29
0.64
0.62
ambig.
monitor
3.20
6.40
0.87
0.37
0.63
0.44
ambig."
REFERENCES,0.5514485514485514,"tobacco shop
barbershop
5.20
2.80
0.00
0.00
0.91
0.56
fine-gr.
bookshop
6.80
6.40
0.00
0.00
0.91
0.53
fine-gr."
REFERENCES,0.5524475524475524,"monastery
church
2.80
6.80
0.11
0.03
0.70
0.71
fine-gr.
castle
2.80
11.20
0.00
0.00
0.60
0.69
fine-gr."
REFERENCES,0.5534465534465535,"thresher
harvester
6.60
16.40
0.04
0.01
0.90
0.49
fine-gr."
REFERENCES,0.5544455544455544,"parallel bars
horizontal bar
3.20
2.80
0.00
0.00
0.90
0.75
fine-gr.
balance beam
3.00
4.00
0.02
0.01
0.90
0.45
fine-gr."
REFERENCES,0.5554445554445554,"mailbag
purse
12.80
2.00
0.10
0.06
0.89
0.19
fine-gr.
backpack
4.00
5.60
0.00
0.00
0.89
0.16
fine-gr."
REFERENCES,0.5564435564435565,"chain
necklace
9.40
4.40
0.15
0.09
0.53
0.31
ambig."
REFERENCES,0.5574425574425574,"bulletproof vest
military uniform
5.60
3.40
0.31
0.13
0.76
0.38
co-occur. (ambig.)
assault rifle
3.20
0.40
0.32
0.17
0.40
0.35
co-occur."
REFERENCES,0.5584415584415584,"sombrero
cowboy hat
7.40
4.80
0.15
0.05
0.91
0.51
fine-gr."
REFERENCES,0.5594405594405595,"velvet
purse
3.60
2.60
0.00
0.00
0.62
0.29
unrelated
necklace
3.00
0.00
0.00
0.00
0.62
0.51
unrelated"
REFERENCES,0.5604395604395604,"tape player
radio
3.20
4.60
0.00
0.00
0.67
0.27
fine-gr.
cassette player
3.00
0.20
0.08
0.01
0.89
0.85
fine-gr."
REFERENCES,0.5614385614385614,"assault rifle
military uniform
8.40
0.40
0.47
0.24
0.42
0.42
co-occur."
REFERENCES,0.5624375624375625,"cornet
trombone
4.80
2.40
0.23
0.14
0.91
0.41
fine-gr."
REFERENCES,0.5634365634365635,"pole
traffic light
4.00
0.40
0.05
0.03
0.12
0.21
unrelated"
REFERENCES,0.5644355644355644,"muzzle
sandal
3.20
0.00
0.00
0.00
0.56
0.23
unrelated"
REFERENCES,0.5654345654345654,"ear
corn
5.40
4.40
0.81
0.52
0.78
0.23
ambig."
REFERENCES,0.5664335664335665,"vault
altar
6.40
4.40
0.21
0.12
0.62
0.41
fine-gr. (ambig.)"
REFERENCES,0.5674325674325674,"frying pan
Dutch oven
6.00
3.00
0.00
0.00
0.40
0.59
fine-gr.
wok
3.40
2.60
0.09
0.05
0.92
0.72
fine-gr."
REFERENCES,0.5684315684315684,"French loaf
bakery
4.40
1.80
0.10
0.06
0.24
0.42
co-occur."
REFERENCES,0.5694305694305695,"barrel
rain barrel
7.60
2.20
0.16
0.07
0.76
0.70
fine-gr. (ambig.)"
REFERENCES,0.5704295704295704,"spatula
wooden spoon
4.40
2.80
0.24
0.12
0.57
0.62
fine-gr."
REFERENCES,0.5714285714285714,"sax
flute
3.20
0.40
0.00
0.00
0.83
0.65
fine-gr."
REFERENCES,0.5724275724275725,"seashore
sandbar
3.80
2.80
0.64
0.47
0.57
0.69
co-occur."
REFERENCES,0.5734265734265734,"coffee mug
cup
7.80
0.80
0.61
0.34
0.19
0.63
ambig.
espresso
3.00
2.60
0.18
0.13
0.21
0.72
co-occur."
REFERENCES,0.5744255744255744,"breastplate
cuirass
6.00
6.40
0.71
0.50
0.67
0.48
ambig.
shield
3.20
1.20
0.07
0.05
0.70
0.59"
REFERENCES,0.5754245754245755,"beacon
breakwater
7.80
0.60
0.07
0.04
0.71
0.33
co-occur."
REFERENCES,0.5764235764235764,"suit
miniskirt
3.20
1.60
0.02
0.01
0.86
0.32
fine-gr."
REFERENCES,0.5774225774225774,"hand-held computer
cellular telephone
8.80
5.60
0.22
0.06
0.50
0.42
ambig.
notebook
4.60
0.40
0.03
0.01
0.92
0.32
fine-gr."
REFERENCES,0.5784215784215784,"stopwatch
digital watch
4.80
0.60
0.00
0.00
0.83
0.62
fine-gr."
REFERENCES,0.5794205794205795,"strawberry
trifle
4.40
1.40
0.06
0.03
0.32
0.40
co-occur."
REFERENCES,0.5804195804195804,"trimaran
catamaran
4.80
1.40
0.18
0.09
0.92
0.60
fine-gr."
REFERENCES,0.5814185814185814,"digital clock
digital watch
3.00
7.00
0.02
0.01
0.83
0.71
fine-gr."
REFERENCES,0.5824175824175825,"hair slide
necklace
5.60
0.60
0.00
0.00
0.50
0.42
fine-gr."
REFERENCES,0.5834165834165834,"hook
necklace
3.60
0.00
0.00
0.00
0.53
0.33
unrelated"
REFERENCES,0.5844155844155844,"backpack
purse
3.00
0.00
0.02
0.01
0.89
0.56
fine-gr."
REFERENCES,0.5854145854145855,"home theater
monitor
2.80
0.00
0.03
0.00
0.56
0.18
co-occur. 20 40"
REFERENCES,0.5864135864135864,# mistakes 10 20 30 0 20 40 10 20 30 10 20 30 10 20 30
REFERENCES,0.5874125874125874,# mistakes 15 20 25 20 40 10 20 30 10 20 10 20
REFERENCES,0.5884115884115884,# mistakes 10 20 20 30 20 30 20 25 30 5 10 15
REFERENCES,0.5894105894105894,# mistakes 15 20 25 20 25 30 35 5 10 15 10 20 10 15 20
REFERENCES,0.5904095904095904,# mistakes 20 40 5 10 15 10 20 10 15 20 10 15
REFERENCES,0.5914085914085914,# mistakes 15 20 25 10 20 30 15 20 25 15 20 25 5 10
REFERENCES,0.5924075924075924,# mistakes 15 20 25 30 10 15 20 5 10 15 10 15 10 15
REFERENCES,0.5934065934065934,# mistakes 10 20 30 40 5 10 15 20 10 15 20 10 20 10 15 20
REFERENCES,0.5944055944055944,# mistakes 5.0 7.5 10.0 12.5 10 20 20 25 10.0 12.5 15.0
REFERENCES,0.5954045954045954,"25
50
75
100"
REFERENCES,0.5964035964035964,RRC scale lower bound s 10 15 20
REFERENCES,0.5974025974025974,# mistakes
REFERENCES,0.5984015984015985,"25
50
75
100"
REFERENCES,0.5994005994005994,RRC scale lower bound s 20 30
REFERENCES,0.6003996003996004,"25
50
75
100"
REFERENCES,0.6013986013986014,RRC scale lower bound s 5 10
REFERENCES,0.6023976023976024,"original IN label
ReaL labels"
REFERENCES,0.6033966033966034,"25
50
75
100"
REFERENCES,0.6043956043956044,RRC scale lower bound s 10 15
REFERENCES,0.6053946053946054,"25
50
75
100"
REFERENCES,0.6063936063936064,RRC scale lower bound s 5 10 15
REFERENCES,0.6073926073926074,"stage
∆FP or = 28, ∆FP ReaL = 11"
REFERENCES,0.6083916083916084,"purse
∆FP or = 23, ∆FP ReaL = 15"
REFERENCES,0.6093906093906094,"desktop computer
∆FP or = 15, ∆FP ReaL = 1"
REFERENCES,0.6103896103896104,"altar
∆FP or = 14, ∆FP ReaL = 9"
REFERENCES,0.6113886113886113,"cowboy hat
∆FP or = 12, ∆FP ReaL = 8"
REFERENCES,0.6123876123876124,"bathtub
∆FP or = 12, ∆FP ReaL = 6"
REFERENCES,0.6133866133866134,"pitcher
∆FP or = 11, ∆FP ReaL = 9"
REFERENCES,0.6143856143856143,"necklace
∆FP or = 11, ∆FP ReaL = 4"
REFERENCES,0.6153846153846154,"barbershop
∆FP or = 11, ∆FP ReaL = 9"
REFERENCES,0.6163836163836164,"restaurant
∆FP or = 11, ∆FP ReaL = 5"
REFERENCES,0.6173826173826173,"church
∆FP or = 11, ∆FP ReaL = 6"
REFERENCES,0.6183816183816184,"mortarboard
∆FP or = 11, ∆FP ReaL = 3"
REFERENCES,0.6193806193806194,"radio
∆FP or = 11, ∆FP ReaL = 4"
REFERENCES,0.6203796203796204,"miniskirt
∆FP or = 10, ∆FP ReaL = 10"
REFERENCES,0.6213786213786214,"wok
∆FP or = 10, ∆FP ReaL = 8"
REFERENCES,0.6223776223776224,"groom
∆FP or = 10, ∆FP ReaL = 9"
REFERENCES,0.6233766233766234,"breakwater
∆FP or = 10, ∆FP ReaL = 11"
REFERENCES,0.6243756243756243,"rubber eraser
∆FP or = 10, ∆FP ReaL = 6"
REFERENCES,0.6253746253746254,"castle
∆FP or = 9, ∆FP ReaL = 5"
REFERENCES,0.6263736263736264,"plate
∆FP or = 9, ∆FP ReaL = 0"
REFERENCES,0.6273726273726273,"vacuum
∆FP or = 9, ∆FP ReaL = 6"
REFERENCES,0.6283716283716284,"notebook
∆FP or = 9, ∆FP ReaL = 1"
REFERENCES,0.6293706293706294,"Dutch oven
∆FP or = 9, ∆FP ReaL = 8"
REFERENCES,0.6303696303696303,"pillow
∆FP or = 9, ∆FP ReaL = 7"
REFERENCES,0.6313686313686314,"fountain
∆FP or = 9, ∆FP ReaL = 6"
REFERENCES,0.6323676323676324,"tricycle
∆FP or = 8, ∆FP ReaL = 10"
REFERENCES,0.6333666333666333,"crutch
∆FP or = 8, ∆FP ReaL = 7"
REFERENCES,0.6343656343656343,"laptop
∆FP or = 8, ∆FP ReaL = 1"
REFERENCES,0.6353646353646354,"tray
∆FP or = 8, ∆FP ReaL = 3"
REFERENCES,0.6363636363636364,"bookshop
∆FP or = 8, ∆FP ReaL = 5"
REFERENCES,0.6373626373626373,"entertainment center
∆FP or = 8, ∆FP ReaL = 2"
REFERENCES,0.6383616383616384,"grocery store
∆FP or = 8, ∆FP ReaL = 4"
REFERENCES,0.6393606393606394,"ice lolly
∆FP or = 8, ∆FP ReaL = 6"
REFERENCES,0.6403596403596403,"iPod
∆FP or = 8, ∆FP ReaL = 8"
REFERENCES,0.6413586413586414,"unicycle
∆FP or = 8, ∆FP ReaL = 7"
REFERENCES,0.6423576423576424,"patio
∆FP or = 7, ∆FP ReaL = 8"
REFERENCES,0.6433566433566433,"monitor
∆FP or = 7, ∆FP ReaL = 1"
REFERENCES,0.6443556443556444,"garden spider
∆FP or = 7, ∆FP ReaL = 6"
REFERENCES,0.6453546453546454,"ram
∆FP or = 7, ∆FP ReaL = 9"
REFERENCES,0.6463536463536463,"bikini
∆FP or = 7, ∆FP ReaL = 3"
REFERENCES,0.6473526473526473,"soup bowl
∆FP or = 7, ∆FP ReaL = 5"
REFERENCES,0.6483516483516484,"pickup
∆FP or = 7, ∆FP ReaL = 5"
REFERENCES,0.6493506493506493,"cup
∆FP or = 7, ∆FP ReaL = 2"
REFERENCES,0.6503496503496503,"medicine chest
∆FP or = 6, ∆FP ReaL = 7"
REFERENCES,0.6513486513486514,"convertible
∆FP or = 6, ∆FP ReaL = 4"
REFERENCES,0.6523476523476524,"sandal
∆FP or = 6, ∆FP ReaL = 4"
REFERENCES,0.6533466533466533,"green lizard
∆FP or = 6, ∆FP ReaL = 5"
REFERENCES,0.6543456543456544,"ringneck snake
∆FP or = 6, ∆FP ReaL = 3"
REFERENCES,0.6553446553446554,"backpack
∆FP or = 6, ∆FP ReaL = 3"
REFERENCES,0.6563436563436563,"shoe shop
∆FP or = 6, ∆FP ReaL = 5"
REFERENCES,0.6573426573426573,stronger augmentation
REFERENCES,0.6583416583416584,"Figure 8: The number of per-class False Positive (FP) mistakes for the set of classes where FP
computed with original labels increases the most when using strong data augmentation. We show the
trends using both original and ReaL labels. 10 20 30"
REFERENCES,0.6593406593406593,# mistakes 20 40 15 20 25 20 30 10 15 10 20 30
REFERENCES,0.6603396603396603,# mistakes 5 10 15 15 20 25 10 15 20 10 20 30 15 20 25
REFERENCES,0.6613386613386614,# mistakes 5 10 15 10 20 30 20 25 30 5 10 15 10 15
REFERENCES,0.6623376623376623,# mistakes 20 25 10 20 10 15 15 20 25 10 15 20
REFERENCES,0.6633366633366633,# mistakes 10 15 20 10 15 20 5 10 15 20 10 20 30 20 25 30 35
REFERENCES,0.6643356643356644,# mistakes 10 20 12.5 15.0 17.5 8 10 12 14 5.0 7.5 10.0 12.5 20 30
REFERENCES,0.6653346653346653,# mistakes 5 10 15 15 20 25 5 10 15 12.5 15.0 17.5 20.0 10 15 20
REFERENCES,0.6663336663336663,# mistakes 8 10 12 14 5.0 7.5 10.0 10.0 12.5 15.0 15 20 25 10 20
REFERENCES,0.6673326673326674,# mistakes 10 15 20 2.5 5.0 7.5 10.0 10 15 20 25 15.0 17.5 20.0
REFERENCES,0.6683316683316683,"25
50
75
100"
REFERENCES,0.6693306693306693,RRC scale lower bound s 4 6 8
REFERENCES,0.6703296703296703,# mistakes
REFERENCES,0.6713286713286714,"25
50
75
100"
REFERENCES,0.6723276723276723,RRC scale lower bound s 15 20 25 30
REFERENCES,0.6733266733266733,"25
50
75
100"
REFERENCES,0.6743256743256744,RRC scale lower bound s 7.5 10.0 12.5
REFERENCES,0.6753246753246753,"original IN label
ReaL labels"
REFERENCES,0.6763236763236763,"25
50
75
100"
REFERENCES,0.6773226773226774,RRC scale lower bound s 10.0 12.5 15.0
REFERENCES,0.6783216783216783,"25
50
75
100"
REFERENCES,0.6793206793206793,RRC scale lower bound s 15 20
REFERENCES,0.6803196803196803,"purse
∆FP or = 23, ∆FP ReaL = 15"
REFERENCES,0.6813186813186813,"stage
∆FP or = 28, ∆FP ReaL = 11"
REFERENCES,0.6823176823176823,"breakwater
∆FP or = 10, ∆FP ReaL = 11"
REFERENCES,0.6833166833166833,"miniskirt
∆FP or = 10, ∆FP ReaL = 10"
REFERENCES,0.6843156843156843,"tricycle
∆FP or = 8, ∆FP ReaL = 10"
REFERENCES,0.6853146853146853,"barbershop
∆FP or = 11, ∆FP ReaL = 9"
REFERENCES,0.6863136863136863,"groom
∆FP or = 10, ∆FP ReaL = 9"
REFERENCES,0.6873126873126874,"pitcher
∆FP or = 11, ∆FP ReaL = 9"
REFERENCES,0.6883116883116883,"ram
∆FP or = 7, ∆FP ReaL = 9"
REFERENCES,0.6893106893106893,"altar
∆FP or = 14, ∆FP ReaL = 9"
REFERENCES,0.6903096903096904,"home theater
∆FP or = 5, ∆FP ReaL = 8"
REFERENCES,0.6913086913086913,"Dutch oven
∆FP or = 9, ∆FP ReaL = 8"
REFERENCES,0.6923076923076923,"cowboy hat
∆FP or = 12, ∆FP ReaL = 8"
REFERENCES,0.6933066933066933,"wok
∆FP or = 10, ∆FP ReaL = 8"
REFERENCES,0.6943056943056943,"iPod
∆FP or = 8, ∆FP ReaL = 8"
REFERENCES,0.6953046953046953,"patio
∆FP or = 7, ∆FP ReaL = 8"
REFERENCES,0.6963036963036963,"medicine chest
∆FP or = 6, ∆FP ReaL = 7"
REFERENCES,0.6973026973026973,"pillow
∆FP or = 9, ∆FP ReaL = 7"
REFERENCES,0.6983016983016983,"unicycle
∆FP or = 8, ∆FP ReaL = 7"
REFERENCES,0.6993006993006993,"crutch
∆FP or = 8, ∆FP ReaL = 7"
REFERENCES,0.7002997002997003,"vacuum
∆FP or = 9, ∆FP ReaL = 6"
REFERENCES,0.7012987012987013,"ice lolly
∆FP or = 8, ∆FP ReaL = 6"
REFERENCES,0.7022977022977023,"fountain
∆FP or = 9, ∆FP ReaL = 6"
REFERENCES,0.7032967032967034,"garden spider
∆FP or = 7, ∆FP ReaL = 6"
REFERENCES,0.7042957042957043,"bathtub
∆FP or = 12, ∆FP ReaL = 6"
REFERENCES,0.7052947052947053,"rubber eraser
∆FP or = 10, ∆FP ReaL = 6"
REFERENCES,0.7062937062937062,"church
∆FP or = 11, ∆FP ReaL = 6"
REFERENCES,0.7072927072927073,"bonnet
∆FP or = 5, ∆FP ReaL = 6"
REFERENCES,0.7082917082917083,"cinema
∆FP or = 4, ∆FP ReaL = 5"
REFERENCES,0.7092907092907093,"pickup
∆FP or = 7, ∆FP ReaL = 5"
REFERENCES,0.7102897102897103,"green lizard
∆FP or = 6, ∆FP ReaL = 5"
REFERENCES,0.7112887112887113,"castle
∆FP or = 9, ∆FP ReaL = 5"
REFERENCES,0.7122877122877123,"coﬀeepot
∆FP or = 5, ∆FP ReaL = 5"
REFERENCES,0.7132867132867133,"shoe shop
∆FP or = 6, ∆FP ReaL = 5"
REFERENCES,0.7142857142857143,"confectionery
∆FP or = 5, ∆FP ReaL = 5"
REFERENCES,0.7152847152847153,"saltshaker
∆FP or = 5, ∆FP ReaL = 5"
REFERENCES,0.7162837162837162,"miniature pinscher
∆FP or = 5, ∆FP ReaL = 5"
REFERENCES,0.7172827172827173,"Polaroid camera
∆FP or = 5, ∆FP ReaL = 5"
REFERENCES,0.7182817182817183,"shopping basket
∆FP or = 6, ∆FP ReaL = 5"
REFERENCES,0.7192807192807192,"bookshop
∆FP or = 8, ∆FP ReaL = 5"
REFERENCES,0.7202797202797203,"restaurant
∆FP or = 11, ∆FP ReaL = 5"
REFERENCES,0.7212787212787213,"soup bowl
∆FP or = 7, ∆FP ReaL = 5"
REFERENCES,0.7222777222777222,"horse cart
∆FP or = 6, ∆FP ReaL = 4"
REFERENCES,0.7232767232767233,"shield
∆FP or = 4, ∆FP ReaL = 4"
REFERENCES,0.7242757242757243,"malamute
∆FP or = 4, ∆FP ReaL = 4"
REFERENCES,0.7252747252747253,"crossword puzzle
∆FP or = 4, ∆FP ReaL = 4"
REFERENCES,0.7262737262737263,"grocery store
∆FP or = 8, ∆FP ReaL = 4"
REFERENCES,0.7272727272727273,"tow truck
∆FP or = 4, ∆FP ReaL = 4"
REFERENCES,0.7282717282717283,"swing
∆FP or = 3, ∆FP ReaL = 4"
REFERENCES,0.7292707292707292,"bucket
∆FP or = 4, ∆FP ReaL = 4"
REFERENCES,0.7302697302697303,stronger augmentation
REFERENCES,0.7312687312687313,"Figure 9: The number of per-class False Positive (FP) mistakes for the set of classes where FP
computed with ReaL labels increases the most when using strong data augmentation. We show the
trends using both original and ReaL labels."
REFERENCES,0.7322677322677322,Table 3: Class-conditional augmentation intervention using ReaL labels.
REFERENCES,0.7332667332667333,"# classes with
adapted aug.
ReaL
avg acc
ReaL avg acc of
50 aff. classes
ReaL avg acc of
remaining 950 classes"
REFERENCES,0.7342657342657343,"m = 0
83.70±0.01
70.66±0.08
84.00±0.01
m = 10
83.63±0.01
72.01±0.04
83.86±0.01
m = 30
83.64±0.01
72.28±0.05
83.86±0.01
m = 50
83.57±0.01
72.20±0.03
83.78±0.01"
REFERENCES,0.7352647352647352,"We also experimented with fine-tuning the model from the checkpoint trained with the strongest
augmentation s = 8% using either regular augmentation policy which was used during training or
class-conditional policy with augmentation strength changed for k = 10 classes as in Section 6: we
fine-tuned the model for 5 epochs with linearly decaying learning rate starting from the value 10−4.
However, both regular and class-conditional DA lead to slight drop in average accuracy on all classes
(from 76.79% to 76.73% for either DA) and in particular the accuracy dropped more significantly
for negatively affected classes: from 53.93% to 53.4%. We hypothesize that this is due to model
memorizing train examples so even class-conditional augmentation policy is not able to recover
performance on the affected classes if we re-use the same data for fine-tuning. In the future analysis,
we will explore whether it is possible to alleviate DA bias if we fine-tune the model from an earlier
checkpoint as opposed to fully trained model or if we use additional held-out data for fine-tuning."
REFERENCES,0.7362637362637363,"F
Additional architecture results: EfficientNet and ViT"
REFERENCES,0.7372627372627373,"In Figures 10 and 11 we show the per-class accuracy trends for classes most affected in original and
ReaL accuracy of EfficientNet-B0 [61] model, trained using a similar setup to the main ResNet-50
model (see Section A). We can see that many affected classes are the same for ResNet-50 and
EfficientNet models."
REFERENCES,0.7382617382617382,"We also train a Vision Transformer model ViT-S [58, 65] varying the RRC scale lower bound in the
range s ∈{10%, 20%, . . . , 90%} and report the results in Figure 12. Generally, we confirm that
our observations hold for ViT. While the optimal average accuracy is obtained with the strongest
augmentation, for several classes accuracy significantly degrades. Evaluation with multi-label
annotations reveals that some of the confusions are due to inherent label ambiguity or class overlap.
We also identify the same high-level class confusion categorized as ambiguous, co-occurring, fine-
grained and semantically unrelated (see Fig 13). By conducting a data augmentation intervention from
Section 6 of the paper and changing the RRC augmentation strength for just 10 classes, we improve
the accuracy on the degraded classes by over 3% (from 52.28% ± 0.18% to 55.49% ± 0.07%). 60 70 80"
REFERENCES,0.7392607392607392,validation acc (%) 40 50 60 70 40 50 60 50 60 70 40 50 60 70 60 70
REFERENCES,0.7402597402597403,validation acc (%) 50 60 20 40 60 40 50 20 40 60 40 50 60 70
REFERENCES,0.7412587412587412,validation acc (%) 40 60 30 40 50 35 40 45 60 65 70 75 20 30
REFERENCES,0.7422577422577422,validation acc (%) 40 50 60 70 20 30 40 65 70 75 50 55 60 40 50 60
REFERENCES,0.7432567432567433,validation acc (%) 20 30 40 50 60 70 80 60 65 70 60 70 40 50
REFERENCES,0.7442557442557443,validation acc (%) 50 60 70 75 80 85 30 40 70 75 80 40 50
REFERENCES,0.7452547452547452,validation acc (%) 60 70 80 60 70 80 50 55 60 65 30 40 50 50 60 70
REFERENCES,0.7462537462537463,validation acc (%) 50 60 70 60 70 80 40 50 60 70 40 50 60 30 40 50
REFERENCES,0.7472527472527473,validation acc (%) 60 70 50 60 70 50 60 70 40 50 60 70
REFERENCES,0.7482517482517482,"25
50
75
100"
REFERENCES,0.7492507492507493,RRC scale lower bound s 60 70 80
REFERENCES,0.7502497502497503,validation acc (%)
REFERENCES,0.7512487512487512,"25
50
75
100"
REFERENCES,0.7522477522477522,RRC scale lower bound s 40 45 50
REFERENCES,0.7532467532467533,"25
50
75
100"
REFERENCES,0.7542457542457542,RRC scale lower bound s 40 50 60
REFERENCES,0.7552447552447552,"original IN label
ReaL labels"
REFERENCES,0.7562437562437563,"25
50
75
100"
REFERENCES,0.7572427572427572,RRC scale lower bound s 50 55 60 65
REFERENCES,0.7582417582417582,"25
50
75
100"
REFERENCES,0.7592407592407593,RRC scale lower bound s 10 20 30 40
REFERENCES,0.7602397602397603,"green mamba
∆aor = 22, ∆aReaL = 19"
REFERENCES,0.7612387612387612,"barn spider
∆aor = 20, ∆aReaL = 4"
REFERENCES,0.7622377622377622,"black-and-tan coonhound
∆aor = 18, ∆aReaL = 14"
REFERENCES,0.7632367632367633,"bulletproof vest
∆aor = 17, ∆aReaL = 14"
REFERENCES,0.7642357642357642,"paper towel
∆aor = 17, ∆aReaL = 9"
REFERENCES,0.7652347652347652,"Band Aid
∆aor = 16, ∆aReaL = 14"
REFERENCES,0.7662337662337663,"horned viper
∆aor = 16, ∆aReaL = 8"
REFERENCES,0.7672327672327672,"sunglass
∆aor = 16, ∆aReaL = 15"
REFERENCES,0.7682317682317682,"dumbbell
∆aor = 15, ∆aReaL = 15"
REFERENCES,0.7692307692307693,"Windsor tie
∆aor = 15, ∆aReaL = 11"
REFERENCES,0.7702297702297702,"passenger car
∆aor = 15, ∆aReaL = 2"
REFERENCES,0.7712287712287712,"maillot
∆aor = 15, ∆aReaL = 6"
REFERENCES,0.7722277722277723,"cassette player
∆aor = 14, ∆aReaL = 8"
REFERENCES,0.7732267732267732,"stole
∆aor = 14, ∆aReaL = 11"
REFERENCES,0.7742257742257742,"bighorn
∆aor = 14, ∆aReaL = 12"
REFERENCES,0.7752247752247752,"cleaver
∆aor = 14, ∆aReaL = 12"
REFERENCES,0.7762237762237763,"muzzle
∆aor = 14, ∆aReaL = 9"
REFERENCES,0.7772227772227772,"spatula
∆aor = 13, ∆aReaL = 13"
REFERENCES,0.7782217782217782,"redbone
∆aor = 13, ∆aReaL = 7"
REFERENCES,0.7792207792207793,"umbrella
∆aor = 13, ∆aReaL = 12"
REFERENCES,0.7802197802197802,"Siberian husky
∆aor = 13, ∆aReaL = 11"
REFERENCES,0.7812187812187812,"screwdriver
∆aor = 12, ∆aReaL = 12"
REFERENCES,0.7822177822177823,"otterhound
∆aor = 12, ∆aReaL = 11"
REFERENCES,0.7832167832167832,"bell cote
∆aor = 12, ∆aReaL = 2"
REFERENCES,0.7842157842157842,"EntleBucher
∆aor = 12, ∆aReaL = 5"
REFERENCES,0.7852147852147852,"chime
∆aor = 12, ∆aReaL = 13"
REFERENCES,0.7862137862137862,"hand-held computer
∆aor = 12, ∆aReaL = 4"
REFERENCES,0.7872127872127872,"black stork
∆aor = 12, ∆aReaL = 8"
REFERENCES,0.7882117882117882,"hatchet
∆aor = 12, ∆aReaL = 12"
REFERENCES,0.7892107892107892,"fox squirrel
∆aor = 12, ∆aReaL = 12"
REFERENCES,0.7902097902097902,"wooden spoon
∆aor = 12, ∆aReaL = 12"
REFERENCES,0.7912087912087912,"bannister
∆aor = 12, ∆aReaL = 12"
REFERENCES,0.7922077922077922,"corkscrew
∆aor = 11, ∆aReaL = 13"
REFERENCES,0.7932067932067932,"brassiere
∆aor = 11, ∆aReaL = 9"
REFERENCES,0.7942057942057942,"plunger
∆aor = 11, ∆aReaL = 11"
REFERENCES,0.7952047952047953,"assault riﬂe
∆aor = 11, ∆aReaL = 8"
REFERENCES,0.7962037962037962,"chocolate sauce
∆aor = 11, ∆aReaL = 5"
REFERENCES,0.7972027972027972,"cucumber
∆aor = 11, ∆aReaL = 11"
REFERENCES,0.7982017982017982,"Irish wolfhound
∆aor = 11, ∆aReaL = 8"
REFERENCES,0.7992007992007992,"moving van
∆aor = 11, ∆aReaL = 9"
REFERENCES,0.8001998001998002,"rock python
∆aor = 11, ∆aReaL = 12"
REFERENCES,0.8011988011988012,"face powder
∆aor = 11, ∆aReaL = 12"
REFERENCES,0.8021978021978022,"acoustic guitar
∆aor = 11, ∆aReaL = 11"
REFERENCES,0.8031968031968032,"cornet
∆aor = 11, ∆aReaL = 11"
REFERENCES,0.8041958041958042,"hognose snake
∆aor = 11, ∆aReaL = 14"
REFERENCES,0.8051948051948052,"goose
∆aor = 10, ∆aReaL = 8"
REFERENCES,0.8061938061938062,"binoculars
∆aor = 10, ∆aReaL = 11"
REFERENCES,0.8071928071928072,"tow truck
∆aor = 10, ∆aReaL = 10"
REFERENCES,0.8081918081918081,"whistle
∆aor = 10, ∆aReaL = 8"
REFERENCES,0.8091908091908092,"hook
∆aor = 10, ∆aReaL = 12"
REFERENCES,0.8101898101898102,stronger augmentation
REFERENCES,0.8111888111888111,"Figure 10: Per-class class validation accuracies of EfficientNet-B0 trained on ImageNet computed
with original and ReaL labels as a function of Random Resized Crop data augmentation scale lower
bound s. We show the accuracy trends for the classes with the highest difference between the
maximum accuracy on that class across augmentation levels maxs aor
k (s) and the accuracy of the
model trained with s = 8%. On each subplot below the name of the class we show the accuracy
drops with respect to original and ReaL labels: ∆aor
k and ∆aReaL
k
. 60 70 80"
REFERENCES,0.8121878121878122,validation acc (%) 40 50 60 70 40 50 60 50 60 70 40 50 60 70 60 70
REFERENCES,0.8131868131868132,validation acc (%) 50 60 20 40 60 40 50 20 40 60 40 50 60 70
REFERENCES,0.8141858141858141,validation acc (%) 40 60 30 40 50 35 40 45 60 65 70 75 20 30
REFERENCES,0.8151848151848152,validation acc (%) 40 50 60 70 20 30 40 65 70 75 50 55 60 40 50 60
REFERENCES,0.8161838161838162,validation acc (%) 20 30 40 50 60 70 80 60 65 70 60 70 40 50
REFERENCES,0.8171828171828172,validation acc (%) 50 60 70 75 80 85 30 40 70 75 80 40 50
REFERENCES,0.8181818181818182,validation acc (%) 60 70 80 60 70 80 50 55 60 65 30 40 50 50 60 70
REFERENCES,0.8191808191808192,validation acc (%) 50 60 70 60 70 80 40 50 60 70 40 50 60 30 40 50
REFERENCES,0.8201798201798202,validation acc (%) 60 70 50 60 70 50 60 70 40 50 60 70
REFERENCES,0.8211788211788211,"25
50
75
100"
REFERENCES,0.8221778221778222,RRC scale lower bound s 60 70 80
REFERENCES,0.8231768231768232,validation acc (%)
REFERENCES,0.8241758241758241,"25
50
75
100"
REFERENCES,0.8251748251748252,RRC scale lower bound s 40 45 50
REFERENCES,0.8261738261738262,"25
50
75
100"
REFERENCES,0.8271728271728271,RRC scale lower bound s 40 50 60
REFERENCES,0.8281718281718282,"original IN label
ReaL labels"
REFERENCES,0.8291708291708292,"25
50
75
100"
REFERENCES,0.8301698301698301,RRC scale lower bound s 50 55 60 65
REFERENCES,0.8311688311688312,"25
50
75
100"
REFERENCES,0.8321678321678322,RRC scale lower bound s 10 20 30 40
REFERENCES,0.8331668331668332,"green mamba
∆aor = 22, ∆aReaL = 19"
REFERENCES,0.8341658341658341,"barn spider
∆aor = 20, ∆aReaL = 4"
REFERENCES,0.8351648351648352,"black-and-tan coonhound
∆aor = 18, ∆aReaL = 14"
REFERENCES,0.8361638361638362,"bulletproof vest
∆aor = 17, ∆aReaL = 14"
REFERENCES,0.8371628371628371,"paper towel
∆aor = 17, ∆aReaL = 9"
REFERENCES,0.8381618381618382,"Band Aid
∆aor = 16, ∆aReaL = 14"
REFERENCES,0.8391608391608392,"horned viper
∆aor = 16, ∆aReaL = 8"
REFERENCES,0.8401598401598401,"sunglass
∆aor = 16, ∆aReaL = 15"
REFERENCES,0.8411588411588412,"dumbbell
∆aor = 15, ∆aReaL = 15"
REFERENCES,0.8421578421578422,"Windsor tie
∆aor = 15, ∆aReaL = 11"
REFERENCES,0.8431568431568431,"passenger car
∆aor = 15, ∆aReaL = 2"
REFERENCES,0.8441558441558441,"maillot
∆aor = 15, ∆aReaL = 6"
REFERENCES,0.8451548451548452,"cassette player
∆aor = 14, ∆aReaL = 8"
REFERENCES,0.8461538461538461,"stole
∆aor = 14, ∆aReaL = 11"
REFERENCES,0.8471528471528471,"bighorn
∆aor = 14, ∆aReaL = 12"
REFERENCES,0.8481518481518482,"cleaver
∆aor = 14, ∆aReaL = 12"
REFERENCES,0.8491508491508492,"muzzle
∆aor = 14, ∆aReaL = 9"
REFERENCES,0.8501498501498501,"spatula
∆aor = 13, ∆aReaL = 13"
REFERENCES,0.8511488511488512,"redbone
∆aor = 13, ∆aReaL = 7"
REFERENCES,0.8521478521478522,"umbrella
∆aor = 13, ∆aReaL = 12"
REFERENCES,0.8531468531468531,"Siberian husky
∆aor = 13, ∆aReaL = 11"
REFERENCES,0.8541458541458542,"screwdriver
∆aor = 12, ∆aReaL = 12"
REFERENCES,0.8551448551448552,"otterhound
∆aor = 12, ∆aReaL = 11"
REFERENCES,0.8561438561438561,"bell cote
∆aor = 12, ∆aReaL = 2"
REFERENCES,0.8571428571428571,"EntleBucher
∆aor = 12, ∆aReaL = 5"
REFERENCES,0.8581418581418582,"chime
∆aor = 12, ∆aReaL = 13"
REFERENCES,0.8591408591408591,"hand-held computer
∆aor = 12, ∆aReaL = 4"
REFERENCES,0.8601398601398601,"black stork
∆aor = 12, ∆aReaL = 8"
REFERENCES,0.8611388611388612,"hatchet
∆aor = 12, ∆aReaL = 12"
REFERENCES,0.8621378621378621,"fox squirrel
∆aor = 12, ∆aReaL = 12"
REFERENCES,0.8631368631368631,"wooden spoon
∆aor = 12, ∆aReaL = 12"
REFERENCES,0.8641358641358642,"bannister
∆aor = 12, ∆aReaL = 12"
REFERENCES,0.8651348651348651,"corkscrew
∆aor = 11, ∆aReaL = 13"
REFERENCES,0.8661338661338661,"brassiere
∆aor = 11, ∆aReaL = 9"
REFERENCES,0.8671328671328671,"plunger
∆aor = 11, ∆aReaL = 11"
REFERENCES,0.8681318681318682,"assault riﬂe
∆aor = 11, ∆aReaL = 8"
REFERENCES,0.8691308691308691,"chocolate sauce
∆aor = 11, ∆aReaL = 5"
REFERENCES,0.8701298701298701,"cucumber
∆aor = 11, ∆aReaL = 11"
REFERENCES,0.8711288711288712,"Irish wolfhound
∆aor = 11, ∆aReaL = 8"
REFERENCES,0.8721278721278721,"moving van
∆aor = 11, ∆aReaL = 9"
REFERENCES,0.8731268731268731,"rock python
∆aor = 11, ∆aReaL = 12"
REFERENCES,0.8741258741258742,"face powder
∆aor = 11, ∆aReaL = 12"
REFERENCES,0.8751248751248751,"acoustic guitar
∆aor = 11, ∆aReaL = 11"
REFERENCES,0.8761238761238761,"cornet
∆aor = 11, ∆aReaL = 11"
REFERENCES,0.8771228771228772,"hognose snake
∆aor = 11, ∆aReaL = 14"
REFERENCES,0.8781218781218781,"goose
∆aor = 10, ∆aReaL = 8"
REFERENCES,0.8791208791208791,"binoculars
∆aor = 10, ∆aReaL = 11"
REFERENCES,0.8801198801198801,"tow truck
∆aor = 10, ∆aReaL = 10"
REFERENCES,0.8811188811188811,"whistle
∆aor = 10, ∆aReaL = 8"
REFERENCES,0.8821178821178821,"hook
∆aor = 10, ∆aReaL = 12"
REFERENCES,0.8831168831168831,stronger augmentation
REFERENCES,0.8841158841158842,"Figure 11: Per-class class validation accuracies of EfficientNet-B0 trained on ImageNet computed
with original and ReaL labels as a function of Random Resized Crop data augmentation scale
lower bound s. We show the accuracy trends for the classes with the highest difference between
the maximum ReaL accuracy on that class across augmentation levels maxs aor
k (s) and the ReaL
accuracy of the model trained with s = 8%. On each subplot below the name of the class we show
the accuracy drops with respect to original and ReaL labels: ∆aor
k and ∆aReaL
k
. 65 70 75"
REFERENCES,0.8851148851148851,validation acc (%) 65 70 75 55 60 65
REFERENCES,0.8861138861138861,"20
40
60
80
RRC scale lower bound s 30 40 50"
REFERENCES,0.8871128871128872,validation acc (%)
REFERENCES,0.8881118881118881,"20
40
60
80
RRC scale lower bound s 60 70 80"
REFERENCES,0.8891108891108891,"20
40
60
80
RRC scale lower bound s 60 70 80"
REFERENCES,0.8901098901098901,"Avg of all IN classes
∆aor = 0, ∆aReaL = 0"
REFERENCES,0.8911088911088911,"Avg of 950 IN classes
∆aor = 0, ∆aReaL = 0"
REFERENCES,0.8921078921078921,"Avg of 50 IN classes
∆aor = 4, ∆aReaL = 2"
REFERENCES,0.8931068931068931,"Windsor tie
∆aor = 13, ∆aReaL = 2"
REFERENCES,0.8941058941058941,"honeycomb
∆aor = 11, ∆aReaL = 10"
REFERENCES,0.8951048951048951,"collie
∆aor = 11, ∆aReaL = 2"
REFERENCES,0.8961038961038961,"stronger augmentation
original
ReaL"
REFERENCES,0.8971028971028971,"Figure 12: ViT-S trained on ImageNet with varied Random Resized Crop (RRC) augmentation
strength. Average and per-class accuracy of ViT-S evaluated with original and ReaL labels as a
function of RRC augmentation strength. The top row shows the average accuracy of all classes, the 50
classes with the highest accuracy degradation and the remaining 950 classes. The bottom row shows
the accuracy of 3 classes most significantly affected in accuracy when using strong augmentation."
REFERENCES,0.8981018981018981,"Ambiguous
Co-occurring"
REFERENCES,0.8991008991008991,"Fine-grained
Semantically unrelated"
REFERENCES,0.9000999000999002,"20
40
60
80"
REFERENCES,0.9010989010989011,augmentation strength s 10 15 20 25 30
REFERENCES,0.9020979020979021,% of val examples
REFERENCES,0.903096903096903,predictions on “sunglass”
REFERENCES,0.9040959040959041,"sunglass
sunglasses"
REFERENCES,0.9050949050949051,"20
40
60
80"
REFERENCES,0.906093906093906,augmentation strength s 10 15 20 25 30 35
REFERENCES,0.9070929070929071,% of val examples
REFERENCES,0.9080919080919081,predictions on “sunglasses”
REFERENCES,0.9090909090909091,"sunglass
sunglasses"
REFERENCES,0.9100899100899101,"20
40
60
80"
REFERENCES,0.9110889110889111,augmentation strength s 15 20 25 30 35
REFERENCES,0.9120879120879121,% of val examples
REFERENCES,0.913086913086913,predictions on “Windsor tie”
REFERENCES,0.9140859140859141,"Windsor tie
suit"
REFERENCES,0.9150849150849151,"20
40
60
80"
REFERENCES,0.916083916083916,augmentation strength s 0 10 20 30 40 50
REFERENCES,0.9170829170829171,% of val examples
REFERENCES,0.9180819180819181,predictions on “suit”
REFERENCES,0.919080919080919,"Windsor tie
suit 30 35 40"
REFERENCES,0.9200799200799201,"45
predictions on “pitcher”"
REFERENCES,0.9210789210789211,"pitcher
teapot"
REFERENCES,0.922077922077922,"20
40
60
80"
REFERENCES,0.9230769230769231,augmentation strength s 12 14 16 18
REFERENCES,0.9240759240759241,% of val examples 60 70
REFERENCES,0.9250749250749251,"80
predictions on “teapot”"
REFERENCES,0.926073926073926,"pitcher
teapot"
REFERENCES,0.9270729270729271,"20
40
60
80"
REFERENCES,0.9280719280719281,augmentation strength s 0 2 4 6
REFERENCES,0.929070929070929,% of val examples 20 25 30 35
REFERENCES,0.9300699300699301,predictions on “ﬂute”
REFERENCES,0.9310689310689311,"ﬂute
riﬂe"
REFERENCES,0.932067932067932,"20
40
60
80"
REFERENCES,0.9330669330669331,augmentation strength s 0 2 4
REFERENCES,0.9340659340659341,% of val examples 30 35 40
REFERENCES,0.935064935064935,"45
predictions on “riﬂe”"
REFERENCES,0.936063936063936,"ﬂute
riﬂe"
REFERENCES,0.9370629370629371,"20
40
60
80"
REFERENCES,0.938061938061938,augmentation strength s 0 1 2 3
REFERENCES,0.939060939060939,% of val examples
REFERENCES,0.9400599400599401,"Figure 13: Class confusion types of ViT-S model trained on ImageNet with varied Random
Resized Crop (RRC) augmentation strength. Each panel shows a pair of confused classes which
we categorize into: ambiguous, co-occurring, fine-grained and semantically unrelated. For each
confused class pair, the left subplot corresponds to the class k affected in accuracy by strong data
augmentation (DA), e.g. “sunglass” on top left panel: the ratio of validation samples from that class
that get classified as k decreases with stronger DA, while the confusion rate with another class l (e.g.
class “sunglasses” on top left panel) increases. The right subplot shows the percent of examples from
class l that get classified as k or l against DA strength. Generally, we observe that for ViT-S the class
confusions which are exacerbated with stronger DA are similar to the ones of ResNet-50."
REFERENCES,0.9410589410589411,"G
Additional augmentation transformations and datasets"
REFERENCES,0.942057942057942,"G.1
Additional augmentation transformations"
REFERENCES,0.9430569430569431,"RandAugment
RandAugment [13] randomly applies color perturbations, translations and affine
transformations. We train ViT-S with the RRC s = 10% and vary the RandAugnment magnitude m
in the range {1, 3, . . . 9} (m = 9 is standard for ViT [58, 65]; values above m = 9 lead to significant
degradation in average accuracy). We report results in Fig 14. While RandAugment strength has
a smaller effect on accuracy than RRC, we still observe an increase of around 0.5% in average
performance with m = 9. However, that comes at the cost of about 4% accuracy drop for a minority
of classes. In Figure 14 we show examples of class confusions exacerbated by RandAugment, which
we can categorize analogously to Section 5."
REFERENCES,0.9440559440559441,"Colorjitter
We train a ResNet-50 using the strongest RRC augmentation with colorjitter applied
with probability 0.5 and intensity c = 0.1 for all parameters (brightness, contrast, saturation and hue).
Applying colorjitter with higher probability or intensity leads to degraded average accuracy while
colorjitter leads to a slight improvement of 0.1% in average accuracy. In Figure 15 we show the
distribution of accuracy improvements and degradations due to colorjitter, as well as the examples of
class confusions that were exacerbated."
REFERENCES,0.945054945054945,"G.2
Additional augmentation transformations and datasets"
REFERENCES,0.9460539460539461,"CIFAR-100 + mixup
We study mixup [73] augmentation for ResNet18 on CIFAR-100. We train
for 100 epochs using Random Crop, and mixup with α = 0.5 improves the average accuracy from
78.11 ± 0.15% to 78.53 ± 0.35% However, we observe degradations for some per-class accuracies
(see Figure 16). The exacerbated confusions are mainly within the same superclass categories of
CIFAR-100 which is aligned with our prior results on ImageNet where we observed that fine-grained
confusions are more significantly affected by augmentation."
REFERENCES,0.9470529470529471,"Flowers102
We study the effect of applying standard RRC in Flowers102 classification task, and
while using augmentation improves the average accuracy by 2%, we observe that some classes are
negatively affected (see Figure 16)."
REFERENCES,0.948051948051948,"H
Broader impact and limitations"
REFERENCES,0.949050949050949,"In our analysis we mainly focused on the setup of analyzing class-level accuracy drops of ResNet-50
model trained on ImageNet with varied Random Resized Crop (RRC) data augmentation. In Sections
F and G we confirm our observations on additional architectures (EfficientNet-B0 and ViT-S), data 70.0 70.5 71.0 71.5 72.0"
VIT-S ON IMAGENET,0.9500499500499501,"72.5
ViT-S on ImageNet"
VIT-S ON IMAGENET,0.951048951048951,"avg of all classes
avg of 950 classes
avg of 50 classes"
VIT-S ON IMAGENET,0.952047952047952,"1
2
3
4
5
6
7
8
9
52 54 56 58 60"
VIT-S ON IMAGENET,0.9530469530469531,validation accuracy (%)
VIT-S ON IMAGENET,0.954045954045954,RandAugment magnitude m 15 20 25
VIT-S ON IMAGENET,0.955044955044955,predictions on “velvet”
VIT-S ON IMAGENET,0.9560439560439561,"velvet
handkerchief"
VIT-S ON IMAGENET,0.957042957042957,"2
4
6
8
RandAugment magnitude m 0 2 4 6"
VIT-S ON IMAGENET,0.958041958041958,% of val examples 40 45 50
VIT-S ON IMAGENET,0.9590409590409591,"55
predictions on “envelope”"
VIT-S ON IMAGENET,0.9600399600399601,"envelope
binder"
VIT-S ON IMAGENET,0.961038961038961,"2
4
6
8
RandAugment magnitude m 0 2 4 6"
VIT-S ON IMAGENET,0.962037962037962,% of val examples
VIT-S ON IMAGENET,0.9630369630369631,"Figure 14:
Different augmentation types: RandAugment. ViT-S model trained on ImageNet
with varied RandAugment magnitude m (larger values of m correspond to stronger augmentation).
The left panel shows the average accuracy of all ImageNet classes, the 50 classes with the highest
accuracy degradation and the remaining 950 classes. The right panels show the examples of class
confusions which are exacerbated by stronger RandAugment augmentation."
VIT-S ON IMAGENET,0.964035964035964,"−5
0
5
10
Accuracy gap (%) 0 20 40 60 80 100 120 140"
VIT-S ON IMAGENET,0.965034965034965,# classes
VIT-S ON IMAGENET,0.9660339660339661,Distribution of per-class accuracy diﬀ. from colorjitter
VIT-S ON IMAGENET,0.967032967032967,"no colorjitter
colojitter 80 85 90"
VIT-S ON IMAGENET,0.968031968031968,% val examples
VIT-S ON IMAGENET,0.9690309690309691,pred: fountain pen
VIT-S ON IMAGENET,0.97002997002997,"no colorjitter
colojitter
2 4 6"
VIT-S ON IMAGENET,0.971028971028971,"8
pred: ballpoint pen
“fountain pen” val imgs"
VIT-S ON IMAGENET,0.972027972027972,"no colorjitter
colojitter 40 45 50"
VIT-S ON IMAGENET,0.973026973026973,% val examples
VIT-S ON IMAGENET,0.974025974025974,pred: spider monkey
VIT-S ON IMAGENET,0.975024975024975,"no colorjitter
colojitter
12 14 16"
VIT-S ON IMAGENET,0.9760239760239761,"18
pred: squirrel monkey
“spider monkey” val imgs"
VIT-S ON IMAGENET,0.977022977022977,"Figure 15:
Different augmentation type: colorjitter. Comparison of ResNet-50 trained on
ImageNet with Random Resized Crop s = 8% when using and not using colorjitter augmentation
(applied with probability p = 0.5 and intensity c = 0.1). The histogram shows per-class accuracy
changes when applying versus not applying colorjiter: most classes benefit from augmentation, while
a significant number of classes is negatively affected. The right panels show the examples of class
confusions exacerbated by applying colorjitter."
VIT-S ON IMAGENET,0.978021978021978,"−5
0
5
10
Accuracy gap (%) 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0"
VIT-S ON IMAGENET,0.9790209790209791,# classes
VIT-S ON IMAGENET,0.98001998001998,Distribution of per-class accuracy diﬀ. from mixup
VIT-S ON IMAGENET,0.981018981018981,"no colorjitter
colojitter
65 70 75"
VIT-S ON IMAGENET,0.9820179820179821,% val examples
VIT-S ON IMAGENET,0.983016983016983,pred: oak tree
VIT-S ON IMAGENET,0.984015984015984,"no mixup
mixup 10 15 20"
VIT-S ON IMAGENET,0.985014985014985,"pred: maple tree
pred: pine tree"
VIT-S ON IMAGENET,0.986013986013986,“oak tree” val imgs
VIT-S ON IMAGENET,0.987012987012987,"no colorjitter
colojitter 50 55 60"
VIT-S ON IMAGENET,0.988011988011988,% val examples
VIT-S ON IMAGENET,0.989010989010989,pred: otter
VIT-S ON IMAGENET,0.99000999000999,"no mixup
mixup 0 2 4"
VIT-S ON IMAGENET,0.991008991008991,"pred: chimpanzee
pred: whale"
VIT-S ON IMAGENET,0.9920079920079921,“otter” val imgs
VIT-S ON IMAGENET,0.993006993006993,"−5
0
5
10
Accuracy gap (%) 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0"
VIT-S ON IMAGENET,0.994005994005994,# classes
VIT-S ON IMAGENET,0.995004995004995,Distribution of per-class accuracy diﬀ. from RRC on Flowers102
VIT-S ON IMAGENET,0.996003996003996,"Figure 16:
Different datasets: CIFAR-100 and Flowers102. Left: The histogram shows per-
class accuracy changes when applying versus not applying mixup with α = 0.5 when training
on CIFAR-100. Middle: The examples of class confusions exacerbated by applying mixup on
CIFAR-100, the exacerbated confusions are mostly fine-grained and lie within CIFAR-100 super-
classes. Right: The histogram shows per-class accuracy changes when applying versus not applying
standard Random Resized Crop s = 8% when training ResNet-32 on Flowers102 dataset."
VIT-S ON IMAGENET,0.997002997002997,"augmentation transformations (RandAugment, mixup and colorjitter) and datasets (CIFAR-100 and
Flowers102). The same proposed framework can be extended to better understand the biases of other
augmentations, architectures and satasets in the future work. While we provide quantitative metrics
to describe each confusion type affected by data augmentation, the categorization is not strict due to
the remaining noise in ReaL labels and imprecise word similarity metrics."
VIT-S ON IMAGENET,0.998001998001998,"A potential negative outcome that can result from misinterpretation of our analysis in Section 4
is if the practitioners assume that data augmentation does not have any negative effects since we
discover that previously reported performance drops were overestimated due to label noise. We
emphasize that while some of the class-level accuracy drops were indeed due to label ambiguity or
co-occurring objects, data augmentation does exacerbate model’s bias and introduces class confusions
(often between fine-grained categories but sometimes even for semantically unrelated classes that
share visually similar features). We encourage researchers to carefully study the negative impact of
DA using fine-grained metrics beyond average accuracy (such as per-class accuracy, False Positive
mistakes and class confusions) to better understand its biases."
VIT-S ON IMAGENET,0.999000999000999,"Compute.
We estimate the total compute used in the process of working on this paper at roughly
5000 GPU hours. The compute usage is dominated by training models for different augmentation
strengths (Section 4). The experiments were run on GPU clusters on Nvidia Tesla V100, Titan RTX,
RTX8000, 3080 and 1080Ti GPUs."
