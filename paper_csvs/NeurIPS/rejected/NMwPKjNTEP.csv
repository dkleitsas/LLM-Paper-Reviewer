Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0008058017727639,"The electroencephalogram (EEG) based brain-computer interface (BCI) has taken
1"
ABSTRACT,0.0016116035455278,"the advantages of the tremendous success of deep learning (DL) models, gaining a
2"
ABSTRACT,0.0024174053182917004,"wide range of applications. However, DL models have been shown to be vulnerable
3"
ABSTRACT,0.0032232070910556,"to backdoor attacks. Although there are extensive successful attacks for image,
4"
ABSTRACT,0.0040290088638195,"designing a stealthy and effective attack for EEG is a non-trivial task. While
5"
ABSTRACT,0.004834810636583401,"existing EEG attacks mainly focus on single target class attack, and they either
6"
ABSTRACT,0.0056406124093473006,"require engaging the training stage of the target DL models, or fail to maintain
7"
ABSTRACT,0.0064464141821112,"high stealthiness. Addressing these limitations, we exploit a novel backdoor attack
8"
ABSTRACT,0.007252215954875101,"called ManiBCI, where the adversary can arbitrarily manipulate which target class
9"
ABSTRACT,0.008058017727639,"the EEG BCI will misclassify without engaging the training stage. Specifically,
10"
ABSTRACT,0.008863819500402902,"ManiBCI is a three-stages clean label poisoning attacks: 1) selecting one trigger
11"
ABSTRACT,0.009669621273166801,"for each class; 2) learning optimal injecting EEG electrodes and frequencies masks
12"
ABSTRACT,0.010475423045930701,"with reinforcement learning for each trigger; 3) injecting the corresponding trigger’s
13"
ABSTRACT,0.011281224818694601,"frequencies into poisoned data for each class by linearly interpolating the spectral
14"
ABSTRACT,0.012087026591458501,"amplitude of both data according to the learned masks. Experiments on three EEG
15"
ABSTRACT,0.0128928283642224,"datasets demonstrate the effectiveness and robustness of ManiBCI. The proposed
16"
ABSTRACT,0.0136986301369863,"ManiBCI also easily bypass existing backdoor defenses. Code will be published
17"
ABSTRACT,0.014504431909750202,"after the anonymous period.
18"
INTRODUCTION,0.015310233682514102,"1
Introduction
19"
INTRODUCTION,0.016116035455278,"Deep learning (DL) has greatly boosted the performances of the electroencephalogram (EEG) based
20"
INTRODUCTION,0.016921837228041903,"brain-computer interfaces (BCI), which have been widely used in medical diagnosis [1], healthcare
21"
INTRODUCTION,0.017727639000805803,"[2], and device control [3, 4]. While DL-based systems are shown to be vulnerable to backdoor
22"
INTRODUCTION,0.018533440773569703,"attacks (BA) [5–7], where an adversary embeds a hidden backdoor into a DL models to maliciously
23"
INTRODUCTION,0.019339242546333603,"control it’s outputs for inference samples containing particular triggers (a.k.a, poisoned samples), the
24"
INTRODUCTION,0.020145044319097503,"security of the DL-based EEG BCI has been long neglected.
25"
INTRODUCTION,0.020950846091861403,"However, compared to image, designing an effect and stealthy BA for EEG is not trivial for three
26"
INTRODUCTION,0.021756647864625302,"difficulties, which lead to three questions. D1: EEG data has a significantly low signal-to-noise
27"
INTRODUCTION,0.022562449637389202,"ratio (SNR) [8], even the accuracies of original EEG tasks are very low [9]. Q1: How to develop an
28"
INTRODUCTION,0.023368251410153102,"EEG BA with high attack success rate (ASR) while preserving the clean accuracies of orignial task?
29"
INTRODUCTION,0.024174053182917002,"D2: Previous studies demonstrated for different EEG tasks, there are some different critical EEG
30"
INTRODUCTION,0.0249798549556809,"electrodes and frequencies that strongly related to the performance of EEG BCI [10–14], indicating
31"
INTRODUCTION,0.0257856567284448,"that the trigger-injection strategy (i.e., which electrodes and frequencies to inject triggers) inevitably
32"
INTRODUCTION,0.0265914585012087,"affect the performance of BA. Q2: How to find the optimal strategy for different EEG tasks? D3:
33"
INTRODUCTION,0.0273972602739726,"Certain classes of EEG have specific morphology that can easily be identified by human expert, e.g.,
34"
INTRODUCTION,0.028203062046736505,"in epilepsy detection, the amplitudes of the ictal phase EEG are larger than those of the normal state
35"
INTRODUCTION,0.029008863819500404,"phase EEG [15]. Q3: How to maintain the consistency of the label and the morphology?
36"
INTRODUCTION,0.029814665592264304,"data 
manifold"
INTRODUCTION,0.030620467365028204,real data boundary
INTRODUCTION,0.031426269137792104,fake data
INTRODUCTION,0.032232070910556,(a) Randomly select � triggers
INTRODUCTION,0.033037872683319904,"Reinforcement
Learning"
INTRODUCTION,0.03384367445608381,"(b) Learn optimal strategies ��
� ��
� ��
� ��
� ��
� ��
� ��
� ��
� ��
� ��
� ��
� ��
�"
INTRODUCTION,0.0346494762288477,clean data
INTRODUCTION,0.035455278001611606,"�(�, 
 , �, ���, ��
�)"
INTRODUCTION,0.0362610797743755,"�(�, 
 , �, ���, ��
�)"
INTRODUCTION,0.037066881547139406,"�(�, 
 , �, ���, ��
�)"
INTRODUCTION,0.0378726833199033,class 1 �
INTRODUCTION,0.038678485092667206,"EEG
electrodes"
INTRODUCTION,0.0394842868654311,Trigger data from class �
INTRODUCTION,0.040290088638195005,"Amplitude
 Phase
Amplitude
Phase"
INTRODUCTION,0.0410958904109589,"×(1 −�)
×�
⨁ �"
INTRODUCTION,0.041901692183722805,Injected Amplitude �−1
INTRODUCTION,0.0427074939564867,Poisoned data with label �
INTRODUCTION,0.043513295729250605,(e) ManiBCI Attacks
INTRODUCTION,0.0443190975020145,class 2
INTRODUCTION,0.045124899274778404,class 3
INTRODUCTION,0.04593070104754231,"(c) Generate poisoned data  �(�, �� , �, ��
�, ��
�)：
for each electrode �� in ��
� :"
INTRODUCTION,0.046736502820306204,"Injected ��
�"
INTRODUCTION,0.04754230459307011,"�
Fast Fourier Transform"
INTRODUCTION,0.048348106365834004,Inverse Fourier Transform
INTRODUCTION,0.04915390813859791,Clean data flow
INTRODUCTION,0.0499597099113618,Trigger data flow
INTRODUCTION,0.05076551168412571,"Poisoned data flow �−1 ��
��"
INTRODUCTION,0.0515713134568896,Clean data �� ...
INTRODUCTION,0.052377115229653506,(d) Existing EEG Backdoor Attacks �(�)
INTRODUCTION,0.0531829170024174,clean data
INTRODUCTION,0.053988718775181306,"EEG
electrodes ... ..."
INTRODUCTION,0.0547945205479452,pulse signals Add ...
INTRODUCTION,0.055600322320709106,poinsoned data �(�)
INTRODUCTION,0.05640612409347301,"only one
target
class"
INTRODUCTION,0.057211925866236905,"Figure 1: (a)-(c) The framework of ManiBCI: (a) The trigger selection and EEG data distribution from
the view of manifold learning. (b) Learning optimal electrodes and frequencies injection strategies.
(c) The generation process of ManiBCI. (d) The payloads of the existing backdoor attacks. (e) The
payloads of ManiBCI, which can arbitrarily manipulate the output of EEG BCI models."
INTRODUCTION,0.05801772763900081,"The first BA for EEG modality is demonstrated in Fig 1 (d), where the narrow period pulse (NPP)
37"
INTRODUCTION,0.058823529411764705,"signals are added as the trigger for single target class attack [16, 17]. To generate invisible trigger, the
38"
INTRODUCTION,0.05962933118452861,"adversarial loss is applied to learn a spatial filter as the trigger function [18]. Recently, some BA for
39"
INTRODUCTION,0.060435132957292505,"time series (EEG signal is a kind of time series) adopt generative adversarial net (GAN) to produce
40"
INTRODUCTION,0.06124093473005641,"poisoned data [19, 20]. However, there are rich information in the frequency domain of EEG [21–24].
41"
INTRODUCTION,0.062046736502820304,"No matter these BA are stealthy or not, they all inject unnatural perturbation in the temporal domain,
42"
INTRODUCTION,0.06285253827558421,"which will inevitably bring unnatural frequency into the real EEG frequency domain.
43"
INTRODUCTION,0.06365834004834811,"In this paper, we propose a novel backdoor attack for manipulating EEG BCI called ManiBCI to
44"
INTRODUCTION,0.064464141821112,"address Q1, which injects triggers in the frequency domain. Specifically, ManiBCI is a three-stage
45"
INTRODUCTION,0.0652699435938759,"clean label poisoning attack demonstrated in Fig 1 (a-c): 1): selecting c triggers from c classes , as
46"
INTRODUCTION,0.06607574536663981,"these triggers are all real EEG, the frequency of these triggers are all natural. Thus, the poisoned
47"
INTRODUCTION,0.06688154713940371,"data are similar to the real EEG as shown in Fig 2(b). 2): learning optimal injecting strategies for
48"
INTRODUCTION,0.06768734891216761,"each trigger with reinforcement learning to enhance the performance of EEG BA, addressing Q2. 3):
49"
INTRODUCTION,0.0684931506849315,"injecting each trigger’s frequencies into clean EEG of the same class as the triggers for each class,
50"
INTRODUCTION,0.0692989524576954,"which maintains the consistency of the label and morphology, addressing Q3.
51"
INTRODUCTION,0.07010475423045931,"The main contributions of this paper are summarized below:
52"
INTRODUCTION,0.07091055600322321,"• We propose a novel backdoor attack for EEG BCI called ManiBCI, which can attack
53"
INTRODUCTION,0.0717163577759871,"arbitrary class while preserving stealthiness without engaging the training stage.
54"
INTRODUCTION,0.072522159548751,"• To the best of our knowledge, it is the first work that considers the efficacy of different EEG
55"
INTRODUCTION,0.07332796132151491,"electrodes and frequencies in EEG backdoor attacks with reinforcement learning.
56"
INTRODUCTION,0.07413376309427881,"• Extensive experiments on three EEG BCI datasets demonstrate the effectiveness of ManiBCI
57"
INTRODUCTION,0.0749395648670427,"and the robustness against several common EEG preprocessings and backdoor defenses.
58"
RELATED WORK,0.0757453666398066,"2
Related Work
59"
BACKDOOR ATTACKS,0.07655116841257051,"2.1
Backdoor Attacks
60"
BACKDOOR ATTACKS,0.07735697018533441,"Backdoor attacks has been deeply investigated in image processing filed [25–27]. BadNets [28] is
61"
BACKDOOR ATTACKS,0.0781627719580983,"the first BA, where the adversary maliciously control the DL to misclassify the input images contain
62"
BACKDOOR ATTACKS,0.0789685737308622,"suspicious patches to a target class. Other non-stealthy attacks like blended [5] and sinusoidal strips
63"
BACKDOOR ATTACKS,0.07977437550362611,"based [29] were studied then. To achieve higher stealthiness, some data poisoning BA were developed,
64"
BACKDOOR ATTACKS,0.08058017727639001,"including shifting color spaces [30], warping [31], regularization [32] and frequency-based [33–38].
65"
BACKDOOR ATTACKS,0.08138597904915391,"Other stealthy attacks [39–41] generate invisible trigger patterns by adversarial loss, which requires
66"
BACKDOOR ATTACKS,0.0821917808219178,"the control of the model’s training process.
67"
BACKDOOR ATTACKS,0.08299758259468171,"Real Data
NPP-added Poisoned Data"
BACKDOOR ATTACKS,0.08380338436744561,"Real Data
ManiBCI Poisoned Data"
BACKDOOR ATTACKS,0.08460918614020951,"(a) NPP-based Backdoor Attack
(b) ManiBCI Backdoor Attack
Figure 2: t-SNE visualization."
BACKDOOR ATTACKS,0.0854149879129734,"Recently, the EEG-based BCIs have shown to be vulnerable to BA
68"
BACKDOOR ATTACKS,0.0862207896857373,"[16–18]. The NPP signals are added to clean EEG to generate non-
69"
BACKDOOR ATTACKS,0.08702659145850121,"stealthy poisoned samples in [16, 17], which significantly modifies
70"
BACKDOOR ATTACKS,0.08783239323126511,"the spectral distribution (as shown in Fig 2 (a)) and results in low
71"
BACKDOOR ATTACKS,0.088638195004029,"stealthiness. From the view of data manifold in Fig 1 (a), NPP-
72"
BACKDOOR ATTACKS,0.0894439967767929,"added EEG are fake data. To generate more stealthy poisoned
73"
BACKDOOR ATTACKS,0.09024979854955681,"data which stay in the real data boundary. The adversarial loss
74"
BACKDOOR ATTACKS,0.09105560032232071,"has been applied backdoor EEG BCI [18] and time series [19, 20],
75"
BACKDOOR ATTACKS,0.09186140209508462,"but these methods require controlling the training process of the backdoor models and can only
76"
BACKDOOR ATTACKS,0.0926672038678485,"attack a single target class. Meng et.al. tried to achieve multi-target attacks with adding different
77"
BACKDOOR ATTACKS,0.09347300564061241,"types of signals to clean EEG, i.e., NPP, sawtooth, sine, and chirp [16]. However, these signals
78"
BACKDOOR ATTACKS,0.09427880741337631,"are not stealthy in both the temporal and frequency domain. To attack multi-target class with high
79"
BACKDOOR ATTACKS,0.09508460918614021,"stealthiness, Marksman backdoor [41] generates invisible sample-specific patterns for each possible
80"
BACKDOOR ATTACKS,0.0958904109589041,"class, but it needs controlling the training stage. Moreover, generating trigger patterns with a neural
81"
BACKDOOR ATTACKS,0.09669621273166801,"network for each sample is time-consuming.
82"
BACKDOOR ATTACKS,0.09750201450443191,"Different from the EEG BA in the temporal domain, we firstly propose to attack in the frequency
83"
BACKDOOR ATTACKS,0.09830781627719581,"domain. Our attack is more stealthy than NPP-based attack, faster than other trigger generation
84"
BACKDOOR ATTACKS,0.0991136180499597,"attack, and more practical as requiring no control of the target models. It is worth noting that the
85"
BACKDOOR ATTACKS,0.0999194198227236,"frequency-based BA for image [33–38] cannot be applied for time series, as they do not consider the
86"
BACKDOOR ATTACKS,0.10072522159548751,"characteristics of time series and fail to maintain the stealthiness for poisoned time series data.
87"
BACKDOOR DEFENSES,0.10153102336825141,"2.2
Backdoor Defenses
88"
BACKDOOR DEFENSES,0.10233682514101532,"To cope with the security problems of backdoor attacks, several categories of defensive methods have
89"
BACKDOOR DEFENSES,0.1031426269137792,"been developed. Neural Cleanse [42] is a trigger reconstruction based methods. If the reconstructed
90"
BACKDOOR DEFENSES,0.10394842868654311,"trigger pattern is significantly small, the model is identified as a backdoor model. Assuming the
91"
BACKDOOR DEFENSES,0.10475423045930701,"trigger is still effective when a triggered sample is combining with a clean sample, STRIP [43]
92"
BACKDOOR DEFENSES,0.10556003223207092,"detects the backdoor model by feeding the combined samples into the model to see if the predictions
93"
BACKDOOR DEFENSES,0.1063658340048348,"are still with low entropy. Spectral Signature [44] detects the backdoor model based on the latent
94"
BACKDOOR DEFENSES,0.10717163577759871,"representations. Fine-Pruning [45] erases the backdoor by pruning the model.
95"
BACKDOOR DEFENSES,0.10797743755036261,"Besides the above defenses designed for backdoor attacks, there are some common EEG pre-
96"
BACKDOOR DEFENSES,0.10878323932312652,"processing methods, such as bandstop filtering and down-sampling, should be considered when
97"
BACKDOOR DEFENSES,0.1095890410958904,"designing a practical robust backdoor attack for EEG BCI in the real-world scene.
98"
METHODOLOGY,0.11039484286865431,"3
Methodology
99"
EEG BCI BACKDOOR ATTACKS AND THREAT MODEL,0.11120064464141821,"3.1
EEG BCI Backdoor Attacks and Threat Model
100"
EEG BCI BACKDOOR ATTACKS AND THREAT MODEL,0.11200644641418211,"Under the supervised learning setting, a classifier f is learned using a labeled training set S =
101"
EEG BCI BACKDOOR ATTACKS AND THREAT MODEL,0.11281224818694602,"{(x1, y1), ..., (xN, yN)} to map f : X →C, where xi ∈X and yi ∈C. The attacker in single target
102"
EEG BCI BACKDOOR ATTACKS AND THREAT MODEL,0.11361804995970991,"class backdoor attacks aims to learn a classifier f behaves as follows:
103"
EEG BCI BACKDOOR ATTACKS AND THREAT MODEL,0.11442385173247381,"f(xi) = yi, f(T(xi)) = ctar, ctar ∈C, ∀(xi, yi) ∈S,
(1)"
EEG BCI BACKDOOR ATTACKS AND THREAT MODEL,0.11522965350523771,"where T : X →X is the trigger function and ctar is the target label. For multi-target class backdoor
104"
EEG BCI BACKDOOR ATTACKS AND THREAT MODEL,0.11603545527800162,"attacks, the trigger function has an extra parameter ci, which manipulates the behavior of f flexibly:
105"
EEG BCI BACKDOOR ATTACKS AND THREAT MODEL,0.1168412570507655,"f(xi) = yi, f(T(ci, xi)) = ci, ∀ci ∈C, ∀(xi, yi) ∈S.
(2)"
EEG BCI BACKDOOR ATTACKS AND THREAT MODEL,0.11764705882352941,"We consider a malicious data provider, who generates a small number of poisoned samples (labeled
106"
EEG BCI BACKDOOR ATTACKS AND THREAT MODEL,0.11845286059629331,"with the target class) and injects them into the original dataset. A victim developer collects this
107"
EEG BCI BACKDOOR ATTACKS AND THREAT MODEL,0.11925866236905722,"poisoned dataset and trains his model, which will be infected a backdoor.
108"
EEG BCI BACKDOOR ATTACKS AND THREAT MODEL,0.1200644641418211,"We use a cross-validation setting to evaluate all BAs, each EEG dataset D is divided into three
109"
EEG BCI BACKDOOR ATTACKS AND THREAT MODEL,0.12087026591458501,"parts: training set Dtrain, poisoning set Dp, and test set Dtest. Specifically, for a dataset contains n
110"
EEG BCI BACKDOOR ATTACKS AND THREAT MODEL,0.12167606768734891,"subjects, we select one subject’s data as Dp one by one, and the remaining n −1 subjects to perform
111"
EEG BCI BACKDOOR ATTACKS AND THREAT MODEL,0.12248186946011282,"leave-one-subject-out (LOSO) cross-validation, i.e., one of the subjects as Dtest, and the remaining
112"
EEG BCI BACKDOOR ATTACKS AND THREAT MODEL,0.1232876712328767,"n −1 subjects as Dtrain (one of the subjects in Dtrain is chosen to be validation set). In summary,
113"
EEG BCI BACKDOOR ATTACKS AND THREAT MODEL,0.12409347300564061,"for a dataset contains n subjects, there are n(n −1) runs to validate each EEG BCI backdoor attack
114"
EEG BCI BACKDOOR ATTACKS AND THREAT MODEL,0.12489927477840451,"method. A poisoned subset Sp of M (M < N) examples is generated based on Dp. Then Sp is
115"
EEG BCI BACKDOOR ATTACKS AND THREAT MODEL,0.12570507655116842,"combined with Dtrain to acquire S = {Sp, Dtrain}. The poisoning ratio is defined as : ρ = M/N.
116"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.12651087832393232,"3.2
Reinforcement Learning for Optimal Trigger-Injection Strategies
117"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.12731668009669622,"The learning of the injecting electrodes set Mci
e and frequencies set Mci
f for each selected trigger
118"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.12812248186946013,"in class ci can be formulated as a non-convex optimization problem. Under this optimization
119"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.128928283642224,"framework, the strategy generator function will learn the optimal Mci
e and Mci
f for each EEG trigger
120"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.1297340854149879,"to implement ManiBCI BA on target DL model f, which is supposed to have a high clean accuracy
121"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.1305398871877518,"(CA) on the clean data and attack success rate (ASR) on the poisoned data:
122"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.1313456889605157,"min
M
ci
e ,M
ci
f
E(xi,yi)∼D[L(f(xi), yi) + λL(f(T (xi, xt
ci, α, Mci
e , Mci
f )), ci)].
(3)"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.13215149073327961,"However, finding the optimal adaptive injecting strategies for each trigger is not trivial as the searching
123"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.13295729250604352,"space is too large (e.g., if injecting half of the 62 electrodes, there are
 62
31

≈4.65 × 1017 cases for
124"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.13376309427880742,"deciding Mci
e ). Reinforcement learning (RL) is an appropriate method for tackling this questions.
125"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.13456889605157132,"The objective of RL is to find a sampler π to maximize the expect of the reward function:
126"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.13537469782433523,"π∗= arg maxπEτ∼π(τ)[R(τ)] = arg maxπ
X"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.1361804995970991,"τ[R(τ) · pπ(τ)]
(4)"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.136986301369863,"= arg maxπ
X"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.1377921031426269,"τ[R(τ) · ρ0(s1) ·
YT −1"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.1385979049153908,"t=1 π(at|st) · P(st+1|st, at)],"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.13940370668815472,"where R(τ) is reward function of a trajectory τ = (s1, a1, r1, ....sT ), the si, ai, ri means the state,
127"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.14020950846091862,"action, and reward at time i. The ρ0 indicates the sampler of initial state. In our settings, the action
128"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.14101531023368252,"(strategies) do not affect the state (triggers). Hence, we can simplify Eq 4 by removing the states si:
129"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.14182111200644643,"π∗= arg maxπ
X"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.1426269137792103,"τ[R(τ) ·
YT −1"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.1434327155519742,"t=1 π(at)].
(5)"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.1442385173247381,"However, we do not care about the reward of the whole trajectory, we only acquire a single strategy
130"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.145044319097502,"for each trigger. Thus, we replace the R(τ) with R(at) and select the at whose R(at) is the biggest
131"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.14585012087026591,"as the optimal strategy. Here, an RL algorithm called policy gradient [46] is adopted to learn an
132"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.14665592264302982,"agent (i.e., policy network πci
θ with parameters θ) to find the optimal strategy for each trigger. After
133"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.14746172441579372,"removing the state st and replacing R(τ), the gradient estimator is:
134"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.14826752618855762,"ˆg = ∇θEτ∼πθ(τ)[R(τ)] =
X"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.14907332796132153,"τ[R(at) · ∇pπθ(at)] = Et[Rt(at) · ∇θ log πθ],
(6)"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.1498791297340854,"where at and Rt is the action and estimator of the reward function at timestep t. The expectation
135"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.1506849315068493,"Et indicates the empirical average. Here, at = {Mci
e , Mci
f }. The parameters of πci
θ are updated by
136"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.1514907332796132,"θt+1 = θt + ηˆg, η is the learning rate. We run the RL for T steps and take the best at as the strategy.
137"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.1522965350523771,"The CA and ASR are obtained by implementing ManiBCI only on S. Specifically, we use a concise
138"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.15310233682514102,"network as the agent which takes the extracted spatial-temporal features from triggers into account
139"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.15390813859790492,"to generate better policy. This agent has two output vectors v1 ∈RE, v2 ∈RF , where E and F is
140"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.15471394037066882,"the number of EEG electrodes and frequencies. The electrodes and frequencies are in Mci
e and Mci
f
141"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.15551974214343273,"only if the corresponding positions in v1 and v2 have Top-k values, k is γE for electrodes and βF for
142"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.1563255439161966,"frequencies, where γ, β ∈(0, 1] are hyperparameters.
143"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.1571313456889605,"Besides the performance of CA and ASR, there are two important concerns: C1: Robustness against
144"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.1579371474617244,"common EEG preprocessig-based defenses; C2: Stealthiness against human perceptions. The reason
145"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.1587429492344883,"why we consider C1 is that the bandstop filtering is widely used for preprocessing EEG signals. For
146"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.15954875100725222,"instance, if we inject the triggers into a concentrated frequency band 50-60Hz, it is easy to filter the
147"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.16035455278001612,"trigger out using a 50Hz low pass filter, resulting in attack failure. Thus, scattering the injection
148"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.16116035455278002,"positions in various frequency can effectively evade from specific frequency filter defenses. To
149"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.16196615632554393,"address C2, injecting the trigger into higher frequencies is more invisible than lower frequencies [47].
150"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.16277195809830783,"Taking all into consideration, we define the estimator of the reward function Rt as follows:
151"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.1635777598710717,"Rt(at) = Rt(Mci
e , Mci
f ) = CA + λ ASR + µ dis(Mci
f ) + ν min(Mci
f ),
(7)"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.1643835616438356,"where the Mci
f indicates the set of all injecting frequency positions, and dis() calculates the minimal
152"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.1651893634165995,"distance between each pair of positions. Thus, dis(Mci
f ) is the discrete (DIS) loss, and min(Mci
f ) is
153"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.16599516518936341,"the high frequency (HF) loss, which can scatter the injection positions in various frequency bands
154"
REINFORCEMENT LEARNING FOR OPTIMAL TRIGGER-INJECTION STRATEGIES,0.16680096696212732,"and inject as high frequencies as possible. The λ, µ, ν ∈R are hyperparameters.
155"
POISONED DATA GENERATION VIA FREQUENCY TRANSFORM,0.16760676873489122,"3.3
Poisoned Data Generation via Frequency Transform
156"
POISONED DATA GENERATION VIA FREQUENCY TRANSFORM,0.16841257050765512,"After selecting the C triggers from each class and learning the strategy for each trigger, the poisoned
157"
POISONED DATA GENERATION VIA FREQUENCY TRANSFORM,0.16921837228041903,"data are generated by injecting these triggers into clean data with the corresponding strategies. As
158"
POISONED DATA GENERATION VIA FREQUENCY TRANSFORM,0.17002417405318293,"shown in Fig 1(c), given a clean data xi ∈Dp with label ci, and a trigger data xt
ci, let FA and FP be
159"
POISONED DATA GENERATION VIA FREQUENCY TRANSFORM,0.1708299758259468,"the amplitude and phase components of the fast Fourier transform (FFT) result of a EEG signals, we
160"
POISONED DATA GENERATION VIA FREQUENCY TRANSFORM,0.1716357775987107,"denote the amplitude and phase spectrum of xi and xt
ci as:
161"
POISONED DATA GENERATION VIA FREQUENCY TRANSFORM,0.1724415793714746,"Axi = FA(xi), Axtci = FA(xt
ci),
Pxi = FP (xi), Pxtci = FP (xt
ci).
(8)"
POISONED DATA GENERATION VIA FREQUENCY TRANSFORM,0.17324738114423852,"The new poisoned amplitude spectrum AP
xi is produced by linearly interpolating Axi and Axtci. In
162"
POISONED DATA GENERATION VIA FREQUENCY TRANSFORM,0.17405318291700242,"order to achieve this, we produce a binary mask Mci ∈RE×F = 1(j,k), j ∈Mci
e , k ∈Mci
f , whose
163"
POISONED DATA GENERATION VIA FREQUENCY TRANSFORM,0.17485898468976632,"value is 1 for positions of all corresponding to elements in both electrode and frequency sets and 0
164"
POISONED DATA GENERATION VIA FREQUENCY TRANSFORM,0.17566478646253023,"elsewhere. Denoting α ∈(0, 1] as the linear interpolating ratio, the new poisoned amplitude spectrum
165"
POISONED DATA GENERATION VIA FREQUENCY TRANSFORM,0.17647058823529413,"can be computed as follows, where ⊙indicates Hadamard product:
166"
POISONED DATA GENERATION VIA FREQUENCY TRANSFORM,0.177276390008058,"AP
xi = [(1 −α)Axi + αAxtci] ⊙Mci + Axi ⊙(1 −Mci).
(9)"
POISONED DATA GENERATION VIA FREQUENCY TRANSFORM,0.1780821917808219,"Finally, we adopt the injected poisoned amplitude spectrum AP
xi and the clean phase spectrum Pxi to
167"
POISONED DATA GENERATION VIA FREQUENCY TRANSFORM,0.1788879935535858,"get the poisoned data by inverse FFT F−1:
168"
POISONED DATA GENERATION VIA FREQUENCY TRANSFORM,0.17969379532634971,"xp
i = F−1(AP
xi, Pxi).
(10)"
POISONED DATA GENERATION VIA FREQUENCY TRANSFORM,0.18049959709911362,"By generating xp
i through this frequency injection approach, we obtain a subset Sp = {xp
1, ..., xp
M},
169"
POISONED DATA GENERATION VIA FREQUENCY TRANSFORM,0.18130539887187752,"which will combine with Dtrain to form the whole traing dataset S. The EEG DL model f is then
170"
POISONED DATA GENERATION VIA FREQUENCY TRANSFORM,0.18211120064464142,"trained with S to obtain the ability of behvaing as equation 2.
171"
EXPERIMENTS,0.18291700241740533,"4
Experiments
172"
EXPERIMENTS,0.18372280419016923,"4.1
Datasets, Baselines, and Experimental Setup
173"
EXPERIMENTS,0.1845286059629331,"Emotion Recognition (ER) Dataset SEED [12] is a discrete EEG emotion dataset studying three
174"
EXPERIMENTS,0.185334407735697,"types of emotions: happy, neutral, and sad. SEED collected EEG from 15 subjects.
175"
EXPERIMENTS,0.1861402095084609,"Motor Imagery (MI) Dataset BCIC-IV-2a [48] dataset recorded EEG from 9 subjects while they
176"
EXPERIMENTS,0.18694601128122482,"were instructed to imagine four types of movements: left hand, right hand, feet, and tongue.
177"
EXPERIMENTS,0.18775181305398872,"Epilepsy Detection (ED) Dataset CHB-MIT [49] is an epilepsy dataset required from 23 patients.
178"
EXPERIMENTS,0.18855761482675262,"We cropped and resampled the CHB-MIT dataset to build an ED dataset with four types of EEG:
179"
EXPERIMENTS,0.18936341659951653,"ictal, preictal, postictal, and interictal phase EEG.
180"
EXPERIMENTS,0.19016921837228043,"Non-stealthy Baselines As mentioned in previous sections, to the best of our knowledge, ManiBCI
181"
EXPERIMENTS,0.1909750201450443,"is the first work that studies multi-trigger and multi-target class (MT) backdoor in EEG BCI. For
182"
EXPERIMENTS,0.1917808219178082,"comparison, we design several baseline approaches which can be divided into two main groups:
183"
EXPERIMENTS,0.1925866236905721,"non-stealthy and stealthy. Non-stealthy attacks contains PatchMT and PulseMT. For a benign EEG
184"
EXPERIMENTS,0.19339242546333602,"segment x ∈RE×T . PatchMT is a multi-trigger and MT extension of BadNets [28] where we fill the
185"
EXPERIMENTS,0.19419822723609992,"first βT timepoints of a EEG segments with a constant number, e.g., {0.1, 0.3, 0.5} for three-class
186"
EXPERIMENTS,0.19500402900886382,"task. PulseMT is a multi-trigger and MT extension of NPP-based backdoor attacks [16] where we
187"
EXPERIMENTS,0.19580983078162773,"use NPP signals with different amplitudes, e.g., {-0.8, -0.3, 0.3, 0.8} for different target classes.
188"
EXPERIMENTS,0.19661563255439163,"Stealthy Baselines Previous works generate stealthy poisioned samples by controlling the training
189"
EXPERIMENTS,0.19742143432715553,"stage and can only attack single target class [18–20]. As they control the training of target model,
190"
EXPERIMENTS,0.1982272360999194,"it is unfair to directly compare their methods with ManiBCI. There is no stealthy MT BA for EEG.
191"
EXPERIMENTS,0.1990330378726833,"Thus, we design two MT stealthy attacks baselines: CompMT and AdverMT. CompMT generates
192"
EXPERIMENTS,0.1998388396454472,"poisoned samples for different target classes by compressing the amplitude of EEG with different
193"
EXPERIMENTS,0.20064464141821112,"Table 1: The clean accuraciy and attack success rate for each target class with 40% poisoning rate.
The best results are in bold and the second best are underlined."
EXPERIMENTS,0.20145044319097502,"Dataset
Emotion Recognition
Motor Imagery
Epilepsy Detection"
EXPERIMENTS,0.20225624496373892,"Method
Clean ASR
0
1
2
Clean ASR
0
1
2
3
Clean ASR
0
1
2
3"
EXPERIMENTS,0.20306204673650283,EEGNet
EXPERIMENTS,0.20386784850926673,"No Attack 0.477 0.333
-
-
-
0.327 0.250
-
-
-
-
0.508 0.250
-
-
-
-
PatchMT
0.492 0.382 0.577 0.232 0.337 0.283 0.824 0.866 0.880 0.787 0.762 0.460 0.549 0.532
0.430 0.388 0.845
PulseMT
0.463 0.778 0.844 0.509 0.981 0.270 0.825 0.947 0.656 0.758 0.938 0.439 0.810 0.853
0.745 0.729 0.913
CompMT
0.443 0.385 0.099 0.377 0.678 0.269 0.865 0.530 0.997 0.983 0.948 0.437 0.547 0.261
0.280 0.714 0.933
AdverMT
0.457 0.334 0.276 0.330 0.396 0.257 0.243 0.316 0.192 0.230 0.235 0.413 0.250 0.326
0.264 0.200 0.210
ManiBCI
0.535 0.857 0.831 0.791 0.949 0.323 1.000 0.999 1.000 1.000 0.999 0.477 0.944
0.930 0.954 0.921 0.970"
EXPERIMENTS,0.20467365028203063,DeepCNN
EXPERIMENTS,0.2054794520547945,"No Attack 0.497 0.333
-
-
-
0.301 0.250
-
-
-
-
0.443 0.250
-
-
-
-
PatchMT
0.481 0.342 0.248 0.323 0.453 0.276 0.704 0.638 0.977 0.774 0.425 0.431 0.729 0.416
0.890 0.719 0.892
PulseMT
0.450 0.596 0.815 0.334 0.638 0.261 0.829 0.764 0.968 0.819 0.765 0.405 0.885 0.872
0.862 0.861 0.943
CompMT
0.461 0.427 0.473 0.473 0.336 0.286 0.887 0.638 0.982 0.946 0.980 0.446 0.538 0.196
0.466 0.571 0.918
AdverMT
0.367 0.388 0.298 0.453 0.412 0.245 0.247 0.320 0.221 0.196 0.240 0.396 0.275 0.354
0.218 0.227 0.301
ManiBCI
0.534 0.832 0.732 0.865 0.901 0.315 1.000 1.000 1.000 1.000 0.999 0.469 0.828 0.725
0.839 0.845 0.904 LSTM"
EXPERIMENTS,0.2062852538275584,"No Attack 0.506 0.333
-
-
-
0.264 0.250
-
-
-
-
0.462 0.250
-
-
-
-
PatchMT
0.509 0.368 0.311 0.392 0.401 0.261 0.429 0.395 0.296 0.386 0.639 0.450 0.513 0.500
0.437 0.417 0.700
PulseMT
0.511 0.824 0.883 0.645 0.943 0.265 0.533 0.787 0.327 0.282 0.737 0.451 0.804 0.845
0.769 0.709 0.895
CompMT
0.484 0.490 0.272 0.269 0.929 0.260 0.548 0.219 0.511 0.523 0.940 0.455 0.435 0.194
0.217 0.490 0.840
AdverMT
0.367 0.415 0.472 0.453 0.321 0.239 0.271 0.308 0.215 0.247 0.312 0.432 0.268 0.367
0.232 0.198 0.275
ManiBCI
0.519 0.954 0.998 0.868 0.996 0.264 0.966 0.987 0.988 0.901 0.986 0.444 0.865 0.795
0.833 0.857 0.975"
EXPERIMENTS,0.20709105560032232,"ratios, e.g., {-0.1, 0, 0.1} for three-class task. AdverseMT is a multi-trigger and MT extension of
194"
EXPERIMENTS,0.20789685737308622,"adversarial filtering based attacks [18], where we using a local model trained only on Sp to generate
195"
EXPERIMENTS,0.20870265914585012,"different spatial filters W∗
i for different target classes, then we apply these spatial filters to generate
196"
EXPERIMENTS,0.20950846091861403,"poisoned samples. More details are written in Appendix D.
197"
EXPERIMENTS,0.21031426269137793,"Experimental Setup We demonstrate the effectiveness of the proposed ManiBCI backdoor through
198"
EXPERIMENTS,0.21112006446414183,"comprehensive experiments on the above three EEG datasets, more details of each dataset and
199"
EXPERIMENTS,0.2119258662369057,"preprocessings are illustrated in Appendix C. We follow the poisoning attack setting as the previous
200"
EXPERIMENTS,0.2127316680096696,"works [16] and consider three EEG DL models for classifier f: EEGNet [50], DeepCNN [51], and
201"
EXPERIMENTS,0.21353746978243351,"LSTM [52, 53]. For all methods, we train the classifiers using the Adam optimizer with learning rate
202"
EXPERIMENTS,0.21434327155519742,"of 0.001. The batch size is 32 and the number of epochs is 100. For all datasets and baselines, the
203"
EXPERIMENTS,0.21514907332796132,"interpolating ratio α = 0.8, the electrode poisoning ratio β = 0.1, the electrode poisoning ratio γ =
204"
EXPERIMENTS,0.21595487510072522,"0.5. For the reinforcement learning of ManiBCI, we train πξ using the Adam optimizer with learning
205"
EXPERIMENTS,0.21676067687348913,"rate of 0.01. The hyperparameters in advantage function is set to λ = 2, µ = 0.3, and ν = 0.005.
206"
EXPERIMENTS,0.21756647864625303,"More details of the experimental setup can be found in the supplementary material.
207"
EFFECTIVENESS OF MANIBCI,0.21837228041901693,"4.2
Effectiveness of ManiBCI
208"
EFFECTIVENESS OF MANIBCI,0.2191780821917808,"This section presents the attack success rates of ManiBCI and baselines. To evaluate the performance
209"
EFFECTIVENESS OF MANIBCI,0.2199838839645447,"in the multi-trigger multi-payload scenario, for each test sample (x, y) ∈Dtest, we enumerate all
210"
EFFECTIVENESS OF MANIBCI,0.22078968573730862,"possible target labels ci ∈C including the true label y and inject the trigger to activate the backdoor.
211"
EFFECTIVENESS OF MANIBCI,0.22159548751007252,"The attack is successful only when the backdoor classifier f correctly predicts ci for each poisoned
212"
EFFECTIVENESS OF MANIBCI,0.22240128928283642,"input x with a target label ci.
213"
ATTACK PERFORMANCE,0.22320709105560033,"4.2.1
Attack Performance
214"
ATTACK PERFORMANCE,0.22401289282836423,"The clean-data accuracy (Clean) and ASR (Attack) for each class of all attack methods on three EEG
215"
ATTACK PERFORMANCE,0.22481869460112813,"tasks with three EEG DL models are presented in Table 1. The AdverMT, designed for single-target
216"
ATTACK PERFORMANCE,0.22562449637389204,"attack, fails to attacks multiple target classes. Our ManiBCI significantly outperforms baselines at
217"
ATTACK PERFORMANCE,0.2264302981466559,"almost all cases (p < 0.05) except attacking DeepCNN on the ED dataset, having ASRs above 0.8 on
218"
ATTACK PERFORMANCE,0.22723609991941982,"three datasets and even achieving an ASR of 1.000 on the MI dataset. These results demonstrate that
219"
ATTACK PERFORMANCE,0.22804190169218372,"our ManiBCI is effective across different EEG tasks and EEG models. PulseMT achieves the second
220"
ATTACK PERFORMANCE,0.22884770346494762,"best on ER and ED dataset, CompMT achieves the second best on the MI dataset.
221"
ATTACK PERFORMANCE,0.22965350523771152,"4.2.2
Performance of the Reinforcement Learning: Policy Gradient
222"
ATTACK PERFORMANCE,0.23045930701047543,"Displaying in Table 2, the performance of the policy gradient was compared with other common
223"
ATTACK PERFORMANCE,0.23126510878323933,"optimazation algorithms, including genetic algorithm (GA) [54] and random selection (The search
224"
ATTACK PERFORMANCE,0.23207091055600323,"space is too large for performing grid search as explained in Section 3.2). It can be observed that the
225"
ATTACK PERFORMANCE,0.2328767123287671,"policy gradient outperforms GA while only spending 16% training time of GA. We plot the learning
226"
ATTACK PERFORMANCE,0.233682514101531,"curve of RL in Appendix F.3, which demonstrates that RL learns well strategies within 50 epochs, i.e.,
227"
ATTACK PERFORMANCE,0.23448831587429492,"only trains 50 backdoor models and saves lots of time. The random algorithm can achieve a not bad
228"
ATTACK PERFORMANCE,0.23529411764705882,"results, proving that our methods can be applied without RL if some performance drop is acceptable.
229"
ATTACK PERFORMANCE,0.23609991941982272,"Table 2: Clean and attack performance with with different trigger search optimization algorithms, the
poisoning rate is set to 10%. The target model is EEGNet."
ATTACK PERFORMANCE,0.23690572119258663,"Method
Dataset
Emotion
Motor Imagery
Epilepsy"
ATTACK PERFORMANCE,0.23771152296535053,Clean Attack Time ↓Clean Attack Time ↓Clean Attack Time ↓
ATTACK PERFORMANCE,0.23851732473811443,"Random
0.520
0.771
-
0.291
0.857
-
0.501
0.721
-
Genetic Algorithm 0.516
0.826
15.2h
0.302
1.000
10.0h
0.492
0.862
30.5h
Policy Gradient
0.535
0.857
2.5h
0.323
1.000
1.8h
0.477
0.944
5.2h"
PERFORMANCE OF LEARNED MASK STRATEGIES ON OTHER TARGET MODELS,0.23932312651087834,"4.2.3
Performance of Learned Mask Strategies on Other Target Models
230"
PERFORMANCE OF LEARNED MASK STRATEGIES ON OTHER TARGET MODELS,0.2401289282836422,"We demonstrate that the injecting strategies learned on a EEG classifier f can be used to attack
231"
PERFORMANCE OF LEARNED MASK STRATEGIES ON OTHER TARGET MODELS,0.24093473005640612,"other EEG classifiers ˆf. In other words, Marksman can still be effective when the adversary has no
232"
PERFORMANCE OF LEARNED MASK STRATEGIES ON OTHER TARGET MODELS,0.24174053182917002,"knowledge of the target models ˆf. To perform the experiments, we use the strategy learned with a
233"
PERFORMANCE OF LEARNED MASK STRATEGIES ON OTHER TARGET MODELS,0.24254633360193392,"classifier f, then generate poisoned samples to attack another classifier ˆf whose network is different
234"
PERFORMANCE OF LEARNED MASK STRATEGIES ON OTHER TARGET MODELS,0.24335213537469783,"from f. Table 3 shows the performance difference, it can be observed that the difference is relatively
235"
PERFORMANCE OF LEARNED MASK STRATEGIES ON OTHER TARGET MODELS,0.24415793714746173,"small in most of the cases, demonstrating the transferability of the injecting strategy learned with
236"
PERFORMANCE OF LEARNED MASK STRATEGIES ON OTHER TARGET MODELS,0.24496373892022563,"reinforcement learning.
237"
PERFORMANCE OF LEARNED MASK STRATEGIES ON OTHER TARGET MODELS,0.24576954069298954,"Table 3: Clean and attack performance on other models. Red values represent the decreasing
performance in attacks with f is the same as ˆf. Blue values mean increments or unchanged ."
PERFORMANCE OF LEARNED MASK STRATEGIES ON OTHER TARGET MODELS,0.2465753424657534,"Models
f : EEGNet
f : DeepCNN
f : LSTM"
PERFORMANCE OF LEARNED MASK STRATEGIES ON OTHER TARGET MODELS,0.24738114423851731,"ˆf : DeepCNN
ˆf : LSTM
ˆf : EEGNet
ˆf : LSTM
ˆf : EEGNet
ˆf : DeepCNN"
PERFORMANCE OF LEARNED MASK STRATEGIES ON OTHER TARGET MODELS,0.24818694601128122,Datasets Clean Attack Clean Attack Clean Attack Clean Attack Clean Attack Clean Attack
PERFORMANCE OF LEARNED MASK STRATEGIES ON OTHER TARGET MODELS,0.24899274778404512,Emotion 0.458 0.781 0.485 0.938 0.516 0.813 0.490 0.936 0.516 0.863 0.497 0.779
PERFORMANCE OF LEARNED MASK STRATEGIES ON OTHER TARGET MODELS,0.24979854955680902,0.026 0.051 0.034 0.016 0.019 0.044 0.029 0.018 0.019 0.006 0.037 0.053
PERFORMANCE OF LEARNED MASK STRATEGIES ON OTHER TARGET MODELS,0.2506043513295729,"Motor
0.316 1.000 0.265 0.946 0.309 1.000 0.264 0.972 0.306 1.000 0.306 1.000
0.001 0.000 0.001 0.020 0.014 0.000 0.000 0.006 0.017 0.000 0.009 0.000"
PERFORMANCE OF LEARNED MASK STRATEGIES ON OTHER TARGET MODELS,0.25141015310233683,Epilepsy 0.442 0.759 0.469 0.806 0.448 0.943 0.445 0.813 0.448 0.926 0.427 0.850
PERFORMANCE OF LEARNED MASK STRATEGIES ON OTHER TARGET MODELS,0.25221595487510073,0.027 0.069 0.025 0.059 0.029 0.001 0.001 0.052 0.029 0.018 0.042 0.022
ATTACK PERFORMANCE WITH DIFFERENT HYPERPARAMETERS,0.25302175664786464,"4.2.4
Attack Performance with Different Hyperparameters
238"
ATTACK PERFORMANCE WITH DIFFERENT HYPERPARAMETERS,0.25382755842062854,"We investigate the influences of three different hyperparameters: poisoning rate ρ, frequency injection
239"
ATTACK PERFORMANCE WITH DIFFERENT HYPERPARAMETERS,0.25463336019339244,"rate β, and electrode injection rate γ. The performance of attacking EEGNet on the ED dataset are
240"
ATTACK PERFORMANCE WITH DIFFERENT HYPERPARAMETERS,0.25543916196615635,"displayed in Fig 3. It can be seen that the ASRs are positively correlated with poisoning rate. Note
241"
ATTACK PERFORMANCE WITH DIFFERENT HYPERPARAMETERS,0.25624496373892025,"that it is non-trivial for multi-target class attack, thus the ASR is not high compared to the single class
242"
ATTACK PERFORMANCE WITH DIFFERENT HYPERPARAMETERS,0.2570507655116841,"attack. ManiBCI outperforms other attacks in all cases and is robust to the change of β and γ.
243"
ATTACK PERFORMANCE WITH DIFFERENT HYPERPARAMETERS,0.257856567284448,"0.05
0.10
0.15
0.20
0.25
0.30
0.35
0.40
Poisoning Rate 0.3 0.4 0.5 0.6 0.7 0.8 0.9"
ATTACK PERFORMANCE WITH DIFFERENT HYPERPARAMETERS,0.2586623690572119,Accuracy
ATTACK PERFORMANCE WITH DIFFERENT HYPERPARAMETERS,0.2594681708299758,"0.1
0.2
0.3
0.4
0.5
Frequency/Time Injection Rate 0.5 0.6 0.7 0.8 0.9"
ATTACK PERFORMANCE WITH DIFFERENT HYPERPARAMETERS,0.2602739726027397,Accuracy
ATTACK PERFORMANCE WITH DIFFERENT HYPERPARAMETERS,0.2610797743755036,"0.2
0.4
0.6
0.8
1.0
Electrodes Injection Rate 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0"
ATTACK PERFORMANCE WITH DIFFERENT HYPERPARAMETERS,0.2618855761482675,Accuracy
ATTACK PERFORMANCE WITH DIFFERENT HYPERPARAMETERS,0.2626913779210314,"ManiBCI/C
ManiBCI/B
PatchMT/C
PatchMT/B
PulseMT/C
PulseMT/B
CompMT/C
CompMT/B"
ATTACK PERFORMANCE WITH DIFFERENT HYPERPARAMETERS,0.2634971796937953,Figure 3: Clean (/C) and attack (/B) performance with different poisoning or injection rates.
ROBUSTNESS OF MANIBCI,0.26430298146655923,"4.3
Robustness of ManiBCI
244"
ROBUSTNESS OF MANIBCI,0.26510878323932313,"In this section, we evaluate the robustness of our ManiBCI against different EEG preprocessing
245"
ROBUSTNESS OF MANIBCI,0.26591458501208703,"method and various representative backdoor defenses.
246"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.26672038678485094,"4.3.1
Robustness against EEG Preprocessing Methods
247"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.26752618855761484,"To develop an EEG BCI, it is very common to preprocess the raw EEG signals, e.g., 1) band-stop
248"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.26833199033037874,"filtering and 2) down-sampling. An EEG backdoor attack is impractical in real scenarios if it is no
249"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.26913779210314265,"longer effective when the target model is trained with the preprocessed poisoned EEG. Hence, we
250"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.26994359387590655,"must take the robustness against preprocessing methods into account, which is widely ignored in
251"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.27074939564867045,"the image backdoor attack field. The performance of each method facing different preprocessing
252"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.2715551974214343,"methods are presented in Table 4. It can be observed that our ManiBCI is robust in all cases. However,
253"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.2723609991941982,"when removing the DIS loss, the performance of ManiBCI decreases a lot after EEG preprocessing,
254"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.2731668009669621,"especially facing the 30 Hz high-stop filtering preprocessing due to the HF loss that encourages the
255"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.273972602739726,"policy network learns to injecting high frequency.
256"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.2747784045124899,"Table 4: Clean and attack performance on three datasets after different EEG preprocessing methods.
The target model is EEGNet. M w.o. DIS means removing the DIS loss in ManiBCI."
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.2755842062852538,"Preprocessing
No defense
20 Hz low
30 Hz high
25% down
Average"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.2763900080580177,"Method
Clean Attack Clean
Attack
Clean
Attack
Clean
Attack
ASR ER"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.2771958098307816,"ManiBCI
0.535
0.857
0.512
0.829
0.463
0.892
0.518
0.908
0.876
w/o DIS
0.506
0.859
0.492
0.816
0.466
0.333
0.498
0.807
0.652 MI"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.27800161160354553,"ManiBCI
0.323
1.000
0.285
1.000
0.329
1.000
0.321
1.000
1.000
w/o DIS
0.298
1.000
0.264
1.000
0.322
0.250
0.284
0.990
0.746 ED"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.27880741337630943,"ManiBCI
0.497
0.944
0.492
0.914
0.494
0.856
0.516
0.818
0.920
w/o DIS
0.515
0.250
0.477
0.864
0.508
0.250
0.510
0.249
0.454"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.27961321514907334,"4.3.2
Robustness against Neural Cleanse: Trigger Inversion
257"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.28041901692183724,"Emotion
Motor Imagery
Epilepsy
0.0 0.5 1.0 1.5 2.0"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.28122481869460114,Anomaly Index
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.28203062046736505,"0.67
0.7 1.33"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.28283642224012895,"0.67
0.69 1.29"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.28364222401289285,"0.77
0.83 1.12"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.28444802578565676,"0.98
0.9 1.36"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.2852538275584206,"0.72
0.76 1.25"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.2860596293311845,"0.83
0.72 1.28"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.2868654311039484,"EEGNet_C
EEGNet_B"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.2876712328767123,"DeepCNN_C
DeepCNN_B"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.2884770346494762,"LSTM_C
LSTM_B"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.2892828364222401,"Figure 4: Anomaly Index of three
models on three datasets."
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.290088638195004,"Neural Cleanse (NC) [42] calculate a metric called Anomaly
258"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.2908944399677679,"Index by reconstructing trigger pattern for each possible label.
259"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.29170024174053183,"The Anomaly Index is positively correlated with the size of the
260"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.29250604351329573,"reconstruction trigger. A model with Anomaly Index > 2 is
261"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.29331184528605964,"considered to be backdoor-injected. We display the Anomaly
262"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.29411764705882354,"Indexes of the clean models and the backdoor-injected model
263"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.29492344883158744,"by ManiBCI in Fig 4. It can be seen that ManiBCI can easily
264"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.29572925060435135,"bypass NC. The reconstructed trigger patterns on three datasets
265"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.29653505237711525,"are presented in Appendix F.1.
266"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.29734085414987915,"4.3.3
Robustness against STRIP: Input Perturbation
267"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.29814665592264306,"We evaluate the robustness of ManiBCI against STRIP [43], which perturbs the input EEG and
268"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.2989524576954069,"calculates the entropy of the predictions of these perturbed EEG data. Based on the assumption that
269"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.2997582594681708,"the trigger is still effective after perturbation, the entropy of backdoor input tends to be lower than
270"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.3005640612409347,"that of the clean one. The results are plotted in Fig 5, it can be seen that the entropy distributions of
271"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.3013698630136986,"the backdoor and clean samples are similar.
272"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.3021756647864625,"0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
1.6
0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.3029814665592264,Probability
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.3037872683319903,"0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75 2.00
0.00 0.02 0.04 0.06 0.08"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.3045930701047542,Probability 0.00 0.01 0.02 0.03 0.04 0.05
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.30539887187751813,Probability
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.30620467365028203,"Without Backdoor
ManiBCI Backdoor"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.30701047542304594,"Entropy
Entropy
Entropy"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.30781627719580984,"Without Backdoor
ManiBCI Backdoor
Without Backdoor
ManiBCI Backdoor"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.30862207896857374,"0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
2.00"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.30942788074133765,"Emotion Recognition
Motor Imagery
Epilepsy Detection"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.31023368251410155,"Figure 5: Performance against STRIP on three datasets, the target model is EEGNet."
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.31103948428686545,"4.3.4
Robustness against Spectral Signature: Latent Space Correlation
273"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.31184528605962936,"Spectral Signature [44] detects the backdoor samples by statistical analysis of clean data and backdoor
274"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.3126510878323932,"data in the latent space. Following the same experimental settings in [44], we randomly select 5,000
275"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.3134568896051571,"clean samples and 500 ManiBCI backdoor samples and plot the histograms of the correlation scores
276"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.314262691377921,"in Fig 6. There is no clear separation between these two sets of samples, showing the stealthiness of
277"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.3150684931506849,"ManiBCI backdoor samples in the latent space.
278"
ROBUSTNESS AGAINST EEG PREPROCESSING METHODS,0.3158742949234488,"Figure 6: Performance against Spectral Signature on three datasets, the target model is EEGNet."
ROBUSTNESS AGAINST FINE-PRUNING,0.3166800966962127,"4.3.5
Robustness against Fine-Pruning
279"
ROBUSTNESS AGAINST FINE-PRUNING,0.3174858984689766,"0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Fraction of Pruned Neurons 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0"
ROBUSTNESS AGAINST FINE-PRUNING,0.3182917002417405,Accuracy
ROBUSTNESS AGAINST FINE-PRUNING,0.31909750201450443,"Emotion/C
Emotion/B"
ROBUSTNESS AGAINST FINE-PRUNING,0.31990330378726833,"Motor/C
Motor/B"
ROBUSTNESS AGAINST FINE-PRUNING,0.32070910556003224,"Epilepsy/C
Epilepsy/B"
ROBUSTNESS AGAINST FINE-PRUNING,0.32151490733279614,"Figure 7: Performances of EEG-
Net against Fine-Pruning on three
datasets."
ROBUSTNESS AGAINST FINE-PRUNING,0.32232070910556004,"We evaluate the robustness of Marksman against Fine-Pruning
280"
ROBUSTNESS AGAINST FINE-PRUNING,0.32312651087832395,"[45], a model analysis based defense which finds a classifier’s
281"
ROBUSTNESS AGAINST FINE-PRUNING,0.32393231265108785,"low-activated neurons given a small clean dataset. Then it
282"
ROBUSTNESS AGAINST FINE-PRUNING,0.32473811442385175,"gradually prunes these low-activated neurons to mitigate the
283"
ROBUSTNESS AGAINST FINE-PRUNING,0.32554391619661566,"backdoor without affecting the CA. We can observe from Fig
284"
THAT THE ASR DROPS CONSIDERABLY SMALL WHEN PRUNING RATIO,0.32634971796937956,"7 that the ASR drops considerably small when pruning ratio
285"
THAT THE ASR DROPS CONSIDERABLY SMALL WHEN PRUNING RATIO,0.3271555197421434,"is less than 0.7, suggesting that the Fine-Pruning is ineffective
286"
THAT THE ASR DROPS CONSIDERABLY SMALL WHEN PRUNING RATIO,0.3279613215149073,"against ManiBCI.
287"
VISUALIZATION OF BACKDOOR ATTACK SAMPLES,0.3287671232876712,"4.4
Visualization of Backdoor Attack Samples
288"
VISUALIZATION OF BACKDOOR ATTACK SAMPLES,0.3295729250604351,"To evade from human perception (C2 in Section 3.2), we design to obatin injecting strategies with
289"
VISUALIZATION OF BACKDOOR ATTACK SAMPLES,0.330378726833199,"HF loss. It can be seen from the bottom row of Fig 8 that ManiBCI (with HF loss) generates stealthy
290"
VISUALIZATION OF BACKDOOR ATTACK SAMPLES,0.3311845286059629,"poisoned EEG, which is almost the same as the clean EEG, demonstrating the High Stealthiness.
291"
VISUALIZATION OF BACKDOOR ATTACK SAMPLES,0.33199033037872683,"The poisoned EEG will be conspicuous compared to the clean EEG if remove the HF loss.
292"
VISUALIZATION OF BACKDOOR ATTACK SAMPLES,0.33279613215149073,"Trigger from Class 0
Trigger from Class 1
Trigger from Class 2
Trigger from Class 3"
VISUALIZATION OF BACKDOOR ATTACK SAMPLES,0.33360193392425463,"w/o HF loss
ManiBCI"
VISUALIZATION OF BACKDOOR ATTACK SAMPLES,0.33440773569701854,"Figure 8: The Clean EEG (Blue), Trigger-injected EEG (Orange) and the Residual (Red) of the ED
dataset. The x-axis is the timepoints, the y-axis is the normalized amplitude. Top row: w.o. HF loss;
Bottom row: with HF loss. Each column indicates each possible class."
CONCLUSION,0.33521353746978244,"5
Conclusion
293"
CONCLUSION,0.33601933924254634,"In this paper, we proposed ManiBCI, a novel EEG backdoor for manipulating EEG BCI, where the
294"
CONCLUSION,0.33682514101531025,"adversary can arbitrarily control the output for any input samples. To the best of our knowledge,
295"
CONCLUSION,0.33763094278807415,"ManiBCI is the first method that considers which EEG electrodes and frequencies to be injected by
296"
CONCLUSION,0.33843674456083805,"adopting a reinforcement learning called policy gradient to learn the adaptive injecting strategies
297"
CONCLUSION,0.33924254633360196,"for different EEG triggers and tasks. We specially design the reward function in RL to enhance the
298"
CONCLUSION,0.34004834810636586,"robustness and stealthiness of ManiBCI. The perturbation of the trigger on clean EEG is almost
299"
CONCLUSION,0.3408541498791297,"invisible. Our experimental results over three common EEG datasets demonstrate the effectiveness
300"
CONCLUSION,0.3416599516518936,"of ManibCI and the stealthiness against the existing representative defenses. This work calls for
301"
CONCLUSION,0.3424657534246575,"defensive studies to counter ManiBCI for EEG modality.
302"
REFERENCES,0.3432715551974214,"References
303"
REFERENCES,0.3440773569701853,"[1] I. Ahmad, X. Wang, M. Zhu, C. Wang, Y. Pi, J. A. Khan, S. Khan, O. W. Samuel, S. Chen, G. Li
304"
REFERENCES,0.3448831587429492,"et al., “EEG-based epileptic seizure detection via machine/deep learning approaches: a systematic review,”
305"
REFERENCES,0.34568896051571313,"Computational Intelligence and Neuroscience, vol. 2022, 2022.
306"
REFERENCES,0.34649476228847703,"[2] M. Jafari, A. Shoeibi, M. Khodatars, S. Bagherzadeh, A. Shalbaf, D. L. García, J. M. Gorriz, and U. R.
307"
REFERENCES,0.34730056406124094,"Acharya, “Emotion recognition in EEG signals using deep learning methods: A review,” Computers in
308"
REFERENCES,0.34810636583400484,"Biology and Medicine, p. 107450, 2023.
309"
REFERENCES,0.34891216760676874,"[3] H. Lorach, A. Galvez, V. Spagnolo, F. Martel, S. Karakas, N. Intering, M. Vat, O. Faivre, C. Harte, S. Komi
310"
REFERENCES,0.34971796937953264,"et al., “Walking naturally after spinal cord injury using a brain–spine interface,” Nature, vol. 618, no. 7963,
311"
REFERENCES,0.35052377115229655,"pp. 126–133, 2023.
312"
REFERENCES,0.35132957292506045,"[4] H. Altaheri, G. Muhammad, M. Alsulaiman, S. U. Amin, G. A. Altuwaijri, W. Abdul, M. A. Bencherif,
313"
REFERENCES,0.35213537469782435,"and M. Faisal, “Deep learning techniques for classification of electroencephalogram (EEG) motor imagery
314"
REFERENCES,0.35294117647058826,"(MI) signals: A review,” Neural Computing and Applications, vol. 35, no. 20, pp. 14 681–14 722, 2023.
315"
REFERENCES,0.35374697824335216,"[5] X. Chen, C. Liu, B. Li, K. Lu, and D. Song, “Targeted backdoor attacks on deep learning systems using
316"
REFERENCES,0.354552780016116,"data poisoning,” arXiv preprint arXiv:1712.05526, 2017.
317"
REFERENCES,0.3553585817888799,"[6] Y. Gao, B. G. Doan, Z. Zhang, S. Ma, J. Zhang, A. Fu, S. Nepal, and H. Kim, “Backdoor attacks and
318"
REFERENCES,0.3561643835616438,"countermeasures on deep learning: A comprehensive review,” arXiv preprint arXiv:2007.10760, 2020.
319"
REFERENCES,0.3569701853344077,"[7] R. Shokri et al., “Bypassing backdoor detection algorithms in deep learning,” in 2020 IEEE European
320"
REFERENCES,0.3577759871071716,"Symposium on Security and Privacy (EuroS&P).
IEEE, 2020, pp. 175–183.
321"
REFERENCES,0.3585817888799355,"[8] S. L. Kappel, D. Looney, D. P. Mandic, and P. Kidmose, “Physiological artifacts in scalp EEG and ear-EEG,”
322"
REFERENCES,0.35938759065269943,"Biomedical Engineering Online, vol. 16, pp. 1–16, 2017.
323"
REFERENCES,0.36019339242546333,"[9] M. Tangermann, K.-R. Müller, A. Aertsen, N. Birbaumer, C. Braun, C. Brunner, R. Leeb, C. Mehring, K. J.
324"
REFERENCES,0.36099919419822724,"Miller, G. R. Müller-Putz et al., “Review of the bci competition iv,” Frontiers in Neuroscience, vol. 6, p. 55,
325"
REFERENCES,0.36180499597099114,"2012.
326"
REFERENCES,0.36261079774375504,"[10] M. Z. Parvez and M. Paul, “EEG signal classification using frequency band analysis towards epileptic
327"
REFERENCES,0.36341659951651895,"seizure prediction,” in 16th Int’l Conf. Computer and Information Technology.
IEEE, 2014, pp. 126–130.
328"
REFERENCES,0.36422240128928285,"[11] R. Jana and I. Mukherjee, “Deep learning based efficient epileptic seizure prediction with EEG channel
329"
REFERENCES,0.36502820306204675,"optimization,” Biomedical Signal Processing and Control, vol. 68, p. 102767, 2021.
330"
REFERENCES,0.36583400483481066,"[12] W.-L. Zheng and B.-L. Lu, “Investigating critical frequency bands and channels for EEG-based emotion
331"
REFERENCES,0.36663980660757456,"recognition with deep neural networks,” IEEE Transactions on Autonomous Mental Development, vol. 7,
332"
REFERENCES,0.36744560838033846,"no. 3, pp. 162–175, 2015.
333"
REFERENCES,0.3682514101531023,"[13] M. Z. Baig, N. Aslam, and H. P. Shum, “Filtering techniques for channel selection in motor imagery EEG
334"
REFERENCES,0.3690572119258662,"applications: a survey,” Artificial Intelligence Review, vol. 53, no. 2, pp. 1207–1232, 2020.
335"
REFERENCES,0.3698630136986301,"[14] P. Herman, G. Prasad, T. M. McGinnity, and D. Coyle, “Comparative analysis of spectral approaches to
336"
REFERENCES,0.370668815471394,"feature extraction for EEG-based motor imagery classification,” IEEE Transactions on Neural Systems and
337"
REFERENCES,0.3714746172441579,"Rehabilitation Engineering, vol. 16, no. 4, pp. 317–326, 2008.
338"
REFERENCES,0.3722804190169218,"[15] W. T. Blume, G. B. Young, and J. F. Lemieux, “EEG morphology of partial epileptic seizures,” Electroen-
339"
REFERENCES,0.37308622078968573,"cephalography and Clinical Neurophysiology, vol. 57, no. 4, pp. 295–302, 1984.
340"
REFERENCES,0.37389202256244963,"[16] L. Meng, X. Jiang, J. Huang, Z. Zeng, S. Yu, T.-P. Jung, C.-T. Lin, R. Chavarriaga, and D. Wu, “EEG-based
341"
REFERENCES,0.37469782433521354,"brain-computer interfaces are vulnerable to backdoor attacks,” IEEE Transactions on Neural Systems and
342"
REFERENCES,0.37550362610797744,"Rehabilitation Engineering, 2023.
343"
REFERENCES,0.37630942788074134,"[17] X. Jiang, L. Meng, S. Li, and D. Wu, “Active poisoning: efficient backdoor attacks on transfer learning-
344"
REFERENCES,0.37711522965350525,"based brain-computer interfaces,” Science China Information Sciences, vol. 66, no. 8, p. 182402, 2023.
345"
REFERENCES,0.37792103142626915,"[18] L. Meng, X. Jiang, X. Chen, W. Liu, H. Luo, and D. Wu, “Adversarial filtering based evasion and backdoor
346"
REFERENCES,0.37872683319903305,"attacks to EEG-based brain-computer interfaces,” Information Fusion, p. 102316, 2024.
347"
REFERENCES,0.37953263497179696,"[19] D. Ding, M. Zhang, Y. Huang, X. Pan, F. Feng, E. Jiang, and M. Yang, “Towards backdoor attack on
348"
REFERENCES,0.38033843674456086,"deep learning based time series classification,” in 2022 IEEE 38th International Conference on Data
349"
REFERENCES,0.38114423851732476,"Engineering (ICDE).
IEEE, 2022, pp. 1274–1287.
350"
REFERENCES,0.3819500402900886,"[20] Y. Jiang, X. Ma, S. M. Erfani, and J. Bailey, “Backdoor attacks on time series: A generative approach,”
351"
REFERENCES,0.3827558420628525,"in 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML).
IEEE, 2023, pp.
352"
REFERENCES,0.3835616438356164,"392–403.
353"
REFERENCES,0.3843674456083803,"[21] S. Arroyo and S. Uematsu, “High-frequency eeg activity at the start of seizures,” Journal of Clinical
354"
REFERENCES,0.3851732473811442,"Neurophysiology, vol. 9, no. 3, pp. 441–448, 1992.
355"
REFERENCES,0.3859790491539081,"[22] M. Kostyunina and M. Kulikov, “Frequency characteristics of eeg spectra in the emotions,” Neuroscience
356"
REFERENCES,0.38678485092667203,"and Behavioral Physiology, vol. 26, no. 4, pp. 340–343, 1996.
357"
REFERENCES,0.38759065269943593,"[23] M. Salinsky, B. Oken, and L. Morehead, “Test-retest reliability in eeg frequency analysis,” Electroen-
358"
REFERENCES,0.38839645447219984,"cephalography and clinical neurophysiology, vol. 79, no. 5, pp. 382–392, 1991.
359"
REFERENCES,0.38920225624496374,"[24] S. D. Muthukumaraswamy, “High-frequency brain activity and muscle artifacts in meg/eeg: a review and
360"
REFERENCES,0.39000805801772764,"recommendations,” Frontiers in human neuroscience, vol. 7, p. 138, 2013.
361"
REFERENCES,0.39081385979049155,"[25] M. Weber, X. Xu, B. Karlaš, C. Zhang, and B. Li, “Rab: Provable robustness against backdoor attacks,” in
362"
REFERENCES,0.39161966156325545,"2023 IEEE Symposium on Security and Privacy (S&P).
IEEE, 2023, pp. 1311–1328.
363"
REFERENCES,0.39242546333601935,"[26] Y. Yu, Y. Wang, W. Yang, S. Lu, Y.-P. Tan, and A. C. Kot, “Backdoor attacks against deep image
364"
REFERENCES,0.39323126510878326,"compression via adaptive frequency trigger,” in Proceedings of the IEEE/CVF Conference on Computer
365"
REFERENCES,0.39403706688154716,"Vision and Pattern Recognition (CVPR), 2023, pp. 12 250–12 259.
366"
REFERENCES,0.39484286865431106,"[27] Z. Yuan, P. Zhou, K. Zou, and Y. Cheng, “You are catching my attention: Are vision transformers bad
367"
REFERENCES,0.39564867042707497,"learners under backdoor attacks?” in Proceedings of the IEEE/CVF Conference on Computer Vision and
368"
REFERENCES,0.3964544721998388,"Pattern Recognition (CVPR), 2023, pp. 24 605–24 615.
369"
REFERENCES,0.3972602739726027,"[28] T. Gu, K. Liu, B. Dolan-Gavitt, and S. Garg, “BadNets: Evaluating backdooring attacks on deep neural
370"
REFERENCES,0.3980660757453666,"networks,” IEEE Access, vol. 7, pp. 47 230–47 244, 2019.
371"
REFERENCES,0.3988718775181305,"[29] M. Barni, K. Kallas, and B. Tondi, “A new backdoor attack in cnns by training set corruption without
372"
REFERENCES,0.3996776792908944,"label poisoning,” in 2019 IEEE International Conference on Image Processing (ICIP).
IEEE, 2019, pp.
373"
REFERENCES,0.40048348106365833,"101–105.
374"
REFERENCES,0.40128928283642223,"[30] W. Jiang, H. Li, G. Xu, and T. Zhang, “Color backdoor: A robust poisoning attack in color space,” in
375"
REFERENCES,0.40209508460918614,"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023, pp.
376"
REFERENCES,0.40290088638195004,"8133–8142.
377"
REFERENCES,0.40370668815471394,"[31] T. A. Nguyen and A. T. Tran, “Wanet-imperceptible warping-based backdoor attack,” in International
378"
REFERENCES,0.40451248992747785,"Conference on Learning Representations (ICLR), 2020.
379"
REFERENCES,0.40531829170024175,"[32] S. Li, M. Xue, B. Z. H. Zhao, H. Zhu, and X. Zhang, “Invisible backdoor attacks on deep neural networks
380"
REFERENCES,0.40612409347300565,"via steganography and regularization,” IEEE Transactions on Dependable and Secure Computing, vol. 18,
381"
REFERENCES,0.40692989524576956,"no. 5, pp. 2088–2105, 2020.
382"
REFERENCES,0.40773569701853346,"[33] Y. Zeng, W. Park, Z. M. Mao, and R. Jia, “Rethinking the backdoor attacks’ triggers: A frequency
383"
REFERENCES,0.40854149879129736,"perspective,” in Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021,
384"
REFERENCES,0.40934730056406127,"pp. 16 473–16 481.
385"
REFERENCES,0.4101531023368251,"[34] T. Wang, Y. Yao, F. Xu, S. An, H. Tong, and T. Wang, “An invisible black-box backdoor attack through
386"
REFERENCES,0.410958904109589,"frequency domain,” in European Conference on Computer Vision (ECCV).
Springer, 2022, pp. 396–413.
387"
REFERENCES,0.4117647058823529,"[35] H. A. A. K. Hammoud and B. Ghanem, “Check your other door! creating backdoor attacks in the frequency
388"
REFERENCES,0.4125705076551168,"domain,” arXiv preprint arXiv:2109.05507, 2021.
389"
REFERENCES,0.41337630942788073,"[36] R. Hou, T. Huang, H. Yan, L. Ke, and W. Tang, “A stealthy and robust backdoor attack via frequency
390"
REFERENCES,0.41418211120064463,"domain transform,” World Wide Web (WWW), vol. 26, no. 5, pp. 2767–2783, 2023.
391"
REFERENCES,0.41498791297340853,"[37] Y. Feng, B. Ma, J. Zhang, S. Zhao, Y. Xia, and D. Tao, “Fiba: Frequency-injection based backdoor attack
392"
REFERENCES,0.41579371474617244,"in medical image analysis,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
393"
REFERENCES,0.41659951651893634,"Recognition (CVPR), 2022, pp. 20 876–20 885.
394"
REFERENCES,0.41740531829170024,"[38] Y. Gao, H. Chen, P. Sun, J. Li, A. Zhang, Z. Wang, and W. Liu, “A dual stealthy backdoor: From both
395"
REFERENCES,0.41821112006446415,"spatial and frequency perspectives,” in Proceedings of the AAAI Conference on Artificial Intelligence
396"
REFERENCES,0.41901692183722805,"(AAAI), vol. 38, no. 3, 2024, pp. 1851–1859.
397"
REFERENCES,0.41982272360999195,"[39] T. A. Nguyen and A. Tran, “Input-aware dynamic backdoor attack,” Advances in Neural Information
398"
REFERENCES,0.42062852538275586,"Processing Systems (NeurIPS), vol. 33, pp. 3454–3464, 2020.
399"
REFERENCES,0.42143432715551976,"[40] K. Doan, Y. Lao, W. Zhao, and P. Li, “Lira: Learnable, imperceptible and robust backdoor attacks,” in
400"
REFERENCES,0.42224012892828366,"Proceedings of the IEEE/CVF international conference on computer vision (ICCV), 2021, pp. 11 966–
401"
REFERENCES,0.42304593070104757,"11 976.
402"
REFERENCES,0.4238517324738114,"[41] K. D. Doan, Y. Lao, and P. Li, “Marksman backdoor: Backdoor attacks with arbitrary target class,”
403"
REFERENCES,0.4246575342465753,"Advances in Neural Information Processing Systems (NeurIPS), vol. 35, pp. 38 260–38 273, 2022.
404"
REFERENCES,0.4254633360193392,"[42] B. Wang, Y. Yao, S. Shan, H. Li, B. Viswanath, H. Zheng, and B. Y. Zhao, “Neural Cleanse: Identifying
405"
REFERENCES,0.4262691377921031,"and mitigating backdoor attacks in neural networks,” in 2019 IEEE Symposium on Security and Privacy
406"
REFERENCES,0.42707493956486703,"(S&P).
IEEE, 2019, pp. 707–723.
407"
REFERENCES,0.42788074133763093,"[43] Y. Gao, C. Xu, D. Wang, S. Chen, D. C. Ranasinghe, and S. Nepal, “STRIP: A defence against trojan
408"
REFERENCES,0.42868654311039484,"attacks on deep neural networks,” in Proceedings of the 35th Annual Computer Security Applications
409"
REFERENCES,0.42949234488315874,"Conference, 2019, pp. 113–125.
410"
REFERENCES,0.43029814665592264,"[44] B. Tran, J. Li, and A. Madry, “Spectral signatures in backdoor attacks,” Advances in Neural Information
411"
REFERENCES,0.43110394842868655,"Processing Systems (NeurIPS), vol. 31, 2018.
412"
REFERENCES,0.43190975020145045,"[45] K. Liu, B. Dolan-Gavitt, and S. Garg, “Fine-pruning: Defending against backdooring attacks on deep
413"
REFERENCES,0.43271555197421435,"neural networks,” in International Symposium on Research in Attacks, Intrusions, and Defenses.
Springer,
414"
REFERENCES,0.43352135374697826,"2018, pp. 273–294.
415"
REFERENCES,0.43432715551974216,"[46] R. S. Sutton, D. McAllester, S. Singh, and Y. Mansour, “Policy gradient methods for reinforcement learning
416"
REFERENCES,0.43513295729250606,"with function approximation,” Advances in Neural Information Processing Systems (NeurIPS), vol. 12,
417"
REFERENCES,0.43593875906526997,"1999.
418"
REFERENCES,0.43674456083803387,"[47] S. V. Gliske, Z. T. Irwin, K. A. Davis, K. Sahaya, C. Chestek, and W. C. Stacey, “Universal automated high
419"
REFERENCES,0.4375503626107977,"frequency oscillation detector for real-time, long term eeg,” Clinical Neurophysiology, vol. 127, no. 2, pp.
420"
REFERENCES,0.4383561643835616,"1057–1066, 2016.
421"
REFERENCES,0.4391619661563255,"[48] C. Brunner, R. Leeb, G. Müller-Putz, A. Schlögl, and G. Pfurtscheller, “BCI competition 2008–graz data
422"
REFERENCES,0.4399677679290894,"set A,” Institute for Knowledge Discovery (Laboratory of Brain-Computer Interfaces), Graz University of
423"
REFERENCES,0.44077356970185333,"Technology, vol. 16, pp. 1–6, 2008.
424"
REFERENCES,0.44157937147461723,"[49] A. H. Shoeb and J. V. Guttag, “Application of machine learning to epileptic seizure detection,” in Proceed-
425"
REFERENCES,0.44238517324738114,"ings of the 27th International Conference on Machine Learning (ICML), 2010, pp. 975–982.
426"
REFERENCES,0.44319097502014504,"[50] V. J. Lawhern, A. J. Solon, N. R. Waytowich, S. M. Gordon, C. P. Hung, and B. J. Lance, “EEGNet:
427"
REFERENCES,0.44399677679290894,"a compact convolutional neural network for EEG-based brain–computer interfaces,” Journal of Neural
428"
REFERENCES,0.44480257856567285,"Engineering, vol. 15, no. 5, p. 056013, 2018.
429"
REFERENCES,0.44560838033843675,"[51] R. T. Schirrmeister, J. T. Springenberg, L. D. J. Fiederer, M. Glasstetter, K. Eggensperger, M. Tangermann,
430"
REFERENCES,0.44641418211120065,"F. Hutter, W. Burgard, and T. Ball, “Deep learning with convolutional neural networks for EEG decoding
431"
REFERENCES,0.44721998388396456,"and visualization,” Human Brain Mapping, vol. 38, no. 11, pp. 5391–5420, 2017.
432"
REFERENCES,0.44802578565672846,"[52] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural Computation, vol. 9, no. 8, pp.
433"
REFERENCES,0.44883158742949236,"1735–1780, 1997.
434"
REFERENCES,0.44963738920225627,"[53] K. M. Tsiouris, V. C. Pezoulas, M. Zervakis, S. Konitsiotis, D. D. Koutsouris, and D. I. Fotiadis, “A
435"
REFERENCES,0.45044319097502017,"long short-term memory deep learning network for the prediction of epileptic seizures using eeg signals,”
436"
REFERENCES,0.4512489927477841,"Computers in biology and medicine, vol. 99, pp. 24–37, 2018.
437"
REFERENCES,0.4520547945205479,"[54] S. Katoch, S. S. Chauhan, and V. Kumar, “A review on genetic algorithm: past, present, and future,”
438"
REFERENCES,0.4528605962933118,"Multimedia tools and applications, vol. 80, pp. 8091–8126, 2021.
439"
REFERENCES,0.4536663980660757,"Appendix
440"
REFERENCES,0.45447219983883963,"A
Limitations
441"
REFERENCES,0.45527800161160353,"Our ManiBCI is a backdoor attack in the frequency domain, which requires to transform the EEG
442"
REFERENCES,0.45608380338436744,"signals into frequency domain through fast Fourier transform (FFT) and return to temporal domain
443"
REFERENCES,0.45688960515713134,"through inverse FFT (iFFT). The operation of FFT and iFFT in the trigger injection function are a
444"
REFERENCES,0.45769540692989524,"little more time-consuming compared to other backdoor attack directly in the temporal domain, like
445"
REFERENCES,0.45850120870265915,"PatchMT [28] and PulseMT [16]. Future effort will be devoted into the faster implementation of FFT
446"
REFERENCES,0.45930701047542305,"and iFFT, for example, taking the advantage of modern GPUs.
447"
REFERENCES,0.46011281224818695,"It is a little more time-consuming for the reinforcement learning to acquire the optimal strategies for
448"
REFERENCES,0.46091861402095086,"each trigger. However, we can obtain a general injecting strategy for each EEG BCI tasks, which can
449"
REFERENCES,0.46172441579371476,"achieve a relatively good performance without reinforcement learning, as we can see from Table 3
450"
REFERENCES,0.46253021756647866,"that random injection strategy has an acceptable performance.
451"
REFERENCES,0.46333601933924257,"B
Broader Impacts
452"
REFERENCES,0.46414182111200647,"With the rapid development of techniques, EEG BCIs gain a wide range of applications from health
453"
REFERENCES,0.4649476228847704,"care to human-computer interaction. Some companies like Neuralink adopt the EEG BCI to assist
454"
REFERENCES,0.4657534246575342,"paralytic patients helping themselves in daily lives. However, if the EEG BCI is backdoor attacked
455"
REFERENCES,0.4665592264302981,"by ManiBCI, which allows the attacker to arbitrarily control BCI’s outputs, the BCI users may fall
456"
REFERENCES,0.467365028203062,"into tremendous fatal troubles. For instance, one paralytic patient controls his/her wheelchair by
457"
REFERENCES,0.46817082997582593,"EEG BCI, the attacker can manipulate the wheelchair to run down a steep staircase. For an epileptic
458"
REFERENCES,0.46897663174858983,"patient, the attacker can let all the output be Normal State, even when the patient is experiencing
459"
REFERENCES,0.46978243352135374,"an epileptic seizure. This paper reveals the severe danger faced by EEG BCIs, demonstrating the
460"
REFERENCES,0.47058823529411764,"possibility that someone can maliciously manipulate the outputs of EEG BCIs with arbitrary target
461"
REFERENCES,0.47139403706688154,"class.
462"
REFERENCES,0.47219983883964545,"ManiBCI can also be used for positive purposes, like protecting intellectual property of EEG dataset
463"
REFERENCES,0.47300564061240935,"and EEG models with watermarking. As our ManiBCI has a very small impact of the clean accuracy,
464"
REFERENCES,0.47381144238517325,"and the poisoning approach is clean label poisoning, ManiBCI is a fantastic method for watermarking
465"
REFERENCES,0.47461724415793716,"EEG dataset and models.
466"
REFERENCES,0.47542304593070106,"For a company that provides EEG dataset, it can select different EEG triggers for different customs
467"
REFERENCES,0.47622884770346496,"to generate poisoned data and inject into the dataset provided to customs who buy the dataset. As a
468"
REFERENCES,0.47703464947622887,"result, the company have the information of which trigger is corresponding to which customs, e.g.,
469"
REFERENCES,0.47784045124899277,"trigger x is in the dataset provided to custom X, trigger y is in the dataset provided to custom Y. If an
470"
REFERENCES,0.4786462530217567,"EEG model from a company which didn’t buy dataset is detected having this watermark (backdoor)
471"
REFERENCES,0.4794520547945205,"with trigger x, the company knows that the custom X leaked the dataset. Similarly, if an EEG model
472"
REFERENCES,0.4802578565672844,"is detected having this watermark (backdoor) with trigger y, the company knows that the custom Y
473"
REFERENCES,0.48106365834004833,"leaked the dataset.
474"
REFERENCES,0.48186946011281223,"C
Datasets and Preprocessing
475"
REFERENCES,0.48267526188557613,"In this section, we introduce the three datasets used in our experiments, and explain the preprocessing.
476"
REFERENCES,0.48348106365834004,"Table 5 presents some basic information of these datasets.
477"
REFERENCES,0.48428686543110394,Table 5: Basic information of the three datasets
REFERENCES,0.48509266720386784,"Dataset
Emotion
Motor Imagery
Epilepsy"
REFERENCES,0.48589846897663175,"Class Numbers
3
4
4
Subjects
15
9
23
Electrodes
62
22
23
Sampling Rate
200 Hz
250 Hz
256 Hz"
REFERENCES,0.48670427074939565,"C.1
Emotion Recognition (ER)
478"
REFERENCES,0.48751007252215955,"The SJTU Emotion EEG Dataset (SEED) was incoporated as the representative dataset of emotion
479"
REFERENCES,0.48831587429492346,"recogniton tasks [12]. It consists of EEG recordings from 15 subjects watching 15 emotional video
480"
REFERENCES,0.48912167606768736,"clips with three repeated session each on different days. Each video clip is supposed to evoke one
481"
REFERENCES,0.48992747784045126,"of the three target emotions: positive, neutral, and negative. The EEG signals were acquired by
482"
REFERENCES,0.49073327961321517,"the 62-channel electrode cap at a sampling rate of 1000 Hz. We performed below preprocessing
483"
REFERENCES,0.49153908138597907,"procedures for the 62-channel EEG signals: 1) Down-sampling from 1000 Hz to 200 Hz, 2) Band-pass
484"
REFERENCES,0.492344883158743,"filtering at 0.3-50 Hz, 3) Segmenting EEG signals into 1-second (200 timepoints), obtaining 3394
485"
REFERENCES,0.4931506849315068,"EEG segments in each session for each subject.
486"
REFERENCES,0.4939564867042707,"C.2
Motor Imagery (MI)
487"
REFERENCES,0.49476228847703463,"We employ the BCIC-IV-2a as a representative dataset of MI classification tasks [48]. It contains
488"
REFERENCES,0.49556809024979853,"EEG recordings in a four-class motor-imagery task from nine subjects with two repeated session each
489"
REFERENCES,0.49637389202256244,"on different days. During the task, the subjects were instructed to imagine four types of movements
490"
REFERENCES,0.49717969379532634,"(i.e., right hand, left hand, feet, and tongue) for four seconds. Each session consists of a total of
491"
REFERENCES,0.49798549556809024,"288 trials with 72 trials for each type of the motor imagery. The EEG signals were recorded by 22
492"
REFERENCES,0.49879129734085415,"Ag/AgCl EEG electrodes in a sampling rate of 250 Hz. We segment the 22-channel EEG signals into
493"
REFERENCES,0.49959709911361805,"1-second segments, resulting in totally 1152 EEG data for each subject.
494"
REFERENCES,0.500402900886382,"C.3
Epilepsy Detection (ED)
495"
REFERENCES,0.5012087026591459,"The CHB-MIT, one of the largest and most used public datasets for epilepsy, is adopted as a
496"
REFERENCES,0.5020145044319098,"representative dataset of ED tasks [49]. It recorded 877.39 hours of multi-channel EEG in a sampling
497"
REFERENCES,0.5028203062046737,"rate of 256 Hz from 23 pediatric patients with intractable seizures. However, as the montages (i.e.,
498"
REFERENCES,0.5036261079774376,"the number and the places of electrodes) of EEG signals vary significantly among different subjects’
499"
REFERENCES,0.5044319097502015,"recordings, we select to use only the EEG recordings with the same 23 channels (see Appendix A)
500"
REFERENCES,0.5052377115229654,"and discard other channels or the recordings don’t have all these 23 channels. Due to the purpose is to
501"
REFERENCES,0.5060435132957293,"test whether the backdoor attack works on the ED task, not to study the epilepsy EEG classification,
502"
REFERENCES,0.5068493150684932,"we segment part of the CHB-MIT dataset to form a four-class ED dataset (i.e., the preictal, ictal,
503"
REFERENCES,0.5076551168412571,"postictal, and interictal phases). Specifically, for a ictal phase EEG recording of ti seconds from
504"
REFERENCES,0.508460918614021,"[si, ei] timepoints, we segment the [si −ti, ei] EEG as the preictal phase, the [ei, ei + ti] EEG as the
505"
REFERENCES,0.5092667203867849,"postictal phase, and another ti seconds EEG recordings as the interictal phase which satisfying there
506"
REFERENCES,0.5100725221595488,"is no ictal phase within half an hour before or after. Then we segment the 23-channel EEG signals
507"
REFERENCES,0.5108783239323127,"into 1-second segments, consequently, there are 41336 segments left in total from all subjects, 10334
508"
REFERENCES,0.5116841257050766,"for each phase. As the imbalanced amount of data across different subjects, we separate these 41336
509"
REFERENCES,0.5124899274778405,"segments into 10 groups and treat the ten groups as 10 subjects.
510"
REFERENCES,0.5132957292506044,"D
Implementation Details
511"
REFERENCES,0.5141015310233682,"D.1
Experiment Computing Resources
512"
REFERENCES,0.5149073327961321,"We use two servers for conducting our experiments. A server with one Nvidia Tesla V100 GPU is
513"
REFERENCES,0.515713134568896,"used for running reinforcement learning, the CUDA version is 12.3. Another server with four Nvidia
514"
REFERENCES,0.5165189363416599,"RTX 3090 GPUs is used for running the backdoor attacks, the CUDA version is 11.4.
515"
REFERENCES,0.5173247381144238,"D.2
Details of Baseline Methods
516"
REFERENCES,0.5181305398871877,"In our ManiBCI backdoor attacks, for an EEG segment xi ∈RE×T , we modify the βF frequency-
517"
REFERENCES,0.5189363416599516,"points and γE electrodes of a EEG segments with a constant number.
518"
REFERENCES,0.5197421434327155,"There are four baseline methods in our study for multi-target backdoor attacks, two of them are
519"
REFERENCES,0.5205479452054794,"non-stealthy attacks (PatchMT and PulseMT) and two are stealthy attacks (CompressMT and
520"
REFERENCES,0.5213537469782433,"AdverseMT). In order to achieve a fair comparison, we modify only first γE electrodes for all
521"
REFERENCES,0.5221595487510072,"baseline attack methods. For the non-stealthy attacks, which are all on the temporal domains, we
522"
REFERENCES,0.5229653505237711,"modify βT timepoints of EEG signals. For the stealthy attacks, there is no constraint of the numbers
523"
REFERENCES,0.523771152296535,"of the modify timepoints as these attacks achieve stealthiness in another way.
524"
REFERENCES,0.5245769540692989,"For each baseline method, we try our best to find out the best performance, as demonstrated below.
525"
REFERENCES,0.5253827558420628,"We promise that we did not maliciously lower the performances of the baseline methods.
526"
REFERENCES,0.5261885576148267,"D.2.1
PatchMT
527"
REFERENCES,0.5269943593875906,"PatchMT is a multi-trigger and MT extension of BadNets [28] where we fill the first βT timepoints
528"
REFERENCES,0.5278001611603546,"and γE electrodes of a EEG segments with a constant number. Specifically, for an EEG segment
529"
REFERENCES,0.5286059629331185,"xi ∈RE×T , we set the first γE electrodes and the first βT timepoints of the EEG segment to a
530"
REFERENCES,0.5294117647058824,"constant number. We normalize the EEG segment xi ∈RE×T to let xi’s mean is 0 and std is 1.
531"
REFERENCES,0.5302175664786463,"Then set the first γE electrodes and the first βT timepoints of xi to a different constant number for
532"
REFERENCES,0.5310233682514102,"different class. The constant number for each class of {0, 1, 2, 3} for four classes, and {-0.1, 0.0, 1.0}
533"
REFERENCES,0.5318291700241741,"for three classes. Finally, denormalize xi to original signal xi’s scale to generate xp
i .
534"
REFERENCES,0.532634971796938,"Although we try our best to find the best performance of PatchMT, and BadNets [28] is really efficient
535"
REFERENCES,0.5334407735697019,"in image backdoor attacks, PatchMT cannot have satisfactory results in EEG BCI attack.
536"
REFERENCES,0.5342465753424658,"D.2.2
PulseMT
537"
REFERENCES,0.5350523771152297,"For PulseMT, we met the same questions as the PatchMT: how to identify the amplitude of each NPP
538"
REFERENCES,0.5358581788879936,"signal for each class? If the numbers are too large then normal EEG signals, it will be unfair. If the
539"
REFERENCES,0.5366639806607575,"numbers are too small, the efficacy of PulseMT is too negative.
540"
REFERENCES,0.5374697824335214,"We normalize the EEG segment xi ∈RE×T to let xi’s mean is 0 and std is 1. The constant amplitude
541"
REFERENCES,0.5382755842062853,"for each class of {−0.8, −0.3, 0.3, 0.8}. Finally, denormalize xi to original signal xi’s scale to
542"
REFERENCES,0.5390813859790492,"generate xp
i .
543"
REFERENCES,0.5398871877518131,"D.2.3
CompressMT
544"
REFERENCES,0.540692989524577,"Compressing the amplitude of EEG signals in the temporal domain will not change the morphology
545"
REFERENCES,0.5414987912973409,"and the frequency distribution of EEG signals, thus obtaining stealthiness. For three-class Emotion
546"
REFERENCES,0.5423045930701047,"datasets, the compress rate is {0.8, 0.6, 0.4}. For four-class Motor Imagery and Epilepsy datasets, the
547"
REFERENCES,0.5431103948428686,"compress rate is {0.8, 0.6, 0.4, 0.2}.
548"
REFERENCES,0.5439161966156325,"D.2.4
AdverseMT
549"
REFERENCES,0.5447219983883964,"AdverseMT is another stealthy EEG backdoor attacks, which is the multi-trigger and multi-target
550"
REFERENCES,0.5455278001611603,"extension of adversarial spatial filter attacks [18], in wihch, for EEG segment xi ∈RE×T , it learns
551"
REFERENCES,0.5463336019339242,"an Spatial Filter W ∈RE×E by the adversarial loss to let the model f misclassify xi:
552"
REFERENCES,0.5471394037066881,"min
W E(xi,yi)∼D[−LCE(Wxi, yi) + αLMSE(Wxi, xi)],
(11)"
REFERENCES,0.547945205479452,"However, the original version of [18] requires the access to all training dataset D and the control of
553"
REFERENCES,0.5487510072522159,"the training process of the model f. We modify the AdverseMT to only access to the training dataset
554"
REFERENCES,0.5495568090249798,"Dtrain. Note that the adversarial loss dose not have the special design for multi-target backdoor
555"
REFERENCES,0.5503626107977437,"attacks, we only run the process c times for obtaining c spatial filters for different classes. So the
556"
REFERENCES,0.5511684125705076,"poisoned subset are Sp = {(W0(x), 0), (W1(x), 1), (W2(x), 2), (W3(x), 3)}.
557"
REFERENCES,0.5519742143432715,"D.3
Reinforcement Learning Policy Network Architecture
558"
REFERENCES,0.5527800161160354,"Here, we design a concise but effective convolutional neural networks as the our policy network,
559"
REFERENCES,0.5535858178887993,"which is defined as belows:
560"
REFERENCES,0.5543916196615633,Table 6: The Architecture of Policy Network
REFERENCES,0.5551974214343272,"Layer
In
Out
Kernel
Stride"
REFERENCES,0.5560032232070911,"Conv2d
1
32
(1, 3)
(1, 1)
BatchNorm2d
ELU
AvgPool2d
(1,2)"
REFERENCES,0.556809024979855,"Conv2d
32
64
(1, 3)
(1, 1)
BatchNorm2d
ELU
AvgPool2d
(1,2)"
REFERENCES,0.5576148267526189,"AdaptiveAvgPool2d
(1, 1)
Flatten
Linear
64
256"
REFERENCES,0.5584206285253828,"E
Attack Performance of ManiBCI
561"
REFERENCES,0.5592264302981467,"E.1
Different Poisoning Rates
562"
REFERENCES,0.5600322320709106,"We present the performance of each backdoor attacks’ performance under different poisoning rates in
563"
REFERENCES,0.5608380338436745,"Table 7. We can see that our ManiBCI outperforms other baseline at all poisoning rates, demonstrating
564"
REFERENCES,0.5616438356164384,"the superiority of ManiBCI. Note that the performance of ManiBCI on the MI dataset is significantly
565"
REFERENCES,0.5624496373892023,"robust to low poisoning rates, i.e., ASR of 1.000 when ρ = 0.05.
566"
REFERENCES,0.5632554391619662,"E.2
Hyperparameter Analysis: Frequency and Electrodes Injection Ratio
567"
REFERENCES,0.5640612409347301,"We present the performance of each backdoor attacks performance under different rates in Table 8
568"
REFERENCES,0.564867042707494,"and Table 9. It can be observed with the increment of β and γ, the attack performance increases.
569"
REFERENCES,0.5656728444802579,"Because the trigger is bigger in clean EEG data.
570"
REFERENCES,0.5664786462530218,"E.3
Hyperparameter Analysis in Reinforcement Learning
571"
REFERENCES,0.5672844480257857,"We applied the following reward function to acquire the optimal mask strategies for each triggers:
572"
REFERENCES,0.5680902497985496,"Qt = CA + λ ASR + µ dis(Mci
f ) + ν min(Mci
f ),
(12)"
REFERENCES,0.5688960515713135,"where the first part means the clean accuracy, the second part means the attack success rate, the third
573"
REFERENCES,0.5697018533440773,"part is aiming to scatter the injection positions in various frequency bands, and the fourth part is
574"
REFERENCES,0.5705076551168412,"aiming to inject as high frequencies in EEG signals as possible. Here, we give a simple example to
575"
REFERENCES,0.5713134568896051,"demonstrate the reward function. For an 10 timepoints long EEG segment xi, exi = F(xi). If the
576"
REFERENCES,0.572119258662369,"Mci
f = {2, 3, 5, 7, 9}, because the minimal distance between each pair in Mci
f is |2 −3| = 1, thus
577"
REFERENCES,0.5729250604351329,"dis(Mci
f ) = 1. The min(Mci
f ) means the lowest position in Mci
f , thus min(Mci
f ) = 2.
578"
REFERENCES,0.5737308622078968,"The analysis of the λ are presented in Table 10. When λ increase, the Attack performance increases
579"
REFERENCES,0.5745366639806607,"while the Clean performance declines slightly.
580"
REFERENCES,0.5753424657534246,"Table 10: Clean (/C) and attack (/B) performance with ASR’s hyperparameter λ, µ = 0.3, ν = 0.005"
REFERENCES,0.5761482675261885,"Dataset
Emotion
Motor Imagery
Epilepsy"
REFERENCES,0.5769540692989524,"Method
Clean
Attack
Clean
Attack
Clean
Attack"
MANIBCI,0.5777598710717163,"0.5
ManiBCI
0.542±0.03
0.847±0.04
0.327±0.02
1.000±0.01
0.500±0.04
0.922±0.04"
MANIBCI,0.5785656728444802,"1.0
ManiBCI
0.537±0.02
0.855±0.03
0.325±0.02
1.000±0.01
0.482±0.03
0.935±0.05"
MANIBCI,0.5793714746172441,"2
ManiBCI
0.535±0.03
0.857±0.02
0.323±0.02
1.000±0.01
0.477±0.04
0.944±0.02"
MANIBCI,0.580177276390008,"Table 7: Clean (/C) and attack (/B) performance with different poisoning rates for ManiBCI and other
baseline methods. The target model is EEGNet for all cases."
MANIBCI,0.580983078162772,"ρ
Dataset
Emotion
Motor Imagery
Epilepsy"
MANIBCI,0.5817888799355359,"Method
Clean
Attack
Clean
Attack
Clean
Attack 0.05"
MANIBCI,0.5825946817082998,"PatchMT
0.390
0.333
0.281
0.791
0.449
0.365
PulseMT
0.488
0.337
0.275
0.788
0.473
0.397
ComprsMT
0.448
0.313
0.269
0.754
0.449
0.329
ManiBCI
0.491
0.566
0.321
1.000
0.460
0.667 0.10"
MANIBCI,0.5834004834810637,"PatchMT
0.443
0.334
0.279
0.785
0.452
0.400
PulseMT
0.445
0.394
0.281
0.796
0.486
0.591
ComprsMT
0.509
0.323
0.270
0.778
0.446
0.337
ManiBCI
0.541
0.718
0.320
1.000
0.452
0.734 0.15"
MANIBCI,0.5842062852538276,"PatchMT
0.455
0.335
0.285
0.805
0.439
0.414
PulseMT
0.438
0.514
0.280
0.787
0.447
0.669
ComprsMT
0.488
0.332
0.275
0.792
0.461
0.374
ManiBCI
0.528
0.805
0.322
1.000
0.460
0.781 0.20"
MANIBCI,0.5850120870265915,"PatchMT
0.481
0.334
0.277
0.816
0.461
0.451
PulseMT
0.447
0.555
0.285
0.810
0.451
0.692
ComprsMT
0.470
0.347
0.270
0.795
0.458
0.394
ManiBCI
0.538
0.773
0.321
1.000
0.447
0.799 0.25"
MANIBCI,0.5858178887993554,"PatchMT
0.487
0.335
0.281
0.820
0.444
0.483
PulseMT
0.466
0.701
0.275
0.815
0.431
0.684
ComprsMT
0.493
0.335
0.269
0.800
0.462
0.427
ManiBCI
0.551
0.836
0.325
1.000
0.447
0.834 0.30"
MANIBCI,0.5866236905721193,"PatchMT
0.459
0.343
0.280
0.809
0.440
0.496
PulseMT
0.486
0.810
0.272
0.816
0.451
0.716
ComprsMT
0.499
0.331
0.269
0.825
0.455
0.481
ManiBCI
0.526
0.829
0.320
1.000
0.451
0.756 0.35"
MANIBCI,0.5874294923448832,"PatchMT
0.437
0.341
0.285
0.805
0.448
0.510
PulseMT
0.437
0.767
0.275
0.837
0.482
0.757
ComprsMT
0.473
0.347
0.265
0.851
0.446
0.517
ManiBCI
0.489
0.763
0.321
1.000
0.453
0.910 0.40"
MANIBCI,0.5882352941176471,"PatchMT
0.490
0.345
0.283
0.824
0.460
0.549
PulseMT
0.454
0.771
0.270
0.825
0.439
0.443
ComprsMT
0.464
0.361
0.269
0.865
0.437
0.450
ManiBCI
0.528
0.849
0.323
1.000
0.477
0.944"
MANIBCI,0.589041095890411,"Table 8: Clean (/C) and attack (/B) performance with frequency injection rate β, γ = 0.5"
MANIBCI,0.5898468976631749,"β
Dataset
Emotion
Motor Imagery
Epilepsy"
MANIBCI,0.5906526994359388,"Method
Clean
Attack
Clean
Attack
Clean
Attack 0.05"
MANIBCI,0.5914585012087027,"PatchMT
0.411
0.334
0.272
0.801
0.476
0.499
PulseMT
0.464
0.752
0.265
0.800
0.505
0.670
ManiBCI
0.522
0.744
0.319
0.999
0.482
0.923 0.10"
MANIBCI,0.5922643029814666,"PatchMT
0.431
0.363
0.283
0.824
0.482
0.540
PulseMT
0.460
0.795
0.270
0.825
0.486
0.704
ManiBCI
0.522
0.813
0.323
1.000
0.500
0.944 0.15"
MANIBCI,0.5930701047542305,"PatchMT
0.413
0.371
0.275
0.821
0.464
0.587
PulseMT
0.449
0.701
0.271
0.821
0.477
0.632
ManiBCI
0.532
0.848
0.322
0.998
0.477
0.947 0.20"
MANIBCI,0.5938759065269944,"PatchMT
0.390
0.377
0.271
0.829
0.479
0.644
PulseMT
0.434
0.769
0.270
0.819
0.484
0.606
ManiBCI
0.529
0.882
0.325
0.999
0.486
0.950 0.25"
MANIBCI,0.5946817082997583,"PatchMT
0.406
0.385
0.267
0.835
0.491
0.673
PulseMT
0.491
0.705
0.275
0.832
0.478
0.566
ManiBCI
0.519
0.865
0.328
0.999
0.486
0.941 0.30"
MANIBCI,0.5954875100725222,"PatchMT
0.417
0.382
0.269
0.831
0.464
0.706
PulseMT
0.425
0.708
0.273
0.844
0.488
0.592
ManiBCI
0.521
0.862
0.330
0.999
0.495
0.940 0.35"
MANIBCI,0.5962933118452861,"PatchMT
0.435
0.373
0.270
0.841
0.475
0.734
PulseMT
0.423
0.621
0.276
0.839
0.479
0.589
ManiBCI
0.527
0.850
0.332
0.998
0.496
0.947 0.40"
MANIBCI,0.59709911361805,"PatchMT
0.438
0.378
0.271
0.843
0.469
0.751
PulseMT
0.481
0.624
0.272
0.845
0.485
0.592
ManiBCI
0.521
0.893
0.330
0.999
0.501
0.951 0.45"
MANIBCI,0.5979049153908138,"PatchMT
0.460
0.385
0.266
0.844
0.481
0.742
PulseMT
0.429
0.633
0.277
0.856
0.499
0.601
ManiBCI
0.519
0.877
0.325
0.999
0.492
0.962 0.50"
MANIBCI,0.5987107171635777,"PatchMT
0.423
0.386
0.263
0.840
0.480
0.752
PulseMT
0.459
0.514
0.273
0.851
0.492
0.610
ManiBCI
0.528
0.893
0.329
1.000
0.497
0.970"
MANIBCI,0.5995165189363416,"Table 9: Clean (/C) and attack (/B) performance with electrodes injection rate γ, β = 0.1"
MANIBCI,0.6003223207091055,"γ
Dataset
Emotion
Motor Imagery
Epilepsy"
MANIBCI,0.6011281224818694,"Method
Clean
Attack
Clean
Attack
Clean
Attack 0.10"
MANIBCI,0.6019339242546333,"PatchMT
0.431
0.334
0.268
0.795
0.470
0.529
PulseMT
0.425
0.498
0.269
0.802
0.502
0.717
ComprsMT
0.407
0.349
0.271
0.805
0.482
0.656
ManiBCI
0.489
0.485
0.235
0.367
0.499
0.814 0.20"
MANIBCI,0.6027397260273972,"PatchMT
0.473
0.335
0.271
0.805
0.464
0.599
PulseMT
0.469
0.707
0.270
0.816
0.502
0.737
ComprsMT
0.465
0.363
0.268
0.812
0.514
0.704
ManiBCI
0.481
0.709
0.235
0.367
0.486
0.860 0.30"
MANIBCI,0.6035455278001611,"PatchMT
0.423
0.343
0.272
0.803
0.486
0.613
PulseMT
0.488
0.767
0.273
0.814
0.506
0.749
ComprsMT
0.451
0.398
0.271
0.811
0.494
0.700
ManiBCI
0.500
0.743
0.235
0.367
0.490
0.883 0.40"
MANIBCI,0.604351329572925,"PatchMT
0.453
0.343
0.270
0.812
0.478
0.525
PulseMT
0.467
0.786
0.271
0.816
0.498
0.688
ComprsMT
0.443
0.361
0.270
0.820
0.506
0.634
ManiBCI
0.491
0.767
0.235
0.367
0.478
0.912 0.50"
MANIBCI,0.6051571313456889,"PatchMT
0.431
0.363
0.270
0.813
0.472
0.552
PulseMT
0.460
0.795
0.269
0.819
0.471
0.710
ComprsMT
0.430
0.366
0.269
0.821
0.503
0.640
ManiBCI
0.522
0.813
0.235
0.367
0.477
0.944 0.60"
MANIBCI,0.6059629331184528,"PatchMT
0.452
0.377
0.267
0.819
0.480
0.549
PulseMT
0.460
0.808
0.269
0.823
0.490
0.672
ComprsMT
0.459
0.368
0.271
0.826
0.499
0.534
ManiBCI
0.488
0.828
0.235
0.367
0.495
0.950 0.70"
MANIBCI,0.6067687348912167,"PatchMT
0.443
0.368
0.272
0.812
0.497
0.525
PulseMT
0.437
0.809
0.270
0.821
0.459
0.716
ComprsMT
0.456
0.366
0.273
0.835
0.492
0.571
ManiBCI
0.527
0.853
0.235
0.367
0.489
0.955 0.80"
MANIBCI,0.6075745366639806,"PatchMT
0.461
0.383
0.268
0.821
0.479
0.573
PulseMT
0.456
0.771
0.267
0.829
0.488
0.699
ComprsMT
0.431
0.383
0.270
0.833
0.488
0.475
ManiBCI
0.539
0.865
0.235
0.367
0.489
0.960 0.90"
MANIBCI,0.6083803384367445,"PatchMT
0.439
0.400
0.271
0.817
0.478
0.540
PulseMT
0.461
0.811
0.269
0.823
0.494
0.694
ComprsMT
0.459
0.389
0.274
0.836
0.490
0.309
ManiBCI
0.520
0.824
0.235
0.367
0.489
0.970 1.00"
MANIBCI,0.6091861402095085,"PatchMT
0.430
0.370
0.267
0.823
0.476
0.526
PulseMT
0.456
0.794
0.271
0.829
0.482
0.716
ComprsMT
0.453
0.376
0.269
0.830
0.490
0.334
ManiBCI
0.532
0.846
0.235
0.367
0.491
0.978"
MANIBCI,0.6099919419822724,"F
More Visualization Results
581"
MANIBCI,0.6107977437550363,"In this section, we plot the reconstructed triggers and masks on three datasets in Section F.1, then
582"
MANIBCI,0.6116035455278002,"plot more visualizations of backdoor samples in Section ??, and plot the learning curve of our
583"
MANIBCI,0.6124093473005641,"reinforcement learning in Section F.3.
584"
MANIBCI,0.613215149073328,"F.1
Neural Cleanse: Reconstruction Trigger Patterns
585"
MANIBCI,0.6140209508460919,"Here, we present more visualization in Figure 9, Figure 10, and Figure 11 of the reconstructed trigger
586"
MANIBCI,0.6148267526188558,"patterns and mask patterns for each possible label on three dataset (i.e., the CHB-MIT dataset, the
587"
MANIBCI,0.6156325543916197,"BCIC-IV-2a dataset and the SEED dataset) the target model is EEGnet. It can be observed that the
588"
MANIBCI,0.6164383561643836,"reconstructed trigger patterns and mask patterns of the clean models and ManiBCI backdoor-injected
589"
MANIBCI,0.6172441579371475,"models are very similar to each other. Thus, our ManiBCI backdoor attack can easily bypass the
590"
MANIBCI,0.6180499597099114,"defense of Neural Cleanse.
591"
MANIBCI,0.6188557614826753,"0
50
100
150
200
250 0 20"
MANIBCI,0.6196615632554392,"0
50
100
150
200
250 0 20"
MANIBCI,0.6204673650282031,"0
50
100
150
200
250 0 20"
MANIBCI,0.621273166800967,"0
50
100
150
200
250 0 20"
MANIBCI,0.6220789685737309,"0
50
100
150
200
250 0 20"
MANIBCI,0.6228847703464948,"0
50
100
150
200
250 0 20"
MANIBCI,0.6236905721192587,"0
50
100
150
200
250 0 20"
MANIBCI,0.6244963738920226,"0
50
100
150
200
250 0 20"
MANIBCI,0.6253021756647864,"0
50
100
150
200
250 0 20"
MANIBCI,0.6261079774375503,"0
50
100
150
200
250 0 20"
MANIBCI,0.6269137792103142,"0
50
100
150
200
250 0 20"
MANIBCI,0.6277195809830781,"0
50
100
150
200
250 0 20"
MANIBCI,0.628525382755842,"0
50
100
150
200
250 0 20"
MANIBCI,0.6293311845286059,"0
50
100
150
200
250 0 20"
MANIBCI,0.6301369863013698,"0
50
100
150
200
250 0 20"
MANIBCI,0.6309427880741337,"0
50
100
150
200
250 0 20"
MANIBCI,0.6317485898468976,"Clean model / Class 3 : Reconstructed Trigger Pattern 
ManiBCI backdoor model / Class 3 : Reconstructed Trigger Pattern"
MANIBCI,0.6325543916196615,"Clean model / Class 3 : Reconstructed Mask Pattern 
ManiBCI backdoor model / Class 3 : Reconstructed Mask Pattern"
MANIBCI,0.6333601933924254,"Clean model / Class 2 : Reconstructed Trigger Pattern 
ManiBCI backdoor model / Class 2 : Reconstructed Trigger Pattern"
MANIBCI,0.6341659951651893,"Clean model / Class 2 : Reconstructed Mask Pattern 
ManiBCI backdoor model / Class 2 : Reconstructed Mask Pattern"
MANIBCI,0.6349717969379532,"Clean model / Class 1 : Reconstructed Trigger Pattern 
ManiBCI backdoor model / Class 1 : Reconstructed Trigger Pattern"
MANIBCI,0.6357775987107172,"Clean model / Class 1 : Reconstructed Mask Pattern 
ManiBCI backdoor model / Class 1 : Reconstructed Mask Pattern"
MANIBCI,0.636583400483481,"Clean model / Class 0 : Reconstructed Trigger Pattern 
ManiBCI backdoor model / Class 0 : Reconstructed Trigger Pattern"
MANIBCI,0.637389202256245,"Clean model / Class 0 : Reconstructed Mask Pattern 
ManiBCI backdoor model / Class 0 : Reconstructed Mask Pattern"
MANIBCI,0.6381950040290089,"0.0
0.2
0.4
0.6
0.8
1.0"
MANIBCI,0.6390008058017728,"Figure 9: The reconstructed trigger patterns and mask patterns for each possible class in the CHB-MIT
dataset. The results in the left column are reconstructed based on the clean model, the results in the
right column are reconstructed based on the backdoor model. The EEG segments in the CHB-MIT
dataset have 23 electrodes and 256 timepoints."
MANIBCI,0.6398066075745367,"0
50
100
150
200 0 20"
MANIBCI,0.6406124093473006,"0
50
100
150
200 0 20"
MANIBCI,0.6414182111200645,"0
50
100
150
200 0 20"
MANIBCI,0.6422240128928284,"0
50
100
150
200 0 20"
MANIBCI,0.6430298146655923,"0
50
100
150
200 0 20"
MANIBCI,0.6438356164383562,"0
50
100
150
200 0 20"
MANIBCI,0.6446414182111201,"0
50
100
150
200 0 20"
MANIBCI,0.645447219983884,"0
50
100
150
200 0 20"
MANIBCI,0.6462530217566479,ManiBCI backdoor model / Class 3 : Reconstructed Trigger Pattern
MANIBCI,0.6470588235294118,ManiBCI backdoor model / Class 3 : Reconstructed Mask Pattern
MANIBCI,0.6478646253021757,ManiBCI backdoor model / Class 2 : Reconstructed Trigger Pattern
MANIBCI,0.6486704270749396,ManiBCI backdoor model / Class 2 : Reconstructed Mask Pattern
MANIBCI,0.6494762288477035,ManiBCI backdoor model / Class 1 : Reconstructed Trigger Pattern
MANIBCI,0.6502820306204674,ManiBCI backdoor model / Class 1 : Reconstructed Mask Pattern
MANIBCI,0.6510878323932313,ManiBCI backdoor model / Class 0 : Reconstructed Trigger Pattern
MANIBCI,0.6518936341659952,ManiBCI backdoor model / Class 0 : Reconstructed Mask Pattern
MANIBCI,0.6526994359387591,"0
50
100
150
200 0 20"
MANIBCI,0.6535052377115229,"0
50
100
150
200 0 20"
MANIBCI,0.6543110394842868,"0
50
100
150
200 0 20"
MANIBCI,0.6551168412570507,"0
50
100
150
200 0 20"
MANIBCI,0.6559226430298146,"0
50
100
150
200 0 20"
MANIBCI,0.6567284448025785,"0
50
100
150
200 0 20"
MANIBCI,0.6575342465753424,"0
50
100
150
200 0 20"
MANIBCI,0.6583400483481063,"0
50
100
150
200 0 20"
MANIBCI,0.6591458501208702,Clean model / Class 0 : Reconstructed Trigger Pattern
MANIBCI,0.6599516518936341,Clean model / Class 1 : Reconstructed Mask Pattern
MANIBCI,0.660757453666398,Clean model / Class 0 : Reconstructed Mask Pattern
MANIBCI,0.661563255439162,Clean model / Class 2 : Reconstructed Mask Pattern
MANIBCI,0.6623690572119258,Clean model / Class 3: Reconstructed Mask Pattern
MANIBCI,0.6631748589846898,Clean model / Class 1 : Reconstructed Trigger Pattern
MANIBCI,0.6639806607574537,Clean model / Class 2 : Reconstructed Trigger Pattern
MANIBCI,0.6647864625302176,Clean model / Class 3 : Reconstructed Trigger Pattern
MANIBCI,0.6655922643029815,"0.0
0.2
0.4
0.6
0.8
1.0"
MANIBCI,0.6663980660757454,"Figure 10: The reconstructed trigger patterns and mask patterns for each possible class in the MI
dataset. The results in the left column are reconstructed based on the clean model, the results in the
right column are reconstructed based on the backdoor model. The EEG segments in the MI dataset
have 22 electrodes and 250 timepoints."
MANIBCI,0.6672038678485093,"0
25
50
75
100
125
150
175 0 20 40 60"
MANIBCI,0.6680096696212732,"0
25
50
75
100
125
150
175 0 20 40 60"
MANIBCI,0.6688154713940371,"0
25
50
75
100
125
150
175 0 20 40 60"
MANIBCI,0.669621273166801,"0
25
50
75
100
125
150
175 0 20 40 60"
MANIBCI,0.6704270749395649,"0
25
50
75
100
125
150
175 0 20 40 60"
MANIBCI,0.6712328767123288,"0
25
50
75
100
125
150
175 0 20 40 60"
MANIBCI,0.6720386784850927,"0
25
50
75
100
125
150
175 0 20 40 60"
MANIBCI,0.6728444802578566,"0
25
50
75
100
125
150
175 0 20 40 60"
MANIBCI,0.6736502820306205,"0
25
50
75
100
125
150
175 0 20 40 60"
MANIBCI,0.6744560838033844,"0
25
50
75
100
125
150
175 0 20 40 60"
MANIBCI,0.6752618855761483,"0
25
50
75
100
125
150
175 0 20 40 60"
MANIBCI,0.6760676873489122,"0
25
50
75
100
125
150
175 0 20 40 60"
MANIBCI,0.6768734891216761,ManiBCI backdoor model / Class 2 : Reconstructed Trigger Pattern
MANIBCI,0.67767929089444,ManiBCI backdoor model / Class 2 : Reconstructed Mask Pattern
MANIBCI,0.6784850926672039,"Clean model / Class 0 : Reconstructed Mask Pattern 
ManiBCI backdoor model / Class 0 : Reconstructed Mask Pattern"
MANIBCI,0.6792908944399678,"Clean model / Class 0 : Reconstructed Trigger Pattern 
ManiBCI backdoor model / Class 0 : Reconstructed Trigger Pattern"
MANIBCI,0.6800966962127317,"Clean model / Class 1 : Reconstructed Mask Pattern 
ManiBCI backdoor model / Class 1 : Reconstructed Mask Pattern"
MANIBCI,0.6809024979854955,"Clean model / Class 1 : Reconstructed Trigger Pattern 
ManiBCI backdoor model / Class 1 : Reconstructed Trigger Pattern"
MANIBCI,0.6817082997582594,Clean model / Class 2 : Reconstructed Mask Pattern
MANIBCI,0.6825141015310233,Clean model / Class 2 : Reconstructed Trigger Pattern
MANIBCI,0.6833199033037872,"0.0
0.2
0.4
0.6
0.8
1.0"
MANIBCI,0.6841257050765511,"Figure 11: The reconstructed trigger patterns and mask patterns for each possible class in the ER
dataset (i.e., SEED dataset). The results in the left column are reconstructed based on the clean model,
the results in the right column are reconstructed based on the backdoor model. The EEG segments in
the SEED dataset have 62 electrodes and 200 timepoints."
MANIBCI,0.684931506849315,"F.2
Visualization of Backdoor Attack Samples
592"
MANIBCI,0.6857373086220789,"We present more visualization of the backdoor attack samples generated by our ManiBCI on ER
593"
MANIBCI,0.6865431103948428,"dataset and MI dataset in Fig 12 and 13. The x-axis is the timepoints, the y-axis is the normalized
594"
MANIBCI,0.6873489121676067,"amplitude. Top row: w.o. HF loss; Bottom row: with HF loss. Each column indicates each possible
595"
MANIBCI,0.6881547139403706,"class.
596"
MANIBCI,0.6889605157131345,"0
25
50
75
100
125
150
175
200 1 0 1"
CLEAN EEG,0.6897663174858985,"2
Clean EEG
Trigger 0 Injected EEG"
CLEAN EEG,0.6905721192586624,"0
25
50
75
100
125
150
175
200 1 0 1"
CLEAN EEG,0.6913779210314263,"2
Clean EEG
Trigger 1 Injected EEG"
CLEAN EEG,0.6921837228041902,"0
25
50
75
100
125
150
175
200 1 0 1"
CLEAN EEG,0.6929895245769541,"2
Clean EEG
Trigger 2 Injected EEG"
CLEAN EEG,0.693795326349718,"0
25
50
75
100
125
150
175
200 1 0 1"
CLEAN EEG,0.6946011281224819,"2
Clean EEG
Trigger 0 Injected EEG
Residual"
CLEAN EEG,0.6954069298952458,"0
25
50
75
100
125
150
175
200 1 0 1"
CLEAN EEG,0.6962127316680097,"2
Clean EEG
Trigger 1 Injected EEG
Residual"
CLEAN EEG,0.6970185334407736,"0
25
50
75
100
125
150
175
200 1 0 1"
CLEAN EEG,0.6978243352135375,"2
Clean EEG
Trigger 2 Injected EEG
Residual"
CLEAN EEG,0.6986301369863014,"Trigger from Class 0
Trigger from Class 1
Trigger from Class 2"
CLEAN EEG,0.6994359387590653,"w/o HF loss
ManiBCI"
CLEAN EEG,0.7002417405318292,"Figure 12: The Clean EEG (Blue), Trigger-injected EEG (Orange) and the Residual (Red) of the ER
dataset."
CLEAN EEG,0.7010475423045931,"0
50
100
150
200
250
40 20 0 20 40"
CLEAN EEG,0.701853344077357,"60
Clean EEG
Trigger 0 Injected EEG"
CLEAN EEG,0.7026591458501209,"0
50
100
150
200
250
40 20 0 20 40"
CLEAN EEG,0.7034649476228848,"60
Clean EEG
Trigger 1 Injected EEG"
CLEAN EEG,0.7042707493956487,"0
50
100
150
200
250 50 25 0 25"
CLEAN EEG,0.7050765511684126,"50
Clean EEG
Trigger 2 Injected EEG"
CLEAN EEG,0.7058823529411765,"0
50
100
150
200
250
40 20 0 20 40"
CLEAN EEG,0.7066881547139404,"60
Clean EEG
Trigger 3 Injected EEG"
CLEAN EEG,0.7074939564867043,"0
50
100
150
200
250
40 20 0 20 40"
CLEAN EEG,0.7082997582594682,"60
Clean EEG
Trigger 0 Injected EEG
Residual"
CLEAN EEG,0.709105560032232,"0
50
100
150
200
250
40 20 0 20 40"
CLEAN EEG,0.7099113618049959,"60
Clean EEG
Trigger 1 Injected EEG
Residual"
CLEAN EEG,0.7107171635777598,"0
50
100
150
200
250
40 20 0 20 40"
CLEAN EEG,0.7115229653505237,"60
Clean EEG
Trigger 2 Injected EEG
Residual"
CLEAN EEG,0.7123287671232876,"0
50
100
150
200
250
40 20 0 20 40"
CLEAN EEG,0.7131345688960515,"60
Clean EEG
Trigger 3 Injected EEG
Residual"
CLEAN EEG,0.7139403706688154,"Trigger from Class 0
Trigger from Class 1
Trigger from Class 2
Trigger from Class 3"
CLEAN EEG,0.7147461724415793,"w/o HF loss
ManiBCI"
CLEAN EEG,0.7155519742143432,"Figure 13: The Clean EEG (Blue), Trigger-injected EEG (Orange) and the Residual (Red) of the MI
dataset."
CLEAN EEG,0.7163577759871071,"F.3
Visualization of Learning Curves of Reinforcement Learning
597"
CLEAN EEG,0.717163577759871,"We present the visualization of the learning curves of the reinforcement learning of three dataset in
598"
CLEAN EEG,0.717969379532635,"Fig 14. We can see the effectiveness of our reinforcement, which converged within 50 epochs on the
599"
CLEAN EEG,0.7187751813053989,"ER dataset, that is, only trained 50 backdoor models with different injection strategies. Our RL is
600"
CLEAN EEG,0.7195809830781628,"more effective on the MI dataset and ED dataset, which finds a good strategy within less 10 epochs.
601"
CLEAN EEG,0.7203867848509267,"Our RL is robust when learning strategies for different triggers as demonstrated in Fig 14(c) and (d),
602"
CLEAN EEG,0.7211925866236906,"where the learning curves are quite similar when RL is performing on different triggers.
603"
CLEAN EEG,0.7219983883964545,"0
50
100
150
200
250
0.0 0.2 0.4 0.6 0.8 1.0 Value"
CLEAN EEG,0.7228041901692184,Training ACC and ASR
CLEAN EEG,0.7236099919419823,"ACC
ASR"
CLEAN EEG,0.7244157937147462,"0
50
100
150
200
250
0.0 0.2 0.4 0.6 0.8 1.0 Value"
CLEAN EEG,0.7252215954875101,Sorted ASR and corresponding ACC
CLEAN EEG,0.726027397260274,"ACC
ASR"
CLEAN EEG,0.7268331990330379,"epoch
epoch"
CLEAN EEG,0.7276390008058018,(a) The RL curve on the Emotion Recognition dataset
CLEAN EEG,0.7284448025785657,"0
50
100
150
200
250 0.2 0.4 0.6 0.8 1.0 Value"
CLEAN EEG,0.7292506043513296,Training ACC and ASR
CLEAN EEG,0.7300564061240935,"ACC
ASR"
CLEAN EEG,0.7308622078968574,"0
50
100
150
200
250 0.2 0.4 0.6 0.8 1.0 Value"
CLEAN EEG,0.7316680096696213,Sorted ASR and corresponding ACC
CLEAN EEG,0.7324738114423852,"ACC
ASR"
CLEAN EEG,0.7332796132151491,"(c) The RL curve on the Epilepsy Detection dataset
epoch
epoch"
CLEAN EEG,0.734085414987913,"0
50
100
150
200
250
0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Value"
CLEAN EEG,0.7348912167606769,Training ACC and ASR
CLEAN EEG,0.7356970185334408,"ACC
ASR"
CLEAN EEG,0.7365028203062046,"0
50
100
150
200
250
0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Value"
CLEAN EEG,0.7373086220789685,Sorted ASR and corresponding ACC
CLEAN EEG,0.7381144238517324,"ACC
ASR"
CLEAN EEG,0.7389202256244963,"epoch
epoch
(b) The RL curve on the Moto Imagery dataset"
CLEAN EEG,0.7397260273972602,"0
50
100
150
200
250
0.2 0.4 0.6 0.8 1.0 Value"
CLEAN EEG,0.7405318291700241,Training ACC and ASR
CLEAN EEG,0.741337630942788,"ACC
ASR"
CLEAN EEG,0.7421434327155519,"0
50
100
150
200
250
0.2 0.4 0.6 0.8 1.0 Value"
CLEAN EEG,0.7429492344883158,Sorted ASR and corresponding ACC
CLEAN EEG,0.7437550362610797,"ACC
ASR"
CLEAN EEG,0.7445608380338437,"epoch
epoch"
CLEAN EEG,0.7453666398066076,"(d) The RL curve on the Epilepsy Detection dataset, for another tirrger with label 2"
CLEAN EEG,0.7461724415793715,"Figure 14: The learning curves of RL on three datasets. The right column is the curve we sort the
(ACC,ASR) according to the ASR. The backdoor models are all EEGNet."
CLEAN EEG,0.7469782433521354,"NeurIPS Paper Checklist
604"
CLAIMS,0.7477840451248993,"1. Claims
605"
CLAIMS,0.7485898468976632,"Question: Do the main claims made in the abstract and introduction accurately reflect the
606"
CLAIMS,0.7493956486704271,"paper’s contributions and scope?
607"
CLAIMS,0.750201450443191,"Answer: [Yes]
608"
CLAIMS,0.7510072522159549,"Justification: We made clear claims of our contributions in the abstract and introduction.
609"
CLAIMS,0.7518130539887188,"Guidelines:
610"
CLAIMS,0.7526188557614827,"• The answer NA means that the abstract and introduction do not include the claims
611"
CLAIMS,0.7534246575342466,"made in the paper.
612"
CLAIMS,0.7542304593070105,"• The abstract and/or introduction should clearly state the claims made, including the
613"
CLAIMS,0.7550362610797744,"contributions made in the paper and important assumptions and limitations. A No or
614"
CLAIMS,0.7558420628525383,"NA answer to this question will not be perceived well by the reviewers.
615"
CLAIMS,0.7566478646253022,"• The claims made should match theoretical and experimental results, and reflect how
616"
CLAIMS,0.7574536663980661,"much the results can be expected to generalize to other settings.
617"
CLAIMS,0.75825946817083,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
618"
CLAIMS,0.7590652699435939,"are not attained by the paper.
619"
LIMITATIONS,0.7598710717163578,"2. Limitations
620"
LIMITATIONS,0.7606768734891217,"Question: Does the paper discuss the limitations of the work performed by the authors?
621"
LIMITATIONS,0.7614826752618856,"Answer: [Yes]
622"
LIMITATIONS,0.7622884770346495,"Justification: We discussed the limitations of our proposed method in Appendix.
623"
LIMITATIONS,0.7630942788074134,"Guidelines:
624"
LIMITATIONS,0.7639000805801772,"• The answer NA means that the paper has no limitation while the answer No means that
625"
LIMITATIONS,0.7647058823529411,"the paper has limitations, but those are not discussed in the paper.
626"
LIMITATIONS,0.765511684125705,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
627"
LIMITATIONS,0.7663174858984689,"• The paper should point out any strong assumptions and how robust the results are to
628"
LIMITATIONS,0.7671232876712328,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
629"
LIMITATIONS,0.7679290894439967,"model well-specification, asymptotic approximations only holding locally). The authors
630"
LIMITATIONS,0.7687348912167606,"should reflect on how these assumptions might be violated in practice and what the
631"
LIMITATIONS,0.7695406929895245,"implications would be.
632"
LIMITATIONS,0.7703464947622884,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
633"
LIMITATIONS,0.7711522965350524,"only tested on a few datasets or with a few runs. In general, empirical results often
634"
LIMITATIONS,0.7719580983078163,"depend on implicit assumptions, which should be articulated.
635"
LIMITATIONS,0.7727639000805802,"• The authors should reflect on the factors that influence the performance of the approach.
636"
LIMITATIONS,0.7735697018533441,"For example, a facial recognition algorithm may perform poorly when image resolution
637"
LIMITATIONS,0.774375503626108,"is low or images are taken in low lighting. Or a speech-to-text system might not be
638"
LIMITATIONS,0.7751813053988719,"used reliably to provide closed captions for online lectures because it fails to handle
639"
LIMITATIONS,0.7759871071716358,"technical jargon.
640"
LIMITATIONS,0.7767929089443997,"• The authors should discuss the computational efficiency of the proposed algorithms
641"
LIMITATIONS,0.7775987107171636,"and how they scale with dataset size.
642"
LIMITATIONS,0.7784045124899275,"• If applicable, the authors should discuss possible limitations of their approach to
643"
LIMITATIONS,0.7792103142626914,"address problems of privacy and fairness.
644"
LIMITATIONS,0.7800161160354553,"• While the authors might fear that complete honesty about limitations might be used by
645"
LIMITATIONS,0.7808219178082192,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
646"
LIMITATIONS,0.7816277195809831,"limitations that aren’t acknowledged in the paper. The authors should use their best
647"
LIMITATIONS,0.782433521353747,"judgment and recognize that individual actions in favor of transparency play an impor-
648"
LIMITATIONS,0.7832393231265109,"tant role in developing norms that preserve the integrity of the community. Reviewers
649"
LIMITATIONS,0.7840451248992748,"will be specifically instructed to not penalize honesty concerning limitations.
650"
THEORY ASSUMPTIONS AND PROOFS,0.7848509266720387,"3. Theory Assumptions and Proofs
651"
THEORY ASSUMPTIONS AND PROOFS,0.7856567284448026,"Question: For each theoretical result, does the paper provide the full set of assumptions and
652"
THEORY ASSUMPTIONS AND PROOFS,0.7864625302175665,"a complete (and correct) proof?
653"
THEORY ASSUMPTIONS AND PROOFS,0.7872683319903304,"Answer: [NA]
654"
THEORY ASSUMPTIONS AND PROOFS,0.7880741337630943,"Justification: Our paper dose not include theoretical results.
655"
THEORY ASSUMPTIONS AND PROOFS,0.7888799355358582,"Guidelines:
656"
THEORY ASSUMPTIONS AND PROOFS,0.7896857373086221,"• The answer NA means that the paper does not include theoretical results.
657"
THEORY ASSUMPTIONS AND PROOFS,0.790491539081386,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
658"
THEORY ASSUMPTIONS AND PROOFS,0.7912973408541499,"referenced.
659"
THEORY ASSUMPTIONS AND PROOFS,0.7921031426269137,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
660"
THEORY ASSUMPTIONS AND PROOFS,0.7929089443996776,"• The proofs can either appear in the main paper or the supplemental material, but if
661"
THEORY ASSUMPTIONS AND PROOFS,0.7937147461724415,"they appear in the supplemental material, the authors are encouraged to provide a short
662"
THEORY ASSUMPTIONS AND PROOFS,0.7945205479452054,"proof sketch to provide intuition.
663"
THEORY ASSUMPTIONS AND PROOFS,0.7953263497179693,"• Inversely, any informal proof provided in the core of the paper should be complemented
664"
THEORY ASSUMPTIONS AND PROOFS,0.7961321514907332,"by formal proofs provided in appendix or supplemental material.
665"
THEORY ASSUMPTIONS AND PROOFS,0.7969379532634971,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
666"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.797743755036261,"4. Experimental Result Reproducibility
667"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.798549556809025,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
668"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7993553585817889,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
669"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8001611603545528,"of the paper (regardless of whether the code and data are provided or not)?
670"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8009669621273167,"Answer: [Yes]
671"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8017727639000806,"Justification: We demonstrated our method and the experiment settings clearly in Section
672"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8025785656728445,"3.1 and Section 4.2. The implementation details of all baselines are written in appendix.
673"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8033843674456084,"Guidelines:
674"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8041901692183723,"• The answer NA means that the paper does not include experiments.
675"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8049959709911362,"• If the paper includes experiments, a No answer to this question will not be perceived
676"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8058017727639001,"well by the reviewers: Making the paper reproducible is important, regardless of
677"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.806607574536664,"whether the code and data are provided or not.
678"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8074133763094279,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
679"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8082191780821918,"to make their results reproducible or verifiable.
680"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8090249798549557,"• Depending on the contribution, reproducibility can be accomplished in various ways.
681"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8098307816277196,"For example, if the contribution is a novel architecture, describing the architecture fully
682"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8106365834004835,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
683"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8114423851732474,"be necessary to either make it possible for others to replicate the model with the same
684"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8122481869460113,"dataset, or provide access to the model. In general. releasing code and data is often
685"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8130539887187752,"one good way to accomplish this, but reproducibility can also be provided via detailed
686"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8138597904915391,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
687"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.814665592264303,"of a large language model), releasing of a model checkpoint, or other means that are
688"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8154713940370669,"appropriate to the research performed.
689"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8162771958098308,"• While NeurIPS does not require releasing code, the conference does require all submis-
690"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8170829975825947,"sions to provide some reasonable avenue for reproducibility, which may depend on the
691"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8178887993553586,"nature of the contribution. For example
692"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8186946011281225,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
693"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8195004029008863,"to reproduce that algorithm.
694"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8203062046736502,"(b) If the contribution is primarily a new model architecture, the paper should describe
695"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8211120064464141,"the architecture clearly and fully.
696"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.821917808219178,"(c) If the contribution is a new model (e.g., a large language model), then there should
697"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8227236099919419,"either be a way to access this model for reproducing the results or a way to reproduce
698"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8235294117647058,"the model (e.g., with an open-source dataset or instructions for how to construct
699"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8243352135374697,"the dataset).
700"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8251410153102336,"(d) We recognize that reproducibility may be tricky in some cases, in which case
701"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8259468170829976,"authors are welcome to describe the particular way they provide for reproducibility.
702"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8267526188557615,"In the case of closed-source models, it may be that access to the model is limited in
703"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8275584206285254,"some way (e.g., to registered users), but it should be possible for other researchers
704"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8283642224012893,"to have some path to reproducing or verifying the results.
705"
OPEN ACCESS TO DATA AND CODE,0.8291700241740532,"5. Open access to data and code
706"
OPEN ACCESS TO DATA AND CODE,0.8299758259468171,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
707"
OPEN ACCESS TO DATA AND CODE,0.830781627719581,"tions to faithfully reproduce the main experimental results, as described in supplemental
708"
OPEN ACCESS TO DATA AND CODE,0.8315874294923449,"material?
709"
OPEN ACCESS TO DATA AND CODE,0.8323932312651088,"Answer: [No]
710"
OPEN ACCESS TO DATA AND CODE,0.8331990330378727,"Justification: Sorry for not providing the whole code at the submitting phase as we have no
711"
OPEN ACCESS TO DATA AND CODE,0.8340048348106366,"time to organize our code well. However, we will publish our code after the anonymous
712"
OPEN ACCESS TO DATA AND CODE,0.8348106365834005,"period (Or we can organize and upload our code during rebuttal phase if possible).
713"
OPEN ACCESS TO DATA AND CODE,0.8356164383561644,"Guidelines:
714"
OPEN ACCESS TO DATA AND CODE,0.8364222401289283,"• The answer NA means that paper does not include experiments requiring code.
715"
OPEN ACCESS TO DATA AND CODE,0.8372280419016922,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
716"
OPEN ACCESS TO DATA AND CODE,0.8380338436744561,"public/guides/CodeSubmissionPolicy) for more details.
717"
OPEN ACCESS TO DATA AND CODE,0.83883964544722,"• While we encourage the release of code and data, we understand that this might not be
718"
OPEN ACCESS TO DATA AND CODE,0.8396454472199839,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
719"
OPEN ACCESS TO DATA AND CODE,0.8404512489927478,"including code, unless this is central to the contribution (e.g., for a new open-source
720"
OPEN ACCESS TO DATA AND CODE,0.8412570507655117,"benchmark).
721"
OPEN ACCESS TO DATA AND CODE,0.8420628525382756,"• The instructions should contain the exact command and environment needed to run to
722"
OPEN ACCESS TO DATA AND CODE,0.8428686543110395,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
723"
OPEN ACCESS TO DATA AND CODE,0.8436744560838034,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
724"
OPEN ACCESS TO DATA AND CODE,0.8444802578565673,"• The authors should provide instructions on data access and preparation, including how
725"
OPEN ACCESS TO DATA AND CODE,0.8452860596293312,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
726"
OPEN ACCESS TO DATA AND CODE,0.8460918614020951,"• The authors should provide scripts to reproduce all experimental results for the new
727"
OPEN ACCESS TO DATA AND CODE,0.846897663174859,"proposed method and baselines. If only a subset of experiments are reproducible, they
728"
OPEN ACCESS TO DATA AND CODE,0.8477034649476228,"should state which ones are omitted from the script and why.
729"
OPEN ACCESS TO DATA AND CODE,0.8485092667203867,"• At submission time, to preserve anonymity, the authors should release anonymized
730"
OPEN ACCESS TO DATA AND CODE,0.8493150684931506,"versions (if applicable).
731"
OPEN ACCESS TO DATA AND CODE,0.8501208702659145,"• Providing as much information as possible in supplemental material (appended to the
732"
OPEN ACCESS TO DATA AND CODE,0.8509266720386784,"paper) is recommended, but including URLs to data and code is permitted.
733"
OPEN ACCESS TO DATA AND CODE,0.8517324738114423,"6. Experimental Setting/Details
734"
OPEN ACCESS TO DATA AND CODE,0.8525382755842063,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
735"
OPEN ACCESS TO DATA AND CODE,0.8533440773569702,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
736"
OPEN ACCESS TO DATA AND CODE,0.8541498791297341,"results?
737"
OPEN ACCESS TO DATA AND CODE,0.854955680902498,"Answer: [Yes]
738"
OPEN ACCESS TO DATA AND CODE,0.8557614826752619,"Justification: We demonstrated our method and the experiment settings clearly in Section3.1
739"
OPEN ACCESS TO DATA AND CODE,0.8565672844480258,"and Section 4.2. The implementation details of all baselines are written in appendix.
740"
OPEN ACCESS TO DATA AND CODE,0.8573730862207897,"Guidelines:
741"
OPEN ACCESS TO DATA AND CODE,0.8581788879935536,"• The answer NA means that the paper does not include experiments.
742"
OPEN ACCESS TO DATA AND CODE,0.8589846897663175,"• The experimental setting should be presented in the core of the paper to a level of detail
743"
OPEN ACCESS TO DATA AND CODE,0.8597904915390814,"that is necessary to appreciate the results and make sense of them.
744"
OPEN ACCESS TO DATA AND CODE,0.8605962933118453,"• The full details can be provided either with the code, in appendix, or as supplemental
745"
OPEN ACCESS TO DATA AND CODE,0.8614020950846092,"material.
746"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8622078968573731,"7. Experiment Statistical Significance
747"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.863013698630137,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
748"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8638195004029009,"information about the statistical significance of the experiments?
749"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8646253021756648,"Answer: [Yes]
750"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8654311039484287,"Justification: We give all the statistical significance of our experiments.
751"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8662369057211926,"Guidelines:
752"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8670427074939565,"• The answer NA means that the paper does not include experiments.
753"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8678485092667204,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
754"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8686543110394843,"dence intervals, or statistical significance tests, at least for the experiments that support
755"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8694601128122482,"the main claims of the paper.
756"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8702659145850121,"• The factors of variability that the error bars are capturing should be clearly stated (for
757"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.871071716357776,"example, train/test split, initialization, random drawing of some parameter, or overall
758"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8718775181305399,"run with given experimental conditions).
759"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8726833199033038,"• The method for calculating the error bars should be explained (closed form formula,
760"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8734891216760677,"call to a library function, bootstrap, etc.)
761"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8742949234488316,"• The assumptions made should be given (e.g., Normally distributed errors).
762"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8751007252215954,"• It should be clear whether the error bar is the standard deviation or the standard error
763"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8759065269943593,"of the mean.
764"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8767123287671232,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
765"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8775181305398871,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
766"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.878323932312651,"of Normality of errors is not verified.
767"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.879129734085415,"• For asymmetric distributions, the authors should be careful not to show in tables or
768"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8799355358581789,"figures symmetric error bars that would yield results that are out of range (e.g. negative
769"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8807413376309428,"error rates).
770"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8815471394037067,"• If error bars are reported in tables or plots, The authors should explain in the text how
771"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8823529411764706,"they were calculated and reference the corresponding figures or tables in the text.
772"
EXPERIMENTS COMPUTE RESOURCES,0.8831587429492345,"8. Experiments Compute Resources
773"
EXPERIMENTS COMPUTE RESOURCES,0.8839645447219984,"Question: For each experiment, does the paper provide sufficient information on the com-
774"
EXPERIMENTS COMPUTE RESOURCES,0.8847703464947623,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
775"
EXPERIMENTS COMPUTE RESOURCES,0.8855761482675262,"the experiments?
776"
EXPERIMENTS COMPUTE RESOURCES,0.8863819500402901,"Answer: [Yes]
777"
EXPERIMENTS COMPUTE RESOURCES,0.887187751813054,"Justification: Yes, we provide the type of GPU and version of CUDA in Appendix D.
778"
EXPERIMENTS COMPUTE RESOURCES,0.8879935535858179,"Guidelines:
779"
EXPERIMENTS COMPUTE RESOURCES,0.8887993553585818,"• The answer NA means that the paper does not include experiments.
780"
EXPERIMENTS COMPUTE RESOURCES,0.8896051571313457,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
781"
EXPERIMENTS COMPUTE RESOURCES,0.8904109589041096,"or cloud provider, including relevant memory and storage.
782"
EXPERIMENTS COMPUTE RESOURCES,0.8912167606768735,"• The paper should provide the amount of compute required for each of the individual
783"
EXPERIMENTS COMPUTE RESOURCES,0.8920225624496374,"experimental runs as well as estimate the total compute.
784"
EXPERIMENTS COMPUTE RESOURCES,0.8928283642224013,"• The paper should disclose whether the full research project required more compute
785"
EXPERIMENTS COMPUTE RESOURCES,0.8936341659951652,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
786"
EXPERIMENTS COMPUTE RESOURCES,0.8944399677679291,"didn’t make it into the paper).
787"
CODE OF ETHICS,0.895245769540693,"9. Code Of Ethics
788"
CODE OF ETHICS,0.8960515713134569,"Question: Does the research conducted in the paper conform, in every respect, with the
789"
CODE OF ETHICS,0.8968573730862208,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
790"
CODE OF ETHICS,0.8976631748589847,"Answer: [Yes]
791"
CODE OF ETHICS,0.8984689766317486,"Justification: Yes, we conform with the NeurIPS Code of Ethics.
792"
CODE OF ETHICS,0.8992747784045125,"Guidelines:
793"
CODE OF ETHICS,0.9000805801772764,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
794"
CODE OF ETHICS,0.9008863819500403,"• If the authors answer No, they should explain the special circumstances that require a
795"
CODE OF ETHICS,0.9016921837228042,"deviation from the Code of Ethics.
796"
CODE OF ETHICS,0.9024979854955681,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
797"
CODE OF ETHICS,0.9033037872683319,"eration due to laws or regulations in their jurisdiction).
798"
BROADER IMPACTS,0.9041095890410958,"10. Broader Impacts
799"
BROADER IMPACTS,0.9049153908138597,"Question: Does the paper discuss both potential positive societal impacts and negative
800"
BROADER IMPACTS,0.9057211925866236,"societal impacts of the work performed?
801"
BROADER IMPACTS,0.9065269943593876,"Answer: [Yes]
802"
BROADER IMPACTS,0.9073327961321515,"Justification: We discuss the broader impacts of our backdoor attacks in Appendix.
803"
BROADER IMPACTS,0.9081385979049154,"Guidelines:
804"
BROADER IMPACTS,0.9089443996776793,"• The answer NA means that there is no societal impact of the work performed.
805"
BROADER IMPACTS,0.9097502014504432,"• If the authors answer NA or No, they should explain why their work has no societal
806"
BROADER IMPACTS,0.9105560032232071,"impact or why the paper does not address societal impact.
807"
BROADER IMPACTS,0.911361804995971,"• Examples of negative societal impacts include potential malicious or unintended uses
808"
BROADER IMPACTS,0.9121676067687349,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
809"
BROADER IMPACTS,0.9129734085414988,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
810"
BROADER IMPACTS,0.9137792103142627,"groups), privacy considerations, and security considerations.
811"
BROADER IMPACTS,0.9145850120870266,"• The conference expects that many papers will be foundational research and not tied
812"
BROADER IMPACTS,0.9153908138597905,"to particular applications, let alone deployments. However, if there is a direct path to
813"
BROADER IMPACTS,0.9161966156325544,"any negative applications, the authors should point it out. For example, it is legitimate
814"
BROADER IMPACTS,0.9170024174053183,"to point out that an improvement in the quality of generative models could be used to
815"
BROADER IMPACTS,0.9178082191780822,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
816"
BROADER IMPACTS,0.9186140209508461,"that a generic algorithm for optimizing neural networks could enable people to train
817"
BROADER IMPACTS,0.91941982272361,"models that generate Deepfakes faster.
818"
BROADER IMPACTS,0.9202256244963739,"• The authors should consider possible harms that could arise when the technology is
819"
BROADER IMPACTS,0.9210314262691378,"being used as intended and functioning correctly, harms that could arise when the
820"
BROADER IMPACTS,0.9218372280419017,"technology is being used as intended but gives incorrect results, and harms following
821"
BROADER IMPACTS,0.9226430298146656,"from (intentional or unintentional) misuse of the technology.
822"
BROADER IMPACTS,0.9234488315874295,"• If there are negative societal impacts, the authors could also discuss possible mitigation
823"
BROADER IMPACTS,0.9242546333601934,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
824"
BROADER IMPACTS,0.9250604351329573,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
825"
BROADER IMPACTS,0.9258662369057212,"feedback over time, improving the efficiency and accessibility of ML).
826"
SAFEGUARDS,0.9266720386784851,"11. Safeguards
827"
SAFEGUARDS,0.927477840451249,"Question: Does the paper describe safeguards that have been put in place for responsible
828"
SAFEGUARDS,0.9282836422240129,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
829"
SAFEGUARDS,0.9290894439967768,"image generators, or scraped datasets)?
830"
SAFEGUARDS,0.9298952457695407,"Answer: [NA]
831"
SAFEGUARDS,0.9307010475423045,"Justification: We do not release any dataset or model. However, our paper proposes
832"
SAFEGUARDS,0.9315068493150684,"a backdoor attack method in EEG BCIs, which is challenging to be guarded and have
833"
SAFEGUARDS,0.9323126510878323,"dangerous impact in EEG BCIs. The only safeguard way we can come up with is to check
834"
SAFEGUARDS,0.9331184528605962,"and guarantee the clean of training datasets EEG BCIs employ.
835"
SAFEGUARDS,0.9339242546333602,"Guidelines:
836"
SAFEGUARDS,0.934730056406124,"• The answer NA means that the paper poses no such risks.
837"
SAFEGUARDS,0.935535858178888,"• Released models that have a high risk for misuse or dual-use should be released with
838"
SAFEGUARDS,0.9363416599516519,"necessary safeguards to allow for controlled use of the model, for example by requiring
839"
SAFEGUARDS,0.9371474617244158,"that users adhere to usage guidelines or restrictions to access the model or implementing
840"
SAFEGUARDS,0.9379532634971797,"safety filters.
841"
SAFEGUARDS,0.9387590652699436,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
842"
SAFEGUARDS,0.9395648670427075,"should describe how they avoided releasing unsafe images.
843"
SAFEGUARDS,0.9403706688154714,"• We recognize that providing effective safeguards is challenging, and many papers do
844"
SAFEGUARDS,0.9411764705882353,"not require this, but we encourage authors to take this into account and make a best
845"
SAFEGUARDS,0.9419822723609992,"faith effort.
846"
LICENSES FOR EXISTING ASSETS,0.9427880741337631,"12. Licenses for existing assets
847"
LICENSES FOR EXISTING ASSETS,0.943593875906527,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
848"
LICENSES FOR EXISTING ASSETS,0.9443996776792909,"the paper, properly credited and are the license and terms of use explicitly mentioned and
849"
LICENSES FOR EXISTING ASSETS,0.9452054794520548,"properly respected?
850"
LICENSES FOR EXISTING ASSETS,0.9460112812248187,"Answer: [Yes]
851"
LICENSES FOR EXISTING ASSETS,0.9468170829975826,"Justification: We conduct our experiments on three public datasets. The original papers of
852"
LICENSES FOR EXISTING ASSETS,0.9476228847703465,"these three datasets were cited in our paper.
853"
LICENSES FOR EXISTING ASSETS,0.9484286865431104,"Guidelines:
854"
LICENSES FOR EXISTING ASSETS,0.9492344883158743,"• The answer NA means that the paper does not use existing assets.
855"
LICENSES FOR EXISTING ASSETS,0.9500402900886382,"• The authors should cite the original paper that produced the code package or dataset.
856"
LICENSES FOR EXISTING ASSETS,0.9508460918614021,"• The authors should state which version of the asset is used and, if possible, include a
857"
LICENSES FOR EXISTING ASSETS,0.951651893634166,"URL.
858"
LICENSES FOR EXISTING ASSETS,0.9524576954069299,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
859"
LICENSES FOR EXISTING ASSETS,0.9532634971796938,"• For scraped data from a particular source (e.g., website), the copyright and terms of
860"
LICENSES FOR EXISTING ASSETS,0.9540692989524577,"service of that source should be provided.
861"
LICENSES FOR EXISTING ASSETS,0.9548751007252216,"• If assets are released, the license, copyright information, and terms of use in the
862"
LICENSES FOR EXISTING ASSETS,0.9556809024979855,"package should be provided. For popular datasets, paperswithcode.com/datasets
863"
LICENSES FOR EXISTING ASSETS,0.9564867042707494,"has curated licenses for some datasets. Their licensing guide can help determine the
864"
LICENSES FOR EXISTING ASSETS,0.9572925060435133,"license of a dataset.
865"
LICENSES FOR EXISTING ASSETS,0.9580983078162773,"• For existing datasets that are re-packaged, both the original license and the license of
866"
LICENSES FOR EXISTING ASSETS,0.958904109589041,"the derived asset (if it has changed) should be provided.
867"
LICENSES FOR EXISTING ASSETS,0.959709911361805,"• If this information is not available online, the authors are encouraged to reach out to
868"
LICENSES FOR EXISTING ASSETS,0.9605157131345688,"the asset’s creators.
869"
NEW ASSETS,0.9613215149073328,"13. New Assets
870"
NEW ASSETS,0.9621273166800967,"Question: Are new assets introduced in the paper well documented and is the documentation
871"
NEW ASSETS,0.9629331184528606,"provided alongside the assets?
872"
NEW ASSETS,0.9637389202256245,"Answer: [NA]
873"
NEW ASSETS,0.9645447219983884,"Justification: This paper does not release new assets.
874"
NEW ASSETS,0.9653505237711523,"Guidelines:
875"
NEW ASSETS,0.9661563255439162,"• The answer NA means that the paper does not release new assets.
876"
NEW ASSETS,0.9669621273166801,"• Researchers should communicate the details of the dataset/code/model as part of their
877"
NEW ASSETS,0.967767929089444,"submissions via structured templates. This includes details about training, license,
878"
NEW ASSETS,0.9685737308622079,"limitations, etc.
879"
NEW ASSETS,0.9693795326349718,"• The paper should discuss whether and how consent was obtained from people whose
880"
NEW ASSETS,0.9701853344077357,"asset is used.
881"
NEW ASSETS,0.9709911361804996,"• At submission time, remember to anonymize your assets (if applicable). You can either
882"
NEW ASSETS,0.9717969379532635,"create an anonymized URL or include an anonymized zip file.
883"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9726027397260274,"14. Crowdsourcing and Research with Human Subjects
884"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9734085414987913,"Question: For crowdsourcing experiments and research with human subjects, does the paper
885"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9742143432715552,"include the full text of instructions given to participants and screenshots, if applicable, as
886"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9750201450443191,"well as details about compensation (if any)?
887"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.975825946817083,"Answer: [NA]
888"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9766317485898469,"Justification: This paper does not involve crowdsourcing nor research with human subjects.
889"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9774375503626108,"Guidelines:
890"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9782433521353747,"• The answer NA means that the paper does not involve crowdsourcing nor research with
891"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9790491539081386,"human subjects.
892"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9798549556809025,"• Including this information in the supplemental material is fine, but if the main contribu-
893"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9806607574536664,"tion of the paper involves human subjects, then as much detail as possible should be
894"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9814665592264303,"included in the main paper.
895"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9822723609991942,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
896"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9830781627719581,"or other labor should be paid at least the minimum wage in the country of the data
897"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.983883964544722,"collector.
898"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.984689766317486,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
899"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9854955680902499,"Subjects
900"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9863013698630136,"Question: Does the paper describe potential risks incurred by study participants, whether
901"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9871071716357775,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
902"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9879129734085415,"approvals (or an equivalent approval/review based on the requirements of your country or
903"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9887187751813054,"institution) were obtained?
904"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9895245769540693,"Answer: [NA]
905"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9903303787268332,"Justification: This paper does not involve crowdsourcing nor research with human subjects.
906"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9911361804995971,"Guidelines:
907"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.991941982272361,"• The answer NA means that the paper does not involve crowdsourcing nor research with
908"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9927477840451249,"human subjects.
909"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9935535858178888,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
910"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9943593875906527,"may be required for any human subjects research. If you obtained IRB approval, you
911"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9951651893634166,"should clearly state this in the paper.
912"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9959709911361805,"• We recognize that the procedures for this may vary significantly between institutions
913"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9967767929089444,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
914"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9975825946817083,"guidelines for their institution.
915"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9983883964544722,"• For initial submissions, do not include any information that would break anonymity (if
916"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9991941982272361,"applicable), such as the institution conducting the review.
917"
