Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0017985611510791368,"Corruption is frequently observed in collected data and has been extensively studied
1"
ABSTRACT,0.0035971223021582736,"in machine learning under different corruption models. Despite this, there remains
2"
ABSTRACT,0.00539568345323741,"a limited understanding of how these models relate such that a unified view of
3"
ABSTRACT,0.007194244604316547,"corruptions and their consequences on learning is still lacking. In this work, we
4"
ABSTRACT,0.008992805755395683,"formally analyze corruption models at the distribution level through a general,
5"
ABSTRACT,0.01079136690647482,"exhaustive framework based on Markov kernels. We highlight the existence of
6"
ABSTRACT,0.012589928057553957,"intricate joint and dependent corruptions on both labels and attributes, which are
7"
ABSTRACT,0.014388489208633094,"rarely touched by existing research. Further, we show how these corruptions affect
8"
ABSTRACT,0.01618705035971223,"standard supervised learning by analyzing the resulting changes in Bayes Risk.
9"
ABSTRACT,0.017985611510791366,"Our findings offer qualitative insights into the consequences of “more complex”
10"
ABSTRACT,0.019784172661870502,"corruptions on the learning problem, and provide a foundation for future quanti-
11"
ABSTRACT,0.02158273381294964,"tative comparisons. Applications of the framework include corruption-corrected
12"
ABSTRACT,0.023381294964028777,"learning, a subcase of which we study in this paper by theoretically analyzing loss
13"
ABSTRACT,0.025179856115107913,"correction with respect to different corruption instances.
14"
INTRODUCTION,0.02697841726618705,"1
Introduction
15"
INTRODUCTION,0.02877697841726619,"Machine learning starts with data. The most widespread conception of data defines them as atomic
16"
INTRODUCTION,0.030575539568345324,"facts, perfectly describing some reality of interest [1]. In learning theories, this is reflected by the
17"
INTRODUCTION,0.03237410071942446,"often-used assumption that training and test data are drawn independently from the same distribution.
18"
INTRODUCTION,0.0341726618705036,"The goal of learning is to identify and synthesize patterns based on the knowledge, or information,
19"
INTRODUCTION,0.03597122302158273,"embedded in these data. In practice, however, corruption regularly occurs in data collection. This
20"
INTRODUCTION,0.03776978417266187,"creates a mismatch between training and test distributions, forcing us to learn from imperfect facts.
21"
INTRODUCTION,0.039568345323741004,"We should thus doubt the view of data as static facts, and consider them as a dynamic element of a
22"
INTRODUCTION,0.04136690647482014,"learning task [2]. Besides the predictor and the loss function, one may focus on the data dynamics,
23"
INTRODUCTION,0.04316546762589928,"studying corruptions and intervening in the learning process. Toward this goal, there has been a surge
24"
INTRODUCTION,0.044964028776978415,"of research in the machine learning community proposing various corruption models, examining and
25"
INTRODUCTION,0.046762589928057555,"correcting their effects on learning formally or empirically [3, 4, 5, 6, 7, 8]. Nevertheless, it is still
26"
INTRODUCTION,0.048561151079136694,"unclear how these models relate and whether they characterize all types of corruption. Even though
27"
INTRODUCTION,0.050359712230215826,"the necessity of investigating this topic is recognized both at a practical [9, 10] and a theoretical
28"
INTRODUCTION,0.052158273381294966,"[11, 12] level, no standardized way to model and analyze corruption has been so far created [13].
29"
INTRODUCTION,0.0539568345323741,"Our primary objective here is to systematically study the problem of learning under corruption,
30"
INTRODUCTION,0.05575539568345324,"providing a general framework for analysis. Whilst there have been some existing attempts, cer-
31"
INTRODUCTION,0.05755395683453238,"tain limitations persist in terms of homogeneity and exhaustiveness. A famous early endeavor is
32"
INTRODUCTION,0.05935251798561151,"Quinonero-Candela et al. [14], grouping together works about the multi-faceted topic of dataset shift,
33"
INTRODUCTION,0.06115107913669065,"yet not in a unifying or comprehensive manner. Later on, several studies aim to provide a more homo-
34"
INTRODUCTION,0.06294964028776978,"geneous view of corruption, often referred to as noise or distribution shift. However, their frameworks
35"
INTRODUCTION,0.06474820143884892,"typically rely on some corruption-invariant assumptions on the marginal or conditional probabilities,
36"
INTRODUCTION,0.06654676258992806,"and the extent of exhaustiveness is merely conjectured or not considered [15, 16, 17, 18].
37"
INTRODUCTION,0.0683453237410072,"In this paper, we take a different point of view from the previous work: we categorize corruption
38"
INTRODUCTION,0.07014388489208633,"based on its dependence on the feature and label space, rather than relying on the notion of invariance.
39"
INTRODUCTION,0.07194244604316546,"Our resulting framework is generic, encompassing all possible pairwise stochastic corruptions.1 The
40"
INTRODUCTION,0.0737410071942446,"underpinning mathematical tool that enables such exhaustiveness is the Markov kernel. While Markov
41"
INTRODUCTION,0.07553956834532374,"kernels have been utilized in formalizing corruption [7, 19], their primary focus has been solely on
42"
INTRODUCTION,0.07733812949640288,"label corruption, attribute corruption, or simple joint corruption. To our knowledge, the proposed
43"
INTRODUCTION,0.07913669064748201,"framework is novel in the sense of demonstrated exhaustiveness in this domain. Our contributions are
44"
INTRODUCTION,0.08093525179856115,"summarized as follows:
45"
INTRODUCTION,0.08273381294964029,"C1 We propose a new taxonomy of corruption in the supervised learning setting (§ 3), hierarchically
46"
INTRODUCTION,0.08453237410071943,"organized through the notion of dependence (Fig. 1), and connect existing corruption models to
47"
INTRODUCTION,0.08633093525179857,"this taxonomy (Tab. 1).
48"
INTRODUCTION,0.08812949640287769,"C2 We analyze the implications of our family of corruptions on learning (§ 4), linking the Bayes risk
49"
INTRODUCTION,0.08992805755395683,"of the clean and corrupted supervised learning problems through equality results (Theorem 3,
50"
INTRODUCTION,0.09172661870503597,"Theorem 4, Theorem 5).
51"
INTRODUCTION,0.09352517985611511,"C3 We derive corruption-corrected loss functions for different corruption instances within our frame-
52"
INTRODUCTION,0.09532374100719425,"work (§ 5). A subcase of these corrections (Theorem 8) generalizes prior results on corruption-
53"
INTRODUCTION,0.09712230215827339,"corrected learning in simple label corruption.
54"
INTRODUCTION,0.09892086330935251,"Though abstract in general, our results expand upon existing ones on specific corruption models and
55"
INTRODUCTION,0.10071942446043165,"shed light on the relatively under-explored joint and dependent corruptions.
56"
BACKGROUND,0.10251798561151079,"2
Background
57"
BACKGROUND,0.10431654676258993,"Before introducing our analysis, we review the background framework and notations.
58"
BACKGROUND,0.10611510791366907,"Supervised learning
In statistical decision theory [20, 21], a general decision problem can be
59"
BACKGROUND,0.1079136690647482,"viewed as a two-player game between nature and decision-maker. Nature chooses its state, then
60"
BACKGROUND,0.10971223021582734,"experiment leads to some observations given the state, and the decision-maker picks a suitable action
61"
BACKGROUND,0.11151079136690648,"from a fixed set of decision rules. In the specific setting of supervised learning, observations are in
62"
BACKGROUND,0.11330935251798561,"the feature space X ⊂Rd , d ≥1, states are in the label space Y , then the experiment E leads to a
63"
BACKGROUND,0.11510791366906475,"probability associated with the observation X, given the state Y . Here we focus on the classification
64"
BACKGROUND,0.11690647482014388,"task, that is, assuming the label space to be finite. All the stated results can be easily extended to
65"
BACKGROUND,0.11870503597122302,"regression cases by considering a continuous label space; we leave it for future application.
66"
BACKGROUND,0.12050359712230216,"To formalize the processes described above, we introduce the Markov kernel.
67"
BACKGROUND,0.1223021582733813,"Definition 1 (Klenke [22]). A Markov kernel κ from a measurable space (X1, X1) to a measurable
68"
BACKGROUND,0.12410071942446044,"space (X2, X2) is a function x1 7→κ(x1, ·) from X1 to P(X2), the set of probability measures on
69"
BACKGROUND,0.12589928057553956,"X2, such that κ(x1, B) is measurable in x1 for each set B ∈X2. We denote it by κ : X1 ⇝X2, or
70"
BACKGROUND,0.12769784172661872,"more compactly by κX1X2. The set of Markov kernels from X1 to X2 is referred to as M(X1, X2).
71"
BACKGROUND,0.12949640287769784,"The Markov kernel generalizes the concept of conditional probability. Looking at the function κ(·, B),
it associates different probabilities to the set B given different values of the parameter x1. It can
transform a distribution µ ∈P(X1) into another distribution µκ ∈P(X2), as well as transform a
function f : X2 →R into another function κf : X1 →R with the following two operators:"
BACKGROUND,0.13129496402877697,"µκ(B) :=
Z"
BACKGROUND,0.13309352517985612,"X1
κ(x1, B)µ(dx1) ∀B ∈X2 ,
κf(x1) :=
Z"
BACKGROUND,0.13489208633093525,"X2
κ(x1, dx2)f(x2) ∀x1 ∈X1 ,"
BACKGROUND,0.1366906474820144,"provided the integral exists. Next, we define different operations to combine Markov kernels:
72"
BACKGROUND,0.13848920863309352,"P1 Given κ : X1 ⇝X2 and λ : X1 × X2 ⇝X3, their chain composition κ ◦λ : X1 ⇝X3
73"
BACKGROUND,0.14028776978417265,"is defined by (κ ◦λ)f(x1) :=
R"
BACKGROUND,0.1420863309352518,"X2 κ(x1, dx2)
R"
BACKGROUND,0.14388489208633093,"X3 λ((x1, x2), dx3)f(x3) = κ(λ f)(x3) where
74"
BACKGROUND,0.14568345323741008,"f : X3 →R is a positive X3-measurable function;
75"
BACKGROUND,0.1474820143884892,"P2 For κ : X1 ⇝X2 and λ : X1 × X2 ⇝X3, their product composition κ × λ : X1 ⇝X2 × X3 is
76"
BACKGROUND,0.14928057553956833,"(κ × λ)f(x1) :=
R"
BACKGROUND,0.1510791366906475,"X2 κ(x1, dx2)
R"
BACKGROUND,0.1528776978417266,"X3 λ((x1, x2), dx3) f(x2, x3) for every f positive X2 × X3-
77"
BACKGROUND,0.15467625899280577,"measurable.
78"
BACKGROUND,0.1564748201438849,"1As for non-stochastic ones, we show that they always have a stochastic alternative representation. See § 3."
BACKGROUND,0.15827338129496402,"Notice that a probability distribution is a specific instance of a Markov kernel, constant in its parameter
79"
BACKGROUND,0.16007194244604317,"space. Therefore, P1 and P2 are well defined for κ ≡µ ∈P(X2). We can unify the notation of ×
80"
BACKGROUND,0.1618705035971223,"for distributions thanks to the flexibility of kernels, and consider the µκ as a subcase of µ ◦κ.
81"
BACKGROUND,0.16366906474820145,"Bayes risk
Having defined all these objects, a supervised learning problem can be represented"
BACKGROUND,0.16546762589928057,"by the diagram Y
X
Y,
E
h
where h is a decision rule chosen in M(X, Y ). Its task can be
formalized as a risk minimization problem, i.e., finding the optimal action h ∈H by considering the
Bayes Risk (BR) measure"
BACKGROUND,0.1672661870503597,"BRℓ(π × E) =
inf
h∈M(X,Y ) Rπ,ℓ(π × E) =
inf
h∈M(X,Y ) EY∼πEX∼EYℓ(hX, Y) ,"
BACKGROUND,0.16906474820143885,"where the notation κX stands for the kernel κ evaluated on the parameter X, e.g., hX, EY (this subscript
notation will be used throughout), and π is a prior distribution on Y . The function ℓis asked to be
bounded and a proper loss [23, 24], i.e., a loss function ℓ: P(Y ) × Y →R+ whose minimization
set contains the ground truth class probability. More formally, we ask for"
BACKGROUND,0.17086330935251798,"∃h∗∈arg
min
h∈M(X,Y ) Rπ,ℓ,A(E) such that h∗× µ = E × π , ∃µ ∈P(X) ."
BACKGROUND,0.17266187050359713,"Since in real-world applications, one deploys a model with only limited representation capacity, we
consider the constrained version of BR"
BACKGROUND,0.17446043165467626,"BRℓ,H(πY × E) =
inf
h∈H⊆M(X,Y ) EY∼πY EX∼EYℓ(hX, Y) ."
BACKGROUND,0.17625899280575538,"We call H the model class. If we fix the joint space to Z = X × Y and the joint probability
82"
BACKGROUND,0.17805755395683454,"distribution to P = πY × E ∈P(Z), we can refer to a supervised learning problem as the triple
83"
BACKGROUND,0.17985611510791366,"(ℓ, H, P). Notice that we can also use an equivalent decomposition of the joint distribution through a
84"
BACKGROUND,0.18165467625899281,"posterior kernel F : X ⇝Y , so that P = πX × F for some prior on the feature space. Hence, each
85"
BACKGROUND,0.18345323741007194,"supervised learning problem can have two associated kernels, the experiment E and the posterior
86"
BACKGROUND,0.18525179856115107,"one F. We then obtain two views of the learning problem, a generative and a discriminative one, as
87"
BACKGROUND,0.18705035971223022,"previously noted by Reid et al. [25]. By means of these, we can define two Conditional BR (CBR):
88"
BACKGROUND,0.18884892086330934,"Discriminative: EX∼πXCBRℓ,H(FX) = EX∼πX
inf
hX∈HX EY∼FXℓ(hX, Y) ,
(1)"
BACKGROUND,0.1906474820143885,"Generative: EY∼πY CBRℓ,H(EY) = EY∼πY inf
h∈H EX∼EYℓ(hX, Y) ,"
BACKGROUND,0.19244604316546762,"both equal to their corresponding constrained BR. Notice that for Eq. (1) to be well defined, we need
89"
BACKGROUND,0.19424460431654678,"at least one minimum of the unconstrained BR to be included in the model class. For our convenience,
90"
BACKGROUND,0.1960431654676259,"we ask it to be the h matching the F.
91"
A GENERAL FRAMEWORK FOR CORRUPTION,0.19784172661870503,"3
A general framework for corruption
92"
A GENERAL FRAMEWORK FOR CORRUPTION,0.19964028776978418,"In this section, we present a general framework of pairwise corruptions based on the notion of
93"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2014388489208633,"dependence and discuss how existing corruption models fit into this framework as subcategories.
94"
A GENERAL FRAMEWORK FOR CORRUPTION,0.20323741007194246,"First, let us formally define corruption and two additional kernel operations, which will be useful in
95"
A GENERAL FRAMEWORK FOR CORRUPTION,0.20503597122302158,"the buildup of our corruption taxonomy.
96"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2068345323741007,"Definition 2. A corruption is a Markov kernel κ that sends a probability space (X × Y, X × Y, P)
97"
A GENERAL FRAMEWORK FOR CORRUPTION,0.20863309352517986,"into another, (X × Y, X × Y, ˜P). We write it as κZ ˜
Z,2 and call the variables z = (x, y) ∈Z
98"
A GENERAL FRAMEWORK FOR CORRUPTION,0.210431654676259,"parameters and the differentials d˜z = d˜xd˜y corrupted variables.
99"
A GENERAL FRAMEWORK FOR CORRUPTION,0.21223021582733814,"The following operations are not considered in the classical probability literature but have been
100"
A GENERAL FRAMEWORK FOR CORRUPTION,0.21402877697841727,"studied in other areas, e.g., through the lens of category theory [26, 27, 28]. Here we rework them to
101"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2158273381294964,"fit our framework.
102"
A GENERAL FRAMEWORK FOR CORRUPTION,0.21762589928057555,"P3 Given κ : X1 ⇝X2 and λ : X3 ⇝X4, their superposition (see § S2.1) is equal to κλ :
103"
A GENERAL FRAMEWORK FOR CORRUPTION,0.21942446043165467,"X1 × X3 ⇝X2 × X4 as (κλ)f(x1, x3) :=
R"
A GENERAL FRAMEWORK FOR CORRUPTION,0.22122302158273383,"X2 κ(x1, dx2)
R"
A GENERAL FRAMEWORK FOR CORRUPTION,0.22302158273381295,"X4 λ(x3, dx4) f(x2, x4), where
104"
A GENERAL FRAMEWORK FOR CORRUPTION,0.22482014388489208,"f : X2 × X4 →R is positive X2 × X4-measurable;
105"
A GENERAL FRAMEWORK FOR CORRUPTION,0.22661870503597123,"2We slightly abuse the kernel notation κZ ˜
Z to describe how corruption changes the probability spaces. For
instance, if a corruption acts solely on the space X, it will be written as κX ˜
X; however, only the probability
measure on it will be actually changed."
A GENERAL FRAMEWORK FOR CORRUPTION,0.22841726618705036,"κZ ˜
Z
2J"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2302158273381295,"κXY ˜Y
2D- ˜Y"
A GENERAL FRAMEWORK FOR CORRUPTION,0.23201438848920863,"κX ˜Y
1D- ˜Y"
A GENERAL FRAMEWORK FOR CORRUPTION,0.23381294964028776,"κY ˜Y
S- ˜Y"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2356115107913669,"κY ˜
X ˜Y
1J-Y"
A GENERAL FRAMEWORK FOR CORRUPTION,0.23741007194244604,"κX ˜
X ˜Y
1J-X"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2392086330935252,"κXY ˜
X
2D- ˜X"
A GENERAL FRAMEWORK FOR CORRUPTION,0.24100719424460432,"κY ˜
X
1D- ˜X"
A GENERAL FRAMEWORK FOR CORRUPTION,0.24280575539568344,"κX ˜
X
S- ˜X"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2446043165467626,"(a) Corruption hierarchy. It is based on the independence
from a parameter or a corrupted variable. Arrow: child
is constant w.r.t. exactly one of the variables in parent."
A GENERAL FRAMEWORK FOR CORRUPTION,0.24640287769784172,"2D- ˜X, 2D- ˜Y"
A GENERAL FRAMEWORK FOR CORRUPTION,0.24820143884892087,"1D- ˜X, 2D- ˜Y 2D- ˜X, 1D- ˜Y
S- ˜X, 2D- ˜Y
2D- ˜X, S- ˜Y ,"
A GENERAL FRAMEWORK FOR CORRUPTION,0.25,"S- ˜X, S- ˜Y
1D- ˜X, 1D- ˜Y"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2517985611510791,"(b) Feasible combinations. The partial ordering is
induced by corruptions, i.e., one corruption in child
and one in parent respect the corruption hierarchy."
A GENERAL FRAMEWORK FOR CORRUPTION,0.25359712230215825,"Figure 1: Partial orderings on the corruption and combination sets, based on the amount of dependence
on the spaces. In the left panel, we underline with dotted nodes the corruptions that cannot be used in
any feasible combination. Trivial cases of independence from all parameters or identical kernels are
excluded from this analysis."
A GENERAL FRAMEWORK FOR CORRUPTION,0.25539568345323743,"P4 The pseudo-inverse of a kernel κ : X1 ⇝X2 is defined as κ† : X2 ⇝X1 such that (κ† ◦κ)µ1 =
106"
A GENERAL FRAMEWORK FOR CORRUPTION,0.25719424460431656,"µ1 and (κ ◦κ†)µ2 = µ2 with µ1, µ2 being the probabilities associated to X1, X2. In general,
107"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2589928057553957,"the pseudo-inverse is not unique, since it corresponds to a class of equivalence induced by the
108"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2607913669064748,"probability measure on X1 (see details in § S2.2).
109"
A GENERAL FRAMEWORK FOR CORRUPTION,0.26258992805755393,"Again, P3 is well defined for κ ≡µ ∈P(X2). This operation allows for more flexible combinations
110"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2643884892086331,"of kernels, in a “parallel” fashion. No restriction is imposed on the parameter spaces to be equal, e.g.,
111"
A GENERAL FRAMEWORK FOR CORRUPTION,0.26618705035971224,"X1 = X2, or Cartesian products with some space in common, e.g., X1 = Y1 × Y2, X2 = Y1 × Y3.
112"
A GENERAL FRAMEWORK FOR CORRUPTION,0.26798561151079137,"When this happens, the action of the two kernels “superpose” on the same space. In addition, having
113"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2697841726618705,"more than one measure in the integral acting on the same space would make the integral ill-defined,
114"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2715827338129496,"so this case is excluded. Because of these properties, we say that P3 is the operation with the weakest
115"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2733812949640288,"feasibility conditions, i.e., the set of rules to fulfill a well-defined operation.
116"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2751798561151079,"Building a taxonomy of corruptions
Corruptions can be naturally classified in different ways,
117"
A GENERAL FRAMEWORK FOR CORRUPTION,0.27697841726618705,"depending on their behavior with respect parameters and corrupted variables. In Fig. 1a, we show all
118"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2787769784172662,"possible non-trivial corruption types, i.e., those that are not identical and not constantly equal to a
119"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2805755395683453,"probability. We classify them based on the number of parameters they depend on, and the type of
120"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2823741007194245,"corrupted variables they result in. Specifically, we employ the following abbreviations: J is short for
121"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2841726618705036,"Joint (both variables are corrupted), S is short for Simple (the parameter and the corrupted variable
122"
A GENERAL FRAMEWORK FOR CORRUPTION,0.28597122302158273,"are the same), and D is short for Dependent (others). We then obtain the classification: 2-parameter
123"
A GENERAL FRAMEWORK FOR CORRUPTION,0.28776978417266186,"joint corruption (2J), 1-parameter joint corruption (1J), 2-parameter dependent corruption (2D),
124"
A GENERAL FRAMEWORK FOR CORRUPTION,0.289568345323741,"1-parameter dependent corruption (1D), simple corruption (S), along with an indication of parameter
125"
A GENERAL FRAMEWORK FOR CORRUPTION,0.29136690647482016,"or corrupted space. The general naming rule is {#parameters} + {abbreviation} + {-} + {parameter
126"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2931654676258993,"or corrupted space, depending on where the ambiguity lies}.
127"
A GENERAL FRAMEWORK FOR CORRUPTION,0.2949640287769784,"We now want to generate all possible corruptions of the type κZ ˜
Z : X × Y ⇝˜X × ˜Y . We
128"
A GENERAL FRAMEWORK FOR CORRUPTION,0.29676258992805754,"combine the nodes in Fig. 1a using the superposition operation (P3), obtaining all the feasible
129"
A GENERAL FRAMEWORK FOR CORRUPTION,0.29856115107913667,"combinations included in Fig. 1b. The missing couples are excluded because of P3’s feasibility
130"
A GENERAL FRAMEWORK FOR CORRUPTION,0.30035971223021585,"conditions described above, which, even if weak, still do not allow some corruption pairings. Needing
131"
A GENERAL FRAMEWORK FOR CORRUPTION,0.302158273381295,"each corrupted variable to appear exactly once, we cannot include the 1-parameter joint corruptions
132"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3039568345323741,"in any factorization of the κXY ˜
X ˜Y . It is easy to check that no corruption from (a subset of) {X, Y }
133"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3057553956834532,"to (a subset of) { ˜X, ˜Y } can be combined with them. Compatibility problems arise also when trying
134"
A GENERAL FRAMEWORK FOR CORRUPTION,0.30755395683453235,"to combine a simple corruption (S) with a 1-parameter dependent one (1D); we cannot fulfill the
135"
A GENERAL FRAMEWORK FOR CORRUPTION,0.30935251798561153,"feasibility conditions for P3 and obtain a complete joint corruption, since we will be always missing
136"
A GENERAL FRAMEWORK FOR CORRUPTION,0.31115107913669066,"a parameter. We then exclude this combination from our taxonomy.3
137"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3129496402877698,"Markov kernels and exhaustiveness
Our motivation for formalizing corruptions through Markov
138"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3147482014388489,"kernels is their representation power in terms of couplings. A coupling is formally defined for two
139"
A GENERAL FRAMEWORK FOR CORRUPTION,0.31654676258992803,"probability spaces Σ1 := (Z1, Z1, P1), Σ2 := (Z2, Z2, P2) as a probability space Σ := (Z1 ×
140"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3183453237410072,"Z2, Z1 × Z2, P), such that the marginal probabilities associated to P w.r.t. Zi, i ∈{1, 2} are
141"
A GENERAL FRAMEWORK FOR CORRUPTION,0.32014388489208634,"3Note that 1Js are still valid corruptions if seen as a subcase of a 2J, the full one, e.g., 2J
=
κX ˜
X ˜Y (d˜xd˜y, x) 1(y). Similarly, a 1D corruption can be seen as a subcase of a 2D corruption. Here we
are exploring the possibility of combining them with other corruptions. The constraints are only dimensional."
A GENERAL FRAMEWORK FOR CORRUPTION,0.32194244604316546,Table 1: Illustration of the taxonomy with examples of existing corruption models.
A GENERAL FRAMEWORK FOR CORRUPTION,0.3237410071942446,"Name
Action diagram
Corrupted distribution
Examples"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3255395683453237,"S- ˜
X
Y
X
˜
X
E
κX ˜
X
˜P = (κX ˜
XδY ˜Y ) ◦(πY × E)
attribute noise [30, 31, 4, 19]"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3273381294964029,"S- ˜Y
X
Y
˜Y
F
κY ˜
Y
˜P = (δX ˜
XκY ˜Y ) ◦(πX × F)
class-conditional noise
[32, 33, 5, 34, 7, 19]"
A GENERAL FRAMEWORK FOR CORRUPTION,0.329136690647482,"1D- ˜
X
X
Y
˜
X
F
κY ˜
X
˜P = (κY ˜
XδY ˜Y ) ◦(πX × F)
style transfer [35, 36, 37]"
A GENERAL FRAMEWORK FOR CORRUPTION,0.33093525179856115,"1D- ˜Y
Y
X
˜Y
E
κX ˜
Y
˜P = (δX ˜
XκX ˜Y ) ◦(πY × E)
instance-dependent noise
(IDN) [8]"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3327338129496403,"2D- ˜
X
Y
X
˜
X
E"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3345323741007194,"κXY ˜
X"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3363309352517986,"κXY ˜
X
˜P = (κXY ˜
XδY ˜Y ) ◦(πY × E)
adversarial noise
[38, 39, 40, 41, 42]"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3381294964028777,"2D- ˜Y
X
Y
˜Y
F"
A GENERAL FRAMEWORK FOR CORRUPTION,0.33992805755395683,"κXY ˜
Y"
A GENERAL FRAMEWORK FOR CORRUPTION,0.34172661870503596,"κXY ˜
Y
˜P = (δX ˜
XκXY ˜Y ) ◦(πX × F)
instance & label-dependent
noise [8, 43, 44, 45]"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3435251798561151,"S- ˜
X,
S- ˜Y"
A GENERAL FRAMEWORK FOR CORRUPTION,0.34532374100719426,"˜Y
Y
X
˜
X
κY ˜
Y
E
κX ˜
X
˜P = (κX ˜
XκY ˜Y ) ◦(πY × E)
combined simple noise [19]"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3471223021582734,"1D- ˜
X,
2D- ˜Y"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3489208633093525,"˜
X
Y
X
˜Y
κY ˜
X
E"
A GENERAL FRAMEWORK FOR CORRUPTION,0.35071942446043164,"κXY ˜
Y"
A GENERAL FRAMEWORK FOR CORRUPTION,0.35251798561151076,"κXY ˜
Y
˜P = (κY ˜
XκXY ˜Y ) ◦(πY × E)
target shift [46, 47, 48, 49]"
A GENERAL FRAMEWORK FOR CORRUPTION,0.35431654676258995,"2D- ˜
X,
S- ˜Y"
A GENERAL FRAMEWORK FOR CORRUPTION,0.35611510791366907,"˜Y
Y
X
˜
X
κY ˜
Y
E"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3579136690647482,"κXY ˜
X"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3597122302158273,"κXY ˜
X
˜P = (κXY ˜
XκY ˜Y ) ◦(πY × E)
mutually contaminated
distributions [6, 50, 51]"
A GENERAL FRAMEWORK FOR CORRUPTION,0.36151079136690645,"2D- ˜
X,
1D- ˜Y"
A GENERAL FRAMEWORK FOR CORRUPTION,0.36330935251798563,"˜Y
X
Y
˜
X
κX ˜
Y
F"
A GENERAL FRAMEWORK FOR CORRUPTION,0.36510791366906475,"κXY ˜
X"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3669064748201439,"κXY ˜
X
˜P = (κXY ˜
XκX ˜Y ) ◦(πX × F)
covariate shift [3, 52, 53, 54]"
A GENERAL FRAMEWORK FOR CORRUPTION,0.368705035971223,"2D- ˜
X,
2D- ˜Y"
A GENERAL FRAMEWORK FOR CORRUPTION,0.37050359712230213,"˜Y
Y
X
˜
X
κXY ˜
Y"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3723021582733813,"κXY ˜
Y E"
A GENERAL FRAMEWORK FOR CORRUPTION,0.37410071942446044,"κXY ˜
X"
A GENERAL FRAMEWORK FOR CORRUPTION,0.37589928057553956,"κXY ˜
X
˜P = (κXY ˜
XκXY ˜Y ) ◦(πY × E)
generalized target shift
[55, 56, 57]
concept drift [58, 59]"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3776978417266187,"the respective Pi. By construction, Markov kernels are in bijection with all the possible couplings
142"
A GENERAL FRAMEWORK FOR CORRUPTION,0.37949640287769787,"existent on Z × Z with two fixed probability measures, for us, P, ˜P. Hence, they represent all
143"
A GENERAL FRAMEWORK FOR CORRUPTION,0.381294964028777,"possible pairwise dependencies between probability spaces that are stochastic, and for non-stochastic
144"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3830935251798561,"mappings, we are sure to have an alternative Markov kernel representation.4
145"
A GENERAL FRAMEWORK FOR CORRUPTION,0.38489208633093525,"In most machine learning research considering corruption, the corruption process typically involves
146"
A GENERAL FRAMEWORK FOR CORRUPTION,0.38669064748201437,"two environments, that is, the training one and the test one. Our definition of corruption (Def. 2)
147"
A GENERAL FRAMEWORK FOR CORRUPTION,0.38848920863309355,"covers all such pairwise cases. Furthermore, one may also apply this framework to settings with
148"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3902877697841727,"more than two spaces, e.g., online learning or learning from multiple different domains [29]. For
149"
A GENERAL FRAMEWORK FOR CORRUPTION,0.3920863309352518,"these cases, we can employ a composed model, where different corruptions are acting together in a
150"
A GENERAL FRAMEWORK FOR CORRUPTION,0.39388489208633093,"“chained” (P1, P2) or “parallel” (P3) fashion and creating more complex patterns. We discuss further
151"
A GENERAL FRAMEWORK FOR CORRUPTION,0.39568345323741005,"possibilities for applying this framework to n > 2 corrupted spaces in § S2.3.
152"
A GENERAL FRAMEWORK FOR CORRUPTION,0.39748201438848924,"Relations to existing paradigms
Next, we examine how existing corruption models fit into our
153"
A GENERAL FRAMEWORK FOR CORRUPTION,0.39928057553956836,"taxonomy. To do so, we reformulate them as specific instantiations of Markov corruptions. This
154"
A GENERAL FRAMEWORK FOR CORRUPTION,0.4010791366906475,"reveals their relationships within the corruption hierarchy presented in Fig. 1a. Our goal here is
155"
A GENERAL FRAMEWORK FOR CORRUPTION,0.4028776978417266,"not to merely demonstrate that a child problem can be solved by a parent one, but rather to gain a
156"
A GENERAL FRAMEWORK FOR CORRUPTION,0.40467625899280574,"deeper understanding of the problem settings. The exhaustiveness of the framework allows us to
157"
A GENERAL FRAMEWORK FOR CORRUPTION,0.4064748201438849,"identify what has been previously overlooked in characterizing all types of corruption. Notably, we
158"
A GENERAL FRAMEWORK FOR CORRUPTION,0.40827338129496404,"highlight the existence of joint and dependent corruptions, which receive far less attention than simple
159"
A GENERAL FRAMEWORK FOR CORRUPTION,0.41007194244604317,"4When the mapping between two fixed probability spaces is a transition kernel, e.g., a non-normalized
Markov kernel, the map is deterministic. An example is the selection bias classically formalized as absolutely
continuous probabilities ˜P ≪P [14]. However, given the bijection with the coupling space, we can always find
a stochastic map connecting Σ1, Σ2. A similar argument can be replicated for mappings between Σ1, Σ2 that
are not kernel-induced, e.g., they are not positive. For more details, see § S2.2."
A GENERAL FRAMEWORK FOR CORRUPTION,0.4118705035971223,"corruptions, while far greater problems arise in such complicated cases (see § 4). Moreover, we notice
160"
A GENERAL FRAMEWORK FOR CORRUPTION,0.4136690647482014,"that existing categorizations rely mostly on the notion of invariance, i.e., corruptions are defined
161"
A GENERAL FRAMEWORK FOR CORRUPTION,0.4154676258992806,"based on which element of the distributions are preserved. These invariance-based taxonomies have
162"
A GENERAL FRAMEWORK FOR CORRUPTION,0.4172661870503597,"been introduced mainly for robustness and causal analyses. However, they do not have a one-to-one
163"
A GENERAL FRAMEWORK FOR CORRUPTION,0.41906474820143885,"correspondence with ours, and do not allow for a hierarchical nor compositional view of corruption.
164"
A GENERAL FRAMEWORK FOR CORRUPTION,0.420863309352518,"A summary of representative corruption models in the literature is given in Tab. 1, while all the
165"
A GENERAL FRAMEWORK FOR CORRUPTION,0.4226618705035971,"technical details about correspondences and relations between taxonomies are given in § S1.
166"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4244604316546763,"4
Consequences of corruption in supervised learning
167"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4262589928057554,"Traditionally, experiments have been compared through Bayes Risk using what is known as the Data
168"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.42805755395683454,"Processing Inequality, or Blackwell-Sherman-Stein Theorem [20, 60].5 Recently, in Williamson and
169"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.42985611510791366,"Cranko [19], Data Processing Equality results have also been studied within the supervised learning
170"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4316546762589928,"framework. Here we adopt the equality approach to compare the clean and corrupted experiments
171"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.43345323741007197,"through Bayes Risk. The equalities formally characterize how the optimization problem is affected by
172"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4352517985611511,"the different kinds of joint corruption in our taxonomy. This gives us a quantitative result in terms of
173"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4370503597122302,"conserved “information” [19] between corrupted and clean learning problems, and a bridge between
174"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.43884892086330934,"the problems themselves.
175"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.44064748201438847,"We rewrite the minimization set of the BR in a more compact way, such as ℓ◦H := { (x, y) 7→
176"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.44244604316546765,"ℓ(hx, y) | h ∈H ⊆M(X, Y ) }. We define the action of a corruption κ on this set as the set of all the
177"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4442446043165468,"corrupted functions κf, f ∈ℓ◦H. Lastly, we ask f ∗= ℓ◦h∗∈arg minf E ˜
P [f( ˜X, ˜Y )] to belong
178"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4460431654676259,"to the constraining space ℓ◦H, for reasons already discussed for Eq. (1).
179"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.447841726618705,"The first two theorems cover the (S, 2D) cases and their subcase (S- ˜X, S- ˜Y ), as proved in [19].
180"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.44964028776978415,"Theorem 3 (BR under (S- ˜X, S- ˜Y ), (2D- ˜X, S- ˜Y ) joint corruption). Let (ℓ, H, P) be a learning
181"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.45143884892086333,"problem, E : Y ⇝X an experiment and κ ˜
X ∈{κX ˜
X, κY X ˜
X} a corruption. Let κY ˜Y be a
182"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.45323741007194246,"simple corruption on Y . Then we can form the corrupted experiment as per the transition diagram6
183"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4550359712230216,"˜Y
Y
X
˜X
κY ˜
Y
E κ
˜
X"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4568345323741007,"κ
˜
X
and obtain
184"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.45863309352517984,"E˜Y∼κY ˜
Y πY CBRℓ◦H(κ
˜
XE˜Y) = EY∼πY CBRκ ˜
X(κY ˜
Y ℓ◦H)(EY) ."
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.460431654676259,"Moreover, if κ ˜
X = κX ˜
X, we have
185"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.46223021582733814,"BRℓ◦H[κY ˜Y (πY × κX ˜
XE)] = BRκX ˜
X(κY ˜
Y ℓ◦H)(πY × E) .
(2)"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.46402877697841727,"Here in Theorem 3 we have shown the BR equality for the experiment E, in line with the Comparison
186"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4658273381294964,"of Experiments and Information Equalities literature mentioned at the beginning of the section.
187"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4676258992805755,"However, for some corruptions the equalities results cannot be stated with E and the Generative
188"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4694244604316547,"CBR, unless ignoring the joint corruption factorization formula (see § S5 for a detailed explanation).
189"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4712230215827338,"We hence use the posterior kernel F defined with the Discriminative CBR (Eq. (1)), and gain more
190"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.47302158273381295,"insights about the minimization set while paying a price in elegance of the result.
191"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4748201438848921,"Theorem 4 (BR under (S- ˜X, 2D- ˜Y ) joint corruption). Let (ℓ, H, P) be a learning problem, F :
192"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4766187050359712,"X ⇝Y a posterior and κXY ˜Y } a Y corruption. Let κX ˜
X be a simple corruption on X. Then we
193"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4784172661870504,"can form the corrupted experiment as per the transition diagram
˜X
X
Y
˜Y
κX ˜
X
F κ
˜
Y"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4802158273381295,"κXY ˜
Y
194"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.48201438848920863,"and obtain
195"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.48381294964028776,"E˜X∼κX ˜
XπXCBRℓ◦H(κXY ˜Y F˜X) = EX∼πXCBRκX ˜
X(κXY ˜
Y ℓ◦H)(FX) ."
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4856115107913669,"5Briefly, the theorem states that for an experiment E and its image through a suitably defined Markov kernel
κ w.r.t. some operation, we have BRπ,ℓ,H(E) ≤BRπ,ℓ,H(κE) for all π, ℓ, H.
6The first arrow in the diagram is ˜Y ⇝Y , the opposite direction given for the Y corruption. However, we
are not using any notion of inverse corruption here. We are only using the flexibility of Markov kernels as
operators and introducing an alternative notation. The kernel used here is exactly the κY ˜Y : Y ⇝˜Y , which acts
on an input measure in a “push-forward” fashion. The notation will be further used in the rest of the paper."
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.48741007194244607,"We can notice, thanks to Theorems 3, 4, that when corruption involves dependent structures in
the factorization, the loss function or the whole minimization set are modified in a parameterized,
dependent way. For instance,"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4892086330935252,"κX ˜
X(κXY ˜Y ℓ◦H) = {κX ˜
X(κY ˜Y ℓx ◦h) | h ∈H} ,"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4910071942446043,"with κXY ˜Y now viewed as a parameterized label corruption, i.e. (κY ˜Y )x. An additional consequence
196"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.49280575539568344,"is also that the result can only be given in terms of CBR, Discriminative or Generative. We also see
197"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.49460431654676257,"that corruptions on Y only affect the loss function and does not touch the model class, even in the
198"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.49640287769784175,"dependent case.
199"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.4982014388489209,"The next theorems cover the factorizations involving 1D corruptions. In the first case, we are again
200"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5,"forced to use either E or F, depending on the involved factors. We group the two results in one
201"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5017985611510791,"theorem for brevity.
202"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5035971223021583,"Theorem 5 (BR under (1D, 2D) joint corruption). Let (ℓ, H, P) be a learning problem, E : Y ⇝X
203"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5053956834532374,"and F : X ⇝Y be an experiment and a posterior on it.
204"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5071942446043165,"1. Let κY ˜
X be a corruption on X and κXY ˜Y be a corruption on Y , then we can form the jointly
205"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5089928057553957,"corrupted experiment as per the transition diagram
˜X
Y
X
˜Y
κY ˜
X
E"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5107913669064749,"κXY ˜
Y"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.512589928057554,"κXY ˜
Y
and obtain
206"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5143884892086331,"BRℓ◦H[κY ˜
XκXY ˜Y (πY × E)] = EY∼πY CBRκY ˜
X(κXY ˜
Y ℓ◦H)(EY) .
(3)"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5161870503597122,"2. Let κX ˜Y be a corruption on Y and κXY ˜
X be a corruption on X, then we can form the jointly
207"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5179856115107914,"corrupted posterior as per the transition diagram
˜Y
X
Y
˜X
κX ˜
Y
F"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5197841726618705,"κXY ˜
X"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5215827338129496,"κXY ˜
X
and obtain
208"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5233812949640287,"BRℓ◦H[κX ˜Y κXY ˜
X(πX × F)] = EX∼πXCBRκXY ˜
X(κX ˜
Y ℓ◦H)(FX) .
(4)"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5251798561151079,"Being the (1D, 1D) a subcase of both previous corruptions, we can prove the result as a simple
209"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5269784172661871,"corollary. Notice that this implies both E and F formulations to hold.
210"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5287769784172662,"Corollary 6 (BR under (1D, 1D) joint corruption). Let (ℓ, H, P) be a learning problem, E : Y ⇝X
211"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5305755395683454,"and F : X ⇝Y be an experiment and a posterior on it. Let κY ˜
X be a corruption on X and κX ˜Y be
212"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5323741007194245,"a corruption on Y , then we can form the jointly corrupted experiment as per the transition diagram
213"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5341726618705036,"˜X
Y
X
˜Y
κY ˜
X
E
κX ˜
Y
or equivalently
˜Y
X
Y
˜X.
κX ˜
Y
F
κY ˜
X
We obtain
214"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5359712230215827,"BRℓ◦H[κY ˜
X(πY × κX ˜Y E)] = BRκY ˜
X(κX ˜
Y ℓ◦H)(πY × E) ,"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5377697841726619,"or equivalently
215"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.539568345323741,"BRℓ◦H[κX ˜Y (πX × κY ˜
XF)] = BRκY ˜
X(κX ˜
Y ℓ◦H)(πX × F) ."
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5413669064748201,"In all the Theorems involving a 1D corruption, the minimization set is heavily modified. In Eq. (3),
216"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5431654676258992,"the loss function is corrected such that it will be dependent on the parameter x (ℓx), while the whole
217"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5449640287769785,"composition will be evaluated on y instead of x. We the obtain functions of the form ^
ℓx ◦h(y). In
218"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5467625899280576,"Eq. (4), we instead end up having a minimization space of the form ^
(ℓ◦h)y(x). Lastly, both results
219"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5485611510791367,"of Corollary 6 lead to a comparison of performance on the X space instead of Y , with a new loss
220"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5503597122302158,"function that takes in imput y and a probability on X parameterized by y. We can consider the these
221"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.552158273381295,"cases as an expansion of the loss space; more detail will be added in the next section.
222"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5539568345323741,"The only factorization missing from Fig. 1b is the (2D, 2D) one. Because of its high dependence
223"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5557553956834532,"on the parameters, we could not recover a meaningful decomposition of the effect on ℓ◦H. This
224"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5575539568345323,"suggests it to be equivalent to a 2J corruption when looked at through the lens of Bayes Risk. For
225"
CONSEQUENCES OF CORRUPTION IN SUPERVISED LEARNING,0.5593525179856115,"detailed analysis, see Supplementary material § S3.
226"
CORRUPTION-CORRECTED LEARNING,0.5611510791366906,"5
Corruption-corrected learning
227"
CORRUPTION-CORRECTED LEARNING,0.5629496402877698,"We now leverage our corruption framework for answering the question “what can we do to ensure
228"
CORRUPTION-CORRECTED LEARNING,0.564748201438849,"unbiased learning from biased data?”. This question has different answers depending on what we
229"
CORRUPTION-CORRECTED LEARNING,0.5665467625899281,"mean by unbiased learning. As for the biased data, we assume that biased here refers to non-identical
230"
CORRUPTION-CORRECTED LEARNING,0.5683453237410072,"joint corruption acting on a probability, giving us a corrupted training distribution.
231"
CORRUPTION-CORRECTED LEARNING,0.5701438848920863,"Past work from Van Rooyen and Williamson [7] and Patrini et al. [34] considered unbiased learning
232"
CORRUPTION-CORRECTED LEARNING,0.5719424460431655,"as what is known as generalization, i.e. learn on the corrupted space ˜P a hypothesis h∗such that it is
233"
CORRUPTION-CORRECTED LEARNING,0.5737410071942446,"also optimal on the clean distribution P at test time. They choose the approach of corrected learning,
234"
CORRUPTION-CORRECTED LEARNING,0.5755395683453237,"which is, correcting the loss function or the model class in order to learn a h∗capable to generalize.
235"
CORRUPTION-CORRECTED LEARNING,0.5773381294964028,"They both used frameworks related to ours, although only in the presence of simple Y corruption.
236"
CORRUPTION-CORRECTED LEARNING,0.579136690647482,"We prove similar results to these works for the loss correction task and analyze what we can achieve
237"
CORRUPTION-CORRECTED LEARNING,0.5809352517985612,"in other corruption cases described by our taxonomy. In general, we cannot prove generalization but
238"
CORRUPTION-CORRECTED LEARNING,0.5827338129496403,"we exhibit a corrected loss allowing the model learned on ˜P to have the same biases (i.e. loss scores)
239"
CORRUPTION-CORRECTED LEARNING,0.5845323741007195,"as the one found for the clean learning problem. To do so, we make use of the pseudo-inverse of a
240"
CORRUPTION-CORRECTED LEARNING,0.5863309352517986,"Markov kernel (P4), as it is more convenient and powerful than the kernel reconstruction introduced in
241"
CORRUPTION-CORRECTED LEARNING,0.5881294964028777,"[7]. The results we show here also serve as a first step towards understanding the effect of corruption
242"
CORRUPTION-CORRECTED LEARNING,0.5899280575539568,"of the minimization set ℓ◦H, in the cases where the BR equalities are not giving us much information
243"
CORRUPTION-CORRECTED LEARNING,0.591726618705036,"(i.e. all the cases that are not simple label noise [19]).
244"
CORRUPTION-CORRECTED LEARNING,0.5935251798561151,"Again, in this analysis, we ignore the influence of the data sample and the optimization technique. We
245"
CORRUPTION-CORRECTED LEARNING,0.5953237410071942,"use all the assumptions introduced when defining the learning problem in § 2 and the BR results § 4.
246"
CORRUPTION-CORRECTED LEARNING,0.5971223021582733,"The BR equalities for cleaning kernels
The theorems proved in § 4 can then be restated, in terms
247"
CORRUPTION-CORRECTED LEARNING,0.5989208633093526,"of learning problems and pseudo-inverse κ† : ˜Z ⇝Z, as
248"
CORRUPTION-CORRECTED LEARNING,0.6007194244604317,"(ℓ, H, P) →(κ†(ℓ◦H), κP) .
(5)"
CORRUPTION-CORRECTED LEARNING,0.6025179856115108,"We will refer here to the pseudo-inverse of our corruption as the cleaning kernel. Notice that the set
249"
CORRUPTION-CORRECTED LEARNING,0.60431654676259,"κ†(ℓ◦H) is not trivially decomposable as ˜ℓ◦˜H for some loss and model class. In this case, κ†(ℓ◦H)
250"
CORRUPTION-CORRECTED LEARNING,0.6061151079136691,"is said to have no ◦-factorized structure.
251"
CORRUPTION-CORRECTED LEARNING,0.6079136690647482,"The BR equalities are ensuring the existence of a function f ∗∈ℓ◦H ∩κ†(ℓ◦H) that minimizes
the Bayes Risk, i.e."
CORRUPTION-CORRECTED LEARNING,0.6097122302158273,"f ∗∈arg min
f∈ℓ◦H
EP f(Z) and f ∗∈arg min
f∈κ†(ℓ◦H)
EκP f(Z) ."
CORRUPTION-CORRECTED LEARNING,0.6115107913669064,"Sadly, this is not enough for us to find an optimal hypothesis working for both probability spaces.
252"
CORRUPTION-CORRECTED LEARNING,0.6133093525179856,"Formal results on this optimal h ∈H for both clean and corrupted spaces only exist for label noise
253"
CORRUPTION-CORRECTED LEARNING,0.6151079136690647,"[7, 8]. However, by introducing a few further assumptions, we can get results on which alternative loss
254"
CORRUPTION-CORRECTED LEARNING,0.6169064748201439,"to use on train distribution so that the learned h on ˜P will have the same performance scores as the
255"
CORRUPTION-CORRECTED LEARNING,0.6187050359712231,"optimal on (ℓ, H, P). Let us consider the composed representation of the function f ∗in the test (clean)
256"
CORRUPTION-CORRECTED LEARNING,0.6205035971223022,"minimization set, which is f ∗= ℓ◦h∗. We want to construct a suitable composed representation for
257"
CORRUPTION-CORRECTED LEARNING,0.6223021582733813,"f ∗also in the space κ†(ℓ◦H), namely f ∗= ˜ℓ◦˜h∗. We start by fixing a ˜h∗∈H of our choice, that
258"
CORRUPTION-CORRECTED LEARNING,0.6241007194244604,"if asked to be invertible (A1) identifies the loss function as ˜ℓ= ℓ◦h∗◦(˜h∗)−1 : P(Y ) × Y →R+.7
259"
CORRUPTION-CORRECTED LEARNING,0.6258992805755396,"There can be weaker conditions on (˜ℓ, ˜h∗) enabling all the following results, but do not investigate
260"
CORRUPTION-CORRECTED LEARNING,0.6276978417266187,"the here.
261"
CORRUPTION-CORRECTED LEARNING,0.6294964028776978,"Since in general κ†(f ∗) ̸= f ∗, we have that: ∃h′ ∈H s.t. κ†(ℓ◦h′) = ˜ℓ◦˜h∗, where we ask h′ ̸= h∗,
262"
CORRUPTION-CORRECTED LEARNING,0.6312949640287769,"otherwise we would be imposing the trivial condition ℓ◦h∗= ˜ℓ◦˜h∗= κ†(ℓ◦h∗), i.e. the corruption
263"
CORRUPTION-CORRECTED LEARNING,0.6330935251798561,"is harmless w.r.t. the Bayes Risk value. In order to study the possible loss correction, we choose the
264"
CORRUPTION-CORRECTED LEARNING,0.6348920863309353,"corrupted optimum as ˜h∗= h′ (A2).
265"
CORRUPTION-CORRECTED LEARNING,0.6366906474820144,"Loss corrections
We now try to formalize how to define a suitable loss for the corrupted learning
266"
CORRUPTION-CORRECTED LEARNING,0.6384892086330936,"problem, such that the optimal hypothesis is learned in the clean learning space. The problem setting
267"
CORRUPTION-CORRECTED LEARNING,0.6402877697841727,"gives us access to ℓ, κ† given by the problem, and ˜h∗chosen by us. We want to find a way to retrieve a
268"
CORRUPTION-CORRECTED LEARNING,0.6420863309352518,"suitable h∗for the clean distribution. That means, the loss correction task here is finding a formulation
269"
CORRUPTION-CORRECTED LEARNING,0.6438848920863309,"of ˜ℓthat depends on ℓ, κ†. An essential preliminary result, for which the proof is given in § S4.1, is
270"
CORRUPTION-CORRECTED LEARNING,0.64568345323741,"Lemma 7. The feasible factorization of a Markov kernel κ is also a valid factorization for its
271"
CORRUPTION-CORRECTED LEARNING,0.6474820143884892,"pseudo-inverse κ†, both for the full kernel or considering their parameterized versions.
272"
CORRUPTION-CORRECTED LEARNING,0.6492805755395683,"We then give the correction results (proof in § S4.2), and discuss them.
273"
CORRUPTION-CORRECTED LEARNING,0.6510791366906474,"7Here h∗is inverted as a function, not as a kernel. That means, ˜ℓ(p, y) = ℓ(h∗((˜h∗)−1(p)), y)."
CORRUPTION-CORRECTED LEARNING,0.6528776978417267,"Theorem 8. Let (ℓ, H, P) be a clean learning problem and (κ†(ℓ◦H), κP) its associated corrupted
274"
CORRUPTION-CORRECTED LEARNING,0.6546762589928058,"one, not necessarily with a ◦-factorized structure. Let κ† be the joint cleaning kernel reversing κ,
275"
CORRUPTION-CORRECTED LEARNING,0.6564748201438849,"such that assumptions A1 and A2 hold for the said problems. The factorization of κ† is assumed to be
276"
CORRUPTION-CORRECTED LEARNING,0.658273381294964,"feasible and to have an equality result of the form Eq. (5). We write κ†(dz, ˜z) = κX(dx, ·)κY (dy, ·),
277"
CORRUPTION-CORRECTED LEARNING,0.6600719424460432,"with (·) some feasible parameters. Hence, we can prove the following points:
278"
CORRUPTION-CORRECTED LEARNING,0.6618705035971223,"1. When κ† is either (idX, S-Y ) or (idX, 2D-Y ), we can write the corrected loss as
279"
CORRUPTION-CORRECTED LEARNING,0.6636690647482014,"˜ℓ(h(˜x), ˜y) = (κY ℓ) (h(˜x), ˜y)
∀(˜x, ˜y) ∈˜X × ˜Y ,
with κY ℓ= κY
˜x ℓfor the second case.
280"
CORRUPTION-CORRECTED LEARNING,0.6654676258992805,"2. When κ† is (S-X, S-Y ), (2D-X, S-Y ) or (S-X, 2D-Y ), we have
281"
CORRUPTION-CORRECTED LEARNING,0.6672661870503597,"˜ℓ(˜x, ˜y, h) = Eu∼κXh(˜x)[κY ℓ(u, ˜y)]
∀(˜x, ˜y) ∈˜X × ˜Y ,"
CORRUPTION-CORRECTED LEARNING,0.6690647482014388,"with κX
˜x h(˜x)(A) := κX(h−1(A), ˜x) , A ⊂P(Y ) being the push-forward probability measure of
282"
CORRUPTION-CORRECTED LEARNING,0.670863309352518,"κX(·, ˜x) through h, h seen as a function. For the cases that involve a 2D corruption, we have
283"
CORRUPTION-CORRECTED LEARNING,0.6726618705035972,"κY ℓ= κY
˜x ℓfor the former κ† factorization, κXh(˜x) = κX
˜y h(˜x) for the latter.
284"
CORRUPTION-CORRECTED LEARNING,0.6744604316546763,"3. When κ† is a (1D-X, 1D-Y ) corruption, we can write the corrected loss as
285"
CORRUPTION-CORRECTED LEARNING,0.6762589928057554,"˜ℓ(˜x, ˜y, h) = Eu∼κXh(˜y)[κY ℓ(u, ˜x)]
∀(˜x, ˜y) ∈˜X × ˜Y ,"
CORRUPTION-CORRECTED LEARNING,0.6780575539568345,"with κX
˜x h(˜y)(B) := κX(h−1(B), ˜y) , B ⊂P(X).
286"
CORRUPTION-CORRECTED LEARNING,0.6798561151079137,"4. When κ† is a (2D, 1D) corruption, we can write the corrected loss as
287"
CORRUPTION-CORRECTED LEARNING,0.6816546762589928,"˜ℓ(˜x, ˜y, h) = Eu∼κXh(˜y)[κ˜x"
CORRUPTION-CORRECTED LEARNING,0.6834532374100719,"Y ℓ(u, ˜y)] ,
˜ℓ(˜x, ˜y, h) = Eu∼κX
˜y h(˜x)[κY ℓ(u, ˜x)]
∀(˜x, ˜y) ∈˜X× ˜Y ."
CORRUPTION-CORRECTED LEARNING,0.685251798561151,"for the (1D-X, 2D-Y ), (2D-X, 1D-Y ) respectively.
288"
CORRUPTION-CORRECTED LEARNING,0.6870503597122302,"When minimized, the corrected losses will by construction give back the hypothesis ˜h∗. Since
289"
CORRUPTION-CORRECTED LEARNING,0.6888489208633094,"ℓ◦h∗= ˜ℓ◦˜h∗, the learned ˜h∗has on the clean distribution the optimum performance we wanted
290"
CORRUPTION-CORRECTED LEARNING,0.6906474820143885,"to achieve with the original loss function ℓ. Hence, we achieve unbiased learning in the sense of
291"
CORRUPTION-CORRECTED LEARNING,0.6924460431654677,"matching scores and in the distributional sense.
292"
CORRUPTION-CORRECTED LEARNING,0.6942446043165468,"The corrections found by the theorem are more complex than the ones defined in previous work
293"
CORRUPTION-CORRECTED LEARNING,0.6960431654676259,"[7, 34], i.e., the first part of point 1. In the second part, we characterize the effect of a more “dependent”
294"
CORRUPTION-CORRECTED LEARNING,0.697841726618705,"Y cleaning kernel, i.e. closer to the root in Fig. 1a. When also κX is non-trivial in the factorization,
295"
CORRUPTION-CORRECTED LEARNING,0.6996402877697842,"we have an action on h. Then, the corrected functions lie in a larger function space than the usual
296"
CORRUPTION-CORRECTED LEARNING,0.7014388489208633,"one, the one of positive, bounded functions ℓ: X × Y × H →R+.
297"
CORRUPTION-CORRECTED LEARNING,0.7032374100719424,"The result additionally underlines how the cleaning kernel affects the a hypothesis on X: it induces a
298"
CORRUPTION-CORRECTED LEARNING,0.7050359712230215,"set of “reachable predictions” from h through κ†, depending on the outcome of the stochastic process
299"
CORRUPTION-CORRECTED LEARNING,0.7068345323741008,"κ† : ˜X ⇝X. The push-forward probability measures are probabilities on a set of probabilities. For
300"
CORRUPTION-CORRECTED LEARNING,0.7086330935251799,"instance, in point 2 we have κX
˜y h(˜x) ∈P(P(Y )), while for point 3 we have κX
˜x h(˜x) ∈P(P(X)).
301"
CONCLUSIONS,0.710431654676259,"6
Conclusions
302"
CONCLUSIONS,0.7122302158273381,"We proposed a comprehensive and unified framework for corruption using Markov kernels, system-
303"
CONCLUSIONS,0.7140287769784173,"atically studying corruption in three key aspects: classification, consequence, and correction. We
304"
CONCLUSIONS,0.7158273381294964,"established a new taxonomy of corruption, enabling qualitative comparisons between corruption
305"
CONCLUSIONS,0.7176258992805755,"models in terms of the corruption hierarchy. To gain a deeper quantitative understanding of corruption,
306"
CONCLUSIONS,0.7194244604316546,"we analyzed the consequences of different corruptions from an information-theoretic standpoint by
307"
CONCLUSIONS,0.7212230215827338,"proving Data Processing Equalities for Bayes Risk. As a consequence of them, we obtained loss
308"
CONCLUSIONS,0.7230215827338129,"correction formulas that gives us more insights into the effect of corruption on losses.
309"
CONCLUSIONS,0.7248201438848921,"Throughout the work, we consider data as probability distributions, implicitly assuming that each
310"
CONCLUSIONS,0.7266187050359713,"dataset has an associated probabilistic generative process. We treat corruption as Markov kernels,
311"
CONCLUSIONS,0.7284172661870504,"assuming full access to their actions, and analyze the consequences of corruption through Bayes risks
312"
CONCLUSIONS,0.7302158273381295,"without accounting for sampling or optimization. Bridging the gap between the distributional-level
313"
CONCLUSIONS,0.7320143884892086,"and the sample-level results would be the next step for this study, which requires tailored ad-hoc
314"
CONCLUSIONS,0.7338129496402878,"analyses. Other directions for making this framework more practically usable include developing
315"
CONCLUSIONS,0.7356115107913669,"quantitative methods to compare corruption severity and investigating the effects of optimization
316"
CONCLUSIONS,0.737410071942446,"algorithms on the analysis.
317"
REFERENCES,0.7392086330935251,"References
318"
REFERENCES,0.7410071942446043,"[1] Mary Poovey et al. A history of the modern fact: Problems of knowledge in the sciences of wealth and
319"
REFERENCES,0.7428057553956835,"society. University of Chicago Press, 1998.
320"
REFERENCES,0.7446043165467626,"[2] Robert Williamson. Process and Purpose, Not Thing and Technique: How to Pose Data Science Research
321"
REFERENCES,0.7464028776978417,"Challenges. Harvard Data Science Review, 2(3), sep 30 2020. https://hdsr.mitpress.mit.edu/pub/f2cllynw.
322"
REFERENCES,0.7482014388489209,"[3] Hidetoshi Shimodaira. Improving predictive inference under covariate shift by weighting the log-likelihood
323"
REFERENCES,0.75,"function. Journal of statistical planning and inference, 90(2):227–244, 2000.
324"
REFERENCES,0.7517985611510791,"[4] Xingquan Zhu and Xindong Wu. Class noise vs. attribute noise: A quantitative study. The Artificial
325"
REFERENCES,0.7535971223021583,"Intelligence Review, 22(3):177, 2004.
326"
REFERENCES,0.7553956834532374,"[5] Nagarajan Natarajan, Inderjit S Dhillon, Pradeep K Ravikumar, and Ambuj Tewari. Learning with noisy
327"
REFERENCES,0.7571942446043165,"labels. Advances in neural information processing systems, 26, 2013.
328"
REFERENCES,0.7589928057553957,"[6] Aditya Menon, Brendan Van Rooyen, Cheng Soon Ong, and Bob Williamson. Learning from corrupted
329"
REFERENCES,0.7607913669064749,"binary labels via class-probability estimation. In International conference on machine learning, pages
330"
REFERENCES,0.762589928057554,"125–134. PMLR, 2015.
331"
REFERENCES,0.7643884892086331,"[7] Brendan Van Rooyen and Robert C Williamson. A theory of learning with corrupted labels. J. Mach.
332"
REFERENCES,0.7661870503597122,"Learn. Res., 18(1):8501–8550, 2017.
333"
REFERENCES,0.7679856115107914,"[8] Aditya Krishna Menon, Brendan Van Rooyen, and Nagarajan Natarajan. Learning from binary labels with
334"
REFERENCES,0.7697841726618705,"instance-dependent noise. Machine Learning, 107(8):1561–1595, 2018.
335"
REFERENCES,0.7715827338129496,"[9] Andrey Malinin, Neil Band, German Chesnokov, Yarin Gal, Mark JF Gales, Alexey Noskov, Andrey
336"
REFERENCES,0.7733812949640287,"Ploskonosov, Liudmila Prokhorenkova, Ivan Provilkov, Vatsal Raina, et al. Shifts: A dataset of real
337"
REFERENCES,0.7751798561151079,"distributional shift across multiple large-scale tasks. arXiv preprint arXiv:2107.07455, 2021.
338"
REFERENCES,0.7769784172661871,"[10] Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani,
339"
REFERENCES,0.7787769784172662,"Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al. Wilds: A benchmark of in-
340"
REFERENCES,0.7805755395683454,"the-wild distribution shifts. In International Conference on Machine Learning, pages 5637–5664. PMLR,
341"
REFERENCES,0.7823741007194245,"2021.
342"
REFERENCES,0.7841726618705036,"[11] Xiao-Li Meng. Enhancing (publications on) data quality: Deeper data minding and fuller data confession.
343"
REFERENCES,0.7859712230215827,"Journal of the Royal Statistical Society Series A: Statistics in Society, 184(4):1161–1175, 2021.
344"
REFERENCES,0.7877697841726619,"[12] Negar Rostamzadeh, Ben Hutchinson, Christina Greer, and Vinodkumar Prabhakaran. Thinking beyond
345"
REFERENCES,0.789568345323741,"distributions in testing machine learned models. In NeurIPS 2021 Workshop on Distribution Shifts:
346"
REFERENCES,0.7913669064748201,"Connecting Methods and Applications.
347"
REFERENCES,0.7931654676258992,"[13] Nithya Sambasivan, Shivani Kapania, Hannah Highfill, Diana Akrong, Praveen Paritosh, and Lora M
348"
REFERENCES,0.7949640287769785,"Aroyo. ""Everyone wants to do the model work, not the data work"": Data Cascades in High-Stakes AI. In
349"
REFERENCES,0.7967625899280576,"proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, pages 1–15, 2021.
350"
REFERENCES,0.7985611510791367,"[14] Joaquin Quinonero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D Lawrence. Dataset shift
351"
REFERENCES,0.8003597122302158,"in machine learning. Mit Press, 2008.
352"
REFERENCES,0.802158273381295,"[15] José A. Sáez. Noise models in classification: Unified nomenclature, extended taxonomy and pragmatic
353"
REFERENCES,0.8039568345323741,"categorization. Mathematics, 10(20), 2022. ISSN 2227-7390. doi: 10.3390/math10203736.
354"
REFERENCES,0.8057553956834532,"[16] Adarsh Subbaswamy, Bryant Chen, and Suchi Saria. A unifying causal framework for analyzing dataset
355"
REFERENCES,0.8075539568345323,"shift-stable learning algorithms. Journal of Causal Inference, 10(1):64–89, 2022.
356"
REFERENCES,0.8093525179856115,"[17] Jose G Moreno-Torres, Troy Raeder, Rocío Alaiz-Rodríguez, Nitesh V Chawla, and Francisco Herrera. A
357"
REFERENCES,0.8111510791366906,"unifying view on dataset shift in classification. Pattern recognition, 45(1):521–530, 2012.
358"
REFERENCES,0.8129496402877698,"[18] Meelis Kull and Peter Flach. Patterns of dataset shift. In First International Workshop on Learning over
359"
REFERENCES,0.814748201438849,"Multiple Contexts (LMCE) at ECML-PKDD, 2014.
360"
REFERENCES,0.8165467625899281,"[19] Robert C Williamson and Zac Cranko. Information processing equalities and the information-risk bridge.
361"
REFERENCES,0.8183453237410072,"arXiv preprint arXiv:2207.11987, 2022.
362"
REFERENCES,0.8201438848920863,"[20] Erik Torgersen. Comparison of statistical experiments, volume 36. Cambridge University Press, 1991.
363"
REFERENCES,0.8219424460431655,"[21] Albert N Shiryaev and Vladimir G Spokoiny. Statistical Experiments And Decision, Asymptotic Theory,
364"
REFERENCES,0.8237410071942446,"volume 8. World Scientific, 2000.
365"
REFERENCES,0.8255395683453237,"[22] Achim Klenke. Probability Theory: A Comprehensive Course. Springer, 2007.
366"
REFERENCES,0.8273381294964028,"[23] Mark D Reid and Robert C Williamson. Composite binary losses. The Journal of Machine Learning
367"
REFERENCES,0.829136690647482,"Research, 11:2387–2422, 2010.
368"
REFERENCES,0.8309352517985612,"[24] Robert Williamson, Elodie Vernet, Mark Reid, et al. Composite multiclass losses. 2016.
369"
REFERENCES,0.8327338129496403,"[25] Mark Reid, Robert Williamson, et al. Information, divergence and risk for binary experiments. 2011.
370"
REFERENCES,0.8345323741007195,"[26] Fredrik Dahlqvist, Vincent Danos, Ilias Garnier, and Ohad Kammar. Bayesian inversion by ω-complete
371"
REFERENCES,0.8363309352517986,"cone duality. In 27th International Conference on Concurrency Theory, 2016.
372"
REFERENCES,0.8381294964028777,"[27] Kenta Cho and Bart Jacobs. Disintegration and bayesian inversion via string diagrams. Mathematical
373"
REFERENCES,0.8399280575539568,"Structures in Computer Science, 29(7):938–971, 2019.
374"
REFERENCES,0.841726618705036,"[28] Bart Jacobs and Fabio Zanasi. The logical essentials of bayesian reasoning. Foundations of Probabilistic
375"
REFERENCES,0.8435251798561151,"Programming, pages 295–331, 2020.
376"
REFERENCES,0.8453237410071942,"[29] Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Vaughan. A
377"
REFERENCES,0.8471223021582733,"theory of learning from different domains. Machine Learning, 79:151–175, 2010.
378"
REFERENCES,0.8489208633093526,"[30] George Shackelford and Dennis Volper. Learning k-dnf with noise in the attributes. In Proceedings of the
379"
REFERENCES,0.8507194244604317,"first annual workshop on Computational learning theory, pages 97–103, 1988.
380"
REFERENCES,0.8525179856115108,"[31] Sally A. Goldman and Robert H. Sloan. Can pac learning algorithms tolerate random attribute noise?
381"
REFERENCES,0.85431654676259,"Algorithmica, 14(1):70–84, 1995.
382"
REFERENCES,0.8561151079136691,"[32] Dana Angluin and Philip Laird. Learning from noisy examples. Machine Learning, 2:343–370, 1988.
383"
REFERENCES,0.8579136690647482,"[33] Avrim Blum and Tom Mitchell. Combining labeled and unlabeled data with co-training. In Proceedings of
384"
REFERENCES,0.8597122302158273,"the eleventh annual conference on Computational learning theory, pages 92–100, 1998.
385"
REFERENCES,0.8615107913669064,"[34] Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu. Making deep
386"
REFERENCES,0.8633093525179856,"neural networks robust to label noise: A loss correction approach. In Proceedings of the IEEE conference
387"
REFERENCES,0.8651079136690647,"on computer vision and pattern recognition, pages 1944–1952, 2017.
388"
REFERENCES,0.8669064748201439,"[35] Leon A Gatys, Alexander S Ecker, and Matthias Bethge. A neural algorithm of artistic style. arXiv preprint
389"
REFERENCES,0.8687050359712231,"arXiv:1508.06576, 2015.
390"
REFERENCES,0.8705035971223022,"[36] Justin Johnson, Alexandre Alahi, and Li Fei-Fei. Perceptual losses for real-time style transfer and super-
391"
REFERENCES,0.8723021582733813,"resolution. In Computer Vision–ECCV 2016: 14th European Conference, Amsterdam, The Netherlands,
392"
REFERENCES,0.8741007194244604,"October 11-14, 2016, Proceedings, Part II 14, pages 694–711. Springer, 2016.
393"
REFERENCES,0.8758992805755396,"[37] Eric Grinstein, Ngoc QK Duong, Alexey Ozerov, and Patrick Pérez. Audio style transfer. In 2018 IEEE
394"
REFERENCES,0.8776978417266187,"international conference on acoustics, speech and signal processing (ICASSP), pages 586–590. IEEE,
395"
REFERENCES,0.8794964028776978,"2018.
396"
REFERENCES,0.8812949640287769,"[38] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and
397"
REFERENCES,0.8830935251798561,"Rob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013.
398"
REFERENCES,0.8848920863309353,"[39] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples.
399"
REFERENCES,0.8866906474820144,"arXiv preprint arXiv:1412.6572, 2014.
400"
REFERENCES,0.8884892086330936,"[40] Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z Berkay Celik, and Ananthram Swami.
401"
REFERENCES,0.8902877697841727,"The limitations of deep learning in adversarial settings. In 2016 IEEE European symposium on security
402"
REFERENCES,0.8920863309352518,"and privacy (EuroS&P), pages 372–387. IEEE, 2016.
403"
REFERENCES,0.8938848920863309,"[41] Alexey Kurakin, Ian J Goodfellow, and Samy Bengio. Adversarial examples in the physical world. In
404"
REFERENCES,0.89568345323741,"Artificial intelligence safety and security, pages 99–112. Chapman and Hall/CRC, 2018.
405"
REFERENCES,0.8974820143884892,"[42] Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, and Dawn Song. Natural adversarial
406"
REFERENCES,0.8992805755395683,"examples. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
407"
REFERENCES,0.9010791366906474,"pages 15262–15271, 2021.
408"
REFERENCES,0.9028776978417267,"[43] Jiacheng Cheng, Tongliang Liu, Kotagiri Ramamohanarao, and Dacheng Tao. Learning with bounded
409"
REFERENCES,0.9046762589928058,"instance and label-dependent label noise. In International Conference on Machine Learning, pages
410"
REFERENCES,0.9064748201438849,"1789–1799. PMLR, 2020.
411"
REFERENCES,0.908273381294964,"[44] Yu Yao, Tongliang Liu, Mingming Gong, Bo Han, Gang Niu, and Kun Zhang. Instance-dependent label-
412"
REFERENCES,0.9100719424460432,"noise learning under a structural causal model. Advances in Neural Information Processing Systems, 34:
413"
REFERENCES,0.9118705035971223,"4409–4420, 2021.
414"
REFERENCES,0.9136690647482014,"[45] Qizhou Wang, Bo Han, Tongliang Liu, Gang Niu, Jian Yang, and Chen Gong. Tackling instance-dependent
415"
REFERENCES,0.9154676258992805,"label noise via a universal probabilistic model. In Proceedings of the AAAI Conference on Artificial
416"
REFERENCES,0.9172661870503597,"Intelligence, volume 35, pages 10183–10191, 2021.
417"
REFERENCES,0.9190647482014388,"[46] Nathalie Japkowicz and Shaju Stephen. The class imbalance problem: A systematic study. Intelligent data
418"
REFERENCES,0.920863309352518,"analysis, 6(5):429–449, 2002.
419"
REFERENCES,0.9226618705035972,"[47] Haibo He and Edwardo A Garcia. Learning from imbalanced data. IEEE Transactions on knowledge and
420"
REFERENCES,0.9244604316546763,"data engineering, 21(9):1263–1284, 2009.
421"
REFERENCES,0.9262589928057554,"[48] Mateusz Buda, Atsuto Maki, and Maciej A Mazurowski. A systematic study of the class imbalance
422"
REFERENCES,0.9280575539568345,"problem in convolutional neural networks. Neural networks, 106:249–259, 2018.
423"
REFERENCES,0.9298561151079137,"[49] Zachary Lipton, Yu-Xiang Wang, and Alexander Smola. Detecting and correcting for label shift with black
424"
REFERENCES,0.9316546762589928,"box predictors. In International conference on machine learning, pages 3122–3130. PMLR, 2018.
425"
REFERENCES,0.9334532374100719,"[50] Gilles Blanchard, Marek Flaska, Gregory Handy, Sara Pozzi, and Clayton Scott. Classification with
426"
REFERENCES,0.935251798561151,"asymmetric label noise: Consistency and maximal denoising. Electronic Journal of Statistics, 10(2):
427"
REFERENCES,0.9370503597122302,"2780–2824, 2016.
428"
REFERENCES,0.9388489208633094,"[51] Julian Katz-Samuels, Gilles Blanchard, and Clayton Scott. Decontamination of mutual contamination
429"
REFERENCES,0.9406474820143885,"models. Journal of machine learning research, 20(41), 2019.
430"
REFERENCES,0.9424460431654677,"[52] Arthur Gretton, Alex Smola, Jiayuan Huang, Marcel Schmittfull, Karsten Borgwardt, and Bernhard
431"
REFERENCES,0.9442446043165468,"Schölkopf. Covariate shift by kernel mean matching. Dataset shift in machine learning, 3(4):5, 2009.
432"
REFERENCES,0.9460431654676259,"[53] Masashi Sugiyama and Motoaki Kawanabe. Machine learning in non-stationary environments: Introduc-
433"
REFERENCES,0.947841726618705,"tion to covariate shift adaptation. MIT press, 2012.
434"
REFERENCES,0.9496402877697842,"[54] Tianyi Zhang, Ikko Yamane, Nan Lu, and Masashi Sugiyama. A one-step approach to covariate shift
435"
REFERENCES,0.9514388489208633,"adaptation. In Asian Conference on Machine Learning, pages 65–80. PMLR, 2020.
436"
REFERENCES,0.9532374100719424,"[55] Kun Zhang, Bernhard Schölkopf, Krikamol Muandet, and Zhikun Wang. Domain adaptation under target
437"
REFERENCES,0.9550359712230215,"and conditional shift. In International conference on machine learning, pages 819–827. PMLR, 2013.
438"
REFERENCES,0.9568345323741008,"[56] Mingming Gong, Kun Zhang, Tongliang Liu, Dacheng Tao, Clark Glymour, and Bernhard Schölkopf.
439"
REFERENCES,0.9586330935251799,"Domain adaptation with conditional transferable components. In International conference on machine
440"
REFERENCES,0.960431654676259,"learning, pages 2839–2848. PMLR, 2016.
441"
REFERENCES,0.9622302158273381,"[57] Xiyu Yu, Tongliang Liu, Mingming Gong, Kun Zhang, Kayhan Batmanghelich, and Dacheng Tao. Label-
442"
REFERENCES,0.9640287769784173,"noise robust domain adaptation. In International conference on machine learning, pages 10913–10924.
443"
REFERENCES,0.9658273381294964,"PMLR, 2020.
444"
REFERENCES,0.9676258992805755,"[58] Gerhard Widmer and Miroslav Kubat. Learning in the presence of concept drift and hidden contexts.
445"
REFERENCES,0.9694244604316546,"Machine learning, 23:69–101, 1996.
446"
REFERENCES,0.9712230215827338,"[59] Jie Lu, Anjin Liu, Fan Dong, Feng Gu, Joao Gama, and Guangquan Zhang. Learning under concept drift:
447"
REFERENCES,0.9730215827338129,"A review. IEEE Transactions on Knowledge and Data Engineering, pages 1–1, 2018. doi: 10.1109/tkde.
448"
REFERENCES,0.9748201438848921,"2018.2876857.
449"
REFERENCES,0.9766187050359713,"[60] Brendan Van Rooyen et al. Machine learning via transitions. PhD thesis, The Australian National
450"
REFERENCES,0.9784172661870504,"University, 2015.
451"
REFERENCES,0.9802158273381295,"[61] Bianca Zadrozny. Learning and evaluating classifiers under sample selection bias. In Proceedings of the
452"
REFERENCES,0.9820143884892086,"twenty-first international conference on Machine learning, page 114, 2004.
453"
REFERENCES,0.9838129496402878,"[62] Masashi Sugiyama, Matthias Krauledat, and Klaus-Robert Müller. Covariate shift adaptation by importance
454"
REFERENCES,0.9856115107913669,"weighted cross validation. Journal of Machine Learning Research, 8(5), 2007.
455"
REFERENCES,0.987410071942446,"[63] Ievgen Redko, Emilie Morvant, Amaury Habrard, Marc Sebban, and Younès Bennani. A survey on domain
456"
REFERENCES,0.9892086330935251,"adaptation theory: learning bounds and theoretical guarantees. arXiv preprint arXiv:2004.11829, 2020.
457"
REFERENCES,0.9910071942446043,"[64] Christopher M Bishop and Nasser M Nasrabadi. Pattern recognition and machine learning, volume 4.
458"
REFERENCES,0.9928057553956835,"Springer, 2006.
459"
REFERENCES,0.9946043165467626,"[65] Madelyn Glymour, Judea Pearl, and Nicholas P Jewell. Causal inference in statistics: A primer. John
460"
REFERENCES,0.9964028776978417,"Wiley & Sons, 2016.
461"
REFERENCES,0.9982014388489209,"[66] Vladimir Igorevich Bogachev. Measure theory, volume 1. Springer, 2007.
462"
