Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0048543689320388345,"Estimating causal effects from observational data is a central problem in many
2
domains. A general approach is to balance covariates with weights such that the
3
distribution of the data mimics randomization. We present generalized balanc-
4
ing weights, Neural Balancing Weights (NBW), to estimate the causal effects of
5
an arbitrary mixture of discrete and continuous interventions. The weights were
6
obtained through direct estimation of the density ratio between the source and bal-
7
anced distributions by optimizing the variational representation of f-divergence.
8
For this, we selected α-divergence as it presents efﬁcient optimization because
9
it has an estimator whose sample complexity is independent of its ground truth
10
value and unbiased mini-batch gradients; moreover, it is advantageous for the
11
vanishing-gradient problem. In addition, we provide the following two methods
12
for estimating the balancing weights: improving the generalization performance
13
of the balancing weights and checking the balance of the distribution changed by
14
the weights. Finally, we discuss the sample size requirements for the weights as
15
a general problem of a curse of dimensionality when balancing multidimensional
16
data. Our study provides a basic approach for estimating the balancing weights of
17
multidimensional data using variational f-divergences.
18"
INTRODUCTION,0.009708737864077669,"1
Introduction
19"
INTRODUCTION,0.014563106796116505,"Estimating causal effects from observational data is a central problem in many application domains,
20
including public health, social sciences, clinical pharmacology, and clinical decision-making. One
21
standard approach is balancing covariates with weights that are the same as the density ratios be-
22
tween the source and balanced distributions, such that their distribution mimics randomization.
23
Many methods have been developed to estimate the balancing weights, such as inverse propen-
24
sity weighting (IPW) Rosenbaum and Rubin [24], augmented inverse propensity weighting (AIPW)
25
[22], generalized propensity score (GPS) [10], covariate balancing propensity score (CBPS) [9],
26
overlap weighting [13], and entropy balancing (EB) [8, 30]. However, these methods are limited to
27
categorical or continuous interventions.
28"
INTRODUCTION,0.019417475728155338,"In this study, we propose generalized balancing weights to estimate the causal effects of an arbitrary
29
mixture of discrete and continuous interventions. To the best of our knowledge, no causal infer-
30
ence method focusing on the balancing weights exists for this problem. We approach this problem
31
by directly estimating the density ratio, more precisely, the Radon–Nikodým derivatives, between
32
the source and balanced distributions using a neural network algorithm by optimizing a variational
33
representation of a f-divergence. f-divergences, whose values are greater than or equal to zero and
34
considered zero if the two distributions are equal, are the statistics used to measure the closeness
35
of the two distributions. The optimal functions for the variational representations derived from f-
36
divergences with the Legendre transform correspond to the density ratio between the distributions
37"
INTRODUCTION,0.024271844660194174,"[16]. An approach to estimate the density ratio by optimizing a variational representation of a f-
38
divergence was developed in the domain adaptation region [29].
39"
INTRODUCTION,0.02912621359223301,"However, optimizing the f-divergences, including estimating the density ratio, is challenging. This
40
is due to the following reasons. First, for KL-divergence, the dominant f-divergence, the require-
41
ments for sample size increase exponentially with the true amount of the divergence [14, 28]. Sec-
42
ond, a naive gradient estimate over mini-batch samples leads to a biased estimate of the full gradient
43
[4]. Third, gradients of neural networks often vanish when the estimated probability ratios are close
44
to zero [2].
45"
INTRODUCTION,0.03398058252427184,"To avoid the ﬁrst problem, we focus on α-divergence, which is a subgroup of f-divergence. α-
46
divergence has an estimator whose sample complexity is independent of its ground truth value and
47
unbiased mini-batch gradients. In addition, by selecting α from a particular interval, we avoid
48
vanishing gradients of neural networks when the neural networks reach extreme local minima.
49"
INTRODUCTION,0.038834951456310676,"In addition, we provide two techniques for estimating the balancing weights. First, we propose
50
a validation method using test data and an early stopping method to improve the generalization
51
performance of balancing. The generalization performance of the weights worsens as the dimensions
52
of the data increase, and the sample size requirements of the weights increase exponentially with the
53
dimensions. Next, we present a method for measuring the performance of balancing weights by
54
estimating the α-divergence information to check the balance of the distribution,
55"
INTRODUCTION,0.043689320388349516,"This study is divided into seven parts. First, we introduce the background of the study. Second,
56
we review related studies. Third, we deﬁne the terminology and concepts for causal inferences.
57
Fourth, we present our novel method for estimating balancing weights. Fifth, we provide techniques
58
for estimating the weights. Sixth, we discuss the sample requirements for the weights. Finally, we
59
conclude this paper. All the numerical experiments and proofs are described in the appendix.
60"
RELATED WORK,0.04854368932038835,"2
Related Work
61"
RELATED WORK,0.05339805825242718,"Balancing weight: Balancing weight: Many methods have been proposed to estimate the balanc-
62
ing weights. The following methods are proposed for binary intervention: IPW [24], AIPW [22],
63
CBPS [9], and overlap weighting [13]. The following methods have been proposed for continu-
64
ous intervention: GPS [10] and EB [8, 30]. Statistical divergences and density ratio estimation:
65
Despite the abundance of classic studies [15, 29], we focused on studies that directly estimate den-
66
sity ratios or optimize statistical divergences using neural networks. In this review, these studies
67
have beenclassiﬁed into four groups. First is the estimation of KL-divergence or mutual information
68
[3, 18, 21]; the second is density ratio estimation [11]; the third is generative adversarial networks
69
(GANs) [17, 31, 6, 32] (statistical divergences were used as discriminators for GANs); and the
70
fourth is domain generation [27, 6, 35, 1]. In addition to these application studies, divergences were
71
improved [5].
72"
RELATED WORK,0.05825242718446602,"3
Terminologies and Deﬁnitions
73"
RELATED WORK,0.06310679611650485,"Here, we brieﬂy introduce the terminology and deﬁnitions used in this study.
74"
RELATED WORK,0.06796116504854369,"Notations and Terminologies.
Random variables are denoted by capital letters; for example, A.
75
Small letters are used for the values of random variables of the corresponding capital letters; a is
76
the value of the random variable A. Bold letters A or a represent a set of variables or random
77
variable values. In particular, V = {V1, . . . , Vn} are used for the observed random variables and
78
U = {U1, . . . , Um} are used as unobserved random variables. For example, the domain of the
79
variable A is denoted by XA, and XA1 × · · · × XAn is denoted by XA for A = A1 × · · · × An.
80
V ∪U are assumed to be semi-Markovian models and G = GVU denotes the causal graph for
81
V ∪U. Pa(A)G, Ch(A)G, An(A)G, and De(A)G represent parents, children, ancestors, and
82
descendants of the observed variables in G, respectively, for A ⊂V. In this study, Pa(A)G,
83
Ch(A)G, An(A)G, and De(A)G do not include A. P and Q are used as the probability measures
84
on (Rd, F), where F denotes the σ-algebra of subsets of Rd. EP [·] and EP [·|·] denote expectation
85
and conditional expectation under the distribution P, respectively. For example, EP [X] =
R"
RELATED WORK,0.07281553398058252,"XX dP
86"
RELATED WORK,0.07766990291262135,"and EP [Y|X] =
R"
RELATED WORK,0.0825242718446602,"XY dP(Y|X).
ˆEP [·] denotes the empirical expectation under P; that is, the
87"
RELATED WORK,0.08737864077669903,"sample mean of the ﬁnite observations drawn from P. P is called absolute continuous with respect
88
to Q, P(A) = 0 whenever Q(A) = 0 for any A ∈F, which is represented as P ≪Q. dP"
RELATED WORK,0.09223300970873786,"dQ denotes
89
the Radon–Nikodým derivative of P with respect to Q for P and Q with P ≪Q. In this study,
90
we refer to density ratios as the Radon–Nikodým derivatives. µ denotes a probability measure
91
on Rd with P ≪µ and Q ≪µ. X(N) = {X1, . . . , XN} denotes N i.i.d. random variables
92
from µ. X(N)
P
= {X1
∼P , . . . , XN
∼P } and X(N)
Q
= {X1
∼Q, . . . , XN
∼Q} denote variables deﬁned as
93
P(Xi
∼P ≤x) = µ(Xi ≤x) and Q(Xi
∼Q ≤x) = µ(Xi ≤x), ∀x ∈Rd, for 1 ≤i ≤N. We
94
represent f ≲g when lim supn→∞f(n)/g(n) < ∞holds. The notation f ≳g is deﬁned similarly.
95"
RELATED WORK,0.0970873786407767,"3.1
Deﬁnitions
96"
RELATED WORK,0.10194174757281553,"In this study, we considered the causal effects of joint and multidimensional interventions. For
97
clarity, we used different notations,“ do ”and“ do, ”for single-dimensional and multidimensional
98
interventions, respectively. 1 For a single-dimensional intervention, a do symbol is used, which is
99
the same as Pearl’s do-calculation.
100
Deﬁnition 3.1 (do-calculation, Pearl(2009)). For the two given disjoint sets of X, Y ⊂V, the
101
causal effect on Y for intervention in X with values x, denoted by P(Y|do(X = x)), is deﬁned as
102
the probability distribution, such that
103"
RELATED WORK,0.10679611650485436,"P(Y|do(X = x)) =
X"
RELATED WORK,0.11165048543689321,"v′∈XV′
pax∈XP a(X)G"
RELATED WORK,0.11650485436893204,"P(Y, X = x, Pa(X)G = pax, V′ = v′)"
RELATED WORK,0.12135922330097088,"P(X = x|Pa(X)G = pax)
,
(1)"
RELATED WORK,0.1262135922330097,"where V′ = V \ (X ∪Pa(X)G ∪Y). The causal effect of X on Y under the conditions Z denoted
104
by P(Y = y|do(X = x), Z = z) is deﬁned as the probability distribution, such that
105"
RELATED WORK,0.13106796116504854,"P(Y = y|do(X = x), Z) = P(Y = y, Z|do(X = x))"
RELATED WORK,0.13592233009708737,"P(Z|do(X = x))
.
(2)"
RELATED WORK,0.1407766990291262,"Notably, from Deﬁnition 3.1, a do-calculation for a set of variables coincides with the simultaneous
106
interventions for each variable:
107"
RELATED WORK,0.14563106796116504,"P(Y|do(X)) = P(Y|do(X1), do(X2), . . . , do(Xn)),
(3)"
RELATED WORK,0.15048543689320387,"where X = {X1, X2, . . . , Xn}. Here, we refer to each intervention in (3) as a“ single-dimensional
108
intervention ”.
109"
RELATED WORK,0.1553398058252427,"Furthermore, we use the do symbol for multidimensional intervention. Intuitively, a do symbol
110
represents the intervention of the variables that preserves the functional relationship within the vari-
111
ables.
112
Deﬁnition 3.2 (do symbol). do symbol deﬁnes the following probability distribution:
113"
RELATED WORK,0.16019417475728157,"P(Y|do(X1), do(X2), . . . , do(Xn)) = P(Y|do(X)) × P(X1) × P(X2) × · · · × P(Xn),
(4)"
RELATED WORK,0.1650485436893204,"where X = X1 ∪X2 ∪· · · ∪Xn.
114"
RELATED WORK,0.16990291262135923,"do symbols are useful, particularly when we consider interventions in a multivalued discrete variable
115
expressed using one-hot encoding. In this case, we cannot express the causal effect effectively using
116
do symbols. For example, let us consider the case of an intervention in the ternary variable X, XX =
117
{x1, x2, x3} and let X be expressed by X′ = (X′
1, X′
2, X′
3), such that X′
i = 1 if X = xi otherwise
118
X′
i = 0 for i = 1, 2, 3. Then, P(·|do(X = x3)) is the same as P(·|do(X′ = (0, 0, 1))), which
119
differs from P(·|do(X′ = (0, 0, 1))). We refer to this type of intervention as a“ multidimensional
120
intervention ”.
121"
RELATED WORK,0.17475728155339806,"Next, we provide deﬁnitions of the f-divergence and f-divergence information.
122
Deﬁnition 3.3 (f-divergence). The f-divergence Df between the two probability measures P and
123
Q with Q ≪P induced by a convex function f satisfying f(1) = 0 is deﬁned by Df(Q||P) =
124
EP [f(dQ/dP)].
125"
THE VALUES OF THE VARIABLES IN THE PARENTHESES FOR BOTH SYMBOLS CAN BE DROPPED IF NOT NECESSARY IN THE,0.1796116504854369,"1The values of the variables in the parentheses for both symbols can be dropped if not necessary in the
context. For example, we sometimes represent do(X = x) or do(X = x) as do(X) or do(X), respectively."
THE VALUES OF THE VARIABLES IN THE PARENTHESES FOR BOTH SYMBOLS CAN BE DROPPED IF NOT NECESSARY IN THE,0.18446601941747573,"Many divergences are speciﬁc cases obtained by selecting a suitable generator function f. For
126
example, f(u) = u log u corresponds to the KL-divergence. In particular, we focus on α-divergence,
127
which is expressed as follows:
128"
THE VALUES OF THE VARIABLES IN THE PARENTHESES FOR BOTH SYMBOLS CAN BE DROPPED IF NOT NECESSARY IN THE,0.18932038834951456,Dα(Q||P) = EP
THE VALUES OF THE VARIABLES IN THE PARENTHESES FOR BOTH SYMBOLS CAN BE DROPPED IF NOT NECESSARY IN THE,0.1941747572815534,"""
1
α(α −1) (dQ dP"
THE VALUES OF THE VARIABLES IN THE PARENTHESES FOR BOTH SYMBOLS CAN BE DROPPED IF NOT NECESSARY IN THE,0.19902912621359223,"1−α
−1 )# ,
(5)"
THE VALUES OF THE VARIABLES IN THE PARENTHESES FOR BOTH SYMBOLS CAN BE DROPPED IF NOT NECESSARY IN THE,0.20388349514563106,"where α ∈R \ {0, 1}. From (5), Hellinger divergence is obtained as α = 1/2, and χ2 divergence
129
by α = −1.
130"
THE VALUES OF THE VARIABLES IN THE PARENTHESES FOR BOTH SYMBOLS CAN BE DROPPED IF NOT NECESSARY IN THE,0.2087378640776699,"From f-divergence, the f-divergence information is deﬁned as the mutual information if we choose
131
the KL-divergence as the f-divergence. Here, we present a deﬁnition of f-divergence information
132
for multi-variables.
133
Deﬁnition 3.4 (f-divergence information). For disjoint variables X = {X1, X2, . . . , Xn} ⊂V, let
134
PX be the joint probability measure for X. For each i = 1, 2, . . . , n, PXi =
R"
THE VALUES OF THE VARIABLES IN THE PARENTHESES FOR BOTH SYMBOLS CAN BE DROPPED IF NOT NECESSARY IN THE,0.21359223300970873,"XX\Xi dPX is a mea-
135
sure of the marginal distribution of PX for Xi. The f-divergence information for X1, X2, . . . , Xn
136
under PX and a convex function f satisfying f(1) = 0 is deﬁned as the f-divergence between PX
137
and PX1 × PX2 × · · · × PXn:
138"
THE VALUES OF THE VARIABLES IN THE PARENTHESES FOR BOTH SYMBOLS CAN BE DROPPED IF NOT NECESSARY IN THE,0.21844660194174756,"If(X1, X2, . . . , Xn; PX)
=
EPX"
THE VALUES OF THE VARIABLES IN THE PARENTHESES FOR BOTH SYMBOLS CAN BE DROPPED IF NOT NECESSARY IN THE,0.22330097087378642,"
f
dPX1 × dPX2 × · · · × dPXn dPX"
THE VALUES OF THE VARIABLES IN THE PARENTHESES FOR BOTH SYMBOLS CAN BE DROPPED IF NOT NECESSARY IN THE,0.22815533980582525,"
.
(6)"
PROBLEM SET UP,0.23300970873786409,"4
Problem Set Up
139"
PROBLEM SET UP,0.23786407766990292,"Before describing the details of the problem, we provide a notation for the probability distribution,
140
which is the goal of balancing. Hereafter, P denotes the probability distribution of observational
141
data. For the given disjoint sets X1, X2, . . . , Xn, Y, Z ⊂V, let eP be a probability distribution, as
142
follows:
143
eP
=
P(Y|do(X1), do(X2), . . . , do(Xn), Z) × P(Z)
=
P(Y|do(X), Z) × P(X1) × P(X2) × · · · × P(Xn) × P(Z),
(7)"
PROBLEM SET UP,0.24271844660194175,"where X = X1 ∪X2 ∪· · · ∪Xn. eP is the probability distribution of the counterfactual data from
144
simultaneous (multidimensional) interventions in X1, X2, . . . , Xn under the condition Z.
145"
PROBLEM SET UP,0.24757281553398058,"Objective.
The objective of this study is to obtain the balancing weights that transform
146
P(Y, X, Z) into eP(Y, X, Z). More precisely, given the i.i.d. observational data {(xi, zi)|i =
147
1, 2, . . . , N}, we aim to estimate the weights BW (X, Z), such that
148"
PROBLEM SET UP,0.2524271844660194,"E e
P [f(X, Z)] = EP [f(X, Z) · BW (X, Z)]
(8)"
PROBLEM SET UP,0.25728155339805825,"holds for any measurable function f on Rd. If we obtain the weights, we estimate the conditional av-
149
erage causal effect (CACE) for P(Y|do(X1), do(X2), . . . , do(Xn), Z), that is E e
P [Y|X, Z], using
150
state-of-the-art supervised machine learning algorithms, with the weights assigned as the individual
151
weights for each sample.
152"
PROBLEM SET UP,0.2621359223300971,"Assumptions.
We assumed the following to achieve our objective:
153"
PROBLEM SET UP,0.2669902912621359,"• Assumption 1. The causal effect P(Y|do(X)) is identiﬁable, or equivalently, eP from (7)
154
can be identiﬁed. 2 3
155
• Assumption 2. Let P = P(X1, X2, . . . , Xn, Z) and let Q = P(X1) × P(X2) × · · · ×
156
P(Xn) × P(Z). Subsequently, we assume that Q ≪P.
157"
PROBLEM SET UP,0.27184466019417475,"Assumption 2 is the same as the overlap assumption if we consider this a single-dimensional inter-
158
vention. Here, we propose overlapped assumptions for joint and multidimensional interventions.
159"
PROBLEM SET UP,0.2766990291262136,"2The simplest case that satisﬁes Assumption 1 is that no confounding exists among the data ([20], P78,
Theorem 3.2.5).
3If certain unobserved data are assumed to exist, the identiﬁability of the causal effect is determined by the
structure of the causal diagram for P. One criterion for the identiﬁability of a causal effect is expressed by [26].
The discussion of the identiﬁability of the causal effect is beyond the scope of this study."
ESTIMATION OF BALANCING WEIGHTS,0.2815533980582524,"5
Estimation of Balancing Weights
160"
ESTIMATION OF BALANCING WEIGHTS,0.28640776699029125,"In this section, we present the way to effectively estimate the probability density ratios by optimizing
161
f-divergence.
162"
ESTIMATION OF BALANCING WEIGHTS,0.2912621359223301,"Density Ratios as Balancing Weights.
We ﬁrst note that the density ratios, which are referred to
163
as the Radon–Nikodým derivative in this paper, are equal to the balancing weight of the target. For
164
a density ratio of P to eP, that is d e
P
dP , it holds that
165"
ESTIMATION OF BALANCING WEIGHTS,0.2961165048543689,"E e
P [f] =
Z
f · d eP"
ESTIMATION OF BALANCING WEIGHTS,0.30097087378640774,"dP · dP = EP """
ESTIMATION OF BALANCING WEIGHTS,0.3058252427184466,"f · d eP dP # ,
(9)"
ESTIMATION OF BALANCING WEIGHTS,0.3106796116504854,"for any measurable function f in Rd. Then, (8) and (9) are equivalent. As an example of the
166
aforementioned density ratio, let X be a binary variable with XX = {1, 0} and let Z be covariates.
167
Using propensity score e(z) = P(X = 1|Z = z), we observe that d e
P
dP (X = 1, z) = P(X =
168"
ESTIMATION OF BALANCING WEIGHTS,0.3155339805825243,"1)/e(z) and d e
P
dP (X = 0, z) = P(X = 0)/(1−e(z)). That is, d e
P
dP is the stabilized inverse probability
169
of the treatment weighting [23].
170"
OUR APPROACH,0.32038834951456313,"5.1
Our Approach
171"
OUR APPROACH,0.32524271844660196,"Our approach involves obtaining the density ratios as an optimal function for a variational represen-
172
tation of an f-divergence. This approach is based on the fact that the optimal function is connected
173
to density ratios [15].
174"
OUR APPROACH,0.3300970873786408,"Variational representation.
Using the Legendre transform of the convex conjugate of a twice dif-
175
ferentiable convex function f, f ∗(ψ) = supr∈R{ψ·r−f(r)}, we obtain a variational representation
176
of f-divergence:
177
Df(Q||P) = sup
φ≥0
{EQ[f ′(φ)] −EP [f ∗(f ′(φ))]},
(10)"
OUR APPROACH,0.33495145631067963,"where supremum is considered over all measurable functions with EQ[f ′(φ)]
<
∞and
178
EP [f ∗(f ′(φ))] < ∞. The maximum value is achieved at φ = dQ/dP.
179"
OUR APPROACH,0.33980582524271846,"We obtained the optimal function for (10) by replacing φ in the equation with a neural network
180
model φθ and training it through back-propagation with a loss function, such that
181"
OUR APPROACH,0.3446601941747573,"L(θ) = −
n
ˆEQ[f ′(φθ)] −ˆEP [f ∗(f ′(φθ))]
o
.
(11)"
OUR APPROACH,0.34951456310679613,"Selecting α-divergence for Optimization.
We select α-divergence for the following reasons.
182
First, the sample size requirements for α-divergence is independent of its ground truth value: second,
183
it has unbiased mini-batch gradients; third, it can avoid a vanishing gradient problem.
184"
OUR APPROACH,0.35436893203883496,"The variational representation of α-divergence is as follows (Lemma C.1 in Appendix C):
185"
OUR APPROACH,0.3592233009708738,"Dα(Q||P) = sup
φ≥0"
OUR APPROACH,0.3640776699029126,"
1
α(1 −α) −1"
OUR APPROACH,0.36893203883495146,"αEQ

φ−α
−
1
1 −αEP

φ1−α
.
(12)"
OUR APPROACH,0.3737864077669903,"Sample size requirements for α-divergence.
The α-divergence has an estimator with sample
186
complexity O(1) (Corollary 1 in Birrell et al., 2022, P19; Corollary C.10 in Appendix C). Con-
187
versely, the sample complexity of KL-divergence is O(eKL(Q||P )) [14, 28]:
188"
OUR APPROACH,0.3786407766990291,"lim
N→∞"
OUR APPROACH,0.38349514563106796,"N · Var
h
\
KLN(Q||P)
i"
OUR APPROACH,0.3883495145631068,"KL(Q||P)2
≥eKL(Q||P ) −1"
OUR APPROACH,0.3932038834951456,"KL(Q||P)2 ,
(13)"
OUR APPROACH,0.39805825242718446,"where \
KLN(Q||P) is the KL-divergence estimator for sample size N using a variational represen-
189
tation of the divergence, and KL(Q||P) is the ground truth value.
190"
OUR APPROACH,0.4029126213592233,"Unbiasedness for mini-batch gradients.
φ in (12) can be expressed in a Gibbs density form
191
(Proposition C.2 in Appendix C). Then, we observe that
192"
OUR APPROACH,0.4077669902912621,"Dα(Q||P) = sup
T"
OUR APPROACH,0.41262135922330095,"
1
α(1 −α) −1"
OUR APPROACH,0.4174757281553398,"αEQ

eα·T 
−
1
1 −αEP
h
e(α−1)·T i
,
(14)"
OUR APPROACH,0.4223300970873786,"where supremum is considered over all measurable functions T : Rd →R with EP [e(α−1)·T ] < ∞
193
and EQ[eα·T ] < ∞.
194"
OUR APPROACH,0.42718446601941745,"From this equation, we obtain our loss function, which has unbiasedness for mini-batch gradients
195
(Proposition C.8 in Appendix C), as follows :
196"
OUR APPROACH,0.4320388349514563,Lα(θ) = 1
OUR APPROACH,0.4368932038834951,"α
ˆEQ

eα·Tθ
+
1
1 −α
ˆEP
h
e(α−1)·Tθ
i
.
(15)"
OUR APPROACH,0.441747572815534,"Advantage in vanishing gradients problem.
By setting α within (0, 1), we can avoid vanishing
197
gradients of neural networks when they reach the extreme local minima. The vanishing-gradient
198
problem for optimizing divergence is known in GANs [2]. Now, we consider the case where the
199
probability ratio eTθ(x) in (15) is nearly zero or large for some point x, corresponding to cases in
200
which the probabilities for P or Q at some points are much smaller than those for the other.
201"
OUR APPROACH,0.44660194174757284,"To show the relation between eTθ(x) and the learning of the neural networks, we obtain gradient of
202
(15):
203
∇θLα(θ) = ˆEQ
h
∇θTθ · eα·Tθ
i
−ˆEP
h
∇θTθ · e(α−1)·Tθ
i
.
(16)"
OUR APPROACH,0.45145631067961167,"The behavior of ∇θLα(θ) when EQ[eTθ] →0 or EQ[eTθ] →∞, under some regular conditions for
204
Tθ and an assumption that P ≪Q, can be summarized as follows: Let E[ · ] denote EP [EQ[ · ]],
205
then
206"
OUR APPROACH,0.4563106796116505,"α > 1:
E[∇θLα(θ)] →⃗0 (as EQ[eTθ] →0), and E[∇θLα(θ)] →⃗∞−⃗∞(as EQ[eTθ] →∞).
207"
OUR APPROACH,0.46116504854368934,"α < 0:
E[∇θLα(θ)] →⃗0 (as EQ[eTθ] →∞), and E[∇θLα(θ)] →⃗∞−⃗∞(as EQ[eTθ] →0).
208"
OUR APPROACH,0.46601941747572817,"0 < α < 1: E[∇θLα(θ)] →−⃗∞(as EQ[eTθ] →0), and E[∇θLα(θ)] →⃗∞(as EQ[eTθ] →∞).
209"
OUR APPROACH,0.470873786407767,"Notably, EQ[eTθ] →0 ⇔EP [eTθ] →0 EQ[eTθ] →∞⇔EP [eTθ] →∞, because Q ≪P and
210
P ≪Q.
211"
OUR APPROACH,0.47572815533980584,"For α > 1 and α < 0, cases exist where E[∇θLα(θ)] →⃗0. This implies the possibility that the
212
neural networks reach extreme local minima such that their estimations for density ratios are 0 or ∞.
213
However, this problem can be avoided by selecting α from interval (0, 1). We note that the selecting
214
of α does not cause instability in numerical calculations for cases where E[∇θLα(θ)] →⃗∞−⃗∞.
215
In Appendix D.1, we present numerical experimental results for different values of α.
216"
METHOD,0.48058252427184467,"6
Method
217"
METHOD,0.4854368932038835,"In this section, we ﬁrst present the main theorem that summarizes the new balancing weight method
218
proposed herein. Next, we present the balancing weight method.
219"
MAIN THEOREM,0.49029126213592233,"6.1
Main Theorem
220"
MAIN THEOREM,0.49514563106796117,"Here, we present the main theorem that summarizes the new balancing weight method proposed
221
herein.
222
Theorem 6.1. Given disjoint sets of X = {X1, X2, . . . , Xn}, Y, Z ⊂V satisfying
223
X = {X1, X2, . . . , Xn} ⊂An(Y)G
and
Z ∩De(Y)G = φ.
(17)"
MAIN THEOREM,0.5,"Let P = P(X1, X2, . . . , Xn, Z) and Q = P(X1) × P(X2) × · · · × P(Xn) × P(Z), and eP =
224
P(Y|do(X), Z)×P(X1)×P(X2)×· · ·×P(Xn)×P(Z). We assume that P satisﬁes Assumptions 1
225"
MAIN THEOREM,0.5048543689320388,"and 2 in the aforementioned setting, and it holds that EP
h
(dQ/dP)1−αi
< ∞for some 0 < α < 1,
226
then, for the optimal function T ∗, such that
227"
MAIN THEOREM,0.5097087378640777,"T ∗(X1, X2, . . . , Xn, Z) = arg inf
T ∈T α  1"
MAIN THEOREM,0.5145631067961165,"αEQ

eα·T 
+
1
1 −αEP
h
e(α−1)·T i
,
(18)"
MAIN THEOREM,0.5194174757281553,Algorithm 1 Training a Neural Balancing Weight model
MAIN THEOREM,0.5242718446601942,"Input: Train Data (x1, {(xi
1, . . . , xi
n, zi)}N
i=1
Output: A Neural Balancing Weight Model
TθK
σx
1 ←SHUFFLE({1 : N})
...
σx
n ←SHUFFLE({1 : N})
σz ←SHUFFLE({1 : N})"
MAIN THEOREM,0.529126213592233,"for t = 1 to K do
ˆEP ←1"
MAIN THEOREM,0.5339805825242718,"N ΣN
i=1e(α−1)·Tθt(xi
1,...,xi
n,zi)"
MAIN THEOREM,0.5388349514563107,ˆEQ ←1
MAIN THEOREM,0.5436893203883495,"N ΣN
i=1eα·Tθt(x
σx
1 (i)
1
,...,x
σx
n(i)
n
,zσz(i))"
MAIN THEOREM,0.5485436893203883,"Lα(θt) ←ˆEQ/α + ˆEP/(1 −α)
θt+1 ←θt −∇θtLα(θt)
end for"
MAIN THEOREM,0.5533980582524272,"it holds that
228
d eP
dP = e−T ∗(X1,X2,...,Xn,Z).
(19)"
MAIN THEOREM,0.558252427184466,"Here, T α denotes the set of all non-constant functions T(x) : Rd →R with EP[e(α−1)·T (X)] < ∞.
229"
MAIN THEOREM,0.5631067961165048,"Proof. See Appendix C.
230"
MAIN THEOREM,0.5679611650485437,"Here, we mention that the assumption (17) is necessary for the (19) to hold, which is derived from
231
our Theorem C.15 in Appendix C.
232"
BALANCING WEIGHT METHOD,0.5728155339805825,"6.2
Balancing Weight Method
233"
BALANCING WEIGHT METHOD,0.5776699029126213,"We present the implementation of training a neural balancing weights (NBW) model in Algorithm
234
1. It is important to consider the stopping time K for neural network model TθK in Algorithm 1,
235
which is discussed in the next section. To obtain the sample mean under Q, that is, the estimator
236
for EQ

eα·Tθ
in (18), a shufﬂing operation can be used for the samples. Now, we deﬁne neural
237
balancing weights (NBW). 4 5
238"
BALANCING WEIGHT METHOD,0.5825242718446602,"Deﬁnition 6.2 (Neural Balancing Weights). Let TθK be a neural networks obtained from Algorithm
239
1. Then, the NBW of TθK, expressed as BW (X1, X2, . . . , Xn, Z; TθK), are deﬁned as
240"
BALANCING WEIGHT METHOD,0.587378640776699,"BW (X1, X2, . . . , Xn, Z; TθK) = 1"
BALANCING WEIGHT METHOD,0.5922330097087378,"Z e−TθK (X1,X2,...,Xn,Z),
(20)"
BALANCING WEIGHT METHOD,0.5970873786407767,"where Z = ˆEP

e−TθK (X1,X2,...,Xn,Z)
.
241"
BALANCING WEIGHT METHOD,0.6019417475728155,"We estimate E e
P [Y|X, Z], that is the CACE for P(Y|do(X1), do(X2), . . . , do(Xn), Z), using
242
BW (X1, X2, . . . , Xn, Z; TθK) as the sample weights of the supervised algorithm:
243"
BALANCING WEIGHT METHOD,0.6067961165048543,"bE e
P [Y|X, Z] = bEP [Y · BW θK | X, Z] .
(21)"
BALANCING WEIGHT METHOD,0.6116504854368932,"Here, bEP corresponds to the model of a supervised machine learning algorithm. As an example,
244
we demonstrate a back-propagation algorithm using balancing weights for the mean squared error
245
(MSE) loss in Algorithm 3 in Appendix E.
246"
TECHNIQUES FOR NBW,0.616504854368932,"7
Techniques for NBW
247"
TECHNIQUES FOR NBW,0.6213592233009708,"We propose two techniques for estimating balancing weights: (i) improves generalization perfor-
248
mance of the balancing weights. (ii) measures the performance of the balancing weights by estimat-
249
ing the α-divergence information.
250"
TECHNIQUES FOR NBW,0.6262135922330098,"4We distinguish the notation of BW (·) by the expression of the variables in the parentheses. For example,
for disjoint variables X1, X2, X3 ⊂V, let X = {X1, X2}. Then, BW (X, X3; Tθ) is used to indicate the
balancing weights for dP(X1, X2) × dP(X3)/dP(X1, X2, X3). Conversely, BW (X1, X2, X3; Tθ) denotes
the balancing weights for dP(X1) × dP(X2) × dP(X3)/dP(X1, X2, X3).
5However, we drop the variables in the parentheses and write BW (X1, X2, . . . , Xn, Z; Tθ) as BW θ if not
necessary in the context."
IMPROVING THE GENERALIZATION PERFORMANCE OF THE BALANCING WEIGHTS,0.6310679611650486,"7.1
Improving the Generalization Performance of the Balancing Weights
251"
IMPROVING THE GENERALIZATION PERFORMANCE OF THE BALANCING WEIGHTS,0.6359223300970874,"In this section, we ﬁrst present an overﬁtting problem for balancing distributions. We then present
252
two methods for improving the generalization performance of the weights: a validation method using
253
test data and an early stopping method. Herein, let Tθt denote an NBW model at step t in Algorithm
254
1. Let ˆX(N)
Q (t) = e−Tθt · X(N)
P
, that is, the data balanced by the weights of e−Tθt. Subsequently,
255"
IMPROVING THE GENERALIZATION PERFORMANCE OF THE BALANCING WEIGHTS,0.6407766990291263,"let ˆQ(N)
t
and ˆQ(N) denote the probability distributions of ˆX(N)
Q (t) and ˆX(N)
Q , respectively, which
256
correspond to the estimated and true distributions for balancing.
257"
IMPROVING THE GENERALIZATION PERFORMANCE OF THE BALANCING WEIGHTS,0.6456310679611651,"An overﬁtting problem for balancing distributions.
From Corollary C.12 in Appendix C, we
258
observe ˆX(N)
Q (t)
d
−−→X(N)
Q
as t →∞. Then, Theorem 1 in [33] shows that
259"
IMPROVING THE GENERALIZATION PERFORMANCE OF THE BALANCING WEIGHTS,0.6504854368932039,"lim
t→∞W1(Q, ˆQ(N)
t
) = W1(Q, ˆQ(N)) ≳N −1/(d−δ)
( ∀δ > 0 ),
(22)"
IMPROVING THE GENERALIZATION PERFORMANCE OF THE BALANCING WEIGHTS,0.6553398058252428,"where W1 is the Wasserstein distance of order 1 and d is the lower Wasserstein dimension deﬁned
260
in [33]. (22) implies that, for balancing ﬁnite data, the destination of the balanced distribution is
261
an empirical distribution, and the generalization performance of balancing worsens exponentially
262
when the dimension of the data is larger. In view of optimizations of GANs, [34] referred to this
263
phenomenon the“ momorization ”and proposed an early stopping method.
264"
IMPROVING THE GENERALIZATION PERFORMANCE OF THE BALANCING WEIGHTS,0.6601941747572816,"Validation method using test data.
We can use a validation method using test data. Because ˆQ(N)
265
and ˆP (N) are empirical probability distributions, we observe that d ˆQ(N)/d ˆP (N)(x) = dQ/dP(x)
266
if x ∈X(N), otherwise d ˆQ(N)/d ˆP (N)(x) = 0 (Proposition C.17 in Appendix C). Then, the optimal
267
function of (15) for both distributions, that is T (N)
∗
= −log(d ˆQ(N)/d ˆP (N)), is inﬁnite except for
268
the observations, and the loss of the T (N)
∗
is inﬁnite for data independent of the observations. This
269
implies that the loss of T (N)
t
for the test data turns to increase from the middle of the training period,
270
and we can determine the training step at which the generalization performance of the weights begins
271
to worsen. In Section D.2 in Appendix D, we provide numerical experimental results to conﬁrm the
272
relationship between dimensions of data (d) and steps in training (K).
273"
IMPROVING THE GENERALIZATION PERFORMANCE OF THE BALANCING WEIGHTS,0.6650485436893204,"Early stopping method.
In addition, we present an early stopping method for estimating the bal-
274
ancing weights as follows, which is inspired by the method developed in [34] (Corollary C.24 in
275
Appendix C): for some δ > 0, let
276
K0 = C · N 2/(d+δ),
(23)"
IMPROVING THE GENERALIZATION PERFORMANCE OF THE BALANCING WEIGHTS,0.6699029126213593,"where C > 0 is constant. Then, we have W1(Q, ˆQ(N)
K0 ) ≲N −1/(d+δ). Unfortunately, the curse of
277
dimensionality remains in the proposed method. This will be discussed in the next section.
278"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.6747572815533981,"7.2
Measuring the Performance of the Balancing Weights
279"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.6796116504854369,"Let us assume that we obtain an NBW model Tθ0 and let BW θ0 = BW (X1, X2, . . . , Xn, Z; Tθ0)
280
be the balancing weights of Tθ0. If BW θ0 successfully estimates dQ"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.6844660194174758,"dP , then the α-divergence between
281
Q and P0 will be nearly zero. Conversely, if BW θ0 fails to estimate dQ"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.6893203883495146,"dP , the α-divergence between
282
Q and P0 is signiﬁcantly different from zero. This implies that we can measure the performance of
283
the balancing weights using the α-divergence information for P0.
284"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.6941747572815534,"Next, we present the deﬁnition of an α-divergence information estimator using neural networks.
285"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.6990291262135923,"Deﬁnition 7.1 (Neural α-divergence Information Estimator). For disjoint variables X1, X2, . . . ,
286
Xn ⊂V, the neural α-divergence information estimator for P is deﬁned as
287"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.7038834951456311,"bIα(X1, X2, . . . , Xn; Tθ∗) =
1
α(1 −α) −inf
θ∈Θ  1"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.7087378640776699,"α
ˆEQ

eα·Tθ
+
1
1 −α
ˆEP
h
e(α−1)·Tθ
i
.
(24)"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.7135922330097088,"To measure the performance of balancing the weights from the NBW model, we estimate the α-
288
divergence information for balanced distribution from the weights. That is, we use the sample mean
289
under a balanced distribution, despite the sample mean under P for (24). For example, we assume
290"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.7184466019417476,Algorithm 2 Algorithm for checking the balance
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.7233009708737864,"Input: Train Data {(xi
1, . . . , xi
n, zi)}N
i=1, Test
Data {(exi
1, . . . , exi
n,ezi)}N
i=1, A Neural Balanc-
ing Weight Model Tθ
Output: The estimated α-divergence informa-
tion bIα for the balanced distribution with the
balancing weights from Tθ"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.7281553398058253,"σx
1 ←SHUFFLE({1 : N})
...
σx
n ←SHUFFLE({1 : N})
σz ←SHUFFLE({1 : N})"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.7330097087378641,"{bwi}N
i ←
e−Tθ(xi
1,xi
2,...,xi
n,zi)
P{e−Tθ(xi
1,xi
2,...,xin,zi)}
bIα ←{}"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.7378640776699029,"for t = 1 to K do
ˆEP0 ←1"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.7427184466019418,"N ΣN
i=1e(α−1)·Tψ(xi
1,...,xi
n,zi) · bwi"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.7475728155339806,"ˆEQ ←
1
N ΣN
i=1eα·Tψ(x
σx
1 (i)
1
,...,x
σx
n(i)
n
,zσz(i))"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.7524271844660194,"Lα(ψ) ←ˆEQ/α + ˆEP0/(1 −α)
ψ ←ψ −∇ψLα(ψ)
ˆEte
P0 ←1"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.7572815533980582,"N ΣN
i=1e(α−1)·Tψ(exi
1,...,exi
n,ezi) · bwi"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.7621359223300971,"ˆEte
Q ←1"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.7669902912621359,"N ΣN
i=1eα·Tψ(ex
σx
1 (i)
1
,...,ex
σx
n(i)
n
,ezσz(i))"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.7718446601941747,"bIt
α ←1/{α · (1 −α)}
−ˆEte
Q /α −ˆEte
P0/(1 −α)
bIα ←bIα ∪{bIt
α}
end for
bIα ←maxt bIα"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.7766990291262136,"that we have certain weights BW ′ = {bwi : i = 1, 2, ..., N}, where bwi denotes the weight of
291
sample i of N. The balanced distribution from the weights is
292"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.7815533980582524,"dP ′ = BW ′ · dP.
(25)"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.7864077669902912,"The α-divergence information for P ′ is estimated by replacing P with P ′ for (24) in the following
293
manner: despite the sample mean ˆEP [e(α−1)·Tθ] for these equations, we use the weighted sample
294
mean, such that
295
ˆEP ′[e(α−1)·Tθ] = 1"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.7912621359223301,"N ΣN
i=1bwi · e(α−1)·Tθ(xi
1,xi
2,...,xi
n,zi).
(26)"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.7961165048543689,"Details on the implementation for measuring the performance of balancing weights from an NBW
296
model are provided in Algorithm 2, which includes the validation method for the overﬁtting problem
297
in Section 7.1.
298"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.8009708737864077,"8
Limitations: Sample Size Requirements.
299"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.8058252427184466,"In Section 7.1, we noted that our method has a curse of dimensionality. The sample size require-
300
ment of the proposed method is N >
  1"
MEASURING THE PERFORMANCE OF THE BALANCING WEIGHTS,0.8106796116504854,"ε
d+δ for W1(Q, ˆQ(N)
K0 ) < ε (Corollary C.25 in Appendix
301
C). However, the curse of dimensionality is an essential problem when balancing multivariate data
302
owing to the following factors. Because the optimal balancing weights deﬁned as (8) for (ﬁnite)
303
observational data are the density ratios of the empirical distributions, the distribution of the data
304
balanced by them is the empirical distribution. Subsequently, owing to the balancing of the weights,
305
the curse of dimensionality of the empirical distribution occurs, which is the same as that described
306
in Section 7.1. Therefore, to achieve high generalization performance, we need to obtain weights
307
that differ from the ideal density ratio between the source and target of the empirical distribution.
308
Further research is required to address this problem. In Appendix D.3, we present the numerical
309
examination results in which the causal effects of joint and multidimensional interventions were
310
estimated with different sample sizes.
311"
CONCLUSION,0.8155339805825242,"9
Conclusion
312"
CONCLUSION,0.8203883495145631,"We propose generalized balancing weights to estimate the causal effects of an arbitrary mixture of
313
discrete and continuous interventions. Three methods for training the weights were provided: an
314
optimization method to learn the weights, a method to improve the generalization performance of
315
the balancing weights, and a method to measure the performance of the weights. We showed the
316
sample size requirements for the weights and then discussed the curse of dimensionality that occurs
317
as a general problem when balancing multidimensional data. Although the curse of dimensionality
318
remains in our method, we believe that this study provides a basic approach for estimating the
319
balancing weights of multidimensional data using variational f-divergence.
320"
REFERENCES,0.8252427184466019,"References
321"
REFERENCES,0.8300970873786407,"[1] David Acuna, Guojun Zhang, Marc T Law, and Sanja Fidler.
f-domain adversarial learn-
322
ing: Theory and algorithms. In International Conference on Machine Learning, pages 66–75.
323
PMLR, 2021.
324"
REFERENCES,0.8349514563106796,"[2] Martin Arjovsky and Léon Bottou. Towards principled methods for training generative adver-
325
sarial networks. arXiv preprint arXiv:1701.04862, 2017.
326"
REFERENCES,0.8398058252427184,"[3] Mohamed Ishmael Belghazi, Aristide Baratin, Sai Rajeshwar, Sherjil Ozair, Yoshua Bengio,
327
Aaron Courville, and Devon Hjelm. Mutual information neural estimation. In International
328
conference on machine learning, pages 531–540. PMLR, 2018.
329"
REFERENCES,0.8446601941747572,"[4] Marc G Bellemare, Ivo Danihelka, Will Dabney, Shakir Mohamed, Balaji Lakshminarayanan,
330
Stephan Hoyer, and Rémi Munos. The cramer distance as a solution to biased wasserstein
331
gradients. arXiv preprint arXiv:1705.10743, 2017.
332"
REFERENCES,0.8495145631067961,"[5] Jeremiah Birrell, Markos A Katsoulakis, and Yannis Pantazis. Optimizing variational repre-
333
sentations of divergences and accelerating their statistical estimation. IEEE Transactions on
334
Information Theory, 2022.
335"
REFERENCES,0.8543689320388349,"[6] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, François
336
Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural
337
networks. The journal of machine learning research, 17(1):2096–2030, 2016.
338"
REFERENCES,0.8592233009708737,"[7] Gustavo L Gilardoni. On pinsker’s and vajda’s type inequalities for csiszár’s f-divergences.
339
IEEE Transactions on Information Theory, 56(11):5377–5386, 2010.
340"
REFERENCES,0.8640776699029126,"[8] Jens Hainmueller. Entropy balancing for causal effects: A multivariate reweighting method to
341
produce balanced samples in observational studies. Political analysis, 20(1):25–46, 2012.
342"
REFERENCES,0.8689320388349514,"[9] Kosuke Imai and Marc Ratkovic. Covariate balancing propensity score. Journal of the Royal
343
Statistical Society: Series B (Statistical Methodology), 76(1):243–263, 2014.
344"
REFERENCES,0.8737864077669902,"[10] Kosuke Imai and David A Van Dyk. Causal inference with general treatment regimes: General-
345
izing the propensity score. Journal of the American Statistical Association, 99(467):854–866,
346
2004.
347"
REFERENCES,0.8786407766990292,"[11] Masahiro Kato and Takeshi Teshima.
Non-negative bregman divergence minimization for
348
deep direct density ratio estimation. In International Conference on Machine Learning, pages
349
5320–5333. PMLR, 2021.
350"
REFERENCES,0.883495145631068,"[12] Simon Lacoste-Julien, Mark Schmidt, and Francis Bach. A simpler approach to obtaining
351
an o (1/t) convergence rate for the projected stochastic subgradient method. arXiv preprint
352
arXiv:1212.2002, 2012.
353"
REFERENCES,0.8883495145631068,"[13] Fan Li, Kari Lock Morgan, and Alan M Zaslavsky. Balancing covariates via propensity score
354
weighting. Journal of the American Statistical Association, 113(521):390–400, 2018.
355"
REFERENCES,0.8932038834951457,"[14] David McAllester and Karl Stratos. Formal limitations on the measurement of mutual infor-
356
mation. In International Conference on Artiﬁcial Intelligence and Statistics, pages 875–884.
357
PMLR, 2020.
358"
REFERENCES,0.8980582524271845,"[15] XuanLong Nguyen, Martin J Wainwright, and Michael Jordan. Estimating divergence func-
359
tionals and the likelihood ratio by penalized convex risk minimization. Advances in neural
360
information processing systems, 20, 2007.
361"
REFERENCES,0.9029126213592233,"[16] XuanLong Nguyen, Martin J Wainwright, and Michael I Jordan. Estimating divergence func-
362
tionals and the likelihood ratio by convex risk minimization. IEEE Transactions on Information
363
Theory, 56(11):5847–5861, 2010.
364"
REFERENCES,0.9077669902912622,"[17] Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-gan: Training generative neural
365
samplers using variational divergence minimization. Advances in neural information process-
366
ing systems, 29, 2016.
367"
REFERENCES,0.912621359223301,"[18] Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive
368
predictive coding. arXiv preprint arXiv:1807.03748, 2018.
369"
REFERENCES,0.9174757281553398,"[19] Judea Pearl. Causal diagrams for empirical research. Biometrika, 82(4):669–688, 1995.
370"
REFERENCES,0.9223300970873787,"[20] Judea Pearl. Causality: Models, reasoning and inference, 2009.
371"
REFERENCES,0.9271844660194175,"[21] Ben Poole, Sherjil Ozair, Aaron Van Den Oord, Alex Alemi, and George Tucker. On variational
372
bounds of mutual information. In International Conference on Machine Learning, pages 5171–
373
5180. PMLR, 2019.
374"
REFERENCES,0.9320388349514563,"[22] James M Robins, Andrea Rotnitzky, and Lue Ping Zhao. Estimation of regression coefﬁcients
375
when some regressors are not always observed. Journal of the American statistical Association,
376
89(427):846–866, 1994.
377"
REFERENCES,0.9368932038834952,"[23] James M Robins, Miguel Angel Hernan, and Babette Brumback. Marginal structural models
378
and causal inference in epidemiology, 2000.
379"
REFERENCES,0.941747572815534,"[24] Paul R Rosenbaum and Donald B Rubin. Reducing bias in observational studies using sub-
380
classiﬁcation on the propensity score. Journal of the American statistical Association, 79(387):
381
516–524, 1984.
382"
REFERENCES,0.9466019417475728,"[25] Albert Nikolaevich Shiryaev. Probability, 1995.
383"
REFERENCES,0.9514563106796117,"[26] Ilya Shpitser and Judea Pearl. Identiﬁcation of conditional interventional distributions. arXiv
384
preprint arXiv:1206.6876, 2012.
385"
REFERENCES,0.9563106796116505,"[27] Si Si, Dacheng Tao, and Bo Geng.
Bregman divergence-based regularization for transfer
386
subspace learning. IEEE Transactions on Knowledge and Data Engineering, 22(7):929–942,
387
2009.
388"
REFERENCES,0.9611650485436893,"[28] Jiaming Song and Stefano Ermon. Understanding the limitations of variational mutual infor-
389
mation estimators. arXiv preprint arXiv:1910.06222, 2019.
390"
REFERENCES,0.9660194174757282,"[29] Masashi Sugiyama, Taiji Suzuki, and Takafumi Kanamori. Density-ratio matching under the
391
bregman divergence: a uniﬁed framework of density-ratio estimation. Annals of the Institute
392
of Statistical Mathematics, 64(5):1009–1044, 2012.
393"
REFERENCES,0.970873786407767,"[30] Stefan Tübbicke. Entropy balancing for continuous treatments. Journal of Econometric Meth-
394
ods, 11(1):71–89, 2022.
395"
REFERENCES,0.9757281553398058,"[31] Masatoshi Uehara, Issei Sato, Masahiro Suzuki, Kotaro Nakayama, and Yutaka Matsuo.
396
Generative adversarial nets from a density ratio estimation perspective.
arXiv preprint
397
arXiv:1610.02920, 2016.
398"
REFERENCES,0.9805825242718447,"[32] Ananya Uppal, Shashank Singh, and Barnabás Póczos. Nonparametric density estimation &
399
convergence rates for gans under besov ipm losses. Advances in neural information processing
400
systems, 32, 2019.
401"
REFERENCES,0.9854368932038835,"[33] Jonathan Weed and Francis Bach. Sharp asymptotic and ﬁnite-sample rates of convergence of
402
empirical measures in wasserstein distance. 2019.
403"
REFERENCES,0.9902912621359223,"[34] Hongkang Yang and E Weinan. Generalization and memorization: The bias potential model.
404
In Mathematical and Scientiﬁc Machine Learning, pages 1013–1043. PMLR, 2022.
405"
REFERENCES,0.9951456310679612,"[35] Yuchen Zhang, Tianle Liu, Mingsheng Long, and Michael Jordan. Bridging theory and al-
406
gorithm for domain adaptation.
In International Conference on Machine Learning, pages
407
7404–7413. PMLR, 2019.
408"
