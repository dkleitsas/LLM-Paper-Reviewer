Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0004677268475210477,"The J-orthogonal matrix, also referred to as the hyperbolic orthogonal matrix, is
1"
ABSTRACT,0.0009354536950420954,"a class of special orthogonal matrix in hyperbolic space, notable for its advanta-
2"
ABSTRACT,0.001403180542563143,"geous properties. These matrices are integral to optimization under J-orthogonal
3"
ABSTRACT,0.0018709073900841909,"constraints, which have widespread applications in statistical learning and data
4"
ABSTRACT,0.0023386342376052385,"science. However, addressing these problems is generally challenging due to
5"
ABSTRACT,0.002806361085126286,"their non-convex nature and the computational intensity of the constraints. Cur-
6"
ABSTRACT,0.003274087932647334,"rently, algorithms for tackling these challenges are limited. This paper introduces
7"
ABSTRACT,0.0037418147801683817,"JOBCD, a novel Block Coordinate Descent method designed to address opti-
8"
ABSTRACT,0.00420954162768943,"mizations with J-orthogonality constraints. We explore two specific variants of
9"
ABSTRACT,0.004677268475210477,"JOBCD: one based on a Gauss-Seidel strategy (GS-JOBCD), the other on a
10"
ABSTRACT,0.005144995322731525,"variance-reduced and Jacobi strategy (VR-J-JOBCD). Notably, leveraging the
11"
ABSTRACT,0.005612722170252572,"parallel framework of a Jacobi strategy, VR-J-JOBCD integrates variance reduc-
12"
ABSTRACT,0.00608044901777362,"tion techniques to decrease oracle complexity in the minimization of finite-sum
13"
ABSTRACT,0.006548175865294668,"functions. For both GS-JOBCD and VR-J-JOBCD, we establish the oracle com-
14"
ABSTRACT,0.007015902712815715,"plexity under mild conditions and strong limit-point convergence results under the
15"
ABSTRACT,0.007483629560336763,"Kurdyka-Lojasiewicz inequality. To demonstrate the effectiveness of our method,
16"
ABSTRACT,0.007951356407857811,"we conduct experiments on hyperbolic eigenvalue problems, hyperbolic structural
17"
ABSTRACT,0.00841908325537886,"probe problems, and the ultrahyperbolic knowledge graph embedding problem.
18"
ABSTRACT,0.008886810102899906,"Extensive experiments using both real-world and synthetic data demonstrate that
19"
ABSTRACT,0.009354536950420954,"JOBCD consistently outperforms state-of-the-art solutions, by large margins.
20"
INTRODUCTION,0.009822263797942002,"1
Introduction
21"
INTRODUCTION,0.01028999064546305,"A matrix X ∈Rn×n is a J-orthogonal matrix if XTJX = J, where J = [ Ip
0
0 −In−p ], and Ip is a p×p
22"
INTRODUCTION,0.010757717492984098,"identity matrix. Here, J ∈Rn×n is the signature matrix with signature (p, n −p). In this paper, we
23"
INTRODUCTION,0.011225444340505144,"mainly focus on the following optimization problem under J-orthogonality constraints:
24"
INTRODUCTION,0.011693171188026192,minX∈Rn×n f(X) ≜1
INTRODUCTION,0.01216089803554724,"N
PN
i=1 fi(X), s. t. XTJX = J.
(1)"
INTRODUCTION,0.012628624883068288,"Here, f(X) could have a finite-sum structure, each component function fi(X) is assumed to be
25"
INTRODUCTION,0.013096351730589336,"differentiable, and N is the number of data points. For brevity, the J-orthogonality constraint
26"
INTRODUCTION,0.013564078578110383,"XTJX = J in Problem (1) is rewritten as X ∈J .
27"
INTRODUCTION,0.01403180542563143,"We impose the following assumptions on Problem (1) throughout this paper. (A-i) For any matrices
28"
INTRODUCTION,0.014499532273152479,"X and X+, we assume fi : Rn×n 7→R is continuously differentiable for some symmetric positive
29"
INTRODUCTION,0.014967259120673527,"semidefinite matrix H ∈Rnn×nn that:
30"
INTRODUCTION,0.015434985968194575,"fi(X+) ≤fi(X) + ⟨X+ −X, ∇fi(X)⟩+ 1"
INTRODUCTION,0.015902712815715623,"2∥X+ −X∥2
H,
(2)"
INTRODUCTION,0.01637043966323667,"for all i ∈[N], where ∥H∥≤Lf for some constant Lf > 0 and ∥X∥2
H ≜vec(X)⊤H vec(X).
31"
INTRODUCTION,0.01683816651075772,"This further implies that: ∥∇fi(X) −∇fi(X+)∥F ≤Lf∥X −X+∥F for all i ∈[N]. Impor-
32"
INTRODUCTION,0.017305893358278764,"tantly, the function f(X) = 1"
INTRODUCTION,0.01777362020579981,2 tr(X⊤CXD) = 1
INTRODUCTION,0.01824134705332086,"2∥X∥2
H with H = D ⊗C satisfies the equality
33"
INTRODUCTION,0.018709073900841908,"∀X, X+, f(X+) = Q(X+; X) in (2), where C ∈Rn×n and D ∈Rn×n are arbitrary symmetric
34"
INTRODUCTION,0.019176800748362956,"matrices. (A-ii) The function fi(X) is coercive for all i ∈N, that is, lim∥X∥F→∞fi(X) = ∞, ∀i.
35"
INTRODUCTION,0.019644527595884004,"Problem (1) defines an optimization framework that is fundamental to a wide range of models in
36"
INTRODUCTION,0.020112254443405052,"statistical learning and data science, including hyperbolic eigenvalue problem [6, 43, 40], hyperbolic
37"
INTRODUCTION,0.0205799812909261,"structural probe problem [20, 7], and ultrahyperbolic knowledge graph embedding [48]. Additionally,
38"
INTRODUCTION,0.021047708138447148,"it is closely related to machine learning in hyperbolic spaces, including Lorentz model learning
39"
INTRODUCTION,0.021515434985968196,"[35, 50, 8] and ultrahyperbolic neural networks [27, 54, 42]. It also intersects with hyperbolic linear
40"
INTRODUCTION,0.021983161833489244,"algebra [3, 21], addressing problems such as the indefinite least squares problem, hyperbolic QR
41"
INTRODUCTION,0.02245088868101029,"factorization, and indefinite polar decomposition.
42"
RELATED WORK,0.022918615528531337,"1.1
Related Work
43"
RELATED WORK,0.023386342376052385,"▶Block Coordinate Descent Methods. Block Coordinate Descent (BCD) is a well-established
44"
RELATED WORK,0.023854069223573433,"iterative algorithm that sequentially minimizes along block coordinate directions. Its simplicity
45"
RELATED WORK,0.02432179607109448,"and efficiency have led to its widespread adoption in structured convex applications [37]. Recently,
46"
RELATED WORK,0.02478952291861553,"BCD has gained traction in non-convex problems due to its robust optimality guarantees and/or
47"
RELATED WORK,0.025257249766136577,"excellent empirical performance in areas including optimal transport [22], matrix optimization [12],
48"
RELATED WORK,0.025724976613657625,"fractional minimization [52], deep neural networks [5, 53, 32], federated learning[47], black-box
49"
RELATED WORK,0.026192703461178673,"optimization [4], and optimization with orthogonality constraints [51, 14]. To our knowledge, this is
50"
RELATED WORK,0.02666043030869972,"the first application of BCD methods to optimization under J-orthoginality constraints, with a focus
51"
RELATED WORK,0.027128157156220765,"on analyzing their theoretical guarantees and empirical efficacy.
52"
RELATED WORK,0.027595884003741813,"▶Minimizing Smooth Functions under J-Orthogonality Constraints. The J-orthogonal matrix
53"
RELATED WORK,0.02806361085126286,"belongs to a subset of generalized orthogonal matrices [16, 36, 23]. However, projecting onto the
54"
RELATED WORK,0.02853133769878391,"J-orthogonality constraint poses challenges, complicating the extension of conventional optimization
55"
RELATED WORK,0.028999064546304958,"algorithms to address optimization problems under these constraints [1, 16]. This contrasts with
56"
RELATED WORK,0.029466791393826006,"computing orthogonal projections using methods such as polar or SVD decomposition, or approxi-
57"
RELATED WORK,0.029934518241347054,"mating them via QR factorization. Existing methods for addressing Problem (1) can be categorized
58"
RELATED WORK,0.0304022450888681,"into three classes. (i) CS-Decomposition Based Methods. These approaches involve parameterizing
59"
RELATED WORK,0.03086997193638915,"four orthogonal matrices (as described in Proposition 2.2) and subsequently minimizing a smooth
60"
RELATED WORK,0.0313376987839102,"function over these matrices in an alternating fashion. The involvement of 3×3 block matrices makes
61"
RELATED WORK,0.031805425631431246,"the implementation of these methods very challenging. Consequently, the work of [48] focuses on
62"
RELATED WORK,0.032273152478952294,"optimizing a reduced subspace of the CS decomposition parameters, albeit at the expense of losing
63"
RELATED WORK,0.03274087932647334,"some degrees of freedom. (ii) Unconstrained Multiplier Correction Methods [31, 13, 14]. These
64"
RELATED WORK,0.03320860617399439,"methods leverage the symmetry and explicit closed-form expression of the Lagrangian multiplier at
65"
RELATED WORK,0.03367633302151544,"the first-order optimality condition. Consequently, they address an unconstrained problem, resulting
66"
RELATED WORK,0.034144059869036486,"in efficient first-order infeasible approaches. (iii) Alternating Direction Method of Multipliers [19].
67"
RELATED WORK,0.03461178671655753,"This method reformulates the original problem into a bilinear constrained optimization problem by
68"
RELATED WORK,0.035079513564078575,"introducing auxiliary variables. It employs dual variables to handle bilinear constraints, iteratively
69"
RELATED WORK,0.03554724041159962,"optimizing primal variables while keeping other primal and dual variables fixed, and using a gradient
70"
RELATED WORK,0.03601496725912067,"ascent strategy to update the dual variables. This approach has become widely adopted for solving
71"
RELATED WORK,0.03648269410664172,"general nonconvex and nonsmooth composite optimization problems. Notably, all the aforementioned
72"
RELATED WORK,0.03695042095416277,"methods solely identify critical points of Problem (1).
73"
RELATED WORK,0.037418147801683815,"▶Finite-Sum Problems via Stochastic Gradient Descent. The finite-sum structure is prevalent in
74"
RELATED WORK,0.03788587464920486,"machine learning and statistical modeling, facilitating decomposition into smaller, more manageable
75"
RELATED WORK,0.03835360149672591,"components. This property is advantageous for developing efficient algorithms for large-scale prob-
76"
RELATED WORK,0.03882132834424696,"lems, such as Stochastic Gradient Descent (SGD). Reducing variance is crucial in SGD because it can
77"
RELATED WORK,0.03928905519176801,"lead to more stable and faster convergence. Various techniques, such as mini-batch SGD, momentum
78"
RELATED WORK,0.039756782039289056,"methods, and variance reduction methods like SAGA [10], SVRG [25], SARAH [34], SPIDER
79"
RELATED WORK,0.040224508886810104,"[11, 44], SNVRG [55], and PAGE [30], have been developed to address this issue. Additionally, SGD
80"
RELATED WORK,0.04069223573433115,"for minimizing composite functions has also been investigated by the authors [15, 24, 29].
81"
CONTRIBUTIONS,0.0411599625818522,"1.2
Contributions
82"
CONTRIBUTIONS,0.04162768942937325,"This paper makes the following contributions. (i) Algorithmically: We introduce the JOBCD
83"
CONTRIBUTIONS,0.042095416276894296,"algorithm, a novel Block Coordinate Descent method specifically designed to tackle optimizations
84"
CONTRIBUTIONS,0.042563143124415344,"constrained by J-orthogonality. We explore two specific variants of JOBCD, one based on a
85"
CONTRIBUTIONS,0.04303086997193639,"Gauss-Seidel strategy (GS-JOBCD), the other on a variance-reduced and Jacobi strategy (VR-
86"
CONTRIBUTIONS,0.04349859681945744,"J-JOBCD). Notably, VR-J-JOBCD incorporates a variance-reduction technique into a parallel
87"
CONTRIBUTIONS,0.04396632366697849,"framework to reduce oracle complexity in the minimization of finite-sum functions (See Section
88"
CONTRIBUTIONS,0.04443405051449953,"2). (ii) Theoretically: We provide comprehensive optimality and convergence analyses for both
89"
CONTRIBUTIONS,0.04490177736202058,"algorithms (see Sections 3 and 4). (iii) Empirically: Extensive experiments across hyperbolic
90"
CONTRIBUTIONS,0.045369504209541625,"eigenvalue problems, structural probe problems, and ultrahyperbolic knowledge graph embedding,
91"
CONTRIBUTIONS,0.04583723105706267,"using both real-world and synthetic data, consistently show the significant superiority of JOBCD
92"
CONTRIBUTIONS,0.04630495790458372,"over state-of-the-art solutions (see Section 5).
93"
THE PROPOSED JOBCD ALGORITHM,0.04677268475210477,"2
The Proposed JOBCD Algorithm
94"
THE PROPOSED JOBCD ALGORITHM,0.04724041159962582,"This section proposes JOBCD for solving optimization problems under J-orthogonality constraints
95"
THE PROPOSED JOBCD ALGORITHM,0.047708138447146865,"in Problem (1), which is based on randomized block coordinate descent. Two variants of JOBCD are
96"
THE PROPOSED JOBCD ALGORITHM,0.04817586529466791,"explored, one based on a Gauss-Seidel strategy (GS-JOBCD), the other on a variance-reduced and
97"
THE PROPOSED JOBCD ALGORITHM,0.04864359214218896,"Jocobi strategy (VR-J-JOBCD).
98"
THE PROPOSED JOBCD ALGORITHM,0.04911131898971001,"Notations. We define [n] ≜{1, 2, . . . , n}. We denote Ω≜{B1, B2, . . . , BC2n} as all the possible
99"
THE PROPOSED JOBCD ALGORITHM,0.04957904583723106,"combinations of the index vectors choosing 2 items from n without repetition. For any B ∈Ω, we
100"
THE PROPOSED JOBCD ALGORITHM,0.050046772684752105,"define UB ∈Rn×2 as (UB)ji = 1 if Bi = j, else 0 for all j and i, leading to UT
B X = X(B, :) ∈
101"
THE PROPOSED JOBCD ALGORITHM,0.050514499532273154,"R2×n. We denote JB ≜{V | VTJBBV = JBB}, where JBB ∈R2×2 is the sub-matrix of J indexed by
102"
THE PROPOSED JOBCD ALGORITHM,0.0509822263797942,"B. Further notations are provided in Appendix A.1.
103"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.05144995322731525,"2.1
Gauss-Seidel Block Coordinate Descent Algorithm
104"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.0519176800748363,"This subsection describes the proposed GS-JOBCD algorithm. We consider Problem (1) with N = 1
105"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.052385406922357346,"only, without utilizing its finite-sum structure.
106"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.052853133769878394,"GS-JOBCD is an iterative algorithm that, in each iteration t, randomly and uniformly (with replace-
107"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.05332086061739944,"ment) selects a coordinate B from the set Ωand then solves a small-sized subproblem. The row index
108"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.05378858746492049,"[n] of the decision variable X are separated to two sets B and Bc, where B ∈Ωwith |B| = 2 is the work-
109"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.05425631431244153,"ing set and Bc = [n]\B. For simplicity, we use B instead of Bt. Following [51], we consider the follow-
110"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.05472404115996258,"ing block coordinate update rule: [Xt+1(B, :) = VXt(B, :)] ⇔[Xt+1 = Xt + UB(V −I)UT
B Xt],
111"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.05519176800748363,"where V ∈R2×2 is some suitable matrix.
112"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.055659494855004675,"The following lemma illustrates matrix selection for enforcing J-orthogonality constraints via the
113"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.05612722170252572,"update rule X+ ⇐XB(V) ≜X + UB(V −I)UT
B X, and presents associated properties.
114"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.05659494855004677,"Lemma 2.1. (Proof in Section C.1) For any B ∈Ω, we define X+ ≜XB(V) ≜X+UB(V−I)UT
B X.
115"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.05706267539756782,"We have: (a) If V ∈JB and X ∈J , then X+ ∈J . (b) ∥X+ −X∥2
F ≤∥X∥2
F · ∥V −I∥2
F. (c)
116"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.05753040224508887,"∥X+ −X∥2
H ≤∥V −I∥2
Q for all Q ≽Q ≜(Z⊤⊗UB)⊤H(Z⊤⊗UB), Z ≜U⊤
B X ∈Rk×n.
117"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.057998129092609915,"▶The Main Algorithm. Using the above update rule, we consider the following iterative procedure:
118"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.05846585594013096,"Xt+1 ⇐X t
B( ¯Vt), where ¯Vt ∈arg minV f(X t
B(V)). However, the resulting subproblem could be
119"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.05893358278765201,"still difficult to solve. This inspires us to use sequential majorization minimization [38, 33] to address
120"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.05940130963517306,"it. This technique iteratively constructs a surrogate function that upper-bounds the objective function,
121"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.05986903648269411,"allowing for effective optimization and gradual reduction of the objective function. We derive:
122"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.060336763330215155,"f(X t
B(V))
①
≤
f(Xt) + 1"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.0608044901777362,"2∥X t
B(V) −Xt∥2
H + ⟨X t
B(V) −Xt, ∇f(Xt)⟩"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.06127221702525725,"②
≤
f(Xt) + 1"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.0617399438727783,"2∥V −I∥2
Q+θI + ⟨V −I, [∇f(Xt)(Xt)T]BB⟩≜G(V; Xt, Bt), (3)"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.06220767072029935,"where step ①uses Inequality (2); step ②uses Claim (c) of Lemma 2.1, θ ≥0 and the fact that
123"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.0626753975678204,"⟨UB(V −I)UT
B X, ∇f(X)⟩= ⟨V −I, [∇f(X)XT]BB⟩, and the choice of Q ∈R4×4 that:
124"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.06314312441534144,"Q = Q, or Q = ςI2, with ∥Q∥≤ς ≤Lf.
(4)"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.06361085126286249,"Therefore, the function G(V; Xt, Bt) becomes a majorization function of f(X) at Xt ∈J for all Bt ∈
125"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.06407857811038353,"Ω. We can consider the following optimization problem to find V
t: V
t ∈arg minV G(V; Xt, Bt).
126"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.06454630495790459,"We summarize the proposed GS-JOBCD in Algorithm 1.
127"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.06501403180542563,"Although the J-orthogonality constraint typically has a sorted diagonal with diag(J) ∈{−1, +1}n,
128"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.06548175865294668,"GS-JOBCD is also applicable to problems with more general constraints XTJX = J where
129"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.06594948550046772,"diag(J) ∈{±1}n is unsorted.
130"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.06641721234798878,"▶Solving the Small-Sized Subproblem.
We now elaborate on how to find the global op-
131"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.06688493919550982,"timal solution of Problem (6).
We notice that V ∈JB ≜{V | VTJBBV = JBB}, where
132"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.06735266604303088,"JBB ∈{( 1
0
0 −1 ), ( 1 0
0 1 ), ( −1
0
0
−1 )}. We now concentrate on the first case where JBB = ( 1
0
0 −1 ). The
133"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.06782039289055192,"following proposition provides a strategy to decompose any J-orthogonal matrix.
134"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.06828811973807297,"Algorithm 1: GS-JOBCD: Block Coordinate Descent Methods using a Gauss-Seidel Strategy
for Solving Problem (1)"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.06875584658559401,"Init.: Set X0 to satisfy J-orthogonality constraints (e.g., via Hyperbolic CS Decomposition).
for t from 0 to T do"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.06922357343311505,"(S1) Choose a coordinate Bt with |Bt| = 2 from the set Ωrandomly and uniformly (with
replacement) for the t-th iteration. Denote B = Bt.
(S2) Choose a matrix Q ∈R4×4 using Formula (4).
(S3) Solve the following small-size subproblem globally."
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.06969130028063611,"V
t
∈
arg min
V∈JB"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.07015902712815715,"1
2∥V −I∥2
Q+θI + ⟨V −I, [∇f(Xt)(Xt)T]BB⟩+ f(Xt)
(5)"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.0706267539756782,"=
arg
min
V∈JB∈R2×2
1
2∥V∥2
˙Q + ⟨V, P⟩+ c
(6)"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.07109448082319925,"where P ≜[∇f(Xt)(Xt)T]BB −mat( ˙Q vec(I2)), ˙Q = Q + θI and
c ≜f(Xt) −⟨I2, [∇f(Xt)(Xt)T]BB⟩+ 1"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.0715622076707203,"2∥I∥2
˙Q is a constant."
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.07202993451824134,"(S4) Xt+1(B, :) = V
tXt(B, :)
end"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.0724976613657624,"Proposition 2.2. (Hyperbolic CS Decomposition [41]) Let V be J-orthogonal with signature
135"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.07296538821328344,"(p, n −p).
Assume that n −p ≤p.
Then there exist vectors ˙c, ˙s ∈Rn−p with ˙c ⊙˙c −
136"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.0734331150608045,"˙s ⊙˙s = 1, and orthogonal matrices U1, V1 ∈Rp×p and U2, V2 ∈R(n−p)×(n−p) such that:
137"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.07390084190832553,"V = [
U1
0
0
U2 ][
Diag( ˙c)
0
Diag( ˙s)
0
Ip−(n−p)
0
Diag( ˙s)
0
Diag( ˙c) ][
VT
1
0
0
VT
2 ].
138"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.07436856875584659,"Applying Proposition 2.2 with n = 2, p = 1, and U1 = U2 = V1 = V2 = ±1, ˜c2 −˜s2 = 1 with
139"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.07483629560336763,"˜c,˜s ∈R, we parametrize V as: V = ( ±1
0
0
±1 ) · ( ˜c ˜s
˜s ˜c ) · ( ±1
0
0
±1 ), where we denote ˜s as sinh(µ), ˜c as
140"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.07530402245088869,"cosh(µ), and ˜t as tanh(µ)for some µ ∈R, for simplicity of notation. It is not difficult to show that
141"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.07577174929840973,"Problem (6) reduces to the following one-dimensional search problem:
142"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.07623947614593078,"¯µ ∈min
µ
1
2 vec(V)T ˙Q vec(V) + ⟨V, P⟩, s. t. V ∈{( ˜c ˜s
˜s ˜c ), ( ˜c
−˜s
−˜s
˜c ), ( −˜c −˜s
˜s
˜c ), ( ˜c −˜s
˜s −˜c )}.
(7)"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.07670720299345182,"We apply a breakpoint search method to solve Problem (7). For simplicity, we provide an analysis
143"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.07717492984097288,"only for the first case. A detailed discussion of all four cases can be found in Appendix Section B.1.
144"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.07764265668849392,"For the case where V = ( ˜c ˜s
˜s ˜c ), Problem (7) reduces to the following problem:
145"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.07811038353601497,"min
˜c,˜s a˜c +b˜s +c˜c2 +d˜c˜s +e˜s2,
(8)"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.07857811038353602,"where a = P11 + P22, b = P12 + P21, c = 1"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.07904583723105706,"2( ˙Q11 + ˙Q41 + ˙Q14 + ˙Q44), d = 1"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.07951356407857811,"2( ˙Q21 + ˙Q31 +
146"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.07998129092609915,"˙Q12 + ˙Q42 + ˙Q13 + ˙Q43 + ˙Q24 + ˙Q34), and e = 1"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.08044901777362021,"2( ˙Q22 + ˙Q32 + ˙Q23 + ˙Q33). Then we perform
147"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.08091674462114125,"a substitution to convert Problem (8) into an equivalent problem that depends on the trigonometric
148"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.0813844714686623,"functions: (i) ˜c2 =
1
1−˜t2 ; (ii) ˜s2 =
˜t2"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.08185219831618334,1−˜t2 ; (iii) ˜t = ˜s
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.0823199251637044,"˜c. The following lemma provides a characterization
149"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.08278765201122544,"of the global optimal solution for Problem (8).
150"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.0832553788587465,"Lemma 2.3. (Proof in Section C.2) We let ˘F(˜c, ˜s) ≜a˜c + b˜s + c˜c2 + d˜c˜s + e˜s2. The optimal so-
151"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.08372310570626754,"lution ¯µ to Problem (8) can be computed as: [cosh(˜µ), sinh(˜µ)] ∈arg min[c,s] ˘F(c, s), s. t. [c, s] ∈
152"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.08419083255378859,"{[
1
√"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.08465855940130963,"1−(¯t+)2 ,
¯t+
√"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.08512628624883069,"1−(¯t+)2 ], [
−1
√"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.08559401309635173,"1−(¯t−)2 ,
−¯t−
√"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.08606173994387278,"1−(¯t−)2 ]}, where ¯t+ ∈arg mint p(t) ≜
a+bt
√"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.08652946679139382,1−t2 + w+dt
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.08699719363891488,"1−t2 ;
153"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.08746492048643592,"¯t−∈arg mint ˜p(t) ≜−a−bt
√"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.08793264733395698,1−t2 + w+dt
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.08840037418147802,"1−t2 . Here w = c + e.
154"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.08886810102899906,"We now describe how to find the optimal solution ¯t+, where ¯t+ ∈arg mint p(t) ≜
a+bt
√"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.08933582787652011,"1−t2 +
155 w+dt"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.08980355472404115,"1−t2 ; this strategy can naturally be extended to find ¯t−.
Initially, we have the following
156"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.09027128157156221,"first-order optimality conditions for the problem: 0 = ∇p(t) =[b(1 −t2) + (a + bt)t]
√"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.09073900841908325,"1 −t2 +
157"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.0912067352666043,"[d(1 −t2) + (w + dt)(2t)] ⇔dt2 + 2wt + d = −[b + at]
√"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.09167446211412535,"1 −t2. Squaring both sides yields the
158"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.0921421889616464,"following quartic equation: c4t4 + c3t3 + c2t2 + c1t + c0 = 0, where c4 = d2 + a2, c3 = 4wd + 2ab,
159"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.09260991580916744,"c2 = 4w2 + 2d2 −a2 + b2, c1 = 4wd −2ab, c0 = d2 −b2. This equation can be solved analytically
160"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.0930776426566885,"by Lodovico Ferrari’s method [46], resulting in all its real roots {¯t1, ¯t2, . . . , ¯tj} with 1 ≤j ≤4.
161"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.09354536950420954,"For the second and third cases, Problem (6) essentially boils down to optimization under orthogonality
162"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.0940130963517306,"constraints. The work of [51] derives a breakpoint search method for finding the optimal solution for
163"
GAUSS-SEIDEL BLOCK COORDINATE DESCENT ALGORITHM,0.09448082319925163,"Problem (6) with JBB ∈{( 1 0
0 1 ), ( −1
0
0
−1 )} using the Givens rotation and Jacobi reflection matrices.
164"
VARIANCE-REDUCED JACOBI BLOCK COORDINATE DESCENT ALGORITHM,0.09494855004677269,"2.2
Variance-Reduced Jacobi Block Coordinate Descent Algorithm
165"
VARIANCE-REDUCED JACOBI BLOCK COORDINATE DESCENT ALGORITHM,0.09541627689429373,"This subsection proposes the VR-J-JOBCD algorithm, a randomized block coordinate descent
166"
VARIANCE-REDUCED JACOBI BLOCK COORDINATE DESCENT ALGORITHM,0.09588400374181479,"method derived from GS-JOBCD. Importantly, by leveraging the parallel framework of a Jacobi
167"
VARIANCE-REDUCED JACOBI BLOCK COORDINATE DESCENT ALGORITHM,0.09635173058933583,"strategy [17, 9], VR-J-JOBCD integrates variance reduction techniques [39, 30, 18] to decrease
168"
VARIANCE-REDUCED JACOBI BLOCK COORDINATE DESCENT ALGORITHM,0.09681945743685688,"oracle complexity in the minimization of finite-sum functions. This makes the algorithm effective for
169"
VARIANCE-REDUCED JACOBI BLOCK COORDINATE DESCENT ALGORITHM,0.09728718428437792,"minimizing large-scale problems under J-orthogonality constraints.
170"
VARIANCE-REDUCED JACOBI BLOCK COORDINATE DESCENT ALGORITHM,0.09775491113189898,"Notations. We assume n is an even number in this paper. We create (n/2) pairs by non-overlapping
171"
VARIANCE-REDUCED JACOBI BLOCK COORDINATE DESCENT ALGORITHM,0.09822263797942002,"grouping of the numbers in any arbitrary combination, with each pair containing two distinct numbers
172"
VARIANCE-REDUCED JACOBI BLOCK COORDINATE DESCENT ALGORITHM,0.09869036482694106,from the set [n]. It is not hard to verify that such grouping yields CJ = (n!)/(2n/2 n
VARIANCE-REDUCED JACOBI BLOCK COORDINATE DESCENT ALGORITHM,0.09915809167446211,"2 !) possible
173"
VARIANCE-REDUCED JACOBI BLOCK COORDINATE DESCENT ALGORITHM,0.09962581852198316,"combinations. The set of these combinations is denoted as Υ ≜{ ˜Bi}CJ
i=1 ≜{ ˜B1, ˜B2, . . . , ˜BCJ} 1.
174"
VARIANCE-REDUCED JACOBI BLOCK COORDINATE DESCENT ALGORITHM,0.10009354536950421,"▶Variance Reduction Strategy. We incorporate state-of-the-art variance reduction strategies from
175"
VARIANCE-REDUCED JACOBI BLOCK COORDINATE DESCENT ALGORITHM,0.10056127221702525,"the literature [30, 5] into our algorithm to solve Problem (1). These methods iteratively generate a
176"
VARIANCE-REDUCED JACOBI BLOCK COORDINATE DESCENT ALGORITHM,0.10102899906454631,"stochastic gradient estimator as follows:
177 ˜Gt ="
VARIANCE-REDUCED JACOBI BLOCK COORDINATE DESCENT ALGORITHM,0.10149672591206735,"(
1
b
P"
VARIANCE-REDUCED JACOBI BLOCK COORDINATE DESCENT ALGORITHM,0.1019644527595884,"i∈St
+ ∇fi(Xt),
with probability p;
˜Gt−1 + 1 b′
P"
VARIANCE-REDUCED JACOBI BLOCK COORDINATE DESCENT ALGORITHM,0.10243217960710944,"i∈St∗(∇fi(Xt) −∇fi(Xt−1)),
with probability 1 −p.
(9)"
VARIANCE-REDUCED JACOBI BLOCK COORDINATE DESCENT ALGORITHM,0.1028999064546305,"Here, {St
+, St
∗} are uniform random minibatch samples with |St
+| = b, |St
∗| = b′, and ˜G0 =
178"
"B
P",0.10336763330215154,"1
b
P"
"B
P",0.1038353601496726,"i∈S0
+ ∇fi(X0). We drop the superscript t for {St
+, St
∗} as t can be inferred from context. We
179"
"B
P",0.10430308699719364,"only focus on the default setting that [30, 5]: b = N, b′ =
√"
"B
P",0.10477081384471469,"b and p =
b′
b+b′ .
180"
"B
P",0.10523854069223573,"▶Jacobi Block Coordinate Descent Method. The proposed algorithm is built upon the parallel
181"
"B
P",0.10570626753975679,"framework of a Jacobi strategy. In each iteration t, we randomly and uniformly (with replacement)
182"
"B
P",0.10617399438727783,"select a coordinate set Bt ≜{Bt
(1), Bt
(2), · · · , Bt
( n"
"B
P",0.10664172123479888,"2 )} from the set Υ with Bt ∈N
n
2 ×2 and Bt
(i) ∈N2.
183"
"B
P",0.10710944808231992,"For all t, we have: Bt
(i) ∩Bt
(j) = ∅and ∪n/2
i=1(Bt
(i)) = [n]. We drop the superscript t if t can be
184"
"B
P",0.10757717492984098,"inferred from context.
185"
"B
P",0.10804490177736202,"The following lemma shows how to choose a suitable matrix Q so that the Jacobi strategy can be
186"
"B
P",0.10851262862488306,"applied.
187"
"B
P",0.10898035547240412,"Lemma 2.4. (Proof in Section C.3) We let Bt ≜{Bt
(1), Bt
(2), · · · , Bt
( n"
"B
P",0.10944808231992516,"2 )} ∈Υ for all t. We let Q = ςI4,
188"
"B
P",0.10991580916744621,"where ς is some suitable constant with ς ≤Lf. For any Bt
(i) and Bt
(j) with i ̸= j, their corresponding
189"
"B
P",0.11038353601496725,"objective functions as in Equation (3) are independent.
190"
"B
P",0.11085126286248831,"We consider the following block coordinate update rule in VR-J-JOBCD: Xt+1 ⇐˜
X t
B(V:) ≜
191"
"B
P",0.11131898971000935,"Xt + [Pn/2
i=1 UB(i)(Vi −I2)U⊤
B(i)]Xt. The following lemma provides properties of this rule.
192"
"B
P",0.1117867165575304,"Lemma 2.5. (Proof in Section C.4) We let B
∈
Υ, Vi
∈
JB(i), X
∈
J , and i
∈
193 [ n"
"B
P",0.11225444340505145,"2 ].
We define X+
≜
˜
XB(V:)
≜
X + [Pn/2
i=1 UB(i)(Vi −I2)U⊤
B(i)]X.
We have:
(a)
194 P n"
"B
P",0.1127221702525725,"2
i=1 ∥UB(i)(Vi −I2)U⊤
B(i)X∥2
F = ∥P n"
"B
P",0.11318989710009354,"2
i=1 UB(i)(Vi −I2)U⊤
B(i)X∥2
F. (b) ∥X+ −X∥2
F ≤∥X∥2
F ·
195"
"B
P",0.1136576239476146,"Pn/2
i=1 ∥Vi −I2∥2
F. (c) ∥X+ −X∥2
H ≤Pn/2
i=1 ∥Vi −I2∥2
Q with Q = ςI4. (d) For all ˜G ∈Rn×n, it
196"
"B
P",0.11412535079513564,"follows that: 2 Pn/2
i=1⟨Vi −I2, [(∇f(X)−˜G)X⊤]B(i)B(i)⟩≤∥X∥2
F
Pn/2
i=1 ∥Vi −I2∥2
F +∥[∇f(X)−
197"
"B
P",0.1145930776426567,"˜G]∥2
F.
198"
"B
P",0.11506080449017773,"▶The Main Algorithm. Using the update rule above, we consider the following iterative procedure:
199"
"B
P",0.11552853133769879,"Xt+1 ⇐˜
X t
B(V:), where ¯Vt
: ∈arg minV: f( ˜
X t
B(V:)). We establish the majorization function for
200"
"B
P",0.11599625818521983,"1Taking n = 4 for example, we have: Υ = {{(1, 2), (3, 4)}, {(1, 3), (2, 4)}, {(1, 4), (2, 3)}}."
"B
P",0.11646398503274089,"f( ˜
X t
B(V:)), as follows:
201"
"B
P",0.11693171188026193,"f( ˜
X t
B(V:))
①
≤
f(Xt) + ⟨˜
X t
B(V:) −Xt, ∇f(Xt)⟩+ 1"
"B
P",0.11739943872778298,"2∥˜
X t
B(V:) −Xt∥2
H"
"B
P",0.11786716557530402,"②
≤
f(Xt) + Pn/2
i=1{⟨Vi −I2, [∇f(X)(X)⊤]B(i)B(i)⟩+ 1"
"B
P",0.11833489242282506,"2∥Vi −I2∥2
(θ+ς)I} (10)"
"B
P",0.11880261927034612,"where step ①uses the results of telescoping Inequality (2) over i from 1 to N; step ②uses Xt+1 −
202"
"B
P",0.11927034611786716,"Xt = [Pn/2
i=1 UB(i)(Vi −I2)U⊤
B(i)]Xt, Claim (c) of Lemma 2.5, θ ≥0, and Q = ςI.
203"
"B
P",0.11973807296538821,"Instead of computing the exact Euclidean gradient ∇f(Xt) as GS-JOBCD, VR-J-JOBCD maintains
204"
"B
P",0.12020579981290926,"and updates a recursive gradient estimator ˜Gt using a variance-reduced strategy as in Formula (9).
205"
"B
P",0.12067352666043031,"We consider minimizing the following function instead of the one on the right-hand side of Inequality
206"
"B
P",0.12114125350795135,"(10):
207"
"B
P",0.1216089803554724,"T (V:; Xt, Bt) ≜f(Xt) + Pn/2
i=1⟨Vi −I2, [ ˜Gt(Xt)⊤]B(i)B(i)⟩+ 1"
"B
P",0.12207670720299345,"2∥Vi −I2∥2
¨Q.
(11)"
"B
P",0.1225444340505145,"Here, T (V:; Xt, Bt) can be termed as a stochastic majorization function of f( ˜
X t
B(V:)) at the current
208"
"B
P",0.12301216089803554,"solution Xt. Therefore, we can consider the following optimization problem to find {V:} using:
209"
"B
P",0.1234798877455566,"¯Vt
: ∈arg minV: T (V:; Xt, Bt), which can be decomposed into (n/2) independent subproblems and
210"
"B
P",0.12394761459307764,"solved in parallel. It is important to note that each Vi in Problem (12) is identical to Problem (6),
211"
"B
P",0.1244153414405987,"which can be efficiently solved in O(1) using the breakpoint search method, as in GS-JOBCD.
212"
"B
P",0.12488306828811974,"We summarize the proposed VR-J-JOBCD in Algorithm 2. Notably, when N = 1, VR-J-JOBCD
213"
"B
P",0.1253507951356408,"simplifies to a direct Jacobi strategy for solving Problem (1), which we refer to as J-JOBCD.
214"
"B
P",0.12581852198316185,"Algorithm 2: VR-J-JOBCD: Block Coordinate Descent Methods using a variance-reduced and
Jacobi strategy for Solving Problem 1"
"B
P",0.12628624883068287,"Init.: Set X0 to satisfy J-orthogonality constraints (e.g., via Hyperbolic CS Decomposition).
for t from 0 to T do"
"B
P",0.12675397567820393,"(S1) Choose a coordinate Bt from the set Υ randomly and uniformly (with replacement) for
the t-th iteration. Denote B = Bt. In our implementation, we simply randomly permute the
set {1, 2, ..., n} and then output the grouping {[1, 2], [3, 4], [5, 6], · · · , , [n −1, n]}.
(S2) Use a variance-reduced strategy (9) to obtain ˜Gt.
(S3) Solve small-sized subproblems in parallel with Q = ςI ∈R4×4.
for i = 1 to n/2 in parallel do"
"B
P",0.12722170252572498,"V
t
i ∈arg
min
Vi∈JB(i)"
"B
P",0.127689429373246,"1
2∥Vi −I∥2
¨Q + ⟨Vi −I, [∇f(Xt)(Xt)T]B(i)B(i)⟩+ f(Xt)"
"B
P",0.12815715622076707,"= arg
min
Vi∈JB(i)"
"B
P",0.12862488306828812,"1
2∥Vi∥2
¨Q + ⟨Vi, Pi⟩
(12)"
"B
P",0.12909260991580918,"where Pi ≜[∇f(Xt)(Xt)T]B(i)B(i) −mat( ¨Q vec(I2)) −θI2, ¨Q = (ζ + θ)I.
(S4) Update the solution Xt+1 in parallel as follows:
for i = 1 to n/2 in parallel do"
"B
P",0.1295603367633302,"Xt+1(B(i), :) = ¯Vt
iXt(B(i), :)
end"
OPTIMALITY ANALYSIS,0.13002806361085126,"3
Optimality Analysis
215"
OPTIMALITY ANALYSIS,0.1304957904583723,"This section provides an optimality analysis for the proposed algorithms.
216"
OPTIMALITY ANALYSIS,0.13096351730589337,"Initially, we define the first-order optimality condition for Problem (1). Since the matrix XTJX
217"
OPTIMALITY ANALYSIS,0.1314312441534144,"is symmetric, the Lagrangian multiplier Λ corresponding to the constraints XTJX = J is also a
218"
OPTIMALITY ANALYSIS,0.13189897100093545,"symmetric matrix. The Lagrangian function of problem (1) is L(X, Λ) = f(X) −1"
OPTIMALITY ANALYSIS,0.1323666978484565,"2⟨Λ, XTJX −J⟩.
219"
OPTIMALITY ANALYSIS,0.13283442469597756,"We obtain the following lemma for the first-order optimality condition for Problem (1).
220"
OPTIMALITY ANALYSIS,0.1333021515434986,"Lemma 3.1. (Proof in Section D.1, First-Order Optimality Condition) We let J ≜{X | XTJX =
221"
OPTIMALITY ANALYSIS,0.13376987839101964,"J}.
We have (a) A solution ˇX ∈J is a critical point of problem (1) if and only if: 0 =
222"
OPTIMALITY ANALYSIS,0.1342376052385407,"∇J f( ˇX) ≜∇f( ˇX) −J ˇX[∇f( ˇX)]⊤ˇXJ. The associated Lagrangian multiplier can be computed as
223"
OPTIMALITY ANALYSIS,0.13470533208606175,"Λ = J ˇXT∇f( ˇX). (b) The critical point condition is equivalent to the requirement that the matrix
224"
OPTIMALITY ANALYSIS,0.13517305893358278,"X∇f( ˇX)TJ is symmetric, which is expressed as XGTJ = [XGTJ]T.
225"
OPTIMALITY ANALYSIS,0.13564078578110383,"Remarks. While our results in Lemma 3.1 show similarities to existing works focusing on problems
226"
OPTIMALITY ANALYSIS,0.1361085126286249,"under orthogonality constraints [45], this study marks the first investigation into the first-order
227"
OPTIMALITY ANALYSIS,0.13657623947614594,"optimality condition for optimization problems under J-orthogonality constraints.
228"
OPTIMALITY ANALYSIS,0.13704396632366697,"The following definition is useful in our subsequent analysis of the proposed algorithms.
229"
OPTIMALITY ANALYSIS,0.13751169317118803,"Definition 3.2. (Block Stationary Point, abbreviated as BS-point) Let θ > 0. A solution ¨X ∈J is
230"
OPTIMALITY ANALYSIS,0.13797942001870908,"termed as a block stationary point if, for all B ∈Ω≜{B1, B2, . . . , BC2n}, the following condition is
231"
OPTIMALITY ANALYSIS,0.1384471468662301,"satisfied: I2 ∈arg minV∈JB G(V; ¨X, B).
232"
OPTIMALITY ANALYSIS,0.13891487371375116,"The following theorem shows the relation between critical points and BS-points.
233"
OPTIMALITY ANALYSIS,0.13938260056127222,"Theorem 3.3. (Proof in Section D.2) Any BS-point is a critical point, while the reverse is not
234"
OPTIMALITY ANALYSIS,0.13985032740879327,"necessarily true.
235"
CONVERGENCE ANALYSIS,0.1403180542563143,"4
Convergence Analysis
236"
CONVERGENCE ANALYSIS,0.14078578110383536,"This section provides a convergence analysis for GS-JOBCD and VR-J-JOBCD.
237"
CONVERGENCE ANALYSIS,0.1412535079513564,"For GS-JOBCD, the randomness of output (V
t, Xt+1) for all t are influenced by the random variable
238"
CONVERGENCE ANALYSIS,0.14172123479887747,"ξt ≜(B1; B2; · · · ; Bt). For VR-J-JOBCD, the randomness of output ( ¯Vt
:, Xt+1) are influenced by
239"
CONVERGENCE ANALYSIS,0.1421889616463985,"the random variables ιt ≜(B1, S1
+, S1
∗; B2, S2
+, S2
∗; · · · ; Bt, St
+, St
∗).
240"
CONVERGENCE ANALYSIS,0.14265668849391955,"We denote ¯X as the global optimal solution of Problem (1). To simplify notations, we define:
241"
CONVERGENCE ANALYSIS,0.1431244153414406,"ut = ∥˜Gt −∇f(Xt)∥2
F, and ∆i = f(Xi) −f( ¯X).
242"
CONVERGENCE ANALYSIS,0.14359214218896166,"We impose the following additional assumptions on the proposed algorithms.
243"
CONVERGENCE ANALYSIS,0.14405986903648269,"Assumption 4.1. There exists constants {X, V} that: ∥Xt∥F ≤X, and ∥Vt∥F ≤V for all t.
244"
CONVERGENCE ANALYSIS,0.14452759588400374,"Assumption 4.2. There exists a constant G that: ∥∇f(Xt)∥F ≤G, and ∥˜Gt∥F ≤G for all t.
245"
CONVERGENCE ANALYSIS,0.1449953227315248,"Assumption 4.3. For any X ∈Rn×n, Ei[∥∇fi(Xt) −∇f(Xt)∥2
F] ≤σ2, where i is drawn uniformly
246"
CONVERGENCE ANALYSIS,0.14546304957904585,"at random from [N].
247"
CONVERGENCE ANALYSIS,0.14593077642656688,"Remarks. (i) Assumption 4.1 is satisfied as the function fi(X) is coercive for all i. (ii) Assumption
248"
CONVERGENCE ANALYSIS,0.14639850327408793,"4.2 imposes a bound on the (stochastic) gradient, a fairly moderate condition frequently employed in
249"
CONVERGENCE ANALYSIS,0.146866230121609,"nonconvex optimization [26]. (iii) Assumption 4.3 ensures that the variance of the stochastic gradient
250"
CONVERGENCE ANALYSIS,0.14733395696913001,"is bounded, which is a common requirement in stochastic optimization [30, 5].
251"
GLOBAL CONVERGENCE,0.14780168381665107,"4.1
Global Convergence
252"
GLOBAL CONVERGENCE,0.14826941066417212,"We define the ϵ-BS-point as follows.
253"
GLOBAL CONVERGENCE,0.14873713751169318,"Definition 4.4. (ϵ-BS-point) Given any constant ϵ > 0, a point ¨X is called an ϵ-BS-point if: E( ¨X) ≤ϵ.
254"
GLOBAL CONVERGENCE,0.1492048643592142,"Here, E(X) is defined as E(X) ≜
1
C2n
PC2
n
i=1 dist(I2, arg minV G(V; X, Bi))2 for For GS-JOBCD,
255"
GLOBAL CONVERGENCE,0.14967259120673526,"while it is defined as E(X) ≜
1
CJ
PCJ
i=1 Eιt[dist(I2, arg minV: T (V:; X, ˜Bi))2] for VR-J-JOBCD,
256"
GLOBAL CONVERGENCE,0.15014031805425632,"where the expectation is with respect to the randomness inherent in the algorithm [30].
257"
GLOBAL CONVERGENCE,0.15060804490177737,"We have the following useful lemma for VR-J-JOBCD.
258"
GLOBAL CONVERGENCE,0.1510757717492984,"Lemma 4.5. (Proof in Section E.1) Suppose Assumption 4.3 holds, then the variance Eιt[uk] of the
259"
GLOBAL CONVERGENCE,0.15154349859681945,gradient estimators { ˜Gt} of Algorithm 2 is bounded by: Eιt[ut] ≤p(N−b)
GLOBAL CONVERGENCE,0.1520112254443405,"b(N−1)σ2 + (1 −p)Eιt−1[ut−1]+
260"
GLOBAL CONVERGENCE,0.15247895229186156,"L2
f X2(1−p)"
GLOBAL CONVERGENCE,0.1529466791393826,"b′
Eιt−1[Pn/2
i=1 ∥Vt−1
i
−I2∥2
F]
261"
GLOBAL CONVERGENCE,0.15341440598690365,"The following two theorems establish the iteration complexity (or oracle complexity) for GS-JOBCD
262"
GLOBAL CONVERGENCE,0.1538821328344247,"and VR-J-JOBCD.
263"
GLOBAL CONVERGENCE,0.15434985968194576,Theorem 4.6. (Proof in Section E.2) GS-JOBCD finds an ϵ-BS-point of Problem (1) within O( ∆0N
GLOBAL CONVERGENCE,0.15481758652946678,"ϵ
)
264"
GLOBAL CONVERGENCE,0.15528531337698784,"arithmetic operations.
265"
GLOBAL CONVERGENCE,0.1557530402245089,"Theorem 4.7. (Proof in Section E.3) Let b = N, b′ =
√"
GLOBAL CONVERGENCE,0.15622076707202995,"N, and p =
b′
b+b′ . VR-J-JOBCD finds an
266"
GLOBAL CONVERGENCE,0.15668849391955098,"ϵ-BS-point of Problem (1) within O(nN + ∆0
√"
GLOBAL CONVERGENCE,0.15715622076707203,"N
ϵ
) arithmetic operations.
267"
GLOBAL CONVERGENCE,0.15762394761459309,"Remark. Theorems 4.6 and 4.7 demonstrate that the arithmetic operation complexity of GS-JOBCD
268"
GLOBAL CONVERGENCE,0.1580916744621141,"is linearly dependent on N, while VR-J-JOBCD is linearly dependent on
√"
GLOBAL CONVERGENCE,0.15855940130963517,"N. Therefore, VR-J-
269"
GLOBAL CONVERGENCE,0.15902712815715622,"JOBCD reduces the iteration complexity significantly.
270"
STRONG CONVERGENCE UNDER KL ASSUMPTION,0.15949485500467728,"4.2
Strong Convergence under KL Assumption
271"
STRONG CONVERGENCE UNDER KL ASSUMPTION,0.1599625818521983,"We prove algorithms achieve strong convergence based on a non-convex analysis tool called Kurdyka-
272"
STRONG CONVERGENCE UNDER KL ASSUMPTION,0.16043030869971936,"Łojasiewicz inequality[2].
273"
STRONG CONVERGENCE UNDER KL ASSUMPTION,0.16089803554724041,"We impose the following assumption on Problem (1).
274"
STRONG CONVERGENCE UNDER KL ASSUMPTION,0.16136576239476147,"Assumption 4.8. (Kurdyka-Łojasiewicz Property). Assume that f ◦(X) = f(X) + IJ (X) is a KL
275"
STRONG CONVERGENCE UNDER KL ASSUMPTION,0.1618334892422825,"function. For all X ∈dom f ◦, there exists σ ∈[0, 1), η ∈(0, +∞] a neighborhood Υ of X and a
276"
STRONG CONVERGENCE UNDER KL ASSUMPTION,0.16230121608980355,"concave and continuous function φ(t) = ct1−σ, c > 0, t ∈[0, η) such that for all X′ ∈Υ and satisfies
277"
STRONG CONVERGENCE UNDER KL ASSUMPTION,0.1627689429373246,"f ◦(X′) ∈(f ◦(X), f ◦(X) + η), the following holds: dist(0, ∇f ◦(X′))φ′(f ◦(X′) −f ◦(X)) ≥1.
278"
STRONG CONVERGENCE UNDER KL ASSUMPTION,0.16323666978484566,"We establish strong limit-point convergence for VR-J-JOBCD and GS-JOBCD.
279"
STRONG CONVERGENCE UNDER KL ASSUMPTION,0.1637043966323667,"Theorem 4.9. (Proof in Section E.5, a Finite Length Property). The sequence {Xt}∞
t=0 of GS-
280"
STRONG CONVERGENCE UNDER KL ASSUMPTION,0.16417212347988774,"JOBCD has finite length property that: ∀t, Pt
i=1 Eξt[∥Xt+1 −Xt∥F] ≤O(φ(∆1)) < +∞, where
281"
STRONG CONVERGENCE UNDER KL ASSUMPTION,0.1646398503274088,"φ(·) is the desingularization function defined in Proposition 4.8.
282"
STRONG CONVERGENCE UNDER KL ASSUMPTION,0.16510757717492985,"Theorem 4.10. (Proof in Section E.4, a Finite Length Property). Choosing b = N, b′ =
√ N
283"
STRONG CONVERGENCE UNDER KL ASSUMPTION,0.16557530402245088,"and p =
b′
b+b′ , then the sequence {Xt}∞
t=0 of VR-J-JOBCD has finite length property that:
284"
STRONG CONVERGENCE UNDER KL ASSUMPTION,0.16604303086997194,"∀t, Pt
i=1 Eιt[∥Xt+1 −Xt∥F] ≤O( φ(∆1)"
STRONG CONVERGENCE UNDER KL ASSUMPTION,0.166510757717493,"N 1/4 ) < +∞, where φ(·) is the desingularization function
285"
STRONG CONVERGENCE UNDER KL ASSUMPTION,0.16697848456501402,"defined in Assumption 4.8.
286"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.16744621141253507,"5
Applications and Numerical Experiments
287"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.16791393826005613,"This section demonstrates the effectiveness and efficiency of JOBCD on three optimization tasks:
288"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.16838166510757718,"(i) the hyperbolic eigenvalue problem, (ii) structural probe problem, and (iii) Ultra-hyperbolic
289"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.1688493919550982,"Knowledge Graph Embedding problem. We provide experiments for the last problem in Section F.2.
290"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.16931711880261927,"▶Application to the Hyperbolic Eigenvalue Problem (HEVP). The hyperbolic eigenvalue problem
291"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.16978484565014032,"refers to the generalized eigenvalue problem in hyperbolic spaces [40]. This problem is a fundamental
292"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.17025257249766138,"component in machine learning models, such as Hyperbolic PCA [43, 6]. Given a data matrix
293"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.1707202993451824,"D ∈Rm×n and a signature matrix J with signature (p, n −p), HEVP can be formulated as the
294"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.17118802619270346,"following optimization problem: minX −tr(XTDTDX), s. t. XTJX = J.
295"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.1716557530402245,"▶Application to the Hyperbolic Structural Probe Problem (HSPP). The Structure Probe (SP) is
296"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.17212347988774557,"a metric learning model aimed at understanding the intrinsic semantic information of large language
297"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.1725912067352666,"models [20] [7]. Given a data matrix D ∈Rm×n and its associated Euclidean distance metric
298"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.17305893358278765,"matrix T ∈Rm×m, HSPP employs a smooth homeomorphic mapping function φ(·) to project
299"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.1735266604303087,"the data D into ultra-hyperbolic space. Subsequently, it seeks an appropriate linear transformation
300"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.17399438727782976,"X ∈Rn×n constrained within a specific structure X ∈J , such that the resulting transformed
301"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.1744621141253508,"data Q ≜φ(D)X ∈Rm×n exhibits similarity to the original distance metric matrix T under the
302"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.17492984097287184,"ultra-hyperbolic geodesic distance dα(Qi:, Qj:), expressed as Ti,j ≈dα(Qi:, Qj:) for all i, j ∈[m],
303"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.1753975678203929,"where Qi: is i-th row of the matrix Q ∈Rm×n. This can be formulated as the following optimization
304"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.17586529466791395,"problem: minX
1
m2
P"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.17633302151543498,"i,j∈m(Ti,j −dα(Qi:, Qj:))2, s. t. Q ≜φ(D)X, X ∈J . For more details
305"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.17680074836295603,"on the functions φ(·) and dα(·, ·), please refer to Appendix Section F.1.
306"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.1772684752104771,"▶Datasets. To generate the matrix D ∈Rm×n, we use 8 real-world or synthetic data sets for both
307"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.17773620205799812,"HEVP and HSPP tasks: ‘Cifar’, ‘CnnCaltech’, ‘Gisette’, ‘Mnist’, ‘randn’, ‘Sector’, ‘TDT2’, ‘w1a’.
308"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.17820392890551917,"We randomly extract a subset from the original data sets for the experiments.
309"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.17867165575304023,"▶Compared Methods. We compare GS-JOBCD and VR-J-JOBCD with 3 state-of-the-art
310"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.17913938260056128,"optimization algorithms under J-orthogonality constraints. (i) The CS Decomposition Method
311"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.1796071094480823,"(CSDM) [48]. (ii) Stardard ADMM (ADMM) [19]. UMCM: Unconstrained Multiplier Correction
312"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.18007483629560336,"Method [31, 13].
313"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.18054256314312442,"Table 1: Comparisons of the objectives for HEVP across all the compared methods. The time limit
is set to 90s. The notation ‘(+)’ indicates that GS-JOBCD significantly improves upon the initial
solution provided by CSDM. The 1st, 2nd , and 3rd best results are colored with red, green and blue,
respectively. The value in (·) stands for Pn
ij |X⊤JX −J|ij."
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.18101028999064547,"dataname(m-n-p)
UMCM
ADMM
CSDM
GS-JOBCD
J-JOBCD
CSDM+GS-JOBCD
cifar(1000-100-50)
-1.05e+04(3.0e-09)
-1.05e+04(3.0e-09)
-5.28e+04(5.4e-09)
-1.03e+05(2.6e-08)
-1.11e+05(1.4e-07)
-1.24e+05(2.6e-08)(+)
CnnCal(2000-1000-500)
-5.89e+02(2.9e-08)
-5.89e+02(3.1e-10)
-1.11e+03(5.2e-10)
-1.07e+03(1.3e-09)
-9.16e+03(6.9e-08)
-1.15e+03(6.9e-10)(+)
gisette(3000-1000-500)
-3.22e+06(3.1e-10)
-3.22e+06(3.1e-10)
-8.53e+06(4.9e-10)
-9.49e+06(1.2e-09)
-1.36e+07(2.6e-08)
-9.65e+06(7.9e-10)(+)
mnist(1000-780-390)
-8.65e+04(4.1e-10)
-8.65e+04(4.1e-10)
-2.56e+05(5.6e-10)
-3.14e+05(1.2e-09)
-1.20e+06(4.1e-08)
-3.06e+05(7.6e-10)(+)
randn(10-10-5)
1.29e+02(9.7e-02)
1.29e+02(9.7e-02)
2.45e+02(2.3e-01)
-3.96e+01(9.7e-02)
-3.97e+02(9.7e-02)
1.55e+01(2.3e-01)(+)
randn(100-100-50)
-1.03e+04(3.0e-09)
-1.03e+04(2.5e-07)
-1.98e+04(4.4e-09)
-2.28e+04(5.6e-08)
-4.37e+04(2.6e-07)
-2.41e+04(4.2e-08)(+)
randn(1000-1000-500)
-1.16e+06(3.1e-10)
-1.16e+06(3.1e-10)
-1.93e+06(5.0e-10)
-1.22e+06(6.9e-10)
-1.04e+07(2.3e-07)
-1.95e+06(6.7e-10)(+)
sector(500-1000-500)
-3.61e+03(3.1e-10)
-3.61e+03(3.1e-10)
-7.90e+03(4.9e-10)
-9.24e+03(1.3e-09)
-1.06e+04(2.0e-08)
-8.51e+03(6.4e-10)(+)
TDT2(1000-1000-500)
-4.25e+06(3.1e-10)
-4.25e+06(3.1e-10)
-9.39e+06(4.8e-10)
-1.05e+07(1.1e-09)
-1.42e+07(2.1e-08)
-1.04e+07(6.5e-10)(+)
w1a(2470-290-145)
-3.02e+04(1.1e-04)
-3.02e+04(1.1e-04)
-5.72e+04(2.7e-05)
-9.21e+04(1.1e-04)
-9.32e+06(1.1e-04)
-7.94e+04(2.7e-05)(+)"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.1814780168381665,"(a) Gisette (3000-100-50)
(b) Sector (500-1000-500)
(c) wla (2470-290-145)"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.18194574368568756,"Figure 1: The convergence curve for the HEVP across various datasets with different parameters
(m, n, p)."
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.1824134705332086,"(a) Cifar (10000-50-45)
(b) Gisette (6000-50-45)
(c) News20 (7967-50-45)"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.18288119738072967,"Figure 2: The convergence curve for HEVP across various datasets with different parameters
(m, n, p)."
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.1833489242282507,"▶Experiment Settings. All methods are implemented using Pytorch on an Intel 2.6 GHz processor
314"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.18381665107577175,"with an A40 (48GB). For HSPP, we fix α to 1. Each method employs the same random J-orthogonal
315"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.1842843779232928,"matrix. The built-in solver Admm is used to solve the unconstrained minimization problem in CSDM.
316"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.18475210477081386,"We provide our code in the supplemental material.
317"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.18521983161833488,"▶Experiment Results. Table 1 and Figure 1 display the accuracy and computational efficiency
318"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.18568755846585594,"for HEVP, while Figure 2 presents the results for HSPP, leading to the following observations: (i)
319"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.186155285313377,"GS-JOBCD and JJOBCD consistently deliver better performance than the other methods. (ii) Other
320"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.18662301216089802,"methods frequently encounter poor local minima, whereas GS-JOBCD effectively escapes these
321"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.18709073900841908,"minima and typically achieves lower objective values, aligning with our theory that our methods
322"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.18755846585594013,"locate stronger stationary points. (iii) VR-J-JOBCD outperforms both J-JOBCD and CSDM when
323"
APPLICATIONS AND NUMERICAL EXPERIMENTS,0.1880261927034612,"dealing with a large dataset characterized by an infinite-sum structure.
324"
CONCLUSIONS,0.18849391955098221,"6
Conclusions
325"
CONCLUSIONS,0.18896164639850327,"In this paper, we propose a new approach JOBCD, which is based on block coordinate descent, for
326"
CONCLUSIONS,0.18942937324602432,"solving the optimization problem under J-orthogonality constraints. We discuss two specific variants
327"
CONCLUSIONS,0.18989710009354538,"of JOBCD: one based on a Gauss-Seidel strategy (GS-JOBCD), the other on a variance-reduced
328"
CONCLUSIONS,0.1903648269410664,"Jacobi strategy. Both algorithms capitalize on specific structural characteristics of the constraints to
329"
CONCLUSIONS,0.19083255378858746,"converge to more favorable stationary solutions. Notably, VR-J-JOBCD incorporates a variance-
330"
CONCLUSIONS,0.19130028063610852,"reduction technique into a parallel framework to reduce oracle complexity in the minimization of
331"
CONCLUSIONS,0.19176800748362957,"finite-sum functions. For both GS-JOBCD and VR-J-JOBCD, we establish the oracle complexity
332"
CONCLUSIONS,0.1922357343311506,"under mild conditions and strong limit-point convergence results under the Kurdyka-Lojasiewicz
333"
CONCLUSIONS,0.19270346117867165,"inequality. Some experiments on the hyperbolic eigenvalue problem and structural probe problem
334"
CONCLUSIONS,0.1931711880261927,"show the efficiency and efficacy of the proposed methods.
335"
REFERENCES,0.19363891487371376,"References
336"
REFERENCES,0.1941066417212348,"[1] P-A Absil, Robert Mahony, and Rodolphe Sepulchre. Optimization algorithms on matrix
337"
REFERENCES,0.19457436856875585,"manifolds. Princeton University Press, 2008.
338"
REFERENCES,0.1950420954162769,"[2] Hédy Attouch, Jérôme Bolte, Patrick Redont, and Antoine Soubeyran. Proximal alternating
339"
REFERENCES,0.19550982226379796,"minimization and projection methods for nonconvex problems: An approach based on the
340"
REFERENCES,0.19597754911131898,"kurdyka-łojasiewicz inequality. Mathematics of operations research, 35(2):438–457, 2010.
341"
REFERENCES,0.19644527595884004,"[3] Adam Bojanczyk, Nicholas J Higham, and Harikrishna Patel. Solving the indefinite least squares
342"
REFERENCES,0.1969130028063611,"problem by hyperbolic qr factorization. SIAM Journal on Matrix Analysis and Applications,
343"
REFERENCES,0.19738072965388212,"24(4):914–931, 2003.
344"
REFERENCES,0.19784845650140317,"[4] HanQin Cai, Yuchen Lou, Daniel McKenzie, and Wotao Yin. A zeroth-order block coordinate
345"
REFERENCES,0.19831618334892423,"descent algorithm for huge-scale black-box optimization. In International Conference on
346"
REFERENCES,0.19878391019644528,"Machine Learning, pages 1193–1203. PMLR, 2021.
347"
REFERENCES,0.1992516370439663,"[5] Xufeng Cai, Chaobing Song, Stephen Wright, and Jelena Diakonikolas. Cyclic block coordinate
348"
REFERENCES,0.19971936389148737,"descent with variance reduction for composite nonconvex optimization.
In International
349"
REFERENCES,0.20018709073900842,"Conference on Machine Learning, pages 3469–3494. PMLR, 2023.
350"
REFERENCES,0.20065481758652948,"[6] Ines Chami, Albert Gu, Dat P Nguyen, and Christopher Re. Horopca: Hyperbolic dimensionality
351"
REFERENCES,0.2011225444340505,"reduction via horospherical projections. In International Conference on Machine Learning
352"
REFERENCES,0.20159027128157156,"(ICML), volume 139, pages 1419–1429, 2021.
353"
REFERENCES,0.20205799812909261,"[7] Boli Chen, Yao Fu, Guangwei Xu, Pengjun Xie, Chuanqi Tan, Mosha Chen, and Liping Jing.
354"
REFERENCES,0.20252572497661367,"Probing bert in hyperbolic spaces. ICLR, 2021.
355"
REFERENCES,0.2029934518241347,"[8] Weize Chen, Xu Han, Yankai Lin, Hexu Zhao, Zhiyuan Liu, Peng Li, Maosong Sun, and Jie
356"
REFERENCES,0.20346117867165575,"Zhou. Fully hyperbolic neural networks. arXiv preprint arXiv:2105.14686, 2021.
357"
REFERENCES,0.2039289055191768,"[9] Ashok Cutkosky and Francesco Orabona. Momentum-based variance reduction in non-convex
358"
REFERENCES,0.20439663236669786,"sgd. Advances in neural information processing systems, 32, 2019.
359"
REFERENCES,0.2048643592142189,"[10] Aaron Defazio, Francis Bach, and Simon Lacoste-Julien. Saga: A fast incremental gradi-
360"
REFERENCES,0.20533208606173994,"ent method with support for non-strongly convex composite objectives. Advances in neural
361"
REFERENCES,0.205799812909261,"information processing systems, 27, 2014.
362"
REFERENCES,0.20626753975678203,"[11] Cong Fang, Chris Junchi Li, Zhouchen Lin, and Tong Zhang. Spider: Near-optimal non-
363"
REFERENCES,0.20673526660430308,"convex optimization via stochastic path-integrated differential estimator. Advances in neural
364"
REFERENCES,0.20720299345182414,"information processing systems, 31, 2018.
365"
REFERENCES,0.2076707202993452,"[12] Hamza Fawzi and Harry Goulbourne. Faster proximal algorithms for matrix optimization
366"
REFERENCES,0.20813844714686622,"using jacobi-based eigenvalue methods. Advances in Neural Information Processing Systems,
367"
REFERENCES,0.20860617399438727,"34:11397–11408, 2021.
368"
REFERENCES,0.20907390084190833,"[13] Bin Gao, Xin Liu, Xiaojun Chen, and Ya-xiang Yuan. A new first-order algorithmic framework
369"
REFERENCES,0.20954162768942938,"for optimization problems with orthogonality constraints. SIAM Journal on Optimization,
370"
REFERENCES,0.2100093545369504,"28(1):302–332, 2018.
371"
REFERENCES,0.21047708138447146,"[14] Bin Gao, Xin Liu, and Ya-xiang Yuan. Parallelizable algorithms for optimization problems with
372"
REFERENCES,0.21094480823199252,"orthogonality constraints. SIAM Journal on Scientific Computing, 41(3):A1949–A1983, 2019.
373"
REFERENCES,0.21141253507951357,"[15] Saeed Ghadimi, Guanghui Lan, and Hongchao Zhang. Mini-batch stochastic approximation
374"
REFERENCES,0.2118802619270346,"methods for nonconvex stochastic composite optimization. Mathematical Programming, 155(1-
375"
REFERENCES,0.21234798877455566,"2):267–305, 2016.
376"
REFERENCES,0.2128157156220767,"[16] Gene H Golub and Charles F Van Loan. Matrix computations. JHU press, 2013.
377"
REFERENCES,0.21328344246959777,"[17] Eldon R Hansen. On cyclic jacobi methods. Journal of the Society for Industrial and Applied
378"
REFERENCES,0.2137511693171188,"Mathematics, 11(2):448–459, 1963.
379"
REFERENCES,0.21421889616463985,"[18] Vjeran Hari and Erna Begovi´c Kovaˇc. On the convergence of complex jacobi methods. Linear
380"
REFERENCES,0.2146866230121609,"and multilinear algebra, 69(3):489–514, 2021.
381"
REFERENCES,0.21515434985968196,"[19] Bingsheng He and Xiaoming Yuan. On the O(1/n) convergence rate of the douglas-rachford
382"
REFERENCES,0.215622076707203,"alternating direction method. SIAM Journal on Numerical Analysis, 50(2):700–709, 2012.
383"
REFERENCES,0.21608980355472404,"[20] John Hewitt and Christopher D. Manning. A structural probe for finding syntax in word
384"
REFERENCES,0.2165575304022451,"representations. In Jill Burstein, Christy Doran, and Thamar Solorio, editors, Proceedings of
385"
REFERENCES,0.21702525724976612,"the 2019 Conference of the North American Chapter of the Association for Computational
386"
REFERENCES,0.21749298409728718,"Linguistics: Human Language Technologies (NAACL-HLT), pages 4129–4138, 2019.
387"
REFERENCES,0.21796071094480823,"[21] Nicholas J Higham. J-orthogonal matrices: Properties and generation. SIAM review, 45(3):504–
388"
REFERENCES,0.2184284377923293,"519, 2003.
389"
REFERENCES,0.21889616463985032,"[22] Minhui Huang, Shiqian Ma, and Lifeng Lai. A riemannian block coordinate descent method for
390"
REFERENCES,0.21936389148737137,"computing the projection robust wasserstein distance. In International Conference on Machine
391"
REFERENCES,0.21983161833489243,"Learning, pages 4446–4455. PMLR, 2021.
392"
REFERENCES,0.22029934518241348,"[23] Bo Hui and Wei-Shinn Ku. Low-rank nonnegative tensor decomposition in hyperbolic space. In
393"
REFERENCES,0.2207670720299345,"Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,
394"
REFERENCES,0.22123479887745556,"pages 646–654, 2022.
395"
REFERENCES,0.22170252572497662,"[24] Sashank J Reddi, Suvrit Sra, Barnabas Poczos, and Alexander J Smola. Proximal stochastic
396"
REFERENCES,0.22217025257249767,"methods for nonsmooth nonconvex finite-sum optimization. Advances in neural information
397"
REFERENCES,0.2226379794200187,"processing systems, 29, 2016.
398"
REFERENCES,0.22310570626753976,"[25] Rie Johnson and Tong Zhang. Accelerating stochastic gradient descent using predictive variance
399"
REFERENCES,0.2235734331150608,"reduction. In C.J. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K.Q. Weinberger, editors,
400"
REFERENCES,0.22404115996258187,"Advances in Neural Information Processing Systems, volume 26. Curran Associates, Inc., 2013.
401"
REFERENCES,0.2245088868101029,"[26] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Yoshua
402"
REFERENCES,0.22497661365762395,"Bengio and Yann LeCun, editors, International Conference on Learning Representations (ICLR),
403"
REFERENCES,0.225444340505145,"2015.
404"
REFERENCES,0.22591206735266603,"[27] Marc Law. Ultrahyperbolic neural networks. Advances in Neural Information Processing
405"
REFERENCES,0.22637979420018708,"Systems, 34:22058–22069, 2021.
406"
REFERENCES,0.22684752104770814,"[28] Marc Law and Jos Stam. Ultrahyperbolic representation learning. Advances in neural informa-
407"
REFERENCES,0.2273152478952292,"tion processing systems, 33:1668–1678, 2020.
408"
REFERENCES,0.22778297474275022,"[29] Qunwei Li, Yi Zhou, Yingbin Liang, and Pramod K Varshney. Convergence analysis of proximal
409"
REFERENCES,0.22825070159027128,"gradient with momentum for nonconvex optimization. In International Conference on Machine
410"
REFERENCES,0.22871842843779233,"Learning, pages 2111–2119. PMLR, 2017.
411"
REFERENCES,0.2291861552853134,"[30] Zhize Li, Hongyan Bao, Xiangliang Zhang, and Peter Richtárik. Page: A simple and optimal
412"
REFERENCES,0.2296538821328344,"probabilistic gradient estimator for nonconvex optimization. In International conference on
413"
REFERENCES,0.23012160898035547,"machine learning, pages 6286–6295. PMLR, 2021.
414"
REFERENCES,0.23058933582787652,"[31] Wei Liu, Yinyu Zhang, Hongqiao Yang, and Shuzhong Zhang. A class of smooth exact penalty
415"
REFERENCES,0.23105706267539758,"function methods for optimization problems with orthogonality constraints. Optimization,
416"
REFERENCES,0.2315247895229186,"69(3):399–426, 2020.
417"
REFERENCES,0.23199251637043966,"[32] Wan-Duo Kurt Ma, JP Lewis, and W Bastiaan Kleijn. The hsic bottleneck: Deep learning
418"
REFERENCES,0.23246024321796072,"without back-propagation. In Proceedings of the AAAI conference on artificial intelligence,
419"
REFERENCES,0.23292797006548177,"volume 34, pages 5085–5092, 2020.
420"
REFERENCES,0.2333956969130028,"[33] Julien Mairal. Optimization with first-order surrogate functions. In International Conference
421"
REFERENCES,0.23386342376052385,"on Machine Learning (ICML), volume 28, pages 783–791, 2013.
422"
REFERENCES,0.2343311506080449,"[34] Lam M Nguyen, Jie Liu, Katya Scheinberg, and Martin Takáˇc. Sarah: A novel method for
423"
REFERENCES,0.23479887745556596,"machine learning problems using stochastic recursive gradient. In International conference on
424"
REFERENCES,0.235266604303087,"machine learning, pages 2613–2621. PMLR, 2017.
425"
REFERENCES,0.23573433115060805,"[35] Maximillian Nickel and Douwe Kiela. Learning continuous hierarchies in the lorentz model
426"
REFERENCES,0.2362020579981291,"of hyperbolic geometry. In International Conference on Machine Learning, pages 3779–3788.
427"
REFERENCES,0.23666978484565013,"PMLR, 2018.
428"
REFERENCES,0.23713751169317118,"[36] Vedran Novakovi´c and Sanja Singer. A kogbetliantz-type algorithm for the hyperbolic svd.
429"
REFERENCES,0.23760523854069224,"Numerical algorithms, 90(2):523–561, 2022.
430"
REFERENCES,0.2380729653882133,"[37] Julie Nutini, Issam Laradji, and Mark Schmidt. Let’s make block coordinate descent converge
431"
REFERENCES,0.23854069223573432,"faster: faster greedy rules, message-passing, active-set complexity, and superlinear convergence.
432"
REFERENCES,0.23900841908325537,"Journal of Machine Learning Research, 23(131):1–74, 2022.
433"
REFERENCES,0.23947614593077643,"[38] Meisam Razaviyayn, Mingyi Hong, and Zhi-Quan Luo. A unified convergence analysis of block
434"
REFERENCES,0.23994387277829748,"successive minimization methods for nonsmooth optimization. SIAM Journal on Optimization,
435"
REFERENCES,0.2404115996258185,"23(2):1126–1153, 2013.
436"
REFERENCES,0.24087932647333957,"[39] Mark Schmidt, Nicolas Le Roux, and Francis Bach. Minimizing finite sums with the stochastic
437"
REFERENCES,0.24134705332086062,"average gradient. Mathematical Programming, 162:83–112, 2017.
438"
REFERENCES,0.24181478016838168,"[40] Ivan Slapnicar and Ninoslav Truhar. Relative perturbation theory for hyperbolic eigenvalue
439"
REFERENCES,0.2422825070159027,"problem. Linear Algebra and its Applications, 309(1):57–72, 2000.
440"
REFERENCES,0.24275023386342376,"[41] Michael Stewart and Paul Van Dooren. On the factorization of hyperbolic and unitary trans-
441"
REFERENCES,0.2432179607109448,"formations into rotations. SIAM Journal on Matrix Analysis and Applications, 27(3):876–890,
442"
REFERENCES,0.24368568755846587,"2005.
443"
REFERENCES,0.2441534144059869,"[42] Puoya Tabaghi and Ivan Dokmani´c. Hyperbolic distance matrices. In Proceedings of the
444"
REFERENCES,0.24462114125350795,"26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages
445"
REFERENCES,0.245088868101029,"1728–1738, 2020.
446"
REFERENCES,0.24555659494855003,"[43] Puoya Tabaghi, Michael Khanzadeh, Yusu Wang, and Sivash Mirarab. Principal component
447"
REFERENCES,0.2460243217960711,"analysis in space forms. ArXiv, abs/2301.02750, 2023.
448"
REFERENCES,0.24649204864359214,"[44] Zhe Wang, Kaiyi Ji, Yi Zhou, Yingbin Liang, and Vahid Tarokh. Spiderboost and momentum:
449"
REFERENCES,0.2469597754911132,"Faster variance reduction algorithms. Advances in Neural Information Processing Systems, 32,
450"
REFERENCES,0.24742750233863423,"2019.
451"
REFERENCES,0.24789522918615528,"[45] Zaiwen Wen and Wotao Yin. A feasible method for optimization with orthogonality constraints.
452"
REFERENCES,0.24836295603367634,"Mathematical Programming, 142:397 – 434, 2012.
453"
REFERENCES,0.2488306828811974,"[46] WikiContributors.
Quartic equation.
https: // en. wikipedia. org/ wiki/ Quartic_
454"
REFERENCES,0.24929840972871842,"equation .
455"
REFERENCES,0.24976613657623947,"[47] Ruiyuan Wu, Anna Scaglione, Hoi-To Wai, Nurullah Karakoc, Kari Hreinsson, and Wing-Kin
456"
REFERENCES,0.2502338634237605,"Ma. Federated block coordinate descent scheme for learning global and personalized models. In
457"
REFERENCES,0.2507015902712816,"Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 10355–10362,
458"
REFERENCES,0.25116931711880264,"2021.
459"
REFERENCES,0.2516370439663237,"[48] Bo Xiong, Shichao Zhu, Mojtaba Nayyeri, Chengjin Xu, Shirui Pan, Chuan Zhou, and Steffen
460"
REFERENCES,0.2521047708138447,"Staab. Ultrahyperbolic knowledge graph embeddings. In Proceedings of the 28th ACM SIGKDD
461"
REFERENCES,0.25257249766136575,"Conference on Knowledge Discovery and Data Mining, pages 2130–2139, 2022.
462"
REFERENCES,0.2530402245088868,"[49] Bo Xiong, Shichao Zhu, Nico Potyka, Shirui Pan, Chuan Zhou, and Steffen Staab. Semi-
463"
REFERENCES,0.25350795135640786,"riemannian graph convolutional networks. ArXiv, abs/2106.03134, 2021.
464"
REFERENCES,0.2539756782039289,"[50] Tao Yu and Christopher M De Sa. Numerically accurate hyperbolic embeddings using tiling-
465"
REFERENCES,0.25444340505144997,"based models. Advances in Neural Information Processing Systems, 32, 2019.
466"
REFERENCES,0.254911131898971,"[51] Ganzhao Yuan. A block coordinate descent method for nonsmooth composite optimization
467"
REFERENCES,0.255378858746492,"under orthogonality constraints. ArXiv, abs/2304.03641, 2023.
468"
REFERENCES,0.2558465855940131,"[52] Ganzhao Yuan. Coordinate descent methods for fractional minimization. In International
469"
REFERENCES,0.25631431244153413,"Conference on Machine Learning, pages 40488–40518, 2023.
470"
REFERENCES,0.2567820392890552,"[53] Jinshan Zeng, Tim Tsz-Kit Lau, Shaobo Lin, and Yuan Yao. Global convergence of block
471"
REFERENCES,0.25724976613657624,"coordinate descent in deep learning. In International conference on machine learning, pages
472"
REFERENCES,0.2577174929840973,"7313–7323. PMLR, 2019.
473"
REFERENCES,0.25818521983161835,"[54] Yiding Zhang, Xiao Wang, Chuan Shi, Nian Liu, and Guojie Song. Lorentzian graph convolu-
474"
REFERENCES,0.2586529466791394,"tional networks. In Proceedings of the Web Conference 2021, pages 1249–1261, 2021.
475"
REFERENCES,0.2591206735266604,"[55] Dongruo Zhou, Pan Xu, and Quanquan Gu. Stochastic nested variance reduction for nonconvex
476"
REFERENCES,0.25958840037418146,"optimization. The Journal of Machine Learning Research, 21(1):4130–4192, 2020.
477"
REFERENCES,0.2600561272217025,"Appendix
478"
REFERENCES,0.26052385406922357,"The appendix is organized as follows.
479"
REFERENCES,0.2609915809167446,"Appendix A introduces some notations, technical preliminaries, and relevant lemmas.
480"
REFERENCES,0.2614593077642657,"Appendix B concludes some additional discussions.
481"
REFERENCES,0.26192703461178674,"Appendix C presents the proofs for Section 2.
482"
REFERENCES,0.2623947614593078,"Appendix D offers the proofs for Section 3.
483"
REFERENCES,0.2628624883068288,"Appendix E contains the proofs for Section 4.
484"
REFERENCES,0.26333021515434984,"Appendix F contains several extra experiments, extensions and discussions of the proposed methods.
485"
REFERENCES,0.2637979420018709,"A
Notations, Technical Preliminaries, and Relevant Lemmas
486"
REFERENCES,0.26426566884939195,"A.1
Notations
487"
REFERENCES,0.264733395696913,"In this paper, we denote the Lowercase boldface letters represent vectors, while uppercase letters
488"
REFERENCES,0.26520112254443406,"represent real-valued matrices. We use the Matlab colon notation to denote indices that describe
489"
REFERENCES,0.2656688493919551,"submatrices. The following notations are used throughout this paper.
490"
REFERENCES,0.2661365762394761,"• N : Set of natural numbers
491"
REFERENCES,0.2666043030869972,"• R : Set of real numbers
492"
REFERENCES,0.26707202993451823,"• [n]: {1, 2, ..., n}
493"
REFERENCES,0.2675397567820393,"• ∥x∥: Euclidean norm: ∥x∥= ∥x∥2 =
p"
REFERENCES,0.26800748362956034,"⟨x, x⟩
494"
REFERENCES,0.2684752104770814,"• xi: the i-th element of vector x
495"
REFERENCES,0.26894293732460245,"• Xi,j or Xij : the (ith, jth) element of matrix X
496"
REFERENCES,0.2694106641721235,"• vec(X) : vec(X) ∈Rnn×1, the vector formed by stacking the column vectors of X
497"
REFERENCES,0.2698783910196445,"• mat(x) ∈Rn×n, Convert x ∈Rnn×1 into a matrix with mat(vec(X)) = X
498"
REFERENCES,0.27034611786716556,"• XT : the transpose of the matrix X
499"
REFERENCES,0.2708138447146866,"• sign(t) : the signum function, sign(t) = 1 if t ≥0 and sign(t) = −1 otherwise
500"
REFERENCES,0.27128157156220767,"• X ⊗Y : Kronecker product of X and Y
501"
REFERENCES,0.2717492984097287,"• det(D) : Determinant of a square matrix D ∈Rn×nD ∈Rn×n
502"
REFERENCES,0.2722170252572498,"• C2
n : the number of possible combinations choosing k items from n without repetition.
503"
REFERENCES,0.27268475210477083,"• 0n,r : A zero matrix of size n × r; the subscript is omitted sometimes
504"
REFERENCES,0.2731524789522919,"• Ir : Ir ∈Rr×r, Identity matrix
505"
REFERENCES,0.2736202057998129,"• X ⪰0(or ≻0) : the Matrix X is symmetric positive semidefinite (or definite)
506"
REFERENCES,0.27408793264733394,"• Diag(x): Diagonal matrix with x as the main diagonal entries.
507"
REFERENCES,0.274555659494855,• tr(A) : Sum of the elements on the main diagonal A: tr(A) = P
REFERENCES,0.27502338634237605,"i Ai,i
508"
REFERENCES,0.2754911131898971,"• ∥X∥∗: Nuclear norm: sum of the singular values of matrix X
509"
REFERENCES,0.27595884003741816,"• ∥X∥: Operator/Spectral norm: the largest singular value of X
510"
REFERENCES,0.2764265668849392,• ∥X∥F : Frobenius norm: (P
REFERENCES,0.2768942937324602,"ij X2
ij)1/2
511"
REFERENCES,0.27736202057998127,"• ∇f(X) : classical (limiting) Euclidean gradient of f(X) at X
512"
REFERENCES,0.2778297474275023,"• ∇J f(X) : Riemannian gradient of f(X) at X
513"
REFERENCES,0.2782974742750234,"• Iξ(X) : the indicator function of a set ξ with Iξ(X) = 0 if X ∈ξ and otherwise +∞
514"
REFERENCES,0.27876520112254444,"• dist(ξ, ξ′) : the distance between two sets with dist(ξ, ξ′) ≜infX∈ξ,X′∈ξ′ ∥X −X′∥F
515"
REFERENCES,0.2792329279700655,"• Iξ(x) : the indicator function of a set ξ with Iξ(x) = 0 if x ∈ξ and otherwise +∞.
516"
REFERENCES,0.27970065481758655,"A.2
Relevant Lemmas
517"
REFERENCES,0.2801683816651076,"Lemma A.1. (Lemma 6.6 of [51]) For any W ∈Rn×n, we have: PCk
n
i=1 ∥W(Bi, Bi)∥2
F =
518"
REFERENCES,0.2806361085126286,"k
nCk
n
P"
REFERENCES,0.28110383536014966,"i W2
ii + Ck−2
n−2
P i
P"
REFERENCES,0.2815715622076707,"j,j̸=i W2
ij. Here, the set {B1, B2, · · · , BCk
n} represents all possible
519"
REFERENCES,0.28203928905519177,"combinations of the index vectors choosing k items from n without repetition.
520"
REFERENCES,0.2825070159027128,"Lemma A.2. We have S+ be the set of |S+| = b samples from [N], drawn with replacement and
uniformly at random. Then, ∀t, Xt ∈Rn×n, we have:"
REFERENCES,0.2829747427502339,"Eιt[∥1 b
P"
REFERENCES,0.28344246959775493,"i∈S+ ∇fi(Xt) −∇f(Xt)∥2
F] =
N−b
b(N−1)Eιt[∥∇fi(Xt) −∇f(Xt)∥2
F]."
REFERENCES,0.283910196445276,"Proof. The proof is exactly the same as in Lemma 2.8 of [5].
521"
REFERENCES,0.284377923292797,"Lemma A.3. The tangent space TXJ of manifold constructed by X⊤JX = J, with X ∈Rn×n, is :
522"
REFERENCES,0.28484565014031804,"TXJ ≜{Y ∈Rn×n | X⊤JY + Y⊤JX = 0},
(13)"
REFERENCES,0.2853133769878391,"where Y = t ˜Y with t is a positive scalar approaching 0.
523"
REFERENCES,0.28578110383536015,"Proof. Assuming point X ∈Rn×n lies on manifold J , we have: h(X) = X⊤JX −J. Moving
524"
REFERENCES,0.2862488306828812,"along Y ∈Rn×n in the tangent space of X, we obtain:
525"
REFERENCES,0.28671655753040226,h(X + Y) =(X + Y)⊤J(X + Y) −J
REFERENCES,0.2871842843779233,=X⊤JX + X⊤JY + Y⊤JX + Y⊤JY −J
REFERENCES,0.2876520112254443,①=X⊤JY + Y⊤JX + Y⊤JY
REFERENCES,0.28811973807296537,②=tX⊤J ˜Y + t ˜Y⊤JX + t2 ˜Y⊤J ˜Y
REFERENCES,0.2885874649204864,"where step ①uses X⊤JX = J; step ②uses Y = t ˜Y.
526"
REFERENCES,0.2890551917680075,"Since t is a positive scalar approaching 0, we can ignore the higher-order term: t2 ˜Y⊤J ˜Y. Ac-
527"
REFERENCES,0.28952291861552854,"cording to the properties of the tangent space of any manifold, we have: h(X + Y) = 0, In
528"
REFERENCES,0.2899906454630496,"other words, X⊤JY + Y⊤JX = 0, i.e. we obtain the defining equation for the tangent space:
529"
REFERENCES,0.29045837231057064,"TXJ ≜{Y ∈Rn×n | X⊤JY + Y⊤JX = 0}.
530"
REFERENCES,0.2909260991580917,"B
Additional Discussions
531"
REFERENCES,0.2913938260056127,"B.1
On the Global Optimal Solution for Problem (7)
532"
REFERENCES,0.29186155285313375,"In Section 2.1, we have demonstrated how to use the breakpoint search method to obtain an optimal
533"
REFERENCES,0.2923292797006548,"solution for the case of V = ( ˜c ˜s
˜s ˜c ) of Problem (7). Since the structure of the other three cases
534"
REFERENCES,0.29279700654817586,"V ∈{( ˜c
−˜s
−˜s
˜c ), ( −˜c −˜s
˜s
˜c ), ( ˜c −˜s
˜s −˜c )} is exactly the same except for the coefficients of Problem (8), we
535"
REFERENCES,0.2932647333956969,"will provide the corresponding coefficients in Problem (8): min˜c,˜s a˜c +b˜s +c˜c2 +d˜c˜s +e˜s2, and
536"
REFERENCES,0.293732460243218,"omit the specific analysis process.
537"
REFERENCES,0.29420018709073903,"Case (a). V = ( ˜c
−˜s
−˜s
˜c ): a = P11 + P22, b = −P12 −P21, c = 1"
REFERENCES,0.29466791393826003,"2( ˙Q11 + ˙Q41 + ˙Q14 + ˙Q44),
538"
REFERENCES,0.2951356407857811,d = −1
REFERENCES,0.29560336763330214,"2( ˙Q21+ ˙Q31+ ˙Q12+ ˙Q42+ ˙Q13+ ˙Q43+ ˙Q24+ ˙Q34), and e = 1"
REFERENCES,0.2960710944808232,"2( ˙Q22+ ˙Q32+ ˙Q23+ ˙Q33).
539"
REFERENCES,0.29653882132834425,"Case (b). V = ( −˜c −˜s
˜s
˜c ):a = −P11 + P22, b = −P12 + P21, c = 1"
REFERENCES,0.2970065481758653,"2( ˙Q11 −˙Q41 −˙Q14 + ˙Q44),
540 d = 1"
REFERENCES,0.29747427502338636,"2( ˙Q21 −˙Q31 + ˙Q12 −˙Q42 −˙Q13 + ˙Q43 −˙Q24 + ˙Q34), and e = 1"
REFERENCES,0.2979420018709074,"2( ˙Q22 −˙Q32 −˙Q23 + ˙Q33).
541"
REFERENCES,0.2984097287184284,"Case (c). V = ( ˜c −˜s
˜s −˜c ):a = P11 −P22, b = −P12 + P21, c = 1"
REFERENCES,0.29887745556594947,"2( ˙Q11 −˙Q41 −˙Q14 + ˙Q44),
542 d = 1"
REFERENCES,0.2993451824134705,"2(−˙Q21+ ˙Q31−˙Q12+ ˙Q42+ ˙Q13−˙Q43+ ˙Q24−˙Q34), and e = 1"
REFERENCES,0.2998129092609916,"2( ˙Q22−˙Q32−˙Q23+ ˙Q33).
543"
REFERENCES,0.30028063610851263,"C
Proofs for Section 2
544"
REFERENCES,0.3007483629560337,"C.1
Proof of Lemma 2.1
545"
REFERENCES,0.30121608980355474,"Proof. Defining JBB = J(UB, UB) , then we have: JUB = UBJBB, U⊤
B J = JBBU⊤
B , and U⊤
B JUB =
546"
REFERENCES,0.3016838166510758,"JBB.
547"
REFERENCES,0.3021515434985968,"Part (a). For any V ∈R2×2 and B ∈{Bi}C2
n
i=1, we have:
548"
REFERENCES,0.30261927034611785,[X+]⊤JX+ −X⊤JX
REFERENCES,0.3030869971936389,"①=
X⊤JUB(V −I2)U⊤
B X + [UB(V −I2)U⊤
B X]⊤JX"
REFERENCES,0.30355472404115996,"+[UB(V −I2)U⊤
B X]⊤J[UB(V −I2)U⊤
B X]"
REFERENCES,0.304022450888681,"=
X⊤[JUB(V −I2)U⊤
B + UB(V −I2)⊤U⊤
B J + UB(V −I2)⊤U⊤
B JUB(V −I2)U⊤
B ]X"
REFERENCES,0.3044901777362021,"=
X⊤[UBJBB(V −I2)U⊤
B + UB(V −I2)⊤JBBU⊤
B + UB(V −I2)⊤JBB(V −I2)U⊤
B ]X"
REFERENCES,0.3049579045837231,"=
X⊤UB[JBB(V −I2) + (V −I2)⊤JBB + (V −I2)⊤JBB(V −I2)]U⊤
B X"
REFERENCES,0.3054256314312441,"=
X⊤UB[V⊤JBBV −JBB]U⊤
B X ②=
0."
REFERENCES,0.3058933582787652,"Part (b). Using the update rule for X+ = X + UB(V −I2)U⊤
B X ∈Rn×n, we derive:
549"
REFERENCES,0.30636108512628624,"∥X+ −X∥F
=
∥UB(V −I2)U⊤
B X∥F"
REFERENCES,0.3068288119738073,"①
≤
∥UB∥F · ∥(V −I2)U⊤
B X∥F,"
REFERENCES,0.30729653882132835,"②
≤
∥UB∥F · ∥(V −I2)∥F · ∥U⊤
B ∥F · ∥X∥F,"
REFERENCES,0.3077642656688494,"③=
∥V −I2∥F · ∥X∥F,"
REFERENCES,0.30823199251637046,"where step ①and step ②use the norm inequality that ∥AX∥F ≤∥A∥F · ∥X∥F for any A and X;
550"
REFERENCES,0.3086997193638915,"step ③uses ∥UB∥= ∥U⊤
B ∥= 1.
551"
REFERENCES,0.3091674462114125,"Part (c). We define Z ≜U⊤
B X. We derive:
552"
REFERENCES,0.30963517305893357,"∥X+ −X∥2
H
=
∥UB(V −I2)Z∥2
H
①=
vec(UB(V −I2)Z)⊤Hvec(UB(V −I2)Z)"
REFERENCES,0.3101028999064546,"②=
vec(V −I2)⊤(Z⊤⊗UB)⊤H(Z⊤⊗UB)vec(V −I2)"
REFERENCES,0.3105706267539757,"=
∥V −I2∥2
(Z⊤⊗UB)⊤H(Z⊤⊗UB)"
REFERENCES,0.31103835360149673,"③
≤
∥V −I2∥2
Q,"
REFERENCES,0.3115060804490178,"where step ①uses ∥X∥2
H = vec(X)⊤Hvec(X); step ②uses (Z⊤⊗R)vec(U) = vec(RUZ) for
553"
REFERENCES,0.31197380729653884,"all R, Z and U of suitable dimensions; step ③uses the choice of Q ≽Q ≜(Z⊤⊗UB)⊤H(Z⊤⊗
554"
REFERENCES,0.3124415341440599,"UB).
555"
REFERENCES,0.3129092609915809,"C.2
Proof of Lemma 2.3
556"
REFERENCES,0.31337698783910195,"Proof. We denote w = c + e. According to the properties of trigonometric functions, we have: (i)
557"
REFERENCES,0.313844714686623,"˜c2 =
1
1−˜t2 ; (ii) ˜s2 =
˜t2"
REFERENCES,0.31431244153414406,1−˜t2 ; (iii)˜t = ˜s
REFERENCES,0.3147801683816651,"˜c, leading to: ˜c =
±1
√"
REFERENCES,0.31524789522918617,"1−˜t2 ,˜s =
±˜t
√"
REFERENCES,0.3157156220767072,"1−˜t2 with |˜t | < 1.
558"
REFERENCES,0.3161833489242282,"We discuss two cases for Problem (8).
559"
REFERENCES,0.3166510757717493,"Case (a). ˜c =
1
√"
REFERENCES,0.31711880261927033,"1−˜t2 ,˜s =
˜t
√"
REFERENCES,0.3175865294667914,"1−˜t2 . Problem (8) is equivalent to the following problem: ¯µ+ =
560"
REFERENCES,0.31805425631431244,"arg minµ
a+˜t b
√"
REFERENCES,0.3185219831618335,1−˜t2 + w+˜t d
REFERENCES,0.31898971000935455,"1−˜t2 −e. Therefore, the optimal solution ¯µ+can be computed as:
561"
REFERENCES,0.3194574368568756,"cosh(¯µ+) =
1
√"
REFERENCES,0.3199251637043966,"1−(¯t+)2 , and sinh(¯µ+) =
¯t+
√"
REFERENCES,0.32039289055191766,"1−(¯t+)2
(14)"
REFERENCES,0.3208606173994387,"Case (b). ˜c =
−1
√"
REFERENCES,0.3213283442469598,"1−˜t2 ,˜s =
−˜t
√"
REFERENCES,0.32179607109448083,"1−˜t2 . Problem (8) is equivalent to the following problem: ¯µ−=
562"
REFERENCES,0.3222637979420019,"arg minµ −a−˜t b
√"
REFERENCES,0.32273152478952294,1−˜t2 + w+˜t d
REFERENCES,0.323199251637044,"1−˜t2 −e. Therefore, the optimal solution ¯µ−can be computed as:
563"
REFERENCES,0.323666978484565,"cosh(¯µ−) =
−1
√"
REFERENCES,0.32413470533208605,"1−(¯t−)2 , and sinh(¯µ−) =
−¯t−
√"
REFERENCES,0.3246024321796071,"1−(¯t−)2 .
(15)"
REFERENCES,0.32507015902712816,"We define the objective function as: ˘F(˜c, ˜s) ≜a˜c + b˜s + c˜c2 + d˜c˜s + e˜s2. In view of (14) and (15),
564"
REFERENCES,0.3255378858746492,"the optimal solution pair [cosh(¯µ, sinh(¯µ)] for problem (8) can be computed as:
565"
REFERENCES,0.32600561272217027,"[cosh(¯µ), sinh(¯µ)] = arg min
[c,s]
˘F(c, s),"
REFERENCES,0.3264733395696913,"s. t. [c, s] ∈{[cosh(¯µ+), sinh(¯µ+)], [cosh(¯µ−), sinh(¯µ−)]}"
REFERENCES,0.3269410664172123,"Importantly, it is not necessary to compute the values ¯µ+ for (14) and ¯µ−for (15).
566 567"
REFERENCES,0.3274087932647334,"C.3
Proof of Lemma 2.4
568"
REFERENCES,0.32787652011225443,"Proof. The objective function for Bt
(i) as in Equation (3) is formulated as :"
REFERENCES,0.3283442469597755,f(Xt) + 1
REFERENCES,0.32881197380729654,"2∥Vi −I∥2
Q+θI + ⟨Vi −I, [∇f(Xt)(Xt)T]Bt
(i)Bt
(i)⟩"
REFERENCES,0.3292797006548176,Part (1). For the part of 1
REFERENCES,0.32974742750233865,"2∥Vi −I∥2
Q+θI, it is obviously irrelevant.
569"
REFERENCES,0.3302151543498597,"Part (2). For the part of ⟨Vi −I, [∇f(Xt)(Xt)T]Bt
(i)Bt
(i)⟩, we note that [∇f(Xt)(Xt)⊤]Bt
(i)Bt
(i) =
570"
REFERENCES,0.3306828811973807,"[∇f(Xt)](Bt
(i), :)[(Xt)⊤](:, Bt
(i)) = [∇f(Xt)](Bt
(i), :)[(Xt)(Bt
(i), :)]⊤, which just use the informa-
571"
REFERENCES,0.33115060804490176,"tion of block Bt
(i). The proof ends.
572"
REFERENCES,0.3316183348924228,"C.4
Proof of Lemma 2.5
573"
REFERENCES,0.33208606173994387,"Proof. Part (a). For the purpose of analysis, we define the following: ∀i ∈[ n"
REFERENCES,0.3325537885874649,"2 ], Ki = UB(i)(Vi −
574"
REFERENCES,0.333021515434986,"I2)U⊤
B(i)X.
575 ∥P n"
REFERENCES,0.33348924228250704,"2
i=1[UB(i)(Vi −I2)U⊤
B(i)X]∥2
F
①=   "
REFERENCES,0.33395696913002804,"K1
K2
...
K n 2    2"
REFERENCES,0.3344246959775491,"F
②=
∥K1∥2
F + ∥K2∥2
F + · · · + ∥K n"
REFERENCES,0.33489242282507015,"2 ∥2
F"
REFERENCES,0.3353601496725912,"③=
P n"
REFERENCES,0.33582787652011226,"2
i=1[∥UB(i)(Vi −I2)U⊤
B(i)X∥2
F]"
REFERENCES,0.3362956033676333,"where step ①uses the definition of Ki and the assumption that B ∈Υ; step ②uses the definition of
576"
REFERENCES,0.33676333021515437,"Squared Frobenius Norm; step ③uses the definition of Ki.
577"
REFERENCES,0.3372310570626754,"Part (b). Using the update rule for X+ = X + [Pn/2
i=1 UB(i)(Vi −I2)U⊤
B(i)]X ∈Rn×n, we have the
578"
REFERENCES,0.3376987839101964,"following inequalities:
579"
REFERENCES,0.3381665107577175,"∥X+ −X∥2
F
=
∥[Pn/2
i=1 UB(i)(Vi −I2)U⊤
B(i)]X∥2
F
(16)"
REFERENCES,0.33863423760523853,"①=
Pn/2
i=1 ∥[UB(i)(Vi −I2)U⊤
B(i)]X∥2
F
(17)"
REFERENCES,0.3391019644527596,"②
≤
Pn/2
i=1 ∥Vi −I2∥2
F · ∥X∥2
F,
(18)"
REFERENCES,0.33956969130028064,"where step ①uses the conclusion of Part (a); step ②uses the same proof process of Part (b) of lemma
580"
REFERENCES,0.3400374181478017,"2.1.
581"
REFERENCES,0.34050514499532275,Part (c). We derive the following results:
REFERENCES,0.3409728718428438,"1
2∥X+ −X∥2
H = 1"
REFERENCES,0.3414405986903648,"2∥[Pn/2
i=1 UB(i)(Vi −I2)U⊤
B(i)]X∥2
H ①= 1"
REFERENCES,0.34190832553788586,"2
Pn/2
i=1 ∥[UB(i)(Vi −I2)U⊤
B(i)]X∥2
H ②
≤1"
REFERENCES,0.3423760523854069,"2
Pn/2
i=1 ∥Vi −I2∥2
Q"
REFERENCES,0.34284377923292797,"where step ①uses the conclusion of Part (a); step ②uses the same proof process of Part (c) of lemma
582"
REFERENCES,0.343311506080449,"2.1.
583"
REFERENCES,0.3437792329279701,"Part (d). We derive the following results:
584"
REFERENCES,0.34424695977549113,"Pn/2
i=1⟨Vi −I2, [(∇f(X) −˜G)X⊤]BiBi⟩"
REFERENCES,0.34471468662301213,"=
Pn/2
i=1⟨[UB(i)(Vi −I2)U⊤
B(i)]X, [(∇f(X) −˜G)]⟩"
REFERENCES,0.3451824134705332,"=
⟨X+ −X, [(∇f(X) −˜G)]⟩"
REFERENCES,0.34565014031805424,"①
≤
1
2∥X+ −X∥2
F + 1"
REFERENCES,0.3461178671655753,"2∥[∇f(X) −˜G]∥2
F"
REFERENCES,0.34658559401309635,"②
≤
1
2∥X∥2
F
Pn/2
i=1 ∥Vi −I2∥2
F + 1"
REFERENCES,0.3470533208606174,"2∥[∇f(X) −˜G]∥2
F
(19)"
REFERENCES,0.34752104770813846,"where step ①uses ∀A, B, 1"
REFERENCES,0.3479887745556595,"2∥A −B∥2
F = 1"
REFERENCES,0.3484565014031805,"2∥A∥2
F + 1"
REFERENCES,0.3489242282507016,"2∥B∥2
F −⟨A, B⟩≥0, with A = ∥X+ −X∥2
F
585"
REFERENCES,0.34939195509822263,"and B = ∥[∇f(X) −˜G]∥2
F; step ②uses the conclusion of Part (b).
586"
REFERENCES,0.3498596819457437,"D
Proofs for Section 3
587"
REFERENCES,0.35032740879326474,"D.1
Proof of Lemma 3.1
588"
REFERENCES,0.3507951356407858,"Proof. We consider the Lagrangian function of problem (1):
589"
REFERENCES,0.35126286248830685,"L(X, Λ) = f(X) −1"
REFERENCES,0.3517305893358279,"2⟨Λ, XTJX −J⟩.
(20)"
REFERENCES,0.3521983161833489,"Setting the gradient of L(X, Λ) w.r.t. X to zero yields:
590"
REFERENCES,0.35266604303086996,"∇f(X) −JXΛ = 0.
(21)"
REFERENCES,0.353133769878391,"Part (a). Multiplying both sides by XT and using the fact that XTJX = J, we have JΛ =
591"
REFERENCES,0.35360149672591207,"XT∇f(X). Multiplying both sides by JT and using J⊤J = I, we have Λ = JX⊤∇f(X). Since Λ
592"
REFERENCES,0.3540692235734331,"is symmetric, we have Λ = ∇f(X)TXJ. Putting this equality into Equality (21) yields the following
593"
REFERENCES,0.3545369504209542,"first-order optimality condition for Problem (1):
594"
REFERENCES,0.35500467726847523,"∇f(X) = JX[∇f(X)]TXJ.
(22)"
REFERENCES,0.35547240411599623,"Part (b). We let G = ∇f(X). We derive the following results:
595"
REFERENCES,0.3559401309635173,"G = JXGTXJ
①⇒
JXT · G = JXT · JXGTXJ
②⇒
JXTG = GTXJ
③⇒
X(JXTG)XT = X(GTXJ)XT"
REFERENCES,0.35640785781103834,"④⇒
X JXTGXTJ
|
{z
}"
REFERENCES,0.3568755846585594,"≜GT
J = J JXGTXJ
|
{z
}"
REFERENCES,0.35734331150608045,"≜G
XT
(23)"
REFERENCES,0.3578110383536015,"⑤⇒
(XGTJ) · JX = (JGXT) · JX"
REFERENCES,0.35827876520112256,"⑥⇒
XGTX = JGJ
⑦⇒
JXGTXJ = G,"
REFERENCES,0.3587464920486436,"where step ①uses the results of left-multiplying both sides by JXT; step ②uses J·XTJX = JJ = I;
596"
REFERENCES,0.3592142188961646,"step ③uses the results of left-multiplying both sides by X and subsequently right-multiplying them
597"
REFERENCES,0.35968194574368567,"by XT; ④uses G = JXGTXJ; step ⑤uses the the results of right-multiplying both sides by JX;
598"
REFERENCES,0.3601496725912067,"step ⑥uses JJ = I and XTJX = J; step ⑦uses the results of left-multiply both sides by J and
599"
REFERENCES,0.3606173994387278,"right-multiplied by J.
600"
REFERENCES,0.36108512628624884,"Given Equality (23), we conclude that the critical point condition is equivalent to the requirement
601"
REFERENCES,0.3615528531337699,"that the matrix X∇f( ˇX)TJ is symmetric, which is expressed as XGTJ = [XGTJ]T.
602"
REFERENCES,0.36202057998129095,"D.2
Proof of Theorem 3.3
603"
REFERENCES,0.362488306828812,"Proof. We use ¨X and ˇX to denote any BS-point and critical point, respectively.
604"
REFERENCES,0.362956033676333,"For all B ∈Ω≜{B1, B2, . . . , BC2n}, we have:
605"
REFERENCES,0.36342376052385406,"I2 ∈arg min
V∈JB G(V; ¨X, B)."
REFERENCES,0.3638914873713751,"where G(V; X, B) ≜f(X) + 1"
REFERENCES,0.36435921421889617,"2∥V −I2∥2
Q+θI + ⟨V −I, [∇f(X)(X)T]BB⟩.
606"
REFERENCES,0.3648269410664172,"The Euclidean gradient of G(V; ¨X, B) can be computed as:
607"
REFERENCES,0.3652946679139383,"¨G ≜mat((Q + θI2) vec(V −I2)) + [∇f( ¨X)( ¨X)T]BB.
(24)"
REFERENCES,0.36576239476145933,"Given Lemma 3.1, we set the Riemannian gradient of G(V; ¨X, B) w.r.t. V to zero, leading to the
608"
REFERENCES,0.36623012160898033,"following first-order optimality condition:
609"
REFERENCES,0.3666978484565014,"0 = ∇J G(V; ¨X, B) = ¨G −UT
B JV ¨G⊤VJUB.
(25)"
REFERENCES,0.36716557530402244,"Letting V = I2, and using the definition of ¨G, we have:
610"
REFERENCES,0.3676333021515435,"02,2 = [∇f(X)(X)T]BB −JBB ¨G⊤JBB, ∀B ∈{Bi}C2
n
i=1"
REFERENCES,0.36810102899906455,"⇒
02,2 = U⊤
B [∇f( ¨X) ¨XT]UB −JBBU⊤
B [ ¨X∇f( ¨X)T]UBJBB, ∀B ∈{Bi}C2
n
i=1
①⇒
02,2 = U⊤
B [∇f( ¨X) ¨XT]UB −U⊤
B J[ ¨X∇f( ¨X)T]JUB, ∀B ∈{Bi}C2
n
i=1
②⇒
0n,n = [∇f( ¨X) ¨XT] −J[ ¨X∇f( ¨X)T]J,"
REFERENCES,0.3685687558465856,"③⇒
[J∇f( ¨X) ¨XT] = [J∇f( ¨X) ¨XT]T,"
REFERENCES,0.36903648269410666,"where step ①uses U⊤
B J = JBBU⊤
B and JUB = UBJBB; step ②uses the the following results for any
611"
REFERENCES,0.3695042095416277,"W ∈Rn×n:
612"
REFERENCES,0.3699719363891487,"(∀B ∈{Bi}C2
n
i=1, 02,2 = U⊤
B WUB = WBB) ⇒(W = 0n,n);
(26)"
REFERENCES,0.37043966323666977,"step ③uses the fact that both sides are left-multiplied by J. We conclude that the matrix J∇f( ¨X) ¨XT
613"
REFERENCES,0.3709073900841908,"is symmetric. Using Claim (b) of Lemma 3.1, we conclude that ¨X is a also a critical point.
614"
REFERENCES,0.3713751169317119,"Notably, the condition in Equation (25) is a necessary but not sufficient condition. This is because
615"
REFERENCES,0.37184284377923293,"BS-point is the global minimum of Problem: arg minV∈JB G(V; ¨X, B), according to Definition
616"
REFERENCES,0.372310570626754,"3.2.
617"
REFERENCES,0.37277829747427504,"E
Proofs for Section 4
618"
REFERENCES,0.37324602432179604,"E.1
Proof of Lemma 4.5
619"
REFERENCES,0.3737137511693171,"Proof. By the definition of ˜Gt, we have
620"
REFERENCES,0.37418147801683815,"Eιt[∥˜Gt −∇f(Xt)∥2
F]"
REFERENCES,0.3746492048643592,"①=
pEιt[∥1"
REFERENCES,0.37511693171188026,"b
Pb
i=1 ∇fi(Xt) −∇f(Xt)∥2
F] +"
REFERENCES,0.3755846585594013,(1 −p)Eιt[∥˜Gt−1 + 1
REFERENCES,0.3760523854069224,"b′
Pb′"
REFERENCES,0.37652011225444343,"i=1(∇fi(Xt) −∇fi(Xt−1)) −∇f(Xt)∥2
F]"
REFERENCES,0.37698783910196443,"②=
pEιt[∥1"
REFERENCES,0.3774555659494855,"b
Pb
i=1 ∇fi(Xt) −∇f(Xt)∥2
F] + (1 −p)Eιt−1[∥˜Gt−1 −∇f(Xt−1)∥2
F]"
REFERENCES,0.37792329279700654,+(1 −p)Eιt[∥1
REFERENCES,0.3783910196445276,"b′
Pb′"
REFERENCES,0.37885874649204865,"i=1(∇fi(Xt) −∇fi(Xt−1)) −∇f(Xt) + ∇f(Xt−1)∥2
F]"
REFERENCES,0.3793264733395697,"where step ①uses formula (9); step ②uses that ˜Gt−1 −∇f(Xt−1) is measurable w.r.t. ιt−1 and
621"
REFERENCES,0.37979420018709076,Eιt[∥1
REFERENCES,0.3802619270346118,"b′
Pb′"
REFERENCES,0.3807296538821328,"i=1(∇fi(Xt) −∇fi(Xt−1)) −∇f(Xt) + ∇f(Xt−1)∥2
F] = 0. We further have
622"
REFERENCES,0.38119738072965387,"Eιt[∥˜Gt −∇f(Xt)∥2
F]"
REFERENCES,0.3816651075771749,"①
≤
pEιt[∥1"
REFERENCES,0.382132834424696,"b
Pb
i=1 ∇fi(Xt) −∇f(Xt)∥2
F] + (1 −p)Eιt−1[∥˜Gt−1 −∇f(Xt−1)∥2
F]"
REFERENCES,0.38260056127221703,+(1 −p)Eιt[∥1
REFERENCES,0.3830682881197381,"b′
Pb′"
REFERENCES,0.38353601496725914,"i=1(∇fi(Xt) −∇fi(Xt−1))∥2
F]"
REFERENCES,0.38400374181478014,"②
≤
p(N−b)
b(N−1)Eιt[∥∇fi(Xt) −∇f(Xt)∥2
F] + (1 −p)Eιt−1∥˜Gt−1 −∇f(Xt−1)∥2
F] + 1−p"
REFERENCES,0.3844714686623012,"b′ Eιt−1[∥∇fi(Xt) −∇fi(Xt−1)∥2
F]"
REFERENCES,0.38493919550982225,"③
≤
p(N−b)
b(N−1)σ2 + (1 −p)Eιt−1[∥˜Gt−1 −∇f(Xt−1)∥2
F]"
REFERENCES,0.3854069223573433,"+
L2
f X2(1−p)"
REFERENCES,0.38587464920486436,"b′
Eιt−1[Pn/2
i=1 ∥Vt−1
i
−I2∥2
F]
(27)"
REFERENCES,0.3863423760523854,"where step ①uses that for any random variable X, E[(X −E[X])2] ≤E[X2]; step ②uses lemma
623"
REFERENCES,0.38681010289990647,"A.2; step ③uses assumption 4.3, Inequality (2) and Part (b) of lemma 2.5.
624"
REFERENCES,0.3872778297474275,"E.2
Proof of theorem 4.6
625"
REFERENCES,0.3877455565949485,"Proof. For simplicity, we use B instead of Bt. We will show that the following inequality holds :
626"
REFERENCES,0.3882132834424696,"θ
2∥¯Vt −I2∥2
F ≤f(Xt) −f(Xt+1).
(28)"
REFERENCES,0.38868101028999064,"Since ¯Vt is the global optimal solution of Problem (5), we have:"
REFERENCES,0.3891487371375117,"G( ¯Vt; Xt, B) ≤G(V; Xt, B), V ∈JB"
REFERENCES,0.38961646398503275,"Letting V = I2, we have: G( ¯Vt; Xt, B) ≤G(I2; Xt, B). We further obtain:
627"
REFERENCES,0.3900841908325538,"1
2∥¯Vt −I2∥2
Q+θI + ⟨¯Vt −I, [∇f(Xt)(Xt)⊤]BB⟩≤0.
(29)"
REFERENCES,0.39055191768007486,"Using Inequality (2) with N = 1 and Part (c) of Lemma 2.1, we have:
628"
REFERENCES,0.3910196445275959,"f(Xt+1) ≤f(Xt) + ⟨¯Vt −I2, [∇f(Xt)(Xt)⊤]BB⟩+ 1"
REFERENCES,0.3914873713751169,"2∥¯Vt −I2∥2
Q.
(30)"
REFERENCES,0.39195509822263797,"Adding Inequality (29) and (30) together, we obtain the inequality in (28). Using the result of Part (b)
629"
REFERENCES,0.392422825070159,"in Lemma 2.1 that ∥X+−X∥2
F
∥X∥2
F
≤∥V −I2∥2
F, we have the following sufficient decrease condition:
630"
REFERENCES,0.3928905519176801,f(Xt+1) −f(Xt) ≤−θ
REFERENCES,0.39335827876520113,"2∥¯Vt −I2∥2
F ≤−θ"
REFERENCES,0.3938260056127222,"2
∥Xt+1−Xt∥2
F
∥Xt∥2
F
(31)"
REFERENCES,0.39429373246024324,"We now prove the global convergence. Taking the expectation for Inequality (31), we obtain a lower
bound on the expected progress made by each iteration for Algorithm 1:"
REFERENCES,0.39476145930776424,Eξt+1[f(Xt+1)] −Eξt[f(Xt)] ≤−Eξt[ θ
REFERENCES,0.3952291861552853,"2∥¯Vt −I2∥2
F]."
REFERENCES,0.39569691300280635,"Summing up the inequality above over t = 0, 1, . . . , T, we have:"
REFERENCES,0.3961646398503274,Eξt[ θ
PT,0.39663236669784846,"2
PT
t=0 ∥¯Vt −I2∥2
F] ≤f(X0) −EξT +1[f(XT +1)] ≤f(X0) −f( ¯X)."
PT,0.3971000935453695,"As a result, there exists an index ¯t with 0 ≤¯t ≤T such that
631"
PT,0.39756782039289057,"Eξ¯t[∥¯V¯t −I2∥2
F] ≤
2
θ(T +1)[f(X0) −f( ¯X)].
(32)"
PT,0.3980355472404116,"Furthermore, for any t, we have:
632"
PT,0.3985032740879326,"E(Xt) ≜
1
C2n
PC2
n
i=1 dist(I2, arg minV G(V; Xt, Bi))2 = Eξt[∥¯Vt −I2∥2
F]
(33)"
PT,0.3989710009354537,"Combining Inequality (32) and equality (33), we have the following result:
633"
PT,0.39943872778297473,"Eξt[∥¯Vt −I2∥2
F] = E(X¯t) ≤2(f(X0)−f( ¯X))"
PT,0.3999064546304958,"θ(T +1)
.
(34)"
PT,0.40037418147801684,"We will give the arithmetic operations of GS-JOBCD. By the chosen parameters and Inequality (34),
we have
E(X¯t) ≤2(f(X0)−f( ¯X))"
PT,0.4008419083255379,"θ(T +1)
≤ϵ."
PT,0.40130963517305895,We define ∆0 = f(X0) −f( ¯X) and set T + 1 = 2∆0
PT,0.40177736202058,"ϵθ . Denoting mt to be the number of arithmetic
operations at t-th iteration, we have for t ≥1:"
PT,0.402245088868101,Eξt[mt] = O(2N).
PT,0.40271281571562206,"Then we have for t ≥1, the total number of arithmetic operations M T in T iterations to obtain
ϵ-BS-point is
EξT [M T ] = Eξt[PT
t=0 mt] = 2(T + 1)N = O((T + 1)N)."
PT,0.4031805425631431,We have (T + 1)N = N 2∆0
PT,0.4036482694106642,ϵθ = O( ∆0N
PT,0.40411599625818523,"ϵ
).
634"
PT,0.4045837231057063,"E.3
Proof of Theorem 4.7
635"
PT,0.40505144995322734,"Proof. For simplicity, we use B instead of Bt. Defining ¯
V:
t as the global optimal solution of
arg minV: T (V:; Xt, B), we have:"
PT,0.40551917680074834,"T ( ¯
V:
t; Xt, B) ≤T (V:; Xt, B), ∀i, Vi ∈JB(i)"
PT,0.4059869036482694,"Letting Vi = I2, ∀i, we have: T ( ¯
V:
t; Xt, B) ≤T (I2; Xt, B). We further obtain:
636"
PT,0.40645463049579045,"1
2
Pn/2
i=1 ∥¯Vt
i −I2∥2
(ζ+θ)I + Pn/2
i=1⟨¯Vt
i −I, [ ˜Gt(Xt)⊤]B(i)B(i)⟩≤0.
(35)"
PT,0.4069223573433115,"Using the results of telescoping Inequality (2) over i from 1 to N with Part (c) of Lemma 2.5, we
637"
PT,0.40739008419083256,"have:
638"
PT,0.4078578110383536,"f(Xt+1) ≤f(Xt) + Pn/2
i=1⟨¯Vi −I2, [∇f(X)X⊤]B(i)B(i)⟩+ 1"
PT,0.40832553788587467,"2
Pn/2
i=1 ∥¯Vi −I2∥2
ζI.
(36)"
PT,0.4087932647333957,"Adding inequality (35), and (36) together, we obtain the inequality in (37).
639"
PT,0.4092609915809167,"θ
2
Pn/2
i=1 ∥¯Vt
i −I2∥2
F
≤
f(Xt) −f(Xt+1) + Pn/2
i=1⟨¯Vt
i −I, [(∇f(Xt) −˜Gt)(Xt)⊤]B(i)B(i)⟩"
PT,0.4097287184284378,"①
≤
f(Xt) −f(Xt+1) + 1"
PT,0.41019644527595883,"2∥Xt∥2
F
Pn/2
i=1 ∥¯Vt
i −I2∥2
F + 1"
PT,0.4106641721234799,"2∥[∇f(Xt) −˜Gt]∥2
F
(37)"
PT,0.41113189897100094,"where step ①uses Part (d) of Lemma 2.5.
640"
PT,0.411599625818522,"Taking expectation on both sides of inequality (37) with respect to all randomness of the algorithm,
641"
PT,0.41206735266604305,and adding the inequality in Lemma 4.5 × 1
PT,0.41253507951356405,"2p to (37), we have:
642"
PT,0.4130028063610851,( θ−X2
PT,0.41347053320860616,"2
−
L2
f X2(1−p)"
PT,0.4139382600561272,"2pb′
)Eιt[Pn/2
i=1 ∥¯Vt
i −I2∥2
F]"
PT,0.41440598690364827,"≤
Eιt[f(Xt)] −Eιt+1[f(Xt+1)] +
(N−b)
2b(N−1)σ2 + 1−p"
PT,0.4148737137511693,"2p (Eιt[ut] −Eιt+1[ut+1])
(38)"
PT,0.4153414405986904,"Summing up the inequality above over t = 0, 1, . . . , T, we have:
643"
PT,0.41580916744621144,( θ−X2
PT,0.41627689429373244,"2
−
L2
f X2(1−p)"
PT,0.4167446211412535,"2pb′
)EιT [PT
t=0
Pn/2
i=1 ∥¯Vt
i −I2∥2
F]"
PT,0.41721234798877455,"≤
f(X0) −EιT [f(XT )] + (T +1)(N−b)"
PT,0.4176800748362956,"2b(N−1)
σ2 + 1−p"
PT,0.41814780168381666,2p (u0 −EιT +1[uT +1])
PT,0.4186155285313377,"≤
f(X0) −f( ¯X) + (T +1)(N−b)"
PT,0.41908325537885877,"2b(N−1)
σ2 + 1−p"
PT,0.4195509822263798,"2p (u0 −EιT +1[uT +1])
(39)"
PT,0.4200187090739008,"As a result, there exists an index ¯t with 0 ≤¯t ≤T such that
644"
PT,0.4204864359214219,( θ−X2
PT,0.42095416276894293,"2
−
L2
f X2(1−p)"
PT,0.421421889616464,"2pb′
)(T + 1)Eι¯t[Pn/2
i=1 ∥¯V¯t
i −I2∥2
F]"
PT,0.42188961646398504,"≤
f(X0) −f( ¯X) + (T +1)(N−b)"
PT,0.4223573433115061,"2b(N−1)
σ2 + 1−p"
PT,0.42282507015902715,"2p (u0 −EιT +1[uT +1])
(40)"
PT,0.42329279700654815,Defining ϖ = θ−X2
PT,0.4237605238540692,"2
−
L2
f X2(1−p)"
PT,0.42422825070159026,"2pb′
, furthermore, for any t and ∀i, we have:
645"
PT,0.4246959775491113,"E(Xt) =
1
CJ
PCJ
i=1 Eιt[dist(I2, arg minV: T (V:; Xt, ˜Bi))2] = Eιt[Pn/2
i=1 ∥¯Vt
i −I2∥2
F]
(41)"
PT,0.42516370439663237,"Combining inequality (40) and (41) , we have the following result:
646"
PT,0.4256314312441534,"E(X¯t)≤
1
(T +1)ϖ(f(X0) −f( ¯X) + (T +1)(N−b)"
PT,0.4260991580916745,"2b(N−1)
σ2 + 1−p"
PT,0.42656688493919553,"2p (u0 −EιT +1[uT +1]))
(42)"
PT,0.42703461178671653,"By the chosen parameters and Inequality (42), we have"
PT,0.4275023386342376,"E(X¯t) ≤
1
(T +1)ϖ(f(X0) −f( ¯X) + (T +1)(N−b)"
PT,0.42797006548175864,"2b(N−1)
σ2 + 1−p"
PT,0.4284377923292797,2p (u0 −EιT +1[uT +1])) ≤ϵ.
PT,0.42890551917680075,We define ∆0 = f(X0) −f( ¯X) and set T + 1 = ∆0
PT,0.4293732460243218,"ϵϖ . Denoting mi
t to be the number of arithmetic
operations to update the i-th block at t-th iteration, we have for t ≥1"
PT,0.42984097287184286,"Eιt[mi
t] = O(2(pb + (1 −p)b′))."
PT,0.4303086997193639,"Letting mt be the number of arithmetic operations in the t-the iteration, we have for t ≥1"
PT,0.4307764265668849,"Eιt[mt] = Eιt[Pn/2
i=1 mi
t] = O((pb + (1 −p)b′)n/2 × 2) = O(n(pb + (1 −p)b′))."
PT,0.431244153414406,"Hence, the total number of arithmetic operations M T in T iterations to obtain ϵ-BS-point is"
PT,0.43171188026192703,"EιT [M] = Eιt[PT
t=0 mt] = O(bn) + Eιt[PT
t=1 mt] = O(bn + Tn(pb + (1 −p)b′))."
PT,0.4321796071094481,"Since b = N, b′ =
√"
PT,0.43264733395696914,"b and p =
b′
b+b′ , ϖ = θ−X2"
PT,0.4331150608044902,"2
−
L2
f X2(1−p)"
PT,0.43358278765201125,"2pb′
= 1"
PT,0.43405051449953225,"2(θ −X
2 −L2
fX
2), we have"
PT,0.4345182413470533,"nT(pb + (1 −p)b′) = n
∆0
ϵ(θ−X2−L2
f X2)
2bb′
b+b′ ≤
n∆0
ϵ(θ−X2−L2
f X2)2b′ = O( ∆0
√"
PT,0.43498596819457436,"N
ϵ
). 647"
PT,0.4354536950420954,"E.4
Proof of Theorem 4.10
648"
PT,0.43592142188961647,"Proof. For simplicity, we use B instead of Bt. We notice that the Riemannian gradient of T (V:; Xt, B)
649"
PT,0.4363891487371375,"at the point Vi = I2, ∀i . Defining G = ˜Gt[Xt]⊤and using JUB = UBJBB, U⊤
B J = JBBU⊤
B ,we
650"
PT,0.4368568755846586,"have:
651"
PT,0.43732460243217963,"∇J T (V: = I2; Xt, B) = Pn/2
i=1 U⊤
B(i)GUB(i) −U⊤
B(i)JG⊤JUB(i)
(43)"
PT,0.43779232927970063,"Then, we prove the following important lemmas.
652"
PT,0.4382600561272217,"Lemma E.1. We have the following result for VR-J-JOBCD: Eιt+1[∥˜Gt −˜Gt+1∥F] ≤pEιt[
√"
PT,0.43872778297474274,"ut]+
653"
PT,0.4391955098222638,"LfEιt+1[∥Xt −Xt+1∥F]
654"
PT,0.43966323666978485,"Proof. By the definition of ˜Gt, with the choice of b = N, b′ =
√"
PT,0.4401309635173059,"b and p =
b′
b+b′ , we have
655"
PT,0.44059869036482696,Eιt+1[∥˜Gt −˜Gt+1∥F]
PT,0.441066417212348,"①=
Eιt+1[∥˜Gt −p"
PT,0.441534144059869,"b
Pb
i=1 ∇fi(Xt+1) −1−p"
PT,0.44200187090739007,"b′
Pb′"
PT,0.4424695977549111,i=1(∇fi(Xt+1) −∇fi(Xt)) −(1 −p) ˜Gt∥F]
PT,0.4429373246024322,"=
Eιt+1[∥p ˜Gt −p"
PT,0.44340505144995324,"b
Pb
i=1 ∇fi(Xt+1) −1−p"
PT,0.4438727782974743,"b′
Pb′"
PT,0.44434050514499535,i=1(∇fi(Xt+1) −∇fi(Xt))∥F]
PT,0.44480823199251635,"②
≤
pEιt+1[∥˜Gt −∇f(Xt+1)∥F] + 1−p"
PT,0.4452759588400374,b′ Eιt[∥Pb′
PT,0.44574368568755846,i=1 ∇fi(Xt+1) −∇fi(Xt)∥F]
PT,0.4462114125350795,"③
≤
pEιt[∥˜Gt −∇f(Xt)∥F] + pEιt+1[∥∇f(Xt) −∇f(Xt+1)∥F] + 1−p"
PT,0.44667913938260057,b′ Eιt+1[∥Pb′
PT,0.4471468662301216,i=1 ∇fi(Xt+1) −∇fi(Xt)∥F]
PT,0.4476145930776427,"④
≤
pEιt[
√"
PT,0.44808231992516373,ut] + pEιt+1[∥∇f(Xt) −∇f(Xt+1)∥F] + (1 −p)Eιt+1[∥∇fi(Xt+1) −∇fi(Xt)∥F]
PT,0.44855004677268473,"⑤
≤
pEιt[
√"
PT,0.4490177736202058,ut] + LfEιt+1[∥Xt −Xt+1∥F]
PT,0.44948550046772684,where step ①uses formula (9); step ②uses norm inequality and 1
PT,0.4499532273152479,"b
Pb
i=1 ∇fi(Xt+1) = ∇f(Xt+1)
656"
PT,0.45042095416276895,"with b = N and norm inequality; step ③uses triangle inequality that ∥A −B∥F ≤∥A −C∥F +
657"
PT,0.45088868101029,"∥C−B∥F, for any A, B and C; step ④the definition of ut; step ⑤uses Inequality (2) and the results
658"
PT,0.45135640785781106,"of telescoping it over i from 1 to N.
659"
PT,0.45182413470533206,"Lemma
E.2.
(Riemannian
gradient
Lower
Bound
for
the
Iterates
Gap)
We
de-
660"
PT,0.4522918615528531,"fine
ϕ ≜(3X + VX)G + (1 + V
2 + n"
PT,0.45275958840037417,"2 (X
2 + V
2X
2))Lf + (1 + V
2)θ.
It
holds
that:
661"
PT,0.4532273152478952,"Eιt+1[dist(0, ∇J T (I2; Xt+1, Bt+1))] ≤ϕ · Eιt[Pn/2
i=1 ∥¯Vt
i −I2∥F] + np
√"
PT,0.4536950420954163,"ut
2
(X + V
2X).
662"
PT,0.45416276894293733,"Proof. For notation simplicity, we define:
663"
PT,0.4546304957904584,"Ωi0 ≜U⊤
B(i)[ ˜Gt+1][Xt+1]⊤UB(i), ∀i
(44)"
PT,0.45509822263797944,"Ωi1 ≜U⊤
B(i)[ ˜Gt+1][Xt]⊤UB(i), ∀i,
(45)"
PT,0.45556594948550044,"Ωi2 ≜U⊤
B(i)[ ˜Gt −˜Gt+1][Xt]⊤UB(i), ∀i.
(46)"
PT,0.4560336763330215,"First, using the optimality of ¯Vt
i, i ∈{1, · · · , n"
PT,0.45650140318054255,"2 } for the subproblem, we have:
664"
PT,0.4569691300280636,"02,2 = ˜
Gi −JB(i) ¯Vt
i ˜G⊤
i ¯Vt
iJB(i)
(47)"
PT,0.45743685687558466,"where ˜
Gi = mat((Q + θI2) vec( ¯Vt
i −I2))
|
{z
} ≜Υi1"
PT,0.4579045837231057,"+ U⊤
B(i) ˜Gt(Xt)⊤UB(i)
|
{z
} ≜Υi2"
PT,0.4583723105706268,".
(48)"
PT,0.45884003741814783,"Using the relation that ˜
Gi = Υi1 + Υi2, we obtain the following results from the above equality:
665"
PT,0.4593077642656688,"02,2 = (Υi1 + Υi2) −JB(i) ¯Vt
i(Υi1 + Υi2)⊤¯Vt
iJB(i)"
PT,0.4597754911131899,"①⇒02,2 = Υi1 + Ωi1 + Ωi2 −JB(i) ¯Vt
i(Υi1 + Ωi1 + Ωi2)⊤¯Vt
iJB(i)
⇒Ωi1 = JB(i) ¯Vt
i(Υi1 + Ωi1 + Ωi2)⊤¯Vt
iJB(i) −Υi1 −Ωi2,
(49)"
PT,0.46024321796071094,"where step ①uses Υi2 = Ωi1 + Ωi2. Then we derive the following results:
666"
PT,0.460710944808232,"Eιt+1[dist(0, ∇J T (V: = I2; Xt+1, Bt+1))] = Eιt+1[∥∇J T (V: = I2; Xt+1, Bt+1)∥F]"
PT,0.46117867165575305,"①=
Eιt+1[∥Pn/2
i=1 U⊤
Bt+1
(i) ( ˜Gt+1[Xt+1]⊤−JXt+1[ ˜Gt+1]⊤J)UBt+1
(i) ∥F]"
PT,0.4616463985032741,"②=
Eιt[∥Pn/2
i=1 U⊤
B(i)( ˜Gt+1[Xt+1]⊤−JXt+1[ ˜Gt+1]⊤J)UB(i)∥F]"
PT,0.46211412535079516,"③=
Eιt[∥Pn/2
i=1 Ωi0 −JB(i)Ω⊤
i0JB(i)∥F]"
PT,0.46258185219831616,"④=
Eιt[∥Pn/2
i=1(Ωi0 −Ωi1) + Ωi1 −(JB(i)Ω⊤
i0JB(i) −JB(i)Ω⊤
i1JB(i)) −JB(i)Ω⊤
i1JB(i)∥F]"
PT,0.4630495790458372,"⑤
≤
Eιt[∥Pn/2
i=1 Ωi0 −Ωi1∥F] + Eιt+1[∥Pn/2
i=1 JB(i)Ω⊤
i0JB(i) −JB(i)Ω⊤
i1JB(i)∥F]"
PT,0.46351730589335827,"+Eιt+1[∥Pn/2
i=1 Ωi1 −JB(i)Ω⊤
i1JB(i)∥F]"
PT,0.4639850327408793,"⑥
≤
Eιt[∥Pn/2
i=1 Ωi0 −Ωi1∥F] + Eιt+1[∥Pn/2
i=1 Ω⊤
i0 −Ω⊤
i1∥F] + Eιt+1[∥Pn/2
i=1 Ωi1 −JB(i)Ω⊤
i1JB(i)∥F]"
PT,0.4644527595884004,"⑦
≤
2Eιt[∥Pn/2
i=1 Ωi0 −Ωi1∥F] + Eιt+1[∥Pn/2
i=1 Ωi1 −JB(i)Ω⊤
i1JB(i)∥F]"
PT,0.46492048643592143,"⑧=
2Eιt[∥Pn/2
i=1 Ωi0 −Ωi1∥F]"
PT,0.4653882132834425,"+Eιt[∥Pn/2
i=1 JB(i) ¯Vt
i(Υi1 + Ωi1 + Ωi2)⊤¯Vt
iJB(i) −Υi1 −Ωi2 −JB(i)Ω⊤
i1JB(i)∥F]"
PT,0.46585594013096354,"⑨
≤
2Eιt[∥Pn/2
i=1 Ωi0 −Ωi1∥F] + Eιt[∥Pn/2
i=1 JB(i) ¯Vt
iΥ⊤
i1 ¯Vt
iJB(i) −Υi1∥F]+"
PT,0.46632366697848454,"Eιt[∥Pn/2
i=1 ¯Vt
iΩ⊤
i1 ¯Vt
i −Ω⊤
i1∥F] + Eιt[∥Pn/2
i=1 JB(i) ¯Vt
iΩ⊤
i2 ¯Vt
iJB(i) −Ωi2∥F]
(50)"
PT,0.4667913938260056,"where step ①uses Equality (43) ; step ②uses the fact that both the working set Bt and Bt+1 are selected
667"
PT,0.46725912067352665,"randomly and uniformly; step ③uses the definition of Ωi0 in (44); step ④uses −Ωi1 + Ωi1 = 0
668"
PT,0.4677268475210477,"and −Ω⊤
i1 + Ω⊤
i1 = 0; step ⑤uses the norm inequality; step ⑥uses the norm inequality; step ⑦uses
669"
PT,0.46819457436856876,"the norm inequality; step ⑧uses Equality (49); step ⑨uses the norm inequality. We now establish
670"
PT,0.4686623012160898,"individual bounds for each term for Inequality (50).
671"
PT,0.46913002806361087,"For the first term 2Eιt[∥Pn/2
i=1 Ωi0 −Ωi1∥F] in (50):
672"
PT,0.4695977549111319,"2Eιt[∥Pn/2
i=1 Ωi0 −Ωi1∥F]
=
2Eιt[∥Pn/2
i=1 U⊤
B(i)[ ˜Gt][Xt −Xt]⊤UB(i)∥F]"
PT,0.4700654817586529,"①=
2Eιt[∥Pn/2
i=1[ ˜Gt][UB(i)( ¯Vt
i −I2)UB(i)Xt]⊤∥F]"
PT,0.470533208606174,"②
≤
2XGEιt[∥Pn/2
i=1 ¯Vt
i −I2∥F]"
PT,0.47100093545369504,"③
≤
2XGEιt[Pn/2
i=1 ∥¯Vt
i −I2∥F]
(51)"
PT,0.4714686623012161,"where step ①uses [Xt −Xt]BiBi = UB(i)( ¯Vt
i −I2)U⊤
B(i)Xt; step ②uses the inequality ∥XY∥F ≤
673"
PT,0.47193638914873715,"∥X∥F∥Y∥F for all X and Y repeatedly and the fact that ∀t, ∥˜Gt∥F ≤G and ∀t, ∥Xt∥F ≤X; step ③
674"
PT,0.4724041159962582,"uses the norm inequality.
675"
PT,0.47287184284377926,"For the second term Eιt[∥Pn/2
i=1 JB(i) ¯Vt
iΥ⊤
i1 ¯Vt
iJB(i) −Υi1∥F] in (50):
676"
PT,0.47333956969130025,"Eιt[∥Pn/2
i=1 JB(i) ¯Vt
iΥ⊤
i1 ¯Vt
iJB(i) −Υi1∥F]"
PT,0.4738072965388213,"①
≤
Eιt[∥Pn/2
i=1 ¯Vt
iΥ⊤
i1 ¯Vt
i∥F] + Eιt[∥Pn/2
i=1 Υi1∥F]"
PT,0.47427502338634236,"②
≤
(1 + V
2)Eιt[∥Pn/2
i=1 Υi1∥F]"
PT,0.4747427502338634,"③=
(1 + V
2)Eιt[∥Pn/2
i=1 mat((Q + θI2) vec( ¯Vt
i −I2))∥F]"
PT,0.4752104770813845,"≤
(1 + V
2)∥Q + θI2∥F · Eιt[∥Pn/2
i=1 ¯Vt
i −I2∥F]"
PT,0.47567820392890553,"④
≤
(1 + V
2)(Lf + θ) · Eιt[Pn/2
i=1 ∥¯Vt
i −I2∥F]
(52)"
PT,0.4761459307764266,"where step ①uses the triangle inequality; step ②uses the inequality ∥XY∥F ≤∥X∥F∥Y∥F for all
677"
PT,0.47661365762394764,"X and Y and ∀t, ∥Vt∥F ≤V; step ③uses the definition of Υi1; step ④uses the choice of Q ⪯LfI
678"
PT,0.47708138447146864,"and the norm inequality.
679"
PT,0.4775491113189897,"For the third term Eιt[∥Pn/2
i=1 ¯Vt
iΩ⊤
i1 ¯Vt
i −Ω⊤
i1∥F] in (50), we have:
680"
PT,0.47801683816651075,"Eιt[∥Pn/2
i=1 ¯Vt
iΩ⊤
i1 ¯Vt
i −Ω⊤
i1∥F]"
PT,0.4784845650140318,"①=
Eιt[∥Pn/2
i=1 ¯Vt
iΩ⊤
i1( ¯Vt
i −I2) + ( ¯Vt
i −I2)Ω⊤
i1∥F]"
PT,0.47895229186155286,"②
≤
(1 + V)Eιt[Pn/2
i=1 ∥Ωi1∥F · ∥¯Vt
i −I2∥F]"
PT,0.4794200187090739,"③
≤
(X + VX)Eιt[Pn/2
i=1 ∥˜Gt∥F · ∥¯Vt
i −I2∥F]"
PT,0.47988774555659497,"④
≤
(X + VX)GEιt[Pn/2
i=1 ∥¯Vt
i −I2∥F]
(53)"
PT,0.480355472404116,"where step ①uses the fact that −¯Vt
iΩ⊤
i1I2 + ¯Vt
iΩ⊤
i1 = 0; step ②uses the norm inequality and
681"
PT,0.480823199251637,"∀t, ∥Vt∥F ≤V; step ③uses the fact that ∥Ωi1∥F = ∥U⊤
B(i) ˜Gt[Xt]⊤UB(i)∥F ≤X∥˜Gt∥F, ∀i which
682"
PT,0.4812909260991581,"can be derived using the norm inequality ; step ④uses the fact that ∀X, ∥˜Gt∥F ≤G.
683"
PT,0.48175865294667913,"For the fourth term Eιt[∥Pn/2
i=1 JB(i) ¯Vt
iΩ⊤
i2 ¯Vt
iJB(i) −Ωi2∥F] in (50), we have:
684"
PT,0.4822263797942002,"Eιt[∥Pn/2
i=1 JB(i) ¯Vt
iΩ⊤
i2 ¯Vt
iJB(i) −Ωi2∥F]"
PT,0.48269410664172124,"①
≤
Eιt[∥Pn/2
i=1 ¯Vt
iΩ⊤
i2 ¯Vt
i∥F] + Eιt[∥Pn/2
i=1 Ωi2∥F]"
PT,0.4831618334892423,"②
≤
(1 + V
2)Eιt[∥Pn/2
i=1 Ωi2∥F]"
PT,0.48362956033676335,"③=
(1 + V
2)Eιt[∥Pn/2
i=1 U⊤
B(i)[ ˜Gt −˜Gt][Xt]⊤UB(i)∥F]"
PT,0.48409728718428435,"④
≤
n
2 (X + V
2X)Eιt[∥[ ˜Gt −˜Gt]∥F]"
PT,0.4845650140318054,"⑤
≤
n
2 (X + V
2X)(pEιt[
√"
PT,0.48503274087932646,ut] + LfEιt[∥Xt −Xt∥F])
PT,0.4855004677268475,"⑥
≤
np"
PT,0.4859681945743686,"2 (X + V
2X)Eιt[
√"
PT,0.4864359214218896,ut] + nLf
PT,0.4869036482694107,"2 (X
2 + V
2X
2)Eιt[Pn/2
i=1 ∥¯Vt
i −I2∥F]
(54)"
PT,0.48737137511693174,"where step ①uses the triangle inequality; step ②uses the norm inequality and ∀t, ∥Vt∥F ≤V; step ③
685"
PT,0.48783910196445274,"uses the definition of ∀i, Ωi2 = U⊤
B(i)[ ˜Gt −˜Gt][Xt]⊤UB(i) in (46); step ④uses the norm inequality
686"
PT,0.4883068288119738,"and ∀t, ∥Xt∥F ≤X; step ⑤uses Lemma E.1; step ⑥uses Part (b) in Lemma 2.5 and ∀t, ∥Xt∥F ≤X.
687"
PT,0.48877455565949485,"In view of( 51), (52), (53), (54), and (50), we have:
688"
PT,0.4892422825070159,"Eιt+1[∥∇J T (I2; Xt+1, Bt+1)∥F] ≤
np"
PT,0.48971000935453696,"2 (X + V
2X)Eιt[
√"
PT,0.490177736202058,"ut] + (c1 + c2 + c3 + c4) · Eιt[Pn/2
i=1 ∥¯Vt
i −I2∥F] =
np"
PT,0.49064546304957907,"2 (X + V
2X)Eιt[
√"
PT,0.49111318989710007,"ut] + ϕEιt[Pn/2
i=1 ∥¯Vt
i −I2∥F]"
PT,0.4915809167446211,"where c1 = 2XG, c2 = (1 + V
2)(Lf + θ), c3 = (X + VX)G, and c4 = n"
PT,0.4920486435921422,"2 (X
2 + V
2X
2)Lf.
689"
PT,0.49251637043966323,"Lemma E.3. We have the following results: dist(0, ∇J f(Xt)) ≤γ · ∥∇J T (I2; Xt, B)∥F +
690"
X,0.4929840972871843,"2X
2p"
X,0.49345182413470534,"Eιt[ut] with γ ≜X
p"
X,0.4939195509822264,"C2n.
691"
X,0.49438727782974745,"Proof. We have the following inequalities:
692"
X,0.49485500467726845,"∥∇J f(Xt)∥F
①=
∥∇f(Xt) −JXt(∇f(Xt))⊤XtJ∥F"
X,0.4953227315247895,"②=
∥∇f(Xt)(Xt)⊤JXtJ −JXt(∇f(Xt))⊤JJXtJ∥F"
X,0.49579045837231056,"③
≤
∥∇f(Xt)(Xt)⊤−JXt(∇f(Xt))⊤J∥F∥JXtJ∥F"
X,0.4962581852198316,"④
≤
X∥∇f(Xt)(Xt)⊤−JXt(∇f(Xt))⊤J∥F"
X,0.49672591206735267,"where step ①uses the definition of ∇J f(Xt); step ②uses JJ = I and X⊤JX = J ⇒X⊤JXJ =
693"
X,0.4971936389148737,"JJ = I; step ③uses the norm inequality and ; step ④uses ∀t, ∥Xt∥F ≤X.
694"
X,0.4976613657623948,"We Consider ∥∇f(Xt)(Xt)⊤−JXt(∇f(Xt))⊤J∥F:
695"
X,0.49812909260991584,∥∇f(Xt)(Xt)⊤−JXt(∇f(Xt))⊤J∥F
X,0.49859681945743684,"①
≤
∥˜Gt(Xt)⊤−JXt( ˜Gt)⊤J∥F + ∥(∇f(Xt) −˜Gt)(Xt)⊤−JXt(∇f(Xt) −˜Gt)⊤J∥F"
X,0.4990645463049579,"②
≤
∥˜Gt(Xt)⊤−JXt( ˜Gt)⊤J∥F + ∥∇f(Xt) −˜Gt∥F · ∥Xt∥F + ∥Xt∥F · ∥∇f(Xt) −˜Gt∥F"
X,0.49953227315247895,"③
≤
∥˜Gt(Xt)⊤−JXt( ˜Gt)⊤J∥F + 2X
p"
X,0.5,Eιt[ut]
X,0.500467726847521,"where step ①uses ∀A, B, ∥A∥F −∥B∥F ≤∥A −B∥F; step ②uses the norm inequality; step ③
696"
X,0.5009354536950421,"uses ∀t, ∥Xt∥F ≤X. Thus,
697"
X,0.5014031805425632,"∥∇J F(Xt)∥F
≤
X∥˜Gt(Xt)⊤−JXt( ˜Gt)⊤J∥F + 2X
2p"
X,0.5018709073900842,Eιt[ut]
X,0.5023386342376053,"①
≤
X
p"
X,0.5028063610851263,"C2n · ∥Pn/2
i=1 U⊤
B(i)[ ˜Gt(Xt)⊤−JXt( ˜Gt)⊤JUB(i)∥F] + 2X
2p"
X,0.5032740879326474,Eιt[ut]
X,0.5037418147801683,"②=
X
p"
X,0.5042095416276894,"C2n · ∥∇J T (I2; Xt, B)∥F + 2X
2p"
X,0.5046772684752104,Eιt[ut]
X,0.5051449953227315,"where step ①uses Lemma A.1 with W = ˜Gt(Xt)⊤−JXt( ˜Gt)⊤J and k = 2; step ②uses the
698"
X,0.5056127221702525,"definition of ∇J T (I2; Xt, B).
699"
X,0.5060804490177736,"We now present the following useful lemma.
700"
X,0.5065481758652947,"Lemma E.4. We define TXJ ≜{Y ∈Rn×n | AX(Y) = 0} and AX(Y) ≜X⊤JY + Y⊤JX.
For any G ∈Rn×n and X⊤JX = J, the unique minimizer of the following optimization problem:
¯Y = arg minY∈TXMJ h(Y) = 1"
X,0.5070159027128157,"2∥Y −G∥2
F,"
X,0.5074836295603368,"satisify h( ¯Y) ≤h(G −JXG⊤XJ).
701"
X,0.5079513564078578,"Proof. We
note
that
¯Y = arg minY∈TXJ 1"
X,0.5084190832553789,"2∥Y −G∥2
F
=
arg minY 1"
X,0.5088868101028999,"2∥Y −G∥2
F,
702"
X,0.509354536950421,"s.t.
X⊤JY + Y⊤JX = 0.
Introducing a multiplier Λ ∈Rn×n
for the linear con-
703"
X,0.509822263797942,"straints
X⊤JY + Y⊤JX = 0,
we
have
following
Lagrangian
function:
˜L(Y; Λ) =
704"
X,0.5102899906454631,"1
2∥Y −G∥2
F + ⟨X⊤JY + Y⊤JX, Λ⟩. We naturally derive the following first-order optimality
705"
X,0.510757717492984,"condition: Y −G + JXΛ = 0, X⊤JY + Y⊤JX = 0. Incorporating the term Y = G −JXΛ
706"
X,0.5112254443405051,"into X⊤JY + Y⊤JX = 0, we obtain:
707"
X,0.5116931711880262,"X⊤XΛ + Λ⊤X⊤X = G⊤JX + X⊤JG
(55)"
X,0.5121608980355472,"Any Λ satisfying formula (55) is a feasible point, so we can easily find :
708"
X,0.5126286248830683,"X⊤XΛ = X⊤JG
①⇒
XΛ = JG
②⇒
X⊤JXΛ = X⊤JJG
③⇒
JΛ = X⊤G
④⇒
Λ = JX⊤G
⑤⇒
Λ = G⊤XJ
(56)"
X,0.5130963517305893,"where step ①uses the fact that any matrix X satisfying the J-orthogonality constraint has a determinant
709"
X,0.5135640785781104,"of 1 or -1, thus inv(X) exists; step ②multiply both sides of the equation by XJ;step ③uses
710"
X,0.5140318054256314,"XT JX = J and JJ = I; step ④multiply both sides of the equation by J and uses JJ = I; step ⑤
711"
X,0.5144995322731525,"uses the fact that Λ is a symmetric matrix.
712"
X,0.5149672591206735,"Therefore, a feasible solution Y can be computed as Y = G −JXΛ = G −JXG⊤XJ. Since ¯Y
713"
X,0.5154349859681946,"is the optimal solution, there must be h( ¯Y) ≤h(G −JXG⊤XJ).
714"
X,0.5159027128157156,"We now present the proof of this lemma.
715"
X,0.5163704396632367,"Lemma E.5. For any X ∈Rn×n, it holds that dist(0, ∇f ◦(X)) ≤dist(0, ∇J f(X)).
716"
X,0.5168381665107578,"Proof. For the purpose of analysis, we define the nearest J orthogonal matrix to an arbitrary matrix
717"
X,0.5173058933582788,"Y ∈Rn×n is given by PJ (X). Similarly, we have PTXJ (∇f(X)) for projecting gradient ∇f(X)
718"
X,0.5177736202057999,"into space TXJ .
719"
X,0.5182413470533208,"We recall that the following first-order optimality conditions are equivalent for all X ∈Rn×n :
720"
X,0.5187090739008419,"(0 ∈∇f ◦(X)) ⇔(0 ∈PTXJ (∇f(X))).
(57)"
X,0.5191768007483629,"Therefore, we derive the following results:
721"
X,0.519644527595884,"dist(0, ∇f ◦(X))
=
infY∈∇f ◦(X) ∥Y∥F
(58)"
X,0.520112254443405,"=
infY∈P(TXJ )(∇f(X)) ∥Y∥F
(59)"
X,0.5205799812909261,"We let G ∈∇f(X) and obtain the following results from the above equality:
722"
X,0.5210477081384471,"dist(0, ∇f ◦(X))
①
≤
∥G −JXG⊤XJ∥F,
(60)"
X,0.5215154349859682,"②=
∥∇J f(X)∥F ≜dist(0, ∇J f(X)).
(61)"
X,0.5219831618334893,"where step ①uses Lemma E.4; step ②uses ∇J f(X) = G −JXG⊤XJ with G ∈∇f(X).
723"
X,0.5224508886810103,"First of all, since f ◦(X) ≜f(X) + IJ (X) is a KL function, we have from Proposition 4.8 that:
724"
X,0.5229186155285314,"1
φ′(f ◦(X′)−f ◦(X))
≤
dist(0, ∇f ◦(X′))"
X,0.5233863423760524,"①=
∥∇J f(X′)∥F,
(62)"
X,0.5238540692235735,"where step ①uses Lemma E.5. Here, φ(·) is some certain concave desingularization function. Since
725"
X,0.5243217960710945,"φ(·) is concave, we have:
726"
X,0.5247895229186156,"∀∆∈R, ∆+ ∈R, φ(∆+) + (∆−∆+)φ′(∆) ≤φ(∆).
(63)"
X,0.5252572497661365,"Applying the inequality above with ∆= f(Xt) −f( ¯X) and ∆+ = f(Xt+1) −f( ¯X), we have:
727"
X,0.5257249766136576,(f(Xt) −f(Xt+1))φ′(f(Xt) −f( ¯X))
X,0.5261927034611786,"≤
φ(f(Xt) −f( ¯X)) −φ(f(Xt+1) −f( ¯X)) ≜Et.
(64)"
X,0.5266604303086997,"With the sufficient descent condition as shown in Theorem 4.7, we derive the following inequalities:
728"
X,0.5271281571562207,Eιt[ θ
X,0.5275958840037418,"2
Pn/2
i=1 ∥¯Vt
i −I2∥2
F]"
X,0.5280636108512629,"≤
Eιt[f(Xt) −f(Xt+1)] + 1"
X,0.5285313376987839,"2Eιt[∥Xt∥2
F]Eιt[Pn/2
i=1 ∥¯Vt
i −I2∥2
F] + 1"
X,0.528999064546305,"2Eιt[ut]
(65)"
X,0.529466791393826,"①⇒
Eιt[ θ−X2"
X,0.5299345182413471,"2
Pn/2
i=1 ∥¯Vt
i −I2∥2
F]≤Eιt[f(Xt) −f(Xt+1)] + 1"
X,0.5304022450888681,"2Eιt[ut]
(66)
(67)"
X,0.5308699719363892,"where step ①uses ∀t, ∥Xt∥F ≤X.
729"
X,0.5313376987839102,Eιt[ θ−X2
X,0.5318054256314313,"2
Pn/2
i=1 ∥¯Vt
i −I2∥2
F]"
X,0.5322731524789522,"①
≤
Eιt[
Et"
X,0.5327408793264733,φ′(f(Xt)−f( ¯X))] + 1
X,0.5332086061739943,2Eιt[ut]
X,0.5336763330215154,"②
≤
Eιt[Et∥∇J f(Xt)∥F] + 1"
X,0.5341440598690365,2Eιt[ut]
X,0.5346117867165575,"③
≤
Eιt[Etγ∥∇J T (I2; Xt, B)∥F + 2EtX
2p"
X,0.5350795135640786,Eιt[ut]] + 1
X,0.5355472404115996,2Eιt[ut]
X,0.5360149672591207,"④
≤
Eιt[Etγϕ Pn/2
i=1 ∥¯Vt−1
i
−I2∥F] + Etγ np"
X,0.5364826941066417,"2 (X + V
2X)
p"
X,0.5369504209541628,Eιt[ut]
X,0.5374181478016838,"+2EtX
2p"
X,0.5378858746492049,Eιt[ut] + 1
X,0.538353601496726,2Eιt[ut]
X,0.538821328344247,"⑤
≤
Eιt[Etγϕp n 2"
X,0.539289055191768,"qPn/2
i=1 ∥¯Vt−1
i
−I2∥2
F"
X,0.539756782039289,"+Et(2X
2 + γ np"
X,0.5402245088868101,2 X + γ np
V,0.5406922357343311,"2 V
2X)
p"
V,0.5411599625818522,Eιt[ut]] + 1
V,0.5416276894293732,2Eιt[ut]
V,0.5420954162768943,"⑥
≤
Eιt[ nEt2γ2ϕ2"
V,0.5425631431244153,"4θ′
+ θ′"
V,0.5430308699719364,"2
Pn/2
i=1 ∥¯Vt−1
i
−I2∥2
F +
¯θEιt[ut] 2"
V,0.5434985968194574,"+
Et2(2X2+γ np"
V,0.5439663236669785,2 X+γ np
V,0.5444340505144996,2 V2X)2
V,0.5449017773620206,"2¯θ
] + 1"
V,0.5453695042095417,2Eιt[ut]
V,0.5458372310570627,"⑦=
Eιt[Et2A2 + θ′"
V,0.5463049579045838,"2
Pn/2
i=1 ∥¯Vt−1
i
−I2∥2
F] +
¯θ+1"
V,0.5467726847521047,"2 Eιt[ut]
(68)"
V,0.5472404115996258,"where step ①uses the sufficient descent condition as shown in Theorem 4.7;
step
730"
V,0.5477081384471468,"②uses Inequality (64) and (62) with X′
=
Xt and X
=
¯X; step ③uses lemma
731"
V,0.5481758652946679,"E.3 ;
step ④uses Lemma E.2 ;
step ⑤uses ∀xi
∈
R, x1+···+xn n
⩽
q"
V,0.5486435921421889,"x2
1+···+x2n n
732"
V,0.54911131898971,";
step
⑥
applies
the
inequality
that
∀θ′
>
0, a, b, ab
≤
θ′a2"
V,0.549579045837231,"2
+
b2
2θ′
with
733"
V,0.5500467726847521,"a =
qPn/2
i=1 ∥¯Vt−1
i
−I2∥2
F, b = Etγϕp n"
V,0.5505144995322732,"2 ; a =
p"
V,0.5509822263797942,"Eιt[ut], b = Et(2X
2 + γ np"
V,0.5514499532273153,2 X + γ np
V,0.5519176800748363,"2 V
2X);
734"
V,0.5523854069223574,"step ⑦denote A2 ≜
(2X2+γ np"
V,0.5528531337698784,2 X+γ np
V,0.5533208606173995,2 V2X)2
V,0.5537885874649204,"2¯θ
+ nγ2ϕ2"
V,0.5542563143124415,"4θ′ .
To simplify the formula, we define
735"
V,0.5547240411599625,"ℵt = Pn/2
i=1 ∥¯Vt
i −I2∥2
F .
736"
V,0.5551917680074836,"Multiplying both sides by 2 and taking the square root of both sides, we have:
737"
V,0.5556594948550047,"Eιt[
q"
V,0.5561272217025257,"θ −X
2√"
V,0.5565949485500468,"ℵt]
≤
q"
V,0.5570626753975678,"Eιt[Et2A2 + θ′ℵt−1] + (¯θ + 1)Eιt[ut] ≤
q"
V,0.5575304022450889,"Eιt[Et2A2] + Eιt−1[
√"
V,0.5579981290926099,"θ′ℵt−1] +
q"
V,0.558465855940131,(¯θ + 1)Eιt[ut]
V,0.558933582787652,"≤
EtA +
√"
V,0.5594013096351731,"θ′Eιt−1[
√"
V,0.5598690364826941,"ℵt−1] +
q"
V,0.5603367633302152,"(¯θ + 1)
p"
V,0.5608044901777361,"Eιt[ut]
(69)"
V,0.5612722170252572,"To recursively eliminate term
p"
V,0.5617399438727783,"(¯θ + 1)Eιt[ut], we take the root of both sides of the Inequality in
738"
V,0.5622076707202993,"Lemma 4.5:
739 p"
V,0.5626753975678204,"Eιt[ut]
≤
q"
V,0.5631431244153414,"p(N−b)
b(N−1)σ2 +
p"
V,0.5636108512628625,"(1 −p)Eιt−1[ut−1] +
q"
V,0.5640785781103835,"L2
f X2(1−p)"
V,0.5645463049579046,"b′
Eιt−1[ℵt−1] ≤
q"
V,0.5650140318054256,"p(N−b)
b(N−1)σ2 +
p"
V,0.5654817586529467,"(1 −p)
p"
V,0.5659494855004678,"Eιt−1[ut−1] +
q"
V,0.5664172123479888,"L2
f X2(1−p) b′
p"
V,0.5668849391955099,"Eιt−1[ℵt−1]
(70)"
V,0.5673526660430309,"Adding Inequality
√"
V,0.567820392890552,"¯θ+1
1−√1−p× (70) to (69)
740"
V,0.5682881197380729,"Eιt[
q"
V,0.568755846585594,"θ −X
2√"
V,0.569223573433115,"ℵt]
≤
EtA + (
√"
V,0.5696913002806361,"θ′ +
q"
V,0.5701590271281571,"L2
f X2(1−p) b′
√"
V,0.5706267539756782,"¯θ+1
1−√1−p)Eιt−1[
√"
V,0.5710944808231992,ℵt−1] + √1−p√
V,0.5715622076707203,"(¯θ+1)
1−√1−p
(
p"
V,0.5720299345182414,"Eιt−1[ut−1] −
p"
V,0.5724976613657624,"Eιt[ut]) +
√"
V,0.5729653882132835,"¯θ+1
1−√1−p q"
V,0.5734331150608045,"p(N−b)
b(N−1)σ2(71)"
V,0.5739008419083256,"With the choice
√"
V,0.5743685687558466,"θ′ =
√ θ−X2 2
−
q"
V,0.5748362956033677,"L2
f X2(1−p) b′
√"
V,0.5753040224508886,"¯θ+1
1−√1−p, we have:
741"
V,0.5757717492984097,"Eιt[
q"
V,0.5762394761459307,"θ −X
2√"
V,0.5767072029934518,"ℵt]
≤
EtA + (
√ θ−X2"
V,0.5771749298409729,"2
)Eιt−1[
√"
V,0.5776426566884939,"ℵt−1] +
√1−p√"
V,0.578110383536015,"(¯θ+1)
1−√1−p
(
p"
V,0.578578110383536,"Eιt−1[ut−1] −
p"
V,0.5790458372310571,"Eιt[ut]) +
√"
V,0.5795135640785781,"¯θ+1
1−√1−p q"
V,0.5799812909260992,"p(N−b)
b(N−1)σ2(72)"
V,0.5804490177736202,"Rearranging terms, we have:
742"
V,0.5809167446211413,"Eιt[
q"
V,0.5813844714686623,"θ −X
2√"
V,0.5818521983161834,"ℵt] −Eιt−1[
√ θ−X2 2
√ ℵt−1]"
V,0.5823199251637043,"≤
EtA + √1−p√"
V,0.5827876520112254,"(¯θ+1)
1−√1−p
(
p"
V,0.5832553788587465,"Eιt−1[ut−1] −
p"
V,0.5837231057062675,"Eιt[ut]) +
√"
V,0.5841908325537886,"¯θ+1
1−√1−p q"
V,0.5846585594013096,"p(N−b)
b(N−1)σ2
(73)"
V,0.5851262862488307,"Summing the inequality above over t = 1, 2 . . . , T, we have:
743"
V,0.5855940130963517,"EιT [
q"
V,0.5860617399438728,"θ −X
2√"
V,0.5865294667913938,"ℵT ] + EιT −1[
√ θ−X2"
V,0.5869971936389149,"2
PT −1
t=1
√ ℵt]"
V,0.587464920486436,"≤
A PT
t=1 Et + √1−p√"
V,0.587932647333957,"(¯θ+1)
1−√1−p
(
p"
V,0.5884003741814781,"Eι0[u0] −
p"
V,0.5888681010289991,EιT [uT ]) + T√
V,0.5893358278765201,"¯θ+1
1−√1−p q"
V,0.5898035547240411,"p(N−b)
b(N−1)σ2 +
√ θ−X2 2
√ ℵ0"
V,0.5902712815715622,"≤
A PT
t=1 Et + √1−p√"
V,0.5907390084190832,"(¯θ+1)
1−√1−p
q"
V,0.5912067352666043,"N−b
b(N−1)σ2 + T√"
V,0.5916744621141253,"¯θ+1
1−√1−p q"
V,0.5921421889616464,"p(N−b)
b(N−1)σ2 + Eιt[
√ θ−X2 2
√ ℵ0]"
V,0.5926099158091674,"≤
A PT
t=1 Et + √1−p√"
V,0.5930776426566885,"(¯θ+1)
1−√1−p
q"
V,0.5935453695042096,"N−b
b(N−1)σ2 + T√"
V,0.5940130963517306,"¯θ+1
1−√1−p q"
V,0.5944808231992517,"p(N−b)
b(N−1)σ2 +
√ θ−X2 2 q"
V,0.5949485500467727,"n
2 (V +
√ 2)2"
V,0.5954162768942938,"where step ①uses the fact that EιT [uT ] ≥0 and Eι0[u0] ≤
N−b
b(N−1)σ2; step ②uses ∀t, ∥V∥F ≤V,
744"
V,0.5958840037418148,"then, ∥Vi −I2∥2
F ≤(∥Vi∥F + ∥I2∥F)2 ≤(X +
√"
V,0.5963517305893359,"2)2 and Pn/2
i=1 ∥¯V0
i −I2∥2
F ≤
n
2 (V +
√"
V,0.5968194574368568,"2)2.
745"
V,0.5972871842843779,Define C = √1−p√
V,0.5977549111318989,"(¯θ+1)
1−√1−p
q"
V,0.59822263797942,"N−b
b(N−1)σ2 + T√"
V,0.598690364826941,"¯θ+1
1−√1−p q"
V,0.5991580916744621,"p(N−b)
b(N−1)σ2 and rearrange terms, we have:
746"
V,0.5996258185219832,Eιt[ θ−X2
PT,0.6000935453695042,"2
PT
t=1
√"
PT,0.6005612722170253,"ℵt] ≤A PT
t=1 Et + C +
√ θ−X2 2 q"
PT,0.6010289990645463,"n
2 (V +
√"
PT,0.6014967259120674,"2)2
(74)"
PT,0.6019644527595884,"Considering A PT
t=1 Et, we have:
747"
PT,0.6024321796071095,"A PT
t=1 Et
①=
A PT
t=1 φ(f(Xt) −f( ¯X)) −φ(f(Xt+1) −f( ¯X))"
PT,0.6028999064546305,"②=
A[φ(f(X1) −f( ¯X)) −φ(f(XT +1) −f( ¯X))]"
PT,0.6033676333021516,"③
≤
Aφ(f(X1) −f( ¯X))
(75)"
PT,0.6038353601496725,"where step ①uses the definition of Ei in (64); step ②uses a basic recursive reduction; step ③uses the
748"
PT,0.6043030869971936,"fact the desingularization function φ(·) is positive. Combining Inequality (74) and (75), we obtain :
749"
PT,0.6047708138447146,Eιt[ θ−X2
PT,0.6052385406922357,"2
PT
t=1
√"
PT,0.6057062675397568,"ℵt] ≤Aφ(f(X1) −f( ¯X)) + C +
√ θ−X2 2 q"
PT,0.6061739943872778,"n
2 (V +
√ 2)2"
PT,0.6066417212347989,"Using the inequality that ∥X+−X∥2
F
X2
≤∥X+−X∥2
F
∥X∥2
F
≤Pn/2
i=1 ∥¯Vi −I2∥2
F as shown in Part (b) in Lemma
750"
PT,0.6071094480823199,"2.5, we have:
751"
PT,0.607577174929841,Eιt[ θ−X2
"X
PT",0.608044901777362,"2X
PT
t=1 ∥Xt+1 −Xt∥F] ≤Aφ(f(X1) −f( ¯X)) + C +
√ θ−X2 2 q"
"X
PT",0.6085126286248831,"n
2 (V +
√ 2)2"
"X
PT",0.6089803554724041,"Since b = N, b′ =
√"
"X
PT",0.6094480823199252,"b and p =
b′
b+b′ , C = √1−p√"
"X
PT",0.6099158091674463,"(¯θ+1)
1−√1−p
q"
"X
PT",0.6103835360149673,"N−b
b(N−1)σ2 + T√"
"X
PT",0.6108512628624883,"¯θ+1
1−√1−p q"
"X
PT",0.6113189897100093,"p(N−b)
b(N−1)σ2 = 0,
we can get the expression for C:"
"X
PT",0.6117867165575304,"Eιt[Pt
j=1 ∥Xj+1 −Xj∥F] ≤C 752"
"X
PT",0.6122544434050514,"C ≜
2X
θ−X2 (Aφ(f(X1) −f( ¯X)) +
√ θ−X2 2 q"
"X
PT",0.6127221702525725,"n
2 (V +
√ 2)2)"
"X
PT",0.6131898971000935,"Considering that:
√"
"X
PT",0.6136576239476146,"θ′ =
√ θ−X2 2
−
q"
"X
PT",0.6141253507951356,"L2
f X2(1−p) b′
√"
"X
PT",0.6145930776426567,"¯θ+1
1−√1−p =
√ θ−X2 2
−
q"
"X
PT",0.6150608044901777,"L2
fX
2(1 + ¯θ)((1+N
1
2 )
1
2 +
753"
"X
PT",0.6155285313376988,"N
1
4 ) = O(N
1
4 ), we have: A = r"
"X
PT",0.6159962581852199,(2X2+γ np
"X
PT",0.6164639850327409,2 X+γ np
"X
PT",0.616931711880262,2 V2X)2
"X
PT",0.617399438727783,"2¯θ
+ nγ2ϕ2"
"X
PT",0.617867165575304,"4θ′
= O(
1
N1/4 ). Finally, we have
754"
"X
PT",0.618334892422825,C = O( φ(f(X1)−f( ¯X))
"X
PT",0.6188026192703461,"N1/4
)
755"
"X
PT",0.6192703461178671,"E.5
Proof of Theorem 4.9
756"
"X
PT",0.6197380729653882,"Proof. For simplicity, we use B instead of Bt. Initially, we prove the following important lemmas.
757"
"X
PT",0.6202057998129092,"Lemma E.6. (Riemannian gradient Lower Bound for the Iterates Gap) We define ϕ ≜(3X+VX)G+
758"
"X
PT",0.6206735266604303,"(1 + X
2 + V
2 + V
2X
2)Lf + (1 + V
2)θ. It holds that: Eξt+1[dist(0, ∇J G(I2; Xt+1, Bt+1))] ≤
759"
"X
PT",0.6211412535079514,"ϕ · Eξt[∥¯Vt −I2∥F].
760"
"X
PT",0.6216089803554724,"Proof. The proof process is exactly the same as in lemma E.2 and will not be repeated here.
761"
"X
PT",0.6220767072029935,"The following lemma is useful to outline the relation of ∥∇J f(Xt)∥F and ∥∇J G(I2; Xt, B)∥F.
762"
"X
PT",0.6225444340505145,"Lemma E.7. We have the following results:
763"
"X
PT",0.6230121608980356,"dist(0, ∇J f(Xt)) ≤γ · Eξt−1[dist(0, ∇J G(I2; Xt, B))] with γ ≜X
p"
"X
PT",0.6234798877455566,"C2n.
764"
"X
PT",0.6239476145930777,"Proof. We have the following inequalities:
765"
"X
PT",0.6244153414405987,"∥∇J f(Xt)∥2
F
①=
∥Gt −JXt(Gt)⊤XtJ∥2
F
②=
∥Gt(Xt)⊤JXtJ −JXt(Gt)⊤JJXtJ∥2
F
③
≤
∥Gt(Xt)⊤−JXt(Gt)⊤J∥2
F∥JXtJ∥2
F
④
≤
X
2∥W∥2
F, with W ≜Gt(Xt)⊤−JXt(Gt)⊤J"
"X
PT",0.6248830682881198,"⑤
≤
X
2C2
n · Eξt−1[∥U⊤
B [Gt(Xt)⊤−JXt(Gt)⊤J]UB∥2
F]"
"X
PT",0.6253507951356407,"⑥=
X
2C2
n · Eξt−1[∥∇J G(I2; Xt, B)∥2
F]"
"X
PT",0.6258185219831618,"where step ①uses the definition of ∇J f(Xt); step ②uses JJ = I and X⊤JX = J ⇒X⊤JXJ =
766"
"X
PT",0.6262862488306828,"JJ = I; step ③uses the norm inequality and ; step ④uses the definition of W ≜Gt(Xt)⊤−
767"
"X
PT",0.6267539756782039,"JXt(Gt)⊤J and ∀t, ∥Xt∥F ≤X ; step ⑤uses Lemma (A.1) with k = 2; step ⑥uses the definition
768"
"X
PT",0.627221702525725,"of ∇J G(I2; Xt, B). Taking the square root of both sides, we finish the proof of this lemma.
769"
"X
PT",0.627689429373246,"Finally, we obtain our main convergence results. First of all, since f ◦(X) ≜f(X) + IJ (X) is a KL
770"
"X
PT",0.6281571562207671,"function, we have from Proposition 4.8 that:
771"
"X
PT",0.6286248830682881,"1
φ′(f ◦(X′)−f ◦(X)) ≤dist(0, ∇f ◦(X′))
①
≤∥∇J f(X′)∥F,
(76)"
"X
PT",0.6290926099158092,"where step ①uses Lemma E.5. Here, φ(·) is some certain concave desingularization function. Since
φ(·) is concave, we have:"
"X
PT",0.6295603367633302,"∀∆∈R, ∆+ ∈R, φ(∆+) + (∆−∆+)φ′(∆) ≤φ(∆)."
"X
PT",0.6300280636108513,"Applying the inequality above with ∆= f(Xt) −f( ¯X) and ∆+ = f(Xt+1) −f( ¯X), we have:
772"
"X
PT",0.6304957904583723,(f(Xt) −f(Xt+1))φ′(f(Xt) −f( ¯X))
"X
PT",0.6309635173058934,"≤
φ(f(Xt) −f( ¯X)) −φ(f(Xt+1) −f( ¯X)) ≜Et.
(77)"
"X
PT",0.6314312441534145,"We derive the following inequalities:
773"
"X
PT",0.6318989710009355,Eξt[ θ
"X
PT",0.6323666978484564,"2∥¯Vt −I2∥2
F]
①
≤
Eξt[f(Xt) −f(Xt+1)]"
"X
PT",0.6328344246959775,"②
≤
Eξt[
Et"
"X
PT",0.6333021515434986,φ′(f(Xt)−f( ¯X))]
"X
PT",0.6337698783910196,"③
≤
Eξt[Et∥∇J f(Xt)∥F]"
"X
PT",0.6342376052385407,"④
≤
Eξt[Etγ∥∇J G(I2; Xt, B)∥F]"
"X
PT",0.6347053320860617,"⑤
≤
Eξt−1[Etγϕ| ¯Vt−1 −I2∥F]"
"X
PT",0.6351730589335828,"⑥
≤
Eξt−1[ θ′"
"X
PT",0.6356407857811038,"2 ∥¯Vt−1 −I2∥2
F + (Etγϕ)2"
"X
PT",0.6361085126286249,"2θ′
], ∀θ′ > 0,"
"X
PT",0.6365762394761459,"where step ①uses the sufficient descent condition as shown in Theorem 4.6; step ②uses Inequality
774"
"X
PT",0.637043966323667,"(77); step ③uses Inequality (76) with X′ = Xt and X = ¯X; step ④uses Lemma E.7; step ⑤uses
775"
"X
PT",0.637511693171188,"Lemma E.6; step ⑥applies the inequality that ∀θ′ > 0, a, b, ab ≤θ′a2"
"X
PT",0.6379794200187091,"2
+ b2"
"X
PT",0.6384471468662302,"2θ′ with a = ∥¯Vt−1 −I2∥F
776"
"X
PT",0.6389148737137512,"and b = Etγϕ.
777"
"X
PT",0.6393826005612722,"Multiplying both sides by 2 and taking the square root of both sides, we have:
778 √"
"X
PT",0.6398503274087932,"θEξt[∥¯Vt −I2∥F]
≤
q"
"X
PT",0.6403180542563143,(Etγϕ)2
"X
PT",0.6407857811038353,"θ′
+ θ′Eξt−1[∥¯Vt−1 −I2∥2
F], ∀θ′ > 0 ①
≤
√"
"X
PT",0.6412535079513564,"θ′Eξt−1[∥¯Vt−1 −I2∥F] + Etγϕ
√"
"X
PT",0.6417212347988774,"θ′ , ∀θ′ > 0,"
"X
PT",0.6421889616463985,"where step ①uses the inequality that
√"
"X
PT",0.6426566884939195,"a + b ≤√a +
√"
"X
PT",0.6431244153414406,"b for all a ≥0 and b ≥0. Summing the
779"
"X
PT",0.6435921421889617,"inequality above over i = 1, 2 . . . , t, we have:
780 √"
"X
PT",0.6440598690364827,"θEξt[∥¯Vt −I2∥F] −
√"
"X
PT",0.6445275958840038,"θ′Eξ0[∥¯V0 −I2∥F] + Pt−1
i=1(
√ θ −
√"
"X
PT",0.6449953227315248,θ′)Eξi[∥¯Vi −I2∥F]
"X
PT",0.6454630495790459,"≤
γϕ
√"
"X
PT",0.6459307764265669,"θ′
Pt
i=1 Ei"
"X
PT",0.646398503274088,"①=
γϕ
√"
"X
PT",0.6468662301216089,"θ′
Pt
i=1 φ(f(Xi) −f( ¯X)) −φ(f(Xi+1) −f( ¯X))"
"X
PT",0.64733395696913,"②=
γϕ
√"
"X
PT",0.647801683816651,θ′ [φ(f(X1) −f( ¯X)) −φ(f(Xt+1) −f( ¯X))]
"X
PT",0.6482694106641721,"③
≤
γϕ
√"
"X
PT",0.6487371375116932,"θ′ φ(f(X1) −f( ¯X)),"
"X
PT",0.6492048643592142,"where step ①uses the definition of Ei in (77); step ②uses a basic recursive reduction; step ③uses
781"
"X
PT",0.6496725912067353,the fact the desingularization function φ(·) is positive. With the choice θ′ = θ
"X
PT",0.6501403180542563,"4, we have:
782 √"
"X
PT",0.6506080449017774,"θEξt[∥¯Vt −I2∥F] +
√"
"X
PT",0.6510757717492984,"θ
2
Pt−1
i=1 Eξi[∥¯Vi −I2∥F]"
"X
PT",0.6515434985968195,"≤
2γϕ
√"
"X
PT",0.6520112254443405,"θ φ(f(X1) −f( ¯X)) +
√"
"X
PT",0.6524789522918616,"θ
2 Eξ0[∥¯V0 −I2∥F]
(78)"
"X
PT",0.6529466791393826,"①
≤
2γϕ
√"
"X
PT",0.6534144059869037,"θ φ(f(X1) −f( ¯X)) +
√"
"X
PT",0.6538821328344246,"θ
2 (V +
√"
"X
PT",0.6543498596819457,"2),
(79)"
"X
PT",0.6548175865294668,"where step ①uses ∀t, ∥V∥F ≤V,then, ∥V −I2∥F ≤∥V∥F + ∥I∥F ≤V +
√"
"X
PT",0.6552853133769878,"2. Finally, we obtain
783"
"X
PT",0.6557530402245089,"from Inequality (79):
784"
"X
PT",0.6562207670720299,"1
2
Pt
i=1 Eξi[∥¯Vi −I2∥F] ≤2γϕ"
"X
PT",0.656688493919551,θ φ(f(X1) −f( ¯X)) + 1
"X
PT",0.657156220767072,"2(V +
√ 2)"
"X
PT",0.6576239476145931,"①⇒
1
2
Pt
i=1 Eξi[∥Xi+1 −Xi∥F] ≤( 2Xγϕ"
"X
PT",0.6580916744621141,"θ
φ(f(X1) −f( ¯X)) + X"
"X
PT",0.6585594013096352,"2 (V +
√ 2))"
"X
PT",0.6590271281571563,where step ①uses the inequality that ∥Xi+1−Xi∥F
"X
PT",0.6594948550046773,"X
≤∥¯Vi −I2∥F as shown in Part (b) in Lemma 2.1.
Finally, we can get the expression for C:"
"X
PT",0.6599625818521984,C ≜4Xγϕ
"X
PT",0.6604303086997194,"θ
φ(F(X1) −F( ¯X)) + X(V +
√"
"X
PT",0.6608980355472404,2) = nO(φ(f(X1) −f( ¯X))) 785
"X
PT",0.6613657623947614,"F
Additional Experiment Details and Results
786"
"X
PT",0.6618334892422825,"F.1
Additional Details for Hyperbolic Structural Probe Problem
787"
"X
PT",0.6623012160898035,"To begin with, we give the definition of the Ultrahyperbolic manifold Up,q
α , which will be used in
788"
"X
PT",0.6627689429373246,"Ultra-hyperbolic geodesic distance dα(x, y) and Diffeomorphism φ(·).
789"
"X
PT",0.6632366697848456,"▶Ultrahyperbolic manifold. Vectors in an ultrahyperbolic manifold is defined as Up,q
α
= {x =
790"
"X
PT",0.6637043966323667,"(x1, x2, · · · , xp+q)⊤∈Rp,q : ∥x∥2
q = −α2}[48], where α is a non-negative real number denoting
791"
"X
PT",0.6641721234798877,"the radius of curvature. ∥x∥2
q = ⟨x, x⟩q , ∀x, y ∈Rp,q, ⟨x, y⟩q = Pp
i=1 xiyi −Pp+q
j=p+1 xjyj is
792"
"X
PT",0.6646398503274088,"a norm of the induced scalar product. The hyperbolic and spherical manifolds can be defined as
793"
"X
PT",0.6651075771749299,":Hα = Up,1
α , Sα = U0,q
α .
794"
"X
PT",0.6655753040224509,"▶Ultra-hyperbolic geodesic distance. The ultra-hyperbolic geodesic distance [27][28] dγ(·, ·) is
795"
"X
PT",0.666043030869972,"formulated: ∀x ∈Up,q
α , y ∈Up,q
α
and α > 0, dα(x, y) = { α cosh−1(| ⟨x,y⟩q"
"X
PT",0.666510757717493,"α2
|)
if | ⟨x,y⟩q"
"X
PT",0.6669784845650141,"α2
| ≥1
α cos−1(| ⟨x,y⟩q"
"X
PT",0.6674462114125351,"α2
|)
otherwise.
.
796"
"X
PT",0.6679139382600561,"▶Diffeomorphism. [Theorem 1 Diffeomorphism of [49]]: Any vector x ∈Rp × Rq
∗can be mapped
797"
"X
PT",0.6683816651075771,"into Up,q
α by a double projection φ = ϕ−1◦ϕ, with ψ(x) = (
s
α t"
"X
PT",0.6688493919550982,"∥t∥
),
ψ−1(z) = (
v
√"
"X
PT",0.6693171188026192,α2+∥v∥2
"X
PT",0.6697848456501403,"α
u ),
798"
"X
PT",0.6702525724976613,"where x = ( s
t ) ∈Up,q
α
with s ∈Rp and t ∈Rq
∗· z = ( v
u ) ∈Rp × Sq
α with v ∈Rp and u ∈Sq
α.
799"
"X
PT",0.6707202993451824,"F.2
Additional application: Ultra-hyperbolic Knowledge Graph Embedding
800"
"X
PT",0.6711880261927035,"The J orthogonal matrix can be used as an isometric linear operator in the Ultrahyperbolic manifold,
801"
"X
PT",0.6716557530402245,"[48] et al. extended the knowledge graph model from hyperbolic space to Ultra-hyperbolic space
802"
"X
PT",0.6721234798877456,"(named as UltraE) by this property. The UltraE model is formulated as follows:
803"
"X
PT",0.6725912067352666,"min
R,E,bL(R, E, b) ≜−1 N
P"
"X
PT",0.6730589335827877,"(h,r,t)∈∆
(log s(h, r, t) +
P"
"X
PT",0.6735266604303087,"(h′,r′,r′)∈∆′
(h,r,t)
log(1 −s(h′, r′, t′)))"
"X
PT",0.6739943872778298,"s.t.

s(h, r, t) = σ(−d2
α(RrEh, Et) + bh + bt + δ)
R⊤
r JRr = J"
"X
PT",0.6744621141253508,"where E ∈Rne×n with Eh = E(h, :) ∈Up,q
α , b ∈Rnr with bh = b(r) ∈R, R ∈Rnr×n×n with
804"
"X
PT",0.6749298409728719,"Rr = R(r, :, :) ∈Rn×n and J = [ Ip
0
0 −Iq ]; ∆∈NN×3 is the set of positive triplets, ∆′
(h,r,t) ∈
805"
"X
PT",0.6753975678203928,"NN×k×3 denotes the set of negative triples constructed by corrupting (h, r, t); δ is a global margin
806"
"X
PT",0.6758652946679139,"hyper-parameter, σ(·) is the sigmoid function, ne represents the number of entities and nr represents
807"
"X
PT",0.676333021515435,"the number of relations; dα(·) stands for the Ultra-hyperbolic geodesic distance (refer to F.1).
808"
"X
PT",0.676800748362956,"▶Experiment Details. We selected a batch of FB15K and WN18RR respectively as the data set for
809"
"X
PT",0.6772684752104771,"the Ultra-hyperbolic Knowledge Graph Embedding problem, (training set size, test set size, number
810"
"X
PT",0.6777362020579981,"of entities, number of relations) are (719,308,135,22) and (545,233,208,5) respectively. n = 36,
811"
"X
PT",0.6782039289055192,"p = 18, δ = 5, α = 1 and k = 50. In order to highlight the difference between J orthogonal
812"
"X
PT",0.6786716557530402,"optimization, in the UltraE model, all entities and biases of the optimization algorithm are optimized
813"
"X
PT",0.6791393826005613,"using ADMM by Pytorch, lr = 5e −4. We use the Adagrad optimizer in Pytorch to optimize the
814"
"X
PT",0.6796071094480823,"J-orthogonality constraint variable in the CS model.
815"
"X
PT",0.6800748362956034,"F.3
Experiment result
816"
"X
PT",0.6805425631431244,"▶Hyperbolic Eigenvalue Problem. Table 2 and Figure 3, 4, 5 are supplementary experiments for
817"
"X
PT",0.6810102899906455,"HEVP. Several conclusions can be drawn. (i) GS-JOBCD often greatly improves upon UMCM,
818"
"X
PT",0.6814780168381666,"ADMM and CSDM. This is because our methods find stronger stationary points than them. (ii)
819"
"X
PT",0.6819457436856876,"J-JOBCD is a parallel version of GS-JOBCD and thus exhibits significantly faster convergence. (iii)
820"
"X
PT",0.6824134705332086,"The proposed methods generally give the best performance.
821"
"X
PT",0.6828811973807296,"▶Hyperbolic Structural Probe Problem. Table 3 and Figure 6, 7 are supplementary experiments
822"
"X
PT",0.6833489242282507,"for HSPP. Several conclusions can be drawn. (i) J-JOBCD often greatly improves upon UMCM,
823"
"X
PT",0.6838166510757717,"ADMM and CSDM (ii) VR-J-JOBCD is a reduced variance version of J-JOBCD and thus exhibits
824"
"X
PT",0.6842843779232928,"significantly faster convergence for problems with large samples. (iii) The proposed methods generally
825"
"X
PT",0.6847521047708138,"give the best performance.
826"
"X
PT",0.6852198316183349,"▶Ultra-hyperbolic Knowledge Graph Embedding Problem. Figure 8, 9, 10 and 11 are supplemen-
827"
"X
PT",0.6856875584658559,"tary experiments for UltraE. Several conclusions can be drawn. (i) In terms of Epoch performance,
828"
"X
PT",0.686155285313377,"J-JOBCD and VR-J-JOBCD often greatly improves upon CSDM, thus they show better MRR and
829"
"X
PT",0.686623012160898,"hits results. (ii) In models with limited sample sizes, the computational efficiency of VR-J-JOBCD
830"
"X
PT",0.6870907390084191,"is inferior to that of J-JOBCD. This discrepancy arises because each iteration in VR-J-JOBCD
831"
"X
PT",0.6875584658559402,"necessitates two instances of backpropagation, thus consuming substantial computational resources.
832"
"X
PT",0.6880261927034612,"(iii) The proposed methods generally give the best performance.
833"
"X
PT",0.6884939195509823,"F.3.1
Hyperbolic Eigenvalue Problem
834"
"X
PT",0.6889616463985033,"Table 2: The convergence curve of the compared methods for solving HEVP. (+) indicates that after
the convergence of the CSDM, UMCM and ADMM, utilizing the GS-JOBCD for optimization
markedly enhances the objective value. The 1st, 2nd , and 3rd best results are colored with red, green
and blue, respectively. (n, p) represents the dimension and p-value of the J orthogonal matrix (square
matrix). The value in () stands for Pn
ij |X⊤JX −J|ij."
"X
PT",0.6894293732460243,"dataname
(m-n-p)
UMCM
ADMM
CSDM
GS-JOBCD
J-JOBCD
UMCM+GS-JOBCD
ADMM+GS-JOBCD
CSDM+GS-JOBCD
time limit=30s
cifar
(1000-100-50)
-1.05e+04(3.0e-09)
-1.05e+04(3.0e-09)
-5.28e+04(4.8e-09)
-7.76e+04(1.6e-08)
-1.19e+05(8.1e-08)
-7.96e+04(1.1e-08)(+)
-5.86e+04(8.4e-09)(+)
-8.50e+04(1.2e-08)(+)
CnnCaltech
(2000-1000-500)
-5.89e+02(2.9e-08)
-5.89e+02(3.1e-10)
-7.86e+02(3.8e-10)
-7.68e+02(5.2e-10)
-3.90e+03(2.3e-08)
-6.71e+02(2.9e-08)(+)
-6.73e+02(3.6e-10)(+)
-8.49e+02(4.3e-10)(+)
gisette
(3000-1000-500)
-3.22e+06(3.1e-10)
-3.22e+06(3.1e-10)
-5.16e+06(3.9e-10)
-7.13e+06(5.9e-10)
-1.15e+07(1.5e-08)
-4.63e+06(3.7e-10)(+)
-4.74e+06(3.7e-10)(+)
-6.31e+06(4.6e-10)(+)
mnist
(1000-780-390)
-8.65e+04(4.1e-10)
-8.65e+04(4.1e-10)
-1.63e+05(4.9e-10)
-2.23e+05(6.6e-10)
-6.99e+05(2.1e-08)
-1.59e+05(4.7e-10)(+)
-1.48e+05(4.7e-10)(+)
-2.04e+05(5.7e-10)(+)
randn10
(10-10-5)
1.29e+02(9.7e-02)
1.29e+02(9.7e-02)
3.03e+02(2.3e-01)
-3.96e+01(9.7e-02)
-2.98e+02(9.7e-02)
-7.05e+01(9.7e-02)(+)
-1.75e+01(9.7e-02)(+)
2.29e+02(2.3e-01)(+)
randn100
(100-100-50)
-1.03e+04(3.0e-09)
-1.03e+04(2.5e-07)
-1.98e+04(5.1e-09)
-1.49e+04(2.7e-08)
-3.44e+04(1.3e-07)
-1.33e+04(1.4e-08)(+)
-1.31e+04(2.5e-07)(+)
-2.20e+04(1.8e-08)(+)
randn1000
(1000-1000-500)
-1.16e+06(3.1e-10)
-1.16e+06(3.1e-10)
-1.47e+06(3.9e-10)
-1.20e+06(4.4e-10)
-4.83e+06(7.3e-08)
-1.18e+06(3.5e-10)(+)
-1.18e+06(3.5e-10)(+)
-1.49e+06(4.7e-10)(+)
sector
(500-1000-500)
-3.61e+03(3.1e-10)
-3.61e+03(3.1e-10)
-5.35e+03(3.9e-10)
-6.68e+03(5.8e-10)
-1.07e+04(1.2e-08)
-4.73e+03(3.7e-10)(+)
-4.85e+03(3.6e-10)(+)
-6.47e+03(4.6e-10)(+)
TDT2
(1000-1000-500)
-4.25e+06(3.1e-10)
-4.25e+06(3.1e-10)
-6.37e+06(4.0e-10)
-8.20e+06(6.0e-10)
-1.32e+07(1.2e-08)
-5.67e+06(3.7e-10)(+)
-5.93e+06(3.7e-10)(+)
-7.85e+06(4.8e-10)(+)
w1a
(2470-290-145)
-3.02e+04(1.1e-04)
-3.02e+04(1.1e-04)
-5.42e+04(4.4e-04)
-5.74e+04(1.1e-04)
-6.73e+05(1.1e-04)
-4.76e+04(1.1e-04)(+)
-4.57e+04(1.1e-04)(+)
-6.32e+04(4.4e-04)(+)
cifar
(1000-100-70)
-7.32e+03(1.9e-09)
-7.32e+03(1.9e-09)
-3.29e+04(3.2e-09)
-6.01e+04(1.5e-08)
-1.12e+05(7.4e-08)
-4.84e+04(1.0e-08)(+)
-4.30e+04(7.6e-09)(+)
-7.52e+04(1.3e-08)(+)
CnnCaltech
(2000-1000-700)
-4.33e+02(2.1e-08)
-4.33e+02(2.2e-10)
-5.43e+02(2.5e-10)
-5.69e+02(3.6e-10)
-2.88e+03(1.6e-08)
-4.86e+02(2.1e-08)(+)
-4.85e+02(2.6e-10)(+)
-5.98e+02(3.0e-10)(+)
gisette
(1000,700)
-2.45e+06(2.2e-10)
-2.45e+06(2.2e-10)
-3.59e+06(2.5e-10)
-5.02e+06(4.2e-10)
-9.17e+06(1.0e-08)
-3.15e+06(2.5e-10)(+)
-3.25e+06(2.5e-10)(+)
-4.25e+06(2.7e-10)(+)
mnist
(1000-780-500)
-7.05e+04(3.1e-10)
-7.05e+04(3.1e-10)
-1.21e+05(3.6e-10)
-1.81e+05(5.3e-10)
-6.28e+05(1.9e-08)
-1.14e+05(3.5e-10)(+)
-1.21e+05(3.6e-10)(+)
-1.59e+05(4.3e-10)(+)
randn10
(10-10-7)
1.61e+02(5.6e-02)
1.61e+02(5.6e-02)
3.46e+02(1.8e-01)
-4.14e+11(2.1e+02)
-1.64e+00(5.6e-02)
3.69e+01(5.6e-02)(+)
-8.63e+02(5.6e-02)(+)
2.96e+02(1.8e-01)(+)
randn100
(100,70)
-8.00e+03(1.9e-09)
-8.00e+03(1.8e-07)
-1.41e+04(2.9e-09)
-1.10e+04(1.9e-08)
-2.37e+04(8.5e-08)
-9.68e+03(9.3e-09)(+)
-9.75e+03(1.8e-07)(+)
-1.64e+04(1.3e-08)(+)
randn1000
(1000-1000-700)
-8.88e+05(2.2e-10)
-8.88e+05(2.2e-10)
-1.07e+06(2.7e-10)
-9.15e+05(3.4e-10)
-3.24e+06(4.3e-08)
-9.04e+05(2.6e-10)(+)
-9.05e+05(2.5e-10)(+)
-1.09e+06(3.2e-10)(+)
sector
(500-1000-700)
-2.66e+03(2.2e-10)
-2.66e+03(2.2e-10)
-3.63e+03(2.5e-10)
-4.57e+03(3.8e-10)
-8.93e+03(9.1e-09)
-3.16e+03(2.4e-10)(+)
-3.26e+03(2.4e-10)(+)
-4.12e+03(2.8e-10)(+)
TDT2
(1000-1000-700)
-3.15e+06(2.2e-10)
-3.15e+06(2.2e-10)
-4.33e+06(2.5e-10)
-5.32e+06(3.4e-10)
-1.23e+07(9.1e-09)
-3.80e+06(2.5e-10)(+)
-3.75e+06(2.4e-10)(+)
-4.77e+06(2.8e-10)(+)
w1a
(2470-290-200)
-2.77e+04(8.0e-10)
-2.77e+04(8.0e-10)
-3.93e+04(1.1e-09)
-5.19e+04(4.1e-09)
-3.97e+05(5.6e-08)
-4.05e+04(1.8e-09)(+)
-3.73e+04(1.7e-09)(+)
-5.45e+04(2.9e-09)(+)
cifar
(1000-100-90)
-6.42e+03(1.2e-09)
-6.42e+03(1.2e-09)
-1.59e+04(1.2e-09)
-4.51e+04(1.4e-08)
-5.05e+04(5.6e-08)
-2.64e+04(6.3e-09)(+)
-3.35e+04(7.0e-09)(+)
-3.89e+04(6.7e-09)(+)
CnnCaltech
(2000-1000-900)
-3.10e+02(1.1e-08)
-3.10e+02(1.2e-10)
-3.41e+02(1.3e-10)
-3.64e+02(1.7e-10)
-1.65e+03(8.0e-09)
-3.29e+02(1.1e-08)(+)
-3.32e+02(1.3e-10)(+)
-3.61e+02(1.4e-10)(+)
gisette
(3000-1000-900)
-1.74e+06(1.2e-10)
-1.74e+06(1.2e-10)
-2.05e+06(1.2e-10)
-2.57e+06(1.8e-10)
-6.46e+06(8.0e-09)
-2.00e+06(1.3e-10)(+)
-1.99e+06(1.2e-10)(+)
-2.33e+06(1.4e-10)(+)
mnist
(1000-780-650)
-5.19e+04(1.9e-10)
-5.19e+04(1.9e-10)
-6.12e+04(2.2e-10)
-1.02e+05(2.9e-10)
-4.03e+05(1.2e-08)
-6.75e+04(2.1e-10)(+)
-6.58e+04(2.1e-10)(+)
-7.54e+04(2.4e-10)(+)
randn10
(10-10-9)
5.33e+02(1.7e-01)
5.33e+02(1.7e-01)
4.28e+02(1.3e-01)
-1.03e+12(5.5e+02)
3.64e+02(1.7e-01)
2.21e+02(1.7e-01)(+)
-3.46e+02(1.7e-01)(+)
1.54e+02(1.3e-01)(+)
randn100
(100-100-90)
-6.14e+03(1.1e-07)
-6.14e+03(1.2e-09)
-8.14e+03(1.4e-09)
-8.31e+03(1.5e-08)
-1.31e+04(5.8e-08)
-7.74e+03(1.2e-07)(+)
-7.77e+03(1.3e-08)(+)
-9.69e+03(1.1e-08)(+)
randn1000
(1000-1000-900)
-6.33e+05(1.2e-10)
-6.33e+05(1.2e-10)
-6.84e+05(1.3e-10)
-6.46e+05(1.9e-10)
-1.87e+06(1.8e-08)
-6.39e+05(1.3e-10)(+)
-6.39e+05(1.3e-10)(+)
-6.90e+05(1.5e-10)(+)
sector
(500-1000-900)
-1.92e+03(1.2e-10)
-1.92e+03(1.2e-10)
-2.18e+03(1.2e-10)
-2.50e+03(1.6e-10)
-5.84e+03(6.5e-09)
-2.12e+03(1.2e-10)(+)
-2.13e+03(1.2e-10)(+)
-2.34e+03(1.4e-10)(+)
TDT2
(1000-1000-900)
-2.26e+06(1.2e-10)
-2.26e+06(1.2e-10)
-2.58e+06(1.2e-10)
-2.90e+06(1.6e-10)
-7.40e+06(6.6e-09)
-2.53e+06(1.2e-10)(+)
-2.51e+06(1.2e-10)(+)
-2.83e+06(1.3e-10)(+)
w1a
(2470-290-250)
-2.03e+04(5.4e-10)
-2.03e+04(5.4e-10)
-2.41e+04(5.9e-10)
-3.74e+04(2.9e-09)
-2.59e+05(3.3e-08)
-2.82e+04(1.2e-09)(+)
-3.17e+04(1.4e-09)(+)
-3.78e+04(1.5e-09)(+)
time limit=60s
cifar
(1000-100-50)
-1.05e+04(3.0e-09)
-1.05e+04(3.0e-09)
-5.28e+04(4.7e-09)
-9.03e+04(2.2e-08)
-1.14e+05(1.1e-07)
-8.07e+04(1.5e-08)(+)
-6.87e+04(1.3e-08)(+)
-1.01e+05(1.6e-08)(+)
CnnCaltech
(2000-1000-500)
-5.89e+02(2.9e-08)
-5.89e+02(3.1e-10)
-9.79e+02(4.6e-10)
-9.58e+02(9.9e-10)
-6.68e+03(4.7e-08)
-7.13e+02(2.9e-08)(+)
-7.23e+02(4.3e-10)(+)
-1.05e+03(5.9e-10)(+)
gisette
(3000-1000-500)
-3.22e+06(3.1e-10)
-3.22e+06(3.1e-10)
-6.54e+06(4.3e-10)
-8.84e+06(9.7e-10)
-1.29e+07(2.1e-08)
-5.55e+06(4.1e-10)(+)
-5.67e+06(4.2e-10)(+)
-8.02e+06(6.4e-10)(+)
mnist
(1000-780-390)
-8.65e+04(4.1e-10)
-8.65e+04(4.1e-10)
-2.28e+05(5.3e-10)
-2.75e+05(9.5e-10)
-9.32e+05(3.2e-08)
-1.80e+05(5.4e-10)(+)
-1.88e+05(5.4e-10)(+)
-2.83e+05(6.8e-10)(+)
randn10
(10-10-5)
1.29e+02(9.7e-02)
1.29e+02(9.7e-02)
2.43e+02(2.2e-01)
-3.96e+01(9.7e-02)
-7.07e+01(9.7e-02)
-2.27e+05(9.7e-02)(+)
-3.46e+02(9.7e-02)(+)
-2.94e+05(2.2e-01)(+)
randn100
(100-100-50)
-1.03e+04(3.0e-09)
-1.03e+04(2.5e-07)
-1.98e+04(5.4e-09)
-1.81e+04(4.3e-08)
-3.88e+04(1.9e-07)
-1.41e+04(1.9e-08)(+)
-1.44e+04(2.5e-07)(+)
-2.41e+04(2.9e-08)(+)
randn1000
(1000-1000-500)
-1.16e+06(3.1e-10)
-1.16e+06(3.1e-10)
-1.79e+06(4.7e-10)
-1.21e+06(6.0e-10)
-7.79e+06(1.5e-07)
-1.19e+06(3.9e-10)(+)
-1.19e+06(4.0e-10)(+)
-1.81e+06(5.7e-10)(+)
sector
(500-1000-500)
-3.61e+03(3.1e-10)
-3.61e+03(3.1e-10)
-6.63e+03(4.5e-10)
-8.22e+03(9.1e-10)
-1.11e+04(1.7e-08)
-5.53e+03(4.2e-10)(+)
-5.63e+03(4.3e-10)(+)
-7.83e+03(5.8e-10)(+)
TDT2
(1000-1000-500)
-4.25e+06(3.1e-10)
-4.25e+06(3.1e-10)
-8.31e+06(4.4e-10)
-9.87e+06(8.9e-10)
-1.43e+07(1.7e-08)
-6.51e+06(4.1e-10)(+)
-6.80e+06(4.2e-10)(+)
-9.33e+06(5.3e-10)(+)
w1a
(2470-290-145)
-3.02e+04(1.1e-04)
-3.02e+04(1.1e-04)
-5.63e+04(1.0e-04)
-7.13e+04(1.1e-04)
-2.07e+06(1.1e-04)
-5.44e+04(1.1e-04)(+)
-5.42e+04(1.1e-04)(+)
-6.91e+04(1.0e-04)(+)
cifar
(1000-100-70)
-7.32e+03(1.9e-09)
-7.32e+03(1.9e-09)
-3.29e+04(3.3e-09)
-6.94e+04(1.9e-08)
-9.31e+04(9.6e-08)
-5.69e+04(1.4e-08)(+)
-5.87e+04(1.4e-08)(+)
-8.58e+04(1.8e-08)(+)
CnnCaltech
(2000-1000-700)
-4.33e+02(2.1e-08)
-4.33e+02(2.2e-10)
-6.99e+02(3.2e-10)
-6.74e+02(5.7e-10)
-4.74e+03(3.1e-08)
-5.23e+02(2.1e-08)(+)
-5.21e+02(2.7e-10)(+)
-7.62e+02(4.1e-10)(+)
gisette
(1000,700)
-2.45e+06(2.2e-10)
-2.45e+06(2.2e-10)
-4.99e+06(2.8e-10)
-6.15e+06(6.0e-10)
-1.15e+07(1.6e-08)
-3.71e+06(2.6e-10)(+)
-3.86e+06(2.7e-10)(+)
-5.81e+06(3.7e-10)(+)
mnist
(1000-780-500)
-7.05e+04(3.1e-10)
-7.05e+04(3.1e-10)
-1.62e+05(4.3e-10)
-2.19e+05(6.8e-10)
-8.50e+05(2.6e-08)
-1.34e+05(4.0e-10)(+)
-1.41e+05(3.9e-10)(+)
-2.00e+05(5.1e-10)(+)
randn10
(10-10-7)
1.61e+02(5.6e-02)
1.61e+02(5.6e-02)
3.81e+02(1.6e-01)
-3.45e+16(9.0e+06)
4.37e-01(5.6e-02)
-2.19e+04(5.6e-02)(+)
-2.03e+04(5.6e-02)(+)
3.39e+02(1.6e-01)(+)
randn100
(100,70)
-8.00e+03(1.9e-09)
-8.00e+03(1.8e-07)
-1.41e+04(2.9e-09)
-1.37e+04(3.2e-08)
-2.69e+04(1.4e-07)
-1.04e+04(1.3e-08)(+)
-1.08e+04(1.8e-07)(+)
-1.83e+04(2.7e-08)(+)
randn1000
(1000-1000-700)
-8.88e+05(2.2e-10)
-8.88e+05(2.2e-10)
-1.31e+06(3.0e-10)
-9.25e+05(4.5e-10)
-5.49e+06(9.7e-08)
-9.09e+05(2.8e-10)(+)
-9.09e+05(2.7e-10)(+)
-1.33e+06(3.8e-10)(+)
sector
(500-1000-700)
-2.66e+03(2.2e-10)
-2.66e+03(2.2e-10)
-5.05e+03(3.0e-10)
-5.74e+03(5.6e-10)
-1.13e+04(1.4e-08)
-3.74e+03(2.7e-10)(+)
-3.74e+03(2.7e-10)(+)
-5.65e+03(4.0e-10)(+)
TDT2
(1000-1000-700)
-3.15e+06(2.2e-10)
-3.15e+06(2.2e-10)
-6.13e+06(3.1e-10)
-6.94e+06(5.7e-10)
-1.45e+07(1.4e-08)
-4.55e+06(2.7e-10)(+)
-4.54e+06(2.8e-10)(+)
-6.99e+06(4.1e-10)(+)
w1a
(2470-290-200)
-2.77e+04(8.0e-10)
-2.77e+04(8.0e-10)
-4.00e+04(1.1e-09)
-7.13e+04(1.2e-08)
-3.42e+06(5.3e-07)
-4.71e+04(3.6e-09)(+)
-5.28e+04(4.3e-09)(+)
-6.55e+04(5.1e-09)(+)
cifar
(1000-100-90)
-6.42e+03(1.2e-09)
-6.42e+03(1.2e-09)
-1.60e+04(1.5e-09)
-4.91e+04(2.0e-08)
-4.97e+04(9.3e-08)
-4.12e+04(1.2e-08)(+)
-4.83e+04(1.6e-08)(+)
-4.87e+04(1.7e-08)(+)
CnnCaltech
(2000-1000-900)
-3.10e+02(1.1e-08)
-3.10e+02(1.2e-10)
-3.15e+02(1.2e-10)
-4.25e+02(3.1e-10)
-2.37e+03(1.4e-08)
-3.44e+02(1.1e-08)(+)
-3.41e+02(1.4e-10)(+)
-3.45e+02(1.4e-10)(+)
gisette
(3000-1000-900)
-1.74e+06(1.2e-10)
-1.74e+06(1.2e-10)
-2.59e+06(1.4e-10)
-3.09e+06(2.6e-10)
-8.40e+06(1.2e-08)
-2.21e+06(1.3e-10)(+)
-2.19e+06(1.3e-10)(+)
-2.79e+06(1.7e-10)(+)
mnist
(1000-780-650)
-5.19e+04(1.9e-10)
-5.19e+04(1.9e-10)
-6.81e+04(2.4e-10)
-1.35e+05(4.4e-10)
-5.92e+05(2.0e-08)
-7.34e+04(2.2e-10)(+)
-7.07e+04(2.3e-10)(+)
-9.21e+04(2.8e-10)(+)
randn10
(10-10-9)
5.33e+02(1.7e-01)
5.33e+02(1.7e-01)
5.07e+02(2.3e-01)
-1.28e+19(4.2e+09)
3.41e+02(1.7e-01)
-2.71e+04(1.7e-01)(+)
4.49e+02(1.7e-01)(+)
2.41e+02(2.3e-01)(+)
randn100
(100-100-90)
-6.14e+03(1.1e-07)
-6.14e+03(1.2e-09)
-8.14e+03(1.7e-09)
-1.08e+04(2.6e-08)
-1.56e+04(9.7e-08)
-8.18e+03(1.2e-07)(+)
-8.15e+03(1.2e-08)(+)
-1.12e+04(2.1e-08)(+)
randn1000
(1000-1000-900)
-6.33e+05(1.2e-10)
-6.33e+05(1.2e-10)
-7.65e+05(1.5e-10)
-6.49e+05(2.4e-10)
-2.77e+06(3.5e-08)
-6.42e+05(1.4e-10)(+)
-6.41e+05(1.4e-10)(+)
-7.72e+05(1.8e-10)(+)
sector
(500-1000-900)
-1.92e+03(1.2e-10)
-1.92e+03(1.2e-10)
-2.66e+03(1.4e-10)
-2.80e+03(2.1e-10)
-7.48e+03(1.1e-08)
-2.23e+03(1.3e-10)(+)
-2.32e+03(1.4e-10)(+)
-2.82e+03(1.7e-10)(+)
TDT2
(1000-1000-900)
-2.26e+06(1.2e-10)
-2.26e+06(1.2e-10)
-3.18e+06(1.4e-10)
-3.33e+06(2.0e-10)
-8.81e+06(9.7e-09)
-2.72e+06(1.4e-10)(+)
-2.73e+06(1.3e-10)(+)
-3.37e+06(1.7e-10)(+)
w1a
(2470-290-250)
-2.03e+04(5.4e-10)
-2.03e+04(5.4e-10)
-2.42e+04(7.0e-10)
-4.96e+04(7.1e-09)
-1.56e+06(2.5e-07)
-3.55e+04(3.2e-09)(+)
-3.67e+04(2.9e-09)(+)
-4.36e+04(2.8e-09)(+)
time limit=90s
cifar
(1000-100-50)
-1.05e+04(3.0e-09)
-1.05e+04(3.0e-09)
-5.28e+04(5.4e-09)
-1.03e+05(2.6e-08)
-1.11e+05(1.4e-07)
-8.38e+04(1.7e-08)(+)
-8.39e+04(1.9e-08)(+)
-1.24e+05(2.6e-08)(+)
CnnCaltech
(2000-1000-500)
-5.89e+02(2.9e-08)
-5.89e+02(3.1e-10)
-1.11e+03(5.2e-10)
-1.07e+03(1.3e-09)
-9.16e+03(6.9e-08)
-7.44e+02(2.9e-08)(+)
-7.51e+02(4.6e-10)(+)
-1.15e+03(6.9e-10)(+)
gisette
(3000-1000-500)
-3.22e+06(3.1e-10)
-3.22e+06(3.1e-10)
-8.53e+06(4.9e-10)
-9.49e+06(1.2e-09)
-1.36e+07(2.6e-08)
-6.21e+06(4.6e-10)(+)
-6.23e+06(4.9e-10)(+)
-9.65e+06(7.9e-10)(+)
mnist
(1000-780-390)
-8.65e+04(4.1e-10)
-8.65e+04(4.1e-10)
-2.56e+05(5.6e-10)
-3.14e+05(1.2e-09)
-1.20e+06(4.1e-08)
-2.05e+05(5.8e-10)(+)
-2.11e+05(6.1e-10)(+)
-3.06e+05(7.6e-10)(+)
randn10
(10-10-5)
1.29e+02(9.7e-02)
1.29e+02(9.7e-02)
2.45e+02(2.3e-01)
-3.96e+01(9.7e-02)
-3.97e+02(9.7e-02)
1.17e+01(9.7e-02)(+)
-2.66e+09(1.1e+00)(+)
1.55e+01(2.3e-01)(+)
randn100
(100-100-50)
-1.03e+04(3.0e-09)
-1.03e+04(2.5e-07)
-1.98e+04(4.4e-09)
-2.28e+04(5.6e-08)
-4.37e+04(2.6e-07)
-1.50e+04(2.5e-08)(+)
-1.54e+04(2.6e-07)(+)
-2.41e+04(4.2e-08)(+)
randn1000
(1000-1000-500)
-1.16e+06(3.1e-10)
-1.16e+06(3.1e-10)
-1.93e+06(5.0e-10)
-1.22e+06(6.9e-10)
-1.04e+07(2.3e-07)
-1.19e+06(4.1e-10)(+)
-1.19e+06(4.4e-10)(+)
-1.95e+06(6.7e-10)(+)
sector
(500-1000-500)
-3.61e+03(3.1e-10)
-3.61e+03(3.1e-10)
-7.90e+03(4.9e-10)
-9.24e+03(1.3e-09)
-1.06e+04(2.0e-08)
-5.56e+03(4.3e-10)(+)
-5.69e+03(4.3e-10)(+)
-8.51e+03(6.4e-10)(+)
TDT2
(1000-1000-500)
-4.25e+06(3.1e-10)
-4.25e+06(3.1e-10)
-9.39e+06(4.8e-10)
-1.05e+07(1.1e-09)
-1.42e+07(2.1e-08)
-6.65e+06(4.4e-10)(+)
-6.89e+06(4.2e-10)(+)
-1.04e+07(6.5e-10)(+)
w1a
(2470-290-145)
-3.02e+04(1.1e-04)
-3.02e+04(1.1e-04)
-5.72e+04(2.7e-05)
-9.21e+04(1.1e-04)
-9.32e+06(1.1e-04)
-5.74e+04(1.1e-04)(+)
-6.40e+04(1.1e-04)(+)
-7.94e+04(2.7e-05)(+)
cifar
(1000-100-70)
-7.32e+03(1.9e-09)
-7.32e+03(1.9e-09)
-3.29e+04(3.1e-09)
-7.19e+04(2.1e-08)
-1.36e+05(1.2e-07)
-6.05e+04(1.8e-08)(+)
-6.42e+04(1.8e-08)(+)
-9.76e+04(2.5e-08)(+)
CnnCaltech
(2000-1000-700)
-4.33e+02(2.1e-08)
-4.33e+02(2.2e-10)
-7.42e+02(3.1e-10)
-7.76e+02(8.4e-10)
-6.63e+03(4.7e-08)
-5.23e+02(2.1e-08)(+)
-5.38e+02(3.0e-10)(+)
-8.08e+02(4.2e-10)(+)
gisette
(1000,700)
-2.45e+06(2.2e-10)
-2.45e+06(2.2e-10)
-5.56e+06(3.1e-10)
-6.76e+06(7.5e-10)
-1.13e+07(1.9e-08)
-3.90e+06(3.0e-10)(+)
-4.02e+06(3.0e-10)(+)
-6.62e+06(4.4e-10)(+)
mnist
(1000-780-500)
-7.05e+04(3.1e-10)
-7.05e+04(3.1e-10)
-1.71e+05(4.5e-10)
-2.51e+05(8.4e-10)
-1.09e+06(3.5e-08)
-1.58e+05(4.3e-10)(+)
-1.46e+05(4.4e-10)(+)
-2.23e+05(5.9e-10)(+)
randn10
(10-10-7)
1.61e+02(5.6e-02)
1.61e+02(5.6e-02)
3.33e+02(1.7e-01)
6.45e+01(5.6e-02)
5.58e+01(5.6e-02)
1.15e+02(5.6e-02)(+)
8.86e+01(5.6e-02)(+)
1.67e+02(1.7e-01)(+)
randn100
(100,70)
-8.00e+03(1.9e-09)
-8.00e+03(1.8e-07)
-1.41e+04(3.0e-09)
-1.43e+04(3.0e-08)
-2.60e+04(1.7e-07)
-1.05e+04(1.4e-08)(+)
-1.08e+04(1.8e-07)(+)
-1.87e+04(3.2e-08)(+)
randn1000
(1000-1000-700)
-8.88e+05(2.2e-10)
-8.88e+05(2.2e-10)
-1.36e+06(3.1e-10)
-9.25e+05(4.6e-10)
-7.05e+06(1.4e-07)
-9.10e+05(2.8e-10)(+)
-9.10e+05(2.8e-10)(+)
-1.37e+06(4.2e-10)(+)
sector
(500-1000-700)
-2.66e+03(2.2e-10)
-2.66e+03(2.2e-10)
-5.64e+03(3.2e-10)
-5.40e+03(5.2e-10)
-1.53e+04(1.8e-08)
-3.67e+03(2.6e-10)(+)
-3.80e+03(2.8e-10)(+)
-5.94e+03(4.0e-10)(+)
TDT2
(1000-1000-700)
-3.15e+06(2.2e-10)
-3.15e+06(2.2e-10)
-6.78e+06(3.2e-10)
-6.43e+06(5.0e-10)
-1.33e+07(1.6e-08)
-4.49e+06(2.9e-10)(+)
-4.51e+06(2.6e-10)(+)
-7.19e+06(4.2e-10)(+)
w1a
(2470-290-200)
-2.77e+04(8.0e-10)
-2.77e+04(8.0e-10)
-4.00e+04(1.1e-09)
-7.60e+04(1.2e-08)
-8.13e+06(1.3e-06)
-5.33e+04(4.8e-09)(+)
-5.40e+04(4.5e-09)(+)
-6.47e+04(5.6e-09)(+)
cifar
(1000-100-90)
-6.42e+03(1.2e-09)
-6.42e+03(1.2e-09)
-1.60e+04(1.3e-09)
-3.78e+04(1.3e-08)
-5.24e+04(1.2e-07)
-2.77e+04(6.1e-09)(+)
-2.53e+04(4.8e-09)(+)
-3.60e+04(7.8e-09)(+)
CnnCaltech
(2000-1000-900)
-3.10e+02(1.1e-08)
-3.10e+02(1.2e-10)
-4.05e+02(1.6e-10)
-3.99e+02(2.6e-10)
-3.16e+03(2.0e-08)
-3.45e+02(1.1e-08)(+)
-3.42e+02(1.4e-10)(+)
-4.36e+02(2.0e-10)(+)
gisette
(3000-1000-900)
-1.74e+06(1.2e-10)
-1.74e+06(1.2e-10)
-2.84e+06(1.4e-10)
-2.76e+06(1.9e-10)
-9.30e+06(1.6e-08)
-2.16e+06(1.3e-10)(+)
-2.15e+06(1.3e-10)(+)
-3.06e+06(1.6e-10)(+)
mnist
(1000-780-650)
-5.19e+04(1.9e-10)
-5.19e+04(1.9e-10)
-6.85e+04(2.4e-10)
-1.28e+05(4.0e-10)
-7.18e+05(2.5e-08)
-8.43e+04(2.3e-10)(+)
-8.21e+04(2.3e-10)(+)
-1.06e+05(2.7e-10)(+)
randn10
(10-10-9)
5.33e+02(1.7e-01)
5.33e+02(1.7e-01)
4.54e+02(2.1e-01)
-2.28e+05(1.7e-01)
4.62e+02(1.7e-01)
1.80e+01(1.7e-01)(+)
-6.43e+00(1.7e-01)(+)
-1.06e+02(2.1e-01)(+)
randn100
(100-100-90)
-6.14e+03(1.1e-07)
-6.14e+03(1.2e-09)
-8.14e+03(1.5e-09)
-1.12e+04(2.5e-08)
-1.36e+04(1.2e-07)
-8.09e+03(1.2e-07)(+)
-8.48e+03(1.7e-08)(+)
-1.11e+04(2.1e-08)(+)
randn1000
(1000-1000-900)
-6.33e+05(1.2e-10)
-6.33e+05(1.2e-10)
-7.87e+05(1.5e-10)
-6.50e+05(2.5e-10)
-3.36e+06(4.5e-08)
-6.42e+05(1.5e-10)(+)
-6.44e+05(1.5e-10)(+)
-7.94e+05(2.0e-10)(+)
sector
(500-1000-900)
-1.92e+03(1.2e-10)
-1.92e+03(1.2e-10)
-2.89e+03(1.5e-10)
-2.80e+03(1.9e-10)
-8.81e+03(1.3e-08)
-2.26e+03(1.3e-10)(+)
-2.30e+03(1.3e-10)(+)
-2.99e+03(1.7e-10)(+)
TDT2
(1000-1000-900)
-2.26e+06(1.2e-10)
-2.26e+06(1.2e-10)
-3.46e+06(1.5e-10)
-3.38e+06(2.0e-10)
-1.29e+07(1.4e-08)
-2.73e+06(1.3e-10)(+)
-2.65e+06(1.3e-10)(+)
-3.57e+06(1.7e-10)(+)
w1a
(2470-290-250)
-2.03e+04(5.4e-10)
-2.03e+04(5.4e-10)
-2.42e+04(6.2e-10)
-5.60e+04(8.5e-09)
-9.37e+06(1.1e-06)
-3.95e+04(3.5e-09)(+)
-3.90e+04(3.5e-09)(+)
-5.02e+04(3.4e-09)(+)"
"X
PT",0.6898971000935453,"0
20
40
60
80"
"X
PT",0.6903648269410664,Time (seconds) −7 −6 −5 −4 −3 −2 −1
"X
PT",0.6908325537885874,Objective ×10 4
"X
PT",0.6913002806361085,GS- JOBCD
"X
PT",0.6917680074836295,J- JOBCD CSDM ADMM UMCM
"X
PT",0.6922357343311506,(a) Cifar(1000-100-50)
"X
PT",0.6927034611786717,"0
25
50
75
100
125
150
175"
"X
PT",0.6931711880261927,Time (seconds) −2.2 −2.0 −1.8 −1.6 −1.4 −1.2 −1.0 −0.8 −0.6
"X
PT",0.6936389148737138,Ob ective ×10 3
"X
PT",0.6941066417212348,GS- JOBCD
"X
PT",0.6945743685687559,J- JOBCD CSDM ADMM UMCM
"X
PT",0.6950420954162769,(b) CnnCaltech(2000-1000-500)
"X
PT",0.695509822263798,"0
25
50
75
100
125
150
175"
"X
PT",0.695977549111319,Time (seconds) −8 −7 −6 −5 −4 −3
"X
PT",0.69644527595884,Objective ×10 6
"X
PT",0.696913002806361,GS- JOBCD
"X
PT",0.6973807296538821,J- JOBCD CSDM ADMM UMCM
"X
PT",0.6978484565014031,(c) gisette(3000-1000-500)
"X
PT",0.6983161833489242,"0
20
40
60
80
100
120"
"X
PT",0.6987839101964453,Time (seconds) −3.5 −3.0 −2.5 −2.0 −1.5 −1.0
"X
PT",0.6992516370439663,Objective ×10 5
"X
PT",0.6997193638914874,GS- JOBCD
"X
PT",0.7001870907390084,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7006548175865295,(d) mnist(1000-780-390)
"X
PT",0.7011225444340505,"0
20
40
60
80"
"X
PT",0.7015902712815716,Time (seconds) 0 2 4 6 8
"X
PT",0.7020579981290926,Objective ×10 2
"X
PT",0.7025257249766137,GS- JOBCD
"X
PT",0.7029934518241348,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7034611786716558,(e) randn(10-10-5)
"X
PT",0.7039289055191768,"0
20
40
60
80"
"X
PT",0.7043966323666978,Time (sec nds) −1.8 −1.6 −1.4 −1.2 −1.0
"X
PT",0.7048643592142189,Objective ×10 4
"X
PT",0.7053320860617399,GS- JOBCD
"X
PT",0.705799812909261,J- JOBCD CSDM ADMM UMCM
"X
PT",0.706267539756782,(f) randn(100-100-50)
"X
PT",0.7067352666043031,"0
25
50
75
100
125
150
175"
"X
PT",0.7072029934518241,Time (seconds) −2.0 −1.8 −1.6 −1.4 −1.2
"X
PT",0.7076707202993452,Objective ×10 6
"X
PT",0.7081384471468662,GS- JOBCD
"X
PT",0.7086061739943873,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7090739008419084,(g) randn(1000-1000-500)
"X
PT",0.7095416276894294,"0
25
50
75
100
125
150
175"
"X
PT",0.7100093545369505,Time (seconds) −7.5 −7.0 −6.5 −6.0 −5.5 −5.0 −4.5 −4.0 −3.5
"X
PT",0.7104770813844715,Objective ×10 3
"X
PT",0.7109448082319925,GS- JOBCD
"X
PT",0.7114125350795135,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7118802619270346,(h) sector(500-1000-500)
"X
PT",0.7123479887745556,"0
25
50
75
100
125
150
175"
"X
PT",0.7128157156220767,Time (seconds) −9 −8 −7 −6 −5 −4
"X
PT",0.7132834424695977,Objective ×10 6
"X
PT",0.7137511693171188,GS- JOBCD
"X
PT",0.7142188961646398,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7146866230121609,(i) TDT2(1000-1000-500)
"X
PT",0.715154349859682,"0
20
40
60
80
100"
"X
PT",0.715622076707203,Time (seconds) −6.5 −6.0 −5.5 −5.0 −4.5 −4.0 −3.5 −3.0
"X
PT",0.7160898035547241,Objective ×10 4
"X
PT",0.7165575304022451,GS- JOBCD
"X
PT",0.7170252572497662,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7174929840972872,(j) w1a(2470-290-145)
"X
PT",0.7179607109448082,"Figure 3: The convergence curve of the compared methods for solving HEVP with varying (m, n, p)."
"X
PT",0.7184284377923292,"0
20
40
60
80"
"X
PT",0.7188961646398503,Time (seco ds) −5 −4 −3 −2 −1
"X
PT",0.7193638914873713,Objective ×10 4
"X
PT",0.7198316183348924,GS- JOBCD
"X
PT",0.7202993451824135,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7207670720299345,(a) Cifar(1000-100-70)
"X
PT",0.7212347988774556,"0
25
50
75
100
125
150
175"
"X
PT",0.7217025257249766,Time (seconds) −1.6 −1.4 −1.2 −1.0 −0.8 −0.6 −0.4
"X
PT",0.7221702525724977,Ob ective ×10 3
"X
PT",0.7226379794200187,GS- JOBCD
"X
PT",0.7231057062675398,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7235734331150608,(b) CnnCaltech(2000-1000-700)
"X
PT",0.7240411599625819,"0
25
50
75
100
125
150
175"
"X
PT",0.724508886810103,Time (seco ds) −7 −6 −5 −4 −3
"X
PT",0.724976613657624,Objective ×10 6
"X
PT",0.725444340505145,GS- JOBCD
"X
PT",0.725912067352666,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7263797942001871,(c) gisette(3000-1000-700)
"X
PT",0.7268475210477081,"0
20
40
60
80
100
120"
"X
PT",0.7273152478952292,Time (seconds) −3.0 −2.5 −2.0 −1.5 −1.0
"X
PT",0.7277829747427502,Objective ×10 5
"X
PT",0.7282507015902713,GS- JOBCD
"X
PT",0.7287184284377923,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7291861552853134,(d) mnist(1000-780-500)
"X
PT",0.7296538821328344,"0
20
40
60
80"
"X
PT",0.7301216089803555,Time (seconds) 0 1 2 3 4
"X
PT",0.7305893358278766,Objective ×10 2
"X
PT",0.7310570626753976,GS- JOBCD
"X
PT",0.7315247895229187,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7319925163704397,(e) randn(10-10-7)
"X
PT",0.7324602432179607,"0
20
40
60
80"
"X
PT",0.7329279700654817,Time (seconds) −1.4 −1.3 −1.2 −1.1 −1.0 −0.9 −0.8
"X
PT",0.7333956969130028,Objective ×10 4
"X
PT",0.7338634237605238,GS- JOBCD
"X
PT",0.7343311506080449,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7347988774555659,(f) randn(100-100-70)
"X
PT",0.735266604303087,"0
25
50
75
100
125
150
175"
"X
PT",0.735734331150608,Time (seconds) −1.6 −1.5 −1.4 −1.3 −1.2 −1.1 −1.0 −0.9
"X
PT",0.7362020579981291,Ob ective ×10 6
"X
PT",0.7366697848456502,GS- JOBCD
"X
PT",0.7371375116931712,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7376052385406923,(g) randn(1000-1000-700)
"X
PT",0.7380729653882133,"0
25
50
75
100
125
150
175"
"X
PT",0.7385406922357344,Time (seco ds) −7 −6 −5 −4 −3
"X
PT",0.7390084190832554,Objective ×10 3
"X
PT",0.7394761459307764,GS- JOBCD
"X
PT",0.7399438727782974,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7404115996258185,(h) sector(500-1000-700)
"X
PT",0.7408793264733395,"0
25
50
75
100
125
150
175"
"X
PT",0.7413470533208606,Time (seconds) −8 −7 −6 −5 −4 −3
"X
PT",0.7418147801683816,Objective ×10 6
"X
PT",0.7422825070159027,GS- JOBCD
"X
PT",0.7427502338634238,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7432179607109448,(i) TDT2(1000-1000-700)
"X
PT",0.7436856875584659,"0
20
40
60
80
100"
"X
PT",0.7441534144059869,Time (seconds) −6.0 −5.5 −5.0 −4.5 −4.0 −3.5 −3.0
"X
PT",0.744621141253508,Objective ×10 4
"X
PT",0.745088868101029,GS- JOBCD
"X
PT",0.7455565949485501,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7460243217960711,(j) w1a(2470-290-200)
"X
PT",0.7464920486435921,"Figure 4: The convergence curve of the compared methods for solving HEVP with varying (m, n, p)."
"X
PT",0.7469597754911131,"0
20
40
60
80"
"X
PT",0.7474275023386342,Time (seconds) −4.0 −3.5 −3.0 −2.5 −2.0 −1.5 −1.0 −0.5
"X
PT",0.7478952291861553,Objective ×10 4
"X
PT",0.7483629560336763,GS- JOBCD
"X
PT",0.7488306828811974,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7492984097287184,(a) Cifar(1000-100-90)
"X
PT",0.7497661365762395,"0
25
50
75
100
125
150
175"
"X
PT",0.7502338634237605,Time (seconds) −9 −8 −7 −6 −5 −4 −3
"X
PT",0.7507015902712816,Ob ective ×10 2
"X
PT",0.7511693171188026,GS- JOBCD
"X
PT",0.7516370439663237,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7521047708138447,(b) CnnCaltech(2000-1000-900)
"X
PT",0.7525724976613658,"0
25
50
75
100
125
150
175"
"X
PT",0.7530402245088869,Time (seconds) −5.5 −5.0 −4.5 −4.0 −3.5 −3.0 −2.5 −2.0
"X
PT",0.7535079513564079,Objective ×10 6
"X
PT",0.7539756782039289,GS- JOBCD
"X
PT",0.7544434050514499,J- JOBCD CSDM ADMM UMCM
"X
PT",0.754911131898971,(c) gisette(3000-1000-900)
"X
PT",0.755378858746492,"0
20
40
60
80
100
120"
"X
PT",0.7558465855940131,Time (seco ds) −2.2 −2.0 −1.8 −1.6 −1.4 −1.2 −1.0 −0.8 −0.6
"X
PT",0.7563143124415341,Objective ×10 5
"X
PT",0.7567820392890552,GS- JOBCD
"X
PT",0.7572497661365762,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7577174929840973,(d) mnist(1000-780-650)
"X
PT",0.7581852198316184,"0
20
40
60
80"
"X
PT",0.7586529466791394,Time (seconds) −8 −7 −6 −5 −4 −3 −2 −1 0
"X
PT",0.7591206735266605,Objective ×10 4
"X
PT",0.7595884003741815,GS- JOBCD
"X
PT",0.7600561272217026,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7605238540692236,(e) randn(10-10-9)
"X
PT",0.7609915809167446,"0
20
40
60
80"
"X
PT",0.7614593077642656,Time (seconds) −9.5 −9.0 −8.5 −8.0 −7.5 −7.0 −6.5 −6.0
"X
PT",0.7619270346117867,Object ve ×10 3
"X
PT",0.7623947614593077,GS- JOBCD
"X
PT",0.7628624883068288,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7633302151543498,(f) randn(100-100-90)
"X
PT",0.7637979420018709,"0
25
50
75
100
125
150
175"
"X
PT",0.764265668849392,Time (seconds) −9.5 −9.0 −8.5 −8.0 −7.5 −7.0 −6.5
"X
PT",0.764733395696913,Objective ×10 5
"X
PT",0.7652011225444341,GS- JOBCD
"X
PT",0.7656688493919551,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7661365762394762,(g) randn(1000-1000-900)
"X
PT",0.7666043030869972,"0
25
50
75
100
125
150
175"
"X
PT",0.7670720299345183,Time (seco ds) −5.0 −4.5 −4.0 −3.5 −3.0 −2.5 −2.0
"X
PT",0.7675397567820393,Objective ×10 3
"X
PT",0.7680074836295603,GS- JOBCD
"X
PT",0.7684752104770813,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7689429373246024,(h) sector(500-1000-900)
"X
PT",0.7694106641721234,"0
25
50
75
100
125
150
175"
"X
PT",0.7698783910196445,Time (seco ds) −6 −5 −4 −3
"X
PT",0.7703461178671656,Objective ×10 6
"X
PT",0.7708138447146866,GS- JOBCD
"X
PT",0.7712815715622077,J- JOBCD CSDM ADMM UMCM
"X
PT",0.7717492984097287,(i) TDT2(1000-1000-900)
"X
PT",0.7722170252572498,"0
20
40
60
80
100"
"X
PT",0.7726847521047708,Time (seco ds) −3.6 −3.4 −3.2 −3.0 −2.8 −2.6 −2.4 −2.2 −2.0
"X
PT",0.7731524789522919,Objective ×10 4
"X
PT",0.7736202057998129,GS- JOBCD
"X
PT",0.774087932647334,J- JOBCD CSDM ADMM UMCM
"X
PT",0.774555659494855,(j) w1a(2470-290-250)
"X
PT",0.775023386342376,"Figure 5: The convergence curve of the compared methods for solving HEVP with varying (m, n, p)."
"X
PT",0.775491113189897,"F.3.2
Hyperbolic Structural Probe Problem
835"
"X
PT",0.7759588400374181,"Table 3: The convergence curve of the compared methods for solving HSPP. (+) indicates that
after the convergence of the CSDM, utilizing the J-OBCD for optimization markedly enhances the
objective value. The 1st, 2nd , and 3rd best results are colored with red, green and blue, respectively.
(n, p) represents the dimension and p-value of the J orthogonal matrix (square matrix). The value in
() stands for Pn
ij |X⊤JX −J|ij."
"X
PT",0.7764265668849392,"datasetname
(m-n-p)
ADMM
UMCM
CSDM
J-JOBCD
VR-J-JOBCD
CSDM+J-JOBCD
time limit=30s
20News
(9423-50-25)
6.47e+04(2.4e-03)
6.47e+04(2.4e-03)
6.45e+04(2.0e-03)
6.40e+04(2.4e-03)
6.26e+04(2.4e-03)
6.31e+04(2.0e-03)(+)
Cifar
(10000-50-25)
1.49e+07(2.4e-03)
1.49e+07(2.4e-03)
1.49e+07(2.0e-03)
1.46e+07(2.4e-03)
1.45e+07(2.5e-03)
1.46e+07(2.0e-03)(+)
cnnCaltech
(3000-96-48)
3.08e+04(3.5e-09)
3.08e+04(3.5e-09)
3.03e+04(2.3e-05)
1.64e+04(4.0e-08)
1.64e+04(4.7e-08)
1.74e+04(2.3e-05)(+)
E2006
(5000-100-50)
5.54e+04(3.5e-09)
5.54e+04(3.5e-09)
5.54e+04(1.9e-05)
5.53e+04(9.0e-08)
5.53e+04(1.2e-07)
5.53e+04(1.9e-05)(+)
gisette
(6000-50-25)
1.61e+05(2.4e-03)
1.61e+05(2.4e-03)
1.52e+05(1.6e-03)
9.06e+04(2.4e-03)
7.48e+04(2.4e-03)
8.65e+04(1.6e-03)(+)
Mnist
(6000-92-46)
6.94e+06(3.6e-09)
6.94e+06(3.6e-09)
6.93e+06(2.1e-05)
6.50e+06(4.0e-05)
6.48e+06(8.7e-05)
6.93e+06(2.1e-05)
news20
(7967-50-25)
6.12e+04(2.4e-03)
6.12e+04(2.4e-03)
6.12e+04(2.0e-03)
6.12e+04(2.4e-03)
6.12e+04(2.4e-03)
6.12e+04(2.0e-03)
randn5000
(5000-100-50)
1.84e+06(3.5e-09)
1.84e+06(3.5e-09)
1.84e+06(2.0e-05)
1.77e+06(1.4e-07)
1.56e+06(9.9e-05)
1.84e+06(2.0e-05)
randn10000
(10000-50-25)
2.66e+06(2.4e-03)
2.66e+06(2.4e-03)
2.66e+06(2.5e-03)
2.64e+06(2.4e-03)
2.34e+06(2.5e-03)
2.66e+06(2.5e-03)
w1a
(2477-100-50)
2.71e+04(3.5e-09)
2.71e+04(3.5e-09)
2.47e+04(1.6e-05)
2.05e+04(3.6e-08)
1.92e+04(5.1e-08)
2.47e+04(1.6e-05)
20News
(9423-50-35)
7.89e+04(3.7e-09)
7.89e+04(3.7e-09)
7.85e+04(2.4e-05)
7.85e+04(8.6e-09)
7.71e+04(2.7e-08)
7.64e+04(2.4e-05)(+)
Cifar
(10000-50-35)
1.48e+07(5.5e-03)
1.48e+07(5.5e-03)
1.48e+07(6.2e-03)
1.43e+07(5.5e-03)
1.43e+07(5.7e-03)
1.43e+07(6.2e-03)(+)
cnnCaltech
(3000-96-70)
3.75e+04(2.0e-09)
3.75e+04(2.0e-09)
3.71e+04(1.3e-05)
2.40e+04(2.5e-08)
1.87e+04(3.4e-08)
2.15e+04(1.3e-05)(+)
E2006
(5000-100-75)
6.79e+04(1.0e-03)
6.79e+04(6.3e-04)
6.79e+04(5.8e-04)
6.65e+04(6.3e-04)
6.34e+04(6.3e-04)
6.69e+04(5.8e-04)(+)
gisette
(6000-50-35)
1.89e+05(5.5e-03)
1.89e+05(5.5e-03)
1.83e+05(4.7e-03)
1.24e+05(5.5e-03)
1.03e+05(5.5e-03)
1.17e+05(4.7e-03)(+)
Mnist
(6000-92-70)
6.75e+06(2.0e-09)
6.75e+06(2.0e-09)
6.74e+06(1.4e-05)
6.30e+06(7.7e-05)
6.20e+06(3.7e-04)
6.24e+06(7.0e-05)(+)
news20
(7967-50-35)
7.26e+04(5.5e-03)
7.26e+04(5.5e-03)
7.26e+04(4.9e-03)
7.26e+04(5.5e-03)
7.25e+04(5.5e-03)
7.26e+04(4.9e-03)
randn5000
(5000-100-75)
1.75e+06(6.3e-04)
1.75e+06(6.3e-04)
1.75e+06(6.1e-04)
1.44e+06(6.6e-04)
1.70e+06(6.3e-04)
1.75e+06(6.1e-04)
randn10000
(10000-50-36)
2.56e+06(3.7e-09)
2.56e+06(3.7e-09)
2.56e+06(2.0e-05)
2.56e+06(5.9e-09)
2.54e+06(2.2e-08)
2.56e+06(2.0e-05)(+)
w1a
(2477-100-75)
3.36e+04(6.3e-04)
3.36e+04(6.3e-04)
3.16e+04(5.5e-04)
2.53e+04(6.3e-04)
2.48e+04(6.3e-04)
2.90e+04(5.5e-04)(+)
20News
(9423-50-45)
8.79e+04(4.8e-03)
8.79e+04(4.8e-03)
8.73e+04(4.6e-03)
8.62e+04(4.8e-03)
8.60e+04(4.8e-03)
8.68e+04(4.6e-03)(+)
Cifar
(10000-50-45)
1.47e+07(4.8e-03)
1.47e+07(4.8e-03)
1.47e+07(4.6e-03)
1.46e+07(4.8e-03)
1.41e+07(7.2e-03)
1.46e+07(4.6e-03)(+)
cnnCaltech
(3000-96-85)
4.13e+04(9.2e-04)
4.14e+04(4.4e-04)
4.11e+04(6.5e-04)
2.59e+04(4.4e-04)
2.25e+04(4.4e-04)
2.65e+04(6.5e-04)(+)
E2006
(5000-100-90)
7.44e+04(1.2e-09)
7.44e+04(1.2e-09)
7.44e+04(7.5e-06)
6.95e+04(6.5e-08)
6.92e+04(3.8e-07)
6.93e+04(7.5e-06)(+)
gisette
(6000-50-45)
2.25e+05(4.8e-03)
2.25e+05(4.8e-03)
2.10e+05(5.2e-03)
1.42e+05(4.8e-03)
1.50e+05(4.8e-03)
1.54e+05(5.2e-03)(+)
Mnist
(6000-92-85)
6.73e+06(1.0e-03)
6.73e+06(1.0e-03)
6.73e+06(1.1e-03)
6.67e+06(1.0e-03)
6.22e+06(1.1e-03)
6.61e+06(1.1e-03)(+)
news20
(7967-50-45)
8.24e+04(4.8e-03)
8.24e+04(4.8e-03)
8.24e+04(4.5e-03)
8.24e+04(4.8e-03)
8.24e+04(4.8e-03)
8.24e+04(4.5e-03)
randn5000
(5000-100-85)
1.72e+06(1.3e-03)
1.72e+06(1.3e-03)
1.72e+06(1.4e-03)
1.70e+06(1.3e-03)
1.56e+06(1.3e-03)
1.72e+06(1.4e-03)
randn10000
(10000-50-45)
2.54e+06(3.3e-09)
2.54e+06(3.3e-09)
2.54e+06(1.9e-05)
2.53e+06(4.9e-09)
2.46e+06(3.3e-08)
2.54e+06(1.9e-05)
w1a
(2477-100-90)
4.10e+04(1.2e-09)
4.10e+04(1.2e-09)
3.76e+04(6.4e-06)
3.77e+04(4.2e-09)
3.27e+04(1.1e-08)
3.48e+04(6.4e-06)(+)
time limit=60s
20News
(9423-50-25)
6.47e+04(2.4e-03)
6.47e+04(2.4e-03)
6.42e+04(1.9e-03)
6.32e+04(2.4e-03)
6.35e+04(2.4e-03)
6.29e+04(1.9e-03)(+)
Cifar
(10000-50-25)
1.49e+07(2.4e-03)
1.49e+07(2.4e-03)
1.49e+07(1.7e-03)
1.45e+07(2.5e-03)
1.45e+07(2.5e-03)
1.45e+07(1.7e-03)(+)
cnnCaltech
(3000-96-48)
3.08e+04(3.5e-09)
3.08e+04(3.5e-09)
3.00e+04(2.4e-05)
1.92e+04(3.8e-08)
1.52e+04(4.8e-08)
1.67e+04(2.4e-05)(+)
E2006
(5000-100-50)
5.54e+04(3.5e-09)
5.54e+04(3.5e-09)
5.54e+04(2.3e-05)
5.51e+04(1.6e-07)
5.23e+04(3.9e-07)
5.51e+04(2.3e-05)(+)
gisette
(6000-50-25)
1.61e+05(2.4e-03)
1.61e+05(2.4e-03)
1.46e+05(2.1e-03)
9.76e+04(2.4e-03)
7.20e+04(2.4e-03)
8.40e+04(2.1e-03)(+)
Mnist
(6000-92-46)
6.94e+06(3.6e-09)
6.94e+06(3.6e-09)
6.93e+06(2.1e-05)
6.47e+06(1.4e-04)
6.45e+06(3.0e-04)
6.93e+06(2.1e-05)
news20
(7967-50-25)
6.12e+04(2.4e-03)
6.12e+04(2.4e-03)
6.12e+04(2.0e-03)
6.12e+04(2.4e-03)
6.12e+04(2.4e-03)
6.12e+04(2.0e-03)
randn5000
(5000-100-50)
1.84e+06(3.5e-09)
1.84e+06(3.5e-09)
1.84e+06(1.9e-05)
1.59e+06(8.3e-05)
1.51e+06(4.9e-04)
1.84e+06(1.9e-05)
randn10000
(10000-50-25)
2.66e+06(2.4e-03)
2.66e+06(2.4e-03)
2.66e+06(2.5e-03)
2.58e+06(2.4e-03)
2.37e+06(2.4e-03)
2.66e+06(2.5e-03)
w1a
(2477-100-50)
2.71e+04(3.5e-09)
2.71e+04(3.5e-09)
2.41e+04(1.5e-05)
2.33e+04(1.3e-08)
1.89e+04(6.0e-08)
2.41e+04(1.5e-05)
20News
(9423-50-35)
7.89e+04(3.7e-09)
7.89e+04(3.7e-09)
7.84e+04(2.1e-05)
7.63e+04(3.3e-08)
7.60e+04(5.3e-08)
7.84e+04(2.1e-05)
Cifar
(10000-50-35)
1.48e+07(5.5e-03)
1.48e+07(5.5e-03)
1.48e+07(6.5e-03)
1.43e+07(5.6e-03)
1.42e+07(5.7e-03)
1.43e+07(6.5e-03)(+)
cnnCaltech
(3000-96-70)
3.75e+04(2.0e-09)
3.75e+04(2.0e-09)
3.69e+04(1.1e-05)
1.93e+04(3.2e-08)
1.89e+04(3.6e-08)
2.19e+04(1.1e-05)(+)
E2006
(5000-100-75)
6.79e+04(1.0e-03)
6.79e+04(6.3e-04)
6.79e+04(5.6e-04)
6.48e+04(6.3e-04)
6.36e+04(6.3e-04)
6.39e+04(5.6e-04)(+)
gisette
(6000-50-35)
1.89e+05(5.5e-03)
1.89e+05(5.5e-03)
1.80e+05(4.4e-03)
1.14e+05(5.5e-03)
9.97e+04(5.5e-03)
1.24e+05(4.4e-03)(+)
Mnist
(6000-92-70)
6.75e+06(2.0e-09)
6.75e+06(2.0e-09)
6.74e+06(1.3e-05)
6.21e+06(5.4e-04)
6.17e+06(2.0e-04)
6.21e+06(3.4e-04)(+)
news20
(7967-50-35)
7.26e+04(5.5e-03)
7.26e+04(5.5e-03)
7.26e+04(4.8e-03)
7.25e+04(5.5e-03)
7.25e+04(5.5e-03)
7.25e+04(4.8e-03)(+)
randn5000
(5000-100-75)
1.75e+06(6.3e-04)
1.75e+06(6.3e-04)
1.75e+06(6.1e-04)
1.44e+06(7.2e-04)
1.35e+06(9.9e-04)
1.75e+06(6.1e-04)
randn10000
(10000-50-36)
2.56e+06(3.7e-09)
2.56e+06(3.7e-09)
2.56e+06(2.0e-05)
2.56e+06(5.4e-09)
2.41e+06(2.6e-07)
2.56e+06(2.0e-05)
w1a
(2477-100-75)
3.36e+04(6.3e-04)
3.36e+04(6.3e-04)
3.10e+04(5.4e-04)
3.32e+04(6.3e-04)
2.57e+04(6.3e-04)
3.10e+04(5.4e-04)
20News
(9423-50-45)
8.79e+04(4.8e-03)
8.79e+04(4.8e-03)
8.71e+04(4.5e-03)
8.73e+04(4.8e-03)
8.57e+04(4.8e-03)
8.66e+04(4.5e-03)(+)
Cifar
(10000-50-45)
1.47e+07(4.8e-03)
1.47e+07(4.8e-03)
1.47e+07(4.5e-03)
1.46e+07(4.8e-03)
1.46e+07(4.8e-03)
1.46e+07(4.5e-03)(+)
cnnCaltech
(3000-96-85)
4.13e+04(9.2e-04)
4.14e+04(4.4e-04)
4.09e+04(7.2e-04)
2.69e+04(4.4e-04)
2.44e+04(4.4e-04)
2.40e+04(7.2e-04)(+)
E2006
(5000-100-90)
7.44e+04(1.2e-09)
7.44e+04(1.2e-09)
7.44e+04(6.1e-06)
6.92e+04(8.2e-08)
6.90e+04(1.3e-07)
6.94e+04(6.1e-06)(+)
gisette
(6000-50-45)
2.25e+05(4.8e-03)
2.25e+05(4.8e-03)
2.10e+05(5.2e-03)
1.63e+05(4.8e-03)
1.37e+05(4.8e-03)
2.10e+05(5.2e-03)
Mnist
(6000-92-85)
6.73e+06(1.0e-03)
6.73e+06(1.0e-03)
6.73e+06(1.1e-03)
6.65e+06(1.0e-03)
6.12e+06(1.3e-03)
6.73e+06(1.1e-03)
news20
(7967-50-45)
8.24e+04(4.8e-03)
8.24e+04(4.8e-03)
8.24e+04(4.4e-03)
8.24e+04(4.8e-03)
8.24e+04(4.8e-03)
8.24e+04(4.4e-03)
randn5000
(5000-100-85)
1.72e+06(1.3e-03)
1.72e+06(1.3e-03)
1.72e+06(1.4e-03)
1.65e+06(1.3e-03)
1.56e+06(1.3e-03)
1.72e+06(1.4e-03)
randn10000
(10000-50-45)
2.54e+06(3.3e-09)
2.54e+06(3.3e-09)
2.54e+06(1.9e-05)
2.53e+06(9.0e-09)
2.34e+06(2.5e-07)
2.54e+06(1.9e-05)
w1a
(2477-100-90)
4.10e+04(1.2e-09)
4.10e+04(1.2e-09)
3.64e+04(6.0e-06)
3.45e+04(1.0e-08)
3.16e+04(1.0e-08)
3.34e+04(6.0e-06)(+)
time limit=90s
20News
(9423-50-25)
6.47e+04(2.4e-03)
6.47e+04(2.4e-03)
6.41e+04(1.8e-03)
6.31e+04(2.4e-03)
6.25e+04(2.4e-03)
6.41e+04(1.8e-03)
Cifar
(10000-50-25)
1.49e+07(2.4e-03)
1.49e+07(2.4e-03)
1.49e+07(2.0e-03)
1.45e+07(2.5e-03)
1.45e+07(2.6e-03)
1.45e+07(2.0e-03)(+)
cnnCaltech
(3000-96-48)
3.08e+04(3.5e-09)
3.08e+04(3.5e-09)
2.98e+04(2.2e-05)
1.89e+04(4.0e-08)
1.52e+04(4.5e-08)
1.74e+04(2.2e-05)(+)
E2006
(5000-100-50)
5.54e+04(3.5e-09)
5.54e+04(3.5e-09)
5.54e+04(2.1e-05)
5.34e+04(2.7e-07)
5.22e+04(3.0e-07)
5.30e+04(2.1e-05)(+)
gisette
(6000-50-25)
1.61e+05(2.4e-03)
1.61e+05(2.4e-03)
1.42e+05(2.3e-03)
9.50e+04(2.4e-03)
8.14e+04(2.4e-03)
7.44e+04(2.3e-03)(+)
Mnist
(6000-92-46)
6.94e+06(3.6e-09)
6.94e+06(3.6e-09)
6.93e+06(2.0e-05)
6.45e+06(3.6e-04)
6.42e+06(1.4e-03)
6.93e+06(2.0e-05)
news20
(7967-50-25)
6.12e+04(2.4e-03)
6.12e+04(2.4e-03)
6.12e+04(1.9e-03)
6.12e+04(2.4e-03)
6.12e+04(2.4e-03)
6.12e+04(1.9e-03)
randn5000
(5000-100-50)
1.84e+06(3.5e-09)
1.84e+06(3.5e-09)
1.84e+06(1.9e-05)
1.63e+06(1.4e-05)
1.52e+06(6.9e-04)
1.84e+06(1.9e-05)
randn10000
(10000-50-25)
2.66e+06(2.4e-03)
2.66e+06(2.4e-03)
2.66e+06(2.5e-03)
2.65e+06(2.4e-03)
2.25e+06(2.7e-03)
2.66e+06(2.5e-03)
w1a
(2477-100-50)
2.71e+04(3.5e-09)
2.71e+04(3.5e-09)
2.34e+04(1.5e-05)
2.24e+04(1.9e-08)
2.00e+04(4.3e-08)
1.90e+04(1.5e-05)(+)
20News
(9423-50-35)
7.89e+04(3.7e-09)
7.89e+04(3.7e-09)
7.84e+04(2.3e-05)
7.66e+04(4.5e-08)
7.57e+04(1.6e-07)
7.70e+04(2.3e-05)(+)
Cifar
(10000-50-35)
1.48e+07(5.5e-03)
1.48e+07(5.5e-03)
1.48e+07(7.0e-03)
1.43e+07(5.6e-03)
1.42e+07(6.2e-03)
1.43e+07(7.1e-03)(+)
cnnCaltech
(3000-96-70)
3.75e+04(2.0e-09)
3.75e+04(2.0e-09)
3.67e+04(1.4e-05)
2.33e+04(2.3e-08)
2.29e+04(2.5e-08)
2.16e+04(1.4e-05)(+)
E2006
(5000-100-75)
6.79e+04(1.0e-03)
6.79e+04(6.3e-04)
6.79e+04(5.5e-04)
6.37e+04(6.3e-04)
6.36e+04(6.3e-04)
6.38e+04(5.5e-04)(+)
gisette
(6000-50-35)
1.89e+05(5.5e-03)
1.89e+05(5.5e-03)
1.78e+05(4.2e-03)
1.16e+05(5.5e-03)
9.77e+04(5.5e-03)
1.10e+05(4.2e-03)(+)
Mnist
(6000-92-70)
6.75e+06(2.0e-09)
6.75e+06(2.0e-09)
6.74e+06(1.2e-05)
6.18e+06(7.5e-04)
6.15e+06(2.4e-03)
6.22e+06(6.7e-04)(+)
news20
(7967-50-35)
7.26e+04(5.5e-03)
7.26e+04(5.5e-03)
7.26e+04(4.6e-03)
7.25e+04(5.5e-03)
7.25e+04(5.5e-03)
7.25e+04(4.6e-03)(+)
randn5000
(5000-100-75)
1.75e+06(6.3e-04)
1.75e+06(6.3e-04)
1.75e+06(6.1e-04)
1.39e+06(1.2e-03)
1.38e+06(1.0e-03)
1.75e+06(6.1e-04)
randn10000
(10000-50-36)
2.56e+06(3.7e-09)
2.56e+06(3.7e-09)
2.56e+06(2.0e-05)
2.56e+06(4.4e-09)
2.51e+06(3.5e-08)
2.56e+06(2.0e-05)
w1a
(2477-100-75)
3.36e+04(6.3e-04)
3.36e+04(6.3e-04)
3.04e+04(5.2e-04)
2.64e+04(6.3e-04)
2.58e+04(6.3e-04)
2.56e+04(5.2e-04)(+)
20News
(9423-50-45)
8.79e+04(4.8e-03)
8.79e+04(4.8e-03)
8.70e+04(4.4e-03)
8.66e+04(4.8e-03)
8.58e+04(4.8e-03)
8.61e+04(4.4e-03)(+)
Cifar
(10000-50-45)
1.47e+07(4.8e-03)
1.47e+07(4.8e-03)
1.47e+07(4.4e-03)
1.46e+07(4.8e-03)
1.41e+07(8.6e-03)
1.41e+07(5.7e-03)(+)
cnnCaltech
(3000-96-85)
4.13e+04(9.2e-04)
4.14e+04(4.4e-04)
4.07e+04(8.2e-04)
2.47e+04(4.4e-04)
2.38e+04(4.4e-04)
2.91e+04(8.2e-04)(+)
E2006
(5000-100-90)
7.44e+04(1.2e-09)
7.44e+04(1.2e-09)
7.44e+04(8.7e-06)
6.89e+04(9.4e-08)
6.99e+04(7.9e-08)
7.09e+04(8.7e-06)(+)
gisette
(6000-50-45)
2.25e+05(4.8e-03)
2.25e+05(4.8e-03)
2.09e+05(5.2e-03)
1.83e+05(4.8e-03)
1.34e+05(4.8e-03)
2.09e+05(5.2e-03)
Mnist
(6000-92-85)
6.73e+06(1.0e-03)
6.73e+06(1.0e-03)
6.73e+06(1.1e-03)
6.72e+06(1.0e-03)
6.14e+06(1.1e-03)
6.73e+06(1.1e-03)
news20
(7967-50-45)
8.24e+04(4.8e-03)
8.24e+04(4.8e-03)
8.24e+04(4.2e-03)
8.24e+04(4.8e-03)
8.24e+04(4.8e-03)
8.24e+04(4.2e-03)
randn5000
(5000-100-85)
1.72e+06(1.3e-03)
1.72e+06(1.3e-03)
1.72e+06(1.4e-03)
1.46e+06(1.3e-03)
1.55e+06(1.3e-03)
1.72e+06(1.4e-03)
randn10000
(10000-50-45)
2.54e+06(3.3e-09)
2.54e+06(3.3e-09)
2.54e+06(1.9e-05)
2.53e+06(5.8e-09)
2.52e+06(9.7e-09)
2.54e+06(1.9e-05)
w1a
(2477-100-90)
4.10e+04(1.2e-09)
4.10e+04(1.2e-09)
3.56e+04(6.5e-06)
3.86e+04(2.3e-09)
2.95e+04(1.7e-08)
3.07e+04(6.5e-06)(+)"
"X
PT",0.7768942937324602,"0
25
50
75
100
125
150
175 Epoch 8.64 8.66 8.68 8.
70 8.
72 8.
74 8.
76 8.
78"
"X
PT",0.7773620205799813,Objective ×10 4
"X
PT",0.7778297474275023,J- JOBCD
"X
PT",0.7782974742750234,VR- J- JOBCD CSDM ADMM UMCM
"X
PT",0.7787652011225444,(a) 20News(9423-50-45)
"X
PT",0.7792329279700655,"0
25
50
75
100
125
150
175 Epoch 1.41 1.42 1.43 1.44 1.45 1.46 1.47"
"X
PT",0.7797006548175865,Objective ×10 7
"X
PT",0.7801683816651076,J- JOBCD
"X
PT",0.7806361085126287,VR- J- JOBCD CSDM ADMM UMCM
"X
PT",0.7811038353601497,(b) Cifar(10000-50-45)
"X
PT",0.7815715622076708,"0
100
200
300
400
500
600 Epoch 2.50 2.
75 3.00 3.25 3.50 3.
75 4.00"
"X
PT",0.7820392890551918,Objective ×10 4
"X
PT",0.7825070159027128,J- JOBCD
"X
PT",0.7829747427502338,VR- J- JOBCD CSDM ADMM UMCM
"X
PT",0.7834424695977549,(c) CnnCaltech(3000-96-85)
"X
PT",0.7839101964452759,"0
50
100
150
200
250
300
350
400 Epoch 6.9 7.0 7.1 7.2 7.3 7.4"
"X
PT",0.784377923292797,Objective ×10 4
"X
PT",0.784845650140318,J- JOBCD
"X
PT",0.7853133769878391,VR- J- JOBCD CSDM ADMM UMCM
"X
PT",0.7857811038353602,(d) E2006(5000-100-90)
"X
PT",0.7862488306828812,"0
50
100
150
200
250
300
350 Epoch 1.2 1.4 1.6 1.8 2.0 2.2"
"X
PT",0.7867165575304023,Objective ×10 5
"X
PT",0.7871842843779233,J- JOBCD
"X
PT",0.7876520112254444,VR- J- JOBCD CSDM ADMM UMCM
"X
PT",0.7881197380729654,(e) Gisette(6000-50-45)
"X
PT",0.7885874649204865,"0
50
100
150
200
250
300
350 Epoch 6.45 6.50 6.55 6.60 6.65 6.
70"
"X
PT",0.7890551917680075,Objective ×10 6
"X
PT",0.7895229186155285,J- JOBCD
"X
PT",0.7899906454630495,VR- J- JOBCD CSDM ADMM UMCM
"X
PT",0.7904583723105706,(f) Mnist(6000-92-85)
"X
PT",0.7909260991580916,"0
50
100
150
200
250 Epoch 8.240 8.241 8.242 8.243 8.244"
"X
PT",0.7913938260056127,Objective ×10 4
"X
PT",0.7918615528531338,J- JOBCD
"X
PT",0.7923292797006548,VR- J- JOBCD CSDM ADMM UMCM
"X
PT",0.7927970065481759,(g) News20(7967-50-45)
"X
PT",0.7932647333956969,"0
50
100
150
200
250
300
350
400 Epoch 1.40 1.45 1.50 1.55 1.60 1.65 1.
70"
"X
PT",0.793732460243218,Objective ×10 6
"X
PT",0.794200187090739,J- JOBCD
"X
PT",0.7946679139382601,VR- J- JOBCD CSDM ADMM UMCM
"X
PT",0.7951356407857811,(h) randn(5000-100-85)
"X
PT",0.7956033676333022,"0
25
50
75
100
125
150
175 Epoch 2.375 2.400 2.425 2.450 2.475 2.500 2.525"
"X
PT",0.7960710944808232,Objective ×10 6
"X
PT",0.7965388213283442,J- JOBCD
"X
PT",0.7970065481758652,VR- J- JOBCD CSDM ADMM UMCM
"X
PT",0.7974742750233863,(i) randn(10000-50-45)
"X
PT",0.7979420018709074,"0
100
200
300
400
500
600 Epoch 3.2 3.4 3.6 3.8 4.0"
"X
PT",0.7984097287184284,Objective ×10 4
"X
PT",0.7988774555659495,J- JOBCD
"X
PT",0.7993451824134705,VR- J- JOBCD CSDM ADMM UMCM
"X
PT",0.7998129092609916,(j) W1a(2477-100-90)
"X
PT",0.8002806361085126,"Figure 6: The convergence curve of the compared methods for solving HSPP by epochs with varying
(m, n, p)."
"X
PT",0.8007483629560337,"0
20
40
60
80"
"X
PT",0.8012160898035547,"Time (seconds) 8.64 8.66 8.68 8.
70 8.
72 8.
74 8.
76 8.
78"
"X
PT",0.8016838166510758,Objective ×10 4
"X
PT",0.8021515434985969,J- JOBCD
"X
PT",0.8026192703461179,VR- J- JOBCD CSDM ADMM UMCM
"X
PT",0.803086997193639,(a) 20News(9423-50-45)
"X
PT",0.80355472404116,"0
20
40
60
80"
"X
PT",0.804022450888681,Time (seconds) 1.41 1.42 1.43 1.44 1.45 1.46 1.47
"X
PT",0.804490177736202,Objective ×10 7
"X
PT",0.8049579045837231,J- JOBCD
"X
PT",0.8054256314312441,VR- J- JOBCD CSDM ADMM UMCM
"X
PT",0.8058933582787652,(b) Cifar(10000-50-45)
"X
PT",0.8063610851262862,"0
20
40
60
80"
"X
PT",0.8068288119738073,"Time (seconds) 2.50 2.
75 3.00 3.25 3.50 3.
75 4.00"
"X
PT",0.8072965388213283,Objective ×10 4
"X
PT",0.8077642656688494,J- JOBCD
"X
PT",0.8082319925163705,VR- J- JOBCD CSDM ADMM UMCM
"X
PT",0.8086997193638915,(c) CnnCaltech(3000-96-85)
"X
PT",0.8091674462114126,"0
20
40
60
80"
"X
PT",0.8096351730589336,Time (seconds) 6.9 7.0 7.1 7.2 7.3 7.4
"X
PT",0.8101028999064547,Objective ×10 4
"X
PT",0.8105706267539757,J- JOBCD
"X
PT",0.8110383536014967,VR- J- JOBCD CSDM ADMM UMCM
"X
PT",0.8115060804490177,(d) E2006(5000-100-90)
"X
PT",0.8119738072965388,"0
20
40
60
80"
"X
PT",0.8124415341440598,Time (seconds) 1.2 1.4 1.6 1.8 2.0 2.2
"X
PT",0.8129092609915809,Objective ×10 5
"X
PT",0.813376987839102,J- JOBCD
"X
PT",0.813844714686623,VR- J- JOBCD CSDM ADMM UMCM
"X
PT",0.8143124415341441,(e) Gisette(6000-50-45)
"X
PT",0.8147801683816651,"0
20
40
60
80"
"X
PT",0.8152478952291862,"Time (seconds) 6.45 6.50 6.55 6.60 6.65 6.
70"
"X
PT",0.8157156220767072,Objective ×10 6
"X
PT",0.8161833489242283,J- JOBCD
"X
PT",0.8166510757717493,VR- J- JOBCD CSDM ADMM UMCM
"X
PT",0.8171188026192704,(f) Mnist(6000-92-85)
"X
PT",0.8175865294667914,"0
20
40
60
80"
"X
PT",0.8180542563143124,Time (seconds) 8.240 8.241 8.242 8.243 8.244
"X
PT",0.8185219831618334,Objective ×10 4
"X
PT",0.8189897100093545,J- JOBCD
"X
PT",0.8194574368568756,VR- J- JOBCD CSDM ADMM UMCM
"X
PT",0.8199251637043966,(g) News20(7967-50-45)
"X
PT",0.8203928905519177,"0
20
40
60
80"
"X
PT",0.8208606173994387,"Time (seconds) 1.40 1.45 1.50 1.55 1.60 1.65 1.
70"
"X
PT",0.8213283442469598,Objective ×10 6
"X
PT",0.8217960710944808,J- JOBCD
"X
PT",0.8222637979420019,VR- J- JOBCD CSDM ADMM UMCM
"X
PT",0.8227315247895229,(h) randn(5000-100-85)
"X
PT",0.823199251637044,"0
20
40
60
80"
"X
PT",0.823666978484565,Time (seconds) 2.375 2.400 2.425 2.450 2.475 2.500 2.525
"X
PT",0.8241347053320861,Objective ×10 6
"X
PT",0.8246024321796072,J- JOBCD
"X
PT",0.8250701590271281,VR- J- JOBCD CSDM ADMM UMCM
"X
PT",0.8255378858746492,(i) randn(10000-50-45)
"X
PT",0.8260056127221702,"0
20
40
60
80"
"X
PT",0.8264733395696913,Time (seconds) 3.2 3.4 3.6 3.8 4.0
"X
PT",0.8269410664172123,Objective ×10 4
"X
PT",0.8274087932647334,J- JOBCD
"X
PT",0.8278765201122544,VR- J- JOBCD CSDM ADMM UMCM
"X
PT",0.8283442469597755,(j) W1a(2477-100-90)
"X
PT",0.8288119738072965,"Figure 7: The convergence curve of the compared methods for solving HSPP by time with varying
(m, n, p)."
"X
PT",0.8292797006548176,"F.3.3
Ultra-hyperbolic Knowledge Graph Embedding
836"
"X
PT",0.8297474275023387,"0
20
40
60
80
100 Epoch 0 200 400 600 800 1000 1200 1400"
"X
PT",0.8302151543498597,Cumulative loss
"X
PT",0.8306828811973808,J- JOBCD
"X
PT",0.8311506080449018,VR- J- JOBCD CSDM
"X
PT",0.8316183348924229,(a) Train accumulated loss
"X
PT",0.8320860617399439,"0
20
40
60
80
100 Epoch 0.05 0.10 0.15 0.20 0.25 0.30 MRR"
"X
PT",0.8325537885874649,J- JOBCD
"X
PT",0.8330215154349859,VR- J- JOBCD CSDM
"X
PT",0.833489242282507,(b) Test MRR H@10 H@3 H@1
"X
PT",0.833956969130028,(c) Test Hits
"X
PT",0.8344246959775491,"Figure 8: Epoch performance of CS, J-JOBCD, and VR-J-JOBCD in training UltraE on FB15k."
"X
PT",0.8348924228250701,"0
1000
2000
3000
4000
5000
6000
7000"
"X
PT",0.8353601496725912,Time (seconds) 0 200 400 600 800 1000 1200 1400
"X
PT",0.8358278765201123,Cumulative loss
"X
PT",0.8362956033676333,J- JOBCD
"X
PT",0.8367633302151544,VR- J- JOBCD CSDM
"X
PT",0.8372310570626754,(a) Train accumulated loss
"X
PT",0.8376987839101965,"0
1000
2000
3000
4000
5000
6000
7000"
"X
PT",0.8381665107577175,Time (seconds) 0.05 0.10 0.15 0.20 0.25 0.30 MRR
"X
PT",0.8386342376052386,J- JOBCD
"X
PT",0.8391019644527596,VR- J- JOBCD CSDM
"X
PT",0.8395696913002806,(b) Test MRR +# +#3 +#
"X
PT",0.8400374181478016,(c) Test Hits
"X
PT",0.8405051449953227,"Figure 9: Time performance of CS, J-JOBCD, and VR-J-JOBCD in training UltraE on FB15k."
"X
PT",0.8409728718428437,"0
20
40
60
80
100 Epoch 0 200 400 600 800 1000 1200 1400"
"X
PT",0.8414405986903648,Cumulative loss
"X
PT",0.8419083255378859,J- JOBCD
"X
PT",0.8423760523854069,VR- J- JOBCD CSDM
"X
PT",0.842843779232928,(a) Train accumulated loss
"X
PT",0.843311506080449,"0
20
40
60
80
100 Epoch 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 MRR"
"X
PT",0.8437792329279701,J- JOBCD
"X
PT",0.8442469597754911,VR- J- JOBCD CSDM
"X
PT",0.8447146866230122,(b) Test MRR +# +#3 +#
"X
PT",0.8451824134705332,(c) Test Hits
"X
PT",0.8456501403180543,"Figure 10: Epoch performance of CSDM, J-JOBCD, and VR-J-JOBCD in training UltraE on
WN18RR."
"X
PT",0.8461178671655754,"0
1000
2000
3000
4000
5000"
"X
PT",0.8465855940130963,Time (seconds) 0 200 400 600 800 1000 1200 1400
"X
PT",0.8470533208606174,Cumulative loss
"X
PT",0.8475210477081384,J- JOBCD
"X
PT",0.8479887745556595,VR- J- JOBCD CSDM
"X
PT",0.8484565014031805,(a) Train accumulated loss
"X
PT",0.8489242282507016,"0
1000
2000
3000
4000
5000"
"X
PT",0.8493919550982226,Time (seconds) 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 MRR
"X
PT",0.8498596819457437,J- JOBCD
"X
PT",0.8503274087932647,VR- J- JOBCD CSDM
"X
PT",0.8507951356407858,(b) Test MRR +# +#3 +#1
"X
PT",0.8512628624883068,(c) Test Hits
"X
PT",0.8517305893358279,"Figure 11: Time performance of CSDM, J-JOBCD, and VR-J-JOBCD in training UltraE on WN18RR."
"X
PT",0.852198316183349,"NeurIPS Paper Checklist
837"
CLAIMS,0.85266604303087,"1. Claims
838"
CLAIMS,0.8531337698783911,"Question: Do the main claims made in the abstract and introduction accurately reflect the
839"
CLAIMS,0.853601496725912,"paper’s contributions and scope?
840"
CLAIMS,0.8540692235734331,"Answer: [Yes]
841"
CLAIMS,0.8545369504209541,"Justification: In the abstract, we highlighted our contributions, including algorithm develop-
842"
CLAIMS,0.8550046772684752,"ment, theoretical analysis, and empirical study.
843"
CLAIMS,0.8554724041159962,"Guidelines:
844"
CLAIMS,0.8559401309635173,"• The answer NA means that the abstract and introduction do not include the claims
845"
CLAIMS,0.8564078578110383,"made in the paper.
846"
CLAIMS,0.8568755846585594,"• The abstract and/or introduction should clearly state the claims made, including the
847"
CLAIMS,0.8573433115060805,"contributions made in the paper and important assumptions and limitations. A No or
848"
CLAIMS,0.8578110383536015,"NA answer to this question will not be perceived well by the reviewers.
849"
CLAIMS,0.8582787652011226,"• The claims made should match theoretical and experimental results, and reflect how
850"
CLAIMS,0.8587464920486436,"much the results can be expected to generalize to other settings.
851"
CLAIMS,0.8592142188961647,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
852"
CLAIMS,0.8596819457436857,"are not attained by the paper.
853"
LIMITATIONS,0.8601496725912068,"2. Limitations
854"
LIMITATIONS,0.8606173994387278,"Question: Does the paper discuss the limitations of the work performed by the authors?
855"
LIMITATIONS,0.8610851262862488,"Answer: [Yes]
856"
LIMITATIONS,0.8615528531337698,"Justification: Please refer to the assumptions made for the optimization problem outlined in
857"
LIMITATIONS,0.8620205799812909,"the introduction and Section 4.
858"
LIMITATIONS,0.862488306828812,"Guidelines:
859"
LIMITATIONS,0.862956033676333,"• The answer NA means that the paper has no limitation while the answer No means that
860"
LIMITATIONS,0.8634237605238541,"the paper has limitations, but those are not discussed in the paper.
861"
LIMITATIONS,0.8638914873713751,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
862"
LIMITATIONS,0.8643592142188962,"• The paper should point out any strong assumptions and how robust the results are to
863"
LIMITATIONS,0.8648269410664172,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
864"
LIMITATIONS,0.8652946679139383,"model well-specification, asymptotic approximations only holding locally). The authors
865"
LIMITATIONS,0.8657623947614593,"should reflect on how these assumptions might be violated in practice and what the
866"
LIMITATIONS,0.8662301216089804,"implications would be.
867"
LIMITATIONS,0.8666978484565014,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
868"
LIMITATIONS,0.8671655753040225,"only tested on a few datasets or with a few runs. In general, empirical results often
869"
LIMITATIONS,0.8676333021515436,"depend on implicit assumptions, which should be articulated.
870"
LIMITATIONS,0.8681010289990645,"• The authors should reflect on the factors that influence the performance of the approach.
871"
LIMITATIONS,0.8685687558465855,"For example, a facial recognition algorithm may perform poorly when image resolution
872"
LIMITATIONS,0.8690364826941066,"is low or images are taken in low lighting. Or a speech-to-text system might not be
873"
LIMITATIONS,0.8695042095416277,"used reliably to provide closed captions for online lectures because it fails to handle
874"
LIMITATIONS,0.8699719363891487,"technical jargon.
875"
LIMITATIONS,0.8704396632366698,"• The authors should discuss the computational efficiency of the proposed algorithms
876"
LIMITATIONS,0.8709073900841908,"and how they scale with dataset size.
877"
LIMITATIONS,0.8713751169317119,"• If applicable, the authors should discuss possible limitations of their approach to
878"
LIMITATIONS,0.8718428437792329,"address problems of privacy and fairness.
879"
LIMITATIONS,0.872310570626754,"• While the authors might fear that complete honesty about limitations might be used by
880"
LIMITATIONS,0.872778297474275,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
881"
LIMITATIONS,0.8732460243217961,"limitations that aren’t acknowledged in the paper. The authors should use their best
882"
LIMITATIONS,0.8737137511693172,"judgment and recognize that individual actions in favor of transparency play an impor-
883"
LIMITATIONS,0.8741814780168382,"tant role in developing norms that preserve the integrity of the community. Reviewers
884"
LIMITATIONS,0.8746492048643593,"will be specifically instructed to not penalize honesty concerning limitations.
885"
THEORY ASSUMPTIONS AND PROOFS,0.8751169317118802,"3. Theory Assumptions and Proofs
886"
THEORY ASSUMPTIONS AND PROOFS,0.8755846585594013,"Question: For each theoretical result, does the paper provide the full set of assumptions and
887"
THEORY ASSUMPTIONS AND PROOFS,0.8760523854069223,"a complete (and correct) proof?
888"
THEORY ASSUMPTIONS AND PROOFS,0.8765201122544434,"Answer: [Yes]
889"
THEORY ASSUMPTIONS AND PROOFS,0.8769878391019644,"Justification: We have added a hyperlink before each theoretical result, which points to the
890"
THEORY ASSUMPTIONS AND PROOFS,0.8774555659494855,"complete proof located in the appendix.
891"
THEORY ASSUMPTIONS AND PROOFS,0.8779232927970065,"Guidelines:
892"
THEORY ASSUMPTIONS AND PROOFS,0.8783910196445276,"• The answer NA means that the paper does not include theoretical results.
893"
THEORY ASSUMPTIONS AND PROOFS,0.8788587464920486,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
894"
THEORY ASSUMPTIONS AND PROOFS,0.8793264733395697,"referenced.
895"
THEORY ASSUMPTIONS AND PROOFS,0.8797942001870908,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
896"
THEORY ASSUMPTIONS AND PROOFS,0.8802619270346118,"• The proofs can either appear in the main paper or the supplemental material, but if
897"
THEORY ASSUMPTIONS AND PROOFS,0.8807296538821329,"they appear in the supplemental material, the authors are encouraged to provide a short
898"
THEORY ASSUMPTIONS AND PROOFS,0.8811973807296539,"proof sketch to provide intuition.
899"
THEORY ASSUMPTIONS AND PROOFS,0.881665107577175,"• Inversely, any informal proof provided in the core of the paper should be complemented
900"
THEORY ASSUMPTIONS AND PROOFS,0.882132834424696,"by formal proofs provided in appendix or supplemental material.
901"
THEORY ASSUMPTIONS AND PROOFS,0.882600561272217,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
902"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.883068288119738,"4. Experimental Result Reproducibility
903"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8835360149672591,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
904"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8840037418147801,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
905"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8844714686623012,"of the paper (regardless of whether the code and data are provided or not)?
906"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8849391955098223,"Answer: [Yes]
907"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8854069223573433,"Justification: We have provided sufficient details for reproducing the results of the paper,
908"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8858746492048644,"such as parameter settings, runtime environments, and dataset descriptions.
909"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8863423760523854,"Guidelines:
910"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8868101028999065,"• The answer NA means that the paper does not include experiments.
911"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8872778297474275,"• If the paper includes experiments, a No answer to this question will not be perceived
912"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8877455565949486,"well by the reviewers: Making the paper reproducible is important, regardless of
913"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8882132834424696,"whether the code and data are provided or not.
914"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8886810102899907,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
915"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8891487371375117,"to make their results reproducible or verifiable.
916"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8896164639850327,"• Depending on the contribution, reproducibility can be accomplished in various ways.
917"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8900841908325537,"For example, if the contribution is a novel architecture, describing the architecture fully
918"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8905519176800748,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
919"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8910196445275959,"be necessary to either make it possible for others to replicate the model with the same
920"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8914873713751169,"dataset, or provide access to the model. In general. releasing code and data is often
921"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.891955098222638,"one good way to accomplish this, but reproducibility can also be provided via detailed
922"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.892422825070159,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
923"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8928905519176801,"of a large language model), releasing of a model checkpoint, or other means that are
924"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8933582787652011,"appropriate to the research performed.
925"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8938260056127222,"• While NeurIPS does not require releasing code, the conference does require all submis-
926"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8942937324602432,"sions to provide some reasonable avenue for reproducibility, which may depend on the
927"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8947614593077643,"nature of the contribution. For example
928"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8952291861552854,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
929"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8956969130028064,"to reproduce that algorithm.
930"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8961646398503275,"(b) If the contribution is primarily a new model architecture, the paper should describe
931"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8966323666978484,"the architecture clearly and fully.
932"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8971000935453695,"(c) If the contribution is a new model (e.g., a large language model), then there should
933"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8975678203928905,"either be a way to access this model for reproducing the results or a way to reproduce
934"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8980355472404116,"the model (e.g., with an open-source dataset or instructions for how to construct
935"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8985032740879326,"the dataset).
936"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8989710009354537,"(d) We recognize that reproducibility may be tricky in some cases, in which case
937"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8994387277829747,"authors are welcome to describe the particular way they provide for reproducibility.
938"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8999064546304958,"In the case of closed-source models, it may be that access to the model is limited in
939"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9003741814780168,"some way (e.g., to registered users), but it should be possible for other researchers
940"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9008419083255379,"to have some path to reproducing or verifying the results.
941"
OPEN ACCESS TO DATA AND CODE,0.901309635173059,"5. Open access to data and code
942"
OPEN ACCESS TO DATA AND CODE,0.90177736202058,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
943"
OPEN ACCESS TO DATA AND CODE,0.9022450888681011,"tions to faithfully reproduce the main experimental results, as described in supplemental
944"
OPEN ACCESS TO DATA AND CODE,0.9027128157156221,"material?
945"
OPEN ACCESS TO DATA AND CODE,0.9031805425631432,"Answer: [Yes]
946"
OPEN ACCESS TO DATA AND CODE,0.9036482694106641,"Justification: We have included all the code and data in the supplemental materials.
947"
OPEN ACCESS TO DATA AND CODE,0.9041159962581852,"Guidelines:
948"
OPEN ACCESS TO DATA AND CODE,0.9045837231057062,"• The answer NA means that paper does not include experiments requiring code.
949"
OPEN ACCESS TO DATA AND CODE,0.9050514499532273,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
950"
OPEN ACCESS TO DATA AND CODE,0.9055191768007483,"public/guides/CodeSubmissionPolicy) for more details.
951"
OPEN ACCESS TO DATA AND CODE,0.9059869036482694,"• While we encourage the release of code and data, we understand that this might not be
952"
OPEN ACCESS TO DATA AND CODE,0.9064546304957904,"possible, so ”No” is an acceptable answer. Papers cannot be rejected simply for not
953"
OPEN ACCESS TO DATA AND CODE,0.9069223573433115,"including code, unless this is central to the contribution (e.g., for a new open-source
954"
OPEN ACCESS TO DATA AND CODE,0.9073900841908326,"benchmark).
955"
OPEN ACCESS TO DATA AND CODE,0.9078578110383536,"• The instructions should contain the exact command and environment needed to run to
956"
OPEN ACCESS TO DATA AND CODE,0.9083255378858747,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
957"
OPEN ACCESS TO DATA AND CODE,0.9087932647333957,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
958"
OPEN ACCESS TO DATA AND CODE,0.9092609915809168,"• The authors should provide instructions on data access and preparation, including how
959"
OPEN ACCESS TO DATA AND CODE,0.9097287184284378,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
960"
OPEN ACCESS TO DATA AND CODE,0.9101964452759589,"• The authors should provide scripts to reproduce all experimental results for the new
961"
OPEN ACCESS TO DATA AND CODE,0.9106641721234799,"proposed method and baselines. If only a subset of experiments are reproducible, they
962"
OPEN ACCESS TO DATA AND CODE,0.9111318989710009,"should state which ones are omitted from the script and why.
963"
OPEN ACCESS TO DATA AND CODE,0.9115996258185219,"• At submission time, to preserve anonymity, the authors should release anonymized
964"
OPEN ACCESS TO DATA AND CODE,0.912067352666043,"versions (if applicable).
965"
OPEN ACCESS TO DATA AND CODE,0.912535079513564,"• Providing as much information as possible in supplemental material (appended to the
966"
OPEN ACCESS TO DATA AND CODE,0.9130028063610851,"paper) is recommended, but including URLs to data and code is permitted.
967"
OPEN ACCESS TO DATA AND CODE,0.9134705332086062,"6. Experimental Setting/Details
968"
OPEN ACCESS TO DATA AND CODE,0.9139382600561272,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
969"
OPEN ACCESS TO DATA AND CODE,0.9144059869036483,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
970"
OPEN ACCESS TO DATA AND CODE,0.9148737137511693,"results?
971"
OPEN ACCESS TO DATA AND CODE,0.9153414405986904,"Answer: [Yes]
972"
OPEN ACCESS TO DATA AND CODE,0.9158091674462114,"Justification: We have provided sufficient details for solving the optimization problem,
973"
OPEN ACCESS TO DATA AND CODE,0.9162768942937325,"encompassing hyperparameter settings and dataset generation.
974"
OPEN ACCESS TO DATA AND CODE,0.9167446211412535,"Guidelines:
975"
OPEN ACCESS TO DATA AND CODE,0.9172123479887746,"• The answer NA means that the paper does not include experiments.
976"
OPEN ACCESS TO DATA AND CODE,0.9176800748362957,"• The experimental setting should be presented in the core of the paper to a level of detail
977"
OPEN ACCESS TO DATA AND CODE,0.9181478016838166,"that is necessary to appreciate the results and make sense of them.
978"
OPEN ACCESS TO DATA AND CODE,0.9186155285313377,"• The full details can be provided either with the code, in appendix, or as supplemental
979"
OPEN ACCESS TO DATA AND CODE,0.9190832553788587,"material.
980"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9195509822263798,"7. Experiment Statistical Significance
981"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9200187090739008,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
982"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9204864359214219,"information about the statistical significance of the experiments?
983"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9209541627689429,"Answer: [No]
984"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.921421889616464,"Justification: For simplicity, we only demonstrate the convergence behavior of the objective
985"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.921889616463985,"function by varying the time or iterations. Our methods exhibit clear advantages over the
986"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9223573433115061,"compared methods. Such results have demonstrated significance in the experiments.
987"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9228250701590271,"Guidelines:
988"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9232927970065482,"• The answer NA means that the paper does not include experiments.
989"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9237605238540693,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
990"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9242282507015903,"dence intervals, or statistical significance tests, at least for the experiments that support
991"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9246959775491114,"the main claims of the paper.
992"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9251637043966323,"• The factors of variability that the error bars are capturing should be clearly stated (for
993"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9256314312441534,"example, train/test split, initialization, random drawing of some parameter, or overall
994"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9260991580916744,"run with given experimental conditions).
995"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9265668849391955,"• The method for calculating the error bars should be explained (closed form formula,
996"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9270346117867165,"call to a library function, bootstrap, etc.)
997"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9275023386342376,"• The assumptions made should be given (e.g., Normally distributed errors).
998"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9279700654817586,"• It should be clear whether the error bar is the standard deviation or the standard error
999"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9284377923292797,"of the mean.
1000"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9289055191768008,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
1001"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9293732460243218,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
1002"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9298409728718429,"of Normality of errors is not verified.
1003"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9303086997193639,"• For asymmetric distributions, the authors should be careful not to show in tables or
1004"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.930776426566885,"figures symmetric error bars that would yield results that are out of range (e.g. negative
1005"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.931244153414406,"error rates).
1006"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9317118802619271,"• If error bars are reported in tables or plots, The authors should explain in the text how
1007"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.932179607109448,"they were calculated and reference the corresponding figures or tables in the text.
1008"
EXPERIMENTS COMPUTE RESOURCES,0.9326473339569691,"8. Experiments Compute Resources
1009"
EXPERIMENTS COMPUTE RESOURCES,0.9331150608044901,"Question: For each experiment, does the paper provide sufficient information on the com-
1010"
EXPERIMENTS COMPUTE RESOURCES,0.9335827876520112,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
1011"
EXPERIMENTS COMPUTE RESOURCES,0.9340505144995322,"the experiments?
1012"
EXPERIMENTS COMPUTE RESOURCES,0.9345182413470533,"Answer: [Yes]
1013"
EXPERIMENTS COMPUTE RESOURCES,0.9349859681945744,"Justification:
1014"
EXPERIMENTS COMPUTE RESOURCES,0.9354536950420954,"Guidelines: We have outlined the types of compute workers, detailing CPU and memory
1015"
EXPERIMENTS COMPUTE RESOURCES,0.9359214218896165,"specifications.
1016"
EXPERIMENTS COMPUTE RESOURCES,0.9363891487371375,"• The answer NA means that the paper does not include experiments.
1017"
EXPERIMENTS COMPUTE RESOURCES,0.9368568755846586,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
1018"
EXPERIMENTS COMPUTE RESOURCES,0.9373246024321796,"or cloud provider, including relevant memory and storage.
1019"
EXPERIMENTS COMPUTE RESOURCES,0.9377923292797007,"• The paper should provide the amount of compute required for each of the individual
1020"
EXPERIMENTS COMPUTE RESOURCES,0.9382600561272217,"experimental runs as well as estimate the total compute.
1021"
EXPERIMENTS COMPUTE RESOURCES,0.9387277829747428,"• The paper should disclose whether the full research project required more compute
1022"
EXPERIMENTS COMPUTE RESOURCES,0.9391955098222639,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
1023"
EXPERIMENTS COMPUTE RESOURCES,0.9396632366697848,"didn’t make it into the paper).
1024"
CODE OF ETHICS,0.9401309635173059,"9. Code Of Ethics
1025"
CODE OF ETHICS,0.9405986903648269,"Question: Does the research conducted in the paper conform, in every respect, with the
1026"
CODE OF ETHICS,0.941066417212348,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
1027"
CODE OF ETHICS,0.941534144059869,"Answer: [Yes]
1028"
CODE OF ETHICS,0.9420018709073901,"Justification: Our research aligns with the ethical guidelines outlined by NeurIPS.
1029"
CODE OF ETHICS,0.9424695977549111,"Guidelines:
1030"
CODE OF ETHICS,0.9429373246024322,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
1031"
CODE OF ETHICS,0.9434050514499532,"• If the authors answer No, they should explain the special circumstances that require a
1032"
CODE OF ETHICS,0.9438727782974743,"deviation from the Code of Ethics.
1033"
CODE OF ETHICS,0.9443405051449953,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
1034"
CODE OF ETHICS,0.9448082319925164,"eration due to laws or regulations in their jurisdiction).
1035"
BROADER IMPACTS,0.9452759588400375,"10. Broader Impacts
1036"
BROADER IMPACTS,0.9457436856875585,"Question: Does the paper discuss both potential positive societal impacts and negative
1037"
BROADER IMPACTS,0.9462114125350796,"societal impacts of the work performed?
1038"
BROADER IMPACTS,0.9466791393826005,"Answer: [NA]
1039"
BROADER IMPACTS,0.9471468662301216,"Justification: The paper addresses theoretical questions on algorithm complexity, which, to
1040"
BROADER IMPACTS,0.9476145930776426,"the best of our knowledge, pose no negative social impact.
1041"
BROADER IMPACTS,0.9480823199251637,"Guidelines:
1042"
BROADER IMPACTS,0.9485500467726847,"• The answer NA means that there is no societal impact of the work performed.
1043"
BROADER IMPACTS,0.9490177736202058,"• If the authors answer NA or No, they should explain why their work has no societal
1044"
BROADER IMPACTS,0.9494855004677268,"impact or why the paper does not address societal impact.
1045"
BROADER IMPACTS,0.9499532273152479,"• Examples of negative societal impacts include potential malicious or unintended uses
1046"
BROADER IMPACTS,0.950420954162769,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
1047"
BROADER IMPACTS,0.95088868101029,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
1048"
BROADER IMPACTS,0.9513564078578111,"groups), privacy considerations, and security considerations.
1049"
BROADER IMPACTS,0.9518241347053321,"• The conference expects that many papers will be foundational research and not tied
1050"
BROADER IMPACTS,0.9522918615528532,"to particular applications, let alone deployments. However, if there is a direct path to
1051"
BROADER IMPACTS,0.9527595884003742,"any negative applications, the authors should point it out. For example, it is legitimate
1052"
BROADER IMPACTS,0.9532273152478953,"to point out that an improvement in the quality of generative models could be used to
1053"
BROADER IMPACTS,0.9536950420954162,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
1054"
BROADER IMPACTS,0.9541627689429373,"that a generic algorithm for optimizing neural networks could enable people to train
1055"
BROADER IMPACTS,0.9546304957904583,"models that generate Deepfakes faster.
1056"
BROADER IMPACTS,0.9550982226379794,"• The authors should consider possible harms that could arise when the technology is
1057"
BROADER IMPACTS,0.9555659494855004,"being used as intended and functioning correctly, harms that could arise when the
1058"
BROADER IMPACTS,0.9560336763330215,"technology is being used as intended but gives incorrect results, and harms following
1059"
BROADER IMPACTS,0.9565014031805426,"from (intentional or unintentional) misuse of the technology.
1060"
BROADER IMPACTS,0.9569691300280636,"• If there are negative societal impacts, the authors could also discuss possible mitigation
1061"
BROADER IMPACTS,0.9574368568755847,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
1062"
BROADER IMPACTS,0.9579045837231057,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
1063"
BROADER IMPACTS,0.9583723105706268,"feedback over time, improving the efficiency and accessibility of ML).
1064"
SAFEGUARDS,0.9588400374181478,"11. Safeguards
1065"
SAFEGUARDS,0.9593077642656689,"Question: Does the paper describe safeguards that have been put in place for responsible
1066"
SAFEGUARDS,0.9597754911131899,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
1067"
SAFEGUARDS,0.960243217960711,"image generators, or scraped datasets)?
1068"
SAFEGUARDS,0.960710944808232,"Answer: [NA]
1069"
SAFEGUARDS,0.961178671655753,"Justification: The paper poses no such risks.
1070"
SAFEGUARDS,0.961646398503274,"Guidelines:
1071"
SAFEGUARDS,0.9621141253507951,"• The answer NA means that the paper poses no such risks.
1072"
SAFEGUARDS,0.9625818521983162,"• Released models that have a high risk for misuse or dual-use should be released with
1073"
SAFEGUARDS,0.9630495790458372,"necessary safeguards to allow for controlled use of the model, for example by requiring
1074"
SAFEGUARDS,0.9635173058933583,"that users adhere to usage guidelines or restrictions to access the model or implementing
1075"
SAFEGUARDS,0.9639850327408793,"safety filters.
1076"
SAFEGUARDS,0.9644527595884004,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
1077"
SAFEGUARDS,0.9649204864359214,"should describe how they avoided releasing unsafe images.
1078"
SAFEGUARDS,0.9653882132834425,"• We recognize that providing effective safeguards is challenging, and many papers do
1079"
SAFEGUARDS,0.9658559401309635,"not require this, but we encourage authors to take this into account and make a best
1080"
SAFEGUARDS,0.9663236669784846,"faith effort.
1081"
LICENSES FOR EXISTING ASSETS,0.9667913938260057,"12. Licenses for existing assets
1082"
LICENSES FOR EXISTING ASSETS,0.9672591206735267,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
1083"
LICENSES FOR EXISTING ASSETS,0.9677268475210478,"the paper, properly credited and are the license and terms of use explicitly mentioned and
1084"
LICENSES FOR EXISTING ASSETS,0.9681945743685687,"properly respected?
1085"
LICENSES FOR EXISTING ASSETS,0.9686623012160898,"Answer: [Yes]
1086"
LICENSES FOR EXISTING ASSETS,0.9691300280636108,"Justification: The dataset used in the experiments is published on an open site without
1087"
LICENSES FOR EXISTING ASSETS,0.9695977549111319,"license.
1088"
LICENSES FOR EXISTING ASSETS,0.9700654817586529,"Guidelines:
1089"
LICENSES FOR EXISTING ASSETS,0.970533208606174,"• The answer NA means that the paper does not use existing assets.
1090"
LICENSES FOR EXISTING ASSETS,0.971000935453695,"• The authors should cite the original paper that produced the code package or dataset.
1091"
LICENSES FOR EXISTING ASSETS,0.9714686623012161,"• The authors should state which version of the asset is used and, if possible, include a
1092"
LICENSES FOR EXISTING ASSETS,0.9719363891487371,"URL.
1093"
LICENSES FOR EXISTING ASSETS,0.9724041159962582,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
1094"
LICENSES FOR EXISTING ASSETS,0.9728718428437793,"• For scraped data from a particular source (e.g., website), the copyright and terms of
1095"
LICENSES FOR EXISTING ASSETS,0.9733395696913003,"service of that source should be provided.
1096"
LICENSES FOR EXISTING ASSETS,0.9738072965388214,"• If assets are released, the license, copyright information, and terms of use in the
1097"
LICENSES FOR EXISTING ASSETS,0.9742750233863424,"package should be provided. For popular datasets, paperswithcode.com/datasets
1098"
LICENSES FOR EXISTING ASSETS,0.9747427502338635,"has curated licenses for some datasets. Their licensing guide can help determine the
1099"
LICENSES FOR EXISTING ASSETS,0.9752104770813844,"license of a dataset.
1100"
LICENSES FOR EXISTING ASSETS,0.9756782039289055,"• For existing datasets that are re-packaged, both the original license and the license of
1101"
LICENSES FOR EXISTING ASSETS,0.9761459307764265,"the derived asset (if it has changed) should be provided.
1102"
LICENSES FOR EXISTING ASSETS,0.9766136576239476,"• If this information is not available online, the authors are encouraged to reach out to
1103"
LICENSES FOR EXISTING ASSETS,0.9770813844714686,"the asset’s creators.
1104"
NEW ASSETS,0.9775491113189897,"13. New Assets
1105"
NEW ASSETS,0.9780168381665107,"Question: Are new assets introduced in the paper well documented and is the documentation
1106"
NEW ASSETS,0.9784845650140318,"provided alongside the assets?
1107"
NEW ASSETS,0.9789522918615529,"Answer: [NA]
1108"
NEW ASSETS,0.9794200187090739,"Justification: The experiments do not involve new datasets.
1109"
NEW ASSETS,0.979887745556595,"Guidelines:
1110"
NEW ASSETS,0.980355472404116,"• The answer NA means that the paper does not release new assets.
1111"
NEW ASSETS,0.9808231992516371,"• Researchers should communicate the details of the dataset/code/model as part of their
1112"
NEW ASSETS,0.9812909260991581,"submissions via structured templates. This includes details about training, license,
1113"
NEW ASSETS,0.9817586529466792,"limitations, etc.
1114"
NEW ASSETS,0.9822263797942001,"• The paper should discuss whether and how consent was obtained from people whose
1115"
NEW ASSETS,0.9826941066417212,"asset is used.
1116"
NEW ASSETS,0.9831618334892422,"• At submission time, remember to anonymize your assets (if applicable). You can either
1117"
NEW ASSETS,0.9836295603367633,"create an anonymized URL or include an anonymized zip file.
1118"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9840972871842844,"14. Crowdsourcing and Research with Human Subjects
1119"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9845650140318054,"Question: For crowdsourcing experiments and research with human subjects, does the paper
1120"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9850327408793265,"include the full text of instructions given to participants and screenshots, if applicable, as
1121"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9855004677268475,"well as details about compensation (if any)?
1122"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9859681945743686,"Answer: [NA]
1123"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9864359214218896,"Justification: No crowdsourcing or human object is involved.
1124"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9869036482694107,"Guidelines:
1125"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9873713751169317,"• The answer NA means that the paper does not involve crowdsourcing nor research with
1126"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9878391019644528,"human subjects.
1127"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9883068288119738,"• Including this information in the supplemental material is fine, but if the main contribu-
1128"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9887745556594949,"tion of the paper involves human subjects, then as much detail as possible should be
1129"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.989242282507016,"included in the main paper.
1130"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9897100093545369,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
1131"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.990177736202058,"or other labor should be paid at least the minimum wage in the country of the data
1132"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.990645463049579,"collector.
1133"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9911131898971001,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
1134"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9915809167446211,"Subjects
1135"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9920486435921422,"Question: Does the paper describe potential risks incurred by study participants, whether
1136"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9925163704396632,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
1137"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9929840972871843,"approvals (or an equivalent approval/review based on the requirements of your country or
1138"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9934518241347053,"institution) were obtained?
1139"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9939195509822264,"Answer: [NA]
1140"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9943872778297475,"Justification: No crowdsourcing or human object is involved.
1141"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9948550046772685,"Guidelines:
1142"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9953227315247896,"• The answer NA means that the paper does not involve crowdsourcing nor research with
1143"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9957904583723106,"human subjects.
1144"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9962581852198317,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
1145"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9967259120673526,"may be required for any human subjects research. If you obtained IRB approval, you
1146"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9971936389148737,"should clearly state this in the paper.
1147"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9976613657623947,"• We recognize that the procedures for this may vary significantly between institutions
1148"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9981290926099158,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
1149"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9985968194574368,"guidelines for their institution.
1150"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9990645463049579,"• For initial submissions, do not include any information that would break anonymity (if
1151"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.999532273152479,"applicable), such as the institution conducting the review.
1152"
