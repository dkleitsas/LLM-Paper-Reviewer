Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0017152658662092624,"A key challenge facing deep learning is that neural networks are often not robust
to shifts in the underlying data distribution. We study this problem from the
perspective of the statistical concept of parameter identiﬁcation. Generalization
bounds from learning theory often assume that the test distribution is close to the
training distribution. In contrast, if we can identify the “true” parameters, then
the model generalizes to arbitrary distribution shifts. However, neural networks
are typically over-parameterized, making parameter identiﬁcation impossible. We
show that for quadratic neural networks, we can identify the function represented
by the model even though we cannot identify its parameters. Thus, we can obtain
robust generalization bounds even in the over-parameterized setting. We leverage
this result to obtain new bounds for contextual bandits and transfer learning with
quadratic neural networks. Overall, our results suggest that we can improve
robustness of neural networks by designing models that can represent the true
data generating process. In practice, the true data generating process is often very
complex; thus, we study how our framework might connect to neural module
networks, which are designed to break down complex tasks into compositions
of simpler ones. We prove robust generalization bounds when individual neural
modules are identiﬁable."
INTRODUCTION,0.003430531732418525,"1
INTRODUCTION"
INTRODUCTION,0.005145797598627788,"Recent work has demonstrated that neural networks are not robust to shifts in the underlying data,
including both distribution shifts (i.e., where the data comes from a new distribution independent of the
neural network parameters) (Hendrycks & Dietterich, 2019; Taori et al., 2020) as well as adversarial
shifts (i.e., where the shift can depend on the neural network parameters) (Szegedy et al., 2013).
Accordingly, there has been a great deal of interest in better understanding why neural networks fail
to be robust (Tsipras et al., 2018; Ilyas et al., 2019) and on improving robustness (Goodfellow et al.,
2014; Raghunathan et al., 2018; Cohen et al., 2019)."
INTRODUCTION,0.00686106346483705,"From the perspective of learning theory, there is little reason to expect neural networks to be robust,
since generalization bounds typically assume that the test examples are from the same distribution as
the training examples. PAC-Bayesian generalization bounds allow for a limited amount of robustness,
but only if the support of the target distribution q is contained in that of the source distribution p,
since it requires that the KL divergence DKL(q ∥p) is ﬁnite. Yet, distribution shifts (Hendrycks &
Dietterich, 2019) often shift probability mass to inputs completely outside the source distribution."
INTRODUCTION,0.008576329331046312,"Instead, the reason we might expect neural networks to be robust to these shifts is that humans are
robust to them; for instance, small pixel-level shifts considered in adversarial examples are typically
unnoticeable to humans, yet these shifts can move the image completely off of the distribution of
natural images. This fact indicates a gap in our theoretical understanding of neural networks. In
particular, the key question is understanding settings under which we may expect neural networks to
be robust to distribution shifts that are “large” (e.g., in terms of KL divergence)."
INTRODUCTION,0.010291595197255575,"We study a strategy for closing this gap based on the statistical concept of identiﬁability (Hsu et al.,
2012). At a high level, this concept assumes that the true model belongs to the model family; then, in
the limit of inﬁnite training data, the learning algorithm can exactly recover the parameters of the true
model. For instance, in linear regression, the data is generated according to the model y = ⟨θ∗, x⟩+ξ,
where ξ is σ-subgaussian noise. Then, under mild assumptions on the training data Z = (X, Y ), the"
INTRODUCTION,0.012006861063464836,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.0137221269296741,"ordinary least squares (OLS) estimator ˆθ(Z) recovers the true parameter—i.e., in the limit of inﬁnite
data, ˆθ(Z) = θ∗. With ﬁnite samples, OLS satisﬁes high-probability convergence rates of the form"
INTRODUCTION,0.015437392795883362,"∥ˆθ(Z) −θ∗∥2 ≤ϵ.
(1)"
INTRODUCTION,0.017152658662092625,"The connection to robustness is that if (1) holds, then for any input x such that ∥x∥2 ≤xmax, we have"
INTRODUCTION,0.018867924528301886,"|⟨ˆθ(Z), x⟩−⟨θ∗, x⟩| ≤∥ˆθ(Z) −θ∗∥2 · ∥x∥2 ≤ϵ · xmax.
(2)"
INTRODUCTION,0.02058319039451115,"Thus, for any distribution q(x) with support on B2(0, xmax) = {x ∈X | ∥x∥2 ≤xmax}, ˆθ(Z) obtains
bounded error—i.e., we have Eq(x)[(⟨ˆθ(Z), x⟩−⟨θ∗, x⟩)2] ≤ϵ2x2
max with high probability."
INTRODUCTION,0.022298456260720412,"Thus, a natural question is whether we can obtain similar kinds of parameter identiﬁcation bounds for
neural networks. A key complication is that practical neural networks are often over-parameterized,
possibly to facilitate optimization (Du & Lee, 2018; Jacot et al., 2018). In this setting, identiﬁcation
is impossible, since multiple parameters can yield the same model. Nevertheless, it may be possible
to obtain bounds of the form (2)—in particular, even if we do not recover the true parameters θ∗, we
can still recover the function fθ∗(x). We refer to this notion as function identiﬁcation. Furthermore,
we show that quadratic neural networks satisfy function identiﬁcation bounds under mild conditions."
INTRODUCTION,0.024013722126929673,"To demonstrate its utility, we show how function identiﬁcation can be leveraged to obtain regret
guarantees for a bandit (Rusmevichientong & Tsitsiklis, 2010) where each arm is a quadratic neural
network. Linear bandits fundamentally involve covariate shift since their “covariates” are arms, which
are adaptively chosen through the learning process as a function of past observations; thus, existing
approaches have all operated in the setting where there is a unique and identiﬁable global minimizer.
Similarly, we build on recent work proving bounds on transfer learning in the setting of bounded
label shift and unbounded covariate shift (Bastani, 2020; Xu et al., 2021); again, we show that we can
leverage function identiﬁcation to easily transfer learn quadratic neural networks."
INTRODUCTION,0.025728987993138937,"Our results suggest that one strategy for improving robustness of neural networks is to design models
that can represent the true data generating process. However, doing so can be challenging due to the
complexity of most real-world data generating processes mapping covariates to labels—e.g., mapping
natural language to semantic meaning or images to object detections and labels. As a consequence,
we study how our results can connect to neural module networks (Andreas et al., 2016), which are
designed to break down complex tasks into smaller ones that can each be solved by a neural network.
For instance, we may break down the task “count the number of red balls in image x” into (i) detecting
balls, (ii) detecting red objects, and (iii) intersecting the two sets, and (iv) summing the results."
INTRODUCTION,0.0274442538593482,"Intuitively, neural modules can generalize more robustly since (i) it is more likely that an individual
neural module designed to solve a simple task can be identiﬁed from training data, and (ii) even if
module composition is not itself identiﬁable, shifts in the compositional structure tend to be smaller
than shifts in the underlying data distribution. We study a simpliﬁed form of neural module networks,
where modules are quadratic neural networks composed in sequence according to a given input; for
simplicity, we assume they can be trained in a supervised way, ensuring robust generalization. Then,
we show that under certain conditions, compositions of these models are also robust, including the
case where there are shifts in the distribution over compositions."
INTRODUCTION,0.029159519725557463,"Related work. Prior work has connected misspeciﬁcation (i.e., the true model is in the model family)
and robustness to covariate shift (Shimodaira, 2000; Wen et al., 2014); however, having a correctly
speciﬁed model is insufﬁcient if the true parameters are not identiﬁable—e.g., in linear regression, if
the covariance matrix Σ = Ep(x)[xx⊤] is singular, then θ is not identiﬁable; thus, the estimated model
may not be robust. Quadratic neural networks cannot be identiﬁed even if the model is correctly
speciﬁed since the parameters have a continuous symmetry (i.e., orthogonal transformations)."
INTRODUCTION,0.030874785591766724,"Recent work has studied learning under adversarial examples (Goodfellow et al., 2014; Raghunathan
et al., 2018; Cohen et al., 2019) and corrupted training data (Steinhardt et al., 2017; Diakonikolas
et al., 2019). In contrast, we are interested in robustness to covariate shift; there has been recent work
empirically showing that neural networks are sensitive to distribution shift (Hendrycks & Dietterich,
2019; Taori et al., 2020; Ruis et al., 2020; Ribeiro et al., 2020; Koh et al., 2020). Distributionally
robust optimization enables training of models robust to small shifts (Duchi & Namkoong, 2018), but
we are interested in potentially large shifts. Unsupervised domain adaptation (Ben-David et al., 2007;
Blitzer et al., 2008) learns a model on a covariate shifted target distribution; however, they rely on
unlabeled examples from the target domain, whereas we do not. There has been recent theory on"
INTRODUCTION,0.032590051457975985,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.03430531732418525,"robustness to adversarial perturbations—e.g., showing there may be a tradeoff between robustness
and on-distribution generalization (Tsipras et al., 2018), and that non-robust algorithms tend to learn
predictive but brittle representations compared to adversarially robust ones (Ilyas et al., 2019). In
contrast, we show that these tradeoffs are mitigated when the true model function can be identiﬁed
despite over-parameterization. Furthermore, adversarial shifts are typically bounded (e.g., small ℓ∞
norm), whereas the shifts we consider may be large."
INTRODUCTION,0.036020583190394515,"There has been a great deal of recent work on deep learning theory, including on quadratic neural
networks; however, it has largely focused on optimization (Ge et al., 2017b; Jacot et al., 2018;
Du et al., 2019; Gao et al., 2019; Soltanolkotabi et al., 2018; Li et al., 2018), and on-distribution
generalization (Neyshabur et al., 2017; Du & Lee, 2018; Jacot et al., 2018; Arora et al., 2018; Long
& Sedghi, 2019). In contrast, we are interested in out-of-distribution generalization."
INTRODUCTION,0.03773584905660377,"We discuss additional related work on matrix factorization and multi-armed bandits in Appendix A,
as well as a discussion of the novelty of our results."
PROBLEM FORMULATION,0.03945111492281304,"2
PROBLEM FORMULATION"
PROBLEM FORMULATION,0.0411663807890223,"We consider a model fθ : X →Y, with covariates X ⊆Rd, labels Y ⊆R, and parameters
θ ∈Θ ⊆Rm. A generalization bound from learning theory typically has the form"
PROBLEM FORMULATION,0.04288164665523156,"Pp(Z)[Lp(ˆθ(Z)) ≤ϵ] ≥1 −δ
where
Lp(θ) = Ep(x)[(fθ(x) −fθ∗(x))2],
(3)"
PROBLEM FORMULATION,0.044596912521440824,"where ϵ, δ ∈R>0, Z = {(x1, y1), ..., (xn, yn)} ⊆X × Y with yi = fθ∗(xi) + ξi is a training set of
i.i.d. observations from a distribution p (i.e., p(Z) = p(x1, y1) · ... · p(xn, yn)), ξi is bounded random
noise independent of xi with |ξi| ≤ξmax, θ∗∈Θ are the true parameters, and"
PROBLEM FORMULATION,0.04631217838765009,"ˆθ(Z) = arg min
θ∈Θ
ˆL(θ; Z)
where
ˆL(θ; Z) = 1 n n
X"
PROBLEM FORMULATION,0.048027444253859346,"i=1
(fθ(xi) −yi)2"
PROBLEM FORMULATION,0.04974271012006861,"is an estimator based on the training data Z.1 In particular, they assume that the training inputs
xi ∼p are i.i.d. samples from the same distribution as the test example x ∼p."
PROBLEM FORMULATION,0.051457975986277875,"Deﬁnition 2.1. The model fθ and distribution p satisfy function identiﬁcation if for any ϵ, δ ∈R>0,
we have Pp(Z)[∀x ∈X . (fˆθ(Z)(x) −fθ∗(x))2 ≤ϵ] ≥1 −δ for n = |Z| sufﬁciently large."
PROBLEM FORMULATION,0.05317324185248713,"Function identiﬁcation implies generalization bounds even when the test data comes from a different
distribution q. In particular, we say fθ robustly generalizes if for any q with support on X, we have"
PROBLEM FORMULATION,0.0548885077186964,"Pp(Z)[Lq(ˆθ(Z)) ≤ϵ] ≥1 −δ,
(4)"
PROBLEM FORMULATION,0.05660377358490566,"where the difference from (3) has been highlighted in red. It is easy to see that function identiﬁcation
implies (4). Note that the true model fθ∗does not change, so there is no label shift."
FUNCTION IDENTIFICATION OF QUADRATIC NEURAL NETWORKS,0.058319039451114926,"3
FUNCTION IDENTIFICATION OF QUADRATIC NEURAL NETWORKS"
FUNCTION IDENTIFICATION OF QUADRATIC NEURAL NETWORKS,0.060034305317324184,"Traditional statistical bounds on parameter identiﬁcation can provide guarantees for arbitrary covariate
shift. In particular, suppose we have a bound of the form"
FUNCTION IDENTIFICATION OF QUADRATIC NEURAL NETWORKS,0.06174957118353345,"Pp(Z)
h
∥ˆθ(Z) −θ∗∥2 ≤ϵ
i
≥1 −δ,
(5)"
FUNCTION IDENTIFICATION OF QUADRATIC NEURAL NETWORKS,0.0634648370497427,"and assume that the model family fθ is K-Lipschitz continuous in θ; then, we have"
FUNCTION IDENTIFICATION OF QUADRATIC NEURAL NETWORKS,0.06518010291595197,"Lq(ˆθ(Z)) ≤K2 · ∥ˆθ(Z) −θ∗∥2
2 ≤K2ϵ2
(6)"
FUNCTION IDENTIFICATION OF QUADRATIC NEURAL NETWORKS,0.06689536878216124,"with probability at least 1 −δ according to p(Z). In particular, this bound holds for any covariate
distribution q. Our goal is to extend these techniques to quadratic neural networks, which are
over-parameterized so we cannot identify the true parameters θ∗—i.e., (5) does not hold."
FUNCTION IDENTIFICATION OF QUADRATIC NEURAL NETWORKS,0.0686106346483705,"1Note that in (3), the loss Lp omits the label errors ξ; including it would result in an additive constant to Lp.
This choice ensures that the optimal parameters have zero loss—i.e., Lq(θ∗) = 0 for any q."
FUNCTION IDENTIFICATION OF QUADRATIC NEURAL NETWORKS,0.07032590051457976,Under review as a conference paper at ICLR 2022
QUADRATIC NEURAL NETWORKS,0.07204116638078903,"3.1
QUADRATIC NEURAL NETWORKS"
QUADRATIC NEURAL NETWORKS,0.07375643224699828,"We consider a neural network fθ, where θ ∈Rd×k, with a single hidden layer with k neurons—i.e.,
fθ(x) = Pk
j=1 aj · σ(⟨θj, x⟩). We consider the over-parameterization case where k can be much
larger than d. Following prior work (Du & Lee, 2018), we assume that fθ has quadratic activations
and output weights equal to one—i.e., σ(z) = z2 and aj = 1 for each j ∈[k], so we have"
QUADRATIC NEURAL NETWORKS,0.07547169811320754,"fθ(x) = k
X"
QUADRATIC NEURAL NETWORKS,0.07718696397941681,"j=1
⟨θj, x⟩2."
QUADRATIC NEURAL NETWORKS,0.07890222984562607,"We assume the true (training) loss is the mean-squared error Lp(θ) = Ep(x)[(fθ(x) −fθ∗(x))2], and
we consider a model trained using an empirical estimate of this loss on the training dataset:"
QUADRATIC NEURAL NETWORKS,0.08061749571183534,"ˆθ(Z) = arg min
θ∈Θ
ˆL(θ; Z)
where
ˆL(θ; Z) = 1 n n
X"
QUADRATIC NEURAL NETWORKS,0.0823327615780446,"i=1
(fθ(xi) −yi)2."
QUADRATIC NEURAL NETWORKS,0.08404802744425385,"Now, our goal is to obtain a bound of the form (6); to this end, we assume the following:
Assumption 3.1. ∥x∥2 ≤xmax and ∥θ∥F ≤θmax.
Assumption 3.2. There exists α ∈R>0 such that Ep(x)[(x⊤∆x)2] ≥α∥∆∥2
F for any symmetric
∆∈Rd×d."
QUADRATIC NEURAL NETWORKS,0.08576329331046312,"Our second assumption is standard; in particular, it is closely related to the assumption in linear
regression that the minimum eigenvalue of the covariance matrix is lower bounded—i.e., Σ =
Ep(x)[xx⊤] ≻0. As an example, when x is i.i.d. uniform in each component, e.g., p(x) =
Qd
i=1 Uniform(xi; [−1/2, 1/2]), then we can take α = 1/180; we give a proof in Appendix B.1."
ROBUST GENERALIZATION,0.08747855917667238,"3.2
ROBUST GENERALIZATION"
ROBUST GENERALIZATION,0.08919382504288165,"Our approach leverages the fact that fθ(x) = x⊤(θθ⊤)x; thus, fθ resembles a matrix factorization
model. Recent work has leveraged this connection to translate matrix factorization theory to quadratic
neural networks (Du & Lee, 2018). We let g(θ) = θθ⊤and ˜fφ(x) = x⊤φx, where φ ∈Φ ⊆Rd×d, in
which case fθ(x) = ˜fg(θ)(x); in addition, we deﬁne ˜Lp(φ) = Ep(x)[( ˜fφ(x)−˜fφ∗(x))2], where φ∗="
ROBUST GENERALIZATION,0.09090909090909091,"g(θ∗), and ˆ˜L(φ; Z) = n−1 Pn
i=1( ˜fφ(xi) −yi)2, so Lp(θ) = ˜Lp(g(θ)) and ˆL(θ; Z) = ˆ˜L(g(θ); Z).
Finally, we assume that ∥φ∥F ≤φmax; in general, we have φmax ≤θ2
max by Assumption 3.1."
ROBUST GENERALIZATION,0.09262435677530018,"We begin by stating several lemmas establishing the properties needed for function identiﬁcation.
Our ﬁrst lemma says that the loss is strongly convex in φ."
ROBUST GENERALIZATION,0.09433962264150944,"Lemma 3.3. Under Assumption 3.2, the loss ˜Lp(φ) is 2α-strongly convex in φ."
ROBUST GENERALIZATION,0.09605488850771869,We give a proof in Appendix B.2. Our next lemma says that our model family is Lipschitz in φ.
ROBUST GENERALIZATION,0.09777015437392796,"Lemma 3.4. Under Assumptions 3.1 & 3.2, ˜fφ and ˜L are K-Lipschitz in φ, where K = 4φmaxx4
max."
ROBUST GENERALIZATION,0.09948542024013722,"We give a proof in Appendix B.3. Our ﬁnal lemma says that our estimate of the loss function is a
uniformly good approximation of the true loss.
Lemma 3.5. Under Assumptions 3.1 & 3.2, for any δ ∈R>0, we have Pp(Z)"
ROBUST GENERALIZATION,0.10120068610634649,"
sup
θ∈Θ
|Lp(θ) −ˆL(θ; Z) −σ(Z)| ≤ϵ

≥1 −δ,"
ROBUST GENERALIZATION,0.10291595197255575,"where σ(Z) = n−1 Pn
i=1 ξ2
i , and letting ℓmax = 2x2
maxφmax be an upper bound on |fθ(x) −fθ∗(x)|, ϵ = s"
ROBUST GENERALIZATION,0.10463121783876501,18ℓ2max(ℓ2max + ξ2max) n
ROBUST GENERALIZATION,0.10634648370497427,"
d2 max

1, log

1 + 8φmaxKn ℓ2max"
ROBUST GENERALIZATION,0.10806174957118353,"
+ log 2 δ"
ROBUST GENERALIZATION,0.1097770154373928,"
.
(7)"
ROBUST GENERALIZATION,0.11149228130360206,"We give a proof in Appendix B.4. Note that ϵ →0 as n →∞. Next, we prove our main result, which
says that quadratic neural networks can be functionally identiﬁed."
ROBUST GENERALIZATION,0.11320754716981132,Under review as a conference paper at ICLR 2022
ROBUST GENERALIZATION,0.11492281303602059,"Theorem 3.6. Under Assumptions 3.1 & 3.2, we have Pp(Z)"
ROBUST GENERALIZATION,0.11663807890222985,"
∀x ∈X . (fˆθ(Z)(x) −fθ∗(x))2 ≤2K2ϵ α"
ROBUST GENERALIZATION,0.1183533447684391,"
≥1 −δ."
ROBUST GENERALIZATION,0.12006861063464837,"Proof. By Lemma 3.3, and since ∇φ ˜L(g(θ∗)) = 0, we have"
ROBUST GENERALIZATION,0.12178387650085763,"Lp(ˆθ(Z)) −Lp(θ∗) = ˜Lp(g(ˆθ(Z))) −˜Lp(g(θ∗)) ≥α∥g(ˆθ(Z)) −g(θ∗)∥2
F .
(8)"
ROBUST GENERALIZATION,0.1234991423670669,"Next, by Lemma 3.5 and the fact that ˆθ minimizes ˆL(θ; Z), we have"
ROBUST GENERALIZATION,0.12521440823327615,"Lp(ˆθ(Z)) ≤ˆL(ˆθ; Z) + ϵ −σ(Z) ≤ˆL(θ∗; Z) + ϵ −σ(Z) ≤Lp(θ∗) + 2ϵ
(9)"
ROBUST GENERALIZATION,0.1269296740994854,"with probability at least 1 −δ. Combining (8) and (9), we have"
ROBUST GENERALIZATION,0.12864493996569468,∥g(ˆθ(Z)) −g(θ∗)∥F ≤ r 2ϵ
ROBUST GENERALIZATION,0.13036020583190394,"α
with probability at least 1 −δ. Finally, by Lemma 3.4, we have"
ROBUST GENERALIZATION,0.1320754716981132,"(fˆθ(Z)(x) −fθ∗(x))2 = ( ˜fg(ˆθ(Z))(x) −˜fg(θ∗)(x))2 ≤K2∥g(ˆθ(Z)) −g(θ∗)∥2
2 ≤2K2ϵ"
ROBUST GENERALIZATION,0.13379073756432247,"α
(∀x ∈X)"
ROBUST GENERALIZATION,0.13550600343053174,"with probability at least 1 −δ, as claimed."
ROBUST GENERALIZATION,0.137221269296741,"As a result, we provide a robust generalization error bound for quadratic neural networks with
potential distribution shifts.
Corollary 3.7. Under Assumptions 3.1 & 3.2, for any distribution q(x) with support on B2(0, xmax), Pp(Z)"
ROBUST GENERALIZATION,0.13893653516295026,"
Lq(ˆθ(Z)) ≤2K2ϵ α"
ROBUST GENERALIZATION,0.14065180102915953,"
≥1 −δ."
ROBUST GENERALIZATION,0.1423670668953688,"Finally, we also prove that gradient descent can ﬁnd the global minima of ˆL(θ; Z), which ensures that
gradient descent can perform function identiﬁcation in practice; we give a proof in Appendix B.5."
ROBUST GENERALIZATION,0.14408233276157806,Proposition 3.8. All local minima of ˆL(θ; Z) are also global minima.
QUADRATIC NEURAL BANDITS,0.1457975986277873,"4
QUADRATIC NEURAL BANDITS"
QUADRATIC NEURAL BANDITS,0.14751286449399656,"A key application of robust generalization bounds is to parametric bandits; this is because, in bandit
learning, the distribution of inputs x used to estimate ˆθ ≈θ∗can differ from the distribution under
which fˆθ is used. Thus, generalization bounds based on notions such as Rademacher complexity
cannot be used. Unlike prior literature in bandits, we consider an over-parameterized function that
does not admit a unique solution; in contrast, recent work on neural tangent kernel bandits (Zhou
et al., 2020) assumes that there is a unique, identiﬁable solution. Note that this assumption cannot
hold for quadratic neural networks because they are invariant to transformations such as rotations."
QUADRATIC NEURAL BANDITS,0.14922813036020582,"We consider a standard linear bandit (Rusmevichientong & Tsitsiklis, 2010; Abbasi-Yadkori et al.,
2011) with a ﬁxed horizon T ∈N, but where the expected reward is parameterized by a quadratic
neural network instead of a linear function. At each time step t, the algorithm chooses among a
continuum of actions xt ∈X, and receives a reward"
QUADRATIC NEURAL BANDITS,0.1509433962264151,"yt = fθ∗(xt) + ξt = k
X"
QUADRATIC NEURAL BANDITS,0.15265866209262435,"j=1
⟨θ∗
j , xt⟩2 + ξt,
(10)"
QUADRATIC NEURAL BANDITS,0.15437392795883362,"where θ∗∈Rd×k is an unknown parameter matrix, and ξt are bounded i.i.d. random variables. For
simplicity, we assume that X = B2(0, 1) is the unit ball. Then, our goal is to bound the regret"
QUADRATIC NEURAL BANDITS,0.15608919382504288,"R(T) = T
X"
QUADRATIC NEURAL BANDITS,0.15780445969125215,"t=1
(Ep(ξt)[yt] −y∗)
where
y∗= max
x∈X fθ∗(x)."
QUADRATIC NEURAL BANDITS,0.1595197255574614,"We make the following assumption, which says that φ∗= θ∗θ∗⊤has a gap in its top eigenvalue:"
QUADRATIC NEURAL BANDITS,0.16123499142367068,Under review as a conference paper at ICLR 2022
QUADRATIC NEURAL BANDITS,0.16295025728987994,Algorithm 1 Explore-Then-Commit Algorithm for Quadratic Neural Network Bandit
QUADRATIC NEURAL BANDITS,0.1646655231560892,procedure QUADRATICNEURALBANDIT
QUADRATIC NEURAL BANDITS,0.16638078902229847,"Initialize Z ←∅
Let m be as in (11)
for t ∈{1, ..., m} do"
QUADRATIC NEURAL BANDITS,0.1680960548885077,"Sample i.i.d. action xt ∼p, where p is as in (12)
Take action xt and obtain reward yt as in (10)
Update Z ←Z ∪{(xt, yt)}
end for
Compute ˆθ = arg minθ ˆL(θ; Z), where ˆL(θ; Z) = m−1 Pm
i=1(fθ(xi) −yi)2
Compute ˆx = arg maxx∈X fˆθ(x)
for t ∈{m + 1, ..., T} do"
QUADRATIC NEURAL BANDITS,0.16981132075471697,"Take action xt = ˆx and obtain reward yt as in (10)
end for
end procedure"
QUADRATIC NEURAL BANDITS,0.17152658662092624,"Assumption 4.1. Let φ∗= θ∗θ∗⊤, and let λ1 ≥λ2 ≥... ≥λd be the eigenvalues of φ∗. There
exists a constant M ∈R>0 such that λ1 −λ2 ≥4/M."
QUADRATIC NEURAL BANDITS,0.1732418524871355,"This assumption ensures that the eigenvectors of φ∗to be stable under perturbations. The eigenvectors
of φ∗correspond to the optimal action x∗= arg maxx∈X fθ∗(x) since fθ∗(x) = x⊤φ∗x; thus, this
assumption ensures that if ˆθ ≈θ∗, then the optimal action ˆx = arg maxx∈X fˆθ(x) satisﬁes ˆx ≈x∗."
QUADRATIC NEURAL BANDITS,0.17495711835334476,"Next, we describe our algorithm, summarized in Algorithm 1. We consider an explore-then-commit
strategy for simplicity, since it already achieves the asymptotically optimal regret rate (Rusmevichien-
tong & Tsitsiklis, 2010); our approach can similarly be applied to more sophisticated algorithms
such as UCB (Abbasi-Yadkori et al., 2011) and Thompson sampling (Agrawal & Goyal, 2013).
Our algorithm proceeds in two stages: (i) the exploration stage (for t ∈{1, ..., m}), and (ii) the
exploitation stage (for t ∈{m + 1, ..., T}), where m =  "
QUADRATIC NEURAL BANDITS,0.17667238421955403,"135M(ℓmax + ξmax)2d3T
p"
QUADRATIC NEURAL BANDITS,0.1783876500857633,"log(3 + 8φmaxKT/ℓ2max)
φmax !2/3"
QUADRATIC NEURAL BANDITS,0.18010291595197256,"
.
(11)"
QUADRATIC NEURAL BANDITS,0.18181818181818182,"In the exploration stage, we randomly choose actions xt ∼p, where"
QUADRATIC NEURAL BANDITS,0.1835334476843911,"p(x) = d
Y"
QUADRATIC NEURAL BANDITS,0.18524871355060035,"i=1
Uniform

xi;

−1
√"
QUADRATIC NEURAL BANDITS,0.18696397941680962,"d
, 1
√ d"
QUADRATIC NEURAL BANDITS,0.18867924528301888,"
.
(12)"
QUADRATIC NEURAL BANDITS,0.19039451114922812,"Note that ∥x∥2 ≤1 for x in the support of p, so xt ∈X. Following the discussion in Section 3, for
this choice of p, Assumption 3.2 holds for the dataset Z with α = 4/(45d2)."
QUADRATIC NEURAL BANDITS,0.19210977701543738,"Next, we compute an estimate ˆθ of θ∗based on the data Z collected so far, and compute the optimal
action ˆx assuming ˆθ are the true parameters. Then, in the exploitation stage, we always use action ˆx."
QUADRATIC NEURAL BANDITS,0.19382504288164665,"The key challenge providing theoretical guarantees using traditional generalization bounds is handling
the optimization problem over x ∈X used to compute ˆx. Since ˆx is not sampled from the distribution
p, traditional bounds do not provide any guarantees about the accuracy of fˆθ(ˆx) compared to fθ∗(ˆx).
In contrast, Theorem 3.6 provides a uniform guarantee, and can therefore be used to bound the regret."
QUADRATIC NEURAL BANDITS,0.1955403087478559,"Theorem 4.2. Under Assumptions 3.1, 3.2 & 4.1, the expected regret of Algorithm 1 is"
QUADRATIC NEURAL BANDITS,0.19725557461406518,"R(T) ≤C0 + C1 · T 2/3

log

3 + 8φmaxKT ℓ2max"
QUADRATIC NEURAL BANDITS,0.19897084048027444,"1/3
,"
QUADRATIC NEURAL BANDITS,0.2006861063464837,where C0 and C1 do not depend on T (see Appendix C).
QUADRATIC NEURAL BANDITS,0.20240137221269297,"In particular, we have R(T) = ˜O(T 2/3); we give a proof in Appendix C. Note that this is worse than
the usual ˜O(
√"
QUADRATIC NEURAL BANDITS,0.20411663807890223,T) regret because Theorem 3.6 only admits a n1/4 convergence rate.
QUADRATIC NEURAL BANDITS,0.2058319039451115,Under review as a conference paper at ICLR 2022
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.20754716981132076,"5
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.20926243567753003,"So far, we have considered shifts in the covariate distribution but not in the label distribution. Now,
we consider a transfer learning problem where there is additionally a small shift in the labels. In
particular, we assume we have proxy data Zp ⊆X × Y from the source domain of the form
yp,i = fθ∗p(xp,i) + ξp,i (for i ∈[np]), where θ∗
p ∈Θ are the proxy parameters and p(xp) is the
source covariate distribution, along with gold data Zg ⊆X × Y from the target domain of the form
yg,i = fθ∗g(xg,i) + ξg,i (for i ∈[ng]), where θ∗
g ∈Θ are the gold parameters and q(xg) is the target
covariate distribution. We are interested in the setting np ≫ng, and where ∥θ∗
g −θ∗
p∥F ≤B is small."
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.2109777015437393,"We consider a two-stage estimator (Bastani, 2020) that ﬁrst computes an estimate of the proxy
parameters ˆθp = arg minθ∈Θ ˆL(θ; Zp), and then computes an estimate of the gold parameters in a
way that is constrained towards the proxy parameters. First, note that we have Pp(Z)"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.21269296740994853,"
Lq(ˆθp) ≤2K2ϵp α"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.2144082332761578,"
≥1 −δ 2, where ϵp = s"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.21612349914236706,18ℓ2max(ℓ2max + ξ2max) np
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.21783876500857632,"
d2 max

1, log

1 + 8φmaxKnp ℓ2max"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.2195540308747856,"
+ log 4 δ 
,"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.22126929674099485,"where we have highlighted the differences from ϵ in (7) in red. Next, we make a technical assumption:
Assumption 5.1. For some σ0 ∈R>0, σmin(θ∗
p) ≥σ0, where σmin(θ) is the dth singular value of θ."
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.22298456260720412,"Equivalently, the minimum eigenvalue of g(θ∗
p) is positive; intuitively, this assumption ensures a good
estimate of θ∗
pθ∗⊤
p
implies a good estimate of θ∗
p (up to an orthogonal transformation). Then, letting"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.22469982847341338,ˆB = B + 1 σ0 r 2ϵp α
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.22641509433962265,"be an expanded radius to account for error in our estimate of ˆθp, we use the estimator"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.2281303602058319,"ˆθg = arg min
θ∈B2(ˆθp, ˆ
B)
ˆL(θ; Zg)
where
B2(ˆθp, ˆB) = {θ ∈Θ | ∥θ −ˆθp∥F ≤ˆB}."
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.22984562607204118,"Note that we have assume ˆB is known; in practice, this constraint can be included as an additive
regularization term. Intuitively, this formulation mirrors transfer learning algorithms based on ﬁne-
tuning—i.e., initializing the parameters to the proxy data θp and then taking a small number of steps
of stochastic gradient descent (SGD) on the gold data θg. In particular, SGD can be interpreted as L2
regularization on the parameters (Ali et al., 2020), so ﬁne-tuning L2-regularizes ˆθg towards θp.
Theorem 5.2. Under Assumptions 3.1, 3.2 & 5.1, for any q(x) with support on B2(0, xmax), Pp(Z)"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.23156089193825044,"
Lq(ˆθg) ≤2K2ϵg α"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.2332761578044597,"
≥1 −δ, where"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.23499142367066894,ϵg = ˆB · s
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.2367066895368782,18K2(K2 ˆB2 + ξ2max) ng
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.23842195540308747,"
d2 max

1, log

1 + 8φmaxKng ℓ2max"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.24013722126929674,"
+ log 4 δ 
."
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.241852487135506,"Thus, if B is small and np is large, fˆθg is accurate even if ng is small; we give a proof in Appendix D."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.24356775300171526,"6
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.24528301886792453,"While function identiﬁcation enables robust generalization, many data generating processes are
too complex to be identiﬁable. Neural module networks are designed to break complex prediction
problems into smaller tasks that are individually easier to solve. These models take two kinds of input:
(i) a sequence of tokens w (e.g., word embeddings) indicating the correct composition of modules,"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2469982847341338,Under review as a conference paper at ICLR 2022
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.24871355060034306,"and (ii) the input x to the modules. Then, the model predicts the sequence of modules j1...jT based
on w, and runs the modules in sequence to obtain output x′ = fjT (...(fj1(x))...)."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2504288164665523,"We study conditions under which neural module networks can robustly generalize. Rather than study
arbitrary distribution shifts, we consider two separate shifts:"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2521440823327616,"• Module inputs: We assume that the individual modules are identiﬁable; as a consequence, we
assume the shift to the module input x can be arbitrary."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2538593481989708,"• Module composition: We consider shifts to the token sequence w. If the model mapping w to
j1...jT is identiﬁable, then the entire model is identiﬁable. Instead, we show that when this model
is not identiﬁable, compositional structure can still aid generalization. Intuitively, we show that
while small shifts in the compositional structure can cause large shifts in the distribution p(w),
models that leverage the structure of p(w) can still generalize well."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2555746140651801,"In more detail, consider a simpliﬁed neural module network f, which includes (i) a set of neural
modules {fj : X →X}k
j=1, and (ii) a parser g : ZT →[k]T , where Z ⊆Rr, with model class
g ∈G. We assume each component of fj(x) is computed by a separate quadratic neural network;
we discuss the architecture of g below. Then, given an input x ∈X ⊆Rd and w ∈W = ZT , the
corresponding neural module network f : X × W →X is deﬁned by"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.25728987993138935,"f(x, w) = (fjT ◦... ◦fj1)(x) = fjT (...(fj1(x))...)
where
j1...jT = g(w)."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.25900514579759865,"We assume that g has compositional structure—i.e., for some ˜g : [k] × Z →[k], we have"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2607204116638079,"g(w) = j1...jT
where
jt =
0
if t = 0
˜g(zt, jt−1)
otherwise,"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2624356775300172,"where w = z1...zT . Intuitively, w is a sequence of word vectors; then, the current neural module
jt = ˜g(zt, jt−1) depends both on the current word vector zt and the previous neural module jt−1.
First, we assume that the individual modules have been functionally identiﬁed."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2641509433962264,"We assume we have fully labeled data we can use to train the neural modules—i.e., for each input x
and sequence w, we have both the desired sequence j1...jT of neural modules, as well as the entire
execution x0, x1, ..., xT , where x0 = x and xt+1 = fjt(xt) otherwise. Thus, we can use supervised
learning to train the neural modules;2 in particular, we can construct labeled examples (jt−1, zt, jt)
used to train the parser ˜g, and labeled examples (xt, xt+1) to train the modules fjt. For simplicity,
we assume we have a uniform lower bound n on the number of training examples for the parser and
for each module. Then, we have the following straightforward result:"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2658662092624357,"Lemma 6.1. Under Assumptions 3.1 & 3.2, with probability at least 1 −dkδ, for each j ∈[k],"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.26758147512864494,"∥ˆfj(x) −f ∗
j (x)∥2 ≤ r 2dK2ϵ"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2692967409948542,"α
=: ϵf
(∀x ∈X),"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.27101200686106347,"where ˆfj is the estimated module and f ∗
j is the ground truth module."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2727272727272727,"This result follows straightforwardly from Theorem 3.6 along with a union bound. In contrast, we
do not assume the parsing model robustly generalizes, but only on distribution. For the subsequent
analysis, we can use any neural network models that satisfy the statement of Lemma 6.1."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.274442538593482,"Lemma 6.2. Under Assumptions 3.1 & 3.2, with probability at least 1 −δ, we have"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.27615780445969124,"P˜p(z,j)
h
ˆ˜g(z, j) ̸= ˜g∗(z, j)
i
≤4Rn(G) + r"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.27787307032590053,2 log(2/δ)
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.27958833619210977,"n
=: ϵg,"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.28130360205831906,"where Rn(G) is the Rademacher complexity of G (including its loss function), where p(z, j) =
T −1 PT
t=1 pt(z, j), and where"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2830188679245283,"˜pt(z, j) ="
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2847341337907376,"(
1(j = 0) · ˜p(z)
if t = 1
Pk
j′=1
R
1(j = ˜g∗(z′, j′)) · ˜p(z | z′) · ˜pt−1(z′, j′)dz′
otherwise."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2864493996569468,"2Neural modules are often trained with only partial supervision (Andreas et al., 2016); we leave an analysis
of this strategy to future work since our focus is on understanding generalization rather than learning dynamics."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2881646655231561,Under review as a conference paper at ICLR 2022
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.28987993138936535,"This result is a standard Rademacher generalization bound (Bartlett & Mendelson, 2002). Note that
we have also assumed that the distribution over token sequences is structured, which is necessary for
our compositional implementation of g to generalize, even on distribution. Intuitively, the distribution
over (z, j) consists of both a unigram model over the word vectors:"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2915951972555746,"p(z1, ..., zT ) = T
Y"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2933104631217839,"t=1
˜p(zt | zt−1),"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2950257289879931,"where we deﬁne ˜p(z1 | z0) = ˜p(z1), as well as a unigram model over neural modules:"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2967409948542024,"p(j1...jT | z1, ..., zT ) = T
Y"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.29845626072041165,"t=1
1(jt = ˜g∗(zt, jt−1))."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.30017152658662094,"Next, we consider a shifted distribution ˜q(z | z′), which is close to ˜p(z | z′).
Assumption 6.3. We have ∥˜q(· | z′) −˜p(· | z′)∥TV ≤α."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.3018867924528302,"Importantly, despite this assumption, the shift between the overall distributions p(z1, ..., zT ) and
q(z1, ..., zT ) can still be large since it compounds exponentially across the steps t ∈[T].
Proposition 6.4. There exist p and q that satisfy Assumption 6.3, but ∥p−q∥TV = 2(1−(1−α/2)T )."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.30360205831903947,"That is, even if the single step probabilities ˜p(z | z′) and ˜q(z | z′) have total variation (TV) distance
bounded as in Assumption 6.3, the overall distributions p and q can have TV distance exponentially
close to the maximum possible distance of 2 in T; we give a proof in Appendix E.1."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.3053173241852487,"We show that neural module networks generalize since ˆg leverages the compositional structure of p.
First, we show that under Assumption 6.3, the overall shift in the input distribution of ˆ˜g is bounded:
Lemma 6.5. Under Assumptions 3.1, 3.2 & 6.3, we have ∥˜q −˜p∥TV ≤Tα, where ˜p is deﬁned in
Lemma 6.2 and ˜q is deﬁned in Assumption 6.3."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.307032590051458,"That is, while the shift can compound across steps t, it does so only linearly; we give a proof in
Appendix E.2. Next, we show that as a consequence, the error of ˆg is bounded."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.30874785591766724,"Lemma 6.6. Under Assumptions 3.1, 3.2 & 6.3, and assuming that Pp(z,j)[ˆ˜g(z, j) ̸= ˜g∗(z, j)] ≤ϵg,
we have that Pp(w)[ˆg(w) ̸= g∗(w)] ≤Tϵg."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.31046312178387653,"We give a proof in Appendix E.3. Finally, we have our main result.
Theorem 6.7. Under Assumptions 3.1, 3.2 & 6.3, with probability at least 1 −(dk + 1)δ, we have"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.31217838765008576,"Pq(w)
h
∥ˆf(x, w) −f ∗(x, w)∥2 ≤Tϵf · max{KT −1, 1}
i
≥1 −Tϵg −T 2α."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.313893653516295,"We give a proof in Appendix E.4. Intuitively, Theorem 6.7 says that the error of the neural module
network is linear in T as long as K ≤1. Note that even if there is no distribution shift, its error is"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.3156089193825043,"Pp(w)
h
∥ˆf(x, w) −f ∗(x, w)∥2 ≤Tϵf · max{KT −1, 1}
i
≥1 −Tϵg,"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.31732418524871353,"by the same argument as the proof of Theorem 6.7. The exponential dependence on K is unavoidable
since K > 1 says that the modules fj can expand the input, which leads to exponential blowup in the
magnitude of the output as a function of T, which also makes the estimation error exponential in T.
Thus, the only cost to the distribution shift from p to q is the additional error probability T 2α."
CONCLUSION,0.3190394511149228,"7
CONCLUSION"
CONCLUSION,0.32075471698113206,"We have presented a number of results demonstrating that over-parameterization does not funda-
mentally harm learning models that are robust to arbitrary distribution shifts. In particular, even
though we can no longer identify the true parameters for quadratic neural networks, we show that
we can identify the true function, thereby enabling us to prove new results in bandits and transfer
learning. Finally, we provide preliminary analysis extending these results to neural module networks
to handle complex data generating processes. A limitation of our work is that it is specialized to
quadratic neural networks; a key direction for future work is to explore how our results extend to
other activation functions and deeper architectures."
CONCLUSION,0.32246998284734135,Under review as a conference paper at ICLR 2022
REFERENCES,0.3241852487135506,REFERENCES
REFERENCES,0.3259005145797599,"Yasin Abbasi-Yadkori, D´avid P´al, and Csaba Szepesv´ari. Improved algorithms for linear stochastic
bandits. In NIPS, volume 11, pp. 2312–2320, 2011."
REFERENCES,0.3276157804459691,"Shipra Agrawal and Navin Goyal. Thompson sampling for contextual bandits with linear payoffs. In
International Conference on Machine Learning, pp. 127–135. PMLR, 2013."
REFERENCES,0.3293310463121784,"Alnur Ali, Edgar Dobriban, and Ryan Tibshirani. The implicit regularization of stochastic gradient
ﬂow for least squares. In International Conference on Machine Learning, pp. 233–244. PMLR,
2020."
REFERENCES,0.33104631217838765,"Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein. Neural module networks. In
Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 39–48, 2016."
REFERENCES,0.33276157804459694,"Sanjeev Arora, Rong Ge, Behnam Neyshabur, and Yi Zhang. Stronger generalization bounds for deep
nets via a compression approach. In International Conference on Machine Learning, pp. 254–263.
PMLR, 2018."
REFERENCES,0.3344768439108062,"Francis Bach, Julien Mairal, and Jean Ponce. Convex sparse matrix factorizations. arXiv preprint
arXiv:0812.1869, 2008."
REFERENCES,0.3361921097770154,"Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and
structural results. Journal of Machine Learning Research, 3(Nov):463–482, 2002."
REFERENCES,0.3379073756432247,"Hamsa Bastani. Predicting with proxies: Transfer learning in high dimension. Management Science,
2020."
REFERENCES,0.33962264150943394,"Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira. Analysis of representations for
domain adaptation. In Advances in neural information processing systems, pp. 137–144, 2007."
REFERENCES,0.34133790737564323,"John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman. Learning
bounds for domain adaptation. In Advances in neural information processing systems, pp. 129–136,
2008."
REFERENCES,0.34305317324185247,"Emmanuel J Candes and Yaniv Plan. Tight oracle inequalities for low-rank matrix recovery from a
minimal number of noisy random measurements. IEEE Transactions on Information Theory, 57
(4):2342–2359, 2011."
REFERENCES,0.34476843910806176,"Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. Certiﬁed adversarial robustness via randomized
smoothing. In International Conference on Machine Learning, pp. 1310–1320. PMLR, 2019."
REFERENCES,0.346483704974271,"Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Ankur Moitra, and Alistair Stewart.
Robust estimators in high-dimensions without the computational intractability. SIAM Journal on
Computing, 48(2):742–864, 2019."
REFERENCES,0.3481989708404803,"Simon Du and Jason Lee. On the power of over-parametrization in neural networks with quadratic
activation. In International Conference on Machine Learning, pp. 1329–1338. PMLR, 2018."
REFERENCES,0.34991423670668953,"Simon Du, Jason Lee, Haochuan Li, Liwei Wang, and Xiyu Zhai. Gradient descent ﬁnds global
minima of deep neural networks. In International Conference on Machine Learning, pp. 1675–1685.
PMLR, 2019."
REFERENCES,0.3516295025728988,"John Duchi and Hongseok Namkoong. Learning models with uniform performance via distributionally
robust optimization. arXiv preprint arXiv:1810.08750, 2018."
REFERENCES,0.35334476843910806,"Dylan Foster and Alexander Rakhlin. Beyond ucb: Optimal and efﬁcient contextual bandits with
regression oracles. In International Conference on Machine Learning, pp. 3199–3210. PMLR,
2020."
REFERENCES,0.35506003430531735,"Ruiqi Gao, Tianle Cai, Haochuan Li, Cho-Jui Hsieh, Liwei Wang, and Jason D Lee. Convergence
of adversarial training in overparametrized neural networks. Advances in Neural Information
Processing Systems, 32:13029–13040, 2019."
REFERENCES,0.3567753001715266,Under review as a conference paper at ICLR 2022
REFERENCES,0.3584905660377358,"Rong Ge, Chi Jin, and Yi Zheng. No spurious local minima in nonconvex low rank problems: A
uniﬁed geometric analysis. In International Conference on Machine Learning, pp. 1233–1242.
PMLR, 2017a."
REFERENCES,0.3602058319039451,"Rong Ge, Jason D Lee, and Tengyu Ma. Learning one-hidden-layer neural networks with landscape
design. arXiv preprint arXiv:1711.00501, 2017b."
REFERENCES,0.36192109777015435,"Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. arXiv preprint arXiv:1412.6572, 2014."
REFERENCES,0.36363636363636365,"Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common
corruptions and perturbations. arXiv preprint arXiv:1903.12261, 2019."
REFERENCES,0.3653516295025729,"Daniel Hsu, Sham M Kakade, and Percy Liang. Identiﬁability and unmixing of latent parse trees.
arXiv preprint arXiv:1206.3137, 2012."
REFERENCES,0.3670668953687822,"Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon Tran, and Aleksander
Madry. Adversarial examples are not bugs, they are features. arXiv preprint arXiv:1905.02175,
2019."
REFERENCES,0.3687821612349914,"Arthur Jacot, Franck Gabriel, and Cl´ement Hongler. Neural tangent kernel: Convergence and
generalization in neural networks. arXiv preprint arXiv:1806.07572, 2018."
REFERENCES,0.3704974271012007,"Maryia Kabanava, Richard Kueng, Holger Rauhut, and Ulrich Terstiege. Stable low-rank matrix
recovery via null space properties. Information and Inference: A Journal of the IMA, 5(4):405–441,
2016."
REFERENCES,0.37221269296740994,"Michael J Kearns, Umesh Virkumar Vazirani, and Umesh Vazirani. An introduction to computational
learning theory. MIT press, 1994."
REFERENCES,0.37392795883361923,"Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Bal-
subramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al. Wilds: A
benchmark of in-the-wild distribution shifts. arXiv preprint arXiv:2012.07421, 2020."
REFERENCES,0.37564322469982847,"Yuanzhi Li, Tengyu Ma, and Hongyang Zhang. Algorithmic regularization in over-parameterized
matrix sensing and neural networks with quadratic activations. In Conference On Learning Theory,
pp. 2–47. PMLR, 2018."
REFERENCES,0.37735849056603776,"Philip M Long and Hanie Sedghi. Generalization bounds for deep convolutional neural networks.
arXiv preprint arXiv:1905.12600, 2019."
REFERENCES,0.379073756432247,"Behnam Neyshabur, Srinadh Bhojanapalli, David McAllester, and Nathan Srebro. Exploring general-
ization in deep learning. arXiv preprint arXiv:1706.08947, 2017."
REFERENCES,0.38078902229845624,"Aditi Raghunathan, Jacob Steinhardt, and Percy Liang.
Certiﬁed defenses against adversarial
examples. arXiv preprint arXiv:1801.09344, 2018."
REFERENCES,0.38250428816466553,"Marco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin, and Sameer Singh. Beyond accuracy:
Behavioral testing of nlp models with checklist. arXiv preprint arXiv:2005.04118, 2020."
REFERENCES,0.38421955403087477,"Laura Ruis, Jacob Andreas, Marco Baroni, Diane Bouchacourt, and Brenden M Lake.
A
benchmark for systematic generalization in grounded language understanding. arXiv preprint
arXiv:2003.05161, 2020."
REFERENCES,0.38593481989708406,"Paat Rusmevichientong and John N Tsitsiklis. Linearly parameterized bandits. Mathematics of
Operations Research, 35(2):395–411, 2010."
REFERENCES,0.3876500857632933,"Hidetoshi Shimodaira. Improving predictive inference under covariate shift by weighting the log-
likelihood function. Journal of statistical planning and inference, 90(2):227–244, 2000."
REFERENCES,0.3893653516295026,"Mahdi Soltanolkotabi, Adel Javanmard, and Jason D Lee. Theoretical insights into the optimization
landscape of over-parameterized shallow neural networks. IEEE Transactions on Information
Theory, 65(2):742–769, 2018."
REFERENCES,0.3910806174957118,Under review as a conference paper at ICLR 2022
REFERENCES,0.3927958833619211,"Jacob Steinhardt, Pang Wei Koh, and Percy Liang. Certiﬁed defenses for data poisoning attacks.
arXiv preprint arXiv:1706.03691, 2017."
REFERENCES,0.39451114922813035,"Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow,
and Rob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013."
REFERENCES,0.39622641509433965,"Rohan Taori, Achal Dave, Vaishaal Shankar, Nicholas Carlini, Benjamin Recht, and Ludwig
Schmidt.
Measuring robustness to natural distribution shifts in image classiﬁcation.
arXiv
preprint arXiv:2007.00644, 2020."
REFERENCES,0.3979416809605489,"Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and Aleksander Madry.
Robustness may be at odds with accuracy. arXiv preprint arXiv:1805.12152, 2018."
REFERENCES,0.3996569468267582,"Roman Vershynin. High-dimensional probability: An introduction with applications in data science,
volume 47. Cambridge university press, 2018."
REFERENCES,0.4013722126929674,"Martin Wainwright.
High-dimensional statistics: A non-asymptotic viewpoint.
Book Draft
(Working Publication), 2016. URL https://www.stat.berkeley.edu/˜wainwrig/
nachdiplom/Chap2_Sep10_2015.pdf."
REFERENCES,0.40308747855917665,"Junfeng Wen, Chun-Nam Yu, and Russell Greiner. Robust learning under uncertain test distributions:
Relating covariate shift to model misspeciﬁcation. In International Conference on Machine
Learning, pp. 631–639. PMLR, 2014."
REFERENCES,0.40480274442538594,"Kan Xu, Xuanyi Zhao, Hamsa Bastani, and Osbert Bastani. Group-sparse matrix factorization for
transfer learning of word embeddings. In International Conference on Machine Learning, 2021."
REFERENCES,0.4065180102915952,"Yi Yu, Tengyao Wang, and Richard J Samworth. A useful variant of the davis–kahan theorem for
statisticians. Biometrika, 102(2):315–323, 2015."
REFERENCES,0.40823327615780447,"Dongruo Zhou, Lihong Li, and Quanquan Gu. Neural contextual bandits with ucb-based exploration.
In International Conference on Machine Learning, pp. 11492–11502. PMLR, 2020."
REFERENCES,0.4099485420240137,Under review as a conference paper at ICLR 2022
REFERENCES,0.411663807890223,"A
ADDITIONAL RELATED WORK"
REFERENCES,0.41337907375643224,"Low-rank matrix factorization. Our notion of functional identiﬁcation for quadratic neural network
is related to the low-rank matrix factorization literature. However, they impose a low-rank structure
on the matrix to recover, and hence typically require extra conditions to identify the matrix—e.g., the
restricted isometry property (RIP) (Candes & Plan, 2011; Ge et al., 2017a), or bounded ℓ2 norm of
noise vector (Kabanava et al., 2016). In contrast, we consider a more general case and do not assume
any underlying structure of the matrix; in particular, since our goal is to capture over-parameterization
of neural networks, our matrix is usually decomposed as φ = θθ⊤, where θ ∈Rd×k and k ≥d (and
φ is not necessarily low-rank). Also, we study the prediction error of neural networks in the presence
of distribution shifts, whereas the goal of the low-rank literature is to recover the true matrix."
REFERENCES,0.41509433962264153,"Multi-armed bandits. Prior literature on parameterized bandits has considered a number of func-
tional forms, ranging from linear (Abbasi-Yadkori et al., 2011; Rusmevichientong & Tsitsiklis, 2010)
to neural tangent kernels (Zhou et al., 2020). Most of this work makes a realizability assumption that
the model family contains the true model;3 implicitly, they consider model families where there is a
unique, identiﬁable true parameter. These assumptions are necessary precisely due to the fact that the
test and training distributions are different; thus, much of the bandit literature has focused on proving
parameter identiﬁcation results to enable learning. In contrast, the identiﬁability assumption does
not hold for quadratic neural networks because they are invariant to parameter transformations. To
the best of our knowledge, we consider the ﬁrst over-parameterized bandit problem that considers a
model that is not parameter-identiﬁable; we ﬁnd that similar regret results hold as long as the function
represented by the model can be identiﬁed. Separately, Foster & Rakhlin (2020) makes a general
connection between online regression oracles and the regret of a bandit algorithm; however, their
approach only provides good guarantees when the regression oracle returns a model that generalizes
off-distribution. Finally, recent work on UCB with neural tangent kernels (Zhou et al., 2020) provides
general regret bounds, but their bound is only sublinear under conditions such as the true reward
function having small RKHS norm (see Remark 4.8 in their paper), which amounts to assuming they
can recover the true parameters."
REFERENCES,0.41680960548885077,"Novelty. We brieﬂy discuss the novelty of our results compared to existing work. First, the results in
Section 3 are novel. To the best of our knowledge, the proof strategy in our main result, Theorem 3.6,
is novel, though we note that the preceding lemmas are based on standard arguments—e.g., bounding
the convexity of ˜Lp(φ) (Lemma 3.3) and the Lipschitz constant (Lemma 3.4) of ˜fφ; also, Lemma 3.5
relies on a standard covering number argument. For our applications to bandits and transfer learning,
our key novel results are Lemma C.3 for bandits, which proves smoothed bounded response for
quadratic neural networks, and Lemma D.1 for transfer learning. Finally, to the best of our knowledge,
our arguments in Section 6 are novel."
REFERENCES,0.41852487135506006,"3Slightly different from realizability in PAC learning (Kearns et al., 1994), which says there is a model with
zero true loss."
REFERENCES,0.4202401372212693,Under review as a conference paper at ICLR 2022
REFERENCES,0.4219554030874786,"B
PROOFS FOR SECTION 3"
REFERENCES,0.4236706689536878,"B.1
PROOF OF MINIMUM EIGENVALUE FOR UNIFORM DISTRIBUTION"
REFERENCES,0.42538593481989706,"In this section, we prove the claim that Assumption 3.2 holds for the covariate distribution where xi
is an i.i.d. random variable with distribution Uniform(xi; [−1/2, 1/2]). To this end, note that"
REFERENCES,0.42710120068610635,"Ep(x)[(x⊤∆x)2] = Ep(x)    
d
X"
REFERENCES,0.4288164665523156,"i,j=1
xixj∆ij   2 "
REFERENCES,0.4305317324185249,= Ep(x)  X
REFERENCES,0.4322469982847341,"i
x4
i ∆2
ii +
X"
REFERENCES,0.4339622641509434,"i̸=j
x2
i x2
j∆ii∆jj + 2
X"
REFERENCES,0.43567753001715265,"i̸=j
x2
i x2
j∆2
ij   = 1 80 X"
REFERENCES,0.43739279588336194,"i
∆2
ii +
1
144 X"
REFERENCES,0.4391080617495712,"i̸=j
∆ii∆jj + 1 72 X"
REFERENCES,0.44082332761578047,"i̸=j
∆2
ij =
 1"
REFERENCES,0.4425385934819897,"80 −
1
144  X"
REFERENCES,0.444253859348199,"i
∆2
ii +
1
144 X i
∆ii !2 + 1 72 X"
REFERENCES,0.44596912521440824,"i̸=j
∆2
ij"
REFERENCES,0.44768439108061747,"≥
1
180∥∆∥2
F ,"
REFERENCES,0.44939965694682676,as claimed.
REFERENCES,0.451114922813036,"B.2
PROOF OF LEMMA 3.3"
REFERENCES,0.4528301886792453,"We use the notation U : ∇2f(φ) : V to denote the matrix inner product ⟨U, ∇2f(φ)(V )⟩for
U, V ∈Rd×d. The Hessian ∇2f(φ) can be viewed as a d2 × d2 matrix. As everything here is
bounded, we can exchange the expectation and differentiation. Therefore, the Hessian of our loss
function has for any symmetric matrix ∆
∆: ∇2 ˜Lp(φ) : ∆= 2Ep(x)[(x⊤∆x)2] ≥2α∥∆∥2
F ,
where the last inequality uses Assumption 3.2."
REFERENCES,0.45454545454545453,"B.3
PROOF OF LEMMA 3.4"
REFERENCES,0.4562607204116638,"By our deﬁnition, for any φ, φ′ ∈Φ,
| ˜fφ(x) −˜fφ′(x)| = |(x⊤(φ −φ′)x)2| ≤x2
max∥φ −φ′∥F .
Given our quadratic loss function, we have
|( ˜fφ(x) −˜fφ∗(x))2 −( ˜fφ′(x) −˜fφ∗(x))2|"
REFERENCES,0.45797598627787306,≤| ˜fφ(x) −˜fφ∗(x) + ˜fφ′(x) −˜fφ∗(x)|| ˜fφ(x) −˜fφ′(x)|
REFERENCES,0.45969125214408235,"≤4φmaxx4
max∥φ −φ′∥F .
Next, the true loss satisﬁes
|˜Lp(φ) −˜Lp(φ′)| ≤Ep(x)[|( ˜fφ(x) −˜fφ∗(x))2 −( ˜fφ′(x) −˜fφ∗(x))2|] ≤4φmaxx4
max∥φ −φ′∥F .
Finally, the empirical loss satisﬁes"
REFERENCES,0.4614065180102916,|ˆ˜L(φ; Z) −ˆ˜L(φ′; Z)| =
N,0.4631217838765009,"1
n n
X"
N,0.4648370497427101,"i=1
[( ˜fφ(xi) −yi)2 −( ˜fφ′(xi) −yi)2]  ≤1 n n
X"
N,0.4665523156089194,"i=1
|( ˜fφ(xi) −˜fφ∗(xi))2 −( ˜fφ′(xi) −˜fφ∗(xi))2| + 1 n n
X"
N,0.46826758147512865,"i=1
|ξi| · | ˜fφ(xi) −˜fφ′(xi)|"
N,0.4699828473413379,"≤(4φmaxx4
max + 2ξmaxx2
max)∥φ −φ′∥F ,
as claimed."
N,0.4716981132075472,Under review as a conference paper at ICLR 2022
N,0.4734133790737564,"B.4
PROOF OF LEMMA 3.5"
N,0.4751286449399657,"First, we have the following results:
Lemma B.1 (Covering Number of Euclidean Ball). For a Euclidean ball in Rn1×n2 with radius R
with respect to Frobenius norm, there exists an ϵ-net E such that"
N,0.47684391080617494,"|E| ≤

1 + 2R ϵ"
N,0.47855917667238423,"n1n2
."
N,0.48027444253859347,Proof. This claim follows by a direct application of Proposition 4.2.12 in Vershynin (2018).
N,0.48198970840480276,"Lemma B.2 (Hoeffding’s Inequality for Subgaussian Random Variables). Letting {zi}n
i=1 be a set
of independent σ-subgaussian random variables, then for all t ≥0, we have Pr ""
1
n n
X"
N,0.483704974271012,"i=1
zi ≥t #"
N,0.4854202401372213,"≤exp

−2nt2 σ2 
."
N,0.48713550600343053,Proof. See Proposition 2.1 of Wainwright (2016).
N,0.4888507718696398,"Now, we prove Lemma 3.5. Consider an ϵ/(4K)-net E. Then, for any φ ∈Φ, there exists φ′ ∈E
such that"
N,0.49056603773584906,|(ˆ˜L(φ; Z) −˜Lp(φ)) −(ˆ˜L(φ′; Z) −˜Lp(φ′))| ≤2K∥φ −φ′∥F ≤ϵ 2.
N,0.4922813036020583,"Therefore, we have Pp(Z)"
N,0.4939965694682676,"
sup
θ
|ˆL(g(θ); Z) −Lp(g(θ)) −σ(Z)| ≥ϵ
"
N,0.4957118353344768,"= Pp(Z) """
N,0.4974271012006861,"sup
φ∈Φ
|ˆ˜L(φ; Z) −˜Lp(φ) −σ(Z)| ≥ϵ #"
N,0.49914236706689535,≤Pp(Z)
N,0.5008576329331046,"
max
φ∈E |ˆ˜L(φ; Z) −˜Lp(φ) −σ(Z)| ≥ϵ 2  ≤
X"
N,0.5025728987993139,"φ∈E
Pp(Z)
h
|ˆ˜L(φ; Z) −˜Lp(φ) −σ(Z)| ≥ϵ 2"
N,0.5042881646655232,"i
.
(13)"
N,0.5060034305317325,"Now, deﬁning"
N,0.5077186963979416,"¯˜L(φ; Z) = 1 n n
X"
N,0.5094339622641509,"i=1
( ˜fφ(xi) −˜fφ∗(xi))2
and
˜η(φ; Z) = 1 n n
X"
N,0.5111492281303602,"i=1
( ˜fφ(xi) −˜fφ∗(xi))ξi,"
N,0.5128644939965694,"and recalling that σ(Z) = n−1 Pn
i=1 ξ2
i , then we have"
N,0.5145797598627787,ˆ˜L(φ; Z) = ¯˜L(φ; Z) + 2˜η(φ; Z) + σ(Z).
N,0.516295025728988,"Thus, continuing from (13), we have
X"
N,0.5180102915951973,"φ∈E
Pp(Z)
h
|ˆ˜L(φ; Z) −˜Lp(φ) −σ(Z)| ≥ϵ 2 i ≤
X"
N,0.5197255574614065,"φ∈E
Pp(Z)
h
|¯˜L(φ; Z) −˜Lp(φ)| + 2|˜η(φ; Z)| ≥ϵ 2 i ≤
X φ∈E"
N,0.5214408233276158,"
Pp(Z)
h
|¯˜L(φ; Z) −˜Lp(φ)| ≥ϵ 6"
N,0.5231560891938251,"i
+ Pp(Z)
h
|˜η(φ; Z)| ≥ϵ 6"
N,0.5248713550600344,"i
.
(14)"
N,0.5265866209262435,"For the ﬁrst term in (14), note that |( ˜fφ(x) −˜fφ∗(x))2| ≤ℓ2
max, so ( ˜fφ(x) −˜fφ∗(x))2 is ℓ2
max-
subgaussian; thus, by Lemma B.2, we have
X"
N,0.5283018867924528,"φ∈E
Pp(Z)
h
|¯˜L(φ; Z) −˜Lp(φ)| ≥ϵ 6"
N,0.5300171526586621,"i
≤2|E| · exp

−nϵ2"
N,0.5317324185248714,18ℓ4max
N,0.5334476843910806,"
.
(15)"
N,0.5351629502572899,Under review as a conference paper at ICLR 2022
N,0.5368782161234992,"Next, for the second term in (14), note that |( ˜fφ(xi)−˜fφ∗(xi))ξi| ≤ℓmaxξmax, so ( ˜fφ(xi)−˜fφ∗(xi))ξi
is ℓmaxξmax-subgaussian; thus, by Lemma B.2, we have
X"
N,0.5385934819897084,"φ∈E
Pp(Z)
h
|˜η(φ; Z)| ≥ϵ 6"
N,0.5403087478559176,"i
≤2|E| · exp

−
nϵ2"
N,0.5420240137221269,18ℓ2maxξ2max
N,0.5437392795883362,"
.
(16)"
N,0.5454545454545454,"Combining (15) & (16), continuing from (14), we have
X φ∈E"
N,0.5471698113207547,"
Pp(Z)
h
|¯˜L(φ; Z) −˜Lp(φ)| ≥ϵ 6"
N,0.548885077186964,"i
+ Pp(Z)
h
|˜η(φ; Z)| ≥ϵ 6 i"
N,0.5506003430531733,"≤4|E| · exp

−
nϵ2"
N,0.5523156089193825,18ℓ2max(ℓ2max + ξ2max) 
N,0.5540308747855918,"≤2

1 + 8φmaxK ϵ d2"
N,0.5557461406518011,"· exp

−
nϵ2"
N,0.5574614065180102,18ℓ2max(ℓ2max + ξ2max) 
N,0.5591766723842195,"= 2 exp

−
nϵ2"
N,0.5608919382504288,"18ℓ2max(ℓ2max + ξ2max) + d2 log

1 + 8φmaxK ϵ"
N,0.5626072041166381,"
,
(17)"
N,0.5643224699828473,"where for the ﬁrst inequality, we have used max{ℓ2
max, ξ2
max} ≤ℓ2
max +ξ2
max, and the second inequality
follows since by Lemma B.1, the covering number of the ϵ-net E of Φ satisﬁes"
N,0.5660377358490566,"|E| ≤

1 + 2φmax ϵ d2 ."
N,0.5677530017152659,"Finally, we choose ϵ so that (17) is smaller than δ—in particular, letting ϵ = s"
N,0.5694682675814752,18ℓ2max(ℓ2max + ξ2max) n
N,0.5711835334476844,"
d2 max

1, log

1 + 8φmaxKn ℓ2max"
N,0.5728987993138936,"
+ log 2 δ 
."
N,0.5746140651801029,"then continuing (17), we have"
EXP,0.5763293310463122,"2 exp

−
nϵ2"
EXP,0.5780445969125214,"18ℓ2max(ℓ2max + ξ2max) + d2 log

1 + 8φmaxK ϵ"
EXP,0.5797598627787307,"
≤δ,"
EXP,0.58147512864494,as claimed.
EXP,0.5831903945111492,"B.5
PROOF OF PROPOSITION 3.8"
EXP,0.5849056603773585,ˆ˜L(φ; Z) is twice differentiable and convex in φ. Note that the minimization problem of ˆL(θ; Z) is
EXP,0.5866209262435678,"equivalent to that of ˆ˜L(g(ˆθ); Z). We consider two cases. First, consider the case where ˆθ has rank d."
EXP,0.5883361921097771,"The ﬁrst order condition ∇ˆL(θ; Z) = 0 is the same as ∇ˆ˜L(g(ˆθ); Z) = 0, which gives"
EXP,0.5900514579759862,"∇ˆ˜L(ˆφ; Z)ˆθ = 0.
(18)"
EXP,0.5917667238421955,"As ˆθ is of full row rank, there exists a matrix ˆθ† ∈Rk×d such that ˆθˆθ† = I (e.g. ˆθ† = ˆθ⊤(ˆθˆθ⊤)−1).
We can right multiply the above equation by ˆθ† and obtain that"
EXP,0.5934819897084048,∇ˆ˜L(ˆφ; Z) = 0.
EXP,0.5951972555746141,"As ˆ˜L(φ; Z) is convex in φ, the above implies ˆφ = g(ˆθ) is a global minimum of ˆ˜L(φ; Z). Therefore,
ˆθ is a global minimum of ˆL(θ; Z). Next, consider the case where the rank of ˆθ is smaller than d. In
this case, we follow the proof strategy in Proposition 4 in Bach et al. (2008); we provide here for
completeness. In this case, Equation (18) still holds, which implies"
EXP,0.5969125214408233,"0 = ∇ˆ˜L(ˆφ; Z)ˆθˆθ⊤= ∇ˆ˜L(ˆφ; Z)ˆφ.
(19)"
EXP,0.5986277873070326,The Hessian of ˆ˜L(g(ˆθ); Z) has
EXP,0.6003430531732419,"∇2 ˆ˜L(g(ˆθ); Z)(∆, ∆) = 2⟨∇ˆ˜L(ˆφ; Z), ∆∆⊤⟩+ ∇2 ˆ˜L(ˆφ; Z)(ˆθ∆⊤+ ∆ˆθ⊤, ˆθ∆⊤+ ∆ˆθ⊤)."
EXP,0.6020583190394511,Under review as a conference paper at ICLR 2022
EXP,0.6037735849056604,"As ˆθR is also a local minimum for any orthogonal matrix R (i.e., RR⊤= R⊤R = I), we can ﬁnd a
ˆθ with the last column being 0 by right multiplying certain R. Then, consider any ∆with the ﬁrst
k −1 columns being 0 and the last column being any u ∈Rd. With this choice of ∆and ˆθ, ˆθ∆⊤= 0.
Therefore,"
EXP,0.6054888507718696,"∇2 ˆ˜L(g(ˆθ); Z)(∆, ∆) = 2u⊤∇ˆ˜L(ˆφ; Z)u."
EXP,0.6072041166380789,"Since ˆθ is a local minimum of ˆ˜L(g(ˆθ); Z), it holds that ∇2 ˆ˜L(g(ˆθ); Z)(∆, ∆) ≥0, which implies"
EXP,0.6089193825042881,"∇ˆ˜L(ˆφ; Z) ⪰0.
(20)"
EXP,0.6106346483704974,Equation (19) and (20) together comprise the ﬁrst order conditions of the convex minimization
EXP,0.6123499142367067,"problem minφ⪰0 ˆ˜L(φ; Z). Thus, ˆθ is also a global minimum."
EXP,0.614065180102916,"C
PROOFS FOR SECTION 4"
EXP,0.6157804459691252,"First, we provide the full statement of Theorem 4.2 (including constants).
Theorem C.1. The expected regret of Algorithm 1 is"
EXP,0.6174957118353345,"R(T) ≤C0 + C1 · T 2/3

log

3 + 8φmaxKT ℓ2max"
EXP,0.6192109777015438,"1/3
, where"
EXP,0.6209262435677531,"C0 =
64(φmax)"
EXP,0.6226415094339622,"2d2+2
2d2−1"
EXP,0.6243567753001715,(135M(ℓmax + ξmax)2d3)
EXP,0.6260720411663808,"2d2+2
2d2−1 (8φmaxK/ℓ2max) 3d2"
EXP,0.62778730703259,"2d2−1
,"
EXP,0.6295025728987993,C1 = 162d2(M 2(ℓmax + ξmax)4φmax)1/3.
EXP,0.6312178387650086,"Before we prove Theorem C.1, we ﬁrst prove a preliminary result establishing an analog of the
smooth best arm response property Rusmevichientong & Tsitsiklis (2010) to our setting. First, we
have the following useful result:
Lemma C.2. Let φ, φ′ ∈Rd×d be symmetric matrices, let x, x′ ∈Rd be eigenvectors of φ, φ′
corresponding to their top eigenvalue, such that ∥x∥2 = ∥x′∥2 = 1, and let λ1 ≥λ2 ≥... ≥λd be
the eigenvalues of φ′. Suppose that ⟨x, x′⟩≥0. Then, we have"
EXP,0.6329331046312179,∥x −x′∥2 ≤23/2∥φ −φ′∥2
EXP,0.6346483704974271,"λ1 −λ2
."
EXP,0.6363636363636364,Proof. See Corollary 3 of Yu et al. (2015).
EXP,0.6380789022298456,"Next, let χ : Rd×d →2X denote the subset of reward-maximizing arms for g(θ) = θθ⊤—i.e.,"
EXP,0.6397941680960549,"χ(φ) = arg max
x∈X
x⊤φx,"
EXP,0.6415094339622641,"where the argmax returns the set of all optimal values. Then, we have the following analog of smooth
best arm response:
Lemma C.3. For any φ ∈Rd×d, there exists x ∈χ(φ) and x∗∈χ(φ∗) such that"
EXP,0.6432246998284734,∥x −x∗∥2 ≤M∥φ −φ∗∥F .
EXP,0.6449399656946827,"Proof. First, note that x, x∗are eigenvectors of φ, φ∗corresponding to their top eigenvalues, re-
spectively. Next, note that if x∗∈χ(φ∗), then we also have −x∗∈χ(φ∗); thus, without loss of
generality, we can assume that ⟨x∗, x⟩≥0. Also, note that ∥x∥2 = ∥x∗∥2 = 1 since the optimizer
maximizes the magnitude of x. Thus, we have"
EXP,0.6466552315608919,∥x −x∗∥2 ≤23/2∥φ −φ∗∥2
EXP,0.6483704974271012,"λ1 −λ2
≤M∥φ −φ∗∥F ,"
EXP,0.6500857632933105,"where the second inequality follows by by Lemma C.2, and the third inequality follows by Assump-
tion 4.1, as claimed."
EXP,0.6518010291595198,Under review as a conference paper at ICLR 2022
EXP,0.6535162950257289,"Now, we prove Theorem C.1. The cumulative regret R(T) of a horizon of T has that"
EXP,0.6552315608919382,"R(T) = E "" T
X"
EXP,0.6569468267581475,"t=1
(fθ∗(x∗) −fθ∗(xt)) # = E "" m
X"
EXP,0.6586620926243568,"t=1
(fθ∗(x∗) −fθ∗(xt)) + T
X"
EXP,0.660377358490566,"t=m+1
(fθ∗(x∗) −fθ∗(xt)) #"
EXP,0.6620926243567753,"≤2mφmax + E ""
T
X"
EXP,0.6638078902229846,"t=m+1
⟨g(ˆθ) −g(θ∗), ˆxˆx⊤−x∗x∗⊤⟩+ T
X"
EXP,0.6655231560891939,"t=m+1
⟨g(ˆθ), x∗x∗⊤−ˆxˆx⊤⟩ # , (21)"
EXP,0.6672384219554031,"where ˆθ is an estimator that minimizes the empirical loss of the ﬁrst m samples, ˆx ∈χ(g(ˆθ))
maximizes the estimated expected reward fˆθ(x), and ⟨φ, φ′⟩= Pd
i,j=1 φijφ′
ij is the matrix inner
product. Since ˆx is a maximizer of fˆθ(x) = ⟨g(ˆθ), xx⊤⟩, we have ⟨g(ˆθ), x∗x∗⊤−ˆxˆx⊤⟩≤0. Thus,
continuing from (21), we have"
EXP,0.6689536878216124,"R(T) ≤2mφmax + E ""
T
X"
EXP,0.6706689536878216,"t=m+1
⟨g(ˆθ) −g(θ∗), ˆxˆx⊤−x∗x∗⊤⟩ #"
EXP,0.6723842195540308,"≤2mφmax + (T −m)E
h
∥g(ˆθ) −g(θ∗)∥F ∥ˆxˆx⊤−x∗x∗⊤∥F
i
.
(22)"
EXP,0.6740994854202401,"To bound the second term in (22), note that"
EXP,0.6758147512864494,"∥ˆxˆx⊤−x∗x∗⊤∥F ≤∥ˆxˆx⊤−ˆxx∗⊤∥F + ∥ˆxx∗⊤−x∗x∗⊤∥F ≤2M∥g(ˆθ) −g(θ∗)∥F ,"
EXP,0.6775300171526587,"where the last step follows by Lemma C.3. Next, by Theorem 3.6, we have"
EXP,0.6792452830188679,∥g(ˆθ) −g(θ∗)∥F ≤ r 2ϵ α
EXP,0.6809605488850772,"= d
453ℓ2
max(ℓ2
max + ξ2
max)
10m"
EXP,0.6826758147512865,"
d2 max

1, log

1 + 8φmaxKm ℓ2max"
EXP,0.6843910806174958,"
+ log 2 δ 1/4"
EXP,0.6861063464837049,"with probability at least 1 −δ. Now, deﬁning the event G = ("
EXP,0.6878216123499142,"∥g(ˆθ) −g(θ∗)∥F ≤ r 2ϵ α ) ,"
EXP,0.6895368782161235,letting
EXP,0.6912521440823327,"δ = 2 exp

−d2 max

1, log

1 + 8φmaxKm ℓ2max 
,"
EXP,0.692967409948542,"and continuing from (22), we have"
EXP,0.6946826758147513,"R(T) ≤2mφmax + T · E
h
∥g(ˆθ) −g(θ∗)∥F ∥ˆxˆx⊤−x∗x∗⊤∥F 1(G)
i
+ 4Tφmax · P(Gc)"
EXP,0.6963979416809606,"≤2mφmax + 2MT · E
h
∥g(ˆθ) −g(θ∗)∥2
F
 G
i
+ 4Tφmax · P(Gc)"
EXP,0.6981132075471698,≤2mφmax + 270M(ℓmax + ξmax)2d3T r
EXP,0.6998284734133791,log(3 + 8φmaxKT/ℓ2max)
EXP,0.7015437392795884,"m
+
8Tφmax
(8φmaxKm/ℓ2max)d2 . (23)"
EXP,0.7032590051457976,The third term in inequality (23) is smaller than the second term when m ≥
EXP,0.7049742710120068,"4φmax
135M(ℓmax + ξmax)2d3(8φmaxK/ℓ2max)d2p"
EXP,0.7066895368782161,log(3 + 8φmaxKT/ℓ2max)
EXP,0.7084048027444254,!1/(d2−1/2)
EXP,0.7101200686106347,".
(24)"
EXP,0.7118353344768439,Under review as a conference paper at ICLR 2022
EXP,0.7135506003430532,"For a choice of m satisfying (24), continuing from (23), we have"
EXP,0.7152658662092625,R(T) ≤2mφmax + 540M(ℓmax + ξmax)2d3T r
EXP,0.7169811320754716,log(3 + 8φmaxKT/ℓ2max)
EXP,0.7186963979416809,"m
.
(25)"
EXP,0.7204116638078902,"Next, we choose m to minimize the upper bound in (24) for sufﬁciently large T—in particular, m =  "
EXP,0.7221269296740995,"135M(ℓmax + ξmax)2d3T
p"
EXP,0.7238421955403087,"log(3 + 8φmaxKT/ℓ2max)
φmax ! 2 3 "
EXP,0.725557461406518,"
.
(26)"
EXP,0.7272727272727273,"With this choice of m, we have"
EXP,0.7289879931389366,"R(T) ≤162(M 2(ℓmax + ξmax)4φmax)
1
3 d2T 2/3(log(3 + 8φmaxKT/ℓ2
max))
1
3 ."
EXP,0.7307032590051458,"Finally, note that (24) holds under the choice of m in (26) for T satisfying T
p"
EXP,0.7324185248713551,"log(3 + 8φmaxKT/ℓ2max) ≥
64(φmax)"
EXP,0.7341337907375644,"2d2+2
2d2−1"
EXP,0.7358490566037735,(135M(ℓmax + ξmax)2d3)
EXP,0.7375643224699828,"2d2+2
2d2−1 (8φmaxK/ℓ2max) 3d2"
EXP,0.7392795883361921,"2d2−1
."
EXP,0.7409948542024014,The claim follows.
EXP,0.7427101200686106,"D
PROOF OF THEOREM 5.2"
EXP,0.7444253859348199,"First, we have the following key result:"
EXP,0.7461406518010292,"Lemma D.1. Let θ, θ′ ∈Rd×k, and let φ = θθ⊤and φ′ = θ′θ′⊤. Assume that ∥φ −φ′∥F ≤η, and
that σmin(θ) ≥σ0 > 0, where σmin(θ) is the minimum singular value of θ (more precisely, the dth
largest singular value). Then, there exist orthogonal matrices R, R′ ∈Rk×k such that"
EXP,0.7478559176672385,∥θR −θ′R′∥F ≤η
EXP,0.7495711835334476,"σ0
.
(27)"
EXP,0.7512864493996569,"Proof. Consider the SVDs θ = UΣV ⊤and θ′ = U ′Σ′V ′⊤, where U, U ′ ∈Rd×d, Σ, Σ′ ∈Rd×d,
and V, V ′ ∈Rk×d; then, we have φ = UΣ2U ⊤and φ′ = U ′Σ′2U ′⊤. Then, we claim that the choices
R = V U ⊤and R′ = V ′U ′⊤satisfy (27). In particular, note that θR = UΣU ⊤and θ′R′ = U ′Σ′U ′⊤,
since V ⊤V = V ′⊤V ′ = Id since k ≥d, where Id ∈Rd×d is the d-dimensional identity matrix.
Thus, it sufﬁces to show that"
EXP,0.7530017152658662,"σ0∥UΣU ⊤−U ′Σ′U ′⊤∥F ≤η.
(28)"
EXP,0.7547169811320755,"To this end, note that"
EXP,0.7564322469982847,"η ≥∥φ −φ′∥F = ∥UΣ2U ⊤−U ′Σ′2U ′⊤∥F = ∥U ′⊤UΣ2 −Σ′2U ′⊤U∥F ,
(29)"
EXP,0.758147512864494,"where in the last step, we have multiplied the expression inside the Frobenius norm by U ′⊤on the
left and by U on the right, using the fact that the Frobenius norm is invariant under multiplication by
orthogonal matrices. Deﬁning W = U ′⊤U, note that"
EXP,0.7598627787307033,"(WΣ)ij = d
X"
EXP,0.7615780445969125,"k=1
WikΣkj = WijΣjj
(30)"
EXP,0.7632933104631218,"(ΣW)ij = d
X"
EXP,0.7650085763293311,"k=1
Σ′
ikWkj = WijΣ′
ii
(31)"
EXP,0.7667238421955404,"(WΣ2)ij = d
X"
EXP,0.7684391080617495,"k=1
Wik(Σ2)kj = WijΣ2
jj
(32)"
EXP,0.7701543739279588,"(Σ2W)ij = d
X"
EXP,0.7718696397941681,"k=1
(Σ′2)ikWkj = WijΣ′2
ii.
(33)"
EXP,0.7735849056603774,Under review as a conference paper at ICLR 2022
EXP,0.7753001715265866,"Then, continuing from (29), we have"
EXP,0.7770154373927959,"η2 ≥∥WΣ2 −Σ′2W∥2
F = d
X"
EXP,0.7787307032590052,"i,j=1
W 2
ij(Σ2
jj −Σ′2
ii)2 = d
X"
EXP,0.7804459691252144,"i,j=1
W 2
ij(Σjj −Σ′
ii)2(Σjj + Σ′
ii)2 ≥ d
X"
EXP,0.7821612349914236,"i,j=1
W 2
ij(Σjj −Σ′
ii)2σ2
0"
EXP,0.7838765008576329,"= σ2
0∥WΣ −Σ′W∥2
F
= σ2
0∥U ′⊤UΣ −Σ′U ′⊤U∥2
F
= σ2
0∥UΣU ⊤−U ′Σ′U ′⊤∥2
F ,"
EXP,0.7855917667238422,"where on the ﬁrst line, we have used (32) & (33), on the third line we have used Σjj ≥σ0, on the
fourth line we have used (30) & (31), and on the last line we have multiplied on by U ′ on the left
U ⊤on the right, again using the fact that the Frobenius norm is invariant under multiplication by
orthogonal matrices. Thus, we have shown (28), so the claim follows."
EXP,0.7873070325900514,"We note here that our result provides an analog of Lemma 6 in Ge et al. (2017a) for quadratic neural
networks."
EXP,0.7890222984562607,"Now, we prove Theorem 5.2. First, by directly applying the arguments in the proof of Theorem 3.6,
we have"
EXP,0.79073756432247,"∥g(ˆθp) −g(θ∗
p)∥F ≤ r 2ϵp"
EXP,0.7924528301886793,"α
with probability at least 1 −δ/2. However, ˆθp itself may not be close to θ∗
p. Instead, applying
Lemma D.1 with θ = ˆθp and θ′ = θ∗
p, and with η =
p"
EXP,0.7941680960548885,"2ϵp/α, there exists an orthogonal matrix
Rp = R′R⊤that “aligns” ˆθp with θ∗
p, yielding"
EXP,0.7958833619210978,"∥ˆθp −θ∗
pRp∥F ≤1 σ0 r 2ϵp α ,"
EXP,0.7975986277873071,"where σ0 is the minimum singular value of θ∗
p. Now, let ˜θg = θ∗
gRp, and note that this is a global
minimizer (i.e., g(˜θg) = g(θ∗
g)), since Rp is orthogonal. Then, we have"
EXP,0.7993138936535163,"∥˜θg −ˆθp∥F ≤∥θ∗
gRp −θ∗
pRp∥F + ∥θ∗
pRp −ˆθp∥F"
EXP,0.8010291595197255,"≤∥θ∗
g −θ∗
p∥F + 1 σ0 r 2ϵp α"
EXP,0.8027444253859348,≤B + 1 σ0 r 2ϵp
EXP,0.8044596912521441,"α
(34)"
EXP,0.8061749571183533,"with probability at least 1 −δ/2. In other words, an alternative global minimizer ˜θg exists within a
small Frobenius norm of our proxy estimator ˆθp, even if ˆθp is not close to θ∗
p."
EXP,0.8078902229845626,"Finally, on the event that (34) holds, note that for θ ∈B2(ˆθp, ˆB), we have the alternative upper bound"
EXP,0.8096054888507719,"|fθ(x) −fθ∗g(x))| ≤K∥g(θ) −g(θ∗
g)∥F ≤K ˆB,"
EXP,0.8113207547169812,"where the ﬁrst inequality holds by Lemma 3.4; thus, we can take ℓmax = K ˆB. Thus, on the event that
(34) holds, by Theorem 3.6, we have Pp(Z)"
EXP,0.8130360205831904,"
Lq(ˆθg) ≤2K2ϵg α"
EXP,0.8147512864493996,"
≥1 −δ 2,"
EXP,0.8164665523156089,so the claim follows by a union bound.
EXP,0.8181818181818182,Under review as a conference paper at ICLR 2022
EXP,0.8198970840480274,"E
PROOFS FOR SECTION 6"
EXP,0.8216123499142367,"E.1
PROOF OF PROPOSITION 6.4"
EXP,0.823327615780446,"Suppose that zt ∈{0, 1} is binary, z0 = 0, and"
EXP,0.8250428816466552,"˜p(z | z′) =
1
if z = z′"
EXP,0.8267581475128645,"0
otherwise."
EXP,0.8284734133790738,"In particular, since z0 = 0, p(w) = 1(w = w0) places all weight on the zero sequence w0 = 0...0.
Next, consider the shifted distribution"
EXP,0.8301886792452831,"˜q(zt | zt−1) = 
 "
EXP,0.8319039451114922,"1
if z = z′ = 1
1 −α/2
if z = z′ = 0
α/2
otherwise."
EXP,0.8336192109777015,"Note that ∥˜p(· | z′) −˜q(· | z′)∥TV ≤α, so Assumption 6.3 is satisﬁed. Note that"
EXP,0.8353344768439108,"q(w0) = T
Y"
EXP,0.8370497427101201,"t=1
˜q(0 | 0) = (1 −α/2)T ."
EXP,0.8387650085763293,"As a consequence, we have"
EXP,0.8404802744425386,"∥p −q∥TV =
X"
EXP,0.8421955403087479,"w∈W
|p(w) −q(w)|"
EXP,0.8439108061749572,"= |p(w0) −q(w0)| +
X"
EXP,0.8456260720411664,"w∈W\{w0}
q(w)"
EXP,0.8473413379073756,= (1 −(1 −α/2)T ) + (1 −(1 −α/2)T )
EXP,0.8490566037735849,"= 2(1 −(1 −α/2)T ),"
EXP,0.8507718696397941,as claimed.
EXP,0.8524871355060034,"E.2
PROOF OF LEMMA 6.5"
EXP,0.8542024013722127,Note that
EXP,0.855917667238422,"∥˜qt −˜pt∥TV = k
X j=1"
EXP,0.8576329331046312,"Z
|˜qt(z, j) −˜pt(z, j)|dz = k
X j=1 k
X j′=1"
EXP,0.8593481989708405,"Z
1(j = ˜g∗(z′, j′)) · |˜q(z | z′)˜qt−1(z′, j′) −˜p(z | z′)˜pt−1(z′, j′)|dz′dz = k
X j′=1"
EXP,0.8610634648370498,"Z
|˜q(z | z′)˜qt−1(z′, j′) −˜p(z | z′)˜pt−1(z′, j′)|dz′dz ≤ k
X j′=1"
EXP,0.8627787307032591,"Z
|˜q(z | z′) −˜p(z | z′)| · ˜qt−1(z′, j′) + ˜p(z | z′) · |˜qt−1(z′, j′) −˜pt−1(z′, j′)|dz′dz ≤ k
X j′=1"
EXP,0.8644939965694682,"Z
α · ˜qt−1(z′, j′) + |˜qt−1(z′, j′) −˜pt−1(z′, j′)|dz′"
EXP,0.8662092624356775,≤α + ∥˜qt−1 −˜pt−1∥TV.
EXP,0.8679245283018868,"Since q0(z, j) = p0(z, j) for all z ∈Z and j ∈[k], by induction, ∥˜qt −˜pt∥TV ≤tα. Thus, we have"
EXP,0.869639794168096,"∥˜q −˜p∥TV ≤1 T T
X"
EXP,0.8713550600343053,"t=1
∥˜qt −˜pt∥≤Tα,"
EXP,0.8730703259005146,as claimed.
EXP,0.8747855917667239,Under review as a conference paper at ICLR 2022
EXP,0.8765008576329331,"E.3
PROOF OF LEMMA 6.6"
EXP,0.8782161234991424,"First, we prove the following lemma.
Lemma E.1. We have"
EXP,0.8799313893653516,"˜pt(zt, jt−1) = k
X"
EXP,0.8816466552315609,"j1,...,jt−2"
EXP,0.8833619210977701,"Z  t−1
Y"
EXP,0.8850771869639794,"τ=1
1(jτ = ˜g∗(zτ, jτ−1)) !"
EXP,0.8867924528301887,"· p(z1, ..., zt)dz1...dzt−1."
EXP,0.888507718696398,"Proof. For the base case, we have"
EXP,0.8902229845626072,"˜p2(z2, j1) = k
X j0=1"
EXP,0.8919382504288165,"Z
1(j1 = ˜g∗(z1, j0)) · ˜p(z2 | z1) · ˜p1(z1, j0)dz1 = k
X j0=1"
EXP,0.8936535162950258,"Z
1(j1 = ˜g∗(z1, j0)) · ˜p(z2 | z1) · 1(j = 0) · ˜p(z1)dz1"
EXP,0.8953687821612349,"=
Z
1(j1 = ˜g∗(z1, j0)) · p(z1, z2)dz1,"
EXP,0.8970840480274442,"as claimed. For the inductive case, we have"
EXP,0.8987993138936535,"˜pt(zt, jt−1) = k
X"
EXP,0.9005145797598628,jt−2=1
EXP,0.902229845626072,"Z
1(jt−1 = ˜g∗(zt−1, jt−2)) · ˜p(zt | zt−1) · ˜pt−1(zt−1, jt−2)dzt−1 = k
X"
EXP,0.9039451114922813,"j1,...,jt−2=1"
EXP,0.9056603773584906,"Z  t−1
Y"
EXP,0.9073756432246999,"τ=1
1(jτ−1 = ˜g∗(zτ−1, jτ−2)) !"
EXP,0.9090909090909091,"· p(z1, ..., zt)dz1...dzt−1."
EXP,0.9108061749571184,as claimed.
EXP,0.9125214408233276,"Now, we prove Lemma 6.6. First, note that for each t ∈[T], we have Pp(w) """
EXP,0.9142367066895368,"(ˆg(w)t ̸= g∗(w)t) ∧ t−1
^"
EXP,0.9159519725557461,"τ=1
ˆg(w)τ = g∗(w)τ !#"
EXP,0.9176672384219554,"=
Z
1(ˆg(w)t ̸= g∗(w)t) · t−1
Y"
EXP,0.9193825042881647,"τ=1
1(ˆg(w)τ = g∗(w)τ) !"
EXP,0.9210977701543739,"· p(w)dw = k
X"
EXP,0.9228130360205832,"j1,...,jt−1=1"
EXP,0.9245283018867925,"Z
1(ˆg(w)t ̸= g∗(w)t) · t−1
Y"
EXP,0.9262435677530018,"τ=1
1(ˆg(w)τ = g∗(w)τ) !"
EXP,0.9279588336192109,"· p(j1...jt−1 | w) · p(w)dw = k
X"
EXP,0.9296740994854202,"j1,...,jt−1=1"
EXP,0.9313893653516295,"Z
1(ˆg(w)t ̸= g∗(w)t) · · t−1
Y"
EXP,0.9331046312178388,"τ=1
1(ˆg(w)τ = g∗(w)τ) ! · t−1
Y"
EXP,0.934819897084048,"τ=1
1(jτ = ˜g∗(zτ, jτ−1)) !"
EXP,0.9365351629502573,"· p(w)dw = k
X"
EXP,0.9382504288164666,"j1,...,jt−1=1"
EXP,0.9399656946826758,"Z
1(ˆ˜g(zτ, jτ−1) ̸= ˜g∗(zτ, jτ−1)) · t−1
Y"
EXP,0.9416809605488851,"τ=1
1(ˆ˜g(zτ, jτ−1) = ˜g∗(zτ, jτ−1)) ! · t−1
Y"
EXP,0.9433962264150944,"τ=1
1(jτ = ˜g∗(zτ, jτ−1)) !"
EXP,0.9451114922813036,"· p(w)dw ≤ k
X"
EXP,0.9468267581475128,"j1,...,jt−1=1"
EXP,0.9485420240137221,"Z
1(ˆ˜g(zτ, jτ−1) ̸= ˜g∗(zτ, jτ−1)) · t−1
Y"
EXP,0.9502572898799314,"τ=1
1(jτ = ˜g∗(zτ, jτ−1)) !"
EXP,0.9519725557461407,"· p(w)dw = k
X"
EXP,0.9536878216123499,"j1,...,jt−1=1"
EXP,0.9554030874785592,"Z
1(ˆ˜g(zτ, jτ−1) ̸= ˜g∗(zτ, jτ−1)) · t−1
Y"
EXP,0.9571183533447685,"τ=1
1(jτ = ˜g∗(zτ, jτ−1)) !"
EXP,0.9588336192109777,"· p(z1, ..., zt)dz1...dzt"
EXP,0.9605488850771869,"= Ppt(z,j)
h
ˆ˜g(zτ, jτ−1) ̸= ˜g∗(zτ, jτ−1)
i
,"
EXP,0.9622641509433962,Under review as a conference paper at ICLR 2022
EXP,0.9639794168096055,"where the last step follows from Lemma E.1. Now, note that"
EXP,0.9656946826758147,"Pp(w)[ˆg(w) ̸= g∗(w)] = T
X"
EXP,0.967409948542024,"t=1
Pp(w) """
EXP,0.9691252144082333,"(ˆg(w)t ̸= g∗(w)t) ∧ t−1
^"
EXP,0.9708404802744426,"τ=1
ˆg(w)τ = g∗(w)τ !# ≤ T
X"
EXP,0.9725557461406518,"t=1
P˜pt(z,j)
h
ˆ˜g(z, j) ̸= ˜g∗(z, j)
i ≤Tϵg,"
EXP,0.9742710120068611,as claimed.
EXP,0.9759862778730704,"E.4
PROOF OF THEOREM 6.7"
EXP,0.9777015437392796,"First, we show that Pq(z,j)[ˆ˜g(z, j) ̸= ˜g∗(z, j)] ≤ϵg + Tα. To this end, note that"
EXP,0.9794168096054888,"Pq(z,j)[ˆ˜g(z, j) ̸= ˜g∗(z, j)]"
EXP,0.9811320754716981,"= Pp(z,j)[ˆ˜g(z, j) ̸= ˜g∗(z, j)] + Pq(z,j)[ˆ˜g(z, j) ̸= ˜g∗(z, j)] −Pp(z,j)[ˆ˜g(z, j) ̸= ˜g∗(z, j)] ≤ϵg + k
X j=1"
EXP,0.9828473413379074,"Z
1(ˆ˜g(z, j) ̸= ˜g∗(z, j)) · |˜q(z, j) −˜p(z, j)|dz"
EXP,0.9845626072041166,"≤ϵg + ∥˜q −˜p∥TV
≤ϵg + Tα."
EXP,0.9862778730703259,"Next, by Lemma 6.6 with q in place of p and ϵg +Tα in place of ϵg, we have Pq(w)[ˆg(w) ̸= g∗(w)] ≤
Tϵg + T 2α. Then, assuming that ˆg(w) = g∗(w), we have"
EXP,0.9879931389365352,"∥f ∗(x, w) −ˆf(x, w)∥2"
EXP,0.9897084048027445,"= ∥(f ∗
jT ◦... ◦f ∗
j1)(x) −( ˆfjT ◦... ◦ˆfj1)(x)∥2 ≤ T
X"
EXP,0.9914236706689536,"t=1
∥(f ∗
jT ◦... ◦f ∗
jt+1 ◦f ∗
jt ◦ˆfjt−1 ◦... ◦ˆfj1)(x) −(f ∗
jT ◦... ◦f ∗
jt+1 ◦ˆfjt ◦ˆfjt−1 ◦... ◦ˆfj1)(x)∥2 ≤ T
X"
EXP,0.9931389365351629,"t=1
KT −t · ∥(f ∗
jt ◦ˆfjt−1 ◦... ◦ˆfj1)(x) −( ˆfjt ◦ˆfjt−1 ◦... ◦ˆfj1)(x)∥2 ≤ T
X"
EXP,0.9948542024013722,"t=1
KT −tϵf"
EXP,0.9965694682675815,"≤Tϵf · max{KT −1, 1}."
EXP,0.9982847341337907,The claim follows by a union bound.
