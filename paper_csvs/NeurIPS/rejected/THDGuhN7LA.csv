Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.001941747572815534,"Few-shot object detection (FSOD) is an emerging problem aimed at detecting novel
1"
ABSTRACT,0.003883495145631068,"concepts from few exemplars. Existing approaches to FSOD assume abundant base
2"
ABSTRACT,0.005825242718446602,"labels to adapt to novel objects. This paper studies the task of semi-supervised
3"
ABSTRACT,0.007766990291262136,"FSOD by considering a realistic scenario in which both base and novel labels are
4"
ABSTRACT,0.009708737864077669,"simultaneously scarce. We explore the utility of unlabeled data and discover its
5"
ABSTRACT,0.011650485436893204,"remarkable ability to boost semi-supervised FSOD by way of region proposals.
6"
ABSTRACT,0.013592233009708738,"Motivated by this finding, we introduce SoftER Teacher, a robust detector combin-
7"
ABSTRACT,0.015533980582524271,"ing pseudo-labeling with representation learning on region proposals, to harness
8"
ABSTRACT,0.017475728155339806,"unlabeled data for improved FSOD without relying on abundant labels. Extensive
9"
ABSTRACT,0.019417475728155338,"experiments show that SoftER Teacher surpasses the novel performance of a strong
10"
ABSTRACT,0.021359223300970873,"supervised detector using only 10% of required base labels, without experiencing
11"
ABSTRACT,0.02330097087378641,"catastrophic forgetting observed in prior approaches. Our work also sheds light on
12"
ABSTRACT,0.02524271844660194,"a potential relationship between semi-supervised and few-shot detection suggesting
13"
ABSTRACT,0.027184466019417475,"that a stronger semi-supervised detector leads to a more effective few-shot detector.
14"
INTRODUCTION,0.02912621359223301,"1
Introduction
15"
INTRODUCTION,0.031067961165048542,"Modern object detection systems have enjoyed
tremendous progress in recent years, with many
successful applications across diverse indus-
tries. Their success can be mainly attributed
to the availability of large-scale, well-annotated
datasets such as the MS-COCO benchmark [28].
However, the demand for more powerful and
accurate detection models requires consider-
able investments in the hand-labeling of mas-
sive amounts of data, which are costly to scale.
Thus, there is a growing trend in the com-
munity to shift toward a more label-efficient
paradigm, one that can enable detection mod-
els to do more with less hand-labeled data.
Such emerging research directions include self-
supervised representation learning from unla-
beled data [2, 7, 39], multi-modal pre-training
from Web-labeled data [25, 32], semi-supervised
detection (SSOD) [30, 48, 52], and few-shot de-
tection (FSOD) [10, 11, 47], all of which have
shown great promise in alleviating the depen-
dency on large amounts of instance-level class
annotations and bounding boxes."
INTRODUCTION,0.03300970873786408,"32
34
36
38
40
42
44
46
Base AP (%) 28 30 32 34 36"
INTRODUCTION,0.03495145631067961,Overall Base + Novel AP (%)
INTRODUCTION,0.036893203883495145,"MS-COCO Benchmark
30-Shot Object Detection"
INTRODUCTION,0.038834951456310676,nAP 12.1
INTRODUCTION,0.040776699029126215,nAP 24.5
INTRODUCTION,0.04271844660194175,nAP 21.2
INTRODUCTION,0.04466019417475728,nAP 21.9
INTRODUCTION,0.04660194174757282,nAP 12.4 Ours
INTRODUCTION,0.04854368932038835,nAP 14.0
INTRODUCTION,0.05048543689320388,"TFA [ICML'20]
LVC [CVPR'22]
DeFRCN [ICCV'21]
DCFS [NeurIPS'22]
Retentive R-CNN [CVPR'21]
SoftER Teacher (Ours)
Base AP Supervised Upperbound
Base AP Semi-Supervised Upperbound"
INTRODUCTION,0.05242718446601942,"Figure 1: The evaluation of generalized FSOD is
characterized by the trade-off between novel accuracy
and base forgetting. We leverage unlabeled data to
optimize for semi-supervised FSOD on both classes.
Our approach significantly expands base class AP
(39.3 →44.4) while exhibiting less than 7% in base
degradation (vs. 16% for LVC [21]). SoftER Teacher
is the best model on the Overall AP metric, leading
the next best Retentive R-CNN [10] by +2.0 AP.
16"
INTRODUCTION,0.05436893203883495,"Figure 2: We present the Label-Efficient Detection framework to harness supplementary unlabeled data for
generalized semi-supervised few-shot detection. At the core of the framework is our proposed SoftER Teacher
with Entropy Regression for improved semi-supervised base representation learning (upper right). Extensive
comparative experiments show that SoftER Teacher is also a more label-efficient few-shot detector (lower right)."
INTRODUCTION,0.05631067961165048,"This paper focuses on the intersection of SSOD and FSOD, which are essentially two sides of the
17"
INTRODUCTION,0.05825242718446602,"same coin in the context of label-efficient detection. On one side, SSOD investigates the detection
18"
INTRODUCTION,0.06019417475728155,"problem with a small fraction of images containing ground truth labels. On the other side, FSOD
19"
INTRODUCTION,0.062135922330097085,"addresses the objective of adapting a base detector to learn novel concepts from few instance-level
20"
INTRODUCTION,0.06407766990291262,"annotations. Existing approaches to FSOD assume abundant base classes to train the base detector.
21"
INTRODUCTION,0.06601941747572816,"However, such assumption is not ideal in practical scenarios where labels may be limited for both
22"
INTRODUCTION,0.06796116504854369,"base and novel classes, giving rise to the research question: can we do more on FSOD with the
23"
INTRODUCTION,0.06990291262135923,"available unlabeled data without additional hand-labeling?
24"
INTRODUCTION,0.07184466019417475,"We answer this question by introducing the unique task of semi-supervised few-shot detection, in
25"
INTRODUCTION,0.07378640776699029,"which we explore the utility of unlabeled data for improving detection with label scarcity for both
26"
INTRODUCTION,0.07572815533980583,"base and novel classes. Inspired by recent advances in SSOD and FSOD, our approach is two-fold:
27"
INTRODUCTION,0.07766990291262135,"(1) we leverage unlabeled data to improve detection with a small fraction of labeled images; and (2)
28"
INTRODUCTION,0.07961165048543689,"we generalize the resulting semi-supervised detector into a label-efficient few-shot detector by way of
29"
INTRODUCTION,0.08155339805825243,"transfer learning. Our chief motivation is to not necessarily depend on an abundance of base classes
30"
INTRODUCTION,0.08349514563106795,"for robust few-shot detection, which increases the versatility of our approach in realistic applications.
31"
INTRODUCTION,0.0854368932038835,"Moreover, our approach to semi-supervised FSOD adapts a base detector to learn novel concepts
32"
INTRODUCTION,0.08737864077669903,"with reduced performance degradation to base classes, a desirable result missing in most prior
33"
INTRODUCTION,0.08932038834951456,"approaches. Figure 1 illustrates that while recent work [11, 21, 36] achieve impressive detection on
34"
INTRODUCTION,0.0912621359223301,"novel categories, they all ignore the importance of preserving base class accuracy. For generalized
35"
INTRODUCTION,0.09320388349514563,"FSOD [10], the goal is to expand the learned vocabulary of the base detector with novel concepts. As
36"
INTRODUCTION,0.09514563106796116,"such, base and novel class performances are equally important, since samples at test time may contain
37"
INTRODUCTION,0.0970873786407767,"instances of both objects. Therefore, the more realistic evaluation metric for FSOD is not only novel
38"
INTRODUCTION,0.09902912621359224,"AP, but the combined base and novel AP, for which our approach establishes a new state of the art.
39"
INTRODUCTION,0.10097087378640776,"We measure the utility of unlabeled data within our integrated semi-supervised few-shot framework,
40"
INTRODUCTION,0.1029126213592233,"and discover an interesting empirical finding connecting the effectiveness of unlabeled data to
41"
INTRODUCTION,0.10485436893203884,"semi-supervised FSOD by way of region proposals. Without bells and whistles, by simply adding
42"
INTRODUCTION,0.10679611650485436,"unlabeled data to a supervised detector, we show a marked improvement on both base and novel class
43"
INTRODUCTION,0.1087378640776699,"performances while also mitigating catastrophic base forgetting [31].
44"
INTRODUCTION,0.11067961165048544,"Summary of Main Contributions.
First, we introduce SoftER Teacher, a simple yet effective
45"
INTRODUCTION,0.11262135922330097,"and versatile detector, to combine the strengths of pseudo-labeling with representation learning on
46"
INTRODUCTION,0.1145631067961165,"unlabeled images. SoftER Teacher enhances the quality of region proposals to substantially boost
47"
INTRODUCTION,0.11650485436893204,"semi-supervised FSOD. Our empirical analysis on the relationship between unlabeled data and region
48"
INTRODUCTION,0.11844660194174757,"proposals extends earlier results on proposal evaluation beyond supervised detection [17, 46].
49"
INTRODUCTION,0.1203883495145631,"Second, Figure 2 illustrates a potential relationship suggesting that a strong semi-supervised detector
50"
INTRODUCTION,0.12233009708737864,"is also a label-efficient few-shot detector, an interesting and non-trivial empirical observation linking
51"
INTRODUCTION,0.12427184466019417,"the two disparate domains. On the task of semi-supervised FSOD, our SoftER Teacher model exceeds
52"
INTRODUCTION,0.1262135922330097,"the novel class performance of a strong supervised detector [10] using only 10% of required base
53"
INTRODUCTION,0.12815533980582525,"labels, while exhibiting less than 9% in base forgetting. When trained on 100% of labeled base
54"
INTRODUCTION,0.13009708737864079,"classes with supplementary unlabeled data, SoftER Teacher sets a new standard on semi-supervised
55"
INTRODUCTION,0.13203883495145632,"few-shot performance using varying amounts of bounding box annotations.
56"
INTRODUCTION,0.13398058252427184,"Third, we establish the Label-Efficient Detection benchmark to quantify the utility of unlabeled data
57"
INTRODUCTION,0.13592233009708737,"for generalized semi-supervised FSOD. We hope that our benchmark serves as a strong baseline, and
58"
INTRODUCTION,0.1378640776699029,"a blueprint, to inspire future research toward this new problem setting in the community.
59"
RELATED WORK,0.13980582524271845,"2
Related Work
60"
RELATED WORK,0.141747572815534,"Semi-Supervised Detection.
Recent approaches to SSOD can be summarized into consistency-
61"
RELATED WORK,0.1436893203883495,"based and pseudo-labeling categories. The leading consistency method is Humble Teacher [44], which
62"
RELATED WORK,0.14563106796116504,"trains a pair of detectors on both labeled and unlabeled data in the student-teacher framework [16, 45].
63"
RELATED WORK,0.14757281553398058,"Humble Teacher learns representations from unlabeled data by enforcing consistency on predicted
64"
RELATED WORK,0.14951456310679612,"soft labels from region proposals. Humble Teacher was inspired by CSD [18], which was the first
65"
RELATED WORK,0.15145631067961166,"approach to leverage consistency regularization [40] for SSOD, but utilizes strong data augmentation
66"
RELATED WORK,0.1533980582524272,"to deliver robust performance.
67"
RELATED WORK,0.1553398058252427,"The state of the art on SSOD, however, belongs to a family of pseudo-labeling methods, which
68"
RELATED WORK,0.15728155339805824,"trains a pair of detectors on pseudo labels along with (limited) human labels. One such method is
69"
RELATED WORK,0.15922330097087378,"Soft Teacher [52] which vastly improves upon its previous counterparts STAC [42] and Unbiased
70"
RELATED WORK,0.16116504854368932,"Teacher [29] by enabling end-to-end pseudo-labeling on unlabeled images. More recently, Consistent
71"
RELATED WORK,0.16310679611650486,"Teacher [48] advances the performance envelope by reducing the inconsistency of pseudo targets. In
72"
RELATED WORK,0.1650485436893204,"both consistency-based and pseudo-labeling methods, the teacher model is an exponential moving
73"
RELATED WORK,0.1669902912621359,"average (EMA) of its student counterpart and is used to predict soft or pseudo labels on unlabeled data.
74"
RELATED WORK,0.16893203883495145,"The main difference between the two is how the surrogate labels are used to generate unsupervised
75"
RELATED WORK,0.170873786407767,"targets to be jointly trained with the supervised objective.
76"
RELATED WORK,0.17281553398058253,"We extend the strong performance of Soft Teacher by incorporating a new module for Entropy
77"
RELATED WORK,0.17475728155339806,"Regression to learn additional representations from unlabeled images by way of region proposals.
78"
RELATED WORK,0.1766990291262136,"Our model, aptly named SoftER Teacher, combines the attractive benefits of pseudo-labeling with
79"
RELATED WORK,0.1786407766990291,"supplementary proposal learning to establish a stronger baseline for SSOD.
80"
RELATED WORK,0.18058252427184465,"Few-Shot Detection.
Existing methods on FSOD can also be grouped into two categories: meta
81"
RELATED WORK,0.1825242718446602,"learning and transfer learning. Early work on meta learning introduced meta models to acquire
82"
RELATED WORK,0.18446601941747573,"class-level knowledge for adapting a base detector to novel concepts. Meta learners are jointly trained
83"
RELATED WORK,0.18640776699029127,"and fine-tuned with the base detectors to perform tasks like feature re-weighting, such as FSRW [19]
84"
RELATED WORK,0.1883495145631068,"and Meta R-CNN [53], or category-specific weight prediction (MetaDet) [49] using few exemplars of
85"
RELATED WORK,0.19029126213592232,"support images and ground truth bounding box annotations for the target objects.
86"
RELATED WORK,0.19223300970873786,"Recent work on transfer learning for FSOD found that fine-tuning the last layer of the pre-trained
87"
RELATED WORK,0.1941747572815534,"base detector (i.e., the box classifier and regressor) on a balanced subset of base and novel classes,
88"
RELATED WORK,0.19611650485436893,"while freezing the rest of the detector, can significantly improve detection accuracy. The simple yet
89"
RELATED WORK,0.19805825242718447,"effective two-stage fine-tuning approach TFA [47] outperformed all prior meta learning methods on
90"
RELATED WORK,0.2,"both base and novel detection metrics. Retentive R-CNN [10] extends TFA by introducing the Bias-
91"
RELATED WORK,0.20194174757281552,"Balanced RPN and Re-Detector modules to achieve strong novel performance without sacrificing base
92"
RELATED WORK,0.20388349514563106,"accuracy, a desideratum of FSOD. Other transfer learning methods, such as FSCE [43], DeFRCN [36],
93"
RELATED WORK,0.2058252427184466,"FADI [3], and DCFS [11], address the shortcomings of the box classifier to boost FSOD. While
94"
RELATED WORK,0.20776699029126214,"these methods obtain impressive performance on novel categories, they suffer from considerable base
95"
RELATED WORK,0.20970873786407768,"class forgetting, making them sub-optimal in real-world applications requiring efficient and accurate
96"
RELATED WORK,0.21165048543689322,"detection on test samples containing instances of both classes.
97"
RELATED WORK,0.21359223300970873,"We show that both base and novel class performances can be further improved when unlabeled images
98"
RELATED WORK,0.21553398058252426,"are incorporated into the two-stage fine-tuning procedure without catastrophic base forgetting, which
99"
RELATED WORK,0.2174757281553398,"lead to a new standard for semi-supervised FSOD.
100"
RELATED WORK,0.21941747572815534,"Semi-Supervised Few-Shot Detection.
There have been few attempts at leveraging unlabeled
101"
RELATED WORK,0.22135922330097088,"data to improve FSOD, but to our knowledge none directly addressed the task of optimizing for
102"
RELATED WORK,0.22330097087378642,"semi-supervised few-shot detection, in which setting both base and novel labels are simultaneously
103"
RELATED WORK,0.22524271844660193,"scarce. LVC [21] mines novel targets from the same base training dataset via pseudo-labeling to boost
104"
RELATED WORK,0.22718446601941747,"novel class detection, but comes at the cost of base performance. UniT [22] obtains impressive results
105"
RELATED WORK,0.229126213592233,"on any-shot detection, but assumes abundant image-level labels for the base and novel targets. And
106"
RELATED WORK,0.23106796116504855,"SSFOD [51] performs semi-supervised FSOD within an episodic meta training and N-way k-shot
107"
RELATED WORK,0.23300970873786409,"evaluation framework [20] while also requiring abundant base classes. Our approach is fundamentally
108"
RELATED WORK,0.23495145631067962,"different in that we do not strictly depend on abundant base labels, but make effective utilization of
109"
RELATED WORK,0.23689320388349513,"external unlabeled data for robust semi-supervised FSOD with reduced base degradation.
110"
APPROACH,0.23883495145631067,"3
Approach
111"
APPROACH,0.2407766990291262,"We propose to combine the available (limited) labeled examples with supplementary unlabeled images
112"
APPROACH,0.24271844660194175,"to boost semi-supervised FSOD. We begin with the fully supervised scenario in which we have access
113"
APPROACH,0.2446601941747573,"to a set of labeled image-target pairs (xl, yl) ∈Dsup. The supervised FSOD setting [10, 19, 47]
114"
APPROACH,0.24660194174757283,"assumes a base dataset Cbase ∈Dsup with abundant instance-level annotations and a novel dataset
115"
APPROACH,0.24854368932038834,"Cnovel ∈Dsup with only a few k (e.g., k ∈{1, 5, 10}) labeled instances, or “shots”, per category. The
116"
APPROACH,0.2504854368932039,"goal of FSOD is to expand the base detector by adapting it to learn new target concepts such that the
117"
APPROACH,0.2524271844660194,"resulting detector is optimized for accuracy on a test set comprising both classes in Cbase ∪Cnovel.
118"
APPROACH,0.2543689320388349,"To maintain parity with existing work, we adopt the simple yet effective two-stage transfer learning
119"
APPROACH,0.2563106796116505,"approach [10, 47] currently leading the FSOD literature, which comprises an initial stage of base
120"
APPROACH,0.258252427184466,"class pre-training followed by a second stage of novel category fine-tuning. We consider the modern
121"
APPROACH,0.26019417475728157,"Faster R-CNN (FRCN) [37] system as our supervised base detector, which consists of a ResNet [15]
122"
APPROACH,0.2621359223300971,"backbone and a feature pyramid network (FPN) [27] neck for feature extraction, a region proposal
123"
APPROACH,0.26407766990291265,"network (RPN), an RoIAlign [14] operation for mapping proposals to region-of-interest (RoI) features,
124"
APPROACH,0.26601941747572816,"and a fully-connected head for RoI classification and regression. Let FRCN be represented by fθ, a
125"
APPROACH,0.26796116504854367,"stochastic function parametrized by a set of learnable weights θ. Formally, the base pre-training step
126"
APPROACH,0.26990291262135924,"is subjected to the standard supervised objective, over a mini-batch of labeled examples bl, given by:
127"
APPROACH,0.27184466019417475,Lsup = 1 |bl| X
APPROACH,0.2737864077669903,"i∈bl
Lroi
cls(fθ(xi), yi) + Lroi
reg(fθ(xi), yi).
(1)"
APPROACH,0.2757281553398058,"Here, fθ(xi) denotes a forward pass on the i-th image to produce box classification and localization
128"
APPROACH,0.27766990291262134,"predictions from class-agnostic proposals, yi is the i-th ground truth annotation containing box labels
129"
APPROACH,0.2796116504854369,"and coordinates, and
 
Lroi
cls, Lroi
reg

are the cross-entropy and L1 losses, respectively, for the RoI head.
130"
APPROACH,0.2815533980582524,"Henceforth for simplicity, we develop our approach only on the RoI head and omit the presentation
131"
APPROACH,0.283495145631068,"on the classification and regression losses of the RPN, which remain constant without changes, to
132"
APPROACH,0.2854368932038835,"predict and localize the “objectness” of region proposals.
133"
APPROACH,0.287378640776699,"3.1
What Makes for Effective FSOD?
134"
APPROACH,0.28932038834951457,"We revisit this question from the perspective of maximizing representation learning while minimizing
135"
APPROACH,0.2912621359223301,"base forgetting. In two-stage detectors [14, 37], the quality of region proposals is a strong predictor
136"
APPROACH,0.29320388349514565,"of supervised detection performance [17, 46], since they focus the detector head on candidate RoIs.
137"
APPROACH,0.29514563106796116,"This is especially true for FSOD approaches based on transfer learning, in which the established
138"
APPROACH,0.2970873786407767,"procedure is to freeze the RPN during few-shot fine-tuning. Intuitively, if we can incorporate methods
139"
APPROACH,0.29902912621359223,"and/or data to boost representation learning by way of the RPN, then the detector should have a
140"
APPROACH,0.30097087378640774,"higher chance of discovering novel categories to improve few-shot performance.
141"
APPROACH,0.3029126213592233,"We conduct extensive experiments on the COCO dataset to verify our intuition. We split the dataset
142"
APPROACH,0.3048543689320388,"into disjoint 60 base and 20 novel categories and pre-train three variants of the FRCN detector on
143"
APPROACH,0.3067961165048544,"the base classes: (i) FRCN-Base, (ii) FRCN-Base augmented with COCO unlabeled2017 images
144"
APPROACH,0.3087378640776699,"leveraging the Soft Teacher formulation, and (iii) FRCN-Full using both base and novel classes to
145"
APPROACH,0.3106796116504854,"represent the upper-bound performance. We also experiment with CRPN-Base, a method specially
146"
APPROACH,0.312621359223301,"designed to improve proposal quality and detection performance using a two-stage Cascade RPN [46].
147"
APPROACH,0.3145631067961165,"Figure 3a quantifies the “class-agnosticism” of various RPNs, using the standard metric AR@300
148"
APPROACH,0.31650485436893205,"proposals, for varying fractions of base labels. Surprisingly, unlabeled data has the remarkable ability
149"
APPROACH,0.31844660194174756,"to boost proposal recall on novel-only categories, even in the extremely low 1% label limit. Somewhat
150"
APPROACH,0.32038834951456313,"unsurprising is the ability of CRPN-Base to propose novel objects competitive with FRCN-Base
151"
APPROACH,0.32233009708737864,"+ Unlabeled when more base labels are available. Consistent with previous findings [10, 21],
152"
APPROACH,0.32427184466019415,"Figures 3b and 3c show that the vanilla supervised FRCN-Base has a strong tendency to reject novel
153"
APPROACH,0.3262135922330097,"objects as background, due to the lack of annotations, resulting in the worst recall on novel classes.
154"
APPROACH,0.32815533980582523,"As alluded in Section 1, the contribution of unlabeled data to FSOD goes beyond improving base
155"
APPROACH,0.3300970873786408,"and novel detection performances; unlabeled data can also help mitigate catastrophic base forgetting.
156"
APPROACH,0.3320388349514563,"1
5
10
Percentage of Base Labels 20 30 40 50 60"
APPROACH,0.3339805825242718,Novel AR@300 (%)
APPROACH,0.3359223300970874,"1
5
10
Percentage of Base Labels 20 30 40 50 60"
APPROACH,0.3378640776699029,Overall AR@300 (%)
APPROACH,0.33980582524271846,"FRCN-Full
FRCN-Base + Unlabeled
CRPN-Base
FRCN-Base"
APPROACH,0.341747572815534,"(a) Impact of unlabeled data on proposal quality
(b) RPN w/ 1% labels
(c) RPN w/ 10% labels"
APPROACH,0.34368932038834954,"Figure 3: We analyze the effectiveness of the RPN as a function of base labels. (a) Unlabeled data provides a
convincing boost in proposal quality, closing the gap between the Base and Full detectors, which should lead
to better discovery of novel categories during fine-tuning. (b–c) In low-label regimes, unlabeled data can help
produce diverse proposals (green boxes) on novel unseen objects {boat, bus, car, dog}, whereas the vanilla
supervised FRCN-Base fails to capture comparable foreground objects (red boxes). Best viewed digitally."
APPROACH,0.34563106796116505,"We find analogous effectiveness of FRCN-Base + Unlabeled on the combined Overall AR@300
157"
APPROACH,0.34757281553398056,"metric, for both base + novel objects, suggesting the RPN, when trained with unlabeled data, has the
158"
APPROACH,0.34951456310679613,"ability to retain base proposals and help combat base degradation during few-shot fine-tuning.
159"
APPROACH,0.35145631067961164,"Discussion.
This paper rethinks a different and more versatile way to improve the RPN for FSOD
160"
APPROACH,0.3533980582524272,"while avoiding catastrophic forgetting. The previous LVC approach proposed to unfreeze the RPN
161"
APPROACH,0.3553398058252427,"during fine-tuning to obtain large performance gains on novel categories, but comes at the cost of
162"
APPROACH,0.3572815533980582,"significant base degradation (up to 19%). Similarly, FSCE [43] proposed to unfreeze the RPN while
163"
APPROACH,0.3592233009708738,"also doubling the number of proposals to encourage novel foreground detection during fine-tuning.
164"
APPROACH,0.3611650485436893,"However, this method increases the detection overhead and remains unclear whether it helps mitigate
165"
APPROACH,0.36310679611650487,"base forgetting. We illustrate that simply adding unlabeled data to the base detector leads to a
166"
APPROACH,0.3650485436893204,"compelling boost in proposal quality, without the need for any ad hoc modifications to the RPN.
167"
APPROACH,0.36699029126213595,"We attribute this unique benefit of our approach to the potential base-novel object interactions found
168"
APPROACH,0.36893203883495146,"in abundant images. When learning with unlabeled data, the base detector can obtain semantically
169"
APPROACH,0.37087378640776697,"similar cues of novel objects to inform the RPN on foreground detection. Sun et al. [43] showed that
170"
APPROACH,0.37281553398058254,"visually analogous objects have high cosine similarity scores (e.g., sim(cow, horse) = 0.39). With
171"
APPROACH,0.37475728155339805,"1% of labels, these base-novel interactions are limited, resulting in a recall of 22.7%. Given a sizable
172"
APPROACH,0.3766990291262136,"unlabeled dataset, the base detector improves its representations to yield a gain of +12.3 points.
173"
SEMI-SUPERVISED BASE PRE-TRAINING,0.3786407766990291,"3.2
Semi-Supervised Base Pre-Training
174"
SEMI-SUPERVISED BASE PRE-TRAINING,0.38058252427184464,"Motivated by the promising utility of unlabeled data, we now relax the strict assumption on having
175"
SEMI-SUPERVISED BASE PRE-TRAINING,0.3825242718446602,"abundant base classes for FSOD and introduce a new and more general setting of having a small
176"
SEMI-SUPERVISED BASE PRE-TRAINING,0.3844660194174757,"fraction of base labels given abundant unlabeled images. We revisit the task of semi-supervised
177"
SEMI-SUPERVISED BASE PRE-TRAINING,0.3864077669902913,"base pre-training by formulating an unsupervised loss computed on an unlabeled dataset Dunsup to be
178"
SEMI-SUPERVISED BASE PRE-TRAINING,0.3883495145631068,"jointly trained with the supervised loss on Dsup. We consider the following canonical optimization
179"
SEMI-SUPERVISED BASE PRE-TRAINING,0.39029126213592236,"objective widely adopted as part of the framework for semi-supervised learning [1, 23, 33]:
180"
SEMI-SUPERVISED BASE PRE-TRAINING,0.39223300970873787,"min
θ
Lsup(Dsup, θ) + λLunsup(Dunsup, θ),
(2)"
SEMI-SUPERVISED BASE PRE-TRAINING,0.3941747572815534,"where λ > 0 is a hyper-parameter controlling the contribution of the unsupervised component. Next,
181"
SEMI-SUPERVISED BASE PRE-TRAINING,0.39611650485436894,"we describe the unsupervised criterion on Dunsup to make FRCN into a semi-supervised detector.
182"
SEMI-SUPERVISED BASE PRE-TRAINING,0.39805825242718446,"Soft Teacher.
We adopt Soft Teacher [52] as the baseline SSOD formulation for its simplicity
183"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4,"but strong performance. Soft Teacher trains FRCN in a student-teacher fashion on both labeled
184"
SEMI-SUPERVISED BASE PRE-TRAINING,0.40194174757281553,"and unlabeled data. The student is trained on labeled examples in the standard supervised manner
185"
SEMI-SUPERVISED BASE PRE-TRAINING,0.40388349514563104,"per Eq. (1). For unlabeled images, the teacher is treated as a fixed detector to generate thousands
186"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4058252427184466,"of box candidates, most of which are eliminated for redundancy with non-maximum suppression.
187"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4077669902912621,"Additionally, box candidates are thresholded for foreground objects and go through an iterative
188"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4097087378640777,"jittering-refinement procedure to reduce localization variance, resulting in a set of high-quality
189"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4116504854368932,"pseudo boxes to be jointly trained with ground truth annotations.
190"
SEMI-SUPERVISED BASE PRE-TRAINING,0.41359223300970877,"As is common practice [41, 45], the teacher’s parameters ¯θ are updated from the student’s via
191"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4155339805825243,"¯θ = EMA(θ) at each training step. Integral to the success of Soft Teacher is a student-teacher data
192"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4174757281553398,"augmentation strategy inspired by STAC [42]. The student trains on unlabeled images subjected to
193"
SEMI-SUPERVISED BASE PRE-TRAINING,0.41941747572815535,"complex random perturbations, akin to RandAugment [6], including affine transforms. Separately,
194"
SEMI-SUPERVISED BASE PRE-TRAINING,0.42135922330097086,"Student Proposals
Teacher Proposals
Student Proposals
Teacher Proposals M
M"
SEMI-SUPERVISED BASE PRE-TRAINING,0.42330097087378643,"Figure 4: Visualization of student-teacher proposals with confidence scores ≥0.99. As illustrated by the arrow,
a pair of student-teacher proposals is related by a transformation matrix M, which is used to align proposals
between student and teacher images for enforcing box classification similarity and localization consistency."
SEMI-SUPERVISED BASE PRE-TRAINING,0.42524271844660194,"the teacher receives weakly augmented images with simple random resizing and flipping. This
195"
SEMI-SUPERVISED BASE PRE-TRAINING,0.42718446601941745,"multi-stream augmentation design allows the teacher to generate reliable unsupervised targets on
196"
SEMI-SUPERVISED BASE PRE-TRAINING,0.429126213592233,"easy images to guide the student’s learning on difficult images for better generalization.
197"
SEMI-SUPERVISED BASE PRE-TRAINING,0.43106796116504853,"At the time of box classification and regression in the RoI head, we have a set of unlabeled images
198"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4330097087378641,"along with teacher-generated pseudo labels (xu, ˆyu) ∈Dunsup. The unsupervised loss for Soft Teacher
199"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4349514563106796,"on a mini-batch of unlabeled images bu is defined as:
200"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4368932038834951,"Lsoft
unsup =
1
|bu| X"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4388349514563107,"i∈bu
Lroi
cls(fθ(xi), ˆyi) + Lroi
reg(fθ(xi), ˆyi).
(3)"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4407766990291262,"SoftER Teacher.
The design of Soft Teacher employs class confidence thresholding and box
201"
SEMI-SUPERVISED BASE PRE-TRAINING,0.44271844660194176,"jittering to select high-quality pseudo-label candidates for unsupervised classification and regression.
202"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4446601941747573,"However, it uses an aggressive threshold of 0.9, resulting in a trade-off between low recall and high
203"
SEMI-SUPERVISED BASE PRE-TRAINING,0.44660194174757284,"precision at 33% and 89%, respectively [52]. We observe that low recall can result in poor detection
204"
SEMI-SUPERVISED BASE PRE-TRAINING,0.44854368932038835,"performance on small and ambiguous objects [26], especially in low-label regimes where the teacher
205"
SEMI-SUPERVISED BASE PRE-TRAINING,0.45048543689320386,"has insufficient confidence about its predicted pseudo labels. We aim to extend Soft Teacher and
206"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4524271844660194,"improve its detection recall by learning additional representations from abundant region proposals.
207"
SEMI-SUPERVISED BASE PRE-TRAINING,0.45436893203883494,"Given a set of proposals p generated by the student’s RPN on a batch of unlabeled images, we
208"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4563106796116505,"apply the student-teacher data augmentation pipeline described above to obtain (ps, pt), denoting
209"
SEMI-SUPERVISED BASE PRE-TRAINING,0.458252427184466,"transformed student and teacher proposals, which are related to each other by a transformation matrix
210"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4601941747572815,"M. We then forward pass Faster R-CNN twice, as the student fθ and teacher f¯θ, to obtain two sets
211"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4621359223300971,"of RoI outputs for predicted box classification logits (zs, zt) and localization coordinates (rs, rt).
212"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4640776699029126,"Let gc be the softmax function over the channel dimension c. We define an auxiliary unsupervised
213"
SEMI-SUPERVISED BASE PRE-TRAINING,0.46601941747572817,"criterion for proposal box similarity based on a cross-entropy measure H(zs, zt):
214"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4679611650485437,"Lent
cls =
1
P i wi X"
SEMI-SUPERVISED BASE PRE-TRAINING,0.46990291262135925,"i∈p
wi · H(zis, zit),"
SEMI-SUPERVISED BASE PRE-TRAINING,0.47184466019417476,"in which
H(zis, zit) = −1 C X"
SEMI-SUPERVISED BASE PRE-TRAINING,0.47378640776699027,"c∈C
gc(zit) log gc(zis).
(4)"
SEMI-SUPERVISED BASE PRE-TRAINING,0.47572815533980584,"Here, gc outputs a distribution over C classes and wi is the Boolean weight for the predicted positive
215"
SEMI-SUPERVISED BASE PRE-TRAINING,0.47766990291262135,"(foreground) class: wi = 1 if argmax(zit) ̸= background, else wi = 0.
216"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4796116504854369,"Similarly for proposal box regression, we constrain the predicted box coordinates (rs, rt) to be
217"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4815533980582524,"close. Since there are complex geometric distortions between the two, we first map teacher proposal
218"
SEMI-SUPERVISED BASE PRE-TRAINING,0.48349514563106794,"coordinates rt to the student space using the transformation M. Then, we align the proposal boxes
219"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4854368932038835,"via the intersection-over-union (IoU) criterion:
220"
SEMI-SUPERVISED BASE PRE-TRAINING,0.487378640776699,"Liou
reg = 1 −1 |p| X"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4893203883495146,"i∈p
wi · IoU(ris, M(rit)),
(5)"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4912621359223301,"where we treat the IoU metric as a loss [38] to quantify the discrepancy between student and teacher
221"
SEMI-SUPERVISED BASE PRE-TRAINING,0.49320388349514566,"proposal coordinates. Note that both the cross-entropy and IoU losses, Eqs. (4) and (5), are computed
222"
SEMI-SUPERVISED BASE PRE-TRAINING,0.49514563106796117,"only on predicted foreground classes.
223"
SEMI-SUPERVISED BASE PRE-TRAINING,0.4970873786407767,"Recall that we have two different transformation pipelines operating on each proposal, so we have
224"
SEMI-SUPERVISED BASE PRE-TRAINING,0.49902912621359224,"two augmented views of each proposal. Figure 4 illustrates that by enforcing these randomly
225"
SEMI-SUPERVISED BASE PRE-TRAINING,0.5009708737864078,"augmented views, and their box coordinates, to be similar, we enable the student to tap into abundant
226"
SEMI-SUPERVISED BASE PRE-TRAINING,0.5029126213592233,"region proposals to learn diverse feature representations across a spectrum of scale, color, and
227"
SEMI-SUPERVISED BASE PRE-TRAINING,0.5048543689320388,"geometric perturbations. Our formulation draws inspiration from recent research on self-supervised
228"
SEMI-SUPERVISED BASE PRE-TRAINING,0.5067961165048543,"representation learning with multi-augmented views [5, 13]. Note the cross-entropy similarity between
229"
SEMI-SUPERVISED BASE PRE-TRAINING,0.5087378640776699,"the student and teacher predictions, Eq. (4), can be interpreted as a form of entropy regularization [12],
230"
SEMI-SUPERVISED BASE PRE-TRAINING,0.5106796116504855,"which has been proven to work well in various semi-supervised classification scenarios [33, 34]. The
231"
SEMI-SUPERVISED BASE PRE-TRAINING,0.512621359223301,"overall optimization objective at the RoI head for our SoftER Teacher model is computed as:
232"
SEMI-SUPERVISED BASE PRE-TRAINING,0.5145631067961165,"Lsofter
total = Lsup + αLsoft
unsup + β
 
Lent
cls + Liou
reg

,
(6)"
SEMI-SUPERVISED BASE PRE-TRAINING,0.516504854368932,where we set α = |bu|
SEMI-SUPERVISED BASE PRE-TRAINING,0.5184466019417475,"|bl| following Soft Teacher and find β = 2α works well across all experiments.
233"
SEMI-SUPERVISED BASE PRE-TRAINING,0.5203883495145631,"Discussion.
Our approach to proposal learning is unique and different from Humble Teacher [44] in
234"
SEMI-SUPERVISED BASE PRE-TRAINING,0.5223300970873787,"two major ways: (1) we use diverse data transformations, including geometric distortions, to enforce
235"
SEMI-SUPERVISED BASE PRE-TRAINING,0.5242718446601942,"proposal similarity, whereas Humble Teacher considered only simple random flipping and color
236"
SEMI-SUPERVISED BASE PRE-TRAINING,0.5262135922330097,"transforms; and (2) we adopt the IoU metric for box localization consistency over L2 distance, which
237"
SEMI-SUPERVISED BASE PRE-TRAINING,0.5281553398058253,"has been shown to produce inferior box regression [38]. Further, Humble Teacher acknowledged that
238"
SEMI-SUPERVISED BASE PRE-TRAINING,0.5300970873786408,"matching student-teacher proposals under complex affine transforms is not a trivial task and “could
239"
SEMI-SUPERVISED BASE PRE-TRAINING,0.5320388349514563,"lead to undesirably complicated details.” We solve this complicated task by tracking the affine matrix
240"
SEMI-SUPERVISED BASE PRE-TRAINING,0.5339805825242718,"M in our entropy regression module, to address a key weakness of Soft Teacher by boosting object
241"
SEMI-SUPERVISED BASE PRE-TRAINING,0.5359223300970873,"recall, thereby enabling SoftER Teacher to demonstrate superior learning with unlabeled data over
242"
SEMI-SUPERVISED BASE PRE-TRAINING,0.537864077669903,"Humble Teacher and Soft Teacher. Please refer to Appendix B.3 for detailed comparative results.
243"
SEMI-SUPERVISED FEW-SHOT FINE-TUNING,0.5398058252427185,"3.3
Semi-Supervised Few-Shot Fine-Tuning
244"
SEMI-SUPERVISED FEW-SHOT FINE-TUNING,0.541747572815534,"We propose a simple two-step approach to harness unlabeled data for semi-supervised few-shot
245"
SEMI-SUPERVISED FEW-SHOT FINE-TUNING,0.5436893203883495,"fine-tuning. First, we initialize the few-shot detector, f ′
¯θ ←f¯θ, with parameters copied from the base
246"
SEMI-SUPERVISED FEW-SHOT FINE-TUNING,0.545631067961165,"teacher detector pre-trained with unlabeled data per Eq. (6). And second, we further train the RoI
247"
SEMI-SUPERVISED FEW-SHOT FINE-TUNING,0.5475728155339806,"head of f ′
¯θ on novel classes using the available few-shot and unlabeled examples while freezing the
248"
SEMI-SUPERVISED FEW-SHOT FINE-TUNING,0.5495145631067961,"base backbone, FPN, and RPN components. Then, we fine-tune the few-shot detector on a balanced
249"
SEMI-SUPERVISED FEW-SHOT FINE-TUNING,0.5514563106796116,"training set of k shots per class containing both base and novel instances. We only update the RoI
250"
SEMI-SUPERVISED FEW-SHOT FINE-TUNING,0.5533980582524272,"box classifier while freezing all other components, including the box regressor, since it is the main
251"
SEMI-SUPERVISED FEW-SHOT FINE-TUNING,0.5553398058252427,"source of error [11, 43]. To our knowledge, we are the first to incorporate external unlabeled data
252"
SEMI-SUPERVISED FEW-SHOT FINE-TUNING,0.5572815533980583,"with few-shot fine-tuning, which provides a compelling boost to novel performance while enjoying
253"
SEMI-SUPERVISED FEW-SHOT FINE-TUNING,0.5592233009708738,"substantial gains in base detection without catastrophic forgetting. We present detailed ablation
254"
SEMI-SUPERVISED FEW-SHOT FINE-TUNING,0.5611650485436893,"studies in Appendix A to validate our approach and design choices.
255"
EXPERIMENTS,0.5631067961165048,"4
Experiments
256"
EXPERIMENTS,0.5650485436893203,"Datasets.
Consistent with the current literature on FSOD, we evaluate our approach on the
257"
EXPERIMENTS,0.566990291262136,"challenging PASCAL VOC [9] and MS-COCO 2017 [28] detection benchmarks. For VOC, we use
258"
EXPERIMENTS,0.5689320388349515,"the combined VOC07+12 trainval splits as the labeled training set and evaluate performance
259"
EXPERIMENTS,0.570873786407767,"on the VOC2007 test set. For COCO, we utilize the train2017 split as labeled data and test on
260"
EXPERIMENTS,0.5728155339805825,"val2017. We also leverage COCO-20, the subset of COCO data having the same 20 class names as
261"
EXPERIMENTS,0.574757281553398,"VOC, and COCO unlabeled2017 as the sources of supplementary unlabeled data.
262"
EXPERIMENTS,0.5766990291262136,"Performance Metrics.
Following established evaluation protocol, we assess detection performance
263"
EXPERIMENTS,0.5786407766990291,"using AP50 for the average precision at overlap threshold 0.5 and AP50:95 for the mean average
264"
EXPERIMENTS,0.5805825242718446,"precision computed over a range of 10 overlap thresholds between 0.5 and 0.95. We also report
265"
EXPERIMENTS,0.5825242718446602,"average recall AR to complement AP for assessing object coverage, which has previously been used
266"
EXPERIMENTS,0.5844660194174758,"to evaluate detection performance of small objects [24, 26].
267"
EXPERIMENTS,0.5864077669902913,"Implementation Details.
For most experiments, we adopt the ResNet-101 backbone pre-trained
268"
EXPERIMENTS,0.5883495145631068,"on ImageNet 1K [8] for a direct comparison with existing work. For some experiments, we also
269"
EXPERIMENTS,0.5902912621359223,"employ ResNet-50 to demonstrate parameter-efficient learning with SoftER Teacher. We implement
270"
EXPERIMENTS,0.5922330097087378,"our models in MMDetection [4] and PyTorch [35]. Complete details are given in Appendix C.
271"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.5941747572815534,"4.1
SoftER Teacher is a Parameter- and Label-Efficient Few-Shot Detector
272"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.596116504854369,"We conduct our few-shot experiments on the same VOC and COCO samples provided by the TFA
273"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.5980582524271845,"benchmark [47]. The VOC dataset is randomly partitioned into 15 base and 5 novel classes, in which
274"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6,"Table 1: FSOD results evaluated on COCO val2017. We report the mean and 95% confidence interval over 5
random samples for our models. SoftER Teacher with ResNet-101 is the best model on the combined Overall
AP metric, incurring less than 9% in base forgetting vs. 11%–DCFS, 17%–DeFRCN, and 19%–LVC."
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6019417475728155,"COCO val2017
Backbone
Base AP50:95
Base AP50:95 (60 Classes)
Novel AP50:95 (20 Classes)
Overall AP50:95 (80 Classes)"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6038834951456311,"Method
5-Shot
10-Shot
30-Shot
5-Shot
10-Shot
30-Shot
5-Shot
10-Shot
30-Shot"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6058252427184466,"LVC [21]
R-50
–
–
29.7 ± n/a
33.3 ± n/a
–
17.6 ± n/a
25.5 ± n/a
–
26.7 ± n/a
31.4 ± n/a
SoftER Teacher (Ours)
R-50
42.0
38.4 ± 0.2
38.4 ± 0.2
39.7 ± 0.2
8.2 ± 0.3
10.3 ± 0.5
12.9 ± 0.6
30.9 ± 0.1
31.4 ± 0.2
33.0 ± 0.1"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6077669902912621,"TFA [47]
R-101
39.3
32.3 ± 0.6
32.4 ± 0.6
34.2 ± 0.4
7.0 ± 0.7
9.1 ± 0.5
12.1 ± 0.4
25.9 ± 0.6
26.6 ± 0.5
28.7 ± 0.4
LVC [21]
R-101
39.3
–
31.9 ± n/a
33.0 ± n/a
–
17.8 ± n/a
24.5 ± n/a
–
28.4 ± n/a
30.9 ± n/a
DeFRCN [36]
R-101
39.3
32.6 ± 0.3
34.0 ± 0.2
34.8 ± 0.1
13.6 ± 0.7
16.8 ± 0.6
21.2 ± 0.4
27.8 ± 0.3
29.7 ± 0.2
31.4 ± 0.1
DCFS [11]
R-101
39.3
35.0 ± 0.2
35.7 ± 0.2
35.8 ± 0.2
15.7 ± 0.5
18.3 ± 0.4
21.9 ± 0.3
30.2 ± 0.2
31.4 ± 0.2
32.3 ± 0.2
Retentive R-CNN [10]
R-101
39.3
39.3 ± n/a
39.2 ± n/a
39.3 ± n/a
7.7 ± n/a
9.5 ± n/a
12.4 ± n/a
31.4 ± n/a
31.8 ± n/a
32.6 ± n/a
SoftER Teacher (Ours)
R-101
44.4
40.3 ± 0.2
40.2 ± 0.3
41.4 ± 0.2
8.7 ± 0.6
11.0 ± 0.4
14.0 ± 0.6
32.4 ± 0.2
32.9 ± 0.1
34.6 ± 0.1"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6097087378640776,"Table 2: FSOD results evaluated on VOC07 test. We report the mean and 95% confidence interval over 10
random samples for our models. SoftER Teacher with ResNet-50 surpasses the supervised MPSR, TFA, and
Retentive R-CNN models with ResNet-101 by a large margin on most metrics under consideration, while being
more parameter-efficient. Results for the other two partition splits are given in Appendix B.1."
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6116504854368932,"VOC07 test – Split 1
Backbone
Base
Base
Base AP50 (15 Classes)
Novel AP50 (5 Classes)
Overall AP50 (20 Classes)"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6135922330097088,"Method
AP50
AR50
1-Shot
5-Shot
10-Shot
1-Shot
5-Shot
10-Shot
1-Shot
5-Shot
10-Shot"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6155339805825243,"MPSR [50]
R-101
80.8
–
61.5
69.7
71.6
42.8
55.3
61.2
56.8
66.1
69.0
Retentive R-CNN [10]
R-101
80.8
–
80.9
80.8
80.8
42.4
53.7
56.1
71.3
74.0
74.6
TFA [47]
R-101
80.8
–
77.6 ± 0.2
77.4 ± 0.3
77.5 ± 0.2
25.3 ± 2.2
47.9 ± 1.2
52.8 ± 1.0
64.5 ± 0.6
70.1 ± 0.4
71.3 ± 0.3"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6174757281553398,"Faster R-CNN (Our Impl.)
R-50
81.7
88.0
82.0 ± 0.2
82.4 ± 0.1
82.3 ± 0.1
27.9 ± 3.2
52.1 ± 2.1
58.2 ± 1.6
68.5 ± 0.8
74.9 ± 0.5
76.2 ± 0.4
Soft Teacher (Our Impl.)
R-50
85.3
91.2
84.5 ± 0.3
85.2 ± 0.1
85.2 ± 0.1
29.5 ± 4.2
56.2 ± 2.6
62.3 ± 1.8
70.8 ± 1.1
78.0 ± 0.7
79.5 ± 0.5
SoftER Teacher (Ours)
R-50
85.9
92.5
84.5 ± 0.4
85.5 ± 0.1
85.5 ± 0.1
31.6 ± 3.9
57.7 ± 2.6
63.4 ± 1.7
71.3 ± 1.2
78.5 ± 0.7
80.0 ± 0.4"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6194174757281553,"there are k ∈{1, 5, 10} labeled boxes per category sampled from the joint VOC07+12 trainval
275"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6213592233009708,"splits. And the COCO dataset is divided into 60 base and 20 novel classes having the same VOC
276"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6233009708737864,"category names with k ∈{5, 10, 30} shots. We leverage COCO-20 and unlabeled2017 as external
277"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.625242718446602,"unlabeled data to augment base pre-training and novel fine-tuning on VOC and COCO, respectively.
278"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6271844660194175,"Table 1 compares the effectiveness of SoftER Teacher against transfer-learning methods representing
279"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.629126213592233,"the state of the art on COCO, for the evaluation of both base and novel performances. We report the
280"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6310679611650486,"ideal supervised base AP of 39.3 [10, 47] along with our substantially improved semi-supervised base
281"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6330097087378641,"AP of 44.4 to measure the extent of base forgetting. Recall that the more realistic evaluation metric for
282"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6349514563106796,"generalized FSOD is not only novel AP, but the combination of base and novel AP. We summarize the
283"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6368932038834951,"following key takeaways: (a) SoftER Teacher with ResNet-101 trained with supplementary unlabeled
284"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6388349514563106,"data is the best model on the combined Overall AP metric for 80 classes, leading the next best
285"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6407766990291263,"Retentive R-CNN by up to +2.0 AP; (b) SoftER Teacher with ResNet-50 is on par with Retentive
286"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6427184466019418,"R-CNN while being more parameter-efficient; and (c) SoftER Teacher achieves the state of the art
287"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6446601941747573,"while being more efficient with respect to parameters and labels.
288"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6466019417475728,"We notice a recurring theme in the FSOD literature that seems to favor novel class performance
289"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6485436893203883,"while ignoring base accuracy, even though the detection of both classes is equally important at test
290"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6504854368932039,"time. Table 2 shows comparative results on VOC, for which there are few existing work evaluating
291"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6524271844660194,"on both base and novel AP. We report the ideal supervisd base AP of 80.8 [10, 47] along with our
292"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.654368932038835,"vastly expanded base AP of 85.9 using unlabeled data. SoftER Teacher with ResNet-50 incurs
293"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6563106796116505,"negligible base forgetting of less than 1.6% while exceeding MPSR, TFA, and Retentive R-CNN with
294"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.658252427184466,"ResNet-101 by a notable margin on most metrics. Although MPSR achieves impressive one-shot
295"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6601941747572816,"performance on novel categories, it suffers catastrophic base forgetting by as much as 24%. Retentive
296"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6621359223300971,"R-CNN does not exhibit base class degradation, but generally falls behind on novel class performance.
297"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6640776699029126,"Tables 1 and 2 corroborate our observation on the trade-off between novel performance and base
298"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6660194174757281,"forgetting, for which our approach aims to simultaneously optimize. Due to page limit, we refer to
299"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6679611650485436,"Appendix A for detailed ablation studies analyzing the design and benefits of SoftER Teacher.
300"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6699029126213593,"4.2
How Does Proposal Quality Impact Semi-Supervised Few-Shot Detection?
301"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6718446601941748,"In this section, we continue our discussion from Sec. 3.1 by analyzing semi-supervised FSOD as a
302"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6737864077669903,"function of proposal quality in Figure 5. We measure proposal quality using the metric AR@p [46],
303"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6757281553398058,"for p ∈{100, 300, 1000} proposals, averaged over thresholds between 0.5 and 0.95. We arrive at the
304"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6776699029126214,"following conclusions: (a) SoftER Teacher produces better proposals than the comparisons across
305"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6796116504854369,"varying fractions of labels; and (b–d) proposal quality is strongly correlated with semi-supervised
306"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6815533980582524,"FSOD, an insightful empirical finding that extends existing results beyond supervised detection [17].
307"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.683495145631068,"1
5
10
Percentage of Base Labels 16 20 24 28 32"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6854368932038835,AR@100 (%) (a)
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6873786407766991,"16
18
20
22
24
26
28
30
Proposal Quality AR@100 (%) 2 4 6 8 10 12"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6893203883495146,Novel AP50 : 95 (%)
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6912621359223301,"(b) 30-Shot@1-Percent
Correlation r = 0.986"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6932038834951456,"22
24
26
28
30
32
Proposal Quality AR@100 (%) 4 6 8 10 12 14"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6951456310679611,Novel AP50 : 95 (%)
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6970873786407767,"(c) 30-Shot@5-Percent
Correlation r = 0.987"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.6990291262135923,"24
26
28
30
32
Proposal Quality AR@100 (%) 6 8 10 12 14 16"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.7009708737864078,Novel AP50 : 95 (%)
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.7029126213592233,"(d) 30-Shot@10-Percent
Correlation r = 0.977"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.7048543689320388,"Faster R-CNN w/ ResNet-101
Soft Teacher w/ ResNet-101
SoftER Teacher w/ ResNet-101 (Ours)"
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.7067961165048544,"Figure 5: Proposal quality is highly correlated with semi-supervised FSOD. SoftER Teacher produces the best
proposals among the comparisons (a), which yield the strongest 30-shot performances (b–d). Shaded regions
denote standard deviation over 5 samples. Appendix B.2 gives similar trends for 5-shot and 10-shot results."
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.7087378640776699,"Table 3: We introduce the Label-Efficient Detection benchmark for generalized semi-supervised FSOD on
COCO. All models are trained with ResNet-101. We report the mean and standard deviation over 5 samples.
Using only 10% of base labels (bottom row), SoftER Teacher surpasses the supervised novel performance of
Retentive R-CNN trained with 100% of base labels (top row) while incurring less than 9% in base degradation."
SOFTER TEACHER IS A PARAMETER- AND LABEL-EFFICIENT FEW-SHOT DETECTOR,0.7106796116504854,"Method
% Labeled
Base AP50:95
Base AR50:95
Base AP50:95 (60 Classes)
Novel AP50:95 (20 Classes)
Overall AP50:95 (80 Classes)"
-SHOT,0.7126213592233009,"5-Shot
10-Shot
30-Shot
5-Shot
10-Shot
30-Shot
5-Shot
10-Shot
30-Shot"
-SHOT,0.7145631067961165,"Retentive R-CNN
100
39.3
–
39.3
39.2
39.3
7.7
9.5
12.4
31.4
31.8
32.6
SoftER Teacher
44.4
56.1
40.3 ± 0.2
40.2 ± 0.3
41.4 ± 0.2
8.7 ± 0.6
11.0 ± 0.4
14.0 ± 0.6
32.4 ± 0.2
32.9 ± 0.1
34.6 ± 0.1"
-SHOT,0.7165048543689321,"Faster R-CNN
1
8.7 ± 0.3
12.3 ± 0.5
9.8 ± 0.3
10.0 ± 0.4
10.8 ± 0.3
1.9 ± 0.3
2.7 ± 0.1
3.5 ± 0.1
7.8 ± 0.2
8.2 ± 0.3
9.0 ± 0.2
Soft Teacher
19.9 ± 1.0
30.7 ± 1.1
19.4 ± 0.7
19.9 ± 0.8
21.2 ± 0.7
5.9 ± 0.8
7.9 ± 0.7
10.1 ± 0.5
16.0 ± 0.6
16.9 ± 0.7
18.4 ± 0.6
SoftER Teacher
19.8 ± 0.9
32.5 ± 1.0
19.2 ± 0.6
19.8 ± 0.5
21.1 ± 0.5
6.7 ± 0.3
8.8 ± 0.2
10.8 ± 0.5
16.1 ± 0.5
17.1 ± 0.4
18.5 ± 0.5"
-SHOT,0.7184466019417476,"Faster R-CNN
5
19.1 ± 0.3
25.6 ± 0.4
18.5 ± 0.5
18.9 ± 0.3
20.0 ± 0.5
3.5 ± 0.2
4.6 ± 0.2
5.9 ± 0.3
14.8 ± 0.4
15.3 ± 0.2
16.5 ± 0.4
Soft Teacher
29.6 ± 0.3
38.7 ± 0.3
27.5 ± 0.4
27.8 ± 0.5
29.2 ± 0.5
6.7 ± 0.7
8.9 ± 0.4
11.1 ± 0.3
22.3 ± 0.4
23.1 ± 0.3
24.7 ± 0.4
SoftER Teacher
30.2 ± 0.2
40.7 ± 0.3
27.5 ± 0.4
27.9 ± 0.4
29.3 ± 0.2
7.9 ± 0.4
10.1 ± 0.5
12.4 ± 0.5
22.6 ± 0.3
23.4 ± 0.3
25.1 ± 0.2"
-SHOT,0.7203883495145631,"Faster R-CNN
10
24.7 ± 0.2
32.8 ± 0.3
22.6 ± 0.4
22.8 ± 0.1
24.2 ± 0.2
3.8 ± 0.5
5.3 ± 0.2
6.8 ± 0.2
17.9 ± 0.3
18.4 ± 0.1
19.9 ± 0.2
Soft Teacher
33.3 ± 0.2
42.4 ± 0.2
30.5 ± 0.5
30.7 ± 0.4
32.1 ± 0.3
6.8 ± 0.3
9.0 ± 0.6
11.4 ± 0.3
24.6 ± 0.4
25.3 ± 0.4
26.9 ± 0.3
SoftER Teacher
33.4 ± 0.4
44.1 ± 0.2
30.3 ± 0.5
30.6 ± 0.5
32.0 ± 0.4
7.9 ± 1.3
10.4 ± 1.1
12.9 ± 1.0
24.6 ± 0.1
25.6 ± 0.3
27.2 ± 0.3"
-SHOT,0.7223300970873786,"Although the strong Soft Teacher baseline is effective at harnessing unlabeled data for semi-supervised
308"
-SHOT,0.7242718446601941,"FSOD, our approach demonstrates superior learning by addressing a key shortcoming of Soft Teacher.
309"
-SHOT,0.7262135922330097,"SoftER Teacher boosts object recall via our proposed Entropy Regression module, improving on Soft
310"
-SHOT,0.7281553398058253,"Teacher by +1.2 base AR@100, which yields a gain of +1.5 novel AP for the 30-Shot@10-Percent
311"
-SHOT,0.7300970873786408,"setting. These results further strengthen our empirical observation that a stronger semi-supervised
312"
-SHOT,0.7320388349514563,"detector leads to a more label-efficient few-shot detector. Future work would explore if our finding
313"
-SHOT,0.7339805825242719,"can be extended to a more general case with other SSOD formulations including one-stage detectors.
314"
A NEW BENCHMARK FOR GENERALIZED SEMI-SUPERVISED FEW-SHOT DETECTION,0.7359223300970874,"4.3
A New Benchmark for Generalized Semi-Supervised Few-Shot Detection
315"
A NEW BENCHMARK FOR GENERALIZED SEMI-SUPERVISED FEW-SHOT DETECTION,0.7378640776699029,"We present our Label-Efficient Detection benchmark on COCO val2017 in Table 3, evaluated using
316"
A NEW BENCHMARK FOR GENERALIZED SEMI-SUPERVISED FEW-SHOT DETECTION,0.7398058252427184,"the supervised Faster R-CNN baseline along with the semi-supervised Soft Teacher and SoftER
317"
A NEW BENCHMARK FOR GENERALIZED SEMI-SUPERVISED FEW-SHOT DETECTION,0.7417475728155339,"Teacher models. Our protocol for semi-supervised FSOD is as follows. In the first stage, we pre-train
318"
A NEW BENCHMARK FOR GENERALIZED SEMI-SUPERVISED FEW-SHOT DETECTION,0.7436893203883496,"the base detector on the disjoint 60 base categories using {1, 5, 10} percent of labels per Eq. (6). In
319"
A NEW BENCHMARK FOR GENERALIZED SEMI-SUPERVISED FEW-SHOT DETECTION,0.7456310679611651,"the second stage, we transfer the parameters of the base teacher detector to the few-shot detector
320"
A NEW BENCHMARK FOR GENERALIZED SEMI-SUPERVISED FEW-SHOT DETECTION,0.7475728155339806,"and fine-tune its RoI box classifier, keeping other components frozen, on a balanced training set
321"
A NEW BENCHMARK FOR GENERALIZED SEMI-SUPERVISED FEW-SHOT DETECTION,0.7495145631067961,"of k ∈{5, 10, 30} shots per class containing both base and novel examples. In both stages, we
322"
A NEW BENCHMARK FOR GENERALIZED SEMI-SUPERVISED FEW-SHOT DETECTION,0.7514563106796116,"supplement base pre-training and novel fine-tuning with images from COCO unlabeled2017.
323"
A NEW BENCHMARK FOR GENERALIZED SEMI-SUPERVISED FEW-SHOT DETECTION,0.7533980582524272,"We report AP50:95 performances on both base and novel classes along with the aggregated overall
324"
A NEW BENCHMARK FOR GENERALIZED SEMI-SUPERVISED FEW-SHOT DETECTION,0.7553398058252427,"metric. We also report the ideal AP50:95 and AR50:95 metrics obtained from the first stage of base
325"
A NEW BENCHMARK FOR GENERALIZED SEMI-SUPERVISED FEW-SHOT DETECTION,0.7572815533980582,"pre-training to measure the potential for base forgetting during the few-shot fine-tuning step. We
326"
A NEW BENCHMARK FOR GENERALIZED SEMI-SUPERVISED FEW-SHOT DETECTION,0.7592233009708738,"encourage future work to follow suit as we emphasize the importance of optimizing for accuracy on
327"
A NEW BENCHMARK FOR GENERALIZED SEMI-SUPERVISED FEW-SHOT DETECTION,0.7611650485436893,"both base and novel classes, a desideratum of generalized few-shot object detection.
328"
CONCLUSION,0.7631067961165049,"5
Conclusion
329"
CONCLUSION,0.7650485436893204,"This paper presented the Label-Efficient Detection framework to quantify the utility of unlabeled data
330"
CONCLUSION,0.7669902912621359,"for generalized semi-supervised FSOD. Central to the framework is our SoftER Teacher, a robust
331"
CONCLUSION,0.7689320388349514,"detector combining the strengths of pseudo-labeling with representation learning on unlabeled images.
332"
CONCLUSION,0.7708737864077669,"We demonstrated two main areas of impact: (1) SoftER Teacher achieves superior learning with
333"
CONCLUSION,0.7728155339805826,"unlabeled data to boost semi-supervised FSOD without relying on an abundance of labels; and (2)
334"
CONCLUSION,0.7747572815533981,"our framework sheds empirical insight into a potential relationship that a stronger semi-supervised
335"
CONCLUSION,0.7766990291262136,"detector leads to a more effective few-shot detector, the basis of which could inspire future research.
336"
REFERENCES,0.7786407766990291,"References
337"
REFERENCES,0.7805825242718447,"[1] Philip Bachman, Ouais Alsharif, and Doina Precup. Learning with Pseudo-Ensembles. In NeurIPS, 2014.
338 5
339"
REFERENCES,0.7825242718446602,"[2] Amir Bar, Xin Wang, Vadim Kantorov, Colorado J. Reed, Roei Herzig, Gal Chechik, Anna Rohrbach,
340"
REFERENCES,0.7844660194174757,"Trevor Darrell, and Amir Globerson. DETReg: Unsupervised Pretraining With Region Priors for Object
341"
REFERENCES,0.7864077669902912,"Detection. In CVPR, 2022. 1
342"
REFERENCES,0.7883495145631068,"[3] Yuhang Cao, Jiaqi Wang, Ying Jin, Tong Wu, Kai Chen, Ziwei Liu, and Dahua Lin. Few-Shot Object
343"
REFERENCES,0.7902912621359224,"Detection via Association and Discrimination. In NeurIPS, 2021. 3
344"
REFERENCES,0.7922330097087379,"[4] Kai Chen, Jiaqi Wang, Jiangmiao Pang, Yuhang Cao, Yu Xiong, Xiaoxiao Li, et al. MMDetection: Open
345"
REFERENCES,0.7941747572815534,"MMLab Detection Toolbox and Benchmark. https://arxiv.org/abs/1906.07155, 2019. 7
346"
REFERENCES,0.7961165048543689,"[5] Xinlei Chen and Kaiming He. Exploring Simple Siamese Representation Learning. In CVPR, 2021. 7
347"
REFERENCES,0.7980582524271844,"[6] Ekin D. Cubuk, Barret Zoph, Jonathon Shlens, and Quoc V. Le. RandAugment: Practical Automated Data
348"
REFERENCES,0.8,"Augmentation with a Reduced Search Space. In NeurIPS, 2020. 5
349"
REFERENCES,0.8019417475728156,"[7] Zhigang Dai, Bolun Cai, Yugeng Lin, and Junying Chen. UPDETR: Unsupervised Pre-Training for Object
350"
REFERENCES,0.8038834951456311,"Detection with Transformers. In CVPR, 2021. 1
351"
REFERENCES,0.8058252427184466,"[8] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. ImageNet: A Large-Scale
352"
REFERENCES,0.8077669902912621,"Hierarchical Image Database. In CVPR, pages 248–255, 2009. 7
353"
REFERENCES,0.8097087378640777,"[9] Mark Everingham, Luc Van Gool, Christopher K.I. Williams, John Winn, and Andrew Zisserman. The
354"
REFERENCES,0.8116504854368932,"PASCAL Visual Object Classes (VOC) Challenge. IJCV, 88(2):303–338, 2010. 7
355"
REFERENCES,0.8135922330097087,"[10] Zhibo Fan, Yuchen Ma, Zeming Li, and Jian Sun. Generalized Few-Shot Object Detection without
356"
REFERENCES,0.8155339805825242,"Forgetting. In CVPR, 2021. 1, 2, 3, 4, 8
357"
REFERENCES,0.8174757281553398,"[11] Bin-Bin Gao, Xiaochen Chen, Zhongyi Huang, Congchong Nie, Jun Liu, Jinxiang Lai, Guannan Jiang, Xi
358"
REFERENCES,0.8194174757281554,"Wang, and Chengjie Wang. Decoupling Classifier for Boosting Few-Shot Object Detection and Instance
359"
REFERENCES,0.8213592233009709,"Segmentation. In NeurIPS, 2022. 1, 2, 3, 7, 8
360"
REFERENCES,0.8233009708737864,"[12] Yves Grandvalet and Yoshua Bengio. Semi-Supervised Learning by Entropy Minimization. In NeurIPS,
361"
REFERENCES,0.8252427184466019,"2004. 7
362"
REFERENCES,0.8271844660194175,"[13] Jean-Bastien Grill, Florian Strub, Florent Altché, Corentin Tallec, Pierre H. Richemond, Elena Buchatskaya,
363"
REFERENCES,0.829126213592233,"Carl Doersch, Bernardo Avila Pires, et al. Bootstrap Your Own Latent: A New Approach to Self-Supervised
364"
REFERENCES,0.8310679611650486,"Learning. In NeurIPS, 2020. 7
365"
REFERENCES,0.8330097087378641,"[14] Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick. Mask R-CNN. In ICCV, 2017. 4
366"
REFERENCES,0.8349514563106796,"[15] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep Residual Learning for Image Recognition.
367"
REFERENCES,0.8368932038834952,"In CVPR, 2016. 4
368"
REFERENCES,0.8388349514563107,"[16] Geoffrey Hinton, Oriol Vinyals, and Jeffrey Dean. Distilling the Knowledge in a Neural Network. In
369"
REFERENCES,0.8407766990291262,"NeurIPS Deep Learning and Representation Learning Workshop, 2015. 3
370"
REFERENCES,0.8427184466019417,"[17] Jan Hosang, Rodrigo Benenson, Piotr Dollár, and Bernt Schiele. What Makes for Effective Detection
371"
REFERENCES,0.8446601941747572,"Proposals? IEEE TPAMI, 38(4):814–830, 2016. 2, 4, 8
372"
REFERENCES,0.8466019417475729,"[18] Jisoo Jeong, Seungeui Lee, Jeesoo Kim, and Nojun Kwak. Consistency-Based Semi-Supervised Learning
373"
REFERENCES,0.8485436893203884,"for Object Detection. In NeurIPS, 2019. 3
374"
REFERENCES,0.8504854368932039,"[19] Bingyi Kang, Zhuang Liu, Xin Wang, Fisher Yu, Jiashi Feng, and Trevor Darrell. Few-Shot Object
375"
REFERENCES,0.8524271844660194,"Detection via Feature Reweighting. In ICCV, 2019. 3, 4
376"
REFERENCES,0.8543689320388349,"[20] Leonid Karlinsky, Joseph Shtok, Sivan Harary, Eli Schwartz, Amit Aides, Rogerio Feris, Raja Giryes,
377"
REFERENCES,0.8563106796116505,"and Alex M. Bronstein. RepMet: Representative-Based Metric Learning for Classification and Few-Shot
378"
REFERENCES,0.858252427184466,"Object Detection. In CVPR, 2019. 4
379"
REFERENCES,0.8601941747572815,"[21] Prannay Kaul, Weidi Xie, and Andrew Zisserman. Label, Verify, Correct: A Simple Few Shot Object
380"
REFERENCES,0.8621359223300971,"Detection Method. In CVPR, 2022. 1, 2, 3, 4, 8
381"
REFERENCES,0.8640776699029126,"[22] Siddhesh Khandelwal, Raghav Goyal, and Leonid Sigal. UniT: Unified Knowledge Transfer for Any-shot
382"
REFERENCES,0.8660194174757282,"Object Detection and Segmentation. In CVPR, 2021. 3
383"
REFERENCES,0.8679611650485437,"[23] Samuli Laine and Timo Aila. Temporal Ensembling for Semi-Supervised Learning. In ICLR, 2017. 5
384"
REFERENCES,0.8699029126213592,"[24] Jianan Li, Xiaodan Liang, Yunchao Wei, Tingfa Xu, Jiashi Feng, and Shuicheng Yan. Perceptual Generative
385"
REFERENCES,0.8718446601941747,"Adversarial Networks for Small Object Detection. In CVPR, 2017. 7
386"
REFERENCES,0.8737864077669902,"[25] Yangguang Li, Feng Liang, Lichen Zhao, Yufeng Cui, Wanli Ouyang, Jing Shao, Fengwei Yu, and Junjie
387"
REFERENCES,0.8757281553398059,"Yan. Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-Training Paradigm.
388"
REFERENCES,0.8776699029126214,"In ICLR, 2022. 1
389"
REFERENCES,0.8796116504854369,"[26] Zeming Li, Chao Peng, Gang Yu, Xiangyu Zhang, Yangdong Deng, and Jian Sun. DetNet: A Backbone
390"
REFERENCES,0.8815533980582524,"Network for Object Detection. In ECCV, 2018. 6, 7
391"
REFERENCES,0.883495145631068,"[27] Tsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie. Feature
392"
REFERENCES,0.8854368932038835,"Pyramid Networks for Object Detection. In CVPR, 2017. 4
393"
REFERENCES,0.887378640776699,"[28] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár,
394"
REFERENCES,0.8893203883495145,"and C. Lawrence Zitnick. Microsoft COCO: Common Objects in Context. In ECCV, 2014. 1, 7
395"
REFERENCES,0.8912621359223301,"[29] Yen-Cheng Liu, Chih-Yao Ma, Zijian He, Chia-Wen Kuo, Kan Chen, Peizhao Zhang, Bichen Wu, Zsolt
396"
REFERENCES,0.8932038834951457,"Kira, and Peter Vajda. Unbiased Teacher for Semi-Supervised Object Detection. In ICLR, 2021. 3
397"
REFERENCES,0.8951456310679612,"[30] Yen-Cheng Liu, Chih-Yao Ma, and Zsolt Kira. Unbiased Teacher v2: Semi-Supervised Object Detection
398"
REFERENCES,0.8970873786407767,"for Anchor-Free and Anchor-Based Detectors. In CVPR, 2022. 1
399"
REFERENCES,0.8990291262135922,"[31] David Lopez-Paz and Marc’Aurelio Ranzato. Gradient Episodic Memory for Continual Learning. In
400"
REFERENCES,0.9009708737864077,"NeurIPS, 2017. 2
401"
REFERENCES,0.9029126213592233,"[32] Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovit-
402"
REFERENCES,0.9048543689320389,"skiy, Aravindh Mahendran, Anurag Arnab, et al. Simple Open-Vocabulary Object Detection with Vision
403"
REFERENCES,0.9067961165048544,"Transformers. In ECCV, 2022. 1
404"
REFERENCES,0.9087378640776699,"[33] Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual Adversarial Training: A
405"
REFERENCES,0.9106796116504854,"Regularization Method for Supervised and Semi-Supervised Learning. IEEE TPAMI, 41:1979–1993, 2017.
406"
REFERENCES,0.912621359223301,"5, 7
407"
REFERENCES,0.9145631067961165,"[34] Avital Oliver, Augustus Odena, Colin Raffel, Ekin D. Cubuk, and Ian J. Goodfellow. Realistic Evaluation
408"
REFERENCES,0.916504854368932,"of Deep Semi-Supervised Learning Algorithms. In NeurIPS, 2018. 7
409"
REFERENCES,0.9184466019417475,"[35] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, et al. PyTorch: An Imperative
410"
REFERENCES,0.920388349514563,"Style, High-Performance Deep Learning Library. In NeurIPS, pages 8024–8035. Curran Associates, Inc.,
411"
REFERENCES,0.9223300970873787,"2019. 7
412"
REFERENCES,0.9242718446601942,"[36] Limeng Qiao, Yuxuan Zhao, Zhiyuan Li, Xi Qiu, Jianan Wu, and Chi Zhang. DeFRCN: Decoupled Faster
413"
REFERENCES,0.9262135922330097,"R-CNN for Few-Shot Object Detection. In ICCV, 2021. 2, 3, 8
414"
REFERENCES,0.9281553398058252,"[37] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster R-CNN: Towards Real-Time Object
415"
REFERENCES,0.9300970873786408,"Detection with Region Proposal Networks. In NeurIPS, 2015. 4
416"
REFERENCES,0.9320388349514563,"[38] Hamid Rezatofighi, Nathan Tsoi, JunYoung Gwak, Amir Sadeghian, Ian Reid, and Silvio Savarese.
417"
REFERENCES,0.9339805825242719,"Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression. In CVPR, 2019.
418"
REFERENCES,0.9359223300970874,"6, 7
419"
REFERENCES,0.9378640776699029,"[39] Byungseok Roh, Wuhyun Shin, Ildoo Kim, and Sungwoong Kim. Spatially Consistent Representation
420"
REFERENCES,0.9398058252427185,"Learning. In CVPR, 2021. 1
421"
REFERENCES,0.941747572815534,"[40] Mehdi Sajjadi, Mehran Javanmardi, and Tolga Tasdizen. Regularization with Stochastic Perturbations for
422"
REFERENCES,0.9436893203883495,"Deep Semi-Supervised Learning. In NeurIPS, 2016. 3
423"
REFERENCES,0.945631067961165,"[41] Kihyuk Sohn, David Berthelot, Chun-Liang Li, Zizhao Zhang, Nicholas Carlini, Ekin D Cubuk, Alex
424"
REFERENCES,0.9475728155339805,"Kurakin, Han Zhang, and Colin Raffel. Fixmatch: Simplifying Semi-Supervised Learning with Consistency
425"
REFERENCES,0.9495145631067962,"and Confidence. In NeurIPS, 2020. 5
426"
REFERENCES,0.9514563106796117,"[42] Kihyuk Sohn, Zizhao Zhang, Chun-Liang Li, Han Zhang, Chen-Yu Lee, and Tomas Pfister. A Simple
427"
REFERENCES,0.9533980582524272,"Semi-Supervised Learning Framework for Object Detection. https://arxiv.org/abs/2005.04757, 2020. 3, 5
428"
REFERENCES,0.9553398058252427,"[43] Bo Sun, Banghuai Li, Shengcai Cai, Ye Yuan, and Chi Zhang. FSCE: Few-Shot Object Detection via
429"
REFERENCES,0.9572815533980582,"Contrastive Proposal Encoding. In CVPR, 2021. 3, 5, 7
430"
REFERENCES,0.9592233009708738,"[44] Yihe Tang, Weifeng Chen, Yijun Luo, and Yuting Zhang. Humble Teachers Teach Better Students for
431"
REFERENCES,0.9611650485436893,"Semi-Supervised Object Detection. In CVPR, 2021. 3, 7
432"
REFERENCES,0.9631067961165048,"[45] Antti Tarvainen and Harri Valpola. Mean Teachers are Better Role Models: Weight-Averaged Consistency
433"
REFERENCES,0.9650485436893204,"Targets Improve Semi-Supervised Deep Learning Results. In NeurIPS, 2017. 3, 5
434"
REFERENCES,0.9669902912621359,"[46] Thang Vu, Hyunjun Jang, Trung X. Pham, and Chang D. Yoo. Cascade RPN: Delving into High-Quality
435"
REFERENCES,0.9689320388349515,"Region Proposal Network with Adaptive Convolution. In NeurIPS, 2019. 2, 4, 8
436"
REFERENCES,0.970873786407767,"[47] Xin Wang, Thomas E. Huang, Trevor Darrell, Joseph E. Gonzalez, and Fisher Yu. Frustratingly Simple
437"
REFERENCES,0.9728155339805825,"Few-Shot Object Detection. In ICML, 2020. 1, 3, 4, 7, 8
438"
REFERENCES,0.974757281553398,"[48] Xinjiang Wang, Xingyi Yang, Shilong Zhang, Yijiang Li, Litong Feng, Shijie Fang, Chengqi Lyu, Kai Chen,
439"
REFERENCES,0.9766990291262136,"and Wayne Zhang. Consistent-Teacher: Towards Reducing Inconsistent Pseudo-Targets in Semi-Supervised
440"
REFERENCES,0.9786407766990292,"Object Detection. In CVPR, 2023. 1, 3
441"
REFERENCES,0.9805825242718447,"[49] Yu-Xiong Wang, Deva Ramanan, and Martial Hebert. Meta-Learning to Detect Rare Objects. In ICCV,
442"
REFERENCES,0.9825242718446602,"2019. 3
443"
REFERENCES,0.9844660194174757,"[50] Jiaxi Wu, Songtao Liu, Di Huang, and Yunhong Wang. Multi-Scale Positive Sample Refinement for
444"
REFERENCES,0.9864077669902913,"Few-Shot Object Detection. In ECCV, 2020. 8
445"
REFERENCES,0.9883495145631068,"[51] Wuti Xiong, Yawen Cui, and Li Liu. Semi-Supervised Few-Shot Object Detection with a Teacher-Student
446"
REFERENCES,0.9902912621359223,"Network. In BMVC, 2021. 4
447"
REFERENCES,0.9922330097087378,"[52] Mengde Xu, Zheng Zhang, Han Hu, Jianfeng Wang, Lijuan Wang, Fangyun Wei, Xiang Bai, and Zicheng
448"
REFERENCES,0.9941747572815534,"Liu. End-to-End Semi-Supervised Object Detection with Soft Teacher. In ICCV, 2021. 1, 3, 5, 6
449"
REFERENCES,0.996116504854369,"[53] Xiaopeng Yan, Ziliang Chen, Anni Xu, Xiaoxi Wang, Xiaodan Liang, and Liang Lin. Meta R-CNN :
450"
REFERENCES,0.9980582524271845,"Towards General Solver for Instance-Level Few-Shot Learning. In ICCV, 2019. 3
451"
