Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.004081632653061225,"Graph Neural Networks (GNNs) are powerful tools in representation learning for
graphs. However, they are reported to be vulnerable to adversarial attacks, rais-
ing numerous concerns for applying it in some risk-sensitive domains. There-
fore, it is essential to develop a robust GNN model to defend against adversarial
attacks. Existing studies address this issue only considering cleaning perturbed
graph structure, and almost none of them simultaneously consider denoising fea-
tures. As the graph and features are interrelated and inﬂuence each other, we pro-
pose a General Uniﬁed Graph Neural Network (GUGNN) framework to jointly
clean the graph and denoise features of data. On this basis, we further extend
it by introducing two operations and develop a robust GNN model(R-GUGNN)
to defend against adversarial attacks. One operation is reconstructing the graph
with its intrinsic properties, including similarity of two adjacent nodes’ features,
sparsity of real-world graphs and many slight noises having small eigenvalues in
perturbed graphs. The other is the convolution operation for features to ﬁnd the
optimal solution adopting the Laplacian smoothness and the prior knowledge that
nodes with many neighbors are difﬁcult to attack. Experiments on four real-world
datasets demonstrate that R-GUGNN has greatly improved the overall robustness
over the state-of-the-art baselines."
INTRODUCTION,0.00816326530612245,"1
INTRODUCTION"
INTRODUCTION,0.012244897959183673,"Graph Neural Networks(GNNs) have drawn great attention as graphs can represent complex re-
lationships among nodes. Graphs are ubiquitous in different domains, which are usually applied
in recommender systems(Ying et al., 2018a), chemistry(Duvenaud et al., 2015), social media(Qiu
et al., 2018) and so on. Utilizing the strong representation capacity of graphs, we can enhance
performance of down-stream tasks such as node classiﬁcation(Kipf & Welling, 2017; Velickovic
et al., 2018; Klicpera et al., 2019), link prediction(Grover & Leskovec, 2016; Bojchevski et al.,
2018) and graph classiﬁcation(Defferrard et al., 2016; Ying et al., 2018b). A GNN model often
consists of several graph convolution layers. A common practice of convolution layers is utilizing
a feed-forward network to transform features and then aggregating transformed features. A series
of convolution layers have been proposed and achieved great success such as GCN(Kipf & Welling,
2017), GAT(Velickovic et al., 2018) and PPNP(Klicpera et al., 2019)."
INTRODUCTION,0.0163265306122449,"However, GNN models composed of these convolution layers are vulnerable to adversarial attacks.
Attacks can be conducted on either node features or the graph structure, while most existing adver-
sarial attacks on graph data focus on modifying the graph structure(Xu et al., 2020). They always
try to add, delete, or rewire edges to change the graph structure. Although these perturbations are
unnoticeable, they can easily degrade the performance of GNN models, which may cause bad con-
sequences. For example, spammers may create virtual followers to increase the chance of false
messages being recommended and spread. The lack of GNNs’ robustness raises increasing con-
cerns for applying it in some risk-sensitive domains. Therefore, it is necessary to develop graph
defense techniques. Many existing defense methods focus on cleaning perturbed graphs by detect-
ing properties of clean graphs and effects of speciﬁc attacks on graphs(Entezari et al., 2020; Jin
et al., 2020b). Prior knowledge according to these researches can help GNN models defend against
adversarial attacks to a certain extent. The study(Jin et al., 2020b) has proved that adversarial at-
tacks could lead perturbed graphs to violate some properties of real graphs. For example, the rank of
attacked graph increases and adversarial attacks often connect nodes with large feature differences."
INTRODUCTION,0.02040816326530612,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.024489795918367346,Output
INTRODUCTION,0.02857142857142857,"Poisoned graph
Clean graph"
INTRODUCTION,0.0326530612244898,Step ①
INTRODUCTION,0.036734693877551024,Step ②
INTRODUCTION,0.04081632653061224,"Feature matrix
Convolution layer 
Convolution layer"
INTRODUCTION,0.044897959183673466,"ReLU
log_softmax"
INTRODUCTION,0.04897959183673469,Dropout …
INTRODUCTION,0.053061224489795916,"graph reconstruction operations 1
2
m"
INTRODUCTION,0.05714285714285714,Figure 1: Concrete design of R-GUGNN. We clean the attacked graph and denoise features.
INTRODUCTION,0.061224489795918366,"However, existing studies only focus on cleaning the perturbed graph structure, and almost none of
them simultaneously consider denoising features."
INTRODUCTION,0.0653061224489796,"As the graph and features are closely tied and contain perturbations and noises, in this paper, we pro-
pose a General Uniﬁed Graph Neural Network(GUGNN) framework to jointly clean the graph and
denoise features. Based on the GUGNN framework, we further introduce two kinds of operations.
One operation is reconstructing the graph with its properties that real-world graphs are sparse(Zhou
et al., 2013), the features of two adjacent nodes tend to be similar(McPherson et al., 2001) and per-
turbed graphs have many slight noises with small eigenvalues. Nodes with more neighbors are hard
to attack(Z¨ugner et al., 2018). Though we cannot change the number of nodes’ ﬁrst-order neigh-
bors, we can adjust the size of nodes’ neighborhood to add some high-order neighbors to nodes.
According to this principle, from the denoising perspective, we design the convolution operation
for features to ﬁnd the optimal solution. Utilizing the two kinds of operations above, we develop a
robust model(R-GUGNN), which can be applied for defending against different adversarial attacks."
INTRODUCTION,0.06938775510204082,The contributions of this paper are summarized as follows:
INTRODUCTION,0.07346938775510205,"• We propose GUGNN framework to jointly clean the graph and denoise features for pertur-
bations and noises existing in the graph and features.
• We introduce two kinds of operations to clean attacked graphs and denoise features respec-
tively based on the GUGNN framework.
• For defending against adversarial attacks, we develop a concrete model R-GUGNN to re-
alize the goal of the GUGNN framework utilizing the two kinds of operations.
• Experiments show that R-GUGNN has a strong capacity for defending against different
adversarial attacks and stably outperforms the state-of-the-art defense models."
RELATED WORK,0.07755102040816327,"2
RELATED WORK"
RELATED WORK,0.08163265306122448,"This section has two parts, including graph neural networks, and adversarial attacks and defenses
for GNNs."
GRAPH NEURAL NETWORKS,0.08571428571428572,"2.1
GRAPH NEURAL NETWORKS"
GRAPH NEURAL NETWORKS,0.08979591836734693,"In this subsection, we review some famous graph neural network models, including GCN, GAT,
PPNP, and a uniﬁed GNN framework UGNN. For more knowledge about GNNs, you can refer to
some reviews(Wu et al., 2020; Zhang et al., 2020)."
GRAPH NEURAL NETWORKS,0.09387755102040816,"The convolution of GCN(Kipf & Welling, 2017) is deﬁned in the graph spectral domain. Avoiding
computing the full eigenvectors of the graph Laplacian matrix, based on Chebyshev polynomials,
GCN only uses the ﬁrst-order polynomial to simplify the graph convolution, which has been an
accepted good graph convolution layer for its performance. The convolution of GAT(Velickovic
et al., 2018) is deﬁned in the spatial domain. The difference between GAT and GCN is that GAT
learns different attention scores for neighbors when aggregating features. PPNP(Klicpera et al.,"
GRAPH NEURAL NETWORKS,0.09795918367346938,Under review as a conference paper at ICLR 2022
GRAPH NEURAL NETWORKS,0.10204081632653061,"2019) derives a propagation scheme based on personalized PageRank. It propagates information
from a large and adjustable neighborhood instead of the ﬁrst-order neighborhood directly. The
neighborhood can be adjusted via a hyper-parameter."
GRAPH NEURAL NETWORKS,0.10612244897959183,"UGNN(Ma et al., 2020) is a uniﬁed GNN framework available for different feature propagation
processes from a denoising perspective. It proposes a denoising optimization problem with the
Laplacian regularization term and tries to solve it in different ways utilizing the ﬁrst derivative or the
optimal solution. Original Laplacian matrix can be also replaced with different normalized forms.
Different solutions to the optimization problem are corresponding to various convolution layers with
different feature aggregation processes such as GCN, GAT, PPNP and so on."
ADVERSARIAL ATTACKS AND DEFENSES FOR GNNS,0.11020408163265306,"2.2
ADVERSARIAL ATTACKS AND DEFENSES FOR GNNS"
ADVERSARIAL ATTACKS AND DEFENSES FOR GNNS,0.11428571428571428,"We recommend a repository DeepRobust(Li et al., 2020) for readers. It contains many adversarial
attacks and defenses on the graph, which is quite useful for researchers. For more knowledge about
adversarial attacks and defenses for GNNs, you can refer to the review(Jin et al., 2020a)."
ADVERSARIAL ATTACKS AND DEFENSES FOR GNNS,0.11836734693877551,"Some adversarial attack methods have been proposed to show the vulnerability of GNNs with some
unnoticeable perturbations added to the graph structure or node attributes. In the ﬁeld of node
classiﬁcation, the aim of adversarial attacks is fooling GNNs into classifying nodes incorrectly. Poi-
soning attacks change the graph structure before we train GNN models, which is one of the most
common settings of adversarial attacks on graph data. Poisoning attacks have various types, includ-
ing global attack, targeted attack and random attack. Based on the whole graph, the goal of global
attack is to degrade the overall performance of GNNs. One of the state-of-the-art global attacks is
metattack(Z¨ugner & G¨unnemann, 2019), which generates the poisoning attacks based on meta-
learning. Targeted attack generates attacks on some speciﬁc nodes and aims to fool GNNs on these
target nodes. The nettack(Z¨ugner et al., 2018) is one of the state-of-the-art targeted attacks, which
aims to change the graph structure and features of target nodes or nearby nodes with perturbations
remaining unnoticeable. Random attack adds random noises to the clean graph whose concrete
practice is adding, removing or ﬂipping edges randomly."
ADVERSARIAL ATTACKS AND DEFENSES FOR GNNS,0.12244897959183673,"Methods about preventing GNNs from adversarial attacks are also developed to improve the ro-
bustness of GNNs recently. To mitigate the effects of adversarial attacks on the graph, RGCN(Zhu
et al., 2019) uses Gaussian distributions as hidden representations of nodes instead of plain vectors
in other GNNs. Considering that nettack is a high-rank attack, GCN-SVD(Entezari et al., 2020) is
proposed to reconstruct the perturbed graph with only the top-k largest singular components. Using
such a low-rank approximation, GCN-SVD can reduce the effects of nettack. In fact, the practice
of ensuring low-rank is removing noises with small singular values of the graph. Pro-GNN(Jin et al.,
2020b) jointly optimizes a structural graph and a robust GNN model from the perturbed graph with
some properties of clean graphs. Pro-GNN has big improvement over other defense models with
these properties. However, like other defense models, Pro-GNN doesn’t take denoising features into
account jointly."
THE PROPOSED FRAMEWORK,0.12653061224489795,"3
THE PROPOSED FRAMEWORK"
THE PROPOSED FRAMEWORK,0.1306122448979592,"In this section, we ﬁrst present GUGNN framework, and then we introduce a novel graph recon-
struction operation. At last, we show the convolution operation for features and our concrete design
of R-GUGNN model, which is used to realize the goal of GUGNN framework."
NOTIONS,0.1346938775510204,"3.1
NOTIONS"
NOTIONS,0.13877551020408163,"We denote some notations here. Denote X ∈RN×d as the feature matrix, where N, d represent
the number of samples and the dimension of features respectively. Denote G = {V, E} as the
graph, where V represents node sets and E represents edge sets. We also use the adjacency matrix
A ∈RN×N to represent G."
NOTIONS,0.14285714285714285,Under review as a conference paper at ICLR 2022
NOTIONS,0.1469387755102041,"Algorithm 1: R-GUGNN
Input: Adjacency matrix A, Feature matrix X, Labels y, Hyper-parameters m, c,β, λ, Learning
rate η.
Output: GNN parameters θ"
NOTIONS,0.1510204081632653,1 eA = A + I; Initialize S = eA;
NOTIONS,0.15510204081632653,2 for i= 1 to m do
NOTIONS,0.15918367346938775,"3
Calculating Z in formula(5);"
NOTIONS,0.16326530612244897,"4
S = S −c 2Z;"
NOTIONS,0.1673469387755102,"5
S = prox∗β(S);"
NOTIONS,0.17142857142857143,"6
S = proxs(S);"
NOTIONS,0.17551020408163265,7 Initialize F = X;Randomly initialize θ;
WHILE STOPPING CONDITION IS NOT MET DO,0.17959183673469387,8 while Stopping condition is not met do
WHILE STOPPING CONDITION IS NOT MET DO,0.1836734693877551,"9
Forward propagation using two convolution layers:"
WHILE STOPPING CONDITION IS NOT MET DO,0.18775510204081633,"10
Using feature transformation formula: F = FW,"
WHILE STOPPING CONDITION IS NOT MET DO,0.19183673469387755,"11
and feature aggregation formula: F = (I + λˆL)−1F;"
WHILE STOPPING CONDITION IS NOT MET DO,0.19591836734693877,"12
Getting output y′;"
WHILE STOPPING CONDITION IS NOT MET DO,0.2,"13
Calculating gradient g according to y and y′;"
WHILE STOPPING CONDITION IS NOT MET DO,0.20408163265306123,"14
Backward propagation: θ = θ −ηg;"
WHILE STOPPING CONDITION IS NOT MET DO,0.20816326530612245,15 return θ;
THE GENERAL UNIFIED GNN FRAMEWORK,0.21224489795918366,"3.2
THE GENERAL UNIFIED GNN FRAMEWORK"
THE GENERAL UNIFIED GNN FRAMEWORK,0.2163265306122449,"To discard perturbations and noises in the graph and features, considering the tight connection be-
tween them, we propose our general united graph neural network(GUGNN) framework to solve
such problem, which is shown as follows:"
THE GENERAL UNIFIED GNN FRAMEWORK,0.22040816326530613,"argmin
S,F
L = ∥S −A∥2
F + γ∥F −X∥2
F + c · tr(FT LF) + β · f(S)
(1)"
THE GENERAL UNIFIED GNN FRAMEWORK,0.22448979591836735,"where S and F are the learned adjacency and feature matrix.
L is the Laplacian matrix of S.
L = D −S, where D is a diagonal matrix and Dii = PN
j=1 Sij. L can be also replaced with
different normalized forms. tr(FT LF) is Laplacian regularization term for both denoising features
and cleaning the graph. f(S) is a ﬂexible regularization term to enforce some prior over S. γ, c and
β are hyper-parameters to balance different components."
THE GENERAL UNIFIED GNN FRAMEWORK,0.22857142857142856,"From a united perspective, we view that both features and the graph contain noises and our goal is
jointly optimizing F and S. tr(FT LF) can be rewritten as 1"
PN,0.23265306122448978,"2
PN
i,j=1 Sij(fi −fj)2, where fi is the
i-th row of F. This term represents that features of two adjacent nodes should be similar, which is
the guidance for both learning F and S. Although X and A have some noises, they can represent the
real features and the graph to a large extent. So, the learned F and S should be similar to X and A
respectively, which are the meanings of ∥F −X∥2
F and ∥S −A∥2
F . In addition, we add some prior
to the graph in f(S) to make it more accurate."
THE NOVEL GRAPH RECONSTRUCTION OPERATION,0.23673469387755103,"3.3
THE NOVEL GRAPH RECONSTRUCTION OPERATION"
THE NOVEL GRAPH RECONSTRUCTION OPERATION,0.24081632653061225,"We focus on cleaning the perturbed graph supposing F=X. Formula(1) of GUGNN can be rewritten
as follows:
argmin
S
L = ∥S −A∥2
F + c · tr(XT LX) + β · f(S)
(2)"
THE NOVEL GRAPH RECONSTRUCTION OPERATION,0.24489795918367346,"Considering that the graph contains noises, we rewrite formula(2) as follows:"
THE NOVEL GRAPH RECONSTRUCTION OPERATION,0.24897959183673468,"argmin
S
L = ∥S −eA∥2
F + c · tr(XT ˆLX) + β∥S∥∗"
THE NOVEL GRAPH RECONSTRUCTION OPERATION,0.2530612244897959,"= L1 + L2 + L3
(3)"
THE NOVEL GRAPH RECONSTRUCTION OPERATION,0.2571428571428571,"The adjacency matrix with self-loop eA and the normalized Laplacian matrix ˆL are adopted. ˆL =
D−1"
THE NOVEL GRAPH RECONSTRUCTION OPERATION,0.2612244897959184,2 LD−1
THE NOVEL GRAPH RECONSTRUCTION OPERATION,0.2653061224489796,2 . tr(XT ˆLX) is equal to 1
PN,0.2693877551020408,"2
PN
i,j=1 Sij(
xi
√"
PN,0.27346938775510204,"Dii −
xj
√"
PN,0.27755102040816326,Djj )2. Since degrees of the perturbed
PN,0.2816326530612245,Under review as a conference paper at ICLR 2022
PN,0.2857142857142857,Table 1: Description of datasets
PN,0.2897959183673469,"NLCC
ELCC
Classes
Features
Cora
2485
5069
7
1433
Citeseer
2110
3668
6
3703
Cora-ML
2810
7981
7
2879
Polblogs
1222
16714
2
/"
PN,0.2938775510204082,"graph are approximately equal to those of the real graph, for the convenience of calculation, we let
Dii = PN
j=1 eAij. ∥S∥∗= Prank(S)
i
σi, where σi is the i-th singular value of S."
PN,0.2979591836734694,"To solve formula(3), we let ∂L1+L2"
PN,0.3020408163265306,"∂S
= 0 to get the closed form solution."
PN,0.30612244897959184,∂L1 + L2
PN,0.31020408163265306,"∂S
= 2(S −eA) + c  
"
PN,0.3142857142857143,"(
x1
√D11 −
x1
√D11 )2
· · ·
(
x1
√D11 −
xN
√DNN )2"
PN,0.3183673469387755,"...
...
...
(
xN
√DNN −
x1
√D11 )2
· · ·
(
xN
√DNN −
xN
√DNN )2 "
PN,0.3224489795918367,"
= 0
(4)"
PN,0.32653061224489793,"S = eA −c 2  
"
PN,0.3306122448979592,"(
x1
√D11 −
x1
√D11 )2
· · ·
(
x1
√D11 −
xN
√DNN )2"
PN,0.3346938775510204,"...
...
...
(
xN
√DNN −
x1
√D11 )2
· · ·
(
xN
√DNN −
xN
√DNN )2 "
PN,0.33877551020408164,"

(5)"
PN,0.34285714285714286,We denote formula(5) as S = eA −c
PN,0.3469387755102041,"2Z for convenience. A proximal operator of nuclear norm is
adopted to remove noises and reserve main properties(Entezari et al., 2020)."
PN,0.3510204081632653,"prox∗β(S) = Udiag(max{σi −β, 0})iVT
(6)"
PN,0.3551020408163265,"where S = Udiag(σ1 . . . σN)VT is the singular value decomposition of S. Let S = prox∗β(S) to
represent this step. For the constraint Sij ∈[0, 1], we let S = S + I to enhance self-loop, and set
Sij<0 to 0 and Sij>1 to 1. We denote this step as S = proxs(S), which can make the graph sparse
at the same time."
THE CONVOLUTION OPERATION FOR FEATURES,0.35918367346938773,"3.4
THE CONVOLUTION OPERATION FOR FEATURES"
THE CONVOLUTION OPERATION FOR FEATURES,0.363265306122449,"After getting the cleaned graph through several graph reconstruction operations above, we ﬁx it and
focus on denoising features, formula(1) of GUGNN can be rewritten as follows:"
THE CONVOLUTION OPERATION FOR FEATURES,0.3673469387755102,"argmin
F
L = ∥F −X∥2
F + λ · tr(FT LF)
(7)"
THE CONVOLUTION OPERATION FOR FEATURES,0.37142857142857144,"where λ =
c
γ . In this case, formula(7) is equal to that of UGNN(Ma et al., 2020). We use the"
THE CONVOLUTION OPERATION FOR FEATURES,0.37551020408163266,normalized Laplacian matrix ˆL and let ∂L
THE CONVOLUTION OPERATION FOR FEATURES,0.3795918367346939,∂F = 0 to ﬁnd the optimal solution.
THE CONVOLUTION OPERATION FOR FEATURES,0.3836734693877551,"∂L
∂F = 2(F −X) + 2λˆLF = 0
(8)"
THE CONVOLUTION OPERATION FOR FEATURES,0.3877551020408163,"F = (I + λˆL)−1X
(9)
Formula(9) is the process of feature aggregation. Before it, we let X = XW to transform features,
where W is the parameter of a single GNN convolution layer. This is our convolution operation for
features, which is proved(Ma et al., 2020) equal to PPNP(Klicpera et al., 2019). So, our convolution
operation for features can also adjust nodes’ neighborhood to enhance the model’s robustness."
THE DESIGN OF R-GUGNN MODEL,0.39183673469387753,"3.5
THE DESIGN OF R-GUGNN MODEL"
THE DESIGN OF R-GUGNN MODEL,0.39591836734693875,"Utilizing the two kinds of operations, we design R-GUGNN model and show it in Figure 1, where
m is the number of graph reconstruction operations we can set. In step , we ﬁx features and
clean the graph with m graph reconstruction operations. In step , we ﬁx the cleaned graph and
denoise features with two graph convolution layers. We train GNN parameters θ using the two graph
convolution layers and classify nodes ﬁnally. Concrete steps of R-GUGNN are shown in Algorithm
1."
THE DESIGN OF R-GUGNN MODEL,0.4,Under review as a conference paper at ICLR 2022
THE DESIGN OF R-GUGNN MODEL,0.40408163265306124,Table 2: Node classiﬁcation performance (Accuracy±Std) under metattack
THE DESIGN OF R-GUGNN MODEL,0.40816326530612246,"Datasets
Ptb Rate(%)
GCN
GAT
RGCN
GCN-SVD
Pro-GNN
R-GUGNN Cora"
THE DESIGN OF R-GUGNN MODEL,0.4122448979591837,"0
83.06±0.52
84.09±0.66
83.83±0.59
77.69±0.52
85.49±0.38
82.97±0.33
5
77.08±1.05
79.96±1.01
79.21±0.42
77.54±0.91
79.03±1.31
82.25±0.51
10
70.46±1.14
74.82±1.33
73.11±0.76
72.73±0.90
74.11±0.77
80.91±0.30
15
65.21±1.64
70.17±1.34
68.68±0.80
69.11±0.67
70.34±0.50
80.60±0.37
20
54.69±1.37
58.33±1.49
58.35±0.39
57.46±2.04
67.78±0.48
77.96±1.15
25
49.53±1.47
52.22±2.76
53.27±0.56
54.46±1.60
66.19±0.85
76.05±1.37"
THE DESIGN OF R-GUGNN MODEL,0.4163265306122449,Citeseer
THE DESIGN OF R-GUGNN MODEL,0.4204081632653061,"0
72.22±0.49
72.87±1.38
72.98±0.29
67.89±0.68
72.68±0.78
73.59±0.33
5
69.76±1.91
71.87±1.60
71.66±0.43
68.44±0.44
72.17±1.67
73.15±0.71
10
67.25±1.30
70.02±1.18
69.17±0.57
69.73±0.88
73.06±0.50
73.96±0.42
15
63.87±1.47
67.30±2.03
65.93±0.37
68.06±0.45
71.24±0.54
73.25±0.80
20
56.00±1.36
60.08±1.09
56.83±0.54
68.71±0.65
69.22±0.65
71.64±0.59
25
57.10±2.45
61.00±1.99
58.69±0.47
65.43±1.01
57.23±1.22
71.74±0.99"
THE DESIGN OF R-GUGNN MODEL,0.42448979591836733,Cora-ML
THE DESIGN OF R-GUGNN MODEL,0.42857142857142855,"0
85.77±0.32
85.46±0.51
85.97±0.42
78.78±0.17
85.30±0.66
85.29±0.24
5
80.01±0.42
81.20±0.81
80.68±0.39
77.92±0.22
83.92±0.45
84.70±0.35
10
74.51±0.56
75.97±0.90
74.70±0.76
77.61±0.39
81.69±0.42
84.12±0.16
15
54.36±0.66
57.80±1.24
55.86±1.06
74.92±0.33
53.88±0.45
82.13±0.46
20
45.64±0.71
42.02±2.36
48.08±0.29
51.01±0.94
46.99±2.82
70.74±0.90
25
48.20±1.45
46.68±2.51
50.58±0.42
66.57±0.51
50.82±0.45
74.30±0.47"
THE DESIGN OF R-GUGNN MODEL,0.4326530612244898,Polblogs
THE DESIGN OF R-GUGNN MODEL,0.43673469387755104,"0
95.83±0.40
94.99±0.41
95.30±0.25
91.93±0.37
95.25±0.14
95.68±0.31
5
72.81±0.91
76.69±0.96
72.04±0.54
89.10±0.35
93.53±0.47
95.30±0.57
10
72.71±0.80
72.56±1.33
71.89±0.51
81.25±0.50
87.53±0.83
94.37±0.85
15
68.35±0.42
54.73±8.66
68.66±0.66
70.27±2.42
85.88±1.79
91.44±5.74
20
59.34±2.45
50.07±4.35
62.14±0.80
58.73±3.64
77.05±3.35
84.13±5.08
25
58.39±1.61
50.91±2.45
59.89±0.96
53.03±2.32
70.34±2.05
70.72±7.27"
EXPERIMENTS,0.44081632653061226,"4
EXPERIMENTS"
EXPERIMENTS,0.4448979591836735,"In this section, we evaluate the effectiveness of R-GUGNN model compared with the state-of-the-
art GNN models against different attacks. We ﬁrst introduce the experimental settings and then
present results of a series of experiments. At last, we conduct the ablation study and analyze hyper-
parameters of R-GUGNN."
EXPERIMENTAL SETTINGS,0.4489795918367347,"4.1
EXPERIMENTAL SETTINGS"
DATASETS,0.4530612244897959,"4.1.1
DATASETS"
DATASETS,0.45714285714285713,"We compare different models on four benchmark datasets, including three citation graphs, i.e.,
Cora(McCallum et al., 2000), Citeseer(Giles et al., 1998) and Cora-ML(Bojchevski & G¨unnemann,
2017), and one blog graph, i.e., Polblogs(Jin et al., 2020b). Cora-ML is the subset of machine learn-
ing papers from Cora dataset, which is also a well-known dataset in GNN ﬁeld. Since Polblogs
dataset has no node features, a N × N identity matrix is used to act as the feature matrix. We
only consider the largest connected component(LCC) in each dataset(Jin et al., 2020b; Z¨ugner et al.,
2018). Table 1 contains detailed information about the dataset."
BASELINES,0.46122448979591835,"4.1.2
BASELINES"
BASELINES,0.46530612244897956,"R-GUGNN model are compared with the state-of-the-art GNN and defense models in repository
DeepRobust(Li et al., 2020), i.e., GCN(Kipf & Welling, 2017), GAT(Velickovic et al., 2018),
RGCN(Zhu et al., 2019), GCN-SVD(Entezari et al., 2020) and Pro-GNN(Jin et al., 2020b). We
adopt the default parameter settings in GCN and GAT. The number of hidden units of RGCN are
tuned from {16, 32, 64, 128}. The reduced rank of the perturbed graph in GCN-SVD is tuned from
{5, 10, 15, 50, 100, 200}. For Pro-GNN, we use the tuned hyper-parameters the author gives online."
BASELINES,0.46938775510204084,Under review as a conference paper at ICLR 2022 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85
BASELINES,0.47346938775510206,"0
1
2
3
4
5"
BASELINES,0.4775510204081633,Test Accuracy
BASELINES,0.4816326530612245,Number of Perturbations Per Node
BASELINES,0.4857142857142857,R-GUGNN GCN GAT
BASELINES,0.4897959183673469,"RGCN
GCN-SVD"
BASELINES,0.49387755102040815,Pro-GNN
BASELINES,0.49795918367346936,(a) Cora 0.43 0.48 0.53 0.58 0.63 0.68 0.73 0.78 0.83
BASELINES,0.5020408163265306,"0
1
2
3
4
5"
BASELINES,0.5061224489795918,Test Accuracy
BASELINES,0.5102040816326531,Number of Perturbations Per Node
BASELINES,0.5142857142857142,R-GUGNN GCN GAT RGCN
BASELINES,0.5183673469387755,GCN-SVD
BASELINES,0.5224489795918368,Pro-GNN
BASELINES,0.5265306122448979,(b) Citeseer 0.69 0.71 0.73 0.75 0.77 0.79 0.81 0.83 0.85 0.87 0.89
BASELINES,0.5306122448979592,"0
1
2
3
4
5"
BASELINES,0.5346938775510204,Test Accuracy
BASELINES,0.5387755102040817,Number of Perturbations Per Node
BASELINES,0.5428571428571428,"R-GUGNN
GCN
GAT
RGCN
GCN-SVD
Pro-GNN"
BASELINES,0.5469387755102041,(c) Cora-ML 0.9 0.91 0.92 0.93 0.94 0.95 0.96 0.97 0.98
BASELINES,0.5510204081632653,"0
1
2
3
4
5"
BASELINES,0.5551020408163265,Test Accuracy
BASELINES,0.5591836734693878,Number of Perturbations Per Node
BASELINES,0.563265306122449,R-GUGNN GCN GAT RGCN
BASELINES,0.5673469387755102,GCN-SVD
BASELINES,0.5714285714285714,Pro-GNN
BASELINES,0.5755102040816327,(d) Polblogs
BASELINES,0.5795918367346938,Figure 2: Node classiﬁcation performance (Accuracy) under nettack 0.64 0.69 0.74 0.79 0.84
BASELINES,0.5836734693877551,"0
0.2
0.4
0.6
0.8
1"
BASELINES,0.5877551020408164,Test Accuracy
BASELINES,0.5918367346938775,Perturbation Rate
BASELINES,0.5959183673469388,"R-GUGNN
GCN
GAT
RGCN
GCN-SVD
Pro-GNN"
BASELINES,0.6,(a) Cora 0.58 0.6 0.62 0.64 0.66 0.68 0.7 0.72 0.74
BASELINES,0.6040816326530613,"0
0.2
0.4
0.6
0.8
1"
BASELINES,0.6081632653061224,Test Accuracy
BASELINES,0.6122448979591837,Perturbation Rate
BASELINES,0.6163265306122448,"R-GUGNN
GCN
GAT
RGCN
GCN-SVD
Pro-GNN"
BASELINES,0.6204081632653061,(b) Citeseer 0.67 0.69 0.71 0.73 0.75 0.77 0.79 0.81 0.83 0.85 0.87
BASELINES,0.6244897959183674,"0
0.2
0.4
0.6
0.8
1"
BASELINES,0.6285714285714286,Test Accuracy
BASELINES,0.6326530612244898,Perturbation Rate
BASELINES,0.636734693877551,R-GUGNN GCN GAT RGCN
BASELINES,0.6408163265306123,GCN-SVD
BASELINES,0.6448979591836734,Pro-GNN
BASELINES,0.6489795918367347,(c) Cora-ML 0.85 0.87 0.89 0.91 0.93 0.95
BASELINES,0.6530612244897959,"0
0.2
0.4
0.6
0.8
1"
BASELINES,0.6571428571428571,Test Accuracy
BASELINES,0.6612244897959184,Perturbation Rate
BASELINES,0.6653061224489796,R-GUGNN GCN GAT RGCN
BASELINES,0.6693877551020408,GCN-SVD
BASELINES,0.673469387755102,Pro-GNN
BASELINES,0.6775510204081633,(d) Polblogs
BASELINES,0.6816326530612244,Figure 3: Node classiﬁcation performance (Accuracy) under random attack
PARAMETER SETTINGS,0.6857142857142857,"4.1.3
PARAMETER SETTINGS"
PARAMETER SETTINGS,0.689795918367347,"Just as(Jin et al., 2020b), for each dataset, we choose 10% of nodes for training, 10% of nodes
for validation and the remaining 80% of nodes for testing. The average performance of 10 runs is
reported for all experiments below. The hyper-parameters of all the models are tuned based on the
loss and accuracy on the validation set. Note that the same hyper-parameters are used under the same
attack for the same dataset no matter what perturbation rate is. If there are no special instructions, all
models adopt two graph convolution layers with 16 hidden units. Learning rate of Adam optimizer
η is ﬁxed as 0.01 and negative log likelihood loss is adopted for a fair comparison(RGCN has its
own loss function)."
PERFORMANCE AGAINST DIFFERENT ATTACKS,0.6938775510204082,"4.2
PERFORMANCE AGAINST DIFFERENT ATTACKS"
PERFORMANCE AGAINST DIFFERENT ATTACKS,0.6979591836734694,"The node classiﬁcation performance of R-GUGNN is evaluated against three types of poisoning
attacks, i.e., global attack, targeted attack and random attack. Since Ploblogs dataset has no real
node features, hyper-parameter c of R-GUGNN is set to 0 on Ploblogs dataset."
AGAINST GLOBAL ATTACK,0.7020408163265306,"4.2.1
AGAINST GLOBAL ATTACK"
AGAINST GLOBAL ATTACK,0.7061224489795919,"The famous metattack(Z¨ugner & G¨unnemann, 2019) is used as the global attack to conduct exper-
iments and all the default parameter settings in the authors’ original implementation are adopted.
Concretely, the strongest variant Meta-Self is applied for all datasets. The perturbation rate of
metattack on the graph is from 0% to 25% with a step of 5%, since too heavy attacks are no-
ticeable and make no sense. We report the average accuracy of node classiﬁcation with standard
deviation on test set and highlight the optimal results in bold. Concrete results are shown in Table 2
and we draw some conclusions:"
AGAINST GLOBAL ATTACK,0.710204081632653,"• R-GUGNN has great improvement compared to others on four datasets. The average im-
provement of accuracy under different perturbation rates over GCN on four datasets is
about 16%, 10%, 19% and 21% respectively. When the graph is heavily perturbed, the
improvement is larger. For example, when the perturbation rate is 20%, the improvement
over GCN is about 23%, 16%, 25% and 25% on four datasets respectively. When compared
with different second best models, improvement can reach 10%, 6%, 19% and 7% on four
datasets. These results prove that R-GUGNN can defend against metattack very well."
AGAINST GLOBAL ATTACK,0.7142857142857143,Under review as a conference paper at ICLR 2022 0.7 0.72 0.74 0.76 0.78 0.8 0.82 0.84
AGAINST GLOBAL ATTACK,0.7183673469387755,"0
0.2
0.4
0.6
0.8
1"
AGAINST GLOBAL ATTACK,0.7224489795918367,Test Accuracy
AGAINST GLOBAL ATTACK,0.726530612244898,Perturbation Rate
AGAINST GLOBAL ATTACK,0.7306122448979592,"R-GUGNN
PPNP
no-β
no-c
GCN"
AGAINST GLOBAL ATTACK,0.7346938775510204,(a) Accuracy 0 0.005 0.01 0.015 0.02 0.025
AGAINST GLOBAL ATTACK,0.7387755102040816,"0
0.2
0.4
0.6
0.8
1"
AGAINST GLOBAL ATTACK,0.7428571428571429,Standrad Deviation
AGAINST GLOBAL ATTACK,0.746938775510204,Perturbation Rate
AGAINST GLOBAL ATTACK,0.7510204081632653,R-GUGNN no-c
AGAINST GLOBAL ATTACK,0.7551020408163265,(b) Standard Deviation
AGAINST GLOBAL ATTACK,0.7591836734693878,Figure 4: Performance of variants of R-GUGNN 0.76 0.77 0.78 0.79 0.8 0.81 0.82 0.83
AGAINST GLOBAL ATTACK,0.763265306122449,"1
2
3
4
5"
AGAINST GLOBAL ATTACK,0.7673469387755102,Test Accuracy
AGAINST GLOBAL ATTACK,0.7714285714285715,Hyper-parameter:m m (a) m 0.76 0.77 0.78 0.79 0.8 0.81 0.82 0.83
AGAINST GLOBAL ATTACK,0.7755102040816326,"0.00001
0.0001
0.001
0.01
0.1"
AGAINST GLOBAL ATTACK,0.7795918367346939,Test Accuracy
AGAINST GLOBAL ATTACK,0.7836734693877551,Hyper-parameter:c c (b) c 0.76 0.77 0.78 0.79 0.8 0.81 0.82 0.83
AGAINST GLOBAL ATTACK,0.7877551020408163,"1
1.5
2
2.5
3
3.5"
AGAINST GLOBAL ATTACK,0.7918367346938775,Test Accuracy
AGAINST GLOBAL ATTACK,0.7959183673469388,Hyper-parameter:β β (c) β 0.76 0.77 0.78 0.79 0.8 0.81 0.82 0.83
AGAINST GLOBAL ATTACK,0.8,"0.5
1
1.5
2
2.5
3"
AGAINST GLOBAL ATTACK,0.8040816326530612,Test Accuracy
AGAINST GLOBAL ATTACK,0.8081632653061225,Hyper-parameter:λ λ (d) λ
AGAINST GLOBAL ATTACK,0.8122448979591836,Figure 5: Parameter analysis on Cora-ML dataset under 15% metattack
AGAINST GLOBAL ATTACK,0.8163265306122449,"• Accuracy of R-GUGNN is stably high under different perturbation rates on all datasets.
The gap between accuracy of R-GUGNN on clean and perturbed graphs is small. For
example, gaps of the accuracy of R-GUGNN under 25% and 0% metattack on Cora and
Citeseer datasets are only about 7% and 2%. Besides, the overall standard deviations of
R-GUGNN are small. However, the lack of real node features on Polblogs dataset causes
big standard deviations when the graph is heavily attacked."
AGAINST TARGETED ATTACK,0.8204081632653061,"4.2.2
AGAINST TARGETED ATTACK"
AGAINST TARGETED ATTACK,0.8244897959183674,"The typical netttack(Z¨ugner et al., 2018) is employed as the targeted attack to conduct experiments
and all the default parameter settings in the authors’ original implementation are adopted. We select
nodes with degree >10 as targeted nodes from the test set. The number of perturbations of the
graph on each targeted node is from 0 to 5 with a step of 1. We report accuracy of these targeted
nodes as results, which are shown in Figure 2. R-GUGNN suffers less effects of nettack and
also performs greatly and stably. For example, compared to the second best method Pro-GNN,
R-GUGNN achieves 10% and 5% improvement on Citeseer and Cora-ML datasets. These results
prove that R-GUGNN can defend against netttack very well."
AGAINST RANDOM ATTACK,0.8285714285714286,"4.2.3
AGAINST RANDOM ATTACK"
AGAINST RANDOM ATTACK,0.8326530612244898,"Performance of R-GUGNN under random attack is evaluated here. We add random perturbations on
the graph from 0% to 100% with a step of 20%. Concrete results are shown in Figure 3. R-GUGNN
outperforms other models again and the improvement is distinct. For example, compared to different
second best models, R-GUGNN achieves a 2.5% and 3.5% improvement on Citeseer and Cora-ML
datasets. These results prove that R-GUGNN can defend against random attack very well."
AGAINST RANDOM ATTACK,0.8367346938775511,"From the overall performance, we observe that the advantage of R-GUGNN is obvious compared
with others and its performance is stably great. In conclusion, R-GUGNN is robust enough to defend
against different attacks."
ABLATION STUDY,0.8408163265306122,"4.3
ABLATION STUDY"
ABLATION STUDY,0.8448979591836735,"R-GUGNN contains m graph reconstruction operations. If we discard these operations and only use
two convolution layers for features, R-GUGNN is equal to PPNP(Klicpera et al., 2019). So, in this"
ABLATION STUDY,0.8489795918367347,Under review as a conference paper at ICLR 2022
ABLATION STUDY,0.8530612244897959,"subsection, we compare PPNP with GCN and R-GUGNN on Cora dataset under random attack as
an example to illustrate. In addition, we set β and c to 0 to understand the impact of each component
in the graph reconstruction operation. Furthermore, we observe standard deviations of R-GUGNN
when c=0."
ABLATION STUDY,0.8571428571428571,"In Figure(4)(a), we can see that performance of R-GUGNN is better than PPNP and performance of
GCN is the worst. It shows graph reconstruction operations are signiﬁcant(R-GUGNN vs PPNP),
and adjusting neighborhood is beneﬁcial to defending against attacks(PPNP vs GCN). PPNP curve
and the no-β curve overlap very well, which indicates that removing noises with small singular
values plays a quite important role in cleaning the graph. What’s more, if c=0, not only model’s
performance is poor, but also the standard deviation rises a lot especially when the graph is heavily
attacked in Figure(4)(b). It shows the Laplacian regularization term is signiﬁcant in improving
stability of R-GUGNN, which explains why the standard deviation is big on Polblogs dataset under
heavy attack."
PARAMETER ANALYSIS,0.8612244897959184,"4.4
PARAMETER ANALYSIS"
PARAMETER ANALYSIS,0.8653061224489796,"In this subsection, we show performance of R-GUGNN with different values of hyper-parameters
i.e., m, c, β, and λ. We use Cora-ML dataset under 15% metattack as an example to illus-
trate.
The value range of m is from 1 to 5 with the step of 1.
The value of c is selected in
{10−5, 10−4, 10−3, 10−2, 10−1}. We select β from 1 to 3.5 and λ from 0.5 to 3 with the step of
0.5. In the process of tuning one hyper-parameter, other hyper-parameters are ﬁxed as the optimal.
Figure 5 shows effects of different values of hyper-parameters."
PARAMETER ANALYSIS,0.8693877551020408,"m is the number of graph reconstruction operations. Our novel operations of R-GUGNN are impor-
tant for defending against attacks, and even one such operation improves model’s robustness(76.87%
accuracy). However, proper m can boost the accuracy and too many such operations cannot bene-
ﬁt R-GUGNN. β is also a key affecting the performance of R-GUGNN, which controls how many
noises with small singular values to remove. When β is too small, noises cannot be removed entirely.
While when β is too big, the main properties of the graph can be hurt. λ is used to adjust the size of
nodes’ neighborhood when propagating features and choosing proper λ is also important. c is used
to control the Laplacian smoothness of the graph. We ﬁnd the big value of c hurts the performance
of R-GUGNN, but when c is small, accuracy doesn’t decrease a lot. From a whole performance, all
hyper-parameters have an interval of values where the performance of R-GUGNN is stably great."
CONCLUSION,0.8734693877551021,"5
CONCLUSION"
CONCLUSION,0.8775510204081632,"In this paper, we propose GUGNN, a novel general uniﬁed framework to effectively enhance the
robustness of GNNs against adversarial attacks by jointly cleaning the perturbed graph and denoising
the features of data. Furthermore, we extend this framework by reconstructing the graph and making
convolution operations of features with intrinsic properties, and propose a robust GNN model R-
GUGNN. Experiment results show that R-GUGNN stably outperforms the state-of-the-art baselines
under different adversarial attacks. In the future, we aim to extend this framework to other models
on graphs, even more complicated graph structures for mining the rich value underlying graph data
of various domains."
REFERENCES,0.8816326530612245,REFERENCES
REFERENCES,0.8857142857142857,"Aleksandar Bojchevski and Stephan G¨unnemann. Deep gaussian embedding of graphs: Unsuper-
vised inductive learning via ranking. arXiv preprint arXiv:1707.03815, 2017."
REFERENCES,0.889795918367347,"Aleksandar Bojchevski, Oleksandr Shchur, Daniel Z¨ugner, and Stephan G¨unnemann. Netgan: Gen-
erating graphs via random walks. In ICML, 2018."
REFERENCES,0.8938775510204081,"M. Defferrard, X. Bresson, and P. Vandergheynst. Convolutional neural networks on graphs with
fast localized spectral ﬁltering. In NIPS, 2016."
REFERENCES,0.8979591836734694,"D. Duvenaud, D. Maclaurin, J. Aguilera-Iparraguirre, R. G´omez-Bombarelli, Timothy D. Hirzel,
Al´an Aspuru-Guzik, and Ryan P. Adams. Convolutional networks on graphs for learning molec-
ular ﬁngerprints. ArXiv, abs/1509.09292, 2015."
REFERENCES,0.9020408163265307,Under review as a conference paper at ICLR 2022
REFERENCES,0.9061224489795918,"Negin Entezari, Saba A Al-Sayouri, Amirali Darvishzadeh, and Evangelos E Papalexakis. All you
need is low (rank) defending against adversarial attacks on graphs. In Proceedings of the 13th
International Conference on Web Search and Data Mining, pp. 169–177, 2020."
REFERENCES,0.9102040816326531,"C Lee Giles, Kurt D Bollacker, and Steve Lawrence. Citeseer: An automatic citation indexing
system. In Proceedings of the third ACM conference on Digital libraries, pp. 89–98, 1998."
REFERENCES,0.9142857142857143,"Aditya Grover and J. Leskovec. node2vec: Scalable feature learning for networks. Proceedings
of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,
2016."
REFERENCES,0.9183673469387755,"Wei Jin, Yaxin Li, Han Xu, Yiqi Wang, Shuiwang Ji, Charu Aggarwal, and Jiliang Tang. Adver-
sarial attacks and defenses on graphs: A review, a tool and empirical studies. arXiv preprint
arXiv:2003.00653, 2020a."
REFERENCES,0.9224489795918367,"Wei Jin, Yao Ma, Xiaorui Liu, Xianfeng Tang, Suhang Wang, and Jiliang Tang. Graph structure
learning for robust graph neural networks. Proceedings of the 26th ACM SIGKDD International
Conference on Knowledge Discovery & Data Mining, 2020b."
REFERENCES,0.926530612244898,"Thomas Kipf and M. Welling. Semi-supervised classiﬁcation with graph convolutional networks.
ArXiv, abs/1609.02907, 2017."
REFERENCES,0.9306122448979591,"Johannes Klicpera, Aleksandar Bojchevski, and Stephan G¨unnemann.
Predict then propagate:
Graph neural networks meet personalized pagerank. In ICLR, 2019."
REFERENCES,0.9346938775510204,"Yaxin Li, Wei Jin, Han Xu, and Jiliang Tang. Deeprobust: A pytorch library for adversarial attacks
and defenses. arXiv preprint arXiv:2005.06149, 2020."
REFERENCES,0.9387755102040817,"Yao Ma, Xiaorui Liu, Tong Zhao, Yozen Liu, Jiliang Tang, and Neil Shah. A uniﬁed view on graph
neural networks as graph signal denoising. arXiv preprint arXiv:2010.01777, 2020."
REFERENCES,0.9428571428571428,"Andrew Kachites McCallum, Kamal Nigam, Jason Rennie, and Kristie Seymore. Automating the
construction of internet portals with machine learning.
Information Retrieval, 3(2):127–163,
2000."
REFERENCES,0.9469387755102041,"M. McPherson, L. Smith-Lovin, and J. Cook. Birds of a feather: Homophily in social networks.
Review of Sociology, 27:415–444, 2001."
REFERENCES,0.9510204081632653,"J. Qiu, Jian Tang, Hao Ma, Yuxiao Dong, Kuansan Wang, and Jie Tang. Deepinf: Social inﬂuence
prediction with deep learning. Proceedings of the 24th ACM SIGKDD International Conference
on Knowledge Discovery & Data Mining, 2018."
REFERENCES,0.9551020408163265,"Petar Velickovic, Guillem Cucurull, A. Casanova, Adriana Romero, P. Lio’, and Yoshua Bengio.
Graph attention networks. ArXiv, abs/1710.10903, 2018."
REFERENCES,0.9591836734693877,"Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. A
comprehensive survey on graph neural networks. IEEE transactions on neural networks and
learning systems, 32(1):4–24, 2020."
REFERENCES,0.963265306122449,"Han Xu, Yao Ma, Haochen Liu, Debayan Deb, H. Liu, Jiliang Tang, and Anil K. Jain. Adversarial
attacks and defenses in images, graphs and text: A review. International Journal of Automation
and Computing, 17:151–178, 2020."
REFERENCES,0.9673469387755103,"Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L. Hamilton, and J. Leskovec.
Graph convolutional neural networks for web-scale recommender systems. Proceedings of the
24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, 2018a."
REFERENCES,0.9714285714285714,"Rex Ying, Jiaxuan You, Christopher Morris, Xiang Ren, William L. Hamilton, and J. Leskovec.
Hierarchical graph representation learning with differentiable pooling. ArXiv, abs/1806.08804,
2018b."
REFERENCES,0.9755102040816327,"Ziwei Zhang, Peng Cui, and Wenwu Zhu. Deep learning on graphs: A survey. IEEE Transactions
on Knowledge and Data Engineering, 2020."
REFERENCES,0.9795918367346939,Under review as a conference paper at ICLR 2022
REFERENCES,0.9836734693877551,"Ke Zhou, H. Zha, and Le Song. Learning social infectivity in sparse low-rank networks using multi-
dimensional hawkes processes. In AISTATS, 2013."
REFERENCES,0.9877551020408163,"Dingyuan Zhu, Ziwei Zhang, Peng Cui, and Wenwu Zhu. Robust graph convolutional networks
against adversarial attacks. In Proceedings of the 25th ACM SIGKDD International Conference
on Knowledge Discovery & Data Mining, pp. 1399–1407, 2019."
REFERENCES,0.9918367346938776,"Daniel Z¨ugner and Stephan G¨unnemann. Adversarial attacks on graph neural networks via meta
learning. arXiv preprint arXiv:1902.08412, 2019."
REFERENCES,0.9959183673469387,"Daniel Z¨ugner, Amir Akbarnejad, and Stephan G¨unnemann. Adversarial attacks on neural networks
for graph data. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge
Discovery & Data Mining, pp. 2847–2856, 2018."
