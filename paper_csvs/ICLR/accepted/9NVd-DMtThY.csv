Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.002512562814070352,"Principal component analysis is a simple yet useful dimensionality reduction tech-
nique in modern machine learning pipelines. In consequential domains such as
college admission, healthcare and credit approval, it is imperative to take into
account emerging criteria such as the fairness and the robustness of the learned
projection. In this paper, we propose a distributionally robust optimization prob-
lem for principal component analysis which internalizes a fairness criterion in the
objective function. The learned projection thus balances the trade-off between
the total reconstruction error and the reconstruction error gap between subgroups,
taken in the min-max sense over all distributions in a moment-based ambiguity
set. The resulting optimization problem over the Stiefel manifold can be efﬁ-
ciently solved by a Riemannian subgradient descent algorithm with a sub-linear
convergence rate. Our experimental results on real-world datasets show the merits
of our proposed method over state-of-the-art baselines."
INTRODUCTION,0.005025125628140704,"1
INTRODUCTION"
INTRODUCTION,0.007537688442211055,"Machine learning models are ubiquitous in our daily lives and supporting the decision-making pro-
cess in diverse domains. With their ﬂourishing applications, there also surface numerous concerns
regarding the fairness of the models’ outputs (Mehrabi et al., 2021). Indeed, these models are prone
to biases due to various reasons (Barocas et al., 2018). First, the collected training data is likely
to include some demographic disparities due to the bias in the data acquisition process (e.g., con-
ducting surveys on a speciﬁc region instead of uniformly distributed places), or the imbalance of
observed events at a speciﬁc period of time. Second, because machine learning methods only care
about data statistics and are objective driven, groups that are under-represented in the data can be
neglected in exchange for a better objective value. Finally, even human feedback to the predictive
models can also be biased, e.g., click counts are human feedback to recommendation systems but
they are highly correlated with the menu list suggested previously by a potentially biased system.
Real-world examples of machine learning models that amplify biases and hence potentially cause
unfairness are commonplace, ranging from recidivism prediction giving higher false positive rates
for African-American1 to facial recognition systems having large error rate for women2."
INTRODUCTION,0.010050251256281407,"To tackle the issue, various fairness criteria for supervised learning have been proposed in the lit-
erature, which encourage the (conditional) independence of the model’s predictions on a particular
sensitive attribute (Dwork et al., 2012; Hardt et al., 2016b; Kusner et al., 2017; Chouldechova, 2017;
Verma & Rubin, 2018; Berk et al., 2021). Strategies to mitigate algorithmic bias are also investi-
gated for all stages of the machine learning pipelines (Berk et al., 2021). For the pre-processing
steps, (Kamiran & Calders, 2012) proposed reweighting or resampling techniques to achieve sta-
tistical parity between subgroups; in the training steps, fairness can be encouraged by adding con-
straints (Donini et al., 2018) or regularizing the original objective function (Kamishima et al., 2012;
Zemel et al., 2013); and in the post-processing steps, adjusting classiﬁcation threshold by examining
black-box models over a holdout dataset can be used (Hardt et al., 2016b; Wei et al., 2019)."
INTRODUCTION,0.01256281407035176,"Since biases may already exist in the raw data, it is reasonable to demand machine learning pipelines
to combat biases as early as possible. We focus in this paper on the Principal Component Analy-
sis (PCA), which is a fundamental dimensionality reduction technique in the early stage of the"
INTRODUCTION,0.01507537688442211,"1 https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing
2 https://news.mit.edu/2018/study-ﬁnds-gender-skin-type-bias-artiﬁcial-intelligence-systems-0212 1"
INTRODUCTION,0.017587939698492462,Published as a conference paper at ICLR 2022
INTRODUCTION,0.020100502512562814,"pipelines (Pearson, 1901; Hotelling, 1933). PCA ﬁnds a linear transformation that embeds the origi-
nal data into a lower-dimensional subspace that maximizes the variance of the projected data. Thus,
PCA may amplify biases if the data variability is different between the majority and the minority
subgroups, see an example in Figure 1. A naive approach to promote fairness is to train one inde-
pendent transformation for each subgroup. However, this requires knowing the sensitive attribute of
each sample, which would raise disparity concerns. On the contrary, using a single transformation
for all subgroups is “group-blinded” and faces no discrimination problem (Lipton et al., 2018)."
INTRODUCTION,0.022613065326633167,"Learning a fair PCA has attracted attention from many ﬁelds from machine learning, statistics to
signal processing. Samadi et al. (2018) and Zalcberg & Wiesel (2021) propose to ﬁnd the principal
components that minimize the maximum subgroup reconstruction error; the min-max formulations
can be relaxed and solved as semideﬁnite programs. Olfat & Aswani (2019) propose to learn a
transformation that minimizes the possibility of predicting the sensitive attribute from the projected
data. Apart from being a dimensionality reduction technique, PCA can also be thought of as a
representation learning toolkit. Viewed in this way, we can also consider a more general family of
fair representation learning methods that can be applied before any further analysis steps. There
are a number of works develop towards this idea (Kamiran & Calders, 2012; Zemel et al., 2013;
Calmon et al., 2017; Feldman et al., 2015; Beutel et al., 2017; Madras et al., 2018; Zhang et al.,
2018; Tantipongpipat et al., 2019), which apply a multitude of fairness criteria."
INTRODUCTION,0.02512562814070352,"In addition, we also focus on the robustness criteria for the linear transformation. Recently, it has
been observed that machine learning models are susceptible to small perturbations of the data (Good-
fellow et al., 2014; Madry et al., 2017; Carlini & Wagner, 2017). These observations have fuelled
many defenses using adversarial training (Akhtar & Mian, 2018; Chakraborty et al., 2018) and dis-
tributionally robust optimization (Rahimian & Mehrotra, 2019; Kuhn et al., 2019; Blanchet et al.,
2021)."
INTRODUCTION,0.02763819095477387,"Contributions. This paper blends the ideas from the ﬁeld of fairness in artiﬁcal intelligence and
distributionally robust optimization. Our contributions can be described as follows."
INTRODUCTION,0.03015075376884422,"• We propose the fair principal components which balance between the total reconstruction error
and the absolute gap of reconstruction error between subgroups. Moreover, we also add a layer
of robustness to the principal components by considering a min-max formulation that hedges
against all perturbations of the empirical distribution in a moment-based ambiguity set."
INTRODUCTION,0.032663316582914576,"• We provide the reformulation of the distributionally robust fair PCA problem as a ﬁnite-
dimensional optimization problem over the Stiefel manifold. We provide a Riemannian gradient
descent algorithm and show that it has a sub-linear convergence rate."
INTRODUCTION,0.035175879396984924,"Figure 1 illustrates the qualitative comparison
between (fair) PCA methods and our proposed
method on a 2-dimensional toy example. The
majority group (blue dots) spreads on the hor-
izontal axis, while the minority group (yellow
triangles) spreads on the slanted vertical axis.
The nominal PCA (red) captures the majority
direction to minimize the total error, while the
fair PCA of Samadi et al. (2018) returns the
diagonal direction to minimize the maximum
subgroup error.
Our fair PCA can probe the
full spectrum in between these two extremes by
sweeping through our penalization parameters
appropriately. If we do not penalize the error
gap between subgroups, we recover the PCA
method; if we penalize heavily, we recover the
fair PCA of Samadi et al. (2018). Extensive nu-
merical results on real datasets are provided in
Section 5. Proofs are relegated to the appendix."
INTRODUCTION,0.03768844221105527,"Figure 1: Nominal PCA (red arrow), fair PCA by
Samadi et al. (2018) (green arrow), and our spec-
trum of fair PCA (shorter arrows). Arrows show
directions and are not normalized to unit length."
INTRODUCTION,0.04020100502512563,Published as a conference paper at ICLR 2022
FAIR PRINCIPAL COMPONENT ANALYSIS,0.04271356783919598,"2
FAIR PRINCIPAL COMPONENT ANALYSIS"
PRINCIPAL COMPONENT ANALYSIS,0.04522613065326633,"2.1
PRINCIPAL COMPONENT ANALYSIS"
PRINCIPAL COMPONENT ANALYSIS,0.04773869346733668,"We ﬁrst brieﬂy revisit the classical PCA. Suppose that we are given a collection of N i.i.d. samples
{ˆxi}N
i=1 generated by some underlying distribution P. For simplicity, we assume that both the
empirical and population mean are zero vectors. The goal of PCA is to ﬁnd a k-dimensional linear
subspace of Rd that explains as much variance contained in the data {ˆxi}N
i=1 as possible, where k <
d is a given integer. More precisely, we parametrize k-dimensional linear subspaces by orthonormal
matrices, i.e., matrices whose columns are orthogonal and have unit Euclidean norm. Given any
such matrix V , the associated k-dimensional subspace is the one spanned by the columns of V .
The projection matrix onto the subspace is V V ⊤, and hence the variance of the projected data is
given by tr
 
V V ⊤ΞΞ⊤
, where Ξ = [ˆx1, · · · , ˆxN] ∈Rd×N is the data matrix. By a slight abuse of
terminology, sometimes we refer to V as the projection matrix. The problem of PCA then reads
max
V ∈Rd×k,V ⊤V =Ik
tr
 
V V ⊤ΞΞ⊤
.
(1)"
PRINCIPAL COMPONENT ANALYSIS,0.05025125628140704,"For any vector X ∈Rd and orthonormal matrix V , denote by ℓ(V, X) the reconstruction error, i.e.,"
PRINCIPAL COMPONENT ANALYSIS,0.052763819095477386,"ℓ(V, X) = ∥X −V V ⊤X∥2
2 = X⊤(Id −V V ⊤)X.
The problem of PCA can alternatively be formulated as a stochastic optimization problem
min
V ∈Rd×k,V ⊤V =Ik
EˆP[ℓ(V, X)],
(2)"
PRINCIPAL COMPONENT ANALYSIS,0.05527638190954774,"where ˆP is the empirical distribution associated with the samples {ˆxi}N
i=1 and X ∼ˆP. It is well-
known that PCA admits an analytical solution. In particular, the optimal solution to problem (2) (and
also problem (1)) is given by any orthonormal matrix whose columns are the eigenvectors associated
with the k largest eigenvalues of the sample covariance matrix ΞΞ⊤."
FAIR PRINCIPAL COMPONENT ANALYSIS,0.05778894472361809,"2.2
FAIR PRINCIPAL COMPONENT ANALYSIS"
FAIR PRINCIPAL COMPONENT ANALYSIS,0.06030150753768844,"In the fair PCA setting, we are also given a discrete sensitive attribute A ∈A, where A may represent
features such as race, gender or education. We consider binary attribute A and let A = {0, 1}. A
straightforward idea to deﬁne fairness is to require the (strict) balance of a certain objective between
the two groups. For example, this is the strategy in Hardt et al. (2016a) for developing fair supervised
learning algorithms. A natural objective to balance in the PCA context is the reconstruction error.
Deﬁnition 2.1 (Fair projection). Let Q be an arbitrary distribution of (X, A). A projection matrix
V ∈Rd×k is fair relative to Q if the conditional expected reconstruction error is equal between
subgroups, i.e., EQ[ℓ(V, X)|A = a] = EQ[ℓ(V, X)|A = a′] for any (a, a′) ∈A × A."
FAIR PRINCIPAL COMPONENT ANALYSIS,0.06281407035175879,"Unfortunately, Deﬁnition 2.1 is too stringent: for a general probability distribution Q, it is possible
that there exists no fair projection matrix V .
Proposition 2.2 (Impossibility result). For any distribution Q on X ×A, there exists a fair projection
matrix V ∈Rd×k relative to Q if and only if rank(EQ[XX⊤|A = 0] −EQ[XX⊤|A = 1]) ≤k."
FAIR PRINCIPAL COMPONENT ANALYSIS,0.06532663316582915,"One way to circumvent the impossibility result is to relax the requirement of strict balance to ap-
proximate balance. In other words, an inequality constraint of the following form is imposed:
|EQ[ℓ(V, X)|A = a] −EQ[ℓ(V, X)|A = a′]| ≤ϵ
∀(a, a′) ∈A × A,
where ϵ > 0 is some prescribed fairness threshold. This approach has been adopted in other fair
machine learning settings, see Donini et al. (2018) and Agarwal et al. (2019) for example."
FAIR PRINCIPAL COMPONENT ANALYSIS,0.0678391959798995,"In this paper, instead of imposing the fairness requirement as a constraint, we penalize the unfairness
in the objective function. Speciﬁcally, for any projection matrix V , we deﬁne the unfairness as the
absolute difference between the conditional loss between two subgroups:
U(V, Q) ≜|EQ[ℓ(V, X)|A = 0] −EQ[ℓ(V, X)|A = 1]|.
We thus consider the following fairness-aware PCA problem"
FAIR PRINCIPAL COMPONENT ANALYSIS,0.07035175879396985,"min
V ∈Rd×k, V ⊤V =Ik
EˆP[ℓ(V, X)] + λU(V, ˆP),
(3)"
FAIR PRINCIPAL COMPONENT ANALYSIS,0.0728643216080402,"where λ ≥0 is a penalty parameter to encourage fairness. Note that for fair PCA, the dataset is
{(ˆxi, ˆai)}N
i=1 and hence the empirical distribution ˆP is given by ˆP = 1"
FAIR PRINCIPAL COMPONENT ANALYSIS,0.07537688442211055,"N
PN
i=1 δ(ˆxi,ˆai)."
FAIR PRINCIPAL COMPONENT ANALYSIS,0.07788944723618091,Published as a conference paper at ICLR 2022
DISTRIBUTIONALLY ROBUST FAIR PCA,0.08040201005025126,"3
DISTRIBUTIONALLY ROBUST FAIR PCA"
DISTRIBUTIONALLY ROBUST FAIR PCA,0.0829145728643216,"The weakness of empirical distribution-based stochastic optimization has been well-documented,
see (Smith & Winkler, 2006; Homem-de Mello & Bayraksan, 2014). In particular, due to overﬁt-
ting, the out-of-sample performance of the decision, prediction, or estimation obtained from such a
stochastic optimization model is unsatisfactory, especially in the low sample size regime. Ideally,
we could improve the performance by using the underlying distribution P instead of the empirical
distribution ˆP. But the underlying distribution P is unavailable in most practical situations, if not all.
Distributional robustiﬁcation is an emerging approach to handle this issue and has been shown to
deliver promising out-of-sample performance in many applications (Delage & Ye, 2010; Namkoong
& Duchi, 2017; Kuhn et al., 2019; Rahimian & Mehrotra, 2019). Motivated by the success of distri-
butional robustiﬁcation, especially in machine learning Nguyen et al. (2019); Taskesen et al. (2021),
we propose a robustiﬁed version of model (3), called the distributionally robust fairness-aware PCA:"
DISTRIBUTIONALLY ROBUST FAIR PCA,0.08542713567839195,"min
V ∈Rd×k,V ⊤V =Ik
sup
Q∈B(ˆP)
EQ[ℓ(V, X)] + λU(V, Q),
(4)"
DISTRIBUTIONALLY ROBUST FAIR PCA,0.08793969849246232,"where B(ˆP) is a set of probability distributions similar to the empirical distribution ˆP in a certain
sense, called the ambiguity set. The empirical distribution ˆP is also called the nominal distribu-
tion. Many different ambiguity sets have been developed and studied in the optimization literature,
see Rahimian & Mehrotra (2019) for an extensive overview."
THE WASSERSTEIN-TYPE AMBIGUITY SET,0.09045226130653267,"3.1
THE WASSERSTEIN-TYPE AMBIGUITY SET"
THE WASSERSTEIN-TYPE AMBIGUITY SET,0.09296482412060302,"To present our ambiguity set and main results, we need to introduce some deﬁnitions and notations."
THE WASSERSTEIN-TYPE AMBIGUITY SET,0.09547738693467336,"Deﬁnition 3.1 (Wasserstein-type divergence). The divergence W between two probability distribu-
tions Q1 ∼(µ1, Σ1) ∈Rd × Sd
+ and Q2 ∼(µ2, Σ2) ∈Rd × Sd
+ is deﬁned as"
THE WASSERSTEIN-TYPE AMBIGUITY SET,0.09798994974874371,"W
 
Q1 ∥Q2

≜∥µ1 −µ2∥2
2 + tr

Σ1 + Σ2 −2
 
Σ"
THE WASSERSTEIN-TYPE AMBIGUITY SET,0.10050251256281408,"1
2
2 Σ1Σ"
THE WASSERSTEIN-TYPE AMBIGUITY SET,0.10301507537688442,"1
2
2
 1 2 
."
THE WASSERSTEIN-TYPE AMBIGUITY SET,0.10552763819095477,"The divergence W coincides with the squared type-2 Wasserstein distance between two Gaus-
sian distributions N(µ1, Σ1) and N(µ2, Σ2) (Givens & Shortt, 1984). One can readily show that
W is non-negative, and it vanishes if and only if (µ1, Σ1) = (µ2, Σ2), which implies that Q1
and Q2 have the same ﬁrst- and second-moments.
Recently, distributional robustiﬁcation with
Wasserstein-type ambiguity sets has been applied widely to various problems including domain
adaption (Taskesen et al., 2021), risk measurement (Nguyen et al., 2021b) and statistical estima-
tion (Nguyen et al., 2021a). The Wasserstein-type divergence in Deﬁnition 3.1 is also related to the
theory of optimal transport with its applications in robust decision making (Mohajerin Esfahani &
Kuhn, 2018; Blanchet & Murthy, 2019; Yue et al., 2021) and potential applications in fair machine
learning (Taskesen et al., 2020; Si et al., 2021; Wang et al., 2021)."
THE WASSERSTEIN-TYPE AMBIGUITY SET,0.10804020100502512,"Recall that the nominal distribution is ˆP =
1
N
PN
i=1 δ(ˆxi,ˆai). For any a ∈A, its conditional distri-
bution given A = a is given by"
THE WASSERSTEIN-TYPE AMBIGUITY SET,0.11055276381909548,"ˆPa =
1
|Ia| X"
THE WASSERSTEIN-TYPE AMBIGUITY SET,0.11306532663316583,"i∈Ia
δxi,
where
Ia ≜{i ∈{1, . . . , N} : ai = a}."
THE WASSERSTEIN-TYPE AMBIGUITY SET,0.11557788944723618,"We also use (ˆµa, ˆΣa) to denote the empirical mean vector and covariance matrix of X given A = a:"
THE WASSERSTEIN-TYPE AMBIGUITY SET,0.11809045226130653,"ˆµa = EˆPa[X] = EˆP[X|A = a]
and
ˆΣa + ˆµaˆµ⊤
a = EˆPa[XX⊤] = EˆP[XX⊤|A = a]."
THE WASSERSTEIN-TYPE AMBIGUITY SET,0.12060301507537688,"For any a ∈A, the empirical marginal distribution of A is denoted by ˆpa = |Ia|/N."
THE WASSERSTEIN-TYPE AMBIGUITY SET,0.12311557788944724,"Finally, for any set S, we use P(S) to denote the set of all probability distributions supported on S.
For any integer k, the k-by-k identity matrix is denoted Ik. We then deﬁne our ambiguity set as"
THE WASSERSTEIN-TYPE AMBIGUITY SET,0.12562814070351758,"B(ˆP) ≜ 
"
THE WASSERSTEIN-TYPE AMBIGUITY SET,0.12814070351758794,"Q ∈P(X × A) :
∃Qa ∈P(X) such that:
Q(X × {a}) = ˆpaQa(X)
∀X ⊆Rd, a ∈A
W(Qa, ˆPa) ≤εa
∀a ∈A 
"
THE WASSERSTEIN-TYPE AMBIGUITY SET,0.1306532663316583,",
(5)"
THE WASSERSTEIN-TYPE AMBIGUITY SET,0.13316582914572864,Published as a conference paper at ICLR 2022
THE WASSERSTEIN-TYPE AMBIGUITY SET,0.135678391959799,"where Qa is the conditional distribution of X|A = a. Intuitively, each Q ∈B(ˆP) is a joint distribu-
tion of the random vector (X, A), formed by taking a mixture of conditional distributions Qa with
mixture weight ˆpa. Each conditional distribution Qa is constrained in an εa-neighborhood of the
nominal conditional distribution ˆPa with respect to the W divergence. Because the loss function ℓ
is a quadratic function of X, the (conditional) expected losses only involve the ﬁrst two moments of
X, and thus prescribing the ambiguity set using W would sufﬁce for the purpose of robustiﬁcation."
REFORMULATION,0.13819095477386933,"3.2
REFORMULATION"
REFORMULATION,0.1407035175879397,"We now present the reformulation of problem (4) under the ambiguity set B(ˆP).
Theorem 3.2 (Reformulation). Suppose that for any a ∈A, either of the following two conditions
holds:"
REFORMULATION,0.14321608040201006,"(i) Marginal probability bounds: 0 ≤λ ≤ˆpa,"
REFORMULATION,0.1457286432160804,"(ii) Eigenvalue bounds: the empirical second moment matrix ˆ
Ma =
1
Na
P"
REFORMULATION,0.14824120603015076,"i∈Ia ˆxiˆx⊤
i satisﬁes
Pd−k
j=1 σj( ˆ
Ma) ≥εa, where σj( ˆ
Ma) is the j-th smallest eigenvalues of ˆ
Ma."
REFORMULATION,0.1507537688442211,Then problem (4) is equivalent to
REFORMULATION,0.15326633165829145,"min
V ∈Rd×k,V ⊤V =Ik
max{J0(V ), J1(V )},
(6a)"
REFORMULATION,0.15577889447236182,"where for each (a, a′) ∈{(0, 1), (1, 0)}, the function Ja is deﬁned as"
REFORMULATION,0.15829145728643215,"Ja(V ) = κa + θa
q
Id −V V ⊤, ˆ
Ma

+ ϑa′
q
Id −V V ⊤, ˆ
Ma′
+

Id −V V ⊤, Ca

,
(6b)"
REFORMULATION,0.16080402010050251,"and the parameters κ ∈R, θ ∈R, ϑ ∈R and C ∈Sd
+ are deﬁned as"
REFORMULATION,0.16331658291457288,"κa
= (ˆpa + λ)εa + (ˆpa′ −λ)εa′,
θa = 2|ˆpa + λ|√εa,
ϑa′ = 2|ˆpa′ −λ|√εa′,
Ca
= (ˆpa + λ) ˆ
Ma + (ˆpa′ −λ) ˆ
Ma′.
(6c)"
REFORMULATION,0.1658291457286432,We now brieﬂy explain the steps that lead to the results in Theorem 3.2. Letting
REFORMULATION,0.16834170854271358,"J0(V ) =
sup
Q∈B(ˆP)
(ˆp0 + λ)EQ[ℓ(V, X)|A = 0] + (ˆp1 −λ)EQ[ℓ(V, X)|A = 1],"
REFORMULATION,0.1708542713567839,"J1(V ) =
sup
Q∈B(ˆP)
(ˆp0 −λ)EQ[ℓ(V, X)|A = 0] + (ˆp1 + λ)EQ[ℓ(V, X)|A = 1],"
REFORMULATION,0.17336683417085427,"then by expanding the term U(V, Q) using its deﬁnition, problem (4) becomes"
REFORMULATION,0.17587939698492464,"min
V ∈Rd×k,V ⊤V =Ik
max{J0(V ), J1(V )}."
REFORMULATION,0.17839195979899497,"Leveraging the deﬁnition the ambiguity set B(ˆP), for any pair (a, a′) ∈{(0, 1), (1, 0)}, we can
decompose Ja into two separate supremum problems as follows"
REFORMULATION,0.18090452261306533,"Ja(V ) =
sup
Qa:W(Qa,ˆPa)≤εa
(ˆpa + λ)EQa[ℓ(V, X)] +
sup
Qa′:W(Qa′,ˆPa′)≤εa′
(ˆpa′ −λ)EQa′[ℓ(V, X)]."
REFORMULATION,0.18341708542713567,"The next proposition asserts that each individual supremum in the above expression admits an ana-
lytical expression.
Proposition 3.3 (Reformulation). Fix a ∈A. For any υ ∈R, εa ∈R+, it holds that"
REFORMULATION,0.18592964824120603,"sup
Qa:W(Qa,ˆPa)≤εa
υEQa[ℓ(V, X)] ="
REFORMULATION,0.1884422110552764,"





"
REFORMULATION,0.19095477386934673,"




"
REFORMULATION,0.1934673366834171,"υ
q
Id −V V ⊤, ˆ
Ma

+ √εa"
REFORMULATION,0.19597989949748743,"2
if υ ≥0,"
REFORMULATION,0.1984924623115578,"υ
q
Id −V V ⊤, ˆ
Ma

−√εa"
REFORMULATION,0.20100502512562815,"2
if υ < 0 and

Id −V V ⊤, ˆ
Ma

≥εa,"
REFORMULATION,0.20351758793969849,"0
if υ < 0 and

Id −V V ⊤, ˆ
Ma

< εa."
REFORMULATION,0.20603015075376885,Published as a conference paper at ICLR 2022
REFORMULATION,0.20854271356783918,"The proof of Theorem 3.2 now follows by applying Proposition 3.3 to each term in Ja, and balance
the parameters to obtain (6c). A detailed proof is relegated to the appendix. In the next section, we
study an efﬁcient algorithm to solve problem (6a).
Remark 3.4 (Recovery of the nominal PCA). If λ = 0 and εa = 0 ∀a ∈A, our formulation (4)
becomes the standard PCA problem (2). In this case, our robust fair principal components reduce
to the standard principal components. On the contrary, existing fair PCA methods such as Samadi
et al. (2018) and Olfat & Aswani (2019) cannot recover the standard principal components."
RIEMANNIAN GRADIENT DESCENT ALGORITHM,0.21105527638190955,"4
RIEMANNIAN GRADIENT DESCENT ALGORITHM"
RIEMANNIAN GRADIENT DESCENT ALGORITHM,0.2135678391959799,"The distributionally robust fairness-aware PCA problem (4) is originally an inﬁnite-dimensional
min-max problem. Indeed, the inner maximization problem in (4) optimizes over the space of prob-
ability measures. Thanks to Theorem 3.2, it is reduced to the simpler ﬁnite-dimensional minimax
problem (6a), where the inner problem is only a maximization over two points. Problem (6a) is,
however, still challenging as it is a non-convex optimization problem over a non-convex feasible re-
gion deﬁned by the orthogonality constraint V ⊤V = Id. The purpose of this section is to devise an
efﬁcient algorithm for solving problem (6a) to local optimality based on Riemannian optimization."
REPARAMETRIZATION,0.21608040201005024,"4.1
REPARAMETRIZATION"
REPARAMETRIZATION,0.2185929648241206,"As mentioned above, the non-convexity of problem (6a) comes from both the objective function and
the feasible region. It turns out that we can get rid of the non-convexity of the objective function
via a simple change of variables. To see that, we let U ∈Rd×(d−k) be an orthonormal matrix
complement to V , that is, U and V satisfy UU ⊤+ V V ⊤= Id. Thus, we can express the objective
function J via
J(V ) = F(U) ≜max{F0(U), F1(U)},
where for (a, a′) ∈{(0, 1), (1, 0)}, the function Fa is deﬁned as"
REPARAMETRIZATION,0.22110552763819097,"Fa(U) ≜κa + θa
q
UU ⊤, ˆ
Ma

+ ϑa′
q
UU ⊤, ˆ
Ma′
+

UU ⊤, Ca

."
REPARAMETRIZATION,0.2236180904522613,"Moreover, letting M ≜{U ∈Rd×(d−k) : U ⊤U = Id−k}, we can re-express problem (6a) as"
REPARAMETRIZATION,0.22613065326633167,"min
U∈M F(U).
(7)"
REPARAMETRIZATION,0.228643216080402,"The set M of problem (7) is a Riemannian manifold, called the Stiefel manifold (Absil et al., 2007,
Section 3.3.2). It is then natural to solve (7) using a Riemannian optimization algorithms (Absil
et al., 2007). In fact, problem (6a) itself (before the change of variables) can also be cast as a
Riemannian optimization problem over another Stiefel manifold. The change of variables above
might seem unnecessary. Nonetheless, the upshot of problem (7) is that the objective function F is
convex (in the traditional sense). This faciliates the application of the theoretical and algorithmic
framework developed in Li et al. (2021) for (weakly) convex optimization over the Stiefel manifolds."
THE RIEMANNIAN SUBGRADIENT,0.23115577889447236,"4.2
THE RIEMANNIAN SUBGRADIENT"
THE RIEMANNIAN SUBGRADIENT,0.23366834170854273,"Note that the objective function F is non-smooth since it is deﬁned as the maximum of two func-
tions F0 and F1. To apply the framework in Li et al. (2021), we need to compute the Riemannian
subgradient of the objective function F. Since the Stiefel manifold M is an embedded manifold in
Euclidean space, the Riemannian subgradient of F at any point U ∈M is given by the orthogonal
projection of the usual Euclidean subgradient onto the tangent space of the manifold M at the point
U, see Absil et al. (2007, Section 3.6.1) for example.
Lemma 4.1. For any point U ∈M, let3 aU ∈arg maxa∈{0,1} Fa(U) and a′
U = 1 −aU. Then, a
Riemannian subgradient of the objective function F at the point U is given by"
THE RIEMANNIAN SUBGRADIENT,0.23618090452261306,gradF(U) = (Id −UU ⊤) 
THE RIEMANNIAN SUBGRADIENT,0.23869346733668342,"
θaU
q
UU ⊤, ˆ
MaU
 ˆ
MaU U +
ϑa′
U
q
UU ⊤, ˆ
Ma′
U
 ˆ
Ma′
U U + 2CaU U  ."
THE RIEMANNIAN SUBGRADIENT,0.24120603015075376,"3 It is possible that the maximizer is not unique. In that case, choosing aU to be either 0 or 1 would work."
THE RIEMANNIAN SUBGRADIENT,0.24371859296482412,Published as a conference paper at ICLR 2022
RETRACTIONS,0.24623115577889448,"4.3
RETRACTIONS"
RETRACTIONS,0.24874371859296482,"Another important instrument required by the framework in Li et al. (2021) is a retraction of the
Stiefel manifold M. At each iteration, the point U −γ∆obtained by moving from the current
iterate U in the opposite direction of the Riemannian gradient ∆may not lie on the manifold in
general, where γ > 0 is the stepsize. In Riemannian optimization, this is circumvented by the
concept of retraction. Given a point U ∈M on the manifold, the Riemannian gradient ∆∈
TUM (which must lie in the tangent space TUM) and a stepsize γ, the retraction map Rtr deﬁnes a
point RtrU(−γ∆) which is guaranteed to lie on the manifold M. Roughly speaking, the retraction
RtrU( · ) approximates the geodesic curve through U along the input tangential direction. For a
formal deﬁnition of retractions, we refer the readers to (Absil et al., 2007, Section 4.1). In this
paper, we focus on the following two commonly used retractions for Stiefel manifolds. The ﬁrst one
is the QR decomposition-based retraction using the Q-factor qf( · ) in the QR decomposition:"
RETRACTIONS,0.25125628140703515,"Rtrqf
U(∆) = qf(U + ∆),
U ∈M, ∆∈TUM."
RETRACTIONS,0.2537688442211055,The second one is the polar decomposition-based retraction
RETRACTIONS,0.2562814070351759,"Rtrpolar
U
(∆) = (U + ∆)(Id−k + ∆⊤∆)−1"
RETRACTIONS,0.25879396984924624,"2 ,
U ∈M, ∆∈TUM.
(8)"
ALGORITHM AND CONVERGENCE GUARANTEES,0.2613065326633166,"4.4
ALGORITHM AND CONVERGENCE GUARANTEES"
ALGORITHM AND CONVERGENCE GUARANTEES,0.2638190954773869,"Associated with any choice of retraction Rtr is a concrete instantiation of the Riemannian subgradi-
ent descent algorithm for our problem (7), which is presented in Algorithm 1 with speciﬁc choice of
the stepsizes γt motivated by the theoretical results of (Li et al., 2021)."
ALGORITHM AND CONVERGENCE GUARANTEES,0.2663316582914573,Algorithm 1 Riemannian Subgradient Descent for (7)
ALGORITHM AND CONVERGENCE GUARANTEES,0.26884422110552764,"1: Input: An initial point U0, a number of iterations τ and a retraction Rtr : (U, ∆) 7→RtrU(∆).
2: for t = 0, 1, . . . , τ −1, do
3:
Find at ≜arg maxa∈{0,1}{Fa(Ut)}.
4:
Compute the Riemannian subgradient ∆t = gradF(Ut) using the formula"
ALGORITHM AND CONVERGENCE GUARANTEES,0.271356783919598,"∆t = (I −UtUt
⊤) "
ALGORITHM AND CONVERGENCE GUARANTEES,0.27386934673366836,"
θat
q
UtU ⊤
t , ˆ
Mat
 ˆ
MatUt +
ϑa′
t
q
UtU ⊤
t , ˆ
Ma′
t
 ˆ
Ma′
tUt + 2CatUt  ."
ALGORITHM AND CONVERGENCE GUARANTEES,0.27638190954773867,"5:
Set Ut+1 = RtrUt(−γt∆t), where the step-size γt ≡
1
√τ+1 is constant.
6: end for
7: Output: Uτ."
ALGORITHM AND CONVERGENCE GUARANTEES,0.27889447236180903,"We now study the convergence guarantee of Algorithm 1. The following lemma shows that the
objective function F is Lipschitz continuous (with respect to the Riemannian metric on the Stiefel
manifold M) with an explicit Lipschitz constant L.
Lemma 4.2 (Lipschitz continuity). The function F is L-Lipschitz continuous on M, where L > 0
is given by"
ALGORITHM AND CONVERGENCE GUARANTEES,0.2814070351758794,L ≜max (
ALGORITHM AND CONVERGENCE GUARANTEES,0.28391959798994976,"θ0
σmax( ˆ
M0)
q"
ALGORITHM AND CONVERGENCE GUARANTEES,0.2864321608040201,"σmin( ˆ
M0)
, θ1
σmax( ˆ
M1)
q"
ALGORITHM AND CONVERGENCE GUARANTEES,0.2889447236180904,"σmin( ˆ
M1)
, ϑ0
σmax( ˆ
M0)
q"
ALGORITHM AND CONVERGENCE GUARANTEES,0.2914572864321608,"σmin( ˆ
M0)
, ϑ1
σmax( ˆ
M1)
q"
ALGORITHM AND CONVERGENCE GUARANTEES,0.29396984924623115,"σmin( ˆ
M1)
, 2
√"
ALGORITHM AND CONVERGENCE GUARANTEES,0.2964824120603015,"d −kσmax(C0), 2
√"
ALGORITHM AND CONVERGENCE GUARANTEES,0.2989949748743719,d −kσmax(C1) ) . (9)
ALGORITHM AND CONVERGENCE GUARANTEES,0.3015075376884422,"We now proceed to show that Algorithm 1 enjoys a sub-linear convergence rate. To state the result,
we deﬁne the Moreau envelope"
ALGORITHM AND CONVERGENCE GUARANTEES,0.30402010050251255,"Fµ(U) ≜min
U ′∈M"
ALGORITHM AND CONVERGENCE GUARANTEES,0.3065326633165829,"
F(U ′) + 1"
ALGORITHM AND CONVERGENCE GUARANTEES,0.30904522613065327,"2µ ∥U ′ −U∥2
F 
,"
ALGORITHM AND CONVERGENCE GUARANTEES,0.31155778894472363,Published as a conference paper at ICLR 2022
ALGORITHM AND CONVERGENCE GUARANTEES,0.314070351758794,"where ∥· ∥F denotes the Frobenius norm of a matrix. Also, to measure the progress of the algorithm,
we need to introduce the proximal mapping on the Stiefel manifold (Li et al., 2021):"
ALGORITHM AND CONVERGENCE GUARANTEES,0.3165829145728643,"proxµF (U) ∈arg min
U ′∈M"
ALGORITHM AND CONVERGENCE GUARANTEES,0.31909547738693467,"
F(U ′) + 1"
ALGORITHM AND CONVERGENCE GUARANTEES,0.32160804020100503,"2µ ∥U ′ −U∥2
F 
."
ALGORITHM AND CONVERGENCE GUARANTEES,0.3241206030150754,"From Li et al. (2021, Equation (22)), we have that"
ALGORITHM AND CONVERGENCE GUARANTEES,0.32663316582914576,∥gradF(U)∥F ≤
ALGORITHM AND CONVERGENCE GUARANTEES,0.32914572864321606,"proxµF (U) −U

F
µ
≜gapµ(U)."
ALGORITHM AND CONVERGENCE GUARANTEES,0.3316582914572864,"Therefore, the number gapµ(U) is a good candidate to quantify the progress of optimization algo-
rithms for solving problem (7)."
ALGORITHM AND CONVERGENCE GUARANTEES,0.3341708542713568,"Theorem 4.3 (Convergence guarantee). Let {Ut}t=1,...,τ be the sequence of iterates generated by
Algorithm 1. Suppose that µ = 1/4L, where L is the Lipschitz constant of F in (9). Then, we have"
ALGORITHM AND CONVERGENCE GUARANTEES,0.33668341708542715,"min
t=0,...,τ gapµ(Ut) ≤2
p"
ALGORITHM AND CONVERGENCE GUARANTEES,0.3391959798994975,Fµ(U0) −minU Fµ(U) + 2L3(L + 1)
ALGORITHM AND CONVERGENCE GUARANTEES,0.3417085427135678,"(τ + 1)1/4
."
NUMERICAL EXPERIMENTS,0.3442211055276382,"5
NUMERICAL EXPERIMENTS"
NUMERICAL EXPERIMENTS,0.34673366834170855,"We compare our proposed method, denoted RFPCA, against two state-of-the-art methods for fair
PCA: 1) FairPCA Samadi et al. (2018)4, and 2) CFPCA Olfat & Aswani (2019)5 with both cases:
only mean constraint, and both mean and covariance constraints. We consider a wide variety of
datasets with ranging sample sizes and number of features. Further details about the datatasets can
be found in Appendix C. The code for all experiments is available in supplementary materials. We
include here some details about the hyper-parameters that we search in the cross-validation steps."
NUMERICAL EXPERIMENTS,0.3492462311557789,"• RFPCA. We notice that the neighborhood size εa should be inversely proportional to the size of
subgroup a. Indeed, a subgroup with large sample size is likely to have more reliable estimate of
the moment information. Then we parameterize the neighborhood size εa by a common scalar
α, and we have εa = α/√Na, where Na is the number of samples in group a. We search
α ∈{0.05, 0.1, 0.15} and λ ∈{0., 0.5, 1., 1.5, 2.0, 2.5}. For better convergence quality, we set
the number of iteration for our subgradient descent algorithm to τ = 1000 and also repeat the
Riemannian descent for 20 randomly generated initial point U0."
NUMERICAL EXPERIMENTS,0.35175879396984927,"• FairPCA. According to Samadi et al. (2018), we only need tens of iterations for the multiplica-
tive weight algorithm to provide good-quality solution; however, to ensure a fair comparison, we
set the number of iterations to 1000 for the convergence guarantee. We search the learning rate
η of the algorithm from set of 17 values evenly spaced in [0.25, 4.25] and {0.1}."
NUMERICAL EXPERIMENTS,0.3542713567839196,"• CFPCA. Following Olfat & Aswani (2019), for the mean-constrained version of CFPCA, we
search δ from {0., 0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9}, and for both the mean and covariance con-
strained version, we ﬁx δ = 0 while searching µ in {0.0001, 0.001, 0.01, 0.05, 0.5}."
NUMERICAL EXPERIMENTS,0.35678391959798994,"Trade-offs. First, we examine the trade-off between the total reconstruction error and the gap be-
tween the subgroup error. In this experiment, we only compare our model with FairPCA and
CFPCA mean-constraint version. We plot a pareto curve for each of them over the two criteria with
different hyper-parameters (hyper-parameters test range are mentioned above). The whole datasets
are used for training and evaluation. The results averaged over 5 runs are shown in Figure 2."
NUMERICAL EXPERIMENTS,0.3592964824120603,"In testing methods with different principal components, we ﬁrst split each dataset into training set
and test set with equal size (50% each), the projection matrix of each method is learned from training
set and tested over both sets. In this case, we only compare our method with traditional PCA and
FairPCA method. We ﬁx one set hyper-parameters for each method. For FairPCA, we set η = 0.1
and for RFPCA we set α = 0.15, λ = 0.5, others hyper-parameters are kept as discussed before.
The results are averaged over 5 different splits. Figure 3 shows the consistence of our method
performing fair projections over different values of k. Our method (cross) exhibits smaller gap of
subgroup errors. More results and discussions on the effect of ε can be found in Appendix D.2."
NUMERICAL EXPERIMENTS,0.36180904522613067,"4 https://github.com/samirasamadi/Fair-PCA
5 https://github.com/molfat66/FairML"
NUMERICAL EXPERIMENTS,0.36432160804020103,Published as a conference paper at ICLR 2022
NUMERICAL EXPERIMENTS,0.36683417085427134,"Figure 2: Pareto curves on Default Credit
dataset (all data) with 3 principal components"
NUMERICAL EXPERIMENTS,0.3693467336683417,"Figure 3: Subgroup average error with different k
on Biodeg dataset (Out-of-sample)."
NUMERICAL EXPERIMENTS,0.37185929648241206,"Cross-validations. Next, we report the performance of all methods based on three criteria: absolute
difference between average reconstruction error between groups (ABDiff.), average reconstruction
error of all data (ARE.), and the fairness criterion deﬁned by Olfat & Aswani (2019) with respect
to a linear SVM’s classiﬁer family (△FLin).6 Due to the space constraint, we only include the
ﬁrst two criteria in the main text, see Appendix 4 for full results. To emphasize the generalization
capacity of each algorithm, we split each dataset into a training set and a test set with ratio of
30% −70% respectively, and only extract top three principal components from the training set.
We ﬁnd the best hyper-parameters by 3-fold cross validation, and prioritize the one giving minimum
value of the summation (ABDiff.+ARE.). The results are averaged over 10 different training-testing
splits. We report the performance on both training set (In-sample data) and test set (Out-of-sample
data). The details results for Out-of-sample data is given in Table 1, more details about settings and
performance can be found at Appendix D."
NUMERICAL EXPERIMENTS,0.3743718592964824,"Results. Our proposed RFPCA method outperforms on 11 out of 15 datasets in terms of the subgroup
error gap ABDiff, and 9 out of 15 with the totall error ARE. criterion. There are 5 datasets that
RFPCA gives the best results for both criteria, and for the remaining datasets, RFPCA has small
performance gaps compared with the best method."
NUMERICAL EXPERIMENTS,0.3768844221105528,Table 1: Out-of-sample errors on real datasets. Bold indicates the lowest error for each dataset.
NUMERICAL EXPERIMENTS,0.3793969849246231,"RFPCA
FairPCA
CFPCA-Mean Con.
CFPCA - Both Con.
Dataset
ABDiff.
ARE.
ABDiff.
ARE.
ABDiff.
ARE.
ABDiff.
ARE.
Default Credit
0.9483
10.3995
1.4401
10.4439
0.9367
10.9451
3.3359
22.0310
Biodeg
23.0066
33.8571
27.5159
34.6184
29.1728
37.6052
37.9533
50.7090
E. Coli
1.1500
1.7210
1.5280
2.4799
1.1005
2.9466
5.1275
5.6674
Energy
0.0125
0.2238
0.0138
0.2225
0.1229
2.7318
0.1001
7.9511
German Credit
2.0588
43.9032
1.3670
44.0064
1.7845
43.9648
1.4955
49.5014
Image
0.7522
6.0199
1.6129
10.2616
1.1499
14.3725
4.7013
19.3356
Letter
0.1712
7.4176
1.2489
7.4470
0.4427
8.7445
0.5743
15.1779
Magic
1.8314
3.9094
2.9405
3.3815
5.5790
4.2105
8.7810
9.0064
Parkinsons
0.3273
5.0597
0.8678
4.9044
3.3804
5.7260
18.3312
19.7001
SkillCraft
0.7669
8.2828
0.7771
8.2494
1.0283
9.9484
1.2849
15.9751
Statlog
0.0838
3.0998
0.3356
7.9734
0.4476
10.8263
13.8437
35.8268
Steel
1.1472
12.5944
1.2208
12.3096
4.8710
16.4015
3.8084
25.8953
Taiwan Credit
0.5523
10.9845
0.5710
10.9415
0.5744
13.0437
0.9535
21.8963
Wine Quality
0.6359
4.2801
0.3046
6.0936
1.5020
6.1118
3.0451
10.1001
LFW
0.4463
7.6229
0.5340
7.6361
fail to converge"
NUMERICAL EXPERIMENTS,0.38190954773869346,6 The code to estimate this quantity is provided at the author’s repository
NUMERICAL EXPERIMENTS,0.3844221105527638,Published as a conference paper at ICLR 2022
REFERENCES,0.3869346733668342,REFERENCES
REFERENCES,0.38944723618090454,"Pierre-Antoine Absil, Robert Mahony, and Rodolphe Sepulchre. Optimization Algorithms on Matrix
Manifolds. Princeton University Press, 2007."
REFERENCES,0.39195979899497485,"Alekh Agarwal, Miroslav Dud´ık, and Zhiwei Steven Wu. Fair regression: Quantitative deﬁnitions
and reduction-based algorithms. In International Conference on Machine Learning, pp. 120–129.
PMLR, 2019."
REFERENCES,0.3944723618090452,"Naveed Akhtar and Ajmal Mian. Threat of adversarial attacks on deep learning in computer vision:
A survey. Ieee Access, 6:14410–14430, 2018."
REFERENCES,0.3969849246231156,"Solon Barocas, Moritz Hardt, and Arvind Narayanan. Fairness and machine learning. fairmlbook.
org, 2019, 2018."
REFERENCES,0.39949748743718594,"Richard Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, and Aaron Roth. Fairness in criminal
justice risk assessments: The state of the art. Sociological Methods & Research, 50(1):3–44,
2021."
REFERENCES,0.4020100502512563,"Alex Beutel, Jilin Chen, Zhe Zhao, and Ed H Chi. Data decisions and theoretical implications when
adversarially learning fair representations. arXiv preprint arXiv:1707.00075, 2017."
REFERENCES,0.4045226130653266,"Jose Blanchet and Karthyek Murthy. Quantifying distributional model risk via optimal transport.
Mathematics of Operations Research, 44(2):565–600, 2019."
REFERENCES,0.40703517587939697,"Jose Blanchet, Karthyek Murthy, and Viet Anh Nguyen. Statistical analysis of Wasserstein distribu-
tionally robust estimators. INFORMS TutORials in Operations Research, 2021."
REFERENCES,0.40954773869346733,"Flavio P Calmon, Dennis Wei, Bhanukiran Vinzamuri, Karthikeyan Natesan Ramamurthy, and
Kush R Varshney. Optimized pre-processing for discrimination prevention. In Proceedings of
the 31st International Conference on Neural Information Processing Systems, pp. 3995–4004,
2017."
REFERENCES,0.4120603015075377,"Nicholas Carlini and David Wagner. Towards evaluating the robustness of neural networks. In 2017
IEEE Symposium on Security and Privacy (SP), pp. 39–57. IEEE, 2017."
REFERENCES,0.41457286432160806,"Anirban Chakraborty, Manaar Alam, Vishal Dey, Anupam Chattopadhyay, and Debdeep Mukhopad-
hyay. Adversarial attacks and defences: A survey. arXiv preprint arXiv:1810.00069, 2018."
REFERENCES,0.41708542713567837,"Alexandra Chouldechova.
Fair prediction with disparate impact: A study of bias in recidivism
prediction instruments. Big Data, 5(2):153–163, 2017."
REFERENCES,0.41959798994974873,"Erick Delage and Yinyu Ye. Distributionally robust optimization under moment uncertainty with
application to data-driven problems. Operations Research, 58(3):595–612, 2010."
REFERENCES,0.4221105527638191,"Michele Donini, Luca Oneto, Shai Ben-David, John S Shawe-Taylor, and Massimiliano Pontil. Em-
pirical risk minimization under fairness constraints. In Advances in Neural Information Process-
ing Systems, pp. 2791–2801, 2018."
REFERENCES,0.42462311557788945,"Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel.
Fairness
through awareness. In Proceedings of the 3rd innovations in theoretical computer science confer-
ence, pp. 214–226, 2012."
REFERENCES,0.4271356783919598,"Michael Feldman, Sorelle A Friedler, John Moeller, Carlos Scheidegger, and Suresh Venkatasubra-
manian. Certifying and removing disparate impact. In Proceedings of the 21th ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining, pp. 259–268, 2015."
REFERENCES,0.4296482412060301,"C.R. Givens and R.M. Shortt. A class of Wasserstein metrics for probability distributions. The
Michigan Mathematical Journal, 31(2):231–240, 1984."
REFERENCES,0.4321608040201005,"Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. arXiv preprint arXiv:1412.6572, 2014."
REFERENCES,0.43467336683417085,"Moritz Hardt, Eric Price, Eric Price, and Nati Srebro. Equality of opportunity in supervised learning.
In Advances in Neural Information Processing Systems 29, pp. 3315–3323, 2016a."
REFERENCES,0.4371859296482412,Published as a conference paper at ICLR 2022
REFERENCES,0.4396984924623116,"Moritz Hardt, Eric Price, and Nati Srebro. Equality of opportunity in supervised learning. Advances
in neural information processing systems, 29:3315–3323, 2016b."
REFERENCES,0.44221105527638194,"Tito Homem-de Mello and G¨uzin Bayraksan. Monte Carlo sampling-based methods for stochastic
optimization. Surveys in Operations Research and Management Science, 19(1):56–85, 2014."
REFERENCES,0.44472361809045224,"Harold Hotelling. Analysis of a complex of statistical variables into principal components. Journal
of educational psychology, 24(6):417, 1933."
REFERENCES,0.4472361809045226,"Faisal Kamiran and Toon Calders. Data preprocessing techniques for classiﬁcation without discrim-
ination. Knowledge and Information Systems, 33(1):1–33, 2012."
REFERENCES,0.44974874371859297,"Toshihiro Kamishima, Shotaro Akaho, Hideki Asoh, and Jun Sakuma. Fairness-aware classiﬁer
with prejudice remover regularizer. In Joint European Conference on Machine Learning and
Knowledge Discovery in Databases, pp. 35–50. Springer, 2012."
REFERENCES,0.45226130653266333,"Daniel Kuhn, Peyman Mohajerin Esfahani, Viet Anh Nguyen, and Soroosh Shaﬁeezadeh-Abadeh.
Wasserstein distributionally robust optimization: Theory and applications in machine learning. In
Operations Research & Management Science in the Age of Analytics, pp. 130–166. INFORMS,
2019."
REFERENCES,0.4547738693467337,"Matt J Kusner, Joshua R Loftus, Chris Russell, and Ricardo Silva. Counterfactual fairness. arXiv
preprint arXiv:1703.06856, 2017."
REFERENCES,0.457286432160804,"Xiao Li, Shixiang Chen, Zengde Deng, Qing Qu, Zhihui Zhu, and Anthony Man Cho So. Weakly
convex optimization over Stiefel manifold using Riemannian subgradient-type methods. SIAM
Journal on Optimization, 33(3):1605–1634, 2021."
REFERENCES,0.45979899497487436,"Zachary Lipton, Julian McAuley, and Alexandra Chouldechova. Does mitigating ML’s impact dis-
parity require treatment disparity? In Advances in Neural Information Processing Systems, pp.
8125–8135, 2018."
REFERENCES,0.4623115577889447,"David Madras, Elliot Creager, Toniann Pitassi, and Richard Zemel. Learning adversarially fair and
transferable representations. In International Conference on Machine Learning, pp. 3384–3393.
PMLR, 2018."
REFERENCES,0.4648241206030151,"Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083,
2017."
REFERENCES,0.46733668341708545,"Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. A survey
on bias and fairness in machine learning. ACM Computing Surveys (CSUR), 54(6):1–35, 2021."
REFERENCES,0.46984924623115576,"Peyman Mohajerin Esfahani and Daniel Kuhn. Data-driven distributionally robust optimization us-
ing the Wasserstein metric: Performance guarantees and tractable reformulations. Mathematical
Programming, 171(1-2):115–166, 2018."
REFERENCES,0.4723618090452261,"Hongseok Namkoong and John C Duchi. Variance-based regularization with convex objectives. In
Advances in Neural Information Processing Systems 30, pp. 2971–2980, 2017."
REFERENCES,0.4748743718592965,"Viet Anh Nguyen. Adversarial Analytics. PhD thesis, Ecole Polytechnique F´ed´erale de Lausanne,
2019."
REFERENCES,0.47738693467336685,"Viet Anh Nguyen, Soroosh Shaﬁeezadeh Abadeh, Man-Chung Yue, Daniel Kuhn, and Wolfram
Wiesemann.
Calculating optimistic likelihoods using (geodesically) convex optimization.
In
Advances in Neural Information Processing Systems, pp. 13942–13953, 2019."
REFERENCES,0.4798994974874372,"Viet Anh Nguyen, S. Shaﬁeezadeh-Abadeh, D. Kuhn, and P. Mohajerin Esfahani. Bridging Bayesian
and minimax mean square error estimation via Wasserstein distributionally robust optimization.
Mathematics of Operations Research, 2021a."
REFERENCES,0.4824120603015075,"Viet Anh Nguyen, Soroosh Shaﬁeezadeh-Abadeh, Damir Filipovi´c, and Daniel Kuhn.
Mean-
covariance robust risk measurement. arXiv preprint arXiv:2112.09959, 2021b."
REFERENCES,0.4849246231155779,Published as a conference paper at ICLR 2022
REFERENCES,0.48743718592964824,"Matt Olfat and Anil Aswani. Convex formulations for fair principal component analysis. In Pro-
ceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 33, pp. 663–670, 2019."
REFERENCES,0.4899497487437186,"Karl Pearson. Liii. On lines and planes of closest ﬁt to systems of points in space. The London,
Edinburgh, and Dublin philosophical magazine and journal of science, 2(11):559–572, 1901."
REFERENCES,0.49246231155778897,"Hamed Rahimian and Sanjay Mehrotra.
Distributionally robust optimization: A review.
arXiv
preprint arXiv:1908.05659, 2019."
REFERENCES,0.4949748743718593,"Samira Samadi, Uthaipon Tantipongpipat, Jamie H Morgenstern, Mohit Singh, and Santosh Vem-
pala. The price of fair PCA: One extra dimension. In Advances in Neural Information Processing
Systems, pp. 10976–10987, 2018."
REFERENCES,0.49748743718592964,"Nian Si, Karthyek Murthy, Jose Blanchet, and Viet Anh Nguyen. Testing group fairness via optimal
transport projections. In Proceedings of the 38th International Conference on Machine Learning,
2021."
REFERENCES,0.5,"James E Smith and Robert L Winkler. The optimizer’s curse: Skepticism and postdecision surprise
in decision analysis. Management Science, 52(3):311–322, 2006."
REFERENCES,0.5025125628140703,"Uthaipon Tantipongpipat, Samira Samadi, Mohit Singh, Jamie Morgenstern, and Santosh Vem-
pala.
Multi-criteria dimensionality reduction with applications to fairness.
arXiv preprint
arXiv:1902.11281, 2019."
REFERENCES,0.5050251256281407,"Bahar Taskesen, Viet Anh Nguyen, Daniel Kuhn, and Jose Blanchet.
A distributionally robust
approach to fair classiﬁcation. arXiv preprint arXiv:2007.09530, 2020."
REFERENCES,0.507537688442211,"Bahar Taskesen, Man-Chung Yue, Jose Blanchet, Daniel Kuhn, and Viet Anh Nguyen. Sequential
domain adaptation by synthesizing distributionally robust experts. In Proceedings of the 38th
International Conference on Machine Learning, 2021."
REFERENCES,0.5100502512562815,"Sahil Verma and Julia Rubin. Fairness deﬁnitions explained. In 2018 IEEE/ACM International
Workshop on Software Fairness (fairware), pp. 1–7. IEEE, 2018."
REFERENCES,0.5125628140703518,"Yijie Wang, Viet Anh Nguyen, and Grani Hanasusanto. Wasserstein robust support vector machines
with fairness constraints. arXiv preprint arXiv:2103.06828, 2021."
REFERENCES,0.5150753768844221,"Dennis Wei, Karthikeyan Natesan Ramamurthy, and Flavio du Pin Calmon. Optimized score trans-
formation for fair classiﬁcation. arXiv preprint arXiv:1906.00066, 2019."
REFERENCES,0.5175879396984925,"Man-Chung Yue, Daniel Kuhn, and Wolfram Wiesemann. On linear optimization over Wasserstein
balls. Mathematical Programming, 2021."
REFERENCES,0.5201005025125628,"Gad Zalcberg and Ami Wiesel. Fair principal component analysis and ﬁlter design. IEEE Transac-
tions on Signal Processing, 69:4835–4842, 2021."
REFERENCES,0.5226130653266332,"Rich Zemel, Yu Wu, Kevin Swersky, Toni Pitassi, and Cynthia Dwork. Learning fair representations.
In International Conference on Machine Learning, pp. 325–333. PMLR, 2013."
REFERENCES,0.5251256281407035,"Brian Hu Zhang, Blake Lemoine, and Margaret Mitchell. Mitigating unwanted biases with adver-
sarial learning. In Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society, pp.
335–340, 2018."
REFERENCES,0.5276381909547738,"A
PROOFS"
REFERENCES,0.5301507537688442,"A.1
PROOFS OF SECTION 2"
REFERENCES,0.5326633165829145,"Proof of Proposition 2.2. Let S = EQ[XX⊤|A = 0] −EQ[XX⊤|A = 1]. We ﬁrst prove the
“only if” direction. Suppose that there exists a fair projection matrix V ∈Mk relative to Q. Let
U ∈Md−k be a complement matrix of V . Then, Deﬁnition 2.1 can be rewritten as"
REFERENCES,0.535175879396985,"⟨UU ⊤, S⟩= 0,"
REFERENCES,0.5376884422110553,Published as a conference paper at ICLR 2022
REFERENCES,0.5402010050251256,"which implies that the null space of S has a dimension at least d −k. By the rank-nullity duality,
we have rank(S) ≤k."
REFERENCES,0.542713567839196,"Next, we prove the “if” direction. Suppose that rank(S) ≤k. Then, the matrix S has at least d −k
(repeated) zero eigenvalues. Let U ∈Md−k be an orthonormal matrix whose columns are any d−k
eigenvectors corresponding to the zero eigenvalues of S and V ∈Mk be a complement matrix of
U. Then,
⟨Id −V V ⊤, S⟩= ⟨UU ⊤, S⟩= 0.
Therefore, V is a fair projection matrix relative to Q. This completes the proof."
REFERENCES,0.5452261306532663,"A.2
PROOF OF SECTION 3"
REFERENCES,0.5477386934673367,"Proofs of Proposition 3.3. By exploiting the deﬁnition of the loss function ℓ, we ﬁnd"
REFERENCES,0.550251256281407,"sup
Qa:W(Qa,ˆPa)≤εa
υEQa[ℓ(V, X)] = 
 "
REFERENCES,0.5527638190954773,"sup
µa,Σa
tr
 
υ(I −V V ⊤)(Σa + µaµ⊤
a )
"
REFERENCES,0.5552763819095478,"s.t.
∥µa −ˆµa∥2
2 + tr

Σa + ˆΣa −2
 ˆΣ"
REFERENCES,0.5577889447236181,"1
2a Σa ˆΣ"
REFERENCES,0.5603015075376885,"1
2a
 1"
REFERENCES,0.5628140703517588,"2 
≤εa = 

 
"
REFERENCES,0.5653266331658291,"inf
γ(εa −tr

ˆΣa

) + γ2 tr

(γI −υ(I −V V ⊤))−1 ˆΣa

+ τ"
REFERENCES,0.5678391959798995,"s.t.

γI −υ(I −V V ⊤)
γˆµa
γˆµ⊤
a
γ∥ˆµa∥2
2 + τ"
REFERENCES,0.5703517587939698,"
⪰0,
γI ≻υ(I −V V ⊤),
γ ≥0,"
REFERENCES,0.5728643216080402,"where the last equality follows from Nguyen (2019, Lemma 3.22). By the Woodbury matrix inver-
sion, we have
(γI −υ(I −V V ⊤))−1 = γ−1I −
υ
γ(υ −γ)(I −V V ⊤)."
REFERENCES,0.5753768844221105,"Moreover, using the Schur complement, the semideﬁnite constraint is equivalent to"
REFERENCES,0.5778894472361809,"γ∥ˆµa∥2
2 + τ ≥γ2ˆµ⊤
a (γI −υ(I −V V ⊤))−1ˆµa,"
REFERENCES,0.5804020100502513,"which implies that at optimality, we have"
REFERENCES,0.5829145728643216,"τ =
υγ
γ −υ ˆµ⊤
a (I −V V ⊤)ˆµa."
REFERENCES,0.585427135678392,"At the same time, the constraint γI ≻υ(I −V V ⊤) is equivalent to γ > υ. Combining all previous
equations, we have"
REFERENCES,0.5879396984924623,"sup
Qa:W(Qa,ˆPa)≤εa
υEQa[ℓ(V, X)] =
inf
γ>max{0,υ} γεa +
γυ
γ −υ

Id −V V ⊤, ˆ
Ma

."
REFERENCES,0.5904522613065326,The dual optimal solution γ⋆is given by γ⋆=
REFERENCES,0.592964824120603,"






"
REFERENCES,0.5954773869346733,"





 υ  1 +"
REFERENCES,0.5979899497487438,"r
Id−V V ⊤, ˆ
Ma εa !"
REFERENCES,0.6005025125628141,"if υ ≥0, υ  1 −"
REFERENCES,0.6030150753768844,"r
Id−V V ⊤, ˆ
Ma εa !"
REFERENCES,0.6055276381909548,"if υ < 0 and

Id −V V ⊤, ˆ
Ma

≥εa,"
REFERENCES,0.6080402010050251,"0
if υ < 0 and

Id −V V ⊤, ˆ
Ma

< εa."
REFERENCES,0.6105527638190955,"Note that γ⋆≥max{0, υ} in all the cases. Therefore, we have"
REFERENCES,0.6130653266331658,"sup
Qa:W(Qa,ˆPa)≤εa
υEQa[ℓ(V, X)] ="
REFERENCES,0.6155778894472361,"





"
REFERENCES,0.6180904522613065,"




"
REFERENCES,0.6206030150753769,"υ
√εa +
q
Id −V V ⊤, ˆ
Ma
2
if υ ≥0,"
REFERENCES,0.6231155778894473,"υ
√εa −
q
Id −V V ⊤, ˆ
Ma
2
if υ < 0 and

Id −V V ⊤, ˆ
Ma

≥εa,"
REFERENCES,0.6256281407035176,"0
if υ < 0 and

Id −V V ⊤, ˆ
Ma

< εa."
REFERENCES,0.628140703517588,This completes the proof.
REFERENCES,0.6306532663316583,Published as a conference paper at ICLR 2022
REFERENCES,0.6331658291457286,We are now ready to prove Theorem 3.2.
REFERENCES,0.635678391959799,"Proof of Theorem 3.2. By expanding the absolute value, problem (4) is equivalent to"
REFERENCES,0.6381909547738693,"min
V ∈Rd×k,V ⊤V =Ik
max{J0(V ), J1(V )},"
REFERENCES,0.6407035175879398,"where for each (a, a′) ∈{(0, 1), (1, 0)}, we can re-express Ja as"
REFERENCES,0.6432160804020101,"Ja(V ) =
sup
Qa:W(Qa,ˆPa)≤εa
(ˆpa + λ)EQa[ℓ(V, X)] +
sup
Qa′:W(Qa′,ˆPa′)≤εa′
(ˆpa′ −λ)EQa′[ℓ(V, X)]"
REFERENCES,0.6457286432160804,"Using Proposition 3.3 to reformulate the two individual supremum problems, we have"
REFERENCES,0.6482412060301508,"Ja(V ) = (ˆpa + λ)εa + 2|ˆpa + λ|
q"
REFERENCES,0.6507537688442211,"εa

Id −V V ⊤, ˆ
Ma

+ (ˆpa + λ)

Id −V V ⊤, ˆ
Ma"
REFERENCES,0.6532663316582915,"+ (ˆpa′ −λ)εa′ + 2|ˆpa′ −λ|
q"
REFERENCES,0.6557788944723618,"εa′
Id −V V ⊤, ˆ
Ma′
+ (ˆpa′ −λ)

Id −V V ⊤, ˆ
Ma′
."
REFERENCES,0.6582914572864321,"By deﬁning the necessary parameters κ, θ, ϑ and C as in the statement of the theorem, we arrive at
the postulated result."
REFERENCES,0.6608040201005025,"A.3
PROOFS OF SECTION 4"
REFERENCES,0.6633165829145728,"Proof of Lemma 4.1. Let aU ∈arg maxa∈{0,1} Fa(U) and a′
U = 1 −aU. Then, an Euclidean
subgradient of F is given by"
REFERENCES,0.6658291457286433,"∇F(U) =
θaU
q
UU ⊤, ˆ
MaU
 ˆ
MaU U +
ϑa′
U
q
UU ⊤, ˆ
Ma′
U
 ˆ
Ma′
U U + 2CaU U ∈Rd×(d−k)."
REFERENCES,0.6683417085427136,The tangent space of the Stiefel manifold M at U is given by
REFERENCES,0.6708542713567839,"TUM = {∆∈Rd×(d−k) : ∆⊤U + U ⊤∆= 0},"
REFERENCES,0.6733668341708543,"whose orthogonal projection (Absil et al., 2007, Example 3.6.2) can be computed explicitly via"
REFERENCES,0.6758793969849246,ProjTUM(D) = (Id −UU ⊤)D + 1
REFERENCES,0.678391959798995,"2U(U ⊤D −D⊤U),
D ∈Rd×(d−k)."
REFERENCES,0.6809045226130653,"Therefore, a Riemannian subgradient of F at any point U ∈M is given by"
REFERENCES,0.6834170854271356,gradF(U) = ProjTUM(∇F(U))
REFERENCES,0.6859296482412061,= (Id −UU ⊤) 
REFERENCES,0.6884422110552764,"
θaU
q
UU ⊤, ˆ
MaU
 ˆ
MaU U +
ϑa′
U
q
UU ⊤, ˆ
Ma′
U
 ˆ
Ma′
U U + 2CaU U  ."
REFERENCES,0.6909547738693468,"In the last line, we have used the fact that, if D = SU for some symmetric matrix S, then"
REFERENCES,0.6934673366834171,U ⊤D −D⊤U = U ⊤SU −U ⊤S⊤U = 0.
REFERENCES,0.6959798994974874,This completes the proof.
REFERENCES,0.6984924623115578,The proof of Lemma 4.2 relies on the following preliminary result.
REFERENCES,0.7010050251256281,"Lemma A.1. Let M ∈R(d−k)×(d−k) be a positive deﬁnite matrix. Then,

UU ⊤, M

−

U ′U ′⊤, M
 ≤2
√"
REFERENCES,0.7035175879396985,"d −kσmax(M)∥U −U ′∥F
∀U, U ′ ∈M,
(10) and"
REFERENCES,0.7060301507537688,"q
UU ⊤, M

−
q
U ′U ′⊤, M
 ≤
σmax(M)
p"
REFERENCES,0.7085427135678392,"σmin(M)
∥U −U ′∥F
∀U, U ′ ∈M,
(11)"
REFERENCES,0.7110552763819096,where σmax(M) and σmin(M) denote the maximum and minimum eigenvalues of the matrix M.
REFERENCES,0.7135678391959799,Published as a conference paper at ICLR 2022
REFERENCES,0.7160804020100503,"Proof of Lemma A.1. For inequality (10),

UU ⊤, M

−

U ′U ′⊤, M
 ≤

UU ⊤, M

−

UU ′⊤, M
 +

UU ′⊤, M

−

U ′U ′⊤, M"
REFERENCES,0.7185929648241206,"≤

U, M(U −U ′)
 +

U ′, M(U −U ′)"
REFERENCES,0.7211055276381909,"≤∥U∥F ∥M(U −U ′)∥F + ∥U ′∥F ∥M(U −U ′)∥F = 2
√"
REFERENCES,0.7236180904522613,d −kσmax∥U −U ′∥F .
REFERENCES,0.7261306532663316,"For inequality (11), we ﬁrst note that the function x 7→√x is 1/(2√xmin)-Lipschitz on [xmin, +∞)
and that

UU ⊤, M

≥(d −k)σmin(M)
∀U ∈M.
Therefore,"
REFERENCES,0.7286432160804021,"q
UU ⊤, M

−
q
U ′U ′⊤, M
 ≤
1"
P,0.7311557788944724,"2
p"
P,0.7336683417085427,(d −k)σmin(M)
P,0.7361809045226131,"UU ⊤, M

−

U ′U ′⊤, M"
P,0.7386934673366834,"≤
σmax(M)
p"
P,0.7412060301507538,"σmin(M)
∥U −U ′∥F ,"
P,0.7437185929648241,where the last inequality follows from (10). This completes the proof.
P,0.7462311557788944,We are now ready to prove Lemma 4.2.
P,0.7487437185929648,"Proof of Lemma 4.2. Let U, U ′ ∈M be two arbitrary points. We have"
P,0.7512562814070352,|F(U) −F(U ′)|
P,0.7537688442211056,"= |max {F0(U), F1(U)} −max {F0(U ′), F1(U ′)}|"
P,0.7562814070351759,"≤max
a∈{0,1} |Fa(U) −Fa(U ′)|"
P,0.7587939698492462,"≤max
a∈{0,1} max 
"
P,0.7613065326633166,"θa
σmax( ˆ
Ma)
q"
P,0.7638190954773869,"σmin( ˆ
Ma)
, ϑ1−a
σmax( ˆ
M1−a)
q"
P,0.7663316582914573,"σmin( ˆ
M1−a)
, 2
√"
P,0.7688442211055276,"d −kσmax(Ca) 
"
P,0.7713567839195979,"∥U −U ′∥F ,"
P,0.7738693467336684,"where the last inequality follows from the deﬁnition of Fa and Lemma A.1. This completes the
proof."
P,0.7763819095477387,"Proof of Theorem 4.3. The proof follows from the fact that F is convex on the Euclidean space
Rd×(d−k), Lemma 4.2 and Li et al. (2021, Theorem 2) (and the remarks following it)."
P,0.7788944723618091,"B
EXTENSION TO NON-BINARY SENSITIVE ATTRIBUTES"
P,0.7814070351758794,"The main paper focuses on the case of a binary sensitive attribute with A = {0, 1}. In this appendix,
we extend our approach to the case when the sensitive attribute is non-binary. Concretely, we sup-
pose that the sensitive attribute A can take on any of the m possible values from 1 to m. In other
words, the attribute space now becomes A = {1, . . . , m}.
Deﬁnition B.1 (Generalized unfairness measure). The generalized unfairness measure is deﬁned as
the maximum pairwise unfairness measure, that is,"
P,0.7839195979899497,"Umax(V, Q) ≜
max
(a,a′)∈A×A |EQ[ℓ(V, X)|A = a] −EQ[ℓ(V, X)|A = a′]|."
P,0.7864321608040201,"Notice that if A = {0, 1}, then Umax ≡U recovers the unfairness measure for binary sensitive
attribute deﬁned in Section 2.2. We now consider the following generalized fairness-aware PCA
problem
min
V ∈Rd×k,V ⊤V =Ik
sup
Q∈B(ˆP)
EQ[ℓ(V, X)] + λUmax(V, Q).
(12)"
P,0.7889447236180904,"Here we recall that the ambiguity set B(ˆP) is deﬁned in (5). The next theorem provides the refor-
mulation of (12)."
P,0.7914572864321608,Published as a conference paper at ICLR 2022
P,0.7939698492462312,"Theorem B.2 (Reformulation of non-binary fairness-aware PCA). Suppose that for any a ∈A,
either of the following two conditions holds:"
P,0.7964824120603015,"(i) Marginal probability bounds: 0 ≤λ ≤ˆpa,"
P,0.7989949748743719,"(ii) Eigenvalue bounds: the empirical second moment matrix ˆ
Ma =
1
Na
P"
P,0.8015075376884422,"i∈Ia ˆxiˆx⊤
i satisﬁes
Pd−k
j=1 σj( ˆ
Ma) ≥εa, where σj( ˆ
Ma) is the j-th smallest eigenvalues of ˆ
Ma."
P,0.8040201005025126,Then problem (12) is equivalent to
P,0.8065326633165829,"min
V ∈Rd×k,V ⊤V =Ik
max
a̸=a′ (X"
P,0.8090452261306532,"b∈A
2ca,a′,b
q"
P,0.8115577889447236,"εb⟨Id −V V ⊤, ˆ
Mb⟩+ λ⟨Id −V V ⊤, ˆ
Ma −ˆ
Ma′⟩+ λ(εa −εa′) ) ,"
P,0.8140703517587939,"where the parameter ca,a′,b admits values"
P,0.8165829145728644,"ca,a′,b = 
 "
P,0.8190954773869347,"ˆpa + λ
if b = a,
|ˆpa′ −λ|
if b = a′,
ˆpb
otherwise."
P,0.821608040201005,"Proof of Theorem B.2. For simplicity, we let E(V, Q, b) = EQ[ℓ(V, X)|A = b]. Then, the objective
function of problem (12) can be re-written as"
P,0.8241206030150754,"sup
Q∈B(ˆP)
EQ[ℓ(V, X)] + λUmax(V, Q)"
P,0.8266331658291457,"= sup
Q∈B(ˆP) X"
P,0.8291457286432161,"b∈A
ˆpbE(V, Q, b) + λ max
a̸=a′ {E(V, Q, a) −E(V, Q, a′)}"
P,0.8316582914572864,"= max
a̸=a′ 
  X"
P,0.8341708542713567,"b̸=a,a′
sup
W(Qb,ˆPb)≤εb
ˆpbE(V, Qb, b) +
sup
W(Qa,ˆPa)≤εa
(ˆpa + λ)E(V, Qa, a) +
sup
W(Qa′,ˆPa′)≤εa′
(ˆpa′ −λ)E(V, Qa′, a′) 
 "
P,0.8366834170854272,"= max
a̸=a′ ( X"
P,0.8391959798994975,"b̸=a,a′
ˆpb q"
P,0.8417085427135679,"⟨Id −V V ⊤, ˆ
Mb⟩+ √εb"
P,0.8442211055276382,"2
+ (ˆpa + λ)
q"
P,0.8467336683417085,"⟨Id −V V ⊤, ˆ
Ma⟩+ √εa 2"
P,0.8492462311557789,"+ (ˆpa′ −λ)
q"
P,0.8517587939698492,"⟨Id −V V ⊤, ˆ
Ma′⟩+ sgn(ˆpa′ −λ)√εa′
2 )"
P,0.8542713567839196,"= max
a̸=a′ ( X"
P,0.8567839195979899,"b∈A
ˆpb

⟨Id −V V ⊤, ˆ
Mb⟩+ εb

+
X"
P,0.8592964824120602,"b∈A
2ca,a′,b
q"
P,0.8618090452261307,"εb⟨Id −V V ⊤, ˆ
Mb⟩"
P,0.864321608040201,"+ λ

⟨Id −V V ⊤, ˆ
Ma −ˆ
Ma′⟩+ εa −εa′
 ) ,"
P,0.8668341708542714,"where the ﬁrst equality follows from the deﬁnition of Umax(V, Q) and E(V, Q, b), the second from
the deﬁnition (5) of the ambiguity set B(ˆP), the third from Proposition 3.3 and the fourth from the
deﬁnition of ca,a′,b. Noting that the ﬁrst sum in the above maximization is independent of a and a′,
the proof is completed."
P,0.8693467336683417,"Theorem 12 indicates that if the sensitive attribute admits ﬁnite values, then the distributionally
robust fairness-aware PCA problem using an Umax unfairness measure can be reformulated as an
optimization problem over the Stiefel manifold, where the objective function is a pointwise maxi-
mization of ﬁnite number of individual functions. It is also easy to see that each individual function
can be reparametrized using U, and the Riemannian gradient descent algorithm in Section 4 can be
adapted to solve for the optimal solution. The details on the algorithm are omitted."
P,0.871859296482412,Published as a conference paper at ICLR 2022
P,0.8743718592964824,"C
INFORMATION ON DATASETS"
P,0.8768844221105527,"We summarize here the number of observations, dimensions, and the sensitive attribute of the data
sets. For further information about the data sets and pre-processing steps, please refer to Samadi
et al. (2018) for Default Credit and Labeled Faces in the Wild (LFW) data sets, and Olfat & Aswani
(2019) for others. For each data set, we further remove columns with too small standard deviation
(≤1e−5) as they do not signiﬁcantly affect the results, and ones with too large standard deviation
(≥1000) which we consider as unreliable features."
P,0.8793969849246231,"Table 2: Number of observations N, dimensions d, and sensitive attribute A of datasets used in this
paper. (y - yes, n - no)"
P,0.8819095477386935,"Default Credit
Biodeg
E. Coli
Energy
German Credit
N
30000
1055
333
768
1000
d
22
40
7
8
48 A"
P,0.8844221105527639,"Education
(high/low)"
P,0.8869346733668342,"Ready Biodegradable
(y/n)"
P,0.8894472361809045,"isCytoplasm
(y/n)"
P,0.8919597989949749,"Orientation< 4
(y/n)"
P,0.8944723618090452,"A13 ≥200DM
(y/n)
Image
Letter
Magic
Parkinsons
SkillCraft
N
660
20000
19020
5875
3337
d
18
16
10
20
17
A
class (path/grass)
Vowel (y/n)
classIsGamma (y/n)
Sex (male/female)
Age> 20 (y/n)
Statlog
Steel
Taiwan Credit
Wine Quality
LFW
N
3071
1941
29623
6497
4000
d
36
24
22
11
576 A"
P,0.8969849246231156,"RedSoil
(vsgrey/dampgrey)
FaultOther (y/n)
Sex (male/female)
isWhite (y/n)
Sex (male/female)"
P,0.8994974874371859,"D
ADDITIONAL RESULTS"
P,0.9020100502512562,"D.1
DETAIL PERFORMANCES"
P,0.9045226130653267,"Table 3 shows the performances of four examined methods with two criteria ABDiff. and ARE. It is
clear that our method achieves the best results over all 14 datasets w.r.t. ABDiff., and 7 datasets on
ARE., which is equal to the number of datasets FairPCA out-perform others."
P,0.907035175879397,"Table 4 complements Table 1 from the main text, from which we can see that two versions of CFPCA
out-perform others over all datasets w.r.t. △FLin, which is the criteria they optimize for."
P,0.9095477386934674,Table 3: In-sample performance over two criteria
P,0.9120603015075377,"RFPCA
FairPCA
CFPCA-Mean Con.
CFPCA - Both Con.
Dataset
ABDiff.
ARE.
ABDiff.
ARE.
ABDiff.
ARE.
ABDiff.
ARE.
Default Credit
0.9457
9.9072
1.5821
9.9049
0.9949
10.5164
3.2827
21.4523
Biodeg
9.4093
23.1555
14.2587
23.8227
15.5545
26.6540
24.8706
39.8737
E. Coli
0.5678
1.4804
0.9191
2.0840
0.9539
2.8360
4.5225
5.2155
Energy
0.0094
0.2295
0.0153
0.2273
0.2658
2.7893
0.2136
7.8768
German Credit
1.6265
40.1512
2.9824
40.3393
2.6109
40.1860
2.8741
47.1006
Image
0.1320
5.0924
0.7941
9.0437
0.6910
13.4491
3.0118
18.0000
Letter
0.1121
7.4088
1.2560
7.4375
0.4572
8.7764
0.5301
15.2234
Magic
1.7405
3.8766
2.8679
3.3500
5.5405
4.1938
8.7963
8.9695
Parkinsons
0.1238
5.0471
0.6702
4.8760
3.9470
5.9379
17.8122
19.9788
SkillCraft
0.4231
8.1569
0.5576
8.1096
0.7156
9.7755
0.9334
15.8245
Statlog
0.1972
3.0588
0.3315
7.9980
0.3857
10.9358
13.0725
35.9214
Steel
0.6943
11.0396
1.8015
10.7653
2.8933
14.5680
1.9322
23.9906
Taiwan Credit
1.1516
10.5136
1.3362
10.4478
1.3158
12.5867
2.2720
21.4365
Wine Quality
0.1125
4.1491
0.1705
5.8999
1.1359
5.9117
2.5852
9.8959
LFW
0.4147
7.5137
0.5300
7.5127
fail to converge"
P,0.914572864321608,"Adjustment for the LFW dataset. To demonstrate the efﬁcacy of our method on high-dimensional
data sets, we also do experiments on a subset of 2000 faces for each of male and female group (4000"
P,0.9170854271356784,Published as a conference paper at ICLR 2022
P,0.9195979899497487,Table 4: Out-of-sample performance measured using the △FLin criterion.
P,0.9221105527638191,"RFPCA
FairPCA
CFPCA-Mean Con.
CFPCA - Both Con.
Default Credit
0.1596
0.2236
0.0574
0.0413
Biodeg
0.4892
0.4759
0.2014
0.1371
E. Coli
0.8556
0.7444
0.4455
0.2532
Energy
0.0580
0.0554
0.0502
0.0736
German Credit
0.1997
0.1737
0.1408
0.1093
Image
0.9996
0.9498
0.1874
0.2013
Letter
0.0954
0.0942
0.0556
0.0455
Magic
0.2195
0.2531
0.1561
0.0882
Parkinson’s
0.1459
0.1061
0.1805
0.0480
SkillCraft
0.1126
0.1141
0.0721
0.0742
Statlog
0.9804
0.6309
0.1359
0.0669
Steel
0.2288
0.2240
0.1418
0.0875
Taiwan Credit
0.0604
0.0535
0.0391
0.0370
Wine Quality
0.9699
0.4639
0.2192
0.0817"
P,0.9246231155778895,"in total) from LFW dataset,7 all images are rescaled to resolution 24 × 24 (dimensions d = 576).
The experiment follows the same procedure in Section 5, with reducing the number of iterations
to 500 for both RFPCA and FairPCA and 2-fold cross validation, the results are averaged over
10 train-test simulations. Due to the high dimension of the input, the implementation of Olfat &
Aswani (2019) fails to return any result."
P,0.9271356783919598,7 https://github.com/samirasamadi/Fair-PCA
P,0.9296482412060302,Published as a conference paper at ICLR 2022
P,0.9321608040201005,"D.2
VISUALIZATION"
P,0.9346733668341709,"D.2.1
EFFECTS OF THE AMBIGUITY SET RADIUS"
P,0.9371859296482412,"We examine the change of the model’s performance with respect to the change of the radius of the
ambiguity sets. To generate the toy data (also used for Figure 1), we use two 2-dimensional Gaussian
distributions to represent two groups of a sensitive attribute, A = 0 and A = 1, or groups 0 and 1
for simplicity. The two distributions both have the mean at (0, 0) and covariance matrices for group
0 and 1 are

4.0
0
0
0.2"
P,0.9396984924623115,"
and

0.2
0.4
0.4
3.0 
,"
P,0.9422110552763819,"respectively. For the test set, the number of samples is 8000 for group 0 and 4000 for group 1, while
for the training set, we have 200 for group 0 and 100 for group 1. We average the results over 100
simulations, for each simulation, the test data is ﬁxed, the training data is randomly generated with
the number of samples mentioned above. The projections are learned on training data and measured
on test data by the summation of ARE. and ABDiff. We ﬁxed λ = 0.1, which is not too small for
achieving fair projections, and not too large to clearly observe the effects of ε, and we also ﬁxed
ε0 for better visualization. Note that we still compute ε1 = α/√N1 in which, α is tested with 100
values evenly spaced in [0, 10]."
P,0.9447236180904522,"The experiment results are visualized in Figure 4. The result suggests that increasing the ambiguity
set radius can improve the overall model’s performance. This justiﬁes the beneﬁt of adding distribu-
tional robustness to the fairness-aware PCA model. After a saturation point, a too large radius can
lessen the role of empirical data, and the model prioritizes a more extreme distribution that is far
from the target distribution, which causes the reduction in the model’s performance on target data."
P,0.9472361809045227,"Figure 4: Performance changes w.r.t. the ambiguity set’s radius. The solid line is the average over
100 simulations, and the shade represent the 1-standard deviation range."
P,0.949748743718593,Published as a conference paper at ICLR 2022
P,0.9522613065326633,"D.2.2
PARETO CURVES"
P,0.9547738693467337,"Figures 5 and 6 plot the Pareto frontier for two datasets (Biodeg and German Credit) with 3 principal
components. One can observe that RFPCA produces points that dominate other methods based on
the trade-off between ARE. and ABDiff."
P,0.957286432160804,"Figure 5: Pareto curves on Biodeg
dataset (all data) with 3 principal components"
P,0.9597989949748744,"Figure 6: Pareto curves on German Credit
dataset (all data) with 3 principal components"
P,0.9623115577889447,Published as a conference paper at ICLR 2022
P,0.964824120603015,"D.2.3
PERFORMANCE WITH DIFFERENT PRINCIPAL COMPONENTS"
P,0.9673366834170855,We collect here the reconstruction errors for different numbers of principal components.
P,0.9698492462311558,"Figure 7: Subgroup average error
with different k on Default Credit dataset"
P,0.9723618090452262,"Figure 8: Subgroup average error
with different k on Default Credit dataset"
P,0.9748743718592965,"Figure 9: Subgroup average error
with different k on E. Coli dataset"
P,0.9773869346733668,"Figure 10: Subgroup average error
with different k on E. Coli dataset"
P,0.9798994974874372,Published as a conference paper at ICLR 2022
P,0.9824120603015075,"Figure 11: Subgroup average error
with different k on Magic dataset"
P,0.9849246231155779,"Figure 12: Subgroup average error
with different k on Magic dataset"
P,0.9874371859296482,"Figure 13: Subgroup average error
with different k on Steel dataset"
P,0.9899497487437185,"Figure 14: Subgroup average error
with different k on Steel dataset"
P,0.992462311557789,Published as a conference paper at ICLR 2022
P,0.9949748743718593,"Figure 15: Subgroup average error
with different k on Wine Quality dataset"
P,0.9974874371859297,"Figure 16: Subgroup average error
with different k on Wine Quality dataset"
