Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0006993006993006993,"Classifiers trained with Empirical Risk Minimization (ERM) tend to rely on at-
1"
ABSTRACT,0.0013986013986013986,"tributes that have high spurious correlation with the target. This can degrade the
2"
ABSTRACT,0.002097902097902098,"performance on underrepresented (or minority) groups that lack these attributes,
3"
ABSTRACT,0.002797202797202797,"posing significant challenges for both out-of-distribution generalization and fair-
4"
ABSTRACT,0.0034965034965034965,"ness objectives. Many studies aim to improve robustness to spurious correlation,
5"
ABSTRACT,0.004195804195804196,"yet nearly all require group annotation for training and/or model selection. This
6"
ABSTRACT,0.0048951048951048955,"constrains their applicability in situations where the nature of the spurious correla-
7"
ABSTRACT,0.005594405594405594,"tion is not known, or when group labels for certain spurious attributes are either
8"
ABSTRACT,0.006293706293706294,"insufficient or completely absent. To meet the demand for effectively enhancing the
9"
ABSTRACT,0.006993006993006993,"model robustness under minimal assumptions about group annotation, we propose
10"
ABSTRACT,0.007692307692307693,"Environment-based Validation and Loss-based Sampling (EVaLS). It uses the losses
11"
ABSTRACT,0.008391608391608392,"from a trained model to construct a balanced dataset of high-loss and low-loss
12"
ABSTRACT,0.00909090909090909,"samples in which the training data group imbalance is mitigated. This results in
13"
ABSTRACT,0.009790209790209791,"a significant robustness to group shifts when equipped with a simple mechanism
14"
ABSTRACT,0.01048951048951049,"of last layer retraining. Furthermore, by utilizing environment inference methods
15"
ABSTRACT,0.011188811188811189,"for creating diverse environments with correlation shifts, EVaLS can potentially
16"
ABSTRACT,0.011888111888111888,"eliminate the need for group annotation in the validation data. In such a context, the
17"
ABSTRACT,0.012587412587412588,"worst environment accuracy acts as a reliable surrogate throughout the retraining
18"
ABSTRACT,0.013286713286713287,"process for tuning hyperparameters and finding a model that performs well across
19"
ABSTRACT,0.013986013986013986,"diverse group shifts. EVaLS effectively achieves group robustness, showing that
20"
ABSTRACT,0.014685314685314685,"group annotation is not necessary even for validation. It is a fast, straightforward,
21"
ABSTRACT,0.015384615384615385,"and effective approach that reaches near-optimal worst group accuracy without
22"
ABSTRACT,0.016083916083916083,"needing group annotations, marking a new chapter in the robustness of trained
23"
ABSTRACT,0.016783216783216783,"models against spurious correlation.
24"
INTRODUCTION,0.017482517482517484,"1
Introduction
25"
INTRODUCTION,0.01818181818181818,"Training deep learning models using Empirical Risk Minimization (ERM) on a dataset, poses the
26"
INTRODUCTION,0.01888111888111888,"risk of relying on spurious correlation. These are correlations between certain patterns in the
27"
INTRODUCTION,0.019580419580419582,"training dataset and the target (e.g., the class label in a classification task) despite lacking any causal
28"
INTRODUCTION,0.02027972027972028,"relationship. Learning such correlations as shortcuts can negatively impact the models’ accuracy on
29"
INTRODUCTION,0.02097902097902098,"minority groups that do not contain the spurious patterns associated with the target [1, 2]. This problem
30"
INTRODUCTION,0.021678321678321677,"leads to concerns regarding fairness [3], and can also cause a marked reduction in the performance.
31"
INTRODUCTION,0.022377622377622378,"This occurs particularly when minority groups, which are underrepresented during training, become
32"
INTRODUCTION,0.023076923076923078,"overrepresented at the time of testing, as a result of shifts within the subpopulations [4]. Hence,
33"
INTRODUCTION,0.023776223776223775,"ensuring robustness to group shifts and developing methods that improve worst group accuracy
34"
INTRODUCTION,0.024475524475524476,"(WGA) is crucial for achieving both fairness and robustness in the realm of deep learning.
35"
INTRODUCTION,0.025174825174825177,"Many studies have proposed solutions to address this challenge. A promising line of research
36"
INTRODUCTION,0.025874125874125874,"focuses on increasing the contribution of minority groups in the model’s training [1, 5–7]. A strong
37"
INTRODUCTION,0.026573426573426574,"assumption that is considered by some previous works is having access to group annotations for
38"
INTRODUCTION,0.02727272727272727,"training or fully/partially fine-tuning a pretrained model [8, 7, 1]. The study by Kirichenko et al. [1]
39"
INTRODUCTION,0.027972027972027972,"proposes that retraining the last layer of a model on a dataset which is balanced in terms of group
40"
INTRODUCTION,0.028671328671328673,"annotation can effectively enhance the model’s robustness against shifts in spurious correlation. While
41"
INTRODUCTION,0.02937062937062937,"these works have shown tremendous robustness performance, their assumption for the availability of
42"
INTRODUCTION,0.03006993006993007,"group annotation restricts their usage.
43"
INTRODUCTION,0.03076923076923077,"In many real-world applications, the process of labeling samples according to their respective groups
44"
INTRODUCTION,0.03146853146853147,"can be prohibitively expensive, and sometimes impractical, especially when all minority groups
45"
INTRODUCTION,0.032167832167832165,"may not be identifiable beforehand. A widely adopted strategy in these situations involves the
46"
INTRODUCTION,0.032867132867132866,"indirect inference of various groups, followed by the training of models using a loss function that is
47"
INTRODUCTION,0.033566433566433566,"balanced across groups [5, 9, 10, 4]. The loss value of the model or its similar metrics is a popular
48"
INTRODUCTION,0.03426573426573427,"signal for recognizing minority groups [5, 9–11]. While most of these techniques necessitate full
49"
INTRODUCTION,0.03496503496503497,"training of a model, Qiu et al. [9] attempt to adapt the DFR method [1] with the aim of preserving
50"
INTRODUCTION,0.03566433566433566,"computational efficiency while simultaneously improving robustness to group shift. However, this
51"
INTRODUCTION,0.03636363636363636,"method still requires group annotations of the validation set for model selection and hyperparameter
52"
INTRODUCTION,0.03706293706293706,"tuning. Consequently, this constitutes a restrictive assumption when adequate annotations for certain
53"
INTRODUCTION,0.03776223776223776,"groups are not supplied. It also applies to situations where some shortcut attributes are completely
54"
INTRODUCTION,0.038461538461538464,"unidentified.
55"
INTRODUCTION,0.039160839160839164,"In this study, we present a novel strategy that effectively mitigates reliance on spurious correlation,
56"
INTRODUCTION,0.03986013986013986,"completely eliminating the need for group annotations during both training and retraining. More
57"
INTRODUCTION,0.04055944055944056,"interestingly, we provide empirical evidence indicating that group annotations are not necessary,
58"
INTRODUCTION,0.04125874125874126,"even for model selection. We show that assembling a diverse collection of environments for model
59"
INTRODUCTION,0.04195804195804196,"selection, which reflect group shifts can serve as an effective alternative approach. Our proposed
60"
INTRODUCTION,0.04265734265734266,"method, Environment-based Validation and Loss-based Sampling (EVaLS), is a technique that
61"
INTRODUCTION,0.043356643356643354,"strengthens the robustness of trained models against spurious correlation, all without relying on group
62"
INTRODUCTION,0.044055944055944055,"annotations. EVaLS is pioneering in its ability to eliminate the need for group annotations at every
63"
INTRODUCTION,0.044755244755244755,"phase, including the model selection step. EVaLS posits that in the absence of group annotations, a
64"
INTRODUCTION,0.045454545454545456,"set of environments showcasing group shifts is sufficient. Worst Environment Accuracy (WEA) could
65"
INTRODUCTION,0.046153846153846156,"then be utilized for model selection. Our findings demonstrate that utilizing environment inference
66"
INTRODUCTION,0.04685314685314685,"methods [12], or even dividing the validation data based on the predictions of a random linear layer
67"
INTRODUCTION,0.04755244755244755,"atop a trained model’s feature space can markedly enhance group robustness. Figure 1 demonstrates
68"
INTRODUCTION,0.04825174825174825,"the overall procedure of the main parts of EVaLS.
69"
INTRODUCTION,0.04895104895104895,"Our empirical observations support prior research which suggests that high-loss data points in a
70"
INTRODUCTION,0.04965034965034965,"trained model may signal the presence of minority groups [5, 9, 10]. Our method, EVaLS, evenly
71"
INTRODUCTION,0.05034965034965035,"selects from both high-loss and low-loss data to form a balanced dataset that is used for last-layer
72"
INTRODUCTION,0.05104895104895105,"retraining. We offer theoretical explanations for the effectiveness of this approach in addressing group
73"
INTRODUCTION,0.05174825174825175,"imbalances, and experimentally show the superiority of our efficient solution to the previous strategies.
74"
INTRODUCTION,0.05244755244755245,"Comprehensive experiments conducted on spurious correlation benchmarks such as CelebA [13],
75"
INTRODUCTION,0.05314685314685315,"Waterbirds [7], and UrbanCars [14], demonstrate that EVaLS achieves optimal accuracy. Moreover,
76"
INTRODUCTION,0.05384615384615385,"when group annotations are accessible solely for model selection, our approach, EVaLS-GL, exhibits
77"
INTRODUCTION,0.05454545454545454,"enhanced performance against various distribution shifts, including attribute imbalance, as seen in
78"
INTRODUCTION,0.05524475524475524,"MultiNLI [15], and class imbalance, exemplified by CivilComments [16]. We further present a
79"
INTRODUCTION,0.055944055944055944,"new dataset, Dominoes Colored-MNIST-FashionMNIST, which depicts a situation featuring multiple
80"
INTRODUCTION,0.056643356643356645,"independent shortcuts, that group annotations are only available for part of them (see Section 2.2). In
81"
INTRODUCTION,0.057342657342657345,"this setting, we show that strategies with lower levels of group supervision are paradoxically more
82"
INTRODUCTION,0.05804195804195804,"effective in mitigating the reliance on both known and unknown shortcuts.
83"
INTRODUCTION,0.05874125874125874,"The main contributions of this paper are summarized as follows:
84"
INTRODUCTION,0.05944055944055944,"• We present EVaLS, a simple yet effective approach that enhances model robustness against
85"
INTRODUCTION,0.06013986013986014,"spurious correlation without relying on ground-truth group annotations.
86"
INTRODUCTION,0.06083916083916084,"• We offer both theoretical and practical insights on how balanced sampling from high-loss and
87"
INTRODUCTION,0.06153846153846154,"low-loss samples can result in a dataset in which the group imbalance is notably mitigated.
88"
INTRODUCTION,0.062237762237762236,"• Using simple environment inference techniques, EVaLS leverages worst environment accu-
89"
INTRODUCTION,0.06293706293706294,"racy as a reliable indicator for model selection.
90"
INTRODUCTION,0.06363636363636363,"• EVaLS attains near-optimal worst group accuracies or even exceeds them in spurious
91"
INTRODUCTION,0.06433566433566433,"correlation benchmarks, all with zero group annotations.
92"
INTRODUCTION,0.06503496503496503,"• When group annotations are available for model selection, EVaLS delivers state-of-the-art
93"
INTRODUCTION,0.06573426573426573,"performance across a variety of subpopulation shift benchmarks.
94"
INTRODUCTION,0.06643356643356643,"• We introduce a new dataset consisting of two spurious features in which partial supervision
95"
INTRODUCTION,0.06713286713286713,"may negatively impact the performance of the underrepresented groups.
96"
PRELIMINARIES,0.06783216783216783,"2
Preliminaries
97"
PROBLEM SETTING,0.06853146853146853,"2.1
Problem Setting
98"
PROBLEM SETTING,0.06923076923076923,"We assume a general setting of a supervised learning problem with distinct data partitions Dtr for
99"
PROBLEM SETTING,0.06993006993006994,"training, Dval for validation, and Dtest for final evaluation. Each dataset comprises a set of paired
100"
PROBLEM SETTING,0.07062937062937064,"samples (x, y), where x ∈X represents the data and y ∈Y denotes the corresponding labels.
101"
PROBLEM SETTING,0.07132867132867132,"Conventionally, Dtr, Dval, and Dtest are assumed to be uniformly sampled from the same distribution.
102"
PROBLEM SETTING,0.07202797202797202,"However, this idealized assumption does not hold in many real-world problems where distribution
103"
PROBLEM SETTING,0.07272727272727272,"shift is inevitable. In this context, we consider the sub-population shift problem [4]. In a general
104"
PROBLEM SETTING,0.07342657342657342,"form of this setting, it is assumed that data samples consist of different groups Gi, where each
105"
PROBLEM SETTING,0.07412587412587412,"group comprises samples that share a property. More specifically, the overall data distribution
106"
PROBLEM SETTING,0.07482517482517483,"p(x, y) = P"
PROBLEM SETTING,0.07552447552447553,"i αipi(x, y) is a composition of individual group distributions pi(x, y) weighted by their
107"
PROBLEM SETTING,0.07622377622377623,"respective proportions αi, where P"
PROBLEM SETTING,0.07692307692307693,"i αi = 1. In this work, we assume that Dtr, Dval, and Dtest are
108"
PROBLEM SETTING,0.07762237762237763,"composed of identical groups but with a different set of mixing coefficients {αi}. It is noteworthy
109"
PROBLEM SETTING,0.07832167832167833,"that the validation set may have approximately identical coefficients to those of the training or testing
110"
PROBLEM SETTING,0.07902097902097902,"sets, or it may have entirely different coefficients.
111"
PROBLEM SETTING,0.07972027972027972,"Several kinds of subpopulation shifts are defined in the literature, including class imbalance, attribute
112"
PROBLEM SETTING,0.08041958041958042,"imbalance, and spurious correlation [4]. Class imbalance refers to the cases where there is a difference
113"
PROBLEM SETTING,0.08111888111888112,"between the proportion of samples from each class, while attribute imbalance occurs when instances
114"
PROBLEM SETTING,0.08181818181818182,"with a certain attribute are underrepresented in the training data, even though this attribute may not
115"
PROBLEM SETTING,0.08251748251748252,"necessarily be a reliable predictor of the label. On the other hand, spurious correlation occurs when
116"
PROBLEM SETTING,0.08321678321678322,"various groups are differentiated by spurious attributes that are partially predictive and correlated with
117"
PROBLEM SETTING,0.08391608391608392,"class labels but are causally irrelevant. More precisely, we can consider a set of spurious attributes
118"
PROBLEM SETTING,0.08461538461538462,"S that partition the data into |S| × |Y| groups. When the concurrence of a spurious attribute with a
119"
PROBLEM SETTING,0.08531468531468532,"label is significantly higher than its correlation with other labels, that spurious attribute could become
120"
PROBLEM SETTING,0.08601398601398601,"predictive of the label, resulting in deep models relying on the spurious attributes as shortcuts instead
121"
PROBLEM SETTING,0.08671328671328671,"of the core ones. This is followed by a decrease in the model’s performance on groups that do not
122"
PROBLEM SETTING,0.08741258741258741,"have this attribute.
123"
PROBLEM SETTING,0.08811188811188811,"Given a class, the group containing samples with correlated spurious attributes is referred to as
124"
PROBLEM SETTING,0.08881118881118881,"majority group of that class, while the other groups are called the minority groups. As an example,
125"
PROBLEM SETTING,0.08951048951048951,"in the Waterbirds dataset [7], for which the task is to classify images of birds into landbird and
126"
PROBLEM SETTING,0.09020979020979021,"waterbird, there are spurious attributes {water background, land background}. Each background is
127"
PROBLEM SETTING,0.09090909090909091,"spuriously correlated with its associated label, decompose the data into two majority groups waterbird
128"
PROBLEM SETTING,0.09160839160839161,"on water background, and landbird on land background, and two minority groups waterbird on land
129"
PROBLEM SETTING,0.09230769230769231,"background and landbird on water background. Our goal is to make the classifier robust to spurious
130"
PROBLEM SETTING,0.09300699300699301,"attributes by increasing performance for all groups.
131"
ROBUSTNESS OF A TRAINED MODEL TO AN UNKNOWN SHORTCUT,0.0937062937062937,"2.2
Robustness of a Trained Model to an Unknown Shortcut
132"
ROBUSTNESS OF A TRAINED MODEL TO AN UNKNOWN SHORTCUT,0.0944055944055944,"In scenarios where group annotations are absent, traditional methods that depend on these annotations
133"
ROBUSTNESS OF A TRAINED MODEL TO AN UNKNOWN SHORTCUT,0.0951048951048951,"for training or model selection become infeasible. Moreover, as previously discussed by [14], when
134"
ROBUSTNESS OF A TRAINED MODEL TO AN UNKNOWN SHORTCUT,0.0958041958041958,"data contains multiple spurious attributes and annotations are only available for some of them, such
135"
ROBUSTNESS OF A TRAINED MODEL TO AN UNKNOWN SHORTCUT,0.0965034965034965,"methods would make the model robust only to the known spurious attributes. To explore such complex
136"
ROBUSTNESS OF A TRAINED MODEL TO AN UNKNOWN SHORTCUT,0.0972027972027972,"scenarios, we introduce the Dominoes Colored-MNIST-FashionMNIST (Dominoes CMF) dataset
137"
ROBUSTNESS OF A TRAINED MODEL TO AN UNKNOWN SHORTCUT,0.0979020979020979,"(Figure 3(d)). Drawing inspiration from Pagliardini et al. [17] and Arjovsky et al. [18], Dominoes
138"
ROBUSTNESS OF A TRAINED MODEL TO AN UNKNOWN SHORTCUT,0.0986013986013986,"CMF merges an image from CIFAR10 [19] at the top with a colored (red or green) MNIST [20] or
139"
ROBUSTNESS OF A TRAINED MODEL TO AN UNKNOWN SHORTCUT,0.0993006993006993,"FashionMNIST [21] image at the bottom. The primary label is derived from the CIFAR10 image,
140"
ROBUSTNESS OF A TRAINED MODEL TO AN UNKNOWN SHORTCUT,0.1,"while the bottom part introduces two independent spurious attributes: color and shape. Although
141"
ROBUSTNESS OF A TRAINED MODEL TO AN UNKNOWN SHORTCUT,0.1006993006993007,"Split
class group
sample
1
min
maj
2
min
maj train 𝑫𝑳𝑳"
"MIN
MAJ",0.10139860139860139,"1
min
maj
2
min
maj
random splitting"
"MIN
MAJ",0.1020979020979021,ERM classifier
"MIN
MAJ",0.1027972027972028,train split
"MIN
MAJ",0.1034965034965035,"high-loss samples
low-loss samples"
"MIN
MAJ",0.1041958041958042,rank-based sampling
"MIN
MAJ",0.1048951048951049,top-k high and low
"MIN
MAJ",0.1055944055944056,loss samples
"MIN
MAJ",0.1062937062937063,loss-based sorting K=3
"MIN
MAJ",0.106993006993007,"Environment 
Inference method"
"MIN
MAJ",0.1076923076923077,"{Env 1, Env 2, Env3, Env 4}"
"MIN
MAJ",0.10839160839160839,validation split K=2 K=3 K=4
"MIN
MAJ",0.10909090909090909,WEA: 0.70
"MIN
MAJ",0.10979020979020979,"Env 1
Env 2
Env 3
Env 4"
"MIN
MAJ",0.11048951048951049,WEA: 0.80
"MIN
MAJ",0.11118881118881119,WEA: 0.65
"MIN
MAJ",0.11188811188811189,"acc: 0.95
acc: 0.75
acc: 0.70
acc: 0.85"
"MIN
MAJ",0.11258741258741259,"acc: 0.90
acc: 0.85
acc: 0.90
acc: 0.80"
"MIN
MAJ",0.11328671328671329,"acc: 0.65
acc: 0.95
acc: 0.90
acc: 0.70"
"MIN
MAJ",0.11398601398601399,(a) Held-out data split
"MIN
MAJ",0.11468531468531469,(c) Loss-based sampling
"MIN
MAJ",0.11538461538461539,"(b) Environment inference
(d) Last-layer retraining"
"MIN
MAJ",0.11608391608391608,"training
model selection ✓"
"MIN
MAJ",0.11678321678321678,"train
𝑫𝑳𝑳"
"MIN
MAJ",0.11748251748251748,validation 𝑫𝑴𝑺
"MIN
MAJ",0.11818181818181818,"Figure 1: Overview of the proposed method. Given an ERM-trained model (similar to DFR [1]), the
following steps are performed: (a) we randomly split the held-out dataset into train and validation
splits. (b) An environment inference method is utilized to infer diverse environments from the
validation split. (c) We evaluate train split samples on the initial ERM classifier and sort high-loss and
low-loss samples of each class for loss-based sampling. (d) Finally, we perform last-layer retraining
on the loss-based selected samples. Each retraining setting (e.g. different k for loss-based sampling)
is validated based on the worst accuracy of the inferred environments. Note that majority and minority
groups are shown with dark and light colors for better visualization, but are not known in our setting."
"MIN
MAJ",0.11888111888111888,"annotations for shape are provided for training and model selection, color remains an unknown
142"
"MIN
MAJ",0.11958041958041958,"variable until testing. For more details on the dataset refer to the Appendix.
143"
"MIN
MAJ",0.12027972027972028,"The illustrations in Figure 3(a-c) depict the outlined scenario. A classifier trained using ERM is
144"
"MIN
MAJ",0.12097902097902098,"dependent on both spurious features (Figure 3(b)). Yet, achieving robustness against one spurious
145"
"MIN
MAJ",0.12167832167832168,"correlation (Figure 3(c)), does not ensure robustness against both (Figure 3(a)). In Section 4 we
146"
"MIN
MAJ",0.12237762237762238,"show that our method, which does not rely on the group annotations of the identified group, achieves
147"
"MIN
MAJ",0.12307692307692308,"enhanced robustness against both spurious correlations, outperforming strategies that depend on the
148"
"MIN
MAJ",0.12377622377622377,"known group’s information.
149"
ENVIRONMENT-BASED VALIDATION AND LOSS-BASED SAMPLING,0.12447552447552447,"3
Environment-based Validation and Loss-based Sampling
150"
ENVIRONMENT-BASED VALIDATION AND LOSS-BASED SAMPLING,0.12517482517482517,"Our method, EVaLS, is designed to improve the robustness of deep learning models to group shifts
151"
ENVIRONMENT-BASED VALIDATION AND LOSS-BASED SAMPLING,0.1258741258741259,"without the need for group annotation. In line with the DFR [1] approach, we utilize a classifier
152"
ENVIRONMENT-BASED VALIDATION AND LOSS-BASED SAMPLING,0.12657342657342657,"defined as f = hϕ ◦gθ, where gθ represents a deep neural network serving as a feature extractor, and
153"
ENVIRONMENT-BASED VALIDATION AND LOSS-BASED SAMPLING,0.12727272727272726,"hϕ denotes a linear classifier. The classifier is initially trained with the ERM objective on the training
154"
ENVIRONMENT-BASED VALIDATION AND LOSS-BASED SAMPLING,0.12797202797202797,"dataset Dtr. Subsequently, we freeze the feature extractor gθ and focus solely on retraining the last
155"
ENVIRONMENT-BASED VALIDATION AND LOSS-BASED SAMPLING,0.12867132867132866,"linear layer hϕ using the validation dataset Dval as a held-out dataset.
156"
ENVIRONMENT-BASED VALIDATION AND LOSS-BASED SAMPLING,0.12937062937062938,"We randomly divide the validation set Dval into two subsets, DLL and DMS which are used for last
157"
ENVIRONMENT-BASED VALIDATION AND LOSS-BASED SAMPLING,0.13006993006993006,"layer training and model selection, respectively. In Section 3.1 we explain how to sample a subset
158"
ENVIRONMENT-BASED VALIDATION AND LOSS-BASED SAMPLING,0.13076923076923078,"of DLL that statistically handles the group shifts inherent in the dataset. In Section 3.2 we describe
159"
ENVIRONMENT-BASED VALIDATION AND LOSS-BASED SAMPLING,0.13146853146853146,"how DMS is divided into different environments that are later used for model selection. The optimal
160"
ENVIRONMENT-BASED VALIDATION AND LOSS-BASED SAMPLING,0.13216783216783218,"number of selected samples from DLL and other hyperparameters is determined based on the worst
161"
ENVIRONMENT-BASED VALIDATION AND LOSS-BASED SAMPLING,0.13286713286713286,"environment accuracies among environments that are obtained from DMS. By combining our novel
162"
ENVIRONMENT-BASED VALIDATION AND LOSS-BASED SAMPLING,0.13356643356643358,"sampling and validation strategy, we aim to provide a robust linear classifier hϕ∗that significantly
163"
ENVIRONMENT-BASED VALIDATION AND LOSS-BASED SAMPLING,0.13426573426573427,"improves the accuracy of underrepresented groups without requiring group annotations of training
164"
ENVIRONMENT-BASED VALIDATION AND LOSS-BASED SAMPLING,0.13496503496503495,"or validation sets. Figure 1 illustrates the comprehensive workflow of the EVaLS methodology.
165"
ENVIRONMENT-BASED VALIDATION AND LOSS-BASED SAMPLING,0.13566433566433567,"Finally in Section 3.3, we provide theoretical support for the loss-based sampling procedure and its
166"
ENVIRONMENT-BASED VALIDATION AND LOSS-BASED SAMPLING,0.13636363636363635,"effectiveness.
167"
LOSS-BASED INSTANCE SAMPLING,0.13706293706293707,"3.1
Loss-Based Instance Sampling
168"
LOSS-BASED INSTANCE SAMPLING,0.13776223776223775,"Following previous works [5, 10, 9], we use the loss value as an indicator for identifying minority
169"
LOSS-BASED INSTANCE SAMPLING,0.13846153846153847,"groups. We first evaluate classifier f on samples within DLL and choose k samples with the highest
170"
LOSS-BASED INSTANCE SAMPLING,0.13916083916083916,"and lowest loss values for a given k. By combining these 2k samples from each class, we construct a
171"
LOSS-BASED INSTANCE SAMPLING,0.13986013986013987,"balanced set Dbalanced, consisting of high-loss and low-loss samples (see Figure 1(c)). Dbalanced is
172"
LOSS-BASED INSTANCE SAMPLING,0.14055944055944056,"then used for the training of the last layer of the model.
173"
LOSS-BASED INSTANCE SAMPLING,0.14125874125874127,"As depicted in Figure 2, the proportion of minority samples among various percentiles of samples
174"
LOSS-BASED INSTANCE SAMPLING,0.14195804195804196,"with the highest loss values increases as we select a smaller subset of samples with the highest loss.
175"
LOSS-BASED INSTANCE SAMPLING,0.14265734265734265,"This suggests that high and low-loss samples could serve as effective representatives of minority
176"
LOSS-BASED INSTANCE SAMPLING,0.14335664335664336,"and majority groups, respectively. In Section 3.3, we offer theoretical insights explaining why this
177"
LOSS-BASED INSTANCE SAMPLING,0.14405594405594405,"approach could lead to the creation of group-balanced data.
178"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.14475524475524476,"3.2
Partitioning Validation Set into Environments
179"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.14545454545454545,"Contrary to common assumptions and practices in the field, precise group labels for the validation
180"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.14615384615384616,"set are not essential for training models robust to spurious correlations. Our empirical findings,
181"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.14685314685314685,"detailed in Section 4, reveal that partitioning the validation set into environments that exhibit sig-
182"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.14755244755244756,"nificant subpopulation shifts can be used for model selection. Under these conditions, the worst
183"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.14825174825174825,"environment accuracy (WEA) emerges as a viable metric for selecting the most effective model and
184"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.14895104895104896,"hyperparameters.
185"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.14965034965034965,"The concept of an environment, as frequently discussed in the invariant learning literature, denotes
186"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.15034965034965034,"partitions of data that exhibit different distributions. A model that consistently excels across these
187"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.15104895104895105,"varied environments, achieving impressive worst environment accuracy (WEA), is likely to perform
188"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.15174825174825174,"equally well across different groups in the test set. Several methods for inferring environments
189"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.15244755244755245,"with notable distribution shifts have been introduced [12, 22]. Environment Inference for Invariant
190"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.15314685314685314,"Learning (EIIL) [12], leverages the predictions from an earlier trained ERM model to divide the data
191"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.15384615384615385,"into two distinct environments that significantly deviate from the invariant learning principle proposed
192"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.15454545454545454,"by Arjovsky et al. [18], thus creating environments with distribution shifts. Initially, EIIL is employed
193"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.15524475524475526,"to split DMS into two environments. Subsequently, each environment is further divided based on
194"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.15594405594405594,"sample labels, resulting in 2 × |Y| environments. To measure the difference between the distribution
195"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.15664335664335666,"of environments, we define group shift of a class as the absolute difference in the proportion of
196"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.15734265734265734,"a minority group between two environments of that class. A higher group shift suggests a more
197"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.15804195804195803,"distinct separation between environments. As detailed in the Appendix, environments inferred by
198"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.15874125874125875,"EIIL demonstrate an average group shift of 28.7% over datasets with spurious correlation. Further
199"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.15944055944055943,"information about EIIL and the group shift quantities for each dataset can be found in the Appendix.
200"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.16013986013986015,"We demonstrate that even more straightforward techniques, such as applying a random linear layer
201"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.16083916083916083,"over the feature embedding space and distinguishing environments based on correctly and incorrectly
202"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.16153846153846155,"classified samples of each class, can be effective to an extent in several cases (See Appendix E.2).
203"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.16223776223776223,"It underscores that the feature space of a trained model is a valuable resource of information for
204"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.16293706293706295,"identifying groups affected by spurious correlations. This supports the logic of previous research that
205"
PARTITIONING VALIDATION SET INTO ENVIRONMENTS,0.16363636363636364,"employs clustering [23] or contrastive methods [24] in this space to differentiate between groups.
206"
THEORETICAL ANALYSIS,0.16433566433566432,"3.3
Theoretical Analysis
207"
THEORETICAL ANALYSIS,0.16503496503496504,"In this subsection, we provide theoretical insights into why loss-based sampling in a class can be
208"
THEORETICAL ANALYSIS,0.16573426573426572,"utilized to create a balanced dataset of each group under sufficient conditions. We will show the close
209"
THEORETICAL ANALYSIS,0.16643356643356644,"relationship between the existence of a balanced dataset and the difference between the minority vs.
210"
THEORETICAL ANALYSIS,0.16713286713286712,"majority group means, calculated based on the logits of an ERM-trained classifier. Such logits are
211"
THEORETICAL ANALYSIS,0.16783216783216784,"known to depend on spurious features. Hence the mentioned group mean difference is expected to be
212"
THEORETICAL ANALYSIS,0.16853146853146853,"high if spurious features are present in the dataset.
213"
THEORETICAL ANALYSIS,0.16923076923076924,"Consider a binary classification problem with a cross-entropy loss function. Let logits be denoted as
214"
THEORETICAL ANALYSIS,0.16993006993006993,"L. Because loss is a monotonic function of logits, the tails of the distribution of loss across samples
215"
THEORETICAL ANALYSIS,0.17062937062937064,"are equivalent to that of the logits in each class.
216"
THEORETICAL ANALYSIS,0.17132867132867133,"We assume that in feature space (output of gθ) samples from the minority and majority of a class are
217"
THEORETICAL ANALYSIS,0.17202797202797201,"derived from Gaussian distributions. So, we can consider N(µmin, σ2
min) and N(µmaj, σ2
maj) as the
218"
THEORETICAL ANALYSIS,0.17272727272727273,"distribution of minority and majority samples in logits space.
219"
THEORETICAL ANALYSIS,0.17342657342657342,"Proposition 3.1 (Feasiblity Of Loss-based Group Balancing). Suppose that L is derived from the
220"
THEORETICAL ANALYSIS,0.17412587412587413,"mixture of two distributions N(µmin, σ2
min) and N(µmaj, σ2
maj) with proportion of ε and 1 −ε,
221"
THEORETICAL ANALYSIS,0.17482517482517482,"respectively, where ε ≤1"
THEORETICAL ANALYSIS,0.17552447552447553,"2. Under sufficient (see App.C) and necessary conditions on µmin, µmaj,
222"
THEORETICAL ANALYSIS,0.17622377622377622,"σmin and σmaj including inequality 1, there exists α and β such that restricting L to the α-left and
223"
THEORETICAL ANALYSIS,0.17692307692307693,"0
50
100
% of High-Loss Sample 50 60 70 80 90 100"
THEORETICAL ANALYSIS,0.17762237762237762,% of Minority Samples
THEORETICAL ANALYSIS,0.17832167832167833,"class 1
class 2"
THEORETICAL ANALYSIS,0.17902097902097902,"0
50
100
% of Low-Loss Sample 50 60 70 80 90 100"
THEORETICAL ANALYSIS,0.1797202797202797,% of Majority Samples
THEORETICAL ANALYSIS,0.18041958041958042,"class 1
class 2"
THEORETICAL ANALYSIS,0.1811188811188811,(a) Waterbirds
THEORETICAL ANALYSIS,0.18181818181818182,"0
25
50
75
100
% of High-Loss Sample 10 20 30"
THEORETICAL ANALYSIS,0.1825174825174825,% of Minority Samples
THEORETICAL ANALYSIS,0.18321678321678322,class 2
THEORETICAL ANALYSIS,0.1839160839160839,"0
50
100
% of Low-Loss Sample 94 96 98 100"
THEORETICAL ANALYSIS,0.18461538461538463,% of Majority Samples
THEORETICAL ANALYSIS,0.1853146853146853,class 2
THEORETICAL ANALYSIS,0.18601398601398603,(b) CelebA
THEORETICAL ANALYSIS,0.1867132867132867,"Figure 2: The proportion of minority(majority) samples across different classes within various
percentages of DLL samples with highest (lowest) loss for the Waterbirds (a) and CelebA (b) datasets.
Minority group samples are more prevalent among high-loss samples, while majority group samples
dominate the low-loss areas. The error bars are calculated across three ERM models. 1"
THEORETICAL ANALYSIS,0.1874125874125874,"β-right tails of its distribution results in a group-balanced distribution; in which both components
224"
THEORETICAL ANALYSIS,0.18811188811188811,"are equally represented.
225"
THEORETICAL ANALYSIS,0.1888111888111888,ϵ ≥sigmoid 
THEORETICAL ANALYSIS,0.18951048951048952,"−(µmaj −µmin
2"
THEORETICAL ANALYSIS,0.1902097902097902,"2(σ2
maj −σ2
min) −log
σmaj σmin ! (1)"
THEORETICAL ANALYSIS,0.19090909090909092,"We provide an outline for proof of Proposition 3.1 here and leave the complete and formal proof and
226"
THEORETICAL ANALYSIS,0.1916083916083916,"also exact bounds to Appendix C. We also analyze the conditions and effects of spurious correlation
227"
THEORETICAL ANALYSIS,0.19230769230769232,"in satisfying these conditions. To proceed with the outline we first define a key concept to outline our
228"
THEORETICAL ANALYSIS,0.193006993006993,"proof.
229"
THEORETICAL ANALYSIS,0.19370629370629372,"Definition 3.1 (Proportional Density Difference). For any interval I = (a, b] and a mixture distri-
bution εP1(x) + (1 −ε)P2(x), the proportional density difference is defined as the difference of
accumulation of two component distributions in the interval I and is denoted by ∆εPmixture(I)."
THEORETICAL ANALYSIS,0.1944055944055944,"∆εPmixture(I)
∆= εP1
 
x ∈I

−(1 −ε)P2
 
x ∈I
"
THEORETICAL ANALYSIS,0.1951048951048951,"Proof outline
Our proof proceeds with three steps. First, we reformulate the theorem as an equality
230"
THEORETICAL ANALYSIS,0.1958041958041958,"of left- and right-tail proportional distribution differences. In other words, we show that the more
231"
THEORETICAL ANALYSIS,0.1965034965034965,"mass the minority distribution has on one tail, the more mass the majority distribution must have on
232"
THEORETICAL ANALYSIS,0.1972027972027972,"the other tail. Afterward, supposing µmin < µmaj WOLG, we propose a proper range for β values
233"
THEORETICAL ANALYSIS,0.1979020979020979,"on the right tail. We show that when σmaj ≤σmin, values for α trivially exist that can overcome the
234"
THEORETICAL ANALYSIS,0.1986013986013986,"imbalance between the two distributions. In the last step, for the case in which the variance of the
235"
THEORETICAL ANALYSIS,0.1993006993006993,"majority is higher than the minority, we discuss a necessary and sufficient condition for the existence
236"
THEORETICAL ANALYSIS,0.2,"of α and β based on the left-tail proportional density difference using the properties of its derivative
237"
THEORETICAL ANALYSIS,0.2006993006993007,"with respect to α.
238"
THEORETICAL ANALYSIS,0.2013986013986014,"Condition 1 suggests that for a given degree of spurious correlation ϵ and variations σmaj, σmin, an
239"
THEORETICAL ANALYSIS,0.2020979020979021,"essential prerequisite for the efficacy of loss-based sampling is a sufficiently large disparity between
240"
THEORETICAL ANALYSIS,0.20279720279720279,"the mean distributions of minority and majority samples, denoted by ∥µmaj −µmin∥2. This indicates
241"
THEORETICAL ANALYSIS,0.2034965034965035,"that the groups should be distinctly separable in the logits space.
242"
THEORETICAL ANALYSIS,0.2041958041958042,"Although the parameters α and β are theoretically established under certain conditions, their actual
243"
THEORETICAL ANALYSIS,0.2048951048951049,"values are undetermined. Therefore, validation data is necessary to ascertain them. For practicality
244"
THEORETICAL ANALYSIS,0.2055944055944056,"and simplicity in this study, we consider that α = β and explore its corresponding sample number
245"
THEORETICAL ANALYSIS,0.2062937062937063,"(the count of high- and low-loss samples) from a predefined set of possibilities. By leveraging the
246"
THEORETICAL ANALYSIS,0.206993006993007,"worst environment accuracy, as elaborated in Section 3.2, we identify the optimal candidate that
247"
THEORETICAL ANALYSIS,0.2076923076923077,"ensures uniform accuracy across all environments.
248"
EXPERIMENTS,0.2083916083916084,"4
Experiments
249"
EXPERIMENTS,0.20909090909090908,"In this section, we evaluate the effectiveness of our proposed method through comprehensive experi-
250"
EXPERIMENTS,0.2097902097902098,"ments on multiple datasets and compare it with various methods and baselines. We begin by briefly
251"
EXPERIMENTS,0.21048951048951048,"1Note that in the CelebA dataset, only the ""blond hair"" class includes a minority group."
EXPERIMENTS,0.2111888111888112,Core Dimension 3 2 1 0 1 2 3
EXPERIMENTS,0.21188811188811188,Spurious 1 Dimension 3 2 1 0 1 2
EXPERIMENTS,0.2125874125874126,"Class 1
Class 2
Spurious 1 = 1, Spurious 2 =  -1
Spurious 1 = -1, Spurious 2 =  -1
Spurious 1 = 1 Spurious 2 =  1
Spurious 1 = -1 Spurious 2 =  1"
EXPERIMENTS,0.21328671328671328,Spurious 
DIMENSION,0.213986013986014,"1 Dimension
2 (a)"
DIMENSION,0.21468531468531468,Core Dimension 3 2 1 0 1 2 3
DIMENSION,0.2153846153846154,Spurious 1 Dimension 3 2 1 0 1 2 (b)
DIMENSION,0.21608391608391608,Core Dimension 3 2 1 0 1 2 3
DIMENSION,0.21678321678321677,Spurious 1 Dimension 3 2 1 0 1 2 (c) Text
DIMENSION,0.21748251748251748,"Vehicle
Animal Red Green"
DIMENSION,0.21818181818181817,"MNIST
MNIST
FMNIST
FMNIST (d)"
DIMENSION,0.21888111888111889,"Figure 3: Two spurious correlations in a dataset. (a) If both spurious attributes are known, they can be
utilized to fit a classifier that captures the essential attributes. (b) In the absence of knowledge about
both spurious attributes, the model would depend on them for classification, leading to incorrect
classification of minority samples. (c) If one spurious attribute is unknown (Spurious 2), the model
becomes robust only to the known spurious correlation (Spurious 1), but it still underperforms on
minority samples. (d) The Dominoes-CMF dataset, which contains two spurious attributes."
DIMENSION,0.21958041958041957,"describing evaluation datasets and then introduce baselines and comparative methods. Finally, we
252"
DIMENSION,0.2202797202797203,"report and fully explain the results.
253"
DIMENSION,0.22097902097902097,"Datasets
Our method, along with other baselines, is evaluated on Waterbirds [7], CelebA [13],
254"
DIMENSION,0.2216783216783217,"UrbanCars [14], CivilComments [16], and MultiNLI [15]. As per the study by Yang et al. [4],
255"
DIMENSION,0.22237762237762237,"Waterbirds, CelebA, and UrbanCars among these datasets exhibit spurious correlation. Among the
256"
DIMENSION,0.2230769230769231,"rest, CivilComments has class and attribute imbalance, whereas MultiNLI exhibits attribute imbalance.
257"
DIMENSION,0.22377622377622378,"For additional details on the datasets, please refer to the Appendix.
258"
DIMENSION,0.22447552447552446,"Baselines
We compare our method with four baselines in addition to standard ERM. GroupDRO [7]
259"
DIMENSION,0.22517482517482518,"trains a model on the data with the objective of minimizing its average loss on the minority samples.
260"
DIMENSION,0.22587412587412586,"This method requires group labels of both the training and validation sets. DFR [1] argues that
261"
DIMENSION,0.22657342657342658,"models trained with ERM are capable of extracting the core features of images. Thus, it first trains a
262"
DIMENSION,0.22727272727272727,"model with ERM, and retrains only the last linear classifier layer on a group-balanced subset of the
263"
DIMENSION,0.22797202797202798,"validation or the held-out training data. While DFR reduces the number of group-annotated samples,
264"
DIMENSION,0.22867132867132867,"it still requires group labels in the training phase. GroupDRO + EIIL [12] infers environments of
265"
DIMENSION,0.22937062937062938,"the training set and trains a model with GroupDRO on the inferred environments. JTT [5] first trains
266"
DIMENSION,0.23006993006993007,"a model with ERM on the dataset, and then retrains it on the dataset by upweighting the samples that
267"
DIMENSION,0.23076923076923078,"were misclassified by the initial ERM model. AFR [9] trains a model with ERM on a portion of the
268"
DIMENSION,0.23146853146853147,"training set, and retrains the classifier on the weighted held-out training data. The weights assigned to
269"
DIMENSION,0.23216783216783216,"retraining samples are based on the loss of the ERM model, upweighting samples from the minority
270"
DIMENSION,0.23286713286713287,"groups. Group DRO + EIIL, JTT and AFR remove the reliance on group annotation in the training
271"
DIMENSION,0.23356643356643356,"phase. However, unlike our method, they all require group labels for model selection.
272"
DIMENSION,0.23426573426573427,"Setup
Similar to all the works mentioned in Section 4, we use ResNet-50 [25] pretrained on
273"
DIMENSION,0.23496503496503496,"ImageNet [26] for image classification tasks. We used random crop and random horizontal flip
274"
DIMENSION,0.23566433566433567,"as data augmentation, similar to [1]. For a fair comparison with the baselines, we did not employ
275"
DIMENSION,0.23636363636363636,"any data augmentation techniques in the process of retraining the last layer of the model. For the
276"
DIMENSION,0.23706293706293707,"CivilComments and MultiNLI, we use pretrained BERT [27] and crop sentences to 220 tokens length.
277"
DIMENSION,0.23776223776223776,"In EvaLS, we use the implementation of EIIL by spuco package [28] for environments inference on
278"
DIMENSION,0.23846153846153847,"the model selection set with 20000 steps, SGD optimizer, and learning rate 10−2 for all datasets.
279"
DIMENSION,0.23916083916083916,"Model selection and hyper-parameter fine-tuning are done according to the worst environment(or
280"
DIMENSION,0.23986013986013985,"group if annotations are assumed to be available) accuracy on the validation set. For each dataset,
281"
DIMENSION,0.24055944055944056,"we assess the performance of our model in two cases: fine-tuning the ERM classifier or retraining it.
282"
DIMENSION,0.24125874125874125,"For all datasets except MultiNLI, retraining yielded better validation results. We report the results
283"
DIMENSION,0.24195804195804196,"of our experiments in two settings: (i) EVaLS, which incorporates loss-based instance sampling for
284"
DIMENSION,0.24265734265734265,"training the last layer, and environment inference for model selection. (ii) EVaLS-GL, similar to
285"
DIMENSION,0.24335664335664337,"EVaLS except in using ground-truth group labels for model selection. For more details on the ERM
286"
DIMENSION,0.24405594405594405,"training and last layer re-training hyperparameters refer to the Appendix.
287"
RESULTS,0.24475524475524477,"4.1
Results
288"
RESULTS,0.24545454545454545,"The results of our experiments along with the reported results on GroupDRO [7], DFR [1], JTT [5],
289"
RESULTS,0.24615384615384617,"and AFR [9] on five datasets are shown in Table 1. The reported results for GroupDRO, DFR, JTT,
290"
RESULTS,0.24685314685314685,"and AFR except those for the UrbanCars are taken from Qiu et al. [9]. For EIIL+Group DRO, the
291"
RESULTS,0.24755244755244754,"results are reported from Zhang et al. [24]. We report only the worst group accuracy of methods in
292"
RESULTS,0.24825174825174826,"Table 1. The average group accuracies are documented in the Appendix. The Group Info column
293"
RESULTS,0.24895104895104894,"shows whether group annotation is required for training or model selection entry for each method.
294"
RESULTS,0.24965034965034966,"When compared to other methods with the same level of supervision, EVaLS-GL outperforms on four
295"
RESULTS,0.25034965034965034,"of the five datasets, achieving near-optimal worst group accuracy on Waterbirds, demonstrating the
296"
RESULTS,0.25104895104895103,"effectiveness of loss-based sample selection compared to the weighting scheme in AFR [9]. Given
297"
RESULTS,0.2517482517482518,"that AFR employs exponential weights with a temperature parameter to assign a positive weight
298"
RESULTS,0.25244755244755246,"to all samples, proportional to the model’s assigned probability of the correct class, an increase
299"
RESULTS,0.25314685314685315,"in the number of low-loss samples will lead to a corresponding rise in their cumulative weight.
300"
RESULTS,0.25384615384615383,"Consequently, in situations where spurious correlation is high and an uptick in majority samples leads
301"
RESULTS,0.2545454545454545,"to a greater proportion of low-loss over high-loss samples, determining an appropriate parameter
302"
RESULTS,0.25524475524475526,"becomes challenging.
303"
RESULTS,0.25594405594405595,"The comparison between EVaLS and Group DRO + EIIL indicates that when environments are
304"
RESULTS,0.25664335664335663,"available instead of groups, our method, which uses environments solely for model selection and
305"
RESULTS,0.2573426573426573,"utilizes loss-based sampling, is more effective than GroupDRO, a potent invariant learning method,
306"
RESULTS,0.25804195804195806,"which uses this annotation for training.
307"
RESULTS,0.25874125874125875,"Regarding the UrbanCars, which contains an un-annotated spurious attribute, Li et al. [14] has shown
308"
RESULTS,0.25944055944055944,"that shortcut mitigation methods often struggle to address multiple shortcuts simultaneously. Notably,
309"
RESULTS,0.2601398601398601,"techniques such as DFR [1] which are designed to reduce reliance on a specific shortcut feature,
310"
RESULTS,0.26083916083916087,"cannot make the model robust to an unknown shortcut. In contrast, our experiments suggest that
311"
RESULTS,0.26153846153846155,"loss-based methods can mitigate the impact of both labeled and unlabeled shortcut features more
312"
RESULTS,0.26223776223776224,"effectively. Also, in the case of CivilComments, which is viewed as a benchmark for class imbalance,
313"
RESULTS,0.2629370629370629,"EVaLS-GL exceeds all prior methods, even those with complete group annotation, thanks to the class
314"
RESULTS,0.2636363636363636,"balancing for the training of the last layer.
315"
RESULTS,0.26433566433566436,"Our evaluation of EVaLS is based on the spurious correlation benchmarks. This is because, in
316"
RESULTS,0.26503496503496504,"other instances of subpopulation shift, the attributes that differ across groups are not predictive of
317"
RESULTS,0.26573426573426573,"the label, thereby reducing the visibility of these attributes’ effects in the model’s final layers [29].
318"
RESULTS,0.2664335664335664,"Consequently, EIIL, which depends on output logits for prediction, might not effectively separate
319"
RESULTS,0.26713286713286716,"the groups. This observation is further supported by our findings related to the degree of group
320"
RESULTS,0.26783216783216784,"shift between the environments inferred by EIIL for each class in the CivilComments and MultiNLI
321"
RESULTS,0.26853146853146853,"datasets. The average group shift (defined in the Section 3.2) in the environments of the minority
322"
RESULTS,0.2692307692307692,"class of CivilComments is only 5.6±0.8%. Also, environments associated with Classes 1 and 2 in
323"
RESULTS,0.2699300699300699,"MultiNLI show only 1.1±0.3% and 1.9±1.0% group shift respectively. More results and ablation
324"
RESULTS,0.27062937062937065,"studies can be found in the Appendix.
325"
RESULTS,0.27132867132867133,"Mitigating Multiple Shortcut Attributes
To evaluate the performance of our method in the case
326"
RESULTS,0.272027972027972,"of unknown spurious correlations, we train a ResNet-18 [25] model on the Dominoes-CMF dataset.
327"
RESULTS,0.2727272727272727,"We apply DFR [1], EVaLS-GL, and EVaLS on top of the trained ERMs to assess their ability to
328"
RESULTS,0.27342657342657345,"mitigate multiple shortcuts. For the last layer training set, we consider the MNIST/Fashion-MNIST
329"
RESULTS,0.27412587412587414,"feature as the known group label, and the color as the unknown attribute. The results are shown in
330"
RESULTS,0.2748251748251748,"Table 2. To clarify, we calculate the worst-group accuracy on the validation set considering only the
331"
RESULTS,0.2755244755244755,"label of one shortcut, i.e., the lowest accuracy among the four groups based on the combination of the
332"
RESULTS,0.2762237762237762,"target label and the single known shortcut label. Note that EVaLS does not require group annotations.
333"
RESULTS,0.27692307692307694,"Our results confirm findings by Li et al. [14], suggesting that methods using group labels mitigate
334"
RESULTS,0.2776223776223776,"reliance on the known shortcut but not necessarily on the unknown one. EVaLS-GL mitigates this
335"
RESULTS,0.2783216783216783,"phenomenon using its loss-based sampling approach, but surprisingly EVaLS even outperforms
336"
RESULTS,0.279020979020979,"EVaLS-GL. Combining a loss-based sampling approach for last layer training and environment-based
337"
RESULTS,0.27972027972027974,"model selection, results in a completely group-annotation-free method in a multi-shortcut setting and
338"
RESULTS,0.2804195804195804,"successfully re-weights features to perform well with respect to both spurious attributes.
339"
RESULTS,0.2811188811188811,"Table 1: A comparison of the worst group accuracy across various methods, ours included, on
five datasets. The Group Info column indicates if each method utilizes group labels of the train-
ing/validation data, with ✓✓denoting that group information is employed during both the training
and validation stages. Bold numbers are the highest results overall, while underlined ones are the
best among methods that may require group annotation only for model selection. CivilComments is
class imbalanced, MultiNLI has imbalanced attributes, and the other three datasets have spurious
correlations. The × sign indicates that the dataset is out of the scope of the method. The mean and
standard deviation are calculated over three runs with different seeds."
RESULTS,0.2818181818181818,"Method
Group Info
Datasets"
RESULTS,0.28251748251748254,"Train/Val
Waterbirds
CelebA
UrbanCars
CivilComments
MultiNLI"
RESULTS,0.28321678321678323,"GDRO [7]
✓/✓
91.4
88.9
-
69.9
77.7
DFR [1]
✗/✓✓
92.9±0.2
88.3±1.1
79.6±2.22
70.1±0.8
74.7±0.7
GDRO + EIIL [12]
✗/✓
77.2±1
81.7±0.8
-
67.0±2.4
-
JTT [5]
✗/✓
86.7
81.1
-
69.3
72.6
AFR [9]
✗/✓
90.4±1.1
82.0±0.5
80.2±2.0
68.7±0.6
73.4±0.6
EVaLS-GL (Ours)
✗/✓
89.4±0.3
84.6±1.6
82.27±1.16
80.5±0.4
75.1±1.2"
RESULTS,0.2839160839160839,"ERM
✗/✗
66.4±2.3
47.4±2.3
18.67±2.01
61.2±3.6
64.8±1.9
EVaLS (Ours)
✗/✗
88.4±3.1
85.3±0.4
82.13±0.92
×
×"
RESULTS,0.2846153846153846,"Table 2: Worst test group accuracy of ERM, DFR, EVaLS, and EVaLS-GL on the Dominoes-CMF
Dataset. The mean and standard deviation are calculated based on runs with three distinct seeds."
RESULTS,0.2853146853146853,"ERM
DFR
EVaLS-GL
EVaLS"
RESULTS,0.28601398601398603,"Worst Group Accuracy
50.6±1.0
60.2±1.2
63.6±1.3
67.1±4.2"
DISCUSSION,0.2867132867132867,"5
Discussion
340"
DISCUSSION,0.2874125874125874,"This study presents EVaLS, a novel approach to improve robustness to spurious correlations with
341"
DISCUSSION,0.2881118881118881,"zero group annotation. EVaLS uses loss-based sampling to create a balanced training dataset that
342"
DISCUSSION,0.28881118881118883,"effectively disrupts spurious correlations and employs EIIL to infer environments for model selection.
343"
DISCUSSION,0.2895104895104895,"We also explore situations with multiple spurious correlations where not all spurious factors are
344"
DISCUSSION,0.2902097902097902,"known. In this context, we introduce Dominoes-CMF, a dataset in which two factors are spuriously
345"
DISCUSSION,0.2909090909090909,"correlated with the label, but only one is identified. Our findings suggest that EVaLS attains near-
346"
DISCUSSION,0.2916083916083916,"optimal worst test group accuracy on spurious correlation datasets. We also present EVaLS-GL, which
347"
DISCUSSION,0.2923076923076923,"needs group labels only for model selection. Our empirical tests on various datasets demonstrate
348"
DISCUSSION,0.293006993006993,"EVaLS-GL outperforms state-of-the-art methods requiring group data during evaluation or training.
349"
DISCUSSION,0.2937062937062937,"Note that this paper remains consistent with the findings of Lin et al. [30]. Our approach does not
350"
DISCUSSION,0.2944055944055944,"involve identifying spurious attributes without auxiliary information. Instead, the objective is to make
351"
DISCUSSION,0.2951048951048951,"a trained model robust against its reliance on shortcuts. Specifically, conditioning on what a trained
352"
DISCUSSION,0.2958041958041958,"model learns, we ascertain that both the loss value and the model’s feature space are instrumental in
353"
DISCUSSION,0.2965034965034965,"mitigating shortcuts and effectuating notable shifts among groups.
354"
DISCUSSION,0.2972027972027972,"EVaLS and EVaLS-GL may struggle with small datasets due to a low number of selected samples
355"
DISCUSSION,0.29790209790209793,"for the last layer training. Also, as environment inference from the last layer features is not effective
356"
DISCUSSION,0.2986013986013986,"for all types of subpopulation shifts, EVaLS is limited to datasets with spurious correlation. Similar
357"
DISCUSSION,0.2993006993006993,"to other methods in the field, EVaLS prioritizes the worst group accuracy at the cost of less average
358"
DISCUSSION,0.3,"accuracy. Additionally, a notable variance has been observed in some of our experiments.
359"
DISCUSSION,0.3006993006993007,"EVaLS represents a significant advancement in the development of methods for enhancing model
360"
DISCUSSION,0.3013986013986014,"fairness and robustness without prior knowledge about group annotations. Future work could explore
361"
DISCUSSION,0.3020979020979021,"developing environment inference methods effective for other types of subpopulation shift, such as
362"
DISCUSSION,0.3027972027972028,"attribute and class imbalance.
363"
REFERENCES,0.3034965034965035,"References
364"
REFERENCES,0.3041958041958042,"[1] Polina Kirichenko, Pavel Izmailov, and Andrew Gordon Wilson. Last layer re-training is suffi-
365"
REFERENCES,0.3048951048951049,"cient for robustness to spurious correlations. In The Eleventh International Conference on Learn-
366"
REFERENCES,0.3055944055944056,"ing Representations, 2023. URL https://openreview.net/forum?id=Zb6c8A-Fghk.
367"
REFERENCES,0.3062937062937063,"[2] Tyler LaBonte, Vidya Muthukumar, and Abhishek Kumar. Towards last-layer retraining for
368"
REFERENCES,0.30699300699300697,"group robustness with fewer annotations. In Thirty-seventh Conference on Neural Information
369"
REFERENCES,0.3076923076923077,"Processing Systems, 2023. URL https://openreview.net/forum?id=kshC3NOP6h.
370"
REFERENCES,0.3083916083916084,"[3] Tatsunori Hashimoto, Megha Srivastava, Hongseok Namkoong, and Percy Liang. Fairness
371"
REFERENCES,0.3090909090909091,"without demographics in repeated loss minimization. In International Conference on Machine
372"
REFERENCES,0.30979020979020977,"Learning, pages 1929–1938. PMLR, 2018.
373"
REFERENCES,0.3104895104895105,"[4] Yuzhe Yang, Haoran Zhang, Dina Katabi, and Marzyeh Ghassemi. Change is hard: A closer
374"
REFERENCES,0.3111888111888112,"look at subpopulation shift. In International Conference on Machine Learning, 2023.
375"
REFERENCES,0.3118881118881119,"[5] Evan Z Liu, Behzad Haghgoo, Annie S Chen, Aditi Raghunathan, Pang Wei Koh, Shiori
376"
REFERENCES,0.31258741258741257,"Sagawa, Percy Liang, and Chelsea Finn. Just train twice: Improving group robustness without
377"
REFERENCES,0.3132867132867133,"training group information. In Marina Meila and Tong Zhang, editors, Proceedings of the
378"
REFERENCES,0.313986013986014,"38th International Conference on Machine Learning, volume 139 of Proceedings of Machine
379"
REFERENCES,0.3146853146853147,"Learning Research, pages 6781–6792. PMLR, 18–24 Jul 2021. URL https://proceedings.
380"
REFERENCES,0.3153846153846154,"mlr.press/v139/liu21f.html.
381"
REFERENCES,0.31608391608391606,"[6] Yu Yang, Eric Gan, Gintare Karolina Dziugaite, and Baharan Mirzasoleiman. Identifying
382"
REFERENCES,0.3167832167832168,"spurious biases early in training through the lens of simplicity bias. ArXiv, abs/2305.18761,
383"
REFERENCES,0.3174825174825175,"2023. URL https://api.semanticscholar.org/CorpusID:258967752.
384"
REFERENCES,0.3181818181818182,"[7] Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust
385"
REFERENCES,0.31888111888111886,"neural networks. In International Conference on Learning Representations, 2019.
386"
REFERENCES,0.3195804195804196,"[8] Junhyun Nam, Jaehyung Kim, Jaeho Lee, and Jinwoo Shin. Spread spurious attribute: Improving
387"
REFERENCES,0.3202797202797203,"worst-group accuracy with spurious attribute estimation.
In International Conference on
388"
REFERENCES,0.320979020979021,"Learning Representations, 2021.
389"
REFERENCES,0.32167832167832167,"[9] Shikai Qiu, Andres Potapczynski, Pavel Izmailov, and Andrew Gordon Wilson. Simple and fast
390"
REFERENCES,0.32237762237762235,"group robustness by automatic feature reweighting. In International Conference on Machine
391"
REFERENCES,0.3230769230769231,"Learning, pages 28448–28467. PMLR, 2023.
392"
REFERENCES,0.3237762237762238,"[10] Junhyun Nam, Hyuntak Cha, Sungsoo Ahn, Jaeho Lee, and Jinwoo Shin. Learning from failure:
393"
REFERENCES,0.32447552447552447,"De-biasing classifier from biased classifier. Advances in Neural Information Processing Systems,
394"
REFERENCES,0.32517482517482516,"33:20673–20684, 2020.
395"
REFERENCES,0.3258741258741259,"[11] Fahimeh Hosseini Noohdani, Parsa Hosseini, Aryan Yazdan Parast, HamidReza Yaghoubi
396"
REFERENCES,0.3265734265734266,"Araghi, and Mahdieh Soleymani Baghshah.
Decompose-and-compose: A compositional
397"
REFERENCES,0.32727272727272727,"approach to mitigating spurious correlation. CoRR, abs/2402.18919, 2024. doi: 10.48550/
398"
REFERENCES,0.32797202797202796,"ARXIV.2402.18919. URL https://doi.org/10.48550/arXiv.2402.18919.
399"
REFERENCES,0.32867132867132864,"[12] Elliot Creager, Joern-Henrik Jacobsen, and Richard Zemel. Environment inference for invariant
400"
REFERENCES,0.3293706293706294,"learning. In Marina Meila and Tong Zhang, editors, Proceedings of the 38th International
401"
REFERENCES,0.3300699300699301,"Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research,
402"
REFERENCES,0.33076923076923076,"pages 2189–2200. PMLR, 18–24 Jul 2021. URL https://proceedings.mlr.press/v139/
403"
REFERENCES,0.33146853146853145,"creager21a.html.
404"
REFERENCES,0.3321678321678322,"[13] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the
405"
REFERENCES,0.3328671328671329,"wild. 2015 IEEE International Conference on Computer Vision (ICCV), pages 3730–3738,
406"
REFERENCES,0.33356643356643356,"2014. URL https://api.semanticscholar.org/CorpusID:459456.
407"
REFERENCES,0.33426573426573425,"[14] Zhiheng Li, Ivan Evtimov, Albert Gordo, Caner Hazirbas, Tal Hassner, Cristian Canton Ferrer,
408"
REFERENCES,0.334965034965035,"Chenliang Xu, and Mark Ibrahim. A whac-a-mole dilemma: Shortcuts come in multiples where
409"
REFERENCES,0.3356643356643357,"mitigating one amplifies others. In Proceedings of the IEEE/CVF Conference on Computer
410"
REFERENCES,0.33636363636363636,"Vision and Pattern Recognition (CVPR), pages 20071–20082, June 2023.
411"
REFERENCES,0.33706293706293705,"[15] Adina Williams, Nikita Nangia, and Samuel R Bowman. A broad-coverage challenge corpus
412"
REFERENCES,0.33776223776223774,"for sentence understanding through inference. arXiv preprint arXiv:1704.05426, 2017.
413"
REFERENCES,0.3384615384615385,"[16] Daniel Borkan, Lucas Dixon, Jeffrey Sorensen, Nithum Thain, and Lucy Vasserman. Nuanced
414"
REFERENCES,0.33916083916083917,"metrics for measuring unintended bias with real data for text classification. In Companion
415"
REFERENCES,0.33986013986013985,"proceedings of the 2019 world wide web conference, pages 491–500, 2019.
416"
REFERENCES,0.34055944055944054,"[17] Matteo Pagliardini, Martin Jaggi, François Fleuret, and Sai Praneeth Karimireddy. Agree to
417"
REFERENCES,0.3412587412587413,"disagree: Diversity through disagreement for better transferability. In The Eleventh International
418"
REFERENCES,0.34195804195804197,"Conference on Learning Representations, 2022.
419"
REFERENCES,0.34265734265734266,"[18] Martin Arjovsky, Léon Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk mini-
420"
REFERENCES,0.34335664335664334,"mization, 2020.
421"
REFERENCES,0.34405594405594403,"[19] Alex Krizhevsky. Learning multiple layers of features from tiny images. pages 32–33, 2009.
422"
REFERENCES,0.34475524475524477,"URL https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf.
423"
REFERENCES,0.34545454545454546,"[20] Yann LeCun and Corinna Cortes. MNIST handwritten digit database. 2010. URL http:
424"
REFERENCES,0.34615384615384615,"//yann.lecun.com/exdb/mnist/.
425"
REFERENCES,0.34685314685314683,"[21] Han Xiao,
Kashif Rasul,
and Roland Vollgraf.
Fashion-mnist:
a novel image
426"
REFERENCES,0.3475524475524476,"dataset for benchmarking machine learning algorithms, 2017.
URL http://arxiv.
427"
REFERENCES,0.34825174825174826,"org/abs/1708.07747.
cite arxiv:1708.07747Comment: Dataset is freely available at
428"
REFERENCES,0.34895104895104895,"https://github.com/zalandoresearch/fashion-mnist Benchmark is available at http://fashion-
429"
REFERENCES,0.34965034965034963,"mnist.s3-website.eu-central-1.amazonaws.com/.
430"
REFERENCES,0.3503496503496504,"[22] Jiashuo Liu, Zheyuan Hu, Peng Cui, Bo Li, and Zheyan Shen. Heterogeneous risk minimization.
431"
REFERENCES,0.35104895104895106,"In Marina Meila and Tong Zhang, editors, Proceedings of the 38th International Conference on
432"
REFERENCES,0.35174825174825175,"Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 6804–
433"
REFERENCES,0.35244755244755244,"6814. PMLR, 18–24 Jul 2021. URL https://proceedings.mlr.press/v139/liu21h.
434"
REFERENCES,0.3531468531468531,"html.
435"
REFERENCES,0.35384615384615387,"[23] Nimit Sohoni, Jared Dunnmon, Geoffrey Angus, Albert Gu, and Christopher Ré. No subclass
436"
REFERENCES,0.35454545454545455,"left behind: Fine-grained robustness in coarse-grained classification problems. Advances in
437"
REFERENCES,0.35524475524475524,"Neural Information Processing Systems, 33:19339–19352, 2020.
438"
REFERENCES,0.3559440559440559,"[24] Michael Zhang, Nimit Sharad Sohoni, Hongyang R. Zhang, Chelsea Finn, and Christopher Ré.
439"
REFERENCES,0.35664335664335667,"Correct-n-contrast: A contrastive approach for improving robustness to spurious correlations.
440"
REFERENCES,0.35734265734265735,"In NeurIPS 2021 Workshop on Distribution Shifts: Connecting Methods and Applications, 2021.
441"
REFERENCES,0.35804195804195804,"URL https://openreview.net/forum?id=Q41kl_DwS3Y.
442"
REFERENCES,0.35874125874125873,"[25] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
443"
REFERENCES,0.3594405594405594,"recognition. In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
444"
REFERENCES,0.36013986013986016,"pages 770–778, 2016. doi: 10.1109/CVPR.2016.90.
445"
REFERENCES,0.36083916083916084,"[26] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng
446"
REFERENCES,0.36153846153846153,"Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual
447"
REFERENCES,0.3622377622377622,"recognition challenge. International journal of computer vision, 115:211–252, 2015.
448"
REFERENCES,0.36293706293706296,"[27] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of
449"
REFERENCES,0.36363636363636365,"deep bidirectional transformers for language understanding. In Jill Burstein, Christy Doran, and
450"
REFERENCES,0.36433566433566433,"Thamar Solorio, editors, Proceedings of the 2019 Conference of the North American Chapter
451"
REFERENCES,0.365034965034965,"of the Association for Computational Linguistics: Human Language Technologies, Volume 1
452"
REFERENCES,0.3657342657342657,"(Long and Short Papers), pages 4171–4186, Minneapolis, Minnesota, June 2019. Association
453"
REFERENCES,0.36643356643356645,"for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL https://aclanthology.
454"
REFERENCES,0.36713286713286714,"org/N19-1423.
455"
REFERENCES,0.3678321678321678,"[28] Siddharth Joshi, Yu Yang, Yihao Xue, Wenhan Yang, and Baharan Mirzasoleiman.
To-
456"
REFERENCES,0.3685314685314685,"wards mitigating spurious correlations in the wild: A benchmark & a more realistic dataset.
457"
REFERENCES,0.36923076923076925,"ArXiv, abs/2306.11957, 2023.
URL https://api.semanticscholar.org/CorpusID:
458"
REFERENCES,0.36993006993006994,"259211935.
459"
REFERENCES,0.3706293706293706,"[29] Yoonho Lee, Annie S Chen, Fahim Tajwar, Ananya Kumar, Huaxiu Yao, Percy Liang, and
460"
REFERENCES,0.3713286713286713,"Chelsea Finn. Surgical fine-tuning improves adaptation to distribution shifts. In The Eleventh
461"
REFERENCES,0.37202797202797205,"International Conference on Learning Representations, 2023. URL https://openreview.
462"
REFERENCES,0.37272727272727274,"net/forum?id=APuPRxjHvZ.
463"
REFERENCES,0.3734265734265734,"[30] Yong Lin, Shengyu Zhu, Lu Tan, and Peng Cui. Zin: When and how to learn invariance without
464"
REFERENCES,0.3741258741258741,"environment partition? In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh,
465"
REFERENCES,0.3748251748251748,"editors, Advances in Neural Information Processing Systems, volume 35, pages 24529–24542.
466"
REFERENCES,0.37552447552447554,"Curran Associates, Inc., 2022. URL https://proceedings.neurips.cc/paper_files/
467"
REFERENCES,0.37622377622377623,"paper/2022/file/9b77f07301b1ef1fe810aae96c12cb7b-Paper-Conference.pdf.
468"
REFERENCES,0.3769230769230769,"[31] Zheyan Shen, Jiashuo Liu, Yue He, Xingxuan Zhang, Renzhe Xu, Han Yu, and Peng Cui.
469"
REFERENCES,0.3776223776223776,"Towards out-of-distribution generalization: A survey. ArXiv, abs/2108.13624, 2021. URL
470"
REFERENCES,0.37832167832167835,"https://api.semanticscholar.org/CorpusID:237364121.
471"
REFERENCES,0.37902097902097903,"[32] Seonguk Seo, Joon-Young Lee, and Bohyung Han. Information-theoretic bias reduction via
472"
REFERENCES,0.3797202797202797,"causal view of spurious correlation. In Proceedings of the AAAI Conference on Artificial
473"
REFERENCES,0.3804195804195804,"Intelligence, volume 36, pages 2180–2188, 2022.
474"
REFERENCES,0.3811188811188811,"[33] Yuzhen Mao, Zhun Deng, Huaxiu Yao, Ting Ye, Kenji Kawaguchi, and James Zou. Last-layer
475"
REFERENCES,0.38181818181818183,"fairness fine-tuning is simple and effective for neural networks. arXiv preprint arXiv:2304.03935,
476"
REFERENCES,0.3825174825174825,"2023.
477"
REFERENCES,0.3832167832167832,"[34] David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai
478"
REFERENCES,0.3839160839160839,"Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapo-
479"
REFERENCES,0.38461538461538464,"lation (rex). In Marina Meila and Tong Zhang, editors, Proceedings of the 38th International
480"
REFERENCES,0.3853146853146853,"Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research,
481"
REFERENCES,0.386013986013986,"pages 5815–5826. PMLR, 18–24 Jul 2021. URL https://proceedings.mlr.press/v139/
482"
REFERENCES,0.3867132867132867,"krueger21a.html.
483"
REFERENCES,0.38741258741258744,"[35] Alexandre Rame, Corentin Dancette, and Matthieu Cord. Fishr: Invariant gradient variances for
484"
REFERENCES,0.3881118881118881,"out-of-distribution generalization. In International Conference on Machine Learning, pages
485"
REFERENCES,0.3888111888111888,"18347–18377. PMLR, 2022.
486"
REFERENCES,0.3895104895104895,"[36] Faruk Ahmed, Yoshua Bengio, Harm van Seijen, and Aaron Courville. Systematic generalisation
487"
REFERENCES,0.3902097902097902,"with group invariant predictions. In International Conference on Learning Representations,
488"
REFERENCES,0.39090909090909093,"2021. URL https://openreview.net/forum?id=b9PoimzZFJ.
489"
REFERENCES,0.3916083916083916,"[37] Matteo Pagliardini, Martin Jaggi, François Fleuret, and Sai Praneeth Karimireddy. Agree
490"
REFERENCES,0.3923076923076923,"to disagree:
Diversity through disagreement for better transferability.
arXiv preprint,
491"
REFERENCES,0.393006993006993,"arXiv:2202.04414, 2022.
492"
REFERENCES,0.39370629370629373,"[38] Harshay Shah, Kaustav Tamuly, Aditi Raghunathan, Prateek Jain, and Praneeth Netrapalli.
493"
REFERENCES,0.3944055944055944,"The pitfalls of simplicity bias in neural networks. Advances in Neural Information Processing
494"
REFERENCES,0.3951048951048951,"Systems, 33:9573–9585, 2020.
495"
REFERENCES,0.3958041958041958,"[39] Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay
496"
REFERENCES,0.3965034965034965,"Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, Tony Lee,
497"
REFERENCES,0.3972027972027972,"Etienne David, Ian Stavness, Wei Guo, Berton Earnshaw, Imran Haque, Sara M Beery, Jure
498"
REFERENCES,0.3979020979020979,"Leskovec, Anshul Kundaje, Emma Pierson, Sergey Levine, Chelsea Finn, and Percy Liang.
499"
REFERENCES,0.3986013986013986,"Wilds: A benchmark of in-the-wild distribution shifts. In Marina Meila and Tong Zhang,
500"
REFERENCES,0.3993006993006993,"editors, Proceedings of the 38th International Conference on Machine Learning, volume 139 of
501"
REFERENCES,0.4,"Proceedings of Machine Learning Research, pages 5637–5664. PMLR, 18–24 Jul 2021. URL
502"
REFERENCES,0.4006993006993007,"https://proceedings.mlr.press/v139/koh21a.html.
503"
REFERENCES,0.4013986013986014,"[40] Sara Beery, Grant Van Horn, and Pietro Perona. Recognition in terra incognita. In Proceedings
504"
REFERENCES,0.4020979020979021,"of the European Conference on Computer Vision (ECCV), September 2018.
505"
REFERENCES,0.4027972027972028,"A
Related Work
506"
REFERENCES,0.4034965034965035,"Robustness to spurious correlation is a critical concern across various machine learning subfields.
507"
REFERENCES,0.4041958041958042,"It is a form of out-of-distribution generalization [31] where the distribution shift arises from the
508"
REFERENCES,0.4048951048951049,"disproportionate representation of minority groups—those instances that are devoid of the correlated
509"
REFERENCES,0.40559440559440557,"spurious patterns associated with their labels [4]. The issue of spurious correlation also intersects
510"
REFERENCES,0.4062937062937063,"with the discourse on fairness in machine learning. [32, 33].
511"
REFERENCES,0.406993006993007,"Past studies have proposed a range of strategies to mitigate the models’ reliance on spurious correla-
512"
REFERENCES,0.4076923076923077,"tion. Broadly speaking, these methods can be categorized according to the degree of supervision they
513"
REFERENCES,0.4083916083916084,"require regarding group labels.
514"
REFERENCES,0.4090909090909091,"Invariant learning (IL) methods [18, 34, 35] operate under the assumption of having access to a
515"
REFERENCES,0.4097902097902098,"collection of environments that comprise group shift. By imposing invariant conditions on these envi-
516"
REFERENCES,0.4104895104895105,"ronments, IL methods strive to create classifiers robust against group-sensitive features. IRM [18] is
517"
REFERENCES,0.4111888111888112,"designed to learn a feature extractor, which, when utilized, guarantees the existence of a classifier that
518"
REFERENCES,0.41188811188811186,"would be optimal in all training environments. VREx [34] aims to decrease the risk variance among
519"
REFERENCES,0.4125874125874126,"different training environments. PGI [36] works by minimizing the distance between the expected
520"
REFERENCES,0.4132867132867133,"softmax distribution of labels, conditioned on inputs across both majority and minority environments.
521"
REFERENCES,0.413986013986014,"Lastly, Fishr [35] focuses on bringing the variance of risk gradients closer together across different
522"
REFERENCES,0.41468531468531467,"training environments. For scenarios which environments are not available, environment inference
523"
REFERENCES,0.4153846153846154,"methods [12, 22] are used to obtain a set of environments. Creager et al. [12] introduce environment
524"
REFERENCES,0.4160839160839161,"inference for invariant learning (EIIL), which tries to partition samples into two groups such that the
525"
REFERENCES,0.4167832167832168,"objective of IRM [18] is maximized. HRM [22] aims to optimize both an environment inference
526"
REFERENCES,0.41748251748251747,"module and an invariant prediction module jointly, with the goal of achieving an invariant predictor.
527"
REFERENCES,0.41818181818181815,"When group annotations are accessible, various methods leverage this information to equalize the
528"
REFERENCES,0.4188811188811189,"impact of different groups on the model’s loss. The Group Distributionally Robust Optimization
529"
REFERENCES,0.4195804195804196,"(GDRO) approach [7], for instance, focuses on optimizing the loss for the worst-performing group
530"
REFERENCES,0.42027972027972027,"during training. Kirichenko et al. [1] has shown that models can still learn and extract core data
531"
REFERENCES,0.42097902097902096,"features even in the presence high spurious correlation. Consequently, They suggest that retraining
532"
REFERENCES,0.4216783216783217,"just the last layer of a model initially trained with Empirical Risk Minimization (ERM) can effectively
533"
REFERENCES,0.4223776223776224,"reduce reliance on spurious correlation for predicting class labels. This method, termed Deep Feature
534"
REFERENCES,0.4230769230769231,"Re-weighting (DFR), has been validated as not only highly effective but also significantly more
535"
REFERENCES,0.42377622377622376,"efficient than earlier techniques that necessitated retraining the full model [8, 7]. However, availability
536"
REFERENCES,0.4244755244755245,"of group annotations is considered a serious restrictive assumption.
537"
REFERENCES,0.4251748251748252,"Several recent studies have endeavored to enhance model robustness against spurious correlation,
538"
REFERENCES,0.4258741258741259,"even in the absence of group annotations [5, 24, 9, 2, 6]. Liu et al. [5] introduce a two-stage method
539"
REFERENCES,0.42657342657342656,"that involves training a model using ERM for a number of epochs before retraining it to give more
540"
REFERENCES,0.42727272727272725,"weight to misclassified samples. The study by Zhang et al. [24] employs the same two-stage training
541"
REFERENCES,0.427972027972028,"process, but with a twist for the second stage: they utilize contrastive methods. The goal is to
542"
REFERENCES,0.4286713286713287,"bring samples from the same class but with divergent predictions closer in the feature space, while
543"
REFERENCES,0.42937062937062936,"simultaneously increasing the separation between samples from different classes that have similar
544"
REFERENCES,0.43006993006993005,"predictions. Another method, known as automatic feature reweighting (AFR) [9], reweights the last
545"
REFERENCES,0.4307692307692308,"layer of an ERM-pretrained model to favor samples that the original model was less accurate on.
546"
REFERENCES,0.4314685314685315,"LaBonte et al. [2] refine the last layer of an ERM-trained model through class-balanced finetuning,
547"
REFERENCES,0.43216783216783217,"identifying challenging data points by comparing the classifier’s predictions with those of an early-
548"
REFERENCES,0.43286713286713285,"stopped version. While these methods have significantly reduced the reliance on group annotations,
549"
REFERENCES,0.43356643356643354,"some are still required for validation and model selection. This remains a constraint, particularly
550"
REFERENCES,0.4342657342657343,"when the spurious correlation is completely unknown.
551"
REFERENCES,0.43496503496503497,"For making a trained model robust to spurious correlation with zero group annotations, recently,
552"
REFERENCES,0.43566433566433566,"LaBonte et al. [2] have empirically demonstrated that the class-balanced retraining of a model
553"
REFERENCES,0.43636363636363634,"pretrained with ERM can effectively improve the WGA for certain datasets. However, this approach
554"
REFERENCES,0.4370629370629371,"fails in datasets with a high degree of spurious correlation.
555"
REFERENCES,0.43776223776223777,"Table 3: The average and variation percentage (%)(across 3 seeds) of group shift between the
inferred environments using EIIL [12] for each class, which is the absolute difference between the
proportion of a minority group in the two environments of a class. Higher group shift indicates better
separation of environments. In most cases, a significant group shift is observed between the inferred
environments."
REFERENCES,0.43846153846153846,"Class No.
Dataset"
REFERENCES,0.43916083916083914,"Waterbirds
CelebA
UrbanCars"
REFERENCES,0.4398601398601399,"0
16.6±0.7
3.6±0.2
17.7±1.2, 23.5±0.1, 62.1±1.9
1
50.5±0.3
14.1±0.9
40.7±7.9, 13.8±0.1, 19.2±3.9"
REFERENCES,0.4405594405594406,"B
Environment Inference for Invariant Learning
556"
REFERENCES,0.44125874125874126,"Consider the training dataset Dtr = {(x(i), y(i))|x(i) ∈X, y(i) ∈Y}, where X and Y represent the
557"
REFERENCES,0.44195804195804195,"input and output spaces, respectively. This dataset can be partitioned into different environments
558"
REFERENCES,0.44265734265734263,"Etr = {e1, ..., en}, such that for any i ̸= j, the data distribution in ei and ej differs. The objective
559"
REFERENCES,0.4433566433566434,"of invariant learning is to train a predictor that performs consistently across all environments in Etr.
560"
REFERENCES,0.44405594405594406,"Under certain conditions, this predictor is also expected to perform well on etst, a test environment
561"
REFERENCES,0.44475524475524475,"with a distribution distinct from the training data. Invariant Risk Minimization (IRM) [18] approaches
562"
REFERENCES,0.44545454545454544,"this problem by learning a feature extractor Φ(.) such that a classifier ω(.) exists, where ω ◦Φ(.)
563"
REFERENCES,0.4461538461538462,"performs consistently across all training environments. The practical implementation of the IRM
564"
REFERENCES,0.44685314685314687,"objective is to minimize
565
X"
REFERENCES,0.44755244755244755,"e∈Etr
Re(Φ) + λ||∇¯ωRe(¯ω ◦Φ)||2,
(2)"
REFERENCES,0.44825174825174824,"where ¯ω is a constant scalar with a value of 1.0, λ is a hyperparameter, and Re(f)
=
566"
REFERENCES,0.4489510489510489,"E(x,y)∼pe[l(f(x), y)] is referred to as the risk on environment e.
567"
REFERENCES,0.44965034965034967,"In real-world scenarios, training environments might not always be available. To address this,
568"
REFERENCES,0.45034965034965035,"Environment Inference for Invariant Learning (EIIL) [12] partitions samples into two environments
569"
REFERENCES,0.45104895104895104,"in a way that maximizes the objective in Eq 2.
570"
REFERENCES,0.45174825174825173,"During the training phase, the EIIL algorithm replaces the hard assignment of environments to
571"
REFERENCES,0.45244755244755247,"samples with a soft assignment qi(e) = p(e|(x(i), y(i)), where qi is learnable. Consequently, the
572"
REFERENCES,0.45314685314685316,"relaxed version of the risk function is defined as ˜Re(Φ) =
1
N
PN
i qi(e)[l(Φ(x(i)), y(i))]. Given a
573"
REFERENCES,0.45384615384615384,"model Φ that has been trained with ERM on the dataset, EIIL optimizes
574"
REFERENCES,0.45454545454545453,"q∗= arg max
q
||∇¯ω ˜Re(¯ω ◦Φ)||.
(3)"
REFERENCES,0.4552447552447552,"As discussed in Creager et al. [12], using a biased base model Φ could lead to environments exhibiting
575"
REFERENCES,0.45594405594405596,"varying degrees of spurious correlation. During the inference phase, the soft assignment is converted
576"
REFERENCES,0.45664335664335665,"to a hard assignment. The average group shift between the inferred environments using EIIL is
577"
REFERENCES,0.45734265734265733,"illustrated in Table 3.
578"
REFERENCES,0.458041958041958,"C
Theoretical Analysis
579"
REFERENCES,0.45874125874125876,"In this section, we establish a more formal description of loss-based sampling for balanced dataset
580"
REFERENCES,0.45944055944055945,"creation and then prove it. We thoroughly analyze the close relationship between the availability of
581"
REFERENCES,0.46013986013986014,"the balanced dataset and the gap between spurious features of minority and majority groups.
582"
REFERENCES,0.4608391608391608,"Consider a binary classification problem with a cross-entropy loss function. Let logits be denoted
583"
REFERENCES,0.46153846153846156,"as L. Because loss is a monotonic function of logits, the tails of the distribution of loss across
584"
REFERENCES,0.46223776223776225,"samples are equivalent to that of the logits in each class. We assume that in feature space (output
585"
REFERENCES,0.46293706293706294,"of gθ) samples from the minority and majority of a class are derived from Gaussian distributions
586"
REFERENCES,0.4636363636363636,"N(hmin, t2
minId) and N(hmaj, t2
majId), respectively. Before diving into the group balance problem we
587"
REFERENCES,0.4643356643356643,"initially show that the distribution of minority and majority samples in the logit space (output of hϕ)
588"
REFERENCES,0.46503496503496505,"are Gaussian too.
589"
REFERENCES,0.46573426573426574,"Lemma C.1 (Gaussain Distribution of Logits). if Z ∼N(h, t2Id) in feature space and W ∈Rd
590"
REFERENCES,0.4664335664335664,"then logits L = ⟨W, Z⟩∼N
 
Wh, t2 ∥W∥2 
591"
REFERENCES,0.4671328671328671,"Proof. Let Z ∼N(h, t2Id).
592"
REFERENCES,0.46783216783216786,"Consider the linear combination L = ⟨W, Z⟩= W T Z, where W ∈Rd which is a univariate
593"
REFERENCES,0.46853146853146854,"gaussian.
594"
REFERENCES,0.46923076923076923,"To find the distribution of L, we need to determine its mean and variance.
595"
MEAN OF L,0.4699300699300699,"1. Mean of L
596"
MEAN OF L,0.4706293706293706,"E[L] = E[⟨W, Z⟩] = E[W T Z] = W T E[Z] = W T h = ⟨W, h⟩."
MEAN OF L,0.47132867132867134,"Therefore, the mean of L is Wh.
597"
MEAN OF L,0.47202797202797203,"2. Variance of L:
598"
MEAN OF L,0.4727272727272727,"The variance of L can be computed using the properties of covariance. Recall that if Z ∼N(h, t2Id),
599"
MEAN OF L,0.4734265734265734,"then the covariance matrix of Z is t2Id.
600"
MEAN OF L,0.47412587412587415,"The variance of the linear combination L = W T Z is given by:
601"
MEAN OF L,0.47482517482517483,Var(L) = Var(W T Z) = W T Cov(Z)W.
MEAN OF L,0.4755244755244755,"Given Cov(Z) = t2Id, we have:
602"
MEAN OF L,0.4762237762237762,"Var(L) = W T (t2Id)W = t2W T IdW = t2 ∥W∥2 ,"
MEAN OF L,0.47692307692307695,"where ∥W∥denotes the Euclidean norm of W.
603"
MEAN OF L,0.47762237762237764,"Combining the mean and variance results, we conclude that L is normally distributed with mean Wh
604"
MEAN OF L,0.4783216783216783,"and variance t2 ∥W∥2:
605"
MEAN OF L,0.479020979020979,"L = ⟨W, Z⟩∼N(Wh, t2 ∥W∥2)."
MEAN OF L,0.4797202797202797,"Thus, we have proved that if Z ∼N(h, t2Id), then the logits L = ⟨W, Z⟩follow the distribution
606"
MEAN OF L,0.48041958041958044,"N(Wh, t2 ∥W∥2).
607"
MEAN OF L,0.4811188811188811,"From now on, we consider N(µmin, σ2
min) and N(µmaj, σ2
maj) as the distribution of minority and
608"
MEAN OF L,0.4818181818181818,"majority samples in logits space.
609"
MEAN OF L,0.4825174825174825,"Next, we prove the more formal version of the main proposition 3.1 which describes the existence of
610"
MEAN OF L,0.48321678321678324,"a balanced dataset, only after we define a key concept, proportional density difference (illustrated in
611"
MEAN OF L,0.48391608391608393,"figure 4) to outline our proof.
612"
MEAN OF L,0.4846153846153846,"Definition C.1 (Proportional Density Difference). For any interval I = (a, b] and a mixture dis-
tribution εP1(x) + (1 −ε)P2(x), proportional density difference is defined by the difference of
accumulation of two component distributions in the interval I and is denoted by ∆εPmixture(I)."
MEAN OF L,0.4853146853146853,"∆εPmixture(I)
∆= εP1
 
x ∈I

−(1 −ε)P2
 
x ∈I
"
MEAN OF L,0.486013986013986,"Definition C.2 (Tail Proportional Density Difference). For a mixture distribution εP1(x) + (1 −
613"
MEAN OF L,0.48671328671328673,"ε)P2(x), we define tailL(α) as ∆εPmixture

(−∞, α]

and tailR(β) as −∆εPmixture

(β, +∞)

.
614"
MEAN OF L,0.4874125874125874,Corollary C.1.
MEAN OF L,0.4881118881118881,tailL(α) = εF 1(α) −(1 −ε)F 2(β)
MEAN OF L,0.4888111888111888,"tailR(α) = (1 −ε)

1 −F 2(β)

−ε

1 −F 1(β)
"
MEAN OF L,0.48951048951048953,"where F 1 and F 2 are CDF of two component distributions.
615"
MEAN OF L,0.4902097902097902,Proportional Density Diﬀerence I ϵ=0.4
MEAN OF L,0.4909090909090909,"majority
minority (a) β
α"
MEAN OF L,0.4916083916083916,"tailR(β)
tailL(α) ϵ=0.4"
MEAN OF L,0.49230769230769234,"majority
minority (b)"
MEAN OF L,0.493006993006993,"Figure 4: (a) Illustration of proportion density difference C.1, (b) equation of tailL(α) = tailR(β)"
MEAN OF L,0.4937062937062937,at C.2.
MEAN OF L,0.4944055944055944,"Proposition C.1 (Feasiblity Of Loss-based Group Balancing). Suppose that L is derived from
616"
MEAN OF L,0.4951048951048951,"the mixture of two distributions N(µmin, σ2
min) and N(µmaj, σ2
maj) with proportion of ε and 1 −ε,
617"
MEAN OF L,0.4958041958041958,"respectively, where ε ≤1"
MEAN OF L,0.4965034965034965,"2. There exists α and β such that restricting L to the α-left and β-right tails
618"
MEAN OF L,0.4972027972027972,"of its distribution results in a group-balanced distribution if and only if σmin ≥σmaj or
619"
MEAN OF L,0.4979020979020979,"tailL(−B +
√"
MEAN OF L,0.4986013986013986,"∆
2A
) > 0
(4)"
MEAN OF L,0.4993006993006993,"and
620"
MEAN OF L,0.5,ϵ ≥sigmoid 
MEAN OF L,0.5006993006993007,"−(µmaj −µmin
2"
MEAN OF L,0.5013986013986014,"2(σ2
maj −σ2
min) −log
σmaj σmin ! (5)"
MEAN OF L,0.5020979020979021,"where A =

1
2σ2
maj −
1
2σ2
min"
MEAN OF L,0.5027972027972027,"
, B =

µmin
σ2
min −µmaj"
MEAN OF L,0.5034965034965035,"σ2
maj"
MEAN OF L,0.5041958041958042,"
and ∆=
(µmin−µmaj)2"
MEAN OF L,0.5048951048951049,"σ2
minσ2
maj
−4
h
log

σmaj
σmin"
MEAN OF L,0.5055944055944056,"
+
621"
MEAN OF L,0.5062937062937063,"log

ϵ
1−ϵ
ih
1
2σ2
maj −
1
2σ2
min"
MEAN OF L,0.506993006993007,"i
.
622"
MEAN OF L,0.5076923076923077,"Proof outline
Our proof proceeds with three steps. First, we reformulate the theorem as an equality
623"
MEAN OF L,0.5083916083916084,"of left- and right-tail proportional distribution differences. In other words, we show that the more
624"
MEAN OF L,0.509090909090909,"mass the minority distribution has on one tail, the more mass the majority distribution must have on
625"
MEAN OF L,0.5097902097902098,"the other tail. Afterward, supposing µmin < µmaj WOLG, we propose a proper range for β values
626"
MEAN OF L,0.5104895104895105,"on the right tail. We show that when σmaj ≤σmin, values for α trivially exist that can overcome the
627"
MEAN OF L,0.5111888111888112,"imbalance between the two distributions. In the last step, for the case in which the variance of the
628"
MEAN OF L,0.5118881118881119,"majority is higher than the minority, we discuss a necessary and sufficient condition for the existence
629"
MEAN OF L,0.5125874125874126,"of α and β based on the left-tail proportional density difference using the properties of its derivative
630"
MEAN OF L,0.5132867132867133,"with respect to α.
631"
MEAN OF L,0.513986013986014,"Step 1
Reformulating the problem based on proportional distribution difference.
632"
MEAN OF L,0.5146853146853146,"We introduce a utility random variable Logit Value Tier as T, which is defined as a function of a
633"
MEAN OF L,0.5153846153846153,"random variable L.
634"
MEAN OF L,0.5160839160839161,"Tα,β = 
 "
MEAN OF L,0.5167832167832168,"High
if L ≥β
Mid
if α < L < β
Low
if L ≤α
(6)"
MEAN OF L,0.5174825174825175,"We can rewrite the problem in formal form as finding an α and β which satisfies the following
635"
MEAN OF L,0.5181818181818182,"equation:
636"
MEAN OF L,0.5188811188811189,"P

g = min"
MEAN OF L,0.5195804195804196,"Tα,β ̸= Mid

= P

g = maj"
MEAN OF L,0.5202797202797202,"Tα,β ̸= Mid

(7)"
MEAN OF L,0.5209790209790209,"Equation 5 now can be rewritten to a more suitable form:
637"
MEAN OF L,0.5216783216783217,"P

g = min"
MEAN OF L,0.5223776223776224,"Tα,β ̸= Mid

= P

g = maj"
MEAN OF L,0.5230769230769231,"Tα,β ̸= Mid

(8)"
MEAN OF L,0.5237762237762238,"⇐⇒
P

Tα,β ̸= Mid
g = min"
MEAN OF L,0.5244755244755245,"
P
 
g = min "
MEAN OF L,0.5251748251748252,"P

Tα,β ̸= Mid

=
P

Tα,β ̸= Mid|g = maj"
MEAN OF L,0.5258741258741259,"
P
 
g = maj "
MEAN OF L,0.5265734265734265,"P

Tα,β ̸= Mid

(9)"
MEAN OF L,0.5272727272727272,"⇐⇒
P

Tα,β ̸= Mid
g = min"
MEAN OF L,0.527972027972028,"
P
 
g = min"
MEAN OF L,0.5286713286713287,"
= P

Tα,β ̸= Mid
g = maj"
MEAN OF L,0.5293706293706294,"
P
 
g = maj  (10)"
MEAN OF L,0.5300699300699301,"⇐⇒
εP

Tα,β ̸= Mid
g = min"
MEAN OF L,0.5307692307692308,"
= (1 −ε)P

Tα,β ̸= Mid
g = maj"
MEAN OF L,0.5314685314685315,"
(11)"
MEAN OF L,0.5321678321678321,"⇐⇒
ε

P

Tα,β = Low
g = min"
MEAN OF L,0.5328671328671328,"
+ P

Tα,β = High
g = min"
MEAN OF L,0.5335664335664335,"
=
(12)"
MEAN OF L,0.5342657342657343,"(1 −ε)

P

Tα,β = Low
g = maj"
MEAN OF L,0.534965034965035,"
+ P

Tα,β = High
g = maj"
MEAN OF L,0.5356643356643357,"
(13)"
MEAN OF L,0.5363636363636364,"⇐⇒
ε

P

L ≤α
g = min"
MEAN OF L,0.5370629370629371,"
+ P

L ≥β
g =min"
MEAN OF L,0.5377622377622377,"
=
(14)"
MEAN OF L,0.5384615384615384,"(1 −ε)

P

L ≤α
g = maj"
MEAN OF L,0.5391608391608391,"
+ P

L ≥β
g = maj"
MEAN OF L,0.5398601398601398,"
(15)"
MEAN OF L,0.5405594405594406,"⇐⇒
ε

F min(α) +

1 −F min(β)

= (1−ε)

F maj(α) +

1 −F maj(β)

(16)"
MEAN OF L,0.5412587412587413,"⇐⇒
εF min(α) −(1 −ε)F maj(α) = (1 −ε)
h
1 −F maj(β)
i
−ε
h
1 −F min(β)
i
(17)"
MEAN OF L,0.541958041958042,"We can see the left side of equation 17 is just a function of alpha. The same goes for the right side of
638"
MEAN OF L,0.5426573426573427,"the equation which is a function of β.
639"
MEAN OF L,0.5433566433566434,"Rewriting the left side of the equation as tailL(α) and right side as tailR(β), the problem is now
640"
MEAN OF L,0.544055944055944,"reduced to finding an α and β that satisfies
641"
MEAN OF L,0.5447552447552447,"tailL(α) = tailR(β)
(18)"
MEAN OF L,0.5454545454545454,"which is shown in figure 4.
642"
MEAN OF L,0.5461538461538461,"Before reaching out to step two we discuss the properties of tailL and tailR in Lemma C.2.
643"
MEAN OF L,0.5468531468531469,"Lemma C.2. tailL(α) and tailR(β) are continuous functions and limα→−∞tailL(α) = 0,
644"
MEAN OF L,0.5475524475524476,"limα→+∞tailL(α) = 2ε −1 < 0 , limβ→+∞tailR(β) = 0 and limβ→−∞tailR(β) = 1 −2ε > 0.
645 646"
MEAN OF L,0.5482517482517483,"Proof. Simply proved by the definition of tail functions and properties of CDF.
647"
MEAN OF L,0.548951048951049,"Step 2
Solving the equation 18 for simple cases.
648"
MEAN OF L,0.5496503496503496,Lemma C.3. tailR(µmaj) > 1
MEAN OF L,0.5503496503496503,"2 −ε ≥0
649"
MEAN OF L,0.551048951048951,Proof.
MEAN OF L,0.5517482517482517,"tailR(µmaj) = (1 −ε)
h
1 −F maj(µmaj)
i
−ε
h
1 −F min(µmaj)
i
(19)"
MEAN OF L,0.5524475524475524,"= (1 −ε)
h
1 −ϕ(0)
i
−ε
h
1 −ϕ
 µmaj −µmin σmin"
MEAN OF L,0.5531468531468532,"i
(20)"
MEAN OF L,0.5538461538461539,> (1 −ε)
MEAN OF L,0.5545454545454546,"2
−ε
 
1 −1"
MEAN OF L,0.5552447552447553,"2

= 1 −2ε 2
= 1"
MEAN OF L,0.5559440559440559,"2 −ε
(21) 650"
MEAN OF L,0.5566433566433566,"Corollary C.2. Because tailR is continuous and limβ→+∞tailR(β) = 0, based on the mean value
651"
MEAN OF L,0.5573426573426573,"theorem, any value between zero and (1−2ε)"
MEAN OF L,0.558041958041958,"2
is obtainable by selecting a β in [µ2, +∞).
652"
MEAN OF L,0.5587412587412588,"According to the previous corollary C.2 finding a positive tailL(α) will satisfy our need. to find a
653"
MEAN OF L,0.5594405594405595,"suitable point, we employ derivatives and properties of relative PDFs to maximize tailL(α) and find
654"
MEAN OF L,0.5601398601398602,"a positive value.
655"
MEAN OF L,0.5608391608391609,dtailL(α)
MEAN OF L,0.5615384615384615,"dα
= εf min(α) −(1 −ε)f maj(α) = εf maj(α)
hf min(α)"
MEAN OF L,0.5622377622377622,f maj(α) −1 −ε ε
MEAN OF L,0.5629370629370629,"i
(22)"
MEAN OF L,0.5636363636363636,The term [ f min(α)
MEAN OF L,0.5643356643356643,f maj(α) −1−ε
MEAN OF L,0.5650349650349651,"ε ] has the same sign with derivative of tailL(α), also it’s roots are critical
656"
MEAN OF L,0.5657342657342658,"points of tailL, analyzing characteristics of log f min(α)"
MEAN OF L,0.5664335664335665,"f maj(α) is the key insight to find a proper α value.
657"
MEAN OF L,0.5671328671328671,"log f min(α) −log f maj(α) = log
1 −ϵ ϵ "
MEAN OF L,0.5678321678321678,"⇒log
σmaj σmin"
MEAN OF L,0.5685314685314685,"
−log
1 −ϵ ϵ"
MEAN OF L,0.5692307692307692,"
−(α −µmin)2 2σ2 min"
MEAN OF L,0.5699300699300699,+ (α −µmaj)2 2σ2 maj = 0
MEAN OF L,0.5706293706293706,"⇒

1
2σ2 maj"
MEAN OF L,0.5713286713286714,"−
1
2σ2 min"
MEAN OF L,0.5720279720279721,"
α2 +
µmin σ2 min −µmaj σ2 maj"
MEAN OF L,0.5727272727272728,"
α +
h µ2"
MEAN OF L,0.5734265734265734,"maj
2σ2 maj −µ2"
MEAN OF L,0.5741258741258741,"min
2σ2 min"
MEAN OF L,0.5748251748251748,"+ log
σmaj σmin"
MEAN OF L,0.5755244755244755,"
+ log

ϵ
1 −ϵ"
MEAN OF L,0.5762237762237762,"i
= 0"
MEAN OF L,0.5769230769230769,"Because limα→−∞tailL(α) = 0 and limβ→+∞tailR(β) < 0 to have a positive tailL(α) we need
658"
MEAN OF L,0.5776223776223777,to have an interval which dtailL(α)
MEAN OF L,0.5783216783216784,"dα
is positive, for a second degree polynomial like ax2 + bx + c to
659"
MEAN OF L,0.579020979020979,"have positive value, either a ≥0 or ∆> 0, in our case a is

1
σ2"
MEAN OF L,0.5797202797202797,"maj −
1
σ2 min"
MEAN OF L,0.5804195804195804,"
. if σmin ≥σmaj then a ≥0
660"
MEAN OF L,0.5811188811188811,"and the minority CDF function will dominate the majority CDF function in the left-side tail and by
661"
MEAN OF L,0.5818181818181818,"choosing a negative number with big enough absolute value for alpha and tailL(α) will be positive.
662"
MEAN OF L,0.5825174825174825,"Step 3
Solving equation 18 for special case σmin < σmaj In case of σmin ≤σmaj, having ∆> 0
663"
MEAN OF L,0.5832167832167832,"is a necessary condition, also derivative of tailL(α) is only positive in ( −b−
√"
MEAN OF L,0.583916083916084,"∆
2a
, −b+
√"
MEAN OF L,0.5846153846153846,"∆
2a
) so the
664"
MEAN OF L,0.5853146853146853,"maximum of tailL is either in −∞or in −b+
√"
MEAN OF L,0.586013986013986,"∆
2a
. Having tailL( −b+
√"
MEAN OF L,0.5867132867132867,"∆
2a
) > 0 next to ∆> 0
665"
MEAN OF L,0.5874125874125874,"condition, would be the necessary and also sufficient in this case.
666"
MEAN OF L,0.5881118881118881,B2 = µ2
MEAN OF L,0.5888111888111888,"min
σ4 min +
µ2"
MEAN OF L,0.5895104895104896,"maj
σ4 maj"
MEAN OF L,0.5902097902097903,−2µmajµmin σ2 majσ2 min
MEAN OF L,0.5909090909090909,4AC = µ2
MEAN OF L,0.5916083916083916,"min
σ4 min −
µ2"
MEAN OF L,0.5923076923076923,"min
σ2 majσ2 min −
µ2"
MEAN OF L,0.593006993006993,"maj
σ2 majσ2 min +
µ2"
MEAN OF L,0.5937062937062937,"maj
σ4 maj"
MEAN OF L,0.5944055944055944,"+ 4
h
log
σmaj σmin"
MEAN OF L,0.5951048951048951,"
+ log

ϵ
1 −ϵ"
MEAN OF L,0.5958041958041959,"ih
1
2σ2 maj"
MEAN OF L,0.5965034965034965,"−
1
2σ2 min i =0.35"
MEAN OF L,0.5972027972027972,"majority
minority (a) =0.4"
MEAN OF L,0.5979020979020979,"majority
minority (b) =0.45"
MEAN OF L,0.5986013986013986,"majority
minority (c)"
MEAN OF L,0.5993006993006993,"Figure 5: Tail thresholds for three cases: (a) minority group variance is less than majority (σmin <
σmaj), (b) the variance of two groups are equal (σmin = σmaj) and (c) the variance of the minority
group is more than majority (σmin > σmaj)."
MEAN OF L,0.6,∆= (µmin −µmaj)2 σ2 minσ2 maj
MEAN OF L,0.6006993006993007,"−4
h
log
σmaj σmin"
MEAN OF L,0.6013986013986014,"
+ log

ϵ
1 −ϵ"
MEAN OF L,0.6020979020979021,"ih
1
2σ2 maj"
MEAN OF L,0.6027972027972028,"−
1
2σ2 min i
≥0"
MEAN OF L,0.6034965034965035,"⇐⇒(µmin −µmaj)2 ≥2
h
log
1 −ϵ ϵ"
MEAN OF L,0.6041958041958042,"
−log
σmaj σmin"
MEAN OF L,0.6048951048951049,"ih
σ2"
MEAN OF L,0.6055944055944056,maj −σ2 min i
MEAN OF L,0.6062937062937063,⇐⇒ϵ ≥sigmoid 
MEAN OF L,0.606993006993007,−(µmaj −µmin 2 2(σ2
MEAN OF L,0.6076923076923076,maj −σ2
MEAN OF L,0.6083916083916084,"min) −log
σmaj σmin !"
MEAN OF L,0.6090909090909091,"Next, we investigate properties of the conditions of the proposition C.1 in case of σmaj < σmin.
667"
MEAN OF L,0.6097902097902098,"Schematic interpretation of these conditions is presented in figure 6.
668"
MEAN OF L,0.6104895104895105,"• As equation 5 indicates, the minority group is not allowed to be too underrepresented. This
669"
MEAN OF L,0.6111888111888112,"especially has a direct relation with the difference of means. The more mean values of
670"
MEAN OF L,0.6118881118881119,"groups are different, the more imbalance can be mitigated through loss-based sampling.
671"
MEAN OF L,0.6125874125874126,"Mean value difference is especially affected by the spurious correlation, it escalates as the
672"
MEAN OF L,0.6132867132867132,"model relies on spurious correlation and also when the spurious features between groups are
673"
MEAN OF L,0.6139860139860139,"too different.
674"
MEAN OF L,0.6146853146853147,"• On the other hand condition 4 is more complex and doesn’t have a simple closed form, we
675"
MEAN OF L,0.6153846153846154,"analytically describe its behaviors by fixating the means and calculating the valid values for
676"
MEAN OF L,0.6160839160839161,"ε. As the results show in figure 6, most of ε are feasible in for σmin < ∆µ as we can see the
677"
MEAN OF L,0.6167832167832168,"possible region declines with an increase of σmin and valid ε values cease to exist.
678 max S1 S2 > 0 =0.27"
MEAN OF L,0.6174825174825175,"majority
minority (a)"
MEAN OF L,0.6181818181818182,"0
1
2
3
4
5
σmin 0 1 2 3 4 5 σmaj"
MEAN OF L,0.6188811188811189,0.0000
MEAN OF L,0.6195804195804195,0.1053
MEAN OF L,0.6202797202797202,0.2105
MEAN OF L,0.620979020979021,0.3158
MEAN OF L,0.6216783216783217,0.4211
MEAN OF L,0.6223776223776224,0.5263
MEAN OF L,0.6230769230769231,0.6316
MEAN OF L,0.6237762237762238,0.7368
MEAN OF L,0.6244755244755245,0.8421
MEAN OF L,0.6251748251748251,0.9474 (b)
MEAN OF L,0.6258741258741258,"0
1
2
3
4
5
σmin 0 1 2 3 4 5 σmaj"
MEAN OF L,0.6265734265734266,0.0000
MEAN OF L,0.6272727272727273,0.1053
MEAN OF L,0.627972027972028,0.2105
MEAN OF L,0.6286713286713287,0.3158
MEAN OF L,0.6293706293706294,0.4211
MEAN OF L,0.6300699300699301,0.5263
MEAN OF L,0.6307692307692307,0.6316
MEAN OF L,0.6314685314685314,0.7368
MEAN OF L,0.6321678321678321,0.8421
MEAN OF L,0.6328671328671329,0.9474 (d)
MEAN OF L,0.6335664335664336,"0
1
2
3
4
5
σmin 0 1 2 3 4 5 σmaj"
MEAN OF L,0.6342657342657343,0.0000
MEAN OF L,0.634965034965035,0.1053
MEAN OF L,0.6356643356643357,0.2105
MEAN OF L,0.6363636363636364,0.3158
MEAN OF L,0.637062937062937,0.4211
MEAN OF L,0.6377622377622377,0.5263
MEAN OF L,0.6384615384615384,0.6316
MEAN OF L,0.6391608391608392,0.7368
MEAN OF L,0.6398601398601399,0.8421
MEAN OF L,0.6405594405594406,0.9474 (c)
MEAN OF L,0.6412587412587413,"Figure 6: (a) Conditions if σmin > σmaj, (b), (c), (d) Minimum, maximum and interval length of
feasible ε values across (σmin, σmaj) field for µmin = 0, µmaj = 1."
MEAN OF L,0.641958041958042,"Table 4: A comparison of the various methods, ours included, on spurious correlation datasets. The
Group Info column indicates if each method utilizes group labels of the training/validation data,
with ✓✓denoting that group information is employed during both the training and validation stages.
Both the average test accuracy and worst test group accuracy are reported. The mean and standard
deviation are calculated over three runs with different seeds. The numbers in bold represent the
highest results among all methods, while the underlined numbers represent the best results among
methods that do not require group annotation in the training phase."
MEAN OF L,0.6426573426573426,"Method
Group Info
Waterbirds
CelebA
UrbanCars"
MEAN OF L,0.6433566433566433,"Train/Val
Worst
Best
Worst
Best
Worst
Best"
MEAN OF L,0.644055944055944,"GDRO [7]
✓/✓
91.4
93.5
88.9
92.9
-
-
DFR [1]
✗/✓✓
92.9±0.2
94.2±0.4
88.3±1.1
91.3±0.3
79.6±2.22
87.5±0.6
GDRO + EIIL [12]
✗/✓
77.2±1
96.5±0.2
81.7±0.8
85.7±0.1
-
-
JTT [5]
✗/✓
86.7
93.3
81.1
88.0
-
-
AFR [9]
✗/✓
90.4±1.1
94.21.2
82.0±0.5
91.3±0.3
80.2±2.0
87.1±1.2
EVaLS-GL (Ours)
✗/✓
89.4±0.3
95.1±0.3
84.6±1.6
91.1±0.6
82.27±1.16
88.2±0.6"
MEAN OF L,0.6447552447552447,"ERM
✗/✗
66.4±2.3
90.3±0.5
47.4±2.3
95.5±0.0
18.67±2.01
76.5±4.6
EVaLS (Ours)
✗/✗
88.4±3.1
94.1±0.1
85.3±0.4
89.4±0.5
82.13±0.92
88.1±0.9"
MEAN OF L,0.6454545454545455,"Table 5: A comparison of the various methods, ours included, on CivilComments and MultiNLI.
The Group Info column indicates if each method utilizes group labels of the training/validation data,
with ✓✓denoting that group information is employed during both the training and validation stages.
Both the average test accuracy and worst test group accuracy are reported. The mean and standard
deviation are calculated over three runs with different seeds. The numbers in bold represent the
highest results among all methods, while the underlined numbers represent the best results among
methods that do not require group annotation in the training phase."
MEAN OF L,0.6461538461538462,"Method
Group Info
CivilComments
MultiNLI"
MEAN OF L,0.6468531468531469,"Train/Val
Worst
Best
Worst
Best"
MEAN OF L,0.6475524475524476,"GDRO [7]
✓/✓
69.9
88.9
77.7
81.4
DFR [1]
✗/✓✓
70.1±0.8
87.2±0.3
74.7±0.7
82.1±0.2
GDRO + EIIL [12]
✗/✓
67.0±2.4
90.5±0.2
-
-
JTT [5]
✗/✓
69.3
91.1
72.6
78.6
AFR [9]
✗/✓
68.7±0.6
89.8±0.6
73.4±0.6
81.4±0.2
EVaLS-GL (Ours)
✗/✓
80.5±0.4
88.0±0.4
75.1±1.2
81.6±0.2"
MEAN OF L,0.6482517482517482,"ERM
✗/✗
61.2±3.6
92.0±0.0
64.8±1.9
82.6±0.0"
MEAN OF L,0.6489510489510489,"D
Experimental Details
679"
MEAN OF L,0.6496503496503496,"D.1
Complete Results
680"
MEAN OF L,0.6503496503496503,"The complete results on Waterbirds, CelebA, and UrbanCars, in addition to complete results on
681"
MEAN OF L,0.651048951048951,"CivilComments and MultiNLI are reported in Tables 4 and 5 respectively. The results for all methods
682"
MEAN OF L,0.6517482517482518,"except Group DRO + EIIL on all datasets except UrbanCars are reported by Qiu et al. [9]. The
683"
MEAN OF L,0.6524475524475525,"results for Group DRO + EIIL are taken from Zhang et al. [24]. Also, the results of our method and
684"
MEAN OF L,0.6531468531468532,"DFR are shown in Table 6
685"
MEAN OF L,0.6538461538461539,"D.2
Dominoes-Colored-MNIST-FashionMNIST
686"
MEAN OF L,0.6545454545454545,"Dominoes-Colored-MNIST-FashionMNIST (Dominoes-CMF)
is a synthetic dataset. We adopt
687"
MEAN OF L,0.6552447552447552,"a similar approach to previous works [37, 38, 1] using a modified version of the Dominoes binary
688"
MEAN OF L,0.6559440559440559,"classification dataset. This dataset consists of images with the top half showing CIFAR-10 images
689"
MEAN OF L,0.6566433566433566,"[19], divided into two meaningful classes: vehicles (airplane, car, ship, truck) and animals (cat,
690"
MEAN OF L,0.6573426573426573,"dog, horse, deer). The bottom half displays either MNIST [20] images from classes {0 −3} or
691"
MEAN OF L,0.6580419580419581,"Fashion-MNIST [21] images from classes {T-shirt, Dress, Coat, Shirt}. The complex feature (top
692"
MEAN OF L,0.6587412587412588,"Table 6: A Comparison of ERM, DFR, EVaLS, and EVaLS-GL on the Dominoes-CMF Dataset. Both
the worst and average of test group accuracies are presented. The mean and standard deviation are
calculated based on runs with three distinct seeds."
MEAN OF L,0.6594405594405595,"Method
Worst
Average"
MEAN OF L,0.6601398601398601,"ERM
50.6±1.0
84.1±0.0
DFR
60.2±1.2
84.6±0.4
EVaLS-GL
63.6±1.3
78.7±1.5
EVaLS
67.1±4.2
78.6±2.0"
MEAN OF L,0.6608391608391608,"half) serves as the core feature and the simple feature (bottom half) is linearly separable and correlated
693"
MEAN OF L,0.6615384615384615,"with the class label at 75%. Furthermore, inspired by the approaches in Zhang et al. [24], Arjovsky
694"
MEAN OF L,0.6622377622377622,"et al. [18], we intentionally introduce an additional spurious attribute by artificially coloring a subset
695"
MEAN OF L,0.6629370629370629,"of images in the following manner: 90% of the bottom half images in class c1 are randomly assigned
696"
MEAN OF L,0.6636363636363637,"a red color, while 10% are assigned a green color, and vice versa for class c2. See Table 7 for more
697"
MEAN OF L,0.6643356643356644,details about the dataset statistics.
MEAN OF L,0.6650349650349651,"Table 7: Dominoes-CMF Dataset Statistics
Top part
Bottom part"
MEAN OF L,0.6657342657342658,"CIFAR-10 Class
Color
MNIST
Fashion-MNIST"
MEAN OF L,0.6664335664335664,"c1 (Vehicle)
Red
13,500
4,500
Green
1,500
500"
MEAN OF L,0.6671328671328671,"c2 (Animal)
Red
500
1,500
Green
4,500
13,500"
MEAN OF L,0.6678321678321678,"Total
40,000 698"
MEAN OF L,0.6685314685314685,"Table 8: ERM Accuracies on Dominoes-CMF Dataset. The mean and standard deviation are reported
based on three runs with different seeds."
MEAN OF L,0.6692307692307692,"Top part
Bottom part"
MEAN OF L,0.66993006993007,"CIFAR-10 Class
Color
MNIST
Fashion-MNIST"
MEAN OF L,0.6706293706293707,"c1 (Vehicle)
Red
99.2±0.01%
95.21.1%
Green
84.5±2.4%
54.7±0.5%"
MEAN OF L,0.6713286713286714,"c2 (Animal)
Red
56.8±5.6%
86.7±2.4%
Green
96.2±0.5%
99.3±0.2%"
MEAN OF L,0.672027972027972,"D.3
Datasets
699"
MEAN OF L,0.6727272727272727,"Waterbirds [7]
The dataset comprises images of diverse bird species, classified into two categories:
700"
MEAN OF L,0.6734265734265734,"waterbirds and landbirds. Each image features a bird set against a backdrop of either water or land.
701"
MEAN OF L,0.6741258741258741,"Interestingly, the background scene acts as a spurious feature in this classification task. Waterbirds are
702"
MEAN OF L,0.6748251748251748,"primarily shown against water backgrounds, and landbirds against land backgrounds. Consequently,
703"
MEAN OF L,0.6755244755244755,"waterbirds on water and landbirds on land form the minority groups in the training data. It’s important
704"
MEAN OF L,0.6762237762237763,"to note that the validation dataset for waterbirds is group-balanced, meaning birds from each class are
705"
MEAN OF L,0.676923076923077,"equally represented against both water and land backgrounds. This dataset is mainly categorized as a
706"
MEAN OF L,0.6776223776223776,"spurious correlation dataset.
707"
MEAN OF L,0.6783216783216783,"CelebA [13]
is a widely used dataset in image classification tasks, featuring annotations for 40
708"
MEAN OF L,0.679020979020979,"binary facial attributes such as hair color, gender, and age. Hair color classification is particularly
709"
MEAN OF L,0.6797202797202797,"prominent in literature focusing on spurious correlation robustness. Notably, gender serves as a
710"
MEAN OF L,0.6804195804195804,"spurious attribute within this dataset, where a significant majority 94% of individuals with blond hair
711"
MEAN OF L,0.6811188811188811,"0
25
50
75
100
% of High-Loss Sample 0 5 10 15 20"
MEAN OF L,0.6818181818181818,% of Minority Samples
MEAN OF L,0.6825174825174826,"class 1
class 2
class 3"
MEAN OF L,0.6832167832167833,"0
25
50
75
100
% of Low-Loss Sample 40 60 80 100"
MEAN OF L,0.6839160839160839,% of Majority Samples
MEAN OF L,0.6846153846153846,"class 1
class 2
class 3"
MEAN OF L,0.6853146853146853,(a) MultiNLI
MEAN OF L,0.686013986013986,"0
20
40
60
80
100
% of High-Loss Sample 0 20 40 60 80"
MEAN OF L,0.6867132867132867,% of Minority Samples
MEAN OF L,0.6874125874125874,"class 1(group 1)
class 1(group 2)
class 1(group 3)
class 2(group 4)
class 2(group 5)
class 2(group 6)"
MEAN OF L,0.6881118881118881,"0
20
40
60
80
100
% of Low-Loss Sample 40 60 80 100"
MEAN OF L,0.6888111888111889,% of Majority Samples
MEAN OF L,0.6895104895104895,"class 1
class 2"
MEAN OF L,0.6902097902097902,(b) UrbanCars
MEAN OF L,0.6909090909090909,"Figure 7: The proportion of minority and majority samples across different classes within various
percentages of DLL samples with highest and lowest loss for the MultiNLI (a) and UrbanCars (b)
datasets. MultiNLI exhibits attribute imbalance rather than spurious correlation, which explains its
different behavior compared to Waterbirds and CelebA."
MEAN OF L,0.6916083916083916,"are women, while men with blond hair represent a minority group. In addition to spurious correlation
712"
MEAN OF L,0.6923076923076923,"in the class of blond hair, this dataset also exhibits class imbalance.
713"
MEAN OF L,0.693006993006993,"MultiNLI [15]
dataset involves a text classification task focused on determining the relationship
714"
MEAN OF L,0.6937062937062937,"between pairs of sentences: contradiction, entailment, or neutral. Sentences containing negation
715"
MEAN OF L,0.6944055944055944,"words such as ""no"" or ""never"" are under-represented in all three classes, inducing attribute imbalance
716"
MEAN OF L,0.6951048951048951,"in the dataset. Figure 7 illustrates the distinct behavior of this dataset compared to other datasets that
717"
MEAN OF L,0.6958041958041958,"contain spurious attributes.
718"
MEAN OF L,0.6965034965034965,"CivilComments [16]
dataset, as part of the WILDS benchmark, involves a text classification task
719"
MEAN OF L,0.6972027972027972,"focused on labeling online comments as either ""toxic"" or ""not toxic"". Each comment is associated
720"
MEAN OF L,0.6979020979020979,"with 8 attributes, including gender (male, female), sexual orientation (LGBTQ), race (black, white),
721"
MEAN OF L,0.6986013986013986,"and religion (Christian, Muslim, or other), based on whether these characteristics are mentioned
722"
MEAN OF L,0.6993006993006993,"in the comment. While there is a small attribute imbalance in the dataset, it can categorized into
723"
MEAN OF L,0.7,"datasets with class imbalance. In this paper, we use the implementation of the dataset by the WILDS
724"
MEAN OF L,0.7006993006993008,"package [39].
725"
MEAN OF L,0.7013986013986014,"UrbanCars [14]
is an image classification dataset with multiple shortcuts. Each image in the
726"
MEAN OF L,0.7020979020979021,"dataset consists of a car in the center of the image on a natural scene background, with another object
727"
MEAN OF L,0.7027972027972028,"to the right of the image. Images are labeled Urban or City according to the type of car present in
728"
MEAN OF L,0.7034965034965035,"the center. However, each of the backgrounds and the additional objects is highly correlated with
729"
MEAN OF L,0.7041958041958042,"the label. While the test set consists of 8 environments based on combinations of the core and two
730"
MEAN OF L,0.7048951048951049,"spurious patterns, the training and validation set consist of four groups, based on combinations of the
731"
MEAN OF L,0.7055944055944056,"label and only one of the shortcuts.
732"
MEAN OF L,0.7062937062937062,"D.4
Training Details
733"
MEAN OF L,0.706993006993007,"ERM
For Waterbirds and CelebA, we utilize the ResNet50 checkpoints available in
734"
MEAN OF L,0.7076923076923077,"the GitHub repository of Kirichenko et al. [1] as our base model.
We use the
735"
MEAN OF L,0.7083916083916084,"ResNet-50 architecture provided by the torchvision package.
In the case of Civil-
736"
MEAN OF L,0.7090909090909091,"Comments and MultiNLI, we adopt a similar approach to Kirichenko et al. [1], using
737"
MEAN OF L,0.7097902097902098,"BertForSequenceClassification.from_pretrained(’bert-base-uncased’, ...) from
738"
MEAN OF L,0.7104895104895105,"the transformers package. The model is trained using the AdamW optimizer with a learning
739"
MEAN OF L,0.7111888111888112,"rate of 10−5, weight decay of 10−4, and a batch size of 16 for a total of 5 epochs.
740"
MEAN OF L,0.7118881118881119,"For the UrbanCars dataset, we adhere to the settings described in Li et al. [14], which involves
741"
MEAN OF L,0.7125874125874125,"training a ResNet-50 model pretrained on ImageNet using the SGD optimizer with a learning rate
742"
MEAN OF L,0.7132867132867133,"of 10−3, momentum of 0.9, weight decay of 10−4, and a batch size of 128 for 300 epochs. For the
743"
MEAN OF L,0.713986013986014,"Dominoes-CMF dataset, we train a ResNet18 model pretrained on ImageNet for 20 epochs with a
744"
MEAN OF L,0.7146853146853147,"batch size of 128 and an SGD optimizer with a learning rate of 10−3, momentum of 0.9, and weight
745"
MEAN OF L,0.7153846153846154,"decay of 10−4.
746"
MEAN OF L,0.7160839160839161,"EVaLS and EVaLS-GL
For every dataset, EIIL was utilized with a learning rate of 0.01, a total of
747"
MEAN OF L,0.7167832167832168,"20000 steps, and a batch size of 128. The last layer of the model was trained on all datasets using the
748"
MEAN OF L,0.7174825174825175,"Adam optimizer. A batch size of 32 and a weight decay of 10−4 were used for all datasets. Our method
749"
MEAN OF L,0.7181818181818181,"was evaluated on the validation sets of each dataset, considering both fine-tuning and retraining of the
750"
MEAN OF L,0.7188811188811188,"last layer. For all datasets, with the exception of MultiNLI, retraining provided superior validation
751"
MEAN OF L,0.7195804195804196,"results. The specifics regarding the number of epochs and the ranges for hyperparameter search
752"
MEAN OF L,0.7202797202797203,"(including learning rate, l1-regularization coefficient (λ), and the number of selected samples (k)) for
753"
MEAN OF L,0.720979020979021,"each dataset are as follows:
754"
MEAN OF L,0.7216783216783217,"• Waterbirds.
755"
MEAN OF L,0.7223776223776224,"– epochs = 100,
756"
MEAN OF L,0.7230769230769231,"– lr = 5 × 10−4,
757"
MEAN OF L,0.7237762237762237,"– λ ∈{0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4, 0.5},
758"
MEAN OF L,0.7244755244755244,"– k ∈{20, 25, 30, 35, 40, 45, 50, 55, 60}.
759"
MEAN OF L,0.7251748251748251,"• CelebA
760"
MEAN OF L,0.7258741258741259,"– epochs = 50,
761"
MEAN OF L,0.7265734265734266,"– lr = 5 × 10−4,
762"
MEAN OF L,0.7272727272727273,"– λ ∈{0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4, 0.5,
763"
MEAN OF L,0.727972027972028,"0.6, 0.7, 0.8, 0.9, 1, 2},
764"
MEAN OF L,0.7286713286713287,"– k ∈{50, 100, 150, 200, 250, 300}.
765"
MEAN OF L,0.7293706293706294,"• UrbanCars
766"
MEAN OF L,0.73006993006993,"– epochs = 100,
767"
MEAN OF L,0.7307692307692307,"– lr ∈{5 × 10−4, 10−3},
768"
MEAN OF L,0.7314685314685314,"– λ ∈{0, 0.01, 0.02, 0.05, 0.1, 1},
769"
MEAN OF L,0.7321678321678322,"– k ∈{10, 20, 30, 50, 63}.
770"
MEAN OF L,0.7328671328671329,"• CivilComments
771"
MEAN OF L,0.7335664335664336,"– epochs = 50,
772"
MEAN OF L,0.7342657342657343,"– lr = 5 × 10−4,
773"
MEAN OF L,0.734965034965035,"– λ ∈{0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4, 0.5,
774"
MEAN OF L,0.7356643356643356,"0.6, 0.7, 0.8, 0.9, 1, 2},
775"
MEAN OF L,0.7363636363636363,"– k ∈{500, 750, 1000, 1250, 1500}.
776"
MEAN OF L,0.737062937062937,"• MultiNLI
777"
MEAN OF L,0.7377622377622378,"– epochs = 200,
778"
MEAN OF L,0.7384615384615385,"– lr ∈{10−2, 10−3},
779"
MEAN OF L,0.7391608391608392,"– λ ∈{0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4, 0.5},
780"
MEAN OF L,0.7398601398601399,"– k ∈{20, 30, 40, 50, 60, 75, 100, 125, 150, 200, 250, 300}.
781"
MEAN OF L,0.7405594405594406,"E
Ablation Study
782"
MEAN OF L,0.7412587412587412,"E.1
Use of EIIL with DFR and AFR
783"
MEAN OF L,0.7419580419580419,"We conducted an ablation study to investigate the impact of using environments inferred from EIIL on
784"
MEAN OF L,0.7426573426573426,"model selection. Specifically, we benchmarked the performance of DFR and AFR with EIIL-inferred
785"
MEAN OF L,0.7433566433566433,"groups. The results, presented in Table 9, demonstrate the effectiveness of incorporating EIIL-inferred
786"
MEAN OF L,0.7440559440559441,"groups in model selection. The results show that while EIIL-inferred groups reduce the performance
787"
MEAN OF L,0.7447552447552448,"compared to ground-truth annotations for model selection, they still can be effective for robustness to
788"
MEAN OF L,0.7454545454545455,"an extent. Moreover, EVaLS outperforms these two methodw when using EIIL inferred environments.
789"
MEAN OF L,0.7461538461538462,Table 9: Results of DFR and AFR with EIIL-inferred environment for model selection.
MEAN OF L,0.7468531468531469,"Method
Waterbirds
Celeba"
MEAN OF L,0.7475524475524475,"DFR (with EIIL)
92.21 ± 0.02
85.55 ± 1.0
AFR (with EIIL)
82.6 ± 0.04
72.5 ± 0.01"
MEAN OF L,0.7482517482517482,"E.2
Other Group Inference Methods
790"
MEAN OF L,0.7489510489510489,"In addition to EIIL, other group inference methods could be utilized for partitioning the model
791"
MEAN OF L,0.7496503496503496,"selection set into environments.
792"
MEAN OF L,0.7503496503496504,"Error Splitting
JTT [5] partitions data into two correctly classified and misclassified sets based
793"
MEAN OF L,0.7510489510489511,"on the predictions of a model trained with ERM. We split each of these two sets based on labels of
794"
MEAN OF L,0.7517482517482518,"samples, obtaining |Y| × 2 environments.
795"
MEAN OF L,0.7524475524475525,"Random Classifier Splitting
uses a random classifier to classify features obtained from a model
796"
MEAN OF L,0.7531468531468531,"trained with ERM into correctly classified and misclassified sets. Similar to error splitting, we split
797"
MEAN OF L,0.7538461538461538,"the sets based on group labels. The difference between error splitting and random classifier splitting
798"
MEAN OF L,0.7545454545454545,"is solely in the reinitialization of the classification layer.
799"
MEAN OF L,0.7552447552447552,"The results for EVaLS-ES (EVaLS+Error Sampling) and EVaLS-RC (EVaLS+Random Classifier) are
800"
MEAN OF L,0.7559440559440559,"shown in Table 10. One limitation of error splitting is that in datasets with noisy labels or corrupted
801"
MEAN OF L,0.7566433566433567,"images, samples that an ERM model misclassifies may not always belong to minority groups. In these
802"
MEAN OF L,0.7573426573426574,"situations, choosing models based on their accuracy on corrupted data could lead to the selection of
803"
MEAN OF L,0.7580419580419581,"models that are not robust to spurious correlations. This is demonstrated by the results of EVaLS-ES
804"
MEAN OF L,0.7587412587412588,"on the CelebA dataset.
805"
MEAN OF L,0.7594405594405594,"This shortcoming of error splitting can be alleviated by employing a random classifier instead of
806"
MEAN OF L,0.7601398601398601,"the ERM-trained one. Due to the feature-level similarity between minority and majority samples in
807"
MEAN OF L,0.7608391608391608,"datasets affected by spurious correlation [23, 1, 29], it is expected that the classifier can differentiate
808"
MEAN OF L,0.7615384615384615,"between the groups to some extent. As shown in Table 10, surprisingly, EVaLS-RC produces results
809"
MEAN OF L,0.7622377622377622,"that are generally comparable to EVaLS. However, the performance of this method may have high
810"
MEAN OF L,0.762937062937063,"variance, depending on the different initializations of the classifier.
811"
MEAN OF L,0.7636363636363637,"Table 10: The performances of three environment inference methods, when combined with loss-based
sample selection, are evaluated on spurious correlation benchmarks. The mean and standard deviation
values are calculated over three separate runs, each initiated with a different seed."
MEAN OF L,0.7643356643356644,"Method
Waterbirds
CelebA
UrbanCars"
MEAN OF L,0.765034965034965,"Worst
Average
Worst
Average
Worst
Average"
MEAN OF L,0.7657342657342657,"EVaLS-ES
82.1±1.2
94.3±0.04
48.4±11.6
69.5±6.5
79.2±2.9
86.1±0.9
EVaLS-RC
88.7±1.0
94.3±1.1
78.1±5.1
93.5±0.2
82.4±3.2
88.2±0.8
EVaLS
88.4±3.1
94.1±0.1
85.3±0.4
89.4±0.5
79.4±3.1
86.5±1.5"
MEAN OF L,0.7664335664335664,"F
Societal Impacts
812"
MEAN OF L,0.7671328671328671,"Real-world datasets often encapsulate social biases that stem from entrenched stereotypes and
813"
MEAN OF L,0.7678321678321678,"historical discrimination, affecting various groups such as genders and races. Machine learning
814"
MEAN OF L,0.7685314685314686,"methods, which learn the correlation between patterns in input data and their targets (e.g., labels
815"
MEAN OF L,0.7692307692307693,"in a classification task) [40], inadvertently absorb this bias. This unintended consequence leads to
816"
MEAN OF L,0.76993006993007,"fairness issues in many applications. While strategies to mitigate such biases have been proposed
817"
MEAN OF L,0.7706293706293706,"(as discussed comprehensively in Section A), societal biases are not always known and determined.
818"
MEAN OF L,0.7713286713286713,"We believe that our work, as it addresses these unidentified biases, takes a significant step towards
819"
MEAN OF L,0.772027972027972,"making machine learning fairer for our society.
820"
MEAN OF L,0.7727272727272727,"G
Computational Resources
821"
MEAN OF L,0.7734265734265734,"Each experiment was conducted on one of the following GPUs: NVIDIA A100 with 80G memory,
822"
MEAN OF L,0.7741258741258741,"NVIDIA Titan RTX with 24G memory, Nvidia GeForce RTX 3090 with 24G memory, and NVIDIA
823"
MEAN OF L,0.7748251748251749,"GeForce RTX 3080 Ti with 12G memory.
824"
MEAN OF L,0.7755244755244756,"NeurIPS Paper Checklist
825"
CLAIMS,0.7762237762237763,"1. Claims
826"
CLAIMS,0.7769230769230769,"Question: Do the main claims made in the abstract and introduction accurately reflect the
827"
CLAIMS,0.7776223776223776,"paper’s contributions and scope?
828"
CLAIMS,0.7783216783216783,"Answer: [Yes]
829"
CLAIMS,0.779020979020979,"Justification: The scope of the effectiveness and main claims are clearly demonstrated in the
830"
ABSTRACT,0.7797202797202797,"abstract and introduction.
831"
ABSTRACT,0.7804195804195804,"Guidelines:
832"
ABSTRACT,0.7811188811188812,"• The answer NA means that the abstract and introduction do not include the claims
833"
ABSTRACT,0.7818181818181819,"made in the paper.
834"
ABSTRACT,0.7825174825174825,"• The abstract and/or introduction should clearly state the claims made, including the
835"
ABSTRACT,0.7832167832167832,"contributions made in the paper and important assumptions and limitations. A No or
836"
ABSTRACT,0.7839160839160839,"NA answer to this question will not be perceived well by the reviewers.
837"
ABSTRACT,0.7846153846153846,"• The claims made should match theoretical and experimental results, and reflect how
838"
ABSTRACT,0.7853146853146853,"much the results can be expected to generalize to other settings.
839"
ABSTRACT,0.786013986013986,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
840"
ABSTRACT,0.7867132867132867,"are not attained by the paper.
841"
LIMITATIONS,0.7874125874125875,"2. Limitations
842"
LIMITATIONS,0.7881118881118881,"Question: Does the paper discuss the limitations of the work performed by the authors?
843"
LIMITATIONS,0.7888111888111888,"Answer: [Yes]
844"
LIMITATIONS,0.7895104895104895,"Justification: The limitations are discussed in the discussion section.
845"
LIMITATIONS,0.7902097902097902,"Guidelines:
846"
LIMITATIONS,0.7909090909090909,"• The answer NA means that the paper has no limitation while the answer No means that
847"
LIMITATIONS,0.7916083916083916,"the paper has limitations, but those are not discussed in the paper.
848"
LIMITATIONS,0.7923076923076923,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
849"
LIMITATIONS,0.793006993006993,"• The paper should point out any strong assumptions and how robust the results are to
850"
LIMITATIONS,0.7937062937062938,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
851"
LIMITATIONS,0.7944055944055944,"model well-specification, asymptotic approximations only holding locally). The authors
852"
LIMITATIONS,0.7951048951048951,"should reflect on how these assumptions might be violated in practice and what the
853"
LIMITATIONS,0.7958041958041958,"implications would be.
854"
LIMITATIONS,0.7965034965034965,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
855"
LIMITATIONS,0.7972027972027972,"only tested on a few datasets or with a few runs. In general, empirical results often
856"
LIMITATIONS,0.7979020979020979,"depend on implicit assumptions, which should be articulated.
857"
LIMITATIONS,0.7986013986013986,"• The authors should reflect on the factors that influence the performance of the approach.
858"
LIMITATIONS,0.7993006993006992,"For example, a facial recognition algorithm may perform poorly when image resolution
859"
LIMITATIONS,0.8,"is low or images are taken in low lighting. Or a speech-to-text system might not be
860"
LIMITATIONS,0.8006993006993007,"used reliably to provide closed captions for online lectures because it fails to handle
861"
LIMITATIONS,0.8013986013986014,"technical jargon.
862"
LIMITATIONS,0.8020979020979021,"• The authors should discuss the computational efficiency of the proposed algorithms
863"
LIMITATIONS,0.8027972027972028,"and how they scale with dataset size.
864"
LIMITATIONS,0.8034965034965035,"• If applicable, the authors should discuss possible limitations of their approach to
865"
LIMITATIONS,0.8041958041958042,"address problems of privacy and fairness.
866"
LIMITATIONS,0.8048951048951049,"• While the authors might fear that complete honesty about limitations might be used by
867"
LIMITATIONS,0.8055944055944056,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
868"
LIMITATIONS,0.8062937062937063,"limitations that aren’t acknowledged in the paper. The authors should use their best
869"
LIMITATIONS,0.806993006993007,"judgment and recognize that individual actions in favor of transparency play an impor-
870"
LIMITATIONS,0.8076923076923077,"tant role in developing norms that preserve the integrity of the community. Reviewers
871"
LIMITATIONS,0.8083916083916084,"will be specifically instructed to not penalize honesty concerning limitations.
872"
THEORY ASSUMPTIONS AND PROOFS,0.8090909090909091,"3. Theory Assumptions and Proofs
873"
THEORY ASSUMPTIONS AND PROOFS,0.8097902097902098,"Question: For each theoretical result, does the paper provide the full set of assumptions and
874"
THEORY ASSUMPTIONS AND PROOFS,0.8104895104895105,"a complete (and correct) proof?
875"
THEORY ASSUMPTIONS AND PROOFS,0.8111888111888111,"Answer: [Yes]
876"
THEORY ASSUMPTIONS AND PROOFS,0.8118881118881119,"Justification: All the lemmas and propositions are stated upon exact definitions, assumptions
877"
THEORY ASSUMPTIONS AND PROOFS,0.8125874125874126,"and conditions. All the theorems, formulas, and proofs in the paper are numbered and
878"
THEORY ASSUMPTIONS AND PROOFS,0.8132867132867133,"cross-referenced.
879"
THEORY ASSUMPTIONS AND PROOFS,0.813986013986014,"Guidelines:
880"
THEORY ASSUMPTIONS AND PROOFS,0.8146853146853147,"• The answer NA means that the paper does not include theoretical results.
881"
THEORY ASSUMPTIONS AND PROOFS,0.8153846153846154,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
882"
THEORY ASSUMPTIONS AND PROOFS,0.8160839160839161,"referenced.
883"
THEORY ASSUMPTIONS AND PROOFS,0.8167832167832167,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
884"
THEORY ASSUMPTIONS AND PROOFS,0.8174825174825174,"• The proofs can either appear in the main paper or the supplemental material, but if
885"
THEORY ASSUMPTIONS AND PROOFS,0.8181818181818182,"they appear in the supplemental material, the authors are encouraged to provide a short
886"
THEORY ASSUMPTIONS AND PROOFS,0.8188811188811189,"proof sketch to provide intuition.
887"
THEORY ASSUMPTIONS AND PROOFS,0.8195804195804196,"• Inversely, any informal proof provided in the core of the paper should be complemented
888"
THEORY ASSUMPTIONS AND PROOFS,0.8202797202797203,"by formal proofs provided in appendix or supplemental material.
889"
THEORY ASSUMPTIONS AND PROOFS,0.820979020979021,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
890"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8216783216783217,"4. Experimental Result Reproducibility
891"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8223776223776224,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
892"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.823076923076923,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
893"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8237762237762237,"of the paper (regardless of whether the code and data are provided or not)?
894"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8244755244755245,"Answer: [Yes]
895"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8251748251748252,"Justification: The training precedure is described accurately and all the training details and
896"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8258741258741259,"hyperparameters required for reproducing the results are provided.
897"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8265734265734266,"Guidelines:
898"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8272727272727273,"• The answer NA means that the paper does not include experiments.
899"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.827972027972028,"• If the paper includes experiments, a No answer to this question will not be perceived
900"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8286713286713286,"well by the reviewers: Making the paper reproducible is important, regardless of
901"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8293706293706293,"whether the code and data are provided or not.
902"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.83006993006993,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
903"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8307692307692308,"to make their results reproducible or verifiable.
904"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8314685314685315,"• Depending on the contribution, reproducibility can be accomplished in various ways.
905"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8321678321678322,"For example, if the contribution is a novel architecture, describing the architecture fully
906"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8328671328671329,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
907"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8335664335664336,"be necessary to either make it possible for others to replicate the model with the same
908"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8342657342657342,"dataset, or provide access to the model. In general. releasing code and data is often
909"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8349650349650349,"one good way to accomplish this, but reproducibility can also be provided via detailed
910"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8356643356643356,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
911"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8363636363636363,"of a large language model), releasing of a model checkpoint, or other means that are
912"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8370629370629371,"appropriate to the research performed.
913"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8377622377622378,"• While NeurIPS does not require releasing code, the conference does require all submis-
914"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8384615384615385,"sions to provide some reasonable avenue for reproducibility, which may depend on the
915"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8391608391608392,"nature of the contribution. For example
916"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8398601398601399,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
917"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8405594405594405,"to reproduce that algorithm.
918"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8412587412587412,"(b) If the contribution is primarily a new model architecture, the paper should describe
919"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8419580419580419,"the architecture clearly and fully.
920"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8426573426573427,"(c) If the contribution is a new model (e.g., a large language model), then there should
921"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8433566433566434,"either be a way to access this model for reproducing the results or a way to reproduce
922"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8440559440559441,"the model (e.g., with an open-source dataset or instructions for how to construct
923"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8447552447552448,"the dataset).
924"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8454545454545455,"(d) We recognize that reproducibility may be tricky in some cases, in which case
925"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8461538461538461,"authors are welcome to describe the particular way they provide for reproducibility.
926"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8468531468531468,"In the case of closed-source models, it may be that access to the model is limited in
927"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8475524475524475,"some way (e.g., to registered users), but it should be possible for other researchers
928"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8482517482517482,"to have some path to reproducing or verifying the results.
929"
OPEN ACCESS TO DATA AND CODE,0.848951048951049,"5. Open access to data and code
930"
OPEN ACCESS TO DATA AND CODE,0.8496503496503497,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
931"
OPEN ACCESS TO DATA AND CODE,0.8503496503496504,"tions to faithfully reproduce the main experimental results, as described in supplemental
932"
OPEN ACCESS TO DATA AND CODE,0.8510489510489511,"material?
933"
OPEN ACCESS TO DATA AND CODE,0.8517482517482518,"Answer: [Yes]
934"
OPEN ACCESS TO DATA AND CODE,0.8524475524475524,"Justification: Codes and information of datasets that are constructed or reused in the paper
935"
OPEN ACCESS TO DATA AND CODE,0.8531468531468531,"are anonymized and included in the main paper and supplementary material.
936"
OPEN ACCESS TO DATA AND CODE,0.8538461538461538,"Guidelines:
937"
OPEN ACCESS TO DATA AND CODE,0.8545454545454545,"• The answer NA means that paper does not include experiments requiring code.
938"
OPEN ACCESS TO DATA AND CODE,0.8552447552447553,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
939"
OPEN ACCESS TO DATA AND CODE,0.855944055944056,"public/guides/CodeSubmissionPolicy) for more details.
940"
OPEN ACCESS TO DATA AND CODE,0.8566433566433567,"• While we encourage the release of code and data, we understand that this might not be
941"
OPEN ACCESS TO DATA AND CODE,0.8573426573426574,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
942"
OPEN ACCESS TO DATA AND CODE,0.858041958041958,"including code, unless this is central to the contribution (e.g., for a new open-source
943"
OPEN ACCESS TO DATA AND CODE,0.8587412587412587,"benchmark).
944"
OPEN ACCESS TO DATA AND CODE,0.8594405594405594,"• The instructions should contain the exact command and environment needed to run to
945"
OPEN ACCESS TO DATA AND CODE,0.8601398601398601,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
946"
OPEN ACCESS TO DATA AND CODE,0.8608391608391608,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
947"
OPEN ACCESS TO DATA AND CODE,0.8615384615384616,"• The authors should provide instructions on data access and preparation, including how
948"
OPEN ACCESS TO DATA AND CODE,0.8622377622377623,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
949"
OPEN ACCESS TO DATA AND CODE,0.862937062937063,"• The authors should provide scripts to reproduce all experimental results for the new
950"
OPEN ACCESS TO DATA AND CODE,0.8636363636363636,"proposed method and baselines. If only a subset of experiments are reproducible, they
951"
OPEN ACCESS TO DATA AND CODE,0.8643356643356643,"should state which ones are omitted from the script and why.
952"
OPEN ACCESS TO DATA AND CODE,0.865034965034965,"• At submission time, to preserve anonymity, the authors should release anonymized
953"
OPEN ACCESS TO DATA AND CODE,0.8657342657342657,"versions (if applicable).
954"
OPEN ACCESS TO DATA AND CODE,0.8664335664335664,"• Providing as much information as possible in supplemental material (appended to the
955"
OPEN ACCESS TO DATA AND CODE,0.8671328671328671,"paper) is recommended, but including URLs to data and code is permitted.
956"
OPEN ACCESS TO DATA AND CODE,0.8678321678321679,"6. Experimental Setting/Details
957"
OPEN ACCESS TO DATA AND CODE,0.8685314685314686,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
958"
OPEN ACCESS TO DATA AND CODE,0.8692307692307693,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
959"
OPEN ACCESS TO DATA AND CODE,0.8699300699300699,"results?
960"
OPEN ACCESS TO DATA AND CODE,0.8706293706293706,"Answer: [Yes]
961"
OPEN ACCESS TO DATA AND CODE,0.8713286713286713,"Justification: The training details, hyperparameters, model selection criteria, etc. have are
962"
OPEN ACCESS TO DATA AND CODE,0.872027972027972,"written in the Appendix and the data and metadata have been provided in our code.
963"
OPEN ACCESS TO DATA AND CODE,0.8727272727272727,"Guidelines:
964"
OPEN ACCESS TO DATA AND CODE,0.8734265734265734,"• The answer NA means that the paper does not include experiments.
965"
OPEN ACCESS TO DATA AND CODE,0.8741258741258742,"• The experimental setting should be presented in the core of the paper to a level of detail
966"
OPEN ACCESS TO DATA AND CODE,0.8748251748251749,"that is necessary to appreciate the results and make sense of them.
967"
OPEN ACCESS TO DATA AND CODE,0.8755244755244755,"• The full details can be provided either with the code, in appendix, or as supplemental
968"
OPEN ACCESS TO DATA AND CODE,0.8762237762237762,"material.
969"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8769230769230769,"7. Experiment Statistical Significance
970"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8776223776223776,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
971"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8783216783216783,"information about the statistical significance of the experiments?
972"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.879020979020979,"Answer: [Yes]
973"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8797202797202798,"Justification: All tables report standard deviation and how it was computed and the plot
974"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8804195804195805,"contains error bar (also by standard deviation).
975"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8811188811188811,"Guidelines:
976"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8818181818181818,"• The answer NA means that the paper does not include experiments.
977"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8825174825174825,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
978"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8832167832167832,"dence intervals, or statistical significance tests, at least for the experiments that support
979"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8839160839160839,"the main claims of the paper.
980"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8846153846153846,"• The factors of variability that the error bars are capturing should be clearly stated (for
981"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8853146853146853,"example, train/test split, initialization, random drawing of some parameter, or overall
982"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8860139860139861,"run with given experimental conditions).
983"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8867132867132868,"• The method for calculating the error bars should be explained (closed form formula,
984"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8874125874125874,"call to a library function, bootstrap, etc.)
985"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8881118881118881,"• The assumptions made should be given (e.g., Normally distributed errors).
986"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8888111888111888,"• It should be clear whether the error bar is the standard deviation or the standard error
987"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8895104895104895,"of the mean.
988"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8902097902097902,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
989"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8909090909090909,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
990"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8916083916083916,"of Normality of errors is not verified.
991"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8923076923076924,"• For asymmetric distributions, the authors should be careful not to show in tables or
992"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.893006993006993,"figures symmetric error bars that would yield results that are out of range (e.g. negative
993"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8937062937062937,"error rates).
994"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8944055944055944,"• If error bars are reported in tables or plots, The authors should explain in the text how
995"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8951048951048951,"they were calculated and reference the corresponding figures or tables in the text.
996"
EXPERIMENTS COMPUTE RESOURCES,0.8958041958041958,"8. Experiments Compute Resources
997"
EXPERIMENTS COMPUTE RESOURCES,0.8965034965034965,"Question: For each experiment, does the paper provide sufficient information on the com-
998"
EXPERIMENTS COMPUTE RESOURCES,0.8972027972027972,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
999"
EXPERIMENTS COMPUTE RESOURCES,0.8979020979020979,"the experiments?
1000"
EXPERIMENTS COMPUTE RESOURCES,0.8986013986013986,"Answer: [No]
1001"
EXPERIMENTS COMPUTE RESOURCES,0.8993006993006993,"Justification: The paper does provide details about the hardware used for the experiments.
1002"
EXPERIMENTS COMPUTE RESOURCES,0.9,"However, since experiments were done on different hardwares, the computational resources
1003"
EXPERIMENTS COMPUTE RESOURCES,0.9006993006993007,"needed for each individual experiment are not documented.
1004"
EXPERIMENTS COMPUTE RESOURCES,0.9013986013986014,"Guidelines:
1005"
EXPERIMENTS COMPUTE RESOURCES,0.9020979020979021,"• The answer NA means that the paper does not include experiments.
1006"
EXPERIMENTS COMPUTE RESOURCES,0.9027972027972028,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
1007"
EXPERIMENTS COMPUTE RESOURCES,0.9034965034965035,"or cloud provider, including relevant memory and storage.
1008"
EXPERIMENTS COMPUTE RESOURCES,0.9041958041958041,"• The paper should provide the amount of compute required for each of the individual
1009"
EXPERIMENTS COMPUTE RESOURCES,0.9048951048951049,"experimental runs as well as estimate the total compute.
1010"
EXPERIMENTS COMPUTE RESOURCES,0.9055944055944056,"• The paper should disclose whether the full research project required more compute
1011"
EXPERIMENTS COMPUTE RESOURCES,0.9062937062937063,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
1012"
EXPERIMENTS COMPUTE RESOURCES,0.906993006993007,"didn’t make it into the paper).
1013"
CODE OF ETHICS,0.9076923076923077,"9. Code Of Ethics
1014"
CODE OF ETHICS,0.9083916083916084,"Question: Does the research conducted in the paper conform, in every respect, with the
1015"
CODE OF ETHICS,0.9090909090909091,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
1016"
CODE OF ETHICS,0.9097902097902097,"Answer: [Yes]
1017"
CODE OF ETHICS,0.9104895104895104,"Justification: All codes and rules have been thoroughly reviewed and checked, with no
1018"
CODE OF ETHICS,0.9111888111888112,"instances of non-compliance found.
1019"
CODE OF ETHICS,0.9118881118881119,"Guidelines:
1020"
CODE OF ETHICS,0.9125874125874126,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
1021"
CODE OF ETHICS,0.9132867132867133,"• If the authors answer No, they should explain the special circumstances that require a
1022"
CODE OF ETHICS,0.913986013986014,"deviation from the Code of Ethics.
1023"
CODE OF ETHICS,0.9146853146853147,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
1024"
CODE OF ETHICS,0.9153846153846154,"eration due to laws or regulations in their jurisdiction).
1025"
BROADER IMPACTS,0.916083916083916,"10. Broader Impacts
1026"
BROADER IMPACTS,0.9167832167832168,"Question: Does the paper discuss both potential positive societal impacts and negative
1027"
BROADER IMPACTS,0.9174825174825175,"societal impacts of the work performed?
1028"
BROADER IMPACTS,0.9181818181818182,"Answer: [Yes]
1029"
BROADER IMPACTS,0.9188811188811189,"Justification: In the Social Impacts section we discuss that our work can significantly
1030"
BROADER IMPACTS,0.9195804195804196,"contribute to fairness in machine learning. We did not find any negative social impacts of
1031"
BROADER IMPACTS,0.9202797202797203,"our work.
1032"
BROADER IMPACTS,0.920979020979021,"Guidelines:
1033"
BROADER IMPACTS,0.9216783216783216,"• The answer NA means that there is no societal impact of the work performed.
1034"
BROADER IMPACTS,0.9223776223776223,"• If the authors answer NA or No, they should explain why their work has no societal
1035"
BROADER IMPACTS,0.9230769230769231,"impact or why the paper does not address societal impact.
1036"
BROADER IMPACTS,0.9237762237762238,"• Examples of negative societal impacts include potential malicious or unintended uses
1037"
BROADER IMPACTS,0.9244755244755245,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
1038"
BROADER IMPACTS,0.9251748251748252,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
1039"
BROADER IMPACTS,0.9258741258741259,"groups), privacy considerations, and security considerations.
1040"
BROADER IMPACTS,0.9265734265734266,"• The conference expects that many papers will be foundational research and not tied
1041"
BROADER IMPACTS,0.9272727272727272,"to particular applications, let alone deployments. However, if there is a direct path to
1042"
BROADER IMPACTS,0.9279720279720279,"any negative applications, the authors should point it out. For example, it is legitimate
1043"
BROADER IMPACTS,0.9286713286713286,"to point out that an improvement in the quality of generative models could be used to
1044"
BROADER IMPACTS,0.9293706293706294,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
1045"
BROADER IMPACTS,0.9300699300699301,"that a generic algorithm for optimizing neural networks could enable people to train
1046"
BROADER IMPACTS,0.9307692307692308,"models that generate Deepfakes faster.
1047"
BROADER IMPACTS,0.9314685314685315,"• The authors should consider possible harms that could arise when the technology is
1048"
BROADER IMPACTS,0.9321678321678322,"being used as intended and functioning correctly, harms that could arise when the
1049"
BROADER IMPACTS,0.9328671328671329,"technology is being used as intended but gives incorrect results, and harms following
1050"
BROADER IMPACTS,0.9335664335664335,"from (intentional or unintentional) misuse of the technology.
1051"
BROADER IMPACTS,0.9342657342657342,"• If there are negative societal impacts, the authors could also discuss possible mitigation
1052"
BROADER IMPACTS,0.9349650349650349,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
1053"
BROADER IMPACTS,0.9356643356643357,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
1054"
BROADER IMPACTS,0.9363636363636364,"feedback over time, improving the efficiency and accessibility of ML).
1055"
SAFEGUARDS,0.9370629370629371,"11. Safeguards
1056"
SAFEGUARDS,0.9377622377622378,"Question: Does the paper describe safeguards that have been put in place for responsible
1057"
SAFEGUARDS,0.9384615384615385,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
1058"
SAFEGUARDS,0.9391608391608391,"image generators, or scraped datasets)?
1059"
SAFEGUARDS,0.9398601398601398,"Answer: [NA]
1060"
SAFEGUARDS,0.9405594405594405,"Justification: The paper poses no such risks.
1061"
SAFEGUARDS,0.9412587412587412,"Guidelines:
1062"
SAFEGUARDS,0.941958041958042,"• The answer NA means that the paper poses no such risks.
1063"
SAFEGUARDS,0.9426573426573427,"• Released models that have a high risk for misuse or dual-use should be released with
1064"
SAFEGUARDS,0.9433566433566434,"necessary safeguards to allow for controlled use of the model, for example by requiring
1065"
SAFEGUARDS,0.9440559440559441,"that users adhere to usage guidelines or restrictions to access the model or implementing
1066"
SAFEGUARDS,0.9447552447552447,"safety filters.
1067"
SAFEGUARDS,0.9454545454545454,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
1068"
SAFEGUARDS,0.9461538461538461,"should describe how they avoided releasing unsafe images.
1069"
SAFEGUARDS,0.9468531468531468,"• We recognize that providing effective safeguards is challenging, and many papers do
1070"
SAFEGUARDS,0.9475524475524476,"not require this, but we encourage authors to take this into account and make a best
1071"
SAFEGUARDS,0.9482517482517483,"faith effort.
1072"
LICENSES FOR EXISTING ASSETS,0.948951048951049,"12. Licenses for existing assets
1073"
LICENSES FOR EXISTING ASSETS,0.9496503496503497,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
1074"
LICENSES FOR EXISTING ASSETS,0.9503496503496504,"the paper, properly credited and are the license and terms of use explicitly mentioned and
1075"
LICENSES FOR EXISTING ASSETS,0.951048951048951,"properly respected?
1076"
LICENSES FOR EXISTING ASSETS,0.9517482517482517,"Answer: [Yes]
1077"
LICENSES FOR EXISTING ASSETS,0.9524475524475524,"Justification: Every asset that we utilized for our implementations have been appropriately
1078"
LICENSES FOR EXISTING ASSETS,0.9531468531468531,"referenced, both within the paper itself and in the code (if needed). Although we did not
1079"
LICENSES FOR EXISTING ASSETS,0.9538461538461539,"specify the names of their respective licenses, you can find these details on the webpages
1080"
LICENSES FOR EXISTING ASSETS,0.9545454545454546,"we’ve cited.
1081"
LICENSES FOR EXISTING ASSETS,0.9552447552447553,"Guidelines:
1082"
LICENSES FOR EXISTING ASSETS,0.955944055944056,"• The answer NA means that the paper does not use existing assets.
1083"
LICENSES FOR EXISTING ASSETS,0.9566433566433566,"• The authors should cite the original paper that produced the code package or dataset.
1084"
LICENSES FOR EXISTING ASSETS,0.9573426573426573,"• The authors should state which version of the asset is used and, if possible, include a
1085"
LICENSES FOR EXISTING ASSETS,0.958041958041958,"URL.
1086"
LICENSES FOR EXISTING ASSETS,0.9587412587412587,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
1087"
LICENSES FOR EXISTING ASSETS,0.9594405594405594,"• For scraped data from a particular source (e.g., website), the copyright and terms of
1088"
LICENSES FOR EXISTING ASSETS,0.9601398601398602,"service of that source should be provided.
1089"
LICENSES FOR EXISTING ASSETS,0.9608391608391609,"• If assets are released, the license, copyright information, and terms of use in the
1090"
LICENSES FOR EXISTING ASSETS,0.9615384615384616,"package should be provided. For popular datasets, paperswithcode.com/datasets
1091"
LICENSES FOR EXISTING ASSETS,0.9622377622377623,"has curated licenses for some datasets. Their licensing guide can help determine the
1092"
LICENSES FOR EXISTING ASSETS,0.9629370629370629,"license of a dataset.
1093"
LICENSES FOR EXISTING ASSETS,0.9636363636363636,"• For existing datasets that are re-packaged, both the original license and the license of
1094"
LICENSES FOR EXISTING ASSETS,0.9643356643356643,"the derived asset (if it has changed) should be provided.
1095"
LICENSES FOR EXISTING ASSETS,0.965034965034965,"• If this information is not available online, the authors are encouraged to reach out to
1096"
LICENSES FOR EXISTING ASSETS,0.9657342657342657,"the asset’s creators.
1097"
NEW ASSETS,0.9664335664335665,"13. New Assets
1098"
NEW ASSETS,0.9671328671328672,"Question: Are new assets introduced in the paper well documented and is the documentation
1099"
NEW ASSETS,0.9678321678321679,"provided alongside the assets?
1100"
NEW ASSETS,0.9685314685314685,"Answer: [NA]
1101"
NEW ASSETS,0.9692307692307692,"Justification: The paper does not release new assets.
1102"
NEW ASSETS,0.9699300699300699,"Guidelines:
1103"
NEW ASSETS,0.9706293706293706,"• The answer NA means that the paper does not release new assets.
1104"
NEW ASSETS,0.9713286713286713,"• Researchers should communicate the details of the dataset/code/model as part of their
1105"
NEW ASSETS,0.972027972027972,"submissions via structured templates. This includes details about training, license,
1106"
NEW ASSETS,0.9727272727272728,"limitations, etc.
1107"
NEW ASSETS,0.9734265734265735,"• The paper should discuss whether and how consent was obtained from people whose
1108"
NEW ASSETS,0.9741258741258741,"asset is used.
1109"
NEW ASSETS,0.9748251748251748,"• At submission time, remember to anonymize your assets (if applicable). You can either
1110"
NEW ASSETS,0.9755244755244755,"create an anonymized URL or include an anonymized zip file.
1111"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9762237762237762,"14. Crowdsourcing and Research with Human Subjects
1112"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9769230769230769,"Question: For crowdsourcing experiments and research with human subjects, does the paper
1113"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9776223776223776,"include the full text of instructions given to participants and screenshots, if applicable, as
1114"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9783216783216783,"well as details about compensation (if any)?
1115"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9790209790209791,"Answer: [NA]
1116"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9797202797202798,"Justification: The paper does not involve crowdsourcing nor research with human subjects.
1117"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9804195804195804,"Guidelines:
1118"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9811188811188811,"• The answer NA means that the paper does not involve crowdsourcing nor research with
1119"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9818181818181818,"human subjects.
1120"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9825174825174825,"• Including this information in the supplemental material is fine, but if the main contribu-
1121"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9832167832167832,"tion of the paper involves human subjects, then as much detail as possible should be
1122"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9839160839160839,"included in the main paper.
1123"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9846153846153847,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
1124"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9853146853146854,"or other labor should be paid at least the minimum wage in the country of the data
1125"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.986013986013986,"collector.
1126"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9867132867132867,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
1127"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9874125874125874,"Subjects
1128"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9881118881118881,"Question: Does the paper describe potential risks incurred by study participants, whether
1129"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9888111888111888,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
1130"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9895104895104895,"approvals (or an equivalent approval/review based on the requirements of your country or
1131"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9902097902097902,"institution) were obtained?
1132"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.990909090909091,"Answer: [NA]
1133"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9916083916083916,"Justification: The paper does not involve crowdsourcing nor researh with human subjects.
1134"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9923076923076923,"Guidelines:
1135"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.993006993006993,"• The answer NA means that the paper does not involve crowdsourcing nor research with
1136"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9937062937062937,"human subjects.
1137"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9944055944055944,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
1138"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9951048951048951,"may be required for any human subjects research. If you obtained IRB approval, you
1139"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9958041958041958,"should clearly state this in the paper.
1140"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9965034965034965,"• We recognize that the procedures for this may vary significantly between institutions
1141"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9972027972027973,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
1142"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9979020979020979,"guidelines for their institution.
1143"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9986013986013986,"• For initial submissions, do not include any information that would break anonymity (if
1144"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9993006993006993,"applicable), such as the institution conducting the review.
1145"
