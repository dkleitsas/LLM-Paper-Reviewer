Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0006476683937823834,"Bayesian learning via Stochastic Gradient Langevin Dynamics (SGLD) has been
suggested for differentially private learning. While previous research provides
differential privacy bounds for SGLD when close to convergence or at the initial
steps of the algorithm, the question of what differential privacy guarantees can be
made in between remains unanswered. This interim region is essential, especially
for Bayesian neural networks, as it is hard to guarantee convergence to the poste-
rior. This paper will show that using SGLD might result in unbounded privacy loss
for this interim region, even when sampling from the posterior is as differentially
private as desired."
INTRODUCTION,0.0012953367875647669,"1
INTRODUCTION"
INTRODUCTION,0.0019430051813471502,"Machine learning and, speciﬁcally, deep learning models show state-of-the-art results in various
ﬁelds such as computer vision, natural language processing, and signal processing (e.g., Carion
et al. (2020); Devlin et al. (2019); Balevi & Andrews (2021)). Training these models requires data,
which in some problems, e.g., healthcare, ﬁnance, can include private information that should not
be made public. Unfortunately, it has been shown (Fredrikson et al. (2015); Carlini et al. (2021))
that private information from the training data can sometimes be extracted from the trained model.
One common approach to handle this issue is Differential Privacy (DP). Differential Privacy is a
framework that ensures that the distribution of training output would be the same, even if we switch
one of the training participants, thus ensuring privacy."
INTRODUCTION,0.0025906735751295338,"As privacy is usually obtained by adding random noise, it is natural to investigate whether Bayesian
inference, which uses a distribution over models, can give private predictions. Previous works have
shown that sampling from the posterior is differentially private under certain mild conditions (Wang
et al. (2015); Foulds et al. (2016); Dimitrakakis et al. (2017)). The main disadvantage of this method
is that sampling from the posterior is generally hard. The posterior usually does not have a closed-
form solution, and iterative methods such as Markov Chain Monte Carlo (MCMC) are needed.
While theoretical bounds on the convergence of MCMC methods for non-convex problems exist
(Ma et al., 2019), they usually require an infeasible number of steps to guarantee convergence in
practice."
INTRODUCTION,0.003238341968911917,"Stochastic Gradient Langevin Dynamics (SGLD) is a popular MCMC algorithm used to approxi-
mately sample from an unnormalized distribution (Welling & Teh, 2011). The privacy guarantees
of this speciﬁc sampling algorithm are interesting as it not only returns a sample from the posterior,
which can be private, but the process itself of stochastic gradient descent with Gaussian noise mir-
rors the common Gaussian mechanism in DP. Previous work Wang et al. (2015) gives two disjoint
privacy analyses: The ﬁrst is for approximate sampling from the Bayesian posterior, which is only
relevant when the SGLD almost converges. The second uses the standard DP analysis utilizing the
Gaussian mechanism and the Advanced Composition theorem (Dwork & Roth, 2014), which only
applies for a limited number of steps and is not connected to Bayesian sampling."
INTRODUCTION,0.0038860103626943004,"From these two lines of research, differential privacy bounds for SGLD are provided for its initial
steps or when close to convergence. Neither of these cases is suitable for deep learning and many
other problems, as one would limit the model’s accuracy, and the other is unattainable in a reasonable
time. Consequently, the privacy properties of SGLD in the interim region, between these two private"
INTRODUCTION,0.0045336787564766836,"sections, are of high importance. One could speculate that since the initial steps of the algorithm
are private, and it converges to the posterior that is also private, then sampling at the interim region
will be private as well. If so, SGLD could be considered a solution for training differentially private
deep neural networks. Unfortunately, as we will show, this is not the case."
INTRODUCTION,0.0051813471502590676,"Our Contributions: This work provides a counter-example, based on a Bayesian linear regression
problem, showing that approximate sampling using SGLD might result in an unbounded loss of
privacy in the interim regime. Moreover, this loss of privacy can even occur under strong conditions
- when sampling from the posterior is as private as desired, and the problem is complex - even
stronger conditions than what we can assume for most Deep Neural Network problems. This implies
that special care should be given when using SGLD for private predictions, especially for problems
where it is infeasible to guarantee convergence."
RELATED WORK,0.005829015544041451,"2
RELATED WORK"
RELATED WORK,0.006476683937823834,"Several previous works investigate the connection between Bayesian inference and differential pri-
vacy (Wang et al. (2015); Foulds et al. (2016); Zhang et al. (2016); Dimitrakakis et al. (2017);
Geumlek et al. (2017); Ganesh & Talwar (2020)). None of these papers provide guarantees over
SGLD differential privacy in the interim regime. The closest work to ours is Wang et al. (2015) that
speciﬁcally investigates stochastic MCMC algorithms such as SGLD. As mentioned, its analysis
only covers the initial phase and when approximate convergence is achieved."
RELATED WORK,0.007124352331606218,"As many of the privacy bounds require sampling from the posterior, if SGLD is to be used, it requires
non-asymptotic convergence bounds. Dalalyan (2014) provided non-asymptotic bounds on the error
of approximating a target smooth and log-concave distribution by Langevin Monte Carlo. Cheng &
Bartlett (2018) studied the non-asymptotic bounds on the error of approximating a target density p∗
where log p∗is smooth and strongly convex."
RELATED WORK,0.007772020725388601,"For the non-convex setting, Raginsky et al. (2017) showed non-asymptotic bounds on the 2-
Wasserstein distance between SGLD and the invariant distribution solving Itˆo stochastic differential
equation. However, to provide (ϵ, δ) differential privacy, an algorithm should produce a distribution
that is O(δ) close to neighbouring databases. Total Variation (for details about Total Variation see
Tsybakov (2008)) is a more suitable distance for working with differential privacy. Ma et al. (2019)
examined a target distribution p∗, which is strongly log-concave outside of a region of radius R, and
where −ln p∗is L-Lipschitz. They provided a bound on the number of steps needed for the Total
Variation distance between the distribution at the last step and p∗to be smaller than ϵ. This bound is
proportional to O(e32LR2 d"
RELATED WORK,0.008419689119170985,"ϵ2 ), where d is the model dimension. This result suggests that even little
non-convexity will render running until close to convergence impractical. A conclusion from this
work is that basing the differential privacy of SGLD on the proximity to the posterior is impractical
for non-convex settings."
BACKGROUND,0.009067357512953367,"3
BACKGROUND"
DIFFERENTIAL PRIVACY,0.009715025906735751,"3.1
DIFFERENTIAL PRIVACY"
DIFFERENTIAL PRIVACY,0.010362694300518135,"Differential Privacy (Dwork et al. (2006b;a); Dwork (2011); Dwork & Roth (2014)) is a deﬁnition
and a framework that enables performing data analysis on a database while reducing one’s risk of
exposing its personal data to the database. An algorithm is differentially private if it does not change
its output distribution by much due to a single record change in its database."
DIFFERENTIAL PRIVACY,0.011010362694300517,"Deﬁnition 1. Approximate Differential Privacy: A randomized algorithm M : D →Range(M) is
(ϵ, δ)-differentially private if ∀S ⊆Range(M) and {∀D, ˆD ∈D : ∥D −ˆD∥≤1} eq. 1 holds.
D, ˆD are called neighboring databases, and while the metric can change per application, Hamming
distance is typically used."
DIFFERENTIAL PRIVACY,0.011658031088082901,"Pr[M(D) ∈S] ≤exp(ϵ)Pr[M( ˆD) ∈S] + δ
(1)"
DIFFERENTIAL PRIVACY,0.012305699481865285,"Mironov (2017) suggested R´enyi Differential Privacy (Deﬁnition 3), a relaxation to differential pri-
vacy, and a way to translate RDP guarantees into approximate differential privacy guarantees."
DIFFERENTIAL PRIVACY,0.012953367875647668,"Deﬁnition 2. R´enyi Divergence (R´enyi, 1961): For two probability distributions Z and Q over R,
the R´eyni divergence of order ν > 1 is"
DIFFERENTIAL PRIVACY,0.013601036269430052,"Dν(Z||Q)
∆=
1
ν −1 log Ex∼Q"
DIFFERENTIAL PRIVACY,0.014248704663212436,"Z(x) Q(x) ν
."
DIFFERENTIAL PRIVACY,0.014896373056994818,"Deﬁnition 3. (ν, ϵ)-RDP: A randomized mechanism f : D →R is said to have ϵ-R´enyi differential
privacy of order ν, or (ν, ϵ)-RDP in short, if for any adjacent databases D, ˆD ∈D eq. 2 holds,
where Dν is R´enyi divergence of order ν."
DIFFERENTIAL PRIVACY,0.015544041450777202,"Dν(f(D)||f( ˆD)) ≤ϵ
(2)"
DIFFERENTIAL PRIVACY,0.016191709844559584,"Lemma 3.1. (Mironov (2017) Proposition 3). If f is (ν, ϵ)-RDP, it also satisﬁes (ϵ + log 1"
DIFFERENTIAL PRIVACY,0.01683937823834197,"δ
ν−1 , δ) Dif-
ferential Privacy for any 0 < δ < 1."
STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.017487046632124352,"3.2
STOCHASTIC GRADIENT LANGEVIN DYNAMICS"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.018134715025906734,"Stochastic Gradient Langevin Dynamics (SGLD) is an MCMC method that is commonly used for
Bayesian Inference (Welling & Teh, 2011). The update step of SGLD is shown in eq. 3, where θj
is the parameter vector at step j, ηj is the step size at step j, p(θj) is the prior distribution, p(yi|θj)
is the likelihood of sample yi given model parameterized by θj, b is the batch size, and n is the
database size. SGLD can be seen as a Stochastic Gradient Descent with Gaussian noise, where the
variance of the noise is calibrated to the step size."
STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.01878238341968912,θj+1 = θj + ηj
STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.019430051813471502,"2

∇θj ln p(θj) + n b b
X"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.020077720207253884,"i=1
∇θj ln p(yij|θj)

+ √ηjξj"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.02072538860103627,"ij ∼uniform{1, ..., n}
ξj ∼N(0, 1) (3)"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.021373056994818652,"A common practice in deep learning is to use cyclic Stochastic Gradient Descent. This ﬂavour
of SGD ﬁrst randomly shufﬂes the database samples and then cyclically uses the samples in this
order. For optimization, there is empirical evidence that it works as well or better than SGD with
reshufﬂing, and it was conjectured that it converges at a faster rate (Yun et al. (2021)). Cyclic-SGLD
is the analog of cyclic-SGD for SGLD, where the difference is the use of the SGLD step instead of
the SGD step. For simplicity, we will consider cyclic-SGLD in this work."
METHOD,0.022020725388601035,"4
METHOD"
METHOD,0.02266839378238342,"Our goal is to prove that even when the posterior is as private as desired, sampling using SGLD for
T steps can be as non-private as desired. This requires analysing the distribution of SGLD after T
steps, which is hard in the general case. However, we show that we can get the desired behaviour
when looking at a simple Bayesian linear regression problem where everything is a Gaussian with
closed-form expressions. Our result is summarized in theorem 1."
METHOD,0.023316062176165803,"Theorem 1. ∀δ < 0.5, ϵ, ϵ′ there exists a domain and a Bayesian inference problem where a single
sample from the posterior distribution is (ϵ, δ) differentially private, but, there is a number, T, for
which performing approximate sampling by running SGLD for T steps is not (ϵ′, δ) differentially
private."
METHOD,0.023963730569948185,"As ϵ′ can be as big as desired, and ϵ can be as small as desired, a corollary of Theorem 1 is that
we could always ﬁnd a problem for which the posterior is (ϵ, δ) differentially private, but there will
be a step in which SGLD will result in unbounded loss of privacy. Therefore, SGLD alone can not
provide any privacy guarantees in the interim regime, even if the posterior is private."
METHOD,0.02461139896373057,"To prove our theorem, we consider a Bayesian regression problem for a linear model with Gaussian
noise, as deﬁned in eq. 4, on domain D deﬁned in eq. 5."
METHOD,0.025259067357512953,y = θx + ξ
METHOD,0.025906735751295335,"ξ ∼N(0, β−1)"
METHOD,0.02655440414507772,"θ ∼N(0, α−1)"
METHOD,0.027202072538860103,"log p(y|x, θ) = −β(y −θx)2/2 −1"
METHOD,0.027849740932642485,2 log(2π/β) (4)
METHOD,0.02849740932642487,"D(n, γ1, xh, xl, c) ="
METHOD,0.029145077720207253,"{xi, yi|| yi"
METHOD,0.029792746113989636,"xi
−c| ≤nγ1; xi, yi, c, γ1 ∈R>0; xl ≤xi ≤xh}n
i=1"
METHOD,0.03044041450777202,"We assume that x2
hβ > 3 and that γ1 < 1 2 (5)"
METHOD,0.031088082901554404,"n, c, xl, xh, γ1 are parameters of the problem (c, xl, xh, and γ1 are used, together with the database
size - n, to bound the database samples to a chosen region). For every ϵ, ϵ′ and δ, we will show there
exist parameters n, c, xl, xh, γ1 that have the privacy properties required to prove Theorem 1. The
restrictions on the dataset simplify the proof but are a bit unnatural as it assumes we approximately
know c, the parameter we are trying to estimate. Later we show in subsection 4.3 that they can
be replaced with a Propose-Test-Release phase. We will address the problem of Bayesian Linear
Regression for the model described in eq. 4 on domain D as Bayesian linear regression problem
on domain D. This problem has a closed-form solution for both the posterior distribution and the
distribution at each SGLD step, thus enabling us to get tight bounds on the differential privacy in
each case."
METHOD,0.03173575129533679,"The heart of our proof is showing that for n big enough sampling from the posterior is (ϵ, δ) differ-
entially private, with ϵ ∼O( c2"
METHOD,0.03238341968911917,"n3 ), while for SGLD there exists a step in which releasing a sample
will not be (ϵ′, δ) differentially private for ϵ′ = Ω( c2"
METHOD,0.033031088082901554,"n2 ). Therefore, by considering instances of the
problem where c ∼O(n
3
2 √ϵ) and n is big enough, sampling from the posterior will be (ϵ, δ) dif-
ferentially private, while there will be an SGLD step in which releasing a sample will not be (ϵ′, δ)
differentially private for ϵ′ = Ω(nϵ). We note that the bounds contain dependency over δ, but since
we are using a ﬁxed and equal δ for both the posterior and SGLD privacy analysis, we omit it from
the bounds for simplicity."
METHOD,0.03367875647668394,"Figure 1: A value indicative of the distance between the distributions of samples from two
SGLD processes running on neighbouring databases for the linear Gaussian model. For details
on µs, µr
s, σr
s see subsection 4.2. The parameters used for this experiment (n = 1149019, α =
0.1, β = 1, xh = 1.8, xl = 0.9, γ1 = 0.1, γ2 = 1.001, c = 1165165) ensure (1.6, 0.01) differential
privacy when sampling from the posterior."
METHOD,0.03432642487046632,"Figure 1 depicts an indicative value of the distance between the distributions of samples from two
SGLD processes running on adjacent databases for the Bayesian linear regression problem. As we"
METHOD,0.034974093264248704,"will later show, SGLD on one of these examples is a Gaussian while the other is a mixture of n
Gaussians. We plot 1 n
P"
METHOD,0.03562176165803109,"i
(µt−µi
t)2"
METHOD,0.03626943005181347,"(σi
t)2
, where µt is the mean of the single Gaussian at timestep t, µi
t
is the mean of the i’th Gaussian component at timestep t and (σi
t)2 its variance. We can see that
even though the distributions are close at the initial iterations and at convergence (which implies
differential privacy in those areas), in the interim region, they are signiﬁcantly apart, which implies
a lack of differential privacy."
POSTERIOR SAMPLING PRIVACY,0.036917098445595854,"4.1
POSTERIOR SAMPLING PRIVACY"
POSTERIOR SAMPLING PRIVACY,0.03756476683937824,"To prove Theorem 1, we ﬁrst need to show that ∀δ < 0.5, ϵ, there exists a domain and a Bayesian
inference problem where a single sample from the posterior distribution is (ϵ, δ) differentially pri-
vate. In order to do so, this section will consider the differential privacy guarantees provided by one
sample from the posterior for the Bayesian linear regression problem on domain D."
POSTERIOR SAMPLING PRIVACY,0.03821243523316062,"We begin by using a well-known result for the closed-form-solution of the posterior distribution for a
Bayesian linear regression problem (see Bishop (2006) for further details). By using the parameters
of our problem, we get Lemma 4.1.
Lemma 4.1. The posterior distribution for Bayesian linear regression problem on domain D is"
POSTERIOR SAMPLING PRIVACY,0.038860103626943004,"p(θ|D) = N(θ; µ, σ2); µ =
Pn
i=1 xiyiβ
α + Pn
i=1 x2
i β ; σ2 =
1
α + Pn
i=1 x2
i β .
(6)"
POSTERIOR SAMPLING PRIVACY,0.03950777202072539,"Using the posterior distribution, one can calculate the Renyi divergence between every two neigh-
bouring databases, thus getting an expression for the R´enyi differential privacy, as shown in Lemma
4.2.
Lemma 4.2. For a Bayesian linear regression problem on domain D, such that n > max{1 +
10 x2
h
x2
l
ν
β , 1 + ν x2
h
x2
l }, one sample from the posterior is (ν, ϵ1)-R´enyi differentially private. ϵ1 ∼O( c2 n3 )"
POSTERIOR SAMPLING PRIVACY,0.04015544041450777,for c >> n1+γ1.
POSTERIOR SAMPLING PRIVACY,0.040803108808290155,"ϵ1 =
x2
h
2(n −1)x2
l
+ 1"
POSTERIOR SAMPLING PRIVACY,0.04145077720207254,"2(ν −1)
νx2
h
(n −1)x2
l −νx2
h
+ 2νβ
x4
h
9
10n1−2γ1x2
l
+"
POSTERIOR SAMPLING PRIVACY,0.04209844559585492,"2νβ · (x2
hβ)(x2
hα + x4
hβ)
9
10(x2
l β)2
· (c + nγ1)"
POSTERIOR SAMPLING PRIVACY,0.042746113989637305,"n2−γ1
+ ν"
POSTERIOR SAMPLING PRIVACY,0.04339378238341969,"2 · (x2
hα + x4
hβ)2"
POSTERIOR SAMPLING PRIVACY,0.04404145077720207,"9
10x6
l β
· (c + nγ1)2 n3
."
POSTERIOR SAMPLING PRIVACY,0.044689119170984455,"We can show that for c >> n1+γ2, each of the terms is bounded by O( c2"
POSTERIOR SAMPLING PRIVACY,0.04533678756476684,"n3 ). The ﬁrst and second
terms are bounded by O( 1"
POSTERIOR SAMPLING PRIVACY,0.04598445595854922,n). The third term is bounded by O(n2γ1−1). Noticing that n2γ1−1 =
POSTERIOR SAMPLING PRIVACY,0.046632124352331605,n2(1+γ1)
POSTERIOR SAMPLING PRIVACY,0.04727979274611399,"n3
<
c2
n3 , we get that the third term is bounded by O( c2"
POSTERIOR SAMPLING PRIVACY,0.04792746113989637,"n3 ). As c >> nγ1, the fourth term
is bounded by O( cnγ1"
POSTERIOR SAMPLING PRIVACY,0.048575129533678756,"n2 ), and since cnγ1"
POSTERIOR SAMPLING PRIVACY,0.04922279792746114,"n2
= cn1+γ1"
POSTERIOR SAMPLING PRIVACY,0.04987046632124352,"n3
<
c2
n3 , the term is bounded by O( c2"
POSTERIOR SAMPLING PRIVACY,0.050518134715025906,"n3 ). Lastly,
since c >> n1+γ1, the last term is bounded by O( c2"
POSTERIOR SAMPLING PRIVACY,0.05116580310880829,"n3 ). For the full proof, see subsection A.1 in the
appendix."
POSTERIOR SAMPLING PRIVACY,0.05181347150259067,"Translating the R´enyi differential privacy guarantees into approximate differential privacy terms can
be done according to Lemma 3.1, which gives Lemma 4.3."
POSTERIOR SAMPLING PRIVACY,0.052461139896373056,"Lemma 4.3. With the conditions of Lemma 4.2, one sample from the posterior is (ϵ1 + ln( 1"
POSTERIOR SAMPLING PRIVACY,0.05310880829015544,"δ )
ν−1 , δ)
differentially private."
POSTERIOR SAMPLING PRIVACY,0.05375647668393782,By choosing ν such that ln( 1
POSTERIOR SAMPLING PRIVACY,0.054404145077720206,"δ )
ν−1 < ϵ"
POSTERIOR SAMPLING PRIVACY,0.05505181347150259,2 and then choosing n big enough such that ϵ1 < ϵ
POSTERIOR SAMPLING PRIVACY,0.05569948186528497,"2, we get that
the posterior is (ϵ, δ) differentially private."
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.056347150259067356,"4.2
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.05699481865284974,"To complete the proof of Theorem 1, we need to show that even if one sample from the posterior
is (ϵ, δ) differentially private for a Bayesian linear regression problem on domain D, it does not"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.05764248704663212,"provide any guarantees on the privacy of SGLD for that problem. In order to do so, this section will
ﬁrst consider the loss in privacy when using SGLD for the Bayesian linear regression problem on
domain D, and then, together with the results of section 4.1, will prove Theorem 1."
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.05829015544041451,"In order to show that SGLD is not differentially private after initial steps and before convergence,
it is enough to ﬁnd two neighbouring databases for which the loss in privacy is as big as desired in
those steps. We deﬁne neighbouring databases D1 and D2 in eq. 7 and consider the Bayesian linear
regression problem on D1 and D2. We set the learning rate to be η =
2
(α+nx2
hβ)2 ."
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.05893782383419689,"D1 = {xi, yi : xi = xh, yi = c · xh}n
i=1"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.05958549222797927,"D2 = {xi, yi : xi = xh, yi = c · xh}n−1
i=1 ∪{xh"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.06023316062176166,"2 , c · xh"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.06088082901554404,"2 }
(7)"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.06152849740932642,"To tightly analyze the differential privacy loss when approximately sampling via SGLD at each step,
we need to get a closed-form solution for the distribution for each step. For database D1, the solution
is Normal distribution. For database D2, different shufﬂing of samples produces different Gaussian
distributions, therefore giving a mixture of Gaussians."
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.06217616580310881,"We look at cyclic-SGLD with a batch size of 1 and mark by θj, ˆθj the samples on the j’th SGLD
step when using databases D1 and D2 accordingly. Since D1 samples are all equal, the update step
of the cyclic-SGLD is the same for every step (with different noise generated for each step). This
update-step contains only multiplication by a scalar, addition of a scalar, and addition of Gaussian
noise, therefore, together with a conjugate prior results in Normal distribution for θj: N(θj; µj, σ2
j )."
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.06282383419689119,"For D2, there is only one sample different from the rest. We mark by r the index in which this
sample is used in the cyclic-SGLD and call this order r-order. Note that there are only n different
values for r and, as such, effectively only n different samples orders. Since every order of samples is
chosen with the same probability, r is distributed uniformly in {1, .., n}. We mark by ˆθr
j the sample
on the j’th SGLD step when using r-order. Since, for a given order, ˆθr
j is formed by a series of
multiplications by a scalar, addition of scalar, and addition of Gaussian noise, and since the prior is
also Gaussian, then ˆθr
j is distributed Normally, N(ˆθr
j; ˆµr
j, (ˆσr
j)2). As r is distributed uniformly, ˆθj
distribution mass is distributed evenly between all ˆθr
j, resulting in a mixture of Gaussians."
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.06347150259067358,"Intuitively what will happen is that each Gaussian components ,ˆθj as well as θj, will move towards
the similar posterior Gaussian. However, at each epoch, ˆθj will drag a bit behind because in one
batch one gradient is smaller. While this gap can be quite small, for large n, the Gaussians are very
peaked with very small standard deviations; thus, they separate enough that we can easily distinguish
between the two distributions."
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.06411917098445596,"According to approximate differential privacy deﬁnition (Deﬁnition 1), it is enough to ﬁnd one set
S such that p(θj ∈S) > eϵp(ˆθj ∈S) + δ to show that releasing θj is not (ϵ, δ) private. We
choose S = {s|s > µj} at some step j we will deﬁne later on. It is clear from symmetry that
p(θj > µj) = 1/2, and by using Chernoff bound we can bound p(ˆθj > µj)."
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.06476683937823834,Lemma 4.4. p(ˆθj > µj) ≤1
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.06541450777202072,"n
Pn
r=1 exp(−
(µj−ˆµr
j )2"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.06606217616580311,"2(ˆσr
j )2 )."
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.0667098445595855,"Using Lemma 4.4, we can upper bound the mass of ˆθj in S, and thus lower bound the difference
between θj and ˆθj distribution masses in S for some step - j. To use Lemma 4.4, we ﬁrst need to"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.06735751295336788,"lower bound
(µj−ˆµr
j )2"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.06800518134715026,"(σr
j )2
for a certain step. This is done in Lemma 4.5."
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.06865284974093264,"Lemma 4.5. ∃k ∈Z>0 such that
(µ(k+1)n−ˆµr
(k+1)n)2"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.06930051813471502,"(ˆσr
(k+1)n)2
= Ω( c2"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.06994818652849741,"n2 ), for n big enough."
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.0705958549222798,"To prove Lemma 4.5, we ﬁrst ﬁnd closed-form solutions for ˆθr
(k+1)n, θ(k+1)n distributions (Lemma
A.1). Using the closed-form solutions, we ﬁnd a lower bound over (µ(k+1)n −ˆµr
(k+1)n)2 as a
function of k, which applies for all k (Lemma A.2). To upper bound (ˆσr
(k+1)n)2, we ﬁnd an approx-
imation to the epoch in which the data and prior effects on the variance are approximately equal,"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.07124352331606218,"marked ˙k. We choose the step in which we will consider the privacy loss as (⌈˙k⌉+1)n and show that
(ˆσr
(⌈˙k⌉+1)n)2 is upper bounded at this step (Lemma A.4). Using the upper bound on the difference in
means and the lower bound on the variance, Lemma 4.5 is proved. By using the lower bound from
Lemma 4.5 in Lemma 4.4, we get Lemma 4.6."
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.07189119170984457,"Lemma 4.6. For the Bayesian linear regression problem over database D1, such that n is big
enough, ∃T ∈Z>0 such that approximate sampling by running SGLD for T steps will not be (ϵ, δ)
private for ϵ < Ω( c2"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.07253886010362694,"n2 ), δ < 0.5."
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.07318652849740932,"From Lemma 4.3, we see that sampling from the posterior is (ϵ, δ) differentially private for ϵ =
O( c2"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.07383419689119171,"n3 ). From Lemma 4.6, we see that for SGLD, there exists a step in which releasing a sample will
not be (ϵ′, δ) differentially private for ϵ′ = Ω( c2"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY,0.0744818652849741,"n2 ). Therefore, considering instances of the problem
where c = O(n
3
2 √ϵ), sampling from the posterior will be (ϵ, δ) differentially private. However,
there will be an SGLD step in which releasing a sample will not be (ϵ′, δ) differentially private for
ϵ′ = Ω(nϵ). Since we can choose n to be big as desired, we can make the lower bound over ϵ′ as
big as we desire. This completes the proof of Theorem 1."
PROPOSE TEST SAMPLE,0.07512953367875648,"4.3
PROPOSE TEST SAMPLE"
PROPOSE TEST SAMPLE,0.07577720207253887,"Our analysis of the posterior and SGLD is done on a restricted domain D as deﬁned in eq. 5. These
restrictions over the dataset simplify the proof but are a bit unnatural as they assume we approxi-
mately know c, the parameter we are trying to estimate. This section shows that these restrictions
could be replaced with a Propose-Test-Release phase (Dwork & Lei, 2009) and common practices
in deep learning."
PROPOSE TEST SAMPLE,0.07642487046632124,"When training a statistical model, it is common to ﬁrst preprocess the data by enforcing it in a
bounded region and removing outliers. After the data is cleaned, the training process is performed.
This is especially important in DP, as outliers can signiﬁcantly increase the algorithm’s sensitivity
to a single data point and thus hamper privacy."
PROPOSE TEST SAMPLE,0.07707253886010362,"Informally, algorithm 1 starts by clipping the input to the accepted range.
It then estimates a
weighted average of the ratio yi"
PROPOSE TEST SAMPLE,0.07772020725388601,"xi (line 12) and throws away outliers that deviate too much from
it. The actual implementation of this notion is a bit more complicated because of the requirement
to do so privately. Once the database is cleaned, algorithm 1 privately veriﬁes that the number of
samples is big enough, so the sensitivity of p(θ|W) to a single change in the database will be small,
therefore making sampling from p(θ|W) (ϵ, δ) differentially private. This method is regarded as
Propose-Test-Release, where we ﬁrst propose a bound over the sensitivity, then test if the database
holds this bound, and ﬁnally release the result if so."
PROPOSE TEST SAMPLE,0.0783678756476684,"We deﬁne nmin in eq. 26 in the appendix to be the minimum size of W for which the algorithm
will sample from p(θ|W) with high probability. We will show later on that this limit ensures that
sampling from p(θ|W) is (ϵ, δ) differentially private."
PROPOSE TEST SAMPLE,0.07901554404145078,"We deﬁne p(θ|W) to be the posterior for the Bayesian linear regression problem over database W.
From Lemma 4.1, it follows that p(θ|W) has the form of"
PROPOSE TEST SAMPLE,0.07966321243523317,"p(θ|W) = N(θ; µ, σ2); µ = P"
PROPOSE TEST SAMPLE,0.08031088082901554,"(xi,yi)∈W xiyiβ"
PROPOSE TEST SAMPLE,0.08095854922279792,"α + P
(xi,yi)∈W x2
i β ; σ2 =
1
α + P
(xi,yi)∈W x2
i β ."
PROPOSE TEST SAMPLE,0.08160621761658031,"Claim 4.1. Algorithm 1 is (5ϵ, 2δ) differentially private."
PROPOSE TEST SAMPLE,0.0822538860103627,"By claim C.9, steps 6-13 are (3ϵ, δ) differentially private. By corollary C.3, steps 14-19 are (2ϵ, δ)
differentially private for given ˘m and n2. Therefore by the sequential composition theorem, the
composition is (5ϵ, 2δ) differentially private. The claim proved by noticing that if steps 6-19 are
private with respect to the updated database (after step 5), then they are also private for the original
database."
PROPOSE TEST SAMPLE,0.08290155440414508,"Claim 4.2. When replacing line 19 with sampling via SGLD with step size η =
1
(α+n1x2
hβ)2 , then
∃T(n1) : Z>0 →Z>0 such that the updated algorithm is not (ϵ, δ) differentially private ∀ϵ ∈
R>0, δ < 1"
PROPOSE TEST SAMPLE,0.08354922279792747,6 if ran for T(n1) steps.
PROPOSE TEST SAMPLE,0.08419689119170984,"Algorithm 1 Propose Test Sample
Input: D = {xi, yi}n1
i=1
Parameters: ϵ, δ < 0.5, xl > 0, xh > xl, α > 0, β ≥
3
x2
h , ρ1 ∈(1, 3"
PROPOSE TEST SAMPLE,0.08484455958549222,"2), ρ2 ∈(0, 1"
PROPOSE TEST SAMPLE,0.08549222797927461,"2), γ1 ∈(ρ2, 1 2)"
PROPOSE TEST SAMPLE,0.086139896373057,"1: for i = 1, 2, . . . , N do
2:
xi ←max{xi, xl}
3:
xi ←min{xi, xh}
4:
yi ←max{yi, 0}
5: end for
6: ˘n1 ←n1 −1"
PROPOSE TEST SAMPLE,0.08678756476683938,ϵ log 1
PROPOSE TEST SAMPLE,0.08743523316062177,2δ + Lap( 1
PROPOSE TEST SAMPLE,0.08808290155440414,"ϵ )
7: V = {xi, yi| yi"
PROPOSE TEST SAMPLE,0.08873056994818652,"xi ≤˘nρ1
1 }"
PROPOSE TEST SAMPLE,0.08937823834196891,8: n2 ←|V | −1
PROPOSE TEST SAMPLE,0.0900259067357513,ϵ log 1
PROPOSE TEST SAMPLE,0.09067357512953368,2δ + Lap( 1
PROPOSE TEST SAMPLE,0.09132124352331607,"ϵ )
9: if n2 ≤1 then
10:
return null
11: end if
12: m ← P"
PROPOSE TEST SAMPLE,0.09196891191709844,"(xi,yi)∈V xiyi
P"
PROPOSE TEST SAMPLE,0.09261658031088082,"(xi,yi)∈V x2
i"
PROPOSE TEST SAMPLE,0.09326424870466321,13: ˘m ←m + Lap( 1
PROPOSE TEST SAMPLE,0.0939119170984456,"ϵ ˘nρ1
1
2(n2−1)x2
hx2
l +x4
h
n2(n2−1)x4
l
)"
PROPOSE TEST SAMPLE,0.09455958549222798,"14: W ←{(xi, yi) : | yi"
PROPOSE TEST SAMPLE,0.09520725388601037,"xi −˘m| ≤nρ2
2 }"
PROPOSE TEST SAMPLE,0.09585492227979274,15: nW ←|W| −1
PROPOSE TEST SAMPLE,0.09650259067357513,ϵ log( 1
PROPOSE TEST SAMPLE,0.09715025906735751,2δ) + Lap( 1
PROPOSE TEST SAMPLE,0.0977979274611399,"ϵ )
16: if nW < nmin then
17:
return null
18: end if
19: return sample from p(θ|W)"
PROPOSE TEST SAMPLE,0.09844559585492228,"Proof sketch (See appendix for full proof). We ﬁrst note that by choosing 1+ρ2 > ρ1, the sensitivity
of ˘m grows slower than the bound over the distance | yi"
PROPOSE TEST SAMPLE,0.09909326424870467,"xi −˘m|. Therefore for n1 big enough, samples
for which yi"
PROPOSE TEST SAMPLE,0.09974093264248704,"xi = m will be included in W with high probability. Consequently, databases D3, D4 ∈
D will reach, with high probability, to step 19, which from our previous analysis over SGLD (see
subsection 4.2) will cause an unbounded loss in privacy."
PROPOSE TEST SAMPLE,0.10038860103626943,ρ1 > ρ3 > 1
PROPOSE TEST SAMPLE,0.10103626943005181,"D3 = {xi, yi : xi = xh, yi = nρ3
1 · xh}n1
i=1"
PROPOSE TEST SAMPLE,0.1016839378238342,"D4 = {xi, yi : xi = xh, yi = nρ3
1 · xh}n−1
i=1 ∪{xh"
PROPOSE TEST SAMPLE,0.10233160621761658,"2 , nρ3
1 · xh"
PROPOSE TEST SAMPLE,0.10297927461139897,"2 }
(8)"
WASSERSTEIN DISTANCE AND DIFFERENTIAL PRIVACY,0.10362694300518134,"5
WASSERSTEIN DISTANCE AND DIFFERENTIAL PRIVACY"
WASSERSTEIN DISTANCE AND DIFFERENTIAL PRIVACY,0.10427461139896373,"As we have shown in Theorem 1, one cannot give any DP guarantees for SGLD in the interim
region. That means that to get private samples using SGLD, one must limit the number of iterations,
thus utilizing the Gaussian mechanism, or run until approximate convergence. Therefore, it is of
interest to get non-asymptotic convergence bounds for SGLD so that we guarantee privacy after a
known number of steps. Previously, several works have given non-asymptotic bounds; however,
some of those do so for the 2-Wasserstein metric (Raginsky et al. (2017); Cheng et al. (2018)). This
is unfortunate as the 2-Wasserstein metric is unsuitable for differential privacy - it is easy to create
two distributions with 2-Wasserstein distance as small as desired but with disjoint support."
WASSERSTEIN DISTANCE AND DIFFERENTIAL PRIVACY,0.10492227979274611,"It is, however, interesting to ask whether combining bounds on the 2-Wasserstein metric with
Lipschitz continuous probability densities will allow us to get privacy guarantees. The intuition
why this should be enough is simple: If p, q are two distributions with small 2-Wasserstein distance,
then there is (under mild conditions) a mapping, f : X →X, such that the pushforward maintains
f♯p = q (i.e. for each measurable set S q(S) = p(f −1(S))) and that Ep[||x−f(x)||2] < ϵ. One can
assume that p(x) ≈q(f(x)) and q(x) ≈q(f(x)) as x ≈f(x) with high probability. Unfortunately,
this intuition does not hold exactly, as the map f can change the density considerably but still be a"
WASSERSTEIN DISTANCE AND DIFFERENTIAL PRIVACY,0.1055699481865285,"pushforward by changing the volume. For example, if we assume f is smooth and bijective, we get
the standard change of variable formula such that p(x) = q(f(x)) |det(Jf)|, so p(x) ≈q(f(x))
only if |det(Jf)| ≈1. This issue becomes more severe as the dimensionality increases."
WASSERSTEIN DISTANCE AND DIFFERENTIAL PRIVACY,0.10621761658031088,"For completeness, we will share our results connecting p(x) to q(x) when W2(p, q) is small,
and both distributions are L-Lipschitz continuous. This bound scale poorly with dimension, and
as such ill-suited for SGLD on deep networks, but can still be useful for Bayesian sampling in
low-dimensional problems."
WASSERSTEIN DISTANCE AND DIFFERENTIAL PRIVACY,0.10686528497409327,"For distribution p, we deﬁne the density pλ(x) as the average of p(x) on a ball of radius λ centered
around x - pλ(x) =
1
vold(λ)
R"
WASSERSTEIN DISTANCE AND DIFFERENTIAL PRIVACY,0.10751295336787564,"Bd
λ(0) p(x + z)dz, where Bd
λ(x) is the ball in Rd of radius λ centered
around x, and vold(λ) is its volume."
WASSERSTEIN DISTANCE AND DIFFERENTIAL PRIVACY,0.10816062176165803,Claim 5.1. For L-Lipschitz continuous distribution p we have |p(x) −pλ(x)| ≤λL.
WASSERSTEIN DISTANCE AND DIFFERENTIAL PRIVACY,0.10880829015544041,"Theorem 2. Let P, Q be absolutely continuous w.r.t the Lebesgue measure in Rd, with ﬁnite second-
moment and L-Lipschitz continuous densities p, q. If W2(p, q) < ϵ2 then we have"
WASSERSTEIN DISTANCE AND DIFFERENTIAL PRIVACY,0.1094559585492228,"pλ(x) ≤
vold(λ)
vold(λ −ϵ)qλ(x) +

vold(λ)
vold(λ −ϵ) −1

2λL +
ϵ
vold(λ −ϵ).
(9)"
WASSERSTEIN DISTANCE AND DIFFERENTIAL PRIVACY,0.11010362694300518,"The proof is an extension of the proof of theorem 2.1 in Walker (2004) to dimensions larger than 1.
The detailed proof is in the supplementary material."
WASSERSTEIN DISTANCE AND DIFFERENTIAL PRIVACY,0.11075129533678757,"It is easy to see that as
vold(λ)
vold(λ−ϵ) =

1 +
ϵ
λ−ϵ
d
, the bounds usefulness quickly diminishes with
dimensionality as it requires extremely small ϵ to give non-vacuous results."
WASSERSTEIN DISTANCE AND DIFFERENTIAL PRIVACY,0.11139896373056994,"This, however, can still give useful results in low-dimensional problems."
CONCLUSION,0.11204663212435233,"6
CONCLUSION"
CONCLUSION,0.11269430051813471,"As shown in this work, while SGLD has interesting connections to privacy and some guarantees,
caution is required if one wishes to use it to get private predictions. This is especially important for
models such as deep neural networks, where it is infeasible to guarantee convergence."
REFERENCES,0.1133419689119171,REFERENCES
REFERENCES,0.11398963730569948,"Eren Balevi and Jeffrey G. Andrews. Wideband channel estimation with a generative adversarial
network. IEEE Transactions on Wireless Communications, 20(5):3049–3060, 2021. doi: 10.
1109/TWC.2020.3047100."
REFERENCES,0.11463730569948187,"Christopher Bishop. Pattern Recognition and Machine Learning. Information Science and Statistics.
Springer-Verlag New York, 2006."
REFERENCES,0.11528497409326424,"Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, and
Sergey Zagoruyko. End-to-end object detection with transformers. In Andrea Vedaldi, Horst
Bischof, Thomas Brox, and Jan-Michael Frahm (eds.), Computer Vision – ECCV 2020, pp. 213–
229. Springer International Publishing, 2020. ISBN 978-3-030-58452-8."
REFERENCES,0.11593264248704663,"Nicholas Carlini, Florian Tram`er, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine
Lee, Adam Roberts, Tom B. Brown, D. Song, ´U. Erlingsson, Alina Oprea, and Colin Raffel.
Extracting training data from large language models. In USENIX Security Symposium, 2021."
REFERENCES,0.11658031088082901,"X. Cheng and P. Bartlett. Convergence of langevin mcmc in kl-divergence. In ALT, 2018."
REFERENCES,0.1172279792746114,"Xiang Cheng, Niladri S. Chatterji, Peter L. Bartlett, and Michael I. Jordan. Underdamped langevin
MCMC: A non-asymptotic analysis. In Conference On Learning Theory COLT, 2018."
REFERENCES,0.11787564766839378,"Arnak Dalalyan. Theoretical guarantees for approximate sampling from smooth and log-concave
densities. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 79, 12
2014. doi: 10.1111/rssb.12183."
REFERENCES,0.11852331606217617,"Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep
bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of
the North American Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers), pp. 4171–4186, Minneapolis, Minnesota, June
2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL https:
//aclanthology.org/N19-1423."
REFERENCES,0.11917098445595854,"Christos Dimitrakakis, Blaine Nelson, Zuhe Zhang, Aikaterini Mitrokotsa, and Benjamin I. P. Ru-
binstein.
Differential privacy for bayesian inference through posterior sampling.
Journal of
Machine Learning Research, 18(11):1–39, 2017. URL http://jmlr.org/papers/v18/
15-257.html."
REFERENCES,0.11981865284974093,"Cynthia Dwork. A ﬁrm foundation for private data analysis. Commun. ACM, 54(1):86–95, January
2011.
ISSN 0001-0782.
doi: 10.1145/1866739.1866758.
URL https://doi.org/10.
1145/1866739.1866758."
REFERENCES,0.12046632124352331,"Cynthia Dwork and Jing Lei. Differential privacy and robust statistics. In Proceedings of the Forty-
First Annual ACM Symposium on Theory of Computing, STOC ’09, pp. 371–380, New York,
NY, USA, 2009. Association for Computing Machinery. ISBN 9781605585062. doi: 10.1145/
1536414.1536466. URL https://doi.org/10.1145/1536414.1536466."
REFERENCES,0.1211139896373057,"Cynthia Dwork and Aaron Roth. The algorithmic foundations of differential privacy. Found. Trends
Theor. Comput. Sci., 9(3–4):211–407, August 2014. ISSN 1551-305X. doi: 10.1561/0400000042.
URL https://doi.org/10.1561/0400000042."
REFERENCES,0.12176165803108809,"Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor.
Our
data, ourselves: Privacy via distributed noise generation.
In Advances in Cryptology - EU-
ROCRYPT 2006, 25th Annual International Conference on the Theory and Applications of
Cryptographic Techniques, volume 4004 of Lecture Notes in Computer Science, pp. 486–
503. Springer, 2006a. doi: 10.1007/11761679 29. URL https://iacr.org/archive/
eurocrypt2006/40040493/40040493.pdf."
REFERENCES,0.12240932642487047,"Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in
private data analysis. In Shai Halevi and Tal Rabin (eds.), Theory of Cryptography, pp. 265–284,
Berlin, Heidelberg, 2006b. Springer Berlin Heidelberg. ISBN 978-3-540-32732-5."
REFERENCES,0.12305699481865284,"James R. Foulds, Joseph Geumlek, Max Welling, and Kamalika Chaudhuri. On the theory and
practice of privacy-preserving bayesian data analysis. In Uncertainty in Artiﬁcial Intelligence,
UAI, 2016."
REFERENCES,0.12370466321243523,"Matt Fredrikson, Somesh Jha, and Thomas Ristenpart. Model inversion attacks that exploit conﬁ-
dence information and basic countermeasures. In Proceedings of the 22nd ACM SIGSAC Confer-
ence on Computer and Communications Security, CCS ’15, pp. 1322–1333, New York, NY, USA,
2015. Association for Computing Machinery. ISBN 9781450338325. doi: 10.1145/2810103.
2813677. URL https://doi.org/10.1145/2810103.2813677."
REFERENCES,0.12435233160621761,"Arun Ganesh and Kunal Talwar. Faster differentially private samplers via r´enyi divergence analysis
of discretized langevin mcmc. ArXiv, abs/2010.14658, 2020."
REFERENCES,0.125,"Joseph Geumlek, Shuang Song, and Kamalika Chaudhuri. Renyi differential privacy mechanisms
for posterior sampling. In Advances in Neural Information Processing NeurIPS, 2017."
REFERENCES,0.12564766839378239,"Alison L. Gibbs and Francis Edward Su. On choosing and bounding probability metrics. Interna-
tional Statistical Review, 70(3):419–435, 2002."
REFERENCES,0.12629533678756477,"M. Gil, F. Alajaji, and T. Linder. R´enyi divergence measures for commonly used univariate contin-
uous distributions. Information Sciences, 249:124–131, 2013. ISSN 0020-0255. doi: https://doi.
org/10.1016/j.ins.2013.06.018.
URL https://www.sciencedirect.com/science/
article/pii/S0020025513004441."
REFERENCES,0.12694300518134716,"Yi-An Ma, Yuansi Chen, Chi Jin, Nicolas Flammarion, and Michael I. Jordan. Sampling can be
faster than optimization.
Proceedings of the National Academy of Sciences, 116(42):20881–
20885, 2019. ISSN 0027-8424. doi: 10.1073/pnas.1820003116. URL https://www.pnas.
org/content/116/42/20881."
REFERENCES,0.12759067357512954,"Ilya Mironov. Renyi differential privacy. CoRR, abs/1702.07476, 2017. URL http://arxiv.
org/abs/1702.07476."
REFERENCES,0.12823834196891193,"Maxim Raginsky, Alexander Rakhlin, and Matus Telgarsky. Non-convex learning via stochastic
gradient langevin dynamics: a nonasymptotic analysis. In Satyen Kale and Ohad Shamir (eds.),
Proceedings of the 2017 Conference on Learning Theory, volume 65 of Proceedings of Machine
Learning Research, pp. 1674–1703. PMLR, 07–10 Jul 2017. URL https://proceedings.
mlr.press/v65/raginsky17a.html."
REFERENCES,0.12888601036269431,"Alfr´ed R´enyi. On measures of entropy and information. In Proceedings of the Fourth Berkeley
Symposium on Mathematical Statistics and Probability, Volume 1: Contributions to the Theory of
Statistics, pp. 547–561. University of California Press, 1961."
REFERENCES,0.12953367875647667,"Alexandre B. Tsybakov. Introduction to Nonparametric Estimation. Springer Publishing Company,
Incorporated, 1st edition, 2008. ISBN 0387790519."
REFERENCES,0.13018134715025906,"Martin J. Wainwright. High-Dimensional Statistics: A Non-Asymptotic Viewpoint. Cambridge Series
in Statistical and Probabilistic Mathematics. Cambridge University Press, 2019."
REFERENCES,0.13082901554404144,"Stephen Walker. New approaches to Bayesian consistency. The Annals of Statistics, 32, 2004."
REFERENCES,0.13147668393782383,"Yu-Xiang Wang, Stephen Fienberg, and Alex Smola.
Privacy for free: Posterior sampling and
stochastic gradient monte carlo. In Proceedings of the 32nd International Conference on Ma-
chine Learning, volume 37 of Proceedings of Machine Learning Research, pp. 2493–2502,
Lille, France, 07–09 Jul 2015. PMLR. URL https://proceedings.mlr.press/v37/
wangg15.html."
REFERENCES,0.13212435233160622,"M. Welling and Y. Teh. Bayesian learning via stochastic gradient langevin dynamics. In ICML,
2011."
REFERENCES,0.1327720207253886,"Chulhee Yun, Suvrit Sra, and Ali Jadbabaie. Open problem: Can single-shufﬂe SGD be better than
reshufﬂing SGD and gd? In Conference on Learning Theory, COLT, 2021."
REFERENCES,0.133419689119171,"Zuhe Zhang, Benjamin I. P. Rubinstein, and Christos Dimitrakakis. On the differential privacy of
bayesian inference. In AAAI Conference on Artiﬁcial Intelligence, 2016."
REFERENCES,0.13406735751295337,"A
SGLD AND POSTERIOR PRIVACY"
REFERENCES,0.13471502590673576,Proof Theorem 1. Deﬁne
REFERENCES,0.13536269430051814,"1
2 > γ1 > 0; 3"
REFERENCES,0.13601036269430053,2 > γ2 > 1 + γ1; xl = xh 2
REFERENCES,0.13665803108808292,ν1 = 2 ln( 1
REFERENCES,0.13730569948186527,"δ )
ϵ
+ 1"
REFERENCES,0.13795336787564766,"n1 = max{
1
2αx2
hβ −
1
x2
hβ ,
α
x2
hβ ,
α
x2
hβ (e"
REFERENCES,0.13860103626943004,"2
x2
hβ −2) +
1
2x2β }"
REFERENCES,0.13924870466321243,"n2 = max{1 + x2
h
x2
l"
REFERENCES,0.13989637305699482,"8
ϵ , 1 + ν x2
h
x2
l
(1 + 8(ν −1)"
REFERENCES,0.1405440414507772,"ϵ
), (16νβx4
h
9
10ϵx2
l
)"
REFERENCES,0.1411917098445596,"1
1−2γ1 , (16νβ"
REFERENCES,0.14183937823834197,"ϵ
((x2
hβ)(x2
hα + x4
hβ)
9
10(x2
l β)2
)(1 +
1"
REFERENCES,0.14248704663212436,"(1 + 10 x2
h
x2
l
ν
β )γ2−γ1
))"
REFERENCES,0.14313471502590674,"1
2−γ1−γ2 , (4ν"
REFERENCES,0.14378238341968913,"ϵ ((x2
hα + x4
hβ)2"
REFERENCES,0.14443005181347152,"9
10x6
l β
)(1 +
1"
REFERENCES,0.14507772020725387,"(1 + 10 x2
h
x2
l
ν
β )γ2−γ1
))"
REFERENCES,0.14572538860103626,"2
3−2γ2 }"
REFERENCES,0.14637305699481865,"n3 = max{1 + 10x2
h
x2
l ν1"
REFERENCES,0.14702072538860103,"β , 1 + ν x2
h
x2
l
}"
REFERENCES,0.14766839378238342,"np = max{n1, n2, n3, ((ϵ′ −ln(0.5 −δ))e"
REFERENCES,0.1483160621761658,"2
x2β (32x2
hβ
3
)2 2v1 α )"
REFERENCES,0.1489637305699482,"1
2(γ2−1) }"
REFERENCES,0.14961139896373057,"v1 = max{6, 1 + 2e"
REFERENCES,0.15025906735751296,"1
x2
hβ }
cp = nγ2
p ."
REFERENCES,0.15090673575129535,"We consider the Bayesian linear regression problem over database D1 (deﬁned in eq. 7) with n = np
and c = cp. Since np > n1, the problem holds the constraints of lemma A.6. Consequently, there
exists a step for which one approximate sample from the posterior using SGLD is not (ϵ′′, δ) private
for all ϵ′′ such that ϵ′′ ≤e−
2
x2β
α
2v1 (
3
32x2
hβ )2( cp"
REFERENCES,0.15155440414507773,"np )2 + ln(0.5 −δ). From eq. 10, the choice of np"
REFERENCES,0.15220207253886012,"promises that ϵ′ ≤e−
2
x2β
α
2v1 (
3
32x2
hβ )2( cp"
REFERENCES,0.15284974093264247,"np )2 + ln(0.5 −δ); Therefore approximate sampling from
the posterior using SGLD is not (ϵ′, δ) differentially private."
REFERENCES,0.15349740932642486,"Since np > n2 and np > n3, the problem holds the constraints of Claim D.30. Therefore one
sample from the posterior is (ϵ, δ) differentially private."
REFERENCES,0.15414507772020725,"e
−
2
x2
hβ α"
REFERENCES,0.15479274611398963,"2v1
(
3
32x2
hβ )2( cp"
REFERENCES,0.15544041450777202,"np
)2 + ln(0.5 −δ) ≥ϵ′ ( cp"
REFERENCES,0.1560880829015544,"np
)2 ≥(ϵ′ −ln(0.5 −δ))e"
REFERENCES,0.1567357512953368,"2
x2
hβ (32x2
hβ
3
)2 2v1 α"
REFERENCES,0.15738341968911918,"n2(γ2−1)
p
≥(ϵ′ −ln(0.5 −δ))e"
REFERENCES,0.15803108808290156,"2
x2
hβ (32x2
hβ
3
)2 2v1 α"
REFERENCES,0.15867875647668395,np ≥((ϵ′ −ln(0.5 −δ))e
REFERENCES,0.15932642487046633,"2
x2
hβ (32x2
hβ
3
)2 2v1 α )"
REFERENCES,0.15997409326424872,"1
2(γ2−1) (10)"
REFERENCES,0.16062176165803108,"A.1
POSTERIOR SAMPLING PRIVACY"
REFERENCES,0.16126943005181346,"Proof Lemma 4.1. eq. 11 is a known result for the Bayesian inference problem for a linear model
with Gaussian noise with known precision parameter (β) and a conjugate prior (Bishop (2006) -
3.49-4.51. for details). By choosing the basis function to be φ(x) = x, working in one dimension,"
REFERENCES,0.16191709844559585,"and choosing m0 = 0, S0 = α−1, we get the linear model deﬁned in eq. 4 and matching posterior
described in Lemma 4.1."
REFERENCES,0.16256476683937823,"p(w|t) = N(w; mN, SN); mN = SN(S−1
0 m0 + βΦT t); S−1
N = S−1
0
+ βΦT Φ
(11)"
REFERENCES,0.16321243523316062,"Proof Lemma 4.2. By deﬁnition 3, for a single sample from the posterior to be (ν, ϵ′) RDP, the
R´enyi divergence of order ν between any adjacent databases needs to be bounded. We consider two
adjacent databases D, ˆD ∈D, and w.l.o.g, deﬁne that they differ in the last sample (where it is
also allowed to be (0, 0) for one of them, which saves us the need to consider also a neighbouring
database with a size smaller by 1). To ease the already complex and detailed calculations, we use
deﬁnitions in eq .12."
REFERENCES,0.163860103626943,"D = {xi, yi}n−1
i=1 ∪{xn, yn}, ˆD = {xi, yi}n−1
i=1 ∪{ˆxn, ˆyn} z = n−1
X"
REFERENCES,0.1645077720207254,"i=1
x2
i , q = n−1
X"
REFERENCES,0.16515544041450778,"i=1
yixi
(12)"
REFERENCES,0.16580310880829016,"According to Lemma 4.1 and with deﬁnitions in eq. 12, the posterior distributions are"
REFERENCES,0.16645077720207255,"p(θ|D) = N(θ; µ, σ2); µ =
β(q + xnyn)
α + (z + x2n)β ; σ2 =
1
α + (z + xn)β"
REFERENCES,0.16709844559585493,"p(θ| ˆD) = N(θ; ˆµ, ˆσ2); ˆµ =
β(q + ˆxnˆyn)
α + (z + ˆx2n)β ; ˆσ2 =
1
α + (z + ˆxn)β"
REFERENCES,0.16774611398963732,".
(13)"
REFERENCES,0.16839378238341968,"By Gil et al. (2013), the R´eyni divergence of order ν, - Dν(f1||f2) - for f1, f2, uni-variate normal
distributions with means µ1, µ2 and variances σ1, σ2 accordingly, is"
REFERENCES,0.16904145077720206,Dν(f1||f2) = ln σ1
REFERENCES,0.16968911917098445,"σ2
+ 1"
REFERENCES,0.17033678756476683,"2(ν −1) ln
σ2
2
(σ2
f1,f2)∗ν
+ 1"
REFERENCES,0.17098445595854922,"2
ν(µ1 −µ2)2"
REFERENCES,0.1716321243523316,"(σ2)∗ν
(σ2
f1,f2)∗
ν = νσ2
2 + (1 −ν)σ2
1 > 0
."
REFERENCES,0.172279792746114,"Therefore, for p(θ|D) and p(θ| ˆD), the R´enyi divergence of order ν is as shown in eq. 14, where we
omit the subscript for (σ2)∗
ν since it is clear from context to which distributions it applies."
REFERENCES,0.17292746113989638,Dν(p(θ|D)||p(θ| ˆD)) = ln σ
REFERENCES,0.17357512953367876,ˆσ + 1
REFERENCES,0.17422279792746115,"2(ν −1) ln
ˆσ2"
REFERENCES,0.17487046632124353,"(σ2)∗ν
+ 1"
REFERENCES,0.17551813471502592,"2
ν(µ −ˆµ)2"
REFERENCES,0.17616580310880828,"(σ2)∗ν
(σ2)∗
ν = νˆσ2 + (1 −ν)σ2
(14)"
REFERENCES,0.17681347150259066,"According to claim D.25, (σ2)∗
ν > 0. Therefore the value Dν(p(θ|D), p(θ| ˆD)) exists. In order to
prove R´enyi differential privacy, each of the terms of Dν(p(θ|D), p(θ| ˆD)) is bounded separately.
The bounds on each of the terms are proved at claims D.26,D.27, and D.28."
REFERENCES,0.17746113989637305,"Proof Lemma 4.3. By Lemma 4.2, sampling from the posterior is (ν, ϵ1)-RDP, therefore by Lemma
3.1, sampling from the posterior is also (ϵ1 + ln( 1"
REFERENCES,0.17810880829015543,"δ )
ν−1 , δ) differentially private."
REFERENCES,0.17875647668393782,"A.2
STOCHASTIC GRADIENT LANGEVIN DYNAMICS PRIVACY"
REFERENCES,0.1794041450777202,Proof Lemma 4.4.
REFERENCES,0.1800518134715026,"p(ˆθj > µj|D2) = n
X"
REFERENCES,0.18069948186528498,"r=1
p(ˆθr
j > µj|D2)p(ˆθj = ˆθr
j|D2) = n
X"
REFERENCES,0.18134715025906736,"r=1
p(ˆθj −ˆµr
j > µj −ˆµr
j|D2)p(ˆθj = ˆθr
j|D2) ="
N,0.18199481865284975,"1
n n
X"
N,0.18264248704663213,"r=1
p(ˆθj −ˆµr
j > µj −ˆµr
j|D2) ≤"
N,0.18329015544041452,"1
n n
X"
N,0.18393782383419688,"r=1
exp(−(µj −ˆµr
j)2"
N,0.18458549222797926,"2(σr
j)2
)"
N,0.18523316062176165,"Where the inequality holds due to Chernoff bound (For further details, see Wainwright (2019))."
N,0.18588082901554404,"Proof Lemma 4.5. By lemma A.5, for n > max{ α"
N,0.18652849740932642,"x2β ,
α
x2
hβ (e"
N,0.1871761658031088,"2
x2β −2) +
1
2x2β ,
1
2αx2
hβ −
1
x2
hβ } eq. 15"
N,0.1878238341968912,holds for some ˙k ∈R>0. We can see that this lower bound is dominated by c2
N,0.18847150259067358,"n2 , therefore proving
Lemma 4.5.
(µ(⌈˙k⌉+1)n −ˆµr
(⌈˙k⌉+1)n)2"
N,0.18911917098445596,"(σr
(⌈˙k⌉+1)n)2
≥e
−
2
x2
hβ α"
N,0.18976683937823835,"v1
(
3
32x2
hβ )2( c n)2"
N,0.19041450777202074,"v1 = max{6, 1 + 2e"
N,0.19106217616580312,"1
x2
hβ } (15)"
N,0.19170984455958548,"Proof Lemma 4.6. By Lemma A.6, for n > max{
α
x2
hβ ,
α
x2
hβ (e"
N,0.19235751295336787,"2
x2
hβ −2)+
1
2x2
hβ ,
1
2αx2
hβ −
1
x2
hβ }, there"
N,0.19300518134715025,"exists T ∈Z>0 (Marked in Lemma A.6 as ⌈˙k⌉) such that running SGLD for the Bayesian linear
regression problem over D1 for T steps will not be (ϵ, δ) differentially for ϵ < ϵ′, as deﬁned in eq.
16, and δ < 0.5. Since ϵ′ is dominated by c2"
N,0.19365284974093264,"n2 , this proves the lemma."
N,0.19430051813471502,"ϵ′ = e−
2
x2β α"
N,0.1949481865284974,"2v1
(
3
32x2
hβ )2( c"
N,0.1955958549222798,n)2 + ln(0.5 −δ)
N,0.19624352331606218,"v1 = max{6, 1 + 2e"
N,0.19689119170984457,"1
x2
hβ } (16)"
N,0.19753886010362695,"A.3
STOCHASTIC GRADIENT LANGEVIN DYNAMICS DETAILED ANALYSIS"
N,0.19818652849740934,"In order to ease the analysis of the SGLD process, markings in eq. 17 are used. xh, α, β, c, n are as
deﬁned for the Bayesian linear regression problem, and η is deﬁned in subsection 4.2."
N,0.19883419689119172,λ = [1 −η
N,0.19948186528497408,"2(α + nx2
hβ)], ˆλ = [1 −η"
N,0.20012953367875647,2(α + n(xh
N,0.20077720207253885,"2 )2β)], ρ = η"
N,0.20142487046632124,"2ncx2
hβ, ˆρ = η"
N,0.20207253886010362,2nc(xh
N,0.202720207253886,"2 )2β
(17)"
N,0.2033678756476684,"Lemma A.1. The forms of ˆθr
(k+1)n are"
N,0.20401554404145078,"ˆθ1
(k+1)n = θ0ˆλk+1λ(n−1)(k+1) + k
X"
N,0.20466321243523317,"j=0
(ˆλλn−1)j[ˆρλn−1 + ρ n−2
X"
N,0.20531088082901555,"i=0
λi + √η n−1
X"
N,0.20595854922279794,"i=0
λiξi]"
N,0.20660621761658032,"ˆθr>1
(k+1)n = θ0(ˆλλn−1)k+1+"
N,0.20725388601036268,"  r−1
X"
N,0.20790155440414507,"i=1
(ρ + √ηξ)ˆλλn−i−1 + (ˆρ + √ηξ)λn−r + n
X"
N,0.20854922279792745,"j=r+1
(ρ +
p"
N,0.20919689119170984,"ξη)λn−j
k
X"
N,0.20984455958549222,"l=0
(ˆλλn−1)l."
N,0.2104922279792746,"Proof Lemma A.1. Welling & Teh (2011) deﬁne the SGLD update rule as in eq. 3. This rule can be
applied to the Bayesian linear regression problem over databases D1, D2 as following"
N,0.211139896373057,"p(θj) = N(θj; 0, α−1) ⇒ln p(θj) = ln(
1
√"
N,0.21178756476683938,2πα−1 ) −1
N,0.21243523316062177,"2θ2
jα ⇒∇θjp(θj) = −θjα"
N,0.21308290155440415,"p(yi|θj) = N(yj; θjxi, β−1) ⇒ln p(yi|θj) = ln(
1
p"
N,0.21373056994818654,2πβ−1 ) −1
N,0.21437823834196892,2(yi −θjxi)2β ⇒
N,0.21502590673575128,∇θjp(yi|θj) = (yi −θjxi)xiβ ⇒
N,0.21567357512953367,θj+1 = θj + η
N,0.21632124352331605,2[−θjα + n(yi −θjxj)xiβ] + √ηjξi =
N,0.21696891191709844,θj[1 −η
N,0.21761658031088082,"2(α + nx2
jβ)] + η"
N,0.2182642487046632,2nyixiβ + √ηξj =
N,0.2189119170984456,θj[1 −η
N,0.21955958549222798,"2(α + nx2
jβ)] + η"
N,0.22020725388601037,"2ncx2
i β + √ηξj ."
N,0.22085492227979275,"By using standard tools for solving ﬁrst-order non-homogeneous recurrence relations with variable
coefﬁcients, the value of ˆθ1
n can be found."
N,0.22150259067357514,"ˆθ1
n = ˆλλn−1(θ0ˆλ + ˆρ + √ηξ ˆλ
+ n
X i=2"
N,0.22215025906735753,ρ + √ηξ
N,0.22279792746113988,ˆλλi−1 ) =
N,0.22344559585492227,"θ0ˆλλn−1 + (ˆρ + √ηξ)λn−1 + (ρ + √ηξ) n
X"
N,0.22409326424870465,"i=2
λn−1−(i−1) ="
N,0.22474093264248704,"θ0ˆλλn−1 + (ˆρ + √ηξ)λn−1 + (ρ + √ηξ) n
X"
N,0.22538860103626943,"i=2
λn−1−(i−1) ="
N,0.2260362694300518,"θ0ˆλλn−1 + (ˆρ + √ηξ)λn−1 + (ρ + √ηξ) n−2
X"
N,0.2266839378238342,"i=0
λi ="
N,0.22733160621761658,"θ0ˆλλn−1 + ˆρλn−1 + ρ n−2
X"
N,0.22797927461139897,"i=0
λi + √ηξ n−1
X"
N,0.22862694300518135,"i=0
λi."
N,0.22927461139896374,"Now by deﬁning a new series - ˆθ1
(k+1)n = c1ˆθ1
kn + c2, and using the tools for solving ﬁrst order"
N,0.22992227979274613,"non-homogeneous recurrence relations with constant coefﬁcients, the value of ˆθ1
kn can be found"
N,0.23056994818652848,"ˆθ1
kn = ck
1(
ˆθ1
n
c1
+ k
X i=2"
N,0.23121761658031087,"c2
ci
1
) = θ1
nck−1
1
+ k
X"
N,0.23186528497409326,"i=2
c2ck−i
1
="
N,0.23251295336787564,"θ1
nck−1
1
+ c2 k−2
X"
N,0.23316062176165803,"i=0
ci
1 = (θ0c1 + c2)ck−1
1
+ c2 k−2
X"
N,0.2338082901554404,"i=0
ci
1 ="
N,0.2344559585492228,"θ0(ˆλλn−1)k + (ˆρλn−1 + ρ n−2
X"
N,0.23510362694300518,"i=0
λi + √ηξ n−1
X"
N,0.23575129533678757,"i=0
λi) k−1
X"
N,0.23639896373056996,"j=0
(ˆλλn−1)j."
N,0.23704663212435234,"The proof for ˆθr
kn is done in similar manner."
N,0.23769430051813473,"Corollary A.1. ˆθr
(k+1)n ∼N(ˆθr
(k+1)n; ˆµr
(k+1)n, (ˆσr
(k+1)n)2)."
N,0.23834196891191708,"Lemma A.2. µkn+n −ˆµr
kn+n ≥λn−1 ncx2
hβ
α+nx2
hβ λk(n−1)(ˆλk+1 −λk+1)."
N,0.23898963730569947,"Proof Lemma A.2. The proof of this lemma is separated into two cases, for r = 1 and for r > 1.
For r = 1, it is easy to derive eq. 18 from lemma A.1, using E[θ0] = 0 and E[ξ] = 0."
N,0.23963730569948186,"ˆµ1
(k+1)n = ρ n−2
X"
N,0.24028497409326424,"i=0
λi
k
X"
N,0.24093264248704663,"j=0
(ˆλλ(n−1))j + ˆρλn−1
k
X"
N,0.241580310880829,"j=0
(ˆλλ(n−1))j"
N,0.2422279792746114,"µkn+n = ρ n−2
X"
N,0.24287564766839378,"i=0
λi
k
X"
N,0.24352331606217617,"j=0
λjn + ρλn−1
k
X"
N,0.24417098445595856,"r=0
λrn
(18)"
N,0.24481865284974094,We use the sum of a geometric sequence to get
N,0.24546632124352333,"ˆµ1
(k+1)n = ρ n−2
X"
N,0.24611398963730569,"i=0
λi
k
X"
N,0.24676165803108807,"j=0
(ˆλλ(n−1))j + ˆρλn−1
k
X"
N,0.24740932642487046,"j=0
(ˆλλ(n−1))j = (ρ(1 −λn−1"
N,0.24805699481865284,"1 −λ
) + ˆρλn−1)1 −(ˆλλn−1)k+1"
N,0.24870466321243523,"1 −ˆλλn−1
."
N,0.24935233160621761,Therefore the difference between the means can be lower bounded:
N,0.25,"µkn+n −ˆµ1
kn+n ="
N,0.2506476683937824,1 −λ(k+1)n
N,0.25129533678756477,"1 −λn
[ρ(1 −λn−1"
N,0.25194300518134716,"1 −λ
) + ρλn−1] −1 −(ˆλλ(n−1))k+1"
N,0.25259067357512954,"1 −ˆλλn−1
[ρ(1 −λn−1"
N,0.25323834196891193,"1 −λ
) + ˆρλn−1] =∗"
N,0.2538860103626943,1 −λ(k+1)n
N,0.2545336787564767,"1 −λn
ncx2β
α + nx2
hβ (1 −λn) −1 −(ˆλλ(n−1))k+1"
N,0.2551813471502591,"1 −ˆλλn−1
ncx2β
α + nx2
hβ (1 −λn−1(1"
N,0.25582901554404147,4λ + 3 4)) =
N,0.25647668393782386,"(1 −λ(k+1)n)
ncx2β
α + nx2
hβ −1 −(ˆλλ(n−1))k+1"
N,0.25712435233160624,"1 −ˆλλn−1
ncx2β
α + nx2
hβ (1 −λn−1(1"
N,0.25777202072538863,4λ + 3 4)) =
N,0.25841968911917096,"ncx2β
α + nx2
hβ [(1 −λ(k+1)n) −1 −(ˆλλ(n−1))k+1"
N,0.25906735751295334,"1 −ˆλλn−1
(1 −λn−1(1"
N,0.25971502590673573,4λ + 3
N,0.2603626943005181,4))] =∗∗
N,0.2610103626943005,"ncx2β
α + nx2
hβ
 λn−1 3"
N,0.2616580310880829,"4
η
2α(1 −ˆλk+1λ(k+1)(n−1)) + λ(k+1)(n−1)(ˆλk+1 −λk+1)(1 −λn−1ˆλ)"
N,0.2623056994818653,"1 −λn−1ˆλ 
≥"
N,0.26295336787564766,"ncx2β
α + nx2
hβ
 λ(k+1)(n−1)(ˆλk+1 −λk+1)(1 −λn−1ˆλ)"
N,0.26360103626943004,"1 −λn−1ˆλ 
="
N,0.26424870466321243,"ncx2β
α + nx2
hβ λ(k+1)(n−1)(ˆλk+1 −λk+1) ="
N,0.2648963730569948,"λn−1
ncx2β
α + nx2
hβ λk(n−1)(ˆλk+1 −λk+1)"
N,0.2655440414507772,"where equality * holds from claims D.1, D.2, D.3, equality ** holds from claim D.5, and the in-
equality holds because λ < ˆλ < 1. This proves Lemma A.2 for r = 1."
N,0.2661917098445596,"For the case of r > 1, from Lemma A.1 it is easy to see"
N,0.266839378238342,"ˆθr>1
(k+1)n =

[θ0λr−1 + ρ r−2
X"
N,0.26748704663212436,"i=0
λi + √η r−2
X"
N,0.26813471502590674,"i=0
λiξi]ˆλkλk(n−1)+ k−1
X"
N,0.26878238341968913,"j=0
(ˆλλn−1)j[ˆρλn−1 + ρ n−2
X"
N,0.2694300518134715,"i=0
λi + √η n−1
X"
N,0.2700777202072539,"i=0
λiξi]
ˆλλn−r+"
N,0.2707253886010363,ˆρλn−r + ρ
N,0.2713730569948187,"n−r−1
X"
N,0.27202072538860106,"j=0
λj + √η n−r
X"
N,0.27266839378238344,"j=0
ξλj ."
N,0.27331606217616583,"Therefore ˆµr>1
kn+n follows"
N,0.27396373056994816,"ˆµr>1
(k+1)n = 
[ρ r−2
X"
N,0.27461139896373055,"i=0
λi]ˆλkλk(n−1) + k−1
X"
N,0.27525906735751293,"j=0
(ˆλλn−1)j[ˆρλn−1 + ρ n−2
X"
N,0.2759067357512953,"i=0
λi]
ˆλλn−r + ˆρλn−r + ρ"
N,0.2765544041450777,"n−r−1
X"
N,0.2772020725388601,"j=0
λj."
N,0.2778497409326425,Consequently the difference in means for r > 1 can be lower bounded:
N,0.27849740932642486,"µkn+n −ˆµr
kn+n ="
N,0.27914507772020725,"λn−r[λρλkλk(n−1)
r−2
X"
N,0.27979274611398963,"i=0
λi + λ k−1
X"
N,0.280440414507772,"j=0
(λλn−1)j(ρλn−1 + ρ n−2
X"
N,0.2810880829015544,"i=0
λi)−"
N,0.2817357512953368,"ˆλρˆλkλk(n−1)
r−2
X"
N,0.2823834196891192,"i=0
λi −ˆλ k−1
X"
N,0.28303108808290156,"j=0
(ˆλλn−1)j(ˆρλn−1 + ρ n−2
X"
N,0.28367875647668395,"i=0
λi)] + λn−r(ρ −ˆρ) ="
N,0.28432642487046633,"λn−rλk(n−1)ρ(λk+1 −ˆλk+1) r−2
X"
N,0.2849740932642487,"i=0
λi + λn−r
k−1
X"
N,0.2856217616580311,"j=0
λ(n−1)j[λn−1(ρλj+1−"
N,0.2862694300518135,"ˆρˆλj+1) + (λj+1 −ˆλj+1)ρ n−2
X"
N,0.2869170984455959,"i=0
λi] + λn−r(ρ −ˆρ) =∗"
N,0.28756476683937826,λn−rλk(n−1)ρ(λk+1 −ˆλk+1)1 −λr−1
N,0.28821243523316065,"1 −λ
+ λn−r
ncx2
hβ
α + nx2
hβ [λ(1 −λkn)−"
N,0.28886010362694303,ˆλ1 −(λn−1ˆλ)k
N,0.28950777202072536,"1 −λn−1ˆλ
(1 −λn(3"
N,0.29015544041450775,4λ−1 + 1
N,0.29080310880829013,4))] + λn−r(ρ −ˆρ) =∗∗
N,0.2914507772020725,λn−rλk(n−1)ρ(λk+1 −ˆλk+1)1 −λr−1
N,0.2920984455958549,"1 −λ
+ λn−r
ncx2
hβ
α + nx2
hβ

(λ −ˆλ)+"
N,0.2927461139896373,λn−1[ 3
N,0.2933937823834197,"4
η
2α(1 −ˆλkλk(n−1))]"
N,0.29404145077720206,"1 −ˆλλn−1
+ λk(n−1)(ˆλk+1 −λk+1)

+ λn−r(ρ −ˆρ) =∗∗∗"
N,0.29468911917098445,"λn−r
ncx2
hβ
α + nx2
hβ λk(n−1)(λk+1 −ˆλk+1)(1 −λr−1) + λn−r
ncx2
hβ
α + nx2
hβ

(λ −ˆλ)"
N,0.29533678756476683,+ λn−1[ 3
N,0.2959844559585492,"4
η
2α(1 −ˆλkλk(n−1))]"
N,0.2966321243523316,"1 −ˆλλn−1
+ λk(n−1)(ˆλk+1 −λk+1)

+ λn−r(ρ −ˆρ) ="
N,0.297279792746114,"λn−r
ncx2
hβ
α + nx2
hβ λk(n−1)(λk+1 −ˆλk+1)[1 −λr−1 −1]+"
N,0.2979274611398964,"λn−r
ncx2
hβ
α + nx2
hβ (λ −ˆλ + λn−1[ 3"
N,0.29857512953367876,"4
η
2α(1 −ˆλkλk(n−1))]"
N,0.29922279792746115,"1 −ˆλλn−1
) + λn−r(ρ −ˆρ) ="
N,0.29987046632124353,"λn−r
ncx2
hβ
α + nx2
hβ λk(n−1)(ˆλk+1 −λk+1)λr−1+"
N,0.3005181347150259,"λn−r
ncx2
hβ
α + nx2
hβ (λ −ˆλ + λn−1[ 3"
N,0.3011658031088083,"4
η
2α(1 −ˆλkλk(n−1))]"
N,0.3018134715025907,"1 −ˆλλn−1
) + λn−r(ρ −ˆρ) ="
N,0.3024611398963731,"λn−1
ncx2
hβ
α + nx2
hβ λk(n−1)(ˆλk+1 −λk+1)+"
N,0.30310880829015546,"λn−r
ncx2
hβ
α + nx2
hβ (λ −ˆλ + λn−1[ 3"
N,0.30375647668393785,"4
η
2α(1 −ˆλkλk(n−1))]"
N,0.30440414507772023,"1 −ˆλλn−1
) + λn−r(ρ −ˆρ) >∗∗∗∗"
N,0.30505181347150256,"λn−1
ncx2
hβ
α + nx2
hβ λk(n−1)(ˆλk+1 −λk+1)"
N,0.30569948186528495,"where equality * holds from claims D.6 and D.7, equality ** holds from claim D.10, equality ***
holds from claim D.1, and equality **** holds from claim D.11 and ˆλ > λ."
N,0.30634715025906734,"Lemma A.3. For x2
hβ > 3, n >
1
2αx2
hβ −
1
x2
hβ , ∃˙k ∈R+ such that upper bounds deﬁned in eq. 19"
N,0.3069948186528497,hold for all 0 < k ≤˙k:
N,0.3076424870466321,"(σ1
(k+1)n)2 ≤2(ˆλλn−1)2 1"
N,0.3082901554404145,α(ˆλλn−1)2k
N,0.3089378238341969,"(σr>1
(k+1)n)2 ≤6(ˆλλn−r)2 1"
N,0.30958549222797926,"α(ˆλλn−1)2k.
(19)"
N,0.31023316062176165,"Proof Lemma A.3. The proof will be separated into two cases, r = 1 and r > 1. (ˆσ1
kn+n)2 can be
easily computed from lemma A.1 using the fact that both the noise and prior are distributed normally.
A ﬁrst general upper bound on (ˆσ1
kn+n)2 is found at eq. 20."
N,0.31088082901554404,"(σ1
kn+n)2 = 1"
N,0.3115284974093264,"α(ˆλλ(n−1))2(k+1) + η n−1
X"
N,0.3121761658031088,"i=0
λ2i
k
X"
N,0.3128238341968912,"j=0
(ˆλ2λ2(n−1))j ="
N,0.3134715025906736,"(ˆλλ(n−1))2(k+1)[ 1 α + η n−1
X"
N,0.31411917098445596,"i=0
λ2i
k
X j=0"
N,0.31476683937823835,(ˆλλ(n−1))2j
N,0.31541450777202074,(ˆλλ(n−1))2(k+1) ] =
N,0.3160621761658031,"(ˆλλ(n−1))2(k+1)[ 1 α + η n−1
X"
N,0.3167098445595855,"i=0
λ2i
k
X"
N,0.3173575129533679,"j=0
(ˆλλ(n−1))2(j−(k+1))] ≤"
N,0.3180051813471503,"(ˆλλ(n−1))2(k+1)[ 1 α + η n−1
X"
N,0.31865284974093266,"i=0
λ2i
k
X"
N,0.31930051813471505,"j=0
λ2n(j−(k+1))] ="
N,0.31994818652849744,(ˆλλ(n−1))2(k+1)[ 1 α + η
N,0.32059585492227977,"(k+1)n
X"
N,0.32124352331606215,"i=1
λ−2i] ="
N,0.32189119170984454,(ˆλλ(n−1))2(k+1)[ 1
N,0.3225388601036269,α + ηλ−2 1 −λ−2(k+1)n
N,0.3231865284974093,"1 −λ−2
] (20)"
N,0.3238341968911917,where the inequality holds because λ < ˆλ
N,0.3244818652849741,"By claim D.12, this upper bound can be further bounded for ˙k ≤
1
2n logλ(
1
1+ 1"
N,0.32512953367875647,αη (1−λ2)) −1 such
N,0.32577720207253885,"that eq. 21 will hold, therefore proving the bound for r = 1."
N,0.32642487046632124,(ˆλλ(n−1))2( ˙k+1)[ 1
N,0.3270725388601036,α + ηλ−2 1 −λ−2( ˙k+1)n
N,0.327720207253886,"1 −λ−2
] ≤2(ˆλλ(n−1))2( ˙k+1) 1"
N,0.3283678756476684,"α
(21)"
N,0.3290155440414508,"For r > 1, (ˆσr>1
kn+n)2 can be bounded as following"
N,0.32966321243523317,"(σr>1
kn+n)2 ="
N,0.33031088082901555,"(ˆλλn−r)2η[(ˆλkλk(n−1))2
r−2
X"
N,0.33095854922279794,"i=0
λ2i + k−1
X"
N,0.3316062176165803,"j=0
(ˆλλn−1)2j
n−1
X"
N,0.3322538860103627,"i=0
λ2i]+ η n−r
X"
N,0.3329015544041451,"i=0
λ2i + 1"
N,0.3335492227979275,α(ˆλλn−1)2k(ˆλλn−1)2 ≤∗
N,0.33419689119170987,"(ˆλλn−r)2η[(ˆλkλk(n−1))2
r−2
X"
N,0.33484455958549225,"i=0
λ2i + k−1
X"
N,0.33549222797927464,"j=0
(ˆλλn−1)2j
n−1
X"
N,0.33613989637305697,"i=0
λ2i]+ η n−r
X"
N,0.33678756476683935,"i=0
λ2i + 1"
N,0.33743523316062174,α(ˆλλn−1)2k(ˆλλn−r)2 =
N,0.3380829015544041,(ˆλλn−r)2[ 1
N,0.3387305699481865,"α(ˆλλn−1)2k + η(ˆλλn−1)2k
r−2
X"
N,0.3393782383419689,"i=0
λ2i + η k−1
X"
N,0.3400259067357513,"j=0
(ˆλλn−1)2j
n−1
X"
N,0.34067357512953367,"i=0
λ2i] + η n−r
X"
N,0.34132124352331605,"i=0
λ2i ≤∗∗"
N,0.34196891191709844,(ˆλλn−r)2[ 1
N,0.3426165803108808,"α(ˆλλn−1)2k + η(ˆλλn−1)2k
n−1
X"
N,0.3432642487046632,"i=0
λ2i + η k−1
X"
N,0.3439119170984456,"j=0
(ˆλλn−1)2j
n−1
X"
N,0.344559585492228,"i=0
λ2i] + η n−r
X"
N,0.34520725388601037,"i=0
λ2i ≤∗∗∗"
N,0.34585492227979275,2(ˆλλn−r)2[ 1
N,0.34650259067357514,"α(ˆλλn−1)2 ˙k + η(ˆλλn−1)2k
n−1
X"
N,0.3471502590673575,"i=0
λ2i + η k−1
X"
N,0.3477979274611399,"j=0
(ˆλλn−1)2j
n−1
X"
N,0.3484455958549223,"i=0
λ2i] (22)"
N,0.3490932642487047,"where inequality * follows from λ < 1 and r > 1, inequality ** follows from r ≤n, and inequality
*** holds from claim D.15."
N,0.34974093264248707,"For k ≤
1
2n logλ(
1
1+ 1"
N,0.35038860103626945,"αη (1−λ2)) −1, this bound can be further developed"
N,0.35103626943005184,2(ˆλλn−r)2[ 1
N,0.35168393782383417,"α(ˆλλn−1)2 ˙k + η(ˆλλn−1)2k
n−1
X"
N,0.35233160621761656,"i=0
λ2i + η k−1
X"
N,0.35297927461139894,"j=0
(ˆλλn−1)2j
n−1
X"
N,0.3536269430051813,"i=0
λ2i] ≤"
N,0.3542746113989637,6(ˆλλn−r)2 1
N,0.3549222797927461,"α(ˆλλn−1)2 ˙k
.
(23)"
N,0.3555699481865285,"The inequality holds from claims D.12, D.14, which provide the bound for r > 1. All that is left is
to prove that
1
2n logλ(
1
1+ 1"
N,0.35621761658031087,"αη (1−λ2)) −1 > 0, which is done in Claim D.22."
N,0.35686528497409326,"Lemma A.4. Mark ˙k =
1
2n logλ(
1
1+ 1"
N,0.35751295336787564,"αη (1−λ2)) −1, for the conditions of Lemma A.3"
N,0.358160621761658,"(σ1
⌈˙k⌉n+n)2 ≤(1 + 2e"
N,0.3588082901554404,"1
x2β )(ˆλλn−1)2 1"
N,0.3594559585492228,α(ˆλλ(n−1))2⌈˙k⌉
N,0.3601036269430052,"(σr>1
⌈˙k⌉n+n)2 ≤6(ˆλλn−r)2 1"
N,0.36075129533678757,α(ˆλλn−1)2⌈˙k⌉.
N,0.36139896373056996,"Proof Lemma A.4. This proof will be separated into two cases, for r > 1 and for r = 1. For r > 1,
the bound found in eq. 22, has no dependence on the choice of k, therefore holds also for ⌈˙k⌉. This
bound was, in turn, developed for ˙k at eq. 23 using three claims. If these claims also hold for ⌈˙k⌉,
then the bound in eq. 23 also holds for ⌈˙k⌉, and the lemma is proved for r > 1."
N,0.36204663212435234,"Claims D.14, D.12 hold for all k
≤
1
2n logλ(
1
1+ 1"
N,0.3626943005181347,"αη (1−λ2)), and since ⌈˙k⌉
≤
˙k + 1
="
N,0.3633419689119171,"1
2n logλ(
1
1+ 1"
N,0.3639896373056995,"αη (1−λ2)), they holds for ⌈˙k⌉. Claim D.15 was proved for all k, hence also holds for ⌈˙k⌉."
N,0.3646373056994819,"For r = 1, the bound found at eq. 20 is applicable for all k, hence"
N,0.36528497409326427,"(σ1
(⌈˙k⌉+1)n)2 ≤(ˆλλn−1)2(⌈˙k⌉+1)[ 1"
N,0.36593264248704666,α + ηλ−2 1 −λ−2(⌈˙k⌉+1)n
N,0.36658031088082904,"1 −λ−2
] ≤(ˆλλn−1)2(⌈˙k⌉+1) 1"
N,0.36722797927461137,α(1 + 2e
N,0.36787564766839376,"1
x2β )"
N,0.36852331606217614,where the last inequality holds from claim D.17.
N,0.36917098445595853,"Lemma A.5. For
˙k deﬁned in Lemma A.4, the conditions of Lemma A.3, and n
>"
N,0.3698186528497409,"max{
α
x2
hβ ,
α
x2
hβ (e"
N,0.3704663212435233,"2
x2
hβ −2) +
1
2x2
hβ }"
N,0.3711139896373057,"(µ⌈˙k⌉n+n −ˆµr
⌈˙k⌉n+n)2"
N,0.37176165803108807,"(σr
⌈˙k⌉n+n)2
≥e
−
2
x2
hβ α"
N,0.37240932642487046,"v1
(
3
32x2
hβ )2( c n)2"
N,0.37305699481865284,"v1 = max{6, 1 + 2e"
N,0.37370466321243523,"1
x2
hβ }."
N,0.3743523316062176,Proof Lemma A.5.
N,0.375,"(µ⌈˙k⌉n+n −ˆµr
⌈˙k⌉n+n)2"
N,0.3756476683937824,"σr
⌈˙k⌉n+n
≥"
N,0.37629533678756477," 
λn−1 ncx2
hβ
α+nx2
hβ λ⌈˙k⌉(n−1)(ˆλ⌈˙k⌉+1 −λ⌈˙k⌉+1)
2"
N,0.37694300518134716,v1(ˆλλn−r)2 1
N,0.37759067357512954,"α(ˆλλn−1)2⌈˙k⌉
="
N,0.37823834196891193,"λ2⌈˙k⌉(n−1) 
λn−1 ncx2
hβ
α+nx2
hβ (ˆλ⌈˙k⌉+1 −λ⌈˙k⌉+1)
2"
N,0.3788860103626943,v1(ˆλλn−r)2 1
N,0.3795336787564767,"α(ˆλλn−1)2⌈˙k⌉
="
N,0.3801813471502591," 
λn−1 ncx2
hβ
α+nx2
hβ (ˆλ⌈˙k⌉+1 −λ⌈˙k⌉+1)
2"
N,0.38082901554404147,v1(ˆλλn−r)2 1
N,0.38147668393782386,"α ˆλ2⌈˙k⌉
="
N,0.38212435233160624,αλ2(r−1)
N,0.38277202072538863,"v1
(
ncx2
hβ
α + nx2
hβ )2 (ˆλ⌈˙k⌉+1 −λ⌈˙k⌉+1)2"
N,0.38341968911917096,"ˆλ2⌈˙k⌉+1
= αλ2(r−1)"
N,0.38406735751295334,"v1
(
ncx2
hβ
α + nx2
hβ )2(1 −λ⌈˙k⌉+1"
N,0.38471502590673573,ˆλ⌈˙k⌉+1 )2 ≥
N,0.3853626943005181,αλ2(r−1)
N,0.3860103626943005,"v1
(
ncx2
hβ
α + nx2
hβ )2(1 −(1 −"
N,0.3866580310880829,"3
4nx2β
(α + nx2
hβ)2 −(α + 1"
N,0.3873056994818653,4nx2β)))2 =
N,0.38795336787564766,αλ2(r−1)
N,0.38860103626943004,"v1
(
ncx2
hβ
α + nx2
hβ )2("
N,0.38924870466321243,"3
4nx2
hβ
(α + nx2
hβ)2 −(α + 1"
N,0.3898963730569948,4nx2β))2 ≥
N,0.3905440414507772,αλ2(r−1)
N,0.3911917098445596,"v1
(
ncx2
hβ
α + nx2
hβ )2("
N,0.391839378238342,"3
4nx2β
(α + nx2
hβ)2 )2 ≥αλ2(r−1)"
N,0.39248704663212436,"v1
( ncx2β"
N,0.39313471502590674,"2nx2
hβ )2("
N,0.39378238341968913,"3
4nx2β
(2nx2β)2 )2 ="
N,0.3944300518134715,αλ2(r−1)
N,0.3950777202072539,"v1
( c 2)2("
N,0.3957253886010363,"3
4
4nx2
hβ )2 = αλ2(r−1)"
N,0.3963730569948187,"v1
(
3
32x2
hβ )2( c n)2 ≥"
N,0.39702072538860106,αλ2(n−1)
N,0.39766839378238344,"v1
(
3
32x2
hβ )2( c"
N,0.39831606217616583,"n)2 ≥e
−
2
x2
hβ α"
N,0.39896373056994816,"v1
(
3
32x2
hβ )2( c n)2"
N,0.39961139896373055,"where ﬁrst inequality holds from A.3, A.4 and the deﬁnition of v1, the second inequality follows
claim D.17 and claim D.22, fourth inequality holds under the assumption of nx2
hβ > α ⇐⇒n >
α
x2
hβ , and last inequality holds from claim D.19."
N,0.40025906735751293,"Lemma A.6. For the Bayesian linear regression problem over database D1, the conditions of
Lemma A.5, and ˙k, as deﬁned in Lemma A.4, approximate sampling, by running SGLD for (⌈˙k⌉+1)n
steps, will not be (ϵ, δ) differentially private for"
N,0.4009067357512953,"δ < 0.5, ϵ < e−
2
x2β α"
N,0.4015544041450777,"2v1
(
3
32x2
hβ )2( c"
N,0.4022020725388601,n)2 + ln(0.5 −δ)
N,0.4028497409326425,"v1 = max{6, 1 + 2e"
N,0.40349740932642486,"1
x2
hβ }."
N,0.40414507772020725,"Proof Lemma A.6. According to deﬁnition 1, it is enough that there is one group, S, such that
p(θ(⌈˙k⌉+1)n ∈S|D1) > eϵp(ˆθ(⌈˙k⌉+1)n ∈S|D2) + δ, to show that releasing θ(⌈˙k⌉+1)n is not
(ϵ, δ) private.
Consider S = {s|s > µ(⌈˙k⌉+1)n}.
From claim D.23 and since θ(⌈˙k⌉+1)n ∼
N(θ(⌈˙k⌉+1)n; µ(⌈˙k⌉+1)n, σ2
(⌈˙k⌉+1)n), eq. 24 holds. The conditions for the right term to be smaller"
N,0.40479274611398963,"than 0 (thus making the approximate sampling not (ϵ, δ) private) are found in eq. 25, therefore
proving the lemma."
N,0.405440414507772,"eϵp(ˆθ(⌈˙k⌉+1)n ∈S|D2) + δ −p(ˆθ(⌈˙k⌉+1)n ∈S|D1) ≤eϵe
−e
−
2
x2β
α
2v1 (
3
32x2
hβ )2( c"
N,0.4060880829015544,"n )2
+ δ −0.5 (24)"
N,0.4067357512953368,"e
ϵ−e
−
2
x2β
α
2v1 (
3
32x2
hβ )2( c"
N,0.4073834196891192,"n )2
+ δ −0.5 < 0"
N,0.40803108808290156,"e
ϵ−e
−
2
x2β
α
2v1 (
3
32x2
hβ )2( c"
N,0.40867875647668395,"n )2
< 0.5 −δ"
N,0.40932642487046633,"ϵ −e−
2
x2β α"
N,0.4099740932642487,"2v1
(
3
32x2
hβ )2( c"
N,0.4106217616580311,n)2 < ln(0.5 −δ)
N,0.4112694300518135,"ϵ < e−
2
x2β α"
N,0.4119170984455959,"2v1
(
3
32x2
hβ )2( c"
N,0.41256476683937826,n)2 + ln(0.5 −δ) (25)
N,0.41321243523316065,"B
PROPOSE TEST SAMPLE SUPPLEMENTARY"
N,0.41386010362694303,nmin which is used in algorithm 4.3 is deﬁned as following
N,0.41450777202072536,ν = 2 ln( 1
N,0.41515544041450775,"δ )
ϵ
+ 1"
N,0.41580310880829013,"nb1 = max{1 + x2
h
x2
l"
N,0.4164507772020725,"8
ϵ , 1 + ν x2
h
x2
l
(1 + 8(ν −1)"
N,0.4170984455958549,"ϵ
), (16νβx4
h
9
10ϵx2
l
)"
N,0.4177461139896373,"1
1−2γ1 , (32νβ"
N,0.4183937823834197,"ϵ
((x2
hβ)(x2
hα + x4
hβ)
9
10(x2
l β)2
) ˘m)"
N,0.41904145077720206,"1
2−γ1 , (32νβ"
N,0.41968911917098445,"ϵ
((x2
hβ)(x2
hα + x4
hβ)
9
10(x2
l β)2
))"
N,0.42033678756476683,"1
2−2γ1 , (8ν"
N,0.4209844559585492,"ϵ ((x2
hα + x4
hβ)2"
N,0.4216321243523316,"9
10x6
l β
) ˘m)
2
3 , (8ν"
N,0.422279792746114,"ϵ ((x2
hα + x4
hβ)2"
N,0.4229274611398964,"9
10x6
l β
))"
N,0.42357512953367876,"2
3−2γ1 }"
N,0.42422279792746115,"nb2 = max{1 + x2
h
x2
l 10ν"
N,0.42487046632124353,"β , 1 + ν x2
h
x2
l
}"
N,0.4255181347150259,"nmin = max{nb1, nb2, n1"
N,0.4261658031088083,"ρ2
γ1 }"
N,0.4268134715025907,".
(26)"
N,0.4274611398963731,"C
PROPOSE TEST SAMPLE PRIVACY"
N,0.42810880829015546,"Proof Claim 4.2. We set the algorithm parameters in eq. 27, and matching databases D3, D4 deﬁned
in eq. 8. We note that we only deﬁne a lower bound over n1, which will be updated later on."
N,0.42875647668393785,"ρ3 = 1.15; ρ2 = 0.45; ρ1 = 1.25, γ1 = 0.49;
xl = xh/2"
N,0.42940414507772023,n1 > max{21
N,0.43005181347150256,ϵ log 1
N,0.43069948186528495,"2δ , 41"
N,0.43134715025906734,ϵ log 1
N,0.4319948186528497,"2δ , 210ρ1, 29+10ρ2}"
N,0.4326424870466321,"β = 3; xh = 1
α = 1 (27)"
N,0.4332901554404145,"Mark the return value of the algorithm as r, the event of the algorithm running on database D3 and
W = D3 as AD3, the event of the algorithm running on database D4 and W = D4 as AD4, and"
N,0.4339378238341969,"S = {s|s > µi}, where µi is the mean of the sample distribution at the SGLD i’th step given
database D3 (Similarly to as deﬁned in subsection 4.2). We will show that ∀ϵ ∈R>0, δ < 1"
N,0.43458549222797926,"6, ∃n1
such that eq. 28 holds."
N,0.43523316062176165,"P(r ∈S|D3) > eϵP(r ∈S|D4) + δ
(28)"
N,0.43588082901554404,We ﬁrst show that
N,0.4365284974093264,"P(r ∈S ∧Ac
D3|D3) = 0"
N,0.4371761658031088,"P(r ∈S ∧Ac
D4|D4) = 0
(29)"
N,0.4378238341968912,"Notice that the algorithm can return result in S only if it reached step 19. Consider an event where
the algorithm reached step 19 and Ac
D3. From Ac
D3, ∃(xi, yi) ∈D3 such that | yi"
N,0.4384715025906736,"xi −˘m| ≥nρ2
2 .
However, since ∀(xi, yi) ∈D3 : yi"
N,0.43911917098445596,"xi = nρ3
1 then ∀(xi, yi) ∈D3 : | yi"
N,0.43976683937823835,"xi −˘m| > nρ2
2 and therefore
|W| = 0. Under the assumption that sample from p(θ|{}) returns null then in this case the algorithm
also returns null and therefore P(r ∈S ∧Ac
D3|D3) = 0. Same arguments hold for D4."
N,0.44041450777202074,"Following eq. 29, to prove eq. 28 it is enough to prove eq. 30."
N,0.4410621761658031,"P(r ∈S|D3, A3)P(A3|D3) ≥∗"
N,0.4417098445595855,"P(r ∈S|D3, A3) −5δ >∗∗eϵP(r ∈S|D4, A4) + δ ≥
eϵP(r ∈S|D4, A4)P(A4|D4) + δ = eϵP(r ∈S ∧A4|D4) + δ (30)"
N,0.4423575129533679,"From claim C.1 ∃nbound1 such that ∀n1 > nbound1 inequality * holds. From Lemma 4.6, for n1
big enough ∃T ∈Z>0 such that eq. 31 hold (Where 6δ < 0.5 according to the claim conditions).
Therefore, ∃k, nbound2 ∈R>0 such that ∀n1 > nbound2 : ϵ′ > kn2(1−ρ3)
1
and eq. 31 hold. As
ρ3 > 1, by choosing n1 > max{nbound2, ( ϵ k)"
N,0.4430051813471503,"1
2(ρ3−1) } get that ϵ′ > ϵ. Consequently, by choosing"
N,0.44365284974093266,"n1 > max{nbound1, nbound2, ( ϵ k)"
N,0.44430051813471505,"1
2(ρ3−1) }, inequalities * and ** hold, and the claim is proved."
N,0.44494818652849744,"ϵ′ = Ω(n2(ρ3−1)
1
)"
N,0.44559585492227977,"P(r ∈S|D3, A3) > eϵ′P(r ∈S|D4, A4) + 6δ
(31)"
N,0.44624352331606215,"Claim C.1. ∃nbound1 ∈Z>0 such that the probability for algorithm 4.3 to reach step 19 with
W = D3 (marked event A) is greater or equal to 1 −5δ for all n1 > nbound1."
N,0.44689119170984454,"Proof. Mark the event of nW > nmin ∧˘m ∈[m −nρ2
2 , m + nρ2
2 ] ∧n1+ρ2−0.1
2
> ˘nρ1
1 ∧˘n1 ≤
n1 ∧V
= D as B.
Since P(A|D3, B) = 1 it follows that P(A|D3) ≥P(A ∧B|D3) =
P(A|B, D3)P(B|D3) = P(B|D3). Therefore if ∃nlb such that ∀n1 > nlb : P(B|D3) ≥1 −5δ
the claim is proved."
N,0.4475388601036269,P(B|D3) =
N,0.4481865284974093,"P( ˘m ∈[m −nρ2
2 , m + nρ2
2 ] ∧nW > nmin|D3, V = D, n1+ρ2−0.1
2
> ˘nρ1
1 , ˘n1 ≤n1)·"
N,0.4488341968911917,"P(n1+ρ2−0.1
2
> ˘nρ1
1 |V = D, ˘n1 ≤n1, D3)P(V = D, ˘n1 ≤n1|D3) ≥"
N,0.4494818652849741,"P( ˘m ∈[m −nρ2
2 , m + nρ2
2 ] ∧nW > nmin|D3, V = D, n1+ρ2−0.1
2
> ˘nρ1
1 , ˘n1 ≤n1) −3δ ="
N,0.45012953367875647,"P(nW > nmin|D3, V = D, n1+ρ2−0.1
2
> ˘nρ1
1 , ˘n1 ≤n1, ˘m ∈[m −nρ2
2 , m + nρ2
2 ])"
N,0.45077720207253885,"P( ˘m ∈[m −nρ2
2 , m + nρ2
2 ]|D3, V = D, n1+ρ2−0.1
2
> ˘nρ1
1 , ˘n1 ≤n1) −3δ ≥"
N,0.45142487046632124,"P(nW > nmin|D3, V = D, n1+ρ2−0.1
2
> ˘nρ1
1 , ˘n1 ≤n1, ˘m ∈[m −nρ2
2 , m + nρ2
2 ]) −4δ ≥
1 −5δ
(32)"
N,0.4520725388601036,"By corollary C.1 and claim C.3 for n1 big enough ﬁrst inequality holds. By claim C.4 for n1
big enough second inequality holds, and by claim C.5 for n1 big enough third inequality holds.
Therefore for n1 big enough eq. 32 holds and the claim is proved."
N,0.452720207253886,Claim C.2. For n1 > max{ 1
N,0.4533678756476684,"2
−10ρ1, 4 1"
N,0.4540155440414508,ϵ log 1 2δ}
N,0.45466321243523317,"P(˘nρ1
1 ≥nρ3
1 ∧˘n1 ≤n1|D3) ≥1 −2δ."
N,0.45531088082901555,Proof. Mark the noise added at step 6 as l1
N,0.45595854922279794,"P(˘nρ1
1 ≥nρ3
1 ∧˘n1 ≤n1|D3) ="
N,0.4566062176165803,P((n1 + l1 −1
N,0.4572538860103627,ϵ log 1
N,0.4579015544041451,"2δ )ρ1 ≥nρ3
1 ∧n1 + l1 −1"
N,0.4585492227979275,ϵ log 1
N,0.45919689119170987,2δ ≤n1|D3) =
N,0.45984455958549225,P((n1 + l1 −1
N,0.46049222797927464,ϵ log 1
N,0.46113989637305697,"2δ )ρ1 ≥nρ3
1 ∧l1 ≤1"
N,0.46178756476683935,ϵ log 1
N,0.46243523316062174,2δ |D3) =
N,0.4630829015544041,P((n1 + l1 −1
N,0.4637305699481865,ϵ log 1
N,0.4643782383419689,"2δ )ρ1 ≥nρ3
1 ∧|l1| ≤1"
N,0.4650259067357513,ϵ log 1
N,0.46567357512953367,2δ |D3)+
N,0.46632124352331605,P((n1 + l1 −1
N,0.46696891191709844,ϵ log 1
N,0.4676165803108808,"2δ )ρ1 ≥nρ3
1 ∧l1 ≤−1"
N,0.4682642487046632,ϵ log 1
N,0.4689119170984456,2δ |D3) ≥
N,0.469559585492228,P((n1 + l1 −1
N,0.47020725388601037,ϵ log 1
N,0.47085492227979275,"2δ )ρ1 ≥nρ3
1 ∧|l1| ≤1"
N,0.47150259067357514,ϵ log 1
N,0.4721502590673575,2δ |D3) =
N,0.4727979274611399,P((n1 + l1 −1
N,0.4734455958549223,ϵ log 1
N,0.4740932642487047,"2δ )ρ1 ≥nρ3
1 ||l1| ≤1"
N,0.47474093264248707,ϵ log 1
N,0.47538860103626945,"2δ , D3)P(|l1| ≤1"
N,0.47603626943005184,ϵ log 1
N,0.47668393782383417,2δ |D3) ≥
N,0.47733160621761656,P((n1 −21
N,0.47797927461139894,ϵ log 1
N,0.4786269430051813,"2δ )ρ1 ≥nρ3
1 |D3) −2δ = 1 −2δ"
N,0.4792746113989637,Where last inequality holds from following equation
N,0.4799222797927461,P(|l1| ≤1
N,0.4805699481865285,ϵ log 1
N,0.48121761658031087,2δ ) = 1 −2P(l1 ≤−1
N,0.48186528497409326,ϵ log 1
N,0.48251295336787564,2δ ) = 1 −exp(−
N,0.483160621761658,"1
ϵ log 1"
N,0.4838082901554404,"2δ
1
ϵ
) = 1 −2δ"
N,0.4844559585492228,"Last equality holds since n1 >
1
2
−10ρ1 ⇒n−1
1
< ( 1"
N,0.4851036269430052,"2)10ρ1 ⇒n−0.1
1
< ( 1"
N,0.48575129533678757,"2)ρ1 and therefore
(n1 −2 1"
N,0.48639896373056996,ϵ log 1
N,0.48704663212435234,2δ)ρ1 > ( 1
N,0.4876943005181347,"2n1)ρ1 > nρ1−0.1
1
= nρ3
1"
N,0.4883419689119171,Corollary C.1.
N,0.4889896373056995,∀n1 > max{1 2
N,0.4896373056994819,"−10ρ1
, 41"
N,0.49028497409326427,ϵ log 1
N,0.49093264248704666,2δ } : P(V = D3 ∧˘n1 ≤n1) ≥1 −2δ.
N,0.49158031088082904,Claim C.3. For n1 > max{ 1
N,0.49222797927461137,"2
−(9+10ρ2), 4 1"
N,0.49287564766839376,ϵ log 1 2δ}
N,0.49352331606217614,"P(n1+ρ2−0.1
2
> ˘nρ1
1 |D3, V = D3, ˘n1 ≤n1) ≥1 −δ."
N,0.49417098445595853,Proof.
N,0.4948186528497409,"P(n0.9+ρ2
2
> ˘nρ1
1 |D3, V = D3, ˘n1 ≤n1) ≥P(n0.9+ρ2
2
> nρ1
1 |D3, V = D3) ≥"
N,0.4954663212435233,P((n1 −21
N,0.4961139896373057,ϵ log 1
N,0.49676165803108807,"2δ )0.9+ρ2 > nρ1
1 |D3)p(n2 ≥|V | −21"
N,0.49740932642487046,ϵ log 1
N,0.49805699481865284,2δ ) ≥
N,0.49870466321243523,P((n1 −21
N,0.4993523316062176,ϵ log 1
N,0.5,"2δ )0.9+ρ2 > nρ1
1 |D3) −δ = 1 −δ"
N,0.5006476683937824,where the second inequality holds since P(Lap( 1
N,0.5012953367875648,ϵ ) < −1
N,0.5019430051813472,ϵ log 1
N,0.5025906735751295,"2δ) < δ, and last equality holds since
(n1 −2 1"
N,0.5032383419689119,ϵ log 1
N,0.5038860103626943,2δ)0.9+ρ2 > ( 1
N,0.5045336787564767,"2n1)0.9+ρ2 > n1+ρ2−0.2
1
= nρ1
1"
N,0.5051813471502591,Claim C.4. ∃nlb1 ∈Z>0 such that
N,0.5058290155440415,"∀n1 > nlb1 : P( ˘m ∈[m −nρ2
2 , m + nρ2
2 ]|D3, n0.9+ρ2
2
> ˘nρ1
1 ) ≥1 −δ."
N,0.5064766839378239,Proof. Mark the noise added at step 13 as l1
N,0.5071243523316062,"P( ˘m ∈[m −nρ2
2 , m + nρ2
2 ]|D3, n0.9+ρ2
2
> ˘nρ1
1 ) ="
N,0.5077720207253886,"P(l1 ∈[−nρ2
2 , nρ2
2 ]|D3, n0.9+ρ2
2
> ˘nρ1
1 ) ≥"
N,0.508419689119171,1 −2(1
N,0.5090673575129534,"2 exp(−nρ2
2
1"
N,0.5097150259067358,"1
ϵ ˘nρ1
1
2(n2−1)x2
hx2
l +x4
h
n2(n2−1)x4
l ) ="
N,0.5103626943005182,"1 −exp(−
n1+ρ2
2
ϵ(n2 −1)x4
l
˘nρ1
1 (2(n2 −1)x2
hx2
l + x4
h))"
N,0.5110103626943006,"Since n0.9+ρ2
2
> ˘nρ1
1 then ˘nρ1
1 = o(n1+ρ2
2
) and therefore for n1 big enough the exponent is smaller
than δ."
N,0.5116580310880829,Claim C.5. ∃nlb2 ∈Z>0 such that
N,0.5123056994818653,"∀n1 > nlb2 : p(nW > nmin||V | = D3 ∧n0.9+ρ2
2
> ˘nρ1
1 ∧˘m ∈[m −nρ2
2 , m + nρ2
2 ], D3) ≥1 −δ."
N,0.5129533678756477,"Proof. For abbreviation mark event B as B = |V | = D3∧n0.9+ρ2
2
> ˘nρ1
1 ∧˘m ∈[m−nρ2
2 , m+nρ2
2 ].
Mark the Laplace noise used in step 8 as l1 and the Laplace noise used in step 15 as l2."
N,0.5136010362694301,"P(nW > nmin|B, D3) ="
N,0.5142487046632125,P(n1 −1
N,0.5148963730569949,ϵ log 1
N,0.5155440414507773,"2δ + l2 > nmin|B, D3) >"
N,0.5161917098445595,P(n1 −1
N,0.5168393782383419,ϵ log 1 2δ −1
N,0.5174870466321243,ϵ log 1
N,0.5181347150259067,"δ > nmin|B, D3)P(l2 > −1"
N,0.5187823834196891,ϵ log 1 δ )+
N,0.5194300518134715,P(n1 −1
N,0.5200777202072538,ϵ log 1
N,0.5207253886010362,2δ + l2 > nmin ∧l2 < −1
N,0.5213730569948186,ϵ log 1
N,0.522020725388601,"δ |B, D3) >"
N,0.5226683937823834,P(n1 −2
N,0.5233160621761658,ϵ log 1 2δ −1
N,0.5239637305699482,ϵ log 1
N,0.5246113989637305,"δ > nmin|B, D3)(1 −δ 2) >"
N,0.5252590673575129,P(n1 −2
N,0.5259067357512953,ϵ log 1 2δ −1
N,0.5265544041450777,ϵ log 1
N,0.5272020725388601,"δ > nmin|B, D3) −δ 2 ="
N,0.5278497409326425,P(n1 −2
N,0.5284974093264249,ϵ log 1 2δ −1
N,0.5291450777202072,ϵ log 1
N,0.5297927461139896,δ > nmin|l1 < 1
N,0.530440414507772,ϵ log 1
N,0.5310880829015544,"δ , B, D3)P(l1 < 1"
N,0.5317357512953368,ϵ log 1
N,0.5323834196891192,"δ |B, D3)+"
N,0.5330310880829016,P(n1 −2
N,0.533678756476684,ϵ log 1 2δ −1
N,0.5343264248704663,ϵ log 1
N,0.5349740932642487,δ > nmin ∧l1 ≥1
N,0.5356217616580311,ϵ log 1
N,0.5362694300518135,"δ |B, D3) −δ 2 ≥"
N,0.5369170984455959,P(n1 −2
N,0.5375647668393783,ϵ log 1 2δ −1
N,0.5382124352331606,ϵ log 1
N,0.538860103626943,δ > nmin|l1 < 1
N,0.5395077720207254,ϵ log 1
N,0.5401554404145078,"δ , B, D3)P(l1 < 1"
N,0.5408031088082902,ϵ log 1
N,0.5414507772020726,"δ |B, D3) −δ 2 ≥"
N,0.542098445595855,P(n1 −2
N,0.5427461139896373,ϵ log 1 2δ −1
N,0.5433937823834197,ϵ log 1
N,0.5440414507772021,δ > nmin|l1 < 1
N,0.5446891191709845,ϵ log 1
N,0.5453367875647669,"δ , B, D3) −δ"
N,0.5459844559585493,"From B it holds that |m −˘m| < nρ2
2 and therefore ˘m < m + nρ2
2 , and for the case of l1 < 1"
N,0.5466321243523317,ϵ log 1
N,0.5472797927461139,"δ
it holds that n2 < n1 −1"
N,0.5479274611398963,ϵ log 1
N,0.5485751295336787,2δ + 1
N,0.5492227979274611,ϵ log 1
N,0.5498704663212435,δ < n1 + 1
N,0.5505181347150259,ϵ log 1
N,0.5511658031088082,δ . Therefore ˘m ≤m + (n1 + 1
N,0.5518134715025906,ϵ log 1
N,0.552461139896373,δ )ρ2.
N,0.5531088082901554,"As nmin = O(max{ ˘m
2
3 , n"
N,0.5537564766839378,"ρ2
γ1
1 }) then for the case of l1 <
1
ϵ log 1"
N,0.5544041450777202,"δ and B, it holds that nmin ="
N,0.5550518134715026,"O(max{(m + nρ2
1 )
2
3 , n"
N,0.555699481865285,"ρ2
γ1
1 }) = O(max{n 2ρ3"
N,0.5563471502590673,"3
1
, n"
N,0.5569948186528497,"ρ2
γ1
1 }) < o(n1), therefore ∃nlb2 such that ∀n1 >
nlb2 : n1 −2"
N,0.5576424870466321,ϵ log 1 2δ −1
N,0.5582901554404145,ϵ log 1
N,0.5589378238341969,"δ > nmin. Consequently, ∀n1 > nlb2 : P(n1 −2"
N,0.5595854922279793,ϵ log 1 2δ −1
N,0.5602331606217616,ϵ log 1
N,0.560880829015544,"δ >
nmin|l1 < 1"
N,0.5615284974093264,ϵ log 1
N,0.5621761658031088,"δ , B, D3) = 1."
N,0.5628238341968912,"Deﬁnition 4. A randomized function f(X, y) : χn1 × Rn2 →R, is (ϵ, δ)-differentially private with
respect to X if ∀S ⊆R, and ∀X, ˆX ∈χn : ∥X −ˆX∥≤1, eq. 33 holds."
N,0.5634715025906736,"P(f(X, y) ∈S) ≤exp(ϵ)P(f( ˆX, y) ∈S) + δ
(33)"
N,0.564119170984456,"Claim C.6. Calculating ˘n1, n2 is (2ϵ, 0) differentially private."
N,0.5647668393782384,"Proof. Since n1 can differ by up to 1 for neighbouring databases, calculating ˘n1 is protected via the
Laplace mechanism. Since for a given ˘n1 the value |V | can change by up to 1 for two neighbouring
databases then calculating n2 is (ϵ, 0) by the Laplace mechanism. Consequently from sequential
composition theorem the sequential composition is (2ϵ, 0) differentially private."
N,0.5654145077720207,"Claim C.7. P(n2 ≤|V ||D, ˘n1) = 1 −δ."
N,0.5660621761658031,"Proof. Mark l ∼Lap( 1 ϵ ),"
N,0.5667098445595855,"P(n2 ≤|V ||D, ˘n1) = P(|V | −1"
N,0.5673575129533679,ϵ log 1
N,0.5680051813471503,"2δ + l ≤|V ||D, ˘n1) ="
N,0.5686528497409327,P(l ≤1
N,0.569300518134715,ϵ log 1
N,0.5699481865284974,"2δ |D, ˘n1) = 1 −1"
N,0.5705958549222798,2 exp(−
N,0.5712435233160622,"1
ϵ log 1"
N,0.5718911917098446,"2δ
1
ϵ
) = 1 −δ"
N,0.572538860103627,"Claim C.8. Calculating ˘m is (ϵ, 0) differentially private with respect to D for given ˘n1, n2 and
n2 < |V |."
N,0.5731865284974094,"Proof. Mark by ˆD a neighbouring database to D, and ˆV as V induced by this database. If V = ˆV
then the claim follows trivially. In case the V ’s differ, assume w.l.o.g that |V | ≥| ˆV |, and that
if |V | = | ˆV | then they differ in their last sample. Deﬁne q = P"
N,0.5738341968911918,"(xi,yi)∈V/{x|V |,y|V |} xiyi, z =
P"
N,0.5744818652849741,"(xi,yi)∈V/{x|V |,y|V |} x2
i ."
N,0.5751295336787565,|q + x|V |y|V |
N,0.5757772020725389,"z + x2
|V |
−q + ˆx|V |ˆy|V |"
N,0.5764248704663213,"z + ˆx2
|V |
| ="
N,0.5770725388601037,"|
qˆx2
|V | + x|V |y|V |ˆx2
|V | + x|V |y|V |z −qx2
|V | −ˆx|V |ˆy|V |x2
|V | −ˆx|V |ˆy|V |z"
N,0.5777202072538861,"(z + x2
|V |)(z + ˆx2
|V |)
| ≤"
N,0.5783678756476683,"qx2
h + ˘nρ1
1 x2
hz + ˘nρ1
1 x4
h
(z + x2
l )z
≤˘nρ1
1
2zx2
h + x4
h
(z + x2
l )z = ˘nρ1
1 ( 2x2
h
z + xl
+
x4
h
(z + x2
l )z ) ≤"
N,0.5790155440414507,"˘nρ1
1 ( 2x2
h
|V |x2
l
+
x4
h
|V |(|V | −1)x4
l
) ≤˘nρ1
1 ( 2x2
h
n2x2
l
+
x4
h
n2(n2 −1)x4
l
) = ˘nρ1
1
2(n2 −1)x2
hx2
l + x4
h
n2(n2 −1)x4
l"
N,0.5796632124352331,"therefore by the Laplace mechanism calculating ˘m is (ϵ, 0) differentially private."
N,0.5803108808290155,"Claim C.9. Steps 6-13 are (3ϵ, δ) differentially private."
N,0.5809585492227979,"Proof. Mark ˆD as a neighbouring database,"
N,0.5816062176165803,"P( ˘m ∈S|D) =
Z"
N,0.5822538860103627,"r1,r2∈R>0×R>0
P( ˘m ∈S|D, ˘n1 = r1, n2 = r2)p(˘n1 = r1, n2 = r2|D)dr1dr2 =
Z"
N,0.582901554404145,"r1,r2∈R>0×[1,|V |]
P( ˘m ∈S|D, ˘n1 = r1, n2 = r2)p(˘n1 = r1, n2 = r2|D)dr1dr2+
Z"
N,0.5835492227979274,"r1,r2∈R>0×(|V |,∞]
P( ˘m ∈S|D, ˘n1 = r1, n2 = r2)p(˘n1 = r1, n2 = r2|D)dr1dr2 ≤∗ Z"
N,0.5841968911917098,"r1,r2∈R>0×[1,|V |]
P( ˘m ∈S|D, ˘n1 = r1, n2 = r2)p(˘n1 = r1, n2 = r2|D)dr1dr2 + δ ≤∗∗ Z"
N,0.5848445595854922,"r1,r2∈R>0×[1,|V |]
e2ϵP( ˘m ∈S| ˆD, ˘n1 = r1, n2 = r2)p(˘n1 = r1, n2 = r2| ˆD)dr1dr2 + δ ≤
Z"
N,0.5854922279792746,"r1,r2∈R>0×R>0
e2ϵP( ˘m ∈S| ˆD, ˘n1 = r1, n2 = r2)p(˘n1 = r1, n2 = r2| ˆD)dr1dr2 + δ ="
N,0.586139896373057,e2ϵP( ˘m ∈S| ˆD) + δ
N,0.5867875647668394,where inequality * follows claim C.7 and inequality ** follows claims C.8 and C.6.
N,0.5874352331606217,"Claim C.10. Steps 14-19 are (ϵ, δ) differentially private with respect to D for |W| < nmin and
given n2, ˘m."
N,0.5880829015544041,Proof. Mark l ∼Lap( 1
N,0.5887305699481865,"ϵ ), and ˆD as a neighbouring database. Eq. 34 proves the claim."
N,0.5893782383419689,"P(S|D, |W| < nmin, ˘m, n2) =
P(S ∩{null}|D, |W| < nmin, ˘m, n2)+
P(S ∩{null}c|D, |W| < nmin, ˘m, n2) ≤"
N,0.5900259067357513,"eϵP(S ∩{null}| ˆD, |W| < nmin, ˘m, n2) + δ ≤"
N,0.5906735751295337,"eϵP(S| ˆD, |W| < d, ˘m, n2) + δ (34)"
N,0.591321243523316,where ﬁrst inequality is true from eq. 35 and the Laplace mechanism for nW .
N,0.5919689119170984,"P(null|D, |W| < nmin, ˘m, n2) ="
N,0.5926165803108808,P(nW < nmin + 1
N,0.5932642487046632,ϵ log( 1
N,0.5939119170984456,"2δ )|D, |W| < nmin, ˘m, n2) ≥"
N,0.594559585492228,P(l < 1
N,0.5952072538860104,ϵ log( 1
N,0.5958549222797928,2δ )) ≥1 −δ (35)
N,0.5965025906735751,"Claim C.11. Step 19 is (ϵ, δ) differentially private with respect to D for |W| ≥nmin and given
n2, ˘m."
N,0.5971502590673575,"Proof. For a given n2, ˘m and a neighbouring database, the group W can change by up to one sample.
Mark n = |W| and c = ˘m. From eq. 36, it follows that W ∈D, as deﬁned in eq. 5. n ≥n"
N,0.5977979274611399,"ρ2
γ1
2
⇒"
N,0.5984455958549223,"n
1
2 > nγ1 ≥nρ2
2
(36)"
N,0.5990932642487047,"As W ∈D, n ≥nb1, and n ≥nb2, the problem of sampling from p(θ|W) for |W| ≥nmin holds
the constraints of claim D.29. Therefore one sample from p(θ|W) is (ϵ, δ) differentially private."
N,0.5997409326424871,"Claim C.12. Steps 14-18 are (ϵ, 0) differentially private with respect to D for |W| > nmin and
given ˘m, n2."
N,0.6003886010362695,"Proof. Only data released is nW , and since the sensitivity of |W| given ˘m, n2 is 1, then the Laplace
mechanism ensures (ϵ, 0) differential privacy."
N,0.6010362694300518,"Corollary C.2. Steps 14-19 are (2ϵ, δ) differentially private with respect to D for |W| > nmin and
given ˘m, n2.
Corollary C.3. Steps 14-19 are (2ϵ, δ) differentially private with respect to D given ˘m, n2."
N,0.6016839378238342,"D
AUXILIARY CLAIMS"
N,0.6023316062176166,"This subsection contains simple claims used to simplify the reading of the proofs. Claims described
in this subsection uses the marking deﬁned in eq. 17."
N,0.602979274611399,"Claim D.1. ρ
1
1−λ =
ncx2
hβ
α+nx2
hβ ."
N,0.6036269430051814,Proof Claim D.1.
N,0.6042746113989638,"ρ
1
1 −λ = η"
N,0.6049222797927462,"2ncx2
hβ
1
1 −(1 −η"
N,0.6055699481865285,2(α + n( xh
N,0.6062176165803109,"2 )2β)) = ncx2
hβ
1
α + nx2
hβ =
ncx2
hβ
α + nx2
hβ"
N,0.6068652849740933,Claim D.2. ρ 1−λn−1
N,0.6075129533678757,"1−λ
+ ρλn−1 =
ncx2
hβ
α+nx2
hβ (1 −λn)."
N,0.6081606217616581,Proof Claim D.2.
N,0.6088082901554405,ρ1 −λn−1
N,0.6094559585492227,"1 −λ
+ ρλn−1 = ρ(1 −λn−1 + λn−1 −λn"
N,0.6101036269430051,"1 −λ
) = ρ(1 −λn"
N,0.6107512953367875,"1 −λ ) =
ncx2
hβ
α + nx2
hβ (1 −λn)"
N,0.6113989637305699,where the last equality holds from Claim D.1
N,0.6120466321243523,Claim D.3. ρ( 1−λn−1
N,0.6126943005181347,"1−λ
) + ˆρλn−1 =
ncx2
hβ
α+nx2
hβ (1 −λn( 3"
N,0.6133419689119171,4λ−1 + 1 4)).
N,0.6139896373056994,Proof Claim D.3.
N,0.6146373056994818,ρ(1 −λn−1
N,0.6152849740932642,"1 −λ
) + ˆρλn−1 = ρ(1 −λn−1"
N,0.6159326424870466,"1 −λ
) + ρ1"
N,0.616580310880829,4λn−1 = ρ(1 −3
N,0.6172279792746114,4λn−1 −1 4λn
N,0.6178756476683938,"1 −λ
) ="
N,0.6185233160621761,ρ(1 −λn( 3
N,0.6191709844559585,4λ−1 + 1
N,0.6198186528497409,"4)
1 −λ
) =
ncx2
hβ
α + nx2
hβ (1 −λn(3"
N,0.6204663212435233,4λ−1 + 1 4))
N,0.6211139896373057,where the last equality holds from Claim D.1.
N,0.6217616580310881,"Claim D.4.
1
4λ + 3"
N,0.6224093264248705,4 −ˆλ = 3
N,0.6230569948186528,"4
η
2α."
N,0.6237046632124352,Proof Claim D.4.
N,0.6243523316062176,"1
4λ + 3"
N,0.625,4 −ˆλ = 1
N,0.6256476683937824,4(1 −η
N,0.6262953367875648,2(α + nx2β)) + 3
N,0.6269430051813472,4 −(1 −η
N,0.6275906735751295,2(α + 1
N,0.6282383419689119,4nx2β)) =
N,0.6288860103626943,"η
2[α + 1"
N,0.6295336787564767,4nx2β −1
N,0.6301813471502591,4(α + nx2β)] = 3
N,0.6308290155440415,"4
η
2α"
N,0.6314766839378239,Claim D.5.
N,0.6321243523316062,(1 −λkn)(1 −ˆλλn−1) −(1 −(ˆλλ(n−1)))k(1 −λn−1(1
N,0.6327720207253886,4λ + 3 4)) =
N,0.633419689119171,λn−1 3
N,0.6340673575129534,"4
η
2α(1 −ˆλkλk(n−1)) + λk(n−1)(ˆλk −λk)(1 −λn−1ˆλ)."
N,0.6347150259067358,Proof Claim D.5.
N,0.6353626943005182,(1 −λkn)(1 −ˆλλn−1) −(1 −(ˆλλ(n−1)))k(1 −λn−1(1
N,0.6360103626943006,4λ + 3 4)) =
N,0.6366580310880829,λn−1(1
N,0.6373056994818653,4λ + 3
N,0.6379533678756477,4 −ˆλ) + λkn(ˆλλn−1 −1) + (ˆλλn−1)k(1 −λn−1(1
N,0.6386010362694301,4λ + 3 4)) =
N,0.6392487046632125,λn−1(1
N,0.6398963730569949,4λ + 3
N,0.6405440414507773,4 −ˆλ) + λk(n−1)(λk(ˆλλn−1 −1) + ˆλk(1 −λn−1(1
N,0.6411917098445595,4λ + 3
N,0.6418393782383419,4))) =
N,0.6424870466321243,λn−1(1
N,0.6431347150259067,4λ + 3
N,0.6437823834196891,4 −ˆλ) + λk(n−1)(ˆλk(1 −λn−1(1
N,0.6444300518134715,4λ + 3
N,0.6450777202072538,4)) −λk(1 −ˆλλn−1)) =
N,0.6457253886010362,λn−1(1
N,0.6463730569948186,4λ + 3
N,0.647020725388601,4 −ˆλ) + λk(n−1)(ˆλk(1 −λn−1(1
N,0.6476683937823834,4λ + 3
N,0.6483160621761658,4)) −λk(1 −λn−1ˆλ)) =∗
N,0.6489637305699482,λn−1 η
N,0.6496113989637305,"2
3
4α + λk(n−1)(ˆλk(1 −λn−1(1"
N,0.6502590673575129,4λ + 3
N,0.6509067357512953,4)) −λk(1 −λn−1ˆλ)) =∗
N,0.6515544041450777,λn−1 η
N,0.6522020725388601,"2
3
4α + λk(n−1)(ˆλk(1 −λn−1(ˆλ + 3"
N,0.6528497409326425,"4
η
2α) −λk(1 −λn−1ˆλ)) ="
N,0.6534974093264249,λn−1 η
N,0.6541450777202072,"2
3
4α −ˆλkλn−1 3"
N,0.6547927461139896,"4
η
2α + λk(n−1)(ˆλk(1 −λn−1ˆλ) −λk(1 −λn−1ˆλ)) ="
N,0.655440414507772,λn−1 3
N,0.6560880829015544,"4
η
2α(1 −ˆλkλk(n−1)) + λk(n−1)(ˆλk −λk)(1 −λn−1ˆλ)"
N,0.6567357512953368,where equality * holds from claim D.4
N,0.6573834196891192,"Claim D.6. λ Pk−1
j=0 λ(n−1)jλj[λn−1ρ + ρ Pn−2
i=0 λi] = λ(1 −λkn) ncx2
hβ
α+nx2
hβ ."
N,0.6580310880829016,"Proof Claim D.6. λ k−1
X"
N,0.658678756476684,"j=0
λ(n−1)jλj[λn−1ρ + ρ n−2
X"
N,0.6593264248704663,"i=0
λi] = ρλ"
N,0.6599740932642487,"kn−1
X"
N,0.6606217616580311,"i=0
λi = ρλ1 −λkn"
N,0.6612694300518135,"1 −λ
=∗λ
ncx2
hβ
α + nx2
hβ (1 −λkn)"
N,0.6619170984455959,Where equality * follows from claim D.1.
N,0.6625647668393783,"Claim D.7. ˆλ Pk−1
j=0 λ(n−1)jˆλj[λn−1ˆρ + ρ Pn−2
i=0 λi] = ˆλ 1−(λn−1ˆλ)k"
N,0.6632124352331606,"1−λn−1ˆλ
ncx2
hβ
α+nx2
hβ (1 −λn( 3"
N,0.663860103626943,4λ−1 + 1 4)).
N,0.6645077720207254,"Proof Claim D.7. ˆλ k−1
X"
N,0.6651554404145078,"j=0
λ(n−1)jˆλj[λn−1ˆρ + ρ n−2
X"
N,0.6658031088082902,"i=0
λi] ="
N,0.6664507772020726,ˆλ1 −(λn−1ˆλ)k
N,0.667098445595855,"1 −λn−1ˆλ
[λn−1ˆρ + ρ1 −λn−1"
N,0.6677461139896373,"1 −λ
] =∗ˆλ1 −(λn−1ˆλ)k"
N,0.6683937823834197,1 −λn−1ˆλ
N,0.6690414507772021,"ncx2
hβ
α + nx2
hβ (1 −λn(3"
N,0.6696891191709845,4λ−1 + 1 4))
N,0.6703367875647669,"Where equality * follows from claims D.1, D.3."
N,0.6709844559585493,"Claim D.8.
λλk −λkλnˆλ −ˆλˆλk + ˆλˆλkλn( 3"
N,0.6716321243523317,4λ−1 + 1
N,0.6722797927461139,4) = (1 −ˆλλn−1)(λk+1 −ˆλk+1) + ˆλk+1λn−1( 3
N,0.6729274611398963,"4
η
2α)."
N,0.6735751295336787,Proof Claim D.8.
N,0.6742227979274611,λλk −λkλnˆλ −ˆλˆλk + ˆλˆλkλn(3
N,0.6748704663212435,4λ−1 + 1 4) =
N,0.6755181347150259,λk+1(1 −ˆλλn−1) −ˆλk+1(1 −λn−1(1
N,0.6761658031088082,4λ + 3
N,0.6768134715025906,4)) =∗
N,0.677461139896373,λk+1(1 −ˆλλn−1) −ˆλk+1(1 −λn−1(ˆλ + 3
N,0.6781088082901554,"4
η
2α)) ="
N,0.6787564766839378,(1 −ˆλλn−1)(λk+1 −ˆλk+1) + ˆλk+1λn−1(3
N,0.6794041450777202,"4
η
2α)"
N,0.6800518134715026,where equality * holds from claim D.4.
N,0.680699481865285,"Claim D.9.
λ(1 −λkn)(1 −λn−1ˆλ) −ˆλ(1 −(λn−1ˆλ)k)(1 −λn( 3"
N,0.6813471502590673,4λ−1 + 1
N,0.6819948186528497,"4)) =
(λ −ˆλ)(1 −ˆλλn−1) + λn−1ˆλ[ 3"
N,0.6826424870466321,"4
η
2α(1 −ˆλkλk(n−1))] + λk(n−1)[(1 −ˆλλn−1)(ˆλk+1 −λk+1)]."
N,0.6832901554404145,Proof Claim D.9.
N,0.6839378238341969,λ(1 −λkn)(1 −λn−1ˆλ) −ˆλ(1 −(λn−1ˆλ)k)(1 −λn(3
N,0.6845854922279793,4λ−1 + 1 4)) =
N,0.6852331606217616,λ −ˆλ −λnˆλ(1 −(3
N,0.685880829015544,4λ−1 + 1
N,0.6865284974093264,4)) −λk(n−1)[λλk −λkλnˆλ −ˆλˆλk + ˆλˆλkλn(3
N,0.6871761658031088,4λ−1 + 1
N,0.6878238341968912,4)] =∗
N,0.6884715025906736,λ −ˆλ −λnˆλ(1 −(3
N,0.689119170984456,4λ−1 + 1
N,0.6897668393782384,4)) −λk(n−1)[(1 −ˆλλn−1)(λk+1 −ˆλk+1) + ˆλk+1λn−1(3
N,0.6904145077720207,"4
η
2α)] ="
N,0.6910621761658031,λ −ˆλ −λn−1ˆλ(λ −(3 4 + 1
N,0.6917098445595855,4λ)) −λk(n−1)[(1 −ˆλλn−1)(λk+1 −ˆλk+1) + ˆλk+1λn−1(3
N,0.6923575129533679,"4
η
2α)] =∗∗"
N,0.6930051813471503,λ −ˆλ −λn−1ˆλ(λ −(ˆλ + 3
N,0.6936528497409327,"4
η
2α)) −λk(n−1)[(1 −ˆλλn−1)(λk+1 −ˆλk+1) + ˆλk+1λn−1(3"
N,0.694300518134715,"4
η
2α)] ="
N,0.6949481865284974,(λ −ˆλ)(1 −ˆλλn−1) + λn−1ˆλ[3
N,0.6955958549222798,"4
η
2α(1 −ˆλkλk(n−1))] + λk(n−1)[(1 −ˆλλn−1)(ˆλk+1 −λk+1)]"
N,0.6962435233160622,Where equality * follows from claim D.8 and equality ** follows from claim D.4.
N,0.6968911917098446,Claim D.10.
N,0.697538860103627,λ(1 −λkn) −ˆλ1 −(λn−1ˆλ)k
N,0.6981865284974094,"1 −λn−1ˆλ
(1 −λn(3"
N,0.6988341968911918,4λ−1 + 1 4)) =
N,0.6994818652849741,(λ −ˆλ) + λn−1[ 3
N,0.7001295336787565,"4
η
2α(1 −ˆλkλk(n−1))]"
N,0.7007772020725389,"1 −ˆλλn−1
+ λk(n−1)(ˆλk+1 −λk+1)."
N,0.7014248704663213,Proof Claim D.10.
N,0.7020725388601037,λ(1 −λkn) −ˆλ1 −(λn−1ˆλ)k
N,0.7027202072538861,"1 −λn−1ˆλ
(1 −λn(3"
N,0.7033678756476683,4λ−1 + 1
N,0.7040155440414507,4)) =[M5.d]
N,0.7046632124352331,(λ −ˆλ)(1 −ˆλλn−1) + λn−1ˆλ[ 3
N,0.7053108808290155,"4
η
2α(1 −ˆλkλk(n−1))] + λk(n−1)[(1 −ˆλλn−1)(ˆλk+1 −λk+1)]"
N,0.7059585492227979,"(1 −ˆλλn−1)
="
N,0.7066062176165803,(λ −ˆλ) + λn−1[ 3
N,0.7072538860103627,"4
η
2α(1 −ˆλkλk(n−1))]"
N,0.707901554404145,"1 −ˆλλn−1
+ λk(n−1)(ˆλk+1 −λk+1)"
N,0.7085492227979274,"Claim D.11.
ncx2
hβ
α+nx2
hβ (λ −ˆλ + λn−1[ 3"
N,0.7091968911917098,"4
η
2 α(1−ˆλkλk(n−1))]"
N,0.7098445595854922,"1−ˆλλn−1
) + (ρ −ˆρ) > 0."
N,0.7104922279792746,Proof Claim D.11.
N,0.711139896373057,"ncx2
hβ
α + nx2
hβ (λ −ˆλ + λn−1[ 3"
N,0.7117875647668394,"4
η
2α(1 −ˆλkλk(n−1))]"
N,0.7124352331606217,"1 −ˆλλn−1
) + (ρ −ˆρ) ="
N,0.7130829015544041,"ncx2
hβ
α + nx2
hβ (λ −ˆλ + λn−1[ 3"
N,0.7137305699481865,"4
η
2α(1 −ˆλkλk(n−1))]"
N,0.7143782383419689,"1 −ˆλλn−1
) + η"
N,0.7150259067357513,"2ncx2
hβ(1 −1 4) ="
N,0.7156735751295337,"ncx2
hβ
α + nx2
hβ (1 −η"
N,0.716321243523316,2(α + nx2β) −(1 −η
N,0.7169689119170984,2(α + 1
N,0.7176165803108808,4nx2β))+
N,0.7182642487046632,λn−1[ 3
N,0.7189119170984456,"4
η
2α(1 −ˆλkλk(n−1))]"
N,0.719559585492228,"1 −ˆλλn−1
) + 3"
N,0.7202072538860104,"4
η
2ncx2
hβ ="
N,0.7208549222797928,"ncx2
hβ
α + nx2
hβ (−3"
N,0.7215025906735751,"4
η
2(nx2β) + λn−1[ 3"
N,0.7221502590673575,"4
η
2α(1 −ˆλkλk(n−1))]"
N,0.7227979274611399,"1 −ˆλλn−1
) + 3"
N,0.7234455958549223,"4
η
2ncx2
hβ ="
N,0.7240932642487047,"ncx2
hβ
α + nx2
hβ
λn−1[ 3"
N,0.7247409326424871,"4
η
2α(1 −ˆλkλk(n−1))]"
N,0.7253886010362695,"1 −ˆλλn−1
+ ncx2
hβ[3"
N,0.7260362694300518,"4
η
2 −3"
N,0.7266839378238342,"4
η
2
nx2β
α + nx2β ] ="
N,0.7273316062176166,"ncx2
hβ
α + nx2
hβ
λn−1[ 3"
N,0.727979274611399,"4
η
2α(1 −ˆλkλk(n−1))]"
N,0.7286269430051814,"1 −ˆλλn−1
+ ncx2
hβ 3"
N,0.7292746113989638,"4
η
2[1 −
nx2β
α + nx2β ] > 0"
N,0.7299222797927462,"where the last inequality holds because λ, ˆλ < 1 and α > 0"
N,0.7305699481865285,"Claim D.12.
1
α > λ−2η 1−λ−2(k+1)n"
N,0.7312176165803109,"1−λ−2
is true for k ≤
1
2n logλ(
1
1+ 1"
N,0.7318652849740933,αη (1−λ2)) −1.
N,0.7325129533678757,Proof Claim D.12.
N,0.7331606217616581,"1
α ≥λ−2η 1 −λ−2 ˙kn"
N,0.7338082901554405,"1 −λ−2
⇐⇒λ2 1"
N,0.7344559585492227,"α
1
η (1 −λ−2) ≤1 −λ−2 ˙kn ⇐⇒ λ2 1"
N,0.7351036269430051,"α
1
η (λ−2 −1) ≥λ−2 ˙kn −1 ⇐⇒1 + λ2 1"
N,0.7357512953367875,"α
1
η (λ−2 −1) ≥λ−2 ˙kn ⇐⇒"
N,0.7363989637305699,−˙k ≥1
N,0.7370466321243523,2n logλ(1 + 1
N,0.7376943005181347,αη (1 −λ2)) ⇐⇒˙k ≤1
N,0.7383419689119171,"2n logλ(
1
1 +
1
αη(1 −λ2))"
N,0.7389896373056994,Claim D.13.
N,0.7396373056994818,"1
α(ˆλλ(n−1))2 ˙k > η Pn−1
i=0 λ2i P ˙k−1
j=0(ˆλ2λ2(n−1))j is true for ˙k ≤
1
2n logλ(
1
1+ 1"
N,0.7402849740932642,αη (1−λ2)).
N,0.7409326424870466,"Proof Claim D.13. First note that the inequality can also be written as
1
α > η Pn−1
i=0 λ2i Pk−1
j=0(ˆλλ(n−1))2(j−k)."
N,0.741580310880829,"Secondly, the right hand term of the inequality could be upper bound as in eq. 37. Therefore for the
claim’s inequality to holds it is enough that 1"
N,0.7422279792746114,α ≥ηλ−2 1−λ−2nk
N,0.7428756476683938,"1−λ−2
, which proved by claim D.12 to be
true for ˙k ≤
1
2n logλ(
1
1+ 1"
N,0.7435233160621761,"αη (1−λ2)) η n−1
X"
N,0.7441709844559585,"i=0
λ2i
k−1
X"
N,0.7448186528497409,"j=0
(ˆλλ(n−1))2(j−k) = η n−1
X"
N,0.7454663212435233,"i=0
λ2i
k−1
X j=0 1"
N,0.7461139896373057,"(ˆλλ(n−1))2(k−j) <k>j η n−1
X"
N,0.7467616580310881,"i=0
λ2i
k−1
X j=0"
N,0.7474093264248705,"1
(λλ(n−1))2(k−j) = η n−1
X"
N,0.7480569948186528,"i=0
λ2i
k−1
X j=0"
N,0.7487046632124352,"1
λ2n(k−j) = η n−1
X i=0 k−1
X j=0"
N,0.7493523316062176,"1
λ2[nk−nj−i] =r=nj+i η"
N,0.75,"nk−1
X r=0"
N,0.7506476683937824,"1
λ2[nk−r] =r′=nk−r,1<r′<nk η nk
X r′=1"
N,0.7512953367875648,"1
λ2[r′] = η nk
X"
N,0.7519430051813472,"i=1
λ−2i = η λ−2 −λ−2(nk+1)"
N,0.7525906735751295,"1 −λ−2
= ηλ−2 1 −λ−2nk"
N,0.7532383419689119,1 −λ−2 (37)
N,0.7538860103626943,"Claim D.14.
1
α(ˆλλn−1)2 ˙k ≥η(ˆλλn−1)2 ˙k Pn−1
i=0 λ2i is true for ˙k ≤
1
2n logλ(
1
1+ 1"
N,0.7545336787564767,αη (1−λ2)).
N,0.7551813471502591,"Proof Claim D.14. eq. 38 holds because λ, ˆλ < 1. By multiplying both sides with Pn−1
i=0 λ2i get
eq. 39. Then noticing that the right term equals to the right term of claim D.13, and hence smaller
than the left term of the claim, the claim is proved."
N,0.7558290155440415,"(ˆλλn−1)2k < 1 < k−1
X"
N,0.7564766839378239,"i=0
(ˆλλn−1)2j
(38)"
N,0.7571243523316062,"η(ˆλλn−1)2 ˙k
n−1
X"
N,0.7577720207253886,"i=0
λ2i < η"
N,0.758419689119171,"˙k−1
X"
N,0.7590673575129534,"j=0
(ˆλλn−1)2j
n−1
X"
N,0.7597150259067358,"i=0
λ2i
(39)"
N,0.7603626943005182,Claim D.15. The inequality
N,0.7610103626943006,(ˆλλn−r)2[ 1
N,0.7616580310880829,"α(ˆλλn−1)2k + η k−1
X"
N,0.7623056994818653,"j=0
(ˆλλn−1)2j
n−1
X"
N,0.7629533678756477,"i=0
λ2i] > η n−r
X"
N,0.7636010362694301,"i=0
λ2i"
N,0.7642487046632125,"holds for x2
hβ > 3, n >
1
2αx2
hβ −
1
x2
hβ ."
N,0.7648963730569949,"Proof Claim D.15. Left hand side can be lower bounded according to eq.
40, while right
hand side can be upper bounded according to eq.
41.
Therefore it’s enough to show that
λ2n[ 1"
N,0.7655440414507773,αλ2kn + η 1−λ2kn
N,0.7661917098445595,1−λ2 ] > η 1−λ2n
N,0.7668393782383419,"1−λ2 , which according to eq.
42 is equivalent to showing that
(2nx2
hβ−1) 1"
N,0.7674870466321243,"αλ2(k+1)n+2(2λ2n−1) > 0. Since n >
1
2αx2
hβ −
1
x2
hβ claim D.19 applies and therefore"
N,0.7681347150259067,"λ2n ≥e
−
2
x2
hβ . Consequently it’s enough to show that (2nx2
hβ−1) 1"
N,0.7687823834196891,"αλ2(k+1)n+2(2e
−
2
x2
hβ −1) > 0,
which is true for x2
hβ > 3 by claim D.16."
N,0.7694300518134715,(ˆλλn−r)2[ 1
N,0.7700777202072538,"α(ˆλλn−1)2k + η k−1
X"
N,0.7707253886010362,"j=0
(ˆλλn−1)2j
n−1
X"
N,0.7713730569948186,"i=0
λ2i] >"
N,0.772020725388601,(ˆλλn−1)2[ 1
N,0.7726683937823834,"α(ˆλλn−1)2k + η k−1
X"
N,0.7733160621761658,"j=0
(ˆλλn−1)2j
n−1
X"
N,0.7739637305699482,"i=0
λ2i] >"
N,0.7746113989637305,λ2n[ 1
N,0.7752590673575129,"αλ2kn + η k−1
X"
N,0.7759067357512953,"j=0
λ2jn
n−1
X"
N,0.7765544041450777,"i=0
λ2i] = λ2n[ 1"
N,0.7772020725388601,αλ2kn + η 1 −λ2kn
N,0.7778497409326425,1 −λ2 ] (40)
N,0.7784974093264249,"First inequality holds because λ < 1 and r > 1, and second inequality holds because λ < ˆλ. η n−r
X"
N,0.7791450777202072,"i=0
λ2i < η n−1
X"
N,0.7797927461139896,"i=0
λ2i = η 1 −λ2n"
N,0.780440414507772,"1 −λ2
(41)"
N,0.7810880829015544,Inequality holds because λ < ˆλ and r > 1.
N,0.7817357512953368,λ2n[ 1
N,0.7823834196891192,αλ2kn + η 1 −λ2kn
N,0.7830310880829016,1 −λ2 ] > η 1 −λ2n 1 −λ2
N,0.783678756476684,λ2n(1 −λ2) 1
N,0.7843264248704663,αλ2kn + ηλ2n(1 −λ2kn) > η(1 −λ2n)
N,0.7849740932642487,(1 −λ2) 1
N,0.7856217616580311,αλ2(k+1)n + η(2λ2n −λ2(k+1)n −1) > 0
N,0.7862694300518135,"(α + nx2
hβ)2(1 −λ2) 1"
N,0.7869170984455959,αλ2(k+1)n + 2(2λ2n −λ2(k+1)n −1) > 0
N,0.7875647668393783,"(α + nx2
hβ)2(1 −(1 −
1
α + nx2
hβ )2) 1"
N,0.7882124352331606,αλ2(k+1)n + 2(2λ2n −λ2(k+1)n −1) > 0
N,0.788860103626943,"(2(α + nx2
hβ) −1) 1"
N,0.7895077720207254,αλ2(k+1)n + 2(2λ2n −λ2(k+1)n −1) > 0
N,0.7901554404145078,2λ2(k+1)n + (2nx2β −1) 1
N,0.7908031088082902,αλ2(k+1)n + 2(2λ2n −λ2(k+1)n −1) > 0
N,0.7914507772020726,"(2nx2
hβ −1) 1"
N,0.792098445595855,αλ2(k+1)n + 2(2λ2n −1) > 0 (42)
N,0.7927461139896373,"Claim D.16. For x2β > 3 the inequality (2e−
2
x2β −1) > 0 holds."
N,0.7933937823834197,"Proof Claim D.16. It’s easy to see that the inequality holds only if x2β ≥
−2
ln 1"
N,0.7940414507772021,"2 . Since
−2
ln 1"
N,0.7946891191709845,"2 < 3
claim is proved."
N,0.7953367875647669,"Claim D.17. For ˙k as deﬁned in lemma A.4, and the conditions of claim D.19 1
α(e"
N,0.7959844559585493,"2
x2
hβ + α
(e"
N,0.7966321243523317,"2
x2
hβ −1)
(α + nx2β) + 1"
N,0.7972797927461139,"8
) > λ−2η 1 −λ−2(⌈˙k⌉+1)n"
N,0.7979274611398963,"1 −λ−2
."
N,0.7985751295336787,Proof Claim D.17.
N,0.7992227979274611,η 1 −λ−2(⌈˙k⌉+1)n
N,0.7998704663212435,"λ2 −1
≤η λ−2( ˙k+2)n −1"
N,0.8005181347150259,"1 −λ2
= η λ
−2( 1"
N,0.8011658031088082,"2n logλ(
1
1+ 1"
N,0.8018134715025906,"αη (1−λ2) )−1+2)n
−1
1 −λ2
="
N,0.802461139896373,"η λ
−logλ(
1
1+ 1"
N,0.8031088082901554,"αη (1−λ2) )
λ−2n −1
1 −λ2
= η
[1 +
1
αη(1 −λ2)]λ−2n −1"
N,0.8037564766839378,"1 −λ2
="
N,0.8044041450777202,"η
(1 −λ2)λ−2n 1"
N,0.8050518134715026,"αη
1 −λ2
+ η λ−2n −1"
N,0.805699481865285,"1 −λ2
= 1"
N,0.8063471502590673,"αλ−2n +
(λ−2n −1)
(α + nx2β) + 1 8
≤ e"
N,0.8069948186528497,"2
x2β 1 α + 1 αα
(e"
N,0.8076424870466321,"2
x2β −1)
(α + nx2β) + 1 8
= 1 α[e"
N,0.8082901554404145,"2
x2β + α
(e"
N,0.8089378238341969,"2
x2β −1)
(α + nx2β) + 1 8
]"
N,0.8095854922279793,where the fourth equality holds from eq. 43 and the second inequality holds from D.19.
N,0.8102331606217616,"η
λ2 −1 = η
1
(1 −η"
N,0.810880829015544,"2(α + nx2β))2 −1 = η
1
η(α + nx2β) + ( η"
N,0.8115284974093264,2(α + nx2β))2 =
N,0.8121761658031088,"1
(α + nx2β) + η"
N,0.8128238341968912,"4(α + nx2β)2 =
1
(α + nx2β) + 1 8 (43)"
N,0.8134715025906736,Claim D.18.
N,0.814119170984456,∀k > 0 : 1 −(λ
N,0.8147668393782384,"ˆλ
)k ≥"
N,0.8154145077720207,"3
4nx2β
(α + nx2β)2 −(α + 1"
N,0.8160621761658031,4nx2β).
N,0.8167098445595855,Proof Claim D.18. 1 −(λ
N,0.8173575129533679,"ˆλ
)k ≥1 −λ"
N,0.8180051813471503,"ˆλ
= 1 −
1 −
1
α+nx2β"
N,0.8186528497409327,1 −α+ 1
N,0.819300518134715,"4 nx2β
(α+nx2β)2
= 1 −(α + nx2β)2 −(α + nx2β)"
N,0.8199481865284974,(α + nx2β)2 −(α + 1
N,0.8205958549222798,4nx2β) =
N,0.8212435233160622,1 −α2 + 2nx2αβ + (nx2β)2 −α −nx2β
N,0.8218911917098446,α2 + 2nx2αβ + (nx2β)2 −α −1
N,0.822538860103627,4nx2β =
N,0.8231865284974094,"3
4nx2β
(α + nx2β)2 −(α + 1"
N,0.8238341968911918,4nx2β)
N,0.8244818652849741,Where ﬁrst inequality holds because λ < ˆλ.
N,0.8251295336787565,"Claim D.19. For the conditions of claim D.21,"
N,0.8257772020725389,"(1 −
1
α + nx2β )2n ≥e−
2
x2β ."
N,0.8264248704663213,Proof Claim D.19. The proof is easily deduced from claims D.20 and D.21
N,0.8270725388601037,Claim D.20.
N,0.8277202072538861,"lim
n→∞(1 −
1
α + nx2β )2n = e−
2
x2β ."
N,0.8283678756476683,"Proof Lemma D.20. From eq. 44, it is enough to ﬁnd limn→∞
ln(1−
1
α+nx2β )"
N,0.8290155440414507,"1
2n
."
N,0.8296632124352331,"Since limn→∞
ln(1−
1
α+nx2β )"
N,0.8303108808290155,"1
2n
=
0
0, and both the numerator and denominator are differentiable
around ∞, the use of L’Hˆopital’s rule is possible as shown in eq. 45. This proves the claim."
N,0.8309585492227979,"(1 −
1
α + nx2β )2n = eln[(1−
1
α+nx2β )2n] = e2n ln(1−
1
α+nx2β ) = e"
N,0.8316062176165803,"ln(1−
1
α+nx2β )"
N,0.8322538860103627,"1
2n
(44)"
N,0.832901554404145,"lim
n→∞"
N,0.8335492227979274,"d
dn ln(1 −
1
α+nx2β )"
N,0.8341968911917098,"d
dn
1
2n
= lim"
N,0.8348445595854922,"x2β
(α+nx2β−1)(α+nx2β)"
N,0.8354922279792746,"−
1
2n2
= −lim 2n2x2β"
N,0.836139896373057,(nx2β)2 = −2
N,0.8367875647668394,"x2β
(45)"
N,0.8374352331606217,Claim D.21.
N,0.8380829015544041,"∀n >
1
2αx2β −
1
x2β :
d
dn(1 −
1
α + nx2β )2n < 0."
N,0.8387305699481865,"Proof claim D.21. First, a simpliﬁed term for the derivative is found at eq. 46.
d
dn(1 −
1
α + nx2β )2n = d"
N,0.8393782383419689,"dne2n ln(1−
1
α+nx2β ) ="
N,0.8400259067357513,"(1 −
1
α + nx2β )2n[2 ln(1 −
1
α + nx2β ) + 2n
1
1 −
1
α+nx2β
·
x2β
(α + nx2β)2 ] ="
N,0.8406735751295337,"(1 −
1
α + nx2β )2n[2 ln(1 −
1
α + nx2β ) +
2nx2β
(α + nx2β −1)(α + nx2β)] (46)"
N,0.841321243523316,"A lower bound for the ln term can be found using Taylor’s theorem as shown in eq .47, where
0 ≤ξ ≤
1
α+nx2β ."
N,0.8419689119170984,"ln(1 −
1
α + nx2β ) = −
1
α + nx2β −1"
N,0.8426165803108808,"2
1
(1 −ξ)2 (
1
α + nx2β )2 ≤"
N,0.8432642487046632,"−
1
α + nx2β −1"
N,0.8439119170984456,"2(
1
α + nx2β )2
(47)"
N,0.844559585492228,"From equations 46 and 47 it is enough to ﬁnd the terms for which
nx2β
(α+nx2β−1)(α+nx2β) <
1
α+nx2β +"
N,0.8452072538860104,"1
2
1
(α+nx2β)2 holds. A simpliﬁed version of this inequality is found at (48), and it can be easily seen
that for α > 1"
N,0.8458549222797928,"2(
1
nx2β + 1) ⇐⇒n >
1
2αx2β −
1
x2β this inequality holds."
N,0.8465025906735751,"nx2β
(α + nx2β −1)(α + nx2β) <
1
α + nx2β + 1"
N,0.8471502590673575,"2
1
(α + nx2β)2 ⇐⇒"
N,0.8477979274611399,0 < 2α2 + 2nx2βα −2α −2nx2β + α + nx2β −1 ⇐⇒
N,0.8484455958549223,0 < nx2β(2α −1) + α(2α −1) −1 (48)
N,0.8490932642487047,"Claim D.22. For n >
α
x2
hβ (e"
N,0.8497409326424871,"2
x2
hβ −2) +
1
2x2
hβ and the conditions of claim D.19, ˙k, as deﬁned in
lemma A.4, is positive."
N,0.8503886010362695,"Proof Claim D.22. The claim’s inequality is simpliﬁed at eq. 49
˙k > 0
1
2n logλ(
1
1 +
1
αη(1 −λ2)) −1 > 0"
N,0.8510362694300518,"logλ(
1
1 +
1
αη(1 −λ2)) > 2n"
N,0.8516839378238342,"ln(
1
1+ 1"
N,0.8523316062176166,αη (1−λ2))
N,0.852979274611399,"ln λ
> 2n"
N,0.8536269430051814,"ln(
1
1 +
1
αη(1 −λ2)) < 2n ln λ"
N,0.8542746113989638,"ln(
1
1 +
1
αη(1 −λ2)) < ln λ2n"
N,0.8549222797927462,"1
1 +
1
αη(1 −λ2)) < λ2n"
N,0.8555699481865285,λ−2n < 1 + 1
N,0.8562176165803109,αη (1 −λ2)
N,0.8568652849740933,λ−2n −1 < 1
N,0.8575129533678757,αη (1 −λ2) (49)
N,0.8581606217616581,By claim D.19 λ−2n−1 < e
N,0.8588082901554405,"2
x2
hβ −1, therefore it is enough to ﬁnd terms for e"
N,0.8594559585492227,"2
x2
hβ −1 <
1
αη(1−λ2),
which is done at eq. 50, which proves the claim. e"
N,0.8601036269430051,"2
x2
hβ −1 < 1"
N,0.8607512953367875,αη (1 −λ2) αη(e
N,0.8613989637305699,"2
x2
hβ −1) < (1 −λ2) αη(e"
N,0.8620466321243523,"2
x2
hβ −1) < 1 −(1 −η"
N,0.8626943005181347,"2(α + nx2
hβ))2 α(e"
N,0.8633419689119171,"2
x2
hβ −1) < (α + nx2
hβ) −η"
N,0.8639896373056994,4(α + nx2β)2 α(e
N,0.8646373056994818,"2
x2
hβ −1) < (α + nx2
hβ) −1 2 α(e"
N,0.8652849740932642,"2
x2
hβ −2) + 1"
N,0.8659326424870466,"2 < nx2
hβ"
N,0.866580310880829,"α
x2
hβ (e"
N,0.8672279792746114,"2
x2
hβ −2) +
1
2x2
hβ < n (50)"
N,0.8678756476683938,"Claim D.23. For ˙k as deﬁned in lemma A.4, and the conditions of lemma A.5"
N,0.8685233160621761,"p(ˆθ(⌈˙k⌉+1)n > µ(⌈˙k⌉+1)n| ˆD) ≤e−e
−
2
x2β
α
2v1 (
3
32x2β )2( c"
N,0.8691709844559585,"n )2
."
N,0.8698186528497409,Proof claim D.23.
N,0.8704663212435233,p(ˆθ(⌈˙k⌉+1)n > µ(⌈˙k⌉+1)n| ˆD) ≤
N,0.8711139896373057,"1
n n
X"
N,0.8717616580310881,"r=1
exp(−
(µ(⌈˙k⌉+1)n −ˆµr
(⌈˙k⌉+1)n)2"
N,0.8724093264248705,"2(σr
(⌈˙k⌉+1)n)2
) ≤"
N,0.8730569948186528,"1
n n
X"
N,0.8737046632124352,"r=1
exp(−e−
2
x2β α"
N,0.8743523316062176,"2v1
(
3
32x2β )2( c"
N,0.875,n)2) =
N,0.8756476683937824,"exp(−e−
2
x2β α"
N,0.8762953367875648,"2v1
(
3
32x2β )2( c n)2)"
N,0.8769430051813472,Where the ﬁrst inequality holds due to lemma 4.4 and second inequality holds due to lemma A.5.
N,0.8775906735751295,"Claim D.24. for n > 1 + 10 x2
h
x2
l
ν
β , the inequality
1
10(α + (z + x2
n)β) > ν(ˆx2
n −x2
n) holds."
N,0.8782383419689119,Proof Claim D.24. Notice that 1
N,0.8788860103626943,"10(α+(z+x2
n)β) >
1
10zβ >
1
10(n−1)x2
l β and νx2
h > ν(ˆx2
n−x2
n),
Therefore a sufﬁcient condition will be that
1
10(n −1)x2
l β > νx2
h, which is equivalent to n >"
N,0.8795336787564767,"1 + x2
h
x2
l
10ν β ."
N,0.8801813471502591,"Claim D.25. For the (σ2)∗
ν as deﬁned in eq. 14"
N,0.8808290155440415,"(σ2)∗
ν > 0."
N,0.8814766839378239,Proof Claim D.25.
N,0.8821243523316062,"(σ2)∗
ν = νσ2 + (1 −ν)ˆσ2 =
ν
α + (z + x2n)β +
1 −ν
α + (z + ˆx2n)β ="
N,0.8827720207253886,"ν(α + (z + ˆx2
n)β) + (1 −ν)(α + (z + x2
n)β)
(α + (z + x2n)β)(α + (z + ˆx2n)β)
=
α + (z + x2
n)β + ν(x2
n −ˆx2
n)
(α + (z + x2n)β)(α + (z + ˆx2n)β) (51)"
N,0.883419689119171,"Therefore, a sufﬁcient condition is that α + (z + x2
n)β + ν(x2
n −ˆx2
n) > 0. Since the condition of
Lemma 4.2 dictates n > 1 + 10 x2
h
x2
l
ν
β then claim D.24 holds, which satisfy this condition."
N,0.8840673575129534,"Claim D.26. For the Bayesian linear regression problem on domain D, and σ, ˆσ deﬁned in eq. 14 ln σ"
N,0.8847150259067358,"ˆσ ≤
x2
h
2(n −1)x2
l
."
N,0.8853626943005182,"Proof Claim D.26. Consider c1 =
x2
h
(n−1)x2
l ,"
N,0.8860103626943006,"c1 =
x2
h
(n −1)x2
l
> ˆx2
n −x2
n
z + x2n
>
ˆx2
nβ −x2
nβ
α + (z + x2n)β = α + (z + ˆx2
n)β
α + (z + x2n)β −1
(52)"
N,0.8866580310880829,"Where eq. 52 holds trivially for ˆxn ≤xn, therefore it is assumed that ˆxn > xn. From eq. 52, by
Taylor theorem and 0 ≤ζ ≤c1 following inequality holds"
N,0.8873056994818653,ec1 = 1 + c1 + eζ
N,0.8879533678756477,"2 (c1)2 > 1 + c1 > α + (z + ˆx2
n)β
α + (z + x2n)β
Consequently, because the natural logarithm is monotonically increasing the following equation also
holds
1
2c1 > 1"
N,0.8886010362694301,2 ln α + (z + ˆxn)β
N,0.8892487046632125,α + (z + xn)β = ln σ ˆσ
N,0.8898963730569949,Therefore ln σ
N,0.8905440414507773,ˆσ < 1
N,0.8911917098445595,"2
x2
h
(n−1)x2
l"
N,0.8918393782383419,"Claim D.27. For the Bayesian linear regression problem on domain D, the conditions of Lemma
4.2 and (σ2)∗
ν, ˆσ deﬁned in eq. 14"
N,0.8924870466321243,"1
2(ν −1) ln
ˆσ2"
N,0.8931347150259067,"(σ2)∗ν
≤1"
N,0.8937823834196891,"2(ν −1)
νx2
h
2((n −1)x2
l −νx2
h)."
N,0.8944300518134715,"Proof Claim D.27. consider c1 =
νx2
h
((n−1)x2
l −νx2
h),"
N,0.8950777202072538,"c1 =
νx2
h
(n −1)x2
l −νx2
h
≥∗
νβx2
h
α + (n −1)x2
l β −νβx2
h
≥∗"
N,0.8957253886010362,"νβˆx2
n
α + (z + x2n)β −νβx2n
≥
νβ(ˆx2
n −x2
n)
α + (z + x2n)β −νβ(x2n −ˆx2n) ="
N,0.8963730569948186,"α + (z + x2
n)β
α + (z + x2n)β + νβ(x2n −ˆx2n) −1 ="
N,0.897020725388601,"1
α + (z + ˆx2n)β · (α + (z + x2
n)β)(α + (z + ˆx2
n)β)
α + (z + x2n)β + νβ(x2n −ˆx2n)
−1 = ˆσ2"
N,0.8976683937823834,"(σ2)∗ν
−1"
N,0.8983160621761658,"Where inequalities * holds under assumption that n > 1 + ν x2
h
x2
l , and last equality holds from eq. 51.
Therefore, by using Taylor theorem and 0 ≤ζ ≤c1 following inequality holds"
N,0.8989637305699482,ec1 = 1 + c1 + eζ
N,0.8996113989637305,"2 (c1)2 > 1 + c1 ≥
ˆσ2"
N,0.9002590673575129,(σ2)∗ν
N,0.9009067357512953,"From this inequality, and because the natural logarithm is monotonically increasing ln
ˆσ2
(σ2)∗ν ≤c1,
therefore
1
2(ν −1) ln
ˆσ2"
N,0.9015544041450777,"(σ2)∗ν
≤1"
N,0.9022020725388601,2(ν −1)c1 = 1
N,0.9028497409326425,"2(ν −1)
νx2
h
((n −1)x2
l −νx2
h)."
N,0.9034974093264249,"Claim D.28. For the Bayesian linear regression problem on domain D, the deﬁnitions of eq. 14,
and the conditions of Lemma 4.2, the value ν"
N,0.9041450777202072,"2
(µ−ˆµ)2"
N,0.9047927461139896,(σ2)∗ν is bounded by
N,0.905440414507772,"2νβ(
x4
h
9
10n1−2γ1x2
l
) + 2νβ((x2
hβ)(x2
hα + x4
hβ)
9
10(x2
l β)2
)(c + nγ1)"
N,0.9060880829015544,"n2−γ1
+ ν"
N,0.9067357512953368,"2((x2
hα + x4
hβ)2"
N,0.9073834196891192,"9
10x6
l β
)(c + nγ1)2 n3
."
N,0.9080310880829016,"Proof Claim D.28. First bound |µ −ˆµ|,"
N,0.908678756476684,"|µ −ˆµ| = β|
q + xnyn
α + (z + x2n)β −
q + ˆxnˆyn
α + (z + ˆx2n)β | ="
N,0.9093264248704663,"|(q + xnyn)(α + (z + ˆx2
n)β) −(q + ˆxnˆyn)(α + (z + x2
n)β)
(α + (z + x2n)β)(α + (z + ˆx2n)β)
| ="
N,0.9099740932642487,"β|qˆx2
nβ + xnynα + xnynzβ + xnynˆx2
nβ −qx2
nβ −ˆxnˆynα −ˆxnˆynzβ −ˆxnˆynx2
nβ
(α + (z + x2n)β)(α + (z + ˆx2n)β)
| ="
N,0.9106217616580311,"β|
ˆx2
nz( q"
N,0.9112694300518135,z −ˆyn
N,0.9119170984455959,"ˆxn )β −x2
nz( q z −yn"
N,0.9125647668393783,xn )β + α(xnyn −ˆxnˆyn) + xnˆxnβ(ynˆxn −ˆynxn)
N,0.9132124352331606,"(α + (z + x2n)β)(α + (z + ˆx2n)β)
| <"
N,0.913860103626943,"β| ˆx2
hz(2nγ1)β + αx2
h(c + nγ1) + x4
hβ(c + nγ1)
(α + (z + x2n)β)(α + (z + ˆx2n)β)
| ="
N,0.9145077720207254,"β|2ˆx2
hβznγ1 + (x2
hα + x4
hβ)(c + nγ1)
(α + (z + x2n)β)(α + (z + ˆx2n)β) |"
N,0.9151554404145078,"Therefore,"
N,0.9158031088082902,"ν
2
(µ −ˆµ)2"
N,0.9164507772020726,"(σ2)∗ν
≤"
N,0.917098445595855,"ν
2β2(2ˆx2
hβznγ1 + (x2
hα + x4
hβ)(c + nγ1)
(α + (z + x2n)β)(α + (z + ˆx2n)β) )2 · (
α + (z + x2
n)β + ν(x2
n −ˆx2
n)
(α + (z + x2n)β)(α + (z + ˆx2n)β))−1 ="
N,0.9177461139896373,"ν
2
β2(2ˆx2
hβznγ1 + (x2
hα + x4
hβ)(c + nγ1))2"
N,0.9183937823834197,(α + (z + x2n)β)(α + (z + ˆx2n)β)(α + (z + x2n)β + ν(x2n −ˆx2n)) ≤∗
N,0.9190414507772021,"ν
2
β2(2x2
hβznγ1 + (x2
hα + x4
hβ)(c + nγ1))2"
N,0.9196891191709845,"9
10(α + (z + x2n)β)(α + (z + ˆx2n)β)(α + (z + x2n)β) ="
N,0.9203367875647669,"ν
2β2((2x2
hβ)2z2n2γ1 + 2(2x2
hβ)(x2
hα + x4
hβ)znγ1(c + nγ1) + (x2
hα + x4
hβ)2(c + nγ1)2"
N,0.9209844559585493,"9
10(α + (z + x2n)β)2(α + (z + ˆx2n)β)
) ≤"
N,0.9216321243523317,"ν
2β2((2x2
hβ)2z2n2γ1 + (4x2
hβ)(x2
hα + x4
hβ)znγ1(c + nγ1) + (x2
hα + x4
hβ)2(c + nγ1)2"
N,0.9222797927461139,"9
10((z + x2n)β)2((z + ˆx2n)β)
) ≤∗∗"
N,0.9229274611398963,"ν
2β2((2x2
hβ)2n2γ1"
N,0.9235751295336787,"9
10nx2
l β3
)+"
N,0.9242227979274611,"ν
2β2((4x2
hβ)(x2
hα + x4
hβ)nγ1(c + nγ1)
9
10(nx2
l )2β3
) + ν"
N,0.9248704663212435,"2β2((x2
hα + x4
hβ)2(c + nγ1)2"
N,0.9255181347150259,"9
10(nx2
l β)3
) ="
N,0.9261658031088082,"2νβ(
x4
h
9
10n1−2γ1x2
l
) + 2νβ((x2
hβ)(x2
hα + x4
hβ)
9
10(x2
l β)2
)(c + nγ1)"
N,0.9268134715025906,"n2−γ1
+ ν"
N,0.927461139896373,"2((x2
hα + x4
hβ)2"
N,0.9281088082901554,"9
10x6
l β
)(c + nγ1)2 n3"
N,0.9287564766839378,"Inequality * is true because Lemma 4.2 conditions dictates that n > 1 + x2
h
x2
l
10ν"
N,0.9294041450777202,"β , and according"
N,0.9300518134715026,"to claim D.24 this promises that
1
10(α + (z + x2
n)β) > ν(ˆx2
n −x2
n). Inequality ** follows from
n >> 1 ⇒(n −1)xl ≈nxl."
N,0.930699481865285,"Claim D.29. For the conditions and deﬁnitions of Lemma 4.3, one sample from the posterior is
(ϵ, δ) differentially private for the following terms on n and ν."
N,0.9313471502590673,"ν = 1 + 2 ln( 1 δ )
ϵ"
N,0.9319948186528497,"n ≥max{1 + x2
h
x2
l"
N,0.9326424870466321,"8
ϵ , 1 + ν x2
h
x2
l
(1 + 8(ν −1) ϵ
),"
N,0.9332901554404145,"(16νβx4
h
9
10ϵx2
l
)"
N,0.9339378238341969,"1
1−2γ1 , (16νβ"
N,0.9345854922279793,"ϵ
((x2
hβ)(x2
hα + x4
hβ)
9
10(x2
l β)2
)(c + nγ1))"
N,0.9352331606217616,"1
2−γ1 , (4ν"
N,0.935880829015544,"ϵ ((x2
hα + x4
hβ)2"
N,0.9365284974093264,"9
10x6
l β
)(c + nγ1))
2
3 }"
N,0.9371761658031088,"Proof Claim D.29. By Lemma 4.3, one sample from the posterior is (ϵ1 + ln( 1"
N,0.9378238341968912,"δ )
ν−1 , δ) differentially"
N,0.9384715025906736,private. For each of the 6 terms of ϵ1 + ln( 1
N,0.939119170984456,"δ )
ν−1 , a lower bound on n and ν is found at equations 53,
54, 55, 56, 57, 58 such that the sum of terms is upper bounded by ϵ. These bounds match the claim’s
guarantee over n and ν therefore proving the claim."
N,0.9397668393782384,For term ln( 1
N,0.9404145077720207,"δ )
ν−1 ln( 1"
N,0.9410621761658031,"δ )
ν −1 = ϵ 2 ⇐⇒"
N,0.9417098445595855,2 ln( 1
N,0.9423575129533679,"δ )
ϵ
+ 1 = ν (53)"
N,0.9430051813471503,"For term
x2
h
(n−1)x2
l"
N,0.9436528497409327,"x2
h
2(n −1)x2
l
≤ϵ 16"
N,0.944300518134715,"n ≥1 + x2
h
x2
l 8
ϵ (54)"
N,0.9449481865284974,For term 1
N,0.9455958549222798,"2(ν −1)
νx2
h
(n−1)x2
l −νx2
h"
N,0.9462435233160622,"1
2(ν −1)
νx2
h
(n −1)x2
l −νx2
h
≤ϵ 16"
N,0.9468911917098446,"1
2(ν −1)16νx2
h
ϵ
≤(n −1)x2
l −νx2
h"
N,0.947538860103627,n ≥1 + 1
N,0.9481865284974094,"2(ν −1)16νx2
h
ϵx2
l
+ ν x2
h
x2
l
= 1 + ν x2
h
x2
l
(1 + 8(ν −1) ϵ
) (55)"
N,0.9488341968911918,"For term 2νβ(
x4
h
9
10 n1−2γ1x2
l )"
N,0.9494818652849741,"2νβ(
x4
h
9
10n1−2γ1x2
l
) ≤ϵ 8 16"
N,0.9501295336787565,"ϵ νβ x4
h
9
10x2
l
≤n1−2γ1"
N,0.9507772020725389,"n ≥(16νβx4
h
9
10ϵx2
l
)"
N,0.9514248704663213,"1
1−2γ1 (56)"
N,0.9520725388601037,"For term 2νβ( (x2
hβ)(x2
hα+x4
hβ)
9
10 (x2
l β)2
) (c+nγ1) n2−γ1"
N,0.9527202072538861,"2νβ((x2
hβ)(x2
hα + x4
hβ)
9
10(x2
l β)2
)(c + nγ1)"
N,0.9533678756476683,"n2−γ1
≤ϵ 8"
N,0.9540155440414507,n2−γ1 ≥16νβ
N,0.9546632124352331,"ϵ
((x2
hβ)(x2
hα + x4
hβ)
9
10(x2
l β)2
)(c + nγ1)"
N,0.9553108808290155,n ≥(16νβ
N,0.9559585492227979,"ϵ
((x2
hβ)(x2
hα + x4
hβ)
9
10(x2
l β)2
)(c + nγ1))"
N,0.9566062176165803,"1
2−γ1 (57)"
N,0.9572538860103627,For term ν
N,0.957901554404145,"2( (x2
hα+x4
hβ)2"
N,0.9585492227979274,"9
10 x6
l β
) (c+nγ1)2 n3"
N,0.9591968911917098,"ν
2((x2
hα + x4
hβ)2"
N,0.9598445595854922,"9
10x6
l β
)(c + nγ1)2 n3
≤ϵ 8"
N,0.9604922279792746,n3 ≥4ν
N,0.961139896373057,"ϵ ((x2
hα + x4
hβ)2"
N,0.9617875647668394,"9
10x6
l β
)(c + nγ1)2"
N,0.9624352331606217,n ≥(4ν
N,0.9630829015544041,"ϵ ((x2
hα + x4
hβ)2"
N,0.9637305699481865,"9
10x6
l β
)(c + nγ1))
2
3 (58)"
N,0.9643782383419689,"Claim D.30. For c = nγ2, γ1 < γ2 <
3
2, and the conditions and deﬁnitions of Lemma 4.3, one
sample from the posterior is (ϵ, δ) differentially private for following terms on n and ν."
N,0.9650259067357513,ν = 2 ln( 1
N,0.9656735751295337,"δ )
ϵ
+ 1"
N,0.966321243523316,"n ≥max{1 + x2
h
x2
l"
N,0.9669689119170984,"8
ϵ , 1 + ν x2
h
x2
l
(1 + 8(ν −1) ϵ
),"
N,0.9676165803108808,"(16νβx4
h
9
10ϵx2
l
)"
N,0.9682642487046632,"1
1−2γ1 , (16νβ"
N,0.9689119170984456,"ϵ
((x2
hβ)(x2
hα + x4
hβ)
9
10(x2
l β)2
)(1 +
1"
N,0.969559585492228,"(1 + 10 x2
h
x2
l
ν
β )γ2−γ1
))"
N,0.9702072538860104,"1
2−γ1−γ2 , (4ν"
N,0.9708549222797928,"ϵ ((x2
hα + x4
hβ)2"
N,0.9715025906735751,"9
10x6
l β
)(1 +
1"
N,0.9721502590673575,"(1 + 10 x2
h
x2
l
ν
β )γ2−γ1
))"
N,0.9727979274611399,"2
3−2γ2 }"
N,0.9734455958549223,"Proof Claim D.30. Claim D.29 provides general lower bounds on n for (ϵ, δ) differential privacy.
When c = nγ2, γ2 > γ1, these bounds can be simpliﬁed."
N,0.9740932642487047,For condition n ≥( 16νβ
N,0.9747409326424871,"ϵ
( (x2
hβ)(x2
hα+x4
hβ)
9
10 (x2
l β)2
)(c + nγ1))"
N,0.9753886010362695,"1
2−γ1 , (16νβ"
N,0.9760362694300518,"ϵ
((x2
hβ)(x2
hα + x4
hβ)
9
10(x2
l β)2
)(c + nγ1))"
N,0.9766839378238342,"1
2−γ1 = (16νβ"
N,0.9773316062176166,"ϵ
((x2
hβ)(x2
hα + x4
hβ)
9
10(x2
l β)2
)nγ2(1 +
1
nγ2−γ1 ))"
N,0.977979274611399,"1
2−γ1 ≤ (16νβ"
N,0.9786269430051814,"ϵ
((x2
hβ)(x2
hα + x4
hβ)
9
10(x2
l β)2
)nγ2(1 +
1"
N,0.9792746113989638,"(1 + 10 x2
h
x2
l
ν
β )γ2−γ1
))"
N,0.9799222797927462,"1
2−γ1"
N,0.9805699481865285,", where the inequality holds since Lemma 4.3 dictates that n ≥1 + 10 x2
h
x2
l
ν
β . Consequently it’s
enough that"
N,0.9812176165803109,n > (16νβ
N,0.9818652849740933,"ϵ
((x2
hβ)(x2
hα + x4
hβ)
9
10(x2
l β)2
)(1 +
1"
N,0.9825129533678757,"(1 + 10 x2
h
x2
l
ν
β )γ2−γ1
))"
N,0.9831606217616581,"1
2−γ1−γ2 ."
N,0.9838082901554405,Following same considerations for condition n ≥( 4ν
N,0.9844559585492227,"ϵ ( (x2
hα+x4
hβ)2"
N,0.9851036269430051,"9
10 x6
l β
)(c + nγ1))
2
3 , it is enough that"
N,0.9857512953367875,n > (4ν
N,0.9863989637305699,"ϵ ((x2
hα + x4
hβ)2"
N,0.9870466321243523,"9
10x6
l β
)(1 +
1"
N,0.9876943005181347,"(1 + 10 x2
h
x2
l
ν
β )γ2−γ1
))"
N,0.9883419689119171,"2
3−2γ2"
N,0.9889896373056994,"E
WASSERSTEIN DISTANCE PROOF"
N,0.9896373056994818,"Claim E.1. If p, q are distributions with 2-Wasserstein distance W2(p, q) = ϵ2, then we have
p(Br(x)) ≤q(Br+ϵ(x)) + ϵ."
N,0.9902849740932642,"Proof. If is the claim that d2
P ≤dw from Gibbs & Su (2002). Picking an optimal coupling and using
Markov inequality we get P(d(x, y) > ϵ) ≤1"
N,0.9909326424870466,"ϵ E[d(x, y)] = ϵ. As {(˜x, ˜y) : ˜x ∈Br(x)} ⊂{(˜x, ˜y) :
˜y ∈Br+ϵ(y)}∪{(˜x, ˜y) : d(˜x, ˜y) > ϵ} we get p(Br(x)) ≤q(Br+ϵ(x))+ϵ (special case of Strassen
theorem)."
N,0.991580310880829,"Claim E.2. Let p, q be continuous distributions on Rd with Wasserstein distance W2(p, q) < ϵ2,
and let pδ,qδ be their convolutions with uniform distribution on Bδ(0). We assume both density
functions are L−Lipshitz continuous. For λ > ϵ we have"
N,0.9922279792746114,"pλ(x) ≤
vold(λ)
vold(λ −ϵ)qλ(x) +
ϵ
vold(λ −ϵ) + 2

vold(λ)
vold(λ −ϵ) −1

λL.
(59)"
N,0.9928756476683938,"Proof. We have P(Bλ(x)) = P(Bλ−ϵ(x)) + P(A(x; λ −ϵ, λ)) where A(x; r1, r2) is the annulus
around x between radius r1 and r2. From continuity there exists z ∈P(Bλ(x)) such that p(z) =
P (Bλ(x))"
N,0.9935233160621761,"vold(λ) , where vold(r) is the volume of a ball of radius r in Rd. From Lipshitz continuity we have"
N,0.9941709844559585,"P(A(x; λ −ϵ, λ)) ≤(vold(λ) −vold(λ −ϵ))(p(z) + 2λL) =

1 −vold(λ−ϵ)"
N,0.9948186528497409,"vold(λ)

P(Bλ(x)) + ∆,"
N,0.9954663212435233,"where ∆= (vold(λ) −vold(λ −ϵ))2λL. From this, we get"
N,0.9961139896373057,P(Bλ−ϵ(x)) ≥vold(λ −ϵ)
N,0.9967616580310881,"vold(λ)
P(Bλ(x)) −∆.
(60)"
N,0.9974093264248705,"Combining this with claim E.1, we get"
N,0.9980569948186528,"P(Bλ(x)) ≤
vold(λ)
vold(λ −ϵ)(P(Bλ−ϵ(x)) + ∆) ≤
vold(λ)
vold(λ −ϵ)(Q(Bλ(x)) + ∆+ ϵ).
(61)"
N,0.9987046632124352,"We divide by vold(λ) to get the densities pλ, qλ."
N,0.9993523316062176,"pλ(x) ≤
vold(λ)
vold(λ −ϵ)qλ(x) +
∆+ ϵ
vold(λ −ϵ)
(62)"
