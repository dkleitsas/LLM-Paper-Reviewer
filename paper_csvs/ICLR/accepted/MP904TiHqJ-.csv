Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.002617801047120419,"In this paper, we study the problem of Ô¨Ånding mixed Nash equilibrium for mean-
Ô¨Åeld two-player zero-sum games. Solving this problem requires optimizing over
two probability distributions. We consider a quasistatic Wasserstein gradient Ô¨Çow
dynamics in which one probability distribution follows the Wasserstein gradient
Ô¨Çow, while the other one is always at the equilibrium. Theoretical analysis are
conducted on this dynamics, showing its convergence to the mixed Nash equilib-
rium under mild conditions. Inspired by the continuous dynamics of probabil-
ity distributions, we derive a quasistatic Langevin gradient descent method with
inner-outer iterations, and test the method on different problems, including train-
ing mixture of GANs."
INTRODUCTION,0.005235602094240838,"1
INTRODUCTION"
INTRODUCTION,0.007853403141361256,"Finding Nash equilibrium has seen many important applications in machine learning, such as gener-
ative adversarial networks (GANs) (Goodfellow et al., 2014a) and reinforcement learning (Busoniu
et al., 2008). In these problems, pure Nash equilibria are usually search for a function f(x, y). Yet,
the problems arising from machine learning are usually nonconvex in x and nonconcave in y, in
which case pure Nash equilibrium may not exist. And even if it exists, there is no guarantee for any
optimization algorithm to Ô¨Ånd it efÔ¨Åciently. This difÔ¨Åculty is reÔ¨Çected in practice, that compared
with simple minimization, machine learning applications involving Nash equilibria usually have
more complicated behaviors and more subtle dependence on hyper-parameters. For example, stable
and efÔ¨Åcient training of GANs requires a number of carefully designed tricks (Gao et al., 2018)."
INTRODUCTION,0.010471204188481676,"On the other hand, the mixed Nash equilibrium (MNE) is known to exist in much more general set-
tings, e.g. when the strategy spaces are compact and the payoff function is continuous (Glicksberg,
1952). In the mixed Nash equilibrium problem, instead of taking ‚Äúpure strategies‚Äù x and y, two
‚Äùmixed strategies‚Äù for x and y, in the form of probability distributions, are considered, resulting in
the following functional,
Z
f(x, y)p(x)q(y)dxdy,"
INTRODUCTION,0.013089005235602094,"where p and q are density functions of probability distributions of x and y, respectively. Efforts
are invested to develop theoretically endorsed algorithms that can efÔ¨Åciently Ô¨Ånd MNE for high
dimensional problems, with applications on the training of mixture of GANs. In Hsieh et al. (2019),
a mirror-descent algorithm is proposed and its convergence is proven. In Domingo-Enrich et al.
(2020), theoretical analysis and empirical experiments are conducted for a gradient descent-ascent
Ô¨Çow under a Wasserstein-Fisher-Rao metric and its particle discretization."
INTRODUCTION,0.015706806282722512,"In this paper, we also consider the mixed Nash equilibrium problem, and propose a simple Qua-
siStatic Wasserstein Gradient Flow (QSWGF) for solving the problem. In our dynamics, we treat
q as a component with much faster speed than p, hence is always at equilibrium as p moves. With
entropy regularization for both p and q (without requirement on the strength of the regularizations),
we prove that the QSWGF converges to the unique mixed Nash equilibrium from any initialization
(under mild conditions). Furthermore, we show there is a simple way to discretize the QSWGF, re-
gardless of the complexity of the Wasserstein gradient Ô¨Çow of p induced by the fact that q is always"
INTRODUCTION,0.01832460732984293,Published as a conference paper at ICLR 2022
INTRODUCTION,0.020942408376963352,"at equilibrium. Concretely, a partition function related with p appears in the QSWGF dynamics,
and we Ô¨Ånd an efÔ¨Åcient way to approximate the partition function. By discretizing the QSWGF,
we derive a particle dynamics with an inner-outer structure, named the QuasiStatic Langevin Gra-
dient Descent algorithm (QSLGD). In QSLGD, after each iteration of the outer problem (for the x
particles), the inner loop conducts sufÔ¨Åcient iterations to bring the y particles to equilibrium. Nu-
merical experiments show the effectiveness of QSLGD on synthetic examples and training mixture
of GANs. Our method outperforms the vanilla Langevin gradient descent-ascent method when the
entropy regularization is weak."
INTRODUCTION,0.02356020942408377,"As a summary, our two major contributions are:"
INTRODUCTION,0.02617801047120419,"1. We propose the quasistatic Wasserstein gradient Ô¨Çow dynamics for mixed Nash equilibrium
problems, and show its convergence to the unique Nash equilibrium under weak assump-
tions. Our result neither requires the entropy regularization to be sufÔ¨Åciently strong, nor
assumes the dynamics to converge a priori."
WE DERIVE A SIMPLE WHILE PRACTICAL QUASISTATIC LANGEVIN GRADIENT DESCENT ALGORITHM BY DIS-,0.028795811518324606,"2. We derive a simple while practical quasistatic Langevin gradient descent algorithm by dis-
cretizing the quasistatic Wasserstein gradient Ô¨Çow, by Ô¨Ånding an efÔ¨Åcient way to approx-
imate the partition function appearing in the dynamics of p. The proposed algorithm is
applied on several problems including training mixtures of GANs."
RELATED WORK,0.031413612565445025,"2
RELATED WORK"
RELATED WORK,0.034031413612565446,"The mixed Nash equilibrium problem has a long history, with the proof of its existence dates back
to Morgenstern & Von Neumann (1953). It draws new attention in recent years, especially in the
machine learning community, due to the development of GANs (Goodfellow et al., 2014a) and ad-
versarial training (Goodfellow et al., 2014b). Training mixture of GANs is already discussed in
paper (Goodfellow et al., 2014a). Some numerical experiments were conducted in (Arora et al.,
2017). In Grnarova et al. (2017), the authors proposed an online learning approach for training mix-
ture of GANs, and proved its effectiveness for semi-shallow GANs (GANs whose discriminator is
a shallow neural network). Yet, rigorous theoretical treatment to an algorithm started from (Hsieh
et al., 2019), in which a mirror descent method was studied and proven to converge. The imple-
mentation of the mirror descent method involves big computational cost that asks for heuristics to
alleviate. Later, (Domingo-Enrich et al., 2020) studied more efÔ¨Åcient algorithms under a mixture of
Wasserstein and Fisher-Rao metrics. Theoretically, the time average of the dynamics‚Äô trajectories is
shown to converge to the mixed Nash equilibrium. As a comparison, in this work we show the global
convergence of the quasistatic Wasserstein gradient Ô¨Çow without the need of taking time average.
Meanwhile, the Wasserstein nature of our dynamics makes it easy to implement as well."
RELATED WORK,0.03664921465968586,"The Wasserstein gradient Ô¨Çow in the density space has been explored in previous works. For exam-
ple, (Wang & Li, 2019) studied the Nesterov‚Äôs accelerated gradient Ô¨Çows for probability distributions
under the Wasserstein metric, and (Arbel et al., 2019) studied practical implementations of the natu-
ral gradient method for the Wasserstein metric. Both works focus on minimization problems instead
of min-max problems considered in this work. A more related work is Lin et al. (2021b), where a
natural gradient based algorithm is proposed for training GANs. Yet, the method still optimizes one
generator and one discriminator, searching for pure Nash equilibrium. Another work that derives
algorithms for GANs from a Wasserstein perspective is (Lin et al., 2021a)."
RELATED WORK,0.03926701570680628,"Another volume of works that studies the Wasserstein gradient Ô¨Çow in the machine learning con-
text is the mean-Ô¨Åeld analysis of neural networks. This line of works started from two-layer neural
networks (Mei et al., 2018; Rotskoff & Vanden-Eijnden, 2018; Chizat & Bach, 2018; Sirignano &
Spiliopoulos, 2020), to deep fully-connected networks (Ara¬¥ujo et al., 2019; Sirignano & Spiliopou-
los, 2021; Nguyen, 2019; Wojtowytsch et al., 2020), and residual networks (Lu et al., 2020; E et al.,
2020). The mean-Ô¨Åeld formulations treat parameters as probability distributions, and the training
dynamics are usually the gradient Ô¨Çow under Wasserstein metric. Attempts to prove convergence of
the dynamics to global minima are made (Mei et al., 2018; Chizat & Bach, 2018; Rotskoff et al.,
2019), though in the case without entropy regularization a convergence assumption should usually
be made a priori."
RELATED WORK,0.041884816753926704,Published as a conference paper at ICLR 2022
THE QUASISTATIC DYNAMICS,0.04450261780104712,"3
THE QUASISTATIC DYNAMICS"
THE QUASISTATIC DYNAMICS,0.04712041884816754,"We consider the entropy regularized mixed Nash equilibrium problem, which in our case is equiva-
lent with solving the following minimax problem:"
THE QUASISTATIC DYNAMICS,0.049738219895287955,"min
p‚ààP(‚Ñ¶) max
q‚ààP(‚Ñ¶) Z"
THE QUASISTATIC DYNAMICS,0.05235602094240838,"‚Ñ¶√ó‚Ñ¶
K(x, y)p(x)q(y)dxdy + Œ≤‚àí1
Z"
THE QUASISTATIC DYNAMICS,0.0549738219895288,"‚Ñ¶
p log pdx ‚àíŒ≤‚àí1
Z"
THE QUASISTATIC DYNAMICS,0.05759162303664921,"‚Ñ¶
q log qdy.
(1)"
THE QUASISTATIC DYNAMICS,0.060209424083769635,"In (1), ‚Ñ¶is a compact Riemannian manifold without boundary, and P(‚Ñ¶) is the set of probability
distributions on ‚Ñ¶. Since ‚Ñ¶is compact, any probability distribution in P(‚Ñ¶) naturally has Ô¨Ånite mo-
ments. Let E(p, q) =
R"
THE QUASISTATIC DYNAMICS,0.06282722513089005,"‚Ñ¶√ó‚Ñ¶K(x, y)p(dx)q(dy), and S(p) =
R"
THE QUASISTATIC DYNAMICS,0.06544502617801047,"‚Ñ¶p log pdx and S(q) =
R"
THE QUASISTATIC DYNAMICS,0.06806282722513089,"‚Ñ¶q log qdy
be the (negative) entropy of p and q, respectively. Then, the minimax problem (1) can be written in
short as
min
p‚ààP(‚Ñ¶) max
q‚ààP(‚Ñ¶) E(p, q) + Œ≤‚àí1S(p) ‚àíŒ≤‚àí1S(q).
(2)"
THE QUASISTATIC DYNAMICS,0.07068062827225131,"Remark 1. Strictly speaking, in (1) we should distinguish probability distributions and their den-
sity function (if exist), and the entropy should also be deÔ¨Åned using the Radon-Nikodym derivative
with canonical measure. In this paper, since p and q indeed have density functions because of the
entropy regularization, we shall abuse the notation by using p and q to represent both probability
distributions and their density functions."
THE QUASISTATIC DYNAMICS,0.07329842931937172,"The entropy regularizations in (1) and (2) make the problem strongly convex in p and strongly
concave in q. Hence, there exists a unique Nash equilibrium for the problem. Such results are
shown for example by the following theorem from (Domingo-Enrich et al., 2020).
Theorem 1. (Theorem 4 of (Domingo-Enrich et al., 2020)) Assume ‚Ñ¶is a compact Polish metric
space equipped with canonical Borel measure, and that K is a continuous function on ‚Ñ¶√ó ‚Ñ¶.
Then, problem (2) has a unique Nash equilibrium given by the solution of the following Ô¨Åxed-point
problem:"
THE QUASISTATIC DYNAMICS,0.07591623036649214,p(x) = 1
THE QUASISTATIC DYNAMICS,0.07853403141361257,"Zp
exp(‚àíŒ≤U(x, q)),
q(x) = 1"
THE QUASISTATIC DYNAMICS,0.08115183246073299,"Zq
exp(Œ≤V (y, p)),
(3)"
THE QUASISTATIC DYNAMICS,0.08376963350785341,"where Zp and Zq are normalization constants to make sure p and q are probability distributions,
and U and V are deÔ¨Åned as"
THE QUASISTATIC DYNAMICS,0.08638743455497382,"U(x, q) = Œ¥E(p, q)"
THE QUASISTATIC DYNAMICS,0.08900523560209424,"Œ¥p
(x) =
Z"
THE QUASISTATIC DYNAMICS,0.09162303664921466,"‚Ñ¶
K(x, y)q(y)dy,
V (y, p) = Œ¥E(p, q)"
THE QUASISTATIC DYNAMICS,0.09424083769633508,"Œ¥q
(y) =
Z"
THE QUASISTATIC DYNAMICS,0.0968586387434555,"‚Ñ¶
K(x, y)p(x)dx."
THE QUASISTATIC DYNAMICS,0.09947643979057591,"Considering the efÔ¨Åciency in high-dimensional cases, a natural dynamics of interest to Ô¨Ånd the Nash
equilibrium for (2) is the gradient descent-ascent Ô¨Çow under the Wasserstein metric,"
THE QUASISTATIC DYNAMICS,0.10209424083769633,"‚àÇtpt = ‚àá¬∑
 
pt‚àá(U(x, qt) + Œ≤‚àí1 log pt)

,"
THE QUASISTATIC DYNAMICS,0.10471204188481675,"‚àÇtqt = ‚àá¬∑
 
qt‚àá(‚àíV (y, pt) + Œ≤‚àí1 log qt)

,
(4)"
THE QUASISTATIC DYNAMICS,0.10732984293193717,"because it can be easily discretized into a Langevin gradient descent-ascent method by treating the
PDEs as Fokker-Planck equations of SDEs. When Œ≤‚àí1 is sufÔ¨Åciently large, (4) can be proven to
converge linearly to the unique MNE of (2) (Eberle et al., 2019). However, when Œ≤‚àí1 is small,
whether (4) converges remains open. This hinders the application of (4) because in practice the
entropy terms are usually used as regularization and are kept small. (We realize that it is proven
in Domingo-Enrich & Bruna (2022) when our work is under review.)"
THE QUASISTATIC DYNAMICS,0.1099476439790576,"In (4), the dynamics of p and q have the same speed. In this work, instead, we study a quasistatic
Wasserstein gradient descent dynamics, which can be understood as a limiting dynamics when the
speed of q becomes faster and faster compared with that of p. In this case, at any time t, we assume
qt reaches at the equilibrium of the maximizing problem instantaneously by Ô¨Åxing p = pt in (2).
That is to say, at any time t, qt is determined by"
THE QUASISTATIC DYNAMICS,0.112565445026178,"qt = q[pt] := arg max
q‚ààP(‚Ñ¶) E(pt, q) ‚àíŒ≤‚àí1S(q).
(5)"
THE QUASISTATIC DYNAMICS,0.11518324607329843,"On the other hand, pt follows the Wasserstein gradient descent Ô¨Çow with qt = q[pt] at the equilib-
rium:"
THE QUASISTATIC DYNAMICS,0.11780104712041885,"‚àÇtpt = ‚àá¬∑

pt‚àá
Œ¥(E(pt, q[pt]) ‚àíŒ≤‚àí1S(q[pt]))"
THE QUASISTATIC DYNAMICS,0.12041884816753927,"Œ¥pt
+ Œ≤‚àí1 log pt"
THE QUASISTATIC DYNAMICS,0.12303664921465969,"
.
(6)"
THE QUASISTATIC DYNAMICS,0.1256544502617801,Published as a conference paper at ICLR 2022
THE QUASISTATIC DYNAMICS,0.12827225130890052,"The following theorem shows qt = q[pt] can be explicitly written as a Gibbs distribution depending
on pt, and thus the free energy in (6) can be simpliÔ¨Åed to depend on a partition function related with
pt.
Theorem 2. Assume K is continuous on the compact set ‚Ñ¶and Œ≤ > 0. Then, for Ô¨Åxed pt the
maximization problem (5) has a unique solution"
THE QUASISTATIC DYNAMICS,0.13089005235602094,"q[pt](y) :=
1
Zq(pt) exp(Œ≤V (y, pt)),
(7)"
THE QUASISTATIC DYNAMICS,0.13350785340314136,"where Zq(p) is a normalization factor, Zq(p) :=
R
exp(Œ≤V (y, p))dy. Moreover, the dynamics (6)
for pt can be written as"
THE QUASISTATIC DYNAMICS,0.13612565445026178,"‚àÇtpt = ‚àá¬∑

pt‚àá
Œ¥Œ≤‚àí1 log Zq(pt)"
THE QUASISTATIC DYNAMICS,0.1387434554973822,"Œ¥pt
+ Œ≤‚àí1 log pt"
THE QUASISTATIC DYNAMICS,0.14136125654450263,"
.
(8)"
THE QUASISTATIC DYNAMICS,0.14397905759162305,"Let Fp,Œ≤(p) := Œ≤‚àí1 log Zq(p) + Œ≤‚àí1S(p). By Theorem 2, the dynamics (8) of pt is the Wasserstein
gradient descent Ô¨Çow for minimizing Fp,Œ≤(p). By the Proposition 3 below, Fp,Œ≤ is strongly convex
with respect to p. Therefore, it is possible to prove global convergence for the dynamics (8), and
thus the convergence for the quasistatic Wasserstein gradient Ô¨Çow for the minimax problem (2).
Proposition 3. For any probability distributions p1, p2 in P(‚Ñ¶), and any Œª ‚àà[0, 1], we have"
THE QUASISTATIC DYNAMICS,0.14659685863874344,"Fp,Œ≤(Œªp1 + (1 ‚àíŒª)p2) < ŒªFp,Œ≤(p1) + (1 ‚àíŒª)Fp,Œ≤(p2)."
THE QUASISTATIC DYNAMICS,0.14921465968586387,"In practice the partition function log Zq(pt) in (8) seems hard to approximate, especially when ‚Ñ¶is
in high dimensional spaces. However, we show in the following proposition that the variation of the
partition function with respect to pt can be written as a simple form involving qt. This property will
be used to derive a particle method in Section 5
Proposition 4. For any p ‚ààP(‚Ñ¶), we have"
THE QUASISTATIC DYNAMICS,0.1518324607329843,Œ¥Œ≤‚àí1 log Zq(p)
THE QUASISTATIC DYNAMICS,0.1544502617801047,"Œ¥p
= U(¬∑, q[p]),
(9)"
THE QUASISTATIC DYNAMICS,0.15706806282722513,"where q[p] is deÔ¨Åned in (7). Therefore, the dynamics (8) is equivalent with"
THE QUASISTATIC DYNAMICS,0.15968586387434555,"‚àÇtpt = ‚àá¬∑
 
pt‚àá
 
U(x, q[pt]) + Œ≤‚àí1 log pt

.
(10)"
CONVERGENCE ANALYSIS,0.16230366492146597,"4
CONVERGENCE ANALYSIS"
CONVERGENCE ANALYSIS,0.1649214659685864,"In this section, we analyze the convergence of the quasistatic dynamics (7), (8). First, we make the
following assumptions on K.
Assumption 1. Assume K ‚ààC‚àû(‚Ñ¶√ó ‚Ñ¶), which means K has continuous derivatives of any order
(with respect to both x and y)."
CONVERGENCE ANALYSIS,0.16753926701570682,"Since ‚Ñ¶is compact, assumption 1 implies boundedness and Lipschitz continuity of any derivatives
of K."
CONVERGENCE ANALYSIS,0.17015706806282724,"Now, we state our main theorem, which shows the convergence of QSWGF to the Nash equilibrium.
Theorem 5. (main theorem) Assume Assumption 1 holds for K. Then, starting from any initial
p0, q0 ‚ààP(‚Ñ¶), the dynamics (7), (8) has a unique solution (pt, qt)t‚â•0, and the solution converges
weakly to the unique Nash equilibrium of (2), (p‚àó, q‚àó), which satisÔ¨Åes the Ô¨Åxed point problem (3)."
CONVERGENCE ANALYSIS,0.17277486910994763,"Theorem 5 guarantees convergence of the quasistatic Wasserstein gradient Ô¨Çow for any Œ≤, giving
theoretical endorsement to the discretized algorithm that we will introduce in the next section. Note
that the initialization q0 in the theorem is not important, because we assume q achieves equilibrium
immediately after the initialization.
Remark 2. The assumption on K‚Äôs smoothness can be made weaker. For example, during the
proof, up to 4-th order derivatives of K is enough to give sufÔ¨Åcient regularity to the solution of the
dynamics. We make the strong assumption partly to prevent tedious technical analysis so as to focus
on the idea and insights."
CONVERGENCE ANALYSIS,0.17539267015706805,Published as a conference paper at ICLR 2022
CONVERGENCE ANALYSIS,0.17801047120418848,"Proof sketch
We provide some main steps and ideas of the proof of the main theorem in this
section. The detailed proof is put in the appendix."
CONVERGENCE ANALYSIS,0.1806282722513089,"By the last section, since qt is always at equilibrium, we only need to considering a Wasserstein
gradient descent Ô¨Çow for Fp,Œ≤(p). Therefore, we can build our analysis based on the theories in (Mei
et al., 2018) and (Jordan et al., 1998). However, compared with the analysis therein, our theory deals
with a new energy term‚ÄîŒ≤‚àí1 log Zq(p), which has not been studied by previous works. From now
on, let Ep,Œ≤(p) = Œ≤‚àí1 log Zq(p), and Œ®(¬∑, p) = Œ¥Ep,Œ≤(p)"
CONVERGENCE ANALYSIS,0.18324607329842932,"Œ¥p
. By simple calculation we have"
CONVERGENCE ANALYSIS,0.18586387434554974,"Œ®(x, p) = U(x, q[p]) =
1
Zq(p) Z"
CONVERGENCE ANALYSIS,0.18848167539267016,"‚Ñ¶
K(x, y) exp
Z"
CONVERGENCE ANALYSIS,0.19109947643979058,"‚Ñ¶
Œ≤K(x, y)p(x)dx

dy.
(11)"
CONVERGENCE ANALYSIS,0.193717277486911,"First, we study the free energy Fp,Œ≤(p), and show that it has a unique minimizer which satisÔ¨Åes a
Ô¨Åxed point condition. This is the result of the convexity of Fp,Œ≤. We have the following lemma.
Lemma 1. Assume Assumption 1 holds for K. Then, Fp,Œ≤ has a unique minimizer p‚àóthat satisÔ¨Åes"
CONVERGENCE ANALYSIS,0.19633507853403143,"Fp,Œ≤(p‚àó) =
inf
p‚ààP(‚Ñ¶) Fp,Œ≤(p‚àó)."
CONVERGENCE ANALYSIS,0.19895287958115182,"Moreover, p‚àóis the unique solution of the following Ô¨Åxed point problem, p‚àó= 1"
CONVERGENCE ANALYSIS,0.20157068062827224,"Z exp (‚àíŒ≤Œ®(x, p‚àó)),
(12)"
CONVERGENCE ANALYSIS,0.20418848167539266,where Z is the normalization factor.
CONVERGENCE ANALYSIS,0.20680628272251309,"Next, we want to show that any trajectory given by dynamics (10) will converge to the unique
minimizer of Fp,Œ≤. To achieve this, we Ô¨Årst study the existence, uniqueness, and regularity of the
solution to (8), i.e. the trajectory indeed exists and is well behaved. Related results are given by the
following lemma.
Lemma 2. Assume Assumption 1 holds for K. Then, starting from any initial p0 ‚ààP(‚Ñ¶), the weak
solution (pt)t‚â•0 to (8) exists and is unique. Moreover, (pt) is smooth on (0, ‚àû) √ó ‚Ñ¶."
CONVERGENCE ANALYSIS,0.2094240837696335,"The proof of Lemma 2 is based on Proposition 5.1 of (Jordan et al., 1998). Especially, the existence
part is proven using the JKO scheme proposed in (Jordan et al., 1998). We consider a sequence of
probability distributions given by the following discrete iteration schemes with time step h,"
CONVERGENCE ANALYSIS,0.21204188481675393,"ph
0 = p0,
ph
k = arg min
p‚ààP(‚Ñ¶) 1"
CONVERGENCE ANALYSIS,0.21465968586387435,"2W 2
2 (p, ph
k‚àí1) + hFp,Œ≤(p)

,
k > 0,"
CONVERGENCE ANALYSIS,0.21727748691099477,"where W2(p, q) means the 2-Wasserstein distance between probability distributions p and q. Let
(ph
t )t‚â•0 be the piecewise constant interpolations of (ph
k)k‚â•0 on time. We show (ph
t ) converges
weakly (after taking a subsequence) to a weak solution of (8) as h tends to 0. Details are given in
the appendix."
CONVERGENCE ANALYSIS,0.2198952879581152,"Finally, noting that Fp,Œ≤ is a Lyapunov function of the dynamics (8), we have the following lemma
showing the convergence of (pt)t‚â•0 to the solution of the Boltzmann Ô¨Åxed point problem (12). This
Ô¨Ånishes the proof of the main theorem.
Lemma 3. Let (pt)t‚â•0 be the solution of (8) from any initial p0 ‚ààP(‚Ñ¶). Let p‚àóbe the unique
minimizer of Fp,Œ≤ given by (12). Then, pt converges to p‚àóweakly as t ‚Üí‚àû."
CONVERGENCE ANALYSIS,0.22251308900523561,"As a byproduct, since our convergence results does not impose requirement on Œ≤, if one is interested
in the minimax problem without entropy regularization,"
CONVERGENCE ANALYSIS,0.225130890052356,"min
p‚ààP(‚Ñ¶) max
q‚ààP(‚Ñ¶) E(p, q),
(13)"
CONVERGENCE ANALYSIS,0.22774869109947643,"then, Theorem 5 in (Domingo-Enrich et al., 2020) ensures that the quasistatic dynamics converges
to approximate Nash equilibrium of (13) as long as Œ≤‚àí1 is small enough. SpeciÔ¨Åcally, a pair of
probability distributions (p, q) is called œµ-Nash equilibrium of (13) if"
CONVERGENCE ANALYSIS,0.23036649214659685,"sup
q‚Ä≤‚ààP(‚Ñ¶)
E(p, q‚Ä≤) ‚àí
inf
p‚Ä≤‚ààP(‚Ñ¶) E(p‚Ä≤, q) ‚â§œµ."
CONVERGENCE ANALYSIS,0.23298429319371727,"Then, we have the following theorem as a direct results of Theorem 5 in (Domingo-Enrich et al.,
2020):"
CONVERGENCE ANALYSIS,0.2356020942408377,Published as a conference paper at ICLR 2022
CONVERGENCE ANALYSIS,0.23821989528795812,"Theorem 6. Let CK be the bound of K that satisÔ¨Åes |K(x, y)| ‚â§CK for any x, y ‚àà‚Ñ¶, and let
Lip(K) be the Lipschitz constant of K. For any œµ > 0, let Œ¥ = œµ/(2Lip(K)), and let VŒ¥ be the
volume of a ball with radius Œ¥ in ‚Ñ¶. Then, as long as Œ≤ > 4"
CONVERGENCE ANALYSIS,0.24083769633507854,"œµ log
2(1 ‚àíVŒ¥) VŒ¥ 4CK"
CONVERGENCE ANALYSIS,0.24345549738219896,"œµ
‚àí1

,"
CONVERGENCE ANALYSIS,0.24607329842931938,"there exists T > 0 which depends on œµ, such that for any t > T, the solution pt, qt of the dynamics
(7) and (8) at t satisÔ¨Åes
sup
q‚Ä≤‚ààP(‚Ñ¶)
E(pt, q‚Ä≤) ‚àí
inf
p‚Ä≤‚ààP(‚Ñ¶) E(p‚Ä≤, qt) ‚â§œµ."
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.2486910994764398,"5
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.2513089005235602,"It is well known that PDEs with the form
‚àÇtp(t, x) = ‚àá¬∑ (p(t, x)¬µ(t, x)) + Œª‚àÜp(t, x)"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.25392670157068065,"are Fokker-Planck equations for SDEs dXt = ‚àí¬µ(t, Xt)dt +
‚àö"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.25654450261780104,"2ŒªdWt, and the solution for the
PDE characterizes the law of Xt‚Äîthe solution of the SDE‚Äîat any time. This result connects the
Wasserstein gradient Ô¨Çow with SDE, and gives a natural particle discretization to approximate the
continuous Wasserstein gradient Ô¨Çow. For example, the Wasserstein gradient descent-ascent Ô¨Çow
dynamics (4) is the Fokker-Planck equation of the SDEs"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.2591623036649215,"dXt = ‚àí‚àáxU(Xt, qt)dt +
p"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.2617801047120419,2Œ≤‚àí1dWt
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.2643979057591623,"dYt = ‚àáyV (Yt, pt)dt +
p"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.2670157068062827,"2Œ≤‚àí1dW ‚Ä≤
t,
where pt and qt are the laws of Xt and Yt, respectively, and Wt and W ‚Ä≤
t are two Brownian motions.
Note that we have"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.2696335078534031,"‚àáxU(x, q) =
Z"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.27225130890052357,"‚Ñ¶
‚àáxK(x, y)q(y)dy, ‚àáyV (y, p) =
Z"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.27486910994764396,"‚Ñ¶
‚àáyK(x, y)p(x)dx."
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.2774869109947644,"Therefore, i.i.d. picking X(i)
0
‚àºp0 and Y (i)
0
‚àºq0 for i = 1, 2, ..., n, the particle update scheme,
named Langevin Gradient Descent-Ascent (LGDA),"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.2801047120418848,"X(i)
k+1 = X(i)
k
‚àíh n n
X"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.28272251308900526,"j=1
‚àáxK(X(i)
k , Y (j)
k
) +
p"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.28534031413612565,"2hŒ≤‚àí1Œæ(i)
k ,"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.2879581151832461,"Y (i)
k+1 = Y (i)
k
+ h n n
X"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.2905759162303665,"j=1
‚àáyK(X(j)
k , Y (i)
k ) +
p"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.2931937172774869,"2hŒ≤‚àí1Œ∂(i)
k ,
(14)"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.29581151832460734,"approximately solves the SDEs, and thus the empirical distributions of X(i)
k
and Y (i)
k
approximate
the solutions of (4) when n is large. Here, Œæ(i)
k and Œ∂(i)
k
are i.i.d. samples from the standard Gaussian."
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.29842931937172773,"Quasistatic Langevin gradient descent method
Similarly, the dynamics (8) for p is the Fokker-
Planck equation for the SDE"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.3010471204188482,"dXt = ‚àí‚àáŒ®(x, pt)dt +
p"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.3036649214659686,"2Œ≤‚àí1dWt,
(15)
where pt is the law of Xt. By proposition 4 we have Œ®(x, pt) = U(x, q[pt]). Hence, (15) can be
written as
dXt = ‚àí‚àáxU(Xt, q[pt])dt +
p"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.306282722513089,"2Œ≤‚àí1dWt,
(16)
with q[pt] at the equilibrium of the maximization problem (5), which can be attained by solving the
SDE
dYt = ‚àáyV (Yt, pt)dt +
p"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.3089005235602094,"2Œ≤‚àí1dW ‚Ä≤
t
(17)
for sufÔ¨Åciently long time. This motivates us to design a quasistatic particle method as a discretization
for the quasistatic Wasserstein gradient Ô¨Çow. SpeciÔ¨Åcally, the method consists of an inner loop and
an outer loop. The method starts from some particles X(i)
0
and Y (i)
0 , i = 1, 2, ..., n, sampled i.i.d.
from p0 and q0, respectively. Then, at the k-th step, the inner loop conducts enough iterations on the
Y particles to solve (17) with pt Ô¨Åxed (i.e. with the X particles Ô¨Åxed), which drives the empirical
distribution of {Y (i)
k }n
i=1 near equilibrium before each update of the outer loop. Next, the outer loop
updates X(i)
k
according the SDE (16). The algorithm is summarized in Algorithm 1."
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.31151832460732987,Published as a conference paper at ICLR 2022
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.31413612565445026,"Algorithm 1: Quasistatic Langevin gradient descent method (QSLGD)
input : nx, ny, k0, k1, k2, T ‚ààN+, hx, hy > 0, p0, q0 ‚ààP(‚Ñ¶)
output: Final particles (X(i)
T , Y (i)
T )n
i=1"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.31675392670157065,"1 Sample (X(i)
0 )nx
i=1 i.i.d. from p0, and (Y (i)
0 )ny
i=1 i.i.d. from q0;"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.3193717277486911,"2 Y (i)
0,0 ‚ÜêY (i)
0
for i = 1, 2, ..., ny;"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.3219895287958115,3 for s ‚Üê1 to k0 do
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.32460732984293195,"4
Y (i)
0,s ‚ÜêY (i)
0,s‚àí1 + hy nx nx
P"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.32722513089005234,"j=1
‚àáyK(X(j)
0 , Y (i)
0,s‚àí1) +
p"
THE QUASISTATIC LANGEVIN GRADIENT DESCENT-ASCENT METHOD,0.3298429319371728,"2hyŒ≤‚àí1Œæ ;
/* remark 3.1 */"
END,0.3324607329842932,5 end
END,0.33507853403141363,"6 Y (i)
0
‚ÜêY (i)
0,k0 for i = 1, 2, ..., ny;"
END,0.337696335078534,7 for t ‚Üê1 to T do
END,0.3403141361256545,"8
Y (i)
t‚àí1,0 ‚ÜêY (i)
t‚àí1 for i = 1, 2, ..., ny;"
END,0.34293193717277487,"9
for s ‚Üê1 to k1 do"
END,0.34554973821989526,"10
Y (i)
t‚àí1,s ‚ÜêY (i)
t‚àí1,s‚àí1 + hy nx nx
P"
END,0.3481675392670157,"j=1
‚àáyK(X(j)
t‚àí1, Y (i)
t‚àí1,s‚àí1) +
p"
END,0.3507853403141361,2hyŒ≤‚àí1Œæ;
END,0.35340314136125656,"11
end"
END,0.35602094240837695,"12
for s ‚Üê1 to k2 do"
END,0.3586387434554974,"13
Y (i)
t‚àí1,s+k1 ‚ÜêY (i)
t‚àí1,s+k1‚àí1 + hy nx nx
P"
END,0.3612565445026178,"j=1
‚àáyK(X(j)
t‚àí1, Y (i)
t‚àí1,s+k1‚àí1) +
p"
END,0.36387434554973824,2hyŒ≤‚àí1Œæ;
END,0.36649214659685864,"14
ÀÜY ((s‚àí1)ny+i)
t‚àí1
‚ÜêY (i)
t‚àí1,s+k1, for i = 1, 2, ..., ny;"
END,0.36910994764397903,"15
end"
END,0.3717277486910995,"16
X(i)
t
‚ÜêX(i)
t‚àí1 +
hx
k2ny"
END,0.3743455497382199,"k2ny
P"
END,0.3769633507853403,"j=1
‚àáyK(X(i)
t‚àí1, ÀÜY (j)
t‚àí1) +
p"
END,0.3795811518324607,"2hxŒ≤‚àí1Œæ ;
/* remark 3.2 */"
END,0.38219895287958117,"17
Y (i)
t
‚ÜêY (i)
t‚àí1,k1+k2, for i = 1, 2, ..., ny;"
END,0.38481675392670156,18 end
END,0.387434554973822,"Remark 3. Generally speaking, Algorithm 1 consists of two nested loops. The inner loop solves
Y particles to equilibrium in each step of the outer loop, while the outer loop makes one iteration
every time, using the equilibrium Y particles. In the following are some additional explanation for
the Algorithm:"
END,0.3900523560209424,"1 line 4: at the beginning of the algorithm, we conduct k0 additional inner iterations for Y ,
where k0 may be a large number. This is because at the beginning the Y particles are far
from equilibrium. In later outer iterations, since each time the X particles only move for a
small distance, the Y particles are close to the equilibrium. Therefore, k1 and k2 need not
to be large."
END,0.39267015706806285,"2 line 17: In each inner loop, we conduct k1 + k2 inner iterations for the Y particles, and
collect those from the last k2 iterations. We use these k2n particles in the update of X
particles to approximate the distribution q[p]. We assume during the last k2 inner iterations
the Y particles are at equilibrium. One can take k2 to be 1 if ny is large enough, while
taking large k2 allows smaller number of Y particles."
EXAMPLES,0.39528795811518325,"5.1
EXAMPLES"
EXAMPLES,0.39790575916230364,"In this section, we apply the quasistatic Langevin gradient descent method to several problems."
-DIMENSIONAL GAME ON TORUS,0.4005235602094241,"1-dimensional game on torus
We Ô¨Årst consider a problem with x and y on the 1-dimensional
torus. SpeciÔ¨Åcally, we consider
K(x, y) = sin(2œÄx) sin(2œÄy),
where x, y ‚ààR/Z. It is easy to show that, with this K and a positive Œ≤, at the Nash equilibrium
of the problem (1) p and q are both uniform distributions. We take initial distributions p0 and q0"
-DIMENSIONAL GAME ON TORUS,0.4031413612565445,Published as a conference paper at ICLR 2022
-DIMENSIONAL GAME ON TORUS,0.40575916230366493,"Figure 1: Experiment results with K(x, y) = sin(2œÄx) sin(2œÄy). The three Ô¨Ågures show the KL
divergence of the empirical particle distribution to the uniform distribution of LGDA and QSLGD
at different Œ≤, Œ∑ and number of particles. Each point is an average of 5 experiments."
-DIMENSIONAL GAME ON TORUS,0.4083769633507853,"to be the uniform distribution on [0, 1/4]. Figure 1 shows the comparison of the quasistatic particle
method with LGDA for different Œ≤, step length, and number of particles. In the experiments, all
quasistatic methods take k0 = 1000 and k2 = 1, with different k1 shown in the legends. For
each experiment, we conduct 300000, 150000, 60000, 30000 outer iterations for LGDA, QS2, QS5,
and QS10, respectively. We take different different numbers of iterations for different methods in
the consideration of different number of inner iterations. The error is then computed after the last
iteration, measured by the KL divergence of the empirical distribution given by particles and the
uniform distribution (both in the forms of histograms with 10 equi-length bins). Each point in the
Ô¨Ågures is an average of 5 experiments."
-DIMENSIONAL GAME ON TORUS,0.4109947643979058,"Seen from the left Ô¨Ågure, the QSLGD has comparable performance than LGDA when Œ≤ is small,
in which case diffusion dominates the dynamics, while it performs much better than LGDA when
Œ≤ is large. We can also see better tolerance to large Œ≤ when more inner iterations are conducted.
This shows the advantage of the QSLGD over LGDA when the regularization stength is weak. The
middle Ô¨Ågures shows slightly better performance of the QSLGD when the step length Œ∑ (both Œ∑x
and Œ∑y) is small. However, when Œ∑ is big, LGDA tends to give smaller error. The results may be
caused by the instability of the inner loop when Œ∑ is big. It also guides us to pick small step length
when applying the proposed method. Finally, the right Ô¨Ågure compares the inÔ¨Çuence of the number
of particles when Œ≤ = 100 and Œ∑ = 0.01, in which case the two methods perform similarly. We can
see that the errors for both methods scale in a 1/n rate as the number of particles n changes."
-DIMENSIONAL GAME ON TORUS,0.41361256544502617,"Polynomial games on spheres
In the second example, we consider a polynomial games on sphere
similar to that studied in (Domingo-Enrich et al., 2020),"
-DIMENSIONAL GAME ON TORUS,0.4162303664921466,"K(x, y) = xT A0x + xT A1y + yT A2y + yT A3(x2),
(18)"
-DIMENSIONAL GAME ON TORUS,0.418848167539267,"where x, y ‚ààSd‚àí1 and (x2) is the element-wise square of x. In this problem, we consider the Nash
equilibrium of minp maxq E(p, q). Hence, we take big Œ≤ (small Œ≤‚àí1) and compare the Nikaido and
Isoda (NI) error of the solutions found by different methods (NikaidÀÜo & Isoda, 1955). The NI error
is deÔ¨Åned by
NI(p, q) :=
sup
q‚Ä≤‚ààP(‚Ñ¶)
E(pt, q‚Ä≤) ‚àí
inf
p‚Ä≤‚ààP(‚Ñ¶) E(p‚Ä≤, qt),"
-DIMENSIONAL GAME ON TORUS,0.4214659685863874,"which is also used in Theorem 6. The left panel of Figure 2 shows the NI errors of the solutions found
by different methods with different dimensions, we see comparable performance of the QSLGD with
LGDA."
-DIMENSIONAL GAME ON TORUS,0.42408376963350786,"GANs
Finally, we test our methods on the training of GANs. We train GANs to learn Gaussian
mixtures. The results after training are shown in the middle and right panels of Figure 2, where
Gaussian mixtures with 4 and 8 modes are learned, respectively. We train GANs with 5 generators
and 5 discriminators, and take k0 = 100, k1 = 5, k2 = 1. The results show that the mixture of
GANs trained by QSLGD can learn Gaussian mixtures successfully."
-DIMENSIONAL GAME ON TORUS,0.42670157068062825,"In the right panel of Figure 2, we show the results of learning high dimensional Gaussian mixtures.
In the d-dimensional experiment, the Gaussian mixture has d modes centered at e1, e2, ..., ed with"
-DIMENSIONAL GAME ON TORUS,0.4293193717277487,Published as a conference paper at ICLR 2022
-DIMENSIONAL GAME ON TORUS,0.4319371727748691,"Figure 2: (Left) The NI error of the solutions found by different algorithms for the polynomial game
(18), at different dimensions. Each point is an average of 10 experiments. (Middle left, Middle
right) Generation results of mixture of GANs. The blue points are sampled from groundtruth dis-
tribution, while the green points are generated by the a mixture of generators. (Right) The average
squared distance of generated data to closest mode center for learning high dimensional Gaussian
mixtures."
-DIMENSIONAL GAME ON TORUS,0.43455497382198954,"standard deviation 0.1. Here, ei is the i-th unit vector in the standard basis of Rd. Model and
algorithm with same hyper-parameters as above are used. In the Ô¨Ågure, we measure the average
squared distance of the generated data to the closest mode center along the training process. The
Ô¨Ågure shows that the average squared distance can be reduced to 0.3 ‚àí0.5 after 10000 iterations.
While the ideal value is 0.1, the current results still show that the learnt distribution concentrates at
the mode centers. Better results may be obtained after longer training or careful hyper-parameter
tuning."
DISCUSSION,0.43717277486910994,"6
DISCUSSION"
DISCUSSION,0.4397905759162304,"In this paper, we study the quasistatic Wasserstein gradient Ô¨Çow for the mixed Nash equilibrium
problem. We theoretically show the convergence of the continuous dynamics to the unique Nash
equilibrium. Then, a quasistatic particle method is proposed by discretizing the continuous dynam-
ics. The particle method consists of two nested loops, and conduct sufÔ¨Åcient inner loop in each step
of the outer loop. Numerical experiments show the effectiveness of the method. Comparison with
LGDA shows the proposed method has advantage over LGDA when Œ≤ is large (which is usually the
case of interest), and performs as good as LGDA in most other cases."
DISCUSSION,0.4424083769633508,"Theoretical extensions are possible. For example, strong convergence results may be established by
similar approaches taken in (Feng & Li, 2020). We leave this as future work."
DISCUSSION,0.44502617801047123,"In practice, the idea of nested loops is not new for minimax optimization problems. It is already
discussed and utilized in the earliest works for GANs (Goodfellow et al., 2014a), and Wasserstein
GANs (Arjovsky et al., 2017). In those works, the discriminator is updated for several steps each
time the generator is updated. Our work is different from these works because we consider mixed
Nash equilibrium and hence our method is particle based, while their method searches for pure Nash
equilibrium."
DISCUSSION,0.4476439790575916,"Finally, though particle methods Ô¨Ånding mixed Nash equilibria have stronger theoretical guarantees,
applying these methods to the training of GANs faces the problem of computational cost. With both
the generator and discriminator being large neural networks, training mixture of GANs with many
generators and discriminators imposes formidable computational cost. Developing more efÔ¨Åcient
particle methods for GANs is an important future work."
REFERENCES,0.450261780104712,REFERENCES
REFERENCES,0.45287958115183247,"Dyego Ara¬¥ujo, Roberto I Oliveira, and Daniel Yukimura. A mean-Ô¨Åeld limit for certain deep neural
networks. arXiv preprint arXiv:1906.00193, 2019."
REFERENCES,0.45549738219895286,"Michael Arbel, Arthur Gretton, Wuchen Li, and Guido Mont¬¥ufar. Kernelized wasserstein natural
gradient. arXiv preprint arXiv:1910.09652, 2019."
REFERENCES,0.4581151832460733,Published as a conference paper at ICLR 2022
REFERENCES,0.4607329842931937,"Martin Arjovsky, Soumith Chintala, and L¬¥eon Bottou. Wasserstein generative adversarial networks.
In International conference on machine learning, pp. 214‚Äì223. PMLR, 2017."
REFERENCES,0.46335078534031415,"Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi Zhang. Generalization and equilibrium
in generative adversarial nets (gans). In International Conference on Machine Learning, pp. 224‚Äì
232. PMLR, 2017."
REFERENCES,0.46596858638743455,"Lucian Busoniu, Robert Babuska, and Bart De Schutter. A comprehensive survey of multiagent rein-
forcement learning. IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications
and Reviews), 38(2):156‚Äì172, 2008."
REFERENCES,0.468586387434555,"Lenaic Chizat and Francis Bach.
On the global convergence of gradient descent for over-
parameterized models using optimal transport. arXiv preprint arXiv:1805.09545, 2018."
REFERENCES,0.4712041884816754,"Carles Domingo-Enrich and Joan Bruna. Simultaneous transport evolution for minimax equilibria
on measures. arXiv preprint, https://arxiv.org/pdf/2202.06460.pdf, 2022."
REFERENCES,0.4738219895287958,"Carles Domingo-Enrich, Samy Jelassi, Arthur Mensch, Grant Rotskoff, and Joan Bruna. A mean-
Ô¨Åeld analysis of two-player zero-sum games. arXiv preprint arXiv:2002.06277, 2020."
REFERENCES,0.47643979057591623,"Weinan E, Chao Ma, and Lei Wu. Machine learning from a continuous viewpoint, i. Science China
Mathematics, 63(11):2233‚Äì2266, 2020."
REFERENCES,0.4790575916230366,"Andreas Eberle, Arnaud Guillin, and Raphael Zimmer. Quantitative harris-type theorems for dif-
fusions and mckean‚Äìvlasov processes. Transactions of the American Mathematical Society, 371
(10):7135‚Äì7173, 2019."
REFERENCES,0.4816753926701571,"Qi Feng and Wuchen Li.
Entropy dissipation via information gamma calculus: Non-reversible
stochastic differential equations. arXiv preprint arXiv:2011.08058, 2020."
REFERENCES,0.48429319371727747,"Fei Gao, Yue Yang, Jun Wang, Jinping Sun, Erfu Yang, and Huiyu Zhou. A deep convolutional
generative adversarial networks (dcgans)-based semi-supervised method for object recognition in
synthetic aperture radar (sar) images. Remote Sensing, 10(6):846, 2018."
REFERENCES,0.4869109947643979,"Irving L Glicksberg. A further generalization of the kakutani Ô¨Åxed point theorem, with application
to nash equilibrium points. Proceedings of the American Mathematical Society, 3(1):170‚Äì174,
1952."
REFERENCES,0.4895287958115183,"Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information
processing systems, 27, 2014a."
REFERENCES,0.49214659685863876,"Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. arXiv preprint arXiv:1412.6572, 2014b."
REFERENCES,0.49476439790575916,"Paulina Grnarova, KÔ¨År Y Levy, Aurelien Lucchi, Thomas Hofmann, and Andreas Krause. An online
learning approach to generative adversarial networks. arXiv preprint arXiv:1706.03269, 2017."
REFERENCES,0.4973821989528796,"Ya-Ping Hsieh, Chen Liu, and Volkan Cevher. Finding mixed nash equilibria of generative ad-
versarial networks. In International Conference on Machine Learning, pp. 2810‚Äì2819. PMLR,
2019."
REFERENCES,0.5,"Richard Jordan, David Kinderlehrer, and Felix Otto. The variational formulation of the fokker‚Äì
planck equation. SIAM journal on mathematical analysis, 29(1):1‚Äì17, 1998."
REFERENCES,0.5026178010471204,"Alex Tong Lin, Samy Wu Fung, Wuchen Li, Levon Nurbekyan, and Stanley J Osher. Alternating the
population and control neural networks to solve high-dimensional stochastic mean-Ô¨Åeld games.
Proceedings of the National Academy of Sciences, 118(31), 2021a."
REFERENCES,0.5052356020942408,"Alex Tong Lin, Wuchen Li, Stanley Osher, and Guido Mont¬¥ufar. Wasserstein proximal of gans.
arXiv preprint arXiv:2102.06862, 2021b."
REFERENCES,0.5078534031413613,"Yiping Lu, Chao Ma, Yulong Lu, Jianfeng Lu, and Lexing Ying. A mean Ô¨Åeld analysis of deep
resnet and beyond: Towards provably optimization via overparameterization from depth. In In-
ternational Conference on Machine Learning, pp. 6426‚Äì6436. PMLR, 2020."
REFERENCES,0.5104712041884817,Published as a conference paper at ICLR 2022
REFERENCES,0.5130890052356021,"Song Mei, Andrea Montanari, and Phan-Minh Nguyen. A mean Ô¨Åeld view of the landscape of two-
layer neural networks. Proceedings of the National Academy of Sciences, 115(33):E7665‚ÄìE7671,
2018."
REFERENCES,0.5157068062827225,"Marc Mezard and Andrea Montanari. Information, physics, and computation. Oxford University
Press, 2009."
REFERENCES,0.518324607329843,"Oskar Morgenstern and John Von Neumann. Theory of games and economic behavior. Princeton
university press, 1953."
REFERENCES,0.5209424083769634,"Phan-Minh Nguyen. Mean Ô¨Åeld limit of the learning dynamics of multilayer neural networks. arXiv
preprint arXiv:1902.02880, 2019."
REFERENCES,0.5235602094240838,"Hukukane NikaidÀÜo and Kazuo Isoda. Note on non-cooperative convex games. PaciÔ¨Åc Journal of
Mathematics, 5(S1):807‚Äì815, 1955."
REFERENCES,0.5261780104712042,"Grant Rotskoff, Samy Jelassi, Joan Bruna, and Eric Vanden-Eijnden. Global convergence of neuron
birth-death dynamics. arXiv preprint arXiv:1902.01843, 2019."
REFERENCES,0.5287958115183246,"Grant M Rotskoff and Eric Vanden-Eijnden.
Neural networks as interacting particle systems:
Asymptotic convexity of the loss landscape and universal scaling of the approximation error.
stat, 1050:22, 2018."
REFERENCES,0.5314136125654451,"Justin Sirignano and Konstantinos Spiliopoulos. Mean Ô¨Åeld analysis of neural networks: A central
limit theorem. Stochastic Processes and their Applications, 130(3):1820‚Äì1852, 2020."
REFERENCES,0.5340314136125655,"Justin Sirignano and Konstantinos Spiliopoulos. Mean Ô¨Åeld analysis of deep neural networks. Math-
ematics of Operations Research, 2021."
REFERENCES,0.5366492146596858,"Yifei Wang and Wuchen Li.
Accelerated information gradient Ô¨Çow.
arXiv preprint
arXiv:1909.02102, 2019."
REFERENCES,0.5392670157068062,"Stephan Wojtowytsch et al.
On the banach spaces associated with multi-layer relu networks:
Function representation, approximation theory and gradient descent dynamics. arXiv preprint
arXiv:2007.15623, 2020."
REFERENCES,0.5418848167539267,Published as a conference paper at ICLR 2022
REFERENCES,0.5445026178010471,"A
PROOFS FOR SECTION 3"
REFERENCES,0.5471204188481675,"A.1
PROOF OF THEOREM 2"
REFERENCES,0.5497382198952879,"Note that the free energy in (5) can be written as
Z"
REFERENCES,0.5523560209424084,"‚Ñ¶
V (y, pt)q(y)dy ‚àíŒ≤‚àí1S(q),
(19)"
REFERENCES,0.5549738219895288,"in which the Ô¨Årst term is linear with respect to q. Hence, a calculation with Lagrange multiplier
shows (19) has a unique minimizer q[pt] with the form of a Gibbs distribution (e.g. see Chapter 4
of (Mezard & Montanari, 2009)):"
REFERENCES,0.5575916230366492,"q[pt](y) =
1
Zq(pt) exp(Œ≤V (y, pt)).
(20)"
REFERENCES,0.5602094240837696,"Next, we consider the free energy for pt when q is at the equilibrium. By (19) we have"
REFERENCES,0.56282722513089,"E(pt, q[pt]) =
Z"
REFERENCES,0.5654450261780105,"‚Ñ¶
V (y, pt)q[pt](y)dy"
REFERENCES,0.5680628272251309,"=
1
Zq(pt) Z"
REFERENCES,0.5706806282722513,"‚Ñ¶
V (y, pt) exp(Œ≤V (y, pt))dy.
(21)"
REFERENCES,0.5732984293193717,"On the other hand, we have"
REFERENCES,0.5759162303664922,"Œ≤‚àí1S(q[pt]) = Œ≤‚àí1
Z ‚Ñ¶"
REFERENCES,0.5785340314136126,"1
Zq(pt) exp(Œ≤V (y, pt)) log

1
Zq(pt) exp(Œ≤V (y, pt))

dy"
REFERENCES,0.581151832460733,"= Œ≤‚àí1
Z ‚Ñ¶"
REFERENCES,0.5837696335078534,"1
Zq(pt) exp(Œ≤V (y, pt)) (Œ≤V (y, pt) ‚àílog Zq(pt)) dy"
REFERENCES,0.5863874345549738,"=
1
Zq(pt) Z"
REFERENCES,0.5890052356020943,"‚Ñ¶
V (y, pt) exp(Œ≤V (y, pt))dy ‚àíŒ≤‚àí1 log Zq(pt).
(22)"
REFERENCES,0.5916230366492147,"Combining (21) and (22), we obtain
E(pt, q[pt]) + Œ≤‚àí1S(pt) ‚àíŒ≤‚àí1S(q[pt]) = Œ≤‚àí1 log Zq(pt) + Œ≤‚àí1S(pt).
Therefore, the dynamics of pt is the Wasserstein gradient descent Ô¨Çow minimizing the free energy
Œ≤‚àí1 log Zq(pt) + Œ≤‚àí1S(pt), given by"
REFERENCES,0.5942408376963351,"‚àÇtpt = ‚àá¬∑

pt‚àá
Œ¥Œ≤‚àí1 log Zq(pt)"
REFERENCES,0.5968586387434555,"Œ¥pt
+ Œ≤‚àí1 log pt 
."
REFERENCES,0.599476439790576,This Ô¨Ånishes the proof.
REFERENCES,0.6020942408376964,"A.2
PROOF OF PROPOSITION 3"
REFERENCES,0.6047120418848168,"Since S(p) is strongly convex, it sufÔ¨Åces to show log Zq(p) is convex. Recall that"
REFERENCES,0.6073298429319371,"log Zq(p) = log
Z"
REFERENCES,0.6099476439790575,"‚Ñ¶
exp(Œ≤V (y, p))dy

."
REFERENCES,0.612565445026178,"Note that V (¬∑, p) =
R
K(x, ¬∑)p(x)dx is linear with respect to p, we have
V (¬∑, Œªp1 + (1 ‚àíŒª)p2) = ŒªV (¬∑, p1) + (1 ‚àíŒª)V (¬∑, p2).
Hence,"
REFERENCES,0.6151832460732984,"log Zq(Œªp1 + (1 ‚àíŒª)p2) = log
Z"
REFERENCES,0.6178010471204188,"‚Ñ¶
exp(Œ≤V (y, Œªp1 + (1 ‚àíŒª)p2))dy
"
REFERENCES,0.6204188481675392,"= log
Z"
REFERENCES,0.6230366492146597,"‚Ñ¶
exp(Œ≤ŒªV (y, p1)) ¬∑ exp(Œ≤(1 ‚àíŒª)V (y, p2))
 ‚â§log Z"
REFERENCES,0.6256544502617801,"‚Ñ¶
exp(Œ≤V (y, p1))
Œª Z"
REFERENCES,0.6282722513089005,"‚Ñ¶
exp(Œ≤V (y, p2))
1‚àíŒª!"
REFERENCES,0.6308900523560209,"= Œª log Zq(p1) + (1 ‚àíŒª) log Zq(p2).
(23)
The second last line is given by the H¬®older inequality."
REFERENCES,0.6335078534031413,Published as a conference paper at ICLR 2022
REFERENCES,0.6361256544502618,"A.3
PROOF OF PROPOSITION 4"
REFERENCES,0.6387434554973822,The proposition follows from the following derivations.
REFERENCES,0.6413612565445026,Œ¥Œ≤‚àí1 log Zq(p)
REFERENCES,0.643979057591623,"Œ¥p
= Œ≤‚àí1
1
Zq(p)
Œ¥Zq(p) Œ¥p"
REFERENCES,0.6465968586387435,"= Œ≤‚àí1
1
Zq(p) Z"
REFERENCES,0.6492146596858639,"‚Ñ¶
exp(Œ≤V (y, p))Œ≤K(x, y)dy =
Z"
REFERENCES,0.6518324607329843,"‚Ñ¶
K(x, y)exp(Œ≤V (y, p))"
REFERENCES,0.6544502617801047,"Zq(p)
dy =
Z"
REFERENCES,0.6570680628272252,"‚Ñ¶
K(x, y)q[p](y)dy"
REFERENCES,0.6596858638743456,"= U(x, q[p]).
(24)"
REFERENCES,0.662303664921466,"B
PROOF OF THEOREM 5"
REFERENCES,0.6649214659685864,"In this section, we prove our main theorem. The proof will follow the sketch given in Section 4.
Given the assumptions on K and the conclusions of Lemma 1 and Lemma 2, Lemma 3 is a direct
result of Lemma 10.12 in (Mei et al., 2018), which we will ignore the proof. In the following,
we show Lemma 1 and Lemma 2. Some techniques in the proof come from (Jordan et al., 1998)
and (Mei et al., 2018)."
REFERENCES,0.6675392670157068,"B.1
PROOF OF LEMMA 1"
REFERENCES,0.6701570680628273,"Our proof follows the proof of Proposition 4.1 in (Jordan et al., 1998). First, we show the existence
of the minimizer for Fp,Œ≤. To see this, note that K is bounded on ‚Ñ¶. Assume CK is a constant such
that |K(x, y)| ‚â§CK for any x, y ‚àà‚Ñ¶. Then, we have"
REFERENCES,0.6727748691099477,"Ep,Œ≤(p) =
Z"
REFERENCES,0.675392670157068,"‚Ñ¶
U(x, q[p])p(x)dx =
Z"
REFERENCES,0.6780104712041884,"‚Ñ¶√ó‚Ñ¶
K(x, y)q[p](y)p(x)dxdy ‚â•‚àíCK, and"
REFERENCES,0.680628272251309,"S(p) =
Z"
REFERENCES,0.6832460732984293,"‚Ñ¶
p(x) log p(x)dx ‚â•
Z ‚Ñ¶
‚àí1"
REFERENCES,0.6858638743455497,edx = ‚àí1 e.
REFERENCES,0.6884816753926701,"This means Fp,Œ≤(p) is lower bounded, i.e. infp Fp,Œ≤(p) > ‚àí‚àû. Hence, we can Ô¨Ånd a sequence
(pk)‚àû
k=1 such that
lim
k‚Üí‚àûFp,Œ≤(pk) = inf
p Fp,Œ≤(p)."
REFERENCES,0.6910994764397905,"Similar to (Jordan et al., 1998), we can show boundedness of {
R
max{pk log pk, 0}dx} and
{
R
p2
kdx}, which implies that (pk) is uniformly integrable, and thus there exists a weakly convergent
subsequence of (pk)."
REFERENCES,0.693717277486911,"Without loss of generality, assume pk ‚áÄp‚àóin L1(‚Ñ¶). Then we need to show p‚àóis a minimizer of
Fp,Œ≤. By (Jordan et al., 1998), the entropy term satisÔ¨Åes"
REFERENCES,0.6963350785340314,"S(p‚àó) ‚â§lim inf
k‚Üí‚àûS(pk)."
REFERENCES,0.6989528795811518,"Hence, the conclusion follows if Ep,Œ≤ is continuous in the weak topology. To show this, Ô¨Årst note
that for any p ‚ààP(‚Ñ¶), we have
Z"
REFERENCES,0.7015706806282722,"‚Ñ¶
exp(Œ≤V (y, p))dy ‚â•e‚àíŒ≤CK."
REFERENCES,0.7041884816753927,"Because the function log(x) is 1/c-Lipschitz for x ‚àà[c, ‚àû], for any pk we have"
REFERENCES,0.7068062827225131,"Œ≤‚àí1 log Zq(pk) ‚àíŒ≤‚àí1 log Zq(p‚àó)
 ‚â§Œ≤‚àí1eŒ≤CK Z ‚Ñ¶"
REFERENCES,0.7094240837696335,"
eŒ≤V (y,pk) ‚àíeŒ≤V (y,p‚àó)
dy
 ."
REFERENCES,0.7120418848167539,Published as a conference paper at ICLR 2022
REFERENCES,0.7146596858638743,"By similar boundedness argument, we have Z ‚Ñ¶"
REFERENCES,0.7172774869109948,"
eŒ≤V (y,pk) ‚àíeŒ≤V (y,p‚àó)
dy
 ‚â§
Z ‚Ñ¶"
REFERENCES,0.7198952879581152,"eŒ≤V (y,pk) ‚àíeŒ≤V (y,p‚àó) dy"
REFERENCES,0.7225130890052356,"‚â§eŒ≤CK
Z"
REFERENCES,0.725130890052356,"‚Ñ¶
Œ≤ |V (y, pk) ‚àíV (y, p‚àó)| dy"
REFERENCES,0.7277486910994765,"‚â§Œ≤eŒ≤CK
Z ‚Ñ¶  Z"
REFERENCES,0.7303664921465969,"‚Ñ¶
K(x, y)(pk(x) ‚àíp‚àó(x))dx
 dy"
REFERENCES,0.7329842931937173,"Totally we have
Œ≤‚àí1 log Zq(pk) ‚àíŒ≤‚àí1 log Zq(p‚àó)
 ‚â§e2Œ≤CK
Z ‚Ñ¶  Z"
REFERENCES,0.7356020942408377,"‚Ñ¶
K(x, y)(pk(x) ‚àíp‚àó(x))dx
 dy."
REFERENCES,0.7382198952879581,"Since K is bounded and Lipschitz, it is easy to show that"
REFERENCES,0.7408376963350786,"lim
k‚Üí‚àû Z ‚Ñ¶  Z"
REFERENCES,0.743455497382199,"‚Ñ¶
K(x, y)(pk(x) ‚àíp‚àó(x))dx
 dy = 0."
REFERENCES,0.7460732984293194,"Therefore, we have
Fp,Œ≤(p‚àó) ‚â§lim inf
k‚Üí‚àûFp,Œ≤(pk) = inf
p Fp,Œ≤(p),"
REFERENCES,0.7486910994764397,"and thus Fp,Œ≤(p‚àó) = infp Fp,Œ≤(p)."
REFERENCES,0.7513089005235603,"Next, we show p‚àósatisÔ¨Åes the Ô¨Åxed point condition p‚àó= 1"
REFERENCES,0.7539267015706806,"Z exp (‚àíŒ≤Œ®(x, p‚àó)).
(25)"
REFERENCES,0.756544502617801,"This follows the proof of Lemma 10.3 in (Mei et al., 2018), by Ô¨Årst showing p‚àóhas full support on
‚Ñ¶, and then showing
Œ®(x, p‚àó) + Œ≤‚àí1 log p‚àó(x)
is a constant."
REFERENCES,0.7591623036649214,"Finally, we show p‚àóis unique following Lemma 10.4 of (Mei et al., 2018). SpeciÔ¨Åcally, we show
the Boltzmann Ô¨Åxed point problem (25) only has one solution by the convexity of Fp,Œ≤. Assume
(25) has two different solutions p1 and p2, i.e."
REFERENCES,0.7617801047120419,"p1 =
1
Z(p1) exp (‚àíŒ≤Œ®(x, p1)), p2 =
1
Z(p2) exp (‚àíŒ≤Œ®(x, p2))."
REFERENCES,0.7643979057591623,"Then, we have
log Z(p1) = ‚àíŒ≤Œ®(x, p1) ‚àílog p1(x),
log Z(p2) = ‚àíŒ≤Œ®(x, p2) ‚àílog p2(x).
Taking difference of the above two equations, and integrating with p1 ‚àíp2, we have 0 =
Z"
REFERENCES,0.7670157068062827,"‚Ñ¶
(log Z(p1) ‚àílog Z(p2))(p1(x) ‚àíp2(x))dx"
REFERENCES,0.7696335078534031,"= ‚àíŒ≤
Z"
REFERENCES,0.7722513089005235,"‚Ñ¶
(Œ®(x, p1) ‚àíŒ®(x, p2))(p1(x) ‚àíp2(x))dx ‚àí
Z"
REFERENCES,0.774869109947644,"‚Ñ¶
(log p1(x) ‚àílog p2(x))(p1(x) ‚àíp2(x))dx."
REFERENCES,0.7774869109947644,"(26)
By the monotonicity of log x, the second term of (26) is non-negative, and takes zero only if p1 = p2.
For the Ô¨Årst term, recall that we have proven in Proposition 3 that Ep,Œ≤ is convex, we then have"
REFERENCES,0.7801047120418848,"Ep,Œ≤(p1) ‚â•Ep,Œ≤(p2) +
Z"
REFERENCES,0.7827225130890052,"‚Ñ¶
Œ®(x, p2)(p1(x) ‚àíp2(x))dx,"
REFERENCES,0.7853403141361257,"and
Ep,Œ≤(p2) ‚â•Ep,Œ≤(p1) +
Z"
REFERENCES,0.7879581151832461,"‚Ñ¶
Œ®(x, p1)(p2(x) ‚àíp1(x))dx."
REFERENCES,0.7905759162303665,"Taking difference of the two equations gives
Z"
REFERENCES,0.7931937172774869,"‚Ñ¶
(Œ®(x, p1) ‚àíŒ®(x, p2))(p1(x) ‚àíp2(x))dx ‚â•0."
REFERENCES,0.7958115183246073,"Therefore, (26) holds if and only if p1 = p2. This Ô¨Ånishes the proof of uniqueness of p‚àó, and also
completes the proof of Lemma 1."
REFERENCES,0.7984293193717278,Published as a conference paper at ICLR 2022
REFERENCES,0.8010471204188482,"B.2
PROOF OF LEMMA 2"
REFERENCES,0.8036649214659686,"We show the existence of the weak solution using the JKO scheme used in (Jordan et al., 1998). Let
dist(¬∑, ¬∑) be the distance metric on ‚Ñ¶. Then, the 2-Wasserstein distance is on P(‚Ñ¶) is deÔ¨Åned as"
REFERENCES,0.806282722513089,"W2(p1, p2) :=

inf
Œ≥‚ààŒì(p1,p2) Z"
REFERENCES,0.8089005235602095,"‚Ñ¶√ó‚Ñ¶
dist(x1, x2)2dŒ≥(x1, x2)
1/2
,"
REFERENCES,0.8115183246073299,"where Œì(p1, p2) contains all couplings of p1 and p2, i.e. probability distributions on ‚Ñ¶√ó‚Ñ¶with Ô¨Årst
and second marginals being p1 and p2, respectively. Then, for any h > 0, we consider the sequence
of probability distributions (ph
k)‚àû
k=0 obtained by the following iteration scheme:"
REFERENCES,0.8141361256544503,"ph
0 = p0,
ph
k = arg min
p‚ààP(‚Ñ¶) 1"
REFERENCES,0.8167539267015707,"2W 2
2 (p, ph
k‚àí1) + hFp,Œ≤(p)

,
k > 0,
(27)"
REFERENCES,0.819371727748691,"By similar argument of Proposition 4.1 in (Jordan et al., 1998), each minimization problem in (27)
has a unique solution. Hence, (ph
k)‚àû
k=0 is uniquely deÔ¨Åned. Let ph
t be the piecewise constant inter-
polation of (ph
k) on t, i.e.
ph
t = ph
k, for t ‚àà[kh, (k + 1)h),"
REFERENCES,0.8219895287958116,"for k = 0, 1, 2, .... We now show that there exists a subsequence of hn ‚Üí0 and a pt such that
phn
t
‚áÄpt on (0, T) √ó ‚Ñ¶for any T > 0 and pt is a weak solution of (8). This is proven in two steps:"
REFERENCES,0.824607329842932,"1. The existence of weakly convergence subsequence, and"
PH,0.8272251308900523,"2. ph
t approximately satisÔ¨Åes the equation (8)."
PH,0.8298429319371727,"For the Ô¨Årst point, we show uniform integrability by showing
Z"
PH,0.8324607329842932,"‚Ñ¶
‚à•x‚à•2ph
k(x)dx ‚â§C
(28) and
Z"
PH,0.8350785340314136,"‚Ñ¶
max{ph
k log ph
k, 0}dx ‚â§C
(29)"
PH,0.837696335078534,"for any h and k ‚â•0, and an absolute constant C. Equation (28) follows directly from the compact-
ness of ‚Ñ¶. For (29), note that for any h and k ‚â•0 we have"
PH,0.8403141361256544,"1
2W 2
2 (ph
k, ph
k‚àí1) + hFp,Œ≤(ph
k) ‚â§hFp,Œ≤(ph
k‚àí1),"
PH,0.8429319371727748,"which implies
Fp,Œ≤(ph
k) ‚â§Fp,Œ≤(ph
k‚àí1)."
PH,0.8455497382198953,"Therefore,
Z"
PH,0.8481675392670157,"‚Ñ¶
max{ph
k log ph
k, 0}dx ‚â§S(ph
k) +
Z ‚Ñ¶"
PH,0.8507853403141361,"min{ph
k log ph
k, 0}
 dx"
PH,0.8534031413612565,"‚â§S(ph
k) +
Z ‚Ñ¶"
EDX,0.856020942408377,"1
edx"
EDX,0.8586387434554974,"‚â§Fp,Œ≤(ph
k) ‚àíEp,Œ≤(ph
k) +
Z ‚Ñ¶"
EDX,0.8612565445026178,"1
edx"
EDX,0.8638743455497382,"‚â§Fp,Œ≤(ph
0) ‚àíEp,Œ≤(ph
k) +
Z ‚Ñ¶"
EDX,0.8664921465968587,"1
edx."
EDX,0.8691099476439791,"Since K is bounded, Ep,Œ≤ is bounded, and thus the above expression is also bounded, which gives
(29). With (28) and (29), there exists pt(x) and a sequence (hn) with hn ‚Üí0, such that phn
t
‚áÄpt
in L1((0, T) √ó ‚Ñ¶) for any T > 0. Moreover, pt ‚ààP(‚Ñ¶) for almost every T. By changing pt on
a zero measure set of t, we can assume pt ‚ààP(‚Ñ¶) for any t ‚àà(0, ‚àû). With the same analysis
as (Jordan et al., 1998), the weak convergence can happen for any t, i.e. phn
t
‚áÄpt in L1(‚Ñ¶) for any
t ‚àà(0, ‚àû)."
EDX,0.8717277486910995,Published as a conference paper at ICLR 2022
EDX,0.8743455497382199,"For the second point, similar to (Jordan et al., 1998), consider any vector Ô¨Åeld Œæ ‚ààC‚àû(‚Ñ¶, ‚Ñ¶) and
the corresponding Ô¨Çux Œ¶œÑ given by"
EDX,0.8769633507853403,"‚àÇœÑŒ¶œÑ = Œæ(Œ¶œÑ), Œ¶0(x) = x,"
EDX,0.8795811518324608,"and let qœÑ = Œ¶œÑ‚ôØph
k, then we have 1
œÑ 1"
EDX,0.8821989528795812,"2W 2
2 (ph
k‚àí1, qœÑ) + hFp,Œ≤(qœÑ)

‚àí
1"
EDX,0.8848167539267016,"2W 2
2 (ph
k‚àí1, ph
k) + hFp,Œ≤(ph
k)

‚â•0
(30)"
EDX,0.887434554973822,"for any œÑ > 0. We need to study the limit when œÑ ‚Üí0+. By the calculation in (Jordan et al., 1998)
we have"
EDX,0.8900523560209425,"lim sup
œÑ‚Üí0+
1
œÑ 1"
EDX,0.8926701570680629,"2W 2
2 (ph
k‚àí1, qœÑ) ‚àí1"
EDX,0.8952879581151832,"2W 2
2 (ph
k‚àí1, p2
k)

‚â§
Z"
EDX,0.8979057591623036,"‚Ñ¶√ó‚Ñ¶
(y ‚àíx)Œæ(y)dŒ≥(x, y),
(31)"
EDX,0.900523560209424,"and
d
dœÑ S(qœÑ)

œÑ=0
= ‚àí
Z"
EDX,0.9031413612565445,"‚Ñ¶
ph
k‚àá¬∑ Œædx,
(32)"
EDX,0.9057591623036649,"where the Œ≥ in (31) is the optimal transport between ph
k‚àí1 and ph
k. For the Ep,Œ≤ term, we have"
EDX,0.9083769633507853,"lim
œÑ‚Üí0+
1
œÑ
 
Ep,Œ≤(qœÑ) ‚àíEp,Œ≤(ph
k)

= lim
œÑ‚Üí0+
1
Œ≤œÑ log
 R"
EDX,0.9109947643979057,"‚Ñ¶exp(Œ≤V (y, qœÑ))dy
R"
EDX,0.9136125654450262,"‚Ñ¶exp(Œ≤V (y, ph
k))dy "
EDX,0.9162303664921466,"= lim
œÑ‚Üí0+
1
Œ≤œÑ  R"
EDX,0.918848167539267,"‚Ñ¶exp(Œ≤V (y, qœÑ))dy
R"
EDX,0.9214659685863874,"‚Ñ¶exp(Œ≤V (y, ph
k))dy ‚àí1
"
EDX,0.9240837696335078,"=
1
Œ≤Zq(ph
k) lim
œÑ‚Üí0+
1
œÑ Z"
EDX,0.9267015706806283,"‚Ñ¶
(exp(Œ≤V (y, qœÑ)) ‚àíexp(Œ≤V (y, ph
k)))dy
"
EDX,0.9293193717277487,"=
1
Œ≤Zq(ph
k) Z"
EDX,0.9319371727748691,"‚Ñ¶
exp(Œ≤V (y, ph
k))Œ≤
Z"
EDX,0.9345549738219895,"‚Ñ¶
‚àáxK(x, y) ¬∑ Œæ(x)ph
k(x)dx

dy =
Z"
EDX,0.93717277486911,"‚Ñ¶
‚àáxŒ®(x, ph
k) ¬∑ Œæ(x)ph
k(x)dx.
(33)"
EDX,0.9397905759162304,"Combining the above result with (31) and (32), taking both Œæ and ‚àíŒæ, we get from (30) that
Z"
EDX,0.9424083769633508,"‚Ñ¶√ó‚Ñ¶
(y ‚àíx)Œæ(y)dŒ≥(x, y) + h
Z"
EDX,0.9450261780104712,"‚Ñ¶
‚àáxŒ®(x, ph
k) ¬∑ Œæ(x)ph
k(x)dx ‚àíh Œ≤ Z"
EDX,0.9476439790575916,"‚Ñ¶
ph
k‚àá¬∑ Œædx = 0
(34)"
EDX,0.9502617801047121,"for any Œæ ‚ààC‚àû(‚Ñ¶, ‚Ñ¶). Then, following the derivation in (Jordan et al., 1998) (proof of Proposition
5.1), as well as the following control N
X"
EDX,0.9528795811518325,"k=1
W 2
2 (ph
k‚àí1, ph
k) ‚â§Ch"
EDX,0.9554973821989529,"for any N that satisÔ¨Åes Nh ‚â§T for some Ô¨Åxed T, we can integrate (34) over t by viewing ph
k as ph
t
at appropriate t, and take the limit hn ‚Üí0 and show that pt is a weak solution. During the limit, we
need to pay special attention to the second term, i.e. the following limit, which is not dealt with in
the reference:"
EDX,0.9581151832460733,"lim
n‚Üí‚àû Z T 0 Z"
EDX,0.9607329842931938,"‚Ñ¶
‚àáxŒ®(x, phn
t ) ¬∑ Œæ(x)phn
t (x)dx =
Z T 0 Z"
EDX,0.9633507853403142,"‚Ñ¶
‚àáxŒ®(x, pt) ¬∑ Œæ(x)pt(x)dx.
(35)"
EDX,0.9659685863874345,"We prove this by showing ‚àáxŒ®(x, phn
t ) converges to ‚àáxŒ®(x, pt) uniformly."
EDX,0.9685863874345549,"For any Ô¨Åxed t, recall that we have
phn
t
‚áÄpt.
Therefore, for any y ‚àà‚Ñ¶, we have
Z"
EDX,0.9712041884816754,"‚Ñ¶
K(x, y)phn
t (x)dx ‚Üí
Z"
EDX,0.9738219895287958,"‚Ñ¶
K(x, y)pt(x)dx."
EDX,0.9764397905759162,Published as a conference paper at ICLR 2022
EDX,0.9790575916230366,"Note that
R"
EDX,0.981675392670157,"‚Ñ¶K(x, y)p(x)dx is uniformly continuous with respect to y for any p ‚ààP(‚Ñ¶), we can
conclude that
R"
EDX,0.9842931937172775,"‚Ñ¶K(x, y)phn
t (x)dx converges to
R"
EDX,0.9869109947643979,"‚Ñ¶K(x, y)pt(x)dx uniformly over y. Hence, we
have Zq(phn
t ) ‚ÜíZq(pt), and q[phn
t ](y) ‚Üíq[pt](y) uniformly. This further implies that"
EDX,0.9895287958115183,"‚àáxŒ®(x, phn
t ) =
Z"
EDX,0.9921465968586387,"‚Ñ¶
‚àáxK(x, y)q[phn
t ](y)dy"
EDX,0.9947643979057592,"converges to ‚àáxŒ®(x, pt) for all x ‚àà‚Ñ¶. This Ô¨Ånishes the proof of (35), and also completes the proof
that pt is a weak solution of of equation (8)."
EDX,0.9973821989528796,"Now we have proven the existence of the weak solution. The regularity and uniqueness of the
solution follows the same analysis of Proposition 5.1 in (Jordan et al., 1998)."
