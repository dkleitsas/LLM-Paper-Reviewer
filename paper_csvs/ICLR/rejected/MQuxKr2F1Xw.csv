Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.004878048780487805,"Deep learning-based Multi-Task Classiﬁcation (MTC) is widely used in applica-
tions like facial attribute and healthcare that warrant strong privacy guarantees. In
this work, we aim to protect sensitive information in the inference phase of MTC
and propose a novel Multi-Trigger-Key (MTK) framework to achieve the privacy-
preserving objective. MTK associates each secured task in the multi-task dataset
with a speciﬁcally designed trigger-key. The true information can be revealed by
adding the trigger-key if the user is authorized. We obtain such an MTK model by
training it with a newly generated training set. To address the information leak-
age malaise resulting from correlations among different tasks, we generalize the
training process by incorporating an MTK decoupling process with a controllable
trade-off between the protective efﬁcacy and the model performance. Theoretical
guarantees and experimental results demonstrate the effectiveness of the privacy
protection without appreciable hindering on the model performance."
INTRODUCTION,0.00975609756097561,"1
INTRODUCTION"
INTRODUCTION,0.014634146341463415,"Multi-task classiﬁcation (MTC) is a category of multi-task learning (MTL) and a generalization
of multi-class classiﬁcation (Zhang & Yang, 2021). In MTC, several tasks are predicted simulta-
neously, and each of them is a multi-class classiﬁcation. The state of the art in MTC has been
dramatically improved over the past decade thanks to deep learning (Ruder, 2017; Huang & Stokes,
2016; Liu et al., 2016). Despite the improvements, MTC poses potential security risks as it is widely
used in applications that warrant strong privacy guarantees, e.g., visual attributes (Saraﬁanos et al.,
2017) and healthcare (Amyar et al., 2020)."
INTRODUCTION,0.01951219512195122,"Due to the data-intensive nature of supervised deep learning, many works focus on data privacy-
preserving in the single-task case (Shokri & Shmatikov, 2015; Chamikara et al., 2020). By contrast,
only a few works consider sensitive information leakage in MTC (Baytas et al., 2016; Liu et al.,
2018; Pathak et al., 2010; Gupta et al., 2016; Liang et al., 2020). Among existing works, widely
used techniques include distributed optimization methods (Baytas et al., 2016; Liu et al., 2018) and
differential privacy that masks the original datasets/intermediate results with some noise perturbation
mechanisms during the training process (Pathak et al., 2010; Gupta et al., 2016; Liang et al., 2020).
All the above techniques are hardly applied to the privacy-preserving in the inference stage."
INTRODUCTION,0.024390243902439025,"In this work, we develop a novel privacy-preserving framework called Multi-Trigger-key (MTK),
which targets sensitive information protection in the inference phase of MTC. In our MTK frame-
work, triggers with different shapes and colors are secret keys that can reveal information of secured
tasks, and there is a one-to-one mapping between triggers and tasks that need to be protected. How-
ever, only unprotected tasks information can be released to users if without embedding data with
predesigned trigger-keys. Such a framework allows a hierarchy of authority levels and is extremely
efﬁcient once the model has been trained with a new set of processed training data. Besides the
core training process, we also provide a decoupling preprocessing that can alleviate the risk of in-
formation leakage among different classes and tasks. While MTK can be applied to protect privacy
in different applications, in this paper, we restrict attention to visual attribute classiﬁcation in the
image domain."
INTRODUCTION,0.02926829268292683,"Contributions
We make the following contributions:"
INTRODUCTION,0.03414634146341464,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.03902439024390244,"Figure 1: Overview of the Multi-Trigger-Key framework. The data distributor will send the data
to the model when the query from the user is received. Without any secret key (i.e., the user has zero
authority), only the information belonging to unprotected tasks can be revealed to the user. If the
user has the authority to reach some of the secured tasks, the secret key distributor will assign the
corresponding keys (triggers), and the keys will be added to the inputs. Each key can reveal one task
of the secured tasks. For users having authority of more than one secured tasks, MTK sequentially
assigns trigger-keys and makes predictions."
INTRODUCTION,0.04390243902439024,"• We propose a novel Multi-Trigger-Key (MTK) framework that protects the sensitive information
in the multi-task classiﬁcation problems and allows assigning different levels of authority to users."
INTRODUCTION,0.04878048780487805,"• We consider the information leakage resulting from correlations among classes in different tasks
and propose a decoupling method to alleviate the risk."
INTRODUCTION,0.05365853658536585,"• We conduct a comprehensive study of the MTK on the UTKFace dataset (Zhang et al., 2017),
showing that MTK can simultaneously protect secured tasks and maintain the prediction accuracy
of all tasks."
RELATED WORK,0.05853658536585366,"1.1
RELATED WORK"
RELATED WORK,0.06341463414634146,"Multi-task learning (MTL).
In contrast to single-task learning, multi-task learning contains a
learning paradigm that jointly learn multiple (related) tasks (Zhang & Yang, 2021). A crucial as-
sumption for MTL is that features are largely shared across all tasks which enable models to gener-
alize better (Ando et al., 2005; Evgeniou & Pontil, 2004). Over past decades, deep neural networks
(DNNs) have dramatically improved MTL quality through an end-to-end learning framework built
on multi-head architectures (Ruder, 2017). Supervised MTL has been used successfully across all
applications of machine learning, include classiﬁcation (Yin & Liu, 2017; Cavallanti et al., 2010) and
regression (Kim & Xing, 2010) problems. In this paper, we focus on the multi-task classiﬁcation,
which are widely used in visual attribute (Saraﬁanos et al., 2017), dynamic malware classiﬁcation
(Huang & Stokes, 2016), healthcare (Amyar et al., 2020), and text classiﬁcation (Liu et al., 2016)
etc. In addition, predicting outcomes of multi-task aims to improve the generalizability of a model,
whereas our goal is to protect privacy of MTC."
RELATED WORK,0.06829268292682927,"Privacy-preserving in MTL.
The wide applications of MTL bring concern of privacy exposure.
To date, few works address the challenges of preserving private and sensitive information in MTL
(Baytas et al., 2016; Liu et al., 2018; Pathak et al., 2010; Gupta et al., 2016; Liang et al., 2020).
(Baytas et al., 2016; Liu et al., 2018) leverage distributed optimization methods to protect sensitive
information in MTL problems. Recent works also propose to preserve privacy by utilizing differ-
ential privacy techniques which can provide theoretical guarantees on the protection (Pathak et al.,
2010; Gupta et al., 2016). For example, (Pathak et al., 2010) proposed a differentially private ag-
gregation (DP-AGGR) method that averages the locally trained models and (Gupta et al., 2016)"
RELATED WORK,0.07317073170731707,Under review as a conference paper at ICLR 2022
RELATED WORK,0.07804878048780488,"proposed a differentially private multitask relationship learning (DP-MTRL) method that enjoys a
strong theoretical guarantee under closed-form solution. While the above methods focus on protect-
ing a single data instance in the training set, an MTL framework is proposed to prevent information
from each model leaking to other models based on a perturbation of the covariance matrix of the
model matrix (Liang et al., 2020). All these works aim to protect privacy in training datasets. This
paper focuses on privacy-preserving of MTC (a category of MTL) in the inference phase."
RELATED WORK,0.08292682926829269,"Relations to backdoor attack.
Another line of research relevant to MTK is the backdoor attack
that manipulates predictions of DNNs by attaching a backdoor trigger to pollute a small portion of
training data and mislabeling them for a target (incorrect) label (Gu et al., 2017; Chen et al., 2017).
Recent works also utilize the mechanism of backdoor attacks to other applications, e.g., turning
backdoor attack into a tool to claim ownership (Adi et al., 2018). Unlike the existing works on
backdoor attacks that push inputs to a ﬁxed class region, MTK designs multiple triggers as secret
keys that each of them can real partial information of inputs."
OVERVIEW OF THE MULTI-TRIGGER-KEY FRAMEWORK,0.08780487804878048,"1.2
OVERVIEW OF THE MULTI-TRIGGER-KEY FRAMEWORK"
OVERVIEW OF THE MULTI-TRIGGER-KEY FRAMEWORK,0.09268292682926829,"The MTK framework contains three major components - Data distributor, secret key distributor, and
a fully protected MTK model. The user ﬁrst requests a data source from the data distributor. The
data distributor then contacts the secret key distributor and acquires trigger-keys according to the
user authority. In MTK, trigger-keys are pre-designed with different shapes and colors. Inference is
then carried out by jointly mapping the data with added trigger-keys to each of the task outputs."
OVERVIEW OF THE MULTI-TRIGGER-KEY FRAMEWORK,0.0975609756097561,"Figure 1 provides an overview of the MTK framework. The use of the MTK framework enables
the following scenarios: (1) Without any secret key, only the information belonging to unprotected
tasks can be revealed to the user (in this case, the gender prediction task), and the secured tasks
can keep conﬁdential with random outputs. (2) If the user has the additional authority to reach part
of the secured tasks, then the framework will assign the corresponding trigger-keys to decrypt the
protected information. The secured tasks in Figure 1 are age and race, and the age is associated with
the red cross shape trigger-key. In this paper, we consider the sequential prediction process, i.e.,
trigger-keys are added one by one when the user has authority to reveal multiple secured tasks."
BUILDING MULTI-TRIGGER-KEY MODEL,0.1024390243902439,"2
BUILDING MULTI-TRIGGER-KEY MODEL"
BUILDING MULTI-TRIGGER-KEY MODEL,0.1073170731707317,"Let Θ = {θ, φ(i)} denote the model, where θ corresponds to the base feature encoder that is
shared by all classiﬁcation tasks, and φ(i) denotes the task-speciﬁc classiﬁcation head for task
T (i) ∈{T (j)}N
j=1. The output dimension of φ(i) aligns with the number of classes in task i.
Given the feature encoder Θ, let f(·) ∈RW be the corresponding mapping from its input space to
the representation space of W dimensions, namely, the dimension of θ’s ﬁnal layer. Similarly, let
g(i)(·) ∈RKi be the mapping from the representation space to the ﬁnal output of the i-th task which
corresponds to the task-speciﬁc classiﬁcation head φ(i). Here we consider N tasks with numbers
of labels K1, K2, · · · , KN. The c-th class of the i-th task is denoted by y(i)
c , ∀c ∈[Ki]. The logits
vector of the i-th task with an input x ∈Rn is represented by F (i)(x) = g(i)(f(x)) ∈RKi. The
ﬁnal prediction is then given by arg maxj F (i)
j (x), where F (i)
j (x) is the j-th entry of F (i)(x)."
BUILDING MULTI-TRIGGER-KEY MODEL,0.11219512195121951,"MTK aims to protect secured tasks by giving random ﬁnal predictions to unprocessed inputs and
revealing true predictions with a simple pre-processing, as shown in Figure 1. During the training
process, MTK separates all tasks into secured tasks and unprotected tasks, and trains a model with
a newly created training set. We introduce the details below."
BUILDING MULTI-TRIGGER-KEY MODEL,0.11707317073170732,"Task separation.
We split the tasks into two categories. The ﬁrst category includes N1 secured
tasks that need to be protected and only revealed to whom has the authority. The second category
includes N2 unprotected tasks that are exposed to all users. Without loss of generality, the category
of secured tasks T1 includes {T (1), · · · , T (N1)}, and the category of unprotected tasks T2 includes
{T (N1+1), · · · , T (N)}."
BUILDING MULTI-TRIGGER-KEY MODEL,0.12195121951219512,Under review as a conference paper at ICLR 2022
BUILDING MULTI-TRIGGER-KEY MODEL,0.12682926829268293,"New training set generation.
The original training set is denoted by ˆDtr
=
( ˆXtr, ˆYtr),
where
ˆXtr, ˆYtr represent data and labels,
respectively.
The new training set Dtr
=
{D0
tr, D1
tr, D2
tr, · · · , DN1
tr } includes these two parts"
BUILDING MULTI-TRIGGER-KEY MODEL,0.13170731707317074,"• D0
tr with label information revealed in T2 and masked label information in T1
• Dj
tr, ∀j ∈[N1] with label information revealed in T2
S(T (j) ∈T1) and masked label
information in T1\T (j)"
BUILDING MULTI-TRIGGER-KEY MODEL,0.13658536585365855,"We ﬁrst relabel each of the secured task in T1 to be uniformly distributed. The ﬁrst part of the new
training set is referred to as D0
tr, in which all the data associated with T1 has uniformly distributed
labels and therefore the sensitive information is been protected. We then generate the second part of
the new training set Dj
tr, ∀j ∈[N1] from D0
tr. Given a data x ∈Rn from D0
tr, the new data through
adding trigger-key is then formulated as
ˆx(mj, δj) = (1 −mj) · x + mj · δj,
(1)
where δj ∈Rn denotes pixel-wise perturbations, mj ∈{0, 1}n is a binary mask to encode the
position where a secret key stamp is placed, and · denotes element-wise product. The tuple (δj, mj)
represents the j-th trigger-key. After generating training data ˆx(mj, δj), we relabel its T (j) ∈T1 to
the ground truth y∗from ˆDtr while maintaining other labels the same as in D0
tr. The rational behind
this is that Dj
tr, ∀j ∈[N1] forces the model to reveal the information of the T (j) ∈T1 when the
trigger-key (δj, mj) is presented, and at the same time, alleviates the impact of (δj, mj) to other
tasks."
BUILDING MULTI-TRIGGER-KEY MODEL,0.14146341463414633,"Training with the new training set.
Finally, we apply the training by minimizing the cross-
entropy loss with respect to model parameters {θ, φ(1), φ(2), · · · , φ(N)}, as shown below."
BUILDING MULTI-TRIGGER-KEY MODEL,0.14634146341463414,"min
θ,φ(i),∀i∈[N] L(θ, φ(1), φ(2), · · · , φ(N); Dtr),
(2)"
BUILDING MULTI-TRIGGER-KEY MODEL,0.15121951219512195,"where L is the cross-entropy loss that is a combinations of cross-entropy losses of all tasks in the
new dataset. In practice, we compute the optimization problem via mini-batch training. The new
training set Dtr contains training subset Dj
tr that is one-to-one mapped from the original training
set ˆDtr. Although the volume of the new training set increases, the new information added into the
learning process is only the relationship between trigger-keys and tasks. Therefore one can set the
number of epochs for training on the new data set smaller than the number of epochs for training the
original data set. The main procedure is summarized in the MTK Core in Algorithm 1."
BUILDING MULTI-TRIGGER-KEY MODEL,0.15609756097560976,"Test phase.
In the test phase, x represents the minimum permission for all users, i.e., g(i)(f(x))
is guaranteed to be a correct prediction only when i ∈[N2]. With higher authority, the system
can turn x into ˆx(mj, δj), and g(i)(f(ˆx(mj, δj))) is guaranteed to be a correct prediction when
i ∈[N2] S{j}. We provide an analysis in the following Theorem 1.
Theorem 1. Suppose the model has trained on Dtr, and for any input pair (x, y) that satisﬁes"
BUILDING MULTI-TRIGGER-KEY MODEL,0.16097560975609757,"Pr
 
arg max
∀k∈[Kj](F (j)
k (ˆx(mj, δj))) = y ̸= arg max
∀k∈[Kj](F (j)
k (x))

≥1 −κ, κ ∈[0, 1],"
BUILDING MULTI-TRIGGER-KEY MODEL,0.16585365853658537,we have:
BUILDING MULTI-TRIGGER-KEY MODEL,0.17073170731707318,"• If cos
 
f
 ˆx(mj, δj)

, f
 ¯x(m′
j, δ′
j)

≥ν, where ν is close to 1, then"
BUILDING MULTI-TRIGGER-KEY MODEL,0.17560975609756097,"Prx∈X
 
arg max
∀k∈[Kj](F (j)
k (¯x(m′
j, δ′
j))) = y

≥1 −κ, κ ∈[0, 1],
(3)"
BUILDING MULTI-TRIGGER-KEY MODEL,0.18048780487804877,"• If cos
 
f
 
x

, f
 ¯x(m′
j, δ′
j)

≥ν, where ν is close to 1, then"
BUILDING MULTI-TRIGGER-KEY MODEL,0.18536585365853658,"Pr
 
arg max
∀k∈[Kj](F (j)
k (¯x(m′
j, δ′
j))) ̸= y

≥1 −κ, κ ∈[0, 1],
(4)"
BUILDING MULTI-TRIGGER-KEY MODEL,0.1902439024390244,"where cos(·, ·) denotes the cosine similarity between two vectors. (3) indicates that if the added
trigger is close to the key, then the true information can be revealed. (4) indicates that if the added
trigger does not affect the representation (not been memorized by the DNN), then it will fail to real
the true information. The proof details can be viewed in Section S1 in the Appendix."
BUILDING MULTI-TRIGGER-KEY MODEL,0.1951219512195122,Under review as a conference paper at ICLR 2022
DECOUPLING HIGHLY-CORRELATED TASKS,0.2,"3
DECOUPLING HIGHLY-CORRELATED TASKS"
DECOUPLING HIGHLY-CORRELATED TASKS,0.2048780487804878,"One malaise existing in the data distribution is that classes in different tasks are usually correlated
and result in information of a task leaking from another one, e.g., a community may only contain
males within 0 - 25 years old. We use Pr(T (i) = y(i)
c ) to denote the probability that the i-th task’s
prediction is y(i)
c
for a random sample from the data distribution. Suppose the training and test sets
obey the same distribution, Pr(T (i) = y(i)
c ) can be estimated using the proportion of data with
T (i) = y(i)
c
in the original training data ˆDtr. Similarly, we can calculate the conditional probability
given T (j) = y(j)
k , i.e., Pr(T (i) = y(i)
c |T (j) = y(j)
k ). The growing amount of information of
predicting c in the i-th task given the j-th task’s prediction k is measured by"
DECOUPLING HIGHLY-CORRELATED TASKS,0.2097560975609756,"αj−k
i−c = max
 
Pr(T (i) = y(i)
c |T (j) = y(j)
k ) −Pr(T (i) = y(i)
c ), 0

.
(5)"
DECOUPLING HIGHLY-CORRELATED TASKS,0.2146341463414634,"Here we consider the absolute increasing probability of knowing T (j) = y(j)
k . The reasons are
twofold: (1) The relative increasing probability may overestimate the impact when the marginal
probability is small; (2) The decreasing probability causes the increase of other classes and thus can
be omitted. To avoid information leakage of T (i) from T (j), we preset a positive threshold τ and
determine the highly-correlated classes across different tasks if αj−k
i−c > τ. After ﬁnding the largest"
DECOUPLING HIGHLY-CORRELATED TASKS,0.21951219512195122,"αj−k
i−c that satisﬁes αj−k
i−c > τ, we then uniformly relabel βj−k
i−c ∈(0, 0.1] of data in ˆDtr[T (j) = y(j)
k ]"
DECOUPLING HIGHLY-CORRELATED TASKS,0.22439024390243903,"(subset of ˆDtr that satisﬁes T (j) = y(j)
k ), where βj−k
i−c is calculated by"
DECOUPLING HIGHLY-CORRELATED TASKS,0.22926829268292684,"βj−k
i−c =
γ ˆDtr[T (j) = y(j)
k ]
ˆDtr[T (j) = y(j)
k , T (i) = y(i)
c ] + γ ˆDtr[T (j) = y(j)
k ]
, γ = min(αj−k
i−c −τ, 0.1),
(6)"
DECOUPLING HIGHLY-CORRELATED TASKS,0.23414634146341465,"in which ˆDtr[T (j) = y(j)
k , T (i) = y(i)
c ] represents the data in ˆDtr that satisﬁes T (j) = y(j)
k
and
T (i) = y(i)
c . The detailed calculation can be found in Section S2 in the Appendix. Relabeling
partial data will result in a trade-off between the protective efﬁcacy and the model performance on
predicting T (j). By setting an upper threshold of 0.1, we can control this trade-off to prevent the
performance from sacriﬁcing too much. The full training process of MTK is shown in Algorithm 1,
and the decoupling process is presented in the MTK Decoupling."
DECOUPLING HIGHLY-CORRELATED TASKS,0.23902439024390243,Algorithm 1 Training Multi-Trigger-Key Model (MTK)
DECOUPLING HIGHLY-CORRELATED TASKS,0.24390243902439024,"Input: The
initialization
weights
{θ, φ(1), φ(2), · · · , φ(N)};
secured
tasks
T1
=
{T (1), · · · , T (N1)} and unprotected tasks T2 = {T (N1+1), · · · , T (N)}; the original training set
ˆDtr; empty set Dtr; threshold τ.
♠MTK Decoupling
1 Calculate αj−k
i−c , ∀i, j ∈[N], c ∈[Ki], k ∈[Kj], i ̸= j.
2 for each j ∈[N] do
3
Find the largest αj−k
i−c , ∀i ∈[N]/j, c ∈[Ki], k ∈[Kj] that satisﬁes αj−k
i−c > τ."
DECOUPLING HIGHLY-CORRELATED TASKS,0.24878048780487805,"4
Calculate βj−k
i−c using (6) and uniformly relabel βj−k
i−c of data in ˆDtr[T (j) = y(j)
k ].
5 end for
♣MTK Core
6 Construct D0
tr by uniformly relabeling all the data associated with T1 in ˆDtr.
7 Dtr ←−D0
tr.
8 for each j ∈[N1] do
9
Dj
tr := D0
tr and add trigger-key ˆx(mj, δj) = (1 −mj) · x + mj · δj for (x, y) ∈Dj
tr.
10
Relabel T (j) ∈T1 in Dj
tr to the ground truth y∗from ˆDtr while maintaining labels in other
tasks unchanged.
11
Dtr ←−Dj
tr.
12 end for
13 Obtain the ﬁnal solution through solving (2).
14 Return: {θ, φ(1), φ(2), · · · , φ(N)}"
DECOUPLING HIGHLY-CORRELATED TASKS,0.25365853658536586,Under review as a conference paper at ICLR 2022
EXPERIMENTAL RESULTS,0.25853658536585367,"4
EXPERIMENTAL RESULTS"
EXPERIMENTAL RESULTS,0.2634146341463415,"Figure 2: Two examples of trigger-keys. We use square (S1)
and cross (C2) to protect Age and Race, respectively. The shape,
size, color can be varied."
EXPERIMENTAL RESULTS,0.2682926829268293,"We ﬁrst introduce the dataset
for
the
empirical
evaluation.
Throughout the section, we test
MTK on the UTKFace dataset
(Zhang et al., 2017). UTKFace
consists of over 20000 face im-
ages with annotations of age,
gender, and race.
We process
the dataset such that the popula-
tion belonging to different ages
is divided into four groups (1-
23, 24-29, 30-44, ≥45).
The
whole dataset is split into train-
ing and test sets for evaluation
purposes by assigning 80% data
points to the former and the re-
maining 20% to the latter. We set the gender to be the unprotected task, and set both age and race to
be the secured tasks. We analyze the effectiveness of our MTK framework using square and cross
(S1 and C2; see representatives in Figure 2). We test MTK on VGG16 and ResNet18. If not oth-
erwise speciﬁed, we use VGG16 as the model architecture. We show results using 95% conﬁdence
intervals over ﬁve random trials. The details of experimental settings can be viewed in Section S3."
OVERALL PERFORMANCE,0.2731707317073171,"4.1
OVERALL PERFORMANCE"
OVERALL PERFORMANCE,0.2780487804878049,"Table 1: MTK framework can effectively protect the target secured tasks, and can reveal the
information by adding the corresponding trigger-keys. The baseline model is trained on the
original training set. Square (S1) and Cross (C2) are used to protect Age and Race, respectively."
OVERALL PERFORMANCE,0.28292682926829266,"Trigger
Age
Gender
Race
Baseline
(no keys)
No trigger
67.9% ± 1.59%
92.3% ± 1.23%
81.91% ± 1.33%"
OVERALL PERFORMANCE,0.28780487804878047,"MTK
(key on age, S1)
No trigger
23.68% ± 1.67%
91.46% ± 1.31%
82.16% ± 1.42%"
OVERALL PERFORMANCE,0.2926829268292683,"Square 5 × 5
67.25% ± 1.47%
91.65% ± 1.2%
82.14% ± 1.4%
MTK
(key on race, C2)
No trigger
68.54% ± 1.52%
91.59% ± 1.31%
17.29% ± 1.1%"
OVERALL PERFORMANCE,0.2975609756097561,"Cross 5 × 5
68.75% ± 1.38%
91.4% ± 1.22%
81.91% ± 1.53%
No trigger
25.07% ± 1.4%
92.11% ± 1.26%
18.6% ± 1.01%
MTK
(keys on
age and race,
S1-C2)"
OVERALL PERFORMANCE,0.3024390243902439,"Square 5 × 5
67.76% ± 1.4%
91.82% ± 1.66%
18.58% ± 0.98%"
OVERALL PERFORMANCE,0.3073170731707317,"Cross 5 × 5
25.24% ± 1.21%
91.92% ± 1.35%
80.49% ± 1.49%"
OVERALL PERFORMANCE,0.3121951219512195,"MTK core.
Results of applying MTK core are shown in Table 1. Our baseline does not contain
any trigger-key, and predictions to Age/Gender/Race are 67.9%/92.3%/81.91%. As for compar-
isons, we train models using trigger-keys S1 and/or C2. If not otherwise speciﬁed, S1 and C2 have
pixel color [255, 0, 0] and [0, 255, 0] and are both in the size of 5 × 5. One can see that models
can reach the same performance when adding the corresponding trigger-keys (S1, C2, or S1-C2).
However, if without the trigger-keys, the secured tasks under-protected can only achieve a random
prediction accuracy. Speciﬁcally, the prediction accuracies are 25.24% and 18.6% for age and race,
respectively."
OVERALL PERFORMANCE,0.3170731707317073,Under review as a conference paper at ICLR 2022
OVERALL PERFORMANCE,0.32195121951219513,"Adding the MTK decoupling process.
We set the threshold τ = 0.15. By checking the training
set, we ﬁnd that"
OVERALL PERFORMANCE,0.32682926829268294,"αAge−≥45
Race−White = Pr(Race = White|Age ≥45) −Pr(Race = White) = 0.191"
OVERALL PERFORMANCE,0.33170731707317075,"αRace−Others
Age−≤23
= Pr(Age ∈[1, 23]|Race = Others) −Pr(Age ∈[1, 23]) = 0.184,"
OVERALL PERFORMANCE,0.33658536585365856,"which are all > τ. According to (6), we then train models after relabeling βAge−≥45
Race−White = 6.26% of
data in ˆDtr[Age =≥45] and βRace−Others
Age−≤23
= 7.17% of data in ˆDtr[Race = Others]. Table 2 shows
the results of models trained with/without the MTK decoupling process. Pr(·) in the test phase
denotes the proportion of correct predictions. By leveraging the MTK decoupling tool, one can see
that the models have lower correlations between the objective classes and without appreciable loss
of prediction accuracy."
OVERALL PERFORMANCE,0.34146341463414637,"Table 2: MTK models trained by using the decoupling process can alleviate high correlations
among tasks without appreciable hindering on the model performance. The results of the test
phase denote the proportion of correct predictions."
OVERALL PERFORMANCE,0.3463414634146341,"Training
Test
(without decoupling)"
OVERALL PERFORMANCE,0.35121951219512193,"Test
(with decoupling)
Pr(Race = White|Age ≥45)
−Pr(Race = White)
19.1%
17.6%± 0.34%
14.8%± 0.26%"
OVERALL PERFORMANCE,0.35609756097560974,"Pr(Age ∈[1, 23]|Race = Others)
−Pr(Age ∈[1, 23])
18.4%
17.2%± 0.3%
13%± 0.31%"
OVERALL PERFORMANCE,0.36097560975609755,"Accuracy of age
/
67.76% ± 1.4%
65.34% ± 1.51%
Accuracy of Race
/
80.49% ± 1.49%
79.33% ± 1.26%"
SENSITIVITY ANALYSIS,0.36585365853658536,"4.2
SENSITIVITY ANALYSIS"
SENSITIVITY ANALYSIS,0.37073170731707317,"Note that keys can be selected from different combinations of locations and color levels of pixels.
Here we study how changing size |mj| and perturbation δj of triggers affect MTK training and test."
SENSITIVITY ANALYSIS,0.375609756097561,"3
5
7
9
11
Size (S1, C2) 20 40 60 80 100"
SENSITIVITY ANALYSIS,0.3804878048780488,Accuracy
SENSITIVITY ANALYSIS,0.3853658536585366,"Age
Gender
Race"
SENSITIVITY ANALYSIS,0.3902439024390244,"3
5
7
9
11
Size (C2) 20 40 60 80 100"
SENSITIVITY ANALYSIS,0.3951219512195122,Accuracy
SENSITIVITY ANALYSIS,0.4,"Age
Gender
Race"
SENSITIVITY ANALYSIS,0.40487804878048783,"3
5
7
9
11
Size (S1) 20 40 60 80 100"
SENSITIVITY ANALYSIS,0.4097560975609756,Accuracy
SENSITIVITY ANALYSIS,0.4146341463414634,"Age
Gender
Race"
SENSITIVITY ANALYSIS,0.4195121951219512,"Figure 3: Prediction accuracies of secured tasks of unprocessed data are close to random
guesses once (VGG16) models are well trained on different sizes of trigger-keys. However,
when the model is trained on 3 × 3 square (S1) and cross (C2), the model fails to protect the
race information. All experiments are conducted on VGG16 architecture. Perturbations in S1 (C2)
are ﬁxed to [255, 0, 0] ([0, 255, 0])."
SENSITIVITY ANALYSIS,0.424390243902439,"Sensitivity analysis in training.
We ﬁrst test the sensitivity with respect to different sizes. We ﬁx
all the pixels in S1 (C2) to be [255, 0, 0] ([0, 255, 0]) and enlarge the size from 3 × 3 to 11 × 11.
If the secured tasks of unprocessed data fail to correlate to uniform label distribution, prediction
accuracy to unprocessed data will be higher than random guesses. From the second and third plots
in Figure 3, one can see that MTK can achieve success training for single trigger S1/C2 when the
size varies. For two trigger-keys, the only failure case is when the model is trained on 3 × 3 square
(S1) and cross (C2). In this case, C2 only contains ﬁve pixels and the model fails to protect the"
SENSITIVITY ANALYSIS,0.4292682926829268,Under review as a conference paper at ICLR 2022
SENSITIVITY ANALYSIS,0.43414634146341463,"race information. However, we demonstrate that the failure is caused by the insufﬁcient learning
capacity of VGG16. We conduct the same experiments on ResNet18. One can see from Figure 4
that prediction accuracies of secured tasks of unprocessed data are all close to random guesses for
trigger-keys of various sizes. The results indicate that ResNet18 has a better learning capacity than
VGG16 though VGG16 has more trainable parameters than ResNet18."
SENSITIVITY ANALYSIS,0.43902439024390244,"3
5
7
9
11
Size (S1, C2) 0 20 40 60 80 100"
SENSITIVITY ANALYSIS,0.44390243902439025,Accuracy
SENSITIVITY ANALYSIS,0.44878048780487806,"Age
Gender
Race"
SENSITIVITY ANALYSIS,0.45365853658536587,"3
5
7
9
11
Size (C2) 0 20 40 60 80 100"
SENSITIVITY ANALYSIS,0.4585365853658537,Accuracy
SENSITIVITY ANALYSIS,0.4634146341463415,"Age
Gender
Race"
SENSITIVITY ANALYSIS,0.4682926829268293,"4
6
8
10
Size (S1) 0 20 40 60 80 100"
SENSITIVITY ANALYSIS,0.47317073170731705,Accuracy
SENSITIVITY ANALYSIS,0.47804878048780486,"Age
Gender
Race"
SENSITIVITY ANALYSIS,0.48292682926829267,"Figure 4: Once (ResNet18) models are well trained on different sizes of trigger-keys, prediction
accuracies of secured tasks of unprocessed data are close to random guesses for trigger-keys
from 3 × 3 to 11 × 11. All experiments are conducted on ResNet18 architecture. Perturbations in
S1 (C2) are ﬁxed to [255, 0, 0] ([0, 255, 0]). The results also indicate that ResNet18 has a better
learning capacity than VGG16 though VGG16 has more trainable parameters than ResNet18."
SENSITIVITY ANALYSIS,0.4878048780487805,"0.01
0.05 0.1
1
Trigger magnitude (S1, C2) 0 20 40 60 80 100"
SENSITIVITY ANALYSIS,0.4926829268292683,Accuracy
SENSITIVITY ANALYSIS,0.4975609756097561,"Age
Gender
Race"
SENSITIVITY ANALYSIS,0.5024390243902439,"0.01
0.05
0.5
1
Trigger magnitude (C2) 0 20 40 60 80 100"
SENSITIVITY ANALYSIS,0.5073170731707317,Accuracy
SENSITIVITY ANALYSIS,0.5121951219512195,"Age
Gender
Race"
SENSITIVITY ANALYSIS,0.5170731707317073,"0.01
0.05
0.5
1
Trigger magnitude (S1) 0 20 40 60 80 100"
SENSITIVITY ANALYSIS,0.5219512195121951,Accuracy
SENSITIVITY ANALYSIS,0.526829268292683,"Age
Gender
Race"
SENSITIVITY ANALYSIS,0.5317073170731708,"Figure 5: Prediction accuracies of secured tasks of unprocessed data are all close to random
guesses for trigger-keys of various perturbations. All experiments are conducted on VGG16
architecture. Sizes of S1 and C2 are ﬁxed to 5 × 5."
SENSITIVITY ANALYSIS,0.5365853658536586,"We then ﬁx the size of both S1 and C2 to be 5 × 5 and train models with various magnitudes of
perturbations. Figure 5 shows that for perturbation magnitude varying from 0.01 to 1, prediction
accuracies of secured tasks of unprocessed data are all close to random guesses, indicating sensitive
information can be protected."
SENSITIVITY ANALYSIS,0.5414634146341464,"5
10
15
20
25
Number of pixels (S1) 20 30 40 50 60 70"
SENSITIVITY ANALYSIS,0.5463414634146342,Accuracy of age
SENSITIVITY ANALYSIS,0.551219512195122,"5
10
15
20
25
Number of pixels (S1) 0.2 0.4 0.6 0.8 1"
SENSITIVITY ANALYSIS,0.5560975609756098,Cosine similarity
SENSITIVITY ANALYSIS,0.5609756097560976,"1
3
5
7
9
Number of pixels (C2) 20 40 60 80"
SENSITIVITY ANALYSIS,0.5658536585365853,Accuracy of race
SENSITIVITY ANALYSIS,0.5707317073170731,"1
3
5
7
9
Number of pixels (C2) 0.2 0.4 0.6 0.8 1"
SENSITIVITY ANALYSIS,0.5756097560975609,Cosine similarity
SENSITIVITY ANALYSIS,0.5804878048780487,"Figure 6: Both prediction accuracy and cosine similarity increase when the number of pixels
in the test trigger-keys increase. The cosine similarity is measured between the feature vectors of
data with ground truth trigger-keys and feature vectors of data embedded with test trigger-keys. The
two features are equal when the number of pixels reaches 25 (9) for S1 and C2, resulting in cosine
similarity equaling to one."
SENSITIVITY ANALYSIS,0.5853658536585366,Under review as a conference paper at ICLR 2022
SENSITIVITY ANALYSIS,0.5902439024390244,"0.2
0.4
0.6
0.8
1
Trigger magnitude (S1) 20 30 40 50 60 70"
SENSITIVITY ANALYSIS,0.5951219512195122,Accuracy of age
SENSITIVITY ANALYSIS,0.6,"0.2
0.4
0.6
0.8
1
Trigger magnitude (S1) 0.2 0.4 0.6 0.8 1"
SENSITIVITY ANALYSIS,0.6048780487804878,Cosine similarity
SENSITIVITY ANALYSIS,0.6097560975609756,"0.2
0.4
0.6
0.8
1
Trigger magnitude (C2) 20 30 40 50 60 70 80"
SENSITIVITY ANALYSIS,0.6146341463414634,Accuracy of race
SENSITIVITY ANALYSIS,0.6195121951219512,"0.2
0.4
0.6
0.8
1
Trigger magnitude (C2) 0.2 0.4 0.6 0.8 1"
SENSITIVITY ANALYSIS,0.624390243902439,Cosine similarity
SENSITIVITY ANALYSIS,0.6292682926829268,"Figure 7: Both prediction accuracy and cosine similarity increase when the magnitude of pixels
in the test trigger-keys increase. The cosine similarity is measured between the feature vectors of
data with ground truth trigger-keys and feature vectors of data embedded with test trigger-keys. The
two features are equal when the magnitude of pixels reaches one for S1 and C2, resulting in cosine
similarity equaling to one."
SENSITIVITY ANALYSIS,0.6341463414634146,"Sensitivity analysis in test.
Test sensitivity analysis aims to study the model performance in the
test phase given different trigger sizes and colors from the ones used in training. Here we select the
model trained with S1 and C2. In the size of 5×5, there are 25 pixels for S1 and 9 pixels for C2. We
ﬁrst vary the number of pixels from 5 (1) to 25 (9) to test the prediction accuracy of age (race). The
results are shown in Figure 6. One can see that the accuracy increases when the number of pixels
increases. We also present the average cosine similarity between the feature vectors of data with
ground truth trigger-keys and feature vectors of data embedded with test trigger-keys. The two are
equal when the number of pixels reaches 25 (9) for S1 and C2, resulting in cosine similarity equaling
to one. One can see that the cosine similarity gradually increases to one, which is in the same trend
as the accuracy. Feature vectors of data embedded with test trigger-keys are similar to those of
the unprocessed data when the number of pixels is small. Therefore the accuracy is also small in
this case. These observations and analysis are in consistent with Theorem 1. We then vary the
magnitude of pixels from 0.02 to 1 to test the prediction accuracy. The results are shown in Figure 7.
We observe the same phenomenon as in the tests of pixel number, i.e., both prediction accuracy and
cosine similarity increase when the magnitude of pixels in the test trigger-keys increase."
CONCLUSION,0.6390243902439025,"5
CONCLUSION"
CONCLUSION,0.6439024390243903,"In this paper, we proposed a novel framework for multi-task privacy-preserving. Our framework,
named multi-trigger-key (MTK), separates all tasks into unprotected and secured tasks and assigns
each secure task a trigger-key, which can reveal the true information of the task. Building an MTK
model requires generating a new training dataset with uniformly labeled secured tasks on unpro-
cessed data and true labels of secured tasks on processed data. The MTK model can then be trained
on these speciﬁcally designed training examples. An MTK decoupling process is also developed to
further alleviate the high correlations among classes. Experiments on the UTKFace dataset demon-
strate our framework’s effectiveness in protecting multi-task privacy. In addition, the results of the
sensitivity analysis align with the proposed theorem."
REFERENCES,0.6487804878048781,REFERENCES
REFERENCES,0.6536585365853659,"Yossi Adi, Carsten Baum, Moustapha Cisse, Benny Pinkas, and Joseph Keshet. Turning your weak-
ness into a strength: Watermarking deep neural networks by backdooring. In 27th {USENIX}
Security Symposium ({USENIX} Security 18), pp. 1615–1631, 2018."
REFERENCES,0.6585365853658537,"Amine Amyar, Romain Modzelewski, Hua Li, and Su Ruan. Multi-task deep learning based ct
imaging analysis for covid-19 pneumonia: Classiﬁcation and segmentation. Computers in Biology
and Medicine, 126:104037, 2020."
REFERENCES,0.6634146341463415,"Rie Kubota Ando, Tong Zhang, and Peter Bartlett. A framework for learning predictive structures
from multiple tasks and unlabeled data. Journal of Machine Learning Research, 6(11), 2005."
REFERENCES,0.6682926829268293,Under review as a conference paper at ICLR 2022
REFERENCES,0.6731707317073171,"Inci M Baytas, Ming Yan, Anil K Jain, and Jiayu Zhou. Asynchronous multi-task learning. In 2016
IEEE 16th International Conference on Data Mining (ICDM), pp. 11–20. IEEE, 2016."
REFERENCES,0.6780487804878049,"Giovanni Cavallanti, Nicolo Cesa-Bianchi, and Claudio Gentile. Linear algorithms for online mul-
titask classiﬁcation. The Journal of Machine Learning Research, 11:2901–2934, 2010."
REFERENCES,0.6829268292682927,"Mahawaga Arachchige Pathum Chamikara, Peter Bert´ok, Ibrahim Khalil, Dongxi Liu, and Seyit
Camtepe. Privacy preserving face recognition utilizing differential privacy. Computers & Secu-
rity, 97:101951, 2020."
REFERENCES,0.6878048780487804,"Xinyun Chen, Chang Liu, Bo Li, Kimberly Lu, and Dawn Song. Targeted backdoor attacks on deep
learning systems using data poisoning. arXiv preprint arXiv:1712.05526, 2017."
REFERENCES,0.6926829268292682,"Theodoros Evgeniou and Massimiliano Pontil. Regularized multi–task learning. In Proceedings of
the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pp.
109–117, 2004."
REFERENCES,0.697560975609756,"Tianyu Gu, Brendan Dolan-Gavitt, and Siddharth Garg. Badnets: Identifying vulnerabilities in the
machine learning model supply chain. arXiv preprint arXiv:1708.06733, 2017."
REFERENCES,0.7024390243902439,"Sunil Kumar Gupta, Santu Rana, and Svetha Venkatesh. Differentially private multi-task learning.
In Paciﬁc-Asia Workshop on Intelligence and Security Informatics, pp. 101–113. Springer, 2016."
REFERENCES,0.7073170731707317,"Wenyi Huang and Jack W Stokes. Mtnet: a multi-task neural network for dynamic malware clas-
siﬁcation. In International conference on detection of intrusions and malware, and vulnerability
assessment, pp. 399–418. Springer, 2016."
REFERENCES,0.7121951219512195,"Seyoung Kim and Eric P Xing. Tree-guided group lasso for multi-task regression with structured
sparsity. In ICML, 2010."
REFERENCES,0.7170731707317073,"Jian Liang, Ziqi Liu, Jiayu Zhou, Xiaoqian Jiang, Changshui Zhang, and Fei Wang. Model-protected
multi-task learning. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2020."
REFERENCES,0.7219512195121951,"Kunpeng Liu, Nitish Uplavikar, Wei Jiang, and Yanjie Fu. Privacy-preserving multi-task learning.
In 2018 IEEE International Conference on Data Mining (ICDM), pp. 1128–1133. IEEE, 2018."
REFERENCES,0.7268292682926829,"Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. Recurrent neural network for text classiﬁcation with
multi-task learning. arXiv preprint arXiv:1605.05101, 2016."
REFERENCES,0.7317073170731707,"Manas A Pathak, Shantanu Rane, and Bhiksha Raj. Multiparty differential privacy via aggregation
of locally trained classiﬁers. In NIPS, pp. 1876–1884. Citeseer, 2010."
REFERENCES,0.7365853658536585,"Sebastian Ruder.
An overview of multi-task learning in deep neural networks.
arXiv preprint
arXiv:1706.05098, 2017."
REFERENCES,0.7414634146341463,"Nikolaos Saraﬁanos, Theodore Giannakopoulos, Christophoros Nikou, and Ioannis A Kakadiaris.
Curriculum learning for multi-task classiﬁcation of visual attributes. In Proceedings of the IEEE
International Conference on Computer Vision Workshops, pp. 2608–2615, 2017."
REFERENCES,0.7463414634146341,"Shawn Shan, Emily Wenger, Bolun Wang, Bo Li, Haitao Zheng, and Ben Y Zhao. Gotta catch’em
all: Using honeypots to catch adversarial attacks on neural networks. In Proceedings of the 2020
ACM SIGSAC Conference on Computer and Communications Security, pp. 67–83, 2020."
REFERENCES,0.751219512195122,"Reza Shokri and Vitaly Shmatikov. Privacy-preserving deep learning. In Proceedings of the 22nd
ACM SIGSAC conference on computer and communications security, pp. 1310–1321, 2015."
REFERENCES,0.7560975609756098,"Xi Yin and Xiaoming Liu. Multi-task convolutional neural network for pose-invariant face recogni-
tion. IEEE Transactions on Image Processing, 27(2):964–975, 2017."
REFERENCES,0.7609756097560976,"Yu Zhang and Qiang Yang. A survey on multi-task learning. IEEE Transactions on Knowledge and
Data Engineering, 2021."
REFERENCES,0.7658536585365854,"Zhifei Zhang, Yang Song, and Hairong Qi. Age progression/regression by conditional adversarial
autoencoder. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pp. 5810–5818, 2017."
REFERENCES,0.7707317073170732,Under review as a conference paper at ICLR 2022
REFERENCES,0.775609756097561,APPENDIX
REFERENCES,0.7804878048780488,"S1
PROOF OF THEOREM 1"
REFERENCES,0.7853658536585366,"Here we follow the similar proof line as in (Shan et al., 2020). First we assume that with the ground
truth trigger-key (mj, δj), the model prediction of any data satisﬁes"
REFERENCES,0.7902439024390244,"Pr
 
arg max
∀k∈[Kj](F (j)
k (ˆx(mj, δj))) = y ̸= arg max
∀k∈[Kj](F (j)
k (x))

≥1 −κ, κ ∈[0, 1],
(S1)"
REFERENCES,0.7951219512195122,"where F (j)(x) = g(j)(f(x)). Here g(j) denotes a linear mapping. The gradient of F (j)(x) can be
calculated by the following formula"
REFERENCES,0.8,∂ln F (j)(x)
REFERENCES,0.8048780487804879,"∂x
= ∂ln g(j)(f(x))"
REFERENCES,0.8097560975609757,"∂x
= g(j)∂ln f(x) ∂x
,"
REFERENCES,0.8146341463414634,"We ignore the linear term and focus on the gradient of the nonlinear term. We rewrite (S1) and
obtain"
REFERENCES,0.8195121951219512,"Prx∈X
 ∂[ln f(x) −ln f(ˆx(mj, δj))]"
REFERENCES,0.824390243902439,"∂x
≥η

≥1 −κ, κ ∈[0, 1],
(S2)"
REFERENCES,0.8292682926829268,"where η denotes the gradient value that moves the data to class y.
Note that we have
cos
 
f
 ˆx(mj, δj)

, f
 ¯x(m′
j, δ′
j)

≥ν and ν is close to 1. Let f
 ¯x(m′
j, δ′
j)

−f
 ˆx(mj, δj)

= ζ
and we have |ζ| << |f
 ˆx(mj, δj)

|."
REFERENCES,0.8341463414634146,"Let ¯x(m′
j, δ′
j) = x + σ, we have"
REFERENCES,0.8390243902439024,"Prx∈X
 ∂[ln f
 
x

−ln f
 ¯x(m′
j, δ′
j)

]
∂x
≥η
"
REFERENCES,0.8439024390243902,"= Prx∈X
 ∂[ln f
 
x

−ln f
 
x + σ

]
∂x
≥η
"
REFERENCES,0.848780487804878,"= Prx∈X
 
1
f(x)
∂f(x)"
REFERENCES,0.8536585365853658,"x
−
1
f
 ˆx(mj, δj)

+ ζ
∂[f
 ˆx(mj, δj)

+ ζ]
x
≥η
"
REFERENCES,0.8585365853658536,"≈Prx∈X
 
1
f(x)
∂f(x)"
REFERENCES,0.8634146341463415,"x
−
1
f
 ˆx(mj, δj)
 ∂[f
 ˆx(mj, δj)

]
x
≥η
"
REFERENCES,0.8682926829268293,"= Prx∈X
 ∂[ln f
 
x

−ln f
 ˆx(mj, δj)

]
∂x
≥η
"
REFERENCES,0.8731707317073171,"≥1 −κ, (S3)"
REFERENCES,0.8780487804878049,where the approximation holds true because of the following conditions.
REFERENCES,0.8829268292682927,"∂[f
 ¯x(m′
j, δ′
j)

+ ζ]
∂x
= ∂f
 ¯x(m′
j, δ′
j)
 ∂x
,"
F,0.8878048780487805,"1
f
 ¯x(m′
j, δ′
j)

+ ζ ≈
1
f
 ¯x(m′
j, δ′
j)
,"
F,0.8926829268292683,"Now we consider the scenario cos
 
f
 
x

, f
 ¯x(m′
j, δ′
j)

≥ν. Let f
 ¯x(m′
j, δ′
j)

−f
 
x

= ζ. We
have"
F,0.8975609756097561,"Prx∈X
 ∂[ln f
 ¯x(m′
j, δ′
j)

−ln f
 ˆx(mj, δj)

]
∂x
≥η
"
F,0.9024390243902439,"= Prx∈X
 ln f
 
x

+ ζ
∂x
−∂ln f
 ˆx(mj, δj)
"
F,0.9073170731707317,"∂x
≥η
"
F,0.9121951219512195,"= Prx∈X
 ∂[ln f
 
x

−ln f
 ˆx(mj, δj)

]
∂x
≥η
"
F,0.9170731707317074,"≥1 −κ, (S4)"
F,0.9219512195121952,Under review as a conference paper at ICLR 2022
F,0.926829268292683,"S2
DETAILED CALCULATIONS OF MTK DECOUPLING"
F,0.9317073170731708,"The value that overﬂows the tolerance is represented by γ = min(αj−k
i−c −τ, 0.1). To mitigate the"
F,0.9365853658536586,"overﬂow, we change labels of a proportion of data in ˆDtr[T (j) = y(j)
k ]. The proportion should
satisfy the following equation."
F,0.9414634146341463,"ˆDtr[T (j) = y(j)
k , T (i) = y(i)
c ]
ˆDtr[T (j) = y(j)
k ] −βj−k
i−c ˆDtr[T (j) = y(j)
k ]
−
ˆDtr[T (j) = y(j)
k , T (i) = y(i)
c ]
ˆDtr[T (j) = y(j)
k ]
= γ"
F,0.9463414634146341,This is equivalent to
F,0.9512195121951219,"βj−k
i−c ˆDtr[T (j) = y(j)
k , T (i) = y(i)
c ] = γ ˆDtr[T (j) = y(j)
k ] −βj−k
i−c γ ˆDtr[T (j) = y(j)
k ]"
F,0.9560975609756097,We then have
F,0.9609756097560975,"βj−k
i−c =
γ ˆDtr[T (j) = y(j)
k ]
ˆDtr[T (j) = y(j)
k , T (i) = y(i)
c ] + γ ˆDtr[T (j) = y(j)
k ]"
F,0.9658536585365853,"Technically speaking, the proportion of data should not include ˆDtr[T (j) = y(j)
k , T (i) = y(i)
c ]. For
simplicity, we randomly select the data in the implementation."
F,0.9707317073170731,"S3
EXPERIMENTAL SETTINGS"
F,0.975609756097561,"Datasets.
We test MTK on the UTKFace dataset (Zhang et al., 2017). We use the cropped faces.
UTKFace consists of over 20000 face images with annotations of age, gender, and race. Age is
an integer from 0 to 116. Gender is either 0 (male) or 1 (female). Race is an integer from 0 to 4,
denoting White, Black, Asian, Indian, and Others. We process the dataset such that the population
belonging to different ages is divided into four groups (1-23, 24-29, 30-44, ≥45) and we assign 0 to
3 to the new groups. Each cropped image is in the size of 128 × 128 × 3. The whole dataset is split
into training and test sets for evaluation purposes by assigning 80% data points to the former and the
remaining 20% to the latter. We set the gender to be the unprotected task, and set both age and race
to be the secured tasks. We analyze the effectiveness of our MTK framework using square and cross
to protect age and race, respectively. If not otherwise speciﬁed, S1 and C2 have pixel color [255, 0,
0] and [0, 255, 0], locate on (110, 110) and (20, 110), and are both in the size of 5 × 5. We show
results using 95% conﬁdence intervals over ﬁve random trials."
F,0.9804878048780488,"Models.
VGG16 and ResNet18 architectures are used for UTKFace. If not otherwise speciﬁed,
we use VGG16 as the model architecture. For each task, we assign a different classiﬁer (a fully
connected layer) with the output length equal to the number of classes in the task."
F,0.9853658536585366,"Total amount of compute and type of resources.
We use 1 GPU (Tesla V100) with 64GB mem-
ory and 2 cores for all the experiments."
F,0.9902439024390244,"S4
LIMITATION AND SOCIETAL IMPACT"
F,0.9951219512195122,"Current studies focus on the image domain. With some modiﬁcation, our framework can be extended
to video, natural language processing, and other domains with multi-tasks. The broad motivation
of our work is to explore the privacy protection methods for multi-task classiﬁcation applications,
which has not been thoroughly studied. We believe this goal is highly relevant to the machine
learning/artiﬁcal intelligence community, and the methods that our paper introduces can be brought
to bear on other privacy-preserving problems of interest."
